WARNING: AVX is not support on your machine. Hence, no_avx core will be imported, It has much worse preformance than avx core.
/home/gongwb/.local/lib/python3.7/site-packages/setuptools/depends.py:2: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0630 22:19:51.950202 112121 init.cc:88] Before Parse: argc is 2, Init commandline: dummy --tryfromenv=check_nan_inf,benchmark,eager_delete_scope,fraction_of_cpu_memory_to_use,initial_cpu_memory_in_mb,init_allocated_mem,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_system_allocator,enable_unused_var_check,free_idle_chunk,free_when_no_cache_hit,call_stack_level,sort_sum_gradient,max_inplace_grad_add,use_pinned_memory,cpu_deterministic,selected_npus,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,gpu_memory_limit_mb 
I0630 22:19:51.950395 112121 init.cc:95] After Parse: argc is 1
/home/liupeng51/github/Paddle/build/build_ubuntu_develop_release_ascend_y_none_3.7.5/python/paddle/hapi/model.py:28: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working
  from collections import Iterable
-----------  Configuration Arguments -----------
data_dir: ./data_bak
debug: False
do_eval: True
epoch: 100
ernie_config_file: config/ernie_base_config.json
eval_batch_size: 35
eval_data_path: ./data
eval_steps: -1
global_bsz: 64
global_steps: 0
grad_merge: 0
init_checkpoint: output/step_1
learning_rate: 0.0001
log_steps: 1
max_seq_len: 512
micro_bsz: 8
num_dp: 1
num_mp: 1
num_pp: 2
num_sharding: 1
num_train_steps: 250
output_dir: output/npu-pp-from-gpu-1f1b
preln: False
save_steps: 500
seed: 2021
use_amp: True
use_hybrid_dp: True
use_lamb: False
use_offload: False
use_recompute: True
use_sharding: True
use_sop: False
vocab_file: ./config/30k-clean.vocab.albert
warmup_steps: 10000
weight_decay: 0.01
------------------------------------------------
[INFO] 2021-06-30 22:19:52,717 [run_pretraining.py:  285]:	pretraining start
[INFO] 2021-06-30 22:19:52,717 [run_pretraining.py:  310]:	using recompute.
[INFO] 2021-06-30 22:19:52,718 [run_pretraining.py:  355]:	using globa_bsz: 64 micro_bsz: 8, acc_steps: 8
[DEBUG] 2021-06-30 22:19:52,782 [run_pretraining.py:  148]:	========= dp_sharding worker: 0 of 1 ==========
[INFO] 2021-06-30 22:19:52,782 [pretraining_ds_mlm.py:  263]:	Apply sharding in distribution env 0/1
[INFO] 2021-06-30 22:19:52,782 [pretraining_ds_mlm.py:  265]:	read from ./data_bak/part-00000.104,./data_bak/part-00000.100,./data_bak/part-00000.107,./data_bak/part-00000.103,./data_bak/part-00000.10,./data_bak/part-00000.105,./data_bak/part-00000.101,./data_bak/part-00000.102,./data_bak/part-00000.106,./data_bak/part-00000.109,./data_bak/part-00000.108
I0630 22:19:52.782786 112121 reader_py.cc:387] init_lod_tensor_blocking_queue
INFO:root:places would be ommited when DataLoader is not iterable
input_mask(-1, 512, 1)
/home/liupeng51/github/Paddle/build/build_ubuntu_develop_release_ascend_y_none_3.7.5/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /home/liupeng51/github/FleetX/examples/hybrid_parallelism/model/ernie.py:153
The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
/home/liupeng51/github/Paddle/build/build_ubuntu_develop_release_ascend_y_none_3.7.5/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /home/liupeng51/github/FleetX/examples/hybrid_parallelism/model/ernie.py:154
The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
/home/liupeng51/github/Paddle/build/build_ubuntu_develop_release_ascend_y_none_3.7.5/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /home/liupeng51/github/FleetX/examples/hybrid_parallelism/model/transformer_encoder.py:166
The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
/home/liupeng51/github/Paddle/build/build_ubuntu_develop_release_ascend_y_none_3.7.5/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /home/liupeng51/github/FleetX/examples/hybrid_parallelism/model/transformer_encoder.py:276
The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
/home/liupeng51/github/Paddle/build/build_ubuntu_develop_release_ascend_y_none_3.7.5/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /home/liupeng51/github/FleetX/examples/hybrid_parallelism/model/transformer_encoder.py:39
The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
/home/liupeng51/github/Paddle/build/build_ubuntu_develop_release_ascend_y_none_3.7.5/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /home/liupeng51/github/FleetX/examples/hybrid_parallelism/model/transformer_encoder.py:40
The behavior of expression A * B has been unified with elementwise_mul(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_mul(X, Y, axis=0) instead of A * B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
[DEBUG] 2021-06-30 22:19:53,511 [run_pretraining.py:  395]:	base lr: 0.0001
/home/liupeng51/github/Paddle/build/build_ubuntu_develop_release_ascend_y_none_3.7.5/python/paddle/distributed/fleet/base/fleet_base.py:813: UserWarning: It is recommended to use DistributedStrategy in fleet.init(). The strategy here is only for compatibility. If the strategy in fleet.distributed_optimizer() is not None, then it will overwrite the DistributedStrategy in fleet.init(), which will take effect in distributed training.
  "It is recommended to use DistributedStrategy "
2021-06-30 22:19:53 INFO     Gradient merge in [pp_gm], acc step = [8]
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:Gradient merge in [pp_gm], acc step = [8]
Wed Jun 30 22:19:53-INFO: recompute segment[0]
Wed Jun 30 22:19:53-INFO: segment start op: [lookup_table_v2]: [['src_ids', 'word_embedding']]
Wed Jun 30 22:19:53-INFO: segment end op: [layer_norm]: [['encoder_layer_0_post_ffn_layer_norm_bias', 'encoder_layer_0_post_ffn_layer_norm_scale', 'tmp_10']]
Wed Jun 30 22:19:53-INFO: recompute segment[0]
Wed Jun 30 22:19:53-INFO: segment start op: [lookup_table_v2]: [['src_ids', 'word_embedding']]
Wed Jun 30 22:19:53-INFO: segment end op: [layer_norm]: [['encoder_layer_0_post_ffn_layer_norm_bias', 'encoder_layer_0_post_ffn_layer_norm_scale', 'tmp_10']]
Wed Jun 30 22:19:53-INFO: found [0] vars which cross recompute segment: [set()], better checkpoints might be set to reduce those vars
pp_rank: 0
2021-06-30 22:19:59 INFO     global word size: 2
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:global word size: 2
2021-06-30 22:19:59 INFO     global rank: 0
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:global rank: 0
2021-06-30 22:19:59 INFO     global endpoints: ['192.168.206.27:6170', '192.168.206.27:6171']
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:global endpoints: ['192.168.206.27:6170', '192.168.206.27:6171']
2021-06-30 22:19:59 INFO     global ring id: 3
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:global ring id: 3
2021-06-30 22:19:59 INFO     ##############################
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:##############################
2021-06-30 22:19:59 INFO     mp group size: 1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:mp group size: 1
2021-06-30 22:19:59 INFO     mp rank: -1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:mp rank: -1
2021-06-30 22:19:59 INFO     mp group id: -1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:mp group id: -1
2021-06-30 22:19:59 INFO     mp group endpoints: []
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:mp group endpoints: []
2021-06-30 22:19:59 INFO     mp ring id: -1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:mp ring id: -1
2021-06-30 22:19:59 INFO     ##############################
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:##############################
2021-06-30 22:19:59 INFO     sharding group size: 1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:sharding group size: 1
2021-06-30 22:19:59 INFO     sharding rank: -1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:sharding rank: -1
2021-06-30 22:19:59 INFO     sharding group id: -1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:sharding group id: -1
2021-06-30 22:19:59 INFO     sharding group endpoints: []
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:sharding group endpoints: []
2021-06-30 22:19:59 INFO     sharding ring id: -1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:sharding ring id: -1
2021-06-30 22:19:59 INFO     ##############################
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:##############################
2021-06-30 22:19:59 INFO     pp group size: 2
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pp group size: 2
2021-06-30 22:19:59 INFO     pp rank: 0
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pp rank: 0
2021-06-30 22:19:59 INFO     pp group id: 0
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pp group id: 0
2021-06-30 22:19:59 INFO     pp group endpoints: ['192.168.206.27:6170', '192.168.206.27:6171']
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pp group endpoints: ['192.168.206.27:6170', '192.168.206.27:6171']
2021-06-30 22:19:59 INFO     pp ring id: 20
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pp ring id: 20
2021-06-30 22:19:59 INFO     ##############################
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:##############################
2021-06-30 22:19:59 INFO     pure dp group size: 1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pure dp group size: 1
2021-06-30 22:19:59 INFO     pure dp rank: -1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pure dp rank: -1
2021-06-30 22:19:59 INFO     pure dp group endpoints: []
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pure dp group endpoints: []
2021-06-30 22:19:59 INFO     pure dp ring id: -1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pure dp ring id: -1
2021-06-30 22:19:59 INFO     ##############################
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:##############################
pp pair:(0, 1), ring_id: 20
pp pair:(1, 0), ring_id: 21
[INFO] 2021-06-30 22:20:03,983 [run_pretraining.py:  427]:	applied_meta_list: ['ShardingOptimizer', 'AMPOptimizer', 'RecomputeOptimizer']
[INFO] 2021-06-30 22:20:03,986 [run_pretraining.py:  428]:	*******go out of gaurd
I0630 22:20:18.653035 112121 collective_helper_npu.cc:83] initialized comm: 0xfffff117f080, nranks: 2, hccl_id: 0xbe04034, rank: 0
I0630 22:20:20.060536 112121 collective_helper_npu.cc:88] initialized comm: 0xfffff117f080, nranks: 2, hccl_id: 0xbe04034, rank: 0
I0630 22:20:20.060756 112121 collective_helper_npu.cc:93] hccl communicator of rank 0 in ring 3 has been created on device 0, with comm: 0xbdd1e00
I0630 22:20:20.890359 112121 collective_helper_npu.cc:83] initialized comm: 0xfffff117f080, nranks: 2, hccl_id: 0xbe1d114, rank: 0
I0630 22:20:22.110141 112121 collective_helper_npu.cc:88] initialized comm: 0xfffff117f080, nranks: 2, hccl_id: 0xbe1d114, rank: 0
I0630 22:20:22.110325 112121 collective_helper_npu.cc:93] hccl communicator of rank 0 in ring 20 has been created on device 0, with comm: 0xbd999e0
I0630 22:20:22.453910 112121 gen_hccl_id_op_helper.cc:181] Server listening on: 192.168.206.27:6170 successful.
I0630 22:20:22.455374 112121 collective_helper_npu.cc:83] initialized comm: 0xfffff117f080, nranks: 2, hccl_id: 0xbe31054, rank: 1
I0630 22:20:23.673548 112121 collective_helper_npu.cc:88] initialized comm: 0xfffff117f080, nranks: 2, hccl_id: 0xbe31054, rank: 1
I0630 22:20:23.673722 112121 collective_helper_npu.cc:93] hccl communicator of rank 1 in ring 21 has been created on device 0, with comm: 0xbd81be0
[INFO] 2021-06-30 22:20:24,060 [run_pretraining.py:  483]:	 
[INFO] 2021-06-30 22:20:24,060 [run_pretraining.py:  484]:	############################WARNING############################
[INFO] 2021-06-30 22:20:24,060 [run_pretraining.py:  485]:	####### using ini_checkpoint, not init_pretraining_params ####
[INFO] 2021-06-30 22:20:24,060 [run_pretraining.py:  486]:	## meaning hyper param e.g. lr will inherit from checkpoint ##
[INFO] 2021-06-30 22:20:24,061 [run_pretraining.py:  487]:	###############################################################
Load model from output/step_1
[INFO] 2021-06-30 22:20:24,516 [run_pretraining.py:  489]:	 
data_loader started
run training
I0630 22:20:30.057348 113388 lod_tensor_blocking_queue.h:104] Init queue with size 1
I0630 22:20:30.057471 113388 buffered_reader.cc:41] BufferedReader
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
run training
[DEBUG] 2021-07-01 01:15:06,587 [run_pretraining.py:  613]:	saving final models to output/npu-pp-from-gpu-1f1b/final_step_250
[DEBUG] 2021-07-01 01:15:06,588 [run_pretraining.py:  614]:	end of training, total steps: 250
I0701 01:15:09.925676 112121 reader.h:164] ~ReaderHolder
I0701 01:15:09.925766 112121 buffered_reader.cc:22] ~BufferedReader
I0701 01:15:09.925779 112121 lod_tensor_blocking_queue.h:59] LoDTensorBlockingQueue close
I0701 01:15:09.925788 112121 blocking_queue.h:132] close queue
I0701 01:15:09.925945 112121 reader.cc:76] ~DecoratedReader
I0701 01:15:09.925957 112121 lod_tensor_blocking_queue.h:59] LoDTensorBlockingQueue close
I0701 01:15:09.925964 112121 blocking_queue.h:132] close queue
I0701 01:15:09.926723 112121 reader.h:164] ~ReaderHolder
I0701 01:15:09.926738 112121 lod_tensor_blocking_queue.h:59] LoDTensorBlockingQueue close
I0701 01:15:09.926744 112121 blocking_queue.h:132] close queue
terminate called without an active exception


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::framework::SignalHandle(char const*, int)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1625073309 (unix time) try "date -d @1625073309" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1b5f9) received by PID 112121 (TID 0xffff4965e1e0) from PID 112121 ***]

