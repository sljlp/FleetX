/home/gongwb/.local/lib/python3.7/site-packages/setuptools/depends.py:2: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0709 16:38:09.979844 36129 init.cc:88] Before Parse: argc is 2, Init commandline: dummy --tryfromenv=check_nan_inf,benchmark,eager_delete_scope,fraction_of_cpu_memory_to_use,initial_cpu_memory_in_mb,init_allocated_mem,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_system_allocator,enable_unused_var_check,free_idle_chunk,free_when_no_cache_hit,call_stack_level,sort_sum_gradient,max_inplace_grad_add,use_pinned_memory,cpu_deterministic,selected_npus,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,gpu_memory_limit_mb 
I0709 16:38:09.980057 36129 init.cc:95] After Parse: argc is 1
-----------  Configuration Arguments -----------
data_dir: ./data
debug: False
do_eval: True
epoch: 100
ernie_config_file: config/ernie_base_config.json
eval_batch_size: 35
eval_data_path: ./data
eval_steps: -1
global_bsz: 8
global_steps: 0
grad_merge: 0
init_checkpoint: 
learning_rate: 0.0001
log_steps: 1
max_seq_len: 512
micro_bsz: 1
num_dp: 1
num_mp: 4
num_pp: 2
num_sharding: 1
num_train_steps: 1600
output_dir: output/test-bs8-mppp
preln: False
save_steps: 500
seed: 2021
use_amp: True
use_hybrid_dp: True
use_lamb: False
use_offload: False
use_recompute: True
use_sharding: True
vocab_file: ./config/30k-clean.vocab.albert
warmup_steps: 10000
weight_decay: 0.01
------------------------------------------------
to run startup
[INFO] 2021-07-09 16:38:10,799 [run_pretraining.py:  216]:	pretraining start
[INFO] 2021-07-09 16:38:10,799 [run_pretraining.py:  234]:	using recompute.
[INFO] 2021-07-09 16:38:10,799 [run_pretraining.py:  279]:	using globa_bsz: 8 micro_bsz: 1, acc_steps: 8
[DEBUG] 2021-07-09 16:38:10,863 [run_pretraining.py:  118]:	========= dp_sharding worker: 0 of 1 ==========
[INFO] 2021-07-09 16:38:10,863 [pretraining_ds_mlm.py:  293]:	Apply sharding in distribution env 0/1
[INFO] 2021-07-09 16:38:10,863 [pretraining_ds_mlm.py:  295]:	read from ./data/part-00000.104,./data/part-00000.100,./data/part-00000.107,./data/part-00000.103,./data/part-00000.10,./data/part-00000.105,./data/part-00000.101,./data/part-00000.102,./data/part-00000.106,./data/part-00000.109,./data/part-00000.108
I0709 16:38:10.864027 36129 reader_py.cc:387] init_lod_tensor_blocking_queue
INFO:root:places would be ommited when DataLoader is not iterable
/home/liupeng51/github/Paddle/build/build_ubuntu_optimizer_checkinf_release_ascend_y_none_3.7.5/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /home/liupeng51/github/FleetX/examples/hybrid_parallelism/model/ernie.py:158
The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
/home/liupeng51/github/Paddle/build/build_ubuntu_optimizer_checkinf_release_ascend_y_none_3.7.5/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /home/liupeng51/github/FleetX/examples/hybrid_parallelism/model/ernie.py:159
The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
/home/liupeng51/github/Paddle/build/build_ubuntu_optimizer_checkinf_release_ascend_y_none_3.7.5/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /home/liupeng51/github/FleetX/examples/hybrid_parallelism/model/transformer_encoder.py:170
The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
/home/liupeng51/github/Paddle/build/build_ubuntu_optimizer_checkinf_release_ascend_y_none_3.7.5/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /home/liupeng51/github/FleetX/examples/hybrid_parallelism/model/transformer_encoder.py:280
The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
/home/liupeng51/github/Paddle/build/build_ubuntu_optimizer_checkinf_release_ascend_y_none_3.7.5/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /home/liupeng51/github/FleetX/examples/hybrid_parallelism/model/transformer_encoder.py:43
The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
/home/liupeng51/github/Paddle/build/build_ubuntu_optimizer_checkinf_release_ascend_y_none_3.7.5/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /home/liupeng51/github/FleetX/examples/hybrid_parallelism/model/transformer_encoder.py:44
The behavior of expression A * B has been unified with elementwise_mul(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_mul(X, Y, axis=0) instead of A * B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
[DEBUG] 2021-07-09 16:38:11,667 [run_pretraining.py:  315]:	base lr: 0.0001
/home/liupeng51/github/Paddle/build/build_ubuntu_optimizer_checkinf_release_ascend_y_none_3.7.5/python/paddle/distributed/fleet/base/fleet_base.py:818: UserWarning: It is recommended to use DistributedStrategy in fleet.init(). The strategy here is only for compatibility. If the strategy in fleet.distributed_optimizer() is not None, then it will overwrite the DistributedStrategy in fleet.init(), which will take effect in distributed training.
  "It is recommended to use DistributedStrategy "
2021-07-09 16:38:11 INFO     Gradient merge in [pp_gm], acc step = [8]
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:Gradient merge in [pp_gm], acc step = [8]
Fri Jul 09 16:38:12-INFO: recompute segment[0]
Fri Jul 09 16:38:12-INFO: segment start op: [squeeze2]: [['shard_index_0.tmp_0']]
Fri Jul 09 16:38:12-INFO: segment end op: [layer_norm]: [['encoder_layer_0_post_ffn_layer_norm_bias', 'encoder_layer_0_post_ffn_layer_norm_scale', 'tmp_10']]
Fri Jul 09 16:38:12-INFO: recompute segment[0]
Fri Jul 09 16:38:12-INFO: segment start op: [squeeze2]: [['shard_index_0.tmp_0']]
Fri Jul 09 16:38:12-INFO: segment end op: [layer_norm]: [['encoder_layer_0_post_ffn_layer_norm_bias', 'encoder_layer_0_post_ffn_layer_norm_scale', 'tmp_10']]
Fri Jul 09 16:38:12-INFO: found [0] vars which cross recompute segment: [set()], better checkpoints might be set to reduce those vars
pp_rank: 1
2021-07-09 16:38:17 INFO     global word size: 8
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:global word size: 8
2021-07-09 16:38:17 INFO     global rank: 7
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:global rank: 7
2021-07-09 16:38:17 INFO     global endpoints: ['192.168.206.27:6170', '192.168.206.27:6171', '192.168.206.27:6172', '192.168.206.27:6173', '192.168.206.27:6174', '192.168.206.27:6175', '192.168.206.27:6176', '192.168.206.27:6177']
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:global endpoints: ['192.168.206.27:6170', '192.168.206.27:6171', '192.168.206.27:6172', '192.168.206.27:6173', '192.168.206.27:6174', '192.168.206.27:6175', '192.168.206.27:6176', '192.168.206.27:6177']
2021-07-09 16:38:17 INFO     global ring id: 3
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:global ring id: 3
2021-07-09 16:38:17 INFO     ##############################
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:##############################
2021-07-09 16:38:17 INFO     mp group size: 4
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:mp group size: 4
2021-07-09 16:38:17 INFO     mp rank: 3
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:mp rank: 3
2021-07-09 16:38:17 INFO     mp group id: 1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:mp group id: 1
2021-07-09 16:38:17 INFO     mp group endpoints: ['192.168.206.27:6174', '192.168.206.27:6175', '192.168.206.27:6176', '192.168.206.27:6177']
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:mp group endpoints: ['192.168.206.27:6174', '192.168.206.27:6175', '192.168.206.27:6176', '192.168.206.27:6177']
2021-07-09 16:38:17 INFO     mp ring id: 0
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:mp ring id: 0
2021-07-09 16:38:17 INFO     ##############################
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:##############################
2021-07-09 16:38:17 INFO     sharding group size: 1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:sharding group size: 1
2021-07-09 16:38:17 INFO     sharding rank: -1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:sharding rank: -1
2021-07-09 16:38:17 INFO     sharding group id: -1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:sharding group id: -1
2021-07-09 16:38:17 INFO     sharding group endpoints: []
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:sharding group endpoints: []
2021-07-09 16:38:17 INFO     sharding ring id: -1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:sharding ring id: -1
2021-07-09 16:38:17 INFO     ##############################
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:##############################
2021-07-09 16:38:17 INFO     pp group size: 2
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pp group size: 2
2021-07-09 16:38:17 INFO     pp rank: 1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pp rank: 1
2021-07-09 16:38:17 INFO     pp group id: 0
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pp group id: 0
2021-07-09 16:38:17 INFO     pp group endpoints: ['192.168.206.27:6173', '192.168.206.27:6177']
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pp group endpoints: ['192.168.206.27:6173', '192.168.206.27:6177']
2021-07-09 16:38:17 INFO     pp ring id: 20
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pp ring id: 20
2021-07-09 16:38:17 INFO     ##############################
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:##############################
2021-07-09 16:38:17 INFO     pure dp group size: 1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pure dp group size: 1
2021-07-09 16:38:17 INFO     pure dp rank: -1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pure dp rank: -1
2021-07-09 16:38:17 INFO     pure dp group endpoints: []
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pure dp group endpoints: []
2021-07-09 16:38:17 INFO     pure dp ring id: -1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pure dp ring id: -1
2021-07-09 16:38:17 INFO     ##############################
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:##############################
pp pair:(0, 1), ring_id: 20
pp pair:(1, 0), ring_id: 21
I0709 16:38:35.834360 36129 gen_hccl_id_op_helper.cc:181] Server listening on: 192.168.206.27:6177 successful.
I0709 16:38:37.082315 36129 collective_helper_npu.cc:83] initialized comm: 0xffffcb9ee0b0, nranks: 8, hccl_id: 0x34149084, rank: 7
I0709 16:38:40.553503 36129 collective_helper_npu.cc:88] initialized comm: 0xffffcb9ee0b0, nranks: 8, hccl_id: 0x34149084, rank: 7
I0709 16:38:40.553649 36129 collective_helper_npu.cc:93] hccl communicator of rank 7 in ring 3 has been created on device 7, with comm: 0x34384910
I0709 16:38:42.949833 36129 gen_hccl_id_op_helper.cc:181] Server listening on: 192.168.206.27:6177 successful.
I0709 16:38:42.952044 36129 collective_helper_npu.cc:83] initialized comm: 0xffffcb9ee0b0, nranks: 4, hccl_id: 0x34349114, rank: 3
I0709 16:38:44.761849 36129 collective_helper_npu.cc:88] initialized comm: 0xffffcb9ee0b0, nranks: 4, hccl_id: 0x34349114, rank: 3
I0709 16:38:44.763275 36129 collective_helper_npu.cc:93] hccl communicator of rank 3 in ring 0 has been created on device 7, with comm: 0x342821c0
I0709 16:38:45.598031 36129 gen_hccl_id_op_helper.cc:181] Server listening on: 192.168.206.27:6177 successful.
I0709 16:38:45.599606 36129 collective_helper_npu.cc:83] initialized comm: 0xffffcb9ee0b0, nranks: 2, hccl_id: 0x34147034, rank: 1
I0709 16:38:46.817382 36129 collective_helper_npu.cc:88] initialized comm: 0xffffcb9ee0b0, nranks: 2, hccl_id: 0x34147034, rank: 1
I0709 16:38:46.817515 36129 collective_helper_npu.cc:93] hccl communicator of rank 1 in ring 20 has been created on device 7, with comm: 0x342a0590
I0709 16:38:47.175665 36129 collective_helper_npu.cc:83] initialized comm: 0xffffcb9ee0b0, nranks: 2, hccl_id: 0x3407be24, rank: 0
I0709 16:38:48.390331 36129 collective_helper_npu.cc:88] initialized comm: 0xffffcb9ee0b0, nranks: 2, hccl_id: 0x3407be24, rank: 0
I0709 16:38:48.391574 36129 collective_helper_npu.cc:93] hccl communicator of rank 0 in ring 21 has been created on device 7, with comm: 0x342b2620
Done broadcast
[INFO] 2021-07-09 16:38:48,774 [run_pretraining.py:  512]:	********exe.run_0******* 
I0709 16:38:51.487800 39348 lod_tensor_blocking_queue.h:104] Init queue with size 1
I0709 16:38:51.488013 39348 buffered_reader.cc:41] BufferedReader
[INFO] 2021-07-09 16:41:11,488 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:11,489 [run_pretraining.py:  534]:	loss/total_loss, 10.759207725524902, 1
[INFO] 2021-07-09 16:41:11,490 [run_pretraining.py:  535]:	loss/mlm_loss, 10.759207725524902, 1
[INFO] 2021-07-09 16:41:11,490 [run_pretraining.py:  536]:	lr/scheduled_lr, 0.0, 1
[INFO] 2021-07-09 16:41:11,490 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 1
[INFO] 2021-07-09 16:41:11,490 [run_pretraining.py:  558]:	worker_index: 7, step: 1, cost: 10.759208, mlm loss: 10.759208, speed: 0.007007 steps/s, speed: 0.056055 samples/s, speed: 28.700095 tokens/s, learning rate: 0.000e+00, loss_scalings: 32768.000000, pp_loss: 10.783619
[INFO] 2021-07-09 16:41:11,490 [run_pretraining.py:  512]:	********exe.run_1******* 
[INFO] 2021-07-09 16:41:16,695 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:16,696 [run_pretraining.py:  534]:	loss/total_loss, 10.747819900512695, 2
[INFO] 2021-07-09 16:41:16,696 [run_pretraining.py:  535]:	loss/mlm_loss, 10.747819900512695, 2
[INFO] 2021-07-09 16:41:16,696 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.99999905104687e-09, 2
[INFO] 2021-07-09 16:41:16,696 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 2
[INFO] 2021-07-09 16:41:16,696 [run_pretraining.py:  558]:	worker_index: 7, step: 2, cost: 10.747820, mlm loss: 10.747820, speed: 0.192106 steps/s, speed: 1.536851 samples/s, speed: 786.867889 tokens/s, learning rate: 1.000e-08, loss_scalings: 32768.000000, pp_loss: 10.763246
[INFO] 2021-07-09 16:41:16,696 [run_pretraining.py:  512]:	********exe.run_2******* 
[INFO] 2021-07-09 16:41:18,811 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:18,811 [run_pretraining.py:  534]:	loss/total_loss, 10.758886337280273, 3
[INFO] 2021-07-09 16:41:18,811 [run_pretraining.py:  535]:	loss/mlm_loss, 10.758886337280273, 3
[INFO] 2021-07-09 16:41:18,811 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.999999810209374e-08, 3
[INFO] 2021-07-09 16:41:18,811 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 3
[INFO] 2021-07-09 16:41:18,812 [run_pretraining.py:  558]:	worker_index: 7, step: 3, cost: 10.758886, mlm loss: 10.758886, speed: 0.472848 steps/s, speed: 3.782782 samples/s, speed: 1936.784276 tokens/s, learning rate: 2.000e-08, loss_scalings: 32768.000000, pp_loss: 10.764178
[INFO] 2021-07-09 16:41:18,812 [run_pretraining.py:  512]:	********exe.run_3******* 
[INFO] 2021-07-09 16:41:20,925 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:20,926 [run_pretraining.py:  534]:	loss/total_loss, 10.799854278564453, 4
[INFO] 2021-07-09 16:41:20,926 [run_pretraining.py:  535]:	loss/mlm_loss, 10.799854278564453, 4
[INFO] 2021-07-09 16:41:20,926 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.999999892949745e-08, 4
[INFO] 2021-07-09 16:41:20,926 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 4
[INFO] 2021-07-09 16:41:20,926 [run_pretraining.py:  558]:	worker_index: 7, step: 4, cost: 10.799854, mlm loss: 10.799854, speed: 0.472993 steps/s, speed: 3.783944 samples/s, speed: 1937.379230 tokens/s, learning rate: 3.000e-08, loss_scalings: 32768.000000, pp_loss: 10.799068
[INFO] 2021-07-09 16:41:20,926 [run_pretraining.py:  512]:	********exe.run_4******* 
[INFO] 2021-07-09 16:41:23,053 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:23,053 [run_pretraining.py:  534]:	loss/total_loss, 10.761637687683105, 5
[INFO] 2021-07-09 16:41:23,053 [run_pretraining.py:  535]:	loss/mlm_loss, 10.761637687683105, 5
[INFO] 2021-07-09 16:41:23,054 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.999999620418748e-08, 5
[INFO] 2021-07-09 16:41:23,054 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 5
[INFO] 2021-07-09 16:41:23,054 [run_pretraining.py:  558]:	worker_index: 7, step: 5, cost: 10.761638, mlm loss: 10.761638, speed: 0.470236 steps/s, speed: 3.761889 samples/s, speed: 1926.087369 tokens/s, learning rate: 4.000e-08, loss_scalings: 32768.000000, pp_loss: 10.741164
[INFO] 2021-07-09 16:41:23,054 [run_pretraining.py:  512]:	********exe.run_5******* 
[INFO] 2021-07-09 16:41:25,222 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:25,223 [run_pretraining.py:  534]:	loss/total_loss, 10.739306449890137, 6
[INFO] 2021-07-09 16:41:25,223 [run_pretraining.py:  535]:	loss/mlm_loss, 10.739306449890137, 6
[INFO] 2021-07-09 16:41:25,223 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.000000058430487e-08, 6
[INFO] 2021-07-09 16:41:25,223 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 6
[INFO] 2021-07-09 16:41:25,223 [run_pretraining.py:  558]:	worker_index: 7, step: 6, cost: 10.739306, mlm loss: 10.739306, speed: 0.461127 steps/s, speed: 3.689016 samples/s, speed: 1888.776305 tokens/s, learning rate: 5.000e-08, loss_scalings: 32768.000000, pp_loss: 10.767538
[INFO] 2021-07-09 16:41:25,223 [run_pretraining.py:  512]:	********exe.run_6******* 
[INFO] 2021-07-09 16:41:27,422 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:27,423 [run_pretraining.py:  534]:	loss/total_loss, 10.74216079711914, 7
[INFO] 2021-07-09 16:41:27,423 [run_pretraining.py:  535]:	loss/mlm_loss, 10.74216079711914, 7
[INFO] 2021-07-09 16:41:27,423 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.99999978589949e-08, 7
[INFO] 2021-07-09 16:41:27,423 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 7
[INFO] 2021-07-09 16:41:27,423 [run_pretraining.py:  558]:	worker_index: 7, step: 7, cost: 10.742161, mlm loss: 10.742161, speed: 0.454658 steps/s, speed: 3.637266 samples/s, speed: 1862.280106 tokens/s, learning rate: 6.000e-08, loss_scalings: 32768.000000, pp_loss: 10.736015
[INFO] 2021-07-09 16:41:27,423 [run_pretraining.py:  512]:	********exe.run_7******* 
[INFO] 2021-07-09 16:41:29,624 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:29,625 [run_pretraining.py:  534]:	loss/total_loss, 10.702466011047363, 8
[INFO] 2021-07-09 16:41:29,625 [run_pretraining.py:  535]:	loss/mlm_loss, 10.702466011047363, 8
[INFO] 2021-07-09 16:41:29,625 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.999999868639861e-08, 8
[INFO] 2021-07-09 16:41:29,625 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 8
[INFO] 2021-07-09 16:41:29,625 [run_pretraining.py:  558]:	worker_index: 7, step: 8, cost: 10.702466, mlm loss: 10.702466, speed: 0.454213 steps/s, speed: 3.633702 samples/s, speed: 1860.455584 tokens/s, learning rate: 7.000e-08, loss_scalings: 32768.000000, pp_loss: 10.782497
[INFO] 2021-07-09 16:41:29,625 [run_pretraining.py:  512]:	********exe.run_8******* 
[INFO] 2021-07-09 16:41:31,794 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:31,794 [run_pretraining.py:  534]:	loss/total_loss, 10.78136157989502, 9
[INFO] 2021-07-09 16:41:31,794 [run_pretraining.py:  535]:	loss/mlm_loss, 10.78136157989502, 9
[INFO] 2021-07-09 16:41:31,794 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.999999240837496e-08, 9
[INFO] 2021-07-09 16:41:31,794 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 9
[INFO] 2021-07-09 16:41:31,794 [run_pretraining.py:  558]:	worker_index: 7, step: 9, cost: 10.781362, mlm loss: 10.781362, speed: 0.461155 steps/s, speed: 3.689244 samples/s, speed: 1888.892806 tokens/s, learning rate: 8.000e-08, loss_scalings: 32768.000000, pp_loss: 10.781145
[INFO] 2021-07-09 16:41:31,794 [run_pretraining.py:  512]:	********exe.run_9******* 
[INFO] 2021-07-09 16:41:33,978 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:33,979 [run_pretraining.py:  534]:	loss/total_loss, 10.746038436889648, 10
[INFO] 2021-07-09 16:41:33,979 [run_pretraining.py:  535]:	loss/mlm_loss, 10.746038436889648, 10
[INFO] 2021-07-09 16:41:33,979 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.999999323577867e-08, 10
[INFO] 2021-07-09 16:41:33,979 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 10
[INFO] 2021-07-09 16:41:33,979 [run_pretraining.py:  558]:	worker_index: 7, step: 10, cost: 10.746038, mlm loss: 10.746038, speed: 0.457876 steps/s, speed: 3.663009 samples/s, speed: 1875.460729 tokens/s, learning rate: 9.000e-08, loss_scalings: 32768.000000, pp_loss: 10.743856
[INFO] 2021-07-09 16:41:33,979 [run_pretraining.py:  512]:	********exe.run_10******* 
[INFO] 2021-07-09 16:41:36,161 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:36,161 [run_pretraining.py:  534]:	loss/total_loss, 10.772452354431152, 11
[INFO] 2021-07-09 16:41:36,161 [run_pretraining.py:  535]:	loss/mlm_loss, 10.772452354431152, 11
[INFO] 2021-07-09 16:41:36,162 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0000000116860974e-07, 11
[INFO] 2021-07-09 16:41:36,162 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 11
[INFO] 2021-07-09 16:41:36,162 [run_pretraining.py:  558]:	worker_index: 7, step: 11, cost: 10.772452, mlm loss: 10.772452, speed: 0.458296 steps/s, speed: 3.666365 samples/s, speed: 1877.179020 tokens/s, learning rate: 1.000e-07, loss_scalings: 32768.000000, pp_loss: 10.766082
[INFO] 2021-07-09 16:41:36,162 [run_pretraining.py:  512]:	********exe.run_11******* 
[INFO] 2021-07-09 16:41:38,365 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:38,366 [run_pretraining.py:  534]:	loss/total_loss, 10.764888763427734, 12
[INFO] 2021-07-09 16:41:38,366 [run_pretraining.py:  535]:	loss/mlm_loss, 10.764888763427734, 12
[INFO] 2021-07-09 16:41:38,366 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.099999948905861e-07, 12
[INFO] 2021-07-09 16:41:38,366 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 12
[INFO] 2021-07-09 16:41:38,366 [run_pretraining.py:  558]:	worker_index: 7, step: 12, cost: 10.764889, mlm loss: 10.764889, speed: 0.453725 steps/s, speed: 3.629804 samples/s, speed: 1858.459510 tokens/s, learning rate: 1.100e-07, loss_scalings: 32768.000000, pp_loss: 10.738869
[INFO] 2021-07-09 16:41:38,366 [run_pretraining.py:  512]:	********exe.run_12******* 
[INFO] 2021-07-09 16:41:41,095 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:41,096 [run_pretraining.py:  534]:	loss/total_loss, 10.730729103088379, 13
[INFO] 2021-07-09 16:41:41,096 [run_pretraining.py:  535]:	loss/mlm_loss, 10.730729103088379, 13
[INFO] 2021-07-09 16:41:41,096 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.199999957179898e-07, 13
[INFO] 2021-07-09 16:41:41,096 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 13
[INFO] 2021-07-09 16:41:41,096 [run_pretraining.py:  558]:	worker_index: 7, step: 13, cost: 10.730729, mlm loss: 10.730729, speed: 0.366442 steps/s, speed: 2.931535 samples/s, speed: 1500.945803 tokens/s, learning rate: 1.200e-07, loss_scalings: 26214.400391, pp_loss: 10.783990
[INFO] 2021-07-09 16:41:41,096 [run_pretraining.py:  512]:	********exe.run_13******* 
[INFO] 2021-07-09 16:41:43,394 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:43,394 [run_pretraining.py:  534]:	loss/total_loss, 10.868694305419922, 14
[INFO] 2021-07-09 16:41:43,394 [run_pretraining.py:  535]:	loss/mlm_loss, 10.868694305419922, 14
[INFO] 2021-07-09 16:41:43,394 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3000000365082087e-07, 14
[INFO] 2021-07-09 16:41:43,394 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 14
[INFO] 2021-07-09 16:41:43,395 [run_pretraining.py:  558]:	worker_index: 7, step: 14, cost: 10.868694, mlm loss: 10.868694, speed: 0.435182 steps/s, speed: 3.481455 samples/s, speed: 1782.505045 tokens/s, learning rate: 1.300e-07, loss_scalings: 26214.400391, pp_loss: 10.760899
[INFO] 2021-07-09 16:41:43,395 [run_pretraining.py:  512]:	********exe.run_14******* 
[INFO] 2021-07-09 16:41:45,642 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:45,643 [run_pretraining.py:  534]:	loss/total_loss, 10.796741485595703, 15
[INFO] 2021-07-09 16:41:45,643 [run_pretraining.py:  535]:	loss/mlm_loss, 10.796741485595703, 15
[INFO] 2021-07-09 16:41:45,643 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3999999737279722e-07, 15
[INFO] 2021-07-09 16:41:45,643 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 15
[INFO] 2021-07-09 16:41:45,643 [run_pretraining.py:  558]:	worker_index: 7, step: 15, cost: 10.796741, mlm loss: 10.796741, speed: 0.444891 steps/s, speed: 3.559128 samples/s, speed: 1822.273441 tokens/s, learning rate: 1.400e-07, loss_scalings: 26214.400391, pp_loss: 10.742632
[INFO] 2021-07-09 16:41:45,643 [run_pretraining.py:  512]:	********exe.run_15******* 
[INFO] 2021-07-09 16:41:47,879 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:47,880 [run_pretraining.py:  534]:	loss/total_loss, 10.761933326721191, 16
[INFO] 2021-07-09 16:41:47,880 [run_pretraining.py:  535]:	loss/mlm_loss, 10.761933326721191, 16
[INFO] 2021-07-09 16:41:47,880 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4999999109477358e-07, 16
[INFO] 2021-07-09 16:41:47,880 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 16
[INFO] 2021-07-09 16:41:47,880 [run_pretraining.py:  558]:	worker_index: 7, step: 16, cost: 10.761933, mlm loss: 10.761933, speed: 0.447098 steps/s, speed: 3.576782 samples/s, speed: 1831.312179 tokens/s, learning rate: 1.500e-07, loss_scalings: 26214.400391, pp_loss: 10.699523
[INFO] 2021-07-09 16:41:47,880 [run_pretraining.py:  512]:	********exe.run_16******* 
[INFO] 2021-07-09 16:41:50,214 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:50,214 [run_pretraining.py:  534]:	loss/total_loss, 10.81010913848877, 17
[INFO] 2021-07-09 16:41:50,215 [run_pretraining.py:  535]:	loss/mlm_loss, 10.81010913848877, 17
[INFO] 2021-07-09 16:41:50,215 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5999998481674993e-07, 17
[INFO] 2021-07-09 16:41:50,215 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 17
[INFO] 2021-07-09 16:41:50,215 [run_pretraining.py:  558]:	worker_index: 7, step: 17, cost: 10.810109, mlm loss: 10.810109, speed: 0.428444 steps/s, speed: 3.427551 samples/s, speed: 1754.906286 tokens/s, learning rate: 1.600e-07, loss_scalings: 26214.400391, pp_loss: 10.744966
[INFO] 2021-07-09 16:41:50,215 [run_pretraining.py:  512]:	********exe.run_17******* 
[INFO] 2021-07-09 16:41:52,448 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:52,449 [run_pretraining.py:  534]:	loss/total_loss, 10.734519004821777, 18
[INFO] 2021-07-09 16:41:52,449 [run_pretraining.py:  535]:	loss/mlm_loss, 10.734519004821777, 18
[INFO] 2021-07-09 16:41:52,449 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.69999992749581e-07, 18
[INFO] 2021-07-09 16:41:52,449 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 18
[INFO] 2021-07-09 16:41:52,449 [run_pretraining.py:  558]:	worker_index: 7, step: 18, cost: 10.734519, mlm loss: 10.734519, speed: 0.447726 steps/s, speed: 3.581808 samples/s, speed: 1833.885943 tokens/s, learning rate: 1.700e-07, loss_scalings: 26214.400391, pp_loss: 10.708960
[INFO] 2021-07-09 16:41:52,449 [run_pretraining.py:  512]:	********exe.run_18******* 
[INFO] 2021-07-09 16:41:54,738 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:54,738 [run_pretraining.py:  534]:	loss/total_loss, 10.698297500610352, 19
[INFO] 2021-07-09 16:41:54,738 [run_pretraining.py:  535]:	loss/mlm_loss, 10.698297500610352, 19
[INFO] 2021-07-09 16:41:54,738 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7999998647155735e-07, 19
[INFO] 2021-07-09 16:41:54,738 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 19
[INFO] 2021-07-09 16:41:54,738 [run_pretraining.py:  558]:	worker_index: 7, step: 19, cost: 10.698298, mlm loss: 10.698298, speed: 0.436907 steps/s, speed: 3.495253 samples/s, speed: 1789.569707 tokens/s, learning rate: 1.800e-07, loss_scalings: 26214.400391, pp_loss: 10.721475
[INFO] 2021-07-09 16:41:54,739 [run_pretraining.py:  512]:	********exe.run_19******* 
[INFO] 2021-07-09 16:41:57,029 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:57,030 [run_pretraining.py:  534]:	loss/total_loss, 10.665203094482422, 20
[INFO] 2021-07-09 16:41:57,030 [run_pretraining.py:  535]:	loss/mlm_loss, 10.665203094482422, 20
[INFO] 2021-07-09 16:41:57,030 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8999999440438842e-07, 20
[INFO] 2021-07-09 16:41:57,030 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 20
[INFO] 2021-07-09 16:41:57,030 [run_pretraining.py:  558]:	worker_index: 7, step: 20, cost: 10.665203, mlm loss: 10.665203, speed: 0.436519 steps/s, speed: 3.492154 samples/s, speed: 1787.983058 tokens/s, learning rate: 1.900e-07, loss_scalings: 26214.400391, pp_loss: 10.712017
[INFO] 2021-07-09 16:41:57,030 [run_pretraining.py:  512]:	********exe.run_20******* 
[INFO] 2021-07-09 16:41:59,304 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:59,304 [run_pretraining.py:  534]:	loss/total_loss, 10.736427307128906, 21
[INFO] 2021-07-09 16:41:59,305 [run_pretraining.py:  535]:	loss/mlm_loss, 10.736427307128906, 21
[INFO] 2021-07-09 16:41:59,305 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0000000233721948e-07, 21
[INFO] 2021-07-09 16:41:59,305 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 21
[INFO] 2021-07-09 16:41:59,305 [run_pretraining.py:  558]:	worker_index: 7, step: 21, cost: 10.736427, mlm loss: 10.736427, speed: 0.439696 steps/s, speed: 3.517569 samples/s, speed: 1800.995334 tokens/s, learning rate: 2.000e-07, loss_scalings: 26214.400391, pp_loss: 10.726251
[INFO] 2021-07-09 16:41:59,305 [run_pretraining.py:  512]:	********exe.run_21******* 
[INFO] 2021-07-09 16:42:01,597 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:01,597 [run_pretraining.py:  534]:	loss/total_loss, 10.737780570983887, 22
[INFO] 2021-07-09 16:42:01,597 [run_pretraining.py:  535]:	loss/mlm_loss, 10.737780570983887, 22
[INFO] 2021-07-09 16:42:01,597 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0999998184834112e-07, 22
[INFO] 2021-07-09 16:42:01,597 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 22
[INFO] 2021-07-09 16:42:01,598 [run_pretraining.py:  558]:	worker_index: 7, step: 22, cost: 10.737781, mlm loss: 10.737781, speed: 0.436294 steps/s, speed: 3.490354 samples/s, speed: 1787.061306 tokens/s, learning rate: 2.100e-07, loss_scalings: 26214.400391, pp_loss: 10.679643
[INFO] 2021-07-09 16:42:01,598 [run_pretraining.py:  512]:	********exe.run_22******* 
[INFO] 2021-07-09 16:42:03,810 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:03,811 [run_pretraining.py:  534]:	loss/total_loss, 10.72257137298584, 23
[INFO] 2021-07-09 16:42:03,811 [run_pretraining.py:  535]:	loss/mlm_loss, 10.72257137298584, 23
[INFO] 2021-07-09 16:42:03,811 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.199999897811722e-07, 23
[INFO] 2021-07-09 16:42:03,811 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 23
[INFO] 2021-07-09 16:42:03,811 [run_pretraining.py:  558]:	worker_index: 7, step: 23, cost: 10.722571, mlm loss: 10.722571, speed: 0.451862 steps/s, speed: 3.614897 samples/s, speed: 1850.827070 tokens/s, learning rate: 2.200e-07, loss_scalings: 26214.400391, pp_loss: 10.693195
[INFO] 2021-07-09 16:42:03,811 [run_pretraining.py:  512]:	********exe.run_23******* 
[INFO] 2021-07-09 16:42:06,000 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:06,000 [run_pretraining.py:  534]:	loss/total_loss, 10.576932907104492, 24
[INFO] 2021-07-09 16:42:06,001 [run_pretraining.py:  535]:	loss/mlm_loss, 10.576932907104492, 24
[INFO] 2021-07-09 16:42:06,001 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2999999771400326e-07, 24
[INFO] 2021-07-09 16:42:06,001 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 24
[INFO] 2021-07-09 16:42:06,001 [run_pretraining.py:  558]:	worker_index: 7, step: 24, cost: 10.576933, mlm loss: 10.576933, speed: 0.456893 steps/s, speed: 3.655142 samples/s, speed: 1871.432806 tokens/s, learning rate: 2.300e-07, loss_scalings: 26214.400391, pp_loss: 10.662045
[INFO] 2021-07-09 16:42:06,001 [run_pretraining.py:  512]:	********exe.run_24******* 
[INFO] 2021-07-09 16:42:08,200 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:08,201 [run_pretraining.py:  534]:	loss/total_loss, 10.73106575012207, 25
[INFO] 2021-07-09 16:42:08,201 [run_pretraining.py:  535]:	loss/mlm_loss, 10.73106575012207, 25
[INFO] 2021-07-09 16:42:08,201 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.399999914359796e-07, 25
[INFO] 2021-07-09 16:42:08,201 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 25
[INFO] 2021-07-09 16:42:08,201 [run_pretraining.py:  558]:	worker_index: 7, step: 25, cost: 10.731066, mlm loss: 10.731066, speed: 0.454618 steps/s, speed: 3.636943 samples/s, speed: 1862.114789 tokens/s, learning rate: 2.400e-07, loss_scalings: 26214.400391, pp_loss: 10.689995
[INFO] 2021-07-09 16:42:08,201 [run_pretraining.py:  512]:	********exe.run_25******* 
[INFO] 2021-07-09 16:42:10,488 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:10,489 [run_pretraining.py:  534]:	loss/total_loss, 10.526437759399414, 26
[INFO] 2021-07-09 16:42:10,489 [run_pretraining.py:  535]:	loss/mlm_loss, 10.526437759399414, 26
[INFO] 2021-07-09 16:42:10,489 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.499999993688107e-07, 26
[INFO] 2021-07-09 16:42:10,489 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 26
[INFO] 2021-07-09 16:42:10,489 [run_pretraining.py:  558]:	worker_index: 7, step: 26, cost: 10.526438, mlm loss: 10.526438, speed: 0.437173 steps/s, speed: 3.497384 samples/s, speed: 1790.660517 tokens/s, learning rate: 2.500e-07, loss_scalings: 26214.400391, pp_loss: 10.595887
[INFO] 2021-07-09 16:42:10,489 [run_pretraining.py:  512]:	********exe.run_26******* 
[INFO] 2021-07-09 16:42:12,724 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:12,724 [run_pretraining.py:  534]:	loss/total_loss, 10.64441967010498, 27
[INFO] 2021-07-09 16:42:12,724 [run_pretraining.py:  535]:	loss/mlm_loss, 10.64441967010498, 27
[INFO] 2021-07-09 16:42:12,724 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6000000730164174e-07, 27
[INFO] 2021-07-09 16:42:12,724 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 27
[INFO] 2021-07-09 16:42:12,724 [run_pretraining.py:  558]:	worker_index: 7, step: 27, cost: 10.644420, mlm loss: 10.644420, speed: 0.447524 steps/s, speed: 3.580195 samples/s, speed: 1833.060010 tokens/s, learning rate: 2.600e-07, loss_scalings: 26214.400391, pp_loss: 10.601724
[INFO] 2021-07-09 16:42:12,725 [run_pretraining.py:  512]:	********exe.run_27******* 
[INFO] 2021-07-09 16:42:14,994 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:14,995 [run_pretraining.py:  534]:	loss/total_loss, 10.719066619873047, 28
[INFO] 2021-07-09 16:42:14,995 [run_pretraining.py:  535]:	loss/mlm_loss, 10.719066619873047, 28
[INFO] 2021-07-09 16:42:14,995 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.699999868127634e-07, 28
[INFO] 2021-07-09 16:42:14,995 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 28
[INFO] 2021-07-09 16:42:14,995 [run_pretraining.py:  558]:	worker_index: 7, step: 28, cost: 10.719067, mlm loss: 10.719067, speed: 0.440529 steps/s, speed: 3.524229 samples/s, speed: 1804.405491 tokens/s, learning rate: 2.700e-07, loss_scalings: 26214.400391, pp_loss: 10.638918
[INFO] 2021-07-09 16:42:14,995 [run_pretraining.py:  512]:	********exe.run_28******* 
[INFO] 2021-07-09 16:42:17,315 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:17,316 [run_pretraining.py:  534]:	loss/total_loss, 10.604846954345703, 29
[INFO] 2021-07-09 16:42:17,316 [run_pretraining.py:  535]:	loss/mlm_loss, 10.604846954345703, 29
[INFO] 2021-07-09 16:42:17,316 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7999999474559445e-07, 29
[INFO] 2021-07-09 16:42:17,316 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 29
[INFO] 2021-07-09 16:42:17,316 [run_pretraining.py:  558]:	worker_index: 7, step: 29, cost: 10.604847, mlm loss: 10.604847, speed: 0.430939 steps/s, speed: 3.447515 samples/s, speed: 1765.127834 tokens/s, learning rate: 2.800e-07, loss_scalings: 26214.400391, pp_loss: 10.606615
[INFO] 2021-07-09 16:42:17,316 [run_pretraining.py:  512]:	********exe.run_29******* 
[INFO] 2021-07-09 16:42:19,517 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:19,517 [run_pretraining.py:  534]:	loss/total_loss, 10.523250579833984, 30
[INFO] 2021-07-09 16:42:19,517 [run_pretraining.py:  535]:	loss/mlm_loss, 10.523250579833984, 30
[INFO] 2021-07-09 16:42:19,518 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.900000026784255e-07, 30
[INFO] 2021-07-09 16:42:19,518 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 30
[INFO] 2021-07-09 16:42:19,518 [run_pretraining.py:  558]:	worker_index: 7, step: 30, cost: 10.523251, mlm loss: 10.523251, speed: 0.454370 steps/s, speed: 3.634956 samples/s, speed: 1861.097500 tokens/s, learning rate: 2.900e-07, loss_scalings: 26214.400391, pp_loss: 10.596039
[INFO] 2021-07-09 16:42:19,518 [run_pretraining.py:  512]:	********exe.run_30******* 
[INFO] 2021-07-09 16:42:21,720 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:21,721 [run_pretraining.py:  534]:	loss/total_loss, 10.599813461303711, 31
[INFO] 2021-07-09 16:42:21,721 [run_pretraining.py:  535]:	loss/mlm_loss, 10.599813461303711, 31
[INFO] 2021-07-09 16:42:21,721 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9999998218954715e-07, 31
[INFO] 2021-07-09 16:42:21,721 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 31
[INFO] 2021-07-09 16:42:21,721 [run_pretraining.py:  558]:	worker_index: 7, step: 31, cost: 10.599813, mlm loss: 10.599813, speed: 0.453960 steps/s, speed: 3.631678 samples/s, speed: 1859.418974 tokens/s, learning rate: 3.000e-07, loss_scalings: 26214.400391, pp_loss: 10.597894
[INFO] 2021-07-09 16:42:21,721 [run_pretraining.py:  512]:	********exe.run_31******* 
[INFO] 2021-07-09 16:42:23,907 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:23,907 [run_pretraining.py:  534]:	loss/total_loss, 10.61822509765625, 32
[INFO] 2021-07-09 16:42:23,907 [run_pretraining.py:  535]:	loss/mlm_loss, 10.61822509765625, 32
[INFO] 2021-07-09 16:42:23,907 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.099999901223782e-07, 32
[INFO] 2021-07-09 16:42:23,908 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 32
[INFO] 2021-07-09 16:42:23,908 [run_pretraining.py:  558]:	worker_index: 7, step: 32, cost: 10.618225, mlm loss: 10.618225, speed: 0.457513 steps/s, speed: 3.660106 samples/s, speed: 1873.974494 tokens/s, learning rate: 3.100e-07, loss_scalings: 26214.400391, pp_loss: 10.570961
[INFO] 2021-07-09 16:42:23,908 [run_pretraining.py:  512]:	********exe.run_32******* 
[INFO] 2021-07-09 16:42:26,119 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:26,119 [run_pretraining.py:  534]:	loss/total_loss, 10.51255989074707, 33
[INFO] 2021-07-09 16:42:26,120 [run_pretraining.py:  535]:	loss/mlm_loss, 10.51255989074707, 33
[INFO] 2021-07-09 16:42:26,120 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.1999996963349986e-07, 33
[INFO] 2021-07-09 16:42:26,120 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 33
[INFO] 2021-07-09 16:42:26,120 [run_pretraining.py:  558]:	worker_index: 7, step: 33, cost: 10.512560, mlm loss: 10.512560, speed: 0.452172 steps/s, speed: 3.617376 samples/s, speed: 1852.096484 tokens/s, learning rate: 3.200e-07, loss_scalings: 26214.400391, pp_loss: 10.531687
[INFO] 2021-07-09 16:42:26,120 [run_pretraining.py:  512]:	********exe.run_33******* 
[INFO] 2021-07-09 16:42:28,332 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:28,332 [run_pretraining.py:  534]:	loss/total_loss, 10.455143928527832, 34
[INFO] 2021-07-09 16:42:28,332 [run_pretraining.py:  535]:	loss/mlm_loss, 10.455143928527832, 34
[INFO] 2021-07-09 16:42:28,332 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.2999997756633093e-07, 34
[INFO] 2021-07-09 16:42:28,332 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 34
[INFO] 2021-07-09 16:42:28,332 [run_pretraining.py:  558]:	worker_index: 7, step: 34, cost: 10.455144, mlm loss: 10.455144, speed: 0.452091 steps/s, speed: 3.616728 samples/s, speed: 1851.764496 tokens/s, learning rate: 3.300e-07, loss_scalings: 26214.400391, pp_loss: 10.507944
[INFO] 2021-07-09 16:42:28,332 [run_pretraining.py:  512]:	********exe.run_34******* 
[INFO] 2021-07-09 16:42:30,593 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:30,593 [run_pretraining.py:  534]:	loss/total_loss, 10.564741134643555, 35
[INFO] 2021-07-09 16:42:30,594 [run_pretraining.py:  535]:	loss/mlm_loss, 10.564741134643555, 35
[INFO] 2021-07-09 16:42:30,594 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.39999985499162e-07, 35
[INFO] 2021-07-09 16:42:30,594 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 35
[INFO] 2021-07-09 16:42:30,594 [run_pretraining.py:  558]:	worker_index: 7, step: 35, cost: 10.564741, mlm loss: 10.564741, speed: 0.442317 steps/s, speed: 3.538535 samples/s, speed: 1811.729995 tokens/s, learning rate: 3.400e-07, loss_scalings: 26214.400391, pp_loss: 10.465915
[INFO] 2021-07-09 16:42:30,594 [run_pretraining.py:  512]:	********exe.run_35******* 
[INFO] 2021-07-09 16:42:32,708 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:32,709 [run_pretraining.py:  534]:	loss/total_loss, 10.435295104980469, 36
[INFO] 2021-07-09 16:42:32,709 [run_pretraining.py:  535]:	loss/mlm_loss, 10.435295104980469, 36
[INFO] 2021-07-09 16:42:32,709 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.4999999343199306e-07, 36
[INFO] 2021-07-09 16:42:32,709 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 36
[INFO] 2021-07-09 16:42:32,709 [run_pretraining.py:  558]:	worker_index: 7, step: 36, cost: 10.435295, mlm loss: 10.435295, speed: 0.472874 steps/s, speed: 3.782989 samples/s, speed: 1936.890179 tokens/s, learning rate: 3.500e-07, loss_scalings: 26214.400391, pp_loss: 10.471941
[INFO] 2021-07-09 16:42:32,709 [run_pretraining.py:  512]:	********exe.run_36******* 
[INFO] 2021-07-09 16:42:34,812 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:34,812 [run_pretraining.py:  534]:	loss/total_loss, 10.521156311035156, 37
[INFO] 2021-07-09 16:42:34,813 [run_pretraining.py:  535]:	loss/mlm_loss, 10.521156311035156, 37
[INFO] 2021-07-09 16:42:34,813 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.599999729431147e-07, 37
[INFO] 2021-07-09 16:42:34,813 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 37
[INFO] 2021-07-09 16:42:34,813 [run_pretraining.py:  558]:	worker_index: 7, step: 37, cost: 10.521156, mlm loss: 10.521156, speed: 0.475514 steps/s, speed: 3.804116 samples/s, speed: 1947.707309 tokens/s, learning rate: 3.600e-07, loss_scalings: 26214.400391, pp_loss: 10.455115
[INFO] 2021-07-09 16:42:34,813 [run_pretraining.py:  512]:	********exe.run_37******* 
[INFO] 2021-07-09 16:42:36,886 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:36,886 [run_pretraining.py:  534]:	loss/total_loss, 10.385108947753906, 38
[INFO] 2021-07-09 16:42:36,886 [run_pretraining.py:  535]:	loss/mlm_loss, 10.385108947753906, 38
[INFO] 2021-07-09 16:42:36,887 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.6999998087594577e-07, 38
[INFO] 2021-07-09 16:42:36,887 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 38
[INFO] 2021-07-09 16:42:36,887 [run_pretraining.py:  558]:	worker_index: 7, step: 38, cost: 10.385109, mlm loss: 10.385109, speed: 0.482334 steps/s, speed: 3.858675 samples/s, speed: 1975.641601 tokens/s, learning rate: 3.700e-07, loss_scalings: 26214.400391, pp_loss: 10.421440
[INFO] 2021-07-09 16:42:36,887 [run_pretraining.py:  512]:	********exe.run_38******* 
[INFO] 2021-07-09 16:42:38,999 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:38,999 [run_pretraining.py:  534]:	loss/total_loss, 10.523965835571289, 39
[INFO] 2021-07-09 16:42:39,000 [run_pretraining.py:  535]:	loss/mlm_loss, 10.523965835571289, 39
[INFO] 2021-07-09 16:42:39,000 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.7999998880877683e-07, 39
[INFO] 2021-07-09 16:42:39,000 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 39
[INFO] 2021-07-09 16:42:39,000 [run_pretraining.py:  558]:	worker_index: 7, step: 39, cost: 10.523966, mlm loss: 10.523966, speed: 0.473395 steps/s, speed: 3.787162 samples/s, speed: 1939.026868 tokens/s, learning rate: 3.800e-07, loss_scalings: 26214.400391, pp_loss: 10.441567
[INFO] 2021-07-09 16:42:39,000 [run_pretraining.py:  512]:	********exe.run_39******* 
[INFO] 2021-07-09 16:42:41,051 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:41,052 [run_pretraining.py:  534]:	loss/total_loss, 10.389350891113281, 40
[INFO] 2021-07-09 16:42:41,052 [run_pretraining.py:  535]:	loss/mlm_loss, 10.389350891113281, 40
[INFO] 2021-07-09 16:42:41,052 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.8999996831989847e-07, 40
[INFO] 2021-07-09 16:42:41,052 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 40
[INFO] 2021-07-09 16:42:41,052 [run_pretraining.py:  558]:	worker_index: 7, step: 40, cost: 10.389351, mlm loss: 10.389351, speed: 0.487394 steps/s, speed: 3.899154 samples/s, speed: 1996.366676 tokens/s, learning rate: 3.900e-07, loss_scalings: 26214.400391, pp_loss: 10.403962
[INFO] 2021-07-09 16:42:41,052 [run_pretraining.py:  512]:	********exe.run_40******* 
[INFO] 2021-07-09 16:42:43,126 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:43,127 [run_pretraining.py:  534]:	loss/total_loss, 10.432123184204102, 41
[INFO] 2021-07-09 16:42:43,127 [run_pretraining.py:  535]:	loss/mlm_loss, 10.432123184204102, 41
[INFO] 2021-07-09 16:42:43,127 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.0000000467443897e-07, 41
[INFO] 2021-07-09 16:42:43,127 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 41
[INFO] 2021-07-09 16:42:43,127 [run_pretraining.py:  558]:	worker_index: 7, step: 41, cost: 10.432123, mlm loss: 10.432123, speed: 0.482130 steps/s, speed: 3.857043 samples/s, speed: 1974.805881 tokens/s, learning rate: 4.000e-07, loss_scalings: 26214.400391, pp_loss: 10.394256
[INFO] 2021-07-09 16:42:43,127 [run_pretraining.py:  512]:	********exe.run_41******* 
[INFO] 2021-07-09 16:42:45,205 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:45,205 [run_pretraining.py:  534]:	loss/total_loss, 10.416400909423828, 42
[INFO] 2021-07-09 16:42:45,205 [run_pretraining.py:  535]:	loss/mlm_loss, 10.416400909423828, 42
[INFO] 2021-07-09 16:42:45,205 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.099999841855606e-07, 42
[INFO] 2021-07-09 16:42:45,206 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 42
[INFO] 2021-07-09 16:42:45,206 [run_pretraining.py:  558]:	worker_index: 7, step: 42, cost: 10.416401, mlm loss: 10.416401, speed: 0.481216 steps/s, speed: 3.849727 samples/s, speed: 1971.060434 tokens/s, learning rate: 4.100e-07, loss_scalings: 26214.400391, pp_loss: 10.365210
[INFO] 2021-07-09 16:42:45,206 [run_pretraining.py:  512]:	********exe.run_42******* 
[INFO] 2021-07-09 16:42:47,301 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:47,301 [run_pretraining.py:  534]:	loss/total_loss, 10.35547161102295, 43
[INFO] 2021-07-09 16:42:47,302 [run_pretraining.py:  535]:	loss/mlm_loss, 10.35547161102295, 43
[INFO] 2021-07-09 16:42:47,302 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.1999996369668224e-07, 43
[INFO] 2021-07-09 16:42:47,302 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 43
[INFO] 2021-07-09 16:42:47,302 [run_pretraining.py:  558]:	worker_index: 7, step: 43, cost: 10.355472, mlm loss: 10.355472, speed: 0.477225 steps/s, speed: 3.817797 samples/s, speed: 1954.712136 tokens/s, learning rate: 4.200e-07, loss_scalings: 26214.400391, pp_loss: 10.321255
[INFO] 2021-07-09 16:42:47,302 [run_pretraining.py:  512]:	********exe.run_43******* 
[INFO] 2021-07-09 16:42:49,498 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:49,499 [run_pretraining.py:  534]:	loss/total_loss, 10.349892616271973, 44
[INFO] 2021-07-09 16:42:49,499 [run_pretraining.py:  535]:	loss/mlm_loss, 10.349892616271973, 44
[INFO] 2021-07-09 16:42:49,499 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.3000000005122274e-07, 44
[INFO] 2021-07-09 16:42:49,499 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 44
[INFO] 2021-07-09 16:42:49,499 [run_pretraining.py:  558]:	worker_index: 7, step: 44, cost: 10.349893, mlm loss: 10.349893, speed: 0.455233 steps/s, speed: 3.641861 samples/s, speed: 1864.633034 tokens/s, learning rate: 4.300e-07, loss_scalings: 26214.400391, pp_loss: 10.314773
[INFO] 2021-07-09 16:42:49,499 [run_pretraining.py:  512]:	********exe.run_44******* 
[INFO] 2021-07-09 16:42:51,672 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:51,673 [run_pretraining.py:  534]:	loss/total_loss, 10.273277282714844, 45
[INFO] 2021-07-09 16:42:51,673 [run_pretraining.py:  535]:	loss/mlm_loss, 10.273277282714844, 45
[INFO] 2021-07-09 16:42:51,673 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.399999795623444e-07, 45
[INFO] 2021-07-09 16:42:51,673 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 45
[INFO] 2021-07-09 16:42:51,673 [run_pretraining.py:  558]:	worker_index: 7, step: 45, cost: 10.273277, mlm loss: 10.273277, speed: 0.460082 steps/s, speed: 3.680658 samples/s, speed: 1884.496714 tokens/s, learning rate: 4.400e-07, loss_scalings: 26214.400391, pp_loss: 10.253038
[INFO] 2021-07-09 16:42:51,673 [run_pretraining.py:  512]:	********exe.run_45******* 
[INFO] 2021-07-09 16:42:53,857 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:53,858 [run_pretraining.py:  534]:	loss/total_loss, 10.20945930480957, 46
[INFO] 2021-07-09 16:42:53,858 [run_pretraining.py:  535]:	loss/mlm_loss, 10.20945930480957, 46
[INFO] 2021-07-09 16:42:53,858 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.49999959073466e-07, 46
[INFO] 2021-07-09 16:42:53,858 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 46
[INFO] 2021-07-09 16:42:53,858 [run_pretraining.py:  558]:	worker_index: 7, step: 46, cost: 10.209459, mlm loss: 10.209459, speed: 0.457791 steps/s, speed: 3.662328 samples/s, speed: 1875.111922 tokens/s, learning rate: 4.500e-07, loss_scalings: 26214.400391, pp_loss: 10.253660
[INFO] 2021-07-09 16:42:53,859 [run_pretraining.py:  512]:	********exe.run_46******* 
[INFO] 2021-07-09 16:42:56,100 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:56,100 [run_pretraining.py:  534]:	loss/total_loss, 10.263690948486328, 47
[INFO] 2021-07-09 16:42:56,101 [run_pretraining.py:  535]:	loss/mlm_loss, 10.263690948486328, 47
[INFO] 2021-07-09 16:42:56,101 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.599999954280065e-07, 47
[INFO] 2021-07-09 16:42:56,101 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 47
[INFO] 2021-07-09 16:42:56,101 [run_pretraining.py:  558]:	worker_index: 7, step: 47, cost: 10.263691, mlm loss: 10.263691, speed: 0.446072 steps/s, speed: 3.568572 samples/s, speed: 1827.108993 tokens/s, learning rate: 4.600e-07, loss_scalings: 26214.400391, pp_loss: 10.256334
[INFO] 2021-07-09 16:42:56,101 [run_pretraining.py:  512]:	********exe.run_47******* 
[INFO] 2021-07-09 16:42:58,371 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:58,372 [run_pretraining.py:  534]:	loss/total_loss, 10.174038887023926, 48
[INFO] 2021-07-09 16:42:58,372 [run_pretraining.py:  535]:	loss/mlm_loss, 10.174038887023926, 48
[INFO] 2021-07-09 16:42:58,372 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.6999997493912815e-07, 48
[INFO] 2021-07-09 16:42:58,372 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 48
[INFO] 2021-07-09 16:42:58,372 [run_pretraining.py:  558]:	worker_index: 7, step: 48, cost: 10.174039, mlm loss: 10.174039, speed: 0.440391 steps/s, speed: 3.523129 samples/s, speed: 1803.842043 tokens/s, learning rate: 4.700e-07, loss_scalings: 26214.400391, pp_loss: 10.201307
[INFO] 2021-07-09 16:42:58,372 [run_pretraining.py:  512]:	********exe.run_48******* 
[INFO] 2021-07-09 16:43:00,611 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:00,612 [run_pretraining.py:  534]:	loss/total_loss, 10.252628326416016, 49
[INFO] 2021-07-09 16:43:00,612 [run_pretraining.py:  535]:	loss/mlm_loss, 10.252628326416016, 49
[INFO] 2021-07-09 16:43:00,612 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.799999828719592e-07, 49
[INFO] 2021-07-09 16:43:00,612 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 49
[INFO] 2021-07-09 16:43:00,612 [run_pretraining.py:  558]:	worker_index: 7, step: 49, cost: 10.252628, mlm loss: 10.252628, speed: 0.446541 steps/s, speed: 3.572325 samples/s, speed: 1829.030467 tokens/s, learning rate: 4.800e-07, loss_scalings: 26214.400391, pp_loss: 10.190258
[INFO] 2021-07-09 16:43:00,612 [run_pretraining.py:  512]:	********exe.run_49******* 
[INFO] 2021-07-09 16:43:02,959 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:02,960 [run_pretraining.py:  534]:	loss/total_loss, 10.155471801757812, 50
[INFO] 2021-07-09 16:43:02,960 [run_pretraining.py:  535]:	loss/mlm_loss, 10.155471801757812, 50
[INFO] 2021-07-09 16:43:02,960 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.899999908047903e-07, 50
[INFO] 2021-07-09 16:43:02,960 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 50
[INFO] 2021-07-09 16:43:02,960 [run_pretraining.py:  558]:	worker_index: 7, step: 50, cost: 10.155472, mlm loss: 10.155472, speed: 0.426000 steps/s, speed: 3.407998 samples/s, speed: 1744.895121 tokens/s, learning rate: 4.900e-07, loss_scalings: 26214.400391, pp_loss: 10.135771
[INFO] 2021-07-09 16:43:02,960 [run_pretraining.py:  512]:	********exe.run_50******* 
[INFO] 2021-07-09 16:43:05,159 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:05,160 [run_pretraining.py:  534]:	loss/total_loss, 10.112833976745605, 51
[INFO] 2021-07-09 16:43:05,160 [run_pretraining.py:  535]:	loss/mlm_loss, 10.112833976745605, 51
[INFO] 2021-07-09 16:43:05,160 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.999999987376214e-07, 51
[INFO] 2021-07-09 16:43:05,160 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 51
[INFO] 2021-07-09 16:43:05,160 [run_pretraining.py:  558]:	worker_index: 7, step: 51, cost: 10.112834, mlm loss: 10.112834, speed: 0.454697 steps/s, speed: 3.637579 samples/s, speed: 1862.440605 tokens/s, learning rate: 5.000e-07, loss_scalings: 26214.400391, pp_loss: 10.143019
[INFO] 2021-07-09 16:43:05,160 [run_pretraining.py:  512]:	********exe.run_51******* 
[INFO] 2021-07-09 16:43:07,448 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:07,449 [run_pretraining.py:  534]:	loss/total_loss, 10.115421295166016, 52
[INFO] 2021-07-09 16:43:07,449 [run_pretraining.py:  535]:	loss/mlm_loss, 10.115421295166016, 52
[INFO] 2021-07-09 16:43:07,449 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.100000066704524e-07, 52
[INFO] 2021-07-09 16:43:07,449 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 52
[INFO] 2021-07-09 16:43:07,449 [run_pretraining.py:  558]:	worker_index: 7, step: 52, cost: 10.115421, mlm loss: 10.115421, speed: 0.436958 steps/s, speed: 3.495666 samples/s, speed: 1789.780752 tokens/s, learning rate: 5.100e-07, loss_scalings: 26214.400391, pp_loss: 10.090446
[INFO] 2021-07-09 16:43:07,450 [run_pretraining.py:  512]:	********exe.run_52******* 
[INFO] 2021-07-09 16:43:09,646 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:09,647 [run_pretraining.py:  534]:	loss/total_loss, 10.027713775634766, 53
[INFO] 2021-07-09 16:43:09,647 [run_pretraining.py:  535]:	loss/mlm_loss, 10.027713775634766, 53
[INFO] 2021-07-09 16:43:09,647 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.200000146032835e-07, 53
[INFO] 2021-07-09 16:43:09,647 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 53
[INFO] 2021-07-09 16:43:09,647 [run_pretraining.py:  558]:	worker_index: 7, step: 53, cost: 10.027714, mlm loss: 10.027714, speed: 0.455129 steps/s, speed: 3.641028 samples/s, speed: 1864.206516 tokens/s, learning rate: 5.200e-07, loss_scalings: 26214.400391, pp_loss: 10.059801
[INFO] 2021-07-09 16:43:09,647 [run_pretraining.py:  512]:	********exe.run_53******* 
[INFO] 2021-07-09 16:43:11,971 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:11,971 [run_pretraining.py:  534]:	loss/total_loss, 10.112442016601562, 54
[INFO] 2021-07-09 16:43:11,971 [run_pretraining.py:  535]:	loss/mlm_loss, 10.112442016601562, 54
[INFO] 2021-07-09 16:43:11,971 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.299999656926957e-07, 54
[INFO] 2021-07-09 16:43:11,971 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 54
[INFO] 2021-07-09 16:43:11,971 [run_pretraining.py:  558]:	worker_index: 7, step: 54, cost: 10.112442, mlm loss: 10.112442, speed: 0.430400 steps/s, speed: 3.443197 samples/s, speed: 1762.916792 tokens/s, learning rate: 5.300e-07, loss_scalings: 26214.400391, pp_loss: 10.074242
[INFO] 2021-07-09 16:43:11,971 [run_pretraining.py:  512]:	********exe.run_54******* 
[INFO] 2021-07-09 16:43:14,177 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:14,178 [run_pretraining.py:  534]:	loss/total_loss, 10.041437149047852, 55
[INFO] 2021-07-09 16:43:14,178 [run_pretraining.py:  535]:	loss/mlm_loss, 10.041437149047852, 55
[INFO] 2021-07-09 16:43:14,178 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.399999736255268e-07, 55
[INFO] 2021-07-09 16:43:14,178 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 55
[INFO] 2021-07-09 16:43:14,178 [run_pretraining.py:  558]:	worker_index: 7, step: 55, cost: 10.041437, mlm loss: 10.041437, speed: 0.453299 steps/s, speed: 3.626392 samples/s, speed: 1856.712492 tokens/s, learning rate: 5.400e-07, loss_scalings: 26214.400391, pp_loss: 10.012966
[INFO] 2021-07-09 16:43:14,178 [run_pretraining.py:  512]:	********exe.run_55******* 
[INFO] 2021-07-09 16:43:16,413 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:16,414 [run_pretraining.py:  534]:	loss/total_loss, 9.991291999816895, 56
[INFO] 2021-07-09 16:43:16,414 [run_pretraining.py:  535]:	loss/mlm_loss, 9.991291999816895, 56
[INFO] 2021-07-09 16:43:16,414 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.499999815583578e-07, 56
[INFO] 2021-07-09 16:43:16,414 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 56
[INFO] 2021-07-09 16:43:16,414 [run_pretraining.py:  558]:	worker_index: 7, step: 56, cost: 9.991292, mlm loss: 9.991292, speed: 0.447316 steps/s, speed: 3.578530 samples/s, speed: 1832.207465 tokens/s, learning rate: 5.500e-07, loss_scalings: 26214.400391, pp_loss: 9.973573
[INFO] 2021-07-09 16:43:16,414 [run_pretraining.py:  512]:	********exe.run_56******* 
[INFO] 2021-07-09 16:43:18,620 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:18,621 [run_pretraining.py:  534]:	loss/total_loss, 9.982471466064453, 57
[INFO] 2021-07-09 16:43:18,621 [run_pretraining.py:  535]:	loss/mlm_loss, 9.982471466064453, 57
[INFO] 2021-07-09 16:43:18,621 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.599999894911889e-07, 57
[INFO] 2021-07-09 16:43:18,621 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 57
[INFO] 2021-07-09 16:43:18,621 [run_pretraining.py:  558]:	worker_index: 7, step: 57, cost: 9.982471, mlm loss: 9.982471, speed: 0.453304 steps/s, speed: 3.626435 samples/s, speed: 1856.734565 tokens/s, learning rate: 5.600e-07, loss_scalings: 26214.400391, pp_loss: 9.958210
[INFO] 2021-07-09 16:43:18,621 [run_pretraining.py:  512]:	********exe.run_57******* 
[INFO] 2021-07-09 16:43:20,815 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:20,816 [run_pretraining.py:  534]:	loss/total_loss, 9.954161643981934, 58
[INFO] 2021-07-09 16:43:20,816 [run_pretraining.py:  535]:	loss/mlm_loss, 9.954161643981934, 58
[INFO] 2021-07-09 16:43:20,816 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.6999999742402e-07, 58
[INFO] 2021-07-09 16:43:20,816 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 58
[INFO] 2021-07-09 16:43:20,816 [run_pretraining.py:  558]:	worker_index: 7, step: 58, cost: 9.954162, mlm loss: 9.954162, speed: 0.455680 steps/s, speed: 3.645441 samples/s, speed: 1866.465966 tokens/s, learning rate: 5.700e-07, loss_scalings: 26214.400391, pp_loss: 9.911270
[INFO] 2021-07-09 16:43:20,816 [run_pretraining.py:  512]:	********exe.run_58******* 
[INFO] 2021-07-09 16:43:23,033 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:23,034 [run_pretraining.py:  534]:	loss/total_loss, 9.89819049835205, 59
[INFO] 2021-07-09 16:43:23,034 [run_pretraining.py:  535]:	loss/mlm_loss, 9.89819049835205, 59
[INFO] 2021-07-09 16:43:23,034 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.80000005356851e-07, 59
[INFO] 2021-07-09 16:43:23,034 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 59
[INFO] 2021-07-09 16:43:23,034 [run_pretraining.py:  558]:	worker_index: 7, step: 59, cost: 9.898190, mlm loss: 9.898190, speed: 0.451049 steps/s, speed: 3.608396 samples/s, speed: 1847.498603 tokens/s, learning rate: 5.800e-07, loss_scalings: 26214.400391, pp_loss: 9.872425
[INFO] 2021-07-09 16:43:23,034 [run_pretraining.py:  512]:	********exe.run_59******* 
[INFO] 2021-07-09 16:43:25,255 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:25,256 [run_pretraining.py:  534]:	loss/total_loss, 9.885345458984375, 60
[INFO] 2021-07-09 16:43:25,256 [run_pretraining.py:  535]:	loss/mlm_loss, 9.885345458984375, 60
[INFO] 2021-07-09 16:43:25,256 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.900000132896821e-07, 60
[INFO] 2021-07-09 16:43:25,256 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 60
[INFO] 2021-07-09 16:43:25,256 [run_pretraining.py:  558]:	worker_index: 7, step: 60, cost: 9.885345, mlm loss: 9.885345, speed: 0.450170 steps/s, speed: 3.601359 samples/s, speed: 1843.895675 tokens/s, learning rate: 5.900e-07, loss_scalings: 26214.400391, pp_loss: 9.836342
[INFO] 2021-07-09 16:43:25,256 [run_pretraining.py:  512]:	********exe.run_60******* 
[INFO] 2021-07-09 16:43:27,468 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:27,469 [run_pretraining.py:  534]:	loss/total_loss, 9.867347717285156, 61
[INFO] 2021-07-09 16:43:27,469 [run_pretraining.py:  535]:	loss/mlm_loss, 9.867347717285156, 61
[INFO] 2021-07-09 16:43:27,469 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.999999643790943e-07, 61
[INFO] 2021-07-09 16:43:27,469 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 61
[INFO] 2021-07-09 16:43:27,469 [run_pretraining.py:  558]:	worker_index: 7, step: 61, cost: 9.867348, mlm loss: 9.867348, speed: 0.452010 steps/s, speed: 3.616081 samples/s, speed: 1851.433226 tokens/s, learning rate: 6.000e-07, loss_scalings: 26214.400391, pp_loss: 9.814314
[INFO] 2021-07-09 16:43:27,469 [run_pretraining.py:  512]:	********exe.run_61******* 
[INFO] 2021-07-09 16:43:29,758 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:29,758 [run_pretraining.py:  534]:	loss/total_loss, 9.8017578125, 62
[INFO] 2021-07-09 16:43:29,758 [run_pretraining.py:  535]:	loss/mlm_loss, 9.8017578125, 62
[INFO] 2021-07-09 16:43:29,758 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.099999723119254e-07, 62
[INFO] 2021-07-09 16:43:29,758 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 62
[INFO] 2021-07-09 16:43:29,758 [run_pretraining.py:  558]:	worker_index: 7, step: 62, cost: 9.801758, mlm loss: 9.801758, speed: 0.436913 steps/s, speed: 3.495301 samples/s, speed: 1789.594314 tokens/s, learning rate: 6.100e-07, loss_scalings: 26214.400391, pp_loss: 9.783034
[INFO] 2021-07-09 16:43:29,758 [run_pretraining.py:  512]:	********exe.run_62******* 
[INFO] 2021-07-09 16:43:32,016 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:32,017 [run_pretraining.py:  534]:	loss/total_loss, 9.738703727722168, 63
[INFO] 2021-07-09 16:43:32,017 [run_pretraining.py:  535]:	loss/mlm_loss, 9.738703727722168, 63
[INFO] 2021-07-09 16:43:32,017 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.199999802447564e-07, 63
[INFO] 2021-07-09 16:43:32,017 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 63
[INFO] 2021-07-09 16:43:32,017 [run_pretraining.py:  558]:	worker_index: 7, step: 63, cost: 9.738704, mlm loss: 9.738704, speed: 0.442842 steps/s, speed: 3.542736 samples/s, speed: 1813.880620 tokens/s, learning rate: 6.200e-07, loss_scalings: 26214.400391, pp_loss: 9.740553
[INFO] 2021-07-09 16:43:32,017 [run_pretraining.py:  512]:	********exe.run_63******* 
[INFO] 2021-07-09 16:43:34,213 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:34,214 [run_pretraining.py:  534]:	loss/total_loss, 9.72708797454834, 64
[INFO] 2021-07-09 16:43:34,214 [run_pretraining.py:  535]:	loss/mlm_loss, 9.72708797454834, 64
[INFO] 2021-07-09 16:43:34,214 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.299999881775875e-07, 64
[INFO] 2021-07-09 16:43:34,214 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 64
[INFO] 2021-07-09 16:43:34,214 [run_pretraining.py:  558]:	worker_index: 7, step: 64, cost: 9.727088, mlm loss: 9.727088, speed: 0.455266 steps/s, speed: 3.642130 samples/s, speed: 1864.770663 tokens/s, learning rate: 6.300e-07, loss_scalings: 26214.400391, pp_loss: 9.696483
[INFO] 2021-07-09 16:43:34,214 [run_pretraining.py:  512]:	********exe.run_64******* 
[INFO] 2021-07-09 16:43:36,397 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:36,397 [run_pretraining.py:  534]:	loss/total_loss, 9.704263687133789, 65
[INFO] 2021-07-09 16:43:36,397 [run_pretraining.py:  535]:	loss/mlm_loss, 9.704263687133789, 65
[INFO] 2021-07-09 16:43:36,398 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.399999392669997e-07, 65
[INFO] 2021-07-09 16:43:36,398 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 65
[INFO] 2021-07-09 16:43:36,398 [run_pretraining.py:  558]:	worker_index: 7, step: 65, cost: 9.704264, mlm loss: 9.704264, speed: 0.458167 steps/s, speed: 3.665332 samples/s, speed: 1876.650185 tokens/s, learning rate: 6.400e-07, loss_scalings: 26214.400391, pp_loss: 9.680188
[INFO] 2021-07-09 16:43:36,398 [run_pretraining.py:  512]:	********exe.run_65******* 
[INFO] 2021-07-09 16:43:38,563 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:38,563 [run_pretraining.py:  534]:	loss/total_loss, 9.664772987365723, 66
[INFO] 2021-07-09 16:43:38,563 [run_pretraining.py:  535]:	loss/mlm_loss, 9.664772987365723, 66
[INFO] 2021-07-09 16:43:38,563 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.500000040432496e-07, 66
[INFO] 2021-07-09 16:43:38,563 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 66
[INFO] 2021-07-09 16:43:38,563 [run_pretraining.py:  558]:	worker_index: 7, step: 66, cost: 9.664773, mlm loss: 9.664773, speed: 0.461889 steps/s, speed: 3.695109 samples/s, speed: 1891.895850 tokens/s, learning rate: 6.500e-07, loss_scalings: 26214.400391, pp_loss: 9.633904
[INFO] 2021-07-09 16:43:38,563 [run_pretraining.py:  512]:	********exe.run_66******* 
[INFO] 2021-07-09 16:43:40,776 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:40,776 [run_pretraining.py:  534]:	loss/total_loss, 9.53464412689209, 67
[INFO] 2021-07-09 16:43:40,777 [run_pretraining.py:  535]:	loss/mlm_loss, 9.53464412689209, 67
[INFO] 2021-07-09 16:43:40,777 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.599999551326619e-07, 67
[INFO] 2021-07-09 16:43:40,777 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 67
[INFO] 2021-07-09 16:43:40,777 [run_pretraining.py:  558]:	worker_index: 7, step: 67, cost: 9.534644, mlm loss: 9.534644, speed: 0.451913 steps/s, speed: 3.615307 samples/s, speed: 1851.037056 tokens/s, learning rate: 6.600e-07, loss_scalings: 26214.400391, pp_loss: 9.598821
[INFO] 2021-07-09 16:43:40,777 [run_pretraining.py:  512]:	********exe.run_67******* 
[INFO] 2021-07-09 16:43:42,923 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:42,924 [run_pretraining.py:  534]:	loss/total_loss, 9.547691345214844, 68
[INFO] 2021-07-09 16:43:42,924 [run_pretraining.py:  535]:	loss/mlm_loss, 9.547691345214844, 68
[INFO] 2021-07-09 16:43:42,924 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.699999630654929e-07, 68
[INFO] 2021-07-09 16:43:42,924 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 68
[INFO] 2021-07-09 16:43:42,924 [run_pretraining.py:  558]:	worker_index: 7, step: 68, cost: 9.547691, mlm loss: 9.547691, speed: 0.465817 steps/s, speed: 3.726534 samples/s, speed: 1907.985445 tokens/s, learning rate: 6.700e-07, loss_scalings: 26214.400391, pp_loss: 9.567395
[INFO] 2021-07-09 16:43:42,924 [run_pretraining.py:  512]:	********exe.run_68******* 
[INFO] 2021-07-09 16:43:45,073 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:45,074 [run_pretraining.py:  534]:	loss/total_loss, 9.49367618560791, 69
[INFO] 2021-07-09 16:43:45,074 [run_pretraining.py:  535]:	loss/mlm_loss, 9.49367618560791, 69
[INFO] 2021-07-09 16:43:45,074 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.79999970998324e-07, 69
[INFO] 2021-07-09 16:43:45,074 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 69
[INFO] 2021-07-09 16:43:45,074 [run_pretraining.py:  558]:	worker_index: 7, step: 69, cost: 9.493676, mlm loss: 9.493676, speed: 0.465295 steps/s, speed: 3.722357 samples/s, speed: 1905.847022 tokens/s, learning rate: 6.800e-07, loss_scalings: 26214.400391, pp_loss: 9.540007
[INFO] 2021-07-09 16:43:45,074 [run_pretraining.py:  512]:	********exe.run_69******* 
[INFO] 2021-07-09 16:43:47,259 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:47,260 [run_pretraining.py:  534]:	loss/total_loss, 9.429840087890625, 70
[INFO] 2021-07-09 16:43:47,260 [run_pretraining.py:  535]:	loss/mlm_loss, 9.429840087890625, 70
[INFO] 2021-07-09 16:43:47,260 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.899999789311551e-07, 70
[INFO] 2021-07-09 16:43:47,260 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 70
[INFO] 2021-07-09 16:43:47,260 [run_pretraining.py:  558]:	worker_index: 7, step: 70, cost: 9.429840, mlm loss: 9.429840, speed: 0.457565 steps/s, speed: 3.660520 samples/s, speed: 1874.186494 tokens/s, learning rate: 6.900e-07, loss_scalings: 26214.400391, pp_loss: 9.473944
[INFO] 2021-07-09 16:43:47,260 [run_pretraining.py:  512]:	********exe.run_70******* 
[INFO] 2021-07-09 16:43:49,431 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:49,432 [run_pretraining.py:  534]:	loss/total_loss, 9.442913055419922, 71
[INFO] 2021-07-09 16:43:49,432 [run_pretraining.py:  535]:	loss/mlm_loss, 9.442913055419922, 71
[INFO] 2021-07-09 16:43:49,432 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.999999868639861e-07, 71
[INFO] 2021-07-09 16:43:49,432 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 71
[INFO] 2021-07-09 16:43:49,432 [run_pretraining.py:  558]:	worker_index: 7, step: 71, cost: 9.442913, mlm loss: 9.442913, speed: 0.460582 steps/s, speed: 3.684657 samples/s, speed: 1886.544376 tokens/s, learning rate: 7.000e-07, loss_scalings: 26214.400391, pp_loss: 9.464432
[INFO] 2021-07-09 16:43:49,432 [run_pretraining.py:  512]:	********exe.run_71******* 
[INFO] 2021-07-09 16:43:51,596 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:51,597 [run_pretraining.py:  534]:	loss/total_loss, 9.389043807983398, 72
[INFO] 2021-07-09 16:43:51,597 [run_pretraining.py:  535]:	loss/mlm_loss, 9.389043807983398, 72
[INFO] 2021-07-09 16:43:51,597 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.099999947968172e-07, 72
[INFO] 2021-07-09 16:43:51,597 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 72
[INFO] 2021-07-09 16:43:51,597 [run_pretraining.py:  558]:	worker_index: 7, step: 72, cost: 9.389044, mlm loss: 9.389044, speed: 0.461994 steps/s, speed: 3.695950 samples/s, speed: 1892.326172 tokens/s, learning rate: 7.100e-07, loss_scalings: 26214.400391, pp_loss: 9.432405
[INFO] 2021-07-09 16:43:51,597 [run_pretraining.py:  512]:	********exe.run_72******* 
[INFO] 2021-07-09 16:43:53,801 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:53,802 [run_pretraining.py:  534]:	loss/total_loss, 9.378820419311523, 73
[INFO] 2021-07-09 16:43:53,802 [run_pretraining.py:  535]:	loss/mlm_loss, 9.378820419311523, 73
[INFO] 2021-07-09 16:43:53,802 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.199999458862294e-07, 73
[INFO] 2021-07-09 16:43:53,802 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 73
[INFO] 2021-07-09 16:43:53,802 [run_pretraining.py:  558]:	worker_index: 7, step: 73, cost: 9.378820, mlm loss: 9.378820, speed: 0.453761 steps/s, speed: 3.630089 samples/s, speed: 1858.605679 tokens/s, learning rate: 7.200e-07, loss_scalings: 26214.400391, pp_loss: 9.385672
[INFO] 2021-07-09 16:43:53,802 [run_pretraining.py:  512]:	********exe.run_73******* 
[INFO] 2021-07-09 16:43:55,997 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:55,998 [run_pretraining.py:  534]:	loss/total_loss, 9.324219703674316, 74
[INFO] 2021-07-09 16:43:55,998 [run_pretraining.py:  535]:	loss/mlm_loss, 9.324219703674316, 74
[INFO] 2021-07-09 16:43:55,998 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.300000106624793e-07, 74
[INFO] 2021-07-09 16:43:55,998 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 74
[INFO] 2021-07-09 16:43:55,998 [run_pretraining.py:  558]:	worker_index: 7, step: 74, cost: 9.324220, mlm loss: 9.324220, speed: 0.455431 steps/s, speed: 3.643450 samples/s, speed: 1865.446146 tokens/s, learning rate: 7.300e-07, loss_scalings: 26214.400391, pp_loss: 9.355867
[INFO] 2021-07-09 16:43:55,998 [run_pretraining.py:  512]:	********exe.run_74******* 
[INFO] 2021-07-09 16:43:58,150 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:58,151 [run_pretraining.py:  534]:	loss/total_loss, 9.301925659179688, 75
[INFO] 2021-07-09 16:43:58,151 [run_pretraining.py:  535]:	loss/mlm_loss, 9.301925659179688, 75
[INFO] 2021-07-09 16:43:58,151 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.399999617518915e-07, 75
[INFO] 2021-07-09 16:43:58,151 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 75
[INFO] 2021-07-09 16:43:58,151 [run_pretraining.py:  558]:	worker_index: 7, step: 75, cost: 9.301926, mlm loss: 9.301926, speed: 0.464665 steps/s, speed: 3.717317 samples/s, speed: 1903.266274 tokens/s, learning rate: 7.400e-07, loss_scalings: 26214.400391, pp_loss: 9.317570
[INFO] 2021-07-09 16:43:58,151 [run_pretraining.py:  512]:	********exe.run_75******* 
[INFO] 2021-07-09 16:44:00,356 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:00,357 [run_pretraining.py:  534]:	loss/total_loss, 9.292681694030762, 76
[INFO] 2021-07-09 16:44:00,357 [run_pretraining.py:  535]:	loss/mlm_loss, 9.292681694030762, 76
[INFO] 2021-07-09 16:44:00,357 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.499999696847226e-07, 76
[INFO] 2021-07-09 16:44:00,357 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 76
[INFO] 2021-07-09 16:44:00,357 [run_pretraining.py:  558]:	worker_index: 7, step: 76, cost: 9.292682, mlm loss: 9.292682, speed: 0.453387 steps/s, speed: 3.627100 samples/s, speed: 1857.074962 tokens/s, learning rate: 7.500e-07, loss_scalings: 26214.400391, pp_loss: 9.269323
[INFO] 2021-07-09 16:44:00,357 [run_pretraining.py:  512]:	********exe.run_76******* 
[INFO] 2021-07-09 16:44:02,562 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:02,563 [run_pretraining.py:  534]:	loss/total_loss, 9.327672004699707, 77
[INFO] 2021-07-09 16:44:02,563 [run_pretraining.py:  535]:	loss/mlm_loss, 9.327672004699707, 77
[INFO] 2021-07-09 16:44:02,563 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.599999776175537e-07, 77
[INFO] 2021-07-09 16:44:02,563 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 77
[INFO] 2021-07-09 16:44:02,563 [run_pretraining.py:  558]:	worker_index: 7, step: 77, cost: 9.327672, mlm loss: 9.327672, speed: 0.453458 steps/s, speed: 3.627660 samples/s, speed: 1857.362068 tokens/s, learning rate: 7.600e-07, loss_scalings: 20971.521484, pp_loss: 9.283752
[INFO] 2021-07-09 16:44:02,563 [run_pretraining.py:  512]:	********exe.run_77******* 
[INFO] 2021-07-09 16:44:04,750 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:04,751 [run_pretraining.py:  534]:	loss/total_loss, 9.2091703414917, 78
[INFO] 2021-07-09 16:44:04,751 [run_pretraining.py:  535]:	loss/mlm_loss, 9.2091703414917, 78
[INFO] 2021-07-09 16:44:04,751 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.699999855503847e-07, 78
[INFO] 2021-07-09 16:44:04,751 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 78
[INFO] 2021-07-09 16:44:04,751 [run_pretraining.py:  558]:	worker_index: 7, step: 78, cost: 9.209170, mlm loss: 9.209170, speed: 0.457163 steps/s, speed: 3.657306 samples/s, speed: 1872.540616 tokens/s, learning rate: 7.700e-07, loss_scalings: 20971.521484, pp_loss: 9.192467
[INFO] 2021-07-09 16:44:04,752 [run_pretraining.py:  512]:	********exe.run_78******* 
[INFO] 2021-07-09 16:44:06,950 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:06,950 [run_pretraining.py:  534]:	loss/total_loss, 9.198272705078125, 79
[INFO] 2021-07-09 16:44:06,950 [run_pretraining.py:  535]:	loss/mlm_loss, 9.198272705078125, 79
[INFO] 2021-07-09 16:44:06,950 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.799999366397969e-07, 79
[INFO] 2021-07-09 16:44:06,950 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 79
[INFO] 2021-07-09 16:44:06,950 [run_pretraining.py:  558]:	worker_index: 7, step: 79, cost: 9.198273, mlm loss: 9.198273, speed: 0.454913 steps/s, speed: 3.639306 samples/s, speed: 1863.324759 tokens/s, learning rate: 7.800e-07, loss_scalings: 20971.521484, pp_loss: 9.168558
[INFO] 2021-07-09 16:44:06,950 [run_pretraining.py:  512]:	********exe.run_79******* 
[INFO] 2021-07-09 16:44:09,170 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:09,170 [run_pretraining.py:  534]:	loss/total_loss, 9.033651351928711, 80
[INFO] 2021-07-09 16:44:09,170 [run_pretraining.py:  535]:	loss/mlm_loss, 9.033651351928711, 80
[INFO] 2021-07-09 16:44:09,170 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.89999944572628e-07, 80
[INFO] 2021-07-09 16:44:09,170 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 80
[INFO] 2021-07-09 16:44:09,170 [run_pretraining.py:  558]:	worker_index: 7, step: 80, cost: 9.033651, mlm loss: 9.033651, speed: 0.450577 steps/s, speed: 3.604614 samples/s, speed: 1845.562140 tokens/s, learning rate: 7.900e-07, loss_scalings: 20971.521484, pp_loss: 9.136308
[INFO] 2021-07-09 16:44:09,170 [run_pretraining.py:  512]:	********exe.run_80******* 
[INFO] 2021-07-09 16:44:11,336 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:11,337 [run_pretraining.py:  534]:	loss/total_loss, 9.109063148498535, 81
[INFO] 2021-07-09 16:44:11,337 [run_pretraining.py:  535]:	loss/mlm_loss, 9.109063148498535, 81
[INFO] 2021-07-09 16:44:11,337 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.000000093488779e-07, 81
[INFO] 2021-07-09 16:44:11,337 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 81
[INFO] 2021-07-09 16:44:11,337 [run_pretraining.py:  558]:	worker_index: 7, step: 81, cost: 9.109063, mlm loss: 9.109063, speed: 0.461667 steps/s, speed: 3.693339 samples/s, speed: 1890.989584 tokens/s, learning rate: 8.000e-07, loss_scalings: 20971.521484, pp_loss: 9.131612
[INFO] 2021-07-09 16:44:11,337 [run_pretraining.py:  512]:	********exe.run_81******* 
[INFO] 2021-07-09 16:44:13,504 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:13,504 [run_pretraining.py:  534]:	loss/total_loss, 9.067270278930664, 82
[INFO] 2021-07-09 16:44:13,504 [run_pretraining.py:  535]:	loss/mlm_loss, 9.067270278930664, 82
[INFO] 2021-07-09 16:44:13,504 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.10000017281709e-07, 82
[INFO] 2021-07-09 16:44:13,504 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 82
[INFO] 2021-07-09 16:44:13,505 [run_pretraining.py:  558]:	worker_index: 7, step: 82, cost: 9.067270, mlm loss: 9.067270, speed: 0.461526 steps/s, speed: 3.692211 samples/s, speed: 1890.412168 tokens/s, learning rate: 8.100e-07, loss_scalings: 20971.521484, pp_loss: 9.067996
[INFO] 2021-07-09 16:44:13,505 [run_pretraining.py:  512]:	********exe.run_82******* 
[INFO] 2021-07-09 16:44:15,678 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:15,678 [run_pretraining.py:  534]:	loss/total_loss, 9.026046752929688, 83
[INFO] 2021-07-09 16:44:15,678 [run_pretraining.py:  535]:	loss/mlm_loss, 9.026046752929688, 83
[INFO] 2021-07-09 16:44:15,678 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.199999683711212e-07, 83
[INFO] 2021-07-09 16:44:15,678 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 83
[INFO] 2021-07-09 16:44:15,679 [run_pretraining.py:  558]:	worker_index: 7, step: 83, cost: 9.026047, mlm loss: 9.026047, speed: 0.460128 steps/s, speed: 3.681023 samples/s, speed: 1884.683809 tokens/s, learning rate: 8.200e-07, loss_scalings: 20971.521484, pp_loss: 9.026386
[INFO] 2021-07-09 16:44:15,679 [run_pretraining.py:  512]:	********exe.run_83******* 
[INFO] 2021-07-09 16:44:17,825 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:17,826 [run_pretraining.py:  534]:	loss/total_loss, 9.022096633911133, 84
[INFO] 2021-07-09 16:44:17,826 [run_pretraining.py:  535]:	loss/mlm_loss, 9.022096633911133, 84
[INFO] 2021-07-09 16:44:17,826 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.299999763039523e-07, 84
[INFO] 2021-07-09 16:44:17,826 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 84
[INFO] 2021-07-09 16:44:17,826 [run_pretraining.py:  558]:	worker_index: 7, step: 84, cost: 9.022097, mlm loss: 9.022097, speed: 0.465779 steps/s, speed: 3.726228 samples/s, speed: 1907.828864 tokens/s, learning rate: 8.300e-07, loss_scalings: 20971.521484, pp_loss: 8.989821
[INFO] 2021-07-09 16:44:17,826 [run_pretraining.py:  512]:	********exe.run_84******* 
[INFO] 2021-07-09 16:44:19,979 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:19,980 [run_pretraining.py:  534]:	loss/total_loss, 9.025680541992188, 85
[INFO] 2021-07-09 16:44:19,980 [run_pretraining.py:  535]:	loss/mlm_loss, 9.025680541992188, 85
[INFO] 2021-07-09 16:44:19,980 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.399999273933645e-07, 85
[INFO] 2021-07-09 16:44:19,980 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 85
[INFO] 2021-07-09 16:44:19,980 [run_pretraining.py:  558]:	worker_index: 7, step: 85, cost: 9.025681, mlm loss: 9.025681, speed: 0.464397 steps/s, speed: 3.715175 samples/s, speed: 1902.169839 tokens/s, learning rate: 8.400e-07, loss_scalings: 20971.521484, pp_loss: 8.948036
[INFO] 2021-07-09 16:44:19,980 [run_pretraining.py:  512]:	********exe.run_85******* 
[INFO] 2021-07-09 16:44:22,125 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:22,126 [run_pretraining.py:  534]:	loss/total_loss, 8.95221996307373, 86
[INFO] 2021-07-09 16:44:22,126 [run_pretraining.py:  535]:	loss/mlm_loss, 8.95221996307373, 86
[INFO] 2021-07-09 16:44:22,126 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.500000490130333e-07, 86
[INFO] 2021-07-09 16:44:22,126 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 86
[INFO] 2021-07-09 16:44:22,126 [run_pretraining.py:  558]:	worker_index: 7, step: 86, cost: 8.952220, mlm loss: 8.952220, speed: 0.466082 steps/s, speed: 3.728658 samples/s, speed: 1909.072685 tokens/s, learning rate: 8.500e-07, loss_scalings: 20971.521484, pp_loss: 8.930513
[INFO] 2021-07-09 16:44:22,127 [run_pretraining.py:  512]:	********exe.run_86******* 
[INFO] 2021-07-09 16:44:24,442 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:24,443 [run_pretraining.py:  534]:	loss/total_loss, 8.915804862976074, 87
[INFO] 2021-07-09 16:44:24,443 [run_pretraining.py:  535]:	loss/mlm_loss, 8.915804862976074, 87
[INFO] 2021-07-09 16:44:24,443 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.600000001024455e-07, 87
[INFO] 2021-07-09 16:44:24,443 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 87
[INFO] 2021-07-09 16:44:24,443 [run_pretraining.py:  558]:	worker_index: 7, step: 87, cost: 8.915805, mlm loss: 8.915805, speed: 0.431816 steps/s, speed: 3.454528 samples/s, speed: 1768.718542 tokens/s, learning rate: 8.600e-07, loss_scalings: 20971.521484, pp_loss: 8.890805
[INFO] 2021-07-09 16:44:24,443 [run_pretraining.py:  512]:	********exe.run_87******* 
[INFO] 2021-07-09 16:44:26,853 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:26,854 [run_pretraining.py:  534]:	loss/total_loss, 8.861494064331055, 88
[INFO] 2021-07-09 16:44:26,854 [run_pretraining.py:  535]:	loss/mlm_loss, 8.861494064331055, 88
[INFO] 2021-07-09 16:44:26,854 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.700000080352766e-07, 88
[INFO] 2021-07-09 16:44:26,854 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 88
[INFO] 2021-07-09 16:44:26,854 [run_pretraining.py:  558]:	worker_index: 7, step: 88, cost: 8.861494, mlm loss: 8.861494, speed: 0.414842 steps/s, speed: 3.318739 samples/s, speed: 1699.194339 tokens/s, learning rate: 8.700e-07, loss_scalings: 20971.521484, pp_loss: 8.882409
[INFO] 2021-07-09 16:44:26,854 [run_pretraining.py:  512]:	********exe.run_88******* 
[INFO] 2021-07-09 16:44:29,019 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:29,019 [run_pretraining.py:  534]:	loss/total_loss, 8.869209289550781, 89
[INFO] 2021-07-09 16:44:29,020 [run_pretraining.py:  535]:	loss/mlm_loss, 8.869209289550781, 89
[INFO] 2021-07-09 16:44:29,020 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.799999591246888e-07, 89
[INFO] 2021-07-09 16:44:29,020 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 89
[INFO] 2021-07-09 16:44:29,020 [run_pretraining.py:  558]:	worker_index: 7, step: 89, cost: 8.869209, mlm loss: 8.869209, speed: 0.461926 steps/s, speed: 3.695411 samples/s, speed: 1892.050451 tokens/s, learning rate: 8.800e-07, loss_scalings: 20971.521484, pp_loss: 8.805046
[INFO] 2021-07-09 16:44:29,020 [run_pretraining.py:  512]:	********exe.run_89******* 
[INFO] 2021-07-09 16:44:31,166 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:31,167 [run_pretraining.py:  534]:	loss/total_loss, 8.828592300415039, 90
[INFO] 2021-07-09 16:44:31,167 [run_pretraining.py:  535]:	loss/mlm_loss, 8.828592300415039, 90
[INFO] 2021-07-09 16:44:31,167 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.899999670575198e-07, 90
[INFO] 2021-07-09 16:44:31,167 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 90
[INFO] 2021-07-09 16:44:31,167 [run_pretraining.py:  558]:	worker_index: 7, step: 90, cost: 8.828592, mlm loss: 8.828592, speed: 0.465798 steps/s, speed: 3.726385 samples/s, speed: 1907.909164 tokens/s, learning rate: 8.900e-07, loss_scalings: 20971.521484, pp_loss: 8.781069
[INFO] 2021-07-09 16:44:31,167 [run_pretraining.py:  512]:	********exe.run_90******* 
[INFO] 2021-07-09 16:44:33,333 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:33,334 [run_pretraining.py:  534]:	loss/total_loss, 8.7871675491333, 91
[INFO] 2021-07-09 16:44:33,334 [run_pretraining.py:  535]:	loss/mlm_loss, 8.7871675491333, 91
[INFO] 2021-07-09 16:44:33,334 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.99999918146932e-07, 91
[INFO] 2021-07-09 16:44:33,334 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 91
[INFO] 2021-07-09 16:44:33,334 [run_pretraining.py:  558]:	worker_index: 7, step: 91, cost: 8.787168, mlm loss: 8.787168, speed: 0.461686 steps/s, speed: 3.693485 samples/s, speed: 1891.064310 tokens/s, learning rate: 9.000e-07, loss_scalings: 20971.521484, pp_loss: 8.718622
[INFO] 2021-07-09 16:44:33,334 [run_pretraining.py:  512]:	********exe.run_91******* 
[INFO] 2021-07-09 16:44:35,490 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:35,491 [run_pretraining.py:  534]:	loss/total_loss, 8.81953239440918, 92
[INFO] 2021-07-09 16:44:35,491 [run_pretraining.py:  535]:	loss/mlm_loss, 8.81953239440918, 92
[INFO] 2021-07-09 16:44:35,491 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.100000397666008e-07, 92
[INFO] 2021-07-09 16:44:35,491 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 92
[INFO] 2021-07-09 16:44:35,491 [run_pretraining.py:  558]:	worker_index: 7, step: 92, cost: 8.819532, mlm loss: 8.819532, speed: 0.463738 steps/s, speed: 3.709905 samples/s, speed: 1899.471338 tokens/s, learning rate: 9.100e-07, loss_scalings: 20971.521484, pp_loss: 8.708762
[INFO] 2021-07-09 16:44:35,491 [run_pretraining.py:  512]:	********exe.run_92******* 
[INFO] 2021-07-09 16:44:37,642 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:37,643 [run_pretraining.py:  534]:	loss/total_loss, 8.609916687011719, 93
[INFO] 2021-07-09 16:44:37,643 [run_pretraining.py:  535]:	loss/mlm_loss, 8.609916687011719, 93
[INFO] 2021-07-09 16:44:37,643 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.19999990856013e-07, 93
[INFO] 2021-07-09 16:44:37,643 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 93
[INFO] 2021-07-09 16:44:37,643 [run_pretraining.py:  558]:	worker_index: 7, step: 93, cost: 8.609917, mlm loss: 8.609917, speed: 0.464813 steps/s, speed: 3.718505 samples/s, speed: 1903.874779 tokens/s, learning rate: 9.200e-07, loss_scalings: 20971.521484, pp_loss: 8.668710
[INFO] 2021-07-09 16:44:37,643 [run_pretraining.py:  512]:	********exe.run_93******* 
[INFO] 2021-07-09 16:44:39,809 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:39,809 [run_pretraining.py:  534]:	loss/total_loss, 8.664653778076172, 94
[INFO] 2021-07-09 16:44:39,810 [run_pretraining.py:  535]:	loss/mlm_loss, 8.664653778076172, 94
[INFO] 2021-07-09 16:44:39,810 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.299999987888441e-07, 94
[INFO] 2021-07-09 16:44:39,810 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 94
[INFO] 2021-07-09 16:44:39,810 [run_pretraining.py:  558]:	worker_index: 7, step: 94, cost: 8.664654, mlm loss: 8.664654, speed: 0.461706 steps/s, speed: 3.693648 samples/s, speed: 1891.147785 tokens/s, learning rate: 9.300e-07, loss_scalings: 20971.521484, pp_loss: 8.593434
[INFO] 2021-07-09 16:44:39,810 [run_pretraining.py:  512]:	********exe.run_94******* 
[INFO] 2021-07-09 16:44:41,968 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:41,968 [run_pretraining.py:  534]:	loss/total_loss, 8.502955436706543, 95
[INFO] 2021-07-09 16:44:41,968 [run_pretraining.py:  535]:	loss/mlm_loss, 8.502955436706543, 95
[INFO] 2021-07-09 16:44:41,969 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.399999498782563e-07, 95
[INFO] 2021-07-09 16:44:41,969 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 95
[INFO] 2021-07-09 16:44:41,969 [run_pretraining.py:  558]:	worker_index: 7, step: 95, cost: 8.502955, mlm loss: 8.502955, speed: 0.463337 steps/s, speed: 3.706697 samples/s, speed: 1897.828779 tokens/s, learning rate: 9.400e-07, loss_scalings: 20971.521484, pp_loss: 8.567863
[INFO] 2021-07-09 16:44:41,969 [run_pretraining.py:  512]:	********exe.run_95******* 
[INFO] 2021-07-09 16:44:44,114 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:44,115 [run_pretraining.py:  534]:	loss/total_loss, 8.559638977050781, 96
[INFO] 2021-07-09 16:44:44,115 [run_pretraining.py:  535]:	loss/mlm_loss, 8.559638977050781, 96
[INFO] 2021-07-09 16:44:44,115 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.499999578110874e-07, 96
[INFO] 2021-07-09 16:44:44,115 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 96
[INFO] 2021-07-09 16:44:44,115 [run_pretraining.py:  558]:	worker_index: 7, step: 96, cost: 8.559639, mlm loss: 8.559639, speed: 0.465998 steps/s, speed: 3.727986 samples/s, speed: 1908.729078 tokens/s, learning rate: 9.500e-07, loss_scalings: 20971.521484, pp_loss: 8.514402
[INFO] 2021-07-09 16:44:44,115 [run_pretraining.py:  512]:	********exe.run_96******* 
[INFO] 2021-07-09 16:44:46,285 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:46,285 [run_pretraining.py:  534]:	loss/total_loss, 8.584500312805176, 97
[INFO] 2021-07-09 16:44:46,286 [run_pretraining.py:  535]:	loss/mlm_loss, 8.584500312805176, 97
[INFO] 2021-07-09 16:44:46,286 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.599999657439184e-07, 97
[INFO] 2021-07-09 16:44:46,286 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 97
[INFO] 2021-07-09 16:44:46,286 [run_pretraining.py:  558]:	worker_index: 7, step: 97, cost: 8.584500, mlm loss: 8.584500, speed: 0.460866 steps/s, speed: 3.686931 samples/s, speed: 1887.708734 tokens/s, learning rate: 9.600e-07, loss_scalings: 16777.216797, pp_loss: 8.529849
[INFO] 2021-07-09 16:44:46,286 [run_pretraining.py:  512]:	********exe.run_97******* 
[INFO] 2021-07-09 16:44:48,444 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:48,445 [run_pretraining.py:  534]:	loss/total_loss, 8.475019454956055, 98
[INFO] 2021-07-09 16:44:48,445 [run_pretraining.py:  535]:	loss/mlm_loss, 8.475019454956055, 98
[INFO] 2021-07-09 16:44:48,445 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.699999736767495e-07, 98
[INFO] 2021-07-09 16:44:48,445 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 98
[INFO] 2021-07-09 16:44:48,445 [run_pretraining.py:  558]:	worker_index: 7, step: 98, cost: 8.475019, mlm loss: 8.475019, speed: 0.463264 steps/s, speed: 3.706111 samples/s, speed: 1897.528609 tokens/s, learning rate: 9.700e-07, loss_scalings: 16777.216797, pp_loss: 8.442334
[INFO] 2021-07-09 16:44:48,445 [run_pretraining.py:  512]:	********exe.run_98******* 
[INFO] 2021-07-09 16:44:50,599 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:50,599 [run_pretraining.py:  534]:	loss/total_loss, 8.447929382324219, 99
[INFO] 2021-07-09 16:44:50,600 [run_pretraining.py:  535]:	loss/mlm_loss, 8.447929382324219, 99
[INFO] 2021-07-09 16:44:50,600 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.799999816095806e-07, 99
[INFO] 2021-07-09 16:44:50,600 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 99
[INFO] 2021-07-09 16:44:50,600 [run_pretraining.py:  558]:	worker_index: 7, step: 99, cost: 8.447929, mlm loss: 8.447929, speed: 0.464258 steps/s, speed: 3.714063 samples/s, speed: 1901.600100 tokens/s, learning rate: 9.800e-07, loss_scalings: 16777.216797, pp_loss: 8.398890
[INFO] 2021-07-09 16:44:50,600 [run_pretraining.py:  512]:	********exe.run_99******* 
[INFO] 2021-07-09 16:44:52,754 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:52,755 [run_pretraining.py:  534]:	loss/total_loss, 8.317463874816895, 100
[INFO] 2021-07-09 16:44:52,755 [run_pretraining.py:  535]:	loss/mlm_loss, 8.317463874816895, 100
[INFO] 2021-07-09 16:44:52,755 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.899999895424116e-07, 100
[INFO] 2021-07-09 16:44:52,755 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 100
[INFO] 2021-07-09 16:44:52,755 [run_pretraining.py:  558]:	worker_index: 7, step: 100, cost: 8.317464, mlm loss: 8.317464, speed: 0.464169 steps/s, speed: 3.713349 samples/s, speed: 1901.234560 tokens/s, learning rate: 9.900e-07, loss_scalings: 16777.216797, pp_loss: 8.348081
[INFO] 2021-07-09 16:44:52,755 [run_pretraining.py:  512]:	********exe.run_100******* 
[INFO] 2021-07-09 16:44:54,966 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:54,966 [run_pretraining.py:  534]:	loss/total_loss, 8.326377868652344, 101
[INFO] 2021-07-09 16:44:54,966 [run_pretraining.py:  535]:	loss/mlm_loss, 8.326377868652344, 101
[INFO] 2021-07-09 16:44:54,966 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.999999974752427e-07, 101
[INFO] 2021-07-09 16:44:54,966 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 101
[INFO] 2021-07-09 16:44:54,966 [run_pretraining.py:  558]:	worker_index: 7, step: 101, cost: 8.326378, mlm loss: 8.326378, speed: 0.452324 steps/s, speed: 3.618592 samples/s, speed: 1852.719257 tokens/s, learning rate: 1.000e-06, loss_scalings: 16777.216797, pp_loss: 8.301584
[INFO] 2021-07-09 16:44:54,966 [run_pretraining.py:  512]:	********exe.run_101******* 
[INFO] 2021-07-09 16:44:57,123 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:57,124 [run_pretraining.py:  534]:	loss/total_loss, 8.279631614685059, 102
[INFO] 2021-07-09 16:44:57,124 [run_pretraining.py:  535]:	loss/mlm_loss, 8.279631614685059, 102
[INFO] 2021-07-09 16:44:57,124 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.009999891721236e-06, 102
[INFO] 2021-07-09 16:44:57,124 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 102
[INFO] 2021-07-09 16:44:57,124 [run_pretraining.py:  558]:	worker_index: 7, step: 102, cost: 8.279632, mlm loss: 8.279632, speed: 0.463560 steps/s, speed: 3.708483 samples/s, speed: 1898.743292 tokens/s, learning rate: 1.010e-06, loss_scalings: 16777.216797, pp_loss: 8.270912
[INFO] 2021-07-09 16:44:57,124 [run_pretraining.py:  512]:	********exe.run_102******* 
[INFO] 2021-07-09 16:44:59,285 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:59,285 [run_pretraining.py:  534]:	loss/total_loss, 8.237602233886719, 103
[INFO] 2021-07-09 16:44:59,285 [run_pretraining.py:  535]:	loss/mlm_loss, 8.237602233886719, 103
[INFO] 2021-07-09 16:44:59,285 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0200000133409048e-06, 103
[INFO] 2021-07-09 16:44:59,285 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 103
[INFO] 2021-07-09 16:44:59,286 [run_pretraining.py:  558]:	worker_index: 7, step: 103, cost: 8.237602, mlm loss: 8.237602, speed: 0.462853 steps/s, speed: 3.702823 samples/s, speed: 1895.845472 tokens/s, learning rate: 1.020e-06, loss_scalings: 16777.216797, pp_loss: 8.226580
[INFO] 2021-07-09 16:44:59,286 [run_pretraining.py:  512]:	********exe.run_103******* 
[INFO] 2021-07-09 16:45:01,494 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:01,494 [run_pretraining.py:  534]:	loss/total_loss, 8.175902366638184, 104
[INFO] 2021-07-09 16:45:01,494 [run_pretraining.py:  535]:	loss/mlm_loss, 8.175902366638184, 104
[INFO] 2021-07-09 16:45:01,495 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.030000021273736e-06, 104
[INFO] 2021-07-09 16:45:01,495 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 104
[INFO] 2021-07-09 16:45:01,495 [run_pretraining.py:  558]:	worker_index: 7, step: 104, cost: 8.175902, mlm loss: 8.175902, speed: 0.452831 steps/s, speed: 3.622648 samples/s, speed: 1854.795924 tokens/s, learning rate: 1.030e-06, loss_scalings: 16777.216797, pp_loss: 8.203742
[INFO] 2021-07-09 16:45:01,495 [run_pretraining.py:  512]:	********exe.run_104******* 
[INFO] 2021-07-09 16:45:03,731 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:03,732 [run_pretraining.py:  534]:	loss/total_loss, 8.109466552734375, 105
[INFO] 2021-07-09 16:45:03,732 [run_pretraining.py:  535]:	loss/mlm_loss, 8.109466552734375, 105
[INFO] 2021-07-09 16:45:03,732 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.040000029206567e-06, 105
[INFO] 2021-07-09 16:45:03,732 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 105
[INFO] 2021-07-09 16:45:03,732 [run_pretraining.py:  558]:	worker_index: 7, step: 105, cost: 8.109467, mlm loss: 8.109467, speed: 0.447085 steps/s, speed: 3.576677 samples/s, speed: 1831.258692 tokens/s, learning rate: 1.040e-06, loss_scalings: 16777.216797, pp_loss: 8.144312
[INFO] 2021-07-09 16:45:03,732 [run_pretraining.py:  512]:	********exe.run_105******* 
[INFO] 2021-07-09 16:45:05,976 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:05,976 [run_pretraining.py:  534]:	loss/total_loss, 8.03599739074707, 106
[INFO] 2021-07-09 16:45:05,976 [run_pretraining.py:  535]:	loss/mlm_loss, 8.03599739074707, 106
[INFO] 2021-07-09 16:45:05,977 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0499999234525603e-06, 106
[INFO] 2021-07-09 16:45:05,977 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 106
[INFO] 2021-07-09 16:45:05,977 [run_pretraining.py:  558]:	worker_index: 7, step: 106, cost: 8.035997, mlm loss: 8.035997, speed: 0.445646 steps/s, speed: 3.565171 samples/s, speed: 1825.367638 tokens/s, learning rate: 1.050e-06, loss_scalings: 16777.216797, pp_loss: 8.059134
[INFO] 2021-07-09 16:45:05,977 [run_pretraining.py:  512]:	********exe.run_106******* 
[INFO] 2021-07-09 16:45:08,190 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:08,191 [run_pretraining.py:  534]:	loss/total_loss, 8.043381690979004, 107
[INFO] 2021-07-09 16:45:08,191 [run_pretraining.py:  535]:	loss/mlm_loss, 8.043381690979004, 107
[INFO] 2021-07-09 16:45:08,191 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0599999313853914e-06, 107
[INFO] 2021-07-09 16:45:08,191 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 107
[INFO] 2021-07-09 16:45:08,191 [run_pretraining.py:  558]:	worker_index: 7, step: 107, cost: 8.043382, mlm loss: 8.043382, speed: 0.451739 steps/s, speed: 3.613913 samples/s, speed: 1850.323339 tokens/s, learning rate: 1.060e-06, loss_scalings: 16777.216797, pp_loss: 8.041922
[INFO] 2021-07-09 16:45:08,191 [run_pretraining.py:  512]:	********exe.run_107******* 
[INFO] 2021-07-09 16:45:10,374 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:10,374 [run_pretraining.py:  534]:	loss/total_loss, 8.003005981445312, 108
[INFO] 2021-07-09 16:45:10,374 [run_pretraining.py:  535]:	loss/mlm_loss, 8.003005981445312, 108
[INFO] 2021-07-09 16:45:10,374 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0700000530050602e-06, 108
[INFO] 2021-07-09 16:45:10,374 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 108
[INFO] 2021-07-09 16:45:10,374 [run_pretraining.py:  558]:	worker_index: 7, step: 108, cost: 8.003006, mlm loss: 8.003006, speed: 0.458130 steps/s, speed: 3.665036 samples/s, speed: 1876.498500 tokens/s, learning rate: 1.070e-06, loss_scalings: 16777.216797, pp_loss: 7.972023
[INFO] 2021-07-09 16:45:10,375 [run_pretraining.py:  512]:	********exe.run_108******* 
[INFO] 2021-07-09 16:45:12,579 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:12,580 [run_pretraining.py:  534]:	loss/total_loss, 7.899586200714111, 109
[INFO] 2021-07-09 16:45:12,580 [run_pretraining.py:  535]:	loss/mlm_loss, 7.899586200714111, 109
[INFO] 2021-07-09 16:45:12,580 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0799999472510535e-06, 109
[INFO] 2021-07-09 16:45:12,580 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 109
[INFO] 2021-07-09 16:45:12,580 [run_pretraining.py:  558]:	worker_index: 7, step: 109, cost: 7.899586, mlm loss: 7.899586, speed: 0.453537 steps/s, speed: 3.628296 samples/s, speed: 1857.687428 tokens/s, learning rate: 1.080e-06, loss_scalings: 16777.216797, pp_loss: 7.925829
[INFO] 2021-07-09 16:45:12,580 [run_pretraining.py:  512]:	********exe.run_109******* 
[INFO] 2021-07-09 16:45:14,768 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:14,768 [run_pretraining.py:  534]:	loss/total_loss, 7.9167304039001465, 110
[INFO] 2021-07-09 16:45:14,769 [run_pretraining.py:  535]:	loss/mlm_loss, 7.9167304039001465, 110
[INFO] 2021-07-09 16:45:14,769 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0899999551838846e-06, 110
[INFO] 2021-07-09 16:45:14,769 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 110
[INFO] 2021-07-09 16:45:14,769 [run_pretraining.py:  558]:	worker_index: 7, step: 110, cost: 7.916730, mlm loss: 7.916730, speed: 0.457030 steps/s, speed: 3.656239 samples/s, speed: 1871.994196 tokens/s, learning rate: 1.090e-06, loss_scalings: 16777.216797, pp_loss: 7.909607
[INFO] 2021-07-09 16:45:14,769 [run_pretraining.py:  512]:	********exe.run_110******* 
[INFO] 2021-07-09 16:45:16,955 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:16,956 [run_pretraining.py:  534]:	loss/total_loss, 7.9197893142700195, 111
[INFO] 2021-07-09 16:45:16,956 [run_pretraining.py:  535]:	loss/mlm_loss, 7.9197893142700195, 111
[INFO] 2021-07-09 16:45:16,956 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0999999631167157e-06, 111
[INFO] 2021-07-09 16:45:16,956 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 111
[INFO] 2021-07-09 16:45:16,956 [run_pretraining.py:  558]:	worker_index: 7, step: 111, cost: 7.919789, mlm loss: 7.919789, speed: 0.457374 steps/s, speed: 3.658994 samples/s, speed: 1873.405174 tokens/s, learning rate: 1.100e-06, loss_scalings: 16777.216797, pp_loss: 7.840316
[INFO] 2021-07-09 16:45:16,956 [run_pretraining.py:  512]:	********exe.run_111******* 
[INFO] 2021-07-09 16:45:19,153 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:19,154 [run_pretraining.py:  534]:	loss/total_loss, 7.7835893630981445, 112
[INFO] 2021-07-09 16:45:19,154 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7835893630981445, 112
[INFO] 2021-07-09 16:45:19,154 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1099999710495467e-06, 112
[INFO] 2021-07-09 16:45:19,154 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 112
[INFO] 2021-07-09 16:45:19,154 [run_pretraining.py:  558]:	worker_index: 7, step: 112, cost: 7.783589, mlm loss: 7.783589, speed: 0.455098 steps/s, speed: 3.640783 samples/s, speed: 1864.081106 tokens/s, learning rate: 1.110e-06, loss_scalings: 16777.216797, pp_loss: 7.764202
[INFO] 2021-07-09 16:45:19,154 [run_pretraining.py:  512]:	********exe.run_112******* 
[INFO] 2021-07-09 16:45:21,337 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:21,337 [run_pretraining.py:  534]:	loss/total_loss, 7.632030963897705, 113
[INFO] 2021-07-09 16:45:21,337 [run_pretraining.py:  535]:	loss/mlm_loss, 7.632030963897705, 113
[INFO] 2021-07-09 16:45:21,338 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1199999789823778e-06, 113
[INFO] 2021-07-09 16:45:21,338 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 113
[INFO] 2021-07-09 16:45:21,338 [run_pretraining.py:  558]:	worker_index: 7, step: 113, cost: 7.632031, mlm loss: 7.632031, speed: 0.458093 steps/s, speed: 3.664741 samples/s, speed: 1876.347249 tokens/s, learning rate: 1.120e-06, loss_scalings: 16777.216797, pp_loss: 7.661868
[INFO] 2021-07-09 16:45:21,338 [run_pretraining.py:  512]:	********exe.run_113******* 
[INFO] 2021-07-09 16:45:23,564 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:23,565 [run_pretraining.py:  534]:	loss/total_loss, 7.668801307678223, 114
[INFO] 2021-07-09 16:45:23,565 [run_pretraining.py:  535]:	loss/mlm_loss, 7.668801307678223, 114
[INFO] 2021-07-09 16:45:23,565 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1299999869152089e-06, 114
[INFO] 2021-07-09 16:45:23,565 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 114
[INFO] 2021-07-09 16:45:23,565 [run_pretraining.py:  558]:	worker_index: 7, step: 114, cost: 7.668801, mlm loss: 7.668801, speed: 0.449138 steps/s, speed: 3.593106 samples/s, speed: 1839.670054 tokens/s, learning rate: 1.130e-06, loss_scalings: 16777.216797, pp_loss: 7.609758
[INFO] 2021-07-09 16:45:23,565 [run_pretraining.py:  512]:	********exe.run_114******* 
[INFO] 2021-07-09 16:45:25,833 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:25,834 [run_pretraining.py:  534]:	loss/total_loss, 7.552278518676758, 115
[INFO] 2021-07-09 16:45:25,834 [run_pretraining.py:  535]:	loss/mlm_loss, 7.552278518676758, 115
[INFO] 2021-07-09 16:45:25,834 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.13999999484804e-06, 115
[INFO] 2021-07-09 16:45:25,834 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 115
[INFO] 2021-07-09 16:45:25,834 [run_pretraining.py:  558]:	worker_index: 7, step: 115, cost: 7.552279, mlm loss: 7.552279, speed: 0.440814 steps/s, speed: 3.526512 samples/s, speed: 1805.574052 tokens/s, learning rate: 1.140e-06, loss_scalings: 16777.216797, pp_loss: 7.559253
[INFO] 2021-07-09 16:45:25,834 [run_pretraining.py:  512]:	********exe.run_115******* 
[INFO] 2021-07-09 16:45:28,052 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:28,052 [run_pretraining.py:  534]:	loss/total_loss, 7.466963768005371, 116
[INFO] 2021-07-09 16:45:28,053 [run_pretraining.py:  535]:	loss/mlm_loss, 7.466963768005371, 116
[INFO] 2021-07-09 16:45:28,053 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.150000002780871e-06, 116
[INFO] 2021-07-09 16:45:28,053 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 116
[INFO] 2021-07-09 16:45:28,053 [run_pretraining.py:  558]:	worker_index: 7, step: 116, cost: 7.466964, mlm loss: 7.466964, speed: 0.450854 steps/s, speed: 3.606836 samples/s, speed: 1846.699868 tokens/s, learning rate: 1.150e-06, loss_scalings: 16777.216797, pp_loss: 7.519307
[INFO] 2021-07-09 16:45:28,053 [run_pretraining.py:  512]:	********exe.run_116******* 
[INFO] 2021-07-09 16:45:30,265 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:30,265 [run_pretraining.py:  534]:	loss/total_loss, 7.498683452606201, 117
[INFO] 2021-07-09 16:45:30,266 [run_pretraining.py:  535]:	loss/mlm_loss, 7.498683452606201, 117
[INFO] 2021-07-09 16:45:30,266 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.160000010713702e-06, 117
[INFO] 2021-07-09 16:45:30,266 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 117
[INFO] 2021-07-09 16:45:30,266 [run_pretraining.py:  558]:	worker_index: 7, step: 117, cost: 7.498683, mlm loss: 7.498683, speed: 0.452007 steps/s, speed: 3.616052 samples/s, speed: 1851.418861 tokens/s, learning rate: 1.160e-06, loss_scalings: 16777.216797, pp_loss: 7.497252
[INFO] 2021-07-09 16:45:30,266 [run_pretraining.py:  512]:	********exe.run_117******* 
[INFO] 2021-07-09 16:45:32,466 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:32,466 [run_pretraining.py:  534]:	loss/total_loss, 7.41059684753418, 118
[INFO] 2021-07-09 16:45:32,466 [run_pretraining.py:  535]:	loss/mlm_loss, 7.41059684753418, 118
[INFO] 2021-07-09 16:45:32,466 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1699999049596954e-06, 118
[INFO] 2021-07-09 16:45:32,466 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 118
[INFO] 2021-07-09 16:45:32,467 [run_pretraining.py:  558]:	worker_index: 7, step: 118, cost: 7.410597, mlm loss: 7.410597, speed: 0.454542 steps/s, speed: 3.636332 samples/s, speed: 1861.802000 tokens/s, learning rate: 1.170e-06, loss_scalings: 16777.216797, pp_loss: 7.430977
[INFO] 2021-07-09 16:45:32,467 [run_pretraining.py:  512]:	********exe.run_118******* 
[INFO] 2021-07-09 16:45:34,699 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:34,699 [run_pretraining.py:  534]:	loss/total_loss, 7.238642692565918, 119
[INFO] 2021-07-09 16:45:34,699 [run_pretraining.py:  535]:	loss/mlm_loss, 7.238642692565918, 119
[INFO] 2021-07-09 16:45:34,699 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1800000265793642e-06, 119
[INFO] 2021-07-09 16:45:34,699 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 119
[INFO] 2021-07-09 16:45:34,700 [run_pretraining.py:  558]:	worker_index: 7, step: 119, cost: 7.238643, mlm loss: 7.238643, speed: 0.447968 steps/s, speed: 3.583745 samples/s, speed: 1834.877613 tokens/s, learning rate: 1.180e-06, loss_scalings: 16777.216797, pp_loss: 7.328646
[INFO] 2021-07-09 16:45:34,700 [run_pretraining.py:  512]:	********exe.run_119******* 
[INFO] 2021-07-09 16:45:36,943 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:36,944 [run_pretraining.py:  534]:	loss/total_loss, 7.24761962890625, 120
[INFO] 2021-07-09 16:45:36,944 [run_pretraining.py:  535]:	loss/mlm_loss, 7.24761962890625, 120
[INFO] 2021-07-09 16:45:36,944 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1900000345121953e-06, 120
[INFO] 2021-07-09 16:45:36,944 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 120
[INFO] 2021-07-09 16:45:36,944 [run_pretraining.py:  558]:	worker_index: 7, step: 120, cost: 7.247620, mlm loss: 7.247620, speed: 0.445629 steps/s, speed: 3.565036 samples/s, speed: 1825.298208 tokens/s, learning rate: 1.190e-06, loss_scalings: 16777.216797, pp_loss: 7.295944
[INFO] 2021-07-09 16:45:36,944 [run_pretraining.py:  512]:	********exe.run_120******* 
[INFO] 2021-07-09 16:45:39,184 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:39,184 [run_pretraining.py:  534]:	loss/total_loss, 7.2099409103393555, 121
[INFO] 2021-07-09 16:45:39,185 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2099409103393555, 121
[INFO] 2021-07-09 16:45:39,185 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1999999287581886e-06, 121
[INFO] 2021-07-09 16:45:39,185 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 121
[INFO] 2021-07-09 16:45:39,185 [run_pretraining.py:  558]:	worker_index: 7, step: 121, cost: 7.209941, mlm loss: 7.209941, speed: 0.446464 steps/s, speed: 3.571710 samples/s, speed: 1828.715651 tokens/s, learning rate: 1.200e-06, loss_scalings: 16777.216797, pp_loss: 7.235887
[INFO] 2021-07-09 16:45:39,185 [run_pretraining.py:  512]:	********exe.run_121******* 
[INFO] 2021-07-09 16:45:41,433 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:41,433 [run_pretraining.py:  534]:	loss/total_loss, 7.258546352386475, 122
[INFO] 2021-07-09 16:45:41,434 [run_pretraining.py:  535]:	loss/mlm_loss, 7.258546352386475, 122
[INFO] 2021-07-09 16:45:41,434 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2099999366910197e-06, 122
[INFO] 2021-07-09 16:45:41,434 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 122
[INFO] 2021-07-09 16:45:41,434 [run_pretraining.py:  558]:	worker_index: 7, step: 122, cost: 7.258546, mlm loss: 7.258546, speed: 0.444769 steps/s, speed: 3.558150 samples/s, speed: 1821.772766 tokens/s, learning rate: 1.210e-06, loss_scalings: 16777.216797, pp_loss: 7.167580
[INFO] 2021-07-09 16:45:41,434 [run_pretraining.py:  512]:	********exe.run_122******* 
[INFO] 2021-07-09 16:45:43,675 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:43,676 [run_pretraining.py:  534]:	loss/total_loss, 7.213738441467285, 123
[INFO] 2021-07-09 16:45:43,676 [run_pretraining.py:  535]:	loss/mlm_loss, 7.213738441467285, 123
[INFO] 2021-07-09 16:45:43,676 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2199999446238508e-06, 123
[INFO] 2021-07-09 16:45:43,676 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 123
[INFO] 2021-07-09 16:45:43,676 [run_pretraining.py:  558]:	worker_index: 7, step: 123, cost: 7.213738, mlm loss: 7.213738, speed: 0.446077 steps/s, speed: 3.568618 samples/s, speed: 1827.132506 tokens/s, learning rate: 1.220e-06, loss_scalings: 16777.216797, pp_loss: 7.105289
[INFO] 2021-07-09 16:45:43,676 [run_pretraining.py:  512]:	********exe.run_123******* 
[INFO] 2021-07-09 16:45:45,911 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:45,911 [run_pretraining.py:  534]:	loss/total_loss, 7.003103256225586, 124
[INFO] 2021-07-09 16:45:45,911 [run_pretraining.py:  535]:	loss/mlm_loss, 7.003103256225586, 124
[INFO] 2021-07-09 16:45:45,912 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2299999525566818e-06, 124
[INFO] 2021-07-09 16:45:45,912 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 124
[INFO] 2021-07-09 16:45:45,912 [run_pretraining.py:  558]:	worker_index: 7, step: 124, cost: 7.003103, mlm loss: 7.003103, speed: 0.447476 steps/s, speed: 3.579809 samples/s, speed: 1832.862296 tokens/s, learning rate: 1.230e-06, loss_scalings: 16777.216797, pp_loss: 7.047206
[INFO] 2021-07-09 16:45:45,912 [run_pretraining.py:  512]:	********exe.run_124******* 
[INFO] 2021-07-09 16:45:48,093 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:48,094 [run_pretraining.py:  534]:	loss/total_loss, 6.963010311126709, 125
[INFO] 2021-07-09 16:45:48,094 [run_pretraining.py:  535]:	loss/mlm_loss, 6.963010311126709, 125
[INFO] 2021-07-09 16:45:48,094 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2399999604895129e-06, 125
[INFO] 2021-07-09 16:45:48,094 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 125
[INFO] 2021-07-09 16:45:48,094 [run_pretraining.py:  558]:	worker_index: 7, step: 125, cost: 6.963010, mlm loss: 6.963010, speed: 0.458329 steps/s, speed: 3.666629 samples/s, speed: 1877.313994 tokens/s, learning rate: 1.240e-06, loss_scalings: 16777.216797, pp_loss: 6.986623
[INFO] 2021-07-09 16:45:48,094 [run_pretraining.py:  512]:	********exe.run_125******* 
[INFO] 2021-07-09 16:45:50,327 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:50,327 [run_pretraining.py:  534]:	loss/total_loss, 6.988441467285156, 126
[INFO] 2021-07-09 16:45:50,328 [run_pretraining.py:  535]:	loss/mlm_loss, 6.988441467285156, 126
[INFO] 2021-07-09 16:45:50,328 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.249999968422344e-06, 126
[INFO] 2021-07-09 16:45:50,328 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 126
[INFO] 2021-07-09 16:45:50,328 [run_pretraining.py:  558]:	worker_index: 7, step: 126, cost: 6.988441, mlm loss: 6.988441, speed: 0.447835 steps/s, speed: 3.582682 samples/s, speed: 1834.332972 tokens/s, learning rate: 1.250e-06, loss_scalings: 16777.216797, pp_loss: 6.931845
[INFO] 2021-07-09 16:45:50,328 [run_pretraining.py:  512]:	********exe.run_126******* 
[INFO] 2021-07-09 16:45:52,570 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:52,570 [run_pretraining.py:  534]:	loss/total_loss, 6.866625785827637, 127
[INFO] 2021-07-09 16:45:52,570 [run_pretraining.py:  535]:	loss/mlm_loss, 6.866625785827637, 127
[INFO] 2021-07-09 16:45:52,570 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.259999976355175e-06, 127
[INFO] 2021-07-09 16:45:52,570 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 127
[INFO] 2021-07-09 16:45:52,570 [run_pretraining.py:  558]:	worker_index: 7, step: 127, cost: 6.866626, mlm loss: 6.866626, speed: 0.446053 steps/s, speed: 3.568425 samples/s, speed: 1827.033796 tokens/s, learning rate: 1.260e-06, loss_scalings: 16777.216797, pp_loss: 6.884792
[INFO] 2021-07-09 16:45:52,571 [run_pretraining.py:  512]:	********exe.run_127******* 
[INFO] 2021-07-09 16:45:54,756 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:54,757 [run_pretraining.py:  534]:	loss/total_loss, 6.767353057861328, 128
[INFO] 2021-07-09 16:45:54,757 [run_pretraining.py:  535]:	loss/mlm_loss, 6.767353057861328, 128
[INFO] 2021-07-09 16:45:54,757 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.269999984288006e-06, 128
[INFO] 2021-07-09 16:45:54,757 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 128
[INFO] 2021-07-09 16:45:54,757 [run_pretraining.py:  558]:	worker_index: 7, step: 128, cost: 6.767353, mlm loss: 6.767353, speed: 0.457499 steps/s, speed: 3.659993 samples/s, speed: 1873.916238 tokens/s, learning rate: 1.270e-06, loss_scalings: 16777.216797, pp_loss: 6.830016
[INFO] 2021-07-09 16:45:54,757 [run_pretraining.py:  512]:	********exe.run_128******* 
[INFO] 2021-07-09 16:45:56,981 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:56,981 [run_pretraining.py:  534]:	loss/total_loss, 6.897403717041016, 129
[INFO] 2021-07-09 16:45:56,981 [run_pretraining.py:  535]:	loss/mlm_loss, 6.897403717041016, 129
[INFO] 2021-07-09 16:45:56,982 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2799998785339994e-06, 129
[INFO] 2021-07-09 16:45:56,982 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 129
[INFO] 2021-07-09 16:45:56,982 [run_pretraining.py:  558]:	worker_index: 7, step: 129, cost: 6.897404, mlm loss: 6.897404, speed: 0.449643 steps/s, speed: 3.597146 samples/s, speed: 1841.738879 tokens/s, learning rate: 1.280e-06, loss_scalings: 16777.216797, pp_loss: 6.782790
[INFO] 2021-07-09 16:45:56,982 [run_pretraining.py:  512]:	********exe.run_129******* 
[INFO] 2021-07-09 16:45:59,243 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:59,243 [run_pretraining.py:  534]:	loss/total_loss, 6.725775241851807, 130
[INFO] 2021-07-09 16:45:59,243 [run_pretraining.py:  535]:	loss/mlm_loss, 6.725775241851807, 130
[INFO] 2021-07-09 16:45:59,243 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2900000001536682e-06, 130
[INFO] 2021-07-09 16:45:59,244 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 130
[INFO] 2021-07-09 16:45:59,244 [run_pretraining.py:  558]:	worker_index: 7, step: 130, cost: 6.725775, mlm loss: 6.725775, speed: 0.442248 steps/s, speed: 3.537983 samples/s, speed: 1811.447272 tokens/s, learning rate: 1.290e-06, loss_scalings: 16777.216797, pp_loss: 6.701249
[INFO] 2021-07-09 16:45:59,244 [run_pretraining.py:  512]:	********exe.run_130******* 
[INFO] 2021-07-09 16:46:01,426 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:01,427 [run_pretraining.py:  534]:	loss/total_loss, 6.556781768798828, 131
[INFO] 2021-07-09 16:46:01,427 [run_pretraining.py:  535]:	loss/mlm_loss, 6.556781768798828, 131
[INFO] 2021-07-09 16:46:01,427 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3000000080864993e-06, 131
[INFO] 2021-07-09 16:46:01,427 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 131
[INFO] 2021-07-09 16:46:01,427 [run_pretraining.py:  558]:	worker_index: 7, step: 131, cost: 6.556782, mlm loss: 6.556782, speed: 0.458144 steps/s, speed: 3.665154 samples/s, speed: 1876.558761 tokens/s, learning rate: 1.300e-06, loss_scalings: 16777.216797, pp_loss: 6.638780
[INFO] 2021-07-09 16:46:01,427 [run_pretraining.py:  512]:	********exe.run_131******* 
[INFO] 2021-07-09 16:46:03,629 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:03,630 [run_pretraining.py:  534]:	loss/total_loss, 6.511734962463379, 132
[INFO] 2021-07-09 16:46:03,630 [run_pretraining.py:  535]:	loss/mlm_loss, 6.511734962463379, 132
[INFO] 2021-07-09 16:46:03,630 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3100000160193304e-06, 132
[INFO] 2021-07-09 16:46:03,630 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 132
[INFO] 2021-07-09 16:46:03,630 [run_pretraining.py:  558]:	worker_index: 7, step: 132, cost: 6.511735, mlm loss: 6.511735, speed: 0.454046 steps/s, speed: 3.632367 samples/s, speed: 1859.772033 tokens/s, learning rate: 1.310e-06, loss_scalings: 16777.216797, pp_loss: 6.526612
[INFO] 2021-07-09 16:46:03,630 [run_pretraining.py:  512]:	********exe.run_132******* 
[INFO] 2021-07-09 16:46:05,961 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:05,962 [run_pretraining.py:  534]:	loss/total_loss, 6.5481462478637695, 133
[INFO] 2021-07-09 16:46:05,962 [run_pretraining.py:  535]:	loss/mlm_loss, 6.5481462478637695, 133
[INFO] 2021-07-09 16:46:05,962 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3199999102653237e-06, 133
[INFO] 2021-07-09 16:46:05,962 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 133
[INFO] 2021-07-09 16:46:05,962 [run_pretraining.py:  558]:	worker_index: 7, step: 133, cost: 6.548146, mlm loss: 6.548146, speed: 0.428993 steps/s, speed: 3.431945 samples/s, speed: 1757.156035 tokens/s, learning rate: 1.320e-06, loss_scalings: 16777.216797, pp_loss: 6.508073
[INFO] 2021-07-09 16:46:05,962 [run_pretraining.py:  512]:	********exe.run_133******* 
[INFO] 2021-07-09 16:46:08,207 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:08,207 [run_pretraining.py:  534]:	loss/total_loss, 6.4378557205200195, 134
[INFO] 2021-07-09 16:46:08,208 [run_pretraining.py:  535]:	loss/mlm_loss, 6.4378557205200195, 134
[INFO] 2021-07-09 16:46:08,208 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3299999181981548e-06, 134
[INFO] 2021-07-09 16:46:08,208 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 134
[INFO] 2021-07-09 16:46:08,208 [run_pretraining.py:  558]:	worker_index: 7, step: 134, cost: 6.437856, mlm loss: 6.437856, speed: 0.445390 steps/s, speed: 3.563118 samples/s, speed: 1824.316474 tokens/s, learning rate: 1.330e-06, loss_scalings: 16777.216797, pp_loss: 6.439960
[INFO] 2021-07-09 16:46:08,208 [run_pretraining.py:  512]:	********exe.run_134******* 
[INFO] 2021-07-09 16:46:10,410 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:10,410 [run_pretraining.py:  534]:	loss/total_loss, 6.347393989562988, 135
[INFO] 2021-07-09 16:46:10,410 [run_pretraining.py:  535]:	loss/mlm_loss, 6.347393989562988, 135
[INFO] 2021-07-09 16:46:10,410 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3399999261309858e-06, 135
[INFO] 2021-07-09 16:46:10,410 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 135
[INFO] 2021-07-09 16:46:10,410 [run_pretraining.py:  558]:	worker_index: 7, step: 135, cost: 6.347394, mlm loss: 6.347394, speed: 0.454162 steps/s, speed: 3.633299 samples/s, speed: 1860.248895 tokens/s, learning rate: 1.340e-06, loss_scalings: 16777.216797, pp_loss: 6.361764
[INFO] 2021-07-09 16:46:10,410 [run_pretraining.py:  512]:	********exe.run_135******* 
[INFO] 2021-07-09 16:46:12,616 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:12,616 [run_pretraining.py:  534]:	loss/total_loss, 6.328293800354004, 136
[INFO] 2021-07-09 16:46:12,616 [run_pretraining.py:  535]:	loss/mlm_loss, 6.328293800354004, 136
[INFO] 2021-07-09 16:46:12,616 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3500000477506546e-06, 136
[INFO] 2021-07-09 16:46:12,617 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 136
[INFO] 2021-07-09 16:46:12,617 [run_pretraining.py:  558]:	worker_index: 7, step: 136, cost: 6.328294, mlm loss: 6.328294, speed: 0.453416 steps/s, speed: 3.627327 samples/s, speed: 1857.191400 tokens/s, learning rate: 1.350e-06, loss_scalings: 16777.216797, pp_loss: 6.344740
[INFO] 2021-07-09 16:46:12,617 [run_pretraining.py:  512]:	********exe.run_136******* 
[INFO] 2021-07-09 16:46:14,845 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:14,846 [run_pretraining.py:  534]:	loss/total_loss, 6.280040264129639, 137
[INFO] 2021-07-09 16:46:14,846 [run_pretraining.py:  535]:	loss/mlm_loss, 6.280040264129639, 137
[INFO] 2021-07-09 16:46:14,846 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.359999941996648e-06, 137
[INFO] 2021-07-09 16:46:14,846 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 137
[INFO] 2021-07-09 16:46:14,846 [run_pretraining.py:  558]:	worker_index: 7, step: 137, cost: 6.280040, mlm loss: 6.280040, speed: 0.448636 steps/s, speed: 3.589085 samples/s, speed: 1837.611376 tokens/s, learning rate: 1.360e-06, loss_scalings: 16777.216797, pp_loss: 6.288786
[INFO] 2021-07-09 16:46:14,846 [run_pretraining.py:  512]:	********exe.run_137******* 
[INFO] 2021-07-09 16:46:17,138 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:17,139 [run_pretraining.py:  534]:	loss/total_loss, 6.225504398345947, 138
[INFO] 2021-07-09 16:46:17,139 [run_pretraining.py:  535]:	loss/mlm_loss, 6.225504398345947, 138
[INFO] 2021-07-09 16:46:17,139 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.369999949929479e-06, 138
[INFO] 2021-07-09 16:46:17,139 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 138
[INFO] 2021-07-09 16:46:17,139 [run_pretraining.py:  558]:	worker_index: 7, step: 138, cost: 6.225504, mlm loss: 6.225504, speed: 0.436217 steps/s, speed: 3.489740 samples/s, speed: 1786.746647 tokens/s, learning rate: 1.370e-06, loss_scalings: 16777.216797, pp_loss: 6.232048
[INFO] 2021-07-09 16:46:17,139 [run_pretraining.py:  512]:	********exe.run_138******* 
[INFO] 2021-07-09 16:46:19,348 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:19,348 [run_pretraining.py:  534]:	loss/total_loss, 6.244582176208496, 139
[INFO] 2021-07-09 16:46:19,349 [run_pretraining.py:  535]:	loss/mlm_loss, 6.244582176208496, 139
[INFO] 2021-07-09 16:46:19,349 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3799999578623101e-06, 139
[INFO] 2021-07-09 16:46:19,349 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 139
[INFO] 2021-07-09 16:46:19,349 [run_pretraining.py:  558]:	worker_index: 7, step: 139, cost: 6.244582, mlm loss: 6.244582, speed: 0.452764 steps/s, speed: 3.622109 samples/s, speed: 1854.519820 tokens/s, learning rate: 1.380e-06, loss_scalings: 16777.216797, pp_loss: 6.185924
[INFO] 2021-07-09 16:46:19,349 [run_pretraining.py:  512]:	********exe.run_139******* 
[INFO] 2021-07-09 16:46:21,475 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:21,475 [run_pretraining.py:  534]:	loss/total_loss, 6.211629867553711, 140
[INFO] 2021-07-09 16:46:21,476 [run_pretraining.py:  535]:	loss/mlm_loss, 6.211629867553711, 140
[INFO] 2021-07-09 16:46:21,476 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3899999657951412e-06, 140
[INFO] 2021-07-09 16:46:21,476 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 140
[INFO] 2021-07-09 16:46:21,476 [run_pretraining.py:  558]:	worker_index: 7, step: 140, cost: 6.211630, mlm loss: 6.211630, speed: 0.470275 steps/s, speed: 3.762198 samples/s, speed: 1926.245233 tokens/s, learning rate: 1.390e-06, loss_scalings: 16777.216797, pp_loss: 6.110242
[INFO] 2021-07-09 16:46:21,476 [run_pretraining.py:  512]:	********exe.run_140******* 
[INFO] 2021-07-09 16:46:23,565 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:23,565 [run_pretraining.py:  534]:	loss/total_loss, 6.112656593322754, 141
[INFO] 2021-07-09 16:46:23,565 [run_pretraining.py:  535]:	loss/mlm_loss, 6.112656593322754, 141
[INFO] 2021-07-09 16:46:23,565 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3999999737279722e-06, 141
[INFO] 2021-07-09 16:46:23,565 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 141
[INFO] 2021-07-09 16:46:23,565 [run_pretraining.py:  558]:	worker_index: 7, step: 141, cost: 6.112657, mlm loss: 6.112657, speed: 0.478731 steps/s, speed: 3.829849 samples/s, speed: 1960.882850 tokens/s, learning rate: 1.400e-06, loss_scalings: 16777.216797, pp_loss: 6.066692
[INFO] 2021-07-09 16:46:23,565 [run_pretraining.py:  512]:	********exe.run_141******* 
[INFO] 2021-07-09 16:46:25,669 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:25,669 [run_pretraining.py:  534]:	loss/total_loss, 5.962260723114014, 142
[INFO] 2021-07-09 16:46:25,670 [run_pretraining.py:  535]:	loss/mlm_loss, 5.962260723114014, 142
[INFO] 2021-07-09 16:46:25,670 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4099999816608033e-06, 142
[INFO] 2021-07-09 16:46:25,670 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 142
[INFO] 2021-07-09 16:46:25,670 [run_pretraining.py:  558]:	worker_index: 7, step: 142, cost: 5.962261, mlm loss: 5.962261, speed: 0.475322 steps/s, speed: 3.802572 samples/s, speed: 1946.916894 tokens/s, learning rate: 1.410e-06, loss_scalings: 16777.216797, pp_loss: 5.982706
[INFO] 2021-07-09 16:46:25,670 [run_pretraining.py:  512]:	********exe.run_142******* 
[INFO] 2021-07-09 16:46:27,904 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:27,905 [run_pretraining.py:  534]:	loss/total_loss, 6.068926811218262, 143
[INFO] 2021-07-09 16:46:27,905 [run_pretraining.py:  535]:	loss/mlm_loss, 6.068926811218262, 143
[INFO] 2021-07-09 16:46:27,905 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4199999895936344e-06, 143
[INFO] 2021-07-09 16:46:27,905 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 143
[INFO] 2021-07-09 16:46:27,905 [run_pretraining.py:  558]:	worker_index: 7, step: 143, cost: 6.068927, mlm loss: 6.068927, speed: 0.447528 steps/s, speed: 3.580227 samples/s, speed: 1833.076048 tokens/s, learning rate: 1.420e-06, loss_scalings: 16777.216797, pp_loss: 6.009942
[INFO] 2021-07-09 16:46:27,905 [run_pretraining.py:  512]:	********exe.run_143******* 
[INFO] 2021-07-09 16:46:29,996 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:29,996 [run_pretraining.py:  534]:	loss/total_loss, 5.9077935218811035, 144
[INFO] 2021-07-09 16:46:29,996 [run_pretraining.py:  535]:	loss/mlm_loss, 5.9077935218811035, 144
[INFO] 2021-07-09 16:46:29,997 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4299999975264654e-06, 144
[INFO] 2021-07-09 16:46:29,997 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 144
[INFO] 2021-07-09 16:46:29,997 [run_pretraining.py:  558]:	worker_index: 7, step: 144, cost: 5.907794, mlm loss: 5.907794, speed: 0.478216 steps/s, speed: 3.825725 samples/s, speed: 1958.771445 tokens/s, learning rate: 1.430e-06, loss_scalings: 16777.216797, pp_loss: 5.876893
[INFO] 2021-07-09 16:46:29,997 [run_pretraining.py:  512]:	********exe.run_144******* 
[INFO] 2021-07-09 16:46:32,134 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:32,135 [run_pretraining.py:  534]:	loss/total_loss, 5.856168270111084, 145
[INFO] 2021-07-09 16:46:32,135 [run_pretraining.py:  535]:	loss/mlm_loss, 5.856168270111084, 145
[INFO] 2021-07-09 16:46:32,135 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4399998917724588e-06, 145
[INFO] 2021-07-09 16:46:32,135 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 145
[INFO] 2021-07-09 16:46:32,135 [run_pretraining.py:  558]:	worker_index: 7, step: 145, cost: 5.856168, mlm loss: 5.856168, speed: 0.467727 steps/s, speed: 3.741817 samples/s, speed: 1915.810225 tokens/s, learning rate: 1.440e-06, loss_scalings: 16777.216797, pp_loss: 5.828131
[INFO] 2021-07-09 16:46:32,135 [run_pretraining.py:  512]:	********exe.run_145******* 
[INFO] 2021-07-09 16:46:34,243 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:34,244 [run_pretraining.py:  534]:	loss/total_loss, 5.787745475769043, 146
[INFO] 2021-07-09 16:46:34,244 [run_pretraining.py:  535]:	loss/mlm_loss, 5.787745475769043, 146
[INFO] 2021-07-09 16:46:34,244 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4499998997052899e-06, 146
[INFO] 2021-07-09 16:46:34,244 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 146
[INFO] 2021-07-09 16:46:34,244 [run_pretraining.py:  558]:	worker_index: 7, step: 146, cost: 5.787745, mlm loss: 5.787745, speed: 0.474383 steps/s, speed: 3.795063 samples/s, speed: 1943.072429 tokens/s, learning rate: 1.450e-06, loss_scalings: 16777.216797, pp_loss: 5.802719
[INFO] 2021-07-09 16:46:34,244 [run_pretraining.py:  512]:	********exe.run_146******* 
[INFO] 2021-07-09 16:46:36,448 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:36,448 [run_pretraining.py:  534]:	loss/total_loss, 5.781486511230469, 147
[INFO] 2021-07-09 16:46:36,449 [run_pretraining.py:  535]:	loss/mlm_loss, 5.781486511230469, 147
[INFO] 2021-07-09 16:46:36,449 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4600000213249587e-06, 147
[INFO] 2021-07-09 16:46:36,449 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 147
[INFO] 2021-07-09 16:46:36,449 [run_pretraining.py:  558]:	worker_index: 7, step: 147, cost: 5.781487, mlm loss: 5.781487, speed: 0.453706 steps/s, speed: 3.629650 samples/s, speed: 1858.380705 tokens/s, learning rate: 1.460e-06, loss_scalings: 16777.216797, pp_loss: 5.748224
[INFO] 2021-07-09 16:46:36,449 [run_pretraining.py:  512]:	********exe.run_147******* 
[INFO] 2021-07-09 16:46:38,656 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:38,656 [run_pretraining.py:  534]:	loss/total_loss, 5.733007431030273, 148
[INFO] 2021-07-09 16:46:38,656 [run_pretraining.py:  535]:	loss/mlm_loss, 5.733007431030273, 148
[INFO] 2021-07-09 16:46:38,657 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4700000292577897e-06, 148
[INFO] 2021-07-09 16:46:38,657 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 148
[INFO] 2021-07-09 16:46:38,657 [run_pretraining.py:  558]:	worker_index: 7, step: 148, cost: 5.733007, mlm loss: 5.733007, speed: 0.453055 steps/s, speed: 3.624439 samples/s, speed: 1855.712721 tokens/s, learning rate: 1.470e-06, loss_scalings: 16777.216797, pp_loss: 5.706322
[INFO] 2021-07-09 16:46:38,657 [run_pretraining.py:  512]:	********exe.run_148******* 
[INFO] 2021-07-09 16:46:40,942 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:40,942 [run_pretraining.py:  534]:	loss/total_loss, 5.604987144470215, 149
[INFO] 2021-07-09 16:46:40,942 [run_pretraining.py:  535]:	loss/mlm_loss, 5.604987144470215, 149
[INFO] 2021-07-09 16:46:40,942 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.479999923503783e-06, 149
[INFO] 2021-07-09 16:46:40,943 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 149
[INFO] 2021-07-09 16:46:40,943 [run_pretraining.py:  558]:	worker_index: 7, step: 149, cost: 5.604987, mlm loss: 5.604987, speed: 0.437593 steps/s, speed: 3.500741 samples/s, speed: 1792.379635 tokens/s, learning rate: 1.480e-06, loss_scalings: 16777.216797, pp_loss: 5.634169
[INFO] 2021-07-09 16:46:40,943 [run_pretraining.py:  512]:	********exe.run_149******* 
[INFO] 2021-07-09 16:46:43,177 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:43,177 [run_pretraining.py:  534]:	loss/total_loss, 5.683920860290527, 150
[INFO] 2021-07-09 16:46:43,177 [run_pretraining.py:  535]:	loss/mlm_loss, 5.683920860290527, 150
[INFO] 2021-07-09 16:46:43,178 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4899999314366141e-06, 150
[INFO] 2021-07-09 16:46:43,178 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 150
[INFO] 2021-07-09 16:46:43,178 [run_pretraining.py:  558]:	worker_index: 7, step: 150, cost: 5.683921, mlm loss: 5.683921, speed: 0.447542 steps/s, speed: 3.580340 samples/s, speed: 1833.133944 tokens/s, learning rate: 1.490e-06, loss_scalings: 16777.216797, pp_loss: 5.601435
[INFO] 2021-07-09 16:46:43,178 [run_pretraining.py:  512]:	********exe.run_150******* 
[INFO] 2021-07-09 16:46:45,409 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:45,410 [run_pretraining.py:  534]:	loss/total_loss, 5.4801459312438965, 151
[INFO] 2021-07-09 16:46:45,410 [run_pretraining.py:  535]:	loss/mlm_loss, 5.4801459312438965, 151
[INFO] 2021-07-09 16:46:45,410 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4999999393694452e-06, 151
[INFO] 2021-07-09 16:46:45,410 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 151
[INFO] 2021-07-09 16:46:45,410 [run_pretraining.py:  558]:	worker_index: 7, step: 151, cost: 5.480146, mlm loss: 5.480146, speed: 0.448044 steps/s, speed: 3.584352 samples/s, speed: 1835.188478 tokens/s, learning rate: 1.500e-06, loss_scalings: 16777.216797, pp_loss: 5.553101
[INFO] 2021-07-09 16:46:45,410 [run_pretraining.py:  512]:	********exe.run_151******* 
[INFO] 2021-07-09 16:46:47,610 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:47,610 [run_pretraining.py:  534]:	loss/total_loss, 5.430719375610352, 152
[INFO] 2021-07-09 16:46:47,610 [run_pretraining.py:  535]:	loss/mlm_loss, 5.430719375610352, 152
[INFO] 2021-07-09 16:46:47,610 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.510000060989114e-06, 152
[INFO] 2021-07-09 16:46:47,611 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 152
[INFO] 2021-07-09 16:46:47,611 [run_pretraining.py:  558]:	worker_index: 7, step: 152, cost: 5.430719, mlm loss: 5.430719, speed: 0.454632 steps/s, speed: 3.637054 samples/s, speed: 1862.171708 tokens/s, learning rate: 1.510e-06, loss_scalings: 16777.216797, pp_loss: 5.462882
[INFO] 2021-07-09 16:46:47,611 [run_pretraining.py:  512]:	********exe.run_152******* 
[INFO] 2021-07-09 16:46:49,802 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:49,803 [run_pretraining.py:  534]:	loss/total_loss, 5.500896453857422, 153
[INFO] 2021-07-09 16:46:49,803 [run_pretraining.py:  535]:	loss/mlm_loss, 5.500896453857422, 153
[INFO] 2021-07-09 16:46:49,803 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5199999552351073e-06, 153
[INFO] 2021-07-09 16:46:49,803 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 153
[INFO] 2021-07-09 16:46:49,803 [run_pretraining.py:  558]:	worker_index: 7, step: 153, cost: 5.500896, mlm loss: 5.500896, speed: 0.456275 steps/s, speed: 3.650201 samples/s, speed: 1868.902882 tokens/s, learning rate: 1.520e-06, loss_scalings: 16777.216797, pp_loss: 5.436893
[INFO] 2021-07-09 16:46:49,803 [run_pretraining.py:  512]:	********exe.run_153******* 
[INFO] 2021-07-09 16:46:52,054 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:52,055 [run_pretraining.py:  534]:	loss/total_loss, 5.3848137855529785, 154
[INFO] 2021-07-09 16:46:52,055 [run_pretraining.py:  535]:	loss/mlm_loss, 5.3848137855529785, 154
[INFO] 2021-07-09 16:46:52,055 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5299999631679384e-06, 154
[INFO] 2021-07-09 16:46:52,055 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 154
[INFO] 2021-07-09 16:46:52,055 [run_pretraining.py:  558]:	worker_index: 7, step: 154, cost: 5.384814, mlm loss: 5.384814, speed: 0.444178 steps/s, speed: 3.553423 samples/s, speed: 1819.352700 tokens/s, learning rate: 1.530e-06, loss_scalings: 16777.216797, pp_loss: 5.372605
[INFO] 2021-07-09 16:46:52,055 [run_pretraining.py:  512]:	********exe.run_154******* 
[INFO] 2021-07-09 16:46:54,317 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:54,318 [run_pretraining.py:  534]:	loss/total_loss, 5.323955535888672, 155
[INFO] 2021-07-09 16:46:54,318 [run_pretraining.py:  535]:	loss/mlm_loss, 5.323955535888672, 155
[INFO] 2021-07-09 16:46:54,318 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5399999711007695e-06, 155
[INFO] 2021-07-09 16:46:54,318 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 155
[INFO] 2021-07-09 16:46:54,318 [run_pretraining.py:  558]:	worker_index: 7, step: 155, cost: 5.323956, mlm loss: 5.323956, speed: 0.442004 steps/s, speed: 3.536034 samples/s, speed: 1810.449470 tokens/s, learning rate: 1.540e-06, loss_scalings: 16777.216797, pp_loss: 5.291855
[INFO] 2021-07-09 16:46:54,318 [run_pretraining.py:  512]:	********exe.run_155******* 
[INFO] 2021-07-09 16:46:56,507 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:56,508 [run_pretraining.py:  534]:	loss/total_loss, 5.207555294036865, 156
[INFO] 2021-07-09 16:46:56,508 [run_pretraining.py:  535]:	loss/mlm_loss, 5.207555294036865, 156
[INFO] 2021-07-09 16:46:56,508 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5499999790336005e-06, 156
[INFO] 2021-07-09 16:46:56,508 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 156
[INFO] 2021-07-09 16:46:56,508 [run_pretraining.py:  558]:	worker_index: 7, step: 156, cost: 5.207555, mlm loss: 5.207555, speed: 0.456711 steps/s, speed: 3.653686 samples/s, speed: 1870.687389 tokens/s, learning rate: 1.550e-06, loss_scalings: 16777.216797, pp_loss: 5.280980
[INFO] 2021-07-09 16:46:56,508 [run_pretraining.py:  512]:	********exe.run_156******* 
[INFO] 2021-07-09 16:46:58,698 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:58,699 [run_pretraining.py:  534]:	loss/total_loss, 5.201254844665527, 157
[INFO] 2021-07-09 16:46:58,699 [run_pretraining.py:  535]:	loss/mlm_loss, 5.201254844665527, 157
[INFO] 2021-07-09 16:46:58,699 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5599998732795939e-06, 157
[INFO] 2021-07-09 16:46:58,699 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 157
[INFO] 2021-07-09 16:46:58,699 [run_pretraining.py:  558]:	worker_index: 7, step: 157, cost: 5.201255, mlm loss: 5.201255, speed: 0.456532 steps/s, speed: 3.652255 samples/s, speed: 1869.954574 tokens/s, learning rate: 1.560e-06, loss_scalings: 16777.216797, pp_loss: 5.207503
[INFO] 2021-07-09 16:46:58,699 [run_pretraining.py:  512]:	********exe.run_157******* 
[INFO] 2021-07-09 16:47:00,902 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:00,902 [run_pretraining.py:  534]:	loss/total_loss, 5.181203365325928, 158
[INFO] 2021-07-09 16:47:00,903 [run_pretraining.py:  535]:	loss/mlm_loss, 5.181203365325928, 158
[INFO] 2021-07-09 16:47:00,903 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.569999881212425e-06, 158
[INFO] 2021-07-09 16:47:00,903 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 158
[INFO] 2021-07-09 16:47:00,903 [run_pretraining.py:  558]:	worker_index: 7, step: 158, cost: 5.181203, mlm loss: 5.181203, speed: 0.453959 steps/s, speed: 3.631673 samples/s, speed: 1859.416358 tokens/s, learning rate: 1.570e-06, loss_scalings: 16777.216797, pp_loss: 5.172811
[INFO] 2021-07-09 16:47:00,903 [run_pretraining.py:  512]:	********exe.run_158******* 
[INFO] 2021-07-09 16:47:03,115 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:03,115 [run_pretraining.py:  534]:	loss/total_loss, 4.985171318054199, 159
[INFO] 2021-07-09 16:47:03,116 [run_pretraining.py:  535]:	loss/mlm_loss, 4.985171318054199, 159
[INFO] 2021-07-09 16:47:03,116 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.579999889145256e-06, 159
[INFO] 2021-07-09 16:47:03,116 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 159
[INFO] 2021-07-09 16:47:03,116 [run_pretraining.py:  558]:	worker_index: 7, step: 159, cost: 4.985171, mlm loss: 4.985171, speed: 0.452028 steps/s, speed: 3.616226 samples/s, speed: 1851.507852 tokens/s, learning rate: 1.580e-06, loss_scalings: 16777.216797, pp_loss: 5.063117
[INFO] 2021-07-09 16:47:03,116 [run_pretraining.py:  512]:	********exe.run_159******* 
[INFO] 2021-07-09 16:47:05,341 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:05,342 [run_pretraining.py:  534]:	loss/total_loss, 5.118805408477783, 160
[INFO] 2021-07-09 16:47:05,342 [run_pretraining.py:  535]:	loss/mlm_loss, 5.118805408477783, 160
[INFO] 2021-07-09 16:47:05,342 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5900000107649248e-06, 160
[INFO] 2021-07-09 16:47:05,342 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 160
[INFO] 2021-07-09 16:47:05,342 [run_pretraining.py:  558]:	worker_index: 7, step: 160, cost: 5.118805, mlm loss: 5.118805, speed: 0.449354 steps/s, speed: 3.594830 samples/s, speed: 1840.552828 tokens/s, learning rate: 1.590e-06, loss_scalings: 16777.216797, pp_loss: 5.075975
[INFO] 2021-07-09 16:47:05,342 [run_pretraining.py:  512]:	********exe.run_160******* 
[INFO] 2021-07-09 16:47:07,610 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:07,611 [run_pretraining.py:  534]:	loss/total_loss, 4.970727443695068, 161
[INFO] 2021-07-09 16:47:07,611 [run_pretraining.py:  535]:	loss/mlm_loss, 4.970727443695068, 161
[INFO] 2021-07-09 16:47:07,611 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6000000186977559e-06, 161
[INFO] 2021-07-09 16:47:07,611 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 161
[INFO] 2021-07-09 16:47:07,611 [run_pretraining.py:  558]:	worker_index: 7, step: 161, cost: 4.970727, mlm loss: 4.970727, speed: 0.440823 steps/s, speed: 3.526586 samples/s, speed: 1805.612005 tokens/s, learning rate: 1.600e-06, loss_scalings: 16777.216797, pp_loss: 4.997908
[INFO] 2021-07-09 16:47:07,611 [run_pretraining.py:  512]:	********exe.run_161******* 
[INFO] 2021-07-09 16:47:09,832 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:09,833 [run_pretraining.py:  534]:	loss/total_loss, 4.921484470367432, 162
[INFO] 2021-07-09 16:47:09,833 [run_pretraining.py:  535]:	loss/mlm_loss, 4.921484470367432, 162
[INFO] 2021-07-09 16:47:09,833 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.610000026630587e-06, 162
[INFO] 2021-07-09 16:47:09,833 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 162
[INFO] 2021-07-09 16:47:09,833 [run_pretraining.py:  558]:	worker_index: 7, step: 162, cost: 4.921484, mlm loss: 4.921484, speed: 0.450187 steps/s, speed: 3.601498 samples/s, speed: 1843.966725 tokens/s, learning rate: 1.610e-06, loss_scalings: 16777.216797, pp_loss: 4.942198
[INFO] 2021-07-09 16:47:09,833 [run_pretraining.py:  512]:	********exe.run_162******* 
[INFO] 2021-07-09 16:47:12,118 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:12,119 [run_pretraining.py:  534]:	loss/total_loss, 4.935783386230469, 163
[INFO] 2021-07-09 16:47:12,119 [run_pretraining.py:  535]:	loss/mlm_loss, 4.935783386230469, 163
[INFO] 2021-07-09 16:47:12,119 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.620000034563418e-06, 163
[INFO] 2021-07-09 16:47:12,119 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 163
[INFO] 2021-07-09 16:47:12,119 [run_pretraining.py:  558]:	worker_index: 7, step: 163, cost: 4.935783, mlm loss: 4.935783, speed: 0.437544 steps/s, speed: 3.500351 samples/s, speed: 1792.179755 tokens/s, learning rate: 1.620e-06, loss_scalings: 16777.216797, pp_loss: 4.907208
[INFO] 2021-07-09 16:47:12,119 [run_pretraining.py:  512]:	********exe.run_163******* 
[INFO] 2021-07-09 16:47:14,684 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:14,685 [run_pretraining.py:  534]:	loss/total_loss, 4.889350891113281, 164
[INFO] 2021-07-09 16:47:14,685 [run_pretraining.py:  535]:	loss/mlm_loss, 4.889350891113281, 164
[INFO] 2021-07-09 16:47:14,685 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6299999288094114e-06, 164
[INFO] 2021-07-09 16:47:14,685 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 164
[INFO] 2021-07-09 16:47:14,685 [run_pretraining.py:  558]:	worker_index: 7, step: 164, cost: 4.889351, mlm loss: 4.889351, speed: 0.389818 steps/s, speed: 3.118546 samples/s, speed: 1596.695390 tokens/s, learning rate: 1.630e-06, loss_scalings: 16777.216797, pp_loss: 4.851511
[INFO] 2021-07-09 16:47:14,685 [run_pretraining.py:  512]:	********exe.run_164******* 
[INFO] 2021-07-09 16:47:17,092 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:17,092 [run_pretraining.py:  534]:	loss/total_loss, 4.760530948638916, 165
[INFO] 2021-07-09 16:47:17,093 [run_pretraining.py:  535]:	loss/mlm_loss, 4.760530948638916, 165
[INFO] 2021-07-09 16:47:17,093 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6399999367422424e-06, 165
[INFO] 2021-07-09 16:47:17,093 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 165
[INFO] 2021-07-09 16:47:17,093 [run_pretraining.py:  558]:	worker_index: 7, step: 165, cost: 4.760531, mlm loss: 4.760531, speed: 0.415449 steps/s, speed: 3.323595 samples/s, speed: 1701.680564 tokens/s, learning rate: 1.640e-06, loss_scalings: 16777.216797, pp_loss: 4.789955
[INFO] 2021-07-09 16:47:17,093 [run_pretraining.py:  512]:	********exe.run_165******* 
[INFO] 2021-07-09 16:47:19,377 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:19,377 [run_pretraining.py:  534]:	loss/total_loss, 4.774728775024414, 166
[INFO] 2021-07-09 16:47:19,377 [run_pretraining.py:  535]:	loss/mlm_loss, 4.774728775024414, 166
[INFO] 2021-07-09 16:47:19,377 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6499999446750735e-06, 166
[INFO] 2021-07-09 16:47:19,377 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 166
[INFO] 2021-07-09 16:47:19,377 [run_pretraining.py:  558]:	worker_index: 7, step: 166, cost: 4.774729, mlm loss: 4.774729, speed: 0.437841 steps/s, speed: 3.502730 samples/s, speed: 1793.397864 tokens/s, learning rate: 1.650e-06, loss_scalings: 16777.216797, pp_loss: 4.768930
[INFO] 2021-07-09 16:47:19,378 [run_pretraining.py:  512]:	********exe.run_166******* 
[INFO] 2021-07-09 16:47:21,633 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:21,633 [run_pretraining.py:  534]:	loss/total_loss, 4.711991310119629, 167
[INFO] 2021-07-09 16:47:21,633 [run_pretraining.py:  535]:	loss/mlm_loss, 4.711991310119629, 167
[INFO] 2021-07-09 16:47:21,633 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6599999526079046e-06, 167
[INFO] 2021-07-09 16:47:21,633 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 167
[INFO] 2021-07-09 16:47:21,633 [run_pretraining.py:  558]:	worker_index: 7, step: 167, cost: 4.711991, mlm loss: 4.711991, speed: 0.443398 steps/s, speed: 3.547186 samples/s, speed: 1816.159224 tokens/s, learning rate: 1.660e-06, loss_scalings: 16777.216797, pp_loss: 4.696985
[INFO] 2021-07-09 16:47:21,634 [run_pretraining.py:  512]:	********exe.run_167******* 
[INFO] 2021-07-09 16:47:23,826 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:23,827 [run_pretraining.py:  534]:	loss/total_loss, 4.631738662719727, 168
[INFO] 2021-07-09 16:47:23,827 [run_pretraining.py:  535]:	loss/mlm_loss, 4.631738662719727, 168
[INFO] 2021-07-09 16:47:23,827 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6699999605407356e-06, 168
[INFO] 2021-07-09 16:47:23,827 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 168
[INFO] 2021-07-09 16:47:23,827 [run_pretraining.py:  558]:	worker_index: 7, step: 168, cost: 4.631739, mlm loss: 4.631739, speed: 0.455992 steps/s, speed: 3.647938 samples/s, speed: 1867.744341 tokens/s, learning rate: 1.670e-06, loss_scalings: 16777.216797, pp_loss: 4.669035
[INFO] 2021-07-09 16:47:23,827 [run_pretraining.py:  512]:	********exe.run_168******* 
[INFO] 2021-07-09 16:47:26,043 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:26,043 [run_pretraining.py:  534]:	loss/total_loss, 4.6454973220825195, 169
[INFO] 2021-07-09 16:47:26,044 [run_pretraining.py:  535]:	loss/mlm_loss, 4.6454973220825195, 169
[INFO] 2021-07-09 16:47:26,044 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.679999854786729e-06, 169
[INFO] 2021-07-09 16:47:26,044 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 169
[INFO] 2021-07-09 16:47:26,044 [run_pretraining.py:  558]:	worker_index: 7, step: 169, cost: 4.645497, mlm loss: 4.645497, speed: 0.451245 steps/s, speed: 3.609963 samples/s, speed: 1848.300813 tokens/s, learning rate: 1.680e-06, loss_scalings: 16777.216797, pp_loss: 4.605286
[INFO] 2021-07-09 16:47:26,044 [run_pretraining.py:  512]:	********exe.run_169******* 
[INFO] 2021-07-09 16:47:28,226 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:28,226 [run_pretraining.py:  534]:	loss/total_loss, 4.617447853088379, 170
[INFO] 2021-07-09 16:47:28,226 [run_pretraining.py:  535]:	loss/mlm_loss, 4.617447853088379, 170
[INFO] 2021-07-09 16:47:28,226 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.68999986271956e-06, 170
[INFO] 2021-07-09 16:47:28,226 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 170
[INFO] 2021-07-09 16:47:28,226 [run_pretraining.py:  558]:	worker_index: 7, step: 170, cost: 4.617448, mlm loss: 4.617448, speed: 0.458288 steps/s, speed: 3.666304 samples/s, speed: 1877.147844 tokens/s, learning rate: 1.690e-06, loss_scalings: 16777.216797, pp_loss: 4.553151
[INFO] 2021-07-09 16:47:28,227 [run_pretraining.py:  512]:	********exe.run_170******* 
[INFO] 2021-07-09 16:47:30,415 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:30,416 [run_pretraining.py:  534]:	loss/total_loss, 4.511545658111572, 171
[INFO] 2021-07-09 16:47:30,416 [run_pretraining.py:  535]:	loss/mlm_loss, 4.511545658111572, 171
[INFO] 2021-07-09 16:47:30,416 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7000000980260666e-06, 171
[INFO] 2021-07-09 16:47:30,416 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 171
[INFO] 2021-07-09 16:47:30,416 [run_pretraining.py:  558]:	worker_index: 7, step: 171, cost: 4.511546, mlm loss: 4.511546, speed: 0.456828 steps/s, speed: 3.654626 samples/s, speed: 1871.168642 tokens/s, learning rate: 1.700e-06, loss_scalings: 16777.216797, pp_loss: 4.501187
[INFO] 2021-07-09 16:47:30,416 [run_pretraining.py:  512]:	********exe.run_171******* 
[INFO] 2021-07-09 16:47:32,605 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:32,605 [run_pretraining.py:  534]:	loss/total_loss, 4.423030376434326, 172
[INFO] 2021-07-09 16:47:32,605 [run_pretraining.py:  535]:	loss/mlm_loss, 4.423030376434326, 172
[INFO] 2021-07-09 16:47:32,605 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.70999999227206e-06, 172
[INFO] 2021-07-09 16:47:32,605 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 172
[INFO] 2021-07-09 16:47:32,605 [run_pretraining.py:  558]:	worker_index: 7, step: 172, cost: 4.423030, mlm loss: 4.423030, speed: 0.456902 steps/s, speed: 3.655214 samples/s, speed: 1871.469501 tokens/s, learning rate: 1.710e-06, loss_scalings: 16777.216797, pp_loss: 4.445142
[INFO] 2021-07-09 16:47:32,605 [run_pretraining.py:  512]:	********exe.run_172******* 
[INFO] 2021-07-09 16:47:34,807 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:34,808 [run_pretraining.py:  534]:	loss/total_loss, 4.406189918518066, 173
[INFO] 2021-07-09 16:47:34,808 [run_pretraining.py:  535]:	loss/mlm_loss, 4.406189918518066, 173
[INFO] 2021-07-09 16:47:34,808 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.720000000204891e-06, 173
[INFO] 2021-07-09 16:47:34,808 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 173
[INFO] 2021-07-09 16:47:34,808 [run_pretraining.py:  558]:	worker_index: 7, step: 173, cost: 4.406190, mlm loss: 4.406190, speed: 0.454137 steps/s, speed: 3.633098 samples/s, speed: 1860.146171 tokens/s, learning rate: 1.720e-06, loss_scalings: 16777.216797, pp_loss: 4.414934
[INFO] 2021-07-09 16:47:34,808 [run_pretraining.py:  512]:	********exe.run_173******* 
[INFO] 2021-07-09 16:47:37,083 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:37,083 [run_pretraining.py:  534]:	loss/total_loss, 4.391135215759277, 174
[INFO] 2021-07-09 16:47:37,083 [run_pretraining.py:  535]:	loss/mlm_loss, 4.391135215759277, 174
[INFO] 2021-07-09 16:47:37,083 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.730000008137722e-06, 174
[INFO] 2021-07-09 16:47:37,084 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 174
[INFO] 2021-07-09 16:47:37,084 [run_pretraining.py:  558]:	worker_index: 7, step: 174, cost: 4.391135, mlm loss: 4.391135, speed: 0.439588 steps/s, speed: 3.516708 samples/s, speed: 1800.554401 tokens/s, learning rate: 1.730e-06, loss_scalings: 16777.216797, pp_loss: 4.371505
[INFO] 2021-07-09 16:47:37,084 [run_pretraining.py:  512]:	********exe.run_174******* 
[INFO] 2021-07-09 16:47:39,295 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:39,296 [run_pretraining.py:  534]:	loss/total_loss, 4.294869422912598, 175
[INFO] 2021-07-09 16:47:39,296 [run_pretraining.py:  535]:	loss/mlm_loss, 4.294869422912598, 175
[INFO] 2021-07-09 16:47:39,296 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.740000016070553e-06, 175
[INFO] 2021-07-09 16:47:39,296 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 175
[INFO] 2021-07-09 16:47:39,296 [run_pretraining.py:  558]:	worker_index: 7, step: 175, cost: 4.294869, mlm loss: 4.294869, speed: 0.452080 steps/s, speed: 3.616637 samples/s, speed: 1851.718391 tokens/s, learning rate: 1.740e-06, loss_scalings: 16777.216797, pp_loss: 4.293077
[INFO] 2021-07-09 16:47:39,296 [run_pretraining.py:  512]:	********exe.run_175******* 
[INFO] 2021-07-09 16:47:41,616 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:41,616 [run_pretraining.py:  534]:	loss/total_loss, 4.270342826843262, 176
[INFO] 2021-07-09 16:47:41,617 [run_pretraining.py:  535]:	loss/mlm_loss, 4.270342826843262, 176
[INFO] 2021-07-09 16:47:41,617 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7499999103165464e-06, 176
[INFO] 2021-07-09 16:47:41,617 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 176
[INFO] 2021-07-09 16:47:41,617 [run_pretraining.py:  558]:	worker_index: 7, step: 176, cost: 4.270343, mlm loss: 4.270343, speed: 0.431059 steps/s, speed: 3.448470 samples/s, speed: 1765.616543 tokens/s, learning rate: 1.750e-06, loss_scalings: 16777.216797, pp_loss: 4.292032
[INFO] 2021-07-09 16:47:41,617 [run_pretraining.py:  512]:	********exe.run_176******* 
[INFO] 2021-07-09 16:47:43,831 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:43,831 [run_pretraining.py:  534]:	loss/total_loss, 4.259945869445801, 177
[INFO] 2021-07-09 16:47:43,831 [run_pretraining.py:  535]:	loss/mlm_loss, 4.259945869445801, 177
[INFO] 2021-07-09 16:47:43,831 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7599999182493775e-06, 177
[INFO] 2021-07-09 16:47:43,831 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 177
[INFO] 2021-07-09 16:47:43,832 [run_pretraining.py:  558]:	worker_index: 7, step: 177, cost: 4.259946, mlm loss: 4.259946, speed: 0.451672 steps/s, speed: 3.613378 samples/s, speed: 1850.049561 tokens/s, learning rate: 1.760e-06, loss_scalings: 16777.216797, pp_loss: 4.245936
[INFO] 2021-07-09 16:47:43,832 [run_pretraining.py:  512]:	********exe.run_177******* 
[INFO] 2021-07-09 16:47:46,076 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:46,077 [run_pretraining.py:  534]:	loss/total_loss, 4.176925182342529, 178
[INFO] 2021-07-09 16:47:46,077 [run_pretraining.py:  535]:	loss/mlm_loss, 4.176925182342529, 178
[INFO] 2021-07-09 16:47:46,077 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7699999261822086e-06, 178
[INFO] 2021-07-09 16:47:46,077 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 178
[INFO] 2021-07-09 16:47:46,077 [run_pretraining.py:  558]:	worker_index: 7, step: 178, cost: 4.176925, mlm loss: 4.176925, speed: 0.445451 steps/s, speed: 3.563607 samples/s, speed: 1824.566605 tokens/s, learning rate: 1.770e-06, loss_scalings: 13421.773438, pp_loss: 4.190386
[INFO] 2021-07-09 16:47:46,077 [run_pretraining.py:  512]:	********exe.run_178******* 
[INFO] 2021-07-09 16:47:48,294 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:48,295 [run_pretraining.py:  534]:	loss/total_loss, 4.153589248657227, 179
[INFO] 2021-07-09 16:47:48,295 [run_pretraining.py:  535]:	loss/mlm_loss, 4.153589248657227, 179
[INFO] 2021-07-09 16:47:48,295 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7799999341150397e-06, 179
[INFO] 2021-07-09 16:47:48,295 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 179
[INFO] 2021-07-09 16:47:48,295 [run_pretraining.py:  558]:	worker_index: 7, step: 179, cost: 4.153589, mlm loss: 4.153589, speed: 0.450967 steps/s, speed: 3.607737 samples/s, speed: 1847.161310 tokens/s, learning rate: 1.780e-06, loss_scalings: 13421.773438, pp_loss: 4.159926
[INFO] 2021-07-09 16:47:48,295 [run_pretraining.py:  512]:	********exe.run_179******* 
[INFO] 2021-07-09 16:47:50,503 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:50,504 [run_pretraining.py:  534]:	loss/total_loss, 4.131766319274902, 180
[INFO] 2021-07-09 16:47:50,504 [run_pretraining.py:  535]:	loss/mlm_loss, 4.131766319274902, 180
[INFO] 2021-07-09 16:47:50,504 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7899999420478707e-06, 180
[INFO] 2021-07-09 16:47:50,504 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 180
[INFO] 2021-07-09 16:47:50,504 [run_pretraining.py:  558]:	worker_index: 7, step: 180, cost: 4.131766, mlm loss: 4.131766, speed: 0.452819 steps/s, speed: 3.622551 samples/s, speed: 1854.745863 tokens/s, learning rate: 1.790e-06, loss_scalings: 13421.773438, pp_loss: 4.129622
[INFO] 2021-07-09 16:47:50,504 [run_pretraining.py:  512]:	********exe.run_180******* 
[INFO] 2021-07-09 16:47:52,712 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:52,713 [run_pretraining.py:  534]:	loss/total_loss, 4.162654876708984, 181
[INFO] 2021-07-09 16:47:52,713 [run_pretraining.py:  535]:	loss/mlm_loss, 4.162654876708984, 181
[INFO] 2021-07-09 16:47:52,713 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.799999836293864e-06, 181
[INFO] 2021-07-09 16:47:52,713 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 181
[INFO] 2021-07-09 16:47:52,713 [run_pretraining.py:  558]:	worker_index: 7, step: 181, cost: 4.162655, mlm loss: 4.162655, speed: 0.452843 steps/s, speed: 3.622748 samples/s, speed: 1854.846789 tokens/s, learning rate: 1.800e-06, loss_scalings: 13421.773438, pp_loss: 4.146147
[INFO] 2021-07-09 16:47:52,713 [run_pretraining.py:  512]:	********exe.run_181******* 
[INFO] 2021-07-09 16:47:54,972 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:54,973 [run_pretraining.py:  534]:	loss/total_loss, 4.133903980255127, 182
[INFO] 2021-07-09 16:47:54,973 [run_pretraining.py:  535]:	loss/mlm_loss, 4.133903980255127, 182
[INFO] 2021-07-09 16:47:54,973 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8100000716003706e-06, 182
[INFO] 2021-07-09 16:47:54,973 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 182
[INFO] 2021-07-09 16:47:54,973 [run_pretraining.py:  558]:	worker_index: 7, step: 182, cost: 4.133904, mlm loss: 4.133904, speed: 0.442639 steps/s, speed: 3.541114 samples/s, speed: 1813.050218 tokens/s, learning rate: 1.810e-06, loss_scalings: 13421.773438, pp_loss: 4.101184
[INFO] 2021-07-09 16:47:54,973 [run_pretraining.py:  512]:	********exe.run_182******* 
[INFO] 2021-07-09 16:47:57,188 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:57,189 [run_pretraining.py:  534]:	loss/total_loss, 4.044200420379639, 183
[INFO] 2021-07-09 16:47:57,189 [run_pretraining.py:  535]:	loss/mlm_loss, 4.044200420379639, 183
[INFO] 2021-07-09 16:47:57,189 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8200000795332016e-06, 183
[INFO] 2021-07-09 16:47:57,189 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 183
[INFO] 2021-07-09 16:47:57,189 [run_pretraining.py:  558]:	worker_index: 7, step: 183, cost: 4.044200, mlm loss: 4.044200, speed: 0.451392 steps/s, speed: 3.611140 samples/s, speed: 1848.903524 tokens/s, learning rate: 1.820e-06, loss_scalings: 13421.773438, pp_loss: 4.040778
[INFO] 2021-07-09 16:47:57,189 [run_pretraining.py:  512]:	********exe.run_183******* 
[INFO] 2021-07-09 16:47:59,436 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:59,437 [run_pretraining.py:  534]:	loss/total_loss, 4.102174758911133, 184
[INFO] 2021-07-09 16:47:59,437 [run_pretraining.py:  535]:	loss/mlm_loss, 4.102174758911133, 184
[INFO] 2021-07-09 16:47:59,437 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.829999973779195e-06, 184
[INFO] 2021-07-09 16:47:59,437 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 184
[INFO] 2021-07-09 16:47:59,437 [run_pretraining.py:  558]:	worker_index: 7, step: 184, cost: 4.102175, mlm loss: 4.102175, speed: 0.444929 steps/s, speed: 3.559432 samples/s, speed: 1822.429245 tokens/s, learning rate: 1.830e-06, loss_scalings: 13421.773438, pp_loss: 4.022756
[INFO] 2021-07-09 16:47:59,437 [run_pretraining.py:  512]:	********exe.run_184******* 
[INFO] 2021-07-09 16:48:01,637 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:01,638 [run_pretraining.py:  534]:	loss/total_loss, 4.022824764251709, 185
[INFO] 2021-07-09 16:48:01,638 [run_pretraining.py:  535]:	loss/mlm_loss, 4.022824764251709, 185
[INFO] 2021-07-09 16:48:01,638 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.839999981712026e-06, 185
[INFO] 2021-07-09 16:48:01,638 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 185
[INFO] 2021-07-09 16:48:01,638 [run_pretraining.py:  558]:	worker_index: 7, step: 185, cost: 4.022825, mlm loss: 4.022825, speed: 0.454545 steps/s, speed: 3.636360 samples/s, speed: 1861.816124 tokens/s, learning rate: 1.840e-06, loss_scalings: 13421.773438, pp_loss: 3.982439
[INFO] 2021-07-09 16:48:01,638 [run_pretraining.py:  512]:	********exe.run_185******* 
[INFO] 2021-07-09 16:48:03,878 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:03,879 [run_pretraining.py:  534]:	loss/total_loss, 3.934267520904541, 186
[INFO] 2021-07-09 16:48:03,879 [run_pretraining.py:  535]:	loss/mlm_loss, 3.934267520904541, 186
[INFO] 2021-07-09 16:48:03,879 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8499999896448571e-06, 186
[INFO] 2021-07-09 16:48:03,879 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 186
[INFO] 2021-07-09 16:48:03,879 [run_pretraining.py:  558]:	worker_index: 7, step: 186, cost: 3.934268, mlm loss: 3.934268, speed: 0.446328 steps/s, speed: 3.570626 samples/s, speed: 1828.160460 tokens/s, learning rate: 1.850e-06, loss_scalings: 13421.773438, pp_loss: 3.952544
[INFO] 2021-07-09 16:48:03,879 [run_pretraining.py:  512]:	********exe.run_186******* 
[INFO] 2021-07-09 16:48:06,091 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:06,092 [run_pretraining.py:  534]:	loss/total_loss, 3.91288161277771, 187
[INFO] 2021-07-09 16:48:06,092 [run_pretraining.py:  535]:	loss/mlm_loss, 3.91288161277771, 187
[INFO] 2021-07-09 16:48:06,092 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8599999975776882e-06, 187
[INFO] 2021-07-09 16:48:06,092 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 187
[INFO] 2021-07-09 16:48:06,092 [run_pretraining.py:  558]:	worker_index: 7, step: 187, cost: 3.912882, mlm loss: 3.912882, speed: 0.451982 steps/s, speed: 3.615858 samples/s, speed: 1851.319106 tokens/s, learning rate: 1.860e-06, loss_scalings: 13421.773438, pp_loss: 3.936265
[INFO] 2021-07-09 16:48:06,093 [run_pretraining.py:  512]:	********exe.run_187******* 
[INFO] 2021-07-09 16:48:08,294 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:08,295 [run_pretraining.py:  534]:	loss/total_loss, 3.871847152709961, 188
[INFO] 2021-07-09 16:48:08,295 [run_pretraining.py:  535]:	loss/mlm_loss, 3.871847152709961, 188
[INFO] 2021-07-09 16:48:08,295 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8699998918236815e-06, 188
[INFO] 2021-07-09 16:48:08,295 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 188
[INFO] 2021-07-09 16:48:08,295 [run_pretraining.py:  558]:	worker_index: 7, step: 188, cost: 3.871847, mlm loss: 3.871847, speed: 0.454125 steps/s, speed: 3.633000 samples/s, speed: 1860.095821 tokens/s, learning rate: 1.870e-06, loss_scalings: 13421.773438, pp_loss: 3.912183
[INFO] 2021-07-09 16:48:08,295 [run_pretraining.py:  512]:	********exe.run_188******* 
[INFO] 2021-07-09 16:48:10,532 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:10,532 [run_pretraining.py:  534]:	loss/total_loss, 3.8812475204467773, 189
[INFO] 2021-07-09 16:48:10,532 [run_pretraining.py:  535]:	loss/mlm_loss, 3.8812475204467773, 189
[INFO] 2021-07-09 16:48:10,532 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8799998997565126e-06, 189
[INFO] 2021-07-09 16:48:10,532 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 189
[INFO] 2021-07-09 16:48:10,532 [run_pretraining.py:  558]:	worker_index: 7, step: 189, cost: 3.881248, mlm loss: 3.881248, speed: 0.447095 steps/s, speed: 3.576757 samples/s, speed: 1831.299685 tokens/s, learning rate: 1.880e-06, loss_scalings: 13421.773438, pp_loss: 3.866972
[INFO] 2021-07-09 16:48:10,533 [run_pretraining.py:  512]:	********exe.run_189******* 
[INFO] 2021-07-09 16:48:12,851 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:12,852 [run_pretraining.py:  534]:	loss/total_loss, 3.7763900756835938, 190
[INFO] 2021-07-09 16:48:12,852 [run_pretraining.py:  535]:	loss/mlm_loss, 3.7763900756835938, 190
[INFO] 2021-07-09 16:48:12,852 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8899999076893437e-06, 190
[INFO] 2021-07-09 16:48:12,852 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 190
[INFO] 2021-07-09 16:48:12,852 [run_pretraining.py:  558]:	worker_index: 7, step: 190, cost: 3.776390, mlm loss: 3.776390, speed: 0.431222 steps/s, speed: 3.449778 samples/s, speed: 1766.286191 tokens/s, learning rate: 1.890e-06, loss_scalings: 13421.773438, pp_loss: 3.826934
[INFO] 2021-07-09 16:48:12,852 [run_pretraining.py:  512]:	********exe.run_190******* 
[INFO] 2021-07-09 16:48:15,120 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:15,120 [run_pretraining.py:  534]:	loss/total_loss, 3.7892093658447266, 191
[INFO] 2021-07-09 16:48:15,120 [run_pretraining.py:  535]:	loss/mlm_loss, 3.7892093658447266, 191
[INFO] 2021-07-09 16:48:15,120 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8999999156221747e-06, 191
[INFO] 2021-07-09 16:48:15,120 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 191
[INFO] 2021-07-09 16:48:15,121 [run_pretraining.py:  558]:	worker_index: 7, step: 191, cost: 3.789209, mlm loss: 3.789209, speed: 0.440958 steps/s, speed: 3.527666 samples/s, speed: 1806.165166 tokens/s, learning rate: 1.900e-06, loss_scalings: 13421.773438, pp_loss: 3.802434
[INFO] 2021-07-09 16:48:15,121 [run_pretraining.py:  512]:	********exe.run_191******* 
[INFO] 2021-07-09 16:48:17,330 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:17,331 [run_pretraining.py:  534]:	loss/total_loss, 3.8114030361175537, 192
[INFO] 2021-07-09 16:48:17,331 [run_pretraining.py:  535]:	loss/mlm_loss, 3.8114030361175537, 192
[INFO] 2021-07-09 16:48:17,331 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.909999809868168e-06, 192
[INFO] 2021-07-09 16:48:17,331 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 192
[INFO] 2021-07-09 16:48:17,331 [run_pretraining.py:  558]:	worker_index: 7, step: 192, cost: 3.811403, mlm loss: 3.811403, speed: 0.452441 steps/s, speed: 3.619528 samples/s, speed: 1853.198305 tokens/s, learning rate: 1.910e-06, loss_scalings: 13421.773438, pp_loss: 3.794396
[INFO] 2021-07-09 16:48:17,332 [run_pretraining.py:  512]:	********exe.run_192******* 
[INFO] 2021-07-09 16:48:19,598 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:19,598 [run_pretraining.py:  534]:	loss/total_loss, 3.776400089263916, 193
[INFO] 2021-07-09 16:48:19,598 [run_pretraining.py:  535]:	loss/mlm_loss, 3.776400089263916, 193
[INFO] 2021-07-09 16:48:19,599 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.919999931487837e-06, 193
[INFO] 2021-07-09 16:48:19,599 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 193
[INFO] 2021-07-09 16:48:19,599 [run_pretraining.py:  558]:	worker_index: 7, step: 193, cost: 3.776400, mlm loss: 3.776400, speed: 0.441214 steps/s, speed: 3.529715 samples/s, speed: 1807.214331 tokens/s, learning rate: 1.920e-06, loss_scalings: 13421.773438, pp_loss: 3.729818
[INFO] 2021-07-09 16:48:19,599 [run_pretraining.py:  512]:	********exe.run_193******* 
[INFO] 2021-07-09 16:48:21,837 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:21,837 [run_pretraining.py:  534]:	loss/total_loss, 3.703658103942871, 194
[INFO] 2021-07-09 16:48:21,837 [run_pretraining.py:  535]:	loss/mlm_loss, 3.703658103942871, 194
[INFO] 2021-07-09 16:48:21,837 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9300000531075057e-06, 194
[INFO] 2021-07-09 16:48:21,837 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 194
[INFO] 2021-07-09 16:48:21,837 [run_pretraining.py:  558]:	worker_index: 7, step: 194, cost: 3.703658, mlm loss: 3.703658, speed: 0.446800 steps/s, speed: 3.574401 samples/s, speed: 1830.093505 tokens/s, learning rate: 1.930e-06, loss_scalings: 13421.773438, pp_loss: 3.711123
[INFO] 2021-07-09 16:48:21,838 [run_pretraining.py:  512]:	********exe.run_194******* 
[INFO] 2021-07-09 16:48:24,148 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:24,148 [run_pretraining.py:  534]:	loss/total_loss, 3.690748453140259, 195
[INFO] 2021-07-09 16:48:24,148 [run_pretraining.py:  535]:	loss/mlm_loss, 3.690748453140259, 195
[INFO] 2021-07-09 16:48:24,148 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.939999947353499e-06, 195
[INFO] 2021-07-09 16:48:24,149 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 195
[INFO] 2021-07-09 16:48:24,149 [run_pretraining.py:  558]:	worker_index: 7, step: 195, cost: 3.690748, mlm loss: 3.690748, speed: 0.432809 steps/s, speed: 3.462475 samples/s, speed: 1772.786954 tokens/s, learning rate: 1.940e-06, loss_scalings: 13421.773438, pp_loss: 3.686391
[INFO] 2021-07-09 16:48:24,149 [run_pretraining.py:  512]:	********exe.run_195******* 
[INFO] 2021-07-09 16:48:26,405 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:26,405 [run_pretraining.py:  534]:	loss/total_loss, 3.666123390197754, 196
[INFO] 2021-07-09 16:48:26,405 [run_pretraining.py:  535]:	loss/mlm_loss, 3.666123390197754, 196
[INFO] 2021-07-09 16:48:26,406 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.950000068973168e-06, 196
[INFO] 2021-07-09 16:48:26,406 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 196
[INFO] 2021-07-09 16:48:26,406 [run_pretraining.py:  558]:	worker_index: 7, step: 196, cost: 3.666123, mlm loss: 3.666123, speed: 0.443164 steps/s, speed: 3.545315 samples/s, speed: 1815.201486 tokens/s, learning rate: 1.950e-06, loss_scalings: 13421.773438, pp_loss: 3.651335
[INFO] 2021-07-09 16:48:26,406 [run_pretraining.py:  512]:	********exe.run_196******* 
[INFO] 2021-07-09 16:48:28,647 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:28,647 [run_pretraining.py:  534]:	loss/total_loss, 3.5934438705444336, 197
[INFO] 2021-07-09 16:48:28,648 [run_pretraining.py:  535]:	loss/mlm_loss, 3.5934438705444336, 197
[INFO] 2021-07-09 16:48:28,648 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.959999963219161e-06, 197
[INFO] 2021-07-09 16:48:28,648 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 197
[INFO] 2021-07-09 16:48:28,648 [run_pretraining.py:  558]:	worker_index: 7, step: 197, cost: 3.593444, mlm loss: 3.593444, speed: 0.446156 steps/s, speed: 3.569246 samples/s, speed: 1827.453970 tokens/s, learning rate: 1.960e-06, loss_scalings: 13421.773438, pp_loss: 3.603242
[INFO] 2021-07-09 16:48:28,648 [run_pretraining.py:  512]:	********exe.run_197******* 
[INFO] 2021-07-09 16:48:30,892 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:30,893 [run_pretraining.py:  534]:	loss/total_loss, 3.5761351585388184, 198
[INFO] 2021-07-09 16:48:30,893 [run_pretraining.py:  535]:	loss/mlm_loss, 3.5761351585388184, 198
[INFO] 2021-07-09 16:48:30,893 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9699998574651545e-06, 198
[INFO] 2021-07-09 16:48:30,893 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 198
[INFO] 2021-07-09 16:48:30,893 [run_pretraining.py:  558]:	worker_index: 7, step: 198, cost: 3.576135, mlm loss: 3.576135, speed: 0.445497 steps/s, speed: 3.563978 samples/s, speed: 1824.756719 tokens/s, learning rate: 1.970e-06, loss_scalings: 13421.773438, pp_loss: 3.575780
[INFO] 2021-07-09 16:48:30,893 [run_pretraining.py:  512]:	********exe.run_198******* 
[INFO] 2021-07-09 16:48:33,126 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:33,127 [run_pretraining.py:  534]:	loss/total_loss, 3.5919268131256104, 199
[INFO] 2021-07-09 16:48:33,127 [run_pretraining.py:  535]:	loss/mlm_loss, 3.5919268131256104, 199
[INFO] 2021-07-09 16:48:33,127 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9799999790848233e-06, 199
[INFO] 2021-07-09 16:48:33,127 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 199
[INFO] 2021-07-09 16:48:33,127 [run_pretraining.py:  558]:	worker_index: 7, step: 199, cost: 3.591927, mlm loss: 3.591927, speed: 0.447777 steps/s, speed: 3.582218 samples/s, speed: 1834.095626 tokens/s, learning rate: 1.980e-06, loss_scalings: 13421.773438, pp_loss: 3.548169
[INFO] 2021-07-09 16:48:33,127 [run_pretraining.py:  512]:	********exe.run_199******* 
[INFO] 2021-07-09 16:48:35,361 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:35,362 [run_pretraining.py:  534]:	loss/total_loss, 3.4980435371398926, 200
[INFO] 2021-07-09 16:48:35,362 [run_pretraining.py:  535]:	loss/mlm_loss, 3.4980435371398926, 200
[INFO] 2021-07-09 16:48:35,362 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9899998733308166e-06, 200
[INFO] 2021-07-09 16:48:35,362 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 200
[INFO] 2021-07-09 16:48:35,362 [run_pretraining.py:  558]:	worker_index: 7, step: 200, cost: 3.498044, mlm loss: 3.498044, speed: 0.447533 steps/s, speed: 3.580267 samples/s, speed: 1833.096781 tokens/s, learning rate: 1.990e-06, loss_scalings: 13421.773438, pp_loss: 3.510255
[INFO] 2021-07-09 16:48:35,362 [run_pretraining.py:  512]:	********exe.run_200******* 
[INFO] 2021-07-09 16:48:37,576 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:37,577 [run_pretraining.py:  534]:	loss/total_loss, 3.4572720527648926, 201
[INFO] 2021-07-09 16:48:37,577 [run_pretraining.py:  535]:	loss/mlm_loss, 3.4572720527648926, 201
[INFO] 2021-07-09 16:48:37,577 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9999999949504854e-06, 201
[INFO] 2021-07-09 16:48:37,577 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 201
[INFO] 2021-07-09 16:48:37,577 [run_pretraining.py:  558]:	worker_index: 7, step: 201, cost: 3.457272, mlm loss: 3.457272, speed: 0.451587 steps/s, speed: 3.612696 samples/s, speed: 1849.700184 tokens/s, learning rate: 2.000e-06, loss_scalings: 13421.773438, pp_loss: 3.476285
[INFO] 2021-07-09 16:48:37,577 [run_pretraining.py:  512]:	********exe.run_201******* 
[INFO] 2021-07-09 16:48:39,797 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:39,797 [run_pretraining.py:  534]:	loss/total_loss, 3.440309762954712, 202
[INFO] 2021-07-09 16:48:39,797 [run_pretraining.py:  535]:	loss/mlm_loss, 3.440309762954712, 202
[INFO] 2021-07-09 16:48:39,798 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0099998891964788e-06, 202
[INFO] 2021-07-09 16:48:39,798 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 202
[INFO] 2021-07-09 16:48:39,798 [run_pretraining.py:  558]:	worker_index: 7, step: 202, cost: 3.440310, mlm loss: 3.440310, speed: 0.450486 steps/s, speed: 3.603887 samples/s, speed: 1845.190277 tokens/s, learning rate: 2.010e-06, loss_scalings: 13421.773438, pp_loss: 3.438085
[INFO] 2021-07-09 16:48:39,798 [run_pretraining.py:  512]:	********exe.run_202******* 
[INFO] 2021-07-09 16:48:42,048 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:42,049 [run_pretraining.py:  534]:	loss/total_loss, 3.352931261062622, 203
[INFO] 2021-07-09 16:48:42,049 [run_pretraining.py:  535]:	loss/mlm_loss, 3.352931261062622, 203
[INFO] 2021-07-09 16:48:42,049 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.019999783442472e-06, 203
[INFO] 2021-07-09 16:48:42,049 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 203
[INFO] 2021-07-09 16:48:42,049 [run_pretraining.py:  558]:	worker_index: 7, step: 203, cost: 3.352931, mlm loss: 3.352931, speed: 0.444297 steps/s, speed: 3.554376 samples/s, speed: 1819.840285 tokens/s, learning rate: 2.020e-06, loss_scalings: 13421.773438, pp_loss: 3.410459
[INFO] 2021-07-09 16:48:42,049 [run_pretraining.py:  512]:	********exe.run_203******* 
[INFO] 2021-07-09 16:48:44,326 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:44,326 [run_pretraining.py:  534]:	loss/total_loss, 3.382540702819824, 204
[INFO] 2021-07-09 16:48:44,326 [run_pretraining.py:  535]:	loss/mlm_loss, 3.382540702819824, 204
[INFO] 2021-07-09 16:48:44,326 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0300001324358163e-06, 204
[INFO] 2021-07-09 16:48:44,326 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 204
[INFO] 2021-07-09 16:48:44,326 [run_pretraining.py:  558]:	worker_index: 7, step: 204, cost: 3.382541, mlm loss: 3.382541, speed: 0.439224 steps/s, speed: 3.513788 samples/s, speed: 1799.059558 tokens/s, learning rate: 2.030e-06, loss_scalings: 13421.773438, pp_loss: 3.389311
[INFO] 2021-07-09 16:48:44,326 [run_pretraining.py:  512]:	********exe.run_204******* 
[INFO] 2021-07-09 16:48:46,641 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:46,642 [run_pretraining.py:  534]:	loss/total_loss, 3.3942508697509766, 205
[INFO] 2021-07-09 16:48:46,642 [run_pretraining.py:  535]:	loss/mlm_loss, 3.3942508697509766, 205
[INFO] 2021-07-09 16:48:46,642 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0400000266818097e-06, 205
[INFO] 2021-07-09 16:48:46,642 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 205
[INFO] 2021-07-09 16:48:46,642 [run_pretraining.py:  558]:	worker_index: 7, step: 205, cost: 3.394251, mlm loss: 3.394251, speed: 0.431923 steps/s, speed: 3.455386 samples/s, speed: 1769.157681 tokens/s, learning rate: 2.040e-06, loss_scalings: 13421.773438, pp_loss: 3.362178
[INFO] 2021-07-09 16:48:46,642 [run_pretraining.py:  512]:	********exe.run_205******* 
[INFO] 2021-07-09 16:48:48,875 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:48,875 [run_pretraining.py:  534]:	loss/total_loss, 3.5018539428710938, 206
[INFO] 2021-07-09 16:48:48,875 [run_pretraining.py:  535]:	loss/mlm_loss, 3.5018539428710938, 206
[INFO] 2021-07-09 16:48:48,875 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.049999920927803e-06, 206
[INFO] 2021-07-09 16:48:48,875 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 206
[INFO] 2021-07-09 16:48:48,875 [run_pretraining.py:  558]:	worker_index: 7, step: 206, cost: 3.501854, mlm loss: 3.501854, speed: 0.447926 steps/s, speed: 3.583405 samples/s, speed: 1834.703411 tokens/s, learning rate: 2.050e-06, loss_scalings: 13421.773438, pp_loss: 3.330348
[INFO] 2021-07-09 16:48:48,876 [run_pretraining.py:  512]:	********exe.run_206******* 
[INFO] 2021-07-09 16:48:51,111 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:51,111 [run_pretraining.py:  534]:	loss/total_loss, 3.246398448944092, 207
[INFO] 2021-07-09 16:48:51,112 [run_pretraining.py:  535]:	loss/mlm_loss, 3.246398448944092, 207
[INFO] 2021-07-09 16:48:51,112 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.060000042547472e-06, 207
[INFO] 2021-07-09 16:48:51,112 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 207
[INFO] 2021-07-09 16:48:51,112 [run_pretraining.py:  558]:	worker_index: 7, step: 207, cost: 3.246398, mlm loss: 3.246398, speed: 0.447307 steps/s, speed: 3.578460 samples/s, speed: 1832.171316 tokens/s, learning rate: 2.060e-06, loss_scalings: 13421.773438, pp_loss: 3.285522
[INFO] 2021-07-09 16:48:51,112 [run_pretraining.py:  512]:	********exe.run_207******* 
[INFO] 2021-07-09 16:48:53,389 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:53,389 [run_pretraining.py:  534]:	loss/total_loss, 3.2402472496032715, 208
[INFO] 2021-07-09 16:48:53,389 [run_pretraining.py:  535]:	loss/mlm_loss, 3.2402472496032715, 208
[INFO] 2021-07-09 16:48:53,389 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.069999936793465e-06, 208
[INFO] 2021-07-09 16:48:53,389 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 208
[INFO] 2021-07-09 16:48:53,389 [run_pretraining.py:  558]:	worker_index: 7, step: 208, cost: 3.240247, mlm loss: 3.240247, speed: 0.439170 steps/s, speed: 3.513358 samples/s, speed: 1798.839351 tokens/s, learning rate: 2.070e-06, loss_scalings: 13421.773438, pp_loss: 3.231832
[INFO] 2021-07-09 16:48:53,389 [run_pretraining.py:  512]:	********exe.run_208******* 
[INFO] 2021-07-09 16:48:55,627 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:55,627 [run_pretraining.py:  534]:	loss/total_loss, 3.225541591644287, 209
[INFO] 2021-07-09 16:48:55,627 [run_pretraining.py:  535]:	loss/mlm_loss, 3.225541591644287, 209
[INFO] 2021-07-09 16:48:55,628 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.080000058413134e-06, 209
[INFO] 2021-07-09 16:48:55,628 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 209
[INFO] 2021-07-09 16:48:55,628 [run_pretraining.py:  558]:	worker_index: 7, step: 209, cost: 3.225542, mlm loss: 3.225542, speed: 0.446898 steps/s, speed: 3.575183 samples/s, speed: 1830.493633 tokens/s, learning rate: 2.080e-06, loss_scalings: 13421.773438, pp_loss: 3.216236
[INFO] 2021-07-09 16:48:55,628 [run_pretraining.py:  512]:	********exe.run_209******* 
[INFO] 2021-07-09 16:48:57,910 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:57,911 [run_pretraining.py:  534]:	loss/total_loss, 3.15480637550354, 210
[INFO] 2021-07-09 16:48:57,911 [run_pretraining.py:  535]:	loss/mlm_loss, 3.15480637550354, 210
[INFO] 2021-07-09 16:48:57,911 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0899999526591273e-06, 210
[INFO] 2021-07-09 16:48:57,911 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 210
[INFO] 2021-07-09 16:48:57,911 [run_pretraining.py:  558]:	worker_index: 7, step: 210, cost: 3.154806, mlm loss: 3.154806, speed: 0.438044 steps/s, speed: 3.504354 samples/s, speed: 1794.229283 tokens/s, learning rate: 2.090e-06, loss_scalings: 13421.773438, pp_loss: 3.194990
[INFO] 2021-07-09 16:48:57,911 [run_pretraining.py:  512]:	********exe.run_210******* 
[INFO] 2021-07-09 16:49:00,151 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:00,152 [run_pretraining.py:  534]:	loss/total_loss, 3.1375339031219482, 211
[INFO] 2021-07-09 16:49:00,152 [run_pretraining.py:  535]:	loss/mlm_loss, 3.1375339031219482, 211
[INFO] 2021-07-09 16:49:00,152 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0999998469051206e-06, 211
[INFO] 2021-07-09 16:49:00,152 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 211
[INFO] 2021-07-09 16:49:00,152 [run_pretraining.py:  558]:	worker_index: 7, step: 211, cost: 3.137534, mlm loss: 3.137534, speed: 0.446354 steps/s, speed: 3.570830 samples/s, speed: 1828.264934 tokens/s, learning rate: 2.100e-06, loss_scalings: 13421.773438, pp_loss: 3.166357
[INFO] 2021-07-09 16:49:00,152 [run_pretraining.py:  512]:	********exe.run_211******* 
[INFO] 2021-07-09 16:49:02,452 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:02,453 [run_pretraining.py:  534]:	loss/total_loss, 3.1116671562194824, 212
[INFO] 2021-07-09 16:49:02,453 [run_pretraining.py:  535]:	loss/mlm_loss, 3.1116671562194824, 212
[INFO] 2021-07-09 16:49:02,453 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1099999685247894e-06, 212
[INFO] 2021-07-09 16:49:02,453 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 212
[INFO] 2021-07-09 16:49:02,453 [run_pretraining.py:  558]:	worker_index: 7, step: 212, cost: 3.111667, mlm loss: 3.111667, speed: 0.434753 steps/s, speed: 3.478027 samples/s, speed: 1780.749986 tokens/s, learning rate: 2.110e-06, loss_scalings: 13421.773438, pp_loss: 3.132417
[INFO] 2021-07-09 16:49:02,453 [run_pretraining.py:  512]:	********exe.run_212******* 
[INFO] 2021-07-09 16:49:04,758 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:04,759 [run_pretraining.py:  534]:	loss/total_loss, 3.150855779647827, 213
[INFO] 2021-07-09 16:49:04,759 [run_pretraining.py:  535]:	loss/mlm_loss, 3.150855779647827, 213
[INFO] 2021-07-09 16:49:04,759 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1199998627707828e-06, 213
[INFO] 2021-07-09 16:49:04,759 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 213
[INFO] 2021-07-09 16:49:04,759 [run_pretraining.py:  558]:	worker_index: 7, step: 213, cost: 3.150856, mlm loss: 3.150856, speed: 0.433751 steps/s, speed: 3.470012 samples/s, speed: 1776.646087 tokens/s, learning rate: 2.120e-06, loss_scalings: 13421.773438, pp_loss: 3.125845
[INFO] 2021-07-09 16:49:04,759 [run_pretraining.py:  512]:	********exe.run_213******* 
[INFO] 2021-07-09 16:49:07,142 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:07,142 [run_pretraining.py:  534]:	loss/total_loss, 3.097372531890869, 214
[INFO] 2021-07-09 16:49:07,142 [run_pretraining.py:  535]:	loss/mlm_loss, 3.097372531890869, 214
[INFO] 2021-07-09 16:49:07,142 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.129999757016776e-06, 214
[INFO] 2021-07-09 16:49:07,142 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 214
[INFO] 2021-07-09 16:49:07,142 [run_pretraining.py:  558]:	worker_index: 7, step: 214, cost: 3.097373, mlm loss: 3.097373, speed: 0.419700 steps/s, speed: 3.357601 samples/s, speed: 1719.091951 tokens/s, learning rate: 2.130e-06, loss_scalings: 13421.773438, pp_loss: 3.091032
[INFO] 2021-07-09 16:49:07,143 [run_pretraining.py:  512]:	********exe.run_214******* 
[INFO] 2021-07-09 16:49:09,453 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:09,454 [run_pretraining.py:  534]:	loss/total_loss, 3.060713768005371, 215
[INFO] 2021-07-09 16:49:09,454 [run_pretraining.py:  535]:	loss/mlm_loss, 3.060713768005371, 215
[INFO] 2021-07-09 16:49:09,454 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1400001060101204e-06, 215
[INFO] 2021-07-09 16:49:09,454 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 215
[INFO] 2021-07-09 16:49:09,454 [run_pretraining.py:  558]:	worker_index: 7, step: 215, cost: 3.060714, mlm loss: 3.060714, speed: 0.432750 steps/s, speed: 3.461999 samples/s, speed: 1772.543686 tokens/s, learning rate: 2.140e-06, loss_scalings: 13421.773438, pp_loss: 3.038384
[INFO] 2021-07-09 16:49:09,454 [run_pretraining.py:  512]:	********exe.run_215******* 
[INFO] 2021-07-09 16:49:11,727 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:11,727 [run_pretraining.py:  534]:	loss/total_loss, 3.029284715652466, 216
[INFO] 2021-07-09 16:49:11,727 [run_pretraining.py:  535]:	loss/mlm_loss, 3.029284715652466, 216
[INFO] 2021-07-09 16:49:11,727 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1500000002561137e-06, 216
[INFO] 2021-07-09 16:49:11,728 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 216
[INFO] 2021-07-09 16:49:11,728 [run_pretraining.py:  558]:	worker_index: 7, step: 216, cost: 3.029285, mlm loss: 3.029285, speed: 0.439944 steps/s, speed: 3.519554 samples/s, speed: 1802.011848 tokens/s, learning rate: 2.150e-06, loss_scalings: 13421.773438, pp_loss: 3.047497
[INFO] 2021-07-09 16:49:11,728 [run_pretraining.py:  512]:	********exe.run_216******* 
[INFO] 2021-07-09 16:49:14,066 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:14,067 [run_pretraining.py:  534]:	loss/total_loss, 3.008354425430298, 217
[INFO] 2021-07-09 16:49:14,067 [run_pretraining.py:  535]:	loss/mlm_loss, 3.008354425430298, 217
[INFO] 2021-07-09 16:49:14,067 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.159999894502107e-06, 217
[INFO] 2021-07-09 16:49:14,067 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 217
[INFO] 2021-07-09 16:49:14,067 [run_pretraining.py:  558]:	worker_index: 7, step: 217, cost: 3.008354, mlm loss: 3.008354, speed: 0.427538 steps/s, speed: 3.420307 samples/s, speed: 1751.197146 tokens/s, learning rate: 2.160e-06, loss_scalings: 13421.773438, pp_loss: 3.032641
[INFO] 2021-07-09 16:49:14,067 [run_pretraining.py:  512]:	********exe.run_217******* 
[INFO] 2021-07-09 16:49:16,333 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:16,334 [run_pretraining.py:  534]:	loss/total_loss, 3.011725425720215, 218
[INFO] 2021-07-09 16:49:16,334 [run_pretraining.py:  535]:	loss/mlm_loss, 3.011725425720215, 218
[INFO] 2021-07-09 16:49:16,334 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.170000016121776e-06, 218
[INFO] 2021-07-09 16:49:16,334 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 218
[INFO] 2021-07-09 16:49:16,334 [run_pretraining.py:  558]:	worker_index: 7, step: 218, cost: 3.011725, mlm loss: 3.011725, speed: 0.441244 steps/s, speed: 3.529951 samples/s, speed: 1807.335057 tokens/s, learning rate: 2.170e-06, loss_scalings: 13421.773438, pp_loss: 3.013842
[INFO] 2021-07-09 16:49:16,334 [run_pretraining.py:  512]:	********exe.run_218******* 
[INFO] 2021-07-09 16:49:18,671 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:18,671 [run_pretraining.py:  534]:	loss/total_loss, 2.9453110694885254, 219
[INFO] 2021-07-09 16:49:18,671 [run_pretraining.py:  535]:	loss/mlm_loss, 2.9453110694885254, 219
[INFO] 2021-07-09 16:49:18,671 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.179999910367769e-06, 219
[INFO] 2021-07-09 16:49:18,671 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 219
[INFO] 2021-07-09 16:49:18,671 [run_pretraining.py:  558]:	worker_index: 7, step: 219, cost: 2.945311, mlm loss: 2.945311, speed: 0.428000 steps/s, speed: 3.424000 samples/s, speed: 1753.088125 tokens/s, learning rate: 2.180e-06, loss_scalings: 13421.773438, pp_loss: 2.978095
[INFO] 2021-07-09 16:49:18,671 [run_pretraining.py:  512]:	********exe.run_219******* 
[INFO] 2021-07-09 16:49:20,890 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:20,891 [run_pretraining.py:  534]:	loss/total_loss, 2.934826612472534, 220
[INFO] 2021-07-09 16:49:20,891 [run_pretraining.py:  535]:	loss/mlm_loss, 2.934826612472534, 220
[INFO] 2021-07-09 16:49:20,891 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.190000031987438e-06, 220
[INFO] 2021-07-09 16:49:20,891 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 220
[INFO] 2021-07-09 16:49:20,891 [run_pretraining.py:  558]:	worker_index: 7, step: 220, cost: 2.934827, mlm loss: 2.934827, speed: 0.450637 steps/s, speed: 3.605097 samples/s, speed: 1845.809603 tokens/s, learning rate: 2.190e-06, loss_scalings: 13421.773438, pp_loss: 2.971479
[INFO] 2021-07-09 16:49:20,891 [run_pretraining.py:  512]:	********exe.run_220******* 
[INFO] 2021-07-09 16:49:23,198 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:23,199 [run_pretraining.py:  534]:	loss/total_loss, 3.0364363193511963, 221
[INFO] 2021-07-09 16:49:23,199 [run_pretraining.py:  535]:	loss/mlm_loss, 3.0364363193511963, 221
[INFO] 2021-07-09 16:49:23,199 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1999999262334313e-06, 221
[INFO] 2021-07-09 16:49:23,199 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 221
[INFO] 2021-07-09 16:49:23,199 [run_pretraining.py:  558]:	worker_index: 7, step: 221, cost: 3.036436, mlm loss: 3.036436, speed: 0.433395 steps/s, speed: 3.467157 samples/s, speed: 1775.184426 tokens/s, learning rate: 2.200e-06, loss_scalings: 13421.773438, pp_loss: 2.963000
[INFO] 2021-07-09 16:49:23,199 [run_pretraining.py:  512]:	********exe.run_221******* 
[INFO] 2021-07-09 16:49:25,465 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:25,465 [run_pretraining.py:  534]:	loss/total_loss, 2.911478042602539, 222
[INFO] 2021-07-09 16:49:25,465 [run_pretraining.py:  535]:	loss/mlm_loss, 2.911478042602539, 222
[INFO] 2021-07-09 16:49:25,466 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2099998204794247e-06, 222
[INFO] 2021-07-09 16:49:25,466 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 222
[INFO] 2021-07-09 16:49:25,466 [run_pretraining.py:  558]:	worker_index: 7, step: 222, cost: 2.911478, mlm loss: 2.911478, speed: 0.441353 steps/s, speed: 3.530825 samples/s, speed: 1807.782361 tokens/s, learning rate: 2.210e-06, loss_scalings: 13421.773438, pp_loss: 2.923816
[INFO] 2021-07-09 16:49:25,466 [run_pretraining.py:  512]:	********exe.run_222******* 
[INFO] 2021-07-09 16:49:27,753 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:27,753 [run_pretraining.py:  534]:	loss/total_loss, 2.905670642852783, 223
[INFO] 2021-07-09 16:49:27,753 [run_pretraining.py:  535]:	loss/mlm_loss, 2.905670642852783, 223
[INFO] 2021-07-09 16:49:27,753 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2199999420990935e-06, 223
[INFO] 2021-07-09 16:49:27,754 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 223
[INFO] 2021-07-09 16:49:27,754 [run_pretraining.py:  558]:	worker_index: 7, step: 223, cost: 2.905671, mlm loss: 2.905671, speed: 0.437193 steps/s, speed: 3.497541 samples/s, speed: 1790.741150 tokens/s, learning rate: 2.220e-06, loss_scalings: 13421.773438, pp_loss: 2.940925
[INFO] 2021-07-09 16:49:27,754 [run_pretraining.py:  512]:	********exe.run_223******* 
[INFO] 2021-07-09 16:49:30,054 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:30,054 [run_pretraining.py:  534]:	loss/total_loss, 2.9193360805511475, 224
[INFO] 2021-07-09 16:49:30,055 [run_pretraining.py:  535]:	loss/mlm_loss, 2.9193360805511475, 224
[INFO] 2021-07-09 16:49:30,055 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.229999836345087e-06, 224
[INFO] 2021-07-09 16:49:30,055 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 224
[INFO] 2021-07-09 16:49:30,055 [run_pretraining.py:  558]:	worker_index: 7, step: 224, cost: 2.919336, mlm loss: 2.919336, speed: 0.434687 steps/s, speed: 3.477493 samples/s, speed: 1780.476664 tokens/s, learning rate: 2.230e-06, loss_scalings: 13421.773438, pp_loss: 2.893160
[INFO] 2021-07-09 16:49:30,055 [run_pretraining.py:  512]:	********exe.run_224******* 
[INFO] 2021-07-09 16:49:32,354 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:32,355 [run_pretraining.py:  534]:	loss/total_loss, 3.002284288406372, 225
[INFO] 2021-07-09 16:49:32,355 [run_pretraining.py:  535]:	loss/mlm_loss, 3.002284288406372, 225
[INFO] 2021-07-09 16:49:32,355 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2399999579647556e-06, 225
[INFO] 2021-07-09 16:49:32,355 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 225
[INFO] 2021-07-09 16:49:32,355 [run_pretraining.py:  558]:	worker_index: 7, step: 225, cost: 3.002284, mlm loss: 3.002284, speed: 0.434867 steps/s, speed: 3.478936 samples/s, speed: 1781.215251 tokens/s, learning rate: 2.240e-06, loss_scalings: 13421.773438, pp_loss: 2.900171
[INFO] 2021-07-09 16:49:32,355 [run_pretraining.py:  512]:	********exe.run_225******* 
[INFO] 2021-07-09 16:49:34,660 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:34,661 [run_pretraining.py:  534]:	loss/total_loss, 2.8354806900024414, 226
[INFO] 2021-07-09 16:49:34,661 [run_pretraining.py:  535]:	loss/mlm_loss, 2.8354806900024414, 226
[INFO] 2021-07-09 16:49:34,661 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2500000795844244e-06, 226
[INFO] 2021-07-09 16:49:34,661 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 226
[INFO] 2021-07-09 16:49:34,661 [run_pretraining.py:  558]:	worker_index: 7, step: 226, cost: 2.835481, mlm loss: 2.835481, speed: 0.433730 steps/s, speed: 3.469838 samples/s, speed: 1776.556982 tokens/s, learning rate: 2.250e-06, loss_scalings: 13421.773438, pp_loss: 2.861455
[INFO] 2021-07-09 16:49:34,661 [run_pretraining.py:  512]:	********exe.run_226******* 
[INFO] 2021-07-09 16:49:36,900 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:36,901 [run_pretraining.py:  534]:	loss/total_loss, 2.8683996200561523, 227
[INFO] 2021-07-09 16:49:36,901 [run_pretraining.py:  535]:	loss/mlm_loss, 2.8683996200561523, 227
[INFO] 2021-07-09 16:49:36,901 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2599999738304177e-06, 227
[INFO] 2021-07-09 16:49:36,901 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 227
[INFO] 2021-07-09 16:49:36,901 [run_pretraining.py:  558]:	worker_index: 7, step: 227, cost: 2.868400, mlm loss: 2.868400, speed: 0.446602 steps/s, speed: 3.572813 samples/s, speed: 1829.280139 tokens/s, learning rate: 2.260e-06, loss_scalings: 10737.418945, pp_loss: 2.858173
[INFO] 2021-07-09 16:49:36,901 [run_pretraining.py:  512]:	********exe.run_227******* 
[INFO] 2021-07-09 16:49:39,217 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:39,217 [run_pretraining.py:  534]:	loss/total_loss, 2.824023723602295, 228
[INFO] 2021-07-09 16:49:39,217 [run_pretraining.py:  535]:	loss/mlm_loss, 2.824023723602295, 228
[INFO] 2021-07-09 16:49:39,217 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2700000954500865e-06, 228
[INFO] 2021-07-09 16:49:39,217 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 228
[INFO] 2021-07-09 16:49:39,217 [run_pretraining.py:  558]:	worker_index: 7, step: 228, cost: 2.824024, mlm loss: 2.824024, speed: 0.431817 steps/s, speed: 3.454532 samples/s, speed: 1768.720545 tokens/s, learning rate: 2.270e-06, loss_scalings: 10737.418945, pp_loss: 2.856797
[INFO] 2021-07-09 16:49:39,218 [run_pretraining.py:  512]:	********exe.run_228******* 
[INFO] 2021-07-09 16:49:41,552 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:41,553 [run_pretraining.py:  534]:	loss/total_loss, 2.830498456954956, 229
[INFO] 2021-07-09 16:49:41,553 [run_pretraining.py:  535]:	loss/mlm_loss, 2.830498456954956, 229
[INFO] 2021-07-09 16:49:41,553 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.27999998969608e-06, 229
[INFO] 2021-07-09 16:49:41,553 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 229
[INFO] 2021-07-09 16:49:41,553 [run_pretraining.py:  558]:	worker_index: 7, step: 229, cost: 2.830498, mlm loss: 2.830498, speed: 0.428270 steps/s, speed: 3.426162 samples/s, speed: 1754.195084 tokens/s, learning rate: 2.280e-06, loss_scalings: 8589.935547, pp_loss: 2.845603
[INFO] 2021-07-09 16:49:41,553 [run_pretraining.py:  512]:	********exe.run_229******* 
[INFO] 2021-07-09 16:49:43,803 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:43,804 [run_pretraining.py:  534]:	loss/total_loss, 2.8781754970550537, 230
[INFO] 2021-07-09 16:49:43,804 [run_pretraining.py:  535]:	loss/mlm_loss, 2.8781754970550537, 230
[INFO] 2021-07-09 16:49:43,804 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.289999883942073e-06, 230
[INFO] 2021-07-09 16:49:43,804 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 230
[INFO] 2021-07-09 16:49:43,804 [run_pretraining.py:  558]:	worker_index: 7, step: 230, cost: 2.878175, mlm loss: 2.878175, speed: 0.444364 steps/s, speed: 3.554915 samples/s, speed: 1820.116379 tokens/s, learning rate: 2.290e-06, loss_scalings: 8589.935547, pp_loss: 2.819236
[INFO] 2021-07-09 16:49:43,804 [run_pretraining.py:  512]:	********exe.run_230******* 
[INFO] 2021-07-09 16:49:46,159 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:46,160 [run_pretraining.py:  534]:	loss/total_loss, 2.855828285217285, 231
[INFO] 2021-07-09 16:49:46,160 [run_pretraining.py:  535]:	loss/mlm_loss, 2.855828285217285, 231
[INFO] 2021-07-09 16:49:46,160 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.300000005561742e-06, 231
[INFO] 2021-07-09 16:49:46,160 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 231
[INFO] 2021-07-09 16:49:46,160 [run_pretraining.py:  558]:	worker_index: 7, step: 231, cost: 2.855828, mlm loss: 2.855828, speed: 0.424539 steps/s, speed: 3.396316 samples/s, speed: 1738.913701 tokens/s, learning rate: 2.300e-06, loss_scalings: 8589.935547, pp_loss: 2.823223
[INFO] 2021-07-09 16:49:46,160 [run_pretraining.py:  512]:	********exe.run_231******* 
[INFO] 2021-07-09 16:49:48,488 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:48,488 [run_pretraining.py:  534]:	loss/total_loss, 2.8107872009277344, 232
[INFO] 2021-07-09 16:49:48,488 [run_pretraining.py:  535]:	loss/mlm_loss, 2.8107872009277344, 232
[INFO] 2021-07-09 16:49:48,488 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3099998998077353e-06, 232
[INFO] 2021-07-09 16:49:48,488 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 232
[INFO] 2021-07-09 16:49:48,488 [run_pretraining.py:  558]:	worker_index: 7, step: 232, cost: 2.810787, mlm loss: 2.810787, speed: 0.429650 steps/s, speed: 3.437204 samples/s, speed: 1759.848253 tokens/s, learning rate: 2.310e-06, loss_scalings: 8589.935547, pp_loss: 2.836176
[INFO] 2021-07-09 16:49:48,488 [run_pretraining.py:  512]:	********exe.run_232******* 
[INFO] 2021-07-09 16:49:50,707 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:50,708 [run_pretraining.py:  534]:	loss/total_loss, 2.821457624435425, 233
[INFO] 2021-07-09 16:49:50,708 [run_pretraining.py:  535]:	loss/mlm_loss, 2.821457624435425, 233
[INFO] 2021-07-09 16:49:50,708 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.320000021427404e-06, 233
[INFO] 2021-07-09 16:49:50,708 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 233
[INFO] 2021-07-09 16:49:50,708 [run_pretraining.py:  558]:	worker_index: 7, step: 233, cost: 2.821458, mlm loss: 2.821458, speed: 0.450618 steps/s, speed: 3.604943 samples/s, speed: 1845.730677 tokens/s, learning rate: 2.320e-06, loss_scalings: 8589.935547, pp_loss: 2.797513
[INFO] 2021-07-09 16:49:50,708 [run_pretraining.py:  512]:	********exe.run_233******* 
[INFO] 2021-07-09 16:49:52,962 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:52,963 [run_pretraining.py:  534]:	loss/total_loss, 2.7954823970794678, 234
[INFO] 2021-07-09 16:49:52,963 [run_pretraining.py:  535]:	loss/mlm_loss, 2.7954823970794678, 234
[INFO] 2021-07-09 16:49:52,963 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3299999156733975e-06, 234
[INFO] 2021-07-09 16:49:52,963 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 234
[INFO] 2021-07-09 16:49:52,963 [run_pretraining.py:  558]:	worker_index: 7, step: 234, cost: 2.795482, mlm loss: 2.795482, speed: 0.443613 steps/s, speed: 3.548906 samples/s, speed: 1817.039751 tokens/s, learning rate: 2.330e-06, loss_scalings: 8589.935547, pp_loss: 2.790033
[INFO] 2021-07-09 16:49:52,963 [run_pretraining.py:  512]:	********exe.run_234******* 
[INFO] 2021-07-09 16:49:55,237 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:55,238 [run_pretraining.py:  534]:	loss/total_loss, 2.7677817344665527, 235
[INFO] 2021-07-09 16:49:55,238 [run_pretraining.py:  535]:	loss/mlm_loss, 2.7677817344665527, 235
[INFO] 2021-07-09 16:49:55,238 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.339999809919391e-06, 235
[INFO] 2021-07-09 16:49:55,238 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 235
[INFO] 2021-07-09 16:49:55,238 [run_pretraining.py:  558]:	worker_index: 7, step: 235, cost: 2.767782, mlm loss: 2.767782, speed: 0.439696 steps/s, speed: 3.517565 samples/s, speed: 1800.993446 tokens/s, learning rate: 2.340e-06, loss_scalings: 8589.935547, pp_loss: 2.794336
[INFO] 2021-07-09 16:49:55,238 [run_pretraining.py:  512]:	********exe.run_235******* 
[INFO] 2021-07-09 16:49:57,486 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:57,487 [run_pretraining.py:  534]:	loss/total_loss, 2.796410322189331, 236
[INFO] 2021-07-09 16:49:57,487 [run_pretraining.py:  535]:	loss/mlm_loss, 2.796410322189331, 236
[INFO] 2021-07-09 16:49:57,487 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3499999315390596e-06, 236
[INFO] 2021-07-09 16:49:57,487 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 236
[INFO] 2021-07-09 16:49:57,487 [run_pretraining.py:  558]:	worker_index: 7, step: 236, cost: 2.796410, mlm loss: 2.796410, speed: 0.444781 steps/s, speed: 3.558248 samples/s, speed: 1821.822802 tokens/s, learning rate: 2.350e-06, loss_scalings: 6871.948730, pp_loss: 2.813767
[INFO] 2021-07-09 16:49:57,487 [run_pretraining.py:  512]:	********exe.run_236******* 
[INFO] 2021-07-09 16:49:59,730 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:59,731 [run_pretraining.py:  534]:	loss/total_loss, 2.808440685272217, 237
[INFO] 2021-07-09 16:49:59,731 [run_pretraining.py:  535]:	loss/mlm_loss, 2.808440685272217, 237
[INFO] 2021-07-09 16:49:59,731 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3600000531587284e-06, 237
[INFO] 2021-07-09 16:49:59,731 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 237
[INFO] 2021-07-09 16:49:59,731 [run_pretraining.py:  558]:	worker_index: 7, step: 237, cost: 2.808441, mlm loss: 2.808441, speed: 0.445720 steps/s, speed: 3.565763 samples/s, speed: 1825.670438 tokens/s, learning rate: 2.360e-06, loss_scalings: 6871.948730, pp_loss: 2.806491
[INFO] 2021-07-09 16:49:59,731 [run_pretraining.py:  512]:	********exe.run_237******* 
[INFO] 2021-07-09 16:50:01,975 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:01,975 [run_pretraining.py:  534]:	loss/total_loss, 2.793811321258545, 238
[INFO] 2021-07-09 16:50:01,975 [run_pretraining.py:  535]:	loss/mlm_loss, 2.793811321258545, 238
[INFO] 2021-07-09 16:50:01,975 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3699999474047218e-06, 238
[INFO] 2021-07-09 16:50:01,975 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 238
[INFO] 2021-07-09 16:50:01,976 [run_pretraining.py:  558]:	worker_index: 7, step: 238, cost: 2.793811, mlm loss: 2.793811, speed: 0.445691 steps/s, speed: 3.565531 samples/s, speed: 1825.552099 tokens/s, learning rate: 2.370e-06, loss_scalings: 6871.948730, pp_loss: 2.801233
[INFO] 2021-07-09 16:50:01,976 [run_pretraining.py:  512]:	********exe.run_238******* 
[INFO] 2021-07-09 16:50:04,217 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:04,218 [run_pretraining.py:  534]:	loss/total_loss, 2.8513314723968506, 239
[INFO] 2021-07-09 16:50:04,218 [run_pretraining.py:  535]:	loss/mlm_loss, 2.8513314723968506, 239
[INFO] 2021-07-09 16:50:04,218 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3800000690243905e-06, 239
[INFO] 2021-07-09 16:50:04,218 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 239
[INFO] 2021-07-09 16:50:04,218 [run_pretraining.py:  558]:	worker_index: 7, step: 239, cost: 2.851331, mlm loss: 2.851331, speed: 0.446010 steps/s, speed: 3.568081 samples/s, speed: 1826.857388 tokens/s, learning rate: 2.380e-06, loss_scalings: 6871.948730, pp_loss: 2.815776
[INFO] 2021-07-09 16:50:04,218 [run_pretraining.py:  512]:	********exe.run_239******* 
[INFO] 2021-07-09 16:50:06,483 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:06,483 [run_pretraining.py:  534]:	loss/total_loss, 2.862623929977417, 240
[INFO] 2021-07-09 16:50:06,484 [run_pretraining.py:  535]:	loss/mlm_loss, 2.862623929977417, 240
[INFO] 2021-07-09 16:50:06,484 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.389999963270384e-06, 240
[INFO] 2021-07-09 16:50:06,484 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 240
[INFO] 2021-07-09 16:50:06,484 [run_pretraining.py:  558]:	worker_index: 7, step: 240, cost: 2.862624, mlm loss: 2.862624, speed: 0.441535 steps/s, speed: 3.532281 samples/s, speed: 1808.527978 tokens/s, learning rate: 2.390e-06, loss_scalings: 5497.559082, pp_loss: 2.823950
[INFO] 2021-07-09 16:50:06,484 [run_pretraining.py:  512]:	********exe.run_240******* 
[INFO] 2021-07-09 16:50:08,788 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:08,789 [run_pretraining.py:  534]:	loss/total_loss, 2.8268356323242188, 241
[INFO] 2021-07-09 16:50:08,789 [run_pretraining.py:  535]:	loss/mlm_loss, 2.8268356323242188, 241
[INFO] 2021-07-09 16:50:08,789 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3999998575163772e-06, 241
[INFO] 2021-07-09 16:50:08,789 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 241
[INFO] 2021-07-09 16:50:08,789 [run_pretraining.py:  558]:	worker_index: 7, step: 241, cost: 2.826836, mlm loss: 2.826836, speed: 0.433934 steps/s, speed: 3.471470 samples/s, speed: 1777.392715 tokens/s, learning rate: 2.400e-06, loss_scalings: 5497.559082, pp_loss: 2.803624
[INFO] 2021-07-09 16:50:08,789 [run_pretraining.py:  512]:	********exe.run_241******* 
[INFO] 2021-07-09 16:50:11,118 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:11,118 [run_pretraining.py:  534]:	loss/total_loss, 2.816173791885376, 242
[INFO] 2021-07-09 16:50:11,119 [run_pretraining.py:  535]:	loss/mlm_loss, 2.816173791885376, 242
[INFO] 2021-07-09 16:50:11,119 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.409999979136046e-06, 242
[INFO] 2021-07-09 16:50:11,119 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 242
[INFO] 2021-07-09 16:50:11,119 [run_pretraining.py:  558]:	worker_index: 7, step: 242, cost: 2.816174, mlm loss: 2.816174, speed: 0.429337 steps/s, speed: 3.434699 samples/s, speed: 1758.565825 tokens/s, learning rate: 2.410e-06, loss_scalings: 5497.559082, pp_loss: 2.818855
[INFO] 2021-07-09 16:50:11,119 [run_pretraining.py:  512]:	********exe.run_242******* 
[INFO] 2021-07-09 16:50:13,373 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:13,374 [run_pretraining.py:  534]:	loss/total_loss, 2.7955162525177, 243
[INFO] 2021-07-09 16:50:13,374 [run_pretraining.py:  535]:	loss/mlm_loss, 2.7955162525177, 243
[INFO] 2021-07-09 16:50:13,374 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4199998733820394e-06, 243
[INFO] 2021-07-09 16:50:13,374 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 243
[INFO] 2021-07-09 16:50:13,374 [run_pretraining.py:  558]:	worker_index: 7, step: 243, cost: 2.795516, mlm loss: 2.795516, speed: 0.443568 steps/s, speed: 3.548548 samples/s, speed: 1816.856430 tokens/s, learning rate: 2.420e-06, loss_scalings: 5497.559082, pp_loss: 2.827258
[INFO] 2021-07-09 16:50:13,374 [run_pretraining.py:  512]:	********exe.run_243******* 
[INFO] 2021-07-09 16:50:15,634 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:15,635 [run_pretraining.py:  534]:	loss/total_loss, 2.900881052017212, 244
[INFO] 2021-07-09 16:50:15,635 [run_pretraining.py:  535]:	loss/mlm_loss, 2.900881052017212, 244
[INFO] 2021-07-09 16:50:15,635 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.429999995001708e-06, 244
[INFO] 2021-07-09 16:50:15,635 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 244
[INFO] 2021-07-09 16:50:15,635 [run_pretraining.py:  558]:	worker_index: 7, step: 244, cost: 2.900881, mlm loss: 2.900881, speed: 0.442389 steps/s, speed: 3.539111 samples/s, speed: 1812.024847 tokens/s, learning rate: 2.430e-06, loss_scalings: 5497.559082, pp_loss: 2.843439
[INFO] 2021-07-09 16:50:15,635 [run_pretraining.py:  512]:	********exe.run_244******* 
[INFO] 2021-07-09 16:50:17,898 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:17,898 [run_pretraining.py:  534]:	loss/total_loss, 2.8648598194122314, 245
[INFO] 2021-07-09 16:50:17,898 [run_pretraining.py:  535]:	loss/mlm_loss, 2.8648598194122314, 245
[INFO] 2021-07-09 16:50:17,898 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4399998892477015e-06, 245
[INFO] 2021-07-09 16:50:17,898 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 245
[INFO] 2021-07-09 16:50:17,899 [run_pretraining.py:  558]:	worker_index: 7, step: 245, cost: 2.864860, mlm loss: 2.864860, speed: 0.441922 steps/s, speed: 3.535378 samples/s, speed: 1810.113743 tokens/s, learning rate: 2.440e-06, loss_scalings: 5497.559082, pp_loss: 2.848964
[INFO] 2021-07-09 16:50:17,899 [run_pretraining.py:  512]:	********exe.run_245******* 
[INFO] 2021-07-09 16:50:20,180 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:20,181 [run_pretraining.py:  534]:	loss/total_loss, 2.8320631980895996, 246
[INFO] 2021-07-09 16:50:20,181 [run_pretraining.py:  535]:	loss/mlm_loss, 2.8320631980895996, 246
[INFO] 2021-07-09 16:50:20,181 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.449999783493695e-06, 246
[INFO] 2021-07-09 16:50:20,181 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 246
[INFO] 2021-07-09 16:50:20,182 [run_pretraining.py:  558]:	worker_index: 7, step: 246, cost: 2.832063, mlm loss: 2.832063, speed: 0.438159 steps/s, speed: 3.505275 samples/s, speed: 1794.700869 tokens/s, learning rate: 2.450e-06, loss_scalings: 5497.559082, pp_loss: 2.868507
[INFO] 2021-07-09 16:50:20,182 [run_pretraining.py:  512]:	********exe.run_246******* 
[INFO] 2021-07-09 16:50:22,441 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:22,441 [run_pretraining.py:  534]:	loss/total_loss, 2.8862648010253906, 247
[INFO] 2021-07-09 16:50:22,442 [run_pretraining.py:  535]:	loss/mlm_loss, 2.8862648010253906, 247
[INFO] 2021-07-09 16:50:22,442 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4599999051133636e-06, 247
[INFO] 2021-07-09 16:50:22,442 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 247
[INFO] 2021-07-09 16:50:22,442 [run_pretraining.py:  558]:	worker_index: 7, step: 247, cost: 2.886265, mlm loss: 2.886265, speed: 0.442538 steps/s, speed: 3.540301 samples/s, speed: 1812.634346 tokens/s, learning rate: 2.460e-06, loss_scalings: 4398.047363, pp_loss: 2.903888
[INFO] 2021-07-09 16:50:22,442 [run_pretraining.py:  512]:	********exe.run_247******* 
[INFO] 2021-07-09 16:50:24,682 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:24,683 [run_pretraining.py:  534]:	loss/total_loss, 2.9218590259552, 248
[INFO] 2021-07-09 16:50:24,683 [run_pretraining.py:  535]:	loss/mlm_loss, 2.9218590259552, 248
[INFO] 2021-07-09 16:50:24,683 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4700000267330324e-06, 248
[INFO] 2021-07-09 16:50:24,683 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 248
[INFO] 2021-07-09 16:50:24,683 [run_pretraining.py:  558]:	worker_index: 7, step: 248, cost: 2.921859, mlm loss: 2.921859, speed: 0.446257 steps/s, speed: 3.570056 samples/s, speed: 1827.868502 tokens/s, learning rate: 2.470e-06, loss_scalings: 4398.047363, pp_loss: 2.903716
[INFO] 2021-07-09 16:50:24,683 [run_pretraining.py:  512]:	********exe.run_248******* 
[INFO] 2021-07-09 16:50:26,917 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:26,917 [run_pretraining.py:  534]:	loss/total_loss, 2.932309150695801, 249
[INFO] 2021-07-09 16:50:26,917 [run_pretraining.py:  535]:	loss/mlm_loss, 2.932309150695801, 249
[INFO] 2021-07-09 16:50:26,917 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4799999209790258e-06, 249
[INFO] 2021-07-09 16:50:26,917 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 249
[INFO] 2021-07-09 16:50:26,918 [run_pretraining.py:  558]:	worker_index: 7, step: 249, cost: 2.932309, mlm loss: 2.932309, speed: 0.447719 steps/s, speed: 3.581751 samples/s, speed: 1833.856383 tokens/s, learning rate: 2.480e-06, loss_scalings: 4398.047363, pp_loss: 2.932668
[INFO] 2021-07-09 16:50:26,918 [run_pretraining.py:  512]:	********exe.run_249******* 
[INFO] 2021-07-09 16:50:29,172 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:29,173 [run_pretraining.py:  534]:	loss/total_loss, 2.995183229446411, 250
[INFO] 2021-07-09 16:50:29,173 [run_pretraining.py:  535]:	loss/mlm_loss, 2.995183229446411, 250
[INFO] 2021-07-09 16:50:29,173 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4900000425986946e-06, 250
[INFO] 2021-07-09 16:50:29,173 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 250
[INFO] 2021-07-09 16:50:29,173 [run_pretraining.py:  558]:	worker_index: 7, step: 250, cost: 2.995183, mlm loss: 2.995183, speed: 0.443475 steps/s, speed: 3.547798 samples/s, speed: 1816.472612 tokens/s, learning rate: 2.490e-06, loss_scalings: 4398.047363, pp_loss: 2.962522
[INFO] 2021-07-09 16:50:29,173 [run_pretraining.py:  512]:	********exe.run_250******* 
[INFO] 2021-07-09 16:50:31,399 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:31,400 [run_pretraining.py:  534]:	loss/total_loss, 2.9686501026153564, 251
[INFO] 2021-07-09 16:50:31,400 [run_pretraining.py:  535]:	loss/mlm_loss, 2.9686501026153564, 251
[INFO] 2021-07-09 16:50:31,400 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.499999936844688e-06, 251
[INFO] 2021-07-09 16:50:31,400 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 251
[INFO] 2021-07-09 16:50:31,400 [run_pretraining.py:  558]:	worker_index: 7, step: 251, cost: 2.968650, mlm loss: 2.968650, speed: 0.449129 steps/s, speed: 3.593035 samples/s, speed: 1839.634005 tokens/s, learning rate: 2.500e-06, loss_scalings: 4398.047363, pp_loss: 2.954787
[INFO] 2021-07-09 16:50:31,400 [run_pretraining.py:  512]:	********exe.run_251******* 
[INFO] 2021-07-09 16:50:33,752 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:33,753 [run_pretraining.py:  534]:	loss/total_loss, 2.9565823078155518, 252
[INFO] 2021-07-09 16:50:33,753 [run_pretraining.py:  535]:	loss/mlm_loss, 2.9565823078155518, 252
[INFO] 2021-07-09 16:50:33,753 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5100000584643567e-06, 252
[INFO] 2021-07-09 16:50:33,753 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 252
[INFO] 2021-07-09 16:50:33,753 [run_pretraining.py:  558]:	worker_index: 7, step: 252, cost: 2.956582, mlm loss: 2.956582, speed: 0.425106 steps/s, speed: 3.400844 samples/s, speed: 1741.232371 tokens/s, learning rate: 2.510e-06, loss_scalings: 4398.047363, pp_loss: 2.969266
[INFO] 2021-07-09 16:50:33,753 [run_pretraining.py:  512]:	********exe.run_252******* 
[INFO] 2021-07-09 16:50:35,970 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:35,970 [run_pretraining.py:  534]:	loss/total_loss, 2.976942539215088, 253
[INFO] 2021-07-09 16:50:35,970 [run_pretraining.py:  535]:	loss/mlm_loss, 2.976942539215088, 253
[INFO] 2021-07-09 16:50:35,970 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.51999995271035e-06, 253
[INFO] 2021-07-09 16:50:35,970 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 253
[INFO] 2021-07-09 16:50:35,970 [run_pretraining.py:  558]:	worker_index: 7, step: 253, cost: 2.976943, mlm loss: 2.976943, speed: 0.451177 steps/s, speed: 3.609414 samples/s, speed: 1848.020079 tokens/s, learning rate: 2.520e-06, loss_scalings: 4398.047363, pp_loss: 2.989413
[INFO] 2021-07-09 16:50:35,970 [run_pretraining.py:  512]:	********exe.run_253******* 
[INFO] 2021-07-09 16:50:38,202 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:38,203 [run_pretraining.py:  534]:	loss/total_loss, 3.0727646350860596, 254
[INFO] 2021-07-09 16:50:38,203 [run_pretraining.py:  535]:	loss/mlm_loss, 3.0727646350860596, 254
[INFO] 2021-07-09 16:50:38,203 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5299998469563434e-06, 254
[INFO] 2021-07-09 16:50:38,203 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 254
[INFO] 2021-07-09 16:50:38,203 [run_pretraining.py:  558]:	worker_index: 7, step: 254, cost: 3.072765, mlm loss: 3.072765, speed: 0.448011 steps/s, speed: 3.584088 samples/s, speed: 1835.052829 tokens/s, learning rate: 2.530e-06, loss_scalings: 4398.047363, pp_loss: 3.000484
[INFO] 2021-07-09 16:50:38,203 [run_pretraining.py:  512]:	********exe.run_254******* 
[INFO] 2021-07-09 16:50:40,438 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:40,439 [run_pretraining.py:  534]:	loss/total_loss, 3.0077266693115234, 255
[INFO] 2021-07-09 16:50:40,439 [run_pretraining.py:  535]:	loss/mlm_loss, 3.0077266693115234, 255
[INFO] 2021-07-09 16:50:40,439 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.539999968576012e-06, 255
[INFO] 2021-07-09 16:50:40,439 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 255
[INFO] 2021-07-09 16:50:40,439 [run_pretraining.py:  558]:	worker_index: 7, step: 255, cost: 3.007727, mlm loss: 3.007727, speed: 0.447379 steps/s, speed: 3.579032 samples/s, speed: 1832.464259 tokens/s, learning rate: 2.540e-06, loss_scalings: 4398.047363, pp_loss: 3.012113
[INFO] 2021-07-09 16:50:40,439 [run_pretraining.py:  512]:	********exe.run_255******* 
[INFO] 2021-07-09 16:50:42,664 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:42,664 [run_pretraining.py:  534]:	loss/total_loss, 3.053966522216797, 256
[INFO] 2021-07-09 16:50:42,665 [run_pretraining.py:  535]:	loss/mlm_loss, 3.053966522216797, 256
[INFO] 2021-07-09 16:50:42,665 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5499998628220055e-06, 256
[INFO] 2021-07-09 16:50:42,665 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 256
[INFO] 2021-07-09 16:50:42,665 [run_pretraining.py:  558]:	worker_index: 7, step: 256, cost: 3.053967, mlm loss: 3.053967, speed: 0.449392 steps/s, speed: 3.595139 samples/s, speed: 1840.710985 tokens/s, learning rate: 2.550e-06, loss_scalings: 4398.047363, pp_loss: 3.059741
[INFO] 2021-07-09 16:50:42,665 [run_pretraining.py:  512]:	********exe.run_256******* 
[INFO] 2021-07-09 16:50:44,878 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:44,879 [run_pretraining.py:  534]:	loss/total_loss, 3.0858559608459473, 257
[INFO] 2021-07-09 16:50:44,879 [run_pretraining.py:  535]:	loss/mlm_loss, 3.0858559608459473, 257
[INFO] 2021-07-09 16:50:44,879 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.559999757067999e-06, 257
[INFO] 2021-07-09 16:50:44,879 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 257
[INFO] 2021-07-09 16:50:44,879 [run_pretraining.py:  558]:	worker_index: 7, step: 257, cost: 3.085856, mlm loss: 3.085856, speed: 0.451771 steps/s, speed: 3.614167 samples/s, speed: 1850.453481 tokens/s, learning rate: 2.560e-06, loss_scalings: 4398.047363, pp_loss: 3.067313
[INFO] 2021-07-09 16:50:44,879 [run_pretraining.py:  512]:	********exe.run_257******* 
[INFO] 2021-07-09 16:50:47,093 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:47,094 [run_pretraining.py:  534]:	loss/total_loss, 3.061124324798584, 258
[INFO] 2021-07-09 16:50:47,094 [run_pretraining.py:  535]:	loss/mlm_loss, 3.061124324798584, 258
[INFO] 2021-07-09 16:50:47,094 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5699998786876677e-06, 258
[INFO] 2021-07-09 16:50:47,094 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 258
[INFO] 2021-07-09 16:50:47,094 [run_pretraining.py:  558]:	worker_index: 7, step: 258, cost: 3.061124, mlm loss: 3.061124, speed: 0.451562 steps/s, speed: 3.612496 samples/s, speed: 1849.597826 tokens/s, learning rate: 2.570e-06, loss_scalings: 4398.047363, pp_loss: 3.106270
[INFO] 2021-07-09 16:50:47,094 [run_pretraining.py:  512]:	********exe.run_258******* 
[INFO] 2021-07-09 16:50:49,510 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:49,511 [run_pretraining.py:  534]:	loss/total_loss, 3.1065187454223633, 259
[INFO] 2021-07-09 16:50:49,511 [run_pretraining.py:  535]:	loss/mlm_loss, 3.1065187454223633, 259
[INFO] 2021-07-09 16:50:49,511 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5800000003073364e-06, 259
[INFO] 2021-07-09 16:50:49,511 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 259
[INFO] 2021-07-09 16:50:49,511 [run_pretraining.py:  558]:	worker_index: 7, step: 259, cost: 3.106519, mlm loss: 3.106519, speed: 0.413906 steps/s, speed: 3.311251 samples/s, speed: 1695.360468 tokens/s, learning rate: 2.580e-06, loss_scalings: 4398.047363, pp_loss: 3.120770
[INFO] 2021-07-09 16:50:49,511 [run_pretraining.py:  512]:	********exe.run_259******* 
[INFO] 2021-07-09 16:50:51,873 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:51,873 [run_pretraining.py:  534]:	loss/total_loss, 3.1914024353027344, 260
[INFO] 2021-07-09 16:50:51,873 [run_pretraining.py:  535]:	loss/mlm_loss, 3.1914024353027344, 260
[INFO] 2021-07-09 16:50:51,874 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.58999989455333e-06, 260
[INFO] 2021-07-09 16:50:51,874 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 260
[INFO] 2021-07-09 16:50:51,874 [run_pretraining.py:  558]:	worker_index: 7, step: 260, cost: 3.191402, mlm loss: 3.191402, speed: 0.423357 steps/s, speed: 3.386854 samples/s, speed: 1734.069021 tokens/s, learning rate: 2.590e-06, loss_scalings: 4398.047363, pp_loss: 3.186348
[INFO] 2021-07-09 16:50:51,874 [run_pretraining.py:  512]:	********exe.run_260******* 
[INFO] 2021-07-09 16:50:54,312 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:54,312 [run_pretraining.py:  534]:	loss/total_loss, 3.169173002243042, 261
[INFO] 2021-07-09 16:50:54,312 [run_pretraining.py:  535]:	loss/mlm_loss, 3.169173002243042, 261
[INFO] 2021-07-09 16:50:54,312 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6000000161729986e-06, 261
[INFO] 2021-07-09 16:50:54,313 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 261
[INFO] 2021-07-09 16:50:54,313 [run_pretraining.py:  558]:	worker_index: 7, step: 261, cost: 3.169173, mlm loss: 3.169173, speed: 0.410128 steps/s, speed: 3.281023 samples/s, speed: 1679.883630 tokens/s, learning rate: 2.600e-06, loss_scalings: 3518.437988, pp_loss: 3.182864
[INFO] 2021-07-09 16:50:54,313 [run_pretraining.py:  512]:	********exe.run_261******* 
[INFO] 2021-07-09 16:50:56,798 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:56,799 [run_pretraining.py:  534]:	loss/total_loss, 3.1998772621154785, 262
[INFO] 2021-07-09 16:50:56,799 [run_pretraining.py:  535]:	loss/mlm_loss, 3.1998772621154785, 262
[INFO] 2021-07-09 16:50:56,799 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.609999910418992e-06, 262
[INFO] 2021-07-09 16:50:56,799 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 262
[INFO] 2021-07-09 16:50:56,799 [run_pretraining.py:  558]:	worker_index: 7, step: 262, cost: 3.199877, mlm loss: 3.199877, speed: 0.402305 steps/s, speed: 3.218437 samples/s, speed: 1647.839543 tokens/s, learning rate: 2.610e-06, loss_scalings: 3518.437988, pp_loss: 3.206924
[INFO] 2021-07-09 16:50:56,799 [run_pretraining.py:  512]:	********exe.run_262******* 
[INFO] 2021-07-09 16:50:59,278 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:59,278 [run_pretraining.py:  534]:	loss/total_loss, 3.1787216663360596, 263
[INFO] 2021-07-09 16:50:59,278 [run_pretraining.py:  535]:	loss/mlm_loss, 3.1787216663360596, 263
[INFO] 2021-07-09 16:50:59,278 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6200000320386607e-06, 263
[INFO] 2021-07-09 16:50:59,278 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 263
[INFO] 2021-07-09 16:50:59,278 [run_pretraining.py:  558]:	worker_index: 7, step: 263, cost: 3.178722, mlm loss: 3.178722, speed: 0.403407 steps/s, speed: 3.227254 samples/s, speed: 1652.353933 tokens/s, learning rate: 2.620e-06, loss_scalings: 3518.437988, pp_loss: 3.259065
[INFO] 2021-07-09 16:50:59,279 [run_pretraining.py:  512]:	********exe.run_263******* 
[INFO] 2021-07-09 16:51:01,505 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:01,505 [run_pretraining.py:  534]:	loss/total_loss, 3.282438278198242, 264
[INFO] 2021-07-09 16:51:01,506 [run_pretraining.py:  535]:	loss/mlm_loss, 3.282438278198242, 264
[INFO] 2021-07-09 16:51:01,506 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.629999926284654e-06, 264
[INFO] 2021-07-09 16:51:01,506 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 264
[INFO] 2021-07-09 16:51:01,506 [run_pretraining.py:  558]:	worker_index: 7, step: 264, cost: 3.282438, mlm loss: 3.282438, speed: 0.449097 steps/s, speed: 3.592773 samples/s, speed: 1839.499865 tokens/s, learning rate: 2.630e-06, loss_scalings: 3518.437988, pp_loss: 3.299434
[INFO] 2021-07-09 16:51:01,506 [run_pretraining.py:  512]:	********exe.run_264******* 
[INFO] 2021-07-09 16:51:03,741 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:03,741 [run_pretraining.py:  534]:	loss/total_loss, 3.30482816696167, 265
[INFO] 2021-07-09 16:51:03,741 [run_pretraining.py:  535]:	loss/mlm_loss, 3.30482816696167, 265
[INFO] 2021-07-09 16:51:03,741 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6399998205306474e-06, 265
[INFO] 2021-07-09 16:51:03,741 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 265
[INFO] 2021-07-09 16:51:03,742 [run_pretraining.py:  558]:	worker_index: 7, step: 265, cost: 3.304828, mlm loss: 3.304828, speed: 0.447408 steps/s, speed: 3.579264 samples/s, speed: 1832.583105 tokens/s, learning rate: 2.640e-06, loss_scalings: 3518.437988, pp_loss: 3.303655
[INFO] 2021-07-09 16:51:03,742 [run_pretraining.py:  512]:	********exe.run_265******* 
[INFO] 2021-07-09 16:51:05,954 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:05,955 [run_pretraining.py:  534]:	loss/total_loss, 3.25331449508667, 266
[INFO] 2021-07-09 16:51:05,955 [run_pretraining.py:  535]:	loss/mlm_loss, 3.25331449508667, 266
[INFO] 2021-07-09 16:51:05,955 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.649999942150316e-06, 266
[INFO] 2021-07-09 16:51:05,955 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 266
[INFO] 2021-07-09 16:51:05,955 [run_pretraining.py:  558]:	worker_index: 7, step: 266, cost: 3.253314, mlm loss: 3.253314, speed: 0.451892 steps/s, speed: 3.615139 samples/s, speed: 1850.951101 tokens/s, learning rate: 2.650e-06, loss_scalings: 3518.437988, pp_loss: 3.281780
[INFO] 2021-07-09 16:51:05,955 [run_pretraining.py:  512]:	********exe.run_266******* 
[INFO] 2021-07-09 16:51:08,195 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:08,195 [run_pretraining.py:  534]:	loss/total_loss, 3.231215715408325, 267
[INFO] 2021-07-09 16:51:08,195 [run_pretraining.py:  535]:	loss/mlm_loss, 3.231215715408325, 267
[INFO] 2021-07-09 16:51:08,196 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6599998363963095e-06, 267
[INFO] 2021-07-09 16:51:08,196 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 267
[INFO] 2021-07-09 16:51:08,196 [run_pretraining.py:  558]:	worker_index: 7, step: 267, cost: 3.231216, mlm loss: 3.231216, speed: 0.446441 steps/s, speed: 3.571529 samples/s, speed: 1828.622999 tokens/s, learning rate: 2.660e-06, loss_scalings: 3518.437988, pp_loss: 3.256890
[INFO] 2021-07-09 16:51:08,196 [run_pretraining.py:  512]:	********exe.run_267******* 
[INFO] 2021-07-09 16:51:10,434 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:10,434 [run_pretraining.py:  534]:	loss/total_loss, 3.225236415863037, 268
[INFO] 2021-07-09 16:51:10,434 [run_pretraining.py:  535]:	loss/mlm_loss, 3.225236415863037, 268
[INFO] 2021-07-09 16:51:10,434 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6699999580159783e-06, 268
[INFO] 2021-07-09 16:51:10,434 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 268
[INFO] 2021-07-09 16:51:10,434 [run_pretraining.py:  558]:	worker_index: 7, step: 268, cost: 3.225236, mlm loss: 3.225236, speed: 0.446826 steps/s, speed: 3.574606 samples/s, speed: 1830.198395 tokens/s, learning rate: 2.670e-06, loss_scalings: 3518.437988, pp_loss: 3.200170
[INFO] 2021-07-09 16:51:10,434 [run_pretraining.py:  512]:	********exe.run_268******* 
[INFO] 2021-07-09 16:51:12,659 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:12,659 [run_pretraining.py:  534]:	loss/total_loss, 3.1516408920288086, 269
[INFO] 2021-07-09 16:51:12,659 [run_pretraining.py:  535]:	loss/mlm_loss, 3.1516408920288086, 269
[INFO] 2021-07-09 16:51:12,660 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6799998522619717e-06, 269
[INFO] 2021-07-09 16:51:12,660 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 269
[INFO] 2021-07-09 16:51:12,660 [run_pretraining.py:  558]:	worker_index: 7, step: 269, cost: 3.151641, mlm loss: 3.151641, speed: 0.449507 steps/s, speed: 3.596056 samples/s, speed: 1841.180884 tokens/s, learning rate: 2.680e-06, loss_scalings: 3518.437988, pp_loss: 3.179434
[INFO] 2021-07-09 16:51:12,660 [run_pretraining.py:  512]:	********exe.run_269******* 
[INFO] 2021-07-09 16:51:14,858 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:14,858 [run_pretraining.py:  534]:	loss/total_loss, 3.160264730453491, 270
[INFO] 2021-07-09 16:51:14,858 [run_pretraining.py:  535]:	loss/mlm_loss, 3.160264730453491, 270
[INFO] 2021-07-09 16:51:14,858 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6899999738816405e-06, 270
[INFO] 2021-07-09 16:51:14,859 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 270
[INFO] 2021-07-09 16:51:14,859 [run_pretraining.py:  558]:	worker_index: 7, step: 270, cost: 3.160265, mlm loss: 3.160265, speed: 0.454901 steps/s, speed: 3.639206 samples/s, speed: 1863.273428 tokens/s, learning rate: 2.690e-06, loss_scalings: 3518.437988, pp_loss: 3.166698
[INFO] 2021-07-09 16:51:14,859 [run_pretraining.py:  512]:	********exe.run_270******* 
[INFO] 2021-07-09 16:51:17,077 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:17,078 [run_pretraining.py:  534]:	loss/total_loss, 3.170379161834717, 271
[INFO] 2021-07-09 16:51:17,078 [run_pretraining.py:  535]:	loss/mlm_loss, 3.170379161834717, 271
[INFO] 2021-07-09 16:51:17,078 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7000000955013093e-06, 271
[INFO] 2021-07-09 16:51:17,078 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 271
[INFO] 2021-07-09 16:51:17,078 [run_pretraining.py:  558]:	worker_index: 7, step: 271, cost: 3.170379, mlm loss: 3.170379, speed: 0.450690 steps/s, speed: 3.605518 samples/s, speed: 1846.025195 tokens/s, learning rate: 2.700e-06, loss_scalings: 3518.437988, pp_loss: 3.182747
[INFO] 2021-07-09 16:51:17,078 [run_pretraining.py:  512]:	********exe.run_271******* 
[INFO] 2021-07-09 16:51:19,303 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:19,304 [run_pretraining.py:  534]:	loss/total_loss, 3.1164472103118896, 272
[INFO] 2021-07-09 16:51:19,304 [run_pretraining.py:  535]:	loss/mlm_loss, 3.1164472103118896, 272
[INFO] 2021-07-09 16:51:19,304 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7099999897473026e-06, 272
[INFO] 2021-07-09 16:51:19,304 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 272
[INFO] 2021-07-09 16:51:19,304 [run_pretraining.py:  558]:	worker_index: 7, step: 272, cost: 3.116447, mlm loss: 3.116447, speed: 0.449398 steps/s, speed: 3.595188 samples/s, speed: 1840.736230 tokens/s, learning rate: 2.710e-06, loss_scalings: 3518.437988, pp_loss: 3.144147
[INFO] 2021-07-09 16:51:19,304 [run_pretraining.py:  512]:	********exe.run_272******* 
[INFO] 2021-07-09 16:51:21,538 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:21,538 [run_pretraining.py:  534]:	loss/total_loss, 3.142202854156494, 273
[INFO] 2021-07-09 16:51:21,538 [run_pretraining.py:  535]:	loss/mlm_loss, 3.142202854156494, 273
[INFO] 2021-07-09 16:51:21,538 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.719999883993296e-06, 273
[INFO] 2021-07-09 16:51:21,538 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 273
[INFO] 2021-07-09 16:51:21,538 [run_pretraining.py:  558]:	worker_index: 7, step: 273, cost: 3.142203, mlm loss: 3.142203, speed: 0.447673 steps/s, speed: 3.581386 samples/s, speed: 1833.669849 tokens/s, learning rate: 2.720e-06, loss_scalings: 3518.437988, pp_loss: 3.098421
[INFO] 2021-07-09 16:51:21,538 [run_pretraining.py:  512]:	********exe.run_273******* 
[INFO] 2021-07-09 16:51:23,785 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:23,785 [run_pretraining.py:  534]:	loss/total_loss, 3.032219886779785, 274
[INFO] 2021-07-09 16:51:23,785 [run_pretraining.py:  535]:	loss/mlm_loss, 3.032219886779785, 274
[INFO] 2021-07-09 16:51:23,785 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7300000056129647e-06, 274
[INFO] 2021-07-09 16:51:23,785 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 274
[INFO] 2021-07-09 16:51:23,785 [run_pretraining.py:  558]:	worker_index: 7, step: 274, cost: 3.032220, mlm loss: 3.032220, speed: 0.445153 steps/s, speed: 3.561227 samples/s, speed: 1823.347988 tokens/s, learning rate: 2.730e-06, loss_scalings: 3518.437988, pp_loss: 3.065751
[INFO] 2021-07-09 16:51:23,786 [run_pretraining.py:  512]:	********exe.run_274******* 
[INFO] 2021-07-09 16:51:26,018 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:26,018 [run_pretraining.py:  534]:	loss/total_loss, 3.0313785076141357, 275
[INFO] 2021-07-09 16:51:26,018 [run_pretraining.py:  535]:	loss/mlm_loss, 3.0313785076141357, 275
[INFO] 2021-07-09 16:51:26,018 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.739999899858958e-06, 275
[INFO] 2021-07-09 16:51:26,018 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 275
[INFO] 2021-07-09 16:51:26,019 [run_pretraining.py:  558]:	worker_index: 7, step: 275, cost: 3.031379, mlm loss: 3.031379, speed: 0.447952 steps/s, speed: 3.583615 samples/s, speed: 1834.810789 tokens/s, learning rate: 2.740e-06, loss_scalings: 3518.437988, pp_loss: 3.028403
[INFO] 2021-07-09 16:51:26,019 [run_pretraining.py:  512]:	********exe.run_275******* 
[INFO] 2021-07-09 16:51:28,270 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:28,271 [run_pretraining.py:  534]:	loss/total_loss, 2.9550604820251465, 276
[INFO] 2021-07-09 16:51:28,271 [run_pretraining.py:  535]:	loss/mlm_loss, 2.9550604820251465, 276
[INFO] 2021-07-09 16:51:28,271 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.750000021478627e-06, 276
[INFO] 2021-07-09 16:51:28,271 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 276
[INFO] 2021-07-09 16:51:28,271 [run_pretraining.py:  558]:	worker_index: 7, step: 276, cost: 2.955060, mlm loss: 2.955060, speed: 0.444055 steps/s, speed: 3.552441 samples/s, speed: 1818.849585 tokens/s, learning rate: 2.750e-06, loss_scalings: 3518.437988, pp_loss: 2.986221
[INFO] 2021-07-09 16:51:28,271 [run_pretraining.py:  512]:	********exe.run_276******* 
[INFO] 2021-07-09 16:51:30,494 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:30,495 [run_pretraining.py:  534]:	loss/total_loss, 2.965747833251953, 277
[INFO] 2021-07-09 16:51:30,495 [run_pretraining.py:  535]:	loss/mlm_loss, 2.965747833251953, 277
[INFO] 2021-07-09 16:51:30,495 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7599999157246202e-06, 277
[INFO] 2021-07-09 16:51:30,495 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 277
[INFO] 2021-07-09 16:51:30,495 [run_pretraining.py:  558]:	worker_index: 7, step: 277, cost: 2.965748, mlm loss: 2.965748, speed: 0.449814 steps/s, speed: 3.598515 samples/s, speed: 1842.439862 tokens/s, learning rate: 2.760e-06, loss_scalings: 3518.437988, pp_loss: 2.977028
[INFO] 2021-07-09 16:51:30,495 [run_pretraining.py:  512]:	********exe.run_277******* 
[INFO] 2021-07-09 16:51:32,772 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:32,772 [run_pretraining.py:  534]:	loss/total_loss, 3.004570960998535, 278
[INFO] 2021-07-09 16:51:32,772 [run_pretraining.py:  535]:	loss/mlm_loss, 3.004570960998535, 278
[INFO] 2021-07-09 16:51:32,772 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7699998099706136e-06, 278
[INFO] 2021-07-09 16:51:32,772 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 278
[INFO] 2021-07-09 16:51:32,772 [run_pretraining.py:  558]:	worker_index: 7, step: 278, cost: 3.004571, mlm loss: 3.004571, speed: 0.439188 steps/s, speed: 3.513500 samples/s, speed: 1798.912245 tokens/s, learning rate: 2.770e-06, loss_scalings: 3518.437988, pp_loss: 2.968229
[INFO] 2021-07-09 16:51:32,773 [run_pretraining.py:  512]:	********exe.run_278******* 
[INFO] 2021-07-09 16:51:35,102 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:35,103 [run_pretraining.py:  534]:	loss/total_loss, 2.94150972366333, 279
[INFO] 2021-07-09 16:51:35,103 [run_pretraining.py:  535]:	loss/mlm_loss, 2.94150972366333, 279
[INFO] 2021-07-09 16:51:35,103 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7799999315902824e-06, 279
[INFO] 2021-07-09 16:51:35,103 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 279
[INFO] 2021-07-09 16:51:35,103 [run_pretraining.py:  558]:	worker_index: 7, step: 279, cost: 2.941510, mlm loss: 2.941510, speed: 0.429161 steps/s, speed: 3.433292 samples/s, speed: 1757.845359 tokens/s, learning rate: 2.780e-06, loss_scalings: 2814.750488, pp_loss: 2.952258
[INFO] 2021-07-09 16:51:35,103 [run_pretraining.py:  512]:	********exe.run_279******* 
[INFO] 2021-07-09 16:51:37,329 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:37,330 [run_pretraining.py:  534]:	loss/total_loss, 3.0436291694641113, 280
[INFO] 2021-07-09 16:51:37,330 [run_pretraining.py:  535]:	loss/mlm_loss, 3.0436291694641113, 280
[INFO] 2021-07-09 16:51:37,330 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7899998258362757e-06, 280
[INFO] 2021-07-09 16:51:37,330 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 280
[INFO] 2021-07-09 16:51:37,330 [run_pretraining.py:  558]:	worker_index: 7, step: 280, cost: 3.043629, mlm loss: 3.043629, speed: 0.449220 steps/s, speed: 3.593759 samples/s, speed: 1840.004814 tokens/s, learning rate: 2.790e-06, loss_scalings: 2814.750488, pp_loss: 2.978370
[INFO] 2021-07-09 16:51:37,330 [run_pretraining.py:  512]:	********exe.run_280******* 
[INFO] 2021-07-09 16:51:39,562 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:39,562 [run_pretraining.py:  534]:	loss/total_loss, 2.9305038452148438, 281
[INFO] 2021-07-09 16:51:39,562 [run_pretraining.py:  535]:	loss/mlm_loss, 2.9305038452148438, 281
[INFO] 2021-07-09 16:51:39,562 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7999999474559445e-06, 281
[INFO] 2021-07-09 16:51:39,563 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 281
[INFO] 2021-07-09 16:51:39,563 [run_pretraining.py:  558]:	worker_index: 7, step: 281, cost: 2.930504, mlm loss: 2.930504, speed: 0.448019 steps/s, speed: 3.584151 samples/s, speed: 1835.085367 tokens/s, learning rate: 2.800e-06, loss_scalings: 2814.750488, pp_loss: 2.939648
[INFO] 2021-07-09 16:51:39,563 [run_pretraining.py:  512]:	********exe.run_281******* 
[INFO] 2021-07-09 16:51:41,777 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:41,778 [run_pretraining.py:  534]:	loss/total_loss, 2.9894063472747803, 282
[INFO] 2021-07-09 16:51:41,778 [run_pretraining.py:  535]:	loss/mlm_loss, 2.9894063472747803, 282
[INFO] 2021-07-09 16:51:41,778 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8100000690756133e-06, 282
[INFO] 2021-07-09 16:51:41,778 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 282
[INFO] 2021-07-09 16:51:41,778 [run_pretraining.py:  558]:	worker_index: 7, step: 282, cost: 2.989406, mlm loss: 2.989406, speed: 0.451520 steps/s, speed: 3.612160 samples/s, speed: 1849.425994 tokens/s, learning rate: 2.810e-06, loss_scalings: 2814.750488, pp_loss: 2.963528
[INFO] 2021-07-09 16:51:41,778 [run_pretraining.py:  512]:	********exe.run_282******* 
[INFO] 2021-07-09 16:51:44,001 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:44,002 [run_pretraining.py:  534]:	loss/total_loss, 2.9993348121643066, 283
[INFO] 2021-07-09 16:51:44,002 [run_pretraining.py:  535]:	loss/mlm_loss, 2.9993348121643066, 283
[INFO] 2021-07-09 16:51:44,002 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8199999633216066e-06, 283
[INFO] 2021-07-09 16:51:44,002 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 283
[INFO] 2021-07-09 16:51:44,002 [run_pretraining.py:  558]:	worker_index: 7, step: 283, cost: 2.999335, mlm loss: 2.999335, speed: 0.449705 steps/s, speed: 3.597641 samples/s, speed: 1841.992032 tokens/s, learning rate: 2.820e-06, loss_scalings: 2814.750488, pp_loss: 3.008563
[INFO] 2021-07-09 16:51:44,002 [run_pretraining.py:  512]:	********exe.run_283******* 
[INFO] 2021-07-09 16:51:46,247 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:46,248 [run_pretraining.py:  534]:	loss/total_loss, 3.0179710388183594, 284
[INFO] 2021-07-09 16:51:46,248 [run_pretraining.py:  535]:	loss/mlm_loss, 3.0179710388183594, 284
[INFO] 2021-07-09 16:51:46,248 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8299998575676e-06, 284
[INFO] 2021-07-09 16:51:46,248 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 284
[INFO] 2021-07-09 16:51:46,248 [run_pretraining.py:  558]:	worker_index: 7, step: 284, cost: 3.017971, mlm loss: 3.017971, speed: 0.445402 steps/s, speed: 3.563213 samples/s, speed: 1824.364906 tokens/s, learning rate: 2.830e-06, loss_scalings: 2814.750488, pp_loss: 3.038976
[INFO] 2021-07-09 16:51:46,248 [run_pretraining.py:  512]:	********exe.run_284******* 
[INFO] 2021-07-09 16:51:48,455 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:48,456 [run_pretraining.py:  534]:	loss/total_loss, 3.1191935539245605, 285
[INFO] 2021-07-09 16:51:48,456 [run_pretraining.py:  535]:	loss/mlm_loss, 3.1191935539245605, 285
[INFO] 2021-07-09 16:51:48,456 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8399999791872688e-06, 285
[INFO] 2021-07-09 16:51:48,456 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 285
[INFO] 2021-07-09 16:51:48,456 [run_pretraining.py:  558]:	worker_index: 7, step: 285, cost: 3.119194, mlm loss: 3.119194, speed: 0.453065 steps/s, speed: 3.624519 samples/s, speed: 1855.753613 tokens/s, learning rate: 2.840e-06, loss_scalings: 2814.750488, pp_loss: 3.081052
[INFO] 2021-07-09 16:51:48,456 [run_pretraining.py:  512]:	********exe.run_285******* 
[INFO] 2021-07-09 16:51:50,652 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:50,653 [run_pretraining.py:  534]:	loss/total_loss, 3.157637596130371, 286
[INFO] 2021-07-09 16:51:50,653 [run_pretraining.py:  535]:	loss/mlm_loss, 3.157637596130371, 286
[INFO] 2021-07-09 16:51:50,653 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.849999873433262e-06, 286
[INFO] 2021-07-09 16:51:50,653 [run_pretraining.py:  539]:	lr/loss_scaling, 2251.800537109375, 286
[INFO] 2021-07-09 16:51:50,653 [run_pretraining.py:  558]:	worker_index: 7, step: 286, cost: 3.157638, mlm loss: 3.157638, speed: 0.455239 steps/s, speed: 3.641910 samples/s, speed: 1864.658130 tokens/s, learning rate: 2.850e-06, loss_scalings: 2251.800537, pp_loss: 3.152602
[INFO] 2021-07-09 16:51:50,653 [run_pretraining.py:  512]:	********exe.run_286******* 
[INFO] 2021-07-09 16:51:52,861 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:52,862 [run_pretraining.py:  534]:	loss/total_loss, 3.2091856002807617, 287
[INFO] 2021-07-09 16:51:52,862 [run_pretraining.py:  535]:	loss/mlm_loss, 3.2091856002807617, 287
[INFO] 2021-07-09 16:51:52,862 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.859999995052931e-06, 287
[INFO] 2021-07-09 16:51:52,862 [run_pretraining.py:  539]:	lr/loss_scaling, 2251.800537109375, 287
[INFO] 2021-07-09 16:51:52,862 [run_pretraining.py:  558]:	worker_index: 7, step: 287, cost: 3.209186, mlm loss: 3.209186, speed: 0.452919 steps/s, speed: 3.623352 samples/s, speed: 1855.156043 tokens/s, learning rate: 2.860e-06, loss_scalings: 2251.800537, pp_loss: 3.205568
[INFO] 2021-07-09 16:51:52,862 [run_pretraining.py:  512]:	********exe.run_287******* 
[INFO] 2021-07-09 16:51:55,085 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:55,086 [run_pretraining.py:  534]:	loss/total_loss, 3.2315115928649902, 288
[INFO] 2021-07-09 16:51:55,086 [run_pretraining.py:  535]:	loss/mlm_loss, 3.2315115928649902, 288
[INFO] 2021-07-09 16:51:55,086 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8699998892989242e-06, 288
[INFO] 2021-07-09 16:51:55,086 [run_pretraining.py:  539]:	lr/loss_scaling, 2251.800537109375, 288
[INFO] 2021-07-09 16:51:55,086 [run_pretraining.py:  558]:	worker_index: 7, step: 288, cost: 3.231512, mlm loss: 3.231512, speed: 0.449677 steps/s, speed: 3.597414 samples/s, speed: 1841.876110 tokens/s, learning rate: 2.870e-06, loss_scalings: 2251.800537, pp_loss: 3.252961
[INFO] 2021-07-09 16:51:55,086 [run_pretraining.py:  512]:	********exe.run_288******* 
[INFO] 2021-07-09 16:51:57,310 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:57,310 [run_pretraining.py:  534]:	loss/total_loss, 3.293226957321167, 289
[INFO] 2021-07-09 16:51:57,310 [run_pretraining.py:  535]:	loss/mlm_loss, 3.293226957321167, 289
[INFO] 2021-07-09 16:51:57,311 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8799997835449176e-06, 289
[INFO] 2021-07-09 16:51:57,311 [run_pretraining.py:  539]:	lr/loss_scaling, 2251.800537109375, 289
[INFO] 2021-07-09 16:51:57,311 [run_pretraining.py:  558]:	worker_index: 7, step: 289, cost: 3.293227, mlm loss: 3.293227, speed: 0.449708 steps/s, speed: 3.597667 samples/s, speed: 1842.005660 tokens/s, learning rate: 2.880e-06, loss_scalings: 2251.800537, pp_loss: 3.314468
[INFO] 2021-07-09 16:51:57,311 [run_pretraining.py:  512]:	********exe.run_289******* 
[INFO] 2021-07-09 16:51:59,571 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:59,571 [run_pretraining.py:  534]:	loss/total_loss, 3.345599412918091, 290
[INFO] 2021-07-09 16:51:59,571 [run_pretraining.py:  535]:	loss/mlm_loss, 3.345599412918091, 290
[INFO] 2021-07-09 16:51:59,571 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8899999051645864e-06, 290
[INFO] 2021-07-09 16:51:59,572 [run_pretraining.py:  539]:	lr/loss_scaling, 2251.800537109375, 290
[INFO] 2021-07-09 16:51:59,572 [run_pretraining.py:  558]:	worker_index: 7, step: 290, cost: 3.345599, mlm loss: 3.345599, speed: 0.442445 steps/s, speed: 3.539562 samples/s, speed: 1812.255751 tokens/s, learning rate: 2.890e-06, loss_scalings: 2251.800537, pp_loss: 3.387301
[INFO] 2021-07-09 16:51:59,572 [run_pretraining.py:  512]:	********exe.run_290******* 
[INFO] 2021-07-09 16:52:01,781 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:01,782 [run_pretraining.py:  534]:	loss/total_loss, 3.388279438018799, 291
[INFO] 2021-07-09 16:52:01,782 [run_pretraining.py:  535]:	loss/mlm_loss, 3.388279438018799, 291
[INFO] 2021-07-09 16:52:01,782 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8999997994105797e-06, 291
[INFO] 2021-07-09 16:52:01,782 [run_pretraining.py:  539]:	lr/loss_scaling, 2251.800537109375, 291
[INFO] 2021-07-09 16:52:01,782 [run_pretraining.py:  558]:	worker_index: 7, step: 291, cost: 3.388279, mlm loss: 3.388279, speed: 0.452482 steps/s, speed: 3.619859 samples/s, speed: 1853.368040 tokens/s, learning rate: 2.900e-06, loss_scalings: 2251.800537, pp_loss: 3.426334
[INFO] 2021-07-09 16:52:01,782 [run_pretraining.py:  512]:	********exe.run_291******* 
[INFO] 2021-07-09 16:52:03,991 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:03,991 [run_pretraining.py:  534]:	loss/total_loss, 3.513747215270996, 292
[INFO] 2021-07-09 16:52:03,991 [run_pretraining.py:  535]:	loss/mlm_loss, 3.513747215270996, 292
[INFO] 2021-07-09 16:52:03,991 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9099999210302485e-06, 292
[INFO] 2021-07-09 16:52:03,991 [run_pretraining.py:  539]:	lr/loss_scaling, 2251.800537109375, 292
[INFO] 2021-07-09 16:52:03,991 [run_pretraining.py:  558]:	worker_index: 7, step: 292, cost: 3.513747, mlm loss: 3.513747, speed: 0.452795 steps/s, speed: 3.622362 samples/s, speed: 1854.649152 tokens/s, learning rate: 2.910e-06, loss_scalings: 2251.800537, pp_loss: 3.505174
[INFO] 2021-07-09 16:52:03,992 [run_pretraining.py:  512]:	********exe.run_292******* 
[INFO] 2021-07-09 16:52:06,244 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:06,245 [run_pretraining.py:  534]:	loss/total_loss, 3.5351765155792236, 293
[INFO] 2021-07-09 16:52:06,245 [run_pretraining.py:  535]:	loss/mlm_loss, 3.5351765155792236, 293
[INFO] 2021-07-09 16:52:06,245 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9200000426499173e-06, 293
[INFO] 2021-07-09 16:52:06,245 [run_pretraining.py:  539]:	lr/loss_scaling, 2251.800537109375, 293
[INFO] 2021-07-09 16:52:06,245 [run_pretraining.py:  558]:	worker_index: 7, step: 293, cost: 3.535177, mlm loss: 3.535177, speed: 0.443815 steps/s, speed: 3.550516 samples/s, speed: 1817.864387 tokens/s, learning rate: 2.920e-06, loss_scalings: 2251.800537, pp_loss: 3.548759
[INFO] 2021-07-09 16:52:06,245 [run_pretraining.py:  512]:	********exe.run_293******* 
[INFO] 2021-07-09 16:52:08,495 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:08,495 [run_pretraining.py:  534]:	loss/total_loss, 3.6380772590637207, 294
[INFO] 2021-07-09 16:52:08,495 [run_pretraining.py:  535]:	loss/mlm_loss, 3.6380772590637207, 294
[INFO] 2021-07-09 16:52:08,495 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9299999368959107e-06, 294
[INFO] 2021-07-09 16:52:08,495 [run_pretraining.py:  539]:	lr/loss_scaling, 1801.4404296875, 294
[INFO] 2021-07-09 16:52:08,495 [run_pretraining.py:  558]:	worker_index: 7, step: 294, cost: 3.638077, mlm loss: 3.638077, speed: 0.444546 steps/s, speed: 3.556370 samples/s, speed: 1820.861399 tokens/s, learning rate: 2.930e-06, loss_scalings: 1801.440430, pp_loss: 3.649627
[INFO] 2021-07-09 16:52:08,496 [run_pretraining.py:  512]:	********exe.run_294******* 
[INFO] 2021-07-09 16:52:10,716 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:10,717 [run_pretraining.py:  534]:	loss/total_loss, 3.7069973945617676, 295
[INFO] 2021-07-09 16:52:10,717 [run_pretraining.py:  535]:	loss/mlm_loss, 3.7069973945617676, 295
[INFO] 2021-07-09 16:52:10,717 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9400000585155794e-06, 295
[INFO] 2021-07-09 16:52:10,717 [run_pretraining.py:  539]:	lr/loss_scaling, 1801.4404296875, 295
[INFO] 2021-07-09 16:52:10,717 [run_pretraining.py:  558]:	worker_index: 7, step: 295, cost: 3.706997, mlm loss: 3.706997, speed: 0.450193 steps/s, speed: 3.601542 samples/s, speed: 1843.989684 tokens/s, learning rate: 2.940e-06, loss_scalings: 1801.440430, pp_loss: 3.714927
[INFO] 2021-07-09 16:52:10,717 [run_pretraining.py:  512]:	********exe.run_295******* 
[INFO] 2021-07-09 16:52:13,034 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:13,035 [run_pretraining.py:  534]:	loss/total_loss, 3.782161235809326, 296
[INFO] 2021-07-09 16:52:13,035 [run_pretraining.py:  535]:	loss/mlm_loss, 3.782161235809326, 296
[INFO] 2021-07-09 16:52:13,035 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9499999527615728e-06, 296
[INFO] 2021-07-09 16:52:13,035 [run_pretraining.py:  539]:	lr/loss_scaling, 1801.4404296875, 296
[INFO] 2021-07-09 16:52:13,035 [run_pretraining.py:  558]:	worker_index: 7, step: 296, cost: 3.782161, mlm loss: 3.782161, speed: 0.431525 steps/s, speed: 3.452202 samples/s, speed: 1767.527352 tokens/s, learning rate: 2.950e-06, loss_scalings: 1801.440430, pp_loss: 3.777713
[INFO] 2021-07-09 16:52:13,035 [run_pretraining.py:  512]:	********exe.run_296******* 
[INFO] 2021-07-09 16:52:15,346 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:15,347 [run_pretraining.py:  534]:	loss/total_loss, 3.8139705657958984, 297
[INFO] 2021-07-09 16:52:15,347 [run_pretraining.py:  535]:	loss/mlm_loss, 3.8139705657958984, 297
[INFO] 2021-07-09 16:52:15,347 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.959999847007566e-06, 297
[INFO] 2021-07-09 16:52:15,347 [run_pretraining.py:  539]:	lr/loss_scaling, 1801.4404296875, 297
[INFO] 2021-07-09 16:52:15,347 [run_pretraining.py:  558]:	worker_index: 7, step: 297, cost: 3.813971, mlm loss: 3.813971, speed: 0.432752 steps/s, speed: 3.462015 samples/s, speed: 1772.551916 tokens/s, learning rate: 2.960e-06, loss_scalings: 1801.440430, pp_loss: 3.823274
[INFO] 2021-07-09 16:52:15,347 [run_pretraining.py:  512]:	********exe.run_297******* 
[INFO] 2021-07-09 16:52:17,548 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:17,549 [run_pretraining.py:  534]:	loss/total_loss, 3.8526041507720947, 298
[INFO] 2021-07-09 16:52:17,549 [run_pretraining.py:  535]:	loss/mlm_loss, 3.8526041507720947, 298
[INFO] 2021-07-09 16:52:17,549 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.969999968627235e-06, 298
[INFO] 2021-07-09 16:52:17,549 [run_pretraining.py:  539]:	lr/loss_scaling, 1801.4404296875, 298
[INFO] 2021-07-09 16:52:17,549 [run_pretraining.py:  558]:	worker_index: 7, step: 298, cost: 3.852604, mlm loss: 3.852604, speed: 0.454193 steps/s, speed: 3.633541 samples/s, speed: 1860.372782 tokens/s, learning rate: 2.970e-06, loss_scalings: 1801.440430, pp_loss: 3.910376
[INFO] 2021-07-09 16:52:17,549 [run_pretraining.py:  512]:	********exe.run_298******* 
[INFO] 2021-07-09 16:52:19,752 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:19,753 [run_pretraining.py:  534]:	loss/total_loss, 3.9333159923553467, 299
[INFO] 2021-07-09 16:52:19,753 [run_pretraining.py:  535]:	loss/mlm_loss, 3.9333159923553467, 299
[INFO] 2021-07-09 16:52:19,753 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9799998628732283e-06, 299
[INFO] 2021-07-09 16:52:19,753 [run_pretraining.py:  539]:	lr/loss_scaling, 1801.4404296875, 299
[INFO] 2021-07-09 16:52:19,753 [run_pretraining.py:  558]:	worker_index: 7, step: 299, cost: 3.933316, mlm loss: 3.933316, speed: 0.453901 steps/s, speed: 3.631209 samples/s, speed: 1859.179116 tokens/s, learning rate: 2.980e-06, loss_scalings: 1801.440430, pp_loss: 3.955921
[INFO] 2021-07-09 16:52:19,753 [run_pretraining.py:  512]:	********exe.run_299******* 
[INFO] 2021-07-09 16:52:21,953 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:21,953 [run_pretraining.py:  534]:	loss/total_loss, 4.040010929107666, 300
[INFO] 2021-07-09 16:52:21,953 [run_pretraining.py:  535]:	loss/mlm_loss, 4.040010929107666, 300
[INFO] 2021-07-09 16:52:21,953 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.989999984492897e-06, 300
[INFO] 2021-07-09 16:52:21,953 [run_pretraining.py:  539]:	lr/loss_scaling, 1801.4404296875, 300
[INFO] 2021-07-09 16:52:21,953 [run_pretraining.py:  558]:	worker_index: 7, step: 300, cost: 4.040011, mlm loss: 4.040011, speed: 0.454581 steps/s, speed: 3.636651 samples/s, speed: 1861.965445 tokens/s, learning rate: 2.990e-06, loss_scalings: 1801.440430, pp_loss: 3.943433
[INFO] 2021-07-09 16:52:21,954 [run_pretraining.py:  512]:	********exe.run_300******* 
[INFO] 2021-07-09 16:52:24,178 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:24,178 [run_pretraining.py:  534]:	loss/total_loss, 3.9385814666748047, 301
[INFO] 2021-07-09 16:52:24,178 [run_pretraining.py:  535]:	loss/mlm_loss, 3.9385814666748047, 301
[INFO] 2021-07-09 16:52:24,179 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9999998787388904e-06, 301
[INFO] 2021-07-09 16:52:24,179 [run_pretraining.py:  539]:	lr/loss_scaling, 1801.4404296875, 301
[INFO] 2021-07-09 16:52:24,179 [run_pretraining.py:  558]:	worker_index: 7, step: 301, cost: 3.938581, mlm loss: 3.938581, speed: 0.449520 steps/s, speed: 3.596160 samples/s, speed: 1841.233767 tokens/s, learning rate: 3.000e-06, loss_scalings: 1801.440430, pp_loss: 3.925644
[INFO] 2021-07-09 16:52:24,179 [run_pretraining.py:  512]:	********exe.run_301******* 
[INFO] 2021-07-09 16:52:26,478 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:26,478 [run_pretraining.py:  534]:	loss/total_loss, 3.929464817047119, 302
[INFO] 2021-07-09 16:52:26,479 [run_pretraining.py:  535]:	loss/mlm_loss, 3.929464817047119, 302
[INFO] 2021-07-09 16:52:26,479 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.0099997729848837e-06, 302
[INFO] 2021-07-09 16:52:26,479 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 302
[INFO] 2021-07-09 16:52:26,479 [run_pretraining.py:  558]:	worker_index: 7, step: 302, cost: 3.929465, mlm loss: 3.929465, speed: 0.434912 steps/s, speed: 3.479292 samples/s, speed: 1781.397730 tokens/s, learning rate: 3.010e-06, loss_scalings: 1441.152344, pp_loss: 3.927454
[INFO] 2021-07-09 16:52:26,479 [run_pretraining.py:  512]:	********exe.run_302******* 
[INFO] 2021-07-09 16:52:28,712 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:28,712 [run_pretraining.py:  534]:	loss/total_loss, 3.8604378700256348, 303
[INFO] 2021-07-09 16:52:28,712 [run_pretraining.py:  535]:	loss/mlm_loss, 3.8604378700256348, 303
[INFO] 2021-07-09 16:52:28,712 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.020000121978228e-06, 303
[INFO] 2021-07-09 16:52:28,712 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 303
[INFO] 2021-07-09 16:52:28,712 [run_pretraining.py:  558]:	worker_index: 7, step: 303, cost: 3.860438, mlm loss: 3.860438, speed: 0.447817 steps/s, speed: 3.582534 samples/s, speed: 1834.257179 tokens/s, learning rate: 3.020e-06, loss_scalings: 1441.152344, pp_loss: 3.923758
[INFO] 2021-07-09 16:52:28,713 [run_pretraining.py:  512]:	********exe.run_303******* 
[INFO] 2021-07-09 16:52:30,932 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:30,932 [run_pretraining.py:  534]:	loss/total_loss, 4.064470291137695, 304
[INFO] 2021-07-09 16:52:30,932 [run_pretraining.py:  535]:	loss/mlm_loss, 4.064470291137695, 304
[INFO] 2021-07-09 16:52:30,932 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.0300000162242213e-06, 304
[INFO] 2021-07-09 16:52:30,932 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 304
[INFO] 2021-07-09 16:52:30,933 [run_pretraining.py:  558]:	worker_index: 7, step: 304, cost: 4.064470, mlm loss: 4.064470, speed: 0.450566 steps/s, speed: 3.604529 samples/s, speed: 1845.518721 tokens/s, learning rate: 3.030e-06, loss_scalings: 1441.152344, pp_loss: 3.965227
[INFO] 2021-07-09 16:52:30,933 [run_pretraining.py:  512]:	********exe.run_304******* 
[INFO] 2021-07-09 16:52:33,188 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:33,189 [run_pretraining.py:  534]:	loss/total_loss, 3.9840774536132812, 305
[INFO] 2021-07-09 16:52:33,189 [run_pretraining.py:  535]:	loss/mlm_loss, 3.9840774536132812, 305
[INFO] 2021-07-09 16:52:33,189 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.0399999104702147e-06, 305
[INFO] 2021-07-09 16:52:33,189 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 305
[INFO] 2021-07-09 16:52:33,189 [run_pretraining.py:  558]:	worker_index: 7, step: 305, cost: 3.984077, mlm loss: 3.984077, speed: 0.443254 steps/s, speed: 3.546036 samples/s, speed: 1815.570377 tokens/s, learning rate: 3.040e-06, loss_scalings: 1441.152344, pp_loss: 3.985142
[INFO] 2021-07-09 16:52:33,189 [run_pretraining.py:  512]:	********exe.run_305******* 
[INFO] 2021-07-09 16:52:35,399 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:35,400 [run_pretraining.py:  534]:	loss/total_loss, 3.979519844055176, 306
[INFO] 2021-07-09 16:52:35,400 [run_pretraining.py:  535]:	loss/mlm_loss, 3.979519844055176, 306
[INFO] 2021-07-09 16:52:35,400 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.0500000320898835e-06, 306
[INFO] 2021-07-09 16:52:35,400 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 306
[INFO] 2021-07-09 16:52:35,400 [run_pretraining.py:  558]:	worker_index: 7, step: 306, cost: 3.979520, mlm loss: 3.979520, speed: 0.452463 steps/s, speed: 3.619706 samples/s, speed: 1853.289666 tokens/s, learning rate: 3.050e-06, loss_scalings: 1441.152344, pp_loss: 4.032220
[INFO] 2021-07-09 16:52:35,400 [run_pretraining.py:  512]:	********exe.run_306******* 
[INFO] 2021-07-09 16:52:37,600 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:37,600 [run_pretraining.py:  534]:	loss/total_loss, 4.032161235809326, 307
[INFO] 2021-07-09 16:52:37,601 [run_pretraining.py:  535]:	loss/mlm_loss, 4.032161235809326, 307
[INFO] 2021-07-09 16:52:37,601 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.059999926335877e-06, 307
[INFO] 2021-07-09 16:52:37,601 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 307
[INFO] 2021-07-09 16:52:37,601 [run_pretraining.py:  558]:	worker_index: 7, step: 307, cost: 4.032161, mlm loss: 4.032161, speed: 0.454523 steps/s, speed: 3.636184 samples/s, speed: 1861.726341 tokens/s, learning rate: 3.060e-06, loss_scalings: 1441.152344, pp_loss: 4.000932
[INFO] 2021-07-09 16:52:37,601 [run_pretraining.py:  512]:	********exe.run_307******* 
[INFO] 2021-07-09 16:52:39,796 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:39,797 [run_pretraining.py:  534]:	loss/total_loss, 4.0365891456604, 308
[INFO] 2021-07-09 16:52:39,797 [run_pretraining.py:  535]:	loss/mlm_loss, 4.0365891456604, 308
[INFO] 2021-07-09 16:52:39,797 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.06999982058187e-06, 308
[INFO] 2021-07-09 16:52:39,797 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 308
[INFO] 2021-07-09 16:52:39,797 [run_pretraining.py:  558]:	worker_index: 7, step: 308, cost: 4.036589, mlm loss: 4.036589, speed: 0.455404 steps/s, speed: 3.643232 samples/s, speed: 1865.334544 tokens/s, learning rate: 3.070e-06, loss_scalings: 1441.152344, pp_loss: 4.030419
[INFO] 2021-07-09 16:52:39,797 [run_pretraining.py:  512]:	********exe.run_308******* 
[INFO] 2021-07-09 16:52:42,017 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:42,017 [run_pretraining.py:  534]:	loss/total_loss, 4.107735633850098, 309
[INFO] 2021-07-09 16:52:42,017 [run_pretraining.py:  535]:	loss/mlm_loss, 4.107735633850098, 309
[INFO] 2021-07-09 16:52:42,017 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.079999942201539e-06, 309
[INFO] 2021-07-09 16:52:42,017 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 309
[INFO] 2021-07-09 16:52:42,018 [run_pretraining.py:  558]:	worker_index: 7, step: 309, cost: 4.107736, mlm loss: 4.107736, speed: 0.450537 steps/s, speed: 3.604300 samples/s, speed: 1845.401562 tokens/s, learning rate: 3.080e-06, loss_scalings: 1441.152344, pp_loss: 4.036586
[INFO] 2021-07-09 16:52:42,018 [run_pretraining.py:  512]:	********exe.run_309******* 
[INFO] 2021-07-09 16:52:44,247 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:44,248 [run_pretraining.py:  534]:	loss/total_loss, 4.037815093994141, 310
[INFO] 2021-07-09 16:52:44,248 [run_pretraining.py:  535]:	loss/mlm_loss, 4.037815093994141, 310
[INFO] 2021-07-09 16:52:44,248 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.0899998364475323e-06, 310
[INFO] 2021-07-09 16:52:44,248 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 310
[INFO] 2021-07-09 16:52:44,248 [run_pretraining.py:  558]:	worker_index: 7, step: 310, cost: 4.037815, mlm loss: 4.037815, speed: 0.448446 steps/s, speed: 3.587567 samples/s, speed: 1836.834520 tokens/s, learning rate: 3.090e-06, loss_scalings: 1441.152344, pp_loss: 3.996661
[INFO] 2021-07-09 16:52:44,248 [run_pretraining.py:  512]:	********exe.run_310******* 
[INFO] 2021-07-09 16:52:46,567 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:46,567 [run_pretraining.py:  534]:	loss/total_loss, 3.954110860824585, 311
[INFO] 2021-07-09 16:52:46,568 [run_pretraining.py:  535]:	loss/mlm_loss, 3.954110860824585, 311
[INFO] 2021-07-09 16:52:46,568 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.099999958067201e-06, 311
[INFO] 2021-07-09 16:52:46,568 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 311
[INFO] 2021-07-09 16:52:46,568 [run_pretraining.py:  558]:	worker_index: 7, step: 311, cost: 3.954111, mlm loss: 3.954111, speed: 0.431198 steps/s, speed: 3.449587 samples/s, speed: 1766.188317 tokens/s, learning rate: 3.100e-06, loss_scalings: 1441.152344, pp_loss: 3.928763
[INFO] 2021-07-09 16:52:46,568 [run_pretraining.py:  512]:	********exe.run_311******* 
[INFO] 2021-07-09 16:52:48,887 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:48,887 [run_pretraining.py:  534]:	loss/total_loss, 3.7928266525268555, 312
[INFO] 2021-07-09 16:52:48,887 [run_pretraining.py:  535]:	loss/mlm_loss, 3.7928266525268555, 312
[INFO] 2021-07-09 16:52:48,887 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.1099998523131944e-06, 312
[INFO] 2021-07-09 16:52:48,888 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 312
[INFO] 2021-07-09 16:52:48,888 [run_pretraining.py:  558]:	worker_index: 7, step: 312, cost: 3.792827, mlm loss: 3.792827, speed: 0.431205 steps/s, speed: 3.449644 samples/s, speed: 1766.217551 tokens/s, learning rate: 3.110e-06, loss_scalings: 1441.152344, pp_loss: 3.858666
[INFO] 2021-07-09 16:52:48,888 [run_pretraining.py:  512]:	********exe.run_312******* 
[INFO] 2021-07-09 16:52:51,098 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:51,099 [run_pretraining.py:  534]:	loss/total_loss, 3.89090895652771, 313
[INFO] 2021-07-09 16:52:51,099 [run_pretraining.py:  535]:	loss/mlm_loss, 3.89090895652771, 313
[INFO] 2021-07-09 16:52:51,099 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.1199997465591878e-06, 313
[INFO] 2021-07-09 16:52:51,099 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 313
[INFO] 2021-07-09 16:52:51,099 [run_pretraining.py:  558]:	worker_index: 7, step: 313, cost: 3.890909, mlm loss: 3.890909, speed: 0.452292 steps/s, speed: 3.618335 samples/s, speed: 1852.587397 tokens/s, learning rate: 3.120e-06, loss_scalings: 1441.152344, pp_loss: 3.801240
[INFO] 2021-07-09 16:52:51,099 [run_pretraining.py:  512]:	********exe.run_313******* 
[INFO] 2021-07-09 16:52:53,315 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:53,316 [run_pretraining.py:  534]:	loss/total_loss, 3.6556124687194824, 314
[INFO] 2021-07-09 16:52:53,316 [run_pretraining.py:  535]:	loss/mlm_loss, 3.6556124687194824, 314
[INFO] 2021-07-09 16:52:53,316 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.130000095552532e-06, 314
[INFO] 2021-07-09 16:52:53,316 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 314
[INFO] 2021-07-09 16:52:53,316 [run_pretraining.py:  558]:	worker_index: 7, step: 314, cost: 3.655612, mlm loss: 3.655612, speed: 0.451227 steps/s, speed: 3.609818 samples/s, speed: 1848.227042 tokens/s, learning rate: 3.130e-06, loss_scalings: 1441.152344, pp_loss: 3.683136
[INFO] 2021-07-09 16:52:53,316 [run_pretraining.py:  512]:	********exe.run_314******* 
[INFO] 2021-07-09 16:52:55,572 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:55,572 [run_pretraining.py:  534]:	loss/total_loss, 3.4830727577209473, 315
[INFO] 2021-07-09 16:52:55,572 [run_pretraining.py:  535]:	loss/mlm_loss, 3.4830727577209473, 315
[INFO] 2021-07-09 16:52:55,572 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.13999976242485e-06, 315
[INFO] 2021-07-09 16:52:55,573 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 315
[INFO] 2021-07-09 16:52:55,573 [run_pretraining.py:  558]:	worker_index: 7, step: 315, cost: 3.483073, mlm loss: 3.483073, speed: 0.443288 steps/s, speed: 3.546303 samples/s, speed: 1815.706998 tokens/s, learning rate: 3.140e-06, loss_scalings: 1441.152344, pp_loss: 3.498618
[INFO] 2021-07-09 16:52:55,573 [run_pretraining.py:  512]:	********exe.run_315******* 
[INFO] 2021-07-09 16:52:57,785 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:57,785 [run_pretraining.py:  534]:	loss/total_loss, 3.3567497730255127, 316
[INFO] 2021-07-09 16:52:57,785 [run_pretraining.py:  535]:	loss/mlm_loss, 3.3567497730255127, 316
[INFO] 2021-07-09 16:52:57,785 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.1499998840445187e-06, 316
[INFO] 2021-07-09 16:52:57,785 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 316
[INFO] 2021-07-09 16:52:57,785 [run_pretraining.py:  558]:	worker_index: 7, step: 316, cost: 3.356750, mlm loss: 3.356750, speed: 0.452054 steps/s, speed: 3.616433 samples/s, speed: 1851.613814 tokens/s, learning rate: 3.150e-06, loss_scalings: 1441.152344, pp_loss: 3.391285
[INFO] 2021-07-09 16:52:57,785 [run_pretraining.py:  512]:	********exe.run_316******* 
[INFO] 2021-07-09 16:52:59,997 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:59,998 [run_pretraining.py:  534]:	loss/total_loss, 3.3535780906677246, 317
[INFO] 2021-07-09 16:52:59,998 [run_pretraining.py:  535]:	loss/mlm_loss, 3.3535780906677246, 317
[INFO] 2021-07-09 16:52:59,998 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.159999778290512e-06, 317
[INFO] 2021-07-09 16:52:59,998 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 317
[INFO] 2021-07-09 16:52:59,998 [run_pretraining.py:  558]:	worker_index: 7, step: 317, cost: 3.353578, mlm loss: 3.353578, speed: 0.452075 steps/s, speed: 3.616600 samples/s, speed: 1851.699231 tokens/s, learning rate: 3.160e-06, loss_scalings: 1441.152344, pp_loss: 3.310645
[INFO] 2021-07-09 16:52:59,998 [run_pretraining.py:  512]:	********exe.run_317******* 
[INFO] 2021-07-09 16:53:02,288 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:02,289 [run_pretraining.py:  534]:	loss/total_loss, 3.2477457523345947, 318
[INFO] 2021-07-09 16:53:02,289 [run_pretraining.py:  535]:	loss/mlm_loss, 3.2477457523345947, 318
[INFO] 2021-07-09 16:53:02,289 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.169999899910181e-06, 318
[INFO] 2021-07-09 16:53:02,289 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 318
[INFO] 2021-07-09 16:53:02,289 [run_pretraining.py:  558]:	worker_index: 7, step: 318, cost: 3.247746, mlm loss: 3.247746, speed: 0.436632 steps/s, speed: 3.493060 samples/s, speed: 1788.446525 tokens/s, learning rate: 3.170e-06, loss_scalings: 1441.152344, pp_loss: 3.243807
[INFO] 2021-07-09 16:53:02,289 [run_pretraining.py:  512]:	********exe.run_318******* 
[INFO] 2021-07-09 16:53:04,642 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:04,642 [run_pretraining.py:  534]:	loss/total_loss, 3.2105915546417236, 319
[INFO] 2021-07-09 16:53:04,642 [run_pretraining.py:  535]:	loss/mlm_loss, 3.2105915546417236, 319
[INFO] 2021-07-09 16:53:04,642 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.1800000215298496e-06, 319
[INFO] 2021-07-09 16:53:04,643 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 319
[INFO] 2021-07-09 16:53:04,643 [run_pretraining.py:  558]:	worker_index: 7, step: 319, cost: 3.210592, mlm loss: 3.210592, speed: 0.424978 steps/s, speed: 3.399824 samples/s, speed: 1740.709972 tokens/s, learning rate: 3.180e-06, loss_scalings: 1441.152344, pp_loss: 3.234242
[INFO] 2021-07-09 16:53:04,643 [run_pretraining.py:  512]:	********exe.run_319******* 
[INFO] 2021-07-09 16:53:06,861 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:06,861 [run_pretraining.py:  534]:	loss/total_loss, 3.2824254035949707, 320
[INFO] 2021-07-09 16:53:06,861 [run_pretraining.py:  535]:	loss/mlm_loss, 3.2824254035949707, 320
[INFO] 2021-07-09 16:53:06,861 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.189999915775843e-06, 320
[INFO] 2021-07-09 16:53:06,862 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 320
[INFO] 2021-07-09 16:53:06,862 [run_pretraining.py:  558]:	worker_index: 7, step: 320, cost: 3.282425, mlm loss: 3.282425, speed: 0.450798 steps/s, speed: 3.606385 samples/s, speed: 1846.469035 tokens/s, learning rate: 3.190e-06, loss_scalings: 1441.152344, pp_loss: 3.215974
[INFO] 2021-07-09 16:53:06,862 [run_pretraining.py:  512]:	********exe.run_320******* 
[INFO] 2021-07-09 16:53:09,071 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:09,072 [run_pretraining.py:  534]:	loss/total_loss, 3.2442593574523926, 321
[INFO] 2021-07-09 16:53:09,072 [run_pretraining.py:  535]:	loss/mlm_loss, 3.2442593574523926, 321
[INFO] 2021-07-09 16:53:09,072 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.2000000373955118e-06, 321
[INFO] 2021-07-09 16:53:09,072 [run_pretraining.py:  539]:	lr/loss_scaling, 1152.921875, 321
[INFO] 2021-07-09 16:53:09,072 [run_pretraining.py:  558]:	worker_index: 7, step: 321, cost: 3.244259, mlm loss: 3.244259, speed: 0.452517 steps/s, speed: 3.620136 samples/s, speed: 1853.509810 tokens/s, learning rate: 3.200e-06, loss_scalings: 1152.921875, pp_loss: 3.167651
[INFO] 2021-07-09 16:53:09,072 [run_pretraining.py:  512]:	********exe.run_321******* 
[INFO] 2021-07-09 16:53:11,325 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:11,325 [run_pretraining.py:  534]:	loss/total_loss, 3.1321167945861816, 322
[INFO] 2021-07-09 16:53:11,325 [run_pretraining.py:  535]:	loss/mlm_loss, 3.1321167945861816, 322
[INFO] 2021-07-09 16:53:11,326 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.209999931641505e-06, 322
[INFO] 2021-07-09 16:53:11,326 [run_pretraining.py:  539]:	lr/loss_scaling, 1152.921875, 322
[INFO] 2021-07-09 16:53:11,326 [run_pretraining.py:  558]:	worker_index: 7, step: 322, cost: 3.132117, mlm loss: 3.132117, speed: 0.443862 steps/s, speed: 3.550895 samples/s, speed: 1818.058109 tokens/s, learning rate: 3.210e-06, loss_scalings: 1152.921875, pp_loss: 3.157906
[INFO] 2021-07-09 16:53:11,326 [run_pretraining.py:  512]:	********exe.run_322******* 
[INFO] 2021-07-09 16:53:13,579 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:13,580 [run_pretraining.py:  534]:	loss/total_loss, 3.092259168624878, 323
[INFO] 2021-07-09 16:53:13,580 [run_pretraining.py:  535]:	loss/mlm_loss, 3.092259168624878, 323
[INFO] 2021-07-09 16:53:13,580 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.220000053261174e-06, 323
[INFO] 2021-07-09 16:53:13,580 [run_pretraining.py:  539]:	lr/loss_scaling, 1152.921875, 323
[INFO] 2021-07-09 16:53:13,580 [run_pretraining.py:  558]:	worker_index: 7, step: 323, cost: 3.092259, mlm loss: 3.092259, speed: 0.443745 steps/s, speed: 3.549961 samples/s, speed: 1817.580131 tokens/s, learning rate: 3.220e-06, loss_scalings: 1152.921875, pp_loss: 3.170200
[INFO] 2021-07-09 16:53:13,580 [run_pretraining.py:  512]:	********exe.run_323******* 
[INFO] 2021-07-09 16:53:15,823 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:15,824 [run_pretraining.py:  534]:	loss/total_loss, 3.1563897132873535, 324
[INFO] 2021-07-09 16:53:15,824 [run_pretraining.py:  535]:	loss/mlm_loss, 3.1563897132873535, 324
[INFO] 2021-07-09 16:53:15,824 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.229999720133492e-06, 324
[INFO] 2021-07-09 16:53:15,824 [run_pretraining.py:  539]:	lr/loss_scaling, 1152.921875, 324
[INFO] 2021-07-09 16:53:15,824 [run_pretraining.py:  558]:	worker_index: 7, step: 324, cost: 3.156390, mlm loss: 3.156390, speed: 0.445714 steps/s, speed: 3.565710 samples/s, speed: 1825.643277 tokens/s, learning rate: 3.230e-06, loss_scalings: 1152.921875, pp_loss: 3.165436
[INFO] 2021-07-09 16:53:15,824 [run_pretraining.py:  512]:	********exe.run_324******* 
[INFO] 2021-07-09 16:53:18,116 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:18,117 [run_pretraining.py:  534]:	loss/total_loss, 3.1863198280334473, 325
[INFO] 2021-07-09 16:53:18,117 [run_pretraining.py:  535]:	loss/mlm_loss, 3.1863198280334473, 325
[INFO] 2021-07-09 16:53:18,117 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.240000069126836e-06, 325
[INFO] 2021-07-09 16:53:18,117 [run_pretraining.py:  539]:	lr/loss_scaling, 1152.921875, 325
[INFO] 2021-07-09 16:53:18,117 [run_pretraining.py:  558]:	worker_index: 7, step: 325, cost: 3.186320, mlm loss: 3.186320, speed: 0.436206 steps/s, speed: 3.489651 samples/s, speed: 1786.701307 tokens/s, learning rate: 3.240e-06, loss_scalings: 1152.921875, pp_loss: 3.205969
[INFO] 2021-07-09 16:53:18,117 [run_pretraining.py:  512]:	********exe.run_325******* 
[INFO] 2021-07-09 16:53:20,310 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:20,310 [run_pretraining.py:  534]:	loss/total_loss, 3.2552571296691895, 326
[INFO] 2021-07-09 16:53:20,311 [run_pretraining.py:  535]:	loss/mlm_loss, 3.2552571296691895, 326
[INFO] 2021-07-09 16:53:20,311 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.249999735999154e-06, 326
[INFO] 2021-07-09 16:53:20,311 [run_pretraining.py:  539]:	lr/loss_scaling, 1152.921875, 326
[INFO] 2021-07-09 16:53:20,311 [run_pretraining.py:  558]:	worker_index: 7, step: 326, cost: 3.255257, mlm loss: 3.255257, speed: 0.456012 steps/s, speed: 3.648093 samples/s, speed: 1867.823739 tokens/s, learning rate: 3.250e-06, loss_scalings: 1152.921875, pp_loss: 3.271337
[INFO] 2021-07-09 16:53:20,311 [run_pretraining.py:  512]:	********exe.run_326******* 
[INFO] 2021-07-09 16:53:22,500 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:22,500 [run_pretraining.py:  534]:	loss/total_loss, 3.317145824432373, 327
[INFO] 2021-07-09 16:53:22,500 [run_pretraining.py:  535]:	loss/mlm_loss, 3.317145824432373, 327
[INFO] 2021-07-09 16:53:22,500 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.2599998576188227e-06, 327
[INFO] 2021-07-09 16:53:22,501 [run_pretraining.py:  539]:	lr/loss_scaling, 1152.921875, 327
[INFO] 2021-07-09 16:53:22,501 [run_pretraining.py:  558]:	worker_index: 7, step: 327, cost: 3.317146, mlm loss: 3.317146, speed: 0.456793 steps/s, speed: 3.654340 samples/s, speed: 1871.022325 tokens/s, learning rate: 3.260e-06, loss_scalings: 1152.921875, pp_loss: 3.406750
[INFO] 2021-07-09 16:53:22,501 [run_pretraining.py:  512]:	********exe.run_327******* 
[INFO] 2021-07-09 16:53:24,769 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:24,770 [run_pretraining.py:  534]:	loss/total_loss, 3.4738454818725586, 328
[INFO] 2021-07-09 16:53:24,770 [run_pretraining.py:  535]:	loss/mlm_loss, 3.4738454818725586, 328
[INFO] 2021-07-09 16:53:24,770 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.269999751864816e-06, 328
[INFO] 2021-07-09 16:53:24,770 [run_pretraining.py:  539]:	lr/loss_scaling, 1152.921875, 328
[INFO] 2021-07-09 16:53:24,770 [run_pretraining.py:  558]:	worker_index: 7, step: 328, cost: 3.473845, mlm loss: 3.473845, speed: 0.440777 steps/s, speed: 3.526212 samples/s, speed: 1805.420547 tokens/s, learning rate: 3.270e-06, loss_scalings: 1152.921875, pp_loss: 3.431873
[INFO] 2021-07-09 16:53:24,770 [run_pretraining.py:  512]:	********exe.run_328******* 
[INFO] 2021-07-09 16:53:26,999 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:27,000 [run_pretraining.py:  534]:	loss/total_loss, 3.5416693687438965, 329
[INFO] 2021-07-09 16:53:27,000 [run_pretraining.py:  535]:	loss/mlm_loss, 3.5416693687438965, 329
[INFO] 2021-07-09 16:53:27,000 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.279999873484485e-06, 329
[INFO] 2021-07-09 16:53:27,000 [run_pretraining.py:  539]:	lr/loss_scaling, 1152.921875, 329
[INFO] 2021-07-09 16:53:27,000 [run_pretraining.py:  558]:	worker_index: 7, step: 329, cost: 3.541669, mlm loss: 3.541669, speed: 0.448589 steps/s, speed: 3.588715 samples/s, speed: 1837.422112 tokens/s, learning rate: 3.280e-06, loss_scalings: 1152.921875, pp_loss: 3.558374
[INFO] 2021-07-09 16:53:27,000 [run_pretraining.py:  512]:	********exe.run_329******* 
[INFO] 2021-07-09 16:53:29,233 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:29,233 [run_pretraining.py:  534]:	loss/total_loss, 3.6577911376953125, 330
[INFO] 2021-07-09 16:53:29,233 [run_pretraining.py:  535]:	loss/mlm_loss, 3.6577911376953125, 330
[INFO] 2021-07-09 16:53:29,233 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.2899999951041536e-06, 330
[INFO] 2021-07-09 16:53:29,233 [run_pretraining.py:  539]:	lr/loss_scaling, 1152.921875, 330
[INFO] 2021-07-09 16:53:29,233 [run_pretraining.py:  558]:	worker_index: 7, step: 330, cost: 3.657791, mlm loss: 3.657791, speed: 0.447859 steps/s, speed: 3.582873 samples/s, speed: 1834.431101 tokens/s, learning rate: 3.290e-06, loss_scalings: 1152.921875, pp_loss: 3.672823
[INFO] 2021-07-09 16:53:29,234 [run_pretraining.py:  512]:	********exe.run_330******* 
[INFO] 2021-07-09 16:53:31,447 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:31,448 [run_pretraining.py:  534]:	loss/total_loss, 3.7786550521850586, 331
[INFO] 2021-07-09 16:53:31,448 [run_pretraining.py:  535]:	loss/mlm_loss, 3.7786550521850586, 331
[INFO] 2021-07-09 16:53:31,448 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.299999889350147e-06, 331
[INFO] 2021-07-09 16:53:31,448 [run_pretraining.py:  539]:	lr/loss_scaling, 922.3375244140625, 331
[INFO] 2021-07-09 16:53:31,448 [run_pretraining.py:  558]:	worker_index: 7, step: 331, cost: 3.778655, mlm loss: 3.778655, speed: 0.451643 steps/s, speed: 3.613143 samples/s, speed: 1849.929037 tokens/s, learning rate: 3.300e-06, loss_scalings: 922.337524, pp_loss: 3.803670
[INFO] 2021-07-09 16:53:31,448 [run_pretraining.py:  512]:	********exe.run_331******* 
[INFO] 2021-07-09 16:53:34,007 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:34,007 [run_pretraining.py:  534]:	loss/total_loss, 3.8853466510772705, 332
[INFO] 2021-07-09 16:53:34,007 [run_pretraining.py:  535]:	loss/mlm_loss, 3.8853466510772705, 332
[INFO] 2021-07-09 16:53:34,008 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.3100000109698158e-06, 332
[INFO] 2021-07-09 16:53:34,008 [run_pretraining.py:  539]:	lr/loss_scaling, 922.3375244140625, 332
[INFO] 2021-07-09 16:53:34,008 [run_pretraining.py:  558]:	worker_index: 7, step: 332, cost: 3.885347, mlm loss: 3.885347, speed: 0.390805 steps/s, speed: 3.126442 samples/s, speed: 1600.738431 tokens/s, learning rate: 3.310e-06, loss_scalings: 922.337524, pp_loss: 3.907887
[INFO] 2021-07-09 16:53:34,008 [run_pretraining.py:  512]:	********exe.run_332******* 
[INFO] 2021-07-09 16:53:36,220 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:36,221 [run_pretraining.py:  534]:	loss/total_loss, 4.1082282066345215, 333
[INFO] 2021-07-09 16:53:36,221 [run_pretraining.py:  535]:	loss/mlm_loss, 4.1082282066345215, 333
[INFO] 2021-07-09 16:53:36,221 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.319999905215809e-06, 333
[INFO] 2021-07-09 16:53:36,221 [run_pretraining.py:  539]:	lr/loss_scaling, 737.8700561523438, 333
[INFO] 2021-07-09 16:53:36,221 [run_pretraining.py:  558]:	worker_index: 7, step: 333, cost: 4.108228, mlm loss: 4.108228, speed: 0.451939 steps/s, speed: 3.615508 samples/s, speed: 1851.140171 tokens/s, learning rate: 3.320e-06, loss_scalings: 737.870056, pp_loss: 4.045404
[INFO] 2021-07-09 16:53:36,221 [run_pretraining.py:  512]:	********exe.run_333******* 
[INFO] 2021-07-09 16:53:38,476 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:38,476 [run_pretraining.py:  534]:	loss/total_loss, 4.14765739440918, 334
[INFO] 2021-07-09 16:53:38,476 [run_pretraining.py:  535]:	loss/mlm_loss, 4.14765739440918, 334
[INFO] 2021-07-09 16:53:38,477 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.330000026835478e-06, 334
[INFO] 2021-07-09 16:53:38,477 [run_pretraining.py:  539]:	lr/loss_scaling, 737.8700561523438, 334
[INFO] 2021-07-09 16:53:38,477 [run_pretraining.py:  558]:	worker_index: 7, step: 334, cost: 4.147657, mlm loss: 4.147657, speed: 0.443461 steps/s, speed: 3.547687 samples/s, speed: 1816.415764 tokens/s, learning rate: 3.330e-06, loss_scalings: 737.870056, pp_loss: 4.120760
[INFO] 2021-07-09 16:53:38,477 [run_pretraining.py:  512]:	********exe.run_334******* 
[INFO] 2021-07-09 16:53:40,742 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:40,742 [run_pretraining.py:  534]:	loss/total_loss, 4.2277750968933105, 335
[INFO] 2021-07-09 16:53:40,743 [run_pretraining.py:  535]:	loss/mlm_loss, 4.2277750968933105, 335
[INFO] 2021-07-09 16:53:40,743 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.3399999210814713e-06, 335
[INFO] 2021-07-09 16:53:40,743 [run_pretraining.py:  539]:	lr/loss_scaling, 737.8700561523438, 335
[INFO] 2021-07-09 16:53:40,743 [run_pretraining.py:  558]:	worker_index: 7, step: 335, cost: 4.227775, mlm loss: 4.227775, speed: 0.441395 steps/s, speed: 3.531160 samples/s, speed: 1807.953772 tokens/s, learning rate: 3.340e-06, loss_scalings: 737.870056, pp_loss: 4.202600
[INFO] 2021-07-09 16:53:40,743 [run_pretraining.py:  512]:	********exe.run_335******* 
[INFO] 2021-07-09 16:53:43,051 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:43,051 [run_pretraining.py:  534]:	loss/total_loss, 4.238044738769531, 336
[INFO] 2021-07-09 16:53:43,051 [run_pretraining.py:  535]:	loss/mlm_loss, 4.238044738769531, 336
[INFO] 2021-07-09 16:53:43,051 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.35000004270114e-06, 336
[INFO] 2021-07-09 16:53:43,052 [run_pretraining.py:  539]:	lr/loss_scaling, 590.2960815429688, 336
[INFO] 2021-07-09 16:53:43,052 [run_pretraining.py:  558]:	worker_index: 7, step: 336, cost: 4.238045, mlm loss: 4.238045, speed: 0.433259 steps/s, speed: 3.466070 samples/s, speed: 1774.628078 tokens/s, learning rate: 3.350e-06, loss_scalings: 590.296082, pp_loss: 4.311375
[INFO] 2021-07-09 16:53:43,052 [run_pretraining.py:  512]:	********exe.run_336******* 
[INFO] 2021-07-09 16:53:45,314 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:45,314 [run_pretraining.py:  534]:	loss/total_loss, 4.29924201965332, 337
[INFO] 2021-07-09 16:53:45,314 [run_pretraining.py:  535]:	loss/mlm_loss, 4.29924201965332, 337
[INFO] 2021-07-09 16:53:45,314 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.359999709573458e-06, 337
[INFO] 2021-07-09 16:53:45,314 [run_pretraining.py:  539]:	lr/loss_scaling, 590.2960815429688, 337
[INFO] 2021-07-09 16:53:45,314 [run_pretraining.py:  558]:	worker_index: 7, step: 337, cost: 4.299242, mlm loss: 4.299242, speed: 0.442058 steps/s, speed: 3.536461 samples/s, speed: 1810.668140 tokens/s, learning rate: 3.360e-06, loss_scalings: 590.296082, pp_loss: 4.374607
[INFO] 2021-07-09 16:53:45,315 [run_pretraining.py:  512]:	********exe.run_337******* 
[INFO] 2021-07-09 16:53:47,644 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:47,645 [run_pretraining.py:  534]:	loss/total_loss, 4.294276237487793, 338
[INFO] 2021-07-09 16:53:47,645 [run_pretraining.py:  535]:	loss/mlm_loss, 4.294276237487793, 338
[INFO] 2021-07-09 16:53:47,645 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.370000058566802e-06, 338
[INFO] 2021-07-09 16:53:47,645 [run_pretraining.py:  539]:	lr/loss_scaling, 590.2960815429688, 338
[INFO] 2021-07-09 16:53:47,645 [run_pretraining.py:  558]:	worker_index: 7, step: 338, cost: 4.294276, mlm loss: 4.294276, speed: 0.429186 steps/s, speed: 3.433488 samples/s, speed: 1757.946088 tokens/s, learning rate: 3.370e-06, loss_scalings: 590.296082, pp_loss: 4.381018
[INFO] 2021-07-09 16:53:47,645 [run_pretraining.py:  512]:	********exe.run_338******* 
[INFO] 2021-07-09 16:53:50,099 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:50,100 [run_pretraining.py:  534]:	loss/total_loss, 4.366322040557861, 339
[INFO] 2021-07-09 16:53:50,100 [run_pretraining.py:  535]:	loss/mlm_loss, 4.366322040557861, 339
[INFO] 2021-07-09 16:53:50,100 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.37999972543912e-06, 339
[INFO] 2021-07-09 16:53:50,100 [run_pretraining.py:  539]:	lr/loss_scaling, 590.2960815429688, 339
[INFO] 2021-07-09 16:53:50,100 [run_pretraining.py:  558]:	worker_index: 7, step: 339, cost: 4.366322, mlm loss: 4.366322, speed: 0.407425 steps/s, speed: 3.259401 samples/s, speed: 1668.813493 tokens/s, learning rate: 3.380e-06, loss_scalings: 590.296082, pp_loss: 4.396317
[INFO] 2021-07-09 16:53:50,100 [run_pretraining.py:  512]:	********exe.run_339******* 
[INFO] 2021-07-09 16:53:52,341 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:52,342 [run_pretraining.py:  534]:	loss/total_loss, 4.3919806480407715, 340
[INFO] 2021-07-09 16:53:52,342 [run_pretraining.py:  535]:	loss/mlm_loss, 4.3919806480407715, 340
[INFO] 2021-07-09 16:53:52,342 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.389999847058789e-06, 340
[INFO] 2021-07-09 16:53:52,342 [run_pretraining.py:  539]:	lr/loss_scaling, 590.2960815429688, 340
[INFO] 2021-07-09 16:53:52,342 [run_pretraining.py:  558]:	worker_index: 7, step: 340, cost: 4.391981, mlm loss: 4.391981, speed: 0.446170 steps/s, speed: 3.569361 samples/s, speed: 1827.512677 tokens/s, learning rate: 3.390e-06, loss_scalings: 590.296082, pp_loss: 4.410601
[INFO] 2021-07-09 16:53:52,342 [run_pretraining.py:  512]:	********exe.run_340******* 
[INFO] 2021-07-09 16:53:54,563 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:54,563 [run_pretraining.py:  534]:	loss/total_loss, 4.443524360656738, 341
[INFO] 2021-07-09 16:53:54,563 [run_pretraining.py:  535]:	loss/mlm_loss, 4.443524360656738, 341
[INFO] 2021-07-09 16:53:54,564 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.400000196052133e-06, 341
[INFO] 2021-07-09 16:53:54,564 [run_pretraining.py:  539]:	lr/loss_scaling, 590.2960815429688, 341
[INFO] 2021-07-09 16:53:54,564 [run_pretraining.py:  558]:	worker_index: 7, step: 341, cost: 4.443524, mlm loss: 4.443524, speed: 0.450266 steps/s, speed: 3.602127 samples/s, speed: 1844.288795 tokens/s, learning rate: 3.400e-06, loss_scalings: 590.296082, pp_loss: 4.389389
[INFO] 2021-07-09 16:53:54,564 [run_pretraining.py:  512]:	********exe.run_341******* 
[INFO] 2021-07-09 16:53:56,905 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:56,905 [run_pretraining.py:  534]:	loss/total_loss, 4.321107864379883, 342
[INFO] 2021-07-09 16:53:56,906 [run_pretraining.py:  535]:	loss/mlm_loss, 4.321107864379883, 342
[INFO] 2021-07-09 16:53:56,906 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.409999862924451e-06, 342
[INFO] 2021-07-09 16:53:56,906 [run_pretraining.py:  539]:	lr/loss_scaling, 590.2960815429688, 342
[INFO] 2021-07-09 16:53:56,906 [run_pretraining.py:  558]:	worker_index: 7, step: 342, cost: 4.321108, mlm loss: 4.321108, speed: 0.427090 steps/s, speed: 3.416716 samples/s, speed: 1749.358693 tokens/s, learning rate: 3.410e-06, loss_scalings: 590.296082, pp_loss: 4.329504
[INFO] 2021-07-09 16:53:56,906 [run_pretraining.py:  512]:	********exe.run_342******* 
[INFO] 2021-07-09 16:53:59,218 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:59,218 [run_pretraining.py:  534]:	loss/total_loss, 4.256744384765625, 343
[INFO] 2021-07-09 16:53:59,218 [run_pretraining.py:  535]:	loss/mlm_loss, 4.256744384765625, 343
[INFO] 2021-07-09 16:53:59,218 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.41999998454412e-06, 343
[INFO] 2021-07-09 16:53:59,218 [run_pretraining.py:  539]:	lr/loss_scaling, 590.2960815429688, 343
[INFO] 2021-07-09 16:53:59,218 [run_pretraining.py:  558]:	worker_index: 7, step: 343, cost: 4.256744, mlm loss: 4.256744, speed: 0.432522 steps/s, speed: 3.460172 samples/s, speed: 1771.608183 tokens/s, learning rate: 3.420e-06, loss_scalings: 590.296082, pp_loss: 4.260585
[INFO] 2021-07-09 16:53:59,219 [run_pretraining.py:  512]:	********exe.run_343******* 
[INFO] 2021-07-09 16:54:01,654 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:01,654 [run_pretraining.py:  534]:	loss/total_loss, 4.186318874359131, 344
[INFO] 2021-07-09 16:54:01,654 [run_pretraining.py:  535]:	loss/mlm_loss, 4.186318874359131, 344
[INFO] 2021-07-09 16:54:01,655 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.429999878790113e-06, 344
[INFO] 2021-07-09 16:54:01,655 [run_pretraining.py:  539]:	lr/loss_scaling, 590.2960815429688, 344
[INFO] 2021-07-09 16:54:01,655 [run_pretraining.py:  558]:	worker_index: 7, step: 344, cost: 4.186319, mlm loss: 4.186319, speed: 0.410576 steps/s, speed: 3.284608 samples/s, speed: 1681.719461 tokens/s, learning rate: 3.430e-06, loss_scalings: 590.296082, pp_loss: 4.193173
[INFO] 2021-07-09 16:54:01,655 [run_pretraining.py:  512]:	********exe.run_344******* 
[INFO] 2021-07-09 16:54:04,186 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:04,186 [run_pretraining.py:  534]:	loss/total_loss, 4.139937400817871, 345
[INFO] 2021-07-09 16:54:04,186 [run_pretraining.py:  535]:	loss/mlm_loss, 4.139937400817871, 345
[INFO] 2021-07-09 16:54:04,186 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.440000000409782e-06, 345
[INFO] 2021-07-09 16:54:04,186 [run_pretraining.py:  539]:	lr/loss_scaling, 590.2960815429688, 345
[INFO] 2021-07-09 16:54:04,187 [run_pretraining.py:  558]:	worker_index: 7, step: 345, cost: 4.139937, mlm loss: 4.139937, speed: 0.395073 steps/s, speed: 3.160584 samples/s, speed: 1618.219175 tokens/s, learning rate: 3.440e-06, loss_scalings: 590.296082, pp_loss: 4.153532
[INFO] 2021-07-09 16:54:04,187 [run_pretraining.py:  512]:	********exe.run_345******* 
[INFO] 2021-07-09 16:54:06,902 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:06,902 [run_pretraining.py:  534]:	loss/total_loss, 4.166619300842285, 346
[INFO] 2021-07-09 16:54:06,903 [run_pretraining.py:  535]:	loss/mlm_loss, 4.166619300842285, 346
[INFO] 2021-07-09 16:54:06,903 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.4499998946557753e-06, 346
[INFO] 2021-07-09 16:54:06,903 [run_pretraining.py:  539]:	lr/loss_scaling, 590.2960815429688, 346
[INFO] 2021-07-09 16:54:06,903 [run_pretraining.py:  558]:	worker_index: 7, step: 346, cost: 4.166619, mlm loss: 4.166619, speed: 0.368228 steps/s, speed: 2.945823 samples/s, speed: 1508.261366 tokens/s, learning rate: 3.450e-06, loss_scalings: 590.296082, pp_loss: 4.143261
[INFO] 2021-07-09 16:54:06,903 [run_pretraining.py:  512]:	********exe.run_346******* 
[INFO] 2021-07-09 16:54:09,158 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:09,159 [run_pretraining.py:  534]:	loss/total_loss, 4.149510860443115, 347
[INFO] 2021-07-09 16:54:09,159 [run_pretraining.py:  535]:	loss/mlm_loss, 4.149510860443115, 347
[INFO] 2021-07-09 16:54:09,159 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.460000016275444e-06, 347
[INFO] 2021-07-09 16:54:09,159 [run_pretraining.py:  539]:	lr/loss_scaling, 590.2960815429688, 347
[INFO] 2021-07-09 16:54:09,159 [run_pretraining.py:  558]:	worker_index: 7, step: 347, cost: 4.149511, mlm loss: 4.149511, speed: 0.443302 steps/s, speed: 3.546416 samples/s, speed: 1815.765145 tokens/s, learning rate: 3.460e-06, loss_scalings: 590.296082, pp_loss: 4.179258
[INFO] 2021-07-09 16:54:09,159 [run_pretraining.py:  512]:	********exe.run_347******* 
[INFO] 2021-07-09 16:54:11,442 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:11,442 [run_pretraining.py:  534]:	loss/total_loss, 4.0973310470581055, 348
[INFO] 2021-07-09 16:54:11,442 [run_pretraining.py:  535]:	loss/mlm_loss, 4.0973310470581055, 348
[INFO] 2021-07-09 16:54:11,442 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.469999683147762e-06, 348
[INFO] 2021-07-09 16:54:11,442 [run_pretraining.py:  539]:	lr/loss_scaling, 590.2960815429688, 348
[INFO] 2021-07-09 16:54:11,443 [run_pretraining.py:  558]:	worker_index: 7, step: 348, cost: 4.097331, mlm loss: 4.097331, speed: 0.438110 steps/s, speed: 3.504879 samples/s, speed: 1794.497846 tokens/s, learning rate: 3.470e-06, loss_scalings: 590.296082, pp_loss: 4.112613
[INFO] 2021-07-09 16:54:11,443 [run_pretraining.py:  512]:	********exe.run_348******* 
[INFO] 2021-07-09 16:54:13,717 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:13,718 [run_pretraining.py:  534]:	loss/total_loss, 4.095447540283203, 349
[INFO] 2021-07-09 16:54:13,718 [run_pretraining.py:  535]:	loss/mlm_loss, 4.095447540283203, 349
[INFO] 2021-07-09 16:54:13,718 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.480000032141106e-06, 349
[INFO] 2021-07-09 16:54:13,718 [run_pretraining.py:  539]:	lr/loss_scaling, 472.23687744140625, 349
[INFO] 2021-07-09 16:54:13,718 [run_pretraining.py:  558]:	worker_index: 7, step: 349, cost: 4.095448, mlm loss: 4.095448, speed: 0.439554 steps/s, speed: 3.516429 samples/s, speed: 1800.411749 tokens/s, learning rate: 3.480e-06, loss_scalings: 472.236877, pp_loss: 4.080183
[INFO] 2021-07-09 16:54:13,718 [run_pretraining.py:  512]:	********exe.run_349******* 
[INFO] 2021-07-09 16:54:16,017 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:16,018 [run_pretraining.py:  534]:	loss/total_loss, 4.032354831695557, 350
[INFO] 2021-07-09 16:54:16,018 [run_pretraining.py:  535]:	loss/mlm_loss, 4.032354831695557, 350
[INFO] 2021-07-09 16:54:16,018 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.489999699013424e-06, 350
[INFO] 2021-07-09 16:54:16,018 [run_pretraining.py:  539]:	lr/loss_scaling, 472.23687744140625, 350
[INFO] 2021-07-09 16:54:16,018 [run_pretraining.py:  558]:	worker_index: 7, step: 350, cost: 4.032355, mlm loss: 4.032355, speed: 0.434965 steps/s, speed: 3.479716 samples/s, speed: 1781.614612 tokens/s, learning rate: 3.490e-06, loss_scalings: 472.236877, pp_loss: 4.043035
[INFO] 2021-07-09 16:54:16,018 [run_pretraining.py:  512]:	********exe.run_350******* 
[INFO] 2021-07-09 16:54:18,289 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:18,290 [run_pretraining.py:  534]:	loss/total_loss, 4.111454486846924, 351
[INFO] 2021-07-09 16:54:18,290 [run_pretraining.py:  535]:	loss/mlm_loss, 4.111454486846924, 351
[INFO] 2021-07-09 16:54:18,290 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.499999820633093e-06, 351
[INFO] 2021-07-09 16:54:18,290 [run_pretraining.py:  539]:	lr/loss_scaling, 472.23687744140625, 351
[INFO] 2021-07-09 16:54:18,290 [run_pretraining.py:  558]:	worker_index: 7, step: 351, cost: 4.111454, mlm loss: 4.111454, speed: 0.440226 steps/s, speed: 3.521808 samples/s, speed: 1803.165575 tokens/s, learning rate: 3.500e-06, loss_scalings: 472.236877, pp_loss: 4.067965
[INFO] 2021-07-09 16:54:18,290 [run_pretraining.py:  512]:	********exe.run_351******* 
[INFO] 2021-07-09 16:54:20,605 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:20,606 [run_pretraining.py:  534]:	loss/total_loss, 4.023824691772461, 352
[INFO] 2021-07-09 16:54:20,606 [run_pretraining.py:  535]:	loss/mlm_loss, 4.023824691772461, 352
[INFO] 2021-07-09 16:54:20,606 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.510000169626437e-06, 352
[INFO] 2021-07-09 16:54:20,606 [run_pretraining.py:  539]:	lr/loss_scaling, 472.23687744140625, 352
[INFO] 2021-07-09 16:54:20,606 [run_pretraining.py:  558]:	worker_index: 7, step: 352, cost: 4.023825, mlm loss: 4.023825, speed: 0.431901 steps/s, speed: 3.455210 samples/s, speed: 1769.067504 tokens/s, learning rate: 3.510e-06, loss_scalings: 472.236877, pp_loss: 4.045127
[INFO] 2021-07-09 16:54:20,606 [run_pretraining.py:  512]:	********exe.run_352******* 
[INFO] 2021-07-09 16:54:22,883 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:22,883 [run_pretraining.py:  534]:	loss/total_loss, 4.058603286743164, 353
[INFO] 2021-07-09 16:54:22,883 [run_pretraining.py:  535]:	loss/mlm_loss, 4.058603286743164, 353
[INFO] 2021-07-09 16:54:22,883 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.519999836498755e-06, 353
[INFO] 2021-07-09 16:54:22,883 [run_pretraining.py:  539]:	lr/loss_scaling, 472.23687744140625, 353
[INFO] 2021-07-09 16:54:22,884 [run_pretraining.py:  558]:	worker_index: 7, step: 353, cost: 4.058603, mlm loss: 4.058603, speed: 0.439241 steps/s, speed: 3.513930 samples/s, speed: 1799.131905 tokens/s, learning rate: 3.520e-06, loss_scalings: 472.236877, pp_loss: 3.980857
[INFO] 2021-07-09 16:54:22,884 [run_pretraining.py:  512]:	********exe.run_353******* 
[INFO] 2021-07-09 16:54:25,111 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:25,111 [run_pretraining.py:  534]:	loss/total_loss, 3.9278311729431152, 354
[INFO] 2021-07-09 16:54:25,111 [run_pretraining.py:  535]:	loss/mlm_loss, 3.9278311729431152, 354
[INFO] 2021-07-09 16:54:25,112 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.529999958118424e-06, 354
[INFO] 2021-07-09 16:54:25,112 [run_pretraining.py:  539]:	lr/loss_scaling, 472.23687744140625, 354
[INFO] 2021-07-09 16:54:25,112 [run_pretraining.py:  558]:	worker_index: 7, step: 354, cost: 3.927831, mlm loss: 3.927831, speed: 0.448930 steps/s, speed: 3.591440 samples/s, speed: 1838.817058 tokens/s, learning rate: 3.530e-06, loss_scalings: 472.236877, pp_loss: 3.955940
[INFO] 2021-07-09 16:54:25,112 [run_pretraining.py:  512]:	********exe.run_354******* 
[INFO] 2021-07-09 16:54:27,349 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:27,350 [run_pretraining.py:  534]:	loss/total_loss, 3.961747646331787, 355
[INFO] 2021-07-09 16:54:27,350 [run_pretraining.py:  535]:	loss/mlm_loss, 3.961747646331787, 355
[INFO] 2021-07-09 16:54:27,350 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.539999852364417e-06, 355
[INFO] 2021-07-09 16:54:27,350 [run_pretraining.py:  539]:	lr/loss_scaling, 472.23687744140625, 355
[INFO] 2021-07-09 16:54:27,350 [run_pretraining.py:  558]:	worker_index: 7, step: 355, cost: 3.961748, mlm loss: 3.961748, speed: 0.446913 steps/s, speed: 3.575308 samples/s, speed: 1830.557608 tokens/s, learning rate: 3.540e-06, loss_scalings: 472.236877, pp_loss: 3.953570
[INFO] 2021-07-09 16:54:27,350 [run_pretraining.py:  512]:	********exe.run_355******* 
[INFO] 2021-07-09 16:54:29,569 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:29,569 [run_pretraining.py:  534]:	loss/total_loss, 4.080175876617432, 356
[INFO] 2021-07-09 16:54:29,569 [run_pretraining.py:  535]:	loss/mlm_loss, 4.080175876617432, 356
[INFO] 2021-07-09 16:54:29,569 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.549999973984086e-06, 356
[INFO] 2021-07-09 16:54:29,569 [run_pretraining.py:  539]:	lr/loss_scaling, 472.23687744140625, 356
[INFO] 2021-07-09 16:54:29,569 [run_pretraining.py:  558]:	worker_index: 7, step: 356, cost: 4.080176, mlm loss: 4.080176, speed: 0.450671 steps/s, speed: 3.605365 samples/s, speed: 1845.946846 tokens/s, learning rate: 3.550e-06, loss_scalings: 472.236877, pp_loss: 3.991098
[INFO] 2021-07-09 16:54:29,570 [run_pretraining.py:  512]:	********exe.run_356******* 
[INFO] 2021-07-09 16:54:31,865 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:31,866 [run_pretraining.py:  534]:	loss/total_loss, 4.018030166625977, 357
[INFO] 2021-07-09 16:54:31,866 [run_pretraining.py:  535]:	loss/mlm_loss, 4.018030166625977, 357
[INFO] 2021-07-09 16:54:31,866 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.5599998682300793e-06, 357
[INFO] 2021-07-09 16:54:31,866 [run_pretraining.py:  539]:	lr/loss_scaling, 472.23687744140625, 357
[INFO] 2021-07-09 16:54:31,866 [run_pretraining.py:  558]:	worker_index: 7, step: 357, cost: 4.018030, mlm loss: 4.018030, speed: 0.435555 steps/s, speed: 3.484439 samples/s, speed: 1784.032701 tokens/s, learning rate: 3.560e-06, loss_scalings: 472.236877, pp_loss: 4.061036
[INFO] 2021-07-09 16:54:31,866 [run_pretraining.py:  512]:	********exe.run_357******* 
[INFO] 2021-07-09 16:54:34,135 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:34,136 [run_pretraining.py:  534]:	loss/total_loss, 4.268823623657227, 358
[INFO] 2021-07-09 16:54:34,136 [run_pretraining.py:  535]:	loss/mlm_loss, 4.268823623657227, 358
[INFO] 2021-07-09 16:54:34,136 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.569999989849748e-06, 358
[INFO] 2021-07-09 16:54:34,136 [run_pretraining.py:  539]:	lr/loss_scaling, 472.23687744140625, 358
[INFO] 2021-07-09 16:54:34,136 [run_pretraining.py:  558]:	worker_index: 7, step: 358, cost: 4.268824, mlm loss: 4.268824, speed: 0.440637 steps/s, speed: 3.525094 samples/s, speed: 1804.848122 tokens/s, learning rate: 3.570e-06, loss_scalings: 472.236877, pp_loss: 4.174592
[INFO] 2021-07-09 16:54:34,136 [run_pretraining.py:  512]:	********exe.run_358******* 
[INFO] 2021-07-09 16:54:36,382 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:36,383 [run_pretraining.py:  534]:	loss/total_loss, 4.23635721206665, 359
[INFO] 2021-07-09 16:54:36,383 [run_pretraining.py:  535]:	loss/mlm_loss, 4.23635721206665, 359
[INFO] 2021-07-09 16:54:36,383 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.5799998840957414e-06, 359
[INFO] 2021-07-09 16:54:36,383 [run_pretraining.py:  539]:	lr/loss_scaling, 472.23687744140625, 359
[INFO] 2021-07-09 16:54:36,383 [run_pretraining.py:  558]:	worker_index: 7, step: 359, cost: 4.236357, mlm loss: 4.236357, speed: 0.445160 steps/s, speed: 3.561277 samples/s, speed: 1823.373726 tokens/s, learning rate: 3.580e-06, loss_scalings: 472.236877, pp_loss: 4.212659
[INFO] 2021-07-09 16:54:36,383 [run_pretraining.py:  512]:	********exe.run_359******* 
[INFO] 2021-07-09 16:54:38,599 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:38,599 [run_pretraining.py:  534]:	loss/total_loss, 4.508901119232178, 360
[INFO] 2021-07-09 16:54:38,599 [run_pretraining.py:  535]:	loss/mlm_loss, 4.508901119232178, 360
[INFO] 2021-07-09 16:54:38,600 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.5900000057154102e-06, 360
[INFO] 2021-07-09 16:54:38,600 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 360
[INFO] 2021-07-09 16:54:38,600 [run_pretraining.py:  558]:	worker_index: 7, step: 360, cost: 4.508901, mlm loss: 4.508901, speed: 0.451284 steps/s, speed: 3.610269 samples/s, speed: 1848.457719 tokens/s, learning rate: 3.590e-06, loss_scalings: 377.789520, pp_loss: 4.370197
[INFO] 2021-07-09 16:54:38,600 [run_pretraining.py:  512]:	********exe.run_360******* 
[INFO] 2021-07-09 16:54:40,813 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:40,813 [run_pretraining.py:  534]:	loss/total_loss, 4.407208442687988, 361
[INFO] 2021-07-09 16:54:40,813 [run_pretraining.py:  535]:	loss/mlm_loss, 4.407208442687988, 361
[INFO] 2021-07-09 16:54:40,813 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.599999672587728e-06, 361
[INFO] 2021-07-09 16:54:40,813 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 361
[INFO] 2021-07-09 16:54:40,813 [run_pretraining.py:  558]:	worker_index: 7, step: 361, cost: 4.407208, mlm loss: 4.407208, speed: 0.451852 steps/s, speed: 3.614815 samples/s, speed: 1850.785198 tokens/s, learning rate: 3.600e-06, loss_scalings: 377.789520, pp_loss: 4.424124
[INFO] 2021-07-09 16:54:40,814 [run_pretraining.py:  512]:	********exe.run_361******* 
[INFO] 2021-07-09 16:54:43,030 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:43,031 [run_pretraining.py:  534]:	loss/total_loss, 4.637697219848633, 362
[INFO] 2021-07-09 16:54:43,031 [run_pretraining.py:  535]:	loss/mlm_loss, 4.637697219848633, 362
[INFO] 2021-07-09 16:54:43,031 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.6100000215810724e-06, 362
[INFO] 2021-07-09 16:54:43,031 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 362
[INFO] 2021-07-09 16:54:43,031 [run_pretraining.py:  558]:	worker_index: 7, step: 362, cost: 4.637697, mlm loss: 4.637697, speed: 0.451051 steps/s, speed: 3.608407 samples/s, speed: 1847.504166 tokens/s, learning rate: 3.610e-06, loss_scalings: 377.789520, pp_loss: 4.560243
[INFO] 2021-07-09 16:54:43,031 [run_pretraining.py:  512]:	********exe.run_362******* 
[INFO] 2021-07-09 16:54:45,307 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:45,308 [run_pretraining.py:  534]:	loss/total_loss, 4.73098087310791, 363
[INFO] 2021-07-09 16:54:45,308 [run_pretraining.py:  535]:	loss/mlm_loss, 4.73098087310791, 363
[INFO] 2021-07-09 16:54:45,308 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.620000143200741e-06, 363
[INFO] 2021-07-09 16:54:45,308 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 363
[INFO] 2021-07-09 16:54:45,308 [run_pretraining.py:  558]:	worker_index: 7, step: 363, cost: 4.730981, mlm loss: 4.730981, speed: 0.439332 steps/s, speed: 3.514656 samples/s, speed: 1799.503905 tokens/s, learning rate: 3.620e-06, loss_scalings: 377.789520, pp_loss: 4.657141
[INFO] 2021-07-09 16:54:45,308 [run_pretraining.py:  512]:	********exe.run_363******* 
[INFO] 2021-07-09 16:54:47,550 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:47,550 [run_pretraining.py:  534]:	loss/total_loss, 4.690767765045166, 364
[INFO] 2021-07-09 16:54:47,550 [run_pretraining.py:  535]:	loss/mlm_loss, 4.690767765045166, 364
[INFO] 2021-07-09 16:54:47,550 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.629999810073059e-06, 364
[INFO] 2021-07-09 16:54:47,550 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 364
[INFO] 2021-07-09 16:54:47,550 [run_pretraining.py:  558]:	worker_index: 7, step: 364, cost: 4.690768, mlm loss: 4.690768, speed: 0.446057 steps/s, speed: 3.568458 samples/s, speed: 1827.050700 tokens/s, learning rate: 3.630e-06, loss_scalings: 377.789520, pp_loss: 4.711382
[INFO] 2021-07-09 16:54:47,551 [run_pretraining.py:  512]:	********exe.run_364******* 
[INFO] 2021-07-09 16:54:49,839 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:49,840 [run_pretraining.py:  534]:	loss/total_loss, 4.689644813537598, 365
[INFO] 2021-07-09 16:54:49,840 [run_pretraining.py:  535]:	loss/mlm_loss, 4.689644813537598, 365
[INFO] 2021-07-09 16:54:49,840 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.6400001590664033e-06, 365
[INFO] 2021-07-09 16:54:49,840 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 365
[INFO] 2021-07-09 16:54:49,840 [run_pretraining.py:  558]:	worker_index: 7, step: 365, cost: 4.689645, mlm loss: 4.689645, speed: 0.436906 steps/s, speed: 3.495251 samples/s, speed: 1789.568402 tokens/s, learning rate: 3.640e-06, loss_scalings: 377.789520, pp_loss: 4.711095
[INFO] 2021-07-09 16:54:49,840 [run_pretraining.py:  512]:	********exe.run_365******* 
[INFO] 2021-07-09 16:54:52,111 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:52,112 [run_pretraining.py:  534]:	loss/total_loss, 4.755934715270996, 366
[INFO] 2021-07-09 16:54:52,112 [run_pretraining.py:  535]:	loss/mlm_loss, 4.755934715270996, 366
[INFO] 2021-07-09 16:54:52,112 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.649999825938721e-06, 366
[INFO] 2021-07-09 16:54:52,112 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 366
[INFO] 2021-07-09 16:54:52,112 [run_pretraining.py:  558]:	worker_index: 7, step: 366, cost: 4.755935, mlm loss: 4.755935, speed: 0.440259 steps/s, speed: 3.522071 samples/s, speed: 1803.300147 tokens/s, learning rate: 3.650e-06, loss_scalings: 377.789520, pp_loss: 4.790556
[INFO] 2021-07-09 16:54:52,112 [run_pretraining.py:  512]:	********exe.run_366******* 
[INFO] 2021-07-09 16:54:54,425 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:54,425 [run_pretraining.py:  534]:	loss/total_loss, 5.025118827819824, 367
[INFO] 2021-07-09 16:54:54,425 [run_pretraining.py:  535]:	loss/mlm_loss, 5.025118827819824, 367
[INFO] 2021-07-09 16:54:54,425 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.65999994755839e-06, 367
[INFO] 2021-07-09 16:54:54,425 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 367
[INFO] 2021-07-09 16:54:54,426 [run_pretraining.py:  558]:	worker_index: 7, step: 367, cost: 5.025119, mlm loss: 5.025119, speed: 0.432374 steps/s, speed: 3.458989 samples/s, speed: 1771.002224 tokens/s, learning rate: 3.660e-06, loss_scalings: 377.789520, pp_loss: 4.886937
[INFO] 2021-07-09 16:54:54,426 [run_pretraining.py:  512]:	********exe.run_367******* 
[INFO] 2021-07-09 16:54:56,680 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:56,680 [run_pretraining.py:  534]:	loss/total_loss, 4.870503902435303, 368
[INFO] 2021-07-09 16:54:56,680 [run_pretraining.py:  535]:	loss/mlm_loss, 4.870503902435303, 368
[INFO] 2021-07-09 16:54:56,680 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.6699998418043833e-06, 368
[INFO] 2021-07-09 16:54:56,680 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 368
[INFO] 2021-07-09 16:54:56,680 [run_pretraining.py:  558]:	worker_index: 7, step: 368, cost: 4.870504, mlm loss: 4.870504, speed: 0.443592 steps/s, speed: 3.548739 samples/s, speed: 1816.954235 tokens/s, learning rate: 3.670e-06, loss_scalings: 377.789520, pp_loss: 4.948332
[INFO] 2021-07-09 16:54:56,681 [run_pretraining.py:  512]:	********exe.run_368******* 
[INFO] 2021-07-09 16:54:58,906 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:58,907 [run_pretraining.py:  534]:	loss/total_loss, 5.140453338623047, 369
[INFO] 2021-07-09 16:54:58,907 [run_pretraining.py:  535]:	loss/mlm_loss, 5.140453338623047, 369
[INFO] 2021-07-09 16:54:58,907 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.679999963424052e-06, 369
[INFO] 2021-07-09 16:54:58,907 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 369
[INFO] 2021-07-09 16:54:58,907 [run_pretraining.py:  558]:	worker_index: 7, step: 369, cost: 5.140453, mlm loss: 5.140453, speed: 0.449229 steps/s, speed: 3.593831 samples/s, speed: 1840.041666 tokens/s, learning rate: 3.680e-06, loss_scalings: 377.789520, pp_loss: 5.040862
[INFO] 2021-07-09 16:54:58,907 [run_pretraining.py:  512]:	********exe.run_369******* 
[INFO] 2021-07-09 16:55:01,178 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:01,178 [run_pretraining.py:  534]:	loss/total_loss, 5.00246000289917, 370
[INFO] 2021-07-09 16:55:01,179 [run_pretraining.py:  535]:	loss/mlm_loss, 5.00246000289917, 370
[INFO] 2021-07-09 16:55:01,179 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.6899998576700455e-06, 370
[INFO] 2021-07-09 16:55:01,179 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 370
[INFO] 2021-07-09 16:55:01,179 [run_pretraining.py:  558]:	worker_index: 7, step: 370, cost: 5.002460, mlm loss: 5.002460, speed: 0.440325 steps/s, speed: 3.522597 samples/s, speed: 1803.569918 tokens/s, learning rate: 3.690e-06, loss_scalings: 377.789520, pp_loss: 5.052297
[INFO] 2021-07-09 16:55:01,179 [run_pretraining.py:  512]:	********exe.run_370******* 
[INFO] 2021-07-09 16:55:03,468 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:03,468 [run_pretraining.py:  534]:	loss/total_loss, 5.054473400115967, 371
[INFO] 2021-07-09 16:55:03,468 [run_pretraining.py:  535]:	loss/mlm_loss, 5.054473400115967, 371
[INFO] 2021-07-09 16:55:03,468 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.6999999792897142e-06, 371
[INFO] 2021-07-09 16:55:03,469 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 371
[INFO] 2021-07-09 16:55:03,469 [run_pretraining.py:  558]:	worker_index: 7, step: 371, cost: 5.054473, mlm loss: 5.054473, speed: 0.436861 steps/s, speed: 3.494887 samples/s, speed: 1789.382194 tokens/s, learning rate: 3.700e-06, loss_scalings: 377.789520, pp_loss: 5.103366
[INFO] 2021-07-09 16:55:03,469 [run_pretraining.py:  512]:	********exe.run_371******* 
[INFO] 2021-07-09 16:55:05,754 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:05,755 [run_pretraining.py:  534]:	loss/total_loss, 4.916820049285889, 372
[INFO] 2021-07-09 16:55:05,755 [run_pretraining.py:  535]:	loss/mlm_loss, 4.916820049285889, 372
[INFO] 2021-07-09 16:55:05,755 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.709999646162032e-06, 372
[INFO] 2021-07-09 16:55:05,755 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 372
[INFO] 2021-07-09 16:55:05,755 [run_pretraining.py:  558]:	worker_index: 7, step: 372, cost: 4.916820, mlm loss: 4.916820, speed: 0.437414 steps/s, speed: 3.499315 samples/s, speed: 1791.649513 tokens/s, learning rate: 3.710e-06, loss_scalings: 377.789520, pp_loss: 4.911715
[INFO] 2021-07-09 16:55:05,756 [run_pretraining.py:  512]:	********exe.run_372******* 
[INFO] 2021-07-09 16:55:08,012 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:08,013 [run_pretraining.py:  534]:	loss/total_loss, 4.72767972946167, 373
[INFO] 2021-07-09 16:55:08,013 [run_pretraining.py:  535]:	loss/mlm_loss, 4.72767972946167, 373
[INFO] 2021-07-09 16:55:08,013 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.7199999951553764e-06, 373
[INFO] 2021-07-09 16:55:08,013 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 373
[INFO] 2021-07-09 16:55:08,013 [run_pretraining.py:  558]:	worker_index: 7, step: 373, cost: 4.727680, mlm loss: 4.727680, speed: 0.443100 steps/s, speed: 3.544797 samples/s, speed: 1814.936085 tokens/s, learning rate: 3.720e-06, loss_scalings: 377.789520, pp_loss: 4.752399
[INFO] 2021-07-09 16:55:08,013 [run_pretraining.py:  512]:	********exe.run_373******* 
[INFO] 2021-07-09 16:55:10,258 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:10,259 [run_pretraining.py:  534]:	loss/total_loss, 4.370656490325928, 374
[INFO] 2021-07-09 16:55:10,259 [run_pretraining.py:  535]:	loss/mlm_loss, 4.370656490325928, 374
[INFO] 2021-07-09 16:55:10,259 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.730000116775045e-06, 374
[INFO] 2021-07-09 16:55:10,259 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 374
[INFO] 2021-07-09 16:55:10,259 [run_pretraining.py:  558]:	worker_index: 7, step: 374, cost: 4.370656, mlm loss: 4.370656, speed: 0.445353 steps/s, speed: 3.562826 samples/s, speed: 1824.166933 tokens/s, learning rate: 3.730e-06, loss_scalings: 377.789520, pp_loss: 4.443667
[INFO] 2021-07-09 16:55:10,259 [run_pretraining.py:  512]:	********exe.run_374******* 
[INFO] 2021-07-09 16:55:12,510 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:12,511 [run_pretraining.py:  534]:	loss/total_loss, 4.005235195159912, 375
[INFO] 2021-07-09 16:55:12,511 [run_pretraining.py:  535]:	loss/mlm_loss, 4.005235195159912, 375
[INFO] 2021-07-09 16:55:12,511 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.739999783647363e-06, 375
[INFO] 2021-07-09 16:55:12,511 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 375
[INFO] 2021-07-09 16:55:12,511 [run_pretraining.py:  558]:	worker_index: 7, step: 375, cost: 4.005235, mlm loss: 4.005235, speed: 0.444159 steps/s, speed: 3.553273 samples/s, speed: 1819.276020 tokens/s, learning rate: 3.740e-06, loss_scalings: 377.789520, pp_loss: 4.050715
[INFO] 2021-07-09 16:55:12,511 [run_pretraining.py:  512]:	********exe.run_375******* 
[INFO] 2021-07-09 16:55:14,758 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:14,758 [run_pretraining.py:  534]:	loss/total_loss, 3.8130125999450684, 376
[INFO] 2021-07-09 16:55:14,758 [run_pretraining.py:  535]:	loss/mlm_loss, 3.8130125999450684, 376
[INFO] 2021-07-09 16:55:14,758 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.7500001326407073e-06, 376
[INFO] 2021-07-09 16:55:14,758 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 376
[INFO] 2021-07-09 16:55:14,759 [run_pretraining.py:  558]:	worker_index: 7, step: 376, cost: 3.813013, mlm loss: 3.813013, speed: 0.445069 steps/s, speed: 3.560555 samples/s, speed: 1823.004366 tokens/s, learning rate: 3.750e-06, loss_scalings: 377.789520, pp_loss: 3.757250
[INFO] 2021-07-09 16:55:14,759 [run_pretraining.py:  512]:	********exe.run_376******* 
[INFO] 2021-07-09 16:55:16,997 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:16,997 [run_pretraining.py:  534]:	loss/total_loss, 3.5783324241638184, 377
[INFO] 2021-07-09 16:55:16,997 [run_pretraining.py:  535]:	loss/mlm_loss, 3.5783324241638184, 377
[INFO] 2021-07-09 16:55:16,997 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.759999799513025e-06, 377
[INFO] 2021-07-09 16:55:16,997 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 377
[INFO] 2021-07-09 16:55:16,998 [run_pretraining.py:  558]:	worker_index: 7, step: 377, cost: 3.578332, mlm loss: 3.578332, speed: 0.446773 steps/s, speed: 3.574186 samples/s, speed: 1829.983169 tokens/s, learning rate: 3.760e-06, loss_scalings: 377.789520, pp_loss: 3.610583
[INFO] 2021-07-09 16:55:16,998 [run_pretraining.py:  512]:	********exe.run_377******* 
[INFO] 2021-07-09 16:55:19,244 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:19,245 [run_pretraining.py:  534]:	loss/total_loss, 3.502427339553833, 378
[INFO] 2021-07-09 16:55:19,245 [run_pretraining.py:  535]:	loss/mlm_loss, 3.502427339553833, 378
[INFO] 2021-07-09 16:55:19,245 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.769999921132694e-06, 378
[INFO] 2021-07-09 16:55:19,245 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 378
[INFO] 2021-07-09 16:55:19,245 [run_pretraining.py:  558]:	worker_index: 7, step: 378, cost: 3.502427, mlm loss: 3.502427, speed: 0.445015 steps/s, speed: 3.560122 samples/s, speed: 1822.782320 tokens/s, learning rate: 3.770e-06, loss_scalings: 377.789520, pp_loss: 3.540220
[INFO] 2021-07-09 16:55:19,245 [run_pretraining.py:  512]:	********exe.run_378******* 
[INFO] 2021-07-09 16:55:21,483 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:21,484 [run_pretraining.py:  534]:	loss/total_loss, 3.692488193511963, 379
[INFO] 2021-07-09 16:55:21,484 [run_pretraining.py:  535]:	loss/mlm_loss, 3.692488193511963, 379
[INFO] 2021-07-09 16:55:21,484 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.7799998153786873e-06, 379
[INFO] 2021-07-09 16:55:21,484 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 379
[INFO] 2021-07-09 16:55:21,484 [run_pretraining.py:  558]:	worker_index: 7, step: 379, cost: 3.692488, mlm loss: 3.692488, speed: 0.446806 steps/s, speed: 3.574451 samples/s, speed: 1830.118849 tokens/s, learning rate: 3.780e-06, loss_scalings: 377.789520, pp_loss: 3.638864
[INFO] 2021-07-09 16:55:21,484 [run_pretraining.py:  512]:	********exe.run_379******* 
[INFO] 2021-07-09 16:55:23,713 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:23,714 [run_pretraining.py:  534]:	loss/total_loss, 3.693436622619629, 380
[INFO] 2021-07-09 16:55:23,714 [run_pretraining.py:  535]:	loss/mlm_loss, 3.693436622619629, 380
[INFO] 2021-07-09 16:55:23,714 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.789999936998356e-06, 380
[INFO] 2021-07-09 16:55:23,714 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 380
[INFO] 2021-07-09 16:55:23,714 [run_pretraining.py:  558]:	worker_index: 7, step: 380, cost: 3.693437, mlm loss: 3.693437, speed: 0.448500 steps/s, speed: 3.587998 samples/s, speed: 1837.054897 tokens/s, learning rate: 3.790e-06, loss_scalings: 377.789520, pp_loss: 3.853075
[INFO] 2021-07-09 16:55:23,714 [run_pretraining.py:  512]:	********exe.run_380******* 
[INFO] 2021-07-09 16:55:25,956 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:25,957 [run_pretraining.py:  534]:	loss/total_loss, 4.013697147369385, 381
[INFO] 2021-07-09 16:55:25,957 [run_pretraining.py:  535]:	loss/mlm_loss, 4.013697147369385, 381
[INFO] 2021-07-09 16:55:25,957 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.7999998312443495e-06, 381
[INFO] 2021-07-09 16:55:25,957 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 381
[INFO] 2021-07-09 16:55:25,957 [run_pretraining.py:  558]:	worker_index: 7, step: 381, cost: 4.013697, mlm loss: 4.013697, speed: 0.445971 steps/s, speed: 3.567771 samples/s, speed: 1826.698884 tokens/s, learning rate: 3.800e-06, loss_scalings: 377.789520, pp_loss: 4.055700
[INFO] 2021-07-09 16:55:25,957 [run_pretraining.py:  512]:	********exe.run_381******* 
[INFO] 2021-07-09 16:55:28,216 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:28,216 [run_pretraining.py:  534]:	loss/total_loss, 4.335660934448242, 382
[INFO] 2021-07-09 16:55:28,217 [run_pretraining.py:  535]:	loss/mlm_loss, 4.335660934448242, 382
[INFO] 2021-07-09 16:55:28,217 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.8099999528640183e-06, 382
[INFO] 2021-07-09 16:55:28,217 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 382
[INFO] 2021-07-09 16:55:28,217 [run_pretraining.py:  558]:	worker_index: 7, step: 382, cost: 4.335661, mlm loss: 4.335661, speed: 0.442681 steps/s, speed: 3.541451 samples/s, speed: 1813.223012 tokens/s, learning rate: 3.810e-06, loss_scalings: 377.789520, pp_loss: 4.361359
[INFO] 2021-07-09 16:55:28,217 [run_pretraining.py:  512]:	********exe.run_382******* 
[INFO] 2021-07-09 16:55:30,463 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:30,463 [run_pretraining.py:  534]:	loss/total_loss, 4.55134391784668, 383
[INFO] 2021-07-09 16:55:30,463 [run_pretraining.py:  535]:	loss/mlm_loss, 4.55134391784668, 383
[INFO] 2021-07-09 16:55:30,463 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.819999619736336e-06, 383
[INFO] 2021-07-09 16:55:30,463 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 383
[INFO] 2021-07-09 16:55:30,464 [run_pretraining.py:  558]:	worker_index: 7, step: 383, cost: 4.551344, mlm loss: 4.551344, speed: 0.445222 steps/s, speed: 3.561774 samples/s, speed: 1823.628437 tokens/s, learning rate: 3.820e-06, loss_scalings: 377.789520, pp_loss: 4.615637
[INFO] 2021-07-09 16:55:30,464 [run_pretraining.py:  512]:	********exe.run_383******* 
[INFO] 2021-07-09 16:55:32,865 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:32,866 [run_pretraining.py:  534]:	loss/total_loss, 4.788759231567383, 384
[INFO] 2021-07-09 16:55:32,866 [run_pretraining.py:  535]:	loss/mlm_loss, 4.788759231567383, 384
[INFO] 2021-07-09 16:55:32,866 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.82999996872968e-06, 384
[INFO] 2021-07-09 16:55:32,866 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 384
[INFO] 2021-07-09 16:55:32,866 [run_pretraining.py:  558]:	worker_index: 7, step: 384, cost: 4.788759, mlm loss: 4.788759, speed: 0.416328 steps/s, speed: 3.330627 samples/s, speed: 1705.281040 tokens/s, learning rate: 3.830e-06, loss_scalings: 377.789520, pp_loss: 4.746960
[INFO] 2021-07-09 16:55:32,866 [run_pretraining.py:  512]:	********exe.run_384******* 
[INFO] 2021-07-09 16:55:35,216 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:35,216 [run_pretraining.py:  534]:	loss/total_loss, 4.687069416046143, 385
[INFO] 2021-07-09 16:55:35,216 [run_pretraining.py:  535]:	loss/mlm_loss, 4.687069416046143, 385
[INFO] 2021-07-09 16:55:35,216 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.839999862975674e-06, 385
[INFO] 2021-07-09 16:55:35,216 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 385
[INFO] 2021-07-09 16:55:35,216 [run_pretraining.py:  558]:	worker_index: 7, step: 385, cost: 4.687069, mlm loss: 4.687069, speed: 0.425583 steps/s, speed: 3.404667 samples/s, speed: 1743.189428 tokens/s, learning rate: 3.840e-06, loss_scalings: 377.789520, pp_loss: 4.741533
[INFO] 2021-07-09 16:55:35,217 [run_pretraining.py:  512]:	********exe.run_385******* 
[INFO] 2021-07-09 16:55:37,494 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:37,495 [run_pretraining.py:  534]:	loss/total_loss, 4.42401647567749, 386
[INFO] 2021-07-09 16:55:37,495 [run_pretraining.py:  535]:	loss/mlm_loss, 4.42401647567749, 386
[INFO] 2021-07-09 16:55:37,495 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.849999757221667e-06, 386
[INFO] 2021-07-09 16:55:37,495 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 386
[INFO] 2021-07-09 16:55:37,495 [run_pretraining.py:  558]:	worker_index: 7, step: 386, cost: 4.424016, mlm loss: 4.424016, speed: 0.438953 steps/s, speed: 3.511624 samples/s, speed: 1797.951344 tokens/s, learning rate: 3.850e-06, loss_scalings: 377.789520, pp_loss: 4.493666
[INFO] 2021-07-09 16:55:37,495 [run_pretraining.py:  512]:	********exe.run_386******* 
[INFO] 2021-07-09 16:55:39,760 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:39,760 [run_pretraining.py:  534]:	loss/total_loss, 4.262438774108887, 387
[INFO] 2021-07-09 16:55:39,760 [run_pretraining.py:  535]:	loss/mlm_loss, 4.262438774108887, 387
[INFO] 2021-07-09 16:55:39,760 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.860000106215011e-06, 387
[INFO] 2021-07-09 16:55:39,760 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 387
[INFO] 2021-07-09 16:55:39,760 [run_pretraining.py:  558]:	worker_index: 7, step: 387, cost: 4.262439, mlm loss: 4.262439, speed: 0.441601 steps/s, speed: 3.532808 samples/s, speed: 1808.797602 tokens/s, learning rate: 3.860e-06, loss_scalings: 377.789520, pp_loss: 4.264864
[INFO] 2021-07-09 16:55:39,761 [run_pretraining.py:  512]:	********exe.run_387******* 
[INFO] 2021-07-09 16:55:42,000 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:42,000 [run_pretraining.py:  534]:	loss/total_loss, 4.232341289520264, 388
[INFO] 2021-07-09 16:55:42,000 [run_pretraining.py:  535]:	loss/mlm_loss, 4.232341289520264, 388
[INFO] 2021-07-09 16:55:42,001 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.870000000461005e-06, 388
[INFO] 2021-07-09 16:55:42,001 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 388
[INFO] 2021-07-09 16:55:42,001 [run_pretraining.py:  558]:	worker_index: 7, step: 388, cost: 4.232341, mlm loss: 4.232341, speed: 0.446492 steps/s, speed: 3.571940 samples/s, speed: 1828.833232 tokens/s, learning rate: 3.870e-06, loss_scalings: 377.789520, pp_loss: 4.263837
[INFO] 2021-07-09 16:55:42,001 [run_pretraining.py:  512]:	********exe.run_388******* 
[INFO] 2021-07-09 16:55:44,265 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:44,265 [run_pretraining.py:  534]:	loss/total_loss, 4.276062965393066, 389
[INFO] 2021-07-09 16:55:44,265 [run_pretraining.py:  535]:	loss/mlm_loss, 4.276062965393066, 389
[INFO] 2021-07-09 16:55:44,265 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.879999894706998e-06, 389
[INFO] 2021-07-09 16:55:44,265 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 389
[INFO] 2021-07-09 16:55:44,265 [run_pretraining.py:  558]:	worker_index: 7, step: 389, cost: 4.276063, mlm loss: 4.276063, speed: 0.441674 steps/s, speed: 3.533395 samples/s, speed: 1809.098168 tokens/s, learning rate: 3.880e-06, loss_scalings: 377.789520, pp_loss: 4.226040
[INFO] 2021-07-09 16:55:44,266 [run_pretraining.py:  512]:	********exe.run_389******* 
[INFO] 2021-07-09 16:55:46,548 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:46,549 [run_pretraining.py:  534]:	loss/total_loss, 4.318352699279785, 390
[INFO] 2021-07-09 16:55:46,549 [run_pretraining.py:  535]:	loss/mlm_loss, 4.318352699279785, 390
[INFO] 2021-07-09 16:55:46,549 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.889999788952991e-06, 390
[INFO] 2021-07-09 16:55:46,549 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 390
[INFO] 2021-07-09 16:55:46,549 [run_pretraining.py:  558]:	worker_index: 7, step: 390, cost: 4.318353, mlm loss: 4.318353, speed: 0.438043 steps/s, speed: 3.504343 samples/s, speed: 1794.223474 tokens/s, learning rate: 3.890e-06, loss_scalings: 377.789520, pp_loss: 4.288861
[INFO] 2021-07-09 16:55:46,549 [run_pretraining.py:  512]:	********exe.run_390******* 
[INFO] 2021-07-09 16:55:48,881 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:48,881 [run_pretraining.py:  534]:	loss/total_loss, 4.1330695152282715, 391
[INFO] 2021-07-09 16:55:48,881 [run_pretraining.py:  535]:	loss/mlm_loss, 4.1330695152282715, 391
[INFO] 2021-07-09 16:55:48,881 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.900000137946336e-06, 391
[INFO] 2021-07-09 16:55:48,881 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 391
[INFO] 2021-07-09 16:55:48,881 [run_pretraining.py:  558]:	worker_index: 7, step: 391, cost: 4.133070, mlm loss: 4.133070, speed: 0.428844 steps/s, speed: 3.430749 samples/s, speed: 1756.543397 tokens/s, learning rate: 3.900e-06, loss_scalings: 377.789520, pp_loss: 4.169116
[INFO] 2021-07-09 16:55:48,882 [run_pretraining.py:  512]:	********exe.run_391******* 
[INFO] 2021-07-09 16:55:51,213 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:51,213 [run_pretraining.py:  534]:	loss/total_loss, 3.727325201034546, 392
[INFO] 2021-07-09 16:55:51,213 [run_pretraining.py:  535]:	loss/mlm_loss, 3.727325201034546, 392
[INFO] 2021-07-09 16:55:51,213 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.909999577444978e-06, 392
[INFO] 2021-07-09 16:55:51,213 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 392
[INFO] 2021-07-09 16:55:51,213 [run_pretraining.py:  558]:	worker_index: 7, step: 392, cost: 3.727325, mlm loss: 3.727325, speed: 0.428941 steps/s, speed: 3.431529 samples/s, speed: 1756.942731 tokens/s, learning rate: 3.910e-06, loss_scalings: 377.789520, pp_loss: 3.808722
[INFO] 2021-07-09 16:55:51,213 [run_pretraining.py:  512]:	********exe.run_392******* 
[INFO] 2021-07-09 16:55:53,524 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:53,525 [run_pretraining.py:  534]:	loss/total_loss, 3.6133880615234375, 393
[INFO] 2021-07-09 16:55:53,525 [run_pretraining.py:  535]:	loss/mlm_loss, 3.6133880615234375, 393
[INFO] 2021-07-09 16:55:53,525 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.919999926438322e-06, 393
[INFO] 2021-07-09 16:55:53,525 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 393
[INFO] 2021-07-09 16:55:53,525 [run_pretraining.py:  558]:	worker_index: 7, step: 393, cost: 3.613388, mlm loss: 3.613388, speed: 0.432736 steps/s, speed: 3.461889 samples/s, speed: 1772.487360 tokens/s, learning rate: 3.920e-06, loss_scalings: 377.789520, pp_loss: 3.425587
[INFO] 2021-07-09 16:55:53,525 [run_pretraining.py:  512]:	********exe.run_393******* 
[INFO] 2021-07-09 16:55:55,772 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:55,772 [run_pretraining.py:  534]:	loss/total_loss, 3.1639740467071533, 394
[INFO] 2021-07-09 16:55:55,772 [run_pretraining.py:  535]:	loss/mlm_loss, 3.1639740467071533, 394
[INFO] 2021-07-09 16:55:55,772 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.929999820684316e-06, 394
[INFO] 2021-07-09 16:55:55,772 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 394
[INFO] 2021-07-09 16:55:55,772 [run_pretraining.py:  558]:	worker_index: 7, step: 394, cost: 3.163974, mlm loss: 3.163974, speed: 0.445089 steps/s, speed: 3.560715 samples/s, speed: 1823.086197 tokens/s, learning rate: 3.930e-06, loss_scalings: 377.789520, pp_loss: 3.137233
[INFO] 2021-07-09 16:55:55,772 [run_pretraining.py:  512]:	********exe.run_394******* 
[INFO] 2021-07-09 16:55:58,046 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:58,047 [run_pretraining.py:  534]:	loss/total_loss, 2.893792152404785, 395
[INFO] 2021-07-09 16:55:58,047 [run_pretraining.py:  535]:	loss/mlm_loss, 2.893792152404785, 395
[INFO] 2021-07-09 16:55:58,047 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.939999714930309e-06, 395
[INFO] 2021-07-09 16:55:58,047 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 395
[INFO] 2021-07-09 16:55:58,047 [run_pretraining.py:  558]:	worker_index: 7, step: 395, cost: 2.893792, mlm loss: 2.893792, speed: 0.439740 steps/s, speed: 3.517921 samples/s, speed: 1801.175468 tokens/s, learning rate: 3.940e-06, loss_scalings: 377.789520, pp_loss: 2.936278
[INFO] 2021-07-09 16:55:58,047 [run_pretraining.py:  512]:	********exe.run_395******* 
[INFO] 2021-07-09 16:56:00,358 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:00,359 [run_pretraining.py:  534]:	loss/total_loss, 2.799283742904663, 396
[INFO] 2021-07-09 16:56:00,359 [run_pretraining.py:  535]:	loss/mlm_loss, 2.799283742904663, 396
[INFO] 2021-07-09 16:56:00,359 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.950000063923653e-06, 396
[INFO] 2021-07-09 16:56:00,359 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 396
[INFO] 2021-07-09 16:56:00,359 [run_pretraining.py:  558]:	worker_index: 7, step: 396, cost: 2.799284, mlm loss: 2.799284, speed: 0.432676 steps/s, speed: 3.461405 samples/s, speed: 1772.239603 tokens/s, learning rate: 3.950e-06, loss_scalings: 377.789520, pp_loss: 2.859867
[INFO] 2021-07-09 16:56:00,359 [run_pretraining.py:  512]:	********exe.run_396******* 
[INFO] 2021-07-09 16:56:02,693 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:02,693 [run_pretraining.py:  534]:	loss/total_loss, 2.8813905715942383, 397
[INFO] 2021-07-09 16:56:02,693 [run_pretraining.py:  535]:	loss/mlm_loss, 2.8813905715942383, 397
[INFO] 2021-07-09 16:56:02,693 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.9599999581696466e-06, 397
[INFO] 2021-07-09 16:56:02,693 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 397
[INFO] 2021-07-09 16:56:02,693 [run_pretraining.py:  558]:	worker_index: 7, step: 397, cost: 2.881391, mlm loss: 2.881391, speed: 0.428467 steps/s, speed: 3.427734 samples/s, speed: 1754.999686 tokens/s, learning rate: 3.960e-06, loss_scalings: 377.789520, pp_loss: 2.884932
[INFO] 2021-07-09 16:56:02,694 [run_pretraining.py:  512]:	********exe.run_397******* 
[INFO] 2021-07-09 16:56:04,973 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:04,973 [run_pretraining.py:  534]:	loss/total_loss, 2.990776538848877, 398
[INFO] 2021-07-09 16:56:04,974 [run_pretraining.py:  535]:	loss/mlm_loss, 2.990776538848877, 398
[INFO] 2021-07-09 16:56:04,974 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.96999985241564e-06, 398
[INFO] 2021-07-09 16:56:04,974 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 398
[INFO] 2021-07-09 16:56:04,974 [run_pretraining.py:  558]:	worker_index: 7, step: 398, cost: 2.990777, mlm loss: 2.990777, speed: 0.438642 steps/s, speed: 3.509137 samples/s, speed: 1796.678189 tokens/s, learning rate: 3.970e-06, loss_scalings: 377.789520, pp_loss: 3.024773
[INFO] 2021-07-09 16:56:04,974 [run_pretraining.py:  512]:	********exe.run_398******* 
[INFO] 2021-07-09 16:56:07,285 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:07,285 [run_pretraining.py:  534]:	loss/total_loss, 3.231963634490967, 399
[INFO] 2021-07-09 16:56:07,285 [run_pretraining.py:  535]:	loss/mlm_loss, 3.231963634490967, 399
[INFO] 2021-07-09 16:56:07,286 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.979999746661633e-06, 399
[INFO] 2021-07-09 16:56:07,286 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 399
[INFO] 2021-07-09 16:56:07,286 [run_pretraining.py:  558]:	worker_index: 7, step: 399, cost: 3.231964, mlm loss: 3.231964, speed: 0.432676 steps/s, speed: 3.461410 samples/s, speed: 1772.241797 tokens/s, learning rate: 3.980e-06, loss_scalings: 377.789520, pp_loss: 3.248788
[INFO] 2021-07-09 16:56:07,286 [run_pretraining.py:  512]:	********exe.run_399******* 
[INFO] 2021-07-09 16:56:09,527 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:09,527 [run_pretraining.py:  534]:	loss/total_loss, 3.8454482555389404, 400
[INFO] 2021-07-09 16:56:09,528 [run_pretraining.py:  535]:	loss/mlm_loss, 3.8454482555389404, 400
[INFO] 2021-07-09 16:56:09,528 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.9900000956549775e-06, 400
[INFO] 2021-07-09 16:56:09,528 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 400
[INFO] 2021-07-09 16:56:09,528 [run_pretraining.py:  558]:	worker_index: 7, step: 400, cost: 3.845448, mlm loss: 3.845448, speed: 0.446131 steps/s, speed: 3.569046 samples/s, speed: 1827.351532 tokens/s, learning rate: 3.990e-06, loss_scalings: 377.789520, pp_loss: 3.666600
[INFO] 2021-07-09 16:56:09,528 [run_pretraining.py:  512]:	********exe.run_400******* 
[INFO] 2021-07-09 16:56:11,821 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:11,822 [run_pretraining.py:  534]:	loss/total_loss, 4.163168430328369, 401
[INFO] 2021-07-09 16:56:11,822 [run_pretraining.py:  535]:	loss/mlm_loss, 4.163168430328369, 401
[INFO] 2021-07-09 16:56:11,822 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.999999989900971e-06, 401
[INFO] 2021-07-09 16:56:11,822 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 401
[INFO] 2021-07-09 16:56:11,822 [run_pretraining.py:  558]:	worker_index: 7, step: 401, cost: 4.163168, mlm loss: 4.163168, speed: 0.435950 steps/s, speed: 3.487601 samples/s, speed: 1785.651504 tokens/s, learning rate: 4.000e-06, loss_scalings: 377.789520, pp_loss: 4.062754
[INFO] 2021-07-09 16:56:11,823 [run_pretraining.py:  512]:	********exe.run_401******* 
[INFO] 2021-07-09 16:56:14,076 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:14,077 [run_pretraining.py:  534]:	loss/total_loss, 4.585671901702881, 402
[INFO] 2021-07-09 16:56:14,077 [run_pretraining.py:  535]:	loss/mlm_loss, 4.585671901702881, 402
[INFO] 2021-07-09 16:56:14,077 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.009999884146964e-06, 402
[INFO] 2021-07-09 16:56:14,077 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 402
[INFO] 2021-07-09 16:56:14,077 [run_pretraining.py:  558]:	worker_index: 7, step: 402, cost: 4.585672, mlm loss: 4.585672, speed: 0.443627 steps/s, speed: 3.549017 samples/s, speed: 1817.096639 tokens/s, learning rate: 4.010e-06, loss_scalings: 377.789520, pp_loss: 4.709905
[INFO] 2021-07-09 16:56:14,077 [run_pretraining.py:  512]:	********exe.run_402******* 
[INFO] 2021-07-09 16:56:16,424 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:16,425 [run_pretraining.py:  534]:	loss/total_loss, 5.212761402130127, 403
[INFO] 2021-07-09 16:56:16,425 [run_pretraining.py:  535]:	loss/mlm_loss, 5.212761402130127, 403
[INFO] 2021-07-09 16:56:16,425 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.0199997783929575e-06, 403
[INFO] 2021-07-09 16:56:16,425 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 403
[INFO] 2021-07-09 16:56:16,425 [run_pretraining.py:  558]:	worker_index: 7, step: 403, cost: 5.212761, mlm loss: 5.212761, speed: 0.425989 steps/s, speed: 3.407909 samples/s, speed: 1744.849576 tokens/s, learning rate: 4.020e-06, loss_scalings: 377.789520, pp_loss: 5.232767
[INFO] 2021-07-09 16:56:16,425 [run_pretraining.py:  512]:	********exe.run_403******* 
[INFO] 2021-07-09 16:56:18,725 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:18,725 [run_pretraining.py:  534]:	loss/total_loss, 5.792836666107178, 404
[INFO] 2021-07-09 16:56:18,725 [run_pretraining.py:  535]:	loss/mlm_loss, 5.792836666107178, 404
[INFO] 2021-07-09 16:56:18,726 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.030000127386302e-06, 404
[INFO] 2021-07-09 16:56:18,726 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 404
[INFO] 2021-07-09 16:56:18,726 [run_pretraining.py:  558]:	worker_index: 7, step: 404, cost: 5.792837, mlm loss: 5.792837, speed: 0.434835 steps/s, speed: 3.478680 samples/s, speed: 1781.084139 tokens/s, learning rate: 4.030e-06, loss_scalings: 377.789520, pp_loss: 5.761426
[INFO] 2021-07-09 16:56:18,726 [run_pretraining.py:  512]:	********exe.run_404******* 
[INFO] 2021-07-09 16:56:21,013 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:21,014 [run_pretraining.py:  534]:	loss/total_loss, 5.892857074737549, 405
[INFO] 2021-07-09 16:56:21,014 [run_pretraining.py:  535]:	loss/mlm_loss, 5.892857074737549, 405
[INFO] 2021-07-09 16:56:21,014 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.039999566884944e-06, 405
[INFO] 2021-07-09 16:56:21,014 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 405
[INFO] 2021-07-09 16:56:21,014 [run_pretraining.py:  558]:	worker_index: 7, step: 405, cost: 5.892857, mlm loss: 5.892857, speed: 0.437131 steps/s, speed: 3.497052 samples/s, speed: 1790.490504 tokens/s, learning rate: 4.040e-06, loss_scalings: 377.789520, pp_loss: 5.896423
[INFO] 2021-07-09 16:56:21,014 [run_pretraining.py:  512]:	********exe.run_405******* 
[INFO] 2021-07-09 16:56:23,273 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:23,273 [run_pretraining.py:  534]:	loss/total_loss, 6.012423992156982, 406
[INFO] 2021-07-09 16:56:23,273 [run_pretraining.py:  535]:	loss/mlm_loss, 6.012423992156982, 406
[INFO] 2021-07-09 16:56:23,274 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.0499999158782884e-06, 406
[INFO] 2021-07-09 16:56:23,274 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 406
[INFO] 2021-07-09 16:56:23,274 [run_pretraining.py:  558]:	worker_index: 7, step: 406, cost: 6.012424, mlm loss: 6.012424, speed: 0.442652 steps/s, speed: 3.541218 samples/s, speed: 1813.103411 tokens/s, learning rate: 4.050e-06, loss_scalings: 377.789520, pp_loss: 5.960045
[INFO] 2021-07-09 16:56:23,274 [run_pretraining.py:  512]:	********exe.run_406******* 
[INFO] 2021-07-09 16:56:25,513 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:25,514 [run_pretraining.py:  534]:	loss/total_loss, 5.611176490783691, 407
[INFO] 2021-07-09 16:56:25,514 [run_pretraining.py:  535]:	loss/mlm_loss, 5.611176490783691, 407
[INFO] 2021-07-09 16:56:25,514 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.060000264871633e-06, 407
[INFO] 2021-07-09 16:56:25,514 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 407
[INFO] 2021-07-09 16:56:25,514 [run_pretraining.py:  558]:	worker_index: 7, step: 407, cost: 5.611176, mlm loss: 5.611176, speed: 0.446485 steps/s, speed: 3.571876 samples/s, speed: 1828.800721 tokens/s, learning rate: 4.060e-06, loss_scalings: 377.789520, pp_loss: 5.511868
[INFO] 2021-07-09 16:56:25,514 [run_pretraining.py:  512]:	********exe.run_407******* 
[INFO] 2021-07-09 16:56:27,788 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:27,789 [run_pretraining.py:  534]:	loss/total_loss, 5.035940170288086, 408
[INFO] 2021-07-09 16:56:27,789 [run_pretraining.py:  535]:	loss/mlm_loss, 5.035940170288086, 408
[INFO] 2021-07-09 16:56:27,789 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.069999704370275e-06, 408
[INFO] 2021-07-09 16:56:27,789 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 408
[INFO] 2021-07-09 16:56:27,790 [run_pretraining.py:  558]:	worker_index: 7, step: 408, cost: 5.035940, mlm loss: 5.035940, speed: 0.439610 steps/s, speed: 3.516878 samples/s, speed: 1800.641400 tokens/s, learning rate: 4.070e-06, loss_scalings: 377.789520, pp_loss: 5.061796
[INFO] 2021-07-09 16:56:27,790 [run_pretraining.py:  512]:	********exe.run_408******* 
[INFO] 2021-07-09 16:56:30,067 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:30,067 [run_pretraining.py:  534]:	loss/total_loss, 4.710430145263672, 409
[INFO] 2021-07-09 16:56:30,067 [run_pretraining.py:  535]:	loss/mlm_loss, 4.710430145263672, 409
[INFO] 2021-07-09 16:56:30,067 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.080000053363619e-06, 409
[INFO] 2021-07-09 16:56:30,068 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 409
[INFO] 2021-07-09 16:56:30,068 [run_pretraining.py:  558]:	worker_index: 7, step: 409, cost: 4.710430, mlm loss: 4.710430, speed: 0.439094 steps/s, speed: 3.512755 samples/s, speed: 1798.530322 tokens/s, learning rate: 4.080e-06, loss_scalings: 377.789520, pp_loss: 4.764896
[INFO] 2021-07-09 16:56:30,068 [run_pretraining.py:  512]:	********exe.run_409******* 
[INFO] 2021-07-09 16:56:32,324 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:32,324 [run_pretraining.py:  534]:	loss/total_loss, 4.914010047912598, 410
[INFO] 2021-07-09 16:56:32,325 [run_pretraining.py:  535]:	loss/mlm_loss, 4.914010047912598, 410
[INFO] 2021-07-09 16:56:32,325 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.089999947609613e-06, 410
[INFO] 2021-07-09 16:56:32,325 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 410
[INFO] 2021-07-09 16:56:32,325 [run_pretraining.py:  558]:	worker_index: 7, step: 410, cost: 4.914010, mlm loss: 4.914010, speed: 0.443138 steps/s, speed: 3.545104 samples/s, speed: 1815.093130 tokens/s, learning rate: 4.090e-06, loss_scalings: 377.789520, pp_loss: 4.640377
[INFO] 2021-07-09 16:56:32,325 [run_pretraining.py:  512]:	********exe.run_410******* 
[INFO] 2021-07-09 16:56:34,586 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:34,586 [run_pretraining.py:  534]:	loss/total_loss, 4.491384506225586, 411
[INFO] 2021-07-09 16:56:34,586 [run_pretraining.py:  535]:	loss/mlm_loss, 4.491384506225586, 411
[INFO] 2021-07-09 16:56:34,586 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.099999841855606e-06, 411
[INFO] 2021-07-09 16:56:34,586 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 411
[INFO] 2021-07-09 16:56:34,587 [run_pretraining.py:  558]:	worker_index: 7, step: 411, cost: 4.491385, mlm loss: 4.491385, speed: 0.442268 steps/s, speed: 3.538144 samples/s, speed: 1811.529788 tokens/s, learning rate: 4.100e-06, loss_scalings: 377.789520, pp_loss: 4.471372
[INFO] 2021-07-09 16:56:34,587 [run_pretraining.py:  512]:	********exe.run_411******* 
[INFO] 2021-07-09 16:56:36,832 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:36,832 [run_pretraining.py:  534]:	loss/total_loss, 3.893347978591919, 412
[INFO] 2021-07-09 16:56:36,832 [run_pretraining.py:  535]:	loss/mlm_loss, 3.893347978591919, 412
[INFO] 2021-07-09 16:56:36,832 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.109999736101599e-06, 412
[INFO] 2021-07-09 16:56:36,832 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 412
[INFO] 2021-07-09 16:56:36,832 [run_pretraining.py:  558]:	worker_index: 7, step: 412, cost: 3.893348, mlm loss: 3.893348, speed: 0.445385 steps/s, speed: 3.563083 samples/s, speed: 1824.298458 tokens/s, learning rate: 4.110e-06, loss_scalings: 377.789520, pp_loss: 3.927889
[INFO] 2021-07-09 16:56:36,833 [run_pretraining.py:  512]:	********exe.run_412******* 
[INFO] 2021-07-09 16:56:39,131 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:39,131 [run_pretraining.py:  534]:	loss/total_loss, 3.68978214263916, 413
[INFO] 2021-07-09 16:56:39,131 [run_pretraining.py:  535]:	loss/mlm_loss, 3.68978214263916, 413
[INFO] 2021-07-09 16:56:39,131 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.120000085094944e-06, 413
[INFO] 2021-07-09 16:56:39,131 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 413
[INFO] 2021-07-09 16:56:39,131 [run_pretraining.py:  558]:	worker_index: 7, step: 413, cost: 3.689782, mlm loss: 3.689782, speed: 0.435105 steps/s, speed: 3.480843 samples/s, speed: 1782.191434 tokens/s, learning rate: 4.120e-06, loss_scalings: 377.789520, pp_loss: 3.730335
[INFO] 2021-07-09 16:56:39,131 [run_pretraining.py:  512]:	********exe.run_413******* 
[INFO] 2021-07-09 16:56:41,358 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:41,358 [run_pretraining.py:  534]:	loss/total_loss, 3.478508472442627, 414
[INFO] 2021-07-09 16:56:41,358 [run_pretraining.py:  535]:	loss/mlm_loss, 3.478508472442627, 414
[INFO] 2021-07-09 16:56:41,358 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.129999979340937e-06, 414
[INFO] 2021-07-09 16:56:41,359 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 414
[INFO] 2021-07-09 16:56:41,359 [run_pretraining.py:  558]:	worker_index: 7, step: 414, cost: 3.478508, mlm loss: 3.478508, speed: 0.449118 steps/s, speed: 3.592940 samples/s, speed: 1839.585350 tokens/s, learning rate: 4.130e-06, loss_scalings: 377.789520, pp_loss: 3.558042
[INFO] 2021-07-09 16:56:41,359 [run_pretraining.py:  512]:	********exe.run_414******* 
[INFO] 2021-07-09 16:56:43,589 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:43,589 [run_pretraining.py:  534]:	loss/total_loss, 3.4092986583709717, 415
[INFO] 2021-07-09 16:56:43,589 [run_pretraining.py:  535]:	loss/mlm_loss, 3.4092986583709717, 415
[INFO] 2021-07-09 16:56:43,589 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.13999987358693e-06, 415
[INFO] 2021-07-09 16:56:43,589 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 415
[INFO] 2021-07-09 16:56:43,589 [run_pretraining.py:  558]:	worker_index: 7, step: 415, cost: 3.409299, mlm loss: 3.409299, speed: 0.448399 steps/s, speed: 3.587194 samples/s, speed: 1836.643452 tokens/s, learning rate: 4.140e-06, loss_scalings: 377.789520, pp_loss: 3.401004
[INFO] 2021-07-09 16:56:43,590 [run_pretraining.py:  512]:	********exe.run_415******* 
[INFO] 2021-07-09 16:56:45,870 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:45,871 [run_pretraining.py:  534]:	loss/total_loss, 3.6200294494628906, 416
[INFO] 2021-07-09 16:56:45,871 [run_pretraining.py:  535]:	loss/mlm_loss, 3.6200294494628906, 416
[INFO] 2021-07-09 16:56:45,871 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.149999767832924e-06, 416
[INFO] 2021-07-09 16:56:45,871 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 416
[INFO] 2021-07-09 16:56:45,871 [run_pretraining.py:  558]:	worker_index: 7, step: 416, cost: 3.620029, mlm loss: 3.620029, speed: 0.438435 steps/s, speed: 3.507478 samples/s, speed: 1795.828919 tokens/s, learning rate: 4.150e-06, loss_scalings: 377.789520, pp_loss: 3.682048
[INFO] 2021-07-09 16:56:45,871 [run_pretraining.py:  512]:	********exe.run_416******* 
[INFO] 2021-07-09 16:56:48,187 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:48,188 [run_pretraining.py:  534]:	loss/total_loss, 4.2503509521484375, 417
[INFO] 2021-07-09 16:56:48,188 [run_pretraining.py:  535]:	loss/mlm_loss, 4.2503509521484375, 417
[INFO] 2021-07-09 16:56:48,188 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.160000116826268e-06, 417
[INFO] 2021-07-09 16:56:48,188 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 417
[INFO] 2021-07-09 16:56:48,188 [run_pretraining.py:  558]:	worker_index: 7, step: 417, cost: 4.250351, mlm loss: 4.250351, speed: 0.431641 steps/s, speed: 3.453124 samples/s, speed: 1767.999741 tokens/s, learning rate: 4.160e-06, loss_scalings: 377.789520, pp_loss: 4.151767
[INFO] 2021-07-09 16:56:48,188 [run_pretraining.py:  512]:	********exe.run_417******* 
[INFO] 2021-07-09 16:56:50,501 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:50,501 [run_pretraining.py:  534]:	loss/total_loss, 4.603245735168457, 418
[INFO] 2021-07-09 16:56:50,501 [run_pretraining.py:  535]:	loss/mlm_loss, 4.603245735168457, 418
[INFO] 2021-07-09 16:56:50,501 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.170000011072261e-06, 418
[INFO] 2021-07-09 16:56:50,501 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 418
[INFO] 2021-07-09 16:56:50,501 [run_pretraining.py:  558]:	worker_index: 7, step: 418, cost: 4.603246, mlm loss: 4.603246, speed: 0.432444 steps/s, speed: 3.459555 samples/s, speed: 1771.292185 tokens/s, learning rate: 4.170e-06, loss_scalings: 377.789520, pp_loss: 4.710398
[INFO] 2021-07-09 16:56:50,501 [run_pretraining.py:  512]:	********exe.run_418******* 
[INFO] 2021-07-09 16:56:52,797 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:52,798 [run_pretraining.py:  534]:	loss/total_loss, 5.402037620544434, 419
[INFO] 2021-07-09 16:56:52,798 [run_pretraining.py:  535]:	loss/mlm_loss, 5.402037620544434, 419
[INFO] 2021-07-09 16:56:52,798 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.179999905318255e-06, 419
[INFO] 2021-07-09 16:56:52,798 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 419
[INFO] 2021-07-09 16:56:52,798 [run_pretraining.py:  558]:	worker_index: 7, step: 419, cost: 5.402038, mlm loss: 5.402038, speed: 0.435544 steps/s, speed: 3.484348 samples/s, speed: 1783.986387 tokens/s, learning rate: 4.180e-06, loss_scalings: 377.789520, pp_loss: 5.386231
[INFO] 2021-07-09 16:56:52,798 [run_pretraining.py:  512]:	********exe.run_419******* 
[INFO] 2021-07-09 16:56:55,129 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:55,130 [run_pretraining.py:  534]:	loss/total_loss, 6.195710182189941, 420
[INFO] 2021-07-09 16:56:55,130 [run_pretraining.py:  535]:	loss/mlm_loss, 6.195710182189941, 420
[INFO] 2021-07-09 16:56:55,130 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.190000254311599e-06, 420
[INFO] 2021-07-09 16:56:55,130 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 420
[INFO] 2021-07-09 16:56:55,130 [run_pretraining.py:  558]:	worker_index: 7, step: 420, cost: 6.195710, mlm loss: 6.195710, speed: 0.428890 steps/s, speed: 3.431122 samples/s, speed: 1756.734688 tokens/s, learning rate: 4.190e-06, loss_scalings: 377.789520, pp_loss: 6.121864
[INFO] 2021-07-09 16:56:55,130 [run_pretraining.py:  512]:	********exe.run_420******* 
[INFO] 2021-07-09 16:56:57,437 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:57,437 [run_pretraining.py:  534]:	loss/total_loss, 7.013423919677734, 421
[INFO] 2021-07-09 16:56:57,438 [run_pretraining.py:  535]:	loss/mlm_loss, 7.013423919677734, 421
[INFO] 2021-07-09 16:56:57,438 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.199999693810241e-06, 421
[INFO] 2021-07-09 16:56:57,438 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 421
[INFO] 2021-07-09 16:56:57,438 [run_pretraining.py:  558]:	worker_index: 7, step: 421, cost: 7.013424, mlm loss: 7.013424, speed: 0.433491 steps/s, speed: 3.467930 samples/s, speed: 1775.580169 tokens/s, learning rate: 4.200e-06, loss_scalings: 377.789520, pp_loss: 6.853925
[INFO] 2021-07-09 16:56:57,438 [run_pretraining.py:  512]:	********exe.run_421******* 
[INFO] 2021-07-09 16:56:59,732 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:59,732 [run_pretraining.py:  534]:	loss/total_loss, 7.222762584686279, 422
[INFO] 2021-07-09 16:56:59,733 [run_pretraining.py:  535]:	loss/mlm_loss, 7.222762584686279, 422
[INFO] 2021-07-09 16:56:59,733 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.2100000428035855e-06, 422
[INFO] 2021-07-09 16:56:59,733 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 422
[INFO] 2021-07-09 16:56:59,733 [run_pretraining.py:  558]:	worker_index: 7, step: 422, cost: 7.222763, mlm loss: 7.222763, speed: 0.435842 steps/s, speed: 3.486732 samples/s, speed: 1785.206921 tokens/s, learning rate: 4.210e-06, loss_scalings: 377.789520, pp_loss: 7.213181
[INFO] 2021-07-09 16:56:59,733 [run_pretraining.py:  512]:	********exe.run_422******* 
[INFO] 2021-07-09 16:57:02,045 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:02,046 [run_pretraining.py:  534]:	loss/total_loss, 6.963998794555664, 423
[INFO] 2021-07-09 16:57:02,046 [run_pretraining.py:  535]:	loss/mlm_loss, 6.963998794555664, 423
[INFO] 2021-07-09 16:57:02,046 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.219999937049579e-06, 423
[INFO] 2021-07-09 16:57:02,046 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 423
[INFO] 2021-07-09 16:57:02,046 [run_pretraining.py:  558]:	worker_index: 7, step: 423, cost: 6.963999, mlm loss: 6.963999, speed: 0.432407 steps/s, speed: 3.459258 samples/s, speed: 1771.140254 tokens/s, learning rate: 4.220e-06, loss_scalings: 377.789520, pp_loss: 7.039907
[INFO] 2021-07-09 16:57:02,046 [run_pretraining.py:  512]:	********exe.run_423******* 
[INFO] 2021-07-09 16:57:04,323 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:04,323 [run_pretraining.py:  534]:	loss/total_loss, 6.716706275939941, 424
[INFO] 2021-07-09 16:57:04,323 [run_pretraining.py:  535]:	loss/mlm_loss, 6.716706275939941, 424
[INFO] 2021-07-09 16:57:04,323 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.229999831295572e-06, 424
[INFO] 2021-07-09 16:57:04,323 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 424
[INFO] 2021-07-09 16:57:04,324 [run_pretraining.py:  558]:	worker_index: 7, step: 424, cost: 6.716706, mlm loss: 6.716706, speed: 0.439218 steps/s, speed: 3.513740 samples/s, speed: 1799.035067 tokens/s, learning rate: 4.230e-06, loss_scalings: 377.789520, pp_loss: 6.676501
[INFO] 2021-07-09 16:57:04,324 [run_pretraining.py:  512]:	********exe.run_424******* 
[INFO] 2021-07-09 16:57:06,555 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:06,555 [run_pretraining.py:  534]:	loss/total_loss, 6.348684310913086, 425
[INFO] 2021-07-09 16:57:06,555 [run_pretraining.py:  535]:	loss/mlm_loss, 6.348684310913086, 425
[INFO] 2021-07-09 16:57:06,555 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.2399997255415656e-06, 425
[INFO] 2021-07-09 16:57:06,555 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 425
[INFO] 2021-07-09 16:57:06,555 [run_pretraining.py:  558]:	worker_index: 7, step: 425, cost: 6.348684, mlm loss: 6.348684, speed: 0.448197 steps/s, speed: 3.585576 samples/s, speed: 1835.815035 tokens/s, learning rate: 4.240e-06, loss_scalings: 377.789520, pp_loss: 6.439828
[INFO] 2021-07-09 16:57:06,555 [run_pretraining.py:  512]:	********exe.run_425******* 
[INFO] 2021-07-09 16:57:08,821 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:08,821 [run_pretraining.py:  534]:	loss/total_loss, 6.222715854644775, 426
[INFO] 2021-07-09 16:57:08,821 [run_pretraining.py:  535]:	loss/mlm_loss, 6.222715854644775, 426
[INFO] 2021-07-09 16:57:08,821 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.25000007453491e-06, 426
[INFO] 2021-07-09 16:57:08,821 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 426
[INFO] 2021-07-09 16:57:08,822 [run_pretraining.py:  558]:	worker_index: 7, step: 426, cost: 6.222716, mlm loss: 6.222716, speed: 0.441391 steps/s, speed: 3.531127 samples/s, speed: 1807.937219 tokens/s, learning rate: 4.250e-06, loss_scalings: 377.789520, pp_loss: 6.294843
[INFO] 2021-07-09 16:57:08,822 [run_pretraining.py:  512]:	********exe.run_426******* 
[INFO] 2021-07-09 16:57:11,205 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:11,205 [run_pretraining.py:  534]:	loss/total_loss, 6.057508945465088, 427
[INFO] 2021-07-09 16:57:11,205 [run_pretraining.py:  535]:	loss/mlm_loss, 6.057508945465088, 427
[INFO] 2021-07-09 16:57:11,205 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.259999514033552e-06, 427
[INFO] 2021-07-09 16:57:11,205 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 427
[INFO] 2021-07-09 16:57:11,205 [run_pretraining.py:  558]:	worker_index: 7, step: 427, cost: 6.057509, mlm loss: 6.057509, speed: 0.419605 steps/s, speed: 3.356844 samples/s, speed: 1718.703962 tokens/s, learning rate: 4.260e-06, loss_scalings: 377.789520, pp_loss: 6.067969
[INFO] 2021-07-09 16:57:11,205 [run_pretraining.py:  512]:	********exe.run_427******* 
[INFO] 2021-07-09 16:57:13,485 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:13,485 [run_pretraining.py:  534]:	loss/total_loss, 5.703858852386475, 428
[INFO] 2021-07-09 16:57:13,486 [run_pretraining.py:  535]:	loss/mlm_loss, 5.703858852386475, 428
[INFO] 2021-07-09 16:57:13,486 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.2699998630268965e-06, 428
[INFO] 2021-07-09 16:57:13,486 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 428
[INFO] 2021-07-09 16:57:13,486 [run_pretraining.py:  558]:	worker_index: 7, step: 428, cost: 5.703859, mlm loss: 5.703859, speed: 0.438650 steps/s, speed: 3.509198 samples/s, speed: 1796.709568 tokens/s, learning rate: 4.270e-06, loss_scalings: 377.789520, pp_loss: 5.742560
[INFO] 2021-07-09 16:57:13,486 [run_pretraining.py:  512]:	********exe.run_428******* 
[INFO] 2021-07-09 16:57:15,730 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:15,731 [run_pretraining.py:  534]:	loss/total_loss, 5.15169620513916, 429
[INFO] 2021-07-09 16:57:15,731 [run_pretraining.py:  535]:	loss/mlm_loss, 5.15169620513916, 429
[INFO] 2021-07-09 16:57:15,731 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.280000212020241e-06, 429
[INFO] 2021-07-09 16:57:15,731 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 429
[INFO] 2021-07-09 16:57:15,731 [run_pretraining.py:  558]:	worker_index: 7, step: 429, cost: 5.151696, mlm loss: 5.151696, speed: 0.445533 steps/s, speed: 3.564266 samples/s, speed: 1824.904418 tokens/s, learning rate: 4.280e-06, loss_scalings: 377.789520, pp_loss: 5.287111
[INFO] 2021-07-09 16:57:15,731 [run_pretraining.py:  512]:	********exe.run_429******* 
[INFO] 2021-07-09 16:57:17,957 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:17,957 [run_pretraining.py:  534]:	loss/total_loss, 5.0551605224609375, 430
[INFO] 2021-07-09 16:57:17,957 [run_pretraining.py:  535]:	loss/mlm_loss, 5.0551605224609375, 430
[INFO] 2021-07-09 16:57:17,957 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.289999651518883e-06, 430
[INFO] 2021-07-09 16:57:17,957 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 430
[INFO] 2021-07-09 16:57:17,957 [run_pretraining.py:  558]:	worker_index: 7, step: 430, cost: 5.055161, mlm loss: 5.055161, speed: 0.449276 steps/s, speed: 3.594208 samples/s, speed: 1840.234625 tokens/s, learning rate: 4.290e-06, loss_scalings: 377.789520, pp_loss: 5.114785
[INFO] 2021-07-09 16:57:17,957 [run_pretraining.py:  512]:	********exe.run_430******* 
[INFO] 2021-07-09 16:57:20,186 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:20,187 [run_pretraining.py:  534]:	loss/total_loss, 5.158943176269531, 431
[INFO] 2021-07-09 16:57:20,187 [run_pretraining.py:  535]:	loss/mlm_loss, 5.158943176269531, 431
[INFO] 2021-07-09 16:57:20,187 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.300000000512227e-06, 431
[INFO] 2021-07-09 16:57:20,187 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 431
[INFO] 2021-07-09 16:57:20,187 [run_pretraining.py:  558]:	worker_index: 7, step: 431, cost: 5.158943, mlm loss: 5.158943, speed: 0.448637 steps/s, speed: 3.589093 samples/s, speed: 1837.615701 tokens/s, learning rate: 4.300e-06, loss_scalings: 377.789520, pp_loss: 5.243524
[INFO] 2021-07-09 16:57:20,187 [run_pretraining.py:  512]:	********exe.run_431******* 
[INFO] 2021-07-09 16:57:22,446 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:22,447 [run_pretraining.py:  534]:	loss/total_loss, 5.63347053527832, 432
[INFO] 2021-07-09 16:57:22,447 [run_pretraining.py:  535]:	loss/mlm_loss, 5.63347053527832, 432
[INFO] 2021-07-09 16:57:22,447 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.309999894758221e-06, 432
[INFO] 2021-07-09 16:57:22,447 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 432
[INFO] 2021-07-09 16:57:22,447 [run_pretraining.py:  558]:	worker_index: 7, step: 432, cost: 5.633471, mlm loss: 5.633471, speed: 0.442564 steps/s, speed: 3.540510 samples/s, speed: 1812.741069 tokens/s, learning rate: 4.310e-06, loss_scalings: 377.789520, pp_loss: 5.627200
[INFO] 2021-07-09 16:57:22,447 [run_pretraining.py:  512]:	********exe.run_432******* 
[INFO] 2021-07-09 16:57:24,871 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:24,871 [run_pretraining.py:  534]:	loss/total_loss, 6.011603832244873, 433
[INFO] 2021-07-09 16:57:24,871 [run_pretraining.py:  535]:	loss/mlm_loss, 6.011603832244873, 433
[INFO] 2021-07-09 16:57:24,871 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.319999789004214e-06, 433
[INFO] 2021-07-09 16:57:24,871 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 433
[INFO] 2021-07-09 16:57:24,872 [run_pretraining.py:  558]:	worker_index: 7, step: 433, cost: 6.011604, mlm loss: 6.011604, speed: 0.412584 steps/s, speed: 3.300672 samples/s, speed: 1689.943822 tokens/s, learning rate: 4.320e-06, loss_scalings: 377.789520, pp_loss: 5.809028
[INFO] 2021-07-09 16:57:24,872 [run_pretraining.py:  512]:	********exe.run_433******* 
[INFO] 2021-07-09 16:57:27,217 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:27,218 [run_pretraining.py:  534]:	loss/total_loss, 5.50153923034668, 434
[INFO] 2021-07-09 16:57:27,218 [run_pretraining.py:  535]:	loss/mlm_loss, 5.50153923034668, 434
[INFO] 2021-07-09 16:57:27,218 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.3299996832502075e-06, 434
[INFO] 2021-07-09 16:57:27,218 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 434
[INFO] 2021-07-09 16:57:27,218 [run_pretraining.py:  558]:	worker_index: 7, step: 434, cost: 5.501539, mlm loss: 5.501539, speed: 0.426254 steps/s, speed: 3.410029 samples/s, speed: 1745.934795 tokens/s, learning rate: 4.330e-06, loss_scalings: 377.789520, pp_loss: 5.510880
[INFO] 2021-07-09 16:57:27,218 [run_pretraining.py:  512]:	********exe.run_434******* 
[INFO] 2021-07-09 16:57:29,593 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:29,594 [run_pretraining.py:  534]:	loss/total_loss, 5.223028659820557, 435
[INFO] 2021-07-09 16:57:29,594 [run_pretraining.py:  535]:	loss/mlm_loss, 5.223028659820557, 435
[INFO] 2021-07-09 16:57:29,594 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.340000032243552e-06, 435
[INFO] 2021-07-09 16:57:29,594 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 435
[INFO] 2021-07-09 16:57:29,594 [run_pretraining.py:  558]:	worker_index: 7, step: 435, cost: 5.223029, mlm loss: 5.223029, speed: 0.421048 steps/s, speed: 3.368385 samples/s, speed: 1724.612881 tokens/s, learning rate: 4.340e-06, loss_scalings: 377.789520, pp_loss: 5.329347
[INFO] 2021-07-09 16:57:29,594 [run_pretraining.py:  512]:	********exe.run_435******* 
[INFO] 2021-07-09 16:57:32,066 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:32,066 [run_pretraining.py:  534]:	loss/total_loss, 5.439452171325684, 436
[INFO] 2021-07-09 16:57:32,066 [run_pretraining.py:  535]:	loss/mlm_loss, 5.439452171325684, 436
[INFO] 2021-07-09 16:57:32,067 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.349999926489545e-06, 436
[INFO] 2021-07-09 16:57:32,067 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 436
[INFO] 2021-07-09 16:57:32,067 [run_pretraining.py:  558]:	worker_index: 7, step: 436, cost: 5.439452, mlm loss: 5.439452, speed: 0.404532 steps/s, speed: 3.236254 samples/s, speed: 1656.962002 tokens/s, learning rate: 4.350e-06, loss_scalings: 377.789520, pp_loss: 5.376405
[INFO] 2021-07-09 16:57:32,067 [run_pretraining.py:  512]:	********exe.run_436******* 
[INFO] 2021-07-09 16:57:34,456 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:34,456 [run_pretraining.py:  534]:	loss/total_loss, 5.250372886657715, 437
[INFO] 2021-07-09 16:57:34,456 [run_pretraining.py:  535]:	loss/mlm_loss, 5.250372886657715, 437
[INFO] 2021-07-09 16:57:34,457 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.359999820735538e-06, 437
[INFO] 2021-07-09 16:57:34,457 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 437
[INFO] 2021-07-09 16:57:34,457 [run_pretraining.py:  558]:	worker_index: 7, step: 437, cost: 5.250373, mlm loss: 5.250373, speed: 0.418518 steps/s, speed: 3.348143 samples/s, speed: 1714.248998 tokens/s, learning rate: 4.360e-06, loss_scalings: 377.789520, pp_loss: 5.264780
[INFO] 2021-07-09 16:57:34,457 [run_pretraining.py:  512]:	********exe.run_437******* 
[INFO] 2021-07-09 16:57:36,859 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:36,860 [run_pretraining.py:  534]:	loss/total_loss, 5.180419921875, 438
[INFO] 2021-07-09 16:57:36,860 [run_pretraining.py:  535]:	loss/mlm_loss, 5.180419921875, 438
[INFO] 2021-07-09 16:57:36,860 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.369999714981532e-06, 438
[INFO] 2021-07-09 16:57:36,860 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 438
[INFO] 2021-07-09 16:57:36,860 [run_pretraining.py:  558]:	worker_index: 7, step: 438, cost: 5.180420, mlm loss: 5.180420, speed: 0.416183 steps/s, speed: 3.329461 samples/s, speed: 1704.684075 tokens/s, learning rate: 4.370e-06, loss_scalings: 377.789520, pp_loss: 5.250880
[INFO] 2021-07-09 16:57:36,860 [run_pretraining.py:  512]:	********exe.run_438******* 
[INFO] 2021-07-09 16:57:39,331 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:39,331 [run_pretraining.py:  534]:	loss/total_loss, 5.215646266937256, 439
[INFO] 2021-07-09 16:57:39,331 [run_pretraining.py:  535]:	loss/mlm_loss, 5.215646266937256, 439
[INFO] 2021-07-09 16:57:39,331 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.380000063974876e-06, 439
[INFO] 2021-07-09 16:57:39,332 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 439
[INFO] 2021-07-09 16:57:39,332 [run_pretraining.py:  558]:	worker_index: 7, step: 439, cost: 5.215646, mlm loss: 5.215646, speed: 0.404728 steps/s, speed: 3.237825 samples/s, speed: 1657.766559 tokens/s, learning rate: 4.380e-06, loss_scalings: 377.789520, pp_loss: 5.192032
[INFO] 2021-07-09 16:57:39,332 [run_pretraining.py:  512]:	********exe.run_439******* 
[INFO] 2021-07-09 16:57:41,991 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:41,992 [run_pretraining.py:  534]:	loss/total_loss, 5.418461322784424, 440
[INFO] 2021-07-09 16:57:41,992 [run_pretraining.py:  535]:	loss/mlm_loss, 5.418461322784424, 440
[INFO] 2021-07-09 16:57:41,992 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.389999958220869e-06, 440
[INFO] 2021-07-09 16:57:41,992 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 440
[INFO] 2021-07-09 16:57:41,992 [run_pretraining.py:  558]:	worker_index: 7, step: 440, cost: 5.418461, mlm loss: 5.418461, speed: 0.375964 steps/s, speed: 3.007709 samples/s, speed: 1539.947160 tokens/s, learning rate: 4.390e-06, loss_scalings: 377.789520, pp_loss: 5.488992
[INFO] 2021-07-09 16:57:41,992 [run_pretraining.py:  512]:	********exe.run_440******* 
[INFO] 2021-07-09 16:57:44,229 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:44,230 [run_pretraining.py:  534]:	loss/total_loss, 5.469307899475098, 441
[INFO] 2021-07-09 16:57:44,230 [run_pretraining.py:  535]:	loss/mlm_loss, 5.469307899475098, 441
[INFO] 2021-07-09 16:57:44,230 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.399999852466863e-06, 441
[INFO] 2021-07-09 16:57:44,230 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 441
[INFO] 2021-07-09 16:57:44,230 [run_pretraining.py:  558]:	worker_index: 7, step: 441, cost: 5.469308, mlm loss: 5.469308, speed: 0.446951 steps/s, speed: 3.575611 samples/s, speed: 1830.712686 tokens/s, learning rate: 4.400e-06, loss_scalings: 377.789520, pp_loss: 5.338844
[INFO] 2021-07-09 16:57:44,230 [run_pretraining.py:  512]:	********exe.run_441******* 
[INFO] 2021-07-09 16:57:46,500 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:46,501 [run_pretraining.py:  534]:	loss/total_loss, 5.6049485206604, 442
[INFO] 2021-07-09 16:57:46,501 [run_pretraining.py:  535]:	loss/mlm_loss, 5.6049485206604, 442
[INFO] 2021-07-09 16:57:46,501 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.410000201460207e-06, 442
[INFO] 2021-07-09 16:57:46,501 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 442
[INFO] 2021-07-09 16:57:46,501 [run_pretraining.py:  558]:	worker_index: 7, step: 442, cost: 5.604949, mlm loss: 5.604949, speed: 0.440453 steps/s, speed: 3.523621 samples/s, speed: 1804.093789 tokens/s, learning rate: 4.410e-06, loss_scalings: 377.789520, pp_loss: 5.630589
[INFO] 2021-07-09 16:57:46,501 [run_pretraining.py:  512]:	********exe.run_442******* 
[INFO] 2021-07-09 16:57:48,774 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:48,775 [run_pretraining.py:  534]:	loss/total_loss, 5.956153869628906, 443
[INFO] 2021-07-09 16:57:48,775 [run_pretraining.py:  535]:	loss/mlm_loss, 5.956153869628906, 443
[INFO] 2021-07-09 16:57:48,775 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.419999640958849e-06, 443
[INFO] 2021-07-09 16:57:48,775 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 443
[INFO] 2021-07-09 16:57:48,775 [run_pretraining.py:  558]:	worker_index: 7, step: 443, cost: 5.956154, mlm loss: 5.956154, speed: 0.439895 steps/s, speed: 3.519163 samples/s, speed: 1801.811514 tokens/s, learning rate: 4.420e-06, loss_scalings: 377.789520, pp_loss: 6.100738
[INFO] 2021-07-09 16:57:48,775 [run_pretraining.py:  512]:	********exe.run_443******* 
[INFO] 2021-07-09 16:57:51,026 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:51,026 [run_pretraining.py:  534]:	loss/total_loss, 6.850635528564453, 444
[INFO] 2021-07-09 16:57:51,026 [run_pretraining.py:  535]:	loss/mlm_loss, 6.850635528564453, 444
[INFO] 2021-07-09 16:57:51,026 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.4299999899521936e-06, 444
[INFO] 2021-07-09 16:57:51,026 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 444
[INFO] 2021-07-09 16:57:51,027 [run_pretraining.py:  558]:	worker_index: 7, step: 444, cost: 6.850636, mlm loss: 6.850636, speed: 0.444285 steps/s, speed: 3.554284 samples/s, speed: 1819.793250 tokens/s, learning rate: 4.430e-06, loss_scalings: 377.789520, pp_loss: 6.954207
[INFO] 2021-07-09 16:57:51,027 [run_pretraining.py:  512]:	********exe.run_444******* 
[INFO] 2021-07-09 16:57:53,351 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:53,351 [run_pretraining.py:  534]:	loss/total_loss, 7.682541847229004, 445
[INFO] 2021-07-09 16:57:53,351 [run_pretraining.py:  535]:	loss/mlm_loss, 7.682541847229004, 445
[INFO] 2021-07-09 16:57:53,351 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.439999884198187e-06, 445
[INFO] 2021-07-09 16:57:53,352 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 445
[INFO] 2021-07-09 16:57:53,352 [run_pretraining.py:  558]:	worker_index: 7, step: 445, cost: 7.682542, mlm loss: 7.682542, speed: 0.430242 steps/s, speed: 3.441938 samples/s, speed: 1762.272473 tokens/s, learning rate: 4.440e-06, loss_scalings: 377.789520, pp_loss: 7.723554
[INFO] 2021-07-09 16:57:53,352 [run_pretraining.py:  512]:	********exe.run_445******* 
[INFO] 2021-07-09 16:57:55,662 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:55,663 [run_pretraining.py:  534]:	loss/total_loss, 7.806678295135498, 446
[INFO] 2021-07-09 16:57:55,663 [run_pretraining.py:  535]:	loss/mlm_loss, 7.806678295135498, 446
[INFO] 2021-07-09 16:57:55,663 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.44999977844418e-06, 446
[INFO] 2021-07-09 16:57:55,663 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 446
[INFO] 2021-07-09 16:57:55,663 [run_pretraining.py:  558]:	worker_index: 7, step: 446, cost: 7.806678, mlm loss: 7.806678, speed: 0.432707 steps/s, speed: 3.461658 samples/s, speed: 1772.368867 tokens/s, learning rate: 4.450e-06, loss_scalings: 377.789520, pp_loss: 7.968378
[INFO] 2021-07-09 16:57:55,663 [run_pretraining.py:  512]:	********exe.run_446******* 
[INFO] 2021-07-09 16:57:57,911 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:57,911 [run_pretraining.py:  534]:	loss/total_loss, 7.743579864501953, 447
[INFO] 2021-07-09 16:57:57,911 [run_pretraining.py:  535]:	loss/mlm_loss, 7.743579864501953, 447
[INFO] 2021-07-09 16:57:57,911 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.459999672690174e-06, 447
[INFO] 2021-07-09 16:57:57,911 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 447
[INFO] 2021-07-09 16:57:57,911 [run_pretraining.py:  558]:	worker_index: 7, step: 447, cost: 7.743580, mlm loss: 7.743580, speed: 0.444937 steps/s, speed: 3.559494 samples/s, speed: 1822.461144 tokens/s, learning rate: 4.460e-06, loss_scalings: 377.789520, pp_loss: 7.844627
[INFO] 2021-07-09 16:57:57,911 [run_pretraining.py:  512]:	********exe.run_447******* 
[INFO] 2021-07-09 16:58:00,165 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:00,166 [run_pretraining.py:  534]:	loss/total_loss, 8.099929809570312, 448
[INFO] 2021-07-09 16:58:00,166 [run_pretraining.py:  535]:	loss/mlm_loss, 8.099929809570312, 448
[INFO] 2021-07-09 16:58:00,166 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.470000021683518e-06, 448
[INFO] 2021-07-09 16:58:00,166 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 448
[INFO] 2021-07-09 16:58:00,166 [run_pretraining.py:  558]:	worker_index: 7, step: 448, cost: 8.099930, mlm loss: 8.099930, speed: 0.443679 steps/s, speed: 3.549431 samples/s, speed: 1817.308459 tokens/s, learning rate: 4.470e-06, loss_scalings: 377.789520, pp_loss: 7.937416
[INFO] 2021-07-09 16:58:00,166 [run_pretraining.py:  512]:	********exe.run_448******* 
[INFO] 2021-07-09 16:58:02,400 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:02,400 [run_pretraining.py:  534]:	loss/total_loss, 7.082493305206299, 449
[INFO] 2021-07-09 16:58:02,400 [run_pretraining.py:  535]:	loss/mlm_loss, 7.082493305206299, 449
[INFO] 2021-07-09 16:58:02,401 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.479999915929511e-06, 449
[INFO] 2021-07-09 16:58:02,401 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 449
[INFO] 2021-07-09 16:58:02,401 [run_pretraining.py:  558]:	worker_index: 7, step: 449, cost: 7.082493, mlm loss: 7.082493, speed: 0.447626 steps/s, speed: 3.581005 samples/s, speed: 1833.474351 tokens/s, learning rate: 4.480e-06, loss_scalings: 377.789520, pp_loss: 7.065210
[INFO] 2021-07-09 16:58:02,401 [run_pretraining.py:  512]:	********exe.run_449******* 
[INFO] 2021-07-09 16:58:04,702 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:04,703 [run_pretraining.py:  534]:	loss/total_loss, 6.408352851867676, 450
[INFO] 2021-07-09 16:58:04,703 [run_pretraining.py:  535]:	loss/mlm_loss, 6.408352851867676, 450
[INFO] 2021-07-09 16:58:04,703 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.4899998101755045e-06, 450
[INFO] 2021-07-09 16:58:04,703 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 450
[INFO] 2021-07-09 16:58:04,703 [run_pretraining.py:  558]:	worker_index: 7, step: 450, cost: 6.408353, mlm loss: 6.408353, speed: 0.434395 steps/s, speed: 3.475159 samples/s, speed: 1779.281383 tokens/s, learning rate: 4.490e-06, loss_scalings: 377.789520, pp_loss: 6.503889
[INFO] 2021-07-09 16:58:04,704 [run_pretraining.py:  512]:	********exe.run_450******* 
[INFO] 2021-07-09 16:58:06,956 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:06,956 [run_pretraining.py:  534]:	loss/total_loss, 6.314598560333252, 451
[INFO] 2021-07-09 16:58:06,956 [run_pretraining.py:  535]:	loss/mlm_loss, 6.314598560333252, 451
[INFO] 2021-07-09 16:58:06,957 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.500000159168849e-06, 451
[INFO] 2021-07-09 16:58:06,957 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 451
[INFO] 2021-07-09 16:58:06,957 [run_pretraining.py:  558]:	worker_index: 7, step: 451, cost: 6.314599, mlm loss: 6.314599, speed: 0.443918 steps/s, speed: 3.551344 samples/s, speed: 1818.288051 tokens/s, learning rate: 4.500e-06, loss_scalings: 377.789520, pp_loss: 6.064883
[INFO] 2021-07-09 16:58:06,957 [run_pretraining.py:  512]:	********exe.run_451******* 
[INFO] 2021-07-09 16:58:09,227 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:09,227 [run_pretraining.py:  534]:	loss/total_loss, 5.436931610107422, 452
[INFO] 2021-07-09 16:58:09,228 [run_pretraining.py:  535]:	loss/mlm_loss, 5.436931610107422, 452
[INFO] 2021-07-09 16:58:09,228 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.510000053414842e-06, 452
[INFO] 2021-07-09 16:58:09,228 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 452
[INFO] 2021-07-09 16:58:09,228 [run_pretraining.py:  558]:	worker_index: 7, step: 452, cost: 5.436932, mlm loss: 5.436932, speed: 0.440441 steps/s, speed: 3.523524 samples/s, speed: 1804.044344 tokens/s, learning rate: 4.510e-06, loss_scalings: 377.789520, pp_loss: 5.616420
[INFO] 2021-07-09 16:58:09,228 [run_pretraining.py:  512]:	********exe.run_452******* 
[INFO] 2021-07-09 16:58:11,449 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:11,450 [run_pretraining.py:  534]:	loss/total_loss, 5.368537902832031, 453
[INFO] 2021-07-09 16:58:11,450 [run_pretraining.py:  535]:	loss/mlm_loss, 5.368537902832031, 453
[INFO] 2021-07-09 16:58:11,450 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.5199999476608355e-06, 453
[INFO] 2021-07-09 16:58:11,450 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 453
[INFO] 2021-07-09 16:58:11,450 [run_pretraining.py:  558]:	worker_index: 7, step: 453, cost: 5.368538, mlm loss: 5.368538, speed: 0.450091 steps/s, speed: 3.600727 samples/s, speed: 1843.572358 tokens/s, learning rate: 4.520e-06, loss_scalings: 377.789520, pp_loss: 5.371056
[INFO] 2021-07-09 16:58:11,450 [run_pretraining.py:  512]:	********exe.run_453******* 
[INFO] 2021-07-09 16:58:13,703 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:13,704 [run_pretraining.py:  534]:	loss/total_loss, 5.272212028503418, 454
[INFO] 2021-07-09 16:58:13,704 [run_pretraining.py:  535]:	loss/mlm_loss, 5.272212028503418, 454
[INFO] 2021-07-09 16:58:13,704 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.529999841906829e-06, 454
[INFO] 2021-07-09 16:58:13,704 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 454
[INFO] 2021-07-09 16:58:13,704 [run_pretraining.py:  558]:	worker_index: 7, step: 454, cost: 5.272212, mlm loss: 5.272212, speed: 0.443854 steps/s, speed: 3.550835 samples/s, speed: 1818.027711 tokens/s, learning rate: 4.530e-06, loss_scalings: 377.789520, pp_loss: 5.359327
[INFO] 2021-07-09 16:58:13,704 [run_pretraining.py:  512]:	********exe.run_454******* 
[INFO] 2021-07-09 16:58:15,928 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:15,929 [run_pretraining.py:  534]:	loss/total_loss, 5.232049465179443, 455
[INFO] 2021-07-09 16:58:15,929 [run_pretraining.py:  535]:	loss/mlm_loss, 5.232049465179443, 455
[INFO] 2021-07-09 16:58:15,929 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.540000190900173e-06, 455
[INFO] 2021-07-09 16:58:15,929 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 455
[INFO] 2021-07-09 16:58:15,929 [run_pretraining.py:  558]:	worker_index: 7, step: 455, cost: 5.232049, mlm loss: 5.232049, speed: 0.449513 steps/s, speed: 3.596105 samples/s, speed: 1841.205746 tokens/s, learning rate: 4.540e-06, loss_scalings: 377.789520, pp_loss: 5.039092
[INFO] 2021-07-09 16:58:15,929 [run_pretraining.py:  512]:	********exe.run_455******* 
[INFO] 2021-07-09 16:58:18,177 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:18,178 [run_pretraining.py:  534]:	loss/total_loss, 4.918184757232666, 456
[INFO] 2021-07-09 16:58:18,178 [run_pretraining.py:  535]:	loss/mlm_loss, 4.918184757232666, 456
[INFO] 2021-07-09 16:58:18,178 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.5499996303988155e-06, 456
[INFO] 2021-07-09 16:58:18,178 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 456
[INFO] 2021-07-09 16:58:18,178 [run_pretraining.py:  558]:	worker_index: 7, step: 456, cost: 4.918185, mlm loss: 4.918185, speed: 0.444766 steps/s, speed: 3.558127 samples/s, speed: 1821.761175 tokens/s, learning rate: 4.550e-06, loss_scalings: 377.789520, pp_loss: 4.840078
[INFO] 2021-07-09 16:58:18,178 [run_pretraining.py:  512]:	********exe.run_456******* 
[INFO] 2021-07-09 16:58:20,412 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:20,412 [run_pretraining.py:  534]:	loss/total_loss, 4.974920749664307, 457
[INFO] 2021-07-09 16:58:20,413 [run_pretraining.py:  535]:	loss/mlm_loss, 4.974920749664307, 457
[INFO] 2021-07-09 16:58:20,413 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.55999997939216e-06, 457
[INFO] 2021-07-09 16:58:20,413 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 457
[INFO] 2021-07-09 16:58:20,413 [run_pretraining.py:  558]:	worker_index: 7, step: 457, cost: 4.974921, mlm loss: 4.974921, speed: 0.447634 steps/s, speed: 3.581072 samples/s, speed: 1833.508986 tokens/s, learning rate: 4.560e-06, loss_scalings: 377.789520, pp_loss: 5.041556
[INFO] 2021-07-09 16:58:20,413 [run_pretraining.py:  512]:	********exe.run_457******* 
[INFO] 2021-07-09 16:58:22,663 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:22,663 [run_pretraining.py:  534]:	loss/total_loss, 5.494946002960205, 458
[INFO] 2021-07-09 16:58:22,663 [run_pretraining.py:  535]:	loss/mlm_loss, 5.494946002960205, 458
[INFO] 2021-07-09 16:58:22,663 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.569999873638153e-06, 458
[INFO] 2021-07-09 16:58:22,663 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 458
[INFO] 2021-07-09 16:58:22,663 [run_pretraining.py:  558]:	worker_index: 7, step: 458, cost: 5.494946, mlm loss: 5.494946, speed: 0.444467 steps/s, speed: 3.555733 samples/s, speed: 1820.535305 tokens/s, learning rate: 4.570e-06, loss_scalings: 377.789520, pp_loss: 5.455032
[INFO] 2021-07-09 16:58:22,663 [run_pretraining.py:  512]:	********exe.run_458******* 
[INFO] 2021-07-09 16:58:24,933 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:24,934 [run_pretraining.py:  534]:	loss/total_loss, 6.14194393157959, 459
[INFO] 2021-07-09 16:58:24,934 [run_pretraining.py:  535]:	loss/mlm_loss, 6.14194393157959, 459
[INFO] 2021-07-09 16:58:24,934 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.579999767884146e-06, 459
[INFO] 2021-07-09 16:58:24,934 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 459
[INFO] 2021-07-09 16:58:24,934 [run_pretraining.py:  558]:	worker_index: 7, step: 459, cost: 6.141944, mlm loss: 6.141944, speed: 0.440480 steps/s, speed: 3.523841 samples/s, speed: 1804.206709 tokens/s, learning rate: 4.580e-06, loss_scalings: 377.789520, pp_loss: 6.139437
[INFO] 2021-07-09 16:58:24,934 [run_pretraining.py:  512]:	********exe.run_459******* 
[INFO] 2021-07-09 16:58:27,178 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:27,179 [run_pretraining.py:  534]:	loss/total_loss, 6.89563512802124, 460
[INFO] 2021-07-09 16:58:27,179 [run_pretraining.py:  535]:	loss/mlm_loss, 6.89563512802124, 460
[INFO] 2021-07-09 16:58:27,179 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.58999966213014e-06, 460
[INFO] 2021-07-09 16:58:27,179 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 460
[INFO] 2021-07-09 16:58:27,179 [run_pretraining.py:  558]:	worker_index: 7, step: 460, cost: 6.895635, mlm loss: 6.895635, speed: 0.445586 steps/s, speed: 3.564686 samples/s, speed: 1825.119227 tokens/s, learning rate: 4.590e-06, loss_scalings: 377.789520, pp_loss: 6.928115
[INFO] 2021-07-09 16:58:27,179 [run_pretraining.py:  512]:	********exe.run_460******* 
[INFO] 2021-07-09 16:58:29,418 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:29,418 [run_pretraining.py:  534]:	loss/total_loss, 7.854365348815918, 461
[INFO] 2021-07-09 16:58:29,418 [run_pretraining.py:  535]:	loss/mlm_loss, 7.854365348815918, 461
[INFO] 2021-07-09 16:58:29,419 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.600000011123484e-06, 461
[INFO] 2021-07-09 16:58:29,419 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 461
[INFO] 2021-07-09 16:58:29,419 [run_pretraining.py:  558]:	worker_index: 7, step: 461, cost: 7.854365, mlm loss: 7.854365, speed: 0.446655 steps/s, speed: 3.573241 samples/s, speed: 1829.499291 tokens/s, learning rate: 4.600e-06, loss_scalings: 377.789520, pp_loss: 7.882717
[INFO] 2021-07-09 16:58:29,419 [run_pretraining.py:  512]:	********exe.run_461******* 
[INFO] 2021-07-09 16:58:31,633 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:31,634 [run_pretraining.py:  534]:	loss/total_loss, 8.525184631347656, 462
[INFO] 2021-07-09 16:58:31,634 [run_pretraining.py:  535]:	loss/mlm_loss, 8.525184631347656, 462
[INFO] 2021-07-09 16:58:31,634 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.609999905369477e-06, 462
[INFO] 2021-07-09 16:58:31,634 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 462
[INFO] 2021-07-09 16:58:31,634 [run_pretraining.py:  558]:	worker_index: 7, step: 462, cost: 8.525185, mlm loss: 8.525185, speed: 0.451542 steps/s, speed: 3.612336 samples/s, speed: 1849.515988 tokens/s, learning rate: 4.610e-06, loss_scalings: 377.789520, pp_loss: 8.489748
[INFO] 2021-07-09 16:58:31,634 [run_pretraining.py:  512]:	********exe.run_462******* 
[INFO] 2021-07-09 16:58:33,845 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:33,845 [run_pretraining.py:  534]:	loss/total_loss, 8.892472267150879, 463
[INFO] 2021-07-09 16:58:33,845 [run_pretraining.py:  535]:	loss/mlm_loss, 8.892472267150879, 463
[INFO] 2021-07-09 16:58:33,845 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.619999799615471e-06, 463
[INFO] 2021-07-09 16:58:33,845 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 463
[INFO] 2021-07-09 16:58:33,846 [run_pretraining.py:  558]:	worker_index: 7, step: 463, cost: 8.892472, mlm loss: 8.892472, speed: 0.452308 steps/s, speed: 3.618462 samples/s, speed: 1852.652325 tokens/s, learning rate: 4.620e-06, loss_scalings: 377.789520, pp_loss: 8.893922
[INFO] 2021-07-09 16:58:33,846 [run_pretraining.py:  512]:	********exe.run_463******* 
[INFO] 2021-07-09 16:58:36,081 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:36,082 [run_pretraining.py:  534]:	loss/total_loss, 9.019784927368164, 464
[INFO] 2021-07-09 16:58:36,082 [run_pretraining.py:  535]:	loss/mlm_loss, 9.019784927368164, 464
[INFO] 2021-07-09 16:58:36,082 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.630000148608815e-06, 464
[INFO] 2021-07-09 16:58:36,082 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 464
[INFO] 2021-07-09 16:58:36,082 [run_pretraining.py:  558]:	worker_index: 7, step: 464, cost: 9.019785, mlm loss: 9.019785, speed: 0.447203 steps/s, speed: 3.577621 samples/s, speed: 1831.741940 tokens/s, learning rate: 4.630e-06, loss_scalings: 377.789520, pp_loss: 9.044649
[INFO] 2021-07-09 16:58:36,082 [run_pretraining.py:  512]:	********exe.run_464******* 
[INFO] 2021-07-09 16:58:38,311 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:38,312 [run_pretraining.py:  534]:	loss/total_loss, 8.847457885742188, 465
[INFO] 2021-07-09 16:58:38,312 [run_pretraining.py:  535]:	loss/mlm_loss, 8.847457885742188, 465
[INFO] 2021-07-09 16:58:38,312 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.640000042854808e-06, 465
[INFO] 2021-07-09 16:58:38,312 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 465
[INFO] 2021-07-09 16:58:38,312 [run_pretraining.py:  558]:	worker_index: 7, step: 465, cost: 8.847458, mlm loss: 8.847458, speed: 0.448646 steps/s, speed: 3.589172 samples/s, speed: 1837.655996 tokens/s, learning rate: 4.640e-06, loss_scalings: 377.789520, pp_loss: 8.863567
[INFO] 2021-07-09 16:58:38,312 [run_pretraining.py:  512]:	********exe.run_465******* 
[INFO] 2021-07-09 16:58:40,559 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:40,559 [run_pretraining.py:  534]:	loss/total_loss, 8.209748268127441, 466
[INFO] 2021-07-09 16:58:40,560 [run_pretraining.py:  535]:	loss/mlm_loss, 8.209748268127441, 466
[INFO] 2021-07-09 16:58:40,560 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.649999937100802e-06, 466
[INFO] 2021-07-09 16:58:40,560 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 466
[INFO] 2021-07-09 16:58:40,560 [run_pretraining.py:  558]:	worker_index: 7, step: 466, cost: 8.209748, mlm loss: 8.209748, speed: 0.445007 steps/s, speed: 3.560058 samples/s, speed: 1822.749829 tokens/s, learning rate: 4.650e-06, loss_scalings: 377.789520, pp_loss: 8.212689
[INFO] 2021-07-09 16:58:40,560 [run_pretraining.py:  512]:	********exe.run_466******* 
[INFO] 2021-07-09 16:58:42,761 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:42,761 [run_pretraining.py:  534]:	loss/total_loss, 7.68298864364624, 467
[INFO] 2021-07-09 16:58:42,761 [run_pretraining.py:  535]:	loss/mlm_loss, 7.68298864364624, 467
[INFO] 2021-07-09 16:58:42,761 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.659999831346795e-06, 467
[INFO] 2021-07-09 16:58:42,761 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 467
[INFO] 2021-07-09 16:58:42,762 [run_pretraining.py:  558]:	worker_index: 7, step: 467, cost: 7.682989, mlm loss: 7.682989, speed: 0.454316 steps/s, speed: 3.634528 samples/s, speed: 1860.878372 tokens/s, learning rate: 4.660e-06, loss_scalings: 377.789520, pp_loss: 7.570591
[INFO] 2021-07-09 16:58:42,762 [run_pretraining.py:  512]:	********exe.run_467******* 
[INFO] 2021-07-09 16:58:45,112 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:45,113 [run_pretraining.py:  534]:	loss/total_loss, 6.700065612792969, 468
[INFO] 2021-07-09 16:58:45,113 [run_pretraining.py:  535]:	loss/mlm_loss, 6.700065612792969, 468
[INFO] 2021-07-09 16:58:45,113 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.670000180340139e-06, 468
[INFO] 2021-07-09 16:58:45,113 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 468
[INFO] 2021-07-09 16:58:45,113 [run_pretraining.py:  558]:	worker_index: 7, step: 468, cost: 6.700066, mlm loss: 6.700066, speed: 0.425369 steps/s, speed: 3.402952 samples/s, speed: 1742.311327 tokens/s, learning rate: 4.670e-06, loss_scalings: 377.789520, pp_loss: 6.718630
[INFO] 2021-07-09 16:58:45,113 [run_pretraining.py:  512]:	********exe.run_468******* 
[INFO] 2021-07-09 16:58:47,314 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:47,315 [run_pretraining.py:  534]:	loss/total_loss, 6.0635480880737305, 469
[INFO] 2021-07-09 16:58:47,315 [run_pretraining.py:  535]:	loss/mlm_loss, 6.0635480880737305, 469
[INFO] 2021-07-09 16:58:47,315 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.679999619838782e-06, 469
[INFO] 2021-07-09 16:58:47,315 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 469
[INFO] 2021-07-09 16:58:47,315 [run_pretraining.py:  558]:	worker_index: 7, step: 469, cost: 6.063548, mlm loss: 6.063548, speed: 0.454252 steps/s, speed: 3.634019 samples/s, speed: 1860.617583 tokens/s, learning rate: 4.680e-06, loss_scalings: 377.789520, pp_loss: 6.083085
[INFO] 2021-07-09 16:58:47,315 [run_pretraining.py:  512]:	********exe.run_469******* 
[INFO] 2021-07-09 16:58:49,617 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:49,618 [run_pretraining.py:  534]:	loss/total_loss, 5.586373329162598, 470
[INFO] 2021-07-09 16:58:49,618 [run_pretraining.py:  535]:	loss/mlm_loss, 5.586373329162598, 470
[INFO] 2021-07-09 16:58:49,618 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.689999968832126e-06, 470
[INFO] 2021-07-09 16:58:49,618 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 470
[INFO] 2021-07-09 16:58:49,618 [run_pretraining.py:  558]:	worker_index: 7, step: 470, cost: 5.586373, mlm loss: 5.586373, speed: 0.434362 steps/s, speed: 3.474894 samples/s, speed: 1779.145950 tokens/s, learning rate: 4.690e-06, loss_scalings: 377.789520, pp_loss: 5.648416
[INFO] 2021-07-09 16:58:49,618 [run_pretraining.py:  512]:	********exe.run_470******* 
[INFO] 2021-07-09 16:58:51,956 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:51,957 [run_pretraining.py:  534]:	loss/total_loss, 5.738065242767334, 471
[INFO] 2021-07-09 16:58:51,957 [run_pretraining.py:  535]:	loss/mlm_loss, 5.738065242767334, 471
[INFO] 2021-07-09 16:58:51,957 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.699999863078119e-06, 471
[INFO] 2021-07-09 16:58:51,957 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 471
[INFO] 2021-07-09 16:58:51,957 [run_pretraining.py:  558]:	worker_index: 7, step: 471, cost: 5.738065, mlm loss: 5.738065, speed: 0.427610 steps/s, speed: 3.420878 samples/s, speed: 1751.489586 tokens/s, learning rate: 4.700e-06, loss_scalings: 377.789520, pp_loss: 5.536819
[INFO] 2021-07-09 16:58:51,957 [run_pretraining.py:  512]:	********exe.run_471******* 
[INFO] 2021-07-09 16:58:54,252 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:54,252 [run_pretraining.py:  534]:	loss/total_loss, 5.377812385559082, 472
[INFO] 2021-07-09 16:58:54,252 [run_pretraining.py:  535]:	loss/mlm_loss, 5.377812385559082, 472
[INFO] 2021-07-09 16:58:54,252 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.709999757324113e-06, 472
[INFO] 2021-07-09 16:58:54,252 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 472
[INFO] 2021-07-09 16:58:54,253 [run_pretraining.py:  558]:	worker_index: 7, step: 472, cost: 5.377812, mlm loss: 5.377812, speed: 0.435812 steps/s, speed: 3.486498 samples/s, speed: 1785.086907 tokens/s, learning rate: 4.710e-06, loss_scalings: 377.789520, pp_loss: 5.416079
[INFO] 2021-07-09 16:58:54,253 [run_pretraining.py:  512]:	********exe.run_472******* 
[INFO] 2021-07-09 16:58:56,818 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:56,818 [run_pretraining.py:  534]:	loss/total_loss, 5.772895336151123, 473
[INFO] 2021-07-09 16:58:56,818 [run_pretraining.py:  535]:	loss/mlm_loss, 5.772895336151123, 473
[INFO] 2021-07-09 16:58:56,818 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.720000106317457e-06, 473
[INFO] 2021-07-09 16:58:56,818 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 473
[INFO] 2021-07-09 16:58:56,818 [run_pretraining.py:  558]:	worker_index: 7, step: 473, cost: 5.772895, mlm loss: 5.772895, speed: 0.389839 steps/s, speed: 3.118708 samples/s, speed: 1596.778645 tokens/s, learning rate: 4.720e-06, loss_scalings: 377.789520, pp_loss: 5.716401
[INFO] 2021-07-09 16:58:56,818 [run_pretraining.py:  512]:	********exe.run_473******* 
[INFO] 2021-07-09 16:58:59,097 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:59,097 [run_pretraining.py:  534]:	loss/total_loss, 5.913725852966309, 474
[INFO] 2021-07-09 16:58:59,097 [run_pretraining.py:  535]:	loss/mlm_loss, 5.913725852966309, 474
[INFO] 2021-07-09 16:58:59,098 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.73000000056345e-06, 474
[INFO] 2021-07-09 16:58:59,098 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 474
[INFO] 2021-07-09 16:58:59,098 [run_pretraining.py:  558]:	worker_index: 7, step: 474, cost: 5.913726, mlm loss: 5.913726, speed: 0.438855 steps/s, speed: 3.510837 samples/s, speed: 1797.548387 tokens/s, learning rate: 4.730e-06, loss_scalings: 377.789520, pp_loss: 5.974191
[INFO] 2021-07-09 16:58:59,098 [run_pretraining.py:  512]:	********exe.run_474******* 
[INFO] 2021-07-09 16:59:01,443 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:01,443 [run_pretraining.py:  534]:	loss/total_loss, 6.290976524353027, 475
[INFO] 2021-07-09 16:59:01,443 [run_pretraining.py:  535]:	loss/mlm_loss, 6.290976524353027, 475
[INFO] 2021-07-09 16:59:01,443 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.7399998948094435e-06, 475
[INFO] 2021-07-09 16:59:01,443 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 475
[INFO] 2021-07-09 16:59:01,443 [run_pretraining.py:  558]:	worker_index: 7, step: 475, cost: 6.290977, mlm loss: 6.290977, speed: 0.426422 steps/s, speed: 3.411375 samples/s, speed: 1746.623865 tokens/s, learning rate: 4.740e-06, loss_scalings: 377.789520, pp_loss: 6.318545
[INFO] 2021-07-09 16:59:01,443 [run_pretraining.py:  512]:	********exe.run_475******* 
[INFO] 2021-07-09 16:59:03,913 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:03,913 [run_pretraining.py:  534]:	loss/total_loss, 6.610310077667236, 476
[INFO] 2021-07-09 16:59:03,913 [run_pretraining.py:  535]:	loss/mlm_loss, 6.610310077667236, 476
[INFO] 2021-07-09 16:59:03,913 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.749999789055437e-06, 476
[INFO] 2021-07-09 16:59:03,913 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 476
[INFO] 2021-07-09 16:59:03,914 [run_pretraining.py:  558]:	worker_index: 7, step: 476, cost: 6.610310, mlm loss: 6.610310, speed: 0.404945 steps/s, speed: 3.239560 samples/s, speed: 1658.654844 tokens/s, learning rate: 4.750e-06, loss_scalings: 377.789520, pp_loss: 6.676780
[INFO] 2021-07-09 16:59:03,914 [run_pretraining.py:  512]:	********exe.run_476******* 
[INFO] 2021-07-09 16:59:06,164 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:06,165 [run_pretraining.py:  534]:	loss/total_loss, 7.078661918640137, 477
[INFO] 2021-07-09 16:59:06,165 [run_pretraining.py:  535]:	loss/mlm_loss, 7.078661918640137, 477
[INFO] 2021-07-09 16:59:06,165 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.760000138048781e-06, 477
[INFO] 2021-07-09 16:59:06,165 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 477
[INFO] 2021-07-09 16:59:06,165 [run_pretraining.py:  558]:	worker_index: 7, step: 477, cost: 7.078662, mlm loss: 7.078662, speed: 0.444278 steps/s, speed: 3.554220 samples/s, speed: 1819.760674 tokens/s, learning rate: 4.760e-06, loss_scalings: 377.789520, pp_loss: 7.122982
[INFO] 2021-07-09 16:59:06,165 [run_pretraining.py:  512]:	********exe.run_477******* 
[INFO] 2021-07-09 16:59:08,412 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:08,412 [run_pretraining.py:  534]:	loss/total_loss, 7.472207546234131, 478
[INFO] 2021-07-09 16:59:08,412 [run_pretraining.py:  535]:	loss/mlm_loss, 7.472207546234131, 478
[INFO] 2021-07-09 16:59:08,412 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.7699995775474235e-06, 478
[INFO] 2021-07-09 16:59:08,413 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 478
[INFO] 2021-07-09 16:59:08,413 [run_pretraining.py:  558]:	worker_index: 7, step: 478, cost: 7.472208, mlm loss: 7.472208, speed: 0.445065 steps/s, speed: 3.560523 samples/s, speed: 1822.987537 tokens/s, learning rate: 4.770e-06, loss_scalings: 377.789520, pp_loss: 7.431686
[INFO] 2021-07-09 16:59:08,413 [run_pretraining.py:  512]:	********exe.run_478******* 
[INFO] 2021-07-09 16:59:10,664 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:10,665 [run_pretraining.py:  534]:	loss/total_loss, 7.482003211975098, 479
[INFO] 2021-07-09 16:59:10,665 [run_pretraining.py:  535]:	loss/mlm_loss, 7.482003211975098, 479
[INFO] 2021-07-09 16:59:10,665 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.779999926540768e-06, 479
[INFO] 2021-07-09 16:59:10,665 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 479
[INFO] 2021-07-09 16:59:10,665 [run_pretraining.py:  558]:	worker_index: 7, step: 479, cost: 7.482003, mlm loss: 7.482003, speed: 0.444061 steps/s, speed: 3.552486 samples/s, speed: 1818.872693 tokens/s, learning rate: 4.780e-06, loss_scalings: 377.789520, pp_loss: 7.528877
[INFO] 2021-07-09 16:59:10,665 [run_pretraining.py:  512]:	********exe.run_479******* 
[INFO] 2021-07-09 16:59:12,940 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:12,940 [run_pretraining.py:  534]:	loss/total_loss, 7.822453022003174, 480
[INFO] 2021-07-09 16:59:12,941 [run_pretraining.py:  535]:	loss/mlm_loss, 7.822453022003174, 480
[INFO] 2021-07-09 16:59:12,941 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.789999820786761e-06, 480
[INFO] 2021-07-09 16:59:12,941 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 480
[INFO] 2021-07-09 16:59:12,941 [run_pretraining.py:  558]:	worker_index: 7, step: 480, cost: 7.822453, mlm loss: 7.822453, speed: 0.439567 steps/s, speed: 3.516532 samples/s, speed: 1800.464580 tokens/s, learning rate: 4.790e-06, loss_scalings: 377.789520, pp_loss: 7.721016
[INFO] 2021-07-09 16:59:12,941 [run_pretraining.py:  512]:	********exe.run_480******* 
[INFO] 2021-07-09 16:59:15,135 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:15,135 [run_pretraining.py:  534]:	loss/total_loss, 7.529876708984375, 481
[INFO] 2021-07-09 16:59:15,135 [run_pretraining.py:  535]:	loss/mlm_loss, 7.529876708984375, 481
[INFO] 2021-07-09 16:59:15,135 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.7999997150327545e-06, 481
[INFO] 2021-07-09 16:59:15,135 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 481
[INFO] 2021-07-09 16:59:15,135 [run_pretraining.py:  558]:	worker_index: 7, step: 481, cost: 7.529877, mlm loss: 7.529877, speed: 0.455786 steps/s, speed: 3.646292 samples/s, speed: 1866.901431 tokens/s, learning rate: 4.800e-06, loss_scalings: 377.789520, pp_loss: 7.561223
[INFO] 2021-07-09 16:59:15,136 [run_pretraining.py:  512]:	********exe.run_481******* 
[INFO] 2021-07-09 16:59:17,359 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:17,359 [run_pretraining.py:  534]:	loss/total_loss, 7.19444465637207, 482
[INFO] 2021-07-09 16:59:17,359 [run_pretraining.py:  535]:	loss/mlm_loss, 7.19444465637207, 482
[INFO] 2021-07-09 16:59:17,359 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.809999609278748e-06, 482
[INFO] 2021-07-09 16:59:17,359 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 482
[INFO] 2021-07-09 16:59:17,360 [run_pretraining.py:  558]:	worker_index: 7, step: 482, cost: 7.194445, mlm loss: 7.194445, speed: 0.449779 steps/s, speed: 3.598233 samples/s, speed: 1842.295434 tokens/s, learning rate: 4.810e-06, loss_scalings: 377.789520, pp_loss: 7.175249
[INFO] 2021-07-09 16:59:17,360 [run_pretraining.py:  512]:	********exe.run_482******* 
[INFO] 2021-07-09 16:59:19,638 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:19,638 [run_pretraining.py:  534]:	loss/total_loss, 6.471735954284668, 483
[INFO] 2021-07-09 16:59:19,638 [run_pretraining.py:  535]:	loss/mlm_loss, 6.471735954284668, 483
[INFO] 2021-07-09 16:59:19,639 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.819999958272092e-06, 483
[INFO] 2021-07-09 16:59:19,639 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 483
[INFO] 2021-07-09 16:59:19,639 [run_pretraining.py:  558]:	worker_index: 7, step: 483, cost: 6.471736, mlm loss: 6.471736, speed: 0.438895 steps/s, speed: 3.511158 samples/s, speed: 1797.712972 tokens/s, learning rate: 4.820e-06, loss_scalings: 377.789520, pp_loss: 6.555353
[INFO] 2021-07-09 16:59:19,639 [run_pretraining.py:  512]:	********exe.run_483******* 
[INFO] 2021-07-09 16:59:22,001 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:22,001 [run_pretraining.py:  534]:	loss/total_loss, 6.167117118835449, 484
[INFO] 2021-07-09 16:59:22,001 [run_pretraining.py:  535]:	loss/mlm_loss, 6.167117118835449, 484
[INFO] 2021-07-09 16:59:22,002 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.829999852518085e-06, 484
[INFO] 2021-07-09 16:59:22,002 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 484
[INFO] 2021-07-09 16:59:22,002 [run_pretraining.py:  558]:	worker_index: 7, step: 484, cost: 6.167117, mlm loss: 6.167117, speed: 0.423311 steps/s, speed: 3.386489 samples/s, speed: 1733.882284 tokens/s, learning rate: 4.830e-06, loss_scalings: 377.789520, pp_loss: 6.151697
[INFO] 2021-07-09 16:59:22,002 [run_pretraining.py:  512]:	********exe.run_484******* 
[INFO] 2021-07-09 16:59:24,530 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:24,531 [run_pretraining.py:  534]:	loss/total_loss, 5.633744716644287, 485
[INFO] 2021-07-09 16:59:24,531 [run_pretraining.py:  535]:	loss/mlm_loss, 5.633744716644287, 485
[INFO] 2021-07-09 16:59:24,531 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.839999746764079e-06, 485
[INFO] 2021-07-09 16:59:24,531 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 485
[INFO] 2021-07-09 16:59:24,531 [run_pretraining.py:  558]:	worker_index: 7, step: 485, cost: 5.633745, mlm loss: 5.633745, speed: 0.395421 steps/s, speed: 3.163365 samples/s, speed: 1619.643005 tokens/s, learning rate: 4.840e-06, loss_scalings: 377.789520, pp_loss: 5.531313
[INFO] 2021-07-09 16:59:24,531 [run_pretraining.py:  512]:	********exe.run_485******* 
[INFO] 2021-07-09 16:59:26,787 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:26,788 [run_pretraining.py:  534]:	loss/total_loss, 5.255553245544434, 486
[INFO] 2021-07-09 16:59:26,788 [run_pretraining.py:  535]:	loss/mlm_loss, 5.255553245544434, 486
[INFO] 2021-07-09 16:59:26,788 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.850000095757423e-06, 486
[INFO] 2021-07-09 16:59:26,788 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 486
[INFO] 2021-07-09 16:59:26,788 [run_pretraining.py:  558]:	worker_index: 7, step: 486, cost: 5.255553, mlm loss: 5.255553, speed: 0.443185 steps/s, speed: 3.545478 samples/s, speed: 1815.284536 tokens/s, learning rate: 4.850e-06, loss_scalings: 377.789520, pp_loss: 5.264651
[INFO] 2021-07-09 16:59:26,788 [run_pretraining.py:  512]:	********exe.run_486******* 
[INFO] 2021-07-09 16:59:29,128 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:29,129 [run_pretraining.py:  534]:	loss/total_loss, 5.406683444976807, 487
[INFO] 2021-07-09 16:59:29,129 [run_pretraining.py:  535]:	loss/mlm_loss, 5.406683444976807, 487
[INFO] 2021-07-09 16:59:29,129 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.859999990003416e-06, 487
[INFO] 2021-07-09 16:59:29,129 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 487
[INFO] 2021-07-09 16:59:29,129 [run_pretraining.py:  558]:	worker_index: 7, step: 487, cost: 5.406683, mlm loss: 5.406683, speed: 0.427326 steps/s, speed: 3.418608 samples/s, speed: 1750.327367 tokens/s, learning rate: 4.860e-06, loss_scalings: 377.789520, pp_loss: 5.253943
[INFO] 2021-07-09 16:59:29,129 [run_pretraining.py:  512]:	********exe.run_487******* 
[INFO] 2021-07-09 16:59:31,351 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:31,351 [run_pretraining.py:  534]:	loss/total_loss, 4.887591361999512, 488
[INFO] 2021-07-09 16:59:31,352 [run_pretraining.py:  535]:	loss/mlm_loss, 4.887591361999512, 488
[INFO] 2021-07-09 16:59:31,352 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.86999988424941e-06, 488
[INFO] 2021-07-09 16:59:31,352 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 488
[INFO] 2021-07-09 16:59:31,352 [run_pretraining.py:  558]:	worker_index: 7, step: 488, cost: 4.887591, mlm loss: 4.887591, speed: 0.450023 steps/s, speed: 3.600182 samples/s, speed: 1843.293257 tokens/s, learning rate: 4.870e-06, loss_scalings: 377.789520, pp_loss: 4.813878
[INFO] 2021-07-09 16:59:31,352 [run_pretraining.py:  512]:	********exe.run_488******* 
[INFO] 2021-07-09 16:59:33,570 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:33,570 [run_pretraining.py:  534]:	loss/total_loss, 4.185121536254883, 489
[INFO] 2021-07-09 16:59:33,571 [run_pretraining.py:  535]:	loss/mlm_loss, 4.185121536254883, 489
[INFO] 2021-07-09 16:59:33,571 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.879999778495403e-06, 489
[INFO] 2021-07-09 16:59:33,571 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 489
[INFO] 2021-07-09 16:59:33,571 [run_pretraining.py:  558]:	worker_index: 7, step: 489, cost: 4.185122, mlm loss: 4.185122, speed: 0.450800 steps/s, speed: 3.606400 samples/s, speed: 1846.476774 tokens/s, learning rate: 4.880e-06, loss_scalings: 377.789520, pp_loss: 4.122695
[INFO] 2021-07-09 16:59:33,571 [run_pretraining.py:  512]:	********exe.run_489******* 
[INFO] 2021-07-09 16:59:35,767 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:35,768 [run_pretraining.py:  534]:	loss/total_loss, 3.218846082687378, 490
[INFO] 2021-07-09 16:59:35,768 [run_pretraining.py:  535]:	loss/mlm_loss, 3.218846082687378, 490
[INFO] 2021-07-09 16:59:35,768 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.890000127488747e-06, 490
[INFO] 2021-07-09 16:59:35,768 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 490
[INFO] 2021-07-09 16:59:35,768 [run_pretraining.py:  558]:	worker_index: 7, step: 490, cost: 3.218846, mlm loss: 3.218846, speed: 0.455237 steps/s, speed: 3.641896 samples/s, speed: 1864.650642 tokens/s, learning rate: 4.890e-06, loss_scalings: 377.789520, pp_loss: 3.274154
[INFO] 2021-07-09 16:59:35,768 [run_pretraining.py:  512]:	********exe.run_490******* 
[INFO] 2021-07-09 16:59:38,002 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:38,002 [run_pretraining.py:  534]:	loss/total_loss, 3.025785207748413, 491
[INFO] 2021-07-09 16:59:38,002 [run_pretraining.py:  535]:	loss/mlm_loss, 3.025785207748413, 491
[INFO] 2021-07-09 16:59:38,002 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.89999956698739e-06, 491
[INFO] 2021-07-09 16:59:38,003 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 491
[INFO] 2021-07-09 16:59:38,003 [run_pretraining.py:  558]:	worker_index: 7, step: 491, cost: 3.025785, mlm loss: 3.025785, speed: 0.447664 steps/s, speed: 3.581310 samples/s, speed: 1833.630707 tokens/s, learning rate: 4.900e-06, loss_scalings: 377.789520, pp_loss: 2.958535
[INFO] 2021-07-09 16:59:38,003 [run_pretraining.py:  512]:	********exe.run_491******* 
[INFO] 2021-07-09 16:59:40,287 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:40,287 [run_pretraining.py:  534]:	loss/total_loss, 2.465353488922119, 492
[INFO] 2021-07-09 16:59:40,287 [run_pretraining.py:  535]:	loss/mlm_loss, 2.465353488922119, 492
[INFO] 2021-07-09 16:59:40,287 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.909999915980734e-06, 492
[INFO] 2021-07-09 16:59:40,287 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 492
[INFO] 2021-07-09 16:59:40,288 [run_pretraining.py:  558]:	worker_index: 7, step: 492, cost: 2.465353, mlm loss: 2.465353, speed: 0.437774 steps/s, speed: 3.502189 samples/s, speed: 1793.120646 tokens/s, learning rate: 4.910e-06, loss_scalings: 377.789520, pp_loss: 2.468637
[INFO] 2021-07-09 16:59:40,288 [run_pretraining.py:  512]:	********exe.run_492******* 
[INFO] 2021-07-09 16:59:42,582 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:42,583 [run_pretraining.py:  534]:	loss/total_loss, 2.054798126220703, 493
[INFO] 2021-07-09 16:59:42,583 [run_pretraining.py:  535]:	loss/mlm_loss, 2.054798126220703, 493
[INFO] 2021-07-09 16:59:42,583 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.919999810226727e-06, 493
[INFO] 2021-07-09 16:59:42,583 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 493
[INFO] 2021-07-09 16:59:42,583 [run_pretraining.py:  558]:	worker_index: 7, step: 493, cost: 2.054798, mlm loss: 2.054798, speed: 0.435729 steps/s, speed: 3.485831 samples/s, speed: 1784.745317 tokens/s, learning rate: 4.920e-06, loss_scalings: 377.789520, pp_loss: 2.043796
[INFO] 2021-07-09 16:59:42,583 [run_pretraining.py:  512]:	********exe.run_493******* 
[INFO] 2021-07-09 16:59:44,901 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:44,902 [run_pretraining.py:  534]:	loss/total_loss, 1.6191366910934448, 494
[INFO] 2021-07-09 16:59:44,902 [run_pretraining.py:  535]:	loss/mlm_loss, 1.6191366910934448, 494
[INFO] 2021-07-09 16:59:44,902 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.929999704472721e-06, 494
[INFO] 2021-07-09 16:59:44,902 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 494
[INFO] 2021-07-09 16:59:44,902 [run_pretraining.py:  558]:	worker_index: 7, step: 494, cost: 1.619137, mlm loss: 1.619137, speed: 0.431385 steps/s, speed: 3.451080 samples/s, speed: 1766.953075 tokens/s, learning rate: 4.930e-06, loss_scalings: 377.789520, pp_loss: 1.661636
[INFO] 2021-07-09 16:59:44,902 [run_pretraining.py:  512]:	********exe.run_494******* 
[INFO] 2021-07-09 16:59:47,153 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:47,154 [run_pretraining.py:  534]:	loss/total_loss, 1.3640191555023193, 495
[INFO] 2021-07-09 16:59:47,154 [run_pretraining.py:  535]:	loss/mlm_loss, 1.3640191555023193, 495
[INFO] 2021-07-09 16:59:47,154 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.940000053466065e-06, 495
[INFO] 2021-07-09 16:59:47,154 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 495
[INFO] 2021-07-09 16:59:47,154 [run_pretraining.py:  558]:	worker_index: 7, step: 495, cost: 1.364019, mlm loss: 1.364019, speed: 0.444163 steps/s, speed: 3.553303 samples/s, speed: 1819.291240 tokens/s, learning rate: 4.940e-06, loss_scalings: 377.789520, pp_loss: 1.392685
[INFO] 2021-07-09 16:59:47,154 [run_pretraining.py:  512]:	********exe.run_495******* 
[INFO] 2021-07-09 16:59:49,389 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:49,389 [run_pretraining.py:  534]:	loss/total_loss, 1.1879029273986816, 496
[INFO] 2021-07-09 16:59:49,390 [run_pretraining.py:  535]:	loss/mlm_loss, 1.1879029273986816, 496
[INFO] 2021-07-09 16:59:49,390 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.949999947712058e-06, 496
[INFO] 2021-07-09 16:59:49,390 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 496
[INFO] 2021-07-09 16:59:49,390 [run_pretraining.py:  558]:	worker_index: 7, step: 496, cost: 1.187903, mlm loss: 1.187903, speed: 0.447437 steps/s, speed: 3.579494 samples/s, speed: 1832.701184 tokens/s, learning rate: 4.950e-06, loss_scalings: 377.789520, pp_loss: 1.217347
[INFO] 2021-07-09 16:59:49,390 [run_pretraining.py:  512]:	********exe.run_496******* 
[INFO] 2021-07-09 16:59:51,627 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:51,627 [run_pretraining.py:  534]:	loss/total_loss, 1.137158751487732, 497
[INFO] 2021-07-09 16:59:51,628 [run_pretraining.py:  535]:	loss/mlm_loss, 1.137158751487732, 497
[INFO] 2021-07-09 16:59:51,628 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.9599998419580515e-06, 497
[INFO] 2021-07-09 16:59:51,628 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 497
[INFO] 2021-07-09 16:59:51,628 [run_pretraining.py:  558]:	worker_index: 7, step: 497, cost: 1.137159, mlm loss: 1.137159, speed: 0.446966 steps/s, speed: 3.575728 samples/s, speed: 1830.772774 tokens/s, learning rate: 4.960e-06, loss_scalings: 377.789520, pp_loss: 1.160555
[INFO] 2021-07-09 16:59:51,628 [run_pretraining.py:  512]:	********exe.run_497******* 
[INFO] 2021-07-09 16:59:53,868 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:53,869 [run_pretraining.py:  534]:	loss/total_loss, 1.1431374549865723, 498
[INFO] 2021-07-09 16:59:53,869 [run_pretraining.py:  535]:	loss/mlm_loss, 1.1431374549865723, 498
[INFO] 2021-07-09 16:59:53,869 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.969999736204045e-06, 498
[INFO] 2021-07-09 16:59:53,869 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 498
[INFO] 2021-07-09 16:59:53,869 [run_pretraining.py:  558]:	worker_index: 7, step: 498, cost: 1.143137, mlm loss: 1.143137, speed: 0.446341 steps/s, speed: 3.570732 samples/s, speed: 1828.214544 tokens/s, learning rate: 4.970e-06, loss_scalings: 377.789520, pp_loss: 1.154576
[INFO] 2021-07-09 16:59:53,869 [run_pretraining.py:  512]:	********exe.run_498******* 
[INFO] 2021-07-09 16:59:56,071 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:56,071 [run_pretraining.py:  534]:	loss/total_loss, 1.2665714025497437, 499
[INFO] 2021-07-09 16:59:56,072 [run_pretraining.py:  535]:	loss/mlm_loss, 1.2665714025497437, 499
[INFO] 2021-07-09 16:59:56,072 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.980000085197389e-06, 499
[INFO] 2021-07-09 16:59:56,072 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 499
[INFO] 2021-07-09 16:59:56,072 [run_pretraining.py:  558]:	worker_index: 7, step: 499, cost: 1.266571, mlm loss: 1.266571, speed: 0.454086 steps/s, speed: 3.632691 samples/s, speed: 1859.937940 tokens/s, learning rate: 4.980e-06, loss_scalings: 377.789520, pp_loss: 1.269013
[INFO] 2021-07-09 16:59:56,072 [run_pretraining.py:  512]:	********exe.run_499******* 
[INFO] 2021-07-09 16:59:58,286 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:58,287 [run_pretraining.py:  534]:	loss/total_loss, 1.5187642574310303, 500
[INFO] 2021-07-09 16:59:58,287 [run_pretraining.py:  535]:	loss/mlm_loss, 1.5187642574310303, 500
[INFO] 2021-07-09 16:59:58,287 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.9899999794433825e-06, 500
[INFO] 2021-07-09 16:59:58,287 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 500
[INFO] 2021-07-09 16:59:58,287 [run_pretraining.py:  558]:	worker_index: 7, step: 500, cost: 1.518764, mlm loss: 1.518764, speed: 0.451565 steps/s, speed: 3.612522 samples/s, speed: 1849.611367 tokens/s, learning rate: 4.990e-06, loss_scalings: 377.789520, pp_loss: 1.535123
[DEBUG] 2021-07-09 16:59:58,287 [run_pretraining.py:  567]:	saving models to output/test-bs8-mppp_7/step_500
[INFO] 2021-07-09 16:59:59,156 [run_pretraining.py:  512]:	********exe.run_500******* 
[INFO] 2021-07-09 17:00:01,459 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 17:00:01,460 [run_pretraining.py:  534]:	loss/total_loss, 2.1125993728637695, 501
[INFO] 2021-07-09 17:00:01,460 [run_pretraining.py:  535]:	loss/mlm_loss, 2.1125993728637695, 501
[INFO] 2021-07-09 17:00:01,460 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.999999873689376e-06, 501
[INFO] 2021-07-09 17:00:01,460 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 501
[INFO] 2021-07-09 17:00:01,460 [run_pretraining.py:  558]:	worker_index: 7, step: 501, cost: 2.112599, mlm loss: 2.112599, speed: 0.315213 steps/s, speed: 2.521702 samples/s, speed: 1291.111597 tokens/s, learning rate: 5.000e-06, loss_scalings: 377.789520, pp_loss: 2.093477
[INFO] 2021-07-09 17:00:01,460 [run_pretraining.py:  512]:	********exe.run_501******* 
[INFO] 2021-07-09 17:00:03,710 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 17:00:03,710 [run_pretraining.py:  534]:	loss/total_loss, 2.9373862743377686, 502
[INFO] 2021-07-09 17:00:03,710 [run_pretraining.py:  535]:	loss/mlm_loss, 2.9373862743377686, 502
[INFO] 2021-07-09 17:00:03,710 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.009999767935369e-06, 502
[INFO] 2021-07-09 17:00:03,711 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 502
[INFO] 2021-07-09 17:00:03,711 [run_pretraining.py:  558]:	worker_index: 7, step: 502, cost: 2.937386, mlm loss: 2.937386, speed: 0.444461 steps/s, speed: 3.555691 samples/s, speed: 1820.513699 tokens/s, learning rate: 5.010e-06, loss_scalings: 377.789520, pp_loss: 2.945528
[INFO] 2021-07-09 17:00:03,711 [run_pretraining.py:  512]:	********exe.run_502******* 
[INFO] 2021-07-09 17:00:05,984 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 17:00:05,985 [run_pretraining.py:  534]:	loss/total_loss, 3.8140666484832764, 503
[INFO] 2021-07-09 17:00:05,985 [run_pretraining.py:  535]:	loss/mlm_loss, 3.8140666484832764, 503
[INFO] 2021-07-09 17:00:05,985 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.020000116928713e-06, 503
[INFO] 2021-07-09 17:00:05,985 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 503
[INFO] 2021-07-09 17:00:05,985 [run_pretraining.py:  558]:	worker_index: 7, step: 503, cost: 3.814067, mlm loss: 3.814067, speed: 0.439813 steps/s, speed: 3.518502 samples/s, speed: 1801.472939 tokens/s, learning rate: 5.020e-06, loss_scalings: 377.789520, pp_loss: 3.811307
[INFO] 2021-07-09 17:00:05,985 [run_pretraining.py:  512]:	********exe.run_503******* 
[INFO] 2021-07-09 17:00:08,228 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 17:00:08,229 [run_pretraining.py:  534]:	loss/total_loss, 4.697262763977051, 504
[INFO] 2021-07-09 17:00:08,229 [run_pretraining.py:  535]:	loss/mlm_loss, 4.697262763977051, 504
[INFO] 2021-07-09 17:00:08,229 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.029999556427356e-06, 504
[INFO] 2021-07-09 17:00:08,229 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 504
[INFO] 2021-07-09 17:00:08,229 [run_pretraining.py:  558]:	worker_index: 7, step: 504, cost: 4.697263, mlm loss: 4.697263, speed: 0.445749 steps/s, speed: 3.565994 samples/s, speed: 1825.788986 tokens/s, learning rate: 5.030e-06, loss_scalings: 377.789520, pp_loss: 4.753710
[INFO] 2021-07-09 17:00:08,229 [run_pretraining.py:  512]:	********exe.run_504******* 
[INFO] 2021-07-09 17:00:10,428 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 17:00:10,428 [run_pretraining.py:  534]:	loss/total_loss, 5.514403343200684, 505
[INFO] 2021-07-09 17:00:10,428 [run_pretraining.py:  535]:	loss/mlm_loss, 5.514403343200684, 505
[INFO] 2021-07-09 17:00:10,428 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.0399999054207e-06, 505
[INFO] 2021-07-09 17:00:10,429 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 505
[INFO] 2021-07-09 17:00:10,429 [run_pretraining.py:  558]:	worker_index: 7, step: 505, cost: 5.514403, mlm loss: 5.514403, speed: 0.454736 steps/s, speed: 3.637886 samples/s, speed: 1862.597700 tokens/s, learning rate: 5.040e-06, loss_scalings: 377.789520, pp_loss: 5.528693
[INFO] 2021-07-09 17:00:10,429 [run_pretraining.py:  512]:	********exe.run_505******* 
[INFO] 2021-07-09 17:00:12,668 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 17:00:12,669 [run_pretraining.py:  534]:	loss/total_loss, 6.234278202056885, 506
[INFO] 2021-07-09 17:00:12,669 [run_pretraining.py:  535]:	loss/mlm_loss, 6.234278202056885, 506
[INFO] 2021-07-09 17:00:12,669 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.050000254414044e-06, 506
[INFO] 2021-07-09 17:00:12,669 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 506
[INFO] 2021-07-09 17:00:12,669 [run_pretraining.py:  558]:	worker_index: 7, step: 506, cost: 6.234278, mlm loss: 6.234278, speed: 0.446476 steps/s, speed: 3.571810 samples/s, speed: 1828.766653 tokens/s, learning rate: 5.050e-06, loss_scalings: 377.789520, pp_loss: 6.181450
[INFO] 2021-07-09 17:00:12,669 [run_pretraining.py:  512]:	********exe.run_506******* 
[INFO] 2021-07-09 17:00:14,885 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 17:00:14,886 [run_pretraining.py:  534]:	loss/total_loss, 6.953920364379883, 507
[INFO] 2021-07-09 17:00:14,886 [run_pretraining.py:  535]:	loss/mlm_loss, 6.953920364379883, 507
[INFO] 2021-07-09 17:00:14,886 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.059999693912687e-06, 507
[INFO] 2021-07-09 17:00:14,886 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 507
[INFO] 2021-07-09 17:00:14,886 [run_pretraining.py:  558]:	worker_index: 7, step: 507, cost: 6.953920, mlm loss: 6.953920, speed: 0.451114 steps/s, speed: 3.608913 samples/s, speed: 1847.763478 tokens/s, learning rate: 5.060e-06, loss_scalings: 377.789520, pp_loss: 6.866659
[INFO] 2021-07-09 17:00:14,886 [run_pretraining.py:  512]:	********exe.run_507******* 
[INFO] 2021-07-09 17:00:17,114 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 17:00:17,114 [run_pretraining.py:  534]:	loss/total_loss, 7.468423843383789, 508
[INFO] 2021-07-09 17:00:17,114 [run_pretraining.py:  535]:	loss/mlm_loss, 7.468423843383789, 508
[INFO] 2021-07-09 17:00:17,114 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.070000042906031e-06, 508
[INFO] 2021-07-09 17:00:17,114 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 508
[INFO] 2021-07-09 17:00:17,114 [run_pretraining.py:  558]:	worker_index: 7, step: 508, cost: 7.468424, mlm loss: 7.468424, speed: 0.448948 steps/s, speed: 3.591581 samples/s, speed: 1838.889292 tokens/s, learning rate: 5.070e-06, loss_scalings: 377.789520, pp_loss: 7.511263
[INFO] 2021-07-09 17:00:17,115 [run_pretraining.py:  512]:	********exe.run_508******* 
[INFO] 2021-07-09 17:00:19,321 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 17:00:19,322 [run_pretraining.py:  534]:	loss/total_loss, 8.076461791992188, 509
[INFO] 2021-07-09 17:00:19,322 [run_pretraining.py:  535]:	loss/mlm_loss, 8.076461791992188, 509
[INFO] 2021-07-09 17:00:19,322 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.079999937152024e-06, 509
[INFO] 2021-07-09 17:00:19,322 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 509
[INFO] 2021-07-09 17:00:19,322 [run_pretraining.py:  558]:	worker_index: 7, step: 509, cost: 8.076462, mlm loss: 8.076462, speed: 0.453077 steps/s, speed: 3.624615 samples/s, speed: 1855.802726 tokens/s, learning rate: 5.080e-06, loss_scalings: 377.789520, pp_loss: 8.048697
[INFO] 2021-07-09 17:00:19,322 [run_pretraining.py:  512]:	********exe.run_509******* 
[INFO] 2021-07-09 17:00:21,560 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 17:00:21,561 [run_pretraining.py:  534]:	loss/total_loss, 8.271291732788086, 510
[INFO] 2021-07-09 17:00:21,561 [run_pretraining.py:  535]:	loss/mlm_loss, 8.271291732788086, 510
[INFO] 2021-07-09 17:00:21,561 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.089999831398018e-06, 510
[INFO] 2021-07-09 17:00:21,561 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 510
[INFO] 2021-07-09 17:00:21,561 [run_pretraining.py:  558]:	worker_index: 7, step: 510, cost: 8.271292, mlm loss: 8.271292, speed: 0.446772 steps/s, speed: 3.574176 samples/s, speed: 1829.978101 tokens/s, learning rate: 5.090e-06, loss_scalings: 377.789520, pp_loss: 8.285084
[INFO] 2021-07-09 17:00:21,561 [run_pretraining.py:  512]:	********exe.run_510******* 
[INFO] 2021-07-09 17:00:23,793 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 17:00:23,793 [run_pretraining.py:  534]:	loss/total_loss, 7.99949836730957, 511
[INFO] 2021-07-09 17:00:23,793 [run_pretraining.py:  535]:	loss/mlm_loss, 7.99949836730957, 511
[INFO] 2021-07-09 17:00:23,794 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.099999725644011e-06, 511
[INFO] 2021-07-09 17:00:23,794 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 511
[INFO] 2021-07-09 17:00:23,794 [run_pretraining.py:  558]:	worker_index: 7, step: 511, cost: 7.999498, mlm loss: 7.999498, speed: 0.448045 steps/s, speed: 3.584362 samples/s, speed: 1835.193575 tokens/s, learning rate: 5.100e-06, loss_scalings: 377.789520, pp_loss: 8.011567
[INFO] 2021-07-09 17:00:23,794 [run_pretraining.py:  512]:	********exe.run_511******* 
[INFO] 2021-07-09 17:00:26,068 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 17:00:26,069 [run_pretraining.py:  534]:	loss/total_loss, 7.388028621673584, 512
[INFO] 2021-07-09 17:00:26,069 [run_pretraining.py:  535]:	loss/mlm_loss, 7.388028621673584, 512
[INFO] 2021-07-09 17:00:26,069 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.110000074637355e-06, 512
[INFO] 2021-07-09 17:00:26,069 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 512
[INFO] 2021-07-09 17:00:26,069 [run_pretraining.py:  558]:	worker_index: 7, step: 512, cost: 7.388029, mlm loss: 7.388029, speed: 0.439574 steps/s, speed: 3.516591 samples/s, speed: 1800.494394 tokens/s, learning rate: 5.110e-06, loss_scalings: 377.789520, pp_loss: 7.277113
[INFO] 2021-07-09 17:00:26,069 [run_pretraining.py:  512]:	********exe.run_512******* 
/home/gongwb/.local/lib/python3.7/multiprocessing/semaphore_tracker.py:144: UserWarning: semaphore_tracker: There appear to be 91 leaked semaphores to clean up at shutdown
  len(cache))
