/home/gongwb/.local/lib/python3.7/site-packages/setuptools/depends.py:2: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0709 16:38:09.882939 36120 init.cc:88] Before Parse: argc is 2, Init commandline: dummy --tryfromenv=check_nan_inf,benchmark,eager_delete_scope,fraction_of_cpu_memory_to_use,initial_cpu_memory_in_mb,init_allocated_mem,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_system_allocator,enable_unused_var_check,free_idle_chunk,free_when_no_cache_hit,call_stack_level,sort_sum_gradient,max_inplace_grad_add,use_pinned_memory,cpu_deterministic,selected_npus,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,gpu_memory_limit_mb 
I0709 16:38:09.883186 36120 init.cc:95] After Parse: argc is 1
-----------  Configuration Arguments -----------
data_dir: ./data
debug: False
do_eval: True
epoch: 100
ernie_config_file: config/ernie_base_config.json
eval_batch_size: 35
eval_data_path: ./data
eval_steps: -1
global_bsz: 8
global_steps: 0
grad_merge: 0
init_checkpoint: 
learning_rate: 0.0001
log_steps: 1
max_seq_len: 512
micro_bsz: 1
num_dp: 1
num_mp: 4
num_pp: 2
num_sharding: 1
num_train_steps: 1600
output_dir: output/test-bs8-mppp
preln: False
save_steps: 500
seed: 2021
use_amp: True
use_hybrid_dp: True
use_lamb: False
use_offload: False
use_recompute: True
use_sharding: True
vocab_file: ./config/30k-clean.vocab.albert
warmup_steps: 10000
weight_decay: 0.01
------------------------------------------------
to run startup
[INFO] 2021-07-09 16:38:10,645 [run_pretraining.py:  216]:	pretraining start
[INFO] 2021-07-09 16:38:10,645 [run_pretraining.py:  234]:	using recompute.
[INFO] 2021-07-09 16:38:10,646 [run_pretraining.py:  279]:	using globa_bsz: 8 micro_bsz: 1, acc_steps: 8
[DEBUG] 2021-07-09 16:38:10,710 [run_pretraining.py:  118]:	========= dp_sharding worker: 0 of 1 ==========
[INFO] 2021-07-09 16:38:10,711 [pretraining_ds_mlm.py:  293]:	Apply sharding in distribution env 0/1
[INFO] 2021-07-09 16:38:10,711 [pretraining_ds_mlm.py:  295]:	read from ./data/part-00000.104,./data/part-00000.100,./data/part-00000.107,./data/part-00000.103,./data/part-00000.10,./data/part-00000.105,./data/part-00000.101,./data/part-00000.102,./data/part-00000.106,./data/part-00000.109,./data/part-00000.108
I0709 16:38:10.711506 36120 reader_py.cc:387] init_lod_tensor_blocking_queue
INFO:root:places would be ommited when DataLoader is not iterable
/home/liupeng51/github/Paddle/build/build_ubuntu_optimizer_checkinf_release_ascend_y_none_3.7.5/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /home/liupeng51/github/FleetX/examples/hybrid_parallelism/model/ernie.py:158
The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
/home/liupeng51/github/Paddle/build/build_ubuntu_optimizer_checkinf_release_ascend_y_none_3.7.5/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /home/liupeng51/github/FleetX/examples/hybrid_parallelism/model/ernie.py:159
The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
/home/liupeng51/github/Paddle/build/build_ubuntu_optimizer_checkinf_release_ascend_y_none_3.7.5/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /home/liupeng51/github/FleetX/examples/hybrid_parallelism/model/transformer_encoder.py:170
The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
/home/liupeng51/github/Paddle/build/build_ubuntu_optimizer_checkinf_release_ascend_y_none_3.7.5/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /home/liupeng51/github/FleetX/examples/hybrid_parallelism/model/transformer_encoder.py:280
The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
/home/liupeng51/github/Paddle/build/build_ubuntu_optimizer_checkinf_release_ascend_y_none_3.7.5/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /home/liupeng51/github/FleetX/examples/hybrid_parallelism/model/transformer_encoder.py:43
The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
/home/liupeng51/github/Paddle/build/build_ubuntu_optimizer_checkinf_release_ascend_y_none_3.7.5/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /home/liupeng51/github/FleetX/examples/hybrid_parallelism/model/transformer_encoder.py:44
The behavior of expression A * B has been unified with elementwise_mul(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_mul(X, Y, axis=0) instead of A * B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
[DEBUG] 2021-07-09 16:38:11,520 [run_pretraining.py:  315]:	base lr: 0.0001
/home/liupeng51/github/Paddle/build/build_ubuntu_optimizer_checkinf_release_ascend_y_none_3.7.5/python/paddle/distributed/fleet/base/fleet_base.py:818: UserWarning: It is recommended to use DistributedStrategy in fleet.init(). The strategy here is only for compatibility. If the strategy in fleet.distributed_optimizer() is not None, then it will overwrite the DistributedStrategy in fleet.init(), which will take effect in distributed training.
  "It is recommended to use DistributedStrategy "
2021-07-09 16:38:11 INFO     Gradient merge in [pp_gm], acc step = [8]
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:Gradient merge in [pp_gm], acc step = [8]
Fri Jul 09 16:38:12-INFO: recompute segment[0]
Fri Jul 09 16:38:12-INFO: segment start op: [squeeze2]: [['shard_index_0.tmp_0']]
Fri Jul 09 16:38:12-INFO: segment end op: [layer_norm]: [['encoder_layer_0_post_ffn_layer_norm_bias', 'encoder_layer_0_post_ffn_layer_norm_scale', 'tmp_10']]
Fri Jul 09 16:38:12-INFO: recompute segment[0]
Fri Jul 09 16:38:12-INFO: segment start op: [squeeze2]: [['shard_index_0.tmp_0']]
Fri Jul 09 16:38:12-INFO: segment end op: [layer_norm]: [['encoder_layer_0_post_ffn_layer_norm_bias', 'encoder_layer_0_post_ffn_layer_norm_scale', 'tmp_10']]
Fri Jul 09 16:38:12-INFO: found [0] vars which cross recompute segment: [set()], better checkpoints might be set to reduce those vars
pp_rank: 1
2021-07-09 16:38:17 INFO     global word size: 8
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:global word size: 8
2021-07-09 16:38:17 INFO     global rank: 4
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:global rank: 4
2021-07-09 16:38:17 INFO     global endpoints: ['192.168.206.27:6170', '192.168.206.27:6171', '192.168.206.27:6172', '192.168.206.27:6173', '192.168.206.27:6174', '192.168.206.27:6175', '192.168.206.27:6176', '192.168.206.27:6177']
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:global endpoints: ['192.168.206.27:6170', '192.168.206.27:6171', '192.168.206.27:6172', '192.168.206.27:6173', '192.168.206.27:6174', '192.168.206.27:6175', '192.168.206.27:6176', '192.168.206.27:6177']
2021-07-09 16:38:17 INFO     global ring id: 3
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:global ring id: 3
2021-07-09 16:38:17 INFO     ##############################
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:##############################
2021-07-09 16:38:17 INFO     mp group size: 4
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:mp group size: 4
2021-07-09 16:38:17 INFO     mp rank: 0
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:mp rank: 0
2021-07-09 16:38:17 INFO     mp group id: 1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:mp group id: 1
2021-07-09 16:38:17 INFO     mp group endpoints: ['192.168.206.27:6174', '192.168.206.27:6175', '192.168.206.27:6176', '192.168.206.27:6177']
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:mp group endpoints: ['192.168.206.27:6174', '192.168.206.27:6175', '192.168.206.27:6176', '192.168.206.27:6177']
2021-07-09 16:38:17 INFO     mp ring id: 0
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:mp ring id: 0
2021-07-09 16:38:17 INFO     ##############################
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:##############################
2021-07-09 16:38:17 INFO     sharding group size: 1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:sharding group size: 1
2021-07-09 16:38:17 INFO     sharding rank: -1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:sharding rank: -1
2021-07-09 16:38:17 INFO     sharding group id: -1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:sharding group id: -1
2021-07-09 16:38:17 INFO     sharding group endpoints: []
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:sharding group endpoints: []
2021-07-09 16:38:17 INFO     sharding ring id: -1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:sharding ring id: -1
2021-07-09 16:38:17 INFO     ##############################
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:##############################
2021-07-09 16:38:17 INFO     pp group size: 2
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pp group size: 2
2021-07-09 16:38:17 INFO     pp rank: 1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pp rank: 1
2021-07-09 16:38:17 INFO     pp group id: 0
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pp group id: 0
2021-07-09 16:38:17 INFO     pp group endpoints: ['192.168.206.27:6170', '192.168.206.27:6174']
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pp group endpoints: ['192.168.206.27:6170', '192.168.206.27:6174']
2021-07-09 16:38:17 INFO     pp ring id: 20
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pp ring id: 20
2021-07-09 16:38:17 INFO     ##############################
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:##############################
2021-07-09 16:38:17 INFO     pure dp group size: 1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pure dp group size: 1
2021-07-09 16:38:17 INFO     pure dp rank: -1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pure dp rank: -1
2021-07-09 16:38:17 INFO     pure dp group endpoints: []
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pure dp group endpoints: []
2021-07-09 16:38:17 INFO     pure dp ring id: -1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pure dp ring id: -1
2021-07-09 16:38:17 INFO     ##############################
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:##############################
pp pair:(0, 1), ring_id: 20
pp pair:(1, 0), ring_id: 21
I0709 16:38:36.024919 36120 gen_hccl_id_op_helper.cc:181] Server listening on: 192.168.206.27:6174 successful.
I0709 16:38:37.082252 36120 collective_helper_npu.cc:83] initialized comm: 0xffffe83811a0, nranks: 8, hccl_id: 0x3e160034, rank: 4
I0709 16:38:40.139866 36120 collective_helper_npu.cc:88] initialized comm: 0xffffe83811a0, nranks: 8, hccl_id: 0x3e160034, rank: 4
I0709 16:38:40.140098 36120 collective_helper_npu.cc:93] hccl communicator of rank 4 in ring 3 has been created on device 4, with comm: 0x3e1c6570
I0709 16:38:42.952042 36120 collective_helper_npu.cc:83] initialized comm: 0xffffe83811a0, nranks: 4, hccl_id: 0x3e1a2114, rank: 0
I0709 16:38:44.761864 36120 collective_helper_npu.cc:88] initialized comm: 0xffffe83811a0, nranks: 4, hccl_id: 0x3e1a2114, rank: 0
I0709 16:38:44.763263 36120 collective_helper_npu.cc:93] hccl communicator of rank 0 in ring 0 has been created on device 4, with comm: 0x3e3f9190
I0709 16:38:45.598277 36120 gen_hccl_id_op_helper.cc:181] Server listening on: 192.168.206.27:6174 successful.
I0709 16:38:46.100020 36120 collective_helper_npu.cc:83] initialized comm: 0xffffe83811a0, nranks: 2, hccl_id: 0x3e1af544, rank: 1
I0709 16:38:47.316670 36120 collective_helper_npu.cc:88] initialized comm: 0xffffe83811a0, nranks: 2, hccl_id: 0x3e1af544, rank: 1
I0709 16:38:47.316805 36120 collective_helper_npu.cc:93] hccl communicator of rank 1 in ring 20 has been created on device 4, with comm: 0x3e24b2b0
W0709 16:38:47.573607 36120 gen_hccl_id_op_helper.cc:120] connect addr=192.168.206.27:6170 failed 1 times with reason: Connection refused retry after 0.5 seconds
I0709 16:38:48.075301 36120 collective_helper_npu.cc:83] initialized comm: 0xffffe83811a0, nranks: 2, hccl_id: 0x3e1b0654, rank: 0
I0709 16:38:49.296372 36120 collective_helper_npu.cc:88] initialized comm: 0xffffe83811a0, nranks: 2, hccl_id: 0x3e1b0654, rank: 0
I0709 16:38:49.297941 36120 collective_helper_npu.cc:93] hccl communicator of rank 0 in ring 21 has been created on device 4, with comm: 0x3e3d75c0
Done broadcast
[INFO] 2021-07-09 16:38:49,582 [run_pretraining.py:  512]:	********exe.run_0******* 
I0709 16:38:52.323608 39434 lod_tensor_blocking_queue.h:104] Init queue with size 1
I0709 16:38:52.323765 39434 buffered_reader.cc:41] BufferedReader
[INFO] 2021-07-09 16:41:11,451 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:11,452 [run_pretraining.py:  534]:	loss/total_loss, 10.308805465698242, 1
[INFO] 2021-07-09 16:41:11,452 [run_pretraining.py:  535]:	loss/mlm_loss, 10.308805465698242, 1
[INFO] 2021-07-09 16:41:11,452 [run_pretraining.py:  536]:	lr/scheduled_lr, 0.0, 1
[INFO] 2021-07-09 16:41:11,452 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 1
[INFO] 2021-07-09 16:41:11,452 [run_pretraining.py:  558]:	worker_index: 4, step: 1, cost: 10.308805, mlm loss: 10.308805, speed: 0.007049 steps/s, speed: 0.056389 samples/s, speed: 28.871227 tokens/s, learning rate: 0.000e+00, loss_scalings: 32768.000000, pp_loss: 10.246965
[INFO] 2021-07-09 16:41:11,452 [run_pretraining.py:  512]:	********exe.run_1******* 
[INFO] 2021-07-09 16:41:16,687 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:16,688 [run_pretraining.py:  534]:	loss/total_loss, 10.291903495788574, 2
[INFO] 2021-07-09 16:41:16,688 [run_pretraining.py:  535]:	loss/mlm_loss, 10.291903495788574, 2
[INFO] 2021-07-09 16:41:16,688 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.99999905104687e-09, 2
[INFO] 2021-07-09 16:41:16,688 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 2
[INFO] 2021-07-09 16:41:16,688 [run_pretraining.py:  558]:	worker_index: 4, step: 2, cost: 10.291903, mlm loss: 10.291903, speed: 0.191001 steps/s, speed: 1.528011 samples/s, speed: 782.341800 tokens/s, learning rate: 1.000e-08, loss_scalings: 32768.000000, pp_loss: 10.318800
[INFO] 2021-07-09 16:41:16,688 [run_pretraining.py:  512]:	********exe.run_2******* 
[INFO] 2021-07-09 16:41:18,809 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:18,809 [run_pretraining.py:  534]:	loss/total_loss, 10.4010648727417, 3
[INFO] 2021-07-09 16:41:18,809 [run_pretraining.py:  535]:	loss/mlm_loss, 10.4010648727417, 3
[INFO] 2021-07-09 16:41:18,809 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.999999810209374e-08, 3
[INFO] 2021-07-09 16:41:18,810 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 3
[INFO] 2021-07-09 16:41:18,810 [run_pretraining.py:  558]:	worker_index: 4, step: 3, cost: 10.401065, mlm loss: 10.401065, speed: 0.471540 steps/s, speed: 3.772318 samples/s, speed: 1931.426983 tokens/s, learning rate: 2.000e-08, loss_scalings: 32768.000000, pp_loss: 10.241254
[INFO] 2021-07-09 16:41:18,810 [run_pretraining.py:  512]:	********exe.run_3******* 
[INFO] 2021-07-09 16:41:20,927 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:20,928 [run_pretraining.py:  534]:	loss/total_loss, 10.180614471435547, 4
[INFO] 2021-07-09 16:41:20,928 [run_pretraining.py:  535]:	loss/mlm_loss, 10.180614471435547, 4
[INFO] 2021-07-09 16:41:20,928 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.999999892949745e-08, 4
[INFO] 2021-07-09 16:41:20,928 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 4
[INFO] 2021-07-09 16:41:20,928 [run_pretraining.py:  558]:	worker_index: 4, step: 4, cost: 10.180614, mlm loss: 10.180614, speed: 0.472164 steps/s, speed: 3.777312 samples/s, speed: 1933.983694 tokens/s, learning rate: 3.000e-08, loss_scalings: 32768.000000, pp_loss: 10.307020
[INFO] 2021-07-09 16:41:20,928 [run_pretraining.py:  512]:	********exe.run_4******* 
[INFO] 2021-07-09 16:41:23,050 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:23,050 [run_pretraining.py:  534]:	loss/total_loss, 10.311142921447754, 5
[INFO] 2021-07-09 16:41:23,050 [run_pretraining.py:  535]:	loss/mlm_loss, 10.311142921447754, 5
[INFO] 2021-07-09 16:41:23,051 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.999999620418748e-08, 5
[INFO] 2021-07-09 16:41:23,051 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 5
[INFO] 2021-07-09 16:41:23,051 [run_pretraining.py:  558]:	worker_index: 4, step: 5, cost: 10.311143, mlm loss: 10.311143, speed: 0.471308 steps/s, speed: 3.770465 samples/s, speed: 1930.478120 tokens/s, learning rate: 4.000e-08, loss_scalings: 32768.000000, pp_loss: 10.243237
[INFO] 2021-07-09 16:41:23,051 [run_pretraining.py:  512]:	********exe.run_5******* 
[INFO] 2021-07-09 16:41:25,218 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:25,219 [run_pretraining.py:  534]:	loss/total_loss, 10.37358570098877, 6
[INFO] 2021-07-09 16:41:25,219 [run_pretraining.py:  535]:	loss/mlm_loss, 10.37358570098877, 6
[INFO] 2021-07-09 16:41:25,219 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.000000058430487e-08, 6
[INFO] 2021-07-09 16:41:25,219 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 6
[INFO] 2021-07-09 16:41:25,219 [run_pretraining.py:  558]:	worker_index: 4, step: 6, cost: 10.373586, mlm loss: 10.373586, speed: 0.461318 steps/s, speed: 3.690545 samples/s, speed: 1889.559071 tokens/s, learning rate: 5.000e-08, loss_scalings: 32768.000000, pp_loss: 10.244250
[INFO] 2021-07-09 16:41:25,219 [run_pretraining.py:  512]:	********exe.run_6******* 
[INFO] 2021-07-09 16:41:27,428 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:27,429 [run_pretraining.py:  534]:	loss/total_loss, 10.203818321228027, 7
[INFO] 2021-07-09 16:41:27,429 [run_pretraining.py:  535]:	loss/mlm_loss, 10.203818321228027, 7
[INFO] 2021-07-09 16:41:27,429 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.99999978589949e-08, 7
[INFO] 2021-07-09 16:41:27,429 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 7
[INFO] 2021-07-09 16:41:27,429 [run_pretraining.py:  558]:	worker_index: 4, step: 7, cost: 10.203818, mlm loss: 10.203818, speed: 0.452607 steps/s, speed: 3.620855 samples/s, speed: 1853.877632 tokens/s, learning rate: 6.000e-08, loss_scalings: 32768.000000, pp_loss: 10.268323
[INFO] 2021-07-09 16:41:27,429 [run_pretraining.py:  512]:	********exe.run_7******* 
[INFO] 2021-07-09 16:41:29,618 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:29,618 [run_pretraining.py:  534]:	loss/total_loss, 10.123517990112305, 8
[INFO] 2021-07-09 16:41:29,618 [run_pretraining.py:  535]:	loss/mlm_loss, 10.123517990112305, 8
[INFO] 2021-07-09 16:41:29,619 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.999999868639861e-08, 8
[INFO] 2021-07-09 16:41:29,619 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 8
[INFO] 2021-07-09 16:41:29,619 [run_pretraining.py:  558]:	worker_index: 4, step: 8, cost: 10.123518, mlm loss: 10.123518, speed: 0.456888 steps/s, speed: 3.655105 samples/s, speed: 1871.413847 tokens/s, learning rate: 7.000e-08, loss_scalings: 32768.000000, pp_loss: 10.265699
[INFO] 2021-07-09 16:41:29,619 [run_pretraining.py:  512]:	********exe.run_8******* 
[INFO] 2021-07-09 16:41:31,791 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:31,791 [run_pretraining.py:  534]:	loss/total_loss, 10.209203720092773, 9
[INFO] 2021-07-09 16:41:31,792 [run_pretraining.py:  535]:	loss/mlm_loss, 10.209203720092773, 9
[INFO] 2021-07-09 16:41:31,792 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.999999240837496e-08, 9
[INFO] 2021-07-09 16:41:31,792 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 9
[INFO] 2021-07-09 16:41:31,792 [run_pretraining.py:  558]:	worker_index: 4, step: 9, cost: 10.209204, mlm loss: 10.209204, speed: 0.460314 steps/s, speed: 3.682513 samples/s, speed: 1885.446425 tokens/s, learning rate: 8.000e-08, loss_scalings: 32768.000000, pp_loss: 10.200599
[INFO] 2021-07-09 16:41:31,792 [run_pretraining.py:  512]:	********exe.run_9******* 
[INFO] 2021-07-09 16:41:33,979 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:33,979 [run_pretraining.py:  534]:	loss/total_loss, 10.255697250366211, 10
[INFO] 2021-07-09 16:41:33,979 [run_pretraining.py:  535]:	loss/mlm_loss, 10.255697250366211, 10
[INFO] 2021-07-09 16:41:33,980 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.999999323577867e-08, 10
[INFO] 2021-07-09 16:41:33,980 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 10
[INFO] 2021-07-09 16:41:33,980 [run_pretraining.py:  558]:	worker_index: 4, step: 10, cost: 10.255697, mlm loss: 10.255697, speed: 0.457192 steps/s, speed: 3.657540 samples/s, speed: 1872.660226 tokens/s, learning rate: 9.000e-08, loss_scalings: 32768.000000, pp_loss: 10.278796
[INFO] 2021-07-09 16:41:33,980 [run_pretraining.py:  512]:	********exe.run_10******* 
[INFO] 2021-07-09 16:41:36,159 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:36,159 [run_pretraining.py:  534]:	loss/total_loss, 10.127225875854492, 11
[INFO] 2021-07-09 16:41:36,159 [run_pretraining.py:  535]:	loss/mlm_loss, 10.127225875854492, 11
[INFO] 2021-07-09 16:41:36,159 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0000000116860974e-07, 11
[INFO] 2021-07-09 16:41:36,160 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 11
[INFO] 2021-07-09 16:41:36,160 [run_pretraining.py:  558]:	worker_index: 4, step: 11, cost: 10.127226, mlm loss: 10.127226, speed: 0.458867 steps/s, speed: 3.670938 samples/s, speed: 1879.520010 tokens/s, learning rate: 1.000e-07, loss_scalings: 32768.000000, pp_loss: 10.231804
[INFO] 2021-07-09 16:41:36,160 [run_pretraining.py:  512]:	********exe.run_11******* 
[INFO] 2021-07-09 16:41:38,370 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:38,370 [run_pretraining.py:  534]:	loss/total_loss, 9.999320983886719, 12
[INFO] 2021-07-09 16:41:38,370 [run_pretraining.py:  535]:	loss/mlm_loss, 9.999320983886719, 12
[INFO] 2021-07-09 16:41:38,371 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.099999948905861e-07, 12
[INFO] 2021-07-09 16:41:38,371 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 12
[INFO] 2021-07-09 16:41:38,371 [run_pretraining.py:  558]:	worker_index: 4, step: 12, cost: 9.999321, mlm loss: 9.999321, speed: 0.452415 steps/s, speed: 3.619318 samples/s, speed: 1853.090763 tokens/s, learning rate: 1.100e-07, loss_scalings: 32768.000000, pp_loss: 10.203006
[INFO] 2021-07-09 16:41:38,371 [run_pretraining.py:  512]:	********exe.run_12******* 
[INFO] 2021-07-09 16:41:41,079 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:41,080 [run_pretraining.py:  534]:	loss/total_loss, 10.361791610717773, 13
[INFO] 2021-07-09 16:41:41,080 [run_pretraining.py:  535]:	loss/mlm_loss, 10.361791610717773, 13
[INFO] 2021-07-09 16:41:41,080 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.199999957179898e-07, 13
[INFO] 2021-07-09 16:41:41,080 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 13
[INFO] 2021-07-09 16:41:41,080 [run_pretraining.py:  558]:	worker_index: 4, step: 13, cost: 10.361792, mlm loss: 10.361792, speed: 0.369157 steps/s, speed: 2.953254 samples/s, speed: 1512.066052 tokens/s, learning rate: 1.200e-07, loss_scalings: 26214.400391, pp_loss: 10.241806
[INFO] 2021-07-09 16:41:41,080 [run_pretraining.py:  512]:	********exe.run_13******* 
[INFO] 2021-07-09 16:41:43,378 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:43,379 [run_pretraining.py:  534]:	loss/total_loss, 10.290227890014648, 14
[INFO] 2021-07-09 16:41:43,379 [run_pretraining.py:  535]:	loss/mlm_loss, 10.290227890014648, 14
[INFO] 2021-07-09 16:41:43,379 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3000000365082087e-07, 14
[INFO] 2021-07-09 16:41:43,379 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 14
[INFO] 2021-07-09 16:41:43,379 [run_pretraining.py:  558]:	worker_index: 4, step: 14, cost: 10.290228, mlm loss: 10.290228, speed: 0.435148 steps/s, speed: 3.481184 samples/s, speed: 1782.366162 tokens/s, learning rate: 1.300e-07, loss_scalings: 26214.400391, pp_loss: 10.232477
[INFO] 2021-07-09 16:41:43,379 [run_pretraining.py:  512]:	********exe.run_14******* 
[INFO] 2021-07-09 16:41:45,635 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:45,636 [run_pretraining.py:  534]:	loss/total_loss, 10.19692325592041, 15
[INFO] 2021-07-09 16:41:45,636 [run_pretraining.py:  535]:	loss/mlm_loss, 10.19692325592041, 15
[INFO] 2021-07-09 16:41:45,636 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3999999737279722e-07, 15
[INFO] 2021-07-09 16:41:45,636 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 15
[INFO] 2021-07-09 16:41:45,636 [run_pretraining.py:  558]:	worker_index: 4, step: 15, cost: 10.196923, mlm loss: 10.196923, speed: 0.443172 steps/s, speed: 3.545378 samples/s, speed: 1815.233516 tokens/s, learning rate: 1.400e-07, loss_scalings: 26214.400391, pp_loss: 10.260374
[INFO] 2021-07-09 16:41:45,636 [run_pretraining.py:  512]:	********exe.run_15******* 
[INFO] 2021-07-09 16:41:47,874 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:47,875 [run_pretraining.py:  534]:	loss/total_loss, 10.10994815826416, 16
[INFO] 2021-07-09 16:41:47,875 [run_pretraining.py:  535]:	loss/mlm_loss, 10.10994815826416, 16
[INFO] 2021-07-09 16:41:47,875 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4999999109477358e-07, 16
[INFO] 2021-07-09 16:41:47,875 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 16
[INFO] 2021-07-09 16:41:47,875 [run_pretraining.py:  558]:	worker_index: 4, step: 16, cost: 10.109948, mlm loss: 10.109948, speed: 0.446795 steps/s, speed: 3.574360 samples/s, speed: 1830.072451 tokens/s, learning rate: 1.500e-07, loss_scalings: 26214.400391, pp_loss: 10.179252
[INFO] 2021-07-09 16:41:47,875 [run_pretraining.py:  512]:	********exe.run_16******* 
[INFO] 2021-07-09 16:41:50,210 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:50,210 [run_pretraining.py:  534]:	loss/total_loss, 10.262474060058594, 17
[INFO] 2021-07-09 16:41:50,210 [run_pretraining.py:  535]:	loss/mlm_loss, 10.262474060058594, 17
[INFO] 2021-07-09 16:41:50,210 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5999998481674993e-07, 17
[INFO] 2021-07-09 16:41:50,210 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 17
[INFO] 2021-07-09 16:41:50,210 [run_pretraining.py:  558]:	worker_index: 4, step: 17, cost: 10.262474, mlm loss: 10.262474, speed: 0.428296 steps/s, speed: 3.426372 samples/s, speed: 1754.302381 tokens/s, learning rate: 1.600e-07, loss_scalings: 26214.400391, pp_loss: 10.212165
[INFO] 2021-07-09 16:41:50,210 [run_pretraining.py:  512]:	********exe.run_17******* 
[INFO] 2021-07-09 16:41:52,445 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:52,445 [run_pretraining.py:  534]:	loss/total_loss, 10.303163528442383, 18
[INFO] 2021-07-09 16:41:52,446 [run_pretraining.py:  535]:	loss/mlm_loss, 10.303163528442383, 18
[INFO] 2021-07-09 16:41:52,446 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.69999992749581e-07, 18
[INFO] 2021-07-09 16:41:52,446 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 18
[INFO] 2021-07-09 16:41:52,446 [run_pretraining.py:  558]:	worker_index: 4, step: 18, cost: 10.303164, mlm loss: 10.303164, speed: 0.447506 steps/s, speed: 3.580045 samples/s, speed: 1832.982953 tokens/s, learning rate: 1.700e-07, loss_scalings: 26214.400391, pp_loss: 10.164500
[INFO] 2021-07-09 16:41:52,446 [run_pretraining.py:  512]:	********exe.run_18******* 
[INFO] 2021-07-09 16:41:54,724 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:54,725 [run_pretraining.py:  534]:	loss/total_loss, 10.047913551330566, 19
[INFO] 2021-07-09 16:41:54,725 [run_pretraining.py:  535]:	loss/mlm_loss, 10.047913551330566, 19
[INFO] 2021-07-09 16:41:54,725 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7999998647155735e-07, 19
[INFO] 2021-07-09 16:41:54,725 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 19
[INFO] 2021-07-09 16:41:54,725 [run_pretraining.py:  558]:	worker_index: 4, step: 19, cost: 10.047914, mlm loss: 10.047914, speed: 0.438904 steps/s, speed: 3.511229 samples/s, speed: 1797.749467 tokens/s, learning rate: 1.800e-07, loss_scalings: 26214.400391, pp_loss: 10.139966
[INFO] 2021-07-09 16:41:54,725 [run_pretraining.py:  512]:	********exe.run_19******* 
[INFO] 2021-07-09 16:41:57,022 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:57,022 [run_pretraining.py:  534]:	loss/total_loss, 10.140416145324707, 20
[INFO] 2021-07-09 16:41:57,022 [run_pretraining.py:  535]:	loss/mlm_loss, 10.140416145324707, 20
[INFO] 2021-07-09 16:41:57,022 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8999999440438842e-07, 20
[INFO] 2021-07-09 16:41:57,023 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 20
[INFO] 2021-07-09 16:41:57,023 [run_pretraining.py:  558]:	worker_index: 4, step: 20, cost: 10.140416, mlm loss: 10.140416, speed: 0.435360 steps/s, speed: 3.482878 samples/s, speed: 1783.233284 tokens/s, learning rate: 1.900e-07, loss_scalings: 26214.400391, pp_loss: 10.159850
[INFO] 2021-07-09 16:41:57,023 [run_pretraining.py:  512]:	********exe.run_20******* 
[INFO] 2021-07-09 16:41:59,296 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:59,296 [run_pretraining.py:  534]:	loss/total_loss, 10.098010063171387, 21
[INFO] 2021-07-09 16:41:59,297 [run_pretraining.py:  535]:	loss/mlm_loss, 10.098010063171387, 21
[INFO] 2021-07-09 16:41:59,297 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0000000233721948e-07, 21
[INFO] 2021-07-09 16:41:59,297 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 21
[INFO] 2021-07-09 16:41:59,297 [run_pretraining.py:  558]:	worker_index: 4, step: 21, cost: 10.098010, mlm loss: 10.098010, speed: 0.439851 steps/s, speed: 3.518806 samples/s, speed: 1801.628607 tokens/s, learning rate: 2.000e-07, loss_scalings: 26214.400391, pp_loss: 10.125907
[INFO] 2021-07-09 16:41:59,297 [run_pretraining.py:  512]:	********exe.run_21******* 
[INFO] 2021-07-09 16:42:01,592 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:01,593 [run_pretraining.py:  534]:	loss/total_loss, 10.022956848144531, 22
[INFO] 2021-07-09 16:42:01,593 [run_pretraining.py:  535]:	loss/mlm_loss, 10.022956848144531, 22
[INFO] 2021-07-09 16:42:01,593 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0999998184834112e-07, 22
[INFO] 2021-07-09 16:42:01,593 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 22
[INFO] 2021-07-09 16:42:01,593 [run_pretraining.py:  558]:	worker_index: 4, step: 22, cost: 10.022957, mlm loss: 10.022957, speed: 0.435625 steps/s, speed: 3.485000 samples/s, speed: 1784.320088 tokens/s, learning rate: 2.100e-07, loss_scalings: 26214.400391, pp_loss: 10.159348
[INFO] 2021-07-09 16:42:01,593 [run_pretraining.py:  512]:	********exe.run_22******* 
[INFO] 2021-07-09 16:42:03,805 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:03,805 [run_pretraining.py:  534]:	loss/total_loss, 10.245354652404785, 23
[INFO] 2021-07-09 16:42:03,805 [run_pretraining.py:  535]:	loss/mlm_loss, 10.245354652404785, 23
[INFO] 2021-07-09 16:42:03,805 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.199999897811722e-07, 23
[INFO] 2021-07-09 16:42:03,806 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 23
[INFO] 2021-07-09 16:42:03,806 [run_pretraining.py:  558]:	worker_index: 4, step: 23, cost: 10.245355, mlm loss: 10.245355, speed: 0.452094 steps/s, speed: 3.616751 samples/s, speed: 1851.776472 tokens/s, learning rate: 2.200e-07, loss_scalings: 26214.400391, pp_loss: 10.117026
[INFO] 2021-07-09 16:42:03,806 [run_pretraining.py:  512]:	********exe.run_23******* 
[INFO] 2021-07-09 16:42:06,005 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:06,006 [run_pretraining.py:  534]:	loss/total_loss, 10.06844711303711, 24
[INFO] 2021-07-09 16:42:06,006 [run_pretraining.py:  535]:	loss/mlm_loss, 10.06844711303711, 24
[INFO] 2021-07-09 16:42:06,006 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2999999771400326e-07, 24
[INFO] 2021-07-09 16:42:06,006 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 24
[INFO] 2021-07-09 16:42:06,007 [run_pretraining.py:  558]:	worker_index: 4, step: 24, cost: 10.068447, mlm loss: 10.068447, speed: 0.454506 steps/s, speed: 3.636050 samples/s, speed: 1861.657345 tokens/s, learning rate: 2.300e-07, loss_scalings: 26214.400391, pp_loss: 10.067451
[INFO] 2021-07-09 16:42:06,007 [run_pretraining.py:  512]:	********exe.run_24******* 
[INFO] 2021-07-09 16:42:08,206 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:08,207 [run_pretraining.py:  534]:	loss/total_loss, 9.978584289550781, 25
[INFO] 2021-07-09 16:42:08,207 [run_pretraining.py:  535]:	loss/mlm_loss, 9.978584289550781, 25
[INFO] 2021-07-09 16:42:08,207 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.399999914359796e-07, 25
[INFO] 2021-07-09 16:42:08,207 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 25
[INFO] 2021-07-09 16:42:08,207 [run_pretraining.py:  558]:	worker_index: 4, step: 25, cost: 9.978584, mlm loss: 9.978584, speed: 0.454524 steps/s, speed: 3.636190 samples/s, speed: 1861.729166 tokens/s, learning rate: 2.400e-07, loss_scalings: 26214.400391, pp_loss: 10.054546
[INFO] 2021-07-09 16:42:08,207 [run_pretraining.py:  512]:	********exe.run_25******* 
[INFO] 2021-07-09 16:42:10,482 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:10,482 [run_pretraining.py:  534]:	loss/total_loss, 10.130136489868164, 26
[INFO] 2021-07-09 16:42:10,482 [run_pretraining.py:  535]:	loss/mlm_loss, 10.130136489868164, 26
[INFO] 2021-07-09 16:42:10,482 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.499999993688107e-07, 26
[INFO] 2021-07-09 16:42:10,483 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 26
[INFO] 2021-07-09 16:42:10,483 [run_pretraining.py:  558]:	worker_index: 4, step: 26, cost: 10.130136, mlm loss: 10.130136, speed: 0.439661 steps/s, speed: 3.517288 samples/s, speed: 1800.851478 tokens/s, learning rate: 2.500e-07, loss_scalings: 26214.400391, pp_loss: 10.126533
[INFO] 2021-07-09 16:42:10,483 [run_pretraining.py:  512]:	********exe.run_26******* 
[INFO] 2021-07-09 16:42:12,720 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:12,721 [run_pretraining.py:  534]:	loss/total_loss, 10.09134292602539, 27
[INFO] 2021-07-09 16:42:12,721 [run_pretraining.py:  535]:	loss/mlm_loss, 10.09134292602539, 27
[INFO] 2021-07-09 16:42:12,721 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6000000730164174e-07, 27
[INFO] 2021-07-09 16:42:12,721 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 27
[INFO] 2021-07-09 16:42:12,721 [run_pretraining.py:  558]:	worker_index: 4, step: 27, cost: 10.091343, mlm loss: 10.091343, speed: 0.446863 steps/s, speed: 3.574901 samples/s, speed: 1830.349317 tokens/s, learning rate: 2.600e-07, loss_scalings: 26214.400391, pp_loss: 10.091148
[INFO] 2021-07-09 16:42:12,721 [run_pretraining.py:  512]:	********exe.run_27******* 
[INFO] 2021-07-09 16:42:14,989 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:14,989 [run_pretraining.py:  534]:	loss/total_loss, 10.14507007598877, 28
[INFO] 2021-07-09 16:42:14,990 [run_pretraining.py:  535]:	loss/mlm_loss, 10.14507007598877, 28
[INFO] 2021-07-09 16:42:14,990 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.699999868127634e-07, 28
[INFO] 2021-07-09 16:42:14,990 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 28
[INFO] 2021-07-09 16:42:14,990 [run_pretraining.py:  558]:	worker_index: 4, step: 28, cost: 10.145070, mlm loss: 10.145070, speed: 0.440917 steps/s, speed: 3.527339 samples/s, speed: 1805.997322 tokens/s, learning rate: 2.700e-07, loss_scalings: 26214.400391, pp_loss: 10.048776
[INFO] 2021-07-09 16:42:14,990 [run_pretraining.py:  512]:	********exe.run_28******* 
[INFO] 2021-07-09 16:42:17,313 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:17,314 [run_pretraining.py:  534]:	loss/total_loss, 9.928818702697754, 29
[INFO] 2021-07-09 16:42:17,314 [run_pretraining.py:  535]:	loss/mlm_loss, 9.928818702697754, 29
[INFO] 2021-07-09 16:42:17,314 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7999999474559445e-07, 29
[INFO] 2021-07-09 16:42:17,314 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 29
[INFO] 2021-07-09 16:42:17,314 [run_pretraining.py:  558]:	worker_index: 4, step: 29, cost: 9.928819, mlm loss: 9.928819, speed: 0.430388 steps/s, speed: 3.443104 samples/s, speed: 1762.869216 tokens/s, learning rate: 2.800e-07, loss_scalings: 26214.400391, pp_loss: 10.037248
[INFO] 2021-07-09 16:42:17,314 [run_pretraining.py:  512]:	********exe.run_29******* 
[INFO] 2021-07-09 16:42:19,518 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:19,518 [run_pretraining.py:  534]:	loss/total_loss, 9.967488288879395, 30
[INFO] 2021-07-09 16:42:19,519 [run_pretraining.py:  535]:	loss/mlm_loss, 9.967488288879395, 30
[INFO] 2021-07-09 16:42:19,519 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.900000026784255e-07, 30
[INFO] 2021-07-09 16:42:19,519 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 30
[INFO] 2021-07-09 16:42:19,519 [run_pretraining.py:  558]:	worker_index: 4, step: 30, cost: 9.967488, mlm loss: 9.967488, speed: 0.453694 steps/s, speed: 3.629552 samples/s, speed: 1858.330852 tokens/s, learning rate: 2.900e-07, loss_scalings: 26214.400391, pp_loss: 9.997993
[INFO] 2021-07-09 16:42:19,519 [run_pretraining.py:  512]:	********exe.run_30******* 
[INFO] 2021-07-09 16:42:21,718 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:21,718 [run_pretraining.py:  534]:	loss/total_loss, 10.034229278564453, 31
[INFO] 2021-07-09 16:42:21,719 [run_pretraining.py:  535]:	loss/mlm_loss, 10.034229278564453, 31
[INFO] 2021-07-09 16:42:21,719 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9999998218954715e-07, 31
[INFO] 2021-07-09 16:42:21,719 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 31
[INFO] 2021-07-09 16:42:21,719 [run_pretraining.py:  558]:	worker_index: 4, step: 31, cost: 10.034229, mlm loss: 10.034229, speed: 0.454705 steps/s, speed: 3.637642 samples/s, speed: 1862.472507 tokens/s, learning rate: 3.000e-07, loss_scalings: 26214.400391, pp_loss: 10.010260
[INFO] 2021-07-09 16:42:21,719 [run_pretraining.py:  512]:	********exe.run_31******* 
[INFO] 2021-07-09 16:42:23,908 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:23,909 [run_pretraining.py:  534]:	loss/total_loss, 9.878396987915039, 32
[INFO] 2021-07-09 16:42:23,909 [run_pretraining.py:  535]:	loss/mlm_loss, 9.878396987915039, 32
[INFO] 2021-07-09 16:42:23,909 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.099999901223782e-07, 32
[INFO] 2021-07-09 16:42:23,909 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 32
[INFO] 2021-07-09 16:42:23,909 [run_pretraining.py:  558]:	worker_index: 4, step: 32, cost: 9.878397, mlm loss: 9.878397, speed: 0.456668 steps/s, speed: 3.653348 samples/s, speed: 1870.514059 tokens/s, learning rate: 3.100e-07, loss_scalings: 26214.400391, pp_loss: 9.953290
[INFO] 2021-07-09 16:42:23,909 [run_pretraining.py:  512]:	********exe.run_32******* 
[INFO] 2021-07-09 16:42:26,116 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:26,116 [run_pretraining.py:  534]:	loss/total_loss, 9.965083122253418, 33
[INFO] 2021-07-09 16:42:26,116 [run_pretraining.py:  535]:	loss/mlm_loss, 9.965083122253418, 33
[INFO] 2021-07-09 16:42:26,116 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.1999996963349986e-07, 33
[INFO] 2021-07-09 16:42:26,117 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 33
[INFO] 2021-07-09 16:42:26,117 [run_pretraining.py:  558]:	worker_index: 4, step: 33, cost: 9.965083, mlm loss: 9.965083, speed: 0.453181 steps/s, speed: 3.625451 samples/s, speed: 1856.230823 tokens/s, learning rate: 3.200e-07, loss_scalings: 26214.400391, pp_loss: 9.976157
[INFO] 2021-07-09 16:42:26,117 [run_pretraining.py:  512]:	********exe.run_33******* 
[INFO] 2021-07-09 16:42:28,334 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:28,335 [run_pretraining.py:  534]:	loss/total_loss, 10.080608367919922, 34
[INFO] 2021-07-09 16:42:28,335 [run_pretraining.py:  535]:	loss/mlm_loss, 10.080608367919922, 34
[INFO] 2021-07-09 16:42:28,335 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.2999997756633093e-07, 34
[INFO] 2021-07-09 16:42:28,335 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 34
[INFO] 2021-07-09 16:42:28,335 [run_pretraining.py:  558]:	worker_index: 4, step: 34, cost: 10.080608, mlm loss: 10.080608, speed: 0.450847 steps/s, speed: 3.606775 samples/s, speed: 1846.668703 tokens/s, learning rate: 3.300e-07, loss_scalings: 26214.400391, pp_loss: 9.928404
[INFO] 2021-07-09 16:42:28,335 [run_pretraining.py:  512]:	********exe.run_34******* 
[INFO] 2021-07-09 16:42:30,590 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:30,591 [run_pretraining.py:  534]:	loss/total_loss, 9.94711685180664, 35
[INFO] 2021-07-09 16:42:30,591 [run_pretraining.py:  535]:	loss/mlm_loss, 9.94711685180664, 35
[INFO] 2021-07-09 16:42:30,591 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.39999985499162e-07, 35
[INFO] 2021-07-09 16:42:30,591 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 35
[INFO] 2021-07-09 16:42:30,591 [run_pretraining.py:  558]:	worker_index: 4, step: 35, cost: 9.947117, mlm loss: 9.947117, speed: 0.443405 steps/s, speed: 3.547243 samples/s, speed: 1816.188599 tokens/s, learning rate: 3.400e-07, loss_scalings: 26214.400391, pp_loss: 9.930223
[INFO] 2021-07-09 16:42:30,591 [run_pretraining.py:  512]:	********exe.run_35******* 
[INFO] 2021-07-09 16:42:32,724 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:32,725 [run_pretraining.py:  534]:	loss/total_loss, 9.858064651489258, 36
[INFO] 2021-07-09 16:42:32,725 [run_pretraining.py:  535]:	loss/mlm_loss, 9.858064651489258, 36
[INFO] 2021-07-09 16:42:32,725 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.4999999343199306e-07, 36
[INFO] 2021-07-09 16:42:32,725 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 36
[INFO] 2021-07-09 16:42:32,725 [run_pretraining.py:  558]:	worker_index: 4, step: 36, cost: 9.858065, mlm loss: 9.858065, speed: 0.468773 steps/s, speed: 3.750183 samples/s, speed: 1920.093889 tokens/s, learning rate: 3.500e-07, loss_scalings: 26214.400391, pp_loss: 9.889413
[INFO] 2021-07-09 16:42:32,725 [run_pretraining.py:  512]:	********exe.run_36******* 
[INFO] 2021-07-09 16:42:34,810 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:34,811 [run_pretraining.py:  534]:	loss/total_loss, 9.92542552947998, 37
[INFO] 2021-07-09 16:42:34,811 [run_pretraining.py:  535]:	loss/mlm_loss, 9.92542552947998, 37
[INFO] 2021-07-09 16:42:34,811 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.599999729431147e-07, 37
[INFO] 2021-07-09 16:42:34,811 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 37
[INFO] 2021-07-09 16:42:34,811 [run_pretraining.py:  558]:	worker_index: 4, step: 37, cost: 9.925426, mlm loss: 9.925426, speed: 0.479503 steps/s, speed: 3.836027 samples/s, speed: 1964.045932 tokens/s, learning rate: 3.600e-07, loss_scalings: 26214.400391, pp_loss: 9.908174
[INFO] 2021-07-09 16:42:34,811 [run_pretraining.py:  512]:	********exe.run_37******* 
[INFO] 2021-07-09 16:42:36,888 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:36,889 [run_pretraining.py:  534]:	loss/total_loss, 9.878973007202148, 38
[INFO] 2021-07-09 16:42:36,889 [run_pretraining.py:  535]:	loss/mlm_loss, 9.878973007202148, 38
[INFO] 2021-07-09 16:42:36,889 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.6999998087594577e-07, 38
[INFO] 2021-07-09 16:42:36,889 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 38
[INFO] 2021-07-09 16:42:36,889 [run_pretraining.py:  558]:	worker_index: 4, step: 38, cost: 9.878973, mlm loss: 9.878973, speed: 0.481472 steps/s, speed: 3.851773 samples/s, speed: 1972.108026 tokens/s, learning rate: 3.700e-07, loss_scalings: 26214.400391, pp_loss: 9.863561
[INFO] 2021-07-09 16:42:36,889 [run_pretraining.py:  512]:	********exe.run_38******* 
[INFO] 2021-07-09 16:42:38,988 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:38,988 [run_pretraining.py:  534]:	loss/total_loss, 9.886231422424316, 39
[INFO] 2021-07-09 16:42:38,988 [run_pretraining.py:  535]:	loss/mlm_loss, 9.886231422424316, 39
[INFO] 2021-07-09 16:42:38,988 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.7999998880877683e-07, 39
[INFO] 2021-07-09 16:42:38,988 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 39
[INFO] 2021-07-09 16:42:38,989 [run_pretraining.py:  558]:	worker_index: 4, step: 39, cost: 9.886231, mlm loss: 9.886231, speed: 0.476436 steps/s, speed: 3.811488 samples/s, speed: 1951.481926 tokens/s, learning rate: 3.800e-07, loss_scalings: 26214.400391, pp_loss: 9.831593
[INFO] 2021-07-09 16:42:38,989 [run_pretraining.py:  512]:	********exe.run_39******* 
[INFO] 2021-07-09 16:42:41,052 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:41,053 [run_pretraining.py:  534]:	loss/total_loss, 9.773321151733398, 40
[INFO] 2021-07-09 16:42:41,053 [run_pretraining.py:  535]:	loss/mlm_loss, 9.773321151733398, 40
[INFO] 2021-07-09 16:42:41,053 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.8999996831989847e-07, 40
[INFO] 2021-07-09 16:42:41,053 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 40
[INFO] 2021-07-09 16:42:41,053 [run_pretraining.py:  558]:	worker_index: 4, step: 40, cost: 9.773321, mlm loss: 9.773321, speed: 0.484539 steps/s, speed: 3.876314 samples/s, speed: 1984.672984 tokens/s, learning rate: 3.900e-07, loss_scalings: 26214.400391, pp_loss: 9.881862
[INFO] 2021-07-09 16:42:41,053 [run_pretraining.py:  512]:	********exe.run_40******* 
[INFO] 2021-07-09 16:42:43,124 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:43,125 [run_pretraining.py:  534]:	loss/total_loss, 9.876398086547852, 41
[INFO] 2021-07-09 16:42:43,125 [run_pretraining.py:  535]:	loss/mlm_loss, 9.876398086547852, 41
[INFO] 2021-07-09 16:42:43,125 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.0000000467443897e-07, 41
[INFO] 2021-07-09 16:42:43,125 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 41
[INFO] 2021-07-09 16:42:43,125 [run_pretraining.py:  558]:	worker_index: 4, step: 41, cost: 9.876398, mlm loss: 9.876398, speed: 0.482713 steps/s, speed: 3.861702 samples/s, speed: 1977.191368 tokens/s, learning rate: 4.000e-07, loss_scalings: 26214.400391, pp_loss: 9.811055
[INFO] 2021-07-09 16:42:43,125 [run_pretraining.py:  512]:	********exe.run_41******* 
[INFO] 2021-07-09 16:42:45,201 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:45,201 [run_pretraining.py:  534]:	loss/total_loss, 9.7338228225708, 42
[INFO] 2021-07-09 16:42:45,201 [run_pretraining.py:  535]:	loss/mlm_loss, 9.7338228225708, 42
[INFO] 2021-07-09 16:42:45,202 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.099999841855606e-07, 42
[INFO] 2021-07-09 16:42:45,202 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 42
[INFO] 2021-07-09 16:42:45,202 [run_pretraining.py:  558]:	worker_index: 4, step: 42, cost: 9.733823, mlm loss: 9.733823, speed: 0.481772 steps/s, speed: 3.854173 samples/s, speed: 1973.336459 tokens/s, learning rate: 4.100e-07, loss_scalings: 26214.400391, pp_loss: 9.837935
[INFO] 2021-07-09 16:42:45,202 [run_pretraining.py:  512]:	********exe.run_42******* 
[INFO] 2021-07-09 16:42:47,297 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:47,297 [run_pretraining.py:  534]:	loss/total_loss, 9.694734573364258, 43
[INFO] 2021-07-09 16:42:47,297 [run_pretraining.py:  535]:	loss/mlm_loss, 9.694734573364258, 43
[INFO] 2021-07-09 16:42:47,297 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.1999996369668224e-07, 43
[INFO] 2021-07-09 16:42:47,298 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 43
[INFO] 2021-07-09 16:42:47,298 [run_pretraining.py:  558]:	worker_index: 4, step: 43, cost: 9.694735, mlm loss: 9.694735, speed: 0.477262 steps/s, speed: 3.818098 samples/s, speed: 1954.866275 tokens/s, learning rate: 4.200e-07, loss_scalings: 26214.400391, pp_loss: 9.736809
[INFO] 2021-07-09 16:42:47,298 [run_pretraining.py:  512]:	********exe.run_43******* 
[INFO] 2021-07-09 16:42:49,495 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:49,496 [run_pretraining.py:  534]:	loss/total_loss, 9.73641586303711, 44
[INFO] 2021-07-09 16:42:49,496 [run_pretraining.py:  535]:	loss/mlm_loss, 9.73641586303711, 44
[INFO] 2021-07-09 16:42:49,496 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.3000000005122274e-07, 44
[INFO] 2021-07-09 16:42:49,496 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 44
[INFO] 2021-07-09 16:42:49,496 [run_pretraining.py:  558]:	worker_index: 4, step: 44, cost: 9.736416, mlm loss: 9.736416, speed: 0.454996 steps/s, speed: 3.639967 samples/s, speed: 1863.663129 tokens/s, learning rate: 4.300e-07, loss_scalings: 26214.400391, pp_loss: 9.744453
[INFO] 2021-07-09 16:42:49,496 [run_pretraining.py:  512]:	********exe.run_44******* 
[INFO] 2021-07-09 16:42:51,667 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:51,667 [run_pretraining.py:  534]:	loss/total_loss, 9.929597854614258, 45
[INFO] 2021-07-09 16:42:51,667 [run_pretraining.py:  535]:	loss/mlm_loss, 9.929597854614258, 45
[INFO] 2021-07-09 16:42:51,667 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.399999795623444e-07, 45
[INFO] 2021-07-09 16:42:51,667 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 45
[INFO] 2021-07-09 16:42:51,667 [run_pretraining.py:  558]:	worker_index: 4, step: 45, cost: 9.929598, mlm loss: 9.929598, speed: 0.460715 steps/s, speed: 3.685720 samples/s, speed: 1887.088546 tokens/s, learning rate: 4.400e-07, loss_scalings: 26214.400391, pp_loss: 9.703558
[INFO] 2021-07-09 16:42:51,667 [run_pretraining.py:  512]:	********exe.run_45******* 
[INFO] 2021-07-09 16:42:53,855 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:53,856 [run_pretraining.py:  534]:	loss/total_loss, 9.7555570602417, 46
[INFO] 2021-07-09 16:42:53,856 [run_pretraining.py:  535]:	loss/mlm_loss, 9.7555570602417, 46
[INFO] 2021-07-09 16:42:53,856 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.49999959073466e-07, 46
[INFO] 2021-07-09 16:42:53,856 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 46
[INFO] 2021-07-09 16:42:53,856 [run_pretraining.py:  558]:	worker_index: 4, step: 46, cost: 9.755557, mlm loss: 9.755557, speed: 0.457060 steps/s, speed: 3.656483 samples/s, speed: 1872.119245 tokens/s, learning rate: 4.500e-07, loss_scalings: 26214.400391, pp_loss: 9.662888
[INFO] 2021-07-09 16:42:53,856 [run_pretraining.py:  512]:	********exe.run_46******* 
[INFO] 2021-07-09 16:42:56,100 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:56,100 [run_pretraining.py:  534]:	loss/total_loss, 9.606596946716309, 47
[INFO] 2021-07-09 16:42:56,100 [run_pretraining.py:  535]:	loss/mlm_loss, 9.606596946716309, 47
[INFO] 2021-07-09 16:42:56,100 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.599999954280065e-07, 47
[INFO] 2021-07-09 16:42:56,100 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 47
[INFO] 2021-07-09 16:42:56,100 [run_pretraining.py:  558]:	worker_index: 4, step: 47, cost: 9.606597, mlm loss: 9.606597, speed: 0.445669 steps/s, speed: 3.565353 samples/s, speed: 1825.460543 tokens/s, learning rate: 4.600e-07, loss_scalings: 26214.400391, pp_loss: 9.686751
[INFO] 2021-07-09 16:42:56,100 [run_pretraining.py:  512]:	********exe.run_47******* 
[INFO] 2021-07-09 16:42:58,375 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:58,375 [run_pretraining.py:  534]:	loss/total_loss, 9.504226684570312, 48
[INFO] 2021-07-09 16:42:58,376 [run_pretraining.py:  535]:	loss/mlm_loss, 9.504226684570312, 48
[INFO] 2021-07-09 16:42:58,376 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.6999997493912815e-07, 48
[INFO] 2021-07-09 16:42:58,376 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 48
[INFO] 2021-07-09 16:42:58,376 [run_pretraining.py:  558]:	worker_index: 4, step: 48, cost: 9.504227, mlm loss: 9.504227, speed: 0.439603 steps/s, speed: 3.516826 samples/s, speed: 1800.614790 tokens/s, learning rate: 4.700e-07, loss_scalings: 26214.400391, pp_loss: 9.657563
[INFO] 2021-07-09 16:42:58,376 [run_pretraining.py:  512]:	********exe.run_48******* 
[INFO] 2021-07-09 16:43:00,610 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:00,611 [run_pretraining.py:  534]:	loss/total_loss, 9.505674362182617, 49
[INFO] 2021-07-09 16:43:00,611 [run_pretraining.py:  535]:	loss/mlm_loss, 9.505674362182617, 49
[INFO] 2021-07-09 16:43:00,611 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.799999828719592e-07, 49
[INFO] 2021-07-09 16:43:00,611 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 49
[INFO] 2021-07-09 16:43:00,611 [run_pretraining.py:  558]:	worker_index: 4, step: 49, cost: 9.505674, mlm loss: 9.505674, speed: 0.447506 steps/s, speed: 3.580046 samples/s, speed: 1832.983540 tokens/s, learning rate: 4.800e-07, loss_scalings: 26214.400391, pp_loss: 9.598705
[INFO] 2021-07-09 16:43:00,611 [run_pretraining.py:  512]:	********exe.run_49******* 
[INFO] 2021-07-09 16:43:02,964 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:02,965 [run_pretraining.py:  534]:	loss/total_loss, 9.673490524291992, 50
[INFO] 2021-07-09 16:43:02,965 [run_pretraining.py:  535]:	loss/mlm_loss, 9.673490524291992, 50
[INFO] 2021-07-09 16:43:02,965 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.899999908047903e-07, 50
[INFO] 2021-07-09 16:43:02,965 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 50
[INFO] 2021-07-09 16:43:02,965 [run_pretraining.py:  558]:	worker_index: 4, step: 50, cost: 9.673491, mlm loss: 9.673491, speed: 0.424890 steps/s, speed: 3.399121 samples/s, speed: 1740.349892 tokens/s, learning rate: 4.900e-07, loss_scalings: 26214.400391, pp_loss: 9.608810
[INFO] 2021-07-09 16:43:02,965 [run_pretraining.py:  512]:	********exe.run_50******* 
[INFO] 2021-07-09 16:43:05,154 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:05,155 [run_pretraining.py:  534]:	loss/total_loss, 9.597850799560547, 51
[INFO] 2021-07-09 16:43:05,155 [run_pretraining.py:  535]:	loss/mlm_loss, 9.597850799560547, 51
[INFO] 2021-07-09 16:43:05,155 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.999999987376214e-07, 51
[INFO] 2021-07-09 16:43:05,155 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 51
[INFO] 2021-07-09 16:43:05,155 [run_pretraining.py:  558]:	worker_index: 4, step: 51, cost: 9.597851, mlm loss: 9.597851, speed: 0.456767 steps/s, speed: 3.654137 samples/s, speed: 1870.918001 tokens/s, learning rate: 5.000e-07, loss_scalings: 26214.400391, pp_loss: 9.529634
[INFO] 2021-07-09 16:43:05,155 [run_pretraining.py:  512]:	********exe.run_51******* 
[INFO] 2021-07-09 16:43:07,439 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:07,440 [run_pretraining.py:  534]:	loss/total_loss, 9.599737167358398, 52
[INFO] 2021-07-09 16:43:07,440 [run_pretraining.py:  535]:	loss/mlm_loss, 9.599737167358398, 52
[INFO] 2021-07-09 16:43:07,440 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.100000066704524e-07, 52
[INFO] 2021-07-09 16:43:07,440 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 52
[INFO] 2021-07-09 16:43:07,440 [run_pretraining.py:  558]:	worker_index: 4, step: 52, cost: 9.599737, mlm loss: 9.599737, speed: 0.437739 steps/s, speed: 3.501913 samples/s, speed: 1792.979543 tokens/s, learning rate: 5.100e-07, loss_scalings: 26214.400391, pp_loss: 9.552956
[INFO] 2021-07-09 16:43:07,441 [run_pretraining.py:  512]:	********exe.run_52******* 
[INFO] 2021-07-09 16:43:09,645 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:09,646 [run_pretraining.py:  534]:	loss/total_loss, 9.393651008605957, 53
[INFO] 2021-07-09 16:43:09,646 [run_pretraining.py:  535]:	loss/mlm_loss, 9.393651008605957, 53
[INFO] 2021-07-09 16:43:09,646 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.200000146032835e-07, 53
[INFO] 2021-07-09 16:43:09,646 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 53
[INFO] 2021-07-09 16:43:09,646 [run_pretraining.py:  558]:	worker_index: 4, step: 53, cost: 9.393651, mlm loss: 9.393651, speed: 0.453526 steps/s, speed: 3.628209 samples/s, speed: 1857.643237 tokens/s, learning rate: 5.200e-07, loss_scalings: 26214.400391, pp_loss: 9.501414
[INFO] 2021-07-09 16:43:09,646 [run_pretraining.py:  512]:	********exe.run_53******* 
[INFO] 2021-07-09 16:43:11,969 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:11,969 [run_pretraining.py:  534]:	loss/total_loss, 9.516315460205078, 54
[INFO] 2021-07-09 16:43:11,969 [run_pretraining.py:  535]:	loss/mlm_loss, 9.516315460205078, 54
[INFO] 2021-07-09 16:43:11,969 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.299999656926957e-07, 54
[INFO] 2021-07-09 16:43:11,969 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 54
[INFO] 2021-07-09 16:43:11,970 [run_pretraining.py:  558]:	worker_index: 4, step: 54, cost: 9.516315, mlm loss: 9.516315, speed: 0.430500 steps/s, speed: 3.444004 samples/s, speed: 1763.329888 tokens/s, learning rate: 5.300e-07, loss_scalings: 26214.400391, pp_loss: 9.486832
[INFO] 2021-07-09 16:43:11,970 [run_pretraining.py:  512]:	********exe.run_54******* 
[INFO] 2021-07-09 16:43:14,174 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:14,174 [run_pretraining.py:  534]:	loss/total_loss, 9.362382888793945, 55
[INFO] 2021-07-09 16:43:14,175 [run_pretraining.py:  535]:	loss/mlm_loss, 9.362382888793945, 55
[INFO] 2021-07-09 16:43:14,175 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.399999736255268e-07, 55
[INFO] 2021-07-09 16:43:14,175 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 55
[INFO] 2021-07-09 16:43:14,175 [run_pretraining.py:  558]:	worker_index: 4, step: 55, cost: 9.362383, mlm loss: 9.362383, speed: 0.453573 steps/s, speed: 3.628588 samples/s, speed: 1857.836891 tokens/s, learning rate: 5.400e-07, loss_scalings: 26214.400391, pp_loss: 9.446838
[INFO] 2021-07-09 16:43:14,175 [run_pretraining.py:  512]:	********exe.run_55******* 
[INFO] 2021-07-09 16:43:16,409 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:16,410 [run_pretraining.py:  534]:	loss/total_loss, 9.44969367980957, 56
[INFO] 2021-07-09 16:43:16,410 [run_pretraining.py:  535]:	loss/mlm_loss, 9.44969367980957, 56
[INFO] 2021-07-09 16:43:16,410 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.499999815583578e-07, 56
[INFO] 2021-07-09 16:43:16,410 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 56
[INFO] 2021-07-09 16:43:16,410 [run_pretraining.py:  558]:	worker_index: 4, step: 56, cost: 9.449694, mlm loss: 9.449694, speed: 0.447498 steps/s, speed: 3.579986 samples/s, speed: 1832.953032 tokens/s, learning rate: 5.500e-07, loss_scalings: 26214.400391, pp_loss: 9.386223
[INFO] 2021-07-09 16:43:16,410 [run_pretraining.py:  512]:	********exe.run_56******* 
[INFO] 2021-07-09 16:43:18,622 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:18,623 [run_pretraining.py:  534]:	loss/total_loss, 9.369542121887207, 57
[INFO] 2021-07-09 16:43:18,623 [run_pretraining.py:  535]:	loss/mlm_loss, 9.369542121887207, 57
[INFO] 2021-07-09 16:43:18,623 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.599999894911889e-07, 57
[INFO] 2021-07-09 16:43:18,623 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 57
[INFO] 2021-07-09 16:43:18,624 [run_pretraining.py:  558]:	worker_index: 4, step: 57, cost: 9.369542, mlm loss: 9.369542, speed: 0.451946 steps/s, speed: 3.615569 samples/s, speed: 1851.171487 tokens/s, learning rate: 5.600e-07, loss_scalings: 26214.400391, pp_loss: 9.342452
[INFO] 2021-07-09 16:43:18,624 [run_pretraining.py:  512]:	********exe.run_57******* 
[INFO] 2021-07-09 16:43:20,798 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:20,799 [run_pretraining.py:  534]:	loss/total_loss, 9.424420356750488, 58
[INFO] 2021-07-09 16:43:20,799 [run_pretraining.py:  535]:	loss/mlm_loss, 9.424420356750488, 58
[INFO] 2021-07-09 16:43:20,799 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.6999999742402e-07, 58
[INFO] 2021-07-09 16:43:20,799 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 58
[INFO] 2021-07-09 16:43:20,799 [run_pretraining.py:  558]:	worker_index: 4, step: 58, cost: 9.424420, mlm loss: 9.424420, speed: 0.459734 steps/s, speed: 3.677876 samples/s, speed: 1883.072288 tokens/s, learning rate: 5.700e-07, loss_scalings: 26214.400391, pp_loss: 9.387741
[INFO] 2021-07-09 16:43:20,800 [run_pretraining.py:  512]:	********exe.run_58******* 
[INFO] 2021-07-09 16:43:23,032 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:23,032 [run_pretraining.py:  534]:	loss/total_loss, 9.410140037536621, 59
[INFO] 2021-07-09 16:43:23,032 [run_pretraining.py:  535]:	loss/mlm_loss, 9.410140037536621, 59
[INFO] 2021-07-09 16:43:23,033 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.80000005356851e-07, 59
[INFO] 2021-07-09 16:43:23,033 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 59
[INFO] 2021-07-09 16:43:23,033 [run_pretraining.py:  558]:	worker_index: 4, step: 59, cost: 9.410140, mlm loss: 9.410140, speed: 0.447924 steps/s, speed: 3.583393 samples/s, speed: 1834.697337 tokens/s, learning rate: 5.800e-07, loss_scalings: 26214.400391, pp_loss: 9.318279
[INFO] 2021-07-09 16:43:23,033 [run_pretraining.py:  512]:	********exe.run_59******* 
[INFO] 2021-07-09 16:43:25,252 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:25,253 [run_pretraining.py:  534]:	loss/total_loss, 9.252585411071777, 60
[INFO] 2021-07-09 16:43:25,253 [run_pretraining.py:  535]:	loss/mlm_loss, 9.252585411071777, 60
[INFO] 2021-07-09 16:43:25,253 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.900000132896821e-07, 60
[INFO] 2021-07-09 16:43:25,253 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 60
[INFO] 2021-07-09 16:43:25,253 [run_pretraining.py:  558]:	worker_index: 4, step: 60, cost: 9.252585, mlm loss: 9.252585, speed: 0.450485 steps/s, speed: 3.603881 samples/s, speed: 1845.187106 tokens/s, learning rate: 5.900e-07, loss_scalings: 26214.400391, pp_loss: 9.236358
[INFO] 2021-07-09 16:43:25,253 [run_pretraining.py:  512]:	********exe.run_60******* 
[INFO] 2021-07-09 16:43:27,464 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:27,465 [run_pretraining.py:  534]:	loss/total_loss, 9.120064735412598, 61
[INFO] 2021-07-09 16:43:27,465 [run_pretraining.py:  535]:	loss/mlm_loss, 9.120064735412598, 61
[INFO] 2021-07-09 16:43:27,465 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.999999643790943e-07, 61
[INFO] 2021-07-09 16:43:27,465 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 61
[INFO] 2021-07-09 16:43:27,465 [run_pretraining.py:  558]:	worker_index: 4, step: 61, cost: 9.120065, mlm loss: 9.120065, speed: 0.452251 steps/s, speed: 3.618009 samples/s, speed: 1852.420801 tokens/s, learning rate: 6.000e-07, loss_scalings: 26214.400391, pp_loss: 9.267303
[INFO] 2021-07-09 16:43:27,465 [run_pretraining.py:  512]:	********exe.run_61******* 
[INFO] 2021-07-09 16:43:29,750 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:29,750 [run_pretraining.py:  534]:	loss/total_loss, 9.2294282913208, 62
[INFO] 2021-07-09 16:43:29,750 [run_pretraining.py:  535]:	loss/mlm_loss, 9.2294282913208, 62
[INFO] 2021-07-09 16:43:29,750 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.099999723119254e-07, 62
[INFO] 2021-07-09 16:43:29,750 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 62
[INFO] 2021-07-09 16:43:29,750 [run_pretraining.py:  558]:	worker_index: 4, step: 62, cost: 9.229428, mlm loss: 9.229428, speed: 0.437659 steps/s, speed: 3.501272 samples/s, speed: 1792.651199 tokens/s, learning rate: 6.100e-07, loss_scalings: 26214.400391, pp_loss: 9.249441
[INFO] 2021-07-09 16:43:29,751 [run_pretraining.py:  512]:	********exe.run_62******* 
[INFO] 2021-07-09 16:43:32,013 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:32,013 [run_pretraining.py:  534]:	loss/total_loss, 9.069804191589355, 63
[INFO] 2021-07-09 16:43:32,013 [run_pretraining.py:  535]:	loss/mlm_loss, 9.069804191589355, 63
[INFO] 2021-07-09 16:43:32,013 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.199999802447564e-07, 63
[INFO] 2021-07-09 16:43:32,013 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 63
[INFO] 2021-07-09 16:43:32,013 [run_pretraining.py:  558]:	worker_index: 4, step: 63, cost: 9.069804, mlm loss: 9.069804, speed: 0.442005 steps/s, speed: 3.536042 samples/s, speed: 1810.453285 tokens/s, learning rate: 6.200e-07, loss_scalings: 26214.400391, pp_loss: 9.123641
[INFO] 2021-07-09 16:43:32,014 [run_pretraining.py:  512]:	********exe.run_63******* 
[INFO] 2021-07-09 16:43:34,198 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:34,199 [run_pretraining.py:  534]:	loss/total_loss, 9.049027442932129, 64
[INFO] 2021-07-09 16:43:34,199 [run_pretraining.py:  535]:	loss/mlm_loss, 9.049027442932129, 64
[INFO] 2021-07-09 16:43:34,199 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.299999881775875e-07, 64
[INFO] 2021-07-09 16:43:34,199 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 64
[INFO] 2021-07-09 16:43:34,199 [run_pretraining.py:  558]:	worker_index: 4, step: 64, cost: 9.049027, mlm loss: 9.049027, speed: 0.457633 steps/s, speed: 3.661064 samples/s, speed: 1874.464599 tokens/s, learning rate: 6.300e-07, loss_scalings: 26214.400391, pp_loss: 9.135510
[INFO] 2021-07-09 16:43:34,199 [run_pretraining.py:  512]:	********exe.run_64******* 
[INFO] 2021-07-09 16:43:36,388 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:36,389 [run_pretraining.py:  534]:	loss/total_loss, 9.019818305969238, 65
[INFO] 2021-07-09 16:43:36,389 [run_pretraining.py:  535]:	loss/mlm_loss, 9.019818305969238, 65
[INFO] 2021-07-09 16:43:36,389 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.399999392669997e-07, 65
[INFO] 2021-07-09 16:43:36,389 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 65
[INFO] 2021-07-09 16:43:36,389 [run_pretraining.py:  558]:	worker_index: 4, step: 65, cost: 9.019818, mlm loss: 9.019818, speed: 0.456780 steps/s, speed: 3.654241 samples/s, speed: 1870.971180 tokens/s, learning rate: 6.400e-07, loss_scalings: 26214.400391, pp_loss: 9.057487
[INFO] 2021-07-09 16:43:36,389 [run_pretraining.py:  512]:	********exe.run_65******* 
[INFO] 2021-07-09 16:43:38,560 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:38,561 [run_pretraining.py:  534]:	loss/total_loss, 9.023674011230469, 66
[INFO] 2021-07-09 16:43:38,561 [run_pretraining.py:  535]:	loss/mlm_loss, 9.023674011230469, 66
[INFO] 2021-07-09 16:43:38,561 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.500000040432496e-07, 66
[INFO] 2021-07-09 16:43:38,561 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 66
[INFO] 2021-07-09 16:43:38,561 [run_pretraining.py:  558]:	worker_index: 4, step: 66, cost: 9.023674, mlm loss: 9.023674, speed: 0.460554 steps/s, speed: 3.684430 samples/s, speed: 1886.427957 tokens/s, learning rate: 6.500e-07, loss_scalings: 26214.400391, pp_loss: 9.044785
[INFO] 2021-07-09 16:43:38,561 [run_pretraining.py:  512]:	********exe.run_66******* 
[INFO] 2021-07-09 16:43:40,772 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:40,773 [run_pretraining.py:  534]:	loss/total_loss, 8.98205852508545, 67
[INFO] 2021-07-09 16:43:40,773 [run_pretraining.py:  535]:	loss/mlm_loss, 8.98205852508545, 67
[INFO] 2021-07-09 16:43:40,773 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.599999551326619e-07, 67
[INFO] 2021-07-09 16:43:40,773 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 67
[INFO] 2021-07-09 16:43:40,773 [run_pretraining.py:  558]:	worker_index: 4, step: 67, cost: 8.982059, mlm loss: 8.982059, speed: 0.452186 steps/s, speed: 3.617490 samples/s, speed: 1852.154988 tokens/s, learning rate: 6.600e-07, loss_scalings: 26214.400391, pp_loss: 9.023321
[INFO] 2021-07-09 16:43:40,773 [run_pretraining.py:  512]:	********exe.run_67******* 
[INFO] 2021-07-09 16:43:42,922 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:42,922 [run_pretraining.py:  534]:	loss/total_loss, 8.956698417663574, 68
[INFO] 2021-07-09 16:43:42,922 [run_pretraining.py:  535]:	loss/mlm_loss, 8.956698417663574, 68
[INFO] 2021-07-09 16:43:42,922 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.699999630654929e-07, 68
[INFO] 2021-07-09 16:43:42,922 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 68
[INFO] 2021-07-09 16:43:42,922 [run_pretraining.py:  558]:	worker_index: 4, step: 68, cost: 8.956698, mlm loss: 8.956698, speed: 0.465441 steps/s, speed: 3.723527 samples/s, speed: 1906.445965 tokens/s, learning rate: 6.700e-07, loss_scalings: 26214.400391, pp_loss: 8.952125
[INFO] 2021-07-09 16:43:42,923 [run_pretraining.py:  512]:	********exe.run_68******* 
[INFO] 2021-07-09 16:43:45,073 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:45,073 [run_pretraining.py:  534]:	loss/total_loss, 8.993907928466797, 69
[INFO] 2021-07-09 16:43:45,073 [run_pretraining.py:  535]:	loss/mlm_loss, 8.993907928466797, 69
[INFO] 2021-07-09 16:43:45,074 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.79999970998324e-07, 69
[INFO] 2021-07-09 16:43:45,074 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 69
[INFO] 2021-07-09 16:43:45,074 [run_pretraining.py:  558]:	worker_index: 4, step: 69, cost: 8.993908, mlm loss: 8.993908, speed: 0.464993 steps/s, speed: 3.719940 samples/s, speed: 1904.609510 tokens/s, learning rate: 6.800e-07, loss_scalings: 26214.400391, pp_loss: 8.919018
[INFO] 2021-07-09 16:43:45,074 [run_pretraining.py:  512]:	********exe.run_69******* 
[INFO] 2021-07-09 16:43:47,257 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:47,257 [run_pretraining.py:  534]:	loss/total_loss, 8.919208526611328, 70
[INFO] 2021-07-09 16:43:47,258 [run_pretraining.py:  535]:	loss/mlm_loss, 8.919208526611328, 70
[INFO] 2021-07-09 16:43:47,258 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.899999789311551e-07, 70
[INFO] 2021-07-09 16:43:47,258 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 70
[INFO] 2021-07-09 16:43:47,258 [run_pretraining.py:  558]:	worker_index: 4, step: 70, cost: 8.919209, mlm loss: 8.919209, speed: 0.457994 steps/s, speed: 3.663955 samples/s, speed: 1875.945056 tokens/s, learning rate: 6.900e-07, loss_scalings: 26214.400391, pp_loss: 8.883781
[INFO] 2021-07-09 16:43:47,258 [run_pretraining.py:  512]:	********exe.run_70******* 
[INFO] 2021-07-09 16:43:49,436 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:49,437 [run_pretraining.py:  534]:	loss/total_loss, 8.770428657531738, 71
[INFO] 2021-07-09 16:43:49,437 [run_pretraining.py:  535]:	loss/mlm_loss, 8.770428657531738, 71
[INFO] 2021-07-09 16:43:49,437 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.999999868639861e-07, 71
[INFO] 2021-07-09 16:43:49,438 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 71
[INFO] 2021-07-09 16:43:49,438 [run_pretraining.py:  558]:	worker_index: 4, step: 71, cost: 8.770429, mlm loss: 8.770429, speed: 0.458913 steps/s, speed: 3.671307 samples/s, speed: 1879.709409 tokens/s, learning rate: 7.000e-07, loss_scalings: 26214.400391, pp_loss: 8.848351
[INFO] 2021-07-09 16:43:49,438 [run_pretraining.py:  512]:	********exe.run_71******* 
[INFO] 2021-07-09 16:43:51,594 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:51,595 [run_pretraining.py:  534]:	loss/total_loss, 8.797040939331055, 72
[INFO] 2021-07-09 16:43:51,595 [run_pretraining.py:  535]:	loss/mlm_loss, 8.797040939331055, 72
[INFO] 2021-07-09 16:43:51,595 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.099999947968172e-07, 72
[INFO] 2021-07-09 16:43:51,595 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 72
[INFO] 2021-07-09 16:43:51,595 [run_pretraining.py:  558]:	worker_index: 4, step: 72, cost: 8.797041, mlm loss: 8.797041, speed: 0.463651 steps/s, speed: 3.709210 samples/s, speed: 1899.115433 tokens/s, learning rate: 7.100e-07, loss_scalings: 26214.400391, pp_loss: 8.775684
[INFO] 2021-07-09 16:43:51,595 [run_pretraining.py:  512]:	********exe.run_72******* 
[INFO] 2021-07-09 16:43:53,806 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:53,807 [run_pretraining.py:  534]:	loss/total_loss, 8.734383583068848, 73
[INFO] 2021-07-09 16:43:53,807 [run_pretraining.py:  535]:	loss/mlm_loss, 8.734383583068848, 73
[INFO] 2021-07-09 16:43:53,807 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.199999458862294e-07, 73
[INFO] 2021-07-09 16:43:53,807 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 73
[INFO] 2021-07-09 16:43:53,807 [run_pretraining.py:  558]:	worker_index: 4, step: 73, cost: 8.734384, mlm loss: 8.734384, speed: 0.452223 steps/s, speed: 3.617784 samples/s, speed: 1852.305160 tokens/s, learning rate: 7.200e-07, loss_scalings: 26214.400391, pp_loss: 8.783500
[INFO] 2021-07-09 16:43:53,807 [run_pretraining.py:  512]:	********exe.run_73******* 
[INFO] 2021-07-09 16:43:55,997 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:55,997 [run_pretraining.py:  534]:	loss/total_loss, 8.739771842956543, 74
[INFO] 2021-07-09 16:43:55,997 [run_pretraining.py:  535]:	loss/mlm_loss, 8.739771842956543, 74
[INFO] 2021-07-09 16:43:55,997 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.300000106624793e-07, 74
[INFO] 2021-07-09 16:43:55,997 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 74
[INFO] 2021-07-09 16:43:55,998 [run_pretraining.py:  558]:	worker_index: 4, step: 74, cost: 8.739772, mlm loss: 8.739772, speed: 0.456663 steps/s, speed: 3.653300 samples/s, speed: 1870.489824 tokens/s, learning rate: 7.300e-07, loss_scalings: 26214.400391, pp_loss: 8.734509
[INFO] 2021-07-09 16:43:55,998 [run_pretraining.py:  512]:	********exe.run_74******* 
[INFO] 2021-07-09 16:43:58,149 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:58,149 [run_pretraining.py:  534]:	loss/total_loss, 8.706758499145508, 75
[INFO] 2021-07-09 16:43:58,150 [run_pretraining.py:  535]:	loss/mlm_loss, 8.706758499145508, 75
[INFO] 2021-07-09 16:43:58,150 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.399999617518915e-07, 75
[INFO] 2021-07-09 16:43:58,150 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 75
[INFO] 2021-07-09 16:43:58,150 [run_pretraining.py:  558]:	worker_index: 4, step: 75, cost: 8.706758, mlm loss: 8.706758, speed: 0.464778 steps/s, speed: 3.718225 samples/s, speed: 1903.731107 tokens/s, learning rate: 7.400e-07, loss_scalings: 26214.400391, pp_loss: 8.709685
[INFO] 2021-07-09 16:43:58,150 [run_pretraining.py:  512]:	********exe.run_75******* 
[INFO] 2021-07-09 16:44:00,356 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:00,356 [run_pretraining.py:  534]:	loss/total_loss, 8.64011001586914, 76
[INFO] 2021-07-09 16:44:00,356 [run_pretraining.py:  535]:	loss/mlm_loss, 8.64011001586914, 76
[INFO] 2021-07-09 16:44:00,357 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.499999696847226e-07, 76
[INFO] 2021-07-09 16:44:00,357 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 76
[INFO] 2021-07-09 16:44:00,357 [run_pretraining.py:  558]:	worker_index: 4, step: 76, cost: 8.640110, mlm loss: 8.640110, speed: 0.453255 steps/s, speed: 3.626038 samples/s, speed: 1856.531511 tokens/s, learning rate: 7.500e-07, loss_scalings: 26214.400391, pp_loss: 8.707218
[INFO] 2021-07-09 16:44:00,357 [run_pretraining.py:  512]:	********exe.run_76******* 
[INFO] 2021-07-09 16:44:02,561 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:02,562 [run_pretraining.py:  534]:	loss/total_loss, 8.617935180664062, 77
[INFO] 2021-07-09 16:44:02,562 [run_pretraining.py:  535]:	loss/mlm_loss, 8.617935180664062, 77
[INFO] 2021-07-09 16:44:02,562 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.599999776175537e-07, 77
[INFO] 2021-07-09 16:44:02,562 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 77
[INFO] 2021-07-09 16:44:02,562 [run_pretraining.py:  558]:	worker_index: 4, step: 77, cost: 8.617935, mlm loss: 8.617935, speed: 0.453558 steps/s, speed: 3.628468 samples/s, speed: 1857.775415 tokens/s, learning rate: 7.600e-07, loss_scalings: 20971.521484, pp_loss: 8.670333
[INFO] 2021-07-09 16:44:02,562 [run_pretraining.py:  512]:	********exe.run_77******* 
[INFO] 2021-07-09 16:44:04,743 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:04,744 [run_pretraining.py:  534]:	loss/total_loss, 8.765973091125488, 78
[INFO] 2021-07-09 16:44:04,744 [run_pretraining.py:  535]:	loss/mlm_loss, 8.765973091125488, 78
[INFO] 2021-07-09 16:44:04,744 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.699999855503847e-07, 78
[INFO] 2021-07-09 16:44:04,744 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 78
[INFO] 2021-07-09 16:44:04,744 [run_pretraining.py:  558]:	worker_index: 4, step: 78, cost: 8.765973, mlm loss: 8.765973, speed: 0.458384 steps/s, speed: 3.667071 samples/s, speed: 1877.540498 tokens/s, learning rate: 7.700e-07, loss_scalings: 20971.521484, pp_loss: 8.601712
[INFO] 2021-07-09 16:44:04,745 [run_pretraining.py:  512]:	********exe.run_78******* 
[INFO] 2021-07-09 16:44:06,949 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:06,950 [run_pretraining.py:  534]:	loss/total_loss, 8.50301742553711, 79
[INFO] 2021-07-09 16:44:06,950 [run_pretraining.py:  535]:	loss/mlm_loss, 8.50301742553711, 79
[INFO] 2021-07-09 16:44:06,950 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.799999366397969e-07, 79
[INFO] 2021-07-09 16:44:06,950 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 79
[INFO] 2021-07-09 16:44:06,950 [run_pretraining.py:  558]:	worker_index: 4, step: 79, cost: 8.503017, mlm loss: 8.503017, speed: 0.453504 steps/s, speed: 3.628030 samples/s, speed: 1857.551245 tokens/s, learning rate: 7.800e-07, loss_scalings: 20971.521484, pp_loss: 8.572407
[INFO] 2021-07-09 16:44:06,950 [run_pretraining.py:  512]:	********exe.run_79******* 
[INFO] 2021-07-09 16:44:09,167 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:09,168 [run_pretraining.py:  534]:	loss/total_loss, 8.509773254394531, 80
[INFO] 2021-07-09 16:44:09,168 [run_pretraining.py:  535]:	loss/mlm_loss, 8.509773254394531, 80
[INFO] 2021-07-09 16:44:09,168 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.89999944572628e-07, 80
[INFO] 2021-07-09 16:44:09,168 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 80
[INFO] 2021-07-09 16:44:09,168 [run_pretraining.py:  558]:	worker_index: 4, step: 80, cost: 8.509773, mlm loss: 8.509773, speed: 0.450972 steps/s, speed: 3.607776 samples/s, speed: 1847.181171 tokens/s, learning rate: 7.900e-07, loss_scalings: 20971.521484, pp_loss: 8.564857
[INFO] 2021-07-09 16:44:09,168 [run_pretraining.py:  512]:	********exe.run_80******* 
[INFO] 2021-07-09 16:44:11,334 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:11,334 [run_pretraining.py:  534]:	loss/total_loss, 8.458849906921387, 81
[INFO] 2021-07-09 16:44:11,334 [run_pretraining.py:  535]:	loss/mlm_loss, 8.458849906921387, 81
[INFO] 2021-07-09 16:44:11,334 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.000000093488779e-07, 81
[INFO] 2021-07-09 16:44:11,334 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 81
[INFO] 2021-07-09 16:44:11,334 [run_pretraining.py:  558]:	worker_index: 4, step: 81, cost: 8.458850, mlm loss: 8.458850, speed: 0.461787 steps/s, speed: 3.694294 samples/s, speed: 1891.478427 tokens/s, learning rate: 8.000e-07, loss_scalings: 20971.521484, pp_loss: 8.546256
[INFO] 2021-07-09 16:44:11,335 [run_pretraining.py:  512]:	********exe.run_81******* 
[INFO] 2021-07-09 16:44:13,502 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:13,502 [run_pretraining.py:  534]:	loss/total_loss, 8.562538146972656, 82
[INFO] 2021-07-09 16:44:13,503 [run_pretraining.py:  535]:	loss/mlm_loss, 8.562538146972656, 82
[INFO] 2021-07-09 16:44:13,503 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.10000017281709e-07, 82
[INFO] 2021-07-09 16:44:13,503 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 82
[INFO] 2021-07-09 16:44:13,503 [run_pretraining.py:  558]:	worker_index: 4, step: 82, cost: 8.562538, mlm loss: 8.562538, speed: 0.461302 steps/s, speed: 3.690418 samples/s, speed: 1889.494024 tokens/s, learning rate: 8.100e-07, loss_scalings: 20971.521484, pp_loss: 8.501893
[INFO] 2021-07-09 16:44:13,503 [run_pretraining.py:  512]:	********exe.run_82******* 
[INFO] 2021-07-09 16:44:15,676 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:15,676 [run_pretraining.py:  534]:	loss/total_loss, 8.418990135192871, 83
[INFO] 2021-07-09 16:44:15,676 [run_pretraining.py:  535]:	loss/mlm_loss, 8.418990135192871, 83
[INFO] 2021-07-09 16:44:15,676 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.199999683711212e-07, 83
[INFO] 2021-07-09 16:44:15,676 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 83
[INFO] 2021-07-09 16:44:15,676 [run_pretraining.py:  558]:	worker_index: 4, step: 83, cost: 8.418990, mlm loss: 8.418990, speed: 0.460190 steps/s, speed: 3.681519 samples/s, speed: 1884.937532 tokens/s, learning rate: 8.200e-07, loss_scalings: 20971.521484, pp_loss: 8.486019
[INFO] 2021-07-09 16:44:15,677 [run_pretraining.py:  512]:	********exe.run_83******* 
[INFO] 2021-07-09 16:44:17,822 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:17,822 [run_pretraining.py:  534]:	loss/total_loss, 8.306747436523438, 84
[INFO] 2021-07-09 16:44:17,822 [run_pretraining.py:  535]:	loss/mlm_loss, 8.306747436523438, 84
[INFO] 2021-07-09 16:44:17,822 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.299999763039523e-07, 84
[INFO] 2021-07-09 16:44:17,822 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 84
[INFO] 2021-07-09 16:44:17,822 [run_pretraining.py:  558]:	worker_index: 4, step: 84, cost: 8.306747, mlm loss: 8.306747, speed: 0.466120 steps/s, speed: 3.728963 samples/s, speed: 1909.229258 tokens/s, learning rate: 8.300e-07, loss_scalings: 20971.521484, pp_loss: 8.427180
[INFO] 2021-07-09 16:44:17,823 [run_pretraining.py:  512]:	********exe.run_84******* 
[INFO] 2021-07-09 16:44:19,982 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:19,983 [run_pretraining.py:  534]:	loss/total_loss, 8.415125846862793, 85
[INFO] 2021-07-09 16:44:19,983 [run_pretraining.py:  535]:	loss/mlm_loss, 8.415125846862793, 85
[INFO] 2021-07-09 16:44:19,983 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.399999273933645e-07, 85
[INFO] 2021-07-09 16:44:19,983 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 85
[INFO] 2021-07-09 16:44:19,983 [run_pretraining.py:  558]:	worker_index: 4, step: 85, cost: 8.415126, mlm loss: 8.415126, speed: 0.462919 steps/s, speed: 3.703350 samples/s, speed: 1896.115393 tokens/s, learning rate: 8.400e-07, loss_scalings: 20971.521484, pp_loss: 8.409004
[INFO] 2021-07-09 16:44:19,983 [run_pretraining.py:  512]:	********exe.run_85******* 
[INFO] 2021-07-09 16:44:22,121 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:22,121 [run_pretraining.py:  534]:	loss/total_loss, 8.349092483520508, 86
[INFO] 2021-07-09 16:44:22,121 [run_pretraining.py:  535]:	loss/mlm_loss, 8.349092483520508, 86
[INFO] 2021-07-09 16:44:22,121 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.500000490130333e-07, 86
[INFO] 2021-07-09 16:44:22,122 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 86
[INFO] 2021-07-09 16:44:22,122 [run_pretraining.py:  558]:	worker_index: 4, step: 86, cost: 8.349092, mlm loss: 8.349092, speed: 0.467817 steps/s, speed: 3.742534 samples/s, speed: 1916.177331 tokens/s, learning rate: 8.500e-07, loss_scalings: 20971.521484, pp_loss: 8.325643
[INFO] 2021-07-09 16:44:22,122 [run_pretraining.py:  512]:	********exe.run_86******* 
[INFO] 2021-07-09 16:44:24,443 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:24,444 [run_pretraining.py:  534]:	loss/total_loss, 8.20817756652832, 87
[INFO] 2021-07-09 16:44:24,444 [run_pretraining.py:  535]:	loss/mlm_loss, 8.20817756652832, 87
[INFO] 2021-07-09 16:44:24,444 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.600000001024455e-07, 87
[INFO] 2021-07-09 16:44:24,444 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 87
[INFO] 2021-07-09 16:44:24,444 [run_pretraining.py:  558]:	worker_index: 4, step: 87, cost: 8.208178, mlm loss: 8.208178, speed: 0.430712 steps/s, speed: 3.445696 samples/s, speed: 1764.196155 tokens/s, learning rate: 8.600e-07, loss_scalings: 20971.521484, pp_loss: 8.300159
[INFO] 2021-07-09 16:44:24,444 [run_pretraining.py:  512]:	********exe.run_87******* 
[INFO] 2021-07-09 16:44:26,849 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:26,849 [run_pretraining.py:  534]:	loss/total_loss, 8.373452186584473, 88
[INFO] 2021-07-09 16:44:26,849 [run_pretraining.py:  535]:	loss/mlm_loss, 8.373452186584473, 88
[INFO] 2021-07-09 16:44:26,849 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.700000080352766e-07, 88
[INFO] 2021-07-09 16:44:26,849 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 88
[INFO] 2021-07-09 16:44:26,849 [run_pretraining.py:  558]:	worker_index: 4, step: 88, cost: 8.373452, mlm loss: 8.373452, speed: 0.415844 steps/s, speed: 3.326750 samples/s, speed: 1703.296159 tokens/s, learning rate: 8.700e-07, loss_scalings: 20971.521484, pp_loss: 8.311572
[INFO] 2021-07-09 16:44:26,850 [run_pretraining.py:  512]:	********exe.run_88******* 
[INFO] 2021-07-09 16:44:29,023 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:29,023 [run_pretraining.py:  534]:	loss/total_loss, 8.286369323730469, 89
[INFO] 2021-07-09 16:44:29,024 [run_pretraining.py:  535]:	loss/mlm_loss, 8.286369323730469, 89
[INFO] 2021-07-09 16:44:29,024 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.799999591246888e-07, 89
[INFO] 2021-07-09 16:44:29,024 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 89
[INFO] 2021-07-09 16:44:29,024 [run_pretraining.py:  558]:	worker_index: 4, step: 89, cost: 8.286369, mlm loss: 8.286369, speed: 0.460055 steps/s, speed: 3.680437 samples/s, speed: 1884.383854 tokens/s, learning rate: 8.800e-07, loss_scalings: 20971.521484, pp_loss: 8.321028
[INFO] 2021-07-09 16:44:29,024 [run_pretraining.py:  512]:	********exe.run_89******* 
[INFO] 2021-07-09 16:44:31,169 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:31,169 [run_pretraining.py:  534]:	loss/total_loss, 8.18274211883545, 90
[INFO] 2021-07-09 16:44:31,170 [run_pretraining.py:  535]:	loss/mlm_loss, 8.18274211883545, 90
[INFO] 2021-07-09 16:44:31,170 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.899999670575198e-07, 90
[INFO] 2021-07-09 16:44:31,170 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 90
[INFO] 2021-07-09 16:44:31,170 [run_pretraining.py:  558]:	worker_index: 4, step: 90, cost: 8.182742, mlm loss: 8.182742, speed: 0.466118 steps/s, speed: 3.728946 samples/s, speed: 1909.220135 tokens/s, learning rate: 8.900e-07, loss_scalings: 20971.521484, pp_loss: 8.226662
[INFO] 2021-07-09 16:44:31,170 [run_pretraining.py:  512]:	********exe.run_90******* 
[INFO] 2021-07-09 16:44:33,325 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:33,326 [run_pretraining.py:  534]:	loss/total_loss, 8.13764762878418, 91
[INFO] 2021-07-09 16:44:33,326 [run_pretraining.py:  535]:	loss/mlm_loss, 8.13764762878418, 91
[INFO] 2021-07-09 16:44:33,326 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.99999918146932e-07, 91
[INFO] 2021-07-09 16:44:33,326 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 91
[INFO] 2021-07-09 16:44:33,326 [run_pretraining.py:  558]:	worker_index: 4, step: 91, cost: 8.137648, mlm loss: 8.137648, speed: 0.463853 steps/s, speed: 3.710827 samples/s, speed: 1899.943564 tokens/s, learning rate: 9.000e-07, loss_scalings: 20971.521484, pp_loss: 8.270066
[INFO] 2021-07-09 16:44:33,326 [run_pretraining.py:  512]:	********exe.run_91******* 
[INFO] 2021-07-09 16:44:35,496 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:35,496 [run_pretraining.py:  534]:	loss/total_loss, 8.06411075592041, 92
[INFO] 2021-07-09 16:44:35,496 [run_pretraining.py:  535]:	loss/mlm_loss, 8.06411075592041, 92
[INFO] 2021-07-09 16:44:35,496 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.100000397666008e-07, 92
[INFO] 2021-07-09 16:44:35,497 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 92
[INFO] 2021-07-09 16:44:35,497 [run_pretraining.py:  558]:	worker_index: 4, step: 92, cost: 8.064111, mlm loss: 8.064111, speed: 0.460897 steps/s, speed: 3.687179 samples/s, speed: 1887.835476 tokens/s, learning rate: 9.100e-07, loss_scalings: 20971.521484, pp_loss: 8.139569
[INFO] 2021-07-09 16:44:35,497 [run_pretraining.py:  512]:	********exe.run_92******* 
[INFO] 2021-07-09 16:44:37,639 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:37,640 [run_pretraining.py:  534]:	loss/total_loss, 8.137126922607422, 93
[INFO] 2021-07-09 16:44:37,640 [run_pretraining.py:  535]:	loss/mlm_loss, 8.137126922607422, 93
[INFO] 2021-07-09 16:44:37,640 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.19999990856013e-07, 93
[INFO] 2021-07-09 16:44:37,640 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 93
[INFO] 2021-07-09 16:44:37,640 [run_pretraining.py:  558]:	worker_index: 4, step: 93, cost: 8.137127, mlm loss: 8.137127, speed: 0.466685 steps/s, speed: 3.733481 samples/s, speed: 1911.542442 tokens/s, learning rate: 9.200e-07, loss_scalings: 20971.521484, pp_loss: 8.092560
[INFO] 2021-07-09 16:44:37,640 [run_pretraining.py:  512]:	********exe.run_93******* 
[INFO] 2021-07-09 16:44:39,807 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:39,808 [run_pretraining.py:  534]:	loss/total_loss, 8.068987846374512, 94
[INFO] 2021-07-09 16:44:39,808 [run_pretraining.py:  535]:	loss/mlm_loss, 8.068987846374512, 94
[INFO] 2021-07-09 16:44:39,808 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.299999987888441e-07, 94
[INFO] 2021-07-09 16:44:39,808 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 94
[INFO] 2021-07-09 16:44:39,808 [run_pretraining.py:  558]:	worker_index: 4, step: 94, cost: 8.068988, mlm loss: 8.068988, speed: 0.461384 steps/s, speed: 3.691072 samples/s, speed: 1889.828868 tokens/s, learning rate: 9.300e-07, loss_scalings: 20971.521484, pp_loss: 8.103700
[INFO] 2021-07-09 16:44:39,808 [run_pretraining.py:  512]:	********exe.run_94******* 
[INFO] 2021-07-09 16:44:41,965 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:41,966 [run_pretraining.py:  534]:	loss/total_loss, 8.036051750183105, 95
[INFO] 2021-07-09 16:44:41,966 [run_pretraining.py:  535]:	loss/mlm_loss, 8.036051750183105, 95
[INFO] 2021-07-09 16:44:41,966 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.399999498782563e-07, 95
[INFO] 2021-07-09 16:44:41,966 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 95
[INFO] 2021-07-09 16:44:41,966 [run_pretraining.py:  558]:	worker_index: 4, step: 95, cost: 8.036052, mlm loss: 8.036052, speed: 0.463503 steps/s, speed: 3.708025 samples/s, speed: 1898.508917 tokens/s, learning rate: 9.400e-07, loss_scalings: 20971.521484, pp_loss: 8.047540
[INFO] 2021-07-09 16:44:41,966 [run_pretraining.py:  512]:	********exe.run_95******* 
[INFO] 2021-07-09 16:44:44,121 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:44,122 [run_pretraining.py:  534]:	loss/total_loss, 8.116501808166504, 96
[INFO] 2021-07-09 16:44:44,122 [run_pretraining.py:  535]:	loss/mlm_loss, 8.116501808166504, 96
[INFO] 2021-07-09 16:44:44,122 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.499999578110874e-07, 96
[INFO] 2021-07-09 16:44:44,122 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 96
[INFO] 2021-07-09 16:44:44,122 [run_pretraining.py:  558]:	worker_index: 4, step: 96, cost: 8.116502, mlm loss: 8.116502, speed: 0.463978 steps/s, speed: 3.711827 samples/s, speed: 1900.455547 tokens/s, learning rate: 9.500e-07, loss_scalings: 20971.521484, pp_loss: 8.028453
[INFO] 2021-07-09 16:44:44,122 [run_pretraining.py:  512]:	********exe.run_96******* 
[INFO] 2021-07-09 16:44:46,281 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:46,281 [run_pretraining.py:  534]:	loss/total_loss, 7.982978820800781, 97
[INFO] 2021-07-09 16:44:46,281 [run_pretraining.py:  535]:	loss/mlm_loss, 7.982978820800781, 97
[INFO] 2021-07-09 16:44:46,281 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.599999657439184e-07, 97
[INFO] 2021-07-09 16:44:46,282 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 97
[INFO] 2021-07-09 16:44:46,282 [run_pretraining.py:  558]:	worker_index: 4, step: 97, cost: 7.982979, mlm loss: 7.982979, speed: 0.463235 steps/s, speed: 3.705883 samples/s, speed: 1897.412297 tokens/s, learning rate: 9.600e-07, loss_scalings: 16777.216797, pp_loss: 7.947543
[INFO] 2021-07-09 16:44:46,282 [run_pretraining.py:  512]:	********exe.run_97******* 
[INFO] 2021-07-09 16:44:48,440 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:48,440 [run_pretraining.py:  534]:	loss/total_loss, 7.963540077209473, 98
[INFO] 2021-07-09 16:44:48,441 [run_pretraining.py:  535]:	loss/mlm_loss, 7.963540077209473, 98
[INFO] 2021-07-09 16:44:48,441 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.699999736767495e-07, 98
[INFO] 2021-07-09 16:44:48,441 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 98
[INFO] 2021-07-09 16:44:48,441 [run_pretraining.py:  558]:	worker_index: 4, step: 98, cost: 7.963540, mlm loss: 7.963540, speed: 0.463297 steps/s, speed: 3.706376 samples/s, speed: 1897.664428 tokens/s, learning rate: 9.700e-07, loss_scalings: 16777.216797, pp_loss: 7.959796
[INFO] 2021-07-09 16:44:48,441 [run_pretraining.py:  512]:	********exe.run_98******* 
[INFO] 2021-07-09 16:44:50,601 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:50,602 [run_pretraining.py:  534]:	loss/total_loss, 8.160085678100586, 99
[INFO] 2021-07-09 16:44:50,602 [run_pretraining.py:  535]:	loss/mlm_loss, 8.160085678100586, 99
[INFO] 2021-07-09 16:44:50,602 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.799999816095806e-07, 99
[INFO] 2021-07-09 16:44:50,602 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 99
[INFO] 2021-07-09 16:44:50,602 [run_pretraining.py:  558]:	worker_index: 4, step: 99, cost: 8.160086, mlm loss: 8.160086, speed: 0.462837 steps/s, speed: 3.702699 samples/s, speed: 1895.781664 tokens/s, learning rate: 9.800e-07, loss_scalings: 16777.216797, pp_loss: 7.924097
[INFO] 2021-07-09 16:44:50,602 [run_pretraining.py:  512]:	********exe.run_99******* 
[INFO] 2021-07-09 16:44:52,753 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:52,753 [run_pretraining.py:  534]:	loss/total_loss, 8.191551208496094, 100
[INFO] 2021-07-09 16:44:52,753 [run_pretraining.py:  535]:	loss/mlm_loss, 8.191551208496094, 100
[INFO] 2021-07-09 16:44:52,753 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.899999895424116e-07, 100
[INFO] 2021-07-09 16:44:52,753 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 100
[INFO] 2021-07-09 16:44:52,754 [run_pretraining.py:  558]:	worker_index: 4, step: 100, cost: 8.191551, mlm loss: 8.191551, speed: 0.464947 steps/s, speed: 3.719576 samples/s, speed: 1904.423082 tokens/s, learning rate: 9.900e-07, loss_scalings: 16777.216797, pp_loss: 7.962445
[INFO] 2021-07-09 16:44:52,754 [run_pretraining.py:  512]:	********exe.run_100******* 
[INFO] 2021-07-09 16:44:54,958 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:54,958 [run_pretraining.py:  534]:	loss/total_loss, 7.710727214813232, 101
[INFO] 2021-07-09 16:44:54,959 [run_pretraining.py:  535]:	loss/mlm_loss, 7.710727214813232, 101
[INFO] 2021-07-09 16:44:54,959 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.999999974752427e-07, 101
[INFO] 2021-07-09 16:44:54,959 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 101
[INFO] 2021-07-09 16:44:54,959 [run_pretraining.py:  558]:	worker_index: 4, step: 101, cost: 7.710727, mlm loss: 7.710727, speed: 0.453601 steps/s, speed: 3.628809 samples/s, speed: 1857.950209 tokens/s, learning rate: 1.000e-06, loss_scalings: 16777.216797, pp_loss: 7.838353
[INFO] 2021-07-09 16:44:54,959 [run_pretraining.py:  512]:	********exe.run_101******* 
[INFO] 2021-07-09 16:44:57,122 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:57,123 [run_pretraining.py:  534]:	loss/total_loss, 8.127429008483887, 102
[INFO] 2021-07-09 16:44:57,123 [run_pretraining.py:  535]:	loss/mlm_loss, 8.127429008483887, 102
[INFO] 2021-07-09 16:44:57,123 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.009999891721236e-06, 102
[INFO] 2021-07-09 16:44:57,123 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 102
[INFO] 2021-07-09 16:44:57,123 [run_pretraining.py:  558]:	worker_index: 4, step: 102, cost: 8.127429, mlm loss: 8.127429, speed: 0.462167 steps/s, speed: 3.697336 samples/s, speed: 1893.036162 tokens/s, learning rate: 1.010e-06, loss_scalings: 16777.216797, pp_loss: 7.958790
[INFO] 2021-07-09 16:44:57,123 [run_pretraining.py:  512]:	********exe.run_102******* 
[INFO] 2021-07-09 16:44:59,281 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:59,282 [run_pretraining.py:  534]:	loss/total_loss, 7.672768592834473, 103
[INFO] 2021-07-09 16:44:59,282 [run_pretraining.py:  535]:	loss/mlm_loss, 7.672768592834473, 103
[INFO] 2021-07-09 16:44:59,282 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0200000133409048e-06, 103
[INFO] 2021-07-09 16:44:59,282 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 103
[INFO] 2021-07-09 16:44:59,282 [run_pretraining.py:  558]:	worker_index: 4, step: 103, cost: 7.672769, mlm loss: 7.672769, speed: 0.463323 steps/s, speed: 3.706584 samples/s, speed: 1897.770918 tokens/s, learning rate: 1.020e-06, loss_scalings: 16777.216797, pp_loss: 7.756964
[INFO] 2021-07-09 16:44:59,282 [run_pretraining.py:  512]:	********exe.run_103******* 
[INFO] 2021-07-09 16:45:01,484 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:01,485 [run_pretraining.py:  534]:	loss/total_loss, 7.720997333526611, 104
[INFO] 2021-07-09 16:45:01,485 [run_pretraining.py:  535]:	loss/mlm_loss, 7.720997333526611, 104
[INFO] 2021-07-09 16:45:01,485 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.030000021273736e-06, 104
[INFO] 2021-07-09 16:45:01,485 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 104
[INFO] 2021-07-09 16:45:01,485 [run_pretraining.py:  558]:	worker_index: 4, step: 104, cost: 7.720997, mlm loss: 7.720997, speed: 0.454066 steps/s, speed: 3.632525 samples/s, speed: 1859.852566 tokens/s, learning rate: 1.030e-06, loss_scalings: 16777.216797, pp_loss: 7.783972
[INFO] 2021-07-09 16:45:01,485 [run_pretraining.py:  512]:	********exe.run_104******* 
[INFO] 2021-07-09 16:45:03,729 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:03,729 [run_pretraining.py:  534]:	loss/total_loss, 7.931687355041504, 105
[INFO] 2021-07-09 16:45:03,729 [run_pretraining.py:  535]:	loss/mlm_loss, 7.931687355041504, 105
[INFO] 2021-07-09 16:45:03,729 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.040000029206567e-06, 105
[INFO] 2021-07-09 16:45:03,729 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 105
[INFO] 2021-07-09 16:45:03,730 [run_pretraining.py:  558]:	worker_index: 4, step: 105, cost: 7.931687, mlm loss: 7.931687, speed: 0.445676 steps/s, speed: 3.565409 samples/s, speed: 1825.489444 tokens/s, learning rate: 1.040e-06, loss_scalings: 16777.216797, pp_loss: 7.791164
[INFO] 2021-07-09 16:45:03,730 [run_pretraining.py:  512]:	********exe.run_105******* 
[INFO] 2021-07-09 16:45:05,983 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:05,984 [run_pretraining.py:  534]:	loss/total_loss, 7.663658142089844, 106
[INFO] 2021-07-09 16:45:05,984 [run_pretraining.py:  535]:	loss/mlm_loss, 7.663658142089844, 106
[INFO] 2021-07-09 16:45:05,984 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0499999234525603e-06, 106
[INFO] 2021-07-09 16:45:05,984 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 106
[INFO] 2021-07-09 16:45:05,984 [run_pretraining.py:  558]:	worker_index: 4, step: 106, cost: 7.663658, mlm loss: 7.663658, speed: 0.443680 steps/s, speed: 3.549438 samples/s, speed: 1817.312304 tokens/s, learning rate: 1.050e-06, loss_scalings: 16777.216797, pp_loss: 7.709411
[INFO] 2021-07-09 16:45:05,984 [run_pretraining.py:  512]:	********exe.run_106******* 
[INFO] 2021-07-09 16:45:08,187 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:08,188 [run_pretraining.py:  534]:	loss/total_loss, 7.875154972076416, 107
[INFO] 2021-07-09 16:45:08,188 [run_pretraining.py:  535]:	loss/mlm_loss, 7.875154972076416, 107
[INFO] 2021-07-09 16:45:08,188 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0599999313853914e-06, 107
[INFO] 2021-07-09 16:45:08,188 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 107
[INFO] 2021-07-09 16:45:08,188 [run_pretraining.py:  558]:	worker_index: 4, step: 107, cost: 7.875155, mlm loss: 7.875155, speed: 0.453847 steps/s, speed: 3.630779 samples/s, speed: 1858.958831 tokens/s, learning rate: 1.060e-06, loss_scalings: 16777.216797, pp_loss: 7.717848
[INFO] 2021-07-09 16:45:08,188 [run_pretraining.py:  512]:	********exe.run_107******* 
[INFO] 2021-07-09 16:45:10,371 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:10,372 [run_pretraining.py:  534]:	loss/total_loss, 7.688909530639648, 108
[INFO] 2021-07-09 16:45:10,372 [run_pretraining.py:  535]:	loss/mlm_loss, 7.688909530639648, 108
[INFO] 2021-07-09 16:45:10,372 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0700000530050602e-06, 108
[INFO] 2021-07-09 16:45:10,372 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 108
[INFO] 2021-07-09 16:45:10,372 [run_pretraining.py:  558]:	worker_index: 4, step: 108, cost: 7.688910, mlm loss: 7.688910, speed: 0.457992 steps/s, speed: 3.663932 samples/s, speed: 1875.933380 tokens/s, learning rate: 1.070e-06, loss_scalings: 16777.216797, pp_loss: 7.606237
[INFO] 2021-07-09 16:45:10,372 [run_pretraining.py:  512]:	********exe.run_108******* 
[INFO] 2021-07-09 16:45:12,577 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:12,578 [run_pretraining.py:  534]:	loss/total_loss, 7.902243137359619, 109
[INFO] 2021-07-09 16:45:12,578 [run_pretraining.py:  535]:	loss/mlm_loss, 7.902243137359619, 109
[INFO] 2021-07-09 16:45:12,578 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0799999472510535e-06, 109
[INFO] 2021-07-09 16:45:12,578 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 109
[INFO] 2021-07-09 16:45:12,578 [run_pretraining.py:  558]:	worker_index: 4, step: 109, cost: 7.902243, mlm loss: 7.902243, speed: 0.453457 steps/s, speed: 3.627660 samples/s, speed: 1857.361666 tokens/s, learning rate: 1.080e-06, loss_scalings: 16777.216797, pp_loss: 7.619787
[INFO] 2021-07-09 16:45:12,578 [run_pretraining.py:  512]:	********exe.run_109******* 
[INFO] 2021-07-09 16:45:14,765 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:14,765 [run_pretraining.py:  534]:	loss/total_loss, 7.7292938232421875, 110
[INFO] 2021-07-09 16:45:14,765 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7292938232421875, 110
[INFO] 2021-07-09 16:45:14,766 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0899999551838846e-06, 110
[INFO] 2021-07-09 16:45:14,766 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 110
[INFO] 2021-07-09 16:45:14,766 [run_pretraining.py:  558]:	worker_index: 4, step: 110, cost: 7.729294, mlm loss: 7.729294, speed: 0.457288 steps/s, speed: 3.658303 samples/s, speed: 1873.051209 tokens/s, learning rate: 1.090e-06, loss_scalings: 16777.216797, pp_loss: 7.649807
[INFO] 2021-07-09 16:45:14,766 [run_pretraining.py:  512]:	********exe.run_110******* 
[INFO] 2021-07-09 16:45:16,950 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:16,951 [run_pretraining.py:  534]:	loss/total_loss, 7.513604164123535, 111
[INFO] 2021-07-09 16:45:16,951 [run_pretraining.py:  535]:	loss/mlm_loss, 7.513604164123535, 111
[INFO] 2021-07-09 16:45:16,951 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0999999631167157e-06, 111
[INFO] 2021-07-09 16:45:16,951 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 111
[INFO] 2021-07-09 16:45:16,951 [run_pretraining.py:  558]:	worker_index: 4, step: 111, cost: 7.513604, mlm loss: 7.513604, speed: 0.457708 steps/s, speed: 3.661661 samples/s, speed: 1874.770405 tokens/s, learning rate: 1.100e-06, loss_scalings: 16777.216797, pp_loss: 7.527276
[INFO] 2021-07-09 16:45:16,951 [run_pretraining.py:  512]:	********exe.run_111******* 
[INFO] 2021-07-09 16:45:19,150 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:19,150 [run_pretraining.py:  534]:	loss/total_loss, 7.347163200378418, 112
[INFO] 2021-07-09 16:45:19,150 [run_pretraining.py:  535]:	loss/mlm_loss, 7.347163200378418, 112
[INFO] 2021-07-09 16:45:19,150 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1099999710495467e-06, 112
[INFO] 2021-07-09 16:45:19,151 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 112
[INFO] 2021-07-09 16:45:19,151 [run_pretraining.py:  558]:	worker_index: 4, step: 112, cost: 7.347163, mlm loss: 7.347163, speed: 0.454819 steps/s, speed: 3.638551 samples/s, speed: 1862.938230 tokens/s, learning rate: 1.110e-06, loss_scalings: 16777.216797, pp_loss: 7.424499
[INFO] 2021-07-09 16:45:19,151 [run_pretraining.py:  512]:	********exe.run_112******* 
[INFO] 2021-07-09 16:45:21,335 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:21,335 [run_pretraining.py:  534]:	loss/total_loss, 7.449942588806152, 113
[INFO] 2021-07-09 16:45:21,336 [run_pretraining.py:  535]:	loss/mlm_loss, 7.449942588806152, 113
[INFO] 2021-07-09 16:45:21,336 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1199999789823778e-06, 113
[INFO] 2021-07-09 16:45:21,336 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 113
[INFO] 2021-07-09 16:45:21,336 [run_pretraining.py:  558]:	worker_index: 4, step: 113, cost: 7.449943, mlm loss: 7.449943, speed: 0.457761 steps/s, speed: 3.662090 samples/s, speed: 1874.989952 tokens/s, learning rate: 1.120e-06, loss_scalings: 16777.216797, pp_loss: 7.394008
[INFO] 2021-07-09 16:45:21,336 [run_pretraining.py:  512]:	********exe.run_113******* 
[INFO] 2021-07-09 16:45:23,563 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:23,563 [run_pretraining.py:  534]:	loss/total_loss, 7.250889778137207, 114
[INFO] 2021-07-09 16:45:23,564 [run_pretraining.py:  535]:	loss/mlm_loss, 7.250889778137207, 114
[INFO] 2021-07-09 16:45:23,564 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1299999869152089e-06, 114
[INFO] 2021-07-09 16:45:23,564 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 114
[INFO] 2021-07-09 16:45:23,564 [run_pretraining.py:  558]:	worker_index: 4, step: 114, cost: 7.250890, mlm loss: 7.250890, speed: 0.448954 steps/s, speed: 3.591629 samples/s, speed: 1838.914093 tokens/s, learning rate: 1.130e-06, loss_scalings: 16777.216797, pp_loss: 7.278051
[INFO] 2021-07-09 16:45:23,564 [run_pretraining.py:  512]:	********exe.run_114******* 
[INFO] 2021-07-09 16:45:25,830 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:25,831 [run_pretraining.py:  534]:	loss/total_loss, 7.217160701751709, 115
[INFO] 2021-07-09 16:45:25,831 [run_pretraining.py:  535]:	loss/mlm_loss, 7.217160701751709, 115
[INFO] 2021-07-09 16:45:25,831 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.13999999484804e-06, 115
[INFO] 2021-07-09 16:45:25,831 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 115
[INFO] 2021-07-09 16:45:25,831 [run_pretraining.py:  558]:	worker_index: 4, step: 115, cost: 7.217161, mlm loss: 7.217161, speed: 0.441213 steps/s, speed: 3.529704 samples/s, speed: 1807.208247 tokens/s, learning rate: 1.140e-06, loss_scalings: 16777.216797, pp_loss: 7.308995
[INFO] 2021-07-09 16:45:25,831 [run_pretraining.py:  512]:	********exe.run_115******* 
[INFO] 2021-07-09 16:45:28,051 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:28,051 [run_pretraining.py:  534]:	loss/total_loss, 7.104904651641846, 116
[INFO] 2021-07-09 16:45:28,051 [run_pretraining.py:  535]:	loss/mlm_loss, 7.104904651641846, 116
[INFO] 2021-07-09 16:45:28,051 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.150000002780871e-06, 116
[INFO] 2021-07-09 16:45:28,051 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 116
[INFO] 2021-07-09 16:45:28,051 [run_pretraining.py:  558]:	worker_index: 4, step: 116, cost: 7.104905, mlm loss: 7.104905, speed: 0.450485 steps/s, speed: 3.603884 samples/s, speed: 1845.188493 tokens/s, learning rate: 1.150e-06, loss_scalings: 16777.216797, pp_loss: 7.242059
[INFO] 2021-07-09 16:45:28,052 [run_pretraining.py:  512]:	********exe.run_116******* 
[INFO] 2021-07-09 16:45:30,260 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:30,261 [run_pretraining.py:  534]:	loss/total_loss, 7.247902870178223, 117
[INFO] 2021-07-09 16:45:30,261 [run_pretraining.py:  535]:	loss/mlm_loss, 7.247902870178223, 117
[INFO] 2021-07-09 16:45:30,261 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.160000010713702e-06, 117
[INFO] 2021-07-09 16:45:30,261 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 117
[INFO] 2021-07-09 16:45:30,261 [run_pretraining.py:  558]:	worker_index: 4, step: 117, cost: 7.247903, mlm loss: 7.247903, speed: 0.452699 steps/s, speed: 3.621595 samples/s, speed: 1854.256407 tokens/s, learning rate: 1.160e-06, loss_scalings: 16777.216797, pp_loss: 7.224539
[INFO] 2021-07-09 16:45:30,261 [run_pretraining.py:  512]:	********exe.run_117******* 
[INFO] 2021-07-09 16:45:32,466 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:32,467 [run_pretraining.py:  534]:	loss/total_loss, 7.288908004760742, 118
[INFO] 2021-07-09 16:45:32,467 [run_pretraining.py:  535]:	loss/mlm_loss, 7.288908004760742, 118
[INFO] 2021-07-09 16:45:32,467 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1699999049596954e-06, 118
[INFO] 2021-07-09 16:45:32,467 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 118
[INFO] 2021-07-09 16:45:32,467 [run_pretraining.py:  558]:	worker_index: 4, step: 118, cost: 7.288908, mlm loss: 7.288908, speed: 0.453488 steps/s, speed: 3.627902 samples/s, speed: 1857.485972 tokens/s, learning rate: 1.170e-06, loss_scalings: 16777.216797, pp_loss: 7.219102
[INFO] 2021-07-09 16:45:32,467 [run_pretraining.py:  512]:	********exe.run_118******* 
[INFO] 2021-07-09 16:45:34,694 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:34,695 [run_pretraining.py:  534]:	loss/total_loss, 7.063371181488037, 119
[INFO] 2021-07-09 16:45:34,695 [run_pretraining.py:  535]:	loss/mlm_loss, 7.063371181488037, 119
[INFO] 2021-07-09 16:45:34,695 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1800000265793642e-06, 119
[INFO] 2021-07-09 16:45:34,695 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 119
[INFO] 2021-07-09 16:45:34,695 [run_pretraining.py:  558]:	worker_index: 4, step: 119, cost: 7.063371, mlm loss: 7.063371, speed: 0.448930 steps/s, speed: 3.591436 samples/s, speed: 1838.815287 tokens/s, learning rate: 1.180e-06, loss_scalings: 16777.216797, pp_loss: 7.131712
[INFO] 2021-07-09 16:45:34,695 [run_pretraining.py:  512]:	********exe.run_119******* 
[INFO] 2021-07-09 16:45:36,940 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:36,941 [run_pretraining.py:  534]:	loss/total_loss, 6.943118572235107, 120
[INFO] 2021-07-09 16:45:36,941 [run_pretraining.py:  535]:	loss/mlm_loss, 6.943118572235107, 120
[INFO] 2021-07-09 16:45:36,941 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1900000345121953e-06, 120
[INFO] 2021-07-09 16:45:36,941 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 120
[INFO] 2021-07-09 16:45:36,941 [run_pretraining.py:  558]:	worker_index: 4, step: 120, cost: 6.943119, mlm loss: 6.943119, speed: 0.445398 steps/s, speed: 3.563182 samples/s, speed: 1824.349020 tokens/s, learning rate: 1.190e-06, loss_scalings: 16777.216797, pp_loss: 7.042025
[INFO] 2021-07-09 16:45:36,941 [run_pretraining.py:  512]:	********exe.run_120******* 
[INFO] 2021-07-09 16:45:39,178 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:39,178 [run_pretraining.py:  534]:	loss/total_loss, 7.001925468444824, 121
[INFO] 2021-07-09 16:45:39,179 [run_pretraining.py:  535]:	loss/mlm_loss, 7.001925468444824, 121
[INFO] 2021-07-09 16:45:39,179 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1999999287581886e-06, 121
[INFO] 2021-07-09 16:45:39,179 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 121
[INFO] 2021-07-09 16:45:39,179 [run_pretraining.py:  558]:	worker_index: 4, step: 121, cost: 7.001925, mlm loss: 7.001925, speed: 0.447005 steps/s, speed: 3.576038 samples/s, speed: 1830.931205 tokens/s, learning rate: 1.200e-06, loss_scalings: 16777.216797, pp_loss: 7.061264
[INFO] 2021-07-09 16:45:39,179 [run_pretraining.py:  512]:	********exe.run_121******* 
[INFO] 2021-07-09 16:45:41,431 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:41,431 [run_pretraining.py:  534]:	loss/total_loss, 6.974770545959473, 122
[INFO] 2021-07-09 16:45:41,431 [run_pretraining.py:  535]:	loss/mlm_loss, 6.974770545959473, 122
[INFO] 2021-07-09 16:45:41,432 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2099999366910197e-06, 122
[INFO] 2021-07-09 16:45:41,432 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 122
[INFO] 2021-07-09 16:45:41,432 [run_pretraining.py:  558]:	worker_index: 4, step: 122, cost: 6.974771, mlm loss: 6.974771, speed: 0.444006 steps/s, speed: 3.552048 samples/s, speed: 1818.648379 tokens/s, learning rate: 1.210e-06, loss_scalings: 16777.216797, pp_loss: 7.002038
[INFO] 2021-07-09 16:45:41,432 [run_pretraining.py:  512]:	********exe.run_122******* 
[INFO] 2021-07-09 16:45:43,672 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:43,672 [run_pretraining.py:  534]:	loss/total_loss, 7.004735946655273, 123
[INFO] 2021-07-09 16:45:43,673 [run_pretraining.py:  535]:	loss/mlm_loss, 7.004735946655273, 123
[INFO] 2021-07-09 16:45:43,673 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2199999446238508e-06, 123
[INFO] 2021-07-09 16:45:43,673 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 123
[INFO] 2021-07-09 16:45:43,673 [run_pretraining.py:  558]:	worker_index: 4, step: 123, cost: 7.004736, mlm loss: 7.004736, speed: 0.446334 steps/s, speed: 3.570670 samples/s, speed: 1828.183027 tokens/s, learning rate: 1.220e-06, loss_scalings: 16777.216797, pp_loss: 6.920127
[INFO] 2021-07-09 16:45:43,673 [run_pretraining.py:  512]:	********exe.run_123******* 
[INFO] 2021-07-09 16:45:45,902 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:45,902 [run_pretraining.py:  534]:	loss/total_loss, 6.80147647857666, 124
[INFO] 2021-07-09 16:45:45,902 [run_pretraining.py:  535]:	loss/mlm_loss, 6.80147647857666, 124
[INFO] 2021-07-09 16:45:45,902 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2299999525566818e-06, 124
[INFO] 2021-07-09 16:45:45,902 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 124
[INFO] 2021-07-09 16:45:45,903 [run_pretraining.py:  558]:	worker_index: 4, step: 124, cost: 6.801476, mlm loss: 6.801476, speed: 0.448619 steps/s, speed: 3.588954 samples/s, speed: 1837.544549 tokens/s, learning rate: 1.230e-06, loss_scalings: 16777.216797, pp_loss: 6.893071
[INFO] 2021-07-09 16:45:45,903 [run_pretraining.py:  512]:	********exe.run_124******* 
[INFO] 2021-07-09 16:45:48,088 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:48,089 [run_pretraining.py:  534]:	loss/total_loss, 6.831810474395752, 125
[INFO] 2021-07-09 16:45:48,089 [run_pretraining.py:  535]:	loss/mlm_loss, 6.831810474395752, 125
[INFO] 2021-07-09 16:45:48,089 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2399999604895129e-06, 125
[INFO] 2021-07-09 16:45:48,089 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 125
[INFO] 2021-07-09 16:45:48,089 [run_pretraining.py:  558]:	worker_index: 4, step: 125, cost: 6.831810, mlm loss: 6.831810, speed: 0.457450 steps/s, speed: 3.659598 samples/s, speed: 1873.714109 tokens/s, learning rate: 1.240e-06, loss_scalings: 16777.216797, pp_loss: 6.868649
[INFO] 2021-07-09 16:45:48,089 [run_pretraining.py:  512]:	********exe.run_125******* 
[INFO] 2021-07-09 16:45:50,317 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:50,317 [run_pretraining.py:  534]:	loss/total_loss, 6.682172775268555, 126
[INFO] 2021-07-09 16:45:50,317 [run_pretraining.py:  535]:	loss/mlm_loss, 6.682172775268555, 126
[INFO] 2021-07-09 16:45:50,318 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.249999968422344e-06, 126
[INFO] 2021-07-09 16:45:50,318 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 126
[INFO] 2021-07-09 16:45:50,318 [run_pretraining.py:  558]:	worker_index: 4, step: 126, cost: 6.682173, mlm loss: 6.682173, speed: 0.448892 steps/s, speed: 3.591134 samples/s, speed: 1838.660604 tokens/s, learning rate: 1.250e-06, loss_scalings: 16777.216797, pp_loss: 6.774048
[INFO] 2021-07-09 16:45:50,318 [run_pretraining.py:  512]:	********exe.run_126******* 
[INFO] 2021-07-09 16:45:52,568 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:52,568 [run_pretraining.py:  534]:	loss/total_loss, 6.753523349761963, 127
[INFO] 2021-07-09 16:45:52,568 [run_pretraining.py:  535]:	loss/mlm_loss, 6.753523349761963, 127
[INFO] 2021-07-09 16:45:52,568 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.259999976355175e-06, 127
[INFO] 2021-07-09 16:45:52,569 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 127
[INFO] 2021-07-09 16:45:52,569 [run_pretraining.py:  558]:	worker_index: 4, step: 127, cost: 6.753523, mlm loss: 6.753523, speed: 0.444372 steps/s, speed: 3.554980 samples/s, speed: 1820.149546 tokens/s, learning rate: 1.260e-06, loss_scalings: 16777.216797, pp_loss: 6.773091
[INFO] 2021-07-09 16:45:52,569 [run_pretraining.py:  512]:	********exe.run_127******* 
[INFO] 2021-07-09 16:45:54,761 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:54,761 [run_pretraining.py:  534]:	loss/total_loss, 6.795231819152832, 128
[INFO] 2021-07-09 16:45:54,762 [run_pretraining.py:  535]:	loss/mlm_loss, 6.795231819152832, 128
[INFO] 2021-07-09 16:45:54,762 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.269999984288006e-06, 128
[INFO] 2021-07-09 16:45:54,762 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 128
[INFO] 2021-07-09 16:45:54,762 [run_pretraining.py:  558]:	worker_index: 4, step: 128, cost: 6.795232, mlm loss: 6.795232, speed: 0.456108 steps/s, speed: 3.648866 samples/s, speed: 1868.219612 tokens/s, learning rate: 1.270e-06, loss_scalings: 16777.216797, pp_loss: 6.816555
[INFO] 2021-07-09 16:45:54,762 [run_pretraining.py:  512]:	********exe.run_128******* 
[INFO] 2021-07-09 16:45:56,981 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:56,981 [run_pretraining.py:  534]:	loss/total_loss, 6.77690315246582, 129
[INFO] 2021-07-09 16:45:56,981 [run_pretraining.py:  535]:	loss/mlm_loss, 6.77690315246582, 129
[INFO] 2021-07-09 16:45:56,981 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2799998785339994e-06, 129
[INFO] 2021-07-09 16:45:56,981 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 129
[INFO] 2021-07-09 16:45:56,982 [run_pretraining.py:  558]:	worker_index: 4, step: 129, cost: 6.776903, mlm loss: 6.776903, speed: 0.450630 steps/s, speed: 3.605043 samples/s, speed: 1845.781839 tokens/s, learning rate: 1.280e-06, loss_scalings: 16777.216797, pp_loss: 6.731493
[INFO] 2021-07-09 16:45:56,982 [run_pretraining.py:  512]:	********exe.run_129******* 
[INFO] 2021-07-09 16:45:59,240 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:59,241 [run_pretraining.py:  534]:	loss/total_loss, 6.832637310028076, 130
[INFO] 2021-07-09 16:45:59,241 [run_pretraining.py:  535]:	loss/mlm_loss, 6.832637310028076, 130
[INFO] 2021-07-09 16:45:59,241 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2900000001536682e-06, 130
[INFO] 2021-07-09 16:45:59,241 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 130
[INFO] 2021-07-09 16:45:59,241 [run_pretraining.py:  558]:	worker_index: 4, step: 130, cost: 6.832637, mlm loss: 6.832637, speed: 0.442731 steps/s, speed: 3.541847 samples/s, speed: 1813.425891 tokens/s, learning rate: 1.290e-06, loss_scalings: 16777.216797, pp_loss: 6.692171
[INFO] 2021-07-09 16:45:59,241 [run_pretraining.py:  512]:	********exe.run_130******* 
[INFO] 2021-07-09 16:46:01,433 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:01,433 [run_pretraining.py:  534]:	loss/total_loss, 6.605873107910156, 131
[INFO] 2021-07-09 16:46:01,433 [run_pretraining.py:  535]:	loss/mlm_loss, 6.605873107910156, 131
[INFO] 2021-07-09 16:46:01,433 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3000000080864993e-06, 131
[INFO] 2021-07-09 16:46:01,434 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 131
[INFO] 2021-07-09 16:46:01,434 [run_pretraining.py:  558]:	worker_index: 4, step: 131, cost: 6.605873, mlm loss: 6.605873, speed: 0.456210 steps/s, speed: 3.649683 samples/s, speed: 1868.637603 tokens/s, learning rate: 1.300e-06, loss_scalings: 16777.216797, pp_loss: 6.644777
[INFO] 2021-07-09 16:46:01,434 [run_pretraining.py:  512]:	********exe.run_131******* 
[INFO] 2021-07-09 16:46:03,628 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:03,629 [run_pretraining.py:  534]:	loss/total_loss, 6.670623779296875, 132
[INFO] 2021-07-09 16:46:03,629 [run_pretraining.py:  535]:	loss/mlm_loss, 6.670623779296875, 132
[INFO] 2021-07-09 16:46:03,629 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3100000160193304e-06, 132
[INFO] 2021-07-09 16:46:03,629 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 132
[INFO] 2021-07-09 16:46:03,629 [run_pretraining.py:  558]:	worker_index: 4, step: 132, cost: 6.670624, mlm loss: 6.670624, speed: 0.455654 steps/s, speed: 3.645232 samples/s, speed: 1866.358703 tokens/s, learning rate: 1.310e-06, loss_scalings: 16777.216797, pp_loss: 6.606604
[INFO] 2021-07-09 16:46:03,629 [run_pretraining.py:  512]:	********exe.run_132******* 
[INFO] 2021-07-09 16:46:05,959 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:05,960 [run_pretraining.py:  534]:	loss/total_loss, 6.531543731689453, 133
[INFO] 2021-07-09 16:46:05,960 [run_pretraining.py:  535]:	loss/mlm_loss, 6.531543731689453, 133
[INFO] 2021-07-09 16:46:05,960 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3199999102653237e-06, 133
[INFO] 2021-07-09 16:46:05,960 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 133
[INFO] 2021-07-09 16:46:05,960 [run_pretraining.py:  558]:	worker_index: 4, step: 133, cost: 6.531544, mlm loss: 6.531544, speed: 0.429075 steps/s, speed: 3.432601 samples/s, speed: 1757.491640 tokens/s, learning rate: 1.320e-06, loss_scalings: 16777.216797, pp_loss: 6.546149
[INFO] 2021-07-09 16:46:05,960 [run_pretraining.py:  512]:	********exe.run_133******* 
[INFO] 2021-07-09 16:46:08,205 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:08,206 [run_pretraining.py:  534]:	loss/total_loss, 6.5116448402404785, 134
[INFO] 2021-07-09 16:46:08,206 [run_pretraining.py:  535]:	loss/mlm_loss, 6.5116448402404785, 134
[INFO] 2021-07-09 16:46:08,206 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3299999181981548e-06, 134
[INFO] 2021-07-09 16:46:08,206 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 134
[INFO] 2021-07-09 16:46:08,206 [run_pretraining.py:  558]:	worker_index: 4, step: 134, cost: 6.511645, mlm loss: 6.511645, speed: 0.445436 steps/s, speed: 3.563486 samples/s, speed: 1824.504986 tokens/s, learning rate: 1.330e-06, loss_scalings: 16777.216797, pp_loss: 6.503631
[INFO] 2021-07-09 16:46:08,206 [run_pretraining.py:  512]:	********exe.run_134******* 
[INFO] 2021-07-09 16:46:10,413 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:10,413 [run_pretraining.py:  534]:	loss/total_loss, 6.394425868988037, 135
[INFO] 2021-07-09 16:46:10,413 [run_pretraining.py:  535]:	loss/mlm_loss, 6.394425868988037, 135
[INFO] 2021-07-09 16:46:10,413 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3399999261309858e-06, 135
[INFO] 2021-07-09 16:46:10,413 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 135
[INFO] 2021-07-09 16:46:10,414 [run_pretraining.py:  558]:	worker_index: 4, step: 135, cost: 6.394426, mlm loss: 6.394426, speed: 0.453098 steps/s, speed: 3.624782 samples/s, speed: 1855.888330 tokens/s, learning rate: 1.340e-06, loss_scalings: 16777.216797, pp_loss: 6.441617
[INFO] 2021-07-09 16:46:10,414 [run_pretraining.py:  512]:	********exe.run_135******* 
[INFO] 2021-07-09 16:46:12,620 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:12,620 [run_pretraining.py:  534]:	loss/total_loss, 6.746809005737305, 136
[INFO] 2021-07-09 16:46:12,620 [run_pretraining.py:  535]:	loss/mlm_loss, 6.746809005737305, 136
[INFO] 2021-07-09 16:46:12,620 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3500000477506546e-06, 136
[INFO] 2021-07-09 16:46:12,621 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 136
[INFO] 2021-07-09 16:46:12,621 [run_pretraining.py:  558]:	worker_index: 4, step: 136, cost: 6.746809, mlm loss: 6.746809, speed: 0.453230 steps/s, speed: 3.625839 samples/s, speed: 1856.429799 tokens/s, learning rate: 1.350e-06, loss_scalings: 16777.216797, pp_loss: 6.444324
[INFO] 2021-07-09 16:46:12,621 [run_pretraining.py:  512]:	********exe.run_136******* 
[INFO] 2021-07-09 16:46:14,851 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:14,851 [run_pretraining.py:  534]:	loss/total_loss, 6.339868545532227, 137
[INFO] 2021-07-09 16:46:14,852 [run_pretraining.py:  535]:	loss/mlm_loss, 6.339868545532227, 137
[INFO] 2021-07-09 16:46:14,852 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.359999941996648e-06, 137
[INFO] 2021-07-09 16:46:14,852 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 137
[INFO] 2021-07-09 16:46:14,852 [run_pretraining.py:  558]:	worker_index: 4, step: 137, cost: 6.339869, mlm loss: 6.339869, speed: 0.448322 steps/s, speed: 3.586579 samples/s, speed: 1836.328365 tokens/s, learning rate: 1.360e-06, loss_scalings: 16777.216797, pp_loss: 6.366034
[INFO] 2021-07-09 16:46:14,852 [run_pretraining.py:  512]:	********exe.run_137******* 
[INFO] 2021-07-09 16:46:17,142 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:17,143 [run_pretraining.py:  534]:	loss/total_loss, 6.469754219055176, 138
[INFO] 2021-07-09 16:46:17,143 [run_pretraining.py:  535]:	loss/mlm_loss, 6.469754219055176, 138
[INFO] 2021-07-09 16:46:17,143 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.369999949929479e-06, 138
[INFO] 2021-07-09 16:46:17,143 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 138
[INFO] 2021-07-09 16:46:17,143 [run_pretraining.py:  558]:	worker_index: 4, step: 138, cost: 6.469754, mlm loss: 6.469754, speed: 0.436599 steps/s, speed: 3.492792 samples/s, speed: 1788.309321 tokens/s, learning rate: 1.370e-06, loss_scalings: 16777.216797, pp_loss: 6.445026
[INFO] 2021-07-09 16:46:17,143 [run_pretraining.py:  512]:	********exe.run_138******* 
[INFO] 2021-07-09 16:46:19,340 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:19,341 [run_pretraining.py:  534]:	loss/total_loss, 6.426575183868408, 139
[INFO] 2021-07-09 16:46:19,341 [run_pretraining.py:  535]:	loss/mlm_loss, 6.426575183868408, 139
[INFO] 2021-07-09 16:46:19,341 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3799999578623101e-06, 139
[INFO] 2021-07-09 16:46:19,341 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 139
[INFO] 2021-07-09 16:46:19,341 [run_pretraining.py:  558]:	worker_index: 4, step: 139, cost: 6.426575, mlm loss: 6.426575, speed: 0.455103 steps/s, speed: 3.640824 samples/s, speed: 1864.102141 tokens/s, learning rate: 1.380e-06, loss_scalings: 16777.216797, pp_loss: 6.341651
[INFO] 2021-07-09 16:46:19,341 [run_pretraining.py:  512]:	********exe.run_139******* 
[INFO] 2021-07-09 16:46:21,473 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:21,473 [run_pretraining.py:  534]:	loss/total_loss, 6.269035339355469, 140
[INFO] 2021-07-09 16:46:21,473 [run_pretraining.py:  535]:	loss/mlm_loss, 6.269035339355469, 140
[INFO] 2021-07-09 16:46:21,473 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3899999657951412e-06, 140
[INFO] 2021-07-09 16:46:21,473 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 140
[INFO] 2021-07-09 16:46:21,473 [run_pretraining.py:  558]:	worker_index: 4, step: 140, cost: 6.269035, mlm loss: 6.269035, speed: 0.469099 steps/s, speed: 3.752796 samples/s, speed: 1921.431335 tokens/s, learning rate: 1.390e-06, loss_scalings: 16777.216797, pp_loss: 6.296806
[INFO] 2021-07-09 16:46:21,474 [run_pretraining.py:  512]:	********exe.run_140******* 
[INFO] 2021-07-09 16:46:23,562 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:23,562 [run_pretraining.py:  534]:	loss/total_loss, 6.609101295471191, 141
[INFO] 2021-07-09 16:46:23,562 [run_pretraining.py:  535]:	loss/mlm_loss, 6.609101295471191, 141
[INFO] 2021-07-09 16:46:23,563 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3999999737279722e-06, 141
[INFO] 2021-07-09 16:46:23,563 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 141
[INFO] 2021-07-09 16:46:23,563 [run_pretraining.py:  558]:	worker_index: 4, step: 141, cost: 6.609101, mlm loss: 6.609101, speed: 0.478780 steps/s, speed: 3.830244 samples/s, speed: 1961.084749 tokens/s, learning rate: 1.400e-06, loss_scalings: 16777.216797, pp_loss: 6.325289
[INFO] 2021-07-09 16:46:23,563 [run_pretraining.py:  512]:	********exe.run_141******* 
[INFO] 2021-07-09 16:46:25,666 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:25,666 [run_pretraining.py:  534]:	loss/total_loss, 6.149715423583984, 142
[INFO] 2021-07-09 16:46:25,666 [run_pretraining.py:  535]:	loss/mlm_loss, 6.149715423583984, 142
[INFO] 2021-07-09 16:46:25,666 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4099999816608033e-06, 142
[INFO] 2021-07-09 16:46:25,666 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 142
[INFO] 2021-07-09 16:46:25,667 [run_pretraining.py:  558]:	worker_index: 4, step: 142, cost: 6.149715, mlm loss: 6.149715, speed: 0.475469 steps/s, speed: 3.803751 samples/s, speed: 1947.520739 tokens/s, learning rate: 1.410e-06, loss_scalings: 16777.216797, pp_loss: 6.216568
[INFO] 2021-07-09 16:46:25,667 [run_pretraining.py:  512]:	********exe.run_142******* 
[INFO] 2021-07-09 16:46:27,900 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:27,901 [run_pretraining.py:  534]:	loss/total_loss, 6.256072044372559, 143
[INFO] 2021-07-09 16:46:27,901 [run_pretraining.py:  535]:	loss/mlm_loss, 6.256072044372559, 143
[INFO] 2021-07-09 16:46:27,901 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4199999895936344e-06, 143
[INFO] 2021-07-09 16:46:27,901 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 143
[INFO] 2021-07-09 16:46:27,901 [run_pretraining.py:  558]:	worker_index: 4, step: 143, cost: 6.256072, mlm loss: 6.256072, speed: 0.447616 steps/s, speed: 3.580931 samples/s, speed: 1833.436783 tokens/s, learning rate: 1.420e-06, loss_scalings: 16777.216797, pp_loss: 6.280437
[INFO] 2021-07-09 16:46:27,901 [run_pretraining.py:  512]:	********exe.run_143******* 
[INFO] 2021-07-09 16:46:29,996 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:29,997 [run_pretraining.py:  534]:	loss/total_loss, 6.145007133483887, 144
[INFO] 2021-07-09 16:46:29,997 [run_pretraining.py:  535]:	loss/mlm_loss, 6.145007133483887, 144
[INFO] 2021-07-09 16:46:29,997 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4299999975264654e-06, 144
[INFO] 2021-07-09 16:46:29,997 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 144
[INFO] 2021-07-09 16:46:29,997 [run_pretraining.py:  558]:	worker_index: 4, step: 144, cost: 6.145007, mlm loss: 6.145007, speed: 0.477305 steps/s, speed: 3.818442 samples/s, speed: 1955.042464 tokens/s, learning rate: 1.430e-06, loss_scalings: 16777.216797, pp_loss: 6.151163
[INFO] 2021-07-09 16:46:29,997 [run_pretraining.py:  512]:	********exe.run_144******* 
[INFO] 2021-07-09 16:46:32,134 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:32,135 [run_pretraining.py:  534]:	loss/total_loss, 6.434859275817871, 145
[INFO] 2021-07-09 16:46:32,135 [run_pretraining.py:  535]:	loss/mlm_loss, 6.434859275817871, 145
[INFO] 2021-07-09 16:46:32,135 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4399998917724588e-06, 145
[INFO] 2021-07-09 16:46:32,135 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 145
[INFO] 2021-07-09 16:46:32,135 [run_pretraining.py:  558]:	worker_index: 4, step: 145, cost: 6.434859, mlm loss: 6.434859, speed: 0.467850 steps/s, speed: 3.742800 samples/s, speed: 1916.313483 tokens/s, learning rate: 1.440e-06, loss_scalings: 16777.216797, pp_loss: 6.150728
[INFO] 2021-07-09 16:46:32,135 [run_pretraining.py:  512]:	********exe.run_145******* 
[INFO] 2021-07-09 16:46:34,240 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:34,241 [run_pretraining.py:  534]:	loss/total_loss, 6.074329853057861, 146
[INFO] 2021-07-09 16:46:34,241 [run_pretraining.py:  535]:	loss/mlm_loss, 6.074329853057861, 146
[INFO] 2021-07-09 16:46:34,241 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4499998997052899e-06, 146
[INFO] 2021-07-09 16:46:34,241 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 146
[INFO] 2021-07-09 16:46:34,241 [run_pretraining.py:  558]:	worker_index: 4, step: 146, cost: 6.074330, mlm loss: 6.074330, speed: 0.474994 steps/s, speed: 3.799952 samples/s, speed: 1945.575253 tokens/s, learning rate: 1.450e-06, loss_scalings: 16777.216797, pp_loss: 6.056977
[INFO] 2021-07-09 16:46:34,241 [run_pretraining.py:  512]:	********exe.run_146******* 
[INFO] 2021-07-09 16:46:36,430 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:36,431 [run_pretraining.py:  534]:	loss/total_loss, 6.169912338256836, 147
[INFO] 2021-07-09 16:46:36,431 [run_pretraining.py:  535]:	loss/mlm_loss, 6.169912338256836, 147
[INFO] 2021-07-09 16:46:36,431 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4600000213249587e-06, 147
[INFO] 2021-07-09 16:46:36,431 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 147
[INFO] 2021-07-09 16:46:36,431 [run_pretraining.py:  558]:	worker_index: 4, step: 147, cost: 6.169912, mlm loss: 6.169912, speed: 0.456791 steps/s, speed: 3.654327 samples/s, speed: 1871.015397 tokens/s, learning rate: 1.460e-06, loss_scalings: 16777.216797, pp_loss: 6.008142
[INFO] 2021-07-09 16:46:36,431 [run_pretraining.py:  512]:	********exe.run_147******* 
[INFO] 2021-07-09 16:46:38,653 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:38,653 [run_pretraining.py:  534]:	loss/total_loss, 6.0227837562561035, 148
[INFO] 2021-07-09 16:46:38,654 [run_pretraining.py:  535]:	loss/mlm_loss, 6.0227837562561035, 148
[INFO] 2021-07-09 16:46:38,654 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4700000292577897e-06, 148
[INFO] 2021-07-09 16:46:38,654 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 148
[INFO] 2021-07-09 16:46:38,654 [run_pretraining.py:  558]:	worker_index: 4, step: 148, cost: 6.022784, mlm loss: 6.022784, speed: 0.450016 steps/s, speed: 3.600128 samples/s, speed: 1843.265371 tokens/s, learning rate: 1.470e-06, loss_scalings: 16777.216797, pp_loss: 6.033984
[INFO] 2021-07-09 16:46:38,654 [run_pretraining.py:  512]:	********exe.run_148******* 
[INFO] 2021-07-09 16:46:40,926 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:40,926 [run_pretraining.py:  534]:	loss/total_loss, 5.934205055236816, 149
[INFO] 2021-07-09 16:46:40,926 [run_pretraining.py:  535]:	loss/mlm_loss, 5.934205055236816, 149
[INFO] 2021-07-09 16:46:40,926 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.479999923503783e-06, 149
[INFO] 2021-07-09 16:46:40,927 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 149
[INFO] 2021-07-09 16:46:40,927 [run_pretraining.py:  558]:	worker_index: 4, step: 149, cost: 5.934205, mlm loss: 5.934205, speed: 0.440109 steps/s, speed: 3.520871 samples/s, speed: 1802.686126 tokens/s, learning rate: 1.480e-06, loss_scalings: 16777.216797, pp_loss: 5.918603
[INFO] 2021-07-09 16:46:40,927 [run_pretraining.py:  512]:	********exe.run_149******* 
[INFO] 2021-07-09 16:46:43,176 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:43,176 [run_pretraining.py:  534]:	loss/total_loss, 6.069491386413574, 150
[INFO] 2021-07-09 16:46:43,176 [run_pretraining.py:  535]:	loss/mlm_loss, 6.069491386413574, 150
[INFO] 2021-07-09 16:46:43,177 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4899999314366141e-06, 150
[INFO] 2021-07-09 16:46:43,177 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 150
[INFO] 2021-07-09 16:46:43,177 [run_pretraining.py:  558]:	worker_index: 4, step: 150, cost: 6.069491, mlm loss: 6.069491, speed: 0.444551 steps/s, speed: 3.556408 samples/s, speed: 1820.880892 tokens/s, learning rate: 1.490e-06, loss_scalings: 16777.216797, pp_loss: 5.916757
[INFO] 2021-07-09 16:46:43,177 [run_pretraining.py:  512]:	********exe.run_150******* 
[INFO] 2021-07-09 16:46:45,408 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:45,408 [run_pretraining.py:  534]:	loss/total_loss, 5.880295753479004, 151
[INFO] 2021-07-09 16:46:45,409 [run_pretraining.py:  535]:	loss/mlm_loss, 5.880295753479004, 151
[INFO] 2021-07-09 16:46:45,409 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4999999393694452e-06, 151
[INFO] 2021-07-09 16:46:45,409 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 151
[INFO] 2021-07-09 16:46:45,409 [run_pretraining.py:  558]:	worker_index: 4, step: 151, cost: 5.880296, mlm loss: 5.880296, speed: 0.448138 steps/s, speed: 3.585106 samples/s, speed: 1835.574167 tokens/s, learning rate: 1.500e-06, loss_scalings: 16777.216797, pp_loss: 5.868193
[INFO] 2021-07-09 16:46:45,409 [run_pretraining.py:  512]:	********exe.run_151******* 
[INFO] 2021-07-09 16:46:47,603 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:47,604 [run_pretraining.py:  534]:	loss/total_loss, 5.814043998718262, 152
[INFO] 2021-07-09 16:46:47,604 [run_pretraining.py:  535]:	loss/mlm_loss, 5.814043998718262, 152
[INFO] 2021-07-09 16:46:47,604 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.510000060989114e-06, 152
[INFO] 2021-07-09 16:46:47,604 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 152
[INFO] 2021-07-09 16:46:47,604 [run_pretraining.py:  558]:	worker_index: 4, step: 152, cost: 5.814044, mlm loss: 5.814044, speed: 0.455676 steps/s, speed: 3.645408 samples/s, speed: 1866.448730 tokens/s, learning rate: 1.510e-06, loss_scalings: 16777.216797, pp_loss: 5.802849
[INFO] 2021-07-09 16:46:47,604 [run_pretraining.py:  512]:	********exe.run_152******* 
[INFO] 2021-07-09 16:46:49,797 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:49,797 [run_pretraining.py:  534]:	loss/total_loss, 6.060450077056885, 153
[INFO] 2021-07-09 16:46:49,797 [run_pretraining.py:  535]:	loss/mlm_loss, 6.060450077056885, 153
[INFO] 2021-07-09 16:46:49,797 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5199999552351073e-06, 153
[INFO] 2021-07-09 16:46:49,797 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 153
[INFO] 2021-07-09 16:46:49,798 [run_pretraining.py:  558]:	worker_index: 4, step: 153, cost: 6.060450, mlm loss: 6.060450, speed: 0.456030 steps/s, speed: 3.648243 samples/s, speed: 1867.900503 tokens/s, learning rate: 1.520e-06, loss_scalings: 16777.216797, pp_loss: 5.808789
[INFO] 2021-07-09 16:46:49,798 [run_pretraining.py:  512]:	********exe.run_153******* 
[INFO] 2021-07-09 16:46:52,049 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:52,050 [run_pretraining.py:  534]:	loss/total_loss, 5.811341285705566, 154
[INFO] 2021-07-09 16:46:52,050 [run_pretraining.py:  535]:	loss/mlm_loss, 5.811341285705566, 154
[INFO] 2021-07-09 16:46:52,050 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5299999631679384e-06, 154
[INFO] 2021-07-09 16:46:52,050 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 154
[INFO] 2021-07-09 16:46:52,050 [run_pretraining.py:  558]:	worker_index: 4, step: 154, cost: 5.811341, mlm loss: 5.811341, speed: 0.444052 steps/s, speed: 3.552418 samples/s, speed: 1818.838224 tokens/s, learning rate: 1.530e-06, loss_scalings: 16777.216797, pp_loss: 5.783450
[INFO] 2021-07-09 16:46:52,050 [run_pretraining.py:  512]:	********exe.run_154******* 
[INFO] 2021-07-09 16:46:54,314 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:54,314 [run_pretraining.py:  534]:	loss/total_loss, 5.718306064605713, 155
[INFO] 2021-07-09 16:46:54,315 [run_pretraining.py:  535]:	loss/mlm_loss, 5.718306064605713, 155
[INFO] 2021-07-09 16:46:54,315 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5399999711007695e-06, 155
[INFO] 2021-07-09 16:46:54,315 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 155
[INFO] 2021-07-09 16:46:54,315 [run_pretraining.py:  558]:	worker_index: 4, step: 155, cost: 5.718306, mlm loss: 5.718306, speed: 0.441700 steps/s, speed: 3.533602 samples/s, speed: 1809.204285 tokens/s, learning rate: 1.540e-06, loss_scalings: 16777.216797, pp_loss: 5.703372
[INFO] 2021-07-09 16:46:54,315 [run_pretraining.py:  512]:	********exe.run_155******* 
[INFO] 2021-07-09 16:46:56,505 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:56,506 [run_pretraining.py:  534]:	loss/total_loss, 5.721686363220215, 156
[INFO] 2021-07-09 16:46:56,506 [run_pretraining.py:  535]:	loss/mlm_loss, 5.721686363220215, 156
[INFO] 2021-07-09 16:46:56,506 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5499999790336005e-06, 156
[INFO] 2021-07-09 16:46:56,506 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 156
[INFO] 2021-07-09 16:46:56,506 [run_pretraining.py:  558]:	worker_index: 4, step: 156, cost: 5.721686, mlm loss: 5.721686, speed: 0.456469 steps/s, speed: 3.651750 samples/s, speed: 1869.696118 tokens/s, learning rate: 1.550e-06, loss_scalings: 16777.216797, pp_loss: 5.652457
[INFO] 2021-07-09 16:46:56,506 [run_pretraining.py:  512]:	********exe.run_156******* 
[INFO] 2021-07-09 16:46:58,697 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:58,697 [run_pretraining.py:  534]:	loss/total_loss, 5.5713210105896, 157
[INFO] 2021-07-09 16:46:58,697 [run_pretraining.py:  535]:	loss/mlm_loss, 5.5713210105896, 157
[INFO] 2021-07-09 16:46:58,698 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5599998732795939e-06, 157
[INFO] 2021-07-09 16:46:58,698 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 157
[INFO] 2021-07-09 16:46:58,698 [run_pretraining.py:  558]:	worker_index: 4, step: 157, cost: 5.571321, mlm loss: 5.571321, speed: 0.456425 steps/s, speed: 3.651399 samples/s, speed: 1869.516055 tokens/s, learning rate: 1.560e-06, loss_scalings: 16777.216797, pp_loss: 5.615707
[INFO] 2021-07-09 16:46:58,698 [run_pretraining.py:  512]:	********exe.run_157******* 
[INFO] 2021-07-09 16:47:00,884 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:00,884 [run_pretraining.py:  534]:	loss/total_loss, 5.670474052429199, 158
[INFO] 2021-07-09 16:47:00,885 [run_pretraining.py:  535]:	loss/mlm_loss, 5.670474052429199, 158
[INFO] 2021-07-09 16:47:00,885 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.569999881212425e-06, 158
[INFO] 2021-07-09 16:47:00,885 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 158
[INFO] 2021-07-09 16:47:00,885 [run_pretraining.py:  558]:	worker_index: 4, step: 158, cost: 5.670474, mlm loss: 5.670474, speed: 0.457347 steps/s, speed: 3.658779 samples/s, speed: 1873.294660 tokens/s, learning rate: 1.570e-06, loss_scalings: 16777.216797, pp_loss: 5.644176
[INFO] 2021-07-09 16:47:00,885 [run_pretraining.py:  512]:	********exe.run_158******* 
[INFO] 2021-07-09 16:47:03,098 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:03,099 [run_pretraining.py:  534]:	loss/total_loss, 5.57580041885376, 159
[INFO] 2021-07-09 16:47:03,099 [run_pretraining.py:  535]:	loss/mlm_loss, 5.57580041885376, 159
[INFO] 2021-07-09 16:47:03,099 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.579999889145256e-06, 159
[INFO] 2021-07-09 16:47:03,099 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 159
[INFO] 2021-07-09 16:47:03,099 [run_pretraining.py:  558]:	worker_index: 4, step: 159, cost: 5.575800, mlm loss: 5.575800, speed: 0.451756 steps/s, speed: 3.614051 samples/s, speed: 1850.394287 tokens/s, learning rate: 1.580e-06, loss_scalings: 16777.216797, pp_loss: 5.611168
[INFO] 2021-07-09 16:47:03,099 [run_pretraining.py:  512]:	********exe.run_159******* 
[INFO] 2021-07-09 16:47:05,330 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:05,330 [run_pretraining.py:  534]:	loss/total_loss, 5.555692672729492, 160
[INFO] 2021-07-09 16:47:05,330 [run_pretraining.py:  535]:	loss/mlm_loss, 5.555692672729492, 160
[INFO] 2021-07-09 16:47:05,330 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5900000107649248e-06, 160
[INFO] 2021-07-09 16:47:05,330 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 160
[INFO] 2021-07-09 16:47:05,330 [run_pretraining.py:  558]:	worker_index: 4, step: 160, cost: 5.555693, mlm loss: 5.555693, speed: 0.448312 steps/s, speed: 3.586497 samples/s, speed: 1836.286558 tokens/s, learning rate: 1.590e-06, loss_scalings: 16777.216797, pp_loss: 5.556055
[INFO] 2021-07-09 16:47:05,331 [run_pretraining.py:  512]:	********exe.run_160******* 
[INFO] 2021-07-09 16:47:07,607 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:07,608 [run_pretraining.py:  534]:	loss/total_loss, 5.383884429931641, 161
[INFO] 2021-07-09 16:47:07,608 [run_pretraining.py:  535]:	loss/mlm_loss, 5.383884429931641, 161
[INFO] 2021-07-09 16:47:07,608 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6000000186977559e-06, 161
[INFO] 2021-07-09 16:47:07,608 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 161
[INFO] 2021-07-09 16:47:07,608 [run_pretraining.py:  558]:	worker_index: 4, step: 161, cost: 5.383884, mlm loss: 5.383884, speed: 0.439194 steps/s, speed: 3.513551 samples/s, speed: 1798.938051 tokens/s, learning rate: 1.600e-06, loss_scalings: 16777.216797, pp_loss: 5.464618
[INFO] 2021-07-09 16:47:07,608 [run_pretraining.py:  512]:	********exe.run_161******* 
[INFO] 2021-07-09 16:47:09,830 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:09,831 [run_pretraining.py:  534]:	loss/total_loss, 5.45036506652832, 162
[INFO] 2021-07-09 16:47:09,831 [run_pretraining.py:  535]:	loss/mlm_loss, 5.45036506652832, 162
[INFO] 2021-07-09 16:47:09,831 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.610000026630587e-06, 162
[INFO] 2021-07-09 16:47:09,831 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 162
[INFO] 2021-07-09 16:47:09,831 [run_pretraining.py:  558]:	worker_index: 4, step: 162, cost: 5.450365, mlm loss: 5.450365, speed: 0.449984 steps/s, speed: 3.599869 samples/s, speed: 1843.132678 tokens/s, learning rate: 1.610e-06, loss_scalings: 16777.216797, pp_loss: 5.436056
[INFO] 2021-07-09 16:47:09,831 [run_pretraining.py:  512]:	********exe.run_162******* 
[INFO] 2021-07-09 16:47:12,114 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:12,115 [run_pretraining.py:  534]:	loss/total_loss, 5.424083709716797, 163
[INFO] 2021-07-09 16:47:12,115 [run_pretraining.py:  535]:	loss/mlm_loss, 5.424083709716797, 163
[INFO] 2021-07-09 16:47:12,115 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.620000034563418e-06, 163
[INFO] 2021-07-09 16:47:12,115 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 163
[INFO] 2021-07-09 16:47:12,115 [run_pretraining.py:  558]:	worker_index: 4, step: 163, cost: 5.424084, mlm loss: 5.424084, speed: 0.437902 steps/s, speed: 3.503220 samples/s, speed: 1793.648388 tokens/s, learning rate: 1.620e-06, loss_scalings: 16777.216797, pp_loss: 5.488327
[INFO] 2021-07-09 16:47:12,115 [run_pretraining.py:  512]:	********exe.run_163******* 
[INFO] 2021-07-09 16:47:14,682 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:14,682 [run_pretraining.py:  534]:	loss/total_loss, 5.395400524139404, 164
[INFO] 2021-07-09 16:47:14,682 [run_pretraining.py:  535]:	loss/mlm_loss, 5.395400524139404, 164
[INFO] 2021-07-09 16:47:14,682 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6299999288094114e-06, 164
[INFO] 2021-07-09 16:47:14,682 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 164
[INFO] 2021-07-09 16:47:14,682 [run_pretraining.py:  558]:	worker_index: 4, step: 164, cost: 5.395401, mlm loss: 5.395401, speed: 0.389634 steps/s, speed: 3.117074 samples/s, speed: 1595.941742 tokens/s, learning rate: 1.630e-06, loss_scalings: 16777.216797, pp_loss: 5.409256
[INFO] 2021-07-09 16:47:14,683 [run_pretraining.py:  512]:	********exe.run_164******* 
[INFO] 2021-07-09 16:47:17,094 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:17,094 [run_pretraining.py:  534]:	loss/total_loss, 5.269278049468994, 165
[INFO] 2021-07-09 16:47:17,094 [run_pretraining.py:  535]:	loss/mlm_loss, 5.269278049468994, 165
[INFO] 2021-07-09 16:47:17,095 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6399999367422424e-06, 165
[INFO] 2021-07-09 16:47:17,095 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 165
[INFO] 2021-07-09 16:47:17,095 [run_pretraining.py:  558]:	worker_index: 4, step: 165, cost: 5.269278, mlm loss: 5.269278, speed: 0.414688 steps/s, speed: 3.317502 samples/s, speed: 1698.560986 tokens/s, learning rate: 1.640e-06, loss_scalings: 16777.216797, pp_loss: 5.331755
[INFO] 2021-07-09 16:47:17,095 [run_pretraining.py:  512]:	********exe.run_165******* 
[INFO] 2021-07-09 16:47:19,375 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:19,375 [run_pretraining.py:  534]:	loss/total_loss, 5.289797306060791, 166
[INFO] 2021-07-09 16:47:19,375 [run_pretraining.py:  535]:	loss/mlm_loss, 5.289797306060791, 166
[INFO] 2021-07-09 16:47:19,375 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6499999446750735e-06, 166
[INFO] 2021-07-09 16:47:19,375 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 166
[INFO] 2021-07-09 16:47:19,375 [run_pretraining.py:  558]:	worker_index: 4, step: 166, cost: 5.289797, mlm loss: 5.289797, speed: 0.438571 steps/s, speed: 3.508570 samples/s, speed: 1796.387934 tokens/s, learning rate: 1.650e-06, loss_scalings: 16777.216797, pp_loss: 5.314348
[INFO] 2021-07-09 16:47:19,376 [run_pretraining.py:  512]:	********exe.run_166******* 
[INFO] 2021-07-09 16:47:21,631 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:21,632 [run_pretraining.py:  534]:	loss/total_loss, 5.247448444366455, 167
[INFO] 2021-07-09 16:47:21,632 [run_pretraining.py:  535]:	loss/mlm_loss, 5.247448444366455, 167
[INFO] 2021-07-09 16:47:21,632 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6599999526079046e-06, 167
[INFO] 2021-07-09 16:47:21,632 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 167
[INFO] 2021-07-09 16:47:21,632 [run_pretraining.py:  558]:	worker_index: 4, step: 167, cost: 5.247448, mlm loss: 5.247448, speed: 0.443269 steps/s, speed: 3.546153 samples/s, speed: 1815.630434 tokens/s, learning rate: 1.660e-06, loss_scalings: 16777.216797, pp_loss: 5.244058
[INFO] 2021-07-09 16:47:21,632 [run_pretraining.py:  512]:	********exe.run_167******* 
[INFO] 2021-07-09 16:47:23,823 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:23,823 [run_pretraining.py:  534]:	loss/total_loss, 5.226810455322266, 168
[INFO] 2021-07-09 16:47:23,823 [run_pretraining.py:  535]:	loss/mlm_loss, 5.226810455322266, 168
[INFO] 2021-07-09 16:47:23,823 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6699999605407356e-06, 168
[INFO] 2021-07-09 16:47:23,824 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 168
[INFO] 2021-07-09 16:47:23,824 [run_pretraining.py:  558]:	worker_index: 4, step: 168, cost: 5.226810, mlm loss: 5.226810, speed: 0.456441 steps/s, speed: 3.651529 samples/s, speed: 1869.582990 tokens/s, learning rate: 1.670e-06, loss_scalings: 16777.216797, pp_loss: 5.186206
[INFO] 2021-07-09 16:47:23,824 [run_pretraining.py:  512]:	********exe.run_168******* 
[INFO] 2021-07-09 16:47:26,042 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:26,042 [run_pretraining.py:  534]:	loss/total_loss, 5.291261196136475, 169
[INFO] 2021-07-09 16:47:26,042 [run_pretraining.py:  535]:	loss/mlm_loss, 5.291261196136475, 169
[INFO] 2021-07-09 16:47:26,042 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.679999854786729e-06, 169
[INFO] 2021-07-09 16:47:26,043 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 169
[INFO] 2021-07-09 16:47:26,043 [run_pretraining.py:  558]:	worker_index: 4, step: 169, cost: 5.291261, mlm loss: 5.291261, speed: 0.450785 steps/s, speed: 3.606277 samples/s, speed: 1846.414064 tokens/s, learning rate: 1.680e-06, loss_scalings: 16777.216797, pp_loss: 5.225449
[INFO] 2021-07-09 16:47:26,043 [run_pretraining.py:  512]:	********exe.run_169******* 
[INFO] 2021-07-09 16:47:28,225 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:28,226 [run_pretraining.py:  534]:	loss/total_loss, 5.151559829711914, 170
[INFO] 2021-07-09 16:47:28,226 [run_pretraining.py:  535]:	loss/mlm_loss, 5.151559829711914, 170
[INFO] 2021-07-09 16:47:28,226 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.68999986271956e-06, 170
[INFO] 2021-07-09 16:47:28,226 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 170
[INFO] 2021-07-09 16:47:28,226 [run_pretraining.py:  558]:	worker_index: 4, step: 170, cost: 5.151560, mlm loss: 5.151560, speed: 0.458116 steps/s, speed: 3.664931 samples/s, speed: 1876.444596 tokens/s, learning rate: 1.690e-06, loss_scalings: 16777.216797, pp_loss: 5.155931
[INFO] 2021-07-09 16:47:28,226 [run_pretraining.py:  512]:	********exe.run_170******* 
[INFO] 2021-07-09 16:47:30,415 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:30,416 [run_pretraining.py:  534]:	loss/total_loss, 5.007632255554199, 171
[INFO] 2021-07-09 16:47:30,416 [run_pretraining.py:  535]:	loss/mlm_loss, 5.007632255554199, 171
[INFO] 2021-07-09 16:47:30,416 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7000000980260666e-06, 171
[INFO] 2021-07-09 16:47:30,416 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 171
[INFO] 2021-07-09 16:47:30,416 [run_pretraining.py:  558]:	worker_index: 4, step: 171, cost: 5.007632, mlm loss: 5.007632, speed: 0.456692 steps/s, speed: 3.653539 samples/s, speed: 1870.612024 tokens/s, learning rate: 1.700e-06, loss_scalings: 16777.216797, pp_loss: 5.065314
[INFO] 2021-07-09 16:47:30,417 [run_pretraining.py:  512]:	********exe.run_171******* 
[INFO] 2021-07-09 16:47:32,601 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:32,602 [run_pretraining.py:  534]:	loss/total_loss, 5.044589042663574, 172
[INFO] 2021-07-09 16:47:32,602 [run_pretraining.py:  535]:	loss/mlm_loss, 5.044589042663574, 172
[INFO] 2021-07-09 16:47:32,602 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.70999999227206e-06, 172
[INFO] 2021-07-09 16:47:32,602 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 172
[INFO] 2021-07-09 16:47:32,602 [run_pretraining.py:  558]:	worker_index: 4, step: 172, cost: 5.044589, mlm loss: 5.044589, speed: 0.457687 steps/s, speed: 3.661496 samples/s, speed: 1874.686120 tokens/s, learning rate: 1.710e-06, loss_scalings: 16777.216797, pp_loss: 5.098577
[INFO] 2021-07-09 16:47:32,602 [run_pretraining.py:  512]:	********exe.run_172******* 
[INFO] 2021-07-09 16:47:34,799 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:34,800 [run_pretraining.py:  534]:	loss/total_loss, 4.974618434906006, 173
[INFO] 2021-07-09 16:47:34,800 [run_pretraining.py:  535]:	loss/mlm_loss, 4.974618434906006, 173
[INFO] 2021-07-09 16:47:34,800 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.720000000204891e-06, 173
[INFO] 2021-07-09 16:47:34,800 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 173
[INFO] 2021-07-09 16:47:34,800 [run_pretraining.py:  558]:	worker_index: 4, step: 173, cost: 4.974618, mlm loss: 4.974618, speed: 0.455077 steps/s, speed: 3.640619 samples/s, speed: 1863.996768 tokens/s, learning rate: 1.720e-06, loss_scalings: 16777.216797, pp_loss: 5.008793
[INFO] 2021-07-09 16:47:34,800 [run_pretraining.py:  512]:	********exe.run_173******* 
[INFO] 2021-07-09 16:47:37,081 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:37,081 [run_pretraining.py:  534]:	loss/total_loss, 4.891006946563721, 174
[INFO] 2021-07-09 16:47:37,081 [run_pretraining.py:  535]:	loss/mlm_loss, 4.891006946563721, 174
[INFO] 2021-07-09 16:47:37,081 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.730000008137722e-06, 174
[INFO] 2021-07-09 16:47:37,081 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 174
[INFO] 2021-07-09 16:47:37,082 [run_pretraining.py:  558]:	worker_index: 4, step: 174, cost: 4.891007, mlm loss: 4.891007, speed: 0.438459 steps/s, speed: 3.507676 samples/s, speed: 1795.929918 tokens/s, learning rate: 1.730e-06, loss_scalings: 16777.216797, pp_loss: 4.953290
[INFO] 2021-07-09 16:47:37,082 [run_pretraining.py:  512]:	********exe.run_174******* 
[INFO] 2021-07-09 16:47:39,271 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:39,271 [run_pretraining.py:  534]:	loss/total_loss, 5.1145124435424805, 175
[INFO] 2021-07-09 16:47:39,271 [run_pretraining.py:  535]:	loss/mlm_loss, 5.1145124435424805, 175
[INFO] 2021-07-09 16:47:39,272 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.740000016070553e-06, 175
[INFO] 2021-07-09 16:47:39,272 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 175
[INFO] 2021-07-09 16:47:39,272 [run_pretraining.py:  558]:	worker_index: 4, step: 175, cost: 5.114512, mlm loss: 5.114512, speed: 0.456743 steps/s, speed: 3.653947 samples/s, speed: 1870.820819 tokens/s, learning rate: 1.740e-06, loss_scalings: 16777.216797, pp_loss: 4.948295
[INFO] 2021-07-09 16:47:39,272 [run_pretraining.py:  512]:	********exe.run_175******* 
[INFO] 2021-07-09 16:47:41,614 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:41,614 [run_pretraining.py:  534]:	loss/total_loss, 4.915033340454102, 176
[INFO] 2021-07-09 16:47:41,615 [run_pretraining.py:  535]:	loss/mlm_loss, 4.915033340454102, 176
[INFO] 2021-07-09 16:47:41,615 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7499999103165464e-06, 176
[INFO] 2021-07-09 16:47:41,615 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 176
[INFO] 2021-07-09 16:47:41,615 [run_pretraining.py:  558]:	worker_index: 4, step: 176, cost: 4.915033, mlm loss: 4.915033, speed: 0.426885 steps/s, speed: 3.415080 samples/s, speed: 1748.520813 tokens/s, learning rate: 1.750e-06, loss_scalings: 16777.216797, pp_loss: 4.947652
[INFO] 2021-07-09 16:47:41,615 [run_pretraining.py:  512]:	********exe.run_176******* 
[INFO] 2021-07-09 16:47:43,826 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:43,826 [run_pretraining.py:  534]:	loss/total_loss, 4.8427510261535645, 177
[INFO] 2021-07-09 16:47:43,826 [run_pretraining.py:  535]:	loss/mlm_loss, 4.8427510261535645, 177
[INFO] 2021-07-09 16:47:43,826 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7599999182493775e-06, 177
[INFO] 2021-07-09 16:47:43,826 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 177
[INFO] 2021-07-09 16:47:43,827 [run_pretraining.py:  558]:	worker_index: 4, step: 177, cost: 4.842751, mlm loss: 4.842751, speed: 0.452278 steps/s, speed: 3.618223 samples/s, speed: 1852.530064 tokens/s, learning rate: 1.760e-06, loss_scalings: 16777.216797, pp_loss: 4.903714
[INFO] 2021-07-09 16:47:43,827 [run_pretraining.py:  512]:	********exe.run_177******* 
[INFO] 2021-07-09 16:47:46,086 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:46,086 [run_pretraining.py:  534]:	loss/total_loss, 4.946786403656006, 178
[INFO] 2021-07-09 16:47:46,086 [run_pretraining.py:  535]:	loss/mlm_loss, 4.946786403656006, 178
[INFO] 2021-07-09 16:47:46,086 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7699999261822086e-06, 178
[INFO] 2021-07-09 16:47:46,087 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 178
[INFO] 2021-07-09 16:47:46,087 [run_pretraining.py:  558]:	worker_index: 4, step: 178, cost: 4.946786, mlm loss: 4.946786, speed: 0.442599 steps/s, speed: 3.540795 samples/s, speed: 1812.887213 tokens/s, learning rate: 1.770e-06, loss_scalings: 13421.773438, pp_loss: 4.868331
[INFO] 2021-07-09 16:47:46,087 [run_pretraining.py:  512]:	********exe.run_178******* 
[INFO] 2021-07-09 16:47:48,288 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:48,289 [run_pretraining.py:  534]:	loss/total_loss, 4.826286792755127, 179
[INFO] 2021-07-09 16:47:48,289 [run_pretraining.py:  535]:	loss/mlm_loss, 4.826286792755127, 179
[INFO] 2021-07-09 16:47:48,289 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7799999341150397e-06, 179
[INFO] 2021-07-09 16:47:48,289 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 179
[INFO] 2021-07-09 16:47:48,289 [run_pretraining.py:  558]:	worker_index: 4, step: 179, cost: 4.826287, mlm loss: 4.826287, speed: 0.454169 steps/s, speed: 3.633354 samples/s, speed: 1860.277498 tokens/s, learning rate: 1.780e-06, loss_scalings: 13421.773438, pp_loss: 4.855731
[INFO] 2021-07-09 16:47:48,289 [run_pretraining.py:  512]:	********exe.run_179******* 
[INFO] 2021-07-09 16:47:50,501 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:50,501 [run_pretraining.py:  534]:	loss/total_loss, 4.7675461769104, 180
[INFO] 2021-07-09 16:47:50,501 [run_pretraining.py:  535]:	loss/mlm_loss, 4.7675461769104, 180
[INFO] 2021-07-09 16:47:50,501 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7899999420478707e-06, 180
[INFO] 2021-07-09 16:47:50,502 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 180
[INFO] 2021-07-09 16:47:50,502 [run_pretraining.py:  558]:	worker_index: 4, step: 180, cost: 4.767546, mlm loss: 4.767546, speed: 0.452130 steps/s, speed: 3.617037 samples/s, speed: 1851.923189 tokens/s, learning rate: 1.790e-06, loss_scalings: 13421.773438, pp_loss: 4.821678
[INFO] 2021-07-09 16:47:50,502 [run_pretraining.py:  512]:	********exe.run_180******* 
[INFO] 2021-07-09 16:47:52,709 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:52,710 [run_pretraining.py:  534]:	loss/total_loss, 4.832959175109863, 181
[INFO] 2021-07-09 16:47:52,710 [run_pretraining.py:  535]:	loss/mlm_loss, 4.832959175109863, 181
[INFO] 2021-07-09 16:47:52,710 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.799999836293864e-06, 181
[INFO] 2021-07-09 16:47:52,710 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 181
[INFO] 2021-07-09 16:47:52,710 [run_pretraining.py:  558]:	worker_index: 4, step: 181, cost: 4.832959, mlm loss: 4.832959, speed: 0.452934 steps/s, speed: 3.623470 samples/s, speed: 1855.216744 tokens/s, learning rate: 1.800e-06, loss_scalings: 13421.773438, pp_loss: 4.780721
[INFO] 2021-07-09 16:47:52,710 [run_pretraining.py:  512]:	********exe.run_181******* 
[INFO] 2021-07-09 16:47:54,970 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:54,971 [run_pretraining.py:  534]:	loss/total_loss, 4.8411688804626465, 182
[INFO] 2021-07-09 16:47:54,971 [run_pretraining.py:  535]:	loss/mlm_loss, 4.8411688804626465, 182
[INFO] 2021-07-09 16:47:54,971 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8100000716003706e-06, 182
[INFO] 2021-07-09 16:47:54,971 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 182
[INFO] 2021-07-09 16:47:54,971 [run_pretraining.py:  558]:	worker_index: 4, step: 182, cost: 4.841169, mlm loss: 4.841169, speed: 0.442430 steps/s, speed: 3.539437 samples/s, speed: 1812.191902 tokens/s, learning rate: 1.810e-06, loss_scalings: 13421.773438, pp_loss: 4.804605
[INFO] 2021-07-09 16:47:54,971 [run_pretraining.py:  512]:	********exe.run_182******* 
[INFO] 2021-07-09 16:47:57,192 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:57,193 [run_pretraining.py:  534]:	loss/total_loss, 4.747873783111572, 183
[INFO] 2021-07-09 16:47:57,193 [run_pretraining.py:  535]:	loss/mlm_loss, 4.747873783111572, 183
[INFO] 2021-07-09 16:47:57,193 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8200000795332016e-06, 183
[INFO] 2021-07-09 16:47:57,193 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 183
[INFO] 2021-07-09 16:47:57,193 [run_pretraining.py:  558]:	worker_index: 4, step: 183, cost: 4.747874, mlm loss: 4.747874, speed: 0.450182 steps/s, speed: 3.601458 samples/s, speed: 1843.946340 tokens/s, learning rate: 1.820e-06, loss_scalings: 13421.773438, pp_loss: 4.757911
[INFO] 2021-07-09 16:47:57,193 [run_pretraining.py:  512]:	********exe.run_183******* 
[INFO] 2021-07-09 16:47:59,433 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:59,434 [run_pretraining.py:  534]:	loss/total_loss, 4.797508716583252, 184
[INFO] 2021-07-09 16:47:59,434 [run_pretraining.py:  535]:	loss/mlm_loss, 4.797508716583252, 184
[INFO] 2021-07-09 16:47:59,434 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.829999973779195e-06, 184
[INFO] 2021-07-09 16:47:59,434 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 184
[INFO] 2021-07-09 16:47:59,434 [run_pretraining.py:  558]:	worker_index: 4, step: 184, cost: 4.797509, mlm loss: 4.797509, speed: 0.446316 steps/s, speed: 3.570530 samples/s, speed: 1828.111243 tokens/s, learning rate: 1.830e-06, loss_scalings: 13421.773438, pp_loss: 4.723602
[INFO] 2021-07-09 16:47:59,434 [run_pretraining.py:  512]:	********exe.run_184******* 
[INFO] 2021-07-09 16:48:01,644 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:01,645 [run_pretraining.py:  534]:	loss/total_loss, 4.798925399780273, 185
[INFO] 2021-07-09 16:48:01,645 [run_pretraining.py:  535]:	loss/mlm_loss, 4.798925399780273, 185
[INFO] 2021-07-09 16:48:01,645 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.839999981712026e-06, 185
[INFO] 2021-07-09 16:48:01,645 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 185
[INFO] 2021-07-09 16:48:01,645 [run_pretraining.py:  558]:	worker_index: 4, step: 185, cost: 4.798925, mlm loss: 4.798925, speed: 0.452421 steps/s, speed: 3.619367 samples/s, speed: 1853.116148 tokens/s, learning rate: 1.840e-06, loss_scalings: 13421.773438, pp_loss: 4.693136
[INFO] 2021-07-09 16:48:01,645 [run_pretraining.py:  512]:	********exe.run_185******* 
[INFO] 2021-07-09 16:48:03,848 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:03,849 [run_pretraining.py:  534]:	loss/total_loss, 4.843470573425293, 186
[INFO] 2021-07-09 16:48:03,849 [run_pretraining.py:  535]:	loss/mlm_loss, 4.843470573425293, 186
[INFO] 2021-07-09 16:48:03,849 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8499999896448571e-06, 186
[INFO] 2021-07-09 16:48:03,849 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 186
[INFO] 2021-07-09 16:48:03,849 [run_pretraining.py:  558]:	worker_index: 4, step: 186, cost: 4.843471, mlm loss: 4.843471, speed: 0.453889 steps/s, speed: 3.631112 samples/s, speed: 1859.129421 tokens/s, learning rate: 1.850e-06, loss_scalings: 13421.773438, pp_loss: 4.689624
[INFO] 2021-07-09 16:48:03,849 [run_pretraining.py:  512]:	********exe.run_186******* 
[INFO] 2021-07-09 16:48:06,088 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:06,089 [run_pretraining.py:  534]:	loss/total_loss, 4.891637325286865, 187
[INFO] 2021-07-09 16:48:06,089 [run_pretraining.py:  535]:	loss/mlm_loss, 4.891637325286865, 187
[INFO] 2021-07-09 16:48:06,089 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8599999975776882e-06, 187
[INFO] 2021-07-09 16:48:06,089 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 187
[INFO] 2021-07-09 16:48:06,089 [run_pretraining.py:  558]:	worker_index: 4, step: 187, cost: 4.891637, mlm loss: 4.891637, speed: 0.446505 steps/s, speed: 3.572041 samples/s, speed: 1828.884825 tokens/s, learning rate: 1.860e-06, loss_scalings: 13421.773438, pp_loss: 4.708868
[INFO] 2021-07-09 16:48:06,089 [run_pretraining.py:  512]:	********exe.run_187******* 
[INFO] 2021-07-09 16:48:08,292 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:08,292 [run_pretraining.py:  534]:	loss/total_loss, 4.575435638427734, 188
[INFO] 2021-07-09 16:48:08,292 [run_pretraining.py:  535]:	loss/mlm_loss, 4.575435638427734, 188
[INFO] 2021-07-09 16:48:08,292 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8699998918236815e-06, 188
[INFO] 2021-07-09 16:48:08,292 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 188
[INFO] 2021-07-09 16:48:08,292 [run_pretraining.py:  558]:	worker_index: 4, step: 188, cost: 4.575436, mlm loss: 4.575436, speed: 0.453993 steps/s, speed: 3.631946 samples/s, speed: 1859.556236 tokens/s, learning rate: 1.870e-06, loss_scalings: 13421.773438, pp_loss: 4.607456
[INFO] 2021-07-09 16:48:08,293 [run_pretraining.py:  512]:	********exe.run_188******* 
[INFO] 2021-07-09 16:48:10,530 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:10,530 [run_pretraining.py:  534]:	loss/total_loss, 4.530083656311035, 189
[INFO] 2021-07-09 16:48:10,530 [run_pretraining.py:  535]:	loss/mlm_loss, 4.530083656311035, 189
[INFO] 2021-07-09 16:48:10,530 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8799998997565126e-06, 189
[INFO] 2021-07-09 16:48:10,530 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 189
[INFO] 2021-07-09 16:48:10,530 [run_pretraining.py:  558]:	worker_index: 4, step: 189, cost: 4.530084, mlm loss: 4.530084, speed: 0.446988 steps/s, speed: 3.575901 samples/s, speed: 1830.861547 tokens/s, learning rate: 1.880e-06, loss_scalings: 13421.773438, pp_loss: 4.576602
[INFO] 2021-07-09 16:48:10,530 [run_pretraining.py:  512]:	********exe.run_189******* 
[INFO] 2021-07-09 16:48:12,847 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:12,848 [run_pretraining.py:  534]:	loss/total_loss, 4.575535774230957, 190
[INFO] 2021-07-09 16:48:12,848 [run_pretraining.py:  535]:	loss/mlm_loss, 4.575535774230957, 190
[INFO] 2021-07-09 16:48:12,848 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8899999076893437e-06, 190
[INFO] 2021-07-09 16:48:12,848 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 190
[INFO] 2021-07-09 16:48:12,848 [run_pretraining.py:  558]:	worker_index: 4, step: 190, cost: 4.575536, mlm loss: 4.575536, speed: 0.431589 steps/s, speed: 3.452713 samples/s, speed: 1767.788890 tokens/s, learning rate: 1.890e-06, loss_scalings: 13421.773438, pp_loss: 4.557817
[INFO] 2021-07-09 16:48:12,848 [run_pretraining.py:  512]:	********exe.run_190******* 
[INFO] 2021-07-09 16:48:15,118 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:15,118 [run_pretraining.py:  534]:	loss/total_loss, 4.467495918273926, 191
[INFO] 2021-07-09 16:48:15,119 [run_pretraining.py:  535]:	loss/mlm_loss, 4.467495918273926, 191
[INFO] 2021-07-09 16:48:15,119 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8999999156221747e-06, 191
[INFO] 2021-07-09 16:48:15,119 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 191
[INFO] 2021-07-09 16:48:15,119 [run_pretraining.py:  558]:	worker_index: 4, step: 191, cost: 4.467496, mlm loss: 4.467496, speed: 0.440481 steps/s, speed: 3.523850 samples/s, speed: 1804.211067 tokens/s, learning rate: 1.900e-06, loss_scalings: 13421.773438, pp_loss: 4.522434
[INFO] 2021-07-09 16:48:15,119 [run_pretraining.py:  512]:	********exe.run_191******* 
[INFO] 2021-07-09 16:48:17,319 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:17,320 [run_pretraining.py:  534]:	loss/total_loss, 4.540643692016602, 192
[INFO] 2021-07-09 16:48:17,320 [run_pretraining.py:  535]:	loss/mlm_loss, 4.540643692016602, 192
[INFO] 2021-07-09 16:48:17,320 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.909999809868168e-06, 192
[INFO] 2021-07-09 16:48:17,320 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 192
[INFO] 2021-07-09 16:48:17,320 [run_pretraining.py:  558]:	worker_index: 4, step: 192, cost: 4.540644, mlm loss: 4.540644, speed: 0.454407 steps/s, speed: 3.635258 samples/s, speed: 1861.251948 tokens/s, learning rate: 1.910e-06, loss_scalings: 13421.773438, pp_loss: 4.528719
[INFO] 2021-07-09 16:48:17,320 [run_pretraining.py:  512]:	********exe.run_192******* 
[INFO] 2021-07-09 16:48:19,606 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:19,606 [run_pretraining.py:  534]:	loss/total_loss, 4.44504451751709, 193
[INFO] 2021-07-09 16:48:19,607 [run_pretraining.py:  535]:	loss/mlm_loss, 4.44504451751709, 193
[INFO] 2021-07-09 16:48:19,607 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.919999931487837e-06, 193
[INFO] 2021-07-09 16:48:19,607 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 193
[INFO] 2021-07-09 16:48:19,607 [run_pretraining.py:  558]:	worker_index: 4, step: 193, cost: 4.445045, mlm loss: 4.445045, speed: 0.437454 steps/s, speed: 3.499632 samples/s, speed: 1791.811711 tokens/s, learning rate: 1.920e-06, loss_scalings: 13421.773438, pp_loss: 4.483395
[INFO] 2021-07-09 16:48:19,607 [run_pretraining.py:  512]:	********exe.run_193******* 
[INFO] 2021-07-09 16:48:21,834 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:21,835 [run_pretraining.py:  534]:	loss/total_loss, 4.484470367431641, 194
[INFO] 2021-07-09 16:48:21,835 [run_pretraining.py:  535]:	loss/mlm_loss, 4.484470367431641, 194
[INFO] 2021-07-09 16:48:21,835 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9300000531075057e-06, 194
[INFO] 2021-07-09 16:48:21,835 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 194
[INFO] 2021-07-09 16:48:21,835 [run_pretraining.py:  558]:	worker_index: 4, step: 194, cost: 4.484470, mlm loss: 4.484470, speed: 0.448864 steps/s, speed: 3.590916 samples/s, speed: 1838.548839 tokens/s, learning rate: 1.930e-06, loss_scalings: 13421.773438, pp_loss: 4.465052
[INFO] 2021-07-09 16:48:21,835 [run_pretraining.py:  512]:	********exe.run_194******* 
[INFO] 2021-07-09 16:48:24,146 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:24,146 [run_pretraining.py:  534]:	loss/total_loss, 4.367452144622803, 195
[INFO] 2021-07-09 16:48:24,146 [run_pretraining.py:  535]:	loss/mlm_loss, 4.367452144622803, 195
[INFO] 2021-07-09 16:48:24,146 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.939999947353499e-06, 195
[INFO] 2021-07-09 16:48:24,146 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 195
[INFO] 2021-07-09 16:48:24,146 [run_pretraining.py:  558]:	worker_index: 4, step: 195, cost: 4.367452, mlm loss: 4.367452, speed: 0.432821 steps/s, speed: 3.462568 samples/s, speed: 1772.835067 tokens/s, learning rate: 1.940e-06, loss_scalings: 13421.773438, pp_loss: 4.440850
[INFO] 2021-07-09 16:48:24,146 [run_pretraining.py:  512]:	********exe.run_195******* 
[INFO] 2021-07-09 16:48:26,407 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:26,407 [run_pretraining.py:  534]:	loss/total_loss, 4.336890697479248, 196
[INFO] 2021-07-09 16:48:26,408 [run_pretraining.py:  535]:	loss/mlm_loss, 4.336890697479248, 196
[INFO] 2021-07-09 16:48:26,408 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.950000068973168e-06, 196
[INFO] 2021-07-09 16:48:26,408 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 196
[INFO] 2021-07-09 16:48:26,408 [run_pretraining.py:  558]:	worker_index: 4, step: 196, cost: 4.336891, mlm loss: 4.336891, speed: 0.442329 steps/s, speed: 3.538633 samples/s, speed: 1811.780054 tokens/s, learning rate: 1.950e-06, loss_scalings: 13421.773438, pp_loss: 4.414956
[INFO] 2021-07-09 16:48:26,408 [run_pretraining.py:  512]:	********exe.run_196******* 
[INFO] 2021-07-09 16:48:28,645 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:28,645 [run_pretraining.py:  534]:	loss/total_loss, 4.382514476776123, 197
[INFO] 2021-07-09 16:48:28,645 [run_pretraining.py:  535]:	loss/mlm_loss, 4.382514476776123, 197
[INFO] 2021-07-09 16:48:28,645 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.959999963219161e-06, 197
[INFO] 2021-07-09 16:48:28,645 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 197
[INFO] 2021-07-09 16:48:28,646 [run_pretraining.py:  558]:	worker_index: 4, step: 197, cost: 4.382514, mlm loss: 4.382514, speed: 0.446998 steps/s, speed: 3.575985 samples/s, speed: 1830.904473 tokens/s, learning rate: 1.960e-06, loss_scalings: 13421.773438, pp_loss: 4.400776
[INFO] 2021-07-09 16:48:28,646 [run_pretraining.py:  512]:	********exe.run_197******* 
[INFO] 2021-07-09 16:48:30,889 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:30,890 [run_pretraining.py:  534]:	loss/total_loss, 4.351003646850586, 198
[INFO] 2021-07-09 16:48:30,890 [run_pretraining.py:  535]:	loss/mlm_loss, 4.351003646850586, 198
[INFO] 2021-07-09 16:48:30,890 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9699998574651545e-06, 198
[INFO] 2021-07-09 16:48:30,890 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 198
[INFO] 2021-07-09 16:48:30,890 [run_pretraining.py:  558]:	worker_index: 4, step: 198, cost: 4.351004, mlm loss: 4.351004, speed: 0.445633 steps/s, speed: 3.565065 samples/s, speed: 1825.313335 tokens/s, learning rate: 1.970e-06, loss_scalings: 13421.773438, pp_loss: 4.362788
[INFO] 2021-07-09 16:48:30,890 [run_pretraining.py:  512]:	********exe.run_198******* 
[INFO] 2021-07-09 16:48:33,122 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:33,123 [run_pretraining.py:  534]:	loss/total_loss, 4.274196147918701, 199
[INFO] 2021-07-09 16:48:33,123 [run_pretraining.py:  535]:	loss/mlm_loss, 4.274196147918701, 199
[INFO] 2021-07-09 16:48:33,123 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9799999790848233e-06, 199
[INFO] 2021-07-09 16:48:33,123 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 199
[INFO] 2021-07-09 16:48:33,123 [run_pretraining.py:  558]:	worker_index: 4, step: 199, cost: 4.274196, mlm loss: 4.274196, speed: 0.447948 steps/s, speed: 3.583582 samples/s, speed: 1834.793741 tokens/s, learning rate: 1.980e-06, loss_scalings: 13421.773438, pp_loss: 4.400017
[INFO] 2021-07-09 16:48:33,123 [run_pretraining.py:  512]:	********exe.run_199******* 
[INFO] 2021-07-09 16:48:35,359 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:35,360 [run_pretraining.py:  534]:	loss/total_loss, 4.324887752532959, 200
[INFO] 2021-07-09 16:48:35,360 [run_pretraining.py:  535]:	loss/mlm_loss, 4.324887752532959, 200
[INFO] 2021-07-09 16:48:35,360 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9899998733308166e-06, 200
[INFO] 2021-07-09 16:48:35,360 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 200
[INFO] 2021-07-09 16:48:35,360 [run_pretraining.py:  558]:	worker_index: 4, step: 200, cost: 4.324888, mlm loss: 4.324888, speed: 0.447248 steps/s, speed: 3.577980 samples/s, speed: 1831.925933 tokens/s, learning rate: 1.990e-06, loss_scalings: 13421.773438, pp_loss: 4.312423
[INFO] 2021-07-09 16:48:35,360 [run_pretraining.py:  512]:	********exe.run_200******* 
[INFO] 2021-07-09 16:48:37,573 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:37,573 [run_pretraining.py:  534]:	loss/total_loss, 4.263586521148682, 201
[INFO] 2021-07-09 16:48:37,573 [run_pretraining.py:  535]:	loss/mlm_loss, 4.263586521148682, 201
[INFO] 2021-07-09 16:48:37,573 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9999999949504854e-06, 201
[INFO] 2021-07-09 16:48:37,573 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 201
[INFO] 2021-07-09 16:48:37,573 [run_pretraining.py:  558]:	worker_index: 4, step: 201, cost: 4.263587, mlm loss: 4.263587, speed: 0.451922 steps/s, speed: 3.615375 samples/s, speed: 1851.071759 tokens/s, learning rate: 2.000e-06, loss_scalings: 13421.773438, pp_loss: 4.319923
[INFO] 2021-07-09 16:48:37,573 [run_pretraining.py:  512]:	********exe.run_201******* 
[INFO] 2021-07-09 16:48:39,794 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:39,795 [run_pretraining.py:  534]:	loss/total_loss, 4.359444618225098, 202
[INFO] 2021-07-09 16:48:39,795 [run_pretraining.py:  535]:	loss/mlm_loss, 4.359444618225098, 202
[INFO] 2021-07-09 16:48:39,795 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0099998891964788e-06, 202
[INFO] 2021-07-09 16:48:39,795 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 202
[INFO] 2021-07-09 16:48:39,795 [run_pretraining.py:  558]:	worker_index: 4, step: 202, cost: 4.359445, mlm loss: 4.359445, speed: 0.450229 steps/s, speed: 3.601835 samples/s, speed: 1844.139326 tokens/s, learning rate: 2.010e-06, loss_scalings: 13421.773438, pp_loss: 4.310233
[INFO] 2021-07-09 16:48:39,795 [run_pretraining.py:  512]:	********exe.run_202******* 
[INFO] 2021-07-09 16:48:42,046 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:42,046 [run_pretraining.py:  534]:	loss/total_loss, 4.219254493713379, 203
[INFO] 2021-07-09 16:48:42,046 [run_pretraining.py:  535]:	loss/mlm_loss, 4.219254493713379, 203
[INFO] 2021-07-09 16:48:42,046 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.019999783442472e-06, 203
[INFO] 2021-07-09 16:48:42,046 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 203
[INFO] 2021-07-09 16:48:42,046 [run_pretraining.py:  558]:	worker_index: 4, step: 203, cost: 4.219254, mlm loss: 4.219254, speed: 0.444286 steps/s, speed: 3.554292 samples/s, speed: 1819.797491 tokens/s, learning rate: 2.020e-06, loss_scalings: 13421.773438, pp_loss: 4.203445
[INFO] 2021-07-09 16:48:42,047 [run_pretraining.py:  512]:	********exe.run_203******* 
[INFO] 2021-07-09 16:48:44,327 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:44,328 [run_pretraining.py:  534]:	loss/total_loss, 4.170848369598389, 204
[INFO] 2021-07-09 16:48:44,328 [run_pretraining.py:  535]:	loss/mlm_loss, 4.170848369598389, 204
[INFO] 2021-07-09 16:48:44,328 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0300001324358163e-06, 204
[INFO] 2021-07-09 16:48:44,328 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 204
[INFO] 2021-07-09 16:48:44,328 [run_pretraining.py:  558]:	worker_index: 4, step: 204, cost: 4.170848, mlm loss: 4.170848, speed: 0.438419 steps/s, speed: 3.507350 samples/s, speed: 1795.763407 tokens/s, learning rate: 2.030e-06, loss_scalings: 13421.773438, pp_loss: 4.189745
[INFO] 2021-07-09 16:48:44,328 [run_pretraining.py:  512]:	********exe.run_204******* 
[INFO] 2021-07-09 16:48:46,639 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:46,639 [run_pretraining.py:  534]:	loss/total_loss, 4.167803764343262, 205
[INFO] 2021-07-09 16:48:46,640 [run_pretraining.py:  535]:	loss/mlm_loss, 4.167803764343262, 205
[INFO] 2021-07-09 16:48:46,640 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0400000266818097e-06, 205
[INFO] 2021-07-09 16:48:46,640 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 205
[INFO] 2021-07-09 16:48:46,640 [run_pretraining.py:  558]:	worker_index: 4, step: 205, cost: 4.167804, mlm loss: 4.167804, speed: 0.432710 steps/s, speed: 3.461682 samples/s, speed: 1772.381301 tokens/s, learning rate: 2.040e-06, loss_scalings: 13421.773438, pp_loss: 4.201885
[INFO] 2021-07-09 16:48:46,640 [run_pretraining.py:  512]:	********exe.run_205******* 
[INFO] 2021-07-09 16:48:48,874 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:48,874 [run_pretraining.py:  534]:	loss/total_loss, 4.243779182434082, 206
[INFO] 2021-07-09 16:48:48,875 [run_pretraining.py:  535]:	loss/mlm_loss, 4.243779182434082, 206
[INFO] 2021-07-09 16:48:48,875 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.049999920927803e-06, 206
[INFO] 2021-07-09 16:48:48,875 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 206
[INFO] 2021-07-09 16:48:48,875 [run_pretraining.py:  558]:	worker_index: 4, step: 206, cost: 4.243779, mlm loss: 4.243779, speed: 0.447579 steps/s, speed: 3.580635 samples/s, speed: 1833.285351 tokens/s, learning rate: 2.050e-06, loss_scalings: 13421.773438, pp_loss: 4.147795
[INFO] 2021-07-09 16:48:48,875 [run_pretraining.py:  512]:	********exe.run_206******* 
[INFO] 2021-07-09 16:48:51,109 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:51,109 [run_pretraining.py:  534]:	loss/total_loss, 4.1422319412231445, 207
[INFO] 2021-07-09 16:48:51,110 [run_pretraining.py:  535]:	loss/mlm_loss, 4.1422319412231445, 207
[INFO] 2021-07-09 16:48:51,110 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.060000042547472e-06, 207
[INFO] 2021-07-09 16:48:51,110 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 207
[INFO] 2021-07-09 16:48:51,110 [run_pretraining.py:  558]:	worker_index: 4, step: 207, cost: 4.142232, mlm loss: 4.142232, speed: 0.447546 steps/s, speed: 3.580371 samples/s, speed: 1833.149788 tokens/s, learning rate: 2.060e-06, loss_scalings: 13421.773438, pp_loss: 4.132727
[INFO] 2021-07-09 16:48:51,110 [run_pretraining.py:  512]:	********exe.run_207******* 
[INFO] 2021-07-09 16:48:53,386 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:53,387 [run_pretraining.py:  534]:	loss/total_loss, 4.067396640777588, 208
[INFO] 2021-07-09 16:48:53,387 [run_pretraining.py:  535]:	loss/mlm_loss, 4.067396640777588, 208
[INFO] 2021-07-09 16:48:53,387 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.069999936793465e-06, 208
[INFO] 2021-07-09 16:48:53,387 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 208
[INFO] 2021-07-09 16:48:53,387 [run_pretraining.py:  558]:	worker_index: 4, step: 208, cost: 4.067397, mlm loss: 4.067397, speed: 0.439201 steps/s, speed: 3.513610 samples/s, speed: 1798.968379 tokens/s, learning rate: 2.070e-06, loss_scalings: 13421.773438, pp_loss: 4.136952
[INFO] 2021-07-09 16:48:53,387 [run_pretraining.py:  512]:	********exe.run_208******* 
[INFO] 2021-07-09 16:48:55,625 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:55,625 [run_pretraining.py:  534]:	loss/total_loss, 4.077925205230713, 209
[INFO] 2021-07-09 16:48:55,625 [run_pretraining.py:  535]:	loss/mlm_loss, 4.077925205230713, 209
[INFO] 2021-07-09 16:48:55,625 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.080000058413134e-06, 209
[INFO] 2021-07-09 16:48:55,625 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 209
[INFO] 2021-07-09 16:48:55,625 [run_pretraining.py:  558]:	worker_index: 4, step: 209, cost: 4.077925, mlm loss: 4.077925, speed: 0.446933 steps/s, speed: 3.575461 samples/s, speed: 1830.636021 tokens/s, learning rate: 2.080e-06, loss_scalings: 13421.773438, pp_loss: 4.080554
[INFO] 2021-07-09 16:48:55,625 [run_pretraining.py:  512]:	********exe.run_209******* 
[INFO] 2021-07-09 16:48:57,907 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:57,908 [run_pretraining.py:  534]:	loss/total_loss, 4.117236137390137, 210
[INFO] 2021-07-09 16:48:57,908 [run_pretraining.py:  535]:	loss/mlm_loss, 4.117236137390137, 210
[INFO] 2021-07-09 16:48:57,908 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0899999526591273e-06, 210
[INFO] 2021-07-09 16:48:57,908 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 210
[INFO] 2021-07-09 16:48:57,908 [run_pretraining.py:  558]:	worker_index: 4, step: 210, cost: 4.117236, mlm loss: 4.117236, speed: 0.438224 steps/s, speed: 3.505792 samples/s, speed: 1794.965260 tokens/s, learning rate: 2.090e-06, loss_scalings: 13421.773438, pp_loss: 4.068526
[INFO] 2021-07-09 16:48:57,908 [run_pretraining.py:  512]:	********exe.run_210******* 
[INFO] 2021-07-09 16:49:00,151 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:00,151 [run_pretraining.py:  534]:	loss/total_loss, 4.034609317779541, 211
[INFO] 2021-07-09 16:49:00,151 [run_pretraining.py:  535]:	loss/mlm_loss, 4.034609317779541, 211
[INFO] 2021-07-09 16:49:00,151 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0999998469051206e-06, 211
[INFO] 2021-07-09 16:49:00,152 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 211
[INFO] 2021-07-09 16:49:00,152 [run_pretraining.py:  558]:	worker_index: 4, step: 211, cost: 4.034609, mlm loss: 4.034609, speed: 0.445843 steps/s, speed: 3.566740 samples/s, speed: 1826.170928 tokens/s, learning rate: 2.100e-06, loss_scalings: 13421.773438, pp_loss: 4.076149
[INFO] 2021-07-09 16:49:00,152 [run_pretraining.py:  512]:	********exe.run_211******* 
[INFO] 2021-07-09 16:49:02,444 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:02,444 [run_pretraining.py:  534]:	loss/total_loss, 3.950671911239624, 212
[INFO] 2021-07-09 16:49:02,444 [run_pretraining.py:  535]:	loss/mlm_loss, 3.950671911239624, 212
[INFO] 2021-07-09 16:49:02,444 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1099999685247894e-06, 212
[INFO] 2021-07-09 16:49:02,444 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 212
[INFO] 2021-07-09 16:49:02,444 [run_pretraining.py:  558]:	worker_index: 4, step: 212, cost: 3.950672, mlm loss: 3.950672, speed: 0.436273 steps/s, speed: 3.490183 samples/s, speed: 1786.973941 tokens/s, learning rate: 2.110e-06, loss_scalings: 13421.773438, pp_loss: 4.017529
[INFO] 2021-07-09 16:49:02,445 [run_pretraining.py:  512]:	********exe.run_212******* 
[INFO] 2021-07-09 16:49:04,755 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:04,755 [run_pretraining.py:  534]:	loss/total_loss, 4.114698886871338, 213
[INFO] 2021-07-09 16:49:04,755 [run_pretraining.py:  535]:	loss/mlm_loss, 4.114698886871338, 213
[INFO] 2021-07-09 16:49:04,755 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1199998627707828e-06, 213
[INFO] 2021-07-09 16:49:04,756 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 213
[INFO] 2021-07-09 16:49:04,756 [run_pretraining.py:  558]:	worker_index: 4, step: 213, cost: 4.114699, mlm loss: 4.114699, speed: 0.432797 steps/s, speed: 3.462372 samples/s, speed: 1772.734637 tokens/s, learning rate: 2.120e-06, loss_scalings: 13421.773438, pp_loss: 4.020730
[INFO] 2021-07-09 16:49:04,756 [run_pretraining.py:  512]:	********exe.run_213******* 
[INFO] 2021-07-09 16:49:07,149 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:07,150 [run_pretraining.py:  534]:	loss/total_loss, 4.071420669555664, 214
[INFO] 2021-07-09 16:49:07,150 [run_pretraining.py:  535]:	loss/mlm_loss, 4.071420669555664, 214
[INFO] 2021-07-09 16:49:07,150 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.129999757016776e-06, 214
[INFO] 2021-07-09 16:49:07,150 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 214
[INFO] 2021-07-09 16:49:07,150 [run_pretraining.py:  558]:	worker_index: 4, step: 214, cost: 4.071421, mlm loss: 4.071421, speed: 0.417771 steps/s, speed: 3.342170 samples/s, speed: 1711.191094 tokens/s, learning rate: 2.130e-06, loss_scalings: 13421.773438, pp_loss: 4.020368
[INFO] 2021-07-09 16:49:07,150 [run_pretraining.py:  512]:	********exe.run_214******* 
[INFO] 2021-07-09 16:49:09,451 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:09,452 [run_pretraining.py:  534]:	loss/total_loss, 3.9106531143188477, 215
[INFO] 2021-07-09 16:49:09,452 [run_pretraining.py:  535]:	loss/mlm_loss, 3.9106531143188477, 215
[INFO] 2021-07-09 16:49:09,452 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1400001060101204e-06, 215
[INFO] 2021-07-09 16:49:09,452 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 215
[INFO] 2021-07-09 16:49:09,452 [run_pretraining.py:  558]:	worker_index: 4, step: 215, cost: 3.910653, mlm loss: 3.910653, speed: 0.434520 steps/s, speed: 3.476157 samples/s, speed: 1779.792343 tokens/s, learning rate: 2.140e-06, loss_scalings: 13421.773438, pp_loss: 3.941109
[INFO] 2021-07-09 16:49:09,452 [run_pretraining.py:  512]:	********exe.run_215******* 
[INFO] 2021-07-09 16:49:11,723 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:11,724 [run_pretraining.py:  534]:	loss/total_loss, 3.8510422706604004, 216
[INFO] 2021-07-09 16:49:11,724 [run_pretraining.py:  535]:	loss/mlm_loss, 3.8510422706604004, 216
[INFO] 2021-07-09 16:49:11,724 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1500000002561137e-06, 216
[INFO] 2021-07-09 16:49:11,724 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 216
[INFO] 2021-07-09 16:49:11,724 [run_pretraining.py:  558]:	worker_index: 4, step: 216, cost: 3.851042, mlm loss: 3.851042, speed: 0.440258 steps/s, speed: 3.522062 samples/s, speed: 1803.295793 tokens/s, learning rate: 2.150e-06, loss_scalings: 13421.773438, pp_loss: 3.930377
[INFO] 2021-07-09 16:49:11,724 [run_pretraining.py:  512]:	********exe.run_216******* 
[INFO] 2021-07-09 16:49:14,064 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:14,065 [run_pretraining.py:  534]:	loss/total_loss, 3.8600995540618896, 217
[INFO] 2021-07-09 16:49:14,065 [run_pretraining.py:  535]:	loss/mlm_loss, 3.8600995540618896, 217
[INFO] 2021-07-09 16:49:14,065 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.159999894502107e-06, 217
[INFO] 2021-07-09 16:49:14,065 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 217
[INFO] 2021-07-09 16:49:14,065 [run_pretraining.py:  558]:	worker_index: 4, step: 217, cost: 3.860100, mlm loss: 3.860100, speed: 0.427305 steps/s, speed: 3.418441 samples/s, speed: 1750.241952 tokens/s, learning rate: 2.160e-06, loss_scalings: 13421.773438, pp_loss: 3.927311
[INFO] 2021-07-09 16:49:14,065 [run_pretraining.py:  512]:	********exe.run_217******* 
[INFO] 2021-07-09 16:49:16,332 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:16,332 [run_pretraining.py:  534]:	loss/total_loss, 4.015957355499268, 218
[INFO] 2021-07-09 16:49:16,333 [run_pretraining.py:  535]:	loss/mlm_loss, 4.015957355499268, 218
[INFO] 2021-07-09 16:49:16,333 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.170000016121776e-06, 218
[INFO] 2021-07-09 16:49:16,333 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 218
[INFO] 2021-07-09 16:49:16,333 [run_pretraining.py:  558]:	worker_index: 4, step: 218, cost: 4.015957, mlm loss: 4.015957, speed: 0.441062 steps/s, speed: 3.528493 samples/s, speed: 1806.588333 tokens/s, learning rate: 2.170e-06, loss_scalings: 13421.773438, pp_loss: 3.901710
[INFO] 2021-07-09 16:49:16,333 [run_pretraining.py:  512]:	********exe.run_218******* 
[INFO] 2021-07-09 16:49:18,672 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:18,673 [run_pretraining.py:  534]:	loss/total_loss, 3.924643039703369, 219
[INFO] 2021-07-09 16:49:18,673 [run_pretraining.py:  535]:	loss/mlm_loss, 3.924643039703369, 219
[INFO] 2021-07-09 16:49:18,673 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.179999910367769e-06, 219
[INFO] 2021-07-09 16:49:18,673 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 219
[INFO] 2021-07-09 16:49:18,673 [run_pretraining.py:  558]:	worker_index: 4, step: 219, cost: 3.924643, mlm loss: 3.924643, speed: 0.427402 steps/s, speed: 3.419216 samples/s, speed: 1750.638426 tokens/s, learning rate: 2.180e-06, loss_scalings: 13421.773438, pp_loss: 3.892576
[INFO] 2021-07-09 16:49:18,673 [run_pretraining.py:  512]:	********exe.run_219******* 
[INFO] 2021-07-09 16:49:20,893 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:20,893 [run_pretraining.py:  534]:	loss/total_loss, 3.877270221710205, 220
[INFO] 2021-07-09 16:49:20,893 [run_pretraining.py:  535]:	loss/mlm_loss, 3.877270221710205, 220
[INFO] 2021-07-09 16:49:20,894 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.190000031987438e-06, 220
[INFO] 2021-07-09 16:49:20,894 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 220
[INFO] 2021-07-09 16:49:20,894 [run_pretraining.py:  558]:	worker_index: 4, step: 220, cost: 3.877270, mlm loss: 3.877270, speed: 0.450475 steps/s, speed: 3.603804 samples/s, speed: 1845.147471 tokens/s, learning rate: 2.190e-06, loss_scalings: 13421.773438, pp_loss: 3.879122
[INFO] 2021-07-09 16:49:20,894 [run_pretraining.py:  512]:	********exe.run_220******* 
[INFO] 2021-07-09 16:49:23,196 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:23,197 [run_pretraining.py:  534]:	loss/total_loss, 3.7987141609191895, 221
[INFO] 2021-07-09 16:49:23,197 [run_pretraining.py:  535]:	loss/mlm_loss, 3.7987141609191895, 221
[INFO] 2021-07-09 16:49:23,197 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1999999262334313e-06, 221
[INFO] 2021-07-09 16:49:23,197 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 221
[INFO] 2021-07-09 16:49:23,197 [run_pretraining.py:  558]:	worker_index: 4, step: 221, cost: 3.798714, mlm loss: 3.798714, speed: 0.434241 steps/s, speed: 3.473925 samples/s, speed: 1778.649540 tokens/s, learning rate: 2.200e-06, loss_scalings: 13421.773438, pp_loss: 3.865146
[INFO] 2021-07-09 16:49:23,197 [run_pretraining.py:  512]:	********exe.run_221******* 
[INFO] 2021-07-09 16:49:25,462 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:25,463 [run_pretraining.py:  534]:	loss/total_loss, 4.010045528411865, 222
[INFO] 2021-07-09 16:49:25,463 [run_pretraining.py:  535]:	loss/mlm_loss, 4.010045528411865, 222
[INFO] 2021-07-09 16:49:25,463 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2099998204794247e-06, 222
[INFO] 2021-07-09 16:49:25,463 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 222
[INFO] 2021-07-09 16:49:25,463 [run_pretraining.py:  558]:	worker_index: 4, step: 222, cost: 4.010046, mlm loss: 4.010046, speed: 0.441486 steps/s, speed: 3.531884 samples/s, speed: 1808.324861 tokens/s, learning rate: 2.210e-06, loss_scalings: 13421.773438, pp_loss: 3.832847
[INFO] 2021-07-09 16:49:25,463 [run_pretraining.py:  512]:	********exe.run_222******* 
[INFO] 2021-07-09 16:49:27,751 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:27,751 [run_pretraining.py:  534]:	loss/total_loss, 3.9577958583831787, 223
[INFO] 2021-07-09 16:49:27,751 [run_pretraining.py:  535]:	loss/mlm_loss, 3.9577958583831787, 223
[INFO] 2021-07-09 16:49:27,752 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2199999420990935e-06, 223
[INFO] 2021-07-09 16:49:27,752 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 223
[INFO] 2021-07-09 16:49:27,752 [run_pretraining.py:  558]:	worker_index: 4, step: 223, cost: 3.957796, mlm loss: 3.957796, speed: 0.437070 steps/s, speed: 3.496561 samples/s, speed: 1790.238995 tokens/s, learning rate: 2.220e-06, loss_scalings: 13421.773438, pp_loss: 3.837683
[INFO] 2021-07-09 16:49:27,752 [run_pretraining.py:  512]:	********exe.run_223******* 
[INFO] 2021-07-09 16:49:30,054 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:30,055 [run_pretraining.py:  534]:	loss/total_loss, 3.823465347290039, 224
[INFO] 2021-07-09 16:49:30,055 [run_pretraining.py:  535]:	loss/mlm_loss, 3.823465347290039, 224
[INFO] 2021-07-09 16:49:30,055 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.229999836345087e-06, 224
[INFO] 2021-07-09 16:49:30,055 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 224
[INFO] 2021-07-09 16:49:30,055 [run_pretraining.py:  558]:	worker_index: 4, step: 224, cost: 3.823465, mlm loss: 3.823465, speed: 0.434282 steps/s, speed: 3.474254 samples/s, speed: 1778.818233 tokens/s, learning rate: 2.230e-06, loss_scalings: 13421.773438, pp_loss: 3.833195
[INFO] 2021-07-09 16:49:30,055 [run_pretraining.py:  512]:	********exe.run_224******* 
[INFO] 2021-07-09 16:49:32,353 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:32,353 [run_pretraining.py:  534]:	loss/total_loss, 3.966761589050293, 225
[INFO] 2021-07-09 16:49:32,354 [run_pretraining.py:  535]:	loss/mlm_loss, 3.966761589050293, 225
[INFO] 2021-07-09 16:49:32,354 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2399999579647556e-06, 225
[INFO] 2021-07-09 16:49:32,354 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 225
[INFO] 2021-07-09 16:49:32,354 [run_pretraining.py:  558]:	worker_index: 4, step: 225, cost: 3.966762, mlm loss: 3.966762, speed: 0.435111 steps/s, speed: 3.480892 samples/s, speed: 1782.216578 tokens/s, learning rate: 2.240e-06, loss_scalings: 13421.773438, pp_loss: 3.842586
[INFO] 2021-07-09 16:49:32,354 [run_pretraining.py:  512]:	********exe.run_225******* 
[INFO] 2021-07-09 16:49:34,667 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:34,667 [run_pretraining.py:  534]:	loss/total_loss, 3.8168630599975586, 226
[INFO] 2021-07-09 16:49:34,668 [run_pretraining.py:  535]:	loss/mlm_loss, 3.8168630599975586, 226
[INFO] 2021-07-09 16:49:34,668 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2500000795844244e-06, 226
[INFO] 2021-07-09 16:49:34,668 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 226
[INFO] 2021-07-09 16:49:34,668 [run_pretraining.py:  558]:	worker_index: 4, step: 226, cost: 3.816863, mlm loss: 3.816863, speed: 0.432280 steps/s, speed: 3.458243 samples/s, speed: 1770.620197 tokens/s, learning rate: 2.250e-06, loss_scalings: 13421.773438, pp_loss: 3.814319
[INFO] 2021-07-09 16:49:34,668 [run_pretraining.py:  512]:	********exe.run_226******* 
[INFO] 2021-07-09 16:49:36,893 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:36,894 [run_pretraining.py:  534]:	loss/total_loss, 3.772050380706787, 227
[INFO] 2021-07-09 16:49:36,894 [run_pretraining.py:  535]:	loss/mlm_loss, 3.772050380706787, 227
[INFO] 2021-07-09 16:49:36,894 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2599999738304177e-06, 227
[INFO] 2021-07-09 16:49:36,894 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 227
[INFO] 2021-07-09 16:49:36,894 [run_pretraining.py:  558]:	worker_index: 4, step: 227, cost: 3.772050, mlm loss: 3.772050, speed: 0.449332 steps/s, speed: 3.594657 samples/s, speed: 1840.464296 tokens/s, learning rate: 2.260e-06, loss_scalings: 10737.418945, pp_loss: 3.806926
[INFO] 2021-07-09 16:49:36,894 [run_pretraining.py:  512]:	********exe.run_227******* 
[INFO] 2021-07-09 16:49:39,213 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:39,214 [run_pretraining.py:  534]:	loss/total_loss, 3.789911985397339, 228
[INFO] 2021-07-09 16:49:39,214 [run_pretraining.py:  535]:	loss/mlm_loss, 3.789911985397339, 228
[INFO] 2021-07-09 16:49:39,214 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2700000954500865e-06, 228
[INFO] 2021-07-09 16:49:39,214 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 228
[INFO] 2021-07-09 16:49:39,214 [run_pretraining.py:  558]:	worker_index: 4, step: 228, cost: 3.789912, mlm loss: 3.789912, speed: 0.431154 steps/s, speed: 3.449232 samples/s, speed: 1766.006943 tokens/s, learning rate: 2.270e-06, loss_scalings: 10737.418945, pp_loss: 3.798174
[INFO] 2021-07-09 16:49:39,214 [run_pretraining.py:  512]:	********exe.run_228******* 
[INFO] 2021-07-09 16:49:41,548 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:41,549 [run_pretraining.py:  534]:	loss/total_loss, 3.927114486694336, 229
[INFO] 2021-07-09 16:49:41,549 [run_pretraining.py:  535]:	loss/mlm_loss, 3.927114486694336, 229
[INFO] 2021-07-09 16:49:41,549 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.27999998969608e-06, 229
[INFO] 2021-07-09 16:49:41,549 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 229
[INFO] 2021-07-09 16:49:41,549 [run_pretraining.py:  558]:	worker_index: 4, step: 229, cost: 3.927114, mlm loss: 3.927114, speed: 0.428385 steps/s, speed: 3.427083 samples/s, speed: 1754.666645 tokens/s, learning rate: 2.280e-06, loss_scalings: 8589.935547, pp_loss: 3.800666
[INFO] 2021-07-09 16:49:41,549 [run_pretraining.py:  512]:	********exe.run_229******* 
[INFO] 2021-07-09 16:49:43,800 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:43,801 [run_pretraining.py:  534]:	loss/total_loss, 3.774358034133911, 230
[INFO] 2021-07-09 16:49:43,801 [run_pretraining.py:  535]:	loss/mlm_loss, 3.774358034133911, 230
[INFO] 2021-07-09 16:49:43,801 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.289999883942073e-06, 230
[INFO] 2021-07-09 16:49:43,801 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 230
[INFO] 2021-07-09 16:49:43,801 [run_pretraining.py:  558]:	worker_index: 4, step: 230, cost: 3.774358, mlm loss: 3.774358, speed: 0.444153 steps/s, speed: 3.553220 samples/s, speed: 1819.248857 tokens/s, learning rate: 2.290e-06, loss_scalings: 8589.935547, pp_loss: 3.786001
[INFO] 2021-07-09 16:49:43,801 [run_pretraining.py:  512]:	********exe.run_230******* 
[INFO] 2021-07-09 16:49:46,158 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:46,158 [run_pretraining.py:  534]:	loss/total_loss, 3.7594475746154785, 231
[INFO] 2021-07-09 16:49:46,158 [run_pretraining.py:  535]:	loss/mlm_loss, 3.7594475746154785, 231
[INFO] 2021-07-09 16:49:46,158 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.300000005561742e-06, 231
[INFO] 2021-07-09 16:49:46,158 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 231
[INFO] 2021-07-09 16:49:46,159 [run_pretraining.py:  558]:	worker_index: 4, step: 231, cost: 3.759448, mlm loss: 3.759448, speed: 0.424313 steps/s, speed: 3.394503 samples/s, speed: 1737.985571 tokens/s, learning rate: 2.300e-06, loss_scalings: 8589.935547, pp_loss: 3.773412
[INFO] 2021-07-09 16:49:46,159 [run_pretraining.py:  512]:	********exe.run_231******* 
[INFO] 2021-07-09 16:49:48,485 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:48,486 [run_pretraining.py:  534]:	loss/total_loss, 3.740902900695801, 232
[INFO] 2021-07-09 16:49:48,486 [run_pretraining.py:  535]:	loss/mlm_loss, 3.740902900695801, 232
[INFO] 2021-07-09 16:49:48,486 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3099998998077353e-06, 232
[INFO] 2021-07-09 16:49:48,486 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 232
[INFO] 2021-07-09 16:49:48,486 [run_pretraining.py:  558]:	worker_index: 4, step: 232, cost: 3.740903, mlm loss: 3.740903, speed: 0.429750 steps/s, speed: 3.437999 samples/s, speed: 1760.255403 tokens/s, learning rate: 2.310e-06, loss_scalings: 8589.935547, pp_loss: 3.805789
[INFO] 2021-07-09 16:49:48,486 [run_pretraining.py:  512]:	********exe.run_232******* 
[INFO] 2021-07-09 16:49:50,724 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:50,725 [run_pretraining.py:  534]:	loss/total_loss, 3.7384824752807617, 233
[INFO] 2021-07-09 16:49:50,725 [run_pretraining.py:  535]:	loss/mlm_loss, 3.7384824752807617, 233
[INFO] 2021-07-09 16:49:50,725 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.320000021427404e-06, 233
[INFO] 2021-07-09 16:49:50,725 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 233
[INFO] 2021-07-09 16:49:50,725 [run_pretraining.py:  558]:	worker_index: 4, step: 233, cost: 3.738482, mlm loss: 3.738482, speed: 0.446797 steps/s, speed: 3.574374 samples/s, speed: 1830.079274 tokens/s, learning rate: 2.320e-06, loss_scalings: 8589.935547, pp_loss: 3.736817
[INFO] 2021-07-09 16:49:50,725 [run_pretraining.py:  512]:	********exe.run_233******* 
[INFO] 2021-07-09 16:49:52,947 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:52,947 [run_pretraining.py:  534]:	loss/total_loss, 3.7678515911102295, 234
[INFO] 2021-07-09 16:49:52,947 [run_pretraining.py:  535]:	loss/mlm_loss, 3.7678515911102295, 234
[INFO] 2021-07-09 16:49:52,948 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3299999156733975e-06, 234
[INFO] 2021-07-09 16:49:52,948 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 234
[INFO] 2021-07-09 16:49:52,948 [run_pretraining.py:  558]:	worker_index: 4, step: 234, cost: 3.767852, mlm loss: 3.767852, speed: 0.450051 steps/s, speed: 3.600404 samples/s, speed: 1843.406984 tokens/s, learning rate: 2.330e-06, loss_scalings: 8589.935547, pp_loss: 3.761315
[INFO] 2021-07-09 16:49:52,948 [run_pretraining.py:  512]:	********exe.run_234******* 
[INFO] 2021-07-09 16:49:55,231 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:55,232 [run_pretraining.py:  534]:	loss/total_loss, 3.727912664413452, 235
[INFO] 2021-07-09 16:49:55,232 [run_pretraining.py:  535]:	loss/mlm_loss, 3.727912664413452, 235
[INFO] 2021-07-09 16:49:55,232 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.339999809919391e-06, 235
[INFO] 2021-07-09 16:49:55,232 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 235
[INFO] 2021-07-09 16:49:55,232 [run_pretraining.py:  558]:	worker_index: 4, step: 235, cost: 3.727913, mlm loss: 3.727913, speed: 0.437901 steps/s, speed: 3.503208 samples/s, speed: 1793.642583 tokens/s, learning rate: 2.340e-06, loss_scalings: 8589.935547, pp_loss: 3.749644
[INFO] 2021-07-09 16:49:55,232 [run_pretraining.py:  512]:	********exe.run_235******* 
[INFO] 2021-07-09 16:49:57,481 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:57,481 [run_pretraining.py:  534]:	loss/total_loss, 3.744141101837158, 236
[INFO] 2021-07-09 16:49:57,481 [run_pretraining.py:  535]:	loss/mlm_loss, 3.744141101837158, 236
[INFO] 2021-07-09 16:49:57,481 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3499999315390596e-06, 236
[INFO] 2021-07-09 16:49:57,482 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 236
[INFO] 2021-07-09 16:49:57,482 [run_pretraining.py:  558]:	worker_index: 4, step: 236, cost: 3.744141, mlm loss: 3.744141, speed: 0.444649 steps/s, speed: 3.557195 samples/s, speed: 1821.283759 tokens/s, learning rate: 2.350e-06, loss_scalings: 6871.948730, pp_loss: 3.744494
[INFO] 2021-07-09 16:49:57,482 [run_pretraining.py:  512]:	********exe.run_236******* 
[INFO] 2021-07-09 16:49:59,725 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:59,726 [run_pretraining.py:  534]:	loss/total_loss, 3.729382038116455, 237
[INFO] 2021-07-09 16:49:59,726 [run_pretraining.py:  535]:	loss/mlm_loss, 3.729382038116455, 237
[INFO] 2021-07-09 16:49:59,726 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3600000531587284e-06, 237
[INFO] 2021-07-09 16:49:59,726 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 237
[INFO] 2021-07-09 16:49:59,726 [run_pretraining.py:  558]:	worker_index: 4, step: 237, cost: 3.729382, mlm loss: 3.729382, speed: 0.445643 steps/s, speed: 3.565147 samples/s, speed: 1825.355225 tokens/s, learning rate: 2.360e-06, loss_scalings: 6871.948730, pp_loss: 3.769148
[INFO] 2021-07-09 16:49:59,726 [run_pretraining.py:  512]:	********exe.run_237******* 
[INFO] 2021-07-09 16:50:01,969 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:01,969 [run_pretraining.py:  534]:	loss/total_loss, 3.7405872344970703, 238
[INFO] 2021-07-09 16:50:01,969 [run_pretraining.py:  535]:	loss/mlm_loss, 3.7405872344970703, 238
[INFO] 2021-07-09 16:50:01,969 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3699999474047218e-06, 238
[INFO] 2021-07-09 16:50:01,969 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 238
[INFO] 2021-07-09 16:50:01,969 [run_pretraining.py:  558]:	worker_index: 4, step: 238, cost: 3.740587, mlm loss: 3.740587, speed: 0.445917 steps/s, speed: 3.567338 samples/s, speed: 1826.476907 tokens/s, learning rate: 2.370e-06, loss_scalings: 6871.948730, pp_loss: 3.746719
[INFO] 2021-07-09 16:50:01,970 [run_pretraining.py:  512]:	********exe.run_238******* 
[INFO] 2021-07-09 16:50:04,223 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:04,224 [run_pretraining.py:  534]:	loss/total_loss, 3.785371780395508, 239
[INFO] 2021-07-09 16:50:04,224 [run_pretraining.py:  535]:	loss/mlm_loss, 3.785371780395508, 239
[INFO] 2021-07-09 16:50:04,224 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3800000690243905e-06, 239
[INFO] 2021-07-09 16:50:04,224 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 239
[INFO] 2021-07-09 16:50:04,224 [run_pretraining.py:  558]:	worker_index: 4, step: 239, cost: 3.785372, mlm loss: 3.785372, speed: 0.443675 steps/s, speed: 3.549404 samples/s, speed: 1817.294811 tokens/s, learning rate: 2.380e-06, loss_scalings: 6871.948730, pp_loss: 3.763321
[INFO] 2021-07-09 16:50:04,224 [run_pretraining.py:  512]:	********exe.run_239******* 
[INFO] 2021-07-09 16:50:06,497 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:06,498 [run_pretraining.py:  534]:	loss/total_loss, 3.834080219268799, 240
[INFO] 2021-07-09 16:50:06,498 [run_pretraining.py:  535]:	loss/mlm_loss, 3.834080219268799, 240
[INFO] 2021-07-09 16:50:06,498 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.389999963270384e-06, 240
[INFO] 2021-07-09 16:50:06,498 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 240
[INFO] 2021-07-09 16:50:06,498 [run_pretraining.py:  558]:	worker_index: 4, step: 240, cost: 3.834080, mlm loss: 3.834080, speed: 0.439890 steps/s, speed: 3.519118 samples/s, speed: 1801.788649 tokens/s, learning rate: 2.390e-06, loss_scalings: 5497.559082, pp_loss: 3.797060
[INFO] 2021-07-09 16:50:06,498 [run_pretraining.py:  512]:	********exe.run_240******* 
[INFO] 2021-07-09 16:50:08,785 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:08,786 [run_pretraining.py:  534]:	loss/total_loss, 3.9754204750061035, 241
[INFO] 2021-07-09 16:50:08,786 [run_pretraining.py:  535]:	loss/mlm_loss, 3.9754204750061035, 241
[INFO] 2021-07-09 16:50:08,786 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3999998575163772e-06, 241
[INFO] 2021-07-09 16:50:08,786 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 241
[INFO] 2021-07-09 16:50:08,786 [run_pretraining.py:  558]:	worker_index: 4, step: 241, cost: 3.975420, mlm loss: 3.975420, speed: 0.437194 steps/s, speed: 3.497553 samples/s, speed: 1790.746936 tokens/s, learning rate: 2.400e-06, loss_scalings: 5497.559082, pp_loss: 3.803579
[INFO] 2021-07-09 16:50:08,786 [run_pretraining.py:  512]:	********exe.run_241******* 
[INFO] 2021-07-09 16:50:11,118 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:11,119 [run_pretraining.py:  534]:	loss/total_loss, 3.7583847045898438, 242
[INFO] 2021-07-09 16:50:11,119 [run_pretraining.py:  535]:	loss/mlm_loss, 3.7583847045898438, 242
[INFO] 2021-07-09 16:50:11,119 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.409999979136046e-06, 242
[INFO] 2021-07-09 16:50:11,119 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 242
[INFO] 2021-07-09 16:50:11,119 [run_pretraining.py:  558]:	worker_index: 4, step: 242, cost: 3.758385, mlm loss: 3.758385, speed: 0.428759 steps/s, speed: 3.430073 samples/s, speed: 1756.197562 tokens/s, learning rate: 2.410e-06, loss_scalings: 5497.559082, pp_loss: 3.826403
[INFO] 2021-07-09 16:50:11,119 [run_pretraining.py:  512]:	********exe.run_242******* 
[INFO] 2021-07-09 16:50:13,369 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:13,370 [run_pretraining.py:  534]:	loss/total_loss, 3.7702796459198, 243
[INFO] 2021-07-09 16:50:13,370 [run_pretraining.py:  535]:	loss/mlm_loss, 3.7702796459198, 243
[INFO] 2021-07-09 16:50:13,370 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4199998733820394e-06, 243
[INFO] 2021-07-09 16:50:13,370 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 243
[INFO] 2021-07-09 16:50:13,370 [run_pretraining.py:  558]:	worker_index: 4, step: 243, cost: 3.770280, mlm loss: 3.770280, speed: 0.444382 steps/s, speed: 3.555053 samples/s, speed: 1820.186958 tokens/s, learning rate: 2.420e-06, loss_scalings: 5497.559082, pp_loss: 3.792264
[INFO] 2021-07-09 16:50:13,370 [run_pretraining.py:  512]:	********exe.run_243******* 
[INFO] 2021-07-09 16:50:15,631 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:15,631 [run_pretraining.py:  534]:	loss/total_loss, 3.794856309890747, 244
[INFO] 2021-07-09 16:50:15,631 [run_pretraining.py:  535]:	loss/mlm_loss, 3.794856309890747, 244
[INFO] 2021-07-09 16:50:15,632 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.429999995001708e-06, 244
[INFO] 2021-07-09 16:50:15,632 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 244
[INFO] 2021-07-09 16:50:15,632 [run_pretraining.py:  558]:	worker_index: 4, step: 244, cost: 3.794856, mlm loss: 3.794856, speed: 0.442260 steps/s, speed: 3.538080 samples/s, speed: 1811.496934 tokens/s, learning rate: 2.430e-06, loss_scalings: 5497.559082, pp_loss: 3.828341
[INFO] 2021-07-09 16:50:15,632 [run_pretraining.py:  512]:	********exe.run_244******* 
[INFO] 2021-07-09 16:50:17,895 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:17,896 [run_pretraining.py:  534]:	loss/total_loss, 3.9457058906555176, 245
[INFO] 2021-07-09 16:50:17,896 [run_pretraining.py:  535]:	loss/mlm_loss, 3.9457058906555176, 245
[INFO] 2021-07-09 16:50:17,896 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4399998892477015e-06, 245
[INFO] 2021-07-09 16:50:17,896 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 245
[INFO] 2021-07-09 16:50:17,896 [run_pretraining.py:  558]:	worker_index: 4, step: 245, cost: 3.945706, mlm loss: 3.945706, speed: 0.441743 steps/s, speed: 3.533946 samples/s, speed: 1809.380348 tokens/s, learning rate: 2.440e-06, loss_scalings: 5497.559082, pp_loss: 3.861343
[INFO] 2021-07-09 16:50:17,896 [run_pretraining.py:  512]:	********exe.run_245******* 
[INFO] 2021-07-09 16:50:20,187 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:20,187 [run_pretraining.py:  534]:	loss/total_loss, 3.8081676959991455, 246
[INFO] 2021-07-09 16:50:20,188 [run_pretraining.py:  535]:	loss/mlm_loss, 3.8081676959991455, 246
[INFO] 2021-07-09 16:50:20,188 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.449999783493695e-06, 246
[INFO] 2021-07-09 16:50:20,188 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 246
[INFO] 2021-07-09 16:50:20,188 [run_pretraining.py:  558]:	worker_index: 4, step: 246, cost: 3.808168, mlm loss: 3.808168, speed: 0.436482 steps/s, speed: 3.491857 samples/s, speed: 1787.830855 tokens/s, learning rate: 2.450e-06, loss_scalings: 5497.559082, pp_loss: 3.861075
[INFO] 2021-07-09 16:50:20,188 [run_pretraining.py:  512]:	********exe.run_246******* 
[INFO] 2021-07-09 16:50:22,440 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:22,441 [run_pretraining.py:  534]:	loss/total_loss, 3.9380502700805664, 247
[INFO] 2021-07-09 16:50:22,441 [run_pretraining.py:  535]:	loss/mlm_loss, 3.9380502700805664, 247
[INFO] 2021-07-09 16:50:22,441 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4599999051133636e-06, 247
[INFO] 2021-07-09 16:50:22,441 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 247
[INFO] 2021-07-09 16:50:22,441 [run_pretraining.py:  558]:	worker_index: 4, step: 247, cost: 3.938050, mlm loss: 3.938050, speed: 0.443954 steps/s, speed: 3.551636 samples/s, speed: 1818.437593 tokens/s, learning rate: 2.460e-06, loss_scalings: 4398.047363, pp_loss: 3.935637
[INFO] 2021-07-09 16:50:22,441 [run_pretraining.py:  512]:	********exe.run_247******* 
[INFO] 2021-07-09 16:50:24,684 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:24,684 [run_pretraining.py:  534]:	loss/total_loss, 3.8987340927124023, 248
[INFO] 2021-07-09 16:50:24,685 [run_pretraining.py:  535]:	loss/mlm_loss, 3.8987340927124023, 248
[INFO] 2021-07-09 16:50:24,685 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4700000267330324e-06, 248
[INFO] 2021-07-09 16:50:24,685 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 248
[INFO] 2021-07-09 16:50:24,685 [run_pretraining.py:  558]:	worker_index: 4, step: 248, cost: 3.898734, mlm loss: 3.898734, speed: 0.445793 steps/s, speed: 3.566342 samples/s, speed: 1825.966934 tokens/s, learning rate: 2.470e-06, loss_scalings: 4398.047363, pp_loss: 3.895830
[INFO] 2021-07-09 16:50:24,685 [run_pretraining.py:  512]:	********exe.run_248******* 
[INFO] 2021-07-09 16:50:26,917 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:26,917 [run_pretraining.py:  534]:	loss/total_loss, 3.998322010040283, 249
[INFO] 2021-07-09 16:50:26,917 [run_pretraining.py:  535]:	loss/mlm_loss, 3.998322010040283, 249
[INFO] 2021-07-09 16:50:26,917 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4799999209790258e-06, 249
[INFO] 2021-07-09 16:50:26,917 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 249
[INFO] 2021-07-09 16:50:26,917 [run_pretraining.py:  558]:	worker_index: 4, step: 249, cost: 3.998322, mlm loss: 3.998322, speed: 0.448055 steps/s, speed: 3.584439 samples/s, speed: 1835.232587 tokens/s, learning rate: 2.480e-06, loss_scalings: 4398.047363, pp_loss: 3.981335
[INFO] 2021-07-09 16:50:26,917 [run_pretraining.py:  512]:	********exe.run_249******* 
[INFO] 2021-07-09 16:50:29,175 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:29,175 [run_pretraining.py:  534]:	loss/total_loss, 3.946493625640869, 250
[INFO] 2021-07-09 16:50:29,175 [run_pretraining.py:  535]:	loss/mlm_loss, 3.946493625640869, 250
[INFO] 2021-07-09 16:50:29,175 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4900000425986946e-06, 250
[INFO] 2021-07-09 16:50:29,175 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 250
[INFO] 2021-07-09 16:50:29,175 [run_pretraining.py:  558]:	worker_index: 4, step: 250, cost: 3.946494, mlm loss: 3.946494, speed: 0.442976 steps/s, speed: 3.543808 samples/s, speed: 1814.429853 tokens/s, learning rate: 2.490e-06, loss_scalings: 4398.047363, pp_loss: 3.949151
[INFO] 2021-07-09 16:50:29,176 [run_pretraining.py:  512]:	********exe.run_250******* 
[INFO] 2021-07-09 16:50:31,400 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:31,401 [run_pretraining.py:  534]:	loss/total_loss, 4.095254898071289, 251
[INFO] 2021-07-09 16:50:31,401 [run_pretraining.py:  535]:	loss/mlm_loss, 4.095254898071289, 251
[INFO] 2021-07-09 16:50:31,401 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.499999936844688e-06, 251
[INFO] 2021-07-09 16:50:31,401 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 251
[INFO] 2021-07-09 16:50:31,401 [run_pretraining.py:  558]:	worker_index: 4, step: 251, cost: 4.095255, mlm loss: 4.095255, speed: 0.449458 steps/s, speed: 3.595662 samples/s, speed: 1840.978849 tokens/s, learning rate: 2.500e-06, loss_scalings: 4398.047363, pp_loss: 3.988858
[INFO] 2021-07-09 16:50:31,401 [run_pretraining.py:  512]:	********exe.run_251******* 
[INFO] 2021-07-09 16:50:33,761 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:33,761 [run_pretraining.py:  534]:	loss/total_loss, 3.9401750564575195, 252
[INFO] 2021-07-09 16:50:33,761 [run_pretraining.py:  535]:	loss/mlm_loss, 3.9401750564575195, 252
[INFO] 2021-07-09 16:50:33,761 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5100000584643567e-06, 252
[INFO] 2021-07-09 16:50:33,761 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 252
[INFO] 2021-07-09 16:50:33,761 [run_pretraining.py:  558]:	worker_index: 4, step: 252, cost: 3.940175, mlm loss: 3.940175, speed: 0.423761 steps/s, speed: 3.390091 samples/s, speed: 1735.726565 tokens/s, learning rate: 2.510e-06, loss_scalings: 4398.047363, pp_loss: 3.990252
[INFO] 2021-07-09 16:50:33,762 [run_pretraining.py:  512]:	********exe.run_252******* 
[INFO] 2021-07-09 16:50:35,977 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:35,978 [run_pretraining.py:  534]:	loss/total_loss, 3.9676613807678223, 253
[INFO] 2021-07-09 16:50:35,978 [run_pretraining.py:  535]:	loss/mlm_loss, 3.9676613807678223, 253
[INFO] 2021-07-09 16:50:35,978 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.51999995271035e-06, 253
[INFO] 2021-07-09 16:50:35,978 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 253
[INFO] 2021-07-09 16:50:35,978 [run_pretraining.py:  558]:	worker_index: 4, step: 253, cost: 3.967661, mlm loss: 3.967661, speed: 0.451202 steps/s, speed: 3.609619 samples/s, speed: 1848.124847 tokens/s, learning rate: 2.520e-06, loss_scalings: 4398.047363, pp_loss: 3.975008
[INFO] 2021-07-09 16:50:35,979 [run_pretraining.py:  512]:	********exe.run_253******* 
[INFO] 2021-07-09 16:50:38,194 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:38,195 [run_pretraining.py:  534]:	loss/total_loss, 4.064603328704834, 254
[INFO] 2021-07-09 16:50:38,195 [run_pretraining.py:  535]:	loss/mlm_loss, 4.064603328704834, 254
[INFO] 2021-07-09 16:50:38,195 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5299998469563434e-06, 254
[INFO] 2021-07-09 16:50:38,195 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 254
[INFO] 2021-07-09 16:50:38,195 [run_pretraining.py:  558]:	worker_index: 4, step: 254, cost: 4.064603, mlm loss: 4.064603, speed: 0.451225 steps/s, speed: 3.609799 samples/s, speed: 1848.217101 tokens/s, learning rate: 2.530e-06, loss_scalings: 4398.047363, pp_loss: 4.045764
[INFO] 2021-07-09 16:50:38,196 [run_pretraining.py:  512]:	********exe.run_254******* 
[INFO] 2021-07-09 16:50:40,434 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:40,435 [run_pretraining.py:  534]:	loss/total_loss, 4.0575947761535645, 255
[INFO] 2021-07-09 16:50:40,435 [run_pretraining.py:  535]:	loss/mlm_loss, 4.0575947761535645, 255
[INFO] 2021-07-09 16:50:40,435 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.539999968576012e-06, 255
[INFO] 2021-07-09 16:50:40,435 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 255
[INFO] 2021-07-09 16:50:40,435 [run_pretraining.py:  558]:	worker_index: 4, step: 255, cost: 4.057595, mlm loss: 4.057595, speed: 0.446605 steps/s, speed: 3.572842 samples/s, speed: 1829.295137 tokens/s, learning rate: 2.540e-06, loss_scalings: 4398.047363, pp_loss: 4.044142
[INFO] 2021-07-09 16:50:40,435 [run_pretraining.py:  512]:	********exe.run_255******* 
[INFO] 2021-07-09 16:50:42,653 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:42,653 [run_pretraining.py:  534]:	loss/total_loss, 4.03433895111084, 256
[INFO] 2021-07-09 16:50:42,653 [run_pretraining.py:  535]:	loss/mlm_loss, 4.03433895111084, 256
[INFO] 2021-07-09 16:50:42,654 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5499998628220055e-06, 256
[INFO] 2021-07-09 16:50:42,654 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 256
[INFO] 2021-07-09 16:50:42,654 [run_pretraining.py:  558]:	worker_index: 4, step: 256, cost: 4.034339, mlm loss: 4.034339, speed: 0.450886 steps/s, speed: 3.607089 samples/s, speed: 1846.829700 tokens/s, learning rate: 2.550e-06, loss_scalings: 4398.047363, pp_loss: 4.109865
[INFO] 2021-07-09 16:50:42,654 [run_pretraining.py:  512]:	********exe.run_256******* 
[INFO] 2021-07-09 16:50:44,873 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:44,874 [run_pretraining.py:  534]:	loss/total_loss, 4.227304935455322, 257
[INFO] 2021-07-09 16:50:44,874 [run_pretraining.py:  535]:	loss/mlm_loss, 4.227304935455322, 257
[INFO] 2021-07-09 16:50:44,874 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.559999757067999e-06, 257
[INFO] 2021-07-09 16:50:44,874 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 257
[INFO] 2021-07-09 16:50:44,874 [run_pretraining.py:  558]:	worker_index: 4, step: 257, cost: 4.227305, mlm loss: 4.227305, speed: 0.450436 steps/s, speed: 3.603488 samples/s, speed: 1844.985776 tokens/s, learning rate: 2.560e-06, loss_scalings: 4398.047363, pp_loss: 4.124219
[INFO] 2021-07-09 16:50:44,875 [run_pretraining.py:  512]:	********exe.run_257******* 
[INFO] 2021-07-09 16:50:47,092 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:47,092 [run_pretraining.py:  534]:	loss/total_loss, 4.0951032638549805, 258
[INFO] 2021-07-09 16:50:47,092 [run_pretraining.py:  535]:	loss/mlm_loss, 4.0951032638549805, 258
[INFO] 2021-07-09 16:50:47,092 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5699998786876677e-06, 258
[INFO] 2021-07-09 16:50:47,092 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 258
[INFO] 2021-07-09 16:50:47,092 [run_pretraining.py:  558]:	worker_index: 4, step: 258, cost: 4.095103, mlm loss: 4.095103, speed: 0.451013 steps/s, speed: 3.608102 samples/s, speed: 1847.348018 tokens/s, learning rate: 2.570e-06, loss_scalings: 4398.047363, pp_loss: 4.094030
[INFO] 2021-07-09 16:50:47,092 [run_pretraining.py:  512]:	********exe.run_258******* 
[INFO] 2021-07-09 16:50:49,506 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:49,506 [run_pretraining.py:  534]:	loss/total_loss, 4.107618808746338, 259
[INFO] 2021-07-09 16:50:49,507 [run_pretraining.py:  535]:	loss/mlm_loss, 4.107618808746338, 259
[INFO] 2021-07-09 16:50:49,507 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5800000003073364e-06, 259
[INFO] 2021-07-09 16:50:49,507 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 259
[INFO] 2021-07-09 16:50:49,507 [run_pretraining.py:  558]:	worker_index: 4, step: 259, cost: 4.107619, mlm loss: 4.107619, speed: 0.414298 steps/s, speed: 3.314386 samples/s, speed: 1696.965420 tokens/s, learning rate: 2.580e-06, loss_scalings: 4398.047363, pp_loss: 4.182341
[INFO] 2021-07-09 16:50:49,507 [run_pretraining.py:  512]:	********exe.run_259******* 
[INFO] 2021-07-09 16:50:51,873 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:51,873 [run_pretraining.py:  534]:	loss/total_loss, 4.08351993560791, 260
[INFO] 2021-07-09 16:50:51,874 [run_pretraining.py:  535]:	loss/mlm_loss, 4.08351993560791, 260
[INFO] 2021-07-09 16:50:51,874 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.58999989455333e-06, 260
[INFO] 2021-07-09 16:50:51,874 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 260
[INFO] 2021-07-09 16:50:51,874 [run_pretraining.py:  558]:	worker_index: 4, step: 260, cost: 4.083520, mlm loss: 4.083520, speed: 0.422594 steps/s, speed: 3.380754 samples/s, speed: 1730.946166 tokens/s, learning rate: 2.590e-06, loss_scalings: 4398.047363, pp_loss: 4.148002
[INFO] 2021-07-09 16:50:51,874 [run_pretraining.py:  512]:	********exe.run_260******* 
[INFO] 2021-07-09 16:50:54,306 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:54,307 [run_pretraining.py:  534]:	loss/total_loss, 4.122128486633301, 261
[INFO] 2021-07-09 16:50:54,307 [run_pretraining.py:  535]:	loss/mlm_loss, 4.122128486633301, 261
[INFO] 2021-07-09 16:50:54,307 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6000000161729986e-06, 261
[INFO] 2021-07-09 16:50:54,307 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 261
[INFO] 2021-07-09 16:50:54,307 [run_pretraining.py:  558]:	worker_index: 4, step: 261, cost: 4.122128, mlm loss: 4.122128, speed: 0.411106 steps/s, speed: 3.288848 samples/s, speed: 1683.889998 tokens/s, learning rate: 2.600e-06, loss_scalings: 3518.437988, pp_loss: 4.148920
[INFO] 2021-07-09 16:50:54,307 [run_pretraining.py:  512]:	********exe.run_261******* 
[INFO] 2021-07-09 16:50:56,795 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:56,795 [run_pretraining.py:  534]:	loss/total_loss, 4.177836894989014, 262
[INFO] 2021-07-09 16:50:56,795 [run_pretraining.py:  535]:	loss/mlm_loss, 4.177836894989014, 262
[INFO] 2021-07-09 16:50:56,796 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.609999910418992e-06, 262
[INFO] 2021-07-09 16:50:56,796 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 262
[INFO] 2021-07-09 16:50:56,796 [run_pretraining.py:  558]:	worker_index: 4, step: 262, cost: 4.177837, mlm loss: 4.177837, speed: 0.401907 steps/s, speed: 3.215254 samples/s, speed: 1646.209864 tokens/s, learning rate: 2.610e-06, loss_scalings: 3518.437988, pp_loss: 4.205790
[INFO] 2021-07-09 16:50:56,796 [run_pretraining.py:  512]:	********exe.run_262******* 
[INFO] 2021-07-09 16:50:59,287 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:59,288 [run_pretraining.py:  534]:	loss/total_loss, 4.19278621673584, 263
[INFO] 2021-07-09 16:50:59,288 [run_pretraining.py:  535]:	loss/mlm_loss, 4.19278621673584, 263
[INFO] 2021-07-09 16:50:59,288 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6200000320386607e-06, 263
[INFO] 2021-07-09 16:50:59,288 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 263
[INFO] 2021-07-09 16:50:59,288 [run_pretraining.py:  558]:	worker_index: 4, step: 263, cost: 4.192786, mlm loss: 4.192786, speed: 0.401297 steps/s, speed: 3.210373 samples/s, speed: 1643.710753 tokens/s, learning rate: 2.620e-06, loss_scalings: 3518.437988, pp_loss: 4.237609
[INFO] 2021-07-09 16:50:59,288 [run_pretraining.py:  512]:	********exe.run_263******* 
[INFO] 2021-07-09 16:51:01,503 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:01,503 [run_pretraining.py:  534]:	loss/total_loss, 4.226984024047852, 264
[INFO] 2021-07-09 16:51:01,503 [run_pretraining.py:  535]:	loss/mlm_loss, 4.226984024047852, 264
[INFO] 2021-07-09 16:51:01,503 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.629999926284654e-06, 264
[INFO] 2021-07-09 16:51:01,503 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 264
[INFO] 2021-07-09 16:51:01,503 [run_pretraining.py:  558]:	worker_index: 4, step: 264, cost: 4.226984, mlm loss: 4.226984, speed: 0.451576 steps/s, speed: 3.612606 samples/s, speed: 1849.654181 tokens/s, learning rate: 2.630e-06, loss_scalings: 3518.437988, pp_loss: 4.275161
[INFO] 2021-07-09 16:51:01,503 [run_pretraining.py:  512]:	********exe.run_264******* 
[INFO] 2021-07-09 16:51:03,738 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:03,738 [run_pretraining.py:  534]:	loss/total_loss, 4.238725662231445, 265
[INFO] 2021-07-09 16:51:03,739 [run_pretraining.py:  535]:	loss/mlm_loss, 4.238725662231445, 265
[INFO] 2021-07-09 16:51:03,739 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6399998205306474e-06, 265
[INFO] 2021-07-09 16:51:03,739 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 265
[INFO] 2021-07-09 16:51:03,739 [run_pretraining.py:  558]:	worker_index: 4, step: 265, cost: 4.238726, mlm loss: 4.238726, speed: 0.447474 steps/s, speed: 3.579796 samples/s, speed: 1832.855452 tokens/s, learning rate: 2.640e-06, loss_scalings: 3518.437988, pp_loss: 4.245313
[INFO] 2021-07-09 16:51:03,739 [run_pretraining.py:  512]:	********exe.run_265******* 
[INFO] 2021-07-09 16:51:05,943 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:05,944 [run_pretraining.py:  534]:	loss/total_loss, 4.146410942077637, 266
[INFO] 2021-07-09 16:51:05,944 [run_pretraining.py:  535]:	loss/mlm_loss, 4.146410942077637, 266
[INFO] 2021-07-09 16:51:05,944 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.649999942150316e-06, 266
[INFO] 2021-07-09 16:51:05,944 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 266
[INFO] 2021-07-09 16:51:05,945 [run_pretraining.py:  558]:	worker_index: 4, step: 266, cost: 4.146411, mlm loss: 4.146411, speed: 0.453514 steps/s, speed: 3.628109 samples/s, speed: 1857.591616 tokens/s, learning rate: 2.650e-06, loss_scalings: 3518.437988, pp_loss: 4.296966
[INFO] 2021-07-09 16:51:05,945 [run_pretraining.py:  512]:	********exe.run_266******* 
[INFO] 2021-07-09 16:51:08,184 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:08,184 [run_pretraining.py:  534]:	loss/total_loss, 4.1616668701171875, 267
[INFO] 2021-07-09 16:51:08,185 [run_pretraining.py:  535]:	loss/mlm_loss, 4.1616668701171875, 267
[INFO] 2021-07-09 16:51:08,185 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6599998363963095e-06, 267
[INFO] 2021-07-09 16:51:08,185 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 267
[INFO] 2021-07-09 16:51:08,185 [run_pretraining.py:  558]:	worker_index: 4, step: 267, cost: 4.161667, mlm loss: 4.161667, speed: 0.446514 steps/s, speed: 3.572112 samples/s, speed: 1828.921233 tokens/s, learning rate: 2.660e-06, loss_scalings: 3518.437988, pp_loss: 4.248301
[INFO] 2021-07-09 16:51:08,185 [run_pretraining.py:  512]:	********exe.run_267******* 
[INFO] 2021-07-09 16:51:10,414 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:10,414 [run_pretraining.py:  534]:	loss/total_loss, 4.10787296295166, 268
[INFO] 2021-07-09 16:51:10,414 [run_pretraining.py:  535]:	loss/mlm_loss, 4.10787296295166, 268
[INFO] 2021-07-09 16:51:10,414 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6699999580159783e-06, 268
[INFO] 2021-07-09 16:51:10,415 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 268
[INFO] 2021-07-09 16:51:10,415 [run_pretraining.py:  558]:	worker_index: 4, step: 268, cost: 4.107873, mlm loss: 4.107873, speed: 0.448603 steps/s, speed: 3.588823 samples/s, speed: 1837.477138 tokens/s, learning rate: 2.670e-06, loss_scalings: 3518.437988, pp_loss: 4.212914
[INFO] 2021-07-09 16:51:10,415 [run_pretraining.py:  512]:	********exe.run_268******* 
[INFO] 2021-07-09 16:51:12,652 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:12,652 [run_pretraining.py:  534]:	loss/total_loss, 4.166269302368164, 269
[INFO] 2021-07-09 16:51:12,653 [run_pretraining.py:  535]:	loss/mlm_loss, 4.166269302368164, 269
[INFO] 2021-07-09 16:51:12,653 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6799998522619717e-06, 269
[INFO] 2021-07-09 16:51:12,653 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 269
[INFO] 2021-07-09 16:51:12,653 [run_pretraining.py:  558]:	worker_index: 4, step: 269, cost: 4.166269, mlm loss: 4.166269, speed: 0.446918 steps/s, speed: 3.575345 samples/s, speed: 1830.576723 tokens/s, learning rate: 2.680e-06, loss_scalings: 3518.437988, pp_loss: 4.164531
[INFO] 2021-07-09 16:51:12,653 [run_pretraining.py:  512]:	********exe.run_269******* 
[INFO] 2021-07-09 16:51:14,855 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:14,855 [run_pretraining.py:  534]:	loss/total_loss, 4.103511810302734, 270
[INFO] 2021-07-09 16:51:14,855 [run_pretraining.py:  535]:	loss/mlm_loss, 4.103511810302734, 270
[INFO] 2021-07-09 16:51:14,855 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6899999738816405e-06, 270
[INFO] 2021-07-09 16:51:14,855 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 270
[INFO] 2021-07-09 16:51:14,856 [run_pretraining.py:  558]:	worker_index: 4, step: 270, cost: 4.103512, mlm loss: 4.103512, speed: 0.454132 steps/s, speed: 3.633057 samples/s, speed: 1860.125427 tokens/s, learning rate: 2.690e-06, loss_scalings: 3518.437988, pp_loss: 4.146414
[INFO] 2021-07-09 16:51:14,856 [run_pretraining.py:  512]:	********exe.run_270******* 
[INFO] 2021-07-09 16:51:17,066 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:17,067 [run_pretraining.py:  534]:	loss/total_loss, 4.2231597900390625, 271
[INFO] 2021-07-09 16:51:17,067 [run_pretraining.py:  535]:	loss/mlm_loss, 4.2231597900390625, 271
[INFO] 2021-07-09 16:51:17,067 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7000000955013093e-06, 271
[INFO] 2021-07-09 16:51:17,067 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 271
[INFO] 2021-07-09 16:51:17,067 [run_pretraining.py:  558]:	worker_index: 4, step: 271, cost: 4.223160, mlm loss: 4.223160, speed: 0.452339 steps/s, speed: 3.618712 samples/s, speed: 1852.780398 tokens/s, learning rate: 2.700e-06, loss_scalings: 3518.437988, pp_loss: 4.171280
[INFO] 2021-07-09 16:51:17,067 [run_pretraining.py:  512]:	********exe.run_271******* 
[INFO] 2021-07-09 16:51:19,300 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:19,301 [run_pretraining.py:  534]:	loss/total_loss, 4.072973251342773, 272
[INFO] 2021-07-09 16:51:19,301 [run_pretraining.py:  535]:	loss/mlm_loss, 4.072973251342773, 272
[INFO] 2021-07-09 16:51:19,301 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7099999897473026e-06, 272
[INFO] 2021-07-09 16:51:19,301 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 272
[INFO] 2021-07-09 16:51:19,301 [run_pretraining.py:  558]:	worker_index: 4, step: 272, cost: 4.072973, mlm loss: 4.072973, speed: 0.447693 steps/s, speed: 3.581544 samples/s, speed: 1833.750291 tokens/s, learning rate: 2.710e-06, loss_scalings: 3518.437988, pp_loss: 4.081784
[INFO] 2021-07-09 16:51:19,301 [run_pretraining.py:  512]:	********exe.run_272******* 
[INFO] 2021-07-09 16:51:21,536 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:21,536 [run_pretraining.py:  534]:	loss/total_loss, 4.02700138092041, 273
[INFO] 2021-07-09 16:51:21,537 [run_pretraining.py:  535]:	loss/mlm_loss, 4.02700138092041, 273
[INFO] 2021-07-09 16:51:21,537 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.719999883993296e-06, 273
[INFO] 2021-07-09 16:51:21,537 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 273
[INFO] 2021-07-09 16:51:21,537 [run_pretraining.py:  558]:	worker_index: 4, step: 273, cost: 4.027001, mlm loss: 4.027001, speed: 0.447455 steps/s, speed: 3.579642 samples/s, speed: 1832.776457 tokens/s, learning rate: 2.720e-06, loss_scalings: 3518.437988, pp_loss: 4.036617
[INFO] 2021-07-09 16:51:21,537 [run_pretraining.py:  512]:	********exe.run_273******* 
[INFO] 2021-07-09 16:51:23,772 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:23,773 [run_pretraining.py:  534]:	loss/total_loss, 3.9577713012695312, 274
[INFO] 2021-07-09 16:51:23,773 [run_pretraining.py:  535]:	loss/mlm_loss, 3.9577713012695312, 274
[INFO] 2021-07-09 16:51:23,773 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7300000056129647e-06, 274
[INFO] 2021-07-09 16:51:23,773 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 274
[INFO] 2021-07-09 16:51:23,773 [run_pretraining.py:  558]:	worker_index: 4, step: 274, cost: 3.957771, mlm loss: 3.957771, speed: 0.447254 steps/s, speed: 3.578035 samples/s, speed: 1831.954063 tokens/s, learning rate: 2.730e-06, loss_scalings: 3518.437988, pp_loss: 4.077753
[INFO] 2021-07-09 16:51:23,774 [run_pretraining.py:  512]:	********exe.run_274******* 
[INFO] 2021-07-09 16:51:26,012 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:26,012 [run_pretraining.py:  534]:	loss/total_loss, 4.100184440612793, 275
[INFO] 2021-07-09 16:51:26,012 [run_pretraining.py:  535]:	loss/mlm_loss, 4.100184440612793, 275
[INFO] 2021-07-09 16:51:26,012 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.739999899858958e-06, 275
[INFO] 2021-07-09 16:51:26,013 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 275
[INFO] 2021-07-09 16:51:26,013 [run_pretraining.py:  558]:	worker_index: 4, step: 275, cost: 4.100184, mlm loss: 4.100184, speed: 0.446741 steps/s, speed: 3.573929 samples/s, speed: 1829.851407 tokens/s, learning rate: 2.740e-06, loss_scalings: 3518.437988, pp_loss: 4.002269
[INFO] 2021-07-09 16:51:26,013 [run_pretraining.py:  512]:	********exe.run_275******* 
[INFO] 2021-07-09 16:51:28,267 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:28,268 [run_pretraining.py:  534]:	loss/total_loss, 3.9097189903259277, 276
[INFO] 2021-07-09 16:51:28,268 [run_pretraining.py:  535]:	loss/mlm_loss, 3.9097189903259277, 276
[INFO] 2021-07-09 16:51:28,268 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.750000021478627e-06, 276
[INFO] 2021-07-09 16:51:28,268 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 276
[INFO] 2021-07-09 16:51:28,268 [run_pretraining.py:  558]:	worker_index: 4, step: 276, cost: 3.909719, mlm loss: 3.909719, speed: 0.443472 steps/s, speed: 3.547777 samples/s, speed: 1816.461857 tokens/s, learning rate: 2.750e-06, loss_scalings: 3518.437988, pp_loss: 3.967113
[INFO] 2021-07-09 16:51:28,268 [run_pretraining.py:  512]:	********exe.run_276******* 
[INFO] 2021-07-09 16:51:30,491 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:30,492 [run_pretraining.py:  534]:	loss/total_loss, 3.831559181213379, 277
[INFO] 2021-07-09 16:51:30,492 [run_pretraining.py:  535]:	loss/mlm_loss, 3.831559181213379, 277
[INFO] 2021-07-09 16:51:30,492 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7599999157246202e-06, 277
[INFO] 2021-07-09 16:51:30,492 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 277
[INFO] 2021-07-09 16:51:30,492 [run_pretraining.py:  558]:	worker_index: 4, step: 277, cost: 3.831559, mlm loss: 3.831559, speed: 0.449791 steps/s, speed: 3.598327 samples/s, speed: 1842.343443 tokens/s, learning rate: 2.760e-06, loss_scalings: 3518.437988, pp_loss: 3.886783
[INFO] 2021-07-09 16:51:30,492 [run_pretraining.py:  512]:	********exe.run_277******* 
[INFO] 2021-07-09 16:51:32,770 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:32,770 [run_pretraining.py:  534]:	loss/total_loss, 3.937105417251587, 278
[INFO] 2021-07-09 16:51:32,771 [run_pretraining.py:  535]:	loss/mlm_loss, 3.937105417251587, 278
[INFO] 2021-07-09 16:51:32,771 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7699998099706136e-06, 278
[INFO] 2021-07-09 16:51:32,771 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 278
[INFO] 2021-07-09 16:51:32,771 [run_pretraining.py:  558]:	worker_index: 4, step: 278, cost: 3.937105, mlm loss: 3.937105, speed: 0.438954 steps/s, speed: 3.511634 samples/s, speed: 1797.956424 tokens/s, learning rate: 2.770e-06, loss_scalings: 3518.437988, pp_loss: 3.941677
[INFO] 2021-07-09 16:51:32,771 [run_pretraining.py:  512]:	********exe.run_278******* 
[INFO] 2021-07-09 16:51:35,100 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:35,100 [run_pretraining.py:  534]:	loss/total_loss, 3.872243881225586, 279
[INFO] 2021-07-09 16:51:35,100 [run_pretraining.py:  535]:	loss/mlm_loss, 3.872243881225586, 279
[INFO] 2021-07-09 16:51:35,100 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7799999315902824e-06, 279
[INFO] 2021-07-09 16:51:35,100 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 279
[INFO] 2021-07-09 16:51:35,101 [run_pretraining.py:  558]:	worker_index: 4, step: 279, cost: 3.872244, mlm loss: 3.872244, speed: 0.429350 steps/s, speed: 3.434802 samples/s, speed: 1758.618569 tokens/s, learning rate: 2.780e-06, loss_scalings: 2814.750488, pp_loss: 3.919714
[INFO] 2021-07-09 16:51:35,101 [run_pretraining.py:  512]:	********exe.run_279******* 
[INFO] 2021-07-09 16:51:37,333 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:37,334 [run_pretraining.py:  534]:	loss/total_loss, 3.9252758026123047, 280
[INFO] 2021-07-09 16:51:37,334 [run_pretraining.py:  535]:	loss/mlm_loss, 3.9252758026123047, 280
[INFO] 2021-07-09 16:51:37,334 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7899998258362757e-06, 280
[INFO] 2021-07-09 16:51:37,334 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 280
[INFO] 2021-07-09 16:51:37,334 [run_pretraining.py:  558]:	worker_index: 4, step: 280, cost: 3.925276, mlm loss: 3.925276, speed: 0.447816 steps/s, speed: 3.582529 samples/s, speed: 1834.254633 tokens/s, learning rate: 2.790e-06, loss_scalings: 2814.750488, pp_loss: 3.906888
[INFO] 2021-07-09 16:51:37,334 [run_pretraining.py:  512]:	********exe.run_280******* 
[INFO] 2021-07-09 16:51:39,555 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:39,556 [run_pretraining.py:  534]:	loss/total_loss, 3.864461898803711, 281
[INFO] 2021-07-09 16:51:39,556 [run_pretraining.py:  535]:	loss/mlm_loss, 3.864461898803711, 281
[INFO] 2021-07-09 16:51:39,556 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7999999474559445e-06, 281
[INFO] 2021-07-09 16:51:39,556 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 281
[INFO] 2021-07-09 16:51:39,556 [run_pretraining.py:  558]:	worker_index: 4, step: 281, cost: 3.864462, mlm loss: 3.864462, speed: 0.450275 steps/s, speed: 3.602197 samples/s, speed: 1844.325027 tokens/s, learning rate: 2.800e-06, loss_scalings: 2814.750488, pp_loss: 3.891414
[INFO] 2021-07-09 16:51:39,556 [run_pretraining.py:  512]:	********exe.run_281******* 
[INFO] 2021-07-09 16:51:41,774 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:41,774 [run_pretraining.py:  534]:	loss/total_loss, 3.8957066535949707, 282
[INFO] 2021-07-09 16:51:41,774 [run_pretraining.py:  535]:	loss/mlm_loss, 3.8957066535949707, 282
[INFO] 2021-07-09 16:51:41,774 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8100000690756133e-06, 282
[INFO] 2021-07-09 16:51:41,775 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 282
[INFO] 2021-07-09 16:51:41,775 [run_pretraining.py:  558]:	worker_index: 4, step: 282, cost: 3.895707, mlm loss: 3.895707, speed: 0.450860 steps/s, speed: 3.606882 samples/s, speed: 1846.723490 tokens/s, learning rate: 2.810e-06, loss_scalings: 2814.750488, pp_loss: 3.934018
[INFO] 2021-07-09 16:51:41,775 [run_pretraining.py:  512]:	********exe.run_282******* 
[INFO] 2021-07-09 16:51:43,998 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:43,998 [run_pretraining.py:  534]:	loss/total_loss, 3.9736595153808594, 283
[INFO] 2021-07-09 16:51:43,998 [run_pretraining.py:  535]:	loss/mlm_loss, 3.9736595153808594, 283
[INFO] 2021-07-09 16:51:43,998 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8199999633216066e-06, 283
[INFO] 2021-07-09 16:51:43,998 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 283
[INFO] 2021-07-09 16:51:43,998 [run_pretraining.py:  558]:	worker_index: 4, step: 283, cost: 3.973660, mlm loss: 3.973660, speed: 0.449821 steps/s, speed: 3.598570 samples/s, speed: 1842.467920 tokens/s, learning rate: 2.820e-06, loss_scalings: 2814.750488, pp_loss: 3.955580
[INFO] 2021-07-09 16:51:43,998 [run_pretraining.py:  512]:	********exe.run_283******* 
[INFO] 2021-07-09 16:51:46,229 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:46,229 [run_pretraining.py:  534]:	loss/total_loss, 3.918578624725342, 284
[INFO] 2021-07-09 16:51:46,230 [run_pretraining.py:  535]:	loss/mlm_loss, 3.918578624725342, 284
[INFO] 2021-07-09 16:51:46,230 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8299998575676e-06, 284
[INFO] 2021-07-09 16:51:46,230 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 284
[INFO] 2021-07-09 16:51:46,230 [run_pretraining.py:  558]:	worker_index: 4, step: 284, cost: 3.918579, mlm loss: 3.918579, speed: 0.448261 steps/s, speed: 3.586089 samples/s, speed: 1836.077551 tokens/s, learning rate: 2.830e-06, loss_scalings: 2814.750488, pp_loss: 3.988920
[INFO] 2021-07-09 16:51:46,230 [run_pretraining.py:  512]:	********exe.run_284******* 
[INFO] 2021-07-09 16:51:48,459 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:48,460 [run_pretraining.py:  534]:	loss/total_loss, 3.989591598510742, 285
[INFO] 2021-07-09 16:51:48,460 [run_pretraining.py:  535]:	loss/mlm_loss, 3.989591598510742, 285
[INFO] 2021-07-09 16:51:48,460 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8399999791872688e-06, 285
[INFO] 2021-07-09 16:51:48,460 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 285
[INFO] 2021-07-09 16:51:48,460 [run_pretraining.py:  558]:	worker_index: 4, step: 285, cost: 3.989592, mlm loss: 3.989592, speed: 0.448538 steps/s, speed: 3.588303 samples/s, speed: 1837.210881 tokens/s, learning rate: 2.840e-06, loss_scalings: 2814.750488, pp_loss: 3.970937
[INFO] 2021-07-09 16:51:48,460 [run_pretraining.py:  512]:	********exe.run_285******* 
[INFO] 2021-07-09 16:51:50,651 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:50,651 [run_pretraining.py:  534]:	loss/total_loss, 3.994326114654541, 286
[INFO] 2021-07-09 16:51:50,652 [run_pretraining.py:  535]:	loss/mlm_loss, 3.994326114654541, 286
[INFO] 2021-07-09 16:51:50,652 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.849999873433262e-06, 286
[INFO] 2021-07-09 16:51:50,652 [run_pretraining.py:  539]:	lr/loss_scaling, 2251.800537109375, 286
[INFO] 2021-07-09 16:51:50,652 [run_pretraining.py:  558]:	worker_index: 4, step: 286, cost: 3.994326, mlm loss: 3.994326, speed: 0.456409 steps/s, speed: 3.651272 samples/s, speed: 1869.451363 tokens/s, learning rate: 2.850e-06, loss_scalings: 2251.800537, pp_loss: 4.040950
[INFO] 2021-07-09 16:51:50,652 [run_pretraining.py:  512]:	********exe.run_286******* 
[INFO] 2021-07-09 16:51:52,868 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:52,869 [run_pretraining.py:  534]:	loss/total_loss, 4.157376766204834, 287
[INFO] 2021-07-09 16:51:52,869 [run_pretraining.py:  535]:	loss/mlm_loss, 4.157376766204834, 287
[INFO] 2021-07-09 16:51:52,869 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.859999995052931e-06, 287
[INFO] 2021-07-09 16:51:52,869 [run_pretraining.py:  539]:	lr/loss_scaling, 2251.800537109375, 287
[INFO] 2021-07-09 16:51:52,869 [run_pretraining.py:  558]:	worker_index: 4, step: 287, cost: 4.157377, mlm loss: 4.157377, speed: 0.451082 steps/s, speed: 3.608657 samples/s, speed: 1847.632521 tokens/s, learning rate: 2.860e-06, loss_scalings: 2251.800537, pp_loss: 4.072003
[INFO] 2021-07-09 16:51:52,869 [run_pretraining.py:  512]:	********exe.run_287******* 
[INFO] 2021-07-09 16:51:55,085 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:55,085 [run_pretraining.py:  534]:	loss/total_loss, 4.242401123046875, 288
[INFO] 2021-07-09 16:51:55,086 [run_pretraining.py:  535]:	loss/mlm_loss, 4.242401123046875, 288
[INFO] 2021-07-09 16:51:55,086 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8699998892989242e-06, 288
[INFO] 2021-07-09 16:51:55,086 [run_pretraining.py:  539]:	lr/loss_scaling, 2251.800537109375, 288
[INFO] 2021-07-09 16:51:55,086 [run_pretraining.py:  558]:	worker_index: 4, step: 288, cost: 4.242401, mlm loss: 4.242401, speed: 0.451311 steps/s, speed: 3.610488 samples/s, speed: 1848.570095 tokens/s, learning rate: 2.870e-06, loss_scalings: 2251.800537, pp_loss: 4.150092
[INFO] 2021-07-09 16:51:55,086 [run_pretraining.py:  512]:	********exe.run_288******* 
[INFO] 2021-07-09 16:51:57,312 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:57,312 [run_pretraining.py:  534]:	loss/total_loss, 4.145160675048828, 289
[INFO] 2021-07-09 16:51:57,312 [run_pretraining.py:  535]:	loss/mlm_loss, 4.145160675048828, 289
[INFO] 2021-07-09 16:51:57,312 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8799997835449176e-06, 289
[INFO] 2021-07-09 16:51:57,312 [run_pretraining.py:  539]:	lr/loss_scaling, 2251.800537109375, 289
[INFO] 2021-07-09 16:51:57,312 [run_pretraining.py:  558]:	worker_index: 4, step: 289, cost: 4.145161, mlm loss: 4.145161, speed: 0.449237 steps/s, speed: 3.593894 samples/s, speed: 1840.073593 tokens/s, learning rate: 2.880e-06, loss_scalings: 2251.800537, pp_loss: 4.142761
[INFO] 2021-07-09 16:51:57,312 [run_pretraining.py:  512]:	********exe.run_289******* 
[INFO] 2021-07-09 16:51:59,571 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:59,571 [run_pretraining.py:  534]:	loss/total_loss, 4.194399833679199, 290
[INFO] 2021-07-09 16:51:59,571 [run_pretraining.py:  535]:	loss/mlm_loss, 4.194399833679199, 290
[INFO] 2021-07-09 16:51:59,571 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8899999051645864e-06, 290
[INFO] 2021-07-09 16:51:59,572 [run_pretraining.py:  539]:	lr/loss_scaling, 2251.800537109375, 290
[INFO] 2021-07-09 16:51:59,572 [run_pretraining.py:  558]:	worker_index: 4, step: 290, cost: 4.194400, mlm loss: 4.194400, speed: 0.442769 steps/s, speed: 3.542151 samples/s, speed: 1813.581526 tokens/s, learning rate: 2.890e-06, loss_scalings: 2251.800537, pp_loss: 4.218640
[INFO] 2021-07-09 16:51:59,572 [run_pretraining.py:  512]:	********exe.run_290******* 
[INFO] 2021-07-09 16:52:01,780 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:01,780 [run_pretraining.py:  534]:	loss/total_loss, 4.258615970611572, 291
[INFO] 2021-07-09 16:52:01,780 [run_pretraining.py:  535]:	loss/mlm_loss, 4.258615970611572, 291
[INFO] 2021-07-09 16:52:01,780 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8999997994105797e-06, 291
[INFO] 2021-07-09 16:52:01,781 [run_pretraining.py:  539]:	lr/loss_scaling, 2251.800537109375, 291
[INFO] 2021-07-09 16:52:01,781 [run_pretraining.py:  558]:	worker_index: 4, step: 291, cost: 4.258616, mlm loss: 4.258616, speed: 0.452826 steps/s, speed: 3.622608 samples/s, speed: 1854.775499 tokens/s, learning rate: 2.900e-06, loss_scalings: 2251.800537, pp_loss: 4.282450
[INFO] 2021-07-09 16:52:01,781 [run_pretraining.py:  512]:	********exe.run_291******* 
[INFO] 2021-07-09 16:52:03,989 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:03,990 [run_pretraining.py:  534]:	loss/total_loss, 4.272767543792725, 292
[INFO] 2021-07-09 16:52:03,990 [run_pretraining.py:  535]:	loss/mlm_loss, 4.272767543792725, 292
[INFO] 2021-07-09 16:52:03,990 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9099999210302485e-06, 292
[INFO] 2021-07-09 16:52:03,990 [run_pretraining.py:  539]:	lr/loss_scaling, 2251.800537109375, 292
[INFO] 2021-07-09 16:52:03,990 [run_pretraining.py:  558]:	worker_index: 4, step: 292, cost: 4.272768, mlm loss: 4.272768, speed: 0.452768 steps/s, speed: 3.622142 samples/s, speed: 1854.536636 tokens/s, learning rate: 2.910e-06, loss_scalings: 2251.800537, pp_loss: 4.302018
[INFO] 2021-07-09 16:52:03,990 [run_pretraining.py:  512]:	********exe.run_292******* 
[INFO] 2021-07-09 16:52:06,243 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:06,243 [run_pretraining.py:  534]:	loss/total_loss, 4.2980570793151855, 293
[INFO] 2021-07-09 16:52:06,243 [run_pretraining.py:  535]:	loss/mlm_loss, 4.2980570793151855, 293
[INFO] 2021-07-09 16:52:06,243 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9200000426499173e-06, 293
[INFO] 2021-07-09 16:52:06,244 [run_pretraining.py:  539]:	lr/loss_scaling, 2251.800537109375, 293
[INFO] 2021-07-09 16:52:06,244 [run_pretraining.py:  558]:	worker_index: 4, step: 293, cost: 4.298057, mlm loss: 4.298057, speed: 0.443872 steps/s, speed: 3.550978 samples/s, speed: 1818.100630 tokens/s, learning rate: 2.920e-06, loss_scalings: 2251.800537, pp_loss: 4.339744
[INFO] 2021-07-09 16:52:06,244 [run_pretraining.py:  512]:	********exe.run_293******* 
[INFO] 2021-07-09 16:52:08,493 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:08,494 [run_pretraining.py:  534]:	loss/total_loss, 4.410348892211914, 294
[INFO] 2021-07-09 16:52:08,494 [run_pretraining.py:  535]:	loss/mlm_loss, 4.410348892211914, 294
[INFO] 2021-07-09 16:52:08,494 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9299999368959107e-06, 294
[INFO] 2021-07-09 16:52:08,494 [run_pretraining.py:  539]:	lr/loss_scaling, 1801.4404296875, 294
[INFO] 2021-07-09 16:52:08,494 [run_pretraining.py:  558]:	worker_index: 4, step: 294, cost: 4.410349, mlm loss: 4.410349, speed: 0.444461 steps/s, speed: 3.555686 samples/s, speed: 1820.510998 tokens/s, learning rate: 2.930e-06, loss_scalings: 1801.440430, pp_loss: 4.429847
[INFO] 2021-07-09 16:52:08,494 [run_pretraining.py:  512]:	********exe.run_294******* 
[INFO] 2021-07-09 16:52:10,711 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:10,712 [run_pretraining.py:  534]:	loss/total_loss, 4.663338661193848, 295
[INFO] 2021-07-09 16:52:10,712 [run_pretraining.py:  535]:	loss/mlm_loss, 4.663338661193848, 295
[INFO] 2021-07-09 16:52:10,712 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9400000585155794e-06, 295
[INFO] 2021-07-09 16:52:10,712 [run_pretraining.py:  539]:	lr/loss_scaling, 1801.4404296875, 295
[INFO] 2021-07-09 16:52:10,712 [run_pretraining.py:  558]:	worker_index: 4, step: 295, cost: 4.663339, mlm loss: 4.663339, speed: 0.450980 steps/s, speed: 3.607837 samples/s, speed: 1847.212750 tokens/s, learning rate: 2.940e-06, loss_scalings: 1801.440430, pp_loss: 4.477210
[INFO] 2021-07-09 16:52:10,712 [run_pretraining.py:  512]:	********exe.run_295******* 
[INFO] 2021-07-09 16:52:13,022 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:13,023 [run_pretraining.py:  534]:	loss/total_loss, 4.492631912231445, 296
[INFO] 2021-07-09 16:52:13,023 [run_pretraining.py:  535]:	loss/mlm_loss, 4.492631912231445, 296
[INFO] 2021-07-09 16:52:13,023 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9499999527615728e-06, 296
[INFO] 2021-07-09 16:52:13,023 [run_pretraining.py:  539]:	lr/loss_scaling, 1801.4404296875, 296
[INFO] 2021-07-09 16:52:13,023 [run_pretraining.py:  558]:	worker_index: 4, step: 296, cost: 4.492632, mlm loss: 4.492632, speed: 0.432859 steps/s, speed: 3.462875 samples/s, speed: 1772.992229 tokens/s, learning rate: 2.950e-06, loss_scalings: 1801.440430, pp_loss: 4.516536
[INFO] 2021-07-09 16:52:13,023 [run_pretraining.py:  512]:	********exe.run_296******* 
[INFO] 2021-07-09 16:52:15,333 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:15,333 [run_pretraining.py:  534]:	loss/total_loss, 4.557131290435791, 297
[INFO] 2021-07-09 16:52:15,333 [run_pretraining.py:  535]:	loss/mlm_loss, 4.557131290435791, 297
[INFO] 2021-07-09 16:52:15,333 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.959999847007566e-06, 297
[INFO] 2021-07-09 16:52:15,333 [run_pretraining.py:  539]:	lr/loss_scaling, 1801.4404296875, 297
[INFO] 2021-07-09 16:52:15,333 [run_pretraining.py:  558]:	worker_index: 4, step: 297, cost: 4.557131, mlm loss: 4.557131, speed: 0.432937 steps/s, speed: 3.463498 samples/s, speed: 1773.311031 tokens/s, learning rate: 2.960e-06, loss_scalings: 1801.440430, pp_loss: 4.590330
[INFO] 2021-07-09 16:52:15,334 [run_pretraining.py:  512]:	********exe.run_297******* 
[INFO] 2021-07-09 16:52:17,543 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:17,544 [run_pretraining.py:  534]:	loss/total_loss, 4.6089887619018555, 298
[INFO] 2021-07-09 16:52:17,544 [run_pretraining.py:  535]:	loss/mlm_loss, 4.6089887619018555, 298
[INFO] 2021-07-09 16:52:17,544 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.969999968627235e-06, 298
[INFO] 2021-07-09 16:52:17,544 [run_pretraining.py:  539]:	lr/loss_scaling, 1801.4404296875, 298
[INFO] 2021-07-09 16:52:17,544 [run_pretraining.py:  558]:	worker_index: 4, step: 298, cost: 4.608989, mlm loss: 4.608989, speed: 0.452523 steps/s, speed: 3.620187 samples/s, speed: 1853.535807 tokens/s, learning rate: 2.970e-06, loss_scalings: 1801.440430, pp_loss: 4.625033
[INFO] 2021-07-09 16:52:17,544 [run_pretraining.py:  512]:	********exe.run_298******* 
[INFO] 2021-07-09 16:52:19,752 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:19,753 [run_pretraining.py:  534]:	loss/total_loss, 4.631359577178955, 299
[INFO] 2021-07-09 16:52:19,753 [run_pretraining.py:  535]:	loss/mlm_loss, 4.631359577178955, 299
[INFO] 2021-07-09 16:52:19,753 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9799998628732283e-06, 299
[INFO] 2021-07-09 16:52:19,753 [run_pretraining.py:  539]:	lr/loss_scaling, 1801.4404296875, 299
[INFO] 2021-07-09 16:52:19,753 [run_pretraining.py:  558]:	worker_index: 4, step: 299, cost: 4.631360, mlm loss: 4.631360, speed: 0.452819 steps/s, speed: 3.622552 samples/s, speed: 1854.746664 tokens/s, learning rate: 2.980e-06, loss_scalings: 1801.440430, pp_loss: 4.668712
[INFO] 2021-07-09 16:52:19,753 [run_pretraining.py:  512]:	********exe.run_299******* 
[INFO] 2021-07-09 16:52:21,948 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:21,948 [run_pretraining.py:  534]:	loss/total_loss, 4.6808624267578125, 300
[INFO] 2021-07-09 16:52:21,948 [run_pretraining.py:  535]:	loss/mlm_loss, 4.6808624267578125, 300
[INFO] 2021-07-09 16:52:21,949 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.989999984492897e-06, 300
[INFO] 2021-07-09 16:52:21,949 [run_pretraining.py:  539]:	lr/loss_scaling, 1801.4404296875, 300
[INFO] 2021-07-09 16:52:21,949 [run_pretraining.py:  558]:	worker_index: 4, step: 300, cost: 4.680862, mlm loss: 4.680862, speed: 0.455594 steps/s, speed: 3.644748 samples/s, speed: 1866.111172 tokens/s, learning rate: 2.990e-06, loss_scalings: 1801.440430, pp_loss: 4.648774
[INFO] 2021-07-09 16:52:21,949 [run_pretraining.py:  512]:	********exe.run_300******* 
[INFO] 2021-07-09 16:52:24,175 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:24,175 [run_pretraining.py:  534]:	loss/total_loss, 4.636964797973633, 301
[INFO] 2021-07-09 16:52:24,175 [run_pretraining.py:  535]:	loss/mlm_loss, 4.636964797973633, 301
[INFO] 2021-07-09 16:52:24,176 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9999998787388904e-06, 301
[INFO] 2021-07-09 16:52:24,176 [run_pretraining.py:  539]:	lr/loss_scaling, 1801.4404296875, 301
[INFO] 2021-07-09 16:52:24,176 [run_pretraining.py:  558]:	worker_index: 4, step: 301, cost: 4.636965, mlm loss: 4.636965, speed: 0.449165 steps/s, speed: 3.593317 samples/s, speed: 1839.778212 tokens/s, learning rate: 3.000e-06, loss_scalings: 1801.440430, pp_loss: 4.675316
[INFO] 2021-07-09 16:52:24,176 [run_pretraining.py:  512]:	********exe.run_301******* 
[INFO] 2021-07-09 16:52:26,467 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:26,468 [run_pretraining.py:  534]:	loss/total_loss, 4.671563148498535, 302
[INFO] 2021-07-09 16:52:26,468 [run_pretraining.py:  535]:	loss/mlm_loss, 4.671563148498535, 302
[INFO] 2021-07-09 16:52:26,468 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.0099997729848837e-06, 302
[INFO] 2021-07-09 16:52:26,468 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 302
[INFO] 2021-07-09 16:52:26,468 [run_pretraining.py:  558]:	worker_index: 4, step: 302, cost: 4.671563, mlm loss: 4.671563, speed: 0.436398 steps/s, speed: 3.491185 samples/s, speed: 1787.486912 tokens/s, learning rate: 3.010e-06, loss_scalings: 1441.152344, pp_loss: 4.647364
[INFO] 2021-07-09 16:52:26,468 [run_pretraining.py:  512]:	********exe.run_302******* 
[INFO] 2021-07-09 16:52:28,709 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:28,709 [run_pretraining.py:  534]:	loss/total_loss, 4.624236106872559, 303
[INFO] 2021-07-09 16:52:28,710 [run_pretraining.py:  535]:	loss/mlm_loss, 4.624236106872559, 303
[INFO] 2021-07-09 16:52:28,710 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.020000121978228e-06, 303
[INFO] 2021-07-09 16:52:28,710 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 303
[INFO] 2021-07-09 16:52:28,710 [run_pretraining.py:  558]:	worker_index: 4, step: 303, cost: 4.624236, mlm loss: 4.624236, speed: 0.446167 steps/s, speed: 3.569338 samples/s, speed: 1827.500819 tokens/s, learning rate: 3.020e-06, loss_scalings: 1441.152344, pp_loss: 4.685020
[INFO] 2021-07-09 16:52:28,710 [run_pretraining.py:  512]:	********exe.run_303******* 
[INFO] 2021-07-09 16:52:30,929 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:30,930 [run_pretraining.py:  534]:	loss/total_loss, 4.707320690155029, 304
[INFO] 2021-07-09 16:52:30,930 [run_pretraining.py:  535]:	loss/mlm_loss, 4.707320690155029, 304
[INFO] 2021-07-09 16:52:30,930 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.0300000162242213e-06, 304
[INFO] 2021-07-09 16:52:30,930 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 304
[INFO] 2021-07-09 16:52:30,930 [run_pretraining.py:  558]:	worker_index: 4, step: 304, cost: 4.707321, mlm loss: 4.707321, speed: 0.450561 steps/s, speed: 3.604492 samples/s, speed: 1845.499888 tokens/s, learning rate: 3.030e-06, loss_scalings: 1441.152344, pp_loss: 4.694768
[INFO] 2021-07-09 16:52:30,930 [run_pretraining.py:  512]:	********exe.run_304******* 
[INFO] 2021-07-09 16:52:33,189 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:33,189 [run_pretraining.py:  534]:	loss/total_loss, 4.655093669891357, 305
[INFO] 2021-07-09 16:52:33,190 [run_pretraining.py:  535]:	loss/mlm_loss, 4.655093669891357, 305
[INFO] 2021-07-09 16:52:33,190 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.0399999104702147e-06, 305
[INFO] 2021-07-09 16:52:33,190 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 305
[INFO] 2021-07-09 16:52:33,190 [run_pretraining.py:  558]:	worker_index: 4, step: 305, cost: 4.655094, mlm loss: 4.655094, speed: 0.442614 steps/s, speed: 3.540913 samples/s, speed: 1812.947476 tokens/s, learning rate: 3.040e-06, loss_scalings: 1441.152344, pp_loss: 4.679780
[INFO] 2021-07-09 16:52:33,190 [run_pretraining.py:  512]:	********exe.run_305******* 
[INFO] 2021-07-09 16:52:35,399 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:35,399 [run_pretraining.py:  534]:	loss/total_loss, 4.660861015319824, 306
[INFO] 2021-07-09 16:52:35,399 [run_pretraining.py:  535]:	loss/mlm_loss, 4.660861015319824, 306
[INFO] 2021-07-09 16:52:35,400 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.0500000320898835e-06, 306
[INFO] 2021-07-09 16:52:35,400 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 306
[INFO] 2021-07-09 16:52:35,400 [run_pretraining.py:  558]:	worker_index: 4, step: 306, cost: 4.660861, mlm loss: 4.660861, speed: 0.452672 steps/s, speed: 3.621378 samples/s, speed: 1854.145740 tokens/s, learning rate: 3.050e-06, loss_scalings: 1441.152344, pp_loss: 4.702024
[INFO] 2021-07-09 16:52:35,400 [run_pretraining.py:  512]:	********exe.run_306******* 
[INFO] 2021-07-09 16:52:37,595 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:37,596 [run_pretraining.py:  534]:	loss/total_loss, 4.693541526794434, 307
[INFO] 2021-07-09 16:52:37,596 [run_pretraining.py:  535]:	loss/mlm_loss, 4.693541526794434, 307
[INFO] 2021-07-09 16:52:37,596 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.059999926335877e-06, 307
[INFO] 2021-07-09 16:52:37,596 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 307
[INFO] 2021-07-09 16:52:37,596 [run_pretraining.py:  558]:	worker_index: 4, step: 307, cost: 4.693542, mlm loss: 4.693542, speed: 0.455369 steps/s, speed: 3.642950 samples/s, speed: 1865.190150 tokens/s, learning rate: 3.060e-06, loss_scalings: 1441.152344, pp_loss: 4.701570
[INFO] 2021-07-09 16:52:37,597 [run_pretraining.py:  512]:	********exe.run_307******* 
[INFO] 2021-07-09 16:52:39,791 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:39,792 [run_pretraining.py:  534]:	loss/total_loss, 4.789811611175537, 308
[INFO] 2021-07-09 16:52:39,792 [run_pretraining.py:  535]:	loss/mlm_loss, 4.789811611175537, 308
[INFO] 2021-07-09 16:52:39,792 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.06999982058187e-06, 308
[INFO] 2021-07-09 16:52:39,792 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 308
[INFO] 2021-07-09 16:52:39,792 [run_pretraining.py:  558]:	worker_index: 4, step: 308, cost: 4.789812, mlm loss: 4.789812, speed: 0.455524 steps/s, speed: 3.644195 samples/s, speed: 1865.827637 tokens/s, learning rate: 3.070e-06, loss_scalings: 1441.152344, pp_loss: 4.708122
[INFO] 2021-07-09 16:52:39,793 [run_pretraining.py:  512]:	********exe.run_308******* 
[INFO] 2021-07-09 16:52:42,013 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:42,014 [run_pretraining.py:  534]:	loss/total_loss, 4.6914472579956055, 309
[INFO] 2021-07-09 16:52:42,014 [run_pretraining.py:  535]:	loss/mlm_loss, 4.6914472579956055, 309
[INFO] 2021-07-09 16:52:42,014 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.079999942201539e-06, 309
[INFO] 2021-07-09 16:52:42,014 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 309
[INFO] 2021-07-09 16:52:42,014 [run_pretraining.py:  558]:	worker_index: 4, step: 309, cost: 4.691447, mlm loss: 4.691447, speed: 0.450215 steps/s, speed: 3.601718 samples/s, speed: 1844.079545 tokens/s, learning rate: 3.080e-06, loss_scalings: 1441.152344, pp_loss: 4.680444
[INFO] 2021-07-09 16:52:42,014 [run_pretraining.py:  512]:	********exe.run_309******* 
[INFO] 2021-07-09 16:52:44,245 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:44,245 [run_pretraining.py:  534]:	loss/total_loss, 4.650092124938965, 310
[INFO] 2021-07-09 16:52:44,246 [run_pretraining.py:  535]:	loss/mlm_loss, 4.650092124938965, 310
[INFO] 2021-07-09 16:52:44,246 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.0899998364475323e-06, 310
[INFO] 2021-07-09 16:52:44,246 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 310
[INFO] 2021-07-09 16:52:44,246 [run_pretraining.py:  558]:	worker_index: 4, step: 310, cost: 4.650092, mlm loss: 4.650092, speed: 0.448250 steps/s, speed: 3.585998 samples/s, speed: 1836.031046 tokens/s, learning rate: 3.090e-06, loss_scalings: 1441.152344, pp_loss: 4.630144
[INFO] 2021-07-09 16:52:44,246 [run_pretraining.py:  512]:	********exe.run_310******* 
[INFO] 2021-07-09 16:52:46,566 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:46,566 [run_pretraining.py:  534]:	loss/total_loss, 4.60033655166626, 311
[INFO] 2021-07-09 16:52:46,566 [run_pretraining.py:  535]:	loss/mlm_loss, 4.60033655166626, 311
[INFO] 2021-07-09 16:52:46,567 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.099999958067201e-06, 311
[INFO] 2021-07-09 16:52:46,567 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 311
[INFO] 2021-07-09 16:52:46,567 [run_pretraining.py:  558]:	worker_index: 4, step: 311, cost: 4.600337, mlm loss: 4.600337, speed: 0.430998 steps/s, speed: 3.447986 samples/s, speed: 1765.369071 tokens/s, learning rate: 3.100e-06, loss_scalings: 1441.152344, pp_loss: 4.599580
[INFO] 2021-07-09 16:52:46,567 [run_pretraining.py:  512]:	********exe.run_311******* 
[INFO] 2021-07-09 16:52:48,883 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:48,883 [run_pretraining.py:  534]:	loss/total_loss, 4.553149223327637, 312
[INFO] 2021-07-09 16:52:48,883 [run_pretraining.py:  535]:	loss/mlm_loss, 4.553149223327637, 312
[INFO] 2021-07-09 16:52:48,883 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.1099998523131944e-06, 312
[INFO] 2021-07-09 16:52:48,883 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 312
[INFO] 2021-07-09 16:52:48,883 [run_pretraining.py:  558]:	worker_index: 4, step: 312, cost: 4.553149, mlm loss: 4.553149, speed: 0.431754 steps/s, speed: 3.454033 samples/s, speed: 1768.465102 tokens/s, learning rate: 3.110e-06, loss_scalings: 1441.152344, pp_loss: 4.551183
[INFO] 2021-07-09 16:52:48,884 [run_pretraining.py:  512]:	********exe.run_312******* 
[INFO] 2021-07-09 16:52:51,097 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:51,098 [run_pretraining.py:  534]:	loss/total_loss, 4.523474216461182, 313
[INFO] 2021-07-09 16:52:51,098 [run_pretraining.py:  535]:	loss/mlm_loss, 4.523474216461182, 313
[INFO] 2021-07-09 16:52:51,098 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.1199997465591878e-06, 313
[INFO] 2021-07-09 16:52:51,098 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 313
[INFO] 2021-07-09 16:52:51,098 [run_pretraining.py:  558]:	worker_index: 4, step: 313, cost: 4.523474, mlm loss: 4.523474, speed: 0.451625 steps/s, speed: 3.612996 samples/s, speed: 1849.854141 tokens/s, learning rate: 3.120e-06, loss_scalings: 1441.152344, pp_loss: 4.543048
[INFO] 2021-07-09 16:52:51,099 [run_pretraining.py:  512]:	********exe.run_313******* 
[INFO] 2021-07-09 16:52:53,317 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:53,318 [run_pretraining.py:  534]:	loss/total_loss, 4.405041694641113, 314
[INFO] 2021-07-09 16:52:53,318 [run_pretraining.py:  535]:	loss/mlm_loss, 4.405041694641113, 314
[INFO] 2021-07-09 16:52:53,318 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.130000095552532e-06, 314
[INFO] 2021-07-09 16:52:53,318 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 314
[INFO] 2021-07-09 16:52:53,318 [run_pretraining.py:  558]:	worker_index: 4, step: 314, cost: 4.405042, mlm loss: 4.405042, speed: 0.450633 steps/s, speed: 3.605062 samples/s, speed: 1845.791556 tokens/s, learning rate: 3.130e-06, loss_scalings: 1441.152344, pp_loss: 4.435108
[INFO] 2021-07-09 16:52:53,318 [run_pretraining.py:  512]:	********exe.run_314******* 
[INFO] 2021-07-09 16:52:55,565 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:55,566 [run_pretraining.py:  534]:	loss/total_loss, 4.349527359008789, 315
[INFO] 2021-07-09 16:52:55,566 [run_pretraining.py:  535]:	loss/mlm_loss, 4.349527359008789, 315
[INFO] 2021-07-09 16:52:55,566 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.13999976242485e-06, 315
[INFO] 2021-07-09 16:52:55,566 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 315
[INFO] 2021-07-09 16:52:55,566 [run_pretraining.py:  558]:	worker_index: 4, step: 315, cost: 4.349527, mlm loss: 4.349527, speed: 0.444986 steps/s, speed: 3.559885 samples/s, speed: 1822.660874 tokens/s, learning rate: 3.140e-06, loss_scalings: 1441.152344, pp_loss: 4.367938
[INFO] 2021-07-09 16:52:55,566 [run_pretraining.py:  512]:	********exe.run_315******* 
[INFO] 2021-07-09 16:52:57,785 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:57,786 [run_pretraining.py:  534]:	loss/total_loss, 4.290831565856934, 316
[INFO] 2021-07-09 16:52:57,786 [run_pretraining.py:  535]:	loss/mlm_loss, 4.290831565856934, 316
[INFO] 2021-07-09 16:52:57,786 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.1499998840445187e-06, 316
[INFO] 2021-07-09 16:52:57,786 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 316
[INFO] 2021-07-09 16:52:57,786 [run_pretraining.py:  558]:	worker_index: 4, step: 316, cost: 4.290832, mlm loss: 4.290832, speed: 0.450611 steps/s, speed: 3.604889 samples/s, speed: 1845.703312 tokens/s, learning rate: 3.150e-06, loss_scalings: 1441.152344, pp_loss: 4.296326
[INFO] 2021-07-09 16:52:57,786 [run_pretraining.py:  512]:	********exe.run_316******* 
[INFO] 2021-07-09 16:52:59,995 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:59,995 [run_pretraining.py:  534]:	loss/total_loss, 4.169069290161133, 317
[INFO] 2021-07-09 16:52:59,995 [run_pretraining.py:  535]:	loss/mlm_loss, 4.169069290161133, 317
[INFO] 2021-07-09 16:52:59,995 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.159999778290512e-06, 317
[INFO] 2021-07-09 16:52:59,995 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 317
[INFO] 2021-07-09 16:52:59,996 [run_pretraining.py:  558]:	worker_index: 4, step: 317, cost: 4.169069, mlm loss: 4.169069, speed: 0.452726 steps/s, speed: 3.621812 samples/s, speed: 1854.367688 tokens/s, learning rate: 3.160e-06, loss_scalings: 1441.152344, pp_loss: 4.210334
[INFO] 2021-07-09 16:52:59,996 [run_pretraining.py:  512]:	********exe.run_317******* 
[INFO] 2021-07-09 16:53:02,285 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:02,285 [run_pretraining.py:  534]:	loss/total_loss, 4.179346084594727, 318
[INFO] 2021-07-09 16:53:02,285 [run_pretraining.py:  535]:	loss/mlm_loss, 4.179346084594727, 318
[INFO] 2021-07-09 16:53:02,286 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.169999899910181e-06, 318
[INFO] 2021-07-09 16:53:02,286 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 318
[INFO] 2021-07-09 16:53:02,286 [run_pretraining.py:  558]:	worker_index: 4, step: 318, cost: 4.179346, mlm loss: 4.179346, speed: 0.436768 steps/s, speed: 3.494142 samples/s, speed: 1789.000953 tokens/s, learning rate: 3.170e-06, loss_scalings: 1441.152344, pp_loss: 4.173015
[INFO] 2021-07-09 16:53:02,286 [run_pretraining.py:  512]:	********exe.run_318******* 
[INFO] 2021-07-09 16:53:04,640 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:04,640 [run_pretraining.py:  534]:	loss/total_loss, 4.123632431030273, 319
[INFO] 2021-07-09 16:53:04,640 [run_pretraining.py:  535]:	loss/mlm_loss, 4.123632431030273, 319
[INFO] 2021-07-09 16:53:04,640 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.1800000215298496e-06, 319
[INFO] 2021-07-09 16:53:04,640 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 319
[INFO] 2021-07-09 16:53:04,640 [run_pretraining.py:  558]:	worker_index: 4, step: 319, cost: 4.123632, mlm loss: 4.123632, speed: 0.424808 steps/s, speed: 3.398461 samples/s, speed: 1740.011814 tokens/s, learning rate: 3.180e-06, loss_scalings: 1441.152344, pp_loss: 4.164064
[INFO] 2021-07-09 16:53:04,640 [run_pretraining.py:  512]:	********exe.run_319******* 
[INFO] 2021-07-09 16:53:06,848 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:06,849 [run_pretraining.py:  534]:	loss/total_loss, 4.101210594177246, 320
[INFO] 2021-07-09 16:53:06,849 [run_pretraining.py:  535]:	loss/mlm_loss, 4.101210594177246, 320
[INFO] 2021-07-09 16:53:06,849 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.189999915775843e-06, 320
[INFO] 2021-07-09 16:53:06,849 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 320
[INFO] 2021-07-09 16:53:06,849 [run_pretraining.py:  558]:	worker_index: 4, step: 320, cost: 4.101211, mlm loss: 4.101211, speed: 0.452868 steps/s, speed: 3.622942 samples/s, speed: 1854.946524 tokens/s, learning rate: 3.190e-06, loss_scalings: 1441.152344, pp_loss: 4.116853
[INFO] 2021-07-09 16:53:06,849 [run_pretraining.py:  512]:	********exe.run_320******* 
[INFO] 2021-07-09 16:53:09,065 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:09,065 [run_pretraining.py:  534]:	loss/total_loss, 4.044239521026611, 321
[INFO] 2021-07-09 16:53:09,065 [run_pretraining.py:  535]:	loss/mlm_loss, 4.044239521026611, 321
[INFO] 2021-07-09 16:53:09,065 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.2000000373955118e-06, 321
[INFO] 2021-07-09 16:53:09,066 [run_pretraining.py:  539]:	lr/loss_scaling, 1152.921875, 321
[INFO] 2021-07-09 16:53:09,066 [run_pretraining.py:  558]:	worker_index: 4, step: 321, cost: 4.044240, mlm loss: 4.044240, speed: 0.451334 steps/s, speed: 3.610674 samples/s, speed: 1848.664979 tokens/s, learning rate: 3.200e-06, loss_scalings: 1152.921875, pp_loss: 4.065809
[INFO] 2021-07-09 16:53:09,066 [run_pretraining.py:  512]:	********exe.run_321******* 
[INFO] 2021-07-09 16:53:11,321 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:11,321 [run_pretraining.py:  534]:	loss/total_loss, 4.042120933532715, 322
[INFO] 2021-07-09 16:53:11,321 [run_pretraining.py:  535]:	loss/mlm_loss, 4.042120933532715, 322
[INFO] 2021-07-09 16:53:11,321 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.209999931641505e-06, 322
[INFO] 2021-07-09 16:53:11,321 [run_pretraining.py:  539]:	lr/loss_scaling, 1152.921875, 322
[INFO] 2021-07-09 16:53:11,321 [run_pretraining.py:  558]:	worker_index: 4, step: 322, cost: 4.042121, mlm loss: 4.042121, speed: 0.443433 steps/s, speed: 3.547465 samples/s, speed: 1816.302078 tokens/s, learning rate: 3.210e-06, loss_scalings: 1152.921875, pp_loss: 4.032720
[INFO] 2021-07-09 16:53:11,321 [run_pretraining.py:  512]:	********exe.run_322******* 
[INFO] 2021-07-09 16:53:13,578 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:13,578 [run_pretraining.py:  534]:	loss/total_loss, 4.127846717834473, 323
[INFO] 2021-07-09 16:53:13,579 [run_pretraining.py:  535]:	loss/mlm_loss, 4.127846717834473, 323
[INFO] 2021-07-09 16:53:13,579 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.220000053261174e-06, 323
[INFO] 2021-07-09 16:53:13,579 [run_pretraining.py:  539]:	lr/loss_scaling, 1152.921875, 323
[INFO] 2021-07-09 16:53:13,579 [run_pretraining.py:  558]:	worker_index: 4, step: 323, cost: 4.127847, mlm loss: 4.127847, speed: 0.443120 steps/s, speed: 3.544964 samples/s, speed: 1815.021412 tokens/s, learning rate: 3.220e-06, loss_scalings: 1152.921875, pp_loss: 4.020734
[INFO] 2021-07-09 16:53:13,579 [run_pretraining.py:  512]:	********exe.run_323******* 
[INFO] 2021-07-09 16:53:15,821 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:15,822 [run_pretraining.py:  534]:	loss/total_loss, 3.9381537437438965, 324
[INFO] 2021-07-09 16:53:15,822 [run_pretraining.py:  535]:	loss/mlm_loss, 3.9381537437438965, 324
[INFO] 2021-07-09 16:53:15,822 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.229999720133492e-06, 324
[INFO] 2021-07-09 16:53:15,822 [run_pretraining.py:  539]:	lr/loss_scaling, 1152.921875, 324
[INFO] 2021-07-09 16:53:15,822 [run_pretraining.py:  558]:	worker_index: 4, step: 324, cost: 3.938154, mlm loss: 3.938154, speed: 0.445923 steps/s, speed: 3.567382 samples/s, speed: 1826.499432 tokens/s, learning rate: 3.230e-06, loss_scalings: 1152.921875, pp_loss: 3.960475
[INFO] 2021-07-09 16:53:15,822 [run_pretraining.py:  512]:	********exe.run_324******* 
[INFO] 2021-07-09 16:53:18,116 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:18,116 [run_pretraining.py:  534]:	loss/total_loss, 3.9321329593658447, 325
[INFO] 2021-07-09 16:53:18,116 [run_pretraining.py:  535]:	loss/mlm_loss, 3.9321329593658447, 325
[INFO] 2021-07-09 16:53:18,116 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.240000069126836e-06, 325
[INFO] 2021-07-09 16:53:18,116 [run_pretraining.py:  539]:	lr/loss_scaling, 1152.921875, 325
[INFO] 2021-07-09 16:53:18,116 [run_pretraining.py:  558]:	worker_index: 4, step: 325, cost: 3.932133, mlm loss: 3.932133, speed: 0.435948 steps/s, speed: 3.487588 samples/s, speed: 1785.644822 tokens/s, learning rate: 3.240e-06, loss_scalings: 1152.921875, pp_loss: 3.974028
[INFO] 2021-07-09 16:53:18,117 [run_pretraining.py:  512]:	********exe.run_325******* 
[INFO] 2021-07-09 16:53:20,312 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:20,312 [run_pretraining.py:  534]:	loss/total_loss, 4.025701999664307, 326
[INFO] 2021-07-09 16:53:20,313 [run_pretraining.py:  535]:	loss/mlm_loss, 4.025701999664307, 326
[INFO] 2021-07-09 16:53:20,313 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.249999735999154e-06, 326
[INFO] 2021-07-09 16:53:20,313 [run_pretraining.py:  539]:	lr/loss_scaling, 1152.921875, 326
[INFO] 2021-07-09 16:53:20,313 [run_pretraining.py:  558]:	worker_index: 4, step: 326, cost: 4.025702, mlm loss: 4.025702, speed: 0.455417 steps/s, speed: 3.643333 samples/s, speed: 1865.386596 tokens/s, learning rate: 3.250e-06, loss_scalings: 1152.921875, pp_loss: 3.955253
[INFO] 2021-07-09 16:53:20,313 [run_pretraining.py:  512]:	********exe.run_326******* 
[INFO] 2021-07-09 16:53:22,492 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:22,492 [run_pretraining.py:  534]:	loss/total_loss, 4.0628204345703125, 327
[INFO] 2021-07-09 16:53:22,492 [run_pretraining.py:  535]:	loss/mlm_loss, 4.0628204345703125, 327
[INFO] 2021-07-09 16:53:22,492 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.2599998576188227e-06, 327
[INFO] 2021-07-09 16:53:22,493 [run_pretraining.py:  539]:	lr/loss_scaling, 1152.921875, 327
[INFO] 2021-07-09 16:53:22,493 [run_pretraining.py:  558]:	worker_index: 4, step: 327, cost: 4.062820, mlm loss: 4.062820, speed: 0.458920 steps/s, speed: 3.671362 samples/s, speed: 1879.737380 tokens/s, learning rate: 3.260e-06, loss_scalings: 1152.921875, pp_loss: 3.992672
[INFO] 2021-07-09 16:53:22,493 [run_pretraining.py:  512]:	********exe.run_327******* 
[INFO] 2021-07-09 16:53:24,766 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:24,766 [run_pretraining.py:  534]:	loss/total_loss, 3.913931369781494, 328
[INFO] 2021-07-09 16:53:24,766 [run_pretraining.py:  535]:	loss/mlm_loss, 3.913931369781494, 328
[INFO] 2021-07-09 16:53:24,766 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.269999751864816e-06, 328
[INFO] 2021-07-09 16:53:24,767 [run_pretraining.py:  539]:	lr/loss_scaling, 1152.921875, 328
[INFO] 2021-07-09 16:53:24,767 [run_pretraining.py:  558]:	worker_index: 4, step: 328, cost: 3.913931, mlm loss: 3.913931, speed: 0.439892 steps/s, speed: 3.519133 samples/s, speed: 1801.796208 tokens/s, learning rate: 3.270e-06, loss_scalings: 1152.921875, pp_loss: 3.955482
[INFO] 2021-07-09 16:53:24,767 [run_pretraining.py:  512]:	********exe.run_328******* 
[INFO] 2021-07-09 16:53:26,989 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:26,990 [run_pretraining.py:  534]:	loss/total_loss, 3.915450096130371, 329
[INFO] 2021-07-09 16:53:26,990 [run_pretraining.py:  535]:	loss/mlm_loss, 3.915450096130371, 329
[INFO] 2021-07-09 16:53:26,990 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.279999873484485e-06, 329
[INFO] 2021-07-09 16:53:26,990 [run_pretraining.py:  539]:	lr/loss_scaling, 1152.921875, 329
[INFO] 2021-07-09 16:53:26,990 [run_pretraining.py:  558]:	worker_index: 4, step: 329, cost: 3.915450, mlm loss: 3.915450, speed: 0.449843 steps/s, speed: 3.598741 samples/s, speed: 1842.555262 tokens/s, learning rate: 3.280e-06, loss_scalings: 1152.921875, pp_loss: 3.936973
[INFO] 2021-07-09 16:53:26,990 [run_pretraining.py:  512]:	********exe.run_329******* 
[INFO] 2021-07-09 16:53:29,234 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:29,234 [run_pretraining.py:  534]:	loss/total_loss, 3.950608730316162, 330
[INFO] 2021-07-09 16:53:29,234 [run_pretraining.py:  535]:	loss/mlm_loss, 3.950608730316162, 330
[INFO] 2021-07-09 16:53:29,235 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.2899999951041536e-06, 330
[INFO] 2021-07-09 16:53:29,235 [run_pretraining.py:  539]:	lr/loss_scaling, 1152.921875, 330
[INFO] 2021-07-09 16:53:29,235 [run_pretraining.py:  558]:	worker_index: 4, step: 330, cost: 3.950609, mlm loss: 3.950609, speed: 0.445671 steps/s, speed: 3.565367 samples/s, speed: 1825.467720 tokens/s, learning rate: 3.290e-06, loss_scalings: 1152.921875, pp_loss: 3.945636
[INFO] 2021-07-09 16:53:29,235 [run_pretraining.py:  512]:	********exe.run_330******* 
[INFO] 2021-07-09 16:53:31,447 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:31,447 [run_pretraining.py:  534]:	loss/total_loss, 3.941962718963623, 331
[INFO] 2021-07-09 16:53:31,447 [run_pretraining.py:  535]:	loss/mlm_loss, 3.941962718963623, 331
[INFO] 2021-07-09 16:53:31,447 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.299999889350147e-06, 331
[INFO] 2021-07-09 16:53:31,448 [run_pretraining.py:  539]:	lr/loss_scaling, 922.3375244140625, 331
[INFO] 2021-07-09 16:53:31,448 [run_pretraining.py:  558]:	worker_index: 4, step: 331, cost: 3.941963, mlm loss: 3.941963, speed: 0.452026 steps/s, speed: 3.616211 samples/s, speed: 1851.499870 tokens/s, learning rate: 3.300e-06, loss_scalings: 922.337524, pp_loss: 3.945565
[INFO] 2021-07-09 16:53:31,448 [run_pretraining.py:  512]:	********exe.run_331******* 
[INFO] 2021-07-09 16:53:34,003 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:34,003 [run_pretraining.py:  534]:	loss/total_loss, 4.038539409637451, 332
[INFO] 2021-07-09 16:53:34,004 [run_pretraining.py:  535]:	loss/mlm_loss, 4.038539409637451, 332
[INFO] 2021-07-09 16:53:34,004 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.3100000109698158e-06, 332
[INFO] 2021-07-09 16:53:34,004 [run_pretraining.py:  539]:	lr/loss_scaling, 922.3375244140625, 332
[INFO] 2021-07-09 16:53:34,004 [run_pretraining.py:  558]:	worker_index: 4, step: 332, cost: 4.038539, mlm loss: 4.038539, speed: 0.391297 steps/s, speed: 3.130376 samples/s, speed: 1602.752537 tokens/s, learning rate: 3.310e-06, loss_scalings: 922.337524, pp_loss: 3.960568
[INFO] 2021-07-09 16:53:34,004 [run_pretraining.py:  512]:	********exe.run_332******* 
[INFO] 2021-07-09 16:53:36,220 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:36,221 [run_pretraining.py:  534]:	loss/total_loss, 4.143022060394287, 333
[INFO] 2021-07-09 16:53:36,221 [run_pretraining.py:  535]:	loss/mlm_loss, 4.143022060394287, 333
[INFO] 2021-07-09 16:53:36,221 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.319999905215809e-06, 333
[INFO] 2021-07-09 16:53:36,221 [run_pretraining.py:  539]:	lr/loss_scaling, 737.8700561523438, 333
[INFO] 2021-07-09 16:53:36,221 [run_pretraining.py:  558]:	worker_index: 4, step: 333, cost: 4.143022, mlm loss: 4.143022, speed: 0.451107 steps/s, speed: 3.608858 samples/s, speed: 1847.735456 tokens/s, learning rate: 3.320e-06, loss_scalings: 737.870056, pp_loss: 4.022779
[INFO] 2021-07-09 16:53:36,221 [run_pretraining.py:  512]:	********exe.run_333******* 
[INFO] 2021-07-09 16:53:38,474 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:38,475 [run_pretraining.py:  534]:	loss/total_loss, 3.9975199699401855, 334
[INFO] 2021-07-09 16:53:38,475 [run_pretraining.py:  535]:	loss/mlm_loss, 3.9975199699401855, 334
[INFO] 2021-07-09 16:53:38,475 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.330000026835478e-06, 334
[INFO] 2021-07-09 16:53:38,475 [run_pretraining.py:  539]:	lr/loss_scaling, 737.8700561523438, 334
[INFO] 2021-07-09 16:53:38,475 [run_pretraining.py:  558]:	worker_index: 4, step: 334, cost: 3.997520, mlm loss: 3.997520, speed: 0.443896 steps/s, speed: 3.551164 samples/s, speed: 1818.196067 tokens/s, learning rate: 3.330e-06, loss_scalings: 737.870056, pp_loss: 4.020945
[INFO] 2021-07-09 16:53:38,475 [run_pretraining.py:  512]:	********exe.run_334******* 
[INFO] 2021-07-09 16:53:40,739 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:40,740 [run_pretraining.py:  534]:	loss/total_loss, 4.032802581787109, 335
[INFO] 2021-07-09 16:53:40,740 [run_pretraining.py:  535]:	loss/mlm_loss, 4.032802581787109, 335
[INFO] 2021-07-09 16:53:40,740 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.3399999210814713e-06, 335
[INFO] 2021-07-09 16:53:40,740 [run_pretraining.py:  539]:	lr/loss_scaling, 737.8700561523438, 335
[INFO] 2021-07-09 16:53:40,740 [run_pretraining.py:  558]:	worker_index: 4, step: 335, cost: 4.032803, mlm loss: 4.032803, speed: 0.441569 steps/s, speed: 3.532549 samples/s, speed: 1808.665255 tokens/s, learning rate: 3.340e-06, loss_scalings: 737.870056, pp_loss: 4.060122
[INFO] 2021-07-09 16:53:40,740 [run_pretraining.py:  512]:	********exe.run_335******* 
[INFO] 2021-07-09 16:53:43,047 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:43,048 [run_pretraining.py:  534]:	loss/total_loss, 4.032621383666992, 336
[INFO] 2021-07-09 16:53:43,048 [run_pretraining.py:  535]:	loss/mlm_loss, 4.032621383666992, 336
[INFO] 2021-07-09 16:53:43,048 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.35000004270114e-06, 336
[INFO] 2021-07-09 16:53:43,048 [run_pretraining.py:  539]:	lr/loss_scaling, 590.2960815429688, 336
[INFO] 2021-07-09 16:53:43,048 [run_pretraining.py:  558]:	worker_index: 4, step: 336, cost: 4.032621, mlm loss: 4.032621, speed: 0.433434 steps/s, speed: 3.467475 samples/s, speed: 1775.347142 tokens/s, learning rate: 3.350e-06, loss_scalings: 590.296082, pp_loss: 4.017902
[INFO] 2021-07-09 16:53:43,048 [run_pretraining.py:  512]:	********exe.run_336******* 
[INFO] 2021-07-09 16:53:45,309 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:45,310 [run_pretraining.py:  534]:	loss/total_loss, 4.022006034851074, 337
[INFO] 2021-07-09 16:53:45,310 [run_pretraining.py:  535]:	loss/mlm_loss, 4.022006034851074, 337
[INFO] 2021-07-09 16:53:45,310 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.359999709573458e-06, 337
[INFO] 2021-07-09 16:53:45,310 [run_pretraining.py:  539]:	lr/loss_scaling, 590.2960815429688, 337
[INFO] 2021-07-09 16:53:45,310 [run_pretraining.py:  558]:	worker_index: 4, step: 337, cost: 4.022006, mlm loss: 4.022006, speed: 0.442176 steps/s, speed: 3.537411 samples/s, speed: 1811.154327 tokens/s, learning rate: 3.360e-06, loss_scalings: 590.296082, pp_loss: 4.050326
[INFO] 2021-07-09 16:53:45,310 [run_pretraining.py:  512]:	********exe.run_337******* 
[INFO] 2021-07-09 16:53:47,641 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:47,642 [run_pretraining.py:  534]:	loss/total_loss, 4.1168437004089355, 338
[INFO] 2021-07-09 16:53:47,642 [run_pretraining.py:  535]:	loss/mlm_loss, 4.1168437004089355, 338
[INFO] 2021-07-09 16:53:47,642 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.370000058566802e-06, 338
[INFO] 2021-07-09 16:53:47,642 [run_pretraining.py:  539]:	lr/loss_scaling, 590.2960815429688, 338
[INFO] 2021-07-09 16:53:47,642 [run_pretraining.py:  558]:	worker_index: 4, step: 338, cost: 4.116844, mlm loss: 4.116844, speed: 0.428976 steps/s, speed: 3.431811 samples/s, speed: 1757.087025 tokens/s, learning rate: 3.370e-06, loss_scalings: 590.296082, pp_loss: 4.052191
[INFO] 2021-07-09 16:53:47,642 [run_pretraining.py:  512]:	********exe.run_338******* 
[INFO] 2021-07-09 16:53:50,097 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:50,098 [run_pretraining.py:  534]:	loss/total_loss, 4.091923713684082, 339
[INFO] 2021-07-09 16:53:50,098 [run_pretraining.py:  535]:	loss/mlm_loss, 4.091923713684082, 339
[INFO] 2021-07-09 16:53:50,098 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.37999972543912e-06, 339
[INFO] 2021-07-09 16:53:50,098 [run_pretraining.py:  539]:	lr/loss_scaling, 590.2960815429688, 339
[INFO] 2021-07-09 16:53:50,098 [run_pretraining.py:  558]:	worker_index: 4, step: 339, cost: 4.091924, mlm loss: 4.091924, speed: 0.407273 steps/s, speed: 3.258185 samples/s, speed: 1668.190595 tokens/s, learning rate: 3.380e-06, loss_scalings: 590.296082, pp_loss: 4.067039
[INFO] 2021-07-09 16:53:50,098 [run_pretraining.py:  512]:	********exe.run_339******* 
[INFO] 2021-07-09 16:53:52,341 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:52,342 [run_pretraining.py:  534]:	loss/total_loss, 4.068288803100586, 340
[INFO] 2021-07-09 16:53:52,342 [run_pretraining.py:  535]:	loss/mlm_loss, 4.068288803100586, 340
[INFO] 2021-07-09 16:53:52,342 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.389999847058789e-06, 340
[INFO] 2021-07-09 16:53:52,342 [run_pretraining.py:  539]:	lr/loss_scaling, 590.2960815429688, 340
[INFO] 2021-07-09 16:53:52,342 [run_pretraining.py:  558]:	worker_index: 4, step: 340, cost: 4.068289, mlm loss: 4.068289, speed: 0.445729 steps/s, speed: 3.565836 samples/s, speed: 1825.707883 tokens/s, learning rate: 3.390e-06, loss_scalings: 590.296082, pp_loss: 4.086532
[INFO] 2021-07-09 16:53:52,342 [run_pretraining.py:  512]:	********exe.run_340******* 
[INFO] 2021-07-09 16:53:54,550 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:54,550 [run_pretraining.py:  534]:	loss/total_loss, 4.231497287750244, 341
[INFO] 2021-07-09 16:53:54,550 [run_pretraining.py:  535]:	loss/mlm_loss, 4.231497287750244, 341
[INFO] 2021-07-09 16:53:54,551 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.400000196052133e-06, 341
[INFO] 2021-07-09 16:53:54,551 [run_pretraining.py:  539]:	lr/loss_scaling, 590.2960815429688, 341
[INFO] 2021-07-09 16:53:54,551 [run_pretraining.py:  558]:	worker_index: 4, step: 341, cost: 4.231497, mlm loss: 4.231497, speed: 0.452927 steps/s, speed: 3.623419 samples/s, speed: 1855.190500 tokens/s, learning rate: 3.400e-06, loss_scalings: 590.296082, pp_loss: 4.117404
[INFO] 2021-07-09 16:53:54,551 [run_pretraining.py:  512]:	********exe.run_341******* 
[INFO] 2021-07-09 16:53:56,894 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:56,895 [run_pretraining.py:  534]:	loss/total_loss, 4.098565101623535, 342
[INFO] 2021-07-09 16:53:56,895 [run_pretraining.py:  535]:	loss/mlm_loss, 4.098565101623535, 342
[INFO] 2021-07-09 16:53:56,895 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.409999862924451e-06, 342
[INFO] 2021-07-09 16:53:56,895 [run_pretraining.py:  539]:	lr/loss_scaling, 590.2960815429688, 342
[INFO] 2021-07-09 16:53:56,895 [run_pretraining.py:  558]:	worker_index: 4, step: 342, cost: 4.098565, mlm loss: 4.098565, speed: 0.426658 steps/s, speed: 3.413260 samples/s, speed: 1747.589156 tokens/s, learning rate: 3.410e-06, loss_scalings: 590.296082, pp_loss: 4.063657
[INFO] 2021-07-09 16:53:56,895 [run_pretraining.py:  512]:	********exe.run_342******* 
[INFO] 2021-07-09 16:53:59,216 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:59,217 [run_pretraining.py:  534]:	loss/total_loss, 4.112089157104492, 343
[INFO] 2021-07-09 16:53:59,217 [run_pretraining.py:  535]:	loss/mlm_loss, 4.112089157104492, 343
[INFO] 2021-07-09 16:53:59,217 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.41999998454412e-06, 343
[INFO] 2021-07-09 16:53:59,217 [run_pretraining.py:  539]:	lr/loss_scaling, 590.2960815429688, 343
[INFO] 2021-07-09 16:53:59,217 [run_pretraining.py:  558]:	worker_index: 4, step: 343, cost: 4.112089, mlm loss: 4.112089, speed: 0.430798 steps/s, speed: 3.446381 samples/s, speed: 1764.547323 tokens/s, learning rate: 3.420e-06, loss_scalings: 590.296082, pp_loss: 4.076763
[INFO] 2021-07-09 16:53:59,217 [run_pretraining.py:  512]:	********exe.run_343******* 
[INFO] 2021-07-09 16:54:01,650 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:01,651 [run_pretraining.py:  534]:	loss/total_loss, 4.048990726470947, 344
[INFO] 2021-07-09 16:54:01,651 [run_pretraining.py:  535]:	loss/mlm_loss, 4.048990726470947, 344
[INFO] 2021-07-09 16:54:01,651 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.429999878790113e-06, 344
[INFO] 2021-07-09 16:54:01,651 [run_pretraining.py:  539]:	lr/loss_scaling, 590.2960815429688, 344
[INFO] 2021-07-09 16:54:01,651 [run_pretraining.py:  558]:	worker_index: 4, step: 344, cost: 4.048991, mlm loss: 4.048991, speed: 0.410985 steps/s, speed: 3.287881 samples/s, speed: 1683.395003 tokens/s, learning rate: 3.430e-06, loss_scalings: 590.296082, pp_loss: 4.076136
[INFO] 2021-07-09 16:54:01,651 [run_pretraining.py:  512]:	********exe.run_344******* 
[INFO] 2021-07-09 16:54:04,188 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:04,189 [run_pretraining.py:  534]:	loss/total_loss, 4.054059028625488, 345
[INFO] 2021-07-09 16:54:04,189 [run_pretraining.py:  535]:	loss/mlm_loss, 4.054059028625488, 345
[INFO] 2021-07-09 16:54:04,189 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.440000000409782e-06, 345
[INFO] 2021-07-09 16:54:04,189 [run_pretraining.py:  539]:	lr/loss_scaling, 590.2960815429688, 345
[INFO] 2021-07-09 16:54:04,189 [run_pretraining.py:  558]:	worker_index: 4, step: 345, cost: 4.054059, mlm loss: 4.054059, speed: 0.394089 steps/s, speed: 3.152713 samples/s, speed: 1614.189224 tokens/s, learning rate: 3.440e-06, loss_scalings: 590.296082, pp_loss: 4.072908
[INFO] 2021-07-09 16:54:04,189 [run_pretraining.py:  512]:	********exe.run_345******* 
[INFO] 2021-07-09 16:54:06,912 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:06,913 [run_pretraining.py:  534]:	loss/total_loss, 4.130210876464844, 346
[INFO] 2021-07-09 16:54:06,913 [run_pretraining.py:  535]:	loss/mlm_loss, 4.130210876464844, 346
[INFO] 2021-07-09 16:54:06,913 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.4499998946557753e-06, 346
[INFO] 2021-07-09 16:54:06,913 [run_pretraining.py:  539]:	lr/loss_scaling, 590.2960815429688, 346
[INFO] 2021-07-09 16:54:06,914 [run_pretraining.py:  558]:	worker_index: 4, step: 346, cost: 4.130211, mlm loss: 4.130211, speed: 0.367142 steps/s, speed: 2.937134 samples/s, speed: 1503.812841 tokens/s, learning rate: 3.450e-06, loss_scalings: 590.296082, pp_loss: 4.108861
[INFO] 2021-07-09 16:54:06,914 [run_pretraining.py:  512]:	********exe.run_346******* 
[INFO] 2021-07-09 16:54:09,148 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:09,149 [run_pretraining.py:  534]:	loss/total_loss, 4.243422985076904, 347
[INFO] 2021-07-09 16:54:09,149 [run_pretraining.py:  535]:	loss/mlm_loss, 4.243422985076904, 347
[INFO] 2021-07-09 16:54:09,149 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.460000016275444e-06, 347
[INFO] 2021-07-09 16:54:09,149 [run_pretraining.py:  539]:	lr/loss_scaling, 590.2960815429688, 347
[INFO] 2021-07-09 16:54:09,149 [run_pretraining.py:  558]:	worker_index: 4, step: 347, cost: 4.243423, mlm loss: 4.243423, speed: 0.447416 steps/s, speed: 3.579332 samples/s, speed: 1832.617901 tokens/s, learning rate: 3.460e-06, loss_scalings: 590.296082, pp_loss: 4.147007
[INFO] 2021-07-09 16:54:09,149 [run_pretraining.py:  512]:	********exe.run_347******* 
[INFO] 2021-07-09 16:54:11,436 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:11,437 [run_pretraining.py:  534]:	loss/total_loss, 4.090210914611816, 348
[INFO] 2021-07-09 16:54:11,437 [run_pretraining.py:  535]:	loss/mlm_loss, 4.090210914611816, 348
[INFO] 2021-07-09 16:54:11,437 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.469999683147762e-06, 348
[INFO] 2021-07-09 16:54:11,437 [run_pretraining.py:  539]:	lr/loss_scaling, 590.2960815429688, 348
[INFO] 2021-07-09 16:54:11,437 [run_pretraining.py:  558]:	worker_index: 4, step: 348, cost: 4.090211, mlm loss: 4.090211, speed: 0.437247 steps/s, speed: 3.497979 samples/s, speed: 1790.965167 tokens/s, learning rate: 3.470e-06, loss_scalings: 590.296082, pp_loss: 4.146041
[INFO] 2021-07-09 16:54:11,437 [run_pretraining.py:  512]:	********exe.run_348******* 
[INFO] 2021-07-09 16:54:13,700 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:13,700 [run_pretraining.py:  534]:	loss/total_loss, 4.10470724105835, 349
[INFO] 2021-07-09 16:54:13,700 [run_pretraining.py:  535]:	loss/mlm_loss, 4.10470724105835, 349
[INFO] 2021-07-09 16:54:13,701 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.480000032141106e-06, 349
[INFO] 2021-07-09 16:54:13,701 [run_pretraining.py:  539]:	lr/loss_scaling, 472.23687744140625, 349
[INFO] 2021-07-09 16:54:13,701 [run_pretraining.py:  558]:	worker_index: 4, step: 349, cost: 4.104707, mlm loss: 4.104707, speed: 0.441892 steps/s, speed: 3.535133 samples/s, speed: 1809.988069 tokens/s, learning rate: 3.480e-06, loss_scalings: 472.236877, pp_loss: 4.114927
[INFO] 2021-07-09 16:54:13,701 [run_pretraining.py:  512]:	********exe.run_349******* 
[INFO] 2021-07-09 16:54:16,001 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:16,001 [run_pretraining.py:  534]:	loss/total_loss, 4.129912376403809, 350
[INFO] 2021-07-09 16:54:16,001 [run_pretraining.py:  535]:	loss/mlm_loss, 4.129912376403809, 350
[INFO] 2021-07-09 16:54:16,002 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.489999699013424e-06, 350
[INFO] 2021-07-09 16:54:16,002 [run_pretraining.py:  539]:	lr/loss_scaling, 472.23687744140625, 350
[INFO] 2021-07-09 16:54:16,002 [run_pretraining.py:  558]:	worker_index: 4, step: 350, cost: 4.129912, mlm loss: 4.129912, speed: 0.434716 steps/s, speed: 3.477731 samples/s, speed: 1780.598274 tokens/s, learning rate: 3.490e-06, loss_scalings: 472.236877, pp_loss: 4.130998
[INFO] 2021-07-09 16:54:16,002 [run_pretraining.py:  512]:	********exe.run_350******* 
[INFO] 2021-07-09 16:54:18,288 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:18,289 [run_pretraining.py:  534]:	loss/total_loss, 4.299989700317383, 351
[INFO] 2021-07-09 16:54:18,289 [run_pretraining.py:  535]:	loss/mlm_loss, 4.299989700317383, 351
[INFO] 2021-07-09 16:54:18,289 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.499999820633093e-06, 351
[INFO] 2021-07-09 16:54:18,289 [run_pretraining.py:  539]:	lr/loss_scaling, 472.23687744140625, 351
[INFO] 2021-07-09 16:54:18,289 [run_pretraining.py:  558]:	worker_index: 4, step: 351, cost: 4.299990, mlm loss: 4.299990, speed: 0.437306 steps/s, speed: 3.498446 samples/s, speed: 1791.204180 tokens/s, learning rate: 3.500e-06, loss_scalings: 472.236877, pp_loss: 4.124647
[INFO] 2021-07-09 16:54:18,289 [run_pretraining.py:  512]:	********exe.run_351******* 
[INFO] 2021-07-09 16:54:20,600 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:20,601 [run_pretraining.py:  534]:	loss/total_loss, 4.209733963012695, 352
[INFO] 2021-07-09 16:54:20,601 [run_pretraining.py:  535]:	loss/mlm_loss, 4.209733963012695, 352
[INFO] 2021-07-09 16:54:20,601 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.510000169626437e-06, 352
[INFO] 2021-07-09 16:54:20,601 [run_pretraining.py:  539]:	lr/loss_scaling, 472.23687744140625, 352
[INFO] 2021-07-09 16:54:20,601 [run_pretraining.py:  558]:	worker_index: 4, step: 352, cost: 4.209734, mlm loss: 4.209734, speed: 0.432650 steps/s, speed: 3.461203 samples/s, speed: 1772.135950 tokens/s, learning rate: 3.510e-06, loss_scalings: 472.236877, pp_loss: 4.098282
[INFO] 2021-07-09 16:54:20,601 [run_pretraining.py:  512]:	********exe.run_352******* 
[INFO] 2021-07-09 16:54:22,878 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:22,878 [run_pretraining.py:  534]:	loss/total_loss, 4.038883209228516, 353
[INFO] 2021-07-09 16:54:22,878 [run_pretraining.py:  535]:	loss/mlm_loss, 4.038883209228516, 353
[INFO] 2021-07-09 16:54:22,879 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.519999836498755e-06, 353
[INFO] 2021-07-09 16:54:22,879 [run_pretraining.py:  539]:	lr/loss_scaling, 472.23687744140625, 353
[INFO] 2021-07-09 16:54:22,879 [run_pretraining.py:  558]:	worker_index: 4, step: 353, cost: 4.038883, mlm loss: 4.038883, speed: 0.439197 steps/s, speed: 3.513577 samples/s, speed: 1798.951614 tokens/s, learning rate: 3.520e-06, loss_scalings: 472.236877, pp_loss: 4.050856
[INFO] 2021-07-09 16:54:22,879 [run_pretraining.py:  512]:	********exe.run_353******* 
[INFO] 2021-07-09 16:54:25,137 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:25,138 [run_pretraining.py:  534]:	loss/total_loss, 4.083735466003418, 354
[INFO] 2021-07-09 16:54:25,138 [run_pretraining.py:  535]:	loss/mlm_loss, 4.083735466003418, 354
[INFO] 2021-07-09 16:54:25,138 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.529999958118424e-06, 354
[INFO] 2021-07-09 16:54:25,138 [run_pretraining.py:  539]:	lr/loss_scaling, 472.23687744140625, 354
[INFO] 2021-07-09 16:54:25,138 [run_pretraining.py:  558]:	worker_index: 4, step: 354, cost: 4.083735, mlm loss: 4.083735, speed: 0.442680 steps/s, speed: 3.541438 samples/s, speed: 1813.216505 tokens/s, learning rate: 3.530e-06, loss_scalings: 472.236877, pp_loss: 4.016795
[INFO] 2021-07-09 16:54:25,139 [run_pretraining.py:  512]:	********exe.run_354******* 
[INFO] 2021-07-09 16:54:27,342 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:27,342 [run_pretraining.py:  534]:	loss/total_loss, 4.145763874053955, 355
[INFO] 2021-07-09 16:54:27,342 [run_pretraining.py:  535]:	loss/mlm_loss, 4.145763874053955, 355
[INFO] 2021-07-09 16:54:27,342 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.539999852364417e-06, 355
[INFO] 2021-07-09 16:54:27,343 [run_pretraining.py:  539]:	lr/loss_scaling, 472.23687744140625, 355
[INFO] 2021-07-09 16:54:27,343 [run_pretraining.py:  558]:	worker_index: 4, step: 355, cost: 4.145764, mlm loss: 4.145764, speed: 0.453826 steps/s, speed: 3.630605 samples/s, speed: 1858.869524 tokens/s, learning rate: 3.540e-06, loss_scalings: 472.236877, pp_loss: 4.043145
[INFO] 2021-07-09 16:54:27,343 [run_pretraining.py:  512]:	********exe.run_355******* 
[INFO] 2021-07-09 16:54:29,563 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:29,564 [run_pretraining.py:  534]:	loss/total_loss, 3.996016263961792, 356
[INFO] 2021-07-09 16:54:29,564 [run_pretraining.py:  535]:	loss/mlm_loss, 3.996016263961792, 356
[INFO] 2021-07-09 16:54:29,564 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.549999973984086e-06, 356
[INFO] 2021-07-09 16:54:29,564 [run_pretraining.py:  539]:	lr/loss_scaling, 472.23687744140625, 356
[INFO] 2021-07-09 16:54:29,564 [run_pretraining.py:  558]:	worker_index: 4, step: 356, cost: 3.996016, mlm loss: 3.996016, speed: 0.450300 steps/s, speed: 3.602403 samples/s, speed: 1844.430367 tokens/s, learning rate: 3.550e-06, loss_scalings: 472.236877, pp_loss: 4.010813
[INFO] 2021-07-09 16:54:29,564 [run_pretraining.py:  512]:	********exe.run_356******* 
[INFO] 2021-07-09 16:54:31,863 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:31,863 [run_pretraining.py:  534]:	loss/total_loss, 4.034208297729492, 357
[INFO] 2021-07-09 16:54:31,863 [run_pretraining.py:  535]:	loss/mlm_loss, 4.034208297729492, 357
[INFO] 2021-07-09 16:54:31,863 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.5599998682300793e-06, 357
[INFO] 2021-07-09 16:54:31,863 [run_pretraining.py:  539]:	lr/loss_scaling, 472.23687744140625, 357
[INFO] 2021-07-09 16:54:31,863 [run_pretraining.py:  558]:	worker_index: 4, step: 357, cost: 4.034208, mlm loss: 4.034208, speed: 0.435026 steps/s, speed: 3.480207 samples/s, speed: 1781.865921 tokens/s, learning rate: 3.560e-06, loss_scalings: 472.236877, pp_loss: 4.092491
[INFO] 2021-07-09 16:54:31,864 [run_pretraining.py:  512]:	********exe.run_357******* 
[INFO] 2021-07-09 16:54:34,136 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:34,137 [run_pretraining.py:  534]:	loss/total_loss, 4.026410102844238, 358
[INFO] 2021-07-09 16:54:34,137 [run_pretraining.py:  535]:	loss/mlm_loss, 4.026410102844238, 358
[INFO] 2021-07-09 16:54:34,137 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.569999989849748e-06, 358
[INFO] 2021-07-09 16:54:34,137 [run_pretraining.py:  539]:	lr/loss_scaling, 472.23687744140625, 358
[INFO] 2021-07-09 16:54:34,137 [run_pretraining.py:  558]:	worker_index: 4, step: 358, cost: 4.026410, mlm loss: 4.026410, speed: 0.439911 steps/s, speed: 3.519292 samples/s, speed: 1801.877468 tokens/s, learning rate: 3.570e-06, loss_scalings: 472.236877, pp_loss: 4.040206
[INFO] 2021-07-09 16:54:34,137 [run_pretraining.py:  512]:	********exe.run_358******* 
[INFO] 2021-07-09 16:54:36,372 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:36,372 [run_pretraining.py:  534]:	loss/total_loss, 4.084611892700195, 359
[INFO] 2021-07-09 16:54:36,372 [run_pretraining.py:  535]:	loss/mlm_loss, 4.084611892700195, 359
[INFO] 2021-07-09 16:54:36,372 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.5799998840957414e-06, 359
[INFO] 2021-07-09 16:54:36,373 [run_pretraining.py:  539]:	lr/loss_scaling, 472.23687744140625, 359
[INFO] 2021-07-09 16:54:36,373 [run_pretraining.py:  558]:	worker_index: 4, step: 359, cost: 4.084612, mlm loss: 4.084612, speed: 0.447493 steps/s, speed: 3.579944 samples/s, speed: 1832.931325 tokens/s, learning rate: 3.580e-06, loss_scalings: 472.236877, pp_loss: 4.094237
[INFO] 2021-07-09 16:54:36,373 [run_pretraining.py:  512]:	********exe.run_359******* 
[INFO] 2021-07-09 16:54:38,603 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:38,603 [run_pretraining.py:  534]:	loss/total_loss, 4.269534587860107, 360
[INFO] 2021-07-09 16:54:38,603 [run_pretraining.py:  535]:	loss/mlm_loss, 4.269534587860107, 360
[INFO] 2021-07-09 16:54:38,603 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.5900000057154102e-06, 360
[INFO] 2021-07-09 16:54:38,604 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 360
[INFO] 2021-07-09 16:54:38,604 [run_pretraining.py:  558]:	worker_index: 4, step: 360, cost: 4.269535, mlm loss: 4.269535, speed: 0.448378 steps/s, speed: 3.587025 samples/s, speed: 1836.556670 tokens/s, learning rate: 3.590e-06, loss_scalings: 377.789520, pp_loss: 4.179570
[INFO] 2021-07-09 16:54:38,604 [run_pretraining.py:  512]:	********exe.run_360******* 
[INFO] 2021-07-09 16:54:40,805 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:40,805 [run_pretraining.py:  534]:	loss/total_loss, 4.1636962890625, 361
[INFO] 2021-07-09 16:54:40,805 [run_pretraining.py:  535]:	loss/mlm_loss, 4.1636962890625, 361
[INFO] 2021-07-09 16:54:40,806 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.599999672587728e-06, 361
[INFO] 2021-07-09 16:54:40,806 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 361
[INFO] 2021-07-09 16:54:40,806 [run_pretraining.py:  558]:	worker_index: 4, step: 361, cost: 4.163696, mlm loss: 4.163696, speed: 0.454266 steps/s, speed: 3.634132 samples/s, speed: 1860.675418 tokens/s, learning rate: 3.600e-06, loss_scalings: 377.789520, pp_loss: 4.193367
[INFO] 2021-07-09 16:54:40,806 [run_pretraining.py:  512]:	********exe.run_361******* 
[INFO] 2021-07-09 16:54:43,028 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:43,028 [run_pretraining.py:  534]:	loss/total_loss, 4.289050579071045, 362
[INFO] 2021-07-09 16:54:43,028 [run_pretraining.py:  535]:	loss/mlm_loss, 4.289050579071045, 362
[INFO] 2021-07-09 16:54:43,028 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.6100000215810724e-06, 362
[INFO] 2021-07-09 16:54:43,029 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 362
[INFO] 2021-07-09 16:54:43,029 [run_pretraining.py:  558]:	worker_index: 4, step: 362, cost: 4.289051, mlm loss: 4.289051, speed: 0.450007 steps/s, speed: 3.600054 samples/s, speed: 1843.227400 tokens/s, learning rate: 3.610e-06, loss_scalings: 377.789520, pp_loss: 4.262006
[INFO] 2021-07-09 16:54:43,029 [run_pretraining.py:  512]:	********exe.run_362******* 
[INFO] 2021-07-09 16:54:45,305 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:45,305 [run_pretraining.py:  534]:	loss/total_loss, 4.27186918258667, 363
[INFO] 2021-07-09 16:54:45,305 [run_pretraining.py:  535]:	loss/mlm_loss, 4.27186918258667, 363
[INFO] 2021-07-09 16:54:45,306 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.620000143200741e-06, 363
[INFO] 2021-07-09 16:54:45,306 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 363
[INFO] 2021-07-09 16:54:45,306 [run_pretraining.py:  558]:	worker_index: 4, step: 363, cost: 4.271869, mlm loss: 4.271869, speed: 0.439278 steps/s, speed: 3.514224 samples/s, speed: 1799.282835 tokens/s, learning rate: 3.620e-06, loss_scalings: 377.789520, pp_loss: 4.276279
[INFO] 2021-07-09 16:54:45,306 [run_pretraining.py:  512]:	********exe.run_363******* 
[INFO] 2021-07-09 16:54:47,542 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:47,543 [run_pretraining.py:  534]:	loss/total_loss, 4.271359443664551, 364
[INFO] 2021-07-09 16:54:47,543 [run_pretraining.py:  535]:	loss/mlm_loss, 4.271359443664551, 364
[INFO] 2021-07-09 16:54:47,543 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.629999810073059e-06, 364
[INFO] 2021-07-09 16:54:47,543 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 364
[INFO] 2021-07-09 16:54:47,543 [run_pretraining.py:  558]:	worker_index: 4, step: 364, cost: 4.271359, mlm loss: 4.271359, speed: 0.447101 steps/s, speed: 3.576810 samples/s, speed: 1831.326820 tokens/s, learning rate: 3.630e-06, loss_scalings: 377.789520, pp_loss: 4.331260
[INFO] 2021-07-09 16:54:47,543 [run_pretraining.py:  512]:	********exe.run_364******* 
[INFO] 2021-07-09 16:54:49,837 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:49,837 [run_pretraining.py:  534]:	loss/total_loss, 4.309345722198486, 365
[INFO] 2021-07-09 16:54:49,837 [run_pretraining.py:  535]:	loss/mlm_loss, 4.309345722198486, 365
[INFO] 2021-07-09 16:54:49,837 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.6400001590664033e-06, 365
[INFO] 2021-07-09 16:54:49,837 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 365
[INFO] 2021-07-09 16:54:49,837 [run_pretraining.py:  558]:	worker_index: 4, step: 365, cost: 4.309346, mlm loss: 4.309346, speed: 0.435989 steps/s, speed: 3.487908 samples/s, speed: 1785.809090 tokens/s, learning rate: 3.640e-06, loss_scalings: 377.789520, pp_loss: 4.347877
[INFO] 2021-07-09 16:54:49,837 [run_pretraining.py:  512]:	********exe.run_365******* 
[INFO] 2021-07-09 16:54:52,077 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:52,077 [run_pretraining.py:  534]:	loss/total_loss, 4.342219352722168, 366
[INFO] 2021-07-09 16:54:52,077 [run_pretraining.py:  535]:	loss/mlm_loss, 4.342219352722168, 366
[INFO] 2021-07-09 16:54:52,078 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.649999825938721e-06, 366
[INFO] 2021-07-09 16:54:52,078 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 366
[INFO] 2021-07-09 16:54:52,078 [run_pretraining.py:  558]:	worker_index: 4, step: 366, cost: 4.342219, mlm loss: 4.342219, speed: 0.446496 steps/s, speed: 3.571967 samples/s, speed: 1828.847249 tokens/s, learning rate: 3.650e-06, loss_scalings: 377.789520, pp_loss: 4.365047
[INFO] 2021-07-09 16:54:52,078 [run_pretraining.py:  512]:	********exe.run_366******* 
[INFO] 2021-07-09 16:54:54,431 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:54,432 [run_pretraining.py:  534]:	loss/total_loss, 4.363811492919922, 367
[INFO] 2021-07-09 16:54:54,432 [run_pretraining.py:  535]:	loss/mlm_loss, 4.363811492919922, 367
[INFO] 2021-07-09 16:54:54,432 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.65999994755839e-06, 367
[INFO] 2021-07-09 16:54:54,432 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 367
[INFO] 2021-07-09 16:54:54,432 [run_pretraining.py:  558]:	worker_index: 4, step: 367, cost: 4.363811, mlm loss: 4.363811, speed: 0.424819 steps/s, speed: 3.398552 samples/s, speed: 1740.058869 tokens/s, learning rate: 3.660e-06, loss_scalings: 377.789520, pp_loss: 4.383070
[INFO] 2021-07-09 16:54:54,432 [run_pretraining.py:  512]:	********exe.run_367******* 
[INFO] 2021-07-09 16:54:56,671 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:56,672 [run_pretraining.py:  534]:	loss/total_loss, 4.420602798461914, 368
[INFO] 2021-07-09 16:54:56,672 [run_pretraining.py:  535]:	loss/mlm_loss, 4.420602798461914, 368
[INFO] 2021-07-09 16:54:56,672 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.6699998418043833e-06, 368
[INFO] 2021-07-09 16:54:56,672 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 368
[INFO] 2021-07-09 16:54:56,672 [run_pretraining.py:  558]:	worker_index: 4, step: 368, cost: 4.420603, mlm loss: 4.420603, speed: 0.446593 steps/s, speed: 3.572740 samples/s, speed: 1829.242937 tokens/s, learning rate: 3.670e-06, loss_scalings: 377.789520, pp_loss: 4.432927
[INFO] 2021-07-09 16:54:56,672 [run_pretraining.py:  512]:	********exe.run_368******* 
[INFO] 2021-07-09 16:54:58,905 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:58,906 [run_pretraining.py:  534]:	loss/total_loss, 4.413341999053955, 369
[INFO] 2021-07-09 16:54:58,906 [run_pretraining.py:  535]:	loss/mlm_loss, 4.413341999053955, 369
[INFO] 2021-07-09 16:54:58,906 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.679999963424052e-06, 369
[INFO] 2021-07-09 16:54:58,906 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 369
[INFO] 2021-07-09 16:54:58,906 [run_pretraining.py:  558]:	worker_index: 4, step: 369, cost: 4.413342, mlm loss: 4.413342, speed: 0.447746 steps/s, speed: 3.581970 samples/s, speed: 1833.968557 tokens/s, learning rate: 3.680e-06, loss_scalings: 377.789520, pp_loss: 4.485603
[INFO] 2021-07-09 16:54:58,906 [run_pretraining.py:  512]:	********exe.run_369******* 
[INFO] 2021-07-09 16:55:01,174 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:01,174 [run_pretraining.py:  534]:	loss/total_loss, 4.432804584503174, 370
[INFO] 2021-07-09 16:55:01,174 [run_pretraining.py:  535]:	loss/mlm_loss, 4.432804584503174, 370
[INFO] 2021-07-09 16:55:01,175 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.6899998576700455e-06, 370
[INFO] 2021-07-09 16:55:01,175 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 370
[INFO] 2021-07-09 16:55:01,175 [run_pretraining.py:  558]:	worker_index: 4, step: 370, cost: 4.432805, mlm loss: 4.432805, speed: 0.440968 steps/s, speed: 3.527748 samples/s, speed: 1806.206942 tokens/s, learning rate: 3.690e-06, loss_scalings: 377.789520, pp_loss: 4.436166
[INFO] 2021-07-09 16:55:01,175 [run_pretraining.py:  512]:	********exe.run_370******* 
[INFO] 2021-07-09 16:55:03,466 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:03,467 [run_pretraining.py:  534]:	loss/total_loss, 4.418024063110352, 371
[INFO] 2021-07-09 16:55:03,467 [run_pretraining.py:  535]:	loss/mlm_loss, 4.418024063110352, 371
[INFO] 2021-07-09 16:55:03,467 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.6999999792897142e-06, 371
[INFO] 2021-07-09 16:55:03,467 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 371
[INFO] 2021-07-09 16:55:03,467 [run_pretraining.py:  558]:	worker_index: 4, step: 371, cost: 4.418024, mlm loss: 4.418024, speed: 0.436312 steps/s, speed: 3.490494 samples/s, speed: 1787.132877 tokens/s, learning rate: 3.700e-06, loss_scalings: 377.789520, pp_loss: 4.473611
[INFO] 2021-07-09 16:55:03,467 [run_pretraining.py:  512]:	********exe.run_371******* 
[INFO] 2021-07-09 16:55:05,726 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:05,727 [run_pretraining.py:  534]:	loss/total_loss, 4.385478496551514, 372
[INFO] 2021-07-09 16:55:05,727 [run_pretraining.py:  535]:	loss/mlm_loss, 4.385478496551514, 372
[INFO] 2021-07-09 16:55:05,727 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.709999646162032e-06, 372
[INFO] 2021-07-09 16:55:05,727 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 372
[INFO] 2021-07-09 16:55:05,727 [run_pretraining.py:  558]:	worker_index: 4, step: 372, cost: 4.385478, mlm loss: 4.385478, speed: 0.442636 steps/s, speed: 3.541087 samples/s, speed: 1813.036442 tokens/s, learning rate: 3.710e-06, loss_scalings: 377.789520, pp_loss: 4.393752
[INFO] 2021-07-09 16:55:05,727 [run_pretraining.py:  512]:	********exe.run_372******* 
[INFO] 2021-07-09 16:55:08,016 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:08,016 [run_pretraining.py:  534]:	loss/total_loss, 4.27823543548584, 373
[INFO] 2021-07-09 16:55:08,016 [run_pretraining.py:  535]:	loss/mlm_loss, 4.27823543548584, 373
[INFO] 2021-07-09 16:55:08,016 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.7199999951553764e-06, 373
[INFO] 2021-07-09 16:55:08,017 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 373
[INFO] 2021-07-09 16:55:08,017 [run_pretraining.py:  558]:	worker_index: 4, step: 373, cost: 4.278235, mlm loss: 4.278235, speed: 0.436921 steps/s, speed: 3.495367 samples/s, speed: 1789.627870 tokens/s, learning rate: 3.720e-06, loss_scalings: 377.789520, pp_loss: 4.309916
[INFO] 2021-07-09 16:55:08,017 [run_pretraining.py:  512]:	********exe.run_373******* 
[INFO] 2021-07-09 16:55:10,256 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:10,257 [run_pretraining.py:  534]:	loss/total_loss, 4.174792289733887, 374
[INFO] 2021-07-09 16:55:10,257 [run_pretraining.py:  535]:	loss/mlm_loss, 4.174792289733887, 374
[INFO] 2021-07-09 16:55:10,257 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.730000116775045e-06, 374
[INFO] 2021-07-09 16:55:10,257 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 374
[INFO] 2021-07-09 16:55:10,257 [run_pretraining.py:  558]:	worker_index: 4, step: 374, cost: 4.174792, mlm loss: 4.174792, speed: 0.446452 steps/s, speed: 3.571614 samples/s, speed: 1828.666599 tokens/s, learning rate: 3.730e-06, loss_scalings: 377.789520, pp_loss: 4.195273
[INFO] 2021-07-09 16:55:10,257 [run_pretraining.py:  512]:	********exe.run_374******* 
[INFO] 2021-07-09 16:55:12,511 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:12,511 [run_pretraining.py:  534]:	loss/total_loss, 3.9788360595703125, 375
[INFO] 2021-07-09 16:55:12,511 [run_pretraining.py:  535]:	loss/mlm_loss, 3.9788360595703125, 375
[INFO] 2021-07-09 16:55:12,511 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.739999783647363e-06, 375
[INFO] 2021-07-09 16:55:12,511 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 375
[INFO] 2021-07-09 16:55:12,511 [run_pretraining.py:  558]:	worker_index: 4, step: 375, cost: 3.978836, mlm loss: 3.978836, speed: 0.443733 steps/s, speed: 3.549860 samples/s, speed: 1817.528405 tokens/s, learning rate: 3.740e-06, loss_scalings: 377.789520, pp_loss: 4.052826
[INFO] 2021-07-09 16:55:12,512 [run_pretraining.py:  512]:	********exe.run_375******* 
[INFO] 2021-07-09 16:55:14,756 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:14,757 [run_pretraining.py:  534]:	loss/total_loss, 3.925826072692871, 376
[INFO] 2021-07-09 16:55:14,757 [run_pretraining.py:  535]:	loss/mlm_loss, 3.925826072692871, 376
[INFO] 2021-07-09 16:55:14,757 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.7500001326407073e-06, 376
[INFO] 2021-07-09 16:55:14,757 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 376
[INFO] 2021-07-09 16:55:14,757 [run_pretraining.py:  558]:	worker_index: 4, step: 376, cost: 3.925826, mlm loss: 3.925826, speed: 0.445433 steps/s, speed: 3.563462 samples/s, speed: 1824.492779 tokens/s, learning rate: 3.750e-06, loss_scalings: 377.789520, pp_loss: 3.865838
[INFO] 2021-07-09 16:55:14,757 [run_pretraining.py:  512]:	********exe.run_376******* 
[INFO] 2021-07-09 16:55:16,989 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:16,989 [run_pretraining.py:  534]:	loss/total_loss, 3.781177520751953, 377
[INFO] 2021-07-09 16:55:16,989 [run_pretraining.py:  535]:	loss/mlm_loss, 3.781177520751953, 377
[INFO] 2021-07-09 16:55:16,989 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.759999799513025e-06, 377
[INFO] 2021-07-09 16:55:16,989 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 377
[INFO] 2021-07-09 16:55:16,990 [run_pretraining.py:  558]:	worker_index: 4, step: 377, cost: 3.781178, mlm loss: 3.781178, speed: 0.448091 steps/s, speed: 3.584727 samples/s, speed: 1835.380027 tokens/s, learning rate: 3.760e-06, loss_scalings: 377.789520, pp_loss: 3.794420
[INFO] 2021-07-09 16:55:16,990 [run_pretraining.py:  512]:	********exe.run_377******* 
[INFO] 2021-07-09 16:55:19,241 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:19,241 [run_pretraining.py:  534]:	loss/total_loss, 3.6661605834960938, 378
[INFO] 2021-07-09 16:55:19,241 [run_pretraining.py:  535]:	loss/mlm_loss, 3.6661605834960938, 378
[INFO] 2021-07-09 16:55:19,242 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.769999921132694e-06, 378
[INFO] 2021-07-09 16:55:19,242 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 378
[INFO] 2021-07-09 16:55:19,242 [run_pretraining.py:  558]:	worker_index: 4, step: 378, cost: 3.666161, mlm loss: 3.666161, speed: 0.444144 steps/s, speed: 3.553152 samples/s, speed: 1819.213795 tokens/s, learning rate: 3.770e-06, loss_scalings: 377.789520, pp_loss: 3.728367
[INFO] 2021-07-09 16:55:19,242 [run_pretraining.py:  512]:	********exe.run_378******* 
[INFO] 2021-07-09 16:55:21,482 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:21,482 [run_pretraining.py:  534]:	loss/total_loss, 3.6362643241882324, 379
[INFO] 2021-07-09 16:55:21,482 [run_pretraining.py:  535]:	loss/mlm_loss, 3.6362643241882324, 379
[INFO] 2021-07-09 16:55:21,482 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.7799998153786873e-06, 379
[INFO] 2021-07-09 16:55:21,482 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 379
[INFO] 2021-07-09 16:55:21,482 [run_pretraining.py:  558]:	worker_index: 4, step: 379, cost: 3.636264, mlm loss: 3.636264, speed: 0.446400 steps/s, speed: 3.571196 samples/s, speed: 1828.452511 tokens/s, learning rate: 3.780e-06, loss_scalings: 377.789520, pp_loss: 3.630058
[INFO] 2021-07-09 16:55:21,482 [run_pretraining.py:  512]:	********exe.run_379******* 
[INFO] 2021-07-09 16:55:23,720 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:23,720 [run_pretraining.py:  534]:	loss/total_loss, 3.5489776134490967, 380
[INFO] 2021-07-09 16:55:23,720 [run_pretraining.py:  535]:	loss/mlm_loss, 3.5489776134490967, 380
[INFO] 2021-07-09 16:55:23,720 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.789999936998356e-06, 380
[INFO] 2021-07-09 16:55:23,720 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 380
[INFO] 2021-07-09 16:55:23,720 [run_pretraining.py:  558]:	worker_index: 4, step: 380, cost: 3.548978, mlm loss: 3.548978, speed: 0.446951 steps/s, speed: 3.575605 samples/s, speed: 1830.709565 tokens/s, learning rate: 3.790e-06, loss_scalings: 377.789520, pp_loss: 3.596200
[INFO] 2021-07-09 16:55:23,721 [run_pretraining.py:  512]:	********exe.run_380******* 
[INFO] 2021-07-09 16:55:25,957 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:25,958 [run_pretraining.py:  534]:	loss/total_loss, 3.6970605850219727, 381
[INFO] 2021-07-09 16:55:25,958 [run_pretraining.py:  535]:	loss/mlm_loss, 3.6970605850219727, 381
[INFO] 2021-07-09 16:55:25,958 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.7999998312443495e-06, 381
[INFO] 2021-07-09 16:55:25,958 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 381
[INFO] 2021-07-09 16:55:25,958 [run_pretraining.py:  558]:	worker_index: 4, step: 381, cost: 3.697061, mlm loss: 3.697061, speed: 0.446990 steps/s, speed: 3.575919 samples/s, speed: 1830.870717 tokens/s, learning rate: 3.800e-06, loss_scalings: 377.789520, pp_loss: 3.595370
[INFO] 2021-07-09 16:55:25,958 [run_pretraining.py:  512]:	********exe.run_381******* 
[INFO] 2021-07-09 16:55:28,215 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:28,216 [run_pretraining.py:  534]:	loss/total_loss, 3.573991298675537, 382
[INFO] 2021-07-09 16:55:28,216 [run_pretraining.py:  535]:	loss/mlm_loss, 3.573991298675537, 382
[INFO] 2021-07-09 16:55:28,216 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.8099999528640183e-06, 382
[INFO] 2021-07-09 16:55:28,216 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 382
[INFO] 2021-07-09 16:55:28,216 [run_pretraining.py:  558]:	worker_index: 4, step: 382, cost: 3.573991, mlm loss: 3.573991, speed: 0.442990 steps/s, speed: 3.543916 samples/s, speed: 1814.485043 tokens/s, learning rate: 3.810e-06, loss_scalings: 377.789520, pp_loss: 3.599300
[INFO] 2021-07-09 16:55:28,217 [run_pretraining.py:  512]:	********exe.run_382******* 
[INFO] 2021-07-09 16:55:30,464 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:30,464 [run_pretraining.py:  534]:	loss/total_loss, 3.5560102462768555, 383
[INFO] 2021-07-09 16:55:30,464 [run_pretraining.py:  535]:	loss/mlm_loss, 3.5560102462768555, 383
[INFO] 2021-07-09 16:55:30,464 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.819999619736336e-06, 383
[INFO] 2021-07-09 16:55:30,464 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 383
[INFO] 2021-07-09 16:55:30,464 [run_pretraining.py:  558]:	worker_index: 4, step: 383, cost: 3.556010, mlm loss: 3.556010, speed: 0.444967 steps/s, speed: 3.559733 samples/s, speed: 1822.583142 tokens/s, learning rate: 3.820e-06, loss_scalings: 377.789520, pp_loss: 3.594184
[INFO] 2021-07-09 16:55:30,465 [run_pretraining.py:  512]:	********exe.run_383******* 
[INFO] 2021-07-09 16:55:32,868 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:32,869 [run_pretraining.py:  534]:	loss/total_loss, 3.6344072818756104, 384
[INFO] 2021-07-09 16:55:32,869 [run_pretraining.py:  535]:	loss/mlm_loss, 3.6344072818756104, 384
[INFO] 2021-07-09 16:55:32,869 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.82999996872968e-06, 384
[INFO] 2021-07-09 16:55:32,869 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 384
[INFO] 2021-07-09 16:55:32,869 [run_pretraining.py:  558]:	worker_index: 4, step: 384, cost: 3.634407, mlm loss: 3.634407, speed: 0.415938 steps/s, speed: 3.327502 samples/s, speed: 1703.681108 tokens/s, learning rate: 3.830e-06, loss_scalings: 377.789520, pp_loss: 3.578512
[INFO] 2021-07-09 16:55:32,869 [run_pretraining.py:  512]:	********exe.run_384******* 
[INFO] 2021-07-09 16:55:35,211 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:35,211 [run_pretraining.py:  534]:	loss/total_loss, 3.49318790435791, 385
[INFO] 2021-07-09 16:55:35,211 [run_pretraining.py:  535]:	loss/mlm_loss, 3.49318790435791, 385
[INFO] 2021-07-09 16:55:35,212 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.839999862975674e-06, 385
[INFO] 2021-07-09 16:55:35,212 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 385
[INFO] 2021-07-09 16:55:35,212 [run_pretraining.py:  558]:	worker_index: 4, step: 385, cost: 3.493188, mlm loss: 3.493188, speed: 0.427046 steps/s, speed: 3.416371 samples/s, speed: 1749.182005 tokens/s, learning rate: 3.840e-06, loss_scalings: 377.789520, pp_loss: 3.485972
[INFO] 2021-07-09 16:55:35,212 [run_pretraining.py:  512]:	********exe.run_385******* 
[INFO] 2021-07-09 16:55:37,495 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:37,495 [run_pretraining.py:  534]:	loss/total_loss, 3.3762776851654053, 386
[INFO] 2021-07-09 16:55:37,495 [run_pretraining.py:  535]:	loss/mlm_loss, 3.3762776851654053, 386
[INFO] 2021-07-09 16:55:37,496 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.849999757221667e-06, 386
[INFO] 2021-07-09 16:55:37,496 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 386
[INFO] 2021-07-09 16:55:37,496 [run_pretraining.py:  558]:	worker_index: 4, step: 386, cost: 3.376278, mlm loss: 3.376278, speed: 0.437959 steps/s, speed: 3.503674 samples/s, speed: 1793.881001 tokens/s, learning rate: 3.850e-06, loss_scalings: 377.789520, pp_loss: 3.404322
[INFO] 2021-07-09 16:55:37,496 [run_pretraining.py:  512]:	********exe.run_386******* 
[INFO] 2021-07-09 16:55:39,764 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:39,765 [run_pretraining.py:  534]:	loss/total_loss, 3.343702793121338, 387
[INFO] 2021-07-09 16:55:39,765 [run_pretraining.py:  535]:	loss/mlm_loss, 3.343702793121338, 387
[INFO] 2021-07-09 16:55:39,766 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.860000106215011e-06, 387
[INFO] 2021-07-09 16:55:39,766 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 387
[INFO] 2021-07-09 16:55:39,766 [run_pretraining.py:  558]:	worker_index: 4, step: 387, cost: 3.343703, mlm loss: 3.343703, speed: 0.440689 steps/s, speed: 3.525510 samples/s, speed: 1805.061079 tokens/s, learning rate: 3.860e-06, loss_scalings: 377.789520, pp_loss: 3.327233
[INFO] 2021-07-09 16:55:39,766 [run_pretraining.py:  512]:	********exe.run_387******* 
[INFO] 2021-07-09 16:55:41,995 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:41,995 [run_pretraining.py:  534]:	loss/total_loss, 3.309765100479126, 388
[INFO] 2021-07-09 16:55:41,996 [run_pretraining.py:  535]:	loss/mlm_loss, 3.309765100479126, 388
[INFO] 2021-07-09 16:55:41,996 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.870000000461005e-06, 388
[INFO] 2021-07-09 16:55:41,996 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 388
[INFO] 2021-07-09 16:55:41,996 [run_pretraining.py:  558]:	worker_index: 4, step: 388, cost: 3.309765, mlm loss: 3.309765, speed: 0.448558 steps/s, speed: 3.588466 samples/s, speed: 1837.294385 tokens/s, learning rate: 3.870e-06, loss_scalings: 377.789520, pp_loss: 3.306924
[INFO] 2021-07-09 16:55:41,996 [run_pretraining.py:  512]:	********exe.run_388******* 
[INFO] 2021-07-09 16:55:44,266 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:44,266 [run_pretraining.py:  534]:	loss/total_loss, 3.2833681106567383, 389
[INFO] 2021-07-09 16:55:44,266 [run_pretraining.py:  535]:	loss/mlm_loss, 3.2833681106567383, 389
[INFO] 2021-07-09 16:55:44,266 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.879999894706998e-06, 389
[INFO] 2021-07-09 16:55:44,266 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 389
[INFO] 2021-07-09 16:55:44,266 [run_pretraining.py:  558]:	worker_index: 4, step: 389, cost: 3.283368, mlm loss: 3.283368, speed: 0.440539 steps/s, speed: 3.524313 samples/s, speed: 1804.448133 tokens/s, learning rate: 3.880e-06, loss_scalings: 377.789520, pp_loss: 3.269653
[INFO] 2021-07-09 16:55:44,266 [run_pretraining.py:  512]:	********exe.run_389******* 
[INFO] 2021-07-09 16:55:46,548 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:46,549 [run_pretraining.py:  534]:	loss/total_loss, 3.3052282333374023, 390
[INFO] 2021-07-09 16:55:46,549 [run_pretraining.py:  535]:	loss/mlm_loss, 3.3052282333374023, 390
[INFO] 2021-07-09 16:55:46,549 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.889999788952991e-06, 390
[INFO] 2021-07-09 16:55:46,549 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 390
[INFO] 2021-07-09 16:55:46,549 [run_pretraining.py:  558]:	worker_index: 4, step: 390, cost: 3.305228, mlm loss: 3.305228, speed: 0.438161 steps/s, speed: 3.505288 samples/s, speed: 1794.707431 tokens/s, learning rate: 3.890e-06, loss_scalings: 377.789520, pp_loss: 3.323062
[INFO] 2021-07-09 16:55:46,549 [run_pretraining.py:  512]:	********exe.run_390******* 
[INFO] 2021-07-09 16:55:48,885 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:48,885 [run_pretraining.py:  534]:	loss/total_loss, 3.2682337760925293, 391
[INFO] 2021-07-09 16:55:48,886 [run_pretraining.py:  535]:	loss/mlm_loss, 3.2682337760925293, 391
[INFO] 2021-07-09 16:55:48,886 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.900000137946336e-06, 391
[INFO] 2021-07-09 16:55:48,886 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 391
[INFO] 2021-07-09 16:55:48,886 [run_pretraining.py:  558]:	worker_index: 4, step: 391, cost: 3.268234, mlm loss: 3.268234, speed: 0.428140 steps/s, speed: 3.425124 samples/s, speed: 1753.663448 tokens/s, learning rate: 3.900e-06, loss_scalings: 377.789520, pp_loss: 3.267732
[INFO] 2021-07-09 16:55:48,886 [run_pretraining.py:  512]:	********exe.run_391******* 
[INFO] 2021-07-09 16:55:51,213 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:51,213 [run_pretraining.py:  534]:	loss/total_loss, 3.143308162689209, 392
[INFO] 2021-07-09 16:55:51,213 [run_pretraining.py:  535]:	loss/mlm_loss, 3.143308162689209, 392
[INFO] 2021-07-09 16:55:51,214 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.909999577444978e-06, 392
[INFO] 2021-07-09 16:55:51,214 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 392
[INFO] 2021-07-09 16:55:51,214 [run_pretraining.py:  558]:	worker_index: 4, step: 392, cost: 3.143308, mlm loss: 3.143308, speed: 0.429670 steps/s, speed: 3.437360 samples/s, speed: 1759.928117 tokens/s, learning rate: 3.910e-06, loss_scalings: 377.789520, pp_loss: 3.185118
[INFO] 2021-07-09 16:55:51,214 [run_pretraining.py:  512]:	********exe.run_392******* 
[INFO] 2021-07-09 16:55:53,526 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:53,527 [run_pretraining.py:  534]:	loss/total_loss, 3.0663230419158936, 393
[INFO] 2021-07-09 16:55:53,527 [run_pretraining.py:  535]:	loss/mlm_loss, 3.0663230419158936, 393
[INFO] 2021-07-09 16:55:53,527 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.919999926438322e-06, 393
[INFO] 2021-07-09 16:55:53,527 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 393
[INFO] 2021-07-09 16:55:53,527 [run_pretraining.py:  558]:	worker_index: 4, step: 393, cost: 3.066323, mlm loss: 3.066323, speed: 0.432409 steps/s, speed: 3.459275 samples/s, speed: 1771.149019 tokens/s, learning rate: 3.920e-06, loss_scalings: 377.789520, pp_loss: 3.057939
[INFO] 2021-07-09 16:55:53,527 [run_pretraining.py:  512]:	********exe.run_393******* 
[INFO] 2021-07-09 16:55:55,770 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:55,771 [run_pretraining.py:  534]:	loss/total_loss, 2.9583256244659424, 394
[INFO] 2021-07-09 16:55:55,771 [run_pretraining.py:  535]:	loss/mlm_loss, 2.9583256244659424, 394
[INFO] 2021-07-09 16:55:55,771 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.929999820684316e-06, 394
[INFO] 2021-07-09 16:55:55,771 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 394
[INFO] 2021-07-09 16:55:55,771 [run_pretraining.py:  558]:	worker_index: 4, step: 394, cost: 2.958326, mlm loss: 2.958326, speed: 0.445727 steps/s, speed: 3.565819 samples/s, speed: 1825.699346 tokens/s, learning rate: 3.930e-06, loss_scalings: 377.789520, pp_loss: 2.988221
[INFO] 2021-07-09 16:55:55,771 [run_pretraining.py:  512]:	********exe.run_394******* 
[INFO] 2021-07-09 16:55:58,040 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:58,041 [run_pretraining.py:  534]:	loss/total_loss, 2.8939120769500732, 395
[INFO] 2021-07-09 16:55:58,041 [run_pretraining.py:  535]:	loss/mlm_loss, 2.8939120769500732, 395
[INFO] 2021-07-09 16:55:58,041 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.939999714930309e-06, 395
[INFO] 2021-07-09 16:55:58,041 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 395
[INFO] 2021-07-09 16:55:58,041 [run_pretraining.py:  558]:	worker_index: 4, step: 395, cost: 2.893912, mlm loss: 2.893912, speed: 0.440673 steps/s, speed: 3.525381 samples/s, speed: 1804.995271 tokens/s, learning rate: 3.940e-06, loss_scalings: 377.789520, pp_loss: 2.915318
[INFO] 2021-07-09 16:55:58,041 [run_pretraining.py:  512]:	********exe.run_395******* 
[INFO] 2021-07-09 16:56:00,359 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:00,360 [run_pretraining.py:  534]:	loss/total_loss, 2.9155492782592773, 396
[INFO] 2021-07-09 16:56:00,360 [run_pretraining.py:  535]:	loss/mlm_loss, 2.9155492782592773, 396
[INFO] 2021-07-09 16:56:00,360 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.950000063923653e-06, 396
[INFO] 2021-07-09 16:56:00,360 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 396
[INFO] 2021-07-09 16:56:00,360 [run_pretraining.py:  558]:	worker_index: 4, step: 396, cost: 2.915549, mlm loss: 2.915549, speed: 0.431363 steps/s, speed: 3.450901 samples/s, speed: 1766.861306 tokens/s, learning rate: 3.950e-06, loss_scalings: 377.789520, pp_loss: 2.937742
[INFO] 2021-07-09 16:56:00,360 [run_pretraining.py:  512]:	********exe.run_396******* 
[INFO] 2021-07-09 16:56:02,691 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:02,692 [run_pretraining.py:  534]:	loss/total_loss, 2.9231603145599365, 397
[INFO] 2021-07-09 16:56:02,692 [run_pretraining.py:  535]:	loss/mlm_loss, 2.9231603145599365, 397
[INFO] 2021-07-09 16:56:02,692 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.9599999581696466e-06, 397
[INFO] 2021-07-09 16:56:02,692 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 397
[INFO] 2021-07-09 16:56:02,692 [run_pretraining.py:  558]:	worker_index: 4, step: 397, cost: 2.923160, mlm loss: 2.923160, speed: 0.428886 steps/s, speed: 3.431092 samples/s, speed: 1756.718881 tokens/s, learning rate: 3.960e-06, loss_scalings: 377.789520, pp_loss: 2.976317
[INFO] 2021-07-09 16:56:02,693 [run_pretraining.py:  512]:	********exe.run_397******* 
[INFO] 2021-07-09 16:56:04,973 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:04,974 [run_pretraining.py:  534]:	loss/total_loss, 2.986721992492676, 398
[INFO] 2021-07-09 16:56:04,974 [run_pretraining.py:  535]:	loss/mlm_loss, 2.986721992492676, 398
[INFO] 2021-07-09 16:56:04,974 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.96999985241564e-06, 398
[INFO] 2021-07-09 16:56:04,974 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 398
[INFO] 2021-07-09 16:56:04,974 [run_pretraining.py:  558]:	worker_index: 4, step: 398, cost: 2.986722, mlm loss: 2.986722, speed: 0.438412 steps/s, speed: 3.507294 samples/s, speed: 1795.734501 tokens/s, learning rate: 3.970e-06, loss_scalings: 377.789520, pp_loss: 2.993951
[INFO] 2021-07-09 16:56:04,974 [run_pretraining.py:  512]:	********exe.run_398******* 
[INFO] 2021-07-09 16:56:07,291 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:07,292 [run_pretraining.py:  534]:	loss/total_loss, 3.0552539825439453, 399
[INFO] 2021-07-09 16:56:07,292 [run_pretraining.py:  535]:	loss/mlm_loss, 3.0552539825439453, 399
[INFO] 2021-07-09 16:56:07,292 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.979999746661633e-06, 399
[INFO] 2021-07-09 16:56:07,292 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 399
[INFO] 2021-07-09 16:56:07,292 [run_pretraining.py:  558]:	worker_index: 4, step: 399, cost: 3.055254, mlm loss: 3.055254, speed: 0.431493 steps/s, speed: 3.451943 samples/s, speed: 1767.394793 tokens/s, learning rate: 3.980e-06, loss_scalings: 377.789520, pp_loss: 3.084927
[INFO] 2021-07-09 16:56:07,292 [run_pretraining.py:  512]:	********exe.run_399******* 
[INFO] 2021-07-09 16:56:09,523 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:09,524 [run_pretraining.py:  534]:	loss/total_loss, 3.2055740356445312, 400
[INFO] 2021-07-09 16:56:09,524 [run_pretraining.py:  535]:	loss/mlm_loss, 3.2055740356445312, 400
[INFO] 2021-07-09 16:56:09,524 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.9900000956549775e-06, 400
[INFO] 2021-07-09 16:56:09,524 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 400
[INFO] 2021-07-09 16:56:09,524 [run_pretraining.py:  558]:	worker_index: 4, step: 400, cost: 3.205574, mlm loss: 3.205574, speed: 0.448221 steps/s, speed: 3.585767 samples/s, speed: 1835.912734 tokens/s, learning rate: 3.990e-06, loss_scalings: 377.789520, pp_loss: 3.187950
[INFO] 2021-07-09 16:56:09,524 [run_pretraining.py:  512]:	********exe.run_400******* 
[INFO] 2021-07-09 16:56:11,822 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:11,823 [run_pretraining.py:  534]:	loss/total_loss, 3.3446402549743652, 401
[INFO] 2021-07-09 16:56:11,823 [run_pretraining.py:  535]:	loss/mlm_loss, 3.3446402549743652, 401
[INFO] 2021-07-09 16:56:11,823 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.999999989900971e-06, 401
[INFO] 2021-07-09 16:56:11,823 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 401
[INFO] 2021-07-09 16:56:11,823 [run_pretraining.py:  558]:	worker_index: 4, step: 401, cost: 3.344640, mlm loss: 3.344640, speed: 0.435082 steps/s, speed: 3.480657 samples/s, speed: 1782.096596 tokens/s, learning rate: 4.000e-06, loss_scalings: 377.789520, pp_loss: 3.313331
[INFO] 2021-07-09 16:56:11,823 [run_pretraining.py:  512]:	********exe.run_401******* 
[INFO] 2021-07-09 16:56:14,080 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:14,080 [run_pretraining.py:  534]:	loss/total_loss, 3.740170478820801, 402
[INFO] 2021-07-09 16:56:14,080 [run_pretraining.py:  535]:	loss/mlm_loss, 3.740170478820801, 402
[INFO] 2021-07-09 16:56:14,080 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.009999884146964e-06, 402
[INFO] 2021-07-09 16:56:14,081 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 402
[INFO] 2021-07-09 16:56:14,081 [run_pretraining.py:  558]:	worker_index: 4, step: 402, cost: 3.740170, mlm loss: 3.740170, speed: 0.443089 steps/s, speed: 3.544715 samples/s, speed: 1814.893904 tokens/s, learning rate: 4.010e-06, loss_scalings: 377.789520, pp_loss: 3.584235
[INFO] 2021-07-09 16:56:14,081 [run_pretraining.py:  512]:	********exe.run_402******* 
[INFO] 2021-07-09 16:56:16,423 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:16,423 [run_pretraining.py:  534]:	loss/total_loss, 3.690418004989624, 403
[INFO] 2021-07-09 16:56:16,423 [run_pretraining.py:  535]:	loss/mlm_loss, 3.690418004989624, 403
[INFO] 2021-07-09 16:56:16,423 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.0199997783929575e-06, 403
[INFO] 2021-07-09 16:56:16,423 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 403
[INFO] 2021-07-09 16:56:16,424 [run_pretraining.py:  558]:	worker_index: 4, step: 403, cost: 3.690418, mlm loss: 3.690418, speed: 0.426934 steps/s, speed: 3.415473 samples/s, speed: 1748.722286 tokens/s, learning rate: 4.020e-06, loss_scalings: 377.789520, pp_loss: 3.690881
[INFO] 2021-07-09 16:56:16,424 [run_pretraining.py:  512]:	********exe.run_403******* 
[INFO] 2021-07-09 16:56:18,722 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:18,723 [run_pretraining.py:  534]:	loss/total_loss, 3.8466341495513916, 404
[INFO] 2021-07-09 16:56:18,723 [run_pretraining.py:  535]:	loss/mlm_loss, 3.8466341495513916, 404
[INFO] 2021-07-09 16:56:18,723 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.030000127386302e-06, 404
[INFO] 2021-07-09 16:56:18,723 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 404
[INFO] 2021-07-09 16:56:18,723 [run_pretraining.py:  558]:	worker_index: 4, step: 404, cost: 3.846634, mlm loss: 3.846634, speed: 0.435020 steps/s, speed: 3.480157 samples/s, speed: 1781.840417 tokens/s, learning rate: 4.030e-06, loss_scalings: 377.789520, pp_loss: 3.814049
[INFO] 2021-07-09 16:56:18,723 [run_pretraining.py:  512]:	********exe.run_404******* 
[INFO] 2021-07-09 16:56:21,008 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:21,008 [run_pretraining.py:  534]:	loss/total_loss, 3.8210232257843018, 405
[INFO] 2021-07-09 16:56:21,008 [run_pretraining.py:  535]:	loss/mlm_loss, 3.8210232257843018, 405
[INFO] 2021-07-09 16:56:21,008 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.039999566884944e-06, 405
[INFO] 2021-07-09 16:56:21,009 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 405
[INFO] 2021-07-09 16:56:21,009 [run_pretraining.py:  558]:	worker_index: 4, step: 405, cost: 3.821023, mlm loss: 3.821023, speed: 0.437618 steps/s, speed: 3.500947 samples/s, speed: 1792.485109 tokens/s, learning rate: 4.040e-06, loss_scalings: 377.789520, pp_loss: 3.881337
[INFO] 2021-07-09 16:56:21,009 [run_pretraining.py:  512]:	********exe.run_405******* 
[INFO] 2021-07-09 16:56:23,275 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:23,276 [run_pretraining.py:  534]:	loss/total_loss, 3.8353562355041504, 406
[INFO] 2021-07-09 16:56:23,276 [run_pretraining.py:  535]:	loss/mlm_loss, 3.8353562355041504, 406
[INFO] 2021-07-09 16:56:23,276 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.0499999158782884e-06, 406
[INFO] 2021-07-09 16:56:23,276 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 406
[INFO] 2021-07-09 16:56:23,277 [run_pretraining.py:  558]:	worker_index: 4, step: 406, cost: 3.835356, mlm loss: 3.835356, speed: 0.441088 steps/s, speed: 3.528704 samples/s, speed: 1806.696246 tokens/s, learning rate: 4.050e-06, loss_scalings: 377.789520, pp_loss: 3.859689
[INFO] 2021-07-09 16:56:23,277 [run_pretraining.py:  512]:	********exe.run_406******* 
[INFO] 2021-07-09 16:56:25,509 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:25,510 [run_pretraining.py:  534]:	loss/total_loss, 3.811251401901245, 407
[INFO] 2021-07-09 16:56:25,510 [run_pretraining.py:  535]:	loss/mlm_loss, 3.811251401901245, 407
[INFO] 2021-07-09 16:56:25,510 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.060000264871633e-06, 407
[INFO] 2021-07-09 16:56:25,510 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 407
[INFO] 2021-07-09 16:56:25,510 [run_pretraining.py:  558]:	worker_index: 4, step: 407, cost: 3.811251, mlm loss: 3.811251, speed: 0.447806 steps/s, speed: 3.582452 samples/s, speed: 1834.215271 tokens/s, learning rate: 4.060e-06, loss_scalings: 377.789520, pp_loss: 3.722799
[INFO] 2021-07-09 16:56:25,510 [run_pretraining.py:  512]:	********exe.run_407******* 
[INFO] 2021-07-09 16:56:27,773 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:27,774 [run_pretraining.py:  534]:	loss/total_loss, 3.477747678756714, 408
[INFO] 2021-07-09 16:56:27,774 [run_pretraining.py:  535]:	loss/mlm_loss, 3.477747678756714, 408
[INFO] 2021-07-09 16:56:27,774 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.069999704370275e-06, 408
[INFO] 2021-07-09 16:56:27,774 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 408
[INFO] 2021-07-09 16:56:27,774 [run_pretraining.py:  558]:	worker_index: 4, step: 408, cost: 3.477748, mlm loss: 3.477748, speed: 0.441895 steps/s, speed: 3.535163 samples/s, speed: 1810.003324 tokens/s, learning rate: 4.070e-06, loss_scalings: 377.789520, pp_loss: 3.513698
[INFO] 2021-07-09 16:56:27,774 [run_pretraining.py:  512]:	********exe.run_408******* 
[INFO] 2021-07-09 16:56:30,064 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:30,064 [run_pretraining.py:  534]:	loss/total_loss, 3.3911471366882324, 409
[INFO] 2021-07-09 16:56:30,064 [run_pretraining.py:  535]:	loss/mlm_loss, 3.3911471366882324, 409
[INFO] 2021-07-09 16:56:30,064 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.080000053363619e-06, 409
[INFO] 2021-07-09 16:56:30,065 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 409
[INFO] 2021-07-09 16:56:30,065 [run_pretraining.py:  558]:	worker_index: 4, step: 409, cost: 3.391147, mlm loss: 3.391147, speed: 0.436695 steps/s, speed: 3.493557 samples/s, speed: 1788.701255 tokens/s, learning rate: 4.080e-06, loss_scalings: 377.789520, pp_loss: 3.414013
[INFO] 2021-07-09 16:56:30,065 [run_pretraining.py:  512]:	********exe.run_409******* 
[INFO] 2021-07-09 16:56:32,321 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:32,322 [run_pretraining.py:  534]:	loss/total_loss, 3.2522659301757812, 410
[INFO] 2021-07-09 16:56:32,322 [run_pretraining.py:  535]:	loss/mlm_loss, 3.2522659301757812, 410
[INFO] 2021-07-09 16:56:32,322 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.089999947609613e-06, 410
[INFO] 2021-07-09 16:56:32,322 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 410
[INFO] 2021-07-09 16:56:32,322 [run_pretraining.py:  558]:	worker_index: 4, step: 410, cost: 3.252266, mlm loss: 3.252266, speed: 0.443062 steps/s, speed: 3.544498 samples/s, speed: 1814.783093 tokens/s, learning rate: 4.090e-06, loss_scalings: 377.789520, pp_loss: 3.304897
[INFO] 2021-07-09 16:56:32,322 [run_pretraining.py:  512]:	********exe.run_410******* 
[INFO] 2021-07-09 16:56:34,584 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:34,584 [run_pretraining.py:  534]:	loss/total_loss, 3.2586288452148438, 411
[INFO] 2021-07-09 16:56:34,584 [run_pretraining.py:  535]:	loss/mlm_loss, 3.2586288452148438, 411
[INFO] 2021-07-09 16:56:34,585 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.099999841855606e-06, 411
[INFO] 2021-07-09 16:56:34,585 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 411
[INFO] 2021-07-09 16:56:34,585 [run_pretraining.py:  558]:	worker_index: 4, step: 411, cost: 3.258629, mlm loss: 3.258629, speed: 0.442119 steps/s, speed: 3.536952 samples/s, speed: 1810.919314 tokens/s, learning rate: 4.100e-06, loss_scalings: 377.789520, pp_loss: 3.180329
[INFO] 2021-07-09 16:56:34,585 [run_pretraining.py:  512]:	********exe.run_411******* 
[INFO] 2021-07-09 16:56:36,829 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:36,829 [run_pretraining.py:  534]:	loss/total_loss, 2.9048168659210205, 412
[INFO] 2021-07-09 16:56:36,829 [run_pretraining.py:  535]:	loss/mlm_loss, 2.9048168659210205, 412
[INFO] 2021-07-09 16:56:36,829 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.109999736101599e-06, 412
[INFO] 2021-07-09 16:56:36,829 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 412
[INFO] 2021-07-09 16:56:36,829 [run_pretraining.py:  558]:	worker_index: 4, step: 412, cost: 2.904817, mlm loss: 2.904817, speed: 0.445602 steps/s, speed: 3.564816 samples/s, speed: 1825.185929 tokens/s, learning rate: 4.110e-06, loss_scalings: 377.789520, pp_loss: 2.933264
[INFO] 2021-07-09 16:56:36,830 [run_pretraining.py:  512]:	********exe.run_412******* 
[INFO] 2021-07-09 16:56:39,135 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:39,136 [run_pretraining.py:  534]:	loss/total_loss, 2.7053210735321045, 413
[INFO] 2021-07-09 16:56:39,136 [run_pretraining.py:  535]:	loss/mlm_loss, 2.7053210735321045, 413
[INFO] 2021-07-09 16:56:39,136 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.120000085094944e-06, 413
[INFO] 2021-07-09 16:56:39,136 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 413
[INFO] 2021-07-09 16:56:39,136 [run_pretraining.py:  558]:	worker_index: 4, step: 413, cost: 2.705321, mlm loss: 2.705321, speed: 0.433686 steps/s, speed: 3.469485 samples/s, speed: 1776.376411 tokens/s, learning rate: 4.120e-06, loss_scalings: 377.789520, pp_loss: 2.765082
[INFO] 2021-07-09 16:56:39,136 [run_pretraining.py:  512]:	********exe.run_413******* 
[INFO] 2021-07-09 16:56:41,356 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:41,356 [run_pretraining.py:  534]:	loss/total_loss, 2.540100574493408, 414
[INFO] 2021-07-09 16:56:41,356 [run_pretraining.py:  535]:	loss/mlm_loss, 2.540100574493408, 414
[INFO] 2021-07-09 16:56:41,356 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.129999979340937e-06, 414
[INFO] 2021-07-09 16:56:41,356 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 414
[INFO] 2021-07-09 16:56:41,357 [run_pretraining.py:  558]:	worker_index: 4, step: 414, cost: 2.540101, mlm loss: 2.540101, speed: 0.450461 steps/s, speed: 3.603692 samples/s, speed: 1845.090201 tokens/s, learning rate: 4.130e-06, loss_scalings: 377.789520, pp_loss: 2.605084
[INFO] 2021-07-09 16:56:41,357 [run_pretraining.py:  512]:	********exe.run_414******* 
[INFO] 2021-07-09 16:56:43,591 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:43,592 [run_pretraining.py:  534]:	loss/total_loss, 2.403242826461792, 415
[INFO] 2021-07-09 16:56:43,592 [run_pretraining.py:  535]:	loss/mlm_loss, 2.403242826461792, 415
[INFO] 2021-07-09 16:56:43,592 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.13999987358693e-06, 415
[INFO] 2021-07-09 16:56:43,592 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 415
[INFO] 2021-07-09 16:56:43,592 [run_pretraining.py:  558]:	worker_index: 4, step: 415, cost: 2.403243, mlm loss: 2.403243, speed: 0.447439 steps/s, speed: 3.579510 samples/s, speed: 1832.709004 tokens/s, learning rate: 4.140e-06, loss_scalings: 377.789520, pp_loss: 2.402657
[INFO] 2021-07-09 16:56:43,592 [run_pretraining.py:  512]:	********exe.run_415******* 
[INFO] 2021-07-09 16:56:45,866 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:45,866 [run_pretraining.py:  534]:	loss/total_loss, 2.3251028060913086, 416
[INFO] 2021-07-09 16:56:45,866 [run_pretraining.py:  535]:	loss/mlm_loss, 2.3251028060913086, 416
[INFO] 2021-07-09 16:56:45,866 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.149999767832924e-06, 416
[INFO] 2021-07-09 16:56:45,867 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 416
[INFO] 2021-07-09 16:56:45,867 [run_pretraining.py:  558]:	worker_index: 4, step: 416, cost: 2.325103, mlm loss: 2.325103, speed: 0.439784 steps/s, speed: 3.518271 samples/s, speed: 1801.354506 tokens/s, learning rate: 4.150e-06, loss_scalings: 377.789520, pp_loss: 2.366363
[INFO] 2021-07-09 16:56:45,867 [run_pretraining.py:  512]:	********exe.run_416******* 
[INFO] 2021-07-09 16:56:48,185 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:48,186 [run_pretraining.py:  534]:	loss/total_loss, 2.383021831512451, 417
[INFO] 2021-07-09 16:56:48,186 [run_pretraining.py:  535]:	loss/mlm_loss, 2.383021831512451, 417
[INFO] 2021-07-09 16:56:48,186 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.160000116826268e-06, 417
[INFO] 2021-07-09 16:56:48,186 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 417
[INFO] 2021-07-09 16:56:48,186 [run_pretraining.py:  558]:	worker_index: 4, step: 417, cost: 2.383022, mlm loss: 2.383022, speed: 0.431193 steps/s, speed: 3.449546 samples/s, speed: 1766.167618 tokens/s, learning rate: 4.160e-06, loss_scalings: 377.789520, pp_loss: 2.318346
[INFO] 2021-07-09 16:56:48,187 [run_pretraining.py:  512]:	********exe.run_417******* 
[INFO] 2021-07-09 16:56:50,495 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:50,496 [run_pretraining.py:  534]:	loss/total_loss, 2.2372026443481445, 418
[INFO] 2021-07-09 16:56:50,496 [run_pretraining.py:  535]:	loss/mlm_loss, 2.2372026443481445, 418
[INFO] 2021-07-09 16:56:50,496 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.170000011072261e-06, 418
[INFO] 2021-07-09 16:56:50,496 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 418
[INFO] 2021-07-09 16:56:50,496 [run_pretraining.py:  558]:	worker_index: 4, step: 418, cost: 2.237203, mlm loss: 2.237203, speed: 0.433071 steps/s, speed: 3.464564 samples/s, speed: 1773.856846 tokens/s, learning rate: 4.170e-06, loss_scalings: 377.789520, pp_loss: 2.250481
[INFO] 2021-07-09 16:56:50,496 [run_pretraining.py:  512]:	********exe.run_418******* 
[INFO] 2021-07-09 16:56:52,796 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:52,796 [run_pretraining.py:  534]:	loss/total_loss, 2.2375926971435547, 419
[INFO] 2021-07-09 16:56:52,796 [run_pretraining.py:  535]:	loss/mlm_loss, 2.2375926971435547, 419
[INFO] 2021-07-09 16:56:52,796 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.179999905318255e-06, 419
[INFO] 2021-07-09 16:56:52,797 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 419
[INFO] 2021-07-09 16:56:52,797 [run_pretraining.py:  558]:	worker_index: 4, step: 419, cost: 2.237593, mlm loss: 2.237593, speed: 0.434841 steps/s, speed: 3.478726 samples/s, speed: 1781.107775 tokens/s, learning rate: 4.180e-06, loss_scalings: 377.789520, pp_loss: 2.232329
[INFO] 2021-07-09 16:56:52,797 [run_pretraining.py:  512]:	********exe.run_419******* 
[INFO] 2021-07-09 16:56:55,126 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:55,127 [run_pretraining.py:  534]:	loss/total_loss, 2.1938788890838623, 420
[INFO] 2021-07-09 16:56:55,127 [run_pretraining.py:  535]:	loss/mlm_loss, 2.1938788890838623, 420
[INFO] 2021-07-09 16:56:55,127 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.190000254311599e-06, 420
[INFO] 2021-07-09 16:56:55,127 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 420
[INFO] 2021-07-09 16:56:55,127 [run_pretraining.py:  558]:	worker_index: 4, step: 420, cost: 2.193879, mlm loss: 2.193879, speed: 0.429197 steps/s, speed: 3.433578 samples/s, speed: 1757.991779 tokens/s, learning rate: 4.190e-06, loss_scalings: 377.789520, pp_loss: 2.222769
[INFO] 2021-07-09 16:56:55,127 [run_pretraining.py:  512]:	********exe.run_420******* 
[INFO] 2021-07-09 16:56:57,441 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:57,442 [run_pretraining.py:  534]:	loss/total_loss, 2.213684558868408, 421
[INFO] 2021-07-09 16:56:57,442 [run_pretraining.py:  535]:	loss/mlm_loss, 2.213684558868408, 421
[INFO] 2021-07-09 16:56:57,442 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.199999693810241e-06, 421
[INFO] 2021-07-09 16:56:57,442 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 421
[INFO] 2021-07-09 16:56:57,442 [run_pretraining.py:  558]:	worker_index: 4, step: 421, cost: 2.213685, mlm loss: 2.213685, speed: 0.432044 steps/s, speed: 3.456350 samples/s, speed: 1769.650994 tokens/s, learning rate: 4.200e-06, loss_scalings: 377.789520, pp_loss: 2.228614
[INFO] 2021-07-09 16:56:57,443 [run_pretraining.py:  512]:	********exe.run_421******* 
[INFO] 2021-07-09 16:56:59,728 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:59,729 [run_pretraining.py:  534]:	loss/total_loss, 2.183481216430664, 422
[INFO] 2021-07-09 16:56:59,729 [run_pretraining.py:  535]:	loss/mlm_loss, 2.183481216430664, 422
[INFO] 2021-07-09 16:56:59,729 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.2100000428035855e-06, 422
[INFO] 2021-07-09 16:56:59,729 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 422
[INFO] 2021-07-09 16:56:59,729 [run_pretraining.py:  558]:	worker_index: 4, step: 422, cost: 2.183481, mlm loss: 2.183481, speed: 0.437482 steps/s, speed: 3.499857 samples/s, speed: 1791.926650 tokens/s, learning rate: 4.210e-06, loss_scalings: 377.789520, pp_loss: 2.233699
[INFO] 2021-07-09 16:56:59,729 [run_pretraining.py:  512]:	********exe.run_422******* 
[INFO] 2021-07-09 16:57:02,030 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:02,031 [run_pretraining.py:  534]:	loss/total_loss, 2.1017909049987793, 423
[INFO] 2021-07-09 16:57:02,031 [run_pretraining.py:  535]:	loss/mlm_loss, 2.1017909049987793, 423
[INFO] 2021-07-09 16:57:02,031 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.219999937049579e-06, 423
[INFO] 2021-07-09 16:57:02,031 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 423
[INFO] 2021-07-09 16:57:02,031 [run_pretraining.py:  558]:	worker_index: 4, step: 423, cost: 2.101791, mlm loss: 2.101791, speed: 0.434477 steps/s, speed: 3.475813 samples/s, speed: 1779.616460 tokens/s, learning rate: 4.220e-06, loss_scalings: 377.789520, pp_loss: 2.129158
[INFO] 2021-07-09 16:57:02,031 [run_pretraining.py:  512]:	********exe.run_423******* 
[INFO] 2021-07-09 16:57:04,316 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:04,317 [run_pretraining.py:  534]:	loss/total_loss, 2.0542869567871094, 424
[INFO] 2021-07-09 16:57:04,317 [run_pretraining.py:  535]:	loss/mlm_loss, 2.0542869567871094, 424
[INFO] 2021-07-09 16:57:04,317 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.229999831295572e-06, 424
[INFO] 2021-07-09 16:57:04,317 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 424
[INFO] 2021-07-09 16:57:04,317 [run_pretraining.py:  558]:	worker_index: 4, step: 424, cost: 2.054287, mlm loss: 2.054287, speed: 0.437654 steps/s, speed: 3.501231 samples/s, speed: 1792.630436 tokens/s, learning rate: 4.230e-06, loss_scalings: 377.789520, pp_loss: 2.079449
[INFO] 2021-07-09 16:57:04,317 [run_pretraining.py:  512]:	********exe.run_424******* 
[INFO] 2021-07-09 16:57:06,552 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:06,553 [run_pretraining.py:  534]:	loss/total_loss, 1.9758002758026123, 425
[INFO] 2021-07-09 16:57:06,553 [run_pretraining.py:  535]:	loss/mlm_loss, 1.9758002758026123, 425
[INFO] 2021-07-09 16:57:06,553 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.2399997255415656e-06, 425
[INFO] 2021-07-09 16:57:06,553 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 425
[INFO] 2021-07-09 16:57:06,553 [run_pretraining.py:  558]:	worker_index: 4, step: 425, cost: 1.975800, mlm loss: 1.975800, speed: 0.447285 steps/s, speed: 3.578283 samples/s, speed: 1832.080853 tokens/s, learning rate: 4.240e-06, loss_scalings: 377.789520, pp_loss: 2.001159
[INFO] 2021-07-09 16:57:06,553 [run_pretraining.py:  512]:	********exe.run_425******* 
[INFO] 2021-07-09 16:57:08,820 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:08,820 [run_pretraining.py:  534]:	loss/total_loss, 1.9388465881347656, 426
[INFO] 2021-07-09 16:57:08,820 [run_pretraining.py:  535]:	loss/mlm_loss, 1.9388465881347656, 426
[INFO] 2021-07-09 16:57:08,820 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.25000007453491e-06, 426
[INFO] 2021-07-09 16:57:08,820 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 426
[INFO] 2021-07-09 16:57:08,820 [run_pretraining.py:  558]:	worker_index: 4, step: 426, cost: 1.938847, mlm loss: 1.938847, speed: 0.441213 steps/s, speed: 3.529704 samples/s, speed: 1807.208628 tokens/s, learning rate: 4.250e-06, loss_scalings: 377.789520, pp_loss: 1.944149
[INFO] 2021-07-09 16:57:08,821 [run_pretraining.py:  512]:	********exe.run_426******* 
[INFO] 2021-07-09 16:57:11,203 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:11,204 [run_pretraining.py:  534]:	loss/total_loss, 1.8799864053726196, 427
[INFO] 2021-07-09 16:57:11,204 [run_pretraining.py:  535]:	loss/mlm_loss, 1.8799864053726196, 427
[INFO] 2021-07-09 16:57:11,204 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.259999514033552e-06, 427
[INFO] 2021-07-09 16:57:11,204 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 427
[INFO] 2021-07-09 16:57:11,204 [run_pretraining.py:  558]:	worker_index: 4, step: 427, cost: 1.879986, mlm loss: 1.879986, speed: 0.419667 steps/s, speed: 3.357338 samples/s, speed: 1718.956926 tokens/s, learning rate: 4.260e-06, loss_scalings: 377.789520, pp_loss: 1.899035
[INFO] 2021-07-09 16:57:11,204 [run_pretraining.py:  512]:	********exe.run_427******* 
[INFO] 2021-07-09 16:57:13,477 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:13,477 [run_pretraining.py:  534]:	loss/total_loss, 1.8436156511306763, 428
[INFO] 2021-07-09 16:57:13,478 [run_pretraining.py:  535]:	loss/mlm_loss, 1.8436156511306763, 428
[INFO] 2021-07-09 16:57:13,478 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.2699998630268965e-06, 428
[INFO] 2021-07-09 16:57:13,478 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 428
[INFO] 2021-07-09 16:57:13,478 [run_pretraining.py:  558]:	worker_index: 4, step: 428, cost: 1.843616, mlm loss: 1.843616, speed: 0.439904 steps/s, speed: 3.519228 samples/s, speed: 1801.844774 tokens/s, learning rate: 4.270e-06, loss_scalings: 377.789520, pp_loss: 1.892594
[INFO] 2021-07-09 16:57:13,478 [run_pretraining.py:  512]:	********exe.run_428******* 
[INFO] 2021-07-09 16:57:15,735 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:15,736 [run_pretraining.py:  534]:	loss/total_loss, 1.798003911972046, 429
[INFO] 2021-07-09 16:57:15,736 [run_pretraining.py:  535]:	loss/mlm_loss, 1.798003911972046, 429
[INFO] 2021-07-09 16:57:15,736 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.280000212020241e-06, 429
[INFO] 2021-07-09 16:57:15,736 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 429
[INFO] 2021-07-09 16:57:15,736 [run_pretraining.py:  558]:	worker_index: 4, step: 429, cost: 1.798004, mlm loss: 1.798004, speed: 0.442927 steps/s, speed: 3.543416 samples/s, speed: 1814.229240 tokens/s, learning rate: 4.280e-06, loss_scalings: 377.789520, pp_loss: 1.811048
[INFO] 2021-07-09 16:57:15,736 [run_pretraining.py:  512]:	********exe.run_429******* 
[INFO] 2021-07-09 16:57:17,959 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:17,960 [run_pretraining.py:  534]:	loss/total_loss, 1.751562476158142, 430
[INFO] 2021-07-09 16:57:17,960 [run_pretraining.py:  535]:	loss/mlm_loss, 1.751562476158142, 430
[INFO] 2021-07-09 16:57:17,960 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.289999651518883e-06, 430
[INFO] 2021-07-09 16:57:17,960 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 430
[INFO] 2021-07-09 16:57:17,960 [run_pretraining.py:  558]:	worker_index: 4, step: 430, cost: 1.751562, mlm loss: 1.751562, speed: 0.449830 steps/s, speed: 3.598637 samples/s, speed: 1842.502303 tokens/s, learning rate: 4.290e-06, loss_scalings: 377.789520, pp_loss: 1.785755
[INFO] 2021-07-09 16:57:17,960 [run_pretraining.py:  512]:	********exe.run_430******* 
[INFO] 2021-07-09 16:57:20,188 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:20,188 [run_pretraining.py:  534]:	loss/total_loss, 1.765929102897644, 431
[INFO] 2021-07-09 16:57:20,189 [run_pretraining.py:  535]:	loss/mlm_loss, 1.765929102897644, 431
[INFO] 2021-07-09 16:57:20,189 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.300000000512227e-06, 431
[INFO] 2021-07-09 16:57:20,189 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 431
[INFO] 2021-07-09 16:57:20,189 [run_pretraining.py:  558]:	worker_index: 4, step: 431, cost: 1.765929, mlm loss: 1.765929, speed: 0.448793 steps/s, speed: 3.590347 samples/s, speed: 1838.257882 tokens/s, learning rate: 4.300e-06, loss_scalings: 377.789520, pp_loss: 1.789199
[INFO] 2021-07-09 16:57:20,189 [run_pretraining.py:  512]:	********exe.run_431******* 
[INFO] 2021-07-09 16:57:22,443 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:22,444 [run_pretraining.py:  534]:	loss/total_loss, 1.758022427558899, 432
[INFO] 2021-07-09 16:57:22,444 [run_pretraining.py:  535]:	loss/mlm_loss, 1.758022427558899, 432
[INFO] 2021-07-09 16:57:22,444 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.309999894758221e-06, 432
[INFO] 2021-07-09 16:57:22,444 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 432
[INFO] 2021-07-09 16:57:22,444 [run_pretraining.py:  558]:	worker_index: 4, step: 432, cost: 1.758022, mlm loss: 1.758022, speed: 0.443500 steps/s, speed: 3.548000 samples/s, speed: 1816.575947 tokens/s, learning rate: 4.310e-06, loss_scalings: 377.789520, pp_loss: 1.800224
[INFO] 2021-07-09 16:57:22,444 [run_pretraining.py:  512]:	********exe.run_432******* 
[INFO] 2021-07-09 16:57:24,868 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:24,869 [run_pretraining.py:  534]:	loss/total_loss, 1.7373946905136108, 433
[INFO] 2021-07-09 16:57:24,869 [run_pretraining.py:  535]:	loss/mlm_loss, 1.7373946905136108, 433
[INFO] 2021-07-09 16:57:24,869 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.319999789004214e-06, 433
[INFO] 2021-07-09 16:57:24,869 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 433
[INFO] 2021-07-09 16:57:24,869 [run_pretraining.py:  558]:	worker_index: 4, step: 433, cost: 1.737395, mlm loss: 1.737395, speed: 0.412455 steps/s, speed: 3.299641 samples/s, speed: 1689.416188 tokens/s, learning rate: 4.320e-06, loss_scalings: 377.789520, pp_loss: 1.760244
[INFO] 2021-07-09 16:57:24,869 [run_pretraining.py:  512]:	********exe.run_433******* 
[INFO] 2021-07-09 16:57:27,222 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:27,223 [run_pretraining.py:  534]:	loss/total_loss, 1.8264647722244263, 434
[INFO] 2021-07-09 16:57:27,223 [run_pretraining.py:  535]:	loss/mlm_loss, 1.8264647722244263, 434
[INFO] 2021-07-09 16:57:27,223 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.3299996832502075e-06, 434
[INFO] 2021-07-09 16:57:27,223 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 434
[INFO] 2021-07-09 16:57:27,223 [run_pretraining.py:  558]:	worker_index: 4, step: 434, cost: 1.826465, mlm loss: 1.826465, speed: 0.424971 steps/s, speed: 3.399769 samples/s, speed: 1740.681753 tokens/s, learning rate: 4.330e-06, loss_scalings: 377.789520, pp_loss: 1.753598
[INFO] 2021-07-09 16:57:27,223 [run_pretraining.py:  512]:	********exe.run_434******* 
[INFO] 2021-07-09 16:57:29,592 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:29,593 [run_pretraining.py:  534]:	loss/total_loss, 1.6774704456329346, 435
[INFO] 2021-07-09 16:57:29,593 [run_pretraining.py:  535]:	loss/mlm_loss, 1.6774704456329346, 435
[INFO] 2021-07-09 16:57:29,593 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.340000032243552e-06, 435
[INFO] 2021-07-09 16:57:29,593 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 435
[INFO] 2021-07-09 16:57:29,593 [run_pretraining.py:  558]:	worker_index: 4, step: 435, cost: 1.677470, mlm loss: 1.677470, speed: 0.422091 steps/s, speed: 3.376726 samples/s, speed: 1728.883901 tokens/s, learning rate: 4.340e-06, loss_scalings: 377.789520, pp_loss: 1.714699
[INFO] 2021-07-09 16:57:29,593 [run_pretraining.py:  512]:	********exe.run_435******* 
[INFO] 2021-07-09 16:57:32,066 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:32,067 [run_pretraining.py:  534]:	loss/total_loss, 1.666710615158081, 436
[INFO] 2021-07-09 16:57:32,067 [run_pretraining.py:  535]:	loss/mlm_loss, 1.666710615158081, 436
[INFO] 2021-07-09 16:57:32,067 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.349999926489545e-06, 436
[INFO] 2021-07-09 16:57:32,067 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 436
[INFO] 2021-07-09 16:57:32,067 [run_pretraining.py:  558]:	worker_index: 4, step: 436, cost: 1.666711, mlm loss: 1.666711, speed: 0.404265 steps/s, speed: 3.234121 samples/s, speed: 1655.869938 tokens/s, learning rate: 4.350e-06, loss_scalings: 377.789520, pp_loss: 1.686421
[INFO] 2021-07-09 16:57:32,067 [run_pretraining.py:  512]:	********exe.run_436******* 
[INFO] 2021-07-09 16:57:34,458 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:34,459 [run_pretraining.py:  534]:	loss/total_loss, 1.6484355926513672, 437
[INFO] 2021-07-09 16:57:34,459 [run_pretraining.py:  535]:	loss/mlm_loss, 1.6484355926513672, 437
[INFO] 2021-07-09 16:57:34,459 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.359999820735538e-06, 437
[INFO] 2021-07-09 16:57:34,459 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 437
[INFO] 2021-07-09 16:57:34,459 [run_pretraining.py:  558]:	worker_index: 4, step: 437, cost: 1.648436, mlm loss: 1.648436, speed: 0.418163 steps/s, speed: 3.345305 samples/s, speed: 1712.796118 tokens/s, learning rate: 4.360e-06, loss_scalings: 377.789520, pp_loss: 1.640620
[INFO] 2021-07-09 16:57:34,460 [run_pretraining.py:  512]:	********exe.run_437******* 
[INFO] 2021-07-09 16:57:36,881 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:36,881 [run_pretraining.py:  534]:	loss/total_loss, 1.598816156387329, 438
[INFO] 2021-07-09 16:57:36,881 [run_pretraining.py:  535]:	loss/mlm_loss, 1.598816156387329, 438
[INFO] 2021-07-09 16:57:36,881 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.369999714981532e-06, 438
[INFO] 2021-07-09 16:57:36,882 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 438
[INFO] 2021-07-09 16:57:36,882 [run_pretraining.py:  558]:	worker_index: 4, step: 438, cost: 1.598816, mlm loss: 1.598816, speed: 0.412962 steps/s, speed: 3.303697 samples/s, speed: 1691.492729 tokens/s, learning rate: 4.370e-06, loss_scalings: 377.789520, pp_loss: 1.593076
[INFO] 2021-07-09 16:57:36,882 [run_pretraining.py:  512]:	********exe.run_438******* 
[INFO] 2021-07-09 16:57:39,329 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:39,330 [run_pretraining.py:  534]:	loss/total_loss, 1.5604960918426514, 439
[INFO] 2021-07-09 16:57:39,330 [run_pretraining.py:  535]:	loss/mlm_loss, 1.5604960918426514, 439
[INFO] 2021-07-09 16:57:39,330 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.380000063974876e-06, 439
[INFO] 2021-07-09 16:57:39,330 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 439
[INFO] 2021-07-09 16:57:39,330 [run_pretraining.py:  558]:	worker_index: 4, step: 439, cost: 1.560496, mlm loss: 1.560496, speed: 0.408546 steps/s, speed: 3.268364 samples/s, speed: 1673.402620 tokens/s, learning rate: 4.380e-06, loss_scalings: 377.789520, pp_loss: 1.555433
[INFO] 2021-07-09 16:57:39,330 [run_pretraining.py:  512]:	********exe.run_439******* 
[INFO] 2021-07-09 16:57:41,988 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:41,988 [run_pretraining.py:  534]:	loss/total_loss, 1.5004111528396606, 440
[INFO] 2021-07-09 16:57:41,989 [run_pretraining.py:  535]:	loss/mlm_loss, 1.5004111528396606, 440
[INFO] 2021-07-09 16:57:41,989 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.389999958220869e-06, 440
[INFO] 2021-07-09 16:57:41,989 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 440
[INFO] 2021-07-09 16:57:41,989 [run_pretraining.py:  558]:	worker_index: 4, step: 440, cost: 1.500411, mlm loss: 1.500411, speed: 0.376200 steps/s, speed: 3.009604 samples/s, speed: 1540.917196 tokens/s, learning rate: 4.390e-06, loss_scalings: 377.789520, pp_loss: 1.512998
[INFO] 2021-07-09 16:57:41,989 [run_pretraining.py:  512]:	********exe.run_440******* 
[INFO] 2021-07-09 16:57:44,225 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:44,226 [run_pretraining.py:  534]:	loss/total_loss, 1.4407718181610107, 441
[INFO] 2021-07-09 16:57:44,226 [run_pretraining.py:  535]:	loss/mlm_loss, 1.4407718181610107, 441
[INFO] 2021-07-09 16:57:44,226 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.399999852466863e-06, 441
[INFO] 2021-07-09 16:57:44,226 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 441
[INFO] 2021-07-09 16:57:44,226 [run_pretraining.py:  558]:	worker_index: 4, step: 441, cost: 1.440772, mlm loss: 1.440772, speed: 0.447137 steps/s, speed: 3.577095 samples/s, speed: 1831.472461 tokens/s, learning rate: 4.400e-06, loss_scalings: 377.789520, pp_loss: 1.447932
[INFO] 2021-07-09 16:57:44,226 [run_pretraining.py:  512]:	********exe.run_441******* 
[INFO] 2021-07-09 16:57:46,508 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:46,508 [run_pretraining.py:  534]:	loss/total_loss, 1.4107356071472168, 442
[INFO] 2021-07-09 16:57:46,508 [run_pretraining.py:  535]:	loss/mlm_loss, 1.4107356071472168, 442
[INFO] 2021-07-09 16:57:46,508 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.410000201460207e-06, 442
[INFO] 2021-07-09 16:57:46,508 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 442
[INFO] 2021-07-09 16:57:46,508 [run_pretraining.py:  558]:	worker_index: 4, step: 442, cost: 1.410736, mlm loss: 1.410736, speed: 0.438266 steps/s, speed: 3.506127 samples/s, speed: 1795.137250 tokens/s, learning rate: 4.410e-06, loss_scalings: 377.789520, pp_loss: 1.412851
[INFO] 2021-07-09 16:57:46,508 [run_pretraining.py:  512]:	********exe.run_442******* 
[INFO] 2021-07-09 16:57:48,766 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:48,766 [run_pretraining.py:  534]:	loss/total_loss, 1.3843202590942383, 443
[INFO] 2021-07-09 16:57:48,766 [run_pretraining.py:  535]:	loss/mlm_loss, 1.3843202590942383, 443
[INFO] 2021-07-09 16:57:48,766 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.419999640958849e-06, 443
[INFO] 2021-07-09 16:57:48,767 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 443
[INFO] 2021-07-09 16:57:48,767 [run_pretraining.py:  558]:	worker_index: 4, step: 443, cost: 1.384320, mlm loss: 1.384320, speed: 0.442940 steps/s, speed: 3.543523 samples/s, speed: 1814.283843 tokens/s, learning rate: 4.420e-06, loss_scalings: 377.789520, pp_loss: 1.398071
[INFO] 2021-07-09 16:57:48,767 [run_pretraining.py:  512]:	********exe.run_443******* 
[INFO] 2021-07-09 16:57:51,027 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:51,027 [run_pretraining.py:  534]:	loss/total_loss, 1.375196933746338, 444
[INFO] 2021-07-09 16:57:51,027 [run_pretraining.py:  535]:	loss/mlm_loss, 1.375196933746338, 444
[INFO] 2021-07-09 16:57:51,027 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.4299999899521936e-06, 444
[INFO] 2021-07-09 16:57:51,028 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 444
[INFO] 2021-07-09 16:57:51,028 [run_pretraining.py:  558]:	worker_index: 4, step: 444, cost: 1.375197, mlm loss: 1.375197, speed: 0.442415 steps/s, speed: 3.539321 samples/s, speed: 1812.132263 tokens/s, learning rate: 4.430e-06, loss_scalings: 377.789520, pp_loss: 1.376159
[INFO] 2021-07-09 16:57:51,028 [run_pretraining.py:  512]:	********exe.run_444******* 
[INFO] 2021-07-09 16:57:53,358 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:53,359 [run_pretraining.py:  534]:	loss/total_loss, 1.3484004735946655, 445
[INFO] 2021-07-09 16:57:53,359 [run_pretraining.py:  535]:	loss/mlm_loss, 1.3484004735946655, 445
[INFO] 2021-07-09 16:57:53,359 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.439999884198187e-06, 445
[INFO] 2021-07-09 16:57:53,359 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 445
[INFO] 2021-07-09 16:57:53,359 [run_pretraining.py:  558]:	worker_index: 4, step: 445, cost: 1.348400, mlm loss: 1.348400, speed: 0.429070 steps/s, speed: 3.432562 samples/s, speed: 1757.471683 tokens/s, learning rate: 4.440e-06, loss_scalings: 377.789520, pp_loss: 1.363969
[INFO] 2021-07-09 16:57:53,359 [run_pretraining.py:  512]:	********exe.run_445******* 
[INFO] 2021-07-09 16:57:55,659 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:55,659 [run_pretraining.py:  534]:	loss/total_loss, 1.3282172679901123, 446
[INFO] 2021-07-09 16:57:55,660 [run_pretraining.py:  535]:	loss/mlm_loss, 1.3282172679901123, 446
[INFO] 2021-07-09 16:57:55,660 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.44999977844418e-06, 446
[INFO] 2021-07-09 16:57:55,660 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 446
[INFO] 2021-07-09 16:57:55,660 [run_pretraining.py:  558]:	worker_index: 4, step: 446, cost: 1.328217, mlm loss: 1.328217, speed: 0.434763 steps/s, speed: 3.478100 samples/s, speed: 1780.787272 tokens/s, learning rate: 4.450e-06, loss_scalings: 377.789520, pp_loss: 1.361920
[INFO] 2021-07-09 16:57:55,660 [run_pretraining.py:  512]:	********exe.run_446******* 
[INFO] 2021-07-09 16:57:57,909 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:57,909 [run_pretraining.py:  534]:	loss/total_loss, 1.3087706565856934, 447
[INFO] 2021-07-09 16:57:57,909 [run_pretraining.py:  535]:	loss/mlm_loss, 1.3087706565856934, 447
[INFO] 2021-07-09 16:57:57,909 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.459999672690174e-06, 447
[INFO] 2021-07-09 16:57:57,909 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 447
[INFO] 2021-07-09 16:57:57,909 [run_pretraining.py:  558]:	worker_index: 4, step: 447, cost: 1.308771, mlm loss: 1.308771, speed: 0.444617 steps/s, speed: 3.556933 samples/s, speed: 1821.149579 tokens/s, learning rate: 4.460e-06, loss_scalings: 377.789520, pp_loss: 1.312624
[INFO] 2021-07-09 16:57:57,910 [run_pretraining.py:  512]:	********exe.run_447******* 
[INFO] 2021-07-09 16:58:00,167 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:00,168 [run_pretraining.py:  534]:	loss/total_loss, 1.2802060842514038, 448
[INFO] 2021-07-09 16:58:00,168 [run_pretraining.py:  535]:	loss/mlm_loss, 1.2802060842514038, 448
[INFO] 2021-07-09 16:58:00,168 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.470000021683518e-06, 448
[INFO] 2021-07-09 16:58:00,168 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 448
[INFO] 2021-07-09 16:58:00,168 [run_pretraining.py:  558]:	worker_index: 4, step: 448, cost: 1.280206, mlm loss: 1.280206, speed: 0.442851 steps/s, speed: 3.542804 samples/s, speed: 1813.915667 tokens/s, learning rate: 4.470e-06, loss_scalings: 377.789520, pp_loss: 1.290504
[INFO] 2021-07-09 16:58:00,168 [run_pretraining.py:  512]:	********exe.run_448******* 
[INFO] 2021-07-09 16:58:02,396 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:02,396 [run_pretraining.py:  534]:	loss/total_loss, 1.2273756265640259, 449
[INFO] 2021-07-09 16:58:02,397 [run_pretraining.py:  535]:	loss/mlm_loss, 1.2273756265640259, 449
[INFO] 2021-07-09 16:58:02,397 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.479999915929511e-06, 449
[INFO] 2021-07-09 16:58:02,397 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 449
[INFO] 2021-07-09 16:58:02,397 [run_pretraining.py:  558]:	worker_index: 4, step: 449, cost: 1.227376, mlm loss: 1.227376, speed: 0.448860 steps/s, speed: 3.590877 samples/s, speed: 1838.528770 tokens/s, learning rate: 4.480e-06, loss_scalings: 377.789520, pp_loss: 1.241381
[INFO] 2021-07-09 16:58:02,397 [run_pretraining.py:  512]:	********exe.run_449******* 
[INFO] 2021-07-09 16:58:04,703 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:04,703 [run_pretraining.py:  534]:	loss/total_loss, 1.1994609832763672, 450
[INFO] 2021-07-09 16:58:04,703 [run_pretraining.py:  535]:	loss/mlm_loss, 1.1994609832763672, 450
[INFO] 2021-07-09 16:58:04,704 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.4899998101755045e-06, 450
[INFO] 2021-07-09 16:58:04,704 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 450
[INFO] 2021-07-09 16:58:04,704 [run_pretraining.py:  558]:	worker_index: 4, step: 450, cost: 1.199461, mlm loss: 1.199461, speed: 0.433599 steps/s, speed: 3.468794 samples/s, speed: 1776.022540 tokens/s, learning rate: 4.490e-06, loss_scalings: 377.789520, pp_loss: 1.198729
[INFO] 2021-07-09 16:58:04,704 [run_pretraining.py:  512]:	********exe.run_450******* 
[INFO] 2021-07-09 16:58:06,961 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:06,962 [run_pretraining.py:  534]:	loss/total_loss, 1.1544830799102783, 451
[INFO] 2021-07-09 16:58:06,962 [run_pretraining.py:  535]:	loss/mlm_loss, 1.1544830799102783, 451
[INFO] 2021-07-09 16:58:06,962 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.500000159168849e-06, 451
[INFO] 2021-07-09 16:58:06,962 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 451
[INFO] 2021-07-09 16:58:06,962 [run_pretraining.py:  558]:	worker_index: 4, step: 451, cost: 1.154483, mlm loss: 1.154483, speed: 0.442858 steps/s, speed: 3.542862 samples/s, speed: 1813.945353 tokens/s, learning rate: 4.500e-06, loss_scalings: 377.789520, pp_loss: 1.144230
[INFO] 2021-07-09 16:58:06,962 [run_pretraining.py:  512]:	********exe.run_451******* 
[INFO] 2021-07-09 16:58:09,225 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:09,226 [run_pretraining.py:  534]:	loss/total_loss, 1.100847840309143, 452
[INFO] 2021-07-09 16:58:09,226 [run_pretraining.py:  535]:	loss/mlm_loss, 1.100847840309143, 452
[INFO] 2021-07-09 16:58:09,226 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.510000053414842e-06, 452
[INFO] 2021-07-09 16:58:09,226 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 452
[INFO] 2021-07-09 16:58:09,226 [run_pretraining.py:  558]:	worker_index: 4, step: 452, cost: 1.100848, mlm loss: 1.100848, speed: 0.441870 steps/s, speed: 3.534959 samples/s, speed: 1809.898830 tokens/s, learning rate: 4.510e-06, loss_scalings: 377.789520, pp_loss: 1.107433
[INFO] 2021-07-09 16:58:09,226 [run_pretraining.py:  512]:	********exe.run_452******* 
[INFO] 2021-07-09 16:58:11,455 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:11,456 [run_pretraining.py:  534]:	loss/total_loss, 1.0966404676437378, 453
[INFO] 2021-07-09 16:58:11,456 [run_pretraining.py:  535]:	loss/mlm_loss, 1.0966404676437378, 453
[INFO] 2021-07-09 16:58:11,456 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.5199999476608355e-06, 453
[INFO] 2021-07-09 16:58:11,456 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 453
[INFO] 2021-07-09 16:58:11,456 [run_pretraining.py:  558]:	worker_index: 4, step: 453, cost: 1.096640, mlm loss: 1.096640, speed: 0.448553 steps/s, speed: 3.588423 samples/s, speed: 1837.272575 tokens/s, learning rate: 4.520e-06, loss_scalings: 377.789520, pp_loss: 1.089563
[INFO] 2021-07-09 16:58:11,456 [run_pretraining.py:  512]:	********exe.run_453******* 
[INFO] 2021-07-09 16:58:13,702 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:13,703 [run_pretraining.py:  534]:	loss/total_loss, 1.061582088470459, 454
[INFO] 2021-07-09 16:58:13,703 [run_pretraining.py:  535]:	loss/mlm_loss, 1.061582088470459, 454
[INFO] 2021-07-09 16:58:13,703 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.529999841906829e-06, 454
[INFO] 2021-07-09 16:58:13,703 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 454
[INFO] 2021-07-09 16:58:13,703 [run_pretraining.py:  558]:	worker_index: 4, step: 454, cost: 1.061582, mlm loss: 1.061582, speed: 0.445151 steps/s, speed: 3.561206 samples/s, speed: 1823.337538 tokens/s, learning rate: 4.530e-06, loss_scalings: 377.789520, pp_loss: 1.057895
[INFO] 2021-07-09 16:58:13,703 [run_pretraining.py:  512]:	********exe.run_454******* 
[INFO] 2021-07-09 16:58:15,927 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:15,928 [run_pretraining.py:  534]:	loss/total_loss, 1.0674355030059814, 455
[INFO] 2021-07-09 16:58:15,928 [run_pretraining.py:  535]:	loss/mlm_loss, 1.0674355030059814, 455
[INFO] 2021-07-09 16:58:15,928 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.540000190900173e-06, 455
[INFO] 2021-07-09 16:58:15,928 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 455
[INFO] 2021-07-09 16:58:15,928 [run_pretraining.py:  558]:	worker_index: 4, step: 455, cost: 1.067436, mlm loss: 1.067436, speed: 0.449589 steps/s, speed: 3.596708 samples/s, speed: 1841.514614 tokens/s, learning rate: 4.540e-06, loss_scalings: 377.789520, pp_loss: 1.043465
[INFO] 2021-07-09 16:58:15,928 [run_pretraining.py:  512]:	********exe.run_455******* 
[INFO] 2021-07-09 16:58:18,177 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:18,177 [run_pretraining.py:  534]:	loss/total_loss, 1.0346893072128296, 456
[INFO] 2021-07-09 16:58:18,177 [run_pretraining.py:  535]:	loss/mlm_loss, 1.0346893072128296, 456
[INFO] 2021-07-09 16:58:18,177 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.5499996303988155e-06, 456
[INFO] 2021-07-09 16:58:18,177 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 456
[INFO] 2021-07-09 16:58:18,178 [run_pretraining.py:  558]:	worker_index: 4, step: 456, cost: 1.034689, mlm loss: 1.034689, speed: 0.444718 steps/s, speed: 3.557743 samples/s, speed: 1821.564346 tokens/s, learning rate: 4.550e-06, loss_scalings: 377.789520, pp_loss: 0.998404
[INFO] 2021-07-09 16:58:18,178 [run_pretraining.py:  512]:	********exe.run_456******* 
[INFO] 2021-07-09 16:58:20,411 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:20,411 [run_pretraining.py:  534]:	loss/total_loss, 0.9829800128936768, 457
[INFO] 2021-07-09 16:58:20,411 [run_pretraining.py:  535]:	loss/mlm_loss, 0.9829800128936768, 457
[INFO] 2021-07-09 16:58:20,412 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.55999997939216e-06, 457
[INFO] 2021-07-09 16:58:20,412 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 457
[INFO] 2021-07-09 16:58:20,412 [run_pretraining.py:  558]:	worker_index: 4, step: 457, cost: 0.982980, mlm loss: 0.982980, speed: 0.447737 steps/s, speed: 3.581895 samples/s, speed: 1833.930185 tokens/s, learning rate: 4.560e-06, loss_scalings: 377.789520, pp_loss: 0.981168
[INFO] 2021-07-09 16:58:20,412 [run_pretraining.py:  512]:	********exe.run_457******* 
[INFO] 2021-07-09 16:58:22,656 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:22,657 [run_pretraining.py:  534]:	loss/total_loss, 0.9810748100280762, 458
[INFO] 2021-07-09 16:58:22,657 [run_pretraining.py:  535]:	loss/mlm_loss, 0.9810748100280762, 458
[INFO] 2021-07-09 16:58:22,657 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.569999873638153e-06, 458
[INFO] 2021-07-09 16:58:22,657 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 458
[INFO] 2021-07-09 16:58:22,657 [run_pretraining.py:  558]:	worker_index: 4, step: 458, cost: 0.981075, mlm loss: 0.981075, speed: 0.445456 steps/s, speed: 3.563649 samples/s, speed: 1824.588114 tokens/s, learning rate: 4.570e-06, loss_scalings: 377.789520, pp_loss: 0.988529
[INFO] 2021-07-09 16:58:22,657 [run_pretraining.py:  512]:	********exe.run_458******* 
[INFO] 2021-07-09 16:58:24,925 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:24,925 [run_pretraining.py:  534]:	loss/total_loss, 1.0022664070129395, 459
[INFO] 2021-07-09 16:58:24,925 [run_pretraining.py:  535]:	loss/mlm_loss, 1.0022664070129395, 459
[INFO] 2021-07-09 16:58:24,925 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.579999767884146e-06, 459
[INFO] 2021-07-09 16:58:24,925 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 459
[INFO] 2021-07-09 16:58:24,925 [run_pretraining.py:  558]:	worker_index: 4, step: 459, cost: 1.002266, mlm loss: 1.002266, speed: 0.441035 steps/s, speed: 3.528279 samples/s, speed: 1806.478724 tokens/s, learning rate: 4.580e-06, loss_scalings: 377.789520, pp_loss: 1.007845
[INFO] 2021-07-09 16:58:24,925 [run_pretraining.py:  512]:	********exe.run_459******* 
[INFO] 2021-07-09 16:58:27,182 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:27,182 [run_pretraining.py:  534]:	loss/total_loss, 1.0108792781829834, 460
[INFO] 2021-07-09 16:58:27,182 [run_pretraining.py:  535]:	loss/mlm_loss, 1.0108792781829834, 460
[INFO] 2021-07-09 16:58:27,183 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.58999966213014e-06, 460
[INFO] 2021-07-09 16:58:27,183 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 460
[INFO] 2021-07-09 16:58:27,183 [run_pretraining.py:  558]:	worker_index: 4, step: 460, cost: 1.010879, mlm loss: 1.010879, speed: 0.443139 steps/s, speed: 3.545116 samples/s, speed: 1815.099267 tokens/s, learning rate: 4.590e-06, loss_scalings: 377.789520, pp_loss: 1.009423
[INFO] 2021-07-09 16:58:27,183 [run_pretraining.py:  512]:	********exe.run_460******* 
[INFO] 2021-07-09 16:58:29,415 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:29,416 [run_pretraining.py:  534]:	loss/total_loss, 1.0492229461669922, 461
[INFO] 2021-07-09 16:58:29,416 [run_pretraining.py:  535]:	loss/mlm_loss, 1.0492229461669922, 461
[INFO] 2021-07-09 16:58:29,416 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.600000011123484e-06, 461
[INFO] 2021-07-09 16:58:29,416 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 461
[INFO] 2021-07-09 16:58:29,416 [run_pretraining.py:  558]:	worker_index: 4, step: 461, cost: 1.049223, mlm loss: 1.049223, speed: 0.447880 steps/s, speed: 3.583042 samples/s, speed: 1834.517291 tokens/s, learning rate: 4.600e-06, loss_scalings: 377.789520, pp_loss: 1.047339
[INFO] 2021-07-09 16:58:29,416 [run_pretraining.py:  512]:	********exe.run_461******* 
[INFO] 2021-07-09 16:58:31,632 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:31,633 [run_pretraining.py:  534]:	loss/total_loss, 1.0650806427001953, 462
[INFO] 2021-07-09 16:58:31,633 [run_pretraining.py:  535]:	loss/mlm_loss, 1.0650806427001953, 462
[INFO] 2021-07-09 16:58:31,633 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.609999905369477e-06, 462
[INFO] 2021-07-09 16:58:31,633 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 462
[INFO] 2021-07-09 16:58:31,633 [run_pretraining.py:  558]:	worker_index: 4, step: 462, cost: 1.065081, mlm loss: 1.065081, speed: 0.451208 steps/s, speed: 3.609665 samples/s, speed: 1848.148506 tokens/s, learning rate: 4.610e-06, loss_scalings: 377.789520, pp_loss: 1.060471
[INFO] 2021-07-09 16:58:31,633 [run_pretraining.py:  512]:	********exe.run_462******* 
[INFO] 2021-07-09 16:58:33,843 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:33,843 [run_pretraining.py:  534]:	loss/total_loss, 1.0703709125518799, 463
[INFO] 2021-07-09 16:58:33,844 [run_pretraining.py:  535]:	loss/mlm_loss, 1.0703709125518799, 463
[INFO] 2021-07-09 16:58:33,844 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.619999799615471e-06, 463
[INFO] 2021-07-09 16:58:33,844 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 463
[INFO] 2021-07-09 16:58:33,844 [run_pretraining.py:  558]:	worker_index: 4, step: 463, cost: 1.070371, mlm loss: 1.070371, speed: 0.452478 steps/s, speed: 3.619820 samples/s, speed: 1853.348046 tokens/s, learning rate: 4.620e-06, loss_scalings: 377.789520, pp_loss: 1.070796
[INFO] 2021-07-09 16:58:33,844 [run_pretraining.py:  512]:	********exe.run_463******* 
[INFO] 2021-07-09 16:58:36,080 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:36,081 [run_pretraining.py:  534]:	loss/total_loss, 1.0703076124191284, 464
[INFO] 2021-07-09 16:58:36,081 [run_pretraining.py:  535]:	loss/mlm_loss, 1.0703076124191284, 464
[INFO] 2021-07-09 16:58:36,081 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.630000148608815e-06, 464
[INFO] 2021-07-09 16:58:36,081 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 464
[INFO] 2021-07-09 16:58:36,081 [run_pretraining.py:  558]:	worker_index: 4, step: 464, cost: 1.070308, mlm loss: 1.070308, speed: 0.447062 steps/s, speed: 3.576493 samples/s, speed: 1831.164220 tokens/s, learning rate: 4.630e-06, loss_scalings: 377.789520, pp_loss: 1.066587
[INFO] 2021-07-09 16:58:36,081 [run_pretraining.py:  512]:	********exe.run_464******* 
[INFO] 2021-07-09 16:58:38,309 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:38,309 [run_pretraining.py:  534]:	loss/total_loss, 1.0642945766448975, 465
[INFO] 2021-07-09 16:58:38,310 [run_pretraining.py:  535]:	loss/mlm_loss, 1.0642945766448975, 465
[INFO] 2021-07-09 16:58:38,310 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.640000042854808e-06, 465
[INFO] 2021-07-09 16:58:38,310 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 465
[INFO] 2021-07-09 16:58:38,310 [run_pretraining.py:  558]:	worker_index: 4, step: 465, cost: 1.064295, mlm loss: 1.064295, speed: 0.448845 steps/s, speed: 3.590761 samples/s, speed: 1838.469746 tokens/s, learning rate: 4.640e-06, loss_scalings: 377.789520, pp_loss: 1.060752
[INFO] 2021-07-09 16:58:38,310 [run_pretraining.py:  512]:	********exe.run_465******* 
[INFO] 2021-07-09 16:58:40,561 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:40,562 [run_pretraining.py:  534]:	loss/total_loss, 1.0646432638168335, 466
[INFO] 2021-07-09 16:58:40,562 [run_pretraining.py:  535]:	loss/mlm_loss, 1.0646432638168335, 466
[INFO] 2021-07-09 16:58:40,562 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.649999937100802e-06, 466
[INFO] 2021-07-09 16:58:40,562 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 466
[INFO] 2021-07-09 16:58:40,562 [run_pretraining.py:  558]:	worker_index: 4, step: 466, cost: 1.064643, mlm loss: 1.064643, speed: 0.444156 steps/s, speed: 3.553246 samples/s, speed: 1819.262150 tokens/s, learning rate: 4.650e-06, loss_scalings: 377.789520, pp_loss: 1.032697
[INFO] 2021-07-09 16:58:40,562 [run_pretraining.py:  512]:	********exe.run_466******* 
[INFO] 2021-07-09 16:58:42,756 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:42,757 [run_pretraining.py:  534]:	loss/total_loss, 0.9813600778579712, 467
[INFO] 2021-07-09 16:58:42,757 [run_pretraining.py:  535]:	loss/mlm_loss, 0.9813600778579712, 467
[INFO] 2021-07-09 16:58:42,757 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.659999831346795e-06, 467
[INFO] 2021-07-09 16:58:42,757 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 467
[INFO] 2021-07-09 16:58:42,757 [run_pretraining.py:  558]:	worker_index: 4, step: 467, cost: 0.981360, mlm loss: 0.981360, speed: 0.455680 steps/s, speed: 3.645438 samples/s, speed: 1866.464344 tokens/s, learning rate: 4.660e-06, loss_scalings: 377.789520, pp_loss: 0.995252
[INFO] 2021-07-09 16:58:42,757 [run_pretraining.py:  512]:	********exe.run_467******* 
[INFO] 2021-07-09 16:58:45,109 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:45,109 [run_pretraining.py:  534]:	loss/total_loss, 0.9789543747901917, 468
[INFO] 2021-07-09 16:58:45,109 [run_pretraining.py:  535]:	loss/mlm_loss, 0.9789543747901917, 468
[INFO] 2021-07-09 16:58:45,109 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.670000180340139e-06, 468
[INFO] 2021-07-09 16:58:45,110 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 468
[INFO] 2021-07-09 16:58:45,110 [run_pretraining.py:  558]:	worker_index: 4, step: 468, cost: 0.978954, mlm loss: 0.978954, speed: 0.425208 steps/s, speed: 3.401667 samples/s, speed: 1741.653552 tokens/s, learning rate: 4.670e-06, loss_scalings: 377.789520, pp_loss: 0.958923
[INFO] 2021-07-09 16:58:45,110 [run_pretraining.py:  512]:	********exe.run_468******* 
[INFO] 2021-07-09 16:58:47,313 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:47,313 [run_pretraining.py:  534]:	loss/total_loss, 0.9093641042709351, 469
[INFO] 2021-07-09 16:58:47,314 [run_pretraining.py:  535]:	loss/mlm_loss, 0.9093641042709351, 469
[INFO] 2021-07-09 16:58:47,314 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.679999619838782e-06, 469
[INFO] 2021-07-09 16:58:47,314 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 469
[INFO] 2021-07-09 16:58:47,314 [run_pretraining.py:  558]:	worker_index: 4, step: 469, cost: 0.909364, mlm loss: 0.909364, speed: 0.453788 steps/s, speed: 3.630306 samples/s, speed: 1858.716879 tokens/s, learning rate: 4.680e-06, loss_scalings: 377.789520, pp_loss: 0.909445
[INFO] 2021-07-09 16:58:47,314 [run_pretraining.py:  512]:	********exe.run_469******* 
[INFO] 2021-07-09 16:58:49,612 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:49,613 [run_pretraining.py:  534]:	loss/total_loss, 0.8805180191993713, 470
[INFO] 2021-07-09 16:58:49,613 [run_pretraining.py:  535]:	loss/mlm_loss, 0.8805180191993713, 470
[INFO] 2021-07-09 16:58:49,613 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.689999968832126e-06, 470
[INFO] 2021-07-09 16:58:49,613 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 470
[INFO] 2021-07-09 16:58:49,613 [run_pretraining.py:  558]:	worker_index: 4, step: 470, cost: 0.880518, mlm loss: 0.880518, speed: 0.435045 steps/s, speed: 3.480361 samples/s, speed: 1781.945024 tokens/s, learning rate: 4.690e-06, loss_scalings: 377.789520, pp_loss: 0.889269
[INFO] 2021-07-09 16:58:49,613 [run_pretraining.py:  512]:	********exe.run_470******* 
[INFO] 2021-07-09 16:58:51,952 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:51,952 [run_pretraining.py:  534]:	loss/total_loss, 0.8615865707397461, 471
[INFO] 2021-07-09 16:58:51,953 [run_pretraining.py:  535]:	loss/mlm_loss, 0.8615865707397461, 471
[INFO] 2021-07-09 16:58:51,953 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.699999863078119e-06, 471
[INFO] 2021-07-09 16:58:51,953 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 471
[INFO] 2021-07-09 16:58:51,953 [run_pretraining.py:  558]:	worker_index: 4, step: 471, cost: 0.861587, mlm loss: 0.861587, speed: 0.427520 steps/s, speed: 3.420162 samples/s, speed: 1751.123070 tokens/s, learning rate: 4.700e-06, loss_scalings: 377.789520, pp_loss: 0.871914
[INFO] 2021-07-09 16:58:51,953 [run_pretraining.py:  512]:	********exe.run_471******* 
[INFO] 2021-07-09 16:58:54,240 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:54,240 [run_pretraining.py:  534]:	loss/total_loss, 0.829508900642395, 472
[INFO] 2021-07-09 16:58:54,240 [run_pretraining.py:  535]:	loss/mlm_loss, 0.829508900642395, 472
[INFO] 2021-07-09 16:58:54,240 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.709999757324113e-06, 472
[INFO] 2021-07-09 16:58:54,241 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 472
[INFO] 2021-07-09 16:58:54,241 [run_pretraining.py:  558]:	worker_index: 4, step: 472, cost: 0.829509, mlm loss: 0.829509, speed: 0.437251 steps/s, speed: 3.498011 samples/s, speed: 1790.981410 tokens/s, learning rate: 4.710e-06, loss_scalings: 377.789520, pp_loss: 0.848227
[INFO] 2021-07-09 16:58:54,241 [run_pretraining.py:  512]:	********exe.run_472******* 
[INFO] 2021-07-09 16:58:56,817 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:56,817 [run_pretraining.py:  534]:	loss/total_loss, 0.8373160362243652, 473
[INFO] 2021-07-09 16:58:56,817 [run_pretraining.py:  535]:	loss/mlm_loss, 0.8373160362243652, 473
[INFO] 2021-07-09 16:58:56,817 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.720000106317457e-06, 473
[INFO] 2021-07-09 16:58:56,817 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 473
[INFO] 2021-07-09 16:58:56,817 [run_pretraining.py:  558]:	worker_index: 4, step: 473, cost: 0.837316, mlm loss: 0.837316, speed: 0.388183 steps/s, speed: 3.105467 samples/s, speed: 1589.999142 tokens/s, learning rate: 4.720e-06, loss_scalings: 377.789520, pp_loss: 0.837393
[INFO] 2021-07-09 16:58:56,817 [run_pretraining.py:  512]:	********exe.run_473******* 
[INFO] 2021-07-09 16:58:59,092 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:59,092 [run_pretraining.py:  534]:	loss/total_loss, 0.8639631271362305, 474
[INFO] 2021-07-09 16:58:59,092 [run_pretraining.py:  535]:	loss/mlm_loss, 0.8639631271362305, 474
[INFO] 2021-07-09 16:58:59,092 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.73000000056345e-06, 474
[INFO] 2021-07-09 16:58:59,093 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 474
[INFO] 2021-07-09 16:58:59,093 [run_pretraining.py:  558]:	worker_index: 4, step: 474, cost: 0.863963, mlm loss: 0.863963, speed: 0.439635 steps/s, speed: 3.517083 samples/s, speed: 1800.746716 tokens/s, learning rate: 4.730e-06, loss_scalings: 377.789520, pp_loss: 0.837774
[INFO] 2021-07-09 16:58:59,093 [run_pretraining.py:  512]:	********exe.run_474******* 
[INFO] 2021-07-09 16:59:01,444 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:01,444 [run_pretraining.py:  534]:	loss/total_loss, 0.870323121547699, 475
[INFO] 2021-07-09 16:59:01,445 [run_pretraining.py:  535]:	loss/mlm_loss, 0.870323121547699, 475
[INFO] 2021-07-09 16:59:01,445 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.7399998948094435e-06, 475
[INFO] 2021-07-09 16:59:01,445 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 475
[INFO] 2021-07-09 16:59:01,445 [run_pretraining.py:  558]:	worker_index: 4, step: 475, cost: 0.870323, mlm loss: 0.870323, speed: 0.425253 steps/s, speed: 3.402022 samples/s, speed: 1741.835256 tokens/s, learning rate: 4.740e-06, loss_scalings: 377.789520, pp_loss: 0.845201
[INFO] 2021-07-09 16:59:01,445 [run_pretraining.py:  512]:	********exe.run_475******* 
[INFO] 2021-07-09 16:59:03,911 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:03,912 [run_pretraining.py:  534]:	loss/total_loss, 0.8646169304847717, 476
[INFO] 2021-07-09 16:59:03,912 [run_pretraining.py:  535]:	loss/mlm_loss, 0.8646169304847717, 476
[INFO] 2021-07-09 16:59:03,912 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.749999789055437e-06, 476
[INFO] 2021-07-09 16:59:03,912 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 476
[INFO] 2021-07-09 16:59:03,912 [run_pretraining.py:  558]:	worker_index: 4, step: 476, cost: 0.864617, mlm loss: 0.864617, speed: 0.405379 steps/s, speed: 3.243030 samples/s, speed: 1660.431546 tokens/s, learning rate: 4.750e-06, loss_scalings: 377.789520, pp_loss: 0.872716
[INFO] 2021-07-09 16:59:03,912 [run_pretraining.py:  512]:	********exe.run_476******* 
[INFO] 2021-07-09 16:59:06,165 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:06,166 [run_pretraining.py:  534]:	loss/total_loss, 0.9074277877807617, 477
[INFO] 2021-07-09 16:59:06,166 [run_pretraining.py:  535]:	loss/mlm_loss, 0.9074277877807617, 477
[INFO] 2021-07-09 16:59:06,166 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.760000138048781e-06, 477
[INFO] 2021-07-09 16:59:06,166 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 477
[INFO] 2021-07-09 16:59:06,167 [run_pretraining.py:  558]:	worker_index: 4, step: 477, cost: 0.907428, mlm loss: 0.907428, speed: 0.443740 steps/s, speed: 3.549921 samples/s, speed: 1817.559556 tokens/s, learning rate: 4.760e-06, loss_scalings: 377.789520, pp_loss: 0.916398
[INFO] 2021-07-09 16:59:06,167 [run_pretraining.py:  512]:	********exe.run_477******* 
[INFO] 2021-07-09 16:59:08,403 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:08,404 [run_pretraining.py:  534]:	loss/total_loss, 0.9756966829299927, 478
[INFO] 2021-07-09 16:59:08,404 [run_pretraining.py:  535]:	loss/mlm_loss, 0.9756966829299927, 478
[INFO] 2021-07-09 16:59:08,404 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.7699995775474235e-06, 478
[INFO] 2021-07-09 16:59:08,404 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 478
[INFO] 2021-07-09 16:59:08,405 [run_pretraining.py:  558]:	worker_index: 4, step: 478, cost: 0.975697, mlm loss: 0.975697, speed: 0.446986 steps/s, speed: 3.575889 samples/s, speed: 1830.855108 tokens/s, learning rate: 4.770e-06, loss_scalings: 377.789520, pp_loss: 0.973311
[INFO] 2021-07-09 16:59:08,405 [run_pretraining.py:  512]:	********exe.run_478******* 
[INFO] 2021-07-09 16:59:10,660 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:10,661 [run_pretraining.py:  534]:	loss/total_loss, 1.0175920724868774, 479
[INFO] 2021-07-09 16:59:10,661 [run_pretraining.py:  535]:	loss/mlm_loss, 1.0175920724868774, 479
[INFO] 2021-07-09 16:59:10,661 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.779999926540768e-06, 479
[INFO] 2021-07-09 16:59:10,661 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 479
[INFO] 2021-07-09 16:59:10,661 [run_pretraining.py:  558]:	worker_index: 4, step: 479, cost: 1.017592, mlm loss: 1.017592, speed: 0.443319 steps/s, speed: 3.546553 samples/s, speed: 1815.835387 tokens/s, learning rate: 4.780e-06, loss_scalings: 377.789520, pp_loss: 1.020786
[INFO] 2021-07-09 16:59:10,661 [run_pretraining.py:  512]:	********exe.run_479******* 
[INFO] 2021-07-09 16:59:12,933 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:12,934 [run_pretraining.py:  534]:	loss/total_loss, 1.080541729927063, 480
[INFO] 2021-07-09 16:59:12,934 [run_pretraining.py:  535]:	loss/mlm_loss, 1.080541729927063, 480
[INFO] 2021-07-09 16:59:12,934 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.789999820786761e-06, 480
[INFO] 2021-07-09 16:59:12,934 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 480
[INFO] 2021-07-09 16:59:12,934 [run_pretraining.py:  558]:	worker_index: 4, step: 480, cost: 1.080542, mlm loss: 1.080542, speed: 0.440018 steps/s, speed: 3.520141 samples/s, speed: 1802.312431 tokens/s, learning rate: 4.790e-06, loss_scalings: 377.789520, pp_loss: 1.092787
[INFO] 2021-07-09 16:59:12,934 [run_pretraining.py:  512]:	********exe.run_480******* 
[INFO] 2021-07-09 16:59:15,139 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:15,140 [run_pretraining.py:  534]:	loss/total_loss, 1.127544641494751, 481
[INFO] 2021-07-09 16:59:15,140 [run_pretraining.py:  535]:	loss/mlm_loss, 1.127544641494751, 481
[INFO] 2021-07-09 16:59:15,140 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.7999997150327545e-06, 481
[INFO] 2021-07-09 16:59:15,140 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 481
[INFO] 2021-07-09 16:59:15,140 [run_pretraining.py:  558]:	worker_index: 4, step: 481, cost: 1.127545, mlm loss: 1.127545, speed: 0.453446 steps/s, speed: 3.627570 samples/s, speed: 1857.316085 tokens/s, learning rate: 4.800e-06, loss_scalings: 377.789520, pp_loss: 1.136869
[INFO] 2021-07-09 16:59:15,140 [run_pretraining.py:  512]:	********exe.run_481******* 
[INFO] 2021-07-09 16:59:17,340 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:17,340 [run_pretraining.py:  534]:	loss/total_loss, 1.1568162441253662, 482
[INFO] 2021-07-09 16:59:17,341 [run_pretraining.py:  535]:	loss/mlm_loss, 1.1568162441253662, 482
[INFO] 2021-07-09 16:59:17,341 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.809999609278748e-06, 482
[INFO] 2021-07-09 16:59:17,341 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 482
[INFO] 2021-07-09 16:59:17,341 [run_pretraining.py:  558]:	worker_index: 4, step: 482, cost: 1.156816, mlm loss: 1.156816, speed: 0.454594 steps/s, speed: 3.636752 samples/s, speed: 1862.017107 tokens/s, learning rate: 4.810e-06, loss_scalings: 377.789520, pp_loss: 1.158474
[INFO] 2021-07-09 16:59:17,341 [run_pretraining.py:  512]:	********exe.run_482******* 
[INFO] 2021-07-09 16:59:19,638 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:19,639 [run_pretraining.py:  534]:	loss/total_loss, 1.1909016370773315, 483
[INFO] 2021-07-09 16:59:19,639 [run_pretraining.py:  535]:	loss/mlm_loss, 1.1909016370773315, 483
[INFO] 2021-07-09 16:59:19,639 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.819999958272092e-06, 483
[INFO] 2021-07-09 16:59:19,639 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 483
[INFO] 2021-07-09 16:59:19,639 [run_pretraining.py:  558]:	worker_index: 4, step: 483, cost: 1.190902, mlm loss: 1.190902, speed: 0.435227 steps/s, speed: 3.481815 samples/s, speed: 1782.689084 tokens/s, learning rate: 4.820e-06, loss_scalings: 377.789520, pp_loss: 1.185103
[INFO] 2021-07-09 16:59:19,639 [run_pretraining.py:  512]:	********exe.run_483******* 
[INFO] 2021-07-09 16:59:22,027 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:22,027 [run_pretraining.py:  534]:	loss/total_loss, 1.1958378553390503, 484
[INFO] 2021-07-09 16:59:22,028 [run_pretraining.py:  535]:	loss/mlm_loss, 1.1958378553390503, 484
[INFO] 2021-07-09 16:59:22,028 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.829999852518085e-06, 484
[INFO] 2021-07-09 16:59:22,028 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 484
[INFO] 2021-07-09 16:59:22,028 [run_pretraining.py:  558]:	worker_index: 4, step: 484, cost: 1.195838, mlm loss: 1.195838, speed: 0.418772 steps/s, speed: 3.350173 samples/s, speed: 1715.288769 tokens/s, learning rate: 4.830e-06, loss_scalings: 377.789520, pp_loss: 1.214706
[INFO] 2021-07-09 16:59:22,028 [run_pretraining.py:  512]:	********exe.run_484******* 
[INFO] 2021-07-09 16:59:24,552 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:24,552 [run_pretraining.py:  534]:	loss/total_loss, 1.1931798458099365, 485
[INFO] 2021-07-09 16:59:24,552 [run_pretraining.py:  535]:	loss/mlm_loss, 1.1931798458099365, 485
[INFO] 2021-07-09 16:59:24,552 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.839999746764079e-06, 485
[INFO] 2021-07-09 16:59:24,552 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 485
[INFO] 2021-07-09 16:59:24,553 [run_pretraining.py:  558]:	worker_index: 4, step: 485, cost: 1.193180, mlm loss: 1.193180, speed: 0.396190 steps/s, speed: 3.169518 samples/s, speed: 1622.793219 tokens/s, learning rate: 4.840e-06, loss_scalings: 377.789520, pp_loss: 1.216004
[INFO] 2021-07-09 16:59:24,553 [run_pretraining.py:  512]:	********exe.run_485******* 
[INFO] 2021-07-09 16:59:26,788 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:26,789 [run_pretraining.py:  534]:	loss/total_loss, 1.2160747051239014, 486
[INFO] 2021-07-09 16:59:26,789 [run_pretraining.py:  535]:	loss/mlm_loss, 1.2160747051239014, 486
[INFO] 2021-07-09 16:59:26,789 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.850000095757423e-06, 486
[INFO] 2021-07-09 16:59:26,789 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 486
[INFO] 2021-07-09 16:59:26,789 [run_pretraining.py:  558]:	worker_index: 4, step: 486, cost: 1.216075, mlm loss: 1.216075, speed: 0.447268 steps/s, speed: 3.578144 samples/s, speed: 1832.009739 tokens/s, learning rate: 4.850e-06, loss_scalings: 377.789520, pp_loss: 1.215281
[INFO] 2021-07-09 16:59:26,789 [run_pretraining.py:  512]:	********exe.run_486******* 
[INFO] 2021-07-09 16:59:29,129 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:29,130 [run_pretraining.py:  534]:	loss/total_loss, 1.2659024000167847, 487
[INFO] 2021-07-09 16:59:29,130 [run_pretraining.py:  535]:	loss/mlm_loss, 1.2659024000167847, 487
[INFO] 2021-07-09 16:59:29,130 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.859999990003416e-06, 487
[INFO] 2021-07-09 16:59:29,130 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 487
[INFO] 2021-07-09 16:59:29,130 [run_pretraining.py:  558]:	worker_index: 4, step: 487, cost: 1.265902, mlm loss: 1.265902, speed: 0.427222 steps/s, speed: 3.417777 samples/s, speed: 1749.901981 tokens/s, learning rate: 4.860e-06, loss_scalings: 377.789520, pp_loss: 1.240887
[INFO] 2021-07-09 16:59:29,131 [run_pretraining.py:  512]:	********exe.run_487******* 
[INFO] 2021-07-09 16:59:31,363 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:31,364 [run_pretraining.py:  534]:	loss/total_loss, 1.1922303438186646, 488
[INFO] 2021-07-09 16:59:31,364 [run_pretraining.py:  535]:	loss/mlm_loss, 1.1922303438186646, 488
[INFO] 2021-07-09 16:59:31,364 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.86999988424941e-06, 488
[INFO] 2021-07-09 16:59:31,364 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 488
[INFO] 2021-07-09 16:59:31,364 [run_pretraining.py:  558]:	worker_index: 4, step: 488, cost: 1.192230, mlm loss: 1.192230, speed: 0.447846 steps/s, speed: 3.582766 samples/s, speed: 1834.376258 tokens/s, learning rate: 4.870e-06, loss_scalings: 377.789520, pp_loss: 1.197376
[INFO] 2021-07-09 16:59:31,364 [run_pretraining.py:  512]:	********exe.run_488******* 
[INFO] 2021-07-09 16:59:33,580 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:33,581 [run_pretraining.py:  534]:	loss/total_loss, 1.1817551851272583, 489
[INFO] 2021-07-09 16:59:33,581 [run_pretraining.py:  535]:	loss/mlm_loss, 1.1817551851272583, 489
[INFO] 2021-07-09 16:59:33,581 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.879999778495403e-06, 489
[INFO] 2021-07-09 16:59:33,581 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 489
[INFO] 2021-07-09 16:59:33,581 [run_pretraining.py:  558]:	worker_index: 4, step: 489, cost: 1.181755, mlm loss: 1.181755, speed: 0.451210 steps/s, speed: 3.609679 samples/s, speed: 1848.155862 tokens/s, learning rate: 4.880e-06, loss_scalings: 377.789520, pp_loss: 1.138057
[INFO] 2021-07-09 16:59:33,581 [run_pretraining.py:  512]:	********exe.run_489******* 
[INFO] 2021-07-09 16:59:35,774 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:35,774 [run_pretraining.py:  534]:	loss/total_loss, 1.0405049324035645, 490
[INFO] 2021-07-09 16:59:35,774 [run_pretraining.py:  535]:	loss/mlm_loss, 1.0405049324035645, 490
[INFO] 2021-07-09 16:59:35,774 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.890000127488747e-06, 490
[INFO] 2021-07-09 16:59:35,775 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 490
[INFO] 2021-07-09 16:59:35,775 [run_pretraining.py:  558]:	worker_index: 4, step: 490, cost: 1.040505, mlm loss: 1.040505, speed: 0.455991 steps/s, speed: 3.647929 samples/s, speed: 1867.739873 tokens/s, learning rate: 4.890e-06, loss_scalings: 377.789520, pp_loss: 1.062675
[INFO] 2021-07-09 16:59:35,775 [run_pretraining.py:  512]:	********exe.run_490******* 
[INFO] 2021-07-09 16:59:37,999 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:38,000 [run_pretraining.py:  534]:	loss/total_loss, 0.9768829345703125, 491
[INFO] 2021-07-09 16:59:38,000 [run_pretraining.py:  535]:	loss/mlm_loss, 0.9768829345703125, 491
[INFO] 2021-07-09 16:59:38,000 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.89999956698739e-06, 491
[INFO] 2021-07-09 16:59:38,000 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 491
[INFO] 2021-07-09 16:59:38,000 [run_pretraining.py:  558]:	worker_index: 4, step: 491, cost: 0.976883, mlm loss: 0.976883, speed: 0.449437 steps/s, speed: 3.595499 samples/s, speed: 1840.895602 tokens/s, learning rate: 4.900e-06, loss_scalings: 377.789520, pp_loss: 0.985884
[INFO] 2021-07-09 16:59:38,000 [run_pretraining.py:  512]:	********exe.run_491******* 
[INFO] 2021-07-09 16:59:40,290 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:40,290 [run_pretraining.py:  534]:	loss/total_loss, 0.9067502021789551, 492
[INFO] 2021-07-09 16:59:40,290 [run_pretraining.py:  535]:	loss/mlm_loss, 0.9067502021789551, 492
[INFO] 2021-07-09 16:59:40,291 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.909999915980734e-06, 492
[INFO] 2021-07-09 16:59:40,291 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 492
[INFO] 2021-07-09 16:59:40,291 [run_pretraining.py:  558]:	worker_index: 4, step: 492, cost: 0.906750, mlm loss: 0.906750, speed: 0.436727 steps/s, speed: 3.493820 samples/s, speed: 1788.835725 tokens/s, learning rate: 4.910e-06, loss_scalings: 377.789520, pp_loss: 0.914766
[INFO] 2021-07-09 16:59:40,291 [run_pretraining.py:  512]:	********exe.run_492******* 
[INFO] 2021-07-09 16:59:42,583 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:42,584 [run_pretraining.py:  534]:	loss/total_loss, 0.8281974792480469, 493
[INFO] 2021-07-09 16:59:42,584 [run_pretraining.py:  535]:	loss/mlm_loss, 0.8281974792480469, 493
[INFO] 2021-07-09 16:59:42,584 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.919999810226727e-06, 493
[INFO] 2021-07-09 16:59:42,584 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 493
[INFO] 2021-07-09 16:59:42,584 [run_pretraining.py:  558]:	worker_index: 4, step: 493, cost: 0.828197, mlm loss: 0.828197, speed: 0.436115 steps/s, speed: 3.488919 samples/s, speed: 1786.326408 tokens/s, learning rate: 4.920e-06, loss_scalings: 377.789520, pp_loss: 0.822504
[INFO] 2021-07-09 16:59:42,584 [run_pretraining.py:  512]:	********exe.run_493******* 
[INFO] 2021-07-09 16:59:44,904 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:44,905 [run_pretraining.py:  534]:	loss/total_loss, 0.7442964315414429, 494
[INFO] 2021-07-09 16:59:44,905 [run_pretraining.py:  535]:	loss/mlm_loss, 0.7442964315414429, 494
[INFO] 2021-07-09 16:59:44,905 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.929999704472721e-06, 494
[INFO] 2021-07-09 16:59:44,905 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 494
[INFO] 2021-07-09 16:59:44,905 [run_pretraining.py:  558]:	worker_index: 4, step: 494, cost: 0.744296, mlm loss: 0.744296, speed: 0.431026 steps/s, speed: 3.448211 samples/s, speed: 1765.483909 tokens/s, learning rate: 4.930e-06, loss_scalings: 377.789520, pp_loss: 0.748649
[INFO] 2021-07-09 16:59:44,905 [run_pretraining.py:  512]:	********exe.run_494******* 
[INFO] 2021-07-09 16:59:47,157 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:47,157 [run_pretraining.py:  534]:	loss/total_loss, 0.6684613227844238, 495
[INFO] 2021-07-09 16:59:47,157 [run_pretraining.py:  535]:	loss/mlm_loss, 0.6684613227844238, 495
[INFO] 2021-07-09 16:59:47,158 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.940000053466065e-06, 495
[INFO] 2021-07-09 16:59:47,158 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 495
[INFO] 2021-07-09 16:59:47,158 [run_pretraining.py:  558]:	worker_index: 4, step: 495, cost: 0.668461, mlm loss: 0.668461, speed: 0.444043 steps/s, speed: 3.552346 samples/s, speed: 1818.801061 tokens/s, learning rate: 4.940e-06, loss_scalings: 377.789520, pp_loss: 0.666223
[INFO] 2021-07-09 16:59:47,158 [run_pretraining.py:  512]:	********exe.run_495******* 
[INFO] 2021-07-09 16:59:49,388 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:49,388 [run_pretraining.py:  534]:	loss/total_loss, 0.604214608669281, 496
[INFO] 2021-07-09 16:59:49,389 [run_pretraining.py:  535]:	loss/mlm_loss, 0.604214608669281, 496
[INFO] 2021-07-09 16:59:49,389 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.949999947712058e-06, 496
[INFO] 2021-07-09 16:59:49,389 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 496
[INFO] 2021-07-09 16:59:49,389 [run_pretraining.py:  558]:	worker_index: 4, step: 496, cost: 0.604215, mlm loss: 0.604215, speed: 0.448339 steps/s, speed: 3.586713 samples/s, speed: 1836.396870 tokens/s, learning rate: 4.950e-06, loss_scalings: 377.789520, pp_loss: 0.605845
[INFO] 2021-07-09 16:59:49,389 [run_pretraining.py:  512]:	********exe.run_496******* 
[INFO] 2021-07-09 16:59:51,631 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:51,632 [run_pretraining.py:  534]:	loss/total_loss, 0.5586128830909729, 497
[INFO] 2021-07-09 16:59:51,632 [run_pretraining.py:  535]:	loss/mlm_loss, 0.5586128830909729, 497
[INFO] 2021-07-09 16:59:51,632 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.9599998419580515e-06, 497
[INFO] 2021-07-09 16:59:51,632 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 497
[INFO] 2021-07-09 16:59:51,632 [run_pretraining.py:  558]:	worker_index: 4, step: 497, cost: 0.558613, mlm loss: 0.558613, speed: 0.445930 steps/s, speed: 3.567443 samples/s, speed: 1826.530891 tokens/s, learning rate: 4.960e-06, loss_scalings: 377.789520, pp_loss: 0.555925
[INFO] 2021-07-09 16:59:51,632 [run_pretraining.py:  512]:	********exe.run_497******* 
[INFO] 2021-07-09 16:59:53,852 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:53,853 [run_pretraining.py:  534]:	loss/total_loss, 0.5174010396003723, 498
[INFO] 2021-07-09 16:59:53,853 [run_pretraining.py:  535]:	loss/mlm_loss, 0.5174010396003723, 498
[INFO] 2021-07-09 16:59:53,853 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.969999736204045e-06, 498
[INFO] 2021-07-09 16:59:53,853 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 498
[INFO] 2021-07-09 16:59:53,853 [run_pretraining.py:  558]:	worker_index: 4, step: 498, cost: 0.517401, mlm loss: 0.517401, speed: 0.450374 steps/s, speed: 3.602988 samples/s, speed: 1844.730017 tokens/s, learning rate: 4.970e-06, loss_scalings: 377.789520, pp_loss: 0.522384
[INFO] 2021-07-09 16:59:53,853 [run_pretraining.py:  512]:	********exe.run_498******* 
[INFO] 2021-07-09 16:59:56,069 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:56,069 [run_pretraining.py:  534]:	loss/total_loss, 0.49443337321281433, 499
[INFO] 2021-07-09 16:59:56,069 [run_pretraining.py:  535]:	loss/mlm_loss, 0.49443337321281433, 499
[INFO] 2021-07-09 16:59:56,069 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.980000085197389e-06, 499
[INFO] 2021-07-09 16:59:56,070 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 499
[INFO] 2021-07-09 16:59:56,070 [run_pretraining.py:  558]:	worker_index: 4, step: 499, cost: 0.494433, mlm loss: 0.494433, speed: 0.451304 steps/s, speed: 3.610433 samples/s, speed: 1848.541452 tokens/s, learning rate: 4.980e-06, loss_scalings: 377.789520, pp_loss: 0.493974
[INFO] 2021-07-09 16:59:56,070 [run_pretraining.py:  512]:	********exe.run_499******* 
[INFO] 2021-07-09 16:59:58,295 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:58,295 [run_pretraining.py:  534]:	loss/total_loss, 0.4716814160346985, 500
[INFO] 2021-07-09 16:59:58,295 [run_pretraining.py:  535]:	loss/mlm_loss, 0.4716814160346985, 500
[INFO] 2021-07-09 16:59:58,295 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.9899999794433825e-06, 500
[INFO] 2021-07-09 16:59:58,295 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 500
[INFO] 2021-07-09 16:59:58,296 [run_pretraining.py:  558]:	worker_index: 4, step: 500, cost: 0.471681, mlm loss: 0.471681, speed: 0.449384 steps/s, speed: 3.595069 samples/s, speed: 1840.675092 tokens/s, learning rate: 4.990e-06, loss_scalings: 377.789520, pp_loss: 0.471186
[DEBUG] 2021-07-09 16:59:58,296 [run_pretraining.py:  567]:	saving models to output/test-bs8-mppp_4/step_500
[INFO] 2021-07-09 16:59:59,175 [run_pretraining.py:  512]:	********exe.run_500******* 
[INFO] 2021-07-09 17:00:01,451 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 17:00:01,452 [run_pretraining.py:  534]:	loss/total_loss, 0.47437649965286255, 501
[INFO] 2021-07-09 17:00:01,452 [run_pretraining.py:  535]:	loss/mlm_loss, 0.47437649965286255, 501
[INFO] 2021-07-09 17:00:01,452 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.999999873689376e-06, 501
[INFO] 2021-07-09 17:00:01,452 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 501
[INFO] 2021-07-09 17:00:01,453 [run_pretraining.py:  558]:	worker_index: 4, step: 501, cost: 0.474376, mlm loss: 0.474376, speed: 0.316817 steps/s, speed: 2.534535 samples/s, speed: 1297.681995 tokens/s, learning rate: 5.000e-06, loss_scalings: 377.789520, pp_loss: 0.464491
[INFO] 2021-07-09 17:00:01,453 [run_pretraining.py:  512]:	********exe.run_501******* 
[INFO] 2021-07-09 17:00:03,713 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 17:00:03,714 [run_pretraining.py:  534]:	loss/total_loss, 0.4589146375656128, 502
[INFO] 2021-07-09 17:00:03,714 [run_pretraining.py:  535]:	loss/mlm_loss, 0.4589146375656128, 502
[INFO] 2021-07-09 17:00:03,714 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.009999767935369e-06, 502
[INFO] 2021-07-09 17:00:03,714 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 502
[INFO] 2021-07-09 17:00:03,714 [run_pretraining.py:  558]:	worker_index: 4, step: 502, cost: 0.458915, mlm loss: 0.458915, speed: 0.442326 steps/s, speed: 3.538607 samples/s, speed: 1811.766870 tokens/s, learning rate: 5.010e-06, loss_scalings: 377.789520, pp_loss: 0.467582
[INFO] 2021-07-09 17:00:03,714 [run_pretraining.py:  512]:	********exe.run_502******* 
[INFO] 2021-07-09 17:00:05,973 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 17:00:05,974 [run_pretraining.py:  534]:	loss/total_loss, 0.46362632513046265, 503
[INFO] 2021-07-09 17:00:05,974 [run_pretraining.py:  535]:	loss/mlm_loss, 0.46362632513046265, 503
[INFO] 2021-07-09 17:00:05,974 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.020000116928713e-06, 503
[INFO] 2021-07-09 17:00:05,974 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 503
[INFO] 2021-07-09 17:00:05,974 [run_pretraining.py:  558]:	worker_index: 4, step: 503, cost: 0.463626, mlm loss: 0.463626, speed: 0.442603 steps/s, speed: 3.540827 samples/s, speed: 1812.903665 tokens/s, learning rate: 5.020e-06, loss_scalings: 377.789520, pp_loss: 0.470721
[INFO] 2021-07-09 17:00:05,974 [run_pretraining.py:  512]:	********exe.run_503******* 
[INFO] 2021-07-09 17:00:08,231 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 17:00:08,232 [run_pretraining.py:  534]:	loss/total_loss, 0.47802969813346863, 504
[INFO] 2021-07-09 17:00:08,232 [run_pretraining.py:  535]:	loss/mlm_loss, 0.47802969813346863, 504
[INFO] 2021-07-09 17:00:08,232 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.029999556427356e-06, 504
[INFO] 2021-07-09 17:00:08,232 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 504
[INFO] 2021-07-09 17:00:08,232 [run_pretraining.py:  558]:	worker_index: 4, step: 504, cost: 0.478030, mlm loss: 0.478030, speed: 0.442954 steps/s, speed: 3.543635 samples/s, speed: 1814.341133 tokens/s, learning rate: 5.030e-06, loss_scalings: 377.789520, pp_loss: 0.479526
[INFO] 2021-07-09 17:00:08,232 [run_pretraining.py:  512]:	********exe.run_504******* 
[INFO] 2021-07-09 17:00:10,430 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 17:00:10,430 [run_pretraining.py:  534]:	loss/total_loss, 0.4933978319168091, 505
[INFO] 2021-07-09 17:00:10,430 [run_pretraining.py:  535]:	loss/mlm_loss, 0.4933978319168091, 505
[INFO] 2021-07-09 17:00:10,430 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.0399999054207e-06, 505
[INFO] 2021-07-09 17:00:10,431 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 505
[INFO] 2021-07-09 17:00:10,431 [run_pretraining.py:  558]:	worker_index: 4, step: 505, cost: 0.493398, mlm loss: 0.493398, speed: 0.454974 steps/s, speed: 3.639793 samples/s, speed: 1863.573976 tokens/s, learning rate: 5.040e-06, loss_scalings: 377.789520, pp_loss: 0.498263
[INFO] 2021-07-09 17:00:10,431 [run_pretraining.py:  512]:	********exe.run_505******* 
[INFO] 2021-07-09 17:00:12,675 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 17:00:12,676 [run_pretraining.py:  534]:	loss/total_loss, 0.5269768238067627, 506
[INFO] 2021-07-09 17:00:12,676 [run_pretraining.py:  535]:	loss/mlm_loss, 0.5269768238067627, 506
[INFO] 2021-07-09 17:00:12,676 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.050000254414044e-06, 506
[INFO] 2021-07-09 17:00:12,676 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 506
[INFO] 2021-07-09 17:00:12,676 [run_pretraining.py:  558]:	worker_index: 4, step: 506, cost: 0.526977, mlm loss: 0.526977, speed: 0.445451 steps/s, speed: 3.563610 samples/s, speed: 1824.568349 tokens/s, learning rate: 5.050e-06, loss_scalings: 377.789520, pp_loss: 0.530367
[INFO] 2021-07-09 17:00:12,676 [run_pretraining.py:  512]:	********exe.run_506******* 
[INFO] 2021-07-09 17:00:14,888 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 17:00:14,889 [run_pretraining.py:  534]:	loss/total_loss, 0.574758768081665, 507
[INFO] 2021-07-09 17:00:14,889 [run_pretraining.py:  535]:	loss/mlm_loss, 0.574758768081665, 507
[INFO] 2021-07-09 17:00:14,889 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.059999693912687e-06, 507
[INFO] 2021-07-09 17:00:14,889 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 507
[INFO] 2021-07-09 17:00:14,889 [run_pretraining.py:  558]:	worker_index: 4, step: 507, cost: 0.574759, mlm loss: 0.574759, speed: 0.452019 steps/s, speed: 3.616153 samples/s, speed: 1851.470538 tokens/s, learning rate: 5.060e-06, loss_scalings: 377.789520, pp_loss: 0.575340
[INFO] 2021-07-09 17:00:14,889 [run_pretraining.py:  512]:	********exe.run_507******* 
[INFO] 2021-07-09 17:00:17,115 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 17:00:17,116 [run_pretraining.py:  534]:	loss/total_loss, 0.6457549333572388, 508
[INFO] 2021-07-09 17:00:17,116 [run_pretraining.py:  535]:	loss/mlm_loss, 0.6457549333572388, 508
[INFO] 2021-07-09 17:00:17,116 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.070000042906031e-06, 508
[INFO] 2021-07-09 17:00:17,116 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 508
[INFO] 2021-07-09 17:00:17,116 [run_pretraining.py:  558]:	worker_index: 4, step: 508, cost: 0.645755, mlm loss: 0.645755, speed: 0.449134 steps/s, speed: 3.593071 samples/s, speed: 1839.652325 tokens/s, learning rate: 5.070e-06, loss_scalings: 377.789520, pp_loss: 0.664597
[INFO] 2021-07-09 17:00:17,116 [run_pretraining.py:  512]:	********exe.run_508******* 
[INFO] 2021-07-09 17:00:19,320 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 17:00:19,320 [run_pretraining.py:  534]:	loss/total_loss, 0.7567422389984131, 509
[INFO] 2021-07-09 17:00:19,321 [run_pretraining.py:  535]:	loss/mlm_loss, 0.7567422389984131, 509
[INFO] 2021-07-09 17:00:19,321 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.079999937152024e-06, 509
[INFO] 2021-07-09 17:00:19,321 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 509
[INFO] 2021-07-09 17:00:19,321 [run_pretraining.py:  558]:	worker_index: 4, step: 509, cost: 0.756742, mlm loss: 0.756742, speed: 0.453739 steps/s, speed: 3.629915 samples/s, speed: 1858.516607 tokens/s, learning rate: 5.080e-06, loss_scalings: 377.789520, pp_loss: 0.779306
[INFO] 2021-07-09 17:00:19,321 [run_pretraining.py:  512]:	********exe.run_509******* 
[INFO] 2021-07-09 17:00:21,543 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 17:00:21,543 [run_pretraining.py:  534]:	loss/total_loss, 0.918758749961853, 510
[INFO] 2021-07-09 17:00:21,543 [run_pretraining.py:  535]:	loss/mlm_loss, 0.918758749961853, 510
[INFO] 2021-07-09 17:00:21,543 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.089999831398018e-06, 510
[INFO] 2021-07-09 17:00:21,543 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 510
[INFO] 2021-07-09 17:00:21,543 [run_pretraining.py:  558]:	worker_index: 4, step: 510, cost: 0.918759, mlm loss: 0.918759, speed: 0.450059 steps/s, speed: 3.600475 samples/s, speed: 1843.443181 tokens/s, learning rate: 5.090e-06, loss_scalings: 377.789520, pp_loss: 0.925641
[INFO] 2021-07-09 17:00:21,543 [run_pretraining.py:  512]:	********exe.run_510******* 
[INFO] 2021-07-09 17:00:23,794 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 17:00:23,794 [run_pretraining.py:  534]:	loss/total_loss, 1.0565403699874878, 511
[INFO] 2021-07-09 17:00:23,794 [run_pretraining.py:  535]:	loss/mlm_loss, 1.0565403699874878, 511
[INFO] 2021-07-09 17:00:23,794 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.099999725644011e-06, 511
[INFO] 2021-07-09 17:00:23,795 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 511
[INFO] 2021-07-09 17:00:23,795 [run_pretraining.py:  558]:	worker_index: 4, step: 511, cost: 1.056540, mlm loss: 1.056540, speed: 0.444313 steps/s, speed: 3.554500 samples/s, speed: 1819.904096 tokens/s, learning rate: 5.100e-06, loss_scalings: 377.789520, pp_loss: 1.054548
[INFO] 2021-07-09 17:00:23,795 [run_pretraining.py:  512]:	********exe.run_511******* 
[INFO] 2021-07-09 17:00:26,077 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 17:00:26,078 [run_pretraining.py:  534]:	loss/total_loss, 1.159671664237976, 512
[INFO] 2021-07-09 17:00:26,078 [run_pretraining.py:  535]:	loss/mlm_loss, 1.159671664237976, 512
[INFO] 2021-07-09 17:00:26,078 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.110000074637355e-06, 512
[INFO] 2021-07-09 17:00:26,078 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 512
[INFO] 2021-07-09 17:00:26,078 [run_pretraining.py:  558]:	worker_index: 4, step: 512, cost: 1.159672, mlm loss: 1.159672, speed: 0.438053 steps/s, speed: 3.504427 samples/s, speed: 1794.266761 tokens/s, learning rate: 5.110e-06, loss_scalings: 377.789520, pp_loss: 1.137831
[INFO] 2021-07-09 17:00:26,078 [run_pretraining.py:  512]:	********exe.run_512******* 
/home/gongwb/.local/lib/python3.7/multiprocessing/semaphore_tracker.py:144: UserWarning: semaphore_tracker: There appear to be 91 leaked semaphores to clean up at shutdown
  len(cache))
