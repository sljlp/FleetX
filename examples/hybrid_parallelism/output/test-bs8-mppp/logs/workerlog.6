/home/gongwb/.local/lib/python3.7/site-packages/setuptools/depends.py:2: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0709 16:38:09.979844 36126 init.cc:88] Before Parse: argc is 2, Init commandline: dummy --tryfromenv=check_nan_inf,benchmark,eager_delete_scope,fraction_of_cpu_memory_to_use,initial_cpu_memory_in_mb,init_allocated_mem,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_system_allocator,enable_unused_var_check,free_idle_chunk,free_when_no_cache_hit,call_stack_level,sort_sum_gradient,max_inplace_grad_add,use_pinned_memory,cpu_deterministic,selected_npus,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,gpu_memory_limit_mb 
I0709 16:38:09.980057 36126 init.cc:95] After Parse: argc is 1
-----------  Configuration Arguments -----------
data_dir: ./data
debug: False
do_eval: True
epoch: 100
ernie_config_file: config/ernie_base_config.json
eval_batch_size: 35
eval_data_path: ./data
eval_steps: -1
global_bsz: 8
global_steps: 0
grad_merge: 0
init_checkpoint: 
learning_rate: 0.0001
log_steps: 1
max_seq_len: 512
micro_bsz: 1
num_dp: 1
num_mp: 4
num_pp: 2
num_sharding: 1
num_train_steps: 1600
output_dir: output/test-bs8-mppp
preln: False
save_steps: 500
seed: 2021
use_amp: True
use_hybrid_dp: True
use_lamb: False
use_offload: False
use_recompute: True
use_sharding: True
vocab_file: ./config/30k-clean.vocab.albert
warmup_steps: 10000
weight_decay: 0.01
------------------------------------------------
to run startup
[INFO] 2021-07-09 16:38:10,783 [run_pretraining.py:  216]:	pretraining start
[INFO] 2021-07-09 16:38:10,783 [run_pretraining.py:  234]:	using recompute.
[INFO] 2021-07-09 16:38:10,784 [run_pretraining.py:  279]:	using globa_bsz: 8 micro_bsz: 1, acc_steps: 8
[DEBUG] 2021-07-09 16:38:10,847 [run_pretraining.py:  118]:	========= dp_sharding worker: 0 of 1 ==========
[INFO] 2021-07-09 16:38:10,847 [pretraining_ds_mlm.py:  293]:	Apply sharding in distribution env 0/1
[INFO] 2021-07-09 16:38:10,847 [pretraining_ds_mlm.py:  295]:	read from ./data/part-00000.104,./data/part-00000.100,./data/part-00000.107,./data/part-00000.103,./data/part-00000.10,./data/part-00000.105,./data/part-00000.101,./data/part-00000.102,./data/part-00000.106,./data/part-00000.109,./data/part-00000.108
I0709 16:38:10.848201 36126 reader_py.cc:387] init_lod_tensor_blocking_queue
INFO:root:places would be ommited when DataLoader is not iterable
/home/liupeng51/github/Paddle/build/build_ubuntu_optimizer_checkinf_release_ascend_y_none_3.7.5/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /home/liupeng51/github/FleetX/examples/hybrid_parallelism/model/ernie.py:158
The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
/home/liupeng51/github/Paddle/build/build_ubuntu_optimizer_checkinf_release_ascend_y_none_3.7.5/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /home/liupeng51/github/FleetX/examples/hybrid_parallelism/model/ernie.py:159
The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
/home/liupeng51/github/Paddle/build/build_ubuntu_optimizer_checkinf_release_ascend_y_none_3.7.5/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /home/liupeng51/github/FleetX/examples/hybrid_parallelism/model/transformer_encoder.py:170
The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
/home/liupeng51/github/Paddle/build/build_ubuntu_optimizer_checkinf_release_ascend_y_none_3.7.5/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /home/liupeng51/github/FleetX/examples/hybrid_parallelism/model/transformer_encoder.py:280
The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
/home/liupeng51/github/Paddle/build/build_ubuntu_optimizer_checkinf_release_ascend_y_none_3.7.5/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /home/liupeng51/github/FleetX/examples/hybrid_parallelism/model/transformer_encoder.py:43
The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
/home/liupeng51/github/Paddle/build/build_ubuntu_optimizer_checkinf_release_ascend_y_none_3.7.5/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /home/liupeng51/github/FleetX/examples/hybrid_parallelism/model/transformer_encoder.py:44
The behavior of expression A * B has been unified with elementwise_mul(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_mul(X, Y, axis=0) instead of A * B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
[DEBUG] 2021-07-09 16:38:11,653 [run_pretraining.py:  315]:	base lr: 0.0001
/home/liupeng51/github/Paddle/build/build_ubuntu_optimizer_checkinf_release_ascend_y_none_3.7.5/python/paddle/distributed/fleet/base/fleet_base.py:818: UserWarning: It is recommended to use DistributedStrategy in fleet.init(). The strategy here is only for compatibility. If the strategy in fleet.distributed_optimizer() is not None, then it will overwrite the DistributedStrategy in fleet.init(), which will take effect in distributed training.
  "It is recommended to use DistributedStrategy "
2021-07-09 16:38:11 INFO     Gradient merge in [pp_gm], acc step = [8]
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:Gradient merge in [pp_gm], acc step = [8]
Fri Jul 09 16:38:12-INFO: recompute segment[0]
Fri Jul 09 16:38:12-INFO: segment start op: [squeeze2]: [['shard_index_0.tmp_0']]
Fri Jul 09 16:38:12-INFO: segment end op: [layer_norm]: [['encoder_layer_0_post_ffn_layer_norm_bias', 'encoder_layer_0_post_ffn_layer_norm_scale', 'tmp_10']]
Fri Jul 09 16:38:12-INFO: recompute segment[0]
Fri Jul 09 16:38:12-INFO: segment start op: [squeeze2]: [['shard_index_0.tmp_0']]
Fri Jul 09 16:38:12-INFO: segment end op: [layer_norm]: [['encoder_layer_0_post_ffn_layer_norm_bias', 'encoder_layer_0_post_ffn_layer_norm_scale', 'tmp_10']]
Fri Jul 09 16:38:12-INFO: found [0] vars which cross recompute segment: [set()], better checkpoints might be set to reduce those vars
pp_rank: 1
2021-07-09 16:38:17 INFO     global word size: 8
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:global word size: 8
2021-07-09 16:38:17 INFO     global rank: 6
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:global rank: 6
2021-07-09 16:38:17 INFO     global endpoints: ['192.168.206.27:6170', '192.168.206.27:6171', '192.168.206.27:6172', '192.168.206.27:6173', '192.168.206.27:6174', '192.168.206.27:6175', '192.168.206.27:6176', '192.168.206.27:6177']
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:global endpoints: ['192.168.206.27:6170', '192.168.206.27:6171', '192.168.206.27:6172', '192.168.206.27:6173', '192.168.206.27:6174', '192.168.206.27:6175', '192.168.206.27:6176', '192.168.206.27:6177']
2021-07-09 16:38:17 INFO     global ring id: 3
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:global ring id: 3
2021-07-09 16:38:17 INFO     ##############################
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:##############################
2021-07-09 16:38:17 INFO     mp group size: 4
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:mp group size: 4
2021-07-09 16:38:17 INFO     mp rank: 2
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:mp rank: 2
2021-07-09 16:38:17 INFO     mp group id: 1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:mp group id: 1
2021-07-09 16:38:17 INFO     mp group endpoints: ['192.168.206.27:6174', '192.168.206.27:6175', '192.168.206.27:6176', '192.168.206.27:6177']
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:mp group endpoints: ['192.168.206.27:6174', '192.168.206.27:6175', '192.168.206.27:6176', '192.168.206.27:6177']
2021-07-09 16:38:17 INFO     mp ring id: 0
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:mp ring id: 0
2021-07-09 16:38:17 INFO     ##############################
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:##############################
2021-07-09 16:38:17 INFO     sharding group size: 1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:sharding group size: 1
2021-07-09 16:38:17 INFO     sharding rank: -1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:sharding rank: -1
2021-07-09 16:38:17 INFO     sharding group id: -1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:sharding group id: -1
2021-07-09 16:38:17 INFO     sharding group endpoints: []
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:sharding group endpoints: []
2021-07-09 16:38:17 INFO     sharding ring id: -1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:sharding ring id: -1
2021-07-09 16:38:17 INFO     ##############################
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:##############################
2021-07-09 16:38:17 INFO     pp group size: 2
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pp group size: 2
2021-07-09 16:38:17 INFO     pp rank: 1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pp rank: 1
2021-07-09 16:38:17 INFO     pp group id: 0
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pp group id: 0
2021-07-09 16:38:17 INFO     pp group endpoints: ['192.168.206.27:6172', '192.168.206.27:6176']
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pp group endpoints: ['192.168.206.27:6172', '192.168.206.27:6176']
2021-07-09 16:38:17 INFO     pp ring id: 20
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pp ring id: 20
2021-07-09 16:38:17 INFO     ##############################
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:##############################
2021-07-09 16:38:17 INFO     pure dp group size: 1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pure dp group size: 1
2021-07-09 16:38:17 INFO     pure dp rank: -1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pure dp rank: -1
2021-07-09 16:38:17 INFO     pure dp group endpoints: []
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pure dp group endpoints: []
2021-07-09 16:38:17 INFO     pure dp ring id: -1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pure dp ring id: -1
2021-07-09 16:38:17 INFO     ##############################
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:##############################
pp pair:(0, 1), ring_id: 20
pp pair:(1, 0), ring_id: 21
I0709 16:38:36.993532 36126 gen_hccl_id_op_helper.cc:181] Server listening on: 192.168.206.27:6176 successful.
I0709 16:38:37.082337 36126 collective_helper_npu.cc:83] initialized comm: 0xffffc3fc7890, nranks: 8, hccl_id: 0x1670fd64, rank: 6
I0709 16:38:40.540292 36126 collective_helper_npu.cc:88] initialized comm: 0xffffc3fc7890, nranks: 8, hccl_id: 0x1670fd64, rank: 6
I0709 16:38:40.540529 36126 collective_helper_npu.cc:93] hccl communicator of rank 6 in ring 3 has been created on device 6, with comm: 0x166fccf0
I0709 16:38:42.949833 36126 gen_hccl_id_op_helper.cc:181] Server listening on: 192.168.206.27:6176 successful.
I0709 16:38:42.952070 36126 collective_helper_npu.cc:83] initialized comm: 0xffffc3fc7890, nranks: 4, hccl_id: 0x166b4fd4, rank: 2
I0709 16:38:44.767850 36126 collective_helper_npu.cc:88] initialized comm: 0xffffc3fc7890, nranks: 4, hccl_id: 0x166b4fd4, rank: 2
I0709 16:38:44.768272 36126 collective_helper_npu.cc:93] hccl communicator of rank 2 in ring 0 has been created on device 6, with comm: 0x166d6e60
I0709 16:38:45.598031 36126 gen_hccl_id_op_helper.cc:181] Server listening on: 192.168.206.27:6176 successful.
I0709 16:38:45.599905 36126 collective_helper_npu.cc:83] initialized comm: 0xffffc3fc7890, nranks: 2, hccl_id: 0x166974a4, rank: 1
I0709 16:38:46.811782 36126 collective_helper_npu.cc:88] initialized comm: 0xffffc3fc7890, nranks: 2, hccl_id: 0x166974a4, rank: 1
I0709 16:38:46.811959 36126 collective_helper_npu.cc:93] hccl communicator of rank 1 in ring 20 has been created on device 6, with comm: 0x164efed0
W0709 16:38:47.174983 36126 gen_hccl_id_op_helper.cc:120] connect addr=192.168.206.27:6172 failed 1 times with reason: Connection refused retry after 0.5 seconds
I0709 16:38:47.676510 36126 collective_helper_npu.cc:83] initialized comm: 0xffffc3fc7890, nranks: 2, hccl_id: 0x166985b4, rank: 0
I0709 16:38:48.899928 36126 collective_helper_npu.cc:88] initialized comm: 0xffffc3fc7890, nranks: 2, hccl_id: 0x166985b4, rank: 0
I0709 16:38:48.901041 36126 collective_helper_npu.cc:93] hccl communicator of rank 0 in ring 21 has been created on device 6, with comm: 0x164baa80
Done broadcast
[INFO] 2021-07-09 16:38:49,185 [run_pretraining.py:  512]:	********exe.run_0******* 
I0709 16:38:51.880602 39390 lod_tensor_blocking_queue.h:104] Init queue with size 1
I0709 16:38:51.881037 39390 buffered_reader.cc:41] BufferedReader
[INFO] 2021-07-09 16:41:11,467 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:11,468 [run_pretraining.py:  534]:	loss/total_loss, 10.272479057312012, 1
[INFO] 2021-07-09 16:41:11,468 [run_pretraining.py:  535]:	loss/mlm_loss, 10.272479057312012, 1
[INFO] 2021-07-09 16:41:11,468 [run_pretraining.py:  536]:	lr/scheduled_lr, 0.0, 1
[INFO] 2021-07-09 16:41:11,469 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 1
[INFO] 2021-07-09 16:41:11,469 [run_pretraining.py:  558]:	worker_index: 6, step: 1, cost: 10.272479, mlm loss: 10.272479, speed: 0.007028 steps/s, speed: 0.056225 samples/s, speed: 28.787158 tokens/s, learning rate: 0.000e+00, loss_scalings: 32768.000000, pp_loss: 10.396810
[INFO] 2021-07-09 16:41:11,469 [run_pretraining.py:  512]:	********exe.run_1******* 
[INFO] 2021-07-09 16:41:16,681 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:16,682 [run_pretraining.py:  534]:	loss/total_loss, 10.43328857421875, 2
[INFO] 2021-07-09 16:41:16,682 [run_pretraining.py:  535]:	loss/mlm_loss, 10.43328857421875, 2
[INFO] 2021-07-09 16:41:16,682 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.99999905104687e-09, 2
[INFO] 2021-07-09 16:41:16,682 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 2
[INFO] 2021-07-09 16:41:16,683 [run_pretraining.py:  558]:	worker_index: 6, step: 2, cost: 10.433289, mlm loss: 10.433289, speed: 0.191820 steps/s, speed: 1.534559 samples/s, speed: 785.694273 tokens/s, learning rate: 1.000e-08, loss_scalings: 32768.000000, pp_loss: 10.419235
[INFO] 2021-07-09 16:41:16,683 [run_pretraining.py:  512]:	********exe.run_2******* 
[INFO] 2021-07-09 16:41:18,805 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:18,806 [run_pretraining.py:  534]:	loss/total_loss, 10.232545852661133, 3
[INFO] 2021-07-09 16:41:18,806 [run_pretraining.py:  535]:	loss/mlm_loss, 10.232545852661133, 3
[INFO] 2021-07-09 16:41:18,806 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.999999810209374e-08, 3
[INFO] 2021-07-09 16:41:18,806 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 3
[INFO] 2021-07-09 16:41:18,806 [run_pretraining.py:  558]:	worker_index: 6, step: 3, cost: 10.232546, mlm loss: 10.232546, speed: 0.470984 steps/s, speed: 3.767871 samples/s, speed: 1929.149934 tokens/s, learning rate: 2.000e-08, loss_scalings: 32768.000000, pp_loss: 10.408423
[INFO] 2021-07-09 16:41:18,807 [run_pretraining.py:  512]:	********exe.run_3******* 
[INFO] 2021-07-09 16:41:20,918 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:20,919 [run_pretraining.py:  534]:	loss/total_loss, 10.451372146606445, 4
[INFO] 2021-07-09 16:41:20,919 [run_pretraining.py:  535]:	loss/mlm_loss, 10.451372146606445, 4
[INFO] 2021-07-09 16:41:20,919 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.999999892949745e-08, 4
[INFO] 2021-07-09 16:41:20,919 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 4
[INFO] 2021-07-09 16:41:20,919 [run_pretraining.py:  558]:	worker_index: 6, step: 4, cost: 10.451372, mlm loss: 10.451372, speed: 0.473481 steps/s, speed: 3.787848 samples/s, speed: 1939.378187 tokens/s, learning rate: 3.000e-08, loss_scalings: 32768.000000, pp_loss: 10.360915
[INFO] 2021-07-09 16:41:20,919 [run_pretraining.py:  512]:	********exe.run_4******* 
[INFO] 2021-07-09 16:41:23,068 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:23,069 [run_pretraining.py:  534]:	loss/total_loss, 10.32596492767334, 5
[INFO] 2021-07-09 16:41:23,069 [run_pretraining.py:  535]:	loss/mlm_loss, 10.32596492767334, 5
[INFO] 2021-07-09 16:41:23,069 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.999999620418748e-08, 5
[INFO] 2021-07-09 16:41:23,069 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 5
[INFO] 2021-07-09 16:41:23,069 [run_pretraining.py:  558]:	worker_index: 6, step: 5, cost: 10.325965, mlm loss: 10.325965, speed: 0.465284 steps/s, speed: 3.722270 samples/s, speed: 1905.801989 tokens/s, learning rate: 4.000e-08, loss_scalings: 32768.000000, pp_loss: 10.406396
[INFO] 2021-07-09 16:41:23,069 [run_pretraining.py:  512]:	********exe.run_5******* 
[INFO] 2021-07-09 16:41:25,217 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:25,217 [run_pretraining.py:  534]:	loss/total_loss, 10.407240867614746, 6
[INFO] 2021-07-09 16:41:25,218 [run_pretraining.py:  535]:	loss/mlm_loss, 10.407240867614746, 6
[INFO] 2021-07-09 16:41:25,218 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.000000058430487e-08, 6
[INFO] 2021-07-09 16:41:25,218 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 6
[INFO] 2021-07-09 16:41:25,218 [run_pretraining.py:  558]:	worker_index: 6, step: 6, cost: 10.407241, mlm loss: 10.407241, speed: 0.465510 steps/s, speed: 3.724084 samples/s, speed: 1906.730765 tokens/s, learning rate: 5.000e-08, loss_scalings: 32768.000000, pp_loss: 10.416453
[INFO] 2021-07-09 16:41:25,218 [run_pretraining.py:  512]:	********exe.run_6******* 
[INFO] 2021-07-09 16:41:27,419 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:27,420 [run_pretraining.py:  534]:	loss/total_loss, 10.557442665100098, 7
[INFO] 2021-07-09 16:41:27,420 [run_pretraining.py:  535]:	loss/mlm_loss, 10.557442665100098, 7
[INFO] 2021-07-09 16:41:27,420 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.99999978589949e-08, 7
[INFO] 2021-07-09 16:41:27,420 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 7
[INFO] 2021-07-09 16:41:27,420 [run_pretraining.py:  558]:	worker_index: 6, step: 7, cost: 10.557443, mlm loss: 10.557443, speed: 0.454162 steps/s, speed: 3.633293 samples/s, speed: 1860.245873 tokens/s, learning rate: 6.000e-08, loss_scalings: 32768.000000, pp_loss: 10.335190
[INFO] 2021-07-09 16:41:27,420 [run_pretraining.py:  512]:	********exe.run_7******* 
[INFO] 2021-07-09 16:41:29,616 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:29,618 [run_pretraining.py:  534]:	loss/total_loss, 10.55422306060791, 8
[INFO] 2021-07-09 16:41:29,618 [run_pretraining.py:  535]:	loss/mlm_loss, 10.55422306060791, 8
[INFO] 2021-07-09 16:41:29,618 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.999999868639861e-08, 8
[INFO] 2021-07-09 16:41:29,618 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 8
[INFO] 2021-07-09 16:41:29,618 [run_pretraining.py:  558]:	worker_index: 6, step: 8, cost: 10.554223, mlm loss: 10.554223, speed: 0.455200 steps/s, speed: 3.641602 samples/s, speed: 1864.500081 tokens/s, learning rate: 7.000e-08, loss_scalings: 32768.000000, pp_loss: 10.405637
[INFO] 2021-07-09 16:41:29,618 [run_pretraining.py:  512]:	********exe.run_8******* 
[INFO] 2021-07-09 16:41:31,786 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:31,787 [run_pretraining.py:  534]:	loss/total_loss, 10.383804321289062, 9
[INFO] 2021-07-09 16:41:31,787 [run_pretraining.py:  535]:	loss/mlm_loss, 10.383804321289062, 9
[INFO] 2021-07-09 16:41:31,787 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.999999240837496e-08, 9
[INFO] 2021-07-09 16:41:31,787 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 9
[INFO] 2021-07-09 16:41:31,787 [run_pretraining.py:  558]:	worker_index: 6, step: 9, cost: 10.383804, mlm loss: 10.383804, speed: 0.461152 steps/s, speed: 3.689213 samples/s, speed: 1888.877230 tokens/s, learning rate: 8.000e-08, loss_scalings: 32768.000000, pp_loss: 10.407137
[INFO] 2021-07-09 16:41:31,787 [run_pretraining.py:  512]:	********exe.run_9******* 
[INFO] 2021-07-09 16:41:33,972 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:33,973 [run_pretraining.py:  534]:	loss/total_loss, 10.320575714111328, 10
[INFO] 2021-07-09 16:41:33,973 [run_pretraining.py:  535]:	loss/mlm_loss, 10.320575714111328, 10
[INFO] 2021-07-09 16:41:33,973 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.999999323577867e-08, 10
[INFO] 2021-07-09 16:41:33,973 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 10
[INFO] 2021-07-09 16:41:33,973 [run_pretraining.py:  558]:	worker_index: 6, step: 10, cost: 10.320576, mlm loss: 10.320576, speed: 0.457550 steps/s, speed: 3.660400 samples/s, speed: 1874.124749 tokens/s, learning rate: 9.000e-08, loss_scalings: 32768.000000, pp_loss: 10.366991
[INFO] 2021-07-09 16:41:33,973 [run_pretraining.py:  512]:	********exe.run_10******* 
[INFO] 2021-07-09 16:41:36,153 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:36,154 [run_pretraining.py:  534]:	loss/total_loss, 10.46362590789795, 11
[INFO] 2021-07-09 16:41:36,154 [run_pretraining.py:  535]:	loss/mlm_loss, 10.46362590789795, 11
[INFO] 2021-07-09 16:41:36,154 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0000000116860974e-07, 11
[INFO] 2021-07-09 16:41:36,154 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 11
[INFO] 2021-07-09 16:41:36,154 [run_pretraining.py:  558]:	worker_index: 6, step: 11, cost: 10.463626, mlm loss: 10.463626, speed: 0.458673 steps/s, speed: 3.669388 samples/s, speed: 1878.726431 tokens/s, learning rate: 1.000e-07, loss_scalings: 32768.000000, pp_loss: 10.336086
[INFO] 2021-07-09 16:41:36,154 [run_pretraining.py:  512]:	********exe.run_11******* 
[INFO] 2021-07-09 16:41:38,385 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:38,385 [run_pretraining.py:  534]:	loss/total_loss, 10.468735694885254, 12
[INFO] 2021-07-09 16:41:38,386 [run_pretraining.py:  535]:	loss/mlm_loss, 10.468735694885254, 12
[INFO] 2021-07-09 16:41:38,386 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.099999948905861e-07, 12
[INFO] 2021-07-09 16:41:38,386 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 12
[INFO] 2021-07-09 16:41:38,386 [run_pretraining.py:  558]:	worker_index: 6, step: 12, cost: 10.468736, mlm loss: 10.468736, speed: 0.448238 steps/s, speed: 3.585905 samples/s, speed: 1835.983562 tokens/s, learning rate: 1.100e-07, loss_scalings: 32768.000000, pp_loss: 10.403527
[INFO] 2021-07-09 16:41:38,386 [run_pretraining.py:  512]:	********exe.run_12******* 
[INFO] 2021-07-09 16:41:41,089 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:41,089 [run_pretraining.py:  534]:	loss/total_loss, 10.325819969177246, 13
[INFO] 2021-07-09 16:41:41,090 [run_pretraining.py:  535]:	loss/mlm_loss, 10.325819969177246, 13
[INFO] 2021-07-09 16:41:41,090 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.199999957179898e-07, 13
[INFO] 2021-07-09 16:41:41,090 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 13
[INFO] 2021-07-09 16:41:41,090 [run_pretraining.py:  558]:	worker_index: 6, step: 13, cost: 10.325820, mlm loss: 10.325820, speed: 0.369919 steps/s, speed: 2.959349 samples/s, speed: 1515.186748 tokens/s, learning rate: 1.200e-07, loss_scalings: 26214.400391, pp_loss: 10.326289
[INFO] 2021-07-09 16:41:41,090 [run_pretraining.py:  512]:	********exe.run_13******* 
[INFO] 2021-07-09 16:41:43,382 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:43,383 [run_pretraining.py:  534]:	loss/total_loss, 10.385750770568848, 14
[INFO] 2021-07-09 16:41:43,383 [run_pretraining.py:  535]:	loss/mlm_loss, 10.385750770568848, 14
[INFO] 2021-07-09 16:41:43,383 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3000000365082087e-07, 14
[INFO] 2021-07-09 16:41:43,383 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 14
[INFO] 2021-07-09 16:41:43,384 [run_pretraining.py:  558]:	worker_index: 6, step: 14, cost: 10.385751, mlm loss: 10.385751, speed: 0.436112 steps/s, speed: 3.488894 samples/s, speed: 1786.313592 tokens/s, learning rate: 1.300e-07, loss_scalings: 26214.400391, pp_loss: 10.403934
[INFO] 2021-07-09 16:41:43,384 [run_pretraining.py:  512]:	********exe.run_14******* 
[INFO] 2021-07-09 16:41:45,639 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:45,639 [run_pretraining.py:  534]:	loss/total_loss, 10.416686058044434, 15
[INFO] 2021-07-09 16:41:45,639 [run_pretraining.py:  535]:	loss/mlm_loss, 10.416686058044434, 15
[INFO] 2021-07-09 16:41:45,639 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3999999737279722e-07, 15
[INFO] 2021-07-09 16:41:45,640 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 15
[INFO] 2021-07-09 16:41:45,640 [run_pretraining.py:  558]:	worker_index: 6, step: 15, cost: 10.416686, mlm loss: 10.416686, speed: 0.443389 steps/s, speed: 3.547115 samples/s, speed: 1816.122937 tokens/s, learning rate: 1.400e-07, loss_scalings: 26214.400391, pp_loss: 10.303848
[INFO] 2021-07-09 16:41:45,640 [run_pretraining.py:  512]:	********exe.run_15******* 
[INFO] 2021-07-09 16:41:47,875 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:47,875 [run_pretraining.py:  534]:	loss/total_loss, 10.4579496383667, 16
[INFO] 2021-07-09 16:41:47,875 [run_pretraining.py:  535]:	loss/mlm_loss, 10.4579496383667, 16
[INFO] 2021-07-09 16:41:47,876 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4999999109477358e-07, 16
[INFO] 2021-07-09 16:41:47,876 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 16
[INFO] 2021-07-09 16:41:47,876 [run_pretraining.py:  558]:	worker_index: 6, step: 16, cost: 10.457950, mlm loss: 10.457950, speed: 0.447359 steps/s, speed: 3.578870 samples/s, speed: 1832.381194 tokens/s, learning rate: 1.500e-07, loss_scalings: 26214.400391, pp_loss: 10.369095
[INFO] 2021-07-09 16:41:47,876 [run_pretraining.py:  512]:	********exe.run_16******* 
[INFO] 2021-07-09 16:41:50,210 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:50,211 [run_pretraining.py:  534]:	loss/total_loss, 10.293956756591797, 17
[INFO] 2021-07-09 16:41:50,211 [run_pretraining.py:  535]:	loss/mlm_loss, 10.293956756591797, 17
[INFO] 2021-07-09 16:41:50,211 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5999998481674993e-07, 17
[INFO] 2021-07-09 16:41:50,211 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 17
[INFO] 2021-07-09 16:41:50,211 [run_pretraining.py:  558]:	worker_index: 6, step: 17, cost: 10.293957, mlm loss: 10.293957, speed: 0.428338 steps/s, speed: 3.426705 samples/s, speed: 1754.472758 tokens/s, learning rate: 1.600e-07, loss_scalings: 26214.400391, pp_loss: 10.348837
[INFO] 2021-07-09 16:41:50,211 [run_pretraining.py:  512]:	********exe.run_17******* 
[INFO] 2021-07-09 16:41:52,444 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:52,445 [run_pretraining.py:  534]:	loss/total_loss, 10.189165115356445, 18
[INFO] 2021-07-09 16:41:52,445 [run_pretraining.py:  535]:	loss/mlm_loss, 10.189165115356445, 18
[INFO] 2021-07-09 16:41:52,445 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.69999992749581e-07, 18
[INFO] 2021-07-09 16:41:52,445 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 18
[INFO] 2021-07-09 16:41:52,445 [run_pretraining.py:  558]:	worker_index: 6, step: 18, cost: 10.189165, mlm loss: 10.189165, speed: 0.447718 steps/s, speed: 3.581745 samples/s, speed: 1833.853251 tokens/s, learning rate: 1.700e-07, loss_scalings: 26214.400391, pp_loss: 10.334114
[INFO] 2021-07-09 16:41:52,445 [run_pretraining.py:  512]:	********exe.run_18******* 
[INFO] 2021-07-09 16:41:54,733 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:54,733 [run_pretraining.py:  534]:	loss/total_loss, 10.40139389038086, 19
[INFO] 2021-07-09 16:41:54,734 [run_pretraining.py:  535]:	loss/mlm_loss, 10.40139389038086, 19
[INFO] 2021-07-09 16:41:54,734 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7999998647155735e-07, 19
[INFO] 2021-07-09 16:41:54,734 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 19
[INFO] 2021-07-09 16:41:54,734 [run_pretraining.py:  558]:	worker_index: 6, step: 19, cost: 10.401394, mlm loss: 10.401394, speed: 0.437090 steps/s, speed: 3.496720 samples/s, speed: 1790.320895 tokens/s, learning rate: 1.800e-07, loss_scalings: 26214.400391, pp_loss: 10.394716
[INFO] 2021-07-09 16:41:54,734 [run_pretraining.py:  512]:	********exe.run_19******* 
[INFO] 2021-07-09 16:41:57,021 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:57,022 [run_pretraining.py:  534]:	loss/total_loss, 10.279133796691895, 20
[INFO] 2021-07-09 16:41:57,022 [run_pretraining.py:  535]:	loss/mlm_loss, 10.279133796691895, 20
[INFO] 2021-07-09 16:41:57,022 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8999999440438842e-07, 20
[INFO] 2021-07-09 16:41:57,022 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 20
[INFO] 2021-07-09 16:41:57,022 [run_pretraining.py:  558]:	worker_index: 6, step: 20, cost: 10.279134, mlm loss: 10.279134, speed: 0.437085 steps/s, speed: 3.496680 samples/s, speed: 1790.300000 tokens/s, learning rate: 1.900e-07, loss_scalings: 26214.400391, pp_loss: 10.312462
[INFO] 2021-07-09 16:41:57,022 [run_pretraining.py:  512]:	********exe.run_20******* 
[INFO] 2021-07-09 16:41:59,298 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:59,299 [run_pretraining.py:  534]:	loss/total_loss, 10.353547096252441, 21
[INFO] 2021-07-09 16:41:59,299 [run_pretraining.py:  535]:	loss/mlm_loss, 10.353547096252441, 21
[INFO] 2021-07-09 16:41:59,299 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0000000233721948e-07, 21
[INFO] 2021-07-09 16:41:59,299 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 21
[INFO] 2021-07-09 16:41:59,299 [run_pretraining.py:  558]:	worker_index: 6, step: 21, cost: 10.353547, mlm loss: 10.353547, speed: 0.439335 steps/s, speed: 3.514679 samples/s, speed: 1799.515592 tokens/s, learning rate: 2.000e-07, loss_scalings: 26214.400391, pp_loss: 10.297891
[INFO] 2021-07-09 16:41:59,299 [run_pretraining.py:  512]:	********exe.run_21******* 
[INFO] 2021-07-09 16:42:01,592 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:01,593 [run_pretraining.py:  534]:	loss/total_loss, 10.297382354736328, 22
[INFO] 2021-07-09 16:42:01,593 [run_pretraining.py:  535]:	loss/mlm_loss, 10.297382354736328, 22
[INFO] 2021-07-09 16:42:01,593 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0999998184834112e-07, 22
[INFO] 2021-07-09 16:42:01,593 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 22
[INFO] 2021-07-09 16:42:01,593 [run_pretraining.py:  558]:	worker_index: 6, step: 22, cost: 10.297382, mlm loss: 10.297382, speed: 0.436059 steps/s, speed: 3.488469 samples/s, speed: 1786.096308 tokens/s, learning rate: 2.100e-07, loss_scalings: 26214.400391, pp_loss: 10.292263
[INFO] 2021-07-09 16:42:01,593 [run_pretraining.py:  512]:	********exe.run_22******* 
[INFO] 2021-07-09 16:42:03,812 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:03,812 [run_pretraining.py:  534]:	loss/total_loss, 10.246011734008789, 23
[INFO] 2021-07-09 16:42:03,813 [run_pretraining.py:  535]:	loss/mlm_loss, 10.246011734008789, 23
[INFO] 2021-07-09 16:42:03,813 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.199999897811722e-07, 23
[INFO] 2021-07-09 16:42:03,813 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 23
[INFO] 2021-07-09 16:42:03,813 [run_pretraining.py:  558]:	worker_index: 6, step: 23, cost: 10.246012, mlm loss: 10.246012, speed: 0.450647 steps/s, speed: 3.605174 samples/s, speed: 1845.849266 tokens/s, learning rate: 2.200e-07, loss_scalings: 26214.400391, pp_loss: 10.321877
[INFO] 2021-07-09 16:42:03,813 [run_pretraining.py:  512]:	********exe.run_23******* 
[INFO] 2021-07-09 16:42:06,001 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:06,002 [run_pretraining.py:  534]:	loss/total_loss, 10.274042129516602, 24
[INFO] 2021-07-09 16:42:06,002 [run_pretraining.py:  535]:	loss/mlm_loss, 10.274042129516602, 24
[INFO] 2021-07-09 16:42:06,002 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2999999771400326e-07, 24
[INFO] 2021-07-09 16:42:06,002 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 24
[INFO] 2021-07-09 16:42:06,002 [run_pretraining.py:  558]:	worker_index: 6, step: 24, cost: 10.274042, mlm loss: 10.274042, speed: 0.456938 steps/s, speed: 3.655504 samples/s, speed: 1871.618131 tokens/s, learning rate: 2.300e-07, loss_scalings: 26214.400391, pp_loss: 10.305044
[INFO] 2021-07-09 16:42:06,002 [run_pretraining.py:  512]:	********exe.run_24******* 
[INFO] 2021-07-09 16:42:08,203 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:08,204 [run_pretraining.py:  534]:	loss/total_loss, 10.324542999267578, 25
[INFO] 2021-07-09 16:42:08,204 [run_pretraining.py:  535]:	loss/mlm_loss, 10.324542999267578, 25
[INFO] 2021-07-09 16:42:08,204 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.399999914359796e-07, 25
[INFO] 2021-07-09 16:42:08,204 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 25
[INFO] 2021-07-09 16:42:08,204 [run_pretraining.py:  558]:	worker_index: 6, step: 25, cost: 10.324543, mlm loss: 10.324543, speed: 0.454187 steps/s, speed: 3.633498 samples/s, speed: 1860.351025 tokens/s, learning rate: 2.400e-07, loss_scalings: 26214.400391, pp_loss: 10.306377
[INFO] 2021-07-09 16:42:08,204 [run_pretraining.py:  512]:	********exe.run_25******* 
[INFO] 2021-07-09 16:42:10,478 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:10,478 [run_pretraining.py:  534]:	loss/total_loss, 10.220308303833008, 26
[INFO] 2021-07-09 16:42:10,479 [run_pretraining.py:  535]:	loss/mlm_loss, 10.220308303833008, 26
[INFO] 2021-07-09 16:42:10,479 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.499999993688107e-07, 26
[INFO] 2021-07-09 16:42:10,479 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 26
[INFO] 2021-07-09 16:42:10,479 [run_pretraining.py:  558]:	worker_index: 6, step: 26, cost: 10.220308, mlm loss: 10.220308, speed: 0.439786 steps/s, speed: 3.518290 samples/s, speed: 1801.364705 tokens/s, learning rate: 2.500e-07, loss_scalings: 26214.400391, pp_loss: 10.228978
[INFO] 2021-07-09 16:42:10,479 [run_pretraining.py:  512]:	********exe.run_26******* 
[INFO] 2021-07-09 16:42:12,716 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:12,717 [run_pretraining.py:  534]:	loss/total_loss, 10.21624755859375, 27
[INFO] 2021-07-09 16:42:12,717 [run_pretraining.py:  535]:	loss/mlm_loss, 10.21624755859375, 27
[INFO] 2021-07-09 16:42:12,717 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6000000730164174e-07, 27
[INFO] 2021-07-09 16:42:12,717 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 27
[INFO] 2021-07-09 16:42:12,717 [run_pretraining.py:  558]:	worker_index: 6, step: 27, cost: 10.216248, mlm loss: 10.216248, speed: 0.446863 steps/s, speed: 3.574905 samples/s, speed: 1830.351463 tokens/s, learning rate: 2.600e-07, loss_scalings: 26214.400391, pp_loss: 10.263000
[INFO] 2021-07-09 16:42:12,717 [run_pretraining.py:  512]:	********exe.run_27******* 
[INFO] 2021-07-09 16:42:14,987 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:14,988 [run_pretraining.py:  534]:	loss/total_loss, 10.143969535827637, 28
[INFO] 2021-07-09 16:42:14,988 [run_pretraining.py:  535]:	loss/mlm_loss, 10.143969535827637, 28
[INFO] 2021-07-09 16:42:14,988 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.699999868127634e-07, 28
[INFO] 2021-07-09 16:42:14,988 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 28
[INFO] 2021-07-09 16:42:14,988 [run_pretraining.py:  558]:	worker_index: 6, step: 28, cost: 10.143970, mlm loss: 10.143970, speed: 0.440487 steps/s, speed: 3.523897 samples/s, speed: 1804.235321 tokens/s, learning rate: 2.700e-07, loss_scalings: 26214.400391, pp_loss: 10.200968
[INFO] 2021-07-09 16:42:14,988 [run_pretraining.py:  512]:	********exe.run_28******* 
[INFO] 2021-07-09 16:42:17,302 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:17,302 [run_pretraining.py:  534]:	loss/total_loss, 10.361747741699219, 29
[INFO] 2021-07-09 16:42:17,302 [run_pretraining.py:  535]:	loss/mlm_loss, 10.361747741699219, 29
[INFO] 2021-07-09 16:42:17,303 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7999999474559445e-07, 29
[INFO] 2021-07-09 16:42:17,303 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 29
[INFO] 2021-07-09 16:42:17,303 [run_pretraining.py:  558]:	worker_index: 6, step: 29, cost: 10.361748, mlm loss: 10.361748, speed: 0.432185 steps/s, speed: 3.457478 samples/s, speed: 1770.228668 tokens/s, learning rate: 2.800e-07, loss_scalings: 26214.400391, pp_loss: 10.218809
[INFO] 2021-07-09 16:42:17,303 [run_pretraining.py:  512]:	********exe.run_29******* 
[INFO] 2021-07-09 16:42:19,512 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:19,512 [run_pretraining.py:  534]:	loss/total_loss, 10.332469940185547, 30
[INFO] 2021-07-09 16:42:19,513 [run_pretraining.py:  535]:	loss/mlm_loss, 10.332469940185547, 30
[INFO] 2021-07-09 16:42:19,513 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.900000026784255e-07, 30
[INFO] 2021-07-09 16:42:19,513 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 30
[INFO] 2021-07-09 16:42:19,513 [run_pretraining.py:  558]:	worker_index: 6, step: 30, cost: 10.332470, mlm loss: 10.332470, speed: 0.452606 steps/s, speed: 3.620847 samples/s, speed: 1853.873431 tokens/s, learning rate: 2.900e-07, loss_scalings: 26214.400391, pp_loss: 10.207331
[INFO] 2021-07-09 16:42:19,513 [run_pretraining.py:  512]:	********exe.run_30******* 
[INFO] 2021-07-09 16:42:21,711 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:21,711 [run_pretraining.py:  534]:	loss/total_loss, 10.292210578918457, 31
[INFO] 2021-07-09 16:42:21,711 [run_pretraining.py:  535]:	loss/mlm_loss, 10.292210578918457, 31
[INFO] 2021-07-09 16:42:21,711 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9999998218954715e-07, 31
[INFO] 2021-07-09 16:42:21,711 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 31
[INFO] 2021-07-09 16:42:21,712 [run_pretraining.py:  558]:	worker_index: 6, step: 31, cost: 10.292211, mlm loss: 10.292211, speed: 0.454947 steps/s, speed: 3.639575 samples/s, speed: 1863.462396 tokens/s, learning rate: 3.000e-07, loss_scalings: 26214.400391, pp_loss: 10.170684
[INFO] 2021-07-09 16:42:21,712 [run_pretraining.py:  512]:	********exe.run_31******* 
[INFO] 2021-07-09 16:42:23,903 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:23,904 [run_pretraining.py:  534]:	loss/total_loss, 10.258636474609375, 32
[INFO] 2021-07-09 16:42:23,904 [run_pretraining.py:  535]:	loss/mlm_loss, 10.258636474609375, 32
[INFO] 2021-07-09 16:42:23,904 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.099999901223782e-07, 32
[INFO] 2021-07-09 16:42:23,904 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 32
[INFO] 2021-07-09 16:42:23,904 [run_pretraining.py:  558]:	worker_index: 6, step: 32, cost: 10.258636, mlm loss: 10.258636, speed: 0.456171 steps/s, speed: 3.649370 samples/s, speed: 1868.477659 tokens/s, learning rate: 3.100e-07, loss_scalings: 26214.400391, pp_loss: 10.185445
[INFO] 2021-07-09 16:42:23,905 [run_pretraining.py:  512]:	********exe.run_32******* 
[INFO] 2021-07-09 16:42:26,114 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:26,114 [run_pretraining.py:  534]:	loss/total_loss, 10.242889404296875, 33
[INFO] 2021-07-09 16:42:26,115 [run_pretraining.py:  535]:	loss/mlm_loss, 10.242889404296875, 33
[INFO] 2021-07-09 16:42:26,115 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.1999996963349986e-07, 33
[INFO] 2021-07-09 16:42:26,115 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 33
[INFO] 2021-07-09 16:42:26,115 [run_pretraining.py:  558]:	worker_index: 6, step: 33, cost: 10.242889, mlm loss: 10.242889, speed: 0.452563 steps/s, speed: 3.620507 samples/s, speed: 1853.699803 tokens/s, learning rate: 3.200e-07, loss_scalings: 26214.400391, pp_loss: 10.188708
[INFO] 2021-07-09 16:42:26,115 [run_pretraining.py:  512]:	********exe.run_33******* 
[INFO] 2021-07-09 16:42:28,328 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:28,330 [run_pretraining.py:  534]:	loss/total_loss, 10.114789009094238, 34
[INFO] 2021-07-09 16:42:28,330 [run_pretraining.py:  535]:	loss/mlm_loss, 10.114789009094238, 34
[INFO] 2021-07-09 16:42:28,330 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.2999997756633093e-07, 34
[INFO] 2021-07-09 16:42:28,330 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 34
[INFO] 2021-07-09 16:42:28,330 [run_pretraining.py:  558]:	worker_index: 6, step: 34, cost: 10.114789, mlm loss: 10.114789, speed: 0.451576 steps/s, speed: 3.612605 samples/s, speed: 1849.653783 tokens/s, learning rate: 3.300e-07, loss_scalings: 26214.400391, pp_loss: 10.149170
[INFO] 2021-07-09 16:42:28,330 [run_pretraining.py:  512]:	********exe.run_34******* 
[INFO] 2021-07-09 16:42:30,587 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:30,588 [run_pretraining.py:  534]:	loss/total_loss, 9.960284233093262, 35
[INFO] 2021-07-09 16:42:30,588 [run_pretraining.py:  535]:	loss/mlm_loss, 9.960284233093262, 35
[INFO] 2021-07-09 16:42:30,588 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.39999985499162e-07, 35
[INFO] 2021-07-09 16:42:30,588 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 35
[INFO] 2021-07-09 16:42:30,588 [run_pretraining.py:  558]:	worker_index: 6, step: 35, cost: 9.960284, mlm loss: 9.960284, speed: 0.442957 steps/s, speed: 3.543654 samples/s, speed: 1814.351097 tokens/s, learning rate: 3.400e-07, loss_scalings: 26214.400391, pp_loss: 10.141825
[INFO] 2021-07-09 16:42:30,588 [run_pretraining.py:  512]:	********exe.run_35******* 
[INFO] 2021-07-09 16:42:32,705 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:32,706 [run_pretraining.py:  534]:	loss/total_loss, 10.2828369140625, 36
[INFO] 2021-07-09 16:42:32,706 [run_pretraining.py:  535]:	loss/mlm_loss, 10.2828369140625, 36
[INFO] 2021-07-09 16:42:32,706 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.4999999343199306e-07, 36
[INFO] 2021-07-09 16:42:32,706 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 36
[INFO] 2021-07-09 16:42:32,706 [run_pretraining.py:  558]:	worker_index: 6, step: 36, cost: 10.282837, mlm loss: 10.282837, speed: 0.472233 steps/s, speed: 3.777861 samples/s, speed: 1934.264803 tokens/s, learning rate: 3.500e-07, loss_scalings: 26214.400391, pp_loss: 10.095230
[INFO] 2021-07-09 16:42:32,707 [run_pretraining.py:  512]:	********exe.run_36******* 
[INFO] 2021-07-09 16:42:34,807 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:34,808 [run_pretraining.py:  534]:	loss/total_loss, 10.218990325927734, 37
[INFO] 2021-07-09 16:42:34,808 [run_pretraining.py:  535]:	loss/mlm_loss, 10.218990325927734, 37
[INFO] 2021-07-09 16:42:34,808 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.599999729431147e-07, 37
[INFO] 2021-07-09 16:42:34,808 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 37
[INFO] 2021-07-09 16:42:34,808 [run_pretraining.py:  558]:	worker_index: 6, step: 37, cost: 10.218990, mlm loss: 10.218990, speed: 0.475947 steps/s, speed: 3.807573 samples/s, speed: 1949.477420 tokens/s, learning rate: 3.600e-07, loss_scalings: 26214.400391, pp_loss: 10.076483
[INFO] 2021-07-09 16:42:34,808 [run_pretraining.py:  512]:	********exe.run_37******* 
[INFO] 2021-07-09 16:42:36,885 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:36,885 [run_pretraining.py:  534]:	loss/total_loss, 9.943641662597656, 38
[INFO] 2021-07-09 16:42:36,885 [run_pretraining.py:  535]:	loss/mlm_loss, 9.943641662597656, 38
[INFO] 2021-07-09 16:42:36,885 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.6999998087594577e-07, 38
[INFO] 2021-07-09 16:42:36,886 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 38
[INFO] 2021-07-09 16:42:36,886 [run_pretraining.py:  558]:	worker_index: 6, step: 38, cost: 9.943642, mlm loss: 9.943642, speed: 0.481524 steps/s, speed: 3.852192 samples/s, speed: 1972.322432 tokens/s, learning rate: 3.700e-07, loss_scalings: 26214.400391, pp_loss: 10.013751
[INFO] 2021-07-09 16:42:36,886 [run_pretraining.py:  512]:	********exe.run_38******* 
[INFO] 2021-07-09 16:42:38,985 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:38,986 [run_pretraining.py:  534]:	loss/total_loss, 9.903963088989258, 39
[INFO] 2021-07-09 16:42:38,986 [run_pretraining.py:  535]:	loss/mlm_loss, 9.903963088989258, 39
[INFO] 2021-07-09 16:42:38,986 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.7999998880877683e-07, 39
[INFO] 2021-07-09 16:42:38,986 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 39
[INFO] 2021-07-09 16:42:38,986 [run_pretraining.py:  558]:	worker_index: 6, step: 39, cost: 9.903963, mlm loss: 9.903963, speed: 0.476206 steps/s, speed: 3.809646 samples/s, speed: 1950.538949 tokens/s, learning rate: 3.800e-07, loss_scalings: 26214.400391, pp_loss: 10.020010
[INFO] 2021-07-09 16:42:38,986 [run_pretraining.py:  512]:	********exe.run_39******* 
[INFO] 2021-07-09 16:42:41,048 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:41,049 [run_pretraining.py:  534]:	loss/total_loss, 10.197979927062988, 40
[INFO] 2021-07-09 16:42:41,049 [run_pretraining.py:  535]:	loss/mlm_loss, 10.197979927062988, 40
[INFO] 2021-07-09 16:42:41,049 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.8999996831989847e-07, 40
[INFO] 2021-07-09 16:42:41,049 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 40
[INFO] 2021-07-09 16:42:41,049 [run_pretraining.py:  558]:	worker_index: 6, step: 40, cost: 10.197980, mlm loss: 10.197980, speed: 0.484846 steps/s, speed: 3.878767 samples/s, speed: 1985.928834 tokens/s, learning rate: 3.900e-07, loss_scalings: 26214.400391, pp_loss: 9.994089
[INFO] 2021-07-09 16:42:41,049 [run_pretraining.py:  512]:	********exe.run_40******* 
[INFO] 2021-07-09 16:42:43,121 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:43,122 [run_pretraining.py:  534]:	loss/total_loss, 9.818868637084961, 41
[INFO] 2021-07-09 16:42:43,122 [run_pretraining.py:  535]:	loss/mlm_loss, 9.818868637084961, 41
[INFO] 2021-07-09 16:42:43,122 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.0000000467443897e-07, 41
[INFO] 2021-07-09 16:42:43,122 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 41
[INFO] 2021-07-09 16:42:43,122 [run_pretraining.py:  558]:	worker_index: 6, step: 41, cost: 9.818869, mlm loss: 9.818869, speed: 0.482585 steps/s, speed: 3.860682 samples/s, speed: 1976.669278 tokens/s, learning rate: 4.000e-07, loss_scalings: 26214.400391, pp_loss: 9.947783
[INFO] 2021-07-09 16:42:43,122 [run_pretraining.py:  512]:	********exe.run_41******* 
[INFO] 2021-07-09 16:42:45,193 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:45,194 [run_pretraining.py:  534]:	loss/total_loss, 9.959683418273926, 42
[INFO] 2021-07-09 16:42:45,194 [run_pretraining.py:  535]:	loss/mlm_loss, 9.959683418273926, 42
[INFO] 2021-07-09 16:42:45,194 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.099999841855606e-07, 42
[INFO] 2021-07-09 16:42:45,194 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 42
[INFO] 2021-07-09 16:42:45,194 [run_pretraining.py:  558]:	worker_index: 6, step: 42, cost: 9.959683, mlm loss: 9.959683, speed: 0.482762 steps/s, speed: 3.862098 samples/s, speed: 1977.394137 tokens/s, learning rate: 4.100e-07, loss_scalings: 26214.400391, pp_loss: 9.878301
[INFO] 2021-07-09 16:42:45,194 [run_pretraining.py:  512]:	********exe.run_42******* 
[INFO] 2021-07-09 16:42:47,287 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:47,288 [run_pretraining.py:  534]:	loss/total_loss, 10.046756744384766, 43
[INFO] 2021-07-09 16:42:47,288 [run_pretraining.py:  535]:	loss/mlm_loss, 10.046756744384766, 43
[INFO] 2021-07-09 16:42:47,288 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.1999996369668224e-07, 43
[INFO] 2021-07-09 16:42:47,288 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 43
[INFO] 2021-07-09 16:42:47,288 [run_pretraining.py:  558]:	worker_index: 6, step: 43, cost: 10.046757, mlm loss: 10.046757, speed: 0.477715 steps/s, speed: 3.821718 samples/s, speed: 1956.719627 tokens/s, learning rate: 4.200e-07, loss_scalings: 26214.400391, pp_loss: 9.979736
[INFO] 2021-07-09 16:42:47,288 [run_pretraining.py:  512]:	********exe.run_43******* 
[INFO] 2021-07-09 16:42:49,500 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:49,501 [run_pretraining.py:  534]:	loss/total_loss, 9.849871635437012, 44
[INFO] 2021-07-09 16:42:49,501 [run_pretraining.py:  535]:	loss/mlm_loss, 9.849871635437012, 44
[INFO] 2021-07-09 16:42:49,501 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.3000000005122274e-07, 44
[INFO] 2021-07-09 16:42:49,501 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 44
[INFO] 2021-07-09 16:42:49,501 [run_pretraining.py:  558]:	worker_index: 6, step: 44, cost: 9.849872, mlm loss: 9.849872, speed: 0.452017 steps/s, speed: 3.616133 samples/s, speed: 1851.460163 tokens/s, learning rate: 4.300e-07, loss_scalings: 26214.400391, pp_loss: 9.910582
[INFO] 2021-07-09 16:42:49,501 [run_pretraining.py:  512]:	********exe.run_44******* 
[INFO] 2021-07-09 16:42:51,665 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:51,666 [run_pretraining.py:  534]:	loss/total_loss, 9.689342498779297, 45
[INFO] 2021-07-09 16:42:51,666 [run_pretraining.py:  535]:	loss/mlm_loss, 9.689342498779297, 45
[INFO] 2021-07-09 16:42:51,666 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.399999795623444e-07, 45
[INFO] 2021-07-09 16:42:51,666 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 45
[INFO] 2021-07-09 16:42:51,666 [run_pretraining.py:  558]:	worker_index: 6, step: 45, cost: 9.689342, mlm loss: 9.689342, speed: 0.462004 steps/s, speed: 3.696032 samples/s, speed: 1892.368485 tokens/s, learning rate: 4.400e-07, loss_scalings: 26214.400391, pp_loss: 9.947346
[INFO] 2021-07-09 16:42:51,667 [run_pretraining.py:  512]:	********exe.run_45******* 
[INFO] 2021-07-09 16:42:53,849 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:53,850 [run_pretraining.py:  534]:	loss/total_loss, 9.885746955871582, 46
[INFO] 2021-07-09 16:42:53,850 [run_pretraining.py:  535]:	loss/mlm_loss, 9.885746955871582, 46
[INFO] 2021-07-09 16:42:53,850 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.49999959073466e-07, 46
[INFO] 2021-07-09 16:42:53,850 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 46
[INFO] 2021-07-09 16:42:53,850 [run_pretraining.py:  558]:	worker_index: 6, step: 46, cost: 9.885747, mlm loss: 9.885747, speed: 0.458089 steps/s, speed: 3.664715 samples/s, speed: 1876.333928 tokens/s, learning rate: 4.500e-07, loss_scalings: 26214.400391, pp_loss: 9.871219
[INFO] 2021-07-09 16:42:53,850 [run_pretraining.py:  512]:	********exe.run_46******* 
[INFO] 2021-07-09 16:42:56,094 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:56,095 [run_pretraining.py:  534]:	loss/total_loss, 9.844459533691406, 47
[INFO] 2021-07-09 16:42:56,095 [run_pretraining.py:  535]:	loss/mlm_loss, 9.844459533691406, 47
[INFO] 2021-07-09 16:42:56,095 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.599999954280065e-07, 47
[INFO] 2021-07-09 16:42:56,095 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 47
[INFO] 2021-07-09 16:42:56,095 [run_pretraining.py:  558]:	worker_index: 6, step: 47, cost: 9.844460, mlm loss: 9.844460, speed: 0.445530 steps/s, speed: 3.564241 samples/s, speed: 1824.891431 tokens/s, learning rate: 4.600e-07, loss_scalings: 26214.400391, pp_loss: 9.830351
[INFO] 2021-07-09 16:42:56,096 [run_pretraining.py:  512]:	********exe.run_47******* 
[INFO] 2021-07-09 16:42:58,370 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:58,370 [run_pretraining.py:  534]:	loss/total_loss, 9.93977165222168, 48
[INFO] 2021-07-09 16:42:58,370 [run_pretraining.py:  535]:	loss/mlm_loss, 9.93977165222168, 48
[INFO] 2021-07-09 16:42:58,370 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.6999997493912815e-07, 48
[INFO] 2021-07-09 16:42:58,370 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 48
[INFO] 2021-07-09 16:42:58,371 [run_pretraining.py:  558]:	worker_index: 6, step: 48, cost: 9.939772, mlm loss: 9.939772, speed: 0.439669 steps/s, speed: 3.517351 samples/s, speed: 1800.883570 tokens/s, learning rate: 4.700e-07, loss_scalings: 26214.400391, pp_loss: 9.861168
[INFO] 2021-07-09 16:42:58,371 [run_pretraining.py:  512]:	********exe.run_48******* 
[INFO] 2021-07-09 16:43:00,602 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:00,602 [run_pretraining.py:  534]:	loss/total_loss, 9.782303810119629, 49
[INFO] 2021-07-09 16:43:00,603 [run_pretraining.py:  535]:	loss/mlm_loss, 9.782303810119629, 49
[INFO] 2021-07-09 16:43:00,603 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.799999828719592e-07, 49
[INFO] 2021-07-09 16:43:00,603 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 49
[INFO] 2021-07-09 16:43:00,603 [run_pretraining.py:  558]:	worker_index: 6, step: 49, cost: 9.782304, mlm loss: 9.782304, speed: 0.448123 steps/s, speed: 3.584981 samples/s, speed: 1835.510037 tokens/s, learning rate: 4.800e-07, loss_scalings: 26214.400391, pp_loss: 9.761581
[INFO] 2021-07-09 16:43:00,603 [run_pretraining.py:  512]:	********exe.run_49******* 
[INFO] 2021-07-09 16:43:02,956 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:02,957 [run_pretraining.py:  534]:	loss/total_loss, 9.776863098144531, 50
[INFO] 2021-07-09 16:43:02,957 [run_pretraining.py:  535]:	loss/mlm_loss, 9.776863098144531, 50
[INFO] 2021-07-09 16:43:02,957 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.899999908047903e-07, 50
[INFO] 2021-07-09 16:43:02,957 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 50
[INFO] 2021-07-09 16:43:02,957 [run_pretraining.py:  558]:	worker_index: 6, step: 50, cost: 9.776863, mlm loss: 9.776863, speed: 0.424878 steps/s, speed: 3.399024 samples/s, speed: 1740.300177 tokens/s, learning rate: 4.900e-07, loss_scalings: 26214.400391, pp_loss: 9.824812
[INFO] 2021-07-09 16:43:02,957 [run_pretraining.py:  512]:	********exe.run_50******* 
[INFO] 2021-07-09 16:43:05,155 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:05,156 [run_pretraining.py:  534]:	loss/total_loss, 9.823467254638672, 51
[INFO] 2021-07-09 16:43:05,156 [run_pretraining.py:  535]:	loss/mlm_loss, 9.823467254638672, 51
[INFO] 2021-07-09 16:43:05,156 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.999999987376214e-07, 51
[INFO] 2021-07-09 16:43:05,156 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 51
[INFO] 2021-07-09 16:43:05,157 [run_pretraining.py:  558]:	worker_index: 6, step: 51, cost: 9.823467, mlm loss: 9.823467, speed: 0.454792 steps/s, speed: 3.638339 samples/s, speed: 1862.829352 tokens/s, learning rate: 5.000e-07, loss_scalings: 26214.400391, pp_loss: 9.797018
[INFO] 2021-07-09 16:43:05,157 [run_pretraining.py:  512]:	********exe.run_51******* 
[INFO] 2021-07-09 16:43:07,437 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:07,438 [run_pretraining.py:  534]:	loss/total_loss, 9.734006881713867, 52
[INFO] 2021-07-09 16:43:07,438 [run_pretraining.py:  535]:	loss/mlm_loss, 9.734006881713867, 52
[INFO] 2021-07-09 16:43:07,438 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.100000066704524e-07, 52
[INFO] 2021-07-09 16:43:07,438 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 52
[INFO] 2021-07-09 16:43:07,438 [run_pretraining.py:  558]:	worker_index: 6, step: 52, cost: 9.734007, mlm loss: 9.734007, speed: 0.438418 steps/s, speed: 3.507341 samples/s, speed: 1795.758714 tokens/s, learning rate: 5.100e-07, loss_scalings: 26214.400391, pp_loss: 9.734827
[INFO] 2021-07-09 16:43:07,438 [run_pretraining.py:  512]:	********exe.run_52******* 
[INFO] 2021-07-09 16:43:09,643 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:09,644 [run_pretraining.py:  534]:	loss/total_loss, 9.62984561920166, 53
[INFO] 2021-07-09 16:43:09,644 [run_pretraining.py:  535]:	loss/mlm_loss, 9.62984561920166, 53
[INFO] 2021-07-09 16:43:09,644 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.200000146032835e-07, 53
[INFO] 2021-07-09 16:43:09,644 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 53
[INFO] 2021-07-09 16:43:09,644 [run_pretraining.py:  558]:	worker_index: 6, step: 53, cost: 9.629846, mlm loss: 9.629846, speed: 0.453419 steps/s, speed: 3.627348 samples/s, speed: 1857.202241 tokens/s, learning rate: 5.200e-07, loss_scalings: 26214.400391, pp_loss: 9.655467
[INFO] 2021-07-09 16:43:09,644 [run_pretraining.py:  512]:	********exe.run_53******* 
[INFO] 2021-07-09 16:43:11,966 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:11,967 [run_pretraining.py:  534]:	loss/total_loss, 9.808076858520508, 54
[INFO] 2021-07-09 16:43:11,967 [run_pretraining.py:  535]:	loss/mlm_loss, 9.808076858520508, 54
[INFO] 2021-07-09 16:43:11,967 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.299999656926957e-07, 54
[INFO] 2021-07-09 16:43:11,967 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 54
[INFO] 2021-07-09 16:43:11,967 [run_pretraining.py:  558]:	worker_index: 6, step: 54, cost: 9.808077, mlm loss: 9.808077, speed: 0.430604 steps/s, speed: 3.444833 samples/s, speed: 1763.754405 tokens/s, learning rate: 5.300e-07, loss_scalings: 26214.400391, pp_loss: 9.730674
[INFO] 2021-07-09 16:43:11,967 [run_pretraining.py:  512]:	********exe.run_54******* 
[INFO] 2021-07-09 16:43:14,171 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:14,171 [run_pretraining.py:  534]:	loss/total_loss, 9.652376174926758, 55
[INFO] 2021-07-09 16:43:14,171 [run_pretraining.py:  535]:	loss/mlm_loss, 9.652376174926758, 55
[INFO] 2021-07-09 16:43:14,172 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.399999736255268e-07, 55
[INFO] 2021-07-09 16:43:14,172 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 55
[INFO] 2021-07-09 16:43:14,172 [run_pretraining.py:  558]:	worker_index: 6, step: 55, cost: 9.652376, mlm loss: 9.652376, speed: 0.453807 steps/s, speed: 3.630460 samples/s, speed: 1858.795310 tokens/s, learning rate: 5.400e-07, loss_scalings: 26214.400391, pp_loss: 9.655045
[INFO] 2021-07-09 16:43:14,172 [run_pretraining.py:  512]:	********exe.run_55******* 
[INFO] 2021-07-09 16:43:16,406 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:16,406 [run_pretraining.py:  534]:	loss/total_loss, 9.696671485900879, 56
[INFO] 2021-07-09 16:43:16,406 [run_pretraining.py:  535]:	loss/mlm_loss, 9.696671485900879, 56
[INFO] 2021-07-09 16:43:16,407 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.499999815583578e-07, 56
[INFO] 2021-07-09 16:43:16,407 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 56
[INFO] 2021-07-09 16:43:16,407 [run_pretraining.py:  558]:	worker_index: 6, step: 56, cost: 9.696671, mlm loss: 9.696671, speed: 0.447563 steps/s, speed: 3.580508 samples/s, speed: 1833.220012 tokens/s, learning rate: 5.500e-07, loss_scalings: 26214.400391, pp_loss: 9.597393
[INFO] 2021-07-09 16:43:16,407 [run_pretraining.py:  512]:	********exe.run_56******* 
[INFO] 2021-07-09 16:43:18,612 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:18,613 [run_pretraining.py:  534]:	loss/total_loss, 9.51992130279541, 57
[INFO] 2021-07-09 16:43:18,613 [run_pretraining.py:  535]:	loss/mlm_loss, 9.51992130279541, 57
[INFO] 2021-07-09 16:43:18,613 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.599999894911889e-07, 57
[INFO] 2021-07-09 16:43:18,613 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 57
[INFO] 2021-07-09 16:43:18,613 [run_pretraining.py:  558]:	worker_index: 6, step: 57, cost: 9.519921, mlm loss: 9.519921, speed: 0.453330 steps/s, speed: 3.626642 samples/s, speed: 1856.840926 tokens/s, learning rate: 5.600e-07, loss_scalings: 26214.400391, pp_loss: 9.573026
[INFO] 2021-07-09 16:43:18,613 [run_pretraining.py:  512]:	********exe.run_57******* 
[INFO] 2021-07-09 16:43:20,792 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:20,792 [run_pretraining.py:  534]:	loss/total_loss, 9.526901245117188, 58
[INFO] 2021-07-09 16:43:20,792 [run_pretraining.py:  535]:	loss/mlm_loss, 9.526901245117188, 58
[INFO] 2021-07-09 16:43:20,793 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.6999999742402e-07, 58
[INFO] 2021-07-09 16:43:20,793 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 58
[INFO] 2021-07-09 16:43:20,793 [run_pretraining.py:  558]:	worker_index: 6, step: 58, cost: 9.526901, mlm loss: 9.526901, speed: 0.458988 steps/s, speed: 3.671901 samples/s, speed: 1880.013226 tokens/s, learning rate: 5.700e-07, loss_scalings: 26214.400391, pp_loss: 9.521287
[INFO] 2021-07-09 16:43:20,793 [run_pretraining.py:  512]:	********exe.run_58******* 
[INFO] 2021-07-09 16:43:23,038 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:23,039 [run_pretraining.py:  534]:	loss/total_loss, 9.309061050415039, 59
[INFO] 2021-07-09 16:43:23,039 [run_pretraining.py:  535]:	loss/mlm_loss, 9.309061050415039, 59
[INFO] 2021-07-09 16:43:23,039 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.80000005356851e-07, 59
[INFO] 2021-07-09 16:43:23,039 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 59
[INFO] 2021-07-09 16:43:23,039 [run_pretraining.py:  558]:	worker_index: 6, step: 59, cost: 9.309061, mlm loss: 9.309061, speed: 0.445241 steps/s, speed: 3.561930 samples/s, speed: 1823.708194 tokens/s, learning rate: 5.800e-07, loss_scalings: 26214.400391, pp_loss: 9.496099
[INFO] 2021-07-09 16:43:23,039 [run_pretraining.py:  512]:	********exe.run_59******* 
[INFO] 2021-07-09 16:43:25,249 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:25,250 [run_pretraining.py:  534]:	loss/total_loss, 9.538415908813477, 60
[INFO] 2021-07-09 16:43:25,250 [run_pretraining.py:  535]:	loss/mlm_loss, 9.538415908813477, 60
[INFO] 2021-07-09 16:43:25,250 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.900000132896821e-07, 60
[INFO] 2021-07-09 16:43:25,250 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 60
[INFO] 2021-07-09 16:43:25,250 [run_pretraining.py:  558]:	worker_index: 6, step: 60, cost: 9.538416, mlm loss: 9.538416, speed: 0.452481 steps/s, speed: 3.619847 samples/s, speed: 1853.361642 tokens/s, learning rate: 5.900e-07, loss_scalings: 26214.400391, pp_loss: 9.583225
[INFO] 2021-07-09 16:43:25,250 [run_pretraining.py:  512]:	********exe.run_60******* 
[INFO] 2021-07-09 16:43:27,459 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:27,460 [run_pretraining.py:  534]:	loss/total_loss, 9.432880401611328, 61
[INFO] 2021-07-09 16:43:27,460 [run_pretraining.py:  535]:	loss/mlm_loss, 9.432880401611328, 61
[INFO] 2021-07-09 16:43:27,460 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.999999643790943e-07, 61
[INFO] 2021-07-09 16:43:27,460 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 61
[INFO] 2021-07-09 16:43:27,460 [run_pretraining.py:  558]:	worker_index: 6, step: 61, cost: 9.432880, mlm loss: 9.432880, speed: 0.452627 steps/s, speed: 3.621019 samples/s, speed: 1853.961858 tokens/s, learning rate: 6.000e-07, loss_scalings: 26214.400391, pp_loss: 9.443787
[INFO] 2021-07-09 16:43:27,460 [run_pretraining.py:  512]:	********exe.run_61******* 
[INFO] 2021-07-09 16:43:29,750 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:29,751 [run_pretraining.py:  534]:	loss/total_loss, 9.329610824584961, 62
[INFO] 2021-07-09 16:43:29,751 [run_pretraining.py:  535]:	loss/mlm_loss, 9.329610824584961, 62
[INFO] 2021-07-09 16:43:29,751 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.099999723119254e-07, 62
[INFO] 2021-07-09 16:43:29,751 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 62
[INFO] 2021-07-09 16:43:29,751 [run_pretraining.py:  558]:	worker_index: 6, step: 62, cost: 9.329611, mlm loss: 9.329611, speed: 0.436585 steps/s, speed: 3.492680 samples/s, speed: 1788.251988 tokens/s, learning rate: 6.100e-07, loss_scalings: 26214.400391, pp_loss: 9.405902
[INFO] 2021-07-09 16:43:29,751 [run_pretraining.py:  512]:	********exe.run_62******* 
[INFO] 2021-07-09 16:43:32,011 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:32,012 [run_pretraining.py:  534]:	loss/total_loss, 9.482845306396484, 63
[INFO] 2021-07-09 16:43:32,012 [run_pretraining.py:  535]:	loss/mlm_loss, 9.482845306396484, 63
[INFO] 2021-07-09 16:43:32,012 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.199999802447564e-07, 63
[INFO] 2021-07-09 16:43:32,012 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 63
[INFO] 2021-07-09 16:43:32,012 [run_pretraining.py:  558]:	worker_index: 6, step: 63, cost: 9.482845, mlm loss: 9.482845, speed: 0.442432 steps/s, speed: 3.539453 samples/s, speed: 1812.200122 tokens/s, learning rate: 6.200e-07, loss_scalings: 26214.400391, pp_loss: 9.404686
[INFO] 2021-07-09 16:43:32,012 [run_pretraining.py:  512]:	********exe.run_63******* 
[INFO] 2021-07-09 16:43:34,190 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:34,191 [run_pretraining.py:  534]:	loss/total_loss, 9.56548023223877, 64
[INFO] 2021-07-09 16:43:34,191 [run_pretraining.py:  535]:	loss/mlm_loss, 9.56548023223877, 64
[INFO] 2021-07-09 16:43:34,191 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.299999881775875e-07, 64
[INFO] 2021-07-09 16:43:34,191 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 64
[INFO] 2021-07-09 16:43:34,191 [run_pretraining.py:  558]:	worker_index: 6, step: 64, cost: 9.565480, mlm loss: 9.565480, speed: 0.459109 steps/s, speed: 3.672873 samples/s, speed: 1880.511230 tokens/s, learning rate: 6.300e-07, loss_scalings: 26214.400391, pp_loss: 9.379800
[INFO] 2021-07-09 16:43:34,191 [run_pretraining.py:  512]:	********exe.run_64******* 
[INFO] 2021-07-09 16:43:36,384 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:36,385 [run_pretraining.py:  534]:	loss/total_loss, 9.461698532104492, 65
[INFO] 2021-07-09 16:43:36,385 [run_pretraining.py:  535]:	loss/mlm_loss, 9.461698532104492, 65
[INFO] 2021-07-09 16:43:36,385 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.399999392669997e-07, 65
[INFO] 2021-07-09 16:43:36,385 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 65
[INFO] 2021-07-09 16:43:36,385 [run_pretraining.py:  558]:	worker_index: 6, step: 65, cost: 9.461699, mlm loss: 9.461699, speed: 0.455884 steps/s, speed: 3.647074 samples/s, speed: 1867.301784 tokens/s, learning rate: 6.400e-07, loss_scalings: 26214.400391, pp_loss: 9.317361
[INFO] 2021-07-09 16:43:36,385 [run_pretraining.py:  512]:	********exe.run_65******* 
[INFO] 2021-07-09 16:43:38,557 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:38,558 [run_pretraining.py:  534]:	loss/total_loss, 9.184977531433105, 66
[INFO] 2021-07-09 16:43:38,558 [run_pretraining.py:  535]:	loss/mlm_loss, 9.184977531433105, 66
[INFO] 2021-07-09 16:43:38,558 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.500000040432496e-07, 66
[INFO] 2021-07-09 16:43:38,558 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 66
[INFO] 2021-07-09 16:43:38,558 [run_pretraining.py:  558]:	worker_index: 6, step: 66, cost: 9.184978, mlm loss: 9.184978, speed: 0.460310 steps/s, speed: 3.682478 samples/s, speed: 1885.428837 tokens/s, learning rate: 6.500e-07, loss_scalings: 26214.400391, pp_loss: 9.247424
[INFO] 2021-07-09 16:43:38,558 [run_pretraining.py:  512]:	********exe.run_66******* 
[INFO] 2021-07-09 16:43:40,767 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:40,768 [run_pretraining.py:  534]:	loss/total_loss, 9.198469161987305, 67
[INFO] 2021-07-09 16:43:40,768 [run_pretraining.py:  535]:	loss/mlm_loss, 9.198469161987305, 67
[INFO] 2021-07-09 16:43:40,768 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.599999551326619e-07, 67
[INFO] 2021-07-09 16:43:40,768 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 67
[INFO] 2021-07-09 16:43:40,768 [run_pretraining.py:  558]:	worker_index: 6, step: 67, cost: 9.198469, mlm loss: 9.198469, speed: 0.452711 steps/s, speed: 3.621688 samples/s, speed: 1854.304040 tokens/s, learning rate: 6.600e-07, loss_scalings: 26214.400391, pp_loss: 9.222739
[INFO] 2021-07-09 16:43:40,768 [run_pretraining.py:  512]:	********exe.run_67******* 
[INFO] 2021-07-09 16:43:42,920 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:42,921 [run_pretraining.py:  534]:	loss/total_loss, 9.294855117797852, 68
[INFO] 2021-07-09 16:43:42,921 [run_pretraining.py:  535]:	loss/mlm_loss, 9.294855117797852, 68
[INFO] 2021-07-09 16:43:42,921 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.699999630654929e-07, 68
[INFO] 2021-07-09 16:43:42,921 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 68
[INFO] 2021-07-09 16:43:42,921 [run_pretraining.py:  558]:	worker_index: 6, step: 68, cost: 9.294855, mlm loss: 9.294855, speed: 0.464635 steps/s, speed: 3.717076 samples/s, speed: 1903.142933 tokens/s, learning rate: 6.700e-07, loss_scalings: 26214.400391, pp_loss: 9.239120
[INFO] 2021-07-09 16:43:42,921 [run_pretraining.py:  512]:	********exe.run_68******* 
[INFO] 2021-07-09 16:43:45,069 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:45,070 [run_pretraining.py:  534]:	loss/total_loss, 9.15182113647461, 69
[INFO] 2021-07-09 16:43:45,070 [run_pretraining.py:  535]:	loss/mlm_loss, 9.15182113647461, 69
[INFO] 2021-07-09 16:43:45,070 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.79999970998324e-07, 69
[INFO] 2021-07-09 16:43:45,070 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 69
[INFO] 2021-07-09 16:43:45,070 [run_pretraining.py:  558]:	worker_index: 6, step: 69, cost: 9.151821, mlm loss: 9.151821, speed: 0.465433 steps/s, speed: 3.723464 samples/s, speed: 1906.413597 tokens/s, learning rate: 6.800e-07, loss_scalings: 26214.400391, pp_loss: 9.128776
[INFO] 2021-07-09 16:43:45,070 [run_pretraining.py:  512]:	********exe.run_69******* 
[INFO] 2021-07-09 16:43:47,251 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:47,252 [run_pretraining.py:  534]:	loss/total_loss, 9.29576301574707, 70
[INFO] 2021-07-09 16:43:47,252 [run_pretraining.py:  535]:	loss/mlm_loss, 9.29576301574707, 70
[INFO] 2021-07-09 16:43:47,252 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.899999789311551e-07, 70
[INFO] 2021-07-09 16:43:47,252 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 70
[INFO] 2021-07-09 16:43:47,252 [run_pretraining.py:  558]:	worker_index: 6, step: 70, cost: 9.295763, mlm loss: 9.295763, speed: 0.458476 steps/s, speed: 3.667811 samples/s, speed: 1877.919152 tokens/s, learning rate: 6.900e-07, loss_scalings: 26214.400391, pp_loss: 9.206389
[INFO] 2021-07-09 16:43:47,252 [run_pretraining.py:  512]:	********exe.run_70******* 
[INFO] 2021-07-09 16:43:49,429 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:49,430 [run_pretraining.py:  534]:	loss/total_loss, 9.25436782836914, 71
[INFO] 2021-07-09 16:43:49,430 [run_pretraining.py:  535]:	loss/mlm_loss, 9.25436782836914, 71
[INFO] 2021-07-09 16:43:49,430 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.999999868639861e-07, 71
[INFO] 2021-07-09 16:43:49,430 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 71
[INFO] 2021-07-09 16:43:49,430 [run_pretraining.py:  558]:	worker_index: 6, step: 71, cost: 9.254368, mlm loss: 9.254368, speed: 0.459177 steps/s, speed: 3.673419 samples/s, speed: 1880.790392 tokens/s, learning rate: 7.000e-07, loss_scalings: 26214.400391, pp_loss: 9.116398
[INFO] 2021-07-09 16:43:49,431 [run_pretraining.py:  512]:	********exe.run_71******* 
[INFO] 2021-07-09 16:43:51,593 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:51,594 [run_pretraining.py:  534]:	loss/total_loss, 9.074151039123535, 72
[INFO] 2021-07-09 16:43:51,594 [run_pretraining.py:  535]:	loss/mlm_loss, 9.074151039123535, 72
[INFO] 2021-07-09 16:43:51,594 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.099999947968172e-07, 72
[INFO] 2021-07-09 16:43:51,594 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 72
[INFO] 2021-07-09 16:43:51,594 [run_pretraining.py:  558]:	worker_index: 6, step: 72, cost: 9.074151, mlm loss: 9.074151, speed: 0.462305 steps/s, speed: 3.698443 samples/s, speed: 1893.602659 tokens/s, learning rate: 7.100e-07, loss_scalings: 26214.400391, pp_loss: 9.044763
[INFO] 2021-07-09 16:43:51,594 [run_pretraining.py:  512]:	********exe.run_72******* 
[INFO] 2021-07-09 16:43:53,809 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:53,809 [run_pretraining.py:  534]:	loss/total_loss, 9.021068572998047, 73
[INFO] 2021-07-09 16:43:53,809 [run_pretraining.py:  535]:	loss/mlm_loss, 9.021068572998047, 73
[INFO] 2021-07-09 16:43:53,809 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.199999458862294e-07, 73
[INFO] 2021-07-09 16:43:53,810 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 73
[INFO] 2021-07-09 16:43:53,810 [run_pretraining.py:  558]:	worker_index: 6, step: 73, cost: 9.021069, mlm loss: 9.021069, speed: 0.451510 steps/s, speed: 3.612082 samples/s, speed: 1849.385977 tokens/s, learning rate: 7.200e-07, loss_scalings: 26214.400391, pp_loss: 9.025930
[INFO] 2021-07-09 16:43:53,810 [run_pretraining.py:  512]:	********exe.run_73******* 
[INFO] 2021-07-09 16:43:55,994 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:55,995 [run_pretraining.py:  534]:	loss/total_loss, 9.03065013885498, 74
[INFO] 2021-07-09 16:43:55,995 [run_pretraining.py:  535]:	loss/mlm_loss, 9.03065013885498, 74
[INFO] 2021-07-09 16:43:55,995 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.300000106624793e-07, 74
[INFO] 2021-07-09 16:43:55,995 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 74
[INFO] 2021-07-09 16:43:55,995 [run_pretraining.py:  558]:	worker_index: 6, step: 74, cost: 9.030650, mlm loss: 9.030650, speed: 0.457713 steps/s, speed: 3.661705 samples/s, speed: 1874.792910 tokens/s, learning rate: 7.300e-07, loss_scalings: 26214.400391, pp_loss: 9.027351
[INFO] 2021-07-09 16:43:55,995 [run_pretraining.py:  512]:	********exe.run_74******* 
[INFO] 2021-07-09 16:43:58,146 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:58,147 [run_pretraining.py:  534]:	loss/total_loss, 8.940560340881348, 75
[INFO] 2021-07-09 16:43:58,147 [run_pretraining.py:  535]:	loss/mlm_loss, 8.940560340881348, 75
[INFO] 2021-07-09 16:43:58,147 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.399999617518915e-07, 75
[INFO] 2021-07-09 16:43:58,147 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 75
[INFO] 2021-07-09 16:43:58,147 [run_pretraining.py:  558]:	worker_index: 6, step: 75, cost: 8.940560, mlm loss: 8.940560, speed: 0.464879 steps/s, speed: 3.719033 samples/s, speed: 1904.144670 tokens/s, learning rate: 7.400e-07, loss_scalings: 26214.400391, pp_loss: 8.961640
[INFO] 2021-07-09 16:43:58,147 [run_pretraining.py:  512]:	********exe.run_75******* 
[INFO] 2021-07-09 16:44:00,354 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:00,354 [run_pretraining.py:  534]:	loss/total_loss, 8.868660926818848, 76
[INFO] 2021-07-09 16:44:00,355 [run_pretraining.py:  535]:	loss/mlm_loss, 8.868660926818848, 76
[INFO] 2021-07-09 16:44:00,355 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.499999696847226e-07, 76
[INFO] 2021-07-09 16:44:00,355 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 76
[INFO] 2021-07-09 16:44:00,355 [run_pretraining.py:  558]:	worker_index: 6, step: 76, cost: 8.868661, mlm loss: 8.868661, speed: 0.453046 steps/s, speed: 3.624367 samples/s, speed: 1855.676039 tokens/s, learning rate: 7.500e-07, loss_scalings: 26214.400391, pp_loss: 8.957108
[INFO] 2021-07-09 16:44:00,355 [run_pretraining.py:  512]:	********exe.run_76******* 
[INFO] 2021-07-09 16:44:02,558 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:02,559 [run_pretraining.py:  534]:	loss/total_loss, 8.975998878479004, 77
[INFO] 2021-07-09 16:44:02,559 [run_pretraining.py:  535]:	loss/mlm_loss, 8.975998878479004, 77
[INFO] 2021-07-09 16:44:02,559 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.599999776175537e-07, 77
[INFO] 2021-07-09 16:44:02,559 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 77
[INFO] 2021-07-09 16:44:02,559 [run_pretraining.py:  558]:	worker_index: 6, step: 77, cost: 8.975999, mlm loss: 8.975999, speed: 0.453741 steps/s, speed: 3.629927 samples/s, speed: 1858.522438 tokens/s, learning rate: 7.600e-07, loss_scalings: 20971.521484, pp_loss: 8.849200
[INFO] 2021-07-09 16:44:02,560 [run_pretraining.py:  512]:	********exe.run_77******* 
[INFO] 2021-07-09 16:44:04,737 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:04,737 [run_pretraining.py:  534]:	loss/total_loss, 8.807706832885742, 78
[INFO] 2021-07-09 16:44:04,738 [run_pretraining.py:  535]:	loss/mlm_loss, 8.807706832885742, 78
[INFO] 2021-07-09 16:44:04,738 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.699999855503847e-07, 78
[INFO] 2021-07-09 16:44:04,738 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 78
[INFO] 2021-07-09 16:44:04,738 [run_pretraining.py:  558]:	worker_index: 6, step: 78, cost: 8.807707, mlm loss: 8.807707, speed: 0.459195 steps/s, speed: 3.673564 samples/s, speed: 1880.864725 tokens/s, learning rate: 7.700e-07, loss_scalings: 20971.521484, pp_loss: 8.848585
[INFO] 2021-07-09 16:44:04,738 [run_pretraining.py:  512]:	********exe.run_78******* 
[INFO] 2021-07-09 16:44:06,946 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:06,946 [run_pretraining.py:  534]:	loss/total_loss, 8.850285530090332, 79
[INFO] 2021-07-09 16:44:06,946 [run_pretraining.py:  535]:	loss/mlm_loss, 8.850285530090332, 79
[INFO] 2021-07-09 16:44:06,946 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.799999366397969e-07, 79
[INFO] 2021-07-09 16:44:06,947 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 79
[INFO] 2021-07-09 16:44:06,947 [run_pretraining.py:  558]:	worker_index: 6, step: 79, cost: 8.850286, mlm loss: 8.850286, speed: 0.452884 steps/s, speed: 3.623070 samples/s, speed: 1855.011818 tokens/s, learning rate: 7.800e-07, loss_scalings: 20971.521484, pp_loss: 8.887667
[INFO] 2021-07-09 16:44:06,947 [run_pretraining.py:  512]:	********exe.run_79******* 
[INFO] 2021-07-09 16:44:09,166 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:09,167 [run_pretraining.py:  534]:	loss/total_loss, 8.927638053894043, 80
[INFO] 2021-07-09 16:44:09,167 [run_pretraining.py:  535]:	loss/mlm_loss, 8.927638053894043, 80
[INFO] 2021-07-09 16:44:09,167 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.89999944572628e-07, 80
[INFO] 2021-07-09 16:44:09,167 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 80
[INFO] 2021-07-09 16:44:09,167 [run_pretraining.py:  558]:	worker_index: 6, step: 80, cost: 8.927638, mlm loss: 8.927638, speed: 0.450484 steps/s, speed: 3.603868 samples/s, speed: 1845.180566 tokens/s, learning rate: 7.900e-07, loss_scalings: 20971.521484, pp_loss: 8.853469
[INFO] 2021-07-09 16:44:09,167 [run_pretraining.py:  512]:	********exe.run_80******* 
[INFO] 2021-07-09 16:44:11,330 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:11,331 [run_pretraining.py:  534]:	loss/total_loss, 8.853771209716797, 81
[INFO] 2021-07-09 16:44:11,331 [run_pretraining.py:  535]:	loss/mlm_loss, 8.853771209716797, 81
[INFO] 2021-07-09 16:44:11,331 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.000000093488779e-07, 81
[INFO] 2021-07-09 16:44:11,331 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 81
[INFO] 2021-07-09 16:44:11,331 [run_pretraining.py:  558]:	worker_index: 6, step: 81, cost: 8.853771, mlm loss: 8.853771, speed: 0.462224 steps/s, speed: 3.697793 samples/s, speed: 1893.270022 tokens/s, learning rate: 8.000e-07, loss_scalings: 20971.521484, pp_loss: 8.727465
[INFO] 2021-07-09 16:44:11,331 [run_pretraining.py:  512]:	********exe.run_81******* 
[INFO] 2021-07-09 16:44:13,499 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:13,499 [run_pretraining.py:  534]:	loss/total_loss, 8.557161331176758, 82
[INFO] 2021-07-09 16:44:13,499 [run_pretraining.py:  535]:	loss/mlm_loss, 8.557161331176758, 82
[INFO] 2021-07-09 16:44:13,499 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.10000017281709e-07, 82
[INFO] 2021-07-09 16:44:13,499 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 82
[INFO] 2021-07-09 16:44:13,500 [run_pretraining.py:  558]:	worker_index: 6, step: 82, cost: 8.557161, mlm loss: 8.557161, speed: 0.461352 steps/s, speed: 3.690819 samples/s, speed: 1889.699157 tokens/s, learning rate: 8.100e-07, loss_scalings: 20971.521484, pp_loss: 8.733837
[INFO] 2021-07-09 16:44:13,500 [run_pretraining.py:  512]:	********exe.run_82******* 
[INFO] 2021-07-09 16:44:15,672 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:15,672 [run_pretraining.py:  534]:	loss/total_loss, 8.472926139831543, 83
[INFO] 2021-07-09 16:44:15,673 [run_pretraining.py:  535]:	loss/mlm_loss, 8.472926139831543, 83
[INFO] 2021-07-09 16:44:15,673 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.199999683711212e-07, 83
[INFO] 2021-07-09 16:44:15,673 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 83
[INFO] 2021-07-09 16:44:15,673 [run_pretraining.py:  558]:	worker_index: 6, step: 83, cost: 8.472926, mlm loss: 8.472926, speed: 0.460285 steps/s, speed: 3.682283 samples/s, speed: 1885.328900 tokens/s, learning rate: 8.200e-07, loss_scalings: 20971.521484, pp_loss: 8.650137
[INFO] 2021-07-09 16:44:15,673 [run_pretraining.py:  512]:	********exe.run_83******* 
[INFO] 2021-07-09 16:44:17,818 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:17,819 [run_pretraining.py:  534]:	loss/total_loss, 8.792435646057129, 84
[INFO] 2021-07-09 16:44:17,819 [run_pretraining.py:  535]:	loss/mlm_loss, 8.792435646057129, 84
[INFO] 2021-07-09 16:44:17,819 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.299999763039523e-07, 84
[INFO] 2021-07-09 16:44:17,819 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 84
[INFO] 2021-07-09 16:44:17,819 [run_pretraining.py:  558]:	worker_index: 6, step: 84, cost: 8.792436, mlm loss: 8.792436, speed: 0.466072 steps/s, speed: 3.728576 samples/s, speed: 1909.030682 tokens/s, learning rate: 8.300e-07, loss_scalings: 20971.521484, pp_loss: 8.701945
[INFO] 2021-07-09 16:44:17,819 [run_pretraining.py:  512]:	********exe.run_84******* 
[INFO] 2021-07-09 16:44:19,974 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:19,974 [run_pretraining.py:  534]:	loss/total_loss, 8.456295013427734, 85
[INFO] 2021-07-09 16:44:19,974 [run_pretraining.py:  535]:	loss/mlm_loss, 8.456295013427734, 85
[INFO] 2021-07-09 16:44:19,975 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.399999273933645e-07, 85
[INFO] 2021-07-09 16:44:19,975 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 85
[INFO] 2021-07-09 16:44:19,975 [run_pretraining.py:  558]:	worker_index: 6, step: 85, cost: 8.456295, mlm loss: 8.456295, speed: 0.464045 steps/s, speed: 3.712361 samples/s, speed: 1900.728886 tokens/s, learning rate: 8.400e-07, loss_scalings: 20971.521484, pp_loss: 8.630167
[INFO] 2021-07-09 16:44:19,975 [run_pretraining.py:  512]:	********exe.run_85******* 
[INFO] 2021-07-09 16:44:22,127 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:22,127 [run_pretraining.py:  534]:	loss/total_loss, 8.570169448852539, 86
[INFO] 2021-07-09 16:44:22,127 [run_pretraining.py:  535]:	loss/mlm_loss, 8.570169448852539, 86
[INFO] 2021-07-09 16:44:22,127 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.500000490130333e-07, 86
[INFO] 2021-07-09 16:44:22,128 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 86
[INFO] 2021-07-09 16:44:22,128 [run_pretraining.py:  558]:	worker_index: 6, step: 86, cost: 8.570169, mlm loss: 8.570169, speed: 0.464630 steps/s, speed: 3.717041 samples/s, speed: 1903.125224 tokens/s, learning rate: 8.500e-07, loss_scalings: 20971.521484, pp_loss: 8.578088
[INFO] 2021-07-09 16:44:22,128 [run_pretraining.py:  512]:	********exe.run_86******* 
[INFO] 2021-07-09 16:44:24,446 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:24,447 [run_pretraining.py:  534]:	loss/total_loss, 8.576759338378906, 87
[INFO] 2021-07-09 16:44:24,447 [run_pretraining.py:  535]:	loss/mlm_loss, 8.576759338378906, 87
[INFO] 2021-07-09 16:44:24,447 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.600000001024455e-07, 87
[INFO] 2021-07-09 16:44:24,447 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 87
[INFO] 2021-07-09 16:44:24,448 [run_pretraining.py:  558]:	worker_index: 6, step: 87, cost: 8.576759, mlm loss: 8.576759, speed: 0.431178 steps/s, speed: 3.449423 samples/s, speed: 1766.104434 tokens/s, learning rate: 8.600e-07, loss_scalings: 20971.521484, pp_loss: 8.616144
[INFO] 2021-07-09 16:44:24,448 [run_pretraining.py:  512]:	********exe.run_87******* 
[INFO] 2021-07-09 16:44:26,847 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:26,848 [run_pretraining.py:  534]:	loss/total_loss, 8.35925579071045, 88
[INFO] 2021-07-09 16:44:26,848 [run_pretraining.py:  535]:	loss/mlm_loss, 8.35925579071045, 88
[INFO] 2021-07-09 16:44:26,848 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.700000080352766e-07, 88
[INFO] 2021-07-09 16:44:26,848 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 88
[INFO] 2021-07-09 16:44:26,848 [run_pretraining.py:  558]:	worker_index: 6, step: 88, cost: 8.359256, mlm loss: 8.359256, speed: 0.416672 steps/s, speed: 3.333376 samples/s, speed: 1706.688470 tokens/s, learning rate: 8.700e-07, loss_scalings: 20971.521484, pp_loss: 8.469092
[INFO] 2021-07-09 16:44:26,848 [run_pretraining.py:  512]:	********exe.run_88******* 
[INFO] 2021-07-09 16:44:29,011 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:29,011 [run_pretraining.py:  534]:	loss/total_loss, 8.318459510803223, 89
[INFO] 2021-07-09 16:44:29,012 [run_pretraining.py:  535]:	loss/mlm_loss, 8.318459510803223, 89
[INFO] 2021-07-09 16:44:29,012 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.799999591246888e-07, 89
[INFO] 2021-07-09 16:44:29,012 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 89
[INFO] 2021-07-09 16:44:29,012 [run_pretraining.py:  558]:	worker_index: 6, step: 89, cost: 8.318460, mlm loss: 8.318460, speed: 0.462340 steps/s, speed: 3.698719 samples/s, speed: 1893.743971 tokens/s, learning rate: 8.800e-07, loss_scalings: 20971.521484, pp_loss: 8.411374
[INFO] 2021-07-09 16:44:29,012 [run_pretraining.py:  512]:	********exe.run_89******* 
[INFO] 2021-07-09 16:44:31,164 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:31,165 [run_pretraining.py:  534]:	loss/total_loss, 8.277024269104004, 90
[INFO] 2021-07-09 16:44:31,165 [run_pretraining.py:  535]:	loss/mlm_loss, 8.277024269104004, 90
[INFO] 2021-07-09 16:44:31,165 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.899999670575198e-07, 90
[INFO] 2021-07-09 16:44:31,165 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 90
[INFO] 2021-07-09 16:44:31,165 [run_pretraining.py:  558]:	worker_index: 6, step: 90, cost: 8.277024, mlm loss: 8.277024, speed: 0.464536 steps/s, speed: 3.716287 samples/s, speed: 1902.738867 tokens/s, learning rate: 8.900e-07, loss_scalings: 20971.521484, pp_loss: 8.429303
[INFO] 2021-07-09 16:44:31,165 [run_pretraining.py:  512]:	********exe.run_90******* 
[INFO] 2021-07-09 16:44:33,320 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:33,321 [run_pretraining.py:  534]:	loss/total_loss, 8.22352409362793, 91
[INFO] 2021-07-09 16:44:33,321 [run_pretraining.py:  535]:	loss/mlm_loss, 8.22352409362793, 91
[INFO] 2021-07-09 16:44:33,321 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.99999918146932e-07, 91
[INFO] 2021-07-09 16:44:33,321 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 91
[INFO] 2021-07-09 16:44:33,321 [run_pretraining.py:  558]:	worker_index: 6, step: 91, cost: 8.223524, mlm loss: 8.223524, speed: 0.463921 steps/s, speed: 3.711370 samples/s, speed: 1900.221589 tokens/s, learning rate: 9.000e-07, loss_scalings: 20971.521484, pp_loss: 8.364997
[INFO] 2021-07-09 16:44:33,322 [run_pretraining.py:  512]:	********exe.run_91******* 
[INFO] 2021-07-09 16:44:35,485 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:35,486 [run_pretraining.py:  534]:	loss/total_loss, 8.53672981262207, 92
[INFO] 2021-07-09 16:44:35,486 [run_pretraining.py:  535]:	loss/mlm_loss, 8.53672981262207, 92
[INFO] 2021-07-09 16:44:35,486 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.100000397666008e-07, 92
[INFO] 2021-07-09 16:44:35,486 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 92
[INFO] 2021-07-09 16:44:35,486 [run_pretraining.py:  558]:	worker_index: 6, step: 92, cost: 8.536730, mlm loss: 8.536730, speed: 0.462045 steps/s, speed: 3.696357 samples/s, speed: 1892.534630 tokens/s, learning rate: 9.100e-07, loss_scalings: 20971.521484, pp_loss: 8.433138
[INFO] 2021-07-09 16:44:35,486 [run_pretraining.py:  512]:	********exe.run_92******* 
[INFO] 2021-07-09 16:44:37,636 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:37,637 [run_pretraining.py:  534]:	loss/total_loss, 8.226313591003418, 93
[INFO] 2021-07-09 16:44:37,637 [run_pretraining.py:  535]:	loss/mlm_loss, 8.226313591003418, 93
[INFO] 2021-07-09 16:44:37,637 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.19999990856013e-07, 93
[INFO] 2021-07-09 16:44:37,637 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 93
[INFO] 2021-07-09 16:44:37,637 [run_pretraining.py:  558]:	worker_index: 6, step: 93, cost: 8.226314, mlm loss: 8.226314, speed: 0.465137 steps/s, speed: 3.721095 samples/s, speed: 1905.200703 tokens/s, learning rate: 9.200e-07, loss_scalings: 20971.521484, pp_loss: 8.327075
[INFO] 2021-07-09 16:44:37,637 [run_pretraining.py:  512]:	********exe.run_93******* 
[INFO] 2021-07-09 16:44:39,805 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:39,806 [run_pretraining.py:  534]:	loss/total_loss, 8.304817199707031, 94
[INFO] 2021-07-09 16:44:39,806 [run_pretraining.py:  535]:	loss/mlm_loss, 8.304817199707031, 94
[INFO] 2021-07-09 16:44:39,806 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.299999987888441e-07, 94
[INFO] 2021-07-09 16:44:39,806 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 94
[INFO] 2021-07-09 16:44:39,806 [run_pretraining.py:  558]:	worker_index: 6, step: 94, cost: 8.304817, mlm loss: 8.304817, speed: 0.461208 steps/s, speed: 3.689668 samples/s, speed: 1889.109857 tokens/s, learning rate: 9.300e-07, loss_scalings: 20971.521484, pp_loss: 8.370947
[INFO] 2021-07-09 16:44:39,806 [run_pretraining.py:  512]:	********exe.run_94******* 
[INFO] 2021-07-09 16:44:41,957 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:41,958 [run_pretraining.py:  534]:	loss/total_loss, 8.325434684753418, 95
[INFO] 2021-07-09 16:44:41,958 [run_pretraining.py:  535]:	loss/mlm_loss, 8.325434684753418, 95
[INFO] 2021-07-09 16:44:41,958 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.399999498782563e-07, 95
[INFO] 2021-07-09 16:44:41,958 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 95
[INFO] 2021-07-09 16:44:41,958 [run_pretraining.py:  558]:	worker_index: 6, step: 95, cost: 8.325435, mlm loss: 8.325435, speed: 0.464716 steps/s, speed: 3.717726 samples/s, speed: 1903.475674 tokens/s, learning rate: 9.400e-07, loss_scalings: 20971.521484, pp_loss: 8.219797
[INFO] 2021-07-09 16:44:41,959 [run_pretraining.py:  512]:	********exe.run_95******* 
[INFO] 2021-07-09 16:44:44,119 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:44,119 [run_pretraining.py:  534]:	loss/total_loss, 8.318580627441406, 96
[INFO] 2021-07-09 16:44:44,119 [run_pretraining.py:  535]:	loss/mlm_loss, 8.318580627441406, 96
[INFO] 2021-07-09 16:44:44,119 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.499999578110874e-07, 96
[INFO] 2021-07-09 16:44:44,119 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 96
[INFO] 2021-07-09 16:44:44,119 [run_pretraining.py:  558]:	worker_index: 6, step: 96, cost: 8.318581, mlm loss: 8.318581, speed: 0.462890 steps/s, speed: 3.703116 samples/s, speed: 1895.995488 tokens/s, learning rate: 9.500e-07, loss_scalings: 20971.521484, pp_loss: 8.268362
[INFO] 2021-07-09 16:44:44,120 [run_pretraining.py:  512]:	********exe.run_96******* 
[INFO] 2021-07-09 16:44:46,278 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:46,279 [run_pretraining.py:  534]:	loss/total_loss, 8.168720245361328, 97
[INFO] 2021-07-09 16:44:46,279 [run_pretraining.py:  535]:	loss/mlm_loss, 8.168720245361328, 97
[INFO] 2021-07-09 16:44:46,279 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.599999657439184e-07, 97
[INFO] 2021-07-09 16:44:46,279 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 97
[INFO] 2021-07-09 16:44:46,279 [run_pretraining.py:  558]:	worker_index: 6, step: 97, cost: 8.168720, mlm loss: 8.168720, speed: 0.463223 steps/s, speed: 3.705782 samples/s, speed: 1897.360538 tokens/s, learning rate: 9.600e-07, loss_scalings: 16777.216797, pp_loss: 8.175253
[INFO] 2021-07-09 16:44:46,279 [run_pretraining.py:  512]:	********exe.run_97******* 
[INFO] 2021-07-09 16:44:48,436 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:48,437 [run_pretraining.py:  534]:	loss/total_loss, 8.088878631591797, 98
[INFO] 2021-07-09 16:44:48,437 [run_pretraining.py:  535]:	loss/mlm_loss, 8.088878631591797, 98
[INFO] 2021-07-09 16:44:48,437 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.699999736767495e-07, 98
[INFO] 2021-07-09 16:44:48,437 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 98
[INFO] 2021-07-09 16:44:48,438 [run_pretraining.py:  558]:	worker_index: 6, step: 98, cost: 8.088879, mlm loss: 8.088879, speed: 0.463411 steps/s, speed: 3.707291 samples/s, speed: 1898.132820 tokens/s, learning rate: 9.700e-07, loss_scalings: 16777.216797, pp_loss: 8.119415
[INFO] 2021-07-09 16:44:48,438 [run_pretraining.py:  512]:	********exe.run_98******* 
[INFO] 2021-07-09 16:44:50,593 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:50,594 [run_pretraining.py:  534]:	loss/total_loss, 8.13135814666748, 99
[INFO] 2021-07-09 16:44:50,594 [run_pretraining.py:  535]:	loss/mlm_loss, 8.13135814666748, 99
[INFO] 2021-07-09 16:44:50,594 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.799999816095806e-07, 99
[INFO] 2021-07-09 16:44:50,594 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 99
[INFO] 2021-07-09 16:44:50,594 [run_pretraining.py:  558]:	worker_index: 6, step: 99, cost: 8.131358, mlm loss: 8.131358, speed: 0.463768 steps/s, speed: 3.710148 samples/s, speed: 1899.595673 tokens/s, learning rate: 9.800e-07, loss_scalings: 16777.216797, pp_loss: 8.160222
[INFO] 2021-07-09 16:44:50,595 [run_pretraining.py:  512]:	********exe.run_99******* 
[INFO] 2021-07-09 16:44:52,748 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:52,749 [run_pretraining.py:  534]:	loss/total_loss, 8.025369644165039, 100
[INFO] 2021-07-09 16:44:52,749 [run_pretraining.py:  535]:	loss/mlm_loss, 8.025369644165039, 100
[INFO] 2021-07-09 16:44:52,749 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.899999895424116e-07, 100
[INFO] 2021-07-09 16:44:52,749 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 100
[INFO] 2021-07-09 16:44:52,749 [run_pretraining.py:  558]:	worker_index: 6, step: 100, cost: 8.025370, mlm loss: 8.025370, speed: 0.464269 steps/s, speed: 3.714155 samples/s, speed: 1901.647460 tokens/s, learning rate: 9.900e-07, loss_scalings: 16777.216797, pp_loss: 8.119914
[INFO] 2021-07-09 16:44:52,749 [run_pretraining.py:  512]:	********exe.run_100******* 
[INFO] 2021-07-09 16:44:54,960 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:54,961 [run_pretraining.py:  534]:	loss/total_loss, 8.074568748474121, 101
[INFO] 2021-07-09 16:44:54,961 [run_pretraining.py:  535]:	loss/mlm_loss, 8.074568748474121, 101
[INFO] 2021-07-09 16:44:54,961 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.999999974752427e-07, 101
[INFO] 2021-07-09 16:44:54,961 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 101
[INFO] 2021-07-09 16:44:54,961 [run_pretraining.py:  558]:	worker_index: 6, step: 101, cost: 8.074569, mlm loss: 8.074569, speed: 0.452178 steps/s, speed: 3.617424 samples/s, speed: 1852.121043 tokens/s, learning rate: 1.000e-06, loss_scalings: 16777.216797, pp_loss: 8.101299
[INFO] 2021-07-09 16:44:54,961 [run_pretraining.py:  512]:	********exe.run_101******* 
[INFO] 2021-07-09 16:44:57,125 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:57,125 [run_pretraining.py:  534]:	loss/total_loss, 7.863003253936768, 102
[INFO] 2021-07-09 16:44:57,125 [run_pretraining.py:  535]:	loss/mlm_loss, 7.863003253936768, 102
[INFO] 2021-07-09 16:44:57,125 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.009999891721236e-06, 102
[INFO] 2021-07-09 16:44:57,125 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 102
[INFO] 2021-07-09 16:44:57,125 [run_pretraining.py:  558]:	worker_index: 6, step: 102, cost: 7.863003, mlm loss: 7.863003, speed: 0.462190 steps/s, speed: 3.697516 samples/s, speed: 1893.128364 tokens/s, learning rate: 1.010e-06, loss_scalings: 16777.216797, pp_loss: 7.972236
[INFO] 2021-07-09 16:44:57,126 [run_pretraining.py:  512]:	********exe.run_102******* 
[INFO] 2021-07-09 16:44:59,279 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:59,279 [run_pretraining.py:  534]:	loss/total_loss, 7.9024457931518555, 103
[INFO] 2021-07-09 16:44:59,279 [run_pretraining.py:  535]:	loss/mlm_loss, 7.9024457931518555, 103
[INFO] 2021-07-09 16:44:59,280 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0200000133409048e-06, 103
[INFO] 2021-07-09 16:44:59,280 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 103
[INFO] 2021-07-09 16:44:59,280 [run_pretraining.py:  558]:	worker_index: 6, step: 103, cost: 7.902446, mlm loss: 7.902446, speed: 0.464356 steps/s, speed: 3.714846 samples/s, speed: 1902.000945 tokens/s, learning rate: 1.020e-06, loss_scalings: 16777.216797, pp_loss: 8.050528
[INFO] 2021-07-09 16:44:59,280 [run_pretraining.py:  512]:	********exe.run_103******* 
[INFO] 2021-07-09 16:45:01,481 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:01,482 [run_pretraining.py:  534]:	loss/total_loss, 7.945420265197754, 104
[INFO] 2021-07-09 16:45:01,482 [run_pretraining.py:  535]:	loss/mlm_loss, 7.945420265197754, 104
[INFO] 2021-07-09 16:45:01,482 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.030000021273736e-06, 104
[INFO] 2021-07-09 16:45:01,482 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 104
[INFO] 2021-07-09 16:45:01,483 [run_pretraining.py:  558]:	worker_index: 6, step: 104, cost: 7.945420, mlm loss: 7.945420, speed: 0.454102 steps/s, speed: 3.632820 samples/s, speed: 1860.003788 tokens/s, learning rate: 1.030e-06, loss_scalings: 16777.216797, pp_loss: 7.927380
[INFO] 2021-07-09 16:45:01,483 [run_pretraining.py:  512]:	********exe.run_104******* 
[INFO] 2021-07-09 16:45:03,725 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:03,725 [run_pretraining.py:  534]:	loss/total_loss, 7.865384578704834, 105
[INFO] 2021-07-09 16:45:03,725 [run_pretraining.py:  535]:	loss/mlm_loss, 7.865384578704834, 105
[INFO] 2021-07-09 16:45:03,725 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.040000029206567e-06, 105
[INFO] 2021-07-09 16:45:03,726 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 105
[INFO] 2021-07-09 16:45:03,726 [run_pretraining.py:  558]:	worker_index: 6, step: 105, cost: 7.865385, mlm loss: 7.865385, speed: 0.445966 steps/s, speed: 3.567731 samples/s, speed: 1826.678490 tokens/s, learning rate: 1.040e-06, loss_scalings: 16777.216797, pp_loss: 7.876276
[INFO] 2021-07-09 16:45:03,726 [run_pretraining.py:  512]:	********exe.run_105******* 
[INFO] 2021-07-09 16:45:05,974 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:05,974 [run_pretraining.py:  534]:	loss/total_loss, 8.032842636108398, 106
[INFO] 2021-07-09 16:45:05,974 [run_pretraining.py:  535]:	loss/mlm_loss, 8.032842636108398, 106
[INFO] 2021-07-09 16:45:05,975 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0499999234525603e-06, 106
[INFO] 2021-07-09 16:45:05,975 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 106
[INFO] 2021-07-09 16:45:05,975 [run_pretraining.py:  558]:	worker_index: 6, step: 106, cost: 8.032843, mlm loss: 8.032843, speed: 0.444755 steps/s, speed: 3.558041 samples/s, speed: 1821.716938 tokens/s, learning rate: 1.050e-06, loss_scalings: 16777.216797, pp_loss: 7.905601
[INFO] 2021-07-09 16:45:05,975 [run_pretraining.py:  512]:	********exe.run_106******* 
[INFO] 2021-07-09 16:45:08,185 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:08,186 [run_pretraining.py:  534]:	loss/total_loss, 7.795651435852051, 107
[INFO] 2021-07-09 16:45:08,186 [run_pretraining.py:  535]:	loss/mlm_loss, 7.795651435852051, 107
[INFO] 2021-07-09 16:45:08,186 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0599999313853914e-06, 107
[INFO] 2021-07-09 16:45:08,186 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 107
[INFO] 2021-07-09 16:45:08,186 [run_pretraining.py:  558]:	worker_index: 6, step: 107, cost: 7.795651, mlm loss: 7.795651, speed: 0.452388 steps/s, speed: 3.619108 samples/s, speed: 1852.983232 tokens/s, learning rate: 1.060e-06, loss_scalings: 16777.216797, pp_loss: 7.826739
[INFO] 2021-07-09 16:45:08,186 [run_pretraining.py:  512]:	********exe.run_107******* 
[INFO] 2021-07-09 16:45:10,368 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:10,369 [run_pretraining.py:  534]:	loss/total_loss, 7.779571533203125, 108
[INFO] 2021-07-09 16:45:10,369 [run_pretraining.py:  535]:	loss/mlm_loss, 7.779571533203125, 108
[INFO] 2021-07-09 16:45:10,369 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0700000530050602e-06, 108
[INFO] 2021-07-09 16:45:10,369 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 108
[INFO] 2021-07-09 16:45:10,369 [run_pretraining.py:  558]:	worker_index: 6, step: 108, cost: 7.779572, mlm loss: 7.779572, speed: 0.458153 steps/s, speed: 3.665223 samples/s, speed: 1876.594223 tokens/s, learning rate: 1.070e-06, loss_scalings: 16777.216797, pp_loss: 7.809622
[INFO] 2021-07-09 16:45:10,369 [run_pretraining.py:  512]:	********exe.run_108******* 
[INFO] 2021-07-09 16:45:12,574 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:12,574 [run_pretraining.py:  534]:	loss/total_loss, 7.791040420532227, 109
[INFO] 2021-07-09 16:45:12,574 [run_pretraining.py:  535]:	loss/mlm_loss, 7.791040420532227, 109
[INFO] 2021-07-09 16:45:12,575 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0799999472510535e-06, 109
[INFO] 2021-07-09 16:45:12,575 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 109
[INFO] 2021-07-09 16:45:12,575 [run_pretraining.py:  558]:	worker_index: 6, step: 109, cost: 7.791040, mlm loss: 7.791040, speed: 0.453570 steps/s, speed: 3.628561 samples/s, speed: 1857.823028 tokens/s, learning rate: 1.080e-06, loss_scalings: 16777.216797, pp_loss: 7.743442
[INFO] 2021-07-09 16:45:12,575 [run_pretraining.py:  512]:	********exe.run_109******* 
[INFO] 2021-07-09 16:45:14,761 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:14,762 [run_pretraining.py:  534]:	loss/total_loss, 7.617135524749756, 110
[INFO] 2021-07-09 16:45:14,762 [run_pretraining.py:  535]:	loss/mlm_loss, 7.617135524749756, 110
[INFO] 2021-07-09 16:45:14,762 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0899999551838846e-06, 110
[INFO] 2021-07-09 16:45:14,762 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 110
[INFO] 2021-07-09 16:45:14,762 [run_pretraining.py:  558]:	worker_index: 6, step: 110, cost: 7.617136, mlm loss: 7.617136, speed: 0.457291 steps/s, speed: 3.658327 samples/s, speed: 1873.063257 tokens/s, learning rate: 1.090e-06, loss_scalings: 16777.216797, pp_loss: 7.682575
[INFO] 2021-07-09 16:45:14,762 [run_pretraining.py:  512]:	********exe.run_110******* 
[INFO] 2021-07-09 16:45:16,955 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:16,956 [run_pretraining.py:  534]:	loss/total_loss, 7.569077014923096, 111
[INFO] 2021-07-09 16:45:16,956 [run_pretraining.py:  535]:	loss/mlm_loss, 7.569077014923096, 111
[INFO] 2021-07-09 16:45:16,956 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0999999631167157e-06, 111
[INFO] 2021-07-09 16:45:16,956 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 111
[INFO] 2021-07-09 16:45:16,956 [run_pretraining.py:  558]:	worker_index: 6, step: 111, cost: 7.569077, mlm loss: 7.569077, speed: 0.455940 steps/s, speed: 3.647521 samples/s, speed: 1867.530548 tokens/s, learning rate: 1.100e-06, loss_scalings: 16777.216797, pp_loss: 7.681833
[INFO] 2021-07-09 16:45:16,956 [run_pretraining.py:  512]:	********exe.run_111******* 
[INFO] 2021-07-09 16:45:19,139 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:19,139 [run_pretraining.py:  534]:	loss/total_loss, 7.585565567016602, 112
[INFO] 2021-07-09 16:45:19,139 [run_pretraining.py:  535]:	loss/mlm_loss, 7.585565567016602, 112
[INFO] 2021-07-09 16:45:19,140 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1099999710495467e-06, 112
[INFO] 2021-07-09 16:45:19,140 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 112
[INFO] 2021-07-09 16:45:19,140 [run_pretraining.py:  558]:	worker_index: 6, step: 112, cost: 7.585566, mlm loss: 7.585566, speed: 0.458074 steps/s, speed: 3.664594 samples/s, speed: 1876.272247 tokens/s, learning rate: 1.110e-06, loss_scalings: 16777.216797, pp_loss: 7.591455
[INFO] 2021-07-09 16:45:19,140 [run_pretraining.py:  512]:	********exe.run_112******* 
[INFO] 2021-07-09 16:45:21,328 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:21,329 [run_pretraining.py:  534]:	loss/total_loss, 7.575047492980957, 113
[INFO] 2021-07-09 16:45:21,329 [run_pretraining.py:  535]:	loss/mlm_loss, 7.575047492980957, 113
[INFO] 2021-07-09 16:45:21,329 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1199999789823778e-06, 113
[INFO] 2021-07-09 16:45:21,329 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 113
[INFO] 2021-07-09 16:45:21,329 [run_pretraining.py:  558]:	worker_index: 6, step: 113, cost: 7.575047, mlm loss: 7.575047, speed: 0.456881 steps/s, speed: 3.655051 samples/s, speed: 1871.386327 tokens/s, learning rate: 1.120e-06, loss_scalings: 16777.216797, pp_loss: 7.631815
[INFO] 2021-07-09 16:45:21,329 [run_pretraining.py:  512]:	********exe.run_113******* 
[INFO] 2021-07-09 16:45:23,567 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:23,568 [run_pretraining.py:  534]:	loss/total_loss, 7.516681671142578, 114
[INFO] 2021-07-09 16:45:23,568 [run_pretraining.py:  535]:	loss/mlm_loss, 7.516681671142578, 114
[INFO] 2021-07-09 16:45:23,568 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1299999869152089e-06, 114
[INFO] 2021-07-09 16:45:23,568 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 114
[INFO] 2021-07-09 16:45:23,568 [run_pretraining.py:  558]:	worker_index: 6, step: 114, cost: 7.516682, mlm loss: 7.516682, speed: 0.446801 steps/s, speed: 3.574405 samples/s, speed: 1830.095260 tokens/s, learning rate: 1.130e-06, loss_scalings: 16777.216797, pp_loss: 7.531495
[INFO] 2021-07-09 16:45:23,568 [run_pretraining.py:  512]:	********exe.run_114******* 
[INFO] 2021-07-09 16:45:25,828 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:25,828 [run_pretraining.py:  534]:	loss/total_loss, 7.585803985595703, 115
[INFO] 2021-07-09 16:45:25,828 [run_pretraining.py:  535]:	loss/mlm_loss, 7.585803985595703, 115
[INFO] 2021-07-09 16:45:25,829 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.13999999484804e-06, 115
[INFO] 2021-07-09 16:45:25,829 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 115
[INFO] 2021-07-09 16:45:25,829 [run_pretraining.py:  558]:	worker_index: 6, step: 115, cost: 7.585804, mlm loss: 7.585804, speed: 0.442462 steps/s, speed: 3.539696 samples/s, speed: 1812.324574 tokens/s, learning rate: 1.140e-06, loss_scalings: 16777.216797, pp_loss: 7.508892
[INFO] 2021-07-09 16:45:25,829 [run_pretraining.py:  512]:	********exe.run_115******* 
[INFO] 2021-07-09 16:45:28,046 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:28,047 [run_pretraining.py:  534]:	loss/total_loss, 7.396421432495117, 116
[INFO] 2021-07-09 16:45:28,047 [run_pretraining.py:  535]:	loss/mlm_loss, 7.396421432495117, 116
[INFO] 2021-07-09 16:45:28,047 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.150000002780871e-06, 116
[INFO] 2021-07-09 16:45:28,047 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 116
[INFO] 2021-07-09 16:45:28,047 [run_pretraining.py:  558]:	worker_index: 6, step: 116, cost: 7.396421, mlm loss: 7.396421, speed: 0.450866 steps/s, speed: 3.606928 samples/s, speed: 1846.746915 tokens/s, learning rate: 1.150e-06, loss_scalings: 16777.216797, pp_loss: 7.456432
[INFO] 2021-07-09 16:45:28,047 [run_pretraining.py:  512]:	********exe.run_116******* 
[INFO] 2021-07-09 16:45:30,260 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:30,260 [run_pretraining.py:  534]:	loss/total_loss, 7.343520641326904, 117
[INFO] 2021-07-09 16:45:30,260 [run_pretraining.py:  535]:	loss/mlm_loss, 7.343520641326904, 117
[INFO] 2021-07-09 16:45:30,260 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.160000010713702e-06, 117
[INFO] 2021-07-09 16:45:30,260 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 117
[INFO] 2021-07-09 16:45:30,261 [run_pretraining.py:  558]:	worker_index: 6, step: 117, cost: 7.343521, mlm loss: 7.343521, speed: 0.451985 steps/s, speed: 3.615878 samples/s, speed: 1851.329679 tokens/s, learning rate: 1.160e-06, loss_scalings: 16777.216797, pp_loss: 7.392831
[INFO] 2021-07-09 16:45:30,261 [run_pretraining.py:  512]:	********exe.run_117******* 
[INFO] 2021-07-09 16:45:32,458 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:32,459 [run_pretraining.py:  534]:	loss/total_loss, 7.2144389152526855, 118
[INFO] 2021-07-09 16:45:32,459 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2144389152526855, 118
[INFO] 2021-07-09 16:45:32,459 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1699999049596954e-06, 118
[INFO] 2021-07-09 16:45:32,459 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 118
[INFO] 2021-07-09 16:45:32,459 [run_pretraining.py:  558]:	worker_index: 6, step: 118, cost: 7.214439, mlm loss: 7.214439, speed: 0.454968 steps/s, speed: 3.639747 samples/s, speed: 1863.550325 tokens/s, learning rate: 1.170e-06, loss_scalings: 16777.216797, pp_loss: 7.296797
[INFO] 2021-07-09 16:45:32,459 [run_pretraining.py:  512]:	********exe.run_118******* 
[INFO] 2021-07-09 16:45:34,690 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:34,691 [run_pretraining.py:  534]:	loss/total_loss, 7.452254772186279, 119
[INFO] 2021-07-09 16:45:34,691 [run_pretraining.py:  535]:	loss/mlm_loss, 7.452254772186279, 119
[INFO] 2021-07-09 16:45:34,691 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1800000265793642e-06, 119
[INFO] 2021-07-09 16:45:34,691 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 119
[INFO] 2021-07-09 16:45:34,691 [run_pretraining.py:  558]:	worker_index: 6, step: 119, cost: 7.452255, mlm loss: 7.452255, speed: 0.448199 steps/s, speed: 3.585593 samples/s, speed: 1835.823470 tokens/s, learning rate: 1.180e-06, loss_scalings: 16777.216797, pp_loss: 7.332223
[INFO] 2021-07-09 16:45:34,691 [run_pretraining.py:  512]:	********exe.run_119******* 
[INFO] 2021-07-09 16:45:36,934 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:36,935 [run_pretraining.py:  534]:	loss/total_loss, 7.322612762451172, 120
[INFO] 2021-07-09 16:45:36,935 [run_pretraining.py:  535]:	loss/mlm_loss, 7.322612762451172, 120
[INFO] 2021-07-09 16:45:36,935 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1900000345121953e-06, 120
[INFO] 2021-07-09 16:45:36,935 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 120
[INFO] 2021-07-09 16:45:36,935 [run_pretraining.py:  558]:	worker_index: 6, step: 120, cost: 7.322613, mlm loss: 7.322613, speed: 0.445744 steps/s, speed: 3.565953 samples/s, speed: 1825.768030 tokens/s, learning rate: 1.190e-06, loss_scalings: 16777.216797, pp_loss: 7.319787
[INFO] 2021-07-09 16:45:36,935 [run_pretraining.py:  512]:	********exe.run_120******* 
[INFO] 2021-07-09 16:45:39,178 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:39,179 [run_pretraining.py:  534]:	loss/total_loss, 7.475468635559082, 121
[INFO] 2021-07-09 16:45:39,179 [run_pretraining.py:  535]:	loss/mlm_loss, 7.475468635559082, 121
[INFO] 2021-07-09 16:45:39,179 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1999999287581886e-06, 121
[INFO] 2021-07-09 16:45:39,179 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 121
[INFO] 2021-07-09 16:45:39,179 [run_pretraining.py:  558]:	worker_index: 6, step: 121, cost: 7.475469, mlm loss: 7.475469, speed: 0.445766 steps/s, speed: 3.566129 samples/s, speed: 1825.858259 tokens/s, learning rate: 1.200e-06, loss_scalings: 16777.216797, pp_loss: 7.206011
[INFO] 2021-07-09 16:45:39,179 [run_pretraining.py:  512]:	********exe.run_121******* 
[INFO] 2021-07-09 16:45:41,423 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:41,424 [run_pretraining.py:  534]:	loss/total_loss, 7.274868011474609, 122
[INFO] 2021-07-09 16:45:41,424 [run_pretraining.py:  535]:	loss/mlm_loss, 7.274868011474609, 122
[INFO] 2021-07-09 16:45:41,424 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2099999366910197e-06, 122
[INFO] 2021-07-09 16:45:41,424 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 122
[INFO] 2021-07-09 16:45:41,425 [run_pretraining.py:  558]:	worker_index: 6, step: 122, cost: 7.274868, mlm loss: 7.274868, speed: 0.445511 steps/s, speed: 3.564087 samples/s, speed: 1824.812733 tokens/s, learning rate: 1.210e-06, loss_scalings: 16777.216797, pp_loss: 7.224975
[INFO] 2021-07-09 16:45:41,425 [run_pretraining.py:  512]:	********exe.run_122******* 
[INFO] 2021-07-09 16:45:43,667 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:43,668 [run_pretraining.py:  534]:	loss/total_loss, 7.074663162231445, 123
[INFO] 2021-07-09 16:45:43,668 [run_pretraining.py:  535]:	loss/mlm_loss, 7.074663162231445, 123
[INFO] 2021-07-09 16:45:43,668 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2199999446238508e-06, 123
[INFO] 2021-07-09 16:45:43,668 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 123
[INFO] 2021-07-09 16:45:43,668 [run_pretraining.py:  558]:	worker_index: 6, step: 123, cost: 7.074663, mlm loss: 7.074663, speed: 0.445773 steps/s, speed: 3.566186 samples/s, speed: 1825.887173 tokens/s, learning rate: 1.220e-06, loss_scalings: 16777.216797, pp_loss: 7.174143
[INFO] 2021-07-09 16:45:43,669 [run_pretraining.py:  512]:	********exe.run_123******* 
[INFO] 2021-07-09 16:45:45,889 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:45,889 [run_pretraining.py:  534]:	loss/total_loss, 7.0873894691467285, 124
[INFO] 2021-07-09 16:45:45,890 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0873894691467285, 124
[INFO] 2021-07-09 16:45:45,890 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2299999525566818e-06, 124
[INFO] 2021-07-09 16:45:45,890 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 124
[INFO] 2021-07-09 16:45:45,890 [run_pretraining.py:  558]:	worker_index: 6, step: 124, cost: 7.087389, mlm loss: 7.087389, speed: 0.450315 steps/s, speed: 3.602521 samples/s, speed: 1844.490566 tokens/s, learning rate: 1.230e-06, loss_scalings: 16777.216797, pp_loss: 7.105999
[INFO] 2021-07-09 16:45:45,890 [run_pretraining.py:  512]:	********exe.run_124******* 
[INFO] 2021-07-09 16:45:48,087 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:48,088 [run_pretraining.py:  534]:	loss/total_loss, 7.10004997253418, 125
[INFO] 2021-07-09 16:45:48,088 [run_pretraining.py:  535]:	loss/mlm_loss, 7.10004997253418, 125
[INFO] 2021-07-09 16:45:48,088 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2399999604895129e-06, 125
[INFO] 2021-07-09 16:45:48,088 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 125
[INFO] 2021-07-09 16:45:48,088 [run_pretraining.py:  558]:	worker_index: 6, step: 125, cost: 7.100050, mlm loss: 7.100050, speed: 0.455087 steps/s, speed: 3.640692 samples/s, speed: 1864.034385 tokens/s, learning rate: 1.240e-06, loss_scalings: 16777.216797, pp_loss: 7.094574
[INFO] 2021-07-09 16:45:48,088 [run_pretraining.py:  512]:	********exe.run_125******* 
[INFO] 2021-07-09 16:45:50,313 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:50,314 [run_pretraining.py:  534]:	loss/total_loss, 7.012327671051025, 126
[INFO] 2021-07-09 16:45:50,314 [run_pretraining.py:  535]:	loss/mlm_loss, 7.012327671051025, 126
[INFO] 2021-07-09 16:45:50,314 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.249999968422344e-06, 126
[INFO] 2021-07-09 16:45:50,314 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 126
[INFO] 2021-07-09 16:45:50,314 [run_pretraining.py:  558]:	worker_index: 6, step: 126, cost: 7.012328, mlm loss: 7.012328, speed: 0.449304 steps/s, speed: 3.594433 samples/s, speed: 1840.349749 tokens/s, learning rate: 1.250e-06, loss_scalings: 16777.216797, pp_loss: 7.029258
[INFO] 2021-07-09 16:45:50,314 [run_pretraining.py:  512]:	********exe.run_126******* 
[INFO] 2021-07-09 16:45:52,565 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:52,566 [run_pretraining.py:  534]:	loss/total_loss, 7.061258316040039, 127
[INFO] 2021-07-09 16:45:52,566 [run_pretraining.py:  535]:	loss/mlm_loss, 7.061258316040039, 127
[INFO] 2021-07-09 16:45:52,566 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.259999976355175e-06, 127
[INFO] 2021-07-09 16:45:52,566 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 127
[INFO] 2021-07-09 16:45:52,566 [run_pretraining.py:  558]:	worker_index: 6, step: 127, cost: 7.061258, mlm loss: 7.061258, speed: 0.444183 steps/s, speed: 3.553467 samples/s, speed: 1819.374857 tokens/s, learning rate: 1.260e-06, loss_scalings: 16777.216797, pp_loss: 7.026046
[INFO] 2021-07-09 16:45:52,566 [run_pretraining.py:  512]:	********exe.run_127******* 
[INFO] 2021-07-09 16:45:54,759 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:54,759 [run_pretraining.py:  534]:	loss/total_loss, 7.051252365112305, 128
[INFO] 2021-07-09 16:45:54,759 [run_pretraining.py:  535]:	loss/mlm_loss, 7.051252365112305, 128
[INFO] 2021-07-09 16:45:54,759 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.269999984288006e-06, 128
[INFO] 2021-07-09 16:45:54,759 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 128
[INFO] 2021-07-09 16:45:54,759 [run_pretraining.py:  558]:	worker_index: 6, step: 128, cost: 7.051252, mlm loss: 7.051252, speed: 0.456106 steps/s, speed: 3.648849 samples/s, speed: 1868.210876 tokens/s, learning rate: 1.270e-06, loss_scalings: 16777.216797, pp_loss: 6.941195
[INFO] 2021-07-09 16:45:54,759 [run_pretraining.py:  512]:	********exe.run_128******* 
[INFO] 2021-07-09 16:45:56,976 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:56,977 [run_pretraining.py:  534]:	loss/total_loss, 7.0642781257629395, 129
[INFO] 2021-07-09 16:45:56,977 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0642781257629395, 129
[INFO] 2021-07-09 16:45:56,977 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2799998785339994e-06, 129
[INFO] 2021-07-09 16:45:56,977 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 129
[INFO] 2021-07-09 16:45:56,977 [run_pretraining.py:  558]:	worker_index: 6, step: 129, cost: 7.064278, mlm loss: 7.064278, speed: 0.451039 steps/s, speed: 3.608315 samples/s, speed: 1847.457080 tokens/s, learning rate: 1.280e-06, loss_scalings: 16777.216797, pp_loss: 6.926938
[INFO] 2021-07-09 16:45:56,977 [run_pretraining.py:  512]:	********exe.run_129******* 
[INFO] 2021-07-09 16:45:59,237 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:59,238 [run_pretraining.py:  534]:	loss/total_loss, 6.9936442375183105, 130
[INFO] 2021-07-09 16:45:59,238 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9936442375183105, 130
[INFO] 2021-07-09 16:45:59,238 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2900000001536682e-06, 130
[INFO] 2021-07-09 16:45:59,238 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 130
[INFO] 2021-07-09 16:45:59,238 [run_pretraining.py:  558]:	worker_index: 6, step: 130, cost: 6.993644, mlm loss: 6.993644, speed: 0.442466 steps/s, speed: 3.539728 samples/s, speed: 1812.340825 tokens/s, learning rate: 1.290e-06, loss_scalings: 16777.216797, pp_loss: 6.876586
[INFO] 2021-07-09 16:45:59,238 [run_pretraining.py:  512]:	********exe.run_130******* 
[INFO] 2021-07-09 16:46:01,438 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:01,439 [run_pretraining.py:  534]:	loss/total_loss, 7.065105438232422, 131
[INFO] 2021-07-09 16:46:01,439 [run_pretraining.py:  535]:	loss/mlm_loss, 7.065105438232422, 131
[INFO] 2021-07-09 16:46:01,439 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3000000080864993e-06, 131
[INFO] 2021-07-09 16:46:01,439 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 131
[INFO] 2021-07-09 16:46:01,440 [run_pretraining.py:  558]:	worker_index: 6, step: 131, cost: 7.065105, mlm loss: 7.065105, speed: 0.454351 steps/s, speed: 3.634810 samples/s, speed: 1861.022503 tokens/s, learning rate: 1.300e-06, loss_scalings: 16777.216797, pp_loss: 6.898020
[INFO] 2021-07-09 16:46:01,440 [run_pretraining.py:  512]:	********exe.run_131******* 
[INFO] 2021-07-09 16:46:03,637 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:03,637 [run_pretraining.py:  534]:	loss/total_loss, 6.701025485992432, 132
[INFO] 2021-07-09 16:46:03,638 [run_pretraining.py:  535]:	loss/mlm_loss, 6.701025485992432, 132
[INFO] 2021-07-09 16:46:03,638 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3100000160193304e-06, 132
[INFO] 2021-07-09 16:46:03,638 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 132
[INFO] 2021-07-09 16:46:03,638 [run_pretraining.py:  558]:	worker_index: 6, step: 132, cost: 6.701025, mlm loss: 6.701025, speed: 0.455029 steps/s, speed: 3.640236 samples/s, speed: 1863.800816 tokens/s, learning rate: 1.310e-06, loss_scalings: 16777.216797, pp_loss: 6.763312
[INFO] 2021-07-09 16:46:03,638 [run_pretraining.py:  512]:	********exe.run_132******* 
[INFO] 2021-07-09 16:46:05,954 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:05,954 [run_pretraining.py:  534]:	loss/total_loss, 6.6681671142578125, 133
[INFO] 2021-07-09 16:46:05,955 [run_pretraining.py:  535]:	loss/mlm_loss, 6.6681671142578125, 133
[INFO] 2021-07-09 16:46:05,955 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3199999102653237e-06, 133
[INFO] 2021-07-09 16:46:05,955 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 133
[INFO] 2021-07-09 16:46:05,955 [run_pretraining.py:  558]:	worker_index: 6, step: 133, cost: 6.668167, mlm loss: 6.668167, speed: 0.431731 steps/s, speed: 3.453845 samples/s, speed: 1768.368625 tokens/s, learning rate: 1.320e-06, loss_scalings: 16777.216797, pp_loss: 6.747466
[INFO] 2021-07-09 16:46:05,955 [run_pretraining.py:  512]:	********exe.run_133******* 
[INFO] 2021-07-09 16:46:08,200 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:08,201 [run_pretraining.py:  534]:	loss/total_loss, 6.7176289558410645, 134
[INFO] 2021-07-09 16:46:08,201 [run_pretraining.py:  535]:	loss/mlm_loss, 6.7176289558410645, 134
[INFO] 2021-07-09 16:46:08,201 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3299999181981548e-06, 134
[INFO] 2021-07-09 16:46:08,201 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 134
[INFO] 2021-07-09 16:46:08,201 [run_pretraining.py:  558]:	worker_index: 6, step: 134, cost: 6.717629, mlm loss: 6.717629, speed: 0.445329 steps/s, speed: 3.562635 samples/s, speed: 1824.069124 tokens/s, learning rate: 1.330e-06, loss_scalings: 16777.216797, pp_loss: 6.725757
[INFO] 2021-07-09 16:46:08,201 [run_pretraining.py:  512]:	********exe.run_134******* 
[INFO] 2021-07-09 16:46:10,408 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:10,408 [run_pretraining.py:  534]:	loss/total_loss, 6.664590358734131, 135
[INFO] 2021-07-09 16:46:10,408 [run_pretraining.py:  535]:	loss/mlm_loss, 6.664590358734131, 135
[INFO] 2021-07-09 16:46:10,409 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3399999261309858e-06, 135
[INFO] 2021-07-09 16:46:10,409 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 135
[INFO] 2021-07-09 16:46:10,409 [run_pretraining.py:  558]:	worker_index: 6, step: 135, cost: 6.664590, mlm loss: 6.664590, speed: 0.453113 steps/s, speed: 3.624903 samples/s, speed: 1855.950282 tokens/s, learning rate: 1.340e-06, loss_scalings: 16777.216797, pp_loss: 6.679857
[INFO] 2021-07-09 16:46:10,409 [run_pretraining.py:  512]:	********exe.run_135******* 
[INFO] 2021-07-09 16:46:12,618 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:12,618 [run_pretraining.py:  534]:	loss/total_loss, 6.712968349456787, 136
[INFO] 2021-07-09 16:46:12,618 [run_pretraining.py:  535]:	loss/mlm_loss, 6.712968349456787, 136
[INFO] 2021-07-09 16:46:12,619 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3500000477506546e-06, 136
[INFO] 2021-07-09 16:46:12,619 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 136
[INFO] 2021-07-09 16:46:12,619 [run_pretraining.py:  558]:	worker_index: 6, step: 136, cost: 6.712968, mlm loss: 6.712968, speed: 0.452602 steps/s, speed: 3.620815 samples/s, speed: 1853.857027 tokens/s, learning rate: 1.350e-06, loss_scalings: 16777.216797, pp_loss: 6.622036
[INFO] 2021-07-09 16:46:12,619 [run_pretraining.py:  512]:	********exe.run_136******* 
[INFO] 2021-07-09 16:46:14,846 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:14,846 [run_pretraining.py:  534]:	loss/total_loss, 6.560543537139893, 137
[INFO] 2021-07-09 16:46:14,846 [run_pretraining.py:  535]:	loss/mlm_loss, 6.560543537139893, 137
[INFO] 2021-07-09 16:46:14,846 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.359999941996648e-06, 137
[INFO] 2021-07-09 16:46:14,846 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 137
[INFO] 2021-07-09 16:46:14,846 [run_pretraining.py:  558]:	worker_index: 6, step: 137, cost: 6.560544, mlm loss: 6.560544, speed: 0.449014 steps/s, speed: 3.592112 samples/s, speed: 1839.161351 tokens/s, learning rate: 1.360e-06, loss_scalings: 16777.216797, pp_loss: 6.604020
[INFO] 2021-07-09 16:46:14,846 [run_pretraining.py:  512]:	********exe.run_137******* 
[INFO] 2021-07-09 16:46:17,133 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:17,133 [run_pretraining.py:  534]:	loss/total_loss, 6.532299995422363, 138
[INFO] 2021-07-09 16:46:17,133 [run_pretraining.py:  535]:	loss/mlm_loss, 6.532299995422363, 138
[INFO] 2021-07-09 16:46:17,134 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.369999949929479e-06, 138
[INFO] 2021-07-09 16:46:17,134 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 138
[INFO] 2021-07-09 16:46:17,134 [run_pretraining.py:  558]:	worker_index: 6, step: 138, cost: 6.532300, mlm loss: 6.532300, speed: 0.437337 steps/s, speed: 3.498697 samples/s, speed: 1791.333050 tokens/s, learning rate: 1.370e-06, loss_scalings: 16777.216797, pp_loss: 6.544353
[INFO] 2021-07-09 16:46:17,134 [run_pretraining.py:  512]:	********exe.run_138******* 
[INFO] 2021-07-09 16:46:19,336 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:19,337 [run_pretraining.py:  534]:	loss/total_loss, 6.495038986206055, 139
[INFO] 2021-07-09 16:46:19,337 [run_pretraining.py:  535]:	loss/mlm_loss, 6.495038986206055, 139
[INFO] 2021-07-09 16:46:19,337 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3799999578623101e-06, 139
[INFO] 2021-07-09 16:46:19,337 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 139
[INFO] 2021-07-09 16:46:19,337 [run_pretraining.py:  558]:	worker_index: 6, step: 139, cost: 6.495039, mlm loss: 6.495039, speed: 0.454014 steps/s, speed: 3.632113 samples/s, speed: 1859.641784 tokens/s, learning rate: 1.380e-06, loss_scalings: 16777.216797, pp_loss: 6.505495
[INFO] 2021-07-09 16:46:19,337 [run_pretraining.py:  512]:	********exe.run_139******* 
[INFO] 2021-07-09 16:46:21,470 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:21,470 [run_pretraining.py:  534]:	loss/total_loss, 6.585932731628418, 140
[INFO] 2021-07-09 16:46:21,471 [run_pretraining.py:  535]:	loss/mlm_loss, 6.585932731628418, 140
[INFO] 2021-07-09 16:46:21,471 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3899999657951412e-06, 140
[INFO] 2021-07-09 16:46:21,471 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 140
[INFO] 2021-07-09 16:46:21,471 [run_pretraining.py:  558]:	worker_index: 6, step: 140, cost: 6.585933, mlm loss: 6.585933, speed: 0.468789 steps/s, speed: 3.750310 samples/s, speed: 1920.158700 tokens/s, learning rate: 1.390e-06, loss_scalings: 16777.216797, pp_loss: 6.519888
[INFO] 2021-07-09 16:46:21,471 [run_pretraining.py:  512]:	********exe.run_140******* 
[INFO] 2021-07-09 16:46:23,560 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:23,560 [run_pretraining.py:  534]:	loss/total_loss, 6.421136856079102, 141
[INFO] 2021-07-09 16:46:23,561 [run_pretraining.py:  535]:	loss/mlm_loss, 6.421136856079102, 141
[INFO] 2021-07-09 16:46:23,561 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3999999737279722e-06, 141
[INFO] 2021-07-09 16:46:23,561 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 141
[INFO] 2021-07-09 16:46:23,561 [run_pretraining.py:  558]:	worker_index: 6, step: 141, cost: 6.421137, mlm loss: 6.421137, speed: 0.478617 steps/s, speed: 3.828934 samples/s, speed: 1960.414299 tokens/s, learning rate: 1.400e-06, loss_scalings: 16777.216797, pp_loss: 6.477602
[INFO] 2021-07-09 16:46:23,561 [run_pretraining.py:  512]:	********exe.run_141******* 
[INFO] 2021-07-09 16:46:25,664 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:25,665 [run_pretraining.py:  534]:	loss/total_loss, 6.392275810241699, 142
[INFO] 2021-07-09 16:46:25,665 [run_pretraining.py:  535]:	loss/mlm_loss, 6.392275810241699, 142
[INFO] 2021-07-09 16:46:25,665 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4099999816608033e-06, 142
[INFO] 2021-07-09 16:46:25,665 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 142
[INFO] 2021-07-09 16:46:25,665 [run_pretraining.py:  558]:	worker_index: 6, step: 142, cost: 6.392276, mlm loss: 6.392276, speed: 0.475361 steps/s, speed: 3.802888 samples/s, speed: 1947.078853 tokens/s, learning rate: 1.410e-06, loss_scalings: 16777.216797, pp_loss: 6.413482
[INFO] 2021-07-09 16:46:25,665 [run_pretraining.py:  512]:	********exe.run_142******* 
[INFO] 2021-07-09 16:46:27,904 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:27,905 [run_pretraining.py:  534]:	loss/total_loss, 6.3179030418396, 143
[INFO] 2021-07-09 16:46:27,905 [run_pretraining.py:  535]:	loss/mlm_loss, 6.3179030418396, 143
[INFO] 2021-07-09 16:46:27,905 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4199999895936344e-06, 143
[INFO] 2021-07-09 16:46:27,905 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 143
[INFO] 2021-07-09 16:46:27,905 [run_pretraining.py:  558]:	worker_index: 6, step: 143, cost: 6.317903, mlm loss: 6.317903, speed: 0.446602 steps/s, speed: 3.572813 samples/s, speed: 1829.280334 tokens/s, learning rate: 1.420e-06, loss_scalings: 16777.216797, pp_loss: 6.360173
[INFO] 2021-07-09 16:46:27,905 [run_pretraining.py:  512]:	********exe.run_143******* 
[INFO] 2021-07-09 16:46:29,990 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:29,991 [run_pretraining.py:  534]:	loss/total_loss, 6.263497352600098, 144
[INFO] 2021-07-09 16:46:29,991 [run_pretraining.py:  535]:	loss/mlm_loss, 6.263497352600098, 144
[INFO] 2021-07-09 16:46:29,991 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4299999975264654e-06, 144
[INFO] 2021-07-09 16:46:29,991 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 144
[INFO] 2021-07-09 16:46:29,991 [run_pretraining.py:  558]:	worker_index: 6, step: 144, cost: 6.263497, mlm loss: 6.263497, speed: 0.479566 steps/s, speed: 3.836528 samples/s, speed: 1964.302384 tokens/s, learning rate: 1.430e-06, loss_scalings: 16777.216797, pp_loss: 6.314153
[INFO] 2021-07-09 16:46:29,991 [run_pretraining.py:  512]:	********exe.run_144******* 
[INFO] 2021-07-09 16:46:32,128 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:32,129 [run_pretraining.py:  534]:	loss/total_loss, 6.39688777923584, 145
[INFO] 2021-07-09 16:46:32,129 [run_pretraining.py:  535]:	loss/mlm_loss, 6.39688777923584, 145
[INFO] 2021-07-09 16:46:32,129 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4399998917724588e-06, 145
[INFO] 2021-07-09 16:46:32,129 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 145
[INFO] 2021-07-09 16:46:32,129 [run_pretraining.py:  558]:	worker_index: 6, step: 145, cost: 6.396888, mlm loss: 6.396888, speed: 0.467857 steps/s, speed: 3.742854 samples/s, speed: 1916.341271 tokens/s, learning rate: 1.440e-06, loss_scalings: 16777.216797, pp_loss: 6.316120
[INFO] 2021-07-09 16:46:32,129 [run_pretraining.py:  512]:	********exe.run_145******* 
[INFO] 2021-07-09 16:46:34,237 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:34,237 [run_pretraining.py:  534]:	loss/total_loss, 6.200148582458496, 146
[INFO] 2021-07-09 16:46:34,237 [run_pretraining.py:  535]:	loss/mlm_loss, 6.200148582458496, 146
[INFO] 2021-07-09 16:46:34,237 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4499998997052899e-06, 146
[INFO] 2021-07-09 16:46:34,238 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 146
[INFO] 2021-07-09 16:46:34,238 [run_pretraining.py:  558]:	worker_index: 6, step: 146, cost: 6.200149, mlm loss: 6.200149, speed: 0.474395 steps/s, speed: 3.795159 samples/s, speed: 1943.121218 tokens/s, learning rate: 1.450e-06, loss_scalings: 16777.216797, pp_loss: 6.258674
[INFO] 2021-07-09 16:46:34,238 [run_pretraining.py:  512]:	********exe.run_146******* 
[INFO] 2021-07-09 16:46:36,425 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:36,426 [run_pretraining.py:  534]:	loss/total_loss, 6.118992805480957, 147
[INFO] 2021-07-09 16:46:36,426 [run_pretraining.py:  535]:	loss/mlm_loss, 6.118992805480957, 147
[INFO] 2021-07-09 16:46:36,426 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4600000213249587e-06, 147
[INFO] 2021-07-09 16:46:36,426 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 147
[INFO] 2021-07-09 16:46:36,426 [run_pretraining.py:  558]:	worker_index: 6, step: 147, cost: 6.118993, mlm loss: 6.118993, speed: 0.457031 steps/s, speed: 3.656245 samples/s, speed: 1871.997460 tokens/s, learning rate: 1.460e-06, loss_scalings: 16777.216797, pp_loss: 6.222261
[INFO] 2021-07-09 16:46:36,426 [run_pretraining.py:  512]:	********exe.run_147******* 
[INFO] 2021-07-09 16:46:38,650 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:38,650 [run_pretraining.py:  534]:	loss/total_loss, 6.184569835662842, 148
[INFO] 2021-07-09 16:46:38,650 [run_pretraining.py:  535]:	loss/mlm_loss, 6.184569835662842, 148
[INFO] 2021-07-09 16:46:38,650 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4700000292577897e-06, 148
[INFO] 2021-07-09 16:46:38,650 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 148
[INFO] 2021-07-09 16:46:38,651 [run_pretraining.py:  558]:	worker_index: 6, step: 148, cost: 6.184570, mlm loss: 6.184570, speed: 0.449736 steps/s, speed: 3.597888 samples/s, speed: 1842.118833 tokens/s, learning rate: 1.470e-06, loss_scalings: 16777.216797, pp_loss: 6.151841
[INFO] 2021-07-09 16:46:38,651 [run_pretraining.py:  512]:	********exe.run_148******* 
[INFO] 2021-07-09 16:46:40,920 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:40,921 [run_pretraining.py:  534]:	loss/total_loss, 6.245010852813721, 149
[INFO] 2021-07-09 16:46:40,921 [run_pretraining.py:  535]:	loss/mlm_loss, 6.245010852813721, 149
[INFO] 2021-07-09 16:46:40,921 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.479999923503783e-06, 149
[INFO] 2021-07-09 16:46:40,921 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 149
[INFO] 2021-07-09 16:46:40,921 [run_pretraining.py:  558]:	worker_index: 6, step: 149, cost: 6.245011, mlm loss: 6.245011, speed: 0.440511 steps/s, speed: 3.524088 samples/s, speed: 1804.333288 tokens/s, learning rate: 1.480e-06, loss_scalings: 16777.216797, pp_loss: 6.141716
[INFO] 2021-07-09 16:46:40,921 [run_pretraining.py:  512]:	********exe.run_149******* 
[INFO] 2021-07-09 16:46:43,172 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:43,172 [run_pretraining.py:  534]:	loss/total_loss, 6.098794937133789, 150
[INFO] 2021-07-09 16:46:43,172 [run_pretraining.py:  535]:	loss/mlm_loss, 6.098794937133789, 150
[INFO] 2021-07-09 16:46:43,173 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4899999314366141e-06, 150
[INFO] 2021-07-09 16:46:43,173 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 150
[INFO] 2021-07-09 16:46:43,173 [run_pretraining.py:  558]:	worker_index: 6, step: 150, cost: 6.098795, mlm loss: 6.098795, speed: 0.444320 steps/s, speed: 3.554559 samples/s, speed: 1819.934171 tokens/s, learning rate: 1.490e-06, loss_scalings: 16777.216797, pp_loss: 6.103621
[INFO] 2021-07-09 16:46:43,173 [run_pretraining.py:  512]:	********exe.run_150******* 
[INFO] 2021-07-09 16:46:45,412 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:45,412 [run_pretraining.py:  534]:	loss/total_loss, 6.015652179718018, 151
[INFO] 2021-07-09 16:46:45,412 [run_pretraining.py:  535]:	loss/mlm_loss, 6.015652179718018, 151
[INFO] 2021-07-09 16:46:45,412 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4999999393694452e-06, 151
[INFO] 2021-07-09 16:46:45,412 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 151
[INFO] 2021-07-09 16:46:45,413 [run_pretraining.py:  558]:	worker_index: 6, step: 151, cost: 6.015652, mlm loss: 6.015652, speed: 0.446583 steps/s, speed: 3.572664 samples/s, speed: 1829.203984 tokens/s, learning rate: 1.500e-06, loss_scalings: 16777.216797, pp_loss: 6.118179
[INFO] 2021-07-09 16:46:45,413 [run_pretraining.py:  512]:	********exe.run_151******* 
[INFO] 2021-07-09 16:46:47,596 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:47,596 [run_pretraining.py:  534]:	loss/total_loss, 5.9931159019470215, 152
[INFO] 2021-07-09 16:46:47,596 [run_pretraining.py:  535]:	loss/mlm_loss, 5.9931159019470215, 152
[INFO] 2021-07-09 16:46:47,596 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.510000060989114e-06, 152
[INFO] 2021-07-09 16:46:47,597 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 152
[INFO] 2021-07-09 16:46:47,597 [run_pretraining.py:  558]:	worker_index: 6, step: 152, cost: 5.993116, mlm loss: 5.993116, speed: 0.457996 steps/s, speed: 3.663965 samples/s, speed: 1875.949973 tokens/s, learning rate: 1.510e-06, loss_scalings: 16777.216797, pp_loss: 6.077949
[INFO] 2021-07-09 16:46:47,597 [run_pretraining.py:  512]:	********exe.run_152******* 
[INFO] 2021-07-09 16:46:49,797 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:49,798 [run_pretraining.py:  534]:	loss/total_loss, 5.965797424316406, 153
[INFO] 2021-07-09 16:46:49,798 [run_pretraining.py:  535]:	loss/mlm_loss, 5.965797424316406, 153
[INFO] 2021-07-09 16:46:49,798 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5199999552351073e-06, 153
[INFO] 2021-07-09 16:46:49,798 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 153
[INFO] 2021-07-09 16:46:49,798 [run_pretraining.py:  558]:	worker_index: 6, step: 153, cost: 5.965797, mlm loss: 5.965797, speed: 0.454345 steps/s, speed: 3.634762 samples/s, speed: 1860.998110 tokens/s, learning rate: 1.520e-06, loss_scalings: 16777.216797, pp_loss: 5.985896
[INFO] 2021-07-09 16:46:49,798 [run_pretraining.py:  512]:	********exe.run_153******* 
[INFO] 2021-07-09 16:46:52,048 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:52,049 [run_pretraining.py:  534]:	loss/total_loss, 5.97144889831543, 154
[INFO] 2021-07-09 16:46:52,049 [run_pretraining.py:  535]:	loss/mlm_loss, 5.97144889831543, 154
[INFO] 2021-07-09 16:46:52,049 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5299999631679384e-06, 154
[INFO] 2021-07-09 16:46:52,049 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 154
[INFO] 2021-07-09 16:46:52,049 [run_pretraining.py:  558]:	worker_index: 6, step: 154, cost: 5.971449, mlm loss: 5.971449, speed: 0.444364 steps/s, speed: 3.554916 samples/s, speed: 1820.116764 tokens/s, learning rate: 1.530e-06, loss_scalings: 16777.216797, pp_loss: 5.976540
[INFO] 2021-07-09 16:46:52,050 [run_pretraining.py:  512]:	********exe.run_154******* 
[INFO] 2021-07-09 16:46:54,313 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:54,313 [run_pretraining.py:  534]:	loss/total_loss, 5.903803825378418, 155
[INFO] 2021-07-09 16:46:54,313 [run_pretraining.py:  535]:	loss/mlm_loss, 5.903803825378418, 155
[INFO] 2021-07-09 16:46:54,313 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5399999711007695e-06, 155
[INFO] 2021-07-09 16:46:54,313 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 155
[INFO] 2021-07-09 16:46:54,313 [run_pretraining.py:  558]:	worker_index: 6, step: 155, cost: 5.903804, mlm loss: 5.903804, speed: 0.441817 steps/s, speed: 3.534539 samples/s, speed: 1809.684158 tokens/s, learning rate: 1.540e-06, loss_scalings: 16777.216797, pp_loss: 5.949349
[INFO] 2021-07-09 16:46:54,314 [run_pretraining.py:  512]:	********exe.run_155******* 
[INFO] 2021-07-09 16:46:56,503 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:56,504 [run_pretraining.py:  534]:	loss/total_loss, 5.896737575531006, 156
[INFO] 2021-07-09 16:46:56,504 [run_pretraining.py:  535]:	loss/mlm_loss, 5.896737575531006, 156
[INFO] 2021-07-09 16:46:56,504 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5499999790336005e-06, 156
[INFO] 2021-07-09 16:46:56,504 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 156
[INFO] 2021-07-09 16:46:56,505 [run_pretraining.py:  558]:	worker_index: 6, step: 156, cost: 5.896738, mlm loss: 5.896738, speed: 0.456551 steps/s, speed: 3.652408 samples/s, speed: 1870.032735 tokens/s, learning rate: 1.550e-06, loss_scalings: 16777.216797, pp_loss: 5.901082
[INFO] 2021-07-09 16:46:56,505 [run_pretraining.py:  512]:	********exe.run_156******* 
[INFO] 2021-07-09 16:46:58,692 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:58,693 [run_pretraining.py:  534]:	loss/total_loss, 5.911875247955322, 157
[INFO] 2021-07-09 16:46:58,693 [run_pretraining.py:  535]:	loss/mlm_loss, 5.911875247955322, 157
[INFO] 2021-07-09 16:46:58,693 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5599998732795939e-06, 157
[INFO] 2021-07-09 16:46:58,693 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 157
[INFO] 2021-07-09 16:46:58,693 [run_pretraining.py:  558]:	worker_index: 6, step: 157, cost: 5.911875, mlm loss: 5.911875, speed: 0.457082 steps/s, speed: 3.656659 samples/s, speed: 1872.209217 tokens/s, learning rate: 1.560e-06, loss_scalings: 16777.216797, pp_loss: 5.838614
[INFO] 2021-07-09 16:46:58,693 [run_pretraining.py:  512]:	********exe.run_157******* 
[INFO] 2021-07-09 16:47:00,880 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:00,881 [run_pretraining.py:  534]:	loss/total_loss, 5.78732442855835, 158
[INFO] 2021-07-09 16:47:00,881 [run_pretraining.py:  535]:	loss/mlm_loss, 5.78732442855835, 158
[INFO] 2021-07-09 16:47:00,881 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.569999881212425e-06, 158
[INFO] 2021-07-09 16:47:00,881 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 158
[INFO] 2021-07-09 16:47:00,881 [run_pretraining.py:  558]:	worker_index: 6, step: 158, cost: 5.787324, mlm loss: 5.787324, speed: 0.457106 steps/s, speed: 3.656848 samples/s, speed: 1872.306339 tokens/s, learning rate: 1.570e-06, loss_scalings: 16777.216797, pp_loss: 5.780276
[INFO] 2021-07-09 16:47:00,882 [run_pretraining.py:  512]:	********exe.run_158******* 
[INFO] 2021-07-09 16:47:03,085 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:03,086 [run_pretraining.py:  534]:	loss/total_loss, 5.848836421966553, 159
[INFO] 2021-07-09 16:47:03,086 [run_pretraining.py:  535]:	loss/mlm_loss, 5.848836421966553, 159
[INFO] 2021-07-09 16:47:03,086 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.579999889145256e-06, 159
[INFO] 2021-07-09 16:47:03,086 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 159
[INFO] 2021-07-09 16:47:03,086 [run_pretraining.py:  558]:	worker_index: 6, step: 159, cost: 5.848836, mlm loss: 5.848836, speed: 0.453772 steps/s, speed: 3.630174 samples/s, speed: 1858.649111 tokens/s, learning rate: 1.580e-06, loss_scalings: 16777.216797, pp_loss: 5.743936
[INFO] 2021-07-09 16:47:03,086 [run_pretraining.py:  512]:	********exe.run_159******* 
[INFO] 2021-07-09 16:47:05,326 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:05,327 [run_pretraining.py:  534]:	loss/total_loss, 5.748404026031494, 160
[INFO] 2021-07-09 16:47:05,327 [run_pretraining.py:  535]:	loss/mlm_loss, 5.748404026031494, 160
[INFO] 2021-07-09 16:47:05,327 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5900000107649248e-06, 160
[INFO] 2021-07-09 16:47:05,327 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 160
[INFO] 2021-07-09 16:47:05,328 [run_pretraining.py:  558]:	worker_index: 6, step: 160, cost: 5.748404, mlm loss: 5.748404, speed: 0.446244 steps/s, speed: 3.569951 samples/s, speed: 1827.814828 tokens/s, learning rate: 1.590e-06, loss_scalings: 16777.216797, pp_loss: 5.712490
[INFO] 2021-07-09 16:47:05,328 [run_pretraining.py:  512]:	********exe.run_160******* 
[INFO] 2021-07-09 16:47:07,603 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:07,604 [run_pretraining.py:  534]:	loss/total_loss, 5.669936180114746, 161
[INFO] 2021-07-09 16:47:07,604 [run_pretraining.py:  535]:	loss/mlm_loss, 5.669936180114746, 161
[INFO] 2021-07-09 16:47:07,604 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6000000186977559e-06, 161
[INFO] 2021-07-09 16:47:07,604 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 161
[INFO] 2021-07-09 16:47:07,604 [run_pretraining.py:  558]:	worker_index: 6, step: 161, cost: 5.669936, mlm loss: 5.669936, speed: 0.439367 steps/s, speed: 3.514936 samples/s, speed: 1799.647357 tokens/s, learning rate: 1.600e-06, loss_scalings: 16777.216797, pp_loss: 5.670748
[INFO] 2021-07-09 16:47:07,604 [run_pretraining.py:  512]:	********exe.run_161******* 
[INFO] 2021-07-09 16:47:09,827 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:09,828 [run_pretraining.py:  534]:	loss/total_loss, 5.699754238128662, 162
[INFO] 2021-07-09 16:47:09,828 [run_pretraining.py:  535]:	loss/mlm_loss, 5.699754238128662, 162
[INFO] 2021-07-09 16:47:09,828 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.610000026630587e-06, 162
[INFO] 2021-07-09 16:47:09,828 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 162
[INFO] 2021-07-09 16:47:09,828 [run_pretraining.py:  558]:	worker_index: 6, step: 162, cost: 5.699754, mlm loss: 5.699754, speed: 0.449766 steps/s, speed: 3.598130 samples/s, speed: 1842.242490 tokens/s, learning rate: 1.610e-06, loss_scalings: 16777.216797, pp_loss: 5.660531
[INFO] 2021-07-09 16:47:09,828 [run_pretraining.py:  512]:	********exe.run_162******* 
[INFO] 2021-07-09 16:47:12,113 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:12,114 [run_pretraining.py:  534]:	loss/total_loss, 5.6206159591674805, 163
[INFO] 2021-07-09 16:47:12,114 [run_pretraining.py:  535]:	loss/mlm_loss, 5.6206159591674805, 163
[INFO] 2021-07-09 16:47:12,114 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.620000034563418e-06, 163
[INFO] 2021-07-09 16:47:12,114 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 163
[INFO] 2021-07-09 16:47:12,114 [run_pretraining.py:  558]:	worker_index: 6, step: 163, cost: 5.620616, mlm loss: 5.620616, speed: 0.437593 steps/s, speed: 3.500745 samples/s, speed: 1792.381318 tokens/s, learning rate: 1.620e-06, loss_scalings: 16777.216797, pp_loss: 5.651871
[INFO] 2021-07-09 16:47:12,114 [run_pretraining.py:  512]:	********exe.run_163******* 
[INFO] 2021-07-09 16:47:14,684 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:14,685 [run_pretraining.py:  534]:	loss/total_loss, 5.523527145385742, 164
[INFO] 2021-07-09 16:47:14,685 [run_pretraining.py:  535]:	loss/mlm_loss, 5.523527145385742, 164
[INFO] 2021-07-09 16:47:14,685 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6299999288094114e-06, 164
[INFO] 2021-07-09 16:47:14,685 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 164
[INFO] 2021-07-09 16:47:14,685 [run_pretraining.py:  558]:	worker_index: 6, step: 164, cost: 5.523527, mlm loss: 5.523527, speed: 0.389030 steps/s, speed: 3.112238 samples/s, speed: 1593.465848 tokens/s, learning rate: 1.630e-06, loss_scalings: 16777.216797, pp_loss: 5.523669
[INFO] 2021-07-09 16:47:14,685 [run_pretraining.py:  512]:	********exe.run_164******* 
[INFO] 2021-07-09 16:47:17,086 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:17,087 [run_pretraining.py:  534]:	loss/total_loss, 5.510429382324219, 165
[INFO] 2021-07-09 16:47:17,087 [run_pretraining.py:  535]:	loss/mlm_loss, 5.510429382324219, 165
[INFO] 2021-07-09 16:47:17,087 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6399999367422424e-06, 165
[INFO] 2021-07-09 16:47:17,087 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 165
[INFO] 2021-07-09 16:47:17,087 [run_pretraining.py:  558]:	worker_index: 6, step: 165, cost: 5.510429, mlm loss: 5.510429, speed: 0.416497 steps/s, speed: 3.331975 samples/s, speed: 1705.971251 tokens/s, learning rate: 1.640e-06, loss_scalings: 16777.216797, pp_loss: 5.478857
[INFO] 2021-07-09 16:47:17,087 [run_pretraining.py:  512]:	********exe.run_165******* 
[INFO] 2021-07-09 16:47:19,371 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:19,371 [run_pretraining.py:  534]:	loss/total_loss, 5.439363956451416, 166
[INFO] 2021-07-09 16:47:19,371 [run_pretraining.py:  535]:	loss/mlm_loss, 5.439363956451416, 166
[INFO] 2021-07-09 16:47:19,372 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6499999446750735e-06, 166
[INFO] 2021-07-09 16:47:19,372 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 166
[INFO] 2021-07-09 16:47:19,372 [run_pretraining.py:  558]:	worker_index: 6, step: 166, cost: 5.439364, mlm loss: 5.439364, speed: 0.437812 steps/s, speed: 3.502497 samples/s, speed: 1793.278243 tokens/s, learning rate: 1.650e-06, loss_scalings: 16777.216797, pp_loss: 5.480738
[INFO] 2021-07-09 16:47:19,372 [run_pretraining.py:  512]:	********exe.run_166******* 
[INFO] 2021-07-09 16:47:21,628 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:21,629 [run_pretraining.py:  534]:	loss/total_loss, 5.429421901702881, 167
[INFO] 2021-07-09 16:47:21,629 [run_pretraining.py:  535]:	loss/mlm_loss, 5.429421901702881, 167
[INFO] 2021-07-09 16:47:21,629 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6599999526079046e-06, 167
[INFO] 2021-07-09 16:47:21,629 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 167
[INFO] 2021-07-09 16:47:21,629 [run_pretraining.py:  558]:	worker_index: 6, step: 167, cost: 5.429422, mlm loss: 5.429422, speed: 0.443061 steps/s, speed: 3.544484 samples/s, speed: 1814.775808 tokens/s, learning rate: 1.660e-06, loss_scalings: 16777.216797, pp_loss: 5.423755
[INFO] 2021-07-09 16:47:21,629 [run_pretraining.py:  512]:	********exe.run_167******* 
[INFO] 2021-07-09 16:47:23,819 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:23,819 [run_pretraining.py:  534]:	loss/total_loss, 5.586744785308838, 168
[INFO] 2021-07-09 16:47:23,820 [run_pretraining.py:  535]:	loss/mlm_loss, 5.586744785308838, 168
[INFO] 2021-07-09 16:47:23,820 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6699999605407356e-06, 168
[INFO] 2021-07-09 16:47:23,820 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 168
[INFO] 2021-07-09 16:47:23,820 [run_pretraining.py:  558]:	worker_index: 6, step: 168, cost: 5.586745, mlm loss: 5.586745, speed: 0.456683 steps/s, speed: 3.653461 samples/s, speed: 1870.572104 tokens/s, learning rate: 1.670e-06, loss_scalings: 16777.216797, pp_loss: 5.469180
[INFO] 2021-07-09 16:47:23,820 [run_pretraining.py:  512]:	********exe.run_168******* 
[INFO] 2021-07-09 16:47:26,033 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:26,033 [run_pretraining.py:  534]:	loss/total_loss, 5.356299877166748, 169
[INFO] 2021-07-09 16:47:26,034 [run_pretraining.py:  535]:	loss/mlm_loss, 5.356299877166748, 169
[INFO] 2021-07-09 16:47:26,034 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.679999854786729e-06, 169
[INFO] 2021-07-09 16:47:26,034 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 169
[INFO] 2021-07-09 16:47:26,034 [run_pretraining.py:  558]:	worker_index: 6, step: 169, cost: 5.356300, mlm loss: 5.356300, speed: 0.451825 steps/s, speed: 3.614598 samples/s, speed: 1850.674347 tokens/s, learning rate: 1.680e-06, loss_scalings: 16777.216797, pp_loss: 5.437085
[INFO] 2021-07-09 16:47:26,034 [run_pretraining.py:  512]:	********exe.run_169******* 
[INFO] 2021-07-09 16:47:28,221 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:28,221 [run_pretraining.py:  534]:	loss/total_loss, 5.3033366203308105, 170
[INFO] 2021-07-09 16:47:28,221 [run_pretraining.py:  535]:	loss/mlm_loss, 5.3033366203308105, 170
[INFO] 2021-07-09 16:47:28,221 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.68999986271956e-06, 170
[INFO] 2021-07-09 16:47:28,222 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 170
[INFO] 2021-07-09 16:47:28,222 [run_pretraining.py:  558]:	worker_index: 6, step: 170, cost: 5.303337, mlm loss: 5.303337, speed: 0.457206 steps/s, speed: 3.657648 samples/s, speed: 1872.715750 tokens/s, learning rate: 1.690e-06, loss_scalings: 16777.216797, pp_loss: 5.341701
[INFO] 2021-07-09 16:47:28,222 [run_pretraining.py:  512]:	********exe.run_170******* 
[INFO] 2021-07-09 16:47:30,408 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:30,409 [run_pretraining.py:  534]:	loss/total_loss, 5.277907371520996, 171
[INFO] 2021-07-09 16:47:30,409 [run_pretraining.py:  535]:	loss/mlm_loss, 5.277907371520996, 171
[INFO] 2021-07-09 16:47:30,409 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7000000980260666e-06, 171
[INFO] 2021-07-09 16:47:30,409 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 171
[INFO] 2021-07-09 16:47:30,410 [run_pretraining.py:  558]:	worker_index: 6, step: 171, cost: 5.277907, mlm loss: 5.277907, speed: 0.457196 steps/s, speed: 3.657567 samples/s, speed: 1872.674107 tokens/s, learning rate: 1.700e-06, loss_scalings: 16777.216797, pp_loss: 5.296355
[INFO] 2021-07-09 16:47:30,410 [run_pretraining.py:  512]:	********exe.run_171******* 
[INFO] 2021-07-09 16:47:32,599 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:32,600 [run_pretraining.py:  534]:	loss/total_loss, 5.217576026916504, 172
[INFO] 2021-07-09 16:47:32,600 [run_pretraining.py:  535]:	loss/mlm_loss, 5.217576026916504, 172
[INFO] 2021-07-09 16:47:32,600 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.70999999227206e-06, 172
[INFO] 2021-07-09 16:47:32,600 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 172
[INFO] 2021-07-09 16:47:32,600 [run_pretraining.py:  558]:	worker_index: 6, step: 172, cost: 5.217576, mlm loss: 5.217576, speed: 0.456689 steps/s, speed: 3.653511 samples/s, speed: 1870.597563 tokens/s, learning rate: 1.710e-06, loss_scalings: 16777.216797, pp_loss: 5.261248
[INFO] 2021-07-09 16:47:32,600 [run_pretraining.py:  512]:	********exe.run_172******* 
[INFO] 2021-07-09 16:47:34,796 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:34,797 [run_pretraining.py:  534]:	loss/total_loss, 5.241450309753418, 173
[INFO] 2021-07-09 16:47:34,797 [run_pretraining.py:  535]:	loss/mlm_loss, 5.241450309753418, 173
[INFO] 2021-07-09 16:47:34,797 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.720000000204891e-06, 173
[INFO] 2021-07-09 16:47:34,797 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 173
[INFO] 2021-07-09 16:47:34,797 [run_pretraining.py:  558]:	worker_index: 6, step: 173, cost: 5.241450, mlm loss: 5.241450, speed: 0.455281 steps/s, speed: 3.642247 samples/s, speed: 1864.830578 tokens/s, learning rate: 1.720e-06, loss_scalings: 16777.216797, pp_loss: 5.211347
[INFO] 2021-07-09 16:47:34,797 [run_pretraining.py:  512]:	********exe.run_173******* 
[INFO] 2021-07-09 16:47:37,076 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:37,077 [run_pretraining.py:  534]:	loss/total_loss, 5.182369232177734, 174
[INFO] 2021-07-09 16:47:37,077 [run_pretraining.py:  535]:	loss/mlm_loss, 5.182369232177734, 174
[INFO] 2021-07-09 16:47:37,077 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.730000008137722e-06, 174
[INFO] 2021-07-09 16:47:37,077 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 174
[INFO] 2021-07-09 16:47:37,077 [run_pretraining.py:  558]:	worker_index: 6, step: 174, cost: 5.182369, mlm loss: 5.182369, speed: 0.438657 steps/s, speed: 3.509255 samples/s, speed: 1796.738694 tokens/s, learning rate: 1.730e-06, loss_scalings: 16777.216797, pp_loss: 5.156669
[INFO] 2021-07-09 16:47:37,078 [run_pretraining.py:  512]:	********exe.run_174******* 
[INFO] 2021-07-09 16:47:39,266 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:39,267 [run_pretraining.py:  534]:	loss/total_loss, 5.105576515197754, 175
[INFO] 2021-07-09 16:47:39,267 [run_pretraining.py:  535]:	loss/mlm_loss, 5.105576515197754, 175
[INFO] 2021-07-09 16:47:39,267 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.740000016070553e-06, 175
[INFO] 2021-07-09 16:47:39,267 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 175
[INFO] 2021-07-09 16:47:39,267 [run_pretraining.py:  558]:	worker_index: 6, step: 175, cost: 5.105577, mlm loss: 5.105577, speed: 0.456878 steps/s, speed: 3.655022 samples/s, speed: 1871.371039 tokens/s, learning rate: 1.740e-06, loss_scalings: 16777.216797, pp_loss: 5.185852
[INFO] 2021-07-09 16:47:39,267 [run_pretraining.py:  512]:	********exe.run_175******* 
[INFO] 2021-07-09 16:47:41,610 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:41,610 [run_pretraining.py:  534]:	loss/total_loss, 5.146729946136475, 176
[INFO] 2021-07-09 16:47:41,610 [run_pretraining.py:  535]:	loss/mlm_loss, 5.146729946136475, 176
[INFO] 2021-07-09 16:47:41,611 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7499999103165464e-06, 176
[INFO] 2021-07-09 16:47:41,611 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 176
[INFO] 2021-07-09 16:47:41,611 [run_pretraining.py:  558]:	worker_index: 6, step: 176, cost: 5.146730, mlm loss: 5.146730, speed: 0.426786 steps/s, speed: 3.414287 samples/s, speed: 1748.114981 tokens/s, learning rate: 1.750e-06, loss_scalings: 16777.216797, pp_loss: 5.149168
[INFO] 2021-07-09 16:47:41,611 [run_pretraining.py:  512]:	********exe.run_176******* 
[INFO] 2021-07-09 16:47:43,825 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:43,825 [run_pretraining.py:  534]:	loss/total_loss, 5.105823516845703, 177
[INFO] 2021-07-09 16:47:43,825 [run_pretraining.py:  535]:	loss/mlm_loss, 5.105823516845703, 177
[INFO] 2021-07-09 16:47:43,825 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7599999182493775e-06, 177
[INFO] 2021-07-09 16:47:43,825 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 177
[INFO] 2021-07-09 16:47:43,826 [run_pretraining.py:  558]:	worker_index: 6, step: 177, cost: 5.105824, mlm loss: 5.105824, speed: 0.451638 steps/s, speed: 3.613106 samples/s, speed: 1849.910312 tokens/s, learning rate: 1.760e-06, loss_scalings: 16777.216797, pp_loss: 5.096507
[INFO] 2021-07-09 16:47:43,826 [run_pretraining.py:  512]:	********exe.run_177******* 
[INFO] 2021-07-09 16:47:46,074 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:46,075 [run_pretraining.py:  534]:	loss/total_loss, 5.02103328704834, 178
[INFO] 2021-07-09 16:47:46,075 [run_pretraining.py:  535]:	loss/mlm_loss, 5.02103328704834, 178
[INFO] 2021-07-09 16:47:46,075 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7699999261822086e-06, 178
[INFO] 2021-07-09 16:47:46,075 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 178
[INFO] 2021-07-09 16:47:46,075 [run_pretraining.py:  558]:	worker_index: 6, step: 178, cost: 5.021033, mlm loss: 5.021033, speed: 0.444602 steps/s, speed: 3.556818 samples/s, speed: 1821.090893 tokens/s, learning rate: 1.770e-06, loss_scalings: 13421.773438, pp_loss: 5.089835
[INFO] 2021-07-09 16:47:46,076 [run_pretraining.py:  512]:	********exe.run_178******* 
[INFO] 2021-07-09 16:47:48,288 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:48,288 [run_pretraining.py:  534]:	loss/total_loss, 5.006838321685791, 179
[INFO] 2021-07-09 16:47:48,289 [run_pretraining.py:  535]:	loss/mlm_loss, 5.006838321685791, 179
[INFO] 2021-07-09 16:47:48,289 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7799999341150397e-06, 179
[INFO] 2021-07-09 16:47:48,289 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 179
[INFO] 2021-07-09 16:47:48,289 [run_pretraining.py:  558]:	worker_index: 6, step: 179, cost: 5.006838, mlm loss: 5.006838, speed: 0.451951 steps/s, speed: 3.615610 samples/s, speed: 1851.192432 tokens/s, learning rate: 1.780e-06, loss_scalings: 13421.773438, pp_loss: 5.077017
[INFO] 2021-07-09 16:47:48,289 [run_pretraining.py:  512]:	********exe.run_179******* 
[INFO] 2021-07-09 16:47:50,497 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:50,498 [run_pretraining.py:  534]:	loss/total_loss, 4.999573230743408, 180
[INFO] 2021-07-09 16:47:50,498 [run_pretraining.py:  535]:	loss/mlm_loss, 4.999573230743408, 180
[INFO] 2021-07-09 16:47:50,498 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7899999420478707e-06, 180
[INFO] 2021-07-09 16:47:50,498 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 180
[INFO] 2021-07-09 16:47:50,498 [run_pretraining.py:  558]:	worker_index: 6, step: 180, cost: 4.999573, mlm loss: 4.999573, speed: 0.452758 steps/s, speed: 3.622067 samples/s, speed: 1854.498200 tokens/s, learning rate: 1.790e-06, loss_scalings: 13421.773438, pp_loss: 4.998284
[INFO] 2021-07-09 16:47:50,498 [run_pretraining.py:  512]:	********exe.run_180******* 
[INFO] 2021-07-09 16:47:52,714 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:52,715 [run_pretraining.py:  534]:	loss/total_loss, 4.98487663269043, 181
[INFO] 2021-07-09 16:47:52,715 [run_pretraining.py:  535]:	loss/mlm_loss, 4.98487663269043, 181
[INFO] 2021-07-09 16:47:52,715 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.799999836293864e-06, 181
[INFO] 2021-07-09 16:47:52,715 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 181
[INFO] 2021-07-09 16:47:52,715 [run_pretraining.py:  558]:	worker_index: 6, step: 181, cost: 4.984877, mlm loss: 4.984877, speed: 0.451184 steps/s, speed: 3.609471 samples/s, speed: 1848.049103 tokens/s, learning rate: 1.800e-06, loss_scalings: 13421.773438, pp_loss: 4.992484
[INFO] 2021-07-09 16:47:52,715 [run_pretraining.py:  512]:	********exe.run_181******* 
[INFO] 2021-07-09 16:47:54,968 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:54,968 [run_pretraining.py:  534]:	loss/total_loss, 4.898664474487305, 182
[INFO] 2021-07-09 16:47:54,969 [run_pretraining.py:  535]:	loss/mlm_loss, 4.898664474487305, 182
[INFO] 2021-07-09 16:47:54,969 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8100000716003706e-06, 182
[INFO] 2021-07-09 16:47:54,969 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 182
[INFO] 2021-07-09 16:47:54,969 [run_pretraining.py:  558]:	worker_index: 6, step: 182, cost: 4.898664, mlm loss: 4.898664, speed: 0.443851 steps/s, speed: 3.550805 samples/s, speed: 1818.012128 tokens/s, learning rate: 1.810e-06, loss_scalings: 13421.773438, pp_loss: 4.956656
[INFO] 2021-07-09 16:47:54,969 [run_pretraining.py:  512]:	********exe.run_182******* 
[INFO] 2021-07-09 16:47:57,190 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:57,190 [run_pretraining.py:  534]:	loss/total_loss, 4.909988880157471, 183
[INFO] 2021-07-09 16:47:57,190 [run_pretraining.py:  535]:	loss/mlm_loss, 4.909988880157471, 183
[INFO] 2021-07-09 16:47:57,191 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8200000795332016e-06, 183
[INFO] 2021-07-09 16:47:57,191 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 183
[INFO] 2021-07-09 16:47:57,191 [run_pretraining.py:  558]:	worker_index: 6, step: 183, cost: 4.909989, mlm loss: 4.909989, speed: 0.450200 steps/s, speed: 3.601597 samples/s, speed: 1844.017592 tokens/s, learning rate: 1.820e-06, loss_scalings: 13421.773438, pp_loss: 4.963231
[INFO] 2021-07-09 16:47:57,191 [run_pretraining.py:  512]:	********exe.run_183******* 
[INFO] 2021-07-09 16:47:59,431 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:59,431 [run_pretraining.py:  534]:	loss/total_loss, 4.89324951171875, 184
[INFO] 2021-07-09 16:47:59,431 [run_pretraining.py:  535]:	loss/mlm_loss, 4.89324951171875, 184
[INFO] 2021-07-09 16:47:59,431 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.829999973779195e-06, 184
[INFO] 2021-07-09 16:47:59,432 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 184
[INFO] 2021-07-09 16:47:59,432 [run_pretraining.py:  558]:	worker_index: 6, step: 184, cost: 4.893250, mlm loss: 4.893250, speed: 0.446390 steps/s, speed: 3.571117 samples/s, speed: 1828.411840 tokens/s, learning rate: 1.830e-06, loss_scalings: 13421.773438, pp_loss: 4.891864
[INFO] 2021-07-09 16:47:59,432 [run_pretraining.py:  512]:	********exe.run_184******* 
[INFO] 2021-07-09 16:48:01,634 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:01,635 [run_pretraining.py:  534]:	loss/total_loss, 4.846097946166992, 185
[INFO] 2021-07-09 16:48:01,635 [run_pretraining.py:  535]:	loss/mlm_loss, 4.846097946166992, 185
[INFO] 2021-07-09 16:48:01,635 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.839999981712026e-06, 185
[INFO] 2021-07-09 16:48:01,635 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 185
[INFO] 2021-07-09 16:48:01,635 [run_pretraining.py:  558]:	worker_index: 6, step: 185, cost: 4.846098, mlm loss: 4.846098, speed: 0.453978 steps/s, speed: 3.631824 samples/s, speed: 1859.493842 tokens/s, learning rate: 1.840e-06, loss_scalings: 13421.773438, pp_loss: 4.844055
[INFO] 2021-07-09 16:48:01,635 [run_pretraining.py:  512]:	********exe.run_185******* 
[INFO] 2021-07-09 16:48:03,842 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:03,843 [run_pretraining.py:  534]:	loss/total_loss, 4.774092197418213, 186
[INFO] 2021-07-09 16:48:03,843 [run_pretraining.py:  535]:	loss/mlm_loss, 4.774092197418213, 186
[INFO] 2021-07-09 16:48:03,843 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8499999896448571e-06, 186
[INFO] 2021-07-09 16:48:03,843 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 186
[INFO] 2021-07-09 16:48:03,843 [run_pretraining.py:  558]:	worker_index: 6, step: 186, cost: 4.774092, mlm loss: 4.774092, speed: 0.453046 steps/s, speed: 3.624368 samples/s, speed: 1855.676641 tokens/s, learning rate: 1.850e-06, loss_scalings: 13421.773438, pp_loss: 4.810248
[INFO] 2021-07-09 16:48:03,843 [run_pretraining.py:  512]:	********exe.run_186******* 
[INFO] 2021-07-09 16:48:06,092 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:06,093 [run_pretraining.py:  534]:	loss/total_loss, 4.7788567543029785, 187
[INFO] 2021-07-09 16:48:06,093 [run_pretraining.py:  535]:	loss/mlm_loss, 4.7788567543029785, 187
[INFO] 2021-07-09 16:48:06,093 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8599999975776882e-06, 187
[INFO] 2021-07-09 16:48:06,093 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 187
[INFO] 2021-07-09 16:48:06,093 [run_pretraining.py:  558]:	worker_index: 6, step: 187, cost: 4.778857, mlm loss: 4.778857, speed: 0.444567 steps/s, speed: 3.556537 samples/s, speed: 1820.947091 tokens/s, learning rate: 1.860e-06, loss_scalings: 13421.773438, pp_loss: 4.782920
[INFO] 2021-07-09 16:48:06,093 [run_pretraining.py:  512]:	********exe.run_187******* 
[INFO] 2021-07-09 16:48:08,288 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:08,289 [run_pretraining.py:  534]:	loss/total_loss, 4.773646831512451, 188
[INFO] 2021-07-09 16:48:08,289 [run_pretraining.py:  535]:	loss/mlm_loss, 4.773646831512451, 188
[INFO] 2021-07-09 16:48:08,289 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8699998918236815e-06, 188
[INFO] 2021-07-09 16:48:08,289 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 188
[INFO] 2021-07-09 16:48:08,289 [run_pretraining.py:  558]:	worker_index: 6, step: 188, cost: 4.773647, mlm loss: 4.773647, speed: 0.455485 steps/s, speed: 3.643876 samples/s, speed: 1865.664527 tokens/s, learning rate: 1.870e-06, loss_scalings: 13421.773438, pp_loss: 4.737706
[INFO] 2021-07-09 16:48:08,289 [run_pretraining.py:  512]:	********exe.run_188******* 
[INFO] 2021-07-09 16:48:10,526 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:10,527 [run_pretraining.py:  534]:	loss/total_loss, 4.698244094848633, 189
[INFO] 2021-07-09 16:48:10,527 [run_pretraining.py:  535]:	loss/mlm_loss, 4.698244094848633, 189
[INFO] 2021-07-09 16:48:10,527 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8799998997565126e-06, 189
[INFO] 2021-07-09 16:48:10,527 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 189
[INFO] 2021-07-09 16:48:10,527 [run_pretraining.py:  558]:	worker_index: 6, step: 189, cost: 4.698244, mlm loss: 4.698244, speed: 0.446968 steps/s, speed: 3.575743 samples/s, speed: 1830.780382 tokens/s, learning rate: 1.880e-06, loss_scalings: 13421.773438, pp_loss: 4.758451
[INFO] 2021-07-09 16:48:10,527 [run_pretraining.py:  512]:	********exe.run_189******* 
[INFO] 2021-07-09 16:48:12,842 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:12,842 [run_pretraining.py:  534]:	loss/total_loss, 4.712100982666016, 190
[INFO] 2021-07-09 16:48:12,842 [run_pretraining.py:  535]:	loss/mlm_loss, 4.712100982666016, 190
[INFO] 2021-07-09 16:48:12,843 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8899999076893437e-06, 190
[INFO] 2021-07-09 16:48:12,843 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 190
[INFO] 2021-07-09 16:48:12,843 [run_pretraining.py:  558]:	worker_index: 6, step: 190, cost: 4.712101, mlm loss: 4.712101, speed: 0.431989 steps/s, speed: 3.455909 samples/s, speed: 1769.425170 tokens/s, learning rate: 1.890e-06, loss_scalings: 13421.773438, pp_loss: 4.704107
[INFO] 2021-07-09 16:48:12,843 [run_pretraining.py:  512]:	********exe.run_190******* 
[INFO] 2021-07-09 16:48:15,115 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:15,115 [run_pretraining.py:  534]:	loss/total_loss, 4.668918609619141, 191
[INFO] 2021-07-09 16:48:15,115 [run_pretraining.py:  535]:	loss/mlm_loss, 4.668918609619141, 191
[INFO] 2021-07-09 16:48:15,115 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8999999156221747e-06, 191
[INFO] 2021-07-09 16:48:15,116 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 191
[INFO] 2021-07-09 16:48:15,116 [run_pretraining.py:  558]:	worker_index: 6, step: 191, cost: 4.668919, mlm loss: 4.668919, speed: 0.440081 steps/s, speed: 3.520649 samples/s, speed: 1802.572450 tokens/s, learning rate: 1.900e-06, loss_scalings: 13421.773438, pp_loss: 4.691255
[INFO] 2021-07-09 16:48:15,116 [run_pretraining.py:  512]:	********exe.run_191******* 
[INFO] 2021-07-09 16:48:17,308 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:17,308 [run_pretraining.py:  534]:	loss/total_loss, 4.583901882171631, 192
[INFO] 2021-07-09 16:48:17,309 [run_pretraining.py:  535]:	loss/mlm_loss, 4.583901882171631, 192
[INFO] 2021-07-09 16:48:17,309 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.909999809868168e-06, 192
[INFO] 2021-07-09 16:48:17,309 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 192
[INFO] 2021-07-09 16:48:17,309 [run_pretraining.py:  558]:	worker_index: 6, step: 192, cost: 4.583902, mlm loss: 4.583902, speed: 0.456110 steps/s, speed: 3.648883 samples/s, speed: 1868.228348 tokens/s, learning rate: 1.910e-06, loss_scalings: 13421.773438, pp_loss: 4.657634
[INFO] 2021-07-09 16:48:17,309 [run_pretraining.py:  512]:	********exe.run_192******* 
[INFO] 2021-07-09 16:48:19,600 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:19,600 [run_pretraining.py:  534]:	loss/total_loss, 4.643670558929443, 193
[INFO] 2021-07-09 16:48:19,600 [run_pretraining.py:  535]:	loss/mlm_loss, 4.643670558929443, 193
[INFO] 2021-07-09 16:48:19,600 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.919999931487837e-06, 193
[INFO] 2021-07-09 16:48:19,600 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 193
[INFO] 2021-07-09 16:48:19,600 [run_pretraining.py:  558]:	worker_index: 6, step: 193, cost: 4.643671, mlm loss: 4.643671, speed: 0.436497 steps/s, speed: 3.491979 samples/s, speed: 1787.893370 tokens/s, learning rate: 1.920e-06, loss_scalings: 13421.773438, pp_loss: 4.641912
[INFO] 2021-07-09 16:48:19,600 [run_pretraining.py:  512]:	********exe.run_193******* 
[INFO] 2021-07-09 16:48:21,832 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:21,833 [run_pretraining.py:  534]:	loss/total_loss, 4.621647357940674, 194
[INFO] 2021-07-09 16:48:21,833 [run_pretraining.py:  535]:	loss/mlm_loss, 4.621647357940674, 194
[INFO] 2021-07-09 16:48:21,833 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9300000531075057e-06, 194
[INFO] 2021-07-09 16:48:21,833 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 194
[INFO] 2021-07-09 16:48:21,833 [run_pretraining.py:  558]:	worker_index: 6, step: 194, cost: 4.621647, mlm loss: 4.621647, speed: 0.448027 steps/s, speed: 3.584214 samples/s, speed: 1835.117515 tokens/s, learning rate: 1.930e-06, loss_scalings: 13421.773438, pp_loss: 4.577354
[INFO] 2021-07-09 16:48:21,833 [run_pretraining.py:  512]:	********exe.run_194******* 
[INFO] 2021-07-09 16:48:24,141 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:24,142 [run_pretraining.py:  534]:	loss/total_loss, 4.652359962463379, 195
[INFO] 2021-07-09 16:48:24,142 [run_pretraining.py:  535]:	loss/mlm_loss, 4.652359962463379, 195
[INFO] 2021-07-09 16:48:24,142 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.939999947353499e-06, 195
[INFO] 2021-07-09 16:48:24,142 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 195
[INFO] 2021-07-09 16:48:24,142 [run_pretraining.py:  558]:	worker_index: 6, step: 195, cost: 4.652360, mlm loss: 4.652360, speed: 0.433235 steps/s, speed: 3.465880 samples/s, speed: 1774.530560 tokens/s, learning rate: 1.940e-06, loss_scalings: 13421.773438, pp_loss: 4.578904
[INFO] 2021-07-09 16:48:24,142 [run_pretraining.py:  512]:	********exe.run_195******* 
[INFO] 2021-07-09 16:48:26,402 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:26,402 [run_pretraining.py:  534]:	loss/total_loss, 4.513678073883057, 196
[INFO] 2021-07-09 16:48:26,402 [run_pretraining.py:  535]:	loss/mlm_loss, 4.513678073883057, 196
[INFO] 2021-07-09 16:48:26,402 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.950000068973168e-06, 196
[INFO] 2021-07-09 16:48:26,402 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 196
[INFO] 2021-07-09 16:48:26,403 [run_pretraining.py:  558]:	worker_index: 6, step: 196, cost: 4.513678, mlm loss: 4.513678, speed: 0.442491 steps/s, speed: 3.539928 samples/s, speed: 1812.443116 tokens/s, learning rate: 1.950e-06, loss_scalings: 13421.773438, pp_loss: 4.510540
[INFO] 2021-07-09 16:48:26,403 [run_pretraining.py:  512]:	********exe.run_196******* 
[INFO] 2021-07-09 16:48:28,643 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:28,643 [run_pretraining.py:  534]:	loss/total_loss, 4.522647857666016, 197
[INFO] 2021-07-09 16:48:28,643 [run_pretraining.py:  535]:	loss/mlm_loss, 4.522647857666016, 197
[INFO] 2021-07-09 16:48:28,644 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.959999963219161e-06, 197
[INFO] 2021-07-09 16:48:28,644 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 197
[INFO] 2021-07-09 16:48:28,644 [run_pretraining.py:  558]:	worker_index: 6, step: 197, cost: 4.522648, mlm loss: 4.522648, speed: 0.446351 steps/s, speed: 3.570804 samples/s, speed: 1828.251704 tokens/s, learning rate: 1.960e-06, loss_scalings: 13421.773438, pp_loss: 4.491538
[INFO] 2021-07-09 16:48:28,644 [run_pretraining.py:  512]:	********exe.run_197******* 
[INFO] 2021-07-09 16:48:30,885 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:30,886 [run_pretraining.py:  534]:	loss/total_loss, 4.47523307800293, 198
[INFO] 2021-07-09 16:48:30,886 [run_pretraining.py:  535]:	loss/mlm_loss, 4.47523307800293, 198
[INFO] 2021-07-09 16:48:30,886 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9699998574651545e-06, 198
[INFO] 2021-07-09 16:48:30,886 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 198
[INFO] 2021-07-09 16:48:30,887 [run_pretraining.py:  558]:	worker_index: 6, step: 198, cost: 4.475233, mlm loss: 4.475233, speed: 0.445995 steps/s, speed: 3.567961 samples/s, speed: 1826.795809 tokens/s, learning rate: 1.970e-06, loss_scalings: 13421.773438, pp_loss: 4.469184
[INFO] 2021-07-09 16:48:30,887 [run_pretraining.py:  512]:	********exe.run_198******* 
[INFO] 2021-07-09 16:48:33,111 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:33,111 [run_pretraining.py:  534]:	loss/total_loss, 4.451584815979004, 199
[INFO] 2021-07-09 16:48:33,112 [run_pretraining.py:  535]:	loss/mlm_loss, 4.451584815979004, 199
[INFO] 2021-07-09 16:48:33,112 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9799999790848233e-06, 199
[INFO] 2021-07-09 16:48:33,112 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 199
[INFO] 2021-07-09 16:48:33,112 [run_pretraining.py:  558]:	worker_index: 6, step: 199, cost: 4.451585, mlm loss: 4.451585, speed: 0.449533 steps/s, speed: 3.596261 samples/s, speed: 1841.285470 tokens/s, learning rate: 1.980e-06, loss_scalings: 13421.773438, pp_loss: 4.433302
[INFO] 2021-07-09 16:48:33,112 [run_pretraining.py:  512]:	********exe.run_199******* 
[INFO] 2021-07-09 16:48:35,354 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:35,355 [run_pretraining.py:  534]:	loss/total_loss, 4.393184661865234, 200
[INFO] 2021-07-09 16:48:35,355 [run_pretraining.py:  535]:	loss/mlm_loss, 4.393184661865234, 200
[INFO] 2021-07-09 16:48:35,355 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9899998733308166e-06, 200
[INFO] 2021-07-09 16:48:35,355 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 200
[INFO] 2021-07-09 16:48:35,355 [run_pretraining.py:  558]:	worker_index: 6, step: 200, cost: 4.393185, mlm loss: 4.393185, speed: 0.445955 steps/s, speed: 3.567637 samples/s, speed: 1826.630323 tokens/s, learning rate: 1.990e-06, loss_scalings: 13421.773438, pp_loss: 4.395910
[INFO] 2021-07-09 16:48:35,355 [run_pretraining.py:  512]:	********exe.run_200******* 
[INFO] 2021-07-09 16:48:37,568 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:37,569 [run_pretraining.py:  534]:	loss/total_loss, 4.402678966522217, 201
[INFO] 2021-07-09 16:48:37,569 [run_pretraining.py:  535]:	loss/mlm_loss, 4.402678966522217, 201
[INFO] 2021-07-09 16:48:37,569 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9999999949504854e-06, 201
[INFO] 2021-07-09 16:48:37,569 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 201
[INFO] 2021-07-09 16:48:37,569 [run_pretraining.py:  558]:	worker_index: 6, step: 201, cost: 4.402679, mlm loss: 4.402679, speed: 0.451712 steps/s, speed: 3.613697 samples/s, speed: 1850.212941 tokens/s, learning rate: 2.000e-06, loss_scalings: 13421.773438, pp_loss: 4.394383
[INFO] 2021-07-09 16:48:37,569 [run_pretraining.py:  512]:	********exe.run_201******* 
[INFO] 2021-07-09 16:48:39,791 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:39,792 [run_pretraining.py:  534]:	loss/total_loss, 4.3822526931762695, 202
[INFO] 2021-07-09 16:48:39,792 [run_pretraining.py:  535]:	loss/mlm_loss, 4.3822526931762695, 202
[INFO] 2021-07-09 16:48:39,792 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0099998891964788e-06, 202
[INFO] 2021-07-09 16:48:39,792 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 202
[INFO] 2021-07-09 16:48:39,792 [run_pretraining.py:  558]:	worker_index: 6, step: 202, cost: 4.382253, mlm loss: 4.382253, speed: 0.450005 steps/s, speed: 3.600044 samples/s, speed: 1843.222456 tokens/s, learning rate: 2.010e-06, loss_scalings: 13421.773438, pp_loss: 4.342201
[INFO] 2021-07-09 16:48:39,792 [run_pretraining.py:  512]:	********exe.run_202******* 
[INFO] 2021-07-09 16:48:42,044 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:42,044 [run_pretraining.py:  534]:	loss/total_loss, 4.299019813537598, 203
[INFO] 2021-07-09 16:48:42,044 [run_pretraining.py:  535]:	loss/mlm_loss, 4.299019813537598, 203
[INFO] 2021-07-09 16:48:42,045 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.019999783442472e-06, 203
[INFO] 2021-07-09 16:48:42,045 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 203
[INFO] 2021-07-09 16:48:42,045 [run_pretraining.py:  558]:	worker_index: 6, step: 203, cost: 4.299020, mlm loss: 4.299020, speed: 0.444086 steps/s, speed: 3.552691 samples/s, speed: 1818.978034 tokens/s, learning rate: 2.020e-06, loss_scalings: 13421.773438, pp_loss: 4.337229
[INFO] 2021-07-09 16:48:42,045 [run_pretraining.py:  512]:	********exe.run_203******* 
[INFO] 2021-07-09 16:48:44,320 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:44,320 [run_pretraining.py:  534]:	loss/total_loss, 4.2835540771484375, 204
[INFO] 2021-07-09 16:48:44,320 [run_pretraining.py:  535]:	loss/mlm_loss, 4.2835540771484375, 204
[INFO] 2021-07-09 16:48:44,321 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0300001324358163e-06, 204
[INFO] 2021-07-09 16:48:44,321 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 204
[INFO] 2021-07-09 16:48:44,321 [run_pretraining.py:  558]:	worker_index: 6, step: 204, cost: 4.283554, mlm loss: 4.283554, speed: 0.439512 steps/s, speed: 3.516094 samples/s, speed: 1800.239878 tokens/s, learning rate: 2.030e-06, loss_scalings: 13421.773438, pp_loss: 4.277280
[INFO] 2021-07-09 16:48:44,321 [run_pretraining.py:  512]:	********exe.run_204******* 
[INFO] 2021-07-09 16:48:46,640 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:46,641 [run_pretraining.py:  534]:	loss/total_loss, 4.291354179382324, 205
[INFO] 2021-07-09 16:48:46,641 [run_pretraining.py:  535]:	loss/mlm_loss, 4.291354179382324, 205
[INFO] 2021-07-09 16:48:46,641 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0400000266818097e-06, 205
[INFO] 2021-07-09 16:48:46,641 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 205
[INFO] 2021-07-09 16:48:46,641 [run_pretraining.py:  558]:	worker_index: 6, step: 205, cost: 4.291354, mlm loss: 4.291354, speed: 0.431103 steps/s, speed: 3.448824 samples/s, speed: 1765.798019 tokens/s, learning rate: 2.040e-06, loss_scalings: 13421.773438, pp_loss: 4.287579
[INFO] 2021-07-09 16:48:46,641 [run_pretraining.py:  512]:	********exe.run_205******* 
[INFO] 2021-07-09 16:48:48,869 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:48,870 [run_pretraining.py:  534]:	loss/total_loss, 4.250660419464111, 206
[INFO] 2021-07-09 16:48:48,870 [run_pretraining.py:  535]:	loss/mlm_loss, 4.250660419464111, 206
[INFO] 2021-07-09 16:48:48,870 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.049999920927803e-06, 206
[INFO] 2021-07-09 16:48:48,870 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 206
[INFO] 2021-07-09 16:48:48,870 [run_pretraining.py:  558]:	worker_index: 6, step: 206, cost: 4.250660, mlm loss: 4.250660, speed: 0.448774 steps/s, speed: 3.590193 samples/s, speed: 1838.178617 tokens/s, learning rate: 2.050e-06, loss_scalings: 13421.773438, pp_loss: 4.234299
[INFO] 2021-07-09 16:48:48,870 [run_pretraining.py:  512]:	********exe.run_206******* 
[INFO] 2021-07-09 16:48:51,104 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:51,105 [run_pretraining.py:  534]:	loss/total_loss, 4.156829833984375, 207
[INFO] 2021-07-09 16:48:51,105 [run_pretraining.py:  535]:	loss/mlm_loss, 4.156829833984375, 207
[INFO] 2021-07-09 16:48:51,105 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.060000042547472e-06, 207
[INFO] 2021-07-09 16:48:51,105 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 207
[INFO] 2021-07-09 16:48:51,105 [run_pretraining.py:  558]:	worker_index: 6, step: 207, cost: 4.156830, mlm loss: 4.156830, speed: 0.447558 steps/s, speed: 3.580462 samples/s, speed: 1833.196734 tokens/s, learning rate: 2.060e-06, loss_scalings: 13421.773438, pp_loss: 4.242004
[INFO] 2021-07-09 16:48:51,105 [run_pretraining.py:  512]:	********exe.run_207******* 
[INFO] 2021-07-09 16:48:53,382 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:53,382 [run_pretraining.py:  534]:	loss/total_loss, 4.177060604095459, 208
[INFO] 2021-07-09 16:48:53,382 [run_pretraining.py:  535]:	loss/mlm_loss, 4.177060604095459, 208
[INFO] 2021-07-09 16:48:53,383 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.069999936793465e-06, 208
[INFO] 2021-07-09 16:48:53,383 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 208
[INFO] 2021-07-09 16:48:53,383 [run_pretraining.py:  558]:	worker_index: 6, step: 208, cost: 4.177061, mlm loss: 4.177061, speed: 0.439176 steps/s, speed: 3.513410 samples/s, speed: 1798.866097 tokens/s, learning rate: 2.070e-06, loss_scalings: 13421.773438, pp_loss: 4.156741
[INFO] 2021-07-09 16:48:53,383 [run_pretraining.py:  512]:	********exe.run_208******* 
[INFO] 2021-07-09 16:48:55,621 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:55,622 [run_pretraining.py:  534]:	loss/total_loss, 4.111490726470947, 209
[INFO] 2021-07-09 16:48:55,622 [run_pretraining.py:  535]:	loss/mlm_loss, 4.111490726470947, 209
[INFO] 2021-07-09 16:48:55,622 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.080000058413134e-06, 209
[INFO] 2021-07-09 16:48:55,622 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 209
[INFO] 2021-07-09 16:48:55,622 [run_pretraining.py:  558]:	worker_index: 6, step: 209, cost: 4.111491, mlm loss: 4.111491, speed: 0.446686 steps/s, speed: 3.573490 samples/s, speed: 1829.626715 tokens/s, learning rate: 2.080e-06, loss_scalings: 13421.773438, pp_loss: 4.124959
[INFO] 2021-07-09 16:48:55,622 [run_pretraining.py:  512]:	********exe.run_209******* 
[INFO] 2021-07-09 16:48:57,906 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:57,907 [run_pretraining.py:  534]:	loss/total_loss, 4.052464485168457, 210
[INFO] 2021-07-09 16:48:57,907 [run_pretraining.py:  535]:	loss/mlm_loss, 4.052464485168457, 210
[INFO] 2021-07-09 16:48:57,907 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0899999526591273e-06, 210
[INFO] 2021-07-09 16:48:57,907 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 210
[INFO] 2021-07-09 16:48:57,907 [run_pretraining.py:  558]:	worker_index: 6, step: 210, cost: 4.052464, mlm loss: 4.052464, speed: 0.437742 steps/s, speed: 3.501938 samples/s, speed: 1792.992455 tokens/s, learning rate: 2.090e-06, loss_scalings: 13421.773438, pp_loss: 4.109149
[INFO] 2021-07-09 16:48:57,907 [run_pretraining.py:  512]:	********exe.run_210******* 
[INFO] 2021-07-09 16:49:00,148 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:00,148 [run_pretraining.py:  534]:	loss/total_loss, 4.053621292114258, 211
[INFO] 2021-07-09 16:49:00,148 [run_pretraining.py:  535]:	loss/mlm_loss, 4.053621292114258, 211
[INFO] 2021-07-09 16:49:00,149 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0999998469051206e-06, 211
[INFO] 2021-07-09 16:49:00,149 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 211
[INFO] 2021-07-09 16:49:00,149 [run_pretraining.py:  558]:	worker_index: 6, step: 211, cost: 4.053621, mlm loss: 4.053621, speed: 0.446283 steps/s, speed: 3.570263 samples/s, speed: 1827.974499 tokens/s, learning rate: 2.100e-06, loss_scalings: 13421.773438, pp_loss: 4.107434
[INFO] 2021-07-09 16:49:00,149 [run_pretraining.py:  512]:	********exe.run_211******* 
[INFO] 2021-07-09 16:49:02,440 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:02,440 [run_pretraining.py:  534]:	loss/total_loss, 4.00926399230957, 212
[INFO] 2021-07-09 16:49:02,441 [run_pretraining.py:  535]:	loss/mlm_loss, 4.00926399230957, 212
[INFO] 2021-07-09 16:49:02,441 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1099999685247894e-06, 212
[INFO] 2021-07-09 16:49:02,441 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 212
[INFO] 2021-07-09 16:49:02,441 [run_pretraining.py:  558]:	worker_index: 6, step: 212, cost: 4.009264, mlm loss: 4.009264, speed: 0.436428 steps/s, speed: 3.491420 samples/s, speed: 1787.607063 tokens/s, learning rate: 2.110e-06, loss_scalings: 13421.773438, pp_loss: 4.047110
[INFO] 2021-07-09 16:49:02,441 [run_pretraining.py:  512]:	********exe.run_212******* 
[INFO] 2021-07-09 16:49:04,752 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:04,752 [run_pretraining.py:  534]:	loss/total_loss, 4.054866790771484, 213
[INFO] 2021-07-09 16:49:04,752 [run_pretraining.py:  535]:	loss/mlm_loss, 4.054866790771484, 213
[INFO] 2021-07-09 16:49:04,753 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1199998627707828e-06, 213
[INFO] 2021-07-09 16:49:04,753 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 213
[INFO] 2021-07-09 16:49:04,753 [run_pretraining.py:  558]:	worker_index: 6, step: 213, cost: 4.054867, mlm loss: 4.054867, speed: 0.432671 steps/s, speed: 3.461366 samples/s, speed: 1772.219310 tokens/s, learning rate: 2.120e-06, loss_scalings: 13421.773438, pp_loss: 4.102555
[INFO] 2021-07-09 16:49:04,753 [run_pretraining.py:  512]:	********exe.run_213******* 
[INFO] 2021-07-09 16:49:07,133 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:07,134 [run_pretraining.py:  534]:	loss/total_loss, 4.067558288574219, 214
[INFO] 2021-07-09 16:49:07,134 [run_pretraining.py:  535]:	loss/mlm_loss, 4.067558288574219, 214
[INFO] 2021-07-09 16:49:07,134 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.129999757016776e-06, 214
[INFO] 2021-07-09 16:49:07,134 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 214
[INFO] 2021-07-09 16:49:07,134 [run_pretraining.py:  558]:	worker_index: 6, step: 214, cost: 4.067558, mlm loss: 4.067558, speed: 0.420061 steps/s, speed: 3.360486 samples/s, speed: 1720.568976 tokens/s, learning rate: 2.130e-06, loss_scalings: 13421.773438, pp_loss: 4.057815
[INFO] 2021-07-09 16:49:07,134 [run_pretraining.py:  512]:	********exe.run_214******* 
[INFO] 2021-07-09 16:49:09,447 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:09,447 [run_pretraining.py:  534]:	loss/total_loss, 3.989612102508545, 215
[INFO] 2021-07-09 16:49:09,447 [run_pretraining.py:  535]:	loss/mlm_loss, 3.989612102508545, 215
[INFO] 2021-07-09 16:49:09,448 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1400001060101204e-06, 215
[INFO] 2021-07-09 16:49:09,448 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 215
[INFO] 2021-07-09 16:49:09,448 [run_pretraining.py:  558]:	worker_index: 6, step: 215, cost: 3.989612, mlm loss: 3.989612, speed: 0.432324 steps/s, speed: 3.458594 samples/s, speed: 1770.800147 tokens/s, learning rate: 2.140e-06, loss_scalings: 13421.773438, pp_loss: 3.986017
[INFO] 2021-07-09 16:49:09,448 [run_pretraining.py:  512]:	********exe.run_215******* 
[INFO] 2021-07-09 16:49:11,720 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:11,721 [run_pretraining.py:  534]:	loss/total_loss, 3.9371116161346436, 216
[INFO] 2021-07-09 16:49:11,721 [run_pretraining.py:  535]:	loss/mlm_loss, 3.9371116161346436, 216
[INFO] 2021-07-09 16:49:11,721 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1500000002561137e-06, 216
[INFO] 2021-07-09 16:49:11,721 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 216
[INFO] 2021-07-09 16:49:11,721 [run_pretraining.py:  558]:	worker_index: 6, step: 216, cost: 3.937112, mlm loss: 3.937112, speed: 0.440023 steps/s, speed: 3.520183 samples/s, speed: 1802.333608 tokens/s, learning rate: 2.150e-06, loss_scalings: 13421.773438, pp_loss: 4.002526
[INFO] 2021-07-09 16:49:11,721 [run_pretraining.py:  512]:	********exe.run_216******* 
[INFO] 2021-07-09 16:49:14,058 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:14,059 [run_pretraining.py:  534]:	loss/total_loss, 3.9619617462158203, 217
[INFO] 2021-07-09 16:49:14,059 [run_pretraining.py:  535]:	loss/mlm_loss, 3.9619617462158203, 217
[INFO] 2021-07-09 16:49:14,059 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.159999894502107e-06, 217
[INFO] 2021-07-09 16:49:14,059 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 217
[INFO] 2021-07-09 16:49:14,059 [run_pretraining.py:  558]:	worker_index: 6, step: 217, cost: 3.961962, mlm loss: 3.961962, speed: 0.427774 steps/s, speed: 3.422194 samples/s, speed: 1752.163570 tokens/s, learning rate: 2.160e-06, loss_scalings: 13421.773438, pp_loss: 3.978098
[INFO] 2021-07-09 16:49:14,060 [run_pretraining.py:  512]:	********exe.run_217******* 
[INFO] 2021-07-09 16:49:16,326 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:16,327 [run_pretraining.py:  534]:	loss/total_loss, 3.976956605911255, 218
[INFO] 2021-07-09 16:49:16,327 [run_pretraining.py:  535]:	loss/mlm_loss, 3.976956605911255, 218
[INFO] 2021-07-09 16:49:16,327 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.170000016121776e-06, 218
[INFO] 2021-07-09 16:49:16,327 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 218
[INFO] 2021-07-09 16:49:16,327 [run_pretraining.py:  558]:	worker_index: 6, step: 218, cost: 3.976957, mlm loss: 3.976957, speed: 0.441128 steps/s, speed: 3.529025 samples/s, speed: 1806.860800 tokens/s, learning rate: 2.170e-06, loss_scalings: 13421.773438, pp_loss: 3.988402
[INFO] 2021-07-09 16:49:16,327 [run_pretraining.py:  512]:	********exe.run_218******* 
[INFO] 2021-07-09 16:49:18,667 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:18,668 [run_pretraining.py:  534]:	loss/total_loss, 3.9265925884246826, 219
[INFO] 2021-07-09 16:49:18,668 [run_pretraining.py:  535]:	loss/mlm_loss, 3.9265925884246826, 219
[INFO] 2021-07-09 16:49:18,668 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.179999910367769e-06, 219
[INFO] 2021-07-09 16:49:18,668 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 219
[INFO] 2021-07-09 16:49:18,668 [run_pretraining.py:  558]:	worker_index: 6, step: 219, cost: 3.926593, mlm loss: 3.926593, speed: 0.427237 steps/s, speed: 3.417893 samples/s, speed: 1749.961159 tokens/s, learning rate: 2.180e-06, loss_scalings: 13421.773438, pp_loss: 3.946741
[INFO] 2021-07-09 16:49:18,668 [run_pretraining.py:  512]:	********exe.run_219******* 
[INFO] 2021-07-09 16:49:20,898 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:20,899 [run_pretraining.py:  534]:	loss/total_loss, 3.933732509613037, 220
[INFO] 2021-07-09 16:49:20,899 [run_pretraining.py:  535]:	loss/mlm_loss, 3.933732509613037, 220
[INFO] 2021-07-09 16:49:20,899 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.190000031987438e-06, 220
[INFO] 2021-07-09 16:49:20,899 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 220
[INFO] 2021-07-09 16:49:20,899 [run_pretraining.py:  558]:	worker_index: 6, step: 220, cost: 3.933733, mlm loss: 3.933733, speed: 0.448440 steps/s, speed: 3.587517 samples/s, speed: 1836.808793 tokens/s, learning rate: 2.190e-06, loss_scalings: 13421.773438, pp_loss: 3.930916
[INFO] 2021-07-09 16:49:20,899 [run_pretraining.py:  512]:	********exe.run_220******* 
[INFO] 2021-07-09 16:49:23,188 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:23,189 [run_pretraining.py:  534]:	loss/total_loss, 3.8912878036499023, 221
[INFO] 2021-07-09 16:49:23,189 [run_pretraining.py:  535]:	loss/mlm_loss, 3.8912878036499023, 221
[INFO] 2021-07-09 16:49:23,189 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1999999262334313e-06, 221
[INFO] 2021-07-09 16:49:23,189 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 221
[INFO] 2021-07-09 16:49:23,190 [run_pretraining.py:  558]:	worker_index: 6, step: 221, cost: 3.891288, mlm loss: 3.891288, speed: 0.436705 steps/s, speed: 3.493639 samples/s, speed: 1788.742972 tokens/s, learning rate: 2.200e-06, loss_scalings: 13421.773438, pp_loss: 3.927552
[INFO] 2021-07-09 16:49:23,190 [run_pretraining.py:  512]:	********exe.run_221******* 
[INFO] 2021-07-09 16:49:25,457 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:25,458 [run_pretraining.py:  534]:	loss/total_loss, 3.9351861476898193, 222
[INFO] 2021-07-09 16:49:25,458 [run_pretraining.py:  535]:	loss/mlm_loss, 3.9351861476898193, 222
[INFO] 2021-07-09 16:49:25,458 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2099998204794247e-06, 222
[INFO] 2021-07-09 16:49:25,458 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 222
[INFO] 2021-07-09 16:49:25,458 [run_pretraining.py:  558]:	worker_index: 6, step: 222, cost: 3.935186, mlm loss: 3.935186, speed: 0.440927 steps/s, speed: 3.527419 samples/s, speed: 1806.038520 tokens/s, learning rate: 2.210e-06, loss_scalings: 13421.773438, pp_loss: 3.927904
[INFO] 2021-07-09 16:49:25,458 [run_pretraining.py:  512]:	********exe.run_222******* 
[INFO] 2021-07-09 16:49:27,748 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:27,749 [run_pretraining.py:  534]:	loss/total_loss, 3.994049549102783, 223
[INFO] 2021-07-09 16:49:27,749 [run_pretraining.py:  535]:	loss/mlm_loss, 3.994049549102783, 223
[INFO] 2021-07-09 16:49:27,749 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2199999420990935e-06, 223
[INFO] 2021-07-09 16:49:27,749 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 223
[INFO] 2021-07-09 16:49:27,749 [run_pretraining.py:  558]:	worker_index: 6, step: 223, cost: 3.994050, mlm loss: 3.994050, speed: 0.436581 steps/s, speed: 3.492647 samples/s, speed: 1788.235422 tokens/s, learning rate: 2.220e-06, loss_scalings: 13421.773438, pp_loss: 3.908423
[INFO] 2021-07-09 16:49:27,750 [run_pretraining.py:  512]:	********exe.run_223******* 
[INFO] 2021-07-09 16:49:30,048 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:30,049 [run_pretraining.py:  534]:	loss/total_loss, 3.980125904083252, 224
[INFO] 2021-07-09 16:49:30,049 [run_pretraining.py:  535]:	loss/mlm_loss, 3.980125904083252, 224
[INFO] 2021-07-09 16:49:30,049 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.229999836345087e-06, 224
[INFO] 2021-07-09 16:49:30,049 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 224
[INFO] 2021-07-09 16:49:30,049 [run_pretraining.py:  558]:	worker_index: 6, step: 224, cost: 3.980126, mlm loss: 3.980126, speed: 0.434983 steps/s, speed: 3.479863 samples/s, speed: 1781.689628 tokens/s, learning rate: 2.230e-06, loss_scalings: 13421.773438, pp_loss: 3.901527
[INFO] 2021-07-09 16:49:30,049 [run_pretraining.py:  512]:	********exe.run_224******* 
[INFO] 2021-07-09 16:49:32,345 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:32,346 [run_pretraining.py:  534]:	loss/total_loss, 3.952409267425537, 225
[INFO] 2021-07-09 16:49:32,346 [run_pretraining.py:  535]:	loss/mlm_loss, 3.952409267425537, 225
[INFO] 2021-07-09 16:49:32,346 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2399999579647556e-06, 225
[INFO] 2021-07-09 16:49:32,346 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 225
[INFO] 2021-07-09 16:49:32,346 [run_pretraining.py:  558]:	worker_index: 6, step: 225, cost: 3.952409, mlm loss: 3.952409, speed: 0.435489 steps/s, speed: 3.483910 samples/s, speed: 1783.761704 tokens/s, learning rate: 2.240e-06, loss_scalings: 13421.773438, pp_loss: 3.924247
[INFO] 2021-07-09 16:49:32,346 [run_pretraining.py:  512]:	********exe.run_225******* 
[INFO] 2021-07-09 16:49:34,656 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:34,657 [run_pretraining.py:  534]:	loss/total_loss, 3.9296789169311523, 226
[INFO] 2021-07-09 16:49:34,657 [run_pretraining.py:  535]:	loss/mlm_loss, 3.9296789169311523, 226
[INFO] 2021-07-09 16:49:34,657 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2500000795844244e-06, 226
[INFO] 2021-07-09 16:49:34,657 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 226
[INFO] 2021-07-09 16:49:34,657 [run_pretraining.py:  558]:	worker_index: 6, step: 226, cost: 3.929679, mlm loss: 3.929679, speed: 0.432860 steps/s, speed: 3.462878 samples/s, speed: 1772.993510 tokens/s, learning rate: 2.250e-06, loss_scalings: 13421.773438, pp_loss: 3.875990
[INFO] 2021-07-09 16:49:34,657 [run_pretraining.py:  512]:	********exe.run_226******* 
[INFO] 2021-07-09 16:49:36,883 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:36,884 [run_pretraining.py:  534]:	loss/total_loss, 3.9169182777404785, 227
[INFO] 2021-07-09 16:49:36,885 [run_pretraining.py:  535]:	loss/mlm_loss, 3.9169182777404785, 227
[INFO] 2021-07-09 16:49:36,885 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2599999738304177e-06, 227
[INFO] 2021-07-09 16:49:36,885 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 227
[INFO] 2021-07-09 16:49:36,885 [run_pretraining.py:  558]:	worker_index: 6, step: 227, cost: 3.916918, mlm loss: 3.916918, speed: 0.448999 steps/s, speed: 3.591991 samples/s, speed: 1839.099531 tokens/s, learning rate: 2.260e-06, loss_scalings: 10737.418945, pp_loss: 3.883051
[INFO] 2021-07-09 16:49:36,885 [run_pretraining.py:  512]:	********exe.run_227******* 
[INFO] 2021-07-09 16:49:39,210 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:39,211 [run_pretraining.py:  534]:	loss/total_loss, 4.009864807128906, 228
[INFO] 2021-07-09 16:49:39,211 [run_pretraining.py:  535]:	loss/mlm_loss, 4.009864807128906, 228
[INFO] 2021-07-09 16:49:39,211 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2700000954500865e-06, 228
[INFO] 2021-07-09 16:49:39,211 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 228
[INFO] 2021-07-09 16:49:39,211 [run_pretraining.py:  558]:	worker_index: 6, step: 228, cost: 4.009865, mlm loss: 4.009865, speed: 0.430009 steps/s, speed: 3.440075 samples/s, speed: 1761.318344 tokens/s, learning rate: 2.270e-06, loss_scalings: 10737.418945, pp_loss: 3.910489
[INFO] 2021-07-09 16:49:39,211 [run_pretraining.py:  512]:	********exe.run_228******* 
[INFO] 2021-07-09 16:49:41,544 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:41,545 [run_pretraining.py:  534]:	loss/total_loss, 3.9056832790374756, 229
[INFO] 2021-07-09 16:49:41,545 [run_pretraining.py:  535]:	loss/mlm_loss, 3.9056832790374756, 229
[INFO] 2021-07-09 16:49:41,545 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.27999998969608e-06, 229
[INFO] 2021-07-09 16:49:41,545 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 229
[INFO] 2021-07-09 16:49:41,545 [run_pretraining.py:  558]:	worker_index: 6, step: 229, cost: 3.905683, mlm loss: 3.905683, speed: 0.428534 steps/s, speed: 3.428272 samples/s, speed: 1755.275464 tokens/s, learning rate: 2.280e-06, loss_scalings: 8589.935547, pp_loss: 3.904324
[INFO] 2021-07-09 16:49:41,545 [run_pretraining.py:  512]:	********exe.run_229******* 
[INFO] 2021-07-09 16:49:43,798 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:43,799 [run_pretraining.py:  534]:	loss/total_loss, 3.8404030799865723, 230
[INFO] 2021-07-09 16:49:43,799 [run_pretraining.py:  535]:	loss/mlm_loss, 3.8404030799865723, 230
[INFO] 2021-07-09 16:49:43,799 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.289999883942073e-06, 230
[INFO] 2021-07-09 16:49:43,799 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 230
[INFO] 2021-07-09 16:49:43,799 [run_pretraining.py:  558]:	worker_index: 6, step: 230, cost: 3.840403, mlm loss: 3.840403, speed: 0.443804 steps/s, speed: 3.550430 samples/s, speed: 1817.820147 tokens/s, learning rate: 2.290e-06, loss_scalings: 8589.935547, pp_loss: 3.871726
[INFO] 2021-07-09 16:49:43,799 [run_pretraining.py:  512]:	********exe.run_230******* 
[INFO] 2021-07-09 16:49:46,154 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:46,155 [run_pretraining.py:  534]:	loss/total_loss, 3.972412109375, 231
[INFO] 2021-07-09 16:49:46,155 [run_pretraining.py:  535]:	loss/mlm_loss, 3.972412109375, 231
[INFO] 2021-07-09 16:49:46,155 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.300000005561742e-06, 231
[INFO] 2021-07-09 16:49:46,155 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 231
[INFO] 2021-07-09 16:49:46,155 [run_pretraining.py:  558]:	worker_index: 6, step: 231, cost: 3.972412, mlm loss: 3.972412, speed: 0.424582 steps/s, speed: 3.396659 samples/s, speed: 1739.089377 tokens/s, learning rate: 2.300e-06, loss_scalings: 8589.935547, pp_loss: 3.922008
[INFO] 2021-07-09 16:49:46,155 [run_pretraining.py:  512]:	********exe.run_231******* 
[INFO] 2021-07-09 16:49:48,484 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:48,485 [run_pretraining.py:  534]:	loss/total_loss, 3.8915205001831055, 232
[INFO] 2021-07-09 16:49:48,485 [run_pretraining.py:  535]:	loss/mlm_loss, 3.8915205001831055, 232
[INFO] 2021-07-09 16:49:48,485 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3099998998077353e-06, 232
[INFO] 2021-07-09 16:49:48,485 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 232
[INFO] 2021-07-09 16:49:48,485 [run_pretraining.py:  558]:	worker_index: 6, step: 232, cost: 3.891521, mlm loss: 3.891521, speed: 0.429310 steps/s, speed: 3.434478 samples/s, speed: 1758.452606 tokens/s, learning rate: 2.310e-06, loss_scalings: 8589.935547, pp_loss: 3.930771
[INFO] 2021-07-09 16:49:48,485 [run_pretraining.py:  512]:	********exe.run_232******* 
[INFO] 2021-07-09 16:49:50,699 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:50,700 [run_pretraining.py:  534]:	loss/total_loss, 3.9207115173339844, 233
[INFO] 2021-07-09 16:49:50,700 [run_pretraining.py:  535]:	loss/mlm_loss, 3.9207115173339844, 233
[INFO] 2021-07-09 16:49:50,700 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.320000021427404e-06, 233
[INFO] 2021-07-09 16:49:50,700 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 233
[INFO] 2021-07-09 16:49:50,701 [run_pretraining.py:  558]:	worker_index: 6, step: 233, cost: 3.920712, mlm loss: 3.920712, speed: 0.451534 steps/s, speed: 3.612272 samples/s, speed: 1849.483334 tokens/s, learning rate: 2.320e-06, loss_scalings: 8589.935547, pp_loss: 3.886888
[INFO] 2021-07-09 16:49:50,701 [run_pretraining.py:  512]:	********exe.run_233******* 
[INFO] 2021-07-09 16:49:52,948 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:52,948 [run_pretraining.py:  534]:	loss/total_loss, 3.8631629943847656, 234
[INFO] 2021-07-09 16:49:52,948 [run_pretraining.py:  535]:	loss/mlm_loss, 3.8631629943847656, 234
[INFO] 2021-07-09 16:49:52,948 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3299999156733975e-06, 234
[INFO] 2021-07-09 16:49:52,949 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 234
[INFO] 2021-07-09 16:49:52,949 [run_pretraining.py:  558]:	worker_index: 6, step: 234, cost: 3.863163, mlm loss: 3.863163, speed: 0.444956 steps/s, speed: 3.559652 samples/s, speed: 1822.541765 tokens/s, learning rate: 2.330e-06, loss_scalings: 8589.935547, pp_loss: 3.895130
[INFO] 2021-07-09 16:49:52,949 [run_pretraining.py:  512]:	********exe.run_234******* 
[INFO] 2021-07-09 16:49:55,224 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:55,225 [run_pretraining.py:  534]:	loss/total_loss, 3.833104133605957, 235
[INFO] 2021-07-09 16:49:55,226 [run_pretraining.py:  535]:	loss/mlm_loss, 3.833104133605957, 235
[INFO] 2021-07-09 16:49:55,226 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.339999809919391e-06, 235
[INFO] 2021-07-09 16:49:55,226 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 235
[INFO] 2021-07-09 16:49:55,226 [run_pretraining.py:  558]:	worker_index: 6, step: 235, cost: 3.833104, mlm loss: 3.833104, speed: 0.439264 steps/s, speed: 3.514113 samples/s, speed: 1799.225927 tokens/s, learning rate: 2.340e-06, loss_scalings: 8589.935547, pp_loss: 3.889693
[INFO] 2021-07-09 16:49:55,226 [run_pretraining.py:  512]:	********exe.run_235******* 
[INFO] 2021-07-09 16:49:57,481 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:57,481 [run_pretraining.py:  534]:	loss/total_loss, 3.8931586742401123, 236
[INFO] 2021-07-09 16:49:57,481 [run_pretraining.py:  535]:	loss/mlm_loss, 3.8931586742401123, 236
[INFO] 2021-07-09 16:49:57,482 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3499999315390596e-06, 236
[INFO] 2021-07-09 16:49:57,482 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 236
[INFO] 2021-07-09 16:49:57,482 [run_pretraining.py:  558]:	worker_index: 6, step: 236, cost: 3.893159, mlm loss: 3.893159, speed: 0.443423 steps/s, speed: 3.547381 samples/s, speed: 1816.259066 tokens/s, learning rate: 2.350e-06, loss_scalings: 6871.948730, pp_loss: 3.896619
[INFO] 2021-07-09 16:49:57,482 [run_pretraining.py:  512]:	********exe.run_236******* 
[INFO] 2021-07-09 16:49:59,724 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:59,725 [run_pretraining.py:  534]:	loss/total_loss, 3.8820595741271973, 237
[INFO] 2021-07-09 16:49:59,726 [run_pretraining.py:  535]:	loss/mlm_loss, 3.8820595741271973, 237
[INFO] 2021-07-09 16:49:59,726 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3600000531587284e-06, 237
[INFO] 2021-07-09 16:49:59,726 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 237
[INFO] 2021-07-09 16:49:59,726 [run_pretraining.py:  558]:	worker_index: 6, step: 237, cost: 3.882060, mlm loss: 3.882060, speed: 0.445748 steps/s, speed: 3.565984 samples/s, speed: 1825.783553 tokens/s, learning rate: 2.360e-06, loss_scalings: 6871.948730, pp_loss: 3.893292
[INFO] 2021-07-09 16:49:59,726 [run_pretraining.py:  512]:	********exe.run_237******* 
[INFO] 2021-07-09 16:50:01,970 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:01,971 [run_pretraining.py:  534]:	loss/total_loss, 3.8567161560058594, 238
[INFO] 2021-07-09 16:50:01,971 [run_pretraining.py:  535]:	loss/mlm_loss, 3.8567161560058594, 238
[INFO] 2021-07-09 16:50:01,971 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3699999474047218e-06, 238
[INFO] 2021-07-09 16:50:01,971 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 238
[INFO] 2021-07-09 16:50:01,971 [run_pretraining.py:  558]:	worker_index: 6, step: 238, cost: 3.856716, mlm loss: 3.856716, speed: 0.445520 steps/s, speed: 3.564163 samples/s, speed: 1824.851500 tokens/s, learning rate: 2.370e-06, loss_scalings: 6871.948730, pp_loss: 3.870278
[INFO] 2021-07-09 16:50:01,971 [run_pretraining.py:  512]:	********exe.run_238******* 
[INFO] 2021-07-09 16:50:04,219 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:04,220 [run_pretraining.py:  534]:	loss/total_loss, 3.8746376037597656, 239
[INFO] 2021-07-09 16:50:04,220 [run_pretraining.py:  535]:	loss/mlm_loss, 3.8746376037597656, 239
[INFO] 2021-07-09 16:50:04,220 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3800000690243905e-06, 239
[INFO] 2021-07-09 16:50:04,220 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 239
[INFO] 2021-07-09 16:50:04,220 [run_pretraining.py:  558]:	worker_index: 6, step: 239, cost: 3.874638, mlm loss: 3.874638, speed: 0.444756 steps/s, speed: 3.558046 samples/s, speed: 1821.719643 tokens/s, learning rate: 2.380e-06, loss_scalings: 6871.948730, pp_loss: 3.909799
[INFO] 2021-07-09 16:50:04,220 [run_pretraining.py:  512]:	********exe.run_239******* 
[INFO] 2021-07-09 16:50:06,472 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:06,473 [run_pretraining.py:  534]:	loss/total_loss, 4.045352458953857, 240
[INFO] 2021-07-09 16:50:06,473 [run_pretraining.py:  535]:	loss/mlm_loss, 4.045352458953857, 240
[INFO] 2021-07-09 16:50:06,473 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.389999963270384e-06, 240
[INFO] 2021-07-09 16:50:06,473 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 240
[INFO] 2021-07-09 16:50:06,473 [run_pretraining.py:  558]:	worker_index: 6, step: 240, cost: 4.045352, mlm loss: 4.045352, speed: 0.444009 steps/s, speed: 3.552073 samples/s, speed: 1818.661278 tokens/s, learning rate: 2.390e-06, loss_scalings: 5497.559082, pp_loss: 3.948638
[INFO] 2021-07-09 16:50:06,473 [run_pretraining.py:  512]:	********exe.run_240******* 
[INFO] 2021-07-09 16:50:08,782 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:08,783 [run_pretraining.py:  534]:	loss/total_loss, 3.9320144653320312, 241
[INFO] 2021-07-09 16:50:08,783 [run_pretraining.py:  535]:	loss/mlm_loss, 3.9320144653320312, 241
[INFO] 2021-07-09 16:50:08,783 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3999998575163772e-06, 241
[INFO] 2021-07-09 16:50:08,783 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 241
[INFO] 2021-07-09 16:50:08,783 [run_pretraining.py:  558]:	worker_index: 6, step: 241, cost: 3.932014, mlm loss: 3.932014, speed: 0.432975 steps/s, speed: 3.463802 samples/s, speed: 1773.466447 tokens/s, learning rate: 2.400e-06, loss_scalings: 5497.559082, pp_loss: 3.911443
[INFO] 2021-07-09 16:50:08,784 [run_pretraining.py:  512]:	********exe.run_241******* 
[INFO] 2021-07-09 16:50:11,115 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:11,116 [run_pretraining.py:  534]:	loss/total_loss, 3.887442111968994, 242
[INFO] 2021-07-09 16:50:11,116 [run_pretraining.py:  535]:	loss/mlm_loss, 3.887442111968994, 242
[INFO] 2021-07-09 16:50:11,116 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.409999979136046e-06, 242
[INFO] 2021-07-09 16:50:11,116 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 242
[INFO] 2021-07-09 16:50:11,116 [run_pretraining.py:  558]:	worker_index: 6, step: 242, cost: 3.887442, mlm loss: 3.887442, speed: 0.428857 steps/s, speed: 3.430855 samples/s, speed: 1756.597996 tokens/s, learning rate: 2.410e-06, loss_scalings: 5497.559082, pp_loss: 3.921453
[INFO] 2021-07-09 16:50:11,116 [run_pretraining.py:  512]:	********exe.run_242******* 
[INFO] 2021-07-09 16:50:13,366 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:13,367 [run_pretraining.py:  534]:	loss/total_loss, 3.8736205101013184, 243
[INFO] 2021-07-09 16:50:13,367 [run_pretraining.py:  535]:	loss/mlm_loss, 3.8736205101013184, 243
[INFO] 2021-07-09 16:50:13,367 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4199998733820394e-06, 243
[INFO] 2021-07-09 16:50:13,367 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 243
[INFO] 2021-07-09 16:50:13,367 [run_pretraining.py:  558]:	worker_index: 6, step: 243, cost: 3.873621, mlm loss: 3.873621, speed: 0.444382 steps/s, speed: 3.555056 samples/s, speed: 1820.188886 tokens/s, learning rate: 2.420e-06, loss_scalings: 5497.559082, pp_loss: 3.937385
[INFO] 2021-07-09 16:50:13,367 [run_pretraining.py:  512]:	********exe.run_243******* 
[INFO] 2021-07-09 16:50:15,628 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:15,629 [run_pretraining.py:  534]:	loss/total_loss, 4.09456205368042, 244
[INFO] 2021-07-09 16:50:15,629 [run_pretraining.py:  535]:	loss/mlm_loss, 4.09456205368042, 244
[INFO] 2021-07-09 16:50:15,629 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.429999995001708e-06, 244
[INFO] 2021-07-09 16:50:15,629 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 244
[INFO] 2021-07-09 16:50:15,629 [run_pretraining.py:  558]:	worker_index: 6, step: 244, cost: 4.094562, mlm loss: 4.094562, speed: 0.442174 steps/s, speed: 3.537392 samples/s, speed: 1811.144589 tokens/s, learning rate: 2.430e-06, loss_scalings: 5497.559082, pp_loss: 3.975729
[INFO] 2021-07-09 16:50:15,629 [run_pretraining.py:  512]:	********exe.run_244******* 
[INFO] 2021-07-09 16:50:17,886 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:17,887 [run_pretraining.py:  534]:	loss/total_loss, 3.948057174682617, 245
[INFO] 2021-07-09 16:50:17,887 [run_pretraining.py:  535]:	loss/mlm_loss, 3.948057174682617, 245
[INFO] 2021-07-09 16:50:17,887 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4399998892477015e-06, 245
[INFO] 2021-07-09 16:50:17,887 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 245
[INFO] 2021-07-09 16:50:17,887 [run_pretraining.py:  558]:	worker_index: 6, step: 245, cost: 3.948057, mlm loss: 3.948057, speed: 0.442963 steps/s, speed: 3.543703 samples/s, speed: 1814.376007 tokens/s, learning rate: 2.440e-06, loss_scalings: 5497.559082, pp_loss: 4.009022
[INFO] 2021-07-09 16:50:17,888 [run_pretraining.py:  512]:	********exe.run_245******* 
[INFO] 2021-07-09 16:50:20,169 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:20,170 [run_pretraining.py:  534]:	loss/total_loss, 3.9581804275512695, 246
[INFO] 2021-07-09 16:50:20,170 [run_pretraining.py:  535]:	loss/mlm_loss, 3.9581804275512695, 246
[INFO] 2021-07-09 16:50:20,170 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.449999783493695e-06, 246
[INFO] 2021-07-09 16:50:20,170 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 246
[INFO] 2021-07-09 16:50:20,170 [run_pretraining.py:  558]:	worker_index: 6, step: 246, cost: 3.958180, mlm loss: 3.958180, speed: 0.438190 steps/s, speed: 3.505518 samples/s, speed: 1794.825367 tokens/s, learning rate: 2.450e-06, loss_scalings: 5497.559082, pp_loss: 3.975476
[INFO] 2021-07-09 16:50:20,170 [run_pretraining.py:  512]:	********exe.run_246******* 
[INFO] 2021-07-09 16:50:22,434 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:22,434 [run_pretraining.py:  534]:	loss/total_loss, 4.002895355224609, 247
[INFO] 2021-07-09 16:50:22,435 [run_pretraining.py:  535]:	loss/mlm_loss, 4.002895355224609, 247
[INFO] 2021-07-09 16:50:22,435 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4599999051133636e-06, 247
[INFO] 2021-07-09 16:50:22,435 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 247
[INFO] 2021-07-09 16:50:22,435 [run_pretraining.py:  558]:	worker_index: 6, step: 247, cost: 4.002895, mlm loss: 4.002895, speed: 0.441719 steps/s, speed: 3.533752 samples/s, speed: 1809.281070 tokens/s, learning rate: 2.460e-06, loss_scalings: 4398.047363, pp_loss: 4.011393
[INFO] 2021-07-09 16:50:22,435 [run_pretraining.py:  512]:	********exe.run_247******* 
[INFO] 2021-07-09 16:50:24,675 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:24,676 [run_pretraining.py:  534]:	loss/total_loss, 4.002468585968018, 248
[INFO] 2021-07-09 16:50:24,676 [run_pretraining.py:  535]:	loss/mlm_loss, 4.002468585968018, 248
[INFO] 2021-07-09 16:50:24,676 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4700000267330324e-06, 248
[INFO] 2021-07-09 16:50:24,676 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 248
[INFO] 2021-07-09 16:50:24,676 [run_pretraining.py:  558]:	worker_index: 6, step: 248, cost: 4.002469, mlm loss: 4.002469, speed: 0.446344 steps/s, speed: 3.570753 samples/s, speed: 1828.225633 tokens/s, learning rate: 2.470e-06, loss_scalings: 4398.047363, pp_loss: 4.011060
[INFO] 2021-07-09 16:50:24,676 [run_pretraining.py:  512]:	********exe.run_248******* 
[INFO] 2021-07-09 16:50:26,911 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:26,912 [run_pretraining.py:  534]:	loss/total_loss, 4.019770622253418, 249
[INFO] 2021-07-09 16:50:26,912 [run_pretraining.py:  535]:	loss/mlm_loss, 4.019770622253418, 249
[INFO] 2021-07-09 16:50:26,912 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4799999209790258e-06, 249
[INFO] 2021-07-09 16:50:26,912 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 249
[INFO] 2021-07-09 16:50:26,912 [run_pretraining.py:  558]:	worker_index: 6, step: 249, cost: 4.019771, mlm loss: 4.019771, speed: 0.447279 steps/s, speed: 3.578235 samples/s, speed: 1832.056236 tokens/s, learning rate: 2.480e-06, loss_scalings: 4398.047363, pp_loss: 4.029803
[INFO] 2021-07-09 16:50:26,912 [run_pretraining.py:  512]:	********exe.run_249******* 
[INFO] 2021-07-09 16:50:29,166 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:29,166 [run_pretraining.py:  534]:	loss/total_loss, 4.025399208068848, 250
[INFO] 2021-07-09 16:50:29,166 [run_pretraining.py:  535]:	loss/mlm_loss, 4.025399208068848, 250
[INFO] 2021-07-09 16:50:29,166 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4900000425986946e-06, 250
[INFO] 2021-07-09 16:50:29,167 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 250
[INFO] 2021-07-09 16:50:29,167 [run_pretraining.py:  558]:	worker_index: 6, step: 250, cost: 4.025399, mlm loss: 4.025399, speed: 0.443734 steps/s, speed: 3.549869 samples/s, speed: 1817.533020 tokens/s, learning rate: 2.490e-06, loss_scalings: 4398.047363, pp_loss: 4.025540
[INFO] 2021-07-09 16:50:29,167 [run_pretraining.py:  512]:	********exe.run_250******* 
[INFO] 2021-07-09 16:50:31,392 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:31,393 [run_pretraining.py:  534]:	loss/total_loss, 4.096515655517578, 251
[INFO] 2021-07-09 16:50:31,393 [run_pretraining.py:  535]:	loss/mlm_loss, 4.096515655517578, 251
[INFO] 2021-07-09 16:50:31,393 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.499999936844688e-06, 251
[INFO] 2021-07-09 16:50:31,393 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 251
[INFO] 2021-07-09 16:50:31,393 [run_pretraining.py:  558]:	worker_index: 6, step: 251, cost: 4.096516, mlm loss: 4.096516, speed: 0.449203 steps/s, speed: 3.593624 samples/s, speed: 1839.935251 tokens/s, learning rate: 2.500e-06, loss_scalings: 4398.047363, pp_loss: 4.031687
[INFO] 2021-07-09 16:50:31,394 [run_pretraining.py:  512]:	********exe.run_251******* 
[INFO] 2021-07-09 16:50:33,748 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:33,749 [run_pretraining.py:  534]:	loss/total_loss, 4.231335163116455, 252
[INFO] 2021-07-09 16:50:33,749 [run_pretraining.py:  535]:	loss/mlm_loss, 4.231335163116455, 252
[INFO] 2021-07-09 16:50:33,749 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5100000584643567e-06, 252
[INFO] 2021-07-09 16:50:33,749 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 252
[INFO] 2021-07-09 16:50:33,749 [run_pretraining.py:  558]:	worker_index: 6, step: 252, cost: 4.231335, mlm loss: 4.231335, speed: 0.424652 steps/s, speed: 3.397213 samples/s, speed: 1739.372856 tokens/s, learning rate: 2.510e-06, loss_scalings: 4398.047363, pp_loss: 4.108166
[INFO] 2021-07-09 16:50:33,749 [run_pretraining.py:  512]:	********exe.run_252******* 
[INFO] 2021-07-09 16:50:35,964 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:35,964 [run_pretraining.py:  534]:	loss/total_loss, 4.145966053009033, 253
[INFO] 2021-07-09 16:50:35,965 [run_pretraining.py:  535]:	loss/mlm_loss, 4.145966053009033, 253
[INFO] 2021-07-09 16:50:35,965 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.51999995271035e-06, 253
[INFO] 2021-07-09 16:50:35,965 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 253
[INFO] 2021-07-09 16:50:35,965 [run_pretraining.py:  558]:	worker_index: 6, step: 253, cost: 4.145966, mlm loss: 4.145966, speed: 0.451442 steps/s, speed: 3.611538 samples/s, speed: 1849.107302 tokens/s, learning rate: 2.520e-06, loss_scalings: 4398.047363, pp_loss: 4.113363
[INFO] 2021-07-09 16:50:35,965 [run_pretraining.py:  512]:	********exe.run_253******* 
[INFO] 2021-07-09 16:50:38,188 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:38,189 [run_pretraining.py:  534]:	loss/total_loss, 4.113807201385498, 254
[INFO] 2021-07-09 16:50:38,189 [run_pretraining.py:  535]:	loss/mlm_loss, 4.113807201385498, 254
[INFO] 2021-07-09 16:50:38,189 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5299998469563434e-06, 254
[INFO] 2021-07-09 16:50:38,189 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 254
[INFO] 2021-07-09 16:50:38,189 [run_pretraining.py:  558]:	worker_index: 6, step: 254, cost: 4.113807, mlm loss: 4.113807, speed: 0.449689 steps/s, speed: 3.597512 samples/s, speed: 1841.926269 tokens/s, learning rate: 2.530e-06, loss_scalings: 4398.047363, pp_loss: 4.116684
[INFO] 2021-07-09 16:50:38,189 [run_pretraining.py:  512]:	********exe.run_254******* 
[INFO] 2021-07-09 16:50:40,432 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:40,432 [run_pretraining.py:  534]:	loss/total_loss, 4.125418663024902, 255
[INFO] 2021-07-09 16:50:40,432 [run_pretraining.py:  535]:	loss/mlm_loss, 4.125418663024902, 255
[INFO] 2021-07-09 16:50:40,432 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.539999968576012e-06, 255
[INFO] 2021-07-09 16:50:40,432 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 255
[INFO] 2021-07-09 16:50:40,433 [run_pretraining.py:  558]:	worker_index: 6, step: 255, cost: 4.125419, mlm loss: 4.125419, speed: 0.445907 steps/s, speed: 3.567258 samples/s, speed: 1826.436324 tokens/s, learning rate: 2.540e-06, loss_scalings: 4398.047363, pp_loss: 4.098191
[INFO] 2021-07-09 16:50:40,433 [run_pretraining.py:  512]:	********exe.run_255******* 
[INFO] 2021-07-09 16:50:42,656 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:42,656 [run_pretraining.py:  534]:	loss/total_loss, 4.109709739685059, 256
[INFO] 2021-07-09 16:50:42,657 [run_pretraining.py:  535]:	loss/mlm_loss, 4.109709739685059, 256
[INFO] 2021-07-09 16:50:42,657 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5499998628220055e-06, 256
[INFO] 2021-07-09 16:50:42,657 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 256
[INFO] 2021-07-09 16:50:42,657 [run_pretraining.py:  558]:	worker_index: 6, step: 256, cost: 4.109710, mlm loss: 4.109710, speed: 0.449734 steps/s, speed: 3.597874 samples/s, speed: 1842.111327 tokens/s, learning rate: 2.550e-06, loss_scalings: 4398.047363, pp_loss: 4.141329
[INFO] 2021-07-09 16:50:42,657 [run_pretraining.py:  512]:	********exe.run_256******* 
[INFO] 2021-07-09 16:50:44,872 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:44,873 [run_pretraining.py:  534]:	loss/total_loss, 4.134690284729004, 257
[INFO] 2021-07-09 16:50:44,873 [run_pretraining.py:  535]:	loss/mlm_loss, 4.134690284729004, 257
[INFO] 2021-07-09 16:50:44,873 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.559999757067999e-06, 257
[INFO] 2021-07-09 16:50:44,873 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 257
[INFO] 2021-07-09 16:50:44,873 [run_pretraining.py:  558]:	worker_index: 6, step: 257, cost: 4.134690, mlm loss: 4.134690, speed: 0.451301 steps/s, speed: 3.610410 samples/s, speed: 1848.529717 tokens/s, learning rate: 2.560e-06, loss_scalings: 4398.047363, pp_loss: 4.149855
[INFO] 2021-07-09 16:50:44,873 [run_pretraining.py:  512]:	********exe.run_257******* 
[INFO] 2021-07-09 16:50:47,087 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:47,088 [run_pretraining.py:  534]:	loss/total_loss, 4.1598076820373535, 258
[INFO] 2021-07-09 16:50:47,088 [run_pretraining.py:  535]:	loss/mlm_loss, 4.1598076820373535, 258
[INFO] 2021-07-09 16:50:47,088 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5699998786876677e-06, 258
[INFO] 2021-07-09 16:50:47,088 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 258
[INFO] 2021-07-09 16:50:47,088 [run_pretraining.py:  558]:	worker_index: 6, step: 258, cost: 4.159808, mlm loss: 4.159808, speed: 0.451580 steps/s, speed: 3.612641 samples/s, speed: 1849.672104 tokens/s, learning rate: 2.570e-06, loss_scalings: 4398.047363, pp_loss: 4.164934
[INFO] 2021-07-09 16:50:47,088 [run_pretraining.py:  512]:	********exe.run_258******* 
[INFO] 2021-07-09 16:50:49,501 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:49,502 [run_pretraining.py:  534]:	loss/total_loss, 4.14190149307251, 259
[INFO] 2021-07-09 16:50:49,502 [run_pretraining.py:  535]:	loss/mlm_loss, 4.14190149307251, 259
[INFO] 2021-07-09 16:50:49,502 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5800000003073364e-06, 259
[INFO] 2021-07-09 16:50:49,502 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 259
[INFO] 2021-07-09 16:50:49,502 [run_pretraining.py:  558]:	worker_index: 6, step: 259, cost: 4.141901, mlm loss: 4.141901, speed: 0.414445 steps/s, speed: 3.315563 samples/s, speed: 1697.568228 tokens/s, learning rate: 2.580e-06, loss_scalings: 4398.047363, pp_loss: 4.169922
[INFO] 2021-07-09 16:50:49,502 [run_pretraining.py:  512]:	********exe.run_259******* 
[INFO] 2021-07-09 16:50:51,866 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:51,866 [run_pretraining.py:  534]:	loss/total_loss, 4.253171443939209, 260
[INFO] 2021-07-09 16:50:51,867 [run_pretraining.py:  535]:	loss/mlm_loss, 4.253171443939209, 260
[INFO] 2021-07-09 16:50:51,867 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.58999989455333e-06, 260
[INFO] 2021-07-09 16:50:51,867 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 260
[INFO] 2021-07-09 16:50:51,867 [run_pretraining.py:  558]:	worker_index: 6, step: 260, cost: 4.253171, mlm loss: 4.253171, speed: 0.422977 steps/s, speed: 3.383817 samples/s, speed: 1732.514223 tokens/s, learning rate: 2.590e-06, loss_scalings: 4398.047363, pp_loss: 4.188759
[INFO] 2021-07-09 16:50:51,867 [run_pretraining.py:  512]:	********exe.run_260******* 
[INFO] 2021-07-09 16:50:54,305 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:54,306 [run_pretraining.py:  534]:	loss/total_loss, 4.213992118835449, 261
[INFO] 2021-07-09 16:50:54,306 [run_pretraining.py:  535]:	loss/mlm_loss, 4.213992118835449, 261
[INFO] 2021-07-09 16:50:54,306 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6000000161729986e-06, 261
[INFO] 2021-07-09 16:50:54,306 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 261
[INFO] 2021-07-09 16:50:54,306 [run_pretraining.py:  558]:	worker_index: 6, step: 261, cost: 4.213992, mlm loss: 4.213992, speed: 0.410053 steps/s, speed: 3.280423 samples/s, speed: 1679.576351 tokens/s, learning rate: 2.600e-06, loss_scalings: 3518.437988, pp_loss: 4.244101
[INFO] 2021-07-09 16:50:54,306 [run_pretraining.py:  512]:	********exe.run_261******* 
[INFO] 2021-07-09 16:50:56,793 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:56,794 [run_pretraining.py:  534]:	loss/total_loss, 4.250152587890625, 262
[INFO] 2021-07-09 16:50:56,794 [run_pretraining.py:  535]:	loss/mlm_loss, 4.250152587890625, 262
[INFO] 2021-07-09 16:50:56,794 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.609999910418992e-06, 262
[INFO] 2021-07-09 16:50:56,794 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 262
[INFO] 2021-07-09 16:50:56,794 [run_pretraining.py:  558]:	worker_index: 6, step: 262, cost: 4.250153, mlm loss: 4.250153, speed: 0.402018 steps/s, speed: 3.216141 samples/s, speed: 1646.663974 tokens/s, learning rate: 2.610e-06, loss_scalings: 3518.437988, pp_loss: 4.259874
[INFO] 2021-07-09 16:50:56,794 [run_pretraining.py:  512]:	********exe.run_262******* 
[INFO] 2021-07-09 16:50:59,271 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:59,271 [run_pretraining.py:  534]:	loss/total_loss, 4.219903945922852, 263
[INFO] 2021-07-09 16:50:59,271 [run_pretraining.py:  535]:	loss/mlm_loss, 4.219903945922852, 263
[INFO] 2021-07-09 16:50:59,272 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6200000320386607e-06, 263
[INFO] 2021-07-09 16:50:59,272 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 263
[INFO] 2021-07-09 16:50:59,272 [run_pretraining.py:  558]:	worker_index: 6, step: 263, cost: 4.219904, mlm loss: 4.219904, speed: 0.403774 steps/s, speed: 3.230196 samples/s, speed: 1653.860304 tokens/s, learning rate: 2.620e-06, loss_scalings: 3518.437988, pp_loss: 4.271619
[INFO] 2021-07-09 16:50:59,272 [run_pretraining.py:  512]:	********exe.run_263******* 
[INFO] 2021-07-09 16:51:01,498 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:01,498 [run_pretraining.py:  534]:	loss/total_loss, 4.318770408630371, 264
[INFO] 2021-07-09 16:51:01,499 [run_pretraining.py:  535]:	loss/mlm_loss, 4.318770408630371, 264
[INFO] 2021-07-09 16:51:01,499 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.629999926284654e-06, 264
[INFO] 2021-07-09 16:51:01,499 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 264
[INFO] 2021-07-09 16:51:01,499 [run_pretraining.py:  558]:	worker_index: 6, step: 264, cost: 4.318770, mlm loss: 4.318770, speed: 0.449161 steps/s, speed: 3.593291 samples/s, speed: 1839.765209 tokens/s, learning rate: 2.630e-06, loss_scalings: 3518.437988, pp_loss: 4.335709
[INFO] 2021-07-09 16:51:01,499 [run_pretraining.py:  512]:	********exe.run_264******* 
[INFO] 2021-07-09 16:51:03,736 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:03,736 [run_pretraining.py:  534]:	loss/total_loss, 4.328840255737305, 265
[INFO] 2021-07-09 16:51:03,736 [run_pretraining.py:  535]:	loss/mlm_loss, 4.328840255737305, 265
[INFO] 2021-07-09 16:51:03,737 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6399998205306474e-06, 265
[INFO] 2021-07-09 16:51:03,737 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 265
[INFO] 2021-07-09 16:51:03,737 [run_pretraining.py:  558]:	worker_index: 6, step: 265, cost: 4.328840, mlm loss: 4.328840, speed: 0.446987 steps/s, speed: 3.575896 samples/s, speed: 1830.858815 tokens/s, learning rate: 2.640e-06, loss_scalings: 3518.437988, pp_loss: 4.319044
[INFO] 2021-07-09 16:51:03,737 [run_pretraining.py:  512]:	********exe.run_265******* 
[INFO] 2021-07-09 16:51:05,939 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:05,940 [run_pretraining.py:  534]:	loss/total_loss, 4.348947525024414, 266
[INFO] 2021-07-09 16:51:05,940 [run_pretraining.py:  535]:	loss/mlm_loss, 4.348947525024414, 266
[INFO] 2021-07-09 16:51:05,940 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.649999942150316e-06, 266
[INFO] 2021-07-09 16:51:05,940 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 266
[INFO] 2021-07-09 16:51:05,940 [run_pretraining.py:  558]:	worker_index: 6, step: 266, cost: 4.348948, mlm loss: 4.348948, speed: 0.453994 steps/s, speed: 3.631954 samples/s, speed: 1859.560463 tokens/s, learning rate: 2.650e-06, loss_scalings: 3518.437988, pp_loss: 4.317801
[INFO] 2021-07-09 16:51:05,940 [run_pretraining.py:  512]:	********exe.run_266******* 
[INFO] 2021-07-09 16:51:08,180 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:08,181 [run_pretraining.py:  534]:	loss/total_loss, 4.330934524536133, 267
[INFO] 2021-07-09 16:51:08,181 [run_pretraining.py:  535]:	loss/mlm_loss, 4.330934524536133, 267
[INFO] 2021-07-09 16:51:08,181 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6599998363963095e-06, 267
[INFO] 2021-07-09 16:51:08,181 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 267
[INFO] 2021-07-09 16:51:08,181 [run_pretraining.py:  558]:	worker_index: 6, step: 267, cost: 4.330935, mlm loss: 4.330935, speed: 0.446292 steps/s, speed: 3.570339 samples/s, speed: 1828.013400 tokens/s, learning rate: 2.660e-06, loss_scalings: 3518.437988, pp_loss: 4.301903
[INFO] 2021-07-09 16:51:08,181 [run_pretraining.py:  512]:	********exe.run_267******* 
[INFO] 2021-07-09 16:51:10,411 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:10,412 [run_pretraining.py:  534]:	loss/total_loss, 4.212439060211182, 268
[INFO] 2021-07-09 16:51:10,412 [run_pretraining.py:  535]:	loss/mlm_loss, 4.212439060211182, 268
[INFO] 2021-07-09 16:51:10,412 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6699999580159783e-06, 268
[INFO] 2021-07-09 16:51:10,412 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 268
[INFO] 2021-07-09 16:51:10,412 [run_pretraining.py:  558]:	worker_index: 6, step: 268, cost: 4.212439, mlm loss: 4.212439, speed: 0.448365 steps/s, speed: 3.586919 samples/s, speed: 1836.502288 tokens/s, learning rate: 2.670e-06, loss_scalings: 3518.437988, pp_loss: 4.248735
[INFO] 2021-07-09 16:51:10,412 [run_pretraining.py:  512]:	********exe.run_268******* 
[INFO] 2021-07-09 16:51:12,651 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:12,652 [run_pretraining.py:  534]:	loss/total_loss, 4.203214645385742, 269
[INFO] 2021-07-09 16:51:12,652 [run_pretraining.py:  535]:	loss/mlm_loss, 4.203214645385742, 269
[INFO] 2021-07-09 16:51:12,652 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6799998522619717e-06, 269
[INFO] 2021-07-09 16:51:12,652 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 269
[INFO] 2021-07-09 16:51:12,652 [run_pretraining.py:  558]:	worker_index: 6, step: 269, cost: 4.203215, mlm loss: 4.203215, speed: 0.446548 steps/s, speed: 3.572382 samples/s, speed: 1829.059482 tokens/s, learning rate: 2.680e-06, loss_scalings: 3518.437988, pp_loss: 4.203148
[INFO] 2021-07-09 16:51:12,653 [run_pretraining.py:  512]:	********exe.run_269******* 
[INFO] 2021-07-09 16:51:14,857 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:14,858 [run_pretraining.py:  534]:	loss/total_loss, 4.209217548370361, 270
[INFO] 2021-07-09 16:51:14,858 [run_pretraining.py:  535]:	loss/mlm_loss, 4.209217548370361, 270
[INFO] 2021-07-09 16:51:14,858 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6899999738816405e-06, 270
[INFO] 2021-07-09 16:51:14,858 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 270
[INFO] 2021-07-09 16:51:14,858 [run_pretraining.py:  558]:	worker_index: 6, step: 270, cost: 4.209218, mlm loss: 4.209218, speed: 0.453511 steps/s, speed: 3.628087 samples/s, speed: 1857.580569 tokens/s, learning rate: 2.690e-06, loss_scalings: 3518.437988, pp_loss: 4.175130
[INFO] 2021-07-09 16:51:14,858 [run_pretraining.py:  512]:	********exe.run_270******* 
[INFO] 2021-07-09 16:51:17,066 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:17,067 [run_pretraining.py:  534]:	loss/total_loss, 4.114926338195801, 271
[INFO] 2021-07-09 16:51:17,067 [run_pretraining.py:  535]:	loss/mlm_loss, 4.114926338195801, 271
[INFO] 2021-07-09 16:51:17,067 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7000000955013093e-06, 271
[INFO] 2021-07-09 16:51:17,067 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 271
[INFO] 2021-07-09 16:51:17,067 [run_pretraining.py:  558]:	worker_index: 6, step: 271, cost: 4.114926, mlm loss: 4.114926, speed: 0.452901 steps/s, speed: 3.623210 samples/s, speed: 1855.083728 tokens/s, learning rate: 2.700e-06, loss_scalings: 3518.437988, pp_loss: 4.198078
[INFO] 2021-07-09 16:51:17,067 [run_pretraining.py:  512]:	********exe.run_271******* 
[INFO] 2021-07-09 16:51:19,304 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:19,304 [run_pretraining.py:  534]:	loss/total_loss, 4.124622821807861, 272
[INFO] 2021-07-09 16:51:19,304 [run_pretraining.py:  535]:	loss/mlm_loss, 4.124622821807861, 272
[INFO] 2021-07-09 16:51:19,304 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7099999897473026e-06, 272
[INFO] 2021-07-09 16:51:19,305 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 272
[INFO] 2021-07-09 16:51:19,305 [run_pretraining.py:  558]:	worker_index: 6, step: 272, cost: 4.124623, mlm loss: 4.124623, speed: 0.447008 steps/s, speed: 3.576061 samples/s, speed: 1830.943108 tokens/s, learning rate: 2.710e-06, loss_scalings: 3518.437988, pp_loss: 4.162110
[INFO] 2021-07-09 16:51:19,305 [run_pretraining.py:  512]:	********exe.run_272******* 
[INFO] 2021-07-09 16:51:21,531 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:21,532 [run_pretraining.py:  534]:	loss/total_loss, 4.244729042053223, 273
[INFO] 2021-07-09 16:51:21,532 [run_pretraining.py:  535]:	loss/mlm_loss, 4.244729042053223, 273
[INFO] 2021-07-09 16:51:21,532 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.719999883993296e-06, 273
[INFO] 2021-07-09 16:51:21,532 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 273
[INFO] 2021-07-09 16:51:21,532 [run_pretraining.py:  558]:	worker_index: 6, step: 273, cost: 4.244729, mlm loss: 4.244729, speed: 0.449048 steps/s, speed: 3.592387 samples/s, speed: 1839.302334 tokens/s, learning rate: 2.720e-06, loss_scalings: 3518.437988, pp_loss: 4.125267
[INFO] 2021-07-09 16:51:21,532 [run_pretraining.py:  512]:	********exe.run_273******* 
[INFO] 2021-07-09 16:51:23,778 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:23,779 [run_pretraining.py:  534]:	loss/total_loss, 4.0471415519714355, 274
[INFO] 2021-07-09 16:51:23,779 [run_pretraining.py:  535]:	loss/mlm_loss, 4.0471415519714355, 274
[INFO] 2021-07-09 16:51:23,779 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7300000056129647e-06, 274
[INFO] 2021-07-09 16:51:23,779 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 274
[INFO] 2021-07-09 16:51:23,780 [run_pretraining.py:  558]:	worker_index: 6, step: 274, cost: 4.047142, mlm loss: 4.047142, speed: 0.445128 steps/s, speed: 3.561024 samples/s, speed: 1823.244269 tokens/s, learning rate: 2.730e-06, loss_scalings: 3518.437988, pp_loss: 4.087354
[INFO] 2021-07-09 16:51:23,780 [run_pretraining.py:  512]:	********exe.run_274******* 
[INFO] 2021-07-09 16:51:26,011 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:26,012 [run_pretraining.py:  534]:	loss/total_loss, 4.024571418762207, 275
[INFO] 2021-07-09 16:51:26,012 [run_pretraining.py:  535]:	loss/mlm_loss, 4.024571418762207, 275
[INFO] 2021-07-09 16:51:26,012 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.739999899858958e-06, 275
[INFO] 2021-07-09 16:51:26,012 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 275
[INFO] 2021-07-09 16:51:26,012 [run_pretraining.py:  558]:	worker_index: 6, step: 275, cost: 4.024571, mlm loss: 4.024571, speed: 0.448023 steps/s, speed: 3.584181 samples/s, speed: 1835.100657 tokens/s, learning rate: 2.740e-06, loss_scalings: 3518.437988, pp_loss: 4.036472
[INFO] 2021-07-09 16:51:26,012 [run_pretraining.py:  512]:	********exe.run_275******* 
[INFO] 2021-07-09 16:51:28,263 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:28,264 [run_pretraining.py:  534]:	loss/total_loss, 3.975677490234375, 276
[INFO] 2021-07-09 16:51:28,264 [run_pretraining.py:  535]:	loss/mlm_loss, 3.975677490234375, 276
[INFO] 2021-07-09 16:51:28,264 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.750000021478627e-06, 276
[INFO] 2021-07-09 16:51:28,264 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 276
[INFO] 2021-07-09 16:51:28,264 [run_pretraining.py:  558]:	worker_index: 6, step: 276, cost: 3.975677, mlm loss: 3.975677, speed: 0.444161 steps/s, speed: 3.553285 samples/s, speed: 1819.281993 tokens/s, learning rate: 2.750e-06, loss_scalings: 3518.437988, pp_loss: 4.017948
[INFO] 2021-07-09 16:51:28,264 [run_pretraining.py:  512]:	********exe.run_276******* 
[INFO] 2021-07-09 16:51:30,486 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:30,486 [run_pretraining.py:  534]:	loss/total_loss, 3.970303535461426, 277
[INFO] 2021-07-09 16:51:30,486 [run_pretraining.py:  535]:	loss/mlm_loss, 3.970303535461426, 277
[INFO] 2021-07-09 16:51:30,486 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7599999157246202e-06, 277
[INFO] 2021-07-09 16:51:30,487 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 277
[INFO] 2021-07-09 16:51:30,487 [run_pretraining.py:  558]:	worker_index: 6, step: 277, cost: 3.970304, mlm loss: 3.970304, speed: 0.450120 steps/s, speed: 3.600962 samples/s, speed: 1843.692649 tokens/s, learning rate: 2.760e-06, loss_scalings: 3518.437988, pp_loss: 3.988657
[INFO] 2021-07-09 16:51:30,487 [run_pretraining.py:  512]:	********exe.run_277******* 
[INFO] 2021-07-09 16:51:32,764 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:32,765 [run_pretraining.py:  534]:	loss/total_loss, 4.0063796043396, 278
[INFO] 2021-07-09 16:51:32,765 [run_pretraining.py:  535]:	loss/mlm_loss, 4.0063796043396, 278
[INFO] 2021-07-09 16:51:32,765 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7699998099706136e-06, 278
[INFO] 2021-07-09 16:51:32,765 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 278
[INFO] 2021-07-09 16:51:32,765 [run_pretraining.py:  558]:	worker_index: 6, step: 278, cost: 4.006380, mlm loss: 4.006380, speed: 0.438977 steps/s, speed: 3.511816 samples/s, speed: 1798.049571 tokens/s, learning rate: 2.770e-06, loss_scalings: 3518.437988, pp_loss: 3.970006
[INFO] 2021-07-09 16:51:32,765 [run_pretraining.py:  512]:	********exe.run_278******* 
[INFO] 2021-07-09 16:51:35,097 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:35,098 [run_pretraining.py:  534]:	loss/total_loss, 3.978977918624878, 279
[INFO] 2021-07-09 16:51:35,098 [run_pretraining.py:  535]:	loss/mlm_loss, 3.978977918624878, 279
[INFO] 2021-07-09 16:51:35,099 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7799999315902824e-06, 279
[INFO] 2021-07-09 16:51:35,099 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 279
[INFO] 2021-07-09 16:51:35,099 [run_pretraining.py:  558]:	worker_index: 6, step: 279, cost: 3.978978, mlm loss: 3.978978, speed: 0.428689 steps/s, speed: 3.429509 samples/s, speed: 1755.908394 tokens/s, learning rate: 2.780e-06, loss_scalings: 2814.750488, pp_loss: 3.968619
[INFO] 2021-07-09 16:51:35,099 [run_pretraining.py:  512]:	********exe.run_279******* 
[INFO] 2021-07-09 16:51:37,322 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:37,322 [run_pretraining.py:  534]:	loss/total_loss, 3.988126277923584, 280
[INFO] 2021-07-09 16:51:37,322 [run_pretraining.py:  535]:	loss/mlm_loss, 3.988126277923584, 280
[INFO] 2021-07-09 16:51:37,323 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7899998258362757e-06, 280
[INFO] 2021-07-09 16:51:37,323 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 280
[INFO] 2021-07-09 16:51:37,323 [run_pretraining.py:  558]:	worker_index: 6, step: 280, cost: 3.988126, mlm loss: 3.988126, speed: 0.449806 steps/s, speed: 3.598449 samples/s, speed: 1842.405679 tokens/s, learning rate: 2.790e-06, loss_scalings: 2814.750488, pp_loss: 3.962459
[INFO] 2021-07-09 16:51:37,323 [run_pretraining.py:  512]:	********exe.run_280******* 
[INFO] 2021-07-09 16:51:39,554 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:39,555 [run_pretraining.py:  534]:	loss/total_loss, 3.9618422985076904, 281
[INFO] 2021-07-09 16:51:39,555 [run_pretraining.py:  535]:	loss/mlm_loss, 3.9618422985076904, 281
[INFO] 2021-07-09 16:51:39,555 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7999999474559445e-06, 281
[INFO] 2021-07-09 16:51:39,555 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 281
[INFO] 2021-07-09 16:51:39,555 [run_pretraining.py:  558]:	worker_index: 6, step: 281, cost: 3.961842, mlm loss: 3.961842, speed: 0.448096 steps/s, speed: 3.584766 samples/s, speed: 1835.400224 tokens/s, learning rate: 2.800e-06, loss_scalings: 2814.750488, pp_loss: 3.984757
[INFO] 2021-07-09 16:51:39,555 [run_pretraining.py:  512]:	********exe.run_281******* 
[INFO] 2021-07-09 16:51:41,771 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:41,772 [run_pretraining.py:  534]:	loss/total_loss, 4.025957107543945, 282
[INFO] 2021-07-09 16:51:41,772 [run_pretraining.py:  535]:	loss/mlm_loss, 4.025957107543945, 282
[INFO] 2021-07-09 16:51:41,772 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8100000690756133e-06, 282
[INFO] 2021-07-09 16:51:41,772 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 282
[INFO] 2021-07-09 16:51:41,772 [run_pretraining.py:  558]:	worker_index: 6, step: 282, cost: 4.025957, mlm loss: 4.025957, speed: 0.451191 steps/s, speed: 3.609525 samples/s, speed: 1848.076935 tokens/s, learning rate: 2.810e-06, loss_scalings: 2814.750488, pp_loss: 4.000271
[INFO] 2021-07-09 16:51:41,772 [run_pretraining.py:  512]:	********exe.run_282******* 
[INFO] 2021-07-09 16:51:43,995 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:43,996 [run_pretraining.py:  534]:	loss/total_loss, 4.059089660644531, 283
[INFO] 2021-07-09 16:51:43,996 [run_pretraining.py:  535]:	loss/mlm_loss, 4.059089660644531, 283
[INFO] 2021-07-09 16:51:43,996 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8199999633216066e-06, 283
[INFO] 2021-07-09 16:51:43,996 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 283
[INFO] 2021-07-09 16:51:43,996 [run_pretraining.py:  558]:	worker_index: 6, step: 283, cost: 4.059090, mlm loss: 4.059090, speed: 0.449800 steps/s, speed: 3.598403 samples/s, speed: 1842.382167 tokens/s, learning rate: 2.820e-06, loss_scalings: 2814.750488, pp_loss: 4.022180
[INFO] 2021-07-09 16:51:43,996 [run_pretraining.py:  512]:	********exe.run_283******* 
[INFO] 2021-07-09 16:51:46,235 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:46,235 [run_pretraining.py:  534]:	loss/total_loss, 3.992818832397461, 284
[INFO] 2021-07-09 16:51:46,235 [run_pretraining.py:  535]:	loss/mlm_loss, 3.992818832397461, 284
[INFO] 2021-07-09 16:51:46,236 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8299998575676e-06, 284
[INFO] 2021-07-09 16:51:46,236 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 284
[INFO] 2021-07-09 16:51:46,236 [run_pretraining.py:  558]:	worker_index: 6, step: 284, cost: 3.992819, mlm loss: 3.992819, speed: 0.446616 steps/s, speed: 3.572929 samples/s, speed: 1829.339548 tokens/s, learning rate: 2.830e-06, loss_scalings: 2814.750488, pp_loss: 4.057828
[INFO] 2021-07-09 16:51:46,236 [run_pretraining.py:  512]:	********exe.run_284******* 
[INFO] 2021-07-09 16:51:48,447 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:48,447 [run_pretraining.py:  534]:	loss/total_loss, 4.1258344650268555, 285
[INFO] 2021-07-09 16:51:48,448 [run_pretraining.py:  535]:	loss/mlm_loss, 4.1258344650268555, 285
[INFO] 2021-07-09 16:51:48,448 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8399999791872688e-06, 285
[INFO] 2021-07-09 16:51:48,448 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 285
[INFO] 2021-07-09 16:51:48,448 [run_pretraining.py:  558]:	worker_index: 6, step: 285, cost: 4.125834, mlm loss: 4.125834, speed: 0.452211 steps/s, speed: 3.617684 samples/s, speed: 1852.254235 tokens/s, learning rate: 2.840e-06, loss_scalings: 2814.750488, pp_loss: 4.081089
[INFO] 2021-07-09 16:51:48,448 [run_pretraining.py:  512]:	********exe.run_285******* 
[INFO] 2021-07-09 16:51:50,646 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:50,647 [run_pretraining.py:  534]:	loss/total_loss, 4.258241653442383, 286
[INFO] 2021-07-09 16:51:50,647 [run_pretraining.py:  535]:	loss/mlm_loss, 4.258241653442383, 286
[INFO] 2021-07-09 16:51:50,647 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.849999873433262e-06, 286
[INFO] 2021-07-09 16:51:50,647 [run_pretraining.py:  539]:	lr/loss_scaling, 2251.800537109375, 286
[INFO] 2021-07-09 16:51:50,647 [run_pretraining.py:  558]:	worker_index: 6, step: 286, cost: 4.258242, mlm loss: 4.258242, speed: 0.454839 steps/s, speed: 3.638711 samples/s, speed: 1863.020048 tokens/s, learning rate: 2.850e-06, loss_scalings: 2251.800537, pp_loss: 4.127234
[INFO] 2021-07-09 16:51:50,647 [run_pretraining.py:  512]:	********exe.run_286******* 
[INFO] 2021-07-09 16:51:52,853 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:52,854 [run_pretraining.py:  534]:	loss/total_loss, 4.157508373260498, 287
[INFO] 2021-07-09 16:51:52,854 [run_pretraining.py:  535]:	loss/mlm_loss, 4.157508373260498, 287
[INFO] 2021-07-09 16:51:52,854 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.859999995052931e-06, 287
[INFO] 2021-07-09 16:51:52,854 [run_pretraining.py:  539]:	lr/loss_scaling, 2251.800537109375, 287
[INFO] 2021-07-09 16:51:52,854 [run_pretraining.py:  558]:	worker_index: 6, step: 287, cost: 4.157508, mlm loss: 4.157508, speed: 0.453248 steps/s, speed: 3.625985 samples/s, speed: 1856.504427 tokens/s, learning rate: 2.860e-06, loss_scalings: 2251.800537, pp_loss: 4.181489
[INFO] 2021-07-09 16:51:52,854 [run_pretraining.py:  512]:	********exe.run_287******* 
[INFO] 2021-07-09 16:51:55,079 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:55,080 [run_pretraining.py:  534]:	loss/total_loss, 4.256918907165527, 288
[INFO] 2021-07-09 16:51:55,080 [run_pretraining.py:  535]:	loss/mlm_loss, 4.256918907165527, 288
[INFO] 2021-07-09 16:51:55,080 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8699998892989242e-06, 288
[INFO] 2021-07-09 16:51:55,080 [run_pretraining.py:  539]:	lr/loss_scaling, 2251.800537109375, 288
[INFO] 2021-07-09 16:51:55,080 [run_pretraining.py:  558]:	worker_index: 6, step: 288, cost: 4.256919, mlm loss: 4.256919, speed: 0.449379 steps/s, speed: 3.595030 samples/s, speed: 1840.655371 tokens/s, learning rate: 2.870e-06, loss_scalings: 2251.800537, pp_loss: 4.200960
[INFO] 2021-07-09 16:51:55,080 [run_pretraining.py:  512]:	********exe.run_288******* 
[INFO] 2021-07-09 16:51:57,303 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:57,304 [run_pretraining.py:  534]:	loss/total_loss, 4.268266677856445, 289
[INFO] 2021-07-09 16:51:57,304 [run_pretraining.py:  535]:	loss/mlm_loss, 4.268266677856445, 289
[INFO] 2021-07-09 16:51:57,304 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8799997835449176e-06, 289
[INFO] 2021-07-09 16:51:57,304 [run_pretraining.py:  539]:	lr/loss_scaling, 2251.800537109375, 289
[INFO] 2021-07-09 16:51:57,304 [run_pretraining.py:  558]:	worker_index: 6, step: 289, cost: 4.268267, mlm loss: 4.268267, speed: 0.449675 steps/s, speed: 3.597399 samples/s, speed: 1841.868409 tokens/s, learning rate: 2.880e-06, loss_scalings: 2251.800537, pp_loss: 4.257666
[INFO] 2021-07-09 16:51:57,305 [run_pretraining.py:  512]:	********exe.run_289******* 
[INFO] 2021-07-09 16:51:59,571 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:59,571 [run_pretraining.py:  534]:	loss/total_loss, 4.31582498550415, 290
[INFO] 2021-07-09 16:51:59,571 [run_pretraining.py:  535]:	loss/mlm_loss, 4.31582498550415, 290
[INFO] 2021-07-09 16:51:59,571 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8899999051645864e-06, 290
[INFO] 2021-07-09 16:51:59,571 [run_pretraining.py:  539]:	lr/loss_scaling, 2251.800537109375, 290
[INFO] 2021-07-09 16:51:59,572 [run_pretraining.py:  558]:	worker_index: 6, step: 290, cost: 4.315825, mlm loss: 4.315825, speed: 0.441214 steps/s, speed: 3.529710 samples/s, speed: 1807.211479 tokens/s, learning rate: 2.890e-06, loss_scalings: 2251.800537, pp_loss: 4.301788
[INFO] 2021-07-09 16:51:59,572 [run_pretraining.py:  512]:	********exe.run_290******* 
[INFO] 2021-07-09 16:52:01,775 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:01,775 [run_pretraining.py:  534]:	loss/total_loss, 4.302286624908447, 291
[INFO] 2021-07-09 16:52:01,775 [run_pretraining.py:  535]:	loss/mlm_loss, 4.302286624908447, 291
[INFO] 2021-07-09 16:52:01,775 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8999997994105797e-06, 291
[INFO] 2021-07-09 16:52:01,776 [run_pretraining.py:  539]:	lr/loss_scaling, 2251.800537109375, 291
[INFO] 2021-07-09 16:52:01,776 [run_pretraining.py:  558]:	worker_index: 6, step: 291, cost: 4.302287, mlm loss: 4.302287, speed: 0.453863 steps/s, speed: 3.630902 samples/s, speed: 1859.021793 tokens/s, learning rate: 2.900e-06, loss_scalings: 2251.800537, pp_loss: 4.328753
[INFO] 2021-07-09 16:52:01,776 [run_pretraining.py:  512]:	********exe.run_291******* 
[INFO] 2021-07-09 16:52:03,983 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:03,984 [run_pretraining.py:  534]:	loss/total_loss, 4.497673988342285, 292
[INFO] 2021-07-09 16:52:03,984 [run_pretraining.py:  535]:	loss/mlm_loss, 4.497673988342285, 292
[INFO] 2021-07-09 16:52:03,984 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9099999210302485e-06, 292
[INFO] 2021-07-09 16:52:03,984 [run_pretraining.py:  539]:	lr/loss_scaling, 2251.800537109375, 292
[INFO] 2021-07-09 16:52:03,985 [run_pretraining.py:  558]:	worker_index: 6, step: 292, cost: 4.497674, mlm loss: 4.497674, speed: 0.452857 steps/s, speed: 3.622860 samples/s, speed: 1854.904065 tokens/s, learning rate: 2.910e-06, loss_scalings: 2251.800537, pp_loss: 4.437530
[INFO] 2021-07-09 16:52:03,985 [run_pretraining.py:  512]:	********exe.run_292******* 
[INFO] 2021-07-09 16:52:06,234 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:06,235 [run_pretraining.py:  534]:	loss/total_loss, 4.531708717346191, 293
[INFO] 2021-07-09 16:52:06,235 [run_pretraining.py:  535]:	loss/mlm_loss, 4.531708717346191, 293
[INFO] 2021-07-09 16:52:06,235 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9200000426499173e-06, 293
[INFO] 2021-07-09 16:52:06,235 [run_pretraining.py:  539]:	lr/loss_scaling, 2251.800537109375, 293
[INFO] 2021-07-09 16:52:06,235 [run_pretraining.py:  558]:	worker_index: 6, step: 293, cost: 4.531709, mlm loss: 4.531709, speed: 0.444463 steps/s, speed: 3.555708 samples/s, speed: 1820.522380 tokens/s, learning rate: 2.920e-06, loss_scalings: 2251.800537, pp_loss: 4.494787
[INFO] 2021-07-09 16:52:06,235 [run_pretraining.py:  512]:	********exe.run_293******* 
[INFO] 2021-07-09 16:52:08,489 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:08,489 [run_pretraining.py:  534]:	loss/total_loss, 4.529928207397461, 294
[INFO] 2021-07-09 16:52:08,489 [run_pretraining.py:  535]:	loss/mlm_loss, 4.529928207397461, 294
[INFO] 2021-07-09 16:52:08,489 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9299999368959107e-06, 294
[INFO] 2021-07-09 16:52:08,490 [run_pretraining.py:  539]:	lr/loss_scaling, 1801.4404296875, 294
[INFO] 2021-07-09 16:52:08,490 [run_pretraining.py:  558]:	worker_index: 6, step: 294, cost: 4.529928, mlm loss: 4.529928, speed: 0.443691 steps/s, speed: 3.549526 samples/s, speed: 1817.357097 tokens/s, learning rate: 2.930e-06, loss_scalings: 1801.440430, pp_loss: 4.564874
[INFO] 2021-07-09 16:52:08,490 [run_pretraining.py:  512]:	********exe.run_294******* 
[INFO] 2021-07-09 16:52:10,708 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:10,709 [run_pretraining.py:  534]:	loss/total_loss, 4.615147590637207, 295
[INFO] 2021-07-09 16:52:10,709 [run_pretraining.py:  535]:	loss/mlm_loss, 4.615147590637207, 295
[INFO] 2021-07-09 16:52:10,709 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9400000585155794e-06, 295
[INFO] 2021-07-09 16:52:10,709 [run_pretraining.py:  539]:	lr/loss_scaling, 1801.4404296875, 295
[INFO] 2021-07-09 16:52:10,709 [run_pretraining.py:  558]:	worker_index: 6, step: 295, cost: 4.615148, mlm loss: 4.615148, speed: 0.450706 steps/s, speed: 3.605646 samples/s, speed: 1846.090855 tokens/s, learning rate: 2.940e-06, loss_scalings: 1801.440430, pp_loss: 4.585043
[INFO] 2021-07-09 16:52:10,709 [run_pretraining.py:  512]:	********exe.run_295******* 
[INFO] 2021-07-09 16:52:13,017 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:13,019 [run_pretraining.py:  534]:	loss/total_loss, 4.688318729400635, 296
[INFO] 2021-07-09 16:52:13,019 [run_pretraining.py:  535]:	loss/mlm_loss, 4.688318729400635, 296
[INFO] 2021-07-09 16:52:13,019 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9499999527615728e-06, 296
[INFO] 2021-07-09 16:52:13,019 [run_pretraining.py:  539]:	lr/loss_scaling, 1801.4404296875, 296
[INFO] 2021-07-09 16:52:13,019 [run_pretraining.py:  558]:	worker_index: 6, step: 296, cost: 4.688319, mlm loss: 4.688319, speed: 0.433065 steps/s, speed: 3.464519 samples/s, speed: 1773.833952 tokens/s, learning rate: 2.950e-06, loss_scalings: 1801.440430, pp_loss: 4.660797
[INFO] 2021-07-09 16:52:13,019 [run_pretraining.py:  512]:	********exe.run_296******* 
[INFO] 2021-07-09 16:52:15,325 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:15,325 [run_pretraining.py:  534]:	loss/total_loss, 4.697315216064453, 297
[INFO] 2021-07-09 16:52:15,325 [run_pretraining.py:  535]:	loss/mlm_loss, 4.697315216064453, 297
[INFO] 2021-07-09 16:52:15,326 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.959999847007566e-06, 297
[INFO] 2021-07-09 16:52:15,326 [run_pretraining.py:  539]:	lr/loss_scaling, 1801.4404296875, 297
[INFO] 2021-07-09 16:52:15,326 [run_pretraining.py:  558]:	worker_index: 6, step: 297, cost: 4.697315, mlm loss: 4.697315, speed: 0.433623 steps/s, speed: 3.468984 samples/s, speed: 1776.119670 tokens/s, learning rate: 2.960e-06, loss_scalings: 1801.440430, pp_loss: 4.698975
[INFO] 2021-07-09 16:52:15,326 [run_pretraining.py:  512]:	********exe.run_297******* 
[INFO] 2021-07-09 16:52:17,542 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:17,542 [run_pretraining.py:  534]:	loss/total_loss, 4.699848175048828, 298
[INFO] 2021-07-09 16:52:17,542 [run_pretraining.py:  535]:	loss/mlm_loss, 4.699848175048828, 298
[INFO] 2021-07-09 16:52:17,543 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.969999968627235e-06, 298
[INFO] 2021-07-09 16:52:17,543 [run_pretraining.py:  539]:	lr/loss_scaling, 1801.4404296875, 298
[INFO] 2021-07-09 16:52:17,543 [run_pretraining.py:  558]:	worker_index: 6, step: 298, cost: 4.699848, mlm loss: 4.699848, speed: 0.451192 steps/s, speed: 3.609533 samples/s, speed: 1848.081110 tokens/s, learning rate: 2.970e-06, loss_scalings: 1801.440430, pp_loss: 4.725061
[INFO] 2021-07-09 16:52:17,543 [run_pretraining.py:  512]:	********exe.run_298******* 
[INFO] 2021-07-09 16:52:19,746 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:19,746 [run_pretraining.py:  534]:	loss/total_loss, 4.9067063331604, 299
[INFO] 2021-07-09 16:52:19,746 [run_pretraining.py:  535]:	loss/mlm_loss, 4.9067063331604, 299
[INFO] 2021-07-09 16:52:19,746 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9799998628732283e-06, 299
[INFO] 2021-07-09 16:52:19,747 [run_pretraining.py:  539]:	lr/loss_scaling, 1801.4404296875, 299
[INFO] 2021-07-09 16:52:19,747 [run_pretraining.py:  558]:	worker_index: 6, step: 299, cost: 4.906706, mlm loss: 4.906706, speed: 0.453893 steps/s, speed: 3.631146 samples/s, speed: 1859.146522 tokens/s, learning rate: 2.980e-06, loss_scalings: 1801.440430, pp_loss: 4.802776
[INFO] 2021-07-09 16:52:19,747 [run_pretraining.py:  512]:	********exe.run_299******* 
[INFO] 2021-07-09 16:52:21,946 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:21,947 [run_pretraining.py:  534]:	loss/total_loss, 4.786786079406738, 300
[INFO] 2021-07-09 16:52:21,947 [run_pretraining.py:  535]:	loss/mlm_loss, 4.786786079406738, 300
[INFO] 2021-07-09 16:52:21,947 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.989999984492897e-06, 300
[INFO] 2021-07-09 16:52:21,947 [run_pretraining.py:  539]:	lr/loss_scaling, 1801.4404296875, 300
[INFO] 2021-07-09 16:52:21,947 [run_pretraining.py:  558]:	worker_index: 6, step: 300, cost: 4.786786, mlm loss: 4.786786, speed: 0.454584 steps/s, speed: 3.636673 samples/s, speed: 1861.976342 tokens/s, learning rate: 2.990e-06, loss_scalings: 1801.440430, pp_loss: 4.785236
[INFO] 2021-07-09 16:52:21,947 [run_pretraining.py:  512]:	********exe.run_300******* 
[INFO] 2021-07-09 16:52:24,170 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:24,170 [run_pretraining.py:  534]:	loss/total_loss, 4.73975944519043, 301
[INFO] 2021-07-09 16:52:24,170 [run_pretraining.py:  535]:	loss/mlm_loss, 4.73975944519043, 301
[INFO] 2021-07-09 16:52:24,171 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9999998787388904e-06, 301
[INFO] 2021-07-09 16:52:24,171 [run_pretraining.py:  539]:	lr/loss_scaling, 1801.4404296875, 301
[INFO] 2021-07-09 16:52:24,171 [run_pretraining.py:  558]:	worker_index: 6, step: 301, cost: 4.739759, mlm loss: 4.739759, speed: 0.449852 steps/s, speed: 3.598813 samples/s, speed: 1842.592019 tokens/s, learning rate: 3.000e-06, loss_scalings: 1801.440430, pp_loss: 4.749179
[INFO] 2021-07-09 16:52:24,171 [run_pretraining.py:  512]:	********exe.run_301******* 
[INFO] 2021-07-09 16:52:26,466 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:26,467 [run_pretraining.py:  534]:	loss/total_loss, 4.718324184417725, 302
[INFO] 2021-07-09 16:52:26,467 [run_pretraining.py:  535]:	loss/mlm_loss, 4.718324184417725, 302
[INFO] 2021-07-09 16:52:26,467 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.0099997729848837e-06, 302
[INFO] 2021-07-09 16:52:26,467 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 302
[INFO] 2021-07-09 16:52:26,467 [run_pretraining.py:  558]:	worker_index: 6, step: 302, cost: 4.718324, mlm loss: 4.718324, speed: 0.435639 steps/s, speed: 3.485112 samples/s, speed: 1784.377354 tokens/s, learning rate: 3.010e-06, loss_scalings: 1441.152344, pp_loss: 4.742943
[INFO] 2021-07-09 16:52:26,467 [run_pretraining.py:  512]:	********exe.run_302******* 
[INFO] 2021-07-09 16:52:28,706 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:28,706 [run_pretraining.py:  534]:	loss/total_loss, 4.67075252532959, 303
[INFO] 2021-07-09 16:52:28,706 [run_pretraining.py:  535]:	loss/mlm_loss, 4.67075252532959, 303
[INFO] 2021-07-09 16:52:28,706 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.020000121978228e-06, 303
[INFO] 2021-07-09 16:52:28,706 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 303
[INFO] 2021-07-09 16:52:28,707 [run_pretraining.py:  558]:	worker_index: 6, step: 303, cost: 4.670753, mlm loss: 4.670753, speed: 0.446632 steps/s, speed: 3.573056 samples/s, speed: 1829.404611 tokens/s, learning rate: 3.020e-06, loss_scalings: 1441.152344, pp_loss: 4.700833
[INFO] 2021-07-09 16:52:28,707 [run_pretraining.py:  512]:	********exe.run_303******* 
[INFO] 2021-07-09 16:52:30,931 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:30,932 [run_pretraining.py:  534]:	loss/total_loss, 4.777975559234619, 304
[INFO] 2021-07-09 16:52:30,932 [run_pretraining.py:  535]:	loss/mlm_loss, 4.777975559234619, 304
[INFO] 2021-07-09 16:52:30,932 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.0300000162242213e-06, 304
[INFO] 2021-07-09 16:52:30,932 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 304
[INFO] 2021-07-09 16:52:30,932 [run_pretraining.py:  558]:	worker_index: 6, step: 304, cost: 4.777976, mlm loss: 4.777976, speed: 0.449399 steps/s, speed: 3.595189 samples/s, speed: 1840.736821 tokens/s, learning rate: 3.030e-06, loss_scalings: 1441.152344, pp_loss: 4.718576
[INFO] 2021-07-09 16:52:30,933 [run_pretraining.py:  512]:	********exe.run_304******* 
[INFO] 2021-07-09 16:52:33,192 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:33,192 [run_pretraining.py:  534]:	loss/total_loss, 4.6433491706848145, 305
[INFO] 2021-07-09 16:52:33,193 [run_pretraining.py:  535]:	loss/mlm_loss, 4.6433491706848145, 305
[INFO] 2021-07-09 16:52:33,193 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.0399999104702147e-06, 305
[INFO] 2021-07-09 16:52:33,193 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 305
[INFO] 2021-07-09 16:52:33,193 [run_pretraining.py:  558]:	worker_index: 6, step: 305, cost: 4.643349, mlm loss: 4.643349, speed: 0.442532 steps/s, speed: 3.540256 samples/s, speed: 1812.611014 tokens/s, learning rate: 3.040e-06, loss_scalings: 1441.152344, pp_loss: 4.689627
[INFO] 2021-07-09 16:52:33,193 [run_pretraining.py:  512]:	********exe.run_305******* 
[INFO] 2021-07-09 16:52:35,391 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:35,391 [run_pretraining.py:  534]:	loss/total_loss, 4.659366607666016, 306
[INFO] 2021-07-09 16:52:35,392 [run_pretraining.py:  535]:	loss/mlm_loss, 4.659366607666016, 306
[INFO] 2021-07-09 16:52:35,392 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.0500000320898835e-06, 306
[INFO] 2021-07-09 16:52:35,392 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 306
[INFO] 2021-07-09 16:52:35,392 [run_pretraining.py:  558]:	worker_index: 6, step: 306, cost: 4.659367, mlm loss: 4.659367, speed: 0.454898 steps/s, speed: 3.639182 samples/s, speed: 1863.261303 tokens/s, learning rate: 3.050e-06, loss_scalings: 1441.152344, pp_loss: 4.703804
[INFO] 2021-07-09 16:52:35,392 [run_pretraining.py:  512]:	********exe.run_306******* 
[INFO] 2021-07-09 16:52:37,595 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:37,596 [run_pretraining.py:  534]:	loss/total_loss, 4.691987037658691, 307
[INFO] 2021-07-09 16:52:37,596 [run_pretraining.py:  535]:	loss/mlm_loss, 4.691987037658691, 307
[INFO] 2021-07-09 16:52:37,596 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.059999926335877e-06, 307
[INFO] 2021-07-09 16:52:37,596 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 307
[INFO] 2021-07-09 16:52:37,596 [run_pretraining.py:  558]:	worker_index: 6, step: 307, cost: 4.691987, mlm loss: 4.691987, speed: 0.453791 steps/s, speed: 3.630331 samples/s, speed: 1858.729347 tokens/s, learning rate: 3.060e-06, loss_scalings: 1441.152344, pp_loss: 4.683786
[INFO] 2021-07-09 16:52:37,596 [run_pretraining.py:  512]:	********exe.run_307******* 
[INFO] 2021-07-09 16:52:39,781 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:39,782 [run_pretraining.py:  534]:	loss/total_loss, 4.651942729949951, 308
[INFO] 2021-07-09 16:52:39,782 [run_pretraining.py:  535]:	loss/mlm_loss, 4.651942729949951, 308
[INFO] 2021-07-09 16:52:39,782 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.06999982058187e-06, 308
[INFO] 2021-07-09 16:52:39,782 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 308
[INFO] 2021-07-09 16:52:39,782 [run_pretraining.py:  558]:	worker_index: 6, step: 308, cost: 4.651943, mlm loss: 4.651943, speed: 0.457648 steps/s, speed: 3.661185 samples/s, speed: 1874.526570 tokens/s, learning rate: 3.070e-06, loss_scalings: 1441.152344, pp_loss: 4.643873
[INFO] 2021-07-09 16:52:39,782 [run_pretraining.py:  512]:	********exe.run_308******* 
[INFO] 2021-07-09 16:52:42,009 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:42,010 [run_pretraining.py:  534]:	loss/total_loss, 4.625606536865234, 309
[INFO] 2021-07-09 16:52:42,010 [run_pretraining.py:  535]:	loss/mlm_loss, 4.625606536865234, 309
[INFO] 2021-07-09 16:52:42,010 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.079999942201539e-06, 309
[INFO] 2021-07-09 16:52:42,010 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 309
[INFO] 2021-07-09 16:52:42,010 [run_pretraining.py:  558]:	worker_index: 6, step: 309, cost: 4.625607, mlm loss: 4.625607, speed: 0.448883 steps/s, speed: 3.591064 samples/s, speed: 1838.624594 tokens/s, learning rate: 3.080e-06, loss_scalings: 1441.152344, pp_loss: 4.659072
[INFO] 2021-07-09 16:52:42,010 [run_pretraining.py:  512]:	********exe.run_309******* 
[INFO] 2021-07-09 16:52:44,241 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:44,242 [run_pretraining.py:  534]:	loss/total_loss, 4.651130676269531, 310
[INFO] 2021-07-09 16:52:44,242 [run_pretraining.py:  535]:	loss/mlm_loss, 4.651130676269531, 310
[INFO] 2021-07-09 16:52:44,242 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.0899998364475323e-06, 310
[INFO] 2021-07-09 16:52:44,242 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 310
[INFO] 2021-07-09 16:52:44,242 [run_pretraining.py:  558]:	worker_index: 6, step: 310, cost: 4.651131, mlm loss: 4.651131, speed: 0.448148 steps/s, speed: 3.585180 samples/s, speed: 1835.612215 tokens/s, learning rate: 3.090e-06, loss_scalings: 1441.152344, pp_loss: 4.620205
[INFO] 2021-07-09 16:52:44,243 [run_pretraining.py:  512]:	********exe.run_310******* 
[INFO] 2021-07-09 16:52:46,563 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:46,563 [run_pretraining.py:  534]:	loss/total_loss, 4.552722930908203, 311
[INFO] 2021-07-09 16:52:46,563 [run_pretraining.py:  535]:	loss/mlm_loss, 4.552722930908203, 311
[INFO] 2021-07-09 16:52:46,564 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.099999958067201e-06, 311
[INFO] 2021-07-09 16:52:46,564 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 311
[INFO] 2021-07-09 16:52:46,564 [run_pretraining.py:  558]:	worker_index: 6, step: 311, cost: 4.552723, mlm loss: 4.552723, speed: 0.430937 steps/s, speed: 3.447497 samples/s, speed: 1765.118223 tokens/s, learning rate: 3.100e-06, loss_scalings: 1441.152344, pp_loss: 4.555237
[INFO] 2021-07-09 16:52:46,564 [run_pretraining.py:  512]:	********exe.run_311******* 
[INFO] 2021-07-09 16:52:48,879 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:48,880 [run_pretraining.py:  534]:	loss/total_loss, 4.481520652770996, 312
[INFO] 2021-07-09 16:52:48,880 [run_pretraining.py:  535]:	loss/mlm_loss, 4.481520652770996, 312
[INFO] 2021-07-09 16:52:48,880 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.1099998523131944e-06, 312
[INFO] 2021-07-09 16:52:48,880 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 312
[INFO] 2021-07-09 16:52:48,880 [run_pretraining.py:  558]:	worker_index: 6, step: 312, cost: 4.481521, mlm loss: 4.481521, speed: 0.431777 steps/s, speed: 3.454213 samples/s, speed: 1768.557220 tokens/s, learning rate: 3.110e-06, loss_scalings: 1441.152344, pp_loss: 4.546920
[INFO] 2021-07-09 16:52:48,881 [run_pretraining.py:  512]:	********exe.run_312******* 
[INFO] 2021-07-09 16:52:51,092 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:51,093 [run_pretraining.py:  534]:	loss/total_loss, 4.49041748046875, 313
[INFO] 2021-07-09 16:52:51,093 [run_pretraining.py:  535]:	loss/mlm_loss, 4.49041748046875, 313
[INFO] 2021-07-09 16:52:51,093 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.1199997465591878e-06, 313
[INFO] 2021-07-09 16:52:51,093 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 313
[INFO] 2021-07-09 16:52:51,093 [run_pretraining.py:  558]:	worker_index: 6, step: 313, cost: 4.490417, mlm loss: 4.490417, speed: 0.452037 steps/s, speed: 3.616298 samples/s, speed: 1851.544368 tokens/s, learning rate: 3.120e-06, loss_scalings: 1441.152344, pp_loss: 4.451558
[INFO] 2021-07-09 16:52:51,093 [run_pretraining.py:  512]:	********exe.run_313******* 
[INFO] 2021-07-09 16:52:53,311 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:53,312 [run_pretraining.py:  534]:	loss/total_loss, 4.294816970825195, 314
[INFO] 2021-07-09 16:52:53,312 [run_pretraining.py:  535]:	loss/mlm_loss, 4.294816970825195, 314
[INFO] 2021-07-09 16:52:53,312 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.130000095552532e-06, 314
[INFO] 2021-07-09 16:52:53,312 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 314
[INFO] 2021-07-09 16:52:53,312 [run_pretraining.py:  558]:	worker_index: 6, step: 314, cost: 4.294817, mlm loss: 4.294817, speed: 0.450865 steps/s, speed: 3.606919 samples/s, speed: 1846.742349 tokens/s, learning rate: 3.130e-06, loss_scalings: 1441.152344, pp_loss: 4.315289
[INFO] 2021-07-09 16:52:53,312 [run_pretraining.py:  512]:	********exe.run_314******* 
[INFO] 2021-07-09 16:52:55,555 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:55,556 [run_pretraining.py:  534]:	loss/total_loss, 4.265635013580322, 315
[INFO] 2021-07-09 16:52:55,556 [run_pretraining.py:  535]:	loss/mlm_loss, 4.265635013580322, 315
[INFO] 2021-07-09 16:52:55,556 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.13999976242485e-06, 315
[INFO] 2021-07-09 16:52:55,556 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 315
[INFO] 2021-07-09 16:52:55,556 [run_pretraining.py:  558]:	worker_index: 6, step: 315, cost: 4.265635, mlm loss: 4.265635, speed: 0.445722 steps/s, speed: 3.565778 samples/s, speed: 1825.678392 tokens/s, learning rate: 3.140e-06, loss_scalings: 1441.152344, pp_loss: 4.244973
[INFO] 2021-07-09 16:52:55,556 [run_pretraining.py:  512]:	********exe.run_315******* 
[INFO] 2021-07-09 16:52:57,780 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:57,781 [run_pretraining.py:  534]:	loss/total_loss, 4.148573398590088, 316
[INFO] 2021-07-09 16:52:57,781 [run_pretraining.py:  535]:	loss/mlm_loss, 4.148573398590088, 316
[INFO] 2021-07-09 16:52:57,781 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.1499998840445187e-06, 316
[INFO] 2021-07-09 16:52:57,781 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 316
[INFO] 2021-07-09 16:52:57,781 [run_pretraining.py:  558]:	worker_index: 6, step: 316, cost: 4.148573, mlm loss: 4.148573, speed: 0.449643 steps/s, speed: 3.597145 samples/s, speed: 1841.738287 tokens/s, learning rate: 3.150e-06, loss_scalings: 1441.152344, pp_loss: 4.166915
[INFO] 2021-07-09 16:52:57,781 [run_pretraining.py:  512]:	********exe.run_316******* 
[INFO] 2021-07-09 16:52:59,987 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:59,988 [run_pretraining.py:  534]:	loss/total_loss, 4.1092095375061035, 317
[INFO] 2021-07-09 16:52:59,988 [run_pretraining.py:  535]:	loss/mlm_loss, 4.1092095375061035, 317
[INFO] 2021-07-09 16:52:59,988 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.159999778290512e-06, 317
[INFO] 2021-07-09 16:52:59,988 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 317
[INFO] 2021-07-09 16:52:59,988 [run_pretraining.py:  558]:	worker_index: 6, step: 317, cost: 4.109210, mlm loss: 4.109210, speed: 0.453203 steps/s, speed: 3.625621 samples/s, speed: 1856.317870 tokens/s, learning rate: 3.160e-06, loss_scalings: 1441.152344, pp_loss: 4.079929
[INFO] 2021-07-09 16:52:59,988 [run_pretraining.py:  512]:	********exe.run_317******* 
[INFO] 2021-07-09 16:53:02,284 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:02,284 [run_pretraining.py:  534]:	loss/total_loss, 4.008336067199707, 318
[INFO] 2021-07-09 16:53:02,285 [run_pretraining.py:  535]:	loss/mlm_loss, 4.008336067199707, 318
[INFO] 2021-07-09 16:53:02,285 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.169999899910181e-06, 318
[INFO] 2021-07-09 16:53:02,285 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 318
[INFO] 2021-07-09 16:53:02,285 [run_pretraining.py:  558]:	worker_index: 6, step: 318, cost: 4.008336, mlm loss: 4.008336, speed: 0.435543 steps/s, speed: 3.484344 samples/s, speed: 1783.984349 tokens/s, learning rate: 3.170e-06, loss_scalings: 1441.152344, pp_loss: 4.037333
[INFO] 2021-07-09 16:53:02,285 [run_pretraining.py:  512]:	********exe.run_318******* 
[INFO] 2021-07-09 16:53:04,637 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:04,638 [run_pretraining.py:  534]:	loss/total_loss, 4.0389509201049805, 319
[INFO] 2021-07-09 16:53:04,638 [run_pretraining.py:  535]:	loss/mlm_loss, 4.0389509201049805, 319
[INFO] 2021-07-09 16:53:04,638 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.1800000215298496e-06, 319
[INFO] 2021-07-09 16:53:04,638 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 319
[INFO] 2021-07-09 16:53:04,638 [run_pretraining.py:  558]:	worker_index: 6, step: 319, cost: 4.038951, mlm loss: 4.038951, speed: 0.424993 steps/s, speed: 3.399947 samples/s, speed: 1740.772763 tokens/s, learning rate: 3.180e-06, loss_scalings: 1441.152344, pp_loss: 3.990695
[INFO] 2021-07-09 16:53:04,639 [run_pretraining.py:  512]:	********exe.run_319******* 
[INFO] 2021-07-09 16:53:06,849 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:06,850 [run_pretraining.py:  534]:	loss/total_loss, 4.021206855773926, 320
[INFO] 2021-07-09 16:53:06,850 [run_pretraining.py:  535]:	loss/mlm_loss, 4.021206855773926, 320
[INFO] 2021-07-09 16:53:06,850 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.189999915775843e-06, 320
[INFO] 2021-07-09 16:53:06,850 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 320
[INFO] 2021-07-09 16:53:06,850 [run_pretraining.py:  558]:	worker_index: 6, step: 320, cost: 4.021207, mlm loss: 4.021207, speed: 0.452221 steps/s, speed: 3.617771 samples/s, speed: 1852.298570 tokens/s, learning rate: 3.190e-06, loss_scalings: 1441.152344, pp_loss: 3.965143
[INFO] 2021-07-09 16:53:06,850 [run_pretraining.py:  512]:	********exe.run_320******* 
[INFO] 2021-07-09 16:53:09,069 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:09,069 [run_pretraining.py:  534]:	loss/total_loss, 3.893756866455078, 321
[INFO] 2021-07-09 16:53:09,070 [run_pretraining.py:  535]:	loss/mlm_loss, 3.893756866455078, 321
[INFO] 2021-07-09 16:53:09,070 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.2000000373955118e-06, 321
[INFO] 2021-07-09 16:53:09,070 [run_pretraining.py:  539]:	lr/loss_scaling, 1152.921875, 321
[INFO] 2021-07-09 16:53:09,070 [run_pretraining.py:  558]:	worker_index: 6, step: 321, cost: 3.893757, mlm loss: 3.893757, speed: 0.450710 steps/s, speed: 3.605676 samples/s, speed: 1846.106328 tokens/s, learning rate: 3.200e-06, loss_scalings: 1152.921875, pp_loss: 3.892416
[INFO] 2021-07-09 16:53:09,070 [run_pretraining.py:  512]:	********exe.run_321******* 
[INFO] 2021-07-09 16:53:11,321 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:11,322 [run_pretraining.py:  534]:	loss/total_loss, 3.8247246742248535, 322
[INFO] 2021-07-09 16:53:11,322 [run_pretraining.py:  535]:	loss/mlm_loss, 3.8247246742248535, 322
[INFO] 2021-07-09 16:53:11,322 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.209999931641505e-06, 322
[INFO] 2021-07-09 16:53:11,322 [run_pretraining.py:  539]:	lr/loss_scaling, 1152.921875, 322
[INFO] 2021-07-09 16:53:11,322 [run_pretraining.py:  558]:	worker_index: 6, step: 322, cost: 3.824725, mlm loss: 3.824725, speed: 0.444143 steps/s, speed: 3.553142 samples/s, speed: 1819.208787 tokens/s, learning rate: 3.210e-06, loss_scalings: 1152.921875, pp_loss: 3.848527
[INFO] 2021-07-09 16:53:11,322 [run_pretraining.py:  512]:	********exe.run_322******* 
[INFO] 2021-07-09 16:53:13,566 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:13,567 [run_pretraining.py:  534]:	loss/total_loss, 3.8053274154663086, 323
[INFO] 2021-07-09 16:53:13,567 [run_pretraining.py:  535]:	loss/mlm_loss, 3.8053274154663086, 323
[INFO] 2021-07-09 16:53:13,567 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.220000053261174e-06, 323
[INFO] 2021-07-09 16:53:13,567 [run_pretraining.py:  539]:	lr/loss_scaling, 1152.921875, 323
[INFO] 2021-07-09 16:53:13,567 [run_pretraining.py:  558]:	worker_index: 6, step: 323, cost: 3.805327, mlm loss: 3.805327, speed: 0.445500 steps/s, speed: 3.564001 samples/s, speed: 1824.768735 tokens/s, learning rate: 3.220e-06, loss_scalings: 1152.921875, pp_loss: 3.824615
[INFO] 2021-07-09 16:53:13,568 [run_pretraining.py:  512]:	********exe.run_323******* 
[INFO] 2021-07-09 16:53:15,818 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:15,818 [run_pretraining.py:  534]:	loss/total_loss, 3.8568687438964844, 324
[INFO] 2021-07-09 16:53:15,818 [run_pretraining.py:  535]:	loss/mlm_loss, 3.8568687438964844, 324
[INFO] 2021-07-09 16:53:15,818 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.229999720133492e-06, 324
[INFO] 2021-07-09 16:53:15,819 [run_pretraining.py:  539]:	lr/loss_scaling, 1152.921875, 324
[INFO] 2021-07-09 16:53:15,819 [run_pretraining.py:  558]:	worker_index: 6, step: 324, cost: 3.856869, mlm loss: 3.856869, speed: 0.444353 steps/s, speed: 3.554827 samples/s, speed: 1820.071643 tokens/s, learning rate: 3.230e-06, loss_scalings: 1152.921875, pp_loss: 3.823146
[INFO] 2021-07-09 16:53:15,819 [run_pretraining.py:  512]:	********exe.run_324******* 
[INFO] 2021-07-09 16:53:18,112 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:18,113 [run_pretraining.py:  534]:	loss/total_loss, 3.7882347106933594, 325
[INFO] 2021-07-09 16:53:18,113 [run_pretraining.py:  535]:	loss/mlm_loss, 3.7882347106933594, 325
[INFO] 2021-07-09 16:53:18,113 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.240000069126836e-06, 325
[INFO] 2021-07-09 16:53:18,113 [run_pretraining.py:  539]:	lr/loss_scaling, 1152.921875, 325
[INFO] 2021-07-09 16:53:18,113 [run_pretraining.py:  558]:	worker_index: 6, step: 325, cost: 3.788235, mlm loss: 3.788235, speed: 0.435994 steps/s, speed: 3.487950 samples/s, speed: 1785.830438 tokens/s, learning rate: 3.240e-06, loss_scalings: 1152.921875, pp_loss: 3.798756
[INFO] 2021-07-09 16:53:18,113 [run_pretraining.py:  512]:	********exe.run_325******* 
[INFO] 2021-07-09 16:53:20,304 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:20,305 [run_pretraining.py:  534]:	loss/total_loss, 3.8388562202453613, 326
[INFO] 2021-07-09 16:53:20,305 [run_pretraining.py:  535]:	loss/mlm_loss, 3.8388562202453613, 326
[INFO] 2021-07-09 16:53:20,305 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.249999735999154e-06, 326
[INFO] 2021-07-09 16:53:20,305 [run_pretraining.py:  539]:	lr/loss_scaling, 1152.921875, 326
[INFO] 2021-07-09 16:53:20,305 [run_pretraining.py:  558]:	worker_index: 6, step: 326, cost: 3.838856, mlm loss: 3.838856, speed: 0.456332 steps/s, speed: 3.650656 samples/s, speed: 1869.136105 tokens/s, learning rate: 3.250e-06, loss_scalings: 1152.921875, pp_loss: 3.846193
[INFO] 2021-07-09 16:53:20,305 [run_pretraining.py:  512]:	********exe.run_326******* 
[INFO] 2021-07-09 16:53:22,496 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:22,497 [run_pretraining.py:  534]:	loss/total_loss, 3.821378231048584, 327
[INFO] 2021-07-09 16:53:22,497 [run_pretraining.py:  535]:	loss/mlm_loss, 3.821378231048584, 327
[INFO] 2021-07-09 16:53:22,497 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.2599998576188227e-06, 327
[INFO] 2021-07-09 16:53:22,497 [run_pretraining.py:  539]:	lr/loss_scaling, 1152.921875, 327
[INFO] 2021-07-09 16:53:22,497 [run_pretraining.py:  558]:	worker_index: 6, step: 327, cost: 3.821378, mlm loss: 3.821378, speed: 0.456347 steps/s, speed: 3.650772 samples/s, speed: 1869.195284 tokens/s, learning rate: 3.260e-06, loss_scalings: 1152.921875, pp_loss: 3.855046
[INFO] 2021-07-09 16:53:22,497 [run_pretraining.py:  512]:	********exe.run_327******* 
[INFO] 2021-07-09 16:53:24,763 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:24,764 [run_pretraining.py:  534]:	loss/total_loss, 3.8536360263824463, 328
[INFO] 2021-07-09 16:53:24,764 [run_pretraining.py:  535]:	loss/mlm_loss, 3.8536360263824463, 328
[INFO] 2021-07-09 16:53:24,764 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.269999751864816e-06, 328
[INFO] 2021-07-09 16:53:24,764 [run_pretraining.py:  539]:	lr/loss_scaling, 1152.921875, 328
[INFO] 2021-07-09 16:53:24,764 [run_pretraining.py:  558]:	worker_index: 6, step: 328, cost: 3.853636, mlm loss: 3.853636, speed: 0.441177 steps/s, speed: 3.529414 samples/s, speed: 1807.060167 tokens/s, learning rate: 3.270e-06, loss_scalings: 1152.921875, pp_loss: 3.872968
[INFO] 2021-07-09 16:53:24,764 [run_pretraining.py:  512]:	********exe.run_328******* 
[INFO] 2021-07-09 16:53:26,985 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:26,986 [run_pretraining.py:  534]:	loss/total_loss, 3.888543128967285, 329
[INFO] 2021-07-09 16:53:26,986 [run_pretraining.py:  535]:	loss/mlm_loss, 3.888543128967285, 329
[INFO] 2021-07-09 16:53:26,986 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.279999873484485e-06, 329
[INFO] 2021-07-09 16:53:26,986 [run_pretraining.py:  539]:	lr/loss_scaling, 1152.921875, 329
[INFO] 2021-07-09 16:53:26,986 [run_pretraining.py:  558]:	worker_index: 6, step: 329, cost: 3.888543, mlm loss: 3.888543, speed: 0.450275 steps/s, speed: 3.602202 samples/s, speed: 1844.327205 tokens/s, learning rate: 3.280e-06, loss_scalings: 1152.921875, pp_loss: 3.947630
[INFO] 2021-07-09 16:53:26,986 [run_pretraining.py:  512]:	********exe.run_329******* 
[INFO] 2021-07-09 16:53:29,225 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:29,226 [run_pretraining.py:  534]:	loss/total_loss, 3.9297664165496826, 330
[INFO] 2021-07-09 16:53:29,226 [run_pretraining.py:  535]:	loss/mlm_loss, 3.9297664165496826, 330
[INFO] 2021-07-09 16:53:29,226 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.2899999951041536e-06, 330
[INFO] 2021-07-09 16:53:29,226 [run_pretraining.py:  539]:	lr/loss_scaling, 1152.921875, 330
[INFO] 2021-07-09 16:53:29,226 [run_pretraining.py:  558]:	worker_index: 6, step: 330, cost: 3.929766, mlm loss: 3.929766, speed: 0.446496 steps/s, speed: 3.571971 samples/s, speed: 1828.849002 tokens/s, learning rate: 3.290e-06, loss_scalings: 1152.921875, pp_loss: 3.962097
[INFO] 2021-07-09 16:53:29,226 [run_pretraining.py:  512]:	********exe.run_330******* 
[INFO] 2021-07-09 16:53:31,441 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:31,442 [run_pretraining.py:  534]:	loss/total_loss, 3.9973769187927246, 331
[INFO] 2021-07-09 16:53:31,442 [run_pretraining.py:  535]:	loss/mlm_loss, 3.9973769187927246, 331
[INFO] 2021-07-09 16:53:31,442 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.299999889350147e-06, 331
[INFO] 2021-07-09 16:53:31,442 [run_pretraining.py:  539]:	lr/loss_scaling, 922.3375244140625, 331
[INFO] 2021-07-09 16:53:31,442 [run_pretraining.py:  558]:	worker_index: 6, step: 331, cost: 3.997377, mlm loss: 3.997377, speed: 0.451428 steps/s, speed: 3.611423 samples/s, speed: 1849.048791 tokens/s, learning rate: 3.300e-06, loss_scalings: 922.337524, pp_loss: 4.056290
[INFO] 2021-07-09 16:53:31,442 [run_pretraining.py:  512]:	********exe.run_331******* 
[INFO] 2021-07-09 16:53:34,000 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:34,001 [run_pretraining.py:  534]:	loss/total_loss, 4.032772541046143, 332
[INFO] 2021-07-09 16:53:34,001 [run_pretraining.py:  535]:	loss/mlm_loss, 4.032772541046143, 332
[INFO] 2021-07-09 16:53:34,001 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.3100000109698158e-06, 332
[INFO] 2021-07-09 16:53:34,001 [run_pretraining.py:  539]:	lr/loss_scaling, 922.3375244140625, 332
[INFO] 2021-07-09 16:53:34,001 [run_pretraining.py:  558]:	worker_index: 6, step: 332, cost: 4.032773, mlm loss: 4.032773, speed: 0.390851 steps/s, speed: 3.126810 samples/s, speed: 1600.926829 tokens/s, learning rate: 3.310e-06, loss_scalings: 922.337524, pp_loss: 4.096579
[INFO] 2021-07-09 16:53:34,001 [run_pretraining.py:  512]:	********exe.run_332******* 
[INFO] 2021-07-09 16:53:36,213 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:36,214 [run_pretraining.py:  534]:	loss/total_loss, 4.102575778961182, 333
[INFO] 2021-07-09 16:53:36,214 [run_pretraining.py:  535]:	loss/mlm_loss, 4.102575778961182, 333
[INFO] 2021-07-09 16:53:36,214 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.319999905215809e-06, 333
[INFO] 2021-07-09 16:53:36,214 [run_pretraining.py:  539]:	lr/loss_scaling, 737.8700561523438, 333
[INFO] 2021-07-09 16:53:36,214 [run_pretraining.py:  558]:	worker_index: 6, step: 333, cost: 4.102576, mlm loss: 4.102576, speed: 0.452064 steps/s, speed: 3.616510 samples/s, speed: 1851.652929 tokens/s, learning rate: 3.320e-06, loss_scalings: 737.870056, pp_loss: 4.149417
[INFO] 2021-07-09 16:53:36,214 [run_pretraining.py:  512]:	********exe.run_333******* 
[INFO] 2021-07-09 16:53:38,470 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:38,470 [run_pretraining.py:  534]:	loss/total_loss, 4.315168380737305, 334
[INFO] 2021-07-09 16:53:38,470 [run_pretraining.py:  535]:	loss/mlm_loss, 4.315168380737305, 334
[INFO] 2021-07-09 16:53:38,470 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.330000026835478e-06, 334
[INFO] 2021-07-09 16:53:38,471 [run_pretraining.py:  539]:	lr/loss_scaling, 737.8700561523438, 334
[INFO] 2021-07-09 16:53:38,471 [run_pretraining.py:  558]:	worker_index: 6, step: 334, cost: 4.315168, mlm loss: 4.315168, speed: 0.443293 steps/s, speed: 3.546346 samples/s, speed: 1815.729259 tokens/s, learning rate: 3.330e-06, loss_scalings: 737.870056, pp_loss: 4.220446
[INFO] 2021-07-09 16:53:38,471 [run_pretraining.py:  512]:	********exe.run_334******* 
[INFO] 2021-07-09 16:53:40,741 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:40,742 [run_pretraining.py:  534]:	loss/total_loss, 4.272541522979736, 335
[INFO] 2021-07-09 16:53:40,742 [run_pretraining.py:  535]:	loss/mlm_loss, 4.272541522979736, 335
[INFO] 2021-07-09 16:53:40,742 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.3399999210814713e-06, 335
[INFO] 2021-07-09 16:53:40,742 [run_pretraining.py:  539]:	lr/loss_scaling, 737.8700561523438, 335
[INFO] 2021-07-09 16:53:40,742 [run_pretraining.py:  558]:	worker_index: 6, step: 335, cost: 4.272542, mlm loss: 4.272542, speed: 0.440381 steps/s, speed: 3.523047 samples/s, speed: 1803.799808 tokens/s, learning rate: 3.340e-06, loss_scalings: 737.870056, pp_loss: 4.263879
[INFO] 2021-07-09 16:53:40,742 [run_pretraining.py:  512]:	********exe.run_335******* 
[INFO] 2021-07-09 16:53:43,044 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:43,045 [run_pretraining.py:  534]:	loss/total_loss, 4.307901859283447, 336
[INFO] 2021-07-09 16:53:43,045 [run_pretraining.py:  535]:	loss/mlm_loss, 4.307901859283447, 336
[INFO] 2021-07-09 16:53:43,045 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.35000004270114e-06, 336
[INFO] 2021-07-09 16:53:43,045 [run_pretraining.py:  539]:	lr/loss_scaling, 590.2960815429688, 336
[INFO] 2021-07-09 16:53:43,045 [run_pretraining.py:  558]:	worker_index: 6, step: 336, cost: 4.307902, mlm loss: 4.307902, speed: 0.434383 steps/s, speed: 3.475067 samples/s, speed: 1779.234394 tokens/s, learning rate: 3.350e-06, loss_scalings: 590.296082, pp_loss: 4.313100
[INFO] 2021-07-09 16:53:43,045 [run_pretraining.py:  512]:	********exe.run_336******* 
[INFO] 2021-07-09 16:53:45,307 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:45,308 [run_pretraining.py:  534]:	loss/total_loss, 4.368562698364258, 337
[INFO] 2021-07-09 16:53:45,308 [run_pretraining.py:  535]:	loss/mlm_loss, 4.368562698364258, 337
[INFO] 2021-07-09 16:53:45,308 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.359999709573458e-06, 337
[INFO] 2021-07-09 16:53:45,308 [run_pretraining.py:  539]:	lr/loss_scaling, 590.2960815429688, 337
[INFO] 2021-07-09 16:53:45,308 [run_pretraining.py:  558]:	worker_index: 6, step: 337, cost: 4.368563, mlm loss: 4.368563, speed: 0.442015 steps/s, speed: 3.536123 samples/s, speed: 1810.495069 tokens/s, learning rate: 3.360e-06, loss_scalings: 590.296082, pp_loss: 4.337090
[INFO] 2021-07-09 16:53:45,308 [run_pretraining.py:  512]:	********exe.run_337******* 
[INFO] 2021-07-09 16:53:47,635 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:47,636 [run_pretraining.py:  534]:	loss/total_loss, 4.297643661499023, 338
[INFO] 2021-07-09 16:53:47,636 [run_pretraining.py:  535]:	loss/mlm_loss, 4.297643661499023, 338
[INFO] 2021-07-09 16:53:47,636 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.370000058566802e-06, 338
[INFO] 2021-07-09 16:53:47,636 [run_pretraining.py:  539]:	lr/loss_scaling, 590.2960815429688, 338
[INFO] 2021-07-09 16:53:47,636 [run_pretraining.py:  558]:	worker_index: 6, step: 338, cost: 4.297644, mlm loss: 4.297644, speed: 0.429611 steps/s, speed: 3.436889 samples/s, speed: 1759.687104 tokens/s, learning rate: 3.370e-06, loss_scalings: 590.296082, pp_loss: 4.383961
[INFO] 2021-07-09 16:53:47,636 [run_pretraining.py:  512]:	********exe.run_338******* 
[INFO] 2021-07-09 16:53:50,092 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:50,092 [run_pretraining.py:  534]:	loss/total_loss, 4.424167156219482, 339
[INFO] 2021-07-09 16:53:50,092 [run_pretraining.py:  535]:	loss/mlm_loss, 4.424167156219482, 339
[INFO] 2021-07-09 16:53:50,093 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.37999972543912e-06, 339
[INFO] 2021-07-09 16:53:50,093 [run_pretraining.py:  539]:	lr/loss_scaling, 590.2960815429688, 339
[INFO] 2021-07-09 16:53:50,093 [run_pretraining.py:  558]:	worker_index: 6, step: 339, cost: 4.424167, mlm loss: 4.424167, speed: 0.407221 steps/s, speed: 3.257769 samples/s, speed: 1667.977937 tokens/s, learning rate: 3.380e-06, loss_scalings: 590.296082, pp_loss: 4.410190
[INFO] 2021-07-09 16:53:50,093 [run_pretraining.py:  512]:	********exe.run_339******* 
[INFO] 2021-07-09 16:53:52,334 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:52,334 [run_pretraining.py:  534]:	loss/total_loss, 4.457285404205322, 340
[INFO] 2021-07-09 16:53:52,335 [run_pretraining.py:  535]:	loss/mlm_loss, 4.457285404205322, 340
[INFO] 2021-07-09 16:53:52,335 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.389999847058789e-06, 340
[INFO] 2021-07-09 16:53:52,335 [run_pretraining.py:  539]:	lr/loss_scaling, 590.2960815429688, 340
[INFO] 2021-07-09 16:53:52,335 [run_pretraining.py:  558]:	worker_index: 6, step: 340, cost: 4.457285, mlm loss: 4.457285, speed: 0.446151 steps/s, speed: 3.569206 samples/s, speed: 1827.433365 tokens/s, learning rate: 3.390e-06, loss_scalings: 590.296082, pp_loss: 4.435232
[INFO] 2021-07-09 16:53:52,335 [run_pretraining.py:  512]:	********exe.run_340******* 
[INFO] 2021-07-09 16:53:54,547 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:54,547 [run_pretraining.py:  534]:	loss/total_loss, 4.389784812927246, 341
[INFO] 2021-07-09 16:53:54,547 [run_pretraining.py:  535]:	loss/mlm_loss, 4.389784812927246, 341
[INFO] 2021-07-09 16:53:54,548 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.400000196052133e-06, 341
[INFO] 2021-07-09 16:53:54,548 [run_pretraining.py:  539]:	lr/loss_scaling, 590.2960815429688, 341
[INFO] 2021-07-09 16:53:54,548 [run_pretraining.py:  558]:	worker_index: 6, step: 341, cost: 4.389785, mlm loss: 4.389785, speed: 0.452041 steps/s, speed: 3.616327 samples/s, speed: 1851.559534 tokens/s, learning rate: 3.400e-06, loss_scalings: 590.296082, pp_loss: 4.432686
[INFO] 2021-07-09 16:53:54,548 [run_pretraining.py:  512]:	********exe.run_341******* 
[INFO] 2021-07-09 16:53:56,897 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:56,897 [run_pretraining.py:  534]:	loss/total_loss, 4.389062404632568, 342
[INFO] 2021-07-09 16:53:56,897 [run_pretraining.py:  535]:	loss/mlm_loss, 4.389062404632568, 342
[INFO] 2021-07-09 16:53:56,898 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.409999862924451e-06, 342
[INFO] 2021-07-09 16:53:56,898 [run_pretraining.py:  539]:	lr/loss_scaling, 590.2960815429688, 342
[INFO] 2021-07-09 16:53:56,898 [run_pretraining.py:  558]:	worker_index: 6, step: 342, cost: 4.389062, mlm loss: 4.389062, speed: 0.425653 steps/s, speed: 3.405227 samples/s, speed: 1743.476015 tokens/s, learning rate: 3.410e-06, loss_scalings: 590.296082, pp_loss: 4.427926
[INFO] 2021-07-09 16:53:56,898 [run_pretraining.py:  512]:	********exe.run_342******* 
[INFO] 2021-07-09 16:53:59,212 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:59,212 [run_pretraining.py:  534]:	loss/total_loss, 4.394251346588135, 343
[INFO] 2021-07-09 16:53:59,213 [run_pretraining.py:  535]:	loss/mlm_loss, 4.394251346588135, 343
[INFO] 2021-07-09 16:53:59,213 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.41999998454412e-06, 343
[INFO] 2021-07-09 16:53:59,213 [run_pretraining.py:  539]:	lr/loss_scaling, 590.2960815429688, 343
[INFO] 2021-07-09 16:53:59,213 [run_pretraining.py:  558]:	worker_index: 6, step: 343, cost: 4.394251, mlm loss: 4.394251, speed: 0.432063 steps/s, speed: 3.456504 samples/s, speed: 1769.730293 tokens/s, learning rate: 3.420e-06, loss_scalings: 590.296082, pp_loss: 4.394741
[INFO] 2021-07-09 16:53:59,213 [run_pretraining.py:  512]:	********exe.run_343******* 
[INFO] 2021-07-09 16:54:01,645 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:01,645 [run_pretraining.py:  534]:	loss/total_loss, 4.343719005584717, 344
[INFO] 2021-07-09 16:54:01,646 [run_pretraining.py:  535]:	loss/mlm_loss, 4.343719005584717, 344
[INFO] 2021-07-09 16:54:01,646 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.429999878790113e-06, 344
[INFO] 2021-07-09 16:54:01,646 [run_pretraining.py:  539]:	lr/loss_scaling, 590.2960815429688, 344
[INFO] 2021-07-09 16:54:01,646 [run_pretraining.py:  558]:	worker_index: 6, step: 344, cost: 4.343719, mlm loss: 4.343719, speed: 0.411144 steps/s, speed: 3.289154 samples/s, speed: 1684.046642 tokens/s, learning rate: 3.430e-06, loss_scalings: 590.296082, pp_loss: 4.346924
[INFO] 2021-07-09 16:54:01,646 [run_pretraining.py:  512]:	********exe.run_344******* 
[INFO] 2021-07-09 16:54:04,182 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:04,183 [run_pretraining.py:  534]:	loss/total_loss, 4.351557731628418, 345
[INFO] 2021-07-09 16:54:04,183 [run_pretraining.py:  535]:	loss/mlm_loss, 4.351557731628418, 345
[INFO] 2021-07-09 16:54:04,183 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.440000000409782e-06, 345
[INFO] 2021-07-09 16:54:04,183 [run_pretraining.py:  539]:	lr/loss_scaling, 590.2960815429688, 345
[INFO] 2021-07-09 16:54:04,183 [run_pretraining.py:  558]:	worker_index: 6, step: 345, cost: 4.351558, mlm loss: 4.351558, speed: 0.394189 steps/s, speed: 3.153514 samples/s, speed: 1614.598979 tokens/s, learning rate: 3.440e-06, loss_scalings: 590.296082, pp_loss: 4.362994
[INFO] 2021-07-09 16:54:04,183 [run_pretraining.py:  512]:	********exe.run_345******* 
[INFO] 2021-07-09 16:54:06,897 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:06,898 [run_pretraining.py:  534]:	loss/total_loss, 4.392633438110352, 346
[INFO] 2021-07-09 16:54:06,898 [run_pretraining.py:  535]:	loss/mlm_loss, 4.392633438110352, 346
[INFO] 2021-07-09 16:54:06,898 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.4499998946557753e-06, 346
[INFO] 2021-07-09 16:54:06,898 [run_pretraining.py:  539]:	lr/loss_scaling, 590.2960815429688, 346
[INFO] 2021-07-09 16:54:06,898 [run_pretraining.py:  558]:	worker_index: 6, step: 346, cost: 4.392633, mlm loss: 4.392633, speed: 0.368452 steps/s, speed: 2.947618 samples/s, speed: 1509.180613 tokens/s, learning rate: 3.450e-06, loss_scalings: 590.296082, pp_loss: 4.376683
[INFO] 2021-07-09 16:54:06,898 [run_pretraining.py:  512]:	********exe.run_346******* 
[INFO] 2021-07-09 16:54:09,153 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:09,154 [run_pretraining.py:  534]:	loss/total_loss, 4.393529891967773, 347
[INFO] 2021-07-09 16:54:09,154 [run_pretraining.py:  535]:	loss/mlm_loss, 4.393529891967773, 347
[INFO] 2021-07-09 16:54:09,154 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.460000016275444e-06, 347
[INFO] 2021-07-09 16:54:09,154 [run_pretraining.py:  539]:	lr/loss_scaling, 590.2960815429688, 347
[INFO] 2021-07-09 16:54:09,154 [run_pretraining.py:  558]:	worker_index: 6, step: 347, cost: 4.393530, mlm loss: 4.393530, speed: 0.443419 steps/s, speed: 3.547356 samples/s, speed: 1816.246201 tokens/s, learning rate: 3.460e-06, loss_scalings: 590.296082, pp_loss: 4.393588
[INFO] 2021-07-09 16:54:09,154 [run_pretraining.py:  512]:	********exe.run_347******* 
[INFO] 2021-07-09 16:54:11,435 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:11,435 [run_pretraining.py:  534]:	loss/total_loss, 4.3384833335876465, 348
[INFO] 2021-07-09 16:54:11,435 [run_pretraining.py:  535]:	loss/mlm_loss, 4.3384833335876465, 348
[INFO] 2021-07-09 16:54:11,435 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.469999683147762e-06, 348
[INFO] 2021-07-09 16:54:11,436 [run_pretraining.py:  539]:	lr/loss_scaling, 590.2960815429688, 348
[INFO] 2021-07-09 16:54:11,436 [run_pretraining.py:  558]:	worker_index: 6, step: 348, cost: 4.338483, mlm loss: 4.338483, speed: 0.438402 steps/s, speed: 3.507220 samples/s, speed: 1795.696398 tokens/s, learning rate: 3.470e-06, loss_scalings: 590.296082, pp_loss: 4.358233
[INFO] 2021-07-09 16:54:11,436 [run_pretraining.py:  512]:	********exe.run_348******* 
[INFO] 2021-07-09 16:54:13,696 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:13,696 [run_pretraining.py:  534]:	loss/total_loss, 4.278388023376465, 349
[INFO] 2021-07-09 16:54:13,696 [run_pretraining.py:  535]:	loss/mlm_loss, 4.278388023376465, 349
[INFO] 2021-07-09 16:54:13,697 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.480000032141106e-06, 349
[INFO] 2021-07-09 16:54:13,697 [run_pretraining.py:  539]:	lr/loss_scaling, 472.23687744140625, 349
[INFO] 2021-07-09 16:54:13,697 [run_pretraining.py:  558]:	worker_index: 6, step: 349, cost: 4.278388, mlm loss: 4.278388, speed: 0.442411 steps/s, speed: 3.539290 samples/s, speed: 1812.116399 tokens/s, learning rate: 3.480e-06, loss_scalings: 472.236877, pp_loss: 4.310644
[INFO] 2021-07-09 16:54:13,697 [run_pretraining.py:  512]:	********exe.run_349******* 
[INFO] 2021-07-09 16:54:15,999 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:16,000 [run_pretraining.py:  534]:	loss/total_loss, 4.315624713897705, 350
[INFO] 2021-07-09 16:54:16,000 [run_pretraining.py:  535]:	loss/mlm_loss, 4.315624713897705, 350
[INFO] 2021-07-09 16:54:16,000 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.489999699013424e-06, 350
[INFO] 2021-07-09 16:54:16,000 [run_pretraining.py:  539]:	lr/loss_scaling, 472.23687744140625, 350
[INFO] 2021-07-09 16:54:16,000 [run_pretraining.py:  558]:	worker_index: 6, step: 350, cost: 4.315625, mlm loss: 4.315625, speed: 0.434309 steps/s, speed: 3.474473 samples/s, speed: 1778.930406 tokens/s, learning rate: 3.490e-06, loss_scalings: 472.236877, pp_loss: 4.290079
[INFO] 2021-07-09 16:54:16,000 [run_pretraining.py:  512]:	********exe.run_350******* 
[INFO] 2021-07-09 16:54:18,286 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:18,286 [run_pretraining.py:  534]:	loss/total_loss, 4.2625908851623535, 351
[INFO] 2021-07-09 16:54:18,287 [run_pretraining.py:  535]:	loss/mlm_loss, 4.2625908851623535, 351
[INFO] 2021-07-09 16:54:18,287 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.499999820633093e-06, 351
[INFO] 2021-07-09 16:54:18,287 [run_pretraining.py:  539]:	lr/loss_scaling, 472.23687744140625, 351
[INFO] 2021-07-09 16:54:18,287 [run_pretraining.py:  558]:	worker_index: 6, step: 351, cost: 4.262591, mlm loss: 4.262591, speed: 0.437412 steps/s, speed: 3.499298 samples/s, speed: 1791.640358 tokens/s, learning rate: 3.500e-06, loss_scalings: 472.236877, pp_loss: 4.257138
[INFO] 2021-07-09 16:54:18,287 [run_pretraining.py:  512]:	********exe.run_351******* 
[INFO] 2021-07-09 16:54:20,601 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:20,601 [run_pretraining.py:  534]:	loss/total_loss, 4.171991348266602, 352
[INFO] 2021-07-09 16:54:20,601 [run_pretraining.py:  535]:	loss/mlm_loss, 4.171991348266602, 352
[INFO] 2021-07-09 16:54:20,601 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.510000169626437e-06, 352
[INFO] 2021-07-09 16:54:20,601 [run_pretraining.py:  539]:	lr/loss_scaling, 472.23687744140625, 352
[INFO] 2021-07-09 16:54:20,602 [run_pretraining.py:  558]:	worker_index: 6, step: 352, cost: 4.171991, mlm loss: 4.171991, speed: 0.432143 steps/s, speed: 3.457141 samples/s, speed: 1770.056311 tokens/s, learning rate: 3.510e-06, loss_scalings: 472.236877, pp_loss: 4.198510
[INFO] 2021-07-09 16:54:20,602 [run_pretraining.py:  512]:	********exe.run_352******* 
[INFO] 2021-07-09 16:54:22,876 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:22,876 [run_pretraining.py:  534]:	loss/total_loss, 4.156408786773682, 353
[INFO] 2021-07-09 16:54:22,876 [run_pretraining.py:  535]:	loss/mlm_loss, 4.156408786773682, 353
[INFO] 2021-07-09 16:54:22,877 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.519999836498755e-06, 353
[INFO] 2021-07-09 16:54:22,877 [run_pretraining.py:  539]:	lr/loss_scaling, 472.23687744140625, 353
[INFO] 2021-07-09 16:54:22,877 [run_pretraining.py:  558]:	worker_index: 6, step: 353, cost: 4.156409, mlm loss: 4.156409, speed: 0.439652 steps/s, speed: 3.517217 samples/s, speed: 1800.815046 tokens/s, learning rate: 3.520e-06, loss_scalings: 472.236877, pp_loss: 4.163701
[INFO] 2021-07-09 16:54:22,877 [run_pretraining.py:  512]:	********exe.run_353******* 
[INFO] 2021-07-09 16:54:25,107 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:25,108 [run_pretraining.py:  534]:	loss/total_loss, 4.083322048187256, 354
[INFO] 2021-07-09 16:54:25,108 [run_pretraining.py:  535]:	loss/mlm_loss, 4.083322048187256, 354
[INFO] 2021-07-09 16:54:25,108 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.529999958118424e-06, 354
[INFO] 2021-07-09 16:54:25,108 [run_pretraining.py:  539]:	lr/loss_scaling, 472.23687744140625, 354
[INFO] 2021-07-09 16:54:25,108 [run_pretraining.py:  558]:	worker_index: 6, step: 354, cost: 4.083322, mlm loss: 4.083322, speed: 0.448216 steps/s, speed: 3.585726 samples/s, speed: 1835.891545 tokens/s, learning rate: 3.530e-06, loss_scalings: 472.236877, pp_loss: 4.126199
[INFO] 2021-07-09 16:54:25,109 [run_pretraining.py:  512]:	********exe.run_354******* 
[INFO] 2021-07-09 16:54:27,342 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:27,343 [run_pretraining.py:  534]:	loss/total_loss, 4.190749168395996, 355
[INFO] 2021-07-09 16:54:27,343 [run_pretraining.py:  535]:	loss/mlm_loss, 4.190749168395996, 355
[INFO] 2021-07-09 16:54:27,343 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.539999852364417e-06, 355
[INFO] 2021-07-09 16:54:27,343 [run_pretraining.py:  539]:	lr/loss_scaling, 472.23687744140625, 355
[INFO] 2021-07-09 16:54:27,343 [run_pretraining.py:  558]:	worker_index: 6, step: 355, cost: 4.190749, mlm loss: 4.190749, speed: 0.447636 steps/s, speed: 3.581085 samples/s, speed: 1833.515639 tokens/s, learning rate: 3.540e-06, loss_scalings: 472.236877, pp_loss: 4.099924
[INFO] 2021-07-09 16:54:27,343 [run_pretraining.py:  512]:	********exe.run_355******* 
[INFO] 2021-07-09 16:54:29,564 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:29,565 [run_pretraining.py:  534]:	loss/total_loss, 4.110396385192871, 356
[INFO] 2021-07-09 16:54:29,565 [run_pretraining.py:  535]:	loss/mlm_loss, 4.110396385192871, 356
[INFO] 2021-07-09 16:54:29,565 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.549999973984086e-06, 356
[INFO] 2021-07-09 16:54:29,565 [run_pretraining.py:  539]:	lr/loss_scaling, 472.23687744140625, 356
[INFO] 2021-07-09 16:54:29,566 [run_pretraining.py:  558]:	worker_index: 6, step: 356, cost: 4.110396, mlm loss: 4.110396, speed: 0.450103 steps/s, speed: 3.600827 samples/s, speed: 1843.623598 tokens/s, learning rate: 3.550e-06, loss_scalings: 472.236877, pp_loss: 4.134076
[INFO] 2021-07-09 16:54:29,566 [run_pretraining.py:  512]:	********exe.run_356******* 
[INFO] 2021-07-09 16:54:31,858 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:31,859 [run_pretraining.py:  534]:	loss/total_loss, 4.164523124694824, 357
[INFO] 2021-07-09 16:54:31,859 [run_pretraining.py:  535]:	loss/mlm_loss, 4.164523124694824, 357
[INFO] 2021-07-09 16:54:31,859 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.5599998682300793e-06, 357
[INFO] 2021-07-09 16:54:31,859 [run_pretraining.py:  539]:	lr/loss_scaling, 472.23687744140625, 357
[INFO] 2021-07-09 16:54:31,859 [run_pretraining.py:  558]:	worker_index: 6, step: 357, cost: 4.164523, mlm loss: 4.164523, speed: 0.436070 steps/s, speed: 3.488557 samples/s, speed: 1786.141431 tokens/s, learning rate: 3.560e-06, loss_scalings: 472.236877, pp_loss: 4.161385
[INFO] 2021-07-09 16:54:31,860 [run_pretraining.py:  512]:	********exe.run_357******* 
[INFO] 2021-07-09 16:54:34,128 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:34,129 [run_pretraining.py:  534]:	loss/total_loss, 4.178192138671875, 358
[INFO] 2021-07-09 16:54:34,129 [run_pretraining.py:  535]:	loss/mlm_loss, 4.178192138671875, 358
[INFO] 2021-07-09 16:54:34,129 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.569999989849748e-06, 358
[INFO] 2021-07-09 16:54:34,129 [run_pretraining.py:  539]:	lr/loss_scaling, 472.23687744140625, 358
[INFO] 2021-07-09 16:54:34,129 [run_pretraining.py:  558]:	worker_index: 6, step: 358, cost: 4.178192, mlm loss: 4.178192, speed: 0.440663 steps/s, speed: 3.525303 samples/s, speed: 1804.955258 tokens/s, learning rate: 3.570e-06, loss_scalings: 472.236877, pp_loss: 4.200572
[INFO] 2021-07-09 16:54:34,130 [run_pretraining.py:  512]:	********exe.run_358******* 
[INFO] 2021-07-09 16:54:36,376 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:36,377 [run_pretraining.py:  534]:	loss/total_loss, 4.2930006980896, 359
[INFO] 2021-07-09 16:54:36,377 [run_pretraining.py:  535]:	loss/mlm_loss, 4.2930006980896, 359
[INFO] 2021-07-09 16:54:36,377 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.5799998840957414e-06, 359
[INFO] 2021-07-09 16:54:36,377 [run_pretraining.py:  539]:	lr/loss_scaling, 472.23687744140625, 359
[INFO] 2021-07-09 16:54:36,377 [run_pretraining.py:  558]:	worker_index: 6, step: 359, cost: 4.293001, mlm loss: 4.293001, speed: 0.445015 steps/s, speed: 3.560118 samples/s, speed: 1822.780579 tokens/s, learning rate: 3.580e-06, loss_scalings: 472.236877, pp_loss: 4.245599
[INFO] 2021-07-09 16:54:36,377 [run_pretraining.py:  512]:	********exe.run_359******* 
[INFO] 2021-07-09 16:54:38,593 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:38,594 [run_pretraining.py:  534]:	loss/total_loss, 4.273031234741211, 360
[INFO] 2021-07-09 16:54:38,594 [run_pretraining.py:  535]:	loss/mlm_loss, 4.273031234741211, 360
[INFO] 2021-07-09 16:54:38,594 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.5900000057154102e-06, 360
[INFO] 2021-07-09 16:54:38,594 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 360
[INFO] 2021-07-09 16:54:38,594 [run_pretraining.py:  558]:	worker_index: 6, step: 360, cost: 4.273031, mlm loss: 4.273031, speed: 0.451212 steps/s, speed: 3.609696 samples/s, speed: 1848.164412 tokens/s, learning rate: 3.590e-06, loss_scalings: 377.789520, pp_loss: 4.270995
[INFO] 2021-07-09 16:54:38,594 [run_pretraining.py:  512]:	********exe.run_360******* 
[INFO] 2021-07-09 16:54:40,807 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:40,808 [run_pretraining.py:  534]:	loss/total_loss, 4.400270938873291, 361
[INFO] 2021-07-09 16:54:40,808 [run_pretraining.py:  535]:	loss/mlm_loss, 4.400270938873291, 361
[INFO] 2021-07-09 16:54:40,808 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.599999672587728e-06, 361
[INFO] 2021-07-09 16:54:40,808 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 361
[INFO] 2021-07-09 16:54:40,808 [run_pretraining.py:  558]:	worker_index: 6, step: 361, cost: 4.400271, mlm loss: 4.400271, speed: 0.451809 steps/s, speed: 3.614469 samples/s, speed: 1850.608361 tokens/s, learning rate: 3.600e-06, loss_scalings: 377.789520, pp_loss: 4.359051
[INFO] 2021-07-09 16:54:40,808 [run_pretraining.py:  512]:	********exe.run_361******* 
[INFO] 2021-07-09 16:54:43,024 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:43,025 [run_pretraining.py:  534]:	loss/total_loss, 4.392796993255615, 362
[INFO] 2021-07-09 16:54:43,025 [run_pretraining.py:  535]:	loss/mlm_loss, 4.392796993255615, 362
[INFO] 2021-07-09 16:54:43,025 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.6100000215810724e-06, 362
[INFO] 2021-07-09 16:54:43,025 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 362
[INFO] 2021-07-09 16:54:43,025 [run_pretraining.py:  558]:	worker_index: 6, step: 362, cost: 4.392797, mlm loss: 4.392797, speed: 0.451151 steps/s, speed: 3.609210 samples/s, speed: 1847.915323 tokens/s, learning rate: 3.610e-06, loss_scalings: 377.789520, pp_loss: 4.401342
[INFO] 2021-07-09 16:54:43,026 [run_pretraining.py:  512]:	********exe.run_362******* 
[INFO] 2021-07-09 16:54:45,301 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:45,301 [run_pretraining.py:  534]:	loss/total_loss, 4.516580581665039, 363
[INFO] 2021-07-09 16:54:45,301 [run_pretraining.py:  535]:	loss/mlm_loss, 4.516580581665039, 363
[INFO] 2021-07-09 16:54:45,302 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.620000143200741e-06, 363
[INFO] 2021-07-09 16:54:45,302 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 363
[INFO] 2021-07-09 16:54:45,302 [run_pretraining.py:  558]:	worker_index: 6, step: 363, cost: 4.516581, mlm loss: 4.516581, speed: 0.439457 steps/s, speed: 3.515653 samples/s, speed: 1800.014478 tokens/s, learning rate: 3.620e-06, loss_scalings: 377.789520, pp_loss: 4.488693
[INFO] 2021-07-09 16:54:45,302 [run_pretraining.py:  512]:	********exe.run_363******* 
[INFO] 2021-07-09 16:54:47,543 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:47,544 [run_pretraining.py:  534]:	loss/total_loss, 4.461965084075928, 364
[INFO] 2021-07-09 16:54:47,544 [run_pretraining.py:  535]:	loss/mlm_loss, 4.461965084075928, 364
[INFO] 2021-07-09 16:54:47,544 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.629999810073059e-06, 364
[INFO] 2021-07-09 16:54:47,545 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 364
[INFO] 2021-07-09 16:54:47,545 [run_pretraining.py:  558]:	worker_index: 6, step: 364, cost: 4.461965, mlm loss: 4.461965, speed: 0.445975 steps/s, speed: 3.567801 samples/s, speed: 1826.714034 tokens/s, learning rate: 3.630e-06, loss_scalings: 377.789520, pp_loss: 4.496712
[INFO] 2021-07-09 16:54:47,545 [run_pretraining.py:  512]:	********exe.run_364******* 
[INFO] 2021-07-09 16:54:49,833 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:49,833 [run_pretraining.py:  534]:	loss/total_loss, 4.49999475479126, 365
[INFO] 2021-07-09 16:54:49,833 [run_pretraining.py:  535]:	loss/mlm_loss, 4.49999475479126, 365
[INFO] 2021-07-09 16:54:49,834 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.6400001590664033e-06, 365
[INFO] 2021-07-09 16:54:49,834 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 365
[INFO] 2021-07-09 16:54:49,834 [run_pretraining.py:  558]:	worker_index: 6, step: 365, cost: 4.499995, mlm loss: 4.499995, speed: 0.436986 steps/s, speed: 3.495888 samples/s, speed: 1789.894684 tokens/s, learning rate: 3.640e-06, loss_scalings: 377.789520, pp_loss: 4.512691
[INFO] 2021-07-09 16:54:49,834 [run_pretraining.py:  512]:	********exe.run_365******* 
[INFO] 2021-07-09 16:54:52,078 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:52,079 [run_pretraining.py:  534]:	loss/total_loss, 4.527223587036133, 366
[INFO] 2021-07-09 16:54:52,079 [run_pretraining.py:  535]:	loss/mlm_loss, 4.527223587036133, 366
[INFO] 2021-07-09 16:54:52,079 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.649999825938721e-06, 366
[INFO] 2021-07-09 16:54:52,079 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 366
[INFO] 2021-07-09 16:54:52,079 [run_pretraining.py:  558]:	worker_index: 6, step: 366, cost: 4.527224, mlm loss: 4.527224, speed: 0.445452 steps/s, speed: 3.563613 samples/s, speed: 1824.569899 tokens/s, learning rate: 3.650e-06, loss_scalings: 377.789520, pp_loss: 4.536555
[INFO] 2021-07-09 16:54:52,079 [run_pretraining.py:  512]:	********exe.run_366******* 
[INFO] 2021-07-09 16:54:54,420 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:54,421 [run_pretraining.py:  534]:	loss/total_loss, 4.562131404876709, 367
[INFO] 2021-07-09 16:54:54,421 [run_pretraining.py:  535]:	loss/mlm_loss, 4.562131404876709, 367
[INFO] 2021-07-09 16:54:54,421 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.65999994755839e-06, 367
[INFO] 2021-07-09 16:54:54,421 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 367
[INFO] 2021-07-09 16:54:54,421 [run_pretraining.py:  558]:	worker_index: 6, step: 367, cost: 4.562131, mlm loss: 4.562131, speed: 0.427133 steps/s, speed: 3.417067 samples/s, speed: 1749.538266 tokens/s, learning rate: 3.660e-06, loss_scalings: 377.789520, pp_loss: 4.580045
[INFO] 2021-07-09 16:54:54,421 [run_pretraining.py:  512]:	********exe.run_367******* 
[INFO] 2021-07-09 16:54:56,671 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:56,672 [run_pretraining.py:  534]:	loss/total_loss, 4.597978591918945, 368
[INFO] 2021-07-09 16:54:56,672 [run_pretraining.py:  535]:	loss/mlm_loss, 4.597978591918945, 368
[INFO] 2021-07-09 16:54:56,672 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.6699998418043833e-06, 368
[INFO] 2021-07-09 16:54:56,672 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 368
[INFO] 2021-07-09 16:54:56,672 [run_pretraining.py:  558]:	worker_index: 6, step: 368, cost: 4.597979, mlm loss: 4.597979, speed: 0.444383 steps/s, speed: 3.555064 samples/s, speed: 1820.192936 tokens/s, learning rate: 3.670e-06, loss_scalings: 377.789520, pp_loss: 4.606709
[INFO] 2021-07-09 16:54:56,672 [run_pretraining.py:  512]:	********exe.run_368******* 
[INFO] 2021-07-09 16:54:58,899 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:58,900 [run_pretraining.py:  534]:	loss/total_loss, 4.599766731262207, 369
[INFO] 2021-07-09 16:54:58,900 [run_pretraining.py:  535]:	loss/mlm_loss, 4.599766731262207, 369
[INFO] 2021-07-09 16:54:58,900 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.679999963424052e-06, 369
[INFO] 2021-07-09 16:54:58,900 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 369
[INFO] 2021-07-09 16:54:58,900 [run_pretraining.py:  558]:	worker_index: 6, step: 369, cost: 4.599767, mlm loss: 4.599767, speed: 0.448932 steps/s, speed: 3.591454 samples/s, speed: 1838.824341 tokens/s, learning rate: 3.680e-06, loss_scalings: 377.789520, pp_loss: 4.626915
[INFO] 2021-07-09 16:54:58,900 [run_pretraining.py:  512]:	********exe.run_369******* 
[INFO] 2021-07-09 16:55:01,176 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:01,176 [run_pretraining.py:  534]:	loss/total_loss, 4.6462321281433105, 370
[INFO] 2021-07-09 16:55:01,176 [run_pretraining.py:  535]:	loss/mlm_loss, 4.6462321281433105, 370
[INFO] 2021-07-09 16:55:01,176 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.6899998576700455e-06, 370
[INFO] 2021-07-09 16:55:01,176 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 370
[INFO] 2021-07-09 16:55:01,177 [run_pretraining.py:  558]:	worker_index: 6, step: 370, cost: 4.646232, mlm loss: 4.646232, speed: 0.439471 steps/s, speed: 3.515771 samples/s, speed: 1800.074642 tokens/s, learning rate: 3.690e-06, loss_scalings: 377.789520, pp_loss: 4.628041
[INFO] 2021-07-09 16:55:01,177 [run_pretraining.py:  512]:	********exe.run_370******* 
[INFO] 2021-07-09 16:55:03,461 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:03,462 [run_pretraining.py:  534]:	loss/total_loss, 4.538045406341553, 371
[INFO] 2021-07-09 16:55:03,462 [run_pretraining.py:  535]:	loss/mlm_loss, 4.538045406341553, 371
[INFO] 2021-07-09 16:55:03,462 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.6999999792897142e-06, 371
[INFO] 2021-07-09 16:55:03,462 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 371
[INFO] 2021-07-09 16:55:03,462 [run_pretraining.py:  558]:	worker_index: 6, step: 371, cost: 4.538045, mlm loss: 4.538045, speed: 0.437646 steps/s, speed: 3.501171 samples/s, speed: 1792.599386 tokens/s, learning rate: 3.700e-06, loss_scalings: 377.789520, pp_loss: 4.573952
[INFO] 2021-07-09 16:55:03,462 [run_pretraining.py:  512]:	********exe.run_371******* 
[INFO] 2021-07-09 16:55:05,723 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:05,723 [run_pretraining.py:  534]:	loss/total_loss, 4.5078229904174805, 372
[INFO] 2021-07-09 16:55:05,723 [run_pretraining.py:  535]:	loss/mlm_loss, 4.5078229904174805, 372
[INFO] 2021-07-09 16:55:05,723 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.709999646162032e-06, 372
[INFO] 2021-07-09 16:55:05,723 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 372
[INFO] 2021-07-09 16:55:05,724 [run_pretraining.py:  558]:	worker_index: 6, step: 372, cost: 4.507823, mlm loss: 4.507823, speed: 0.442347 steps/s, speed: 3.538778 samples/s, speed: 1811.854574 tokens/s, learning rate: 3.710e-06, loss_scalings: 377.789520, pp_loss: 4.501603
[INFO] 2021-07-09 16:55:05,724 [run_pretraining.py:  512]:	********exe.run_372******* 
[INFO] 2021-07-09 16:55:08,006 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:08,007 [run_pretraining.py:  534]:	loss/total_loss, 4.448600769042969, 373
[INFO] 2021-07-09 16:55:08,007 [run_pretraining.py:  535]:	loss/mlm_loss, 4.448600769042969, 373
[INFO] 2021-07-09 16:55:08,007 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.7199999951553764e-06, 373
[INFO] 2021-07-09 16:55:08,007 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 373
[INFO] 2021-07-09 16:55:08,007 [run_pretraining.py:  558]:	worker_index: 6, step: 373, cost: 4.448601, mlm loss: 4.448601, speed: 0.438027 steps/s, speed: 3.504214 samples/s, speed: 1794.157704 tokens/s, learning rate: 3.720e-06, loss_scalings: 377.789520, pp_loss: 4.373696
[INFO] 2021-07-09 16:55:08,007 [run_pretraining.py:  512]:	********exe.run_373******* 
[INFO] 2021-07-09 16:55:10,253 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:10,254 [run_pretraining.py:  534]:	loss/total_loss, 4.246115684509277, 374
[INFO] 2021-07-09 16:55:10,254 [run_pretraining.py:  535]:	loss/mlm_loss, 4.246115684509277, 374
[INFO] 2021-07-09 16:55:10,254 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.730000116775045e-06, 374
[INFO] 2021-07-09 16:55:10,254 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 374
[INFO] 2021-07-09 16:55:10,254 [run_pretraining.py:  558]:	worker_index: 6, step: 374, cost: 4.246116, mlm loss: 4.246116, speed: 0.445127 steps/s, speed: 3.561015 samples/s, speed: 1823.239431 tokens/s, learning rate: 3.730e-06, loss_scalings: 377.789520, pp_loss: 4.231204
[INFO] 2021-07-09 16:55:10,255 [run_pretraining.py:  512]:	********exe.run_374******* 
[INFO] 2021-07-09 16:55:12,506 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:12,506 [run_pretraining.py:  534]:	loss/total_loss, 3.9536070823669434, 375
[INFO] 2021-07-09 16:55:12,507 [run_pretraining.py:  535]:	loss/mlm_loss, 3.9536070823669434, 375
[INFO] 2021-07-09 16:55:12,507 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.739999783647363e-06, 375
[INFO] 2021-07-09 16:55:12,507 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 375
[INFO] 2021-07-09 16:55:12,507 [run_pretraining.py:  558]:	worker_index: 6, step: 375, cost: 3.953607, mlm loss: 3.953607, speed: 0.444127 steps/s, speed: 3.553017 samples/s, speed: 1819.144640 tokens/s, learning rate: 3.740e-06, loss_scalings: 377.789520, pp_loss: 4.017764
[INFO] 2021-07-09 16:55:12,507 [run_pretraining.py:  512]:	********exe.run_375******* 
[INFO] 2021-07-09 16:55:14,751 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:14,752 [run_pretraining.py:  534]:	loss/total_loss, 3.8132147789001465, 376
[INFO] 2021-07-09 16:55:14,752 [run_pretraining.py:  535]:	loss/mlm_loss, 3.8132147789001465, 376
[INFO] 2021-07-09 16:55:14,752 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.7500001326407073e-06, 376
[INFO] 2021-07-09 16:55:14,752 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 376
[INFO] 2021-07-09 16:55:14,752 [run_pretraining.py:  558]:	worker_index: 6, step: 376, cost: 3.813215, mlm loss: 3.813215, speed: 0.445496 steps/s, speed: 3.563965 samples/s, speed: 1824.750129 tokens/s, learning rate: 3.750e-06, loss_scalings: 377.789520, pp_loss: 3.863583
[INFO] 2021-07-09 16:55:14,752 [run_pretraining.py:  512]:	********exe.run_376******* 
[INFO] 2021-07-09 16:55:16,985 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:16,986 [run_pretraining.py:  534]:	loss/total_loss, 3.7339253425598145, 377
[INFO] 2021-07-09 16:55:16,986 [run_pretraining.py:  535]:	loss/mlm_loss, 3.7339253425598145, 377
[INFO] 2021-07-09 16:55:16,986 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.759999799513025e-06, 377
[INFO] 2021-07-09 16:55:16,986 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 377
[INFO] 2021-07-09 16:55:16,986 [run_pretraining.py:  558]:	worker_index: 6, step: 377, cost: 3.733925, mlm loss: 3.733925, speed: 0.447738 steps/s, speed: 3.581906 samples/s, speed: 1833.935667 tokens/s, learning rate: 3.760e-06, loss_scalings: 377.789520, pp_loss: 3.741755
[INFO] 2021-07-09 16:55:16,986 [run_pretraining.py:  512]:	********exe.run_377******* 
[INFO] 2021-07-09 16:55:19,238 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:19,239 [run_pretraining.py:  534]:	loss/total_loss, 3.68963360786438, 378
[INFO] 2021-07-09 16:55:19,239 [run_pretraining.py:  535]:	loss/mlm_loss, 3.68963360786438, 378
[INFO] 2021-07-09 16:55:19,239 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.769999921132694e-06, 378
[INFO] 2021-07-09 16:55:19,239 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 378
[INFO] 2021-07-09 16:55:19,239 [run_pretraining.py:  558]:	worker_index: 6, step: 378, cost: 3.689634, mlm loss: 3.689634, speed: 0.444055 steps/s, speed: 3.552444 samples/s, speed: 1818.851318 tokens/s, learning rate: 3.770e-06, loss_scalings: 377.789520, pp_loss: 3.657654
[INFO] 2021-07-09 16:55:19,239 [run_pretraining.py:  512]:	********exe.run_378******* 
[INFO] 2021-07-09 16:55:21,478 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:21,479 [run_pretraining.py:  534]:	loss/total_loss, 3.6620113849639893, 379
[INFO] 2021-07-09 16:55:21,479 [run_pretraining.py:  535]:	loss/mlm_loss, 3.6620113849639893, 379
[INFO] 2021-07-09 16:55:21,479 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.7799998153786873e-06, 379
[INFO] 2021-07-09 16:55:21,479 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 379
[INFO] 2021-07-09 16:55:21,479 [run_pretraining.py:  558]:	worker_index: 6, step: 379, cost: 3.662011, mlm loss: 3.662011, speed: 0.446572 steps/s, speed: 3.572577 samples/s, speed: 1829.159190 tokens/s, learning rate: 3.780e-06, loss_scalings: 377.789520, pp_loss: 3.631394
[INFO] 2021-07-09 16:55:21,479 [run_pretraining.py:  512]:	********exe.run_379******* 
[INFO] 2021-07-09 16:55:23,708 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:23,709 [run_pretraining.py:  534]:	loss/total_loss, 3.597018003463745, 380
[INFO] 2021-07-09 16:55:23,709 [run_pretraining.py:  535]:	loss/mlm_loss, 3.597018003463745, 380
[INFO] 2021-07-09 16:55:23,709 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.789999936998356e-06, 380
[INFO] 2021-07-09 16:55:23,709 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 380
[INFO] 2021-07-09 16:55:23,709 [run_pretraining.py:  558]:	worker_index: 6, step: 380, cost: 3.597018, mlm loss: 3.597018, speed: 0.448465 steps/s, speed: 3.587720 samples/s, speed: 1836.912883 tokens/s, learning rate: 3.790e-06, loss_scalings: 377.789520, pp_loss: 3.592717
[INFO] 2021-07-09 16:55:23,710 [run_pretraining.py:  512]:	********exe.run_380******* 
[INFO] 2021-07-09 16:55:25,950 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:25,951 [run_pretraining.py:  534]:	loss/total_loss, 3.561276435852051, 381
[INFO] 2021-07-09 16:55:25,951 [run_pretraining.py:  535]:	loss/mlm_loss, 3.561276435852051, 381
[INFO] 2021-07-09 16:55:25,951 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.7999998312443495e-06, 381
[INFO] 2021-07-09 16:55:25,951 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 381
[INFO] 2021-07-09 16:55:25,951 [run_pretraining.py:  558]:	worker_index: 6, step: 381, cost: 3.561276, mlm loss: 3.561276, speed: 0.446211 steps/s, speed: 3.569689 samples/s, speed: 1827.680656 tokens/s, learning rate: 3.800e-06, loss_scalings: 377.789520, pp_loss: 3.573081
[INFO] 2021-07-09 16:55:25,951 [run_pretraining.py:  512]:	********exe.run_381******* 
[INFO] 2021-07-09 16:55:28,210 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:28,210 [run_pretraining.py:  534]:	loss/total_loss, 3.6047816276550293, 382
[INFO] 2021-07-09 16:55:28,210 [run_pretraining.py:  535]:	loss/mlm_loss, 3.6047816276550293, 382
[INFO] 2021-07-09 16:55:28,210 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.8099999528640183e-06, 382
[INFO] 2021-07-09 16:55:28,211 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 382
[INFO] 2021-07-09 16:55:28,211 [run_pretraining.py:  558]:	worker_index: 6, step: 382, cost: 3.604782, mlm loss: 3.604782, speed: 0.442730 steps/s, speed: 3.541838 samples/s, speed: 1813.421297 tokens/s, learning rate: 3.810e-06, loss_scalings: 377.789520, pp_loss: 3.618948
[INFO] 2021-07-09 16:55:28,211 [run_pretraining.py:  512]:	********exe.run_382******* 
[INFO] 2021-07-09 16:55:30,459 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:30,459 [run_pretraining.py:  534]:	loss/total_loss, 3.644519805908203, 383
[INFO] 2021-07-09 16:55:30,459 [run_pretraining.py:  535]:	loss/mlm_loss, 3.644519805908203, 383
[INFO] 2021-07-09 16:55:30,459 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.819999619736336e-06, 383
[INFO] 2021-07-09 16:55:30,460 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 383
[INFO] 2021-07-09 16:55:30,460 [run_pretraining.py:  558]:	worker_index: 6, step: 383, cost: 3.644520, mlm loss: 3.644520, speed: 0.444769 steps/s, speed: 3.558152 samples/s, speed: 1821.773732 tokens/s, learning rate: 3.820e-06, loss_scalings: 377.789520, pp_loss: 3.620985
[INFO] 2021-07-09 16:55:30,460 [run_pretraining.py:  512]:	********exe.run_383******* 
[INFO] 2021-07-09 16:55:32,862 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:32,862 [run_pretraining.py:  534]:	loss/total_loss, 3.564103841781616, 384
[INFO] 2021-07-09 16:55:32,863 [run_pretraining.py:  535]:	loss/mlm_loss, 3.564103841781616, 384
[INFO] 2021-07-09 16:55:32,863 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.82999996872968e-06, 384
[INFO] 2021-07-09 16:55:32,863 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 384
[INFO] 2021-07-09 16:55:32,863 [run_pretraining.py:  558]:	worker_index: 6, step: 384, cost: 3.564104, mlm loss: 3.564104, speed: 0.416240 steps/s, speed: 3.329919 samples/s, speed: 1704.918547 tokens/s, learning rate: 3.830e-06, loss_scalings: 377.789520, pp_loss: 3.603668
[INFO] 2021-07-09 16:55:32,863 [run_pretraining.py:  512]:	********exe.run_384******* 
[INFO] 2021-07-09 16:55:35,213 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:35,213 [run_pretraining.py:  534]:	loss/total_loss, 3.5788424015045166, 385
[INFO] 2021-07-09 16:55:35,213 [run_pretraining.py:  535]:	loss/mlm_loss, 3.5788424015045166, 385
[INFO] 2021-07-09 16:55:35,213 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.839999862975674e-06, 385
[INFO] 2021-07-09 16:55:35,213 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 385
[INFO] 2021-07-09 16:55:35,214 [run_pretraining.py:  558]:	worker_index: 6, step: 385, cost: 3.578842, mlm loss: 3.578842, speed: 0.425513 steps/s, speed: 3.404100 samples/s, speed: 1742.899400 tokens/s, learning rate: 3.840e-06, loss_scalings: 377.789520, pp_loss: 3.558568
[INFO] 2021-07-09 16:55:35,214 [run_pretraining.py:  512]:	********exe.run_385******* 
[INFO] 2021-07-09 16:55:37,488 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:37,489 [run_pretraining.py:  534]:	loss/total_loss, 3.406764030456543, 386
[INFO] 2021-07-09 16:55:37,489 [run_pretraining.py:  535]:	loss/mlm_loss, 3.406764030456543, 386
[INFO] 2021-07-09 16:55:37,489 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.849999757221667e-06, 386
[INFO] 2021-07-09 16:55:37,489 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 386
[INFO] 2021-07-09 16:55:37,489 [run_pretraining.py:  558]:	worker_index: 6, step: 386, cost: 3.406764, mlm loss: 3.406764, speed: 0.439525 steps/s, speed: 3.516200 samples/s, speed: 1800.294587 tokens/s, learning rate: 3.850e-06, loss_scalings: 377.789520, pp_loss: 3.437394
[INFO] 2021-07-09 16:55:37,490 [run_pretraining.py:  512]:	********exe.run_386******* 
[INFO] 2021-07-09 16:55:39,755 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:39,755 [run_pretraining.py:  534]:	loss/total_loss, 3.476637363433838, 387
[INFO] 2021-07-09 16:55:39,756 [run_pretraining.py:  535]:	loss/mlm_loss, 3.476637363433838, 387
[INFO] 2021-07-09 16:55:39,756 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.860000106215011e-06, 387
[INFO] 2021-07-09 16:55:39,756 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 387
[INFO] 2021-07-09 16:55:39,756 [run_pretraining.py:  558]:	worker_index: 6, step: 387, cost: 3.476637, mlm loss: 3.476637, speed: 0.441370 steps/s, speed: 3.530962 samples/s, speed: 1807.852557 tokens/s, learning rate: 3.860e-06, loss_scalings: 377.789520, pp_loss: 3.367976
[INFO] 2021-07-09 16:55:39,756 [run_pretraining.py:  512]:	********exe.run_387******* 
[INFO] 2021-07-09 16:55:41,996 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:41,997 [run_pretraining.py:  534]:	loss/total_loss, 3.3403327465057373, 388
[INFO] 2021-07-09 16:55:41,997 [run_pretraining.py:  535]:	loss/mlm_loss, 3.3403327465057373, 388
[INFO] 2021-07-09 16:55:41,997 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.870000000461005e-06, 388
[INFO] 2021-07-09 16:55:41,997 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 388
[INFO] 2021-07-09 16:55:41,997 [run_pretraining.py:  558]:	worker_index: 6, step: 388, cost: 3.340333, mlm loss: 3.340333, speed: 0.446249 steps/s, speed: 3.569993 samples/s, speed: 1827.836414 tokens/s, learning rate: 3.870e-06, loss_scalings: 377.789520, pp_loss: 3.326092
[INFO] 2021-07-09 16:55:41,998 [run_pretraining.py:  512]:	********exe.run_388******* 
[INFO] 2021-07-09 16:55:44,261 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:44,261 [run_pretraining.py:  534]:	loss/total_loss, 3.296504497528076, 389
[INFO] 2021-07-09 16:55:44,261 [run_pretraining.py:  535]:	loss/mlm_loss, 3.296504497528076, 389
[INFO] 2021-07-09 16:55:44,262 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.879999894706998e-06, 389
[INFO] 2021-07-09 16:55:44,262 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 389
[INFO] 2021-07-09 16:55:44,262 [run_pretraining.py:  558]:	worker_index: 6, step: 389, cost: 3.296504, mlm loss: 3.296504, speed: 0.441781 steps/s, speed: 3.534247 samples/s, speed: 1809.534718 tokens/s, learning rate: 3.880e-06, loss_scalings: 377.789520, pp_loss: 3.286693
[INFO] 2021-07-09 16:55:44,262 [run_pretraining.py:  512]:	********exe.run_389******* 
[INFO] 2021-07-09 16:55:46,543 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:46,544 [run_pretraining.py:  534]:	loss/total_loss, 3.3128578662872314, 390
[INFO] 2021-07-09 16:55:46,544 [run_pretraining.py:  535]:	loss/mlm_loss, 3.3128578662872314, 390
[INFO] 2021-07-09 16:55:46,544 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.889999788952991e-06, 390
[INFO] 2021-07-09 16:55:46,544 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 390
[INFO] 2021-07-09 16:55:46,544 [run_pretraining.py:  558]:	worker_index: 6, step: 390, cost: 3.312858, mlm loss: 3.312858, speed: 0.438303 steps/s, speed: 3.506421 samples/s, speed: 1795.287510 tokens/s, learning rate: 3.890e-06, loss_scalings: 377.789520, pp_loss: 3.314776
[INFO] 2021-07-09 16:55:46,544 [run_pretraining.py:  512]:	********exe.run_390******* 
[INFO] 2021-07-09 16:55:48,880 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:48,881 [run_pretraining.py:  534]:	loss/total_loss, 3.2712464332580566, 391
[INFO] 2021-07-09 16:55:48,881 [run_pretraining.py:  535]:	loss/mlm_loss, 3.2712464332580566, 391
[INFO] 2021-07-09 16:55:48,881 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.900000137946336e-06, 391
[INFO] 2021-07-09 16:55:48,881 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 391
[INFO] 2021-07-09 16:55:48,881 [run_pretraining.py:  558]:	worker_index: 6, step: 391, cost: 3.271246, mlm loss: 3.271246, speed: 0.427962 steps/s, speed: 3.423698 samples/s, speed: 1752.933399 tokens/s, learning rate: 3.900e-06, loss_scalings: 377.789520, pp_loss: 3.269291
[INFO] 2021-07-09 16:55:48,881 [run_pretraining.py:  512]:	********exe.run_391******* 
[INFO] 2021-07-09 16:55:51,207 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:51,208 [run_pretraining.py:  534]:	loss/total_loss, 3.174933433532715, 392
[INFO] 2021-07-09 16:55:51,208 [run_pretraining.py:  535]:	loss/mlm_loss, 3.174933433532715, 392
[INFO] 2021-07-09 16:55:51,208 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.909999577444978e-06, 392
[INFO] 2021-07-09 16:55:51,208 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 392
[INFO] 2021-07-09 16:55:51,208 [run_pretraining.py:  558]:	worker_index: 6, step: 392, cost: 3.174933, mlm loss: 3.174933, speed: 0.429844 steps/s, speed: 3.438751 samples/s, speed: 1760.640368 tokens/s, learning rate: 3.910e-06, loss_scalings: 377.789520, pp_loss: 3.155721
[INFO] 2021-07-09 16:55:51,208 [run_pretraining.py:  512]:	********exe.run_392******* 
[INFO] 2021-07-09 16:55:53,511 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:53,511 [run_pretraining.py:  534]:	loss/total_loss, 3.0651674270629883, 393
[INFO] 2021-07-09 16:55:53,511 [run_pretraining.py:  535]:	loss/mlm_loss, 3.0651674270629883, 393
[INFO] 2021-07-09 16:55:53,511 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.919999926438322e-06, 393
[INFO] 2021-07-09 16:55:53,512 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 393
[INFO] 2021-07-09 16:55:53,512 [run_pretraining.py:  558]:	worker_index: 6, step: 393, cost: 3.065167, mlm loss: 3.065167, speed: 0.434313 steps/s, speed: 3.474504 samples/s, speed: 1778.945879 tokens/s, learning rate: 3.920e-06, loss_scalings: 377.789520, pp_loss: 3.044438
[INFO] 2021-07-09 16:55:53,512 [run_pretraining.py:  512]:	********exe.run_393******* 
[INFO] 2021-07-09 16:55:55,767 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:55,767 [run_pretraining.py:  534]:	loss/total_loss, 2.9646553993225098, 394
[INFO] 2021-07-09 16:55:55,767 [run_pretraining.py:  535]:	loss/mlm_loss, 2.9646553993225098, 394
[INFO] 2021-07-09 16:55:55,767 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.929999820684316e-06, 394
[INFO] 2021-07-09 16:55:55,768 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 394
[INFO] 2021-07-09 16:55:55,768 [run_pretraining.py:  558]:	worker_index: 6, step: 394, cost: 2.964655, mlm loss: 2.964655, speed: 0.443392 steps/s, speed: 3.547133 samples/s, speed: 1816.131961 tokens/s, learning rate: 3.930e-06, loss_scalings: 377.789520, pp_loss: 2.944106
[INFO] 2021-07-09 16:55:55,768 [run_pretraining.py:  512]:	********exe.run_394******* 
[INFO] 2021-07-09 16:55:58,042 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:58,042 [run_pretraining.py:  534]:	loss/total_loss, 2.866013288497925, 395
[INFO] 2021-07-09 16:55:58,043 [run_pretraining.py:  535]:	loss/mlm_loss, 2.866013288497925, 395
[INFO] 2021-07-09 16:55:58,043 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.939999714930309e-06, 395
[INFO] 2021-07-09 16:55:58,043 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 395
[INFO] 2021-07-09 16:55:58,043 [run_pretraining.py:  558]:	worker_index: 6, step: 395, cost: 2.866013, mlm loss: 2.866013, speed: 0.439670 steps/s, speed: 3.517362 samples/s, speed: 1800.889422 tokens/s, learning rate: 3.940e-06, loss_scalings: 377.789520, pp_loss: 2.890495
[INFO] 2021-07-09 16:55:58,043 [run_pretraining.py:  512]:	********exe.run_395******* 
[INFO] 2021-07-09 16:56:00,353 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:00,353 [run_pretraining.py:  534]:	loss/total_loss, 2.858839511871338, 396
[INFO] 2021-07-09 16:56:00,354 [run_pretraining.py:  535]:	loss/mlm_loss, 2.858839511871338, 396
[INFO] 2021-07-09 16:56:00,354 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.950000063923653e-06, 396
[INFO] 2021-07-09 16:56:00,354 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 396
[INFO] 2021-07-09 16:56:00,354 [run_pretraining.py:  558]:	worker_index: 6, step: 396, cost: 2.858840, mlm loss: 2.858840, speed: 0.432840 steps/s, speed: 3.462720 samples/s, speed: 1772.912455 tokens/s, learning rate: 3.950e-06, loss_scalings: 377.789520, pp_loss: 2.856591
[INFO] 2021-07-09 16:56:00,354 [run_pretraining.py:  512]:	********exe.run_396******* 
[INFO] 2021-07-09 16:56:02,688 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:02,689 [run_pretraining.py:  534]:	loss/total_loss, 2.8216614723205566, 397
[INFO] 2021-07-09 16:56:02,689 [run_pretraining.py:  535]:	loss/mlm_loss, 2.8216614723205566, 397
[INFO] 2021-07-09 16:56:02,689 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.9599999581696466e-06, 397
[INFO] 2021-07-09 16:56:02,689 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 397
[INFO] 2021-07-09 16:56:02,689 [run_pretraining.py:  558]:	worker_index: 6, step: 397, cost: 2.821661, mlm loss: 2.821661, speed: 0.428332 steps/s, speed: 3.426655 samples/s, speed: 1754.447137 tokens/s, learning rate: 3.960e-06, loss_scalings: 377.789520, pp_loss: 2.829833
[INFO] 2021-07-09 16:56:02,689 [run_pretraining.py:  512]:	********exe.run_397******* 
[INFO] 2021-07-09 16:56:04,968 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:04,969 [run_pretraining.py:  534]:	loss/total_loss, 2.8991663455963135, 398
[INFO] 2021-07-09 16:56:04,969 [run_pretraining.py:  535]:	loss/mlm_loss, 2.8991663455963135, 398
[INFO] 2021-07-09 16:56:04,969 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.96999985241564e-06, 398
[INFO] 2021-07-09 16:56:04,969 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 398
[INFO] 2021-07-09 16:56:04,969 [run_pretraining.py:  558]:	worker_index: 6, step: 398, cost: 2.899166, mlm loss: 2.899166, speed: 0.438694 steps/s, speed: 3.509556 samples/s, speed: 1796.892606 tokens/s, learning rate: 3.970e-06, loss_scalings: 377.789520, pp_loss: 2.859303
[INFO] 2021-07-09 16:56:04,969 [run_pretraining.py:  512]:	********exe.run_398******* 
[INFO] 2021-07-09 16:56:07,277 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:07,278 [run_pretraining.py:  534]:	loss/total_loss, 2.871201276779175, 399
[INFO] 2021-07-09 16:56:07,278 [run_pretraining.py:  535]:	loss/mlm_loss, 2.871201276779175, 399
[INFO] 2021-07-09 16:56:07,278 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.979999746661633e-06, 399
[INFO] 2021-07-09 16:56:07,278 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 399
[INFO] 2021-07-09 16:56:07,278 [run_pretraining.py:  558]:	worker_index: 6, step: 399, cost: 2.871201, mlm loss: 2.871201, speed: 0.433191 steps/s, speed: 3.465531 samples/s, speed: 1774.351684 tokens/s, learning rate: 3.980e-06, loss_scalings: 377.789520, pp_loss: 2.876215
[INFO] 2021-07-09 16:56:07,278 [run_pretraining.py:  512]:	********exe.run_399******* 
[INFO] 2021-07-09 16:56:09,519 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:09,520 [run_pretraining.py:  534]:	loss/total_loss, 2.9853737354278564, 400
[INFO] 2021-07-09 16:56:09,520 [run_pretraining.py:  535]:	loss/mlm_loss, 2.9853737354278564, 400
[INFO] 2021-07-09 16:56:09,520 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.9900000956549775e-06, 400
[INFO] 2021-07-09 16:56:09,520 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 400
[INFO] 2021-07-09 16:56:09,520 [run_pretraining.py:  558]:	worker_index: 6, step: 400, cost: 2.985374, mlm loss: 2.985374, speed: 0.446218 steps/s, speed: 3.569744 samples/s, speed: 1827.709044 tokens/s, learning rate: 3.990e-06, loss_scalings: 377.789520, pp_loss: 2.946595
[INFO] 2021-07-09 16:56:09,520 [run_pretraining.py:  512]:	********exe.run_400******* 
[INFO] 2021-07-09 16:56:11,822 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:11,823 [run_pretraining.py:  534]:	loss/total_loss, 3.0590057373046875, 401
[INFO] 2021-07-09 16:56:11,823 [run_pretraining.py:  535]:	loss/mlm_loss, 3.0590057373046875, 401
[INFO] 2021-07-09 16:56:11,823 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.999999989900971e-06, 401
[INFO] 2021-07-09 16:56:11,823 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 401
[INFO] 2021-07-09 16:56:11,823 [run_pretraining.py:  558]:	worker_index: 6, step: 401, cost: 3.059006, mlm loss: 3.059006, speed: 0.434382 steps/s, speed: 3.475060 samples/s, speed: 1779.230708 tokens/s, learning rate: 4.000e-06, loss_scalings: 377.789520, pp_loss: 3.021381
[INFO] 2021-07-09 16:56:11,823 [run_pretraining.py:  512]:	********exe.run_401******* 
[INFO] 2021-07-09 16:56:14,076 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:14,077 [run_pretraining.py:  534]:	loss/total_loss, 3.1027944087982178, 402
[INFO] 2021-07-09 16:56:14,077 [run_pretraining.py:  535]:	loss/mlm_loss, 3.1027944087982178, 402
[INFO] 2021-07-09 16:56:14,077 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.009999884146964e-06, 402
[INFO] 2021-07-09 16:56:14,077 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 402
[INFO] 2021-07-09 16:56:14,077 [run_pretraining.py:  558]:	worker_index: 6, step: 402, cost: 3.102794, mlm loss: 3.102794, speed: 0.443773 steps/s, speed: 3.550183 samples/s, speed: 1817.693592 tokens/s, learning rate: 4.010e-06, loss_scalings: 377.789520, pp_loss: 3.110715
[INFO] 2021-07-09 16:56:14,077 [run_pretraining.py:  512]:	********exe.run_402******* 
[INFO] 2021-07-09 16:56:16,420 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:16,420 [run_pretraining.py:  534]:	loss/total_loss, 3.1954169273376465, 403
[INFO] 2021-07-09 16:56:16,421 [run_pretraining.py:  535]:	loss/mlm_loss, 3.1954169273376465, 403
[INFO] 2021-07-09 16:56:16,421 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.0199997783929575e-06, 403
[INFO] 2021-07-09 16:56:16,421 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 403
[INFO] 2021-07-09 16:56:16,421 [run_pretraining.py:  558]:	worker_index: 6, step: 403, cost: 3.195417, mlm loss: 3.195417, speed: 0.426780 steps/s, speed: 3.414242 samples/s, speed: 1748.091679 tokens/s, learning rate: 4.020e-06, loss_scalings: 377.789520, pp_loss: 3.220079
[INFO] 2021-07-09 16:56:16,421 [run_pretraining.py:  512]:	********exe.run_403******* 
[INFO] 2021-07-09 16:56:18,720 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:18,720 [run_pretraining.py:  534]:	loss/total_loss, 3.3084897994995117, 404
[INFO] 2021-07-09 16:56:18,720 [run_pretraining.py:  535]:	loss/mlm_loss, 3.3084897994995117, 404
[INFO] 2021-07-09 16:56:18,720 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.030000127386302e-06, 404
[INFO] 2021-07-09 16:56:18,720 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 404
[INFO] 2021-07-09 16:56:18,721 [run_pretraining.py:  558]:	worker_index: 6, step: 404, cost: 3.308490, mlm loss: 3.308490, speed: 0.434953 steps/s, speed: 3.479625 samples/s, speed: 1781.568238 tokens/s, learning rate: 4.030e-06, loss_scalings: 377.789520, pp_loss: 3.292335
[INFO] 2021-07-09 16:56:18,721 [run_pretraining.py:  512]:	********exe.run_404******* 
[INFO] 2021-07-09 16:56:21,006 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:21,007 [run_pretraining.py:  534]:	loss/total_loss, 3.2840614318847656, 405
[INFO] 2021-07-09 16:56:21,007 [run_pretraining.py:  535]:	loss/mlm_loss, 3.2840614318847656, 405
[INFO] 2021-07-09 16:56:21,007 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.039999566884944e-06, 405
[INFO] 2021-07-09 16:56:21,007 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 405
[INFO] 2021-07-09 16:56:21,007 [run_pretraining.py:  558]:	worker_index: 6, step: 405, cost: 3.284061, mlm loss: 3.284061, speed: 0.437429 steps/s, speed: 3.499433 samples/s, speed: 1791.709493 tokens/s, learning rate: 4.040e-06, loss_scalings: 377.789520, pp_loss: 3.292677
[INFO] 2021-07-09 16:56:21,007 [run_pretraining.py:  512]:	********exe.run_405******* 
[INFO] 2021-07-09 16:56:23,267 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:23,268 [run_pretraining.py:  534]:	loss/total_loss, 3.233001708984375, 406
[INFO] 2021-07-09 16:56:23,268 [run_pretraining.py:  535]:	loss/mlm_loss, 3.233001708984375, 406
[INFO] 2021-07-09 16:56:23,268 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.0499999158782884e-06, 406
[INFO] 2021-07-09 16:56:23,268 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 406
[INFO] 2021-07-09 16:56:23,268 [run_pretraining.py:  558]:	worker_index: 6, step: 406, cost: 3.233002, mlm loss: 3.233002, speed: 0.442400 steps/s, speed: 3.539203 samples/s, speed: 1812.072055 tokens/s, learning rate: 4.050e-06, loss_scalings: 377.789520, pp_loss: 3.270581
[INFO] 2021-07-09 16:56:23,269 [run_pretraining.py:  512]:	********exe.run_406******* 
[INFO] 2021-07-09 16:56:25,508 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:25,509 [run_pretraining.py:  534]:	loss/total_loss, 3.16892671585083, 407
[INFO] 2021-07-09 16:56:25,509 [run_pretraining.py:  535]:	loss/mlm_loss, 3.16892671585083, 407
[INFO] 2021-07-09 16:56:25,509 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.060000264871633e-06, 407
[INFO] 2021-07-09 16:56:25,509 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 407
[INFO] 2021-07-09 16:56:25,509 [run_pretraining.py:  558]:	worker_index: 6, step: 407, cost: 3.168927, mlm loss: 3.168927, speed: 0.446424 steps/s, speed: 3.571395 samples/s, speed: 1828.554099 tokens/s, learning rate: 4.060e-06, loss_scalings: 377.789520, pp_loss: 3.130406
[INFO] 2021-07-09 16:56:25,509 [run_pretraining.py:  512]:	********exe.run_407******* 
[INFO] 2021-07-09 16:56:27,767 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:27,768 [run_pretraining.py:  534]:	loss/total_loss, 3.0004031658172607, 408
[INFO] 2021-07-09 16:56:27,768 [run_pretraining.py:  535]:	loss/mlm_loss, 3.0004031658172607, 408
[INFO] 2021-07-09 16:56:27,768 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.069999704370275e-06, 408
[INFO] 2021-07-09 16:56:27,768 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 408
[INFO] 2021-07-09 16:56:27,768 [run_pretraining.py:  558]:	worker_index: 6, step: 408, cost: 3.000403, mlm loss: 3.000403, speed: 0.442752 steps/s, speed: 3.542016 samples/s, speed: 1813.512033 tokens/s, learning rate: 4.070e-06, loss_scalings: 377.789520, pp_loss: 3.016348
[INFO] 2021-07-09 16:56:27,768 [run_pretraining.py:  512]:	********exe.run_408******* 
[INFO] 2021-07-09 16:56:30,062 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:30,062 [run_pretraining.py:  534]:	loss/total_loss, 2.9052608013153076, 409
[INFO] 2021-07-09 16:56:30,063 [run_pretraining.py:  535]:	loss/mlm_loss, 2.9052608013153076, 409
[INFO] 2021-07-09 16:56:30,063 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.080000053363619e-06, 409
[INFO] 2021-07-09 16:56:30,063 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 409
[INFO] 2021-07-09 16:56:30,063 [run_pretraining.py:  558]:	worker_index: 6, step: 409, cost: 2.905261, mlm loss: 2.905261, speed: 0.435970 steps/s, speed: 3.487763 samples/s, speed: 1785.734470 tokens/s, learning rate: 4.080e-06, loss_scalings: 377.789520, pp_loss: 2.923754
[INFO] 2021-07-09 16:56:30,063 [run_pretraining.py:  512]:	********exe.run_409******* 
[INFO] 2021-07-09 16:56:32,319 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:32,320 [run_pretraining.py:  534]:	loss/total_loss, 2.8874528408050537, 410
[INFO] 2021-07-09 16:56:32,320 [run_pretraining.py:  535]:	loss/mlm_loss, 2.8874528408050537, 410
[INFO] 2021-07-09 16:56:32,320 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.089999947609613e-06, 410
[INFO] 2021-07-09 16:56:32,320 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 410
[INFO] 2021-07-09 16:56:32,321 [run_pretraining.py:  558]:	worker_index: 6, step: 410, cost: 2.887453, mlm loss: 2.887453, speed: 0.443076 steps/s, speed: 3.544607 samples/s, speed: 1814.838880 tokens/s, learning rate: 4.090e-06, loss_scalings: 377.789520, pp_loss: 2.858961
[INFO] 2021-07-09 16:56:32,321 [run_pretraining.py:  512]:	********exe.run_410******* 
[INFO] 2021-07-09 16:56:34,584 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:34,584 [run_pretraining.py:  534]:	loss/total_loss, 2.7602169513702393, 411
[INFO] 2021-07-09 16:56:34,584 [run_pretraining.py:  535]:	loss/mlm_loss, 2.7602169513702393, 411
[INFO] 2021-07-09 16:56:34,585 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.099999841855606e-06, 411
[INFO] 2021-07-09 16:56:34,585 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 411
[INFO] 2021-07-09 16:56:34,585 [run_pretraining.py:  558]:	worker_index: 6, step: 411, cost: 2.760217, mlm loss: 2.760217, speed: 0.441784 steps/s, speed: 3.534276 samples/s, speed: 1809.549203 tokens/s, learning rate: 4.100e-06, loss_scalings: 377.789520, pp_loss: 2.766142
[INFO] 2021-07-09 16:56:34,585 [run_pretraining.py:  512]:	********exe.run_411******* 
[INFO] 2021-07-09 16:56:36,825 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:36,825 [run_pretraining.py:  534]:	loss/total_loss, 2.6338839530944824, 412
[INFO] 2021-07-09 16:56:36,826 [run_pretraining.py:  535]:	loss/mlm_loss, 2.6338839530944824, 412
[INFO] 2021-07-09 16:56:36,826 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.109999736101599e-06, 412
[INFO] 2021-07-09 16:56:36,826 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 412
[INFO] 2021-07-09 16:56:36,826 [run_pretraining.py:  558]:	worker_index: 6, step: 412, cost: 2.633884, mlm loss: 2.633884, speed: 0.446346 steps/s, speed: 3.570768 samples/s, speed: 1828.233415 tokens/s, learning rate: 4.110e-06, loss_scalings: 377.789520, pp_loss: 2.632809
[INFO] 2021-07-09 16:56:36,826 [run_pretraining.py:  512]:	********exe.run_412******* 
[INFO] 2021-07-09 16:56:39,126 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:39,126 [run_pretraining.py:  534]:	loss/total_loss, 2.5167717933654785, 413
[INFO] 2021-07-09 16:56:39,126 [run_pretraining.py:  535]:	loss/mlm_loss, 2.5167717933654785, 413
[INFO] 2021-07-09 16:56:39,126 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.120000085094944e-06, 413
[INFO] 2021-07-09 16:56:39,126 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 413
[INFO] 2021-07-09 16:56:39,127 [run_pretraining.py:  558]:	worker_index: 6, step: 413, cost: 2.516772, mlm loss: 2.516772, speed: 0.434779 steps/s, speed: 3.478234 samples/s, speed: 1780.855757 tokens/s, learning rate: 4.120e-06, loss_scalings: 377.789520, pp_loss: 2.542019
[INFO] 2021-07-09 16:56:39,127 [run_pretraining.py:  512]:	********exe.run_413******* 
[INFO] 2021-07-09 16:56:41,344 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:41,345 [run_pretraining.py:  534]:	loss/total_loss, 2.43227219581604, 414
[INFO] 2021-07-09 16:56:41,345 [run_pretraining.py:  535]:	loss/mlm_loss, 2.43227219581604, 414
[INFO] 2021-07-09 16:56:41,345 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.129999979340937e-06, 414
[INFO] 2021-07-09 16:56:41,345 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 414
[INFO] 2021-07-09 16:56:41,345 [run_pretraining.py:  558]:	worker_index: 6, step: 414, cost: 2.432272, mlm loss: 2.432272, speed: 0.450901 steps/s, speed: 3.607209 samples/s, speed: 1846.891049 tokens/s, learning rate: 4.130e-06, loss_scalings: 377.789520, pp_loss: 2.450993
[INFO] 2021-07-09 16:56:41,345 [run_pretraining.py:  512]:	********exe.run_414******* 
[INFO] 2021-07-09 16:56:43,582 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:43,582 [run_pretraining.py:  534]:	loss/total_loss, 2.3612637519836426, 415
[INFO] 2021-07-09 16:56:43,582 [run_pretraining.py:  535]:	loss/mlm_loss, 2.3612637519836426, 415
[INFO] 2021-07-09 16:56:43,582 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.13999987358693e-06, 415
[INFO] 2021-07-09 16:56:43,582 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 415
[INFO] 2021-07-09 16:56:43,583 [run_pretraining.py:  558]:	worker_index: 6, step: 415, cost: 2.361264, mlm loss: 2.361264, speed: 0.447057 steps/s, speed: 3.576452 samples/s, speed: 1831.143532 tokens/s, learning rate: 4.140e-06, loss_scalings: 377.789520, pp_loss: 2.354800
[INFO] 2021-07-09 16:56:43,583 [run_pretraining.py:  512]:	********exe.run_415******* 
[INFO] 2021-07-09 16:56:45,863 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:45,864 [run_pretraining.py:  534]:	loss/total_loss, 2.340207099914551, 416
[INFO] 2021-07-09 16:56:45,864 [run_pretraining.py:  535]:	loss/mlm_loss, 2.340207099914551, 416
[INFO] 2021-07-09 16:56:45,864 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.149999767832924e-06, 416
[INFO] 2021-07-09 16:56:45,864 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 416
[INFO] 2021-07-09 16:56:45,865 [run_pretraining.py:  558]:	worker_index: 6, step: 416, cost: 2.340207, mlm loss: 2.340207, speed: 0.438356 steps/s, speed: 3.506846 samples/s, speed: 1795.505348 tokens/s, learning rate: 4.150e-06, loss_scalings: 377.789520, pp_loss: 2.335852
[INFO] 2021-07-09 16:56:45,865 [run_pretraining.py:  512]:	********exe.run_416******* 
[INFO] 2021-07-09 16:56:48,182 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:48,183 [run_pretraining.py:  534]:	loss/total_loss, 2.3453221321105957, 417
[INFO] 2021-07-09 16:56:48,183 [run_pretraining.py:  535]:	loss/mlm_loss, 2.3453221321105957, 417
[INFO] 2021-07-09 16:56:48,183 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.160000116826268e-06, 417
[INFO] 2021-07-09 16:56:48,183 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 417
[INFO] 2021-07-09 16:56:48,183 [run_pretraining.py:  558]:	worker_index: 6, step: 417, cost: 2.345322, mlm loss: 2.345322, speed: 0.431417 steps/s, speed: 3.451338 samples/s, speed: 1767.085204 tokens/s, learning rate: 4.160e-06, loss_scalings: 377.789520, pp_loss: 2.346066
[INFO] 2021-07-09 16:56:48,183 [run_pretraining.py:  512]:	********exe.run_417******* 
[INFO] 2021-07-09 16:56:50,495 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:50,496 [run_pretraining.py:  534]:	loss/total_loss, 2.324554681777954, 418
[INFO] 2021-07-09 16:56:50,496 [run_pretraining.py:  535]:	loss/mlm_loss, 2.324554681777954, 418
[INFO] 2021-07-09 16:56:50,496 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.170000011072261e-06, 418
[INFO] 2021-07-09 16:56:50,496 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 418
[INFO] 2021-07-09 16:56:50,496 [run_pretraining.py:  558]:	worker_index: 6, step: 418, cost: 2.324555, mlm loss: 2.324555, speed: 0.432411 steps/s, speed: 3.459286 samples/s, speed: 1771.154314 tokens/s, learning rate: 4.170e-06, loss_scalings: 377.789520, pp_loss: 2.332519
[INFO] 2021-07-09 16:56:50,496 [run_pretraining.py:  512]:	********exe.run_418******* 
[INFO] 2021-07-09 16:56:52,792 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:52,793 [run_pretraining.py:  534]:	loss/total_loss, 2.3308887481689453, 419
[INFO] 2021-07-09 16:56:52,793 [run_pretraining.py:  535]:	loss/mlm_loss, 2.3308887481689453, 419
[INFO] 2021-07-09 16:56:52,793 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.179999905318255e-06, 419
[INFO] 2021-07-09 16:56:52,793 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 419
[INFO] 2021-07-09 16:56:52,793 [run_pretraining.py:  558]:	worker_index: 6, step: 419, cost: 2.330889, mlm loss: 2.330889, speed: 0.435506 steps/s, speed: 3.484047 samples/s, speed: 1783.832270 tokens/s, learning rate: 4.180e-06, loss_scalings: 377.789520, pp_loss: 2.331171
[INFO] 2021-07-09 16:56:52,793 [run_pretraining.py:  512]:	********exe.run_419******* 
[INFO] 2021-07-09 16:56:55,124 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:55,125 [run_pretraining.py:  534]:	loss/total_loss, 2.380825996398926, 420
[INFO] 2021-07-09 16:56:55,125 [run_pretraining.py:  535]:	loss/mlm_loss, 2.380825996398926, 420
[INFO] 2021-07-09 16:56:55,125 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.190000254311599e-06, 420
[INFO] 2021-07-09 16:56:55,125 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 420
[INFO] 2021-07-09 16:56:55,125 [run_pretraining.py:  558]:	worker_index: 6, step: 420, cost: 2.380826, mlm loss: 2.380826, speed: 0.428927 steps/s, speed: 3.431415 samples/s, speed: 1756.884517 tokens/s, learning rate: 4.190e-06, loss_scalings: 377.789520, pp_loss: 2.349652
[INFO] 2021-07-09 16:56:55,125 [run_pretraining.py:  512]:	********exe.run_420******* 
[INFO] 2021-07-09 16:56:57,439 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:57,440 [run_pretraining.py:  534]:	loss/total_loss, 2.3542325496673584, 421
[INFO] 2021-07-09 16:56:57,440 [run_pretraining.py:  535]:	loss/mlm_loss, 2.3542325496673584, 421
[INFO] 2021-07-09 16:56:57,440 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.199999693810241e-06, 421
[INFO] 2021-07-09 16:56:57,440 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 421
[INFO] 2021-07-09 16:56:57,440 [run_pretraining.py:  558]:	worker_index: 6, step: 421, cost: 2.354233, mlm loss: 2.354233, speed: 0.432097 steps/s, speed: 3.456777 samples/s, speed: 1769.869583 tokens/s, learning rate: 4.200e-06, loss_scalings: 377.789520, pp_loss: 2.356702
[INFO] 2021-07-09 16:56:57,440 [run_pretraining.py:  512]:	********exe.run_421******* 
[INFO] 2021-07-09 16:56:59,729 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:59,730 [run_pretraining.py:  534]:	loss/total_loss, 2.3237063884735107, 422
[INFO] 2021-07-09 16:56:59,730 [run_pretraining.py:  535]:	loss/mlm_loss, 2.3237063884735107, 422
[INFO] 2021-07-09 16:56:59,730 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.2100000428035855e-06, 422
[INFO] 2021-07-09 16:56:59,730 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 422
[INFO] 2021-07-09 16:56:59,730 [run_pretraining.py:  558]:	worker_index: 6, step: 422, cost: 2.323706, mlm loss: 2.323706, speed: 0.436890 steps/s, speed: 3.495120 samples/s, speed: 1789.501668 tokens/s, learning rate: 4.210e-06, loss_scalings: 377.789520, pp_loss: 2.340775
[INFO] 2021-07-09 16:56:59,730 [run_pretraining.py:  512]:	********exe.run_422******* 
[INFO] 2021-07-09 16:57:02,027 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:02,028 [run_pretraining.py:  534]:	loss/total_loss, 2.2616305351257324, 423
[INFO] 2021-07-09 16:57:02,028 [run_pretraining.py:  535]:	loss/mlm_loss, 2.2616305351257324, 423
[INFO] 2021-07-09 16:57:02,028 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.219999937049579e-06, 423
[INFO] 2021-07-09 16:57:02,028 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 423
[INFO] 2021-07-09 16:57:02,028 [run_pretraining.py:  558]:	worker_index: 6, step: 423, cost: 2.261631, mlm loss: 2.261631, speed: 0.435245 steps/s, speed: 3.481961 samples/s, speed: 1782.763820 tokens/s, learning rate: 4.220e-06, loss_scalings: 377.789520, pp_loss: 2.259572
[INFO] 2021-07-09 16:57:02,028 [run_pretraining.py:  512]:	********exe.run_423******* 
[INFO] 2021-07-09 16:57:04,319 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:04,320 [run_pretraining.py:  534]:	loss/total_loss, 2.211897611618042, 424
[INFO] 2021-07-09 16:57:04,320 [run_pretraining.py:  535]:	loss/mlm_loss, 2.211897611618042, 424
[INFO] 2021-07-09 16:57:04,320 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.229999831295572e-06, 424
[INFO] 2021-07-09 16:57:04,320 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 424
[INFO] 2021-07-09 16:57:04,320 [run_pretraining.py:  558]:	worker_index: 6, step: 424, cost: 2.211898, mlm loss: 2.211898, speed: 0.436476 steps/s, speed: 3.491806 samples/s, speed: 1787.804808 tokens/s, learning rate: 4.230e-06, loss_scalings: 377.789520, pp_loss: 2.195451
[INFO] 2021-07-09 16:57:04,320 [run_pretraining.py:  512]:	********exe.run_424******* 
[INFO] 2021-07-09 16:57:06,551 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:06,552 [run_pretraining.py:  534]:	loss/total_loss, 2.128272294998169, 425
[INFO] 2021-07-09 16:57:06,552 [run_pretraining.py:  535]:	loss/mlm_loss, 2.128272294998169, 425
[INFO] 2021-07-09 16:57:06,552 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.2399997255415656e-06, 425
[INFO] 2021-07-09 16:57:06,552 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 425
[INFO] 2021-07-09 16:57:06,552 [run_pretraining.py:  558]:	worker_index: 6, step: 425, cost: 2.128272, mlm loss: 2.128272, speed: 0.448061 steps/s, speed: 3.584490 samples/s, speed: 1835.259054 tokens/s, learning rate: 4.240e-06, loss_scalings: 377.789520, pp_loss: 2.154808
[INFO] 2021-07-09 16:57:06,553 [run_pretraining.py:  512]:	********exe.run_425******* 
[INFO] 2021-07-09 16:57:08,818 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:08,819 [run_pretraining.py:  534]:	loss/total_loss, 2.133547306060791, 426
[INFO] 2021-07-09 16:57:08,819 [run_pretraining.py:  535]:	loss/mlm_loss, 2.133547306060791, 426
[INFO] 2021-07-09 16:57:08,819 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.25000007453491e-06, 426
[INFO] 2021-07-09 16:57:08,819 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 426
[INFO] 2021-07-09 16:57:08,819 [run_pretraining.py:  558]:	worker_index: 6, step: 426, cost: 2.133547, mlm loss: 2.133547, speed: 0.441326 steps/s, speed: 3.530605 samples/s, speed: 1807.669563 tokens/s, learning rate: 4.250e-06, loss_scalings: 377.789520, pp_loss: 2.128882
[INFO] 2021-07-09 16:57:08,819 [run_pretraining.py:  512]:	********exe.run_426******* 
[INFO] 2021-07-09 16:57:11,201 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:11,202 [run_pretraining.py:  534]:	loss/total_loss, 2.1174476146698, 427
[INFO] 2021-07-09 16:57:11,202 [run_pretraining.py:  535]:	loss/mlm_loss, 2.1174476146698, 427
[INFO] 2021-07-09 16:57:11,202 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.259999514033552e-06, 427
[INFO] 2021-07-09 16:57:11,202 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 427
[INFO] 2021-07-09 16:57:11,202 [run_pretraining.py:  558]:	worker_index: 6, step: 427, cost: 2.117448, mlm loss: 2.117448, speed: 0.419777 steps/s, speed: 3.358220 samples/s, speed: 1719.408525 tokens/s, learning rate: 4.260e-06, loss_scalings: 377.789520, pp_loss: 2.112933
[INFO] 2021-07-09 16:57:11,202 [run_pretraining.py:  512]:	********exe.run_427******* 
[INFO] 2021-07-09 16:57:13,472 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:13,473 [run_pretraining.py:  534]:	loss/total_loss, 2.076294422149658, 428
[INFO] 2021-07-09 16:57:13,473 [run_pretraining.py:  535]:	loss/mlm_loss, 2.076294422149658, 428
[INFO] 2021-07-09 16:57:13,473 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.2699998630268965e-06, 428
[INFO] 2021-07-09 16:57:13,473 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 428
[INFO] 2021-07-09 16:57:13,473 [run_pretraining.py:  558]:	worker_index: 6, step: 428, cost: 2.076294, mlm loss: 2.076294, speed: 0.440452 steps/s, speed: 3.523617 samples/s, speed: 1804.092084 tokens/s, learning rate: 4.270e-06, loss_scalings: 377.789520, pp_loss: 2.070467
[INFO] 2021-07-09 16:57:13,473 [run_pretraining.py:  512]:	********exe.run_428******* 
[INFO] 2021-07-09 16:57:15,724 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:15,725 [run_pretraining.py:  534]:	loss/total_loss, 2.0392510890960693, 429
[INFO] 2021-07-09 16:57:15,725 [run_pretraining.py:  535]:	loss/mlm_loss, 2.0392510890960693, 429
[INFO] 2021-07-09 16:57:15,725 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.280000212020241e-06, 429
[INFO] 2021-07-09 16:57:15,725 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 429
[INFO] 2021-07-09 16:57:15,725 [run_pretraining.py:  558]:	worker_index: 6, step: 429, cost: 2.039251, mlm loss: 2.039251, speed: 0.444148 steps/s, speed: 3.553184 samples/s, speed: 1819.230170 tokens/s, learning rate: 4.280e-06, loss_scalings: 377.789520, pp_loss: 2.048923
[INFO] 2021-07-09 16:57:15,725 [run_pretraining.py:  512]:	********exe.run_429******* 
[INFO] 2021-07-09 16:57:17,954 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:17,955 [run_pretraining.py:  534]:	loss/total_loss, 2.0106656551361084, 430
[INFO] 2021-07-09 16:57:17,955 [run_pretraining.py:  535]:	loss/mlm_loss, 2.0106656551361084, 430
[INFO] 2021-07-09 16:57:17,955 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.289999651518883e-06, 430
[INFO] 2021-07-09 16:57:17,955 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 430
[INFO] 2021-07-09 16:57:17,955 [run_pretraining.py:  558]:	worker_index: 6, step: 430, cost: 2.010666, mlm loss: 2.010666, speed: 0.448589 steps/s, speed: 3.588714 samples/s, speed: 1837.421522 tokens/s, learning rate: 4.290e-06, loss_scalings: 377.789520, pp_loss: 2.012163
[INFO] 2021-07-09 16:57:17,955 [run_pretraining.py:  512]:	********exe.run_430******* 
[INFO] 2021-07-09 16:57:20,179 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:20,180 [run_pretraining.py:  534]:	loss/total_loss, 2.0279626846313477, 431
[INFO] 2021-07-09 16:57:20,180 [run_pretraining.py:  535]:	loss/mlm_loss, 2.0279626846313477, 431
[INFO] 2021-07-09 16:57:20,180 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.300000000512227e-06, 431
[INFO] 2021-07-09 16:57:20,180 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 431
[INFO] 2021-07-09 16:57:20,180 [run_pretraining.py:  558]:	worker_index: 6, step: 431, cost: 2.027963, mlm loss: 2.027963, speed: 0.449631 steps/s, speed: 3.597051 samples/s, speed: 1841.689915 tokens/s, learning rate: 4.300e-06, loss_scalings: 377.789520, pp_loss: 2.021640
[INFO] 2021-07-09 16:57:20,180 [run_pretraining.py:  512]:	********exe.run_431******* 
[INFO] 2021-07-09 16:57:22,442 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:22,442 [run_pretraining.py:  534]:	loss/total_loss, 2.0149335861206055, 432
[INFO] 2021-07-09 16:57:22,443 [run_pretraining.py:  535]:	loss/mlm_loss, 2.0149335861206055, 432
[INFO] 2021-07-09 16:57:22,443 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.309999894758221e-06, 432
[INFO] 2021-07-09 16:57:22,443 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 432
[INFO] 2021-07-09 16:57:22,443 [run_pretraining.py:  558]:	worker_index: 6, step: 432, cost: 2.014934, mlm loss: 2.014934, speed: 0.442032 steps/s, speed: 3.536253 samples/s, speed: 1810.561470 tokens/s, learning rate: 4.310e-06, loss_scalings: 377.789520, pp_loss: 2.021683
[INFO] 2021-07-09 16:57:22,443 [run_pretraining.py:  512]:	********exe.run_432******* 
[INFO] 2021-07-09 16:57:24,868 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:24,869 [run_pretraining.py:  534]:	loss/total_loss, 2.011706829071045, 433
[INFO] 2021-07-09 16:57:24,869 [run_pretraining.py:  535]:	loss/mlm_loss, 2.011706829071045, 433
[INFO] 2021-07-09 16:57:24,869 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.319999789004214e-06, 433
[INFO] 2021-07-09 16:57:24,869 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 433
[INFO] 2021-07-09 16:57:24,869 [run_pretraining.py:  558]:	worker_index: 6, step: 433, cost: 2.011707, mlm loss: 2.011707, speed: 0.412233 steps/s, speed: 3.297861 samples/s, speed: 1688.504947 tokens/s, learning rate: 4.320e-06, loss_scalings: 377.789520, pp_loss: 1.996805
[INFO] 2021-07-09 16:57:24,869 [run_pretraining.py:  512]:	********exe.run_433******* 
[INFO] 2021-07-09 16:57:27,215 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:27,216 [run_pretraining.py:  534]:	loss/total_loss, 1.9310520887374878, 434
[INFO] 2021-07-09 16:57:27,216 [run_pretraining.py:  535]:	loss/mlm_loss, 1.9310520887374878, 434
[INFO] 2021-07-09 16:57:27,216 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.3299996832502075e-06, 434
[INFO] 2021-07-09 16:57:27,216 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 434
[INFO] 2021-07-09 16:57:27,216 [run_pretraining.py:  558]:	worker_index: 6, step: 434, cost: 1.931052, mlm loss: 1.931052, speed: 0.426266 steps/s, speed: 3.410129 samples/s, speed: 1745.985897 tokens/s, learning rate: 4.330e-06, loss_scalings: 377.789520, pp_loss: 1.945179
[INFO] 2021-07-09 16:57:27,216 [run_pretraining.py:  512]:	********exe.run_434******* 
[INFO] 2021-07-09 16:57:29,594 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:29,595 [run_pretraining.py:  534]:	loss/total_loss, 1.8875977993011475, 435
[INFO] 2021-07-09 16:57:29,595 [run_pretraining.py:  535]:	loss/mlm_loss, 1.8875977993011475, 435
[INFO] 2021-07-09 16:57:29,595 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.340000032243552e-06, 435
[INFO] 2021-07-09 16:57:29,595 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 435
[INFO] 2021-07-09 16:57:29,595 [run_pretraining.py:  558]:	worker_index: 6, step: 435, cost: 1.887598, mlm loss: 1.887598, speed: 0.420363 steps/s, speed: 3.362900 samples/s, speed: 1721.805021 tokens/s, learning rate: 4.340e-06, loss_scalings: 377.789520, pp_loss: 1.903539
[INFO] 2021-07-09 16:57:29,596 [run_pretraining.py:  512]:	********exe.run_435******* 
[INFO] 2021-07-09 16:57:32,061 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:32,062 [run_pretraining.py:  534]:	loss/total_loss, 1.9267265796661377, 436
[INFO] 2021-07-09 16:57:32,062 [run_pretraining.py:  535]:	loss/mlm_loss, 1.9267265796661377, 436
[INFO] 2021-07-09 16:57:32,062 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.349999926489545e-06, 436
[INFO] 2021-07-09 16:57:32,062 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 436
[INFO] 2021-07-09 16:57:32,062 [run_pretraining.py:  558]:	worker_index: 6, step: 436, cost: 1.926727, mlm loss: 1.926727, speed: 0.405491 steps/s, speed: 3.243927 samples/s, speed: 1660.890807 tokens/s, learning rate: 4.350e-06, loss_scalings: 377.789520, pp_loss: 1.885354
[INFO] 2021-07-09 16:57:32,062 [run_pretraining.py:  512]:	********exe.run_436******* 
[INFO] 2021-07-09 16:57:34,443 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:34,444 [run_pretraining.py:  534]:	loss/total_loss, 1.85740065574646, 437
[INFO] 2021-07-09 16:57:34,444 [run_pretraining.py:  535]:	loss/mlm_loss, 1.85740065574646, 437
[INFO] 2021-07-09 16:57:34,444 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.359999820735538e-06, 437
[INFO] 2021-07-09 16:57:34,444 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 437
[INFO] 2021-07-09 16:57:34,445 [run_pretraining.py:  558]:	worker_index: 6, step: 437, cost: 1.857401, mlm loss: 1.857401, speed: 0.419898 steps/s, speed: 3.359181 samples/s, speed: 1719.900652 tokens/s, learning rate: 4.360e-06, loss_scalings: 377.789520, pp_loss: 1.852373
[INFO] 2021-07-09 16:57:34,445 [run_pretraining.py:  512]:	********exe.run_437******* 
[INFO] 2021-07-09 16:57:36,856 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:36,857 [run_pretraining.py:  534]:	loss/total_loss, 1.848963975906372, 438
[INFO] 2021-07-09 16:57:36,857 [run_pretraining.py:  535]:	loss/mlm_loss, 1.848963975906372, 438
[INFO] 2021-07-09 16:57:36,857 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.369999714981532e-06, 438
[INFO] 2021-07-09 16:57:36,857 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 438
[INFO] 2021-07-09 16:57:36,857 [run_pretraining.py:  558]:	worker_index: 6, step: 438, cost: 1.848964, mlm loss: 1.848964, speed: 0.414551 steps/s, speed: 3.316404 samples/s, speed: 1697.999092 tokens/s, learning rate: 4.370e-06, loss_scalings: 377.789520, pp_loss: 1.845140
[INFO] 2021-07-09 16:57:36,858 [run_pretraining.py:  512]:	********exe.run_438******* 
[INFO] 2021-07-09 16:57:39,326 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:39,327 [run_pretraining.py:  534]:	loss/total_loss, 1.826086401939392, 439
[INFO] 2021-07-09 16:57:39,327 [run_pretraining.py:  535]:	loss/mlm_loss, 1.826086401939392, 439
[INFO] 2021-07-09 16:57:39,327 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.380000063974876e-06, 439
[INFO] 2021-07-09 16:57:39,327 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 439
[INFO] 2021-07-09 16:57:39,327 [run_pretraining.py:  558]:	worker_index: 6, step: 439, cost: 1.826086, mlm loss: 1.826086, speed: 0.404993 steps/s, speed: 3.239947 samples/s, speed: 1658.852797 tokens/s, learning rate: 4.380e-06, loss_scalings: 377.789520, pp_loss: 1.813740
[INFO] 2021-07-09 16:57:39,327 [run_pretraining.py:  512]:	********exe.run_439******* 
[INFO] 2021-07-09 16:57:41,986 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:41,987 [run_pretraining.py:  534]:	loss/total_loss, 1.8037991523742676, 440
[INFO] 2021-07-09 16:57:41,987 [run_pretraining.py:  535]:	loss/mlm_loss, 1.8037991523742676, 440
[INFO] 2021-07-09 16:57:41,987 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.389999958220869e-06, 440
[INFO] 2021-07-09 16:57:41,987 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 440
[INFO] 2021-07-09 16:57:41,987 [run_pretraining.py:  558]:	worker_index: 6, step: 440, cost: 1.803799, mlm loss: 1.803799, speed: 0.376108 steps/s, speed: 3.008868 samples/s, speed: 1540.540252 tokens/s, learning rate: 4.390e-06, loss_scalings: 377.789520, pp_loss: 1.802708
[INFO] 2021-07-09 16:57:41,987 [run_pretraining.py:  512]:	********exe.run_440******* 
[INFO] 2021-07-09 16:57:44,217 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:44,218 [run_pretraining.py:  534]:	loss/total_loss, 1.785142183303833, 441
[INFO] 2021-07-09 16:57:44,218 [run_pretraining.py:  535]:	loss/mlm_loss, 1.785142183303833, 441
[INFO] 2021-07-09 16:57:44,218 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.399999852466863e-06, 441
[INFO] 2021-07-09 16:57:44,218 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 441
[INFO] 2021-07-09 16:57:44,218 [run_pretraining.py:  558]:	worker_index: 6, step: 441, cost: 1.785142, mlm loss: 1.785142, speed: 0.448304 steps/s, speed: 3.586428 samples/s, speed: 1836.251230 tokens/s, learning rate: 4.400e-06, loss_scalings: 377.789520, pp_loss: 1.769288
[INFO] 2021-07-09 16:57:44,218 [run_pretraining.py:  512]:	********exe.run_441******* 
[INFO] 2021-07-09 16:57:46,504 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:46,504 [run_pretraining.py:  534]:	loss/total_loss, 1.7629382610321045, 442
[INFO] 2021-07-09 16:57:46,504 [run_pretraining.py:  535]:	loss/mlm_loss, 1.7629382610321045, 442
[INFO] 2021-07-09 16:57:46,504 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.410000201460207e-06, 442
[INFO] 2021-07-09 16:57:46,504 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 442
[INFO] 2021-07-09 16:57:46,505 [run_pretraining.py:  558]:	worker_index: 6, step: 442, cost: 1.762938, mlm loss: 1.762938, speed: 0.437495 steps/s, speed: 3.499961 samples/s, speed: 1791.979920 tokens/s, learning rate: 4.410e-06, loss_scalings: 377.789520, pp_loss: 1.750907
[INFO] 2021-07-09 16:57:46,505 [run_pretraining.py:  512]:	********exe.run_442******* 
[INFO] 2021-07-09 16:57:48,763 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:48,764 [run_pretraining.py:  534]:	loss/total_loss, 1.7318469285964966, 443
[INFO] 2021-07-09 16:57:48,764 [run_pretraining.py:  535]:	loss/mlm_loss, 1.7318469285964966, 443
[INFO] 2021-07-09 16:57:48,764 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.419999640958849e-06, 443
[INFO] 2021-07-09 16:57:48,764 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 443
[INFO] 2021-07-09 16:57:48,764 [run_pretraining.py:  558]:	worker_index: 6, step: 443, cost: 1.731847, mlm loss: 1.731847, speed: 0.442717 steps/s, speed: 3.541734 samples/s, speed: 1813.367702 tokens/s, learning rate: 4.420e-06, loss_scalings: 377.789520, pp_loss: 1.740179
[INFO] 2021-07-09 16:57:48,764 [run_pretraining.py:  512]:	********exe.run_443******* 
[INFO] 2021-07-09 16:57:51,023 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:51,023 [run_pretraining.py:  534]:	loss/total_loss, 1.7455297708511353, 444
[INFO] 2021-07-09 16:57:51,024 [run_pretraining.py:  535]:	loss/mlm_loss, 1.7455297708511353, 444
[INFO] 2021-07-09 16:57:51,024 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.4299999899521936e-06, 444
[INFO] 2021-07-09 16:57:51,024 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 444
[INFO] 2021-07-09 16:57:51,024 [run_pretraining.py:  558]:	worker_index: 6, step: 444, cost: 1.745530, mlm loss: 1.745530, speed: 0.442660 steps/s, speed: 3.541280 samples/s, speed: 1813.135367 tokens/s, learning rate: 4.430e-06, loss_scalings: 377.789520, pp_loss: 1.739364
[INFO] 2021-07-09 16:57:51,024 [run_pretraining.py:  512]:	********exe.run_444******* 
[INFO] 2021-07-09 16:57:53,360 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:53,360 [run_pretraining.py:  534]:	loss/total_loss, 1.762450933456421, 445
[INFO] 2021-07-09 16:57:53,360 [run_pretraining.py:  535]:	loss/mlm_loss, 1.762450933456421, 445
[INFO] 2021-07-09 16:57:53,360 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.439999884198187e-06, 445
[INFO] 2021-07-09 16:57:53,360 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 445
[INFO] 2021-07-09 16:57:53,360 [run_pretraining.py:  558]:	worker_index: 6, step: 445, cost: 1.762451, mlm loss: 1.762451, speed: 0.428067 steps/s, speed: 3.424537 samples/s, speed: 1753.362945 tokens/s, learning rate: 4.440e-06, loss_scalings: 377.789520, pp_loss: 1.742928
[INFO] 2021-07-09 16:57:53,361 [run_pretraining.py:  512]:	********exe.run_445******* 
[INFO] 2021-07-09 16:57:55,660 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:55,661 [run_pretraining.py:  534]:	loss/total_loss, 1.687054991722107, 446
[INFO] 2021-07-09 16:57:55,661 [run_pretraining.py:  535]:	loss/mlm_loss, 1.687054991722107, 446
[INFO] 2021-07-09 16:57:55,661 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.44999977844418e-06, 446
[INFO] 2021-07-09 16:57:55,661 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 446
[INFO] 2021-07-09 16:57:55,661 [run_pretraining.py:  558]:	worker_index: 6, step: 446, cost: 1.687055, mlm loss: 1.687055, speed: 0.434807 steps/s, speed: 3.478452 samples/s, speed: 1780.967448 tokens/s, learning rate: 4.450e-06, loss_scalings: 377.789520, pp_loss: 1.717670
[INFO] 2021-07-09 16:57:55,661 [run_pretraining.py:  512]:	********exe.run_446******* 
[INFO] 2021-07-09 16:57:57,905 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:57,906 [run_pretraining.py:  534]:	loss/total_loss, 1.658677101135254, 447
[INFO] 2021-07-09 16:57:57,906 [run_pretraining.py:  535]:	loss/mlm_loss, 1.658677101135254, 447
[INFO] 2021-07-09 16:57:57,906 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.459999672690174e-06, 447
[INFO] 2021-07-09 16:57:57,906 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 447
[INFO] 2021-07-09 16:57:57,906 [run_pretraining.py:  558]:	worker_index: 6, step: 447, cost: 1.658677, mlm loss: 1.658677, speed: 0.445485 steps/s, speed: 3.563878 samples/s, speed: 1824.705746 tokens/s, learning rate: 4.460e-06, loss_scalings: 377.789520, pp_loss: 1.677217
[INFO] 2021-07-09 16:57:57,907 [run_pretraining.py:  512]:	********exe.run_447******* 
[INFO] 2021-07-09 16:58:00,169 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:00,169 [run_pretraining.py:  534]:	loss/total_loss, 1.6532020568847656, 448
[INFO] 2021-07-09 16:58:00,169 [run_pretraining.py:  535]:	loss/mlm_loss, 1.6532020568847656, 448
[INFO] 2021-07-09 16:58:00,169 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.470000021683518e-06, 448
[INFO] 2021-07-09 16:58:00,169 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 448
[INFO] 2021-07-09 16:58:00,170 [run_pretraining.py:  558]:	worker_index: 6, step: 448, cost: 1.653202, mlm loss: 1.653202, speed: 0.442011 steps/s, speed: 3.536090 samples/s, speed: 1810.477898 tokens/s, learning rate: 4.470e-06, loss_scalings: 377.789520, pp_loss: 1.652242
[INFO] 2021-07-09 16:58:00,170 [run_pretraining.py:  512]:	********exe.run_448******* 
[INFO] 2021-07-09 16:58:02,395 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:02,396 [run_pretraining.py:  534]:	loss/total_loss, 1.5838817358016968, 449
[INFO] 2021-07-09 16:58:02,396 [run_pretraining.py:  535]:	loss/mlm_loss, 1.5838817358016968, 449
[INFO] 2021-07-09 16:58:02,396 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.479999915929511e-06, 449
[INFO] 2021-07-09 16:58:02,396 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 449
[INFO] 2021-07-09 16:58:02,396 [run_pretraining.py:  558]:	worker_index: 6, step: 449, cost: 1.583882, mlm loss: 1.583882, speed: 0.449294 steps/s, speed: 3.594351 samples/s, speed: 1840.307955 tokens/s, learning rate: 4.480e-06, loss_scalings: 377.789520, pp_loss: 1.602030
[INFO] 2021-07-09 16:58:02,396 [run_pretraining.py:  512]:	********exe.run_449******* 
[INFO] 2021-07-09 16:58:04,698 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:04,699 [run_pretraining.py:  534]:	loss/total_loss, 1.552126169204712, 450
[INFO] 2021-07-09 16:58:04,699 [run_pretraining.py:  535]:	loss/mlm_loss, 1.552126169204712, 450
[INFO] 2021-07-09 16:58:04,699 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.4899998101755045e-06, 450
[INFO] 2021-07-09 16:58:04,699 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 450
[INFO] 2021-07-09 16:58:04,699 [run_pretraining.py:  558]:	worker_index: 6, step: 450, cost: 1.552126, mlm loss: 1.552126, speed: 0.434249 steps/s, speed: 3.473990 samples/s, speed: 1778.682871 tokens/s, learning rate: 4.490e-06, loss_scalings: 377.789520, pp_loss: 1.551607
[INFO] 2021-07-09 16:58:04,700 [run_pretraining.py:  512]:	********exe.run_450******* 
[INFO] 2021-07-09 16:58:06,951 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:06,952 [run_pretraining.py:  534]:	loss/total_loss, 1.510791540145874, 451
[INFO] 2021-07-09 16:58:06,952 [run_pretraining.py:  535]:	loss/mlm_loss, 1.510791540145874, 451
[INFO] 2021-07-09 16:58:06,952 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.500000159168849e-06, 451
[INFO] 2021-07-09 16:58:06,952 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 451
[INFO] 2021-07-09 16:58:06,952 [run_pretraining.py:  558]:	worker_index: 6, step: 451, cost: 1.510792, mlm loss: 1.510792, speed: 0.444022 steps/s, speed: 3.552174 samples/s, speed: 1818.712875 tokens/s, learning rate: 4.500e-06, loss_scalings: 377.789520, pp_loss: 1.511778
[INFO] 2021-07-09 16:58:06,952 [run_pretraining.py:  512]:	********exe.run_451******* 
[INFO] 2021-07-09 16:58:09,223 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:09,224 [run_pretraining.py:  534]:	loss/total_loss, 1.466803789138794, 452
[INFO] 2021-07-09 16:58:09,224 [run_pretraining.py:  535]:	loss/mlm_loss, 1.466803789138794, 452
[INFO] 2021-07-09 16:58:09,224 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.510000053414842e-06, 452
[INFO] 2021-07-09 16:58:09,224 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 452
[INFO] 2021-07-09 16:58:09,224 [run_pretraining.py:  558]:	worker_index: 6, step: 452, cost: 1.466804, mlm loss: 1.466804, speed: 0.440335 steps/s, speed: 3.522679 samples/s, speed: 1803.611574 tokens/s, learning rate: 4.510e-06, loss_scalings: 377.789520, pp_loss: 1.480383
[INFO] 2021-07-09 16:58:09,224 [run_pretraining.py:  512]:	********exe.run_452******* 
[INFO] 2021-07-09 16:58:11,452 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:11,453 [run_pretraining.py:  534]:	loss/total_loss, 1.4615856409072876, 453
[INFO] 2021-07-09 16:58:11,453 [run_pretraining.py:  535]:	loss/mlm_loss, 1.4615856409072876, 453
[INFO] 2021-07-09 16:58:11,453 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.5199999476608355e-06, 453
[INFO] 2021-07-09 16:58:11,453 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 453
[INFO] 2021-07-09 16:58:11,453 [run_pretraining.py:  558]:	worker_index: 6, step: 453, cost: 1.461586, mlm loss: 1.461586, speed: 0.448761 steps/s, speed: 3.590085 samples/s, speed: 1838.123745 tokens/s, learning rate: 4.520e-06, loss_scalings: 377.789520, pp_loss: 1.471074
[INFO] 2021-07-09 16:58:11,453 [run_pretraining.py:  512]:	********exe.run_453******* 
[INFO] 2021-07-09 16:58:13,698 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:13,698 [run_pretraining.py:  534]:	loss/total_loss, 1.453756332397461, 454
[INFO] 2021-07-09 16:58:13,699 [run_pretraining.py:  535]:	loss/mlm_loss, 1.453756332397461, 454
[INFO] 2021-07-09 16:58:13,699 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.529999841906829e-06, 454
[INFO] 2021-07-09 16:58:13,699 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 454
[INFO] 2021-07-09 16:58:13,699 [run_pretraining.py:  558]:	worker_index: 6, step: 454, cost: 1.453756, mlm loss: 1.453756, speed: 0.445397 steps/s, speed: 3.563173 samples/s, speed: 1824.344565 tokens/s, learning rate: 4.530e-06, loss_scalings: 377.789520, pp_loss: 1.461677
[INFO] 2021-07-09 16:58:13,699 [run_pretraining.py:  512]:	********exe.run_454******* 
[INFO] 2021-07-09 16:58:15,926 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:15,927 [run_pretraining.py:  534]:	loss/total_loss, 1.4282963275909424, 455
[INFO] 2021-07-09 16:58:15,927 [run_pretraining.py:  535]:	loss/mlm_loss, 1.4282963275909424, 455
[INFO] 2021-07-09 16:58:15,927 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.540000190900173e-06, 455
[INFO] 2021-07-09 16:58:15,927 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 455
[INFO] 2021-07-09 16:58:15,927 [run_pretraining.py:  558]:	worker_index: 6, step: 455, cost: 1.428296, mlm loss: 1.428296, speed: 0.448951 steps/s, speed: 3.591611 samples/s, speed: 1838.904645 tokens/s, learning rate: 4.540e-06, loss_scalings: 377.789520, pp_loss: 1.427529
[INFO] 2021-07-09 16:58:15,927 [run_pretraining.py:  512]:	********exe.run_455******* 
[INFO] 2021-07-09 16:58:18,175 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:18,176 [run_pretraining.py:  534]:	loss/total_loss, 1.4147076606750488, 456
[INFO] 2021-07-09 16:58:18,176 [run_pretraining.py:  535]:	loss/mlm_loss, 1.4147076606750488, 456
[INFO] 2021-07-09 16:58:18,176 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.5499996303988155e-06, 456
[INFO] 2021-07-09 16:58:18,176 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 456
[INFO] 2021-07-09 16:58:18,176 [run_pretraining.py:  558]:	worker_index: 6, step: 456, cost: 1.414708, mlm loss: 1.414708, speed: 0.444744 steps/s, speed: 3.557954 samples/s, speed: 1821.672510 tokens/s, learning rate: 4.550e-06, loss_scalings: 377.789520, pp_loss: 1.417371
[INFO] 2021-07-09 16:58:18,176 [run_pretraining.py:  512]:	********exe.run_456******* 
[INFO] 2021-07-09 16:58:20,408 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:20,408 [run_pretraining.py:  534]:	loss/total_loss, 1.4127546548843384, 457
[INFO] 2021-07-09 16:58:20,408 [run_pretraining.py:  535]:	loss/mlm_loss, 1.4127546548843384, 457
[INFO] 2021-07-09 16:58:20,408 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.55999997939216e-06, 457
[INFO] 2021-07-09 16:58:20,409 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 457
[INFO] 2021-07-09 16:58:20,409 [run_pretraining.py:  558]:	worker_index: 6, step: 457, cost: 1.412755, mlm loss: 1.412755, speed: 0.448056 steps/s, speed: 3.584447 samples/s, speed: 1835.236705 tokens/s, learning rate: 4.560e-06, loss_scalings: 377.789520, pp_loss: 1.413362
[INFO] 2021-07-09 16:58:20,409 [run_pretraining.py:  512]:	********exe.run_457******* 
[INFO] 2021-07-09 16:58:22,655 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:22,656 [run_pretraining.py:  534]:	loss/total_loss, 1.4178285598754883, 458
[INFO] 2021-07-09 16:58:22,656 [run_pretraining.py:  535]:	loss/mlm_loss, 1.4178285598754883, 458
[INFO] 2021-07-09 16:58:22,656 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.569999873638153e-06, 458
[INFO] 2021-07-09 16:58:22,656 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 458
[INFO] 2021-07-09 16:58:22,656 [run_pretraining.py:  558]:	worker_index: 6, step: 458, cost: 1.417829, mlm loss: 1.417829, speed: 0.445044 steps/s, speed: 3.560353 samples/s, speed: 1822.900493 tokens/s, learning rate: 4.570e-06, loss_scalings: 377.789520, pp_loss: 1.412586
[INFO] 2021-07-09 16:58:22,656 [run_pretraining.py:  512]:	********exe.run_458******* 
[INFO] 2021-07-09 16:58:24,923 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:24,924 [run_pretraining.py:  534]:	loss/total_loss, 1.4171415567398071, 459
[INFO] 2021-07-09 16:58:24,924 [run_pretraining.py:  535]:	loss/mlm_loss, 1.4171415567398071, 459
[INFO] 2021-07-09 16:58:24,924 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.579999767884146e-06, 459
[INFO] 2021-07-09 16:58:24,924 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 459
[INFO] 2021-07-09 16:58:24,924 [run_pretraining.py:  558]:	worker_index: 6, step: 459, cost: 1.417142, mlm loss: 1.417142, speed: 0.441048 steps/s, speed: 3.528383 samples/s, speed: 1806.532102 tokens/s, learning rate: 4.580e-06, loss_scalings: 377.789520, pp_loss: 1.417519
[INFO] 2021-07-09 16:58:24,924 [run_pretraining.py:  512]:	********exe.run_459******* 
[INFO] 2021-07-09 16:58:27,174 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:27,174 [run_pretraining.py:  534]:	loss/total_loss, 1.4257266521453857, 460
[INFO] 2021-07-09 16:58:27,175 [run_pretraining.py:  535]:	loss/mlm_loss, 1.4257266521453857, 460
[INFO] 2021-07-09 16:58:27,175 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.58999966213014e-06, 460
[INFO] 2021-07-09 16:58:27,175 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 460
[INFO] 2021-07-09 16:58:27,175 [run_pretraining.py:  558]:	worker_index: 6, step: 460, cost: 1.425727, mlm loss: 1.425727, speed: 0.444477 steps/s, speed: 3.555815 samples/s, speed: 1820.577170 tokens/s, learning rate: 4.590e-06, loss_scalings: 377.789520, pp_loss: 1.432174
[INFO] 2021-07-09 16:58:27,175 [run_pretraining.py:  512]:	********exe.run_460******* 
[INFO] 2021-07-09 16:58:29,411 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:29,412 [run_pretraining.py:  534]:	loss/total_loss, 1.4752789735794067, 461
[INFO] 2021-07-09 16:58:29,412 [run_pretraining.py:  535]:	loss/mlm_loss, 1.4752789735794067, 461
[INFO] 2021-07-09 16:58:29,412 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.600000011123484e-06, 461
[INFO] 2021-07-09 16:58:29,412 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 461
[INFO] 2021-07-09 16:58:29,412 [run_pretraining.py:  558]:	worker_index: 6, step: 461, cost: 1.475279, mlm loss: 1.475279, speed: 0.447150 steps/s, speed: 3.577198 samples/s, speed: 1831.525374 tokens/s, learning rate: 4.600e-06, loss_scalings: 377.789520, pp_loss: 1.458205
[INFO] 2021-07-09 16:58:29,412 [run_pretraining.py:  512]:	********exe.run_461******* 
[INFO] 2021-07-09 16:58:31,636 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:31,637 [run_pretraining.py:  534]:	loss/total_loss, 1.4789174795150757, 462
[INFO] 2021-07-09 16:58:31,637 [run_pretraining.py:  535]:	loss/mlm_loss, 1.4789174795150757, 462
[INFO] 2021-07-09 16:58:31,637 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.609999905369477e-06, 462
[INFO] 2021-07-09 16:58:31,637 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 462
[INFO] 2021-07-09 16:58:31,637 [run_pretraining.py:  558]:	worker_index: 6, step: 462, cost: 1.478917, mlm loss: 1.478917, speed: 0.449533 steps/s, speed: 3.596262 samples/s, speed: 1841.286062 tokens/s, learning rate: 4.610e-06, loss_scalings: 377.789520, pp_loss: 1.469986
[INFO] 2021-07-09 16:58:31,637 [run_pretraining.py:  512]:	********exe.run_462******* 
[INFO] 2021-07-09 16:58:33,840 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:33,840 [run_pretraining.py:  534]:	loss/total_loss, 1.4740697145462036, 463
[INFO] 2021-07-09 16:58:33,840 [run_pretraining.py:  535]:	loss/mlm_loss, 1.4740697145462036, 463
[INFO] 2021-07-09 16:58:33,840 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.619999799615471e-06, 463
[INFO] 2021-07-09 16:58:33,841 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 463
[INFO] 2021-07-09 16:58:33,841 [run_pretraining.py:  558]:	worker_index: 6, step: 463, cost: 1.474070, mlm loss: 1.474070, speed: 0.453947 steps/s, speed: 3.631574 samples/s, speed: 1859.366047 tokens/s, learning rate: 4.620e-06, loss_scalings: 377.789520, pp_loss: 1.469391
[INFO] 2021-07-09 16:58:33,841 [run_pretraining.py:  512]:	********exe.run_463******* 
[INFO] 2021-07-09 16:58:36,077 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:36,077 [run_pretraining.py:  534]:	loss/total_loss, 1.4575616121292114, 464
[INFO] 2021-07-09 16:58:36,077 [run_pretraining.py:  535]:	loss/mlm_loss, 1.4575616121292114, 464
[INFO] 2021-07-09 16:58:36,078 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.630000148608815e-06, 464
[INFO] 2021-07-09 16:58:36,078 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 464
[INFO] 2021-07-09 16:58:36,078 [run_pretraining.py:  558]:	worker_index: 6, step: 464, cost: 1.457562, mlm loss: 1.457562, speed: 0.447142 steps/s, speed: 3.577140 samples/s, speed: 1831.495500 tokens/s, learning rate: 4.630e-06, loss_scalings: 377.789520, pp_loss: 1.449497
[INFO] 2021-07-09 16:58:36,078 [run_pretraining.py:  512]:	********exe.run_464******* 
[INFO] 2021-07-09 16:58:38,303 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:38,304 [run_pretraining.py:  534]:	loss/total_loss, 1.4318132400512695, 465
[INFO] 2021-07-09 16:58:38,304 [run_pretraining.py:  535]:	loss/mlm_loss, 1.4318132400512695, 465
[INFO] 2021-07-09 16:58:38,304 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.640000042854808e-06, 465
[INFO] 2021-07-09 16:58:38,304 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 465
[INFO] 2021-07-09 16:58:38,304 [run_pretraining.py:  558]:	worker_index: 6, step: 465, cost: 1.431813, mlm loss: 1.431813, speed: 0.449350 steps/s, speed: 3.594801 samples/s, speed: 1840.538237 tokens/s, learning rate: 4.640e-06, loss_scalings: 377.789520, pp_loss: 1.423582
[INFO] 2021-07-09 16:58:38,304 [run_pretraining.py:  512]:	********exe.run_465******* 
[INFO] 2021-07-09 16:58:40,555 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:40,556 [run_pretraining.py:  534]:	loss/total_loss, 1.3706133365631104, 466
[INFO] 2021-07-09 16:58:40,556 [run_pretraining.py:  535]:	loss/mlm_loss, 1.3706133365631104, 466
[INFO] 2021-07-09 16:58:40,556 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.649999937100802e-06, 466
[INFO] 2021-07-09 16:58:40,556 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 466
[INFO] 2021-07-09 16:58:40,557 [run_pretraining.py:  558]:	worker_index: 6, step: 466, cost: 1.370613, mlm loss: 1.370613, speed: 0.444057 steps/s, speed: 3.552457 samples/s, speed: 1818.857865 tokens/s, learning rate: 4.650e-06, loss_scalings: 377.789520, pp_loss: 1.374041
[INFO] 2021-07-09 16:58:40,557 [run_pretraining.py:  512]:	********exe.run_466******* 
[INFO] 2021-07-09 16:58:42,757 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:42,758 [run_pretraining.py:  534]:	loss/total_loss, 1.3623849153518677, 467
[INFO] 2021-07-09 16:58:42,758 [run_pretraining.py:  535]:	loss/mlm_loss, 1.3623849153518677, 467
[INFO] 2021-07-09 16:58:42,758 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.659999831346795e-06, 467
[INFO] 2021-07-09 16:58:42,758 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 467
[INFO] 2021-07-09 16:58:42,758 [run_pretraining.py:  558]:	worker_index: 6, step: 467, cost: 1.362385, mlm loss: 1.362385, speed: 0.454402 steps/s, speed: 3.635213 samples/s, speed: 1861.228960 tokens/s, learning rate: 4.660e-06, loss_scalings: 377.789520, pp_loss: 1.335961
[INFO] 2021-07-09 16:58:42,758 [run_pretraining.py:  512]:	********exe.run_467******* 
[INFO] 2021-07-09 16:58:45,114 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:45,114 [run_pretraining.py:  534]:	loss/total_loss, 1.2822439670562744, 468
[INFO] 2021-07-09 16:58:45,115 [run_pretraining.py:  535]:	loss/mlm_loss, 1.2822439670562744, 468
[INFO] 2021-07-09 16:58:45,115 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.670000180340139e-06, 468
[INFO] 2021-07-09 16:58:45,115 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 468
[INFO] 2021-07-09 16:58:45,115 [run_pretraining.py:  558]:	worker_index: 6, step: 468, cost: 1.282244, mlm loss: 1.282244, speed: 0.424393 steps/s, speed: 3.395143 samples/s, speed: 1738.313012 tokens/s, learning rate: 4.670e-06, loss_scalings: 377.789520, pp_loss: 1.295728
[INFO] 2021-07-09 16:58:45,115 [run_pretraining.py:  512]:	********exe.run_468******* 
[INFO] 2021-07-09 16:58:47,312 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:47,312 [run_pretraining.py:  534]:	loss/total_loss, 1.3019185066223145, 469
[INFO] 2021-07-09 16:58:47,312 [run_pretraining.py:  535]:	loss/mlm_loss, 1.3019185066223145, 469
[INFO] 2021-07-09 16:58:47,312 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.679999619838782e-06, 469
[INFO] 2021-07-09 16:58:47,313 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 469
[INFO] 2021-07-09 16:58:47,313 [run_pretraining.py:  558]:	worker_index: 6, step: 469, cost: 1.301919, mlm loss: 1.301919, speed: 0.455147 steps/s, speed: 3.641177 samples/s, speed: 1864.282376 tokens/s, learning rate: 4.680e-06, loss_scalings: 377.789520, pp_loss: 1.277772
[INFO] 2021-07-09 16:58:47,313 [run_pretraining.py:  512]:	********exe.run_469******* 
[INFO] 2021-07-09 16:58:49,611 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:49,612 [run_pretraining.py:  534]:	loss/total_loss, 1.2511663436889648, 470
[INFO] 2021-07-09 16:58:49,612 [run_pretraining.py:  535]:	loss/mlm_loss, 1.2511663436889648, 470
[INFO] 2021-07-09 16:58:49,612 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.689999968832126e-06, 470
[INFO] 2021-07-09 16:58:49,612 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 470
[INFO] 2021-07-09 16:58:49,612 [run_pretraining.py:  558]:	worker_index: 6, step: 470, cost: 1.251166, mlm loss: 1.251166, speed: 0.434968 steps/s, speed: 3.479745 samples/s, speed: 1781.629393 tokens/s, learning rate: 4.690e-06, loss_scalings: 377.789520, pp_loss: 1.258179
[INFO] 2021-07-09 16:58:49,612 [run_pretraining.py:  512]:	********exe.run_470******* 
[INFO] 2021-07-09 16:58:51,949 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:51,950 [run_pretraining.py:  534]:	loss/total_loss, 1.2643922567367554, 471
[INFO] 2021-07-09 16:58:51,950 [run_pretraining.py:  535]:	loss/mlm_loss, 1.2643922567367554, 471
[INFO] 2021-07-09 16:58:51,950 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.699999863078119e-06, 471
[INFO] 2021-07-09 16:58:51,950 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 471
[INFO] 2021-07-09 16:58:51,950 [run_pretraining.py:  558]:	worker_index: 6, step: 471, cost: 1.264392, mlm loss: 1.264392, speed: 0.427822 steps/s, speed: 3.422574 samples/s, speed: 1752.357840 tokens/s, learning rate: 4.700e-06, loss_scalings: 377.789520, pp_loss: 1.261923
[INFO] 2021-07-09 16:58:51,951 [run_pretraining.py:  512]:	********exe.run_471******* 
[INFO] 2021-07-09 16:58:54,236 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:54,237 [run_pretraining.py:  534]:	loss/total_loss, 1.2498105764389038, 472
[INFO] 2021-07-09 16:58:54,237 [run_pretraining.py:  535]:	loss/mlm_loss, 1.2498105764389038, 472
[INFO] 2021-07-09 16:58:54,237 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.709999757324113e-06, 472
[INFO] 2021-07-09 16:58:54,237 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 472
[INFO] 2021-07-09 16:58:54,237 [run_pretraining.py:  558]:	worker_index: 6, step: 472, cost: 1.249811, mlm loss: 1.249811, speed: 0.437424 steps/s, speed: 3.499390 samples/s, speed: 1791.687444 tokens/s, learning rate: 4.710e-06, loss_scalings: 377.789520, pp_loss: 1.254961
[INFO] 2021-07-09 16:58:54,237 [run_pretraining.py:  512]:	********exe.run_472******* 
[INFO] 2021-07-09 16:58:56,811 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:56,812 [run_pretraining.py:  534]:	loss/total_loss, 1.2827882766723633, 473
[INFO] 2021-07-09 16:58:56,812 [run_pretraining.py:  535]:	loss/mlm_loss, 1.2827882766723633, 473
[INFO] 2021-07-09 16:58:56,812 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.720000106317457e-06, 473
[INFO] 2021-07-09 16:58:56,812 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 473
[INFO] 2021-07-09 16:58:56,812 [run_pretraining.py:  558]:	worker_index: 6, step: 473, cost: 1.282788, mlm loss: 1.282788, speed: 0.388446 steps/s, speed: 3.107569 samples/s, speed: 1591.075571 tokens/s, learning rate: 4.720e-06, loss_scalings: 377.789520, pp_loss: 1.263341
[INFO] 2021-07-09 16:58:56,812 [run_pretraining.py:  512]:	********exe.run_473******* 
[INFO] 2021-07-09 16:58:59,092 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:59,093 [run_pretraining.py:  534]:	loss/total_loss, 1.2630572319030762, 474
[INFO] 2021-07-09 16:58:59,093 [run_pretraining.py:  535]:	loss/mlm_loss, 1.2630572319030762, 474
[INFO] 2021-07-09 16:58:59,093 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.73000000056345e-06, 474
[INFO] 2021-07-09 16:58:59,093 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 474
[INFO] 2021-07-09 16:58:59,093 [run_pretraining.py:  558]:	worker_index: 6, step: 474, cost: 1.263057, mlm loss: 1.263057, speed: 0.438569 steps/s, speed: 3.508550 samples/s, speed: 1796.377604 tokens/s, learning rate: 4.730e-06, loss_scalings: 377.789520, pp_loss: 1.281120
[INFO] 2021-07-09 16:58:59,093 [run_pretraining.py:  512]:	********exe.run_474******* 
[INFO] 2021-07-09 16:59:01,439 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:01,439 [run_pretraining.py:  534]:	loss/total_loss, 1.3165531158447266, 475
[INFO] 2021-07-09 16:59:01,439 [run_pretraining.py:  535]:	loss/mlm_loss, 1.3165531158447266, 475
[INFO] 2021-07-09 16:59:01,440 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.7399998948094435e-06, 475
[INFO] 2021-07-09 16:59:01,440 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 475
[INFO] 2021-07-09 16:59:01,440 [run_pretraining.py:  558]:	worker_index: 6, step: 475, cost: 1.316553, mlm loss: 1.316553, speed: 0.426277 steps/s, speed: 3.410216 samples/s, speed: 1746.030615 tokens/s, learning rate: 4.740e-06, loss_scalings: 377.789520, pp_loss: 1.325622
[INFO] 2021-07-09 16:59:01,440 [run_pretraining.py:  512]:	********exe.run_475******* 
[INFO] 2021-07-09 16:59:03,908 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:03,909 [run_pretraining.py:  534]:	loss/total_loss, 1.3638954162597656, 476
[INFO] 2021-07-09 16:59:03,909 [run_pretraining.py:  535]:	loss/mlm_loss, 1.3638954162597656, 476
[INFO] 2021-07-09 16:59:03,909 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.749999789055437e-06, 476
[INFO] 2021-07-09 16:59:03,909 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 476
[INFO] 2021-07-09 16:59:03,909 [run_pretraining.py:  558]:	worker_index: 6, step: 476, cost: 1.363895, mlm loss: 1.363895, speed: 0.405108 steps/s, speed: 3.240863 samples/s, speed: 1659.321763 tokens/s, learning rate: 4.750e-06, loss_scalings: 377.789520, pp_loss: 1.364460
[INFO] 2021-07-09 16:59:03,909 [run_pretraining.py:  512]:	********exe.run_476******* 
[INFO] 2021-07-09 16:59:06,166 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:06,166 [run_pretraining.py:  534]:	loss/total_loss, 1.412280559539795, 477
[INFO] 2021-07-09 16:59:06,167 [run_pretraining.py:  535]:	loss/mlm_loss, 1.412280559539795, 477
[INFO] 2021-07-09 16:59:06,167 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.760000138048781e-06, 477
[INFO] 2021-07-09 16:59:06,167 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 477
[INFO] 2021-07-09 16:59:06,167 [run_pretraining.py:  558]:	worker_index: 6, step: 477, cost: 1.412281, mlm loss: 1.412281, speed: 0.443007 steps/s, speed: 3.544056 samples/s, speed: 1814.556720 tokens/s, learning rate: 4.760e-06, loss_scalings: 377.789520, pp_loss: 1.413672
[INFO] 2021-07-09 16:59:06,167 [run_pretraining.py:  512]:	********exe.run_477******* 
[INFO] 2021-07-09 16:59:08,405 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:08,406 [run_pretraining.py:  534]:	loss/total_loss, 1.4872828722000122, 478
[INFO] 2021-07-09 16:59:08,406 [run_pretraining.py:  535]:	loss/mlm_loss, 1.4872828722000122, 478
[INFO] 2021-07-09 16:59:08,406 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.7699995775474235e-06, 478
[INFO] 2021-07-09 16:59:08,406 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 478
[INFO] 2021-07-09 16:59:08,406 [run_pretraining.py:  558]:	worker_index: 6, step: 478, cost: 1.487283, mlm loss: 1.487283, speed: 0.446702 steps/s, speed: 3.573615 samples/s, speed: 1829.691019 tokens/s, learning rate: 4.770e-06, loss_scalings: 377.789520, pp_loss: 1.493688
[INFO] 2021-07-09 16:59:08,406 [run_pretraining.py:  512]:	********exe.run_478******* 
[INFO] 2021-07-09 16:59:10,659 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:10,660 [run_pretraining.py:  534]:	loss/total_loss, 1.530027151107788, 479
[INFO] 2021-07-09 16:59:10,660 [run_pretraining.py:  535]:	loss/mlm_loss, 1.530027151107788, 479
[INFO] 2021-07-09 16:59:10,660 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.779999926540768e-06, 479
[INFO] 2021-07-09 16:59:10,660 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 479
[INFO] 2021-07-09 16:59:10,660 [run_pretraining.py:  558]:	worker_index: 6, step: 479, cost: 1.530027, mlm loss: 1.530027, speed: 0.443759 steps/s, speed: 3.550074 samples/s, speed: 1817.638014 tokens/s, learning rate: 4.780e-06, loss_scalings: 377.789520, pp_loss: 1.542051
[INFO] 2021-07-09 16:59:10,660 [run_pretraining.py:  512]:	********exe.run_479******* 
[INFO] 2021-07-09 16:59:12,934 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:12,935 [run_pretraining.py:  534]:	loss/total_loss, 1.6213161945343018, 480
[INFO] 2021-07-09 16:59:12,935 [run_pretraining.py:  535]:	loss/mlm_loss, 1.6213161945343018, 480
[INFO] 2021-07-09 16:59:12,935 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.789999820786761e-06, 480
[INFO] 2021-07-09 16:59:12,935 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 480
[INFO] 2021-07-09 16:59:12,935 [run_pretraining.py:  558]:	worker_index: 6, step: 480, cost: 1.621316, mlm loss: 1.621316, speed: 0.439702 steps/s, speed: 3.517616 samples/s, speed: 1801.019312 tokens/s, learning rate: 4.790e-06, loss_scalings: 377.789520, pp_loss: 1.607631
[INFO] 2021-07-09 16:59:12,935 [run_pretraining.py:  512]:	********exe.run_480******* 
[INFO] 2021-07-09 16:59:15,123 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:15,124 [run_pretraining.py:  534]:	loss/total_loss, 1.6431176662445068, 481
[INFO] 2021-07-09 16:59:15,124 [run_pretraining.py:  535]:	loss/mlm_loss, 1.6431176662445068, 481
[INFO] 2021-07-09 16:59:15,124 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.7999997150327545e-06, 481
[INFO] 2021-07-09 16:59:15,124 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 481
[INFO] 2021-07-09 16:59:15,124 [run_pretraining.py:  558]:	worker_index: 6, step: 481, cost: 1.643118, mlm loss: 1.643118, speed: 0.457002 steps/s, speed: 3.656018 samples/s, speed: 1871.881402 tokens/s, learning rate: 4.800e-06, loss_scalings: 377.789520, pp_loss: 1.643141
[INFO] 2021-07-09 16:59:15,124 [run_pretraining.py:  512]:	********exe.run_481******* 
[INFO] 2021-07-09 16:59:17,339 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:17,339 [run_pretraining.py:  534]:	loss/total_loss, 1.6503527164459229, 482
[INFO] 2021-07-09 16:59:17,340 [run_pretraining.py:  535]:	loss/mlm_loss, 1.6503527164459229, 482
[INFO] 2021-07-09 16:59:17,340 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.809999609278748e-06, 482
[INFO] 2021-07-09 16:59:17,340 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 482
[INFO] 2021-07-09 16:59:17,340 [run_pretraining.py:  558]:	worker_index: 6, step: 482, cost: 1.650353, mlm loss: 1.650353, speed: 0.451468 steps/s, speed: 3.611742 samples/s, speed: 1849.211795 tokens/s, learning rate: 4.810e-06, loss_scalings: 377.789520, pp_loss: 1.659423
[INFO] 2021-07-09 16:59:17,340 [run_pretraining.py:  512]:	********exe.run_482******* 
[INFO] 2021-07-09 16:59:19,640 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:19,641 [run_pretraining.py:  534]:	loss/total_loss, 1.6685082912445068, 483
[INFO] 2021-07-09 16:59:19,641 [run_pretraining.py:  535]:	loss/mlm_loss, 1.6685082912445068, 483
[INFO] 2021-07-09 16:59:19,641 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.819999958272092e-06, 483
[INFO] 2021-07-09 16:59:19,641 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 483
[INFO] 2021-07-09 16:59:19,641 [run_pretraining.py:  558]:	worker_index: 6, step: 483, cost: 1.668508, mlm loss: 1.668508, speed: 0.434673 steps/s, speed: 3.477388 samples/s, speed: 1780.422600 tokens/s, learning rate: 4.820e-06, loss_scalings: 377.789520, pp_loss: 1.666820
[INFO] 2021-07-09 16:59:19,641 [run_pretraining.py:  512]:	********exe.run_483******* 
[INFO] 2021-07-09 16:59:21,998 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:21,998 [run_pretraining.py:  534]:	loss/total_loss, 1.6708866357803345, 484
[INFO] 2021-07-09 16:59:21,998 [run_pretraining.py:  535]:	loss/mlm_loss, 1.6708866357803345, 484
[INFO] 2021-07-09 16:59:21,998 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.829999852518085e-06, 484
[INFO] 2021-07-09 16:59:21,998 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 484
[INFO] 2021-07-09 16:59:21,999 [run_pretraining.py:  558]:	worker_index: 6, step: 484, cost: 1.670887, mlm loss: 1.670887, speed: 0.424294 steps/s, speed: 3.394352 samples/s, speed: 1737.908213 tokens/s, learning rate: 4.830e-06, loss_scalings: 377.789520, pp_loss: 1.672951
[INFO] 2021-07-09 16:59:21,999 [run_pretraining.py:  512]:	********exe.run_484******* 
[INFO] 2021-07-09 16:59:24,525 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:24,525 [run_pretraining.py:  534]:	loss/total_loss, 1.661216139793396, 485
[INFO] 2021-07-09 16:59:24,525 [run_pretraining.py:  535]:	loss/mlm_loss, 1.661216139793396, 485
[INFO] 2021-07-09 16:59:24,525 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.839999746764079e-06, 485
[INFO] 2021-07-09 16:59:24,525 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 485
[INFO] 2021-07-09 16:59:24,526 [run_pretraining.py:  558]:	worker_index: 6, step: 485, cost: 1.661216, mlm loss: 1.661216, speed: 0.395837 steps/s, speed: 3.166697 samples/s, speed: 1621.349005 tokens/s, learning rate: 4.840e-06, loss_scalings: 377.789520, pp_loss: 1.666739
[INFO] 2021-07-09 16:59:24,526 [run_pretraining.py:  512]:	********exe.run_485******* 
[INFO] 2021-07-09 16:59:26,783 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:26,784 [run_pretraining.py:  534]:	loss/total_loss, 1.6795775890350342, 486
[INFO] 2021-07-09 16:59:26,784 [run_pretraining.py:  535]:	loss/mlm_loss, 1.6795775890350342, 486
[INFO] 2021-07-09 16:59:26,784 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.850000095757423e-06, 486
[INFO] 2021-07-09 16:59:26,784 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 486
[INFO] 2021-07-09 16:59:26,784 [run_pretraining.py:  558]:	worker_index: 6, step: 486, cost: 1.679578, mlm loss: 1.679578, speed: 0.442876 steps/s, speed: 3.543004 samples/s, speed: 1814.018136 tokens/s, learning rate: 4.850e-06, loss_scalings: 377.789520, pp_loss: 1.676813
[INFO] 2021-07-09 16:59:26,784 [run_pretraining.py:  512]:	********exe.run_486******* 
[INFO] 2021-07-09 16:59:29,124 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:29,124 [run_pretraining.py:  534]:	loss/total_loss, 1.6793432235717773, 487
[INFO] 2021-07-09 16:59:29,124 [run_pretraining.py:  535]:	loss/mlm_loss, 1.6793432235717773, 487
[INFO] 2021-07-09 16:59:29,124 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.859999990003416e-06, 487
[INFO] 2021-07-09 16:59:29,125 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 487
[INFO] 2021-07-09 16:59:29,125 [run_pretraining.py:  558]:	worker_index: 6, step: 487, cost: 1.679343, mlm loss: 1.679343, speed: 0.427403 steps/s, speed: 3.419227 samples/s, speed: 1750.644313 tokens/s, learning rate: 4.860e-06, loss_scalings: 377.789520, pp_loss: 1.695079
[INFO] 2021-07-09 16:59:29,125 [run_pretraining.py:  512]:	********exe.run_487******* 
[INFO] 2021-07-09 16:59:31,338 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:31,339 [run_pretraining.py:  534]:	loss/total_loss, 1.6692684888839722, 488
[INFO] 2021-07-09 16:59:31,339 [run_pretraining.py:  535]:	loss/mlm_loss, 1.6692684888839722, 488
[INFO] 2021-07-09 16:59:31,339 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.86999988424941e-06, 488
[INFO] 2021-07-09 16:59:31,339 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 488
[INFO] 2021-07-09 16:59:31,339 [run_pretraining.py:  558]:	worker_index: 6, step: 488, cost: 1.669268, mlm loss: 1.669268, speed: 0.451629 steps/s, speed: 3.613033 samples/s, speed: 1849.872864 tokens/s, learning rate: 4.870e-06, loss_scalings: 377.789520, pp_loss: 1.671995
[INFO] 2021-07-09 16:59:31,340 [run_pretraining.py:  512]:	********exe.run_488******* 
[INFO] 2021-07-09 16:59:33,574 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:33,575 [run_pretraining.py:  534]:	loss/total_loss, 1.6043943166732788, 489
[INFO] 2021-07-09 16:59:33,575 [run_pretraining.py:  535]:	loss/mlm_loss, 1.6043943166732788, 489
[INFO] 2021-07-09 16:59:33,575 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.879999778495403e-06, 489
[INFO] 2021-07-09 16:59:33,575 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 489
[INFO] 2021-07-09 16:59:33,575 [run_pretraining.py:  558]:	worker_index: 6, step: 489, cost: 1.604394, mlm loss: 1.604394, speed: 0.447416 steps/s, speed: 3.579329 samples/s, speed: 1832.616533 tokens/s, learning rate: 4.880e-06, loss_scalings: 377.789520, pp_loss: 1.600777
[INFO] 2021-07-09 16:59:33,575 [run_pretraining.py:  512]:	********exe.run_489******* 
[INFO] 2021-07-09 16:59:35,763 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:35,764 [run_pretraining.py:  534]:	loss/total_loss, 1.5007106065750122, 490
[INFO] 2021-07-09 16:59:35,764 [run_pretraining.py:  535]:	loss/mlm_loss, 1.5007106065750122, 490
[INFO] 2021-07-09 16:59:35,764 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.890000127488747e-06, 490
[INFO] 2021-07-09 16:59:35,764 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 490
[INFO] 2021-07-09 16:59:35,764 [run_pretraining.py:  558]:	worker_index: 6, step: 490, cost: 1.500711, mlm loss: 1.500711, speed: 0.456907 steps/s, speed: 3.655259 samples/s, speed: 1871.492742 tokens/s, learning rate: 4.890e-06, loss_scalings: 377.789520, pp_loss: 1.496656
[INFO] 2021-07-09 16:59:35,765 [run_pretraining.py:  512]:	********exe.run_490******* 
[INFO] 2021-07-09 16:59:37,997 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:37,998 [run_pretraining.py:  534]:	loss/total_loss, 1.4050228595733643, 491
[INFO] 2021-07-09 16:59:37,998 [run_pretraining.py:  535]:	loss/mlm_loss, 1.4050228595733643, 491
[INFO] 2021-07-09 16:59:37,998 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.89999956698739e-06, 491
[INFO] 2021-07-09 16:59:37,998 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 491
[INFO] 2021-07-09 16:59:37,998 [run_pretraining.py:  558]:	worker_index: 6, step: 491, cost: 1.405023, mlm loss: 1.405023, speed: 0.447818 steps/s, speed: 3.582545 samples/s, speed: 1834.263055 tokens/s, learning rate: 4.900e-06, loss_scalings: 377.789520, pp_loss: 1.415700
[INFO] 2021-07-09 16:59:37,998 [run_pretraining.py:  512]:	********exe.run_491******* 
[INFO] 2021-07-09 16:59:40,281 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:40,282 [run_pretraining.py:  534]:	loss/total_loss, 1.3145623207092285, 492
[INFO] 2021-07-09 16:59:40,282 [run_pretraining.py:  535]:	loss/mlm_loss, 1.3145623207092285, 492
[INFO] 2021-07-09 16:59:40,282 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.909999915980734e-06, 492
[INFO] 2021-07-09 16:59:40,282 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 492
[INFO] 2021-07-09 16:59:40,282 [run_pretraining.py:  558]:	worker_index: 6, step: 492, cost: 1.314562, mlm loss: 1.314562, speed: 0.437993 steps/s, speed: 3.503946 samples/s, speed: 1794.020372 tokens/s, learning rate: 4.910e-06, loss_scalings: 377.789520, pp_loss: 1.313422
[INFO] 2021-07-09 16:59:40,282 [run_pretraining.py:  512]:	********exe.run_492******* 
[INFO] 2021-07-09 16:59:42,585 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:42,586 [run_pretraining.py:  534]:	loss/total_loss, 1.203289270401001, 493
[INFO] 2021-07-09 16:59:42,586 [run_pretraining.py:  535]:	loss/mlm_loss, 1.203289270401001, 493
[INFO] 2021-07-09 16:59:42,586 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.919999810226727e-06, 493
[INFO] 2021-07-09 16:59:42,586 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 493
[INFO] 2021-07-09 16:59:42,586 [run_pretraining.py:  558]:	worker_index: 6, step: 493, cost: 1.203289, mlm loss: 1.203289, speed: 0.434101 steps/s, speed: 3.472809 samples/s, speed: 1778.078136 tokens/s, learning rate: 4.920e-06, loss_scalings: 377.789520, pp_loss: 1.200190
[INFO] 2021-07-09 16:59:42,586 [run_pretraining.py:  512]:	********exe.run_493******* 
[INFO] 2021-07-09 16:59:44,898 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:44,899 [run_pretraining.py:  534]:	loss/total_loss, 1.0951175689697266, 494
[INFO] 2021-07-09 16:59:44,899 [run_pretraining.py:  535]:	loss/mlm_loss, 1.0951175689697266, 494
[INFO] 2021-07-09 16:59:44,899 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.929999704472721e-06, 494
[INFO] 2021-07-09 16:59:44,899 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 494
[INFO] 2021-07-09 16:59:44,899 [run_pretraining.py:  558]:	worker_index: 6, step: 494, cost: 1.095118, mlm loss: 1.095118, speed: 0.432454 steps/s, speed: 3.459632 samples/s, speed: 1771.331816 tokens/s, learning rate: 4.930e-06, loss_scalings: 377.789520, pp_loss: 1.088206
[INFO] 2021-07-09 16:59:44,899 [run_pretraining.py:  512]:	********exe.run_494******* 
[INFO] 2021-07-09 16:59:47,149 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:47,149 [run_pretraining.py:  534]:	loss/total_loss, 0.9923162460327148, 495
[INFO] 2021-07-09 16:59:47,150 [run_pretraining.py:  535]:	loss/mlm_loss, 0.9923162460327148, 495
[INFO] 2021-07-09 16:59:47,150 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.940000053466065e-06, 495
[INFO] 2021-07-09 16:59:47,150 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 495
[INFO] 2021-07-09 16:59:47,150 [run_pretraining.py:  558]:	worker_index: 6, step: 495, cost: 0.992316, mlm loss: 0.992316, speed: 0.444485 steps/s, speed: 3.555877 samples/s, speed: 1820.609004 tokens/s, learning rate: 4.940e-06, loss_scalings: 377.789520, pp_loss: 0.994156
[INFO] 2021-07-09 16:59:47,150 [run_pretraining.py:  512]:	********exe.run_495******* 
[INFO] 2021-07-09 16:59:49,390 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:49,391 [run_pretraining.py:  534]:	loss/total_loss, 0.9159078598022461, 496
[INFO] 2021-07-09 16:59:49,391 [run_pretraining.py:  535]:	loss/mlm_loss, 0.9159078598022461, 496
[INFO] 2021-07-09 16:59:49,391 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.949999947712058e-06, 496
[INFO] 2021-07-09 16:59:49,391 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 496
[INFO] 2021-07-09 16:59:49,391 [run_pretraining.py:  558]:	worker_index: 6, step: 496, cost: 0.915908, mlm loss: 0.915908, speed: 0.446256 steps/s, speed: 3.570049 samples/s, speed: 1827.865196 tokens/s, learning rate: 4.950e-06, loss_scalings: 377.789520, pp_loss: 0.925724
[INFO] 2021-07-09 16:59:49,391 [run_pretraining.py:  512]:	********exe.run_496******* 
[INFO] 2021-07-09 16:59:51,621 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:51,622 [run_pretraining.py:  534]:	loss/total_loss, 0.8761051297187805, 497
[INFO] 2021-07-09 16:59:51,622 [run_pretraining.py:  535]:	loss/mlm_loss, 0.8761051297187805, 497
[INFO] 2021-07-09 16:59:51,622 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.9599998419580515e-06, 497
[INFO] 2021-07-09 16:59:51,622 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 497
[INFO] 2021-07-09 16:59:51,622 [run_pretraining.py:  558]:	worker_index: 6, step: 497, cost: 0.876105, mlm loss: 0.876105, speed: 0.448412 steps/s, speed: 3.587297 samples/s, speed: 1836.695879 tokens/s, learning rate: 4.960e-06, loss_scalings: 377.789520, pp_loss: 0.877697
[INFO] 2021-07-09 16:59:51,622 [run_pretraining.py:  512]:	********exe.run_497******* 
[INFO] 2021-07-09 16:59:53,844 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:53,844 [run_pretraining.py:  534]:	loss/total_loss, 0.8392369151115417, 498
[INFO] 2021-07-09 16:59:53,844 [run_pretraining.py:  535]:	loss/mlm_loss, 0.8392369151115417, 498
[INFO] 2021-07-09 16:59:53,845 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.969999736204045e-06, 498
[INFO] 2021-07-09 16:59:53,845 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 498
[INFO] 2021-07-09 16:59:53,845 [run_pretraining.py:  558]:	worker_index: 6, step: 498, cost: 0.839237, mlm loss: 0.839237, speed: 0.450053 steps/s, speed: 3.600424 samples/s, speed: 1843.417269 tokens/s, learning rate: 4.970e-06, loss_scalings: 377.789520, pp_loss: 0.843755
[INFO] 2021-07-09 16:59:53,845 [run_pretraining.py:  512]:	********exe.run_498******* 
[INFO] 2021-07-09 16:59:56,065 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:56,066 [run_pretraining.py:  534]:	loss/total_loss, 0.8124316930770874, 499
[INFO] 2021-07-09 16:59:56,066 [run_pretraining.py:  535]:	loss/mlm_loss, 0.8124316930770874, 499
[INFO] 2021-07-09 16:59:56,066 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.980000085197389e-06, 499
[INFO] 2021-07-09 16:59:56,066 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 499
[INFO] 2021-07-09 16:59:56,066 [run_pretraining.py:  558]:	worker_index: 6, step: 499, cost: 0.812432, mlm loss: 0.812432, speed: 0.450301 steps/s, speed: 3.602407 samples/s, speed: 1844.432347 tokens/s, learning rate: 4.980e-06, loss_scalings: 377.789520, pp_loss: 0.815655
[INFO] 2021-07-09 16:59:56,066 [run_pretraining.py:  512]:	********exe.run_499******* 
[INFO] 2021-07-09 16:59:58,283 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:58,283 [run_pretraining.py:  534]:	loss/total_loss, 0.8110164403915405, 500
[INFO] 2021-07-09 16:59:58,284 [run_pretraining.py:  535]:	loss/mlm_loss, 0.8110164403915405, 500
[INFO] 2021-07-09 16:59:58,284 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.9899999794433825e-06, 500
[INFO] 2021-07-09 16:59:58,284 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 500
[INFO] 2021-07-09 16:59:58,284 [run_pretraining.py:  558]:	worker_index: 6, step: 500, cost: 0.811016, mlm loss: 0.811016, speed: 0.451076 steps/s, speed: 3.608610 samples/s, speed: 1847.608478 tokens/s, learning rate: 4.990e-06, loss_scalings: 377.789520, pp_loss: 0.804460
[DEBUG] 2021-07-09 16:59:58,284 [run_pretraining.py:  567]:	saving models to output/test-bs8-mppp_6/step_500
[INFO] 2021-07-09 16:59:59,155 [run_pretraining.py:  512]:	********exe.run_500******* 
[INFO] 2021-07-09 17:00:01,448 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 17:00:01,449 [run_pretraining.py:  534]:	loss/total_loss, 0.8011265993118286, 501
[INFO] 2021-07-09 17:00:01,449 [run_pretraining.py:  535]:	loss/mlm_loss, 0.8011265993118286, 501
[INFO] 2021-07-09 17:00:01,449 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.999999873689376e-06, 501
[INFO] 2021-07-09 17:00:01,449 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 501
[INFO] 2021-07-09 17:00:01,449 [run_pretraining.py:  558]:	worker_index: 6, step: 501, cost: 0.801127, mlm loss: 0.801127, speed: 0.315976 steps/s, speed: 2.527805 samples/s, speed: 1294.235949 tokens/s, learning rate: 5.000e-06, loss_scalings: 377.789520, pp_loss: 0.805918
[INFO] 2021-07-09 17:00:01,449 [run_pretraining.py:  512]:	********exe.run_501******* 
[INFO] 2021-07-09 17:00:03,698 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 17:00:03,699 [run_pretraining.py:  534]:	loss/total_loss, 0.8287124037742615, 502
[INFO] 2021-07-09 17:00:03,699 [run_pretraining.py:  535]:	loss/mlm_loss, 0.8287124037742615, 502
[INFO] 2021-07-09 17:00:03,699 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.009999767935369e-06, 502
[INFO] 2021-07-09 17:00:03,699 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 502
[INFO] 2021-07-09 17:00:03,699 [run_pretraining.py:  558]:	worker_index: 6, step: 502, cost: 0.828712, mlm loss: 0.828712, speed: 0.444663 steps/s, speed: 3.557307 samples/s, speed: 1821.341105 tokens/s, learning rate: 5.010e-06, loss_scalings: 377.789520, pp_loss: 0.823818
[INFO] 2021-07-09 17:00:03,699 [run_pretraining.py:  512]:	********exe.run_502******* 
[INFO] 2021-07-09 17:00:05,965 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 17:00:05,966 [run_pretraining.py:  534]:	loss/total_loss, 0.8313344717025757, 503
[INFO] 2021-07-09 17:00:05,966 [run_pretraining.py:  535]:	loss/mlm_loss, 0.8313344717025757, 503
[INFO] 2021-07-09 17:00:05,966 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.020000116928713e-06, 503
[INFO] 2021-07-09 17:00:05,966 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 503
[INFO] 2021-07-09 17:00:05,966 [run_pretraining.py:  558]:	worker_index: 6, step: 503, cost: 0.831334, mlm loss: 0.831334, speed: 0.441231 steps/s, speed: 3.529845 samples/s, speed: 1807.280871 tokens/s, learning rate: 5.020e-06, loss_scalings: 377.789520, pp_loss: 0.832895
[INFO] 2021-07-09 17:00:05,966 [run_pretraining.py:  512]:	********exe.run_503******* 
[INFO] 2021-07-09 17:00:08,223 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 17:00:08,224 [run_pretraining.py:  534]:	loss/total_loss, 0.8419674038887024, 504
[INFO] 2021-07-09 17:00:08,224 [run_pretraining.py:  535]:	loss/mlm_loss, 0.8419674038887024, 504
[INFO] 2021-07-09 17:00:08,224 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.029999556427356e-06, 504
[INFO] 2021-07-09 17:00:08,224 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 504
[INFO] 2021-07-09 17:00:08,224 [run_pretraining.py:  558]:	worker_index: 6, step: 504, cost: 0.841967, mlm loss: 0.841967, speed: 0.442940 steps/s, speed: 3.543522 samples/s, speed: 1814.283077 tokens/s, learning rate: 5.030e-06, loss_scalings: 377.789520, pp_loss: 0.848541
[INFO] 2021-07-09 17:00:08,224 [run_pretraining.py:  512]:	********exe.run_504******* 
[INFO] 2021-07-09 17:00:10,424 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 17:00:10,424 [run_pretraining.py:  534]:	loss/total_loss, 0.8534204363822937, 505
[INFO] 2021-07-09 17:00:10,424 [run_pretraining.py:  535]:	loss/mlm_loss, 0.8534204363822937, 505
[INFO] 2021-07-09 17:00:10,424 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.0399999054207e-06, 505
[INFO] 2021-07-09 17:00:10,425 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 505
[INFO] 2021-07-09 17:00:10,425 [run_pretraining.py:  558]:	worker_index: 6, step: 505, cost: 0.853420, mlm loss: 0.853420, speed: 0.454634 steps/s, speed: 3.637071 samples/s, speed: 1862.180589 tokens/s, learning rate: 5.040e-06, loss_scalings: 377.789520, pp_loss: 0.852575
[INFO] 2021-07-09 17:00:10,425 [run_pretraining.py:  512]:	********exe.run_505******* 
[INFO] 2021-07-09 17:00:12,663 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 17:00:12,664 [run_pretraining.py:  534]:	loss/total_loss, 0.8637637495994568, 506
[INFO] 2021-07-09 17:00:12,664 [run_pretraining.py:  535]:	loss/mlm_loss, 0.8637637495994568, 506
[INFO] 2021-07-09 17:00:12,664 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.050000254414044e-06, 506
[INFO] 2021-07-09 17:00:12,664 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 506
[INFO] 2021-07-09 17:00:12,664 [run_pretraining.py:  558]:	worker_index: 6, step: 506, cost: 0.863764, mlm loss: 0.863764, speed: 0.446661 steps/s, speed: 3.573288 samples/s, speed: 1829.523450 tokens/s, learning rate: 5.050e-06, loss_scalings: 377.789520, pp_loss: 0.867135
[INFO] 2021-07-09 17:00:12,664 [run_pretraining.py:  512]:	********exe.run_506******* 
[INFO] 2021-07-09 17:00:14,898 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 17:00:14,898 [run_pretraining.py:  534]:	loss/total_loss, 0.9242322444915771, 507
[INFO] 2021-07-09 17:00:14,898 [run_pretraining.py:  535]:	loss/mlm_loss, 0.9242322444915771, 507
[INFO] 2021-07-09 17:00:14,898 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.059999693912687e-06, 507
[INFO] 2021-07-09 17:00:14,898 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 507
[INFO] 2021-07-09 17:00:14,899 [run_pretraining.py:  558]:	worker_index: 6, step: 507, cost: 0.924232, mlm loss: 0.924232, speed: 0.447677 steps/s, speed: 3.581419 samples/s, speed: 1833.686680 tokens/s, learning rate: 5.060e-06, loss_scalings: 377.789520, pp_loss: 0.919510
[INFO] 2021-07-09 17:00:14,899 [run_pretraining.py:  512]:	********exe.run_507******* 
[INFO] 2021-07-09 17:00:17,106 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 17:00:17,107 [run_pretraining.py:  534]:	loss/total_loss, 1.026145100593567, 508
[INFO] 2021-07-09 17:00:17,107 [run_pretraining.py:  535]:	loss/mlm_loss, 1.026145100593567, 508
[INFO] 2021-07-09 17:00:17,107 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.070000042906031e-06, 508
[INFO] 2021-07-09 17:00:17,107 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 508
[INFO] 2021-07-09 17:00:17,107 [run_pretraining.py:  558]:	worker_index: 6, step: 508, cost: 1.026145, mlm loss: 1.026145, speed: 0.452972 steps/s, speed: 3.623775 samples/s, speed: 1855.373023 tokens/s, learning rate: 5.070e-06, loss_scalings: 377.789520, pp_loss: 1.031365
[INFO] 2021-07-09 17:00:17,107 [run_pretraining.py:  512]:	********exe.run_508******* 
[INFO] 2021-07-09 17:00:19,316 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 17:00:19,317 [run_pretraining.py:  534]:	loss/total_loss, 1.2191401720046997, 509
[INFO] 2021-07-09 17:00:19,317 [run_pretraining.py:  535]:	loss/mlm_loss, 1.2191401720046997, 509
[INFO] 2021-07-09 17:00:19,317 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.079999937152024e-06, 509
[INFO] 2021-07-09 17:00:19,317 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 509
[INFO] 2021-07-09 17:00:19,317 [run_pretraining.py:  558]:	worker_index: 6, step: 509, cost: 1.219140, mlm loss: 1.219140, speed: 0.452555 steps/s, speed: 3.620441 samples/s, speed: 1853.665801 tokens/s, learning rate: 5.080e-06, loss_scalings: 377.789520, pp_loss: 1.214259
[INFO] 2021-07-09 17:00:19,317 [run_pretraining.py:  512]:	********exe.run_509******* 
[INFO] 2021-07-09 17:00:21,533 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 17:00:21,533 [run_pretraining.py:  534]:	loss/total_loss, 1.441344976425171, 510
[INFO] 2021-07-09 17:00:21,534 [run_pretraining.py:  535]:	loss/mlm_loss, 1.441344976425171, 510
[INFO] 2021-07-09 17:00:21,534 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.089999831398018e-06, 510
[INFO] 2021-07-09 17:00:21,534 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 510
[INFO] 2021-07-09 17:00:21,534 [run_pretraining.py:  558]:	worker_index: 6, step: 510, cost: 1.441345, mlm loss: 1.441345, speed: 0.451284 steps/s, speed: 3.610269 samples/s, speed: 1848.457719 tokens/s, learning rate: 5.090e-06, loss_scalings: 377.789520, pp_loss: 1.443206
[INFO] 2021-07-09 17:00:21,534 [run_pretraining.py:  512]:	********exe.run_510******* 
[INFO] 2021-07-09 17:00:23,785 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 17:00:23,786 [run_pretraining.py:  534]:	loss/total_loss, 1.62644362449646, 511
[INFO] 2021-07-09 17:00:23,786 [run_pretraining.py:  535]:	loss/mlm_loss, 1.62644362449646, 511
[INFO] 2021-07-09 17:00:23,786 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.099999725644011e-06, 511
[INFO] 2021-07-09 17:00:23,786 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 511
[INFO] 2021-07-09 17:00:23,786 [run_pretraining.py:  558]:	worker_index: 6, step: 511, cost: 1.626444, mlm loss: 1.626444, speed: 0.444095 steps/s, speed: 3.552763 samples/s, speed: 1819.014434 tokens/s, learning rate: 5.100e-06, loss_scalings: 377.789520, pp_loss: 1.630521
[INFO] 2021-07-09 17:00:23,786 [run_pretraining.py:  512]:	********exe.run_511******* 
[INFO] 2021-07-09 17:00:26,065 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 17:00:26,065 [run_pretraining.py:  534]:	loss/total_loss, 1.7370423078536987, 512
[INFO] 2021-07-09 17:00:26,065 [run_pretraining.py:  535]:	loss/mlm_loss, 1.7370423078536987, 512
[INFO] 2021-07-09 17:00:26,065 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.110000074637355e-06, 512
[INFO] 2021-07-09 17:00:26,065 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 512
[INFO] 2021-07-09 17:00:26,066 [run_pretraining.py:  558]:	worker_index: 6, step: 512, cost: 1.737042, mlm loss: 1.737042, speed: 0.438855 steps/s, speed: 3.510841 samples/s, speed: 1797.550456 tokens/s, learning rate: 5.110e-06, loss_scalings: 377.789520, pp_loss: 1.730789
[INFO] 2021-07-09 17:00:26,066 [run_pretraining.py:  512]:	********exe.run_512******* 
/home/gongwb/.local/lib/python3.7/multiprocessing/semaphore_tracker.py:144: UserWarning: semaphore_tracker: There appear to be 91 leaked semaphores to clean up at shutdown
  len(cache))
