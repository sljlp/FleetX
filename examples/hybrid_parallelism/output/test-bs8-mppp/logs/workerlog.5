/home/gongwb/.local/lib/python3.7/site-packages/setuptools/depends.py:2: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0709 16:38:09.913803 36123 init.cc:88] Before Parse: argc is 2, Init commandline: dummy --tryfromenv=check_nan_inf,benchmark,eager_delete_scope,fraction_of_cpu_memory_to_use,initial_cpu_memory_in_mb,init_allocated_mem,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_system_allocator,enable_unused_var_check,free_idle_chunk,free_when_no_cache_hit,call_stack_level,sort_sum_gradient,max_inplace_grad_add,use_pinned_memory,cpu_deterministic,selected_npus,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,gpu_memory_limit_mb 
I0709 16:38:09.913997 36123 init.cc:95] After Parse: argc is 1
-----------  Configuration Arguments -----------
data_dir: ./data
debug: False
do_eval: True
epoch: 100
ernie_config_file: config/ernie_base_config.json
eval_batch_size: 35
eval_data_path: ./data
eval_steps: -1
global_bsz: 8
global_steps: 0
grad_merge: 0
init_checkpoint: 
learning_rate: 0.0001
log_steps: 1
max_seq_len: 512
micro_bsz: 1
num_dp: 1
num_mp: 4
num_pp: 2
num_sharding: 1
num_train_steps: 1600
output_dir: output/test-bs8-mppp
preln: False
save_steps: 500
seed: 2021
use_amp: True
use_hybrid_dp: True
use_lamb: False
use_offload: False
use_recompute: True
use_sharding: True
vocab_file: ./config/30k-clean.vocab.albert
warmup_steps: 10000
weight_decay: 0.01
------------------------------------------------
to run startup
[INFO] 2021-07-09 16:38:10,689 [run_pretraining.py:  216]:	pretraining start
[INFO] 2021-07-09 16:38:10,689 [run_pretraining.py:  234]:	using recompute.
[INFO] 2021-07-09 16:38:10,690 [run_pretraining.py:  279]:	using globa_bsz: 8 micro_bsz: 1, acc_steps: 8
[DEBUG] 2021-07-09 16:38:10,754 [run_pretraining.py:  118]:	========= dp_sharding worker: 0 of 1 ==========
[INFO] 2021-07-09 16:38:10,754 [pretraining_ds_mlm.py:  293]:	Apply sharding in distribution env 0/1
[INFO] 2021-07-09 16:38:10,754 [pretraining_ds_mlm.py:  295]:	read from ./data/part-00000.104,./data/part-00000.100,./data/part-00000.107,./data/part-00000.103,./data/part-00000.10,./data/part-00000.105,./data/part-00000.101,./data/part-00000.102,./data/part-00000.106,./data/part-00000.109,./data/part-00000.108
I0709 16:38:10.755033 36123 reader_py.cc:387] init_lod_tensor_blocking_queue
INFO:root:places would be ommited when DataLoader is not iterable
/home/liupeng51/github/Paddle/build/build_ubuntu_optimizer_checkinf_release_ascend_y_none_3.7.5/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /home/liupeng51/github/FleetX/examples/hybrid_parallelism/model/ernie.py:158
The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
/home/liupeng51/github/Paddle/build/build_ubuntu_optimizer_checkinf_release_ascend_y_none_3.7.5/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /home/liupeng51/github/FleetX/examples/hybrid_parallelism/model/ernie.py:159
The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
/home/liupeng51/github/Paddle/build/build_ubuntu_optimizer_checkinf_release_ascend_y_none_3.7.5/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /home/liupeng51/github/FleetX/examples/hybrid_parallelism/model/transformer_encoder.py:170
The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
/home/liupeng51/github/Paddle/build/build_ubuntu_optimizer_checkinf_release_ascend_y_none_3.7.5/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /home/liupeng51/github/FleetX/examples/hybrid_parallelism/model/transformer_encoder.py:280
The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
/home/liupeng51/github/Paddle/build/build_ubuntu_optimizer_checkinf_release_ascend_y_none_3.7.5/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /home/liupeng51/github/FleetX/examples/hybrid_parallelism/model/transformer_encoder.py:43
The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
/home/liupeng51/github/Paddle/build/build_ubuntu_optimizer_checkinf_release_ascend_y_none_3.7.5/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /home/liupeng51/github/FleetX/examples/hybrid_parallelism/model/transformer_encoder.py:44
The behavior of expression A * B has been unified with elementwise_mul(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_mul(X, Y, axis=0) instead of A * B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
[DEBUG] 2021-07-09 16:38:11,565 [run_pretraining.py:  315]:	base lr: 0.0001
/home/liupeng51/github/Paddle/build/build_ubuntu_optimizer_checkinf_release_ascend_y_none_3.7.5/python/paddle/distributed/fleet/base/fleet_base.py:818: UserWarning: It is recommended to use DistributedStrategy in fleet.init(). The strategy here is only for compatibility. If the strategy in fleet.distributed_optimizer() is not None, then it will overwrite the DistributedStrategy in fleet.init(), which will take effect in distributed training.
  "It is recommended to use DistributedStrategy "
2021-07-09 16:38:11 INFO     Gradient merge in [pp_gm], acc step = [8]
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:Gradient merge in [pp_gm], acc step = [8]
Fri Jul 09 16:38:12-INFO: recompute segment[0]
Fri Jul 09 16:38:12-INFO: segment start op: [squeeze2]: [['shard_index_0.tmp_0']]
Fri Jul 09 16:38:12-INFO: segment end op: [layer_norm]: [['encoder_layer_0_post_ffn_layer_norm_bias', 'encoder_layer_0_post_ffn_layer_norm_scale', 'tmp_10']]
Fri Jul 09 16:38:12-INFO: recompute segment[0]
Fri Jul 09 16:38:12-INFO: segment start op: [squeeze2]: [['shard_index_0.tmp_0']]
Fri Jul 09 16:38:12-INFO: segment end op: [layer_norm]: [['encoder_layer_0_post_ffn_layer_norm_bias', 'encoder_layer_0_post_ffn_layer_norm_scale', 'tmp_10']]
Fri Jul 09 16:38:12-INFO: found [0] vars which cross recompute segment: [set()], better checkpoints might be set to reduce those vars
pp_rank: 1
2021-07-09 16:38:17 INFO     global word size: 8
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:global word size: 8
2021-07-09 16:38:17 INFO     global rank: 5
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:global rank: 5
2021-07-09 16:38:17 INFO     global endpoints: ['192.168.206.27:6170', '192.168.206.27:6171', '192.168.206.27:6172', '192.168.206.27:6173', '192.168.206.27:6174', '192.168.206.27:6175', '192.168.206.27:6176', '192.168.206.27:6177']
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:global endpoints: ['192.168.206.27:6170', '192.168.206.27:6171', '192.168.206.27:6172', '192.168.206.27:6173', '192.168.206.27:6174', '192.168.206.27:6175', '192.168.206.27:6176', '192.168.206.27:6177']
2021-07-09 16:38:17 INFO     global ring id: 3
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:global ring id: 3
2021-07-09 16:38:17 INFO     ##############################
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:##############################
2021-07-09 16:38:17 INFO     mp group size: 4
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:mp group size: 4
2021-07-09 16:38:17 INFO     mp rank: 1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:mp rank: 1
2021-07-09 16:38:17 INFO     mp group id: 1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:mp group id: 1
2021-07-09 16:38:17 INFO     mp group endpoints: ['192.168.206.27:6174', '192.168.206.27:6175', '192.168.206.27:6176', '192.168.206.27:6177']
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:mp group endpoints: ['192.168.206.27:6174', '192.168.206.27:6175', '192.168.206.27:6176', '192.168.206.27:6177']
2021-07-09 16:38:17 INFO     mp ring id: 0
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:mp ring id: 0
2021-07-09 16:38:17 INFO     ##############################
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:##############################
2021-07-09 16:38:17 INFO     sharding group size: 1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:sharding group size: 1
2021-07-09 16:38:17 INFO     sharding rank: -1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:sharding rank: -1
2021-07-09 16:38:17 INFO     sharding group id: -1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:sharding group id: -1
2021-07-09 16:38:17 INFO     sharding group endpoints: []
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:sharding group endpoints: []
2021-07-09 16:38:17 INFO     sharding ring id: -1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:sharding ring id: -1
2021-07-09 16:38:17 INFO     ##############################
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:##############################
2021-07-09 16:38:17 INFO     pp group size: 2
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pp group size: 2
2021-07-09 16:38:17 INFO     pp rank: 1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pp rank: 1
2021-07-09 16:38:17 INFO     pp group id: 0
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pp group id: 0
2021-07-09 16:38:17 INFO     pp group endpoints: ['192.168.206.27:6171', '192.168.206.27:6175']
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pp group endpoints: ['192.168.206.27:6171', '192.168.206.27:6175']
2021-07-09 16:38:17 INFO     pp ring id: 20
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pp ring id: 20
2021-07-09 16:38:17 INFO     ##############################
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:##############################
2021-07-09 16:38:17 INFO     pure dp group size: 1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pure dp group size: 1
2021-07-09 16:38:17 INFO     pure dp rank: -1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pure dp rank: -1
2021-07-09 16:38:17 INFO     pure dp group endpoints: []
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pure dp group endpoints: []
2021-07-09 16:38:17 INFO     pure dp ring id: -1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pure dp ring id: -1
2021-07-09 16:38:17 INFO     ##############################
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:##############################
pp pair:(0, 1), ring_id: 20
pp pair:(1, 0), ring_id: 21
I0709 16:38:36.450546 36123 gen_hccl_id_op_helper.cc:181] Server listening on: 192.168.206.27:6175 successful.
I0709 16:38:37.082293 36123 collective_helper_npu.cc:83] initialized comm: 0xffffd7fbdbf0, nranks: 8, hccl_id: 0xe9df084, rank: 5
I0709 16:38:40.343006 36123 collective_helper_npu.cc:88] initialized comm: 0xffffd7fbdbf0, nranks: 8, hccl_id: 0xe9df084, rank: 5
I0709 16:38:40.343150 36123 collective_helper_npu.cc:93] hccl communicator of rank 5 in ring 3 has been created on device 5, with comm: 0xe8cd670
I0709 16:38:42.949978 36123 gen_hccl_id_op_helper.cc:181] Server listening on: 192.168.206.27:6175 successful.
I0709 16:38:42.951988 36123 collective_helper_npu.cc:83] initialized comm: 0xffffd7fbdbf0, nranks: 4, hccl_id: 0xea21114, rank: 1
I0709 16:38:44.571563 36123 collective_helper_npu.cc:88] initialized comm: 0xffffd7fbdbf0, nranks: 4, hccl_id: 0xea21114, rank: 1
I0709 16:38:44.572795 36123 collective_helper_npu.cc:93] hccl communicator of rank 1 in ring 0 has been created on device 5, with comm: 0xe9685b0
I0709 16:38:45.598277 36123 gen_hccl_id_op_helper.cc:181] Server listening on: 192.168.206.27:6175 successful.
I0709 16:38:46.100214 36123 collective_helper_npu.cc:83] initialized comm: 0xffffd7fbdbf0, nranks: 2, hccl_id: 0xe9dd034, rank: 1
I0709 16:38:47.315480 36123 collective_helper_npu.cc:88] initialized comm: 0xffffd7fbdbf0, nranks: 2, hccl_id: 0xe9dd034, rank: 1
I0709 16:38:47.315650 36123 collective_helper_npu.cc:93] hccl communicator of rank 1 in ring 20 has been created on device 5, with comm: 0xe99b5f0
W0709 16:38:47.573607 36123 gen_hccl_id_op_helper.cc:120] connect addr=192.168.206.27:6171 failed 1 times with reason: Connection refused retry after 0.5 seconds
I0709 16:38:48.075184 36123 collective_helper_npu.cc:83] initialized comm: 0xffffd7fbdbf0, nranks: 2, hccl_id: 0xea2e4d4, rank: 0
I0709 16:38:49.296447 36123 collective_helper_npu.cc:88] initialized comm: 0xffffd7fbdbf0, nranks: 2, hccl_id: 0xea2e4d4, rank: 0
I0709 16:38:49.296586 36123 collective_helper_npu.cc:93] hccl communicator of rank 0 in ring 21 has been created on device 5, with comm: 0xe9af020
Done broadcast
[INFO] 2021-07-09 16:38:49,582 [run_pretraining.py:  512]:	********exe.run_0******* 
I0709 16:38:52.321491 39432 lod_tensor_blocking_queue.h:104] Init queue with size 1
I0709 16:38:52.321687 39432 buffered_reader.cc:41] BufferedReader
[INFO] 2021-07-09 16:41:11,443 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:11,445 [run_pretraining.py:  534]:	loss/total_loss, 10.418046951293945, 1
[INFO] 2021-07-09 16:41:11,445 [run_pretraining.py:  535]:	loss/mlm_loss, 10.418046951293945, 1
[INFO] 2021-07-09 16:41:11,445 [run_pretraining.py:  536]:	lr/scheduled_lr, 0.0, 1
[INFO] 2021-07-09 16:41:11,445 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 1
[INFO] 2021-07-09 16:41:11,445 [run_pretraining.py:  558]:	worker_index: 5, step: 1, cost: 10.418047, mlm loss: 10.418047, speed: 0.007049 steps/s, speed: 0.056392 samples/s, speed: 28.872629 tokens/s, learning rate: 0.000e+00, loss_scalings: 32768.000000, pp_loss: 10.295198
[INFO] 2021-07-09 16:41:11,445 [run_pretraining.py:  512]:	********exe.run_1******* 
[INFO] 2021-07-09 16:41:16,684 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:16,685 [run_pretraining.py:  534]:	loss/total_loss, 10.214278221130371, 2
[INFO] 2021-07-09 16:41:16,685 [run_pretraining.py:  535]:	loss/mlm_loss, 10.214278221130371, 2
[INFO] 2021-07-09 16:41:16,685 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.99999905104687e-09, 2
[INFO] 2021-07-09 16:41:16,685 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 2
[INFO] 2021-07-09 16:41:16,685 [run_pretraining.py:  558]:	worker_index: 5, step: 2, cost: 10.214278, mlm loss: 10.214278, speed: 0.190864 steps/s, speed: 1.526911 samples/s, speed: 781.778595 tokens/s, learning rate: 1.000e-08, loss_scalings: 32768.000000, pp_loss: 10.217410
[INFO] 2021-07-09 16:41:16,685 [run_pretraining.py:  512]:	********exe.run_2******* 
[INFO] 2021-07-09 16:41:18,808 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:18,808 [run_pretraining.py:  534]:	loss/total_loss, 10.274088859558105, 3
[INFO] 2021-07-09 16:41:18,808 [run_pretraining.py:  535]:	loss/mlm_loss, 10.274088859558105, 3
[INFO] 2021-07-09 16:41:18,809 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.999999810209374e-08, 3
[INFO] 2021-07-09 16:41:18,809 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 3
[INFO] 2021-07-09 16:41:18,809 [run_pretraining.py:  558]:	worker_index: 5, step: 3, cost: 10.274089, mlm loss: 10.274089, speed: 0.471089 steps/s, speed: 3.768714 samples/s, speed: 1929.581768 tokens/s, learning rate: 2.000e-08, loss_scalings: 32768.000000, pp_loss: 10.294040
[INFO] 2021-07-09 16:41:18,809 [run_pretraining.py:  512]:	********exe.run_3******* 
[INFO] 2021-07-09 16:41:20,921 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:20,921 [run_pretraining.py:  534]:	loss/total_loss, 10.406414031982422, 4
[INFO] 2021-07-09 16:41:20,921 [run_pretraining.py:  535]:	loss/mlm_loss, 10.406414031982422, 4
[INFO] 2021-07-09 16:41:20,921 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.999999892949745e-08, 4
[INFO] 2021-07-09 16:41:20,921 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 4
[INFO] 2021-07-09 16:41:20,922 [run_pretraining.py:  558]:	worker_index: 5, step: 4, cost: 10.406414, mlm loss: 10.406414, speed: 0.473450 steps/s, speed: 3.787601 samples/s, speed: 1939.251654 tokens/s, learning rate: 3.000e-08, loss_scalings: 32768.000000, pp_loss: 10.263885
[INFO] 2021-07-09 16:41:20,922 [run_pretraining.py:  512]:	********exe.run_4******* 
[INFO] 2021-07-09 16:41:23,083 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:23,084 [run_pretraining.py:  534]:	loss/total_loss, 10.200922012329102, 5
[INFO] 2021-07-09 16:41:23,084 [run_pretraining.py:  535]:	loss/mlm_loss, 10.200922012329102, 5
[INFO] 2021-07-09 16:41:23,084 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.999999620418748e-08, 5
[INFO] 2021-07-09 16:41:23,085 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 5
[INFO] 2021-07-09 16:41:23,085 [run_pretraining.py:  558]:	worker_index: 5, step: 5, cost: 10.200922, mlm loss: 10.200922, speed: 0.462482 steps/s, speed: 3.699853 samples/s, speed: 1894.324677 tokens/s, learning rate: 4.000e-08, loss_scalings: 32768.000000, pp_loss: 10.279092
[INFO] 2021-07-09 16:41:23,085 [run_pretraining.py:  512]:	********exe.run_5******* 
[INFO] 2021-07-09 16:41:25,220 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:25,221 [run_pretraining.py:  534]:	loss/total_loss, 10.251690864562988, 6
[INFO] 2021-07-09 16:41:25,221 [run_pretraining.py:  535]:	loss/mlm_loss, 10.251690864562988, 6
[INFO] 2021-07-09 16:41:25,221 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.000000058430487e-08, 6
[INFO] 2021-07-09 16:41:25,221 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 6
[INFO] 2021-07-09 16:41:25,221 [run_pretraining.py:  558]:	worker_index: 5, step: 6, cost: 10.251691, mlm loss: 10.251691, speed: 0.468204 steps/s, speed: 3.745628 samples/s, speed: 1917.761688 tokens/s, learning rate: 5.000e-08, loss_scalings: 32768.000000, pp_loss: 10.287147
[INFO] 2021-07-09 16:41:25,221 [run_pretraining.py:  512]:	********exe.run_6******* 
[INFO] 2021-07-09 16:41:27,421 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:27,422 [run_pretraining.py:  534]:	loss/total_loss, 10.286112785339355, 7
[INFO] 2021-07-09 16:41:27,422 [run_pretraining.py:  535]:	loss/mlm_loss, 10.286112785339355, 7
[INFO] 2021-07-09 16:41:27,422 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.99999978589949e-08, 7
[INFO] 2021-07-09 16:41:27,422 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 7
[INFO] 2021-07-09 16:41:27,423 [run_pretraining.py:  558]:	worker_index: 5, step: 7, cost: 10.286113, mlm loss: 10.286113, speed: 0.454431 steps/s, speed: 3.635450 samples/s, speed: 1861.350356 tokens/s, learning rate: 6.000e-08, loss_scalings: 32768.000000, pp_loss: 10.275717
[INFO] 2021-07-09 16:41:27,423 [run_pretraining.py:  512]:	********exe.run_7******* 
[INFO] 2021-07-09 16:41:29,619 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:29,619 [run_pretraining.py:  534]:	loss/total_loss, 10.282490730285645, 8
[INFO] 2021-07-09 16:41:29,620 [run_pretraining.py:  535]:	loss/mlm_loss, 10.282490730285645, 8
[INFO] 2021-07-09 16:41:29,620 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.999999868639861e-08, 8
[INFO] 2021-07-09 16:41:29,620 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 8
[INFO] 2021-07-09 16:41:29,620 [run_pretraining.py:  558]:	worker_index: 5, step: 8, cost: 10.282491, mlm loss: 10.282491, speed: 0.455214 steps/s, speed: 3.641713 samples/s, speed: 1864.556943 tokens/s, learning rate: 7.000e-08, loss_scalings: 32768.000000, pp_loss: 10.359988
[INFO] 2021-07-09 16:41:29,620 [run_pretraining.py:  512]:	********exe.run_8******* 
[INFO] 2021-07-09 16:41:31,788 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:31,789 [run_pretraining.py:  534]:	loss/total_loss, 10.290247917175293, 9
[INFO] 2021-07-09 16:41:31,789 [run_pretraining.py:  535]:	loss/mlm_loss, 10.290247917175293, 9
[INFO] 2021-07-09 16:41:31,789 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.999999240837496e-08, 9
[INFO] 2021-07-09 16:41:31,789 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 9
[INFO] 2021-07-09 16:41:31,789 [run_pretraining.py:  558]:	worker_index: 5, step: 9, cost: 10.290248, mlm loss: 10.290248, speed: 0.461088 steps/s, speed: 3.688707 samples/s, speed: 1888.618085 tokens/s, learning rate: 8.000e-08, loss_scalings: 32768.000000, pp_loss: 10.297378
[INFO] 2021-07-09 16:41:31,789 [run_pretraining.py:  512]:	********exe.run_9******* 
[INFO] 2021-07-09 16:41:33,977 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:33,978 [run_pretraining.py:  534]:	loss/total_loss, 10.181289672851562, 10
[INFO] 2021-07-09 16:41:33,978 [run_pretraining.py:  535]:	loss/mlm_loss, 10.181289672851562, 10
[INFO] 2021-07-09 16:41:33,978 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.999999323577867e-08, 10
[INFO] 2021-07-09 16:41:33,978 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 10
[INFO] 2021-07-09 16:41:33,978 [run_pretraining.py:  558]:	worker_index: 5, step: 10, cost: 10.181290, mlm loss: 10.181290, speed: 0.456981 steps/s, speed: 3.655847 samples/s, speed: 1871.793501 tokens/s, learning rate: 9.000e-08, loss_scalings: 32768.000000, pp_loss: 10.203049
[INFO] 2021-07-09 16:41:33,978 [run_pretraining.py:  512]:	********exe.run_10******* 
[INFO] 2021-07-09 16:41:36,154 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:36,155 [run_pretraining.py:  534]:	loss/total_loss, 10.150909423828125, 11
[INFO] 2021-07-09 16:41:36,155 [run_pretraining.py:  535]:	loss/mlm_loss, 10.150909423828125, 11
[INFO] 2021-07-09 16:41:36,155 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0000000116860974e-07, 11
[INFO] 2021-07-09 16:41:36,155 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 11
[INFO] 2021-07-09 16:41:36,155 [run_pretraining.py:  558]:	worker_index: 5, step: 11, cost: 10.150909, mlm loss: 10.150909, speed: 0.459509 steps/s, speed: 3.676075 samples/s, speed: 1882.150329 tokens/s, learning rate: 1.000e-07, loss_scalings: 32768.000000, pp_loss: 10.284066
[INFO] 2021-07-09 16:41:36,155 [run_pretraining.py:  512]:	********exe.run_11******* 
[INFO] 2021-07-09 16:41:38,368 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:38,369 [run_pretraining.py:  534]:	loss/total_loss, 10.445723533630371, 12
[INFO] 2021-07-09 16:41:38,370 [run_pretraining.py:  535]:	loss/mlm_loss, 10.445723533630371, 12
[INFO] 2021-07-09 16:41:38,370 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.099999948905861e-07, 12
[INFO] 2021-07-09 16:41:38,370 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 12
[INFO] 2021-07-09 16:41:38,370 [run_pretraining.py:  558]:	worker_index: 5, step: 12, cost: 10.445724, mlm loss: 10.445724, speed: 0.451758 steps/s, speed: 3.614067 samples/s, speed: 1850.402259 tokens/s, learning rate: 1.100e-07, loss_scalings: 32768.000000, pp_loss: 10.326207
[INFO] 2021-07-09 16:41:38,370 [run_pretraining.py:  512]:	********exe.run_12******* 
[INFO] 2021-07-09 16:41:41,079 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:41,079 [run_pretraining.py:  534]:	loss/total_loss, 10.173652648925781, 13
[INFO] 2021-07-09 16:41:41,080 [run_pretraining.py:  535]:	loss/mlm_loss, 10.173652648925781, 13
[INFO] 2021-07-09 16:41:41,080 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.199999957179898e-07, 13
[INFO] 2021-07-09 16:41:41,080 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 13
[INFO] 2021-07-09 16:41:41,080 [run_pretraining.py:  558]:	worker_index: 5, step: 13, cost: 10.173653, mlm loss: 10.173653, speed: 0.369104 steps/s, speed: 2.952832 samples/s, speed: 1511.849823 tokens/s, learning rate: 1.200e-07, loss_scalings: 26214.400391, pp_loss: 10.282109
[INFO] 2021-07-09 16:41:41,080 [run_pretraining.py:  512]:	********exe.run_13******* 
[INFO] 2021-07-09 16:41:43,401 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:43,401 [run_pretraining.py:  534]:	loss/total_loss, 10.313679695129395, 14
[INFO] 2021-07-09 16:41:43,401 [run_pretraining.py:  535]:	loss/mlm_loss, 10.313679695129395, 14
[INFO] 2021-07-09 16:41:43,401 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3000000365082087e-07, 14
[INFO] 2021-07-09 16:41:43,401 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 14
[INFO] 2021-07-09 16:41:43,402 [run_pretraining.py:  558]:	worker_index: 5, step: 14, cost: 10.313680, mlm loss: 10.313680, speed: 0.430855 steps/s, speed: 3.446840 samples/s, speed: 1764.782056 tokens/s, learning rate: 1.300e-07, loss_scalings: 26214.400391, pp_loss: 10.251645
[INFO] 2021-07-09 16:41:43,402 [run_pretraining.py:  512]:	********exe.run_14******* 
[INFO] 2021-07-09 16:41:45,651 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:45,651 [run_pretraining.py:  534]:	loss/total_loss, 10.319520950317383, 15
[INFO] 2021-07-09 16:41:45,651 [run_pretraining.py:  535]:	loss/mlm_loss, 10.319520950317383, 15
[INFO] 2021-07-09 16:41:45,651 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3999999737279722e-07, 15
[INFO] 2021-07-09 16:41:45,651 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 15
[INFO] 2021-07-09 16:41:45,652 [run_pretraining.py:  558]:	worker_index: 5, step: 15, cost: 10.319521, mlm loss: 10.319521, speed: 0.444564 steps/s, speed: 3.556515 samples/s, speed: 1820.935511 tokens/s, learning rate: 1.400e-07, loss_scalings: 26214.400391, pp_loss: 10.293927
[INFO] 2021-07-09 16:41:45,652 [run_pretraining.py:  512]:	********exe.run_15******* 
[INFO] 2021-07-09 16:41:47,874 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:47,874 [run_pretraining.py:  534]:	loss/total_loss, 10.233867645263672, 16
[INFO] 2021-07-09 16:41:47,875 [run_pretraining.py:  535]:	loss/mlm_loss, 10.233867645263672, 16
[INFO] 2021-07-09 16:41:47,875 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4999999109477358e-07, 16
[INFO] 2021-07-09 16:41:47,875 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 16
[INFO] 2021-07-09 16:41:47,875 [run_pretraining.py:  558]:	worker_index: 5, step: 16, cost: 10.233868, mlm loss: 10.233868, speed: 0.449951 steps/s, speed: 3.599604 samples/s, speed: 1842.997434 tokens/s, learning rate: 1.500e-07, loss_scalings: 26214.400391, pp_loss: 10.236120
[INFO] 2021-07-09 16:41:47,875 [run_pretraining.py:  512]:	********exe.run_16******* 
[INFO] 2021-07-09 16:41:50,209 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:50,209 [run_pretraining.py:  534]:	loss/total_loss, 10.20189094543457, 17
[INFO] 2021-07-09 16:41:50,209 [run_pretraining.py:  535]:	loss/mlm_loss, 10.20189094543457, 17
[INFO] 2021-07-09 16:41:50,209 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5999998481674993e-07, 17
[INFO] 2021-07-09 16:41:50,210 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 17
[INFO] 2021-07-09 16:41:50,210 [run_pretraining.py:  558]:	worker_index: 5, step: 17, cost: 10.201891, mlm loss: 10.201891, speed: 0.428415 steps/s, speed: 3.427322 samples/s, speed: 1754.788877 tokens/s, learning rate: 1.600e-07, loss_scalings: 26214.400391, pp_loss: 10.281964
[INFO] 2021-07-09 16:41:50,210 [run_pretraining.py:  512]:	********exe.run_17******* 
[INFO] 2021-07-09 16:41:52,457 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:52,458 [run_pretraining.py:  534]:	loss/total_loss, 10.176497459411621, 18
[INFO] 2021-07-09 16:41:52,458 [run_pretraining.py:  535]:	loss/mlm_loss, 10.176497459411621, 18
[INFO] 2021-07-09 16:41:52,458 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.69999992749581e-07, 18
[INFO] 2021-07-09 16:41:52,458 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 18
[INFO] 2021-07-09 16:41:52,458 [run_pretraining.py:  558]:	worker_index: 5, step: 18, cost: 10.176497, mlm loss: 10.176497, speed: 0.444863 steps/s, speed: 3.558901 samples/s, speed: 1822.157088 tokens/s, learning rate: 1.700e-07, loss_scalings: 26214.400391, pp_loss: 10.239353
[INFO] 2021-07-09 16:41:52,458 [run_pretraining.py:  512]:	********exe.run_18******* 
[INFO] 2021-07-09 16:41:54,736 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:54,736 [run_pretraining.py:  534]:	loss/total_loss, 10.399039268493652, 19
[INFO] 2021-07-09 16:41:54,737 [run_pretraining.py:  535]:	loss/mlm_loss, 10.399039268493652, 19
[INFO] 2021-07-09 16:41:54,737 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7999998647155735e-07, 19
[INFO] 2021-07-09 16:41:54,737 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 19
[INFO] 2021-07-09 16:41:54,737 [run_pretraining.py:  558]:	worker_index: 5, step: 19, cost: 10.399039, mlm loss: 10.399039, speed: 0.438985 steps/s, speed: 3.511881 samples/s, speed: 1798.083256 tokens/s, learning rate: 1.800e-07, loss_scalings: 26214.400391, pp_loss: 10.319363
[INFO] 2021-07-09 16:41:54,737 [run_pretraining.py:  512]:	********exe.run_19******* 
[INFO] 2021-07-09 16:41:57,022 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:57,023 [run_pretraining.py:  534]:	loss/total_loss, 10.31933879852295, 20
[INFO] 2021-07-09 16:41:57,023 [run_pretraining.py:  535]:	loss/mlm_loss, 10.31933879852295, 20
[INFO] 2021-07-09 16:41:57,023 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8999999440438842e-07, 20
[INFO] 2021-07-09 16:41:57,023 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 20
[INFO] 2021-07-09 16:41:57,023 [run_pretraining.py:  558]:	worker_index: 5, step: 20, cost: 10.319339, mlm loss: 10.319339, speed: 0.437483 steps/s, speed: 3.499863 samples/s, speed: 1791.929828 tokens/s, learning rate: 1.900e-07, loss_scalings: 26214.400391, pp_loss: 10.207154
[INFO] 2021-07-09 16:41:57,023 [run_pretraining.py:  512]:	********exe.run_20******* 
[INFO] 2021-07-09 16:41:59,310 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:41:59,310 [run_pretraining.py:  534]:	loss/total_loss, 10.158307075500488, 21
[INFO] 2021-07-09 16:41:59,310 [run_pretraining.py:  535]:	loss/mlm_loss, 10.158307075500488, 21
[INFO] 2021-07-09 16:41:59,310 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0000000233721948e-07, 21
[INFO] 2021-07-09 16:41:59,310 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 21
[INFO] 2021-07-09 16:41:59,310 [run_pretraining.py:  558]:	worker_index: 5, step: 21, cost: 10.158307, mlm loss: 10.158307, speed: 0.437365 steps/s, speed: 3.498917 samples/s, speed: 1791.445313 tokens/s, learning rate: 2.000e-07, loss_scalings: 26214.400391, pp_loss: 10.261676
[INFO] 2021-07-09 16:41:59,311 [run_pretraining.py:  512]:	********exe.run_21******* 
[INFO] 2021-07-09 16:42:01,590 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:01,590 [run_pretraining.py:  534]:	loss/total_loss, 10.428173065185547, 22
[INFO] 2021-07-09 16:42:01,591 [run_pretraining.py:  535]:	loss/mlm_loss, 10.428173065185547, 22
[INFO] 2021-07-09 16:42:01,591 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0999998184834112e-07, 22
[INFO] 2021-07-09 16:42:01,591 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 22
[INFO] 2021-07-09 16:42:01,591 [run_pretraining.py:  558]:	worker_index: 5, step: 22, cost: 10.428173, mlm loss: 10.428173, speed: 0.438671 steps/s, speed: 3.509368 samples/s, speed: 1796.796384 tokens/s, learning rate: 2.100e-07, loss_scalings: 26214.400391, pp_loss: 10.330517
[INFO] 2021-07-09 16:42:01,591 [run_pretraining.py:  512]:	********exe.run_22******* 
[INFO] 2021-07-09 16:42:03,805 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:03,805 [run_pretraining.py:  534]:	loss/total_loss, 10.292258262634277, 23
[INFO] 2021-07-09 16:42:03,805 [run_pretraining.py:  535]:	loss/mlm_loss, 10.292258262634277, 23
[INFO] 2021-07-09 16:42:03,805 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.199999897811722e-07, 23
[INFO] 2021-07-09 16:42:03,806 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 23
[INFO] 2021-07-09 16:42:03,806 [run_pretraining.py:  558]:	worker_index: 5, step: 23, cost: 10.292258, mlm loss: 10.292258, speed: 0.451640 steps/s, speed: 3.613119 samples/s, speed: 1849.916687 tokens/s, learning rate: 2.200e-07, loss_scalings: 26214.400391, pp_loss: 10.228169
[INFO] 2021-07-09 16:42:03,806 [run_pretraining.py:  512]:	********exe.run_23******* 
[INFO] 2021-07-09 16:42:06,026 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:06,027 [run_pretraining.py:  534]:	loss/total_loss, 10.266434669494629, 24
[INFO] 2021-07-09 16:42:06,027 [run_pretraining.py:  535]:	loss/mlm_loss, 10.266434669494629, 24
[INFO] 2021-07-09 16:42:06,027 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2999999771400326e-07, 24
[INFO] 2021-07-09 16:42:06,027 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 24
[INFO] 2021-07-09 16:42:06,027 [run_pretraining.py:  558]:	worker_index: 5, step: 24, cost: 10.266435, mlm loss: 10.266435, speed: 0.450257 steps/s, speed: 3.602058 samples/s, speed: 1844.253554 tokens/s, learning rate: 2.300e-07, loss_scalings: 26214.400391, pp_loss: 10.205631
[INFO] 2021-07-09 16:42:06,027 [run_pretraining.py:  512]:	********exe.run_24******* 
[INFO] 2021-07-09 16:42:08,207 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:08,207 [run_pretraining.py:  534]:	loss/total_loss, 10.566575050354004, 25
[INFO] 2021-07-09 16:42:08,208 [run_pretraining.py:  535]:	loss/mlm_loss, 10.566575050354004, 25
[INFO] 2021-07-09 16:42:08,208 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.399999914359796e-07, 25
[INFO] 2021-07-09 16:42:08,208 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 25
[INFO] 2021-07-09 16:42:08,208 [run_pretraining.py:  558]:	worker_index: 5, step: 25, cost: 10.566575, mlm loss: 10.566575, speed: 0.458711 steps/s, speed: 3.669687 samples/s, speed: 1878.879915 tokens/s, learning rate: 2.400e-07, loss_scalings: 26214.400391, pp_loss: 10.265429
[INFO] 2021-07-09 16:42:08,208 [run_pretraining.py:  512]:	********exe.run_25******* 
[INFO] 2021-07-09 16:42:10,488 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:10,488 [run_pretraining.py:  534]:	loss/total_loss, 10.223736763000488, 26
[INFO] 2021-07-09 16:42:10,489 [run_pretraining.py:  535]:	loss/mlm_loss, 10.223736763000488, 26
[INFO] 2021-07-09 16:42:10,489 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.499999993688107e-07, 26
[INFO] 2021-07-09 16:42:10,489 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 26
[INFO] 2021-07-09 16:42:10,489 [run_pretraining.py:  558]:	worker_index: 5, step: 26, cost: 10.223737, mlm loss: 10.223737, speed: 0.438539 steps/s, speed: 3.508313 samples/s, speed: 1796.256083 tokens/s, learning rate: 2.500e-07, loss_scalings: 26214.400391, pp_loss: 10.204285
[INFO] 2021-07-09 16:42:10,489 [run_pretraining.py:  512]:	********exe.run_26******* 
[INFO] 2021-07-09 16:42:12,721 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:12,721 [run_pretraining.py:  534]:	loss/total_loss, 10.116491317749023, 27
[INFO] 2021-07-09 16:42:12,722 [run_pretraining.py:  535]:	loss/mlm_loss, 10.116491317749023, 27
[INFO] 2021-07-09 16:42:12,722 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6000000730164174e-07, 27
[INFO] 2021-07-09 16:42:12,722 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 27
[INFO] 2021-07-09 16:42:12,722 [run_pretraining.py:  558]:	worker_index: 5, step: 27, cost: 10.116491, mlm loss: 10.116491, speed: 0.447964 steps/s, speed: 3.583710 samples/s, speed: 1834.859584 tokens/s, learning rate: 2.600e-07, loss_scalings: 26214.400391, pp_loss: 10.114903
[INFO] 2021-07-09 16:42:12,722 [run_pretraining.py:  512]:	********exe.run_27******* 
[INFO] 2021-07-09 16:42:15,006 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:15,007 [run_pretraining.py:  534]:	loss/total_loss, 10.331230163574219, 28
[INFO] 2021-07-09 16:42:15,007 [run_pretraining.py:  535]:	loss/mlm_loss, 10.331230163574219, 28
[INFO] 2021-07-09 16:42:15,007 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.699999868127634e-07, 28
[INFO] 2021-07-09 16:42:15,007 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 28
[INFO] 2021-07-09 16:42:15,007 [run_pretraining.py:  558]:	worker_index: 5, step: 28, cost: 10.331230, mlm loss: 10.331230, speed: 0.437757 steps/s, speed: 3.502052 samples/s, speed: 1793.050653 tokens/s, learning rate: 2.700e-07, loss_scalings: 26214.400391, pp_loss: 10.232049
[INFO] 2021-07-09 16:42:15,007 [run_pretraining.py:  512]:	********exe.run_28******* 
[INFO] 2021-07-09 16:42:17,313 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:17,314 [run_pretraining.py:  534]:	loss/total_loss, 10.19297981262207, 29
[INFO] 2021-07-09 16:42:17,314 [run_pretraining.py:  535]:	loss/mlm_loss, 10.19297981262207, 29
[INFO] 2021-07-09 16:42:17,314 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7999999474559445e-07, 29
[INFO] 2021-07-09 16:42:17,314 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 29
[INFO] 2021-07-09 16:42:17,314 [run_pretraining.py:  558]:	worker_index: 5, step: 29, cost: 10.192980, mlm loss: 10.192980, speed: 0.433551 steps/s, speed: 3.468406 samples/s, speed: 1775.823905 tokens/s, learning rate: 2.800e-07, loss_scalings: 26214.400391, pp_loss: 10.119808
[INFO] 2021-07-09 16:42:17,314 [run_pretraining.py:  512]:	********exe.run_29******* 
[INFO] 2021-07-09 16:42:19,515 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:19,515 [run_pretraining.py:  534]:	loss/total_loss, 10.043155670166016, 30
[INFO] 2021-07-09 16:42:19,515 [run_pretraining.py:  535]:	loss/mlm_loss, 10.043155670166016, 30
[INFO] 2021-07-09 16:42:19,515 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.900000026784255e-07, 30
[INFO] 2021-07-09 16:42:19,515 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 30
[INFO] 2021-07-09 16:42:19,515 [run_pretraining.py:  558]:	worker_index: 5, step: 30, cost: 10.043156, mlm loss: 10.043156, speed: 0.454395 steps/s, speed: 3.635158 samples/s, speed: 1861.201134 tokens/s, learning rate: 2.900e-07, loss_scalings: 26214.400391, pp_loss: 10.062157
[INFO] 2021-07-09 16:42:19,516 [run_pretraining.py:  512]:	********exe.run_30******* 
[INFO] 2021-07-09 16:42:21,718 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:21,719 [run_pretraining.py:  534]:	loss/total_loss, 10.012307167053223, 31
[INFO] 2021-07-09 16:42:21,719 [run_pretraining.py:  535]:	loss/mlm_loss, 10.012307167053223, 31
[INFO] 2021-07-09 16:42:21,719 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9999998218954715e-07, 31
[INFO] 2021-07-09 16:42:21,719 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 31
[INFO] 2021-07-09 16:42:21,719 [run_pretraining.py:  558]:	worker_index: 5, step: 31, cost: 10.012307, mlm loss: 10.012307, speed: 0.453953 steps/s, speed: 3.631623 samples/s, speed: 1859.391001 tokens/s, learning rate: 3.000e-07, loss_scalings: 26214.400391, pp_loss: 10.068890
[INFO] 2021-07-09 16:42:21,719 [run_pretraining.py:  512]:	********exe.run_31******* 
[INFO] 2021-07-09 16:42:23,915 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:23,916 [run_pretraining.py:  534]:	loss/total_loss, 10.215415954589844, 32
[INFO] 2021-07-09 16:42:23,916 [run_pretraining.py:  535]:	loss/mlm_loss, 10.215415954589844, 32
[INFO] 2021-07-09 16:42:23,916 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.099999901223782e-07, 32
[INFO] 2021-07-09 16:42:23,916 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 32
[INFO] 2021-07-09 16:42:23,916 [run_pretraining.py:  558]:	worker_index: 5, step: 32, cost: 10.215416, mlm loss: 10.215416, speed: 0.455201 steps/s, speed: 3.641611 samples/s, speed: 1864.504735 tokens/s, learning rate: 3.100e-07, loss_scalings: 26214.400391, pp_loss: 10.088328
[INFO] 2021-07-09 16:42:23,917 [run_pretraining.py:  512]:	********exe.run_32******* 
[INFO] 2021-07-09 16:42:26,117 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:26,117 [run_pretraining.py:  534]:	loss/total_loss, 9.9874906539917, 33
[INFO] 2021-07-09 16:42:26,117 [run_pretraining.py:  535]:	loss/mlm_loss, 9.9874906539917, 33
[INFO] 2021-07-09 16:42:26,117 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.1999996963349986e-07, 33
[INFO] 2021-07-09 16:42:26,117 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 33
[INFO] 2021-07-09 16:42:26,118 [run_pretraining.py:  558]:	worker_index: 5, step: 33, cost: 9.987491, mlm loss: 9.987491, speed: 0.454477 steps/s, speed: 3.635816 samples/s, speed: 1861.537725 tokens/s, learning rate: 3.200e-07, loss_scalings: 26214.400391, pp_loss: 10.033962
[INFO] 2021-07-09 16:42:26,118 [run_pretraining.py:  512]:	********exe.run_33******* 
[INFO] 2021-07-09 16:42:28,334 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:28,335 [run_pretraining.py:  534]:	loss/total_loss, 10.102714538574219, 34
[INFO] 2021-07-09 16:42:28,335 [run_pretraining.py:  535]:	loss/mlm_loss, 10.102714538574219, 34
[INFO] 2021-07-09 16:42:28,335 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.2999997756633093e-07, 34
[INFO] 2021-07-09 16:42:28,335 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 34
[INFO] 2021-07-09 16:42:28,335 [run_pretraining.py:  558]:	worker_index: 5, step: 34, cost: 10.102715, mlm loss: 10.102715, speed: 0.451084 steps/s, speed: 3.608673 samples/s, speed: 1847.640668 tokens/s, learning rate: 3.300e-07, loss_scalings: 26214.400391, pp_loss: 10.009132
[INFO] 2021-07-09 16:42:28,335 [run_pretraining.py:  512]:	********exe.run_34******* 
[INFO] 2021-07-09 16:42:30,590 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:30,591 [run_pretraining.py:  534]:	loss/total_loss, 10.062847137451172, 35
[INFO] 2021-07-09 16:42:30,591 [run_pretraining.py:  535]:	loss/mlm_loss, 10.062847137451172, 35
[INFO] 2021-07-09 16:42:30,591 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.39999985499162e-07, 35
[INFO] 2021-07-09 16:42:30,591 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 35
[INFO] 2021-07-09 16:42:30,591 [run_pretraining.py:  558]:	worker_index: 5, step: 35, cost: 10.062847, mlm loss: 10.062847, speed: 0.443430 steps/s, speed: 3.547439 samples/s, speed: 1816.288637 tokens/s, learning rate: 3.400e-07, loss_scalings: 26214.400391, pp_loss: 9.956169
[INFO] 2021-07-09 16:42:30,591 [run_pretraining.py:  512]:	********exe.run_35******* 
[INFO] 2021-07-09 16:42:32,731 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:32,731 [run_pretraining.py:  534]:	loss/total_loss, 9.941142082214355, 36
[INFO] 2021-07-09 16:42:32,731 [run_pretraining.py:  535]:	loss/mlm_loss, 9.941142082214355, 36
[INFO] 2021-07-09 16:42:32,732 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.4999999343199306e-07, 36
[INFO] 2021-07-09 16:42:32,732 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 36
[INFO] 2021-07-09 16:42:32,732 [run_pretraining.py:  558]:	worker_index: 5, step: 36, cost: 9.941142, mlm loss: 9.941142, speed: 0.467265 steps/s, speed: 3.738122 samples/s, speed: 1913.918379 tokens/s, learning rate: 3.500e-07, loss_scalings: 26214.400391, pp_loss: 9.969513
[INFO] 2021-07-09 16:42:32,732 [run_pretraining.py:  512]:	********exe.run_36******* 
[INFO] 2021-07-09 16:42:34,810 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:34,810 [run_pretraining.py:  534]:	loss/total_loss, 10.108440399169922, 37
[INFO] 2021-07-09 16:42:34,811 [run_pretraining.py:  535]:	loss/mlm_loss, 10.108440399169922, 37
[INFO] 2021-07-09 16:42:34,811 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.599999729431147e-07, 37
[INFO] 2021-07-09 16:42:34,811 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 37
[INFO] 2021-07-09 16:42:34,811 [run_pretraining.py:  558]:	worker_index: 5, step: 37, cost: 10.108440, mlm loss: 10.108440, speed: 0.481137 steps/s, speed: 3.849093 samples/s, speed: 1970.735749 tokens/s, learning rate: 3.600e-07, loss_scalings: 26214.400391, pp_loss: 9.994370
[INFO] 2021-07-09 16:42:34,811 [run_pretraining.py:  512]:	********exe.run_37******* 
[INFO] 2021-07-09 16:42:36,889 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:36,889 [run_pretraining.py:  534]:	loss/total_loss, 9.86794662475586, 38
[INFO] 2021-07-09 16:42:36,889 [run_pretraining.py:  535]:	loss/mlm_loss, 9.86794662475586, 38
[INFO] 2021-07-09 16:42:36,889 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.6999998087594577e-07, 38
[INFO] 2021-07-09 16:42:36,890 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 38
[INFO] 2021-07-09 16:42:36,890 [run_pretraining.py:  558]:	worker_index: 5, step: 38, cost: 9.867947, mlm loss: 9.867947, speed: 0.481186 steps/s, speed: 3.849485 samples/s, speed: 1970.936065 tokens/s, learning rate: 3.700e-07, loss_scalings: 26214.400391, pp_loss: 9.904451
[INFO] 2021-07-09 16:42:36,890 [run_pretraining.py:  512]:	********exe.run_38******* 
[INFO] 2021-07-09 16:42:38,993 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:38,993 [run_pretraining.py:  534]:	loss/total_loss, 10.080947875976562, 39
[INFO] 2021-07-09 16:42:38,993 [run_pretraining.py:  535]:	loss/mlm_loss, 10.080947875976562, 39
[INFO] 2021-07-09 16:42:38,993 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.7999998880877683e-07, 39
[INFO] 2021-07-09 16:42:38,993 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 39
[INFO] 2021-07-09 16:42:38,994 [run_pretraining.py:  558]:	worker_index: 5, step: 39, cost: 10.080948, mlm loss: 10.080948, speed: 0.475464 steps/s, speed: 3.803713 samples/s, speed: 1947.501090 tokens/s, learning rate: 3.800e-07, loss_scalings: 26214.400391, pp_loss: 9.950052
[INFO] 2021-07-09 16:42:38,994 [run_pretraining.py:  512]:	********exe.run_39******* 
[INFO] 2021-07-09 16:42:41,052 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:41,053 [run_pretraining.py:  534]:	loss/total_loss, 9.969115257263184, 40
[INFO] 2021-07-09 16:42:41,053 [run_pretraining.py:  535]:	loss/mlm_loss, 9.969115257263184, 40
[INFO] 2021-07-09 16:42:41,053 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.8999996831989847e-07, 40
[INFO] 2021-07-09 16:42:41,053 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 40
[INFO] 2021-07-09 16:42:41,053 [run_pretraining.py:  558]:	worker_index: 5, step: 40, cost: 9.969115, mlm loss: 9.969115, speed: 0.485753 steps/s, speed: 3.886024 samples/s, speed: 1989.644180 tokens/s, learning rate: 3.900e-07, loss_scalings: 26214.400391, pp_loss: 9.958806
[INFO] 2021-07-09 16:42:41,053 [run_pretraining.py:  512]:	********exe.run_40******* 
[INFO] 2021-07-09 16:42:43,124 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:43,125 [run_pretraining.py:  534]:	loss/total_loss, 9.912776947021484, 41
[INFO] 2021-07-09 16:42:43,125 [run_pretraining.py:  535]:	loss/mlm_loss, 9.912776947021484, 41
[INFO] 2021-07-09 16:42:43,125 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.0000000467443897e-07, 41
[INFO] 2021-07-09 16:42:43,125 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 41
[INFO] 2021-07-09 16:42:43,125 [run_pretraining.py:  558]:	worker_index: 5, step: 41, cost: 9.912777, mlm loss: 9.912777, speed: 0.482683 steps/s, speed: 3.861463 samples/s, speed: 1977.068954 tokens/s, learning rate: 4.000e-07, loss_scalings: 26214.400391, pp_loss: 9.880838
[INFO] 2021-07-09 16:42:43,125 [run_pretraining.py:  512]:	********exe.run_41******* 
[INFO] 2021-07-09 16:42:45,202 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:45,202 [run_pretraining.py:  534]:	loss/total_loss, 9.88032341003418, 42
[INFO] 2021-07-09 16:42:45,202 [run_pretraining.py:  535]:	loss/mlm_loss, 9.88032341003418, 42
[INFO] 2021-07-09 16:42:45,203 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.099999841855606e-07, 42
[INFO] 2021-07-09 16:42:45,203 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 42
[INFO] 2021-07-09 16:42:45,203 [run_pretraining.py:  558]:	worker_index: 5, step: 42, cost: 9.880323, mlm loss: 9.880323, speed: 0.481529 steps/s, speed: 3.852229 samples/s, speed: 1972.341453 tokens/s, learning rate: 4.100e-07, loss_scalings: 26214.400391, pp_loss: 9.888503
[INFO] 2021-07-09 16:42:45,203 [run_pretraining.py:  512]:	********exe.run_42******* 
[INFO] 2021-07-09 16:42:47,291 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:47,292 [run_pretraining.py:  534]:	loss/total_loss, 9.918953895568848, 43
[INFO] 2021-07-09 16:42:47,292 [run_pretraining.py:  535]:	loss/mlm_loss, 9.918953895568848, 43
[INFO] 2021-07-09 16:42:47,292 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.1999996369668224e-07, 43
[INFO] 2021-07-09 16:42:47,292 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 43
[INFO] 2021-07-09 16:42:47,292 [run_pretraining.py:  558]:	worker_index: 5, step: 43, cost: 9.918954, mlm loss: 9.918954, speed: 0.478750 steps/s, speed: 3.830001 samples/s, speed: 1960.960739 tokens/s, learning rate: 4.200e-07, loss_scalings: 26214.400391, pp_loss: 9.827603
[INFO] 2021-07-09 16:42:47,292 [run_pretraining.py:  512]:	********exe.run_43******* 
[INFO] 2021-07-09 16:42:49,517 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:49,518 [run_pretraining.py:  534]:	loss/total_loss, 9.785626411437988, 44
[INFO] 2021-07-09 16:42:49,518 [run_pretraining.py:  535]:	loss/mlm_loss, 9.785626411437988, 44
[INFO] 2021-07-09 16:42:49,518 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.3000000005122274e-07, 44
[INFO] 2021-07-09 16:42:49,518 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 44
[INFO] 2021-07-09 16:42:49,518 [run_pretraining.py:  558]:	worker_index: 5, step: 44, cost: 9.785626, mlm loss: 9.785626, speed: 0.449397 steps/s, speed: 3.595174 samples/s, speed: 1840.728932 tokens/s, learning rate: 4.300e-07, loss_scalings: 26214.400391, pp_loss: 9.829754
[INFO] 2021-07-09 16:42:49,518 [run_pretraining.py:  512]:	********exe.run_44******* 
[INFO] 2021-07-09 16:42:51,659 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:51,660 [run_pretraining.py:  534]:	loss/total_loss, 9.678462982177734, 45
[INFO] 2021-07-09 16:42:51,660 [run_pretraining.py:  535]:	loss/mlm_loss, 9.678462982177734, 45
[INFO] 2021-07-09 16:42:51,660 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.399999795623444e-07, 45
[INFO] 2021-07-09 16:42:51,660 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 45
[INFO] 2021-07-09 16:42:51,660 [run_pretraining.py:  558]:	worker_index: 5, step: 45, cost: 9.678463, mlm loss: 9.678463, speed: 0.466950 steps/s, speed: 3.735599 samples/s, speed: 1912.626502 tokens/s, learning rate: 4.400e-07, loss_scalings: 26214.400391, pp_loss: 9.758434
[INFO] 2021-07-09 16:42:51,660 [run_pretraining.py:  512]:	********exe.run_45******* 
[INFO] 2021-07-09 16:42:53,854 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:53,855 [run_pretraining.py:  534]:	loss/total_loss, 9.635671615600586, 46
[INFO] 2021-07-09 16:42:53,855 [run_pretraining.py:  535]:	loss/mlm_loss, 9.635671615600586, 46
[INFO] 2021-07-09 16:42:53,855 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.49999959073466e-07, 46
[INFO] 2021-07-09 16:42:53,855 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 46
[INFO] 2021-07-09 16:42:53,855 [run_pretraining.py:  558]:	worker_index: 5, step: 46, cost: 9.635672, mlm loss: 9.635672, speed: 0.455757 steps/s, speed: 3.646053 samples/s, speed: 1866.779107 tokens/s, learning rate: 4.500e-07, loss_scalings: 26214.400391, pp_loss: 9.731261
[INFO] 2021-07-09 16:42:53,855 [run_pretraining.py:  512]:	********exe.run_46******* 
[INFO] 2021-07-09 16:42:56,098 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:56,099 [run_pretraining.py:  534]:	loss/total_loss, 9.751547813415527, 47
[INFO] 2021-07-09 16:42:56,099 [run_pretraining.py:  535]:	loss/mlm_loss, 9.751547813415527, 47
[INFO] 2021-07-09 16:42:56,099 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.599999954280065e-07, 47
[INFO] 2021-07-09 16:42:56,099 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 47
[INFO] 2021-07-09 16:42:56,099 [run_pretraining.py:  558]:	worker_index: 5, step: 47, cost: 9.751548, mlm loss: 9.751548, speed: 0.445763 steps/s, speed: 3.566101 samples/s, speed: 1825.843511 tokens/s, learning rate: 4.600e-07, loss_scalings: 26214.400391, pp_loss: 9.776988
[INFO] 2021-07-09 16:42:56,099 [run_pretraining.py:  512]:	********exe.run_47******* 
[INFO] 2021-07-09 16:42:58,373 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:42:58,374 [run_pretraining.py:  534]:	loss/total_loss, 9.622706413269043, 48
[INFO] 2021-07-09 16:42:58,374 [run_pretraining.py:  535]:	loss/mlm_loss, 9.622706413269043, 48
[INFO] 2021-07-09 16:42:58,374 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.6999997493912815e-07, 48
[INFO] 2021-07-09 16:42:58,374 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 48
[INFO] 2021-07-09 16:42:58,374 [run_pretraining.py:  558]:	worker_index: 5, step: 48, cost: 9.622706, mlm loss: 9.622706, speed: 0.439760 steps/s, speed: 3.518078 samples/s, speed: 1801.255728 tokens/s, learning rate: 4.700e-07, loss_scalings: 26214.400391, pp_loss: 9.702583
[INFO] 2021-07-09 16:42:58,374 [run_pretraining.py:  512]:	********exe.run_48******* 
[INFO] 2021-07-09 16:43:00,606 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:00,607 [run_pretraining.py:  534]:	loss/total_loss, 9.81167221069336, 49
[INFO] 2021-07-09 16:43:00,607 [run_pretraining.py:  535]:	loss/mlm_loss, 9.81167221069336, 49
[INFO] 2021-07-09 16:43:00,607 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.799999828719592e-07, 49
[INFO] 2021-07-09 16:43:00,607 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 49
[INFO] 2021-07-09 16:43:00,607 [run_pretraining.py:  558]:	worker_index: 5, step: 49, cost: 9.811672, mlm loss: 9.811672, speed: 0.447945 steps/s, speed: 3.583561 samples/s, speed: 1834.783160 tokens/s, learning rate: 4.800e-07, loss_scalings: 26214.400391, pp_loss: 9.714144
[INFO] 2021-07-09 16:43:00,607 [run_pretraining.py:  512]:	********exe.run_49******* 
[INFO] 2021-07-09 16:43:02,957 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:02,957 [run_pretraining.py:  534]:	loss/total_loss, 9.621542930603027, 50
[INFO] 2021-07-09 16:43:02,957 [run_pretraining.py:  535]:	loss/mlm_loss, 9.621542930603027, 50
[INFO] 2021-07-09 16:43:02,957 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.899999908047903e-07, 50
[INFO] 2021-07-09 16:43:02,958 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 50
[INFO] 2021-07-09 16:43:02,958 [run_pretraining.py:  558]:	worker_index: 5, step: 50, cost: 9.621543, mlm loss: 9.621543, speed: 0.425578 steps/s, speed: 3.404627 samples/s, speed: 1743.168911 tokens/s, learning rate: 4.900e-07, loss_scalings: 26214.400391, pp_loss: 9.657562
[INFO] 2021-07-09 16:43:02,958 [run_pretraining.py:  512]:	********exe.run_50******* 
[INFO] 2021-07-09 16:43:05,175 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:05,175 [run_pretraining.py:  534]:	loss/total_loss, 9.572980880737305, 51
[INFO] 2021-07-09 16:43:05,176 [run_pretraining.py:  535]:	loss/mlm_loss, 9.572980880737305, 51
[INFO] 2021-07-09 16:43:05,176 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.999999987376214e-07, 51
[INFO] 2021-07-09 16:43:05,176 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 51
[INFO] 2021-07-09 16:43:05,176 [run_pretraining.py:  558]:	worker_index: 5, step: 51, cost: 9.572981, mlm loss: 9.572981, speed: 0.450973 steps/s, speed: 3.607784 samples/s, speed: 1847.185540 tokens/s, learning rate: 5.000e-07, loss_scalings: 26214.400391, pp_loss: 9.626831
[INFO] 2021-07-09 16:43:05,176 [run_pretraining.py:  512]:	********exe.run_51******* 
[INFO] 2021-07-09 16:43:07,441 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:07,441 [run_pretraining.py:  534]:	loss/total_loss, 9.597575187683105, 52
[INFO] 2021-07-09 16:43:07,441 [run_pretraining.py:  535]:	loss/mlm_loss, 9.597575187683105, 52
[INFO] 2021-07-09 16:43:07,441 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.100000066704524e-07, 52
[INFO] 2021-07-09 16:43:07,441 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 52
[INFO] 2021-07-09 16:43:07,441 [run_pretraining.py:  558]:	worker_index: 5, step: 52, cost: 9.597575, mlm loss: 9.597575, speed: 0.441491 steps/s, speed: 3.531931 samples/s, speed: 1808.348654 tokens/s, learning rate: 5.100e-07, loss_scalings: 26214.400391, pp_loss: 9.611003
[INFO] 2021-07-09 16:43:07,442 [run_pretraining.py:  512]:	********exe.run_52******* 
[INFO] 2021-07-09 16:43:09,644 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:09,644 [run_pretraining.py:  534]:	loss/total_loss, 9.587706565856934, 53
[INFO] 2021-07-09 16:43:09,645 [run_pretraining.py:  535]:	loss/mlm_loss, 9.587706565856934, 53
[INFO] 2021-07-09 16:43:09,645 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.200000146032835e-07, 53
[INFO] 2021-07-09 16:43:09,645 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 53
[INFO] 2021-07-09 16:43:09,645 [run_pretraining.py:  558]:	worker_index: 5, step: 53, cost: 9.587707, mlm loss: 9.587707, speed: 0.454018 steps/s, speed: 3.632142 samples/s, speed: 1859.656680 tokens/s, learning rate: 5.200e-07, loss_scalings: 26214.400391, pp_loss: 9.530900
[INFO] 2021-07-09 16:43:09,645 [run_pretraining.py:  512]:	********exe.run_53******* 
[INFO] 2021-07-09 16:43:11,968 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:11,968 [run_pretraining.py:  534]:	loss/total_loss, 9.597929000854492, 54
[INFO] 2021-07-09 16:43:11,968 [run_pretraining.py:  535]:	loss/mlm_loss, 9.597929000854492, 54
[INFO] 2021-07-09 16:43:11,968 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.299999656926957e-07, 54
[INFO] 2021-07-09 16:43:11,969 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 54
[INFO] 2021-07-09 16:43:11,969 [run_pretraining.py:  558]:	worker_index: 5, step: 54, cost: 9.597929, mlm loss: 9.597929, speed: 0.430451 steps/s, speed: 3.443604 samples/s, speed: 1763.125397 tokens/s, learning rate: 5.300e-07, loss_scalings: 26214.400391, pp_loss: 9.539653
[INFO] 2021-07-09 16:43:11,969 [run_pretraining.py:  512]:	********exe.run_54******* 
[INFO] 2021-07-09 16:43:14,170 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:14,171 [run_pretraining.py:  534]:	loss/total_loss, 9.513586044311523, 55
[INFO] 2021-07-09 16:43:14,171 [run_pretraining.py:  535]:	loss/mlm_loss, 9.513586044311523, 55
[INFO] 2021-07-09 16:43:14,171 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.399999736255268e-07, 55
[INFO] 2021-07-09 16:43:14,171 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 55
[INFO] 2021-07-09 16:43:14,171 [run_pretraining.py:  558]:	worker_index: 5, step: 55, cost: 9.513586, mlm loss: 9.513586, speed: 0.454117 steps/s, speed: 3.632938 samples/s, speed: 1860.064202 tokens/s, learning rate: 5.400e-07, loss_scalings: 26214.400391, pp_loss: 9.527061
[INFO] 2021-07-09 16:43:14,172 [run_pretraining.py:  512]:	********exe.run_55******* 
[INFO] 2021-07-09 16:43:16,409 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:16,410 [run_pretraining.py:  534]:	loss/total_loss, 9.416570663452148, 56
[INFO] 2021-07-09 16:43:16,410 [run_pretraining.py:  535]:	loss/mlm_loss, 9.416570663452148, 56
[INFO] 2021-07-09 16:43:16,410 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.499999815583578e-07, 56
[INFO] 2021-07-09 16:43:16,410 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 56
[INFO] 2021-07-09 16:43:16,410 [run_pretraining.py:  558]:	worker_index: 5, step: 56, cost: 9.416571, mlm loss: 9.416571, speed: 0.446827 steps/s, speed: 3.574615 samples/s, speed: 1830.203075 tokens/s, learning rate: 5.500e-07, loss_scalings: 26214.400391, pp_loss: 9.460542
[INFO] 2021-07-09 16:43:16,410 [run_pretraining.py:  512]:	********exe.run_56******* 
[INFO] 2021-07-09 16:43:18,626 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:18,626 [run_pretraining.py:  534]:	loss/total_loss, 9.51870346069336, 57
[INFO] 2021-07-09 16:43:18,626 [run_pretraining.py:  535]:	loss/mlm_loss, 9.51870346069336, 57
[INFO] 2021-07-09 16:43:18,626 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.599999894911889e-07, 57
[INFO] 2021-07-09 16:43:18,626 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 57
[INFO] 2021-07-09 16:43:18,626 [run_pretraining.py:  558]:	worker_index: 5, step: 57, cost: 9.518703, mlm loss: 9.518703, speed: 0.451334 steps/s, speed: 3.610671 samples/s, speed: 1848.663785 tokens/s, learning rate: 5.600e-07, loss_scalings: 26214.400391, pp_loss: 9.430513
[INFO] 2021-07-09 16:43:18,627 [run_pretraining.py:  512]:	********exe.run_57******* 
[INFO] 2021-07-09 16:43:20,803 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:20,804 [run_pretraining.py:  534]:	loss/total_loss, 9.378913879394531, 58
[INFO] 2021-07-09 16:43:20,804 [run_pretraining.py:  535]:	loss/mlm_loss, 9.378913879394531, 58
[INFO] 2021-07-09 16:43:20,804 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.6999999742402e-07, 58
[INFO] 2021-07-09 16:43:20,804 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 58
[INFO] 2021-07-09 16:43:20,804 [run_pretraining.py:  558]:	worker_index: 5, step: 58, cost: 9.378914, mlm loss: 9.378914, speed: 0.459306 steps/s, speed: 3.674446 samples/s, speed: 1881.316413 tokens/s, learning rate: 5.700e-07, loss_scalings: 26214.400391, pp_loss: 9.368690
[INFO] 2021-07-09 16:43:20,804 [run_pretraining.py:  512]:	********exe.run_58******* 
[INFO] 2021-07-09 16:43:23,034 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:23,035 [run_pretraining.py:  534]:	loss/total_loss, 9.567400932312012, 59
[INFO] 2021-07-09 16:43:23,035 [run_pretraining.py:  535]:	loss/mlm_loss, 9.567400932312012, 59
[INFO] 2021-07-09 16:43:23,035 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.80000005356851e-07, 59
[INFO] 2021-07-09 16:43:23,035 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 59
[INFO] 2021-07-09 16:43:23,035 [run_pretraining.py:  558]:	worker_index: 5, step: 59, cost: 9.567401, mlm loss: 9.567401, speed: 0.448379 steps/s, speed: 3.587032 samples/s, speed: 1836.560204 tokens/s, learning rate: 5.800e-07, loss_scalings: 26214.400391, pp_loss: 9.383883
[INFO] 2021-07-09 16:43:23,035 [run_pretraining.py:  512]:	********exe.run_59******* 
[INFO] 2021-07-09 16:43:25,252 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:25,252 [run_pretraining.py:  534]:	loss/total_loss, 9.506817817687988, 60
[INFO] 2021-07-09 16:43:25,253 [run_pretraining.py:  535]:	loss/mlm_loss, 9.506817817687988, 60
[INFO] 2021-07-09 16:43:25,253 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.900000132896821e-07, 60
[INFO] 2021-07-09 16:43:25,253 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 60
[INFO] 2021-07-09 16:43:25,253 [run_pretraining.py:  558]:	worker_index: 5, step: 60, cost: 9.506818, mlm loss: 9.506818, speed: 0.451070 steps/s, speed: 3.608558 samples/s, speed: 1847.581852 tokens/s, learning rate: 5.900e-07, loss_scalings: 26214.400391, pp_loss: 9.346923
[INFO] 2021-07-09 16:43:25,253 [run_pretraining.py:  512]:	********exe.run_60******* 
[INFO] 2021-07-09 16:43:27,461 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:27,462 [run_pretraining.py:  534]:	loss/total_loss, 9.174036979675293, 61
[INFO] 2021-07-09 16:43:27,462 [run_pretraining.py:  535]:	loss/mlm_loss, 9.174036979675293, 61
[INFO] 2021-07-09 16:43:27,462 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.999999643790943e-07, 61
[INFO] 2021-07-09 16:43:27,462 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 61
[INFO] 2021-07-09 16:43:27,462 [run_pretraining.py:  558]:	worker_index: 5, step: 61, cost: 9.174037, mlm loss: 9.174037, speed: 0.452737 steps/s, speed: 3.621894 samples/s, speed: 1854.409922 tokens/s, learning rate: 6.000e-07, loss_scalings: 26214.400391, pp_loss: 9.248453
[INFO] 2021-07-09 16:43:27,463 [run_pretraining.py:  512]:	********exe.run_61******* 
[INFO] 2021-07-09 16:43:29,747 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:29,748 [run_pretraining.py:  534]:	loss/total_loss, 9.408982276916504, 62
[INFO] 2021-07-09 16:43:29,748 [run_pretraining.py:  535]:	loss/mlm_loss, 9.408982276916504, 62
[INFO] 2021-07-09 16:43:29,748 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.099999723119254e-07, 62
[INFO] 2021-07-09 16:43:29,748 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 62
[INFO] 2021-07-09 16:43:29,748 [run_pretraining.py:  558]:	worker_index: 5, step: 62, cost: 9.408982, mlm loss: 9.408982, speed: 0.437635 steps/s, speed: 3.501081 samples/s, speed: 1792.553561 tokens/s, learning rate: 6.100e-07, loss_scalings: 26214.400391, pp_loss: 9.240841
[INFO] 2021-07-09 16:43:29,748 [run_pretraining.py:  512]:	********exe.run_62******* 
[INFO] 2021-07-09 16:43:32,012 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:32,013 [run_pretraining.py:  534]:	loss/total_loss, 9.296453475952148, 63
[INFO] 2021-07-09 16:43:32,013 [run_pretraining.py:  535]:	loss/mlm_loss, 9.296453475952148, 63
[INFO] 2021-07-09 16:43:32,013 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.199999802447564e-07, 63
[INFO] 2021-07-09 16:43:32,013 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 63
[INFO] 2021-07-09 16:43:32,013 [run_pretraining.py:  558]:	worker_index: 5, step: 63, cost: 9.296453, mlm loss: 9.296453, speed: 0.441664 steps/s, speed: 3.533313 samples/s, speed: 1809.056067 tokens/s, learning rate: 6.200e-07, loss_scalings: 26214.400391, pp_loss: 9.258790
[INFO] 2021-07-09 16:43:32,013 [run_pretraining.py:  512]:	********exe.run_63******* 
[INFO] 2021-07-09 16:43:34,194 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:34,194 [run_pretraining.py:  534]:	loss/total_loss, 9.433601379394531, 64
[INFO] 2021-07-09 16:43:34,194 [run_pretraining.py:  535]:	loss/mlm_loss, 9.433601379394531, 64
[INFO] 2021-07-09 16:43:34,195 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.299999881775875e-07, 64
[INFO] 2021-07-09 16:43:34,195 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 64
[INFO] 2021-07-09 16:43:34,195 [run_pretraining.py:  558]:	worker_index: 5, step: 64, cost: 9.433601, mlm loss: 9.433601, speed: 0.458519 steps/s, speed: 3.668155 samples/s, speed: 1878.095293 tokens/s, learning rate: 6.300e-07, loss_scalings: 26214.400391, pp_loss: 9.143012
[INFO] 2021-07-09 16:43:34,195 [run_pretraining.py:  512]:	********exe.run_64******* 
[INFO] 2021-07-09 16:43:36,387 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:36,388 [run_pretraining.py:  534]:	loss/total_loss, 9.193803787231445, 65
[INFO] 2021-07-09 16:43:36,388 [run_pretraining.py:  535]:	loss/mlm_loss, 9.193803787231445, 65
[INFO] 2021-07-09 16:43:36,388 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.399999392669997e-07, 65
[INFO] 2021-07-09 16:43:36,388 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 65
[INFO] 2021-07-09 16:43:36,388 [run_pretraining.py:  558]:	worker_index: 5, step: 65, cost: 9.193804, mlm loss: 9.193804, speed: 0.456023 steps/s, speed: 3.648183 samples/s, speed: 1867.869634 tokens/s, learning rate: 6.400e-07, loss_scalings: 26214.400391, pp_loss: 9.221859
[INFO] 2021-07-09 16:43:36,388 [run_pretraining.py:  512]:	********exe.run_65******* 
[INFO] 2021-07-09 16:43:38,560 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:38,561 [run_pretraining.py:  534]:	loss/total_loss, 9.262490272521973, 66
[INFO] 2021-07-09 16:43:38,561 [run_pretraining.py:  535]:	loss/mlm_loss, 9.262490272521973, 66
[INFO] 2021-07-09 16:43:38,561 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.500000040432496e-07, 66
[INFO] 2021-07-09 16:43:38,561 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 66
[INFO] 2021-07-09 16:43:38,561 [run_pretraining.py:  558]:	worker_index: 5, step: 66, cost: 9.262490, mlm loss: 9.262490, speed: 0.460365 steps/s, speed: 3.682921 samples/s, speed: 1885.655647 tokens/s, learning rate: 6.500e-07, loss_scalings: 26214.400391, pp_loss: 9.161788
[INFO] 2021-07-09 16:43:38,561 [run_pretraining.py:  512]:	********exe.run_66******* 
[INFO] 2021-07-09 16:43:40,776 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:40,776 [run_pretraining.py:  534]:	loss/total_loss, 8.98721694946289, 67
[INFO] 2021-07-09 16:43:40,776 [run_pretraining.py:  535]:	loss/mlm_loss, 8.98721694946289, 67
[INFO] 2021-07-09 16:43:40,777 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.599999551326619e-07, 67
[INFO] 2021-07-09 16:43:40,777 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 67
[INFO] 2021-07-09 16:43:40,777 [run_pretraining.py:  558]:	worker_index: 5, step: 67, cost: 8.987217, mlm loss: 8.987217, speed: 0.451505 steps/s, speed: 3.612042 samples/s, speed: 1849.365671 tokens/s, learning rate: 6.600e-07, loss_scalings: 26214.400391, pp_loss: 9.127666
[INFO] 2021-07-09 16:43:40,777 [run_pretraining.py:  512]:	********exe.run_67******* 
[INFO] 2021-07-09 16:43:42,921 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:42,921 [run_pretraining.py:  534]:	loss/total_loss, 8.954992294311523, 68
[INFO] 2021-07-09 16:43:42,921 [run_pretraining.py:  535]:	loss/mlm_loss, 8.954992294311523, 68
[INFO] 2021-07-09 16:43:42,922 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.699999630654929e-07, 68
[INFO] 2021-07-09 16:43:42,922 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 68
[INFO] 2021-07-09 16:43:42,922 [run_pretraining.py:  558]:	worker_index: 5, step: 68, cost: 8.954992, mlm loss: 8.954992, speed: 0.466356 steps/s, speed: 3.730848 samples/s, speed: 1910.194086 tokens/s, learning rate: 6.700e-07, loss_scalings: 26214.400391, pp_loss: 9.030285
[INFO] 2021-07-09 16:43:42,922 [run_pretraining.py:  512]:	********exe.run_68******* 
[INFO] 2021-07-09 16:43:45,071 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:45,071 [run_pretraining.py:  534]:	loss/total_loss, 8.844572067260742, 69
[INFO] 2021-07-09 16:43:45,071 [run_pretraining.py:  535]:	loss/mlm_loss, 8.844572067260742, 69
[INFO] 2021-07-09 16:43:45,072 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.79999970998324e-07, 69
[INFO] 2021-07-09 16:43:45,072 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 69
[INFO] 2021-07-09 16:43:45,072 [run_pretraining.py:  558]:	worker_index: 5, step: 69, cost: 8.844572, mlm loss: 8.844572, speed: 0.465268 steps/s, speed: 3.722144 samples/s, speed: 1905.737510 tokens/s, learning rate: 6.800e-07, loss_scalings: 26214.400391, pp_loss: 8.981588
[INFO] 2021-07-09 16:43:45,072 [run_pretraining.py:  512]:	********exe.run_69******* 
[INFO] 2021-07-09 16:43:47,257 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:47,257 [run_pretraining.py:  534]:	loss/total_loss, 8.990614891052246, 70
[INFO] 2021-07-09 16:43:47,258 [run_pretraining.py:  535]:	loss/mlm_loss, 8.990614891052246, 70
[INFO] 2021-07-09 16:43:47,258 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.899999789311551e-07, 70
[INFO] 2021-07-09 16:43:47,258 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 70
[INFO] 2021-07-09 16:43:47,258 [run_pretraining.py:  558]:	worker_index: 5, step: 70, cost: 8.990615, mlm loss: 8.990615, speed: 0.457554 steps/s, speed: 3.660435 samples/s, speed: 1874.142536 tokens/s, learning rate: 6.900e-07, loss_scalings: 26214.400391, pp_loss: 9.059517
[INFO] 2021-07-09 16:43:47,258 [run_pretraining.py:  512]:	********exe.run_70******* 
[INFO] 2021-07-09 16:43:49,447 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:49,448 [run_pretraining.py:  534]:	loss/total_loss, 9.001863479614258, 71
[INFO] 2021-07-09 16:43:49,448 [run_pretraining.py:  535]:	loss/mlm_loss, 9.001863479614258, 71
[INFO] 2021-07-09 16:43:49,448 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.999999868639861e-07, 71
[INFO] 2021-07-09 16:43:49,448 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 71
[INFO] 2021-07-09 16:43:49,448 [run_pretraining.py:  558]:	worker_index: 5, step: 71, cost: 9.001863, mlm loss: 9.001863, speed: 0.456681 steps/s, speed: 3.653448 samples/s, speed: 1870.565383 tokens/s, learning rate: 7.000e-07, loss_scalings: 26214.400391, pp_loss: 8.952415
[INFO] 2021-07-09 16:43:49,448 [run_pretraining.py:  512]:	********exe.run_71******* 
[INFO] 2021-07-09 16:43:51,593 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:51,594 [run_pretraining.py:  534]:	loss/total_loss, 8.768135070800781, 72
[INFO] 2021-07-09 16:43:51,594 [run_pretraining.py:  535]:	loss/mlm_loss, 8.768135070800781, 72
[INFO] 2021-07-09 16:43:51,594 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.099999947968172e-07, 72
[INFO] 2021-07-09 16:43:51,594 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 72
[INFO] 2021-07-09 16:43:51,594 [run_pretraining.py:  558]:	worker_index: 5, step: 72, cost: 8.768135, mlm loss: 8.768135, speed: 0.466112 steps/s, speed: 3.728898 samples/s, speed: 1909.195735 tokens/s, learning rate: 7.100e-07, loss_scalings: 26214.400391, pp_loss: 8.858799
[INFO] 2021-07-09 16:43:51,594 [run_pretraining.py:  512]:	********exe.run_72******* 
[INFO] 2021-07-09 16:43:53,807 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:53,807 [run_pretraining.py:  534]:	loss/total_loss, 8.718649864196777, 73
[INFO] 2021-07-09 16:43:53,807 [run_pretraining.py:  535]:	loss/mlm_loss, 8.718649864196777, 73
[INFO] 2021-07-09 16:43:53,807 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.199999458862294e-07, 73
[INFO] 2021-07-09 16:43:53,808 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 73
[INFO] 2021-07-09 16:43:53,808 [run_pretraining.py:  558]:	worker_index: 5, step: 73, cost: 8.718650, mlm loss: 8.718650, speed: 0.451959 steps/s, speed: 3.615669 samples/s, speed: 1851.222353 tokens/s, learning rate: 7.200e-07, loss_scalings: 26214.400391, pp_loss: 8.835691
[INFO] 2021-07-09 16:43:53,808 [run_pretraining.py:  512]:	********exe.run_73******* 
[INFO] 2021-07-09 16:43:55,988 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:55,989 [run_pretraining.py:  534]:	loss/total_loss, 8.739323616027832, 74
[INFO] 2021-07-09 16:43:55,989 [run_pretraining.py:  535]:	loss/mlm_loss, 8.739323616027832, 74
[INFO] 2021-07-09 16:43:55,989 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.300000106624793e-07, 74
[INFO] 2021-07-09 16:43:55,989 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 74
[INFO] 2021-07-09 16:43:55,989 [run_pretraining.py:  558]:	worker_index: 5, step: 74, cost: 8.739324, mlm loss: 8.739324, speed: 0.458469 steps/s, speed: 3.667756 samples/s, speed: 1877.890824 tokens/s, learning rate: 7.300e-07, loss_scalings: 26214.400391, pp_loss: 8.805562
[INFO] 2021-07-09 16:43:55,990 [run_pretraining.py:  512]:	********exe.run_74******* 
[INFO] 2021-07-09 16:43:58,140 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:43:58,140 [run_pretraining.py:  534]:	loss/total_loss, 8.76571273803711, 75
[INFO] 2021-07-09 16:43:58,141 [run_pretraining.py:  535]:	loss/mlm_loss, 8.76571273803711, 75
[INFO] 2021-07-09 16:43:58,141 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.399999617518915e-07, 75
[INFO] 2021-07-09 16:43:58,141 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 75
[INFO] 2021-07-09 16:43:58,141 [run_pretraining.py:  558]:	worker_index: 5, step: 75, cost: 8.765713, mlm loss: 8.765713, speed: 0.464968 steps/s, speed: 3.719744 samples/s, speed: 1904.509008 tokens/s, learning rate: 7.400e-07, loss_scalings: 26214.400391, pp_loss: 8.808817
[INFO] 2021-07-09 16:43:58,141 [run_pretraining.py:  512]:	********exe.run_75******* 
[INFO] 2021-07-09 16:44:00,354 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:00,355 [run_pretraining.py:  534]:	loss/total_loss, 8.689473152160645, 76
[INFO] 2021-07-09 16:44:00,355 [run_pretraining.py:  535]:	loss/mlm_loss, 8.689473152160645, 76
[INFO] 2021-07-09 16:44:00,355 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.499999696847226e-07, 76
[INFO] 2021-07-09 16:44:00,355 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 76
[INFO] 2021-07-09 16:44:00,355 [run_pretraining.py:  558]:	worker_index: 5, step: 76, cost: 8.689473, mlm loss: 8.689473, speed: 0.451767 steps/s, speed: 3.614140 samples/s, speed: 1850.439529 tokens/s, learning rate: 7.500e-07, loss_scalings: 26214.400391, pp_loss: 8.738692
[INFO] 2021-07-09 16:44:00,355 [run_pretraining.py:  512]:	********exe.run_76******* 
[INFO] 2021-07-09 16:44:02,566 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:02,566 [run_pretraining.py:  534]:	loss/total_loss, 8.825908660888672, 77
[INFO] 2021-07-09 16:44:02,566 [run_pretraining.py:  535]:	loss/mlm_loss, 8.825908660888672, 77
[INFO] 2021-07-09 16:44:02,566 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.599999776175537e-07, 77
[INFO] 2021-07-09 16:44:02,566 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 77
[INFO] 2021-07-09 16:44:02,566 [run_pretraining.py:  558]:	worker_index: 5, step: 77, cost: 8.825909, mlm loss: 8.825909, speed: 0.452338 steps/s, speed: 3.618708 samples/s, speed: 1852.778400 tokens/s, learning rate: 7.600e-07, loss_scalings: 20971.521484, pp_loss: 8.712357
[INFO] 2021-07-09 16:44:02,567 [run_pretraining.py:  512]:	********exe.run_77******* 
[INFO] 2021-07-09 16:44:04,753 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:04,753 [run_pretraining.py:  534]:	loss/total_loss, 8.599018096923828, 78
[INFO] 2021-07-09 16:44:04,754 [run_pretraining.py:  535]:	loss/mlm_loss, 8.599018096923828, 78
[INFO] 2021-07-09 16:44:04,754 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.699999855503847e-07, 78
[INFO] 2021-07-09 16:44:04,754 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 78
[INFO] 2021-07-09 16:44:04,754 [run_pretraining.py:  558]:	worker_index: 5, step: 78, cost: 8.599018, mlm loss: 8.599018, speed: 0.457316 steps/s, speed: 3.658532 samples/s, speed: 1873.168229 tokens/s, learning rate: 7.700e-07, loss_scalings: 20971.521484, pp_loss: 8.582556
[INFO] 2021-07-09 16:44:04,754 [run_pretraining.py:  512]:	********exe.run_78******* 
[INFO] 2021-07-09 16:44:06,941 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:06,941 [run_pretraining.py:  534]:	loss/total_loss, 8.879910469055176, 79
[INFO] 2021-07-09 16:44:06,942 [run_pretraining.py:  535]:	loss/mlm_loss, 8.879910469055176, 79
[INFO] 2021-07-09 16:44:06,942 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.799999366397969e-07, 79
[INFO] 2021-07-09 16:44:06,942 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 79
[INFO] 2021-07-09 16:44:06,942 [run_pretraining.py:  558]:	worker_index: 5, step: 79, cost: 8.879910, mlm loss: 8.879910, speed: 0.457171 steps/s, speed: 3.657368 samples/s, speed: 1872.572456 tokens/s, learning rate: 7.800e-07, loss_scalings: 20971.521484, pp_loss: 8.622550
[INFO] 2021-07-09 16:44:06,942 [run_pretraining.py:  512]:	********exe.run_79******* 
[INFO] 2021-07-09 16:44:09,166 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:09,166 [run_pretraining.py:  534]:	loss/total_loss, 8.535202980041504, 80
[INFO] 2021-07-09 16:44:09,166 [run_pretraining.py:  535]:	loss/mlm_loss, 8.535202980041504, 80
[INFO] 2021-07-09 16:44:09,167 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.89999944572628e-07, 80
[INFO] 2021-07-09 16:44:09,167 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 80
[INFO] 2021-07-09 16:44:09,167 [run_pretraining.py:  558]:	worker_index: 5, step: 80, cost: 8.535203, mlm loss: 8.535203, speed: 0.449622 steps/s, speed: 3.596972 samples/s, speed: 1841.649838 tokens/s, learning rate: 7.900e-07, loss_scalings: 20971.521484, pp_loss: 8.591144
[INFO] 2021-07-09 16:44:09,167 [run_pretraining.py:  512]:	********exe.run_80******* 
[INFO] 2021-07-09 16:44:11,322 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:11,323 [run_pretraining.py:  534]:	loss/total_loss, 8.553970336914062, 81
[INFO] 2021-07-09 16:44:11,323 [run_pretraining.py:  535]:	loss/mlm_loss, 8.553970336914062, 81
[INFO] 2021-07-09 16:44:11,323 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.000000093488779e-07, 81
[INFO] 2021-07-09 16:44:11,323 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 81
[INFO] 2021-07-09 16:44:11,323 [run_pretraining.py:  558]:	worker_index: 5, step: 81, cost: 8.553970, mlm loss: 8.553970, speed: 0.463909 steps/s, speed: 3.711269 samples/s, speed: 1900.169676 tokens/s, learning rate: 8.000e-07, loss_scalings: 20971.521484, pp_loss: 8.581167
[INFO] 2021-07-09 16:44:11,323 [run_pretraining.py:  512]:	********exe.run_81******* 
[INFO] 2021-07-09 16:44:13,500 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:13,500 [run_pretraining.py:  534]:	loss/total_loss, 8.476572036743164, 82
[INFO] 2021-07-09 16:44:13,500 [run_pretraining.py:  535]:	loss/mlm_loss, 8.476572036743164, 82
[INFO] 2021-07-09 16:44:13,500 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.10000017281709e-07, 82
[INFO] 2021-07-09 16:44:13,501 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 82
[INFO] 2021-07-09 16:44:13,501 [run_pretraining.py:  558]:	worker_index: 5, step: 82, cost: 8.476572, mlm loss: 8.476572, speed: 0.459375 steps/s, speed: 3.674996 samples/s, speed: 1881.598081 tokens/s, learning rate: 8.100e-07, loss_scalings: 20971.521484, pp_loss: 8.527293
[INFO] 2021-07-09 16:44:13,501 [run_pretraining.py:  512]:	********exe.run_82******* 
[INFO] 2021-07-09 16:44:15,674 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:15,675 [run_pretraining.py:  534]:	loss/total_loss, 8.610124588012695, 83
[INFO] 2021-07-09 16:44:15,675 [run_pretraining.py:  535]:	loss/mlm_loss, 8.610124588012695, 83
[INFO] 2021-07-09 16:44:15,675 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.199999683711212e-07, 83
[INFO] 2021-07-09 16:44:15,675 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 83
[INFO] 2021-07-09 16:44:15,675 [run_pretraining.py:  558]:	worker_index: 5, step: 83, cost: 8.610125, mlm loss: 8.610125, speed: 0.459971 steps/s, speed: 3.679768 samples/s, speed: 1884.041432 tokens/s, learning rate: 8.200e-07, loss_scalings: 20971.521484, pp_loss: 8.570192
[INFO] 2021-07-09 16:44:15,675 [run_pretraining.py:  512]:	********exe.run_83******* 
[INFO] 2021-07-09 16:44:17,818 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:17,819 [run_pretraining.py:  534]:	loss/total_loss, 8.844354629516602, 84
[INFO] 2021-07-09 16:44:17,819 [run_pretraining.py:  535]:	loss/mlm_loss, 8.844354629516602, 84
[INFO] 2021-07-09 16:44:17,819 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.299999763039523e-07, 84
[INFO] 2021-07-09 16:44:17,819 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 84
[INFO] 2021-07-09 16:44:17,819 [run_pretraining.py:  558]:	worker_index: 5, step: 84, cost: 8.844355, mlm loss: 8.844355, speed: 0.466668 steps/s, speed: 3.733347 samples/s, speed: 1911.473746 tokens/s, learning rate: 8.300e-07, loss_scalings: 20971.521484, pp_loss: 8.522912
[INFO] 2021-07-09 16:44:17,819 [run_pretraining.py:  512]:	********exe.run_84******* 
[INFO] 2021-07-09 16:44:19,978 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:19,979 [run_pretraining.py:  534]:	loss/total_loss, 8.32866096496582, 85
[INFO] 2021-07-09 16:44:19,979 [run_pretraining.py:  535]:	loss/mlm_loss, 8.32866096496582, 85
[INFO] 2021-07-09 16:44:19,979 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.399999273933645e-07, 85
[INFO] 2021-07-09 16:44:19,979 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 85
[INFO] 2021-07-09 16:44:19,979 [run_pretraining.py:  558]:	worker_index: 5, step: 85, cost: 8.328661, mlm loss: 8.328661, speed: 0.463105 steps/s, speed: 3.704840 samples/s, speed: 1896.877866 tokens/s, learning rate: 8.400e-07, loss_scalings: 20971.521484, pp_loss: 8.322206
[INFO] 2021-07-09 16:44:19,979 [run_pretraining.py:  512]:	********exe.run_85******* 
[INFO] 2021-07-09 16:44:22,122 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:22,122 [run_pretraining.py:  534]:	loss/total_loss, 8.383152961730957, 86
[INFO] 2021-07-09 16:44:22,122 [run_pretraining.py:  535]:	loss/mlm_loss, 8.383152961730957, 86
[INFO] 2021-07-09 16:44:22,122 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.500000490130333e-07, 86
[INFO] 2021-07-09 16:44:22,122 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 86
[INFO] 2021-07-09 16:44:22,123 [run_pretraining.py:  558]:	worker_index: 5, step: 86, cost: 8.383153, mlm loss: 8.383153, speed: 0.466664 steps/s, speed: 3.733309 samples/s, speed: 1911.454180 tokens/s, learning rate: 8.500e-07, loss_scalings: 20971.521484, pp_loss: 8.373755
[INFO] 2021-07-09 16:44:22,123 [run_pretraining.py:  512]:	********exe.run_86******* 
[INFO] 2021-07-09 16:44:24,442 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:24,443 [run_pretraining.py:  534]:	loss/total_loss, 8.302872657775879, 87
[INFO] 2021-07-09 16:44:24,443 [run_pretraining.py:  535]:	loss/mlm_loss, 8.302872657775879, 87
[INFO] 2021-07-09 16:44:24,443 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.600000001024455e-07, 87
[INFO] 2021-07-09 16:44:24,443 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 87
[INFO] 2021-07-09 16:44:24,443 [run_pretraining.py:  558]:	worker_index: 5, step: 87, cost: 8.302873, mlm loss: 8.302873, speed: 0.431019 steps/s, speed: 3.448149 samples/s, speed: 1765.452340 tokens/s, learning rate: 8.600e-07, loss_scalings: 20971.521484, pp_loss: 8.316110
[INFO] 2021-07-09 16:44:24,443 [run_pretraining.py:  512]:	********exe.run_87******* 
[INFO] 2021-07-09 16:44:26,850 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:26,850 [run_pretraining.py:  534]:	loss/total_loss, 8.383858680725098, 88
[INFO] 2021-07-09 16:44:26,851 [run_pretraining.py:  535]:	loss/mlm_loss, 8.383858680725098, 88
[INFO] 2021-07-09 16:44:26,851 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.700000080352766e-07, 88
[INFO] 2021-07-09 16:44:26,851 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 88
[INFO] 2021-07-09 16:44:26,851 [run_pretraining.py:  558]:	worker_index: 5, step: 88, cost: 8.383859, mlm loss: 8.383859, speed: 0.415472 steps/s, speed: 3.323772 samples/s, speed: 1701.771419 tokens/s, learning rate: 8.700e-07, loss_scalings: 20971.521484, pp_loss: 8.382516
[INFO] 2021-07-09 16:44:26,851 [run_pretraining.py:  512]:	********exe.run_88******* 
[INFO] 2021-07-09 16:44:29,021 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:29,022 [run_pretraining.py:  534]:	loss/total_loss, 8.344945907592773, 89
[INFO] 2021-07-09 16:44:29,022 [run_pretraining.py:  535]:	loss/mlm_loss, 8.344945907592773, 89
[INFO] 2021-07-09 16:44:29,022 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.799999591246888e-07, 89
[INFO] 2021-07-09 16:44:29,022 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 89
[INFO] 2021-07-09 16:44:29,022 [run_pretraining.py:  558]:	worker_index: 5, step: 89, cost: 8.344946, mlm loss: 8.344946, speed: 0.460752 steps/s, speed: 3.686017 samples/s, speed: 1887.240911 tokens/s, learning rate: 8.800e-07, loss_scalings: 20971.521484, pp_loss: 8.301696
[INFO] 2021-07-09 16:44:29,022 [run_pretraining.py:  512]:	********exe.run_89******* 
[INFO] 2021-07-09 16:44:31,166 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:31,167 [run_pretraining.py:  534]:	loss/total_loss, 8.187349319458008, 90
[INFO] 2021-07-09 16:44:31,167 [run_pretraining.py:  535]:	loss/mlm_loss, 8.187349319458008, 90
[INFO] 2021-07-09 16:44:31,167 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.899999670575198e-07, 90
[INFO] 2021-07-09 16:44:31,167 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 90
[INFO] 2021-07-09 16:44:31,167 [run_pretraining.py:  558]:	worker_index: 5, step: 90, cost: 8.187349, mlm loss: 8.187349, speed: 0.466272 steps/s, speed: 3.730179 samples/s, speed: 1909.851561 tokens/s, learning rate: 8.900e-07, loss_scalings: 20971.521484, pp_loss: 8.169396
[INFO] 2021-07-09 16:44:31,167 [run_pretraining.py:  512]:	********exe.run_90******* 
[INFO] 2021-07-09 16:44:33,325 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:33,326 [run_pretraining.py:  534]:	loss/total_loss, 8.178288459777832, 91
[INFO] 2021-07-09 16:44:33,326 [run_pretraining.py:  535]:	loss/mlm_loss, 8.178288459777832, 91
[INFO] 2021-07-09 16:44:33,326 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.99999918146932e-07, 91
[INFO] 2021-07-09 16:44:33,326 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 91
[INFO] 2021-07-09 16:44:33,326 [run_pretraining.py:  558]:	worker_index: 5, step: 91, cost: 8.178288, mlm loss: 8.178288, speed: 0.463372 steps/s, speed: 3.706974 samples/s, speed: 1897.970933 tokens/s, learning rate: 9.000e-07, loss_scalings: 20971.521484, pp_loss: 8.216899
[INFO] 2021-07-09 16:44:33,326 [run_pretraining.py:  512]:	********exe.run_91******* 
[INFO] 2021-07-09 16:44:35,486 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:35,487 [run_pretraining.py:  534]:	loss/total_loss, 8.296442031860352, 92
[INFO] 2021-07-09 16:44:35,487 [run_pretraining.py:  535]:	loss/mlm_loss, 8.296442031860352, 92
[INFO] 2021-07-09 16:44:35,487 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.100000397666008e-07, 92
[INFO] 2021-07-09 16:44:35,487 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 92
[INFO] 2021-07-09 16:44:35,487 [run_pretraining.py:  558]:	worker_index: 5, step: 92, cost: 8.296442, mlm loss: 8.296442, speed: 0.462869 steps/s, speed: 3.702953 samples/s, speed: 1895.911794 tokens/s, learning rate: 9.100e-07, loss_scalings: 20971.521484, pp_loss: 8.175664
[INFO] 2021-07-09 16:44:35,487 [run_pretraining.py:  512]:	********exe.run_92******* 
[INFO] 2021-07-09 16:44:37,638 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:37,638 [run_pretraining.py:  534]:	loss/total_loss, 8.048452377319336, 93
[INFO] 2021-07-09 16:44:37,638 [run_pretraining.py:  535]:	loss/mlm_loss, 8.048452377319336, 93
[INFO] 2021-07-09 16:44:37,639 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.19999990856013e-07, 93
[INFO] 2021-07-09 16:44:37,639 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 93
[INFO] 2021-07-09 16:44:37,639 [run_pretraining.py:  558]:	worker_index: 5, step: 93, cost: 8.048452, mlm loss: 8.048452, speed: 0.464962 steps/s, speed: 3.719699 samples/s, speed: 1904.485995 tokens/s, learning rate: 9.200e-07, loss_scalings: 20971.521484, pp_loss: 8.097707
[INFO] 2021-07-09 16:44:37,639 [run_pretraining.py:  512]:	********exe.run_93******* 
[INFO] 2021-07-09 16:44:39,805 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:39,805 [run_pretraining.py:  534]:	loss/total_loss, 8.0146484375, 94
[INFO] 2021-07-09 16:44:39,805 [run_pretraining.py:  535]:	loss/mlm_loss, 8.0146484375, 94
[INFO] 2021-07-09 16:44:39,805 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.299999987888441e-07, 94
[INFO] 2021-07-09 16:44:39,805 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 94
[INFO] 2021-07-09 16:44:39,806 [run_pretraining.py:  558]:	worker_index: 5, step: 94, cost: 8.014648, mlm loss: 8.014648, speed: 0.461665 steps/s, speed: 3.693320 samples/s, speed: 1890.979802 tokens/s, learning rate: 9.300e-07, loss_scalings: 20971.521484, pp_loss: 8.094536
[INFO] 2021-07-09 16:44:39,806 [run_pretraining.py:  512]:	********exe.run_94******* 
[INFO] 2021-07-09 16:44:41,965 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:41,966 [run_pretraining.py:  534]:	loss/total_loss, 8.052090644836426, 95
[INFO] 2021-07-09 16:44:41,966 [run_pretraining.py:  535]:	loss/mlm_loss, 8.052090644836426, 95
[INFO] 2021-07-09 16:44:41,966 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.399999498782563e-07, 95
[INFO] 2021-07-09 16:44:41,966 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 95
[INFO] 2021-07-09 16:44:41,966 [run_pretraining.py:  558]:	worker_index: 5, step: 95, cost: 8.052091, mlm loss: 8.052091, speed: 0.462980 steps/s, speed: 3.703837 samples/s, speed: 1896.364459 tokens/s, learning rate: 9.400e-07, loss_scalings: 20971.521484, pp_loss: 7.992435
[INFO] 2021-07-09 16:44:41,966 [run_pretraining.py:  512]:	********exe.run_95******* 
[INFO] 2021-07-09 16:44:44,127 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:44,127 [run_pretraining.py:  534]:	loss/total_loss, 8.005583763122559, 96
[INFO] 2021-07-09 16:44:44,128 [run_pretraining.py:  535]:	loss/mlm_loss, 8.005583763122559, 96
[INFO] 2021-07-09 16:44:44,128 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.499999578110874e-07, 96
[INFO] 2021-07-09 16:44:44,128 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 96
[INFO] 2021-07-09 16:44:44,128 [run_pretraining.py:  558]:	worker_index: 5, step: 96, cost: 8.005584, mlm loss: 8.005584, speed: 0.462740 steps/s, speed: 3.701917 samples/s, speed: 1895.381554 tokens/s, learning rate: 9.500e-07, loss_scalings: 20971.521484, pp_loss: 8.050678
[INFO] 2021-07-09 16:44:44,128 [run_pretraining.py:  512]:	********exe.run_96******* 
[INFO] 2021-07-09 16:44:46,283 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:46,284 [run_pretraining.py:  534]:	loss/total_loss, 8.111037254333496, 97
[INFO] 2021-07-09 16:44:46,284 [run_pretraining.py:  535]:	loss/mlm_loss, 8.111037254333496, 97
[INFO] 2021-07-09 16:44:46,284 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.599999657439184e-07, 97
[INFO] 2021-07-09 16:44:46,284 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 97
[INFO] 2021-07-09 16:44:46,284 [run_pretraining.py:  558]:	worker_index: 5, step: 97, cost: 8.111037, mlm loss: 8.111037, speed: 0.463946 steps/s, speed: 3.711564 samples/s, speed: 1900.320799 tokens/s, learning rate: 9.600e-07, loss_scalings: 16777.216797, pp_loss: 8.011456
[INFO] 2021-07-09 16:44:46,284 [run_pretraining.py:  512]:	********exe.run_97******* 
[INFO] 2021-07-09 16:44:48,442 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:48,442 [run_pretraining.py:  534]:	loss/total_loss, 7.824707984924316, 98
[INFO] 2021-07-09 16:44:48,442 [run_pretraining.py:  535]:	loss/mlm_loss, 7.824707984924316, 98
[INFO] 2021-07-09 16:44:48,443 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.699999736767495e-07, 98
[INFO] 2021-07-09 16:44:48,443 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 98
[INFO] 2021-07-09 16:44:48,443 [run_pretraining.py:  558]:	worker_index: 5, step: 98, cost: 7.824708, mlm loss: 7.824708, speed: 0.463371 steps/s, speed: 3.706969 samples/s, speed: 1897.968207 tokens/s, learning rate: 9.700e-07, loss_scalings: 16777.216797, pp_loss: 7.894065
[INFO] 2021-07-09 16:44:48,443 [run_pretraining.py:  512]:	********exe.run_98******* 
[INFO] 2021-07-09 16:44:50,596 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:50,597 [run_pretraining.py:  534]:	loss/total_loss, 7.754984378814697, 99
[INFO] 2021-07-09 16:44:50,597 [run_pretraining.py:  535]:	loss/mlm_loss, 7.754984378814697, 99
[INFO] 2021-07-09 16:44:50,597 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.799999816095806e-07, 99
[INFO] 2021-07-09 16:44:50,597 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 99
[INFO] 2021-07-09 16:44:50,597 [run_pretraining.py:  558]:	worker_index: 5, step: 99, cost: 7.754984, mlm loss: 7.754984, speed: 0.464355 steps/s, speed: 3.714837 samples/s, speed: 1901.996312 tokens/s, learning rate: 9.800e-07, loss_scalings: 16777.216797, pp_loss: 7.855569
[INFO] 2021-07-09 16:44:50,597 [run_pretraining.py:  512]:	********exe.run_99******* 
[INFO] 2021-07-09 16:44:52,750 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:52,751 [run_pretraining.py:  534]:	loss/total_loss, 7.888599395751953, 100
[INFO] 2021-07-09 16:44:52,751 [run_pretraining.py:  535]:	loss/mlm_loss, 7.888599395751953, 100
[INFO] 2021-07-09 16:44:52,751 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.899999895424116e-07, 100
[INFO] 2021-07-09 16:44:52,751 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 100
[INFO] 2021-07-09 16:44:52,751 [run_pretraining.py:  558]:	worker_index: 5, step: 100, cost: 7.888599, mlm loss: 7.888599, speed: 0.464417 steps/s, speed: 3.715335 samples/s, speed: 1902.251770 tokens/s, learning rate: 9.900e-07, loss_scalings: 16777.216797, pp_loss: 7.828806
[INFO] 2021-07-09 16:44:52,751 [run_pretraining.py:  512]:	********exe.run_100******* 
[INFO] 2021-07-09 16:44:54,962 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:54,962 [run_pretraining.py:  534]:	loss/total_loss, 7.723927021026611, 101
[INFO] 2021-07-09 16:44:54,963 [run_pretraining.py:  535]:	loss/mlm_loss, 7.723927021026611, 101
[INFO] 2021-07-09 16:44:54,963 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.999999974752427e-07, 101
[INFO] 2021-07-09 16:44:54,963 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 101
[INFO] 2021-07-09 16:44:54,963 [run_pretraining.py:  558]:	worker_index: 5, step: 101, cost: 7.723927, mlm loss: 7.723927, speed: 0.452225 steps/s, speed: 3.617803 samples/s, speed: 1852.314946 tokens/s, learning rate: 1.000e-06, loss_scalings: 16777.216797, pp_loss: 7.765051
[INFO] 2021-07-09 16:44:54,963 [run_pretraining.py:  512]:	********exe.run_101******* 
[INFO] 2021-07-09 16:44:57,120 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:57,120 [run_pretraining.py:  534]:	loss/total_loss, 7.920485496520996, 102
[INFO] 2021-07-09 16:44:57,121 [run_pretraining.py:  535]:	loss/mlm_loss, 7.920485496520996, 102
[INFO] 2021-07-09 16:44:57,121 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.009999891721236e-06, 102
[INFO] 2021-07-09 16:44:57,121 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 102
[INFO] 2021-07-09 16:44:57,121 [run_pretraining.py:  558]:	worker_index: 5, step: 102, cost: 7.920485, mlm loss: 7.920485, speed: 0.463554 steps/s, speed: 3.708429 samples/s, speed: 1898.715592 tokens/s, learning rate: 1.010e-06, loss_scalings: 16777.216797, pp_loss: 7.763479
[INFO] 2021-07-09 16:44:57,121 [run_pretraining.py:  512]:	********exe.run_102******* 
[INFO] 2021-07-09 16:44:59,287 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:44:59,287 [run_pretraining.py:  534]:	loss/total_loss, 7.9063849449157715, 103
[INFO] 2021-07-09 16:44:59,287 [run_pretraining.py:  535]:	loss/mlm_loss, 7.9063849449157715, 103
[INFO] 2021-07-09 16:44:59,288 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0200000133409048e-06, 103
[INFO] 2021-07-09 16:44:59,288 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 103
[INFO] 2021-07-09 16:44:59,288 [run_pretraining.py:  558]:	worker_index: 5, step: 103, cost: 7.906385, mlm loss: 7.906385, speed: 0.461631 steps/s, speed: 3.693047 samples/s, speed: 1890.840151 tokens/s, learning rate: 1.020e-06, loss_scalings: 16777.216797, pp_loss: 7.749093
[INFO] 2021-07-09 16:44:59,288 [run_pretraining.py:  512]:	********exe.run_103******* 
[INFO] 2021-07-09 16:45:01,482 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:01,482 [run_pretraining.py:  534]:	loss/total_loss, 7.622574806213379, 104
[INFO] 2021-07-09 16:45:01,483 [run_pretraining.py:  535]:	loss/mlm_loss, 7.622574806213379, 104
[INFO] 2021-07-09 16:45:01,483 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.030000021273736e-06, 104
[INFO] 2021-07-09 16:45:01,483 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 104
[INFO] 2021-07-09 16:45:01,483 [run_pretraining.py:  558]:	worker_index: 5, step: 104, cost: 7.622575, mlm loss: 7.622575, speed: 0.455711 steps/s, speed: 3.645685 samples/s, speed: 1866.590682 tokens/s, learning rate: 1.030e-06, loss_scalings: 16777.216797, pp_loss: 7.608702
[INFO] 2021-07-09 16:45:01,483 [run_pretraining.py:  512]:	********exe.run_104******* 
[INFO] 2021-07-09 16:45:03,726 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:03,726 [run_pretraining.py:  534]:	loss/total_loss, 7.510576248168945, 105
[INFO] 2021-07-09 16:45:03,726 [run_pretraining.py:  535]:	loss/mlm_loss, 7.510576248168945, 105
[INFO] 2021-07-09 16:45:03,726 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.040000029206567e-06, 105
[INFO] 2021-07-09 16:45:03,727 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 105
[INFO] 2021-07-09 16:45:03,727 [run_pretraining.py:  558]:	worker_index: 5, step: 105, cost: 7.510576, mlm loss: 7.510576, speed: 0.445816 steps/s, speed: 3.566530 samples/s, speed: 1826.063393 tokens/s, learning rate: 1.040e-06, loss_scalings: 16777.216797, pp_loss: 7.650017
[INFO] 2021-07-09 16:45:03,727 [run_pretraining.py:  512]:	********exe.run_105******* 
[INFO] 2021-07-09 16:45:05,976 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:05,977 [run_pretraining.py:  534]:	loss/total_loss, 7.526651859283447, 106
[INFO] 2021-07-09 16:45:05,977 [run_pretraining.py:  535]:	loss/mlm_loss, 7.526651859283447, 106
[INFO] 2021-07-09 16:45:05,977 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0499999234525603e-06, 106
[INFO] 2021-07-09 16:45:05,977 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 106
[INFO] 2021-07-09 16:45:05,977 [run_pretraining.py:  558]:	worker_index: 5, step: 106, cost: 7.526652, mlm loss: 7.526652, speed: 0.444451 steps/s, speed: 3.555608 samples/s, speed: 1820.471258 tokens/s, learning rate: 1.050e-06, loss_scalings: 16777.216797, pp_loss: 7.568365
[INFO] 2021-07-09 16:45:05,977 [run_pretraining.py:  512]:	********exe.run_106******* 
[INFO] 2021-07-09 16:45:08,186 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:08,186 [run_pretraining.py:  534]:	loss/total_loss, 7.644090175628662, 107
[INFO] 2021-07-09 16:45:08,186 [run_pretraining.py:  535]:	loss/mlm_loss, 7.644090175628662, 107
[INFO] 2021-07-09 16:45:08,186 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0599999313853914e-06, 107
[INFO] 2021-07-09 16:45:08,187 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 107
[INFO] 2021-07-09 16:45:08,187 [run_pretraining.py:  558]:	worker_index: 5, step: 107, cost: 7.644090, mlm loss: 7.644090, speed: 0.452778 steps/s, speed: 3.622222 samples/s, speed: 1854.577477 tokens/s, learning rate: 1.060e-06, loss_scalings: 16777.216797, pp_loss: 7.513198
[INFO] 2021-07-09 16:45:08,187 [run_pretraining.py:  512]:	********exe.run_107******* 
[INFO] 2021-07-09 16:45:10,369 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:10,370 [run_pretraining.py:  534]:	loss/total_loss, 7.424966812133789, 108
[INFO] 2021-07-09 16:45:10,370 [run_pretraining.py:  535]:	loss/mlm_loss, 7.424966812133789, 108
[INFO] 2021-07-09 16:45:10,370 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0700000530050602e-06, 108
[INFO] 2021-07-09 16:45:10,370 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 108
[INFO] 2021-07-09 16:45:10,370 [run_pretraining.py:  558]:	worker_index: 5, step: 108, cost: 7.424967, mlm loss: 7.424967, speed: 0.458130 steps/s, speed: 3.665042 samples/s, speed: 1876.501574 tokens/s, learning rate: 1.070e-06, loss_scalings: 16777.216797, pp_loss: 7.486315
[INFO] 2021-07-09 16:45:10,370 [run_pretraining.py:  512]:	********exe.run_108******* 
[INFO] 2021-07-09 16:45:12,578 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:12,578 [run_pretraining.py:  534]:	loss/total_loss, 7.388258934020996, 109
[INFO] 2021-07-09 16:45:12,578 [run_pretraining.py:  535]:	loss/mlm_loss, 7.388258934020996, 109
[INFO] 2021-07-09 16:45:12,578 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0799999472510535e-06, 109
[INFO] 2021-07-09 16:45:12,578 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 109
[INFO] 2021-07-09 16:45:12,579 [run_pretraining.py:  558]:	worker_index: 5, step: 109, cost: 7.388259, mlm loss: 7.388259, speed: 0.452938 steps/s, speed: 3.623501 samples/s, speed: 1855.232571 tokens/s, learning rate: 1.080e-06, loss_scalings: 16777.216797, pp_loss: 7.380242
[INFO] 2021-07-09 16:45:12,579 [run_pretraining.py:  512]:	********exe.run_109******* 
[INFO] 2021-07-09 16:45:14,760 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:14,761 [run_pretraining.py:  534]:	loss/total_loss, 7.350269794464111, 110
[INFO] 2021-07-09 16:45:14,761 [run_pretraining.py:  535]:	loss/mlm_loss, 7.350269794464111, 110
[INFO] 2021-07-09 16:45:14,761 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0899999551838846e-06, 110
[INFO] 2021-07-09 16:45:14,761 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 110
[INFO] 2021-07-09 16:45:14,761 [run_pretraining.py:  558]:	worker_index: 5, step: 110, cost: 7.350270, mlm loss: 7.350270, speed: 0.458346 steps/s, speed: 3.666769 samples/s, speed: 1877.385591 tokens/s, learning rate: 1.090e-06, loss_scalings: 16777.216797, pp_loss: 7.401387
[INFO] 2021-07-09 16:45:14,761 [run_pretraining.py:  512]:	********exe.run_110******* 
[INFO] 2021-07-09 16:45:16,964 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:16,965 [run_pretraining.py:  534]:	loss/total_loss, 7.254185199737549, 111
[INFO] 2021-07-09 16:45:16,965 [run_pretraining.py:  535]:	loss/mlm_loss, 7.254185199737549, 111
[INFO] 2021-07-09 16:45:16,965 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0999999631167157e-06, 111
[INFO] 2021-07-09 16:45:16,965 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 111
[INFO] 2021-07-09 16:45:16,965 [run_pretraining.py:  558]:	worker_index: 5, step: 111, cost: 7.254185, mlm loss: 7.254185, speed: 0.453836 steps/s, speed: 3.630690 samples/s, speed: 1858.913372 tokens/s, learning rate: 1.100e-06, loss_scalings: 16777.216797, pp_loss: 7.310852
[INFO] 2021-07-09 16:45:16,965 [run_pretraining.py:  512]:	********exe.run_111******* 
[INFO] 2021-07-09 16:45:19,139 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:19,140 [run_pretraining.py:  534]:	loss/total_loss, 7.17913293838501, 112
[INFO] 2021-07-09 16:45:19,140 [run_pretraining.py:  535]:	loss/mlm_loss, 7.17913293838501, 112
[INFO] 2021-07-09 16:45:19,140 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1099999710495467e-06, 112
[INFO] 2021-07-09 16:45:19,140 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 112
[INFO] 2021-07-09 16:45:19,140 [run_pretraining.py:  558]:	worker_index: 5, step: 112, cost: 7.179133, mlm loss: 7.179133, speed: 0.459871 steps/s, speed: 3.678964 samples/s, speed: 1883.629739 tokens/s, learning rate: 1.110e-06, loss_scalings: 16777.216797, pp_loss: 7.285627
[INFO] 2021-07-09 16:45:19,140 [run_pretraining.py:  512]:	********exe.run_112******* 
[INFO] 2021-07-09 16:45:21,331 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:21,332 [run_pretraining.py:  534]:	loss/total_loss, 7.159326076507568, 113
[INFO] 2021-07-09 16:45:21,332 [run_pretraining.py:  535]:	loss/mlm_loss, 7.159326076507568, 113
[INFO] 2021-07-09 16:45:21,332 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1199999789823778e-06, 113
[INFO] 2021-07-09 16:45:21,332 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 113
[INFO] 2021-07-09 16:45:21,332 [run_pretraining.py:  558]:	worker_index: 5, step: 113, cost: 7.159326, mlm loss: 7.159326, speed: 0.456329 steps/s, speed: 3.650635 samples/s, speed: 1869.125327 tokens/s, learning rate: 1.120e-06, loss_scalings: 16777.216797, pp_loss: 7.244399
[INFO] 2021-07-09 16:45:21,333 [run_pretraining.py:  512]:	********exe.run_113******* 
[INFO] 2021-07-09 16:45:23,561 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:23,562 [run_pretraining.py:  534]:	loss/total_loss, 7.242321014404297, 114
[INFO] 2021-07-09 16:45:23,562 [run_pretraining.py:  535]:	loss/mlm_loss, 7.242321014404297, 114
[INFO] 2021-07-09 16:45:23,562 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1299999869152089e-06, 114
[INFO] 2021-07-09 16:45:23,562 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 114
[INFO] 2021-07-09 16:45:23,562 [run_pretraining.py:  558]:	worker_index: 5, step: 114, cost: 7.242321, mlm loss: 7.242321, speed: 0.448662 steps/s, speed: 3.589294 samples/s, speed: 1837.718702 tokens/s, learning rate: 1.130e-06, loss_scalings: 16777.216797, pp_loss: 7.158665
[INFO] 2021-07-09 16:45:23,562 [run_pretraining.py:  512]:	********exe.run_114******* 
[INFO] 2021-07-09 16:45:25,828 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:25,829 [run_pretraining.py:  534]:	loss/total_loss, 7.106572151184082, 115
[INFO] 2021-07-09 16:45:25,829 [run_pretraining.py:  535]:	loss/mlm_loss, 7.106572151184082, 115
[INFO] 2021-07-09 16:45:25,829 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.13999999484804e-06, 115
[INFO] 2021-07-09 16:45:25,829 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 115
[INFO] 2021-07-09 16:45:25,829 [run_pretraining.py:  558]:	worker_index: 5, step: 115, cost: 7.106572, mlm loss: 7.106572, speed: 0.441204 steps/s, speed: 3.529632 samples/s, speed: 1807.171558 tokens/s, learning rate: 1.140e-06, loss_scalings: 16777.216797, pp_loss: 7.074710
[INFO] 2021-07-09 16:45:25,829 [run_pretraining.py:  512]:	********exe.run_115******* 
[INFO] 2021-07-09 16:45:28,052 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:28,053 [run_pretraining.py:  534]:	loss/total_loss, 6.994532585144043, 116
[INFO] 2021-07-09 16:45:28,053 [run_pretraining.py:  535]:	loss/mlm_loss, 6.994532585144043, 116
[INFO] 2021-07-09 16:45:28,053 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.150000002780871e-06, 116
[INFO] 2021-07-09 16:45:28,053 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 116
[INFO] 2021-07-09 16:45:28,053 [run_pretraining.py:  558]:	worker_index: 5, step: 116, cost: 6.994533, mlm loss: 6.994533, speed: 0.449732 steps/s, speed: 3.597857 samples/s, speed: 1842.103031 tokens/s, learning rate: 1.150e-06, loss_scalings: 16777.216797, pp_loss: 7.094471
[INFO] 2021-07-09 16:45:28,054 [run_pretraining.py:  512]:	********exe.run_116******* 
[INFO] 2021-07-09 16:45:30,259 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:30,260 [run_pretraining.py:  534]:	loss/total_loss, 7.023538589477539, 117
[INFO] 2021-07-09 16:45:30,260 [run_pretraining.py:  535]:	loss/mlm_loss, 7.023538589477539, 117
[INFO] 2021-07-09 16:45:30,260 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.160000010713702e-06, 117
[INFO] 2021-07-09 16:45:30,260 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 117
[INFO] 2021-07-09 16:45:30,260 [run_pretraining.py:  558]:	worker_index: 5, step: 117, cost: 7.023539, mlm loss: 7.023539, speed: 0.453293 steps/s, speed: 3.626348 samples/s, speed: 1856.690018 tokens/s, learning rate: 1.160e-06, loss_scalings: 16777.216797, pp_loss: 7.019304
[INFO] 2021-07-09 16:45:30,260 [run_pretraining.py:  512]:	********exe.run_117******* 
[INFO] 2021-07-09 16:45:32,475 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:32,475 [run_pretraining.py:  534]:	loss/total_loss, 7.074400424957275, 118
[INFO] 2021-07-09 16:45:32,475 [run_pretraining.py:  535]:	loss/mlm_loss, 7.074400424957275, 118
[INFO] 2021-07-09 16:45:32,476 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1699999049596954e-06, 118
[INFO] 2021-07-09 16:45:32,476 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 118
[INFO] 2021-07-09 16:45:32,476 [run_pretraining.py:  558]:	worker_index: 5, step: 118, cost: 7.074400, mlm loss: 7.074400, speed: 0.451507 steps/s, speed: 3.612052 samples/s, speed: 1849.370847 tokens/s, learning rate: 1.170e-06, loss_scalings: 16777.216797, pp_loss: 6.961404
[INFO] 2021-07-09 16:45:32,476 [run_pretraining.py:  512]:	********exe.run_118******* 
[INFO] 2021-07-09 16:45:34,692 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:34,692 [run_pretraining.py:  534]:	loss/total_loss, 6.847548484802246, 119
[INFO] 2021-07-09 16:45:34,692 [run_pretraining.py:  535]:	loss/mlm_loss, 6.847548484802246, 119
[INFO] 2021-07-09 16:45:34,692 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1800000265793642e-06, 119
[INFO] 2021-07-09 16:45:34,693 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 119
[INFO] 2021-07-09 16:45:34,693 [run_pretraining.py:  558]:	worker_index: 5, step: 119, cost: 6.847548, mlm loss: 6.847548, speed: 0.451233 steps/s, speed: 3.609862 samples/s, speed: 1848.249511 tokens/s, learning rate: 1.180e-06, loss_scalings: 16777.216797, pp_loss: 6.982248
[INFO] 2021-07-09 16:45:34,693 [run_pretraining.py:  512]:	********exe.run_119******* 
[INFO] 2021-07-09 16:45:36,937 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:36,937 [run_pretraining.py:  534]:	loss/total_loss, 6.964221954345703, 120
[INFO] 2021-07-09 16:45:36,938 [run_pretraining.py:  535]:	loss/mlm_loss, 6.964221954345703, 120
[INFO] 2021-07-09 16:45:36,938 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1900000345121953e-06, 120
[INFO] 2021-07-09 16:45:36,938 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 120
[INFO] 2021-07-09 16:45:36,938 [run_pretraining.py:  558]:	worker_index: 5, step: 120, cost: 6.964222, mlm loss: 6.964222, speed: 0.445537 steps/s, speed: 3.564293 samples/s, speed: 1824.917988 tokens/s, learning rate: 1.190e-06, loss_scalings: 16777.216797, pp_loss: 6.942768
[INFO] 2021-07-09 16:45:36,938 [run_pretraining.py:  512]:	********exe.run_120******* 
[INFO] 2021-07-09 16:45:39,180 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:39,181 [run_pretraining.py:  534]:	loss/total_loss, 6.81241512298584, 121
[INFO] 2021-07-09 16:45:39,181 [run_pretraining.py:  535]:	loss/mlm_loss, 6.81241512298584, 121
[INFO] 2021-07-09 16:45:39,181 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1999999287581886e-06, 121
[INFO] 2021-07-09 16:45:39,181 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 121
[INFO] 2021-07-09 16:45:39,181 [run_pretraining.py:  558]:	worker_index: 5, step: 121, cost: 6.812415, mlm loss: 6.812415, speed: 0.445933 steps/s, speed: 3.567461 samples/s, speed: 1826.539824 tokens/s, learning rate: 1.200e-06, loss_scalings: 16777.216797, pp_loss: 6.794543
[INFO] 2021-07-09 16:45:39,181 [run_pretraining.py:  512]:	********exe.run_121******* 
[INFO] 2021-07-09 16:45:41,428 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:41,429 [run_pretraining.py:  534]:	loss/total_loss, 6.931360721588135, 122
[INFO] 2021-07-09 16:45:41,429 [run_pretraining.py:  535]:	loss/mlm_loss, 6.931360721588135, 122
[INFO] 2021-07-09 16:45:41,429 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2099999366910197e-06, 122
[INFO] 2021-07-09 16:45:41,429 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 122
[INFO] 2021-07-09 16:45:41,430 [run_pretraining.py:  558]:	worker_index: 5, step: 122, cost: 6.931361, mlm loss: 6.931361, speed: 0.444868 steps/s, speed: 3.558944 samples/s, speed: 1822.179121 tokens/s, learning rate: 1.210e-06, loss_scalings: 16777.216797, pp_loss: 6.799092
[INFO] 2021-07-09 16:45:41,430 [run_pretraining.py:  512]:	********exe.run_122******* 
[INFO] 2021-07-09 16:45:43,670 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:43,670 [run_pretraining.py:  534]:	loss/total_loss, 6.765595436096191, 123
[INFO] 2021-07-09 16:45:43,670 [run_pretraining.py:  535]:	loss/mlm_loss, 6.765595436096191, 123
[INFO] 2021-07-09 16:45:43,670 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2199999446238508e-06, 123
[INFO] 2021-07-09 16:45:43,671 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 123
[INFO] 2021-07-09 16:45:43,671 [run_pretraining.py:  558]:	worker_index: 5, step: 123, cost: 6.765595, mlm loss: 6.765595, speed: 0.446352 steps/s, speed: 3.570819 samples/s, speed: 1828.259486 tokens/s, learning rate: 1.220e-06, loss_scalings: 16777.216797, pp_loss: 6.666770
[INFO] 2021-07-09 16:45:43,671 [run_pretraining.py:  512]:	********exe.run_123******* 
[INFO] 2021-07-09 16:45:45,892 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:45,893 [run_pretraining.py:  534]:	loss/total_loss, 6.811588287353516, 124
[INFO] 2021-07-09 16:45:45,893 [run_pretraining.py:  535]:	loss/mlm_loss, 6.811588287353516, 124
[INFO] 2021-07-09 16:45:45,893 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2299999525566818e-06, 124
[INFO] 2021-07-09 16:45:45,893 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 124
[INFO] 2021-07-09 16:45:45,893 [run_pretraining.py:  558]:	worker_index: 5, step: 124, cost: 6.811588, mlm loss: 6.811588, speed: 0.450055 steps/s, speed: 3.600443 samples/s, speed: 1843.426566 tokens/s, learning rate: 1.230e-06, loss_scalings: 16777.216797, pp_loss: 6.736517
[INFO] 2021-07-09 16:45:45,893 [run_pretraining.py:  512]:	********exe.run_124******* 
[INFO] 2021-07-09 16:45:48,092 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:48,092 [run_pretraining.py:  534]:	loss/total_loss, 6.66330623626709, 125
[INFO] 2021-07-09 16:45:48,092 [run_pretraining.py:  535]:	loss/mlm_loss, 6.66330623626709, 125
[INFO] 2021-07-09 16:45:48,093 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2399999604895129e-06, 125
[INFO] 2021-07-09 16:45:48,093 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 125
[INFO] 2021-07-09 16:45:48,093 [run_pretraining.py:  558]:	worker_index: 5, step: 125, cost: 6.663306, mlm loss: 6.663306, speed: 0.454797 steps/s, speed: 3.638375 samples/s, speed: 1862.848137 tokens/s, learning rate: 1.240e-06, loss_scalings: 16777.216797, pp_loss: 6.624520
[INFO] 2021-07-09 16:45:48,093 [run_pretraining.py:  512]:	********exe.run_125******* 
[INFO] 2021-07-09 16:45:50,316 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:50,317 [run_pretraining.py:  534]:	loss/total_loss, 6.544850826263428, 126
[INFO] 2021-07-09 16:45:50,317 [run_pretraining.py:  535]:	loss/mlm_loss, 6.544850826263428, 126
[INFO] 2021-07-09 16:45:50,317 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.249999968422344e-06, 126
[INFO] 2021-07-09 16:45:50,317 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 126
[INFO] 2021-07-09 16:45:50,317 [run_pretraining.py:  558]:	worker_index: 5, step: 126, cost: 6.544851, mlm loss: 6.544851, speed: 0.449673 steps/s, speed: 3.597383 samples/s, speed: 1841.860313 tokens/s, learning rate: 1.250e-06, loss_scalings: 16777.216797, pp_loss: 6.576504
[INFO] 2021-07-09 16:45:50,317 [run_pretraining.py:  512]:	********exe.run_126******* 
[INFO] 2021-07-09 16:45:52,565 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:52,565 [run_pretraining.py:  534]:	loss/total_loss, 6.43430757522583, 127
[INFO] 2021-07-09 16:45:52,565 [run_pretraining.py:  535]:	loss/mlm_loss, 6.43430757522583, 127
[INFO] 2021-07-09 16:45:52,565 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.259999976355175e-06, 127
[INFO] 2021-07-09 16:45:52,566 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 127
[INFO] 2021-07-09 16:45:52,566 [run_pretraining.py:  558]:	worker_index: 5, step: 127, cost: 6.434308, mlm loss: 6.434308, speed: 0.444909 steps/s, speed: 3.559268 samples/s, speed: 1822.345347 tokens/s, learning rate: 1.260e-06, loss_scalings: 16777.216797, pp_loss: 6.496407
[INFO] 2021-07-09 16:45:52,566 [run_pretraining.py:  512]:	********exe.run_127******* 
[INFO] 2021-07-09 16:45:54,775 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:54,775 [run_pretraining.py:  534]:	loss/total_loss, 6.4537672996521, 128
[INFO] 2021-07-09 16:45:54,775 [run_pretraining.py:  535]:	loss/mlm_loss, 6.4537672996521, 128
[INFO] 2021-07-09 16:45:54,775 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.269999984288006e-06, 128
[INFO] 2021-07-09 16:45:54,776 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 128
[INFO] 2021-07-09 16:45:54,776 [run_pretraining.py:  558]:	worker_index: 5, step: 128, cost: 6.453767, mlm loss: 6.453767, speed: 0.452623 steps/s, speed: 3.620988 samples/s, speed: 1853.945852 tokens/s, learning rate: 1.270e-06, loss_scalings: 16777.216797, pp_loss: 6.441777
[INFO] 2021-07-09 16:45:54,776 [run_pretraining.py:  512]:	********exe.run_128******* 
[INFO] 2021-07-09 16:45:56,978 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:56,979 [run_pretraining.py:  534]:	loss/total_loss, 6.41992712020874, 129
[INFO] 2021-07-09 16:45:56,979 [run_pretraining.py:  535]:	loss/mlm_loss, 6.41992712020874, 129
[INFO] 2021-07-09 16:45:56,979 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2799998785339994e-06, 129
[INFO] 2021-07-09 16:45:56,979 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 129
[INFO] 2021-07-09 16:45:56,979 [run_pretraining.py:  558]:	worker_index: 5, step: 129, cost: 6.419927, mlm loss: 6.419927, speed: 0.453948 steps/s, speed: 3.631582 samples/s, speed: 1859.369871 tokens/s, learning rate: 1.280e-06, loss_scalings: 16777.216797, pp_loss: 6.388518
[INFO] 2021-07-09 16:45:56,979 [run_pretraining.py:  512]:	********exe.run_129******* 
[INFO] 2021-07-09 16:45:59,237 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:45:59,237 [run_pretraining.py:  534]:	loss/total_loss, 6.9674859046936035, 130
[INFO] 2021-07-09 16:45:59,237 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9674859046936035, 130
[INFO] 2021-07-09 16:45:59,237 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2900000001536682e-06, 130
[INFO] 2021-07-09 16:45:59,237 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 130
[INFO] 2021-07-09 16:45:59,238 [run_pretraining.py:  558]:	worker_index: 5, step: 130, cost: 6.967486, mlm loss: 6.967486, speed: 0.442958 steps/s, speed: 3.543665 samples/s, speed: 1814.356653 tokens/s, learning rate: 1.290e-06, loss_scalings: 16777.216797, pp_loss: 6.454121
[INFO] 2021-07-09 16:45:59,238 [run_pretraining.py:  512]:	********exe.run_130******* 
[INFO] 2021-07-09 16:46:01,451 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:01,451 [run_pretraining.py:  534]:	loss/total_loss, 6.584932327270508, 131
[INFO] 2021-07-09 16:46:01,451 [run_pretraining.py:  535]:	loss/mlm_loss, 6.584932327270508, 131
[INFO] 2021-07-09 16:46:01,452 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3000000080864993e-06, 131
[INFO] 2021-07-09 16:46:01,452 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 131
[INFO] 2021-07-09 16:46:01,452 [run_pretraining.py:  558]:	worker_index: 5, step: 131, cost: 6.584932, mlm loss: 6.584932, speed: 0.451791 steps/s, speed: 3.614331 samples/s, speed: 1850.537396 tokens/s, learning rate: 1.300e-06, loss_scalings: 16777.216797, pp_loss: 6.388751
[INFO] 2021-07-09 16:46:01,452 [run_pretraining.py:  512]:	********exe.run_131******* 
[INFO] 2021-07-09 16:46:03,631 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:03,632 [run_pretraining.py:  534]:	loss/total_loss, 6.257869243621826, 132
[INFO] 2021-07-09 16:46:03,632 [run_pretraining.py:  535]:	loss/mlm_loss, 6.257869243621826, 132
[INFO] 2021-07-09 16:46:03,632 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3100000160193304e-06, 132
[INFO] 2021-07-09 16:46:03,632 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 132
[INFO] 2021-07-09 16:46:03,632 [run_pretraining.py:  558]:	worker_index: 5, step: 132, cost: 6.257869, mlm loss: 6.257869, speed: 0.458708 steps/s, speed: 3.669660 samples/s, speed: 1878.866147 tokens/s, learning rate: 1.310e-06, loss_scalings: 16777.216797, pp_loss: 6.251366
[INFO] 2021-07-09 16:46:03,632 [run_pretraining.py:  512]:	********exe.run_132******* 
[INFO] 2021-07-09 16:46:05,956 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:05,957 [run_pretraining.py:  534]:	loss/total_loss, 6.407278060913086, 133
[INFO] 2021-07-09 16:46:05,957 [run_pretraining.py:  535]:	loss/mlm_loss, 6.407278060913086, 133
[INFO] 2021-07-09 16:46:05,958 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3199999102653237e-06, 133
[INFO] 2021-07-09 16:46:05,958 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 133
[INFO] 2021-07-09 16:46:05,958 [run_pretraining.py:  558]:	worker_index: 5, step: 133, cost: 6.407278, mlm loss: 6.407278, speed: 0.430189 steps/s, speed: 3.441513 samples/s, speed: 1762.054492 tokens/s, learning rate: 1.320e-06, loss_scalings: 16777.216797, pp_loss: 6.248106
[INFO] 2021-07-09 16:46:05,958 [run_pretraining.py:  512]:	********exe.run_133******* 
[INFO] 2021-07-09 16:46:08,200 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:08,201 [run_pretraining.py:  534]:	loss/total_loss, 6.401984691619873, 134
[INFO] 2021-07-09 16:46:08,201 [run_pretraining.py:  535]:	loss/mlm_loss, 6.401984691619873, 134
[INFO] 2021-07-09 16:46:08,201 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3299999181981548e-06, 134
[INFO] 2021-07-09 16:46:08,201 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 134
[INFO] 2021-07-09 16:46:08,201 [run_pretraining.py:  558]:	worker_index: 5, step: 134, cost: 6.401985, mlm loss: 6.401985, speed: 0.445867 steps/s, speed: 3.566935 samples/s, speed: 1826.270515 tokens/s, learning rate: 1.330e-06, loss_scalings: 16777.216797, pp_loss: 6.210238
[INFO] 2021-07-09 16:46:08,201 [run_pretraining.py:  512]:	********exe.run_134******* 
[INFO] 2021-07-09 16:46:10,409 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:10,409 [run_pretraining.py:  534]:	loss/total_loss, 6.156445503234863, 135
[INFO] 2021-07-09 16:46:10,409 [run_pretraining.py:  535]:	loss/mlm_loss, 6.156445503234863, 135
[INFO] 2021-07-09 16:46:10,409 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3399999261309858e-06, 135
[INFO] 2021-07-09 16:46:10,409 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 135
[INFO] 2021-07-09 16:46:10,410 [run_pretraining.py:  558]:	worker_index: 5, step: 135, cost: 6.156446, mlm loss: 6.156446, speed: 0.452982 steps/s, speed: 3.623853 samples/s, speed: 1855.412498 tokens/s, learning rate: 1.340e-06, loss_scalings: 16777.216797, pp_loss: 6.129306
[INFO] 2021-07-09 16:46:10,410 [run_pretraining.py:  512]:	********exe.run_135******* 
[INFO] 2021-07-09 16:46:12,608 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:12,608 [run_pretraining.py:  534]:	loss/total_loss, 6.148632526397705, 136
[INFO] 2021-07-09 16:46:12,608 [run_pretraining.py:  535]:	loss/mlm_loss, 6.148632526397705, 136
[INFO] 2021-07-09 16:46:12,609 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3500000477506546e-06, 136
[INFO] 2021-07-09 16:46:12,609 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 136
[INFO] 2021-07-09 16:46:12,609 [run_pretraining.py:  558]:	worker_index: 5, step: 136, cost: 6.148633, mlm loss: 6.148633, speed: 0.454871 steps/s, speed: 3.638966 samples/s, speed: 1863.150771 tokens/s, learning rate: 1.350e-06, loss_scalings: 16777.216797, pp_loss: 6.079474
[INFO] 2021-07-09 16:46:12,609 [run_pretraining.py:  512]:	********exe.run_136******* 
[INFO] 2021-07-09 16:46:14,848 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:14,849 [run_pretraining.py:  534]:	loss/total_loss, 5.974782943725586, 137
[INFO] 2021-07-09 16:46:14,849 [run_pretraining.py:  535]:	loss/mlm_loss, 5.974782943725586, 137
[INFO] 2021-07-09 16:46:14,849 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.359999941996648e-06, 137
[INFO] 2021-07-09 16:46:14,849 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 137
[INFO] 2021-07-09 16:46:14,849 [run_pretraining.py:  558]:	worker_index: 5, step: 137, cost: 5.974783, mlm loss: 5.974783, speed: 0.446496 steps/s, speed: 3.571970 samples/s, speed: 1828.848807 tokens/s, learning rate: 1.360e-06, loss_scalings: 16777.216797, pp_loss: 6.060974
[INFO] 2021-07-09 16:46:14,849 [run_pretraining.py:  512]:	********exe.run_137******* 
[INFO] 2021-07-09 16:46:17,158 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:17,159 [run_pretraining.py:  534]:	loss/total_loss, 6.235828399658203, 138
[INFO] 2021-07-09 16:46:17,159 [run_pretraining.py:  535]:	loss/mlm_loss, 6.235828399658203, 138
[INFO] 2021-07-09 16:46:17,159 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.369999949929479e-06, 138
[INFO] 2021-07-09 16:46:17,159 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 138
[INFO] 2021-07-09 16:46:17,159 [run_pretraining.py:  558]:	worker_index: 5, step: 138, cost: 6.235828, mlm loss: 6.235828, speed: 0.432988 steps/s, speed: 3.463901 samples/s, speed: 1773.517159 tokens/s, learning rate: 1.370e-06, loss_scalings: 16777.216797, pp_loss: 6.056585
[INFO] 2021-07-09 16:46:17,159 [run_pretraining.py:  512]:	********exe.run_138******* 
[INFO] 2021-07-09 16:46:19,341 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:19,341 [run_pretraining.py:  534]:	loss/total_loss, 5.8881306648254395, 139
[INFO] 2021-07-09 16:46:19,341 [run_pretraining.py:  535]:	loss/mlm_loss, 5.8881306648254395, 139
[INFO] 2021-07-09 16:46:19,341 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3799999578623101e-06, 139
[INFO] 2021-07-09 16:46:19,341 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 139
[INFO] 2021-07-09 16:46:19,341 [run_pretraining.py:  558]:	worker_index: 5, step: 139, cost: 5.888131, mlm loss: 5.888131, speed: 0.458390 steps/s, speed: 3.667119 samples/s, speed: 1877.565121 tokens/s, learning rate: 1.380e-06, loss_scalings: 16777.216797, pp_loss: 5.949242
[INFO] 2021-07-09 16:46:19,341 [run_pretraining.py:  512]:	********exe.run_139******* 
[INFO] 2021-07-09 16:46:21,486 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:21,486 [run_pretraining.py:  534]:	loss/total_loss, 5.987215995788574, 140
[INFO] 2021-07-09 16:46:21,486 [run_pretraining.py:  535]:	loss/mlm_loss, 5.987215995788574, 140
[INFO] 2021-07-09 16:46:21,486 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3899999657951412e-06, 140
[INFO] 2021-07-09 16:46:21,487 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 140
[INFO] 2021-07-09 16:46:21,487 [run_pretraining.py:  558]:	worker_index: 5, step: 140, cost: 5.987216, mlm loss: 5.987216, speed: 0.466287 steps/s, speed: 3.730298 samples/s, speed: 1909.912710 tokens/s, learning rate: 1.390e-06, loss_scalings: 16777.216797, pp_loss: 5.895612
[INFO] 2021-07-09 16:46:21,487 [run_pretraining.py:  512]:	********exe.run_140******* 
[INFO] 2021-07-09 16:46:23,559 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:23,559 [run_pretraining.py:  534]:	loss/total_loss, 6.020351886749268, 141
[INFO] 2021-07-09 16:46:23,560 [run_pretraining.py:  535]:	loss/mlm_loss, 6.020351886749268, 141
[INFO] 2021-07-09 16:46:23,560 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3999999737279722e-06, 141
[INFO] 2021-07-09 16:46:23,560 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 141
[INFO] 2021-07-09 16:46:23,560 [run_pretraining.py:  558]:	worker_index: 5, step: 141, cost: 6.020352, mlm loss: 6.020352, speed: 0.482501 steps/s, speed: 3.860005 samples/s, speed: 1976.322735 tokens/s, learning rate: 1.400e-06, loss_scalings: 16777.216797, pp_loss: 5.831239
[INFO] 2021-07-09 16:46:23,560 [run_pretraining.py:  512]:	********exe.run_141******* 
[INFO] 2021-07-09 16:46:25,663 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:25,664 [run_pretraining.py:  534]:	loss/total_loss, 5.695346832275391, 142
[INFO] 2021-07-09 16:46:25,664 [run_pretraining.py:  535]:	loss/mlm_loss, 5.695346832275391, 142
[INFO] 2021-07-09 16:46:25,664 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4099999816608033e-06, 142
[INFO] 2021-07-09 16:46:25,664 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 142
[INFO] 2021-07-09 16:46:25,664 [run_pretraining.py:  558]:	worker_index: 5, step: 142, cost: 5.695347, mlm loss: 5.695347, speed: 0.475398 steps/s, speed: 3.803185 samples/s, speed: 1947.230688 tokens/s, learning rate: 1.410e-06, loss_scalings: 16777.216797, pp_loss: 5.771862
[INFO] 2021-07-09 16:46:25,664 [run_pretraining.py:  512]:	********exe.run_142******* 
[INFO] 2021-07-09 16:46:27,900 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:27,901 [run_pretraining.py:  534]:	loss/total_loss, 5.712960243225098, 143
[INFO] 2021-07-09 16:46:27,901 [run_pretraining.py:  535]:	loss/mlm_loss, 5.712960243225098, 143
[INFO] 2021-07-09 16:46:27,901 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4199999895936344e-06, 143
[INFO] 2021-07-09 16:46:27,901 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 143
[INFO] 2021-07-09 16:46:27,901 [run_pretraining.py:  558]:	worker_index: 5, step: 143, cost: 5.712960, mlm loss: 5.712960, speed: 0.447131 steps/s, speed: 3.577045 samples/s, speed: 1831.447275 tokens/s, learning rate: 1.420e-06, loss_scalings: 16777.216797, pp_loss: 5.791454
[INFO] 2021-07-09 16:46:27,901 [run_pretraining.py:  512]:	********exe.run_143******* 
[INFO] 2021-07-09 16:46:29,991 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:29,991 [run_pretraining.py:  534]:	loss/total_loss, 5.729427337646484, 144
[INFO] 2021-07-09 16:46:29,991 [run_pretraining.py:  535]:	loss/mlm_loss, 5.729427337646484, 144
[INFO] 2021-07-09 16:46:29,991 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4299999975264654e-06, 144
[INFO] 2021-07-09 16:46:29,992 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 144
[INFO] 2021-07-09 16:46:29,992 [run_pretraining.py:  558]:	worker_index: 5, step: 144, cost: 5.729427, mlm loss: 5.729427, speed: 0.478584 steps/s, speed: 3.828676 samples/s, speed: 1960.281875 tokens/s, learning rate: 1.430e-06, loss_scalings: 16777.216797, pp_loss: 5.677938
[INFO] 2021-07-09 16:46:29,992 [run_pretraining.py:  512]:	********exe.run_144******* 
[INFO] 2021-07-09 16:46:32,141 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:32,141 [run_pretraining.py:  534]:	loss/total_loss, 5.951098442077637, 145
[INFO] 2021-07-09 16:46:32,142 [run_pretraining.py:  535]:	loss/mlm_loss, 5.951098442077637, 145
[INFO] 2021-07-09 16:46:32,142 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4399998917724588e-06, 145
[INFO] 2021-07-09 16:46:32,142 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 145
[INFO] 2021-07-09 16:46:32,142 [run_pretraining.py:  558]:	worker_index: 5, step: 145, cost: 5.951098, mlm loss: 5.951098, speed: 0.465215 steps/s, speed: 3.721718 samples/s, speed: 1905.519581 tokens/s, learning rate: 1.440e-06, loss_scalings: 16777.216797, pp_loss: 5.668610
[INFO] 2021-07-09 16:46:32,142 [run_pretraining.py:  512]:	********exe.run_145******* 
[INFO] 2021-07-09 16:46:34,238 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:34,238 [run_pretraining.py:  534]:	loss/total_loss, 5.514326572418213, 146
[INFO] 2021-07-09 16:46:34,238 [run_pretraining.py:  535]:	loss/mlm_loss, 5.514326572418213, 146
[INFO] 2021-07-09 16:46:34,238 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4499998997052899e-06, 146
[INFO] 2021-07-09 16:46:34,239 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 146
[INFO] 2021-07-09 16:46:34,239 [run_pretraining.py:  558]:	worker_index: 5, step: 146, cost: 5.514327, mlm loss: 5.514327, speed: 0.477066 steps/s, speed: 3.816529 samples/s, speed: 1954.062927 tokens/s, learning rate: 1.450e-06, loss_scalings: 16777.216797, pp_loss: 5.639215
[INFO] 2021-07-09 16:46:34,239 [run_pretraining.py:  512]:	********exe.run_146******* 
[INFO] 2021-07-09 16:46:36,421 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:36,421 [run_pretraining.py:  534]:	loss/total_loss, 5.583120346069336, 147
[INFO] 2021-07-09 16:46:36,422 [run_pretraining.py:  535]:	loss/mlm_loss, 5.583120346069336, 147
[INFO] 2021-07-09 16:46:36,422 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4600000213249587e-06, 147
[INFO] 2021-07-09 16:46:36,422 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 147
[INFO] 2021-07-09 16:46:36,422 [run_pretraining.py:  558]:	worker_index: 5, step: 147, cost: 5.583120, mlm loss: 5.583120, speed: 0.458193 steps/s, speed: 3.665544 samples/s, speed: 1876.758634 tokens/s, learning rate: 1.460e-06, loss_scalings: 16777.216797, pp_loss: 5.597186
[INFO] 2021-07-09 16:46:36,422 [run_pretraining.py:  512]:	********exe.run_147******* 
[INFO] 2021-07-09 16:46:38,651 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:38,651 [run_pretraining.py:  534]:	loss/total_loss, 5.5386762619018555, 148
[INFO] 2021-07-09 16:46:38,651 [run_pretraining.py:  535]:	loss/mlm_loss, 5.5386762619018555, 148
[INFO] 2021-07-09 16:46:38,652 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4700000292577897e-06, 148
[INFO] 2021-07-09 16:46:38,652 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 148
[INFO] 2021-07-09 16:46:38,652 [run_pretraining.py:  558]:	worker_index: 5, step: 148, cost: 5.538676, mlm loss: 5.538676, speed: 0.448591 steps/s, speed: 3.588725 samples/s, speed: 1837.427418 tokens/s, learning rate: 1.470e-06, loss_scalings: 16777.216797, pp_loss: 5.556115
[INFO] 2021-07-09 16:46:38,652 [run_pretraining.py:  512]:	********exe.run_148******* 
[INFO] 2021-07-09 16:46:40,926 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:40,926 [run_pretraining.py:  534]:	loss/total_loss, 5.586348533630371, 149
[INFO] 2021-07-09 16:46:40,926 [run_pretraining.py:  535]:	loss/mlm_loss, 5.586348533630371, 149
[INFO] 2021-07-09 16:46:40,927 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.479999923503783e-06, 149
[INFO] 2021-07-09 16:46:40,927 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 149
[INFO] 2021-07-09 16:46:40,927 [run_pretraining.py:  558]:	worker_index: 5, step: 149, cost: 5.586349, mlm loss: 5.586349, speed: 0.439694 steps/s, speed: 3.517555 samples/s, speed: 1800.987970 tokens/s, learning rate: 1.480e-06, loss_scalings: 16777.216797, pp_loss: 5.441752
[INFO] 2021-07-09 16:46:40,927 [run_pretraining.py:  512]:	********exe.run_149******* 
[INFO] 2021-07-09 16:46:43,172 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:43,173 [run_pretraining.py:  534]:	loss/total_loss, 5.448473930358887, 150
[INFO] 2021-07-09 16:46:43,173 [run_pretraining.py:  535]:	loss/mlm_loss, 5.448473930358887, 150
[INFO] 2021-07-09 16:46:43,173 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4899999314366141e-06, 150
[INFO] 2021-07-09 16:46:43,173 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 150
[INFO] 2021-07-09 16:46:43,173 [run_pretraining.py:  558]:	worker_index: 5, step: 150, cost: 5.448474, mlm loss: 5.448474, speed: 0.445308 steps/s, speed: 3.562466 samples/s, speed: 1823.982558 tokens/s, learning rate: 1.490e-06, loss_scalings: 16777.216797, pp_loss: 5.378383
[INFO] 2021-07-09 16:46:43,173 [run_pretraining.py:  512]:	********exe.run_150******* 
[INFO] 2021-07-09 16:46:45,404 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:45,404 [run_pretraining.py:  534]:	loss/total_loss, 5.323093414306641, 151
[INFO] 2021-07-09 16:46:45,404 [run_pretraining.py:  535]:	loss/mlm_loss, 5.323093414306641, 151
[INFO] 2021-07-09 16:46:45,404 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4999999393694452e-06, 151
[INFO] 2021-07-09 16:46:45,404 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 151
[INFO] 2021-07-09 16:46:45,405 [run_pretraining.py:  558]:	worker_index: 5, step: 151, cost: 5.323093, mlm loss: 5.323093, speed: 0.448270 steps/s, speed: 3.586156 samples/s, speed: 1836.112088 tokens/s, learning rate: 1.500e-06, loss_scalings: 16777.216797, pp_loss: 5.371979
[INFO] 2021-07-09 16:46:45,405 [run_pretraining.py:  512]:	********exe.run_151******* 
[INFO] 2021-07-09 16:46:47,597 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:47,598 [run_pretraining.py:  534]:	loss/total_loss, 5.335549354553223, 152
[INFO] 2021-07-09 16:46:47,598 [run_pretraining.py:  535]:	loss/mlm_loss, 5.335549354553223, 152
[INFO] 2021-07-09 16:46:47,598 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.510000060989114e-06, 152
[INFO] 2021-07-09 16:46:47,598 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 152
[INFO] 2021-07-09 16:46:47,598 [run_pretraining.py:  558]:	worker_index: 5, step: 152, cost: 5.335549, mlm loss: 5.335549, speed: 0.456001 steps/s, speed: 3.648012 samples/s, speed: 1867.781907 tokens/s, learning rate: 1.510e-06, loss_scalings: 16777.216797, pp_loss: 5.336738
[INFO] 2021-07-09 16:46:47,598 [run_pretraining.py:  512]:	********exe.run_152******* 
[INFO] 2021-07-09 16:46:49,797 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:49,797 [run_pretraining.py:  534]:	loss/total_loss, 5.389537334442139, 153
[INFO] 2021-07-09 16:46:49,798 [run_pretraining.py:  535]:	loss/mlm_loss, 5.389537334442139, 153
[INFO] 2021-07-09 16:46:49,798 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5199999552351073e-06, 153
[INFO] 2021-07-09 16:46:49,798 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 153
[INFO] 2021-07-09 16:46:49,798 [run_pretraining.py:  558]:	worker_index: 5, step: 153, cost: 5.389537, mlm loss: 5.389537, speed: 0.454744 steps/s, speed: 3.637950 samples/s, speed: 1862.630213 tokens/s, learning rate: 1.520e-06, loss_scalings: 16777.216797, pp_loss: 5.290884
[INFO] 2021-07-09 16:46:49,798 [run_pretraining.py:  512]:	********exe.run_153******* 
[INFO] 2021-07-09 16:46:52,049 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:52,049 [run_pretraining.py:  534]:	loss/total_loss, 5.178202152252197, 154
[INFO] 2021-07-09 16:46:52,049 [run_pretraining.py:  535]:	loss/mlm_loss, 5.178202152252197, 154
[INFO] 2021-07-09 16:46:52,049 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5299999631679384e-06, 154
[INFO] 2021-07-09 16:46:52,049 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 154
[INFO] 2021-07-09 16:46:52,050 [run_pretraining.py:  558]:	worker_index: 5, step: 154, cost: 5.178202, mlm loss: 5.178202, speed: 0.444259 steps/s, speed: 3.554072 samples/s, speed: 1819.684923 tokens/s, learning rate: 1.530e-06, loss_scalings: 16777.216797, pp_loss: 5.225861
[INFO] 2021-07-09 16:46:52,050 [run_pretraining.py:  512]:	********exe.run_154******* 
[INFO] 2021-07-09 16:46:54,313 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:54,314 [run_pretraining.py:  534]:	loss/total_loss, 5.132744312286377, 155
[INFO] 2021-07-09 16:46:54,314 [run_pretraining.py:  535]:	loss/mlm_loss, 5.132744312286377, 155
[INFO] 2021-07-09 16:46:54,314 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5399999711007695e-06, 155
[INFO] 2021-07-09 16:46:54,314 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 155
[INFO] 2021-07-09 16:46:54,314 [run_pretraining.py:  558]:	worker_index: 5, step: 155, cost: 5.132744, mlm loss: 5.132744, speed: 0.441733 steps/s, speed: 3.533862 samples/s, speed: 1809.337091 tokens/s, learning rate: 1.540e-06, loss_scalings: 16777.216797, pp_loss: 5.262086
[INFO] 2021-07-09 16:46:54,314 [run_pretraining.py:  512]:	********exe.run_155******* 
[INFO] 2021-07-09 16:46:56,504 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:56,505 [run_pretraining.py:  534]:	loss/total_loss, 5.137119770050049, 156
[INFO] 2021-07-09 16:46:56,505 [run_pretraining.py:  535]:	loss/mlm_loss, 5.137119770050049, 156
[INFO] 2021-07-09 16:46:56,505 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5499999790336005e-06, 156
[INFO] 2021-07-09 16:46:56,505 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 156
[INFO] 2021-07-09 16:46:56,505 [run_pretraining.py:  558]:	worker_index: 5, step: 156, cost: 5.137120, mlm loss: 5.137120, speed: 0.456549 steps/s, speed: 3.652391 samples/s, speed: 1870.024389 tokens/s, learning rate: 1.550e-06, loss_scalings: 16777.216797, pp_loss: 5.175196
[INFO] 2021-07-09 16:46:56,505 [run_pretraining.py:  512]:	********exe.run_156******* 
[INFO] 2021-07-09 16:46:58,693 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:46:58,693 [run_pretraining.py:  534]:	loss/total_loss, 5.1022491455078125, 157
[INFO] 2021-07-09 16:46:58,694 [run_pretraining.py:  535]:	loss/mlm_loss, 5.1022491455078125, 157
[INFO] 2021-07-09 16:46:58,694 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5599998732795939e-06, 157
[INFO] 2021-07-09 16:46:58,694 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 157
[INFO] 2021-07-09 16:46:58,694 [run_pretraining.py:  558]:	worker_index: 5, step: 157, cost: 5.102249, mlm loss: 5.102249, speed: 0.457035 steps/s, speed: 3.656282 samples/s, speed: 1872.016226 tokens/s, learning rate: 1.560e-06, loss_scalings: 16777.216797, pp_loss: 5.062772
[INFO] 2021-07-09 16:46:58,694 [run_pretraining.py:  512]:	********exe.run_157******* 
[INFO] 2021-07-09 16:47:00,883 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:00,883 [run_pretraining.py:  534]:	loss/total_loss, 5.039124011993408, 158
[INFO] 2021-07-09 16:47:00,884 [run_pretraining.py:  535]:	loss/mlm_loss, 5.039124011993408, 158
[INFO] 2021-07-09 16:47:00,884 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.569999881212425e-06, 158
[INFO] 2021-07-09 16:47:00,884 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 158
[INFO] 2021-07-09 16:47:00,884 [run_pretraining.py:  558]:	worker_index: 5, step: 158, cost: 5.039124, mlm loss: 5.039124, speed: 0.456795 steps/s, speed: 3.654364 samples/s, speed: 1871.034347 tokens/s, learning rate: 1.570e-06, loss_scalings: 16777.216797, pp_loss: 5.080949
[INFO] 2021-07-09 16:47:00,884 [run_pretraining.py:  512]:	********exe.run_158******* 
[INFO] 2021-07-09 16:47:03,101 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:03,102 [run_pretraining.py:  534]:	loss/total_loss, 4.941206932067871, 159
[INFO] 2021-07-09 16:47:03,102 [run_pretraining.py:  535]:	loss/mlm_loss, 4.941206932067871, 159
[INFO] 2021-07-09 16:47:03,102 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.579999889145256e-06, 159
[INFO] 2021-07-09 16:47:03,102 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 159
[INFO] 2021-07-09 16:47:03,102 [run_pretraining.py:  558]:	worker_index: 5, step: 159, cost: 4.941207, mlm loss: 4.941207, speed: 0.450884 steps/s, speed: 3.607074 samples/s, speed: 1846.821758 tokens/s, learning rate: 1.580e-06, loss_scalings: 16777.216797, pp_loss: 4.992846
[INFO] 2021-07-09 16:47:03,102 [run_pretraining.py:  512]:	********exe.run_159******* 
[INFO] 2021-07-09 16:47:05,329 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:05,329 [run_pretraining.py:  534]:	loss/total_loss, 4.955050468444824, 160
[INFO] 2021-07-09 16:47:05,329 [run_pretraining.py:  535]:	loss/mlm_loss, 4.955050468444824, 160
[INFO] 2021-07-09 16:47:05,329 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5900000107649248e-06, 160
[INFO] 2021-07-09 16:47:05,329 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 160
[INFO] 2021-07-09 16:47:05,330 [run_pretraining.py:  558]:	worker_index: 5, step: 160, cost: 4.955050, mlm loss: 4.955050, speed: 0.449117 steps/s, speed: 3.592939 samples/s, speed: 1839.584956 tokens/s, learning rate: 1.590e-06, loss_scalings: 16777.216797, pp_loss: 5.076604
[INFO] 2021-07-09 16:47:05,330 [run_pretraining.py:  512]:	********exe.run_160******* 
[INFO] 2021-07-09 16:47:07,612 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:07,612 [run_pretraining.py:  534]:	loss/total_loss, 4.989084720611572, 161
[INFO] 2021-07-09 16:47:07,612 [run_pretraining.py:  535]:	loss/mlm_loss, 4.989084720611572, 161
[INFO] 2021-07-09 16:47:07,612 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6000000186977559e-06, 161
[INFO] 2021-07-09 16:47:07,612 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 161
[INFO] 2021-07-09 16:47:07,613 [run_pretraining.py:  558]:	worker_index: 5, step: 161, cost: 4.989085, mlm loss: 4.989085, speed: 0.438157 steps/s, speed: 3.505255 samples/s, speed: 1794.690557 tokens/s, learning rate: 1.600e-06, loss_scalings: 16777.216797, pp_loss: 4.941580
[INFO] 2021-07-09 16:47:07,613 [run_pretraining.py:  512]:	********exe.run_161******* 
[INFO] 2021-07-09 16:47:09,827 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:09,828 [run_pretraining.py:  534]:	loss/total_loss, 4.883095741271973, 162
[INFO] 2021-07-09 16:47:09,828 [run_pretraining.py:  535]:	loss/mlm_loss, 4.883095741271973, 162
[INFO] 2021-07-09 16:47:09,828 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.610000026630587e-06, 162
[INFO] 2021-07-09 16:47:09,828 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 162
[INFO] 2021-07-09 16:47:09,828 [run_pretraining.py:  558]:	worker_index: 5, step: 162, cost: 4.883096, mlm loss: 4.883096, speed: 0.451491 steps/s, speed: 3.611927 samples/s, speed: 1849.306546 tokens/s, learning rate: 1.610e-06, loss_scalings: 16777.216797, pp_loss: 4.879049
[INFO] 2021-07-09 16:47:09,828 [run_pretraining.py:  512]:	********exe.run_162******* 
[INFO] 2021-07-09 16:47:12,114 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:12,115 [run_pretraining.py:  534]:	loss/total_loss, 4.834112167358398, 163
[INFO] 2021-07-09 16:47:12,115 [run_pretraining.py:  535]:	loss/mlm_loss, 4.834112167358398, 163
[INFO] 2021-07-09 16:47:12,115 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.620000034563418e-06, 163
[INFO] 2021-07-09 16:47:12,115 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 163
[INFO] 2021-07-09 16:47:12,115 [run_pretraining.py:  558]:	worker_index: 5, step: 163, cost: 4.834112, mlm loss: 4.834112, speed: 0.437348 steps/s, speed: 3.498781 samples/s, speed: 1791.375637 tokens/s, learning rate: 1.620e-06, loss_scalings: 16777.216797, pp_loss: 4.831072
[INFO] 2021-07-09 16:47:12,115 [run_pretraining.py:  512]:	********exe.run_163******* 
[INFO] 2021-07-09 16:47:14,679 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:14,680 [run_pretraining.py:  534]:	loss/total_loss, 5.068953037261963, 164
[INFO] 2021-07-09 16:47:14,680 [run_pretraining.py:  535]:	loss/mlm_loss, 5.068953037261963, 164
[INFO] 2021-07-09 16:47:14,680 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6299999288094114e-06, 164
[INFO] 2021-07-09 16:47:14,680 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 164
[INFO] 2021-07-09 16:47:14,680 [run_pretraining.py:  558]:	worker_index: 5, step: 164, cost: 5.068953, mlm loss: 5.068953, speed: 0.389994 steps/s, speed: 3.119955 samples/s, speed: 1597.417073 tokens/s, learning rate: 1.630e-06, loss_scalings: 16777.216797, pp_loss: 4.795722
[INFO] 2021-07-09 16:47:14,680 [run_pretraining.py:  512]:	********exe.run_164******* 
[INFO] 2021-07-09 16:47:17,088 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:17,089 [run_pretraining.py:  534]:	loss/total_loss, 4.669105052947998, 165
[INFO] 2021-07-09 16:47:17,089 [run_pretraining.py:  535]:	loss/mlm_loss, 4.669105052947998, 165
[INFO] 2021-07-09 16:47:17,089 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6399999367422424e-06, 165
[INFO] 2021-07-09 16:47:17,089 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 165
[INFO] 2021-07-09 16:47:17,089 [run_pretraining.py:  558]:	worker_index: 5, step: 165, cost: 4.669105, mlm loss: 4.669105, speed: 0.415239 steps/s, speed: 3.321913 samples/s, speed: 1700.819526 tokens/s, learning rate: 1.640e-06, loss_scalings: 16777.216797, pp_loss: 4.727179
[INFO] 2021-07-09 16:47:17,089 [run_pretraining.py:  512]:	********exe.run_165******* 
[INFO] 2021-07-09 16:47:19,374 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:19,375 [run_pretraining.py:  534]:	loss/total_loss, 4.634751796722412, 166
[INFO] 2021-07-09 16:47:19,375 [run_pretraining.py:  535]:	loss/mlm_loss, 4.634751796722412, 166
[INFO] 2021-07-09 16:47:19,375 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6499999446750735e-06, 166
[INFO] 2021-07-09 16:47:19,375 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 166
[INFO] 2021-07-09 16:47:19,375 [run_pretraining.py:  558]:	worker_index: 5, step: 166, cost: 4.634752, mlm loss: 4.634752, speed: 0.437533 steps/s, speed: 3.500266 samples/s, speed: 1792.136382 tokens/s, learning rate: 1.650e-06, loss_scalings: 16777.216797, pp_loss: 4.700256
[INFO] 2021-07-09 16:47:19,376 [run_pretraining.py:  512]:	********exe.run_166******* 
[INFO] 2021-07-09 16:47:21,629 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:21,630 [run_pretraining.py:  534]:	loss/total_loss, 4.78892707824707, 167
[INFO] 2021-07-09 16:47:21,630 [run_pretraining.py:  535]:	loss/mlm_loss, 4.78892707824707, 167
[INFO] 2021-07-09 16:47:21,630 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6599999526079046e-06, 167
[INFO] 2021-07-09 16:47:21,630 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 167
[INFO] 2021-07-09 16:47:21,630 [run_pretraining.py:  558]:	worker_index: 5, step: 167, cost: 4.788927, mlm loss: 4.788927, speed: 0.443694 steps/s, speed: 3.549555 samples/s, speed: 1817.372284 tokens/s, learning rate: 1.660e-06, loss_scalings: 16777.216797, pp_loss: 4.670580
[INFO] 2021-07-09 16:47:21,630 [run_pretraining.py:  512]:	********exe.run_167******* 
[INFO] 2021-07-09 16:47:23,811 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:23,812 [run_pretraining.py:  534]:	loss/total_loss, 4.642389297485352, 168
[INFO] 2021-07-09 16:47:23,812 [run_pretraining.py:  535]:	loss/mlm_loss, 4.642389297485352, 168
[INFO] 2021-07-09 16:47:23,812 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6699999605407356e-06, 168
[INFO] 2021-07-09 16:47:23,812 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 168
[INFO] 2021-07-09 16:47:23,812 [run_pretraining.py:  558]:	worker_index: 5, step: 168, cost: 4.642389, mlm loss: 4.642389, speed: 0.458426 steps/s, speed: 3.667408 samples/s, speed: 1877.713079 tokens/s, learning rate: 1.670e-06, loss_scalings: 16777.216797, pp_loss: 4.627021
[INFO] 2021-07-09 16:47:23,812 [run_pretraining.py:  512]:	********exe.run_168******* 
[INFO] 2021-07-09 16:47:26,037 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:26,037 [run_pretraining.py:  534]:	loss/total_loss, 4.575925350189209, 169
[INFO] 2021-07-09 16:47:26,037 [run_pretraining.py:  535]:	loss/mlm_loss, 4.575925350189209, 169
[INFO] 2021-07-09 16:47:26,037 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.679999854786729e-06, 169
[INFO] 2021-07-09 16:47:26,038 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 169
[INFO] 2021-07-09 16:47:26,038 [run_pretraining.py:  558]:	worker_index: 5, step: 169, cost: 4.575925, mlm loss: 4.575925, speed: 0.449466 steps/s, speed: 3.595729 samples/s, speed: 1841.013373 tokens/s, learning rate: 1.680e-06, loss_scalings: 16777.216797, pp_loss: 4.545433
[INFO] 2021-07-09 16:47:26,038 [run_pretraining.py:  512]:	********exe.run_169******* 
[INFO] 2021-07-09 16:47:28,220 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:28,221 [run_pretraining.py:  534]:	loss/total_loss, 4.605134963989258, 170
[INFO] 2021-07-09 16:47:28,221 [run_pretraining.py:  535]:	loss/mlm_loss, 4.605134963989258, 170
[INFO] 2021-07-09 16:47:28,221 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.68999986271956e-06, 170
[INFO] 2021-07-09 16:47:28,221 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 170
[INFO] 2021-07-09 16:47:28,221 [run_pretraining.py:  558]:	worker_index: 5, step: 170, cost: 4.605135, mlm loss: 4.605135, speed: 0.458077 steps/s, speed: 3.664614 samples/s, speed: 1876.282288 tokens/s, learning rate: 1.690e-06, loss_scalings: 16777.216797, pp_loss: 4.626058
[INFO] 2021-07-09 16:47:28,221 [run_pretraining.py:  512]:	********exe.run_170******* 
[INFO] 2021-07-09 16:47:30,427 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:30,428 [run_pretraining.py:  534]:	loss/total_loss, 4.448848724365234, 171
[INFO] 2021-07-09 16:47:30,428 [run_pretraining.py:  535]:	loss/mlm_loss, 4.448848724365234, 171
[INFO] 2021-07-09 16:47:30,428 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7000000980260666e-06, 171
[INFO] 2021-07-09 16:47:30,428 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 171
[INFO] 2021-07-09 16:47:30,428 [run_pretraining.py:  558]:	worker_index: 5, step: 171, cost: 4.448849, mlm loss: 4.448849, speed: 0.453299 steps/s, speed: 3.626390 samples/s, speed: 1856.711489 tokens/s, learning rate: 1.700e-06, loss_scalings: 16777.216797, pp_loss: 4.470994
[INFO] 2021-07-09 16:47:30,428 [run_pretraining.py:  512]:	********exe.run_171******* 
[INFO] 2021-07-09 16:47:32,601 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:32,602 [run_pretraining.py:  534]:	loss/total_loss, 4.365164279937744, 172
[INFO] 2021-07-09 16:47:32,602 [run_pretraining.py:  535]:	loss/mlm_loss, 4.365164279937744, 172
[INFO] 2021-07-09 16:47:32,602 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.70999999227206e-06, 172
[INFO] 2021-07-09 16:47:32,602 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 172
[INFO] 2021-07-09 16:47:32,602 [run_pretraining.py:  558]:	worker_index: 5, step: 172, cost: 4.365164, mlm loss: 4.365164, speed: 0.460085 steps/s, speed: 3.680678 samples/s, speed: 1884.507256 tokens/s, learning rate: 1.710e-06, loss_scalings: 16777.216797, pp_loss: 4.472305
[INFO] 2021-07-09 16:47:32,602 [run_pretraining.py:  512]:	********exe.run_172******* 
[INFO] 2021-07-09 16:47:34,804 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:34,805 [run_pretraining.py:  534]:	loss/total_loss, 4.336119651794434, 173
[INFO] 2021-07-09 16:47:34,805 [run_pretraining.py:  535]:	loss/mlm_loss, 4.336119651794434, 173
[INFO] 2021-07-09 16:47:34,805 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.720000000204891e-06, 173
[INFO] 2021-07-09 16:47:34,805 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 173
[INFO] 2021-07-09 16:47:34,805 [run_pretraining.py:  558]:	worker_index: 5, step: 173, cost: 4.336120, mlm loss: 4.336120, speed: 0.454064 steps/s, speed: 3.632513 samples/s, speed: 1859.846728 tokens/s, learning rate: 1.720e-06, loss_scalings: 16777.216797, pp_loss: 4.392291
[INFO] 2021-07-09 16:47:34,805 [run_pretraining.py:  512]:	********exe.run_173******* 
[INFO] 2021-07-09 16:47:37,080 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:37,081 [run_pretraining.py:  534]:	loss/total_loss, 4.3049211502075195, 174
[INFO] 2021-07-09 16:47:37,081 [run_pretraining.py:  535]:	loss/mlm_loss, 4.3049211502075195, 174
[INFO] 2021-07-09 16:47:37,081 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.730000008137722e-06, 174
[INFO] 2021-07-09 16:47:37,081 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 174
[INFO] 2021-07-09 16:47:37,081 [run_pretraining.py:  558]:	worker_index: 5, step: 174, cost: 4.304921, mlm loss: 4.304921, speed: 0.439485 steps/s, speed: 3.515878 samples/s, speed: 1800.129529 tokens/s, learning rate: 1.730e-06, loss_scalings: 16777.216797, pp_loss: 4.330824
[INFO] 2021-07-09 16:47:37,081 [run_pretraining.py:  512]:	********exe.run_174******* 
[INFO] 2021-07-09 16:47:39,271 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:39,272 [run_pretraining.py:  534]:	loss/total_loss, 4.287498474121094, 175
[INFO] 2021-07-09 16:47:39,272 [run_pretraining.py:  535]:	loss/mlm_loss, 4.287498474121094, 175
[INFO] 2021-07-09 16:47:39,272 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.740000016070553e-06, 175
[INFO] 2021-07-09 16:47:39,272 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 175
[INFO] 2021-07-09 16:47:39,272 [run_pretraining.py:  558]:	worker_index: 5, step: 175, cost: 4.287498, mlm loss: 4.287498, speed: 0.456629 steps/s, speed: 3.653033 samples/s, speed: 1870.352979 tokens/s, learning rate: 1.740e-06, loss_scalings: 16777.216797, pp_loss: 4.300521
[INFO] 2021-07-09 16:47:39,272 [run_pretraining.py:  512]:	********exe.run_175******* 
[INFO] 2021-07-09 16:47:41,612 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:41,613 [run_pretraining.py:  534]:	loss/total_loss, 4.257082462310791, 176
[INFO] 2021-07-09 16:47:41,613 [run_pretraining.py:  535]:	loss/mlm_loss, 4.257082462310791, 176
[INFO] 2021-07-09 16:47:41,613 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7499999103165464e-06, 176
[INFO] 2021-07-09 16:47:41,613 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 176
[INFO] 2021-07-09 16:47:41,613 [run_pretraining.py:  558]:	worker_index: 5, step: 176, cost: 4.257082, mlm loss: 4.257082, speed: 0.427262 steps/s, speed: 3.418096 samples/s, speed: 1750.065086 tokens/s, learning rate: 1.750e-06, loss_scalings: 16777.216797, pp_loss: 4.372022
[INFO] 2021-07-09 16:47:41,613 [run_pretraining.py:  512]:	********exe.run_176******* 
[INFO] 2021-07-09 16:47:43,824 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:43,825 [run_pretraining.py:  534]:	loss/total_loss, 4.190183639526367, 177
[INFO] 2021-07-09 16:47:43,825 [run_pretraining.py:  535]:	loss/mlm_loss, 4.190183639526367, 177
[INFO] 2021-07-09 16:47:43,825 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7599999182493775e-06, 177
[INFO] 2021-07-09 16:47:43,825 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 177
[INFO] 2021-07-09 16:47:43,825 [run_pretraining.py:  558]:	worker_index: 5, step: 177, cost: 4.190184, mlm loss: 4.190184, speed: 0.452207 steps/s, speed: 3.617654 samples/s, speed: 1852.239058 tokens/s, learning rate: 1.760e-06, loss_scalings: 16777.216797, pp_loss: 4.248724
[INFO] 2021-07-09 16:47:43,825 [run_pretraining.py:  512]:	********exe.run_177******* 
[INFO] 2021-07-09 16:47:46,076 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:46,076 [run_pretraining.py:  534]:	loss/total_loss, 4.164962291717529, 178
[INFO] 2021-07-09 16:47:46,077 [run_pretraining.py:  535]:	loss/mlm_loss, 4.164962291717529, 178
[INFO] 2021-07-09 16:47:46,077 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7699999261822086e-06, 178
[INFO] 2021-07-09 16:47:46,077 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 178
[INFO] 2021-07-09 16:47:46,077 [run_pretraining.py:  558]:	worker_index: 5, step: 178, cost: 4.164962, mlm loss: 4.164962, speed: 0.444269 steps/s, speed: 3.554149 samples/s, speed: 1819.724051 tokens/s, learning rate: 1.770e-06, loss_scalings: 13421.773438, pp_loss: 4.193645
[INFO] 2021-07-09 16:47:46,077 [run_pretraining.py:  512]:	********exe.run_178******* 
[INFO] 2021-07-09 16:47:48,304 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:48,305 [run_pretraining.py:  534]:	loss/total_loss, 4.304374694824219, 179
[INFO] 2021-07-09 16:47:48,305 [run_pretraining.py:  535]:	loss/mlm_loss, 4.304374694824219, 179
[INFO] 2021-07-09 16:47:48,305 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7799999341150397e-06, 179
[INFO] 2021-07-09 16:47:48,305 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 179
[INFO] 2021-07-09 16:47:48,305 [run_pretraining.py:  558]:	worker_index: 5, step: 179, cost: 4.304375, mlm loss: 4.304375, speed: 0.448883 steps/s, speed: 3.591067 samples/s, speed: 1838.626168 tokens/s, learning rate: 1.780e-06, loss_scalings: 13421.773438, pp_loss: 4.219705
[INFO] 2021-07-09 16:47:48,305 [run_pretraining.py:  512]:	********exe.run_179******* 
[INFO] 2021-07-09 16:47:50,504 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:50,504 [run_pretraining.py:  534]:	loss/total_loss, 4.368378162384033, 180
[INFO] 2021-07-09 16:47:50,504 [run_pretraining.py:  535]:	loss/mlm_loss, 4.368378162384033, 180
[INFO] 2021-07-09 16:47:50,504 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7899999420478707e-06, 180
[INFO] 2021-07-09 16:47:50,505 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 180
[INFO] 2021-07-09 16:47:50,505 [run_pretraining.py:  558]:	worker_index: 5, step: 180, cost: 4.368378, mlm loss: 4.368378, speed: 0.454808 steps/s, speed: 3.638464 samples/s, speed: 1862.893788 tokens/s, learning rate: 1.790e-06, loss_scalings: 13421.773438, pp_loss: 4.178219
[INFO] 2021-07-09 16:47:50,505 [run_pretraining.py:  512]:	********exe.run_180******* 
[INFO] 2021-07-09 16:47:52,709 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:52,709 [run_pretraining.py:  534]:	loss/total_loss, 4.0566511154174805, 181
[INFO] 2021-07-09 16:47:52,709 [run_pretraining.py:  535]:	loss/mlm_loss, 4.0566511154174805, 181
[INFO] 2021-07-09 16:47:52,710 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.799999836293864e-06, 181
[INFO] 2021-07-09 16:47:52,710 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 181
[INFO] 2021-07-09 16:47:52,710 [run_pretraining.py:  558]:	worker_index: 5, step: 181, cost: 4.056651, mlm loss: 4.056651, speed: 0.453654 steps/s, speed: 3.629236 samples/s, speed: 1858.168648 tokens/s, learning rate: 1.800e-06, loss_scalings: 13421.773438, pp_loss: 4.093033
[INFO] 2021-07-09 16:47:52,710 [run_pretraining.py:  512]:	********exe.run_181******* 
[INFO] 2021-07-09 16:47:54,967 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:54,968 [run_pretraining.py:  534]:	loss/total_loss, 4.118881702423096, 182
[INFO] 2021-07-09 16:47:54,968 [run_pretraining.py:  535]:	loss/mlm_loss, 4.118881702423096, 182
[INFO] 2021-07-09 16:47:54,968 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8100000716003706e-06, 182
[INFO] 2021-07-09 16:47:54,968 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 182
[INFO] 2021-07-09 16:47:54,968 [run_pretraining.py:  558]:	worker_index: 5, step: 182, cost: 4.118882, mlm loss: 4.118882, speed: 0.442861 steps/s, speed: 3.542885 samples/s, speed: 1813.957228 tokens/s, learning rate: 1.810e-06, loss_scalings: 13421.773438, pp_loss: 4.122488
[INFO] 2021-07-09 16:47:54,969 [run_pretraining.py:  512]:	********exe.run_182******* 
[INFO] 2021-07-09 16:47:57,191 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:57,191 [run_pretraining.py:  534]:	loss/total_loss, 4.04161262512207, 183
[INFO] 2021-07-09 16:47:57,192 [run_pretraining.py:  535]:	loss/mlm_loss, 4.04161262512207, 183
[INFO] 2021-07-09 16:47:57,192 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8200000795332016e-06, 183
[INFO] 2021-07-09 16:47:57,192 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 183
[INFO] 2021-07-09 16:47:57,192 [run_pretraining.py:  558]:	worker_index: 5, step: 183, cost: 4.041613, mlm loss: 4.041613, speed: 0.449914 steps/s, speed: 3.599314 samples/s, speed: 1842.848966 tokens/s, learning rate: 1.820e-06, loss_scalings: 13421.773438, pp_loss: 4.044122
[INFO] 2021-07-09 16:47:57,192 [run_pretraining.py:  512]:	********exe.run_183******* 
[INFO] 2021-07-09 16:47:59,431 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:47:59,432 [run_pretraining.py:  534]:	loss/total_loss, 3.9874415397644043, 184
[INFO] 2021-07-09 16:47:59,432 [run_pretraining.py:  535]:	loss/mlm_loss, 3.9874415397644043, 184
[INFO] 2021-07-09 16:47:59,432 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.829999973779195e-06, 184
[INFO] 2021-07-09 16:47:59,432 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 184
[INFO] 2021-07-09 16:47:59,432 [run_pretraining.py:  558]:	worker_index: 5, step: 184, cost: 3.987442, mlm loss: 3.987442, speed: 0.446548 steps/s, speed: 3.572388 samples/s, speed: 1829.062598 tokens/s, learning rate: 1.830e-06, loss_scalings: 13421.773438, pp_loss: 4.007786
[INFO] 2021-07-09 16:47:59,432 [run_pretraining.py:  512]:	********exe.run_184******* 
[INFO] 2021-07-09 16:48:01,639 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:01,639 [run_pretraining.py:  534]:	loss/total_loss, 4.018911361694336, 185
[INFO] 2021-07-09 16:48:01,640 [run_pretraining.py:  535]:	loss/mlm_loss, 4.018911361694336, 185
[INFO] 2021-07-09 16:48:01,640 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.839999981712026e-06, 185
[INFO] 2021-07-09 16:48:01,640 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 185
[INFO] 2021-07-09 16:48:01,640 [run_pretraining.py:  558]:	worker_index: 5, step: 185, cost: 4.018911, mlm loss: 4.018911, speed: 0.453076 steps/s, speed: 3.624609 samples/s, speed: 1855.799919 tokens/s, learning rate: 1.840e-06, loss_scalings: 13421.773438, pp_loss: 3.977469
[INFO] 2021-07-09 16:48:01,640 [run_pretraining.py:  512]:	********exe.run_185******* 
[INFO] 2021-07-09 16:48:03,847 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:03,848 [run_pretraining.py:  534]:	loss/total_loss, 3.9901390075683594, 186
[INFO] 2021-07-09 16:48:03,848 [run_pretraining.py:  535]:	loss/mlm_loss, 3.9901390075683594, 186
[INFO] 2021-07-09 16:48:03,848 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8499999896448571e-06, 186
[INFO] 2021-07-09 16:48:03,848 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 186
[INFO] 2021-07-09 16:48:03,848 [run_pretraining.py:  558]:	worker_index: 5, step: 186, cost: 3.990139, mlm loss: 3.990139, speed: 0.452975 steps/s, speed: 3.623804 samples/s, speed: 1855.387451 tokens/s, learning rate: 1.850e-06, loss_scalings: 13421.773438, pp_loss: 3.935270
[INFO] 2021-07-09 16:48:03,848 [run_pretraining.py:  512]:	********exe.run_186******* 
[INFO] 2021-07-09 16:48:06,088 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:06,088 [run_pretraining.py:  534]:	loss/total_loss, 4.289435386657715, 187
[INFO] 2021-07-09 16:48:06,088 [run_pretraining.py:  535]:	loss/mlm_loss, 4.289435386657715, 187
[INFO] 2021-07-09 16:48:06,088 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8599999975776882e-06, 187
[INFO] 2021-07-09 16:48:06,089 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 187
[INFO] 2021-07-09 16:48:06,089 [run_pretraining.py:  558]:	worker_index: 5, step: 187, cost: 4.289435, mlm loss: 4.289435, speed: 0.446498 steps/s, speed: 3.571982 samples/s, speed: 1828.854842 tokens/s, learning rate: 1.860e-06, loss_scalings: 13421.773438, pp_loss: 3.985477
[INFO] 2021-07-09 16:48:06,089 [run_pretraining.py:  512]:	********exe.run_187******* 
[INFO] 2021-07-09 16:48:08,289 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:08,290 [run_pretraining.py:  534]:	loss/total_loss, 3.841359853744507, 188
[INFO] 2021-07-09 16:48:08,290 [run_pretraining.py:  535]:	loss/mlm_loss, 3.841359853744507, 188
[INFO] 2021-07-09 16:48:08,290 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8699998918236815e-06, 188
[INFO] 2021-07-09 16:48:08,290 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 188
[INFO] 2021-07-09 16:48:08,290 [run_pretraining.py:  558]:	worker_index: 5, step: 188, cost: 3.841360, mlm loss: 3.841360, speed: 0.454344 steps/s, speed: 3.634755 samples/s, speed: 1860.994683 tokens/s, learning rate: 1.870e-06, loss_scalings: 13421.773438, pp_loss: 3.922866
[INFO] 2021-07-09 16:48:08,290 [run_pretraining.py:  512]:	********exe.run_188******* 
[INFO] 2021-07-09 16:48:10,529 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:10,529 [run_pretraining.py:  534]:	loss/total_loss, 3.8034887313842773, 189
[INFO] 2021-07-09 16:48:10,530 [run_pretraining.py:  535]:	loss/mlm_loss, 3.8034887313842773, 189
[INFO] 2021-07-09 16:48:10,530 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8799998997565126e-06, 189
[INFO] 2021-07-09 16:48:10,530 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 189
[INFO] 2021-07-09 16:48:10,530 [run_pretraining.py:  558]:	worker_index: 5, step: 189, cost: 3.803489, mlm loss: 3.803489, speed: 0.446666 steps/s, speed: 3.573328 samples/s, speed: 1829.543907 tokens/s, learning rate: 1.880e-06, loss_scalings: 13421.773438, pp_loss: 3.833671
[INFO] 2021-07-09 16:48:10,530 [run_pretraining.py:  512]:	********exe.run_189******* 
[INFO] 2021-07-09 16:48:12,844 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:12,845 [run_pretraining.py:  534]:	loss/total_loss, 3.8100132942199707, 190
[INFO] 2021-07-09 16:48:12,845 [run_pretraining.py:  535]:	loss/mlm_loss, 3.8100132942199707, 190
[INFO] 2021-07-09 16:48:12,845 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8899999076893437e-06, 190
[INFO] 2021-07-09 16:48:12,845 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 190
[INFO] 2021-07-09 16:48:12,845 [run_pretraining.py:  558]:	worker_index: 5, step: 190, cost: 3.810013, mlm loss: 3.810013, speed: 0.431996 steps/s, speed: 3.455969 samples/s, speed: 1769.456333 tokens/s, learning rate: 1.890e-06, loss_scalings: 13421.773438, pp_loss: 3.787397
[INFO] 2021-07-09 16:48:12,845 [run_pretraining.py:  512]:	********exe.run_190******* 
[INFO] 2021-07-09 16:48:15,113 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:15,113 [run_pretraining.py:  534]:	loss/total_loss, 3.836151599884033, 191
[INFO] 2021-07-09 16:48:15,114 [run_pretraining.py:  535]:	loss/mlm_loss, 3.836151599884033, 191
[INFO] 2021-07-09 16:48:15,114 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8999999156221747e-06, 191
[INFO] 2021-07-09 16:48:15,114 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 191
[INFO] 2021-07-09 16:48:15,114 [run_pretraining.py:  558]:	worker_index: 5, step: 191, cost: 3.836152, mlm loss: 3.836152, speed: 0.440953 steps/s, speed: 3.527626 samples/s, speed: 1806.144469 tokens/s, learning rate: 1.900e-06, loss_scalings: 13421.773438, pp_loss: 3.838281
[INFO] 2021-07-09 16:48:15,114 [run_pretraining.py:  512]:	********exe.run_191******* 
[INFO] 2021-07-09 16:48:17,310 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:17,311 [run_pretraining.py:  534]:	loss/total_loss, 3.751889705657959, 192
[INFO] 2021-07-09 16:48:17,311 [run_pretraining.py:  535]:	loss/mlm_loss, 3.751889705657959, 192
[INFO] 2021-07-09 16:48:17,311 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.909999809868168e-06, 192
[INFO] 2021-07-09 16:48:17,311 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 192
[INFO] 2021-07-09 16:48:17,311 [run_pretraining.py:  558]:	worker_index: 5, step: 192, cost: 3.751890, mlm loss: 3.751890, speed: 0.455296 steps/s, speed: 3.642367 samples/s, speed: 1864.891914 tokens/s, learning rate: 1.910e-06, loss_scalings: 13421.773438, pp_loss: 3.807921
[INFO] 2021-07-09 16:48:17,311 [run_pretraining.py:  512]:	********exe.run_192******* 
[INFO] 2021-07-09 16:48:19,601 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:19,601 [run_pretraining.py:  534]:	loss/total_loss, 3.7057225704193115, 193
[INFO] 2021-07-09 16:48:19,601 [run_pretraining.py:  535]:	loss/mlm_loss, 3.7057225704193115, 193
[INFO] 2021-07-09 16:48:19,601 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.919999931487837e-06, 193
[INFO] 2021-07-09 16:48:19,601 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 193
[INFO] 2021-07-09 16:48:19,602 [run_pretraining.py:  558]:	worker_index: 5, step: 193, cost: 3.705723, mlm loss: 3.705723, speed: 0.436705 steps/s, speed: 3.493638 samples/s, speed: 1788.742600 tokens/s, learning rate: 1.920e-06, loss_scalings: 13421.773438, pp_loss: 3.720333
[INFO] 2021-07-09 16:48:19,602 [run_pretraining.py:  512]:	********exe.run_193******* 
[INFO] 2021-07-09 16:48:21,825 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:21,825 [run_pretraining.py:  534]:	loss/total_loss, 3.670530319213867, 194
[INFO] 2021-07-09 16:48:21,825 [run_pretraining.py:  535]:	loss/mlm_loss, 3.670530319213867, 194
[INFO] 2021-07-09 16:48:21,826 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9300000531075057e-06, 194
[INFO] 2021-07-09 16:48:21,826 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 194
[INFO] 2021-07-09 16:48:21,826 [run_pretraining.py:  558]:	worker_index: 5, step: 194, cost: 3.670530, mlm loss: 3.670530, speed: 0.449760 steps/s, speed: 3.598080 samples/s, speed: 1842.216809 tokens/s, learning rate: 1.930e-06, loss_scalings: 13421.773438, pp_loss: 3.700810
[INFO] 2021-07-09 16:48:21,826 [run_pretraining.py:  512]:	********exe.run_194******* 
[INFO] 2021-07-09 16:48:24,145 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:24,145 [run_pretraining.py:  534]:	loss/total_loss, 3.61214017868042, 195
[INFO] 2021-07-09 16:48:24,146 [run_pretraining.py:  535]:	loss/mlm_loss, 3.61214017868042, 195
[INFO] 2021-07-09 16:48:24,146 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.939999947353499e-06, 195
[INFO] 2021-07-09 16:48:24,146 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 195
[INFO] 2021-07-09 16:48:24,146 [run_pretraining.py:  558]:	worker_index: 5, step: 195, cost: 3.612140, mlm loss: 3.612140, speed: 0.431151 steps/s, speed: 3.449204 samples/s, speed: 1765.992602 tokens/s, learning rate: 1.940e-06, loss_scalings: 13421.773438, pp_loss: 3.673157
[INFO] 2021-07-09 16:48:24,146 [run_pretraining.py:  512]:	********exe.run_195******* 
[INFO] 2021-07-09 16:48:26,403 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:26,404 [run_pretraining.py:  534]:	loss/total_loss, 3.582676887512207, 196
[INFO] 2021-07-09 16:48:26,404 [run_pretraining.py:  535]:	loss/mlm_loss, 3.582676887512207, 196
[INFO] 2021-07-09 16:48:26,404 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.950000068973168e-06, 196
[INFO] 2021-07-09 16:48:26,404 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 196
[INFO] 2021-07-09 16:48:26,404 [run_pretraining.py:  558]:	worker_index: 5, step: 196, cost: 3.582677, mlm loss: 3.582677, speed: 0.442884 steps/s, speed: 3.543074 samples/s, speed: 1814.053955 tokens/s, learning rate: 1.950e-06, loss_scalings: 13421.773438, pp_loss: 3.655834
[INFO] 2021-07-09 16:48:26,404 [run_pretraining.py:  512]:	********exe.run_196******* 
[INFO] 2021-07-09 16:48:28,642 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:28,643 [run_pretraining.py:  534]:	loss/total_loss, 3.554460048675537, 197
[INFO] 2021-07-09 16:48:28,643 [run_pretraining.py:  535]:	loss/mlm_loss, 3.554460048675537, 197
[INFO] 2021-07-09 16:48:28,643 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.959999963219161e-06, 197
[INFO] 2021-07-09 16:48:28,643 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 197
[INFO] 2021-07-09 16:48:28,643 [run_pretraining.py:  558]:	worker_index: 5, step: 197, cost: 3.554460, mlm loss: 3.554460, speed: 0.446849 steps/s, speed: 3.574794 samples/s, speed: 1830.294327 tokens/s, learning rate: 1.960e-06, loss_scalings: 13421.773438, pp_loss: 3.615049
[INFO] 2021-07-09 16:48:28,643 [run_pretraining.py:  512]:	********exe.run_197******* 
[INFO] 2021-07-09 16:48:30,890 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:30,890 [run_pretraining.py:  534]:	loss/total_loss, 3.8020095825195312, 198
[INFO] 2021-07-09 16:48:30,890 [run_pretraining.py:  535]:	loss/mlm_loss, 3.8020095825195312, 198
[INFO] 2021-07-09 16:48:30,891 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9699998574651545e-06, 198
[INFO] 2021-07-09 16:48:30,891 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 198
[INFO] 2021-07-09 16:48:30,891 [run_pretraining.py:  558]:	worker_index: 5, step: 198, cost: 3.802010, mlm loss: 3.802010, speed: 0.445045 steps/s, speed: 3.560358 samples/s, speed: 1822.903394 tokens/s, learning rate: 1.970e-06, loss_scalings: 13421.773438, pp_loss: 3.620347
[INFO] 2021-07-09 16:48:30,891 [run_pretraining.py:  512]:	********exe.run_198******* 
[INFO] 2021-07-09 16:48:33,114 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:33,115 [run_pretraining.py:  534]:	loss/total_loss, 3.5344152450561523, 199
[INFO] 2021-07-09 16:48:33,115 [run_pretraining.py:  535]:	loss/mlm_loss, 3.5344152450561523, 199
[INFO] 2021-07-09 16:48:33,115 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9799999790848233e-06, 199
[INFO] 2021-07-09 16:48:33,115 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 199
[INFO] 2021-07-09 16:48:33,115 [run_pretraining.py:  558]:	worker_index: 5, step: 199, cost: 3.534415, mlm loss: 3.534415, speed: 0.449742 steps/s, speed: 3.597935 samples/s, speed: 1842.142733 tokens/s, learning rate: 1.980e-06, loss_scalings: 13421.773438, pp_loss: 3.624957
[INFO] 2021-07-09 16:48:33,115 [run_pretraining.py:  512]:	********exe.run_199******* 
[INFO] 2021-07-09 16:48:35,358 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:35,359 [run_pretraining.py:  534]:	loss/total_loss, 3.5197854042053223, 200
[INFO] 2021-07-09 16:48:35,359 [run_pretraining.py:  535]:	loss/mlm_loss, 3.5197854042053223, 200
[INFO] 2021-07-09 16:48:35,359 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9899998733308166e-06, 200
[INFO] 2021-07-09 16:48:35,359 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 200
[INFO] 2021-07-09 16:48:35,359 [run_pretraining.py:  558]:	worker_index: 5, step: 200, cost: 3.519785, mlm loss: 3.519785, speed: 0.445731 steps/s, speed: 3.565850 samples/s, speed: 1825.715449 tokens/s, learning rate: 1.990e-06, loss_scalings: 13421.773438, pp_loss: 3.516926
[INFO] 2021-07-09 16:48:35,359 [run_pretraining.py:  512]:	********exe.run_200******* 
[INFO] 2021-07-09 16:48:37,571 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:37,571 [run_pretraining.py:  534]:	loss/total_loss, 3.458082675933838, 201
[INFO] 2021-07-09 16:48:37,572 [run_pretraining.py:  535]:	loss/mlm_loss, 3.458082675933838, 201
[INFO] 2021-07-09 16:48:37,572 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9999999949504854e-06, 201
[INFO] 2021-07-09 16:48:37,572 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 201
[INFO] 2021-07-09 16:48:37,572 [run_pretraining.py:  558]:	worker_index: 5, step: 201, cost: 3.458083, mlm loss: 3.458083, speed: 0.452067 steps/s, speed: 3.616535 samples/s, speed: 1851.665702 tokens/s, learning rate: 2.000e-06, loss_scalings: 13421.773438, pp_loss: 3.468466
[INFO] 2021-07-09 16:48:37,572 [run_pretraining.py:  512]:	********exe.run_201******* 
[INFO] 2021-07-09 16:48:39,793 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:39,793 [run_pretraining.py:  534]:	loss/total_loss, 3.498365879058838, 202
[INFO] 2021-07-09 16:48:39,793 [run_pretraining.py:  535]:	loss/mlm_loss, 3.498365879058838, 202
[INFO] 2021-07-09 16:48:39,793 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0099998891964788e-06, 202
[INFO] 2021-07-09 16:48:39,793 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 202
[INFO] 2021-07-09 16:48:39,794 [run_pretraining.py:  558]:	worker_index: 5, step: 202, cost: 3.498366, mlm loss: 3.498366, speed: 0.450266 steps/s, speed: 3.602129 samples/s, speed: 1844.290181 tokens/s, learning rate: 2.010e-06, loss_scalings: 13421.773438, pp_loss: 3.483685
[INFO] 2021-07-09 16:48:39,794 [run_pretraining.py:  512]:	********exe.run_202******* 
[INFO] 2021-07-09 16:48:42,042 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:42,043 [run_pretraining.py:  534]:	loss/total_loss, 3.344048023223877, 203
[INFO] 2021-07-09 16:48:42,043 [run_pretraining.py:  535]:	loss/mlm_loss, 3.344048023223877, 203
[INFO] 2021-07-09 16:48:42,043 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.019999783442472e-06, 203
[INFO] 2021-07-09 16:48:42,043 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 203
[INFO] 2021-07-09 16:48:42,043 [run_pretraining.py:  558]:	worker_index: 5, step: 203, cost: 3.344048, mlm loss: 3.344048, speed: 0.444675 steps/s, speed: 3.557398 samples/s, speed: 1821.387641 tokens/s, learning rate: 2.020e-06, loss_scalings: 13421.773438, pp_loss: 3.417573
[INFO] 2021-07-09 16:48:42,043 [run_pretraining.py:  512]:	********exe.run_203******* 
[INFO] 2021-07-09 16:48:44,331 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:44,331 [run_pretraining.py:  534]:	loss/total_loss, 3.5593008995056152, 204
[INFO] 2021-07-09 16:48:44,331 [run_pretraining.py:  535]:	loss/mlm_loss, 3.5593008995056152, 204
[INFO] 2021-07-09 16:48:44,331 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0300001324358163e-06, 204
[INFO] 2021-07-09 16:48:44,331 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 204
[INFO] 2021-07-09 16:48:44,332 [run_pretraining.py:  558]:	worker_index: 5, step: 204, cost: 3.559301, mlm loss: 3.559301, speed: 0.437097 steps/s, speed: 3.496777 samples/s, speed: 1790.349814 tokens/s, learning rate: 2.030e-06, loss_scalings: 13421.773438, pp_loss: 3.377792
[INFO] 2021-07-09 16:48:44,332 [run_pretraining.py:  512]:	********exe.run_204******* 
[INFO] 2021-07-09 16:48:46,636 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:46,637 [run_pretraining.py:  534]:	loss/total_loss, 3.384652614593506, 205
[INFO] 2021-07-09 16:48:46,637 [run_pretraining.py:  535]:	loss/mlm_loss, 3.384652614593506, 205
[INFO] 2021-07-09 16:48:46,637 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0400000266818097e-06, 205
[INFO] 2021-07-09 16:48:46,637 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 205
[INFO] 2021-07-09 16:48:46,637 [run_pretraining.py:  558]:	worker_index: 5, step: 205, cost: 3.384653, mlm loss: 3.384653, speed: 0.433821 steps/s, speed: 3.470566 samples/s, speed: 1776.929813 tokens/s, learning rate: 2.040e-06, loss_scalings: 13421.773438, pp_loss: 3.400754
[INFO] 2021-07-09 16:48:46,637 [run_pretraining.py:  512]:	********exe.run_205******* 
[INFO] 2021-07-09 16:48:48,884 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:48,885 [run_pretraining.py:  534]:	loss/total_loss, 3.381862163543701, 206
[INFO] 2021-07-09 16:48:48,885 [run_pretraining.py:  535]:	loss/mlm_loss, 3.381862163543701, 206
[INFO] 2021-07-09 16:48:48,885 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.049999920927803e-06, 206
[INFO] 2021-07-09 16:48:48,885 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 206
[INFO] 2021-07-09 16:48:48,885 [run_pretraining.py:  558]:	worker_index: 5, step: 206, cost: 3.381862, mlm loss: 3.381862, speed: 0.445031 steps/s, speed: 3.560250 samples/s, speed: 1822.847883 tokens/s, learning rate: 2.050e-06, loss_scalings: 13421.773438, pp_loss: 3.368493
[INFO] 2021-07-09 16:48:48,885 [run_pretraining.py:  512]:	********exe.run_206******* 
[INFO] 2021-07-09 16:48:51,105 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:51,106 [run_pretraining.py:  534]:	loss/total_loss, 3.270702600479126, 207
[INFO] 2021-07-09 16:48:51,106 [run_pretraining.py:  535]:	loss/mlm_loss, 3.270702600479126, 207
[INFO] 2021-07-09 16:48:51,106 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.060000042547472e-06, 207
[INFO] 2021-07-09 16:48:51,106 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 207
[INFO] 2021-07-09 16:48:51,106 [run_pretraining.py:  558]:	worker_index: 5, step: 207, cost: 3.270703, mlm loss: 3.270703, speed: 0.450339 steps/s, speed: 3.602711 samples/s, speed: 1844.588200 tokens/s, learning rate: 2.060e-06, loss_scalings: 13421.773438, pp_loss: 3.362090
[INFO] 2021-07-09 16:48:51,106 [run_pretraining.py:  512]:	********exe.run_207******* 
[INFO] 2021-07-09 16:48:53,384 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:53,385 [run_pretraining.py:  534]:	loss/total_loss, 3.342261791229248, 208
[INFO] 2021-07-09 16:48:53,385 [run_pretraining.py:  535]:	loss/mlm_loss, 3.342261791229248, 208
[INFO] 2021-07-09 16:48:53,385 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.069999936793465e-06, 208
[INFO] 2021-07-09 16:48:53,385 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 208
[INFO] 2021-07-09 16:48:53,385 [run_pretraining.py:  558]:	worker_index: 5, step: 208, cost: 3.342262, mlm loss: 3.342262, speed: 0.438985 steps/s, speed: 3.511882 samples/s, speed: 1798.083633 tokens/s, learning rate: 2.070e-06, loss_scalings: 13421.773438, pp_loss: 3.276880
[INFO] 2021-07-09 16:48:53,385 [run_pretraining.py:  512]:	********exe.run_208******* 
[INFO] 2021-07-09 16:48:55,623 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:55,624 [run_pretraining.py:  534]:	loss/total_loss, 3.201704502105713, 209
[INFO] 2021-07-09 16:48:55,624 [run_pretraining.py:  535]:	loss/mlm_loss, 3.201704502105713, 209
[INFO] 2021-07-09 16:48:55,624 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.080000058413134e-06, 209
[INFO] 2021-07-09 16:48:55,624 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 209
[INFO] 2021-07-09 16:48:55,624 [run_pretraining.py:  558]:	worker_index: 5, step: 209, cost: 3.201705, mlm loss: 3.201705, speed: 0.446782 steps/s, speed: 3.574256 samples/s, speed: 1830.019037 tokens/s, learning rate: 2.080e-06, loss_scalings: 13421.773438, pp_loss: 3.249061
[INFO] 2021-07-09 16:48:55,624 [run_pretraining.py:  512]:	********exe.run_209******* 
[INFO] 2021-07-09 16:48:57,908 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:48:57,908 [run_pretraining.py:  534]:	loss/total_loss, 3.2017760276794434, 210
[INFO] 2021-07-09 16:48:57,908 [run_pretraining.py:  535]:	loss/mlm_loss, 3.2017760276794434, 210
[INFO] 2021-07-09 16:48:57,908 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0899999526591273e-06, 210
[INFO] 2021-07-09 16:48:57,908 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 210
[INFO] 2021-07-09 16:48:57,908 [run_pretraining.py:  558]:	worker_index: 5, step: 210, cost: 3.201776, mlm loss: 3.201776, speed: 0.437857 steps/s, speed: 3.502857 samples/s, speed: 1793.463016 tokens/s, learning rate: 2.090e-06, loss_scalings: 13421.773438, pp_loss: 3.270122
[INFO] 2021-07-09 16:48:57,908 [run_pretraining.py:  512]:	********exe.run_210******* 
[INFO] 2021-07-09 16:49:00,149 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:00,149 [run_pretraining.py:  534]:	loss/total_loss, 3.1784965991973877, 211
[INFO] 2021-07-09 16:49:00,150 [run_pretraining.py:  535]:	loss/mlm_loss, 3.1784965991973877, 211
[INFO] 2021-07-09 16:49:00,150 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0999998469051206e-06, 211
[INFO] 2021-07-09 16:49:00,150 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 211
[INFO] 2021-07-09 16:49:00,150 [run_pretraining.py:  558]:	worker_index: 5, step: 211, cost: 3.178497, mlm loss: 3.178497, speed: 0.446277 steps/s, speed: 3.570214 samples/s, speed: 1827.949409 tokens/s, learning rate: 2.100e-06, loss_scalings: 13421.773438, pp_loss: 3.202127
[INFO] 2021-07-09 16:49:00,150 [run_pretraining.py:  512]:	********exe.run_211******* 
[INFO] 2021-07-09 16:49:02,443 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:02,443 [run_pretraining.py:  534]:	loss/total_loss, 3.119990348815918, 212
[INFO] 2021-07-09 16:49:02,444 [run_pretraining.py:  535]:	loss/mlm_loss, 3.119990348815918, 212
[INFO] 2021-07-09 16:49:02,444 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1099999685247894e-06, 212
[INFO] 2021-07-09 16:49:02,444 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 212
[INFO] 2021-07-09 16:49:02,444 [run_pretraining.py:  558]:	worker_index: 5, step: 212, cost: 3.119990, mlm loss: 3.119990, speed: 0.436066 steps/s, speed: 3.488531 samples/s, speed: 1786.127875 tokens/s, learning rate: 2.110e-06, loss_scalings: 13421.773438, pp_loss: 3.177996
[INFO] 2021-07-09 16:49:02,444 [run_pretraining.py:  512]:	********exe.run_212******* 
[INFO] 2021-07-09 16:49:04,754 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:04,754 [run_pretraining.py:  534]:	loss/total_loss, 3.193319320678711, 213
[INFO] 2021-07-09 16:49:04,755 [run_pretraining.py:  535]:	loss/mlm_loss, 3.193319320678711, 213
[INFO] 2021-07-09 16:49:04,755 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1199998627707828e-06, 213
[INFO] 2021-07-09 16:49:04,755 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 213
[INFO] 2021-07-09 16:49:04,755 [run_pretraining.py:  558]:	worker_index: 5, step: 213, cost: 3.193319, mlm loss: 3.193319, speed: 0.432866 steps/s, speed: 3.462930 samples/s, speed: 1773.020225 tokens/s, learning rate: 2.120e-06, loss_scalings: 13421.773438, pp_loss: 3.244750
[INFO] 2021-07-09 16:49:04,755 [run_pretraining.py:  512]:	********exe.run_213******* 
[INFO] 2021-07-09 16:49:07,139 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:07,140 [run_pretraining.py:  534]:	loss/total_loss, 3.1413168907165527, 214
[INFO] 2021-07-09 16:49:07,140 [run_pretraining.py:  535]:	loss/mlm_loss, 3.1413168907165527, 214
[INFO] 2021-07-09 16:49:07,140 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.129999757016776e-06, 214
[INFO] 2021-07-09 16:49:07,140 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 214
[INFO] 2021-07-09 16:49:07,140 [run_pretraining.py:  558]:	worker_index: 5, step: 214, cost: 3.141317, mlm loss: 3.141317, speed: 0.419362 steps/s, speed: 3.354896 samples/s, speed: 1717.706760 tokens/s, learning rate: 2.130e-06, loss_scalings: 13421.773438, pp_loss: 3.221672
[INFO] 2021-07-09 16:49:07,140 [run_pretraining.py:  512]:	********exe.run_214******* 
[INFO] 2021-07-09 16:49:09,448 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:09,449 [run_pretraining.py:  534]:	loss/total_loss, 3.142761707305908, 215
[INFO] 2021-07-09 16:49:09,449 [run_pretraining.py:  535]:	loss/mlm_loss, 3.142761707305908, 215
[INFO] 2021-07-09 16:49:09,449 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1400001060101204e-06, 215
[INFO] 2021-07-09 16:49:09,449 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 215
[INFO] 2021-07-09 16:49:09,449 [run_pretraining.py:  558]:	worker_index: 5, step: 215, cost: 3.142762, mlm loss: 3.142762, speed: 0.433154 steps/s, speed: 3.465230 samples/s, speed: 1774.197578 tokens/s, learning rate: 2.140e-06, loss_scalings: 13421.773438, pp_loss: 3.248127
[INFO] 2021-07-09 16:49:09,450 [run_pretraining.py:  512]:	********exe.run_215******* 
[INFO] 2021-07-09 16:49:11,718 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:11,719 [run_pretraining.py:  534]:	loss/total_loss, 3.0564441680908203, 216
[INFO] 2021-07-09 16:49:11,719 [run_pretraining.py:  535]:	loss/mlm_loss, 3.0564441680908203, 216
[INFO] 2021-07-09 16:49:11,719 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1500000002561137e-06, 216
[INFO] 2021-07-09 16:49:11,719 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 216
[INFO] 2021-07-09 16:49:11,720 [run_pretraining.py:  558]:	worker_index: 5, step: 216, cost: 3.056444, mlm loss: 3.056444, speed: 0.440664 steps/s, speed: 3.525314 samples/s, speed: 1804.960947 tokens/s, learning rate: 2.150e-06, loss_scalings: 13421.773438, pp_loss: 3.193781
[INFO] 2021-07-09 16:49:11,720 [run_pretraining.py:  512]:	********exe.run_216******* 
[INFO] 2021-07-09 16:49:14,062 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:14,063 [run_pretraining.py:  534]:	loss/total_loss, 3.068324565887451, 217
[INFO] 2021-07-09 16:49:14,064 [run_pretraining.py:  535]:	loss/mlm_loss, 3.068324565887451, 217
[INFO] 2021-07-09 16:49:14,064 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.159999894502107e-06, 217
[INFO] 2021-07-09 16:49:14,064 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 217
[INFO] 2021-07-09 16:49:14,064 [run_pretraining.py:  558]:	worker_index: 5, step: 217, cost: 3.068325, mlm loss: 3.068325, speed: 0.426712 steps/s, speed: 3.413697 samples/s, speed: 1747.812820 tokens/s, learning rate: 2.160e-06, loss_scalings: 13421.773438, pp_loss: 3.122303
[INFO] 2021-07-09 16:49:14,064 [run_pretraining.py:  512]:	********exe.run_217******* 
[INFO] 2021-07-09 16:49:16,326 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:16,327 [run_pretraining.py:  534]:	loss/total_loss, 3.1288297176361084, 218
[INFO] 2021-07-09 16:49:16,327 [run_pretraining.py:  535]:	loss/mlm_loss, 3.1288297176361084, 218
[INFO] 2021-07-09 16:49:16,327 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.170000016121776e-06, 218
[INFO] 2021-07-09 16:49:16,327 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 218
[INFO] 2021-07-09 16:49:16,327 [run_pretraining.py:  558]:	worker_index: 5, step: 218, cost: 3.128830, mlm loss: 3.128830, speed: 0.441933 steps/s, speed: 3.535463 samples/s, speed: 1810.156847 tokens/s, learning rate: 2.170e-06, loss_scalings: 13421.773438, pp_loss: 3.113086
[INFO] 2021-07-09 16:49:16,327 [run_pretraining.py:  512]:	********exe.run_218******* 
[INFO] 2021-07-09 16:49:18,668 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:18,669 [run_pretraining.py:  534]:	loss/total_loss, 3.0778615474700928, 219
[INFO] 2021-07-09 16:49:18,670 [run_pretraining.py:  535]:	loss/mlm_loss, 3.0778615474700928, 219
[INFO] 2021-07-09 16:49:18,670 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.179999910367769e-06, 219
[INFO] 2021-07-09 16:49:18,670 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 219
[INFO] 2021-07-09 16:49:18,670 [run_pretraining.py:  558]:	worker_index: 5, step: 219, cost: 3.077862, mlm loss: 3.077862, speed: 0.427032 steps/s, speed: 3.416256 samples/s, speed: 1749.122880 tokens/s, learning rate: 2.180e-06, loss_scalings: 13421.773438, pp_loss: 3.106300
[INFO] 2021-07-09 16:49:18,670 [run_pretraining.py:  512]:	********exe.run_219******* 
[INFO] 2021-07-09 16:49:20,889 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:20,890 [run_pretraining.py:  534]:	loss/total_loss, 3.040855646133423, 220
[INFO] 2021-07-09 16:49:20,890 [run_pretraining.py:  535]:	loss/mlm_loss, 3.040855646133423, 220
[INFO] 2021-07-09 16:49:20,890 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.190000031987438e-06, 220
[INFO] 2021-07-09 16:49:20,890 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 220
[INFO] 2021-07-09 16:49:20,890 [run_pretraining.py:  558]:	worker_index: 5, step: 220, cost: 3.040856, mlm loss: 3.040856, speed: 0.450528 steps/s, speed: 3.604225 samples/s, speed: 1845.363305 tokens/s, learning rate: 2.190e-06, loss_scalings: 13421.773438, pp_loss: 3.124804
[INFO] 2021-07-09 16:49:20,890 [run_pretraining.py:  512]:	********exe.run_220******* 
[INFO] 2021-07-09 16:49:23,199 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:23,200 [run_pretraining.py:  534]:	loss/total_loss, 3.055647850036621, 221
[INFO] 2021-07-09 16:49:23,200 [run_pretraining.py:  535]:	loss/mlm_loss, 3.055647850036621, 221
[INFO] 2021-07-09 16:49:23,200 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1999999262334313e-06, 221
[INFO] 2021-07-09 16:49:23,200 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 221
[INFO] 2021-07-09 16:49:23,200 [run_pretraining.py:  558]:	worker_index: 5, step: 221, cost: 3.055648, mlm loss: 3.055648, speed: 0.433005 steps/s, speed: 3.464041 samples/s, speed: 1773.588931 tokens/s, learning rate: 2.200e-06, loss_scalings: 13421.773438, pp_loss: 3.057328
[INFO] 2021-07-09 16:49:23,200 [run_pretraining.py:  512]:	********exe.run_221******* 
[INFO] 2021-07-09 16:49:25,460 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:25,460 [run_pretraining.py:  534]:	loss/total_loss, 3.1158695220947266, 222
[INFO] 2021-07-09 16:49:25,460 [run_pretraining.py:  535]:	loss/mlm_loss, 3.1158695220947266, 222
[INFO] 2021-07-09 16:49:25,460 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2099998204794247e-06, 222
[INFO] 2021-07-09 16:49:25,461 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 222
[INFO] 2021-07-09 16:49:25,461 [run_pretraining.py:  558]:	worker_index: 5, step: 222, cost: 3.115870, mlm loss: 3.115870, speed: 0.442527 steps/s, speed: 3.540219 samples/s, speed: 1812.591889 tokens/s, learning rate: 2.210e-06, loss_scalings: 13421.773438, pp_loss: 3.054615
[INFO] 2021-07-09 16:49:25,461 [run_pretraining.py:  512]:	********exe.run_222******* 
[INFO] 2021-07-09 16:49:27,747 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:27,748 [run_pretraining.py:  534]:	loss/total_loss, 3.306734085083008, 223
[INFO] 2021-07-09 16:49:27,748 [run_pretraining.py:  535]:	loss/mlm_loss, 3.306734085083008, 223
[INFO] 2021-07-09 16:49:27,748 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2199999420990935e-06, 223
[INFO] 2021-07-09 16:49:27,748 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 223
[INFO] 2021-07-09 16:49:27,748 [run_pretraining.py:  558]:	worker_index: 5, step: 223, cost: 3.306734, mlm loss: 3.306734, speed: 0.437309 steps/s, speed: 3.498473 samples/s, speed: 1791.218187 tokens/s, learning rate: 2.220e-06, loss_scalings: 13421.773438, pp_loss: 3.115061
[INFO] 2021-07-09 16:49:27,748 [run_pretraining.py:  512]:	********exe.run_223******* 
[INFO] 2021-07-09 16:49:30,049 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:30,050 [run_pretraining.py:  534]:	loss/total_loss, 3.0520193576812744, 224
[INFO] 2021-07-09 16:49:30,050 [run_pretraining.py:  535]:	loss/mlm_loss, 3.0520193576812744, 224
[INFO] 2021-07-09 16:49:30,050 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.229999836345087e-06, 224
[INFO] 2021-07-09 16:49:30,050 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 224
[INFO] 2021-07-09 16:49:30,050 [run_pretraining.py:  558]:	worker_index: 5, step: 224, cost: 3.052019, mlm loss: 3.052019, speed: 0.434513 steps/s, speed: 3.476104 samples/s, speed: 1779.765240 tokens/s, learning rate: 2.230e-06, loss_scalings: 13421.773438, pp_loss: 3.036285
[INFO] 2021-07-09 16:49:30,050 [run_pretraining.py:  512]:	********exe.run_224******* 
[INFO] 2021-07-09 16:49:32,349 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:32,350 [run_pretraining.py:  534]:	loss/total_loss, 3.054499864578247, 225
[INFO] 2021-07-09 16:49:32,350 [run_pretraining.py:  535]:	loss/mlm_loss, 3.054499864578247, 225
[INFO] 2021-07-09 16:49:32,350 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2399999579647556e-06, 225
[INFO] 2021-07-09 16:49:32,350 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 225
[INFO] 2021-07-09 16:49:32,350 [run_pretraining.py:  558]:	worker_index: 5, step: 225, cost: 3.054500, mlm loss: 3.054500, speed: 0.434887 steps/s, speed: 3.479097 samples/s, speed: 1781.297620 tokens/s, learning rate: 2.240e-06, loss_scalings: 13421.773438, pp_loss: 3.075696
[INFO] 2021-07-09 16:49:32,350 [run_pretraining.py:  512]:	********exe.run_225******* 
[INFO] 2021-07-09 16:49:34,653 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:34,654 [run_pretraining.py:  534]:	loss/total_loss, 2.996473789215088, 226
[INFO] 2021-07-09 16:49:34,654 [run_pretraining.py:  535]:	loss/mlm_loss, 2.996473789215088, 226
[INFO] 2021-07-09 16:49:34,654 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2500000795844244e-06, 226
[INFO] 2021-07-09 16:49:34,654 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 226
[INFO] 2021-07-09 16:49:34,654 [run_pretraining.py:  558]:	worker_index: 5, step: 226, cost: 2.996474, mlm loss: 2.996474, speed: 0.434157 steps/s, speed: 3.473255 samples/s, speed: 1778.306543 tokens/s, learning rate: 2.250e-06, loss_scalings: 13421.773438, pp_loss: 3.026344
[INFO] 2021-07-09 16:49:34,654 [run_pretraining.py:  512]:	********exe.run_226******* 
[INFO] 2021-07-09 16:49:36,891 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:36,891 [run_pretraining.py:  534]:	loss/total_loss, 3.0880682468414307, 227
[INFO] 2021-07-09 16:49:36,892 [run_pretraining.py:  535]:	loss/mlm_loss, 3.0880682468414307, 227
[INFO] 2021-07-09 16:49:36,892 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2599999738304177e-06, 227
[INFO] 2021-07-09 16:49:36,892 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 227
[INFO] 2021-07-09 16:49:36,892 [run_pretraining.py:  558]:	worker_index: 5, step: 227, cost: 3.088068, mlm loss: 3.088068, speed: 0.447079 steps/s, speed: 3.576632 samples/s, speed: 1831.235464 tokens/s, learning rate: 2.260e-06, loss_scalings: 10737.418945, pp_loss: 3.072836
[INFO] 2021-07-09 16:49:36,892 [run_pretraining.py:  512]:	********exe.run_227******* 
[INFO] 2021-07-09 16:49:39,207 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:39,207 [run_pretraining.py:  534]:	loss/total_loss, 3.019991397857666, 228
[INFO] 2021-07-09 16:49:39,208 [run_pretraining.py:  535]:	loss/mlm_loss, 3.019991397857666, 228
[INFO] 2021-07-09 16:49:39,208 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2700000954500865e-06, 228
[INFO] 2021-07-09 16:49:39,208 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 228
[INFO] 2021-07-09 16:49:39,208 [run_pretraining.py:  558]:	worker_index: 5, step: 228, cost: 3.019991, mlm loss: 3.019991, speed: 0.431927 steps/s, speed: 3.455417 samples/s, speed: 1769.173532 tokens/s, learning rate: 2.270e-06, loss_scalings: 10737.418945, pp_loss: 3.050426
[INFO] 2021-07-09 16:49:39,208 [run_pretraining.py:  512]:	********exe.run_228******* 
[INFO] 2021-07-09 16:49:41,546 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:41,547 [run_pretraining.py:  534]:	loss/total_loss, 3.070180654525757, 229
[INFO] 2021-07-09 16:49:41,547 [run_pretraining.py:  535]:	loss/mlm_loss, 3.070180654525757, 229
[INFO] 2021-07-09 16:49:41,548 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.27999998969608e-06, 229
[INFO] 2021-07-09 16:49:41,548 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 229
[INFO] 2021-07-09 16:49:41,548 [run_pretraining.py:  558]:	worker_index: 5, step: 229, cost: 3.070181, mlm loss: 3.070181, speed: 0.427504 steps/s, speed: 3.420029 samples/s, speed: 1751.055068 tokens/s, learning rate: 2.280e-06, loss_scalings: 8589.935547, pp_loss: 3.090674
[INFO] 2021-07-09 16:49:41,548 [run_pretraining.py:  512]:	********exe.run_229******* 
[INFO] 2021-07-09 16:49:43,798 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:43,799 [run_pretraining.py:  534]:	loss/total_loss, 2.9807794094085693, 230
[INFO] 2021-07-09 16:49:43,799 [run_pretraining.py:  535]:	loss/mlm_loss, 2.9807794094085693, 230
[INFO] 2021-07-09 16:49:43,799 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.289999883942073e-06, 230
[INFO] 2021-07-09 16:49:43,799 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 230
[INFO] 2021-07-09 16:49:43,799 [run_pretraining.py:  558]:	worker_index: 5, step: 230, cost: 2.980779, mlm loss: 2.980779, speed: 0.444266 steps/s, speed: 3.554131 samples/s, speed: 1819.714991 tokens/s, learning rate: 2.290e-06, loss_scalings: 8589.935547, pp_loss: 3.052923
[INFO] 2021-07-09 16:49:43,799 [run_pretraining.py:  512]:	********exe.run_230******* 
[INFO] 2021-07-09 16:49:46,153 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:46,154 [run_pretraining.py:  534]:	loss/total_loss, 3.009673833847046, 231
[INFO] 2021-07-09 16:49:46,154 [run_pretraining.py:  535]:	loss/mlm_loss, 3.009673833847046, 231
[INFO] 2021-07-09 16:49:46,154 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.300000005561742e-06, 231
[INFO] 2021-07-09 16:49:46,154 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 231
[INFO] 2021-07-09 16:49:46,155 [run_pretraining.py:  558]:	worker_index: 5, step: 231, cost: 3.009674, mlm loss: 3.009674, speed: 0.424715 steps/s, speed: 3.397724 samples/s, speed: 1739.634583 tokens/s, learning rate: 2.300e-06, loss_scalings: 8589.935547, pp_loss: 3.035923
[INFO] 2021-07-09 16:49:46,155 [run_pretraining.py:  512]:	********exe.run_231******* 
[INFO] 2021-07-09 16:49:48,489 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:48,490 [run_pretraining.py:  534]:	loss/total_loss, 3.017446279525757, 232
[INFO] 2021-07-09 16:49:48,490 [run_pretraining.py:  535]:	loss/mlm_loss, 3.017446279525757, 232
[INFO] 2021-07-09 16:49:48,490 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3099998998077353e-06, 232
[INFO] 2021-07-09 16:49:48,490 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 232
[INFO] 2021-07-09 16:49:48,490 [run_pretraining.py:  558]:	worker_index: 5, step: 232, cost: 3.017446, mlm loss: 3.017446, speed: 0.428228 steps/s, speed: 3.425822 samples/s, speed: 1754.021000 tokens/s, learning rate: 2.310e-06, loss_scalings: 8589.935547, pp_loss: 3.049142
[INFO] 2021-07-09 16:49:48,491 [run_pretraining.py:  512]:	********exe.run_232******* 
[INFO] 2021-07-09 16:49:50,698 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:50,699 [run_pretraining.py:  534]:	loss/total_loss, 3.0290935039520264, 233
[INFO] 2021-07-09 16:49:50,699 [run_pretraining.py:  535]:	loss/mlm_loss, 3.0290935039520264, 233
[INFO] 2021-07-09 16:49:50,699 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.320000021427404e-06, 233
[INFO] 2021-07-09 16:49:50,699 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 233
[INFO] 2021-07-09 16:49:50,699 [run_pretraining.py:  558]:	worker_index: 5, step: 233, cost: 3.029094, mlm loss: 3.029094, speed: 0.452877 steps/s, speed: 3.623015 samples/s, speed: 1854.983577 tokens/s, learning rate: 2.320e-06, loss_scalings: 8589.935547, pp_loss: 3.057622
[INFO] 2021-07-09 16:49:50,699 [run_pretraining.py:  512]:	********exe.run_233******* 
[INFO] 2021-07-09 16:49:52,944 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:52,945 [run_pretraining.py:  534]:	loss/total_loss, 2.982762336730957, 234
[INFO] 2021-07-09 16:49:52,945 [run_pretraining.py:  535]:	loss/mlm_loss, 2.982762336730957, 234
[INFO] 2021-07-09 16:49:52,945 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3299999156733975e-06, 234
[INFO] 2021-07-09 16:49:52,945 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 234
[INFO] 2021-07-09 16:49:52,945 [run_pretraining.py:  558]:	worker_index: 5, step: 234, cost: 2.982762, mlm loss: 2.982762, speed: 0.445366 steps/s, speed: 3.562929 samples/s, speed: 1824.219618 tokens/s, learning rate: 2.330e-06, loss_scalings: 8589.935547, pp_loss: 3.020793
[INFO] 2021-07-09 16:49:52,945 [run_pretraining.py:  512]:	********exe.run_234******* 
[INFO] 2021-07-09 16:49:55,232 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:55,232 [run_pretraining.py:  534]:	loss/total_loss, 3.01228666305542, 235
[INFO] 2021-07-09 16:49:55,233 [run_pretraining.py:  535]:	loss/mlm_loss, 3.01228666305542, 235
[INFO] 2021-07-09 16:49:55,233 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.339999809919391e-06, 235
[INFO] 2021-07-09 16:49:55,233 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 235
[INFO] 2021-07-09 16:49:55,233 [run_pretraining.py:  558]:	worker_index: 5, step: 235, cost: 3.012287, mlm loss: 3.012287, speed: 0.437263 steps/s, speed: 3.498104 samples/s, speed: 1791.029022 tokens/s, learning rate: 2.340e-06, loss_scalings: 8589.935547, pp_loss: 3.043719
[INFO] 2021-07-09 16:49:55,233 [run_pretraining.py:  512]:	********exe.run_235******* 
[INFO] 2021-07-09 16:49:57,480 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:57,480 [run_pretraining.py:  534]:	loss/total_loss, 3.0285236835479736, 236
[INFO] 2021-07-09 16:49:57,481 [run_pretraining.py:  535]:	loss/mlm_loss, 3.0285236835479736, 236
[INFO] 2021-07-09 16:49:57,481 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3499999315390596e-06, 236
[INFO] 2021-07-09 16:49:57,481 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 236
[INFO] 2021-07-09 16:49:57,481 [run_pretraining.py:  558]:	worker_index: 5, step: 236, cost: 3.028524, mlm loss: 3.028524, speed: 0.444979 steps/s, speed: 3.559832 samples/s, speed: 1822.634189 tokens/s, learning rate: 2.350e-06, loss_scalings: 6871.948730, pp_loss: 3.077904
[INFO] 2021-07-09 16:49:57,481 [run_pretraining.py:  512]:	********exe.run_236******* 
[INFO] 2021-07-09 16:49:59,726 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:49:59,727 [run_pretraining.py:  534]:	loss/total_loss, 3.036367177963257, 237
[INFO] 2021-07-09 16:49:59,727 [run_pretraining.py:  535]:	loss/mlm_loss, 3.036367177963257, 237
[INFO] 2021-07-09 16:49:59,727 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3600000531587284e-06, 237
[INFO] 2021-07-09 16:49:59,727 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 237
[INFO] 2021-07-09 16:49:59,727 [run_pretraining.py:  558]:	worker_index: 5, step: 237, cost: 3.036367, mlm loss: 3.036367, speed: 0.445291 steps/s, speed: 3.562326 samples/s, speed: 1823.910909 tokens/s, learning rate: 2.360e-06, loss_scalings: 6871.948730, pp_loss: 3.087356
[INFO] 2021-07-09 16:49:59,727 [run_pretraining.py:  512]:	********exe.run_237******* 
[INFO] 2021-07-09 16:50:01,968 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:01,969 [run_pretraining.py:  534]:	loss/total_loss, 3.053481340408325, 238
[INFO] 2021-07-09 16:50:01,969 [run_pretraining.py:  535]:	loss/mlm_loss, 3.053481340408325, 238
[INFO] 2021-07-09 16:50:01,969 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3699999474047218e-06, 238
[INFO] 2021-07-09 16:50:01,969 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 238
[INFO] 2021-07-09 16:50:01,969 [run_pretraining.py:  558]:	worker_index: 5, step: 238, cost: 3.053481, mlm loss: 3.053481, speed: 0.446173 steps/s, speed: 3.569380 samples/s, speed: 1827.522786 tokens/s, learning rate: 2.370e-06, loss_scalings: 6871.948730, pp_loss: 3.062442
[INFO] 2021-07-09 16:50:01,969 [run_pretraining.py:  512]:	********exe.run_238******* 
[INFO] 2021-07-09 16:50:04,212 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:04,213 [run_pretraining.py:  534]:	loss/total_loss, 3.2626583576202393, 239
[INFO] 2021-07-09 16:50:04,213 [run_pretraining.py:  535]:	loss/mlm_loss, 3.2626583576202393, 239
[INFO] 2021-07-09 16:50:04,213 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3800000690243905e-06, 239
[INFO] 2021-07-09 16:50:04,213 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 239
[INFO] 2021-07-09 16:50:04,213 [run_pretraining.py:  558]:	worker_index: 5, step: 239, cost: 3.262658, mlm loss: 3.262658, speed: 0.445769 steps/s, speed: 3.566154 samples/s, speed: 1825.870873 tokens/s, learning rate: 2.380e-06, loss_scalings: 6871.948730, pp_loss: 3.117265
[INFO] 2021-07-09 16:50:04,213 [run_pretraining.py:  512]:	********exe.run_239******* 
[INFO] 2021-07-09 16:50:06,475 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:06,475 [run_pretraining.py:  534]:	loss/total_loss, 3.2116551399230957, 240
[INFO] 2021-07-09 16:50:06,475 [run_pretraining.py:  535]:	loss/mlm_loss, 3.2116551399230957, 240
[INFO] 2021-07-09 16:50:06,476 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.389999963270384e-06, 240
[INFO] 2021-07-09 16:50:06,476 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 240
[INFO] 2021-07-09 16:50:06,476 [run_pretraining.py:  558]:	worker_index: 5, step: 240, cost: 3.211655, mlm loss: 3.211655, speed: 0.442146 steps/s, speed: 3.537166 samples/s, speed: 1811.029081 tokens/s, learning rate: 2.390e-06, loss_scalings: 5497.559082, pp_loss: 3.212278
[INFO] 2021-07-09 16:50:06,476 [run_pretraining.py:  512]:	********exe.run_240******* 
[INFO] 2021-07-09 16:50:08,782 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:08,783 [run_pretraining.py:  534]:	loss/total_loss, 3.140127182006836, 241
[INFO] 2021-07-09 16:50:08,783 [run_pretraining.py:  535]:	loss/mlm_loss, 3.140127182006836, 241
[INFO] 2021-07-09 16:50:08,783 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3999998575163772e-06, 241
[INFO] 2021-07-09 16:50:08,783 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 241
[INFO] 2021-07-09 16:50:08,783 [run_pretraining.py:  558]:	worker_index: 5, step: 241, cost: 3.140127, mlm loss: 3.140127, speed: 0.433489 steps/s, speed: 3.467911 samples/s, speed: 1775.570443 tokens/s, learning rate: 2.400e-06, loss_scalings: 5497.559082, pp_loss: 3.131411
[INFO] 2021-07-09 16:50:08,783 [run_pretraining.py:  512]:	********exe.run_241******* 
[INFO] 2021-07-09 16:50:11,116 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:11,116 [run_pretraining.py:  534]:	loss/total_loss, 3.1159915924072266, 242
[INFO] 2021-07-09 16:50:11,117 [run_pretraining.py:  535]:	loss/mlm_loss, 3.1159915924072266, 242
[INFO] 2021-07-09 16:50:11,117 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.409999979136046e-06, 242
[INFO] 2021-07-09 16:50:11,117 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 242
[INFO] 2021-07-09 16:50:11,117 [run_pretraining.py:  558]:	worker_index: 5, step: 242, cost: 3.115992, mlm loss: 3.115992, speed: 0.428665 steps/s, speed: 3.429320 samples/s, speed: 1755.812026 tokens/s, learning rate: 2.410e-06, loss_scalings: 5497.559082, pp_loss: 3.147166
[INFO] 2021-07-09 16:50:11,117 [run_pretraining.py:  512]:	********exe.run_242******* 
[INFO] 2021-07-09 16:50:13,366 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:13,367 [run_pretraining.py:  534]:	loss/total_loss, 3.177940845489502, 243
[INFO] 2021-07-09 16:50:13,367 [run_pretraining.py:  535]:	loss/mlm_loss, 3.177940845489502, 243
[INFO] 2021-07-09 16:50:13,367 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4199998733820394e-06, 243
[INFO] 2021-07-09 16:50:13,368 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 243
[INFO] 2021-07-09 16:50:13,368 [run_pretraining.py:  558]:	worker_index: 5, step: 243, cost: 3.177941, mlm loss: 3.177941, speed: 0.444436 steps/s, speed: 3.555488 samples/s, speed: 1820.409723 tokens/s, learning rate: 2.420e-06, loss_scalings: 5497.559082, pp_loss: 3.176810
[INFO] 2021-07-09 16:50:13,368 [run_pretraining.py:  512]:	********exe.run_243******* 
[INFO] 2021-07-09 16:50:15,628 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:15,629 [run_pretraining.py:  534]:	loss/total_loss, 3.2049615383148193, 244
[INFO] 2021-07-09 16:50:15,629 [run_pretraining.py:  535]:	loss/mlm_loss, 3.2049615383148193, 244
[INFO] 2021-07-09 16:50:15,629 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.429999995001708e-06, 244
[INFO] 2021-07-09 16:50:15,629 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 244
[INFO] 2021-07-09 16:50:15,629 [run_pretraining.py:  558]:	worker_index: 5, step: 244, cost: 3.204962, mlm loss: 3.204962, speed: 0.442341 steps/s, speed: 3.538728 samples/s, speed: 1811.828778 tokens/s, learning rate: 2.430e-06, loss_scalings: 5497.559082, pp_loss: 3.220041
[INFO] 2021-07-09 16:50:15,629 [run_pretraining.py:  512]:	********exe.run_244******* 
[INFO] 2021-07-09 16:50:17,898 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:17,899 [run_pretraining.py:  534]:	loss/total_loss, 3.2784762382507324, 245
[INFO] 2021-07-09 16:50:17,899 [run_pretraining.py:  535]:	loss/mlm_loss, 3.2784762382507324, 245
[INFO] 2021-07-09 16:50:17,899 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4399998892477015e-06, 245
[INFO] 2021-07-09 16:50:17,899 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 245
[INFO] 2021-07-09 16:50:17,899 [run_pretraining.py:  558]:	worker_index: 5, step: 245, cost: 3.278476, mlm loss: 3.278476, speed: 0.440620 steps/s, speed: 3.524957 samples/s, speed: 1804.778159 tokens/s, learning rate: 2.440e-06, loss_scalings: 5497.559082, pp_loss: 3.307391
[INFO] 2021-07-09 16:50:17,899 [run_pretraining.py:  512]:	********exe.run_245******* 
[INFO] 2021-07-09 16:50:20,171 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:20,172 [run_pretraining.py:  534]:	loss/total_loss, 3.5342373847961426, 246
[INFO] 2021-07-09 16:50:20,172 [run_pretraining.py:  535]:	loss/mlm_loss, 3.5342373847961426, 246
[INFO] 2021-07-09 16:50:20,172 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.449999783493695e-06, 246
[INFO] 2021-07-09 16:50:20,172 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 246
[INFO] 2021-07-09 16:50:20,172 [run_pretraining.py:  558]:	worker_index: 5, step: 246, cost: 3.534237, mlm loss: 3.534237, speed: 0.440073 steps/s, speed: 3.520584 samples/s, speed: 1802.538785 tokens/s, learning rate: 2.450e-06, loss_scalings: 5497.559082, pp_loss: 3.300278
[INFO] 2021-07-09 16:50:20,172 [run_pretraining.py:  512]:	********exe.run_246******* 
[INFO] 2021-07-09 16:50:22,434 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:22,435 [run_pretraining.py:  534]:	loss/total_loss, 3.28471040725708, 247
[INFO] 2021-07-09 16:50:22,435 [run_pretraining.py:  535]:	loss/mlm_loss, 3.28471040725708, 247
[INFO] 2021-07-09 16:50:22,435 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4599999051133636e-06, 247
[INFO] 2021-07-09 16:50:22,435 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 247
[INFO] 2021-07-09 16:50:22,435 [run_pretraining.py:  558]:	worker_index: 5, step: 247, cost: 3.284710, mlm loss: 3.284710, speed: 0.442045 steps/s, speed: 3.536362 samples/s, speed: 1810.617379 tokens/s, learning rate: 2.460e-06, loss_scalings: 4398.047363, pp_loss: 3.298315
[INFO] 2021-07-09 16:50:22,435 [run_pretraining.py:  512]:	********exe.run_247******* 
[INFO] 2021-07-09 16:50:24,677 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:24,678 [run_pretraining.py:  534]:	loss/total_loss, 3.2744650840759277, 248
[INFO] 2021-07-09 16:50:24,678 [run_pretraining.py:  535]:	loss/mlm_loss, 3.2744650840759277, 248
[INFO] 2021-07-09 16:50:24,678 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4700000267330324e-06, 248
[INFO] 2021-07-09 16:50:24,678 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 248
[INFO] 2021-07-09 16:50:24,678 [run_pretraining.py:  558]:	worker_index: 5, step: 248, cost: 3.274465, mlm loss: 3.274465, speed: 0.445944 steps/s, speed: 3.567549 samples/s, speed: 1826.585073 tokens/s, learning rate: 2.470e-06, loss_scalings: 4398.047363, pp_loss: 3.287391
[INFO] 2021-07-09 16:50:24,679 [run_pretraining.py:  512]:	********exe.run_248******* 
[INFO] 2021-07-09 16:50:26,911 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:26,911 [run_pretraining.py:  534]:	loss/total_loss, 3.330918788909912, 249
[INFO] 2021-07-09 16:50:26,912 [run_pretraining.py:  535]:	loss/mlm_loss, 3.330918788909912, 249
[INFO] 2021-07-09 16:50:26,912 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4799999209790258e-06, 249
[INFO] 2021-07-09 16:50:26,912 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 249
[INFO] 2021-07-09 16:50:26,912 [run_pretraining.py:  558]:	worker_index: 5, step: 249, cost: 3.330919, mlm loss: 3.330919, speed: 0.447888 steps/s, speed: 3.583104 samples/s, speed: 1834.549223 tokens/s, learning rate: 2.480e-06, loss_scalings: 4398.047363, pp_loss: 3.335871
[INFO] 2021-07-09 16:50:26,912 [run_pretraining.py:  512]:	********exe.run_249******* 
[INFO] 2021-07-09 16:50:29,167 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:29,168 [run_pretraining.py:  534]:	loss/total_loss, 3.331594467163086, 250
[INFO] 2021-07-09 16:50:29,168 [run_pretraining.py:  535]:	loss/mlm_loss, 3.331594467163086, 250
[INFO] 2021-07-09 16:50:29,168 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4900000425986946e-06, 250
[INFO] 2021-07-09 16:50:29,169 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 250
[INFO] 2021-07-09 16:50:29,169 [run_pretraining.py:  558]:	worker_index: 5, step: 250, cost: 3.331594, mlm loss: 3.331594, speed: 0.443255 steps/s, speed: 3.546038 samples/s, speed: 1815.571528 tokens/s, learning rate: 2.490e-06, loss_scalings: 4398.047363, pp_loss: 3.352592
[INFO] 2021-07-09 16:50:29,169 [run_pretraining.py:  512]:	********exe.run_250******* 
[INFO] 2021-07-09 16:50:31,396 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:31,396 [run_pretraining.py:  534]:	loss/total_loss, 3.3903958797454834, 251
[INFO] 2021-07-09 16:50:31,396 [run_pretraining.py:  535]:	loss/mlm_loss, 3.3903958797454834, 251
[INFO] 2021-07-09 16:50:31,397 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.499999936844688e-06, 251
[INFO] 2021-07-09 16:50:31,397 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 251
[INFO] 2021-07-09 16:50:31,397 [run_pretraining.py:  558]:	worker_index: 5, step: 251, cost: 3.390396, mlm loss: 3.390396, speed: 0.448977 steps/s, speed: 3.591818 samples/s, speed: 1839.010744 tokens/s, learning rate: 2.500e-06, loss_scalings: 4398.047363, pp_loss: 3.377665
[INFO] 2021-07-09 16:50:31,397 [run_pretraining.py:  512]:	********exe.run_251******* 
[INFO] 2021-07-09 16:50:33,747 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:33,748 [run_pretraining.py:  534]:	loss/total_loss, 3.6269919872283936, 252
[INFO] 2021-07-09 16:50:33,748 [run_pretraining.py:  535]:	loss/mlm_loss, 3.6269919872283936, 252
[INFO] 2021-07-09 16:50:33,748 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5100000584643567e-06, 252
[INFO] 2021-07-09 16:50:33,748 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 252
[INFO] 2021-07-09 16:50:33,748 [run_pretraining.py:  558]:	worker_index: 5, step: 252, cost: 3.626992, mlm loss: 3.626992, speed: 0.425379 steps/s, speed: 3.403034 samples/s, speed: 1742.353382 tokens/s, learning rate: 2.510e-06, loss_scalings: 4398.047363, pp_loss: 3.422054
[INFO] 2021-07-09 16:50:33,748 [run_pretraining.py:  512]:	********exe.run_252******* 
[INFO] 2021-07-09 16:50:35,962 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:35,963 [run_pretraining.py:  534]:	loss/total_loss, 3.3617794513702393, 253
[INFO] 2021-07-09 16:50:35,964 [run_pretraining.py:  535]:	loss/mlm_loss, 3.3617794513702393, 253
[INFO] 2021-07-09 16:50:35,964 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.51999995271035e-06, 253
[INFO] 2021-07-09 16:50:35,964 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 253
[INFO] 2021-07-09 16:50:35,964 [run_pretraining.py:  558]:	worker_index: 5, step: 253, cost: 3.361779, mlm loss: 3.361779, speed: 0.451499 steps/s, speed: 3.611994 samples/s, speed: 1849.340985 tokens/s, learning rate: 2.520e-06, loss_scalings: 4398.047363, pp_loss: 3.417217
[INFO] 2021-07-09 16:50:35,964 [run_pretraining.py:  512]:	********exe.run_253******* 
[INFO] 2021-07-09 16:50:38,215 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:38,216 [run_pretraining.py:  534]:	loss/total_loss, 3.4420034885406494, 254
[INFO] 2021-07-09 16:50:38,216 [run_pretraining.py:  535]:	loss/mlm_loss, 3.4420034885406494, 254
[INFO] 2021-07-09 16:50:38,216 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5299998469563434e-06, 254
[INFO] 2021-07-09 16:50:38,216 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 254
[INFO] 2021-07-09 16:50:38,216 [run_pretraining.py:  558]:	worker_index: 5, step: 254, cost: 3.442003, mlm loss: 3.442003, speed: 0.444083 steps/s, speed: 3.552662 samples/s, speed: 1818.963012 tokens/s, learning rate: 2.530e-06, loss_scalings: 4398.047363, pp_loss: 3.458462
[INFO] 2021-07-09 16:50:38,216 [run_pretraining.py:  512]:	********exe.run_254******* 
[INFO] 2021-07-09 16:50:40,432 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:40,432 [run_pretraining.py:  534]:	loss/total_loss, 3.4643540382385254, 255
[INFO] 2021-07-09 16:50:40,433 [run_pretraining.py:  535]:	loss/mlm_loss, 3.4643540382385254, 255
[INFO] 2021-07-09 16:50:40,433 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.539999968576012e-06, 255
[INFO] 2021-07-09 16:50:40,433 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 255
[INFO] 2021-07-09 16:50:40,433 [run_pretraining.py:  558]:	worker_index: 5, step: 255, cost: 3.464354, mlm loss: 3.464354, speed: 0.451298 steps/s, speed: 3.610387 samples/s, speed: 1848.517982 tokens/s, learning rate: 2.540e-06, loss_scalings: 4398.047363, pp_loss: 3.431319
[INFO] 2021-07-09 16:50:40,433 [run_pretraining.py:  512]:	********exe.run_255******* 
[INFO] 2021-07-09 16:50:42,651 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:42,651 [run_pretraining.py:  534]:	loss/total_loss, 3.6554806232452393, 256
[INFO] 2021-07-09 16:50:42,651 [run_pretraining.py:  535]:	loss/mlm_loss, 3.6554806232452393, 256
[INFO] 2021-07-09 16:50:42,651 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5499998628220055e-06, 256
[INFO] 2021-07-09 16:50:42,652 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 256
[INFO] 2021-07-09 16:50:42,652 [run_pretraining.py:  558]:	worker_index: 5, step: 256, cost: 3.655481, mlm loss: 3.655481, speed: 0.450848 steps/s, speed: 3.606785 samples/s, speed: 1846.674062 tokens/s, learning rate: 2.550e-06, loss_scalings: 4398.047363, pp_loss: 3.523921
[INFO] 2021-07-09 16:50:42,652 [run_pretraining.py:  512]:	********exe.run_256******* 
[INFO] 2021-07-09 16:50:44,876 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:44,877 [run_pretraining.py:  534]:	loss/total_loss, 3.83141827583313, 257
[INFO] 2021-07-09 16:50:44,877 [run_pretraining.py:  535]:	loss/mlm_loss, 3.83141827583313, 257
[INFO] 2021-07-09 16:50:44,877 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.559999757067999e-06, 257
[INFO] 2021-07-09 16:50:44,877 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 257
[INFO] 2021-07-09 16:50:44,877 [run_pretraining.py:  558]:	worker_index: 5, step: 257, cost: 3.831418, mlm loss: 3.831418, speed: 0.449511 steps/s, speed: 3.596086 samples/s, speed: 1841.196275 tokens/s, learning rate: 2.560e-06, loss_scalings: 4398.047363, pp_loss: 3.589111
[INFO] 2021-07-09 16:50:44,877 [run_pretraining.py:  512]:	********exe.run_257******* 
[INFO] 2021-07-09 16:50:47,090 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:47,091 [run_pretraining.py:  534]:	loss/total_loss, 3.4980525970458984, 258
[INFO] 2021-07-09 16:50:47,091 [run_pretraining.py:  535]:	loss/mlm_loss, 3.4980525970458984, 258
[INFO] 2021-07-09 16:50:47,091 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5699998786876677e-06, 258
[INFO] 2021-07-09 16:50:47,091 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 258
[INFO] 2021-07-09 16:50:47,091 [run_pretraining.py:  558]:	worker_index: 5, step: 258, cost: 3.498053, mlm loss: 3.498053, speed: 0.451786 steps/s, speed: 3.614292 samples/s, speed: 1850.517264 tokens/s, learning rate: 2.570e-06, loss_scalings: 4398.047363, pp_loss: 3.599353
[INFO] 2021-07-09 16:50:47,091 [run_pretraining.py:  512]:	********exe.run_258******* 
[INFO] 2021-07-09 16:50:49,507 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:49,507 [run_pretraining.py:  534]:	loss/total_loss, 3.5154194831848145, 259
[INFO] 2021-07-09 16:50:49,507 [run_pretraining.py:  535]:	loss/mlm_loss, 3.5154194831848145, 259
[INFO] 2021-07-09 16:50:49,508 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5800000003073364e-06, 259
[INFO] 2021-07-09 16:50:49,508 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 259
[INFO] 2021-07-09 16:50:49,508 [run_pretraining.py:  558]:	worker_index: 5, step: 259, cost: 3.515419, mlm loss: 3.515419, speed: 0.413907 steps/s, speed: 3.311253 samples/s, speed: 1695.361305 tokens/s, learning rate: 2.580e-06, loss_scalings: 4398.047363, pp_loss: 3.617014
[INFO] 2021-07-09 16:50:49,508 [run_pretraining.py:  512]:	********exe.run_259******* 
[INFO] 2021-07-09 16:50:51,869 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:51,869 [run_pretraining.py:  534]:	loss/total_loss, 3.5750813484191895, 260
[INFO] 2021-07-09 16:50:51,869 [run_pretraining.py:  535]:	loss/mlm_loss, 3.5750813484191895, 260
[INFO] 2021-07-09 16:50:51,869 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.58999989455333e-06, 260
[INFO] 2021-07-09 16:50:51,870 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 260
[INFO] 2021-07-09 16:50:51,870 [run_pretraining.py:  558]:	worker_index: 5, step: 260, cost: 3.575081, mlm loss: 3.575081, speed: 0.423516 steps/s, speed: 3.388130 samples/s, speed: 1734.722480 tokens/s, learning rate: 2.590e-06, loss_scalings: 4398.047363, pp_loss: 3.606701
[INFO] 2021-07-09 16:50:51,870 [run_pretraining.py:  512]:	********exe.run_260******* 
[INFO] 2021-07-09 16:50:54,305 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:54,306 [run_pretraining.py:  534]:	loss/total_loss, 3.893580675125122, 261
[INFO] 2021-07-09 16:50:54,306 [run_pretraining.py:  535]:	loss/mlm_loss, 3.893580675125122, 261
[INFO] 2021-07-09 16:50:54,306 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6000000161729986e-06, 261
[INFO] 2021-07-09 16:50:54,306 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 261
[INFO] 2021-07-09 16:50:54,306 [run_pretraining.py:  558]:	worker_index: 5, step: 261, cost: 3.893581, mlm loss: 3.893581, speed: 0.410515 steps/s, speed: 3.284117 samples/s, speed: 1681.467792 tokens/s, learning rate: 2.600e-06, loss_scalings: 3518.437988, pp_loss: 3.731005
[INFO] 2021-07-09 16:50:54,306 [run_pretraining.py:  512]:	********exe.run_261******* 
[INFO] 2021-07-09 16:50:56,793 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:56,794 [run_pretraining.py:  534]:	loss/total_loss, 3.9490745067596436, 262
[INFO] 2021-07-09 16:50:56,794 [run_pretraining.py:  535]:	loss/mlm_loss, 3.9490745067596436, 262
[INFO] 2021-07-09 16:50:56,794 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.609999910418992e-06, 262
[INFO] 2021-07-09 16:50:56,794 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 262
[INFO] 2021-07-09 16:50:56,794 [run_pretraining.py:  558]:	worker_index: 5, step: 262, cost: 3.949075, mlm loss: 3.949075, speed: 0.402110 steps/s, speed: 3.216877 samples/s, speed: 1647.040959 tokens/s, learning rate: 2.610e-06, loss_scalings: 3518.437988, pp_loss: 3.728920
[INFO] 2021-07-09 16:50:56,794 [run_pretraining.py:  512]:	********exe.run_262******* 
[INFO] 2021-07-09 16:50:59,271 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:50:59,272 [run_pretraining.py:  534]:	loss/total_loss, 3.9706032276153564, 263
[INFO] 2021-07-09 16:50:59,272 [run_pretraining.py:  535]:	loss/mlm_loss, 3.9706032276153564, 263
[INFO] 2021-07-09 16:50:59,272 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6200000320386607e-06, 263
[INFO] 2021-07-09 16:50:59,272 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 263
[INFO] 2021-07-09 16:50:59,272 [run_pretraining.py:  558]:	worker_index: 5, step: 263, cost: 3.970603, mlm loss: 3.970603, speed: 0.403622 steps/s, speed: 3.228974 samples/s, speed: 1653.234517 tokens/s, learning rate: 2.620e-06, loss_scalings: 3518.437988, pp_loss: 3.752948
[INFO] 2021-07-09 16:50:59,272 [run_pretraining.py:  512]:	********exe.run_263******* 
[INFO] 2021-07-09 16:51:01,500 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:01,501 [run_pretraining.py:  534]:	loss/total_loss, 3.733030319213867, 264
[INFO] 2021-07-09 16:51:01,501 [run_pretraining.py:  535]:	loss/mlm_loss, 3.733030319213867, 264
[INFO] 2021-07-09 16:51:01,501 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.629999926284654e-06, 264
[INFO] 2021-07-09 16:51:01,501 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 264
[INFO] 2021-07-09 16:51:01,501 [run_pretraining.py:  558]:	worker_index: 5, step: 264, cost: 3.733030, mlm loss: 3.733030, speed: 0.448774 steps/s, speed: 3.590189 samples/s, speed: 1838.176847 tokens/s, learning rate: 2.630e-06, loss_scalings: 3518.437988, pp_loss: 3.802867
[INFO] 2021-07-09 16:51:01,501 [run_pretraining.py:  512]:	********exe.run_264******* 
[INFO] 2021-07-09 16:51:03,736 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:03,737 [run_pretraining.py:  534]:	loss/total_loss, 3.742250680923462, 265
[INFO] 2021-07-09 16:51:03,737 [run_pretraining.py:  535]:	loss/mlm_loss, 3.742250680923462, 265
[INFO] 2021-07-09 16:51:03,737 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6399998205306474e-06, 265
[INFO] 2021-07-09 16:51:03,737 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 265
[INFO] 2021-07-09 16:51:03,737 [run_pretraining.py:  558]:	worker_index: 5, step: 265, cost: 3.742251, mlm loss: 3.742251, speed: 0.447429 steps/s, speed: 3.579431 samples/s, speed: 1832.668925 tokens/s, learning rate: 2.640e-06, loss_scalings: 3518.437988, pp_loss: 3.721901
[INFO] 2021-07-09 16:51:03,737 [run_pretraining.py:  512]:	********exe.run_265******* 
[INFO] 2021-07-09 16:51:05,962 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:05,962 [run_pretraining.py:  534]:	loss/total_loss, 3.6859850883483887, 266
[INFO] 2021-07-09 16:51:05,962 [run_pretraining.py:  535]:	loss/mlm_loss, 3.6859850883483887, 266
[INFO] 2021-07-09 16:51:05,962 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.649999942150316e-06, 266
[INFO] 2021-07-09 16:51:05,962 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 266
[INFO] 2021-07-09 16:51:05,962 [run_pretraining.py:  558]:	worker_index: 5, step: 266, cost: 3.685985, mlm loss: 3.685985, speed: 0.449473 steps/s, speed: 3.595781 samples/s, speed: 1841.040007 tokens/s, learning rate: 2.650e-06, loss_scalings: 3518.437988, pp_loss: 3.765887
[INFO] 2021-07-09 16:51:05,963 [run_pretraining.py:  512]:	********exe.run_266******* 
[INFO] 2021-07-09 16:51:08,181 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:08,182 [run_pretraining.py:  534]:	loss/total_loss, 3.6702890396118164, 267
[INFO] 2021-07-09 16:51:08,182 [run_pretraining.py:  535]:	loss/mlm_loss, 3.6702890396118164, 267
[INFO] 2021-07-09 16:51:08,182 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6599998363963095e-06, 267
[INFO] 2021-07-09 16:51:08,182 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 267
[INFO] 2021-07-09 16:51:08,182 [run_pretraining.py:  558]:	worker_index: 5, step: 267, cost: 3.670289, mlm loss: 3.670289, speed: 0.450699 steps/s, speed: 3.605594 samples/s, speed: 1846.064273 tokens/s, learning rate: 2.660e-06, loss_scalings: 3518.437988, pp_loss: 3.724400
[INFO] 2021-07-09 16:51:08,182 [run_pretraining.py:  512]:	********exe.run_267******* 
[INFO] 2021-07-09 16:51:10,444 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:10,445 [run_pretraining.py:  534]:	loss/total_loss, 3.6072838306427, 268
[INFO] 2021-07-09 16:51:10,445 [run_pretraining.py:  535]:	loss/mlm_loss, 3.6072838306427, 268
[INFO] 2021-07-09 16:51:10,445 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6699999580159783e-06, 268
[INFO] 2021-07-09 16:51:10,445 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 268
[INFO] 2021-07-09 16:51:10,445 [run_pretraining.py:  558]:	worker_index: 5, step: 268, cost: 3.607284, mlm loss: 3.607284, speed: 0.441955 steps/s, speed: 3.535641 samples/s, speed: 1810.248400 tokens/s, learning rate: 2.670e-06, loss_scalings: 3518.437988, pp_loss: 3.640540
[INFO] 2021-07-09 16:51:10,445 [run_pretraining.py:  512]:	********exe.run_268******* 
[INFO] 2021-07-09 16:51:12,653 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:12,653 [run_pretraining.py:  534]:	loss/total_loss, 3.6238934993743896, 269
[INFO] 2021-07-09 16:51:12,653 [run_pretraining.py:  535]:	loss/mlm_loss, 3.6238934993743896, 269
[INFO] 2021-07-09 16:51:12,653 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6799998522619717e-06, 269
[INFO] 2021-07-09 16:51:12,653 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 269
[INFO] 2021-07-09 16:51:12,653 [run_pretraining.py:  558]:	worker_index: 5, step: 269, cost: 3.623893, mlm loss: 3.623893, speed: 0.453033 steps/s, speed: 3.624261 samples/s, speed: 1855.621722 tokens/s, learning rate: 2.680e-06, loss_scalings: 3518.437988, pp_loss: 3.631792
[INFO] 2021-07-09 16:51:12,653 [run_pretraining.py:  512]:	********exe.run_269******* 
[INFO] 2021-07-09 16:51:14,854 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:14,854 [run_pretraining.py:  534]:	loss/total_loss, 3.568549156188965, 270
[INFO] 2021-07-09 16:51:14,854 [run_pretraining.py:  535]:	loss/mlm_loss, 3.568549156188965, 270
[INFO] 2021-07-09 16:51:14,855 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6899999738816405e-06, 270
[INFO] 2021-07-09 16:51:14,855 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 270
[INFO] 2021-07-09 16:51:14,855 [run_pretraining.py:  558]:	worker_index: 5, step: 270, cost: 3.568549, mlm loss: 3.568549, speed: 0.454402 steps/s, speed: 3.635219 samples/s, speed: 1861.232187 tokens/s, learning rate: 2.690e-06, loss_scalings: 3518.437988, pp_loss: 3.590899
[INFO] 2021-07-09 16:51:14,855 [run_pretraining.py:  512]:	********exe.run_270******* 
[INFO] 2021-07-09 16:51:17,070 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:17,071 [run_pretraining.py:  534]:	loss/total_loss, 3.662353038787842, 271
[INFO] 2021-07-09 16:51:17,071 [run_pretraining.py:  535]:	loss/mlm_loss, 3.662353038787842, 271
[INFO] 2021-07-09 16:51:17,071 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7000000955013093e-06, 271
[INFO] 2021-07-09 16:51:17,071 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 271
[INFO] 2021-07-09 16:51:17,071 [run_pretraining.py:  558]:	worker_index: 5, step: 271, cost: 3.662353, mlm loss: 3.662353, speed: 0.451352 steps/s, speed: 3.610818 samples/s, speed: 1848.738983 tokens/s, learning rate: 2.700e-06, loss_scalings: 3518.437988, pp_loss: 3.601182
[INFO] 2021-07-09 16:51:17,071 [run_pretraining.py:  512]:	********exe.run_271******* 
[INFO] 2021-07-09 16:51:19,297 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:19,298 [run_pretraining.py:  534]:	loss/total_loss, 3.52282977104187, 272
[INFO] 2021-07-09 16:51:19,298 [run_pretraining.py:  535]:	loss/mlm_loss, 3.52282977104187, 272
[INFO] 2021-07-09 16:51:19,298 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7099999897473026e-06, 272
[INFO] 2021-07-09 16:51:19,298 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 272
[INFO] 2021-07-09 16:51:19,298 [run_pretraining.py:  558]:	worker_index: 5, step: 272, cost: 3.522830, mlm loss: 3.522830, speed: 0.449133 steps/s, speed: 3.593067 samples/s, speed: 1839.650355 tokens/s, learning rate: 2.710e-06, loss_scalings: 3518.437988, pp_loss: 3.541169
[INFO] 2021-07-09 16:51:19,298 [run_pretraining.py:  512]:	********exe.run_272******* 
[INFO] 2021-07-09 16:51:21,531 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:21,532 [run_pretraining.py:  534]:	loss/total_loss, 3.519390106201172, 273
[INFO] 2021-07-09 16:51:21,532 [run_pretraining.py:  535]:	loss/mlm_loss, 3.519390106201172, 273
[INFO] 2021-07-09 16:51:21,532 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.719999883993296e-06, 273
[INFO] 2021-07-09 16:51:21,532 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 273
[INFO] 2021-07-09 16:51:21,532 [run_pretraining.py:  558]:	worker_index: 5, step: 273, cost: 3.519390, mlm loss: 3.519390, speed: 0.447794 steps/s, speed: 3.582356 samples/s, speed: 1834.166118 tokens/s, learning rate: 2.720e-06, loss_scalings: 3518.437988, pp_loss: 3.507888
[INFO] 2021-07-09 16:51:21,532 [run_pretraining.py:  512]:	********exe.run_273******* 
[INFO] 2021-07-09 16:51:23,787 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:23,788 [run_pretraining.py:  534]:	loss/total_loss, 3.428765296936035, 274
[INFO] 2021-07-09 16:51:23,788 [run_pretraining.py:  535]:	loss/mlm_loss, 3.428765296936035, 274
[INFO] 2021-07-09 16:51:23,788 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7300000056129647e-06, 274
[INFO] 2021-07-09 16:51:23,788 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 274
[INFO] 2021-07-09 16:51:23,788 [run_pretraining.py:  558]:	worker_index: 5, step: 274, cost: 3.428765, mlm loss: 3.428765, speed: 0.443411 steps/s, speed: 3.547288 samples/s, speed: 1816.211256 tokens/s, learning rate: 2.730e-06, loss_scalings: 3518.437988, pp_loss: 3.530979
[INFO] 2021-07-09 16:51:23,788 [run_pretraining.py:  512]:	********exe.run_274******* 
[INFO] 2021-07-09 16:51:26,013 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:26,013 [run_pretraining.py:  534]:	loss/total_loss, 3.42954683303833, 275
[INFO] 2021-07-09 16:51:26,013 [run_pretraining.py:  535]:	loss/mlm_loss, 3.42954683303833, 275
[INFO] 2021-07-09 16:51:26,013 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.739999899858958e-06, 275
[INFO] 2021-07-09 16:51:26,013 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 275
[INFO] 2021-07-09 16:51:26,014 [run_pretraining.py:  558]:	worker_index: 5, step: 275, cost: 3.429547, mlm loss: 3.429547, speed: 0.449473 steps/s, speed: 3.595787 samples/s, speed: 1841.043164 tokens/s, learning rate: 2.740e-06, loss_scalings: 3518.437988, pp_loss: 3.405878
[INFO] 2021-07-09 16:51:26,014 [run_pretraining.py:  512]:	********exe.run_275******* 
[INFO] 2021-07-09 16:51:28,264 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:28,264 [run_pretraining.py:  534]:	loss/total_loss, 3.3542349338531494, 276
[INFO] 2021-07-09 16:51:28,264 [run_pretraining.py:  535]:	loss/mlm_loss, 3.3542349338531494, 276
[INFO] 2021-07-09 16:51:28,264 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.750000021478627e-06, 276
[INFO] 2021-07-09 16:51:28,264 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 276
[INFO] 2021-07-09 16:51:28,265 [run_pretraining.py:  558]:	worker_index: 5, step: 276, cost: 3.354235, mlm loss: 3.354235, speed: 0.444378 steps/s, speed: 3.555025 samples/s, speed: 1820.172880 tokens/s, learning rate: 2.750e-06, loss_scalings: 3518.437988, pp_loss: 3.454364
[INFO] 2021-07-09 16:51:28,265 [run_pretraining.py:  512]:	********exe.run_276******* 
[INFO] 2021-07-09 16:51:30,487 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:30,488 [run_pretraining.py:  534]:	loss/total_loss, 3.3433475494384766, 277
[INFO] 2021-07-09 16:51:30,488 [run_pretraining.py:  535]:	loss/mlm_loss, 3.3433475494384766, 277
[INFO] 2021-07-09 16:51:30,488 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7599999157246202e-06, 277
[INFO] 2021-07-09 16:51:30,488 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 277
[INFO] 2021-07-09 16:51:30,488 [run_pretraining.py:  558]:	worker_index: 5, step: 277, cost: 3.343348, mlm loss: 3.343348, speed: 0.449802 steps/s, speed: 3.598419 samples/s, speed: 1842.390663 tokens/s, learning rate: 2.760e-06, loss_scalings: 3518.437988, pp_loss: 3.351404
[INFO] 2021-07-09 16:51:30,489 [run_pretraining.py:  512]:	********exe.run_277******* 
[INFO] 2021-07-09 16:51:32,767 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:32,767 [run_pretraining.py:  534]:	loss/total_loss, 3.5959391593933105, 278
[INFO] 2021-07-09 16:51:32,767 [run_pretraining.py:  535]:	loss/mlm_loss, 3.5959391593933105, 278
[INFO] 2021-07-09 16:51:32,768 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7699998099706136e-06, 278
[INFO] 2021-07-09 16:51:32,768 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 278
[INFO] 2021-07-09 16:51:32,768 [run_pretraining.py:  558]:	worker_index: 5, step: 278, cost: 3.595939, mlm loss: 3.595939, speed: 0.438883 steps/s, speed: 3.511066 samples/s, speed: 1797.665945 tokens/s, learning rate: 2.770e-06, loss_scalings: 3518.437988, pp_loss: 3.398764
[INFO] 2021-07-09 16:51:32,768 [run_pretraining.py:  512]:	********exe.run_278******* 
[INFO] 2021-07-09 16:51:35,097 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:35,098 [run_pretraining.py:  534]:	loss/total_loss, 3.357621192932129, 279
[INFO] 2021-07-09 16:51:35,098 [run_pretraining.py:  535]:	loss/mlm_loss, 3.357621192932129, 279
[INFO] 2021-07-09 16:51:35,098 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7799999315902824e-06, 279
[INFO] 2021-07-09 16:51:35,098 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 279
[INFO] 2021-07-09 16:51:35,098 [run_pretraining.py:  558]:	worker_index: 5, step: 279, cost: 3.357621, mlm loss: 3.357621, speed: 0.429240 steps/s, speed: 3.433921 samples/s, speed: 1758.167552 tokens/s, learning rate: 2.780e-06, loss_scalings: 2814.750488, pp_loss: 3.381352
[INFO] 2021-07-09 16:51:35,098 [run_pretraining.py:  512]:	********exe.run_279******* 
[INFO] 2021-07-09 16:51:37,323 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:37,324 [run_pretraining.py:  534]:	loss/total_loss, 3.50628399848938, 280
[INFO] 2021-07-09 16:51:37,324 [run_pretraining.py:  535]:	loss/mlm_loss, 3.50628399848938, 280
[INFO] 2021-07-09 16:51:37,324 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7899998258362757e-06, 280
[INFO] 2021-07-09 16:51:37,324 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 280
[INFO] 2021-07-09 16:51:37,324 [run_pretraining.py:  558]:	worker_index: 5, step: 280, cost: 3.506284, mlm loss: 3.506284, speed: 0.449353 steps/s, speed: 3.594823 samples/s, speed: 1840.549476 tokens/s, learning rate: 2.790e-06, loss_scalings: 2814.750488, pp_loss: 3.430247
[INFO] 2021-07-09 16:51:37,324 [run_pretraining.py:  512]:	********exe.run_280******* 
[INFO] 2021-07-09 16:51:39,556 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:39,556 [run_pretraining.py:  534]:	loss/total_loss, 3.3539371490478516, 281
[INFO] 2021-07-09 16:51:39,556 [run_pretraining.py:  535]:	loss/mlm_loss, 3.3539371490478516, 281
[INFO] 2021-07-09 16:51:39,557 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7999999474559445e-06, 281
[INFO] 2021-07-09 16:51:39,557 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 281
[INFO] 2021-07-09 16:51:39,557 [run_pretraining.py:  558]:	worker_index: 5, step: 281, cost: 3.353937, mlm loss: 3.353937, speed: 0.448077 steps/s, speed: 3.584612 samples/s, speed: 1835.321598 tokens/s, learning rate: 2.800e-06, loss_scalings: 2814.750488, pp_loss: 3.401923
[INFO] 2021-07-09 16:51:39,557 [run_pretraining.py:  512]:	********exe.run_281******* 
[INFO] 2021-07-09 16:51:41,771 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:41,772 [run_pretraining.py:  534]:	loss/total_loss, 3.735985279083252, 282
[INFO] 2021-07-09 16:51:41,772 [run_pretraining.py:  535]:	loss/mlm_loss, 3.735985279083252, 282
[INFO] 2021-07-09 16:51:41,772 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8100000690756133e-06, 282
[INFO] 2021-07-09 16:51:41,772 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 282
[INFO] 2021-07-09 16:51:41,772 [run_pretraining.py:  558]:	worker_index: 5, step: 282, cost: 3.735985, mlm loss: 3.735985, speed: 0.451455 steps/s, speed: 3.611639 samples/s, speed: 1849.159249 tokens/s, learning rate: 2.810e-06, loss_scalings: 2814.750488, pp_loss: 3.449242
[INFO] 2021-07-09 16:51:41,773 [run_pretraining.py:  512]:	********exe.run_282******* 
[INFO] 2021-07-09 16:51:43,994 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:43,995 [run_pretraining.py:  534]:	loss/total_loss, 3.6138358116149902, 283
[INFO] 2021-07-09 16:51:43,995 [run_pretraining.py:  535]:	loss/mlm_loss, 3.6138358116149902, 283
[INFO] 2021-07-09 16:51:43,995 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8199999633216066e-06, 283
[INFO] 2021-07-09 16:51:43,995 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 283
[INFO] 2021-07-09 16:51:43,995 [run_pretraining.py:  558]:	worker_index: 5, step: 283, cost: 3.613836, mlm loss: 3.613836, speed: 0.449981 steps/s, speed: 3.599846 samples/s, speed: 1843.121209 tokens/s, learning rate: 2.820e-06, loss_scalings: 2814.750488, pp_loss: 3.465948
[INFO] 2021-07-09 16:51:43,996 [run_pretraining.py:  512]:	********exe.run_283******* 
[INFO] 2021-07-09 16:51:46,231 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:46,232 [run_pretraining.py:  534]:	loss/total_loss, 3.4601736068725586, 284
[INFO] 2021-07-09 16:51:46,232 [run_pretraining.py:  535]:	loss/mlm_loss, 3.4601736068725586, 284
[INFO] 2021-07-09 16:51:46,232 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8299998575676e-06, 284
[INFO] 2021-07-09 16:51:46,232 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 284
[INFO] 2021-07-09 16:51:46,232 [run_pretraining.py:  558]:	worker_index: 5, step: 284, cost: 3.460174, mlm loss: 3.460174, speed: 0.447226 steps/s, speed: 3.577805 samples/s, speed: 1831.836276 tokens/s, learning rate: 2.830e-06, loss_scalings: 2814.750488, pp_loss: 3.505431
[INFO] 2021-07-09 16:51:46,232 [run_pretraining.py:  512]:	********exe.run_284******* 
[INFO] 2021-07-09 16:51:48,446 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:48,447 [run_pretraining.py:  534]:	loss/total_loss, 3.550609588623047, 285
[INFO] 2021-07-09 16:51:48,447 [run_pretraining.py:  535]:	loss/mlm_loss, 3.550609588623047, 285
[INFO] 2021-07-09 16:51:48,447 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8399999791872688e-06, 285
[INFO] 2021-07-09 16:51:48,447 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 285
[INFO] 2021-07-09 16:51:48,447 [run_pretraining.py:  558]:	worker_index: 5, step: 285, cost: 3.550610, mlm loss: 3.550610, speed: 0.451563 steps/s, speed: 3.612502 samples/s, speed: 1849.600813 tokens/s, learning rate: 2.840e-06, loss_scalings: 2814.750488, pp_loss: 3.573329
[INFO] 2021-07-09 16:51:48,447 [run_pretraining.py:  512]:	********exe.run_285******* 
[INFO] 2021-07-09 16:51:50,652 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:50,653 [run_pretraining.py:  534]:	loss/total_loss, 3.615185499191284, 286
[INFO] 2021-07-09 16:51:50,653 [run_pretraining.py:  535]:	loss/mlm_loss, 3.615185499191284, 286
[INFO] 2021-07-09 16:51:50,653 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.849999873433262e-06, 286
[INFO] 2021-07-09 16:51:50,653 [run_pretraining.py:  539]:	lr/loss_scaling, 2251.800537109375, 286
[INFO] 2021-07-09 16:51:50,653 [run_pretraining.py:  558]:	worker_index: 5, step: 286, cost: 3.615185, mlm loss: 3.615185, speed: 0.453537 steps/s, speed: 3.628294 samples/s, speed: 1857.686624 tokens/s, learning rate: 2.850e-06, loss_scalings: 2251.800537, pp_loss: 3.628574
[INFO] 2021-07-09 16:51:50,653 [run_pretraining.py:  512]:	********exe.run_286******* 
[INFO] 2021-07-09 16:51:52,856 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:52,857 [run_pretraining.py:  534]:	loss/total_loss, 3.76229190826416, 287
[INFO] 2021-07-09 16:51:52,857 [run_pretraining.py:  535]:	loss/mlm_loss, 3.76229190826416, 287
[INFO] 2021-07-09 16:51:52,857 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.859999995052931e-06, 287
[INFO] 2021-07-09 16:51:52,857 [run_pretraining.py:  539]:	lr/loss_scaling, 2251.800537109375, 287
[INFO] 2021-07-09 16:51:52,857 [run_pretraining.py:  558]:	worker_index: 5, step: 287, cost: 3.762292, mlm loss: 3.762292, speed: 0.453844 steps/s, speed: 3.630755 samples/s, speed: 1858.946762 tokens/s, learning rate: 2.860e-06, loss_scalings: 2251.800537, pp_loss: 3.689035
[INFO] 2021-07-09 16:51:52,857 [run_pretraining.py:  512]:	********exe.run_287******* 
[INFO] 2021-07-09 16:51:55,079 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:55,080 [run_pretraining.py:  534]:	loss/total_loss, 3.6972105503082275, 288
[INFO] 2021-07-09 16:51:55,080 [run_pretraining.py:  535]:	loss/mlm_loss, 3.6972105503082275, 288
[INFO] 2021-07-09 16:51:55,080 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8699998892989242e-06, 288
[INFO] 2021-07-09 16:51:55,080 [run_pretraining.py:  539]:	lr/loss_scaling, 2251.800537109375, 288
[INFO] 2021-07-09 16:51:55,080 [run_pretraining.py:  558]:	worker_index: 5, step: 288, cost: 3.697211, mlm loss: 3.697211, speed: 0.450020 steps/s, speed: 3.600163 samples/s, speed: 1843.283368 tokens/s, learning rate: 2.870e-06, loss_scalings: 2251.800537, pp_loss: 3.781713
[INFO] 2021-07-09 16:51:55,080 [run_pretraining.py:  512]:	********exe.run_288******* 
[INFO] 2021-07-09 16:51:57,304 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:57,305 [run_pretraining.py:  534]:	loss/total_loss, 4.049005031585693, 289
[INFO] 2021-07-09 16:51:57,305 [run_pretraining.py:  535]:	loss/mlm_loss, 4.049005031585693, 289
[INFO] 2021-07-09 16:51:57,305 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8799997835449176e-06, 289
[INFO] 2021-07-09 16:51:57,305 [run_pretraining.py:  539]:	lr/loss_scaling, 2251.800537109375, 289
[INFO] 2021-07-09 16:51:57,305 [run_pretraining.py:  558]:	worker_index: 5, step: 289, cost: 4.049005, mlm loss: 4.049005, speed: 0.449481 steps/s, speed: 3.595846 samples/s, speed: 1841.073153 tokens/s, learning rate: 2.880e-06, loss_scalings: 2251.800537, pp_loss: 3.843731
[INFO] 2021-07-09 16:51:57,306 [run_pretraining.py:  512]:	********exe.run_289******* 
[INFO] 2021-07-09 16:51:59,584 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:51:59,585 [run_pretraining.py:  534]:	loss/total_loss, 3.807799816131592, 290
[INFO] 2021-07-09 16:51:59,585 [run_pretraining.py:  535]:	loss/mlm_loss, 3.807799816131592, 290
[INFO] 2021-07-09 16:51:59,585 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8899999051645864e-06, 290
[INFO] 2021-07-09 16:51:59,585 [run_pretraining.py:  539]:	lr/loss_scaling, 2251.800537109375, 290
[INFO] 2021-07-09 16:51:59,585 [run_pretraining.py:  558]:	worker_index: 5, step: 290, cost: 3.807800, mlm loss: 3.807800, speed: 0.438741 steps/s, speed: 3.509931 samples/s, speed: 1797.084891 tokens/s, learning rate: 2.890e-06, loss_scalings: 2251.800537, pp_loss: 3.881449
[INFO] 2021-07-09 16:51:59,585 [run_pretraining.py:  512]:	********exe.run_290******* 
[INFO] 2021-07-09 16:52:01,774 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:01,774 [run_pretraining.py:  534]:	loss/total_loss, 3.956747055053711, 291
[INFO] 2021-07-09 16:52:01,775 [run_pretraining.py:  535]:	loss/mlm_loss, 3.956747055053711, 291
[INFO] 2021-07-09 16:52:01,775 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8999997994105797e-06, 291
[INFO] 2021-07-09 16:52:01,775 [run_pretraining.py:  539]:	lr/loss_scaling, 2251.800537109375, 291
[INFO] 2021-07-09 16:52:01,775 [run_pretraining.py:  558]:	worker_index: 5, step: 291, cost: 3.956747, mlm loss: 3.956747, speed: 0.456875 steps/s, speed: 3.654996 samples/s, speed: 1871.357993 tokens/s, learning rate: 2.900e-06, loss_scalings: 2251.800537, pp_loss: 3.953169
[INFO] 2021-07-09 16:52:01,775 [run_pretraining.py:  512]:	********exe.run_291******* 
[INFO] 2021-07-09 16:52:04,009 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:04,010 [run_pretraining.py:  534]:	loss/total_loss, 4.212672233581543, 292
[INFO] 2021-07-09 16:52:04,010 [run_pretraining.py:  535]:	loss/mlm_loss, 4.212672233581543, 292
[INFO] 2021-07-09 16:52:04,010 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9099999210302485e-06, 292
[INFO] 2021-07-09 16:52:04,010 [run_pretraining.py:  539]:	lr/loss_scaling, 2251.800537109375, 292
[INFO] 2021-07-09 16:52:04,010 [run_pretraining.py:  558]:	worker_index: 5, step: 292, cost: 4.212672, mlm loss: 4.212672, speed: 0.447516 steps/s, speed: 3.580128 samples/s, speed: 1833.025784 tokens/s, learning rate: 2.910e-06, loss_scalings: 2251.800537, pp_loss: 4.032985
[INFO] 2021-07-09 16:52:04,010 [run_pretraining.py:  512]:	********exe.run_292******* 
[INFO] 2021-07-09 16:52:06,244 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:06,244 [run_pretraining.py:  534]:	loss/total_loss, 4.110448837280273, 293
[INFO] 2021-07-09 16:52:06,244 [run_pretraining.py:  535]:	loss/mlm_loss, 4.110448837280273, 293
[INFO] 2021-07-09 16:52:06,244 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9200000426499173e-06, 293
[INFO] 2021-07-09 16:52:06,245 [run_pretraining.py:  539]:	lr/loss_scaling, 2251.800537109375, 293
[INFO] 2021-07-09 16:52:06,245 [run_pretraining.py:  558]:	worker_index: 5, step: 293, cost: 4.110449, mlm loss: 4.110449, speed: 0.447662 steps/s, speed: 3.581299 samples/s, speed: 1833.624835 tokens/s, learning rate: 2.920e-06, loss_scalings: 2251.800537, pp_loss: 4.080664
[INFO] 2021-07-09 16:52:06,245 [run_pretraining.py:  512]:	********exe.run_293******* 
[INFO] 2021-07-09 16:52:08,487 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:08,488 [run_pretraining.py:  534]:	loss/total_loss, 4.238584518432617, 294
[INFO] 2021-07-09 16:52:08,488 [run_pretraining.py:  535]:	loss/mlm_loss, 4.238584518432617, 294
[INFO] 2021-07-09 16:52:08,488 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9299999368959107e-06, 294
[INFO] 2021-07-09 16:52:08,488 [run_pretraining.py:  539]:	lr/loss_scaling, 1801.4404296875, 294
[INFO] 2021-07-09 16:52:08,488 [run_pretraining.py:  558]:	worker_index: 5, step: 294, cost: 4.238585, mlm loss: 4.238585, speed: 0.445905 steps/s, speed: 3.567242 samples/s, speed: 1826.427974 tokens/s, learning rate: 2.930e-06, loss_scalings: 1801.440430, pp_loss: 4.236460
[INFO] 2021-07-09 16:52:08,488 [run_pretraining.py:  512]:	********exe.run_294******* 
[INFO] 2021-07-09 16:52:10,710 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:10,710 [run_pretraining.py:  534]:	loss/total_loss, 4.390837669372559, 295
[INFO] 2021-07-09 16:52:10,710 [run_pretraining.py:  535]:	loss/mlm_loss, 4.390837669372559, 295
[INFO] 2021-07-09 16:52:10,710 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9400000585155794e-06, 295
[INFO] 2021-07-09 16:52:10,711 [run_pretraining.py:  539]:	lr/loss_scaling, 1801.4404296875, 295
[INFO] 2021-07-09 16:52:10,711 [run_pretraining.py:  558]:	worker_index: 5, step: 295, cost: 4.390838, mlm loss: 4.390838, speed: 0.450058 steps/s, speed: 3.600461 samples/s, speed: 1843.436258 tokens/s, learning rate: 2.940e-06, loss_scalings: 1801.440430, pp_loss: 4.273141
[INFO] 2021-07-09 16:52:10,711 [run_pretraining.py:  512]:	********exe.run_295******* 
[INFO] 2021-07-09 16:52:13,019 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:13,020 [run_pretraining.py:  534]:	loss/total_loss, 4.347524166107178, 296
[INFO] 2021-07-09 16:52:13,020 [run_pretraining.py:  535]:	loss/mlm_loss, 4.347524166107178, 296
[INFO] 2021-07-09 16:52:13,020 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9499999527615728e-06, 296
[INFO] 2021-07-09 16:52:13,020 [run_pretraining.py:  539]:	lr/loss_scaling, 1801.4404296875, 296
[INFO] 2021-07-09 16:52:13,020 [run_pretraining.py:  558]:	worker_index: 5, step: 296, cost: 4.347524, mlm loss: 4.347524, speed: 0.433118 steps/s, speed: 3.464947 samples/s, speed: 1774.052659 tokens/s, learning rate: 2.950e-06, loss_scalings: 1801.440430, pp_loss: 4.402379
[INFO] 2021-07-09 16:52:13,020 [run_pretraining.py:  512]:	********exe.run_296******* 
[INFO] 2021-07-09 16:52:15,332 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:15,332 [run_pretraining.py:  534]:	loss/total_loss, 4.426752090454102, 297
[INFO] 2021-07-09 16:52:15,332 [run_pretraining.py:  535]:	loss/mlm_loss, 4.426752090454102, 297
[INFO] 2021-07-09 16:52:15,332 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.959999847007566e-06, 297
[INFO] 2021-07-09 16:52:15,333 [run_pretraining.py:  539]:	lr/loss_scaling, 1801.4404296875, 297
[INFO] 2021-07-09 16:52:15,333 [run_pretraining.py:  558]:	worker_index: 5, step: 297, cost: 4.426752, mlm loss: 4.426752, speed: 0.432561 steps/s, speed: 3.460491 samples/s, speed: 1771.771341 tokens/s, learning rate: 2.960e-06, loss_scalings: 1801.440430, pp_loss: 4.534831
[INFO] 2021-07-09 16:52:15,333 [run_pretraining.py:  512]:	********exe.run_297******* 
[INFO] 2021-07-09 16:52:17,547 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:17,548 [run_pretraining.py:  534]:	loss/total_loss, 4.789388179779053, 298
[INFO] 2021-07-09 16:52:17,548 [run_pretraining.py:  535]:	loss/mlm_loss, 4.789388179779053, 298
[INFO] 2021-07-09 16:52:17,548 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.969999968627235e-06, 298
[INFO] 2021-07-09 16:52:17,548 [run_pretraining.py:  539]:	lr/loss_scaling, 1801.4404296875, 298
[INFO] 2021-07-09 16:52:17,548 [run_pretraining.py:  558]:	worker_index: 5, step: 298, cost: 4.789388, mlm loss: 4.789388, speed: 0.451532 steps/s, speed: 3.612258 samples/s, speed: 1849.476166 tokens/s, learning rate: 2.970e-06, loss_scalings: 1801.440430, pp_loss: 4.599485
[INFO] 2021-07-09 16:52:17,548 [run_pretraining.py:  512]:	********exe.run_298******* 
[INFO] 2021-07-09 16:52:19,748 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:19,749 [run_pretraining.py:  534]:	loss/total_loss, 4.58309268951416, 299
[INFO] 2021-07-09 16:52:19,749 [run_pretraining.py:  535]:	loss/mlm_loss, 4.58309268951416, 299
[INFO] 2021-07-09 16:52:19,749 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9799998628732283e-06, 299
[INFO] 2021-07-09 16:52:19,749 [run_pretraining.py:  539]:	lr/loss_scaling, 1801.4404296875, 299
[INFO] 2021-07-09 16:52:19,749 [run_pretraining.py:  558]:	worker_index: 5, step: 299, cost: 4.583093, mlm loss: 4.583093, speed: 0.454491 steps/s, speed: 3.635928 samples/s, speed: 1861.595012 tokens/s, learning rate: 2.980e-06, loss_scalings: 1801.440430, pp_loss: 4.691489
[INFO] 2021-07-09 16:52:19,749 [run_pretraining.py:  512]:	********exe.run_299******* 
[INFO] 2021-07-09 16:52:21,948 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:21,948 [run_pretraining.py:  534]:	loss/total_loss, 4.58311128616333, 300
[INFO] 2021-07-09 16:52:21,948 [run_pretraining.py:  535]:	loss/mlm_loss, 4.58311128616333, 300
[INFO] 2021-07-09 16:52:21,949 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.989999984492897e-06, 300
[INFO] 2021-07-09 16:52:21,949 [run_pretraining.py:  539]:	lr/loss_scaling, 1801.4404296875, 300
[INFO] 2021-07-09 16:52:21,949 [run_pretraining.py:  558]:	worker_index: 5, step: 300, cost: 4.583111, mlm loss: 4.583111, speed: 0.454738 steps/s, speed: 3.637903 samples/s, speed: 1862.606181 tokens/s, learning rate: 2.990e-06, loss_scalings: 1801.440430, pp_loss: 4.617112
[INFO] 2021-07-09 16:52:21,949 [run_pretraining.py:  512]:	********exe.run_300******* 
[INFO] 2021-07-09 16:52:24,173 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:24,174 [run_pretraining.py:  534]:	loss/total_loss, 4.616087913513184, 301
[INFO] 2021-07-09 16:52:24,174 [run_pretraining.py:  535]:	loss/mlm_loss, 4.616087913513184, 301
[INFO] 2021-07-09 16:52:24,174 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9999998787388904e-06, 301
[INFO] 2021-07-09 16:52:24,174 [run_pretraining.py:  539]:	lr/loss_scaling, 1801.4404296875, 301
[INFO] 2021-07-09 16:52:24,174 [run_pretraining.py:  558]:	worker_index: 5, step: 301, cost: 4.616088, mlm loss: 4.616088, speed: 0.449490 steps/s, speed: 3.595923 samples/s, speed: 1841.112416 tokens/s, learning rate: 3.000e-06, loss_scalings: 1801.440430, pp_loss: 4.580621
[INFO] 2021-07-09 16:52:24,174 [run_pretraining.py:  512]:	********exe.run_301******* 
[INFO] 2021-07-09 16:52:26,490 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:26,490 [run_pretraining.py:  534]:	loss/total_loss, 4.544294357299805, 302
[INFO] 2021-07-09 16:52:26,491 [run_pretraining.py:  535]:	loss/mlm_loss, 4.544294357299805, 302
[INFO] 2021-07-09 16:52:26,491 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.0099997729848837e-06, 302
[INFO] 2021-07-09 16:52:26,491 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 302
[INFO] 2021-07-09 16:52:26,491 [run_pretraining.py:  558]:	worker_index: 5, step: 302, cost: 4.544294, mlm loss: 4.544294, speed: 0.431772 steps/s, speed: 3.454175 samples/s, speed: 1768.537558 tokens/s, learning rate: 3.010e-06, loss_scalings: 1441.152344, pp_loss: 4.536401
[INFO] 2021-07-09 16:52:26,491 [run_pretraining.py:  512]:	********exe.run_302******* 
[INFO] 2021-07-09 16:52:28,706 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:28,707 [run_pretraining.py:  534]:	loss/total_loss, 4.461230278015137, 303
[INFO] 2021-07-09 16:52:28,707 [run_pretraining.py:  535]:	loss/mlm_loss, 4.461230278015137, 303
[INFO] 2021-07-09 16:52:28,707 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.020000121978228e-06, 303
[INFO] 2021-07-09 16:52:28,707 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 303
[INFO] 2021-07-09 16:52:28,707 [run_pretraining.py:  558]:	worker_index: 5, step: 303, cost: 4.461230, mlm loss: 4.461230, speed: 0.451319 steps/s, speed: 3.610555 samples/s, speed: 1848.604109 tokens/s, learning rate: 3.020e-06, loss_scalings: 1441.152344, pp_loss: 4.552461
[INFO] 2021-07-09 16:52:28,707 [run_pretraining.py:  512]:	********exe.run_303******* 
[INFO] 2021-07-09 16:52:30,926 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:30,927 [run_pretraining.py:  534]:	loss/total_loss, 4.599142074584961, 304
[INFO] 2021-07-09 16:52:30,927 [run_pretraining.py:  535]:	loss/mlm_loss, 4.599142074584961, 304
[INFO] 2021-07-09 16:52:30,927 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.0300000162242213e-06, 304
[INFO] 2021-07-09 16:52:30,927 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 304
[INFO] 2021-07-09 16:52:30,927 [run_pretraining.py:  558]:	worker_index: 5, step: 304, cost: 4.599142, mlm loss: 4.599142, speed: 0.450633 steps/s, speed: 3.605060 samples/s, speed: 1845.790763 tokens/s, learning rate: 3.030e-06, loss_scalings: 1441.152344, pp_loss: 4.586123
[INFO] 2021-07-09 16:52:30,927 [run_pretraining.py:  512]:	********exe.run_304******* 
[INFO] 2021-07-09 16:52:33,187 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:33,188 [run_pretraining.py:  534]:	loss/total_loss, 4.552023410797119, 305
[INFO] 2021-07-09 16:52:33,188 [run_pretraining.py:  535]:	loss/mlm_loss, 4.552023410797119, 305
[INFO] 2021-07-09 16:52:33,188 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.0399999104702147e-06, 305
[INFO] 2021-07-09 16:52:33,188 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 305
[INFO] 2021-07-09 16:52:33,188 [run_pretraining.py:  558]:	worker_index: 5, step: 305, cost: 4.552023, mlm loss: 4.552023, speed: 0.442450 steps/s, speed: 3.539599 samples/s, speed: 1812.274868 tokens/s, learning rate: 3.040e-06, loss_scalings: 1441.152344, pp_loss: 4.562655
[INFO] 2021-07-09 16:52:33,188 [run_pretraining.py:  512]:	********exe.run_305******* 
[INFO] 2021-07-09 16:52:35,392 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:35,393 [run_pretraining.py:  534]:	loss/total_loss, 4.513105392456055, 306
[INFO] 2021-07-09 16:52:35,393 [run_pretraining.py:  535]:	loss/mlm_loss, 4.513105392456055, 306
[INFO] 2021-07-09 16:52:35,393 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.0500000320898835e-06, 306
[INFO] 2021-07-09 16:52:35,393 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 306
[INFO] 2021-07-09 16:52:35,393 [run_pretraining.py:  558]:	worker_index: 5, step: 306, cost: 4.513105, mlm loss: 4.513105, speed: 0.453607 steps/s, speed: 3.628858 samples/s, speed: 1857.975527 tokens/s, learning rate: 3.050e-06, loss_scalings: 1441.152344, pp_loss: 4.552903
[INFO] 2021-07-09 16:52:35,393 [run_pretraining.py:  512]:	********exe.run_306******* 
[INFO] 2021-07-09 16:52:37,596 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:37,597 [run_pretraining.py:  534]:	loss/total_loss, 4.687074184417725, 307
[INFO] 2021-07-09 16:52:37,597 [run_pretraining.py:  535]:	loss/mlm_loss, 4.687074184417725, 307
[INFO] 2021-07-09 16:52:37,597 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.059999926335877e-06, 307
[INFO] 2021-07-09 16:52:37,597 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 307
[INFO] 2021-07-09 16:52:37,597 [run_pretraining.py:  558]:	worker_index: 5, step: 307, cost: 4.687074, mlm loss: 4.687074, speed: 0.453923 steps/s, speed: 3.631381 samples/s, speed: 1859.267043 tokens/s, learning rate: 3.060e-06, loss_scalings: 1441.152344, pp_loss: 4.624067
[INFO] 2021-07-09 16:52:37,597 [run_pretraining.py:  512]:	********exe.run_307******* 
[INFO] 2021-07-09 16:52:39,792 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:39,792 [run_pretraining.py:  534]:	loss/total_loss, 4.589888572692871, 308
[INFO] 2021-07-09 16:52:39,792 [run_pretraining.py:  535]:	loss/mlm_loss, 4.589888572692871, 308
[INFO] 2021-07-09 16:52:39,792 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.06999982058187e-06, 308
[INFO] 2021-07-09 16:52:39,792 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 308
[INFO] 2021-07-09 16:52:39,793 [run_pretraining.py:  558]:	worker_index: 5, step: 308, cost: 4.589889, mlm loss: 4.589889, speed: 0.455584 steps/s, speed: 3.644676 samples/s, speed: 1866.074079 tokens/s, learning rate: 3.070e-06, loss_scalings: 1441.152344, pp_loss: 4.538733
[INFO] 2021-07-09 16:52:39,793 [run_pretraining.py:  512]:	********exe.run_308******* 
[INFO] 2021-07-09 16:52:42,010 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:42,011 [run_pretraining.py:  534]:	loss/total_loss, 4.526793479919434, 309
[INFO] 2021-07-09 16:52:42,011 [run_pretraining.py:  535]:	loss/mlm_loss, 4.526793479919434, 309
[INFO] 2021-07-09 16:52:42,011 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.079999942201539e-06, 309
[INFO] 2021-07-09 16:52:42,011 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 309
[INFO] 2021-07-09 16:52:42,011 [run_pretraining.py:  558]:	worker_index: 5, step: 309, cost: 4.526793, mlm loss: 4.526793, speed: 0.450884 steps/s, speed: 3.607068 samples/s, speed: 1846.818979 tokens/s, learning rate: 3.080e-06, loss_scalings: 1441.152344, pp_loss: 4.557540
[INFO] 2021-07-09 16:52:42,011 [run_pretraining.py:  512]:	********exe.run_309******* 
[INFO] 2021-07-09 16:52:44,241 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:44,242 [run_pretraining.py:  534]:	loss/total_loss, 4.550267219543457, 310
[INFO] 2021-07-09 16:52:44,242 [run_pretraining.py:  535]:	loss/mlm_loss, 4.550267219543457, 310
[INFO] 2021-07-09 16:52:44,242 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.0899998364475323e-06, 310
[INFO] 2021-07-09 16:52:44,242 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 310
[INFO] 2021-07-09 16:52:44,242 [run_pretraining.py:  558]:	worker_index: 5, step: 310, cost: 4.550267, mlm loss: 4.550267, speed: 0.448347 steps/s, speed: 3.586772 samples/s, speed: 1836.427297 tokens/s, learning rate: 3.090e-06, loss_scalings: 1441.152344, pp_loss: 4.470171
[INFO] 2021-07-09 16:52:44,242 [run_pretraining.py:  512]:	********exe.run_310******* 
[INFO] 2021-07-09 16:52:46,568 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:46,568 [run_pretraining.py:  534]:	loss/total_loss, 4.6161041259765625, 311
[INFO] 2021-07-09 16:52:46,568 [run_pretraining.py:  535]:	loss/mlm_loss, 4.6161041259765625, 311
[INFO] 2021-07-09 16:52:46,569 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.099999958067201e-06, 311
[INFO] 2021-07-09 16:52:46,569 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 311
[INFO] 2021-07-09 16:52:46,569 [run_pretraining.py:  558]:	worker_index: 5, step: 311, cost: 4.616104, mlm loss: 4.616104, speed: 0.429963 steps/s, speed: 3.439703 samples/s, speed: 1761.127859 tokens/s, learning rate: 3.100e-06, loss_scalings: 1441.152344, pp_loss: 4.416463
[INFO] 2021-07-09 16:52:46,569 [run_pretraining.py:  512]:	********exe.run_311******* 
[INFO] 2021-07-09 16:52:48,881 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:48,881 [run_pretraining.py:  534]:	loss/total_loss, 4.283608436584473, 312
[INFO] 2021-07-09 16:52:48,882 [run_pretraining.py:  535]:	loss/mlm_loss, 4.283608436584473, 312
[INFO] 2021-07-09 16:52:48,882 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.1099998523131944e-06, 312
[INFO] 2021-07-09 16:52:48,882 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 312
[INFO] 2021-07-09 16:52:48,882 [run_pretraining.py:  558]:	worker_index: 5, step: 312, cost: 4.283608, mlm loss: 4.283608, speed: 0.432448 steps/s, speed: 3.459584 samples/s, speed: 1771.307161 tokens/s, learning rate: 3.110e-06, loss_scalings: 1441.152344, pp_loss: 4.351135
[INFO] 2021-07-09 16:52:48,882 [run_pretraining.py:  512]:	********exe.run_312******* 
[INFO] 2021-07-09 16:52:51,114 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:51,115 [run_pretraining.py:  534]:	loss/total_loss, 4.404949188232422, 313
[INFO] 2021-07-09 16:52:51,115 [run_pretraining.py:  535]:	loss/mlm_loss, 4.404949188232422, 313
[INFO] 2021-07-09 16:52:51,115 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.1199997465591878e-06, 313
[INFO] 2021-07-09 16:52:51,115 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 313
[INFO] 2021-07-09 16:52:51,115 [run_pretraining.py:  558]:	worker_index: 5, step: 313, cost: 4.404949, mlm loss: 4.404949, speed: 0.447917 steps/s, speed: 3.583337 samples/s, speed: 1834.668339 tokens/s, learning rate: 3.120e-06, loss_scalings: 1441.152344, pp_loss: 4.298198
[INFO] 2021-07-09 16:52:51,115 [run_pretraining.py:  512]:	********exe.run_313******* 
[INFO] 2021-07-09 16:52:53,313 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:53,313 [run_pretraining.py:  534]:	loss/total_loss, 4.07089376449585, 314
[INFO] 2021-07-09 16:52:53,313 [run_pretraining.py:  535]:	loss/mlm_loss, 4.07089376449585, 314
[INFO] 2021-07-09 16:52:53,313 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.130000095552532e-06, 314
[INFO] 2021-07-09 16:52:53,314 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 314
[INFO] 2021-07-09 16:52:53,314 [run_pretraining.py:  558]:	worker_index: 5, step: 314, cost: 4.070894, mlm loss: 4.070894, speed: 0.454982 steps/s, speed: 3.639854 samples/s, speed: 1863.605310 tokens/s, learning rate: 3.130e-06, loss_scalings: 1441.152344, pp_loss: 4.125278
[INFO] 2021-07-09 16:52:53,314 [run_pretraining.py:  512]:	********exe.run_314******* 
[INFO] 2021-07-09 16:52:55,558 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:55,558 [run_pretraining.py:  534]:	loss/total_loss, 3.9617533683776855, 315
[INFO] 2021-07-09 16:52:55,559 [run_pretraining.py:  535]:	loss/mlm_loss, 3.9617533683776855, 315
[INFO] 2021-07-09 16:52:55,559 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.13999976242485e-06, 315
[INFO] 2021-07-09 16:52:55,559 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 315
[INFO] 2021-07-09 16:52:55,559 [run_pretraining.py:  558]:	worker_index: 5, step: 315, cost: 3.961753, mlm loss: 3.961753, speed: 0.445525 steps/s, speed: 3.564201 samples/s, speed: 1824.870883 tokens/s, learning rate: 3.140e-06, loss_scalings: 1441.152344, pp_loss: 4.055377
[INFO] 2021-07-09 16:52:55,559 [run_pretraining.py:  512]:	********exe.run_315******* 
[INFO] 2021-07-09 16:52:57,780 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:57,781 [run_pretraining.py:  534]:	loss/total_loss, 3.84197998046875, 316
[INFO] 2021-07-09 16:52:57,781 [run_pretraining.py:  535]:	loss/mlm_loss, 3.84197998046875, 316
[INFO] 2021-07-09 16:52:57,781 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.1499998840445187e-06, 316
[INFO] 2021-07-09 16:52:57,781 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 316
[INFO] 2021-07-09 16:52:57,781 [run_pretraining.py:  558]:	worker_index: 5, step: 316, cost: 3.841980, mlm loss: 3.841980, speed: 0.450154 steps/s, speed: 3.601230 samples/s, speed: 1843.829974 tokens/s, learning rate: 3.150e-06, loss_scalings: 1441.152344, pp_loss: 3.902502
[INFO] 2021-07-09 16:52:57,781 [run_pretraining.py:  512]:	********exe.run_316******* 
[INFO] 2021-07-09 16:52:59,992 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:52:59,993 [run_pretraining.py:  534]:	loss/total_loss, 3.774623155593872, 317
[INFO] 2021-07-09 16:52:59,993 [run_pretraining.py:  535]:	loss/mlm_loss, 3.774623155593872, 317
[INFO] 2021-07-09 16:52:59,993 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.159999778290512e-06, 317
[INFO] 2021-07-09 16:52:59,993 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 317
[INFO] 2021-07-09 16:52:59,993 [run_pretraining.py:  558]:	worker_index: 5, step: 317, cost: 3.774623, mlm loss: 3.774623, speed: 0.452182 steps/s, speed: 3.617458 samples/s, speed: 1852.138415 tokens/s, learning rate: 3.160e-06, loss_scalings: 1441.152344, pp_loss: 3.746967
[INFO] 2021-07-09 16:52:59,993 [run_pretraining.py:  512]:	********exe.run_317******* 
[INFO] 2021-07-09 16:53:02,283 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:02,283 [run_pretraining.py:  534]:	loss/total_loss, 3.7079710960388184, 318
[INFO] 2021-07-09 16:53:02,283 [run_pretraining.py:  535]:	loss/mlm_loss, 3.7079710960388184, 318
[INFO] 2021-07-09 16:53:02,284 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.169999899910181e-06, 318
[INFO] 2021-07-09 16:53:02,284 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 318
[INFO] 2021-07-09 16:53:02,284 [run_pretraining.py:  558]:	worker_index: 5, step: 318, cost: 3.707971, mlm loss: 3.707971, speed: 0.436739 steps/s, speed: 3.493913 samples/s, speed: 1788.883595 tokens/s, learning rate: 3.170e-06, loss_scalings: 1441.152344, pp_loss: 3.695834
[INFO] 2021-07-09 16:53:02,284 [run_pretraining.py:  512]:	********exe.run_318******* 
[INFO] 2021-07-09 16:53:04,638 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:04,638 [run_pretraining.py:  534]:	loss/total_loss, 3.6310722827911377, 319
[INFO] 2021-07-09 16:53:04,638 [run_pretraining.py:  535]:	loss/mlm_loss, 3.6310722827911377, 319
[INFO] 2021-07-09 16:53:04,638 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.1800000215298496e-06, 319
[INFO] 2021-07-09 16:53:04,638 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 319
[INFO] 2021-07-09 16:53:04,639 [run_pretraining.py:  558]:	worker_index: 5, step: 319, cost: 3.631072, mlm loss: 3.631072, speed: 0.424788 steps/s, speed: 3.398308 samples/s, speed: 1739.933570 tokens/s, learning rate: 3.180e-06, loss_scalings: 1441.152344, pp_loss: 3.710248
[INFO] 2021-07-09 16:53:04,639 [run_pretraining.py:  512]:	********exe.run_319******* 
[INFO] 2021-07-09 16:53:06,857 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:06,858 [run_pretraining.py:  534]:	loss/total_loss, 3.615903377532959, 320
[INFO] 2021-07-09 16:53:06,858 [run_pretraining.py:  535]:	loss/mlm_loss, 3.615903377532959, 320
[INFO] 2021-07-09 16:53:06,858 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.189999915775843e-06, 320
[INFO] 2021-07-09 16:53:06,858 [run_pretraining.py:  539]:	lr/loss_scaling, 1441.15234375, 320
[INFO] 2021-07-09 16:53:06,858 [run_pretraining.py:  558]:	worker_index: 5, step: 320, cost: 3.615903, mlm loss: 3.615903, speed: 0.450685 steps/s, speed: 3.605482 samples/s, speed: 1846.006550 tokens/s, learning rate: 3.190e-06, loss_scalings: 1441.152344, pp_loss: 3.656600
[INFO] 2021-07-09 16:53:06,858 [run_pretraining.py:  512]:	********exe.run_320******* 
[INFO] 2021-07-09 16:53:09,068 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:09,069 [run_pretraining.py:  534]:	loss/total_loss, 3.557040214538574, 321
[INFO] 2021-07-09 16:53:09,069 [run_pretraining.py:  535]:	loss/mlm_loss, 3.557040214538574, 321
[INFO] 2021-07-09 16:53:09,069 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.2000000373955118e-06, 321
[INFO] 2021-07-09 16:53:09,069 [run_pretraining.py:  539]:	lr/loss_scaling, 1152.921875, 321
[INFO] 2021-07-09 16:53:09,069 [run_pretraining.py:  558]:	worker_index: 5, step: 321, cost: 3.557040, mlm loss: 3.557040, speed: 0.452376 steps/s, speed: 3.619004 samples/s, speed: 1852.930271 tokens/s, learning rate: 3.200e-06, loss_scalings: 1152.921875, pp_loss: 3.567617
[INFO] 2021-07-09 16:53:09,069 [run_pretraining.py:  512]:	********exe.run_321******* 
[INFO] 2021-07-09 16:53:11,318 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:11,319 [run_pretraining.py:  534]:	loss/total_loss, 3.5703892707824707, 322
[INFO] 2021-07-09 16:53:11,319 [run_pretraining.py:  535]:	loss/mlm_loss, 3.5703892707824707, 322
[INFO] 2021-07-09 16:53:11,319 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.209999931641505e-06, 322
[INFO] 2021-07-09 16:53:11,319 [run_pretraining.py:  539]:	lr/loss_scaling, 1152.921875, 322
[INFO] 2021-07-09 16:53:11,319 [run_pretraining.py:  558]:	worker_index: 5, step: 322, cost: 3.570389, mlm loss: 3.570389, speed: 0.444591 steps/s, speed: 3.556727 samples/s, speed: 1821.043986 tokens/s, learning rate: 3.210e-06, loss_scalings: 1152.921875, pp_loss: 3.566603
[INFO] 2021-07-09 16:53:11,319 [run_pretraining.py:  512]:	********exe.run_322******* 
[INFO] 2021-07-09 16:53:13,582 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:13,583 [run_pretraining.py:  534]:	loss/total_loss, 3.5733397006988525, 323
[INFO] 2021-07-09 16:53:13,583 [run_pretraining.py:  535]:	loss/mlm_loss, 3.5733397006988525, 323
[INFO] 2021-07-09 16:53:13,583 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.220000053261174e-06, 323
[INFO] 2021-07-09 16:53:13,583 [run_pretraining.py:  539]:	lr/loss_scaling, 1152.921875, 323
[INFO] 2021-07-09 16:53:13,583 [run_pretraining.py:  558]:	worker_index: 5, step: 323, cost: 3.573340, mlm loss: 3.573340, speed: 0.441808 steps/s, speed: 3.534467 samples/s, speed: 1809.646986 tokens/s, learning rate: 3.220e-06, loss_scalings: 1152.921875, pp_loss: 3.521609
[INFO] 2021-07-09 16:53:13,583 [run_pretraining.py:  512]:	********exe.run_323******* 
[INFO] 2021-07-09 16:53:15,819 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:15,820 [run_pretraining.py:  534]:	loss/total_loss, 3.487595796585083, 324
[INFO] 2021-07-09 16:53:15,820 [run_pretraining.py:  535]:	loss/mlm_loss, 3.487595796585083, 324
[INFO] 2021-07-09 16:53:15,820 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.229999720133492e-06, 324
[INFO] 2021-07-09 16:53:15,820 [run_pretraining.py:  539]:	lr/loss_scaling, 1152.921875, 324
[INFO] 2021-07-09 16:53:15,820 [run_pretraining.py:  558]:	worker_index: 5, step: 324, cost: 3.487596, mlm loss: 3.487596, speed: 0.447157 steps/s, speed: 3.577260 samples/s, speed: 1831.557006 tokens/s, learning rate: 3.230e-06, loss_scalings: 1152.921875, pp_loss: 3.528846
[INFO] 2021-07-09 16:53:15,820 [run_pretraining.py:  512]:	********exe.run_324******* 
[INFO] 2021-07-09 16:53:18,110 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:18,110 [run_pretraining.py:  534]:	loss/total_loss, 3.4826886653900146, 325
[INFO] 2021-07-09 16:53:18,110 [run_pretraining.py:  535]:	loss/mlm_loss, 3.4826886653900146, 325
[INFO] 2021-07-09 16:53:18,110 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.240000069126836e-06, 325
[INFO] 2021-07-09 16:53:18,110 [run_pretraining.py:  539]:	lr/loss_scaling, 1152.921875, 325
[INFO] 2021-07-09 16:53:18,111 [run_pretraining.py:  558]:	worker_index: 5, step: 325, cost: 3.482689, mlm loss: 3.482689, speed: 0.436780 steps/s, speed: 3.494236 samples/s, speed: 1789.049019 tokens/s, learning rate: 3.240e-06, loss_scalings: 1152.921875, pp_loss: 3.546828
[INFO] 2021-07-09 16:53:18,111 [run_pretraining.py:  512]:	********exe.run_325******* 
[INFO] 2021-07-09 16:53:20,305 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:20,306 [run_pretraining.py:  534]:	loss/total_loss, 3.6097254753112793, 326
[INFO] 2021-07-09 16:53:20,306 [run_pretraining.py:  535]:	loss/mlm_loss, 3.6097254753112793, 326
[INFO] 2021-07-09 16:53:20,306 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.249999735999154e-06, 326
[INFO] 2021-07-09 16:53:20,306 [run_pretraining.py:  539]:	lr/loss_scaling, 1152.921875, 326
[INFO] 2021-07-09 16:53:20,306 [run_pretraining.py:  558]:	worker_index: 5, step: 326, cost: 3.609725, mlm loss: 3.609725, speed: 0.455533 steps/s, speed: 3.644267 samples/s, speed: 1865.864721 tokens/s, learning rate: 3.250e-06, loss_scalings: 1152.921875, pp_loss: 3.616042
[INFO] 2021-07-09 16:53:20,307 [run_pretraining.py:  512]:	********exe.run_326******* 
[INFO] 2021-07-09 16:53:22,496 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:22,497 [run_pretraining.py:  534]:	loss/total_loss, 3.6373562812805176, 327
[INFO] 2021-07-09 16:53:22,497 [run_pretraining.py:  535]:	loss/mlm_loss, 3.6373562812805176, 327
[INFO] 2021-07-09 16:53:22,497 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.2599998576188227e-06, 327
[INFO] 2021-07-09 16:53:22,497 [run_pretraining.py:  539]:	lr/loss_scaling, 1152.921875, 327
[INFO] 2021-07-09 16:53:22,497 [run_pretraining.py:  558]:	worker_index: 5, step: 327, cost: 3.637356, mlm loss: 3.637356, speed: 0.456601 steps/s, speed: 3.652805 samples/s, speed: 1870.236311 tokens/s, learning rate: 3.260e-06, loss_scalings: 1152.921875, pp_loss: 3.647954
[INFO] 2021-07-09 16:53:22,497 [run_pretraining.py:  512]:	********exe.run_327******* 
[INFO] 2021-07-09 16:53:24,766 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:24,766 [run_pretraining.py:  534]:	loss/total_loss, 3.8604867458343506, 328
[INFO] 2021-07-09 16:53:24,766 [run_pretraining.py:  535]:	loss/mlm_loss, 3.8604867458343506, 328
[INFO] 2021-07-09 16:53:24,766 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.269999751864816e-06, 328
[INFO] 2021-07-09 16:53:24,767 [run_pretraining.py:  539]:	lr/loss_scaling, 1152.921875, 328
[INFO] 2021-07-09 16:53:24,767 [run_pretraining.py:  558]:	worker_index: 5, step: 328, cost: 3.860487, mlm loss: 3.860487, speed: 0.440770 steps/s, speed: 3.526156 samples/s, speed: 1805.392088 tokens/s, learning rate: 3.270e-06, loss_scalings: 1152.921875, pp_loss: 3.669777
[INFO] 2021-07-09 16:53:24,767 [run_pretraining.py:  512]:	********exe.run_328******* 
[INFO] 2021-07-09 16:53:26,989 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:26,989 [run_pretraining.py:  534]:	loss/total_loss, 3.711941719055176, 329
[INFO] 2021-07-09 16:53:26,989 [run_pretraining.py:  535]:	loss/mlm_loss, 3.711941719055176, 329
[INFO] 2021-07-09 16:53:26,990 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.279999873484485e-06, 329
[INFO] 2021-07-09 16:53:26,990 [run_pretraining.py:  539]:	lr/loss_scaling, 1152.921875, 329
[INFO] 2021-07-09 16:53:26,990 [run_pretraining.py:  558]:	worker_index: 5, step: 329, cost: 3.711942, mlm loss: 3.711942, speed: 0.449983 steps/s, speed: 3.599865 samples/s, speed: 1843.131096 tokens/s, learning rate: 3.280e-06, loss_scalings: 1152.921875, pp_loss: 3.724332
[INFO] 2021-07-09 16:53:26,990 [run_pretraining.py:  512]:	********exe.run_329******* 
[INFO] 2021-07-09 16:53:29,225 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:29,226 [run_pretraining.py:  534]:	loss/total_loss, 3.832481622695923, 330
[INFO] 2021-07-09 16:53:29,226 [run_pretraining.py:  535]:	loss/mlm_loss, 3.832481622695923, 330
[INFO] 2021-07-09 16:53:29,226 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.2899999951041536e-06, 330
[INFO] 2021-07-09 16:53:29,226 [run_pretraining.py:  539]:	lr/loss_scaling, 1152.921875, 330
[INFO] 2021-07-09 16:53:29,227 [run_pretraining.py:  558]:	worker_index: 5, step: 330, cost: 3.832482, mlm loss: 3.832482, speed: 0.447199 steps/s, speed: 3.577591 samples/s, speed: 1831.726511 tokens/s, learning rate: 3.290e-06, loss_scalings: 1152.921875, pp_loss: 3.862363
[INFO] 2021-07-09 16:53:29,227 [run_pretraining.py:  512]:	********exe.run_330******* 
[INFO] 2021-07-09 16:53:31,443 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:31,443 [run_pretraining.py:  534]:	loss/total_loss, 3.8009116649627686, 331
[INFO] 2021-07-09 16:53:31,443 [run_pretraining.py:  535]:	loss/mlm_loss, 3.8009116649627686, 331
[INFO] 2021-07-09 16:53:31,443 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.299999889350147e-06, 331
[INFO] 2021-07-09 16:53:31,443 [run_pretraining.py:  539]:	lr/loss_scaling, 922.3375244140625, 331
[INFO] 2021-07-09 16:53:31,444 [run_pretraining.py:  558]:	worker_index: 5, step: 331, cost: 3.800912, mlm loss: 3.800912, speed: 0.451207 steps/s, speed: 3.609659 samples/s, speed: 1848.145524 tokens/s, learning rate: 3.300e-06, loss_scalings: 922.337524, pp_loss: 3.903193
[INFO] 2021-07-09 16:53:31,444 [run_pretraining.py:  512]:	********exe.run_331******* 
[INFO] 2021-07-09 16:53:34,001 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:34,001 [run_pretraining.py:  534]:	loss/total_loss, 3.9365735054016113, 332
[INFO] 2021-07-09 16:53:34,001 [run_pretraining.py:  535]:	loss/mlm_loss, 3.9365735054016113, 332
[INFO] 2021-07-09 16:53:34,001 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.3100000109698158e-06, 332
[INFO] 2021-07-09 16:53:34,001 [run_pretraining.py:  539]:	lr/loss_scaling, 922.3375244140625, 332
[INFO] 2021-07-09 16:53:34,002 [run_pretraining.py:  558]:	worker_index: 5, step: 332, cost: 3.936574, mlm loss: 3.936574, speed: 0.391044 steps/s, speed: 3.128349 samples/s, speed: 1601.714461 tokens/s, learning rate: 3.310e-06, loss_scalings: 922.337524, pp_loss: 3.924820
[INFO] 2021-07-09 16:53:34,002 [run_pretraining.py:  512]:	********exe.run_332******* 
[INFO] 2021-07-09 16:53:36,228 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:36,229 [run_pretraining.py:  534]:	loss/total_loss, 4.055201530456543, 333
[INFO] 2021-07-09 16:53:36,229 [run_pretraining.py:  535]:	loss/mlm_loss, 4.055201530456543, 333
[INFO] 2021-07-09 16:53:36,229 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.319999905215809e-06, 333
[INFO] 2021-07-09 16:53:36,229 [run_pretraining.py:  539]:	lr/loss_scaling, 737.8700561523438, 333
[INFO] 2021-07-09 16:53:36,229 [run_pretraining.py:  558]:	worker_index: 5, step: 333, cost: 4.055202, mlm loss: 4.055202, speed: 0.449029 steps/s, speed: 3.592232 samples/s, speed: 1839.222586 tokens/s, learning rate: 3.320e-06, loss_scalings: 737.870056, pp_loss: 4.067821
[INFO] 2021-07-09 16:53:36,229 [run_pretraining.py:  512]:	********exe.run_333******* 
[INFO] 2021-07-09 16:53:38,495 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:38,495 [run_pretraining.py:  534]:	loss/total_loss, 4.0276336669921875, 334
[INFO] 2021-07-09 16:53:38,495 [run_pretraining.py:  535]:	loss/mlm_loss, 4.0276336669921875, 334
[INFO] 2021-07-09 16:53:38,496 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.330000026835478e-06, 334
[INFO] 2021-07-09 16:53:38,496 [run_pretraining.py:  539]:	lr/loss_scaling, 737.8700561523438, 334
[INFO] 2021-07-09 16:53:38,496 [run_pretraining.py:  558]:	worker_index: 5, step: 334, cost: 4.027634, mlm loss: 4.027634, speed: 0.441341 steps/s, speed: 3.530724 samples/s, speed: 1807.730811 tokens/s, learning rate: 3.330e-06, loss_scalings: 737.870056, pp_loss: 4.050350
[INFO] 2021-07-09 16:53:38,496 [run_pretraining.py:  512]:	********exe.run_334******* 
[INFO] 2021-07-09 16:53:40,736 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:40,736 [run_pretraining.py:  534]:	loss/total_loss, 4.118931770324707, 335
[INFO] 2021-07-09 16:53:40,736 [run_pretraining.py:  535]:	loss/mlm_loss, 4.118931770324707, 335
[INFO] 2021-07-09 16:53:40,737 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.3399999210814713e-06, 335
[INFO] 2021-07-09 16:53:40,737 [run_pretraining.py:  539]:	lr/loss_scaling, 737.8700561523438, 335
[INFO] 2021-07-09 16:53:40,737 [run_pretraining.py:  558]:	worker_index: 5, step: 335, cost: 4.118932, mlm loss: 4.118932, speed: 0.446373 steps/s, speed: 3.570982 samples/s, speed: 1828.342957 tokens/s, learning rate: 3.340e-06, loss_scalings: 737.870056, pp_loss: 4.134558
[INFO] 2021-07-09 16:53:40,737 [run_pretraining.py:  512]:	********exe.run_335******* 
[INFO] 2021-07-09 16:53:43,046 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:43,046 [run_pretraining.py:  534]:	loss/total_loss, 4.129913330078125, 336
[INFO] 2021-07-09 16:53:43,047 [run_pretraining.py:  535]:	loss/mlm_loss, 4.129913330078125, 336
[INFO] 2021-07-09 16:53:43,047 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.35000004270114e-06, 336
[INFO] 2021-07-09 16:53:43,047 [run_pretraining.py:  539]:	lr/loss_scaling, 590.2960815429688, 336
[INFO] 2021-07-09 16:53:43,047 [run_pretraining.py:  558]:	worker_index: 5, step: 336, cost: 4.129913, mlm loss: 4.129913, speed: 0.433025 steps/s, speed: 3.464198 samples/s, speed: 1773.669499 tokens/s, learning rate: 3.350e-06, loss_scalings: 590.296082, pp_loss: 4.182940
[INFO] 2021-07-09 16:53:43,047 [run_pretraining.py:  512]:	********exe.run_336******* 
[INFO] 2021-07-09 16:53:45,299 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:45,300 [run_pretraining.py:  534]:	loss/total_loss, 4.164468288421631, 337
[INFO] 2021-07-09 16:53:45,300 [run_pretraining.py:  535]:	loss/mlm_loss, 4.164468288421631, 337
[INFO] 2021-07-09 16:53:45,300 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.359999709573458e-06, 337
[INFO] 2021-07-09 16:53:45,300 [run_pretraining.py:  539]:	lr/loss_scaling, 590.2960815429688, 337
[INFO] 2021-07-09 16:53:45,300 [run_pretraining.py:  558]:	worker_index: 5, step: 337, cost: 4.164468, mlm loss: 4.164468, speed: 0.443917 steps/s, speed: 3.551337 samples/s, speed: 1818.284395 tokens/s, learning rate: 3.360e-06, loss_scalings: 590.296082, pp_loss: 4.196282
[INFO] 2021-07-09 16:53:45,300 [run_pretraining.py:  512]:	********exe.run_337******* 
[INFO] 2021-07-09 16:53:47,637 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:47,638 [run_pretraining.py:  534]:	loss/total_loss, 4.454324722290039, 338
[INFO] 2021-07-09 16:53:47,638 [run_pretraining.py:  535]:	loss/mlm_loss, 4.454324722290039, 338
[INFO] 2021-07-09 16:53:47,638 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.370000058566802e-06, 338
[INFO] 2021-07-09 16:53:47,638 [run_pretraining.py:  539]:	lr/loss_scaling, 590.2960815429688, 338
[INFO] 2021-07-09 16:53:47,638 [run_pretraining.py:  558]:	worker_index: 5, step: 338, cost: 4.454325, mlm loss: 4.454325, speed: 0.427825 steps/s, speed: 3.422601 samples/s, speed: 1752.371961 tokens/s, learning rate: 3.370e-06, loss_scalings: 590.296082, pp_loss: 4.278143
[INFO] 2021-07-09 16:53:47,638 [run_pretraining.py:  512]:	********exe.run_338******* 
[INFO] 2021-07-09 16:53:50,093 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:50,094 [run_pretraining.py:  534]:	loss/total_loss, 4.282773494720459, 339
[INFO] 2021-07-09 16:53:50,094 [run_pretraining.py:  535]:	loss/mlm_loss, 4.282773494720459, 339
[INFO] 2021-07-09 16:53:50,094 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.37999972543912e-06, 339
[INFO] 2021-07-09 16:53:50,094 [run_pretraining.py:  539]:	lr/loss_scaling, 590.2960815429688, 339
[INFO] 2021-07-09 16:53:50,094 [run_pretraining.py:  558]:	worker_index: 5, step: 339, cost: 4.282773, mlm loss: 4.282773, speed: 0.407256 steps/s, speed: 3.258045 samples/s, speed: 1668.118839 tokens/s, learning rate: 3.380e-06, loss_scalings: 590.296082, pp_loss: 4.298325
[INFO] 2021-07-09 16:53:50,095 [run_pretraining.py:  512]:	********exe.run_339******* 
[INFO] 2021-07-09 16:53:52,350 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:52,350 [run_pretraining.py:  534]:	loss/total_loss, 4.591620445251465, 340
[INFO] 2021-07-09 16:53:52,350 [run_pretraining.py:  535]:	loss/mlm_loss, 4.591620445251465, 340
[INFO] 2021-07-09 16:53:52,350 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.389999847058789e-06, 340
[INFO] 2021-07-09 16:53:52,350 [run_pretraining.py:  539]:	lr/loss_scaling, 590.2960815429688, 340
[INFO] 2021-07-09 16:53:52,351 [run_pretraining.py:  558]:	worker_index: 5, step: 340, cost: 4.591620, mlm loss: 4.591620, speed: 0.443369 steps/s, speed: 3.546950 samples/s, speed: 1816.038275 tokens/s, learning rate: 3.390e-06, loss_scalings: 590.296082, pp_loss: 4.351346
[INFO] 2021-07-09 16:53:52,351 [run_pretraining.py:  512]:	********exe.run_340******* 
[INFO] 2021-07-09 16:53:54,545 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:54,545 [run_pretraining.py:  534]:	loss/total_loss, 4.410376071929932, 341
[INFO] 2021-07-09 16:53:54,546 [run_pretraining.py:  535]:	loss/mlm_loss, 4.410376071929932, 341
[INFO] 2021-07-09 16:53:54,546 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.400000196052133e-06, 341
[INFO] 2021-07-09 16:53:54,546 [run_pretraining.py:  539]:	lr/loss_scaling, 590.2960815429688, 341
[INFO] 2021-07-09 16:53:54,546 [run_pretraining.py:  558]:	worker_index: 5, step: 341, cost: 4.410376, mlm loss: 4.410376, speed: 0.455673 steps/s, speed: 3.645385 samples/s, speed: 1866.436969 tokens/s, learning rate: 3.400e-06, loss_scalings: 590.296082, pp_loss: 4.363314
[INFO] 2021-07-09 16:53:54,546 [run_pretraining.py:  512]:	********exe.run_341******* 
[INFO] 2021-07-09 16:53:56,897 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:56,898 [run_pretraining.py:  534]:	loss/total_loss, 4.31290864944458, 342
[INFO] 2021-07-09 16:53:56,898 [run_pretraining.py:  535]:	loss/mlm_loss, 4.31290864944458, 342
[INFO] 2021-07-09 16:53:56,898 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.409999862924451e-06, 342
[INFO] 2021-07-09 16:53:56,898 [run_pretraining.py:  539]:	lr/loss_scaling, 590.2960815429688, 342
[INFO] 2021-07-09 16:53:56,898 [run_pretraining.py:  558]:	worker_index: 5, step: 342, cost: 4.312909, mlm loss: 4.312909, speed: 0.425225 steps/s, speed: 3.401799 samples/s, speed: 1741.721002 tokens/s, learning rate: 3.410e-06, loss_scalings: 590.296082, pp_loss: 4.334714
[INFO] 2021-07-09 16:53:56,898 [run_pretraining.py:  512]:	********exe.run_342******* 
[INFO] 2021-07-09 16:53:59,213 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:53:59,213 [run_pretraining.py:  534]:	loss/total_loss, 4.481202125549316, 343
[INFO] 2021-07-09 16:53:59,213 [run_pretraining.py:  535]:	loss/mlm_loss, 4.481202125549316, 343
[INFO] 2021-07-09 16:53:59,214 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.41999998454412e-06, 343
[INFO] 2021-07-09 16:53:59,214 [run_pretraining.py:  539]:	lr/loss_scaling, 590.2960815429688, 343
[INFO] 2021-07-09 16:53:59,214 [run_pretraining.py:  558]:	worker_index: 5, step: 343, cost: 4.481202, mlm loss: 4.481202, speed: 0.431994 steps/s, speed: 3.455949 samples/s, speed: 1769.445763 tokens/s, learning rate: 3.420e-06, loss_scalings: 590.296082, pp_loss: 4.293911
[INFO] 2021-07-09 16:53:59,214 [run_pretraining.py:  512]:	********exe.run_343******* 
[INFO] 2021-07-09 16:54:01,648 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:01,649 [run_pretraining.py:  534]:	loss/total_loss, 4.320620536804199, 344
[INFO] 2021-07-09 16:54:01,649 [run_pretraining.py:  535]:	loss/mlm_loss, 4.320620536804199, 344
[INFO] 2021-07-09 16:54:01,649 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.429999878790113e-06, 344
[INFO] 2021-07-09 16:54:01,649 [run_pretraining.py:  539]:	lr/loss_scaling, 590.2960815429688, 344
[INFO] 2021-07-09 16:54:01,649 [run_pretraining.py:  558]:	worker_index: 5, step: 344, cost: 4.320621, mlm loss: 4.320621, speed: 0.410737 steps/s, speed: 3.285895 samples/s, speed: 1682.378041 tokens/s, learning rate: 3.430e-06, loss_scalings: 590.296082, pp_loss: 4.342799
[INFO] 2021-07-09 16:54:01,649 [run_pretraining.py:  512]:	********exe.run_344******* 
[INFO] 2021-07-09 16:54:04,176 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:04,176 [run_pretraining.py:  534]:	loss/total_loss, 4.246243476867676, 345
[INFO] 2021-07-09 16:54:04,176 [run_pretraining.py:  535]:	loss/mlm_loss, 4.246243476867676, 345
[INFO] 2021-07-09 16:54:04,176 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.440000000409782e-06, 345
[INFO] 2021-07-09 16:54:04,177 [run_pretraining.py:  539]:	lr/loss_scaling, 590.2960815429688, 345
[INFO] 2021-07-09 16:54:04,177 [run_pretraining.py:  558]:	worker_index: 5, step: 345, cost: 4.246243, mlm loss: 4.246243, speed: 0.395740 steps/s, speed: 3.165917 samples/s, speed: 1620.949582 tokens/s, learning rate: 3.440e-06, loss_scalings: 590.296082, pp_loss: 4.281172
[INFO] 2021-07-09 16:54:04,177 [run_pretraining.py:  512]:	********exe.run_345******* 
[INFO] 2021-07-09 16:54:06,898 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:06,899 [run_pretraining.py:  534]:	loss/total_loss, 4.266246795654297, 346
[INFO] 2021-07-09 16:54:06,899 [run_pretraining.py:  535]:	loss/mlm_loss, 4.266246795654297, 346
[INFO] 2021-07-09 16:54:06,899 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.4499998946557753e-06, 346
[INFO] 2021-07-09 16:54:06,899 [run_pretraining.py:  539]:	lr/loss_scaling, 590.2960815429688, 346
[INFO] 2021-07-09 16:54:06,899 [run_pretraining.py:  558]:	worker_index: 5, step: 346, cost: 4.266247, mlm loss: 4.266247, speed: 0.367415 steps/s, speed: 2.939316 samples/s, speed: 1504.929794 tokens/s, learning rate: 3.450e-06, loss_scalings: 590.296082, pp_loss: 4.275331
[INFO] 2021-07-09 16:54:06,899 [run_pretraining.py:  512]:	********exe.run_346******* 
[INFO] 2021-07-09 16:54:09,149 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:09,149 [run_pretraining.py:  534]:	loss/total_loss, 4.354128360748291, 347
[INFO] 2021-07-09 16:54:09,149 [run_pretraining.py:  535]:	loss/mlm_loss, 4.354128360748291, 347
[INFO] 2021-07-09 16:54:09,149 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.460000016275444e-06, 347
[INFO] 2021-07-09 16:54:09,149 [run_pretraining.py:  539]:	lr/loss_scaling, 590.2960815429688, 347
[INFO] 2021-07-09 16:54:09,149 [run_pretraining.py:  558]:	worker_index: 5, step: 347, cost: 4.354128, mlm loss: 4.354128, speed: 0.444487 steps/s, speed: 3.555896 samples/s, speed: 1820.618844 tokens/s, learning rate: 3.460e-06, loss_scalings: 590.296082, pp_loss: 4.352119
[INFO] 2021-07-09 16:54:09,150 [run_pretraining.py:  512]:	********exe.run_347******* 
[INFO] 2021-07-09 16:54:11,434 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:11,435 [run_pretraining.py:  534]:	loss/total_loss, 4.219880104064941, 348
[INFO] 2021-07-09 16:54:11,435 [run_pretraining.py:  535]:	loss/mlm_loss, 4.219880104064941, 348
[INFO] 2021-07-09 16:54:11,435 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.469999683147762e-06, 348
[INFO] 2021-07-09 16:54:11,435 [run_pretraining.py:  539]:	lr/loss_scaling, 590.2960815429688, 348
[INFO] 2021-07-09 16:54:11,435 [run_pretraining.py:  558]:	worker_index: 5, step: 348, cost: 4.219880, mlm loss: 4.219880, speed: 0.437613 steps/s, speed: 3.500903 samples/s, speed: 1792.462293 tokens/s, learning rate: 3.470e-06, loss_scalings: 590.296082, pp_loss: 4.301724
[INFO] 2021-07-09 16:54:11,435 [run_pretraining.py:  512]:	********exe.run_348******* 
[INFO] 2021-07-09 16:54:13,703 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:13,704 [run_pretraining.py:  534]:	loss/total_loss, 4.38048791885376, 349
[INFO] 2021-07-09 16:54:13,704 [run_pretraining.py:  535]:	loss/mlm_loss, 4.38048791885376, 349
[INFO] 2021-07-09 16:54:13,704 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.480000032141106e-06, 349
[INFO] 2021-07-09 16:54:13,704 [run_pretraining.py:  539]:	lr/loss_scaling, 472.23687744140625, 349
[INFO] 2021-07-09 16:54:13,704 [run_pretraining.py:  558]:	worker_index: 5, step: 349, cost: 4.380488, mlm loss: 4.380488, speed: 0.440829 steps/s, speed: 3.526631 samples/s, speed: 1805.634968 tokens/s, learning rate: 3.480e-06, loss_scalings: 472.236877, pp_loss: 4.271600
[INFO] 2021-07-09 16:54:13,704 [run_pretraining.py:  512]:	********exe.run_349******* 
[INFO] 2021-07-09 16:54:15,998 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:15,998 [run_pretraining.py:  534]:	loss/total_loss, 4.190084934234619, 350
[INFO] 2021-07-09 16:54:15,998 [run_pretraining.py:  535]:	loss/mlm_loss, 4.190084934234619, 350
[INFO] 2021-07-09 16:54:15,999 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.489999699013424e-06, 350
[INFO] 2021-07-09 16:54:15,999 [run_pretraining.py:  539]:	lr/loss_scaling, 472.23687744140625, 350
[INFO] 2021-07-09 16:54:15,999 [run_pretraining.py:  558]:	worker_index: 5, step: 350, cost: 4.190085, mlm loss: 4.190085, speed: 0.436004 steps/s, speed: 3.488036 samples/s, speed: 1785.874249 tokens/s, learning rate: 3.490e-06, loss_scalings: 472.236877, pp_loss: 4.248739
[INFO] 2021-07-09 16:54:15,999 [run_pretraining.py:  512]:	********exe.run_350******* 
[INFO] 2021-07-09 16:54:18,287 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:18,288 [run_pretraining.py:  534]:	loss/total_loss, 4.307629585266113, 351
[INFO] 2021-07-09 16:54:18,288 [run_pretraining.py:  535]:	loss/mlm_loss, 4.307629585266113, 351
[INFO] 2021-07-09 16:54:18,288 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.499999820633093e-06, 351
[INFO] 2021-07-09 16:54:18,288 [run_pretraining.py:  539]:	lr/loss_scaling, 472.23687744140625, 351
[INFO] 2021-07-09 16:54:18,288 [run_pretraining.py:  558]:	worker_index: 5, step: 351, cost: 4.307630, mlm loss: 4.307630, speed: 0.436921 steps/s, speed: 3.495369 samples/s, speed: 1789.628802 tokens/s, learning rate: 3.500e-06, loss_scalings: 472.236877, pp_loss: 4.217550
[INFO] 2021-07-09 16:54:18,288 [run_pretraining.py:  512]:	********exe.run_351******* 
[INFO] 2021-07-09 16:54:20,600 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:20,601 [run_pretraining.py:  534]:	loss/total_loss, 4.1946539878845215, 352
[INFO] 2021-07-09 16:54:20,601 [run_pretraining.py:  535]:	loss/mlm_loss, 4.1946539878845215, 352
[INFO] 2021-07-09 16:54:20,601 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.510000169626437e-06, 352
[INFO] 2021-07-09 16:54:20,601 [run_pretraining.py:  539]:	lr/loss_scaling, 472.23687744140625, 352
[INFO] 2021-07-09 16:54:20,601 [run_pretraining.py:  558]:	worker_index: 5, step: 352, cost: 4.194654, mlm loss: 4.194654, speed: 0.432489 steps/s, speed: 3.459911 samples/s, speed: 1771.474281 tokens/s, learning rate: 3.510e-06, loss_scalings: 472.236877, pp_loss: 4.179885
[INFO] 2021-07-09 16:54:20,601 [run_pretraining.py:  512]:	********exe.run_352******* 
[INFO] 2021-07-09 16:54:22,891 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:22,892 [run_pretraining.py:  534]:	loss/total_loss, 4.044220447540283, 353
[INFO] 2021-07-09 16:54:22,892 [run_pretraining.py:  535]:	loss/mlm_loss, 4.044220447540283, 353
[INFO] 2021-07-09 16:54:22,892 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.519999836498755e-06, 353
[INFO] 2021-07-09 16:54:22,892 [run_pretraining.py:  539]:	lr/loss_scaling, 472.23687744140625, 353
[INFO] 2021-07-09 16:54:22,892 [run_pretraining.py:  558]:	worker_index: 5, step: 353, cost: 4.044220, mlm loss: 4.044220, speed: 0.436576 steps/s, speed: 3.492609 samples/s, speed: 1788.215692 tokens/s, learning rate: 3.520e-06, loss_scalings: 472.236877, pp_loss: 4.070936
[INFO] 2021-07-09 16:54:22,892 [run_pretraining.py:  512]:	********exe.run_353******* 
[INFO] 2021-07-09 16:54:25,106 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:25,107 [run_pretraining.py:  534]:	loss/total_loss, 4.156737327575684, 354
[INFO] 2021-07-09 16:54:25,107 [run_pretraining.py:  535]:	loss/mlm_loss, 4.156737327575684, 354
[INFO] 2021-07-09 16:54:25,107 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.529999958118424e-06, 354
[INFO] 2021-07-09 16:54:25,107 [run_pretraining.py:  539]:	lr/loss_scaling, 472.23687744140625, 354
[INFO] 2021-07-09 16:54:25,107 [run_pretraining.py:  558]:	worker_index: 5, step: 354, cost: 4.156737, mlm loss: 4.156737, speed: 0.451656 steps/s, speed: 3.613250 samples/s, speed: 1849.984217 tokens/s, learning rate: 3.530e-06, loss_scalings: 472.236877, pp_loss: 4.095217
[INFO] 2021-07-09 16:54:25,107 [run_pretraining.py:  512]:	********exe.run_354******* 
[INFO] 2021-07-09 16:54:27,355 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:27,355 [run_pretraining.py:  534]:	loss/total_loss, 4.081674098968506, 355
[INFO] 2021-07-09 16:54:27,355 [run_pretraining.py:  535]:	loss/mlm_loss, 4.081674098968506, 355
[INFO] 2021-07-09 16:54:27,355 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.539999852364417e-06, 355
[INFO] 2021-07-09 16:54:27,355 [run_pretraining.py:  539]:	lr/loss_scaling, 472.23687744140625, 355
[INFO] 2021-07-09 16:54:27,356 [run_pretraining.py:  558]:	worker_index: 5, step: 355, cost: 4.081674, mlm loss: 4.081674, speed: 0.444866 steps/s, speed: 3.558930 samples/s, speed: 1822.172356 tokens/s, learning rate: 3.540e-06, loss_scalings: 472.236877, pp_loss: 4.020827
[INFO] 2021-07-09 16:54:27,356 [run_pretraining.py:  512]:	********exe.run_355******* 
[INFO] 2021-07-09 16:54:29,573 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:29,573 [run_pretraining.py:  534]:	loss/total_loss, 4.00310754776001, 356
[INFO] 2021-07-09 16:54:29,573 [run_pretraining.py:  535]:	loss/mlm_loss, 4.00310754776001, 356
[INFO] 2021-07-09 16:54:29,573 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.549999973984086e-06, 356
[INFO] 2021-07-09 16:54:29,574 [run_pretraining.py:  539]:	lr/loss_scaling, 472.23687744140625, 356
[INFO] 2021-07-09 16:54:29,574 [run_pretraining.py:  558]:	worker_index: 5, step: 356, cost: 4.003108, mlm loss: 4.003108, speed: 0.450983 steps/s, speed: 3.607867 samples/s, speed: 1847.228044 tokens/s, learning rate: 3.550e-06, loss_scalings: 472.236877, pp_loss: 4.006506
[INFO] 2021-07-09 16:54:29,574 [run_pretraining.py:  512]:	********exe.run_356******* 
[INFO] 2021-07-09 16:54:31,862 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:31,863 [run_pretraining.py:  534]:	loss/total_loss, 4.0774383544921875, 357
[INFO] 2021-07-09 16:54:31,863 [run_pretraining.py:  535]:	loss/mlm_loss, 4.0774383544921875, 357
[INFO] 2021-07-09 16:54:31,863 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.5599998682300793e-06, 357
[INFO] 2021-07-09 16:54:31,863 [run_pretraining.py:  539]:	lr/loss_scaling, 472.23687744140625, 357
[INFO] 2021-07-09 16:54:31,863 [run_pretraining.py:  558]:	worker_index: 5, step: 357, cost: 4.077438, mlm loss: 4.077438, speed: 0.436934 steps/s, speed: 3.495474 samples/s, speed: 1789.682680 tokens/s, learning rate: 3.560e-06, loss_scalings: 472.236877, pp_loss: 4.151717
[INFO] 2021-07-09 16:54:31,863 [run_pretraining.py:  512]:	********exe.run_357******* 
[INFO] 2021-07-09 16:54:34,121 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:34,122 [run_pretraining.py:  534]:	loss/total_loss, 4.085362434387207, 358
[INFO] 2021-07-09 16:54:34,122 [run_pretraining.py:  535]:	loss/mlm_loss, 4.085362434387207, 358
[INFO] 2021-07-09 16:54:34,122 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.569999989849748e-06, 358
[INFO] 2021-07-09 16:54:34,122 [run_pretraining.py:  539]:	lr/loss_scaling, 472.23687744140625, 358
[INFO] 2021-07-09 16:54:34,122 [run_pretraining.py:  558]:	worker_index: 5, step: 358, cost: 4.085362, mlm loss: 4.085362, speed: 0.442759 steps/s, speed: 3.542071 samples/s, speed: 1813.540557 tokens/s, learning rate: 3.570e-06, loss_scalings: 472.236877, pp_loss: 4.145885
[INFO] 2021-07-09 16:54:34,122 [run_pretraining.py:  512]:	********exe.run_358******* 
[INFO] 2021-07-09 16:54:36,380 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:36,380 [run_pretraining.py:  534]:	loss/total_loss, 4.400769233703613, 359
[INFO] 2021-07-09 16:54:36,380 [run_pretraining.py:  535]:	loss/mlm_loss, 4.400769233703613, 359
[INFO] 2021-07-09 16:54:36,380 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.5799998840957414e-06, 359
[INFO] 2021-07-09 16:54:36,380 [run_pretraining.py:  539]:	lr/loss_scaling, 472.23687744140625, 359
[INFO] 2021-07-09 16:54:36,380 [run_pretraining.py:  558]:	worker_index: 5, step: 359, cost: 4.400769, mlm loss: 4.400769, speed: 0.442962 steps/s, speed: 3.543699 samples/s, speed: 1814.374090 tokens/s, learning rate: 3.580e-06, loss_scalings: 472.236877, pp_loss: 4.207084
[INFO] 2021-07-09 16:54:36,381 [run_pretraining.py:  512]:	********exe.run_359******* 
[INFO] 2021-07-09 16:54:38,595 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:38,596 [run_pretraining.py:  534]:	loss/total_loss, 4.363422870635986, 360
[INFO] 2021-07-09 16:54:38,596 [run_pretraining.py:  535]:	loss/mlm_loss, 4.363422870635986, 360
[INFO] 2021-07-09 16:54:38,596 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.5900000057154102e-06, 360
[INFO] 2021-07-09 16:54:38,596 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 360
[INFO] 2021-07-09 16:54:38,596 [run_pretraining.py:  558]:	worker_index: 5, step: 360, cost: 4.363423, mlm loss: 4.363423, speed: 0.451496 steps/s, speed: 3.611971 samples/s, speed: 1849.329240 tokens/s, learning rate: 3.590e-06, loss_scalings: 377.789520, pp_loss: 4.312739
[INFO] 2021-07-09 16:54:38,596 [run_pretraining.py:  512]:	********exe.run_360******* 
[INFO] 2021-07-09 16:54:40,808 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:40,808 [run_pretraining.py:  534]:	loss/total_loss, 4.310507774353027, 361
[INFO] 2021-07-09 16:54:40,808 [run_pretraining.py:  535]:	loss/mlm_loss, 4.310507774353027, 361
[INFO] 2021-07-09 16:54:40,808 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.599999672587728e-06, 361
[INFO] 2021-07-09 16:54:40,808 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 361
[INFO] 2021-07-09 16:54:40,809 [run_pretraining.py:  558]:	worker_index: 5, step: 361, cost: 4.310508, mlm loss: 4.310508, speed: 0.452106 steps/s, speed: 3.616848 samples/s, speed: 1851.826174 tokens/s, learning rate: 3.600e-06, loss_scalings: 377.789520, pp_loss: 4.369087
[INFO] 2021-07-09 16:54:40,809 [run_pretraining.py:  512]:	********exe.run_361******* 
[INFO] 2021-07-09 16:54:43,028 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:43,028 [run_pretraining.py:  534]:	loss/total_loss, 4.660037040710449, 362
[INFO] 2021-07-09 16:54:43,028 [run_pretraining.py:  535]:	loss/mlm_loss, 4.660037040710449, 362
[INFO] 2021-07-09 16:54:43,028 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.6100000215810724e-06, 362
[INFO] 2021-07-09 16:54:43,029 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 362
[INFO] 2021-07-09 16:54:43,029 [run_pretraining.py:  558]:	worker_index: 5, step: 362, cost: 4.660037, mlm loss: 4.660037, speed: 0.450576 steps/s, speed: 3.604605 samples/s, speed: 1845.557580 tokens/s, learning rate: 3.610e-06, loss_scalings: 377.789520, pp_loss: 4.532009
[INFO] 2021-07-09 16:54:43,029 [run_pretraining.py:  512]:	********exe.run_362******* 
[INFO] 2021-07-09 16:54:45,302 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:45,303 [run_pretraining.py:  534]:	loss/total_loss, 4.519003868103027, 363
[INFO] 2021-07-09 16:54:45,303 [run_pretraining.py:  535]:	loss/mlm_loss, 4.519003868103027, 363
[INFO] 2021-07-09 16:54:45,303 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.620000143200741e-06, 363
[INFO] 2021-07-09 16:54:45,303 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 363
[INFO] 2021-07-09 16:54:45,303 [run_pretraining.py:  558]:	worker_index: 5, step: 363, cost: 4.519004, mlm loss: 4.519004, speed: 0.439740 steps/s, speed: 3.517922 samples/s, speed: 1801.175846 tokens/s, learning rate: 3.620e-06, loss_scalings: 377.789520, pp_loss: 4.516283
[INFO] 2021-07-09 16:54:45,303 [run_pretraining.py:  512]:	********exe.run_363******* 
[INFO] 2021-07-09 16:54:47,546 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:47,547 [run_pretraining.py:  534]:	loss/total_loss, 4.549380779266357, 364
[INFO] 2021-07-09 16:54:47,547 [run_pretraining.py:  535]:	loss/mlm_loss, 4.549380779266357, 364
[INFO] 2021-07-09 16:54:47,547 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.629999810073059e-06, 364
[INFO] 2021-07-09 16:54:47,547 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 364
[INFO] 2021-07-09 16:54:47,547 [run_pretraining.py:  558]:	worker_index: 5, step: 364, cost: 4.549381, mlm loss: 4.549381, speed: 0.445836 steps/s, speed: 3.566685 samples/s, speed: 1826.142975 tokens/s, learning rate: 3.630e-06, loss_scalings: 377.789520, pp_loss: 4.567575
[INFO] 2021-07-09 16:54:47,547 [run_pretraining.py:  512]:	********exe.run_364******* 
[INFO] 2021-07-09 16:54:49,835 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:49,836 [run_pretraining.py:  534]:	loss/total_loss, 4.565529823303223, 365
[INFO] 2021-07-09 16:54:49,836 [run_pretraining.py:  535]:	loss/mlm_loss, 4.565529823303223, 365
[INFO] 2021-07-09 16:54:49,836 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.6400001590664033e-06, 365
[INFO] 2021-07-09 16:54:49,836 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 365
[INFO] 2021-07-09 16:54:49,836 [run_pretraining.py:  558]:	worker_index: 5, step: 365, cost: 4.565530, mlm loss: 4.565530, speed: 0.436937 steps/s, speed: 3.495498 samples/s, speed: 1789.695172 tokens/s, learning rate: 3.640e-06, loss_scalings: 377.789520, pp_loss: 4.582419
[INFO] 2021-07-09 16:54:49,837 [run_pretraining.py:  512]:	********exe.run_365******* 
[INFO] 2021-07-09 16:54:52,083 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:52,083 [run_pretraining.py:  534]:	loss/total_loss, 4.60739278793335, 366
[INFO] 2021-07-09 16:54:52,083 [run_pretraining.py:  535]:	loss/mlm_loss, 4.60739278793335, 366
[INFO] 2021-07-09 16:54:52,084 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.649999825938721e-06, 366
[INFO] 2021-07-09 16:54:52,084 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 366
[INFO] 2021-07-09 16:54:52,084 [run_pretraining.py:  558]:	worker_index: 5, step: 366, cost: 4.607393, mlm loss: 4.607393, speed: 0.445107 steps/s, speed: 3.560860 samples/s, speed: 1823.160102 tokens/s, learning rate: 3.650e-06, loss_scalings: 377.789520, pp_loss: 4.627479
[INFO] 2021-07-09 16:54:52,084 [run_pretraining.py:  512]:	********exe.run_366******* 
[INFO] 2021-07-09 16:54:54,424 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:54,425 [run_pretraining.py:  534]:	loss/total_loss, 4.676314353942871, 367
[INFO] 2021-07-09 16:54:54,425 [run_pretraining.py:  535]:	loss/mlm_loss, 4.676314353942871, 367
[INFO] 2021-07-09 16:54:54,425 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.65999994755839e-06, 367
[INFO] 2021-07-09 16:54:54,425 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 367
[INFO] 2021-07-09 16:54:54,425 [run_pretraining.py:  558]:	worker_index: 5, step: 367, cost: 4.676314, mlm loss: 4.676314, speed: 0.427184 steps/s, speed: 3.417476 samples/s, speed: 1749.747459 tokens/s, learning rate: 3.660e-06, loss_scalings: 377.789520, pp_loss: 4.689606
[INFO] 2021-07-09 16:54:54,425 [run_pretraining.py:  512]:	********exe.run_367******* 
[INFO] 2021-07-09 16:54:56,677 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:56,678 [run_pretraining.py:  534]:	loss/total_loss, 4.696426868438721, 368
[INFO] 2021-07-09 16:54:56,678 [run_pretraining.py:  535]:	loss/mlm_loss, 4.696426868438721, 368
[INFO] 2021-07-09 16:54:56,678 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.6699998418043833e-06, 368
[INFO] 2021-07-09 16:54:56,678 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 368
[INFO] 2021-07-09 16:54:56,678 [run_pretraining.py:  558]:	worker_index: 5, step: 368, cost: 4.696427, mlm loss: 4.696427, speed: 0.444049 steps/s, speed: 3.552392 samples/s, speed: 1818.824937 tokens/s, learning rate: 3.670e-06, loss_scalings: 377.789520, pp_loss: 4.738254
[INFO] 2021-07-09 16:54:56,678 [run_pretraining.py:  512]:	********exe.run_368******* 
[INFO] 2021-07-09 16:54:58,902 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:54:58,903 [run_pretraining.py:  534]:	loss/total_loss, 4.960304260253906, 369
[INFO] 2021-07-09 16:54:58,903 [run_pretraining.py:  535]:	loss/mlm_loss, 4.960304260253906, 369
[INFO] 2021-07-09 16:54:58,903 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.679999963424052e-06, 369
[INFO] 2021-07-09 16:54:58,903 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 369
[INFO] 2021-07-09 16:54:58,903 [run_pretraining.py:  558]:	worker_index: 5, step: 369, cost: 4.960304, mlm loss: 4.960304, speed: 0.449537 steps/s, speed: 3.596296 samples/s, speed: 1841.303428 tokens/s, learning rate: 3.680e-06, loss_scalings: 377.789520, pp_loss: 4.797497
[INFO] 2021-07-09 16:54:58,903 [run_pretraining.py:  512]:	********exe.run_369******* 
[INFO] 2021-07-09 16:55:01,176 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:01,177 [run_pretraining.py:  534]:	loss/total_loss, 4.700458526611328, 370
[INFO] 2021-07-09 16:55:01,177 [run_pretraining.py:  535]:	loss/mlm_loss, 4.700458526611328, 370
[INFO] 2021-07-09 16:55:01,177 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.6899998576700455e-06, 370
[INFO] 2021-07-09 16:55:01,177 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 370
[INFO] 2021-07-09 16:55:01,177 [run_pretraining.py:  558]:	worker_index: 5, step: 370, cost: 4.700459, mlm loss: 4.700459, speed: 0.439923 steps/s, speed: 3.519386 samples/s, speed: 1801.925472 tokens/s, learning rate: 3.690e-06, loss_scalings: 377.789520, pp_loss: 4.704067
[INFO] 2021-07-09 16:55:01,177 [run_pretraining.py:  512]:	********exe.run_370******* 
[INFO] 2021-07-09 16:55:03,465 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:03,466 [run_pretraining.py:  534]:	loss/total_loss, 4.648243427276611, 371
[INFO] 2021-07-09 16:55:03,466 [run_pretraining.py:  535]:	loss/mlm_loss, 4.648243427276611, 371
[INFO] 2021-07-09 16:55:03,466 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.6999999792897142e-06, 371
[INFO] 2021-07-09 16:55:03,466 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 371
[INFO] 2021-07-09 16:55:03,466 [run_pretraining.py:  558]:	worker_index: 5, step: 371, cost: 4.648243, mlm loss: 4.648243, speed: 0.436965 steps/s, speed: 3.495723 samples/s, speed: 1789.810399 tokens/s, learning rate: 3.700e-06, loss_scalings: 377.789520, pp_loss: 4.748014
[INFO] 2021-07-09 16:55:03,466 [run_pretraining.py:  512]:	********exe.run_371******* 
[INFO] 2021-07-09 16:55:05,727 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:05,727 [run_pretraining.py:  534]:	loss/total_loss, 4.587643623352051, 372
[INFO] 2021-07-09 16:55:05,727 [run_pretraining.py:  535]:	loss/mlm_loss, 4.587643623352051, 372
[INFO] 2021-07-09 16:55:05,727 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.709999646162032e-06, 372
[INFO] 2021-07-09 16:55:05,727 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 372
[INFO] 2021-07-09 16:55:05,728 [run_pretraining.py:  558]:	worker_index: 5, step: 372, cost: 4.587644, mlm loss: 4.587644, speed: 0.442350 steps/s, speed: 3.538798 samples/s, speed: 1811.864702 tokens/s, learning rate: 3.710e-06, loss_scalings: 377.789520, pp_loss: 4.569830
[INFO] 2021-07-09 16:55:05,728 [run_pretraining.py:  512]:	********exe.run_372******* 
[INFO] 2021-07-09 16:55:08,014 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:08,015 [run_pretraining.py:  534]:	loss/total_loss, 4.395575523376465, 373
[INFO] 2021-07-09 16:55:08,015 [run_pretraining.py:  535]:	loss/mlm_loss, 4.395575523376465, 373
[INFO] 2021-07-09 16:55:08,015 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.7199999951553764e-06, 373
[INFO] 2021-07-09 16:55:08,015 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 373
[INFO] 2021-07-09 16:55:08,015 [run_pretraining.py:  558]:	worker_index: 5, step: 373, cost: 4.395576, mlm loss: 4.395576, speed: 0.437281 steps/s, speed: 3.498252 samples/s, speed: 1791.104833 tokens/s, learning rate: 3.720e-06, loss_scalings: 377.789520, pp_loss: 4.404924
[INFO] 2021-07-09 16:55:08,015 [run_pretraining.py:  512]:	********exe.run_373******* 
[INFO] 2021-07-09 16:55:10,256 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:10,257 [run_pretraining.py:  534]:	loss/total_loss, 4.1845383644104, 374
[INFO] 2021-07-09 16:55:10,257 [run_pretraining.py:  535]:	loss/mlm_loss, 4.1845383644104, 374
[INFO] 2021-07-09 16:55:10,257 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.730000116775045e-06, 374
[INFO] 2021-07-09 16:55:10,257 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 374
[INFO] 2021-07-09 16:55:10,257 [run_pretraining.py:  558]:	worker_index: 5, step: 374, cost: 4.184538, mlm loss: 4.184538, speed: 0.446154 steps/s, speed: 3.569229 samples/s, speed: 1827.445028 tokens/s, learning rate: 3.730e-06, loss_scalings: 377.789520, pp_loss: 4.210176
[INFO] 2021-07-09 16:55:10,257 [run_pretraining.py:  512]:	********exe.run_374******* 
[INFO] 2021-07-09 16:55:12,503 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:12,504 [run_pretraining.py:  534]:	loss/total_loss, 3.975886821746826, 375
[INFO] 2021-07-09 16:55:12,504 [run_pretraining.py:  535]:	loss/mlm_loss, 3.975886821746826, 375
[INFO] 2021-07-09 16:55:12,504 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.739999783647363e-06, 375
[INFO] 2021-07-09 16:55:12,504 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 375
[INFO] 2021-07-09 16:55:12,504 [run_pretraining.py:  558]:	worker_index: 5, step: 375, cost: 3.975887, mlm loss: 3.975887, speed: 0.445215 steps/s, speed: 3.561722 samples/s, speed: 1823.601530 tokens/s, learning rate: 3.740e-06, loss_scalings: 377.789520, pp_loss: 3.989144
[INFO] 2021-07-09 16:55:12,504 [run_pretraining.py:  512]:	********exe.run_375******* 
[INFO] 2021-07-09 16:55:14,756 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:14,757 [run_pretraining.py:  534]:	loss/total_loss, 3.7499618530273438, 376
[INFO] 2021-07-09 16:55:14,757 [run_pretraining.py:  535]:	loss/mlm_loss, 3.7499618530273438, 376
[INFO] 2021-07-09 16:55:14,757 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.7500001326407073e-06, 376
[INFO] 2021-07-09 16:55:14,757 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 376
[INFO] 2021-07-09 16:55:14,757 [run_pretraining.py:  558]:	worker_index: 5, step: 376, cost: 3.749962, mlm loss: 3.749962, speed: 0.443951 steps/s, speed: 3.551606 samples/s, speed: 1818.422195 tokens/s, learning rate: 3.750e-06, loss_scalings: 377.789520, pp_loss: 3.777864
[INFO] 2021-07-09 16:55:14,757 [run_pretraining.py:  512]:	********exe.run_376******* 
[INFO] 2021-07-09 16:55:16,982 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:16,982 [run_pretraining.py:  534]:	loss/total_loss, 3.59006929397583, 377
[INFO] 2021-07-09 16:55:16,982 [run_pretraining.py:  535]:	loss/mlm_loss, 3.59006929397583, 377
[INFO] 2021-07-09 16:55:16,983 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.759999799513025e-06, 377
[INFO] 2021-07-09 16:55:16,983 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 377
[INFO] 2021-07-09 16:55:16,983 [run_pretraining.py:  558]:	worker_index: 5, step: 377, cost: 3.590069, mlm loss: 3.590069, speed: 0.449487 steps/s, speed: 3.595893 samples/s, speed: 1841.097026 tokens/s, learning rate: 3.760e-06, loss_scalings: 377.789520, pp_loss: 3.616288
[INFO] 2021-07-09 16:55:16,983 [run_pretraining.py:  512]:	********exe.run_377******* 
[INFO] 2021-07-09 16:55:19,240 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:19,241 [run_pretraining.py:  534]:	loss/total_loss, 3.4780430793762207, 378
[INFO] 2021-07-09 16:55:19,241 [run_pretraining.py:  535]:	loss/mlm_loss, 3.4780430793762207, 378
[INFO] 2021-07-09 16:55:19,241 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.769999921132694e-06, 378
[INFO] 2021-07-09 16:55:19,241 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 378
[INFO] 2021-07-09 16:55:19,241 [run_pretraining.py:  558]:	worker_index: 5, step: 378, cost: 3.478043, mlm loss: 3.478043, speed: 0.442903 steps/s, speed: 3.543226 samples/s, speed: 1814.131919 tokens/s, learning rate: 3.770e-06, loss_scalings: 377.789520, pp_loss: 3.532662
[INFO] 2021-07-09 16:55:19,241 [run_pretraining.py:  512]:	********exe.run_378******* 
[INFO] 2021-07-09 16:55:21,480 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:21,481 [run_pretraining.py:  534]:	loss/total_loss, 3.6628549098968506, 379
[INFO] 2021-07-09 16:55:21,481 [run_pretraining.py:  535]:	loss/mlm_loss, 3.6628549098968506, 379
[INFO] 2021-07-09 16:55:21,481 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.7799998153786873e-06, 379
[INFO] 2021-07-09 16:55:21,481 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 379
[INFO] 2021-07-09 16:55:21,481 [run_pretraining.py:  558]:	worker_index: 5, step: 379, cost: 3.662855, mlm loss: 3.662855, speed: 0.446519 steps/s, speed: 3.572151 samples/s, speed: 1828.941482 tokens/s, learning rate: 3.780e-06, loss_scalings: 377.789520, pp_loss: 3.526509
[INFO] 2021-07-09 16:55:21,482 [run_pretraining.py:  512]:	********exe.run_379******* 
[INFO] 2021-07-09 16:55:23,712 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:23,712 [run_pretraining.py:  534]:	loss/total_loss, 3.384945869445801, 380
[INFO] 2021-07-09 16:55:23,712 [run_pretraining.py:  535]:	loss/mlm_loss, 3.384945869445801, 380
[INFO] 2021-07-09 16:55:23,712 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.789999936998356e-06, 380
[INFO] 2021-07-09 16:55:23,713 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 380
[INFO] 2021-07-09 16:55:23,713 [run_pretraining.py:  558]:	worker_index: 5, step: 380, cost: 3.384946, mlm loss: 3.384946, speed: 0.448349 steps/s, speed: 3.586791 samples/s, speed: 1836.437112 tokens/s, learning rate: 3.790e-06, loss_scalings: 377.789520, pp_loss: 3.479268
[INFO] 2021-07-09 16:55:23,713 [run_pretraining.py:  512]:	********exe.run_380******* 
[INFO] 2021-07-09 16:55:25,957 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:25,958 [run_pretraining.py:  534]:	loss/total_loss, 3.5150949954986572, 381
[INFO] 2021-07-09 16:55:25,958 [run_pretraining.py:  535]:	loss/mlm_loss, 3.5150949954986572, 381
[INFO] 2021-07-09 16:55:25,958 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.7999998312443495e-06, 381
[INFO] 2021-07-09 16:55:25,958 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 381
[INFO] 2021-07-09 16:55:25,958 [run_pretraining.py:  558]:	worker_index: 5, step: 381, cost: 3.515095, mlm loss: 3.515095, speed: 0.445432 steps/s, speed: 3.563455 samples/s, speed: 1824.488710 tokens/s, learning rate: 3.800e-06, loss_scalings: 377.789520, pp_loss: 3.509897
[INFO] 2021-07-09 16:55:25,958 [run_pretraining.py:  512]:	********exe.run_381******* 
[INFO] 2021-07-09 16:55:28,222 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:28,222 [run_pretraining.py:  534]:	loss/total_loss, 3.5512137413024902, 382
[INFO] 2021-07-09 16:55:28,222 [run_pretraining.py:  535]:	loss/mlm_loss, 3.5512137413024902, 382
[INFO] 2021-07-09 16:55:28,222 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.8099999528640183e-06, 382
[INFO] 2021-07-09 16:55:28,223 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 382
[INFO] 2021-07-09 16:55:28,223 [run_pretraining.py:  558]:	worker_index: 5, step: 382, cost: 3.551214, mlm loss: 3.551214, speed: 0.441769 steps/s, speed: 3.534154 samples/s, speed: 1809.487070 tokens/s, learning rate: 3.810e-06, loss_scalings: 377.789520, pp_loss: 3.601395
[INFO] 2021-07-09 16:55:28,223 [run_pretraining.py:  512]:	********exe.run_382******* 
[INFO] 2021-07-09 16:55:30,461 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:30,462 [run_pretraining.py:  534]:	loss/total_loss, 3.592603921890259, 383
[INFO] 2021-07-09 16:55:30,462 [run_pretraining.py:  535]:	loss/mlm_loss, 3.592603921890259, 383
[INFO] 2021-07-09 16:55:30,462 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.819999619736336e-06, 383
[INFO] 2021-07-09 16:55:30,462 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 383
[INFO] 2021-07-09 16:55:30,462 [run_pretraining.py:  558]:	worker_index: 5, step: 383, cost: 3.592604, mlm loss: 3.592604, speed: 0.446624 steps/s, speed: 3.572993 samples/s, speed: 1829.372664 tokens/s, learning rate: 3.820e-06, loss_scalings: 377.789520, pp_loss: 3.645635
[INFO] 2021-07-09 16:55:30,462 [run_pretraining.py:  512]:	********exe.run_383******* 
[INFO] 2021-07-09 16:55:32,865 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:32,866 [run_pretraining.py:  534]:	loss/total_loss, 3.712144136428833, 384
[INFO] 2021-07-09 16:55:32,866 [run_pretraining.py:  535]:	loss/mlm_loss, 3.712144136428833, 384
[INFO] 2021-07-09 16:55:32,866 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.82999996872968e-06, 384
[INFO] 2021-07-09 16:55:32,866 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 384
[INFO] 2021-07-09 16:55:32,866 [run_pretraining.py:  558]:	worker_index: 5, step: 384, cost: 3.712144, mlm loss: 3.712144, speed: 0.416146 steps/s, speed: 3.329170 samples/s, speed: 1704.534899 tokens/s, learning rate: 3.830e-06, loss_scalings: 377.789520, pp_loss: 3.661280
[INFO] 2021-07-09 16:55:32,866 [run_pretraining.py:  512]:	********exe.run_384******* 
[INFO] 2021-07-09 16:55:35,216 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:35,217 [run_pretraining.py:  534]:	loss/total_loss, 3.5757505893707275, 385
[INFO] 2021-07-09 16:55:35,217 [run_pretraining.py:  535]:	loss/mlm_loss, 3.5757505893707275, 385
[INFO] 2021-07-09 16:55:35,217 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.839999862975674e-06, 385
[INFO] 2021-07-09 16:55:35,217 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 385
[INFO] 2021-07-09 16:55:35,217 [run_pretraining.py:  558]:	worker_index: 5, step: 385, cost: 3.575751, mlm loss: 3.575751, speed: 0.425428 steps/s, speed: 3.403424 samples/s, speed: 1742.552907 tokens/s, learning rate: 3.840e-06, loss_scalings: 377.789520, pp_loss: 3.607953
[INFO] 2021-07-09 16:55:35,217 [run_pretraining.py:  512]:	********exe.run_385******* 
[INFO] 2021-07-09 16:55:37,495 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:37,495 [run_pretraining.py:  534]:	loss/total_loss, 3.442821502685547, 386
[INFO] 2021-07-09 16:55:37,495 [run_pretraining.py:  535]:	loss/mlm_loss, 3.442821502685547, 386
[INFO] 2021-07-09 16:55:37,496 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.849999757221667e-06, 386
[INFO] 2021-07-09 16:55:37,496 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 386
[INFO] 2021-07-09 16:55:37,496 [run_pretraining.py:  558]:	worker_index: 5, step: 386, cost: 3.442822, mlm loss: 3.442822, speed: 0.439040 steps/s, speed: 3.512323 samples/s, speed: 1798.309491 tokens/s, learning rate: 3.850e-06, loss_scalings: 377.789520, pp_loss: 3.514761
[INFO] 2021-07-09 16:55:37,496 [run_pretraining.py:  512]:	********exe.run_386******* 
[INFO] 2021-07-09 16:55:39,773 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:39,773 [run_pretraining.py:  534]:	loss/total_loss, 3.337675094604492, 387
[INFO] 2021-07-09 16:55:39,773 [run_pretraining.py:  535]:	loss/mlm_loss, 3.337675094604492, 387
[INFO] 2021-07-09 16:55:39,773 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.860000106215011e-06, 387
[INFO] 2021-07-09 16:55:39,773 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 387
[INFO] 2021-07-09 16:55:39,773 [run_pretraining.py:  558]:	worker_index: 5, step: 387, cost: 3.337675, mlm loss: 3.337675, speed: 0.439172 steps/s, speed: 3.513379 samples/s, speed: 1798.849898 tokens/s, learning rate: 3.860e-06, loss_scalings: 377.789520, pp_loss: 3.340604
[INFO] 2021-07-09 16:55:39,773 [run_pretraining.py:  512]:	********exe.run_387******* 
[INFO] 2021-07-09 16:55:41,998 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:41,998 [run_pretraining.py:  534]:	loss/total_loss, 3.2928717136383057, 388
[INFO] 2021-07-09 16:55:41,998 [run_pretraining.py:  535]:	loss/mlm_loss, 3.2928717136383057, 388
[INFO] 2021-07-09 16:55:41,998 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.870000000461005e-06, 388
[INFO] 2021-07-09 16:55:41,999 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 388
[INFO] 2021-07-09 16:55:41,999 [run_pretraining.py:  558]:	worker_index: 5, step: 388, cost: 3.292872, mlm loss: 3.292872, speed: 0.449506 steps/s, speed: 3.596046 samples/s, speed: 1841.175556 tokens/s, learning rate: 3.870e-06, loss_scalings: 377.789520, pp_loss: 3.347111
[INFO] 2021-07-09 16:55:41,999 [run_pretraining.py:  512]:	********exe.run_388******* 
[INFO] 2021-07-09 16:55:44,264 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:44,264 [run_pretraining.py:  534]:	loss/total_loss, 3.4353203773498535, 389
[INFO] 2021-07-09 16:55:44,264 [run_pretraining.py:  535]:	loss/mlm_loss, 3.4353203773498535, 389
[INFO] 2021-07-09 16:55:44,265 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.879999894706998e-06, 389
[INFO] 2021-07-09 16:55:44,265 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 389
[INFO] 2021-07-09 16:55:44,265 [run_pretraining.py:  558]:	worker_index: 5, step: 389, cost: 3.435320, mlm loss: 3.435320, speed: 0.441428 steps/s, speed: 3.531426 samples/s, speed: 1808.090010 tokens/s, learning rate: 3.880e-06, loss_scalings: 377.789520, pp_loss: 3.278454
[INFO] 2021-07-09 16:55:44,265 [run_pretraining.py:  512]:	********exe.run_389******* 
[INFO] 2021-07-09 16:55:46,550 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:46,550 [run_pretraining.py:  534]:	loss/total_loss, 3.4184980392456055, 390
[INFO] 2021-07-09 16:55:46,551 [run_pretraining.py:  535]:	loss/mlm_loss, 3.4184980392456055, 390
[INFO] 2021-07-09 16:55:46,551 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.889999788952991e-06, 390
[INFO] 2021-07-09 16:55:46,551 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 390
[INFO] 2021-07-09 16:55:46,551 [run_pretraining.py:  558]:	worker_index: 5, step: 390, cost: 3.418498, mlm loss: 3.418498, speed: 0.437539 steps/s, speed: 3.500314 samples/s, speed: 1792.160873 tokens/s, learning rate: 3.890e-06, loss_scalings: 377.789520, pp_loss: 3.307087
[INFO] 2021-07-09 16:55:46,551 [run_pretraining.py:  512]:	********exe.run_390******* 
[INFO] 2021-07-09 16:55:48,892 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:48,893 [run_pretraining.py:  534]:	loss/total_loss, 3.1801908016204834, 391
[INFO] 2021-07-09 16:55:48,893 [run_pretraining.py:  535]:	loss/mlm_loss, 3.1801908016204834, 391
[INFO] 2021-07-09 16:55:48,893 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.900000137946336e-06, 391
[INFO] 2021-07-09 16:55:48,893 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 391
[INFO] 2021-07-09 16:55:48,893 [run_pretraining.py:  558]:	worker_index: 5, step: 391, cost: 3.180191, mlm loss: 3.180191, speed: 0.427087 steps/s, speed: 3.416696 samples/s, speed: 1749.348183 tokens/s, learning rate: 3.900e-06, loss_scalings: 377.789520, pp_loss: 3.237534
[INFO] 2021-07-09 16:55:48,893 [run_pretraining.py:  512]:	********exe.run_391******* 
[INFO] 2021-07-09 16:55:51,212 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:51,213 [run_pretraining.py:  534]:	loss/total_loss, 3.0124430656433105, 392
[INFO] 2021-07-09 16:55:51,213 [run_pretraining.py:  535]:	loss/mlm_loss, 3.0124430656433105, 392
[INFO] 2021-07-09 16:55:51,213 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.909999577444978e-06, 392
[INFO] 2021-07-09 16:55:51,213 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 392
[INFO] 2021-07-09 16:55:51,213 [run_pretraining.py:  558]:	worker_index: 5, step: 392, cost: 3.012443, mlm loss: 3.012443, speed: 0.431150 steps/s, speed: 3.449200 samples/s, speed: 1765.990605 tokens/s, learning rate: 3.910e-06, loss_scalings: 377.789520, pp_loss: 3.095004
[INFO] 2021-07-09 16:55:51,213 [run_pretraining.py:  512]:	********exe.run_392******* 
[INFO] 2021-07-09 16:55:53,516 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:53,517 [run_pretraining.py:  534]:	loss/total_loss, 2.912702798843384, 393
[INFO] 2021-07-09 16:55:53,517 [run_pretraining.py:  535]:	loss/mlm_loss, 2.912702798843384, 393
[INFO] 2021-07-09 16:55:53,517 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.919999926438322e-06, 393
[INFO] 2021-07-09 16:55:53,517 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 393
[INFO] 2021-07-09 16:55:53,517 [run_pretraining.py:  558]:	worker_index: 5, step: 393, cost: 2.912703, mlm loss: 2.912703, speed: 0.434090 steps/s, speed: 3.472722 samples/s, speed: 1778.033602 tokens/s, learning rate: 3.920e-06, loss_scalings: 377.789520, pp_loss: 2.896209
[INFO] 2021-07-09 16:55:53,518 [run_pretraining.py:  512]:	********exe.run_393******* 
[INFO] 2021-07-09 16:55:55,771 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:55,772 [run_pretraining.py:  534]:	loss/total_loss, 2.674560308456421, 394
[INFO] 2021-07-09 16:55:55,772 [run_pretraining.py:  535]:	loss/mlm_loss, 2.674560308456421, 394
[INFO] 2021-07-09 16:55:55,772 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.929999820684316e-06, 394
[INFO] 2021-07-09 16:55:55,772 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 394
[INFO] 2021-07-09 16:55:55,772 [run_pretraining.py:  558]:	worker_index: 5, step: 394, cost: 2.674560, mlm loss: 2.674560, speed: 0.443682 steps/s, speed: 3.549457 samples/s, speed: 1817.321916 tokens/s, learning rate: 3.930e-06, loss_scalings: 377.789520, pp_loss: 2.698089
[INFO] 2021-07-09 16:55:55,772 [run_pretraining.py:  512]:	********exe.run_394******* 
[INFO] 2021-07-09 16:55:58,044 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:55:58,045 [run_pretraining.py:  534]:	loss/total_loss, 2.554119110107422, 395
[INFO] 2021-07-09 16:55:58,045 [run_pretraining.py:  535]:	loss/mlm_loss, 2.554119110107422, 395
[INFO] 2021-07-09 16:55:58,045 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.939999714930309e-06, 395
[INFO] 2021-07-09 16:55:58,045 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 395
[INFO] 2021-07-09 16:55:58,045 [run_pretraining.py:  558]:	worker_index: 5, step: 395, cost: 2.554119, mlm loss: 2.554119, speed: 0.440041 steps/s, speed: 3.520327 samples/s, speed: 1802.407353 tokens/s, learning rate: 3.940e-06, loss_scalings: 377.789520, pp_loss: 2.592785
[INFO] 2021-07-09 16:55:58,045 [run_pretraining.py:  512]:	********exe.run_395******* 
[INFO] 2021-07-09 16:56:00,358 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:00,359 [run_pretraining.py:  534]:	loss/total_loss, 2.4787044525146484, 396
[INFO] 2021-07-09 16:56:00,359 [run_pretraining.py:  535]:	loss/mlm_loss, 2.4787044525146484, 396
[INFO] 2021-07-09 16:56:00,359 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.950000063923653e-06, 396
[INFO] 2021-07-09 16:56:00,359 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 396
[INFO] 2021-07-09 16:56:00,359 [run_pretraining.py:  558]:	worker_index: 5, step: 396, cost: 2.478704, mlm loss: 2.478704, speed: 0.432303 steps/s, speed: 3.458426 samples/s, speed: 1770.714183 tokens/s, learning rate: 3.950e-06, loss_scalings: 377.789520, pp_loss: 2.513285
[INFO] 2021-07-09 16:56:00,359 [run_pretraining.py:  512]:	********exe.run_396******* 
[INFO] 2021-07-09 16:56:02,713 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:02,713 [run_pretraining.py:  534]:	loss/total_loss, 2.439188241958618, 397
[INFO] 2021-07-09 16:56:02,714 [run_pretraining.py:  535]:	loss/mlm_loss, 2.439188241958618, 397
[INFO] 2021-07-09 16:56:02,714 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.9599999581696466e-06, 397
[INFO] 2021-07-09 16:56:02,714 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 397
[INFO] 2021-07-09 16:56:02,714 [run_pretraining.py:  558]:	worker_index: 5, step: 397, cost: 2.439188, mlm loss: 2.439188, speed: 0.424785 steps/s, speed: 3.398280 samples/s, speed: 1739.919297 tokens/s, learning rate: 3.960e-06, loss_scalings: 377.789520, pp_loss: 2.493417
[INFO] 2021-07-09 16:56:02,714 [run_pretraining.py:  512]:	********exe.run_397******* 
[INFO] 2021-07-09 16:56:04,965 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:04,966 [run_pretraining.py:  534]:	loss/total_loss, 2.4508635997772217, 398
[INFO] 2021-07-09 16:56:04,966 [run_pretraining.py:  535]:	loss/mlm_loss, 2.4508635997772217, 398
[INFO] 2021-07-09 16:56:04,966 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.96999985241564e-06, 398
[INFO] 2021-07-09 16:56:04,966 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 398
[INFO] 2021-07-09 16:56:04,966 [run_pretraining.py:  558]:	worker_index: 5, step: 398, cost: 2.450864, mlm loss: 2.450864, speed: 0.444149 steps/s, speed: 3.553190 samples/s, speed: 1819.233252 tokens/s, learning rate: 3.970e-06, loss_scalings: 377.789520, pp_loss: 2.450532
[INFO] 2021-07-09 16:56:04,966 [run_pretraining.py:  512]:	********exe.run_398******* 
[INFO] 2021-07-09 16:56:07,287 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:07,288 [run_pretraining.py:  534]:	loss/total_loss, 2.4592015743255615, 399
[INFO] 2021-07-09 16:56:07,288 [run_pretraining.py:  535]:	loss/mlm_loss, 2.4592015743255615, 399
[INFO] 2021-07-09 16:56:07,288 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.979999746661633e-06, 399
[INFO] 2021-07-09 16:56:07,288 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 399
[INFO] 2021-07-09 16:56:07,289 [run_pretraining.py:  558]:	worker_index: 5, step: 399, cost: 2.459202, mlm loss: 2.459202, speed: 0.430717 steps/s, speed: 3.445736 samples/s, speed: 1764.216627 tokens/s, learning rate: 3.980e-06, loss_scalings: 377.789520, pp_loss: 2.474120
[INFO] 2021-07-09 16:56:07,289 [run_pretraining.py:  512]:	********exe.run_399******* 
[INFO] 2021-07-09 16:56:09,548 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:09,549 [run_pretraining.py:  534]:	loss/total_loss, 2.5679452419281006, 400
[INFO] 2021-07-09 16:56:09,549 [run_pretraining.py:  535]:	loss/mlm_loss, 2.5679452419281006, 400
[INFO] 2021-07-09 16:56:09,549 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.9900000956549775e-06, 400
[INFO] 2021-07-09 16:56:09,549 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 400
[INFO] 2021-07-09 16:56:09,549 [run_pretraining.py:  558]:	worker_index: 5, step: 400, cost: 2.567945, mlm loss: 2.567945, speed: 0.442498 steps/s, speed: 3.539983 samples/s, speed: 1812.471416 tokens/s, learning rate: 3.990e-06, loss_scalings: 377.789520, pp_loss: 2.540747
[INFO] 2021-07-09 16:56:09,549 [run_pretraining.py:  512]:	********exe.run_400******* 
[INFO] 2021-07-09 16:56:11,819 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:11,820 [run_pretraining.py:  534]:	loss/total_loss, 2.682340145111084, 401
[INFO] 2021-07-09 16:56:11,820 [run_pretraining.py:  535]:	loss/mlm_loss, 2.682340145111084, 401
[INFO] 2021-07-09 16:56:11,820 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.999999989900971e-06, 401
[INFO] 2021-07-09 16:56:11,820 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 401
[INFO] 2021-07-09 16:56:11,820 [run_pretraining.py:  558]:	worker_index: 5, step: 401, cost: 2.682340, mlm loss: 2.682340, speed: 0.440440 steps/s, speed: 3.523522 samples/s, speed: 1804.043207 tokens/s, learning rate: 4.000e-06, loss_scalings: 377.789520, pp_loss: 2.641666
[INFO] 2021-07-09 16:56:11,820 [run_pretraining.py:  512]:	********exe.run_401******* 
[INFO] 2021-07-09 16:56:14,080 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:14,080 [run_pretraining.py:  534]:	loss/total_loss, 2.8451321125030518, 402
[INFO] 2021-07-09 16:56:14,080 [run_pretraining.py:  535]:	loss/mlm_loss, 2.8451321125030518, 402
[INFO] 2021-07-09 16:56:14,080 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.009999884146964e-06, 402
[INFO] 2021-07-09 16:56:14,081 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 402
[INFO] 2021-07-09 16:56:14,081 [run_pretraining.py:  558]:	worker_index: 5, step: 402, cost: 2.845132, mlm loss: 2.845132, speed: 0.442564 steps/s, speed: 3.540516 samples/s, speed: 1812.743938 tokens/s, learning rate: 4.010e-06, loss_scalings: 377.789520, pp_loss: 2.809532
[INFO] 2021-07-09 16:56:14,081 [run_pretraining.py:  512]:	********exe.run_402******* 
[INFO] 2021-07-09 16:56:16,419 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:16,419 [run_pretraining.py:  534]:	loss/total_loss, 2.9105725288391113, 403
[INFO] 2021-07-09 16:56:16,419 [run_pretraining.py:  535]:	loss/mlm_loss, 2.9105725288391113, 403
[INFO] 2021-07-09 16:56:16,420 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.0199997783929575e-06, 403
[INFO] 2021-07-09 16:56:16,420 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 403
[INFO] 2021-07-09 16:56:16,420 [run_pretraining.py:  558]:	worker_index: 5, step: 403, cost: 2.910573, mlm loss: 2.910573, speed: 0.427641 steps/s, speed: 3.421130 samples/s, speed: 1751.618341 tokens/s, learning rate: 4.020e-06, loss_scalings: 377.789520, pp_loss: 2.914091
[INFO] 2021-07-09 16:56:16,420 [run_pretraining.py:  512]:	********exe.run_403******* 
[INFO] 2021-07-09 16:56:18,721 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:18,721 [run_pretraining.py:  534]:	loss/total_loss, 3.028301239013672, 404
[INFO] 2021-07-09 16:56:18,721 [run_pretraining.py:  535]:	loss/mlm_loss, 3.028301239013672, 404
[INFO] 2021-07-09 16:56:18,722 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.030000127386302e-06, 404
[INFO] 2021-07-09 16:56:18,722 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 404
[INFO] 2021-07-09 16:56:18,722 [run_pretraining.py:  558]:	worker_index: 5, step: 404, cost: 3.028301, mlm loss: 3.028301, speed: 0.434534 steps/s, speed: 3.476274 samples/s, speed: 1779.852269 tokens/s, learning rate: 4.030e-06, loss_scalings: 377.789520, pp_loss: 3.054487
[INFO] 2021-07-09 16:56:18,722 [run_pretraining.py:  512]:	********exe.run_404******* 
[INFO] 2021-07-09 16:56:21,001 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:21,002 [run_pretraining.py:  534]:	loss/total_loss, 3.2542834281921387, 405
[INFO] 2021-07-09 16:56:21,002 [run_pretraining.py:  535]:	loss/mlm_loss, 3.2542834281921387, 405
[INFO] 2021-07-09 16:56:21,002 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.039999566884944e-06, 405
[INFO] 2021-07-09 16:56:21,002 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 405
[INFO] 2021-07-09 16:56:21,002 [run_pretraining.py:  558]:	worker_index: 5, step: 405, cost: 3.254283, mlm loss: 3.254283, speed: 0.438635 steps/s, speed: 3.509078 samples/s, speed: 1796.647750 tokens/s, learning rate: 4.040e-06, loss_scalings: 377.789520, pp_loss: 3.072781
[INFO] 2021-07-09 16:56:21,002 [run_pretraining.py:  512]:	********exe.run_405******* 
[INFO] 2021-07-09 16:56:23,281 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:23,282 [run_pretraining.py:  534]:	loss/total_loss, 3.0273818969726562, 406
[INFO] 2021-07-09 16:56:23,282 [run_pretraining.py:  535]:	loss/mlm_loss, 3.0273818969726562, 406
[INFO] 2021-07-09 16:56:23,282 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.0499999158782884e-06, 406
[INFO] 2021-07-09 16:56:23,282 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 406
[INFO] 2021-07-09 16:56:23,282 [run_pretraining.py:  558]:	worker_index: 5, step: 406, cost: 3.027382, mlm loss: 3.027382, speed: 0.438734 steps/s, speed: 3.509874 samples/s, speed: 1797.055378 tokens/s, learning rate: 4.050e-06, loss_scalings: 377.789520, pp_loss: 3.076529
[INFO] 2021-07-09 16:56:23,282 [run_pretraining.py:  512]:	********exe.run_406******* 
[INFO] 2021-07-09 16:56:25,521 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:25,522 [run_pretraining.py:  534]:	loss/total_loss, 3.0935418605804443, 407
[INFO] 2021-07-09 16:56:25,522 [run_pretraining.py:  535]:	loss/mlm_loss, 3.0935418605804443, 407
[INFO] 2021-07-09 16:56:25,522 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.060000264871633e-06, 407
[INFO] 2021-07-09 16:56:25,522 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 407
[INFO] 2021-07-09 16:56:25,522 [run_pretraining.py:  558]:	worker_index: 5, step: 407, cost: 3.093542, mlm loss: 3.093542, speed: 0.446611 steps/s, speed: 3.572887 samples/s, speed: 1829.318316 tokens/s, learning rate: 4.060e-06, loss_scalings: 377.789520, pp_loss: 2.922178
[INFO] 2021-07-09 16:56:25,522 [run_pretraining.py:  512]:	********exe.run_407******* 
[INFO] 2021-07-09 16:56:27,767 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:27,768 [run_pretraining.py:  534]:	loss/total_loss, 2.791877269744873, 408
[INFO] 2021-07-09 16:56:27,768 [run_pretraining.py:  535]:	loss/mlm_loss, 2.791877269744873, 408
[INFO] 2021-07-09 16:56:27,768 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.069999704370275e-06, 408
[INFO] 2021-07-09 16:56:27,768 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 408
[INFO] 2021-07-09 16:56:27,768 [run_pretraining.py:  558]:	worker_index: 5, step: 408, cost: 2.791877, mlm loss: 2.791877, speed: 0.445372 steps/s, speed: 3.562977 samples/s, speed: 1824.244025 tokens/s, learning rate: 4.070e-06, loss_scalings: 377.789520, pp_loss: 2.781122
[INFO] 2021-07-09 16:56:27,768 [run_pretraining.py:  512]:	********exe.run_408******* 
[INFO] 2021-07-09 16:56:30,064 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:30,065 [run_pretraining.py:  534]:	loss/total_loss, 2.601062297821045, 409
[INFO] 2021-07-09 16:56:30,065 [run_pretraining.py:  535]:	loss/mlm_loss, 2.601062297821045, 409
[INFO] 2021-07-09 16:56:30,065 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.080000053363619e-06, 409
[INFO] 2021-07-09 16:56:30,065 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 409
[INFO] 2021-07-09 16:56:30,065 [run_pretraining.py:  558]:	worker_index: 5, step: 409, cost: 2.601062, mlm loss: 2.601062, speed: 0.435443 steps/s, speed: 3.483548 samples/s, speed: 1783.576518 tokens/s, learning rate: 4.080e-06, loss_scalings: 377.789520, pp_loss: 2.640858
[INFO] 2021-07-09 16:56:30,065 [run_pretraining.py:  512]:	********exe.run_409******* 
[INFO] 2021-07-09 16:56:32,321 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:32,321 [run_pretraining.py:  534]:	loss/total_loss, 2.577241897583008, 410
[INFO] 2021-07-09 16:56:32,321 [run_pretraining.py:  535]:	loss/mlm_loss, 2.577241897583008, 410
[INFO] 2021-07-09 16:56:32,321 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.089999947609613e-06, 410
[INFO] 2021-07-09 16:56:32,322 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 410
[INFO] 2021-07-09 16:56:32,322 [run_pretraining.py:  558]:	worker_index: 5, step: 410, cost: 2.577242, mlm loss: 2.577242, speed: 0.443293 steps/s, speed: 3.546340 samples/s, speed: 1815.726188 tokens/s, learning rate: 4.090e-06, loss_scalings: 377.789520, pp_loss: 2.577293
[INFO] 2021-07-09 16:56:32,322 [run_pretraining.py:  512]:	********exe.run_410******* 
[INFO] 2021-07-09 16:56:34,581 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:34,582 [run_pretraining.py:  534]:	loss/total_loss, 2.532869577407837, 411
[INFO] 2021-07-09 16:56:34,582 [run_pretraining.py:  535]:	loss/mlm_loss, 2.532869577407837, 411
[INFO] 2021-07-09 16:56:34,582 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.099999841855606e-06, 411
[INFO] 2021-07-09 16:56:34,582 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 411
[INFO] 2021-07-09 16:56:34,582 [run_pretraining.py:  558]:	worker_index: 5, step: 411, cost: 2.532870, mlm loss: 2.532870, speed: 0.442533 steps/s, speed: 3.540265 samples/s, speed: 1812.615604 tokens/s, learning rate: 4.100e-06, loss_scalings: 377.789520, pp_loss: 2.522866
[INFO] 2021-07-09 16:56:34,582 [run_pretraining.py:  512]:	********exe.run_411******* 
[INFO] 2021-07-09 16:56:36,826 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:36,827 [run_pretraining.py:  534]:	loss/total_loss, 2.2977077960968018, 412
[INFO] 2021-07-09 16:56:36,827 [run_pretraining.py:  535]:	loss/mlm_loss, 2.2977077960968018, 412
[INFO] 2021-07-09 16:56:36,827 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.109999736101599e-06, 412
[INFO] 2021-07-09 16:56:36,827 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 412
[INFO] 2021-07-09 16:56:36,827 [run_pretraining.py:  558]:	worker_index: 5, step: 412, cost: 2.297708, mlm loss: 2.297708, speed: 0.445507 steps/s, speed: 3.564058 samples/s, speed: 1824.797809 tokens/s, learning rate: 4.110e-06, loss_scalings: 377.789520, pp_loss: 2.312577
[INFO] 2021-07-09 16:56:36,827 [run_pretraining.py:  512]:	********exe.run_412******* 
[INFO] 2021-07-09 16:56:39,123 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:39,124 [run_pretraining.py:  534]:	loss/total_loss, 2.165249824523926, 413
[INFO] 2021-07-09 16:56:39,124 [run_pretraining.py:  535]:	loss/mlm_loss, 2.165249824523926, 413
[INFO] 2021-07-09 16:56:39,124 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.120000085094944e-06, 413
[INFO] 2021-07-09 16:56:39,124 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 413
[INFO] 2021-07-09 16:56:39,124 [run_pretraining.py:  558]:	worker_index: 5, step: 413, cost: 2.165250, mlm loss: 2.165250, speed: 0.435498 steps/s, speed: 3.483987 samples/s, speed: 1783.801524 tokens/s, learning rate: 4.120e-06, loss_scalings: 377.789520, pp_loss: 2.238582
[INFO] 2021-07-09 16:56:39,124 [run_pretraining.py:  512]:	********exe.run_413******* 
[INFO] 2021-07-09 16:56:41,354 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:41,355 [run_pretraining.py:  534]:	loss/total_loss, 2.062067747116089, 414
[INFO] 2021-07-09 16:56:41,355 [run_pretraining.py:  535]:	loss/mlm_loss, 2.062067747116089, 414
[INFO] 2021-07-09 16:56:41,355 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.129999979340937e-06, 414
[INFO] 2021-07-09 16:56:41,355 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 414
[INFO] 2021-07-09 16:56:41,355 [run_pretraining.py:  558]:	worker_index: 5, step: 414, cost: 2.062068, mlm loss: 2.062068, speed: 0.448454 steps/s, speed: 3.587636 samples/s, speed: 1836.869478 tokens/s, learning rate: 4.130e-06, loss_scalings: 377.789520, pp_loss: 2.146209
[INFO] 2021-07-09 16:56:41,355 [run_pretraining.py:  512]:	********exe.run_414******* 
[INFO] 2021-07-09 16:56:43,585 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:43,586 [run_pretraining.py:  534]:	loss/total_loss, 1.9921952486038208, 415
[INFO] 2021-07-09 16:56:43,586 [run_pretraining.py:  535]:	loss/mlm_loss, 1.9921952486038208, 415
[INFO] 2021-07-09 16:56:43,586 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.13999987358693e-06, 415
[INFO] 2021-07-09 16:56:43,586 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 415
[INFO] 2021-07-09 16:56:43,586 [run_pretraining.py:  558]:	worker_index: 5, step: 415, cost: 1.992195, mlm loss: 1.992195, speed: 0.448269 steps/s, speed: 3.586148 samples/s, speed: 1836.107967 tokens/s, learning rate: 4.140e-06, loss_scalings: 377.789520, pp_loss: 1.983358
[INFO] 2021-07-09 16:56:43,587 [run_pretraining.py:  512]:	********exe.run_415******* 
[INFO] 2021-07-09 16:56:45,864 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:45,865 [run_pretraining.py:  534]:	loss/total_loss, 1.960378885269165, 416
[INFO] 2021-07-09 16:56:45,865 [run_pretraining.py:  535]:	loss/mlm_loss, 1.960378885269165, 416
[INFO] 2021-07-09 16:56:45,865 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.149999767832924e-06, 416
[INFO] 2021-07-09 16:56:45,865 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 416
[INFO] 2021-07-09 16:56:45,865 [run_pretraining.py:  558]:	worker_index: 5, step: 416, cost: 1.960379, mlm loss: 1.960379, speed: 0.438947 steps/s, speed: 3.511577 samples/s, speed: 1797.927635 tokens/s, learning rate: 4.150e-06, loss_scalings: 377.789520, pp_loss: 2.001115
[INFO] 2021-07-09 16:56:45,865 [run_pretraining.py:  512]:	********exe.run_416******* 
[INFO] 2021-07-09 16:56:48,190 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:48,190 [run_pretraining.py:  534]:	loss/total_loss, 2.1337594985961914, 417
[INFO] 2021-07-09 16:56:48,191 [run_pretraining.py:  535]:	loss/mlm_loss, 2.1337594985961914, 417
[INFO] 2021-07-09 16:56:48,191 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.160000116826268e-06, 417
[INFO] 2021-07-09 16:56:48,191 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 417
[INFO] 2021-07-09 16:56:48,191 [run_pretraining.py:  558]:	worker_index: 5, step: 417, cost: 2.133759, mlm loss: 2.133759, speed: 0.430130 steps/s, speed: 3.441044 samples/s, speed: 1761.814521 tokens/s, learning rate: 4.160e-06, loss_scalings: 377.789520, pp_loss: 2.009220
[INFO] 2021-07-09 16:56:48,191 [run_pretraining.py:  512]:	********exe.run_417******* 
[INFO] 2021-07-09 16:56:50,496 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:50,496 [run_pretraining.py:  534]:	loss/total_loss, 1.973490595817566, 418
[INFO] 2021-07-09 16:56:50,496 [run_pretraining.py:  535]:	loss/mlm_loss, 1.973490595817566, 418
[INFO] 2021-07-09 16:56:50,496 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.170000011072261e-06, 418
[INFO] 2021-07-09 16:56:50,497 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 418
[INFO] 2021-07-09 16:56:50,497 [run_pretraining.py:  558]:	worker_index: 5, step: 418, cost: 1.973491, mlm loss: 1.973491, speed: 0.433829 steps/s, speed: 3.470629 samples/s, speed: 1776.961976 tokens/s, learning rate: 4.170e-06, loss_scalings: 377.789520, pp_loss: 2.005127
[INFO] 2021-07-09 16:56:50,497 [run_pretraining.py:  512]:	********exe.run_418******* 
[INFO] 2021-07-09 16:56:52,793 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:52,794 [run_pretraining.py:  534]:	loss/total_loss, 2.007725715637207, 419
[INFO] 2021-07-09 16:56:52,794 [run_pretraining.py:  535]:	loss/mlm_loss, 2.007725715637207, 419
[INFO] 2021-07-09 16:56:52,794 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.179999905318255e-06, 419
[INFO] 2021-07-09 16:56:52,794 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 419
[INFO] 2021-07-09 16:56:52,794 [run_pretraining.py:  558]:	worker_index: 5, step: 419, cost: 2.007726, mlm loss: 2.007726, speed: 0.435426 steps/s, speed: 3.483406 samples/s, speed: 1783.503750 tokens/s, learning rate: 4.180e-06, loss_scalings: 377.789520, pp_loss: 1.993821
[INFO] 2021-07-09 16:56:52,794 [run_pretraining.py:  512]:	********exe.run_419******* 
[INFO] 2021-07-09 16:56:55,126 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:55,126 [run_pretraining.py:  534]:	loss/total_loss, 2.0122008323669434, 420
[INFO] 2021-07-09 16:56:55,126 [run_pretraining.py:  535]:	loss/mlm_loss, 2.0122008323669434, 420
[INFO] 2021-07-09 16:56:55,127 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.190000254311599e-06, 420
[INFO] 2021-07-09 16:56:55,127 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 420
[INFO] 2021-07-09 16:56:55,127 [run_pretraining.py:  558]:	worker_index: 5, step: 420, cost: 2.012201, mlm loss: 2.012201, speed: 0.428819 steps/s, speed: 3.430550 samples/s, speed: 1756.441572 tokens/s, learning rate: 4.190e-06, loss_scalings: 377.789520, pp_loss: 2.042598
[INFO] 2021-07-09 16:56:55,127 [run_pretraining.py:  512]:	********exe.run_420******* 
[INFO] 2021-07-09 16:56:57,448 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:57,448 [run_pretraining.py:  534]:	loss/total_loss, 2.0732078552246094, 421
[INFO] 2021-07-09 16:56:57,449 [run_pretraining.py:  535]:	loss/mlm_loss, 2.0732078552246094, 421
[INFO] 2021-07-09 16:56:57,449 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.199999693810241e-06, 421
[INFO] 2021-07-09 16:56:57,449 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 421
[INFO] 2021-07-09 16:56:57,449 [run_pretraining.py:  558]:	worker_index: 5, step: 421, cost: 2.073208, mlm loss: 2.073208, speed: 0.430754 steps/s, speed: 3.446029 samples/s, speed: 1764.366648 tokens/s, learning rate: 4.200e-06, loss_scalings: 377.789520, pp_loss: 2.031550
[INFO] 2021-07-09 16:56:57,449 [run_pretraining.py:  512]:	********exe.run_421******* 
[INFO] 2021-07-09 16:56:59,729 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:56:59,729 [run_pretraining.py:  534]:	loss/total_loss, 1.9752815961837769, 422
[INFO] 2021-07-09 16:56:59,729 [run_pretraining.py:  535]:	loss/mlm_loss, 1.9752815961837769, 422
[INFO] 2021-07-09 16:56:59,729 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.2100000428035855e-06, 422
[INFO] 2021-07-09 16:56:59,729 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 422
[INFO] 2021-07-09 16:56:59,729 [run_pretraining.py:  558]:	worker_index: 5, step: 422, cost: 1.975282, mlm loss: 1.975282, speed: 0.438610 steps/s, speed: 3.508880 samples/s, speed: 1796.546483 tokens/s, learning rate: 4.210e-06, loss_scalings: 377.789520, pp_loss: 2.032027
[INFO] 2021-07-09 16:56:59,729 [run_pretraining.py:  512]:	********exe.run_422******* 
[INFO] 2021-07-09 16:57:02,030 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:02,031 [run_pretraining.py:  534]:	loss/total_loss, 2.039415121078491, 423
[INFO] 2021-07-09 16:57:02,031 [run_pretraining.py:  535]:	loss/mlm_loss, 2.039415121078491, 423
[INFO] 2021-07-09 16:57:02,031 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.219999937049579e-06, 423
[INFO] 2021-07-09 16:57:02,031 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 423
[INFO] 2021-07-09 16:57:02,031 [run_pretraining.py:  558]:	worker_index: 5, step: 423, cost: 2.039415, mlm loss: 2.039415, speed: 0.434545 steps/s, speed: 3.476359 samples/s, speed: 1779.895788 tokens/s, learning rate: 4.220e-06, loss_scalings: 377.789520, pp_loss: 1.898971
[INFO] 2021-07-09 16:57:02,031 [run_pretraining.py:  512]:	********exe.run_423******* 
[INFO] 2021-07-09 16:57:04,320 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:04,321 [run_pretraining.py:  534]:	loss/total_loss, 1.7861549854278564, 424
[INFO] 2021-07-09 16:57:04,321 [run_pretraining.py:  535]:	loss/mlm_loss, 1.7861549854278564, 424
[INFO] 2021-07-09 16:57:04,321 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.229999831295572e-06, 424
[INFO] 2021-07-09 16:57:04,321 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 424
[INFO] 2021-07-09 16:57:04,321 [run_pretraining.py:  558]:	worker_index: 5, step: 424, cost: 1.786155, mlm loss: 1.786155, speed: 0.436866 steps/s, speed: 3.494928 samples/s, speed: 1789.403069 tokens/s, learning rate: 4.230e-06, loss_scalings: 377.789520, pp_loss: 1.782579
[INFO] 2021-07-09 16:57:04,321 [run_pretraining.py:  512]:	********exe.run_424******* 
[INFO] 2021-07-09 16:57:06,543 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:06,543 [run_pretraining.py:  534]:	loss/total_loss, 1.6548070907592773, 425
[INFO] 2021-07-09 16:57:06,544 [run_pretraining.py:  535]:	loss/mlm_loss, 1.6548070907592773, 425
[INFO] 2021-07-09 16:57:06,544 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.2399997255415656e-06, 425
[INFO] 2021-07-09 16:57:06,544 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 425
[INFO] 2021-07-09 16:57:06,544 [run_pretraining.py:  558]:	worker_index: 5, step: 425, cost: 1.654807, mlm loss: 1.654807, speed: 0.450030 steps/s, speed: 3.600244 samples/s, speed: 1843.324901 tokens/s, learning rate: 4.240e-06, loss_scalings: 377.789520, pp_loss: 1.675429
[INFO] 2021-07-09 16:57:06,544 [run_pretraining.py:  512]:	********exe.run_425******* 
[INFO] 2021-07-09 16:57:08,818 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:08,819 [run_pretraining.py:  534]:	loss/total_loss, 1.592656135559082, 426
[INFO] 2021-07-09 16:57:08,819 [run_pretraining.py:  535]:	loss/mlm_loss, 1.592656135559082, 426
[INFO] 2021-07-09 16:57:08,819 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.25000007453491e-06, 426
[INFO] 2021-07-09 16:57:08,819 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 426
[INFO] 2021-07-09 16:57:08,819 [run_pretraining.py:  558]:	worker_index: 5, step: 426, cost: 1.592656, mlm loss: 1.592656, speed: 0.439632 steps/s, speed: 3.517059 samples/s, speed: 1800.734259 tokens/s, learning rate: 4.250e-06, loss_scalings: 377.789520, pp_loss: 1.606317
[INFO] 2021-07-09 16:57:08,819 [run_pretraining.py:  512]:	********exe.run_426******* 
[INFO] 2021-07-09 16:57:11,202 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:11,203 [run_pretraining.py:  534]:	loss/total_loss, 1.5359416007995605, 427
[INFO] 2021-07-09 16:57:11,203 [run_pretraining.py:  535]:	loss/mlm_loss, 1.5359416007995605, 427
[INFO] 2021-07-09 16:57:11,203 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.259999514033552e-06, 427
[INFO] 2021-07-09 16:57:11,203 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 427
[INFO] 2021-07-09 16:57:11,203 [run_pretraining.py:  558]:	worker_index: 5, step: 427, cost: 1.535942, mlm loss: 1.535942, speed: 0.419607 steps/s, speed: 3.356856 samples/s, speed: 1718.710324 tokens/s, learning rate: 4.260e-06, loss_scalings: 377.789520, pp_loss: 1.533985
[INFO] 2021-07-09 16:57:11,203 [run_pretraining.py:  512]:	********exe.run_427******* 
[INFO] 2021-07-09 16:57:13,481 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:13,481 [run_pretraining.py:  534]:	loss/total_loss, 1.4800517559051514, 428
[INFO] 2021-07-09 16:57:13,482 [run_pretraining.py:  535]:	loss/mlm_loss, 1.4800517559051514, 428
[INFO] 2021-07-09 16:57:13,482 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.2699998630268965e-06, 428
[INFO] 2021-07-09 16:57:13,482 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 428
[INFO] 2021-07-09 16:57:13,482 [run_pretraining.py:  558]:	worker_index: 5, step: 428, cost: 1.480052, mlm loss: 1.480052, speed: 0.438947 steps/s, speed: 3.511574 samples/s, speed: 1797.926130 tokens/s, learning rate: 4.270e-06, loss_scalings: 377.789520, pp_loss: 1.512073
[INFO] 2021-07-09 16:57:13,482 [run_pretraining.py:  512]:	********exe.run_428******* 
[INFO] 2021-07-09 16:57:15,725 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:15,725 [run_pretraining.py:  534]:	loss/total_loss, 1.413735032081604, 429
[INFO] 2021-07-09 16:57:15,725 [run_pretraining.py:  535]:	loss/mlm_loss, 1.413735032081604, 429
[INFO] 2021-07-09 16:57:15,726 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.280000212020241e-06, 429
[INFO] 2021-07-09 16:57:15,726 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 429
[INFO] 2021-07-09 16:57:15,726 [run_pretraining.py:  558]:	worker_index: 5, step: 429, cost: 1.413735, mlm loss: 1.413735, speed: 0.445821 steps/s, speed: 3.566564 samples/s, speed: 1826.080862 tokens/s, learning rate: 4.280e-06, loss_scalings: 377.789520, pp_loss: 1.430654
[INFO] 2021-07-09 16:57:15,726 [run_pretraining.py:  512]:	********exe.run_429******* 
[INFO] 2021-07-09 16:57:17,957 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:17,957 [run_pretraining.py:  534]:	loss/total_loss, 1.3937479257583618, 430
[INFO] 2021-07-09 16:57:17,957 [run_pretraining.py:  535]:	loss/mlm_loss, 1.3937479257583618, 430
[INFO] 2021-07-09 16:57:17,958 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.289999651518883e-06, 430
[INFO] 2021-07-09 16:57:17,958 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 430
[INFO] 2021-07-09 16:57:17,958 [run_pretraining.py:  558]:	worker_index: 5, step: 430, cost: 1.393748, mlm loss: 1.393748, speed: 0.448180 steps/s, speed: 3.585437 samples/s, speed: 1835.743827 tokens/s, learning rate: 4.290e-06, loss_scalings: 377.789520, pp_loss: 1.402175
[INFO] 2021-07-09 16:57:17,958 [run_pretraining.py:  512]:	********exe.run_430******* 
[INFO] 2021-07-09 16:57:20,182 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:20,183 [run_pretraining.py:  534]:	loss/total_loss, 1.4033167362213135, 431
[INFO] 2021-07-09 16:57:20,183 [run_pretraining.py:  535]:	loss/mlm_loss, 1.4033167362213135, 431
[INFO] 2021-07-09 16:57:20,183 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.300000000512227e-06, 431
[INFO] 2021-07-09 16:57:20,183 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 431
[INFO] 2021-07-09 16:57:20,183 [run_pretraining.py:  558]:	worker_index: 5, step: 431, cost: 1.403317, mlm loss: 1.403317, speed: 0.449471 steps/s, speed: 3.595770 samples/s, speed: 1841.034286 tokens/s, learning rate: 4.300e-06, loss_scalings: 377.789520, pp_loss: 1.431380
[INFO] 2021-07-09 16:57:20,183 [run_pretraining.py:  512]:	********exe.run_431******* 
[INFO] 2021-07-09 16:57:22,441 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:22,441 [run_pretraining.py:  534]:	loss/total_loss, 1.4991533756256104, 432
[INFO] 2021-07-09 16:57:22,442 [run_pretraining.py:  535]:	loss/mlm_loss, 1.4991533756256104, 432
[INFO] 2021-07-09 16:57:22,442 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.309999894758221e-06, 432
[INFO] 2021-07-09 16:57:22,442 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 432
[INFO] 2021-07-09 16:57:22,442 [run_pretraining.py:  558]:	worker_index: 5, step: 432, cost: 1.499153, mlm loss: 1.499153, speed: 0.442884 steps/s, speed: 3.543068 samples/s, speed: 1814.050890 tokens/s, learning rate: 4.310e-06, loss_scalings: 377.789520, pp_loss: 1.449643
[INFO] 2021-07-09 16:57:22,442 [run_pretraining.py:  512]:	********exe.run_432******* 
[INFO] 2021-07-09 16:57:24,868 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:24,869 [run_pretraining.py:  534]:	loss/total_loss, 1.4248789548873901, 433
[INFO] 2021-07-09 16:57:24,869 [run_pretraining.py:  535]:	loss/mlm_loss, 1.4248789548873901, 433
[INFO] 2021-07-09 16:57:24,870 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.319999789004214e-06, 433
[INFO] 2021-07-09 16:57:24,870 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 433
[INFO] 2021-07-09 16:57:24,870 [run_pretraining.py:  558]:	worker_index: 5, step: 433, cost: 1.424879, mlm loss: 1.424879, speed: 0.412003 steps/s, speed: 3.296021 samples/s, speed: 1687.562529 tokens/s, learning rate: 4.320e-06, loss_scalings: 377.789520, pp_loss: 1.437808
[INFO] 2021-07-09 16:57:24,870 [run_pretraining.py:  512]:	********exe.run_433******* 
[INFO] 2021-07-09 16:57:27,217 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:27,218 [run_pretraining.py:  534]:	loss/total_loss, 1.5195506811141968, 434
[INFO] 2021-07-09 16:57:27,218 [run_pretraining.py:  535]:	loss/mlm_loss, 1.5195506811141968, 434
[INFO] 2021-07-09 16:57:27,218 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.3299996832502075e-06, 434
[INFO] 2021-07-09 16:57:27,218 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 434
[INFO] 2021-07-09 16:57:27,218 [run_pretraining.py:  558]:	worker_index: 5, step: 434, cost: 1.519551, mlm loss: 1.519551, speed: 0.425916 steps/s, speed: 3.407329 samples/s, speed: 1744.552617 tokens/s, learning rate: 4.330e-06, loss_scalings: 377.789520, pp_loss: 1.443768
[INFO] 2021-07-09 16:57:27,218 [run_pretraining.py:  512]:	********exe.run_434******* 
[INFO] 2021-07-09 16:57:29,595 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:29,595 [run_pretraining.py:  534]:	loss/total_loss, 1.3631118535995483, 435
[INFO] 2021-07-09 16:57:29,595 [run_pretraining.py:  535]:	loss/mlm_loss, 1.3631118535995483, 435
[INFO] 2021-07-09 16:57:29,595 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.340000032243552e-06, 435
[INFO] 2021-07-09 16:57:29,596 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 435
[INFO] 2021-07-09 16:57:29,596 [run_pretraining.py:  558]:	worker_index: 5, step: 435, cost: 1.363112, mlm loss: 1.363112, speed: 0.420760 steps/s, speed: 3.366083 samples/s, speed: 1723.434695 tokens/s, learning rate: 4.340e-06, loss_scalings: 377.789520, pp_loss: 1.400601
[INFO] 2021-07-09 16:57:29,596 [run_pretraining.py:  512]:	********exe.run_435******* 
[INFO] 2021-07-09 16:57:32,063 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:32,063 [run_pretraining.py:  534]:	loss/total_loss, 1.3993072509765625, 436
[INFO] 2021-07-09 16:57:32,063 [run_pretraining.py:  535]:	loss/mlm_loss, 1.3993072509765625, 436
[INFO] 2021-07-09 16:57:32,064 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.349999926489545e-06, 436
[INFO] 2021-07-09 16:57:32,064 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 436
[INFO] 2021-07-09 16:57:32,064 [run_pretraining.py:  558]:	worker_index: 5, step: 436, cost: 1.399307, mlm loss: 1.399307, speed: 0.405292 steps/s, speed: 3.242340 samples/s, speed: 1660.077922 tokens/s, learning rate: 4.350e-06, loss_scalings: 377.789520, pp_loss: 1.388307
[INFO] 2021-07-09 16:57:32,064 [run_pretraining.py:  512]:	********exe.run_436******* 
[INFO] 2021-07-09 16:57:34,456 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:34,457 [run_pretraining.py:  534]:	loss/total_loss, 1.3580549955368042, 437
[INFO] 2021-07-09 16:57:34,457 [run_pretraining.py:  535]:	loss/mlm_loss, 1.3580549955368042, 437
[INFO] 2021-07-09 16:57:34,457 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.359999820735538e-06, 437
[INFO] 2021-07-09 16:57:34,457 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 437
[INFO] 2021-07-09 16:57:34,457 [run_pretraining.py:  558]:	worker_index: 5, step: 437, cost: 1.358055, mlm loss: 1.358055, speed: 0.417929 steps/s, speed: 3.343429 samples/s, speed: 1711.835779 tokens/s, learning rate: 4.360e-06, loss_scalings: 377.789520, pp_loss: 1.360549
[INFO] 2021-07-09 16:57:34,457 [run_pretraining.py:  512]:	********exe.run_437******* 
[INFO] 2021-07-09 16:57:36,860 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:36,860 [run_pretraining.py:  534]:	loss/total_loss, 1.3297266960144043, 438
[INFO] 2021-07-09 16:57:36,860 [run_pretraining.py:  535]:	loss/mlm_loss, 1.3297266960144043, 438
[INFO] 2021-07-09 16:57:36,861 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.369999714981532e-06, 438
[INFO] 2021-07-09 16:57:36,861 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 438
[INFO] 2021-07-09 16:57:36,861 [run_pretraining.py:  558]:	worker_index: 5, step: 438, cost: 1.329727, mlm loss: 1.329727, speed: 0.416183 steps/s, speed: 3.329460 samples/s, speed: 1704.683737 tokens/s, learning rate: 4.370e-06, loss_scalings: 377.789520, pp_loss: 1.348452
[INFO] 2021-07-09 16:57:36,861 [run_pretraining.py:  512]:	********exe.run_438******* 
[INFO] 2021-07-09 16:57:39,328 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:39,328 [run_pretraining.py:  534]:	loss/total_loss, 1.2970231771469116, 439
[INFO] 2021-07-09 16:57:39,328 [run_pretraining.py:  535]:	loss/mlm_loss, 1.2970231771469116, 439
[INFO] 2021-07-09 16:57:39,328 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.380000063974876e-06, 439
[INFO] 2021-07-09 16:57:39,329 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 439
[INFO] 2021-07-09 16:57:39,329 [run_pretraining.py:  558]:	worker_index: 5, step: 439, cost: 1.297023, mlm loss: 1.297023, speed: 0.405320 steps/s, speed: 3.242560 samples/s, speed: 1660.190700 tokens/s, learning rate: 4.380e-06, loss_scalings: 377.789520, pp_loss: 1.300740
[INFO] 2021-07-09 16:57:39,329 [run_pretraining.py:  512]:	********exe.run_439******* 
[INFO] 2021-07-09 16:57:41,988 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:41,988 [run_pretraining.py:  534]:	loss/total_loss, 1.3248668909072876, 440
[INFO] 2021-07-09 16:57:41,989 [run_pretraining.py:  535]:	loss/mlm_loss, 1.3248668909072876, 440
[INFO] 2021-07-09 16:57:41,989 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.389999958220869e-06, 440
[INFO] 2021-07-09 16:57:41,989 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 440
[INFO] 2021-07-09 16:57:41,989 [run_pretraining.py:  558]:	worker_index: 5, step: 440, cost: 1.324867, mlm loss: 1.324867, speed: 0.376002 steps/s, speed: 3.008018 samples/s, speed: 1540.105227 tokens/s, learning rate: 4.390e-06, loss_scalings: 377.789520, pp_loss: 1.287368
[INFO] 2021-07-09 16:57:41,989 [run_pretraining.py:  512]:	********exe.run_440******* 
[INFO] 2021-07-09 16:57:44,227 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:44,227 [run_pretraining.py:  534]:	loss/total_loss, 1.2046664953231812, 441
[INFO] 2021-07-09 16:57:44,227 [run_pretraining.py:  535]:	loss/mlm_loss, 1.2046664953231812, 441
[INFO] 2021-07-09 16:57:44,228 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.399999852466863e-06, 441
[INFO] 2021-07-09 16:57:44,228 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 441
[INFO] 2021-07-09 16:57:44,228 [run_pretraining.py:  558]:	worker_index: 5, step: 441, cost: 1.204666, mlm loss: 1.204666, speed: 0.446794 steps/s, speed: 3.574351 samples/s, speed: 1830.067967 tokens/s, learning rate: 4.400e-06, loss_scalings: 377.789520, pp_loss: 1.230640
[INFO] 2021-07-09 16:57:44,228 [run_pretraining.py:  512]:	********exe.run_441******* 
[INFO] 2021-07-09 16:57:46,504 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:46,505 [run_pretraining.py:  534]:	loss/total_loss, 1.1764987707138062, 442
[INFO] 2021-07-09 16:57:46,505 [run_pretraining.py:  535]:	loss/mlm_loss, 1.1764987707138062, 442
[INFO] 2021-07-09 16:57:46,505 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.410000201460207e-06, 442
[INFO] 2021-07-09 16:57:46,505 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 442
[INFO] 2021-07-09 16:57:46,505 [run_pretraining.py:  558]:	worker_index: 5, step: 442, cost: 1.176499, mlm loss: 1.176499, speed: 0.439184 steps/s, speed: 3.513474 samples/s, speed: 1798.898683 tokens/s, learning rate: 4.410e-06, loss_scalings: 377.789520, pp_loss: 1.184509
[INFO] 2021-07-09 16:57:46,505 [run_pretraining.py:  512]:	********exe.run_442******* 
[INFO] 2021-07-09 16:57:48,766 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:48,766 [run_pretraining.py:  534]:	loss/total_loss, 1.144134521484375, 443
[INFO] 2021-07-09 16:57:48,766 [run_pretraining.py:  535]:	loss/mlm_loss, 1.144134521484375, 443
[INFO] 2021-07-09 16:57:48,766 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.419999640958849e-06, 443
[INFO] 2021-07-09 16:57:48,766 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 443
[INFO] 2021-07-09 16:57:48,766 [run_pretraining.py:  558]:	worker_index: 5, step: 443, cost: 1.144135, mlm loss: 1.144135, speed: 0.442394 steps/s, speed: 3.539152 samples/s, speed: 1812.045680 tokens/s, learning rate: 4.420e-06, loss_scalings: 377.789520, pp_loss: 1.152714
[INFO] 2021-07-09 16:57:48,767 [run_pretraining.py:  512]:	********exe.run_443******* 
[INFO] 2021-07-09 16:57:51,036 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:51,036 [run_pretraining.py:  534]:	loss/total_loss, 1.2050633430480957, 444
[INFO] 2021-07-09 16:57:51,036 [run_pretraining.py:  535]:	loss/mlm_loss, 1.2050633430480957, 444
[INFO] 2021-07-09 16:57:51,037 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.4299999899521936e-06, 444
[INFO] 2021-07-09 16:57:51,037 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 444
[INFO] 2021-07-09 16:57:51,037 [run_pretraining.py:  558]:	worker_index: 5, step: 444, cost: 1.205063, mlm loss: 1.205063, speed: 0.440612 steps/s, speed: 3.524895 samples/s, speed: 1804.746307 tokens/s, learning rate: 4.430e-06, loss_scalings: 377.789520, pp_loss: 1.180744
[INFO] 2021-07-09 16:57:51,037 [run_pretraining.py:  512]:	********exe.run_444******* 
[INFO] 2021-07-09 16:57:53,355 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:53,356 [run_pretraining.py:  534]:	loss/total_loss, 1.1560207605361938, 445
[INFO] 2021-07-09 16:57:53,356 [run_pretraining.py:  535]:	loss/mlm_loss, 1.1560207605361938, 445
[INFO] 2021-07-09 16:57:53,356 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.439999884198187e-06, 445
[INFO] 2021-07-09 16:57:53,356 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 445
[INFO] 2021-07-09 16:57:53,356 [run_pretraining.py:  558]:	worker_index: 5, step: 445, cost: 1.156021, mlm loss: 1.156021, speed: 0.431274 steps/s, speed: 3.450194 samples/s, speed: 1766.499227 tokens/s, learning rate: 4.440e-06, loss_scalings: 377.789520, pp_loss: 1.153395
[INFO] 2021-07-09 16:57:53,356 [run_pretraining.py:  512]:	********exe.run_445******* 
[INFO] 2021-07-09 16:57:55,663 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:55,664 [run_pretraining.py:  534]:	loss/total_loss, 1.134108304977417, 446
[INFO] 2021-07-09 16:57:55,664 [run_pretraining.py:  535]:	loss/mlm_loss, 1.134108304977417, 446
[INFO] 2021-07-09 16:57:55,664 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.44999977844418e-06, 446
[INFO] 2021-07-09 16:57:55,664 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 446
[INFO] 2021-07-09 16:57:55,664 [run_pretraining.py:  558]:	worker_index: 5, step: 446, cost: 1.134108, mlm loss: 1.134108, speed: 0.433357 steps/s, speed: 3.466853 samples/s, speed: 1775.028525 tokens/s, learning rate: 4.450e-06, loss_scalings: 377.789520, pp_loss: 1.145601
[INFO] 2021-07-09 16:57:55,664 [run_pretraining.py:  512]:	********exe.run_446******* 
[INFO] 2021-07-09 16:57:57,907 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:57:57,908 [run_pretraining.py:  534]:	loss/total_loss, 1.095185399055481, 447
[INFO] 2021-07-09 16:57:57,908 [run_pretraining.py:  535]:	loss/mlm_loss, 1.095185399055481, 447
[INFO] 2021-07-09 16:57:57,908 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.459999672690174e-06, 447
[INFO] 2021-07-09 16:57:57,908 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 447
[INFO] 2021-07-09 16:57:57,908 [run_pretraining.py:  558]:	worker_index: 5, step: 447, cost: 1.095185, mlm loss: 1.095185, speed: 0.445801 steps/s, speed: 3.566408 samples/s, speed: 1826.000897 tokens/s, learning rate: 4.460e-06, loss_scalings: 377.789520, pp_loss: 1.106940
[INFO] 2021-07-09 16:57:57,908 [run_pretraining.py:  512]:	********exe.run_447******* 
[INFO] 2021-07-09 16:58:00,170 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:00,170 [run_pretraining.py:  534]:	loss/total_loss, 1.096673607826233, 448
[INFO] 2021-07-09 16:58:00,170 [run_pretraining.py:  535]:	loss/mlm_loss, 1.096673607826233, 448
[INFO] 2021-07-09 16:58:00,171 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.470000021683518e-06, 448
[INFO] 2021-07-09 16:58:00,171 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 448
[INFO] 2021-07-09 16:58:00,171 [run_pretraining.py:  558]:	worker_index: 5, step: 448, cost: 1.096674, mlm loss: 1.096674, speed: 0.442120 steps/s, speed: 3.536961 samples/s, speed: 1810.924086 tokens/s, learning rate: 4.470e-06, loss_scalings: 377.789520, pp_loss: 1.112275
[INFO] 2021-07-09 16:58:00,171 [run_pretraining.py:  512]:	********exe.run_448******* 
[INFO] 2021-07-09 16:58:02,395 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:02,396 [run_pretraining.py:  534]:	loss/total_loss, 1.0422918796539307, 449
[INFO] 2021-07-09 16:58:02,396 [run_pretraining.py:  535]:	loss/mlm_loss, 1.0422918796539307, 449
[INFO] 2021-07-09 16:58:02,396 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.479999915929511e-06, 449
[INFO] 2021-07-09 16:58:02,396 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 449
[INFO] 2021-07-09 16:58:02,396 [run_pretraining.py:  558]:	worker_index: 5, step: 449, cost: 1.042292, mlm loss: 1.042292, speed: 0.449435 steps/s, speed: 3.595482 samples/s, speed: 1840.886725 tokens/s, learning rate: 4.480e-06, loss_scalings: 377.789520, pp_loss: 1.048357
[INFO] 2021-07-09 16:58:02,397 [run_pretraining.py:  512]:	********exe.run_449******* 
[INFO] 2021-07-09 16:58:04,700 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:04,701 [run_pretraining.py:  534]:	loss/total_loss, 1.0294835567474365, 450
[INFO] 2021-07-09 16:58:04,701 [run_pretraining.py:  535]:	loss/mlm_loss, 1.0294835567474365, 450
[INFO] 2021-07-09 16:58:04,701 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.4899998101755045e-06, 450
[INFO] 2021-07-09 16:58:04,701 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 450
[INFO] 2021-07-09 16:58:04,701 [run_pretraining.py:  558]:	worker_index: 5, step: 450, cost: 1.029484, mlm loss: 1.029484, speed: 0.434073 steps/s, speed: 3.472580 samples/s, speed: 1777.961102 tokens/s, learning rate: 4.490e-06, loss_scalings: 377.789520, pp_loss: 1.015583
[INFO] 2021-07-09 16:58:04,701 [run_pretraining.py:  512]:	********exe.run_450******* 
[INFO] 2021-07-09 16:58:06,952 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:06,952 [run_pretraining.py:  534]:	loss/total_loss, 1.016284704208374, 451
[INFO] 2021-07-09 16:58:06,953 [run_pretraining.py:  535]:	loss/mlm_loss, 1.016284704208374, 451
[INFO] 2021-07-09 16:58:06,953 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.500000159168849e-06, 451
[INFO] 2021-07-09 16:58:06,953 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 451
[INFO] 2021-07-09 16:58:06,953 [run_pretraining.py:  558]:	worker_index: 5, step: 451, cost: 1.016285, mlm loss: 1.016285, speed: 0.444211 steps/s, speed: 3.553684 samples/s, speed: 1819.486230 tokens/s, learning rate: 4.500e-06, loss_scalings: 377.789520, pp_loss: 0.971499
[INFO] 2021-07-09 16:58:06,953 [run_pretraining.py:  512]:	********exe.run_451******* 
[INFO] 2021-07-09 16:58:09,225 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:09,226 [run_pretraining.py:  534]:	loss/total_loss, 0.9672179818153381, 452
[INFO] 2021-07-09 16:58:09,226 [run_pretraining.py:  535]:	loss/mlm_loss, 0.9672179818153381, 452
[INFO] 2021-07-09 16:58:09,226 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.510000053414842e-06, 452
[INFO] 2021-07-09 16:58:09,226 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 452
[INFO] 2021-07-09 16:58:09,226 [run_pretraining.py:  558]:	worker_index: 5, step: 452, cost: 0.967218, mlm loss: 0.967218, speed: 0.440006 steps/s, speed: 3.520047 samples/s, speed: 1802.263839 tokens/s, learning rate: 4.510e-06, loss_scalings: 377.789520, pp_loss: 0.954274
[INFO] 2021-07-09 16:58:09,226 [run_pretraining.py:  512]:	********exe.run_452******* 
[INFO] 2021-07-09 16:58:11,453 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:11,454 [run_pretraining.py:  534]:	loss/total_loss, 0.9165754318237305, 453
[INFO] 2021-07-09 16:58:11,454 [run_pretraining.py:  535]:	loss/mlm_loss, 0.9165754318237305, 453
[INFO] 2021-07-09 16:58:11,454 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.5199999476608355e-06, 453
[INFO] 2021-07-09 16:58:11,454 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 453
[INFO] 2021-07-09 16:58:11,454 [run_pretraining.py:  558]:	worker_index: 5, step: 453, cost: 0.916575, mlm loss: 0.916575, speed: 0.448938 steps/s, speed: 3.591503 samples/s, speed: 1838.849337 tokens/s, learning rate: 4.520e-06, loss_scalings: 377.789520, pp_loss: 0.916951
[INFO] 2021-07-09 16:58:11,455 [run_pretraining.py:  512]:	********exe.run_453******* 
[INFO] 2021-07-09 16:58:13,702 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:13,703 [run_pretraining.py:  534]:	loss/total_loss, 0.9422053694725037, 454
[INFO] 2021-07-09 16:58:13,703 [run_pretraining.py:  535]:	loss/mlm_loss, 0.9422053694725037, 454
[INFO] 2021-07-09 16:58:13,703 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.529999841906829e-06, 454
[INFO] 2021-07-09 16:58:13,703 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 454
[INFO] 2021-07-09 16:58:13,703 [run_pretraining.py:  558]:	worker_index: 5, step: 454, cost: 0.942205, mlm loss: 0.942205, speed: 0.444818 steps/s, speed: 3.558542 samples/s, speed: 1821.973505 tokens/s, learning rate: 4.530e-06, loss_scalings: 377.789520, pp_loss: 0.916730
[INFO] 2021-07-09 16:58:13,703 [run_pretraining.py:  512]:	********exe.run_454******* 
[INFO] 2021-07-09 16:58:15,927 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:15,927 [run_pretraining.py:  534]:	loss/total_loss, 0.9248193502426147, 455
[INFO] 2021-07-09 16:58:15,927 [run_pretraining.py:  535]:	loss/mlm_loss, 0.9248193502426147, 455
[INFO] 2021-07-09 16:58:15,927 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.540000190900173e-06, 455
[INFO] 2021-07-09 16:58:15,928 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 455
[INFO] 2021-07-09 16:58:15,928 [run_pretraining.py:  558]:	worker_index: 5, step: 455, cost: 0.924819, mlm loss: 0.924819, speed: 0.449715 steps/s, speed: 3.597719 samples/s, speed: 1842.032322 tokens/s, learning rate: 4.540e-06, loss_scalings: 377.789520, pp_loss: 0.890277
[INFO] 2021-07-09 16:58:15,928 [run_pretraining.py:  512]:	********exe.run_455******* 
[INFO] 2021-07-09 16:58:18,179 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:18,179 [run_pretraining.py:  534]:	loss/total_loss, 0.8823902010917664, 456
[INFO] 2021-07-09 16:58:18,180 [run_pretraining.py:  535]:	loss/mlm_loss, 0.8823902010917664, 456
[INFO] 2021-07-09 16:58:18,180 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.5499996303988155e-06, 456
[INFO] 2021-07-09 16:58:18,180 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 456
[INFO] 2021-07-09 16:58:18,180 [run_pretraining.py:  558]:	worker_index: 5, step: 456, cost: 0.882390, mlm loss: 0.882390, speed: 0.444148 steps/s, speed: 3.553182 samples/s, speed: 1819.229399 tokens/s, learning rate: 4.550e-06, loss_scalings: 377.789520, pp_loss: 0.875634
[INFO] 2021-07-09 16:58:18,180 [run_pretraining.py:  512]:	********exe.run_456******* 
[INFO] 2021-07-09 16:58:20,413 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:20,413 [run_pretraining.py:  534]:	loss/total_loss, 0.8797461986541748, 457
[INFO] 2021-07-09 16:58:20,413 [run_pretraining.py:  535]:	loss/mlm_loss, 0.8797461986541748, 457
[INFO] 2021-07-09 16:58:20,413 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.55999997939216e-06, 457
[INFO] 2021-07-09 16:58:20,413 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 457
[INFO] 2021-07-09 16:58:20,413 [run_pretraining.py:  558]:	worker_index: 5, step: 457, cost: 0.879746, mlm loss: 0.879746, speed: 0.447828 steps/s, speed: 3.582627 samples/s, speed: 1834.304965 tokens/s, learning rate: 4.560e-06, loss_scalings: 377.789520, pp_loss: 0.873173
[INFO] 2021-07-09 16:58:20,414 [run_pretraining.py:  512]:	********exe.run_457******* 
[INFO] 2021-07-09 16:58:22,678 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:22,678 [run_pretraining.py:  534]:	loss/total_loss, 0.9325684309005737, 458
[INFO] 2021-07-09 16:58:22,679 [run_pretraining.py:  535]:	loss/mlm_loss, 0.9325684309005737, 458
[INFO] 2021-07-09 16:58:22,679 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.569999873638153e-06, 458
[INFO] 2021-07-09 16:58:22,679 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 458
[INFO] 2021-07-09 16:58:22,679 [run_pretraining.py:  558]:	worker_index: 5, step: 458, cost: 0.932568, mlm loss: 0.932568, speed: 0.441560 steps/s, speed: 3.532480 samples/s, speed: 1808.629839 tokens/s, learning rate: 4.570e-06, loss_scalings: 377.789520, pp_loss: 0.894986
[INFO] 2021-07-09 16:58:22,679 [run_pretraining.py:  512]:	********exe.run_458******* 
[INFO] 2021-07-09 16:58:24,918 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:24,919 [run_pretraining.py:  534]:	loss/total_loss, 0.88750159740448, 459
[INFO] 2021-07-09 16:58:24,919 [run_pretraining.py:  535]:	loss/mlm_loss, 0.88750159740448, 459
[INFO] 2021-07-09 16:58:24,919 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.579999767884146e-06, 459
[INFO] 2021-07-09 16:58:24,919 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 459
[INFO] 2021-07-09 16:58:24,919 [run_pretraining.py:  558]:	worker_index: 5, step: 459, cost: 0.887502, mlm loss: 0.887502, speed: 0.446558 steps/s, speed: 3.572461 samples/s, speed: 1829.099792 tokens/s, learning rate: 4.580e-06, loss_scalings: 377.789520, pp_loss: 0.900068
[INFO] 2021-07-09 16:58:24,919 [run_pretraining.py:  512]:	********exe.run_459******* 
[INFO] 2021-07-09 16:58:27,177 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:27,177 [run_pretraining.py:  534]:	loss/total_loss, 0.9189714789390564, 460
[INFO] 2021-07-09 16:58:27,178 [run_pretraining.py:  535]:	loss/mlm_loss, 0.9189714789390564, 460
[INFO] 2021-07-09 16:58:27,178 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.58999966213014e-06, 460
[INFO] 2021-07-09 16:58:27,178 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 460
[INFO] 2021-07-09 16:58:27,178 [run_pretraining.py:  558]:	worker_index: 5, step: 460, cost: 0.918971, mlm loss: 0.918971, speed: 0.442838 steps/s, speed: 3.542708 samples/s, speed: 1813.866256 tokens/s, learning rate: 4.590e-06, loss_scalings: 377.789520, pp_loss: 0.915444
[INFO] 2021-07-09 16:58:27,178 [run_pretraining.py:  512]:	********exe.run_460******* 
[INFO] 2021-07-09 16:58:29,416 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:29,416 [run_pretraining.py:  534]:	loss/total_loss, 0.9548019170761108, 461
[INFO] 2021-07-09 16:58:29,416 [run_pretraining.py:  535]:	loss/mlm_loss, 0.9548019170761108, 461
[INFO] 2021-07-09 16:58:29,416 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.600000011123484e-06, 461
[INFO] 2021-07-09 16:58:29,416 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 461
[INFO] 2021-07-09 16:58:29,417 [run_pretraining.py:  558]:	worker_index: 5, step: 461, cost: 0.954802, mlm loss: 0.954802, speed: 0.446798 steps/s, speed: 3.574384 samples/s, speed: 1830.084733 tokens/s, learning rate: 4.600e-06, loss_scalings: 377.789520, pp_loss: 0.970663
[INFO] 2021-07-09 16:58:29,417 [run_pretraining.py:  512]:	********exe.run_461******* 
[INFO] 2021-07-09 16:58:31,632 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:31,632 [run_pretraining.py:  534]:	loss/total_loss, 0.9794286489486694, 462
[INFO] 2021-07-09 16:58:31,632 [run_pretraining.py:  535]:	loss/mlm_loss, 0.9794286489486694, 462
[INFO] 2021-07-09 16:58:31,633 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.609999905369477e-06, 462
[INFO] 2021-07-09 16:58:31,633 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 462
[INFO] 2021-07-09 16:58:31,633 [run_pretraining.py:  558]:	worker_index: 5, step: 462, cost: 0.979429, mlm loss: 0.979429, speed: 0.451381 steps/s, speed: 3.611048 samples/s, speed: 1848.856765 tokens/s, learning rate: 4.610e-06, loss_scalings: 377.789520, pp_loss: 0.992228
[INFO] 2021-07-09 16:58:31,633 [run_pretraining.py:  512]:	********exe.run_462******* 
[INFO] 2021-07-09 16:58:33,847 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:33,847 [run_pretraining.py:  534]:	loss/total_loss, 0.9869861006736755, 463
[INFO] 2021-07-09 16:58:33,847 [run_pretraining.py:  535]:	loss/mlm_loss, 0.9869861006736755, 463
[INFO] 2021-07-09 16:58:33,847 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.619999799615471e-06, 463
[INFO] 2021-07-09 16:58:33,847 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 463
[INFO] 2021-07-09 16:58:33,848 [run_pretraining.py:  558]:	worker_index: 5, step: 463, cost: 0.986986, mlm loss: 0.986986, speed: 0.451628 steps/s, speed: 3.613026 samples/s, speed: 1849.869279 tokens/s, learning rate: 4.620e-06, loss_scalings: 377.789520, pp_loss: 0.992101
[INFO] 2021-07-09 16:58:33,848 [run_pretraining.py:  512]:	********exe.run_463******* 
[INFO] 2021-07-09 16:58:36,079 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:36,080 [run_pretraining.py:  534]:	loss/total_loss, 0.9766495227813721, 464
[INFO] 2021-07-09 16:58:36,080 [run_pretraining.py:  535]:	loss/mlm_loss, 0.9766495227813721, 464
[INFO] 2021-07-09 16:58:36,080 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.630000148608815e-06, 464
[INFO] 2021-07-09 16:58:36,080 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 464
[INFO] 2021-07-09 16:58:36,080 [run_pretraining.py:  558]:	worker_index: 5, step: 464, cost: 0.976650, mlm loss: 0.976650, speed: 0.448067 steps/s, speed: 3.584540 samples/s, speed: 1835.284346 tokens/s, learning rate: 4.630e-06, loss_scalings: 377.789520, pp_loss: 0.978554
[INFO] 2021-07-09 16:58:36,080 [run_pretraining.py:  512]:	********exe.run_464******* 
[INFO] 2021-07-09 16:58:38,305 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:38,306 [run_pretraining.py:  534]:	loss/total_loss, 0.9542555809020996, 465
[INFO] 2021-07-09 16:58:38,306 [run_pretraining.py:  535]:	loss/mlm_loss, 0.9542555809020996, 465
[INFO] 2021-07-09 16:58:38,306 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.640000042854808e-06, 465
[INFO] 2021-07-09 16:58:38,306 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 465
[INFO] 2021-07-09 16:58:38,306 [run_pretraining.py:  558]:	worker_index: 5, step: 465, cost: 0.954256, mlm loss: 0.954256, speed: 0.449328 steps/s, speed: 3.594622 samples/s, speed: 1840.446551 tokens/s, learning rate: 4.640e-06, loss_scalings: 377.789520, pp_loss: 0.961114
[INFO] 2021-07-09 16:58:38,306 [run_pretraining.py:  512]:	********exe.run_465******* 
[INFO] 2021-07-09 16:58:40,559 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:40,559 [run_pretraining.py:  534]:	loss/total_loss, 0.901772677898407, 466
[INFO] 2021-07-09 16:58:40,559 [run_pretraining.py:  535]:	loss/mlm_loss, 0.901772677898407, 466
[INFO] 2021-07-09 16:58:40,559 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.649999937100802e-06, 466
[INFO] 2021-07-09 16:58:40,560 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 466
[INFO] 2021-07-09 16:58:40,560 [run_pretraining.py:  558]:	worker_index: 5, step: 466, cost: 0.901773, mlm loss: 0.901773, speed: 0.443938 steps/s, speed: 3.551504 samples/s, speed: 1818.370036 tokens/s, learning rate: 4.650e-06, loss_scalings: 377.789520, pp_loss: 0.906774
[INFO] 2021-07-09 16:58:40,560 [run_pretraining.py:  512]:	********exe.run_466******* 
[INFO] 2021-07-09 16:58:42,759 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:42,759 [run_pretraining.py:  534]:	loss/total_loss, 0.8754462599754333, 467
[INFO] 2021-07-09 16:58:42,759 [run_pretraining.py:  535]:	loss/mlm_loss, 0.8754462599754333, 467
[INFO] 2021-07-09 16:58:42,759 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.659999831346795e-06, 467
[INFO] 2021-07-09 16:58:42,759 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 467
[INFO] 2021-07-09 16:58:42,760 [run_pretraining.py:  558]:	worker_index: 5, step: 467, cost: 0.875446, mlm loss: 0.875446, speed: 0.454698 steps/s, speed: 3.637584 samples/s, speed: 1862.443230 tokens/s, learning rate: 4.660e-06, loss_scalings: 377.789520, pp_loss: 0.860679
[INFO] 2021-07-09 16:58:42,760 [run_pretraining.py:  512]:	********exe.run_467******* 
[INFO] 2021-07-09 16:58:45,109 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:45,109 [run_pretraining.py:  534]:	loss/total_loss, 0.7888062000274658, 468
[INFO] 2021-07-09 16:58:45,109 [run_pretraining.py:  535]:	loss/mlm_loss, 0.7888062000274658, 468
[INFO] 2021-07-09 16:58:45,109 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.670000180340139e-06, 468
[INFO] 2021-07-09 16:58:45,109 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 468
[INFO] 2021-07-09 16:58:45,110 [run_pretraining.py:  558]:	worker_index: 5, step: 468, cost: 0.788806, mlm loss: 0.788806, speed: 0.425668 steps/s, speed: 3.405342 samples/s, speed: 1743.535290 tokens/s, learning rate: 4.670e-06, loss_scalings: 377.789520, pp_loss: 0.808353
[INFO] 2021-07-09 16:58:45,110 [run_pretraining.py:  512]:	********exe.run_468******* 
[INFO] 2021-07-09 16:58:47,311 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:47,312 [run_pretraining.py:  534]:	loss/total_loss, 0.7694341540336609, 469
[INFO] 2021-07-09 16:58:47,312 [run_pretraining.py:  535]:	loss/mlm_loss, 0.7694341540336609, 469
[INFO] 2021-07-09 16:58:47,312 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.679999619838782e-06, 469
[INFO] 2021-07-09 16:58:47,312 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 469
[INFO] 2021-07-09 16:58:47,312 [run_pretraining.py:  558]:	worker_index: 5, step: 469, cost: 0.769434, mlm loss: 0.769434, speed: 0.454132 steps/s, speed: 3.633055 samples/s, speed: 1860.124017 tokens/s, learning rate: 4.680e-06, loss_scalings: 377.789520, pp_loss: 0.760892
[INFO] 2021-07-09 16:58:47,312 [run_pretraining.py:  512]:	********exe.run_469******* 
[INFO] 2021-07-09 16:58:49,613 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:49,614 [run_pretraining.py:  534]:	loss/total_loss, 0.7217206954956055, 470
[INFO] 2021-07-09 16:58:49,614 [run_pretraining.py:  535]:	loss/mlm_loss, 0.7217206954956055, 470
[INFO] 2021-07-09 16:58:49,614 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.689999968832126e-06, 470
[INFO] 2021-07-09 16:58:49,614 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 470
[INFO] 2021-07-09 16:58:49,614 [run_pretraining.py:  558]:	worker_index: 5, step: 470, cost: 0.721721, mlm loss: 0.721721, speed: 0.434566 steps/s, speed: 3.476525 samples/s, speed: 1779.980802 tokens/s, learning rate: 4.690e-06, loss_scalings: 377.789520, pp_loss: 0.747226
[INFO] 2021-07-09 16:58:49,614 [run_pretraining.py:  512]:	********exe.run_470******* 
[INFO] 2021-07-09 16:58:51,950 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:51,950 [run_pretraining.py:  534]:	loss/total_loss, 0.7601495981216431, 471
[INFO] 2021-07-09 16:58:51,951 [run_pretraining.py:  535]:	loss/mlm_loss, 0.7601495981216431, 471
[INFO] 2021-07-09 16:58:51,951 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.699999863078119e-06, 471
[INFO] 2021-07-09 16:58:51,951 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 471
[INFO] 2021-07-09 16:58:51,951 [run_pretraining.py:  558]:	worker_index: 5, step: 471, cost: 0.760150, mlm loss: 0.760150, speed: 0.428069 steps/s, speed: 3.424555 samples/s, speed: 1753.372071 tokens/s, learning rate: 4.700e-06, loss_scalings: 377.789520, pp_loss: 0.739414
[INFO] 2021-07-09 16:58:51,951 [run_pretraining.py:  512]:	********exe.run_471******* 
[INFO] 2021-07-09 16:58:54,247 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:54,248 [run_pretraining.py:  534]:	loss/total_loss, 0.716551661491394, 472
[INFO] 2021-07-09 16:58:54,248 [run_pretraining.py:  535]:	loss/mlm_loss, 0.716551661491394, 472
[INFO] 2021-07-09 16:58:54,248 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.709999757324113e-06, 472
[INFO] 2021-07-09 16:58:54,248 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 472
[INFO] 2021-07-09 16:58:54,248 [run_pretraining.py:  558]:	worker_index: 5, step: 472, cost: 0.716552, mlm loss: 0.716552, speed: 0.435399 steps/s, speed: 3.483191 samples/s, speed: 1783.393962 tokens/s, learning rate: 4.710e-06, loss_scalings: 377.789520, pp_loss: 0.724752
[INFO] 2021-07-09 16:58:54,248 [run_pretraining.py:  512]:	********exe.run_472******* 
[INFO] 2021-07-09 16:58:56,815 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:56,816 [run_pretraining.py:  534]:	loss/total_loss, 0.7513785362243652, 473
[INFO] 2021-07-09 16:58:56,816 [run_pretraining.py:  535]:	loss/mlm_loss, 0.7513785362243652, 473
[INFO] 2021-07-09 16:58:56,816 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.720000106317457e-06, 473
[INFO] 2021-07-09 16:58:56,816 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 473
[INFO] 2021-07-09 16:58:56,817 [run_pretraining.py:  558]:	worker_index: 5, step: 473, cost: 0.751379, mlm loss: 0.751379, speed: 0.389471 steps/s, speed: 3.115770 samples/s, speed: 1595.274125 tokens/s, learning rate: 4.720e-06, loss_scalings: 377.789520, pp_loss: 0.738837
[INFO] 2021-07-09 16:58:56,817 [run_pretraining.py:  512]:	********exe.run_473******* 
[INFO] 2021-07-09 16:58:59,096 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:58:59,096 [run_pretraining.py:  534]:	loss/total_loss, 0.7426949739456177, 474
[INFO] 2021-07-09 16:58:59,096 [run_pretraining.py:  535]:	loss/mlm_loss, 0.7426949739456177, 474
[INFO] 2021-07-09 16:58:59,096 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.73000000056345e-06, 474
[INFO] 2021-07-09 16:58:59,096 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 474
[INFO] 2021-07-09 16:58:59,096 [run_pretraining.py:  558]:	worker_index: 5, step: 474, cost: 0.742695, mlm loss: 0.742695, speed: 0.438761 steps/s, speed: 3.510088 samples/s, speed: 1797.164975 tokens/s, learning rate: 4.730e-06, loss_scalings: 377.789520, pp_loss: 0.751327
[INFO] 2021-07-09 16:58:59,096 [run_pretraining.py:  512]:	********exe.run_474******* 
[INFO] 2021-07-09 16:59:01,441 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:01,442 [run_pretraining.py:  534]:	loss/total_loss, 0.795067548751831, 475
[INFO] 2021-07-09 16:59:01,442 [run_pretraining.py:  535]:	loss/mlm_loss, 0.795067548751831, 475
[INFO] 2021-07-09 16:59:01,442 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.7399998948094435e-06, 475
[INFO] 2021-07-09 16:59:01,442 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 475
[INFO] 2021-07-09 16:59:01,442 [run_pretraining.py:  558]:	worker_index: 5, step: 475, cost: 0.795068, mlm loss: 0.795068, speed: 0.426436 steps/s, speed: 3.411490 samples/s, speed: 1746.682999 tokens/s, learning rate: 4.740e-06, loss_scalings: 377.789520, pp_loss: 0.771528
[INFO] 2021-07-09 16:59:01,442 [run_pretraining.py:  512]:	********exe.run_475******* 
[INFO] 2021-07-09 16:59:03,910 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:03,910 [run_pretraining.py:  534]:	loss/total_loss, 0.7775192856788635, 476
[INFO] 2021-07-09 16:59:03,910 [run_pretraining.py:  535]:	loss/mlm_loss, 0.7775192856788635, 476
[INFO] 2021-07-09 16:59:03,910 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.749999789055437e-06, 476
[INFO] 2021-07-09 16:59:03,910 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 476
[INFO] 2021-07-09 16:59:03,911 [run_pretraining.py:  558]:	worker_index: 5, step: 476, cost: 0.777519, mlm loss: 0.777519, speed: 0.405218 steps/s, speed: 3.241744 samples/s, speed: 1659.773035 tokens/s, learning rate: 4.750e-06, loss_scalings: 377.789520, pp_loss: 0.788732
[INFO] 2021-07-09 16:59:03,911 [run_pretraining.py:  512]:	********exe.run_476******* 
[INFO] 2021-07-09 16:59:06,181 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:06,182 [run_pretraining.py:  534]:	loss/total_loss, 0.7941266894340515, 477
[INFO] 2021-07-09 16:59:06,182 [run_pretraining.py:  535]:	loss/mlm_loss, 0.7941266894340515, 477
[INFO] 2021-07-09 16:59:06,182 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.760000138048781e-06, 477
[INFO] 2021-07-09 16:59:06,182 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 477
[INFO] 2021-07-09 16:59:06,182 [run_pretraining.py:  558]:	worker_index: 5, step: 477, cost: 0.794127, mlm loss: 0.794127, speed: 0.440307 steps/s, speed: 3.522456 samples/s, speed: 1803.497593 tokens/s, learning rate: 4.760e-06, loss_scalings: 377.789520, pp_loss: 0.804831
[INFO] 2021-07-09 16:59:06,182 [run_pretraining.py:  512]:	********exe.run_477******* 
[INFO] 2021-07-09 16:59:08,428 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:08,429 [run_pretraining.py:  534]:	loss/total_loss, 0.8890039324760437, 478
[INFO] 2021-07-09 16:59:08,429 [run_pretraining.py:  535]:	loss/mlm_loss, 0.8890039324760437, 478
[INFO] 2021-07-09 16:59:08,429 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.7699995775474235e-06, 478
[INFO] 2021-07-09 16:59:08,429 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 478
[INFO] 2021-07-09 16:59:08,429 [run_pretraining.py:  558]:	worker_index: 5, step: 478, cost: 0.889004, mlm loss: 0.889004, speed: 0.445205 steps/s, speed: 3.561639 samples/s, speed: 1823.559139 tokens/s, learning rate: 4.770e-06, loss_scalings: 377.789520, pp_loss: 0.848161
[INFO] 2021-07-09 16:59:08,429 [run_pretraining.py:  512]:	********exe.run_478******* 
[INFO] 2021-07-09 16:59:10,666 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:10,667 [run_pretraining.py:  534]:	loss/total_loss, 0.8328995704650879, 479
[INFO] 2021-07-09 16:59:10,667 [run_pretraining.py:  535]:	loss/mlm_loss, 0.8328995704650879, 479
[INFO] 2021-07-09 16:59:10,667 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.779999926540768e-06, 479
[INFO] 2021-07-09 16:59:10,667 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 479
[INFO] 2021-07-09 16:59:10,667 [run_pretraining.py:  558]:	worker_index: 5, step: 479, cost: 0.832900, mlm loss: 0.832900, speed: 0.446945 steps/s, speed: 3.575561 samples/s, speed: 1830.687130 tokens/s, learning rate: 4.780e-06, loss_scalings: 377.789520, pp_loss: 0.846958
[INFO] 2021-07-09 16:59:10,667 [run_pretraining.py:  512]:	********exe.run_479******* 
[INFO] 2021-07-09 16:59:12,935 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:12,936 [run_pretraining.py:  534]:	loss/total_loss, 0.8693728446960449, 480
[INFO] 2021-07-09 16:59:12,936 [run_pretraining.py:  535]:	loss/mlm_loss, 0.8693728446960449, 480
[INFO] 2021-07-09 16:59:12,936 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.789999820786761e-06, 480
[INFO] 2021-07-09 16:59:12,936 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 480
[INFO] 2021-07-09 16:59:12,936 [run_pretraining.py:  558]:	worker_index: 5, step: 480, cost: 0.869373, mlm loss: 0.869373, speed: 0.440927 steps/s, speed: 3.527414 samples/s, speed: 1806.036052 tokens/s, learning rate: 4.790e-06, loss_scalings: 377.789520, pp_loss: 0.866122
[INFO] 2021-07-09 16:59:12,936 [run_pretraining.py:  512]:	********exe.run_480******* 
[INFO] 2021-07-09 16:59:15,130 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:15,131 [run_pretraining.py:  534]:	loss/total_loss, 0.8632674217224121, 481
[INFO] 2021-07-09 16:59:15,131 [run_pretraining.py:  535]:	loss/mlm_loss, 0.8632674217224121, 481
[INFO] 2021-07-09 16:59:15,131 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.7999997150327545e-06, 481
[INFO] 2021-07-09 16:59:15,131 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 481
[INFO] 2021-07-09 16:59:15,131 [run_pretraining.py:  558]:	worker_index: 5, step: 481, cost: 0.863267, mlm loss: 0.863267, speed: 0.455736 steps/s, speed: 3.645885 samples/s, speed: 1866.692902 tokens/s, learning rate: 4.800e-06, loss_scalings: 377.789520, pp_loss: 0.865683
[INFO] 2021-07-09 16:59:15,131 [run_pretraining.py:  512]:	********exe.run_481******* 
[INFO] 2021-07-09 16:59:17,342 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:17,342 [run_pretraining.py:  534]:	loss/total_loss, 0.8544972538948059, 482
[INFO] 2021-07-09 16:59:17,342 [run_pretraining.py:  535]:	loss/mlm_loss, 0.8544972538948059, 482
[INFO] 2021-07-09 16:59:17,342 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.809999609278748e-06, 482
[INFO] 2021-07-09 16:59:17,342 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 482
[INFO] 2021-07-09 16:59:17,343 [run_pretraining.py:  558]:	worker_index: 5, step: 482, cost: 0.854497, mlm loss: 0.854497, speed: 0.452285 steps/s, speed: 3.618277 samples/s, speed: 1852.558031 tokens/s, learning rate: 4.810e-06, loss_scalings: 377.789520, pp_loss: 0.867314
[INFO] 2021-07-09 16:59:17,343 [run_pretraining.py:  512]:	********exe.run_482******* 
[INFO] 2021-07-09 16:59:19,638 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:19,639 [run_pretraining.py:  534]:	loss/total_loss, 0.831526517868042, 483
[INFO] 2021-07-09 16:59:19,639 [run_pretraining.py:  535]:	loss/mlm_loss, 0.831526517868042, 483
[INFO] 2021-07-09 16:59:19,639 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.819999958272092e-06, 483
[INFO] 2021-07-09 16:59:19,639 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 483
[INFO] 2021-07-09 16:59:19,639 [run_pretraining.py:  558]:	worker_index: 5, step: 483, cost: 0.831527, mlm loss: 0.831527, speed: 0.435550 steps/s, speed: 3.484399 samples/s, speed: 1784.012137 tokens/s, learning rate: 4.820e-06, loss_scalings: 377.789520, pp_loss: 0.846130
[INFO] 2021-07-09 16:59:19,639 [run_pretraining.py:  512]:	********exe.run_483******* 
[INFO] 2021-07-09 16:59:21,999 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:21,999 [run_pretraining.py:  534]:	loss/total_loss, 0.8273251056671143, 484
[INFO] 2021-07-09 16:59:21,999 [run_pretraining.py:  535]:	loss/mlm_loss, 0.8273251056671143, 484
[INFO] 2021-07-09 16:59:21,999 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.829999852518085e-06, 484
[INFO] 2021-07-09 16:59:22,000 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 484
[INFO] 2021-07-09 16:59:22,000 [run_pretraining.py:  558]:	worker_index: 5, step: 484, cost: 0.827325, mlm loss: 0.827325, speed: 0.423761 steps/s, speed: 3.390090 samples/s, speed: 1735.726039 tokens/s, learning rate: 4.830e-06, loss_scalings: 377.789520, pp_loss: 0.836433
[INFO] 2021-07-09 16:59:22,000 [run_pretraining.py:  512]:	********exe.run_484******* 
[INFO] 2021-07-09 16:59:24,535 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:24,536 [run_pretraining.py:  534]:	loss/total_loss, 0.8184137344360352, 485
[INFO] 2021-07-09 16:59:24,536 [run_pretraining.py:  535]:	loss/mlm_loss, 0.8184137344360352, 485
[INFO] 2021-07-09 16:59:24,536 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.839999746764079e-06, 485
[INFO] 2021-07-09 16:59:24,536 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 485
[INFO] 2021-07-09 16:59:24,536 [run_pretraining.py:  558]:	worker_index: 5, step: 485, cost: 0.818414, mlm loss: 0.818414, speed: 0.394349 steps/s, speed: 3.154792 samples/s, speed: 1615.253713 tokens/s, learning rate: 4.840e-06, loss_scalings: 377.789520, pp_loss: 0.826212
[INFO] 2021-07-09 16:59:24,536 [run_pretraining.py:  512]:	********exe.run_485******* 
[INFO] 2021-07-09 16:59:26,789 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:26,790 [run_pretraining.py:  534]:	loss/total_loss, 0.8189244866371155, 486
[INFO] 2021-07-09 16:59:26,790 [run_pretraining.py:  535]:	loss/mlm_loss, 0.8189244866371155, 486
[INFO] 2021-07-09 16:59:26,790 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.850000095757423e-06, 486
[INFO] 2021-07-09 16:59:26,790 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 486
[INFO] 2021-07-09 16:59:26,790 [run_pretraining.py:  558]:	worker_index: 5, step: 486, cost: 0.818924, mlm loss: 0.818924, speed: 0.443815 steps/s, speed: 3.550523 samples/s, speed: 1817.867657 tokens/s, learning rate: 4.850e-06, loss_scalings: 377.789520, pp_loss: 0.828061
[INFO] 2021-07-09 16:59:26,790 [run_pretraining.py:  512]:	********exe.run_486******* 
[INFO] 2021-07-09 16:59:29,131 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:29,132 [run_pretraining.py:  534]:	loss/total_loss, 0.8251762986183167, 487
[INFO] 2021-07-09 16:59:29,132 [run_pretraining.py:  535]:	loss/mlm_loss, 0.8251762986183167, 487
[INFO] 2021-07-09 16:59:29,132 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.859999990003416e-06, 487
[INFO] 2021-07-09 16:59:29,132 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 487
[INFO] 2021-07-09 16:59:29,132 [run_pretraining.py:  558]:	worker_index: 5, step: 487, cost: 0.825176, mlm loss: 0.825176, speed: 0.427054 steps/s, speed: 3.416433 samples/s, speed: 1749.213528 tokens/s, learning rate: 4.860e-06, loss_scalings: 377.789520, pp_loss: 0.830439
[INFO] 2021-07-09 16:59:29,132 [run_pretraining.py:  512]:	********exe.run_487******* 
[INFO] 2021-07-09 16:59:31,342 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:31,343 [run_pretraining.py:  534]:	loss/total_loss, 0.8402390480041504, 488
[INFO] 2021-07-09 16:59:31,343 [run_pretraining.py:  535]:	loss/mlm_loss, 0.8402390480041504, 488
[INFO] 2021-07-09 16:59:31,343 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.86999988424941e-06, 488
[INFO] 2021-07-09 16:59:31,343 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 488
[INFO] 2021-07-09 16:59:31,343 [run_pretraining.py:  558]:	worker_index: 5, step: 488, cost: 0.840239, mlm loss: 0.840239, speed: 0.452481 steps/s, speed: 3.619845 samples/s, speed: 1853.360842 tokens/s, learning rate: 4.870e-06, loss_scalings: 377.789520, pp_loss: 0.813043
[INFO] 2021-07-09 16:59:31,343 [run_pretraining.py:  512]:	********exe.run_488******* 
[INFO] 2021-07-09 16:59:33,579 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:33,580 [run_pretraining.py:  534]:	loss/total_loss, 0.7805523872375488, 489
[INFO] 2021-07-09 16:59:33,580 [run_pretraining.py:  535]:	loss/mlm_loss, 0.7805523872375488, 489
[INFO] 2021-07-09 16:59:33,580 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.879999778495403e-06, 489
[INFO] 2021-07-09 16:59:33,580 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 489
[INFO] 2021-07-09 16:59:33,580 [run_pretraining.py:  558]:	worker_index: 5, step: 489, cost: 0.780552, mlm loss: 0.780552, speed: 0.447120 steps/s, speed: 3.576961 samples/s, speed: 1831.404128 tokens/s, learning rate: 4.880e-06, loss_scalings: 377.789520, pp_loss: 0.769183
[INFO] 2021-07-09 16:59:33,580 [run_pretraining.py:  512]:	********exe.run_489******* 
[INFO] 2021-07-09 16:59:35,790 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:35,791 [run_pretraining.py:  534]:	loss/total_loss, 0.7165140509605408, 490
[INFO] 2021-07-09 16:59:35,791 [run_pretraining.py:  535]:	loss/mlm_loss, 0.7165140509605408, 490
[INFO] 2021-07-09 16:59:35,791 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.890000127488747e-06, 490
[INFO] 2021-07-09 16:59:35,791 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 490
[INFO] 2021-07-09 16:59:35,791 [run_pretraining.py:  558]:	worker_index: 5, step: 490, cost: 0.716514, mlm loss: 0.716514, speed: 0.452473 steps/s, speed: 3.619783 samples/s, speed: 1853.328853 tokens/s, learning rate: 4.890e-06, loss_scalings: 377.789520, pp_loss: 0.720540
[INFO] 2021-07-09 16:59:35,791 [run_pretraining.py:  512]:	********exe.run_490******* 
[INFO] 2021-07-09 16:59:38,031 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:38,032 [run_pretraining.py:  534]:	loss/total_loss, 0.680130124092102, 491
[INFO] 2021-07-09 16:59:38,032 [run_pretraining.py:  535]:	loss/mlm_loss, 0.680130124092102, 491
[INFO] 2021-07-09 16:59:38,032 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.89999956698739e-06, 491
[INFO] 2021-07-09 16:59:38,032 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 491
[INFO] 2021-07-09 16:59:38,032 [run_pretraining.py:  558]:	worker_index: 5, step: 491, cost: 0.680130, mlm loss: 0.680130, speed: 0.446401 steps/s, speed: 3.571205 samples/s, speed: 1828.457182 tokens/s, learning rate: 4.900e-06, loss_scalings: 377.789520, pp_loss: 0.683467
[INFO] 2021-07-09 16:59:38,032 [run_pretraining.py:  512]:	********exe.run_491******* 
[INFO] 2021-07-09 16:59:40,289 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:40,290 [run_pretraining.py:  534]:	loss/total_loss, 0.6474506855010986, 492
[INFO] 2021-07-09 16:59:40,290 [run_pretraining.py:  535]:	loss/mlm_loss, 0.6474506855010986, 492
[INFO] 2021-07-09 16:59:40,290 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.909999915980734e-06, 492
[INFO] 2021-07-09 16:59:40,290 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 492
[INFO] 2021-07-09 16:59:40,290 [run_pretraining.py:  558]:	worker_index: 5, step: 492, cost: 0.647451, mlm loss: 0.647451, speed: 0.442943 steps/s, speed: 3.543547 samples/s, speed: 1814.296297 tokens/s, learning rate: 4.910e-06, loss_scalings: 377.789520, pp_loss: 0.640857
[INFO] 2021-07-09 16:59:40,290 [run_pretraining.py:  512]:	********exe.run_492******* 
[INFO] 2021-07-09 16:59:42,584 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:42,584 [run_pretraining.py:  534]:	loss/total_loss, 0.5823125839233398, 493
[INFO] 2021-07-09 16:59:42,585 [run_pretraining.py:  535]:	loss/mlm_loss, 0.5823125839233398, 493
[INFO] 2021-07-09 16:59:42,585 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.919999810226727e-06, 493
[INFO] 2021-07-09 16:59:42,585 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 493
[INFO] 2021-07-09 16:59:42,585 [run_pretraining.py:  558]:	worker_index: 5, step: 493, cost: 0.582313, mlm loss: 0.582313, speed: 0.435946 steps/s, speed: 3.487570 samples/s, speed: 1785.635728 tokens/s, learning rate: 4.920e-06, loss_scalings: 377.789520, pp_loss: 0.588062
[INFO] 2021-07-09 16:59:42,585 [run_pretraining.py:  512]:	********exe.run_493******* 
[INFO] 2021-07-09 16:59:44,903 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:44,904 [run_pretraining.py:  534]:	loss/total_loss, 0.5387645363807678, 494
[INFO] 2021-07-09 16:59:44,904 [run_pretraining.py:  535]:	loss/mlm_loss, 0.5387645363807678, 494
[INFO] 2021-07-09 16:59:44,904 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.929999704472721e-06, 494
[INFO] 2021-07-09 16:59:44,904 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 494
[INFO] 2021-07-09 16:59:44,904 [run_pretraining.py:  558]:	worker_index: 5, step: 494, cost: 0.538765, mlm loss: 0.538765, speed: 0.431234 steps/s, speed: 3.449870 samples/s, speed: 1766.333588 tokens/s, learning rate: 4.930e-06, loss_scalings: 377.789520, pp_loss: 0.543712
[INFO] 2021-07-09 16:59:44,905 [run_pretraining.py:  512]:	********exe.run_494******* 
[INFO] 2021-07-09 16:59:47,155 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:47,155 [run_pretraining.py:  534]:	loss/total_loss, 0.4955868124961853, 495
[INFO] 2021-07-09 16:59:47,155 [run_pretraining.py:  535]:	loss/mlm_loss, 0.4955868124961853, 495
[INFO] 2021-07-09 16:59:47,155 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.940000053466065e-06, 495
[INFO] 2021-07-09 16:59:47,155 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 495
[INFO] 2021-07-09 16:59:47,156 [run_pretraining.py:  558]:	worker_index: 5, step: 495, cost: 0.495587, mlm loss: 0.495587, speed: 0.444372 steps/s, speed: 3.554977 samples/s, speed: 1820.148389 tokens/s, learning rate: 4.940e-06, loss_scalings: 377.789520, pp_loss: 0.496837
[INFO] 2021-07-09 16:59:47,156 [run_pretraining.py:  512]:	********exe.run_495******* 
[INFO] 2021-07-09 16:59:49,394 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:49,395 [run_pretraining.py:  534]:	loss/total_loss, 0.4631403088569641, 496
[INFO] 2021-07-09 16:59:49,395 [run_pretraining.py:  535]:	loss/mlm_loss, 0.4631403088569641, 496
[INFO] 2021-07-09 16:59:49,395 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.949999947712058e-06, 496
[INFO] 2021-07-09 16:59:49,395 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 496
[INFO] 2021-07-09 16:59:49,395 [run_pretraining.py:  558]:	worker_index: 5, step: 496, cost: 0.463140, mlm loss: 0.463140, speed: 0.446655 steps/s, speed: 3.573242 samples/s, speed: 1829.499875 tokens/s, learning rate: 4.950e-06, loss_scalings: 377.789520, pp_loss: 0.464249
[INFO] 2021-07-09 16:59:49,395 [run_pretraining.py:  512]:	********exe.run_496******* 
[INFO] 2021-07-09 16:59:51,635 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:51,636 [run_pretraining.py:  534]:	loss/total_loss, 0.44094958901405334, 497
[INFO] 2021-07-09 16:59:51,636 [run_pretraining.py:  535]:	loss/mlm_loss, 0.44094958901405334, 497
[INFO] 2021-07-09 16:59:51,636 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.9599998419580515e-06, 497
[INFO] 2021-07-09 16:59:51,636 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 497
[INFO] 2021-07-09 16:59:51,636 [run_pretraining.py:  558]:	worker_index: 5, step: 497, cost: 0.440950, mlm loss: 0.440950, speed: 0.446371 steps/s, speed: 3.570972 samples/s, speed: 1828.337509 tokens/s, learning rate: 4.960e-06, loss_scalings: 377.789520, pp_loss: 0.441149
[INFO] 2021-07-09 16:59:51,636 [run_pretraining.py:  512]:	********exe.run_497******* 
[INFO] 2021-07-09 16:59:53,849 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:53,849 [run_pretraining.py:  534]:	loss/total_loss, 0.4231961965560913, 498
[INFO] 2021-07-09 16:59:53,850 [run_pretraining.py:  535]:	loss/mlm_loss, 0.4231961965560913, 498
[INFO] 2021-07-09 16:59:53,850 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.969999736204045e-06, 498
[INFO] 2021-07-09 16:59:53,850 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 498
[INFO] 2021-07-09 16:59:53,850 [run_pretraining.py:  558]:	worker_index: 5, step: 498, cost: 0.423196, mlm loss: 0.423196, speed: 0.451848 steps/s, speed: 3.614784 samples/s, speed: 1850.769248 tokens/s, learning rate: 4.970e-06, loss_scalings: 377.789520, pp_loss: 0.424321
[INFO] 2021-07-09 16:59:53,850 [run_pretraining.py:  512]:	********exe.run_498******* 
[INFO] 2021-07-09 16:59:56,075 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:56,075 [run_pretraining.py:  534]:	loss/total_loss, 0.4127938747406006, 499
[INFO] 2021-07-09 16:59:56,075 [run_pretraining.py:  535]:	loss/mlm_loss, 0.4127938747406006, 499
[INFO] 2021-07-09 16:59:56,076 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.980000085197389e-06, 499
[INFO] 2021-07-09 16:59:56,076 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 499
[INFO] 2021-07-09 16:59:56,076 [run_pretraining.py:  558]:	worker_index: 5, step: 499, cost: 0.412794, mlm loss: 0.412794, speed: 0.449394 steps/s, speed: 3.595149 samples/s, speed: 1840.716113 tokens/s, learning rate: 4.980e-06, loss_scalings: 377.789520, pp_loss: 0.417483
[INFO] 2021-07-09 16:59:56,076 [run_pretraining.py:  512]:	********exe.run_499******* 
[INFO] 2021-07-09 16:59:58,287 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 16:59:58,288 [run_pretraining.py:  534]:	loss/total_loss, 0.4055776000022888, 500
[INFO] 2021-07-09 16:59:58,288 [run_pretraining.py:  535]:	loss/mlm_loss, 0.4055776000022888, 500
[INFO] 2021-07-09 16:59:58,288 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.9899999794433825e-06, 500
[INFO] 2021-07-09 16:59:58,288 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 500
[INFO] 2021-07-09 16:59:58,288 [run_pretraining.py:  558]:	worker_index: 5, step: 500, cost: 0.405578, mlm loss: 0.405578, speed: 0.452167 steps/s, speed: 3.617335 samples/s, speed: 1852.075319 tokens/s, learning rate: 4.990e-06, loss_scalings: 377.789520, pp_loss: 0.407145
[DEBUG] 2021-07-09 16:59:58,288 [run_pretraining.py:  567]:	saving models to output/test-bs8-mppp_5/step_500
[INFO] 2021-07-09 16:59:59,154 [run_pretraining.py:  512]:	********exe.run_500******* 
[INFO] 2021-07-09 17:00:01,445 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 17:00:01,446 [run_pretraining.py:  534]:	loss/total_loss, 0.4222664535045624, 501
[INFO] 2021-07-09 17:00:01,446 [run_pretraining.py:  535]:	loss/mlm_loss, 0.4222664535045624, 501
[INFO] 2021-07-09 17:00:01,446 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.999999873689376e-06, 501
[INFO] 2021-07-09 17:00:01,446 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 501
[INFO] 2021-07-09 17:00:01,446 [run_pretraining.py:  558]:	worker_index: 5, step: 501, cost: 0.422266, mlm loss: 0.422266, speed: 0.316707 steps/s, speed: 2.533659 samples/s, speed: 1297.233412 tokens/s, learning rate: 5.000e-06, loss_scalings: 377.789520, pp_loss: 0.413120
[INFO] 2021-07-09 17:00:01,446 [run_pretraining.py:  512]:	********exe.run_501******* 
[INFO] 2021-07-09 17:00:03,712 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 17:00:03,713 [run_pretraining.py:  534]:	loss/total_loss, 0.4264223873615265, 502
[INFO] 2021-07-09 17:00:03,713 [run_pretraining.py:  535]:	loss/mlm_loss, 0.4264223873615265, 502
[INFO] 2021-07-09 17:00:03,713 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.009999767935369e-06, 502
[INFO] 2021-07-09 17:00:03,713 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 502
[INFO] 2021-07-09 17:00:03,713 [run_pretraining.py:  558]:	worker_index: 5, step: 502, cost: 0.426422, mlm loss: 0.426422, speed: 0.441229 steps/s, speed: 3.529830 samples/s, speed: 1807.272886 tokens/s, learning rate: 5.010e-06, loss_scalings: 377.789520, pp_loss: 0.435849
[INFO] 2021-07-09 17:00:03,713 [run_pretraining.py:  512]:	********exe.run_502******* 
[INFO] 2021-07-09 17:00:05,977 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 17:00:05,977 [run_pretraining.py:  534]:	loss/total_loss, 0.43460097908973694, 503
[INFO] 2021-07-09 17:00:05,978 [run_pretraining.py:  535]:	loss/mlm_loss, 0.43460097908973694, 503
[INFO] 2021-07-09 17:00:05,978 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.020000116928713e-06, 503
[INFO] 2021-07-09 17:00:05,978 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 503
[INFO] 2021-07-09 17:00:05,978 [run_pretraining.py:  558]:	worker_index: 5, step: 503, cost: 0.434601, mlm loss: 0.434601, speed: 0.441738 steps/s, speed: 3.533906 samples/s, speed: 1809.359768 tokens/s, learning rate: 5.020e-06, loss_scalings: 377.789520, pp_loss: 0.440180
[INFO] 2021-07-09 17:00:05,978 [run_pretraining.py:  512]:	********exe.run_503******* 
[INFO] 2021-07-09 17:00:08,228 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 17:00:08,228 [run_pretraining.py:  534]:	loss/total_loss, 0.4486757218837738, 504
[INFO] 2021-07-09 17:00:08,228 [run_pretraining.py:  535]:	loss/mlm_loss, 0.4486757218837738, 504
[INFO] 2021-07-09 17:00:08,228 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.029999556427356e-06, 504
[INFO] 2021-07-09 17:00:08,228 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 504
[INFO] 2021-07-09 17:00:08,229 [run_pretraining.py:  558]:	worker_index: 5, step: 504, cost: 0.448676, mlm loss: 0.448676, speed: 0.444438 steps/s, speed: 3.555505 samples/s, speed: 1820.418596 tokens/s, learning rate: 5.030e-06, loss_scalings: 377.789520, pp_loss: 0.451764
[INFO] 2021-07-09 17:00:08,229 [run_pretraining.py:  512]:	********exe.run_504******* 
[INFO] 2021-07-09 17:00:10,434 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 17:00:10,434 [run_pretraining.py:  534]:	loss/total_loss, 0.4647459387779236, 505
[INFO] 2021-07-09 17:00:10,434 [run_pretraining.py:  535]:	loss/mlm_loss, 0.4647459387779236, 505
[INFO] 2021-07-09 17:00:10,435 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.0399999054207e-06, 505
[INFO] 2021-07-09 17:00:10,435 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 505
[INFO] 2021-07-09 17:00:10,435 [run_pretraining.py:  558]:	worker_index: 5, step: 505, cost: 0.464746, mlm loss: 0.464746, speed: 0.453408 steps/s, speed: 3.627263 samples/s, speed: 1857.158876 tokens/s, learning rate: 5.040e-06, loss_scalings: 377.789520, pp_loss: 0.470052
[INFO] 2021-07-09 17:00:10,435 [run_pretraining.py:  512]:	********exe.run_505******* 
[INFO] 2021-07-09 17:00:12,682 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 17:00:12,682 [run_pretraining.py:  534]:	loss/total_loss, 0.47975072264671326, 506
[INFO] 2021-07-09 17:00:12,682 [run_pretraining.py:  535]:	loss/mlm_loss, 0.47975072264671326, 506
[INFO] 2021-07-09 17:00:12,682 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.050000254414044e-06, 506
[INFO] 2021-07-09 17:00:12,682 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 506
[INFO] 2021-07-09 17:00:12,682 [run_pretraining.py:  558]:	worker_index: 5, step: 506, cost: 0.479751, mlm loss: 0.479751, speed: 0.445039 steps/s, speed: 3.560313 samples/s, speed: 1822.880377 tokens/s, learning rate: 5.050e-06, loss_scalings: 377.789520, pp_loss: 0.475506
[INFO] 2021-07-09 17:00:12,682 [run_pretraining.py:  512]:	********exe.run_506******* 
[INFO] 2021-07-09 17:00:14,886 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 17:00:14,886 [run_pretraining.py:  534]:	loss/total_loss, 0.5090368986129761, 507
[INFO] 2021-07-09 17:00:14,886 [run_pretraining.py:  535]:	loss/mlm_loss, 0.5090368986129761, 507
[INFO] 2021-07-09 17:00:14,886 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.059999693912687e-06, 507
[INFO] 2021-07-09 17:00:14,887 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 507
[INFO] 2021-07-09 17:00:14,887 [run_pretraining.py:  558]:	worker_index: 5, step: 507, cost: 0.509037, mlm loss: 0.509037, speed: 0.453829 steps/s, speed: 3.630630 samples/s, speed: 1858.882799 tokens/s, learning rate: 5.060e-06, loss_scalings: 377.789520, pp_loss: 0.494322
[INFO] 2021-07-09 17:00:14,887 [run_pretraining.py:  512]:	********exe.run_507******* 
[INFO] 2021-07-09 17:00:17,112 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 17:00:17,113 [run_pretraining.py:  534]:	loss/total_loss, 0.5264717936515808, 508
[INFO] 2021-07-09 17:00:17,113 [run_pretraining.py:  535]:	loss/mlm_loss, 0.5264717936515808, 508
[INFO] 2021-07-09 17:00:17,113 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.070000042906031e-06, 508
[INFO] 2021-07-09 17:00:17,113 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 508
[INFO] 2021-07-09 17:00:17,113 [run_pretraining.py:  558]:	worker_index: 5, step: 508, cost: 0.526472, mlm loss: 0.526472, speed: 0.449255 steps/s, speed: 3.594043 samples/s, speed: 1840.150065 tokens/s, learning rate: 5.070e-06, loss_scalings: 377.789520, pp_loss: 0.534346
[INFO] 2021-07-09 17:00:17,113 [run_pretraining.py:  512]:	********exe.run_508******* 
[INFO] 2021-07-09 17:00:19,321 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 17:00:19,321 [run_pretraining.py:  534]:	loss/total_loss, 0.603162407875061, 509
[INFO] 2021-07-09 17:00:19,321 [run_pretraining.py:  535]:	loss/mlm_loss, 0.603162407875061, 509
[INFO] 2021-07-09 17:00:19,321 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.079999937152024e-06, 509
[INFO] 2021-07-09 17:00:19,321 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 509
[INFO] 2021-07-09 17:00:19,322 [run_pretraining.py:  558]:	worker_index: 5, step: 509, cost: 0.603162, mlm loss: 0.603162, speed: 0.452978 steps/s, speed: 3.623825 samples/s, speed: 1855.398271 tokens/s, learning rate: 5.080e-06, loss_scalings: 377.789520, pp_loss: 0.610376
[INFO] 2021-07-09 17:00:19,322 [run_pretraining.py:  512]:	********exe.run_509******* 
[INFO] 2021-07-09 17:00:21,538 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 17:00:21,538 [run_pretraining.py:  534]:	loss/total_loss, 0.6986533403396606, 510
[INFO] 2021-07-09 17:00:21,539 [run_pretraining.py:  535]:	loss/mlm_loss, 0.6986533403396606, 510
[INFO] 2021-07-09 17:00:21,539 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.089999831398018e-06, 510
[INFO] 2021-07-09 17:00:21,539 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 510
[INFO] 2021-07-09 17:00:21,539 [run_pretraining.py:  558]:	worker_index: 5, step: 510, cost: 0.698653, mlm loss: 0.698653, speed: 0.451150 steps/s, speed: 3.609199 samples/s, speed: 1847.909758 tokens/s, learning rate: 5.090e-06, loss_scalings: 377.789520, pp_loss: 0.703171
[INFO] 2021-07-09 17:00:21,539 [run_pretraining.py:  512]:	********exe.run_510******* 
[INFO] 2021-07-09 17:00:23,788 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 17:00:23,789 [run_pretraining.py:  534]:	loss/total_loss, 0.787952184677124, 511
[INFO] 2021-07-09 17:00:23,789 [run_pretraining.py:  535]:	loss/mlm_loss, 0.787952184677124, 511
[INFO] 2021-07-09 17:00:23,789 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.099999725644011e-06, 511
[INFO] 2021-07-09 17:00:23,789 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 511
[INFO] 2021-07-09 17:00:23,789 [run_pretraining.py:  558]:	worker_index: 5, step: 511, cost: 0.787952, mlm loss: 0.787952, speed: 0.444560 steps/s, speed: 3.556478 samples/s, speed: 1820.916789 tokens/s, learning rate: 5.100e-06, loss_scalings: 377.789520, pp_loss: 0.785266
[INFO] 2021-07-09 17:00:23,789 [run_pretraining.py:  512]:	********exe.run_511******* 
[INFO] 2021-07-09 17:00:26,076 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-09 17:00:26,077 [run_pretraining.py:  534]:	loss/total_loss, 0.8392253518104553, 512
[INFO] 2021-07-09 17:00:26,077 [run_pretraining.py:  535]:	loss/mlm_loss, 0.8392253518104553, 512
[INFO] 2021-07-09 17:00:26,077 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.110000074637355e-06, 512
[INFO] 2021-07-09 17:00:26,077 [run_pretraining.py:  539]:	lr/loss_scaling, 377.7895202636719, 512
[INFO] 2021-07-09 17:00:26,077 [run_pretraining.py:  558]:	worker_index: 5, step: 512, cost: 0.839225, mlm loss: 0.839225, speed: 0.437118 steps/s, speed: 3.496944 samples/s, speed: 1790.435084 tokens/s, learning rate: 5.110e-06, loss_scalings: 377.789520, pp_loss: 0.826269
[INFO] 2021-07-09 17:00:26,077 [run_pretraining.py:  512]:	********exe.run_512******* 
/home/gongwb/.local/lib/python3.7/multiprocessing/semaphore_tracker.py:144: UserWarning: semaphore_tracker: There appear to be 91 leaked semaphores to clean up at shutdown
  len(cache))
