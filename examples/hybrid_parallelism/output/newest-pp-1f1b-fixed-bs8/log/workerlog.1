WARNING: Logging before InitGoogleLogging() is written to STDERR
I0707 16:25:56.422799 43622 init.cc:88] Before Parse: argc is 2, Init commandline: dummy --tryfromenv=check_nan_inf,benchmark,eager_delete_scope,fraction_of_cpu_memory_to_use,initial_cpu_memory_in_mb,init_allocated_mem,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_system_allocator,enable_unused_var_check,free_idle_chunk,free_when_no_cache_hit,call_stack_level,sort_sum_gradient,max_inplace_grad_add,use_pinned_memory,cpu_deterministic,use_mkldnn,tracer_mkldnn_ops_on,tracer_mkldnn_ops_off,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,cudnn_batchnorm_spatial_persistent,gpu_allocator_retry_time,local_exe_sub_scope_limit,gpu_memory_limit_mb,conv2d_disable_cudnn 
I0707 16:25:56.423071 43622 init.cc:95] After Parse: argc is 1
[INFO] 2021-07-07 16:25:56,945 [run_pretraining.py:   52]:	tensorboard not found, using visualdl
-----------  Configuration Arguments -----------
data_dir: ./data
debug: False
do_eval: True
epoch: 100
ernie_config_file: config/ernie_base_config.json
eval_batch_size: 35
eval_data_path: ./data
eval_steps: -1
global_bsz: 8
global_steps: 0
grad_merge: 0
init_checkpoint: 
learning_rate: 0.0001
log_steps: 1
max_seq_len: 512
micro_bsz: 1
num_dp: 1
num_mp: 1
num_pp: 2
num_sharding: 1
num_train_steps: 250
output_dir: output/newest-pp-1f1b-fixed-bs8
preln: False
save_steps: 100
seed: 2021
use_amp: True
use_hybrid_dp: True
use_lamb: False
use_offload: False
use_recompute: True
use_sharding: True
use_sop: False
vocab_file: ./config/30k-clean.vocab.albert
warmup_steps: 10000
weight_decay: 0.01
------------------------------------------------
to run startup
[INFO] 2021-07-07 16:25:56,949 [run_pretraining.py:  201]:	pretraining start
[INFO] 2021-07-07 16:25:56,949 [run_pretraining.py:  216]:	using recompute.
[INFO] 2021-07-07 16:25:56,950 [run_pretraining.py:  261]:	using globa_bsz: 8 micro_bsz: 1, acc_steps: 8
[DEBUG] 2021-07-07 16:25:57,001 [run_pretraining.py:  108]:	========= dp_sharding worker: 0 of 1 ==========
[INFO] 2021-07-07 16:25:57,001 [pretraining_ds_mlm.py:  255]:	Apply sharding in distribution env 0/1
[INFO] 2021-07-07 16:25:57,001 [pretraining_ds_mlm.py:  257]:	read from ./data/part-00000.101,./data/part-00000.102,./data/part-00000.106,./data/part-00000.109,./data/part-00000.105,./data/part-00000.104,./data/part-00000.108,./data/part-00000.107,./data/part-00000.103,./data/part-00000.100,./data/part-00000.10
I0707 16:25:57.001937 43622 reader_py.cc:387] init_lod_tensor_blocking_queue
INFO:root:places would be ommited when DataLoader is not iterable
/code_lp/paddle/Paddle/build/fix_pp_precise_1f1b/python/paddle/fluid/framework.py:2049: UserWarning: The Attr(force_cpu) of Op(fill_constant) will be deprecated in the future, please use 'device_guard' instead. 'device_guard' has higher priority when they are used at the same time.
  "used at the same time." % type)
/code_lp/paddle/Paddle/build/fix_pp_precise_1f1b/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /code_lp/Ascend/FleetX/examples/hybrid_parallelism/model/ernie.py:149
The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
/code_lp/paddle/Paddle/build/fix_pp_precise_1f1b/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /code_lp/Ascend/FleetX/examples/hybrid_parallelism/model/ernie.py:150
The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
/code_lp/paddle/Paddle/build/fix_pp_precise_1f1b/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /code_lp/Ascend/FleetX/examples/hybrid_parallelism/model/transformer_encoder.py:166
The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
/code_lp/paddle/Paddle/build/fix_pp_precise_1f1b/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /code_lp/Ascend/FleetX/examples/hybrid_parallelism/model/transformer_encoder.py:276
The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
/code_lp/paddle/Paddle/build/fix_pp_precise_1f1b/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /code_lp/Ascend/FleetX/examples/hybrid_parallelism/model/transformer_encoder.py:39
The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
/code_lp/paddle/Paddle/build/fix_pp_precise_1f1b/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /code_lp/Ascend/FleetX/examples/hybrid_parallelism/model/transformer_encoder.py:40
The behavior of expression A * B has been unified with elementwise_mul(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_mul(X, Y, axis=0) instead of A * B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
[DEBUG] 2021-07-07 16:25:57,503 [run_pretraining.py:  295]:	base lr: 0.0001
/code_lp/paddle/Paddle/build/fix_pp_precise_1f1b/python/paddle/distributed/fleet/base/fleet_base.py:818: UserWarning: It is recommended to use DistributedStrategy in fleet.init(). The strategy here is only for compatibility. If the strategy in fleet.distributed_optimizer() is not None, then it will overwrite the DistributedStrategy in fleet.init(), which will take effect in distributed training.
  "It is recommended to use DistributedStrategy "
[INFO] 2021-07-07 16:25:57,513 [run_pretraining.py:  319]:	using dist strategy:     +==============================================================================+
    |                                                                              |
    |                         DistributedStrategy Overview                         |
    |                                                                              |
    +==============================================================================+
    |                           amp=True <-> amp_configs                           |
    +------------------------------------------------------------------------------+
    |                     init_loss_scaling                 32768.0                |
    |                    incr_every_n_steps                   1000                 |
    |               decr_every_n_nan_or_inf                    2                   |
    |                            incr_ratio                   2.0                  |
    |                            decr_ratio            0.800000011920929           |
    |              use_dynamic_loss_scaling                   True                 |
    |                     custom_white_list                 softmax                |
    |                                                      layer_norm              |
    |                                                         gelu                 |
    |                         use_pure_fp16                  False                 |
    |                        use_fp16_guard                  False                 |
    +==============================================================================+
    |                     recompute=True <-> recompute_configs                     |
    +------------------------------------------------------------------------------+
    |                           checkpoints            layer_norm_2.tmp_2          |
    |                        enable_offload                  False                 |
    +==============================================================================+
    |                      pipeline=True <-> pipeline_configs                      |
    +------------------------------------------------------------------------------+
    |                      micro_batch_size                    1                   |
    |                      accumulate_steps                    8                   |
    |                         schedule_mode                   1F1B                 |
    +==============================================================================+
    |                        a_sync=True <-> a_sync_configs                        |
    +------------------------------------------------------------------------------+
    |                               k_steps                    -1                  |
    |                     max_merge_var_num                    1                   |
    |                       send_queue_size                    16                  |
    |               independent_recv_thread                  False                 |
    |         min_send_grad_num_before_recv                    1                   |
    |                      thread_pool_size                    1                   |
    |                       send_wait_times                    1                   |
    |               runtime_split_send_recv                  False                 |
    |                        launch_barrier                   True                 |
    |             heter_worker_device_guard                   cpu                  |
    |                        lr_decay_steps                    10                  |
    |                            use_ps_gpu                    0                   |
    +==============================================================================+
    |                      sharding=True <-> sharding_configs                      |
    +------------------------------------------------------------------------------+
    |             sharding_segment_strategy           segment_broadcast_MB         |
    |                  segment_broadcast_MB                   32.0                 |
    |                       sharding_degree                    1                   |
    |                             mp_degree                    1                   |
    |                             dp_degree                    1                   |
    |                             hybrid_dp                  False                 |
    |               gradient_merge_acc_step                    8                   |
    |                      optimize_offload                  False                 |
    |              pp_allreduce_in_optimize                  False                 |
    |                             pp_degree                    2                   |
    +==============================================================================+
    |                    Environment Flags, Communication Flags                    |
    +------------------------------------------------------------------------------+
    |                                  mode                    1                   |
    |                               elastic                  False                 |
    |                                  auto                  False                 |
    |                   sync_nccl_allreduce                   True                 |
    |                         nccl_comm_num                    1                   |
    |            use_hierarchical_allreduce                  False                 |
    |   hierarchical_allreduce_inter_nranks                    1                   |
    |                       sync_batch_norm                  False                 |
    |                   fuse_all_reduce_ops                   True                 |
    |                  fuse_grad_size_in_MB                    32                  |
    |              fuse_grad_size_in_TFLOPS                   50.0                 |
    |               cudnn_exhaustive_search                  False                 |
    |             conv_workspace_size_limit                   512                  |
    |    cudnn_batchnorm_spatial_persistent                  False                 |
    |                        fp16_allreduce                  False                 |
    |               last_comm_group_size_MB                   1.0                  |
    |                find_unused_parameters                  False                 |
    |            without_graph_optimization                  False                 |
    |                 fuse_grad_size_in_num                    1                   |
    |                 calc_comm_same_stream                  False                 |
    +==============================================================================+
    |                                Build Strategy                                |
    +------------------------------------------------------------------------------+
    |           enable_sequential_execution                  False                 |
    |              fuse_elewise_add_act_ops                  False                 |
    |                       fuse_bn_act_ops                  False                 |
    |              fuse_relu_depthwise_conv                  False                 |
    |                    fuse_broadcast_ops                  False                 |
    |                fuse_all_optimizer_ops                  False                 |
    |                        enable_inplace                  False                 |
    |     enable_backward_optimizer_op_deps                   True                 |
    |                 cache_runtime_context                  False                 |
    |                   fuse_bn_add_act_ops                   True                 |
    |                    enable_auto_fusion                  False                 |
    |                          enable_addto                  False                 |
    +==============================================================================+
    |                              Execution Strategy                              |
    +------------------------------------------------------------------------------+
    |                           num_threads                    1                   |
    |          num_iteration_per_drop_scope                    10                  |
    |                 num_iteration_per_run                    1                   |
    |                    use_thread_barrier                  False                 |
    +==============================================================================+

2021-07-07 16:25:57 INFO     Gradient merge in [pp_gm], acc step = [8]
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:Gradient merge in [pp_gm], acc step = [8]
Wed Jul 07 16:25:57-INFO: recompute segment[0]
Wed Jul 07 16:25:57-INFO: segment start op: [lookup_table]: [['src_ids', 'word_embedding']]
Wed Jul 07 16:25:57-INFO: segment end op: [layer_norm]: [['encoder_layer_0_post_ffn_layer_norm_bias', 'encoder_layer_0_post_ffn_layer_norm_scale', 'tmp_10']]
Wed Jul 07 16:25:57-INFO: recompute segment[0]
Wed Jul 07 16:25:57-INFO: segment start op: [lookup_table]: [['src_ids', 'word_embedding']]
Wed Jul 07 16:25:57-INFO: segment end op: [layer_norm]: [['encoder_layer_0_post_ffn_layer_norm_bias', 'encoder_layer_0_post_ffn_layer_norm_scale', 'tmp_10']]
Wed Jul 07 16:25:57-INFO: found [0] vars which cross recompute segment: [set()], better checkpoints might be set to reduce those vars
pp_rank: 1
2021-07-07 16:26:01 INFO     global word size: 2
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:global word size: 2
2021-07-07 16:26:01 INFO     global rank: 1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:global rank: 1
2021-07-07 16:26:01 INFO     global endpoints: ['127.0.0.1:22352', '127.0.0.1:10130']
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:global endpoints: ['127.0.0.1:22352', '127.0.0.1:10130']
2021-07-07 16:26:01 INFO     global ring id: 3
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:global ring id: 3
2021-07-07 16:26:01 INFO     ##############################
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:##############################
2021-07-07 16:26:01 INFO     mp group size: 1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:mp group size: 1
2021-07-07 16:26:01 INFO     mp rank: -1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:mp rank: -1
2021-07-07 16:26:01 INFO     mp group id: -1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:mp group id: -1
2021-07-07 16:26:01 INFO     mp group endpoints: []
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:mp group endpoints: []
2021-07-07 16:26:01 INFO     mp ring id: -1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:mp ring id: -1
2021-07-07 16:26:01 INFO     ##############################
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:##############################
2021-07-07 16:26:01 INFO     sharding group size: 1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:sharding group size: 1
2021-07-07 16:26:01 INFO     sharding rank: -1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:sharding rank: -1
2021-07-07 16:26:01 INFO     sharding group id: -1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:sharding group id: -1
2021-07-07 16:26:01 INFO     sharding group endpoints: []
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:sharding group endpoints: []
2021-07-07 16:26:01 INFO     sharding ring id: -1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:sharding ring id: -1
2021-07-07 16:26:01 INFO     ##############################
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:##############################
2021-07-07 16:26:01 INFO     pp group size: 2
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pp group size: 2
2021-07-07 16:26:01 INFO     pp rank: 1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pp rank: 1
2021-07-07 16:26:01 INFO     pp group id: 0
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pp group id: 0
2021-07-07 16:26:01 INFO     pp group endpoints: ['127.0.0.1:22352', '127.0.0.1:10130']
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pp group endpoints: ['127.0.0.1:22352', '127.0.0.1:10130']
2021-07-07 16:26:01 INFO     pp ring id: 20
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pp ring id: 20
2021-07-07 16:26:01 INFO     ##############################
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:##############################
2021-07-07 16:26:01 INFO     pure dp group size: 1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pure dp group size: 1
2021-07-07 16:26:01 INFO     pure dp rank: -1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pure dp rank: -1
2021-07-07 16:26:01 INFO     pure dp group endpoints: []
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pure dp group endpoints: []
2021-07-07 16:26:01 INFO     pure dp ring id: -1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pure dp ring id: -1
2021-07-07 16:26:01 INFO     ##############################
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:##############################
pp pair:(0, 1), ring_id: 20
pp pair:(1, 0), ring_id: 21
[INFO] 2021-07-07 16:26:04,834 [run_pretraining.py:  325]:	final strategy:     +==============================================================================+
    |                                                                              |
    |                         DistributedStrategy Overview                         |
    |                                                                              |
    +==============================================================================+
    |                           amp=True <-> amp_configs                           |
    +------------------------------------------------------------------------------+
    |                     init_loss_scaling                 32768.0                |
    |                    incr_every_n_steps                   1000                 |
    |               decr_every_n_nan_or_inf                    2                   |
    |                            incr_ratio                   2.0                  |
    |                            decr_ratio            0.800000011920929           |
    |              use_dynamic_loss_scaling                   True                 |
    |                     custom_white_list                 softmax                |
    |                                                      layer_norm              |
    |                                                         gelu                 |
    |                         use_pure_fp16                  False                 |
    |                        use_fp16_guard                  False                 |
    +==============================================================================+
    |                     recompute=True <-> recompute_configs                     |
    +------------------------------------------------------------------------------+
    |                           checkpoints            layer_norm_2.tmp_2          |
    |                        enable_offload                  False                 |
    +==============================================================================+
    |                      sharding=True <-> sharding_configs                      |
    +------------------------------------------------------------------------------+
    |             sharding_segment_strategy           segment_broadcast_MB         |
    |                  segment_broadcast_MB                   32.0                 |
    |                       sharding_degree                    1                   |
    |                             mp_degree                    1                   |
    |                             dp_degree                    1                   |
    |                             hybrid_dp                  False                 |
    |               gradient_merge_acc_step                    8                   |
    |                      optimize_offload                  False                 |
    |              pp_allreduce_in_optimize                  False                 |
    |                             pp_degree                    2                   |
    +==============================================================================+
    |                    Environment Flags, Communication Flags                    |
    +------------------------------------------------------------------------------+
    |                                  mode                    1                   |
    |                               elastic                  False                 |
    |                                  auto                  False                 |
    |                   sync_nccl_allreduce                   True                 |
    |                         nccl_comm_num                    1                   |
    |            use_hierarchical_allreduce                  False                 |
    |   hierarchical_allreduce_inter_nranks                    1                   |
    |                       sync_batch_norm                  False                 |
    |                   fuse_all_reduce_ops                   True                 |
    |                  fuse_grad_size_in_MB                    32                  |
    |              fuse_grad_size_in_TFLOPS                   50.0                 |
    |               cudnn_exhaustive_search                  False                 |
    |             conv_workspace_size_limit                   512                  |
    |    cudnn_batchnorm_spatial_persistent                  False                 |
    |                        fp16_allreduce                  False                 |
    |               last_comm_group_size_MB                   1.0                  |
    |                find_unused_parameters                  False                 |
    |            without_graph_optimization                  False                 |
    |                 fuse_grad_size_in_num                    1                   |
    |                 calc_comm_same_stream                  False                 |
    +==============================================================================+
    |                                Build Strategy                                |
    +------------------------------------------------------------------------------+
    |           enable_sequential_execution                  False                 |
    |              fuse_elewise_add_act_ops                  False                 |
    |                       fuse_bn_act_ops                  False                 |
    |              fuse_relu_depthwise_conv                  False                 |
    |                    fuse_broadcast_ops                  False                 |
    |                fuse_all_optimizer_ops                  False                 |
    |                        enable_inplace                  False                 |
    |     enable_backward_optimizer_op_deps                   True                 |
    |                 cache_runtime_context                  False                 |
    |                   fuse_bn_add_act_ops                   True                 |
    |                    enable_auto_fusion                  False                 |
    |                          enable_addto                  False                 |
    +==============================================================================+
    |                              Execution Strategy                              |
    +------------------------------------------------------------------------------+
    |                           num_threads                    1                   |
    |          num_iteration_per_drop_scope                    10                  |
    |                 num_iteration_per_run                    1                   |
    |                    use_thread_barrier                  False                 |
    +==============================================================================+

[INFO] 2021-07-07 16:26:04,835 [run_pretraining.py:  326]:	applied_meta_list: ['ShardingOptimizer', 'AMPOptimizer', 'RecomputeOptimizer']
W0707 16:26:05.195480 43622 device_context.cc:430] Please NOTE: device: 1, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 10.1
W0707 16:26:05.200774 43622 device_context.cc:448] device: 1, cuDNN Version: 7.6.
I0707 16:26:08.873888 43622 gen_comm_id_helper.cc:181] Server listening on: 127.0.0.1:10130 successful.
yq01-sys-hic-k8s-v100-box-a225-0562:43622:43622 [1] NCCL INFO Bootstrap : Using xgbe0:10.127.28.15<0>
yq01-sys-hic-k8s-v100-box-a225-0562:43622:43622 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
yq01-sys-hic-k8s-v100-box-a225-0562:43622:43622 [1] NCCL INFO NET/IB : No device found.
yq01-sys-hic-k8s-v100-box-a225-0562:43622:43622 [1] NCCL INFO NET/Socket : Using [0]xgbe0:10.127.28.15<0> [1]veth5bf641d:fe80::50fb:cdff:fe90:2686%veth5bf641d<0>
yq01-sys-hic-k8s-v100-box-a225-0562:43622:43622 [1] NCCL INFO Using network Socket
yq01-sys-hic-k8s-v100-box-a225-0562:43622:43622 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0 [2] -1/-1/-1->1->0 [3] -1/-1/-1->1->0
yq01-sys-hic-k8s-v100-box-a225-0562:43622:43622 [1] NCCL INFO Setting affinity for GPU 1 to ffffff
yq01-sys-hic-k8s-v100-box-a225-0562:43622:43622 [1] NCCL INFO Channel 00 : 1[40000] -> 0[3f000] via P2P/IPC
yq01-sys-hic-k8s-v100-box-a225-0562:43622:43622 [1] NCCL INFO Channel 01 : 1[40000] -> 0[3f000] via P2P/IPC
yq01-sys-hic-k8s-v100-box-a225-0562:43622:43622 [1] NCCL INFO Channel 02 : 1[40000] -> 0[3f000] via P2P/IPC
yq01-sys-hic-k8s-v100-box-a225-0562:43622:43622 [1] NCCL INFO Channel 03 : 1[40000] -> 0[3f000] via P2P/IPC
yq01-sys-hic-k8s-v100-box-a225-0562:43622:43622 [1] NCCL INFO Connected all rings
yq01-sys-hic-k8s-v100-box-a225-0562:43622:43622 [1] NCCL INFO Connected all trees
yq01-sys-hic-k8s-v100-box-a225-0562:43622:43622 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
yq01-sys-hic-k8s-v100-box-a225-0562:43622:43622 [1] NCCL INFO 4 coll channels, 4 p2p channels, 4 p2p channels per peer
yq01-sys-hic-k8s-v100-box-a225-0562:43622:43622 [1] NCCL INFO comm 0x6c3eeb50 rank 1 nranks 2 cudaDev 1 busId 40000 - Init COMPLETE
I0707 16:26:15.130548 43622 collective_helper.cc:104] nccl communicator of rank 1 in ring 3 has been created on device 1
yq01-sys-hic-k8s-v100-box-a225-0562:43622:43622 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0 [2] -1/-1/-1->1->0 [3] -1/-1/-1->1->0
yq01-sys-hic-k8s-v100-box-a225-0562:43622:43622 [1] NCCL INFO Setting affinity for GPU 1 to ffffff
yq01-sys-hic-k8s-v100-box-a225-0562:43622:43622 [1] NCCL INFO Channel 00 : 1[40000] -> 0[3f000] via P2P/IPC
yq01-sys-hic-k8s-v100-box-a225-0562:43622:43622 [1] NCCL INFO Channel 01 : 1[40000] -> 0[3f000] via P2P/IPC
yq01-sys-hic-k8s-v100-box-a225-0562:43622:43622 [1] NCCL INFO Channel 02 : 1[40000] -> 0[3f000] via P2P/IPC
yq01-sys-hic-k8s-v100-box-a225-0562:43622:43622 [1] NCCL INFO Channel 03 : 1[40000] -> 0[3f000] via P2P/IPC
yq01-sys-hic-k8s-v100-box-a225-0562:43622:43622 [1] NCCL INFO Connected all rings
yq01-sys-hic-k8s-v100-box-a225-0562:43622:43622 [1] NCCL INFO Connected all trees
yq01-sys-hic-k8s-v100-box-a225-0562:43622:43622 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
yq01-sys-hic-k8s-v100-box-a225-0562:43622:43622 [1] NCCL INFO 4 coll channels, 4 p2p channels, 4 p2p channels per peer
yq01-sys-hic-k8s-v100-box-a225-0562:43622:43622 [1] NCCL INFO comm 0x69509de0 rank 1 nranks 2 cudaDev 1 busId 40000 - Init COMPLETE
I0707 16:26:15.243513 43622 collective_helper.cc:104] nccl communicator of rank 1 in ring 20 has been created on device 1
NCCL version 2.8.3+cuda10.1
yq01-sys-hic-k8s-v100-box-a225-0562:43622:43622 [1] NCCL INFO Channel 00/04 :    0   1
yq01-sys-hic-k8s-v100-box-a225-0562:43622:43622 [1] NCCL INFO Channel 01/04 :    0   1
yq01-sys-hic-k8s-v100-box-a225-0562:43622:43622 [1] NCCL INFO Channel 02/04 :    0   1
yq01-sys-hic-k8s-v100-box-a225-0562:43622:43622 [1] NCCL INFO Channel 03/04 :    0   1
yq01-sys-hic-k8s-v100-box-a225-0562:43622:43622 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1
yq01-sys-hic-k8s-v100-box-a225-0562:43622:43622 [1] NCCL INFO Setting affinity for GPU 1 to ffffff
yq01-sys-hic-k8s-v100-box-a225-0562:43622:43622 [1] NCCL INFO Channel 00 : 0[40000] -> 1[3f000] via P2P/IPC
yq01-sys-hic-k8s-v100-box-a225-0562:43622:43622 [1] NCCL INFO Channel 01 : 0[40000] -> 1[3f000] via P2P/IPC
yq01-sys-hic-k8s-v100-box-a225-0562:43622:43622 [1] NCCL INFO Channel 02 : 0[40000] -> 1[3f000] via P2P/IPC
yq01-sys-hic-k8s-v100-box-a225-0562:43622:43622 [1] NCCL INFO Channel 03 : 0[40000] -> 1[3f000] via P2P/IPC
yq01-sys-hic-k8s-v100-box-a225-0562:43622:43622 [1] NCCL INFO Connected all rings
yq01-sys-hic-k8s-v100-box-a225-0562:43622:43622 [1] NCCL INFO Connected all trees
yq01-sys-hic-k8s-v100-box-a225-0562:43622:43622 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
yq01-sys-hic-k8s-v100-box-a225-0562:43622:43622 [1] NCCL INFO 4 coll channels, 4 p2p channels, 4 p2p channels per peer
yq01-sys-hic-k8s-v100-box-a225-0562:43622:43622 [1] NCCL INFO comm 0x6a9fe2b0 rank 0 nranks 2 cudaDev 1 busId 40000 - Init COMPLETE
I0707 16:26:15.310956 43622 collective_helper.cc:104] nccl communicator of rank 0 in ring 21 has been created on device 1
I0707 16:26:15.732455 43622 lod_tensor_blocking_queue.h:104] Init queue with size 1
I0707 16:26:15.732620 43622 buffered_reader.cc:41] BufferedReader
yq01-sys-hic-k8s-v100-box-a225-0562:43622:43622 [1] NCCL INFO Launch mode Parallel
[INFO] 2021-07-07 16:26:16,579 [run_pretraining.py:  451]:	worker_index: 1, step: 1, cost: 10.411992, mlm loss: 10.411992, speed: 0.789995 steps/s, speed: 6.319964 samples/s, speed: 3235.821454 tokens/s, learning rate: 0.000e+00, loss_scalings: 32768.000000, pp_loss: 10.394878
[DEBUG] 2021-07-07 16:26:16,616 [run_pretraining.py:  460]:	saving models to output/newest-pp-1f1b-fixed-bs8/step_1
[INFO] 2021-07-07 16:26:19,706 [run_pretraining.py:  451]:	worker_index: 1, step: 2, cost: 10.502705, mlm loss: 10.502705, speed: 0.323673 steps/s, speed: 2.589380 samples/s, speed: 1325.762681 tokens/s, learning rate: 1.000e-08, loss_scalings: 32768.000000, pp_loss: 10.421579
[INFO] 2021-07-07 16:26:20,262 [run_pretraining.py:  451]:	worker_index: 1, step: 3, cost: 10.343376, mlm loss: 10.343376, speed: 1.801774 steps/s, speed: 14.414190 samples/s, speed: 7380.065160 tokens/s, learning rate: 2.000e-08, loss_scalings: 32768.000000, pp_loss: 10.454061
[INFO] 2021-07-07 16:26:21,009 [run_pretraining.py:  451]:	worker_index: 1, step: 4, cost: 10.418733, mlm loss: 10.418733, speed: 1.415531 steps/s, speed: 11.324250 samples/s, speed: 5798.015965 tokens/s, learning rate: 3.000e-08, loss_scalings: 32768.000000, pp_loss: 10.430349
[INFO] 2021-07-07 16:26:21,630 [run_pretraining.py:  451]:	worker_index: 1, step: 5, cost: 10.387131, mlm loss: 10.387131, speed: 1.713357 steps/s, speed: 13.706859 samples/s, speed: 7017.911818 tokens/s, learning rate: 4.000e-08, loss_scalings: 32768.000000, pp_loss: 10.385620
[INFO] 2021-07-07 16:26:22,244 [run_pretraining.py:  451]:	worker_index: 1, step: 6, cost: 10.427003, mlm loss: 10.427003, speed: 1.733916 steps/s, speed: 13.871326 samples/s, speed: 7102.118822 tokens/s, learning rate: 5.000e-08, loss_scalings: 32768.000000, pp_loss: 10.423250
[INFO] 2021-07-07 16:26:22,893 [run_pretraining.py:  451]:	worker_index: 1, step: 7, cost: 10.010564, mlm loss: 10.010564, speed: 1.631061 steps/s, speed: 13.048492 samples/s, speed: 6680.827894 tokens/s, learning rate: 6.000e-08, loss_scalings: 32768.000000, pp_loss: 10.333889
[INFO] 2021-07-07 16:26:23,669 [run_pretraining.py:  451]:	worker_index: 1, step: 8, cost: 10.287292, mlm loss: 10.287292, speed: 1.355122 steps/s, speed: 10.840975 samples/s, speed: 5550.579046 tokens/s, learning rate: 7.000e-08, loss_scalings: 32768.000000, pp_loss: 10.390685
[INFO] 2021-07-07 16:26:24,347 [run_pretraining.py:  451]:	worker_index: 1, step: 9, cost: 10.394706, mlm loss: 10.394706, speed: 1.477375 steps/s, speed: 11.818998 samples/s, speed: 6051.327193 tokens/s, learning rate: 8.000e-08, loss_scalings: 32768.000000, pp_loss: 10.398467
[INFO] 2021-07-07 16:26:25,478 [run_pretraining.py:  451]:	worker_index: 1, step: 10, cost: 10.418615, mlm loss: 10.418615, speed: 0.913519 steps/s, speed: 7.308151 samples/s, speed: 3741.773249 tokens/s, learning rate: 9.000e-08, loss_scalings: 32768.000000, pp_loss: 10.381636
[INFO] 2021-07-07 16:26:26,156 [run_pretraining.py:  451]:	worker_index: 1, step: 11, cost: 10.446508, mlm loss: 10.446508, speed: 1.475703 steps/s, speed: 11.805625 samples/s, speed: 6044.480107 tokens/s, learning rate: 1.000e-07, loss_scalings: 32768.000000, pp_loss: 10.397501
[INFO] 2021-07-07 16:26:26,771 [run_pretraining.py:  451]:	worker_index: 1, step: 12, cost: 10.437275, mlm loss: 10.437275, speed: 1.728182 steps/s, speed: 13.825460 samples/s, speed: 7078.635331 tokens/s, learning rate: 1.100e-07, loss_scalings: 32768.000000, pp_loss: 10.399216
[INFO] 2021-07-07 16:26:27,362 [run_pretraining.py:  451]:	worker_index: 1, step: 13, cost: 10.392143, mlm loss: 10.392143, speed: 1.801856 steps/s, speed: 14.414846 samples/s, speed: 7380.401227 tokens/s, learning rate: 1.200e-07, loss_scalings: 32768.000000, pp_loss: 10.394339
[INFO] 2021-07-07 16:26:27,967 [run_pretraining.py:  451]:	worker_index: 1, step: 14, cost: 10.272137, mlm loss: 10.272137, speed: 1.761093 steps/s, speed: 14.088745 samples/s, speed: 7213.437579 tokens/s, learning rate: 1.300e-07, loss_scalings: 32768.000000, pp_loss: 10.372971
[INFO] 2021-07-07 16:26:28,587 [run_pretraining.py:  451]:	worker_index: 1, step: 15, cost: 10.443369, mlm loss: 10.443369, speed: 1.714089 steps/s, speed: 13.712713 samples/s, speed: 7020.908893 tokens/s, learning rate: 1.400e-07, loss_scalings: 32768.000000, pp_loss: 10.454274
[INFO] 2021-07-07 16:26:29,219 [run_pretraining.py:  451]:	worker_index: 1, step: 16, cost: 10.413479, mlm loss: 10.413479, speed: 1.674664 steps/s, speed: 13.397315 samples/s, speed: 6859.425107 tokens/s, learning rate: 1.500e-07, loss_scalings: 32768.000000, pp_loss: 10.422523
[INFO] 2021-07-07 16:26:29,894 [run_pretraining.py:  451]:	worker_index: 1, step: 17, cost: 10.322840, mlm loss: 10.322840, speed: 1.561721 steps/s, speed: 12.493766 samples/s, speed: 6396.808119 tokens/s, learning rate: 1.600e-07, loss_scalings: 32768.000000, pp_loss: 10.377518
[INFO] 2021-07-07 16:26:30,613 [run_pretraining.py:  451]:	worker_index: 1, step: 18, cost: 10.425240, mlm loss: 10.425240, speed: 1.461060 steps/s, speed: 11.688479 samples/s, speed: 5984.501203 tokens/s, learning rate: 1.700e-07, loss_scalings: 32768.000000, pp_loss: 10.431058
[INFO] 2021-07-07 16:26:31,368 [run_pretraining.py:  451]:	worker_index: 1, step: 19, cost: 10.501822, mlm loss: 10.501822, speed: 1.393808 steps/s, speed: 11.150467 samples/s, speed: 5709.039221 tokens/s, learning rate: 1.800e-07, loss_scalings: 32768.000000, pp_loss: 10.400090
[INFO] 2021-07-07 16:26:32,072 [run_pretraining.py:  451]:	worker_index: 1, step: 20, cost: 10.410765, mlm loss: 10.410765, speed: 1.495232 steps/s, speed: 11.961857 samples/s, speed: 6124.470721 tokens/s, learning rate: 1.900e-07, loss_scalings: 32768.000000, pp_loss: 10.394533
[INFO] 2021-07-07 16:26:32,742 [run_pretraining.py:  451]:	worker_index: 1, step: 21, cost: 10.481814, mlm loss: 10.481814, speed: 1.577732 steps/s, speed: 12.621855 samples/s, speed: 6462.389840 tokens/s, learning rate: 2.000e-07, loss_scalings: 32768.000000, pp_loss: 10.406462
[INFO] 2021-07-07 16:26:33,361 [run_pretraining.py:  451]:	worker_index: 1, step: 22, cost: 10.399757, mlm loss: 10.399757, speed: 1.717145 steps/s, speed: 13.737162 samples/s, speed: 7033.426711 tokens/s, learning rate: 2.100e-07, loss_scalings: 32768.000000, pp_loss: 10.451198
[INFO] 2021-07-07 16:26:34,012 [run_pretraining.py:  451]:	worker_index: 1, step: 23, cost: 10.097307, mlm loss: 10.097307, speed: 1.626891 steps/s, speed: 13.015128 samples/s, speed: 6663.745606 tokens/s, learning rate: 2.200e-07, loss_scalings: 32768.000000, pp_loss: 10.378895
[INFO] 2021-07-07 16:26:35,161 [run_pretraining.py:  451]:	worker_index: 1, step: 24, cost: 10.277768, mlm loss: 10.277768, speed: 0.871346 steps/s, speed: 6.970765 samples/s, speed: 3569.031618 tokens/s, learning rate: 2.300e-07, loss_scalings: 32768.000000, pp_loss: 10.386820
[INFO] 2021-07-07 16:26:36,458 [run_pretraining.py:  451]:	worker_index: 1, step: 25, cost: 10.416306, mlm loss: 10.416306, speed: 0.793238 steps/s, speed: 6.345907 samples/s, speed: 3249.104208 tokens/s, learning rate: 2.400e-07, loss_scalings: 32768.000000, pp_loss: 10.460599
[INFO] 2021-07-07 16:26:36,996 [run_pretraining.py:  451]:	worker_index: 1, step: 26, cost: 10.359972, mlm loss: 10.359972, speed: 1.863699 steps/s, speed: 14.909595 samples/s, speed: 7633.712823 tokens/s, learning rate: 2.500e-07, loss_scalings: 32768.000000, pp_loss: 10.412898
[INFO] 2021-07-07 16:26:37,541 [run_pretraining.py:  451]:	worker_index: 1, step: 27, cost: 10.436455, mlm loss: 10.436455, speed: 1.837081 steps/s, speed: 14.696648 samples/s, speed: 7524.683903 tokens/s, learning rate: 2.600e-07, loss_scalings: 32768.000000, pp_loss: 10.427442
[INFO] 2021-07-07 16:26:38,183 [run_pretraining.py:  451]:	worker_index: 1, step: 28, cost: 10.246536, mlm loss: 10.246536, speed: 1.645400 steps/s, speed: 13.163200 samples/s, speed: 6739.558483 tokens/s, learning rate: 2.700e-07, loss_scalings: 32768.000000, pp_loss: 10.348269
[INFO] 2021-07-07 16:26:38,865 [run_pretraining.py:  451]:	worker_index: 1, step: 29, cost: 10.453838, mlm loss: 10.453838, speed: 1.553360 steps/s, speed: 12.426882 samples/s, speed: 6362.563393 tokens/s, learning rate: 2.800e-07, loss_scalings: 32768.000000, pp_loss: 10.365612
[INFO] 2021-07-07 16:26:39,508 [run_pretraining.py:  451]:	worker_index: 1, step: 30, cost: 10.416905, mlm loss: 10.416905, speed: 1.650620 steps/s, speed: 13.204963 samples/s, speed: 6760.941133 tokens/s, learning rate: 2.900e-07, loss_scalings: 32768.000000, pp_loss: 10.352165
[INFO] 2021-07-07 16:26:40,284 [run_pretraining.py:  451]:	worker_index: 1, step: 31, cost: 10.468184, mlm loss: 10.468184, speed: 1.347025 steps/s, speed: 10.776199 samples/s, speed: 5517.413766 tokens/s, learning rate: 3.000e-07, loss_scalings: 32768.000000, pp_loss: 10.401084
[INFO] 2021-07-07 16:26:40,946 [run_pretraining.py:  451]:	worker_index: 1, step: 32, cost: 10.386847, mlm loss: 10.386847, speed: 1.592695 steps/s, speed: 12.741562 samples/s, speed: 6523.679727 tokens/s, learning rate: 3.100e-07, loss_scalings: 32768.000000, pp_loss: 10.341632
[INFO] 2021-07-07 16:26:41,602 [run_pretraining.py:  451]:	worker_index: 1, step: 33, cost: 10.360982, mlm loss: 10.360982, speed: 1.612861 steps/s, speed: 12.902886 samples/s, speed: 6606.277543 tokens/s, learning rate: 3.200e-07, loss_scalings: 32768.000000, pp_loss: 10.324411
[INFO] 2021-07-07 16:26:42,210 [run_pretraining.py:  451]:	worker_index: 1, step: 34, cost: 10.380191, mlm loss: 10.380191, speed: 1.745085 steps/s, speed: 13.960683 samples/s, speed: 7147.869741 tokens/s, learning rate: 3.300e-07, loss_scalings: 32768.000000, pp_loss: 10.401481
[INFO] 2021-07-07 16:26:42,811 [run_pretraining.py:  451]:	worker_index: 1, step: 35, cost: 10.464119, mlm loss: 10.464119, speed: 1.774237 steps/s, speed: 14.193892 samples/s, speed: 7267.272778 tokens/s, learning rate: 3.400e-07, loss_scalings: 32768.000000, pp_loss: 10.368087
[INFO] 2021-07-07 16:26:43,412 [run_pretraining.py:  451]:	worker_index: 1, step: 36, cost: 10.307090, mlm loss: 10.307090, speed: 1.761146 steps/s, speed: 14.089165 samples/s, speed: 7213.652628 tokens/s, learning rate: 3.500e-07, loss_scalings: 32768.000000, pp_loss: 10.343635
[INFO] 2021-07-07 16:26:44,014 [run_pretraining.py:  451]:	worker_index: 1, step: 37, cost: 10.276871, mlm loss: 10.276871, speed: 1.771912 steps/s, speed: 14.175298 samples/s, speed: 7257.752371 tokens/s, learning rate: 3.600e-07, loss_scalings: 32768.000000, pp_loss: 10.363007
[INFO] 2021-07-07 16:26:45,298 [run_pretraining.py:  451]:	worker_index: 1, step: 38, cost: 10.385553, mlm loss: 10.385553, speed: 0.799650 steps/s, speed: 6.397201 samples/s, speed: 3275.366877 tokens/s, learning rate: 3.700e-07, loss_scalings: 32768.000000, pp_loss: 10.325351
[INFO] 2021-07-07 16:26:46,555 [run_pretraining.py:  451]:	worker_index: 1, step: 39, cost: 10.059484, mlm loss: 10.059484, speed: 0.795854 steps/s, speed: 6.366832 samples/s, speed: 3259.817844 tokens/s, learning rate: 3.800e-07, loss_scalings: 32768.000000, pp_loss: 10.301392
[INFO] 2021-07-07 16:26:47,218 [run_pretraining.py:  451]:	worker_index: 1, step: 40, cost: 10.260485, mlm loss: 10.260485, speed: 1.540953 steps/s, speed: 12.327622 samples/s, speed: 6311.742644 tokens/s, learning rate: 3.900e-07, loss_scalings: 32768.000000, pp_loss: 10.291561
[INFO] 2021-07-07 16:26:47,778 [run_pretraining.py:  451]:	worker_index: 1, step: 41, cost: 10.326308, mlm loss: 10.326308, speed: 1.788424 steps/s, speed: 14.307395 samples/s, speed: 7325.386146 tokens/s, learning rate: 4.000e-07, loss_scalings: 32768.000000, pp_loss: 10.352104
[INFO] 2021-07-07 16:26:48,424 [run_pretraining.py:  451]:	worker_index: 1, step: 42, cost: 10.310104, mlm loss: 10.310104, speed: 1.640523 steps/s, speed: 13.124185 samples/s, speed: 6719.582485 tokens/s, learning rate: 4.100e-07, loss_scalings: 32768.000000, pp_loss: 10.346964
[INFO] 2021-07-07 16:26:48,997 [run_pretraining.py:  451]:	worker_index: 1, step: 43, cost: 10.357314, mlm loss: 10.357314, speed: 1.747042 steps/s, speed: 13.976337 samples/s, speed: 7155.884587 tokens/s, learning rate: 4.200e-07, loss_scalings: 32768.000000, pp_loss: 10.339544
[INFO] 2021-07-07 16:26:49,738 [run_pretraining.py:  451]:	worker_index: 1, step: 44, cost: 10.411165, mlm loss: 10.411165, speed: 1.426330 steps/s, speed: 11.410639 samples/s, speed: 5842.246971 tokens/s, learning rate: 4.300e-07, loss_scalings: 32768.000000, pp_loss: 10.310114
[INFO] 2021-07-07 16:26:50,360 [run_pretraining.py:  451]:	worker_index: 1, step: 45, cost: 9.998951, mlm loss: 9.998951, speed: 1.707067 steps/s, speed: 13.656540 samples/s, speed: 6992.148297 tokens/s, learning rate: 4.400e-07, loss_scalings: 32768.000000, pp_loss: 10.286959
[INFO] 2021-07-07 16:26:50,950 [run_pretraining.py:  451]:	worker_index: 1, step: 46, cost: 10.289469, mlm loss: 10.289469, speed: 1.699442 steps/s, speed: 13.595535 samples/s, speed: 6960.913720 tokens/s, learning rate: 4.500e-07, loss_scalings: 32768.000000, pp_loss: 10.336333
[INFO] 2021-07-07 16:26:51,627 [run_pretraining.py:  451]:	worker_index: 1, step: 47, cost: 10.395130, mlm loss: 10.395130, speed: 1.477931 steps/s, speed: 11.823446 samples/s, speed: 6053.604471 tokens/s, learning rate: 4.600e-07, loss_scalings: 32768.000000, pp_loss: 10.320950
[INFO] 2021-07-07 16:26:52,275 [run_pretraining.py:  451]:	worker_index: 1, step: 48, cost: 10.510512, mlm loss: 10.510512, speed: 1.637485 steps/s, speed: 13.099882 samples/s, speed: 6707.139834 tokens/s, learning rate: 4.700e-07, loss_scalings: 32768.000000, pp_loss: 10.331363
[INFO] 2021-07-07 16:26:52,975 [run_pretraining.py:  451]:	worker_index: 1, step: 49, cost: 10.343232, mlm loss: 10.343232, speed: 1.504853 steps/s, speed: 12.038821 samples/s, speed: 6163.876104 tokens/s, learning rate: 4.800e-07, loss_scalings: 32768.000000, pp_loss: 10.345801
[INFO] 2021-07-07 16:26:53,694 [run_pretraining.py:  451]:	worker_index: 1, step: 50, cost: 10.207857, mlm loss: 10.207857, speed: 1.467035 steps/s, speed: 11.736279 samples/s, speed: 6008.974771 tokens/s, learning rate: 4.900e-07, loss_scalings: 32768.000000, pp_loss: 10.230458
[INFO] 2021-07-07 16:26:54,329 [run_pretraining.py:  451]:	worker_index: 1, step: 51, cost: 10.264234, mlm loss: 10.264234, speed: 1.575003 steps/s, speed: 12.600024 samples/s, speed: 6451.212497 tokens/s, learning rate: 5.000e-07, loss_scalings: 32768.000000, pp_loss: 10.276535
[INFO] 2021-07-07 16:26:55,538 [run_pretraining.py:  451]:	worker_index: 1, step: 52, cost: 10.382093, mlm loss: 10.382093, speed: 0.853396 steps/s, speed: 6.827165 samples/s, speed: 3495.508641 tokens/s, learning rate: 5.100e-07, loss_scalings: 32768.000000, pp_loss: 10.292341
[INFO] 2021-07-07 16:26:56,797 [run_pretraining.py:  451]:	worker_index: 1, step: 53, cost: 10.287119, mlm loss: 10.287119, speed: 0.817058 steps/s, speed: 6.536461 samples/s, speed: 3346.668001 tokens/s, learning rate: 5.200e-07, loss_scalings: 32768.000000, pp_loss: 10.280766
[INFO] 2021-07-07 16:26:57,427 [run_pretraining.py:  451]:	worker_index: 1, step: 54, cost: 10.404221, mlm loss: 10.404221, speed: 1.690177 steps/s, speed: 13.521415 samples/s, speed: 6922.964383 tokens/s, learning rate: 5.300e-07, loss_scalings: 32768.000000, pp_loss: 10.294086
[INFO] 2021-07-07 16:26:58,013 [run_pretraining.py:  451]:	worker_index: 1, step: 55, cost: 10.226987, mlm loss: 10.226987, speed: 1.708918 steps/s, speed: 13.671346 samples/s, speed: 6999.729129 tokens/s, learning rate: 5.400e-07, loss_scalings: 32768.000000, pp_loss: 10.252791
[INFO] 2021-07-07 16:26:58,569 [run_pretraining.py:  451]:	worker_index: 1, step: 56, cost: 10.184826, mlm loss: 10.184826, speed: 1.803063 steps/s, speed: 14.424501 samples/s, speed: 7385.344315 tokens/s, learning rate: 5.500e-07, loss_scalings: 32768.000000, pp_loss: 10.233749
[INFO] 2021-07-07 16:26:59,310 [run_pretraining.py:  451]:	worker_index: 1, step: 57, cost: 10.242481, mlm loss: 10.242481, speed: 1.422135 steps/s, speed: 11.377083 samples/s, speed: 5825.066688 tokens/s, learning rate: 5.600e-07, loss_scalings: 32768.000000, pp_loss: 10.231091
[INFO] 2021-07-07 16:26:59,932 [run_pretraining.py:  451]:	worker_index: 1, step: 58, cost: 10.295923, mlm loss: 10.295923, speed: 1.703630 steps/s, speed: 13.629038 samples/s, speed: 6978.067330 tokens/s, learning rate: 5.700e-07, loss_scalings: 32768.000000, pp_loss: 10.281318
[INFO] 2021-07-07 16:27:00,494 [run_pretraining.py:  451]:	worker_index: 1, step: 59, cost: 10.212665, mlm loss: 10.212665, speed: 1.781364 steps/s, speed: 14.250914 samples/s, speed: 7296.467847 tokens/s, learning rate: 5.800e-07, loss_scalings: 32768.000000, pp_loss: 10.271185
[INFO] 2021-07-07 16:27:01,209 [run_pretraining.py:  451]:	worker_index: 1, step: 60, cost: 10.305239, mlm loss: 10.305239, speed: 1.469478 steps/s, speed: 11.755822 samples/s, speed: 6018.981020 tokens/s, learning rate: 5.900e-07, loss_scalings: 32768.000000, pp_loss: 10.249577
[INFO] 2021-07-07 16:27:01,879 [run_pretraining.py:  451]:	worker_index: 1, step: 61, cost: 10.126060, mlm loss: 10.126060, speed: 1.583221 steps/s, speed: 12.665768 samples/s, speed: 6484.873364 tokens/s, learning rate: 6.000e-07, loss_scalings: 32768.000000, pp_loss: 10.289277
[INFO] 2021-07-07 16:27:02,512 [run_pretraining.py:  451]:	worker_index: 1, step: 62, cost: 10.339787, mlm loss: 10.339787, speed: 1.668723 steps/s, speed: 13.349785 samples/s, speed: 6835.090134 tokens/s, learning rate: 6.100e-07, loss_scalings: 32768.000000, pp_loss: 10.228060
[INFO] 2021-07-07 16:27:03,102 [run_pretraining.py:  451]:	worker_index: 1, step: 63, cost: 10.063017, mlm loss: 10.063017, speed: 1.805757 steps/s, speed: 14.446056 samples/s, speed: 7396.380647 tokens/s, learning rate: 6.200e-07, loss_scalings: 32768.000000, pp_loss: 10.214858
[INFO] 2021-07-07 16:27:03,740 [run_pretraining.py:  451]:	worker_index: 1, step: 64, cost: 10.263243, mlm loss: 10.263243, speed: 1.662529 steps/s, speed: 13.300235 samples/s, speed: 6809.720448 tokens/s, learning rate: 6.300e-07, loss_scalings: 32768.000000, pp_loss: 10.278009
[INFO] 2021-07-07 16:27:04,287 [run_pretraining.py:  451]:	worker_index: 1, step: 65, cost: 10.308835, mlm loss: 10.308835, speed: 1.827645 steps/s, speed: 14.621158 samples/s, speed: 7486.032945 tokens/s, learning rate: 6.400e-07, loss_scalings: 32768.000000, pp_loss: 10.202600
[INFO] 2021-07-07 16:27:05,372 [run_pretraining.py:  451]:	worker_index: 1, step: 66, cost: 10.168150, mlm loss: 10.168150, speed: 0.955216 steps/s, speed: 7.641728 samples/s, speed: 3912.564937 tokens/s, learning rate: 6.500e-07, loss_scalings: 32768.000000, pp_loss: 10.225009
[INFO] 2021-07-07 16:27:06,502 [run_pretraining.py:  451]:	worker_index: 1, step: 67, cost: 10.175667, mlm loss: 10.175667, speed: 0.915180 steps/s, speed: 7.321440 samples/s, speed: 3748.577457 tokens/s, learning rate: 6.600e-07, loss_scalings: 32768.000000, pp_loss: 10.219110
[INFO] 2021-07-07 16:27:07,117 [run_pretraining.py:  451]:	worker_index: 1, step: 68, cost: 10.203347, mlm loss: 10.203347, speed: 1.692091 steps/s, speed: 13.536727 samples/s, speed: 6930.804062 tokens/s, learning rate: 6.700e-07, loss_scalings: 32768.000000, pp_loss: 10.153360
[INFO] 2021-07-07 16:27:07,706 [run_pretraining.py:  451]:	worker_index: 1, step: 69, cost: 10.096375, mlm loss: 10.096375, speed: 1.699166 steps/s, speed: 13.593326 samples/s, speed: 6959.782918 tokens/s, learning rate: 6.800e-07, loss_scalings: 32768.000000, pp_loss: 10.167469
[INFO] 2021-07-07 16:27:08,292 [run_pretraining.py:  451]:	worker_index: 1, step: 70, cost: 10.177290, mlm loss: 10.177290, speed: 1.815463 steps/s, speed: 14.523704 samples/s, speed: 7436.136255 tokens/s, learning rate: 6.900e-07, loss_scalings: 32768.000000, pp_loss: 10.162270
[INFO] 2021-07-07 16:27:09,041 [run_pretraining.py:  451]:	worker_index: 1, step: 71, cost: 10.182153, mlm loss: 10.182153, speed: 1.399053 steps/s, speed: 11.192422 samples/s, speed: 5730.519815 tokens/s, learning rate: 7.000e-07, loss_scalings: 32768.000000, pp_loss: 10.165621
[INFO] 2021-07-07 16:27:09,616 [run_pretraining.py:  451]:	worker_index: 1, step: 72, cost: 10.209568, mlm loss: 10.209568, speed: 1.843417 steps/s, speed: 14.747334 samples/s, speed: 7550.634990 tokens/s, learning rate: 7.100e-07, loss_scalings: 32768.000000, pp_loss: 10.175924
[INFO] 2021-07-07 16:27:10,188 [run_pretraining.py:  451]:	worker_index: 1, step: 73, cost: 10.016809, mlm loss: 10.016809, speed: 1.854575 steps/s, speed: 14.836597 samples/s, speed: 7596.337452 tokens/s, learning rate: 7.200e-07, loss_scalings: 32768.000000, pp_loss: 10.140594
[INFO] 2021-07-07 16:27:10,760 [run_pretraining.py:  451]:	worker_index: 1, step: 74, cost: 10.215481, mlm loss: 10.215481, speed: 1.866670 steps/s, speed: 14.933357 samples/s, speed: 7645.878819 tokens/s, learning rate: 7.300e-07, loss_scalings: 32768.000000, pp_loss: 10.155203
[INFO] 2021-07-07 16:27:11,334 [run_pretraining.py:  451]:	worker_index: 1, step: 75, cost: 10.089598, mlm loss: 10.089598, speed: 1.848171 steps/s, speed: 14.785368 samples/s, speed: 7570.108500 tokens/s, learning rate: 7.400e-07, loss_scalings: 32768.000000, pp_loss: 10.140597
[INFO] 2021-07-07 16:27:11,834 [run_pretraining.py:  451]:	worker_index: 1, step: 76, cost: 10.204960, mlm loss: 10.204960, speed: 2.000992 steps/s, speed: 16.007939 samples/s, speed: 8196.064516 tokens/s, learning rate: 7.500e-07, loss_scalings: 32768.000000, pp_loss: 10.172180
[INFO] 2021-07-07 16:27:12,409 [run_pretraining.py:  451]:	worker_index: 1, step: 77, cost: 10.108739, mlm loss: 10.108739, speed: 1.859747 steps/s, speed: 14.877975 samples/s, speed: 7617.523445 tokens/s, learning rate: 7.600e-07, loss_scalings: 32768.000000, pp_loss: 10.118763
[INFO] 2021-07-07 16:27:12,930 [run_pretraining.py:  451]:	worker_index: 1, step: 78, cost: 10.098801, mlm loss: 10.098801, speed: 1.920895 steps/s, speed: 15.367163 samples/s, speed: 7867.987710 tokens/s, learning rate: 7.700e-07, loss_scalings: 32768.000000, pp_loss: 10.179098
[INFO] 2021-07-07 16:27:13,466 [run_pretraining.py:  451]:	worker_index: 1, step: 79, cost: 9.961176, mlm loss: 9.961176, speed: 1.997368 steps/s, speed: 15.978948 samples/s, speed: 8181.221232 tokens/s, learning rate: 7.800e-07, loss_scalings: 32768.000000, pp_loss: 10.072489
[INFO] 2021-07-07 16:27:14,469 [run_pretraining.py:  451]:	worker_index: 1, step: 80, cost: 10.115731, mlm loss: 10.115731, speed: 1.034067 steps/s, speed: 8.272534 samples/s, speed: 4235.537412 tokens/s, learning rate: 7.900e-07, loss_scalings: 32768.000000, pp_loss: 10.092174
[INFO] 2021-07-07 16:27:15,030 [run_pretraining.py:  451]:	worker_index: 1, step: 81, cost: 10.168637, mlm loss: 10.168637, speed: 1.904666 steps/s, speed: 15.237324 samples/s, speed: 7801.510082 tokens/s, learning rate: 8.000e-07, loss_scalings: 32768.000000, pp_loss: 10.141653
[INFO] 2021-07-07 16:27:16,222 [run_pretraining.py:  451]:	worker_index: 1, step: 82, cost: 10.137724, mlm loss: 10.137724, speed: 0.864867 steps/s, speed: 6.918936 samples/s, speed: 3542.495252 tokens/s, learning rate: 8.100e-07, loss_scalings: 32768.000000, pp_loss: 10.174304
[INFO] 2021-07-07 16:27:16,783 [run_pretraining.py:  451]:	worker_index: 1, step: 83, cost: 9.990717, mlm loss: 9.990717, speed: 1.785661 steps/s, speed: 14.285290 samples/s, speed: 7314.068485 tokens/s, learning rate: 8.200e-07, loss_scalings: 32768.000000, pp_loss: 10.142284
[INFO] 2021-07-07 16:27:17,354 [run_pretraining.py:  451]:	worker_index: 1, step: 84, cost: 10.085809, mlm loss: 10.085809, speed: 1.753959 steps/s, speed: 14.031674 samples/s, speed: 7184.216843 tokens/s, learning rate: 8.300e-07, loss_scalings: 32768.000000, pp_loss: 10.110671
[INFO] 2021-07-07 16:27:18,070 [run_pretraining.py:  451]:	worker_index: 1, step: 85, cost: 9.988267, mlm loss: 9.988267, speed: 1.398909 steps/s, speed: 11.191275 samples/s, speed: 5729.933053 tokens/s, learning rate: 8.400e-07, loss_scalings: 32768.000000, pp_loss: 10.114747
[INFO] 2021-07-07 16:27:18,626 [run_pretraining.py:  451]:	worker_index: 1, step: 86, cost: 10.182455, mlm loss: 10.182455, speed: 1.799262 steps/s, speed: 14.394094 samples/s, speed: 7369.776045 tokens/s, learning rate: 8.500e-07, loss_scalings: 32768.000000, pp_loss: 10.014796
[INFO] 2021-07-07 16:27:19,286 [run_pretraining.py:  451]:	worker_index: 1, step: 87, cost: 10.018851, mlm loss: 10.018851, speed: 1.518804 steps/s, speed: 12.150434 samples/s, speed: 6221.022212 tokens/s, learning rate: 8.600e-07, loss_scalings: 32768.000000, pp_loss: 10.017695
[INFO] 2021-07-07 16:27:19,922 [run_pretraining.py:  451]:	worker_index: 1, step: 88, cost: 10.122794, mlm loss: 10.122794, speed: 1.667217 steps/s, speed: 13.337734 samples/s, speed: 6828.920014 tokens/s, learning rate: 8.700e-07, loss_scalings: 32768.000000, pp_loss: 10.061077
[INFO] 2021-07-07 16:27:20,564 [run_pretraining.py:  451]:	worker_index: 1, step: 89, cost: 10.200842, mlm loss: 10.200842, speed: 1.644067 steps/s, speed: 13.152535 samples/s, speed: 6734.097994 tokens/s, learning rate: 8.800e-07, loss_scalings: 32768.000000, pp_loss: 10.132933
[INFO] 2021-07-07 16:27:21,232 [run_pretraining.py:  451]:	worker_index: 1, step: 90, cost: 10.095360, mlm loss: 10.095360, speed: 1.581833 steps/s, speed: 12.654667 samples/s, speed: 6479.189569 tokens/s, learning rate: 8.900e-07, loss_scalings: 32768.000000, pp_loss: 10.075747
[INFO] 2021-07-07 16:27:21,879 [run_pretraining.py:  451]:	worker_index: 1, step: 91, cost: 10.226692, mlm loss: 10.226692, speed: 1.635125 steps/s, speed: 13.081002 samples/s, speed: 6697.473140 tokens/s, learning rate: 9.000e-07, loss_scalings: 32768.000000, pp_loss: 10.047285
[INFO] 2021-07-07 16:27:22,515 [run_pretraining.py:  451]:	worker_index: 1, step: 92, cost: 10.062429, mlm loss: 10.062429, speed: 1.665521 steps/s, speed: 13.324171 samples/s, speed: 6821.975340 tokens/s, learning rate: 9.100e-07, loss_scalings: 32768.000000, pp_loss: 10.080947
[INFO] 2021-07-07 16:27:23,095 [run_pretraining.py:  451]:	worker_index: 1, step: 93, cost: 9.894610, mlm loss: 9.894610, speed: 1.841771 steps/s, speed: 14.734169 samples/s, speed: 7543.894420 tokens/s, learning rate: 9.200e-07, loss_scalings: 32768.000000, pp_loss: 9.985674
[INFO] 2021-07-07 16:27:24,223 [run_pretraining.py:  451]:	worker_index: 1, step: 94, cost: 9.996401, mlm loss: 9.996401, speed: 0.917365 steps/s, speed: 7.338924 samples/s, speed: 3757.528880 tokens/s, learning rate: 9.300e-07, loss_scalings: 32768.000000, pp_loss: 10.033365
[INFO] 2021-07-07 16:27:24,823 [run_pretraining.py:  451]:	worker_index: 1, step: 95, cost: 10.096490, mlm loss: 10.096490, speed: 1.773467 steps/s, speed: 14.187735 samples/s, speed: 7264.120083 tokens/s, learning rate: 9.400e-07, loss_scalings: 32768.000000, pp_loss: 9.995084
[INFO] 2021-07-07 16:27:25,922 [run_pretraining.py:  451]:	worker_index: 1, step: 96, cost: 10.126033, mlm loss: 10.126033, speed: 0.910739 steps/s, speed: 7.285909 samples/s, speed: 3730.385565 tokens/s, learning rate: 9.500e-07, loss_scalings: 32768.000000, pp_loss: 9.965923
[INFO] 2021-07-07 16:27:26,485 [run_pretraining.py:  451]:	worker_index: 1, step: 97, cost: 10.008598, mlm loss: 10.008598, speed: 1.908330 steps/s, speed: 15.266643 samples/s, speed: 7816.521096 tokens/s, learning rate: 9.600e-07, loss_scalings: 32768.000000, pp_loss: 9.906705
[INFO] 2021-07-07 16:27:27,254 [run_pretraining.py:  451]:	worker_index: 1, step: 98, cost: 9.844665, mlm loss: 9.844665, speed: 1.374155 steps/s, speed: 10.993242 samples/s, speed: 5628.540121 tokens/s, learning rate: 9.700e-07, loss_scalings: 32768.000000, pp_loss: 9.950307
[INFO] 2021-07-07 16:27:27,819 [run_pretraining.py:  451]:	worker_index: 1, step: 99, cost: 9.758255, mlm loss: 9.758255, speed: 1.773156 steps/s, speed: 14.185245 samples/s, speed: 7262.845647 tokens/s, learning rate: 9.800e-07, loss_scalings: 32768.000000, pp_loss: 9.889366
[INFO] 2021-07-07 16:27:28,514 [run_pretraining.py:  451]:	worker_index: 1, step: 100, cost: 9.816954, mlm loss: 9.816954, speed: 1.440404 steps/s, speed: 11.523233 samples/s, speed: 5899.895114 tokens/s, learning rate: 9.900e-07, loss_scalings: 32768.000000, pp_loss: 9.946634
[DEBUG] 2021-07-07 16:27:28,514 [run_pretraining.py:  460]:	saving models to output/newest-pp-1f1b-fixed-bs8/step_100
[INFO] 2021-07-07 16:27:30,946 [run_pretraining.py:  451]:	worker_index: 1, step: 101, cost: 10.180285, mlm loss: 10.180285, speed: 0.411321 steps/s, speed: 3.290570 samples/s, speed: 1684.771811 tokens/s, learning rate: 1.000e-06, loss_scalings: 32768.000000, pp_loss: 9.928640
[INFO] 2021-07-07 16:27:31,598 [run_pretraining.py:  451]:	worker_index: 1, step: 102, cost: 10.139661, mlm loss: 10.139661, speed: 1.630118 steps/s, speed: 13.040941 samples/s, speed: 6676.961697 tokens/s, learning rate: 1.010e-06, loss_scalings: 32768.000000, pp_loss: 9.939416
[INFO] 2021-07-07 16:27:32,274 [run_pretraining.py:  451]:	worker_index: 1, step: 103, cost: 9.933964, mlm loss: 9.933964, speed: 1.567089 steps/s, speed: 12.536711 samples/s, speed: 6418.796076 tokens/s, learning rate: 1.020e-06, loss_scalings: 32768.000000, pp_loss: 9.949875
[INFO] 2021-07-07 16:27:32,987 [run_pretraining.py:  451]:	worker_index: 1, step: 104, cost: 9.826327, mlm loss: 9.826327, speed: 1.480718 steps/s, speed: 11.845744 samples/s, speed: 6065.020903 tokens/s, learning rate: 1.030e-06, loss_scalings: 32768.000000, pp_loss: 9.929306
[INFO] 2021-07-07 16:27:33,656 [run_pretraining.py:  451]:	worker_index: 1, step: 105, cost: 9.750070, mlm loss: 9.750070, speed: 1.495317 steps/s, speed: 11.962539 samples/s, speed: 6124.820072 tokens/s, learning rate: 1.040e-06, loss_scalings: 32768.000000, pp_loss: 9.866205
[INFO] 2021-07-07 16:27:34,292 [run_pretraining.py:  451]:	worker_index: 1, step: 106, cost: 9.910832, mlm loss: 9.910832, speed: 1.572963 steps/s, speed: 12.583703 samples/s, speed: 6442.856039 tokens/s, learning rate: 1.050e-06, loss_scalings: 32768.000000, pp_loss: 9.965041
[INFO] 2021-07-07 16:27:35,416 [run_pretraining.py:  451]:	worker_index: 1, step: 107, cost: 10.050862, mlm loss: 10.050862, speed: 0.920798 steps/s, speed: 7.366386 samples/s, speed: 3771.589481 tokens/s, learning rate: 1.060e-06, loss_scalings: 32768.000000, pp_loss: 9.964873
[INFO] 2021-07-07 16:27:36,065 [run_pretraining.py:  451]:	worker_index: 1, step: 108, cost: 10.020628, mlm loss: 10.020628, speed: 1.634965 steps/s, speed: 13.079722 samples/s, speed: 6696.817851 tokens/s, learning rate: 1.070e-06, loss_scalings: 32768.000000, pp_loss: 9.913592
[INFO] 2021-07-07 16:27:36,715 [run_pretraining.py:  451]:	worker_index: 1, step: 109, cost: 9.899130, mlm loss: 9.899130, speed: 1.630675 steps/s, speed: 13.045397 samples/s, speed: 6679.243484 tokens/s, learning rate: 1.080e-06, loss_scalings: 32768.000000, pp_loss: 9.870426
[INFO] 2021-07-07 16:27:37,996 [run_pretraining.py:  451]:	worker_index: 1, step: 110, cost: 10.111462, mlm loss: 10.111462, speed: 0.802842 steps/s, speed: 6.422734 samples/s, speed: 3288.439951 tokens/s, learning rate: 1.090e-06, loss_scalings: 32768.000000, pp_loss: 9.956032
[INFO] 2021-07-07 16:27:38,535 [run_pretraining.py:  451]:	worker_index: 1, step: 111, cost: 10.032269, mlm loss: 10.032269, speed: 1.986778 steps/s, speed: 15.894221 samples/s, speed: 8137.840909 tokens/s, learning rate: 1.100e-06, loss_scalings: 32768.000000, pp_loss: 9.899454
[INFO] 2021-07-07 16:27:39,141 [run_pretraining.py:  451]:	worker_index: 1, step: 112, cost: 9.876421, mlm loss: 9.876421, speed: 1.753642 steps/s, speed: 14.029133 samples/s, speed: 7182.916229 tokens/s, learning rate: 1.110e-06, loss_scalings: 32768.000000, pp_loss: 9.970397
[INFO] 2021-07-07 16:27:39,690 [run_pretraining.py:  451]:	worker_index: 1, step: 113, cost: 9.980099, mlm loss: 9.980099, speed: 1.825364 steps/s, speed: 14.602915 samples/s, speed: 7476.692467 tokens/s, learning rate: 1.120e-06, loss_scalings: 32768.000000, pp_loss: 9.794992
[INFO] 2021-07-07 16:27:40,360 [run_pretraining.py:  451]:	worker_index: 1, step: 114, cost: 9.626367, mlm loss: 9.626367, speed: 1.579269 steps/s, speed: 12.634150 samples/s, speed: 6468.684695 tokens/s, learning rate: 1.130e-06, loss_scalings: 32768.000000, pp_loss: 9.691046
[INFO] 2021-07-07 16:27:40,970 [run_pretraining.py:  451]:	worker_index: 1, step: 115, cost: 9.871107, mlm loss: 9.871107, speed: 1.642280 steps/s, speed: 13.138239 samples/s, speed: 6726.778414 tokens/s, learning rate: 1.140e-06, loss_scalings: 32768.000000, pp_loss: 9.810531
[INFO] 2021-07-07 16:27:41,631 [run_pretraining.py:  451]:	worker_index: 1, step: 116, cost: 9.874807, mlm loss: 9.874807, speed: 1.600914 steps/s, speed: 12.807309 samples/s, speed: 6557.342136 tokens/s, learning rate: 1.150e-06, loss_scalings: 32768.000000, pp_loss: 9.843978
[INFO] 2021-07-07 16:27:42,269 [run_pretraining.py:  451]:	worker_index: 1, step: 117, cost: 10.173144, mlm loss: 10.173144, speed: 1.661153 steps/s, speed: 13.289226 samples/s, speed: 6804.083742 tokens/s, learning rate: 1.160e-06, loss_scalings: 32768.000000, pp_loss: 9.773769
[INFO] 2021-07-07 16:27:42,901 [run_pretraining.py:  451]:	worker_index: 1, step: 118, cost: 9.859972, mlm loss: 9.859972, speed: 1.677075 steps/s, speed: 13.416599 samples/s, speed: 6869.298872 tokens/s, learning rate: 1.170e-06, loss_scalings: 32768.000000, pp_loss: 9.834316
[INFO] 2021-07-07 16:27:43,504 [run_pretraining.py:  451]:	worker_index: 1, step: 119, cost: 9.713012, mlm loss: 9.713012, speed: 1.761610 steps/s, speed: 14.092881 samples/s, speed: 7215.555303 tokens/s, learning rate: 1.180e-06, loss_scalings: 32768.000000, pp_loss: 9.712260
[INFO] 2021-07-07 16:27:44,124 [run_pretraining.py:  451]:	worker_index: 1, step: 120, cost: 9.709101, mlm loss: 9.709101, speed: 1.712491 steps/s, speed: 13.699931 samples/s, speed: 7014.364525 tokens/s, learning rate: 1.190e-06, loss_scalings: 32768.000000, pp_loss: 9.829757
[INFO] 2021-07-07 16:27:45,237 [run_pretraining.py:  451]:	worker_index: 1, step: 121, cost: 9.851191, mlm loss: 9.851191, speed: 0.899668 steps/s, speed: 7.197342 samples/s, speed: 3685.038989 tokens/s, learning rate: 1.200e-06, loss_scalings: 32768.000000, pp_loss: 9.722700
[INFO] 2021-07-07 16:27:45,852 [run_pretraining.py:  451]:	worker_index: 1, step: 122, cost: 9.809537, mlm loss: 9.809537, speed: 1.626845 steps/s, speed: 13.014760 samples/s, speed: 6663.556925 tokens/s, learning rate: 1.210e-06, loss_scalings: 32768.000000, pp_loss: 9.897635
[INFO] 2021-07-07 16:27:46,564 [run_pretraining.py:  451]:	worker_index: 1, step: 123, cost: 9.832332, mlm loss: 9.832332, speed: 1.405966 steps/s, speed: 11.247730 samples/s, speed: 5758.838001 tokens/s, learning rate: 1.220e-06, loss_scalings: 32768.000000, pp_loss: 9.808343
[INFO] 2021-07-07 16:27:47,793 [run_pretraining.py:  451]:	worker_index: 1, step: 124, cost: 9.828931, mlm loss: 9.828931, speed: 0.814526 steps/s, speed: 6.516206 samples/s, speed: 3336.297285 tokens/s, learning rate: 1.230e-06, loss_scalings: 32768.000000, pp_loss: 9.763830
[INFO] 2021-07-07 16:27:48,373 [run_pretraining.py:  451]:	worker_index: 1, step: 125, cost: 9.591920, mlm loss: 9.591920, speed: 1.727667 steps/s, speed: 13.821337 samples/s, speed: 7076.524331 tokens/s, learning rate: 1.240e-06, loss_scalings: 32768.000000, pp_loss: 9.701683
[INFO] 2021-07-07 16:27:49,056 [run_pretraining.py:  451]:	worker_index: 1, step: 126, cost: 9.848014, mlm loss: 9.848014, speed: 1.465587 steps/s, speed: 11.724698 samples/s, speed: 6003.045288 tokens/s, learning rate: 1.250e-06, loss_scalings: 32768.000000, pp_loss: 9.763724
[INFO] 2021-07-07 16:27:49,580 [run_pretraining.py:  451]:	worker_index: 1, step: 127, cost: 9.887618, mlm loss: 9.887618, speed: 1.912017 steps/s, speed: 15.296137 samples/s, speed: 7831.622117 tokens/s, learning rate: 1.260e-06, loss_scalings: 32768.000000, pp_loss: 9.825960
[INFO] 2021-07-07 16:27:50,192 [run_pretraining.py:  451]:	worker_index: 1, step: 128, cost: 10.013153, mlm loss: 10.013153, speed: 1.738044 steps/s, speed: 13.904348 samples/s, speed: 7119.026295 tokens/s, learning rate: 1.270e-06, loss_scalings: 32768.000000, pp_loss: 9.699324
[INFO] 2021-07-07 16:27:50,727 [run_pretraining.py:  451]:	worker_index: 1, step: 129, cost: 9.142174, mlm loss: 9.142174, speed: 1.872099 steps/s, speed: 14.976796 samples/s, speed: 7668.119299 tokens/s, learning rate: 1.280e-06, loss_scalings: 32768.000000, pp_loss: 9.628199
[INFO] 2021-07-07 16:27:51,337 [run_pretraining.py:  451]:	worker_index: 1, step: 130, cost: 9.959613, mlm loss: 9.959613, speed: 1.758657 steps/s, speed: 14.069257 samples/s, speed: 7203.459525 tokens/s, learning rate: 1.290e-06, loss_scalings: 32768.000000, pp_loss: 9.689373
[INFO] 2021-07-07 16:27:51,935 [run_pretraining.py:  451]:	worker_index: 1, step: 131, cost: 9.793454, mlm loss: 9.793454, speed: 1.792510 steps/s, speed: 14.340077 samples/s, speed: 7342.119377 tokens/s, learning rate: 1.300e-06, loss_scalings: 32768.000000, pp_loss: 9.731806
[INFO] 2021-07-07 16:27:52,494 [run_pretraining.py:  451]:	worker_index: 1, step: 132, cost: 9.690628, mlm loss: 9.690628, speed: 1.907977 steps/s, speed: 15.263816 samples/s, speed: 7815.073920 tokens/s, learning rate: 1.310e-06, loss_scalings: 32768.000000, pp_loss: 9.715377
[INFO] 2021-07-07 16:27:53,085 [run_pretraining.py:  451]:	worker_index: 1, step: 133, cost: 9.626945, mlm loss: 9.626945, speed: 1.798100 steps/s, speed: 14.384801 samples/s, speed: 7365.017949 tokens/s, learning rate: 1.320e-06, loss_scalings: 32768.000000, pp_loss: 9.752019
[INFO] 2021-07-07 16:27:53,741 [run_pretraining.py:  451]:	worker_index: 1, step: 134, cost: 9.868760, mlm loss: 9.868760, speed: 1.613114 steps/s, speed: 12.904915 samples/s, speed: 6607.316711 tokens/s, learning rate: 1.330e-06, loss_scalings: 32768.000000, pp_loss: 9.749707
[INFO] 2021-07-07 16:27:54,971 [run_pretraining.py:  451]:	worker_index: 1, step: 135, cost: 9.741659, mlm loss: 9.741659, speed: 0.838842 steps/s, speed: 6.710736 samples/s, speed: 3435.896873 tokens/s, learning rate: 1.340e-06, loss_scalings: 32768.000000, pp_loss: 9.705214
[INFO] 2021-07-07 16:27:55,680 [run_pretraining.py:  451]:	worker_index: 1, step: 136, cost: 9.662972, mlm loss: 9.662972, speed: 1.490811 steps/s, speed: 11.926487 samples/s, speed: 6106.361393 tokens/s, learning rate: 1.350e-06, loss_scalings: 32768.000000, pp_loss: 9.659747
[INFO] 2021-07-07 16:27:56,388 [run_pretraining.py:  451]:	worker_index: 1, step: 137, cost: 9.911921, mlm loss: 9.911921, speed: 1.497388 steps/s, speed: 11.979105 samples/s, speed: 6133.301864 tokens/s, learning rate: 1.360e-06, loss_scalings: 32768.000000, pp_loss: 9.671949
[INFO] 2021-07-07 16:27:57,632 [run_pretraining.py:  451]:	worker_index: 1, step: 138, cost: 9.679073, mlm loss: 9.679073, speed: 0.829024 steps/s, speed: 6.632191 samples/s, speed: 3395.682032 tokens/s, learning rate: 1.370e-06, loss_scalings: 32768.000000, pp_loss: 9.627676
[INFO] 2021-07-07 16:27:58,315 [run_pretraining.py:  451]:	worker_index: 1, step: 139, cost: 9.935769, mlm loss: 9.935769, speed: 1.499333 steps/s, speed: 11.994667 samples/s, speed: 6141.269281 tokens/s, learning rate: 1.380e-06, loss_scalings: 32768.000000, pp_loss: 9.742572
[INFO] 2021-07-07 16:27:59,040 [run_pretraining.py:  451]:	worker_index: 1, step: 140, cost: 9.359782, mlm loss: 9.359782, speed: 1.460490 steps/s, speed: 11.683916 samples/s, speed: 5982.165207 tokens/s, learning rate: 1.390e-06, loss_scalings: 32768.000000, pp_loss: 9.558245
[INFO] 2021-07-07 16:27:59,709 [run_pretraining.py:  451]:	worker_index: 1, step: 141, cost: 9.592437, mlm loss: 9.592437, speed: 1.497662 steps/s, speed: 11.981295 samples/s, speed: 6134.423154 tokens/s, learning rate: 1.400e-06, loss_scalings: 32768.000000, pp_loss: 9.475821
[INFO] 2021-07-07 16:28:00,362 [run_pretraining.py:  451]:	worker_index: 1, step: 142, cost: 9.574960, mlm loss: 9.574960, speed: 1.531728 steps/s, speed: 12.253822 samples/s, speed: 6273.956777 tokens/s, learning rate: 1.410e-06, loss_scalings: 32768.000000, pp_loss: 9.762177
[INFO] 2021-07-07 16:28:01,014 [run_pretraining.py:  451]:	worker_index: 1, step: 143, cost: 9.791176, mlm loss: 9.791176, speed: 1.536581 steps/s, speed: 12.292644 samples/s, speed: 6293.833858 tokens/s, learning rate: 1.420e-06, loss_scalings: 32768.000000, pp_loss: 9.601069
[INFO] 2021-07-07 16:28:01,579 [run_pretraining.py:  451]:	worker_index: 1, step: 144, cost: 9.383635, mlm loss: 9.383635, speed: 1.777256 steps/s, speed: 14.218046 samples/s, speed: 7279.639517 tokens/s, learning rate: 1.430e-06, loss_scalings: 32768.000000, pp_loss: 9.637645
[INFO] 2021-07-07 16:28:02,108 [run_pretraining.py:  451]:	worker_index: 1, step: 145, cost: 9.693355, mlm loss: 9.693355, speed: 1.892065 steps/s, speed: 15.136516 samples/s, speed: 7749.896216 tokens/s, learning rate: 1.440e-06, loss_scalings: 32768.000000, pp_loss: 9.651147
[INFO] 2021-07-07 16:28:02,694 [run_pretraining.py:  451]:	worker_index: 1, step: 146, cost: 10.150655, mlm loss: 10.150655, speed: 1.820158 steps/s, speed: 14.561261 samples/s, speed: 7455.365836 tokens/s, learning rate: 1.450e-06, loss_scalings: 32768.000000, pp_loss: 9.702507
[INFO] 2021-07-07 16:28:03,216 [run_pretraining.py:  451]:	worker_index: 1, step: 147, cost: 9.672269, mlm loss: 9.672269, speed: 1.916265 steps/s, speed: 15.330122 samples/s, speed: 7849.022215 tokens/s, learning rate: 1.460e-06, loss_scalings: 32768.000000, pp_loss: 9.480058
[INFO] 2021-07-07 16:28:03,810 [run_pretraining.py:  451]:	worker_index: 1, step: 148, cost: 9.747924, mlm loss: 9.747924, speed: 1.795853 steps/s, speed: 14.366822 samples/s, speed: 7355.813056 tokens/s, learning rate: 1.470e-06, loss_scalings: 32768.000000, pp_loss: 9.648816
[INFO] 2021-07-07 16:28:04,997 [run_pretraining.py:  451]:	worker_index: 1, step: 149, cost: 9.724844, mlm loss: 9.724844, speed: 0.843365 steps/s, speed: 6.746919 samples/s, speed: 3454.422526 tokens/s, learning rate: 1.480e-06, loss_scalings: 32768.000000, pp_loss: 9.711445
[INFO] 2021-07-07 16:28:05,561 [run_pretraining.py:  451]:	worker_index: 1, step: 150, cost: 9.710645, mlm loss: 9.710645, speed: 1.772078 steps/s, speed: 14.176627 samples/s, speed: 7258.433106 tokens/s, learning rate: 1.490e-06, loss_scalings: 32768.000000, pp_loss: 9.584923
[INFO] 2021-07-07 16:28:06,159 [run_pretraining.py:  451]:	worker_index: 1, step: 151, cost: 9.602045, mlm loss: 9.602045, speed: 1.797163 steps/s, speed: 14.377306 samples/s, speed: 7361.180568 tokens/s, learning rate: 1.500e-06, loss_scalings: 32768.000000, pp_loss: 9.561316
[INFO] 2021-07-07 16:28:07,383 [run_pretraining.py:  451]:	worker_index: 1, step: 152, cost: 9.390600, mlm loss: 9.390600, speed: 0.843198 steps/s, speed: 6.745584 samples/s, speed: 3453.739180 tokens/s, learning rate: 1.510e-06, loss_scalings: 32768.000000, pp_loss: 9.564053
[INFO] 2021-07-07 16:28:07,958 [run_pretraining.py:  451]:	worker_index: 1, step: 153, cost: 9.736901, mlm loss: 9.736901, speed: 1.746873 steps/s, speed: 13.974987 samples/s, speed: 7155.193150 tokens/s, learning rate: 1.520e-06, loss_scalings: 32768.000000, pp_loss: 9.644080
[INFO] 2021-07-07 16:28:08,513 [run_pretraining.py:  451]:	worker_index: 1, step: 154, cost: 9.608008, mlm loss: 9.608008, speed: 1.802874 steps/s, speed: 14.422994 samples/s, speed: 7384.572910 tokens/s, learning rate: 1.530e-06, loss_scalings: 32768.000000, pp_loss: 9.690071
[INFO] 2021-07-07 16:28:09,064 [run_pretraining.py:  451]:	worker_index: 1, step: 155, cost: 9.519230, mlm loss: 9.519230, speed: 1.820663 steps/s, speed: 14.565300 samples/s, speed: 7457.433783 tokens/s, learning rate: 1.540e-06, loss_scalings: 32768.000000, pp_loss: 9.603247
[INFO] 2021-07-07 16:28:09,577 [run_pretraining.py:  451]:	worker_index: 1, step: 156, cost: 9.448874, mlm loss: 9.448874, speed: 1.949543 steps/s, speed: 15.596346 samples/s, speed: 7985.329371 tokens/s, learning rate: 1.550e-06, loss_scalings: 32768.000000, pp_loss: 9.601808
[INFO] 2021-07-07 16:28:10,135 [run_pretraining.py:  451]:	worker_index: 1, step: 157, cost: 9.660675, mlm loss: 9.660675, speed: 1.927926 steps/s, speed: 15.423411 samples/s, speed: 7896.786280 tokens/s, learning rate: 1.560e-06, loss_scalings: 32768.000000, pp_loss: 9.613480
[INFO] 2021-07-07 16:28:10,746 [run_pretraining.py:  451]:	worker_index: 1, step: 158, cost: 9.800520, mlm loss: 9.800520, speed: 1.748400 steps/s, speed: 13.987197 samples/s, speed: 7161.444782 tokens/s, learning rate: 1.570e-06, loss_scalings: 32768.000000, pp_loss: 9.552646
[INFO] 2021-07-07 16:28:11,261 [run_pretraining.py:  451]:	worker_index: 1, step: 159, cost: 9.550653, mlm loss: 9.550653, speed: 1.945052 steps/s, speed: 15.560415 samples/s, speed: 7966.932427 tokens/s, learning rate: 1.580e-06, loss_scalings: 32768.000000, pp_loss: 9.535989
[INFO] 2021-07-07 16:28:11,825 [run_pretraining.py:  451]:	worker_index: 1, step: 160, cost: 9.519047, mlm loss: 9.519047, speed: 1.922427 steps/s, speed: 15.379419 samples/s, speed: 7874.262554 tokens/s, learning rate: 1.590e-06, loss_scalings: 32768.000000, pp_loss: 9.496614
[INFO] 2021-07-07 16:28:12,403 [run_pretraining.py:  451]:	worker_index: 1, step: 161, cost: 9.661918, mlm loss: 9.661918, speed: 1.843289 steps/s, speed: 14.746310 samples/s, speed: 7550.110697 tokens/s, learning rate: 1.600e-06, loss_scalings: 32768.000000, pp_loss: 9.464903
[INFO] 2021-07-07 16:28:12,998 [run_pretraining.py:  451]:	worker_index: 1, step: 162, cost: 9.241788, mlm loss: 9.241788, speed: 1.787480 steps/s, speed: 14.299840 samples/s, speed: 7321.518176 tokens/s, learning rate: 1.610e-06, loss_scalings: 32768.000000, pp_loss: 9.585796
[INFO] 2021-07-07 16:28:14,194 [run_pretraining.py:  451]:	worker_index: 1, step: 163, cost: 9.509209, mlm loss: 9.509209, speed: 0.863152 steps/s, speed: 6.905213 samples/s, speed: 3535.469006 tokens/s, learning rate: 1.620e-06, loss_scalings: 32768.000000, pp_loss: 9.404708
[INFO] 2021-07-07 16:28:14,758 [run_pretraining.py:  451]:	worker_index: 1, step: 164, cost: 9.517237, mlm loss: 9.517237, speed: 1.891830 steps/s, speed: 15.134639 samples/s, speed: 7748.934935 tokens/s, learning rate: 1.630e-06, loss_scalings: 32768.000000, pp_loss: 9.546176
[INFO] 2021-07-07 16:28:15,355 [run_pretraining.py:  451]:	worker_index: 1, step: 165, cost: 9.282056, mlm loss: 9.282056, speed: 1.779039 steps/s, speed: 14.232308 samples/s, speed: 7286.941931 tokens/s, learning rate: 1.640e-06, loss_scalings: 32768.000000, pp_loss: 9.587368
[INFO] 2021-07-07 16:28:16,578 [run_pretraining.py:  451]:	worker_index: 1, step: 166, cost: 9.546868, mlm loss: 9.546868, speed: 0.818985 steps/s, speed: 6.551879 samples/s, speed: 3354.561972 tokens/s, learning rate: 1.650e-06, loss_scalings: 32768.000000, pp_loss: 9.601336
[INFO] 2021-07-07 16:28:17,198 [run_pretraining.py:  451]:	worker_index: 1, step: 167, cost: 9.644547, mlm loss: 9.644547, speed: 1.614492 steps/s, speed: 12.915938 samples/s, speed: 6612.960340 tokens/s, learning rate: 1.660e-06, loss_scalings: 32768.000000, pp_loss: 9.506334
[INFO] 2021-07-07 16:28:17,874 [run_pretraining.py:  451]:	worker_index: 1, step: 168, cost: 9.565157, mlm loss: 9.565157, speed: 1.574015 steps/s, speed: 12.592123 samples/s, speed: 6447.167047 tokens/s, learning rate: 1.670e-06, loss_scalings: 32768.000000, pp_loss: 9.493734
[INFO] 2021-07-07 16:28:18,524 [run_pretraining.py:  451]:	worker_index: 1, step: 169, cost: 9.625876, mlm loss: 9.625876, speed: 1.634436 steps/s, speed: 13.075487 samples/s, speed: 6694.649260 tokens/s, learning rate: 1.680e-06, loss_scalings: 32768.000000, pp_loss: 9.493120
[INFO] 2021-07-07 16:28:19,178 [run_pretraining.py:  451]:	worker_index: 1, step: 170, cost: 9.738937, mlm loss: 9.738937, speed: 1.616978 steps/s, speed: 12.935826 samples/s, speed: 6623.142695 tokens/s, learning rate: 1.690e-06, loss_scalings: 32768.000000, pp_loss: 9.398717
[INFO] 2021-07-07 16:28:19,767 [run_pretraining.py:  451]:	worker_index: 1, step: 171, cost: 9.498672, mlm loss: 9.498672, speed: 1.701936 steps/s, speed: 13.615489 samples/s, speed: 6971.130125 tokens/s, learning rate: 1.700e-06, loss_scalings: 32768.000000, pp_loss: 9.541301
[INFO] 2021-07-07 16:28:20,309 [run_pretraining.py:  451]:	worker_index: 1, step: 172, cost: 9.746980, mlm loss: 9.746980, speed: 1.847031 steps/s, speed: 14.776246 samples/s, speed: 7565.438096 tokens/s, learning rate: 1.710e-06, loss_scalings: 32768.000000, pp_loss: 9.392718
[INFO] 2021-07-07 16:28:20,894 [run_pretraining.py:  451]:	worker_index: 1, step: 173, cost: 9.850868, mlm loss: 9.850868, speed: 1.819429 steps/s, speed: 14.555431 samples/s, speed: 7452.380826 tokens/s, learning rate: 1.720e-06, loss_scalings: 32768.000000, pp_loss: 9.567114
[INFO] 2021-07-07 16:28:21,404 [run_pretraining.py:  451]:	worker_index: 1, step: 174, cost: 9.295813, mlm loss: 9.295813, speed: 1.962208 steps/s, speed: 15.697664 samples/s, speed: 8037.204016 tokens/s, learning rate: 1.730e-06, loss_scalings: 32768.000000, pp_loss: 9.485985
[INFO] 2021-07-07 16:28:22,127 [run_pretraining.py:  451]:	worker_index: 1, step: 175, cost: 9.583273, mlm loss: 9.583273, speed: 1.457908 steps/s, speed: 11.663261 samples/s, speed: 5971.589610 tokens/s, learning rate: 1.740e-06, loss_scalings: 32768.000000, pp_loss: 9.266465
[INFO] 2021-07-07 16:28:22,637 [run_pretraining.py:  451]:	worker_index: 1, step: 176, cost: 9.266842, mlm loss: 9.266842, speed: 1.964565 steps/s, speed: 15.716524 samples/s, speed: 8046.860054 tokens/s, learning rate: 1.750e-06, loss_scalings: 32768.000000, pp_loss: 9.407383
[INFO] 2021-07-07 16:28:23,792 [run_pretraining.py:  451]:	worker_index: 1, step: 177, cost: 9.648500, mlm loss: 9.648500, speed: 0.894893 steps/s, speed: 7.159143 samples/s, speed: 3665.481354 tokens/s, learning rate: 1.760e-06, loss_scalings: 32768.000000, pp_loss: 9.381435
[INFO] 2021-07-07 16:28:24,332 [run_pretraining.py:  451]:	worker_index: 1, step: 178, cost: 9.673670, mlm loss: 9.673670, speed: 1.980280 steps/s, speed: 15.842239 samples/s, speed: 8111.226242 tokens/s, learning rate: 1.770e-06, loss_scalings: 32768.000000, pp_loss: 9.524151
[INFO] 2021-07-07 16:28:24,901 [run_pretraining.py:  451]:	worker_index: 1, step: 179, cost: 9.394659, mlm loss: 9.394659, speed: 1.866612 steps/s, speed: 14.932899 samples/s, speed: 7645.644034 tokens/s, learning rate: 1.780e-06, loss_scalings: 32768.000000, pp_loss: 9.514679
[INFO] 2021-07-07 16:28:25,481 [run_pretraining.py:  451]:	worker_index: 1, step: 180, cost: 9.612730, mlm loss: 9.612730, speed: 1.836072 steps/s, speed: 14.688574 samples/s, speed: 7520.549987 tokens/s, learning rate: 1.790e-06, loss_scalings: 32768.000000, pp_loss: 9.555837
[INFO] 2021-07-07 16:28:26,614 [run_pretraining.py:  451]:	worker_index: 1, step: 181, cost: 9.223366, mlm loss: 9.223366, speed: 0.883097 steps/s, speed: 7.064777 samples/s, speed: 3617.165620 tokens/s, learning rate: 1.800e-06, loss_scalings: 32768.000000, pp_loss: 9.558704
[INFO] 2021-07-07 16:28:27,212 [run_pretraining.py:  451]:	worker_index: 1, step: 182, cost: 9.782535, mlm loss: 9.782535, speed: 1.783869 steps/s, speed: 14.270951 samples/s, speed: 7306.727167 tokens/s, learning rate: 1.810e-06, loss_scalings: 32768.000000, pp_loss: 9.362421
[INFO] 2021-07-07 16:28:27,768 [run_pretraining.py:  451]:	worker_index: 1, step: 183, cost: 9.557996, mlm loss: 9.557996, speed: 1.805691 steps/s, speed: 14.445527 samples/s, speed: 7396.109988 tokens/s, learning rate: 1.820e-06, loss_scalings: 32768.000000, pp_loss: 9.447083
[INFO] 2021-07-07 16:28:28,293 [run_pretraining.py:  451]:	worker_index: 1, step: 184, cost: 9.273859, mlm loss: 9.273859, speed: 1.911210 steps/s, speed: 15.289683 samples/s, speed: 7828.317575 tokens/s, learning rate: 1.830e-06, loss_scalings: 32768.000000, pp_loss: 9.370300
[INFO] 2021-07-07 16:28:28,868 [run_pretraining.py:  451]:	worker_index: 1, step: 185, cost: 9.686432, mlm loss: 9.686432, speed: 1.882578 steps/s, speed: 15.060621 samples/s, speed: 7711.038172 tokens/s, learning rate: 1.840e-06, loss_scalings: 32768.000000, pp_loss: 9.487157
[INFO] 2021-07-07 16:28:29,473 [run_pretraining.py:  451]:	worker_index: 1, step: 186, cost: 9.316577, mlm loss: 9.316577, speed: 1.748682 steps/s, speed: 13.989459 samples/s, speed: 7162.603248 tokens/s, learning rate: 1.850e-06, loss_scalings: 32768.000000, pp_loss: 9.280519
[INFO] 2021-07-07 16:28:30,151 [run_pretraining.py:  451]:	worker_index: 1, step: 187, cost: 9.511785, mlm loss: 9.511785, speed: 1.559114 steps/s, speed: 12.472909 samples/s, speed: 6386.129275 tokens/s, learning rate: 1.860e-06, loss_scalings: 32768.000000, pp_loss: 9.507361
[INFO] 2021-07-07 16:28:30,830 [run_pretraining.py:  451]:	worker_index: 1, step: 188, cost: 9.527109, mlm loss: 9.527109, speed: 1.473519 steps/s, speed: 11.788152 samples/s, speed: 6035.533750 tokens/s, learning rate: 1.870e-06, loss_scalings: 32768.000000, pp_loss: 9.310924
[INFO] 2021-07-07 16:28:31,512 [run_pretraining.py:  451]:	worker_index: 1, step: 189, cost: 9.414349, mlm loss: 9.414349, speed: 1.468682 steps/s, speed: 11.749454 samples/s, speed: 6015.720543 tokens/s, learning rate: 1.880e-06, loss_scalings: 32768.000000, pp_loss: 9.330168
[INFO] 2021-07-07 16:28:32,075 [run_pretraining.py:  451]:	worker_index: 1, step: 190, cost: 9.573089, mlm loss: 9.573089, speed: 1.887431 steps/s, speed: 15.099448 samples/s, speed: 7730.917554 tokens/s, learning rate: 1.890e-06, loss_scalings: 32768.000000, pp_loss: 9.307143
[INFO] 2021-07-07 16:28:33,312 [run_pretraining.py:  451]:	worker_index: 1, step: 191, cost: 9.188521, mlm loss: 9.188521, speed: 0.833057 steps/s, speed: 6.664454 samples/s, speed: 3412.200354 tokens/s, learning rate: 1.900e-06, loss_scalings: 32768.000000, pp_loss: 9.418052
[INFO] 2021-07-07 16:28:33,926 [run_pretraining.py:  451]:	worker_index: 1, step: 192, cost: 9.581409, mlm loss: 9.581409, speed: 1.721441 steps/s, speed: 13.771531 samples/s, speed: 7051.023939 tokens/s, learning rate: 1.910e-06, loss_scalings: 32768.000000, pp_loss: 9.411501
[INFO] 2021-07-07 16:28:34,602 [run_pretraining.py:  451]:	worker_index: 1, step: 193, cost: 9.149612, mlm loss: 9.149612, speed: 1.561303 steps/s, speed: 12.490422 samples/s, speed: 6395.096057 tokens/s, learning rate: 1.920e-06, loss_scalings: 32768.000000, pp_loss: 9.324656
[INFO] 2021-07-07 16:28:35,177 [run_pretraining.py:  451]:	worker_index: 1, step: 194, cost: 9.434497, mlm loss: 9.434497, speed: 1.749738 steps/s, speed: 13.997904 samples/s, speed: 7166.926918 tokens/s, learning rate: 1.930e-06, loss_scalings: 32768.000000, pp_loss: 9.411967
[INFO] 2021-07-07 16:28:36,453 [run_pretraining.py:  451]:	worker_index: 1, step: 195, cost: 9.533978, mlm loss: 9.533978, speed: 0.807682 steps/s, speed: 6.461459 samples/s, speed: 3308.266799 tokens/s, learning rate: 1.940e-06, loss_scalings: 32768.000000, pp_loss: 9.517153
[INFO] 2021-07-07 16:28:37,044 [run_pretraining.py:  451]:	worker_index: 1, step: 196, cost: 9.609241, mlm loss: 9.609241, speed: 1.697441 steps/s, speed: 13.579529 samples/s, speed: 6952.718798 tokens/s, learning rate: 1.950e-06, loss_scalings: 32768.000000, pp_loss: 9.416634
[INFO] 2021-07-07 16:28:37,750 [run_pretraining.py:  451]:	worker_index: 1, step: 197, cost: 9.611781, mlm loss: 9.611781, speed: 1.495557 steps/s, speed: 11.964459 samples/s, speed: 6125.802835 tokens/s, learning rate: 1.960e-06, loss_scalings: 32768.000000, pp_loss: 9.408237
[INFO] 2021-07-07 16:28:38,416 [run_pretraining.py:  451]:	worker_index: 1, step: 198, cost: 9.601028, mlm loss: 9.601028, speed: 1.502948 steps/s, speed: 12.023584 samples/s, speed: 6156.074954 tokens/s, learning rate: 1.970e-06, loss_scalings: 32768.000000, pp_loss: 9.397327
[INFO] 2021-07-07 16:28:39,111 [run_pretraining.py:  451]:	worker_index: 1, step: 199, cost: 8.995445, mlm loss: 8.995445, speed: 1.517693 steps/s, speed: 12.141544 samples/s, speed: 6216.470582 tokens/s, learning rate: 1.980e-06, loss_scalings: 32768.000000, pp_loss: 9.277862
[INFO] 2021-07-07 16:28:39,688 [run_pretraining.py:  451]:	worker_index: 1, step: 200, cost: 9.424404, mlm loss: 9.424404, speed: 1.736103 steps/s, speed: 13.888826 samples/s, speed: 7111.079040 tokens/s, learning rate: 1.990e-06, loss_scalings: 32768.000000, pp_loss: 9.189657
[DEBUG] 2021-07-07 16:28:39,726 [run_pretraining.py:  460]:	saving models to output/newest-pp-1f1b-fixed-bs8/step_200
[INFO] 2021-07-07 16:28:42,328 [run_pretraining.py:  451]:	worker_index: 1, step: 201, cost: 9.698608, mlm loss: 9.698608, speed: 0.384315 steps/s, speed: 3.074523 samples/s, speed: 1574.155828 tokens/s, learning rate: 2.000e-06, loss_scalings: 32768.000000, pp_loss: 9.359596
[INFO] 2021-07-07 16:28:42,887 [run_pretraining.py:  451]:	worker_index: 1, step: 202, cost: 9.303575, mlm loss: 9.303575, speed: 1.791999 steps/s, speed: 14.335990 samples/s, speed: 7340.027072 tokens/s, learning rate: 2.010e-06, loss_scalings: 32768.000000, pp_loss: 9.376426
[INFO] 2021-07-07 16:28:43,491 [run_pretraining.py:  451]:	worker_index: 1, step: 203, cost: 8.659598, mlm loss: 8.659598, speed: 1.766203 steps/s, speed: 14.129628 samples/s, speed: 7234.369320 tokens/s, learning rate: 2.020e-06, loss_scalings: 32768.000000, pp_loss: 9.418472
[INFO] 2021-07-07 16:28:44,661 [run_pretraining.py:  451]:	worker_index: 1, step: 204, cost: 9.162008, mlm loss: 9.162008, speed: 0.881594 steps/s, speed: 7.052753 samples/s, speed: 3611.009582 tokens/s, learning rate: 2.030e-06, loss_scalings: 32768.000000, pp_loss: 9.330046
[INFO] 2021-07-07 16:28:45,311 [run_pretraining.py:  451]:	worker_index: 1, step: 205, cost: 9.234265, mlm loss: 9.234265, speed: 1.624272 steps/s, speed: 12.994176 samples/s, speed: 6653.018136 tokens/s, learning rate: 2.040e-06, loss_scalings: 32768.000000, pp_loss: 9.256243
[INFO] 2021-07-07 16:28:46,038 [run_pretraining.py:  451]:	worker_index: 1, step: 206, cost: 9.326385, mlm loss: 9.326385, speed: 1.452068 steps/s, speed: 11.616547 samples/s, speed: 5947.672266 tokens/s, learning rate: 2.050e-06, loss_scalings: 32768.000000, pp_loss: 9.227860
[INFO] 2021-07-07 16:28:46,699 [run_pretraining.py:  451]:	worker_index: 1, step: 207, cost: 9.334909, mlm loss: 9.334909, speed: 1.515011 steps/s, speed: 12.120090 samples/s, speed: 6205.485931 tokens/s, learning rate: 2.060e-06, loss_scalings: 32768.000000, pp_loss: 9.200406
[INFO] 2021-07-07 16:28:47,351 [run_pretraining.py:  451]:	worker_index: 1, step: 208, cost: 9.437132, mlm loss: 9.437132, speed: 1.621446 steps/s, speed: 12.971566 samples/s, speed: 6641.441824 tokens/s, learning rate: 2.070e-06, loss_scalings: 32768.000000, pp_loss: 9.387624
[INFO] 2021-07-07 16:28:48,573 [run_pretraining.py:  451]:	worker_index: 1, step: 209, cost: 9.257128, mlm loss: 9.257128, speed: 0.843112 steps/s, speed: 6.744893 samples/s, speed: 3453.385114 tokens/s, learning rate: 2.080e-06, loss_scalings: 32768.000000, pp_loss: 9.270570
[INFO] 2021-07-07 16:28:49,265 [run_pretraining.py:  451]:	worker_index: 1, step: 210, cost: 9.043571, mlm loss: 9.043571, speed: 1.449363 steps/s, speed: 11.594903 samples/s, speed: 5936.590368 tokens/s, learning rate: 2.090e-06, loss_scalings: 32768.000000, pp_loss: 9.389557
[INFO] 2021-07-07 16:28:49,860 [run_pretraining.py:  451]:	worker_index: 1, step: 211, cost: 9.478121, mlm loss: 9.478121, speed: 1.684429 steps/s, speed: 13.475432 samples/s, speed: 6899.421169 tokens/s, learning rate: 2.100e-06, loss_scalings: 32768.000000, pp_loss: 9.223249
[INFO] 2021-07-07 16:28:50,562 [run_pretraining.py:  451]:	worker_index: 1, step: 212, cost: 9.194025, mlm loss: 9.194025, speed: 1.426687 steps/s, speed: 11.413495 samples/s, speed: 5843.709574 tokens/s, learning rate: 2.110e-06, loss_scalings: 32768.000000, pp_loss: 9.338168
[INFO] 2021-07-07 16:28:51,216 [run_pretraining.py:  451]:	worker_index: 1, step: 213, cost: 9.284001, mlm loss: 9.284001, speed: 1.530845 steps/s, speed: 12.246760 samples/s, speed: 6270.341055 tokens/s, learning rate: 2.120e-06, loss_scalings: 32768.000000, pp_loss: 9.289742
[INFO] 2021-07-07 16:28:51,919 [run_pretraining.py:  451]:	worker_index: 1, step: 214, cost: 9.465179, mlm loss: 9.465179, speed: 1.424898 steps/s, speed: 11.399184 samples/s, speed: 5836.382062 tokens/s, learning rate: 2.130e-06, loss_scalings: 32768.000000, pp_loss: 9.303461
[INFO] 2021-07-07 16:28:52,658 [run_pretraining.py:  451]:	worker_index: 1, step: 215, cost: 9.265070, mlm loss: 9.265070, speed: 1.424211 steps/s, speed: 11.393691 samples/s, speed: 5833.569898 tokens/s, learning rate: 2.140e-06, loss_scalings: 32768.000000, pp_loss: 9.179285
[INFO] 2021-07-07 16:28:53,338 [run_pretraining.py:  451]:	worker_index: 1, step: 216, cost: 8.923505, mlm loss: 8.923505, speed: 1.472801 steps/s, speed: 11.782406 samples/s, speed: 6032.592112 tokens/s, learning rate: 2.150e-06, loss_scalings: 32768.000000, pp_loss: 9.130111
[INFO] 2021-07-07 16:28:53,963 [run_pretraining.py:  451]:	worker_index: 1, step: 217, cost: 9.550068, mlm loss: 9.550068, speed: 1.600014 steps/s, speed: 12.800112 samples/s, speed: 6553.657501 tokens/s, learning rate: 2.160e-06, loss_scalings: 32768.000000, pp_loss: 9.193142
[INFO] 2021-07-07 16:28:55,169 [run_pretraining.py:  451]:	worker_index: 1, step: 218, cost: 9.671376, mlm loss: 9.671376, speed: 0.854860 steps/s, speed: 6.838877 samples/s, speed: 3501.505207 tokens/s, learning rate: 2.170e-06, loss_scalings: 32768.000000, pp_loss: 9.342492
[INFO] 2021-07-07 16:28:55,769 [run_pretraining.py:  451]:	worker_index: 1, step: 219, cost: 9.173221, mlm loss: 9.173221, speed: 1.670006 steps/s, speed: 13.360044 samples/s, speed: 6840.342555 tokens/s, learning rate: 2.180e-06, loss_scalings: 32768.000000, pp_loss: 9.259094
[INFO] 2021-07-07 16:28:56,338 [run_pretraining.py:  451]:	worker_index: 1, step: 220, cost: 9.877358, mlm loss: 9.877358, speed: 1.759586 steps/s, speed: 14.076688 samples/s, speed: 7207.264199 tokens/s, learning rate: 2.190e-06, loss_scalings: 32768.000000, pp_loss: 9.410871
[INFO] 2021-07-07 16:28:56,944 [run_pretraining.py:  451]:	worker_index: 1, step: 221, cost: 9.341354, mlm loss: 9.341354, speed: 1.761106 steps/s, speed: 14.088852 samples/s, speed: 7213.492097 tokens/s, learning rate: 2.200e-06, loss_scalings: 32768.000000, pp_loss: 9.274388
[INFO] 2021-07-07 16:28:57,664 [run_pretraining.py:  451]:	worker_index: 1, step: 222, cost: 9.340608, mlm loss: 9.340608, speed: 1.457267 steps/s, speed: 11.658135 samples/s, speed: 5968.965031 tokens/s, learning rate: 2.210e-06, loss_scalings: 32768.000000, pp_loss: 9.327379
[INFO] 2021-07-07 16:28:58,880 [run_pretraining.py:  451]:	worker_index: 1, step: 223, cost: 9.014510, mlm loss: 9.014510, speed: 0.822494 steps/s, speed: 6.579956 samples/s, speed: 3368.937373 tokens/s, learning rate: 2.220e-06, loss_scalings: 32768.000000, pp_loss: 9.211333
[INFO] 2021-07-07 16:28:59,570 [run_pretraining.py:  451]:	worker_index: 1, step: 224, cost: 9.266650, mlm loss: 9.266650, speed: 1.535506 steps/s, speed: 12.284044 samples/s, speed: 6289.430668 tokens/s, learning rate: 2.230e-06, loss_scalings: 32768.000000, pp_loss: 9.179101
[INFO] 2021-07-07 16:29:00,178 [run_pretraining.py:  451]:	worker_index: 1, step: 225, cost: 9.485035, mlm loss: 9.485035, speed: 1.744687 steps/s, speed: 13.957495 samples/s, speed: 7146.237417 tokens/s, learning rate: 2.240e-06, loss_scalings: 32768.000000, pp_loss: 9.400293
[INFO] 2021-07-07 16:29:00,926 [run_pretraining.py:  451]:	worker_index: 1, step: 226, cost: 9.052126, mlm loss: 9.052126, speed: 1.406137 steps/s, speed: 11.249099 samples/s, speed: 5759.538826 tokens/s, learning rate: 2.250e-06, loss_scalings: 32768.000000, pp_loss: 9.158196
[INFO] 2021-07-07 16:29:01,528 [run_pretraining.py:  451]:	worker_index: 1, step: 227, cost: 8.709544, mlm loss: 8.709544, speed: 1.756658 steps/s, speed: 14.053265 samples/s, speed: 7195.271516 tokens/s, learning rate: 2.260e-06, loss_scalings: 32768.000000, pp_loss: 9.135420
[INFO] 2021-07-07 16:29:02,311 [run_pretraining.py:  451]:	worker_index: 1, step: 228, cost: 9.113323, mlm loss: 9.113323, speed: 1.333833 steps/s, speed: 10.670663 samples/s, speed: 5463.379238 tokens/s, learning rate: 2.270e-06, loss_scalings: 32768.000000, pp_loss: 9.240856
[INFO] 2021-07-07 16:29:03,007 [run_pretraining.py:  451]:	worker_index: 1, step: 229, cost: 9.196644, mlm loss: 9.196644, speed: 1.438953 steps/s, speed: 11.511626 samples/s, speed: 5893.952369 tokens/s, learning rate: 2.280e-06, loss_scalings: 32768.000000, pp_loss: 9.188391
[INFO] 2021-07-07 16:29:03,647 [run_pretraining.py:  451]:	worker_index: 1, step: 230, cost: 9.403773, mlm loss: 9.403773, speed: 1.564461 steps/s, speed: 12.515692 samples/s, speed: 6408.034193 tokens/s, learning rate: 2.290e-06, loss_scalings: 32768.000000, pp_loss: 9.295348
[INFO] 2021-07-07 16:29:04,295 [run_pretraining.py:  451]:	worker_index: 1, step: 231, cost: 9.219946, mlm loss: 9.219946, speed: 1.623685 steps/s, speed: 12.989478 samples/s, speed: 6650.612625 tokens/s, learning rate: 2.300e-06, loss_scalings: 32768.000000, pp_loss: 9.132279
[INFO] 2021-07-07 16:29:05,435 [run_pretraining.py:  451]:	worker_index: 1, step: 232, cost: 8.612386, mlm loss: 8.612386, speed: 0.877353 steps/s, speed: 7.018820 samples/s, speed: 3593.635991 tokens/s, learning rate: 2.310e-06, loss_scalings: 32768.000000, pp_loss: 9.075368
[INFO] 2021-07-07 16:29:06,033 [run_pretraining.py:  451]:	worker_index: 1, step: 233, cost: 9.471094, mlm loss: 9.471094, speed: 1.771735 steps/s, speed: 14.173878 samples/s, speed: 7257.025781 tokens/s, learning rate: 2.320e-06, loss_scalings: 32768.000000, pp_loss: 9.252395
[INFO] 2021-07-07 16:29:06,562 [run_pretraining.py:  451]:	worker_index: 1, step: 234, cost: 9.184536, mlm loss: 9.184536, speed: 1.892082 steps/s, speed: 15.136653 samples/s, speed: 7749.966137 tokens/s, learning rate: 2.330e-06, loss_scalings: 32768.000000, pp_loss: 9.217743
[INFO] 2021-07-07 16:29:07,157 [run_pretraining.py:  451]:	worker_index: 1, step: 235, cost: 8.900475, mlm loss: 8.900475, speed: 1.797410 steps/s, speed: 14.379284 samples/s, speed: 7362.193172 tokens/s, learning rate: 2.340e-06, loss_scalings: 32768.000000, pp_loss: 9.053164
[INFO] 2021-07-07 16:29:07,754 [run_pretraining.py:  451]:	worker_index: 1, step: 236, cost: 9.014117, mlm loss: 9.014117, speed: 1.676699 steps/s, speed: 13.413596 samples/s, speed: 6867.761086 tokens/s, learning rate: 2.350e-06, loss_scalings: 32768.000000, pp_loss: 9.052682
[INFO] 2021-07-07 16:29:09,051 [run_pretraining.py:  451]:	worker_index: 1, step: 237, cost: 8.817899, mlm loss: 8.817899, speed: 0.792535 steps/s, speed: 6.340279 samples/s, speed: 3246.223012 tokens/s, learning rate: 2.360e-06, loss_scalings: 32768.000000, pp_loss: 9.183472
[INFO] 2021-07-07 16:29:09,740 [run_pretraining.py:  451]:	worker_index: 1, step: 238, cost: 8.806788, mlm loss: 8.806788, speed: 1.478843 steps/s, speed: 11.830746 samples/s, speed: 6057.341809 tokens/s, learning rate: 2.370e-06, loss_scalings: 32768.000000, pp_loss: 9.130607
[INFO] 2021-07-07 16:29:10,475 [run_pretraining.py:  451]:	worker_index: 1, step: 239, cost: 8.750102, mlm loss: 8.750102, speed: 1.364381 steps/s, speed: 10.915049 samples/s, speed: 5588.505023 tokens/s, learning rate: 2.380e-06, loss_scalings: 32768.000000, pp_loss: 9.042525
[INFO] 2021-07-07 16:29:11,141 [run_pretraining.py:  451]:	worker_index: 1, step: 240, cost: 8.837186, mlm loss: 8.837186, speed: 1.504573 steps/s, speed: 12.036584 samples/s, speed: 6162.730758 tokens/s, learning rate: 2.390e-06, loss_scalings: 32768.000000, pp_loss: 9.046691
[INFO] 2021-07-07 16:29:11,780 [run_pretraining.py:  451]:	worker_index: 1, step: 241, cost: 9.090276, mlm loss: 9.090276, speed: 1.566965 steps/s, speed: 12.535718 samples/s, speed: 6418.287695 tokens/s, learning rate: 2.400e-06, loss_scalings: 32768.000000, pp_loss: 9.039456
[INFO] 2021-07-07 16:29:12,394 [run_pretraining.py:  451]:	worker_index: 1, step: 242, cost: 9.160025, mlm loss: 9.160025, speed: 1.725865 steps/s, speed: 13.806920 samples/s, speed: 7069.142827 tokens/s, learning rate: 2.410e-06, loss_scalings: 32768.000000, pp_loss: 9.073666
[INFO] 2021-07-07 16:29:12,991 [run_pretraining.py:  451]:	worker_index: 1, step: 243, cost: 9.227192, mlm loss: 9.227192, speed: 1.776810 steps/s, speed: 14.214480 samples/s, speed: 7277.813887 tokens/s, learning rate: 2.420e-06, loss_scalings: 32768.000000, pp_loss: 9.247984
[INFO] 2021-07-07 16:29:13,581 [run_pretraining.py:  451]:	worker_index: 1, step: 244, cost: 9.037080, mlm loss: 9.037080, speed: 1.806849 steps/s, speed: 14.454793 samples/s, speed: 7400.854156 tokens/s, learning rate: 2.430e-06, loss_scalings: 32768.000000, pp_loss: 9.343854
[INFO] 2021-07-07 16:29:14,140 [run_pretraining.py:  451]:	worker_index: 1, step: 245, cost: 9.404144, mlm loss: 9.404144, speed: 1.789203 steps/s, speed: 14.313626 samples/s, speed: 7328.576626 tokens/s, learning rate: 2.440e-06, loss_scalings: 32768.000000, pp_loss: 9.234879
[INFO] 2021-07-07 16:29:15,284 [run_pretraining.py:  451]:	worker_index: 1, step: 246, cost: 8.897221, mlm loss: 8.897221, speed: 0.875813 steps/s, speed: 7.006502 samples/s, speed: 3587.328986 tokens/s, learning rate: 2.450e-06, loss_scalings: 32768.000000, pp_loss: 9.219109
[INFO] 2021-07-07 16:29:15,895 [run_pretraining.py:  451]:	worker_index: 1, step: 247, cost: 8.961586, mlm loss: 8.961586, speed: 1.735800 steps/s, speed: 13.886401 samples/s, speed: 7109.837136 tokens/s, learning rate: 2.460e-06, loss_scalings: 32768.000000, pp_loss: 9.267138
[INFO] 2021-07-07 16:29:16,444 [run_pretraining.py:  451]:	worker_index: 1, step: 248, cost: 9.356332, mlm loss: 9.356332, speed: 1.948487 steps/s, speed: 15.587898 samples/s, speed: 7981.003944 tokens/s, learning rate: 2.470e-06, loss_scalings: 32768.000000, pp_loss: 9.266427
[INFO] 2021-07-07 16:29:16,990 [run_pretraining.py:  451]:	worker_index: 1, step: 249, cost: 9.140305, mlm loss: 9.140305, speed: 1.958167 steps/s, speed: 15.665337 samples/s, speed: 8020.652724 tokens/s, learning rate: 2.480e-06, loss_scalings: 32768.000000, pp_loss: 9.044563
[INFO] 2021-07-07 16:29:17,724 [run_pretraining.py:  451]:	worker_index: 1, step: 250, cost: 8.879316, mlm loss: 8.879316, speed: 1.426503 steps/s, speed: 11.412020 samples/s, speed: 5842.954334 tokens/s, learning rate: 2.490e-06, loss_scalings: 32768.000000, pp_loss: 9.115604
[DEBUG] 2021-07-07 16:29:18,814 [run_pretraining.py:  468]:	saving final models to output/newest-pp-1f1b-fixed-bs8/final_step_250
[DEBUG] 2021-07-07 16:29:18,815 [run_pretraining.py:  469]:	end of training, total steps: 250
I0707 16:29:19.441308 43622 reader.h:164] ~ReaderHolder
I0707 16:29:19.441496 43622 reader.h:164] ~ReaderHolder
I0707 16:29:19.441504 43622 buffered_reader.cc:22] ~BufferedReader
I0707 16:29:19.441514 43622 lod_tensor_blocking_queue.h:59] LoDTensorBlockingQueue close
I0707 16:29:19.441519 43622 blocking_queue.h:132] close queue
I0707 16:29:19.441687 43622 reader.cc:76] ~DecoratedReader
I0707 16:29:19.441694 43622 lod_tensor_blocking_queue.h:59] LoDTensorBlockingQueue close
I0707 16:29:19.441697 43622 blocking_queue.h:132] close queue
I0707 16:29:19.441701 43622 lod_tensor_blocking_queue.h:59] LoDTensorBlockingQueue close
I0707 16:29:19.441704 43622 blocking_queue.h:132] close queue
terminate called without an active exception


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::framework::SignalHandle(char const*, int)
1   paddle::platform::GetCurrentTraceBackString[abi:cxx11]()

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1625646559 (unix time) try "date -d @1625646559" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xaa66) received by PID 43622 (TID 0x7f54da829700) from PID 43622 ***]

