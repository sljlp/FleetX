/home/gongwb/.local/lib/python3.7/site-packages/setuptools/depends.py:2: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0712 16:56:03.228435 48407 init.cc:88] Before Parse: argc is 2, Init commandline: dummy --tryfromenv=check_nan_inf,benchmark,eager_delete_scope,fraction_of_cpu_memory_to_use,initial_cpu_memory_in_mb,init_allocated_mem,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_system_allocator,enable_unused_var_check,free_idle_chunk,free_when_no_cache_hit,call_stack_level,sort_sum_gradient,max_inplace_grad_add,use_pinned_memory,cpu_deterministic,selected_npus,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,gpu_memory_limit_mb 
I0712 16:56:03.228633 48407 init.cc:95] After Parse: argc is 1
-----------  Configuration Arguments -----------
data_dir: ./data
debug: False
do_eval: True
epoch: 100
ernie_config_file: config/ernie_base_config.json
eval_batch_size: 35
eval_data_path: ./data
eval_steps: -1
global_bsz: 8
global_steps: 0
grad_merge: 0
init_checkpoint: 
learning_rate: 0.0001
log_steps: 1
max_seq_len: 512
micro_bsz: 1
num_dp: 2
num_mp: 2
num_pp: 2
num_sharding: 1
num_train_steps: 3000
output_dir: output/step3000-3p-bs8-npu
preln: False
save_steps: 4000
seed: 2021
use_amp: True
use_hybrid_dp: True
use_lamb: False
use_offload: False
use_recompute: True
use_sharding: True
vocab_file: ./config/30k-clean.vocab.albert
warmup_steps: 10000
weight_decay: 0.01
------------------------------------------------
to run startup
[INFO] 2021-07-12 16:56:04,170 [run_pretraining.py:  216]:	pretraining start
[INFO] 2021-07-12 16:56:04,171 [run_pretraining.py:  234]:	using recompute.
[INFO] 2021-07-12 16:56:04,171 [run_pretraining.py:  279]:	using globa_bsz: 8 micro_bsz: 1, acc_steps: 4
[DEBUG] 2021-07-12 16:56:04,235 [run_pretraining.py:  118]:	========= dp_sharding worker: 1 of 2 ==========
[INFO] 2021-07-12 16:56:04,235 [pretraining_ds_mlm.py:  289]:	Apply sharding in distribution env 1/2
[INFO] 2021-07-12 16:56:04,235 [pretraining_ds_mlm.py:  291]:	read from ./data/part-00000.100,./data/part-00000.103,./data/part-00000.105,./data/part-00000.102,./data/part-00000.109
I0712 16:56:04.235852 48407 reader_py.cc:387] init_lod_tensor_blocking_queue
INFO:root:places would be ommited when DataLoader is not iterable
/home/liupeng51/github/Paddle/build/build_ubuntu_develop_release_ascend_y_none_3.7.5/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /home/liupeng51/github/FleetX/examples/hybrid_parallelism/model/ernie.py:158
The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
/home/liupeng51/github/Paddle/build/build_ubuntu_develop_release_ascend_y_none_3.7.5/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /home/liupeng51/github/FleetX/examples/hybrid_parallelism/model/ernie.py:159
The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
/home/liupeng51/github/Paddle/build/build_ubuntu_develop_release_ascend_y_none_3.7.5/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /home/liupeng51/github/FleetX/examples/hybrid_parallelism/model/transformer_encoder.py:170
The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
/home/liupeng51/github/Paddle/build/build_ubuntu_develop_release_ascend_y_none_3.7.5/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /home/liupeng51/github/FleetX/examples/hybrid_parallelism/model/transformer_encoder.py:280
The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
/home/liupeng51/github/Paddle/build/build_ubuntu_develop_release_ascend_y_none_3.7.5/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /home/liupeng51/github/FleetX/examples/hybrid_parallelism/model/transformer_encoder.py:43
The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
/home/liupeng51/github/Paddle/build/build_ubuntu_develop_release_ascend_y_none_3.7.5/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /home/liupeng51/github/FleetX/examples/hybrid_parallelism/model/transformer_encoder.py:44
The behavior of expression A * B has been unified with elementwise_mul(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_mul(X, Y, axis=0) instead of A * B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
[DEBUG] 2021-07-12 16:56:05,045 [run_pretraining.py:  315]:	base lr: 0.0001
/home/liupeng51/github/Paddle/build/build_ubuntu_develop_release_ascend_y_none_3.7.5/python/paddle/distributed/fleet/base/fleet_base.py:818: UserWarning: It is recommended to use DistributedStrategy in fleet.init(). The strategy here is only for compatibility. If the strategy in fleet.distributed_optimizer() is not None, then it will overwrite the DistributedStrategy in fleet.init(), which will take effect in distributed training.
  "It is recommended to use DistributedStrategy "
2021-07-12 16:56:05 INFO     Gradient merge in [pp_gm], acc step = [4]
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:Gradient merge in [pp_gm], acc step = [4]
Mon Jul 12 16:56:05-INFO: recompute segment[0]
Mon Jul 12 16:56:05-INFO: segment start op: [squeeze2]: [['shard_index_0.tmp_0']]
Mon Jul 12 16:56:05-INFO: segment end op: [layer_norm]: [['encoder_layer_0_post_ffn_layer_norm_bias', 'encoder_layer_0_post_ffn_layer_norm_scale', 'tmp_10']]
Mon Jul 12 16:56:05-INFO: recompute segment[0]
Mon Jul 12 16:56:05-INFO: segment start op: [squeeze2]: [['shard_index_0.tmp_0']]
Mon Jul 12 16:56:05-INFO: segment end op: [layer_norm]: [['encoder_layer_0_post_ffn_layer_norm_bias', 'encoder_layer_0_post_ffn_layer_norm_scale', 'tmp_10']]
Mon Jul 12 16:56:05-INFO: found [0] vars which cross recompute segment: [set()], better checkpoints might be set to reduce those vars
pp_rank: 1
2021-07-12 16:56:10 INFO     Hybrid DP mode turn on !
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:Hybrid DP mode turn on !
2021-07-12 16:56:10 INFO     global word size: 8
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:global word size: 8
2021-07-12 16:56:10 INFO     global rank: 6
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:global rank: 6
2021-07-12 16:56:10 INFO     global endpoints: ['192.168.206.27:6170', '192.168.206.27:6171', '192.168.206.27:6172', '192.168.206.27:6173', '192.168.206.27:6174', '192.168.206.27:6175', '192.168.206.27:6176', '192.168.206.27:6177']
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:global endpoints: ['192.168.206.27:6170', '192.168.206.27:6171', '192.168.206.27:6172', '192.168.206.27:6173', '192.168.206.27:6174', '192.168.206.27:6175', '192.168.206.27:6176', '192.168.206.27:6177']
2021-07-12 16:56:10 INFO     global ring id: 3
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:global ring id: 3
2021-07-12 16:56:10 INFO     ##############################
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:##############################
2021-07-12 16:56:10 INFO     mp group size: 2
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:mp group size: 2
2021-07-12 16:56:10 INFO     mp rank: 0
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:mp rank: 0
2021-07-12 16:56:10 INFO     mp group id: 3
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:mp group id: 3
2021-07-12 16:56:10 INFO     mp group endpoints: ['192.168.206.27:6176', '192.168.206.27:6177']
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:mp group endpoints: ['192.168.206.27:6176', '192.168.206.27:6177']
2021-07-12 16:56:10 INFO     mp ring id: 0
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:mp ring id: 0
2021-07-12 16:56:10 INFO     ##############################
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:##############################
2021-07-12 16:56:10 INFO     sharding group size: 1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:sharding group size: 1
2021-07-12 16:56:10 INFO     sharding rank: -1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:sharding rank: -1
2021-07-12 16:56:10 INFO     sharding group id: -1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:sharding group id: -1
2021-07-12 16:56:10 INFO     sharding group endpoints: []
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:sharding group endpoints: []
2021-07-12 16:56:10 INFO     sharding ring id: -1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:sharding ring id: -1
2021-07-12 16:56:10 INFO     ##############################
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:##############################
2021-07-12 16:56:10 INFO     pp group size: 2
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pp group size: 2
2021-07-12 16:56:10 INFO     pp rank: 1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pp rank: 1
2021-07-12 16:56:10 INFO     pp group id: 1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pp group id: 1
2021-07-12 16:56:10 INFO     pp group endpoints: ['192.168.206.27:6174', '192.168.206.27:6176']
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pp group endpoints: ['192.168.206.27:6174', '192.168.206.27:6176']
2021-07-12 16:56:10 INFO     pp ring id: 20
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pp ring id: 20
2021-07-12 16:56:10 INFO     ##############################
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:##############################
2021-07-12 16:56:10 INFO     pure dp group size: 2
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pure dp group size: 2
2021-07-12 16:56:10 INFO     pure dp rank: 1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pure dp rank: 1
2021-07-12 16:56:10 INFO     pure dp group endpoints: ['192.168.206.27:6172', '192.168.206.27:6176']
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pure dp group endpoints: ['192.168.206.27:6172', '192.168.206.27:6176']
2021-07-12 16:56:10 INFO     pure dp ring id: 2
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pure dp ring id: 2
2021-07-12 16:56:10 INFO     ##############################
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:##############################
pp pair:(0, 1), ring_id: 20
pp pair:(1, 0), ring_id: 21
I0712 16:56:30.858134 48407 gen_hccl_id_op_helper.cc:181] Server listening on: 192.168.206.27:6176 successful.
I0712 16:56:31.352216 48407 collective_helper_npu.cc:83] initialized comm: 0xffffd3834ef0, nranks: 8, hccl_id: 0x3c6f9034, rank: 6
I0712 16:56:34.819380 48407 collective_helper_npu.cc:88] initialized comm: 0xffffd3834ef0, nranks: 8, hccl_id: 0x3c6f9034, rank: 6
I0712 16:56:34.819664 48407 collective_helper_npu.cc:93] hccl communicator of rank 6 in ring 3 has been created on device 6, with comm: 0x3c842700
I0712 16:56:36.120965 48407 collective_helper_npu.cc:83] initialized comm: 0xffffd3834ef0, nranks: 2, hccl_id: 0x3c77b034, rank: 0
I0712 16:56:37.347616 48407 collective_helper_npu.cc:88] initialized comm: 0xffffd3834ef0, nranks: 2, hccl_id: 0x3c77b034, rank: 0
I0712 16:56:37.350750 48407 collective_helper_npu.cc:93] hccl communicator of rank 0 in ring 0 has been created on device 6, with comm: 0x3c5ceda0
I0712 16:56:37.670351 48407 gen_hccl_id_op_helper.cc:181] Server listening on: 192.168.206.27:6176 successful.
I0712 16:56:37.671144 48407 collective_helper_npu.cc:83] initialized comm: 0xffffd3834ef0, nranks: 2, hccl_id: 0x3c785a24, rank: 1
I0712 16:56:38.885092 48407 collective_helper_npu.cc:88] initialized comm: 0xffffd3834ef0, nranks: 2, hccl_id: 0x3c785a24, rank: 1
I0712 16:56:38.885264 48407 collective_helper_npu.cc:93] hccl communicator of rank 1 in ring 20 has been created on device 6, with comm: 0x3c580a40
W0712 16:56:39.227864 48407 gen_hccl_id_op_helper.cc:120] connect addr=192.168.206.27:6174 failed 1 times with reason: Connection refused retry after 0.5 seconds
I0712 16:56:39.728677 48407 collective_helper_npu.cc:83] initialized comm: 0xffffd3834ef0, nranks: 2, hccl_id: 0x3c786a54, rank: 0
I0712 16:56:40.943624 48407 collective_helper_npu.cc:88] initialized comm: 0xffffd3834ef0, nranks: 2, hccl_id: 0x3c786a54, rank: 0
I0712 16:56:40.944022 48407 collective_helper_npu.cc:93] hccl communicator of rank 0 in ring 21 has been created on device 6, with comm: 0x3c7ce570
I0712 16:56:41.225286 48407 gen_hccl_id_op_helper.cc:181] Server listening on: 192.168.206.27:6176 successful.
I0712 16:56:41.484364 48407 collective_helper_npu.cc:83] initialized comm: 0xffffd3834ef0, nranks: 2, hccl_id: 0x3c78d404, rank: 1
I0712 16:56:42.701654 48407 collective_helper_npu.cc:88] initialized comm: 0xffffd3834ef0, nranks: 2, hccl_id: 0x3c78d404, rank: 1
I0712 16:56:42.701833 48407 collective_helper_npu.cc:93] hccl communicator of rank 1 in ring 2 has been created on device 6, with comm: 0x3c6a9510
Done broadcast
[INFO] 2021-07-12 16:56:43,035 [run_pretraining.py:  512]:	********exe.run_0******* 
I0712 16:56:45.791301 51981 lod_tensor_blocking_queue.h:104] Init queue with size 1
I0712 16:56:45.791514 51981 buffered_reader.cc:41] BufferedReader
[INFO] 2021-07-12 17:00:10,137 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:00:10,139 [run_pretraining.py:  534]:	loss/total_loss, 10.430290222167969, 1
[INFO] 2021-07-12 17:00:10,139 [run_pretraining.py:  535]:	loss/mlm_loss, 10.430290222167969, 1
[INFO] 2021-07-12 17:00:10,139 [run_pretraining.py:  536]:	lr/scheduled_lr, 0.0, 1
[INFO] 2021-07-12 17:00:10,139 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 1
[INFO] 2021-07-12 17:00:10,139 [run_pretraining.py:  558]:	worker_index: 6, step: 1, cost: 10.430290, mlm loss: 10.430290, speed: 0.004828 steps/s, speed: 0.038628 samples/s, speed: 19.777410 tokens/s, learning rate: 0.000e+00, loss_scalings: 32768.000000, pp_loss: 10.388388
[INFO] 2021-07-12 17:00:10,139 [run_pretraining.py:  512]:	********exe.run_1******* 
[INFO] 2021-07-12 17:01:50,850 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:01:50,852 [run_pretraining.py:  534]:	loss/total_loss, 10.365936279296875, 2
[INFO] 2021-07-12 17:01:50,852 [run_pretraining.py:  535]:	loss/mlm_loss, 10.365936279296875, 2
[INFO] 2021-07-12 17:01:50,852 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.99999905104687e-09, 2
[INFO] 2021-07-12 17:01:50,852 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 2
[INFO] 2021-07-12 17:01:50,852 [run_pretraining.py:  558]:	worker_index: 6, step: 2, cost: 10.365936, mlm loss: 10.365936, speed: 0.009929 steps/s, speed: 0.079434 samples/s, speed: 40.670386 tokens/s, learning rate: 1.000e-08, loss_scalings: 32768.000000, pp_loss: 10.365381
[INFO] 2021-07-12 17:01:50,852 [run_pretraining.py:  512]:	********exe.run_2******* 
[INFO] 2021-07-12 17:03:30,509 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:03:30,510 [run_pretraining.py:  534]:	loss/total_loss, 10.408519744873047, 3
[INFO] 2021-07-12 17:03:30,510 [run_pretraining.py:  535]:	loss/mlm_loss, 10.408519744873047, 3
[INFO] 2021-07-12 17:03:30,510 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.999999810209374e-08, 3
[INFO] 2021-07-12 17:03:30,510 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 3
[INFO] 2021-07-12 17:03:30,511 [run_pretraining.py:  558]:	worker_index: 6, step: 3, cost: 10.408520, mlm loss: 10.408520, speed: 0.010034 steps/s, speed: 0.080275 samples/s, speed: 41.100732 tokens/s, learning rate: 2.000e-08, loss_scalings: 32768.000000, pp_loss: 9.527796
[INFO] 2021-07-12 17:03:30,511 [run_pretraining.py:  512]:	********exe.run_3******* 
[INFO] 2021-07-12 17:05:10,848 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:05:10,849 [run_pretraining.py:  534]:	loss/total_loss, 10.484134674072266, 4
[INFO] 2021-07-12 17:05:10,849 [run_pretraining.py:  535]:	loss/mlm_loss, 10.484134674072266, 4
[INFO] 2021-07-12 17:05:10,849 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.999999892949745e-08, 4
[INFO] 2021-07-12 17:05:10,849 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 4
[INFO] 2021-07-12 17:05:10,849 [run_pretraining.py:  558]:	worker_index: 6, step: 4, cost: 10.484135, mlm loss: 10.484135, speed: 0.009966 steps/s, speed: 0.079730 samples/s, speed: 40.822001 tokens/s, learning rate: 3.000e-08, loss_scalings: 32768.000000, pp_loss: 10.441919
[INFO] 2021-07-12 17:05:10,850 [run_pretraining.py:  512]:	********exe.run_4******* 
[INFO] 2021-07-12 17:06:52,489 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:06:52,490 [run_pretraining.py:  534]:	loss/total_loss, 10.454849243164062, 5
[INFO] 2021-07-12 17:06:52,490 [run_pretraining.py:  535]:	loss/mlm_loss, 10.454849243164062, 5
[INFO] 2021-07-12 17:06:52,490 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.999999620418748e-08, 5
[INFO] 2021-07-12 17:06:52,490 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 5
[INFO] 2021-07-12 17:06:52,490 [run_pretraining.py:  558]:	worker_index: 6, step: 5, cost: 10.454849, mlm loss: 10.454849, speed: 0.009839 steps/s, speed: 0.078709 samples/s, speed: 40.299160 tokens/s, learning rate: 4.000e-08, loss_scalings: 26214.400391, pp_loss: 10.458828
[INFO] 2021-07-12 17:06:52,490 [run_pretraining.py:  512]:	********exe.run_5******* 
[INFO] 2021-07-12 17:08:33,469 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:08:33,470 [run_pretraining.py:  534]:	loss/total_loss, 10.337913513183594, 6
[INFO] 2021-07-12 17:08:33,470 [run_pretraining.py:  535]:	loss/mlm_loss, 10.337913513183594, 6
[INFO] 2021-07-12 17:08:33,470 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.000000058430487e-08, 6
[INFO] 2021-07-12 17:08:33,470 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 6
[INFO] 2021-07-12 17:08:33,470 [run_pretraining.py:  558]:	worker_index: 6, step: 6, cost: 10.337914, mlm loss: 10.337914, speed: 0.009903 steps/s, speed: 0.079224 samples/s, speed: 40.562716 tokens/s, learning rate: 5.000e-08, loss_scalings: 26214.400391, pp_loss: 10.409094
[INFO] 2021-07-12 17:08:33,471 [run_pretraining.py:  512]:	********exe.run_6******* 
[INFO] 2021-07-12 17:10:13,728 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:10:13,728 [run_pretraining.py:  534]:	loss/total_loss, 10.406415939331055, 7
[INFO] 2021-07-12 17:10:13,729 [run_pretraining.py:  535]:	loss/mlm_loss, 10.406415939331055, 7
[INFO] 2021-07-12 17:10:13,729 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.99999978589949e-08, 7
[INFO] 2021-07-12 17:10:13,729 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 7
[INFO] 2021-07-12 17:10:13,729 [run_pretraining.py:  558]:	worker_index: 6, step: 7, cost: 10.406416, mlm loss: 10.406416, speed: 0.009974 steps/s, speed: 0.079794 samples/s, speed: 40.854741 tokens/s, learning rate: 6.000e-08, loss_scalings: 26214.400391, pp_loss: 10.401293
[INFO] 2021-07-12 17:10:13,729 [run_pretraining.py:  512]:	********exe.run_7******* 
[INFO] 2021-07-12 17:11:53,670 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:11:53,671 [run_pretraining.py:  534]:	loss/total_loss, 10.23565673828125, 8
[INFO] 2021-07-12 17:11:53,671 [run_pretraining.py:  535]:	loss/mlm_loss, 10.23565673828125, 8
[INFO] 2021-07-12 17:11:53,671 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.999999868639861e-08, 8
[INFO] 2021-07-12 17:11:53,671 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 8
[INFO] 2021-07-12 17:11:53,671 [run_pretraining.py:  558]:	worker_index: 6, step: 8, cost: 10.235657, mlm loss: 10.235657, speed: 0.010006 steps/s, speed: 0.080047 samples/s, speed: 40.983968 tokens/s, learning rate: 7.000e-08, loss_scalings: 26214.400391, pp_loss: 10.375173
[INFO] 2021-07-12 17:11:53,671 [run_pretraining.py:  512]:	********exe.run_8******* 
[INFO] 2021-07-12 17:13:32,334 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:13:32,335 [run_pretraining.py:  534]:	loss/total_loss, 10.540851593017578, 9
[INFO] 2021-07-12 17:13:32,335 [run_pretraining.py:  535]:	loss/mlm_loss, 10.540851593017578, 9
[INFO] 2021-07-12 17:13:32,335 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.999999240837496e-08, 9
[INFO] 2021-07-12 17:13:32,335 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 9
[INFO] 2021-07-12 17:13:32,335 [run_pretraining.py:  558]:	worker_index: 6, step: 9, cost: 10.540852, mlm loss: 10.540852, speed: 0.010135 steps/s, speed: 0.081084 samples/s, speed: 41.514930 tokens/s, learning rate: 8.000e-08, loss_scalings: 26214.400391, pp_loss: 9.326202
[INFO] 2021-07-12 17:13:32,336 [run_pretraining.py:  512]:	********exe.run_9******* 
[INFO] 2021-07-12 17:15:11,270 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:15:11,271 [run_pretraining.py:  534]:	loss/total_loss, 10.23422622680664, 10
[INFO] 2021-07-12 17:15:11,271 [run_pretraining.py:  535]:	loss/mlm_loss, 10.23422622680664, 10
[INFO] 2021-07-12 17:15:11,271 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.999999323577867e-08, 10
[INFO] 2021-07-12 17:15:11,271 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 10
[INFO] 2021-07-12 17:15:11,271 [run_pretraining.py:  558]:	worker_index: 6, step: 10, cost: 10.234226, mlm loss: 10.234226, speed: 0.010108 steps/s, speed: 0.080861 samples/s, speed: 41.400986 tokens/s, learning rate: 9.000e-08, loss_scalings: 26214.400391, pp_loss: 10.313987
[INFO] 2021-07-12 17:15:11,271 [run_pretraining.py:  512]:	********exe.run_10******* 
[INFO] 2021-07-12 17:16:00,905 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:16:00,906 [run_pretraining.py:  534]:	loss/total_loss, 10.391267776489258, 11
[INFO] 2021-07-12 17:16:00,906 [run_pretraining.py:  535]:	loss/mlm_loss, 10.391267776489258, 11
[INFO] 2021-07-12 17:16:00,906 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0000000116860974e-07, 11
[INFO] 2021-07-12 17:16:00,906 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 11
[INFO] 2021-07-12 17:16:00,906 [run_pretraining.py:  558]:	worker_index: 6, step: 11, cost: 10.391268, mlm loss: 10.391268, speed: 0.020147 steps/s, speed: 0.161179 samples/s, speed: 82.523460 tokens/s, learning rate: 1.000e-07, loss_scalings: 26214.400391, pp_loss: 10.365047
[INFO] 2021-07-12 17:16:00,906 [run_pretraining.py:  512]:	********exe.run_11******* 
[INFO] 2021-07-12 17:17:35,434 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:17:35,434 [run_pretraining.py:  534]:	loss/total_loss, 10.383445739746094, 12
[INFO] 2021-07-12 17:17:35,435 [run_pretraining.py:  535]:	loss/mlm_loss, 10.383445739746094, 12
[INFO] 2021-07-12 17:17:35,435 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.099999948905861e-07, 12
[INFO] 2021-07-12 17:17:35,435 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 12
[INFO] 2021-07-12 17:17:35,435 [run_pretraining.py:  558]:	worker_index: 6, step: 12, cost: 10.383446, mlm loss: 10.383446, speed: 0.010579 steps/s, speed: 0.084631 samples/s, speed: 43.331236 tokens/s, learning rate: 1.100e-07, loss_scalings: 26214.400391, pp_loss: 10.370533
[INFO] 2021-07-12 17:17:35,435 [run_pretraining.py:  512]:	********exe.run_12******* 
[INFO] 2021-07-12 17:18:51,089 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:18:51,090 [run_pretraining.py:  534]:	loss/total_loss, 10.467909812927246, 13
[INFO] 2021-07-12 17:18:51,090 [run_pretraining.py:  535]:	loss/mlm_loss, 10.467909812927246, 13
[INFO] 2021-07-12 17:18:51,090 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.199999957179898e-07, 13
[INFO] 2021-07-12 17:18:51,090 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 13
[INFO] 2021-07-12 17:18:51,090 [run_pretraining.py:  558]:	worker_index: 6, step: 13, cost: 10.467910, mlm loss: 10.467910, speed: 0.013218 steps/s, speed: 0.105744 samples/s, speed: 54.140823 tokens/s, learning rate: 1.200e-07, loss_scalings: 26214.400391, pp_loss: 10.368147
[INFO] 2021-07-12 17:18:51,090 [run_pretraining.py:  512]:	********exe.run_13******* 
[INFO] 2021-07-12 17:20:05,866 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:20:05,867 [run_pretraining.py:  534]:	loss/total_loss, 10.28267765045166, 14
[INFO] 2021-07-12 17:20:05,867 [run_pretraining.py:  535]:	loss/mlm_loss, 10.28267765045166, 14
[INFO] 2021-07-12 17:20:05,867 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3000000365082087e-07, 14
[INFO] 2021-07-12 17:20:05,867 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 14
[INFO] 2021-07-12 17:20:05,867 [run_pretraining.py:  558]:	worker_index: 6, step: 14, cost: 10.282678, mlm loss: 10.282678, speed: 0.013373 steps/s, speed: 0.106986 samples/s, speed: 54.776962 tokens/s, learning rate: 1.300e-07, loss_scalings: 26214.400391, pp_loss: 10.391258
[INFO] 2021-07-12 17:20:05,867 [run_pretraining.py:  512]:	********exe.run_14******* 
[INFO] 2021-07-12 17:21:43,827 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:21:43,828 [run_pretraining.py:  534]:	loss/total_loss, 10.247434616088867, 15
[INFO] 2021-07-12 17:21:43,828 [run_pretraining.py:  535]:	loss/mlm_loss, 10.247434616088867, 15
[INFO] 2021-07-12 17:21:43,828 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3999999737279722e-07, 15
[INFO] 2021-07-12 17:21:43,828 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 15
[INFO] 2021-07-12 17:21:43,828 [run_pretraining.py:  558]:	worker_index: 6, step: 15, cost: 10.247435, mlm loss: 10.247435, speed: 0.010208 steps/s, speed: 0.081666 samples/s, speed: 41.812920 tokens/s, learning rate: 1.400e-07, loss_scalings: 26214.400391, pp_loss: 10.347965
[INFO] 2021-07-12 17:21:43,828 [run_pretraining.py:  512]:	********exe.run_15******* 
[INFO] 2021-07-12 17:22:59,154 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:22:59,155 [run_pretraining.py:  534]:	loss/total_loss, 7.514766216278076, 16
[INFO] 2021-07-12 17:22:59,155 [run_pretraining.py:  535]:	loss/mlm_loss, 7.514766216278076, 16
[INFO] 2021-07-12 17:22:59,155 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4999999109477358e-07, 16
[INFO] 2021-07-12 17:22:59,155 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 16
[INFO] 2021-07-12 17:22:59,155 [run_pretraining.py:  558]:	worker_index: 6, step: 16, cost: 7.514766, mlm loss: 7.514766, speed: 0.013276 steps/s, speed: 0.106205 samples/s, speed: 54.376871 tokens/s, learning rate: 1.500e-07, loss_scalings: 26214.400391, pp_loss: 9.704491
[INFO] 2021-07-12 17:22:59,155 [run_pretraining.py:  512]:	********exe.run_16******* 
[INFO] 2021-07-12 17:23:49,303 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:23:49,303 [run_pretraining.py:  534]:	loss/total_loss, 10.390473365783691, 17
[INFO] 2021-07-12 17:23:49,303 [run_pretraining.py:  535]:	loss/mlm_loss, 10.390473365783691, 17
[INFO] 2021-07-12 17:23:49,303 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5999998481674993e-07, 17
[INFO] 2021-07-12 17:23:49,304 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 17
[INFO] 2021-07-12 17:23:49,304 [run_pretraining.py:  558]:	worker_index: 6, step: 17, cost: 10.390473, mlm loss: 10.390473, speed: 0.019941 steps/s, speed: 0.159528 samples/s, speed: 81.678472 tokens/s, learning rate: 1.600e-07, loss_scalings: 26214.400391, pp_loss: 10.418060
[INFO] 2021-07-12 17:23:49,304 [run_pretraining.py:  512]:	********exe.run_17******* 
[INFO] 2021-07-12 17:25:28,091 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:25:28,092 [run_pretraining.py:  534]:	loss/total_loss, 10.47364616394043, 18
[INFO] 2021-07-12 17:25:28,092 [run_pretraining.py:  535]:	loss/mlm_loss, 10.47364616394043, 18
[INFO] 2021-07-12 17:25:28,092 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.69999992749581e-07, 18
[INFO] 2021-07-12 17:25:28,092 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 18
[INFO] 2021-07-12 17:25:28,092 [run_pretraining.py:  558]:	worker_index: 6, step: 18, cost: 10.473646, mlm loss: 10.473646, speed: 0.010123 steps/s, speed: 0.080982 samples/s, speed: 41.462701 tokens/s, learning rate: 1.700e-07, loss_scalings: 26214.400391, pp_loss: 10.412095
[INFO] 2021-07-12 17:25:28,092 [run_pretraining.py:  512]:	********exe.run_18******* 
[INFO] 2021-07-12 17:27:03,438 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:27:03,439 [run_pretraining.py:  534]:	loss/total_loss, 10.324853897094727, 19
[INFO] 2021-07-12 17:27:03,439 [run_pretraining.py:  535]:	loss/mlm_loss, 10.324853897094727, 19
[INFO] 2021-07-12 17:27:03,439 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7999998647155735e-07, 19
[INFO] 2021-07-12 17:27:03,439 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 19
[INFO] 2021-07-12 17:27:03,439 [run_pretraining.py:  558]:	worker_index: 6, step: 19, cost: 10.324854, mlm loss: 10.324854, speed: 0.010488 steps/s, speed: 0.083905 samples/s, speed: 42.959219 tokens/s, learning rate: 1.800e-07, loss_scalings: 26214.400391, pp_loss: 10.408956
[INFO] 2021-07-12 17:27:03,439 [run_pretraining.py:  512]:	********exe.run_19******* 
[INFO] 2021-07-12 17:28:18,376 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:28:18,377 [run_pretraining.py:  534]:	loss/total_loss, 10.354302406311035, 20
[INFO] 2021-07-12 17:28:18,377 [run_pretraining.py:  535]:	loss/mlm_loss, 10.354302406311035, 20
[INFO] 2021-07-12 17:28:18,377 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8999999440438842e-07, 20
[INFO] 2021-07-12 17:28:18,377 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 20
[INFO] 2021-07-12 17:28:18,377 [run_pretraining.py:  558]:	worker_index: 6, step: 20, cost: 10.354302, mlm loss: 10.354302, speed: 0.013344 steps/s, speed: 0.106756 samples/s, speed: 54.658883 tokens/s, learning rate: 1.900e-07, loss_scalings: 26214.400391, pp_loss: 10.411510
[INFO] 2021-07-12 17:28:18,377 [run_pretraining.py:  512]:	********exe.run_20******* 
[INFO] 2021-07-12 17:29:07,956 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:29:07,956 [run_pretraining.py:  534]:	loss/total_loss, 6.363382816314697, 21
[INFO] 2021-07-12 17:29:07,957 [run_pretraining.py:  535]:	loss/mlm_loss, 6.363382816314697, 21
[INFO] 2021-07-12 17:29:07,957 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0000000233721948e-07, 21
[INFO] 2021-07-12 17:29:07,957 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 21
[INFO] 2021-07-12 17:29:07,957 [run_pretraining.py:  558]:	worker_index: 6, step: 21, cost: 6.363383, mlm loss: 6.363383, speed: 0.020170 steps/s, speed: 0.161359 samples/s, speed: 82.616009 tokens/s, learning rate: 2.000e-07, loss_scalings: 26214.400391, pp_loss: 9.405865
[INFO] 2021-07-12 17:29:07,957 [run_pretraining.py:  512]:	********exe.run_21******* 
[INFO] 2021-07-12 17:30:23,123 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:30:23,124 [run_pretraining.py:  534]:	loss/total_loss, 10.415037155151367, 22
[INFO] 2021-07-12 17:30:23,124 [run_pretraining.py:  535]:	loss/mlm_loss, 10.415037155151367, 22
[INFO] 2021-07-12 17:30:23,124 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0999998184834112e-07, 22
[INFO] 2021-07-12 17:30:23,124 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 22
[INFO] 2021-07-12 17:30:23,124 [run_pretraining.py:  558]:	worker_index: 6, step: 22, cost: 10.415037, mlm loss: 10.415037, speed: 0.013304 steps/s, speed: 0.106430 samples/s, speed: 54.492375 tokens/s, learning rate: 2.100e-07, loss_scalings: 26214.400391, pp_loss: 10.454532
[INFO] 2021-07-12 17:30:23,124 [run_pretraining.py:  512]:	********exe.run_22******* 
[INFO] 2021-07-12 17:32:00,383 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:32:00,383 [run_pretraining.py:  534]:	loss/total_loss, 10.36093521118164, 23
[INFO] 2021-07-12 17:32:00,383 [run_pretraining.py:  535]:	loss/mlm_loss, 10.36093521118164, 23
[INFO] 2021-07-12 17:32:00,383 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.199999897811722e-07, 23
[INFO] 2021-07-12 17:32:00,384 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 23
[INFO] 2021-07-12 17:32:00,384 [run_pretraining.py:  558]:	worker_index: 6, step: 23, cost: 10.360935, mlm loss: 10.360935, speed: 0.010282 steps/s, speed: 0.082255 samples/s, speed: 42.114449 tokens/s, learning rate: 2.200e-07, loss_scalings: 26214.400391, pp_loss: 10.417665
[INFO] 2021-07-12 17:32:00,384 [run_pretraining.py:  512]:	********exe.run_23******* 
[INFO] 2021-07-12 17:33:12,815 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:33:12,816 [run_pretraining.py:  534]:	loss/total_loss, 7.494632244110107, 24
[INFO] 2021-07-12 17:33:12,816 [run_pretraining.py:  535]:	loss/mlm_loss, 7.494632244110107, 24
[INFO] 2021-07-12 17:33:12,816 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2999999771400326e-07, 24
[INFO] 2021-07-12 17:33:12,816 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 24
[INFO] 2021-07-12 17:33:12,816 [run_pretraining.py:  558]:	worker_index: 6, step: 24, cost: 7.494632, mlm loss: 7.494632, speed: 0.013806 steps/s, speed: 0.110449 samples/s, speed: 56.549640 tokens/s, learning rate: 2.300e-07, loss_scalings: 26214.400391, pp_loss: 9.627928
[INFO] 2021-07-12 17:33:12,816 [run_pretraining.py:  512]:	********exe.run_24******* 
[INFO] 2021-07-12 17:34:27,394 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:34:27,395 [run_pretraining.py:  534]:	loss/total_loss, 10.352712631225586, 25
[INFO] 2021-07-12 17:34:27,395 [run_pretraining.py:  535]:	loss/mlm_loss, 10.352712631225586, 25
[INFO] 2021-07-12 17:34:27,395 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.399999914359796e-07, 25
[INFO] 2021-07-12 17:34:27,395 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 25
[INFO] 2021-07-12 17:34:27,395 [run_pretraining.py:  558]:	worker_index: 6, step: 25, cost: 10.352713, mlm loss: 10.352713, speed: 0.013409 steps/s, speed: 0.107270 samples/s, speed: 54.922359 tokens/s, learning rate: 2.400e-07, loss_scalings: 26214.400391, pp_loss: 10.132563
[INFO] 2021-07-12 17:34:27,395 [run_pretraining.py:  512]:	********exe.run_25******* 
[INFO] 2021-07-12 17:36:04,227 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:36:04,227 [run_pretraining.py:  534]:	loss/total_loss, 10.406670570373535, 26
[INFO] 2021-07-12 17:36:04,228 [run_pretraining.py:  535]:	loss/mlm_loss, 10.406670570373535, 26
[INFO] 2021-07-12 17:36:04,228 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.499999993688107e-07, 26
[INFO] 2021-07-12 17:36:04,228 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 26
[INFO] 2021-07-12 17:36:04,228 [run_pretraining.py:  558]:	worker_index: 6, step: 26, cost: 10.406671, mlm loss: 10.406671, speed: 0.010327 steps/s, speed: 0.082617 samples/s, speed: 42.300070 tokens/s, learning rate: 2.500e-07, loss_scalings: 26214.400391, pp_loss: 9.416500
[INFO] 2021-07-12 17:36:04,228 [run_pretraining.py:  512]:	********exe.run_26******* 
[INFO] 2021-07-12 17:37:41,310 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:37:41,311 [run_pretraining.py:  534]:	loss/total_loss, 10.429977416992188, 27
[INFO] 2021-07-12 17:37:41,311 [run_pretraining.py:  535]:	loss/mlm_loss, 10.429977416992188, 27
[INFO] 2021-07-12 17:37:41,311 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6000000730164174e-07, 27
[INFO] 2021-07-12 17:37:41,311 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 27
[INFO] 2021-07-12 17:37:41,311 [run_pretraining.py:  558]:	worker_index: 6, step: 27, cost: 10.429977, mlm loss: 10.429977, speed: 0.010301 steps/s, speed: 0.082404 samples/s, speed: 42.190918 tokens/s, learning rate: 2.600e-07, loss_scalings: 26214.400391, pp_loss: 10.404659
[INFO] 2021-07-12 17:37:41,311 [run_pretraining.py:  512]:	********exe.run_27******* 
[INFO] 2021-07-12 17:38:32,250 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:38:32,251 [run_pretraining.py:  534]:	loss/total_loss, 10.317070007324219, 28
[INFO] 2021-07-12 17:38:32,251 [run_pretraining.py:  535]:	loss/mlm_loss, 10.317070007324219, 28
[INFO] 2021-07-12 17:38:32,251 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.699999868127634e-07, 28
[INFO] 2021-07-12 17:38:32,251 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 28
[INFO] 2021-07-12 17:38:32,251 [run_pretraining.py:  558]:	worker_index: 6, step: 28, cost: 10.317070, mlm loss: 10.317070, speed: 0.019631 steps/s, speed: 0.157050 samples/s, speed: 80.409708 tokens/s, learning rate: 2.700e-07, loss_scalings: 26214.400391, pp_loss: 9.839666
[INFO] 2021-07-12 17:38:32,251 [run_pretraining.py:  512]:	********exe.run_28******* 
[INFO] 2021-07-12 17:39:43,324 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:39:43,324 [run_pretraining.py:  534]:	loss/total_loss, 10.419812202453613, 29
[INFO] 2021-07-12 17:39:43,324 [run_pretraining.py:  535]:	loss/mlm_loss, 10.419812202453613, 29
[INFO] 2021-07-12 17:39:43,324 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7999999474559445e-07, 29
[INFO] 2021-07-12 17:39:43,325 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 29
[INFO] 2021-07-12 17:39:43,325 [run_pretraining.py:  558]:	worker_index: 6, step: 29, cost: 10.419812, mlm loss: 10.419812, speed: 0.014070 steps/s, speed: 0.112561 samples/s, speed: 57.631088 tokens/s, learning rate: 2.800e-07, loss_scalings: 26214.400391, pp_loss: 10.405557
[INFO] 2021-07-12 17:39:43,325 [run_pretraining.py:  512]:	********exe.run_29******* 
[INFO] 2021-07-12 17:40:32,216 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:40:32,216 [run_pretraining.py:  534]:	loss/total_loss, 10.28430461883545, 30
[INFO] 2021-07-12 17:40:32,216 [run_pretraining.py:  535]:	loss/mlm_loss, 10.28430461883545, 30
[INFO] 2021-07-12 17:40:32,216 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.900000026784255e-07, 30
[INFO] 2021-07-12 17:40:32,217 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 30
[INFO] 2021-07-12 17:40:32,217 [run_pretraining.py:  558]:	worker_index: 6, step: 30, cost: 10.284305, mlm loss: 10.284305, speed: 0.020454 steps/s, speed: 0.163628 samples/s, speed: 83.777661 tokens/s, learning rate: 2.900e-07, loss_scalings: 26214.400391, pp_loss: 10.349270
[INFO] 2021-07-12 17:40:32,217 [run_pretraining.py:  512]:	********exe.run_30******* 
[INFO] 2021-07-12 17:41:23,352 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:41:23,353 [run_pretraining.py:  534]:	loss/total_loss, 10.369651794433594, 31
[INFO] 2021-07-12 17:41:23,353 [run_pretraining.py:  535]:	loss/mlm_loss, 10.369651794433594, 31
[INFO] 2021-07-12 17:41:23,353 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9999998218954715e-07, 31
[INFO] 2021-07-12 17:41:23,353 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 31
[INFO] 2021-07-12 17:41:23,353 [run_pretraining.py:  558]:	worker_index: 6, step: 31, cost: 10.369652, mlm loss: 10.369652, speed: 0.019556 steps/s, speed: 0.156446 samples/s, speed: 80.100119 tokens/s, learning rate: 3.000e-07, loss_scalings: 26214.400391, pp_loss: 10.349495
[INFO] 2021-07-12 17:41:23,354 [run_pretraining.py:  512]:	********exe.run_31******* 
[INFO] 2021-07-12 17:42:13,622 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:42:13,622 [run_pretraining.py:  534]:	loss/total_loss, 10.483986854553223, 32
[INFO] 2021-07-12 17:42:13,623 [run_pretraining.py:  535]:	loss/mlm_loss, 10.483986854553223, 32
[INFO] 2021-07-12 17:42:13,623 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.099999901223782e-07, 32
[INFO] 2021-07-12 17:42:13,623 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 32
[INFO] 2021-07-12 17:42:13,623 [run_pretraining.py:  558]:	worker_index: 6, step: 32, cost: 10.483987, mlm loss: 10.483987, speed: 0.019893 steps/s, speed: 0.159145 samples/s, speed: 81.482274 tokens/s, learning rate: 3.100e-07, loss_scalings: 26214.400391, pp_loss: 9.209542
[INFO] 2021-07-12 17:42:13,623 [run_pretraining.py:  512]:	********exe.run_32******* 
[INFO] 2021-07-12 17:43:03,043 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:43:03,044 [run_pretraining.py:  534]:	loss/total_loss, 10.33814525604248, 33
[INFO] 2021-07-12 17:43:03,044 [run_pretraining.py:  535]:	loss/mlm_loss, 10.33814525604248, 33
[INFO] 2021-07-12 17:43:03,044 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.1999996963349986e-07, 33
[INFO] 2021-07-12 17:43:03,044 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 33
[INFO] 2021-07-12 17:43:03,044 [run_pretraining.py:  558]:	worker_index: 6, step: 33, cost: 10.338145, mlm loss: 10.338145, speed: 0.020234 steps/s, speed: 0.161876 samples/s, speed: 82.880404 tokens/s, learning rate: 3.200e-07, loss_scalings: 26214.400391, pp_loss: 10.388911
[INFO] 2021-07-12 17:43:03,044 [run_pretraining.py:  512]:	********exe.run_33******* 
[INFO] 2021-07-12 17:43:29,442 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:43:29,442 [run_pretraining.py:  534]:	loss/total_loss, 10.388575553894043, 34
[INFO] 2021-07-12 17:43:29,442 [run_pretraining.py:  535]:	loss/mlm_loss, 10.388575553894043, 34
[INFO] 2021-07-12 17:43:29,442 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.2999997756633093e-07, 34
[INFO] 2021-07-12 17:43:29,443 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 34
[INFO] 2021-07-12 17:43:29,443 [run_pretraining.py:  558]:	worker_index: 6, step: 34, cost: 10.388576, mlm loss: 10.388576, speed: 0.037882 steps/s, speed: 0.303057 samples/s, speed: 155.165048 tokens/s, learning rate: 3.300e-07, loss_scalings: 26214.400391, pp_loss: 10.346267
[INFO] 2021-07-12 17:43:29,443 [run_pretraining.py:  512]:	********exe.run_34******* 
[INFO] 2021-07-12 17:44:17,413 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:44:17,414 [run_pretraining.py:  534]:	loss/total_loss, 10.378480911254883, 35
[INFO] 2021-07-12 17:44:17,414 [run_pretraining.py:  535]:	loss/mlm_loss, 10.378480911254883, 35
[INFO] 2021-07-12 17:44:17,414 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.39999985499162e-07, 35
[INFO] 2021-07-12 17:44:17,414 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 35
[INFO] 2021-07-12 17:44:17,414 [run_pretraining.py:  558]:	worker_index: 6, step: 35, cost: 10.378481, mlm loss: 10.378481, speed: 0.020846 steps/s, speed: 0.166768 samples/s, speed: 85.384966 tokens/s, learning rate: 3.400e-07, loss_scalings: 26214.400391, pp_loss: 10.412441
[INFO] 2021-07-12 17:44:17,415 [run_pretraining.py:  512]:	********exe.run_35******* 
[INFO] 2021-07-12 17:44:42,787 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:44:42,787 [run_pretraining.py:  534]:	loss/total_loss, 10.276056289672852, 36
[INFO] 2021-07-12 17:44:42,788 [run_pretraining.py:  535]:	loss/mlm_loss, 10.276056289672852, 36
[INFO] 2021-07-12 17:44:42,788 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.4999999343199306e-07, 36
[INFO] 2021-07-12 17:44:42,788 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 36
[INFO] 2021-07-12 17:44:42,788 [run_pretraining.py:  558]:	worker_index: 6, step: 36, cost: 10.276056, mlm loss: 10.276056, speed: 0.039412 steps/s, speed: 0.315300 samples/s, speed: 161.433467 tokens/s, learning rate: 3.500e-07, loss_scalings: 26214.400391, pp_loss: 10.312169
[INFO] 2021-07-12 17:44:42,788 [run_pretraining.py:  512]:	********exe.run_36******* 
[INFO] 2021-07-12 17:45:32,298 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:45:32,298 [run_pretraining.py:  534]:	loss/total_loss, 10.415689468383789, 37
[INFO] 2021-07-12 17:45:32,298 [run_pretraining.py:  535]:	loss/mlm_loss, 10.415689468383789, 37
[INFO] 2021-07-12 17:45:32,298 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.599999729431147e-07, 37
[INFO] 2021-07-12 17:45:32,299 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 37
[INFO] 2021-07-12 17:45:32,299 [run_pretraining.py:  558]:	worker_index: 6, step: 37, cost: 10.415689, mlm loss: 10.415689, speed: 0.020198 steps/s, speed: 0.161583 samples/s, speed: 82.730689 tokens/s, learning rate: 3.600e-07, loss_scalings: 26214.400391, pp_loss: 10.398987
[INFO] 2021-07-12 17:45:32,299 [run_pretraining.py:  512]:	********exe.run_37******* 
[INFO] 2021-07-12 17:45:33,249 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:45:33,250 [run_pretraining.py:  534]:	loss/total_loss, 10.392738342285156, 38
[INFO] 2021-07-12 17:45:33,250 [run_pretraining.py:  535]:	loss/mlm_loss, 10.392738342285156, 38
[INFO] 2021-07-12 17:45:33,250 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.6999998087594577e-07, 38
[INFO] 2021-07-12 17:45:33,250 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 38
[INFO] 2021-07-12 17:45:33,250 [run_pretraining.py:  558]:	worker_index: 6, step: 38, cost: 10.392738, mlm loss: 10.392738, speed: 1.052025 steps/s, speed: 8.416203 samples/s, speed: 4309.095744 tokens/s, learning rate: 3.700e-07, loss_scalings: 26214.400391, pp_loss: 10.393895
[INFO] 2021-07-12 17:45:33,250 [run_pretraining.py:  512]:	********exe.run_38******* 
[INFO] 2021-07-12 17:46:46,188 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:46:46,189 [run_pretraining.py:  534]:	loss/total_loss, 10.26827335357666, 39
[INFO] 2021-07-12 17:46:46,189 [run_pretraining.py:  535]:	loss/mlm_loss, 10.26827335357666, 39
[INFO] 2021-07-12 17:46:46,189 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.7999998880877683e-07, 39
[INFO] 2021-07-12 17:46:46,189 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 39
[INFO] 2021-07-12 17:46:46,189 [run_pretraining.py:  558]:	worker_index: 6, step: 39, cost: 10.268273, mlm loss: 10.268273, speed: 0.013710 steps/s, speed: 0.109682 samples/s, speed: 56.157073 tokens/s, learning rate: 3.800e-07, loss_scalings: 26214.400391, pp_loss: 10.365865
[INFO] 2021-07-12 17:46:46,189 [run_pretraining.py:  512]:	********exe.run_39******* 
[INFO] 2021-07-12 17:47:10,250 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:47:10,251 [run_pretraining.py:  534]:	loss/total_loss, 10.353252410888672, 40
[INFO] 2021-07-12 17:47:10,251 [run_pretraining.py:  535]:	loss/mlm_loss, 10.353252410888672, 40
[INFO] 2021-07-12 17:47:10,251 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.8999996831989847e-07, 40
[INFO] 2021-07-12 17:47:10,251 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 40
[INFO] 2021-07-12 17:47:10,251 [run_pretraining.py:  558]:	worker_index: 6, step: 40, cost: 10.353252, mlm loss: 10.353252, speed: 0.041560 steps/s, speed: 0.332481 samples/s, speed: 170.230240 tokens/s, learning rate: 3.900e-07, loss_scalings: 26214.400391, pp_loss: 10.355488
[INFO] 2021-07-12 17:47:10,251 [run_pretraining.py:  512]:	********exe.run_40******* 
[INFO] 2021-07-12 17:48:26,858 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:48:26,859 [run_pretraining.py:  534]:	loss/total_loss, 10.258153915405273, 41
[INFO] 2021-07-12 17:48:26,859 [run_pretraining.py:  535]:	loss/mlm_loss, 10.258153915405273, 41
[INFO] 2021-07-12 17:48:26,859 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.0000000467443897e-07, 41
[INFO] 2021-07-12 17:48:26,859 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 41
[INFO] 2021-07-12 17:48:26,859 [run_pretraining.py:  558]:	worker_index: 6, step: 41, cost: 10.258154, mlm loss: 10.258154, speed: 0.013054 steps/s, speed: 0.104429 samples/s, speed: 53.467772 tokens/s, learning rate: 4.000e-07, loss_scalings: 26214.400391, pp_loss: 10.384527
[INFO] 2021-07-12 17:48:26,859 [run_pretraining.py:  512]:	********exe.run_41******* 
[INFO] 2021-07-12 17:49:41,987 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:49:41,988 [run_pretraining.py:  534]:	loss/total_loss, 10.442314147949219, 42
[INFO] 2021-07-12 17:49:41,988 [run_pretraining.py:  535]:	loss/mlm_loss, 10.442314147949219, 42
[INFO] 2021-07-12 17:49:41,988 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.099999841855606e-07, 42
[INFO] 2021-07-12 17:49:41,988 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 42
[INFO] 2021-07-12 17:49:41,988 [run_pretraining.py:  558]:	worker_index: 6, step: 42, cost: 10.442314, mlm loss: 10.442314, speed: 0.013310 steps/s, speed: 0.106484 samples/s, speed: 54.519787 tokens/s, learning rate: 4.100e-07, loss_scalings: 26214.400391, pp_loss: 10.372657
[INFO] 2021-07-12 17:49:41,989 [run_pretraining.py:  512]:	********exe.run_42******* 
[INFO] 2021-07-12 17:50:07,115 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:50:07,115 [run_pretraining.py:  534]:	loss/total_loss, 10.343877792358398, 43
[INFO] 2021-07-12 17:50:07,115 [run_pretraining.py:  535]:	loss/mlm_loss, 10.343877792358398, 43
[INFO] 2021-07-12 17:50:07,116 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.1999996369668224e-07, 43
[INFO] 2021-07-12 17:50:07,116 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 43
[INFO] 2021-07-12 17:50:07,116 [run_pretraining.py:  558]:	worker_index: 6, step: 43, cost: 10.343878, mlm loss: 10.343878, speed: 0.039799 steps/s, speed: 0.318388 samples/s, speed: 163.014773 tokens/s, learning rate: 4.200e-07, loss_scalings: 26214.400391, pp_loss: 10.359737
[INFO] 2021-07-12 17:50:07,116 [run_pretraining.py:  512]:	********exe.run_43******* 
[INFO] 2021-07-12 17:50:31,954 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:50:31,955 [run_pretraining.py:  534]:	loss/total_loss, 10.281732559204102, 44
[INFO] 2021-07-12 17:50:31,955 [run_pretraining.py:  535]:	loss/mlm_loss, 10.281732559204102, 44
[INFO] 2021-07-12 17:50:31,955 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.3000000005122274e-07, 44
[INFO] 2021-07-12 17:50:31,955 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 44
[INFO] 2021-07-12 17:50:31,955 [run_pretraining.py:  558]:	worker_index: 6, step: 44, cost: 10.281733, mlm loss: 10.281733, speed: 0.040260 steps/s, speed: 0.322079 samples/s, speed: 164.904275 tokens/s, learning rate: 4.300e-07, loss_scalings: 26214.400391, pp_loss: 10.286119
[INFO] 2021-07-12 17:50:31,955 [run_pretraining.py:  512]:	********exe.run_44******* 
[INFO] 2021-07-12 17:51:21,604 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:51:21,604 [run_pretraining.py:  534]:	loss/total_loss, 10.335017204284668, 45
[INFO] 2021-07-12 17:51:21,604 [run_pretraining.py:  535]:	loss/mlm_loss, 10.335017204284668, 45
[INFO] 2021-07-12 17:51:21,605 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.399999795623444e-07, 45
[INFO] 2021-07-12 17:51:21,605 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 45
[INFO] 2021-07-12 17:51:21,605 [run_pretraining.py:  558]:	worker_index: 6, step: 45, cost: 10.335017, mlm loss: 10.335017, speed: 0.020141 steps/s, speed: 0.161132 samples/s, speed: 82.499409 tokens/s, learning rate: 4.400e-07, loss_scalings: 26214.400391, pp_loss: 10.367383
[INFO] 2021-07-12 17:51:21,605 [run_pretraining.py:  512]:	********exe.run_45******* 
[INFO] 2021-07-12 17:51:48,538 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:51:48,539 [run_pretraining.py:  534]:	loss/total_loss, 10.373672485351562, 46
[INFO] 2021-07-12 17:51:48,539 [run_pretraining.py:  535]:	loss/mlm_loss, 10.373672485351562, 46
[INFO] 2021-07-12 17:51:48,539 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.49999959073466e-07, 46
[INFO] 2021-07-12 17:51:48,539 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 46
[INFO] 2021-07-12 17:51:48,540 [run_pretraining.py:  558]:	worker_index: 6, step: 46, cost: 10.373672, mlm loss: 10.373672, speed: 0.037128 steps/s, speed: 0.297023 samples/s, speed: 152.075917 tokens/s, learning rate: 4.500e-07, loss_scalings: 26214.400391, pp_loss: 10.316273
[INFO] 2021-07-12 17:51:48,540 [run_pretraining.py:  512]:	********exe.run_46******* 
[INFO] 2021-07-12 17:52:37,780 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:52:37,781 [run_pretraining.py:  534]:	loss/total_loss, 10.24604606628418, 47
[INFO] 2021-07-12 17:52:37,781 [run_pretraining.py:  535]:	loss/mlm_loss, 10.24604606628418, 47
[INFO] 2021-07-12 17:52:37,781 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.599999954280065e-07, 47
[INFO] 2021-07-12 17:52:37,781 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 47
[INFO] 2021-07-12 17:52:37,781 [run_pretraining.py:  558]:	worker_index: 6, step: 47, cost: 10.246046, mlm loss: 10.246046, speed: 0.020308 steps/s, speed: 0.162467 samples/s, speed: 83.183224 tokens/s, learning rate: 4.600e-07, loss_scalings: 26214.400391, pp_loss: 10.358967
[INFO] 2021-07-12 17:52:37,781 [run_pretraining.py:  512]:	********exe.run_47******* 
[INFO] 2021-07-12 17:53:02,014 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:53:02,015 [run_pretraining.py:  534]:	loss/total_loss, 10.333822250366211, 48
[INFO] 2021-07-12 17:53:02,015 [run_pretraining.py:  535]:	loss/mlm_loss, 10.333822250366211, 48
[INFO] 2021-07-12 17:53:02,015 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.6999997493912815e-07, 48
[INFO] 2021-07-12 17:53:02,015 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 48
[INFO] 2021-07-12 17:53:02,015 [run_pretraining.py:  558]:	worker_index: 6, step: 48, cost: 10.333822, mlm loss: 10.333822, speed: 0.041265 steps/s, speed: 0.330123 samples/s, speed: 169.022813 tokens/s, learning rate: 4.700e-07, loss_scalings: 26214.400391, pp_loss: 10.330154
[INFO] 2021-07-12 17:53:02,015 [run_pretraining.py:  512]:	********exe.run_48******* 
[INFO] 2021-07-12 17:54:14,147 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:54:14,148 [run_pretraining.py:  534]:	loss/total_loss, 10.39532470703125, 49
[INFO] 2021-07-12 17:54:14,148 [run_pretraining.py:  535]:	loss/mlm_loss, 10.39532470703125, 49
[INFO] 2021-07-12 17:54:14,148 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.799999828719592e-07, 49
[INFO] 2021-07-12 17:54:14,148 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 49
[INFO] 2021-07-12 17:54:14,148 [run_pretraining.py:  558]:	worker_index: 6, step: 49, cost: 10.395325, mlm loss: 10.395325, speed: 0.013863 steps/s, speed: 0.110907 samples/s, speed: 56.784446 tokens/s, learning rate: 4.800e-07, loss_scalings: 26214.400391, pp_loss: 9.208573
[INFO] 2021-07-12 17:54:14,148 [run_pretraining.py:  512]:	********exe.run_49******* 
[INFO] 2021-07-12 17:54:39,249 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:54:39,250 [run_pretraining.py:  534]:	loss/total_loss, 10.368839263916016, 50
[INFO] 2021-07-12 17:54:39,250 [run_pretraining.py:  535]:	loss/mlm_loss, 10.368839263916016, 50
[INFO] 2021-07-12 17:54:39,250 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.899999908047903e-07, 50
[INFO] 2021-07-12 17:54:39,250 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 50
[INFO] 2021-07-12 17:54:39,250 [run_pretraining.py:  558]:	worker_index: 6, step: 50, cost: 10.368839, mlm loss: 10.368839, speed: 0.039839 steps/s, speed: 0.318713 samples/s, speed: 163.180969 tokens/s, learning rate: 4.900e-07, loss_scalings: 26214.400391, pp_loss: 10.344966
[INFO] 2021-07-12 17:54:39,250 [run_pretraining.py:  512]:	********exe.run_50******* 
[INFO] 2021-07-12 17:55:04,390 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:55:04,390 [run_pretraining.py:  534]:	loss/total_loss, 10.488197326660156, 51
[INFO] 2021-07-12 17:55:04,390 [run_pretraining.py:  535]:	loss/mlm_loss, 10.488197326660156, 51
[INFO] 2021-07-12 17:55:04,391 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.999999987376214e-07, 51
[INFO] 2021-07-12 17:55:04,391 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 51
[INFO] 2021-07-12 17:55:04,391 [run_pretraining.py:  558]:	worker_index: 6, step: 51, cost: 10.488197, mlm loss: 10.488197, speed: 0.039777 steps/s, speed: 0.318220 samples/s, speed: 162.928413 tokens/s, learning rate: 5.000e-07, loss_scalings: 26214.400391, pp_loss: 10.367208
[INFO] 2021-07-12 17:55:04,391 [run_pretraining.py:  512]:	********exe.run_51******* 
[INFO] 2021-07-12 17:56:38,511 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:56:38,512 [run_pretraining.py:  534]:	loss/total_loss, 10.334964752197266, 52
[INFO] 2021-07-12 17:56:38,512 [run_pretraining.py:  535]:	loss/mlm_loss, 10.334964752197266, 52
[INFO] 2021-07-12 17:56:38,512 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.100000066704524e-07, 52
[INFO] 2021-07-12 17:56:38,512 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 52
[INFO] 2021-07-12 17:56:38,512 [run_pretraining.py:  558]:	worker_index: 6, step: 52, cost: 10.334965, mlm loss: 10.334965, speed: 0.010625 steps/s, speed: 0.084997 samples/s, speed: 43.518662 tokens/s, learning rate: 5.100e-07, loss_scalings: 26214.400391, pp_loss: 10.352693
[INFO] 2021-07-12 17:56:38,512 [run_pretraining.py:  512]:	********exe.run_52******* 
[INFO] 2021-07-12 17:57:01,483 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:57:01,483 [run_pretraining.py:  534]:	loss/total_loss, 10.328564643859863, 53
[INFO] 2021-07-12 17:57:01,484 [run_pretraining.py:  535]:	loss/mlm_loss, 10.328564643859863, 53
[INFO] 2021-07-12 17:57:01,484 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.200000146032835e-07, 53
[INFO] 2021-07-12 17:57:01,484 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 53
[INFO] 2021-07-12 17:57:01,484 [run_pretraining.py:  558]:	worker_index: 6, step: 53, cost: 10.328565, mlm loss: 10.328565, speed: 0.043533 steps/s, speed: 0.348266 samples/s, speed: 178.312275 tokens/s, learning rate: 5.200e-07, loss_scalings: 26214.400391, pp_loss: 10.340207
[INFO] 2021-07-12 17:57:01,484 [run_pretraining.py:  512]:	********exe.run_53******* 
[INFO] 2021-07-12 17:57:26,473 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:57:26,474 [run_pretraining.py:  534]:	loss/total_loss, 10.40361213684082, 54
[INFO] 2021-07-12 17:57:26,474 [run_pretraining.py:  535]:	loss/mlm_loss, 10.40361213684082, 54
[INFO] 2021-07-12 17:57:26,474 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.299999656926957e-07, 54
[INFO] 2021-07-12 17:57:26,474 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 54
[INFO] 2021-07-12 17:57:26,474 [run_pretraining.py:  558]:	worker_index: 6, step: 54, cost: 10.403612, mlm loss: 10.403612, speed: 0.040017 steps/s, speed: 0.320134 samples/s, speed: 163.908396 tokens/s, learning rate: 5.300e-07, loss_scalings: 26214.400391, pp_loss: 10.322525
[INFO] 2021-07-12 17:57:26,474 [run_pretraining.py:  512]:	********exe.run_54******* 
[INFO] 2021-07-12 17:57:51,310 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:57:51,311 [run_pretraining.py:  534]:	loss/total_loss, 10.320685386657715, 55
[INFO] 2021-07-12 17:57:51,311 [run_pretraining.py:  535]:	loss/mlm_loss, 10.320685386657715, 55
[INFO] 2021-07-12 17:57:51,311 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.399999736255268e-07, 55
[INFO] 2021-07-12 17:57:51,311 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 55
[INFO] 2021-07-12 17:57:51,311 [run_pretraining.py:  558]:	worker_index: 6, step: 55, cost: 10.320685, mlm loss: 10.320685, speed: 0.040264 steps/s, speed: 0.322109 samples/s, speed: 164.919732 tokens/s, learning rate: 5.400e-07, loss_scalings: 26214.400391, pp_loss: 10.218979
[INFO] 2021-07-12 17:57:51,311 [run_pretraining.py:  512]:	********exe.run_55******* 
[INFO] 2021-07-12 17:57:52,300 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:57:52,300 [run_pretraining.py:  534]:	loss/total_loss, 10.372092247009277, 56
[INFO] 2021-07-12 17:57:52,300 [run_pretraining.py:  535]:	loss/mlm_loss, 10.372092247009277, 56
[INFO] 2021-07-12 17:57:52,301 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.499999815583578e-07, 56
[INFO] 2021-07-12 17:57:52,301 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 56
[INFO] 2021-07-12 17:57:52,301 [run_pretraining.py:  558]:	worker_index: 6, step: 56, cost: 10.372092, mlm loss: 10.372092, speed: 1.011333 steps/s, speed: 8.090663 samples/s, speed: 4142.419588 tokens/s, learning rate: 5.500e-07, loss_scalings: 26214.400391, pp_loss: 10.363299
[INFO] 2021-07-12 17:57:52,301 [run_pretraining.py:  512]:	********exe.run_56******* 
[INFO] 2021-07-12 17:58:15,806 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:58:15,807 [run_pretraining.py:  534]:	loss/total_loss, 10.28981876373291, 57
[INFO] 2021-07-12 17:58:15,807 [run_pretraining.py:  535]:	loss/mlm_loss, 10.28981876373291, 57
[INFO] 2021-07-12 17:58:15,807 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.599999894911889e-07, 57
[INFO] 2021-07-12 17:58:15,808 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 57
[INFO] 2021-07-12 17:58:15,808 [run_pretraining.py:  558]:	worker_index: 6, step: 57, cost: 10.289819, mlm loss: 10.289819, speed: 0.042542 steps/s, speed: 0.340337 samples/s, speed: 174.252463 tokens/s, learning rate: 5.600e-07, loss_scalings: 26214.400391, pp_loss: 10.379299
[INFO] 2021-07-12 17:58:15,808 [run_pretraining.py:  512]:	********exe.run_57******* 
[INFO] 2021-07-12 17:58:42,071 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:58:42,072 [run_pretraining.py:  534]:	loss/total_loss, 10.264032363891602, 58
[INFO] 2021-07-12 17:58:42,072 [run_pretraining.py:  535]:	loss/mlm_loss, 10.264032363891602, 58
[INFO] 2021-07-12 17:58:42,072 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.6999999742402e-07, 58
[INFO] 2021-07-12 17:58:42,072 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 58
[INFO] 2021-07-12 17:58:42,072 [run_pretraining.py:  558]:	worker_index: 6, step: 58, cost: 10.264032, mlm loss: 10.264032, speed: 0.038075 steps/s, speed: 0.304604 samples/s, speed: 155.957093 tokens/s, learning rate: 5.700e-07, loss_scalings: 26214.400391, pp_loss: 10.379780
[INFO] 2021-07-12 17:58:42,072 [run_pretraining.py:  512]:	********exe.run_58******* 
[INFO] 2021-07-12 17:59:06,979 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:59:06,980 [run_pretraining.py:  534]:	loss/total_loss, 10.30795955657959, 59
[INFO] 2021-07-12 17:59:06,980 [run_pretraining.py:  535]:	loss/mlm_loss, 10.30795955657959, 59
[INFO] 2021-07-12 17:59:06,980 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.80000005356851e-07, 59
[INFO] 2021-07-12 17:59:06,980 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 59
[INFO] 2021-07-12 17:59:06,980 [run_pretraining.py:  558]:	worker_index: 6, step: 59, cost: 10.307960, mlm loss: 10.307960, speed: 0.040149 steps/s, speed: 0.321189 samples/s, speed: 164.448525 tokens/s, learning rate: 5.800e-07, loss_scalings: 26214.400391, pp_loss: 10.330178
[INFO] 2021-07-12 17:59:06,980 [run_pretraining.py:  512]:	********exe.run_59******* 
[INFO] 2021-07-12 17:59:07,935 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:59:07,935 [run_pretraining.py:  534]:	loss/total_loss, 10.259842872619629, 60
[INFO] 2021-07-12 17:59:07,936 [run_pretraining.py:  535]:	loss/mlm_loss, 10.259842872619629, 60
[INFO] 2021-07-12 17:59:07,936 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.900000132896821e-07, 60
[INFO] 2021-07-12 17:59:07,936 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 60
[INFO] 2021-07-12 17:59:07,936 [run_pretraining.py:  558]:	worker_index: 6, step: 60, cost: 10.259843, mlm loss: 10.259843, speed: 1.047292 steps/s, speed: 8.378334 samples/s, speed: 4289.707043 tokens/s, learning rate: 5.900e-07, loss_scalings: 26214.400391, pp_loss: 10.267559
[INFO] 2021-07-12 17:59:07,936 [run_pretraining.py:  512]:	********exe.run_60******* 
[INFO] 2021-07-12 17:59:34,485 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:59:34,486 [run_pretraining.py:  534]:	loss/total_loss, 10.328617095947266, 61
[INFO] 2021-07-12 17:59:34,486 [run_pretraining.py:  535]:	loss/mlm_loss, 10.328617095947266, 61
[INFO] 2021-07-12 17:59:34,486 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.999999643790943e-07, 61
[INFO] 2021-07-12 17:59:34,486 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 61
[INFO] 2021-07-12 17:59:34,486 [run_pretraining.py:  558]:	worker_index: 6, step: 61, cost: 10.328617, mlm loss: 10.328617, speed: 0.037665 steps/s, speed: 0.301323 samples/s, speed: 154.277588 tokens/s, learning rate: 6.000e-07, loss_scalings: 26214.400391, pp_loss: 9.328279
[INFO] 2021-07-12 17:59:34,486 [run_pretraining.py:  512]:	********exe.run_61******* 
[INFO] 2021-07-12 17:59:57,539 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:59:57,540 [run_pretraining.py:  534]:	loss/total_loss, 10.261492729187012, 62
[INFO] 2021-07-12 17:59:57,540 [run_pretraining.py:  535]:	loss/mlm_loss, 10.261492729187012, 62
[INFO] 2021-07-12 17:59:57,540 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.099999723119254e-07, 62
[INFO] 2021-07-12 17:59:57,540 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 62
[INFO] 2021-07-12 17:59:57,540 [run_pretraining.py:  558]:	worker_index: 6, step: 62, cost: 10.261493, mlm loss: 10.261493, speed: 0.043378 steps/s, speed: 0.347025 samples/s, speed: 177.676668 tokens/s, learning rate: 6.100e-07, loss_scalings: 26214.400391, pp_loss: 10.307469
[INFO] 2021-07-12 17:59:57,540 [run_pretraining.py:  512]:	********exe.run_62******* 
[INFO] 2021-07-12 18:00:22,665 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:00:22,665 [run_pretraining.py:  534]:	loss/total_loss, 10.329463958740234, 63
[INFO] 2021-07-12 18:00:22,665 [run_pretraining.py:  535]:	loss/mlm_loss, 10.329463958740234, 63
[INFO] 2021-07-12 18:00:22,666 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.199999802447564e-07, 63
[INFO] 2021-07-12 18:00:22,666 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 63
[INFO] 2021-07-12 18:00:22,666 [run_pretraining.py:  558]:	worker_index: 6, step: 63, cost: 10.329464, mlm loss: 10.329464, speed: 0.039801 steps/s, speed: 0.318410 samples/s, speed: 163.025895 tokens/s, learning rate: 6.200e-07, loss_scalings: 26214.400391, pp_loss: 10.296761
[INFO] 2021-07-12 18:00:22,666 [run_pretraining.py:  512]:	********exe.run_63******* 
[INFO] 2021-07-12 18:00:47,668 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:00:47,668 [run_pretraining.py:  534]:	loss/total_loss, 10.287101745605469, 64
[INFO] 2021-07-12 18:00:47,669 [run_pretraining.py:  535]:	loss/mlm_loss, 10.287101745605469, 64
[INFO] 2021-07-12 18:00:47,669 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.299999881775875e-07, 64
[INFO] 2021-07-12 18:00:47,669 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 64
[INFO] 2021-07-12 18:00:47,669 [run_pretraining.py:  558]:	worker_index: 6, step: 64, cost: 10.287102, mlm loss: 10.287102, speed: 0.039996 steps/s, speed: 0.319969 samples/s, speed: 163.824125 tokens/s, learning rate: 6.300e-07, loss_scalings: 26214.400391, pp_loss: 10.264287
[INFO] 2021-07-12 18:00:47,669 [run_pretraining.py:  512]:	********exe.run_64******* 
[INFO] 2021-07-12 18:01:34,939 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:01:34,940 [run_pretraining.py:  534]:	loss/total_loss, 10.185714721679688, 65
[INFO] 2021-07-12 18:01:34,940 [run_pretraining.py:  535]:	loss/mlm_loss, 10.185714721679688, 65
[INFO] 2021-07-12 18:01:34,940 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.399999392669997e-07, 65
[INFO] 2021-07-12 18:01:34,940 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 65
[INFO] 2021-07-12 18:01:34,941 [run_pretraining.py:  558]:	worker_index: 6, step: 65, cost: 10.185715, mlm loss: 10.185715, speed: 0.021155 steps/s, speed: 0.169237 samples/s, speed: 86.649499 tokens/s, learning rate: 6.400e-07, loss_scalings: 26214.400391, pp_loss: 10.273146
[INFO] 2021-07-12 18:01:34,941 [run_pretraining.py:  512]:	********exe.run_65******* 
[INFO] 2021-07-12 18:01:58,677 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:01:58,678 [run_pretraining.py:  534]:	loss/total_loss, 10.31184196472168, 66
[INFO] 2021-07-12 18:01:58,678 [run_pretraining.py:  535]:	loss/mlm_loss, 10.31184196472168, 66
[INFO] 2021-07-12 18:01:58,678 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.500000040432496e-07, 66
[INFO] 2021-07-12 18:01:58,678 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 66
[INFO] 2021-07-12 18:01:58,678 [run_pretraining.py:  558]:	worker_index: 6, step: 66, cost: 10.311842, mlm loss: 10.311842, speed: 0.042128 steps/s, speed: 0.337026 samples/s, speed: 172.557184 tokens/s, learning rate: 6.500e-07, loss_scalings: 26214.400391, pp_loss: 10.345963
[INFO] 2021-07-12 18:01:58,679 [run_pretraining.py:  512]:	********exe.run_66******* 
[INFO] 2021-07-12 18:02:24,261 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:02:24,262 [run_pretraining.py:  534]:	loss/total_loss, 10.40560531616211, 67
[INFO] 2021-07-12 18:02:24,262 [run_pretraining.py:  535]:	loss/mlm_loss, 10.40560531616211, 67
[INFO] 2021-07-12 18:02:24,262 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.599999551326619e-07, 67
[INFO] 2021-07-12 18:02:24,262 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 67
[INFO] 2021-07-12 18:02:24,262 [run_pretraining.py:  558]:	worker_index: 6, step: 67, cost: 10.405605, mlm loss: 10.405605, speed: 0.039088 steps/s, speed: 0.312707 samples/s, speed: 160.106203 tokens/s, learning rate: 6.600e-07, loss_scalings: 26214.400391, pp_loss: 10.276636
[INFO] 2021-07-12 18:02:24,262 [run_pretraining.py:  512]:	********exe.run_67******* 
[INFO] 2021-07-12 18:03:12,739 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:03:12,740 [run_pretraining.py:  534]:	loss/total_loss, 10.23829460144043, 68
[INFO] 2021-07-12 18:03:12,740 [run_pretraining.py:  535]:	loss/mlm_loss, 10.23829460144043, 68
[INFO] 2021-07-12 18:03:12,740 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.699999630654929e-07, 68
[INFO] 2021-07-12 18:03:12,740 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 68
[INFO] 2021-07-12 18:03:12,740 [run_pretraining.py:  558]:	worker_index: 6, step: 68, cost: 10.238295, mlm loss: 10.238295, speed: 0.020628 steps/s, speed: 0.165026 samples/s, speed: 84.493069 tokens/s, learning rate: 6.700e-07, loss_scalings: 26214.400391, pp_loss: 10.243868
[INFO] 2021-07-12 18:03:12,740 [run_pretraining.py:  512]:	********exe.run_68******* 
[INFO] 2021-07-12 18:03:37,914 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:03:37,915 [run_pretraining.py:  534]:	loss/total_loss, 10.185590744018555, 69
[INFO] 2021-07-12 18:03:37,915 [run_pretraining.py:  535]:	loss/mlm_loss, 10.185590744018555, 69
[INFO] 2021-07-12 18:03:37,915 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.79999970998324e-07, 69
[INFO] 2021-07-12 18:03:37,915 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 69
[INFO] 2021-07-12 18:03:37,915 [run_pretraining.py:  558]:	worker_index: 6, step: 69, cost: 10.185591, mlm loss: 10.185591, speed: 0.039723 steps/s, speed: 0.317786 samples/s, speed: 162.706238 tokens/s, learning rate: 6.800e-07, loss_scalings: 26214.400391, pp_loss: 10.274531
[INFO] 2021-07-12 18:03:37,915 [run_pretraining.py:  512]:	********exe.run_69******* 
[INFO] 2021-07-12 18:04:03,908 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:04:03,908 [run_pretraining.py:  534]:	loss/total_loss, 10.144698143005371, 70
[INFO] 2021-07-12 18:04:03,908 [run_pretraining.py:  535]:	loss/mlm_loss, 10.144698143005371, 70
[INFO] 2021-07-12 18:04:03,908 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.899999789311551e-07, 70
[INFO] 2021-07-12 18:04:03,909 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 70
[INFO] 2021-07-12 18:04:03,909 [run_pretraining.py:  558]:	worker_index: 6, step: 70, cost: 10.144698, mlm loss: 10.144698, speed: 0.038472 steps/s, speed: 0.307779 samples/s, speed: 157.583025 tokens/s, learning rate: 6.900e-07, loss_scalings: 26214.400391, pp_loss: 10.315079
[INFO] 2021-07-12 18:04:03,909 [run_pretraining.py:  512]:	********exe.run_70******* 
[INFO] 2021-07-12 18:04:28,995 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:04:28,996 [run_pretraining.py:  534]:	loss/total_loss, 10.356510162353516, 71
[INFO] 2021-07-12 18:04:28,996 [run_pretraining.py:  535]:	loss/mlm_loss, 10.356510162353516, 71
[INFO] 2021-07-12 18:04:28,996 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.999999868639861e-07, 71
[INFO] 2021-07-12 18:04:28,996 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 71
[INFO] 2021-07-12 18:04:28,997 [run_pretraining.py:  558]:	worker_index: 6, step: 71, cost: 10.356510, mlm loss: 10.356510, speed: 0.039861 steps/s, speed: 0.318889 samples/s, speed: 163.271040 tokens/s, learning rate: 7.000e-07, loss_scalings: 26214.400391, pp_loss: 10.291324
[INFO] 2021-07-12 18:04:28,997 [run_pretraining.py:  512]:	********exe.run_71******* 
[INFO] 2021-07-12 18:04:54,338 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:04:54,339 [run_pretraining.py:  534]:	loss/total_loss, 10.337898254394531, 72
[INFO] 2021-07-12 18:04:54,339 [run_pretraining.py:  535]:	loss/mlm_loss, 10.337898254394531, 72
[INFO] 2021-07-12 18:04:54,339 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.099999947968172e-07, 72
[INFO] 2021-07-12 18:04:54,339 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 72
[INFO] 2021-07-12 18:04:54,340 [run_pretraining.py:  558]:	worker_index: 6, step: 72, cost: 10.337898, mlm loss: 10.337898, speed: 0.039460 steps/s, speed: 0.315679 samples/s, speed: 161.627635 tokens/s, learning rate: 7.100e-07, loss_scalings: 26214.400391, pp_loss: 10.335472
[INFO] 2021-07-12 18:04:54,340 [run_pretraining.py:  512]:	********exe.run_72******* 
[INFO] 2021-07-12 18:06:07,146 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:06:07,147 [run_pretraining.py:  534]:	loss/total_loss, 10.168787002563477, 73
[INFO] 2021-07-12 18:06:07,147 [run_pretraining.py:  535]:	loss/mlm_loss, 10.168787002563477, 73
[INFO] 2021-07-12 18:06:07,147 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.199999458862294e-07, 73
[INFO] 2021-07-12 18:06:07,147 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 73
[INFO] 2021-07-12 18:06:07,147 [run_pretraining.py:  558]:	worker_index: 6, step: 73, cost: 10.168787, mlm loss: 10.168787, speed: 0.013735 steps/s, speed: 0.109880 samples/s, speed: 56.258409 tokens/s, learning rate: 7.200e-07, loss_scalings: 26214.400391, pp_loss: 10.277174
[INFO] 2021-07-12 18:06:07,147 [run_pretraining.py:  512]:	********exe.run_73******* 
[INFO] 2021-07-12 18:06:30,303 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:06:30,304 [run_pretraining.py:  534]:	loss/total_loss, 10.346589088439941, 74
[INFO] 2021-07-12 18:06:30,304 [run_pretraining.py:  535]:	loss/mlm_loss, 10.346589088439941, 74
[INFO] 2021-07-12 18:06:30,304 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.300000106624793e-07, 74
[INFO] 2021-07-12 18:06:30,304 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 74
[INFO] 2021-07-12 18:06:30,304 [run_pretraining.py:  558]:	worker_index: 6, step: 74, cost: 10.346589, mlm loss: 10.346589, speed: 0.043184 steps/s, speed: 0.345476 samples/s, speed: 176.883602 tokens/s, learning rate: 7.300e-07, loss_scalings: 26214.400391, pp_loss: 10.311659
[INFO] 2021-07-12 18:06:30,305 [run_pretraining.py:  512]:	********exe.run_74******* 
[INFO] 2021-07-12 18:07:18,878 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:07:18,879 [run_pretraining.py:  534]:	loss/total_loss, 10.075834274291992, 75
[INFO] 2021-07-12 18:07:18,879 [run_pretraining.py:  535]:	loss/mlm_loss, 10.075834274291992, 75
[INFO] 2021-07-12 18:07:18,879 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.399999617518915e-07, 75
[INFO] 2021-07-12 18:07:18,879 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 75
[INFO] 2021-07-12 18:07:18,879 [run_pretraining.py:  558]:	worker_index: 6, step: 75, cost: 10.075834, mlm loss: 10.075834, speed: 0.020587 steps/s, speed: 0.164698 samples/s, speed: 84.325534 tokens/s, learning rate: 7.400e-07, loss_scalings: 26214.400391, pp_loss: 10.273355
[INFO] 2021-07-12 18:07:18,879 [run_pretraining.py:  512]:	********exe.run_75******* 
[INFO] 2021-07-12 18:07:19,852 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:07:19,853 [run_pretraining.py:  534]:	loss/total_loss, 10.340331077575684, 76
[INFO] 2021-07-12 18:07:19,853 [run_pretraining.py:  535]:	loss/mlm_loss, 10.340331077575684, 76
[INFO] 2021-07-12 18:07:19,853 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.499999696847226e-07, 76
[INFO] 2021-07-12 18:07:19,853 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 76
[INFO] 2021-07-12 18:07:19,853 [run_pretraining.py:  558]:	worker_index: 6, step: 76, cost: 10.340331, mlm loss: 10.340331, speed: 1.027100 steps/s, speed: 8.216797 samples/s, speed: 4206.999978 tokens/s, learning rate: 7.500e-07, loss_scalings: 26214.400391, pp_loss: 10.366335
[INFO] 2021-07-12 18:07:19,853 [run_pretraining.py:  512]:	********exe.run_76******* 
[INFO] 2021-07-12 18:07:20,834 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:07:20,834 [run_pretraining.py:  534]:	loss/total_loss, 10.316489219665527, 77
[INFO] 2021-07-12 18:07:20,834 [run_pretraining.py:  535]:	loss/mlm_loss, 10.316489219665527, 77
[INFO] 2021-07-12 18:07:20,834 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.599999776175537e-07, 77
[INFO] 2021-07-12 18:07:20,835 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 77
[INFO] 2021-07-12 18:07:20,835 [run_pretraining.py:  558]:	worker_index: 6, step: 77, cost: 10.316489, mlm loss: 10.316489, speed: 1.019770 steps/s, speed: 8.158160 samples/s, speed: 4176.978107 tokens/s, learning rate: 7.600e-07, loss_scalings: 26214.400391, pp_loss: 10.345924
[INFO] 2021-07-12 18:07:20,835 [run_pretraining.py:  512]:	********exe.run_77******* 
[INFO] 2021-07-12 18:08:10,246 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:08:10,247 [run_pretraining.py:  534]:	loss/total_loss, 10.243966102600098, 78
[INFO] 2021-07-12 18:08:10,247 [run_pretraining.py:  535]:	loss/mlm_loss, 10.243966102600098, 78
[INFO] 2021-07-12 18:08:10,247 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.699999855503847e-07, 78
[INFO] 2021-07-12 18:08:10,247 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 78
[INFO] 2021-07-12 18:08:10,247 [run_pretraining.py:  558]:	worker_index: 6, step: 78, cost: 10.243966, mlm loss: 10.243966, speed: 0.020238 steps/s, speed: 0.161905 samples/s, speed: 82.895261 tokens/s, learning rate: 7.700e-07, loss_scalings: 26214.400391, pp_loss: 10.220984
[INFO] 2021-07-12 18:08:10,247 [run_pretraining.py:  512]:	********exe.run_78******* 
[INFO] 2021-07-12 18:08:34,210 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:08:34,210 [run_pretraining.py:  534]:	loss/total_loss, 10.339381217956543, 79
[INFO] 2021-07-12 18:08:34,210 [run_pretraining.py:  535]:	loss/mlm_loss, 10.339381217956543, 79
[INFO] 2021-07-12 18:08:34,211 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.799999366397969e-07, 79
[INFO] 2021-07-12 18:08:34,211 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 79
[INFO] 2021-07-12 18:08:34,211 [run_pretraining.py:  558]:	worker_index: 6, step: 79, cost: 10.339381, mlm loss: 10.339381, speed: 0.041731 steps/s, speed: 0.333850 samples/s, speed: 170.931051 tokens/s, learning rate: 7.800e-07, loss_scalings: 26214.400391, pp_loss: 10.259857
[INFO] 2021-07-12 18:08:34,211 [run_pretraining.py:  512]:	********exe.run_79******* 
[INFO] 2021-07-12 18:08:35,165 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:08:35,165 [run_pretraining.py:  534]:	loss/total_loss, 10.37541675567627, 80
[INFO] 2021-07-12 18:08:35,166 [run_pretraining.py:  535]:	loss/mlm_loss, 10.37541675567627, 80
[INFO] 2021-07-12 18:08:35,166 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.89999944572628e-07, 80
[INFO] 2021-07-12 18:08:35,166 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 80
[INFO] 2021-07-12 18:08:35,166 [run_pretraining.py:  558]:	worker_index: 6, step: 80, cost: 10.375417, mlm loss: 10.375417, speed: 1.047871 steps/s, speed: 8.382964 samples/s, speed: 4292.077655 tokens/s, learning rate: 7.900e-07, loss_scalings: 26214.400391, pp_loss: 10.180928
[INFO] 2021-07-12 18:08:35,166 [run_pretraining.py:  512]:	********exe.run_80******* 
[INFO] 2021-07-12 18:09:23,450 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:09:23,451 [run_pretraining.py:  534]:	loss/total_loss, 9.176331520080566, 81
[INFO] 2021-07-12 18:09:23,451 [run_pretraining.py:  535]:	loss/mlm_loss, 9.176331520080566, 81
[INFO] 2021-07-12 18:09:23,451 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.000000093488779e-07, 81
[INFO] 2021-07-12 18:09:23,451 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 81
[INFO] 2021-07-12 18:09:23,451 [run_pretraining.py:  558]:	worker_index: 6, step: 81, cost: 9.176332, mlm loss: 9.176332, speed: 0.020711 steps/s, speed: 0.165684 samples/s, speed: 84.830329 tokens/s, learning rate: 8.000e-07, loss_scalings: 26214.400391, pp_loss: 10.002927
[INFO] 2021-07-12 18:09:23,451 [run_pretraining.py:  512]:	********exe.run_81******* 
[INFO] 2021-07-12 18:09:24,412 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:09:24,413 [run_pretraining.py:  534]:	loss/total_loss, 10.34558391571045, 82
[INFO] 2021-07-12 18:09:24,413 [run_pretraining.py:  535]:	loss/mlm_loss, 10.34558391571045, 82
[INFO] 2021-07-12 18:09:24,413 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.10000017281709e-07, 82
[INFO] 2021-07-12 18:09:24,413 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 82
[INFO] 2021-07-12 18:09:24,413 [run_pretraining.py:  558]:	worker_index: 6, step: 82, cost: 10.345584, mlm loss: 10.345584, speed: 1.039989 steps/s, speed: 8.319908 samples/s, speed: 4259.793119 tokens/s, learning rate: 8.100e-07, loss_scalings: 26214.400391, pp_loss: 10.246221
[INFO] 2021-07-12 18:09:24,414 [run_pretraining.py:  512]:	********exe.run_82******* 
[INFO] 2021-07-12 18:09:25,353 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:09:25,353 [run_pretraining.py:  534]:	loss/total_loss, 10.217521667480469, 83
[INFO] 2021-07-12 18:09:25,353 [run_pretraining.py:  535]:	loss/mlm_loss, 10.217521667480469, 83
[INFO] 2021-07-12 18:09:25,353 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.199999683711212e-07, 83
[INFO] 2021-07-12 18:09:25,353 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 83
[INFO] 2021-07-12 18:09:25,354 [run_pretraining.py:  558]:	worker_index: 6, step: 83, cost: 10.217522, mlm loss: 10.217522, speed: 1.064569 steps/s, speed: 8.516550 samples/s, speed: 4360.473601 tokens/s, learning rate: 8.200e-07, loss_scalings: 26214.400391, pp_loss: 10.192182
[INFO] 2021-07-12 18:09:25,354 [run_pretraining.py:  512]:	********exe.run_83******* 
[INFO] 2021-07-12 18:09:26,289 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:09:26,290 [run_pretraining.py:  534]:	loss/total_loss, 10.285872459411621, 84
[INFO] 2021-07-12 18:09:26,290 [run_pretraining.py:  535]:	loss/mlm_loss, 10.285872459411621, 84
[INFO] 2021-07-12 18:09:26,290 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.299999763039523e-07, 84
[INFO] 2021-07-12 18:09:26,290 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 84
[INFO] 2021-07-12 18:09:26,290 [run_pretraining.py:  558]:	worker_index: 6, step: 84, cost: 10.285872, mlm loss: 10.285872, speed: 1.068745 steps/s, speed: 8.549959 samples/s, speed: 4377.578774 tokens/s, learning rate: 8.300e-07, loss_scalings: 26214.400391, pp_loss: 10.215904
[INFO] 2021-07-12 18:09:26,290 [run_pretraining.py:  512]:	********exe.run_84******* 
[INFO] 2021-07-12 18:09:27,227 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:09:27,228 [run_pretraining.py:  534]:	loss/total_loss, 10.321359634399414, 85
[INFO] 2021-07-12 18:09:27,228 [run_pretraining.py:  535]:	loss/mlm_loss, 10.321359634399414, 85
[INFO] 2021-07-12 18:09:27,228 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.399999273933645e-07, 85
[INFO] 2021-07-12 18:09:27,228 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 85
[INFO] 2021-07-12 18:09:27,228 [run_pretraining.py:  558]:	worker_index: 6, step: 85, cost: 10.321360, mlm loss: 10.321360, speed: 1.066965 steps/s, speed: 8.535717 samples/s, speed: 4370.287007 tokens/s, learning rate: 8.400e-07, loss_scalings: 26214.400391, pp_loss: 9.211622
[INFO] 2021-07-12 18:09:27,228 [run_pretraining.py:  512]:	********exe.run_85******* 
[INFO] 2021-07-12 18:09:51,412 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:09:51,412 [run_pretraining.py:  534]:	loss/total_loss, 10.159194946289062, 86
[INFO] 2021-07-12 18:09:51,412 [run_pretraining.py:  535]:	loss/mlm_loss, 10.159194946289062, 86
[INFO] 2021-07-12 18:09:51,412 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.500000490130333e-07, 86
[INFO] 2021-07-12 18:09:51,413 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 86
[INFO] 2021-07-12 18:09:51,413 [run_pretraining.py:  558]:	worker_index: 6, step: 86, cost: 10.159195, mlm loss: 10.159195, speed: 0.041350 steps/s, speed: 0.330799 samples/s, speed: 169.368873 tokens/s, learning rate: 8.500e-07, loss_scalings: 26214.400391, pp_loss: 10.243941
[INFO] 2021-07-12 18:09:51,413 [run_pretraining.py:  512]:	********exe.run_86******* 
[INFO] 2021-07-12 18:10:17,857 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:10:17,858 [run_pretraining.py:  534]:	loss/total_loss, 10.236348152160645, 87
[INFO] 2021-07-12 18:10:17,858 [run_pretraining.py:  535]:	loss/mlm_loss, 10.236348152160645, 87
[INFO] 2021-07-12 18:10:17,858 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.600000001024455e-07, 87
[INFO] 2021-07-12 18:10:17,858 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 87
[INFO] 2021-07-12 18:10:17,858 [run_pretraining.py:  558]:	worker_index: 6, step: 87, cost: 10.236348, mlm loss: 10.236348, speed: 0.037814 steps/s, speed: 0.302516 samples/s, speed: 154.888160 tokens/s, learning rate: 8.600e-07, loss_scalings: 26214.400391, pp_loss: 10.270253
[INFO] 2021-07-12 18:10:17,858 [run_pretraining.py:  512]:	********exe.run_87******* 
[INFO] 2021-07-12 18:10:43,547 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:10:43,547 [run_pretraining.py:  534]:	loss/total_loss, 10.293427467346191, 88
[INFO] 2021-07-12 18:10:43,547 [run_pretraining.py:  535]:	loss/mlm_loss, 10.293427467346191, 88
[INFO] 2021-07-12 18:10:43,548 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.700000080352766e-07, 88
[INFO] 2021-07-12 18:10:43,548 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 88
[INFO] 2021-07-12 18:10:43,548 [run_pretraining.py:  558]:	worker_index: 6, step: 88, cost: 10.293427, mlm loss: 10.293427, speed: 0.038928 steps/s, speed: 0.311421 samples/s, speed: 159.447649 tokens/s, learning rate: 8.700e-07, loss_scalings: 26214.400391, pp_loss: 10.263132
[INFO] 2021-07-12 18:10:43,548 [run_pretraining.py:  512]:	********exe.run_88******* 
[INFO] 2021-07-12 18:11:07,456 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:11:07,456 [run_pretraining.py:  534]:	loss/total_loss, 10.362539291381836, 89
[INFO] 2021-07-12 18:11:07,456 [run_pretraining.py:  535]:	loss/mlm_loss, 10.362539291381836, 89
[INFO] 2021-07-12 18:11:07,457 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.799999591246888e-07, 89
[INFO] 2021-07-12 18:11:07,457 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 89
[INFO] 2021-07-12 18:11:07,457 [run_pretraining.py:  558]:	worker_index: 6, step: 89, cost: 10.362539, mlm loss: 10.362539, speed: 0.041827 steps/s, speed: 0.334613 samples/s, speed: 171.321614 tokens/s, learning rate: 8.800e-07, loss_scalings: 26214.400391, pp_loss: 10.263308
[INFO] 2021-07-12 18:11:07,457 [run_pretraining.py:  512]:	********exe.run_89******* 
[INFO] 2021-07-12 18:11:57,427 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:11:57,428 [run_pretraining.py:  534]:	loss/total_loss, 10.076005935668945, 90
[INFO] 2021-07-12 18:11:57,428 [run_pretraining.py:  535]:	loss/mlm_loss, 10.076005935668945, 90
[INFO] 2021-07-12 18:11:57,428 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.899999670575198e-07, 90
[INFO] 2021-07-12 18:11:57,428 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 90
[INFO] 2021-07-12 18:11:57,428 [run_pretraining.py:  558]:	worker_index: 6, step: 90, cost: 10.076006, mlm loss: 10.076006, speed: 0.020012 steps/s, speed: 0.160094 samples/s, speed: 81.968224 tokens/s, learning rate: 8.900e-07, loss_scalings: 26214.400391, pp_loss: 9.509511
[INFO] 2021-07-12 18:11:57,428 [run_pretraining.py:  512]:	********exe.run_90******* 
[INFO] 2021-07-12 18:11:58,366 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:11:58,366 [run_pretraining.py:  534]:	loss/total_loss, 10.227132797241211, 91
[INFO] 2021-07-12 18:11:58,366 [run_pretraining.py:  535]:	loss/mlm_loss, 10.227132797241211, 91
[INFO] 2021-07-12 18:11:58,367 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.99999918146932e-07, 91
[INFO] 2021-07-12 18:11:58,367 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 91
[INFO] 2021-07-12 18:11:58,367 [run_pretraining.py:  558]:	worker_index: 6, step: 91, cost: 10.227133, mlm loss: 10.227133, speed: 1.066096 steps/s, speed: 8.528768 samples/s, speed: 4366.729029 tokens/s, learning rate: 9.000e-07, loss_scalings: 26214.400391, pp_loss: 9.247061
[INFO] 2021-07-12 18:11:58,367 [run_pretraining.py:  512]:	********exe.run_91******* 
[INFO] 2021-07-12 18:11:59,304 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:11:59,305 [run_pretraining.py:  534]:	loss/total_loss, 10.223165512084961, 92
[INFO] 2021-07-12 18:11:59,305 [run_pretraining.py:  535]:	loss/mlm_loss, 10.223165512084961, 92
[INFO] 2021-07-12 18:11:59,305 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.100000397666008e-07, 92
[INFO] 2021-07-12 18:11:59,305 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 92
[INFO] 2021-07-12 18:11:59,305 [run_pretraining.py:  558]:	worker_index: 6, step: 92, cost: 10.223166, mlm loss: 10.223166, speed: 1.066466 steps/s, speed: 8.531728 samples/s, speed: 4368.244599 tokens/s, learning rate: 9.100e-07, loss_scalings: 26214.400391, pp_loss: 10.205139
[INFO] 2021-07-12 18:11:59,305 [run_pretraining.py:  512]:	********exe.run_92******* 
[INFO] 2021-07-12 18:12:00,238 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:12:00,238 [run_pretraining.py:  534]:	loss/total_loss, 10.214982986450195, 93
[INFO] 2021-07-12 18:12:00,239 [run_pretraining.py:  535]:	loss/mlm_loss, 10.214982986450195, 93
[INFO] 2021-07-12 18:12:00,239 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.19999990856013e-07, 93
[INFO] 2021-07-12 18:12:00,239 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 93
[INFO] 2021-07-12 18:12:00,239 [run_pretraining.py:  558]:	worker_index: 6, step: 93, cost: 10.214983, mlm loss: 10.214983, speed: 1.071827 steps/s, speed: 8.574615 samples/s, speed: 4390.202869 tokens/s, learning rate: 9.200e-07, loss_scalings: 26214.400391, pp_loss: 10.224564
[INFO] 2021-07-12 18:12:00,239 [run_pretraining.py:  512]:	********exe.run_93******* 
[INFO] 2021-07-12 18:12:01,184 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:12:01,185 [run_pretraining.py:  534]:	loss/total_loss, 10.340295791625977, 94
[INFO] 2021-07-12 18:12:01,185 [run_pretraining.py:  535]:	loss/mlm_loss, 10.340295791625977, 94
[INFO] 2021-07-12 18:12:01,185 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.299999987888441e-07, 94
[INFO] 2021-07-12 18:12:01,185 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 94
[INFO] 2021-07-12 18:12:01,185 [run_pretraining.py:  558]:	worker_index: 6, step: 94, cost: 10.340296, mlm loss: 10.340296, speed: 1.057320 steps/s, speed: 8.458562 samples/s, speed: 4330.783962 tokens/s, learning rate: 9.300e-07, loss_scalings: 26214.400391, pp_loss: 10.201303
[INFO] 2021-07-12 18:12:01,185 [run_pretraining.py:  512]:	********exe.run_94******* 
[INFO] 2021-07-12 18:12:26,866 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:12:26,867 [run_pretraining.py:  534]:	loss/total_loss, 10.203422546386719, 95
[INFO] 2021-07-12 18:12:26,867 [run_pretraining.py:  535]:	loss/mlm_loss, 10.203422546386719, 95
[INFO] 2021-07-12 18:12:26,867 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.399999498782563e-07, 95
[INFO] 2021-07-12 18:12:26,867 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 95
[INFO] 2021-07-12 18:12:26,867 [run_pretraining.py:  558]:	worker_index: 6, step: 95, cost: 10.203423, mlm loss: 10.203423, speed: 0.038940 steps/s, speed: 0.311518 samples/s, speed: 159.497113 tokens/s, learning rate: 9.400e-07, loss_scalings: 26214.400391, pp_loss: 10.242572
[INFO] 2021-07-12 18:12:26,867 [run_pretraining.py:  512]:	********exe.run_95******* 
[INFO] 2021-07-12 18:12:27,820 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:12:27,821 [run_pretraining.py:  534]:	loss/total_loss, 10.0310697555542, 96
[INFO] 2021-07-12 18:12:27,821 [run_pretraining.py:  535]:	loss/mlm_loss, 10.0310697555542, 96
[INFO] 2021-07-12 18:12:27,821 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.499999578110874e-07, 96
[INFO] 2021-07-12 18:12:27,821 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 96
[INFO] 2021-07-12 18:12:27,821 [run_pretraining.py:  558]:	worker_index: 6, step: 96, cost: 10.031070, mlm loss: 10.031070, speed: 1.048933 steps/s, speed: 8.391461 samples/s, speed: 4296.428082 tokens/s, learning rate: 9.500e-07, loss_scalings: 26214.400391, pp_loss: 10.087235
[INFO] 2021-07-12 18:12:27,821 [run_pretraining.py:  512]:	********exe.run_96******* 
[INFO] 2021-07-12 18:12:51,369 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:12:51,370 [run_pretraining.py:  534]:	loss/total_loss, 10.216069221496582, 97
[INFO] 2021-07-12 18:12:51,370 [run_pretraining.py:  535]:	loss/mlm_loss, 10.216069221496582, 97
[INFO] 2021-07-12 18:12:51,370 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.599999657439184e-07, 97
[INFO] 2021-07-12 18:12:51,371 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 97
[INFO] 2021-07-12 18:12:51,371 [run_pretraining.py:  558]:	worker_index: 6, step: 97, cost: 10.216069, mlm loss: 10.216069, speed: 0.042465 steps/s, speed: 0.339720 samples/s, speed: 173.936521 tokens/s, learning rate: 9.600e-07, loss_scalings: 26214.400391, pp_loss: 10.196565
[INFO] 2021-07-12 18:12:51,371 [run_pretraining.py:  512]:	********exe.run_97******* 
[INFO] 2021-07-12 18:12:52,318 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:12:52,318 [run_pretraining.py:  534]:	loss/total_loss, 10.238845825195312, 98
[INFO] 2021-07-12 18:12:52,318 [run_pretraining.py:  535]:	loss/mlm_loss, 10.238845825195312, 98
[INFO] 2021-07-12 18:12:52,319 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.699999736767495e-07, 98
[INFO] 2021-07-12 18:12:52,319 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 98
[INFO] 2021-07-12 18:12:52,319 [run_pretraining.py:  558]:	worker_index: 6, step: 98, cost: 10.238846, mlm loss: 10.238846, speed: 1.055476 steps/s, speed: 8.443807 samples/s, speed: 4323.229327 tokens/s, learning rate: 9.700e-07, loss_scalings: 26214.400391, pp_loss: 10.192465
[INFO] 2021-07-12 18:12:52,319 [run_pretraining.py:  512]:	********exe.run_98******* 
[INFO] 2021-07-12 18:13:17,570 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:13:17,571 [run_pretraining.py:  534]:	loss/total_loss, 9.977472305297852, 99
[INFO] 2021-07-12 18:13:17,571 [run_pretraining.py:  535]:	loss/mlm_loss, 9.977472305297852, 99
[INFO] 2021-07-12 18:13:17,571 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.799999816095806e-07, 99
[INFO] 2021-07-12 18:13:17,571 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 99
[INFO] 2021-07-12 18:13:17,571 [run_pretraining.py:  558]:	worker_index: 6, step: 99, cost: 9.977472, mlm loss: 9.977472, speed: 0.039601 steps/s, speed: 0.316812 samples/s, speed: 162.207712 tokens/s, learning rate: 9.800e-07, loss_scalings: 26214.400391, pp_loss: 10.131275
[INFO] 2021-07-12 18:13:17,571 [run_pretraining.py:  512]:	********exe.run_99******* 
[INFO] 2021-07-12 18:13:18,513 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:13:18,514 [run_pretraining.py:  534]:	loss/total_loss, 10.159461975097656, 100
[INFO] 2021-07-12 18:13:18,514 [run_pretraining.py:  535]:	loss/mlm_loss, 10.159461975097656, 100
[INFO] 2021-07-12 18:13:18,514 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.899999895424116e-07, 100
[INFO] 2021-07-12 18:13:18,514 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 100
[INFO] 2021-07-12 18:13:18,514 [run_pretraining.py:  558]:	worker_index: 6, step: 100, cost: 10.159462, mlm loss: 10.159462, speed: 1.061054 steps/s, speed: 8.488434 samples/s, speed: 4346.078263 tokens/s, learning rate: 9.900e-07, loss_scalings: 26214.400391, pp_loss: 10.176970
[INFO] 2021-07-12 18:13:18,514 [run_pretraining.py:  512]:	********exe.run_100******* 
[INFO] 2021-07-12 18:13:19,453 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:13:19,453 [run_pretraining.py:  534]:	loss/total_loss, 10.29177188873291, 101
[INFO] 2021-07-12 18:13:19,453 [run_pretraining.py:  535]:	loss/mlm_loss, 10.29177188873291, 101
[INFO] 2021-07-12 18:13:19,453 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.999999974752427e-07, 101
[INFO] 2021-07-12 18:13:19,453 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 101
[INFO] 2021-07-12 18:13:19,454 [run_pretraining.py:  558]:	worker_index: 6, step: 101, cost: 10.291772, mlm loss: 10.291772, speed: 1.065490 steps/s, speed: 8.523919 samples/s, speed: 4364.246435 tokens/s, learning rate: 1.000e-06, loss_scalings: 26214.400391, pp_loss: 10.213899
[INFO] 2021-07-12 18:13:19,454 [run_pretraining.py:  512]:	********exe.run_101******* 
[INFO] 2021-07-12 18:13:44,827 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:13:44,828 [run_pretraining.py:  534]:	loss/total_loss, 10.213160514831543, 102
[INFO] 2021-07-12 18:13:44,828 [run_pretraining.py:  535]:	loss/mlm_loss, 10.213160514831543, 102
[INFO] 2021-07-12 18:13:44,828 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.009999891721236e-06, 102
[INFO] 2021-07-12 18:13:44,828 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 102
[INFO] 2021-07-12 18:13:44,828 [run_pretraining.py:  558]:	worker_index: 6, step: 102, cost: 10.213161, mlm loss: 10.213161, speed: 0.039411 steps/s, speed: 0.315284 samples/s, speed: 161.425563 tokens/s, learning rate: 1.010e-06, loss_scalings: 26214.400391, pp_loss: 10.155518
[INFO] 2021-07-12 18:13:44,828 [run_pretraining.py:  512]:	********exe.run_102******* 
[INFO] 2021-07-12 18:13:45,822 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:13:45,822 [run_pretraining.py:  534]:	loss/total_loss, 10.126349449157715, 103
[INFO] 2021-07-12 18:13:45,822 [run_pretraining.py:  535]:	loss/mlm_loss, 10.126349449157715, 103
[INFO] 2021-07-12 18:13:45,822 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0200000133409048e-06, 103
[INFO] 2021-07-12 18:13:45,823 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 103
[INFO] 2021-07-12 18:13:45,823 [run_pretraining.py:  558]:	worker_index: 6, step: 103, cost: 10.126349, mlm loss: 10.126349, speed: 1.006244 steps/s, speed: 8.049954 samples/s, speed: 4121.576686 tokens/s, learning rate: 1.020e-06, loss_scalings: 26214.400391, pp_loss: 10.214191
[INFO] 2021-07-12 18:13:45,823 [run_pretraining.py:  512]:	********exe.run_103******* 
[INFO] 2021-07-12 18:14:11,859 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:14:11,860 [run_pretraining.py:  534]:	loss/total_loss, 10.076324462890625, 104
[INFO] 2021-07-12 18:14:11,860 [run_pretraining.py:  535]:	loss/mlm_loss, 10.076324462890625, 104
[INFO] 2021-07-12 18:14:11,860 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.030000021273736e-06, 104
[INFO] 2021-07-12 18:14:11,860 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 104
[INFO] 2021-07-12 18:14:11,860 [run_pretraining.py:  558]:	worker_index: 6, step: 104, cost: 10.076324, mlm loss: 10.076324, speed: 0.038408 steps/s, speed: 0.307260 samples/s, speed: 157.317242 tokens/s, learning rate: 1.030e-06, loss_scalings: 26214.400391, pp_loss: 10.168259
[INFO] 2021-07-12 18:14:11,860 [run_pretraining.py:  512]:	********exe.run_104******* 
[INFO] 2021-07-12 18:14:37,268 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:14:37,269 [run_pretraining.py:  534]:	loss/total_loss, 10.188233375549316, 105
[INFO] 2021-07-12 18:14:37,269 [run_pretraining.py:  535]:	loss/mlm_loss, 10.188233375549316, 105
[INFO] 2021-07-12 18:14:37,269 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.040000029206567e-06, 105
[INFO] 2021-07-12 18:14:37,269 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 105
[INFO] 2021-07-12 18:14:37,269 [run_pretraining.py:  558]:	worker_index: 6, step: 105, cost: 10.188233, mlm loss: 10.188233, speed: 0.039357 steps/s, speed: 0.314860 samples/s, speed: 161.208201 tokens/s, learning rate: 1.040e-06, loss_scalings: 26214.400391, pp_loss: 10.178582
[INFO] 2021-07-12 18:14:37,269 [run_pretraining.py:  512]:	********exe.run_105******* 
[INFO] 2021-07-12 18:14:38,251 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:14:38,252 [run_pretraining.py:  534]:	loss/total_loss, 10.111189842224121, 106
[INFO] 2021-07-12 18:14:38,252 [run_pretraining.py:  535]:	loss/mlm_loss, 10.111189842224121, 106
[INFO] 2021-07-12 18:14:38,252 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0499999234525603e-06, 106
[INFO] 2021-07-12 18:14:38,252 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 106
[INFO] 2021-07-12 18:14:38,252 [run_pretraining.py:  558]:	worker_index: 6, step: 106, cost: 10.111190, mlm loss: 10.111190, speed: 1.017912 steps/s, speed: 8.143293 samples/s, speed: 4169.366182 tokens/s, learning rate: 1.050e-06, loss_scalings: 26214.400391, pp_loss: 10.112768
[INFO] 2021-07-12 18:14:38,252 [run_pretraining.py:  512]:	********exe.run_106******* 
[INFO] 2021-07-12 18:14:39,218 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:14:39,218 [run_pretraining.py:  534]:	loss/total_loss, 10.207728385925293, 107
[INFO] 2021-07-12 18:14:39,218 [run_pretraining.py:  535]:	loss/mlm_loss, 10.207728385925293, 107
[INFO] 2021-07-12 18:14:39,218 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0599999313853914e-06, 107
[INFO] 2021-07-12 18:14:39,218 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 107
[INFO] 2021-07-12 18:14:39,219 [run_pretraining.py:  558]:	worker_index: 6, step: 107, cost: 10.207728, mlm loss: 10.207728, speed: 1.035512 steps/s, speed: 8.284096 samples/s, speed: 4241.457074 tokens/s, learning rate: 1.060e-06, loss_scalings: 26214.400391, pp_loss: 10.036577
[INFO] 2021-07-12 18:14:39,219 [run_pretraining.py:  512]:	********exe.run_107******* 
[INFO] 2021-07-12 18:14:40,185 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:14:40,186 [run_pretraining.py:  534]:	loss/total_loss, 10.241093635559082, 108
[INFO] 2021-07-12 18:14:40,186 [run_pretraining.py:  535]:	loss/mlm_loss, 10.241093635559082, 108
[INFO] 2021-07-12 18:14:40,186 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0700000530050602e-06, 108
[INFO] 2021-07-12 18:14:40,186 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 108
[INFO] 2021-07-12 18:14:40,186 [run_pretraining.py:  558]:	worker_index: 6, step: 108, cost: 10.241094, mlm loss: 10.241094, speed: 1.034300 steps/s, speed: 8.274397 samples/s, speed: 4236.491011 tokens/s, learning rate: 1.070e-06, loss_scalings: 26214.400391, pp_loss: 10.134935
[INFO] 2021-07-12 18:14:40,186 [run_pretraining.py:  512]:	********exe.run_108******* 
[INFO] 2021-07-12 18:14:41,125 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:14:41,126 [run_pretraining.py:  534]:	loss/total_loss, 10.013622283935547, 109
[INFO] 2021-07-12 18:14:41,126 [run_pretraining.py:  535]:	loss/mlm_loss, 10.013622283935547, 109
[INFO] 2021-07-12 18:14:41,126 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0799999472510535e-06, 109
[INFO] 2021-07-12 18:14:41,126 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 109
[INFO] 2021-07-12 18:14:41,126 [run_pretraining.py:  558]:	worker_index: 6, step: 109, cost: 10.013622, mlm loss: 10.013622, speed: 1.064844 steps/s, speed: 8.518753 samples/s, speed: 4361.601665 tokens/s, learning rate: 1.080e-06, loss_scalings: 26214.400391, pp_loss: 10.020313
[INFO] 2021-07-12 18:14:41,126 [run_pretraining.py:  512]:	********exe.run_109******* 
[INFO] 2021-07-12 18:14:42,053 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:14:42,054 [run_pretraining.py:  534]:	loss/total_loss, 10.088421821594238, 110
[INFO] 2021-07-12 18:14:42,054 [run_pretraining.py:  535]:	loss/mlm_loss, 10.088421821594238, 110
[INFO] 2021-07-12 18:14:42,054 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0899999551838846e-06, 110
[INFO] 2021-07-12 18:14:42,054 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 110
[INFO] 2021-07-12 18:14:42,055 [run_pretraining.py:  558]:	worker_index: 6, step: 110, cost: 10.088422, mlm loss: 10.088422, speed: 1.077798 steps/s, speed: 8.622380 samples/s, speed: 4414.658624 tokens/s, learning rate: 1.090e-06, loss_scalings: 26214.400391, pp_loss: 10.097903
[INFO] 2021-07-12 18:14:42,055 [run_pretraining.py:  512]:	********exe.run_110******* 
[INFO] 2021-07-12 18:14:42,994 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:14:42,994 [run_pretraining.py:  534]:	loss/total_loss, 9.893547058105469, 111
[INFO] 2021-07-12 18:14:42,994 [run_pretraining.py:  535]:	loss/mlm_loss, 9.893547058105469, 111
[INFO] 2021-07-12 18:14:42,994 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0999999631167157e-06, 111
[INFO] 2021-07-12 18:14:42,995 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 111
[INFO] 2021-07-12 18:14:42,995 [run_pretraining.py:  558]:	worker_index: 6, step: 111, cost: 9.893547, mlm loss: 9.893547, speed: 1.064513 steps/s, speed: 8.516103 samples/s, speed: 4360.244517 tokens/s, learning rate: 1.100e-06, loss_scalings: 26214.400391, pp_loss: 10.088460
[INFO] 2021-07-12 18:14:42,995 [run_pretraining.py:  512]:	********exe.run_111******* 
[INFO] 2021-07-12 18:14:43,928 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:14:43,929 [run_pretraining.py:  534]:	loss/total_loss, 10.164972305297852, 112
[INFO] 2021-07-12 18:14:43,929 [run_pretraining.py:  535]:	loss/mlm_loss, 10.164972305297852, 112
[INFO] 2021-07-12 18:14:43,929 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1099999710495467e-06, 112
[INFO] 2021-07-12 18:14:43,929 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 112
[INFO] 2021-07-12 18:14:43,930 [run_pretraining.py:  558]:	worker_index: 6, step: 112, cost: 10.164972, mlm loss: 10.164972, speed: 1.070510 steps/s, speed: 8.564080 samples/s, speed: 4384.808738 tokens/s, learning rate: 1.110e-06, loss_scalings: 26214.400391, pp_loss: 10.170097
[INFO] 2021-07-12 18:14:43,930 [run_pretraining.py:  512]:	********exe.run_112******* 
[INFO] 2021-07-12 18:14:44,859 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:14:44,860 [run_pretraining.py:  534]:	loss/total_loss, 10.175283432006836, 113
[INFO] 2021-07-12 18:14:44,860 [run_pretraining.py:  535]:	loss/mlm_loss, 10.175283432006836, 113
[INFO] 2021-07-12 18:14:44,860 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1199999789823778e-06, 113
[INFO] 2021-07-12 18:14:44,860 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 113
[INFO] 2021-07-12 18:14:44,860 [run_pretraining.py:  558]:	worker_index: 6, step: 113, cost: 10.175283, mlm loss: 10.175283, speed: 1.075469 steps/s, speed: 8.603753 samples/s, speed: 4405.121771 tokens/s, learning rate: 1.120e-06, loss_scalings: 26214.400391, pp_loss: 10.116362
[INFO] 2021-07-12 18:14:44,860 [run_pretraining.py:  512]:	********exe.run_113******* 
[INFO] 2021-07-12 18:15:08,562 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:15:08,563 [run_pretraining.py:  534]:	loss/total_loss, 10.153146743774414, 114
[INFO] 2021-07-12 18:15:08,563 [run_pretraining.py:  535]:	loss/mlm_loss, 10.153146743774414, 114
[INFO] 2021-07-12 18:15:08,563 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1299999869152089e-06, 114
[INFO] 2021-07-12 18:15:08,563 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 114
[INFO] 2021-07-12 18:15:08,563 [run_pretraining.py:  558]:	worker_index: 6, step: 114, cost: 10.153147, mlm loss: 10.153147, speed: 0.042190 steps/s, speed: 0.337518 samples/s, speed: 172.809454 tokens/s, learning rate: 1.130e-06, loss_scalings: 26214.400391, pp_loss: 10.105848
[INFO] 2021-07-12 18:15:08,563 [run_pretraining.py:  512]:	********exe.run_114******* 
[INFO] 2021-07-12 18:15:33,786 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:15:33,787 [run_pretraining.py:  534]:	loss/total_loss, 10.126867294311523, 115
[INFO] 2021-07-12 18:15:33,787 [run_pretraining.py:  535]:	loss/mlm_loss, 10.126867294311523, 115
[INFO] 2021-07-12 18:15:33,787 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.13999999484804e-06, 115
[INFO] 2021-07-12 18:15:33,787 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 115
[INFO] 2021-07-12 18:15:33,787 [run_pretraining.py:  558]:	worker_index: 6, step: 115, cost: 10.126867, mlm loss: 10.126867, speed: 0.039646 steps/s, speed: 0.317167 samples/s, speed: 162.389422 tokens/s, learning rate: 1.140e-06, loss_scalings: 26214.400391, pp_loss: 10.145013
[INFO] 2021-07-12 18:15:33,787 [run_pretraining.py:  512]:	********exe.run_115******* 
[INFO] 2021-07-12 18:15:34,728 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:15:34,729 [run_pretraining.py:  534]:	loss/total_loss, 10.058342933654785, 116
[INFO] 2021-07-12 18:15:34,729 [run_pretraining.py:  535]:	loss/mlm_loss, 10.058342933654785, 116
[INFO] 2021-07-12 18:15:34,729 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.150000002780871e-06, 116
[INFO] 2021-07-12 18:15:34,729 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 116
[INFO] 2021-07-12 18:15:34,729 [run_pretraining.py:  558]:	worker_index: 6, step: 116, cost: 10.058343, mlm loss: 10.058343, speed: 1.062812 steps/s, speed: 8.502495 samples/s, speed: 4353.277268 tokens/s, learning rate: 1.150e-06, loss_scalings: 26214.400391, pp_loss: 10.095662
[INFO] 2021-07-12 18:15:34,729 [run_pretraining.py:  512]:	********exe.run_116******* 
[INFO] 2021-07-12 18:15:35,675 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:15:35,676 [run_pretraining.py:  534]:	loss/total_loss, 10.01315689086914, 117
[INFO] 2021-07-12 18:15:35,676 [run_pretraining.py:  535]:	loss/mlm_loss, 10.01315689086914, 117
[INFO] 2021-07-12 18:15:35,676 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.160000010713702e-06, 117
[INFO] 2021-07-12 18:15:35,676 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 117
[INFO] 2021-07-12 18:15:35,676 [run_pretraining.py:  558]:	worker_index: 6, step: 117, cost: 10.013157, mlm loss: 10.013157, speed: 1.056638 steps/s, speed: 8.453107 samples/s, speed: 4327.990949 tokens/s, learning rate: 1.160e-06, loss_scalings: 26214.400391, pp_loss: 10.055412
[INFO] 2021-07-12 18:15:35,676 [run_pretraining.py:  512]:	********exe.run_117******* 
[INFO] 2021-07-12 18:16:01,599 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:16:01,600 [run_pretraining.py:  534]:	loss/total_loss, 10.052002906799316, 118
[INFO] 2021-07-12 18:16:01,600 [run_pretraining.py:  535]:	loss/mlm_loss, 10.052002906799316, 118
[INFO] 2021-07-12 18:16:01,600 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1699999049596954e-06, 118
[INFO] 2021-07-12 18:16:01,600 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 118
[INFO] 2021-07-12 18:16:01,600 [run_pretraining.py:  558]:	worker_index: 6, step: 118, cost: 10.052003, mlm loss: 10.052003, speed: 0.038575 steps/s, speed: 0.308598 samples/s, speed: 158.002218 tokens/s, learning rate: 1.170e-06, loss_scalings: 26214.400391, pp_loss: 10.114025
[INFO] 2021-07-12 18:16:01,601 [run_pretraining.py:  512]:	********exe.run_118******* 
[INFO] 2021-07-12 18:16:02,555 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:16:02,555 [run_pretraining.py:  534]:	loss/total_loss, 10.0697660446167, 119
[INFO] 2021-07-12 18:16:02,555 [run_pretraining.py:  535]:	loss/mlm_loss, 10.0697660446167, 119
[INFO] 2021-07-12 18:16:02,555 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1800000265793642e-06, 119
[INFO] 2021-07-12 18:16:02,556 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 119
[INFO] 2021-07-12 18:16:02,556 [run_pretraining.py:  558]:	worker_index: 6, step: 119, cost: 10.069766, mlm loss: 10.069766, speed: 1.047793 steps/s, speed: 8.382340 samples/s, speed: 4291.758134 tokens/s, learning rate: 1.180e-06, loss_scalings: 26214.400391, pp_loss: 8.935927
[INFO] 2021-07-12 18:16:02,556 [run_pretraining.py:  512]:	********exe.run_119******* 
[INFO] 2021-07-12 18:16:03,485 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:16:03,486 [run_pretraining.py:  534]:	loss/total_loss, 10.019197463989258, 120
[INFO] 2021-07-12 18:16:03,486 [run_pretraining.py:  535]:	loss/mlm_loss, 10.019197463989258, 120
[INFO] 2021-07-12 18:16:03,486 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1900000345121953e-06, 120
[INFO] 2021-07-12 18:16:03,486 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 120
[INFO] 2021-07-12 18:16:03,486 [run_pretraining.py:  558]:	worker_index: 6, step: 120, cost: 10.019197, mlm loss: 10.019197, speed: 1.075200 steps/s, speed: 8.601601 samples/s, speed: 4404.019630 tokens/s, learning rate: 1.190e-06, loss_scalings: 26214.400391, pp_loss: 10.034728
[INFO] 2021-07-12 18:16:03,486 [run_pretraining.py:  512]:	********exe.run_120******* 
[INFO] 2021-07-12 18:16:04,415 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:16:04,416 [run_pretraining.py:  534]:	loss/total_loss, 10.018964767456055, 121
[INFO] 2021-07-12 18:16:04,416 [run_pretraining.py:  535]:	loss/mlm_loss, 10.018964767456055, 121
[INFO] 2021-07-12 18:16:04,416 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1999999287581886e-06, 121
[INFO] 2021-07-12 18:16:04,416 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 121
[INFO] 2021-07-12 18:16:04,416 [run_pretraining.py:  558]:	worker_index: 6, step: 121, cost: 10.018965, mlm loss: 10.018965, speed: 1.076162 steps/s, speed: 8.609299 samples/s, speed: 4407.960967 tokens/s, learning rate: 1.200e-06, loss_scalings: 26214.400391, pp_loss: 10.112713
[INFO] 2021-07-12 18:16:04,416 [run_pretraining.py:  512]:	********exe.run_121******* 
[INFO] 2021-07-12 18:16:30,650 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:16:30,650 [run_pretraining.py:  534]:	loss/total_loss, 10.054707527160645, 122
[INFO] 2021-07-12 18:16:30,650 [run_pretraining.py:  535]:	loss/mlm_loss, 10.054707527160645, 122
[INFO] 2021-07-12 18:16:30,651 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2099999366910197e-06, 122
[INFO] 2021-07-12 18:16:30,651 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 122
[INFO] 2021-07-12 18:16:30,651 [run_pretraining.py:  558]:	worker_index: 6, step: 122, cost: 10.054708, mlm loss: 10.054708, speed: 0.038119 steps/s, speed: 0.304951 samples/s, speed: 156.134952 tokens/s, learning rate: 1.210e-06, loss_scalings: 26214.400391, pp_loss: 10.025128
[INFO] 2021-07-12 18:16:30,651 [run_pretraining.py:  512]:	********exe.run_122******* 
[INFO] 2021-07-12 18:16:31,599 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:16:31,600 [run_pretraining.py:  534]:	loss/total_loss, 9.955450057983398, 123
[INFO] 2021-07-12 18:16:31,600 [run_pretraining.py:  535]:	loss/mlm_loss, 9.955450057983398, 123
[INFO] 2021-07-12 18:16:31,600 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2199999446238508e-06, 123
[INFO] 2021-07-12 18:16:31,600 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 123
[INFO] 2021-07-12 18:16:31,600 [run_pretraining.py:  558]:	worker_index: 6, step: 123, cost: 9.955450, mlm loss: 9.955450, speed: 1.053900 steps/s, speed: 8.431200 samples/s, speed: 4316.774562 tokens/s, learning rate: 1.220e-06, loss_scalings: 26214.400391, pp_loss: 10.096887
[INFO] 2021-07-12 18:16:31,600 [run_pretraining.py:  512]:	********exe.run_123******* 
[INFO] 2021-07-12 18:16:32,545 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:16:32,546 [run_pretraining.py:  534]:	loss/total_loss, 10.035747528076172, 124
[INFO] 2021-07-12 18:16:32,546 [run_pretraining.py:  535]:	loss/mlm_loss, 10.035747528076172, 124
[INFO] 2021-07-12 18:16:32,546 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2299999525566818e-06, 124
[INFO] 2021-07-12 18:16:32,546 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 124
[INFO] 2021-07-12 18:16:32,546 [run_pretraining.py:  558]:	worker_index: 6, step: 124, cost: 10.035748, mlm loss: 10.035748, speed: 1.057912 steps/s, speed: 8.463299 samples/s, speed: 4333.208948 tokens/s, learning rate: 1.230e-06, loss_scalings: 26214.400391, pp_loss: 10.052418
[INFO] 2021-07-12 18:16:32,546 [run_pretraining.py:  512]:	********exe.run_124******* 
[INFO] 2021-07-12 18:16:33,484 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:16:33,484 [run_pretraining.py:  534]:	loss/total_loss, 10.057273864746094, 125
[INFO] 2021-07-12 18:16:33,484 [run_pretraining.py:  535]:	loss/mlm_loss, 10.057273864746094, 125
[INFO] 2021-07-12 18:16:33,484 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2399999604895129e-06, 125
[INFO] 2021-07-12 18:16:33,485 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 125
[INFO] 2021-07-12 18:16:33,485 [run_pretraining.py:  558]:	worker_index: 6, step: 125, cost: 10.057274, mlm loss: 10.057274, speed: 1.066617 steps/s, speed: 8.532938 samples/s, speed: 4368.864454 tokens/s, learning rate: 1.240e-06, loss_scalings: 26214.400391, pp_loss: 9.981481
[INFO] 2021-07-12 18:16:33,485 [run_pretraining.py:  512]:	********exe.run_125******* 
[INFO] 2021-07-12 18:16:58,770 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:16:58,770 [run_pretraining.py:  534]:	loss/total_loss, 10.100251197814941, 126
[INFO] 2021-07-12 18:16:58,771 [run_pretraining.py:  535]:	loss/mlm_loss, 10.100251197814941, 126
[INFO] 2021-07-12 18:16:58,771 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.249999968422344e-06, 126
[INFO] 2021-07-12 18:16:58,771 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 126
[INFO] 2021-07-12 18:16:58,771 [run_pretraining.py:  558]:	worker_index: 6, step: 126, cost: 10.100251, mlm loss: 10.100251, speed: 0.039548 steps/s, speed: 0.316388 samples/s, speed: 161.990577 tokens/s, learning rate: 1.250e-06, loss_scalings: 26214.400391, pp_loss: 10.037000
[INFO] 2021-07-12 18:16:58,771 [run_pretraining.py:  512]:	********exe.run_126******* 
[INFO] 2021-07-12 18:16:59,707 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:16:59,708 [run_pretraining.py:  534]:	loss/total_loss, 10.296786308288574, 127
[INFO] 2021-07-12 18:16:59,708 [run_pretraining.py:  535]:	loss/mlm_loss, 10.296786308288574, 127
[INFO] 2021-07-12 18:16:59,708 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.259999976355175e-06, 127
[INFO] 2021-07-12 18:16:59,708 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 127
[INFO] 2021-07-12 18:16:59,708 [run_pretraining.py:  558]:	worker_index: 6, step: 127, cost: 10.296786, mlm loss: 10.296786, speed: 1.067868 steps/s, speed: 8.542943 samples/s, speed: 4373.986645 tokens/s, learning rate: 1.260e-06, loss_scalings: 26214.400391, pp_loss: 10.162448
[INFO] 2021-07-12 18:16:59,708 [run_pretraining.py:  512]:	********exe.run_127******* 
[INFO] 2021-07-12 18:17:26,178 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:17:26,179 [run_pretraining.py:  534]:	loss/total_loss, 9.990477561950684, 128
[INFO] 2021-07-12 18:17:26,179 [run_pretraining.py:  535]:	loss/mlm_loss, 9.990477561950684, 128
[INFO] 2021-07-12 18:17:26,179 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.269999984288006e-06, 128
[INFO] 2021-07-12 18:17:26,179 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 128
[INFO] 2021-07-12 18:17:26,179 [run_pretraining.py:  558]:	worker_index: 6, step: 128, cost: 9.990478, mlm loss: 9.990478, speed: 0.037778 steps/s, speed: 0.302224 samples/s, speed: 154.738518 tokens/s, learning rate: 1.270e-06, loss_scalings: 26214.400391, pp_loss: 10.160256
[INFO] 2021-07-12 18:17:26,179 [run_pretraining.py:  512]:	********exe.run_128******* 
[INFO] 2021-07-12 18:18:14,913 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:18:14,914 [run_pretraining.py:  534]:	loss/total_loss, 10.09260368347168, 129
[INFO] 2021-07-12 18:18:14,914 [run_pretraining.py:  535]:	loss/mlm_loss, 10.09260368347168, 129
[INFO] 2021-07-12 18:18:14,914 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2799998785339994e-06, 129
[INFO] 2021-07-12 18:18:14,914 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 129
[INFO] 2021-07-12 18:18:14,914 [run_pretraining.py:  558]:	worker_index: 6, step: 129, cost: 10.092604, mlm loss: 10.092604, speed: 0.020519 steps/s, speed: 0.164155 samples/s, speed: 84.047503 tokens/s, learning rate: 1.280e-06, loss_scalings: 26214.400391, pp_loss: 10.092797
[INFO] 2021-07-12 18:18:14,914 [run_pretraining.py:  512]:	********exe.run_129******* 
[INFO] 2021-07-12 18:18:15,859 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:18:15,860 [run_pretraining.py:  534]:	loss/total_loss, 10.009178161621094, 130
[INFO] 2021-07-12 18:18:15,860 [run_pretraining.py:  535]:	loss/mlm_loss, 10.009178161621094, 130
[INFO] 2021-07-12 18:18:15,860 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2900000001536682e-06, 130
[INFO] 2021-07-12 18:18:15,860 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 130
[INFO] 2021-07-12 18:18:15,860 [run_pretraining.py:  558]:	worker_index: 6, step: 130, cost: 10.009178, mlm loss: 10.009178, speed: 1.057803 steps/s, speed: 8.462426 samples/s, speed: 4332.761979 tokens/s, learning rate: 1.290e-06, loss_scalings: 26214.400391, pp_loss: 9.539833
[INFO] 2021-07-12 18:18:15,861 [run_pretraining.py:  512]:	********exe.run_130******* 
[INFO] 2021-07-12 18:19:03,076 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:19:03,077 [run_pretraining.py:  534]:	loss/total_loss, 10.171074867248535, 131
[INFO] 2021-07-12 18:19:03,077 [run_pretraining.py:  535]:	loss/mlm_loss, 10.171074867248535, 131
[INFO] 2021-07-12 18:19:03,077 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3000000080864993e-06, 131
[INFO] 2021-07-12 18:19:03,077 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 131
[INFO] 2021-07-12 18:19:03,077 [run_pretraining.py:  558]:	worker_index: 6, step: 131, cost: 10.171075, mlm loss: 10.171075, speed: 0.021179 steps/s, speed: 0.169434 samples/s, speed: 86.750176 tokens/s, learning rate: 1.300e-06, loss_scalings: 26214.400391, pp_loss: 10.167409
[INFO] 2021-07-12 18:19:03,077 [run_pretraining.py:  512]:	********exe.run_131******* 
[INFO] 2021-07-12 18:19:04,035 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:19:04,036 [run_pretraining.py:  534]:	loss/total_loss, 10.15418815612793, 132
[INFO] 2021-07-12 18:19:04,036 [run_pretraining.py:  535]:	loss/mlm_loss, 10.15418815612793, 132
[INFO] 2021-07-12 18:19:04,036 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3100000160193304e-06, 132
[INFO] 2021-07-12 18:19:04,036 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 132
[INFO] 2021-07-12 18:19:04,036 [run_pretraining.py:  558]:	worker_index: 6, step: 132, cost: 10.154188, mlm loss: 10.154188, speed: 1.043836 steps/s, speed: 8.350690 samples/s, speed: 4275.553078 tokens/s, learning rate: 1.310e-06, loss_scalings: 26214.400391, pp_loss: 10.018282
[INFO] 2021-07-12 18:19:04,036 [run_pretraining.py:  512]:	********exe.run_132******* 
[INFO] 2021-07-12 18:19:04,971 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:19:04,972 [run_pretraining.py:  534]:	loss/total_loss, 9.931288719177246, 133
[INFO] 2021-07-12 18:19:04,972 [run_pretraining.py:  535]:	loss/mlm_loss, 9.931288719177246, 133
[INFO] 2021-07-12 18:19:04,972 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3199999102653237e-06, 133
[INFO] 2021-07-12 18:19:04,972 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 133
[INFO] 2021-07-12 18:19:04,972 [run_pretraining.py:  558]:	worker_index: 6, step: 133, cost: 9.931289, mlm loss: 9.931289, speed: 1.069080 steps/s, speed: 8.552641 samples/s, speed: 4378.952317 tokens/s, learning rate: 1.320e-06, loss_scalings: 26214.400391, pp_loss: 9.977425
[INFO] 2021-07-12 18:19:04,972 [run_pretraining.py:  512]:	********exe.run_133******* 
[INFO] 2021-07-12 18:19:05,913 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:19:05,914 [run_pretraining.py:  534]:	loss/total_loss, 10.182917594909668, 134
[INFO] 2021-07-12 18:19:05,914 [run_pretraining.py:  535]:	loss/mlm_loss, 10.182917594909668, 134
[INFO] 2021-07-12 18:19:05,914 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3299999181981548e-06, 134
[INFO] 2021-07-12 18:19:05,914 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 134
[INFO] 2021-07-12 18:19:05,914 [run_pretraining.py:  558]:	worker_index: 6, step: 134, cost: 10.182918, mlm loss: 10.182918, speed: 1.062230 steps/s, speed: 8.497837 samples/s, speed: 4350.892582 tokens/s, learning rate: 1.330e-06, loss_scalings: 26214.400391, pp_loss: 10.113630
[INFO] 2021-07-12 18:19:05,914 [run_pretraining.py:  512]:	********exe.run_134******* 
[INFO] 2021-07-12 18:19:52,318 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:19:52,319 [run_pretraining.py:  534]:	loss/total_loss, 9.74502182006836, 135
[INFO] 2021-07-12 18:19:52,319 [run_pretraining.py:  535]:	loss/mlm_loss, 9.74502182006836, 135
[INFO] 2021-07-12 18:19:52,319 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3399999261309858e-06, 135
[INFO] 2021-07-12 18:19:52,319 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 135
[INFO] 2021-07-12 18:19:52,319 [run_pretraining.py:  558]:	worker_index: 6, step: 135, cost: 9.745022, mlm loss: 9.745022, speed: 0.021550 steps/s, speed: 0.172398 samples/s, speed: 88.267978 tokens/s, learning rate: 1.340e-06, loss_scalings: 26214.400391, pp_loss: 9.995494
[INFO] 2021-07-12 18:19:52,319 [run_pretraining.py:  512]:	********exe.run_135******* 
[INFO] 2021-07-12 18:19:53,243 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:19:53,244 [run_pretraining.py:  534]:	loss/total_loss, 10.021539688110352, 136
[INFO] 2021-07-12 18:19:53,244 [run_pretraining.py:  535]:	loss/mlm_loss, 10.021539688110352, 136
[INFO] 2021-07-12 18:19:53,244 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3500000477506546e-06, 136
[INFO] 2021-07-12 18:19:53,244 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 136
[INFO] 2021-07-12 18:19:53,244 [run_pretraining.py:  558]:	worker_index: 6, step: 136, cost: 10.021540, mlm loss: 10.021540, speed: 1.082171 steps/s, speed: 8.657365 samples/s, speed: 4432.570919 tokens/s, learning rate: 1.350e-06, loss_scalings: 26214.400391, pp_loss: 9.077590
[INFO] 2021-07-12 18:19:53,244 [run_pretraining.py:  512]:	********exe.run_136******* 
[INFO] 2021-07-12 18:19:54,176 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:19:54,176 [run_pretraining.py:  534]:	loss/total_loss, 9.991589546203613, 137
[INFO] 2021-07-12 18:19:54,176 [run_pretraining.py:  535]:	loss/mlm_loss, 9.991589546203613, 137
[INFO] 2021-07-12 18:19:54,177 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.359999941996648e-06, 137
[INFO] 2021-07-12 18:19:54,177 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 137
[INFO] 2021-07-12 18:19:54,177 [run_pretraining.py:  558]:	worker_index: 6, step: 137, cost: 9.991590, mlm loss: 9.991590, speed: 1.073059 steps/s, speed: 8.584471 samples/s, speed: 4395.249304 tokens/s, learning rate: 1.360e-06, loss_scalings: 26214.400391, pp_loss: 9.975142
[INFO] 2021-07-12 18:19:54,177 [run_pretraining.py:  512]:	********exe.run_137******* 
[INFO] 2021-07-12 18:19:55,118 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:19:55,118 [run_pretraining.py:  534]:	loss/total_loss, 10.063220977783203, 138
[INFO] 2021-07-12 18:19:55,118 [run_pretraining.py:  535]:	loss/mlm_loss, 10.063220977783203, 138
[INFO] 2021-07-12 18:19:55,119 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.369999949929479e-06, 138
[INFO] 2021-07-12 18:19:55,119 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 138
[INFO] 2021-07-12 18:19:55,119 [run_pretraining.py:  558]:	worker_index: 6, step: 138, cost: 10.063221, mlm loss: 10.063221, speed: 1.062357 steps/s, speed: 8.498859 samples/s, speed: 4351.416041 tokens/s, learning rate: 1.370e-06, loss_scalings: 26214.400391, pp_loss: 10.003723
[INFO] 2021-07-12 18:19:55,119 [run_pretraining.py:  512]:	********exe.run_138******* 
[INFO] 2021-07-12 18:19:56,055 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:19:56,056 [run_pretraining.py:  534]:	loss/total_loss, 10.036176681518555, 139
[INFO] 2021-07-12 18:19:56,056 [run_pretraining.py:  535]:	loss/mlm_loss, 10.036176681518555, 139
[INFO] 2021-07-12 18:19:56,056 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3799999578623101e-06, 139
[INFO] 2021-07-12 18:19:56,056 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 139
[INFO] 2021-07-12 18:19:56,056 [run_pretraining.py:  558]:	worker_index: 6, step: 139, cost: 10.036177, mlm loss: 10.036177, speed: 1.067772 steps/s, speed: 8.542173 samples/s, speed: 4373.592461 tokens/s, learning rate: 1.380e-06, loss_scalings: 26214.400391, pp_loss: 10.036994
[INFO] 2021-07-12 18:19:56,056 [run_pretraining.py:  512]:	********exe.run_139******* 
[INFO] 2021-07-12 18:20:19,881 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:20:19,882 [run_pretraining.py:  534]:	loss/total_loss, 10.071728706359863, 140
[INFO] 2021-07-12 18:20:19,882 [run_pretraining.py:  535]:	loss/mlm_loss, 10.071728706359863, 140
[INFO] 2021-07-12 18:20:19,882 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3899999657951412e-06, 140
[INFO] 2021-07-12 18:20:19,882 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 140
[INFO] 2021-07-12 18:20:19,882 [run_pretraining.py:  558]:	worker_index: 6, step: 140, cost: 10.071729, mlm loss: 10.071729, speed: 0.041972 steps/s, speed: 0.335772 samples/s, speed: 171.915300 tokens/s, learning rate: 1.390e-06, loss_scalings: 26214.400391, pp_loss: 9.986835
[INFO] 2021-07-12 18:20:19,883 [run_pretraining.py:  512]:	********exe.run_140******* 
[INFO] 2021-07-12 18:20:20,817 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:20:20,818 [run_pretraining.py:  534]:	loss/total_loss, 7.92875337600708, 141
[INFO] 2021-07-12 18:20:20,818 [run_pretraining.py:  535]:	loss/mlm_loss, 7.92875337600708, 141
[INFO] 2021-07-12 18:20:20,818 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3999999737279722e-06, 141
[INFO] 2021-07-12 18:20:20,818 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 141
[INFO] 2021-07-12 18:20:20,818 [run_pretraining.py:  558]:	worker_index: 6, step: 141, cost: 7.928753, mlm loss: 7.928753, speed: 1.069309 steps/s, speed: 8.554473 samples/s, speed: 4379.890080 tokens/s, learning rate: 1.400e-06, loss_scalings: 26214.400391, pp_loss: 9.475116
[INFO] 2021-07-12 18:20:20,818 [run_pretraining.py:  512]:	********exe.run_141******* 
[INFO] 2021-07-12 18:20:21,757 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:20:21,757 [run_pretraining.py:  534]:	loss/total_loss, 10.070110321044922, 142
[INFO] 2021-07-12 18:20:21,757 [run_pretraining.py:  535]:	loss/mlm_loss, 10.070110321044922, 142
[INFO] 2021-07-12 18:20:21,757 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4099999816608033e-06, 142
[INFO] 2021-07-12 18:20:21,757 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 142
[INFO] 2021-07-12 18:20:21,758 [run_pretraining.py:  558]:	worker_index: 6, step: 142, cost: 10.070110, mlm loss: 10.070110, speed: 1.065572 steps/s, speed: 8.524577 samples/s, speed: 4364.583494 tokens/s, learning rate: 1.410e-06, loss_scalings: 26214.400391, pp_loss: 10.039172
[INFO] 2021-07-12 18:20:21,758 [run_pretraining.py:  512]:	********exe.run_142******* 
[INFO] 2021-07-12 18:20:45,275 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:20:45,276 [run_pretraining.py:  534]:	loss/total_loss, 10.032047271728516, 143
[INFO] 2021-07-12 18:20:45,276 [run_pretraining.py:  535]:	loss/mlm_loss, 10.032047271728516, 143
[INFO] 2021-07-12 18:20:45,276 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4199999895936344e-06, 143
[INFO] 2021-07-12 18:20:45,276 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 143
[INFO] 2021-07-12 18:20:45,276 [run_pretraining.py:  558]:	worker_index: 6, step: 143, cost: 10.032047, mlm loss: 10.032047, speed: 0.042521 steps/s, speed: 0.340166 samples/s, speed: 174.164979 tokens/s, learning rate: 1.420e-06, loss_scalings: 26214.400391, pp_loss: 10.089982
[INFO] 2021-07-12 18:20:45,276 [run_pretraining.py:  512]:	********exe.run_143******* 
[INFO] 2021-07-12 18:21:08,569 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:21:08,569 [run_pretraining.py:  534]:	loss/total_loss, 9.844891548156738, 144
[INFO] 2021-07-12 18:21:08,569 [run_pretraining.py:  535]:	loss/mlm_loss, 9.844891548156738, 144
[INFO] 2021-07-12 18:21:08,570 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4299999975264654e-06, 144
[INFO] 2021-07-12 18:21:08,570 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 144
[INFO] 2021-07-12 18:21:08,570 [run_pretraining.py:  558]:	worker_index: 6, step: 144, cost: 9.844892, mlm loss: 9.844892, speed: 0.042932 steps/s, speed: 0.343452 samples/s, speed: 175.847631 tokens/s, learning rate: 1.430e-06, loss_scalings: 26214.400391, pp_loss: 9.876888
[INFO] 2021-07-12 18:21:08,570 [run_pretraining.py:  512]:	********exe.run_144******* 
[INFO] 2021-07-12 18:21:09,530 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:21:09,531 [run_pretraining.py:  534]:	loss/total_loss, 9.878545761108398, 145
[INFO] 2021-07-12 18:21:09,531 [run_pretraining.py:  535]:	loss/mlm_loss, 9.878545761108398, 145
[INFO] 2021-07-12 18:21:09,531 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4399998917724588e-06, 145
[INFO] 2021-07-12 18:21:09,531 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 145
[INFO] 2021-07-12 18:21:09,531 [run_pretraining.py:  558]:	worker_index: 6, step: 145, cost: 9.878546, mlm loss: 9.878546, speed: 1.040641 steps/s, speed: 8.325125 samples/s, speed: 4262.463878 tokens/s, learning rate: 1.440e-06, loss_scalings: 26214.400391, pp_loss: 9.874069
[INFO] 2021-07-12 18:21:09,532 [run_pretraining.py:  512]:	********exe.run_145******* 
[INFO] 2021-07-12 18:21:10,476 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:21:10,476 [run_pretraining.py:  534]:	loss/total_loss, 9.813486099243164, 146
[INFO] 2021-07-12 18:21:10,477 [run_pretraining.py:  535]:	loss/mlm_loss, 9.813486099243164, 146
[INFO] 2021-07-12 18:21:10,477 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4499998997052899e-06, 146
[INFO] 2021-07-12 18:21:10,477 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 146
[INFO] 2021-07-12 18:21:10,477 [run_pretraining.py:  558]:	worker_index: 6, step: 146, cost: 9.813486, mlm loss: 9.813486, speed: 1.058645 steps/s, speed: 8.469160 samples/s, speed: 4336.210074 tokens/s, learning rate: 1.450e-06, loss_scalings: 26214.400391, pp_loss: 9.921268
[INFO] 2021-07-12 18:21:10,477 [run_pretraining.py:  512]:	********exe.run_146******* 
[INFO] 2021-07-12 18:21:11,458 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:21:11,459 [run_pretraining.py:  534]:	loss/total_loss, 10.082925796508789, 147
[INFO] 2021-07-12 18:21:11,459 [run_pretraining.py:  535]:	loss/mlm_loss, 10.082925796508789, 147
[INFO] 2021-07-12 18:21:11,459 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4600000213249587e-06, 147
[INFO] 2021-07-12 18:21:11,459 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 147
[INFO] 2021-07-12 18:21:11,459 [run_pretraining.py:  558]:	worker_index: 6, step: 147, cost: 10.082926, mlm loss: 10.082926, speed: 1.018646 steps/s, speed: 8.149165 samples/s, speed: 4172.372559 tokens/s, learning rate: 1.460e-06, loss_scalings: 26214.400391, pp_loss: 9.943722
[INFO] 2021-07-12 18:21:11,459 [run_pretraining.py:  512]:	********exe.run_147******* 
[INFO] 2021-07-12 18:21:12,409 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:21:12,410 [run_pretraining.py:  534]:	loss/total_loss, 9.83849811553955, 148
[INFO] 2021-07-12 18:21:12,410 [run_pretraining.py:  535]:	loss/mlm_loss, 9.83849811553955, 148
[INFO] 2021-07-12 18:21:12,410 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4700000292577897e-06, 148
[INFO] 2021-07-12 18:21:12,410 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 148
[INFO] 2021-07-12 18:21:12,410 [run_pretraining.py:  558]:	worker_index: 6, step: 148, cost: 9.838498, mlm loss: 9.838498, speed: 1.052143 steps/s, speed: 8.417142 samples/s, speed: 4309.576761 tokens/s, learning rate: 1.470e-06, loss_scalings: 26214.400391, pp_loss: 9.925181
[INFO] 2021-07-12 18:21:12,411 [run_pretraining.py:  512]:	********exe.run_148******* 
[INFO] 2021-07-12 18:21:13,351 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:21:13,352 [run_pretraining.py:  534]:	loss/total_loss, 9.928655624389648, 149
[INFO] 2021-07-12 18:21:13,352 [run_pretraining.py:  535]:	loss/mlm_loss, 9.928655624389648, 149
[INFO] 2021-07-12 18:21:13,352 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.479999923503783e-06, 149
[INFO] 2021-07-12 18:21:13,352 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 149
[INFO] 2021-07-12 18:21:13,352 [run_pretraining.py:  558]:	worker_index: 6, step: 149, cost: 9.928656, mlm loss: 9.928656, speed: 1.062339 steps/s, speed: 8.498709 samples/s, speed: 4351.338891 tokens/s, learning rate: 1.480e-06, loss_scalings: 26214.400391, pp_loss: 9.845650
[INFO] 2021-07-12 18:21:13,353 [run_pretraining.py:  512]:	********exe.run_149******* 
[INFO] 2021-07-12 18:21:14,297 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:21:14,297 [run_pretraining.py:  534]:	loss/total_loss, 9.828768730163574, 150
[INFO] 2021-07-12 18:21:14,297 [run_pretraining.py:  535]:	loss/mlm_loss, 9.828768730163574, 150
[INFO] 2021-07-12 18:21:14,297 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4899999314366141e-06, 150
[INFO] 2021-07-12 18:21:14,298 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 150
[INFO] 2021-07-12 18:21:14,298 [run_pretraining.py:  558]:	worker_index: 6, step: 150, cost: 9.828769, mlm loss: 9.828769, speed: 1.058773 steps/s, speed: 8.470180 samples/s, speed: 4336.732195 tokens/s, learning rate: 1.490e-06, loss_scalings: 26214.400391, pp_loss: 9.949446
[INFO] 2021-07-12 18:21:14,298 [run_pretraining.py:  512]:	********exe.run_150******* 
[INFO] 2021-07-12 18:21:15,241 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:21:15,242 [run_pretraining.py:  534]:	loss/total_loss, 9.960775375366211, 151
[INFO] 2021-07-12 18:21:15,242 [run_pretraining.py:  535]:	loss/mlm_loss, 9.960775375366211, 151
[INFO] 2021-07-12 18:21:15,242 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4999999393694452e-06, 151
[INFO] 2021-07-12 18:21:15,242 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 151
[INFO] 2021-07-12 18:21:15,242 [run_pretraining.py:  558]:	worker_index: 6, step: 151, cost: 9.960775, mlm loss: 9.960775, speed: 1.059878 steps/s, speed: 8.479026 samples/s, speed: 4341.261422 tokens/s, learning rate: 1.500e-06, loss_scalings: 26214.400391, pp_loss: 9.905882
[INFO] 2021-07-12 18:21:15,242 [run_pretraining.py:  512]:	********exe.run_151******* 
[INFO] 2021-07-12 18:21:16,188 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:21:16,189 [run_pretraining.py:  534]:	loss/total_loss, 9.812142372131348, 152
[INFO] 2021-07-12 18:21:16,189 [run_pretraining.py:  535]:	loss/mlm_loss, 9.812142372131348, 152
[INFO] 2021-07-12 18:21:16,189 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.510000060989114e-06, 152
[INFO] 2021-07-12 18:21:16,189 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 152
[INFO] 2021-07-12 18:21:16,189 [run_pretraining.py:  558]:	worker_index: 6, step: 152, cost: 9.812142, mlm loss: 9.812142, speed: 1.056186 steps/s, speed: 8.449484 samples/s, speed: 4326.136025 tokens/s, learning rate: 1.510e-06, loss_scalings: 26214.400391, pp_loss: 9.886972
[INFO] 2021-07-12 18:21:16,190 [run_pretraining.py:  512]:	********exe.run_152******* 
[INFO] 2021-07-12 18:21:17,133 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:21:17,133 [run_pretraining.py:  534]:	loss/total_loss, 9.944314002990723, 153
[INFO] 2021-07-12 18:21:17,134 [run_pretraining.py:  535]:	loss/mlm_loss, 9.944314002990723, 153
[INFO] 2021-07-12 18:21:17,134 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5199999552351073e-06, 153
[INFO] 2021-07-12 18:21:17,134 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 153
[INFO] 2021-07-12 18:21:17,134 [run_pretraining.py:  558]:	worker_index: 6, step: 153, cost: 9.944314, mlm loss: 9.944314, speed: 1.059674 steps/s, speed: 8.477394 samples/s, speed: 4340.425659 tokens/s, learning rate: 1.520e-06, loss_scalings: 26214.400391, pp_loss: 10.034043
[INFO] 2021-07-12 18:21:17,134 [run_pretraining.py:  512]:	********exe.run_153******* 
[INFO] 2021-07-12 18:21:42,894 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:21:42,895 [run_pretraining.py:  534]:	loss/total_loss, 9.843791961669922, 154
[INFO] 2021-07-12 18:21:42,895 [run_pretraining.py:  535]:	loss/mlm_loss, 9.843791961669922, 154
[INFO] 2021-07-12 18:21:42,895 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5299999631679384e-06, 154
[INFO] 2021-07-12 18:21:42,896 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 154
[INFO] 2021-07-12 18:21:42,896 [run_pretraining.py:  558]:	worker_index: 6, step: 154, cost: 9.843792, mlm loss: 9.843792, speed: 0.038818 steps/s, speed: 0.310547 samples/s, speed: 158.999882 tokens/s, learning rate: 1.530e-06, loss_scalings: 26214.400391, pp_loss: 9.968876
[INFO] 2021-07-12 18:21:42,896 [run_pretraining.py:  512]:	********exe.run_154******* 
[INFO] 2021-07-12 18:21:43,891 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:21:43,891 [run_pretraining.py:  534]:	loss/total_loss, 9.959667205810547, 155
[INFO] 2021-07-12 18:21:43,891 [run_pretraining.py:  535]:	loss/mlm_loss, 9.959667205810547, 155
[INFO] 2021-07-12 18:21:43,892 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5399999711007695e-06, 155
[INFO] 2021-07-12 18:21:43,892 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 155
[INFO] 2021-07-12 18:21:43,892 [run_pretraining.py:  558]:	worker_index: 6, step: 155, cost: 9.959667, mlm loss: 9.959667, speed: 1.004776 steps/s, speed: 8.038207 samples/s, speed: 4115.561729 tokens/s, learning rate: 1.540e-06, loss_scalings: 26214.400391, pp_loss: 9.951139
[INFO] 2021-07-12 18:21:43,892 [run_pretraining.py:  512]:	********exe.run_155******* 
[INFO] 2021-07-12 18:21:44,859 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:21:44,860 [run_pretraining.py:  534]:	loss/total_loss, 10.03381633758545, 156
[INFO] 2021-07-12 18:21:44,860 [run_pretraining.py:  535]:	loss/mlm_loss, 10.03381633758545, 156
[INFO] 2021-07-12 18:21:44,860 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5499999790336005e-06, 156
[INFO] 2021-07-12 18:21:44,860 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 156
[INFO] 2021-07-12 18:21:44,860 [run_pretraining.py:  558]:	worker_index: 6, step: 156, cost: 10.033816, mlm loss: 10.033816, speed: 1.033571 steps/s, speed: 8.268571 samples/s, speed: 4233.508396 tokens/s, learning rate: 1.550e-06, loss_scalings: 26214.400391, pp_loss: 9.983370
[INFO] 2021-07-12 18:21:44,860 [run_pretraining.py:  512]:	********exe.run_156******* 
[INFO] 2021-07-12 18:21:45,828 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:21:45,828 [run_pretraining.py:  534]:	loss/total_loss, 9.949519157409668, 157
[INFO] 2021-07-12 18:21:45,828 [run_pretraining.py:  535]:	loss/mlm_loss, 9.949519157409668, 157
[INFO] 2021-07-12 18:21:45,828 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5599998732795939e-06, 157
[INFO] 2021-07-12 18:21:45,828 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 157
[INFO] 2021-07-12 18:21:45,829 [run_pretraining.py:  558]:	worker_index: 6, step: 157, cost: 9.949519, mlm loss: 9.949519, speed: 1.033222 steps/s, speed: 8.265776 samples/s, speed: 4232.077565 tokens/s, learning rate: 1.560e-06, loss_scalings: 26214.400391, pp_loss: 9.967888
[INFO] 2021-07-12 18:21:45,829 [run_pretraining.py:  512]:	********exe.run_157******* 
[INFO] 2021-07-12 18:22:11,589 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:11,590 [run_pretraining.py:  534]:	loss/total_loss, 10.11301040649414, 158
[INFO] 2021-07-12 18:22:11,590 [run_pretraining.py:  535]:	loss/mlm_loss, 10.11301040649414, 158
[INFO] 2021-07-12 18:22:11,590 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.569999881212425e-06, 158
[INFO] 2021-07-12 18:22:11,590 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 158
[INFO] 2021-07-12 18:22:11,591 [run_pretraining.py:  558]:	worker_index: 6, step: 158, cost: 10.113010, mlm loss: 10.113010, speed: 0.038818 steps/s, speed: 0.310545 samples/s, speed: 158.998946 tokens/s, learning rate: 1.570e-06, loss_scalings: 26214.400391, pp_loss: 9.602217
[INFO] 2021-07-12 18:22:11,591 [run_pretraining.py:  512]:	********exe.run_158******* 
[INFO] 2021-07-12 18:22:12,581 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:12,582 [run_pretraining.py:  534]:	loss/total_loss, 10.081175804138184, 159
[INFO] 2021-07-12 18:22:12,582 [run_pretraining.py:  535]:	loss/mlm_loss, 10.081175804138184, 159
[INFO] 2021-07-12 18:22:12,582 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.579999889145256e-06, 159
[INFO] 2021-07-12 18:22:12,582 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 159
[INFO] 2021-07-12 18:22:12,582 [run_pretraining.py:  558]:	worker_index: 6, step: 159, cost: 10.081176, mlm loss: 10.081176, speed: 1.009144 steps/s, speed: 8.073150 samples/s, speed: 4133.452634 tokens/s, learning rate: 1.580e-06, loss_scalings: 26214.400391, pp_loss: 10.026311
[INFO] 2021-07-12 18:22:12,582 [run_pretraining.py:  512]:	********exe.run_159******* 
[INFO] 2021-07-12 18:22:13,548 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:13,548 [run_pretraining.py:  534]:	loss/total_loss, 9.976564407348633, 160
[INFO] 2021-07-12 18:22:13,549 [run_pretraining.py:  535]:	loss/mlm_loss, 9.976564407348633, 160
[INFO] 2021-07-12 18:22:13,549 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5900000107649248e-06, 160
[INFO] 2021-07-12 18:22:13,549 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 160
[INFO] 2021-07-12 18:22:13,549 [run_pretraining.py:  558]:	worker_index: 6, step: 160, cost: 9.976564, mlm loss: 9.976564, speed: 1.035304 steps/s, speed: 8.282431 samples/s, speed: 4240.604862 tokens/s, learning rate: 1.590e-06, loss_scalings: 26214.400391, pp_loss: 8.771517
[INFO] 2021-07-12 18:22:13,549 [run_pretraining.py:  512]:	********exe.run_160******* 
[INFO] 2021-07-12 18:22:14,518 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:14,518 [run_pretraining.py:  534]:	loss/total_loss, 9.949831008911133, 161
[INFO] 2021-07-12 18:22:14,518 [run_pretraining.py:  535]:	loss/mlm_loss, 9.949831008911133, 161
[INFO] 2021-07-12 18:22:14,518 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6000000186977559e-06, 161
[INFO] 2021-07-12 18:22:14,518 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 161
[INFO] 2021-07-12 18:22:14,519 [run_pretraining.py:  558]:	worker_index: 6, step: 161, cost: 9.949831, mlm loss: 9.949831, speed: 1.032009 steps/s, speed: 8.256071 samples/s, speed: 4227.108467 tokens/s, learning rate: 1.600e-06, loss_scalings: 26214.400391, pp_loss: 9.873774
[INFO] 2021-07-12 18:22:14,519 [run_pretraining.py:  512]:	********exe.run_161******* 
[INFO] 2021-07-12 18:22:15,487 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:15,488 [run_pretraining.py:  534]:	loss/total_loss, 9.871309280395508, 162
[INFO] 2021-07-12 18:22:15,488 [run_pretraining.py:  535]:	loss/mlm_loss, 9.871309280395508, 162
[INFO] 2021-07-12 18:22:15,488 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.610000026630587e-06, 162
[INFO] 2021-07-12 18:22:15,488 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 162
[INFO] 2021-07-12 18:22:15,488 [run_pretraining.py:  558]:	worker_index: 6, step: 162, cost: 9.871309, mlm loss: 9.871309, speed: 1.031976 steps/s, speed: 8.255809 samples/s, speed: 4226.974301 tokens/s, learning rate: 1.610e-06, loss_scalings: 26214.400391, pp_loss: 9.932150
[INFO] 2021-07-12 18:22:15,488 [run_pretraining.py:  512]:	********exe.run_162******* 
[INFO] 2021-07-12 18:22:16,456 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:16,456 [run_pretraining.py:  534]:	loss/total_loss, 9.985629081726074, 163
[INFO] 2021-07-12 18:22:16,457 [run_pretraining.py:  535]:	loss/mlm_loss, 9.985629081726074, 163
[INFO] 2021-07-12 18:22:16,457 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.620000034563418e-06, 163
[INFO] 2021-07-12 18:22:16,457 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 163
[INFO] 2021-07-12 18:22:16,457 [run_pretraining.py:  558]:	worker_index: 6, step: 163, cost: 9.985629, mlm loss: 9.985629, speed: 1.033258 steps/s, speed: 8.266064 samples/s, speed: 4232.224567 tokens/s, learning rate: 1.620e-06, loss_scalings: 26214.400391, pp_loss: 9.876704
[INFO] 2021-07-12 18:22:16,457 [run_pretraining.py:  512]:	********exe.run_163******* 
[INFO] 2021-07-12 18:22:17,427 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:17,428 [run_pretraining.py:  534]:	loss/total_loss, 9.77574348449707, 164
[INFO] 2021-07-12 18:22:17,428 [run_pretraining.py:  535]:	loss/mlm_loss, 9.77574348449707, 164
[INFO] 2021-07-12 18:22:17,428 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6299999288094114e-06, 164
[INFO] 2021-07-12 18:22:17,428 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 164
[INFO] 2021-07-12 18:22:17,428 [run_pretraining.py:  558]:	worker_index: 6, step: 164, cost: 9.775743, mlm loss: 9.775743, speed: 1.030015 steps/s, speed: 8.240119 samples/s, speed: 4218.940926 tokens/s, learning rate: 1.630e-06, loss_scalings: 26214.400391, pp_loss: 9.973103
[INFO] 2021-07-12 18:22:17,428 [run_pretraining.py:  512]:	********exe.run_164******* 
[INFO] 2021-07-12 18:22:18,404 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:18,404 [run_pretraining.py:  534]:	loss/total_loss, 9.85189437866211, 165
[INFO] 2021-07-12 18:22:18,405 [run_pretraining.py:  535]:	loss/mlm_loss, 9.85189437866211, 165
[INFO] 2021-07-12 18:22:18,405 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6399999367422424e-06, 165
[INFO] 2021-07-12 18:22:18,405 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 165
[INFO] 2021-07-12 18:22:18,405 [run_pretraining.py:  558]:	worker_index: 6, step: 165, cost: 9.851894, mlm loss: 9.851894, speed: 1.024897 steps/s, speed: 8.199178 samples/s, speed: 4197.979282 tokens/s, learning rate: 1.640e-06, loss_scalings: 26214.400391, pp_loss: 9.768356
[INFO] 2021-07-12 18:22:18,405 [run_pretraining.py:  512]:	********exe.run_165******* 
[INFO] 2021-07-12 18:22:19,361 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:19,362 [run_pretraining.py:  534]:	loss/total_loss, 9.971840858459473, 166
[INFO] 2021-07-12 18:22:19,362 [run_pretraining.py:  535]:	loss/mlm_loss, 9.971840858459473, 166
[INFO] 2021-07-12 18:22:19,362 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6499999446750735e-06, 166
[INFO] 2021-07-12 18:22:19,362 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 166
[INFO] 2021-07-12 18:22:19,362 [run_pretraining.py:  558]:	worker_index: 6, step: 166, cost: 9.971841, mlm loss: 9.971841, speed: 1.045075 steps/s, speed: 8.360598 samples/s, speed: 4280.626128 tokens/s, learning rate: 1.650e-06, loss_scalings: 26214.400391, pp_loss: 9.933957
[INFO] 2021-07-12 18:22:19,363 [run_pretraining.py:  512]:	********exe.run_166******* 
[INFO] 2021-07-12 18:22:20,336 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:20,337 [run_pretraining.py:  534]:	loss/total_loss, 9.825809478759766, 167
[INFO] 2021-07-12 18:22:20,337 [run_pretraining.py:  535]:	loss/mlm_loss, 9.825809478759766, 167
[INFO] 2021-07-12 18:22:20,337 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6599999526079046e-06, 167
[INFO] 2021-07-12 18:22:20,337 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 167
[INFO] 2021-07-12 18:22:20,337 [run_pretraining.py:  558]:	worker_index: 6, step: 167, cost: 9.825809, mlm loss: 9.825809, speed: 1.026923 steps/s, speed: 8.215385 samples/s, speed: 4206.276896 tokens/s, learning rate: 1.660e-06, loss_scalings: 26214.400391, pp_loss: 9.958123
[INFO] 2021-07-12 18:22:20,337 [run_pretraining.py:  512]:	********exe.run_167******* 
[INFO] 2021-07-12 18:22:21,302 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:21,303 [run_pretraining.py:  534]:	loss/total_loss, 9.772802352905273, 168
[INFO] 2021-07-12 18:22:21,303 [run_pretraining.py:  535]:	loss/mlm_loss, 9.772802352905273, 168
[INFO] 2021-07-12 18:22:21,303 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6699999605407356e-06, 168
[INFO] 2021-07-12 18:22:21,303 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 168
[INFO] 2021-07-12 18:22:21,303 [run_pretraining.py:  558]:	worker_index: 6, step: 168, cost: 9.772802, mlm loss: 9.772802, speed: 1.035427 steps/s, speed: 8.283413 samples/s, speed: 4241.107353 tokens/s, learning rate: 1.670e-06, loss_scalings: 26214.400391, pp_loss: 9.803348
[INFO] 2021-07-12 18:22:21,304 [run_pretraining.py:  512]:	********exe.run_168******* 
[INFO] 2021-07-12 18:22:22,369 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:22,370 [run_pretraining.py:  534]:	loss/total_loss, 9.817649841308594, 169
[INFO] 2021-07-12 18:22:22,370 [run_pretraining.py:  535]:	loss/mlm_loss, 9.817649841308594, 169
[INFO] 2021-07-12 18:22:22,370 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.679999854786729e-06, 169
[INFO] 2021-07-12 18:22:22,370 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 169
[INFO] 2021-07-12 18:22:22,370 [run_pretraining.py:  558]:	worker_index: 6, step: 169, cost: 9.817650, mlm loss: 9.817650, speed: 0.937873 steps/s, speed: 7.502987 samples/s, speed: 3841.529482 tokens/s, learning rate: 1.680e-06, loss_scalings: 26214.400391, pp_loss: 9.891949
[INFO] 2021-07-12 18:22:22,371 [run_pretraining.py:  512]:	********exe.run_169******* 
[INFO] 2021-07-12 18:22:23,445 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:23,445 [run_pretraining.py:  534]:	loss/total_loss, 9.968330383300781, 170
[INFO] 2021-07-12 18:22:23,445 [run_pretraining.py:  535]:	loss/mlm_loss, 9.968330383300781, 170
[INFO] 2021-07-12 18:22:23,446 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.68999986271956e-06, 170
[INFO] 2021-07-12 18:22:23,446 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 170
[INFO] 2021-07-12 18:22:23,446 [run_pretraining.py:  558]:	worker_index: 6, step: 170, cost: 9.968330, mlm loss: 9.968330, speed: 0.930570 steps/s, speed: 7.444558 samples/s, speed: 3811.613704 tokens/s, learning rate: 1.690e-06, loss_scalings: 26214.400391, pp_loss: 9.872447
[INFO] 2021-07-12 18:22:23,446 [run_pretraining.py:  512]:	********exe.run_170******* 
[INFO] 2021-07-12 18:22:24,488 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:24,489 [run_pretraining.py:  534]:	loss/total_loss, 9.966832160949707, 171
[INFO] 2021-07-12 18:22:24,489 [run_pretraining.py:  535]:	loss/mlm_loss, 9.966832160949707, 171
[INFO] 2021-07-12 18:22:24,489 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7000000980260666e-06, 171
[INFO] 2021-07-12 18:22:24,489 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 171
[INFO] 2021-07-12 18:22:24,489 [run_pretraining.py:  558]:	worker_index: 6, step: 171, cost: 9.966832, mlm loss: 9.966832, speed: 0.958985 steps/s, speed: 7.671883 samples/s, speed: 3928.004297 tokens/s, learning rate: 1.700e-06, loss_scalings: 26214.400391, pp_loss: 9.843208
[INFO] 2021-07-12 18:22:24,489 [run_pretraining.py:  512]:	********exe.run_171******* 
[INFO] 2021-07-12 18:22:25,542 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:25,543 [run_pretraining.py:  534]:	loss/total_loss, 9.952240943908691, 172
[INFO] 2021-07-12 18:22:25,543 [run_pretraining.py:  535]:	loss/mlm_loss, 9.952240943908691, 172
[INFO] 2021-07-12 18:22:25,543 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.70999999227206e-06, 172
[INFO] 2021-07-12 18:22:25,543 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 172
[INFO] 2021-07-12 18:22:25,543 [run_pretraining.py:  558]:	worker_index: 6, step: 172, cost: 9.952241, mlm loss: 9.952241, speed: 0.949623 steps/s, speed: 7.596982 samples/s, speed: 3889.654591 tokens/s, learning rate: 1.710e-06, loss_scalings: 26214.400391, pp_loss: 9.800293
[INFO] 2021-07-12 18:22:25,543 [run_pretraining.py:  512]:	********exe.run_172******* 
[INFO] 2021-07-12 18:22:26,596 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:26,597 [run_pretraining.py:  534]:	loss/total_loss, 9.911767959594727, 173
[INFO] 2021-07-12 18:22:26,597 [run_pretraining.py:  535]:	loss/mlm_loss, 9.911767959594727, 173
[INFO] 2021-07-12 18:22:26,597 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.720000000204891e-06, 173
[INFO] 2021-07-12 18:22:26,597 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 173
[INFO] 2021-07-12 18:22:26,597 [run_pretraining.py:  558]:	worker_index: 6, step: 173, cost: 9.911768, mlm loss: 9.911768, speed: 0.949026 steps/s, speed: 7.592205 samples/s, speed: 3887.208810 tokens/s, learning rate: 1.720e-06, loss_scalings: 26214.400391, pp_loss: 9.876862
[INFO] 2021-07-12 18:22:26,598 [run_pretraining.py:  512]:	********exe.run_173******* 
[INFO] 2021-07-12 18:22:52,553 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:52,554 [run_pretraining.py:  534]:	loss/total_loss, 10.121970176696777, 174
[INFO] 2021-07-12 18:22:52,554 [run_pretraining.py:  535]:	loss/mlm_loss, 10.121970176696777, 174
[INFO] 2021-07-12 18:22:52,554 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.730000008137722e-06, 174
[INFO] 2021-07-12 18:22:52,554 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 174
[INFO] 2021-07-12 18:22:52,554 [run_pretraining.py:  558]:	worker_index: 6, step: 174, cost: 10.121970, mlm loss: 10.121970, speed: 0.038527 steps/s, speed: 0.308212 samples/s, speed: 157.804721 tokens/s, learning rate: 1.730e-06, loss_scalings: 26214.400391, pp_loss: 9.882052
[INFO] 2021-07-12 18:22:52,554 [run_pretraining.py:  512]:	********exe.run_174******* 
[INFO] 2021-07-12 18:23:41,443 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:23:41,444 [run_pretraining.py:  534]:	loss/total_loss, 9.970909118652344, 175
[INFO] 2021-07-12 18:23:41,444 [run_pretraining.py:  535]:	loss/mlm_loss, 9.970909118652344, 175
[INFO] 2021-07-12 18:23:41,444 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.740000016070553e-06, 175
[INFO] 2021-07-12 18:23:41,445 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 175
[INFO] 2021-07-12 18:23:41,445 [run_pretraining.py:  558]:	worker_index: 6, step: 175, cost: 9.970909, mlm loss: 9.970909, speed: 0.020454 steps/s, speed: 0.163634 samples/s, speed: 83.780753 tokens/s, learning rate: 1.740e-06, loss_scalings: 26214.400391, pp_loss: 9.892956
[INFO] 2021-07-12 18:23:41,445 [run_pretraining.py:  512]:	********exe.run_175******* 
[INFO] 2021-07-12 18:23:42,428 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:23:42,429 [run_pretraining.py:  534]:	loss/total_loss, 9.592855453491211, 176
[INFO] 2021-07-12 18:23:42,429 [run_pretraining.py:  535]:	loss/mlm_loss, 9.592855453491211, 176
[INFO] 2021-07-12 18:23:42,429 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7499999103165464e-06, 176
[INFO] 2021-07-12 18:23:42,429 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 176
[INFO] 2021-07-12 18:23:42,429 [run_pretraining.py:  558]:	worker_index: 6, step: 176, cost: 9.592855, mlm loss: 9.592855, speed: 1.016494 steps/s, speed: 8.131953 samples/s, speed: 4163.560134 tokens/s, learning rate: 1.750e-06, loss_scalings: 26214.400391, pp_loss: 9.804464
[INFO] 2021-07-12 18:23:42,429 [run_pretraining.py:  512]:	********exe.run_176******* 
[INFO] 2021-07-12 18:23:43,386 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:23:43,387 [run_pretraining.py:  534]:	loss/total_loss, 9.897367477416992, 177
[INFO] 2021-07-12 18:23:43,387 [run_pretraining.py:  535]:	loss/mlm_loss, 9.897367477416992, 177
[INFO] 2021-07-12 18:23:43,387 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7599999182493775e-06, 177
[INFO] 2021-07-12 18:23:43,387 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 177
[INFO] 2021-07-12 18:23:43,387 [run_pretraining.py:  558]:	worker_index: 6, step: 177, cost: 9.897367, mlm loss: 9.897367, speed: 1.044355 steps/s, speed: 8.354844 samples/s, speed: 4277.680121 tokens/s, learning rate: 1.760e-06, loss_scalings: 26214.400391, pp_loss: 9.896511
[INFO] 2021-07-12 18:23:43,388 [run_pretraining.py:  512]:	********exe.run_177******* 
[INFO] 2021-07-12 18:23:44,363 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:23:44,364 [run_pretraining.py:  534]:	loss/total_loss, 9.893117904663086, 178
[INFO] 2021-07-12 18:23:44,364 [run_pretraining.py:  535]:	loss/mlm_loss, 9.893117904663086, 178
[INFO] 2021-07-12 18:23:44,364 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7699999261822086e-06, 178
[INFO] 2021-07-12 18:23:44,364 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 178
[INFO] 2021-07-12 18:23:44,364 [run_pretraining.py:  558]:	worker_index: 6, step: 178, cost: 9.893118, mlm loss: 9.893118, speed: 1.024795 steps/s, speed: 8.198361 samples/s, speed: 4197.560799 tokens/s, learning rate: 1.770e-06, loss_scalings: 26214.400391, pp_loss: 9.830692
[INFO] 2021-07-12 18:23:44,364 [run_pretraining.py:  512]:	********exe.run_178******* 
[INFO] 2021-07-12 18:23:45,417 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:23:45,418 [run_pretraining.py:  534]:	loss/total_loss, 9.881132125854492, 179
[INFO] 2021-07-12 18:23:45,418 [run_pretraining.py:  535]:	loss/mlm_loss, 9.881132125854492, 179
[INFO] 2021-07-12 18:23:45,418 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7799999341150397e-06, 179
[INFO] 2021-07-12 18:23:45,418 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 179
[INFO] 2021-07-12 18:23:45,418 [run_pretraining.py:  558]:	worker_index: 6, step: 179, cost: 9.881132, mlm loss: 9.881132, speed: 0.949189 steps/s, speed: 7.593512 samples/s, speed: 3887.878256 tokens/s, learning rate: 1.780e-06, loss_scalings: 26214.400391, pp_loss: 9.678009
[INFO] 2021-07-12 18:23:45,418 [run_pretraining.py:  512]:	********exe.run_179******* 
[INFO] 2021-07-12 18:23:46,481 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:23:46,481 [run_pretraining.py:  534]:	loss/total_loss, 9.865462303161621, 180
[INFO] 2021-07-12 18:23:46,481 [run_pretraining.py:  535]:	loss/mlm_loss, 9.865462303161621, 180
[INFO] 2021-07-12 18:23:46,481 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7899999420478707e-06, 180
[INFO] 2021-07-12 18:23:46,482 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 180
[INFO] 2021-07-12 18:23:46,482 [run_pretraining.py:  558]:	worker_index: 6, step: 180, cost: 9.865462, mlm loss: 9.865462, speed: 0.941068 steps/s, speed: 7.528545 samples/s, speed: 3854.615103 tokens/s, learning rate: 1.790e-06, loss_scalings: 26214.400391, pp_loss: 9.809704
[INFO] 2021-07-12 18:23:46,482 [run_pretraining.py:  512]:	********exe.run_180******* 
[INFO] 2021-07-12 18:24:11,810 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:24:11,811 [run_pretraining.py:  534]:	loss/total_loss, 10.051374435424805, 181
[INFO] 2021-07-12 18:24:11,811 [run_pretraining.py:  535]:	loss/mlm_loss, 10.051374435424805, 181
[INFO] 2021-07-12 18:24:11,811 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.799999836293864e-06, 181
[INFO] 2021-07-12 18:24:11,811 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 181
[INFO] 2021-07-12 18:24:11,811 [run_pretraining.py:  558]:	worker_index: 6, step: 181, cost: 10.051374, mlm loss: 10.051374, speed: 0.039481 steps/s, speed: 0.315845 samples/s, speed: 161.712570 tokens/s, learning rate: 1.800e-06, loss_scalings: 26214.400391, pp_loss: 9.900257
[INFO] 2021-07-12 18:24:11,811 [run_pretraining.py:  512]:	********exe.run_181******* 
[INFO] 2021-07-12 18:24:12,840 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:24:12,841 [run_pretraining.py:  534]:	loss/total_loss, 10.045537948608398, 182
[INFO] 2021-07-12 18:24:12,841 [run_pretraining.py:  535]:	loss/mlm_loss, 10.045537948608398, 182
[INFO] 2021-07-12 18:24:12,841 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8100000716003706e-06, 182
[INFO] 2021-07-12 18:24:12,841 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 182
[INFO] 2021-07-12 18:24:12,841 [run_pretraining.py:  558]:	worker_index: 6, step: 182, cost: 10.045538, mlm loss: 10.045538, speed: 0.971476 steps/s, speed: 7.771808 samples/s, speed: 3979.165778 tokens/s, learning rate: 1.810e-06, loss_scalings: 26214.400391, pp_loss: 9.920242
[INFO] 2021-07-12 18:24:12,842 [run_pretraining.py:  512]:	********exe.run_182******* 
[INFO] 2021-07-12 18:24:13,889 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:24:13,889 [run_pretraining.py:  534]:	loss/total_loss, 9.653166770935059, 183
[INFO] 2021-07-12 18:24:13,889 [run_pretraining.py:  535]:	loss/mlm_loss, 9.653166770935059, 183
[INFO] 2021-07-12 18:24:13,889 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8200000795332016e-06, 183
[INFO] 2021-07-12 18:24:13,890 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 183
[INFO] 2021-07-12 18:24:13,890 [run_pretraining.py:  558]:	worker_index: 6, step: 183, cost: 9.653167, mlm loss: 9.653167, speed: 0.954722 steps/s, speed: 7.637775 samples/s, speed: 3910.540622 tokens/s, learning rate: 1.820e-06, loss_scalings: 26214.400391, pp_loss: 9.770442
[INFO] 2021-07-12 18:24:13,890 [run_pretraining.py:  512]:	********exe.run_183******* 
[INFO] 2021-07-12 18:24:39,787 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:24:39,788 [run_pretraining.py:  534]:	loss/total_loss, 9.81477165222168, 184
[INFO] 2021-07-12 18:24:39,788 [run_pretraining.py:  535]:	loss/mlm_loss, 9.81477165222168, 184
[INFO] 2021-07-12 18:24:39,788 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.829999973779195e-06, 184
[INFO] 2021-07-12 18:24:39,788 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 184
[INFO] 2021-07-12 18:24:39,788 [run_pretraining.py:  558]:	worker_index: 6, step: 184, cost: 9.814772, mlm loss: 9.814772, speed: 0.038614 steps/s, speed: 0.308909 samples/s, speed: 158.161409 tokens/s, learning rate: 1.830e-06, loss_scalings: 26214.400391, pp_loss: 9.814228
[INFO] 2021-07-12 18:24:39,788 [run_pretraining.py:  512]:	********exe.run_184******* 
[INFO] 2021-07-12 18:24:40,762 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:24:40,763 [run_pretraining.py:  534]:	loss/total_loss, 9.565237045288086, 185
[INFO] 2021-07-12 18:24:40,763 [run_pretraining.py:  535]:	loss/mlm_loss, 9.565237045288086, 185
[INFO] 2021-07-12 18:24:40,763 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.839999981712026e-06, 185
[INFO] 2021-07-12 18:24:40,763 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 185
[INFO] 2021-07-12 18:24:40,763 [run_pretraining.py:  558]:	worker_index: 6, step: 185, cost: 9.565237, mlm loss: 9.565237, speed: 1.026318 steps/s, speed: 8.210544 samples/s, speed: 4203.798468 tokens/s, learning rate: 1.840e-06, loss_scalings: 26214.400391, pp_loss: 8.565405
[INFO] 2021-07-12 18:24:40,763 [run_pretraining.py:  512]:	********exe.run_185******* 
[INFO] 2021-07-12 18:24:41,716 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:24:41,717 [run_pretraining.py:  534]:	loss/total_loss, 9.796907424926758, 186
[INFO] 2021-07-12 18:24:41,717 [run_pretraining.py:  535]:	loss/mlm_loss, 9.796907424926758, 186
[INFO] 2021-07-12 18:24:41,717 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8499999896448571e-06, 186
[INFO] 2021-07-12 18:24:41,717 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 186
[INFO] 2021-07-12 18:24:41,717 [run_pretraining.py:  558]:	worker_index: 6, step: 186, cost: 9.796907, mlm loss: 9.796907, speed: 1.048696 steps/s, speed: 8.389571 samples/s, speed: 4295.460200 tokens/s, learning rate: 1.850e-06, loss_scalings: 26214.400391, pp_loss: 9.786085
[INFO] 2021-07-12 18:24:41,718 [run_pretraining.py:  512]:	********exe.run_186******* 
[INFO] 2021-07-12 18:24:42,679 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:24:42,680 [run_pretraining.py:  534]:	loss/total_loss, 9.665458679199219, 187
[INFO] 2021-07-12 18:24:42,680 [run_pretraining.py:  535]:	loss/mlm_loss, 9.665458679199219, 187
[INFO] 2021-07-12 18:24:42,680 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8599999975776882e-06, 187
[INFO] 2021-07-12 18:24:42,680 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 187
[INFO] 2021-07-12 18:24:42,680 [run_pretraining.py:  558]:	worker_index: 6, step: 187, cost: 9.665459, mlm loss: 9.665459, speed: 1.039358 steps/s, speed: 8.314863 samples/s, speed: 4257.210100 tokens/s, learning rate: 1.860e-06, loss_scalings: 26214.400391, pp_loss: 9.730171
[INFO] 2021-07-12 18:24:42,680 [run_pretraining.py:  512]:	********exe.run_187******* 
[INFO] 2021-07-12 18:25:06,937 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:25:06,937 [run_pretraining.py:  534]:	loss/total_loss, 9.820500373840332, 188
[INFO] 2021-07-12 18:25:06,938 [run_pretraining.py:  535]:	loss/mlm_loss, 9.820500373840332, 188
[INFO] 2021-07-12 18:25:06,938 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8699998918236815e-06, 188
[INFO] 2021-07-12 18:25:06,938 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 188
[INFO] 2021-07-12 18:25:06,938 [run_pretraining.py:  558]:	worker_index: 6, step: 188, cost: 9.820500, mlm loss: 9.820500, speed: 0.041226 steps/s, speed: 0.329805 samples/s, speed: 168.859933 tokens/s, learning rate: 1.870e-06, loss_scalings: 26214.400391, pp_loss: 9.758050
[INFO] 2021-07-12 18:25:06,938 [run_pretraining.py:  512]:	********exe.run_188******* 
[INFO] 2021-07-12 18:25:07,893 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:25:07,893 [run_pretraining.py:  534]:	loss/total_loss, 9.901468276977539, 189
[INFO] 2021-07-12 18:25:07,894 [run_pretraining.py:  535]:	loss/mlm_loss, 9.901468276977539, 189
[INFO] 2021-07-12 18:25:07,894 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8799998997565126e-06, 189
[INFO] 2021-07-12 18:25:07,894 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 189
[INFO] 2021-07-12 18:25:07,894 [run_pretraining.py:  558]:	worker_index: 6, step: 189, cost: 9.901468, mlm loss: 9.901468, speed: 1.046900 steps/s, speed: 8.375197 samples/s, speed: 4288.100974 tokens/s, learning rate: 1.880e-06, loss_scalings: 26214.400391, pp_loss: 9.788570
[INFO] 2021-07-12 18:25:07,894 [run_pretraining.py:  512]:	********exe.run_189******* 
[INFO] 2021-07-12 18:25:30,891 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:25:30,892 [run_pretraining.py:  534]:	loss/total_loss, 9.544644355773926, 190
[INFO] 2021-07-12 18:25:30,892 [run_pretraining.py:  535]:	loss/mlm_loss, 9.544644355773926, 190
[INFO] 2021-07-12 18:25:30,892 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8899999076893437e-06, 190
[INFO] 2021-07-12 18:25:30,892 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 190
[INFO] 2021-07-12 18:25:30,892 [run_pretraining.py:  558]:	worker_index: 6, step: 190, cost: 9.544644, mlm loss: 9.544644, speed: 0.043482 steps/s, speed: 0.347858 samples/s, speed: 178.103545 tokens/s, learning rate: 1.890e-06, loss_scalings: 26214.400391, pp_loss: 9.704578
[INFO] 2021-07-12 18:25:30,892 [run_pretraining.py:  512]:	********exe.run_190******* 
[INFO] 2021-07-12 18:25:31,862 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:25:31,863 [run_pretraining.py:  534]:	loss/total_loss, 9.744024276733398, 191
[INFO] 2021-07-12 18:25:31,863 [run_pretraining.py:  535]:	loss/mlm_loss, 9.744024276733398, 191
[INFO] 2021-07-12 18:25:31,863 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8999999156221747e-06, 191
[INFO] 2021-07-12 18:25:31,863 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 191
[INFO] 2021-07-12 18:25:31,863 [run_pretraining.py:  558]:	worker_index: 6, step: 191, cost: 9.744024, mlm loss: 9.744024, speed: 1.031052 steps/s, speed: 8.248420 samples/s, speed: 4223.190998 tokens/s, learning rate: 1.900e-06, loss_scalings: 26214.400391, pp_loss: 9.758062
[INFO] 2021-07-12 18:25:31,863 [run_pretraining.py:  512]:	********exe.run_191******* 
[INFO] 2021-07-12 18:25:32,821 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:25:32,822 [run_pretraining.py:  534]:	loss/total_loss, 9.829445838928223, 192
[INFO] 2021-07-12 18:25:32,822 [run_pretraining.py:  535]:	loss/mlm_loss, 9.829445838928223, 192
[INFO] 2021-07-12 18:25:32,822 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.909999809868168e-06, 192
[INFO] 2021-07-12 18:25:32,822 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 192
[INFO] 2021-07-12 18:25:32,822 [run_pretraining.py:  558]:	worker_index: 6, step: 192, cost: 9.829446, mlm loss: 9.829446, speed: 1.043237 steps/s, speed: 8.345894 samples/s, speed: 4273.097583 tokens/s, learning rate: 1.910e-06, loss_scalings: 26214.400391, pp_loss: 9.830781
[INFO] 2021-07-12 18:25:32,822 [run_pretraining.py:  512]:	********exe.run_192******* 
[INFO] 2021-07-12 18:25:58,160 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:25:58,161 [run_pretraining.py:  534]:	loss/total_loss, 9.759394645690918, 193
[INFO] 2021-07-12 18:25:58,161 [run_pretraining.py:  535]:	loss/mlm_loss, 9.759394645690918, 193
[INFO] 2021-07-12 18:25:58,161 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.919999931487837e-06, 193
[INFO] 2021-07-12 18:25:58,162 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 193
[INFO] 2021-07-12 18:25:58,162 [run_pretraining.py:  558]:	worker_index: 6, step: 193, cost: 9.759395, mlm loss: 9.759395, speed: 0.039466 steps/s, speed: 0.315725 samples/s, speed: 161.651234 tokens/s, learning rate: 1.920e-06, loss_scalings: 26214.400391, pp_loss: 9.799809
[INFO] 2021-07-12 18:25:58,162 [run_pretraining.py:  512]:	********exe.run_193******* 
[INFO] 2021-07-12 18:26:21,183 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:26:21,183 [run_pretraining.py:  534]:	loss/total_loss, 10.182732582092285, 194
[INFO] 2021-07-12 18:26:21,184 [run_pretraining.py:  535]:	loss/mlm_loss, 10.182732582092285, 194
[INFO] 2021-07-12 18:26:21,184 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9300000531075057e-06, 194
[INFO] 2021-07-12 18:26:21,184 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 194
[INFO] 2021-07-12 18:26:21,184 [run_pretraining.py:  558]:	worker_index: 6, step: 194, cost: 10.182733, mlm loss: 10.182733, speed: 0.043438 steps/s, speed: 0.347502 samples/s, speed: 177.921248 tokens/s, learning rate: 1.930e-06, loss_scalings: 26214.400391, pp_loss: 9.948288
[INFO] 2021-07-12 18:26:21,184 [run_pretraining.py:  512]:	********exe.run_194******* 
[INFO] 2021-07-12 18:26:22,138 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:26:22,138 [run_pretraining.py:  534]:	loss/total_loss, 9.711851119995117, 195
[INFO] 2021-07-12 18:26:22,139 [run_pretraining.py:  535]:	loss/mlm_loss, 9.711851119995117, 195
[INFO] 2021-07-12 18:26:22,139 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.939999947353499e-06, 195
[INFO] 2021-07-12 18:26:22,139 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 195
[INFO] 2021-07-12 18:26:22,139 [run_pretraining.py:  558]:	worker_index: 6, step: 195, cost: 9.711851, mlm loss: 9.711851, speed: 1.047952 steps/s, speed: 8.383613 samples/s, speed: 4292.410093 tokens/s, learning rate: 1.940e-06, loss_scalings: 26214.400391, pp_loss: 9.674147
[INFO] 2021-07-12 18:26:22,139 [run_pretraining.py:  512]:	********exe.run_195******* 
[INFO] 2021-07-12 18:26:23,096 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:26:23,097 [run_pretraining.py:  534]:	loss/total_loss, 9.667091369628906, 196
[INFO] 2021-07-12 18:26:23,097 [run_pretraining.py:  535]:	loss/mlm_loss, 9.667091369628906, 196
[INFO] 2021-07-12 18:26:23,097 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.950000068973168e-06, 196
[INFO] 2021-07-12 18:26:23,097 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 196
[INFO] 2021-07-12 18:26:23,097 [run_pretraining.py:  558]:	worker_index: 6, step: 196, cost: 9.667091, mlm loss: 9.667091, speed: 1.044257 steps/s, speed: 8.354058 samples/s, speed: 4277.277545 tokens/s, learning rate: 1.950e-06, loss_scalings: 26214.400391, pp_loss: 9.849724
[INFO] 2021-07-12 18:26:23,097 [run_pretraining.py:  512]:	********exe.run_196******* 
[INFO] 2021-07-12 18:26:24,063 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:26:24,064 [run_pretraining.py:  534]:	loss/total_loss, 8.003186225891113, 197
[INFO] 2021-07-12 18:26:24,064 [run_pretraining.py:  535]:	loss/mlm_loss, 8.003186225891113, 197
[INFO] 2021-07-12 18:26:24,064 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.959999963219161e-06, 197
[INFO] 2021-07-12 18:26:24,064 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 197
[INFO] 2021-07-12 18:26:24,064 [run_pretraining.py:  558]:	worker_index: 6, step: 197, cost: 8.003186, mlm loss: 8.003186, speed: 1.034704 steps/s, speed: 8.277630 samples/s, speed: 4238.146466 tokens/s, learning rate: 1.960e-06, loss_scalings: 26214.400391, pp_loss: 9.228765
[INFO] 2021-07-12 18:26:24,065 [run_pretraining.py:  512]:	********exe.run_197******* 
[INFO] 2021-07-12 18:26:25,021 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:26:25,021 [run_pretraining.py:  534]:	loss/total_loss, 9.795595169067383, 198
[INFO] 2021-07-12 18:26:25,021 [run_pretraining.py:  535]:	loss/mlm_loss, 9.795595169067383, 198
[INFO] 2021-07-12 18:26:25,021 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9699998574651545e-06, 198
[INFO] 2021-07-12 18:26:25,022 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 198
[INFO] 2021-07-12 18:26:25,022 [run_pretraining.py:  558]:	worker_index: 6, step: 198, cost: 9.795595, mlm loss: 9.795595, speed: 1.045561 steps/s, speed: 8.364485 samples/s, speed: 4282.616231 tokens/s, learning rate: 1.970e-06, loss_scalings: 26214.400391, pp_loss: 9.815987
[INFO] 2021-07-12 18:26:25,022 [run_pretraining.py:  512]:	********exe.run_198******* 
[INFO] 2021-07-12 18:27:15,709 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:27:15,710 [run_pretraining.py:  534]:	loss/total_loss, 9.66678237915039, 199
[INFO] 2021-07-12 18:27:15,710 [run_pretraining.py:  535]:	loss/mlm_loss, 9.66678237915039, 199
[INFO] 2021-07-12 18:27:15,710 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9799999790848233e-06, 199
[INFO] 2021-07-12 18:27:15,710 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 199
[INFO] 2021-07-12 18:27:15,710 [run_pretraining.py:  558]:	worker_index: 6, step: 199, cost: 9.666782, mlm loss: 9.666782, speed: 0.019729 steps/s, speed: 0.157829 samples/s, speed: 80.808339 tokens/s, learning rate: 1.980e-06, loss_scalings: 26214.400391, pp_loss: 9.796329
[INFO] 2021-07-12 18:27:15,710 [run_pretraining.py:  512]:	********exe.run_199******* 
[INFO] 2021-07-12 18:27:40,965 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:27:40,966 [run_pretraining.py:  534]:	loss/total_loss, 9.556011199951172, 200
[INFO] 2021-07-12 18:27:40,966 [run_pretraining.py:  535]:	loss/mlm_loss, 9.556011199951172, 200
[INFO] 2021-07-12 18:27:40,966 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9899998733308166e-06, 200
[INFO] 2021-07-12 18:27:40,966 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 200
[INFO] 2021-07-12 18:27:40,966 [run_pretraining.py:  558]:	worker_index: 6, step: 200, cost: 9.556011, mlm loss: 9.556011, speed: 0.039595 steps/s, speed: 0.316763 samples/s, speed: 162.182739 tokens/s, learning rate: 1.990e-06, loss_scalings: 26214.400391, pp_loss: 8.762031
[INFO] 2021-07-12 18:27:40,967 [run_pretraining.py:  512]:	********exe.run_200******* 
[INFO] 2021-07-12 18:28:05,990 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:05,991 [run_pretraining.py:  534]:	loss/total_loss, 9.833147048950195, 201
[INFO] 2021-07-12 18:28:05,991 [run_pretraining.py:  535]:	loss/mlm_loss, 9.833147048950195, 201
[INFO] 2021-07-12 18:28:05,991 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9999999949504854e-06, 201
[INFO] 2021-07-12 18:28:05,991 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 201
[INFO] 2021-07-12 18:28:05,991 [run_pretraining.py:  558]:	worker_index: 6, step: 201, cost: 9.833147, mlm loss: 9.833147, speed: 0.039961 steps/s, speed: 0.319692 samples/s, speed: 163.682056 tokens/s, learning rate: 2.000e-06, loss_scalings: 26214.400391, pp_loss: 9.799318
[INFO] 2021-07-12 18:28:05,992 [run_pretraining.py:  512]:	********exe.run_201******* 
[INFO] 2021-07-12 18:28:06,917 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:06,917 [run_pretraining.py:  534]:	loss/total_loss, 9.677040100097656, 202
[INFO] 2021-07-12 18:28:06,917 [run_pretraining.py:  535]:	loss/mlm_loss, 9.677040100097656, 202
[INFO] 2021-07-12 18:28:06,917 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0099998891964788e-06, 202
[INFO] 2021-07-12 18:28:06,917 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 202
[INFO] 2021-07-12 18:28:06,918 [run_pretraining.py:  558]:	worker_index: 6, step: 202, cost: 9.677040, mlm loss: 9.677040, speed: 1.080621 steps/s, speed: 8.644970 samples/s, speed: 4426.224779 tokens/s, learning rate: 2.010e-06, loss_scalings: 26214.400391, pp_loss: 9.675567
[INFO] 2021-07-12 18:28:06,918 [run_pretraining.py:  512]:	********exe.run_202******* 
[INFO] 2021-07-12 18:28:07,935 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:07,935 [run_pretraining.py:  534]:	loss/total_loss, 9.613142967224121, 203
[INFO] 2021-07-12 18:28:07,935 [run_pretraining.py:  535]:	loss/mlm_loss, 9.613142967224121, 203
[INFO] 2021-07-12 18:28:07,935 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.019999783442472e-06, 203
[INFO] 2021-07-12 18:28:07,936 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 203
[INFO] 2021-07-12 18:28:07,936 [run_pretraining.py:  558]:	worker_index: 6, step: 203, cost: 9.613143, mlm loss: 9.613143, speed: 0.982884 steps/s, speed: 7.863074 samples/s, speed: 4025.893673 tokens/s, learning rate: 2.020e-06, loss_scalings: 26214.400391, pp_loss: 9.682042
[INFO] 2021-07-12 18:28:07,936 [run_pretraining.py:  512]:	********exe.run_203******* 
[INFO] 2021-07-12 18:28:08,856 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:08,857 [run_pretraining.py:  534]:	loss/total_loss, 9.740330696105957, 204
[INFO] 2021-07-12 18:28:08,857 [run_pretraining.py:  535]:	loss/mlm_loss, 9.740330696105957, 204
[INFO] 2021-07-12 18:28:08,857 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0300001324358163e-06, 204
[INFO] 2021-07-12 18:28:08,857 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 204
[INFO] 2021-07-12 18:28:08,857 [run_pretraining.py:  558]:	worker_index: 6, step: 204, cost: 9.740331, mlm loss: 9.740331, speed: 1.085967 steps/s, speed: 8.687735 samples/s, speed: 4448.120534 tokens/s, learning rate: 2.030e-06, loss_scalings: 26214.400391, pp_loss: 9.842382
[INFO] 2021-07-12 18:28:08,857 [run_pretraining.py:  512]:	********exe.run_204******* 
[INFO] 2021-07-12 18:28:09,768 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:09,769 [run_pretraining.py:  534]:	loss/total_loss, 10.177876472473145, 205
[INFO] 2021-07-12 18:28:09,769 [run_pretraining.py:  535]:	loss/mlm_loss, 10.177876472473145, 205
[INFO] 2021-07-12 18:28:09,769 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0400000266818097e-06, 205
[INFO] 2021-07-12 18:28:09,769 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 205
[INFO] 2021-07-12 18:28:09,769 [run_pretraining.py:  558]:	worker_index: 6, step: 205, cost: 10.177876, mlm loss: 10.177876, speed: 1.097215 steps/s, speed: 8.777720 samples/s, speed: 4494.192607 tokens/s, learning rate: 2.040e-06, loss_scalings: 26214.400391, pp_loss: 9.726018
[INFO] 2021-07-12 18:28:09,770 [run_pretraining.py:  512]:	********exe.run_205******* 
[INFO] 2021-07-12 18:28:10,679 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:10,679 [run_pretraining.py:  534]:	loss/total_loss, 9.582375526428223, 206
[INFO] 2021-07-12 18:28:10,679 [run_pretraining.py:  535]:	loss/mlm_loss, 9.582375526428223, 206
[INFO] 2021-07-12 18:28:10,679 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.049999920927803e-06, 206
[INFO] 2021-07-12 18:28:10,680 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 206
[INFO] 2021-07-12 18:28:10,680 [run_pretraining.py:  558]:	worker_index: 6, step: 206, cost: 9.582376, mlm loss: 9.582376, speed: 1.099595 steps/s, speed: 8.796760 samples/s, speed: 4503.941158 tokens/s, learning rate: 2.050e-06, loss_scalings: 26214.400391, pp_loss: 9.671471
[INFO] 2021-07-12 18:28:10,680 [run_pretraining.py:  512]:	********exe.run_206******* 
[INFO] 2021-07-12 18:28:11,590 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:11,591 [run_pretraining.py:  534]:	loss/total_loss, 9.638787269592285, 207
[INFO] 2021-07-12 18:28:11,591 [run_pretraining.py:  535]:	loss/mlm_loss, 9.638787269592285, 207
[INFO] 2021-07-12 18:28:11,591 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.060000042547472e-06, 207
[INFO] 2021-07-12 18:28:11,591 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 207
[INFO] 2021-07-12 18:28:11,591 [run_pretraining.py:  558]:	worker_index: 6, step: 207, cost: 9.638787, mlm loss: 9.638787, speed: 1.097688 steps/s, speed: 8.781501 samples/s, speed: 4496.128585 tokens/s, learning rate: 2.060e-06, loss_scalings: 26214.400391, pp_loss: 9.719943
[INFO] 2021-07-12 18:28:11,591 [run_pretraining.py:  512]:	********exe.run_207******* 
[INFO] 2021-07-12 18:28:12,502 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:12,502 [run_pretraining.py:  534]:	loss/total_loss, 9.615337371826172, 208
[INFO] 2021-07-12 18:28:12,502 [run_pretraining.py:  535]:	loss/mlm_loss, 9.615337371826172, 208
[INFO] 2021-07-12 18:28:12,502 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.069999936793465e-06, 208
[INFO] 2021-07-12 18:28:12,502 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 208
[INFO] 2021-07-12 18:28:12,503 [run_pretraining.py:  558]:	worker_index: 6, step: 208, cost: 9.615337, mlm loss: 9.615337, speed: 1.098314 steps/s, speed: 8.786509 samples/s, speed: 4498.692851 tokens/s, learning rate: 2.070e-06, loss_scalings: 26214.400391, pp_loss: 9.757401
[INFO] 2021-07-12 18:28:12,503 [run_pretraining.py:  512]:	********exe.run_208******* 
[INFO] 2021-07-12 18:28:13,443 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:13,443 [run_pretraining.py:  534]:	loss/total_loss, 9.733436584472656, 209
[INFO] 2021-07-12 18:28:13,443 [run_pretraining.py:  535]:	loss/mlm_loss, 9.733436584472656, 209
[INFO] 2021-07-12 18:28:13,443 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.080000058413134e-06, 209
[INFO] 2021-07-12 18:28:13,444 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 209
[INFO] 2021-07-12 18:28:13,444 [run_pretraining.py:  558]:	worker_index: 6, step: 209, cost: 9.733437, mlm loss: 9.733437, speed: 1.063483 steps/s, speed: 8.507863 samples/s, speed: 4356.025708 tokens/s, learning rate: 2.080e-06, loss_scalings: 26214.400391, pp_loss: 9.780852
[INFO] 2021-07-12 18:28:13,444 [run_pretraining.py:  512]:	********exe.run_209******* 
[INFO] 2021-07-12 18:28:14,351 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:14,351 [run_pretraining.py:  534]:	loss/total_loss, 9.630313873291016, 210
[INFO] 2021-07-12 18:28:14,352 [run_pretraining.py:  535]:	loss/mlm_loss, 9.630313873291016, 210
[INFO] 2021-07-12 18:28:14,352 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0899999526591273e-06, 210
[INFO] 2021-07-12 18:28:14,352 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 210
[INFO] 2021-07-12 18:28:14,352 [run_pretraining.py:  558]:	worker_index: 6, step: 210, cost: 9.630314, mlm loss: 9.630314, speed: 1.101934 steps/s, speed: 8.815468 samples/s, speed: 4513.519825 tokens/s, learning rate: 2.090e-06, loss_scalings: 26214.400391, pp_loss: 9.597125
[INFO] 2021-07-12 18:28:14,352 [run_pretraining.py:  512]:	********exe.run_210******* 
[INFO] 2021-07-12 18:28:15,263 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:15,264 [run_pretraining.py:  534]:	loss/total_loss, 9.769152641296387, 211
[INFO] 2021-07-12 18:28:15,264 [run_pretraining.py:  535]:	loss/mlm_loss, 9.769152641296387, 211
[INFO] 2021-07-12 18:28:15,264 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0999998469051206e-06, 211
[INFO] 2021-07-12 18:28:15,264 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 211
[INFO] 2021-07-12 18:28:15,264 [run_pretraining.py:  558]:	worker_index: 6, step: 211, cost: 9.769153, mlm loss: 9.769153, speed: 1.097238 steps/s, speed: 8.777904 samples/s, speed: 4494.286662 tokens/s, learning rate: 2.100e-06, loss_scalings: 26214.400391, pp_loss: 9.635818
[INFO] 2021-07-12 18:28:15,264 [run_pretraining.py:  512]:	********exe.run_211******* 
[INFO] 2021-07-12 18:28:16,170 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:16,170 [run_pretraining.py:  534]:	loss/total_loss, 9.557538986206055, 212
[INFO] 2021-07-12 18:28:16,170 [run_pretraining.py:  535]:	loss/mlm_loss, 9.557538986206055, 212
[INFO] 2021-07-12 18:28:16,171 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1099999685247894e-06, 212
[INFO] 2021-07-12 18:28:16,171 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 212
[INFO] 2021-07-12 18:28:16,171 [run_pretraining.py:  558]:	worker_index: 6, step: 212, cost: 9.557539, mlm loss: 9.557539, speed: 1.103740 steps/s, speed: 8.829923 samples/s, speed: 4520.920650 tokens/s, learning rate: 2.110e-06, loss_scalings: 26214.400391, pp_loss: 9.686890
[INFO] 2021-07-12 18:28:16,171 [run_pretraining.py:  512]:	********exe.run_212******* 
[INFO] 2021-07-12 18:28:17,079 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:17,080 [run_pretraining.py:  534]:	loss/total_loss, 9.860551834106445, 213
[INFO] 2021-07-12 18:28:17,080 [run_pretraining.py:  535]:	loss/mlm_loss, 9.860551834106445, 213
[INFO] 2021-07-12 18:28:17,080 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1199998627707828e-06, 213
[INFO] 2021-07-12 18:28:17,080 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 213
[INFO] 2021-07-12 18:28:17,080 [run_pretraining.py:  558]:	worker_index: 6, step: 213, cost: 9.860552, mlm loss: 9.860552, speed: 1.100097 steps/s, speed: 8.800777 samples/s, speed: 4505.997818 tokens/s, learning rate: 2.120e-06, loss_scalings: 26214.400391, pp_loss: 9.707380
[INFO] 2021-07-12 18:28:17,081 [run_pretraining.py:  512]:	********exe.run_213******* 
[INFO] 2021-07-12 18:28:17,990 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:17,990 [run_pretraining.py:  534]:	loss/total_loss, 9.877543449401855, 214
[INFO] 2021-07-12 18:28:17,990 [run_pretraining.py:  535]:	loss/mlm_loss, 9.877543449401855, 214
[INFO] 2021-07-12 18:28:17,990 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.129999757016776e-06, 214
[INFO] 2021-07-12 18:28:17,991 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 214
[INFO] 2021-07-12 18:28:17,991 [run_pretraining.py:  558]:	worker_index: 6, step: 214, cost: 9.877543, mlm loss: 9.877543, speed: 1.099637 steps/s, speed: 8.797092 samples/s, speed: 4504.111195 tokens/s, learning rate: 2.130e-06, loss_scalings: 26214.400391, pp_loss: 9.737823
[INFO] 2021-07-12 18:28:17,991 [run_pretraining.py:  512]:	********exe.run_214******* 
[INFO] 2021-07-12 18:28:18,898 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:18,898 [run_pretraining.py:  534]:	loss/total_loss, 9.667643547058105, 215
[INFO] 2021-07-12 18:28:18,898 [run_pretraining.py:  535]:	loss/mlm_loss, 9.667643547058105, 215
[INFO] 2021-07-12 18:28:18,899 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1400001060101204e-06, 215
[INFO] 2021-07-12 18:28:18,899 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 215
[INFO] 2021-07-12 18:28:18,899 [run_pretraining.py:  558]:	worker_index: 6, step: 215, cost: 9.667644, mlm loss: 9.667644, speed: 1.102053 steps/s, speed: 8.816420 samples/s, speed: 4514.007240 tokens/s, learning rate: 2.140e-06, loss_scalings: 26214.400391, pp_loss: 9.675888
[INFO] 2021-07-12 18:28:18,899 [run_pretraining.py:  512]:	********exe.run_215******* 
[INFO] 2021-07-12 18:28:19,810 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:19,810 [run_pretraining.py:  534]:	loss/total_loss, 9.508084297180176, 216
[INFO] 2021-07-12 18:28:19,810 [run_pretraining.py:  535]:	loss/mlm_loss, 9.508084297180176, 216
[INFO] 2021-07-12 18:28:19,811 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1500000002561137e-06, 216
[INFO] 2021-07-12 18:28:19,811 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 216
[INFO] 2021-07-12 18:28:19,811 [run_pretraining.py:  558]:	worker_index: 6, step: 216, cost: 9.508084, mlm loss: 9.508084, speed: 1.097373 steps/s, speed: 8.778983 samples/s, speed: 4494.839316 tokens/s, learning rate: 2.150e-06, loss_scalings: 26214.400391, pp_loss: 9.488983
[INFO] 2021-07-12 18:28:19,811 [run_pretraining.py:  512]:	********exe.run_216******* 
[INFO] 2021-07-12 18:28:20,723 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:20,724 [run_pretraining.py:  534]:	loss/total_loss, 9.737234115600586, 217
[INFO] 2021-07-12 18:28:20,724 [run_pretraining.py:  535]:	loss/mlm_loss, 9.737234115600586, 217
[INFO] 2021-07-12 18:28:20,724 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.159999894502107e-06, 217
[INFO] 2021-07-12 18:28:20,724 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 217
[INFO] 2021-07-12 18:28:20,724 [run_pretraining.py:  558]:	worker_index: 6, step: 217, cost: 9.737234, mlm loss: 9.737234, speed: 1.095333 steps/s, speed: 8.762667 samples/s, speed: 4486.485257 tokens/s, learning rate: 2.160e-06, loss_scalings: 26214.400391, pp_loss: 9.759333
[INFO] 2021-07-12 18:28:20,724 [run_pretraining.py:  512]:	********exe.run_217******* 
[INFO] 2021-07-12 18:28:46,550 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:46,551 [run_pretraining.py:  534]:	loss/total_loss, 9.811607360839844, 218
[INFO] 2021-07-12 18:28:46,551 [run_pretraining.py:  535]:	loss/mlm_loss, 9.811607360839844, 218
[INFO] 2021-07-12 18:28:46,551 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.170000016121776e-06, 218
[INFO] 2021-07-12 18:28:46,551 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 218
[INFO] 2021-07-12 18:28:46,551 [run_pretraining.py:  558]:	worker_index: 6, step: 218, cost: 9.811607, mlm loss: 9.811607, speed: 0.038721 steps/s, speed: 0.309766 samples/s, speed: 158.600291 tokens/s, learning rate: 2.170e-06, loss_scalings: 26214.400391, pp_loss: 9.662910
[INFO] 2021-07-12 18:28:46,551 [run_pretraining.py:  512]:	********exe.run_218******* 
[INFO] 2021-07-12 18:28:47,458 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:47,459 [run_pretraining.py:  534]:	loss/total_loss, 9.440299987792969, 219
[INFO] 2021-07-12 18:28:47,459 [run_pretraining.py:  535]:	loss/mlm_loss, 9.440299987792969, 219
[INFO] 2021-07-12 18:28:47,459 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.179999910367769e-06, 219
[INFO] 2021-07-12 18:28:47,459 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 219
[INFO] 2021-07-12 18:28:47,459 [run_pretraining.py:  558]:	worker_index: 6, step: 219, cost: 9.440300, mlm loss: 9.440300, speed: 1.101903 steps/s, speed: 8.815228 samples/s, speed: 4513.396505 tokens/s, learning rate: 2.180e-06, loss_scalings: 26214.400391, pp_loss: 9.590439
[INFO] 2021-07-12 18:28:47,459 [run_pretraining.py:  512]:	********exe.run_219******* 
[INFO] 2021-07-12 18:28:48,366 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:48,367 [run_pretraining.py:  534]:	loss/total_loss, 9.333393096923828, 220
[INFO] 2021-07-12 18:28:48,367 [run_pretraining.py:  535]:	loss/mlm_loss, 9.333393096923828, 220
[INFO] 2021-07-12 18:28:48,367 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.190000031987438e-06, 220
[INFO] 2021-07-12 18:28:48,367 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 220
[INFO] 2021-07-12 18:28:48,367 [run_pretraining.py:  558]:	worker_index: 6, step: 220, cost: 9.333393, mlm loss: 9.333393, speed: 1.102481 steps/s, speed: 8.819850 samples/s, speed: 4515.763284 tokens/s, learning rate: 2.190e-06, loss_scalings: 26214.400391, pp_loss: 9.470562
[INFO] 2021-07-12 18:28:48,367 [run_pretraining.py:  512]:	********exe.run_220******* 
[INFO] 2021-07-12 18:28:49,276 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:49,276 [run_pretraining.py:  534]:	loss/total_loss, 9.93688678741455, 221
[INFO] 2021-07-12 18:28:49,276 [run_pretraining.py:  535]:	loss/mlm_loss, 9.93688678741455, 221
[INFO] 2021-07-12 18:28:49,277 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1999999262334313e-06, 221
[INFO] 2021-07-12 18:28:49,277 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 221
[INFO] 2021-07-12 18:28:49,277 [run_pretraining.py:  558]:	worker_index: 6, step: 221, cost: 9.936887, mlm loss: 9.936887, speed: 1.100220 steps/s, speed: 8.801760 samples/s, speed: 4506.501342 tokens/s, learning rate: 2.200e-06, loss_scalings: 26214.400391, pp_loss: 9.661680
[INFO] 2021-07-12 18:28:49,277 [run_pretraining.py:  512]:	********exe.run_221******* 
[INFO] 2021-07-12 18:28:50,187 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:50,188 [run_pretraining.py:  534]:	loss/total_loss, 9.71615219116211, 222
[INFO] 2021-07-12 18:28:50,188 [run_pretraining.py:  535]:	loss/mlm_loss, 9.71615219116211, 222
[INFO] 2021-07-12 18:28:50,188 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2099998204794247e-06, 222
[INFO] 2021-07-12 18:28:50,188 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 222
[INFO] 2021-07-12 18:28:50,188 [run_pretraining.py:  558]:	worker_index: 6, step: 222, cost: 9.716152, mlm loss: 9.716152, speed: 1.098011 steps/s, speed: 8.784090 samples/s, speed: 4497.453915 tokens/s, learning rate: 2.210e-06, loss_scalings: 26214.400391, pp_loss: 9.589817
[INFO] 2021-07-12 18:28:50,188 [run_pretraining.py:  512]:	********exe.run_222******* 
[INFO] 2021-07-12 18:28:51,095 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:51,096 [run_pretraining.py:  534]:	loss/total_loss, 9.30949592590332, 223
[INFO] 2021-07-12 18:28:51,096 [run_pretraining.py:  535]:	loss/mlm_loss, 9.30949592590332, 223
[INFO] 2021-07-12 18:28:51,096 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2199999420990935e-06, 223
[INFO] 2021-07-12 18:28:51,096 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 223
[INFO] 2021-07-12 18:28:51,096 [run_pretraining.py:  558]:	worker_index: 6, step: 223, cost: 9.309496, mlm loss: 9.309496, speed: 1.102042 steps/s, speed: 8.816335 samples/s, speed: 4513.963357 tokens/s, learning rate: 2.220e-06, loss_scalings: 26214.400391, pp_loss: 9.590780
[INFO] 2021-07-12 18:28:51,096 [run_pretraining.py:  512]:	********exe.run_223******* 
[INFO] 2021-07-12 18:28:52,009 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:52,010 [run_pretraining.py:  534]:	loss/total_loss, 9.696810722351074, 224
[INFO] 2021-07-12 18:28:52,010 [run_pretraining.py:  535]:	loss/mlm_loss, 9.696810722351074, 224
[INFO] 2021-07-12 18:28:52,010 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.229999836345087e-06, 224
[INFO] 2021-07-12 18:28:52,010 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 224
[INFO] 2021-07-12 18:28:52,010 [run_pretraining.py:  558]:	worker_index: 6, step: 224, cost: 9.696811, mlm loss: 9.696811, speed: 1.095064 steps/s, speed: 8.760511 samples/s, speed: 4485.381848 tokens/s, learning rate: 2.230e-06, loss_scalings: 26214.400391, pp_loss: 9.616954
[INFO] 2021-07-12 18:28:52,010 [run_pretraining.py:  512]:	********exe.run_224******* 
[INFO] 2021-07-12 18:28:52,925 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:52,926 [run_pretraining.py:  534]:	loss/total_loss, 9.792037963867188, 225
[INFO] 2021-07-12 18:28:52,926 [run_pretraining.py:  535]:	loss/mlm_loss, 9.792037963867188, 225
[INFO] 2021-07-12 18:28:52,926 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2399999579647556e-06, 225
[INFO] 2021-07-12 18:28:52,926 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 225
[INFO] 2021-07-12 18:28:52,926 [run_pretraining.py:  558]:	worker_index: 6, step: 225, cost: 9.792038, mlm loss: 9.792038, speed: 1.092683 steps/s, speed: 8.741461 samples/s, speed: 4475.628269 tokens/s, learning rate: 2.240e-06, loss_scalings: 26214.400391, pp_loss: 9.608090
[INFO] 2021-07-12 18:28:52,926 [run_pretraining.py:  512]:	********exe.run_225******* 
[INFO] 2021-07-12 18:28:53,841 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:53,842 [run_pretraining.py:  534]:	loss/total_loss, 9.788871765136719, 226
[INFO] 2021-07-12 18:28:53,842 [run_pretraining.py:  535]:	loss/mlm_loss, 9.788871765136719, 226
[INFO] 2021-07-12 18:28:53,842 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2500000795844244e-06, 226
[INFO] 2021-07-12 18:28:53,842 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 226
[INFO] 2021-07-12 18:28:53,842 [run_pretraining.py:  558]:	worker_index: 6, step: 226, cost: 9.788872, mlm loss: 9.788872, speed: 1.092422 steps/s, speed: 8.739374 samples/s, speed: 4474.559328 tokens/s, learning rate: 2.250e-06, loss_scalings: 26214.400391, pp_loss: 9.530216
[INFO] 2021-07-12 18:28:53,842 [run_pretraining.py:  512]:	********exe.run_226******* 
[INFO] 2021-07-12 18:28:54,746 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:54,746 [run_pretraining.py:  534]:	loss/total_loss, 9.658624649047852, 227
[INFO] 2021-07-12 18:28:54,746 [run_pretraining.py:  535]:	loss/mlm_loss, 9.658624649047852, 227
[INFO] 2021-07-12 18:28:54,747 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2599999738304177e-06, 227
[INFO] 2021-07-12 18:28:54,747 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 227
[INFO] 2021-07-12 18:28:54,747 [run_pretraining.py:  558]:	worker_index: 6, step: 227, cost: 9.658625, mlm loss: 9.658625, speed: 1.106604 steps/s, speed: 8.852833 samples/s, speed: 4532.650419 tokens/s, learning rate: 2.260e-06, loss_scalings: 26214.400391, pp_loss: 9.556419
[INFO] 2021-07-12 18:28:54,747 [run_pretraining.py:  512]:	********exe.run_227******* 
[INFO] 2021-07-12 18:28:55,653 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:55,653 [run_pretraining.py:  534]:	loss/total_loss, 9.295886039733887, 228
[INFO] 2021-07-12 18:28:55,653 [run_pretraining.py:  535]:	loss/mlm_loss, 9.295886039733887, 228
[INFO] 2021-07-12 18:28:55,653 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2700000954500865e-06, 228
[INFO] 2021-07-12 18:28:55,654 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 228
[INFO] 2021-07-12 18:28:55,654 [run_pretraining.py:  558]:	worker_index: 6, step: 228, cost: 9.295886, mlm loss: 9.295886, speed: 1.103557 steps/s, speed: 8.828457 samples/s, speed: 4520.170080 tokens/s, learning rate: 2.270e-06, loss_scalings: 26214.400391, pp_loss: 9.565366
[INFO] 2021-07-12 18:28:55,654 [run_pretraining.py:  512]:	********exe.run_228******* 
[INFO] 2021-07-12 18:28:56,559 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:56,560 [run_pretraining.py:  534]:	loss/total_loss, 9.428293228149414, 229
[INFO] 2021-07-12 18:28:56,560 [run_pretraining.py:  535]:	loss/mlm_loss, 9.428293228149414, 229
[INFO] 2021-07-12 18:28:56,560 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.27999998969608e-06, 229
[INFO] 2021-07-12 18:28:56,560 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 229
[INFO] 2021-07-12 18:28:56,560 [run_pretraining.py:  558]:	worker_index: 6, step: 229, cost: 9.428293, mlm loss: 9.428293, speed: 1.103834 steps/s, speed: 8.830669 samples/s, speed: 4521.302572 tokens/s, learning rate: 2.280e-06, loss_scalings: 26214.400391, pp_loss: 9.490808
[INFO] 2021-07-12 18:28:56,560 [run_pretraining.py:  512]:	********exe.run_229******* 
[INFO] 2021-07-12 18:28:57,464 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:57,465 [run_pretraining.py:  534]:	loss/total_loss, 9.625736236572266, 230
[INFO] 2021-07-12 18:28:57,465 [run_pretraining.py:  535]:	loss/mlm_loss, 9.625736236572266, 230
[INFO] 2021-07-12 18:28:57,465 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.289999883942073e-06, 230
[INFO] 2021-07-12 18:28:57,465 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 230
[INFO] 2021-07-12 18:28:57,465 [run_pretraining.py:  558]:	worker_index: 6, step: 230, cost: 9.625736, mlm loss: 9.625736, speed: 1.105793 steps/s, speed: 8.846342 samples/s, speed: 4529.327138 tokens/s, learning rate: 2.290e-06, loss_scalings: 26214.400391, pp_loss: 9.628932
[INFO] 2021-07-12 18:28:57,466 [run_pretraining.py:  512]:	********exe.run_230******* 
[INFO] 2021-07-12 18:28:58,376 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:58,377 [run_pretraining.py:  534]:	loss/total_loss, 9.692615509033203, 231
[INFO] 2021-07-12 18:28:58,377 [run_pretraining.py:  535]:	loss/mlm_loss, 9.692615509033203, 231
[INFO] 2021-07-12 18:28:58,377 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.300000005561742e-06, 231
[INFO] 2021-07-12 18:28:58,377 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 231
[INFO] 2021-07-12 18:28:58,377 [run_pretraining.py:  558]:	worker_index: 6, step: 231, cost: 9.692616, mlm loss: 9.692616, speed: 1.097675 steps/s, speed: 8.781398 samples/s, speed: 4496.075635 tokens/s, learning rate: 2.300e-06, loss_scalings: 26214.400391, pp_loss: 9.476779
[INFO] 2021-07-12 18:28:58,377 [run_pretraining.py:  512]:	********exe.run_231******* 
[INFO] 2021-07-12 18:28:59,286 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:59,286 [run_pretraining.py:  534]:	loss/total_loss, 9.551237106323242, 232
[INFO] 2021-07-12 18:28:59,287 [run_pretraining.py:  535]:	loss/mlm_loss, 9.551237106323242, 232
[INFO] 2021-07-12 18:28:59,287 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3099998998077353e-06, 232
[INFO] 2021-07-12 18:28:59,287 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 232
[INFO] 2021-07-12 18:28:59,287 [run_pretraining.py:  558]:	worker_index: 6, step: 232, cost: 9.551237, mlm loss: 9.551237, speed: 1.100152 steps/s, speed: 8.801216 samples/s, speed: 4506.222381 tokens/s, learning rate: 2.310e-06, loss_scalings: 26214.400391, pp_loss: 9.616584
[INFO] 2021-07-12 18:28:59,287 [run_pretraining.py:  512]:	********exe.run_232******* 
[INFO] 2021-07-12 18:29:00,201 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:00,202 [run_pretraining.py:  534]:	loss/total_loss, 9.660165786743164, 233
[INFO] 2021-07-12 18:29:00,202 [run_pretraining.py:  535]:	loss/mlm_loss, 9.660165786743164, 233
[INFO] 2021-07-12 18:29:00,202 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.320000021427404e-06, 233
[INFO] 2021-07-12 18:29:00,202 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 233
[INFO] 2021-07-12 18:29:00,202 [run_pretraining.py:  558]:	worker_index: 6, step: 233, cost: 9.660166, mlm loss: 9.660166, speed: 1.093201 steps/s, speed: 8.745608 samples/s, speed: 4477.751345 tokens/s, learning rate: 2.320e-06, loss_scalings: 26214.400391, pp_loss: 9.515451
[INFO] 2021-07-12 18:29:00,202 [run_pretraining.py:  512]:	********exe.run_233******* 
[INFO] 2021-07-12 18:29:01,113 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:01,113 [run_pretraining.py:  534]:	loss/total_loss, 9.623699188232422, 234
[INFO] 2021-07-12 18:29:01,114 [run_pretraining.py:  535]:	loss/mlm_loss, 9.623699188232422, 234
[INFO] 2021-07-12 18:29:01,114 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3299999156733975e-06, 234
[INFO] 2021-07-12 18:29:01,114 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 234
[INFO] 2021-07-12 18:29:01,114 [run_pretraining.py:  558]:	worker_index: 6, step: 234, cost: 9.623699, mlm loss: 9.623699, speed: 1.097915 steps/s, speed: 8.783322 samples/s, speed: 4497.060707 tokens/s, learning rate: 2.330e-06, loss_scalings: 26214.400391, pp_loss: 9.551168
[INFO] 2021-07-12 18:29:01,114 [run_pretraining.py:  512]:	********exe.run_234******* 
[INFO] 2021-07-12 18:29:02,014 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:02,015 [run_pretraining.py:  534]:	loss/total_loss, 9.60256576538086, 235
[INFO] 2021-07-12 18:29:02,015 [run_pretraining.py:  535]:	loss/mlm_loss, 9.60256576538086, 235
[INFO] 2021-07-12 18:29:02,015 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.339999809919391e-06, 235
[INFO] 2021-07-12 18:29:02,015 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 235
[INFO] 2021-07-12 18:29:02,016 [run_pretraining.py:  558]:	worker_index: 6, step: 235, cost: 9.602566, mlm loss: 9.602566, speed: 1.109996 steps/s, speed: 8.879965 samples/s, speed: 4546.542255 tokens/s, learning rate: 2.340e-06, loss_scalings: 26214.400391, pp_loss: 9.553117
[INFO] 2021-07-12 18:29:02,016 [run_pretraining.py:  512]:	********exe.run_235******* 
[INFO] 2021-07-12 18:29:02,930 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:02,930 [run_pretraining.py:  534]:	loss/total_loss, 9.620002746582031, 236
[INFO] 2021-07-12 18:29:02,930 [run_pretraining.py:  535]:	loss/mlm_loss, 9.620002746582031, 236
[INFO] 2021-07-12 18:29:02,930 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3499999315390596e-06, 236
[INFO] 2021-07-12 18:29:02,931 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 236
[INFO] 2021-07-12 18:29:02,931 [run_pretraining.py:  558]:	worker_index: 6, step: 236, cost: 9.620003, mlm loss: 9.620003, speed: 1.093613 steps/s, speed: 8.748905 samples/s, speed: 4479.439577 tokens/s, learning rate: 2.350e-06, loss_scalings: 26214.400391, pp_loss: 8.554415
[INFO] 2021-07-12 18:29:02,931 [run_pretraining.py:  512]:	********exe.run_236******* 
[INFO] 2021-07-12 18:29:03,850 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:03,851 [run_pretraining.py:  534]:	loss/total_loss, 9.5321044921875, 237
[INFO] 2021-07-12 18:29:03,851 [run_pretraining.py:  535]:	loss/mlm_loss, 9.5321044921875, 237
[INFO] 2021-07-12 18:29:03,851 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3600000531587284e-06, 237
[INFO] 2021-07-12 18:29:03,851 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 237
[INFO] 2021-07-12 18:29:03,851 [run_pretraining.py:  558]:	worker_index: 6, step: 237, cost: 9.532104, mlm loss: 9.532104, speed: 1.086920 steps/s, speed: 8.695359 samples/s, speed: 4452.023557 tokens/s, learning rate: 2.360e-06, loss_scalings: 26214.400391, pp_loss: 9.588067
[INFO] 2021-07-12 18:29:03,851 [run_pretraining.py:  512]:	********exe.run_237******* 
[INFO] 2021-07-12 18:29:04,763 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:04,763 [run_pretraining.py:  534]:	loss/total_loss, 8.433747291564941, 238
[INFO] 2021-07-12 18:29:04,764 [run_pretraining.py:  535]:	loss/mlm_loss, 8.433747291564941, 238
[INFO] 2021-07-12 18:29:04,764 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3699999474047218e-06, 238
[INFO] 2021-07-12 18:29:04,764 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 238
[INFO] 2021-07-12 18:29:04,764 [run_pretraining.py:  558]:	worker_index: 6, step: 238, cost: 8.433747, mlm loss: 8.433747, speed: 1.096882 steps/s, speed: 8.775053 samples/s, speed: 4492.826900 tokens/s, learning rate: 2.370e-06, loss_scalings: 26214.400391, pp_loss: 9.231690
[INFO] 2021-07-12 18:29:04,764 [run_pretraining.py:  512]:	********exe.run_238******* 
[INFO] 2021-07-12 18:29:27,927 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:27,928 [run_pretraining.py:  534]:	loss/total_loss, 9.848373413085938, 239
[INFO] 2021-07-12 18:29:27,928 [run_pretraining.py:  535]:	loss/mlm_loss, 9.848373413085938, 239
[INFO] 2021-07-12 18:29:27,928 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3800000690243905e-06, 239
[INFO] 2021-07-12 18:29:27,928 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 239
[INFO] 2021-07-12 18:29:27,928 [run_pretraining.py:  558]:	worker_index: 6, step: 239, cost: 9.848373, mlm loss: 9.848373, speed: 0.043171 steps/s, speed: 0.345368 samples/s, speed: 176.828581 tokens/s, learning rate: 2.380e-06, loss_scalings: 26214.400391, pp_loss: 9.488537
[INFO] 2021-07-12 18:29:27,928 [run_pretraining.py:  512]:	********exe.run_239******* 
[INFO] 2021-07-12 18:29:28,816 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:28,817 [run_pretraining.py:  534]:	loss/total_loss, 9.331432342529297, 240
[INFO] 2021-07-12 18:29:28,817 [run_pretraining.py:  535]:	loss/mlm_loss, 9.331432342529297, 240
[INFO] 2021-07-12 18:29:28,817 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.389999963270384e-06, 240
[INFO] 2021-07-12 18:29:28,817 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 240
[INFO] 2021-07-12 18:29:28,817 [run_pretraining.py:  558]:	worker_index: 6, step: 240, cost: 9.331432, mlm loss: 9.331432, speed: 1.125985 steps/s, speed: 9.007882 samples/s, speed: 4612.035513 tokens/s, learning rate: 2.390e-06, loss_scalings: 26214.400391, pp_loss: 9.304369
[INFO] 2021-07-12 18:29:28,817 [run_pretraining.py:  512]:	********exe.run_240******* 
[INFO] 2021-07-12 18:29:29,729 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:29,730 [run_pretraining.py:  534]:	loss/total_loss, 9.028891563415527, 241
[INFO] 2021-07-12 18:29:29,730 [run_pretraining.py:  535]:	loss/mlm_loss, 9.028891563415527, 241
[INFO] 2021-07-12 18:29:29,730 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3999998575163772e-06, 241
[INFO] 2021-07-12 18:29:29,731 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 241
[INFO] 2021-07-12 18:29:29,731 [run_pretraining.py:  558]:	worker_index: 6, step: 241, cost: 9.028892, mlm loss: 9.028892, speed: 1.096211 steps/s, speed: 8.769688 samples/s, speed: 4490.080371 tokens/s, learning rate: 2.400e-06, loss_scalings: 26214.400391, pp_loss: 9.363094
[INFO] 2021-07-12 18:29:29,731 [run_pretraining.py:  512]:	********exe.run_241******* 
[INFO] 2021-07-12 18:29:30,626 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:30,627 [run_pretraining.py:  534]:	loss/total_loss, 9.330192565917969, 242
[INFO] 2021-07-12 18:29:30,627 [run_pretraining.py:  535]:	loss/mlm_loss, 9.330192565917969, 242
[INFO] 2021-07-12 18:29:30,627 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.409999979136046e-06, 242
[INFO] 2021-07-12 18:29:30,627 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 242
[INFO] 2021-07-12 18:29:30,627 [run_pretraining.py:  558]:	worker_index: 6, step: 242, cost: 9.330193, mlm loss: 9.330193, speed: 1.116735 steps/s, speed: 8.933881 samples/s, speed: 4574.146923 tokens/s, learning rate: 2.410e-06, loss_scalings: 26214.400391, pp_loss: 9.562070
[INFO] 2021-07-12 18:29:30,627 [run_pretraining.py:  512]:	********exe.run_242******* 
[INFO] 2021-07-12 18:29:31,534 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:31,534 [run_pretraining.py:  534]:	loss/total_loss, 9.14488410949707, 243
[INFO] 2021-07-12 18:29:31,534 [run_pretraining.py:  535]:	loss/mlm_loss, 9.14488410949707, 243
[INFO] 2021-07-12 18:29:31,535 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4199998733820394e-06, 243
[INFO] 2021-07-12 18:29:31,535 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 243
[INFO] 2021-07-12 18:29:31,535 [run_pretraining.py:  558]:	worker_index: 6, step: 243, cost: 9.144884, mlm loss: 9.144884, speed: 1.102844 steps/s, speed: 8.822751 samples/s, speed: 4517.248681 tokens/s, learning rate: 2.420e-06, loss_scalings: 26214.400391, pp_loss: 9.393290
[INFO] 2021-07-12 18:29:31,535 [run_pretraining.py:  512]:	********exe.run_243******* 
[INFO] 2021-07-12 18:29:32,442 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:32,443 [run_pretraining.py:  534]:	loss/total_loss, 9.94976806640625, 244
[INFO] 2021-07-12 18:29:32,443 [run_pretraining.py:  535]:	loss/mlm_loss, 9.94976806640625, 244
[INFO] 2021-07-12 18:29:32,443 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.429999995001708e-06, 244
[INFO] 2021-07-12 18:29:32,443 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 244
[INFO] 2021-07-12 18:29:32,444 [run_pretraining.py:  558]:	worker_index: 6, step: 244, cost: 9.949768, mlm loss: 9.949768, speed: 1.101285 steps/s, speed: 8.810281 samples/s, speed: 4510.864014 tokens/s, learning rate: 2.430e-06, loss_scalings: 26214.400391, pp_loss: 9.535592
[INFO] 2021-07-12 18:29:32,444 [run_pretraining.py:  512]:	********exe.run_244******* 
[INFO] 2021-07-12 18:29:33,346 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:33,346 [run_pretraining.py:  534]:	loss/total_loss, 9.493017196655273, 245
[INFO] 2021-07-12 18:29:33,347 [run_pretraining.py:  535]:	loss/mlm_loss, 9.493017196655273, 245
[INFO] 2021-07-12 18:29:33,347 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4399998892477015e-06, 245
[INFO] 2021-07-12 18:29:33,347 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 245
[INFO] 2021-07-12 18:29:33,347 [run_pretraining.py:  558]:	worker_index: 6, step: 245, cost: 9.493017, mlm loss: 9.493017, speed: 1.107999 steps/s, speed: 8.863990 samples/s, speed: 4538.363114 tokens/s, learning rate: 2.440e-06, loss_scalings: 26214.400391, pp_loss: 9.066758
[INFO] 2021-07-12 18:29:33,347 [run_pretraining.py:  512]:	********exe.run_245******* 
[INFO] 2021-07-12 18:29:34,246 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:34,247 [run_pretraining.py:  534]:	loss/total_loss, 9.448582649230957, 246
[INFO] 2021-07-12 18:29:34,247 [run_pretraining.py:  535]:	loss/mlm_loss, 9.448582649230957, 246
[INFO] 2021-07-12 18:29:34,247 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.449999783493695e-06, 246
[INFO] 2021-07-12 18:29:34,247 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 246
[INFO] 2021-07-12 18:29:34,247 [run_pretraining.py:  558]:	worker_index: 6, step: 246, cost: 9.448583, mlm loss: 9.448583, speed: 1.111879 steps/s, speed: 8.895036 samples/s, speed: 4554.258299 tokens/s, learning rate: 2.450e-06, loss_scalings: 26214.400391, pp_loss: 9.414516
[INFO] 2021-07-12 18:29:34,247 [run_pretraining.py:  512]:	********exe.run_246******* 
[INFO] 2021-07-12 18:29:35,158 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:35,158 [run_pretraining.py:  534]:	loss/total_loss, 9.577896118164062, 247
[INFO] 2021-07-12 18:29:35,159 [run_pretraining.py:  535]:	loss/mlm_loss, 9.577896118164062, 247
[INFO] 2021-07-12 18:29:35,159 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4599999051133636e-06, 247
[INFO] 2021-07-12 18:29:35,159 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 247
[INFO] 2021-07-12 18:29:35,159 [run_pretraining.py:  558]:	worker_index: 6, step: 247, cost: 9.577896, mlm loss: 9.577896, speed: 1.097409 steps/s, speed: 8.779275 samples/s, speed: 4494.988673 tokens/s, learning rate: 2.460e-06, loss_scalings: 26214.400391, pp_loss: 9.602447
[INFO] 2021-07-12 18:29:35,159 [run_pretraining.py:  512]:	********exe.run_247******* 
[INFO] 2021-07-12 18:29:36,059 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:36,059 [run_pretraining.py:  534]:	loss/total_loss, 9.677258491516113, 248
[INFO] 2021-07-12 18:29:36,059 [run_pretraining.py:  535]:	loss/mlm_loss, 9.677258491516113, 248
[INFO] 2021-07-12 18:29:36,060 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4700000267330324e-06, 248
[INFO] 2021-07-12 18:29:36,060 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 248
[INFO] 2021-07-12 18:29:36,060 [run_pretraining.py:  558]:	worker_index: 6, step: 248, cost: 9.677258, mlm loss: 9.677258, speed: 1.110953 steps/s, speed: 8.887626 samples/s, speed: 4550.464502 tokens/s, learning rate: 2.470e-06, loss_scalings: 26214.400391, pp_loss: 9.476829
[INFO] 2021-07-12 18:29:36,060 [run_pretraining.py:  512]:	********exe.run_248******* 
[INFO] 2021-07-12 18:29:36,967 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:36,968 [run_pretraining.py:  534]:	loss/total_loss, 9.684621810913086, 249
[INFO] 2021-07-12 18:29:36,968 [run_pretraining.py:  535]:	loss/mlm_loss, 9.684621810913086, 249
[INFO] 2021-07-12 18:29:36,968 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4799999209790258e-06, 249
[INFO] 2021-07-12 18:29:36,968 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 249
[INFO] 2021-07-12 18:29:36,968 [run_pretraining.py:  558]:	worker_index: 6, step: 249, cost: 9.684622, mlm loss: 9.684622, speed: 1.101968 steps/s, speed: 8.815742 samples/s, speed: 4513.659753 tokens/s, learning rate: 2.480e-06, loss_scalings: 26214.400391, pp_loss: 9.688009
[INFO] 2021-07-12 18:29:36,968 [run_pretraining.py:  512]:	********exe.run_249******* 
[INFO] 2021-07-12 18:30:02,770 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:02,771 [run_pretraining.py:  534]:	loss/total_loss, 9.370304107666016, 250
[INFO] 2021-07-12 18:30:02,771 [run_pretraining.py:  535]:	loss/mlm_loss, 9.370304107666016, 250
[INFO] 2021-07-12 18:30:02,771 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4900000425986946e-06, 250
[INFO] 2021-07-12 18:30:02,772 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 250
[INFO] 2021-07-12 18:30:02,772 [run_pretraining.py:  558]:	worker_index: 6, step: 250, cost: 9.370304, mlm loss: 9.370304, speed: 0.038755 steps/s, speed: 0.310044 samples/s, speed: 158.742413 tokens/s, learning rate: 2.490e-06, loss_scalings: 26214.400391, pp_loss: 9.390217
[INFO] 2021-07-12 18:30:02,772 [run_pretraining.py:  512]:	********exe.run_250******* 
[INFO] 2021-07-12 18:30:03,684 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:03,684 [run_pretraining.py:  534]:	loss/total_loss, 9.322280883789062, 251
[INFO] 2021-07-12 18:30:03,684 [run_pretraining.py:  535]:	loss/mlm_loss, 9.322280883789062, 251
[INFO] 2021-07-12 18:30:03,685 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.499999936844688e-06, 251
[INFO] 2021-07-12 18:30:03,685 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 251
[INFO] 2021-07-12 18:30:03,685 [run_pretraining.py:  558]:	worker_index: 6, step: 251, cost: 9.322281, mlm loss: 9.322281, speed: 1.095949 steps/s, speed: 8.767594 samples/s, speed: 4489.008035 tokens/s, learning rate: 2.500e-06, loss_scalings: 26214.400391, pp_loss: 9.551477
[INFO] 2021-07-12 18:30:03,685 [run_pretraining.py:  512]:	********exe.run_251******* 
[INFO] 2021-07-12 18:30:04,593 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:04,594 [run_pretraining.py:  534]:	loss/total_loss, 9.3742036819458, 252
[INFO] 2021-07-12 18:30:04,594 [run_pretraining.py:  535]:	loss/mlm_loss, 9.3742036819458, 252
[INFO] 2021-07-12 18:30:04,594 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5100000584643567e-06, 252
[INFO] 2021-07-12 18:30:04,594 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 252
[INFO] 2021-07-12 18:30:04,594 [run_pretraining.py:  558]:	worker_index: 6, step: 252, cost: 9.374204, mlm loss: 9.374204, speed: 1.100361 steps/s, speed: 8.802890 samples/s, speed: 4507.079470 tokens/s, learning rate: 2.510e-06, loss_scalings: 26214.400391, pp_loss: 9.589006
[INFO] 2021-07-12 18:30:04,594 [run_pretraining.py:  512]:	********exe.run_252******* 
[INFO] 2021-07-12 18:30:05,517 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:05,517 [run_pretraining.py:  534]:	loss/total_loss, 9.701855659484863, 253
[INFO] 2021-07-12 18:30:05,517 [run_pretraining.py:  535]:	loss/mlm_loss, 9.701855659484863, 253
[INFO] 2021-07-12 18:30:05,517 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.51999995271035e-06, 253
[INFO] 2021-07-12 18:30:05,518 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 253
[INFO] 2021-07-12 18:30:05,518 [run_pretraining.py:  558]:	worker_index: 6, step: 253, cost: 9.701856, mlm loss: 9.701856, speed: 1.083820 steps/s, speed: 8.670559 samples/s, speed: 4439.326422 tokens/s, learning rate: 2.520e-06, loss_scalings: 26214.400391, pp_loss: 9.577085
[INFO] 2021-07-12 18:30:05,518 [run_pretraining.py:  512]:	********exe.run_253******* 
[INFO] 2021-07-12 18:30:06,430 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:06,431 [run_pretraining.py:  534]:	loss/total_loss, 9.870267868041992, 254
[INFO] 2021-07-12 18:30:06,431 [run_pretraining.py:  535]:	loss/mlm_loss, 9.870267868041992, 254
[INFO] 2021-07-12 18:30:06,431 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5299998469563434e-06, 254
[INFO] 2021-07-12 18:30:06,431 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 254
[INFO] 2021-07-12 18:30:06,431 [run_pretraining.py:  558]:	worker_index: 6, step: 254, cost: 9.870268, mlm loss: 9.870268, speed: 1.095430 steps/s, speed: 8.763442 samples/s, speed: 4486.882477 tokens/s, learning rate: 2.530e-06, loss_scalings: 26214.400391, pp_loss: 9.631794
[INFO] 2021-07-12 18:30:06,431 [run_pretraining.py:  512]:	********exe.run_254******* 
[INFO] 2021-07-12 18:30:07,398 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:07,398 [run_pretraining.py:  534]:	loss/total_loss, 9.61741828918457, 255
[INFO] 2021-07-12 18:30:07,399 [run_pretraining.py:  535]:	loss/mlm_loss, 9.61741828918457, 255
[INFO] 2021-07-12 18:30:07,399 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.539999968576012e-06, 255
[INFO] 2021-07-12 18:30:07,399 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 255
[INFO] 2021-07-12 18:30:07,399 [run_pretraining.py:  558]:	worker_index: 6, step: 255, cost: 9.617418, mlm loss: 9.617418, speed: 1.034310 steps/s, speed: 8.274482 samples/s, speed: 4236.534889 tokens/s, learning rate: 2.540e-06, loss_scalings: 26214.400391, pp_loss: 9.519679
[INFO] 2021-07-12 18:30:07,399 [run_pretraining.py:  512]:	********exe.run_255******* 
[INFO] 2021-07-12 18:30:33,998 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:33,998 [run_pretraining.py:  534]:	loss/total_loss, 9.555656433105469, 256
[INFO] 2021-07-12 18:30:33,999 [run_pretraining.py:  535]:	loss/mlm_loss, 9.555656433105469, 256
[INFO] 2021-07-12 18:30:33,999 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5499998628220055e-06, 256
[INFO] 2021-07-12 18:30:33,999 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 256
[INFO] 2021-07-12 18:30:33,999 [run_pretraining.py:  558]:	worker_index: 6, step: 256, cost: 9.555656, mlm loss: 9.555656, speed: 0.037595 steps/s, speed: 0.300761 samples/s, speed: 153.989574 tokens/s, learning rate: 2.550e-06, loss_scalings: 26214.400391, pp_loss: 9.691048
[INFO] 2021-07-12 18:30:33,999 [run_pretraining.py:  512]:	********exe.run_256******* 
[INFO] 2021-07-12 18:30:34,943 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:34,944 [run_pretraining.py:  534]:	loss/total_loss, 9.350763320922852, 257
[INFO] 2021-07-12 18:30:34,944 [run_pretraining.py:  535]:	loss/mlm_loss, 9.350763320922852, 257
[INFO] 2021-07-12 18:30:34,944 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.559999757067999e-06, 257
[INFO] 2021-07-12 18:30:34,944 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 257
[INFO] 2021-07-12 18:30:34,944 [run_pretraining.py:  558]:	worker_index: 6, step: 257, cost: 9.350763, mlm loss: 9.350763, speed: 1.058811 steps/s, speed: 8.470490 samples/s, speed: 4336.890936 tokens/s, learning rate: 2.560e-06, loss_scalings: 26214.400391, pp_loss: 9.475578
[INFO] 2021-07-12 18:30:34,944 [run_pretraining.py:  512]:	********exe.run_257******* 
[INFO] 2021-07-12 18:30:35,860 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:35,860 [run_pretraining.py:  534]:	loss/total_loss, 9.607439994812012, 258
[INFO] 2021-07-12 18:30:35,860 [run_pretraining.py:  535]:	loss/mlm_loss, 9.607439994812012, 258
[INFO] 2021-07-12 18:30:35,861 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5699998786876677e-06, 258
[INFO] 2021-07-12 18:30:35,861 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 258
[INFO] 2021-07-12 18:30:35,861 [run_pretraining.py:  558]:	worker_index: 6, step: 258, cost: 9.607440, mlm loss: 9.607440, speed: 1.091738 steps/s, speed: 8.733903 samples/s, speed: 4471.758259 tokens/s, learning rate: 2.570e-06, loss_scalings: 26214.400391, pp_loss: 8.340823
[INFO] 2021-07-12 18:30:35,861 [run_pretraining.py:  512]:	********exe.run_258******* 
[INFO] 2021-07-12 18:30:36,776 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:36,777 [run_pretraining.py:  534]:	loss/total_loss, 9.50404167175293, 259
[INFO] 2021-07-12 18:30:36,777 [run_pretraining.py:  535]:	loss/mlm_loss, 9.50404167175293, 259
[INFO] 2021-07-12 18:30:36,777 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5800000003073364e-06, 259
[INFO] 2021-07-12 18:30:36,777 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 259
[INFO] 2021-07-12 18:30:36,777 [run_pretraining.py:  558]:	worker_index: 6, step: 259, cost: 9.504042, mlm loss: 9.504042, speed: 1.091818 steps/s, speed: 8.734546 samples/s, speed: 4472.087683 tokens/s, learning rate: 2.580e-06, loss_scalings: 26214.400391, pp_loss: 9.532578
[INFO] 2021-07-12 18:30:36,777 [run_pretraining.py:  512]:	********exe.run_259******* 
[INFO] 2021-07-12 18:30:37,692 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:37,693 [run_pretraining.py:  534]:	loss/total_loss, 9.23876667022705, 260
[INFO] 2021-07-12 18:30:37,693 [run_pretraining.py:  535]:	loss/mlm_loss, 9.23876667022705, 260
[INFO] 2021-07-12 18:30:37,693 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.58999989455333e-06, 260
[INFO] 2021-07-12 18:30:37,693 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 260
[INFO] 2021-07-12 18:30:37,693 [run_pretraining.py:  558]:	worker_index: 6, step: 260, cost: 9.238767, mlm loss: 9.238767, speed: 1.092484 steps/s, speed: 8.739872 samples/s, speed: 4474.814568 tokens/s, learning rate: 2.590e-06, loss_scalings: 26214.400391, pp_loss: 9.381107
[INFO] 2021-07-12 18:30:37,693 [run_pretraining.py:  512]:	********exe.run_260******* 
[INFO] 2021-07-12 18:30:38,603 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:38,603 [run_pretraining.py:  534]:	loss/total_loss, 9.369858741760254, 261
[INFO] 2021-07-12 18:30:38,603 [run_pretraining.py:  535]:	loss/mlm_loss, 9.369858741760254, 261
[INFO] 2021-07-12 18:30:38,604 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6000000161729986e-06, 261
[INFO] 2021-07-12 18:30:38,604 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 261
[INFO] 2021-07-12 18:30:38,604 [run_pretraining.py:  558]:	worker_index: 6, step: 261, cost: 9.369859, mlm loss: 9.369859, speed: 1.099424 steps/s, speed: 8.795393 samples/s, speed: 4503.241070 tokens/s, learning rate: 2.600e-06, loss_scalings: 26214.400391, pp_loss: 9.298832
[INFO] 2021-07-12 18:30:38,604 [run_pretraining.py:  512]:	********exe.run_261******* 
[INFO] 2021-07-12 18:30:39,509 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:39,509 [run_pretraining.py:  534]:	loss/total_loss, 9.201896667480469, 262
[INFO] 2021-07-12 18:30:39,509 [run_pretraining.py:  535]:	loss/mlm_loss, 9.201896667480469, 262
[INFO] 2021-07-12 18:30:39,510 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.609999910418992e-06, 262
[INFO] 2021-07-12 18:30:39,510 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 262
[INFO] 2021-07-12 18:30:39,510 [run_pretraining.py:  558]:	worker_index: 6, step: 262, cost: 9.201897, mlm loss: 9.201897, speed: 1.104619 steps/s, speed: 8.836951 samples/s, speed: 4524.518755 tokens/s, learning rate: 2.610e-06, loss_scalings: 26214.400391, pp_loss: 9.452095
[INFO] 2021-07-12 18:30:39,510 [run_pretraining.py:  512]:	********exe.run_262******* 
[INFO] 2021-07-12 18:30:40,421 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:40,422 [run_pretraining.py:  534]:	loss/total_loss, 9.556671142578125, 263
[INFO] 2021-07-12 18:30:40,422 [run_pretraining.py:  535]:	loss/mlm_loss, 9.556671142578125, 263
[INFO] 2021-07-12 18:30:40,422 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6200000320386607e-06, 263
[INFO] 2021-07-12 18:30:40,422 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 263
[INFO] 2021-07-12 18:30:40,422 [run_pretraining.py:  558]:	worker_index: 6, step: 263, cost: 9.556671, mlm loss: 9.556671, speed: 1.097013 steps/s, speed: 8.776104 samples/s, speed: 4493.365092 tokens/s, learning rate: 2.620e-06, loss_scalings: 26214.400391, pp_loss: 9.456570
[INFO] 2021-07-12 18:30:40,422 [run_pretraining.py:  512]:	********exe.run_263******* 
[INFO] 2021-07-12 18:30:41,330 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:41,331 [run_pretraining.py:  534]:	loss/total_loss, 7.828209400177002, 264
[INFO] 2021-07-12 18:30:41,331 [run_pretraining.py:  535]:	loss/mlm_loss, 7.828209400177002, 264
[INFO] 2021-07-12 18:30:41,331 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.629999926284654e-06, 264
[INFO] 2021-07-12 18:30:41,331 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 264
[INFO] 2021-07-12 18:30:41,331 [run_pretraining.py:  558]:	worker_index: 6, step: 264, cost: 7.828209, mlm loss: 7.828209, speed: 1.101144 steps/s, speed: 8.809150 samples/s, speed: 4510.284915 tokens/s, learning rate: 2.630e-06, loss_scalings: 26214.400391, pp_loss: 9.112136
[INFO] 2021-07-12 18:30:41,331 [run_pretraining.py:  512]:	********exe.run_264******* 
[INFO] 2021-07-12 18:30:42,240 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:42,241 [run_pretraining.py:  534]:	loss/total_loss, 9.106056213378906, 265
[INFO] 2021-07-12 18:30:42,241 [run_pretraining.py:  535]:	loss/mlm_loss, 9.106056213378906, 265
[INFO] 2021-07-12 18:30:42,241 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6399998205306474e-06, 265
[INFO] 2021-07-12 18:30:42,241 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 265
[INFO] 2021-07-12 18:30:42,241 [run_pretraining.py:  558]:	worker_index: 6, step: 265, cost: 9.106056, mlm loss: 9.106056, speed: 1.099712 steps/s, speed: 8.797699 samples/s, speed: 4504.421783 tokens/s, learning rate: 2.640e-06, loss_scalings: 26214.400391, pp_loss: 9.304050
[INFO] 2021-07-12 18:30:42,241 [run_pretraining.py:  512]:	********exe.run_265******* 
[INFO] 2021-07-12 18:30:43,161 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:43,161 [run_pretraining.py:  534]:	loss/total_loss, 9.226967811584473, 266
[INFO] 2021-07-12 18:30:43,161 [run_pretraining.py:  535]:	loss/mlm_loss, 9.226967811584473, 266
[INFO] 2021-07-12 18:30:43,161 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.649999942150316e-06, 266
[INFO] 2021-07-12 18:30:43,162 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 266
[INFO] 2021-07-12 18:30:43,162 [run_pretraining.py:  558]:	worker_index: 6, step: 266, cost: 9.226968, mlm loss: 9.226968, speed: 1.087039 steps/s, speed: 8.696314 samples/s, speed: 4452.512782 tokens/s, learning rate: 2.650e-06, loss_scalings: 26214.400391, pp_loss: 9.524787
[INFO] 2021-07-12 18:30:43,162 [run_pretraining.py:  512]:	********exe.run_266******* 
[INFO] 2021-07-12 18:30:44,230 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:44,230 [run_pretraining.py:  534]:	loss/total_loss, 9.238113403320312, 267
[INFO] 2021-07-12 18:30:44,230 [run_pretraining.py:  535]:	loss/mlm_loss, 9.238113403320312, 267
[INFO] 2021-07-12 18:30:44,230 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6599998363963095e-06, 267
[INFO] 2021-07-12 18:30:44,231 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 267
[INFO] 2021-07-12 18:30:44,231 [run_pretraining.py:  558]:	worker_index: 6, step: 267, cost: 9.238113, mlm loss: 9.238113, speed: 0.936078 steps/s, speed: 7.488620 samples/s, speed: 3834.173455 tokens/s, learning rate: 2.660e-06, loss_scalings: 26214.400391, pp_loss: 9.415479
[INFO] 2021-07-12 18:30:44,231 [run_pretraining.py:  512]:	********exe.run_267******* 
[INFO] 2021-07-12 18:30:45,281 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:45,282 [run_pretraining.py:  534]:	loss/total_loss, 9.57993221282959, 268
[INFO] 2021-07-12 18:30:45,282 [run_pretraining.py:  535]:	loss/mlm_loss, 9.57993221282959, 268
[INFO] 2021-07-12 18:30:45,282 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6699999580159783e-06, 268
[INFO] 2021-07-12 18:30:45,282 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 268
[INFO] 2021-07-12 18:30:45,282 [run_pretraining.py:  558]:	worker_index: 6, step: 268, cost: 9.579932, mlm loss: 9.579932, speed: 0.951779 steps/s, speed: 7.614233 samples/s, speed: 3898.487245 tokens/s, learning rate: 2.670e-06, loss_scalings: 26214.400391, pp_loss: 9.441287
[INFO] 2021-07-12 18:30:45,282 [run_pretraining.py:  512]:	********exe.run_268******* 
[INFO] 2021-07-12 18:30:46,338 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:46,338 [run_pretraining.py:  534]:	loss/total_loss, 9.452438354492188, 269
[INFO] 2021-07-12 18:30:46,338 [run_pretraining.py:  535]:	loss/mlm_loss, 9.452438354492188, 269
[INFO] 2021-07-12 18:30:46,338 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6799998522619717e-06, 269
[INFO] 2021-07-12 18:30:46,339 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 269
[INFO] 2021-07-12 18:30:46,339 [run_pretraining.py:  558]:	worker_index: 6, step: 269, cost: 9.452438, mlm loss: 9.452438, speed: 0.947128 steps/s, speed: 7.577027 samples/s, speed: 3879.437803 tokens/s, learning rate: 2.680e-06, loss_scalings: 26214.400391, pp_loss: 9.470916
[INFO] 2021-07-12 18:30:46,339 [run_pretraining.py:  512]:	********exe.run_269******* 
[INFO] 2021-07-12 18:30:47,395 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:47,396 [run_pretraining.py:  534]:	loss/total_loss, 9.007413864135742, 270
[INFO] 2021-07-12 18:30:47,396 [run_pretraining.py:  535]:	loss/mlm_loss, 9.007413864135742, 270
[INFO] 2021-07-12 18:30:47,396 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6899999738816405e-06, 270
[INFO] 2021-07-12 18:30:47,396 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 270
[INFO] 2021-07-12 18:30:47,396 [run_pretraining.py:  558]:	worker_index: 6, step: 270, cost: 9.007414, mlm loss: 9.007414, speed: 0.945999 steps/s, speed: 7.567988 samples/s, speed: 3874.810021 tokens/s, learning rate: 2.690e-06, loss_scalings: 26214.400391, pp_loss: 9.445286
[INFO] 2021-07-12 18:30:47,397 [run_pretraining.py:  512]:	********exe.run_270******* 
[INFO] 2021-07-12 18:30:48,457 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:48,457 [run_pretraining.py:  534]:	loss/total_loss, 9.789555549621582, 271
[INFO] 2021-07-12 18:30:48,457 [run_pretraining.py:  535]:	loss/mlm_loss, 9.789555549621582, 271
[INFO] 2021-07-12 18:30:48,457 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7000000955013093e-06, 271
[INFO] 2021-07-12 18:30:48,458 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 271
[INFO] 2021-07-12 18:30:48,458 [run_pretraining.py:  558]:	worker_index: 6, step: 271, cost: 9.789556, mlm loss: 9.789556, speed: 0.942969 steps/s, speed: 7.543750 samples/s, speed: 3862.399765 tokens/s, learning rate: 2.700e-06, loss_scalings: 26214.400391, pp_loss: 9.641122
[INFO] 2021-07-12 18:30:48,458 [run_pretraining.py:  512]:	********exe.run_271******* 
[INFO] 2021-07-12 18:30:49,528 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:49,529 [run_pretraining.py:  534]:	loss/total_loss, 9.486005783081055, 272
[INFO] 2021-07-12 18:30:49,529 [run_pretraining.py:  535]:	loss/mlm_loss, 9.486005783081055, 272
[INFO] 2021-07-12 18:30:49,529 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7099999897473026e-06, 272
[INFO] 2021-07-12 18:30:49,529 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 272
[INFO] 2021-07-12 18:30:49,529 [run_pretraining.py:  558]:	worker_index: 6, step: 272, cost: 9.486006, mlm loss: 9.486006, speed: 0.933738 steps/s, speed: 7.469907 samples/s, speed: 3824.592178 tokens/s, learning rate: 2.710e-06, loss_scalings: 26214.400391, pp_loss: 9.500280
[INFO] 2021-07-12 18:30:49,529 [run_pretraining.py:  512]:	********exe.run_272******* 
[INFO] 2021-07-12 18:30:50,587 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:50,587 [run_pretraining.py:  534]:	loss/total_loss, 9.582330703735352, 273
[INFO] 2021-07-12 18:30:50,587 [run_pretraining.py:  535]:	loss/mlm_loss, 9.582330703735352, 273
[INFO] 2021-07-12 18:30:50,587 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.719999883993296e-06, 273
[INFO] 2021-07-12 18:30:50,588 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 273
[INFO] 2021-07-12 18:30:50,588 [run_pretraining.py:  558]:	worker_index: 6, step: 273, cost: 9.582331, mlm loss: 9.582331, speed: 0.945595 steps/s, speed: 7.564757 samples/s, speed: 3873.155488 tokens/s, learning rate: 2.720e-06, loss_scalings: 26214.400391, pp_loss: 9.563732
[INFO] 2021-07-12 18:30:50,588 [run_pretraining.py:  512]:	********exe.run_273******* 
[INFO] 2021-07-12 18:30:51,639 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:51,640 [run_pretraining.py:  534]:	loss/total_loss, 5.593520164489746, 274
[INFO] 2021-07-12 18:30:51,640 [run_pretraining.py:  535]:	loss/mlm_loss, 5.593520164489746, 274
[INFO] 2021-07-12 18:30:51,640 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7300000056129647e-06, 274
[INFO] 2021-07-12 18:30:51,640 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 274
[INFO] 2021-07-12 18:30:51,640 [run_pretraining.py:  558]:	worker_index: 6, step: 274, cost: 5.593520, mlm loss: 5.593520, speed: 0.950780 steps/s, speed: 7.606236 samples/s, speed: 3894.392957 tokens/s, learning rate: 2.730e-06, loss_scalings: 26214.400391, pp_loss: 8.580843
[INFO] 2021-07-12 18:30:51,640 [run_pretraining.py:  512]:	********exe.run_274******* 
[INFO] 2021-07-12 18:30:52,700 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:52,701 [run_pretraining.py:  534]:	loss/total_loss, 9.528115272521973, 275
[INFO] 2021-07-12 18:30:52,701 [run_pretraining.py:  535]:	loss/mlm_loss, 9.528115272521973, 275
[INFO] 2021-07-12 18:30:52,701 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.739999899858958e-06, 275
[INFO] 2021-07-12 18:30:52,701 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 275
[INFO] 2021-07-12 18:30:52,701 [run_pretraining.py:  558]:	worker_index: 6, step: 275, cost: 9.528115, mlm loss: 9.528115, speed: 0.943309 steps/s, speed: 7.546471 samples/s, speed: 3863.793101 tokens/s, learning rate: 2.740e-06, loss_scalings: 26214.400391, pp_loss: 9.620591
[INFO] 2021-07-12 18:30:52,701 [run_pretraining.py:  512]:	********exe.run_275******* 
[INFO] 2021-07-12 18:30:53,835 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:53,835 [run_pretraining.py:  534]:	loss/total_loss, 9.210050582885742, 276
[INFO] 2021-07-12 18:30:53,835 [run_pretraining.py:  535]:	loss/mlm_loss, 9.210050582885742, 276
[INFO] 2021-07-12 18:30:53,835 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.750000021478627e-06, 276
[INFO] 2021-07-12 18:30:53,836 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 276
[INFO] 2021-07-12 18:30:53,836 [run_pretraining.py:  558]:	worker_index: 6, step: 276, cost: 9.210051, mlm loss: 9.210051, speed: 0.881873 steps/s, speed: 7.054988 samples/s, speed: 3612.153746 tokens/s, learning rate: 2.750e-06, loss_scalings: 26214.400391, pp_loss: 9.353653
[INFO] 2021-07-12 18:30:53,836 [run_pretraining.py:  512]:	********exe.run_276******* 
[INFO] 2021-07-12 18:30:54,931 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:54,932 [run_pretraining.py:  534]:	loss/total_loss, 9.460064888000488, 277
[INFO] 2021-07-12 18:30:54,932 [run_pretraining.py:  535]:	loss/mlm_loss, 9.460064888000488, 277
[INFO] 2021-07-12 18:30:54,932 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7599999157246202e-06, 277
[INFO] 2021-07-12 18:30:54,932 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 277
[INFO] 2021-07-12 18:30:54,932 [run_pretraining.py:  558]:	worker_index: 6, step: 277, cost: 9.460065, mlm loss: 9.460065, speed: 0.912760 steps/s, speed: 7.302077 samples/s, speed: 3738.663512 tokens/s, learning rate: 2.760e-06, loss_scalings: 26214.400391, pp_loss: 9.454580
[INFO] 2021-07-12 18:30:54,932 [run_pretraining.py:  512]:	********exe.run_277******* 
[INFO] 2021-07-12 18:30:56,003 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:56,003 [run_pretraining.py:  534]:	loss/total_loss, 9.249183654785156, 278
[INFO] 2021-07-12 18:30:56,004 [run_pretraining.py:  535]:	loss/mlm_loss, 9.249183654785156, 278
[INFO] 2021-07-12 18:30:56,004 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7699998099706136e-06, 278
[INFO] 2021-07-12 18:30:56,004 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 278
[INFO] 2021-07-12 18:30:56,004 [run_pretraining.py:  558]:	worker_index: 6, step: 278, cost: 9.249184, mlm loss: 9.249184, speed: 0.933558 steps/s, speed: 7.468462 samples/s, speed: 3823.852426 tokens/s, learning rate: 2.770e-06, loss_scalings: 26214.400391, pp_loss: 9.405760
[INFO] 2021-07-12 18:30:56,004 [run_pretraining.py:  512]:	********exe.run_278******* 
[INFO] 2021-07-12 18:30:57,086 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:57,087 [run_pretraining.py:  534]:	loss/total_loss, 9.267679214477539, 279
[INFO] 2021-07-12 18:30:57,087 [run_pretraining.py:  535]:	loss/mlm_loss, 9.267679214477539, 279
[INFO] 2021-07-12 18:30:57,087 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7799999315902824e-06, 279
[INFO] 2021-07-12 18:30:57,087 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 279
[INFO] 2021-07-12 18:30:57,087 [run_pretraining.py:  558]:	worker_index: 6, step: 279, cost: 9.267679, mlm loss: 9.267679, speed: 0.923721 steps/s, speed: 7.389767 samples/s, speed: 3783.560455 tokens/s, learning rate: 2.780e-06, loss_scalings: 26214.400391, pp_loss: 9.128566
[INFO] 2021-07-12 18:30:57,087 [run_pretraining.py:  512]:	********exe.run_279******* 
[INFO] 2021-07-12 18:30:58,178 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:58,179 [run_pretraining.py:  534]:	loss/total_loss, 9.31108283996582, 280
[INFO] 2021-07-12 18:30:58,179 [run_pretraining.py:  535]:	loss/mlm_loss, 9.31108283996582, 280
[INFO] 2021-07-12 18:30:58,179 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7899998258362757e-06, 280
[INFO] 2021-07-12 18:30:58,179 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 280
[INFO] 2021-07-12 18:30:58,179 [run_pretraining.py:  558]:	worker_index: 6, step: 280, cost: 9.311083, mlm loss: 9.311083, speed: 0.916532 steps/s, speed: 7.332257 samples/s, speed: 3754.115614 tokens/s, learning rate: 2.790e-06, loss_scalings: 26214.400391, pp_loss: 9.369160
[INFO] 2021-07-12 18:30:58,179 [run_pretraining.py:  512]:	********exe.run_280******* 
[INFO] 2021-07-12 18:30:59,267 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:59,267 [run_pretraining.py:  534]:	loss/total_loss, 9.352108001708984, 281
[INFO] 2021-07-12 18:30:59,267 [run_pretraining.py:  535]:	loss/mlm_loss, 9.352108001708984, 281
[INFO] 2021-07-12 18:30:59,267 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7999999474559445e-06, 281
[INFO] 2021-07-12 18:30:59,267 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 281
[INFO] 2021-07-12 18:30:59,268 [run_pretraining.py:  558]:	worker_index: 6, step: 281, cost: 9.352108, mlm loss: 9.352108, speed: 0.919306 steps/s, speed: 7.354446 samples/s, speed: 3765.476365 tokens/s, learning rate: 2.800e-06, loss_scalings: 26214.400391, pp_loss: 9.297256
[INFO] 2021-07-12 18:30:59,268 [run_pretraining.py:  512]:	********exe.run_281******* 
[INFO] 2021-07-12 18:31:00,352 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:00,352 [run_pretraining.py:  534]:	loss/total_loss, 9.230489730834961, 282
[INFO] 2021-07-12 18:31:00,352 [run_pretraining.py:  535]:	loss/mlm_loss, 9.230489730834961, 282
[INFO] 2021-07-12 18:31:00,352 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8100000690756133e-06, 282
[INFO] 2021-07-12 18:31:00,353 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 282
[INFO] 2021-07-12 18:31:00,353 [run_pretraining.py:  558]:	worker_index: 6, step: 282, cost: 9.230490, mlm loss: 9.230490, speed: 0.922193 steps/s, speed: 7.377543 samples/s, speed: 3777.302195 tokens/s, learning rate: 2.810e-06, loss_scalings: 26214.400391, pp_loss: 9.484295
[INFO] 2021-07-12 18:31:00,353 [run_pretraining.py:  512]:	********exe.run_282******* 
[INFO] 2021-07-12 18:31:01,441 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:01,442 [run_pretraining.py:  534]:	loss/total_loss, 9.303929328918457, 283
[INFO] 2021-07-12 18:31:01,442 [run_pretraining.py:  535]:	loss/mlm_loss, 9.303929328918457, 283
[INFO] 2021-07-12 18:31:01,442 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8199999633216066e-06, 283
[INFO] 2021-07-12 18:31:01,442 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 283
[INFO] 2021-07-12 18:31:01,442 [run_pretraining.py:  558]:	worker_index: 6, step: 283, cost: 9.303929, mlm loss: 9.303929, speed: 0.918324 steps/s, speed: 7.346593 samples/s, speed: 3761.455599 tokens/s, learning rate: 2.820e-06, loss_scalings: 26214.400391, pp_loss: 9.290132
[INFO] 2021-07-12 18:31:01,442 [run_pretraining.py:  512]:	********exe.run_283******* 
[INFO] 2021-07-12 18:31:02,539 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:02,539 [run_pretraining.py:  534]:	loss/total_loss, 9.258879661560059, 284
[INFO] 2021-07-12 18:31:02,540 [run_pretraining.py:  535]:	loss/mlm_loss, 9.258879661560059, 284
[INFO] 2021-07-12 18:31:02,540 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8299998575676e-06, 284
[INFO] 2021-07-12 18:31:02,540 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 284
[INFO] 2021-07-12 18:31:02,540 [run_pretraining.py:  558]:	worker_index: 6, step: 284, cost: 9.258880, mlm loss: 9.258880, speed: 0.911793 steps/s, speed: 7.294343 samples/s, speed: 3734.703833 tokens/s, learning rate: 2.830e-06, loss_scalings: 26214.400391, pp_loss: 9.338806
[INFO] 2021-07-12 18:31:02,540 [run_pretraining.py:  512]:	********exe.run_284******* 
[INFO] 2021-07-12 18:31:03,622 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:03,622 [run_pretraining.py:  534]:	loss/total_loss, 9.3662691116333, 285
[INFO] 2021-07-12 18:31:03,623 [run_pretraining.py:  535]:	loss/mlm_loss, 9.3662691116333, 285
[INFO] 2021-07-12 18:31:03,623 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8399999791872688e-06, 285
[INFO] 2021-07-12 18:31:03,623 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 285
[INFO] 2021-07-12 18:31:03,623 [run_pretraining.py:  558]:	worker_index: 6, step: 285, cost: 9.366269, mlm loss: 9.366269, speed: 0.923938 steps/s, speed: 7.391503 samples/s, speed: 3784.449755 tokens/s, learning rate: 2.840e-06, loss_scalings: 26214.400391, pp_loss: 9.445354
[INFO] 2021-07-12 18:31:03,623 [run_pretraining.py:  512]:	********exe.run_285******* 
[INFO] 2021-07-12 18:31:04,718 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:04,718 [run_pretraining.py:  534]:	loss/total_loss, 9.455020904541016, 286
[INFO] 2021-07-12 18:31:04,718 [run_pretraining.py:  535]:	loss/mlm_loss, 9.455020904541016, 286
[INFO] 2021-07-12 18:31:04,718 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.849999873433262e-06, 286
[INFO] 2021-07-12 18:31:04,719 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 286
[INFO] 2021-07-12 18:31:04,719 [run_pretraining.py:  558]:	worker_index: 6, step: 286, cost: 9.455021, mlm loss: 9.455021, speed: 0.913190 steps/s, speed: 7.305524 samples/s, speed: 3740.428237 tokens/s, learning rate: 2.850e-06, loss_scalings: 26214.400391, pp_loss: 9.327287
[INFO] 2021-07-12 18:31:04,719 [run_pretraining.py:  512]:	********exe.run_286******* 
[INFO] 2021-07-12 18:31:05,809 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:05,809 [run_pretraining.py:  534]:	loss/total_loss, 9.494827270507812, 287
[INFO] 2021-07-12 18:31:05,809 [run_pretraining.py:  535]:	loss/mlm_loss, 9.494827270507812, 287
[INFO] 2021-07-12 18:31:05,809 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.859999995052931e-06, 287
[INFO] 2021-07-12 18:31:05,810 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 287
[INFO] 2021-07-12 18:31:05,810 [run_pretraining.py:  558]:	worker_index: 6, step: 287, cost: 9.494827, mlm loss: 9.494827, speed: 0.917224 steps/s, speed: 7.337795 samples/s, speed: 3756.951218 tokens/s, learning rate: 2.860e-06, loss_scalings: 26214.400391, pp_loss: 9.368073
[INFO] 2021-07-12 18:31:05,810 [run_pretraining.py:  512]:	********exe.run_287******* 
[INFO] 2021-07-12 18:31:06,899 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:06,900 [run_pretraining.py:  534]:	loss/total_loss, 9.238885879516602, 288
[INFO] 2021-07-12 18:31:06,900 [run_pretraining.py:  535]:	loss/mlm_loss, 9.238885879516602, 288
[INFO] 2021-07-12 18:31:06,900 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8699998892989242e-06, 288
[INFO] 2021-07-12 18:31:06,900 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 288
[INFO] 2021-07-12 18:31:06,900 [run_pretraining.py:  558]:	worker_index: 6, step: 288, cost: 9.238886, mlm loss: 9.238886, speed: 0.917778 steps/s, speed: 7.342222 samples/s, speed: 3759.217688 tokens/s, learning rate: 2.870e-06, loss_scalings: 26214.400391, pp_loss: 9.304623
[INFO] 2021-07-12 18:31:06,900 [run_pretraining.py:  512]:	********exe.run_288******* 
[INFO] 2021-07-12 18:31:07,992 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:07,993 [run_pretraining.py:  534]:	loss/total_loss, 9.142934799194336, 289
[INFO] 2021-07-12 18:31:07,993 [run_pretraining.py:  535]:	loss/mlm_loss, 9.142934799194336, 289
[INFO] 2021-07-12 18:31:07,993 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8799997835449176e-06, 289
[INFO] 2021-07-12 18:31:07,993 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 289
[INFO] 2021-07-12 18:31:07,993 [run_pretraining.py:  558]:	worker_index: 6, step: 289, cost: 9.142935, mlm loss: 9.142935, speed: 0.915107 steps/s, speed: 7.320853 samples/s, speed: 3748.276485 tokens/s, learning rate: 2.880e-06, loss_scalings: 26214.400391, pp_loss: 9.387964
[INFO] 2021-07-12 18:31:07,994 [run_pretraining.py:  512]:	********exe.run_289******* 
[INFO] 2021-07-12 18:31:09,084 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:09,085 [run_pretraining.py:  534]:	loss/total_loss, 9.429863929748535, 290
[INFO] 2021-07-12 18:31:09,085 [run_pretraining.py:  535]:	loss/mlm_loss, 9.429863929748535, 290
[INFO] 2021-07-12 18:31:09,085 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8899999051645864e-06, 290
[INFO] 2021-07-12 18:31:09,085 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 290
[INFO] 2021-07-12 18:31:09,086 [run_pretraining.py:  558]:	worker_index: 6, step: 290, cost: 9.429864, mlm loss: 9.429864, speed: 0.916334 steps/s, speed: 7.330676 samples/s, speed: 3753.306110 tokens/s, learning rate: 2.890e-06, loss_scalings: 26214.400391, pp_loss: 9.337008
[INFO] 2021-07-12 18:31:09,086 [run_pretraining.py:  512]:	********exe.run_290******* 
[INFO] 2021-07-12 18:31:10,156 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:10,157 [run_pretraining.py:  534]:	loss/total_loss, 9.388994216918945, 291
[INFO] 2021-07-12 18:31:10,157 [run_pretraining.py:  535]:	loss/mlm_loss, 9.388994216918945, 291
[INFO] 2021-07-12 18:31:10,157 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8999997994105797e-06, 291
[INFO] 2021-07-12 18:31:10,157 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 291
[INFO] 2021-07-12 18:31:10,157 [run_pretraining.py:  558]:	worker_index: 6, step: 291, cost: 9.388994, mlm loss: 9.388994, speed: 0.933518 steps/s, speed: 7.468144 samples/s, speed: 3823.689872 tokens/s, learning rate: 2.900e-06, loss_scalings: 26214.400391, pp_loss: 9.328077
[INFO] 2021-07-12 18:31:10,158 [run_pretraining.py:  512]:	********exe.run_291******* 
[INFO] 2021-07-12 18:31:11,245 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:11,246 [run_pretraining.py:  534]:	loss/total_loss, 9.373456954956055, 292
[INFO] 2021-07-12 18:31:11,246 [run_pretraining.py:  535]:	loss/mlm_loss, 9.373456954956055, 292
[INFO] 2021-07-12 18:31:11,246 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9099999210302485e-06, 292
[INFO] 2021-07-12 18:31:11,246 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 292
[INFO] 2021-07-12 18:31:11,247 [run_pretraining.py:  558]:	worker_index: 6, step: 292, cost: 9.373457, mlm loss: 9.373457, speed: 0.918823 steps/s, speed: 7.350581 samples/s, speed: 3763.497473 tokens/s, learning rate: 2.910e-06, loss_scalings: 26214.400391, pp_loss: 9.442556
[INFO] 2021-07-12 18:31:11,247 [run_pretraining.py:  512]:	********exe.run_292******* 
[INFO] 2021-07-12 18:31:12,346 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:12,347 [run_pretraining.py:  534]:	loss/total_loss, 9.664131164550781, 293
[INFO] 2021-07-12 18:31:12,347 [run_pretraining.py:  535]:	loss/mlm_loss, 9.664131164550781, 293
[INFO] 2021-07-12 18:31:12,347 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9200000426499173e-06, 293
[INFO] 2021-07-12 18:31:12,347 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 293
[INFO] 2021-07-12 18:31:12,347 [run_pretraining.py:  558]:	worker_index: 6, step: 293, cost: 9.664131, mlm loss: 9.664131, speed: 0.909315 steps/s, speed: 7.274522 samples/s, speed: 3724.555366 tokens/s, learning rate: 2.920e-06, loss_scalings: 26214.400391, pp_loss: 9.560987
[INFO] 2021-07-12 18:31:12,347 [run_pretraining.py:  512]:	********exe.run_293******* 
[INFO] 2021-07-12 18:31:13,431 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:13,432 [run_pretraining.py:  534]:	loss/total_loss, 9.39178466796875, 294
[INFO] 2021-07-12 18:31:13,432 [run_pretraining.py:  535]:	loss/mlm_loss, 9.39178466796875, 294
[INFO] 2021-07-12 18:31:13,432 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9299999368959107e-06, 294
[INFO] 2021-07-12 18:31:13,432 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 294
[INFO] 2021-07-12 18:31:13,433 [run_pretraining.py:  558]:	worker_index: 6, step: 294, cost: 9.391785, mlm loss: 9.391785, speed: 0.921857 steps/s, speed: 7.374855 samples/s, speed: 3775.925715 tokens/s, learning rate: 2.930e-06, loss_scalings: 26214.400391, pp_loss: 9.539163
[INFO] 2021-07-12 18:31:13,433 [run_pretraining.py:  512]:	********exe.run_294******* 
[INFO] 2021-07-12 18:31:14,521 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:14,521 [run_pretraining.py:  534]:	loss/total_loss, 9.578782081604004, 295
[INFO] 2021-07-12 18:31:14,521 [run_pretraining.py:  535]:	loss/mlm_loss, 9.578782081604004, 295
[INFO] 2021-07-12 18:31:14,522 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9400000585155794e-06, 295
[INFO] 2021-07-12 18:31:14,522 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 295
[INFO] 2021-07-12 18:31:14,522 [run_pretraining.py:  558]:	worker_index: 6, step: 295, cost: 9.578782, mlm loss: 9.578782, speed: 0.918665 steps/s, speed: 7.349317 samples/s, speed: 3762.850393 tokens/s, learning rate: 2.940e-06, loss_scalings: 26214.400391, pp_loss: 9.361635
[INFO] 2021-07-12 18:31:14,522 [run_pretraining.py:  512]:	********exe.run_295******* 
[INFO] 2021-07-12 18:31:15,606 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:15,606 [run_pretraining.py:  534]:	loss/total_loss, 9.197542190551758, 296
[INFO] 2021-07-12 18:31:15,606 [run_pretraining.py:  535]:	loss/mlm_loss, 9.197542190551758, 296
[INFO] 2021-07-12 18:31:15,606 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9499999527615728e-06, 296
[INFO] 2021-07-12 18:31:15,606 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 296
[INFO] 2021-07-12 18:31:15,607 [run_pretraining.py:  558]:	worker_index: 6, step: 296, cost: 9.197542, mlm loss: 9.197542, speed: 0.922442 steps/s, speed: 7.379533 samples/s, speed: 3778.320672 tokens/s, learning rate: 2.950e-06, loss_scalings: 26214.400391, pp_loss: 9.501047
[INFO] 2021-07-12 18:31:15,607 [run_pretraining.py:  512]:	********exe.run_296******* 
[INFO] 2021-07-12 18:31:16,703 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:16,703 [run_pretraining.py:  534]:	loss/total_loss, 9.387706756591797, 297
[INFO] 2021-07-12 18:31:16,703 [run_pretraining.py:  535]:	loss/mlm_loss, 9.387706756591797, 297
[INFO] 2021-07-12 18:31:16,703 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.959999847007566e-06, 297
[INFO] 2021-07-12 18:31:16,704 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 297
[INFO] 2021-07-12 18:31:16,704 [run_pretraining.py:  558]:	worker_index: 6, step: 297, cost: 9.387707, mlm loss: 9.387707, speed: 0.912124 steps/s, speed: 7.296991 samples/s, speed: 3736.059355 tokens/s, learning rate: 2.960e-06, loss_scalings: 26214.400391, pp_loss: 9.420183
[INFO] 2021-07-12 18:31:16,704 [run_pretraining.py:  512]:	********exe.run_297******* 
[INFO] 2021-07-12 18:31:42,952 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:42,953 [run_pretraining.py:  534]:	loss/total_loss, 9.41807746887207, 298
[INFO] 2021-07-12 18:31:42,953 [run_pretraining.py:  535]:	loss/mlm_loss, 9.41807746887207, 298
[INFO] 2021-07-12 18:31:42,953 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.969999968627235e-06, 298
[INFO] 2021-07-12 18:31:42,953 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 298
[INFO] 2021-07-12 18:31:42,953 [run_pretraining.py:  558]:	worker_index: 6, step: 298, cost: 9.418077, mlm loss: 9.418077, speed: 0.038097 steps/s, speed: 0.304777 samples/s, speed: 156.045749 tokens/s, learning rate: 2.970e-06, loss_scalings: 26214.400391, pp_loss: 9.298903
[INFO] 2021-07-12 18:31:42,953 [run_pretraining.py:  512]:	********exe.run_298******* 
[INFO] 2021-07-12 18:31:43,905 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:43,906 [run_pretraining.py:  534]:	loss/total_loss, 9.591282844543457, 299
[INFO] 2021-07-12 18:31:43,906 [run_pretraining.py:  535]:	loss/mlm_loss, 9.591282844543457, 299
[INFO] 2021-07-12 18:31:43,906 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9799998628732283e-06, 299
[INFO] 2021-07-12 18:31:43,906 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 299
[INFO] 2021-07-12 18:31:43,906 [run_pretraining.py:  558]:	worker_index: 6, step: 299, cost: 9.591283, mlm loss: 9.591283, speed: 1.050414 steps/s, speed: 8.403316 samples/s, speed: 4302.497743 tokens/s, learning rate: 2.980e-06, loss_scalings: 26214.400391, pp_loss: 9.453650
[INFO] 2021-07-12 18:31:43,906 [run_pretraining.py:  512]:	********exe.run_299******* 
[INFO] 2021-07-12 18:31:44,847 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:44,847 [run_pretraining.py:  534]:	loss/total_loss, 9.419502258300781, 300
[INFO] 2021-07-12 18:31:44,847 [run_pretraining.py:  535]:	loss/mlm_loss, 9.419502258300781, 300
[INFO] 2021-07-12 18:31:44,848 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.989999984492897e-06, 300
[INFO] 2021-07-12 18:31:44,848 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 300
[INFO] 2021-07-12 18:31:44,848 [run_pretraining.py:  558]:	worker_index: 6, step: 300, cost: 9.419502, mlm loss: 9.419502, speed: 1.062661 steps/s, speed: 8.501290 samples/s, speed: 4352.660726 tokens/s, learning rate: 2.990e-06, loss_scalings: 26214.400391, pp_loss: 9.410431
[INFO] 2021-07-12 18:31:44,848 [run_pretraining.py:  512]:	********exe.run_300******* 
[INFO] 2021-07-12 18:31:45,771 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:45,771 [run_pretraining.py:  534]:	loss/total_loss, 9.258968353271484, 301
[INFO] 2021-07-12 18:31:45,771 [run_pretraining.py:  535]:	loss/mlm_loss, 9.258968353271484, 301
[INFO] 2021-07-12 18:31:45,771 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9999998787388904e-06, 301
[INFO] 2021-07-12 18:31:45,771 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 301
[INFO] 2021-07-12 18:31:45,772 [run_pretraining.py:  558]:	worker_index: 6, step: 301, cost: 9.258968, mlm loss: 9.258968, speed: 1.083312 steps/s, speed: 8.666499 samples/s, speed: 4437.247642 tokens/s, learning rate: 3.000e-06, loss_scalings: 26214.400391, pp_loss: 9.249307
[INFO] 2021-07-12 18:31:45,772 [run_pretraining.py:  512]:	********exe.run_301******* 
[INFO] 2021-07-12 18:31:46,699 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:46,699 [run_pretraining.py:  534]:	loss/total_loss, 9.514236450195312, 302
[INFO] 2021-07-12 18:31:46,699 [run_pretraining.py:  535]:	loss/mlm_loss, 9.514236450195312, 302
[INFO] 2021-07-12 18:31:46,700 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.0099997729848837e-06, 302
[INFO] 2021-07-12 18:31:46,700 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 302
[INFO] 2021-07-12 18:31:46,700 [run_pretraining.py:  558]:	worker_index: 6, step: 302, cost: 9.514236, mlm loss: 9.514236, speed: 1.078216 steps/s, speed: 8.625725 samples/s, speed: 4416.371130 tokens/s, learning rate: 3.010e-06, loss_scalings: 26214.400391, pp_loss: 9.369054
[INFO] 2021-07-12 18:31:46,700 [run_pretraining.py:  512]:	********exe.run_302******* 
[INFO] 2021-07-12 18:31:47,609 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:47,610 [run_pretraining.py:  534]:	loss/total_loss, 9.20003890991211, 303
[INFO] 2021-07-12 18:31:47,610 [run_pretraining.py:  535]:	loss/mlm_loss, 9.20003890991211, 303
[INFO] 2021-07-12 18:31:47,610 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.020000121978228e-06, 303
[INFO] 2021-07-12 18:31:47,610 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 303
[INFO] 2021-07-12 18:31:47,611 [run_pretraining.py:  558]:	worker_index: 6, step: 303, cost: 9.200039, mlm loss: 9.200039, speed: 1.098940 steps/s, speed: 8.791521 samples/s, speed: 4501.258864 tokens/s, learning rate: 3.020e-06, loss_scalings: 26214.400391, pp_loss: 9.221970
[INFO] 2021-07-12 18:31:47,611 [run_pretraining.py:  512]:	********exe.run_303******* 
[INFO] 2021-07-12 18:31:48,518 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:48,519 [run_pretraining.py:  534]:	loss/total_loss, 9.279738426208496, 304
[INFO] 2021-07-12 18:31:48,519 [run_pretraining.py:  535]:	loss/mlm_loss, 9.279738426208496, 304
[INFO] 2021-07-12 18:31:48,519 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.0300000162242213e-06, 304
[INFO] 2021-07-12 18:31:48,519 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 304
[INFO] 2021-07-12 18:31:48,519 [run_pretraining.py:  558]:	worker_index: 6, step: 304, cost: 9.279738, mlm loss: 9.279738, speed: 1.101471 steps/s, speed: 8.811764 samples/s, speed: 4511.623344 tokens/s, learning rate: 3.030e-06, loss_scalings: 26214.400391, pp_loss: 9.392749
[INFO] 2021-07-12 18:31:48,519 [run_pretraining.py:  512]:	********exe.run_304******* 
[INFO] 2021-07-12 18:31:49,431 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:49,432 [run_pretraining.py:  534]:	loss/total_loss, 9.545687675476074, 305
[INFO] 2021-07-12 18:31:49,432 [run_pretraining.py:  535]:	loss/mlm_loss, 9.545687675476074, 305
[INFO] 2021-07-12 18:31:49,432 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.0399999104702147e-06, 305
[INFO] 2021-07-12 18:31:49,432 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 305
[INFO] 2021-07-12 18:31:49,433 [run_pretraining.py:  558]:	worker_index: 6, step: 305, cost: 9.545688, mlm loss: 9.545688, speed: 1.095668 steps/s, speed: 8.765340 samples/s, speed: 4487.854145 tokens/s, learning rate: 3.040e-06, loss_scalings: 26214.400391, pp_loss: 9.603254
[INFO] 2021-07-12 18:31:49,433 [run_pretraining.py:  512]:	********exe.run_305******* 
[INFO] 2021-07-12 18:31:50,343 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:50,343 [run_pretraining.py:  534]:	loss/total_loss, 9.08859634399414, 306
[INFO] 2021-07-12 18:31:50,343 [run_pretraining.py:  535]:	loss/mlm_loss, 9.08859634399414, 306
[INFO] 2021-07-12 18:31:50,343 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.0500000320898835e-06, 306
[INFO] 2021-07-12 18:31:50,344 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 306
[INFO] 2021-07-12 18:31:50,344 [run_pretraining.py:  558]:	worker_index: 6, step: 306, cost: 9.088596, mlm loss: 9.088596, speed: 1.098426 steps/s, speed: 8.787405 samples/s, speed: 4499.151148 tokens/s, learning rate: 3.050e-06, loss_scalings: 26214.400391, pp_loss: 9.371939
[INFO] 2021-07-12 18:31:50,344 [run_pretraining.py:  512]:	********exe.run_306******* 
[INFO] 2021-07-12 18:31:51,247 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:51,248 [run_pretraining.py:  534]:	loss/total_loss, 9.154841423034668, 307
[INFO] 2021-07-12 18:31:51,248 [run_pretraining.py:  535]:	loss/mlm_loss, 9.154841423034668, 307
[INFO] 2021-07-12 18:31:51,248 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.059999926335877e-06, 307
[INFO] 2021-07-12 18:31:51,248 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 307
[INFO] 2021-07-12 18:31:51,248 [run_pretraining.py:  558]:	worker_index: 6, step: 307, cost: 9.154841, mlm loss: 9.154841, speed: 1.106225 steps/s, speed: 8.849797 samples/s, speed: 4531.096318 tokens/s, learning rate: 3.060e-06, loss_scalings: 26214.400391, pp_loss: 9.313648
[INFO] 2021-07-12 18:31:51,248 [run_pretraining.py:  512]:	********exe.run_307******* 
[INFO] 2021-07-12 18:31:52,166 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:52,167 [run_pretraining.py:  534]:	loss/total_loss, 9.564369201660156, 308
[INFO] 2021-07-12 18:31:52,167 [run_pretraining.py:  535]:	loss/mlm_loss, 9.564369201660156, 308
[INFO] 2021-07-12 18:31:52,167 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.06999982058187e-06, 308
[INFO] 2021-07-12 18:31:52,167 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 308
[INFO] 2021-07-12 18:31:52,167 [run_pretraining.py:  558]:	worker_index: 6, step: 308, cost: 9.564369, mlm loss: 9.564369, speed: 1.089378 steps/s, speed: 8.715023 samples/s, speed: 4462.091590 tokens/s, learning rate: 3.070e-06, loss_scalings: 26214.400391, pp_loss: 9.291674
[INFO] 2021-07-12 18:31:52,167 [run_pretraining.py:  512]:	********exe.run_308******* 
[INFO] 2021-07-12 18:31:53,079 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:53,080 [run_pretraining.py:  534]:	loss/total_loss, 8.990962982177734, 309
[INFO] 2021-07-12 18:31:53,080 [run_pretraining.py:  535]:	loss/mlm_loss, 8.990962982177734, 309
[INFO] 2021-07-12 18:31:53,080 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.079999942201539e-06, 309
[INFO] 2021-07-12 18:31:53,080 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 309
[INFO] 2021-07-12 18:31:53,080 [run_pretraining.py:  558]:	worker_index: 6, step: 309, cost: 8.990963, mlm loss: 8.990963, speed: 1.095856 steps/s, speed: 8.766852 samples/s, speed: 4488.628030 tokens/s, learning rate: 3.080e-06, loss_scalings: 26214.400391, pp_loss: 9.233117
[INFO] 2021-07-12 18:31:53,080 [run_pretraining.py:  512]:	********exe.run_309******* 
[INFO] 2021-07-12 18:32:18,913 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:32:18,914 [run_pretraining.py:  534]:	loss/total_loss, 9.104519844055176, 310
[INFO] 2021-07-12 18:32:18,914 [run_pretraining.py:  535]:	loss/mlm_loss, 9.104519844055176, 310
[INFO] 2021-07-12 18:32:18,914 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.0899998364475323e-06, 310
[INFO] 2021-07-12 18:32:18,914 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 310
[INFO] 2021-07-12 18:32:18,914 [run_pretraining.py:  558]:	worker_index: 6, step: 310, cost: 9.104520, mlm loss: 9.104520, speed: 0.038710 steps/s, speed: 0.309682 samples/s, speed: 158.557296 tokens/s, learning rate: 3.090e-06, loss_scalings: 26214.400391, pp_loss: 9.385201
[INFO] 2021-07-12 18:32:18,914 [run_pretraining.py:  512]:	********exe.run_310******* 
[INFO] 2021-07-12 18:32:19,813 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:32:19,814 [run_pretraining.py:  534]:	loss/total_loss, 9.167551040649414, 311
[INFO] 2021-07-12 18:32:19,814 [run_pretraining.py:  535]:	loss/mlm_loss, 9.167551040649414, 311
[INFO] 2021-07-12 18:32:19,814 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.099999958067201e-06, 311
[INFO] 2021-07-12 18:32:19,814 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 311
[INFO] 2021-07-12 18:32:19,814 [run_pretraining.py:  558]:	worker_index: 6, step: 311, cost: 9.167551, mlm loss: 9.167551, speed: 1.111826 steps/s, speed: 8.894607 samples/s, speed: 4554.038581 tokens/s, learning rate: 3.100e-06, loss_scalings: 26214.400391, pp_loss: 9.439593
[INFO] 2021-07-12 18:32:19,814 [run_pretraining.py:  512]:	********exe.run_311******* 
[INFO] 2021-07-12 18:32:20,732 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:32:20,732 [run_pretraining.py:  534]:	loss/total_loss, 9.0515775680542, 312
[INFO] 2021-07-12 18:32:20,732 [run_pretraining.py:  535]:	loss/mlm_loss, 9.0515775680542, 312
[INFO] 2021-07-12 18:32:20,732 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.1099998523131944e-06, 312
[INFO] 2021-07-12 18:32:20,733 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 312
[INFO] 2021-07-12 18:32:20,733 [run_pretraining.py:  558]:	worker_index: 6, step: 312, cost: 9.051578, mlm loss: 9.051578, speed: 1.089555 steps/s, speed: 8.716438 samples/s, speed: 4462.816039 tokens/s, learning rate: 3.110e-06, loss_scalings: 26214.400391, pp_loss: 9.340988
[INFO] 2021-07-12 18:32:20,733 [run_pretraining.py:  512]:	********exe.run_312******* 
[INFO] 2021-07-12 18:32:21,638 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:32:21,638 [run_pretraining.py:  534]:	loss/total_loss, 9.4881010055542, 313
[INFO] 2021-07-12 18:32:21,638 [run_pretraining.py:  535]:	loss/mlm_loss, 9.4881010055542, 313
[INFO] 2021-07-12 18:32:21,638 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.1199997465591878e-06, 313
[INFO] 2021-07-12 18:32:21,638 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 313
[INFO] 2021-07-12 18:32:21,639 [run_pretraining.py:  558]:	worker_index: 6, step: 313, cost: 9.488101, mlm loss: 9.488101, speed: 1.104809 steps/s, speed: 8.838475 samples/s, speed: 4525.299378 tokens/s, learning rate: 3.120e-06, loss_scalings: 26214.400391, pp_loss: 9.514414
[INFO] 2021-07-12 18:32:21,639 [run_pretraining.py:  512]:	********exe.run_313******* 
[INFO] 2021-07-12 18:32:48,133 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:32:48,134 [run_pretraining.py:  534]:	loss/total_loss, 9.347137451171875, 314
[INFO] 2021-07-12 18:32:48,134 [run_pretraining.py:  535]:	loss/mlm_loss, 9.347137451171875, 314
[INFO] 2021-07-12 18:32:48,134 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.130000095552532e-06, 314
[INFO] 2021-07-12 18:32:48,134 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 314
[INFO] 2021-07-12 18:32:48,134 [run_pretraining.py:  558]:	worker_index: 6, step: 314, cost: 9.347137, mlm loss: 9.347137, speed: 0.037743 steps/s, speed: 0.301946 samples/s, speed: 154.596509 tokens/s, learning rate: 3.130e-06, loss_scalings: 26214.400391, pp_loss: 9.418921
[INFO] 2021-07-12 18:32:48,134 [run_pretraining.py:  512]:	********exe.run_314******* 
[INFO] 2021-07-12 18:33:14,232 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:14,232 [run_pretraining.py:  534]:	loss/total_loss, 9.169692039489746, 315
[INFO] 2021-07-12 18:33:14,232 [run_pretraining.py:  535]:	loss/mlm_loss, 9.169692039489746, 315
[INFO] 2021-07-12 18:33:14,232 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.13999976242485e-06, 315
[INFO] 2021-07-12 18:33:14,233 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 315
[INFO] 2021-07-12 18:33:14,233 [run_pretraining.py:  558]:	worker_index: 6, step: 315, cost: 9.169692, mlm loss: 9.169692, speed: 0.038317 steps/s, speed: 0.306539 samples/s, speed: 156.947963 tokens/s, learning rate: 3.140e-06, loss_scalings: 26214.400391, pp_loss: 9.228384
[INFO] 2021-07-12 18:33:14,233 [run_pretraining.py:  512]:	********exe.run_315******* 
[INFO] 2021-07-12 18:33:15,173 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:15,174 [run_pretraining.py:  534]:	loss/total_loss, 9.328145027160645, 316
[INFO] 2021-07-12 18:33:15,174 [run_pretraining.py:  535]:	loss/mlm_loss, 9.328145027160645, 316
[INFO] 2021-07-12 18:33:15,174 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.1499998840445187e-06, 316
[INFO] 2021-07-12 18:33:15,174 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 316
[INFO] 2021-07-12 18:33:15,174 [run_pretraining.py:  558]:	worker_index: 6, step: 316, cost: 9.328145, mlm loss: 9.328145, speed: 1.063128 steps/s, speed: 8.505027 samples/s, speed: 4354.573791 tokens/s, learning rate: 3.150e-06, loss_scalings: 26214.400391, pp_loss: 9.365107
[INFO] 2021-07-12 18:33:15,174 [run_pretraining.py:  512]:	********exe.run_316******* 
[INFO] 2021-07-12 18:33:16,092 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:16,093 [run_pretraining.py:  534]:	loss/total_loss, 9.17766284942627, 317
[INFO] 2021-07-12 18:33:16,093 [run_pretraining.py:  535]:	loss/mlm_loss, 9.17766284942627, 317
[INFO] 2021-07-12 18:33:16,093 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.159999778290512e-06, 317
[INFO] 2021-07-12 18:33:16,093 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 317
[INFO] 2021-07-12 18:33:16,093 [run_pretraining.py:  558]:	worker_index: 6, step: 317, cost: 9.177663, mlm loss: 9.177663, speed: 1.088822 steps/s, speed: 8.710577 samples/s, speed: 4459.815455 tokens/s, learning rate: 3.160e-06, loss_scalings: 26214.400391, pp_loss: 9.180783
[INFO] 2021-07-12 18:33:16,093 [run_pretraining.py:  512]:	********exe.run_317******* 
[INFO] 2021-07-12 18:33:17,002 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:17,003 [run_pretraining.py:  534]:	loss/total_loss, 9.354473114013672, 318
[INFO] 2021-07-12 18:33:17,003 [run_pretraining.py:  535]:	loss/mlm_loss, 9.354473114013672, 318
[INFO] 2021-07-12 18:33:17,003 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.169999899910181e-06, 318
[INFO] 2021-07-12 18:33:17,003 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 318
[INFO] 2021-07-12 18:33:17,004 [run_pretraining.py:  558]:	worker_index: 6, step: 318, cost: 9.354473, mlm loss: 9.354473, speed: 1.099405 steps/s, speed: 8.795243 samples/s, speed: 4503.164345 tokens/s, learning rate: 3.170e-06, loss_scalings: 26214.400391, pp_loss: 9.428837
[INFO] 2021-07-12 18:33:17,004 [run_pretraining.py:  512]:	********exe.run_318******* 
[INFO] 2021-07-12 18:33:17,907 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:17,908 [run_pretraining.py:  534]:	loss/total_loss, 9.296920776367188, 319
[INFO] 2021-07-12 18:33:17,908 [run_pretraining.py:  535]:	loss/mlm_loss, 9.296920776367188, 319
[INFO] 2021-07-12 18:33:17,908 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.1800000215298496e-06, 319
[INFO] 2021-07-12 18:33:17,908 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 319
[INFO] 2021-07-12 18:33:17,908 [run_pretraining.py:  558]:	worker_index: 6, step: 319, cost: 9.296921, mlm loss: 9.296921, speed: 1.106412 steps/s, speed: 8.851294 samples/s, speed: 4531.862476 tokens/s, learning rate: 3.180e-06, loss_scalings: 26214.400391, pp_loss: 9.436823
[INFO] 2021-07-12 18:33:17,908 [run_pretraining.py:  512]:	********exe.run_319******* 
[INFO] 2021-07-12 18:33:18,826 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:18,827 [run_pretraining.py:  534]:	loss/total_loss, 9.550060272216797, 320
[INFO] 2021-07-12 18:33:18,827 [run_pretraining.py:  535]:	loss/mlm_loss, 9.550060272216797, 320
[INFO] 2021-07-12 18:33:18,827 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.189999915775843e-06, 320
[INFO] 2021-07-12 18:33:18,827 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 320
[INFO] 2021-07-12 18:33:18,827 [run_pretraining.py:  558]:	worker_index: 6, step: 320, cost: 9.550060, mlm loss: 9.550060, speed: 1.088644 steps/s, speed: 8.709155 samples/s, speed: 4459.087350 tokens/s, learning rate: 3.190e-06, loss_scalings: 26214.400391, pp_loss: 9.496869
[INFO] 2021-07-12 18:33:18,827 [run_pretraining.py:  512]:	********exe.run_320******* 
[INFO] 2021-07-12 18:33:19,738 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:19,738 [run_pretraining.py:  534]:	loss/total_loss, 9.730756759643555, 321
[INFO] 2021-07-12 18:33:19,739 [run_pretraining.py:  535]:	loss/mlm_loss, 9.730756759643555, 321
[INFO] 2021-07-12 18:33:19,739 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.2000000373955118e-06, 321
[INFO] 2021-07-12 18:33:19,739 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 321
[INFO] 2021-07-12 18:33:19,739 [run_pretraining.py:  558]:	worker_index: 6, step: 321, cost: 9.730757, mlm loss: 9.730757, speed: 1.097970 steps/s, speed: 8.783763 samples/s, speed: 4497.286734 tokens/s, learning rate: 3.200e-06, loss_scalings: 26214.400391, pp_loss: 9.303928
[INFO] 2021-07-12 18:33:19,739 [run_pretraining.py:  512]:	********exe.run_321******* 
[INFO] 2021-07-12 18:33:20,651 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:20,652 [run_pretraining.py:  534]:	loss/total_loss, 9.436373710632324, 322
[INFO] 2021-07-12 18:33:20,652 [run_pretraining.py:  535]:	loss/mlm_loss, 9.436373710632324, 322
[INFO] 2021-07-12 18:33:20,652 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.209999931641505e-06, 322
[INFO] 2021-07-12 18:33:20,652 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 322
[INFO] 2021-07-12 18:33:20,652 [run_pretraining.py:  558]:	worker_index: 6, step: 322, cost: 9.436374, mlm loss: 9.436374, speed: 1.095860 steps/s, speed: 8.766881 samples/s, speed: 4488.643276 tokens/s, learning rate: 3.210e-06, loss_scalings: 26214.400391, pp_loss: 9.368101
[INFO] 2021-07-12 18:33:20,652 [run_pretraining.py:  512]:	********exe.run_322******* 
[INFO] 2021-07-12 18:33:21,559 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:21,559 [run_pretraining.py:  534]:	loss/total_loss, 9.420560836791992, 323
[INFO] 2021-07-12 18:33:21,560 [run_pretraining.py:  535]:	loss/mlm_loss, 9.420560836791992, 323
[INFO] 2021-07-12 18:33:21,560 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.220000053261174e-06, 323
[INFO] 2021-07-12 18:33:21,560 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 323
[INFO] 2021-07-12 18:33:21,560 [run_pretraining.py:  558]:	worker_index: 6, step: 323, cost: 9.420561, mlm loss: 9.420561, speed: 1.102673 steps/s, speed: 8.821381 samples/s, speed: 4516.546825 tokens/s, learning rate: 3.220e-06, loss_scalings: 26214.400391, pp_loss: 9.597353
[INFO] 2021-07-12 18:33:21,560 [run_pretraining.py:  512]:	********exe.run_323******* 
[INFO] 2021-07-12 18:33:22,469 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:22,470 [run_pretraining.py:  534]:	loss/total_loss, 9.34931755065918, 324
[INFO] 2021-07-12 18:33:22,470 [run_pretraining.py:  535]:	loss/mlm_loss, 9.34931755065918, 324
[INFO] 2021-07-12 18:33:22,470 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.229999720133492e-06, 324
[INFO] 2021-07-12 18:33:22,470 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 324
[INFO] 2021-07-12 18:33:22,470 [run_pretraining.py:  558]:	worker_index: 6, step: 324, cost: 9.349318, mlm loss: 9.349318, speed: 1.099497 steps/s, speed: 8.795974 samples/s, speed: 4503.538551 tokens/s, learning rate: 3.230e-06, loss_scalings: 26214.400391, pp_loss: 9.269474
[INFO] 2021-07-12 18:33:22,470 [run_pretraining.py:  512]:	********exe.run_324******* 
[INFO] 2021-07-12 18:33:23,390 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:23,390 [run_pretraining.py:  534]:	loss/total_loss, 9.498083114624023, 325
[INFO] 2021-07-12 18:33:23,390 [run_pretraining.py:  535]:	loss/mlm_loss, 9.498083114624023, 325
[INFO] 2021-07-12 18:33:23,391 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.240000069126836e-06, 325
[INFO] 2021-07-12 18:33:23,391 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 325
[INFO] 2021-07-12 18:33:23,391 [run_pretraining.py:  558]:	worker_index: 6, step: 325, cost: 9.498083, mlm loss: 9.498083, speed: 1.086897 steps/s, speed: 8.695178 samples/s, speed: 4451.931262 tokens/s, learning rate: 3.240e-06, loss_scalings: 26214.400391, pp_loss: 9.312666
[INFO] 2021-07-12 18:33:23,391 [run_pretraining.py:  512]:	********exe.run_325******* 
[INFO] 2021-07-12 18:33:49,754 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:49,754 [run_pretraining.py:  534]:	loss/total_loss, 9.374866485595703, 326
[INFO] 2021-07-12 18:33:49,755 [run_pretraining.py:  535]:	loss/mlm_loss, 9.374866485595703, 326
[INFO] 2021-07-12 18:33:49,755 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.249999735999154e-06, 326
[INFO] 2021-07-12 18:33:49,755 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 326
[INFO] 2021-07-12 18:33:49,755 [run_pretraining.py:  558]:	worker_index: 6, step: 326, cost: 9.374866, mlm loss: 9.374866, speed: 0.037931 steps/s, speed: 0.303451 samples/s, speed: 155.367121 tokens/s, learning rate: 3.250e-06, loss_scalings: 20971.521484, pp_loss: 9.375494
[INFO] 2021-07-12 18:33:49,755 [run_pretraining.py:  512]:	********exe.run_326******* 
[INFO] 2021-07-12 18:33:50,684 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:50,685 [run_pretraining.py:  534]:	loss/total_loss, 9.317970275878906, 327
[INFO] 2021-07-12 18:33:50,685 [run_pretraining.py:  535]:	loss/mlm_loss, 9.317970275878906, 327
[INFO] 2021-07-12 18:33:50,685 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.2599998576188227e-06, 327
[INFO] 2021-07-12 18:33:50,685 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 327
[INFO] 2021-07-12 18:33:50,685 [run_pretraining.py:  558]:	worker_index: 6, step: 327, cost: 9.317970, mlm loss: 9.317970, speed: 1.075734 steps/s, speed: 8.605870 samples/s, speed: 4406.205252 tokens/s, learning rate: 3.260e-06, loss_scalings: 20971.521484, pp_loss: 9.324185
[INFO] 2021-07-12 18:33:50,685 [run_pretraining.py:  512]:	********exe.run_327******* 
[INFO] 2021-07-12 18:33:51,618 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:51,618 [run_pretraining.py:  534]:	loss/total_loss, 9.299627304077148, 328
[INFO] 2021-07-12 18:33:51,619 [run_pretraining.py:  535]:	loss/mlm_loss, 9.299627304077148, 328
[INFO] 2021-07-12 18:33:51,619 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.269999751864816e-06, 328
[INFO] 2021-07-12 18:33:51,619 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 328
[INFO] 2021-07-12 18:33:51,619 [run_pretraining.py:  558]:	worker_index: 6, step: 328, cost: 9.299627, mlm loss: 9.299627, speed: 1.071964 steps/s, speed: 8.575715 samples/s, speed: 4390.766129 tokens/s, learning rate: 3.270e-06, loss_scalings: 20971.521484, pp_loss: 9.270067
[INFO] 2021-07-12 18:33:51,619 [run_pretraining.py:  512]:	********exe.run_328******* 
[INFO] 2021-07-12 18:33:52,541 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:52,541 [run_pretraining.py:  534]:	loss/total_loss, 9.071674346923828, 329
[INFO] 2021-07-12 18:33:52,541 [run_pretraining.py:  535]:	loss/mlm_loss, 9.071674346923828, 329
[INFO] 2021-07-12 18:33:52,541 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.279999873484485e-06, 329
[INFO] 2021-07-12 18:33:52,542 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 329
[INFO] 2021-07-12 18:33:52,542 [run_pretraining.py:  558]:	worker_index: 6, step: 329, cost: 9.071674, mlm loss: 9.071674, speed: 1.084567 steps/s, speed: 8.676532 samples/s, speed: 4442.384494 tokens/s, learning rate: 3.280e-06, loss_scalings: 20971.521484, pp_loss: 9.210631
[INFO] 2021-07-12 18:33:52,542 [run_pretraining.py:  512]:	********exe.run_329******* 
[INFO] 2021-07-12 18:33:53,469 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:53,469 [run_pretraining.py:  534]:	loss/total_loss, 9.512982368469238, 330
[INFO] 2021-07-12 18:33:53,469 [run_pretraining.py:  535]:	loss/mlm_loss, 9.512982368469238, 330
[INFO] 2021-07-12 18:33:53,469 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.2899999951041536e-06, 330
[INFO] 2021-07-12 18:33:53,469 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 330
[INFO] 2021-07-12 18:33:53,470 [run_pretraining.py:  558]:	worker_index: 6, step: 330, cost: 9.512982, mlm loss: 9.512982, speed: 1.078479 steps/s, speed: 8.627832 samples/s, speed: 4417.449930 tokens/s, learning rate: 3.290e-06, loss_scalings: 20971.521484, pp_loss: 9.295924
[INFO] 2021-07-12 18:33:53,470 [run_pretraining.py:  512]:	********exe.run_330******* 
[INFO] 2021-07-12 18:33:54,409 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:54,410 [run_pretraining.py:  534]:	loss/total_loss, 9.359333038330078, 331
[INFO] 2021-07-12 18:33:54,410 [run_pretraining.py:  535]:	loss/mlm_loss, 9.359333038330078, 331
[INFO] 2021-07-12 18:33:54,410 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.299999889350147e-06, 331
[INFO] 2021-07-12 18:33:54,410 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 331
[INFO] 2021-07-12 18:33:54,410 [run_pretraining.py:  558]:	worker_index: 6, step: 331, cost: 9.359333, mlm loss: 9.359333, speed: 1.063801 steps/s, speed: 8.510407 samples/s, speed: 4357.328289 tokens/s, learning rate: 3.300e-06, loss_scalings: 20971.521484, pp_loss: 9.321949
[INFO] 2021-07-12 18:33:54,410 [run_pretraining.py:  512]:	********exe.run_331******* 
[INFO] 2021-07-12 18:33:55,339 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:55,340 [run_pretraining.py:  534]:	loss/total_loss, 9.342508316040039, 332
[INFO] 2021-07-12 18:33:55,340 [run_pretraining.py:  535]:	loss/mlm_loss, 9.342508316040039, 332
[INFO] 2021-07-12 18:33:55,340 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.3100000109698158e-06, 332
[INFO] 2021-07-12 18:33:55,340 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 332
[INFO] 2021-07-12 18:33:55,340 [run_pretraining.py:  558]:	worker_index: 6, step: 332, cost: 9.342508, mlm loss: 9.342508, speed: 1.076573 steps/s, speed: 8.612583 samples/s, speed: 4409.642247 tokens/s, learning rate: 3.310e-06, loss_scalings: 20971.521484, pp_loss: 9.205094
[INFO] 2021-07-12 18:33:55,340 [run_pretraining.py:  512]:	********exe.run_332******* 
[INFO] 2021-07-12 18:33:56,263 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:56,264 [run_pretraining.py:  534]:	loss/total_loss, 5.741644382476807, 333
[INFO] 2021-07-12 18:33:56,264 [run_pretraining.py:  535]:	loss/mlm_loss, 5.741644382476807, 333
[INFO] 2021-07-12 18:33:56,264 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.319999905215809e-06, 333
[INFO] 2021-07-12 18:33:56,264 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 333
[INFO] 2021-07-12 18:33:56,264 [run_pretraining.py:  558]:	worker_index: 6, step: 333, cost: 5.741644, mlm loss: 5.741644, speed: 1.083162 steps/s, speed: 8.665295 samples/s, speed: 4436.631147 tokens/s, learning rate: 3.320e-06, loss_scalings: 20971.521484, pp_loss: 8.437807
[INFO] 2021-07-12 18:33:56,264 [run_pretraining.py:  512]:	********exe.run_333******* 
[INFO] 2021-07-12 18:33:57,190 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:57,190 [run_pretraining.py:  534]:	loss/total_loss, 9.527749061584473, 334
[INFO] 2021-07-12 18:33:57,191 [run_pretraining.py:  535]:	loss/mlm_loss, 9.527749061584473, 334
[INFO] 2021-07-12 18:33:57,191 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.330000026835478e-06, 334
[INFO] 2021-07-12 18:33:57,191 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 334
[INFO] 2021-07-12 18:33:57,191 [run_pretraining.py:  558]:	worker_index: 6, step: 334, cost: 9.527749, mlm loss: 9.527749, speed: 1.079670 steps/s, speed: 8.637360 samples/s, speed: 4422.328135 tokens/s, learning rate: 3.330e-06, loss_scalings: 20971.521484, pp_loss: 9.334245
[INFO] 2021-07-12 18:33:57,191 [run_pretraining.py:  512]:	********exe.run_334******* 
[INFO] 2021-07-12 18:33:58,124 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:58,124 [run_pretraining.py:  534]:	loss/total_loss, 9.129846572875977, 335
[INFO] 2021-07-12 18:33:58,124 [run_pretraining.py:  535]:	loss/mlm_loss, 9.129846572875977, 335
[INFO] 2021-07-12 18:33:58,124 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.3399999210814713e-06, 335
[INFO] 2021-07-12 18:33:58,125 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 335
[INFO] 2021-07-12 18:33:58,125 [run_pretraining.py:  558]:	worker_index: 6, step: 335, cost: 9.129847, mlm loss: 9.129847, speed: 1.071720 steps/s, speed: 8.573761 samples/s, speed: 4389.765377 tokens/s, learning rate: 3.340e-06, loss_scalings: 20971.521484, pp_loss: 9.244049
[INFO] 2021-07-12 18:33:58,125 [run_pretraining.py:  512]:	********exe.run_335******* 
[INFO] 2021-07-12 18:33:59,048 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:59,049 [run_pretraining.py:  534]:	loss/total_loss, 9.240068435668945, 336
[INFO] 2021-07-12 18:33:59,049 [run_pretraining.py:  535]:	loss/mlm_loss, 9.240068435668945, 336
[INFO] 2021-07-12 18:33:59,049 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.35000004270114e-06, 336
[INFO] 2021-07-12 18:33:59,049 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 336
[INFO] 2021-07-12 18:33:59,049 [run_pretraining.py:  558]:	worker_index: 6, step: 336, cost: 9.240068, mlm loss: 9.240068, speed: 1.082197 steps/s, speed: 8.657575 samples/s, speed: 4432.678425 tokens/s, learning rate: 3.350e-06, loss_scalings: 20971.521484, pp_loss: 9.326706
[INFO] 2021-07-12 18:33:59,050 [run_pretraining.py:  512]:	********exe.run_336******* 
[INFO] 2021-07-12 18:33:59,970 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:59,971 [run_pretraining.py:  534]:	loss/total_loss, 9.43412971496582, 337
[INFO] 2021-07-12 18:33:59,971 [run_pretraining.py:  535]:	loss/mlm_loss, 9.43412971496582, 337
[INFO] 2021-07-12 18:33:59,971 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.359999709573458e-06, 337
[INFO] 2021-07-12 18:33:59,971 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 337
[INFO] 2021-07-12 18:33:59,971 [run_pretraining.py:  558]:	worker_index: 6, step: 337, cost: 9.434130, mlm loss: 9.434130, speed: 1.085590 steps/s, speed: 8.684718 samples/s, speed: 4446.575511 tokens/s, learning rate: 3.360e-06, loss_scalings: 20971.521484, pp_loss: 9.291407
[INFO] 2021-07-12 18:33:59,971 [run_pretraining.py:  512]:	********exe.run_337******* 
[INFO] 2021-07-12 18:34:00,895 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:00,896 [run_pretraining.py:  534]:	loss/total_loss, 9.42978572845459, 338
[INFO] 2021-07-12 18:34:00,896 [run_pretraining.py:  535]:	loss/mlm_loss, 9.42978572845459, 338
[INFO] 2021-07-12 18:34:00,896 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.370000058566802e-06, 338
[INFO] 2021-07-12 18:34:00,896 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 338
[INFO] 2021-07-12 18:34:00,896 [run_pretraining.py:  558]:	worker_index: 6, step: 338, cost: 9.429786, mlm loss: 9.429786, speed: 1.081832 steps/s, speed: 8.654659 samples/s, speed: 4431.185254 tokens/s, learning rate: 3.370e-06, loss_scalings: 20971.521484, pp_loss: 9.363930
[INFO] 2021-07-12 18:34:00,897 [run_pretraining.py:  512]:	********exe.run_338******* 
[INFO] 2021-07-12 18:34:01,816 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:01,817 [run_pretraining.py:  534]:	loss/total_loss, 9.414380073547363, 339
[INFO] 2021-07-12 18:34:01,817 [run_pretraining.py:  535]:	loss/mlm_loss, 9.414380073547363, 339
[INFO] 2021-07-12 18:34:01,817 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.37999972543912e-06, 339
[INFO] 2021-07-12 18:34:01,817 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 339
[INFO] 2021-07-12 18:34:01,817 [run_pretraining.py:  558]:	worker_index: 6, step: 339, cost: 9.414380, mlm loss: 9.414380, speed: 1.087004 steps/s, speed: 8.696030 samples/s, speed: 4452.367388 tokens/s, learning rate: 3.380e-06, loss_scalings: 20971.521484, pp_loss: 9.446461
[INFO] 2021-07-12 18:34:01,817 [run_pretraining.py:  512]:	********exe.run_339******* 
[INFO] 2021-07-12 18:34:02,751 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:02,752 [run_pretraining.py:  534]:	loss/total_loss, 9.261007308959961, 340
[INFO] 2021-07-12 18:34:02,752 [run_pretraining.py:  535]:	loss/mlm_loss, 9.261007308959961, 340
[INFO] 2021-07-12 18:34:02,752 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.389999847058789e-06, 340
[INFO] 2021-07-12 18:34:02,752 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 340
[INFO] 2021-07-12 18:34:02,752 [run_pretraining.py:  558]:	worker_index: 6, step: 340, cost: 9.261007, mlm loss: 9.261007, speed: 1.070129 steps/s, speed: 8.561034 samples/s, speed: 4383.249223 tokens/s, learning rate: 3.390e-06, loss_scalings: 20971.521484, pp_loss: 9.278280
[INFO] 2021-07-12 18:34:02,752 [run_pretraining.py:  512]:	********exe.run_340******* 
[INFO] 2021-07-12 18:34:03,668 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:03,669 [run_pretraining.py:  534]:	loss/total_loss, 7.396796703338623, 341
[INFO] 2021-07-12 18:34:03,669 [run_pretraining.py:  535]:	loss/mlm_loss, 7.396796703338623, 341
[INFO] 2021-07-12 18:34:03,669 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.400000196052133e-06, 341
[INFO] 2021-07-12 18:34:03,670 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 341
[INFO] 2021-07-12 18:34:03,670 [run_pretraining.py:  558]:	worker_index: 6, step: 341, cost: 7.396797, mlm loss: 7.396797, speed: 1.091089 steps/s, speed: 8.728711 samples/s, speed: 4469.100199 tokens/s, learning rate: 3.400e-06, loss_scalings: 20971.521484, pp_loss: 8.813184
[INFO] 2021-07-12 18:34:03,670 [run_pretraining.py:  512]:	********exe.run_341******* 
[INFO] 2021-07-12 18:34:04,595 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:04,595 [run_pretraining.py:  534]:	loss/total_loss, 10.213959693908691, 342
[INFO] 2021-07-12 18:34:04,595 [run_pretraining.py:  535]:	loss/mlm_loss, 10.213959693908691, 342
[INFO] 2021-07-12 18:34:04,595 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.409999862924451e-06, 342
[INFO] 2021-07-12 18:34:04,596 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 342
[INFO] 2021-07-12 18:34:04,596 [run_pretraining.py:  558]:	worker_index: 6, step: 342, cost: 10.213960, mlm loss: 10.213960, speed: 1.080715 steps/s, speed: 8.645716 samples/s, speed: 4426.606837 tokens/s, learning rate: 3.410e-06, loss_scalings: 20971.521484, pp_loss: 9.496666
[INFO] 2021-07-12 18:34:04,596 [run_pretraining.py:  512]:	********exe.run_342******* 
[INFO] 2021-07-12 18:34:30,477 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:30,478 [run_pretraining.py:  534]:	loss/total_loss, 9.447257041931152, 343
[INFO] 2021-07-12 18:34:30,478 [run_pretraining.py:  535]:	loss/mlm_loss, 9.447257041931152, 343
[INFO] 2021-07-12 18:34:30,478 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.41999998454412e-06, 343
[INFO] 2021-07-12 18:34:30,478 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 343
[INFO] 2021-07-12 18:34:30,478 [run_pretraining.py:  558]:	worker_index: 6, step: 343, cost: 9.447257, mlm loss: 9.447257, speed: 0.038637 steps/s, speed: 0.309098 samples/s, speed: 158.258073 tokens/s, learning rate: 3.420e-06, loss_scalings: 20971.521484, pp_loss: 9.325766
[INFO] 2021-07-12 18:34:30,478 [run_pretraining.py:  512]:	********exe.run_343******* 
[INFO] 2021-07-12 18:34:31,382 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:31,383 [run_pretraining.py:  534]:	loss/total_loss, 9.544008255004883, 344
[INFO] 2021-07-12 18:34:31,383 [run_pretraining.py:  535]:	loss/mlm_loss, 9.544008255004883, 344
[INFO] 2021-07-12 18:34:31,383 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.429999878790113e-06, 344
[INFO] 2021-07-12 18:34:31,383 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 344
[INFO] 2021-07-12 18:34:31,383 [run_pretraining.py:  558]:	worker_index: 6, step: 344, cost: 9.544008, mlm loss: 9.544008, speed: 1.105676 steps/s, speed: 8.845405 samples/s, speed: 4528.847153 tokens/s, learning rate: 3.430e-06, loss_scalings: 20971.521484, pp_loss: 9.338377
[INFO] 2021-07-12 18:34:31,384 [run_pretraining.py:  512]:	********exe.run_344******* 
[INFO] 2021-07-12 18:34:32,304 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:32,305 [run_pretraining.py:  534]:	loss/total_loss, 4.944112777709961, 345
[INFO] 2021-07-12 18:34:32,305 [run_pretraining.py:  535]:	loss/mlm_loss, 4.944112777709961, 345
[INFO] 2021-07-12 18:34:32,305 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.440000000409782e-06, 345
[INFO] 2021-07-12 18:34:32,305 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 345
[INFO] 2021-07-12 18:34:32,305 [run_pretraining.py:  558]:	worker_index: 6, step: 345, cost: 4.944113, mlm loss: 4.944113, speed: 1.085978 steps/s, speed: 8.687825 samples/s, speed: 4448.166602 tokens/s, learning rate: 3.440e-06, loss_scalings: 20971.521484, pp_loss: 8.206266
[INFO] 2021-07-12 18:34:32,305 [run_pretraining.py:  512]:	********exe.run_345******* 
[INFO] 2021-07-12 18:34:33,230 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:33,231 [run_pretraining.py:  534]:	loss/total_loss, 8.774698257446289, 346
[INFO] 2021-07-12 18:34:33,231 [run_pretraining.py:  535]:	loss/mlm_loss, 8.774698257446289, 346
[INFO] 2021-07-12 18:34:33,231 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.4499998946557753e-06, 346
[INFO] 2021-07-12 18:34:33,231 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 346
[INFO] 2021-07-12 18:34:33,231 [run_pretraining.py:  558]:	worker_index: 6, step: 346, cost: 8.774698, mlm loss: 8.774698, speed: 1.080750 steps/s, speed: 8.646002 samples/s, speed: 4426.752835 tokens/s, learning rate: 3.450e-06, loss_scalings: 20971.521484, pp_loss: 9.009647
[INFO] 2021-07-12 18:34:33,231 [run_pretraining.py:  512]:	********exe.run_346******* 
[INFO] 2021-07-12 18:34:34,153 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:34,153 [run_pretraining.py:  534]:	loss/total_loss, 9.236369132995605, 347
[INFO] 2021-07-12 18:34:34,153 [run_pretraining.py:  535]:	loss/mlm_loss, 9.236369132995605, 347
[INFO] 2021-07-12 18:34:34,153 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.460000016275444e-06, 347
[INFO] 2021-07-12 18:34:34,154 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 347
[INFO] 2021-07-12 18:34:34,154 [run_pretraining.py:  558]:	worker_index: 6, step: 347, cost: 9.236369, mlm loss: 9.236369, speed: 1.084732 steps/s, speed: 8.677858 samples/s, speed: 4443.063488 tokens/s, learning rate: 3.460e-06, loss_scalings: 20971.521484, pp_loss: 9.502473
[INFO] 2021-07-12 18:34:34,154 [run_pretraining.py:  512]:	********exe.run_347******* 
[INFO] 2021-07-12 18:34:35,071 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:35,072 [run_pretraining.py:  534]:	loss/total_loss, 9.292150497436523, 348
[INFO] 2021-07-12 18:34:35,072 [run_pretraining.py:  535]:	loss/mlm_loss, 9.292150497436523, 348
[INFO] 2021-07-12 18:34:35,072 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.469999683147762e-06, 348
[INFO] 2021-07-12 18:34:35,072 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 348
[INFO] 2021-07-12 18:34:35,072 [run_pretraining.py:  558]:	worker_index: 6, step: 348, cost: 9.292150, mlm loss: 9.292150, speed: 1.089792 steps/s, speed: 8.718340 samples/s, speed: 4463.790068 tokens/s, learning rate: 3.470e-06, loss_scalings: 20971.521484, pp_loss: 9.264397
[INFO] 2021-07-12 18:34:35,072 [run_pretraining.py:  512]:	********exe.run_348******* 
[INFO] 2021-07-12 18:34:35,993 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:35,994 [run_pretraining.py:  534]:	loss/total_loss, 6.171350479125977, 349
[INFO] 2021-07-12 18:34:35,994 [run_pretraining.py:  535]:	loss/mlm_loss, 6.171350479125977, 349
[INFO] 2021-07-12 18:34:35,994 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.480000032141106e-06, 349
[INFO] 2021-07-12 18:34:35,994 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 349
[INFO] 2021-07-12 18:34:35,994 [run_pretraining.py:  558]:	worker_index: 6, step: 349, cost: 6.171350, mlm loss: 6.171350, speed: 1.084850 steps/s, speed: 8.678799 samples/s, speed: 4443.544999 tokens/s, learning rate: 3.480e-06, loss_scalings: 20971.521484, pp_loss: 8.506347
[INFO] 2021-07-12 18:34:35,995 [run_pretraining.py:  512]:	********exe.run_349******* 
[INFO] 2021-07-12 18:34:36,911 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:36,912 [run_pretraining.py:  534]:	loss/total_loss, 9.193570137023926, 350
[INFO] 2021-07-12 18:34:36,912 [run_pretraining.py:  535]:	loss/mlm_loss, 9.193570137023926, 350
[INFO] 2021-07-12 18:34:36,912 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.489999699013424e-06, 350
[INFO] 2021-07-12 18:34:36,912 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 350
[INFO] 2021-07-12 18:34:36,912 [run_pretraining.py:  558]:	worker_index: 6, step: 350, cost: 9.193570, mlm loss: 9.193570, speed: 1.090771 steps/s, speed: 8.726167 samples/s, speed: 4467.797334 tokens/s, learning rate: 3.490e-06, loss_scalings: 20971.521484, pp_loss: 9.165112
[INFO] 2021-07-12 18:34:36,912 [run_pretraining.py:  512]:	********exe.run_350******* 
[INFO] 2021-07-12 18:34:37,838 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:37,839 [run_pretraining.py:  534]:	loss/total_loss, 8.650596618652344, 351
[INFO] 2021-07-12 18:34:37,839 [run_pretraining.py:  535]:	loss/mlm_loss, 8.650596618652344, 351
[INFO] 2021-07-12 18:34:37,839 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.499999820633093e-06, 351
[INFO] 2021-07-12 18:34:37,839 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 351
[INFO] 2021-07-12 18:34:37,839 [run_pretraining.py:  558]:	worker_index: 6, step: 351, cost: 8.650597, mlm loss: 8.650597, speed: 1.079525 steps/s, speed: 8.636199 samples/s, speed: 4421.733988 tokens/s, learning rate: 3.500e-06, loss_scalings: 20971.521484, pp_loss: 8.881818
[INFO] 2021-07-12 18:34:37,839 [run_pretraining.py:  512]:	********exe.run_351******* 
[INFO] 2021-07-12 18:34:38,765 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:38,766 [run_pretraining.py:  534]:	loss/total_loss, 9.17719554901123, 352
[INFO] 2021-07-12 18:34:38,766 [run_pretraining.py:  535]:	loss/mlm_loss, 9.17719554901123, 352
[INFO] 2021-07-12 18:34:38,766 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.510000169626437e-06, 352
[INFO] 2021-07-12 18:34:38,766 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 352
[INFO] 2021-07-12 18:34:38,766 [run_pretraining.py:  558]:	worker_index: 6, step: 352, cost: 9.177196, mlm loss: 9.177196, speed: 1.079400 steps/s, speed: 8.635197 samples/s, speed: 4421.220782 tokens/s, learning rate: 3.510e-06, loss_scalings: 20971.521484, pp_loss: 9.207512
[INFO] 2021-07-12 18:34:38,766 [run_pretraining.py:  512]:	********exe.run_352******* 
[INFO] 2021-07-12 18:34:39,690 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:39,691 [run_pretraining.py:  534]:	loss/total_loss, 9.320234298706055, 353
[INFO] 2021-07-12 18:34:39,691 [run_pretraining.py:  535]:	loss/mlm_loss, 9.320234298706055, 353
[INFO] 2021-07-12 18:34:39,691 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.519999836498755e-06, 353
[INFO] 2021-07-12 18:34:39,691 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 353
[INFO] 2021-07-12 18:34:39,691 [run_pretraining.py:  558]:	worker_index: 6, step: 353, cost: 9.320234, mlm loss: 9.320234, speed: 1.081770 steps/s, speed: 8.654161 samples/s, speed: 4430.930395 tokens/s, learning rate: 3.520e-06, loss_scalings: 20971.521484, pp_loss: 9.208070
[INFO] 2021-07-12 18:34:39,691 [run_pretraining.py:  512]:	********exe.run_353******* 
[INFO] 2021-07-12 18:34:40,620 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:40,621 [run_pretraining.py:  534]:	loss/total_loss, 9.416183471679688, 354
[INFO] 2021-07-12 18:34:40,621 [run_pretraining.py:  535]:	loss/mlm_loss, 9.416183471679688, 354
[INFO] 2021-07-12 18:34:40,621 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.529999958118424e-06, 354
[INFO] 2021-07-12 18:34:40,621 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 354
[INFO] 2021-07-12 18:34:40,621 [run_pretraining.py:  558]:	worker_index: 6, step: 354, cost: 9.416183, mlm loss: 9.416183, speed: 1.076362 steps/s, speed: 8.610894 samples/s, speed: 4408.777688 tokens/s, learning rate: 3.530e-06, loss_scalings: 20971.521484, pp_loss: 9.205139
[INFO] 2021-07-12 18:34:40,621 [run_pretraining.py:  512]:	********exe.run_354******* 
[INFO] 2021-07-12 18:34:41,538 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:41,538 [run_pretraining.py:  534]:	loss/total_loss, 9.164027214050293, 355
[INFO] 2021-07-12 18:34:41,539 [run_pretraining.py:  535]:	loss/mlm_loss, 9.164027214050293, 355
[INFO] 2021-07-12 18:34:41,539 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.539999852364417e-06, 355
[INFO] 2021-07-12 18:34:41,539 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 355
[INFO] 2021-07-12 18:34:41,539 [run_pretraining.py:  558]:	worker_index: 6, step: 355, cost: 9.164027, mlm loss: 9.164027, speed: 1.090566 steps/s, speed: 8.724529 samples/s, speed: 4466.958603 tokens/s, learning rate: 3.540e-06, loss_scalings: 16777.216797, pp_loss: 9.263360
[INFO] 2021-07-12 18:34:41,539 [run_pretraining.py:  512]:	********exe.run_355******* 
[INFO] 2021-07-12 18:34:42,505 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:42,506 [run_pretraining.py:  534]:	loss/total_loss, 9.320412635803223, 356
[INFO] 2021-07-12 18:34:42,506 [run_pretraining.py:  535]:	loss/mlm_loss, 9.320412635803223, 356
[INFO] 2021-07-12 18:34:42,506 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.549999973984086e-06, 356
[INFO] 2021-07-12 18:34:42,506 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 356
[INFO] 2021-07-12 18:34:42,506 [run_pretraining.py:  558]:	worker_index: 6, step: 356, cost: 9.320413, mlm loss: 9.320413, speed: 1.034721 steps/s, speed: 8.277769 samples/s, speed: 4238.217563 tokens/s, learning rate: 3.550e-06, loss_scalings: 16777.216797, pp_loss: 9.378117
[INFO] 2021-07-12 18:34:42,506 [run_pretraining.py:  512]:	********exe.run_356******* 
[INFO] 2021-07-12 18:34:43,435 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:43,435 [run_pretraining.py:  534]:	loss/total_loss, 9.10317611694336, 357
[INFO] 2021-07-12 18:34:43,435 [run_pretraining.py:  535]:	loss/mlm_loss, 9.10317611694336, 357
[INFO] 2021-07-12 18:34:43,436 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.5599998682300793e-06, 357
[INFO] 2021-07-12 18:34:43,436 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 357
[INFO] 2021-07-12 18:34:43,436 [run_pretraining.py:  558]:	worker_index: 6, step: 357, cost: 9.103176, mlm loss: 9.103176, speed: 1.076414 steps/s, speed: 8.611314 samples/s, speed: 4408.992664 tokens/s, learning rate: 3.560e-06, loss_scalings: 16777.216797, pp_loss: 9.156827
[INFO] 2021-07-12 18:34:43,436 [run_pretraining.py:  512]:	********exe.run_357******* 
[INFO] 2021-07-12 18:34:44,357 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:44,357 [run_pretraining.py:  534]:	loss/total_loss, 9.249493598937988, 358
[INFO] 2021-07-12 18:34:44,357 [run_pretraining.py:  535]:	loss/mlm_loss, 9.249493598937988, 358
[INFO] 2021-07-12 18:34:44,357 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.569999989849748e-06, 358
[INFO] 2021-07-12 18:34:44,357 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 358
[INFO] 2021-07-12 18:34:44,358 [run_pretraining.py:  558]:	worker_index: 6, step: 358, cost: 9.249494, mlm loss: 9.249494, speed: 1.085707 steps/s, speed: 8.685655 samples/s, speed: 4447.055482 tokens/s, learning rate: 3.570e-06, loss_scalings: 16777.216797, pp_loss: 9.164814
[INFO] 2021-07-12 18:34:44,358 [run_pretraining.py:  512]:	********exe.run_358******* 
[INFO] 2021-07-12 18:34:45,277 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:45,278 [run_pretraining.py:  534]:	loss/total_loss, 8.932666778564453, 359
[INFO] 2021-07-12 18:34:45,278 [run_pretraining.py:  535]:	loss/mlm_loss, 8.932666778564453, 359
[INFO] 2021-07-12 18:34:45,278 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.5799998840957414e-06, 359
[INFO] 2021-07-12 18:34:45,278 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 359
[INFO] 2021-07-12 18:34:45,278 [run_pretraining.py:  558]:	worker_index: 6, step: 359, cost: 8.932667, mlm loss: 8.932667, speed: 1.087313 steps/s, speed: 8.698503 samples/s, speed: 4453.633559 tokens/s, learning rate: 3.580e-06, loss_scalings: 16777.216797, pp_loss: 9.132257
[INFO] 2021-07-12 18:34:45,278 [run_pretraining.py:  512]:	********exe.run_359******* 
[INFO] 2021-07-12 18:34:46,202 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:46,203 [run_pretraining.py:  534]:	loss/total_loss, 9.422800064086914, 360
[INFO] 2021-07-12 18:34:46,203 [run_pretraining.py:  535]:	loss/mlm_loss, 9.422800064086914, 360
[INFO] 2021-07-12 18:34:46,203 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.5900000057154102e-06, 360
[INFO] 2021-07-12 18:34:46,203 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 360
[INFO] 2021-07-12 18:34:46,203 [run_pretraining.py:  558]:	worker_index: 6, step: 360, cost: 9.422800, mlm loss: 9.422800, speed: 1.081491 steps/s, speed: 8.651932 samples/s, speed: 4429.789033 tokens/s, learning rate: 3.590e-06, loss_scalings: 16777.216797, pp_loss: 9.282747
[INFO] 2021-07-12 18:34:46,203 [run_pretraining.py:  512]:	********exe.run_360******* 
[INFO] 2021-07-12 18:34:47,125 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:47,126 [run_pretraining.py:  534]:	loss/total_loss, 9.541688919067383, 361
[INFO] 2021-07-12 18:34:47,126 [run_pretraining.py:  535]:	loss/mlm_loss, 9.541688919067383, 361
[INFO] 2021-07-12 18:34:47,126 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.599999672587728e-06, 361
[INFO] 2021-07-12 18:34:47,126 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 361
[INFO] 2021-07-12 18:34:47,126 [run_pretraining.py:  558]:	worker_index: 6, step: 361, cost: 9.541689, mlm loss: 9.541689, speed: 1.084742 steps/s, speed: 8.677935 samples/s, speed: 4443.102557 tokens/s, learning rate: 3.600e-06, loss_scalings: 16777.216797, pp_loss: 8.373462
[INFO] 2021-07-12 18:34:47,126 [run_pretraining.py:  512]:	********exe.run_361******* 
[INFO] 2021-07-12 18:34:48,054 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:48,054 [run_pretraining.py:  534]:	loss/total_loss, 9.013609886169434, 362
[INFO] 2021-07-12 18:34:48,055 [run_pretraining.py:  535]:	loss/mlm_loss, 9.013609886169434, 362
[INFO] 2021-07-12 18:34:48,055 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.6100000215810724e-06, 362
[INFO] 2021-07-12 18:34:48,055 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 362
[INFO] 2021-07-12 18:34:48,055 [run_pretraining.py:  558]:	worker_index: 6, step: 362, cost: 9.013610, mlm loss: 9.013610, speed: 1.077414 steps/s, speed: 8.619313 samples/s, speed: 4413.088010 tokens/s, learning rate: 3.610e-06, loss_scalings: 16777.216797, pp_loss: 9.273884
[INFO] 2021-07-12 18:34:48,055 [run_pretraining.py:  512]:	********exe.run_362******* 
[INFO] 2021-07-12 18:34:48,969 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:48,969 [run_pretraining.py:  534]:	loss/total_loss, 9.104848861694336, 363
[INFO] 2021-07-12 18:34:48,969 [run_pretraining.py:  535]:	loss/mlm_loss, 9.104848861694336, 363
[INFO] 2021-07-12 18:34:48,970 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.620000143200741e-06, 363
[INFO] 2021-07-12 18:34:48,970 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 363
[INFO] 2021-07-12 18:34:48,970 [run_pretraining.py:  558]:	worker_index: 6, step: 363, cost: 9.104849, mlm loss: 9.104849, speed: 1.093973 steps/s, speed: 8.751787 samples/s, speed: 4480.915195 tokens/s, learning rate: 3.620e-06, loss_scalings: 16777.216797, pp_loss: 9.153974
[INFO] 2021-07-12 18:34:48,970 [run_pretraining.py:  512]:	********exe.run_363******* 
[INFO] 2021-07-12 18:34:49,894 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:49,895 [run_pretraining.py:  534]:	loss/total_loss, 9.575011253356934, 364
[INFO] 2021-07-12 18:34:49,895 [run_pretraining.py:  535]:	loss/mlm_loss, 9.575011253356934, 364
[INFO] 2021-07-12 18:34:49,895 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.629999810073059e-06, 364
[INFO] 2021-07-12 18:34:49,895 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 364
[INFO] 2021-07-12 18:34:49,895 [run_pretraining.py:  558]:	worker_index: 6, step: 364, cost: 9.575011, mlm loss: 9.575011, speed: 1.081063 steps/s, speed: 8.648504 samples/s, speed: 4428.034150 tokens/s, learning rate: 3.630e-06, loss_scalings: 16777.216797, pp_loss: 9.199264
[INFO] 2021-07-12 18:34:49,896 [run_pretraining.py:  512]:	********exe.run_364******* 
[INFO] 2021-07-12 18:34:50,819 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:50,820 [run_pretraining.py:  534]:	loss/total_loss, 9.41165542602539, 365
[INFO] 2021-07-12 18:34:50,820 [run_pretraining.py:  535]:	loss/mlm_loss, 9.41165542602539, 365
[INFO] 2021-07-12 18:34:50,820 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.6400001590664033e-06, 365
[INFO] 2021-07-12 18:34:50,820 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 365
[INFO] 2021-07-12 18:34:50,820 [run_pretraining.py:  558]:	worker_index: 6, step: 365, cost: 9.411655, mlm loss: 9.411655, speed: 1.082612 steps/s, speed: 8.660894 samples/s, speed: 4434.377472 tokens/s, learning rate: 3.640e-06, loss_scalings: 16777.216797, pp_loss: 9.360796
[INFO] 2021-07-12 18:34:50,820 [run_pretraining.py:  512]:	********exe.run_365******* 
[INFO] 2021-07-12 18:34:51,744 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:51,744 [run_pretraining.py:  534]:	loss/total_loss, 9.303267478942871, 366
[INFO] 2021-07-12 18:34:51,745 [run_pretraining.py:  535]:	loss/mlm_loss, 9.303267478942871, 366
[INFO] 2021-07-12 18:34:51,745 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.649999825938721e-06, 366
[INFO] 2021-07-12 18:34:51,745 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 366
[INFO] 2021-07-12 18:34:51,745 [run_pretraining.py:  558]:	worker_index: 6, step: 366, cost: 9.303267, mlm loss: 9.303267, speed: 1.081978 steps/s, speed: 8.655826 samples/s, speed: 4431.783088 tokens/s, learning rate: 3.650e-06, loss_scalings: 16777.216797, pp_loss: 9.158742
[INFO] 2021-07-12 18:34:51,745 [run_pretraining.py:  512]:	********exe.run_366******* 
[INFO] 2021-07-12 18:34:52,679 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:52,680 [run_pretraining.py:  534]:	loss/total_loss, 9.139266967773438, 367
[INFO] 2021-07-12 18:34:52,680 [run_pretraining.py:  535]:	loss/mlm_loss, 9.139266967773438, 367
[INFO] 2021-07-12 18:34:52,680 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.65999994755839e-06, 367
[INFO] 2021-07-12 18:34:52,680 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 367
[INFO] 2021-07-12 18:34:52,680 [run_pretraining.py:  558]:	worker_index: 6, step: 367, cost: 9.139267, mlm loss: 9.139267, speed: 1.069921 steps/s, speed: 8.559372 samples/s, speed: 4382.398334 tokens/s, learning rate: 3.660e-06, loss_scalings: 16777.216797, pp_loss: 9.244398
[INFO] 2021-07-12 18:34:52,680 [run_pretraining.py:  512]:	********exe.run_367******* 
[INFO] 2021-07-12 18:34:53,604 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:53,605 [run_pretraining.py:  534]:	loss/total_loss, 9.208105087280273, 368
[INFO] 2021-07-12 18:34:53,605 [run_pretraining.py:  535]:	loss/mlm_loss, 9.208105087280273, 368
[INFO] 2021-07-12 18:34:53,605 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.6699998418043833e-06, 368
[INFO] 2021-07-12 18:34:53,605 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 368
[INFO] 2021-07-12 18:34:53,605 [run_pretraining.py:  558]:	worker_index: 6, step: 368, cost: 9.208105, mlm loss: 9.208105, speed: 1.081910 steps/s, speed: 8.655284 samples/s, speed: 4431.505298 tokens/s, learning rate: 3.670e-06, loss_scalings: 16777.216797, pp_loss: 9.159214
[INFO] 2021-07-12 18:34:53,605 [run_pretraining.py:  512]:	********exe.run_368******* 
[INFO] 2021-07-12 18:35:19,223 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:19,224 [run_pretraining.py:  534]:	loss/total_loss, 9.547568321228027, 369
[INFO] 2021-07-12 18:35:19,224 [run_pretraining.py:  535]:	loss/mlm_loss, 9.547568321228027, 369
[INFO] 2021-07-12 18:35:19,224 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.679999963424052e-06, 369
[INFO] 2021-07-12 18:35:19,224 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 369
[INFO] 2021-07-12 18:35:19,224 [run_pretraining.py:  558]:	worker_index: 6, step: 369, cost: 9.547568, mlm loss: 9.547568, speed: 0.039035 steps/s, speed: 0.312279 samples/s, speed: 159.887028 tokens/s, learning rate: 3.680e-06, loss_scalings: 16777.216797, pp_loss: 9.141828
[INFO] 2021-07-12 18:35:19,224 [run_pretraining.py:  512]:	********exe.run_369******* 
[INFO] 2021-07-12 18:35:20,161 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:20,162 [run_pretraining.py:  534]:	loss/total_loss, 9.534072875976562, 370
[INFO] 2021-07-12 18:35:20,162 [run_pretraining.py:  535]:	loss/mlm_loss, 9.534072875976562, 370
[INFO] 2021-07-12 18:35:20,162 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.6899998576700455e-06, 370
[INFO] 2021-07-12 18:35:20,162 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 370
[INFO] 2021-07-12 18:35:20,162 [run_pretraining.py:  558]:	worker_index: 6, step: 370, cost: 9.534073, mlm loss: 9.534073, speed: 1.066933 steps/s, speed: 8.535463 samples/s, speed: 4370.156939 tokens/s, learning rate: 3.690e-06, loss_scalings: 16777.216797, pp_loss: 9.446051
[INFO] 2021-07-12 18:35:20,162 [run_pretraining.py:  512]:	********exe.run_370******* 
[INFO] 2021-07-12 18:35:21,083 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:21,084 [run_pretraining.py:  534]:	loss/total_loss, 9.349383354187012, 371
[INFO] 2021-07-12 18:35:21,084 [run_pretraining.py:  535]:	loss/mlm_loss, 9.349383354187012, 371
[INFO] 2021-07-12 18:35:21,084 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.6999999792897142e-06, 371
[INFO] 2021-07-12 18:35:21,084 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 371
[INFO] 2021-07-12 18:35:21,084 [run_pretraining.py:  558]:	worker_index: 6, step: 371, cost: 9.349383, mlm loss: 9.349383, speed: 1.085539 steps/s, speed: 8.684309 samples/s, speed: 4446.366060 tokens/s, learning rate: 3.700e-06, loss_scalings: 16777.216797, pp_loss: 8.786431
[INFO] 2021-07-12 18:35:21,084 [run_pretraining.py:  512]:	********exe.run_371******* 
[INFO] 2021-07-12 18:35:22,015 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:22,016 [run_pretraining.py:  534]:	loss/total_loss, 8.965421676635742, 372
[INFO] 2021-07-12 18:35:22,017 [run_pretraining.py:  535]:	loss/mlm_loss, 8.965421676635742, 372
[INFO] 2021-07-12 18:35:22,018 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.709999646162032e-06, 372
[INFO] 2021-07-12 18:35:22,019 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 372
[INFO] 2021-07-12 18:35:22,020 [run_pretraining.py:  558]:	worker_index: 6, step: 372, cost: 8.965422, mlm loss: 8.965422, speed: 1.073721 steps/s, speed: 8.589770 samples/s, speed: 4397.962070 tokens/s, learning rate: 3.710e-06, loss_scalings: 16777.216797, pp_loss: 9.276009
[INFO] 2021-07-12 18:35:22,023 [run_pretraining.py:  512]:	********exe.run_372******* 
[INFO] 2021-07-12 18:35:22,921 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:22,921 [run_pretraining.py:  534]:	loss/total_loss, 9.364921569824219, 373
[INFO] 2021-07-12 18:35:22,921 [run_pretraining.py:  535]:	loss/mlm_loss, 9.364921569824219, 373
[INFO] 2021-07-12 18:35:22,921 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.7199999951553764e-06, 373
[INFO] 2021-07-12 18:35:22,921 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 373
[INFO] 2021-07-12 18:35:22,922 [run_pretraining.py:  558]:	worker_index: 6, step: 373, cost: 9.364922, mlm loss: 9.364922, speed: 1.113909 steps/s, speed: 8.911274 samples/s, speed: 4562.572435 tokens/s, learning rate: 3.720e-06, loss_scalings: 16777.216797, pp_loss: 9.165626
[INFO] 2021-07-12 18:35:22,922 [run_pretraining.py:  512]:	********exe.run_373******* 
[INFO] 2021-07-12 18:35:23,847 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:23,848 [run_pretraining.py:  534]:	loss/total_loss, 9.181611061096191, 374
[INFO] 2021-07-12 18:35:23,848 [run_pretraining.py:  535]:	loss/mlm_loss, 9.181611061096191, 374
[INFO] 2021-07-12 18:35:23,848 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.730000116775045e-06, 374
[INFO] 2021-07-12 18:35:23,848 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 374
[INFO] 2021-07-12 18:35:23,848 [run_pretraining.py:  558]:	worker_index: 6, step: 374, cost: 9.181611, mlm loss: 9.181611, speed: 1.079717 steps/s, speed: 8.637735 samples/s, speed: 4422.520527 tokens/s, learning rate: 3.730e-06, loss_scalings: 13421.773438, pp_loss: 9.116473
[INFO] 2021-07-12 18:35:23,848 [run_pretraining.py:  512]:	********exe.run_374******* 
[INFO] 2021-07-12 18:35:24,762 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:24,762 [run_pretraining.py:  534]:	loss/total_loss, 9.018655776977539, 375
[INFO] 2021-07-12 18:35:24,763 [run_pretraining.py:  535]:	loss/mlm_loss, 9.018655776977539, 375
[INFO] 2021-07-12 18:35:24,763 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.739999783647363e-06, 375
[INFO] 2021-07-12 18:35:24,763 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 375
[INFO] 2021-07-12 18:35:24,763 [run_pretraining.py:  558]:	worker_index: 6, step: 375, cost: 9.018656, mlm loss: 9.018656, speed: 1.094463 steps/s, speed: 8.755702 samples/s, speed: 4482.919291 tokens/s, learning rate: 3.740e-06, loss_scalings: 13421.773438, pp_loss: 9.123690
[INFO] 2021-07-12 18:35:24,763 [run_pretraining.py:  512]:	********exe.run_375******* 
[INFO] 2021-07-12 18:35:25,699 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:25,699 [run_pretraining.py:  534]:	loss/total_loss, 9.433696746826172, 376
[INFO] 2021-07-12 18:35:25,700 [run_pretraining.py:  535]:	loss/mlm_loss, 9.433696746826172, 376
[INFO] 2021-07-12 18:35:25,700 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.7500001326407073e-06, 376
[INFO] 2021-07-12 18:35:25,700 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 376
[INFO] 2021-07-12 18:35:25,700 [run_pretraining.py:  558]:	worker_index: 6, step: 376, cost: 9.433697, mlm loss: 9.433697, speed: 1.068116 steps/s, speed: 8.544931 samples/s, speed: 4375.004726 tokens/s, learning rate: 3.750e-06, loss_scalings: 13421.773438, pp_loss: 9.239214
[INFO] 2021-07-12 18:35:25,700 [run_pretraining.py:  512]:	********exe.run_376******* 
[INFO] 2021-07-12 18:35:26,618 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:26,619 [run_pretraining.py:  534]:	loss/total_loss, 9.092795372009277, 377
[INFO] 2021-07-12 18:35:26,619 [run_pretraining.py:  535]:	loss/mlm_loss, 9.092795372009277, 377
[INFO] 2021-07-12 18:35:26,619 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.759999799513025e-06, 377
[INFO] 2021-07-12 18:35:26,619 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 377
[INFO] 2021-07-12 18:35:26,619 [run_pretraining.py:  558]:	worker_index: 6, step: 377, cost: 9.092795, mlm loss: 9.092795, speed: 1.088277 steps/s, speed: 8.706215 samples/s, speed: 4457.582121 tokens/s, learning rate: 3.760e-06, loss_scalings: 13421.773438, pp_loss: 9.080452
[INFO] 2021-07-12 18:35:26,620 [run_pretraining.py:  512]:	********exe.run_377******* 
[INFO] 2021-07-12 18:35:53,336 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:53,336 [run_pretraining.py:  534]:	loss/total_loss, 9.499676704406738, 378
[INFO] 2021-07-12 18:35:53,336 [run_pretraining.py:  535]:	loss/mlm_loss, 9.499676704406738, 378
[INFO] 2021-07-12 18:35:53,336 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.769999921132694e-06, 378
[INFO] 2021-07-12 18:35:53,336 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 378
[INFO] 2021-07-12 18:35:53,337 [run_pretraining.py:  558]:	worker_index: 6, step: 378, cost: 9.499677, mlm loss: 9.499677, speed: 0.037430 steps/s, speed: 0.299441 samples/s, speed: 153.314038 tokens/s, learning rate: 3.770e-06, loss_scalings: 13421.773438, pp_loss: 9.303439
[INFO] 2021-07-12 18:35:53,337 [run_pretraining.py:  512]:	********exe.run_378******* 
[INFO] 2021-07-12 18:35:54,249 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:54,249 [run_pretraining.py:  534]:	loss/total_loss, 9.166701316833496, 379
[INFO] 2021-07-12 18:35:54,249 [run_pretraining.py:  535]:	loss/mlm_loss, 9.166701316833496, 379
[INFO] 2021-07-12 18:35:54,249 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.7799998153786873e-06, 379
[INFO] 2021-07-12 18:35:54,249 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 379
[INFO] 2021-07-12 18:35:54,250 [run_pretraining.py:  558]:	worker_index: 6, step: 379, cost: 9.166701, mlm loss: 9.166701, speed: 1.096175 steps/s, speed: 8.769399 samples/s, speed: 4489.932513 tokens/s, learning rate: 3.780e-06, loss_scalings: 13421.773438, pp_loss: 9.179623
[INFO] 2021-07-12 18:35:54,250 [run_pretraining.py:  512]:	********exe.run_379******* 
[INFO] 2021-07-12 18:35:55,173 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:55,173 [run_pretraining.py:  534]:	loss/total_loss, 9.468944549560547, 380
[INFO] 2021-07-12 18:35:55,173 [run_pretraining.py:  535]:	loss/mlm_loss, 9.468944549560547, 380
[INFO] 2021-07-12 18:35:55,173 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.789999936998356e-06, 380
[INFO] 2021-07-12 18:35:55,174 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 380
[INFO] 2021-07-12 18:35:55,174 [run_pretraining.py:  558]:	worker_index: 6, step: 380, cost: 9.468945, mlm loss: 9.468945, speed: 1.083056 steps/s, speed: 8.664449 samples/s, speed: 4436.198099 tokens/s, learning rate: 3.790e-06, loss_scalings: 13421.773438, pp_loss: 9.351370
[INFO] 2021-07-12 18:35:55,174 [run_pretraining.py:  512]:	********exe.run_380******* 
[INFO] 2021-07-12 18:35:56,086 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:56,086 [run_pretraining.py:  534]:	loss/total_loss, 9.04934024810791, 381
[INFO] 2021-07-12 18:35:56,086 [run_pretraining.py:  535]:	loss/mlm_loss, 9.04934024810791, 381
[INFO] 2021-07-12 18:35:56,086 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.7999998312443495e-06, 381
[INFO] 2021-07-12 18:35:56,087 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 381
[INFO] 2021-07-12 18:35:56,087 [run_pretraining.py:  558]:	worker_index: 6, step: 381, cost: 9.049340, mlm loss: 9.049340, speed: 1.096046 steps/s, speed: 8.768371 samples/s, speed: 4489.405702 tokens/s, learning rate: 3.800e-06, loss_scalings: 13421.773438, pp_loss: 9.235055
[INFO] 2021-07-12 18:35:56,087 [run_pretraining.py:  512]:	********exe.run_381******* 
[INFO] 2021-07-12 18:35:57,149 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:57,149 [run_pretraining.py:  534]:	loss/total_loss, 9.183073997497559, 382
[INFO] 2021-07-12 18:35:57,149 [run_pretraining.py:  535]:	loss/mlm_loss, 9.183073997497559, 382
[INFO] 2021-07-12 18:35:57,149 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.8099999528640183e-06, 382
[INFO] 2021-07-12 18:35:57,150 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 382
[INFO] 2021-07-12 18:35:57,150 [run_pretraining.py:  558]:	worker_index: 6, step: 382, cost: 9.183074, mlm loss: 9.183074, speed: 0.941403 steps/s, speed: 7.531227 samples/s, speed: 3855.988113 tokens/s, learning rate: 3.810e-06, loss_scalings: 13421.773438, pp_loss: 9.108402
[INFO] 2021-07-12 18:35:57,150 [run_pretraining.py:  512]:	********exe.run_382******* 
[INFO] 2021-07-12 18:35:58,057 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:58,057 [run_pretraining.py:  534]:	loss/total_loss, 9.00536060333252, 383
[INFO] 2021-07-12 18:35:58,057 [run_pretraining.py:  535]:	loss/mlm_loss, 9.00536060333252, 383
[INFO] 2021-07-12 18:35:58,057 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.819999619736336e-06, 383
[INFO] 2021-07-12 18:35:58,057 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 383
[INFO] 2021-07-12 18:35:58,058 [run_pretraining.py:  558]:	worker_index: 6, step: 383, cost: 9.005361, mlm loss: 9.005361, speed: 1.102341 steps/s, speed: 8.818726 samples/s, speed: 4515.187673 tokens/s, learning rate: 3.820e-06, loss_scalings: 13421.773438, pp_loss: 9.155375
[INFO] 2021-07-12 18:35:58,058 [run_pretraining.py:  512]:	********exe.run_383******* 
[INFO] 2021-07-12 18:35:58,963 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:58,963 [run_pretraining.py:  534]:	loss/total_loss, 8.897007942199707, 384
[INFO] 2021-07-12 18:35:58,964 [run_pretraining.py:  535]:	loss/mlm_loss, 8.897007942199707, 384
[INFO] 2021-07-12 18:35:58,964 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.82999996872968e-06, 384
[INFO] 2021-07-12 18:35:58,964 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 384
[INFO] 2021-07-12 18:35:58,964 [run_pretraining.py:  558]:	worker_index: 6, step: 384, cost: 8.897008, mlm loss: 8.897008, speed: 1.104216 steps/s, speed: 8.833726 samples/s, speed: 4522.867821 tokens/s, learning rate: 3.830e-06, loss_scalings: 13421.773438, pp_loss: 9.171490
[INFO] 2021-07-12 18:35:58,964 [run_pretraining.py:  512]:	********exe.run_384******* 
[INFO] 2021-07-12 18:35:59,865 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:59,866 [run_pretraining.py:  534]:	loss/total_loss, 9.275557518005371, 385
[INFO] 2021-07-12 18:35:59,866 [run_pretraining.py:  535]:	loss/mlm_loss, 9.275557518005371, 385
[INFO] 2021-07-12 18:35:59,866 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.839999862975674e-06, 385
[INFO] 2021-07-12 18:35:59,866 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 385
[INFO] 2021-07-12 18:35:59,866 [run_pretraining.py:  558]:	worker_index: 6, step: 385, cost: 9.275558, mlm loss: 9.275558, speed: 1.109354 steps/s, speed: 8.874831 samples/s, speed: 4543.913552 tokens/s, learning rate: 3.840e-06, loss_scalings: 13421.773438, pp_loss: 9.159966
[INFO] 2021-07-12 18:35:59,866 [run_pretraining.py:  512]:	********exe.run_385******* 
[INFO] 2021-07-12 18:36:25,771 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:25,771 [run_pretraining.py:  534]:	loss/total_loss, 9.095179557800293, 386
[INFO] 2021-07-12 18:36:25,771 [run_pretraining.py:  535]:	loss/mlm_loss, 9.095179557800293, 386
[INFO] 2021-07-12 18:36:25,772 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.849999757221667e-06, 386
[INFO] 2021-07-12 18:36:25,772 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 386
[INFO] 2021-07-12 18:36:25,772 [run_pretraining.py:  558]:	worker_index: 6, step: 386, cost: 9.095180, mlm loss: 9.095180, speed: 0.038603 steps/s, speed: 0.308822 samples/s, speed: 158.116775 tokens/s, learning rate: 3.850e-06, loss_scalings: 13421.773438, pp_loss: 9.054852
[INFO] 2021-07-12 18:36:25,772 [run_pretraining.py:  512]:	********exe.run_386******* 
[INFO] 2021-07-12 18:36:26,659 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:26,660 [run_pretraining.py:  534]:	loss/total_loss, 9.430212020874023, 387
[INFO] 2021-07-12 18:36:26,660 [run_pretraining.py:  535]:	loss/mlm_loss, 9.430212020874023, 387
[INFO] 2021-07-12 18:36:26,660 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.860000106215011e-06, 387
[INFO] 2021-07-12 18:36:26,660 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 387
[INFO] 2021-07-12 18:36:26,660 [run_pretraining.py:  558]:	worker_index: 6, step: 387, cost: 9.430212, mlm loss: 9.430212, speed: 1.126286 steps/s, speed: 9.010289 samples/s, speed: 4613.267780 tokens/s, learning rate: 3.860e-06, loss_scalings: 13421.773438, pp_loss: 9.388757
[INFO] 2021-07-12 18:36:26,661 [run_pretraining.py:  512]:	********exe.run_387******* 
[INFO] 2021-07-12 18:36:27,569 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:27,570 [run_pretraining.py:  534]:	loss/total_loss, 9.241043090820312, 388
[INFO] 2021-07-12 18:36:27,570 [run_pretraining.py:  535]:	loss/mlm_loss, 9.241043090820312, 388
[INFO] 2021-07-12 18:36:27,570 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.870000000461005e-06, 388
[INFO] 2021-07-12 18:36:27,570 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 388
[INFO] 2021-07-12 18:36:27,570 [run_pretraining.py:  558]:	worker_index: 6, step: 388, cost: 9.241043, mlm loss: 9.241043, speed: 1.100330 steps/s, speed: 8.802638 samples/s, speed: 4506.950590 tokens/s, learning rate: 3.870e-06, loss_scalings: 13421.773438, pp_loss: 9.297558
[INFO] 2021-07-12 18:36:27,570 [run_pretraining.py:  512]:	********exe.run_388******* 
[INFO] 2021-07-12 18:36:28,486 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:28,486 [run_pretraining.py:  534]:	loss/total_loss, 9.305937767028809, 389
[INFO] 2021-07-12 18:36:28,487 [run_pretraining.py:  535]:	loss/mlm_loss, 9.305937767028809, 389
[INFO] 2021-07-12 18:36:28,487 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.879999894706998e-06, 389
[INFO] 2021-07-12 18:36:28,487 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 389
[INFO] 2021-07-12 18:36:28,487 [run_pretraining.py:  558]:	worker_index: 6, step: 389, cost: 9.305938, mlm loss: 9.305938, speed: 1.091455 steps/s, speed: 8.731641 samples/s, speed: 4470.600422 tokens/s, learning rate: 3.880e-06, loss_scalings: 13421.773438, pp_loss: 9.136903
[INFO] 2021-07-12 18:36:28,487 [run_pretraining.py:  512]:	********exe.run_389******* 
[INFO] 2021-07-12 18:36:29,404 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:29,405 [run_pretraining.py:  534]:	loss/total_loss, 9.371837615966797, 390
[INFO] 2021-07-12 18:36:29,405 [run_pretraining.py:  535]:	loss/mlm_loss, 9.371837615966797, 390
[INFO] 2021-07-12 18:36:29,405 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.889999788952991e-06, 390
[INFO] 2021-07-12 18:36:29,405 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 390
[INFO] 2021-07-12 18:36:29,405 [run_pretraining.py:  558]:	worker_index: 6, step: 390, cost: 9.371838, mlm loss: 9.371838, speed: 1.089952 steps/s, speed: 8.719616 samples/s, speed: 4464.443138 tokens/s, learning rate: 3.890e-06, loss_scalings: 13421.773438, pp_loss: 9.238453
[INFO] 2021-07-12 18:36:29,405 [run_pretraining.py:  512]:	********exe.run_390******* 
[INFO] 2021-07-12 18:36:30,307 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:30,308 [run_pretraining.py:  534]:	loss/total_loss, 9.483240127563477, 391
[INFO] 2021-07-12 18:36:30,308 [run_pretraining.py:  535]:	loss/mlm_loss, 9.483240127563477, 391
[INFO] 2021-07-12 18:36:30,308 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.900000137946336e-06, 391
[INFO] 2021-07-12 18:36:30,308 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 391
[INFO] 2021-07-12 18:36:30,308 [run_pretraining.py:  558]:	worker_index: 6, step: 391, cost: 9.483240, mlm loss: 9.483240, speed: 1.108033 steps/s, speed: 8.864262 samples/s, speed: 4538.502189 tokens/s, learning rate: 3.900e-06, loss_scalings: 13421.773438, pp_loss: 9.297041
[INFO] 2021-07-12 18:36:30,308 [run_pretraining.py:  512]:	********exe.run_391******* 
[INFO] 2021-07-12 18:36:31,226 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:31,227 [run_pretraining.py:  534]:	loss/total_loss, 9.230964660644531, 392
[INFO] 2021-07-12 18:36:31,227 [run_pretraining.py:  535]:	loss/mlm_loss, 9.230964660644531, 392
[INFO] 2021-07-12 18:36:31,227 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.909999577444978e-06, 392
[INFO] 2021-07-12 18:36:31,227 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 392
[INFO] 2021-07-12 18:36:31,227 [run_pretraining.py:  558]:	worker_index: 6, step: 392, cost: 9.230965, mlm loss: 9.230965, speed: 1.088801 steps/s, speed: 8.710405 samples/s, speed: 4459.727468 tokens/s, learning rate: 3.910e-06, loss_scalings: 13421.773438, pp_loss: 9.296149
[INFO] 2021-07-12 18:36:31,228 [run_pretraining.py:  512]:	********exe.run_392******* 
[INFO] 2021-07-12 18:36:32,134 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:32,134 [run_pretraining.py:  534]:	loss/total_loss, 9.443697929382324, 393
[INFO] 2021-07-12 18:36:32,134 [run_pretraining.py:  535]:	loss/mlm_loss, 9.443697929382324, 393
[INFO] 2021-07-12 18:36:32,134 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.919999926438322e-06, 393
[INFO] 2021-07-12 18:36:32,134 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 393
[INFO] 2021-07-12 18:36:32,135 [run_pretraining.py:  558]:	worker_index: 6, step: 393, cost: 9.443698, mlm loss: 9.443698, speed: 1.103307 steps/s, speed: 8.826460 samples/s, speed: 4519.147517 tokens/s, learning rate: 3.920e-06, loss_scalings: 13421.773438, pp_loss: 9.216659
[INFO] 2021-07-12 18:36:32,135 [run_pretraining.py:  512]:	********exe.run_393******* 
[INFO] 2021-07-12 18:36:33,047 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:33,047 [run_pretraining.py:  534]:	loss/total_loss, 9.216629981994629, 394
[INFO] 2021-07-12 18:36:33,048 [run_pretraining.py:  535]:	loss/mlm_loss, 9.216629981994629, 394
[INFO] 2021-07-12 18:36:33,048 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.929999820684316e-06, 394
[INFO] 2021-07-12 18:36:33,048 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 394
[INFO] 2021-07-12 18:36:33,048 [run_pretraining.py:  558]:	worker_index: 6, step: 394, cost: 9.216630, mlm loss: 9.216630, speed: 1.095813 steps/s, speed: 8.766503 samples/s, speed: 4488.449778 tokens/s, learning rate: 3.930e-06, loss_scalings: 13421.773438, pp_loss: 9.299518
[INFO] 2021-07-12 18:36:33,048 [run_pretraining.py:  512]:	********exe.run_394******* 
[INFO] 2021-07-12 18:36:33,957 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:33,958 [run_pretraining.py:  534]:	loss/total_loss, 8.052852630615234, 395
[INFO] 2021-07-12 18:36:33,958 [run_pretraining.py:  535]:	loss/mlm_loss, 8.052852630615234, 395
[INFO] 2021-07-12 18:36:33,958 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.939999714930309e-06, 395
[INFO] 2021-07-12 18:36:33,958 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 395
[INFO] 2021-07-12 18:36:33,958 [run_pretraining.py:  558]:	worker_index: 6, step: 395, cost: 8.052853, mlm loss: 8.052853, speed: 1.099544 steps/s, speed: 8.796354 samples/s, speed: 4503.733352 tokens/s, learning rate: 3.940e-06, loss_scalings: 13421.773438, pp_loss: 9.195020
[INFO] 2021-07-12 18:36:33,958 [run_pretraining.py:  512]:	********exe.run_395******* 
[INFO] 2021-07-12 18:36:34,866 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:34,867 [run_pretraining.py:  534]:	loss/total_loss, 9.431427001953125, 396
[INFO] 2021-07-12 18:36:34,867 [run_pretraining.py:  535]:	loss/mlm_loss, 9.431427001953125, 396
[INFO] 2021-07-12 18:36:34,867 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.950000063923653e-06, 396
[INFO] 2021-07-12 18:36:34,867 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 396
[INFO] 2021-07-12 18:36:34,867 [run_pretraining.py:  558]:	worker_index: 6, step: 396, cost: 9.431427, mlm loss: 9.431427, speed: 1.100817 steps/s, speed: 8.806538 samples/s, speed: 4508.947280 tokens/s, learning rate: 3.950e-06, loss_scalings: 13421.773438, pp_loss: 9.184604
[INFO] 2021-07-12 18:36:34,867 [run_pretraining.py:  512]:	********exe.run_396******* 
[INFO] 2021-07-12 18:36:35,775 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:35,775 [run_pretraining.py:  534]:	loss/total_loss, 9.355173110961914, 397
[INFO] 2021-07-12 18:36:35,775 [run_pretraining.py:  535]:	loss/mlm_loss, 9.355173110961914, 397
[INFO] 2021-07-12 18:36:35,776 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.9599999581696466e-06, 397
[INFO] 2021-07-12 18:36:35,776 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 397
[INFO] 2021-07-12 18:36:35,776 [run_pretraining.py:  558]:	worker_index: 6, step: 397, cost: 9.355173, mlm loss: 9.355173, speed: 1.101781 steps/s, speed: 8.814250 samples/s, speed: 4512.896181 tokens/s, learning rate: 3.960e-06, loss_scalings: 13421.773438, pp_loss: 9.260185
[INFO] 2021-07-12 18:36:35,776 [run_pretraining.py:  512]:	********exe.run_397******* 
[INFO] 2021-07-12 18:36:36,687 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:36,687 [run_pretraining.py:  534]:	loss/total_loss, 9.43498706817627, 398
[INFO] 2021-07-12 18:36:36,687 [run_pretraining.py:  535]:	loss/mlm_loss, 9.43498706817627, 398
[INFO] 2021-07-12 18:36:36,688 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.96999985241564e-06, 398
[INFO] 2021-07-12 18:36:36,688 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 398
[INFO] 2021-07-12 18:36:36,688 [run_pretraining.py:  558]:	worker_index: 6, step: 398, cost: 9.434987, mlm loss: 9.434987, speed: 1.097315 steps/s, speed: 8.778521 samples/s, speed: 4494.602952 tokens/s, learning rate: 3.970e-06, loss_scalings: 13421.773438, pp_loss: 9.290691
[INFO] 2021-07-12 18:36:36,688 [run_pretraining.py:  512]:	********exe.run_398******* 
[INFO] 2021-07-12 18:36:37,595 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:37,596 [run_pretraining.py:  534]:	loss/total_loss, 9.090126037597656, 399
[INFO] 2021-07-12 18:36:37,596 [run_pretraining.py:  535]:	loss/mlm_loss, 9.090126037597656, 399
[INFO] 2021-07-12 18:36:37,596 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.979999746661633e-06, 399
[INFO] 2021-07-12 18:36:37,596 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 399
[INFO] 2021-07-12 18:36:37,596 [run_pretraining.py:  558]:	worker_index: 6, step: 399, cost: 9.090126, mlm loss: 9.090126, speed: 1.101633 steps/s, speed: 8.813060 samples/s, speed: 4512.286931 tokens/s, learning rate: 3.980e-06, loss_scalings: 13421.773438, pp_loss: 9.147232
[INFO] 2021-07-12 18:36:37,596 [run_pretraining.py:  512]:	********exe.run_399******* 
[INFO] 2021-07-12 18:36:38,508 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:38,509 [run_pretraining.py:  534]:	loss/total_loss, 8.73001480102539, 400
[INFO] 2021-07-12 18:36:38,509 [run_pretraining.py:  535]:	loss/mlm_loss, 8.73001480102539, 400
[INFO] 2021-07-12 18:36:38,509 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.9900000956549775e-06, 400
[INFO] 2021-07-12 18:36:38,509 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 400
[INFO] 2021-07-12 18:36:38,509 [run_pretraining.py:  558]:	worker_index: 6, step: 400, cost: 8.730015, mlm loss: 8.730015, speed: 1.096409 steps/s, speed: 8.771272 samples/s, speed: 4490.891416 tokens/s, learning rate: 3.990e-06, loss_scalings: 13421.773438, pp_loss: 9.224321
[INFO] 2021-07-12 18:36:38,509 [run_pretraining.py:  512]:	********exe.run_400******* 
[INFO] 2021-07-12 18:36:39,417 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:39,418 [run_pretraining.py:  534]:	loss/total_loss, 9.174150466918945, 401
[INFO] 2021-07-12 18:36:39,418 [run_pretraining.py:  535]:	loss/mlm_loss, 9.174150466918945, 401
[INFO] 2021-07-12 18:36:39,418 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.999999989900971e-06, 401
[INFO] 2021-07-12 18:36:39,418 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 401
[INFO] 2021-07-12 18:36:39,418 [run_pretraining.py:  558]:	worker_index: 6, step: 401, cost: 9.174150, mlm loss: 9.174150, speed: 1.100599 steps/s, speed: 8.804788 samples/s, speed: 4508.051626 tokens/s, learning rate: 4.000e-06, loss_scalings: 13421.773438, pp_loss: 9.155722
[INFO] 2021-07-12 18:36:39,418 [run_pretraining.py:  512]:	********exe.run_401******* 
[INFO] 2021-07-12 18:36:40,330 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:40,330 [run_pretraining.py:  534]:	loss/total_loss, 9.146476745605469, 402
[INFO] 2021-07-12 18:36:40,331 [run_pretraining.py:  535]:	loss/mlm_loss, 9.146476745605469, 402
[INFO] 2021-07-12 18:36:40,331 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.009999884146964e-06, 402
[INFO] 2021-07-12 18:36:40,331 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 402
[INFO] 2021-07-12 18:36:40,331 [run_pretraining.py:  558]:	worker_index: 6, step: 402, cost: 9.146477, mlm loss: 9.146477, speed: 1.096796 steps/s, speed: 8.774371 samples/s, speed: 4492.477967 tokens/s, learning rate: 4.010e-06, loss_scalings: 13421.773438, pp_loss: 9.306961
[INFO] 2021-07-12 18:36:40,331 [run_pretraining.py:  512]:	********exe.run_402******* 
[INFO] 2021-07-12 18:36:41,236 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:41,236 [run_pretraining.py:  534]:	loss/total_loss, 8.9154052734375, 403
[INFO] 2021-07-12 18:36:41,236 [run_pretraining.py:  535]:	loss/mlm_loss, 8.9154052734375, 403
[INFO] 2021-07-12 18:36:41,236 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.0199997783929575e-06, 403
[INFO] 2021-07-12 18:36:41,236 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 403
[INFO] 2021-07-12 18:36:41,237 [run_pretraining.py:  558]:	worker_index: 6, step: 403, cost: 8.915405, mlm loss: 8.915405, speed: 1.105033 steps/s, speed: 8.840261 samples/s, speed: 4526.213823 tokens/s, learning rate: 4.020e-06, loss_scalings: 13421.773438, pp_loss: 8.458075
[INFO] 2021-07-12 18:36:41,237 [run_pretraining.py:  512]:	********exe.run_403******* 
[INFO] 2021-07-12 18:36:42,157 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:42,157 [run_pretraining.py:  534]:	loss/total_loss, 8.952116012573242, 404
[INFO] 2021-07-12 18:36:42,157 [run_pretraining.py:  535]:	loss/mlm_loss, 8.952116012573242, 404
[INFO] 2021-07-12 18:36:42,157 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.030000127386302e-06, 404
[INFO] 2021-07-12 18:36:42,158 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 404
[INFO] 2021-07-12 18:36:42,158 [run_pretraining.py:  558]:	worker_index: 6, step: 404, cost: 8.952116, mlm loss: 8.952116, speed: 1.086521 steps/s, speed: 8.692171 samples/s, speed: 4450.391662 tokens/s, learning rate: 4.030e-06, loss_scalings: 13421.773438, pp_loss: 8.843533
[INFO] 2021-07-12 18:36:42,158 [run_pretraining.py:  512]:	********exe.run_404******* 
[INFO] 2021-07-12 18:36:43,067 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:43,068 [run_pretraining.py:  534]:	loss/total_loss, 8.815278053283691, 405
[INFO] 2021-07-12 18:36:43,068 [run_pretraining.py:  535]:	loss/mlm_loss, 8.815278053283691, 405
[INFO] 2021-07-12 18:36:43,068 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.039999566884944e-06, 405
[INFO] 2021-07-12 18:36:43,068 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 405
[INFO] 2021-07-12 18:36:43,068 [run_pretraining.py:  558]:	worker_index: 6, step: 405, cost: 8.815278, mlm loss: 8.815278, speed: 1.099085 steps/s, speed: 8.792678 samples/s, speed: 4501.850983 tokens/s, learning rate: 4.040e-06, loss_scalings: 13421.773438, pp_loss: 9.141212
[INFO] 2021-07-12 18:36:43,068 [run_pretraining.py:  512]:	********exe.run_405******* 
[INFO] 2021-07-12 18:36:43,988 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:43,989 [run_pretraining.py:  534]:	loss/total_loss, 8.981932640075684, 406
[INFO] 2021-07-12 18:36:43,989 [run_pretraining.py:  535]:	loss/mlm_loss, 8.981932640075684, 406
[INFO] 2021-07-12 18:36:43,989 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.0499999158782884e-06, 406
[INFO] 2021-07-12 18:36:43,989 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 406
[INFO] 2021-07-12 18:36:43,989 [run_pretraining.py:  558]:	worker_index: 6, step: 406, cost: 8.981933, mlm loss: 8.981933, speed: 1.086345 steps/s, speed: 8.690762 samples/s, speed: 4449.670088 tokens/s, learning rate: 4.050e-06, loss_scalings: 13421.773438, pp_loss: 9.140814
[INFO] 2021-07-12 18:36:43,990 [run_pretraining.py:  512]:	********exe.run_406******* 
[INFO] 2021-07-12 18:36:44,892 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:44,892 [run_pretraining.py:  534]:	loss/total_loss, 9.533319473266602, 407
[INFO] 2021-07-12 18:36:44,893 [run_pretraining.py:  535]:	loss/mlm_loss, 9.533319473266602, 407
[INFO] 2021-07-12 18:36:44,893 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.060000264871633e-06, 407
[INFO] 2021-07-12 18:36:44,893 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 407
[INFO] 2021-07-12 18:36:44,893 [run_pretraining.py:  558]:	worker_index: 6, step: 407, cost: 9.533319, mlm loss: 9.533319, speed: 1.107791 steps/s, speed: 8.862326 samples/s, speed: 4537.510864 tokens/s, learning rate: 4.060e-06, loss_scalings: 13421.773438, pp_loss: 9.350274
[INFO] 2021-07-12 18:36:44,893 [run_pretraining.py:  512]:	********exe.run_407******* 
[INFO] 2021-07-12 18:36:45,799 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:45,800 [run_pretraining.py:  534]:	loss/total_loss, 9.626580238342285, 408
[INFO] 2021-07-12 18:36:45,800 [run_pretraining.py:  535]:	loss/mlm_loss, 9.626580238342285, 408
[INFO] 2021-07-12 18:36:45,800 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.069999704370275e-06, 408
[INFO] 2021-07-12 18:36:45,800 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 408
[INFO] 2021-07-12 18:36:45,800 [run_pretraining.py:  558]:	worker_index: 6, step: 408, cost: 9.626580, mlm loss: 9.626580, speed: 1.102916 steps/s, speed: 8.823327 samples/s, speed: 4517.543264 tokens/s, learning rate: 4.070e-06, loss_scalings: 13421.773438, pp_loss: 8.176501
[INFO] 2021-07-12 18:36:45,800 [run_pretraining.py:  512]:	********exe.run_408******* 
[INFO] 2021-07-12 18:36:46,703 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:46,704 [run_pretraining.py:  534]:	loss/total_loss, 9.427498817443848, 409
[INFO] 2021-07-12 18:36:46,704 [run_pretraining.py:  535]:	loss/mlm_loss, 9.427498817443848, 409
[INFO] 2021-07-12 18:36:46,704 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.080000053363619e-06, 409
[INFO] 2021-07-12 18:36:46,704 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 409
[INFO] 2021-07-12 18:36:46,705 [run_pretraining.py:  558]:	worker_index: 6, step: 409, cost: 9.427499, mlm loss: 9.427499, speed: 1.106771 steps/s, speed: 8.854164 samples/s, speed: 4533.332168 tokens/s, learning rate: 4.080e-06, loss_scalings: 13421.773438, pp_loss: 9.148662
[INFO] 2021-07-12 18:36:46,705 [run_pretraining.py:  512]:	********exe.run_409******* 
[INFO] 2021-07-12 18:36:47,655 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:47,656 [run_pretraining.py:  534]:	loss/total_loss, 9.23485279083252, 410
[INFO] 2021-07-12 18:36:47,656 [run_pretraining.py:  535]:	loss/mlm_loss, 9.23485279083252, 410
[INFO] 2021-07-12 18:36:47,656 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.089999947609613e-06, 410
[INFO] 2021-07-12 18:36:47,656 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 410
[INFO] 2021-07-12 18:36:47,656 [run_pretraining.py:  558]:	worker_index: 6, step: 410, cost: 9.234853, mlm loss: 9.234853, speed: 1.051447 steps/s, speed: 8.411574 samples/s, speed: 4306.725734 tokens/s, learning rate: 4.090e-06, loss_scalings: 13421.773438, pp_loss: 9.089355
[INFO] 2021-07-12 18:36:47,656 [run_pretraining.py:  512]:	********exe.run_410******* 
[INFO] 2021-07-12 18:36:48,694 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:48,695 [run_pretraining.py:  534]:	loss/total_loss, 9.100831985473633, 411
[INFO] 2021-07-12 18:36:48,695 [run_pretraining.py:  535]:	loss/mlm_loss, 9.100831985473633, 411
[INFO] 2021-07-12 18:36:48,695 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.099999841855606e-06, 411
[INFO] 2021-07-12 18:36:48,695 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 411
[INFO] 2021-07-12 18:36:48,695 [run_pretraining.py:  558]:	worker_index: 6, step: 411, cost: 9.100832, mlm loss: 9.100832, speed: 0.963002 steps/s, speed: 7.704017 samples/s, speed: 3944.456936 tokens/s, learning rate: 4.100e-06, loss_scalings: 13421.773438, pp_loss: 8.877842
[INFO] 2021-07-12 18:36:48,696 [run_pretraining.py:  512]:	********exe.run_411******* 
[INFO] 2021-07-12 18:36:49,741 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:49,742 [run_pretraining.py:  534]:	loss/total_loss, 9.166775703430176, 412
[INFO] 2021-07-12 18:36:49,742 [run_pretraining.py:  535]:	loss/mlm_loss, 9.166775703430176, 412
[INFO] 2021-07-12 18:36:49,742 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.109999736101599e-06, 412
[INFO] 2021-07-12 18:36:49,742 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 412
[INFO] 2021-07-12 18:36:49,742 [run_pretraining.py:  558]:	worker_index: 6, step: 412, cost: 9.166776, mlm loss: 9.166776, speed: 0.955861 steps/s, speed: 7.646892 samples/s, speed: 3915.208692 tokens/s, learning rate: 4.110e-06, loss_scalings: 13421.773438, pp_loss: 9.026212
[INFO] 2021-07-12 18:36:49,742 [run_pretraining.py:  512]:	********exe.run_412******* 
[INFO] 2021-07-12 18:36:50,801 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:50,802 [run_pretraining.py:  534]:	loss/total_loss, 9.456618309020996, 413
[INFO] 2021-07-12 18:36:50,802 [run_pretraining.py:  535]:	loss/mlm_loss, 9.456618309020996, 413
[INFO] 2021-07-12 18:36:50,802 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.120000085094944e-06, 413
[INFO] 2021-07-12 18:36:50,802 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 413
[INFO] 2021-07-12 18:36:50,802 [run_pretraining.py:  558]:	worker_index: 6, step: 413, cost: 9.456618, mlm loss: 9.456618, speed: 0.943978 steps/s, speed: 7.551821 samples/s, speed: 3866.532316 tokens/s, learning rate: 4.120e-06, loss_scalings: 13421.773438, pp_loss: 9.094157
[INFO] 2021-07-12 18:36:50,802 [run_pretraining.py:  512]:	********exe.run_413******* 
[INFO] 2021-07-12 18:36:51,876 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:51,877 [run_pretraining.py:  534]:	loss/total_loss, 9.303132057189941, 414
[INFO] 2021-07-12 18:36:51,877 [run_pretraining.py:  535]:	loss/mlm_loss, 9.303132057189941, 414
[INFO] 2021-07-12 18:36:51,877 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.129999979340937e-06, 414
[INFO] 2021-07-12 18:36:51,877 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 414
[INFO] 2021-07-12 18:36:51,877 [run_pretraining.py:  558]:	worker_index: 6, step: 414, cost: 9.303132, mlm loss: 9.303132, speed: 0.930832 steps/s, speed: 7.446656 samples/s, speed: 3812.688000 tokens/s, learning rate: 4.130e-06, loss_scalings: 13421.773438, pp_loss: 9.149901
[INFO] 2021-07-12 18:36:51,878 [run_pretraining.py:  512]:	********exe.run_414******* 
[INFO] 2021-07-12 18:36:52,908 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:52,908 [run_pretraining.py:  534]:	loss/total_loss, 9.065383911132812, 415
[INFO] 2021-07-12 18:36:52,908 [run_pretraining.py:  535]:	loss/mlm_loss, 9.065383911132812, 415
[INFO] 2021-07-12 18:36:52,908 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.13999987358693e-06, 415
[INFO] 2021-07-12 18:36:52,909 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 415
[INFO] 2021-07-12 18:36:52,909 [run_pretraining.py:  558]:	worker_index: 6, step: 415, cost: 9.065384, mlm loss: 9.065384, speed: 0.970388 steps/s, speed: 7.763107 samples/s, speed: 3974.710925 tokens/s, learning rate: 4.140e-06, loss_scalings: 13421.773438, pp_loss: 9.157715
[INFO] 2021-07-12 18:36:52,909 [run_pretraining.py:  512]:	********exe.run_415******* 
[INFO] 2021-07-12 18:36:53,968 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:53,968 [run_pretraining.py:  534]:	loss/total_loss, 9.43496036529541, 416
[INFO] 2021-07-12 18:36:53,969 [run_pretraining.py:  535]:	loss/mlm_loss, 9.43496036529541, 416
[INFO] 2021-07-12 18:36:53,969 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.149999767832924e-06, 416
[INFO] 2021-07-12 18:36:53,969 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 416
[INFO] 2021-07-12 18:36:53,969 [run_pretraining.py:  558]:	worker_index: 6, step: 416, cost: 9.434960, mlm loss: 9.434960, speed: 0.943857 steps/s, speed: 7.550857 samples/s, speed: 3866.038971 tokens/s, learning rate: 4.150e-06, loss_scalings: 13421.773438, pp_loss: 8.210937
[INFO] 2021-07-12 18:36:53,969 [run_pretraining.py:  512]:	********exe.run_416******* 
[INFO] 2021-07-12 18:36:55,024 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:55,025 [run_pretraining.py:  534]:	loss/total_loss, 8.95577335357666, 417
[INFO] 2021-07-12 18:36:55,025 [run_pretraining.py:  535]:	loss/mlm_loss, 8.95577335357666, 417
[INFO] 2021-07-12 18:36:55,025 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.160000116826268e-06, 417
[INFO] 2021-07-12 18:36:55,025 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 417
[INFO] 2021-07-12 18:36:55,025 [run_pretraining.py:  558]:	worker_index: 6, step: 417, cost: 8.955773, mlm loss: 8.955773, speed: 0.947356 steps/s, speed: 7.578848 samples/s, speed: 3880.370121 tokens/s, learning rate: 4.160e-06, loss_scalings: 13421.773438, pp_loss: 9.156504
[INFO] 2021-07-12 18:36:55,025 [run_pretraining.py:  512]:	********exe.run_417******* 
[INFO] 2021-07-12 18:36:56,078 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:56,079 [run_pretraining.py:  534]:	loss/total_loss, 9.011098861694336, 418
[INFO] 2021-07-12 18:36:56,079 [run_pretraining.py:  535]:	loss/mlm_loss, 9.011098861694336, 418
[INFO] 2021-07-12 18:36:56,079 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.170000011072261e-06, 418
[INFO] 2021-07-12 18:36:56,079 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 418
[INFO] 2021-07-12 18:36:56,079 [run_pretraining.py:  558]:	worker_index: 6, step: 418, cost: 9.011099, mlm loss: 9.011099, speed: 0.949146 steps/s, speed: 7.593165 samples/s, speed: 3887.700535 tokens/s, learning rate: 4.170e-06, loss_scalings: 13421.773438, pp_loss: 8.932711
[INFO] 2021-07-12 18:36:56,080 [run_pretraining.py:  512]:	********exe.run_418******* 
[INFO] 2021-07-12 18:36:57,132 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:57,133 [run_pretraining.py:  534]:	loss/total_loss, 9.075319290161133, 419
[INFO] 2021-07-12 18:36:57,133 [run_pretraining.py:  535]:	loss/mlm_loss, 9.075319290161133, 419
[INFO] 2021-07-12 18:36:57,133 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.179999905318255e-06, 419
[INFO] 2021-07-12 18:36:57,133 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 419
[INFO] 2021-07-12 18:36:57,133 [run_pretraining.py:  558]:	worker_index: 6, step: 419, cost: 9.075319, mlm loss: 9.075319, speed: 0.949460 steps/s, speed: 7.595683 samples/s, speed: 3888.989816 tokens/s, learning rate: 4.180e-06, loss_scalings: 13421.773438, pp_loss: 9.084797
[INFO] 2021-07-12 18:36:57,133 [run_pretraining.py:  512]:	********exe.run_419******* 
[INFO] 2021-07-12 18:36:58,188 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:58,189 [run_pretraining.py:  534]:	loss/total_loss, 9.106669425964355, 420
[INFO] 2021-07-12 18:36:58,189 [run_pretraining.py:  535]:	loss/mlm_loss, 9.106669425964355, 420
[INFO] 2021-07-12 18:36:58,189 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.190000254311599e-06, 420
[INFO] 2021-07-12 18:36:58,189 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 420
[INFO] 2021-07-12 18:36:58,189 [run_pretraining.py:  558]:	worker_index: 6, step: 420, cost: 9.106669, mlm loss: 9.106669, speed: 0.947792 steps/s, speed: 7.582333 samples/s, speed: 3882.154514 tokens/s, learning rate: 4.190e-06, loss_scalings: 13421.773438, pp_loss: 9.215256
[INFO] 2021-07-12 18:36:58,189 [run_pretraining.py:  512]:	********exe.run_420******* 
[INFO] 2021-07-12 18:36:59,244 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:59,245 [run_pretraining.py:  534]:	loss/total_loss, 9.295360565185547, 421
[INFO] 2021-07-12 18:36:59,245 [run_pretraining.py:  535]:	loss/mlm_loss, 9.295360565185547, 421
[INFO] 2021-07-12 18:36:59,245 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.199999693810241e-06, 421
[INFO] 2021-07-12 18:36:59,245 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 421
[INFO] 2021-07-12 18:36:59,245 [run_pretraining.py:  558]:	worker_index: 6, step: 421, cost: 9.295361, mlm loss: 9.295361, speed: 0.947569 steps/s, speed: 7.580548 samples/s, speed: 3881.240629 tokens/s, learning rate: 4.200e-06, loss_scalings: 13421.773438, pp_loss: 9.074624
[INFO] 2021-07-12 18:36:59,245 [run_pretraining.py:  512]:	********exe.run_421******* 
[INFO] 2021-07-12 18:37:00,298 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:00,299 [run_pretraining.py:  534]:	loss/total_loss, 8.72493839263916, 422
[INFO] 2021-07-12 18:37:00,299 [run_pretraining.py:  535]:	loss/mlm_loss, 8.72493839263916, 422
[INFO] 2021-07-12 18:37:00,299 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.2100000428035855e-06, 422
[INFO] 2021-07-12 18:37:00,299 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 422
[INFO] 2021-07-12 18:37:00,299 [run_pretraining.py:  558]:	worker_index: 6, step: 422, cost: 8.724938, mlm loss: 8.724938, speed: 0.949324 steps/s, speed: 7.594588 samples/s, speed: 3888.429116 tokens/s, learning rate: 4.210e-06, loss_scalings: 13421.773438, pp_loss: 9.016501
[INFO] 2021-07-12 18:37:00,299 [run_pretraining.py:  512]:	********exe.run_422******* 
[INFO] 2021-07-12 18:37:01,349 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:01,349 [run_pretraining.py:  534]:	loss/total_loss, 9.16624641418457, 423
[INFO] 2021-07-12 18:37:01,349 [run_pretraining.py:  535]:	loss/mlm_loss, 9.16624641418457, 423
[INFO] 2021-07-12 18:37:01,350 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.219999937049579e-06, 423
[INFO] 2021-07-12 18:37:01,350 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 423
[INFO] 2021-07-12 18:37:01,350 [run_pretraining.py:  558]:	worker_index: 6, step: 423, cost: 9.166246, mlm loss: 9.166246, speed: 0.952707 steps/s, speed: 7.621658 samples/s, speed: 3902.288758 tokens/s, learning rate: 4.220e-06, loss_scalings: 13421.773438, pp_loss: 8.297218
[INFO] 2021-07-12 18:37:01,350 [run_pretraining.py:  512]:	********exe.run_423******* 
[INFO] 2021-07-12 18:37:02,405 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:02,405 [run_pretraining.py:  534]:	loss/total_loss, 9.01440143585205, 424
[INFO] 2021-07-12 18:37:02,405 [run_pretraining.py:  535]:	loss/mlm_loss, 9.01440143585205, 424
[INFO] 2021-07-12 18:37:02,406 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.229999831295572e-06, 424
[INFO] 2021-07-12 18:37:02,406 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 424
[INFO] 2021-07-12 18:37:02,406 [run_pretraining.py:  558]:	worker_index: 6, step: 424, cost: 9.014401, mlm loss: 9.014401, speed: 0.947625 steps/s, speed: 7.581002 samples/s, speed: 3881.473006 tokens/s, learning rate: 4.230e-06, loss_scalings: 13421.773438, pp_loss: 9.036777
[INFO] 2021-07-12 18:37:02,406 [run_pretraining.py:  512]:	********exe.run_424******* 
[INFO] 2021-07-12 18:37:03,463 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:03,464 [run_pretraining.py:  534]:	loss/total_loss, 9.26456069946289, 425
[INFO] 2021-07-12 18:37:03,464 [run_pretraining.py:  535]:	loss/mlm_loss, 9.26456069946289, 425
[INFO] 2021-07-12 18:37:03,464 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.2399997255415656e-06, 425
[INFO] 2021-07-12 18:37:03,464 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 425
[INFO] 2021-07-12 18:37:03,464 [run_pretraining.py:  558]:	worker_index: 6, step: 425, cost: 9.264561, mlm loss: 9.264561, speed: 0.945688 steps/s, speed: 7.565500 samples/s, speed: 3873.536237 tokens/s, learning rate: 4.240e-06, loss_scalings: 13421.773438, pp_loss: 9.166953
[INFO] 2021-07-12 18:37:03,464 [run_pretraining.py:  512]:	********exe.run_425******* 
[INFO] 2021-07-12 18:37:04,519 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:04,520 [run_pretraining.py:  534]:	loss/total_loss, 8.932149887084961, 426
[INFO] 2021-07-12 18:37:04,520 [run_pretraining.py:  535]:	loss/mlm_loss, 8.932149887084961, 426
[INFO] 2021-07-12 18:37:04,520 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.25000007453491e-06, 426
[INFO] 2021-07-12 18:37:04,520 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 426
[INFO] 2021-07-12 18:37:04,520 [run_pretraining.py:  558]:	worker_index: 6, step: 426, cost: 8.932150, mlm loss: 8.932150, speed: 0.947240 steps/s, speed: 7.577920 samples/s, speed: 3879.895144 tokens/s, learning rate: 4.250e-06, loss_scalings: 13421.773438, pp_loss: 8.892303
[INFO] 2021-07-12 18:37:04,520 [run_pretraining.py:  512]:	********exe.run_426******* 
[INFO] 2021-07-12 18:37:05,640 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:05,641 [run_pretraining.py:  534]:	loss/total_loss, 8.958288192749023, 427
[INFO] 2021-07-12 18:37:05,641 [run_pretraining.py:  535]:	loss/mlm_loss, 8.958288192749023, 427
[INFO] 2021-07-12 18:37:05,641 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.259999514033552e-06, 427
[INFO] 2021-07-12 18:37:05,641 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 427
[INFO] 2021-07-12 18:37:05,641 [run_pretraining.py:  558]:	worker_index: 6, step: 427, cost: 8.958288, mlm loss: 8.958288, speed: 0.892724 steps/s, speed: 7.141791 samples/s, speed: 3656.596799 tokens/s, learning rate: 4.260e-06, loss_scalings: 13421.773438, pp_loss: 9.029667
[INFO] 2021-07-12 18:37:05,641 [run_pretraining.py:  512]:	********exe.run_427******* 
[INFO] 2021-07-12 18:37:06,746 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:06,747 [run_pretraining.py:  534]:	loss/total_loss, 8.909830093383789, 428
[INFO] 2021-07-12 18:37:06,747 [run_pretraining.py:  535]:	loss/mlm_loss, 8.909830093383789, 428
[INFO] 2021-07-12 18:37:06,747 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.2699998630268965e-06, 428
[INFO] 2021-07-12 18:37:06,747 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 428
[INFO] 2021-07-12 18:37:06,747 [run_pretraining.py:  558]:	worker_index: 6, step: 428, cost: 8.909830, mlm loss: 8.909830, speed: 0.904570 steps/s, speed: 7.236560 samples/s, speed: 3705.118858 tokens/s, learning rate: 4.270e-06, loss_scalings: 13421.773438, pp_loss: 9.129536
[INFO] 2021-07-12 18:37:06,748 [run_pretraining.py:  512]:	********exe.run_428******* 
[INFO] 2021-07-12 18:37:07,835 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:07,836 [run_pretraining.py:  534]:	loss/total_loss, 8.907017707824707, 429
[INFO] 2021-07-12 18:37:07,836 [run_pretraining.py:  535]:	loss/mlm_loss, 8.907017707824707, 429
[INFO] 2021-07-12 18:37:07,836 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.280000212020241e-06, 429
[INFO] 2021-07-12 18:37:07,836 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 429
[INFO] 2021-07-12 18:37:07,836 [run_pretraining.py:  558]:	worker_index: 6, step: 429, cost: 8.907018, mlm loss: 8.907018, speed: 0.919262 steps/s, speed: 7.354096 samples/s, speed: 3765.297280 tokens/s, learning rate: 4.280e-06, loss_scalings: 13421.773438, pp_loss: 9.009484
[INFO] 2021-07-12 18:37:07,836 [run_pretraining.py:  512]:	********exe.run_429******* 
[INFO] 2021-07-12 18:37:08,888 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:08,889 [run_pretraining.py:  534]:	loss/total_loss, 8.88543701171875, 430
[INFO] 2021-07-12 18:37:08,889 [run_pretraining.py:  535]:	loss/mlm_loss, 8.88543701171875, 430
[INFO] 2021-07-12 18:37:08,889 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.289999651518883e-06, 430
[INFO] 2021-07-12 18:37:08,889 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 430
[INFO] 2021-07-12 18:37:08,889 [run_pretraining.py:  558]:	worker_index: 6, step: 430, cost: 8.885437, mlm loss: 8.885437, speed: 0.950043 steps/s, speed: 7.600342 samples/s, speed: 3891.375257 tokens/s, learning rate: 4.290e-06, loss_scalings: 13421.773438, pp_loss: 9.020996
[INFO] 2021-07-12 18:37:08,889 [run_pretraining.py:  512]:	********exe.run_430******* 
[INFO] 2021-07-12 18:37:09,947 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:09,948 [run_pretraining.py:  534]:	loss/total_loss, 5.057394504547119, 431
[INFO] 2021-07-12 18:37:09,948 [run_pretraining.py:  535]:	loss/mlm_loss, 5.057394504547119, 431
[INFO] 2021-07-12 18:37:09,948 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.300000000512227e-06, 431
[INFO] 2021-07-12 18:37:09,948 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 431
[INFO] 2021-07-12 18:37:09,948 [run_pretraining.py:  558]:	worker_index: 6, step: 431, cost: 5.057395, mlm loss: 5.057395, speed: 0.945191 steps/s, speed: 7.561530 samples/s, speed: 3871.503240 tokens/s, learning rate: 4.300e-06, loss_scalings: 13421.773438, pp_loss: 7.865270
[INFO] 2021-07-12 18:37:09,948 [run_pretraining.py:  512]:	********exe.run_431******* 
[INFO] 2021-07-12 18:37:11,014 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:11,014 [run_pretraining.py:  534]:	loss/total_loss, 9.044368743896484, 432
[INFO] 2021-07-12 18:37:11,014 [run_pretraining.py:  535]:	loss/mlm_loss, 9.044368743896484, 432
[INFO] 2021-07-12 18:37:11,015 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.309999894758221e-06, 432
[INFO] 2021-07-12 18:37:11,015 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 432
[INFO] 2021-07-12 18:37:11,015 [run_pretraining.py:  558]:	worker_index: 6, step: 432, cost: 9.044369, mlm loss: 9.044369, speed: 0.938037 steps/s, speed: 7.504294 samples/s, speed: 3842.198753 tokens/s, learning rate: 4.310e-06, loss_scalings: 13421.773438, pp_loss: 9.205410
[INFO] 2021-07-12 18:37:11,015 [run_pretraining.py:  512]:	********exe.run_432******* 
[INFO] 2021-07-12 18:37:12,062 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:12,062 [run_pretraining.py:  534]:	loss/total_loss, 9.3013334274292, 433
[INFO] 2021-07-12 18:37:12,062 [run_pretraining.py:  535]:	loss/mlm_loss, 9.3013334274292, 433
[INFO] 2021-07-12 18:37:12,063 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.319999789004214e-06, 433
[INFO] 2021-07-12 18:37:12,063 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 433
[INFO] 2021-07-12 18:37:12,063 [run_pretraining.py:  558]:	worker_index: 6, step: 433, cost: 9.301333, mlm loss: 9.301333, speed: 0.954884 steps/s, speed: 7.639075 samples/s, speed: 3911.206554 tokens/s, learning rate: 4.320e-06, loss_scalings: 13421.773438, pp_loss: 9.175120
[INFO] 2021-07-12 18:37:12,063 [run_pretraining.py:  512]:	********exe.run_433******* 
[INFO] 2021-07-12 18:37:13,105 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:13,106 [run_pretraining.py:  534]:	loss/total_loss, 9.172642707824707, 434
[INFO] 2021-07-12 18:37:13,106 [run_pretraining.py:  535]:	loss/mlm_loss, 9.172642707824707, 434
[INFO] 2021-07-12 18:37:13,106 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.3299996832502075e-06, 434
[INFO] 2021-07-12 18:37:13,106 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 434
[INFO] 2021-07-12 18:37:13,106 [run_pretraining.py:  558]:	worker_index: 6, step: 434, cost: 9.172643, mlm loss: 9.172643, speed: 0.959080 steps/s, speed: 7.672638 samples/s, speed: 3928.390517 tokens/s, learning rate: 4.330e-06, loss_scalings: 13421.773438, pp_loss: 9.014911
[INFO] 2021-07-12 18:37:13,106 [run_pretraining.py:  512]:	********exe.run_434******* 
[INFO] 2021-07-12 18:37:14,156 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:14,156 [run_pretraining.py:  534]:	loss/total_loss, 8.659402847290039, 435
[INFO] 2021-07-12 18:37:14,156 [run_pretraining.py:  535]:	loss/mlm_loss, 8.659402847290039, 435
[INFO] 2021-07-12 18:37:14,157 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.340000032243552e-06, 435
[INFO] 2021-07-12 18:37:14,157 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 435
[INFO] 2021-07-12 18:37:14,157 [run_pretraining.py:  558]:	worker_index: 6, step: 435, cost: 8.659403, mlm loss: 8.659403, speed: 0.952484 steps/s, speed: 7.619873 samples/s, speed: 3901.375117 tokens/s, learning rate: 4.340e-06, loss_scalings: 13421.773438, pp_loss: 8.796022
[INFO] 2021-07-12 18:37:14,157 [run_pretraining.py:  512]:	********exe.run_435******* 
[INFO] 2021-07-12 18:37:15,211 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:15,211 [run_pretraining.py:  534]:	loss/total_loss, 9.557182312011719, 436
[INFO] 2021-07-12 18:37:15,211 [run_pretraining.py:  535]:	loss/mlm_loss, 9.557182312011719, 436
[INFO] 2021-07-12 18:37:15,211 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.349999926489545e-06, 436
[INFO] 2021-07-12 18:37:15,212 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 436
[INFO] 2021-07-12 18:37:15,212 [run_pretraining.py:  558]:	worker_index: 6, step: 436, cost: 9.557182, mlm loss: 9.557182, speed: 0.948650 steps/s, speed: 7.589201 samples/s, speed: 3885.671102 tokens/s, learning rate: 4.350e-06, loss_scalings: 13421.773438, pp_loss: 9.101976
[INFO] 2021-07-12 18:37:15,212 [run_pretraining.py:  512]:	********exe.run_436******* 
[INFO] 2021-07-12 18:37:16,265 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:16,266 [run_pretraining.py:  534]:	loss/total_loss, 8.89274787902832, 437
[INFO] 2021-07-12 18:37:16,266 [run_pretraining.py:  535]:	loss/mlm_loss, 8.89274787902832, 437
[INFO] 2021-07-12 18:37:16,266 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.359999820735538e-06, 437
[INFO] 2021-07-12 18:37:16,266 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 437
[INFO] 2021-07-12 18:37:16,266 [run_pretraining.py:  558]:	worker_index: 6, step: 437, cost: 8.892748, mlm loss: 8.892748, speed: 0.948810 steps/s, speed: 7.590484 samples/s, speed: 3886.327710 tokens/s, learning rate: 4.360e-06, loss_scalings: 13421.773438, pp_loss: 8.904861
[INFO] 2021-07-12 18:37:16,266 [run_pretraining.py:  512]:	********exe.run_437******* 
[INFO] 2021-07-12 18:37:17,317 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:17,318 [run_pretraining.py:  534]:	loss/total_loss, 8.553449630737305, 438
[INFO] 2021-07-12 18:37:17,318 [run_pretraining.py:  535]:	loss/mlm_loss, 8.553449630737305, 438
[INFO] 2021-07-12 18:37:17,318 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.369999714981532e-06, 438
[INFO] 2021-07-12 18:37:17,318 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 438
[INFO] 2021-07-12 18:37:17,318 [run_pretraining.py:  558]:	worker_index: 6, step: 438, cost: 8.553450, mlm loss: 8.553450, speed: 0.951080 steps/s, speed: 7.608641 samples/s, speed: 3895.623962 tokens/s, learning rate: 4.370e-06, loss_scalings: 13421.773438, pp_loss: 8.936554
[INFO] 2021-07-12 18:37:17,319 [run_pretraining.py:  512]:	********exe.run_438******* 
[INFO] 2021-07-12 18:37:18,372 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:18,372 [run_pretraining.py:  534]:	loss/total_loss, 8.413166046142578, 439
[INFO] 2021-07-12 18:37:18,372 [run_pretraining.py:  535]:	loss/mlm_loss, 8.413166046142578, 439
[INFO] 2021-07-12 18:37:18,372 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.380000063974876e-06, 439
[INFO] 2021-07-12 18:37:18,372 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 439
[INFO] 2021-07-12 18:37:18,373 [run_pretraining.py:  558]:	worker_index: 6, step: 439, cost: 8.413166, mlm loss: 8.413166, speed: 0.949281 steps/s, speed: 7.594251 samples/s, speed: 3888.256625 tokens/s, learning rate: 4.380e-06, loss_scalings: 13421.773438, pp_loss: 8.894686
[INFO] 2021-07-12 18:37:18,373 [run_pretraining.py:  512]:	********exe.run_439******* 
[INFO] 2021-07-12 18:37:19,423 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:19,424 [run_pretraining.py:  534]:	loss/total_loss, 9.30803394317627, 440
[INFO] 2021-07-12 18:37:19,424 [run_pretraining.py:  535]:	loss/mlm_loss, 9.30803394317627, 440
[INFO] 2021-07-12 18:37:19,424 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.389999958220869e-06, 440
[INFO] 2021-07-12 18:37:19,424 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 440
[INFO] 2021-07-12 18:37:19,424 [run_pretraining.py:  558]:	worker_index: 6, step: 440, cost: 9.308034, mlm loss: 9.308034, speed: 0.951618 steps/s, speed: 7.612942 samples/s, speed: 3897.826522 tokens/s, learning rate: 4.390e-06, loss_scalings: 13421.773438, pp_loss: 9.097107
[INFO] 2021-07-12 18:37:19,424 [run_pretraining.py:  512]:	********exe.run_440******* 
[INFO] 2021-07-12 18:37:20,477 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:20,477 [run_pretraining.py:  534]:	loss/total_loss, 9.51634407043457, 441
[INFO] 2021-07-12 18:37:20,478 [run_pretraining.py:  535]:	loss/mlm_loss, 9.51634407043457, 441
[INFO] 2021-07-12 18:37:20,478 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.399999852466863e-06, 441
[INFO] 2021-07-12 18:37:20,478 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 441
[INFO] 2021-07-12 18:37:20,478 [run_pretraining.py:  558]:	worker_index: 6, step: 441, cost: 9.516344, mlm loss: 9.516344, speed: 0.949625 steps/s, speed: 7.597001 samples/s, speed: 3889.664278 tokens/s, learning rate: 4.400e-06, loss_scalings: 13421.773438, pp_loss: 8.411869
[INFO] 2021-07-12 18:37:20,478 [run_pretraining.py:  512]:	********exe.run_441******* 
[INFO] 2021-07-12 18:37:21,531 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:21,532 [run_pretraining.py:  534]:	loss/total_loss, 9.253928184509277, 442
[INFO] 2021-07-12 18:37:21,532 [run_pretraining.py:  535]:	loss/mlm_loss, 9.253928184509277, 442
[INFO] 2021-07-12 18:37:21,532 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.410000201460207e-06, 442
[INFO] 2021-07-12 18:37:21,532 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 442
[INFO] 2021-07-12 18:37:21,532 [run_pretraining.py:  558]:	worker_index: 6, step: 442, cost: 9.253928, mlm loss: 9.253928, speed: 0.949036 steps/s, speed: 7.592291 samples/s, speed: 3887.252787 tokens/s, learning rate: 4.410e-06, loss_scalings: 13421.773438, pp_loss: 9.243899
[INFO] 2021-07-12 18:37:21,532 [run_pretraining.py:  512]:	********exe.run_442******* 
[INFO] 2021-07-12 18:37:22,620 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:22,620 [run_pretraining.py:  534]:	loss/total_loss, 8.972107887268066, 443
[INFO] 2021-07-12 18:37:22,620 [run_pretraining.py:  535]:	loss/mlm_loss, 8.972107887268066, 443
[INFO] 2021-07-12 18:37:22,621 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.419999640958849e-06, 443
[INFO] 2021-07-12 18:37:22,621 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 443
[INFO] 2021-07-12 18:37:22,621 [run_pretraining.py:  558]:	worker_index: 6, step: 443, cost: 8.972108, mlm loss: 8.972108, speed: 0.919312 steps/s, speed: 7.354499 samples/s, speed: 3765.503600 tokens/s, learning rate: 4.420e-06, loss_scalings: 13421.773438, pp_loss: 8.898503
[INFO] 2021-07-12 18:37:22,621 [run_pretraining.py:  512]:	********exe.run_443******* 
[INFO] 2021-07-12 18:37:23,684 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:23,685 [run_pretraining.py:  534]:	loss/total_loss, 8.801520347595215, 444
[INFO] 2021-07-12 18:37:23,685 [run_pretraining.py:  535]:	loss/mlm_loss, 8.801520347595215, 444
[INFO] 2021-07-12 18:37:23,685 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.4299999899521936e-06, 444
[INFO] 2021-07-12 18:37:23,685 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 444
[INFO] 2021-07-12 18:37:23,685 [run_pretraining.py:  558]:	worker_index: 6, step: 444, cost: 8.801520, mlm loss: 8.801520, speed: 0.939985 steps/s, speed: 7.519876 samples/s, speed: 3850.176606 tokens/s, learning rate: 4.430e-06, loss_scalings: 13421.773438, pp_loss: 9.053577
[INFO] 2021-07-12 18:37:23,685 [run_pretraining.py:  512]:	********exe.run_444******* 
[INFO] 2021-07-12 18:37:24,740 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:24,740 [run_pretraining.py:  534]:	loss/total_loss, 9.250044822692871, 445
[INFO] 2021-07-12 18:37:24,741 [run_pretraining.py:  535]:	loss/mlm_loss, 9.250044822692871, 445
[INFO] 2021-07-12 18:37:24,741 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.439999884198187e-06, 445
[INFO] 2021-07-12 18:37:24,741 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 445
[INFO] 2021-07-12 18:37:24,741 [run_pretraining.py:  558]:	worker_index: 6, step: 445, cost: 9.250045, mlm loss: 9.250045, speed: 0.948075 steps/s, speed: 7.584601 samples/s, speed: 3883.315469 tokens/s, learning rate: 4.440e-06, loss_scalings: 13421.773438, pp_loss: 9.077525
[INFO] 2021-07-12 18:37:24,741 [run_pretraining.py:  512]:	********exe.run_445******* 
[INFO] 2021-07-12 18:37:25,791 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:25,791 [run_pretraining.py:  534]:	loss/total_loss, 8.622962951660156, 446
[INFO] 2021-07-12 18:37:25,791 [run_pretraining.py:  535]:	loss/mlm_loss, 8.622962951660156, 446
[INFO] 2021-07-12 18:37:25,792 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.44999977844418e-06, 446
[INFO] 2021-07-12 18:37:25,792 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 446
[INFO] 2021-07-12 18:37:25,792 [run_pretraining.py:  558]:	worker_index: 6, step: 446, cost: 8.622963, mlm loss: 8.622963, speed: 0.952225 steps/s, speed: 7.617801 samples/s, speed: 3900.314022 tokens/s, learning rate: 4.450e-06, loss_scalings: 13421.773438, pp_loss: 8.832262
[INFO] 2021-07-12 18:37:25,792 [run_pretraining.py:  512]:	********exe.run_446******* 
[INFO] 2021-07-12 18:37:26,842 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:26,843 [run_pretraining.py:  534]:	loss/total_loss, 9.033696174621582, 447
[INFO] 2021-07-12 18:37:26,843 [run_pretraining.py:  535]:	loss/mlm_loss, 9.033696174621582, 447
[INFO] 2021-07-12 18:37:26,843 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.459999672690174e-06, 447
[INFO] 2021-07-12 18:37:26,843 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 447
[INFO] 2021-07-12 18:37:26,843 [run_pretraining.py:  558]:	worker_index: 6, step: 447, cost: 9.033696, mlm loss: 9.033696, speed: 0.951405 steps/s, speed: 7.611240 samples/s, speed: 3896.954746 tokens/s, learning rate: 4.460e-06, loss_scalings: 13421.773438, pp_loss: 9.059848
[INFO] 2021-07-12 18:37:26,844 [run_pretraining.py:  512]:	********exe.run_447******* 
[INFO] 2021-07-12 18:37:27,894 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:27,894 [run_pretraining.py:  534]:	loss/total_loss, 8.982958793640137, 448
[INFO] 2021-07-12 18:37:27,894 [run_pretraining.py:  535]:	loss/mlm_loss, 8.982958793640137, 448
[INFO] 2021-07-12 18:37:27,895 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.470000021683518e-06, 448
[INFO] 2021-07-12 18:37:27,895 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 448
[INFO] 2021-07-12 18:37:27,895 [run_pretraining.py:  558]:	worker_index: 6, step: 448, cost: 8.982959, mlm loss: 8.982959, speed: 0.951926 steps/s, speed: 7.615408 samples/s, speed: 3899.088901 tokens/s, learning rate: 4.470e-06, loss_scalings: 13421.773438, pp_loss: 9.163246
[INFO] 2021-07-12 18:37:27,895 [run_pretraining.py:  512]:	********exe.run_448******* 
[INFO] 2021-07-12 18:37:28,953 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:28,954 [run_pretraining.py:  534]:	loss/total_loss, 9.289210319519043, 449
[INFO] 2021-07-12 18:37:28,954 [run_pretraining.py:  535]:	loss/mlm_loss, 9.289210319519043, 449
[INFO] 2021-07-12 18:37:28,954 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.479999915929511e-06, 449
[INFO] 2021-07-12 18:37:28,954 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 449
[INFO] 2021-07-12 18:37:28,954 [run_pretraining.py:  558]:	worker_index: 6, step: 449, cost: 9.289210, mlm loss: 9.289210, speed: 0.944494 steps/s, speed: 7.555955 samples/s, speed: 3868.648952 tokens/s, learning rate: 4.480e-06, loss_scalings: 13421.773438, pp_loss: 9.082455
[INFO] 2021-07-12 18:37:28,954 [run_pretraining.py:  512]:	********exe.run_449******* 
[INFO] 2021-07-12 18:37:29,999 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:30,000 [run_pretraining.py:  534]:	loss/total_loss, 9.213546752929688, 450
[INFO] 2021-07-12 18:37:30,000 [run_pretraining.py:  535]:	loss/mlm_loss, 9.213546752929688, 450
[INFO] 2021-07-12 18:37:30,000 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.4899998101755045e-06, 450
[INFO] 2021-07-12 18:37:30,000 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 450
[INFO] 2021-07-12 18:37:30,000 [run_pretraining.py:  558]:	worker_index: 6, step: 450, cost: 9.213547, mlm loss: 9.213547, speed: 0.956861 steps/s, speed: 7.654889 samples/s, speed: 3919.303076 tokens/s, learning rate: 4.490e-06, loss_scalings: 13421.773438, pp_loss: 9.250187
[INFO] 2021-07-12 18:37:30,000 [run_pretraining.py:  512]:	********exe.run_450******* 
[INFO] 2021-07-12 18:37:31,056 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:31,057 [run_pretraining.py:  534]:	loss/total_loss, 9.21544361114502, 451
[INFO] 2021-07-12 18:37:31,057 [run_pretraining.py:  535]:	loss/mlm_loss, 9.21544361114502, 451
[INFO] 2021-07-12 18:37:31,057 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.500000159168849e-06, 451
[INFO] 2021-07-12 18:37:31,057 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 451
[INFO] 2021-07-12 18:37:31,057 [run_pretraining.py:  558]:	worker_index: 6, step: 451, cost: 9.215444, mlm loss: 9.215444, speed: 0.946756 steps/s, speed: 7.574049 samples/s, speed: 3877.913239 tokens/s, learning rate: 4.500e-06, loss_scalings: 13421.773438, pp_loss: 8.898545
[INFO] 2021-07-12 18:37:31,057 [run_pretraining.py:  512]:	********exe.run_451******* 
[INFO] 2021-07-12 18:37:56,803 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:56,804 [run_pretraining.py:  534]:	loss/total_loss, 9.048704147338867, 452
[INFO] 2021-07-12 18:37:56,804 [run_pretraining.py:  535]:	loss/mlm_loss, 9.048704147338867, 452
[INFO] 2021-07-12 18:37:56,804 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.510000053414842e-06, 452
[INFO] 2021-07-12 18:37:56,804 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 452
[INFO] 2021-07-12 18:37:56,805 [run_pretraining.py:  558]:	worker_index: 6, step: 452, cost: 9.048704, mlm loss: 9.048704, speed: 0.038840 steps/s, speed: 0.310718 samples/s, speed: 159.087453 tokens/s, learning rate: 4.510e-06, loss_scalings: 13421.773438, pp_loss: 9.317734
[INFO] 2021-07-12 18:37:56,805 [run_pretraining.py:  512]:	********exe.run_452******* 
[INFO] 2021-07-12 18:37:57,717 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:57,718 [run_pretraining.py:  534]:	loss/total_loss, 9.170013427734375, 453
[INFO] 2021-07-12 18:37:57,718 [run_pretraining.py:  535]:	loss/mlm_loss, 9.170013427734375, 453
[INFO] 2021-07-12 18:37:57,718 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.5199999476608355e-06, 453
[INFO] 2021-07-12 18:37:57,718 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 453
[INFO] 2021-07-12 18:37:57,718 [run_pretraining.py:  558]:	worker_index: 6, step: 453, cost: 9.170013, mlm loss: 9.170013, speed: 1.095585 steps/s, speed: 8.764683 samples/s, speed: 4487.517706 tokens/s, learning rate: 4.520e-06, loss_scalings: 13421.773438, pp_loss: 9.084576
[INFO] 2021-07-12 18:37:57,718 [run_pretraining.py:  512]:	********exe.run_453******* 
[INFO] 2021-07-12 18:37:58,628 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:58,629 [run_pretraining.py:  534]:	loss/total_loss, 9.55856704711914, 454
[INFO] 2021-07-12 18:37:58,629 [run_pretraining.py:  535]:	loss/mlm_loss, 9.55856704711914, 454
[INFO] 2021-07-12 18:37:58,629 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.529999841906829e-06, 454
[INFO] 2021-07-12 18:37:58,629 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 454
[INFO] 2021-07-12 18:37:58,629 [run_pretraining.py:  558]:	worker_index: 6, step: 454, cost: 9.558567, mlm loss: 9.558567, speed: 1.098319 steps/s, speed: 8.786555 samples/s, speed: 4498.716412 tokens/s, learning rate: 4.530e-06, loss_scalings: 13421.773438, pp_loss: 9.128867
[INFO] 2021-07-12 18:37:58,629 [run_pretraining.py:  512]:	********exe.run_454******* 
[INFO] 2021-07-12 18:37:59,533 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:59,534 [run_pretraining.py:  534]:	loss/total_loss, 8.91469955444336, 455
[INFO] 2021-07-12 18:37:59,534 [run_pretraining.py:  535]:	loss/mlm_loss, 8.91469955444336, 455
[INFO] 2021-07-12 18:37:59,534 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.540000190900173e-06, 455
[INFO] 2021-07-12 18:37:59,534 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 455
[INFO] 2021-07-12 18:37:59,534 [run_pretraining.py:  558]:	worker_index: 6, step: 455, cost: 8.914700, mlm loss: 8.914700, speed: 1.105967 steps/s, speed: 8.847739 samples/s, speed: 4530.042528 tokens/s, learning rate: 4.540e-06, loss_scalings: 13421.773438, pp_loss: 8.965270
[INFO] 2021-07-12 18:37:59,534 [run_pretraining.py:  512]:	********exe.run_455******* 
[INFO] 2021-07-12 18:38:00,440 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:00,440 [run_pretraining.py:  534]:	loss/total_loss, 9.321391105651855, 456
[INFO] 2021-07-12 18:38:00,440 [run_pretraining.py:  535]:	loss/mlm_loss, 9.321391105651855, 456
[INFO] 2021-07-12 18:38:00,441 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.5499996303988155e-06, 456
[INFO] 2021-07-12 18:38:00,441 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 456
[INFO] 2021-07-12 18:38:00,441 [run_pretraining.py:  558]:	worker_index: 6, step: 456, cost: 9.321391, mlm loss: 9.321391, speed: 1.103905 steps/s, speed: 8.831236 samples/s, speed: 4521.592925 tokens/s, learning rate: 4.550e-06, loss_scalings: 13421.773438, pp_loss: 9.161869
[INFO] 2021-07-12 18:38:00,441 [run_pretraining.py:  512]:	********exe.run_456******* 
[INFO] 2021-07-12 18:38:01,348 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:01,348 [run_pretraining.py:  534]:	loss/total_loss, 9.35997200012207, 457
[INFO] 2021-07-12 18:38:01,349 [run_pretraining.py:  535]:	loss/mlm_loss, 9.35997200012207, 457
[INFO] 2021-07-12 18:38:01,349 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.55999997939216e-06, 457
[INFO] 2021-07-12 18:38:01,349 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 457
[INFO] 2021-07-12 18:38:01,349 [run_pretraining.py:  558]:	worker_index: 6, step: 457, cost: 9.359972, mlm loss: 9.359972, speed: 1.102039 steps/s, speed: 8.816312 samples/s, speed: 4513.951496 tokens/s, learning rate: 4.560e-06, loss_scalings: 13421.773438, pp_loss: 9.115717
[INFO] 2021-07-12 18:38:01,349 [run_pretraining.py:  512]:	********exe.run_457******* 
[INFO] 2021-07-12 18:38:02,256 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:02,256 [run_pretraining.py:  534]:	loss/total_loss, 7.558646202087402, 458
[INFO] 2021-07-12 18:38:02,257 [run_pretraining.py:  535]:	loss/mlm_loss, 7.558646202087402, 458
[INFO] 2021-07-12 18:38:02,257 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.569999873638153e-06, 458
[INFO] 2021-07-12 18:38:02,257 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 458
[INFO] 2021-07-12 18:38:02,257 [run_pretraining.py:  558]:	worker_index: 6, step: 458, cost: 7.558646, mlm loss: 7.558646, speed: 1.102217 steps/s, speed: 8.817736 samples/s, speed: 4514.681020 tokens/s, learning rate: 4.570e-06, loss_scalings: 13421.773438, pp_loss: 8.825192
[INFO] 2021-07-12 18:38:02,257 [run_pretraining.py:  512]:	********exe.run_458******* 
[INFO] 2021-07-12 18:38:03,164 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:03,165 [run_pretraining.py:  534]:	loss/total_loss, 9.326594352722168, 459
[INFO] 2021-07-12 18:38:03,165 [run_pretraining.py:  535]:	loss/mlm_loss, 9.326594352722168, 459
[INFO] 2021-07-12 18:38:03,165 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.579999767884146e-06, 459
[INFO] 2021-07-12 18:38:03,165 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 459
[INFO] 2021-07-12 18:38:03,165 [run_pretraining.py:  558]:	worker_index: 6, step: 459, cost: 9.326594, mlm loss: 9.326594, speed: 1.101857 steps/s, speed: 8.814859 samples/s, speed: 4513.207981 tokens/s, learning rate: 4.580e-06, loss_scalings: 13421.773438, pp_loss: 9.304187
[INFO] 2021-07-12 18:38:03,165 [run_pretraining.py:  512]:	********exe.run_459******* 
[INFO] 2021-07-12 18:38:04,077 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:04,078 [run_pretraining.py:  534]:	loss/total_loss, 9.363000869750977, 460
[INFO] 2021-07-12 18:38:04,078 [run_pretraining.py:  535]:	loss/mlm_loss, 9.363000869750977, 460
[INFO] 2021-07-12 18:38:04,078 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.58999966213014e-06, 460
[INFO] 2021-07-12 18:38:04,078 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 460
[INFO] 2021-07-12 18:38:04,078 [run_pretraining.py:  558]:	worker_index: 6, step: 460, cost: 9.363001, mlm loss: 9.363001, speed: 1.096041 steps/s, speed: 8.768332 samples/s, speed: 4489.385758 tokens/s, learning rate: 4.590e-06, loss_scalings: 13421.773438, pp_loss: 9.219360
[INFO] 2021-07-12 18:38:04,078 [run_pretraining.py:  512]:	********exe.run_460******* 
[INFO] 2021-07-12 18:38:04,984 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:04,984 [run_pretraining.py:  534]:	loss/total_loss, 9.294075012207031, 461
[INFO] 2021-07-12 18:38:04,984 [run_pretraining.py:  535]:	loss/mlm_loss, 9.294075012207031, 461
[INFO] 2021-07-12 18:38:04,985 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.600000011123484e-06, 461
[INFO] 2021-07-12 18:38:04,985 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 461
[INFO] 2021-07-12 18:38:04,985 [run_pretraining.py:  558]:	worker_index: 6, step: 461, cost: 9.294075, mlm loss: 9.294075, speed: 1.103913 steps/s, speed: 8.831306 samples/s, speed: 4521.628626 tokens/s, learning rate: 4.600e-06, loss_scalings: 13421.773438, pp_loss: 8.336298
[INFO] 2021-07-12 18:38:04,985 [run_pretraining.py:  512]:	********exe.run_461******* 
[INFO] 2021-07-12 18:38:05,896 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:05,897 [run_pretraining.py:  534]:	loss/total_loss, 8.041702270507812, 462
[INFO] 2021-07-12 18:38:05,897 [run_pretraining.py:  535]:	loss/mlm_loss, 8.041702270507812, 462
[INFO] 2021-07-12 18:38:05,897 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.609999905369477e-06, 462
[INFO] 2021-07-12 18:38:05,897 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 462
[INFO] 2021-07-12 18:38:05,897 [run_pretraining.py:  558]:	worker_index: 6, step: 462, cost: 8.041702, mlm loss: 8.041702, speed: 1.096649 steps/s, speed: 8.773190 samples/s, speed: 4491.873043 tokens/s, learning rate: 4.610e-06, loss_scalings: 13421.773438, pp_loss: 8.716000
[INFO] 2021-07-12 18:38:05,897 [run_pretraining.py:  512]:	********exe.run_462******* 
[INFO] 2021-07-12 18:38:06,803 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:06,803 [run_pretraining.py:  534]:	loss/total_loss, 8.996358871459961, 463
[INFO] 2021-07-12 18:38:06,803 [run_pretraining.py:  535]:	loss/mlm_loss, 8.996358871459961, 463
[INFO] 2021-07-12 18:38:06,804 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.619999799615471e-06, 463
[INFO] 2021-07-12 18:38:06,804 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 463
[INFO] 2021-07-12 18:38:06,804 [run_pretraining.py:  558]:	worker_index: 6, step: 463, cost: 8.996359, mlm loss: 8.996359, speed: 1.104224 steps/s, speed: 8.833796 samples/s, speed: 4522.903543 tokens/s, learning rate: 4.620e-06, loss_scalings: 13421.773438, pp_loss: 9.195658
[INFO] 2021-07-12 18:38:06,804 [run_pretraining.py:  512]:	********exe.run_463******* 
[INFO] 2021-07-12 18:38:07,712 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:07,713 [run_pretraining.py:  534]:	loss/total_loss, 5.667585849761963, 464
[INFO] 2021-07-12 18:38:07,713 [run_pretraining.py:  535]:	loss/mlm_loss, 5.667585849761963, 464
[INFO] 2021-07-12 18:38:07,713 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.630000148608815e-06, 464
[INFO] 2021-07-12 18:38:07,713 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 464
[INFO] 2021-07-12 18:38:07,713 [run_pretraining.py:  558]:	worker_index: 6, step: 464, cost: 5.667586, mlm loss: 5.667586, speed: 1.100685 steps/s, speed: 8.805477 samples/s, speed: 4508.404166 tokens/s, learning rate: 4.630e-06, loss_scalings: 13421.773438, pp_loss: 8.398409
[INFO] 2021-07-12 18:38:07,713 [run_pretraining.py:  512]:	********exe.run_464******* 
[INFO] 2021-07-12 18:38:08,617 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:08,618 [run_pretraining.py:  534]:	loss/total_loss, 9.300153732299805, 465
[INFO] 2021-07-12 18:38:08,618 [run_pretraining.py:  535]:	loss/mlm_loss, 9.300153732299805, 465
[INFO] 2021-07-12 18:38:08,618 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.640000042854808e-06, 465
[INFO] 2021-07-12 18:38:08,618 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 465
[INFO] 2021-07-12 18:38:08,618 [run_pretraining.py:  558]:	worker_index: 6, step: 465, cost: 9.300154, mlm loss: 9.300154, speed: 1.105717 steps/s, speed: 8.845733 samples/s, speed: 4529.015494 tokens/s, learning rate: 4.640e-06, loss_scalings: 13421.773438, pp_loss: 9.150978
[INFO] 2021-07-12 18:38:08,618 [run_pretraining.py:  512]:	********exe.run_465******* 
[INFO] 2021-07-12 18:38:09,533 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:09,534 [run_pretraining.py:  534]:	loss/total_loss, 9.032478332519531, 466
[INFO] 2021-07-12 18:38:09,534 [run_pretraining.py:  535]:	loss/mlm_loss, 9.032478332519531, 466
[INFO] 2021-07-12 18:38:09,534 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.649999937100802e-06, 466
[INFO] 2021-07-12 18:38:09,534 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 466
[INFO] 2021-07-12 18:38:09,534 [run_pretraining.py:  558]:	worker_index: 6, step: 466, cost: 9.032478, mlm loss: 9.032478, speed: 1.092506 steps/s, speed: 8.740045 samples/s, speed: 4474.903152 tokens/s, learning rate: 4.650e-06, loss_scalings: 13421.773438, pp_loss: 9.015230
[INFO] 2021-07-12 18:38:09,534 [run_pretraining.py:  512]:	********exe.run_466******* 
[INFO] 2021-07-12 18:38:10,435 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:10,435 [run_pretraining.py:  534]:	loss/total_loss, 9.408077239990234, 467
[INFO] 2021-07-12 18:38:10,435 [run_pretraining.py:  535]:	loss/mlm_loss, 9.408077239990234, 467
[INFO] 2021-07-12 18:38:10,436 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.659999831346795e-06, 467
[INFO] 2021-07-12 18:38:10,436 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 467
[INFO] 2021-07-12 18:38:10,436 [run_pretraining.py:  558]:	worker_index: 6, step: 467, cost: 9.408077, mlm loss: 9.408077, speed: 1.109963 steps/s, speed: 8.879707 samples/s, speed: 4546.409906 tokens/s, learning rate: 4.660e-06, loss_scalings: 13421.773438, pp_loss: 8.119570
[INFO] 2021-07-12 18:38:10,436 [run_pretraining.py:  512]:	********exe.run_467******* 
[INFO] 2021-07-12 18:38:11,352 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:11,352 [run_pretraining.py:  534]:	loss/total_loss, 9.865982055664062, 468
[INFO] 2021-07-12 18:38:11,353 [run_pretraining.py:  535]:	loss/mlm_loss, 9.865982055664062, 468
[INFO] 2021-07-12 18:38:11,353 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.670000180340139e-06, 468
[INFO] 2021-07-12 18:38:11,353 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 468
[INFO] 2021-07-12 18:38:11,353 [run_pretraining.py:  558]:	worker_index: 6, step: 468, cost: 9.865982, mlm loss: 9.865982, speed: 1.091338 steps/s, speed: 8.730701 samples/s, speed: 4470.118845 tokens/s, learning rate: 4.670e-06, loss_scalings: 13421.773438, pp_loss: 8.681588
[INFO] 2021-07-12 18:38:11,353 [run_pretraining.py:  512]:	********exe.run_468******* 
[INFO] 2021-07-12 18:38:12,263 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:12,264 [run_pretraining.py:  534]:	loss/total_loss, 9.177735328674316, 469
[INFO] 2021-07-12 18:38:12,264 [run_pretraining.py:  535]:	loss/mlm_loss, 9.177735328674316, 469
[INFO] 2021-07-12 18:38:12,264 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.679999619838782e-06, 469
[INFO] 2021-07-12 18:38:12,264 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 469
[INFO] 2021-07-12 18:38:12,264 [run_pretraining.py:  558]:	worker_index: 6, step: 469, cost: 9.177735, mlm loss: 9.177735, speed: 1.097897 steps/s, speed: 8.783177 samples/s, speed: 4496.986547 tokens/s, learning rate: 4.680e-06, loss_scalings: 13421.773438, pp_loss: 9.024068
[INFO] 2021-07-12 18:38:12,264 [run_pretraining.py:  512]:	********exe.run_469******* 
[INFO] 2021-07-12 18:38:13,168 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:13,169 [run_pretraining.py:  534]:	loss/total_loss, 9.359519004821777, 470
[INFO] 2021-07-12 18:38:13,169 [run_pretraining.py:  535]:	loss/mlm_loss, 9.359519004821777, 470
[INFO] 2021-07-12 18:38:13,169 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.689999968832126e-06, 470
[INFO] 2021-07-12 18:38:13,169 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 470
[INFO] 2021-07-12 18:38:13,169 [run_pretraining.py:  558]:	worker_index: 6, step: 470, cost: 9.359519, mlm loss: 9.359519, speed: 1.106247 steps/s, speed: 8.849977 samples/s, speed: 4531.188339 tokens/s, learning rate: 4.690e-06, loss_scalings: 13421.773438, pp_loss: 9.044890
[INFO] 2021-07-12 18:38:13,169 [run_pretraining.py:  512]:	********exe.run_470******* 
[INFO] 2021-07-12 18:38:14,086 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:14,086 [run_pretraining.py:  534]:	loss/total_loss, 9.25613784790039, 471
[INFO] 2021-07-12 18:38:14,086 [run_pretraining.py:  535]:	loss/mlm_loss, 9.25613784790039, 471
[INFO] 2021-07-12 18:38:14,087 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.699999863078119e-06, 471
[INFO] 2021-07-12 18:38:14,087 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 471
[INFO] 2021-07-12 18:38:14,087 [run_pretraining.py:  558]:	worker_index: 6, step: 471, cost: 9.256138, mlm loss: 9.256138, speed: 1.090427 steps/s, speed: 8.723413 samples/s, speed: 4466.387238 tokens/s, learning rate: 4.700e-06, loss_scalings: 13421.773438, pp_loss: 9.077081
[INFO] 2021-07-12 18:38:14,087 [run_pretraining.py:  512]:	********exe.run_471******* 
[INFO] 2021-07-12 18:38:14,995 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:14,996 [run_pretraining.py:  534]:	loss/total_loss, 9.157916069030762, 472
[INFO] 2021-07-12 18:38:14,996 [run_pretraining.py:  535]:	loss/mlm_loss, 9.157916069030762, 472
[INFO] 2021-07-12 18:38:14,996 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.709999757324113e-06, 472
[INFO] 2021-07-12 18:38:14,996 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 472
[INFO] 2021-07-12 18:38:14,996 [run_pretraining.py:  558]:	worker_index: 6, step: 472, cost: 9.157916, mlm loss: 9.157916, speed: 1.100124 steps/s, speed: 8.800992 samples/s, speed: 4506.107733 tokens/s, learning rate: 4.710e-06, loss_scalings: 13421.773438, pp_loss: 9.126885
[INFO] 2021-07-12 18:38:14,997 [run_pretraining.py:  512]:	********exe.run_472******* 
[INFO] 2021-07-12 18:38:15,943 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:15,944 [run_pretraining.py:  534]:	loss/total_loss, 9.000284194946289, 473
[INFO] 2021-07-12 18:38:15,944 [run_pretraining.py:  535]:	loss/mlm_loss, 9.000284194946289, 473
[INFO] 2021-07-12 18:38:15,944 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.720000106317457e-06, 473
[INFO] 2021-07-12 18:38:15,944 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 473
[INFO] 2021-07-12 18:38:15,944 [run_pretraining.py:  558]:	worker_index: 6, step: 473, cost: 9.000284, mlm loss: 9.000284, speed: 1.056072 steps/s, speed: 8.448576 samples/s, speed: 4325.670908 tokens/s, learning rate: 4.720e-06, loss_scalings: 13421.773438, pp_loss: 8.956152
[INFO] 2021-07-12 18:38:15,944 [run_pretraining.py:  512]:	********exe.run_473******* 
[INFO] 2021-07-12 18:38:16,846 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:16,846 [run_pretraining.py:  534]:	loss/total_loss, 8.655303955078125, 474
[INFO] 2021-07-12 18:38:16,846 [run_pretraining.py:  535]:	loss/mlm_loss, 8.655303955078125, 474
[INFO] 2021-07-12 18:38:16,846 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.73000000056345e-06, 474
[INFO] 2021-07-12 18:38:16,846 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 474
[INFO] 2021-07-12 18:38:16,847 [run_pretraining.py:  558]:	worker_index: 6, step: 474, cost: 8.655304, mlm loss: 8.655304, speed: 1.108882 steps/s, speed: 8.871054 samples/s, speed: 4541.979441 tokens/s, learning rate: 4.730e-06, loss_scalings: 13421.773438, pp_loss: 9.024240
[INFO] 2021-07-12 18:38:16,847 [run_pretraining.py:  512]:	********exe.run_474******* 
[INFO] 2021-07-12 18:38:17,748 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:17,749 [run_pretraining.py:  534]:	loss/total_loss, 8.976816177368164, 475
[INFO] 2021-07-12 18:38:17,749 [run_pretraining.py:  535]:	loss/mlm_loss, 8.976816177368164, 475
[INFO] 2021-07-12 18:38:17,749 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.7399998948094435e-06, 475
[INFO] 2021-07-12 18:38:17,749 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 475
[INFO] 2021-07-12 18:38:17,749 [run_pretraining.py:  558]:	worker_index: 6, step: 475, cost: 8.976816, mlm loss: 8.976816, speed: 1.109103 steps/s, speed: 8.872822 samples/s, speed: 4542.885025 tokens/s, learning rate: 4.740e-06, loss_scalings: 13421.773438, pp_loss: 9.111633
[INFO] 2021-07-12 18:38:17,749 [run_pretraining.py:  512]:	********exe.run_475******* 
[INFO] 2021-07-12 18:38:18,667 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:18,668 [run_pretraining.py:  534]:	loss/total_loss, 9.163700103759766, 476
[INFO] 2021-07-12 18:38:18,668 [run_pretraining.py:  535]:	loss/mlm_loss, 9.163700103759766, 476
[INFO] 2021-07-12 18:38:18,668 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.749999789055437e-06, 476
[INFO] 2021-07-12 18:38:18,668 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 476
[INFO] 2021-07-12 18:38:18,668 [run_pretraining.py:  558]:	worker_index: 6, step: 476, cost: 9.163700, mlm loss: 9.163700, speed: 1.088333 steps/s, speed: 8.706662 samples/s, speed: 4457.811137 tokens/s, learning rate: 4.750e-06, loss_scalings: 13421.773438, pp_loss: 9.109789
[INFO] 2021-07-12 18:38:18,669 [run_pretraining.py:  512]:	********exe.run_476******* 
[INFO] 2021-07-12 18:38:19,579 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:19,580 [run_pretraining.py:  534]:	loss/total_loss, 8.864904403686523, 477
[INFO] 2021-07-12 18:38:19,580 [run_pretraining.py:  535]:	loss/mlm_loss, 8.864904403686523, 477
[INFO] 2021-07-12 18:38:19,580 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.760000138048781e-06, 477
[INFO] 2021-07-12 18:38:19,580 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 477
[INFO] 2021-07-12 18:38:19,580 [run_pretraining.py:  558]:	worker_index: 6, step: 477, cost: 8.864904, mlm loss: 8.864904, speed: 1.097800 steps/s, speed: 8.782402 samples/s, speed: 4496.589890 tokens/s, learning rate: 4.760e-06, loss_scalings: 13421.773438, pp_loss: 8.934126
[INFO] 2021-07-12 18:38:19,580 [run_pretraining.py:  512]:	********exe.run_477******* 
[INFO] 2021-07-12 18:38:20,499 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:20,500 [run_pretraining.py:  534]:	loss/total_loss, 9.31503677368164, 478
[INFO] 2021-07-12 18:38:20,500 [run_pretraining.py:  535]:	loss/mlm_loss, 9.31503677368164, 478
[INFO] 2021-07-12 18:38:20,500 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.7699995775474235e-06, 478
[INFO] 2021-07-12 18:38:20,500 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 478
[INFO] 2021-07-12 18:38:20,500 [run_pretraining.py:  558]:	worker_index: 6, step: 478, cost: 9.315037, mlm loss: 9.315037, speed: 1.087720 steps/s, speed: 8.701758 samples/s, speed: 4455.300184 tokens/s, learning rate: 4.770e-06, loss_scalings: 13421.773438, pp_loss: 9.149091
[INFO] 2021-07-12 18:38:20,500 [run_pretraining.py:  512]:	********exe.run_478******* 
[INFO] 2021-07-12 18:38:21,417 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:21,418 [run_pretraining.py:  534]:	loss/total_loss, 8.777910232543945, 479
[INFO] 2021-07-12 18:38:21,418 [run_pretraining.py:  535]:	loss/mlm_loss, 8.777910232543945, 479
[INFO] 2021-07-12 18:38:21,418 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.779999926540768e-06, 479
[INFO] 2021-07-12 18:38:21,418 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 479
[INFO] 2021-07-12 18:38:21,418 [run_pretraining.py:  558]:	worker_index: 6, step: 479, cost: 8.777910, mlm loss: 8.777910, speed: 1.090221 steps/s, speed: 8.721766 samples/s, speed: 4465.544394 tokens/s, learning rate: 4.780e-06, loss_scalings: 13421.773438, pp_loss: 8.763737
[INFO] 2021-07-12 18:38:21,418 [run_pretraining.py:  512]:	********exe.run_479******* 
[INFO] 2021-07-12 18:38:22,321 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:22,321 [run_pretraining.py:  534]:	loss/total_loss, 9.087092399597168, 480
[INFO] 2021-07-12 18:38:22,322 [run_pretraining.py:  535]:	loss/mlm_loss, 9.087092399597168, 480
[INFO] 2021-07-12 18:38:22,322 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.789999820786761e-06, 480
[INFO] 2021-07-12 18:38:22,322 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 480
[INFO] 2021-07-12 18:38:22,322 [run_pretraining.py:  558]:	worker_index: 6, step: 480, cost: 9.087092, mlm loss: 9.087092, speed: 1.107313 steps/s, speed: 8.858505 samples/s, speed: 4535.554659 tokens/s, learning rate: 4.790e-06, loss_scalings: 13421.773438, pp_loss: 9.060211
[INFO] 2021-07-12 18:38:22,322 [run_pretraining.py:  512]:	********exe.run_480******* 
[INFO] 2021-07-12 18:38:23,236 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:23,236 [run_pretraining.py:  534]:	loss/total_loss, 9.280715942382812, 481
[INFO] 2021-07-12 18:38:23,236 [run_pretraining.py:  535]:	loss/mlm_loss, 9.280715942382812, 481
[INFO] 2021-07-12 18:38:23,236 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.7999997150327545e-06, 481
[INFO] 2021-07-12 18:38:23,236 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 481
[INFO] 2021-07-12 18:38:23,237 [run_pretraining.py:  558]:	worker_index: 6, step: 481, cost: 9.280716, mlm loss: 9.280716, speed: 1.094115 steps/s, speed: 8.752922 samples/s, speed: 4481.496128 tokens/s, learning rate: 4.800e-06, loss_scalings: 13421.773438, pp_loss: 9.176203
[INFO] 2021-07-12 18:38:23,237 [run_pretraining.py:  512]:	********exe.run_481******* 
[INFO] 2021-07-12 18:38:24,132 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:24,133 [run_pretraining.py:  534]:	loss/total_loss, 9.639814376831055, 482
[INFO] 2021-07-12 18:38:24,133 [run_pretraining.py:  535]:	loss/mlm_loss, 9.639814376831055, 482
[INFO] 2021-07-12 18:38:24,133 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.809999609278748e-06, 482
[INFO] 2021-07-12 18:38:24,133 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 482
[INFO] 2021-07-12 18:38:24,133 [run_pretraining.py:  558]:	worker_index: 6, step: 482, cost: 9.639814, mlm loss: 9.639814, speed: 1.116437 steps/s, speed: 8.931493 samples/s, speed: 4572.924510 tokens/s, learning rate: 4.810e-06, loss_scalings: 13421.773438, pp_loss: 9.139313
[INFO] 2021-07-12 18:38:24,133 [run_pretraining.py:  512]:	********exe.run_482******* 
[INFO] 2021-07-12 18:38:25,038 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:25,038 [run_pretraining.py:  534]:	loss/total_loss, 9.059008598327637, 483
[INFO] 2021-07-12 18:38:25,038 [run_pretraining.py:  535]:	loss/mlm_loss, 9.059008598327637, 483
[INFO] 2021-07-12 18:38:25,038 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.819999958272092e-06, 483
[INFO] 2021-07-12 18:38:25,039 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 483
[INFO] 2021-07-12 18:38:25,039 [run_pretraining.py:  558]:	worker_index: 6, step: 483, cost: 9.059009, mlm loss: 9.059009, speed: 1.105091 steps/s, speed: 8.840725 samples/s, speed: 4526.451139 tokens/s, learning rate: 4.820e-06, loss_scalings: 13421.773438, pp_loss: 8.243670
[INFO] 2021-07-12 18:38:25,039 [run_pretraining.py:  512]:	********exe.run_483******* 
[INFO] 2021-07-12 18:38:25,950 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:25,950 [run_pretraining.py:  534]:	loss/total_loss, 6.26071310043335, 484
[INFO] 2021-07-12 18:38:25,950 [run_pretraining.py:  535]:	loss/mlm_loss, 6.26071310043335, 484
[INFO] 2021-07-12 18:38:25,950 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.829999852518085e-06, 484
[INFO] 2021-07-12 18:38:25,951 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 484
[INFO] 2021-07-12 18:38:25,951 [run_pretraining.py:  558]:	worker_index: 6, step: 484, cost: 6.260713, mlm loss: 6.260713, speed: 1.097345 steps/s, speed: 8.778763 samples/s, speed: 4494.726422 tokens/s, learning rate: 4.830e-06, loss_scalings: 13421.773438, pp_loss: 8.236525
[INFO] 2021-07-12 18:38:25,951 [run_pretraining.py:  512]:	********exe.run_484******* 
[INFO] 2021-07-12 18:38:51,796 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:51,797 [run_pretraining.py:  534]:	loss/total_loss, 8.932465553283691, 485
[INFO] 2021-07-12 18:38:51,797 [run_pretraining.py:  535]:	loss/mlm_loss, 8.932465553283691, 485
[INFO] 2021-07-12 18:38:51,797 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.839999746764079e-06, 485
[INFO] 2021-07-12 18:38:51,797 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 485
[INFO] 2021-07-12 18:38:51,797 [run_pretraining.py:  558]:	worker_index: 6, step: 485, cost: 8.932466, mlm loss: 8.932466, speed: 0.038690 steps/s, speed: 0.309524 samples/s, speed: 158.476201 tokens/s, learning rate: 4.840e-06, loss_scalings: 13421.773438, pp_loss: 8.932463
[INFO] 2021-07-12 18:38:51,798 [run_pretraining.py:  512]:	********exe.run_485******* 
[INFO] 2021-07-12 18:38:52,690 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:52,690 [run_pretraining.py:  534]:	loss/total_loss, 8.871082305908203, 486
[INFO] 2021-07-12 18:38:52,691 [run_pretraining.py:  535]:	loss/mlm_loss, 8.871082305908203, 486
[INFO] 2021-07-12 18:38:52,691 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.850000095757423e-06, 486
[INFO] 2021-07-12 18:38:52,691 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 486
[INFO] 2021-07-12 18:38:52,691 [run_pretraining.py:  558]:	worker_index: 6, step: 486, cost: 8.871082, mlm loss: 8.871082, speed: 1.120257 steps/s, speed: 8.962059 samples/s, speed: 4588.574092 tokens/s, learning rate: 4.850e-06, loss_scalings: 13421.773438, pp_loss: 8.734518
[INFO] 2021-07-12 18:38:52,691 [run_pretraining.py:  512]:	********exe.run_486******* 
[INFO] 2021-07-12 18:39:19,133 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:19,134 [run_pretraining.py:  534]:	loss/total_loss, 8.472457885742188, 487
[INFO] 2021-07-12 18:39:19,134 [run_pretraining.py:  535]:	loss/mlm_loss, 8.472457885742188, 487
[INFO] 2021-07-12 18:39:19,134 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.859999990003416e-06, 487
[INFO] 2021-07-12 18:39:19,134 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 487
[INFO] 2021-07-12 18:39:19,134 [run_pretraining.py:  558]:	worker_index: 6, step: 487, cost: 8.472458, mlm loss: 8.472458, speed: 0.037818 steps/s, speed: 0.302543 samples/s, speed: 154.902246 tokens/s, learning rate: 4.860e-06, loss_scalings: 13421.773438, pp_loss: 8.948746
[INFO] 2021-07-12 18:39:19,134 [run_pretraining.py:  512]:	********exe.run_487******* 
[INFO] 2021-07-12 18:39:44,481 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:44,481 [run_pretraining.py:  534]:	loss/total_loss, 8.857282638549805, 488
[INFO] 2021-07-12 18:39:44,481 [run_pretraining.py:  535]:	loss/mlm_loss, 8.857282638549805, 488
[INFO] 2021-07-12 18:39:44,481 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.86999988424941e-06, 488
[INFO] 2021-07-12 18:39:44,481 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 488
[INFO] 2021-07-12 18:39:44,482 [run_pretraining.py:  558]:	worker_index: 6, step: 488, cost: 8.857283, mlm loss: 8.857283, speed: 0.039453 steps/s, speed: 0.315623 samples/s, speed: 161.598910 tokens/s, learning rate: 4.870e-06, loss_scalings: 13421.773438, pp_loss: 8.949476
[INFO] 2021-07-12 18:39:44,482 [run_pretraining.py:  512]:	********exe.run_488******* 
[INFO] 2021-07-12 18:39:45,393 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:45,394 [run_pretraining.py:  534]:	loss/total_loss, 9.455595016479492, 489
[INFO] 2021-07-12 18:39:45,394 [run_pretraining.py:  535]:	loss/mlm_loss, 9.455595016479492, 489
[INFO] 2021-07-12 18:39:45,394 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.879999778495403e-06, 489
[INFO] 2021-07-12 18:39:45,394 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 489
[INFO] 2021-07-12 18:39:45,394 [run_pretraining.py:  558]:	worker_index: 6, step: 489, cost: 9.455595, mlm loss: 9.455595, speed: 1.096540 steps/s, speed: 8.772323 samples/s, speed: 4491.429144 tokens/s, learning rate: 4.880e-06, loss_scalings: 13421.773438, pp_loss: 9.140446
[INFO] 2021-07-12 18:39:45,394 [run_pretraining.py:  512]:	********exe.run_489******* 
[INFO] 2021-07-12 18:39:46,302 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:46,302 [run_pretraining.py:  534]:	loss/total_loss, 8.332204818725586, 490
[INFO] 2021-07-12 18:39:46,303 [run_pretraining.py:  535]:	loss/mlm_loss, 8.332204818725586, 490
[INFO] 2021-07-12 18:39:46,303 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.890000127488747e-06, 490
[INFO] 2021-07-12 18:39:46,303 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 490
[INFO] 2021-07-12 18:39:46,303 [run_pretraining.py:  558]:	worker_index: 6, step: 490, cost: 8.332205, mlm loss: 8.332205, speed: 1.101513 steps/s, speed: 8.812105 samples/s, speed: 4511.797517 tokens/s, learning rate: 4.890e-06, loss_scalings: 13421.773438, pp_loss: 8.700878
[INFO] 2021-07-12 18:39:46,303 [run_pretraining.py:  512]:	********exe.run_490******* 
[INFO] 2021-07-12 18:39:47,211 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:47,211 [run_pretraining.py:  534]:	loss/total_loss, 8.32483196258545, 491
[INFO] 2021-07-12 18:39:47,211 [run_pretraining.py:  535]:	loss/mlm_loss, 8.32483196258545, 491
[INFO] 2021-07-12 18:39:47,211 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.89999956698739e-06, 491
[INFO] 2021-07-12 18:39:47,212 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 491
[INFO] 2021-07-12 18:39:47,212 [run_pretraining.py:  558]:	worker_index: 6, step: 491, cost: 8.324832, mlm loss: 8.324832, speed: 1.101208 steps/s, speed: 8.809664 samples/s, speed: 4510.547800 tokens/s, learning rate: 4.900e-06, loss_scalings: 13421.773438, pp_loss: 8.749953
[INFO] 2021-07-12 18:39:47,212 [run_pretraining.py:  512]:	********exe.run_491******* 
[INFO] 2021-07-12 18:39:48,119 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:48,120 [run_pretraining.py:  534]:	loss/total_loss, 9.001786231994629, 492
[INFO] 2021-07-12 18:39:48,120 [run_pretraining.py:  535]:	loss/mlm_loss, 9.001786231994629, 492
[INFO] 2021-07-12 18:39:48,120 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.909999915980734e-06, 492
[INFO] 2021-07-12 18:39:48,120 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 492
[INFO] 2021-07-12 18:39:48,120 [run_pretraining.py:  558]:	worker_index: 6, step: 492, cost: 9.001786, mlm loss: 9.001786, speed: 1.101192 steps/s, speed: 8.809534 samples/s, speed: 4510.481484 tokens/s, learning rate: 4.910e-06, loss_scalings: 13421.773438, pp_loss: 9.013639
[INFO] 2021-07-12 18:39:48,121 [run_pretraining.py:  512]:	********exe.run_492******* 
[INFO] 2021-07-12 18:39:49,028 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:49,028 [run_pretraining.py:  534]:	loss/total_loss, 8.970296859741211, 493
[INFO] 2021-07-12 18:39:49,028 [run_pretraining.py:  535]:	loss/mlm_loss, 8.970296859741211, 493
[INFO] 2021-07-12 18:39:49,028 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.919999810226727e-06, 493
[INFO] 2021-07-12 18:39:49,029 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 493
[INFO] 2021-07-12 18:39:49,029 [run_pretraining.py:  558]:	worker_index: 6, step: 493, cost: 8.970297, mlm loss: 8.970297, speed: 1.101961 steps/s, speed: 8.815688 samples/s, speed: 4513.632478 tokens/s, learning rate: 4.920e-06, loss_scalings: 13421.773438, pp_loss: 9.018869
[INFO] 2021-07-12 18:39:49,029 [run_pretraining.py:  512]:	********exe.run_493******* 
[INFO] 2021-07-12 18:39:49,930 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:49,931 [run_pretraining.py:  534]:	loss/total_loss, 9.101580619812012, 494
[INFO] 2021-07-12 18:39:49,931 [run_pretraining.py:  535]:	loss/mlm_loss, 9.101580619812012, 494
[INFO] 2021-07-12 18:39:49,931 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.929999704472721e-06, 494
[INFO] 2021-07-12 18:39:49,931 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 494
[INFO] 2021-07-12 18:39:49,931 [run_pretraining.py:  558]:	worker_index: 6, step: 494, cost: 9.101581, mlm loss: 9.101581, speed: 1.108590 steps/s, speed: 8.868718 samples/s, speed: 4540.783760 tokens/s, learning rate: 4.930e-06, loss_scalings: 13421.773438, pp_loss: 9.021536
[INFO] 2021-07-12 18:39:49,931 [run_pretraining.py:  512]:	********exe.run_494******* 
[INFO] 2021-07-12 18:39:50,835 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:50,836 [run_pretraining.py:  534]:	loss/total_loss, 9.447165489196777, 495
[INFO] 2021-07-12 18:39:50,836 [run_pretraining.py:  535]:	loss/mlm_loss, 9.447165489196777, 495
[INFO] 2021-07-12 18:39:50,836 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.940000053466065e-06, 495
[INFO] 2021-07-12 18:39:50,836 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 495
[INFO] 2021-07-12 18:39:50,836 [run_pretraining.py:  558]:	worker_index: 6, step: 495, cost: 9.447165, mlm loss: 9.447165, speed: 1.106171 steps/s, speed: 8.849368 samples/s, speed: 4530.876440 tokens/s, learning rate: 4.940e-06, loss_scalings: 13421.773438, pp_loss: 9.037850
[INFO] 2021-07-12 18:39:50,836 [run_pretraining.py:  512]:	********exe.run_495******* 
[INFO] 2021-07-12 18:39:51,735 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:51,735 [run_pretraining.py:  534]:	loss/total_loss, 9.09013557434082, 496
[INFO] 2021-07-12 18:39:51,735 [run_pretraining.py:  535]:	loss/mlm_loss, 9.09013557434082, 496
[INFO] 2021-07-12 18:39:51,735 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.949999947712058e-06, 496
[INFO] 2021-07-12 18:39:51,735 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 496
[INFO] 2021-07-12 18:39:51,736 [run_pretraining.py:  558]:	worker_index: 6, step: 496, cost: 9.090136, mlm loss: 9.090136, speed: 1.112751 steps/s, speed: 8.902009 samples/s, speed: 4557.828670 tokens/s, learning rate: 4.950e-06, loss_scalings: 13421.773438, pp_loss: 9.276270
[INFO] 2021-07-12 18:39:51,736 [run_pretraining.py:  512]:	********exe.run_496******* 
[INFO] 2021-07-12 18:39:52,646 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:52,647 [run_pretraining.py:  534]:	loss/total_loss, 8.633922576904297, 497
[INFO] 2021-07-12 18:39:52,647 [run_pretraining.py:  535]:	loss/mlm_loss, 8.633922576904297, 497
[INFO] 2021-07-12 18:39:52,647 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.9599998419580515e-06, 497
[INFO] 2021-07-12 18:39:52,647 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 497
[INFO] 2021-07-12 18:39:52,647 [run_pretraining.py:  558]:	worker_index: 6, step: 497, cost: 8.633923, mlm loss: 8.633923, speed: 1.098011 steps/s, speed: 8.784085 samples/s, speed: 4497.451560 tokens/s, learning rate: 4.960e-06, loss_scalings: 13421.773438, pp_loss: 8.999687
[INFO] 2021-07-12 18:39:52,647 [run_pretraining.py:  512]:	********exe.run_497******* 
[INFO] 2021-07-12 18:39:53,562 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:53,563 [run_pretraining.py:  534]:	loss/total_loss, 8.746665000915527, 498
[INFO] 2021-07-12 18:39:53,563 [run_pretraining.py:  535]:	loss/mlm_loss, 8.746665000915527, 498
[INFO] 2021-07-12 18:39:53,563 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.969999736204045e-06, 498
[INFO] 2021-07-12 18:39:53,563 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 498
[INFO] 2021-07-12 18:39:53,563 [run_pretraining.py:  558]:	worker_index: 6, step: 498, cost: 8.746665, mlm loss: 8.746665, speed: 1.092243 steps/s, speed: 8.737944 samples/s, speed: 4473.827567 tokens/s, learning rate: 4.970e-06, loss_scalings: 13421.773438, pp_loss: 8.723399
[INFO] 2021-07-12 18:39:53,563 [run_pretraining.py:  512]:	********exe.run_498******* 
[INFO] 2021-07-12 18:39:54,472 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:54,473 [run_pretraining.py:  534]:	loss/total_loss, 8.688676834106445, 499
[INFO] 2021-07-12 18:39:54,473 [run_pretraining.py:  535]:	loss/mlm_loss, 8.688676834106445, 499
[INFO] 2021-07-12 18:39:54,473 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.980000085197389e-06, 499
[INFO] 2021-07-12 18:39:54,473 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 499
[INFO] 2021-07-12 18:39:54,473 [run_pretraining.py:  558]:	worker_index: 6, step: 499, cost: 8.688677, mlm loss: 8.688677, speed: 1.100057 steps/s, speed: 8.800456 samples/s, speed: 4505.833547 tokens/s, learning rate: 4.980e-06, loss_scalings: 13421.773438, pp_loss: 8.915312
[INFO] 2021-07-12 18:39:54,473 [run_pretraining.py:  512]:	********exe.run_499******* 
[INFO] 2021-07-12 18:39:55,387 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:55,387 [run_pretraining.py:  534]:	loss/total_loss, 9.433016777038574, 500
[INFO] 2021-07-12 18:39:55,388 [run_pretraining.py:  535]:	loss/mlm_loss, 9.433016777038574, 500
[INFO] 2021-07-12 18:39:55,388 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.9899999794433825e-06, 500
[INFO] 2021-07-12 18:39:55,388 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 500
[INFO] 2021-07-12 18:39:55,388 [run_pretraining.py:  558]:	worker_index: 6, step: 500, cost: 9.433017, mlm loss: 9.433017, speed: 1.093913 steps/s, speed: 8.751301 samples/s, speed: 4480.666269 tokens/s, learning rate: 4.990e-06, loss_scalings: 13421.773438, pp_loss: 9.124880
[INFO] 2021-07-12 18:39:55,388 [run_pretraining.py:  512]:	********exe.run_500******* 
[INFO] 2021-07-12 18:39:56,286 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:56,287 [run_pretraining.py:  534]:	loss/total_loss, 8.811873435974121, 501
[INFO] 2021-07-12 18:39:56,287 [run_pretraining.py:  535]:	loss/mlm_loss, 8.811873435974121, 501
[INFO] 2021-07-12 18:39:56,287 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.999999873689376e-06, 501
[INFO] 2021-07-12 18:39:56,287 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 501
[INFO] 2021-07-12 18:39:56,287 [run_pretraining.py:  558]:	worker_index: 6, step: 501, cost: 8.811873, mlm loss: 8.811873, speed: 1.112696 steps/s, speed: 8.901568 samples/s, speed: 4557.602562 tokens/s, learning rate: 5.000e-06, loss_scalings: 13421.773438, pp_loss: 8.943892
[INFO] 2021-07-12 18:39:56,287 [run_pretraining.py:  512]:	********exe.run_501******* 
[INFO] 2021-07-12 18:39:57,196 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:57,197 [run_pretraining.py:  534]:	loss/total_loss, 8.79695987701416, 502
[INFO] 2021-07-12 18:39:57,197 [run_pretraining.py:  535]:	loss/mlm_loss, 8.79695987701416, 502
[INFO] 2021-07-12 18:39:57,197 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.009999767935369e-06, 502
[INFO] 2021-07-12 18:39:57,197 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 502
[INFO] 2021-07-12 18:39:57,197 [run_pretraining.py:  558]:	worker_index: 6, step: 502, cost: 8.796960, mlm loss: 8.796960, speed: 1.100119 steps/s, speed: 8.800950 samples/s, speed: 4506.086459 tokens/s, learning rate: 5.010e-06, loss_scalings: 13421.773438, pp_loss: 8.906084
[INFO] 2021-07-12 18:39:57,197 [run_pretraining.py:  512]:	********exe.run_502******* 
[INFO] 2021-07-12 18:39:58,105 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:58,105 [run_pretraining.py:  534]:	loss/total_loss, 8.767330169677734, 503
[INFO] 2021-07-12 18:39:58,106 [run_pretraining.py:  535]:	loss/mlm_loss, 8.767330169677734, 503
[INFO] 2021-07-12 18:39:58,106 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.020000116928713e-06, 503
[INFO] 2021-07-12 18:39:58,106 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 503
[INFO] 2021-07-12 18:39:58,106 [run_pretraining.py:  558]:	worker_index: 6, step: 503, cost: 8.767330, mlm loss: 8.767330, speed: 1.101245 steps/s, speed: 8.809962 samples/s, speed: 4510.700572 tokens/s, learning rate: 5.020e-06, loss_scalings: 13421.773438, pp_loss: 9.150009
[INFO] 2021-07-12 18:39:58,106 [run_pretraining.py:  512]:	********exe.run_503******* 
[INFO] 2021-07-12 18:39:59,020 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:59,020 [run_pretraining.py:  534]:	loss/total_loss, 8.770800590515137, 504
[INFO] 2021-07-12 18:39:59,020 [run_pretraining.py:  535]:	loss/mlm_loss, 8.770800590515137, 504
[INFO] 2021-07-12 18:39:59,020 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.029999556427356e-06, 504
[INFO] 2021-07-12 18:39:59,021 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 504
[INFO] 2021-07-12 18:39:59,021 [run_pretraining.py:  558]:	worker_index: 6, step: 504, cost: 8.770801, mlm loss: 8.770801, speed: 1.093981 steps/s, speed: 8.751845 samples/s, speed: 4480.944413 tokens/s, learning rate: 5.030e-06, loss_scalings: 13421.773438, pp_loss: 8.933332
[INFO] 2021-07-12 18:39:59,021 [run_pretraining.py:  512]:	********exe.run_504******* 
[INFO] 2021-07-12 18:39:59,923 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:59,923 [run_pretraining.py:  534]:	loss/total_loss, 9.270057678222656, 505
[INFO] 2021-07-12 18:39:59,923 [run_pretraining.py:  535]:	loss/mlm_loss, 9.270057678222656, 505
[INFO] 2021-07-12 18:39:59,923 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.0399999054207e-06, 505
[INFO] 2021-07-12 18:39:59,923 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 505
[INFO] 2021-07-12 18:39:59,924 [run_pretraining.py:  558]:	worker_index: 6, step: 505, cost: 9.270058, mlm loss: 9.270058, speed: 1.108361 steps/s, speed: 8.866890 samples/s, speed: 4539.847823 tokens/s, learning rate: 5.040e-06, loss_scalings: 13421.773438, pp_loss: 8.142704
[INFO] 2021-07-12 18:39:59,924 [run_pretraining.py:  512]:	********exe.run_505******* 
[INFO] 2021-07-12 18:40:00,836 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:00,837 [run_pretraining.py:  534]:	loss/total_loss, 8.55636215209961, 506
[INFO] 2021-07-12 18:40:00,837 [run_pretraining.py:  535]:	loss/mlm_loss, 8.55636215209961, 506
[INFO] 2021-07-12 18:40:00,837 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.050000254414044e-06, 506
[INFO] 2021-07-12 18:40:00,837 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 506
[INFO] 2021-07-12 18:40:00,837 [run_pretraining.py:  558]:	worker_index: 6, step: 506, cost: 8.556362, mlm loss: 8.556362, speed: 1.095542 steps/s, speed: 8.764337 samples/s, speed: 4487.340714 tokens/s, learning rate: 5.050e-06, loss_scalings: 13421.773438, pp_loss: 8.696704
[INFO] 2021-07-12 18:40:00,837 [run_pretraining.py:  512]:	********exe.run_506******* 
[INFO] 2021-07-12 18:40:01,751 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:01,752 [run_pretraining.py:  534]:	loss/total_loss, 8.544282913208008, 507
[INFO] 2021-07-12 18:40:01,752 [run_pretraining.py:  535]:	loss/mlm_loss, 8.544282913208008, 507
[INFO] 2021-07-12 18:40:01,752 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.059999693912687e-06, 507
[INFO] 2021-07-12 18:40:01,752 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 507
[INFO] 2021-07-12 18:40:01,752 [run_pretraining.py:  558]:	worker_index: 6, step: 507, cost: 8.544283, mlm loss: 8.544283, speed: 1.093609 steps/s, speed: 8.748873 samples/s, speed: 4479.423225 tokens/s, learning rate: 5.060e-06, loss_scalings: 13421.773438, pp_loss: 8.780161
[INFO] 2021-07-12 18:40:01,752 [run_pretraining.py:  512]:	********exe.run_507******* 
[INFO] 2021-07-12 18:40:02,656 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:02,657 [run_pretraining.py:  534]:	loss/total_loss, 8.782036781311035, 508
[INFO] 2021-07-12 18:40:02,657 [run_pretraining.py:  535]:	loss/mlm_loss, 8.782036781311035, 508
[INFO] 2021-07-12 18:40:02,657 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.070000042906031e-06, 508
[INFO] 2021-07-12 18:40:02,657 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 508
[INFO] 2021-07-12 18:40:02,657 [run_pretraining.py:  558]:	worker_index: 6, step: 508, cost: 8.782037, mlm loss: 8.782037, speed: 1.105712 steps/s, speed: 8.845698 samples/s, speed: 4528.997585 tokens/s, learning rate: 5.070e-06, loss_scalings: 13421.773438, pp_loss: 8.798071
[INFO] 2021-07-12 18:40:02,657 [run_pretraining.py:  512]:	********exe.run_508******* 
[INFO] 2021-07-12 18:40:03,566 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:03,567 [run_pretraining.py:  534]:	loss/total_loss, 9.136030197143555, 509
[INFO] 2021-07-12 18:40:03,567 [run_pretraining.py:  535]:	loss/mlm_loss, 9.136030197143555, 509
[INFO] 2021-07-12 18:40:03,567 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.079999937152024e-06, 509
[INFO] 2021-07-12 18:40:03,567 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 509
[INFO] 2021-07-12 18:40:03,567 [run_pretraining.py:  558]:	worker_index: 6, step: 509, cost: 9.136030, mlm loss: 9.136030, speed: 1.099905 steps/s, speed: 8.799238 samples/s, speed: 4505.209663 tokens/s, learning rate: 5.080e-06, loss_scalings: 13421.773438, pp_loss: 9.160686
[INFO] 2021-07-12 18:40:03,567 [run_pretraining.py:  512]:	********exe.run_509******* 
[INFO] 2021-07-12 18:40:04,481 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:04,481 [run_pretraining.py:  534]:	loss/total_loss, 8.612390518188477, 510
[INFO] 2021-07-12 18:40:04,481 [run_pretraining.py:  535]:	loss/mlm_loss, 8.612390518188477, 510
[INFO] 2021-07-12 18:40:04,482 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.089999831398018e-06, 510
[INFO] 2021-07-12 18:40:04,482 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 510
[INFO] 2021-07-12 18:40:04,482 [run_pretraining.py:  558]:	worker_index: 6, step: 510, cost: 8.612391, mlm loss: 8.612391, speed: 1.094248 steps/s, speed: 8.753984 samples/s, speed: 4482.039793 tokens/s, learning rate: 5.090e-06, loss_scalings: 13421.773438, pp_loss: 8.833544
[INFO] 2021-07-12 18:40:04,482 [run_pretraining.py:  512]:	********exe.run_510******* 
[INFO] 2021-07-12 18:40:05,403 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:05,404 [run_pretraining.py:  534]:	loss/total_loss, 8.826375007629395, 511
[INFO] 2021-07-12 18:40:05,404 [run_pretraining.py:  535]:	loss/mlm_loss, 8.826375007629395, 511
[INFO] 2021-07-12 18:40:05,404 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.099999725644011e-06, 511
[INFO] 2021-07-12 18:40:05,404 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 511
[INFO] 2021-07-12 18:40:05,404 [run_pretraining.py:  558]:	worker_index: 6, step: 511, cost: 8.826375, mlm loss: 8.826375, speed: 1.085096 steps/s, speed: 8.680770 samples/s, speed: 4444.554328 tokens/s, learning rate: 5.100e-06, loss_scalings: 13421.773438, pp_loss: 8.907287
[INFO] 2021-07-12 18:40:05,404 [run_pretraining.py:  512]:	********exe.run_511******* 
[INFO] 2021-07-12 18:40:06,333 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:06,334 [run_pretraining.py:  534]:	loss/total_loss, 9.099355697631836, 512
[INFO] 2021-07-12 18:40:06,334 [run_pretraining.py:  535]:	loss/mlm_loss, 9.099355697631836, 512
[INFO] 2021-07-12 18:40:06,334 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.110000074637355e-06, 512
[INFO] 2021-07-12 18:40:06,334 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 512
[INFO] 2021-07-12 18:40:06,334 [run_pretraining.py:  558]:	worker_index: 6, step: 512, cost: 9.099356, mlm loss: 9.099356, speed: 1.075603 steps/s, speed: 8.604826 samples/s, speed: 4405.670789 tokens/s, learning rate: 5.110e-06, loss_scalings: 13421.773438, pp_loss: 8.789026
[INFO] 2021-07-12 18:40:06,334 [run_pretraining.py:  512]:	********exe.run_512******* 
[INFO] 2021-07-12 18:40:07,248 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:07,248 [run_pretraining.py:  534]:	loss/total_loss, 8.685747146606445, 513
[INFO] 2021-07-12 18:40:07,248 [run_pretraining.py:  535]:	loss/mlm_loss, 8.685747146606445, 513
[INFO] 2021-07-12 18:40:07,248 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.119999514135998e-06, 513
[INFO] 2021-07-12 18:40:07,249 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 513
[INFO] 2021-07-12 18:40:07,249 [run_pretraining.py:  558]:	worker_index: 6, step: 513, cost: 8.685747, mlm loss: 8.685747, speed: 1.094677 steps/s, speed: 8.757413 samples/s, speed: 4483.795623 tokens/s, learning rate: 5.120e-06, loss_scalings: 13421.773438, pp_loss: 8.689001
[INFO] 2021-07-12 18:40:07,249 [run_pretraining.py:  512]:	********exe.run_513******* 
[INFO] 2021-07-12 18:40:08,157 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:08,158 [run_pretraining.py:  534]:	loss/total_loss, 9.393693923950195, 514
[INFO] 2021-07-12 18:40:08,158 [run_pretraining.py:  535]:	loss/mlm_loss, 9.393693923950195, 514
[INFO] 2021-07-12 18:40:08,158 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.129999863129342e-06, 514
[INFO] 2021-07-12 18:40:08,158 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 514
[INFO] 2021-07-12 18:40:08,158 [run_pretraining.py:  558]:	worker_index: 6, step: 514, cost: 9.393694, mlm loss: 9.393694, speed: 1.100533 steps/s, speed: 8.804266 samples/s, speed: 4507.784301 tokens/s, learning rate: 5.130e-06, loss_scalings: 13421.773438, pp_loss: 9.112843
[INFO] 2021-07-12 18:40:08,158 [run_pretraining.py:  512]:	********exe.run_514******* 
[INFO] 2021-07-12 18:40:09,061 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:09,061 [run_pretraining.py:  534]:	loss/total_loss, 8.541046142578125, 515
[INFO] 2021-07-12 18:40:09,061 [run_pretraining.py:  535]:	loss/mlm_loss, 8.541046142578125, 515
[INFO] 2021-07-12 18:40:09,062 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.139999757375335e-06, 515
[INFO] 2021-07-12 18:40:09,062 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 515
[INFO] 2021-07-12 18:40:09,062 [run_pretraining.py:  558]:	worker_index: 6, step: 515, cost: 8.541046, mlm loss: 8.541046, speed: 1.107337 steps/s, speed: 8.858695 samples/s, speed: 4535.651651 tokens/s, learning rate: 5.140e-06, loss_scalings: 13421.773438, pp_loss: 8.659100
[INFO] 2021-07-12 18:40:09,062 [run_pretraining.py:  512]:	********exe.run_515******* 
[INFO] 2021-07-12 18:40:09,971 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:09,972 [run_pretraining.py:  534]:	loss/total_loss, 8.647457122802734, 516
[INFO] 2021-07-12 18:40:09,972 [run_pretraining.py:  535]:	loss/mlm_loss, 8.647457122802734, 516
[INFO] 2021-07-12 18:40:09,972 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.149999651621329e-06, 516
[INFO] 2021-07-12 18:40:09,972 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 516
[INFO] 2021-07-12 18:40:09,972 [run_pretraining.py:  558]:	worker_index: 6, step: 516, cost: 8.647457, mlm loss: 8.647457, speed: 1.099333 steps/s, speed: 8.794667 samples/s, speed: 4502.869273 tokens/s, learning rate: 5.150e-06, loss_scalings: 13421.773438, pp_loss: 8.824689
[INFO] 2021-07-12 18:40:09,972 [run_pretraining.py:  512]:	********exe.run_516******* 
[INFO] 2021-07-12 18:40:10,877 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:10,878 [run_pretraining.py:  534]:	loss/total_loss, 8.702644348144531, 517
[INFO] 2021-07-12 18:40:10,878 [run_pretraining.py:  535]:	loss/mlm_loss, 8.702644348144531, 517
[INFO] 2021-07-12 18:40:10,878 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.160000000614673e-06, 517
[INFO] 2021-07-12 18:40:10,878 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 517
[INFO] 2021-07-12 18:40:10,878 [run_pretraining.py:  558]:	worker_index: 6, step: 517, cost: 8.702644, mlm loss: 8.702644, speed: 1.104432 steps/s, speed: 8.835457 samples/s, speed: 4523.753887 tokens/s, learning rate: 5.160e-06, loss_scalings: 13421.773438, pp_loss: 8.822800
[INFO] 2021-07-12 18:40:10,878 [run_pretraining.py:  512]:	********exe.run_517******* 
[INFO] 2021-07-12 18:40:11,774 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:11,774 [run_pretraining.py:  534]:	loss/total_loss, 9.100107192993164, 518
[INFO] 2021-07-12 18:40:11,774 [run_pretraining.py:  535]:	loss/mlm_loss, 9.100107192993164, 518
[INFO] 2021-07-12 18:40:11,774 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.169999894860666e-06, 518
[INFO] 2021-07-12 18:40:11,775 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 518
[INFO] 2021-07-12 18:40:11,775 [run_pretraining.py:  558]:	worker_index: 6, step: 518, cost: 9.100107, mlm loss: 9.100107, speed: 1.116551 steps/s, speed: 8.932406 samples/s, speed: 4573.391969 tokens/s, learning rate: 5.170e-06, loss_scalings: 13421.773438, pp_loss: 8.853117
[INFO] 2021-07-12 18:40:11,775 [run_pretraining.py:  512]:	********exe.run_518******* 
[INFO] 2021-07-12 18:40:12,681 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:12,681 [run_pretraining.py:  534]:	loss/total_loss, 8.868671417236328, 519
[INFO] 2021-07-12 18:40:12,681 [run_pretraining.py:  535]:	loss/mlm_loss, 8.868671417236328, 519
[INFO] 2021-07-12 18:40:12,681 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.17999978910666e-06, 519
[INFO] 2021-07-12 18:40:12,682 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 519
[INFO] 2021-07-12 18:40:12,682 [run_pretraining.py:  558]:	worker_index: 6, step: 519, cost: 8.868671, mlm loss: 8.868671, speed: 1.103371 steps/s, speed: 8.826968 samples/s, speed: 4519.407870 tokens/s, learning rate: 5.180e-06, loss_scalings: 13421.773438, pp_loss: 8.924697
[INFO] 2021-07-12 18:40:12,682 [run_pretraining.py:  512]:	********exe.run_519******* 
[INFO] 2021-07-12 18:40:13,588 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:13,588 [run_pretraining.py:  534]:	loss/total_loss, 8.96387004852295, 520
[INFO] 2021-07-12 18:40:13,588 [run_pretraining.py:  535]:	loss/mlm_loss, 8.96387004852295, 520
[INFO] 2021-07-12 18:40:13,589 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.189999683352653e-06, 520
[INFO] 2021-07-12 18:40:13,589 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 520
[INFO] 2021-07-12 18:40:13,589 [run_pretraining.py:  558]:	worker_index: 6, step: 520, cost: 8.963870, mlm loss: 8.963870, speed: 1.103288 steps/s, speed: 8.826302 samples/s, speed: 4519.066683 tokens/s, learning rate: 5.190e-06, loss_scalings: 13421.773438, pp_loss: 8.870655
[INFO] 2021-07-12 18:40:13,589 [run_pretraining.py:  512]:	********exe.run_520******* 
[INFO] 2021-07-12 18:40:14,495 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:14,496 [run_pretraining.py:  534]:	loss/total_loss, 8.348026275634766, 521
[INFO] 2021-07-12 18:40:14,496 [run_pretraining.py:  535]:	loss/mlm_loss, 8.348026275634766, 521
[INFO] 2021-07-12 18:40:14,496 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.200000032345997e-06, 521
[INFO] 2021-07-12 18:40:14,496 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 521
[INFO] 2021-07-12 18:40:14,496 [run_pretraining.py:  558]:	worker_index: 6, step: 521, cost: 8.348026, mlm loss: 8.348026, speed: 1.103170 steps/s, speed: 8.825360 samples/s, speed: 4518.584116 tokens/s, learning rate: 5.200e-06, loss_scalings: 13421.773438, pp_loss: 8.686413
[INFO] 2021-07-12 18:40:14,496 [run_pretraining.py:  512]:	********exe.run_521******* 
[INFO] 2021-07-12 18:40:15,434 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:15,434 [run_pretraining.py:  534]:	loss/total_loss, 8.972853660583496, 522
[INFO] 2021-07-12 18:40:15,435 [run_pretraining.py:  535]:	loss/mlm_loss, 8.972853660583496, 522
[INFO] 2021-07-12 18:40:15,435 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.2099999265919905e-06, 522
[INFO] 2021-07-12 18:40:15,435 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 522
[INFO] 2021-07-12 18:40:15,435 [run_pretraining.py:  558]:	worker_index: 6, step: 522, cost: 8.972854, mlm loss: 8.972854, speed: 1.065946 steps/s, speed: 8.527571 samples/s, speed: 4366.116438 tokens/s, learning rate: 5.210e-06, loss_scalings: 13421.773438, pp_loss: 8.983745
[INFO] 2021-07-12 18:40:15,435 [run_pretraining.py:  512]:	********exe.run_522******* 
[INFO] 2021-07-12 18:40:16,345 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:16,345 [run_pretraining.py:  534]:	loss/total_loss, 9.362712860107422, 523
[INFO] 2021-07-12 18:40:16,345 [run_pretraining.py:  535]:	loss/mlm_loss, 9.362712860107422, 523
[INFO] 2021-07-12 18:40:16,346 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.219999820837984e-06, 523
[INFO] 2021-07-12 18:40:16,346 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 523
[INFO] 2021-07-12 18:40:16,346 [run_pretraining.py:  558]:	worker_index: 6, step: 523, cost: 9.362713, mlm loss: 9.362713, speed: 1.098574 steps/s, speed: 8.788592 samples/s, speed: 4499.759212 tokens/s, learning rate: 5.220e-06, loss_scalings: 13421.773438, pp_loss: 8.987450
[INFO] 2021-07-12 18:40:16,346 [run_pretraining.py:  512]:	********exe.run_523******* 
[INFO] 2021-07-12 18:40:17,245 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:17,246 [run_pretraining.py:  534]:	loss/total_loss, 8.873136520385742, 524
[INFO] 2021-07-12 18:40:17,246 [run_pretraining.py:  535]:	loss/mlm_loss, 8.873136520385742, 524
[INFO] 2021-07-12 18:40:17,246 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.229999715083977e-06, 524
[INFO] 2021-07-12 18:40:17,246 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 524
[INFO] 2021-07-12 18:40:17,246 [run_pretraining.py:  558]:	worker_index: 6, step: 524, cost: 8.873137, mlm loss: 8.873137, speed: 1.111677 steps/s, speed: 8.893418 samples/s, speed: 4553.430242 tokens/s, learning rate: 5.230e-06, loss_scalings: 13421.773438, pp_loss: 8.960419
[INFO] 2021-07-12 18:40:17,246 [run_pretraining.py:  512]:	********exe.run_524******* 
[INFO] 2021-07-12 18:40:18,158 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:18,158 [run_pretraining.py:  534]:	loss/total_loss, 8.810593605041504, 525
[INFO] 2021-07-12 18:40:18,159 [run_pretraining.py:  535]:	loss/mlm_loss, 8.810593605041504, 525
[INFO] 2021-07-12 18:40:18,159 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.2400000640773214e-06, 525
[INFO] 2021-07-12 18:40:18,159 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 525
[INFO] 2021-07-12 18:40:18,159 [run_pretraining.py:  558]:	worker_index: 6, step: 525, cost: 8.810594, mlm loss: 8.810594, speed: 1.096305 steps/s, speed: 8.770440 samples/s, speed: 4490.465317 tokens/s, learning rate: 5.240e-06, loss_scalings: 13421.773438, pp_loss: 8.709427
[INFO] 2021-07-12 18:40:18,159 [run_pretraining.py:  512]:	********exe.run_525******* 
[INFO] 2021-07-12 18:40:19,065 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:19,065 [run_pretraining.py:  534]:	loss/total_loss, 8.806927680969238, 526
[INFO] 2021-07-12 18:40:19,066 [run_pretraining.py:  535]:	loss/mlm_loss, 8.806927680969238, 526
[INFO] 2021-07-12 18:40:19,066 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.249999503575964e-06, 526
[INFO] 2021-07-12 18:40:19,066 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 526
[INFO] 2021-07-12 18:40:19,066 [run_pretraining.py:  558]:	worker_index: 6, step: 526, cost: 8.806928, mlm loss: 8.806928, speed: 1.103559 steps/s, speed: 8.828469 samples/s, speed: 4520.176026 tokens/s, learning rate: 5.250e-06, loss_scalings: 13421.773438, pp_loss: 8.168607
[INFO] 2021-07-12 18:40:19,066 [run_pretraining.py:  512]:	********exe.run_526******* 
[INFO] 2021-07-12 18:40:19,971 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:19,972 [run_pretraining.py:  534]:	loss/total_loss, 9.040366172790527, 527
[INFO] 2021-07-12 18:40:19,972 [run_pretraining.py:  535]:	loss/mlm_loss, 9.040366172790527, 527
[INFO] 2021-07-12 18:40:19,972 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.259999852569308e-06, 527
[INFO] 2021-07-12 18:40:19,972 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 527
[INFO] 2021-07-12 18:40:19,972 [run_pretraining.py:  558]:	worker_index: 6, step: 527, cost: 9.040366, mlm loss: 9.040366, speed: 1.104336 steps/s, speed: 8.834689 samples/s, speed: 4523.360831 tokens/s, learning rate: 5.260e-06, loss_scalings: 13421.773438, pp_loss: 8.822029
[INFO] 2021-07-12 18:40:19,972 [run_pretraining.py:  512]:	********exe.run_527******* 
[INFO] 2021-07-12 18:40:20,883 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:20,884 [run_pretraining.py:  534]:	loss/total_loss, 8.464743614196777, 528
[INFO] 2021-07-12 18:40:20,884 [run_pretraining.py:  535]:	loss/mlm_loss, 8.464743614196777, 528
[INFO] 2021-07-12 18:40:20,884 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.270000201562652e-06, 528
[INFO] 2021-07-12 18:40:20,884 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 528
[INFO] 2021-07-12 18:40:20,884 [run_pretraining.py:  558]:	worker_index: 6, step: 528, cost: 8.464744, mlm loss: 8.464744, speed: 1.097300 steps/s, speed: 8.778397 samples/s, speed: 4494.539455 tokens/s, learning rate: 5.270e-06, loss_scalings: 13421.773438, pp_loss: 8.679593
[INFO] 2021-07-12 18:40:20,884 [run_pretraining.py:  512]:	********exe.run_528******* 
[INFO] 2021-07-12 18:40:21,787 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:21,788 [run_pretraining.py:  534]:	loss/total_loss, 9.05083179473877, 529
[INFO] 2021-07-12 18:40:21,788 [run_pretraining.py:  535]:	loss/mlm_loss, 9.05083179473877, 529
[INFO] 2021-07-12 18:40:21,788 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.279999641061295e-06, 529
[INFO] 2021-07-12 18:40:21,788 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 529
[INFO] 2021-07-12 18:40:21,788 [run_pretraining.py:  558]:	worker_index: 6, step: 529, cost: 9.050832, mlm loss: 9.050832, speed: 1.107265 steps/s, speed: 8.858119 samples/s, speed: 4535.357096 tokens/s, learning rate: 5.280e-06, loss_scalings: 13421.773438, pp_loss: 8.965069
[INFO] 2021-07-12 18:40:21,788 [run_pretraining.py:  512]:	********exe.run_529******* 
[INFO] 2021-07-12 18:40:22,696 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:22,696 [run_pretraining.py:  534]:	loss/total_loss, 8.50260066986084, 530
[INFO] 2021-07-12 18:40:22,696 [run_pretraining.py:  535]:	loss/mlm_loss, 8.50260066986084, 530
[INFO] 2021-07-12 18:40:22,696 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.289999990054639e-06, 530
[INFO] 2021-07-12 18:40:22,697 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 530
[INFO] 2021-07-12 18:40:22,697 [run_pretraining.py:  558]:	worker_index: 6, step: 530, cost: 8.502601, mlm loss: 8.502601, speed: 1.101336 steps/s, speed: 8.810686 samples/s, speed: 4511.071294 tokens/s, learning rate: 5.290e-06, loss_scalings: 13421.773438, pp_loss: 8.882456
[INFO] 2021-07-12 18:40:22,697 [run_pretraining.py:  512]:	********exe.run_530******* 
[INFO] 2021-07-12 18:40:23,602 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:23,603 [run_pretraining.py:  534]:	loss/total_loss, 8.532180786132812, 531
[INFO] 2021-07-12 18:40:23,603 [run_pretraining.py:  535]:	loss/mlm_loss, 8.532180786132812, 531
[INFO] 2021-07-12 18:40:23,603 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.299999884300632e-06, 531
[INFO] 2021-07-12 18:40:23,603 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 531
[INFO] 2021-07-12 18:40:23,603 [run_pretraining.py:  558]:	worker_index: 6, step: 531, cost: 8.532181, mlm loss: 8.532181, speed: 1.104115 steps/s, speed: 8.832924 samples/s, speed: 4522.457062 tokens/s, learning rate: 5.300e-06, loss_scalings: 13421.773438, pp_loss: 8.857133
[INFO] 2021-07-12 18:40:23,603 [run_pretraining.py:  512]:	********exe.run_531******* 
[INFO] 2021-07-12 18:40:24,507 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:24,507 [run_pretraining.py:  534]:	loss/total_loss, 9.257843971252441, 532
[INFO] 2021-07-12 18:40:24,507 [run_pretraining.py:  535]:	loss/mlm_loss, 9.257843971252441, 532
[INFO] 2021-07-12 18:40:24,508 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.309999778546626e-06, 532
[INFO] 2021-07-12 18:40:24,508 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 532
[INFO] 2021-07-12 18:40:24,508 [run_pretraining.py:  558]:	worker_index: 6, step: 532, cost: 9.257844, mlm loss: 9.257844, speed: 1.106286 steps/s, speed: 8.850288 samples/s, speed: 4531.347293 tokens/s, learning rate: 5.310e-06, loss_scalings: 13421.773438, pp_loss: 8.828509
[INFO] 2021-07-12 18:40:24,508 [run_pretraining.py:  512]:	********exe.run_532******* 
[INFO] 2021-07-12 18:40:25,413 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:25,414 [run_pretraining.py:  534]:	loss/total_loss, 9.055420875549316, 533
[INFO] 2021-07-12 18:40:25,414 [run_pretraining.py:  535]:	loss/mlm_loss, 9.055420875549316, 533
[INFO] 2021-07-12 18:40:25,414 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.319999672792619e-06, 533
[INFO] 2021-07-12 18:40:25,414 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 533
[INFO] 2021-07-12 18:40:25,414 [run_pretraining.py:  558]:	worker_index: 6, step: 533, cost: 9.055421, mlm loss: 9.055421, speed: 1.103717 steps/s, speed: 8.829733 samples/s, speed: 4520.823097 tokens/s, learning rate: 5.320e-06, loss_scalings: 13421.773438, pp_loss: 8.930865
[INFO] 2021-07-12 18:40:25,415 [run_pretraining.py:  512]:	********exe.run_533******* 
[INFO] 2021-07-12 18:40:26,342 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:26,343 [run_pretraining.py:  534]:	loss/total_loss, 9.225053787231445, 534
[INFO] 2021-07-12 18:40:26,343 [run_pretraining.py:  535]:	loss/mlm_loss, 9.225053787231445, 534
[INFO] 2021-07-12 18:40:26,343 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.330000021785963e-06, 534
[INFO] 2021-07-12 18:40:26,343 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 534
[INFO] 2021-07-12 18:40:26,343 [run_pretraining.py:  558]:	worker_index: 6, step: 534, cost: 9.225054, mlm loss: 9.225054, speed: 1.077299 steps/s, speed: 8.618392 samples/s, speed: 4412.616476 tokens/s, learning rate: 5.330e-06, loss_scalings: 13421.773438, pp_loss: 8.999973
[INFO] 2021-07-12 18:40:26,343 [run_pretraining.py:  512]:	********exe.run_534******* 
[INFO] 2021-07-12 18:40:27,246 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:27,247 [run_pretraining.py:  534]:	loss/total_loss, 9.036552429199219, 535
[INFO] 2021-07-12 18:40:27,247 [run_pretraining.py:  535]:	loss/mlm_loss, 9.036552429199219, 535
[INFO] 2021-07-12 18:40:27,247 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.339999916031957e-06, 535
[INFO] 2021-07-12 18:40:27,247 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 535
[INFO] 2021-07-12 18:40:27,247 [run_pretraining.py:  558]:	worker_index: 6, step: 535, cost: 9.036552, mlm loss: 9.036552, speed: 1.107163 steps/s, speed: 8.857306 samples/s, speed: 4534.940474 tokens/s, learning rate: 5.340e-06, loss_scalings: 13421.773438, pp_loss: 8.915847
[INFO] 2021-07-12 18:40:27,247 [run_pretraining.py:  512]:	********exe.run_535******* 
[INFO] 2021-07-12 18:40:28,154 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:28,155 [run_pretraining.py:  534]:	loss/total_loss, 9.133050918579102, 536
[INFO] 2021-07-12 18:40:28,155 [run_pretraining.py:  535]:	loss/mlm_loss, 9.133050918579102, 536
[INFO] 2021-07-12 18:40:28,155 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.34999981027795e-06, 536
[INFO] 2021-07-12 18:40:28,155 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 536
[INFO] 2021-07-12 18:40:28,155 [run_pretraining.py:  558]:	worker_index: 6, step: 536, cost: 9.133051, mlm loss: 9.133051, speed: 1.102556 steps/s, speed: 8.820446 samples/s, speed: 4516.068358 tokens/s, learning rate: 5.350e-06, loss_scalings: 13421.773438, pp_loss: 8.818514
[INFO] 2021-07-12 18:40:28,155 [run_pretraining.py:  512]:	********exe.run_536******* 
[INFO] 2021-07-12 18:40:29,057 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:29,057 [run_pretraining.py:  534]:	loss/total_loss, 8.934759140014648, 537
[INFO] 2021-07-12 18:40:29,057 [run_pretraining.py:  535]:	loss/mlm_loss, 8.934759140014648, 537
[INFO] 2021-07-12 18:40:29,057 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.359999704523943e-06, 537
[INFO] 2021-07-12 18:40:29,058 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 537
[INFO] 2021-07-12 18:40:29,058 [run_pretraining.py:  558]:	worker_index: 6, step: 537, cost: 8.934759, mlm loss: 8.934759, speed: 1.108847 steps/s, speed: 8.870777 samples/s, speed: 4541.837752 tokens/s, learning rate: 5.360e-06, loss_scalings: 13421.773438, pp_loss: 8.230911
[INFO] 2021-07-12 18:40:29,058 [run_pretraining.py:  512]:	********exe.run_537******* 
[INFO] 2021-07-12 18:40:30,015 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:30,016 [run_pretraining.py:  534]:	loss/total_loss, 8.743104934692383, 538
[INFO] 2021-07-12 18:40:30,016 [run_pretraining.py:  535]:	loss/mlm_loss, 8.743104934692383, 538
[INFO] 2021-07-12 18:40:30,016 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.370000053517288e-06, 538
[INFO] 2021-07-12 18:40:30,016 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 538
[INFO] 2021-07-12 18:40:30,016 [run_pretraining.py:  558]:	worker_index: 6, step: 538, cost: 8.743105, mlm loss: 8.743105, speed: 1.044309 steps/s, speed: 8.354472 samples/s, speed: 4277.489474 tokens/s, learning rate: 5.370e-06, loss_scalings: 13421.773438, pp_loss: 8.837006
[INFO] 2021-07-12 18:40:30,016 [run_pretraining.py:  512]:	********exe.run_538******* 
[INFO] 2021-07-12 18:40:30,971 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:30,972 [run_pretraining.py:  534]:	loss/total_loss, 8.698384284973145, 539
[INFO] 2021-07-12 18:40:30,972 [run_pretraining.py:  535]:	loss/mlm_loss, 8.698384284973145, 539
[INFO] 2021-07-12 18:40:30,972 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.379999947763281e-06, 539
[INFO] 2021-07-12 18:40:30,972 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 539
[INFO] 2021-07-12 18:40:30,972 [run_pretraining.py:  558]:	worker_index: 6, step: 539, cost: 8.698384, mlm loss: 8.698384, speed: 1.046281 steps/s, speed: 8.370250 samples/s, speed: 4285.567974 tokens/s, learning rate: 5.380e-06, loss_scalings: 13421.773438, pp_loss: 8.883640
[INFO] 2021-07-12 18:40:30,972 [run_pretraining.py:  512]:	********exe.run_539******* 
[INFO] 2021-07-12 18:40:31,880 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:31,881 [run_pretraining.py:  534]:	loss/total_loss, 8.982830047607422, 540
[INFO] 2021-07-12 18:40:31,881 [run_pretraining.py:  535]:	loss/mlm_loss, 8.982830047607422, 540
[INFO] 2021-07-12 18:40:31,881 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.389999842009274e-06, 540
[INFO] 2021-07-12 18:40:31,881 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 540
[INFO] 2021-07-12 18:40:31,881 [run_pretraining.py:  558]:	worker_index: 6, step: 540, cost: 8.982830, mlm loss: 8.982830, speed: 1.100969 steps/s, speed: 8.807754 samples/s, speed: 4509.569833 tokens/s, learning rate: 5.390e-06, loss_scalings: 13421.773438, pp_loss: 8.798697
[INFO] 2021-07-12 18:40:31,881 [run_pretraining.py:  512]:	********exe.run_540******* 
[INFO] 2021-07-12 18:40:32,774 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:32,774 [run_pretraining.py:  534]:	loss/total_loss, 8.805438041687012, 541
[INFO] 2021-07-12 18:40:32,775 [run_pretraining.py:  535]:	loss/mlm_loss, 8.805438041687012, 541
[INFO] 2021-07-12 18:40:32,775 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.4000001910026185e-06, 541
[INFO] 2021-07-12 18:40:32,775 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 541
[INFO] 2021-07-12 18:40:32,775 [run_pretraining.py:  558]:	worker_index: 6, step: 541, cost: 8.805438, mlm loss: 8.805438, speed: 1.120162 steps/s, speed: 8.961298 samples/s, speed: 4588.184396 tokens/s, learning rate: 5.400e-06, loss_scalings: 13421.773438, pp_loss: 8.922618
[INFO] 2021-07-12 18:40:32,775 [run_pretraining.py:  512]:	********exe.run_541******* 
[INFO] 2021-07-12 18:40:33,685 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:33,686 [run_pretraining.py:  534]:	loss/total_loss, 8.602490425109863, 542
[INFO] 2021-07-12 18:40:33,686 [run_pretraining.py:  535]:	loss/mlm_loss, 8.602490425109863, 542
[INFO] 2021-07-12 18:40:33,686 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.409999630501261e-06, 542
[INFO] 2021-07-12 18:40:33,686 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 542
[INFO] 2021-07-12 18:40:33,686 [run_pretraining.py:  558]:	worker_index: 6, step: 542, cost: 8.602490, mlm loss: 8.602490, speed: 1.098281 steps/s, speed: 8.786252 samples/s, speed: 4498.560917 tokens/s, learning rate: 5.410e-06, loss_scalings: 13421.773438, pp_loss: 7.561667
[INFO] 2021-07-12 18:40:33,686 [run_pretraining.py:  512]:	********exe.run_542******* 
[INFO] 2021-07-12 18:40:34,601 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:34,601 [run_pretraining.py:  534]:	loss/total_loss, 8.435009956359863, 543
[INFO] 2021-07-12 18:40:34,601 [run_pretraining.py:  535]:	loss/mlm_loss, 8.435009956359863, 543
[INFO] 2021-07-12 18:40:34,601 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.419999979494605e-06, 543
[INFO] 2021-07-12 18:40:34,601 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 543
[INFO] 2021-07-12 18:40:34,602 [run_pretraining.py:  558]:	worker_index: 6, step: 543, cost: 8.435010, mlm loss: 8.435010, speed: 1.093146 steps/s, speed: 8.745168 samples/s, speed: 4477.526110 tokens/s, learning rate: 5.420e-06, loss_scalings: 13421.773438, pp_loss: 8.934713
[INFO] 2021-07-12 18:40:34,602 [run_pretraining.py:  512]:	********exe.run_543******* 
[INFO] 2021-07-12 18:40:35,580 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:35,581 [run_pretraining.py:  534]:	loss/total_loss, 8.798270225524902, 544
[INFO] 2021-07-12 18:40:35,581 [run_pretraining.py:  535]:	loss/mlm_loss, 8.798270225524902, 544
[INFO] 2021-07-12 18:40:35,581 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.4299998737405986e-06, 544
[INFO] 2021-07-12 18:40:35,581 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 544
[INFO] 2021-07-12 18:40:35,581 [run_pretraining.py:  558]:	worker_index: 6, step: 544, cost: 8.798270, mlm loss: 8.798270, speed: 1.021296 steps/s, speed: 8.170365 samples/s, speed: 4183.227027 tokens/s, learning rate: 5.430e-06, loss_scalings: 13421.773438, pp_loss: 8.835299
[INFO] 2021-07-12 18:40:35,581 [run_pretraining.py:  512]:	********exe.run_544******* 
[INFO] 2021-07-12 18:40:36,644 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:36,645 [run_pretraining.py:  534]:	loss/total_loss, 8.887722969055176, 545
[INFO] 2021-07-12 18:40:36,645 [run_pretraining.py:  535]:	loss/mlm_loss, 8.887722969055176, 545
[INFO] 2021-07-12 18:40:36,645 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.439999767986592e-06, 545
[INFO] 2021-07-12 18:40:36,645 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 545
[INFO] 2021-07-12 18:40:36,645 [run_pretraining.py:  558]:	worker_index: 6, step: 545, cost: 8.887723, mlm loss: 8.887723, speed: 0.940698 steps/s, speed: 7.525583 samples/s, speed: 3853.098748 tokens/s, learning rate: 5.440e-06, loss_scalings: 13421.773438, pp_loss: 8.672669
[INFO] 2021-07-12 18:40:36,645 [run_pretraining.py:  512]:	********exe.run_545******* 
[INFO] 2021-07-12 18:40:37,711 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:37,711 [run_pretraining.py:  534]:	loss/total_loss, 8.825942039489746, 546
[INFO] 2021-07-12 18:40:37,712 [run_pretraining.py:  535]:	loss/mlm_loss, 8.825942039489746, 546
[INFO] 2021-07-12 18:40:37,712 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.449999662232585e-06, 546
[INFO] 2021-07-12 18:40:37,712 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 546
[INFO] 2021-07-12 18:40:37,712 [run_pretraining.py:  558]:	worker_index: 6, step: 546, cost: 8.825942, mlm loss: 8.825942, speed: 0.938135 steps/s, speed: 7.505077 samples/s, speed: 3842.599224 tokens/s, learning rate: 5.450e-06, loss_scalings: 13421.773438, pp_loss: 8.812170
[INFO] 2021-07-12 18:40:37,712 [run_pretraining.py:  512]:	********exe.run_546******* 
[INFO] 2021-07-12 18:40:38,765 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:38,766 [run_pretraining.py:  534]:	loss/total_loss, 9.233626365661621, 547
[INFO] 2021-07-12 18:40:38,766 [run_pretraining.py:  535]:	loss/mlm_loss, 9.233626365661621, 547
[INFO] 2021-07-12 18:40:38,766 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.4600000112259295e-06, 547
[INFO] 2021-07-12 18:40:38,766 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 547
[INFO] 2021-07-12 18:40:38,766 [run_pretraining.py:  558]:	worker_index: 6, step: 547, cost: 9.233626, mlm loss: 9.233626, speed: 0.948867 steps/s, speed: 7.590935 samples/s, speed: 3886.558938 tokens/s, learning rate: 5.460e-06, loss_scalings: 13421.773438, pp_loss: 8.990884
[INFO] 2021-07-12 18:40:38,767 [run_pretraining.py:  512]:	********exe.run_547******* 
[INFO] 2021-07-12 18:40:39,822 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:39,823 [run_pretraining.py:  534]:	loss/total_loss, 9.028779983520508, 548
[INFO] 2021-07-12 18:40:39,823 [run_pretraining.py:  535]:	loss/mlm_loss, 9.028779983520508, 548
[INFO] 2021-07-12 18:40:39,823 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.469999905471923e-06, 548
[INFO] 2021-07-12 18:40:39,823 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 548
[INFO] 2021-07-12 18:40:39,823 [run_pretraining.py:  558]:	worker_index: 6, step: 548, cost: 9.028780, mlm loss: 9.028780, speed: 0.946688 steps/s, speed: 7.573501 samples/s, speed: 3877.632275 tokens/s, learning rate: 5.470e-06, loss_scalings: 13421.773438, pp_loss: 8.801374
[INFO] 2021-07-12 18:40:39,824 [run_pretraining.py:  512]:	********exe.run_548******* 
[INFO] 2021-07-12 18:40:40,883 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:40,883 [run_pretraining.py:  534]:	loss/total_loss, 8.811184883117676, 549
[INFO] 2021-07-12 18:40:40,884 [run_pretraining.py:  535]:	loss/mlm_loss, 8.811184883117676, 549
[INFO] 2021-07-12 18:40:40,884 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.479999799717916e-06, 549
[INFO] 2021-07-12 18:40:40,884 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 549
[INFO] 2021-07-12 18:40:40,884 [run_pretraining.py:  558]:	worker_index: 6, step: 549, cost: 8.811185, mlm loss: 8.811185, speed: 0.943690 steps/s, speed: 7.549520 samples/s, speed: 3865.354412 tokens/s, learning rate: 5.480e-06, loss_scalings: 13421.773438, pp_loss: 8.955771
[INFO] 2021-07-12 18:40:40,884 [run_pretraining.py:  512]:	********exe.run_549******* 
[INFO] 2021-07-12 18:40:41,937 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:41,937 [run_pretraining.py:  534]:	loss/total_loss, 8.168928146362305, 550
[INFO] 2021-07-12 18:40:41,937 [run_pretraining.py:  535]:	loss/mlm_loss, 8.168928146362305, 550
[INFO] 2021-07-12 18:40:41,937 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.49000014871126e-06, 550
[INFO] 2021-07-12 18:40:41,937 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 550
[INFO] 2021-07-12 18:40:41,938 [run_pretraining.py:  558]:	worker_index: 6, step: 550, cost: 8.168928, mlm loss: 8.168928, speed: 0.949730 steps/s, speed: 7.597840 samples/s, speed: 3890.094084 tokens/s, learning rate: 5.490e-06, loss_scalings: 13421.773438, pp_loss: 8.713185
[INFO] 2021-07-12 18:40:41,938 [run_pretraining.py:  512]:	********exe.run_550******* 
[INFO] 2021-07-12 18:40:43,006 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:43,006 [run_pretraining.py:  534]:	loss/total_loss, 8.933389663696289, 551
[INFO] 2021-07-12 18:40:43,006 [run_pretraining.py:  535]:	loss/mlm_loss, 8.933389663696289, 551
[INFO] 2021-07-12 18:40:43,006 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.500000042957254e-06, 551
[INFO] 2021-07-12 18:40:43,007 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 551
[INFO] 2021-07-12 18:40:43,007 [run_pretraining.py:  558]:	worker_index: 6, step: 551, cost: 8.933390, mlm loss: 8.933390, speed: 0.935983 steps/s, speed: 7.487866 samples/s, speed: 3833.787571 tokens/s, learning rate: 5.500e-06, loss_scalings: 13421.773438, pp_loss: 8.781607
[INFO] 2021-07-12 18:40:43,007 [run_pretraining.py:  512]:	********exe.run_551******* 
[INFO] 2021-07-12 18:40:44,084 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:44,084 [run_pretraining.py:  534]:	loss/total_loss, 9.081480026245117, 552
[INFO] 2021-07-12 18:40:44,084 [run_pretraining.py:  535]:	loss/mlm_loss, 9.081480026245117, 552
[INFO] 2021-07-12 18:40:44,084 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.509999937203247e-06, 552
[INFO] 2021-07-12 18:40:44,085 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 552
[INFO] 2021-07-12 18:40:44,085 [run_pretraining.py:  558]:	worker_index: 6, step: 552, cost: 9.081480, mlm loss: 9.081480, speed: 0.928250 steps/s, speed: 7.426000 samples/s, speed: 3802.111889 tokens/s, learning rate: 5.510e-06, loss_scalings: 13421.773438, pp_loss: 8.892869
[INFO] 2021-07-12 18:40:44,085 [run_pretraining.py:  512]:	********exe.run_552******* 
[INFO] 2021-07-12 18:40:45,133 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:45,133 [run_pretraining.py:  534]:	loss/total_loss, 8.645500183105469, 553
[INFO] 2021-07-12 18:40:45,133 [run_pretraining.py:  535]:	loss/mlm_loss, 8.645500183105469, 553
[INFO] 2021-07-12 18:40:45,134 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.5199998314492404e-06, 553
[INFO] 2021-07-12 18:40:45,134 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 553
[INFO] 2021-07-12 18:40:45,134 [run_pretraining.py:  558]:	worker_index: 6, step: 553, cost: 8.645500, mlm loss: 8.645500, speed: 0.953843 steps/s, speed: 7.630740 samples/s, speed: 3906.938914 tokens/s, learning rate: 5.520e-06, loss_scalings: 13421.773438, pp_loss: 7.981884
[INFO] 2021-07-12 18:40:45,134 [run_pretraining.py:  512]:	********exe.run_553******* 
[INFO] 2021-07-12 18:40:46,191 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:46,192 [run_pretraining.py:  534]:	loss/total_loss, 9.052430152893066, 554
[INFO] 2021-07-12 18:40:46,192 [run_pretraining.py:  535]:	loss/mlm_loss, 9.052430152893066, 554
[INFO] 2021-07-12 18:40:46,192 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.530000180442585e-06, 554
[INFO] 2021-07-12 18:40:46,192 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 554
[INFO] 2021-07-12 18:40:46,192 [run_pretraining.py:  558]:	worker_index: 6, step: 554, cost: 9.052430, mlm loss: 9.052430, speed: 0.945452 steps/s, speed: 7.563618 samples/s, speed: 3872.572283 tokens/s, learning rate: 5.530e-06, loss_scalings: 13421.773438, pp_loss: 8.266563
[INFO] 2021-07-12 18:40:46,192 [run_pretraining.py:  512]:	********exe.run_554******* 
[INFO] 2021-07-12 18:40:47,256 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:47,257 [run_pretraining.py:  534]:	loss/total_loss, 10.080653190612793, 555
[INFO] 2021-07-12 18:40:47,257 [run_pretraining.py:  535]:	loss/mlm_loss, 10.080653190612793, 555
[INFO] 2021-07-12 18:40:47,257 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.539999619941227e-06, 555
[INFO] 2021-07-12 18:40:47,257 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 555
[INFO] 2021-07-12 18:40:47,257 [run_pretraining.py:  558]:	worker_index: 6, step: 555, cost: 10.080653, mlm loss: 10.080653, speed: 0.939719 steps/s, speed: 7.517750 samples/s, speed: 3849.087982 tokens/s, learning rate: 5.540e-06, loss_scalings: 13421.773438, pp_loss: 9.061436
[INFO] 2021-07-12 18:40:47,257 [run_pretraining.py:  512]:	********exe.run_555******* 
[INFO] 2021-07-12 18:40:48,315 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:48,316 [run_pretraining.py:  534]:	loss/total_loss, 9.184734344482422, 556
[INFO] 2021-07-12 18:40:48,316 [run_pretraining.py:  535]:	loss/mlm_loss, 9.184734344482422, 556
[INFO] 2021-07-12 18:40:48,316 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.549999968934571e-06, 556
[INFO] 2021-07-12 18:40:48,316 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 556
[INFO] 2021-07-12 18:40:48,316 [run_pretraining.py:  558]:	worker_index: 6, step: 556, cost: 9.184734, mlm loss: 9.184734, speed: 0.944739 steps/s, speed: 7.557909 samples/s, speed: 3869.649304 tokens/s, learning rate: 5.550e-06, loss_scalings: 13421.773438, pp_loss: 8.838473
[INFO] 2021-07-12 18:40:48,316 [run_pretraining.py:  512]:	********exe.run_556******* 
[INFO] 2021-07-12 18:40:49,392 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:49,393 [run_pretraining.py:  534]:	loss/total_loss, 9.10779857635498, 557
[INFO] 2021-07-12 18:40:49,393 [run_pretraining.py:  535]:	loss/mlm_loss, 9.10779857635498, 557
[INFO] 2021-07-12 18:40:49,393 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.559999863180565e-06, 557
[INFO] 2021-07-12 18:40:49,393 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 557
[INFO] 2021-07-12 18:40:49,393 [run_pretraining.py:  558]:	worker_index: 6, step: 557, cost: 9.107799, mlm loss: 9.107799, speed: 0.929095 steps/s, speed: 7.432757 samples/s, speed: 3805.571724 tokens/s, learning rate: 5.560e-06, loss_scalings: 13421.773438, pp_loss: 8.903863
[INFO] 2021-07-12 18:40:49,393 [run_pretraining.py:  512]:	********exe.run_557******* 
[INFO] 2021-07-12 18:40:50,472 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:50,472 [run_pretraining.py:  534]:	loss/total_loss, 8.87208366394043, 558
[INFO] 2021-07-12 18:40:50,473 [run_pretraining.py:  535]:	loss/mlm_loss, 8.87208366394043, 558
[INFO] 2021-07-12 18:40:50,473 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.569999757426558e-06, 558
[INFO] 2021-07-12 18:40:50,473 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 558
[INFO] 2021-07-12 18:40:50,473 [run_pretraining.py:  558]:	worker_index: 6, step: 558, cost: 8.872084, mlm loss: 8.872084, speed: 0.926901 steps/s, speed: 7.415208 samples/s, speed: 3796.586534 tokens/s, learning rate: 5.570e-06, loss_scalings: 13421.773438, pp_loss: 8.862860
[INFO] 2021-07-12 18:40:50,473 [run_pretraining.py:  512]:	********exe.run_558******* 
[INFO] 2021-07-12 18:40:51,527 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:51,528 [run_pretraining.py:  534]:	loss/total_loss, 9.0111083984375, 559
[INFO] 2021-07-12 18:40:51,528 [run_pretraining.py:  535]:	loss/mlm_loss, 9.0111083984375, 559
[INFO] 2021-07-12 18:40:51,528 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.579999651672551e-06, 559
[INFO] 2021-07-12 18:40:51,528 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 559
[INFO] 2021-07-12 18:40:51,528 [run_pretraining.py:  558]:	worker_index: 6, step: 559, cost: 9.011108, mlm loss: 9.011108, speed: 0.948306 steps/s, speed: 7.586446 samples/s, speed: 3884.260190 tokens/s, learning rate: 5.580e-06, loss_scalings: 13421.773438, pp_loss: 8.777063
[INFO] 2021-07-12 18:40:51,528 [run_pretraining.py:  512]:	********exe.run_559******* 
[INFO] 2021-07-12 18:40:52,586 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:52,586 [run_pretraining.py:  534]:	loss/total_loss, 8.091652870178223, 560
[INFO] 2021-07-12 18:40:52,587 [run_pretraining.py:  535]:	loss/mlm_loss, 8.091652870178223, 560
[INFO] 2021-07-12 18:40:52,587 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.590000000665896e-06, 560
[INFO] 2021-07-12 18:40:52,587 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 560
[INFO] 2021-07-12 18:40:52,587 [run_pretraining.py:  558]:	worker_index: 6, step: 560, cost: 8.091653, mlm loss: 8.091653, speed: 0.945089 steps/s, speed: 7.560712 samples/s, speed: 3871.084510 tokens/s, learning rate: 5.590e-06, loss_scalings: 13421.773438, pp_loss: 8.751243
[INFO] 2021-07-12 18:40:52,587 [run_pretraining.py:  512]:	********exe.run_560******* 
[INFO] 2021-07-12 18:40:53,653 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:53,653 [run_pretraining.py:  534]:	loss/total_loss, 8.90233325958252, 561
[INFO] 2021-07-12 18:40:53,653 [run_pretraining.py:  535]:	loss/mlm_loss, 8.90233325958252, 561
[INFO] 2021-07-12 18:40:53,654 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.599999894911889e-06, 561
[INFO] 2021-07-12 18:40:53,654 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 561
[INFO] 2021-07-12 18:40:53,654 [run_pretraining.py:  558]:	worker_index: 6, step: 561, cost: 8.902333, mlm loss: 8.902333, speed: 0.938014 steps/s, speed: 7.504110 samples/s, speed: 3842.104233 tokens/s, learning rate: 5.600e-06, loss_scalings: 13421.773438, pp_loss: 8.952233
[INFO] 2021-07-12 18:40:53,654 [run_pretraining.py:  512]:	********exe.run_561******* 
[INFO] 2021-07-12 18:40:54,705 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:54,705 [run_pretraining.py:  534]:	loss/total_loss, 9.15301513671875, 562
[INFO] 2021-07-12 18:40:54,706 [run_pretraining.py:  535]:	loss/mlm_loss, 9.15301513671875, 562
[INFO] 2021-07-12 18:40:54,706 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.609999789157882e-06, 562
[INFO] 2021-07-12 18:40:54,706 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 562
[INFO] 2021-07-12 18:40:54,706 [run_pretraining.py:  558]:	worker_index: 6, step: 562, cost: 9.153015, mlm loss: 9.153015, speed: 0.951085 steps/s, speed: 7.608679 samples/s, speed: 3895.643396 tokens/s, learning rate: 5.610e-06, loss_scalings: 13421.773438, pp_loss: 8.922009
[INFO] 2021-07-12 18:40:54,706 [run_pretraining.py:  512]:	********exe.run_562******* 
[INFO] 2021-07-12 18:40:55,765 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:55,765 [run_pretraining.py:  534]:	loss/total_loss, 8.50866413116455, 563
[INFO] 2021-07-12 18:40:55,766 [run_pretraining.py:  535]:	loss/mlm_loss, 8.50866413116455, 563
[INFO] 2021-07-12 18:40:55,766 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.6200001381512266e-06, 563
[INFO] 2021-07-12 18:40:55,766 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 563
[INFO] 2021-07-12 18:40:55,766 [run_pretraining.py:  558]:	worker_index: 6, step: 563, cost: 8.508664, mlm loss: 8.508664, speed: 0.944041 steps/s, speed: 7.552331 samples/s, speed: 3866.793396 tokens/s, learning rate: 5.620e-06, loss_scalings: 13421.773438, pp_loss: 8.674175
[INFO] 2021-07-12 18:40:55,766 [run_pretraining.py:  512]:	********exe.run_563******* 
[INFO] 2021-07-12 18:40:56,818 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:56,819 [run_pretraining.py:  534]:	loss/total_loss, 9.166622161865234, 564
[INFO] 2021-07-12 18:40:56,819 [run_pretraining.py:  535]:	loss/mlm_loss, 9.166622161865234, 564
[INFO] 2021-07-12 18:40:56,819 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.629999577649869e-06, 564
[INFO] 2021-07-12 18:40:56,819 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 564
[INFO] 2021-07-12 18:40:56,819 [run_pretraining.py:  558]:	worker_index: 6, step: 564, cost: 9.166622, mlm loss: 9.166622, speed: 0.950123 steps/s, speed: 7.600981 samples/s, speed: 3891.702294 tokens/s, learning rate: 5.630e-06, loss_scalings: 13421.773438, pp_loss: 8.933319
[INFO] 2021-07-12 18:40:56,819 [run_pretraining.py:  512]:	********exe.run_564******* 
[INFO] 2021-07-12 18:40:57,867 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:57,867 [run_pretraining.py:  534]:	loss/total_loss, 8.441844940185547, 565
[INFO] 2021-07-12 18:40:57,868 [run_pretraining.py:  535]:	loss/mlm_loss, 8.441844940185547, 565
[INFO] 2021-07-12 18:40:57,868 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.639999926643213e-06, 565
[INFO] 2021-07-12 18:40:57,868 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 565
[INFO] 2021-07-12 18:40:57,868 [run_pretraining.py:  558]:	worker_index: 6, step: 565, cost: 8.441845, mlm loss: 8.441845, speed: 0.954124 steps/s, speed: 7.632990 samples/s, speed: 3908.090738 tokens/s, learning rate: 5.640e-06, loss_scalings: 13421.773438, pp_loss: 8.699714
[INFO] 2021-07-12 18:40:57,868 [run_pretraining.py:  512]:	********exe.run_565******* 
[INFO] 2021-07-12 18:40:58,928 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:58,929 [run_pretraining.py:  534]:	loss/total_loss, 6.179440975189209, 566
[INFO] 2021-07-12 18:40:58,929 [run_pretraining.py:  535]:	loss/mlm_loss, 6.179440975189209, 566
[INFO] 2021-07-12 18:40:58,929 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.649999820889207e-06, 566
[INFO] 2021-07-12 18:40:58,929 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 566
[INFO] 2021-07-12 18:40:58,929 [run_pretraining.py:  558]:	worker_index: 6, step: 566, cost: 6.179441, mlm loss: 6.179441, speed: 0.943016 steps/s, speed: 7.544129 samples/s, speed: 3862.594286 tokens/s, learning rate: 5.650e-06, loss_scalings: 13421.773438, pp_loss: 8.224223
[INFO] 2021-07-12 18:40:58,929 [run_pretraining.py:  512]:	********exe.run_566******* 
[INFO] 2021-07-12 18:40:59,985 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:59,985 [run_pretraining.py:  534]:	loss/total_loss, 8.608530044555664, 567
[INFO] 2021-07-12 18:40:59,986 [run_pretraining.py:  535]:	loss/mlm_loss, 8.608530044555664, 567
[INFO] 2021-07-12 18:40:59,986 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.6599997151352e-06, 567
[INFO] 2021-07-12 18:40:59,986 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 567
[INFO] 2021-07-12 18:40:59,986 [run_pretraining.py:  558]:	worker_index: 6, step: 567, cost: 8.608530, mlm loss: 8.608530, speed: 0.946854 steps/s, speed: 7.574836 samples/s, speed: 3878.315937 tokens/s, learning rate: 5.660e-06, loss_scalings: 13421.773438, pp_loss: 8.722730
[INFO] 2021-07-12 18:40:59,986 [run_pretraining.py:  512]:	********exe.run_567******* 
[INFO] 2021-07-12 18:41:01,034 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:01,034 [run_pretraining.py:  534]:	loss/total_loss, 8.826065063476562, 568
[INFO] 2021-07-12 18:41:01,034 [run_pretraining.py:  535]:	loss/mlm_loss, 8.826065063476562, 568
[INFO] 2021-07-12 18:41:01,035 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.669999609381193e-06, 568
[INFO] 2021-07-12 18:41:01,035 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 568
[INFO] 2021-07-12 18:41:01,035 [run_pretraining.py:  558]:	worker_index: 6, step: 568, cost: 8.826065, mlm loss: 8.826065, speed: 0.954053 steps/s, speed: 7.632422 samples/s, speed: 3907.800052 tokens/s, learning rate: 5.670e-06, loss_scalings: 13421.773438, pp_loss: 8.727812
[INFO] 2021-07-12 18:41:01,035 [run_pretraining.py:  512]:	********exe.run_568******* 
[INFO] 2021-07-12 18:41:01,949 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:01,950 [run_pretraining.py:  534]:	loss/total_loss, 8.722626686096191, 569
[INFO] 2021-07-12 18:41:01,950 [run_pretraining.py:  535]:	loss/mlm_loss, 8.722626686096191, 569
[INFO] 2021-07-12 18:41:01,950 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.6799999583745375e-06, 569
[INFO] 2021-07-12 18:41:01,950 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 569
[INFO] 2021-07-12 18:41:01,950 [run_pretraining.py:  558]:	worker_index: 6, step: 569, cost: 8.722627, mlm loss: 8.722627, speed: 1.093065 steps/s, speed: 8.744519 samples/s, speed: 4477.193551 tokens/s, learning rate: 5.680e-06, loss_scalings: 13421.773438, pp_loss: 8.876528
[INFO] 2021-07-12 18:41:01,950 [run_pretraining.py:  512]:	********exe.run_569******* 
[INFO] 2021-07-12 18:41:02,869 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:02,869 [run_pretraining.py:  534]:	loss/total_loss, 9.031694412231445, 570
[INFO] 2021-07-12 18:41:02,869 [run_pretraining.py:  535]:	loss/mlm_loss, 9.031694412231445, 570
[INFO] 2021-07-12 18:41:02,869 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.689999852620531e-06, 570
[INFO] 2021-07-12 18:41:02,869 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 570
[INFO] 2021-07-12 18:41:02,870 [run_pretraining.py:  558]:	worker_index: 6, step: 570, cost: 9.031694, mlm loss: 9.031694, speed: 1.088646 steps/s, speed: 8.709166 samples/s, speed: 4459.093137 tokens/s, learning rate: 5.690e-06, loss_scalings: 13421.773438, pp_loss: 8.729628
[INFO] 2021-07-12 18:41:02,870 [run_pretraining.py:  512]:	********exe.run_570******* 
[INFO] 2021-07-12 18:41:03,786 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:03,786 [run_pretraining.py:  534]:	loss/total_loss, 8.934575080871582, 571
[INFO] 2021-07-12 18:41:03,787 [run_pretraining.py:  535]:	loss/mlm_loss, 8.934575080871582, 571
[INFO] 2021-07-12 18:41:03,787 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.699999746866524e-06, 571
[INFO] 2021-07-12 18:41:03,787 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 571
[INFO] 2021-07-12 18:41:03,787 [run_pretraining.py:  558]:	worker_index: 6, step: 571, cost: 8.934575, mlm loss: 8.934575, speed: 1.091021 steps/s, speed: 8.728171 samples/s, speed: 4468.823524 tokens/s, learning rate: 5.700e-06, loss_scalings: 13421.773438, pp_loss: 8.780189
[INFO] 2021-07-12 18:41:03,787 [run_pretraining.py:  512]:	********exe.run_571******* 
[INFO] 2021-07-12 18:41:04,810 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:04,811 [run_pretraining.py:  534]:	loss/total_loss, 8.836848258972168, 572
[INFO] 2021-07-12 18:41:04,811 [run_pretraining.py:  535]:	loss/mlm_loss, 8.836848258972168, 572
[INFO] 2021-07-12 18:41:04,811 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.7100000958598685e-06, 572
[INFO] 2021-07-12 18:41:04,811 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 572
[INFO] 2021-07-12 18:41:04,811 [run_pretraining.py:  558]:	worker_index: 6, step: 572, cost: 8.836848, mlm loss: 8.836848, speed: 0.976665 steps/s, speed: 7.813323 samples/s, speed: 4000.421278 tokens/s, learning rate: 5.710e-06, loss_scalings: 13421.773438, pp_loss: 8.723654
[INFO] 2021-07-12 18:41:04,811 [run_pretraining.py:  512]:	********exe.run_572******* 
[INFO] 2021-07-12 18:41:05,871 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:05,872 [run_pretraining.py:  534]:	loss/total_loss, 8.702736854553223, 573
[INFO] 2021-07-12 18:41:05,872 [run_pretraining.py:  535]:	loss/mlm_loss, 8.702736854553223, 573
[INFO] 2021-07-12 18:41:05,872 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.719999990105862e-06, 573
[INFO] 2021-07-12 18:41:05,872 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 573
[INFO] 2021-07-12 18:41:05,872 [run_pretraining.py:  558]:	worker_index: 6, step: 573, cost: 8.702737, mlm loss: 8.702737, speed: 0.943411 steps/s, speed: 7.547286 samples/s, speed: 3864.210254 tokens/s, learning rate: 5.720e-06, loss_scalings: 13421.773438, pp_loss: 8.736816
[INFO] 2021-07-12 18:41:05,872 [run_pretraining.py:  512]:	********exe.run_573******* 
[INFO] 2021-07-12 18:41:07,013 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:07,019 [run_pretraining.py:  534]:	loss/total_loss, 8.746308326721191, 574
[INFO] 2021-07-12 18:41:07,024 [run_pretraining.py:  535]:	loss/mlm_loss, 8.746308326721191, 574
[INFO] 2021-07-12 18:41:07,028 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.729999884351855e-06, 574
[INFO] 2021-07-12 18:41:07,028 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 574
[INFO] 2021-07-12 18:41:07,030 [run_pretraining.py:  558]:	worker_index: 6, step: 574, cost: 8.746308, mlm loss: 8.746308, speed: 0.872267 steps/s, speed: 6.978132 samples/s, speed: 3572.803642 tokens/s, learning rate: 5.730e-06, loss_scalings: 13421.773438, pp_loss: 8.785788
[INFO] 2021-07-12 18:41:07,031 [run_pretraining.py:  512]:	********exe.run_574******* 
[INFO] 2021-07-12 18:41:07,903 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:07,903 [run_pretraining.py:  534]:	loss/total_loss, 8.331250190734863, 575
[INFO] 2021-07-12 18:41:07,903 [run_pretraining.py:  535]:	loss/mlm_loss, 8.331250190734863, 575
[INFO] 2021-07-12 18:41:07,903 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.7399997785978485e-06, 575
[INFO] 2021-07-12 18:41:07,904 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 575
[INFO] 2021-07-12 18:41:07,904 [run_pretraining.py:  558]:	worker_index: 6, step: 575, cost: 8.331250, mlm loss: 8.331250, speed: 1.146451 steps/s, speed: 9.171609 samples/s, speed: 4695.863750 tokens/s, learning rate: 5.740e-06, loss_scalings: 13421.773438, pp_loss: 8.629607
[INFO] 2021-07-12 18:41:07,904 [run_pretraining.py:  512]:	********exe.run_575******* 
[INFO] 2021-07-12 18:41:08,817 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:08,818 [run_pretraining.py:  534]:	loss/total_loss, 9.013081550598145, 576
[INFO] 2021-07-12 18:41:08,818 [run_pretraining.py:  535]:	loss/mlm_loss, 9.013081550598145, 576
[INFO] 2021-07-12 18:41:08,818 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.750000127591193e-06, 576
[INFO] 2021-07-12 18:41:08,818 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 576
[INFO] 2021-07-12 18:41:08,818 [run_pretraining.py:  558]:	worker_index: 6, step: 576, cost: 9.013082, mlm loss: 9.013082, speed: 1.094129 steps/s, speed: 8.753034 samples/s, speed: 4481.553411 tokens/s, learning rate: 5.750e-06, loss_scalings: 13421.773438, pp_loss: 8.607531
[INFO] 2021-07-12 18:41:08,818 [run_pretraining.py:  512]:	********exe.run_576******* 
[INFO] 2021-07-12 18:41:09,730 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:09,730 [run_pretraining.py:  534]:	loss/total_loss, 8.446002006530762, 577
[INFO] 2021-07-12 18:41:09,731 [run_pretraining.py:  535]:	loss/mlm_loss, 8.446002006530762, 577
[INFO] 2021-07-12 18:41:09,731 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.759999567089835e-06, 577
[INFO] 2021-07-12 18:41:09,731 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 577
[INFO] 2021-07-12 18:41:09,731 [run_pretraining.py:  558]:	worker_index: 6, step: 577, cost: 8.446002, mlm loss: 8.446002, speed: 1.096819 steps/s, speed: 8.774555 samples/s, speed: 4492.571950 tokens/s, learning rate: 5.760e-06, loss_scalings: 13421.773438, pp_loss: 7.992886
[INFO] 2021-07-12 18:41:09,731 [run_pretraining.py:  512]:	********exe.run_577******* 
[INFO] 2021-07-12 18:41:10,658 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:10,659 [run_pretraining.py:  534]:	loss/total_loss, 9.09280014038086, 578
[INFO] 2021-07-12 18:41:10,659 [run_pretraining.py:  535]:	loss/mlm_loss, 9.09280014038086, 578
[INFO] 2021-07-12 18:41:10,659 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.769999916083179e-06, 578
[INFO] 2021-07-12 18:41:10,659 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 578
[INFO] 2021-07-12 18:41:10,659 [run_pretraining.py:  558]:	worker_index: 6, step: 578, cost: 9.092800, mlm loss: 9.092800, speed: 1.078217 steps/s, speed: 8.625736 samples/s, speed: 4416.376807 tokens/s, learning rate: 5.770e-06, loss_scalings: 13421.773438, pp_loss: 8.939965
[INFO] 2021-07-12 18:41:10,659 [run_pretraining.py:  512]:	********exe.run_578******* 
[INFO] 2021-07-12 18:41:11,576 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:11,577 [run_pretraining.py:  534]:	loss/total_loss, 9.1541109085083, 579
[INFO] 2021-07-12 18:41:11,577 [run_pretraining.py:  535]:	loss/mlm_loss, 9.1541109085083, 579
[INFO] 2021-07-12 18:41:11,577 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.779999810329173e-06, 579
[INFO] 2021-07-12 18:41:11,577 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 579
[INFO] 2021-07-12 18:41:11,577 [run_pretraining.py:  558]:	worker_index: 6, step: 579, cost: 9.154111, mlm loss: 9.154111, speed: 1.089812 steps/s, speed: 8.718494 samples/s, speed: 4463.868937 tokens/s, learning rate: 5.780e-06, loss_scalings: 13421.773438, pp_loss: 9.014022
[INFO] 2021-07-12 18:41:11,577 [run_pretraining.py:  512]:	********exe.run_579******* 
[INFO] 2021-07-12 18:41:12,487 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:12,488 [run_pretraining.py:  534]:	loss/total_loss, 8.838172912597656, 580
[INFO] 2021-07-12 18:41:12,488 [run_pretraining.py:  535]:	loss/mlm_loss, 8.838172912597656, 580
[INFO] 2021-07-12 18:41:12,488 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.789999704575166e-06, 580
[INFO] 2021-07-12 18:41:12,488 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 580
[INFO] 2021-07-12 18:41:12,488 [run_pretraining.py:  558]:	worker_index: 6, step: 580, cost: 8.838173, mlm loss: 8.838173, speed: 1.098888 steps/s, speed: 8.791104 samples/s, speed: 4501.045410 tokens/s, learning rate: 5.790e-06, loss_scalings: 13421.773438, pp_loss: 8.024143
[INFO] 2021-07-12 18:41:12,488 [run_pretraining.py:  512]:	********exe.run_580******* 
[INFO] 2021-07-12 18:41:13,412 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:13,413 [run_pretraining.py:  534]:	loss/total_loss, 8.937152862548828, 581
[INFO] 2021-07-12 18:41:13,413 [run_pretraining.py:  535]:	loss/mlm_loss, 8.937152862548828, 581
[INFO] 2021-07-12 18:41:13,413 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.7999995988211595e-06, 581
[INFO] 2021-07-12 18:41:13,413 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 581
[INFO] 2021-07-12 18:41:13,413 [run_pretraining.py:  558]:	worker_index: 6, step: 581, cost: 8.937153, mlm loss: 8.937153, speed: 1.081647 steps/s, speed: 8.653177 samples/s, speed: 4430.426478 tokens/s, learning rate: 5.800e-06, loss_scalings: 13421.773438, pp_loss: 8.678328
[INFO] 2021-07-12 18:41:13,413 [run_pretraining.py:  512]:	********exe.run_581******* 
[INFO] 2021-07-12 18:41:14,327 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:14,328 [run_pretraining.py:  534]:	loss/total_loss, 8.240718841552734, 582
[INFO] 2021-07-12 18:41:14,328 [run_pretraining.py:  535]:	loss/mlm_loss, 8.240718841552734, 582
[INFO] 2021-07-12 18:41:14,328 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.809999947814504e-06, 582
[INFO] 2021-07-12 18:41:14,328 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 582
[INFO] 2021-07-12 18:41:14,328 [run_pretraining.py:  558]:	worker_index: 6, step: 582, cost: 8.240719, mlm loss: 8.240719, speed: 1.093820 steps/s, speed: 8.750557 samples/s, speed: 4480.285338 tokens/s, learning rate: 5.810e-06, loss_scalings: 13421.773438, pp_loss: 7.995500
[INFO] 2021-07-12 18:41:14,328 [run_pretraining.py:  512]:	********exe.run_582******* 
[INFO] 2021-07-12 18:41:15,239 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:15,239 [run_pretraining.py:  534]:	loss/total_loss, 8.349464416503906, 583
[INFO] 2021-07-12 18:41:15,239 [run_pretraining.py:  535]:	loss/mlm_loss, 8.349464416503906, 583
[INFO] 2021-07-12 18:41:15,239 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.819999842060497e-06, 583
[INFO] 2021-07-12 18:41:15,239 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 583
[INFO] 2021-07-12 18:41:15,240 [run_pretraining.py:  558]:	worker_index: 6, step: 583, cost: 8.349464, mlm loss: 8.349464, speed: 1.098099 steps/s, speed: 8.784789 samples/s, speed: 4497.811864 tokens/s, learning rate: 5.820e-06, loss_scalings: 13421.773438, pp_loss: 8.893587
[INFO] 2021-07-12 18:41:15,240 [run_pretraining.py:  512]:	********exe.run_583******* 
[INFO] 2021-07-12 18:41:16,164 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:16,164 [run_pretraining.py:  534]:	loss/total_loss, 8.578824996948242, 584
[INFO] 2021-07-12 18:41:16,164 [run_pretraining.py:  535]:	loss/mlm_loss, 8.578824996948242, 584
[INFO] 2021-07-12 18:41:16,164 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.82999973630649e-06, 584
[INFO] 2021-07-12 18:41:16,164 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 584
[INFO] 2021-07-12 18:41:16,165 [run_pretraining.py:  558]:	worker_index: 6, step: 584, cost: 8.578825, mlm loss: 8.578825, speed: 1.081923 steps/s, speed: 8.655384 samples/s, speed: 4431.556738 tokens/s, learning rate: 5.830e-06, loss_scalings: 13421.773438, pp_loss: 8.525042
[INFO] 2021-07-12 18:41:16,165 [run_pretraining.py:  512]:	********exe.run_584******* 
[INFO] 2021-07-12 18:41:17,072 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:17,073 [run_pretraining.py:  534]:	loss/total_loss, 9.495772361755371, 585
[INFO] 2021-07-12 18:41:17,073 [run_pretraining.py:  535]:	loss/mlm_loss, 9.495772361755371, 585
[INFO] 2021-07-12 18:41:17,073 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.840000085299835e-06, 585
[INFO] 2021-07-12 18:41:17,073 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 585
[INFO] 2021-07-12 18:41:17,073 [run_pretraining.py:  558]:	worker_index: 6, step: 585, cost: 9.495772, mlm loss: 9.495772, speed: 1.101727 steps/s, speed: 8.813815 samples/s, speed: 4512.673323 tokens/s, learning rate: 5.840e-06, loss_scalings: 13421.773438, pp_loss: 8.951475
[INFO] 2021-07-12 18:41:17,073 [run_pretraining.py:  512]:	********exe.run_585******* 
[INFO] 2021-07-12 18:41:17,987 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:17,987 [run_pretraining.py:  534]:	loss/total_loss, 9.187955856323242, 586
[INFO] 2021-07-12 18:41:17,987 [run_pretraining.py:  535]:	loss/mlm_loss, 9.187955856323242, 586
[INFO] 2021-07-12 18:41:17,988 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.849999979545828e-06, 586
[INFO] 2021-07-12 18:41:17,988 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 586
[INFO] 2021-07-12 18:41:17,988 [run_pretraining.py:  558]:	worker_index: 6, step: 586, cost: 9.187956, mlm loss: 9.187956, speed: 1.094015 steps/s, speed: 8.752121 samples/s, speed: 4481.085835 tokens/s, learning rate: 5.850e-06, loss_scalings: 13421.773438, pp_loss: 8.757101
[INFO] 2021-07-12 18:41:17,988 [run_pretraining.py:  512]:	********exe.run_586******* 
[INFO] 2021-07-12 18:41:18,894 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:18,895 [run_pretraining.py:  534]:	loss/total_loss, 8.586222648620605, 587
[INFO] 2021-07-12 18:41:18,895 [run_pretraining.py:  535]:	loss/mlm_loss, 8.586222648620605, 587
[INFO] 2021-07-12 18:41:18,895 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.859999873791821e-06, 587
[INFO] 2021-07-12 18:41:18,895 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 587
[INFO] 2021-07-12 18:41:18,896 [run_pretraining.py:  558]:	worker_index: 6, step: 587, cost: 8.586223, mlm loss: 8.586223, speed: 1.102576 steps/s, speed: 8.820611 samples/s, speed: 4516.152646 tokens/s, learning rate: 5.860e-06, loss_scalings: 13421.773438, pp_loss: 8.746060
[INFO] 2021-07-12 18:41:18,896 [run_pretraining.py:  512]:	********exe.run_587******* 
[INFO] 2021-07-12 18:41:19,795 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:19,796 [run_pretraining.py:  534]:	loss/total_loss, 8.676724433898926, 588
[INFO] 2021-07-12 18:41:19,796 [run_pretraining.py:  535]:	loss/mlm_loss, 8.676724433898926, 588
[INFO] 2021-07-12 18:41:19,796 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.869999768037815e-06, 588
[INFO] 2021-07-12 18:41:19,796 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 588
[INFO] 2021-07-12 18:41:19,796 [run_pretraining.py:  558]:	worker_index: 6, step: 588, cost: 8.676724, mlm loss: 8.676724, speed: 1.111230 steps/s, speed: 8.889837 samples/s, speed: 4551.596551 tokens/s, learning rate: 5.870e-06, loss_scalings: 13421.773438, pp_loss: 8.552711
[INFO] 2021-07-12 18:41:19,796 [run_pretraining.py:  512]:	********exe.run_588******* 
[INFO] 2021-07-12 18:41:20,703 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:20,703 [run_pretraining.py:  534]:	loss/total_loss, 8.22403335571289, 589
[INFO] 2021-07-12 18:41:20,704 [run_pretraining.py:  535]:	loss/mlm_loss, 8.22403335571289, 589
[INFO] 2021-07-12 18:41:20,704 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.880000117031159e-06, 589
[INFO] 2021-07-12 18:41:20,704 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 589
[INFO] 2021-07-12 18:41:20,704 [run_pretraining.py:  558]:	worker_index: 6, step: 589, cost: 8.224033, mlm loss: 8.224033, speed: 1.102602 steps/s, speed: 8.820815 samples/s, speed: 4516.257121 tokens/s, learning rate: 5.880e-06, loss_scalings: 13421.773438, pp_loss: 7.744125
[INFO] 2021-07-12 18:41:20,704 [run_pretraining.py:  512]:	********exe.run_589******* 
[INFO] 2021-07-12 18:41:21,667 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:21,668 [run_pretraining.py:  534]:	loss/total_loss, 8.920849800109863, 590
[INFO] 2021-07-12 18:41:21,668 [run_pretraining.py:  535]:	loss/mlm_loss, 8.920849800109863, 590
[INFO] 2021-07-12 18:41:21,668 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.889999556529801e-06, 590
[INFO] 2021-07-12 18:41:21,668 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 590
[INFO] 2021-07-12 18:41:21,668 [run_pretraining.py:  558]:	worker_index: 6, step: 590, cost: 8.920850, mlm loss: 8.920850, speed: 1.037529 steps/s, speed: 8.300233 samples/s, speed: 4249.719470 tokens/s, learning rate: 5.890e-06, loss_scalings: 13421.773438, pp_loss: 9.001822
[INFO] 2021-07-12 18:41:21,668 [run_pretraining.py:  512]:	********exe.run_590******* 
[INFO] 2021-07-12 18:41:22,568 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:22,568 [run_pretraining.py:  534]:	loss/total_loss, 8.953557014465332, 591
[INFO] 2021-07-12 18:41:22,568 [run_pretraining.py:  535]:	loss/mlm_loss, 8.953557014465332, 591
[INFO] 2021-07-12 18:41:22,568 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.8999999055231456e-06, 591
[INFO] 2021-07-12 18:41:22,569 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 591
[INFO] 2021-07-12 18:41:22,569 [run_pretraining.py:  558]:	worker_index: 6, step: 591, cost: 8.953557, mlm loss: 8.953557, speed: 1.111603 steps/s, speed: 8.892827 samples/s, speed: 4553.127340 tokens/s, learning rate: 5.900e-06, loss_scalings: 13421.773438, pp_loss: 9.005956
[INFO] 2021-07-12 18:41:22,569 [run_pretraining.py:  512]:	********exe.run_591******* 
[INFO] 2021-07-12 18:41:23,482 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:23,483 [run_pretraining.py:  534]:	loss/total_loss, 8.709091186523438, 592
[INFO] 2021-07-12 18:41:23,483 [run_pretraining.py:  535]:	loss/mlm_loss, 8.709091186523438, 592
[INFO] 2021-07-12 18:41:23,483 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.909999799769139e-06, 592
[INFO] 2021-07-12 18:41:23,483 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 592
[INFO] 2021-07-12 18:41:23,483 [run_pretraining.py:  558]:	worker_index: 6, step: 592, cost: 8.709091, mlm loss: 8.709091, speed: 1.094062 steps/s, speed: 8.752500 samples/s, speed: 4481.279867 tokens/s, learning rate: 5.910e-06, loss_scalings: 13421.773438, pp_loss: 8.935241
[INFO] 2021-07-12 18:41:23,483 [run_pretraining.py:  512]:	********exe.run_592******* 
[INFO] 2021-07-12 18:41:24,393 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:24,394 [run_pretraining.py:  534]:	loss/total_loss, 9.158458709716797, 593
[INFO] 2021-07-12 18:41:24,394 [run_pretraining.py:  535]:	loss/mlm_loss, 9.158458709716797, 593
[INFO] 2021-07-12 18:41:24,394 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.919999694015132e-06, 593
[INFO] 2021-07-12 18:41:24,394 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 593
[INFO] 2021-07-12 18:41:24,394 [run_pretraining.py:  558]:	worker_index: 6, step: 593, cost: 9.158459, mlm loss: 9.158459, speed: 1.098616 steps/s, speed: 8.788931 samples/s, speed: 4499.932470 tokens/s, learning rate: 5.920e-06, loss_scalings: 13421.773438, pp_loss: 8.619523
[INFO] 2021-07-12 18:41:24,394 [run_pretraining.py:  512]:	********exe.run_593******* 
[INFO] 2021-07-12 18:41:25,356 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:25,356 [run_pretraining.py:  534]:	loss/total_loss, 8.502767562866211, 594
[INFO] 2021-07-12 18:41:25,356 [run_pretraining.py:  535]:	loss/mlm_loss, 8.502767562866211, 594
[INFO] 2021-07-12 18:41:25,356 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.9300000430084765e-06, 594
[INFO] 2021-07-12 18:41:25,356 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 594
[INFO] 2021-07-12 18:41:25,357 [run_pretraining.py:  558]:	worker_index: 6, step: 594, cost: 8.502768, mlm loss: 8.502768, speed: 1.040098 steps/s, speed: 8.320781 samples/s, speed: 4260.239950 tokens/s, learning rate: 5.930e-06, loss_scalings: 13421.773438, pp_loss: 8.795473
[INFO] 2021-07-12 18:41:25,357 [run_pretraining.py:  512]:	********exe.run_594******* 
[INFO] 2021-07-12 18:41:26,287 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:26,288 [run_pretraining.py:  534]:	loss/total_loss, 8.60461711883545, 595
[INFO] 2021-07-12 18:41:26,288 [run_pretraining.py:  535]:	loss/mlm_loss, 8.60461711883545, 595
[INFO] 2021-07-12 18:41:26,288 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.93999993725447e-06, 595
[INFO] 2021-07-12 18:41:26,288 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 595
[INFO] 2021-07-12 18:41:26,288 [run_pretraining.py:  558]:	worker_index: 6, step: 595, cost: 8.604617, mlm loss: 8.604617, speed: 1.074483 steps/s, speed: 8.595865 samples/s, speed: 4401.082906 tokens/s, learning rate: 5.940e-06, loss_scalings: 13421.773438, pp_loss: 8.646418
[INFO] 2021-07-12 18:41:26,288 [run_pretraining.py:  512]:	********exe.run_595******* 
[INFO] 2021-07-12 18:41:27,221 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:27,222 [run_pretraining.py:  534]:	loss/total_loss, 8.318090438842773, 596
[INFO] 2021-07-12 18:41:27,222 [run_pretraining.py:  535]:	loss/mlm_loss, 8.318090438842773, 596
[INFO] 2021-07-12 18:41:27,222 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.949999831500463e-06, 596
[INFO] 2021-07-12 18:41:27,222 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 596
[INFO] 2021-07-12 18:41:27,222 [run_pretraining.py:  558]:	worker_index: 6, step: 596, cost: 8.318090, mlm loss: 8.318090, speed: 1.070931 steps/s, speed: 8.567449 samples/s, speed: 4386.534000 tokens/s, learning rate: 5.950e-06, loss_scalings: 13421.773438, pp_loss: 8.592778
[INFO] 2021-07-12 18:41:27,223 [run_pretraining.py:  512]:	********exe.run_596******* 
[INFO] 2021-07-12 18:41:28,135 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:28,135 [run_pretraining.py:  534]:	loss/total_loss, 8.825915336608887, 597
[INFO] 2021-07-12 18:41:28,135 [run_pretraining.py:  535]:	loss/mlm_loss, 8.825915336608887, 597
[INFO] 2021-07-12 18:41:28,135 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.9599997257464565e-06, 597
[INFO] 2021-07-12 18:41:28,136 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 597
[INFO] 2021-07-12 18:41:28,136 [run_pretraining.py:  558]:	worker_index: 6, step: 597, cost: 8.825915, mlm loss: 8.825915, speed: 1.095891 steps/s, speed: 8.767131 samples/s, speed: 4488.771111 tokens/s, learning rate: 5.960e-06, loss_scalings: 13421.773438, pp_loss: 8.888785
[INFO] 2021-07-12 18:41:28,136 [run_pretraining.py:  512]:	********exe.run_597******* 
[INFO] 2021-07-12 18:41:29,045 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:29,045 [run_pretraining.py:  534]:	loss/total_loss, 8.666929244995117, 598
[INFO] 2021-07-12 18:41:29,045 [run_pretraining.py:  535]:	loss/mlm_loss, 8.666929244995117, 598
[INFO] 2021-07-12 18:41:29,045 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.970000074739801e-06, 598
[INFO] 2021-07-12 18:41:29,046 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 598
[INFO] 2021-07-12 18:41:29,046 [run_pretraining.py:  558]:	worker_index: 6, step: 598, cost: 8.666929, mlm loss: 8.666929, speed: 1.099889 steps/s, speed: 8.799113 samples/s, speed: 4505.145866 tokens/s, learning rate: 5.970e-06, loss_scalings: 13421.773438, pp_loss: 8.607496
[INFO] 2021-07-12 18:41:29,046 [run_pretraining.py:  512]:	********exe.run_598******* 
[INFO] 2021-07-12 18:41:29,963 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:29,964 [run_pretraining.py:  534]:	loss/total_loss, 8.913031578063965, 599
[INFO] 2021-07-12 18:41:29,964 [run_pretraining.py:  535]:	loss/mlm_loss, 8.913031578063965, 599
[INFO] 2021-07-12 18:41:29,964 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.979999968985794e-06, 599
[INFO] 2021-07-12 18:41:29,964 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 599
[INFO] 2021-07-12 18:41:29,964 [run_pretraining.py:  558]:	worker_index: 6, step: 599, cost: 8.913032, mlm loss: 8.913032, speed: 1.089519 steps/s, speed: 8.716150 samples/s, speed: 4462.668812 tokens/s, learning rate: 5.980e-06, loss_scalings: 13421.773438, pp_loss: 8.810722
[INFO] 2021-07-12 18:41:29,964 [run_pretraining.py:  512]:	********exe.run_599******* 
[INFO] 2021-07-12 18:41:30,878 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:30,878 [run_pretraining.py:  534]:	loss/total_loss, 8.795832633972168, 600
[INFO] 2021-07-12 18:41:30,878 [run_pretraining.py:  535]:	loss/mlm_loss, 8.795832633972168, 600
[INFO] 2021-07-12 18:41:30,878 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.9899998632317875e-06, 600
[INFO] 2021-07-12 18:41:30,879 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 600
[INFO] 2021-07-12 18:41:30,879 [run_pretraining.py:  558]:	worker_index: 6, step: 600, cost: 8.795833, mlm loss: 8.795833, speed: 1.094310 steps/s, speed: 8.754482 samples/s, speed: 4482.294719 tokens/s, learning rate: 5.990e-06, loss_scalings: 13421.773438, pp_loss: 8.771118
[INFO] 2021-07-12 18:41:30,879 [run_pretraining.py:  512]:	********exe.run_600******* 
[INFO] 2021-07-12 18:41:31,786 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:31,787 [run_pretraining.py:  534]:	loss/total_loss, 8.889385223388672, 601
[INFO] 2021-07-12 18:41:31,787 [run_pretraining.py:  535]:	loss/mlm_loss, 8.889385223388672, 601
[INFO] 2021-07-12 18:41:31,787 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.999999757477781e-06, 601
[INFO] 2021-07-12 18:41:31,787 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 601
[INFO] 2021-07-12 18:41:31,787 [run_pretraining.py:  558]:	worker_index: 6, step: 601, cost: 8.889385, mlm loss: 8.889385, speed: 1.101757 steps/s, speed: 8.814056 samples/s, speed: 4512.796603 tokens/s, learning rate: 6.000e-06, loss_scalings: 13421.773438, pp_loss: 8.700394
[INFO] 2021-07-12 18:41:31,787 [run_pretraining.py:  512]:	********exe.run_601******* 
[INFO] 2021-07-12 18:41:32,701 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:32,702 [run_pretraining.py:  534]:	loss/total_loss, 8.617365837097168, 602
[INFO] 2021-07-12 18:41:32,702 [run_pretraining.py:  535]:	loss/mlm_loss, 8.617365837097168, 602
[INFO] 2021-07-12 18:41:32,702 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.010000106471125e-06, 602
[INFO] 2021-07-12 18:41:32,702 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 602
[INFO] 2021-07-12 18:41:32,702 [run_pretraining.py:  558]:	worker_index: 6, step: 602, cost: 8.617366, mlm loss: 8.617366, speed: 1.093641 steps/s, speed: 8.749127 samples/s, speed: 4479.552872 tokens/s, learning rate: 6.010e-06, loss_scalings: 13421.773438, pp_loss: 8.732827
[INFO] 2021-07-12 18:41:32,702 [run_pretraining.py:  512]:	********exe.run_602******* 
[INFO] 2021-07-12 18:41:33,617 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:33,618 [run_pretraining.py:  534]:	loss/total_loss, 9.050980567932129, 603
[INFO] 2021-07-12 18:41:33,618 [run_pretraining.py:  535]:	loss/mlm_loss, 9.050980567932129, 603
[INFO] 2021-07-12 18:41:33,618 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.0199995459697675e-06, 603
[INFO] 2021-07-12 18:41:33,618 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 603
[INFO] 2021-07-12 18:41:33,618 [run_pretraining.py:  558]:	worker_index: 6, step: 603, cost: 9.050981, mlm loss: 9.050981, speed: 1.092653 steps/s, speed: 8.741220 samples/s, speed: 4475.504679 tokens/s, learning rate: 6.020e-06, loss_scalings: 13421.773438, pp_loss: 8.834519
[INFO] 2021-07-12 18:41:33,618 [run_pretraining.py:  512]:	********exe.run_603******* 
[INFO] 2021-07-12 18:41:34,539 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:34,540 [run_pretraining.py:  534]:	loss/total_loss, 8.551443099975586, 604
[INFO] 2021-07-12 18:41:34,540 [run_pretraining.py:  535]:	loss/mlm_loss, 8.551443099975586, 604
[INFO] 2021-07-12 18:41:34,540 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.029999894963112e-06, 604
[INFO] 2021-07-12 18:41:34,540 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 604
[INFO] 2021-07-12 18:41:34,540 [run_pretraining.py:  558]:	worker_index: 6, step: 604, cost: 8.551443, mlm loss: 8.551443, speed: 1.084911 steps/s, speed: 8.679286 samples/s, speed: 4443.794415 tokens/s, learning rate: 6.030e-06, loss_scalings: 13421.773438, pp_loss: 8.699154
[INFO] 2021-07-12 18:41:34,540 [run_pretraining.py:  512]:	********exe.run_604******* 
[INFO] 2021-07-12 18:41:35,447 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:35,448 [run_pretraining.py:  534]:	loss/total_loss, 8.34865951538086, 605
[INFO] 2021-07-12 18:41:35,448 [run_pretraining.py:  535]:	loss/mlm_loss, 8.34865951538086, 605
[INFO] 2021-07-12 18:41:35,448 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.040000243956456e-06, 605
[INFO] 2021-07-12 18:41:35,448 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 605
[INFO] 2021-07-12 18:41:35,448 [run_pretraining.py:  558]:	worker_index: 6, step: 605, cost: 8.348660, mlm loss: 8.348660, speed: 1.102440 steps/s, speed: 8.819523 samples/s, speed: 4515.595926 tokens/s, learning rate: 6.040e-06, loss_scalings: 13421.773438, pp_loss: 8.568232
[INFO] 2021-07-12 18:41:35,448 [run_pretraining.py:  512]:	********exe.run_605******* 
[INFO] 2021-07-12 18:41:36,361 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:36,361 [run_pretraining.py:  534]:	loss/total_loss, 8.457197189331055, 606
[INFO] 2021-07-12 18:41:36,361 [run_pretraining.py:  535]:	loss/mlm_loss, 8.457197189331055, 606
[INFO] 2021-07-12 18:41:36,361 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.049999683455098e-06, 606
[INFO] 2021-07-12 18:41:36,361 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 606
[INFO] 2021-07-12 18:41:36,362 [run_pretraining.py:  558]:	worker_index: 6, step: 606, cost: 8.457197, mlm loss: 8.457197, speed: 1.095654 steps/s, speed: 8.765233 samples/s, speed: 4487.799045 tokens/s, learning rate: 6.050e-06, loss_scalings: 13421.773438, pp_loss: 8.620638
[INFO] 2021-07-12 18:41:36,362 [run_pretraining.py:  512]:	********exe.run_606******* 
[INFO] 2021-07-12 18:41:37,272 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:37,272 [run_pretraining.py:  534]:	loss/total_loss, 8.703619003295898, 607
[INFO] 2021-07-12 18:41:37,272 [run_pretraining.py:  535]:	loss/mlm_loss, 8.703619003295898, 607
[INFO] 2021-07-12 18:41:37,273 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.060000032448443e-06, 607
[INFO] 2021-07-12 18:41:37,273 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 607
[INFO] 2021-07-12 18:41:37,273 [run_pretraining.py:  558]:	worker_index: 6, step: 607, cost: 8.703619, mlm loss: 8.703619, speed: 1.098392 steps/s, speed: 8.787138 samples/s, speed: 4499.014474 tokens/s, learning rate: 6.060e-06, loss_scalings: 13421.773438, pp_loss: 8.621097
[INFO] 2021-07-12 18:41:37,273 [run_pretraining.py:  512]:	********exe.run_607******* 
[INFO] 2021-07-12 18:41:38,192 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:38,192 [run_pretraining.py:  534]:	loss/total_loss, 8.390243530273438, 608
[INFO] 2021-07-12 18:41:38,192 [run_pretraining.py:  535]:	loss/mlm_loss, 8.390243530273438, 608
[INFO] 2021-07-12 18:41:38,192 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.069999926694436e-06, 608
[INFO] 2021-07-12 18:41:38,193 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 608
[INFO] 2021-07-12 18:41:38,193 [run_pretraining.py:  558]:	worker_index: 6, step: 608, cost: 8.390244, mlm loss: 8.390244, speed: 1.087933 steps/s, speed: 8.703462 samples/s, speed: 4456.172685 tokens/s, learning rate: 6.070e-06, loss_scalings: 13421.773438, pp_loss: 8.491364
[INFO] 2021-07-12 18:41:38,193 [run_pretraining.py:  512]:	********exe.run_608******* 
[INFO] 2021-07-12 18:41:39,109 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:39,109 [run_pretraining.py:  534]:	loss/total_loss, 8.410719871520996, 609
[INFO] 2021-07-12 18:41:39,109 [run_pretraining.py:  535]:	loss/mlm_loss, 8.410719871520996, 609
[INFO] 2021-07-12 18:41:39,109 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.079999820940429e-06, 609
[INFO] 2021-07-12 18:41:39,110 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 609
[INFO] 2021-07-12 18:41:39,110 [run_pretraining.py:  558]:	worker_index: 6, step: 609, cost: 8.410720, mlm loss: 8.410720, speed: 1.091310 steps/s, speed: 8.730481 samples/s, speed: 4470.006027 tokens/s, learning rate: 6.080e-06, loss_scalings: 13421.773438, pp_loss: 8.654943
[INFO] 2021-07-12 18:41:39,110 [run_pretraining.py:  512]:	********exe.run_609******* 
[INFO] 2021-07-12 18:41:40,033 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:40,034 [run_pretraining.py:  534]:	loss/total_loss, 8.231870651245117, 610
[INFO] 2021-07-12 18:41:40,034 [run_pretraining.py:  535]:	loss/mlm_loss, 8.231870651245117, 610
[INFO] 2021-07-12 18:41:40,034 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.089999715186423e-06, 610
[INFO] 2021-07-12 18:41:40,034 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 610
[INFO] 2021-07-12 18:41:40,034 [run_pretraining.py:  558]:	worker_index: 6, step: 610, cost: 8.231871, mlm loss: 8.231871, speed: 1.082508 steps/s, speed: 8.660066 samples/s, speed: 4433.954019 tokens/s, learning rate: 6.090e-06, loss_scalings: 13421.773438, pp_loss: 8.552433
[INFO] 2021-07-12 18:41:40,034 [run_pretraining.py:  512]:	********exe.run_610******* 
[INFO] 2021-07-12 18:41:40,945 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:40,946 [run_pretraining.py:  534]:	loss/total_loss, 8.909749031066895, 611
[INFO] 2021-07-12 18:41:40,946 [run_pretraining.py:  535]:	loss/mlm_loss, 8.909749031066895, 611
[INFO] 2021-07-12 18:41:40,946 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.100000064179767e-06, 611
[INFO] 2021-07-12 18:41:40,946 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 611
[INFO] 2021-07-12 18:41:40,946 [run_pretraining.py:  558]:	worker_index: 6, step: 611, cost: 8.909749, mlm loss: 8.909749, speed: 1.097604 steps/s, speed: 8.780830 samples/s, speed: 4495.785021 tokens/s, learning rate: 6.100e-06, loss_scalings: 13421.773438, pp_loss: 8.767201
[INFO] 2021-07-12 18:41:40,946 [run_pretraining.py:  512]:	********exe.run_611******* 
[INFO] 2021-07-12 18:41:41,867 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:41,868 [run_pretraining.py:  534]:	loss/total_loss, 8.743721008300781, 612
[INFO] 2021-07-12 18:41:41,868 [run_pretraining.py:  535]:	loss/mlm_loss, 8.743721008300781, 612
[INFO] 2021-07-12 18:41:41,868 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.109999503678409e-06, 612
[INFO] 2021-07-12 18:41:41,868 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 612
[INFO] 2021-07-12 18:41:41,868 [run_pretraining.py:  558]:	worker_index: 6, step: 612, cost: 8.743721, mlm loss: 8.743721, speed: 1.085406 steps/s, speed: 8.683248 samples/s, speed: 4445.822961 tokens/s, learning rate: 6.110e-06, loss_scalings: 13421.773438, pp_loss: 8.690722
[INFO] 2021-07-12 18:41:41,868 [run_pretraining.py:  512]:	********exe.run_612******* 
[INFO] 2021-07-12 18:41:42,784 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:42,784 [run_pretraining.py:  534]:	loss/total_loss, 8.48193073272705, 613
[INFO] 2021-07-12 18:41:42,784 [run_pretraining.py:  535]:	loss/mlm_loss, 8.48193073272705, 613
[INFO] 2021-07-12 18:41:42,784 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.119999852671754e-06, 613
[INFO] 2021-07-12 18:41:42,785 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 613
[INFO] 2021-07-12 18:41:42,785 [run_pretraining.py:  558]:	worker_index: 6, step: 613, cost: 8.481931, mlm loss: 8.481931, speed: 1.091804 steps/s, speed: 8.734435 samples/s, speed: 4472.030641 tokens/s, learning rate: 6.120e-06, loss_scalings: 13421.773438, pp_loss: 7.927565
[INFO] 2021-07-12 18:41:42,785 [run_pretraining.py:  512]:	********exe.run_613******* 
[INFO] 2021-07-12 18:41:43,694 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:43,694 [run_pretraining.py:  534]:	loss/total_loss, 8.716780662536621, 614
[INFO] 2021-07-12 18:41:43,694 [run_pretraining.py:  535]:	loss/mlm_loss, 8.716780662536621, 614
[INFO] 2021-07-12 18:41:43,694 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.129999746917747e-06, 614
[INFO] 2021-07-12 18:41:43,694 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 614
[INFO] 2021-07-12 18:41:43,695 [run_pretraining.py:  558]:	worker_index: 6, step: 614, cost: 8.716781, mlm loss: 8.716781, speed: 1.099834 steps/s, speed: 8.798670 samples/s, speed: 4504.919048 tokens/s, learning rate: 6.130e-06, loss_scalings: 13421.773438, pp_loss: 8.416911
[INFO] 2021-07-12 18:41:43,695 [run_pretraining.py:  512]:	********exe.run_614******* 
[INFO] 2021-07-12 18:41:44,615 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:44,616 [run_pretraining.py:  534]:	loss/total_loss, 8.70921516418457, 615
[INFO] 2021-07-12 18:41:44,616 [run_pretraining.py:  535]:	loss/mlm_loss, 8.70921516418457, 615
[INFO] 2021-07-12 18:41:44,616 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.13999964116374e-06, 615
[INFO] 2021-07-12 18:41:44,616 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 615
[INFO] 2021-07-12 18:41:44,616 [run_pretraining.py:  558]:	worker_index: 6, step: 615, cost: 8.709215, mlm loss: 8.709215, speed: 1.086063 steps/s, speed: 8.688507 samples/s, speed: 4448.515597 tokens/s, learning rate: 6.140e-06, loss_scalings: 13421.773438, pp_loss: 8.570438
[INFO] 2021-07-12 18:41:44,616 [run_pretraining.py:  512]:	********exe.run_615******* 
[INFO] 2021-07-12 18:42:10,720 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:10,721 [run_pretraining.py:  534]:	loss/total_loss, 9.090368270874023, 616
[INFO] 2021-07-12 18:42:10,721 [run_pretraining.py:  535]:	loss/mlm_loss, 9.090368270874023, 616
[INFO] 2021-07-12 18:42:10,721 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.1499999901570845e-06, 616
[INFO] 2021-07-12 18:42:10,721 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 616
[INFO] 2021-07-12 18:42:10,721 [run_pretraining.py:  558]:	worker_index: 6, step: 616, cost: 9.090368, mlm loss: 9.090368, speed: 0.038308 steps/s, speed: 0.306465 samples/s, speed: 156.909833 tokens/s, learning rate: 6.150e-06, loss_scalings: 13421.773438, pp_loss: 8.604008
[INFO] 2021-07-12 18:42:10,721 [run_pretraining.py:  512]:	********exe.run_616******* 
[INFO] 2021-07-12 18:42:11,635 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:11,636 [run_pretraining.py:  534]:	loss/total_loss, 8.626211166381836, 617
[INFO] 2021-07-12 18:42:11,636 [run_pretraining.py:  535]:	loss/mlm_loss, 8.626211166381836, 617
[INFO] 2021-07-12 18:42:11,636 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.159999884403078e-06, 617
[INFO] 2021-07-12 18:42:11,636 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 617
[INFO] 2021-07-12 18:42:11,636 [run_pretraining.py:  558]:	worker_index: 6, step: 617, cost: 8.626211, mlm loss: 8.626211, speed: 1.093613 steps/s, speed: 8.748901 samples/s, speed: 4479.437241 tokens/s, learning rate: 6.160e-06, loss_scalings: 13421.773438, pp_loss: 8.690442
[INFO] 2021-07-12 18:42:11,636 [run_pretraining.py:  512]:	********exe.run_617******* 
[INFO] 2021-07-12 18:42:12,554 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:12,555 [run_pretraining.py:  534]:	loss/total_loss, 8.838056564331055, 618
[INFO] 2021-07-12 18:42:12,555 [run_pretraining.py:  535]:	loss/mlm_loss, 8.838056564331055, 618
[INFO] 2021-07-12 18:42:12,555 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.169999778649071e-06, 618
[INFO] 2021-07-12 18:42:12,555 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 618
[INFO] 2021-07-12 18:42:12,555 [run_pretraining.py:  558]:	worker_index: 6, step: 618, cost: 8.838057, mlm loss: 8.838057, speed: 1.088769 steps/s, speed: 8.710152 samples/s, speed: 4459.597809 tokens/s, learning rate: 6.170e-06, loss_scalings: 13421.773438, pp_loss: 8.715506
[INFO] 2021-07-12 18:42:12,555 [run_pretraining.py:  512]:	********exe.run_618******* 
[INFO] 2021-07-12 18:42:13,467 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:13,468 [run_pretraining.py:  534]:	loss/total_loss, 8.786745071411133, 619
[INFO] 2021-07-12 18:42:13,468 [run_pretraining.py:  535]:	loss/mlm_loss, 8.786745071411133, 619
[INFO] 2021-07-12 18:42:13,468 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.179999672895065e-06, 619
[INFO] 2021-07-12 18:42:13,468 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 619
[INFO] 2021-07-12 18:42:13,468 [run_pretraining.py:  558]:	worker_index: 6, step: 619, cost: 8.786745, mlm loss: 8.786745, speed: 1.096349 steps/s, speed: 8.770791 samples/s, speed: 4490.644902 tokens/s, learning rate: 6.180e-06, loss_scalings: 13421.773438, pp_loss: 8.851248
[INFO] 2021-07-12 18:42:13,468 [run_pretraining.py:  512]:	********exe.run_619******* 
[INFO] 2021-07-12 18:42:14,382 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:14,382 [run_pretraining.py:  534]:	loss/total_loss, 8.511362075805664, 620
[INFO] 2021-07-12 18:42:14,382 [run_pretraining.py:  535]:	loss/mlm_loss, 8.511362075805664, 620
[INFO] 2021-07-12 18:42:14,382 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.190000021888409e-06, 620
[INFO] 2021-07-12 18:42:14,383 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 620
[INFO] 2021-07-12 18:42:14,383 [run_pretraining.py:  558]:	worker_index: 6, step: 620, cost: 8.511362, mlm loss: 8.511362, speed: 1.094354 steps/s, speed: 8.754834 samples/s, speed: 4482.474821 tokens/s, learning rate: 6.190e-06, loss_scalings: 13421.773438, pp_loss: 8.426031
[INFO] 2021-07-12 18:42:14,383 [run_pretraining.py:  512]:	********exe.run_620******* 
[INFO] 2021-07-12 18:42:15,292 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:15,292 [run_pretraining.py:  534]:	loss/total_loss, 8.237306594848633, 621
[INFO] 2021-07-12 18:42:15,292 [run_pretraining.py:  535]:	loss/mlm_loss, 8.237306594848633, 621
[INFO] 2021-07-12 18:42:15,292 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.199999916134402e-06, 621
[INFO] 2021-07-12 18:42:15,293 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 621
[INFO] 2021-07-12 18:42:15,293 [run_pretraining.py:  558]:	worker_index: 6, step: 621, cost: 8.237307, mlm loss: 8.237307, speed: 1.099706 steps/s, speed: 8.797650 samples/s, speed: 4504.396981 tokens/s, learning rate: 6.200e-06, loss_scalings: 13421.773438, pp_loss: 7.701760
[INFO] 2021-07-12 18:42:15,293 [run_pretraining.py:  512]:	********exe.run_621******* 
[INFO] 2021-07-12 18:42:16,205 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:16,205 [run_pretraining.py:  534]:	loss/total_loss, 8.607795715332031, 622
[INFO] 2021-07-12 18:42:16,205 [run_pretraining.py:  535]:	loss/mlm_loss, 8.607795715332031, 622
[INFO] 2021-07-12 18:42:16,205 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.2099998103803955e-06, 622
[INFO] 2021-07-12 18:42:16,206 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 622
[INFO] 2021-07-12 18:42:16,206 [run_pretraining.py:  558]:	worker_index: 6, step: 622, cost: 8.607796, mlm loss: 8.607796, speed: 1.096204 steps/s, speed: 8.769633 samples/s, speed: 4490.052207 tokens/s, learning rate: 6.210e-06, loss_scalings: 13421.773438, pp_loss: 8.521537
[INFO] 2021-07-12 18:42:16,206 [run_pretraining.py:  512]:	********exe.run_622******* 
[INFO] 2021-07-12 18:42:17,118 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:17,119 [run_pretraining.py:  534]:	loss/total_loss, 8.814887046813965, 623
[INFO] 2021-07-12 18:42:17,119 [run_pretraining.py:  535]:	loss/mlm_loss, 8.814887046813965, 623
[INFO] 2021-07-12 18:42:17,119 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.219999704626389e-06, 623
[INFO] 2021-07-12 18:42:17,119 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 623
[INFO] 2021-07-12 18:42:17,119 [run_pretraining.py:  558]:	worker_index: 6, step: 623, cost: 8.814887, mlm loss: 8.814887, speed: 1.095689 steps/s, speed: 8.765514 samples/s, speed: 4487.943246 tokens/s, learning rate: 6.220e-06, loss_scalings: 13421.773438, pp_loss: 8.634500
[INFO] 2021-07-12 18:42:17,119 [run_pretraining.py:  512]:	********exe.run_623******* 
[INFO] 2021-07-12 18:42:18,039 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:18,039 [run_pretraining.py:  534]:	loss/total_loss, 8.844261169433594, 624
[INFO] 2021-07-12 18:42:18,039 [run_pretraining.py:  535]:	loss/mlm_loss, 8.844261169433594, 624
[INFO] 2021-07-12 18:42:18,039 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.230000053619733e-06, 624
[INFO] 2021-07-12 18:42:18,040 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 624
[INFO] 2021-07-12 18:42:18,040 [run_pretraining.py:  558]:	worker_index: 6, step: 624, cost: 8.844261, mlm loss: 8.844261, speed: 1.087093 steps/s, speed: 8.696745 samples/s, speed: 4452.733199 tokens/s, learning rate: 6.230e-06, loss_scalings: 13421.773438, pp_loss: 8.654758
[INFO] 2021-07-12 18:42:18,040 [run_pretraining.py:  512]:	********exe.run_624******* 
[INFO] 2021-07-12 18:42:18,954 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:18,955 [run_pretraining.py:  534]:	loss/total_loss, 8.50915241241455, 625
[INFO] 2021-07-12 18:42:18,955 [run_pretraining.py:  535]:	loss/mlm_loss, 8.50915241241455, 625
[INFO] 2021-07-12 18:42:18,955 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.2399994931183755e-06, 625
[INFO] 2021-07-12 18:42:18,955 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 625
[INFO] 2021-07-12 18:42:18,955 [run_pretraining.py:  558]:	worker_index: 6, step: 625, cost: 8.509152, mlm loss: 8.509152, speed: 1.093331 steps/s, speed: 8.746650 samples/s, speed: 4478.284763 tokens/s, learning rate: 6.240e-06, loss_scalings: 13421.773438, pp_loss: 8.650052
[INFO] 2021-07-12 18:42:18,955 [run_pretraining.py:  512]:	********exe.run_625******* 
[INFO] 2021-07-12 18:42:19,865 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:19,865 [run_pretraining.py:  534]:	loss/total_loss, 5.833548069000244, 626
[INFO] 2021-07-12 18:42:19,865 [run_pretraining.py:  535]:	loss/mlm_loss, 5.833548069000244, 626
[INFO] 2021-07-12 18:42:19,865 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.24999984211172e-06, 626
[INFO] 2021-07-12 18:42:19,865 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 626
[INFO] 2021-07-12 18:42:19,866 [run_pretraining.py:  558]:	worker_index: 6, step: 626, cost: 5.833548, mlm loss: 5.833548, speed: 1.099095 steps/s, speed: 8.792756 samples/s, speed: 4501.891093 tokens/s, learning rate: 6.250e-06, loss_scalings: 13421.773438, pp_loss: 7.975301
[INFO] 2021-07-12 18:42:19,866 [run_pretraining.py:  512]:	********exe.run_626******* 
[INFO] 2021-07-12 18:42:20,772 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:20,773 [run_pretraining.py:  534]:	loss/total_loss, 8.880249977111816, 627
[INFO] 2021-07-12 18:42:20,773 [run_pretraining.py:  535]:	loss/mlm_loss, 8.880249977111816, 627
[INFO] 2021-07-12 18:42:20,773 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.260000191105064e-06, 627
[INFO] 2021-07-12 18:42:20,773 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 627
[INFO] 2021-07-12 18:42:20,773 [run_pretraining.py:  558]:	worker_index: 6, step: 627, cost: 8.880250, mlm loss: 8.880250, speed: 1.102646 steps/s, speed: 8.821169 samples/s, speed: 4516.438775 tokens/s, learning rate: 6.260e-06, loss_scalings: 13421.773438, pp_loss: 8.705006
[INFO] 2021-07-12 18:42:20,773 [run_pretraining.py:  512]:	********exe.run_627******* 
[INFO] 2021-07-12 18:42:21,690 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:21,691 [run_pretraining.py:  534]:	loss/total_loss, 8.911077499389648, 628
[INFO] 2021-07-12 18:42:21,691 [run_pretraining.py:  535]:	loss/mlm_loss, 8.911077499389648, 628
[INFO] 2021-07-12 18:42:21,691 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.270000085351057e-06, 628
[INFO] 2021-07-12 18:42:21,691 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 628
[INFO] 2021-07-12 18:42:21,691 [run_pretraining.py:  558]:	worker_index: 6, step: 628, cost: 8.911077, mlm loss: 8.911077, speed: 1.089828 steps/s, speed: 8.718628 samples/s, speed: 4463.937369 tokens/s, learning rate: 6.270e-06, loss_scalings: 13421.773438, pp_loss: 8.556248
[INFO] 2021-07-12 18:42:21,692 [run_pretraining.py:  512]:	********exe.run_628******* 
[INFO] 2021-07-12 18:42:22,607 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:22,607 [run_pretraining.py:  534]:	loss/total_loss, 8.563047409057617, 629
[INFO] 2021-07-12 18:42:22,607 [run_pretraining.py:  535]:	loss/mlm_loss, 8.563047409057617, 629
[INFO] 2021-07-12 18:42:22,608 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.2799995248497e-06, 629
[INFO] 2021-07-12 18:42:22,608 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 629
[INFO] 2021-07-12 18:42:22,608 [run_pretraining.py:  558]:	worker_index: 6, step: 629, cost: 8.563047, mlm loss: 8.563047, speed: 1.092258 steps/s, speed: 8.738065 samples/s, speed: 4473.889314 tokens/s, learning rate: 6.280e-06, loss_scalings: 13421.773438, pp_loss: 8.757668
[INFO] 2021-07-12 18:42:22,608 [run_pretraining.py:  512]:	********exe.run_629******* 
[INFO] 2021-07-12 18:42:23,526 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:23,526 [run_pretraining.py:  534]:	loss/total_loss, 8.755011558532715, 630
[INFO] 2021-07-12 18:42:23,526 [run_pretraining.py:  535]:	loss/mlm_loss, 8.755011558532715, 630
[INFO] 2021-07-12 18:42:23,526 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.289999873843044e-06, 630
[INFO] 2021-07-12 18:42:23,527 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 630
[INFO] 2021-07-12 18:42:23,527 [run_pretraining.py:  558]:	worker_index: 6, step: 630, cost: 8.755012, mlm loss: 8.755012, speed: 1.089133 steps/s, speed: 8.713061 samples/s, speed: 4461.087024 tokens/s, learning rate: 6.290e-06, loss_scalings: 13421.773438, pp_loss: 7.825263
[INFO] 2021-07-12 18:42:23,527 [run_pretraining.py:  512]:	********exe.run_630******* 
[INFO] 2021-07-12 18:42:24,439 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:24,439 [run_pretraining.py:  534]:	loss/total_loss, 8.684954643249512, 631
[INFO] 2021-07-12 18:42:24,439 [run_pretraining.py:  535]:	loss/mlm_loss, 8.684954643249512, 631
[INFO] 2021-07-12 18:42:24,439 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.299999768089037e-06, 631
[INFO] 2021-07-12 18:42:24,440 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 631
[INFO] 2021-07-12 18:42:24,440 [run_pretraining.py:  558]:	worker_index: 6, step: 631, cost: 8.684955, mlm loss: 8.684955, speed: 1.096105 steps/s, speed: 8.768838 samples/s, speed: 4489.645039 tokens/s, learning rate: 6.300e-06, loss_scalings: 13421.773438, pp_loss: 8.767914
[INFO] 2021-07-12 18:42:24,440 [run_pretraining.py:  512]:	********exe.run_631******* 
[INFO] 2021-07-12 18:42:25,361 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:25,362 [run_pretraining.py:  534]:	loss/total_loss, 8.751681327819824, 632
[INFO] 2021-07-12 18:42:25,362 [run_pretraining.py:  535]:	loss/mlm_loss, 8.751681327819824, 632
[INFO] 2021-07-12 18:42:25,362 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.310000117082382e-06, 632
[INFO] 2021-07-12 18:42:25,362 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 632
[INFO] 2021-07-12 18:42:25,362 [run_pretraining.py:  558]:	worker_index: 6, step: 632, cost: 8.751681, mlm loss: 8.751681, speed: 1.084415 steps/s, speed: 8.675321 samples/s, speed: 4441.764274 tokens/s, learning rate: 6.310e-06, loss_scalings: 13421.773438, pp_loss: 8.794010
[INFO] 2021-07-12 18:42:25,363 [run_pretraining.py:  512]:	********exe.run_632******* 
[INFO] 2021-07-12 18:42:26,284 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:26,284 [run_pretraining.py:  534]:	loss/total_loss, 9.243200302124023, 633
[INFO] 2021-07-12 18:42:26,285 [run_pretraining.py:  535]:	loss/mlm_loss, 9.243200302124023, 633
[INFO] 2021-07-12 18:42:26,285 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.319999556581024e-06, 633
[INFO] 2021-07-12 18:42:26,285 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 633
[INFO] 2021-07-12 18:42:26,285 [run_pretraining.py:  558]:	worker_index: 6, step: 633, cost: 9.243200, mlm loss: 9.243200, speed: 1.085076 steps/s, speed: 8.680606 samples/s, speed: 4444.470391 tokens/s, learning rate: 6.320e-06, loss_scalings: 13421.773438, pp_loss: 8.961848
[INFO] 2021-07-12 18:42:26,285 [run_pretraining.py:  512]:	********exe.run_633******* 
[INFO] 2021-07-12 18:42:27,209 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:27,210 [run_pretraining.py:  534]:	loss/total_loss, 8.4829740524292, 634
[INFO] 2021-07-12 18:42:27,210 [run_pretraining.py:  535]:	loss/mlm_loss, 8.4829740524292, 634
[INFO] 2021-07-12 18:42:27,210 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.329999905574368e-06, 634
[INFO] 2021-07-12 18:42:27,210 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 634
[INFO] 2021-07-12 18:42:27,210 [run_pretraining.py:  558]:	worker_index: 6, step: 634, cost: 8.482974, mlm loss: 8.482974, speed: 1.081292 steps/s, speed: 8.650335 samples/s, speed: 4428.971361 tokens/s, learning rate: 6.330e-06, loss_scalings: 13421.773438, pp_loss: 8.621776
[INFO] 2021-07-12 18:42:27,210 [run_pretraining.py:  512]:	********exe.run_634******* 
[INFO] 2021-07-12 18:42:28,128 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:28,129 [run_pretraining.py:  534]:	loss/total_loss, 8.896718978881836, 635
[INFO] 2021-07-12 18:42:28,129 [run_pretraining.py:  535]:	loss/mlm_loss, 8.896718978881836, 635
[INFO] 2021-07-12 18:42:28,129 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.339999799820362e-06, 635
[INFO] 2021-07-12 18:42:28,129 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 635
[INFO] 2021-07-12 18:42:28,129 [run_pretraining.py:  558]:	worker_index: 6, step: 635, cost: 8.896719, mlm loss: 8.896719, speed: 1.088815 steps/s, speed: 8.710518 samples/s, speed: 4459.785353 tokens/s, learning rate: 6.340e-06, loss_scalings: 13421.773438, pp_loss: 8.536520
[INFO] 2021-07-12 18:42:28,130 [run_pretraining.py:  512]:	********exe.run_635******* 
[INFO] 2021-07-12 18:42:29,073 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:29,074 [run_pretraining.py:  534]:	loss/total_loss, 8.729218482971191, 636
[INFO] 2021-07-12 18:42:29,074 [run_pretraining.py:  535]:	loss/mlm_loss, 8.729218482971191, 636
[INFO] 2021-07-12 18:42:29,074 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.350000148813706e-06, 636
[INFO] 2021-07-12 18:42:29,074 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 636
[INFO] 2021-07-12 18:42:29,074 [run_pretraining.py:  558]:	worker_index: 6, step: 636, cost: 8.729218, mlm loss: 8.729218, speed: 1.059122 steps/s, speed: 8.472980 samples/s, speed: 4338.165665 tokens/s, learning rate: 6.350e-06, loss_scalings: 13421.773438, pp_loss: 8.694244
[INFO] 2021-07-12 18:42:29,074 [run_pretraining.py:  512]:	********exe.run_636******* 
[INFO] 2021-07-12 18:42:29,998 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:29,999 [run_pretraining.py:  534]:	loss/total_loss, 8.370220184326172, 637
[INFO] 2021-07-12 18:42:29,999 [run_pretraining.py:  535]:	loss/mlm_loss, 8.370220184326172, 637
[INFO] 2021-07-12 18:42:29,999 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.360000043059699e-06, 637
[INFO] 2021-07-12 18:42:29,999 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 637
[INFO] 2021-07-12 18:42:29,999 [run_pretraining.py:  558]:	worker_index: 6, step: 637, cost: 8.370220, mlm loss: 8.370220, speed: 1.081912 steps/s, speed: 8.655293 samples/s, speed: 4431.509870 tokens/s, learning rate: 6.360e-06, loss_scalings: 13421.773438, pp_loss: 8.720268
[INFO] 2021-07-12 18:42:29,999 [run_pretraining.py:  512]:	********exe.run_637******* 
[INFO] 2021-07-12 18:42:30,922 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:30,923 [run_pretraining.py:  534]:	loss/total_loss, 8.554725646972656, 638
[INFO] 2021-07-12 18:42:30,923 [run_pretraining.py:  535]:	loss/mlm_loss, 8.554725646972656, 638
[INFO] 2021-07-12 18:42:30,923 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.369999482558342e-06, 638
[INFO] 2021-07-12 18:42:30,923 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 638
[INFO] 2021-07-12 18:42:30,923 [run_pretraining.py:  558]:	worker_index: 6, step: 638, cost: 8.554726, mlm loss: 8.554726, speed: 1.083010 steps/s, speed: 8.664078 samples/s, speed: 4436.007951 tokens/s, learning rate: 6.370e-06, loss_scalings: 13421.773438, pp_loss: 7.799516
[INFO] 2021-07-12 18:42:30,923 [run_pretraining.py:  512]:	********exe.run_638******* 
[INFO] 2021-07-12 18:42:31,831 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:31,832 [run_pretraining.py:  534]:	loss/total_loss, 8.986388206481934, 639
[INFO] 2021-07-12 18:42:31,832 [run_pretraining.py:  535]:	loss/mlm_loss, 8.986388206481934, 639
[INFO] 2021-07-12 18:42:31,832 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.379999831551686e-06, 639
[INFO] 2021-07-12 18:42:31,832 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 639
[INFO] 2021-07-12 18:42:31,832 [run_pretraining.py:  558]:	worker_index: 6, step: 639, cost: 8.986388, mlm loss: 8.986388, speed: 1.100881 steps/s, speed: 8.807046 samples/s, speed: 4509.207642 tokens/s, learning rate: 6.380e-06, loss_scalings: 13421.773438, pp_loss: 8.522759
[INFO] 2021-07-12 18:42:31,833 [run_pretraining.py:  512]:	********exe.run_639******* 
[INFO] 2021-07-12 18:42:32,827 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:32,827 [run_pretraining.py:  534]:	loss/total_loss, 8.98411750793457, 640
[INFO] 2021-07-12 18:42:32,828 [run_pretraining.py:  535]:	loss/mlm_loss, 8.98411750793457, 640
[INFO] 2021-07-12 18:42:32,828 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.39000018054503e-06, 640
[INFO] 2021-07-12 18:42:32,828 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 640
[INFO] 2021-07-12 18:42:32,828 [run_pretraining.py:  558]:	worker_index: 6, step: 640, cost: 8.984118, mlm loss: 8.984118, speed: 1.005409 steps/s, speed: 8.043268 samples/s, speed: 4118.153352 tokens/s, learning rate: 6.390e-06, loss_scalings: 13421.773438, pp_loss: 8.599043
[INFO] 2021-07-12 18:42:32,828 [run_pretraining.py:  512]:	********exe.run_640******* 
[INFO] 2021-07-12 18:42:33,732 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:33,733 [run_pretraining.py:  534]:	loss/total_loss, 8.316658020019531, 641
[INFO] 2021-07-12 18:42:33,733 [run_pretraining.py:  535]:	loss/mlm_loss, 8.316658020019531, 641
[INFO] 2021-07-12 18:42:33,733 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.4000000747910235e-06, 641
[INFO] 2021-07-12 18:42:33,733 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 641
[INFO] 2021-07-12 18:42:33,733 [run_pretraining.py:  558]:	worker_index: 6, step: 641, cost: 8.316658, mlm loss: 8.316658, speed: 1.105271 steps/s, speed: 8.842165 samples/s, speed: 4527.188287 tokens/s, learning rate: 6.400e-06, loss_scalings: 13421.773438, pp_loss: 8.546968
[INFO] 2021-07-12 18:42:33,733 [run_pretraining.py:  512]:	********exe.run_641******* 
[INFO] 2021-07-12 18:42:34,639 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:34,639 [run_pretraining.py:  534]:	loss/total_loss, 9.063236236572266, 642
[INFO] 2021-07-12 18:42:34,639 [run_pretraining.py:  535]:	loss/mlm_loss, 9.063236236572266, 642
[INFO] 2021-07-12 18:42:34,639 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.409999514289666e-06, 642
[INFO] 2021-07-12 18:42:34,640 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 642
[INFO] 2021-07-12 18:42:34,640 [run_pretraining.py:  558]:	worker_index: 6, step: 642, cost: 9.063236, mlm loss: 9.063236, speed: 1.104269 steps/s, speed: 8.834152 samples/s, speed: 4523.085733 tokens/s, learning rate: 6.410e-06, loss_scalings: 13421.773438, pp_loss: 8.714478
[INFO] 2021-07-12 18:42:34,640 [run_pretraining.py:  512]:	********exe.run_642******* 
[INFO] 2021-07-12 18:42:35,550 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:35,551 [run_pretraining.py:  534]:	loss/total_loss, 8.248046875, 643
[INFO] 2021-07-12 18:42:35,551 [run_pretraining.py:  535]:	loss/mlm_loss, 8.248046875, 643
[INFO] 2021-07-12 18:42:35,551 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.41999986328301e-06, 643
[INFO] 2021-07-12 18:42:35,551 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 643
[INFO] 2021-07-12 18:42:35,551 [run_pretraining.py:  558]:	worker_index: 6, step: 643, cost: 8.248047, mlm loss: 8.248047, speed: 1.097677 steps/s, speed: 8.781414 samples/s, speed: 4496.083872 tokens/s, learning rate: 6.420e-06, loss_scalings: 13421.773438, pp_loss: 8.554934
[INFO] 2021-07-12 18:42:35,551 [run_pretraining.py:  512]:	********exe.run_643******* 
[INFO] 2021-07-12 18:42:36,455 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:36,456 [run_pretraining.py:  534]:	loss/total_loss, 8.732826232910156, 644
[INFO] 2021-07-12 18:42:36,456 [run_pretraining.py:  535]:	loss/mlm_loss, 8.732826232910156, 644
[INFO] 2021-07-12 18:42:36,456 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.4299997575290035e-06, 644
[INFO] 2021-07-12 18:42:36,456 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 644
[INFO] 2021-07-12 18:42:36,456 [run_pretraining.py:  558]:	worker_index: 6, step: 644, cost: 8.732826, mlm loss: 8.732826, speed: 1.105856 steps/s, speed: 8.846851 samples/s, speed: 4529.587471 tokens/s, learning rate: 6.430e-06, loss_scalings: 13421.773438, pp_loss: 8.735393
[INFO] 2021-07-12 18:42:36,456 [run_pretraining.py:  512]:	********exe.run_644******* 
[INFO] 2021-07-12 18:42:37,519 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:37,519 [run_pretraining.py:  534]:	loss/total_loss, 8.467010498046875, 645
[INFO] 2021-07-12 18:42:37,519 [run_pretraining.py:  535]:	loss/mlm_loss, 8.467010498046875, 645
[INFO] 2021-07-12 18:42:37,519 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.440000106522348e-06, 645
[INFO] 2021-07-12 18:42:37,519 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 645
[INFO] 2021-07-12 18:42:37,520 [run_pretraining.py:  558]:	worker_index: 6, step: 645, cost: 8.467010, mlm loss: 8.467010, speed: 0.941141 steps/s, speed: 7.529131 samples/s, speed: 3854.915230 tokens/s, learning rate: 6.440e-06, loss_scalings: 13421.773438, pp_loss: 8.557701
[INFO] 2021-07-12 18:42:37,520 [run_pretraining.py:  512]:	********exe.run_645******* 
[INFO] 2021-07-12 18:42:38,597 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:38,597 [run_pretraining.py:  534]:	loss/total_loss, 8.46207332611084, 646
[INFO] 2021-07-12 18:42:38,597 [run_pretraining.py:  535]:	loss/mlm_loss, 8.46207332611084, 646
[INFO] 2021-07-12 18:42:38,597 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.44999954602099e-06, 646
[INFO] 2021-07-12 18:42:38,598 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 646
[INFO] 2021-07-12 18:42:38,598 [run_pretraining.py:  558]:	worker_index: 6, step: 646, cost: 8.462073, mlm loss: 8.462073, speed: 0.928208 steps/s, speed: 7.425663 samples/s, speed: 3801.939399 tokens/s, learning rate: 6.450e-06, loss_scalings: 13421.773438, pp_loss: 8.426224
[INFO] 2021-07-12 18:42:38,598 [run_pretraining.py:  512]:	********exe.run_646******* 
[INFO] 2021-07-12 18:42:39,710 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:39,711 [run_pretraining.py:  534]:	loss/total_loss, 8.373628616333008, 647
[INFO] 2021-07-12 18:42:39,711 [run_pretraining.py:  535]:	loss/mlm_loss, 8.373628616333008, 647
[INFO] 2021-07-12 18:42:39,711 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.459999440266984e-06, 647
[INFO] 2021-07-12 18:42:39,711 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 647
[INFO] 2021-07-12 18:42:39,711 [run_pretraining.py:  558]:	worker_index: 6, step: 647, cost: 8.373629, mlm loss: 8.373629, speed: 0.898661 steps/s, speed: 7.189291 samples/s, speed: 3680.916762 tokens/s, learning rate: 6.460e-06, loss_scalings: 13421.773438, pp_loss: 8.499380
[INFO] 2021-07-12 18:42:39,711 [run_pretraining.py:  512]:	********exe.run_647******* 
[INFO] 2021-07-12 18:42:40,773 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:40,773 [run_pretraining.py:  534]:	loss/total_loss, 8.407870292663574, 648
[INFO] 2021-07-12 18:42:40,773 [run_pretraining.py:  535]:	loss/mlm_loss, 8.407870292663574, 648
[INFO] 2021-07-12 18:42:40,773 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.469999789260328e-06, 648
[INFO] 2021-07-12 18:42:40,773 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 648
[INFO] 2021-07-12 18:42:40,774 [run_pretraining.py:  558]:	worker_index: 6, step: 648, cost: 8.407870, mlm loss: 8.407870, speed: 0.941881 steps/s, speed: 7.535049 samples/s, speed: 3857.945066 tokens/s, learning rate: 6.470e-06, loss_scalings: 13421.773438, pp_loss: 8.467980
[INFO] 2021-07-12 18:42:40,774 [run_pretraining.py:  512]:	********exe.run_648******* 
[INFO] 2021-07-12 18:42:41,818 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:41,818 [run_pretraining.py:  534]:	loss/total_loss, 7.91593074798584, 649
[INFO] 2021-07-12 18:42:41,819 [run_pretraining.py:  535]:	loss/mlm_loss, 7.91593074798584, 649
[INFO] 2021-07-12 18:42:41,819 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.480000138253672e-06, 649
[INFO] 2021-07-12 18:42:41,819 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 649
[INFO] 2021-07-12 18:42:41,819 [run_pretraining.py:  558]:	worker_index: 6, step: 649, cost: 7.915931, mlm loss: 7.915931, speed: 0.957301 steps/s, speed: 7.658411 samples/s, speed: 3921.106460 tokens/s, learning rate: 6.480e-06, loss_scalings: 13421.773438, pp_loss: 8.366002
[INFO] 2021-07-12 18:42:41,819 [run_pretraining.py:  512]:	********exe.run_649******* 
[INFO] 2021-07-12 18:42:42,764 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:42,765 [run_pretraining.py:  534]:	loss/total_loss, 8.635724067687988, 650
[INFO] 2021-07-12 18:42:42,765 [run_pretraining.py:  535]:	loss/mlm_loss, 8.635724067687988, 650
[INFO] 2021-07-12 18:42:42,765 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.490000032499665e-06, 650
[INFO] 2021-07-12 18:42:42,765 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 650
[INFO] 2021-07-12 18:42:42,765 [run_pretraining.py:  558]:	worker_index: 6, step: 650, cost: 8.635724, mlm loss: 8.635724, speed: 1.057135 steps/s, speed: 8.457076 samples/s, speed: 4330.023164 tokens/s, learning rate: 6.490e-06, loss_scalings: 13421.773438, pp_loss: 8.644828
[INFO] 2021-07-12 18:42:42,766 [run_pretraining.py:  512]:	********exe.run_650******* 
[INFO] 2021-07-12 18:42:43,654 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:43,655 [run_pretraining.py:  534]:	loss/total_loss, 4.286677360534668, 651
[INFO] 2021-07-12 18:42:43,655 [run_pretraining.py:  535]:	loss/mlm_loss, 4.286677360534668, 651
[INFO] 2021-07-12 18:42:43,655 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.499999471998308e-06, 651
[INFO] 2021-07-12 18:42:43,655 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 651
[INFO] 2021-07-12 18:42:43,655 [run_pretraining.py:  558]:	worker_index: 6, step: 651, cost: 4.286677, mlm loss: 4.286677, speed: 1.124931 steps/s, speed: 8.999448 samples/s, speed: 4607.717257 tokens/s, learning rate: 6.500e-06, loss_scalings: 13421.773438, pp_loss: 7.458880
[INFO] 2021-07-12 18:42:43,655 [run_pretraining.py:  512]:	********exe.run_651******* 
[INFO] 2021-07-12 18:42:44,565 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:44,566 [run_pretraining.py:  534]:	loss/total_loss, 8.613837242126465, 652
[INFO] 2021-07-12 18:42:44,566 [run_pretraining.py:  535]:	loss/mlm_loss, 8.613837242126465, 652
[INFO] 2021-07-12 18:42:44,566 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.509999820991652e-06, 652
[INFO] 2021-07-12 18:42:44,566 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 652
[INFO] 2021-07-12 18:42:44,566 [run_pretraining.py:  558]:	worker_index: 6, step: 652, cost: 8.613837, mlm loss: 8.613837, speed: 1.098348 steps/s, speed: 8.786786 samples/s, speed: 4498.834218 tokens/s, learning rate: 6.510e-06, loss_scalings: 13421.773438, pp_loss: 8.698203
[INFO] 2021-07-12 18:42:44,566 [run_pretraining.py:  512]:	********exe.run_652******* 
[INFO] 2021-07-12 18:42:45,484 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:45,484 [run_pretraining.py:  534]:	loss/total_loss, 7.748409271240234, 653
[INFO] 2021-07-12 18:42:45,484 [run_pretraining.py:  535]:	loss/mlm_loss, 7.748409271240234, 653
[INFO] 2021-07-12 18:42:45,484 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.5199997152376454e-06, 653
[INFO] 2021-07-12 18:42:45,484 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 653
[INFO] 2021-07-12 18:42:45,485 [run_pretraining.py:  558]:	worker_index: 6, step: 653, cost: 7.748409, mlm loss: 7.748409, speed: 1.089811 steps/s, speed: 8.718485 samples/s, speed: 4463.864297 tokens/s, learning rate: 6.520e-06, loss_scalings: 13421.773438, pp_loss: 8.409272
[INFO] 2021-07-12 18:42:45,485 [run_pretraining.py:  512]:	********exe.run_653******* 
[INFO] 2021-07-12 18:42:46,385 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:46,385 [run_pretraining.py:  534]:	loss/total_loss, 8.668118476867676, 654
[INFO] 2021-07-12 18:42:46,386 [run_pretraining.py:  535]:	loss/mlm_loss, 8.668118476867676, 654
[INFO] 2021-07-12 18:42:46,386 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.53000006423099e-06, 654
[INFO] 2021-07-12 18:42:46,386 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 654
[INFO] 2021-07-12 18:42:46,386 [run_pretraining.py:  558]:	worker_index: 6, step: 654, cost: 8.668118, mlm loss: 8.668118, speed: 1.110443 steps/s, speed: 8.883546 samples/s, speed: 4548.375488 tokens/s, learning rate: 6.530e-06, loss_scalings: 13421.773438, pp_loss: 8.714686
[INFO] 2021-07-12 18:42:46,386 [run_pretraining.py:  512]:	********exe.run_654******* 
[INFO] 2021-07-12 18:42:47,292 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:47,292 [run_pretraining.py:  534]:	loss/total_loss, 8.734098434448242, 655
[INFO] 2021-07-12 18:42:47,292 [run_pretraining.py:  535]:	loss/mlm_loss, 8.734098434448242, 655
[INFO] 2021-07-12 18:42:47,293 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.539999503729632e-06, 655
[INFO] 2021-07-12 18:42:47,293 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 655
[INFO] 2021-07-12 18:42:47,293 [run_pretraining.py:  558]:	worker_index: 6, step: 655, cost: 8.734098, mlm loss: 8.734098, speed: 1.103410 steps/s, speed: 8.827282 samples/s, speed: 4519.568376 tokens/s, learning rate: 6.540e-06, loss_scalings: 13421.773438, pp_loss: 8.641107
[INFO] 2021-07-12 18:42:47,293 [run_pretraining.py:  512]:	********exe.run_655******* 
[INFO] 2021-07-12 18:42:48,203 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:48,204 [run_pretraining.py:  534]:	loss/total_loss, 8.99365234375, 656
[INFO] 2021-07-12 18:42:48,204 [run_pretraining.py:  535]:	loss/mlm_loss, 8.99365234375, 656
[INFO] 2021-07-12 18:42:48,204 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.549999852722976e-06, 656
[INFO] 2021-07-12 18:42:48,204 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 656
[INFO] 2021-07-12 18:42:48,204 [run_pretraining.py:  558]:	worker_index: 6, step: 656, cost: 8.993652, mlm loss: 8.993652, speed: 1.098347 steps/s, speed: 8.786776 samples/s, speed: 4498.829506 tokens/s, learning rate: 6.550e-06, loss_scalings: 13421.773438, pp_loss: 8.537733
[INFO] 2021-07-12 18:42:48,204 [run_pretraining.py:  512]:	********exe.run_656******* 
[INFO] 2021-07-12 18:42:49,108 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:49,109 [run_pretraining.py:  534]:	loss/total_loss, 8.084122657775879, 657
[INFO] 2021-07-12 18:42:49,109 [run_pretraining.py:  535]:	loss/mlm_loss, 8.084122657775879, 657
[INFO] 2021-07-12 18:42:49,109 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.55999974696897e-06, 657
[INFO] 2021-07-12 18:42:49,109 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 657
[INFO] 2021-07-12 18:42:49,109 [run_pretraining.py:  558]:	worker_index: 6, step: 657, cost: 8.084123, mlm loss: 8.084123, speed: 1.105354 steps/s, speed: 8.842833 samples/s, speed: 4527.530702 tokens/s, learning rate: 6.560e-06, loss_scalings: 13421.773438, pp_loss: 8.287255
[INFO] 2021-07-12 18:42:49,109 [run_pretraining.py:  512]:	********exe.run_657******* 
[INFO] 2021-07-12 18:42:50,000 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:50,001 [run_pretraining.py:  534]:	loss/total_loss, 8.598915100097656, 658
[INFO] 2021-07-12 18:42:50,001 [run_pretraining.py:  535]:	loss/mlm_loss, 8.598915100097656, 658
[INFO] 2021-07-12 18:42:50,001 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.570000095962314e-06, 658
[INFO] 2021-07-12 18:42:50,001 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 658
[INFO] 2021-07-12 18:42:50,001 [run_pretraining.py:  558]:	worker_index: 6, step: 658, cost: 8.598915, mlm loss: 8.598915, speed: 1.122352 steps/s, speed: 8.978817 samples/s, speed: 4597.154341 tokens/s, learning rate: 6.570e-06, loss_scalings: 13421.773438, pp_loss: 8.346445
[INFO] 2021-07-12 18:42:50,001 [run_pretraining.py:  512]:	********exe.run_658******* 
[INFO] 2021-07-12 18:42:50,916 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:50,916 [run_pretraining.py:  534]:	loss/total_loss, 8.665349960327148, 659
[INFO] 2021-07-12 18:42:50,916 [run_pretraining.py:  535]:	loss/mlm_loss, 8.665349960327148, 659
[INFO] 2021-07-12 18:42:50,916 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.579999990208307e-06, 659
[INFO] 2021-07-12 18:42:50,916 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 659
[INFO] 2021-07-12 18:42:50,916 [run_pretraining.py:  558]:	worker_index: 6, step: 659, cost: 8.665350, mlm loss: 8.665350, speed: 1.093160 steps/s, speed: 8.745280 samples/s, speed: 4477.583292 tokens/s, learning rate: 6.580e-06, loss_scalings: 13421.773438, pp_loss: 8.459135
[INFO] 2021-07-12 18:42:50,917 [run_pretraining.py:  512]:	********exe.run_659******* 
[INFO] 2021-07-12 18:42:51,824 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:51,824 [run_pretraining.py:  534]:	loss/total_loss, 8.71104907989502, 660
[INFO] 2021-07-12 18:42:51,825 [run_pretraining.py:  535]:	loss/mlm_loss, 8.71104907989502, 660
[INFO] 2021-07-12 18:42:51,825 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.58999942970695e-06, 660
[INFO] 2021-07-12 18:42:51,825 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 660
[INFO] 2021-07-12 18:42:51,825 [run_pretraining.py:  558]:	worker_index: 6, step: 660, cost: 8.711049, mlm loss: 8.711049, speed: 1.101825 steps/s, speed: 8.814602 samples/s, speed: 4513.076380 tokens/s, learning rate: 6.590e-06, loss_scalings: 13421.773438, pp_loss: 8.541146
[INFO] 2021-07-12 18:42:51,825 [run_pretraining.py:  512]:	********exe.run_660******* 
[INFO] 2021-07-12 18:42:52,727 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:52,728 [run_pretraining.py:  534]:	loss/total_loss, 8.528992652893066, 661
[INFO] 2021-07-12 18:42:52,728 [run_pretraining.py:  535]:	loss/mlm_loss, 8.528992652893066, 661
[INFO] 2021-07-12 18:42:52,728 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.599999778700294e-06, 661
[INFO] 2021-07-12 18:42:52,728 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 661
[INFO] 2021-07-12 18:42:52,728 [run_pretraining.py:  558]:	worker_index: 6, step: 661, cost: 8.528993, mlm loss: 8.528993, speed: 1.107717 steps/s, speed: 8.861738 samples/s, speed: 4537.210076 tokens/s, learning rate: 6.600e-06, loss_scalings: 13421.773438, pp_loss: 8.467516
[INFO] 2021-07-12 18:42:52,728 [run_pretraining.py:  512]:	********exe.run_661******* 
[INFO] 2021-07-12 18:42:53,631 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:53,631 [run_pretraining.py:  534]:	loss/total_loss, 8.456655502319336, 662
[INFO] 2021-07-12 18:42:53,631 [run_pretraining.py:  535]:	loss/mlm_loss, 8.456655502319336, 662
[INFO] 2021-07-12 18:42:53,631 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.610000127693638e-06, 662
[INFO] 2021-07-12 18:42:53,631 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 662
[INFO] 2021-07-12 18:42:53,632 [run_pretraining.py:  558]:	worker_index: 6, step: 662, cost: 8.456656, mlm loss: 8.456656, speed: 1.107994 steps/s, speed: 8.863948 samples/s, speed: 4538.341534 tokens/s, learning rate: 6.610e-06, loss_scalings: 13421.773438, pp_loss: 8.606915
[INFO] 2021-07-12 18:42:53,632 [run_pretraining.py:  512]:	********exe.run_662******* 
[INFO] 2021-07-12 18:42:54,536 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:54,537 [run_pretraining.py:  534]:	loss/total_loss, 8.521145820617676, 663
[INFO] 2021-07-12 18:42:54,537 [run_pretraining.py:  535]:	loss/mlm_loss, 8.521145820617676, 663
[INFO] 2021-07-12 18:42:54,537 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.6200000219396316e-06, 663
[INFO] 2021-07-12 18:42:54,537 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 663
[INFO] 2021-07-12 18:42:54,537 [run_pretraining.py:  558]:	worker_index: 6, step: 663, cost: 8.521146, mlm loss: 8.521146, speed: 1.105109 steps/s, speed: 8.840874 samples/s, speed: 4526.527467 tokens/s, learning rate: 6.620e-06, loss_scalings: 13421.773438, pp_loss: 8.341635
[INFO] 2021-07-12 18:42:54,537 [run_pretraining.py:  512]:	********exe.run_663******* 
[INFO] 2021-07-12 18:42:55,444 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:55,444 [run_pretraining.py:  534]:	loss/total_loss, 8.279624938964844, 664
[INFO] 2021-07-12 18:42:55,445 [run_pretraining.py:  535]:	loss/mlm_loss, 8.279624938964844, 664
[INFO] 2021-07-12 18:42:55,445 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.629999461438274e-06, 664
[INFO] 2021-07-12 18:42:55,445 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 664
[INFO] 2021-07-12 18:42:55,445 [run_pretraining.py:  558]:	worker_index: 6, step: 664, cost: 8.279625, mlm loss: 8.279625, speed: 1.102543 steps/s, speed: 8.820342 samples/s, speed: 4516.014937 tokens/s, learning rate: 6.630e-06, loss_scalings: 13421.773438, pp_loss: 8.428097
[INFO] 2021-07-12 18:42:55,445 [run_pretraining.py:  512]:	********exe.run_664******* 
[INFO] 2021-07-12 18:42:56,348 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:56,349 [run_pretraining.py:  534]:	loss/total_loss, 8.136025428771973, 665
[INFO] 2021-07-12 18:42:56,349 [run_pretraining.py:  535]:	loss/mlm_loss, 8.136025428771973, 665
[INFO] 2021-07-12 18:42:56,349 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.639999810431618e-06, 665
[INFO] 2021-07-12 18:42:56,349 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 665
[INFO] 2021-07-12 18:42:56,349 [run_pretraining.py:  558]:	worker_index: 6, step: 665, cost: 8.136025, mlm loss: 8.136025, speed: 1.106530 steps/s, speed: 8.852240 samples/s, speed: 4532.346688 tokens/s, learning rate: 6.640e-06, loss_scalings: 13421.773438, pp_loss: 8.411067
[INFO] 2021-07-12 18:42:56,349 [run_pretraining.py:  512]:	********exe.run_665******* 
[INFO] 2021-07-12 18:43:19,343 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:19,344 [run_pretraining.py:  534]:	loss/total_loss, 8.815011978149414, 666
[INFO] 2021-07-12 18:43:19,344 [run_pretraining.py:  535]:	loss/mlm_loss, 8.815011978149414, 666
[INFO] 2021-07-12 18:43:19,344 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.649999704677612e-06, 666
[INFO] 2021-07-12 18:43:19,344 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 666
[INFO] 2021-07-12 18:43:19,344 [run_pretraining.py:  558]:	worker_index: 6, step: 666, cost: 8.815012, mlm loss: 8.815012, speed: 0.043489 steps/s, speed: 0.347911 samples/s, speed: 178.130497 tokens/s, learning rate: 6.650e-06, loss_scalings: 13421.773438, pp_loss: 8.675980
[INFO] 2021-07-12 18:43:19,344 [run_pretraining.py:  512]:	********exe.run_666******* 
[INFO] 2021-07-12 18:43:20,298 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:20,299 [run_pretraining.py:  534]:	loss/total_loss, 8.488468170166016, 667
[INFO] 2021-07-12 18:43:20,299 [run_pretraining.py:  535]:	loss/mlm_loss, 8.488468170166016, 667
[INFO] 2021-07-12 18:43:20,299 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.660000053670956e-06, 667
[INFO] 2021-07-12 18:43:20,299 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 667
[INFO] 2021-07-12 18:43:20,299 [run_pretraining.py:  558]:	worker_index: 6, step: 667, cost: 8.488468, mlm loss: 8.488468, speed: 1.047854 steps/s, speed: 8.382830 samples/s, speed: 4292.009029 tokens/s, learning rate: 6.660e-06, loss_scalings: 13421.773438, pp_loss: 8.561870
[INFO] 2021-07-12 18:43:20,299 [run_pretraining.py:  512]:	********exe.run_667******* 
[INFO] 2021-07-12 18:43:21,240 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:21,240 [run_pretraining.py:  534]:	loss/total_loss, 9.02865982055664, 668
[INFO] 2021-07-12 18:43:21,240 [run_pretraining.py:  535]:	loss/mlm_loss, 9.02865982055664, 668
[INFO] 2021-07-12 18:43:21,240 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.669999493169598e-06, 668
[INFO] 2021-07-12 18:43:21,240 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 668
[INFO] 2021-07-12 18:43:21,241 [run_pretraining.py:  558]:	worker_index: 6, step: 668, cost: 9.028660, mlm loss: 9.028660, speed: 1.063269 steps/s, speed: 8.506150 samples/s, speed: 4355.148921 tokens/s, learning rate: 6.670e-06, loss_scalings: 13421.773438, pp_loss: 8.766593
[INFO] 2021-07-12 18:43:21,241 [run_pretraining.py:  512]:	********exe.run_668******* 
[INFO] 2021-07-12 18:43:22,179 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:22,180 [run_pretraining.py:  534]:	loss/total_loss, 7.966385841369629, 669
[INFO] 2021-07-12 18:43:22,180 [run_pretraining.py:  535]:	loss/mlm_loss, 7.966385841369629, 669
[INFO] 2021-07-12 18:43:22,180 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.6799998421629425e-06, 669
[INFO] 2021-07-12 18:43:22,180 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 669
[INFO] 2021-07-12 18:43:22,180 [run_pretraining.py:  558]:	worker_index: 6, step: 669, cost: 7.966386, mlm loss: 7.966386, speed: 1.064726 steps/s, speed: 8.517806 samples/s, speed: 4361.116714 tokens/s, learning rate: 6.680e-06, loss_scalings: 13421.773438, pp_loss: 8.226339
[INFO] 2021-07-12 18:43:22,180 [run_pretraining.py:  512]:	********exe.run_669******* 
[INFO] 2021-07-12 18:43:23,247 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:23,248 [run_pretraining.py:  534]:	loss/total_loss, 8.281220436096191, 670
[INFO] 2021-07-12 18:43:23,248 [run_pretraining.py:  535]:	loss/mlm_loss, 8.281220436096191, 670
[INFO] 2021-07-12 18:43:23,248 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.689999736408936e-06, 670
[INFO] 2021-07-12 18:43:23,248 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 670
[INFO] 2021-07-12 18:43:23,248 [run_pretraining.py:  558]:	worker_index: 6, step: 670, cost: 8.281220, mlm loss: 8.281220, speed: 0.937008 steps/s, speed: 7.496065 samples/s, speed: 3837.985124 tokens/s, learning rate: 6.690e-06, loss_scalings: 13421.773438, pp_loss: 8.487268
[INFO] 2021-07-12 18:43:23,248 [run_pretraining.py:  512]:	********exe.run_670******* 
[INFO] 2021-07-12 18:43:49,154 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:49,154 [run_pretraining.py:  534]:	loss/total_loss, 8.462594032287598, 671
[INFO] 2021-07-12 18:43:49,155 [run_pretraining.py:  535]:	loss/mlm_loss, 8.462594032287598, 671
[INFO] 2021-07-12 18:43:49,155 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.70000008540228e-06, 671
[INFO] 2021-07-12 18:43:49,155 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 671
[INFO] 2021-07-12 18:43:49,155 [run_pretraining.py:  558]:	worker_index: 6, step: 671, cost: 8.462594, mlm loss: 8.462594, speed: 0.038601 steps/s, speed: 0.308811 samples/s, speed: 158.111239 tokens/s, learning rate: 6.700e-06, loss_scalings: 13421.773438, pp_loss: 8.367019
[INFO] 2021-07-12 18:43:49,155 [run_pretraining.py:  512]:	********exe.run_671******* 
[INFO] 2021-07-12 18:43:50,200 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:50,201 [run_pretraining.py:  534]:	loss/total_loss, 8.922986030578613, 672
[INFO] 2021-07-12 18:43:50,201 [run_pretraining.py:  535]:	loss/mlm_loss, 8.922986030578613, 672
[INFO] 2021-07-12 18:43:50,201 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.7099999796482734e-06, 672
[INFO] 2021-07-12 18:43:50,201 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 672
[INFO] 2021-07-12 18:43:50,201 [run_pretraining.py:  558]:	worker_index: 6, step: 672, cost: 8.922986, mlm loss: 8.922986, speed: 0.956620 steps/s, speed: 7.652961 samples/s, speed: 3918.316211 tokens/s, learning rate: 6.710e-06, loss_scalings: 13421.773438, pp_loss: 8.531676
[INFO] 2021-07-12 18:43:50,201 [run_pretraining.py:  512]:	********exe.run_672******* 
[INFO] 2021-07-12 18:43:51,233 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:51,234 [run_pretraining.py:  534]:	loss/total_loss, 8.438923835754395, 673
[INFO] 2021-07-12 18:43:51,234 [run_pretraining.py:  535]:	loss/mlm_loss, 8.438923835754395, 673
[INFO] 2021-07-12 18:43:51,234 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.719999419146916e-06, 673
[INFO] 2021-07-12 18:43:51,234 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 673
[INFO] 2021-07-12 18:43:51,234 [run_pretraining.py:  558]:	worker_index: 6, step: 673, cost: 8.438924, mlm loss: 8.438924, speed: 0.968384 steps/s, speed: 7.747075 samples/s, speed: 3966.502237 tokens/s, learning rate: 6.720e-06, loss_scalings: 13421.773438, pp_loss: 8.457623
[INFO] 2021-07-12 18:43:51,234 [run_pretraining.py:  512]:	********exe.run_673******* 
[INFO] 2021-07-12 18:43:52,331 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:52,331 [run_pretraining.py:  534]:	loss/total_loss, 8.62552547454834, 674
[INFO] 2021-07-12 18:43:52,331 [run_pretraining.py:  535]:	loss/mlm_loss, 8.62552547454834, 674
[INFO] 2021-07-12 18:43:52,331 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.72999976814026e-06, 674
[INFO] 2021-07-12 18:43:52,332 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 674
[INFO] 2021-07-12 18:43:52,332 [run_pretraining.py:  558]:	worker_index: 6, step: 674, cost: 8.625525, mlm loss: 8.625525, speed: 0.911849 steps/s, speed: 7.294792 samples/s, speed: 3734.933610 tokens/s, learning rate: 6.730e-06, loss_scalings: 13421.773438, pp_loss: 8.673908
[INFO] 2021-07-12 18:43:52,332 [run_pretraining.py:  512]:	********exe.run_674******* 
[INFO] 2021-07-12 18:43:53,373 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:53,374 [run_pretraining.py:  534]:	loss/total_loss, 8.282712936401367, 675
[INFO] 2021-07-12 18:43:53,374 [run_pretraining.py:  535]:	loss/mlm_loss, 8.282712936401367, 675
[INFO] 2021-07-12 18:43:53,374 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.740000117133604e-06, 675
[INFO] 2021-07-12 18:43:53,374 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 675
[INFO] 2021-07-12 18:43:53,374 [run_pretraining.py:  558]:	worker_index: 6, step: 675, cost: 8.282713, mlm loss: 8.282713, speed: 0.959922 steps/s, speed: 7.679377 samples/s, speed: 3931.841126 tokens/s, learning rate: 6.740e-06, loss_scalings: 13421.773438, pp_loss: 8.347477
[INFO] 2021-07-12 18:43:53,374 [run_pretraining.py:  512]:	********exe.run_675******* 
[INFO] 2021-07-12 18:43:54,420 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:54,421 [run_pretraining.py:  534]:	loss/total_loss, 6.852383613586426, 676
[INFO] 2021-07-12 18:43:54,421 [run_pretraining.py:  535]:	loss/mlm_loss, 6.852383613586426, 676
[INFO] 2021-07-12 18:43:54,421 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.750000011379598e-06, 676
[INFO] 2021-07-12 18:43:54,421 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 676
[INFO] 2021-07-12 18:43:54,421 [run_pretraining.py:  558]:	worker_index: 6, step: 676, cost: 6.852384, mlm loss: 6.852384, speed: 0.955992 steps/s, speed: 7.647938 samples/s, speed: 3915.744120 tokens/s, learning rate: 6.750e-06, loss_scalings: 13421.773438, pp_loss: 7.945347
[INFO] 2021-07-12 18:43:54,421 [run_pretraining.py:  512]:	********exe.run_676******* 
[INFO] 2021-07-12 18:43:55,354 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:55,355 [run_pretraining.py:  534]:	loss/total_loss, 8.502782821655273, 677
[INFO] 2021-07-12 18:43:55,355 [run_pretraining.py:  535]:	loss/mlm_loss, 8.502782821655273, 677
[INFO] 2021-07-12 18:43:55,355 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.75999945087824e-06, 677
[INFO] 2021-07-12 18:43:55,355 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 677
[INFO] 2021-07-12 18:43:55,355 [run_pretraining.py:  558]:	worker_index: 6, step: 677, cost: 8.502783, mlm loss: 8.502783, speed: 1.071013 steps/s, speed: 8.568108 samples/s, speed: 4386.871150 tokens/s, learning rate: 6.760e-06, loss_scalings: 13421.773438, pp_loss: 8.413387
[INFO] 2021-07-12 18:43:55,355 [run_pretraining.py:  512]:	********exe.run_677******* 
[INFO] 2021-07-12 18:43:56,273 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:56,274 [run_pretraining.py:  534]:	loss/total_loss, 8.12350845336914, 678
[INFO] 2021-07-12 18:43:56,274 [run_pretraining.py:  535]:	loss/mlm_loss, 8.12350845336914, 678
[INFO] 2021-07-12 18:43:56,274 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.769999799871584e-06, 678
[INFO] 2021-07-12 18:43:56,274 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 678
[INFO] 2021-07-12 18:43:56,274 [run_pretraining.py:  558]:	worker_index: 6, step: 678, cost: 8.123508, mlm loss: 8.123508, speed: 1.088762 steps/s, speed: 8.710095 samples/s, speed: 4459.568868 tokens/s, learning rate: 6.770e-06, loss_scalings: 13421.773438, pp_loss: 8.189936
[INFO] 2021-07-12 18:43:56,275 [run_pretraining.py:  512]:	********exe.run_678******* 
[INFO] 2021-07-12 18:43:57,187 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:57,187 [run_pretraining.py:  534]:	loss/total_loss, 8.317887306213379, 679
[INFO] 2021-07-12 18:43:57,188 [run_pretraining.py:  535]:	loss/mlm_loss, 8.317887306213379, 679
[INFO] 2021-07-12 18:43:57,188 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.779999694117578e-06, 679
[INFO] 2021-07-12 18:43:57,188 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 679
[INFO] 2021-07-12 18:43:57,188 [run_pretraining.py:  558]:	worker_index: 6, step: 679, cost: 8.317887, mlm loss: 8.317887, speed: 1.095683 steps/s, speed: 8.765464 samples/s, speed: 4487.917453 tokens/s, learning rate: 6.780e-06, loss_scalings: 13421.773438, pp_loss: 8.412161
[INFO] 2021-07-12 18:43:57,188 [run_pretraining.py:  512]:	********exe.run_679******* 
[INFO] 2021-07-12 18:43:58,112 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:58,113 [run_pretraining.py:  534]:	loss/total_loss, 8.41421890258789, 680
[INFO] 2021-07-12 18:43:58,113 [run_pretraining.py:  535]:	loss/mlm_loss, 8.41421890258789, 680
[INFO] 2021-07-12 18:43:58,113 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.790000043110922e-06, 680
[INFO] 2021-07-12 18:43:58,113 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 680
[INFO] 2021-07-12 18:43:58,113 [run_pretraining.py:  558]:	worker_index: 6, step: 680, cost: 8.414219, mlm loss: 8.414219, speed: 1.081368 steps/s, speed: 8.650941 samples/s, speed: 4429.281949 tokens/s, learning rate: 6.790e-06, loss_scalings: 13421.773438, pp_loss: 8.451511
[INFO] 2021-07-12 18:43:58,113 [run_pretraining.py:  512]:	********exe.run_680******* 
[INFO] 2021-07-12 18:43:59,034 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:59,034 [run_pretraining.py:  534]:	loss/total_loss, 8.317536354064941, 681
[INFO] 2021-07-12 18:43:59,034 [run_pretraining.py:  535]:	loss/mlm_loss, 8.317536354064941, 681
[INFO] 2021-07-12 18:43:59,034 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.800000392104266e-06, 681
[INFO] 2021-07-12 18:43:59,035 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 681
[INFO] 2021-07-12 18:43:59,035 [run_pretraining.py:  558]:	worker_index: 6, step: 681, cost: 8.317536, mlm loss: 8.317536, speed: 1.086300 steps/s, speed: 8.690402 samples/s, speed: 4449.485698 tokens/s, learning rate: 6.800e-06, loss_scalings: 13421.773438, pp_loss: 8.493966
[INFO] 2021-07-12 18:43:59,035 [run_pretraining.py:  512]:	********exe.run_681******* 
[INFO] 2021-07-12 18:43:59,954 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:59,955 [run_pretraining.py:  534]:	loss/total_loss, 8.575251579284668, 682
[INFO] 2021-07-12 18:43:59,955 [run_pretraining.py:  535]:	loss/mlm_loss, 8.575251579284668, 682
[INFO] 2021-07-12 18:43:59,955 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.809999831602909e-06, 682
[INFO] 2021-07-12 18:43:59,955 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 682
[INFO] 2021-07-12 18:43:59,955 [run_pretraining.py:  558]:	worker_index: 6, step: 682, cost: 8.575252, mlm loss: 8.575252, speed: 1.086964 steps/s, speed: 8.695710 samples/s, speed: 4452.203542 tokens/s, learning rate: 6.810e-06, loss_scalings: 13421.773438, pp_loss: 8.619829
[INFO] 2021-07-12 18:43:59,955 [run_pretraining.py:  512]:	********exe.run_682******* 
[INFO] 2021-07-12 18:44:00,872 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:00,872 [run_pretraining.py:  534]:	loss/total_loss, 8.462738037109375, 683
[INFO] 2021-07-12 18:44:00,873 [run_pretraining.py:  535]:	loss/mlm_loss, 8.462738037109375, 683
[INFO] 2021-07-12 18:44:00,873 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.819999725848902e-06, 683
[INFO] 2021-07-12 18:44:00,873 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 683
[INFO] 2021-07-12 18:44:00,873 [run_pretraining.py:  558]:	worker_index: 6, step: 683, cost: 8.462738, mlm loss: 8.462738, speed: 1.090718 steps/s, speed: 8.725742 samples/s, speed: 4467.580070 tokens/s, learning rate: 6.820e-06, loss_scalings: 13421.773438, pp_loss: 8.335166
[INFO] 2021-07-12 18:44:00,873 [run_pretraining.py:  512]:	********exe.run_683******* 
[INFO] 2021-07-12 18:44:01,810 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:01,811 [run_pretraining.py:  534]:	loss/total_loss, 8.745609283447266, 684
[INFO] 2021-07-12 18:44:01,811 [run_pretraining.py:  535]:	loss/mlm_loss, 8.745609283447266, 684
[INFO] 2021-07-12 18:44:01,811 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.830000074842246e-06, 684
[INFO] 2021-07-12 18:44:01,811 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 684
[INFO] 2021-07-12 18:44:01,811 [run_pretraining.py:  558]:	worker_index: 6, step: 684, cost: 8.745609, mlm loss: 8.745609, speed: 1.066739 steps/s, speed: 8.533915 samples/s, speed: 4369.364465 tokens/s, learning rate: 6.830e-06, loss_scalings: 13421.773438, pp_loss: 8.551207
[INFO] 2021-07-12 18:44:01,811 [run_pretraining.py:  512]:	********exe.run_684******* 
[INFO] 2021-07-12 18:44:02,731 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:02,732 [run_pretraining.py:  534]:	loss/total_loss, 8.705771446228027, 685
[INFO] 2021-07-12 18:44:02,732 [run_pretraining.py:  535]:	loss/mlm_loss, 8.705771446228027, 685
[INFO] 2021-07-12 18:44:02,732 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.83999996908824e-06, 685
[INFO] 2021-07-12 18:44:02,732 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 685
[INFO] 2021-07-12 18:44:02,733 [run_pretraining.py:  558]:	worker_index: 6, step: 685, cost: 8.705771, mlm loss: 8.705771, speed: 1.086002 steps/s, speed: 8.688019 samples/s, speed: 4448.265651 tokens/s, learning rate: 6.840e-06, loss_scalings: 13421.773438, pp_loss: 8.158293
[INFO] 2021-07-12 18:44:02,733 [run_pretraining.py:  512]:	********exe.run_685******* 
[INFO] 2021-07-12 18:44:03,661 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:03,662 [run_pretraining.py:  534]:	loss/total_loss, 9.009875297546387, 686
[INFO] 2021-07-12 18:44:03,662 [run_pretraining.py:  535]:	loss/mlm_loss, 9.009875297546387, 686
[INFO] 2021-07-12 18:44:03,662 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.849999408586882e-06, 686
[INFO] 2021-07-12 18:44:03,662 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 686
[INFO] 2021-07-12 18:44:03,662 [run_pretraining.py:  558]:	worker_index: 6, step: 686, cost: 9.009875, mlm loss: 9.009875, speed: 1.076223 steps/s, speed: 8.609785 samples/s, speed: 4408.209797 tokens/s, learning rate: 6.850e-06, loss_scalings: 13421.773438, pp_loss: 8.627314
[INFO] 2021-07-12 18:44:03,663 [run_pretraining.py:  512]:	********exe.run_686******* 
[INFO] 2021-07-12 18:44:04,584 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:04,585 [run_pretraining.py:  534]:	loss/total_loss, 8.424163818359375, 687
[INFO] 2021-07-12 18:44:04,585 [run_pretraining.py:  535]:	loss/mlm_loss, 8.424163818359375, 687
[INFO] 2021-07-12 18:44:04,585 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.859999757580226e-06, 687
[INFO] 2021-07-12 18:44:04,585 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 687
[INFO] 2021-07-12 18:44:04,585 [run_pretraining.py:  558]:	worker_index: 6, step: 687, cost: 8.424164, mlm loss: 8.424164, speed: 1.084334 steps/s, speed: 8.674668 samples/s, speed: 4441.430116 tokens/s, learning rate: 6.860e-06, loss_scalings: 13421.773438, pp_loss: 8.682813
[INFO] 2021-07-12 18:44:04,585 [run_pretraining.py:  512]:	********exe.run_687******* 
[INFO] 2021-07-12 18:44:05,497 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:05,498 [run_pretraining.py:  534]:	loss/total_loss, 8.535608291625977, 688
[INFO] 2021-07-12 18:44:05,498 [run_pretraining.py:  535]:	loss/mlm_loss, 8.535608291625977, 688
[INFO] 2021-07-12 18:44:05,498 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.8700001065735705e-06, 688
[INFO] 2021-07-12 18:44:05,498 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 688
[INFO] 2021-07-12 18:44:05,498 [run_pretraining.py:  558]:	worker_index: 6, step: 688, cost: 8.535608, mlm loss: 8.535608, speed: 1.096195 steps/s, speed: 8.769562 samples/s, speed: 4490.015829 tokens/s, learning rate: 6.870e-06, loss_scalings: 13421.773438, pp_loss: 7.414877
[INFO] 2021-07-12 18:44:05,498 [run_pretraining.py:  512]:	********exe.run_688******* 
[INFO] 2021-07-12 18:44:06,425 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:06,426 [run_pretraining.py:  534]:	loss/total_loss, 8.353987693786621, 689
[INFO] 2021-07-12 18:44:06,426 [run_pretraining.py:  535]:	loss/mlm_loss, 8.353987693786621, 689
[INFO] 2021-07-12 18:44:06,426 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.880000000819564e-06, 689
[INFO] 2021-07-12 18:44:06,426 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 689
[INFO] 2021-07-12 18:44:06,426 [run_pretraining.py:  558]:	worker_index: 6, step: 689, cost: 8.353988, mlm loss: 8.353988, speed: 1.078308 steps/s, speed: 8.626463 samples/s, speed: 4416.749218 tokens/s, learning rate: 6.880e-06, loss_scalings: 13421.773438, pp_loss: 8.305695
[INFO] 2021-07-12 18:44:06,426 [run_pretraining.py:  512]:	********exe.run_689******* 
[INFO] 2021-07-12 18:44:07,343 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:07,343 [run_pretraining.py:  534]:	loss/total_loss, 8.276628494262695, 690
[INFO] 2021-07-12 18:44:07,344 [run_pretraining.py:  535]:	loss/mlm_loss, 8.276628494262695, 690
[INFO] 2021-07-12 18:44:07,344 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.889999440318206e-06, 690
[INFO] 2021-07-12 18:44:07,344 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 690
[INFO] 2021-07-12 18:44:07,344 [run_pretraining.py:  558]:	worker_index: 6, step: 690, cost: 8.276628, mlm loss: 8.276628, speed: 1.090855 steps/s, speed: 8.726841 samples/s, speed: 4468.142444 tokens/s, learning rate: 6.890e-06, loss_scalings: 13421.773438, pp_loss: 7.443871
[INFO] 2021-07-12 18:44:07,344 [run_pretraining.py:  512]:	********exe.run_690******* 
[INFO] 2021-07-12 18:44:08,270 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:08,270 [run_pretraining.py:  534]:	loss/total_loss, 8.462075233459473, 691
[INFO] 2021-07-12 18:44:08,270 [run_pretraining.py:  535]:	loss/mlm_loss, 8.462075233459473, 691
[INFO] 2021-07-12 18:44:08,271 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.8999997893115506e-06, 691
[INFO] 2021-07-12 18:44:08,271 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 691
[INFO] 2021-07-12 18:44:08,271 [run_pretraining.py:  558]:	worker_index: 6, step: 691, cost: 8.462075, mlm loss: 8.462075, speed: 1.079713 steps/s, speed: 8.637704 samples/s, speed: 4422.504589 tokens/s, learning rate: 6.900e-06, loss_scalings: 13421.773438, pp_loss: 8.601486
[INFO] 2021-07-12 18:44:08,271 [run_pretraining.py:  512]:	********exe.run_691******* 
[INFO] 2021-07-12 18:44:09,199 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:09,199 [run_pretraining.py:  534]:	loss/total_loss, 8.086405754089355, 692
[INFO] 2021-07-12 18:44:09,199 [run_pretraining.py:  535]:	loss/mlm_loss, 8.086405754089355, 692
[INFO] 2021-07-12 18:44:09,200 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.909999683557544e-06, 692
[INFO] 2021-07-12 18:44:09,200 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 692
[INFO] 2021-07-12 18:44:09,200 [run_pretraining.py:  558]:	worker_index: 6, step: 692, cost: 8.086406, mlm loss: 8.086406, speed: 1.077202 steps/s, speed: 8.617615 samples/s, speed: 4412.218699 tokens/s, learning rate: 6.910e-06, loss_scalings: 13421.773438, pp_loss: 8.156159
[INFO] 2021-07-12 18:44:09,200 [run_pretraining.py:  512]:	********exe.run_692******* 
[INFO] 2021-07-12 18:44:10,129 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:10,130 [run_pretraining.py:  534]:	loss/total_loss, 8.660079002380371, 693
[INFO] 2021-07-12 18:44:10,130 [run_pretraining.py:  535]:	loss/mlm_loss, 8.660079002380371, 693
[INFO] 2021-07-12 18:44:10,130 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.920000032550888e-06, 693
[INFO] 2021-07-12 18:44:10,130 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 693
[INFO] 2021-07-12 18:44:10,130 [run_pretraining.py:  558]:	worker_index: 6, step: 693, cost: 8.660079, mlm loss: 8.660079, speed: 1.075848 steps/s, speed: 8.606786 samples/s, speed: 4406.674286 tokens/s, learning rate: 6.920e-06, loss_scalings: 13421.773438, pp_loss: 8.149805
[INFO] 2021-07-12 18:44:10,130 [run_pretraining.py:  512]:	********exe.run_693******* 
[INFO] 2021-07-12 18:44:11,035 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:11,036 [run_pretraining.py:  534]:	loss/total_loss, 8.408193588256836, 694
[INFO] 2021-07-12 18:44:11,036 [run_pretraining.py:  535]:	loss/mlm_loss, 8.408193588256836, 694
[INFO] 2021-07-12 18:44:11,036 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.930000381544232e-06, 694
[INFO] 2021-07-12 18:44:11,036 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 694
[INFO] 2021-07-12 18:44:11,036 [run_pretraining.py:  558]:	worker_index: 6, step: 694, cost: 8.408194, mlm loss: 8.408194, speed: 1.104411 steps/s, speed: 8.835289 samples/s, speed: 4523.668123 tokens/s, learning rate: 6.930e-06, loss_scalings: 13421.773438, pp_loss: 8.286806
[INFO] 2021-07-12 18:44:11,036 [run_pretraining.py:  512]:	********exe.run_694******* 
[INFO] 2021-07-12 18:44:11,953 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:11,954 [run_pretraining.py:  534]:	loss/total_loss, 8.339940071105957, 695
[INFO] 2021-07-12 18:44:11,954 [run_pretraining.py:  535]:	loss/mlm_loss, 8.339940071105957, 695
[INFO] 2021-07-12 18:44:11,954 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.939999366295524e-06, 695
[INFO] 2021-07-12 18:44:11,954 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 695
[INFO] 2021-07-12 18:44:11,954 [run_pretraining.py:  558]:	worker_index: 6, step: 695, cost: 8.339940, mlm loss: 8.339940, speed: 1.089972 steps/s, speed: 8.719779 samples/s, speed: 4464.526671 tokens/s, learning rate: 6.940e-06, loss_scalings: 13421.773438, pp_loss: 8.448148
[INFO] 2021-07-12 18:44:11,954 [run_pretraining.py:  512]:	********exe.run_695******* 
[INFO] 2021-07-12 18:44:12,870 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:12,871 [run_pretraining.py:  534]:	loss/total_loss, 8.337563514709473, 696
[INFO] 2021-07-12 18:44:12,871 [run_pretraining.py:  535]:	loss/mlm_loss, 8.337563514709473, 696
[INFO] 2021-07-12 18:44:12,871 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.949999715288868e-06, 696
[INFO] 2021-07-12 18:44:12,871 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 696
[INFO] 2021-07-12 18:44:12,871 [run_pretraining.py:  558]:	worker_index: 6, step: 696, cost: 8.337564, mlm loss: 8.337564, speed: 1.091713 steps/s, speed: 8.733701 samples/s, speed: 4471.654669 tokens/s, learning rate: 6.950e-06, loss_scalings: 13421.773438, pp_loss: 8.482760
[INFO] 2021-07-12 18:44:12,871 [run_pretraining.py:  512]:	********exe.run_696******* 
[INFO] 2021-07-12 18:44:13,783 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:13,783 [run_pretraining.py:  534]:	loss/total_loss, 8.22221565246582, 697
[INFO] 2021-07-12 18:44:13,783 [run_pretraining.py:  535]:	loss/mlm_loss, 8.22221565246582, 697
[INFO] 2021-07-12 18:44:13,783 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.960000064282212e-06, 697
[INFO] 2021-07-12 18:44:13,784 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 697
[INFO] 2021-07-12 18:44:13,784 [run_pretraining.py:  558]:	worker_index: 6, step: 697, cost: 8.222216, mlm loss: 8.222216, speed: 1.096607 steps/s, speed: 8.772852 samples/s, speed: 4491.700405 tokens/s, learning rate: 6.960e-06, loss_scalings: 13421.773438, pp_loss: 8.346230
[INFO] 2021-07-12 18:44:13,784 [run_pretraining.py:  512]:	********exe.run_697******* 
[INFO] 2021-07-12 18:44:14,695 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:14,696 [run_pretraining.py:  534]:	loss/total_loss, 8.789443016052246, 698
[INFO] 2021-07-12 18:44:14,696 [run_pretraining.py:  535]:	loss/mlm_loss, 8.789443016052246, 698
[INFO] 2021-07-12 18:44:14,696 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.969999958528206e-06, 698
[INFO] 2021-07-12 18:44:14,696 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 698
[INFO] 2021-07-12 18:44:14,696 [run_pretraining.py:  558]:	worker_index: 6, step: 698, cost: 8.789443, mlm loss: 8.789443, speed: 1.096482 steps/s, speed: 8.771852 samples/s, speed: 4491.188442 tokens/s, learning rate: 6.970e-06, loss_scalings: 13421.773438, pp_loss: 8.641799
[INFO] 2021-07-12 18:44:14,696 [run_pretraining.py:  512]:	********exe.run_698******* 
[INFO] 2021-07-12 18:44:15,603 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:15,603 [run_pretraining.py:  534]:	loss/total_loss, 8.432228088378906, 699
[INFO] 2021-07-12 18:44:15,604 [run_pretraining.py:  535]:	loss/mlm_loss, 8.432228088378906, 699
[INFO] 2021-07-12 18:44:15,604 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.979999398026848e-06, 699
[INFO] 2021-07-12 18:44:15,604 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 699
[INFO] 2021-07-12 18:44:15,604 [run_pretraining.py:  558]:	worker_index: 6, step: 699, cost: 8.432228, mlm loss: 8.432228, speed: 1.102855 steps/s, speed: 8.822837 samples/s, speed: 4517.292629 tokens/s, learning rate: 6.980e-06, loss_scalings: 13421.773438, pp_loss: 8.313632
[INFO] 2021-07-12 18:44:15,604 [run_pretraining.py:  512]:	********exe.run_699******* 
[INFO] 2021-07-12 18:44:16,543 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:16,544 [run_pretraining.py:  534]:	loss/total_loss, 8.867231369018555, 700
[INFO] 2021-07-12 18:44:16,544 [run_pretraining.py:  535]:	loss/mlm_loss, 8.867231369018555, 700
[INFO] 2021-07-12 18:44:16,544 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.9899997470201924e-06, 700
[INFO] 2021-07-12 18:44:16,544 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 700
[INFO] 2021-07-12 18:44:16,544 [run_pretraining.py:  558]:	worker_index: 6, step: 700, cost: 8.867231, mlm loss: 8.867231, speed: 1.063935 steps/s, speed: 8.511480 samples/s, speed: 4357.877617 tokens/s, learning rate: 6.990e-06, loss_scalings: 13421.773438, pp_loss: 8.790678
[INFO] 2021-07-12 18:44:16,544 [run_pretraining.py:  512]:	********exe.run_700******* 
[INFO] 2021-07-12 18:44:17,458 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:17,458 [run_pretraining.py:  534]:	loss/total_loss, 8.177521705627441, 701
[INFO] 2021-07-12 18:44:17,458 [run_pretraining.py:  535]:	loss/mlm_loss, 8.177521705627441, 701
[INFO] 2021-07-12 18:44:17,458 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.999999641266186e-06, 701
[INFO] 2021-07-12 18:44:17,458 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 701
[INFO] 2021-07-12 18:44:17,459 [run_pretraining.py:  558]:	worker_index: 6, step: 701, cost: 8.177522, mlm loss: 8.177522, speed: 1.094759 steps/s, speed: 8.758074 samples/s, speed: 4484.133845 tokens/s, learning rate: 7.000e-06, loss_scalings: 13421.773438, pp_loss: 8.448470
[INFO] 2021-07-12 18:44:17,459 [run_pretraining.py:  512]:	********exe.run_701******* 
[INFO] 2021-07-12 18:44:18,373 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:18,374 [run_pretraining.py:  534]:	loss/total_loss, 8.208659172058105, 702
[INFO] 2021-07-12 18:44:18,374 [run_pretraining.py:  535]:	loss/mlm_loss, 8.208659172058105, 702
[INFO] 2021-07-12 18:44:18,374 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.00999999025953e-06, 702
[INFO] 2021-07-12 18:44:18,374 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 702
[INFO] 2021-07-12 18:44:18,374 [run_pretraining.py:  558]:	worker_index: 6, step: 702, cost: 8.208659, mlm loss: 8.208659, speed: 1.092861 steps/s, speed: 8.742885 samples/s, speed: 4476.357120 tokens/s, learning rate: 7.010e-06, loss_scalings: 13421.773438, pp_loss: 8.276256
[INFO] 2021-07-12 18:44:18,374 [run_pretraining.py:  512]:	********exe.run_702******* 
[INFO] 2021-07-12 18:44:19,285 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:19,286 [run_pretraining.py:  534]:	loss/total_loss, 8.665573120117188, 703
[INFO] 2021-07-12 18:44:19,286 [run_pretraining.py:  535]:	loss/mlm_loss, 8.665573120117188, 703
[INFO] 2021-07-12 18:44:19,286 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.020000339252874e-06, 703
[INFO] 2021-07-12 18:44:19,286 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 703
[INFO] 2021-07-12 18:44:19,286 [run_pretraining.py:  558]:	worker_index: 6, step: 703, cost: 8.665573, mlm loss: 8.665573, speed: 1.097470 steps/s, speed: 8.779759 samples/s, speed: 4495.236840 tokens/s, learning rate: 7.020e-06, loss_scalings: 13421.773438, pp_loss: 8.518711
[INFO] 2021-07-12 18:44:19,286 [run_pretraining.py:  512]:	********exe.run_703******* 
[INFO] 2021-07-12 18:44:20,204 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:20,205 [run_pretraining.py:  534]:	loss/total_loss, 8.258151054382324, 704
[INFO] 2021-07-12 18:44:20,205 [run_pretraining.py:  535]:	loss/mlm_loss, 8.258151054382324, 704
[INFO] 2021-07-12 18:44:20,205 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.029999778751517e-06, 704
[INFO] 2021-07-12 18:44:20,205 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 704
[INFO] 2021-07-12 18:44:20,205 [run_pretraining.py:  558]:	worker_index: 6, step: 704, cost: 8.258151, mlm loss: 8.258151, speed: 1.088972 steps/s, speed: 8.711776 samples/s, speed: 4460.429145 tokens/s, learning rate: 7.030e-06, loss_scalings: 13421.773438, pp_loss: 8.253900
[INFO] 2021-07-12 18:44:20,205 [run_pretraining.py:  512]:	********exe.run_704******* 
[INFO] 2021-07-12 18:44:21,126 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:21,127 [run_pretraining.py:  534]:	loss/total_loss, 8.43970012664795, 705
[INFO] 2021-07-12 18:44:21,127 [run_pretraining.py:  535]:	loss/mlm_loss, 8.43970012664795, 705
[INFO] 2021-07-12 18:44:21,127 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.03999967299751e-06, 705
[INFO] 2021-07-12 18:44:21,127 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 705
[INFO] 2021-07-12 18:44:21,127 [run_pretraining.py:  558]:	worker_index: 6, step: 705, cost: 8.439700, mlm loss: 8.439700, speed: 1.085636 steps/s, speed: 8.685084 samples/s, speed: 4446.763113 tokens/s, learning rate: 7.040e-06, loss_scalings: 13421.773438, pp_loss: 8.305336
[INFO] 2021-07-12 18:44:21,127 [run_pretraining.py:  512]:	********exe.run_705******* 
[INFO] 2021-07-12 18:44:22,043 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:22,044 [run_pretraining.py:  534]:	loss/total_loss, 8.139785766601562, 706
[INFO] 2021-07-12 18:44:22,044 [run_pretraining.py:  535]:	loss/mlm_loss, 8.139785766601562, 706
[INFO] 2021-07-12 18:44:22,044 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.050000021990854e-06, 706
[INFO] 2021-07-12 18:44:22,044 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 706
[INFO] 2021-07-12 18:44:22,044 [run_pretraining.py:  558]:	worker_index: 6, step: 706, cost: 8.139786, mlm loss: 8.139786, speed: 1.090916 steps/s, speed: 8.727324 samples/s, speed: 4468.389979 tokens/s, learning rate: 7.050e-06, loss_scalings: 13421.773438, pp_loss: 8.465872
[INFO] 2021-07-12 18:44:22,044 [run_pretraining.py:  512]:	********exe.run_706******* 
[INFO] 2021-07-12 18:44:22,999 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:22,999 [run_pretraining.py:  534]:	loss/total_loss, 8.326286315917969, 707
[INFO] 2021-07-12 18:44:23,000 [run_pretraining.py:  535]:	loss/mlm_loss, 8.326286315917969, 707
[INFO] 2021-07-12 18:44:23,000 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.059999916236848e-06, 707
[INFO] 2021-07-12 18:44:23,000 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 707
[INFO] 2021-07-12 18:44:23,000 [run_pretraining.py:  558]:	worker_index: 6, step: 707, cost: 8.326286, mlm loss: 8.326286, speed: 1.047346 steps/s, speed: 8.378767 samples/s, speed: 4289.928775 tokens/s, learning rate: 7.060e-06, loss_scalings: 13421.773438, pp_loss: 7.600169
[INFO] 2021-07-12 18:44:23,000 [run_pretraining.py:  512]:	********exe.run_707******* 
[INFO] 2021-07-12 18:44:23,932 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:23,933 [run_pretraining.py:  534]:	loss/total_loss, 8.79707145690918, 708
[INFO] 2021-07-12 18:44:23,933 [run_pretraining.py:  535]:	loss/mlm_loss, 8.79707145690918, 708
[INFO] 2021-07-12 18:44:23,933 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.06999935573549e-06, 708
[INFO] 2021-07-12 18:44:23,933 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 708
[INFO] 2021-07-12 18:44:23,933 [run_pretraining.py:  558]:	worker_index: 6, step: 708, cost: 8.797071, mlm loss: 8.797071, speed: 1.072132 steps/s, speed: 8.577052 samples/s, speed: 4391.450763 tokens/s, learning rate: 7.070e-06, loss_scalings: 13421.773438, pp_loss: 8.347755
[INFO] 2021-07-12 18:44:23,933 [run_pretraining.py:  512]:	********exe.run_708******* 
[INFO] 2021-07-12 18:44:24,844 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:24,844 [run_pretraining.py:  534]:	loss/total_loss, 8.65227222442627, 709
[INFO] 2021-07-12 18:44:24,845 [run_pretraining.py:  535]:	loss/mlm_loss, 8.65227222442627, 709
[INFO] 2021-07-12 18:44:24,845 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.079999704728834e-06, 709
[INFO] 2021-07-12 18:44:24,845 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 709
[INFO] 2021-07-12 18:44:24,845 [run_pretraining.py:  558]:	worker_index: 6, step: 709, cost: 8.652272, mlm loss: 8.652272, speed: 1.097879 steps/s, speed: 8.783034 samples/s, speed: 4496.913566 tokens/s, learning rate: 7.080e-06, loss_scalings: 13421.773438, pp_loss: 8.093484
[INFO] 2021-07-12 18:44:24,845 [run_pretraining.py:  512]:	********exe.run_709******* 
[INFO] 2021-07-12 18:44:25,756 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:25,756 [run_pretraining.py:  534]:	loss/total_loss, 7.822450160980225, 710
[INFO] 2021-07-12 18:44:25,756 [run_pretraining.py:  535]:	loss/mlm_loss, 7.822450160980225, 710
[INFO] 2021-07-12 18:44:25,756 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.0900000537221786e-06, 710
[INFO] 2021-07-12 18:44:25,756 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 710
[INFO] 2021-07-12 18:44:25,757 [run_pretraining.py:  558]:	worker_index: 6, step: 710, cost: 7.822450, mlm loss: 7.822450, speed: 1.097644 steps/s, speed: 8.781154 samples/s, speed: 4495.950914 tokens/s, learning rate: 7.090e-06, loss_scalings: 13421.773438, pp_loss: 7.939361
[INFO] 2021-07-12 18:44:25,757 [run_pretraining.py:  512]:	********exe.run_710******* 
[INFO] 2021-07-12 18:44:26,683 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:26,684 [run_pretraining.py:  534]:	loss/total_loss, 7.9449052810668945, 711
[INFO] 2021-07-12 18:44:26,684 [run_pretraining.py:  535]:	loss/mlm_loss, 7.9449052810668945, 711
[INFO] 2021-07-12 18:44:26,684 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.099999947968172e-06, 711
[INFO] 2021-07-12 18:44:26,684 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 711
[INFO] 2021-07-12 18:44:26,684 [run_pretraining.py:  558]:	worker_index: 6, step: 711, cost: 7.944905, mlm loss: 7.944905, speed: 1.078819 steps/s, speed: 8.630548 samples/s, speed: 4418.840656 tokens/s, learning rate: 7.100e-06, loss_scalings: 13421.773438, pp_loss: 8.445137
[INFO] 2021-07-12 18:44:26,684 [run_pretraining.py:  512]:	********exe.run_711******* 
[INFO] 2021-07-12 18:44:27,601 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:27,602 [run_pretraining.py:  534]:	loss/total_loss, 8.783872604370117, 712
[INFO] 2021-07-12 18:44:27,602 [run_pretraining.py:  535]:	loss/mlm_loss, 8.783872604370117, 712
[INFO] 2021-07-12 18:44:27,602 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.109999387466814e-06, 712
[INFO] 2021-07-12 18:44:27,602 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 712
[INFO] 2021-07-12 18:44:27,602 [run_pretraining.py:  558]:	worker_index: 6, step: 712, cost: 8.783873, mlm loss: 8.783873, speed: 1.090467 steps/s, speed: 8.723735 samples/s, speed: 4466.552129 tokens/s, learning rate: 7.110e-06, loss_scalings: 13421.773438, pp_loss: 8.516817
[INFO] 2021-07-12 18:44:27,602 [run_pretraining.py:  512]:	********exe.run_712******* 
[INFO] 2021-07-12 18:44:28,562 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:28,562 [run_pretraining.py:  534]:	loss/total_loss, 8.721368789672852, 713
[INFO] 2021-07-12 18:44:28,562 [run_pretraining.py:  535]:	loss/mlm_loss, 8.721368789672852, 713
[INFO] 2021-07-12 18:44:28,562 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.119999736460159e-06, 713
[INFO] 2021-07-12 18:44:28,563 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 713
[INFO] 2021-07-12 18:44:28,563 [run_pretraining.py:  558]:	worker_index: 6, step: 713, cost: 8.721369, mlm loss: 8.721369, speed: 1.041653 steps/s, speed: 8.333227 samples/s, speed: 4266.612456 tokens/s, learning rate: 7.120e-06, loss_scalings: 13421.773438, pp_loss: 8.411827
[INFO] 2021-07-12 18:44:28,563 [run_pretraining.py:  512]:	********exe.run_713******* 
[INFO] 2021-07-12 18:44:29,634 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:29,635 [run_pretraining.py:  534]:	loss/total_loss, 8.36532974243164, 714
[INFO] 2021-07-12 18:44:29,635 [run_pretraining.py:  535]:	loss/mlm_loss, 8.36532974243164, 714
[INFO] 2021-07-12 18:44:29,635 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.129999630706152e-06, 714
[INFO] 2021-07-12 18:44:29,635 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 714
[INFO] 2021-07-12 18:44:29,636 [run_pretraining.py:  558]:	worker_index: 6, step: 714, cost: 8.365330, mlm loss: 8.365330, speed: 0.932759 steps/s, speed: 7.462069 samples/s, speed: 3820.579332 tokens/s, learning rate: 7.130e-06, loss_scalings: 13421.773438, pp_loss: 8.357381
[INFO] 2021-07-12 18:44:29,636 [run_pretraining.py:  512]:	********exe.run_714******* 
[INFO] 2021-07-12 18:44:30,711 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:30,712 [run_pretraining.py:  534]:	loss/total_loss, 5.648812770843506, 715
[INFO] 2021-07-12 18:44:30,712 [run_pretraining.py:  535]:	loss/mlm_loss, 5.648812770843506, 715
[INFO] 2021-07-12 18:44:30,712 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.139999979699496e-06, 715
[INFO] 2021-07-12 18:44:30,712 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 715
[INFO] 2021-07-12 18:44:30,712 [run_pretraining.py:  558]:	worker_index: 6, step: 715, cost: 5.648813, mlm loss: 5.648813, speed: 0.929268 steps/s, speed: 7.434142 samples/s, speed: 3806.280806 tokens/s, learning rate: 7.140e-06, loss_scalings: 13421.773438, pp_loss: 7.767481
[INFO] 2021-07-12 18:44:30,712 [run_pretraining.py:  512]:	********exe.run_715******* 
[INFO] 2021-07-12 18:44:31,775 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:31,776 [run_pretraining.py:  534]:	loss/total_loss, 8.448318481445312, 716
[INFO] 2021-07-12 18:44:31,776 [run_pretraining.py:  535]:	loss/mlm_loss, 8.448318481445312, 716
[INFO] 2021-07-12 18:44:31,776 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.15000032869284e-06, 716
[INFO] 2021-07-12 18:44:31,776 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 716
[INFO] 2021-07-12 18:44:31,776 [run_pretraining.py:  558]:	worker_index: 6, step: 716, cost: 8.448318, mlm loss: 8.448318, speed: 0.940416 steps/s, speed: 7.523326 samples/s, speed: 3851.942832 tokens/s, learning rate: 7.150e-06, loss_scalings: 13421.773438, pp_loss: 8.712680
[INFO] 2021-07-12 18:44:31,776 [run_pretraining.py:  512]:	********exe.run_716******* 
[INFO] 2021-07-12 18:44:32,843 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:32,844 [run_pretraining.py:  534]:	loss/total_loss, 8.35240650177002, 717
[INFO] 2021-07-12 18:44:32,844 [run_pretraining.py:  535]:	loss/mlm_loss, 8.35240650177002, 717
[INFO] 2021-07-12 18:44:32,844 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.159999768191483e-06, 717
[INFO] 2021-07-12 18:44:32,844 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 717
[INFO] 2021-07-12 18:44:32,844 [run_pretraining.py:  558]:	worker_index: 6, step: 717, cost: 8.352407, mlm loss: 8.352407, speed: 0.936890 steps/s, speed: 7.495122 samples/s, speed: 3837.502465 tokens/s, learning rate: 7.160e-06, loss_scalings: 13421.773438, pp_loss: 8.512667
[INFO] 2021-07-12 18:44:32,845 [run_pretraining.py:  512]:	********exe.run_717******* 
[INFO] 2021-07-12 18:44:33,909 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:33,910 [run_pretraining.py:  534]:	loss/total_loss, 8.297176361083984, 718
[INFO] 2021-07-12 18:44:33,910 [run_pretraining.py:  535]:	loss/mlm_loss, 8.297176361083984, 718
[INFO] 2021-07-12 18:44:33,910 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.169999662437476e-06, 718
[INFO] 2021-07-12 18:44:33,910 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 718
[INFO] 2021-07-12 18:44:33,910 [run_pretraining.py:  558]:	worker_index: 6, step: 718, cost: 8.297176, mlm loss: 8.297176, speed: 0.938729 steps/s, speed: 7.509829 samples/s, speed: 3845.032202 tokens/s, learning rate: 7.170e-06, loss_scalings: 13421.773438, pp_loss: 8.713921
[INFO] 2021-07-12 18:44:33,911 [run_pretraining.py:  512]:	********exe.run_718******* 
[INFO] 2021-07-12 18:44:34,978 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:34,979 [run_pretraining.py:  534]:	loss/total_loss, 8.367238998413086, 719
[INFO] 2021-07-12 18:44:34,979 [run_pretraining.py:  535]:	loss/mlm_loss, 8.367238998413086, 719
[INFO] 2021-07-12 18:44:34,979 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.1800000114308205e-06, 719
[INFO] 2021-07-12 18:44:34,979 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 719
[INFO] 2021-07-12 18:44:34,979 [run_pretraining.py:  558]:	worker_index: 6, step: 719, cost: 8.367239, mlm loss: 8.367239, speed: 0.936431 steps/s, speed: 7.491451 samples/s, speed: 3835.622709 tokens/s, learning rate: 7.180e-06, loss_scalings: 13421.773438, pp_loss: 8.144190
[INFO] 2021-07-12 18:44:34,979 [run_pretraining.py:  512]:	********exe.run_719******* 
[INFO] 2021-07-12 18:44:36,049 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:36,050 [run_pretraining.py:  534]:	loss/total_loss, 9.407204627990723, 720
[INFO] 2021-07-12 18:44:36,050 [run_pretraining.py:  535]:	loss/mlm_loss, 9.407204627990723, 720
[INFO] 2021-07-12 18:44:36,050 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.189999905676814e-06, 720
[INFO] 2021-07-12 18:44:36,050 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 720
[INFO] 2021-07-12 18:44:36,050 [run_pretraining.py:  558]:	worker_index: 6, step: 720, cost: 9.407205, mlm loss: 9.407205, speed: 0.934223 steps/s, speed: 7.473785 samples/s, speed: 3826.577898 tokens/s, learning rate: 7.190e-06, loss_scalings: 13421.773438, pp_loss: 8.500639
[INFO] 2021-07-12 18:44:36,050 [run_pretraining.py:  512]:	********exe.run_720******* 
[INFO] 2021-07-12 18:44:37,118 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:37,119 [run_pretraining.py:  534]:	loss/total_loss, 8.548038482666016, 721
[INFO] 2021-07-12 18:44:37,119 [run_pretraining.py:  535]:	loss/mlm_loss, 8.548038482666016, 721
[INFO] 2021-07-12 18:44:37,119 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.199999345175456e-06, 721
[INFO] 2021-07-12 18:44:37,119 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 721
[INFO] 2021-07-12 18:44:37,119 [run_pretraining.py:  558]:	worker_index: 6, step: 721, cost: 8.548038, mlm loss: 8.548038, speed: 0.936016 steps/s, speed: 7.488127 samples/s, speed: 3833.921038 tokens/s, learning rate: 7.200e-06, loss_scalings: 13421.773438, pp_loss: 8.454269
[INFO] 2021-07-12 18:44:37,119 [run_pretraining.py:  512]:	********exe.run_721******* 
[INFO] 2021-07-12 18:44:38,201 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:38,201 [run_pretraining.py:  534]:	loss/total_loss, 7.975922107696533, 722
[INFO] 2021-07-12 18:44:38,201 [run_pretraining.py:  535]:	loss/mlm_loss, 7.975922107696533, 722
[INFO] 2021-07-12 18:44:38,201 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.2099996941688005e-06, 722
[INFO] 2021-07-12 18:44:38,202 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 722
[INFO] 2021-07-12 18:44:38,202 [run_pretraining.py:  558]:	worker_index: 6, step: 722, cost: 7.975922, mlm loss: 7.975922, speed: 0.924469 steps/s, speed: 7.395749 samples/s, speed: 3786.623504 tokens/s, learning rate: 7.210e-06, loss_scalings: 13421.773438, pp_loss: 8.228139
[INFO] 2021-07-12 18:44:38,202 [run_pretraining.py:  512]:	********exe.run_722******* 
[INFO] 2021-07-12 18:44:39,318 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:39,319 [run_pretraining.py:  534]:	loss/total_loss, 8.28065299987793, 723
[INFO] 2021-07-12 18:44:39,319 [run_pretraining.py:  535]:	loss/mlm_loss, 8.28065299987793, 723
[INFO] 2021-07-12 18:44:39,319 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.220000043162145e-06, 723
[INFO] 2021-07-12 18:44:39,319 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 723
[INFO] 2021-07-12 18:44:39,319 [run_pretraining.py:  558]:	worker_index: 6, step: 723, cost: 8.280653, mlm loss: 8.280653, speed: 0.895375 steps/s, speed: 7.162999 samples/s, speed: 3667.455564 tokens/s, learning rate: 7.220e-06, loss_scalings: 13421.773438, pp_loss: 8.377926
[INFO] 2021-07-12 18:44:39,319 [run_pretraining.py:  512]:	********exe.run_723******* 
[INFO] 2021-07-12 18:44:40,384 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:40,385 [run_pretraining.py:  534]:	loss/total_loss, 8.459663391113281, 724
[INFO] 2021-07-12 18:44:40,385 [run_pretraining.py:  535]:	loss/mlm_loss, 8.459663391113281, 724
[INFO] 2021-07-12 18:44:40,385 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.229999937408138e-06, 724
[INFO] 2021-07-12 18:44:40,385 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 724
[INFO] 2021-07-12 18:44:40,385 [run_pretraining.py:  558]:	worker_index: 6, step: 724, cost: 8.459663, mlm loss: 8.459663, speed: 0.938856 steps/s, speed: 7.510849 samples/s, speed: 3845.554631 tokens/s, learning rate: 7.230e-06, loss_scalings: 13421.773438, pp_loss: 8.228143
[INFO] 2021-07-12 18:44:40,385 [run_pretraining.py:  512]:	********exe.run_724******* 
[INFO] 2021-07-12 18:44:41,446 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:41,447 [run_pretraining.py:  534]:	loss/total_loss, 5.7152628898620605, 725
[INFO] 2021-07-12 18:44:41,447 [run_pretraining.py:  535]:	loss/mlm_loss, 5.7152628898620605, 725
[INFO] 2021-07-12 18:44:41,447 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.240000286401482e-06, 725
[INFO] 2021-07-12 18:44:41,447 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 725
[INFO] 2021-07-12 18:44:41,447 [run_pretraining.py:  558]:	worker_index: 6, step: 725, cost: 5.715263, mlm loss: 5.715263, speed: 0.942287 steps/s, speed: 7.538292 samples/s, speed: 3859.605703 tokens/s, learning rate: 7.240e-06, loss_scalings: 13421.773438, pp_loss: 7.611389
[INFO] 2021-07-12 18:44:41,447 [run_pretraining.py:  512]:	********exe.run_725******* 
[INFO] 2021-07-12 18:44:42,507 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:42,507 [run_pretraining.py:  534]:	loss/total_loss, 8.38300609588623, 726
[INFO] 2021-07-12 18:44:42,507 [run_pretraining.py:  535]:	loss/mlm_loss, 8.38300609588623, 726
[INFO] 2021-07-12 18:44:42,508 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.249999725900125e-06, 726
[INFO] 2021-07-12 18:44:42,508 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 726
[INFO] 2021-07-12 18:44:42,508 [run_pretraining.py:  558]:	worker_index: 6, step: 726, cost: 8.383006, mlm loss: 8.383006, speed: 0.943350 steps/s, speed: 7.546804 samples/s, speed: 3863.963427 tokens/s, learning rate: 7.250e-06, loss_scalings: 13421.773438, pp_loss: 8.253428
[INFO] 2021-07-12 18:44:42,508 [run_pretraining.py:  512]:	********exe.run_726******* 
[INFO] 2021-07-12 18:44:43,575 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:43,575 [run_pretraining.py:  534]:	loss/total_loss, 8.281312942504883, 727
[INFO] 2021-07-12 18:44:43,576 [run_pretraining.py:  535]:	loss/mlm_loss, 8.281312942504883, 727
[INFO] 2021-07-12 18:44:43,576 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.259999620146118e-06, 727
[INFO] 2021-07-12 18:44:43,576 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 727
[INFO] 2021-07-12 18:44:43,576 [run_pretraining.py:  558]:	worker_index: 6, step: 727, cost: 8.281313, mlm loss: 8.281313, speed: 0.936875 steps/s, speed: 7.494996 samples/s, speed: 3837.438176 tokens/s, learning rate: 7.260e-06, loss_scalings: 13421.773438, pp_loss: 8.420074
[INFO] 2021-07-12 18:44:43,576 [run_pretraining.py:  512]:	********exe.run_727******* 
[INFO] 2021-07-12 18:44:44,621 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:44,622 [run_pretraining.py:  534]:	loss/total_loss, 8.613899230957031, 728
[INFO] 2021-07-12 18:44:44,622 [run_pretraining.py:  535]:	loss/mlm_loss, 8.613899230957031, 728
[INFO] 2021-07-12 18:44:44,622 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.269999969139462e-06, 728
[INFO] 2021-07-12 18:44:44,622 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 728
[INFO] 2021-07-12 18:44:44,622 [run_pretraining.py:  558]:	worker_index: 6, step: 728, cost: 8.613899, mlm loss: 8.613899, speed: 0.956085 steps/s, speed: 7.648684 samples/s, speed: 3916.126148 tokens/s, learning rate: 7.270e-06, loss_scalings: 13421.773438, pp_loss: 8.329119
[INFO] 2021-07-12 18:44:44,623 [run_pretraining.py:  512]:	********exe.run_728******* 
[INFO] 2021-07-12 18:44:45,677 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:45,677 [run_pretraining.py:  534]:	loss/total_loss, 8.230025291442871, 729
[INFO] 2021-07-12 18:44:45,678 [run_pretraining.py:  535]:	loss/mlm_loss, 8.230025291442871, 729
[INFO] 2021-07-12 18:44:45,678 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.2800003181328066e-06, 729
[INFO] 2021-07-12 18:44:45,678 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 729
[INFO] 2021-07-12 18:44:45,678 [run_pretraining.py:  558]:	worker_index: 6, step: 729, cost: 8.230025, mlm loss: 8.230025, speed: 0.948189 steps/s, speed: 7.585513 samples/s, speed: 3883.782504 tokens/s, learning rate: 7.280e-06, loss_scalings: 13421.773438, pp_loss: 7.327284
[INFO] 2021-07-12 18:44:45,678 [run_pretraining.py:  512]:	********exe.run_729******* 
[INFO] 2021-07-12 18:44:46,745 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:46,746 [run_pretraining.py:  534]:	loss/total_loss, 8.362919807434082, 730
[INFO] 2021-07-12 18:44:46,746 [run_pretraining.py:  535]:	loss/mlm_loss, 8.362919807434082, 730
[INFO] 2021-07-12 18:44:46,746 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.289999757631449e-06, 730
[INFO] 2021-07-12 18:44:46,746 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 730
[INFO] 2021-07-12 18:44:46,746 [run_pretraining.py:  558]:	worker_index: 6, step: 730, cost: 8.362920, mlm loss: 8.362920, speed: 0.936554 steps/s, speed: 7.492429 samples/s, speed: 3836.123740 tokens/s, learning rate: 7.290e-06, loss_scalings: 13421.773438, pp_loss: 8.301092
[INFO] 2021-07-12 18:44:46,746 [run_pretraining.py:  512]:	********exe.run_730******* 
[INFO] 2021-07-12 18:44:47,816 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:47,817 [run_pretraining.py:  534]:	loss/total_loss, 8.806154251098633, 731
[INFO] 2021-07-12 18:44:47,817 [run_pretraining.py:  535]:	loss/mlm_loss, 8.806154251098633, 731
[INFO] 2021-07-12 18:44:47,817 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.299999651877442e-06, 731
[INFO] 2021-07-12 18:44:47,817 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 731
[INFO] 2021-07-12 18:44:47,817 [run_pretraining.py:  558]:	worker_index: 6, step: 731, cost: 8.806154, mlm loss: 8.806154, speed: 0.934525 steps/s, speed: 7.476200 samples/s, speed: 3827.814158 tokens/s, learning rate: 7.300e-06, loss_scalings: 13421.773438, pp_loss: 8.476873
[INFO] 2021-07-12 18:44:47,817 [run_pretraining.py:  512]:	********exe.run_731******* 
[INFO] 2021-07-12 18:44:48,879 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:48,880 [run_pretraining.py:  534]:	loss/total_loss, 7.867447853088379, 732
[INFO] 2021-07-12 18:44:48,880 [run_pretraining.py:  535]:	loss/mlm_loss, 7.867447853088379, 732
[INFO] 2021-07-12 18:44:48,880 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.310000000870787e-06, 732
[INFO] 2021-07-12 18:44:48,880 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 732
[INFO] 2021-07-12 18:44:48,880 [run_pretraining.py:  558]:	worker_index: 6, step: 732, cost: 7.867448, mlm loss: 7.867448, speed: 0.941278 steps/s, speed: 7.530225 samples/s, speed: 3855.474958 tokens/s, learning rate: 7.310e-06, loss_scalings: 13421.773438, pp_loss: 8.442560
[INFO] 2021-07-12 18:44:48,880 [run_pretraining.py:  512]:	********exe.run_732******* 
[INFO] 2021-07-12 18:44:49,950 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:49,951 [run_pretraining.py:  534]:	loss/total_loss, 7.767545700073242, 733
[INFO] 2021-07-12 18:44:49,951 [run_pretraining.py:  535]:	loss/mlm_loss, 7.767545700073242, 733
[INFO] 2021-07-12 18:44:49,951 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.31999989511678e-06, 733
[INFO] 2021-07-12 18:44:49,951 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 733
[INFO] 2021-07-12 18:44:49,951 [run_pretraining.py:  558]:	worker_index: 6, step: 733, cost: 7.767546, mlm loss: 7.767546, speed: 0.934399 steps/s, speed: 7.475195 samples/s, speed: 3827.299947 tokens/s, learning rate: 7.320e-06, loss_scalings: 13421.773438, pp_loss: 7.853749
[INFO] 2021-07-12 18:44:49,951 [run_pretraining.py:  512]:	********exe.run_733******* 
[INFO] 2021-07-12 18:44:51,022 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:51,023 [run_pretraining.py:  534]:	loss/total_loss, 8.43341064453125, 734
[INFO] 2021-07-12 18:44:51,023 [run_pretraining.py:  535]:	loss/mlm_loss, 8.43341064453125, 734
[INFO] 2021-07-12 18:44:51,023 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.329999334615422e-06, 734
[INFO] 2021-07-12 18:44:51,023 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 734
[INFO] 2021-07-12 18:44:51,023 [run_pretraining.py:  558]:	worker_index: 6, step: 734, cost: 8.433411, mlm loss: 8.433411, speed: 0.933508 steps/s, speed: 7.468061 samples/s, speed: 3823.647321 tokens/s, learning rate: 7.330e-06, loss_scalings: 13421.773438, pp_loss: 8.047390
[INFO] 2021-07-12 18:44:51,023 [run_pretraining.py:  512]:	********exe.run_734******* 
[INFO] 2021-07-12 18:44:52,066 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:52,067 [run_pretraining.py:  534]:	loss/total_loss, 8.628292083740234, 735
[INFO] 2021-07-12 18:44:52,067 [run_pretraining.py:  535]:	loss/mlm_loss, 8.628292083740234, 735
[INFO] 2021-07-12 18:44:52,067 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.339999683608767e-06, 735
[INFO] 2021-07-12 18:44:52,067 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 735
[INFO] 2021-07-12 18:44:52,067 [run_pretraining.py:  558]:	worker_index: 6, step: 735, cost: 8.628292, mlm loss: 8.628292, speed: 0.958058 steps/s, speed: 7.664465 samples/s, speed: 3924.206321 tokens/s, learning rate: 7.340e-06, loss_scalings: 13421.773438, pp_loss: 8.260916
[INFO] 2021-07-12 18:44:52,068 [run_pretraining.py:  512]:	********exe.run_735******* 
[INFO] 2021-07-12 18:44:52,974 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:52,975 [run_pretraining.py:  534]:	loss/total_loss, 8.366609573364258, 736
[INFO] 2021-07-12 18:44:52,975 [run_pretraining.py:  535]:	loss/mlm_loss, 8.366609573364258, 736
[INFO] 2021-07-12 18:44:52,975 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.350000032602111e-06, 736
[INFO] 2021-07-12 18:44:52,975 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 736
[INFO] 2021-07-12 18:44:52,975 [run_pretraining.py:  558]:	worker_index: 6, step: 736, cost: 8.366610, mlm loss: 8.366610, speed: 1.102210 steps/s, speed: 8.817676 samples/s, speed: 4514.650173 tokens/s, learning rate: 7.350e-06, loss_scalings: 13421.773438, pp_loss: 8.095733
[INFO] 2021-07-12 18:44:52,975 [run_pretraining.py:  512]:	********exe.run_736******* 
[INFO] 2021-07-12 18:44:53,891 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:53,892 [run_pretraining.py:  534]:	loss/total_loss, 8.260321617126465, 737
[INFO] 2021-07-12 18:44:53,892 [run_pretraining.py:  535]:	loss/mlm_loss, 8.260321617126465, 737
[INFO] 2021-07-12 18:44:53,892 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.359999926848104e-06, 737
[INFO] 2021-07-12 18:44:53,892 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 737
[INFO] 2021-07-12 18:44:53,892 [run_pretraining.py:  558]:	worker_index: 6, step: 737, cost: 8.260322, mlm loss: 8.260322, speed: 1.091310 steps/s, speed: 8.730483 samples/s, speed: 4470.007190 tokens/s, learning rate: 7.360e-06, loss_scalings: 13421.773438, pp_loss: 8.257674
[INFO] 2021-07-12 18:44:53,893 [run_pretraining.py:  512]:	********exe.run_737******* 
[INFO] 2021-07-12 18:44:54,807 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:54,807 [run_pretraining.py:  534]:	loss/total_loss, 8.250652313232422, 738
[INFO] 2021-07-12 18:44:54,808 [run_pretraining.py:  535]:	loss/mlm_loss, 8.250652313232422, 738
[INFO] 2021-07-12 18:44:54,808 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.3700002758414485e-06, 738
[INFO] 2021-07-12 18:44:54,808 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 738
[INFO] 2021-07-12 18:44:54,808 [run_pretraining.py:  558]:	worker_index: 6, step: 738, cost: 8.250652, mlm loss: 8.250652, speed: 1.093235 steps/s, speed: 8.745879 samples/s, speed: 4477.890231 tokens/s, learning rate: 7.370e-06, loss_scalings: 13421.773438, pp_loss: 8.264813
[INFO] 2021-07-12 18:44:54,808 [run_pretraining.py:  512]:	********exe.run_738******* 
[INFO] 2021-07-12 18:44:55,716 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:55,717 [run_pretraining.py:  534]:	loss/total_loss, 8.354689598083496, 739
[INFO] 2021-07-12 18:44:55,717 [run_pretraining.py:  535]:	loss/mlm_loss, 8.354689598083496, 739
[INFO] 2021-07-12 18:44:55,717 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.379999715340091e-06, 739
[INFO] 2021-07-12 18:44:55,717 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 739
[INFO] 2021-07-12 18:44:55,717 [run_pretraining.py:  558]:	worker_index: 6, step: 739, cost: 8.354690, mlm loss: 8.354690, speed: 1.100756 steps/s, speed: 8.806048 samples/s, speed: 4508.696414 tokens/s, learning rate: 7.380e-06, loss_scalings: 13421.773438, pp_loss: 8.201784
[INFO] 2021-07-12 18:44:55,717 [run_pretraining.py:  512]:	********exe.run_739******* 
[INFO] 2021-07-12 18:44:56,633 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:56,633 [run_pretraining.py:  534]:	loss/total_loss, 8.03698444366455, 740
[INFO] 2021-07-12 18:44:56,633 [run_pretraining.py:  535]:	loss/mlm_loss, 8.03698444366455, 740
[INFO] 2021-07-12 18:44:56,633 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.389999609586084e-06, 740
[INFO] 2021-07-12 18:44:56,633 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 740
[INFO] 2021-07-12 18:44:56,634 [run_pretraining.py:  558]:	worker_index: 6, step: 740, cost: 8.036984, mlm loss: 8.036984, speed: 1.092000 steps/s, speed: 8.736004 samples/s, speed: 4472.834013 tokens/s, learning rate: 7.390e-06, loss_scalings: 13421.773438, pp_loss: 8.400532
[INFO] 2021-07-12 18:44:56,634 [run_pretraining.py:  512]:	********exe.run_740******* 
[INFO] 2021-07-12 18:44:57,550 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:57,551 [run_pretraining.py:  534]:	loss/total_loss, 5.78042459487915, 741
[INFO] 2021-07-12 18:44:57,551 [run_pretraining.py:  535]:	loss/mlm_loss, 5.78042459487915, 741
[INFO] 2021-07-12 18:44:57,551 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.3999999585794285e-06, 741
[INFO] 2021-07-12 18:44:57,551 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 741
[INFO] 2021-07-12 18:44:57,551 [run_pretraining.py:  558]:	worker_index: 6, step: 741, cost: 5.780425, mlm loss: 5.780425, speed: 1.090626 steps/s, speed: 8.725012 samples/s, speed: 4467.206008 tokens/s, learning rate: 7.400e-06, loss_scalings: 13421.773438, pp_loss: 7.325027
[INFO] 2021-07-12 18:44:57,551 [run_pretraining.py:  512]:	********exe.run_741******* 
[INFO] 2021-07-12 18:44:58,461 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:58,462 [run_pretraining.py:  534]:	loss/total_loss, 8.13376235961914, 742
[INFO] 2021-07-12 18:44:58,462 [run_pretraining.py:  535]:	loss/mlm_loss, 8.13376235961914, 742
[INFO] 2021-07-12 18:44:58,462 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.409999852825422e-06, 742
[INFO] 2021-07-12 18:44:58,462 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 742
[INFO] 2021-07-12 18:44:58,462 [run_pretraining.py:  558]:	worker_index: 6, step: 742, cost: 8.133762, mlm loss: 8.133762, speed: 1.098104 steps/s, speed: 8.784832 samples/s, speed: 4497.834238 tokens/s, learning rate: 7.410e-06, loss_scalings: 13421.773438, pp_loss: 8.197790
[INFO] 2021-07-12 18:44:58,463 [run_pretraining.py:  512]:	********exe.run_742******* 
[INFO] 2021-07-12 18:44:59,382 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:59,383 [run_pretraining.py:  534]:	loss/total_loss, 8.637945175170898, 743
[INFO] 2021-07-12 18:44:59,383 [run_pretraining.py:  535]:	loss/mlm_loss, 8.637945175170898, 743
[INFO] 2021-07-12 18:44:59,383 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.419999292324064e-06, 743
[INFO] 2021-07-12 18:44:59,383 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 743
[INFO] 2021-07-12 18:44:59,383 [run_pretraining.py:  558]:	worker_index: 6, step: 743, cost: 8.637945, mlm loss: 8.637945, speed: 1.086946 steps/s, speed: 8.695566 samples/s, speed: 4452.129700 tokens/s, learning rate: 7.420e-06, loss_scalings: 13421.773438, pp_loss: 8.295860
[INFO] 2021-07-12 18:44:59,383 [run_pretraining.py:  512]:	********exe.run_743******* 
[INFO] 2021-07-12 18:45:00,284 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:00,285 [run_pretraining.py:  534]:	loss/total_loss, 8.426737785339355, 744
[INFO] 2021-07-12 18:45:00,285 [run_pretraining.py:  535]:	loss/mlm_loss, 8.426737785339355, 744
[INFO] 2021-07-12 18:45:00,285 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.4299996413174085e-06, 744
[INFO] 2021-07-12 18:45:00,285 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 744
[INFO] 2021-07-12 18:45:00,285 [run_pretraining.py:  558]:	worker_index: 6, step: 744, cost: 8.426738, mlm loss: 8.426738, speed: 1.109905 steps/s, speed: 8.879239 samples/s, speed: 4546.170493 tokens/s, learning rate: 7.430e-06, loss_scalings: 13421.773438, pp_loss: 8.283759
[INFO] 2021-07-12 18:45:00,285 [run_pretraining.py:  512]:	********exe.run_744******* 
[INFO] 2021-07-12 18:45:01,199 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:01,199 [run_pretraining.py:  534]:	loss/total_loss, 8.047950744628906, 745
[INFO] 2021-07-12 18:45:01,200 [run_pretraining.py:  535]:	loss/mlm_loss, 8.047950744628906, 745
[INFO] 2021-07-12 18:45:01,200 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.439999990310753e-06, 745
[INFO] 2021-07-12 18:45:01,200 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 745
[INFO] 2021-07-12 18:45:01,200 [run_pretraining.py:  558]:	worker_index: 6, step: 745, cost: 8.047951, mlm loss: 8.047951, speed: 1.093809 steps/s, speed: 8.750468 samples/s, speed: 4480.239771 tokens/s, learning rate: 7.440e-06, loss_scalings: 13421.773438, pp_loss: 8.176701
[INFO] 2021-07-12 18:45:01,200 [run_pretraining.py:  512]:	********exe.run_745******* 
[INFO] 2021-07-12 18:45:02,122 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:02,123 [run_pretraining.py:  534]:	loss/total_loss, 7.54567289352417, 746
[INFO] 2021-07-12 18:45:02,123 [run_pretraining.py:  535]:	loss/mlm_loss, 7.54567289352417, 746
[INFO] 2021-07-12 18:45:02,123 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.449999884556746e-06, 746
[INFO] 2021-07-12 18:45:02,123 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 746
[INFO] 2021-07-12 18:45:02,123 [run_pretraining.py:  558]:	worker_index: 6, step: 746, cost: 7.545673, mlm loss: 7.545673, speed: 1.083640 steps/s, speed: 8.669121 samples/s, speed: 4438.590084 tokens/s, learning rate: 7.450e-06, loss_scalings: 13421.773438, pp_loss: 8.139237
[INFO] 2021-07-12 18:45:02,123 [run_pretraining.py:  512]:	********exe.run_746******* 
[INFO] 2021-07-12 18:45:03,038 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:03,038 [run_pretraining.py:  534]:	loss/total_loss, 8.210006713867188, 747
[INFO] 2021-07-12 18:45:03,039 [run_pretraining.py:  535]:	loss/mlm_loss, 8.210006713867188, 747
[INFO] 2021-07-12 18:45:03,039 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.46000023355009e-06, 747
[INFO] 2021-07-12 18:45:03,039 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 747
[INFO] 2021-07-12 18:45:03,039 [run_pretraining.py:  558]:	worker_index: 6, step: 747, cost: 8.210007, mlm loss: 8.210007, speed: 1.093141 steps/s, speed: 8.745125 samples/s, speed: 4477.503938 tokens/s, learning rate: 7.460e-06, loss_scalings: 13421.773438, pp_loss: 8.374523
[INFO] 2021-07-12 18:45:03,039 [run_pretraining.py:  512]:	********exe.run_747******* 
[INFO] 2021-07-12 18:45:03,959 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:03,959 [run_pretraining.py:  534]:	loss/total_loss, 8.55388069152832, 748
[INFO] 2021-07-12 18:45:03,960 [run_pretraining.py:  535]:	loss/mlm_loss, 8.55388069152832, 748
[INFO] 2021-07-12 18:45:03,960 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.469999673048733e-06, 748
[INFO] 2021-07-12 18:45:03,960 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 748
[INFO] 2021-07-12 18:45:03,960 [run_pretraining.py:  558]:	worker_index: 6, step: 748, cost: 8.553881, mlm loss: 8.553881, speed: 1.086677 steps/s, speed: 8.693412 samples/s, speed: 4451.026978 tokens/s, learning rate: 7.470e-06, loss_scalings: 13421.773438, pp_loss: 7.946436
[INFO] 2021-07-12 18:45:03,960 [run_pretraining.py:  512]:	********exe.run_748******* 
[INFO] 2021-07-12 18:45:04,872 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:04,872 [run_pretraining.py:  534]:	loss/total_loss, 8.277254104614258, 749
[INFO] 2021-07-12 18:45:04,872 [run_pretraining.py:  535]:	loss/mlm_loss, 8.277254104614258, 749
[INFO] 2021-07-12 18:45:04,872 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.479999567294726e-06, 749
[INFO] 2021-07-12 18:45:04,873 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 749
[INFO] 2021-07-12 18:45:04,873 [run_pretraining.py:  558]:	worker_index: 6, step: 749, cost: 8.277254, mlm loss: 8.277254, speed: 1.096342 steps/s, speed: 8.770734 samples/s, speed: 4490.615557 tokens/s, learning rate: 7.480e-06, loss_scalings: 13421.773438, pp_loss: 8.304029
[INFO] 2021-07-12 18:45:04,873 [run_pretraining.py:  512]:	********exe.run_749******* 
[INFO] 2021-07-12 18:45:05,782 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:05,782 [run_pretraining.py:  534]:	loss/total_loss, 8.400155067443848, 750
[INFO] 2021-07-12 18:45:05,783 [run_pretraining.py:  535]:	loss/mlm_loss, 8.400155067443848, 750
[INFO] 2021-07-12 18:45:05,783 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.48999991628807e-06, 750
[INFO] 2021-07-12 18:45:05,783 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 750
[INFO] 2021-07-12 18:45:05,783 [run_pretraining.py:  558]:	worker_index: 6, step: 750, cost: 8.400155, mlm loss: 8.400155, speed: 1.099510 steps/s, speed: 8.796080 samples/s, speed: 4503.592857 tokens/s, learning rate: 7.490e-06, loss_scalings: 13421.773438, pp_loss: 8.478230
[INFO] 2021-07-12 18:45:05,783 [run_pretraining.py:  512]:	********exe.run_750******* 
[INFO] 2021-07-12 18:45:06,697 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:06,698 [run_pretraining.py:  534]:	loss/total_loss, 8.074729919433594, 751
[INFO] 2021-07-12 18:45:06,698 [run_pretraining.py:  535]:	loss/mlm_loss, 8.074729919433594, 751
[INFO] 2021-07-12 18:45:06,698 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.500000265281415e-06, 751
[INFO] 2021-07-12 18:45:06,698 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 751
[INFO] 2021-07-12 18:45:06,698 [run_pretraining.py:  558]:	worker_index: 6, step: 751, cost: 8.074730, mlm loss: 8.074730, speed: 1.093268 steps/s, speed: 8.746144 samples/s, speed: 4478.025625 tokens/s, learning rate: 7.500e-06, loss_scalings: 13421.773438, pp_loss: 8.286531
[INFO] 2021-07-12 18:45:06,698 [run_pretraining.py:  512]:	********exe.run_751******* 
[INFO] 2021-07-12 18:45:07,606 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:07,606 [run_pretraining.py:  534]:	loss/total_loss, 8.713024139404297, 752
[INFO] 2021-07-12 18:45:07,607 [run_pretraining.py:  535]:	loss/mlm_loss, 8.713024139404297, 752
[INFO] 2021-07-12 18:45:07,607 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.509999704780057e-06, 752
[INFO] 2021-07-12 18:45:07,607 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 752
[INFO] 2021-07-12 18:45:07,607 [run_pretraining.py:  558]:	worker_index: 6, step: 752, cost: 8.713024, mlm loss: 8.713024, speed: 1.101526 steps/s, speed: 8.812206 samples/s, speed: 4511.849653 tokens/s, learning rate: 7.510e-06, loss_scalings: 13421.773438, pp_loss: 8.626889
[INFO] 2021-07-12 18:45:07,607 [run_pretraining.py:  512]:	********exe.run_752******* 
[INFO] 2021-07-12 18:45:08,515 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:08,516 [run_pretraining.py:  534]:	loss/total_loss, 8.298259735107422, 753
[INFO] 2021-07-12 18:45:08,516 [run_pretraining.py:  535]:	loss/mlm_loss, 8.298259735107422, 753
[INFO] 2021-07-12 18:45:08,516 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.51999959902605e-06, 753
[INFO] 2021-07-12 18:45:08,516 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 753
[INFO] 2021-07-12 18:45:08,516 [run_pretraining.py:  558]:	worker_index: 6, step: 753, cost: 8.298260, mlm loss: 8.298260, speed: 1.100410 steps/s, speed: 8.803278 samples/s, speed: 4507.278125 tokens/s, learning rate: 7.520e-06, loss_scalings: 13421.773438, pp_loss: 8.146701
[INFO] 2021-07-12 18:45:08,516 [run_pretraining.py:  512]:	********exe.run_753******* 
[INFO] 2021-07-12 18:45:09,413 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:09,413 [run_pretraining.py:  534]:	loss/total_loss, 8.131851196289062, 754
[INFO] 2021-07-12 18:45:09,413 [run_pretraining.py:  535]:	loss/mlm_loss, 8.131851196289062, 754
[INFO] 2021-07-12 18:45:09,414 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.529999948019395e-06, 754
[INFO] 2021-07-12 18:45:09,414 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 754
[INFO] 2021-07-12 18:45:09,414 [run_pretraining.py:  558]:	worker_index: 6, step: 754, cost: 8.131851, mlm loss: 8.131851, speed: 1.115099 steps/s, speed: 8.920791 samples/s, speed: 4567.445084 tokens/s, learning rate: 7.530e-06, loss_scalings: 13421.773438, pp_loss: 8.459763
[INFO] 2021-07-12 18:45:09,414 [run_pretraining.py:  512]:	********exe.run_754******* 
[INFO] 2021-07-12 18:45:10,315 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:10,315 [run_pretraining.py:  534]:	loss/total_loss, 8.395025253295898, 755
[INFO] 2021-07-12 18:45:10,315 [run_pretraining.py:  535]:	loss/mlm_loss, 8.395025253295898, 755
[INFO] 2021-07-12 18:45:10,315 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.539999842265388e-06, 755
[INFO] 2021-07-12 18:45:10,315 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 755
[INFO] 2021-07-12 18:45:10,316 [run_pretraining.py:  558]:	worker_index: 6, step: 755, cost: 8.395025, mlm loss: 8.395025, speed: 1.109797 steps/s, speed: 8.878377 samples/s, speed: 4545.729029 tokens/s, learning rate: 7.540e-06, loss_scalings: 13421.773438, pp_loss: 8.301001
[INFO] 2021-07-12 18:45:10,316 [run_pretraining.py:  512]:	********exe.run_755******* 
[INFO] 2021-07-12 18:45:11,219 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:11,219 [run_pretraining.py:  534]:	loss/total_loss, 8.269516944885254, 756
[INFO] 2021-07-12 18:45:11,220 [run_pretraining.py:  535]:	loss/mlm_loss, 8.269516944885254, 756
[INFO] 2021-07-12 18:45:11,220 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.5499992817640305e-06, 756
[INFO] 2021-07-12 18:45:11,220 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 756
[INFO] 2021-07-12 18:45:11,220 [run_pretraining.py:  558]:	worker_index: 6, step: 756, cost: 8.269517, mlm loss: 8.269517, speed: 1.106747 steps/s, speed: 8.853977 samples/s, speed: 4533.236472 tokens/s, learning rate: 7.550e-06, loss_scalings: 13421.773438, pp_loss: 8.367314
[INFO] 2021-07-12 18:45:11,220 [run_pretraining.py:  512]:	********exe.run_756******* 
[INFO] 2021-07-12 18:45:12,128 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:12,129 [run_pretraining.py:  534]:	loss/total_loss, 8.441686630249023, 757
[INFO] 2021-07-12 18:45:12,129 [run_pretraining.py:  535]:	loss/mlm_loss, 8.441686630249023, 757
[INFO] 2021-07-12 18:45:12,129 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.559999630757375e-06, 757
[INFO] 2021-07-12 18:45:12,129 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 757
[INFO] 2021-07-12 18:45:12,129 [run_pretraining.py:  558]:	worker_index: 6, step: 757, cost: 8.441687, mlm loss: 8.441687, speed: 1.100660 steps/s, speed: 8.805280 samples/s, speed: 4508.303604 tokens/s, learning rate: 7.560e-06, loss_scalings: 13421.773438, pp_loss: 8.171675
[INFO] 2021-07-12 18:45:12,129 [run_pretraining.py:  512]:	********exe.run_757******* 
[INFO] 2021-07-12 18:45:13,026 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:13,027 [run_pretraining.py:  534]:	loss/total_loss, 8.092341423034668, 758
[INFO] 2021-07-12 18:45:13,027 [run_pretraining.py:  535]:	loss/mlm_loss, 8.092341423034668, 758
[INFO] 2021-07-12 18:45:13,027 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.569999979750719e-06, 758
[INFO] 2021-07-12 18:45:13,027 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 758
[INFO] 2021-07-12 18:45:13,027 [run_pretraining.py:  558]:	worker_index: 6, step: 758, cost: 8.092341, mlm loss: 8.092341, speed: 1.114454 steps/s, speed: 8.915629 samples/s, speed: 4564.801864 tokens/s, learning rate: 7.570e-06, loss_scalings: 13421.773438, pp_loss: 8.369521
[INFO] 2021-07-12 18:45:13,027 [run_pretraining.py:  512]:	********exe.run_758******* 
[INFO] 2021-07-12 18:45:13,935 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:13,935 [run_pretraining.py:  534]:	loss/total_loss, 7.809598922729492, 759
[INFO] 2021-07-12 18:45:13,935 [run_pretraining.py:  535]:	loss/mlm_loss, 7.809598922729492, 759
[INFO] 2021-07-12 18:45:13,936 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.579999873996712e-06, 759
[INFO] 2021-07-12 18:45:13,936 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 759
[INFO] 2021-07-12 18:45:13,936 [run_pretraining.py:  558]:	worker_index: 6, step: 759, cost: 7.809599, mlm loss: 7.809599, speed: 1.101425 steps/s, speed: 8.811401 samples/s, speed: 4511.437338 tokens/s, learning rate: 7.580e-06, loss_scalings: 13421.773438, pp_loss: 8.186216
[INFO] 2021-07-12 18:45:13,936 [run_pretraining.py:  512]:	********exe.run_759******* 
[INFO] 2021-07-12 18:45:14,842 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:14,843 [run_pretraining.py:  534]:	loss/total_loss, 7.905064582824707, 760
[INFO] 2021-07-12 18:45:14,843 [run_pretraining.py:  535]:	loss/mlm_loss, 7.905064582824707, 760
[INFO] 2021-07-12 18:45:14,843 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.5900002229900565e-06, 760
[INFO] 2021-07-12 18:45:14,843 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 760
[INFO] 2021-07-12 18:45:14,843 [run_pretraining.py:  558]:	worker_index: 6, step: 760, cost: 7.905065, mlm loss: 7.905065, speed: 1.102856 steps/s, speed: 8.822844 samples/s, speed: 4517.296192 tokens/s, learning rate: 7.590e-06, loss_scalings: 13421.773438, pp_loss: 8.188133
[INFO] 2021-07-12 18:45:14,843 [run_pretraining.py:  512]:	********exe.run_760******* 
[INFO] 2021-07-12 18:45:15,745 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:15,745 [run_pretraining.py:  534]:	loss/total_loss, 8.798626899719238, 761
[INFO] 2021-07-12 18:45:15,745 [run_pretraining.py:  535]:	loss/mlm_loss, 8.798626899719238, 761
[INFO] 2021-07-12 18:45:15,745 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.599999662488699e-06, 761
[INFO] 2021-07-12 18:45:15,746 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 761
[INFO] 2021-07-12 18:45:15,746 [run_pretraining.py:  558]:	worker_index: 6, step: 761, cost: 8.798627, mlm loss: 8.798627, speed: 1.108899 steps/s, speed: 8.871194 samples/s, speed: 4542.051491 tokens/s, learning rate: 7.600e-06, loss_scalings: 13421.773438, pp_loss: 8.694044
[INFO] 2021-07-12 18:45:15,746 [run_pretraining.py:  512]:	********exe.run_761******* 
[INFO] 2021-07-12 18:45:16,650 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:16,650 [run_pretraining.py:  534]:	loss/total_loss, 8.312996864318848, 762
[INFO] 2021-07-12 18:45:16,651 [run_pretraining.py:  535]:	loss/mlm_loss, 8.312996864318848, 762
[INFO] 2021-07-12 18:45:16,651 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.609999556734692e-06, 762
[INFO] 2021-07-12 18:45:16,651 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 762
[INFO] 2021-07-12 18:45:16,651 [run_pretraining.py:  558]:	worker_index: 6, step: 762, cost: 8.312997, mlm loss: 8.312997, speed: 1.105592 steps/s, speed: 8.844733 samples/s, speed: 4528.503346 tokens/s, learning rate: 7.610e-06, loss_scalings: 13421.773438, pp_loss: 8.358200
[INFO] 2021-07-12 18:45:16,651 [run_pretraining.py:  512]:	********exe.run_762******* 
[INFO] 2021-07-12 18:45:17,549 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:17,550 [run_pretraining.py:  534]:	loss/total_loss, 7.8040080070495605, 763
[INFO] 2021-07-12 18:45:17,550 [run_pretraining.py:  535]:	loss/mlm_loss, 7.8040080070495605, 763
[INFO] 2021-07-12 18:45:17,550 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.6199999057280365e-06, 763
[INFO] 2021-07-12 18:45:17,550 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 763
[INFO] 2021-07-12 18:45:17,550 [run_pretraining.py:  558]:	worker_index: 6, step: 763, cost: 7.804008, mlm loss: 7.804008, speed: 1.113116 steps/s, speed: 8.904929 samples/s, speed: 4559.323725 tokens/s, learning rate: 7.620e-06, loss_scalings: 13421.773438, pp_loss: 7.453155
[INFO] 2021-07-12 18:45:17,550 [run_pretraining.py:  512]:	********exe.run_763******* 
[INFO] 2021-07-12 18:45:18,464 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:18,465 [run_pretraining.py:  534]:	loss/total_loss, 8.235705375671387, 764
[INFO] 2021-07-12 18:45:18,466 [run_pretraining.py:  535]:	loss/mlm_loss, 8.235705375671387, 764
[INFO] 2021-07-12 18:45:18,468 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.63000025472138e-06, 764
[INFO] 2021-07-12 18:45:18,468 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 764
[INFO] 2021-07-12 18:45:18,469 [run_pretraining.py:  558]:	worker_index: 6, step: 764, cost: 8.235705, mlm loss: 8.235705, speed: 1.093212 steps/s, speed: 8.745695 samples/s, speed: 4477.795694 tokens/s, learning rate: 7.630e-06, loss_scalings: 13421.773438, pp_loss: 8.310029
[INFO] 2021-07-12 18:45:18,469 [run_pretraining.py:  512]:	********exe.run_764******* 
[INFO] 2021-07-12 18:45:19,372 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:19,372 [run_pretraining.py:  534]:	loss/total_loss, 8.673786163330078, 765
[INFO] 2021-07-12 18:45:19,372 [run_pretraining.py:  535]:	loss/mlm_loss, 8.673786163330078, 765
[INFO] 2021-07-12 18:45:19,373 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.639999239472672e-06, 765
[INFO] 2021-07-12 18:45:19,373 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 765
[INFO] 2021-07-12 18:45:19,373 [run_pretraining.py:  558]:	worker_index: 6, step: 765, cost: 8.673786, mlm loss: 8.673786, speed: 1.107171 steps/s, speed: 8.857366 samples/s, speed: 4534.971598 tokens/s, learning rate: 7.640e-06, loss_scalings: 13421.773438, pp_loss: 8.273630
[INFO] 2021-07-12 18:45:19,373 [run_pretraining.py:  512]:	********exe.run_765******* 
[INFO] 2021-07-12 18:45:20,292 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:20,292 [run_pretraining.py:  534]:	loss/total_loss, 8.453441619873047, 766
[INFO] 2021-07-12 18:45:20,292 [run_pretraining.py:  535]:	loss/mlm_loss, 8.453441619873047, 766
[INFO] 2021-07-12 18:45:20,293 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.650000043213367e-06, 766
[INFO] 2021-07-12 18:45:20,293 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 766
[INFO] 2021-07-12 18:45:20,293 [run_pretraining.py:  558]:	worker_index: 6, step: 766, cost: 8.453442, mlm loss: 8.453442, speed: 1.087718 steps/s, speed: 8.701742 samples/s, speed: 4455.292096 tokens/s, learning rate: 7.650e-06, loss_scalings: 13421.773438, pp_loss: 8.674243
[INFO] 2021-07-12 18:45:20,293 [run_pretraining.py:  512]:	********exe.run_766******* 
[INFO] 2021-07-12 18:45:21,197 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:21,197 [run_pretraining.py:  534]:	loss/total_loss, 8.480427742004395, 767
[INFO] 2021-07-12 18:45:21,197 [run_pretraining.py:  535]:	loss/mlm_loss, 8.480427742004395, 767
[INFO] 2021-07-12 18:45:21,197 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.65999993745936e-06, 767
[INFO] 2021-07-12 18:45:21,198 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 767
[INFO] 2021-07-12 18:45:21,198 [run_pretraining.py:  558]:	worker_index: 6, step: 767, cost: 8.480428, mlm loss: 8.480428, speed: 1.105980 steps/s, speed: 8.847837 samples/s, speed: 4530.092697 tokens/s, learning rate: 7.660e-06, loss_scalings: 13421.773438, pp_loss: 8.005070
[INFO] 2021-07-12 18:45:21,198 [run_pretraining.py:  512]:	********exe.run_767******* 
[INFO] 2021-07-12 18:45:22,115 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:22,115 [run_pretraining.py:  534]:	loss/total_loss, 8.263384819030762, 768
[INFO] 2021-07-12 18:45:22,115 [run_pretraining.py:  535]:	loss/mlm_loss, 8.263384819030762, 768
[INFO] 2021-07-12 18:45:22,115 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.669999831705354e-06, 768
[INFO] 2021-07-12 18:45:22,116 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 768
[INFO] 2021-07-12 18:45:22,116 [run_pretraining.py:  558]:	worker_index: 6, step: 768, cost: 8.263385, mlm loss: 8.263385, speed: 1.090192 steps/s, speed: 8.721540 samples/s, speed: 4465.428324 tokens/s, learning rate: 7.670e-06, loss_scalings: 13421.773438, pp_loss: 8.233382
[INFO] 2021-07-12 18:45:22,116 [run_pretraining.py:  512]:	********exe.run_768******* 
[INFO] 2021-07-12 18:45:23,029 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:23,029 [run_pretraining.py:  534]:	loss/total_loss, 8.581724166870117, 769
[INFO] 2021-07-12 18:45:23,029 [run_pretraining.py:  535]:	loss/mlm_loss, 8.581724166870117, 769
[INFO] 2021-07-12 18:45:23,029 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.679999725951348e-06, 769
[INFO] 2021-07-12 18:45:23,030 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 769
[INFO] 2021-07-12 18:45:23,030 [run_pretraining.py:  558]:	worker_index: 6, step: 769, cost: 8.581724, mlm loss: 8.581724, speed: 1.094995 steps/s, speed: 8.759958 samples/s, speed: 4485.098469 tokens/s, learning rate: 7.680e-06, loss_scalings: 13421.773438, pp_loss: 8.477587
[INFO] 2021-07-12 18:45:23,030 [run_pretraining.py:  512]:	********exe.run_769******* 
[INFO] 2021-07-12 18:45:23,934 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:23,935 [run_pretraining.py:  534]:	loss/total_loss, 8.164682388305664, 770
[INFO] 2021-07-12 18:45:23,935 [run_pretraining.py:  535]:	loss/mlm_loss, 8.164682388305664, 770
[INFO] 2021-07-12 18:45:23,935 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.68999962019734e-06, 770
[INFO] 2021-07-12 18:45:23,935 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 770
[INFO] 2021-07-12 18:45:23,935 [run_pretraining.py:  558]:	worker_index: 6, step: 770, cost: 8.164682, mlm loss: 8.164682, speed: 1.104935 steps/s, speed: 8.839484 samples/s, speed: 4525.815571 tokens/s, learning rate: 7.690e-06, loss_scalings: 13421.773438, pp_loss: 8.245659
[INFO] 2021-07-12 18:45:23,935 [run_pretraining.py:  512]:	********exe.run_770******* 
[INFO] 2021-07-12 18:45:24,854 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:24,855 [run_pretraining.py:  534]:	loss/total_loss, 8.377389907836914, 771
[INFO] 2021-07-12 18:45:24,855 [run_pretraining.py:  535]:	loss/mlm_loss, 8.377389907836914, 771
[INFO] 2021-07-12 18:45:24,855 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.699999514443334e-06, 771
[INFO] 2021-07-12 18:45:24,855 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 771
[INFO] 2021-07-12 18:45:24,855 [run_pretraining.py:  558]:	worker_index: 6, step: 771, cost: 8.377390, mlm loss: 8.377390, speed: 1.087894 steps/s, speed: 8.703148 samples/s, speed: 4456.012027 tokens/s, learning rate: 7.700e-06, loss_scalings: 13421.773438, pp_loss: 8.383852
[INFO] 2021-07-12 18:45:24,855 [run_pretraining.py:  512]:	********exe.run_771******* 
[INFO] 2021-07-12 18:45:25,786 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:25,787 [run_pretraining.py:  534]:	loss/total_loss, 7.982547760009766, 772
[INFO] 2021-07-12 18:45:25,787 [run_pretraining.py:  535]:	loss/mlm_loss, 7.982547760009766, 772
[INFO] 2021-07-12 18:45:25,787 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.71000031818403e-06, 772
[INFO] 2021-07-12 18:45:25,787 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 772
[INFO] 2021-07-12 18:45:25,787 [run_pretraining.py:  558]:	worker_index: 6, step: 772, cost: 7.982548, mlm loss: 7.982548, speed: 1.073874 steps/s, speed: 8.590992 samples/s, speed: 4398.588136 tokens/s, learning rate: 7.710e-06, loss_scalings: 13421.773438, pp_loss: 8.195219
[INFO] 2021-07-12 18:45:25,787 [run_pretraining.py:  512]:	********exe.run_772******* 
[INFO] 2021-07-12 18:45:26,843 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:26,843 [run_pretraining.py:  534]:	loss/total_loss, 8.064165115356445, 773
[INFO] 2021-07-12 18:45:26,843 [run_pretraining.py:  535]:	loss/mlm_loss, 8.064165115356445, 773
[INFO] 2021-07-12 18:45:26,843 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.720000212430023e-06, 773
[INFO] 2021-07-12 18:45:26,843 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 773
[INFO] 2021-07-12 18:45:26,844 [run_pretraining.py:  558]:	worker_index: 6, step: 773, cost: 8.064165, mlm loss: 8.064165, speed: 0.947297 steps/s, speed: 7.578377 samples/s, speed: 3880.129112 tokens/s, learning rate: 7.720e-06, loss_scalings: 13421.773438, pp_loss: 8.361969
[INFO] 2021-07-12 18:45:26,844 [run_pretraining.py:  512]:	********exe.run_773******* 
[INFO] 2021-07-12 18:45:27,902 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:27,903 [run_pretraining.py:  534]:	loss/total_loss, 7.653800964355469, 774
[INFO] 2021-07-12 18:45:27,903 [run_pretraining.py:  535]:	loss/mlm_loss, 7.653800964355469, 774
[INFO] 2021-07-12 18:45:27,903 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.729999197181314e-06, 774
[INFO] 2021-07-12 18:45:27,903 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 774
[INFO] 2021-07-12 18:45:27,903 [run_pretraining.py:  558]:	worker_index: 6, step: 774, cost: 7.653801, mlm loss: 7.653801, speed: 0.944110 steps/s, speed: 7.552883 samples/s, speed: 3867.076273 tokens/s, learning rate: 7.730e-06, loss_scalings: 13421.773438, pp_loss: 7.283058
[INFO] 2021-07-12 18:45:27,904 [run_pretraining.py:  512]:	********exe.run_774******* 
[INFO] 2021-07-12 18:45:28,964 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:28,964 [run_pretraining.py:  534]:	loss/total_loss, 8.743819236755371, 775
[INFO] 2021-07-12 18:45:28,964 [run_pretraining.py:  535]:	loss/mlm_loss, 8.743819236755371, 775
[INFO] 2021-07-12 18:45:28,965 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.74000000092201e-06, 775
[INFO] 2021-07-12 18:45:28,965 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 775
[INFO] 2021-07-12 18:45:28,965 [run_pretraining.py:  558]:	worker_index: 6, step: 775, cost: 8.743819, mlm loss: 8.743819, speed: 0.942872 steps/s, speed: 7.542980 samples/s, speed: 3862.005575 tokens/s, learning rate: 7.740e-06, loss_scalings: 13421.773438, pp_loss: 7.328633
[INFO] 2021-07-12 18:45:28,965 [run_pretraining.py:  512]:	********exe.run_775******* 
[INFO] 2021-07-12 18:45:30,034 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:30,034 [run_pretraining.py:  534]:	loss/total_loss, 7.928001880645752, 776
[INFO] 2021-07-12 18:45:30,034 [run_pretraining.py:  535]:	loss/mlm_loss, 7.928001880645752, 776
[INFO] 2021-07-12 18:45:30,034 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.749999895168003e-06, 776
[INFO] 2021-07-12 18:45:30,035 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 776
[INFO] 2021-07-12 18:45:30,035 [run_pretraining.py:  558]:	worker_index: 6, step: 776, cost: 7.928002, mlm loss: 7.928002, speed: 0.935333 steps/s, speed: 7.482663 samples/s, speed: 3831.123586 tokens/s, learning rate: 7.750e-06, loss_scalings: 13421.773438, pp_loss: 8.219688
[INFO] 2021-07-12 18:45:30,035 [run_pretraining.py:  512]:	********exe.run_776******* 
[INFO] 2021-07-12 18:45:31,110 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:31,111 [run_pretraining.py:  534]:	loss/total_loss, 8.386589050292969, 777
[INFO] 2021-07-12 18:45:31,111 [run_pretraining.py:  535]:	loss/mlm_loss, 8.386589050292969, 777
[INFO] 2021-07-12 18:45:31,111 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.759999789413996e-06, 777
[INFO] 2021-07-12 18:45:31,111 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 777
[INFO] 2021-07-12 18:45:31,111 [run_pretraining.py:  558]:	worker_index: 6, step: 777, cost: 8.386589, mlm loss: 8.386589, speed: 0.929502 steps/s, speed: 7.436017 samples/s, speed: 3807.240723 tokens/s, learning rate: 7.760e-06, loss_scalings: 13421.773438, pp_loss: 8.314727
[INFO] 2021-07-12 18:45:31,111 [run_pretraining.py:  512]:	********exe.run_777******* 
[INFO] 2021-07-12 18:45:32,173 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:32,173 [run_pretraining.py:  534]:	loss/total_loss, 8.717910766601562, 778
[INFO] 2021-07-12 18:45:32,173 [run_pretraining.py:  535]:	loss/mlm_loss, 8.717910766601562, 778
[INFO] 2021-07-12 18:45:32,173 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.76999968365999e-06, 778
[INFO] 2021-07-12 18:45:32,174 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 778
[INFO] 2021-07-12 18:45:32,174 [run_pretraining.py:  558]:	worker_index: 6, step: 778, cost: 8.717911, mlm loss: 8.717911, speed: 0.941831 steps/s, speed: 7.534646 samples/s, speed: 3857.738886 tokens/s, learning rate: 7.770e-06, loss_scalings: 13421.773438, pp_loss: 8.270824
[INFO] 2021-07-12 18:45:32,174 [run_pretraining.py:  512]:	********exe.run_778******* 
[INFO] 2021-07-12 18:45:33,235 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:33,236 [run_pretraining.py:  534]:	loss/total_loss, 8.341099739074707, 779
[INFO] 2021-07-12 18:45:33,236 [run_pretraining.py:  535]:	loss/mlm_loss, 8.341099739074707, 779
[INFO] 2021-07-12 18:45:33,236 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.779999577905983e-06, 779
[INFO] 2021-07-12 18:45:33,236 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 779
[INFO] 2021-07-12 18:45:33,236 [run_pretraining.py:  558]:	worker_index: 6, step: 779, cost: 8.341100, mlm loss: 8.341100, speed: 0.941817 steps/s, speed: 7.534536 samples/s, speed: 3857.682580 tokens/s, learning rate: 7.780e-06, loss_scalings: 13421.773438, pp_loss: 8.256398
[INFO] 2021-07-12 18:45:33,236 [run_pretraining.py:  512]:	********exe.run_779******* 
[INFO] 2021-07-12 18:45:34,296 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:34,296 [run_pretraining.py:  534]:	loss/total_loss, 7.901945114135742, 780
[INFO] 2021-07-12 18:45:34,296 [run_pretraining.py:  535]:	loss/mlm_loss, 7.901945114135742, 780
[INFO] 2021-07-12 18:45:34,297 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.789999472151976e-06, 780
[INFO] 2021-07-12 18:45:34,297 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 780
[INFO] 2021-07-12 18:45:34,297 [run_pretraining.py:  558]:	worker_index: 6, step: 780, cost: 7.901945, mlm loss: 7.901945, speed: 0.943456 steps/s, speed: 7.547647 samples/s, speed: 3864.395395 tokens/s, learning rate: 7.790e-06, loss_scalings: 13421.773438, pp_loss: 8.201193
[INFO] 2021-07-12 18:45:34,297 [run_pretraining.py:  512]:	********exe.run_780******* 
[INFO] 2021-07-12 18:45:35,370 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:35,370 [run_pretraining.py:  534]:	loss/total_loss, 8.11270523071289, 781
[INFO] 2021-07-12 18:45:35,370 [run_pretraining.py:  535]:	loss/mlm_loss, 8.11270523071289, 781
[INFO] 2021-07-12 18:45:35,370 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.800000275892671e-06, 781
[INFO] 2021-07-12 18:45:35,371 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 781
[INFO] 2021-07-12 18:45:35,371 [run_pretraining.py:  558]:	worker_index: 6, step: 781, cost: 8.112705, mlm loss: 8.112705, speed: 0.931822 steps/s, speed: 7.454577 samples/s, speed: 3816.743632 tokens/s, learning rate: 7.800e-06, loss_scalings: 13421.773438, pp_loss: 8.124198
[INFO] 2021-07-12 18:45:35,371 [run_pretraining.py:  512]:	********exe.run_781******* 
[INFO] 2021-07-12 18:45:36,429 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:36,430 [run_pretraining.py:  534]:	loss/total_loss, 8.213422775268555, 782
[INFO] 2021-07-12 18:45:36,430 [run_pretraining.py:  535]:	loss/mlm_loss, 8.213422775268555, 782
[INFO] 2021-07-12 18:45:36,430 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.810000170138665e-06, 782
[INFO] 2021-07-12 18:45:36,430 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 782
[INFO] 2021-07-12 18:45:36,430 [run_pretraining.py:  558]:	worker_index: 6, step: 782, cost: 8.213423, mlm loss: 8.213423, speed: 0.944489 steps/s, speed: 7.555914 samples/s, speed: 3868.628044 tokens/s, learning rate: 7.810e-06, loss_scalings: 13421.773438, pp_loss: 8.411924
[INFO] 2021-07-12 18:45:36,430 [run_pretraining.py:  512]:	********exe.run_782******* 
[INFO] 2021-07-12 18:45:37,487 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:37,487 [run_pretraining.py:  534]:	loss/total_loss, 8.149890899658203, 783
[INFO] 2021-07-12 18:45:37,488 [run_pretraining.py:  535]:	loss/mlm_loss, 8.149890899658203, 783
[INFO] 2021-07-12 18:45:37,488 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.819999154889956e-06, 783
[INFO] 2021-07-12 18:45:37,488 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 783
[INFO] 2021-07-12 18:45:37,488 [run_pretraining.py:  558]:	worker_index: 6, step: 783, cost: 8.149891, mlm loss: 8.149891, speed: 0.946091 steps/s, speed: 7.568724 samples/s, speed: 3875.186725 tokens/s, learning rate: 7.820e-06, loss_scalings: 13421.773438, pp_loss: 8.174843
[INFO] 2021-07-12 18:45:37,488 [run_pretraining.py:  512]:	********exe.run_783******* 
[INFO] 2021-07-12 18:45:38,551 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:38,552 [run_pretraining.py:  534]:	loss/total_loss, 8.145041465759277, 784
[INFO] 2021-07-12 18:45:38,552 [run_pretraining.py:  535]:	loss/mlm_loss, 8.145041465759277, 784
[INFO] 2021-07-12 18:45:38,552 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.829999958630651e-06, 784
[INFO] 2021-07-12 18:45:38,552 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 784
[INFO] 2021-07-12 18:45:38,552 [run_pretraining.py:  558]:	worker_index: 6, step: 784, cost: 8.145041, mlm loss: 8.145041, speed: 0.940154 steps/s, speed: 7.521230 samples/s, speed: 3850.869609 tokens/s, learning rate: 7.830e-06, loss_scalings: 13421.773438, pp_loss: 7.848843
[INFO] 2021-07-12 18:45:38,552 [run_pretraining.py:  512]:	********exe.run_784******* 
[INFO] 2021-07-12 18:45:39,617 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:39,617 [run_pretraining.py:  534]:	loss/total_loss, 7.938283920288086, 785
[INFO] 2021-07-12 18:45:39,617 [run_pretraining.py:  535]:	loss/mlm_loss, 7.938283920288086, 785
[INFO] 2021-07-12 18:45:39,617 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.839999852876645e-06, 785
[INFO] 2021-07-12 18:45:39,617 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 785
[INFO] 2021-07-12 18:45:39,618 [run_pretraining.py:  558]:	worker_index: 6, step: 785, cost: 7.938284, mlm loss: 7.938284, speed: 0.939250 steps/s, speed: 7.514001 samples/s, speed: 3847.168432 tokens/s, learning rate: 7.840e-06, loss_scalings: 13421.773438, pp_loss: 8.226815
[INFO] 2021-07-12 18:45:39,618 [run_pretraining.py:  512]:	********exe.run_785******* 
[INFO] 2021-07-12 18:45:40,629 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:40,630 [run_pretraining.py:  534]:	loss/total_loss, 8.211454391479492, 786
[INFO] 2021-07-12 18:45:40,630 [run_pretraining.py:  535]:	loss/mlm_loss, 8.211454391479492, 786
[INFO] 2021-07-12 18:45:40,630 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.849999747122638e-06, 786
[INFO] 2021-07-12 18:45:40,630 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 786
[INFO] 2021-07-12 18:45:40,630 [run_pretraining.py:  558]:	worker_index: 6, step: 786, cost: 8.211454, mlm loss: 8.211454, speed: 0.988128 steps/s, speed: 7.905022 samples/s, speed: 4047.371376 tokens/s, learning rate: 7.850e-06, loss_scalings: 13421.773438, pp_loss: 8.427023
[INFO] 2021-07-12 18:45:40,630 [run_pretraining.py:  512]:	********exe.run_786******* 
[INFO] 2021-07-12 18:45:41,550 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:41,550 [run_pretraining.py:  534]:	loss/total_loss, 8.707185745239258, 787
[INFO] 2021-07-12 18:45:41,550 [run_pretraining.py:  535]:	loss/mlm_loss, 8.707185745239258, 787
[INFO] 2021-07-12 18:45:41,550 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.859999641368631e-06, 787
[INFO] 2021-07-12 18:45:41,551 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 787
[INFO] 2021-07-12 18:45:41,551 [run_pretraining.py:  558]:	worker_index: 6, step: 787, cost: 8.707186, mlm loss: 8.707186, speed: 1.087430 steps/s, speed: 8.699437 samples/s, speed: 4454.111590 tokens/s, learning rate: 7.860e-06, loss_scalings: 13421.773438, pp_loss: 8.413454
[INFO] 2021-07-12 18:45:41,551 [run_pretraining.py:  512]:	********exe.run_787******* 
[INFO] 2021-07-12 18:45:42,464 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:42,465 [run_pretraining.py:  534]:	loss/total_loss, 8.22723388671875, 788
[INFO] 2021-07-12 18:45:42,465 [run_pretraining.py:  535]:	loss/mlm_loss, 8.22723388671875, 788
[INFO] 2021-07-12 18:45:42,465 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.869999535614625e-06, 788
[INFO] 2021-07-12 18:45:42,465 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 788
[INFO] 2021-07-12 18:45:42,465 [run_pretraining.py:  558]:	worker_index: 6, step: 788, cost: 8.227234, mlm loss: 8.227234, speed: 1.094254 steps/s, speed: 8.754032 samples/s, speed: 4482.064349 tokens/s, learning rate: 7.870e-06, loss_scalings: 13421.773438, pp_loss: 8.134215
[INFO] 2021-07-12 18:45:42,465 [run_pretraining.py:  512]:	********exe.run_788******* 
[INFO] 2021-07-12 18:45:43,379 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:43,379 [run_pretraining.py:  534]:	loss/total_loss, 8.294106483459473, 789
[INFO] 2021-07-12 18:45:43,379 [run_pretraining.py:  535]:	loss/mlm_loss, 8.294106483459473, 789
[INFO] 2021-07-12 18:45:43,379 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.879999429860618e-06, 789
[INFO] 2021-07-12 18:45:43,379 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 789
[INFO] 2021-07-12 18:45:43,380 [run_pretraining.py:  558]:	worker_index: 6, step: 789, cost: 8.294106, mlm loss: 8.294106, speed: 1.094559 steps/s, speed: 8.756472 samples/s, speed: 4483.313539 tokens/s, learning rate: 7.880e-06, loss_scalings: 13421.773438, pp_loss: 8.272898
[INFO] 2021-07-12 18:45:43,380 [run_pretraining.py:  512]:	********exe.run_789******* 
[INFO] 2021-07-12 18:46:08,283 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:08,284 [run_pretraining.py:  534]:	loss/total_loss, 8.711544036865234, 790
[INFO] 2021-07-12 18:46:08,284 [run_pretraining.py:  535]:	loss/mlm_loss, 8.711544036865234, 790
[INFO] 2021-07-12 18:46:08,284 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.890000233601313e-06, 790
[INFO] 2021-07-12 18:46:08,284 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 790
[INFO] 2021-07-12 18:46:08,284 [run_pretraining.py:  558]:	worker_index: 6, step: 790, cost: 8.711544, mlm loss: 8.711544, speed: 0.040154 steps/s, speed: 0.321234 samples/s, speed: 164.471561 tokens/s, learning rate: 7.890e-06, loss_scalings: 13421.773438, pp_loss: 8.361979
[INFO] 2021-07-12 18:46:08,284 [run_pretraining.py:  512]:	********exe.run_790******* 
[INFO] 2021-07-12 18:46:09,196 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:09,196 [run_pretraining.py:  534]:	loss/total_loss, 8.052999496459961, 791
[INFO] 2021-07-12 18:46:09,197 [run_pretraining.py:  535]:	loss/mlm_loss, 8.052999496459961, 791
[INFO] 2021-07-12 18:46:09,197 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.900000127847306e-06, 791
[INFO] 2021-07-12 18:46:09,197 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 791
[INFO] 2021-07-12 18:46:09,197 [run_pretraining.py:  558]:	worker_index: 6, step: 791, cost: 8.052999, mlm loss: 8.052999, speed: 1.096763 steps/s, speed: 8.774105 samples/s, speed: 4492.341698 tokens/s, learning rate: 7.900e-06, loss_scalings: 13421.773438, pp_loss: 7.656172
[INFO] 2021-07-12 18:46:09,197 [run_pretraining.py:  512]:	********exe.run_791******* 
[INFO] 2021-07-12 18:46:10,122 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:10,122 [run_pretraining.py:  534]:	loss/total_loss, 7.871002674102783, 792
[INFO] 2021-07-12 18:46:10,122 [run_pretraining.py:  535]:	loss/mlm_loss, 7.871002674102783, 792
[INFO] 2021-07-12 18:46:10,122 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.9100000220933e-06, 792
[INFO] 2021-07-12 18:46:10,122 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 792
[INFO] 2021-07-12 18:46:10,123 [run_pretraining.py:  558]:	worker_index: 6, step: 792, cost: 7.871003, mlm loss: 7.871003, speed: 1.081115 steps/s, speed: 8.648919 samples/s, speed: 4428.246443 tokens/s, learning rate: 7.910e-06, loss_scalings: 13421.773438, pp_loss: 8.265526
[INFO] 2021-07-12 18:46:10,123 [run_pretraining.py:  512]:	********exe.run_792******* 
[INFO] 2021-07-12 18:46:11,037 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:11,038 [run_pretraining.py:  534]:	loss/total_loss, 8.031235694885254, 793
[INFO] 2021-07-12 18:46:11,038 [run_pretraining.py:  535]:	loss/mlm_loss, 8.031235694885254, 793
[INFO] 2021-07-12 18:46:11,038 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.919999916339293e-06, 793
[INFO] 2021-07-12 18:46:11,038 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 793
[INFO] 2021-07-12 18:46:11,038 [run_pretraining.py:  558]:	worker_index: 6, step: 793, cost: 8.031236, mlm loss: 8.031236, speed: 1.092593 steps/s, speed: 8.740744 samples/s, speed: 4475.261018 tokens/s, learning rate: 7.920e-06, loss_scalings: 13421.773438, pp_loss: 8.131829
[INFO] 2021-07-12 18:46:11,039 [run_pretraining.py:  512]:	********exe.run_793******* 
[INFO] 2021-07-12 18:46:36,790 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:36,790 [run_pretraining.py:  534]:	loss/total_loss, 8.397080421447754, 794
[INFO] 2021-07-12 18:46:36,791 [run_pretraining.py:  535]:	loss/mlm_loss, 8.397080421447754, 794
[INFO] 2021-07-12 18:46:36,791 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.929999810585286e-06, 794
[INFO] 2021-07-12 18:46:36,791 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 794
[INFO] 2021-07-12 18:46:36,791 [run_pretraining.py:  558]:	worker_index: 6, step: 794, cost: 8.397080, mlm loss: 8.397080, speed: 0.038833 steps/s, speed: 0.310660 samples/s, speed: 159.057926 tokens/s, learning rate: 7.930e-06, loss_scalings: 13421.773438, pp_loss: 8.389555
[INFO] 2021-07-12 18:46:36,791 [run_pretraining.py:  512]:	********exe.run_794******* 
[INFO] 2021-07-12 18:46:37,702 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:37,703 [run_pretraining.py:  534]:	loss/total_loss, 8.378559112548828, 795
[INFO] 2021-07-12 18:46:37,703 [run_pretraining.py:  535]:	loss/mlm_loss, 8.378559112548828, 795
[INFO] 2021-07-12 18:46:37,703 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.93999970483128e-06, 795
[INFO] 2021-07-12 18:46:37,703 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 795
[INFO] 2021-07-12 18:46:37,703 [run_pretraining.py:  558]:	worker_index: 6, step: 795, cost: 8.378559, mlm loss: 8.378559, speed: 1.096705 steps/s, speed: 8.773639 samples/s, speed: 4492.103247 tokens/s, learning rate: 7.940e-06, loss_scalings: 13421.773438, pp_loss: 8.106182
[INFO] 2021-07-12 18:46:37,703 [run_pretraining.py:  512]:	********exe.run_795******* 
[INFO] 2021-07-12 18:46:38,656 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:38,657 [run_pretraining.py:  534]:	loss/total_loss, 7.746973514556885, 796
[INFO] 2021-07-12 18:46:38,657 [run_pretraining.py:  535]:	loss/mlm_loss, 7.746973514556885, 796
[INFO] 2021-07-12 18:46:38,657 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.949999599077273e-06, 796
[INFO] 2021-07-12 18:46:38,657 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 796
[INFO] 2021-07-12 18:46:38,657 [run_pretraining.py:  558]:	worker_index: 6, step: 796, cost: 7.746974, mlm loss: 7.746974, speed: 1.049429 steps/s, speed: 8.395429 samples/s, speed: 4298.459795 tokens/s, learning rate: 7.950e-06, loss_scalings: 13421.773438, pp_loss: 7.755014
[INFO] 2021-07-12 18:46:38,657 [run_pretraining.py:  512]:	********exe.run_796******* 
[INFO] 2021-07-12 18:46:39,733 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:39,733 [run_pretraining.py:  534]:	loss/total_loss, 8.094099998474121, 797
[INFO] 2021-07-12 18:46:39,733 [run_pretraining.py:  535]:	loss/mlm_loss, 8.094099998474121, 797
[INFO] 2021-07-12 18:46:39,734 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.959999493323267e-06, 797
[INFO] 2021-07-12 18:46:39,734 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 797
[INFO] 2021-07-12 18:46:39,734 [run_pretraining.py:  558]:	worker_index: 6, step: 797, cost: 8.094100, mlm loss: 8.094100, speed: 0.929270 steps/s, speed: 7.434162 samples/s, speed: 3806.290926 tokens/s, learning rate: 7.960e-06, loss_scalings: 13421.773438, pp_loss: 8.292089
[INFO] 2021-07-12 18:46:39,734 [run_pretraining.py:  512]:	********exe.run_797******* 
[INFO] 2021-07-12 18:46:40,797 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:40,798 [run_pretraining.py:  534]:	loss/total_loss, 8.385648727416992, 798
[INFO] 2021-07-12 18:46:40,798 [run_pretraining.py:  535]:	loss/mlm_loss, 8.385648727416992, 798
[INFO] 2021-07-12 18:46:40,798 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.970000297063962e-06, 798
[INFO] 2021-07-12 18:46:40,798 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 798
[INFO] 2021-07-12 18:46:40,798 [run_pretraining.py:  558]:	worker_index: 6, step: 798, cost: 8.385649, mlm loss: 8.385649, speed: 0.940180 steps/s, speed: 7.521440 samples/s, speed: 3850.977509 tokens/s, learning rate: 7.970e-06, loss_scalings: 13421.773438, pp_loss: 8.281319
[INFO] 2021-07-12 18:46:40,798 [run_pretraining.py:  512]:	********exe.run_798******* 
[INFO] 2021-07-12 18:46:41,867 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:41,868 [run_pretraining.py:  534]:	loss/total_loss, 8.406026840209961, 799
[INFO] 2021-07-12 18:46:41,868 [run_pretraining.py:  535]:	loss/mlm_loss, 8.406026840209961, 799
[INFO] 2021-07-12 18:46:41,868 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.980000191309955e-06, 799
[INFO] 2021-07-12 18:46:41,868 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 799
[INFO] 2021-07-12 18:46:41,868 [run_pretraining.py:  558]:	worker_index: 6, step: 799, cost: 8.406027, mlm loss: 8.406027, speed: 0.935148 steps/s, speed: 7.481182 samples/s, speed: 3830.365079 tokens/s, learning rate: 7.980e-06, loss_scalings: 13421.773438, pp_loss: 8.378969
[INFO] 2021-07-12 18:46:41,868 [run_pretraining.py:  512]:	********exe.run_799******* 
[INFO] 2021-07-12 18:46:42,801 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:42,802 [run_pretraining.py:  534]:	loss/total_loss, 8.427278518676758, 800
[INFO] 2021-07-12 18:46:42,802 [run_pretraining.py:  535]:	loss/mlm_loss, 8.427278518676758, 800
[INFO] 2021-07-12 18:46:42,802 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.989999176061247e-06, 800
[INFO] 2021-07-12 18:46:42,802 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 800
[INFO] 2021-07-12 18:46:42,802 [run_pretraining.py:  558]:	worker_index: 6, step: 800, cost: 8.427279, mlm loss: 8.427279, speed: 1.071280 steps/s, speed: 8.570237 samples/s, speed: 4387.961361 tokens/s, learning rate: 7.990e-06, loss_scalings: 13421.773438, pp_loss: 8.466053
[INFO] 2021-07-12 18:46:42,802 [run_pretraining.py:  512]:	********exe.run_800******* 
[INFO] 2021-07-12 18:46:43,718 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:43,718 [run_pretraining.py:  534]:	loss/total_loss, 8.880908966064453, 801
[INFO] 2021-07-12 18:46:43,718 [run_pretraining.py:  535]:	loss/mlm_loss, 8.880908966064453, 801
[INFO] 2021-07-12 18:46:43,718 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.999999979801942e-06, 801
[INFO] 2021-07-12 18:46:43,719 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 801
[INFO] 2021-07-12 18:46:43,719 [run_pretraining.py:  558]:	worker_index: 6, step: 801, cost: 8.880909, mlm loss: 8.880909, speed: 1.092124 steps/s, speed: 8.736991 samples/s, speed: 4473.339471 tokens/s, learning rate: 8.000e-06, loss_scalings: 13421.773438, pp_loss: 8.617716
[INFO] 2021-07-12 18:46:43,719 [run_pretraining.py:  512]:	********exe.run_801******* 
[INFO] 2021-07-12 18:46:44,633 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:44,634 [run_pretraining.py:  534]:	loss/total_loss, 8.763825416564941, 802
[INFO] 2021-07-12 18:46:44,634 [run_pretraining.py:  535]:	loss/mlm_loss, 8.763825416564941, 802
[INFO] 2021-07-12 18:46:44,634 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.009999874047935e-06, 802
[INFO] 2021-07-12 18:46:44,634 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 802
[INFO] 2021-07-12 18:46:44,634 [run_pretraining.py:  558]:	worker_index: 6, step: 802, cost: 8.763825, mlm loss: 8.763825, speed: 1.093433 steps/s, speed: 8.747464 samples/s, speed: 4478.701548 tokens/s, learning rate: 8.010e-06, loss_scalings: 13421.773438, pp_loss: 8.380549
[INFO] 2021-07-12 18:46:44,634 [run_pretraining.py:  512]:	********exe.run_802******* 
[INFO] 2021-07-12 18:46:45,561 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:45,561 [run_pretraining.py:  534]:	loss/total_loss, 8.495060920715332, 803
[INFO] 2021-07-12 18:46:45,561 [run_pretraining.py:  535]:	loss/mlm_loss, 8.495060920715332, 803
[INFO] 2021-07-12 18:46:45,562 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.019999768293928e-06, 803
[INFO] 2021-07-12 18:46:45,562 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 803
[INFO] 2021-07-12 18:46:45,562 [run_pretraining.py:  558]:	worker_index: 6, step: 803, cost: 8.495061, mlm loss: 8.495061, speed: 1.078644 steps/s, speed: 8.629152 samples/s, speed: 4418.125868 tokens/s, learning rate: 8.020e-06, loss_scalings: 13421.773438, pp_loss: 8.313050
[INFO] 2021-07-12 18:46:45,562 [run_pretraining.py:  512]:	********exe.run_803******* 
[INFO] 2021-07-12 18:46:46,483 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:46,484 [run_pretraining.py:  534]:	loss/total_loss, 8.273900032043457, 804
[INFO] 2021-07-12 18:46:46,484 [run_pretraining.py:  535]:	loss/mlm_loss, 8.273900032043457, 804
[INFO] 2021-07-12 18:46:46,484 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.030000572034623e-06, 804
[INFO] 2021-07-12 18:46:46,484 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 804
[INFO] 2021-07-12 18:46:46,484 [run_pretraining.py:  558]:	worker_index: 6, step: 804, cost: 8.273900, mlm loss: 8.273900, speed: 1.084871 steps/s, speed: 8.678969 samples/s, speed: 4443.632349 tokens/s, learning rate: 8.030e-06, loss_scalings: 13421.773438, pp_loss: 8.200359
[INFO] 2021-07-12 18:46:46,484 [run_pretraining.py:  512]:	********exe.run_804******* 
[INFO] 2021-07-12 18:46:47,395 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:47,396 [run_pretraining.py:  534]:	loss/total_loss, 8.599664688110352, 805
[INFO] 2021-07-12 18:46:47,396 [run_pretraining.py:  535]:	loss/mlm_loss, 8.599664688110352, 805
[INFO] 2021-07-12 18:46:47,396 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.039999556785915e-06, 805
[INFO] 2021-07-12 18:46:47,396 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 805
[INFO] 2021-07-12 18:46:47,396 [run_pretraining.py:  558]:	worker_index: 6, step: 805, cost: 8.599665, mlm loss: 8.599665, speed: 1.097100 steps/s, speed: 8.776802 samples/s, speed: 4493.722390 tokens/s, learning rate: 8.040e-06, loss_scalings: 13421.773438, pp_loss: 8.653210
[INFO] 2021-07-12 18:46:47,396 [run_pretraining.py:  512]:	********exe.run_805******* 
[INFO] 2021-07-12 18:46:48,388 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:48,389 [run_pretraining.py:  534]:	loss/total_loss, 8.270025253295898, 806
[INFO] 2021-07-12 18:46:48,389 [run_pretraining.py:  535]:	loss/mlm_loss, 8.270025253295898, 806
[INFO] 2021-07-12 18:46:48,389 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.049999451031908e-06, 806
[INFO] 2021-07-12 18:46:48,389 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 806
[INFO] 2021-07-12 18:46:48,389 [run_pretraining.py:  558]:	worker_index: 6, step: 806, cost: 8.270025, mlm loss: 8.270025, speed: 1.008179 steps/s, speed: 8.065430 samples/s, speed: 4129.500284 tokens/s, learning rate: 8.050e-06, loss_scalings: 13421.773438, pp_loss: 8.220221
[INFO] 2021-07-12 18:46:48,389 [run_pretraining.py:  512]:	********exe.run_806******* 
[INFO] 2021-07-12 18:46:49,446 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:49,447 [run_pretraining.py:  534]:	loss/total_loss, 7.885533809661865, 807
[INFO] 2021-07-12 18:46:49,447 [run_pretraining.py:  535]:	loss/mlm_loss, 7.885533809661865, 807
[INFO] 2021-07-12 18:46:49,447 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.060000254772604e-06, 807
[INFO] 2021-07-12 18:46:49,447 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 807
[INFO] 2021-07-12 18:46:49,447 [run_pretraining.py:  558]:	worker_index: 6, step: 807, cost: 7.885534, mlm loss: 7.885534, speed: 0.945920 steps/s, speed: 7.567359 samples/s, speed: 3874.487564 tokens/s, learning rate: 8.060e-06, loss_scalings: 13421.773438, pp_loss: 8.156755
[INFO] 2021-07-12 18:46:49,447 [run_pretraining.py:  512]:	********exe.run_807******* 
[INFO] 2021-07-12 18:46:50,516 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:50,517 [run_pretraining.py:  534]:	loss/total_loss, 8.067621231079102, 808
[INFO] 2021-07-12 18:46:50,517 [run_pretraining.py:  535]:	loss/mlm_loss, 8.067621231079102, 808
[INFO] 2021-07-12 18:46:50,517 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.070000149018597e-06, 808
[INFO] 2021-07-12 18:46:50,517 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 808
[INFO] 2021-07-12 18:46:50,517 [run_pretraining.py:  558]:	worker_index: 6, step: 808, cost: 8.067621, mlm loss: 8.067621, speed: 0.935025 steps/s, speed: 7.480198 samples/s, speed: 3829.861282 tokens/s, learning rate: 8.070e-06, loss_scalings: 13421.773438, pp_loss: 8.121945
[INFO] 2021-07-12 18:46:50,517 [run_pretraining.py:  512]:	********exe.run_808******* 
[INFO] 2021-07-12 18:47:16,734 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:16,735 [run_pretraining.py:  534]:	loss/total_loss, 8.468457221984863, 809
[INFO] 2021-07-12 18:47:16,735 [run_pretraining.py:  535]:	loss/mlm_loss, 8.468457221984863, 809
[INFO] 2021-07-12 18:47:16,735 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.079999133769888e-06, 809
[INFO] 2021-07-12 18:47:16,735 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 809
[INFO] 2021-07-12 18:47:16,735 [run_pretraining.py:  558]:	worker_index: 6, step: 809, cost: 8.468457, mlm loss: 8.468457, speed: 0.038143 steps/s, speed: 0.305141 samples/s, speed: 156.232048 tokens/s, learning rate: 8.080e-06, loss_scalings: 13421.773438, pp_loss: 7.257025
[INFO] 2021-07-12 18:47:16,735 [run_pretraining.py:  512]:	********exe.run_809******* 
[INFO] 2021-07-12 18:47:17,826 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:17,827 [run_pretraining.py:  534]:	loss/total_loss, 7.774459362030029, 810
[INFO] 2021-07-12 18:47:17,827 [run_pretraining.py:  535]:	loss/mlm_loss, 7.774459362030029, 810
[INFO] 2021-07-12 18:47:17,827 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.089999937510584e-06, 810
[INFO] 2021-07-12 18:47:17,827 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 810
[INFO] 2021-07-12 18:47:17,827 [run_pretraining.py:  558]:	worker_index: 6, step: 810, cost: 7.774459, mlm loss: 7.774459, speed: 0.916177 steps/s, speed: 7.329413 samples/s, speed: 3752.659250 tokens/s, learning rate: 8.090e-06, loss_scalings: 13421.773438, pp_loss: 8.079343
[INFO] 2021-07-12 18:47:17,827 [run_pretraining.py:  512]:	********exe.run_810******* 
[INFO] 2021-07-12 18:47:18,741 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:18,742 [run_pretraining.py:  534]:	loss/total_loss, 8.35629653930664, 811
[INFO] 2021-07-12 18:47:18,742 [run_pretraining.py:  535]:	loss/mlm_loss, 8.35629653930664, 811
[INFO] 2021-07-12 18:47:18,742 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.099999831756577e-06, 811
[INFO] 2021-07-12 18:47:18,742 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 811
[INFO] 2021-07-12 18:47:18,742 [run_pretraining.py:  558]:	worker_index: 6, step: 811, cost: 8.356297, mlm loss: 8.356297, speed: 1.093823 steps/s, speed: 8.750587 samples/s, speed: 4480.300528 tokens/s, learning rate: 8.100e-06, loss_scalings: 13421.773438, pp_loss: 8.271714
[INFO] 2021-07-12 18:47:18,742 [run_pretraining.py:  512]:	********exe.run_811******* 
[INFO] 2021-07-12 18:47:19,665 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:19,665 [run_pretraining.py:  534]:	loss/total_loss, 7.9909443855285645, 812
[INFO] 2021-07-12 18:47:19,665 [run_pretraining.py:  535]:	loss/mlm_loss, 7.9909443855285645, 812
[INFO] 2021-07-12 18:47:19,665 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.10999972600257e-06, 812
[INFO] 2021-07-12 18:47:19,665 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 812
[INFO] 2021-07-12 18:47:19,666 [run_pretraining.py:  558]:	worker_index: 6, step: 812, cost: 7.990944, mlm loss: 7.990944, speed: 1.084047 steps/s, speed: 8.672375 samples/s, speed: 4440.255796 tokens/s, learning rate: 8.110e-06, loss_scalings: 13421.773438, pp_loss: 8.100935
[INFO] 2021-07-12 18:47:19,666 [run_pretraining.py:  512]:	********exe.run_812******* 
[INFO] 2021-07-12 18:47:20,594 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:20,594 [run_pretraining.py:  534]:	loss/total_loss, 8.463787078857422, 813
[INFO] 2021-07-12 18:47:20,594 [run_pretraining.py:  535]:	loss/mlm_loss, 8.463787078857422, 813
[INFO] 2021-07-12 18:47:20,595 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.120000529743265e-06, 813
[INFO] 2021-07-12 18:47:20,595 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 813
[INFO] 2021-07-12 18:47:20,595 [run_pretraining.py:  558]:	worker_index: 6, step: 813, cost: 8.463787, mlm loss: 8.463787, speed: 1.076970 steps/s, speed: 8.615758 samples/s, speed: 4411.268176 tokens/s, learning rate: 8.120e-06, loss_scalings: 13421.773438, pp_loss: 8.516710
[INFO] 2021-07-12 18:47:20,595 [run_pretraining.py:  512]:	********exe.run_813******* 
[INFO] 2021-07-12 18:47:21,507 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:21,508 [run_pretraining.py:  534]:	loss/total_loss, 8.604718208312988, 814
[INFO] 2021-07-12 18:47:21,508 [run_pretraining.py:  535]:	loss/mlm_loss, 8.604718208312988, 814
[INFO] 2021-07-12 18:47:21,508 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.129999514494557e-06, 814
[INFO] 2021-07-12 18:47:21,508 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 814
[INFO] 2021-07-12 18:47:21,508 [run_pretraining.py:  558]:	worker_index: 6, step: 814, cost: 8.604718, mlm loss: 8.604718, speed: 1.095415 steps/s, speed: 8.763319 samples/s, speed: 4486.819198 tokens/s, learning rate: 8.130e-06, loss_scalings: 13421.773438, pp_loss: 8.300785
[INFO] 2021-07-12 18:47:21,508 [run_pretraining.py:  512]:	********exe.run_814******* 
[INFO] 2021-07-12 18:47:22,432 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:22,433 [run_pretraining.py:  534]:	loss/total_loss, 8.122126579284668, 815
[INFO] 2021-07-12 18:47:22,433 [run_pretraining.py:  535]:	loss/mlm_loss, 8.122126579284668, 815
[INFO] 2021-07-12 18:47:22,433 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.13999940874055e-06, 815
[INFO] 2021-07-12 18:47:22,433 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 815
[INFO] 2021-07-12 18:47:22,433 [run_pretraining.py:  558]:	worker_index: 6, step: 815, cost: 8.122127, mlm loss: 8.122127, speed: 1.082304 steps/s, speed: 8.658435 samples/s, speed: 4433.118794 tokens/s, learning rate: 8.140e-06, loss_scalings: 13421.773438, pp_loss: 8.282117
[INFO] 2021-07-12 18:47:22,433 [run_pretraining.py:  512]:	********exe.run_815******* 
[INFO] 2021-07-12 18:47:23,378 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:23,378 [run_pretraining.py:  534]:	loss/total_loss, 8.588963508605957, 816
[INFO] 2021-07-12 18:47:23,379 [run_pretraining.py:  535]:	loss/mlm_loss, 8.588963508605957, 816
[INFO] 2021-07-12 18:47:23,379 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.150000212481245e-06, 816
[INFO] 2021-07-12 18:47:23,379 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 816
[INFO] 2021-07-12 18:47:23,379 [run_pretraining.py:  558]:	worker_index: 6, step: 816, cost: 8.588964, mlm loss: 8.588964, speed: 1.058014 steps/s, speed: 8.464112 samples/s, speed: 4333.625401 tokens/s, learning rate: 8.150e-06, loss_scalings: 13421.773438, pp_loss: 8.453389
[INFO] 2021-07-12 18:47:23,379 [run_pretraining.py:  512]:	********exe.run_816******* 
[INFO] 2021-07-12 18:47:24,296 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:24,296 [run_pretraining.py:  534]:	loss/total_loss, 8.389363288879395, 817
[INFO] 2021-07-12 18:47:24,297 [run_pretraining.py:  535]:	loss/mlm_loss, 8.389363288879395, 817
[INFO] 2021-07-12 18:47:24,297 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.160000106727239e-06, 817
[INFO] 2021-07-12 18:47:24,297 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 817
[INFO] 2021-07-12 18:47:24,297 [run_pretraining.py:  558]:	worker_index: 6, step: 817, cost: 8.389363, mlm loss: 8.389363, speed: 1.090258 steps/s, speed: 8.722063 samples/s, speed: 4465.696454 tokens/s, learning rate: 8.160e-06, loss_scalings: 13421.773438, pp_loss: 8.329801
[INFO] 2021-07-12 18:47:24,297 [run_pretraining.py:  512]:	********exe.run_817******* 
[INFO] 2021-07-12 18:47:25,223 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:25,224 [run_pretraining.py:  534]:	loss/total_loss, 8.226497650146484, 818
[INFO] 2021-07-12 18:47:25,224 [run_pretraining.py:  535]:	loss/mlm_loss, 8.226497650146484, 818
[INFO] 2021-07-12 18:47:25,224 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.16999909147853e-06, 818
[INFO] 2021-07-12 18:47:25,224 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 818
[INFO] 2021-07-12 18:47:25,224 [run_pretraining.py:  558]:	worker_index: 6, step: 818, cost: 8.226498, mlm loss: 8.226498, speed: 1.079126 steps/s, speed: 8.633011 samples/s, speed: 4420.101474 tokens/s, learning rate: 8.170e-06, loss_scalings: 13421.773438, pp_loss: 8.110763
[INFO] 2021-07-12 18:47:25,224 [run_pretraining.py:  512]:	********exe.run_818******* 
[INFO] 2021-07-12 18:47:26,135 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:26,136 [run_pretraining.py:  534]:	loss/total_loss, 8.428520202636719, 819
[INFO] 2021-07-12 18:47:26,136 [run_pretraining.py:  535]:	loss/mlm_loss, 8.428520202636719, 819
[INFO] 2021-07-12 18:47:26,136 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.179999895219225e-06, 819
[INFO] 2021-07-12 18:47:26,136 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 819
[INFO] 2021-07-12 18:47:26,136 [run_pretraining.py:  558]:	worker_index: 6, step: 819, cost: 8.428520, mlm loss: 8.428520, speed: 1.097601 steps/s, speed: 8.780812 samples/s, speed: 4495.775609 tokens/s, learning rate: 8.180e-06, loss_scalings: 13421.773438, pp_loss: 8.229862
[INFO] 2021-07-12 18:47:26,136 [run_pretraining.py:  512]:	********exe.run_819******* 
[INFO] 2021-07-12 18:47:27,055 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:27,056 [run_pretraining.py:  534]:	loss/total_loss, 8.752836227416992, 820
[INFO] 2021-07-12 18:47:27,056 [run_pretraining.py:  535]:	loss/mlm_loss, 8.752836227416992, 820
[INFO] 2021-07-12 18:47:27,056 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.189999789465219e-06, 820
[INFO] 2021-07-12 18:47:27,056 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 820
[INFO] 2021-07-12 18:47:27,056 [run_pretraining.py:  558]:	worker_index: 6, step: 820, cost: 8.752836, mlm loss: 8.752836, speed: 1.087852 steps/s, speed: 8.702817 samples/s, speed: 4455.842134 tokens/s, learning rate: 8.190e-06, loss_scalings: 13421.773438, pp_loss: 8.270618
[INFO] 2021-07-12 18:47:27,056 [run_pretraining.py:  512]:	********exe.run_820******* 
[INFO] 2021-07-12 18:47:28,010 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:28,011 [run_pretraining.py:  534]:	loss/total_loss, 8.096972465515137, 821
[INFO] 2021-07-12 18:47:28,011 [run_pretraining.py:  535]:	loss/mlm_loss, 8.096972465515137, 821
[INFO] 2021-07-12 18:47:28,011 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.199999683711212e-06, 821
[INFO] 2021-07-12 18:47:28,011 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 821
[INFO] 2021-07-12 18:47:28,011 [run_pretraining.py:  558]:	worker_index: 6, step: 821, cost: 8.096972, mlm loss: 8.096972, speed: 1.047427 steps/s, speed: 8.379418 samples/s, speed: 4290.261951 tokens/s, learning rate: 8.200e-06, loss_scalings: 13421.773438, pp_loss: 8.092159
[INFO] 2021-07-12 18:47:28,011 [run_pretraining.py:  512]:	********exe.run_821******* 
[INFO] 2021-07-12 18:47:29,022 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:29,023 [run_pretraining.py:  534]:	loss/total_loss, 7.991652011871338, 822
[INFO] 2021-07-12 18:47:29,023 [run_pretraining.py:  535]:	loss/mlm_loss, 7.991652011871338, 822
[INFO] 2021-07-12 18:47:29,023 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.209999577957205e-06, 822
[INFO] 2021-07-12 18:47:29,023 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 822
[INFO] 2021-07-12 18:47:29,023 [run_pretraining.py:  558]:	worker_index: 6, step: 822, cost: 7.991652, mlm loss: 7.991652, speed: 0.989017 steps/s, speed: 7.912133 samples/s, speed: 4051.012297 tokens/s, learning rate: 8.210e-06, loss_scalings: 13421.773438, pp_loss: 7.962879
[INFO] 2021-07-12 18:47:29,023 [run_pretraining.py:  512]:	********exe.run_822******* 
[INFO] 2021-07-12 18:47:30,089 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:30,090 [run_pretraining.py:  534]:	loss/total_loss, 8.72274112701416, 823
[INFO] 2021-07-12 18:47:30,090 [run_pretraining.py:  535]:	loss/mlm_loss, 8.72274112701416, 823
[INFO] 2021-07-12 18:47:30,090 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.219999472203199e-06, 823
[INFO] 2021-07-12 18:47:30,090 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 823
[INFO] 2021-07-12 18:47:30,090 [run_pretraining.py:  558]:	worker_index: 6, step: 823, cost: 8.722741, mlm loss: 8.722741, speed: 0.937954 steps/s, speed: 7.503635 samples/s, speed: 3841.861081 tokens/s, learning rate: 8.220e-06, loss_scalings: 13421.773438, pp_loss: 8.089705
[INFO] 2021-07-12 18:47:30,090 [run_pretraining.py:  512]:	********exe.run_823******* 
[INFO] 2021-07-12 18:47:31,122 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:31,123 [run_pretraining.py:  534]:	loss/total_loss, 8.50255298614502, 824
[INFO] 2021-07-12 18:47:31,123 [run_pretraining.py:  535]:	loss/mlm_loss, 8.50255298614502, 824
[INFO] 2021-07-12 18:47:31,123 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.229999366449192e-06, 824
[INFO] 2021-07-12 18:47:31,123 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 824
[INFO] 2021-07-12 18:47:31,123 [run_pretraining.py:  558]:	worker_index: 6, step: 824, cost: 8.502553, mlm loss: 8.502553, speed: 0.968536 steps/s, speed: 7.748289 samples/s, speed: 3967.124156 tokens/s, learning rate: 8.230e-06, loss_scalings: 13421.773438, pp_loss: 8.297179
[INFO] 2021-07-12 18:47:31,123 [run_pretraining.py:  512]:	********exe.run_824******* 
[INFO] 2021-07-12 18:47:32,194 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:32,195 [run_pretraining.py:  534]:	loss/total_loss, 8.05240535736084, 825
[INFO] 2021-07-12 18:47:32,195 [run_pretraining.py:  535]:	loss/mlm_loss, 8.05240535736084, 825
[INFO] 2021-07-12 18:47:32,195 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.240000170189887e-06, 825
[INFO] 2021-07-12 18:47:32,195 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 825
[INFO] 2021-07-12 18:47:32,195 [run_pretraining.py:  558]:	worker_index: 6, step: 825, cost: 8.052405, mlm loss: 8.052405, speed: 0.933426 steps/s, speed: 7.467410 samples/s, speed: 3823.313753 tokens/s, learning rate: 8.240e-06, loss_scalings: 13421.773438, pp_loss: 7.485132
[INFO] 2021-07-12 18:47:32,195 [run_pretraining.py:  512]:	********exe.run_825******* 
[INFO] 2021-07-12 18:47:33,259 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:33,260 [run_pretraining.py:  534]:	loss/total_loss, 8.431365013122559, 826
[INFO] 2021-07-12 18:47:33,260 [run_pretraining.py:  535]:	loss/mlm_loss, 8.431365013122559, 826
[INFO] 2021-07-12 18:47:33,260 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.25000006443588e-06, 826
[INFO] 2021-07-12 18:47:33,260 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 826
[INFO] 2021-07-12 18:47:33,260 [run_pretraining.py:  558]:	worker_index: 6, step: 826, cost: 8.431365, mlm loss: 8.431365, speed: 0.939409 steps/s, speed: 7.515270 samples/s, speed: 3847.818124 tokens/s, learning rate: 8.250e-06, loss_scalings: 13421.773438, pp_loss: 8.281430
[INFO] 2021-07-12 18:47:33,261 [run_pretraining.py:  512]:	********exe.run_826******* 
[INFO] 2021-07-12 18:47:34,328 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:34,329 [run_pretraining.py:  534]:	loss/total_loss, 8.108497619628906, 827
[INFO] 2021-07-12 18:47:34,329 [run_pretraining.py:  535]:	loss/mlm_loss, 8.108497619628906, 827
[INFO] 2021-07-12 18:47:34,329 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.259999958681874e-06, 827
[INFO] 2021-07-12 18:47:34,329 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 827
[INFO] 2021-07-12 18:47:34,329 [run_pretraining.py:  558]:	worker_index: 6, step: 827, cost: 8.108498, mlm loss: 8.108498, speed: 0.936378 steps/s, speed: 7.491021 samples/s, speed: 3835.402640 tokens/s, learning rate: 8.260e-06, loss_scalings: 13421.773438, pp_loss: 8.231209
[INFO] 2021-07-12 18:47:34,329 [run_pretraining.py:  512]:	********exe.run_827******* 
[INFO] 2021-07-12 18:47:35,397 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:35,398 [run_pretraining.py:  534]:	loss/total_loss, 8.235655784606934, 828
[INFO] 2021-07-12 18:47:35,398 [run_pretraining.py:  535]:	loss/mlm_loss, 8.235655784606934, 828
[INFO] 2021-07-12 18:47:35,398 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.269999852927867e-06, 828
[INFO] 2021-07-12 18:47:35,398 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 828
[INFO] 2021-07-12 18:47:35,398 [run_pretraining.py:  558]:	worker_index: 6, step: 828, cost: 8.235656, mlm loss: 8.235656, speed: 0.936205 steps/s, speed: 7.489638 samples/s, speed: 3834.694649 tokens/s, learning rate: 8.270e-06, loss_scalings: 13421.773438, pp_loss: 8.090662
[INFO] 2021-07-12 18:47:35,398 [run_pretraining.py:  512]:	********exe.run_828******* 
[INFO] 2021-07-12 18:47:36,463 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:36,463 [run_pretraining.py:  534]:	loss/total_loss, 8.147769927978516, 829
[INFO] 2021-07-12 18:47:36,464 [run_pretraining.py:  535]:	loss/mlm_loss, 8.147769927978516, 829
[INFO] 2021-07-12 18:47:36,464 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.27999974717386e-06, 829
[INFO] 2021-07-12 18:47:36,464 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 829
[INFO] 2021-07-12 18:47:36,464 [run_pretraining.py:  558]:	worker_index: 6, step: 829, cost: 8.147770, mlm loss: 8.147770, speed: 0.938797 steps/s, speed: 7.510380 samples/s, speed: 3845.314485 tokens/s, learning rate: 8.280e-06, loss_scalings: 13421.773438, pp_loss: 8.229578
[INFO] 2021-07-12 18:47:36,464 [run_pretraining.py:  512]:	********exe.run_829******* 
[INFO] 2021-07-12 18:47:37,530 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:37,530 [run_pretraining.py:  534]:	loss/total_loss, 8.500897407531738, 830
[INFO] 2021-07-12 18:47:37,530 [run_pretraining.py:  535]:	loss/mlm_loss, 8.500897407531738, 830
[INFO] 2021-07-12 18:47:37,531 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.289999641419854e-06, 830
[INFO] 2021-07-12 18:47:37,531 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 830
[INFO] 2021-07-12 18:47:37,531 [run_pretraining.py:  558]:	worker_index: 6, step: 830, cost: 8.500897, mlm loss: 8.500897, speed: 0.937958 steps/s, speed: 7.503667 samples/s, speed: 3841.877405 tokens/s, learning rate: 8.290e-06, loss_scalings: 13421.773438, pp_loss: 8.594401
[INFO] 2021-07-12 18:47:37,531 [run_pretraining.py:  512]:	********exe.run_830******* 
[INFO] 2021-07-12 18:47:38,601 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:38,602 [run_pretraining.py:  534]:	loss/total_loss, 8.426616668701172, 831
[INFO] 2021-07-12 18:47:38,602 [run_pretraining.py:  535]:	loss/mlm_loss, 8.426616668701172, 831
[INFO] 2021-07-12 18:47:38,602 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.299999535665847e-06, 831
[INFO] 2021-07-12 18:47:38,602 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 831
[INFO] 2021-07-12 18:47:38,602 [run_pretraining.py:  558]:	worker_index: 6, step: 831, cost: 8.426617, mlm loss: 8.426617, speed: 0.933863 steps/s, speed: 7.470903 samples/s, speed: 3825.102254 tokens/s, learning rate: 8.300e-06, loss_scalings: 13421.773438, pp_loss: 8.254566
[INFO] 2021-07-12 18:47:38,602 [run_pretraining.py:  512]:	********exe.run_831******* 
[INFO] 2021-07-12 18:47:39,664 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:39,664 [run_pretraining.py:  534]:	loss/total_loss, 8.289957046508789, 832
[INFO] 2021-07-12 18:47:39,665 [run_pretraining.py:  535]:	loss/mlm_loss, 8.289957046508789, 832
[INFO] 2021-07-12 18:47:39,665 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.30999942991184e-06, 832
[INFO] 2021-07-12 18:47:39,665 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 832
[INFO] 2021-07-12 18:47:39,665 [run_pretraining.py:  558]:	worker_index: 6, step: 832, cost: 8.289957, mlm loss: 8.289957, speed: 0.941688 steps/s, speed: 7.533504 samples/s, speed: 3857.154253 tokens/s, learning rate: 8.310e-06, loss_scalings: 13421.773438, pp_loss: 8.078569
[INFO] 2021-07-12 18:47:39,665 [run_pretraining.py:  512]:	********exe.run_832******* 
[INFO] 2021-07-12 18:47:40,725 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:40,726 [run_pretraining.py:  534]:	loss/total_loss, 8.272915840148926, 833
[INFO] 2021-07-12 18:47:40,726 [run_pretraining.py:  535]:	loss/mlm_loss, 8.272915840148926, 833
[INFO] 2021-07-12 18:47:40,726 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.320000233652536e-06, 833
[INFO] 2021-07-12 18:47:40,726 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 833
[INFO] 2021-07-12 18:47:40,726 [run_pretraining.py:  558]:	worker_index: 6, step: 833, cost: 8.272916, mlm loss: 8.272916, speed: 0.942852 steps/s, speed: 7.542817 samples/s, speed: 3861.922232 tokens/s, learning rate: 8.320e-06, loss_scalings: 13421.773438, pp_loss: 8.311052
[INFO] 2021-07-12 18:47:40,726 [run_pretraining.py:  512]:	********exe.run_833******* 
[INFO] 2021-07-12 18:47:41,738 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:41,744 [run_pretraining.py:  534]:	loss/total_loss, 8.431610107421875, 834
[INFO] 2021-07-12 18:47:41,749 [run_pretraining.py:  535]:	loss/mlm_loss, 8.431610107421875, 834
[INFO] 2021-07-12 18:47:41,754 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.33000012789853e-06, 834
[INFO] 2021-07-12 18:47:41,760 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 834
[INFO] 2021-07-12 18:47:41,765 [run_pretraining.py:  558]:	worker_index: 6, step: 834, cost: 8.431610, mlm loss: 8.431610, speed: 0.982775 steps/s, speed: 7.862198 samples/s, speed: 4025.445599 tokens/s, learning rate: 8.330e-06, loss_scalings: 13421.773438, pp_loss: 8.160243
[INFO] 2021-07-12 18:47:41,770 [run_pretraining.py:  512]:	********exe.run_834******* 
[INFO] 2021-07-12 18:47:42,646 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:42,647 [run_pretraining.py:  534]:	loss/total_loss, 8.583267211914062, 835
[INFO] 2021-07-12 18:47:42,647 [run_pretraining.py:  535]:	loss/mlm_loss, 8.583267211914062, 835
[INFO] 2021-07-12 18:47:42,647 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.340000022144523e-06, 835
[INFO] 2021-07-12 18:47:42,647 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 835
[INFO] 2021-07-12 18:47:42,647 [run_pretraining.py:  558]:	worker_index: 6, step: 835, cost: 8.583267, mlm loss: 8.583267, speed: 1.141110 steps/s, speed: 9.128880 samples/s, speed: 4673.986722 tokens/s, learning rate: 8.340e-06, loss_scalings: 13421.773438, pp_loss: 8.242048
[INFO] 2021-07-12 18:47:42,647 [run_pretraining.py:  512]:	********exe.run_835******* 
[INFO] 2021-07-12 18:47:43,564 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:43,564 [run_pretraining.py:  534]:	loss/total_loss, 8.127581596374512, 836
[INFO] 2021-07-12 18:47:43,564 [run_pretraining.py:  535]:	loss/mlm_loss, 8.127581596374512, 836
[INFO] 2021-07-12 18:47:43,564 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.349999916390516e-06, 836
[INFO] 2021-07-12 18:47:43,565 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 836
[INFO] 2021-07-12 18:47:43,565 [run_pretraining.py:  558]:	worker_index: 6, step: 836, cost: 8.127582, mlm loss: 8.127582, speed: 1.090453 steps/s, speed: 8.723623 samples/s, speed: 4466.495229 tokens/s, learning rate: 8.350e-06, loss_scalings: 13421.773438, pp_loss: 8.006417
[INFO] 2021-07-12 18:47:43,565 [run_pretraining.py:  512]:	********exe.run_836******* 
[INFO] 2021-07-12 18:47:44,473 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:44,474 [run_pretraining.py:  534]:	loss/total_loss, 7.839278221130371, 837
[INFO] 2021-07-12 18:47:44,474 [run_pretraining.py:  535]:	loss/mlm_loss, 7.839278221130371, 837
[INFO] 2021-07-12 18:47:44,474 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.35999981063651e-06, 837
[INFO] 2021-07-12 18:47:44,474 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 837
[INFO] 2021-07-12 18:47:44,474 [run_pretraining.py:  558]:	worker_index: 6, step: 837, cost: 7.839278, mlm loss: 7.839278, speed: 1.100687 steps/s, speed: 8.805495 samples/s, speed: 4508.413631 tokens/s, learning rate: 8.360e-06, loss_scalings: 13421.773438, pp_loss: 8.300918
[INFO] 2021-07-12 18:47:44,474 [run_pretraining.py:  512]:	********exe.run_837******* 
[INFO] 2021-07-12 18:47:45,391 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:45,391 [run_pretraining.py:  534]:	loss/total_loss, 7.280398368835449, 838
[INFO] 2021-07-12 18:47:45,391 [run_pretraining.py:  535]:	loss/mlm_loss, 7.280398368835449, 838
[INFO] 2021-07-12 18:47:45,392 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.369999704882503e-06, 838
[INFO] 2021-07-12 18:47:45,392 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 838
[INFO] 2021-07-12 18:47:45,392 [run_pretraining.py:  558]:	worker_index: 6, step: 838, cost: 7.280398, mlm loss: 7.280398, speed: 1.090328 steps/s, speed: 8.722628 samples/s, speed: 4465.985512 tokens/s, learning rate: 8.370e-06, loss_scalings: 13421.773438, pp_loss: 7.939402
[INFO] 2021-07-12 18:47:45,392 [run_pretraining.py:  512]:	********exe.run_838******* 
[INFO] 2021-07-12 18:47:46,311 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:46,312 [run_pretraining.py:  534]:	loss/total_loss, 8.399397850036621, 839
[INFO] 2021-07-12 18:47:46,312 [run_pretraining.py:  535]:	loss/mlm_loss, 8.399397850036621, 839
[INFO] 2021-07-12 18:47:46,312 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.380000508623198e-06, 839
[INFO] 2021-07-12 18:47:46,312 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 839
[INFO] 2021-07-12 18:47:46,312 [run_pretraining.py:  558]:	worker_index: 6, step: 839, cost: 8.399398, mlm loss: 8.399398, speed: 1.087663 steps/s, speed: 8.701302 samples/s, speed: 4455.066804 tokens/s, learning rate: 8.380e-06, loss_scalings: 13421.773438, pp_loss: 7.944272
[INFO] 2021-07-12 18:47:46,312 [run_pretraining.py:  512]:	********exe.run_839******* 
[INFO] 2021-07-12 18:47:47,238 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:47,239 [run_pretraining.py:  534]:	loss/total_loss, 7.987158298492432, 840
[INFO] 2021-07-12 18:47:47,239 [run_pretraining.py:  535]:	loss/mlm_loss, 7.987158298492432, 840
[INFO] 2021-07-12 18:47:47,239 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.38999949337449e-06, 840
[INFO] 2021-07-12 18:47:47,239 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 840
[INFO] 2021-07-12 18:47:47,239 [run_pretraining.py:  558]:	worker_index: 6, step: 840, cost: 7.987158, mlm loss: 7.987158, speed: 1.079081 steps/s, speed: 8.632649 samples/s, speed: 4419.916115 tokens/s, learning rate: 8.390e-06, loss_scalings: 13421.773438, pp_loss: 8.159497
[INFO] 2021-07-12 18:47:47,239 [run_pretraining.py:  512]:	********exe.run_840******* 
[INFO] 2021-07-12 18:47:48,302 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:48,303 [run_pretraining.py:  534]:	loss/total_loss, 8.03113079071045, 841
[INFO] 2021-07-12 18:47:48,303 [run_pretraining.py:  535]:	loss/mlm_loss, 8.03113079071045, 841
[INFO] 2021-07-12 18:47:48,303 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.399999387620483e-06, 841
[INFO] 2021-07-12 18:47:48,303 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 841
[INFO] 2021-07-12 18:47:48,303 [run_pretraining.py:  558]:	worker_index: 6, step: 841, cost: 8.031131, mlm loss: 8.031131, speed: 0.940553 steps/s, speed: 7.524428 samples/s, speed: 3852.506881 tokens/s, learning rate: 8.400e-06, loss_scalings: 13421.773438, pp_loss: 8.156873
[INFO] 2021-07-12 18:47:48,303 [run_pretraining.py:  512]:	********exe.run_841******* 
[INFO] 2021-07-12 18:47:49,365 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:49,366 [run_pretraining.py:  534]:	loss/total_loss, 8.458197593688965, 842
[INFO] 2021-07-12 18:47:49,366 [run_pretraining.py:  535]:	loss/mlm_loss, 8.458197593688965, 842
[INFO] 2021-07-12 18:47:49,366 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.410000191361178e-06, 842
[INFO] 2021-07-12 18:47:49,366 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 842
[INFO] 2021-07-12 18:47:49,366 [run_pretraining.py:  558]:	worker_index: 6, step: 842, cost: 8.458198, mlm loss: 8.458198, speed: 0.941314 steps/s, speed: 7.530508 samples/s, speed: 3855.620324 tokens/s, learning rate: 8.410e-06, loss_scalings: 13421.773438, pp_loss: 7.550271
[INFO] 2021-07-12 18:47:49,366 [run_pretraining.py:  512]:	********exe.run_842******* 
[INFO] 2021-07-12 18:47:50,429 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:50,430 [run_pretraining.py:  534]:	loss/total_loss, 8.556989669799805, 843
[INFO] 2021-07-12 18:47:50,430 [run_pretraining.py:  535]:	loss/mlm_loss, 8.556989669799805, 843
[INFO] 2021-07-12 18:47:50,430 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.420000085607171e-06, 843
[INFO] 2021-07-12 18:47:50,430 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 843
[INFO] 2021-07-12 18:47:50,430 [run_pretraining.py:  558]:	worker_index: 6, step: 843, cost: 8.556990, mlm loss: 8.556990, speed: 0.940641 steps/s, speed: 7.525131 samples/s, speed: 3852.867164 tokens/s, learning rate: 8.420e-06, loss_scalings: 13421.773438, pp_loss: 8.474197
[INFO] 2021-07-12 18:47:50,430 [run_pretraining.py:  512]:	********exe.run_843******* 
[INFO] 2021-07-12 18:47:51,494 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:51,494 [run_pretraining.py:  534]:	loss/total_loss, 8.276638984680176, 844
[INFO] 2021-07-12 18:47:51,494 [run_pretraining.py:  535]:	loss/mlm_loss, 8.276638984680176, 844
[INFO] 2021-07-12 18:47:51,494 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.429999070358463e-06, 844
[INFO] 2021-07-12 18:47:51,494 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 844
[INFO] 2021-07-12 18:47:51,494 [run_pretraining.py:  558]:	worker_index: 6, step: 844, cost: 8.276639, mlm loss: 8.276639, speed: 0.940126 steps/s, speed: 7.521007 samples/s, speed: 3850.755674 tokens/s, learning rate: 8.430e-06, loss_scalings: 13421.773438, pp_loss: 8.358006
[INFO] 2021-07-12 18:47:51,495 [run_pretraining.py:  512]:	********exe.run_844******* 
[INFO] 2021-07-12 18:47:52,553 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:52,554 [run_pretraining.py:  534]:	loss/total_loss, 8.141438484191895, 845
[INFO] 2021-07-12 18:47:52,554 [run_pretraining.py:  535]:	loss/mlm_loss, 8.141438484191895, 845
[INFO] 2021-07-12 18:47:52,554 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.439999874099158e-06, 845
[INFO] 2021-07-12 18:47:52,554 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 845
[INFO] 2021-07-12 18:47:52,554 [run_pretraining.py:  558]:	worker_index: 6, step: 845, cost: 8.141438, mlm loss: 8.141438, speed: 0.944279 steps/s, speed: 7.554235 samples/s, speed: 3867.768408 tokens/s, learning rate: 8.440e-06, loss_scalings: 13421.773438, pp_loss: 8.316374
[INFO] 2021-07-12 18:47:52,554 [run_pretraining.py:  512]:	********exe.run_845******* 
[INFO] 2021-07-12 18:47:53,617 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:53,618 [run_pretraining.py:  534]:	loss/total_loss, 8.215216636657715, 846
[INFO] 2021-07-12 18:47:53,618 [run_pretraining.py:  535]:	loss/mlm_loss, 8.215216636657715, 846
[INFO] 2021-07-12 18:47:53,618 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.449999768345151e-06, 846
[INFO] 2021-07-12 18:47:53,618 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 846
[INFO] 2021-07-12 18:47:53,618 [run_pretraining.py:  558]:	worker_index: 6, step: 846, cost: 8.215217, mlm loss: 8.215217, speed: 0.940477 steps/s, speed: 7.523818 samples/s, speed: 3852.195036 tokens/s, learning rate: 8.450e-06, loss_scalings: 13421.773438, pp_loss: 8.234708
[INFO] 2021-07-12 18:47:53,618 [run_pretraining.py:  512]:	********exe.run_846******* 
[INFO] 2021-07-12 18:47:54,672 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:54,673 [run_pretraining.py:  534]:	loss/total_loss, 8.096473693847656, 847
[INFO] 2021-07-12 18:47:54,673 [run_pretraining.py:  535]:	loss/mlm_loss, 8.096473693847656, 847
[INFO] 2021-07-12 18:47:54,673 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.459999662591144e-06, 847
[INFO] 2021-07-12 18:47:54,673 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 847
[INFO] 2021-07-12 18:47:54,673 [run_pretraining.py:  558]:	worker_index: 6, step: 847, cost: 8.096474, mlm loss: 8.096474, speed: 0.948690 steps/s, speed: 7.589517 samples/s, speed: 3885.832816 tokens/s, learning rate: 8.460e-06, loss_scalings: 13421.773438, pp_loss: 7.911325
[INFO] 2021-07-12 18:47:54,673 [run_pretraining.py:  512]:	********exe.run_847******* 
[INFO] 2021-07-12 18:47:55,747 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:55,748 [run_pretraining.py:  534]:	loss/total_loss, 8.020395278930664, 848
[INFO] 2021-07-12 18:47:55,748 [run_pretraining.py:  535]:	loss/mlm_loss, 8.020395278930664, 848
[INFO] 2021-07-12 18:47:55,748 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.47000046633184e-06, 848
[INFO] 2021-07-12 18:47:55,748 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 848
[INFO] 2021-07-12 18:47:55,748 [run_pretraining.py:  558]:	worker_index: 6, step: 848, cost: 8.020395, mlm loss: 8.020395, speed: 0.930758 steps/s, speed: 7.446066 samples/s, speed: 3812.385951 tokens/s, learning rate: 8.470e-06, loss_scalings: 13421.773438, pp_loss: 8.305029
[INFO] 2021-07-12 18:47:55,748 [run_pretraining.py:  512]:	********exe.run_848******* 
[INFO] 2021-07-12 18:47:56,815 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:56,816 [run_pretraining.py:  534]:	loss/total_loss, 7.779982566833496, 849
[INFO] 2021-07-12 18:47:56,816 [run_pretraining.py:  535]:	loss/mlm_loss, 7.779982566833496, 849
[INFO] 2021-07-12 18:47:56,816 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.479999451083131e-06, 849
[INFO] 2021-07-12 18:47:56,816 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 849
[INFO] 2021-07-12 18:47:56,816 [run_pretraining.py:  558]:	worker_index: 6, step: 849, cost: 7.779983, mlm loss: 7.779983, speed: 0.936898 steps/s, speed: 7.495182 samples/s, speed: 3837.533324 tokens/s, learning rate: 8.480e-06, loss_scalings: 13421.773438, pp_loss: 8.250503
[INFO] 2021-07-12 18:47:56,816 [run_pretraining.py:  512]:	********exe.run_849******* 
[INFO] 2021-07-12 18:47:57,872 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:57,872 [run_pretraining.py:  534]:	loss/total_loss, 7.988800048828125, 850
[INFO] 2021-07-12 18:47:57,872 [run_pretraining.py:  535]:	loss/mlm_loss, 7.988800048828125, 850
[INFO] 2021-07-12 18:47:57,872 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.489999345329124e-06, 850
[INFO] 2021-07-12 18:47:57,873 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 850
[INFO] 2021-07-12 18:47:57,873 [run_pretraining.py:  558]:	worker_index: 6, step: 850, cost: 7.988800, mlm loss: 7.988800, speed: 0.947160 steps/s, speed: 7.577277 samples/s, speed: 3879.565708 tokens/s, learning rate: 8.490e-06, loss_scalings: 13421.773438, pp_loss: 7.210178
[INFO] 2021-07-12 18:47:57,873 [run_pretraining.py:  512]:	********exe.run_850******* 
[INFO] 2021-07-12 18:47:59,117 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:59,117 [run_pretraining.py:  534]:	loss/total_loss, 7.908400058746338, 851
[INFO] 2021-07-12 18:47:59,117 [run_pretraining.py:  535]:	loss/mlm_loss, 7.908400058746338, 851
[INFO] 2021-07-12 18:47:59,118 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.50000014906982e-06, 851
[INFO] 2021-07-12 18:47:59,118 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 851
[INFO] 2021-07-12 18:47:59,118 [run_pretraining.py:  558]:	worker_index: 6, step: 851, cost: 7.908400, mlm loss: 7.908400, speed: 0.803630 steps/s, speed: 6.429037 samples/s, speed: 3291.667149 tokens/s, learning rate: 8.500e-06, loss_scalings: 13421.773438, pp_loss: 8.124095
[INFO] 2021-07-12 18:47:59,118 [run_pretraining.py:  512]:	********exe.run_851******* 
[INFO] 2021-07-12 18:48:00,180 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:00,180 [run_pretraining.py:  534]:	loss/total_loss, 7.381104469299316, 852
[INFO] 2021-07-12 18:48:00,180 [run_pretraining.py:  535]:	loss/mlm_loss, 7.381104469299316, 852
[INFO] 2021-07-12 18:48:00,180 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.510000043315813e-06, 852
[INFO] 2021-07-12 18:48:00,181 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 852
[INFO] 2021-07-12 18:48:00,181 [run_pretraining.py:  558]:	worker_index: 6, step: 852, cost: 7.381104, mlm loss: 7.381104, speed: 0.941397 steps/s, speed: 7.531178 samples/s, speed: 3855.963015 tokens/s, learning rate: 8.510e-06, loss_scalings: 13421.773438, pp_loss: 8.121542
[INFO] 2021-07-12 18:48:00,181 [run_pretraining.py:  512]:	********exe.run_852******* 
[INFO] 2021-07-12 18:48:01,248 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:01,248 [run_pretraining.py:  534]:	loss/total_loss, 7.704280853271484, 853
[INFO] 2021-07-12 18:48:01,248 [run_pretraining.py:  535]:	loss/mlm_loss, 7.704280853271484, 853
[INFO] 2021-07-12 18:48:01,248 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.519999028067105e-06, 853
[INFO] 2021-07-12 18:48:01,249 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 853
[INFO] 2021-07-12 18:48:01,249 [run_pretraining.py:  558]:	worker_index: 6, step: 853, cost: 7.704281, mlm loss: 7.704281, speed: 0.936925 steps/s, speed: 7.495398 samples/s, speed: 3837.643906 tokens/s, learning rate: 8.520e-06, loss_scalings: 13421.773438, pp_loss: 8.188443
[INFO] 2021-07-12 18:48:01,249 [run_pretraining.py:  512]:	********exe.run_853******* 
[INFO] 2021-07-12 18:48:02,366 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:02,367 [run_pretraining.py:  534]:	loss/total_loss, 7.691501617431641, 854
[INFO] 2021-07-12 18:48:02,367 [run_pretraining.py:  535]:	loss/mlm_loss, 7.691501617431641, 854
[INFO] 2021-07-12 18:48:02,367 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.5299998318078e-06, 854
[INFO] 2021-07-12 18:48:02,367 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 854
[INFO] 2021-07-12 18:48:02,367 [run_pretraining.py:  558]:	worker_index: 6, step: 854, cost: 7.691502, mlm loss: 7.691502, speed: 0.894500 steps/s, speed: 7.156001 samples/s, speed: 3663.872573 tokens/s, learning rate: 8.530e-06, loss_scalings: 13421.773438, pp_loss: 8.197424
[INFO] 2021-07-12 18:48:02,367 [run_pretraining.py:  512]:	********exe.run_854******* 
[INFO] 2021-07-12 18:48:03,427 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:03,428 [run_pretraining.py:  534]:	loss/total_loss, 8.022181510925293, 855
[INFO] 2021-07-12 18:48:03,428 [run_pretraining.py:  535]:	loss/mlm_loss, 8.022181510925293, 855
[INFO] 2021-07-12 18:48:03,428 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.539999726053793e-06, 855
[INFO] 2021-07-12 18:48:03,428 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 855
[INFO] 2021-07-12 18:48:03,428 [run_pretraining.py:  558]:	worker_index: 6, step: 855, cost: 8.022182, mlm loss: 8.022182, speed: 0.943220 steps/s, speed: 7.545758 samples/s, speed: 3863.428165 tokens/s, learning rate: 8.540e-06, loss_scalings: 13421.773438, pp_loss: 8.016956
[INFO] 2021-07-12 18:48:03,428 [run_pretraining.py:  512]:	********exe.run_855******* 
[INFO] 2021-07-12 18:48:04,499 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:04,500 [run_pretraining.py:  534]:	loss/total_loss, 7.961994171142578, 856
[INFO] 2021-07-12 18:48:04,500 [run_pretraining.py:  535]:	loss/mlm_loss, 7.961994171142578, 856
[INFO] 2021-07-12 18:48:04,500 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.549999620299786e-06, 856
[INFO] 2021-07-12 18:48:04,500 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 856
[INFO] 2021-07-12 18:48:04,500 [run_pretraining.py:  558]:	worker_index: 6, step: 856, cost: 7.961994, mlm loss: 7.961994, speed: 0.933354 steps/s, speed: 7.466828 samples/s, speed: 3823.015974 tokens/s, learning rate: 8.550e-06, loss_scalings: 13421.773438, pp_loss: 8.090818
[INFO] 2021-07-12 18:48:04,500 [run_pretraining.py:  512]:	********exe.run_856******* 
[INFO] 2021-07-12 18:48:05,528 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:05,529 [run_pretraining.py:  534]:	loss/total_loss, 8.577588081359863, 857
[INFO] 2021-07-12 18:48:05,529 [run_pretraining.py:  535]:	loss/mlm_loss, 8.577588081359863, 857
[INFO] 2021-07-12 18:48:05,529 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.560000424040481e-06, 857
[INFO] 2021-07-12 18:48:05,529 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 857
[INFO] 2021-07-12 18:48:05,529 [run_pretraining.py:  558]:	worker_index: 6, step: 857, cost: 8.577588, mlm loss: 8.577588, speed: 0.972464 steps/s, speed: 7.779715 samples/s, speed: 3983.214076 tokens/s, learning rate: 8.560e-06, loss_scalings: 13421.773438, pp_loss: 8.198078
[INFO] 2021-07-12 18:48:05,529 [run_pretraining.py:  512]:	********exe.run_857******* 
[INFO] 2021-07-12 18:48:06,450 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:06,451 [run_pretraining.py:  534]:	loss/total_loss, 8.36013126373291, 858
[INFO] 2021-07-12 18:48:06,451 [run_pretraining.py:  535]:	loss/mlm_loss, 8.36013126373291, 858
[INFO] 2021-07-12 18:48:06,451 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.569999408791773e-06, 858
[INFO] 2021-07-12 18:48:06,451 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 858
[INFO] 2021-07-12 18:48:06,451 [run_pretraining.py:  558]:	worker_index: 6, step: 858, cost: 8.360131, mlm loss: 8.360131, speed: 1.085689 steps/s, speed: 8.685514 samples/s, speed: 4446.982962 tokens/s, learning rate: 8.570e-06, loss_scalings: 13421.773438, pp_loss: 8.229519
[INFO] 2021-07-12 18:48:06,451 [run_pretraining.py:  512]:	********exe.run_858******* 
[INFO] 2021-07-12 18:48:07,364 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:07,364 [run_pretraining.py:  534]:	loss/total_loss, 5.296933650970459, 859
[INFO] 2021-07-12 18:48:07,364 [run_pretraining.py:  535]:	loss/mlm_loss, 5.296933650970459, 859
[INFO] 2021-07-12 18:48:07,364 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.579999303037766e-06, 859
[INFO] 2021-07-12 18:48:07,364 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 859
[INFO] 2021-07-12 18:48:07,365 [run_pretraining.py:  558]:	worker_index: 6, step: 859, cost: 5.296934, mlm loss: 5.296934, speed: 1.095629 steps/s, speed: 8.765031 samples/s, speed: 4487.695883 tokens/s, learning rate: 8.580e-06, loss_scalings: 13421.773438, pp_loss: 7.649802
[INFO] 2021-07-12 18:48:07,365 [run_pretraining.py:  512]:	********exe.run_859******* 
[INFO] 2021-07-12 18:48:08,317 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:08,318 [run_pretraining.py:  534]:	loss/total_loss, 7.563105583190918, 860
[INFO] 2021-07-12 18:48:08,318 [run_pretraining.py:  535]:	loss/mlm_loss, 7.563105583190918, 860
[INFO] 2021-07-12 18:48:08,318 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.590000106778461e-06, 860
[INFO] 2021-07-12 18:48:08,318 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 860
[INFO] 2021-07-12 18:48:08,319 [run_pretraining.py:  558]:	worker_index: 6, step: 860, cost: 7.563106, mlm loss: 7.563106, speed: 1.049030 steps/s, speed: 8.392240 samples/s, speed: 4296.826748 tokens/s, learning rate: 8.590e-06, loss_scalings: 13421.773438, pp_loss: 8.057171
[INFO] 2021-07-12 18:48:08,319 [run_pretraining.py:  512]:	********exe.run_860******* 
[INFO] 2021-07-12 18:48:09,228 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:09,229 [run_pretraining.py:  534]:	loss/total_loss, 8.172074317932129, 861
[INFO] 2021-07-12 18:48:09,229 [run_pretraining.py:  535]:	loss/mlm_loss, 8.172074317932129, 861
[INFO] 2021-07-12 18:48:09,229 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.600000001024455e-06, 861
[INFO] 2021-07-12 18:48:09,229 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 861
[INFO] 2021-07-12 18:48:09,229 [run_pretraining.py:  558]:	worker_index: 6, step: 861, cost: 8.172074, mlm loss: 8.172074, speed: 1.098640 steps/s, speed: 8.789124 samples/s, speed: 4500.031481 tokens/s, learning rate: 8.600e-06, loss_scalings: 13421.773438, pp_loss: 7.984142
[INFO] 2021-07-12 18:48:09,230 [run_pretraining.py:  512]:	********exe.run_861******* 
[INFO] 2021-07-12 18:48:10,160 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:10,160 [run_pretraining.py:  534]:	loss/total_loss, 8.207987785339355, 862
[INFO] 2021-07-12 18:48:10,160 [run_pretraining.py:  535]:	loss/mlm_loss, 8.207987785339355, 862
[INFO] 2021-07-12 18:48:10,161 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.609999895270448e-06, 862
[INFO] 2021-07-12 18:48:10,161 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 862
[INFO] 2021-07-12 18:48:10,161 [run_pretraining.py:  558]:	worker_index: 6, step: 862, cost: 8.207988, mlm loss: 8.207988, speed: 1.074615 steps/s, speed: 8.596922 samples/s, speed: 4401.624151 tokens/s, learning rate: 8.610e-06, loss_scalings: 13421.773438, pp_loss: 8.148444
[INFO] 2021-07-12 18:48:10,161 [run_pretraining.py:  512]:	********exe.run_862******* 
[INFO] 2021-07-12 18:48:11,077 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:11,077 [run_pretraining.py:  534]:	loss/total_loss, 8.492955207824707, 863
[INFO] 2021-07-12 18:48:11,077 [run_pretraining.py:  535]:	loss/mlm_loss, 8.492955207824707, 863
[INFO] 2021-07-12 18:48:11,077 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.619999789516442e-06, 863
[INFO] 2021-07-12 18:48:11,077 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 863
[INFO] 2021-07-12 18:48:11,078 [run_pretraining.py:  558]:	worker_index: 6, step: 863, cost: 8.492955, mlm loss: 8.492955, speed: 1.091524 steps/s, speed: 8.732196 samples/s, speed: 4470.884298 tokens/s, learning rate: 8.620e-06, loss_scalings: 13421.773438, pp_loss: 8.288056
[INFO] 2021-07-12 18:48:11,078 [run_pretraining.py:  512]:	********exe.run_863******* 
[INFO] 2021-07-12 18:48:12,001 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:12,002 [run_pretraining.py:  534]:	loss/total_loss, 8.589494705200195, 864
[INFO] 2021-07-12 18:48:12,002 [run_pretraining.py:  535]:	loss/mlm_loss, 8.589494705200195, 864
[INFO] 2021-07-12 18:48:12,002 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.629999683762435e-06, 864
[INFO] 2021-07-12 18:48:12,002 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 864
[INFO] 2021-07-12 18:48:12,002 [run_pretraining.py:  558]:	worker_index: 6, step: 864, cost: 8.589495, mlm loss: 8.589495, speed: 1.082663 steps/s, speed: 8.661305 samples/s, speed: 4434.588085 tokens/s, learning rate: 8.630e-06, loss_scalings: 13421.773438, pp_loss: 8.204388
[INFO] 2021-07-12 18:48:12,002 [run_pretraining.py:  512]:	********exe.run_864******* 
[INFO] 2021-07-12 18:48:12,913 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:12,914 [run_pretraining.py:  534]:	loss/total_loss, 7.8836565017700195, 865
[INFO] 2021-07-12 18:48:12,914 [run_pretraining.py:  535]:	loss/mlm_loss, 7.8836565017700195, 865
[INFO] 2021-07-12 18:48:12,914 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.639999578008428e-06, 865
[INFO] 2021-07-12 18:48:12,914 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 865
[INFO] 2021-07-12 18:48:12,914 [run_pretraining.py:  558]:	worker_index: 6, step: 865, cost: 7.883657, mlm loss: 7.883657, speed: 1.097009 steps/s, speed: 8.776069 samples/s, speed: 4493.347463 tokens/s, learning rate: 8.640e-06, loss_scalings: 13421.773438, pp_loss: 8.186376
[INFO] 2021-07-12 18:48:12,914 [run_pretraining.py:  512]:	********exe.run_865******* 
[INFO] 2021-07-12 18:48:13,836 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:13,837 [run_pretraining.py:  534]:	loss/total_loss, 8.274864196777344, 866
[INFO] 2021-07-12 18:48:13,837 [run_pretraining.py:  535]:	loss/mlm_loss, 8.274864196777344, 866
[INFO] 2021-07-12 18:48:13,837 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.649999472254422e-06, 866
[INFO] 2021-07-12 18:48:13,837 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 866
[INFO] 2021-07-12 18:48:13,837 [run_pretraining.py:  558]:	worker_index: 6, step: 866, cost: 8.274864, mlm loss: 8.274864, speed: 1.084451 steps/s, speed: 8.675610 samples/s, speed: 4441.912422 tokens/s, learning rate: 8.650e-06, loss_scalings: 13421.773438, pp_loss: 8.161023
[INFO] 2021-07-12 18:48:13,837 [run_pretraining.py:  512]:	********exe.run_866******* 
[INFO] 2021-07-12 18:48:14,750 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:14,750 [run_pretraining.py:  534]:	loss/total_loss, 8.130464553833008, 867
[INFO] 2021-07-12 18:48:14,750 [run_pretraining.py:  535]:	loss/mlm_loss, 8.130464553833008, 867
[INFO] 2021-07-12 18:48:14,750 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.659999366500415e-06, 867
[INFO] 2021-07-12 18:48:14,750 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 867
[INFO] 2021-07-12 18:48:14,751 [run_pretraining.py:  558]:	worker_index: 6, step: 867, cost: 8.130465, mlm loss: 8.130465, speed: 1.095457 steps/s, speed: 8.763660 samples/s, speed: 4486.993805 tokens/s, learning rate: 8.660e-06, loss_scalings: 13421.773438, pp_loss: 7.995234
[INFO] 2021-07-12 18:48:14,751 [run_pretraining.py:  512]:	********exe.run_867******* 
[INFO] 2021-07-12 18:48:15,663 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:15,664 [run_pretraining.py:  534]:	loss/total_loss, 8.12513542175293, 868
[INFO] 2021-07-12 18:48:15,664 [run_pretraining.py:  535]:	loss/mlm_loss, 8.12513542175293, 868
[INFO] 2021-07-12 18:48:15,664 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.67000017024111e-06, 868
[INFO] 2021-07-12 18:48:15,664 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 868
[INFO] 2021-07-12 18:48:15,664 [run_pretraining.py:  558]:	worker_index: 6, step: 868, cost: 8.125135, mlm loss: 8.125135, speed: 1.095310 steps/s, speed: 8.762483 samples/s, speed: 4486.391528 tokens/s, learning rate: 8.670e-06, loss_scalings: 13421.773438, pp_loss: 7.897492
[INFO] 2021-07-12 18:48:15,664 [run_pretraining.py:  512]:	********exe.run_868******* 
[INFO] 2021-07-12 18:48:16,591 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:16,597 [run_pretraining.py:  534]:	loss/total_loss, 7.70030403137207, 869
[INFO] 2021-07-12 18:48:16,602 [run_pretraining.py:  535]:	loss/mlm_loss, 7.70030403137207, 869
[INFO] 2021-07-12 18:48:16,607 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.680000064487103e-06, 869
[INFO] 2021-07-12 18:48:16,613 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 869
[INFO] 2021-07-12 18:48:16,618 [run_pretraining.py:  558]:	worker_index: 6, step: 869, cost: 7.700304, mlm loss: 7.700304, speed: 1.072324 steps/s, speed: 8.578589 samples/s, speed: 4392.237794 tokens/s, learning rate: 8.680e-06, loss_scalings: 13421.773438, pp_loss: 7.936752
[INFO] 2021-07-12 18:48:16,623 [run_pretraining.py:  512]:	********exe.run_869******* 
[INFO] 2021-07-12 18:48:17,501 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:17,502 [run_pretraining.py:  534]:	loss/total_loss, 8.766870498657227, 870
[INFO] 2021-07-12 18:48:17,502 [run_pretraining.py:  535]:	loss/mlm_loss, 8.766870498657227, 870
[INFO] 2021-07-12 18:48:17,502 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.689999958733097e-06, 870
[INFO] 2021-07-12 18:48:17,502 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 870
[INFO] 2021-07-12 18:48:17,502 [run_pretraining.py:  558]:	worker_index: 6, step: 870, cost: 8.766870, mlm loss: 8.766870, speed: 1.138328 steps/s, speed: 9.106624 samples/s, speed: 4662.591667 tokens/s, learning rate: 8.690e-06, loss_scalings: 13421.773438, pp_loss: 8.276953
[INFO] 2021-07-12 18:48:17,502 [run_pretraining.py:  512]:	********exe.run_870******* 
[INFO] 2021-07-12 18:48:44,182 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:44,182 [run_pretraining.py:  534]:	loss/total_loss, 7.945589542388916, 871
[INFO] 2021-07-12 18:48:44,183 [run_pretraining.py:  535]:	loss/mlm_loss, 7.945589542388916, 871
[INFO] 2021-07-12 18:48:44,183 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.69999985297909e-06, 871
[INFO] 2021-07-12 18:48:44,183 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 871
[INFO] 2021-07-12 18:48:44,183 [run_pretraining.py:  558]:	worker_index: 6, step: 871, cost: 7.945590, mlm loss: 7.945590, speed: 0.037481 steps/s, speed: 0.299850 samples/s, speed: 153.523397 tokens/s, learning rate: 8.700e-06, loss_scalings: 13421.773438, pp_loss: 8.169767
[INFO] 2021-07-12 18:48:44,183 [run_pretraining.py:  512]:	********exe.run_871******* 
[INFO] 2021-07-12 18:48:45,080 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:45,081 [run_pretraining.py:  534]:	loss/total_loss, 8.050483703613281, 872
[INFO] 2021-07-12 18:48:45,081 [run_pretraining.py:  535]:	loss/mlm_loss, 8.050483703613281, 872
[INFO] 2021-07-12 18:48:45,081 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.709999747225083e-06, 872
[INFO] 2021-07-12 18:48:45,081 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 872
[INFO] 2021-07-12 18:48:45,081 [run_pretraining.py:  558]:	worker_index: 6, step: 872, cost: 8.050484, mlm loss: 8.050484, speed: 1.114355 steps/s, speed: 8.914840 samples/s, speed: 4564.398005 tokens/s, learning rate: 8.710e-06, loss_scalings: 13421.773438, pp_loss: 8.209199
[INFO] 2021-07-12 18:48:45,081 [run_pretraining.py:  512]:	********exe.run_872******* 
[INFO] 2021-07-12 18:49:12,291 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:12,292 [run_pretraining.py:  534]:	loss/total_loss, 8.639362335205078, 873
[INFO] 2021-07-12 18:49:12,292 [run_pretraining.py:  535]:	loss/mlm_loss, 8.639362335205078, 873
[INFO] 2021-07-12 18:49:12,292 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.719999641471077e-06, 873
[INFO] 2021-07-12 18:49:12,292 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 873
[INFO] 2021-07-12 18:49:12,292 [run_pretraining.py:  558]:	worker_index: 6, step: 873, cost: 8.639362, mlm loss: 8.639362, speed: 0.036751 steps/s, speed: 0.294006 samples/s, speed: 150.531235 tokens/s, learning rate: 8.720e-06, loss_scalings: 13421.773438, pp_loss: 8.272333
[INFO] 2021-07-12 18:49:12,292 [run_pretraining.py:  512]:	********exe.run_873******* 
[INFO] 2021-07-12 18:49:13,248 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:13,249 [run_pretraining.py:  534]:	loss/total_loss, 7.937170505523682, 874
[INFO] 2021-07-12 18:49:13,249 [run_pretraining.py:  535]:	loss/mlm_loss, 7.937170505523682, 874
[INFO] 2021-07-12 18:49:13,249 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.730000445211772e-06, 874
[INFO] 2021-07-12 18:49:13,249 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 874
[INFO] 2021-07-12 18:49:13,249 [run_pretraining.py:  558]:	worker_index: 6, step: 874, cost: 7.937171, mlm loss: 7.937171, speed: 1.045495 steps/s, speed: 8.363959 samples/s, speed: 4282.347219 tokens/s, learning rate: 8.730e-06, loss_scalings: 13421.773438, pp_loss: 8.003184
[INFO] 2021-07-12 18:49:13,249 [run_pretraining.py:  512]:	********exe.run_874******* 
[INFO] 2021-07-12 18:49:14,152 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:14,153 [run_pretraining.py:  534]:	loss/total_loss, 8.255741119384766, 875
[INFO] 2021-07-12 18:49:14,153 [run_pretraining.py:  535]:	loss/mlm_loss, 8.255741119384766, 875
[INFO] 2021-07-12 18:49:14,153 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.739999429963063e-06, 875
[INFO] 2021-07-12 18:49:14,153 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 875
[INFO] 2021-07-12 18:49:14,153 [run_pretraining.py:  558]:	worker_index: 6, step: 875, cost: 8.255741, mlm loss: 8.255741, speed: 1.106910 steps/s, speed: 8.855284 samples/s, speed: 4533.905235 tokens/s, learning rate: 8.740e-06, loss_scalings: 13421.773438, pp_loss: 8.234966
[INFO] 2021-07-12 18:49:14,153 [run_pretraining.py:  512]:	********exe.run_875******* 
[INFO] 2021-07-12 18:49:40,897 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:40,898 [run_pretraining.py:  534]:	loss/total_loss, 8.016618728637695, 876
[INFO] 2021-07-12 18:49:40,898 [run_pretraining.py:  535]:	loss/mlm_loss, 8.016618728637695, 876
[INFO] 2021-07-12 18:49:40,898 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.749999324209057e-06, 876
[INFO] 2021-07-12 18:49:40,898 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 876
[INFO] 2021-07-12 18:49:40,898 [run_pretraining.py:  558]:	worker_index: 6, step: 876, cost: 8.016619, mlm loss: 8.016619, speed: 0.037391 steps/s, speed: 0.299128 samples/s, speed: 153.153769 tokens/s, learning rate: 8.750e-06, loss_scalings: 13421.773438, pp_loss: 8.084261
[INFO] 2021-07-12 18:49:40,898 [run_pretraining.py:  512]:	********exe.run_876******* 
[INFO] 2021-07-12 18:49:41,837 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:41,837 [run_pretraining.py:  534]:	loss/total_loss, 7.662655353546143, 877
[INFO] 2021-07-12 18:49:41,837 [run_pretraining.py:  535]:	loss/mlm_loss, 7.662655353546143, 877
[INFO] 2021-07-12 18:49:41,837 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.760000127949752e-06, 877
[INFO] 2021-07-12 18:49:41,837 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 877
[INFO] 2021-07-12 18:49:41,838 [run_pretraining.py:  558]:	worker_index: 6, step: 877, cost: 7.662655, mlm loss: 7.662655, speed: 1.065556 steps/s, speed: 8.524447 samples/s, speed: 4364.516965 tokens/s, learning rate: 8.760e-06, loss_scalings: 13421.773438, pp_loss: 8.042178
[INFO] 2021-07-12 18:49:41,838 [run_pretraining.py:  512]:	********exe.run_877******* 
[INFO] 2021-07-12 18:49:42,770 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:42,770 [run_pretraining.py:  534]:	loss/total_loss, 7.785675048828125, 878
[INFO] 2021-07-12 18:49:42,770 [run_pretraining.py:  535]:	loss/mlm_loss, 7.785675048828125, 878
[INFO] 2021-07-12 18:49:42,770 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.770000022195745e-06, 878
[INFO] 2021-07-12 18:49:42,771 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 878
[INFO] 2021-07-12 18:49:42,771 [run_pretraining.py:  558]:	worker_index: 6, step: 878, cost: 7.785675, mlm loss: 7.785675, speed: 1.072473 steps/s, speed: 8.579785 samples/s, speed: 4392.849875 tokens/s, learning rate: 8.770e-06, loss_scalings: 13421.773438, pp_loss: 8.110665
[INFO] 2021-07-12 18:49:42,771 [run_pretraining.py:  512]:	********exe.run_878******* 
[INFO] 2021-07-12 18:49:43,788 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:43,789 [run_pretraining.py:  534]:	loss/total_loss, 8.023033142089844, 879
[INFO] 2021-07-12 18:49:43,789 [run_pretraining.py:  535]:	loss/mlm_loss, 8.023033142089844, 879
[INFO] 2021-07-12 18:49:43,789 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.779999916441739e-06, 879
[INFO] 2021-07-12 18:49:43,789 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 879
[INFO] 2021-07-12 18:49:43,789 [run_pretraining.py:  558]:	worker_index: 6, step: 879, cost: 8.023033, mlm loss: 8.023033, speed: 0.982245 steps/s, speed: 7.857960 samples/s, speed: 4023.275501 tokens/s, learning rate: 8.780e-06, loss_scalings: 13421.773438, pp_loss: 8.073938
[INFO] 2021-07-12 18:49:43,789 [run_pretraining.py:  512]:	********exe.run_879******* 
[INFO] 2021-07-12 18:49:44,718 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:44,719 [run_pretraining.py:  534]:	loss/total_loss, 8.33276653289795, 880
[INFO] 2021-07-12 18:49:44,719 [run_pretraining.py:  535]:	loss/mlm_loss, 8.33276653289795, 880
[INFO] 2021-07-12 18:49:44,719 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.789999810687732e-06, 880
[INFO] 2021-07-12 18:49:44,719 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 880
[INFO] 2021-07-12 18:49:44,719 [run_pretraining.py:  558]:	worker_index: 6, step: 880, cost: 8.332767, mlm loss: 8.332767, speed: 1.076188 steps/s, speed: 8.609502 samples/s, speed: 4408.065020 tokens/s, learning rate: 8.790e-06, loss_scalings: 13421.773438, pp_loss: 8.106318
[INFO] 2021-07-12 18:49:44,719 [run_pretraining.py:  512]:	********exe.run_880******* 
[INFO] 2021-07-12 18:49:45,715 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:45,716 [run_pretraining.py:  534]:	loss/total_loss, 8.120340347290039, 881
[INFO] 2021-07-12 18:49:45,716 [run_pretraining.py:  535]:	loss/mlm_loss, 8.120340347290039, 881
[INFO] 2021-07-12 18:49:45,716 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.799999704933725e-06, 881
[INFO] 2021-07-12 18:49:45,716 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 881
[INFO] 2021-07-12 18:49:45,716 [run_pretraining.py:  558]:	worker_index: 6, step: 881, cost: 8.120340, mlm loss: 8.120340, speed: 1.003989 steps/s, speed: 8.031913 samples/s, speed: 4112.339334 tokens/s, learning rate: 8.800e-06, loss_scalings: 13421.773438, pp_loss: 8.146318
[INFO] 2021-07-12 18:49:45,716 [run_pretraining.py:  512]:	********exe.run_881******* 
[INFO] 2021-07-12 18:49:46,781 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:46,782 [run_pretraining.py:  534]:	loss/total_loss, 8.239531517028809, 882
[INFO] 2021-07-12 18:49:46,782 [run_pretraining.py:  535]:	loss/mlm_loss, 8.239531517028809, 882
[INFO] 2021-07-12 18:49:46,782 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.809999599179719e-06, 882
[INFO] 2021-07-12 18:49:46,782 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 882
[INFO] 2021-07-12 18:49:46,782 [run_pretraining.py:  558]:	worker_index: 6, step: 882, cost: 8.239532, mlm loss: 8.239532, speed: 0.938508 steps/s, speed: 7.508061 samples/s, speed: 3844.127108 tokens/s, learning rate: 8.810e-06, loss_scalings: 13421.773438, pp_loss: 8.050411
[INFO] 2021-07-12 18:49:46,782 [run_pretraining.py:  512]:	********exe.run_882******* 
[INFO] 2021-07-12 18:49:47,841 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:47,842 [run_pretraining.py:  534]:	loss/total_loss, 8.052791595458984, 883
[INFO] 2021-07-12 18:49:47,842 [run_pretraining.py:  535]:	loss/mlm_loss, 8.052791595458984, 883
[INFO] 2021-07-12 18:49:47,842 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.820000402920414e-06, 883
[INFO] 2021-07-12 18:49:47,842 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 883
[INFO] 2021-07-12 18:49:47,842 [run_pretraining.py:  558]:	worker_index: 6, step: 883, cost: 8.052792, mlm loss: 8.052792, speed: 0.943968 steps/s, speed: 7.551746 samples/s, speed: 3866.494027 tokens/s, learning rate: 8.820e-06, loss_scalings: 13421.773438, pp_loss: 7.993948
[INFO] 2021-07-12 18:49:47,842 [run_pretraining.py:  512]:	********exe.run_883******* 
[INFO] 2021-07-12 18:49:48,905 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:48,906 [run_pretraining.py:  534]:	loss/total_loss, 8.19372844696045, 884
[INFO] 2021-07-12 18:49:48,906 [run_pretraining.py:  535]:	loss/mlm_loss, 8.19372844696045, 884
[INFO] 2021-07-12 18:49:48,906 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.829999387671705e-06, 884
[INFO] 2021-07-12 18:49:48,906 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 884
[INFO] 2021-07-12 18:49:48,906 [run_pretraining.py:  558]:	worker_index: 6, step: 884, cost: 8.193728, mlm loss: 8.193728, speed: 0.940452 steps/s, speed: 7.523616 samples/s, speed: 3852.091386 tokens/s, learning rate: 8.830e-06, loss_scalings: 13421.773438, pp_loss: 8.077471
[INFO] 2021-07-12 18:49:48,906 [run_pretraining.py:  512]:	********exe.run_884******* 
[INFO] 2021-07-12 18:49:49,981 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:49,981 [run_pretraining.py:  534]:	loss/total_loss, 8.664532661437988, 885
[INFO] 2021-07-12 18:49:49,981 [run_pretraining.py:  535]:	loss/mlm_loss, 8.664532661437988, 885
[INFO] 2021-07-12 18:49:49,982 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.839999281917699e-06, 885
[INFO] 2021-07-12 18:49:49,982 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 885
[INFO] 2021-07-12 18:49:49,982 [run_pretraining.py:  558]:	worker_index: 6, step: 885, cost: 8.664533, mlm loss: 8.664533, speed: 0.930507 steps/s, speed: 7.444054 samples/s, speed: 3811.355793 tokens/s, learning rate: 8.840e-06, loss_scalings: 13421.773438, pp_loss: 8.319556
[INFO] 2021-07-12 18:49:49,982 [run_pretraining.py:  512]:	********exe.run_885******* 
[INFO] 2021-07-12 18:49:51,066 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:51,067 [run_pretraining.py:  534]:	loss/total_loss, 7.965698719024658, 886
[INFO] 2021-07-12 18:49:51,067 [run_pretraining.py:  535]:	loss/mlm_loss, 7.965698719024658, 886
[INFO] 2021-07-12 18:49:51,067 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.850000085658394e-06, 886
[INFO] 2021-07-12 18:49:51,067 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 886
[INFO] 2021-07-12 18:49:51,067 [run_pretraining.py:  558]:	worker_index: 6, step: 886, cost: 7.965699, mlm loss: 7.965699, speed: 0.921915 steps/s, speed: 7.375319 samples/s, speed: 3776.163082 tokens/s, learning rate: 8.850e-06, loss_scalings: 13421.773438, pp_loss: 7.780670
[INFO] 2021-07-12 18:49:51,067 [run_pretraining.py:  512]:	********exe.run_886******* 
[INFO] 2021-07-12 18:49:52,139 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:52,140 [run_pretraining.py:  534]:	loss/total_loss, 8.855856895446777, 887
[INFO] 2021-07-12 18:49:52,140 [run_pretraining.py:  535]:	loss/mlm_loss, 8.855856895446777, 887
[INFO] 2021-07-12 18:49:52,140 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.859999979904387e-06, 887
[INFO] 2021-07-12 18:49:52,140 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 887
[INFO] 2021-07-12 18:49:52,140 [run_pretraining.py:  558]:	worker_index: 6, step: 887, cost: 8.855857, mlm loss: 8.855857, speed: 0.932476 steps/s, speed: 7.459805 samples/s, speed: 3819.419916 tokens/s, learning rate: 8.860e-06, loss_scalings: 13421.773438, pp_loss: 8.283750
[INFO] 2021-07-12 18:49:52,140 [run_pretraining.py:  512]:	********exe.run_887******* 
[INFO] 2021-07-12 18:49:53,210 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:53,210 [run_pretraining.py:  534]:	loss/total_loss, 7.846424102783203, 888
[INFO] 2021-07-12 18:49:53,211 [run_pretraining.py:  535]:	loss/mlm_loss, 7.846424102783203, 888
[INFO] 2021-07-12 18:49:53,211 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.86999987415038e-06, 888
[INFO] 2021-07-12 18:49:53,211 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 888
[INFO] 2021-07-12 18:49:53,211 [run_pretraining.py:  558]:	worker_index: 6, step: 888, cost: 7.846424, mlm loss: 7.846424, speed: 0.934647 steps/s, speed: 7.477179 samples/s, speed: 3828.315710 tokens/s, learning rate: 8.870e-06, loss_scalings: 13421.773438, pp_loss: 8.122108
[INFO] 2021-07-12 18:49:53,211 [run_pretraining.py:  512]:	********exe.run_888******* 
[INFO] 2021-07-12 18:49:54,284 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:54,284 [run_pretraining.py:  534]:	loss/total_loss, 8.033720970153809, 889
[INFO] 2021-07-12 18:49:54,284 [run_pretraining.py:  535]:	loss/mlm_loss, 8.033720970153809, 889
[INFO] 2021-07-12 18:49:54,285 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.879999768396374e-06, 889
[INFO] 2021-07-12 18:49:54,285 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 889
[INFO] 2021-07-12 18:49:54,285 [run_pretraining.py:  558]:	worker_index: 6, step: 889, cost: 8.033721, mlm loss: 8.033721, speed: 0.931872 steps/s, speed: 7.454977 samples/s, speed: 3816.947997 tokens/s, learning rate: 8.880e-06, loss_scalings: 13421.773438, pp_loss: 7.767314
[INFO] 2021-07-12 18:49:54,285 [run_pretraining.py:  512]:	********exe.run_889******* 
[INFO] 2021-07-12 18:49:55,191 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:55,192 [run_pretraining.py:  534]:	loss/total_loss, 7.074587345123291, 890
[INFO] 2021-07-12 18:49:55,192 [run_pretraining.py:  535]:	loss/mlm_loss, 7.074587345123291, 890
[INFO] 2021-07-12 18:49:55,192 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.889999662642367e-06, 890
[INFO] 2021-07-12 18:49:55,192 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 890
[INFO] 2021-07-12 18:49:55,192 [run_pretraining.py:  558]:	worker_index: 6, step: 890, cost: 7.074587, mlm loss: 7.074587, speed: 1.102745 steps/s, speed: 8.821960 samples/s, speed: 4516.843692 tokens/s, learning rate: 8.890e-06, loss_scalings: 13421.773438, pp_loss: 7.820481
[INFO] 2021-07-12 18:49:55,192 [run_pretraining.py:  512]:	********exe.run_890******* 
[INFO] 2021-07-12 18:49:56,103 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:56,104 [run_pretraining.py:  534]:	loss/total_loss, 7.505174160003662, 891
[INFO] 2021-07-12 18:49:56,104 [run_pretraining.py:  535]:	loss/mlm_loss, 7.505174160003662, 891
[INFO] 2021-07-12 18:49:56,104 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.89999955688836e-06, 891
[INFO] 2021-07-12 18:49:56,104 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 891
[INFO] 2021-07-12 18:49:56,104 [run_pretraining.py:  558]:	worker_index: 6, step: 891, cost: 7.505174, mlm loss: 7.505174, speed: 1.097543 steps/s, speed: 8.780341 samples/s, speed: 4495.534441 tokens/s, learning rate: 8.900e-06, loss_scalings: 13421.773438, pp_loss: 7.796913
[INFO] 2021-07-12 18:49:56,104 [run_pretraining.py:  512]:	********exe.run_891******* 
[INFO] 2021-07-12 18:49:57,016 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:57,016 [run_pretraining.py:  534]:	loss/total_loss, 7.981408596038818, 892
[INFO] 2021-07-12 18:49:57,016 [run_pretraining.py:  535]:	loss/mlm_loss, 7.981408596038818, 892
[INFO] 2021-07-12 18:49:57,016 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.910000360629056e-06, 892
[INFO] 2021-07-12 18:49:57,016 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 892
[INFO] 2021-07-12 18:49:57,017 [run_pretraining.py:  558]:	worker_index: 6, step: 892, cost: 7.981409, mlm loss: 7.981409, speed: 1.096808 steps/s, speed: 8.774463 samples/s, speed: 4492.524958 tokens/s, learning rate: 8.910e-06, loss_scalings: 13421.773438, pp_loss: 8.048394
[INFO] 2021-07-12 18:49:57,017 [run_pretraining.py:  512]:	********exe.run_892******* 
[INFO] 2021-07-12 18:49:57,926 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:57,926 [run_pretraining.py:  534]:	loss/total_loss, 7.830724716186523, 893
[INFO] 2021-07-12 18:49:57,926 [run_pretraining.py:  535]:	loss/mlm_loss, 7.830724716186523, 893
[INFO] 2021-07-12 18:49:57,926 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.919999345380347e-06, 893
[INFO] 2021-07-12 18:49:57,926 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 893
[INFO] 2021-07-12 18:49:57,927 [run_pretraining.py:  558]:	worker_index: 6, step: 893, cost: 7.830725, mlm loss: 7.830725, speed: 1.099658 steps/s, speed: 8.797263 samples/s, speed: 4504.198581 tokens/s, learning rate: 8.920e-06, loss_scalings: 13421.773438, pp_loss: 8.172146
[INFO] 2021-07-12 18:49:57,927 [run_pretraining.py:  512]:	********exe.run_893******* 
[INFO] 2021-07-12 18:49:58,835 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:58,836 [run_pretraining.py:  534]:	loss/total_loss, 8.29991626739502, 894
[INFO] 2021-07-12 18:49:58,836 [run_pretraining.py:  535]:	loss/mlm_loss, 8.29991626739502, 894
[INFO] 2021-07-12 18:49:58,836 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.92999923962634e-06, 894
[INFO] 2021-07-12 18:49:58,836 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 894
[INFO] 2021-07-12 18:49:58,836 [run_pretraining.py:  558]:	worker_index: 6, step: 894, cost: 8.299916, mlm loss: 8.299916, speed: 1.100025 steps/s, speed: 8.800200 samples/s, speed: 4505.702375 tokens/s, learning rate: 8.930e-06, loss_scalings: 13421.773438, pp_loss: 8.107294
[INFO] 2021-07-12 18:49:58,836 [run_pretraining.py:  512]:	********exe.run_894******* 
[INFO] 2021-07-12 18:49:59,749 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:59,749 [run_pretraining.py:  534]:	loss/total_loss, 8.08777141571045, 895
[INFO] 2021-07-12 18:49:59,749 [run_pretraining.py:  535]:	loss/mlm_loss, 8.08777141571045, 895
[INFO] 2021-07-12 18:49:59,749 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.940000043367036e-06, 895
[INFO] 2021-07-12 18:49:59,750 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 895
[INFO] 2021-07-12 18:49:59,750 [run_pretraining.py:  558]:	worker_index: 6, step: 895, cost: 8.087771, mlm loss: 8.087771, speed: 1.095751 steps/s, speed: 8.766006 samples/s, speed: 4488.195325 tokens/s, learning rate: 8.940e-06, loss_scalings: 13421.773438, pp_loss: 8.142010
[INFO] 2021-07-12 18:49:59,750 [run_pretraining.py:  512]:	********exe.run_895******* 
[INFO] 2021-07-12 18:50:00,677 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:00,678 [run_pretraining.py:  534]:	loss/total_loss, 7.980786323547363, 896
[INFO] 2021-07-12 18:50:00,678 [run_pretraining.py:  535]:	loss/mlm_loss, 7.980786323547363, 896
[INFO] 2021-07-12 18:50:00,678 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.949999937613029e-06, 896
[INFO] 2021-07-12 18:50:00,678 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 896
[INFO] 2021-07-12 18:50:00,678 [run_pretraining.py:  558]:	worker_index: 6, step: 896, cost: 7.980786, mlm loss: 7.980786, speed: 1.077782 steps/s, speed: 8.622258 samples/s, speed: 4414.596232 tokens/s, learning rate: 8.950e-06, loss_scalings: 13421.773438, pp_loss: 7.978012
[INFO] 2021-07-12 18:50:00,678 [run_pretraining.py:  512]:	********exe.run_896******* 
[INFO] 2021-07-12 18:50:01,597 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:01,598 [run_pretraining.py:  534]:	loss/total_loss, 7.714261054992676, 897
[INFO] 2021-07-12 18:50:01,598 [run_pretraining.py:  535]:	loss/mlm_loss, 7.714261054992676, 897
[INFO] 2021-07-12 18:50:01,598 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.959999831859022e-06, 897
[INFO] 2021-07-12 18:50:01,598 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 897
[INFO] 2021-07-12 18:50:01,598 [run_pretraining.py:  558]:	worker_index: 6, step: 897, cost: 7.714261, mlm loss: 7.714261, speed: 1.087614 steps/s, speed: 8.700912 samples/s, speed: 4454.866949 tokens/s, learning rate: 8.960e-06, loss_scalings: 13421.773438, pp_loss: 7.947917
[INFO] 2021-07-12 18:50:01,598 [run_pretraining.py:  512]:	********exe.run_897******* 
[INFO] 2021-07-12 18:50:02,519 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:02,520 [run_pretraining.py:  534]:	loss/total_loss, 8.151128768920898, 898
[INFO] 2021-07-12 18:50:02,520 [run_pretraining.py:  535]:	loss/mlm_loss, 8.151128768920898, 898
[INFO] 2021-07-12 18:50:02,520 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.969999726105016e-06, 898
[INFO] 2021-07-12 18:50:02,520 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 898
[INFO] 2021-07-12 18:50:02,520 [run_pretraining.py:  558]:	worker_index: 6, step: 898, cost: 8.151129, mlm loss: 8.151129, speed: 1.085261 steps/s, speed: 8.682086 samples/s, speed: 4445.228235 tokens/s, learning rate: 8.970e-06, loss_scalings: 13421.773438, pp_loss: 7.188383
[INFO] 2021-07-12 18:50:02,521 [run_pretraining.py:  512]:	********exe.run_898******* 
[INFO] 2021-07-12 18:50:03,432 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:03,433 [run_pretraining.py:  534]:	loss/total_loss, 7.814065933227539, 899
[INFO] 2021-07-12 18:50:03,433 [run_pretraining.py:  535]:	loss/mlm_loss, 7.814065933227539, 899
[INFO] 2021-07-12 18:50:03,433 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.979999620351009e-06, 899
[INFO] 2021-07-12 18:50:03,433 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 899
[INFO] 2021-07-12 18:50:03,433 [run_pretraining.py:  558]:	worker_index: 6, step: 899, cost: 7.814066, mlm loss: 7.814066, speed: 1.096592 steps/s, speed: 8.772738 samples/s, speed: 4491.641688 tokens/s, learning rate: 8.980e-06, loss_scalings: 13421.773438, pp_loss: 8.153402
[INFO] 2021-07-12 18:50:03,433 [run_pretraining.py:  512]:	********exe.run_899******* 
[INFO] 2021-07-12 18:50:04,358 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:04,358 [run_pretraining.py:  534]:	loss/total_loss, 7.8358001708984375, 900
[INFO] 2021-07-12 18:50:04,358 [run_pretraining.py:  535]:	loss/mlm_loss, 7.8358001708984375, 900
[INFO] 2021-07-12 18:50:04,358 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.989999514597002e-06, 900
[INFO] 2021-07-12 18:50:04,358 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 900
[INFO] 2021-07-12 18:50:04,359 [run_pretraining.py:  558]:	worker_index: 6, step: 900, cost: 7.835800, mlm loss: 7.835800, speed: 1.081350 steps/s, speed: 8.650801 samples/s, speed: 4429.210008 tokens/s, learning rate: 8.990e-06, loss_scalings: 13421.773438, pp_loss: 7.929093
[INFO] 2021-07-12 18:50:04,359 [run_pretraining.py:  512]:	********exe.run_900******* 
[INFO] 2021-07-12 18:50:05,421 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:05,421 [run_pretraining.py:  534]:	loss/total_loss, 7.876625061035156, 901
[INFO] 2021-07-12 18:50:05,421 [run_pretraining.py:  535]:	loss/mlm_loss, 7.876625061035156, 901
[INFO] 2021-07-12 18:50:05,421 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.000000318337698e-06, 901
[INFO] 2021-07-12 18:50:05,421 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 901
[INFO] 2021-07-12 18:50:05,422 [run_pretraining.py:  558]:	worker_index: 6, step: 901, cost: 7.876625, mlm loss: 7.876625, speed: 0.941391 steps/s, speed: 7.531127 samples/s, speed: 3855.937051 tokens/s, learning rate: 9.000e-06, loss_scalings: 13421.773438, pp_loss: 7.186749
[INFO] 2021-07-12 18:50:05,422 [run_pretraining.py:  512]:	********exe.run_901******* 
[INFO] 2021-07-12 18:50:06,476 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:06,476 [run_pretraining.py:  534]:	loss/total_loss, 7.974259376525879, 902
[INFO] 2021-07-12 18:50:06,477 [run_pretraining.py:  535]:	loss/mlm_loss, 7.974259376525879, 902
[INFO] 2021-07-12 18:50:06,477 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.009999303088989e-06, 902
[INFO] 2021-07-12 18:50:06,477 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 902
[INFO] 2021-07-12 18:50:06,477 [run_pretraining.py:  558]:	worker_index: 6, step: 902, cost: 7.974259, mlm loss: 7.974259, speed: 0.948200 steps/s, speed: 7.585598 samples/s, speed: 3883.826404 tokens/s, learning rate: 9.010e-06, loss_scalings: 13421.773438, pp_loss: 7.544533
[INFO] 2021-07-12 18:50:06,477 [run_pretraining.py:  512]:	********exe.run_902******* 
[INFO] 2021-07-12 18:50:07,550 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:07,551 [run_pretraining.py:  534]:	loss/total_loss, 7.693593978881836, 903
[INFO] 2021-07-12 18:50:07,551 [run_pretraining.py:  535]:	loss/mlm_loss, 7.693593978881836, 903
[INFO] 2021-07-12 18:50:07,551 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.020000106829684e-06, 903
[INFO] 2021-07-12 18:50:07,551 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 903
[INFO] 2021-07-12 18:50:07,551 [run_pretraining.py:  558]:	worker_index: 6, step: 903, cost: 7.693594, mlm loss: 7.693594, speed: 0.931553 steps/s, speed: 7.452427 samples/s, speed: 3815.642473 tokens/s, learning rate: 9.020e-06, loss_scalings: 13421.773438, pp_loss: 8.159825
[INFO] 2021-07-12 18:50:07,551 [run_pretraining.py:  512]:	********exe.run_903******* 
[INFO] 2021-07-12 18:50:08,622 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:08,623 [run_pretraining.py:  534]:	loss/total_loss, 8.26589584350586, 904
[INFO] 2021-07-12 18:50:08,623 [run_pretraining.py:  535]:	loss/mlm_loss, 8.26589584350586, 904
[INFO] 2021-07-12 18:50:08,623 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.030000001075678e-06, 904
[INFO] 2021-07-12 18:50:08,623 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 904
[INFO] 2021-07-12 18:50:08,623 [run_pretraining.py:  558]:	worker_index: 6, step: 904, cost: 8.265896, mlm loss: 8.265896, speed: 0.933330 steps/s, speed: 7.466640 samples/s, speed: 3822.919844 tokens/s, learning rate: 9.030e-06, loss_scalings: 13421.773438, pp_loss: 7.606405
[INFO] 2021-07-12 18:50:08,623 [run_pretraining.py:  512]:	********exe.run_904******* 
[INFO] 2021-07-12 18:50:09,686 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:09,687 [run_pretraining.py:  534]:	loss/total_loss, 7.496638774871826, 905
[INFO] 2021-07-12 18:50:09,687 [run_pretraining.py:  535]:	loss/mlm_loss, 7.496638774871826, 905
[INFO] 2021-07-12 18:50:09,687 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.039999895321671e-06, 905
[INFO] 2021-07-12 18:50:09,687 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 905
[INFO] 2021-07-12 18:50:09,687 [run_pretraining.py:  558]:	worker_index: 6, step: 905, cost: 7.496639, mlm loss: 7.496639, speed: 0.940389 steps/s, speed: 7.523110 samples/s, speed: 3851.832288 tokens/s, learning rate: 9.040e-06, loss_scalings: 13421.773438, pp_loss: 7.932836
[INFO] 2021-07-12 18:50:09,687 [run_pretraining.py:  512]:	********exe.run_905******* 
[INFO] 2021-07-12 18:50:10,771 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:10,772 [run_pretraining.py:  534]:	loss/total_loss, 7.347393035888672, 906
[INFO] 2021-07-12 18:50:10,772 [run_pretraining.py:  535]:	loss/mlm_loss, 7.347393035888672, 906
[INFO] 2021-07-12 18:50:10,772 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.049999789567664e-06, 906
[INFO] 2021-07-12 18:50:10,772 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 906
[INFO] 2021-07-12 18:50:10,772 [run_pretraining.py:  558]:	worker_index: 6, step: 906, cost: 7.347393, mlm loss: 7.347393, speed: 0.922107 steps/s, speed: 7.376857 samples/s, speed: 3776.950923 tokens/s, learning rate: 9.050e-06, loss_scalings: 13421.773438, pp_loss: 7.696589
[INFO] 2021-07-12 18:50:10,773 [run_pretraining.py:  512]:	********exe.run_906******* 
[INFO] 2021-07-12 18:50:11,842 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:11,843 [run_pretraining.py:  534]:	loss/total_loss, 8.545846939086914, 907
[INFO] 2021-07-12 18:50:11,843 [run_pretraining.py:  535]:	loss/mlm_loss, 8.545846939086914, 907
[INFO] 2021-07-12 18:50:11,843 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.059999683813658e-06, 907
[INFO] 2021-07-12 18:50:11,843 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 907
[INFO] 2021-07-12 18:50:11,843 [run_pretraining.py:  558]:	worker_index: 6, step: 907, cost: 8.545847, mlm loss: 8.545847, speed: 0.934365 steps/s, speed: 7.474919 samples/s, speed: 3827.158414 tokens/s, learning rate: 9.060e-06, loss_scalings: 13421.773438, pp_loss: 8.205138
[INFO] 2021-07-12 18:50:11,843 [run_pretraining.py:  512]:	********exe.run_907******* 
[INFO] 2021-07-12 18:50:12,901 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:12,901 [run_pretraining.py:  534]:	loss/total_loss, 8.137031555175781, 908
[INFO] 2021-07-12 18:50:12,901 [run_pretraining.py:  535]:	loss/mlm_loss, 8.137031555175781, 908
[INFO] 2021-07-12 18:50:12,902 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.069999578059651e-06, 908
[INFO] 2021-07-12 18:50:12,902 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 908
[INFO] 2021-07-12 18:50:12,902 [run_pretraining.py:  558]:	worker_index: 6, step: 908, cost: 8.137032, mlm loss: 8.137032, speed: 0.945538 steps/s, speed: 7.564307 samples/s, speed: 3872.924979 tokens/s, learning rate: 9.070e-06, loss_scalings: 13421.773438, pp_loss: 8.011619
[INFO] 2021-07-12 18:50:12,902 [run_pretraining.py:  512]:	********exe.run_908******* 
[INFO] 2021-07-12 18:50:13,971 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:13,971 [run_pretraining.py:  534]:	loss/total_loss, 7.4185791015625, 909
[INFO] 2021-07-12 18:50:13,971 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4185791015625, 909
[INFO] 2021-07-12 18:50:13,972 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.080000381800346e-06, 909
[INFO] 2021-07-12 18:50:13,972 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 909
[INFO] 2021-07-12 18:50:13,972 [run_pretraining.py:  558]:	worker_index: 6, step: 909, cost: 7.418579, mlm loss: 7.418579, speed: 0.935231 steps/s, speed: 7.481849 samples/s, speed: 3830.706711 tokens/s, learning rate: 9.080e-06, loss_scalings: 13421.773438, pp_loss: 7.923316
[INFO] 2021-07-12 18:50:13,972 [run_pretraining.py:  512]:	********exe.run_909******* 
[INFO] 2021-07-12 18:50:15,041 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:15,042 [run_pretraining.py:  534]:	loss/total_loss, 7.9077558517456055, 910
[INFO] 2021-07-12 18:50:15,042 [run_pretraining.py:  535]:	loss/mlm_loss, 7.9077558517456055, 910
[INFO] 2021-07-12 18:50:15,042 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.089999366551638e-06, 910
[INFO] 2021-07-12 18:50:15,042 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 910
[INFO] 2021-07-12 18:50:15,042 [run_pretraining.py:  558]:	worker_index: 6, step: 910, cost: 7.907756, mlm loss: 7.907756, speed: 0.934751 steps/s, speed: 7.478006 samples/s, speed: 3828.738890 tokens/s, learning rate: 9.090e-06, loss_scalings: 13421.773438, pp_loss: 7.890038
[INFO] 2021-07-12 18:50:15,042 [run_pretraining.py:  512]:	********exe.run_910******* 
[INFO] 2021-07-12 18:50:16,096 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:16,097 [run_pretraining.py:  534]:	loss/total_loss, 8.129204750061035, 911
[INFO] 2021-07-12 18:50:16,097 [run_pretraining.py:  535]:	loss/mlm_loss, 8.129204750061035, 911
[INFO] 2021-07-12 18:50:16,097 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.099999260797631e-06, 911
[INFO] 2021-07-12 18:50:16,097 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 911
[INFO] 2021-07-12 18:50:16,097 [run_pretraining.py:  558]:	worker_index: 6, step: 911, cost: 8.129205, mlm loss: 8.129205, speed: 0.948450 steps/s, speed: 7.587604 samples/s, speed: 3884.853070 tokens/s, learning rate: 9.100e-06, loss_scalings: 13421.773438, pp_loss: 7.893024
[INFO] 2021-07-12 18:50:16,097 [run_pretraining.py:  512]:	********exe.run_911******* 
[INFO] 2021-07-12 18:50:17,147 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:17,148 [run_pretraining.py:  534]:	loss/total_loss, 8.662637710571289, 912
[INFO] 2021-07-12 18:50:17,148 [run_pretraining.py:  535]:	loss/mlm_loss, 8.662637710571289, 912
[INFO] 2021-07-12 18:50:17,148 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.110000064538326e-06, 912
[INFO] 2021-07-12 18:50:17,148 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 912
[INFO] 2021-07-12 18:50:17,148 [run_pretraining.py:  558]:	worker_index: 6, step: 912, cost: 8.662638, mlm loss: 8.662638, speed: 0.951996 steps/s, speed: 7.615965 samples/s, speed: 3899.373867 tokens/s, learning rate: 9.110e-06, loss_scalings: 13421.773438, pp_loss: 8.242618
[INFO] 2021-07-12 18:50:17,148 [run_pretraining.py:  512]:	********exe.run_912******* 
[INFO] 2021-07-12 18:50:18,205 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:18,205 [run_pretraining.py:  534]:	loss/total_loss, 7.695980548858643, 913
[INFO] 2021-07-12 18:50:18,206 [run_pretraining.py:  535]:	loss/mlm_loss, 7.695980548858643, 913
[INFO] 2021-07-12 18:50:18,206 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.11999995878432e-06, 913
[INFO] 2021-07-12 18:50:18,206 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 913
[INFO] 2021-07-12 18:50:18,206 [run_pretraining.py:  558]:	worker_index: 6, step: 913, cost: 7.695981, mlm loss: 7.695981, speed: 0.946249 steps/s, speed: 7.569989 samples/s, speed: 3875.834548 tokens/s, learning rate: 9.120e-06, loss_scalings: 13421.773438, pp_loss: 7.934349
[INFO] 2021-07-12 18:50:18,206 [run_pretraining.py:  512]:	********exe.run_913******* 
[INFO] 2021-07-12 18:50:19,275 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:19,276 [run_pretraining.py:  534]:	loss/total_loss, 5.768925189971924, 914
[INFO] 2021-07-12 18:50:19,276 [run_pretraining.py:  535]:	loss/mlm_loss, 5.768925189971924, 914
[INFO] 2021-07-12 18:50:19,276 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.129999853030313e-06, 914
[INFO] 2021-07-12 18:50:19,276 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 914
[INFO] 2021-07-12 18:50:19,276 [run_pretraining.py:  558]:	worker_index: 6, step: 914, cost: 5.768925, mlm loss: 5.768925, speed: 0.934887 steps/s, speed: 7.479097 samples/s, speed: 3829.297870 tokens/s, learning rate: 9.130e-06, loss_scalings: 13421.773438, pp_loss: 7.414627
[INFO] 2021-07-12 18:50:19,276 [run_pretraining.py:  512]:	********exe.run_914******* 
[INFO] 2021-07-12 18:50:20,338 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:20,339 [run_pretraining.py:  534]:	loss/total_loss, 8.079744338989258, 915
[INFO] 2021-07-12 18:50:20,339 [run_pretraining.py:  535]:	loss/mlm_loss, 8.079744338989258, 915
[INFO] 2021-07-12 18:50:20,339 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.139999747276306e-06, 915
[INFO] 2021-07-12 18:50:20,339 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 915
[INFO] 2021-07-12 18:50:20,339 [run_pretraining.py:  558]:	worker_index: 6, step: 915, cost: 8.079744, mlm loss: 8.079744, speed: 0.941390 steps/s, speed: 7.531124 samples/s, speed: 3855.935320 tokens/s, learning rate: 9.140e-06, loss_scalings: 13421.773438, pp_loss: 7.955667
[INFO] 2021-07-12 18:50:20,339 [run_pretraining.py:  512]:	********exe.run_915******* 
[INFO] 2021-07-12 18:50:21,281 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:21,282 [run_pretraining.py:  534]:	loss/total_loss, 7.961565971374512, 916
[INFO] 2021-07-12 18:50:21,282 [run_pretraining.py:  535]:	loss/mlm_loss, 7.961565971374512, 916
[INFO] 2021-07-12 18:50:21,282 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.1499996415223e-06, 916
[INFO] 2021-07-12 18:50:21,282 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 916
[INFO] 2021-07-12 18:50:21,282 [run_pretraining.py:  558]:	worker_index: 6, step: 916, cost: 7.961566, mlm loss: 7.961566, speed: 1.061263 steps/s, speed: 8.490105 samples/s, speed: 4346.933803 tokens/s, learning rate: 9.150e-06, loss_scalings: 13421.773438, pp_loss: 8.064168
[INFO] 2021-07-12 18:50:21,282 [run_pretraining.py:  512]:	********exe.run_916******* 
[INFO] 2021-07-12 18:50:22,193 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:22,194 [run_pretraining.py:  534]:	loss/total_loss, 8.298264503479004, 917
[INFO] 2021-07-12 18:50:22,194 [run_pretraining.py:  535]:	loss/mlm_loss, 8.298264503479004, 917
[INFO] 2021-07-12 18:50:22,194 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.159999535768293e-06, 917
[INFO] 2021-07-12 18:50:22,194 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 917
[INFO] 2021-07-12 18:50:22,194 [run_pretraining.py:  558]:	worker_index: 6, step: 917, cost: 8.298265, mlm loss: 8.298265, speed: 1.097249 steps/s, speed: 8.777991 samples/s, speed: 4494.331340 tokens/s, learning rate: 9.160e-06, loss_scalings: 13421.773438, pp_loss: 7.829700
[INFO] 2021-07-12 18:50:22,194 [run_pretraining.py:  512]:	********exe.run_917******* 
[INFO] 2021-07-12 18:50:23,111 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:23,112 [run_pretraining.py:  534]:	loss/total_loss, 8.337946891784668, 918
[INFO] 2021-07-12 18:50:23,112 [run_pretraining.py:  535]:	loss/mlm_loss, 8.337946891784668, 918
[INFO] 2021-07-12 18:50:23,112 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.170000339508988e-06, 918
[INFO] 2021-07-12 18:50:23,112 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 918
[INFO] 2021-07-12 18:50:23,112 [run_pretraining.py:  558]:	worker_index: 6, step: 918, cost: 8.337947, mlm loss: 8.337947, speed: 1.090037 steps/s, speed: 8.720298 samples/s, speed: 4464.792371 tokens/s, learning rate: 9.170e-06, loss_scalings: 13421.773438, pp_loss: 8.229805
[INFO] 2021-07-12 18:50:23,112 [run_pretraining.py:  512]:	********exe.run_918******* 
[INFO] 2021-07-12 18:50:24,026 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:24,027 [run_pretraining.py:  534]:	loss/total_loss, 8.894403457641602, 919
[INFO] 2021-07-12 18:50:24,027 [run_pretraining.py:  535]:	loss/mlm_loss, 8.894403457641602, 919
[INFO] 2021-07-12 18:50:24,027 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.17999932426028e-06, 919
[INFO] 2021-07-12 18:50:24,027 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 919
[INFO] 2021-07-12 18:50:24,027 [run_pretraining.py:  558]:	worker_index: 6, step: 919, cost: 8.894403, mlm loss: 8.894403, speed: 1.093892 steps/s, speed: 8.751139 samples/s, speed: 4480.583300 tokens/s, learning rate: 9.180e-06, loss_scalings: 13421.773438, pp_loss: 8.433133
[INFO] 2021-07-12 18:50:24,027 [run_pretraining.py:  512]:	********exe.run_919******* 
[INFO] 2021-07-12 18:50:24,940 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:24,940 [run_pretraining.py:  534]:	loss/total_loss, 8.401275634765625, 920
[INFO] 2021-07-12 18:50:24,940 [run_pretraining.py:  535]:	loss/mlm_loss, 8.401275634765625, 920
[INFO] 2021-07-12 18:50:24,940 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.189999218506273e-06, 920
[INFO] 2021-07-12 18:50:24,940 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 920
[INFO] 2021-07-12 18:50:24,941 [run_pretraining.py:  558]:	worker_index: 6, step: 920, cost: 8.401276, mlm loss: 8.401276, speed: 1.095653 steps/s, speed: 8.765228 samples/s, speed: 4487.796701 tokens/s, learning rate: 9.190e-06, loss_scalings: 13421.773438, pp_loss: 7.990195
[INFO] 2021-07-12 18:50:24,941 [run_pretraining.py:  512]:	********exe.run_920******* 
[INFO] 2021-07-12 18:50:25,864 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:25,864 [run_pretraining.py:  534]:	loss/total_loss, 7.959830284118652, 921
[INFO] 2021-07-12 18:50:25,864 [run_pretraining.py:  535]:	loss/mlm_loss, 7.959830284118652, 921
[INFO] 2021-07-12 18:50:25,864 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.200000022246968e-06, 921
[INFO] 2021-07-12 18:50:25,865 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 921
[INFO] 2021-07-12 18:50:25,865 [run_pretraining.py:  558]:	worker_index: 6, step: 921, cost: 7.959830, mlm loss: 7.959830, speed: 1.082967 steps/s, speed: 8.663736 samples/s, speed: 4435.832708 tokens/s, learning rate: 9.200e-06, loss_scalings: 13421.773438, pp_loss: 8.060838
[INFO] 2021-07-12 18:50:25,865 [run_pretraining.py:  512]:	********exe.run_921******* 
[INFO] 2021-07-12 18:50:26,777 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:26,777 [run_pretraining.py:  534]:	loss/total_loss, 7.975286960601807, 922
[INFO] 2021-07-12 18:50:26,777 [run_pretraining.py:  535]:	loss/mlm_loss, 7.975286960601807, 922
[INFO] 2021-07-12 18:50:26,777 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.209999916492961e-06, 922
[INFO] 2021-07-12 18:50:26,777 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 922
[INFO] 2021-07-12 18:50:26,778 [run_pretraining.py:  558]:	worker_index: 6, step: 922, cost: 7.975287, mlm loss: 7.975287, speed: 1.096303 steps/s, speed: 8.770422 samples/s, speed: 4490.455927 tokens/s, learning rate: 9.210e-06, loss_scalings: 13421.773438, pp_loss: 7.965989
[INFO] 2021-07-12 18:50:26,778 [run_pretraining.py:  512]:	********exe.run_922******* 
[INFO] 2021-07-12 18:50:27,694 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:27,695 [run_pretraining.py:  534]:	loss/total_loss, 8.543773651123047, 923
[INFO] 2021-07-12 18:50:27,695 [run_pretraining.py:  535]:	loss/mlm_loss, 8.543773651123047, 923
[INFO] 2021-07-12 18:50:27,695 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.219999810738955e-06, 923
[INFO] 2021-07-12 18:50:27,695 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 923
[INFO] 2021-07-12 18:50:27,695 [run_pretraining.py:  558]:	worker_index: 6, step: 923, cost: 8.543774, mlm loss: 8.543774, speed: 1.090348 steps/s, speed: 8.722784 samples/s, speed: 4466.065619 tokens/s, learning rate: 9.220e-06, loss_scalings: 13421.773438, pp_loss: 8.353206
[INFO] 2021-07-12 18:50:27,695 [run_pretraining.py:  512]:	********exe.run_923******* 
[INFO] 2021-07-12 18:50:28,618 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:28,619 [run_pretraining.py:  534]:	loss/total_loss, 8.424188613891602, 924
[INFO] 2021-07-12 18:50:28,619 [run_pretraining.py:  535]:	loss/mlm_loss, 8.424188613891602, 924
[INFO] 2021-07-12 18:50:28,619 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.229999704984948e-06, 924
[INFO] 2021-07-12 18:50:28,619 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 924
[INFO] 2021-07-12 18:50:28,619 [run_pretraining.py:  558]:	worker_index: 6, step: 924, cost: 8.424189, mlm loss: 8.424189, speed: 1.083615 steps/s, speed: 8.668922 samples/s, speed: 4438.488026 tokens/s, learning rate: 9.230e-06, loss_scalings: 13421.773438, pp_loss: 7.589262
[INFO] 2021-07-12 18:50:28,619 [run_pretraining.py:  512]:	********exe.run_924******* 
[INFO] 2021-07-12 18:50:29,541 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:29,541 [run_pretraining.py:  534]:	loss/total_loss, 8.360105514526367, 925
[INFO] 2021-07-12 18:50:29,541 [run_pretraining.py:  535]:	loss/mlm_loss, 8.360105514526367, 925
[INFO] 2021-07-12 18:50:29,541 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.239999599230941e-06, 925
[INFO] 2021-07-12 18:50:29,541 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 925
[INFO] 2021-07-12 18:50:29,542 [run_pretraining.py:  558]:	worker_index: 6, step: 925, cost: 8.360106, mlm loss: 8.360106, speed: 1.084692 steps/s, speed: 8.677540 samples/s, speed: 4442.900327 tokens/s, learning rate: 9.240e-06, loss_scalings: 13421.773438, pp_loss: 8.329727
[INFO] 2021-07-12 18:50:29,542 [run_pretraining.py:  512]:	********exe.run_925******* 
[INFO] 2021-07-12 18:50:30,459 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:30,459 [run_pretraining.py:  534]:	loss/total_loss, 7.737807273864746, 926
[INFO] 2021-07-12 18:50:30,459 [run_pretraining.py:  535]:	loss/mlm_loss, 7.737807273864746, 926
[INFO] 2021-07-12 18:50:30,459 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.249999493476935e-06, 926
[INFO] 2021-07-12 18:50:30,459 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 926
[INFO] 2021-07-12 18:50:30,460 [run_pretraining.py:  558]:	worker_index: 6, step: 926, cost: 7.737807, mlm loss: 7.737807, speed: 1.090147 steps/s, speed: 8.721177 samples/s, speed: 4465.242626 tokens/s, learning rate: 9.250e-06, loss_scalings: 13421.773438, pp_loss: 7.832667
[INFO] 2021-07-12 18:50:30,460 [run_pretraining.py:  512]:	********exe.run_926******* 
[INFO] 2021-07-12 18:50:31,388 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:31,388 [run_pretraining.py:  534]:	loss/total_loss, 7.89759635925293, 927
[INFO] 2021-07-12 18:50:31,388 [run_pretraining.py:  535]:	loss/mlm_loss, 7.89759635925293, 927
[INFO] 2021-07-12 18:50:31,388 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.26000029721763e-06, 927
[INFO] 2021-07-12 18:50:31,389 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 927
[INFO] 2021-07-12 18:50:31,389 [run_pretraining.py:  558]:	worker_index: 6, step: 927, cost: 7.897596, mlm loss: 7.897596, speed: 1.077042 steps/s, speed: 8.616333 samples/s, speed: 4411.562692 tokens/s, learning rate: 9.260e-06, loss_scalings: 13421.773438, pp_loss: 8.084242
[INFO] 2021-07-12 18:50:31,389 [run_pretraining.py:  512]:	********exe.run_927******* 
[INFO] 2021-07-12 18:50:32,313 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:32,313 [run_pretraining.py:  534]:	loss/total_loss, 8.280132293701172, 928
[INFO] 2021-07-12 18:50:32,313 [run_pretraining.py:  535]:	loss/mlm_loss, 8.280132293701172, 928
[INFO] 2021-07-12 18:50:32,313 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.269999281968921e-06, 928
[INFO] 2021-07-12 18:50:32,313 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 928
[INFO] 2021-07-12 18:50:32,314 [run_pretraining.py:  558]:	worker_index: 6, step: 928, cost: 8.280132, mlm loss: 8.280132, speed: 1.082075 steps/s, speed: 8.656601 samples/s, speed: 4432.179827 tokens/s, learning rate: 9.270e-06, loss_scalings: 13421.773438, pp_loss: 8.120220
[INFO] 2021-07-12 18:50:32,314 [run_pretraining.py:  512]:	********exe.run_928******* 
[INFO] 2021-07-12 18:50:33,228 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:33,229 [run_pretraining.py:  534]:	loss/total_loss, 7.930054187774658, 929
[INFO] 2021-07-12 18:50:33,229 [run_pretraining.py:  535]:	loss/mlm_loss, 7.930054187774658, 929
[INFO] 2021-07-12 18:50:33,229 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.280000085709617e-06, 929
[INFO] 2021-07-12 18:50:33,229 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 929
[INFO] 2021-07-12 18:50:33,229 [run_pretraining.py:  558]:	worker_index: 6, step: 929, cost: 7.930054, mlm loss: 7.930054, speed: 1.092586 steps/s, speed: 8.740685 samples/s, speed: 4475.230708 tokens/s, learning rate: 9.280e-06, loss_scalings: 13421.773438, pp_loss: 8.124456
[INFO] 2021-07-12 18:50:33,230 [run_pretraining.py:  512]:	********exe.run_929******* 
[INFO] 2021-07-12 18:50:34,150 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:34,151 [run_pretraining.py:  534]:	loss/total_loss, 8.142074584960938, 930
[INFO] 2021-07-12 18:50:34,151 [run_pretraining.py:  535]:	loss/mlm_loss, 8.142074584960938, 930
[INFO] 2021-07-12 18:50:34,151 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.28999997995561e-06, 930
[INFO] 2021-07-12 18:50:34,151 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 930
[INFO] 2021-07-12 18:50:34,151 [run_pretraining.py:  558]:	worker_index: 6, step: 930, cost: 8.142075, mlm loss: 8.142075, speed: 1.086070 steps/s, speed: 8.688563 samples/s, speed: 4448.544394 tokens/s, learning rate: 9.290e-06, loss_scalings: 13421.773438, pp_loss: 7.982793
[INFO] 2021-07-12 18:50:34,151 [run_pretraining.py:  512]:	********exe.run_930******* 
[INFO] 2021-07-12 18:50:35,065 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:35,066 [run_pretraining.py:  534]:	loss/total_loss, 8.015268325805664, 931
[INFO] 2021-07-12 18:50:35,066 [run_pretraining.py:  535]:	loss/mlm_loss, 8.015268325805664, 931
[INFO] 2021-07-12 18:50:35,066 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.299999874201603e-06, 931
[INFO] 2021-07-12 18:50:35,066 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 931
[INFO] 2021-07-12 18:50:35,066 [run_pretraining.py:  558]:	worker_index: 6, step: 931, cost: 8.015268, mlm loss: 8.015268, speed: 1.093592 steps/s, speed: 8.748734 samples/s, speed: 4479.351981 tokens/s, learning rate: 9.300e-06, loss_scalings: 13421.773438, pp_loss: 6.516706
[INFO] 2021-07-12 18:50:35,066 [run_pretraining.py:  512]:	********exe.run_931******* 
[INFO] 2021-07-12 18:50:35,967 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:35,967 [run_pretraining.py:  534]:	loss/total_loss, 8.293895721435547, 932
[INFO] 2021-07-12 18:50:35,967 [run_pretraining.py:  535]:	loss/mlm_loss, 8.293895721435547, 932
[INFO] 2021-07-12 18:50:35,967 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.309999768447597e-06, 932
[INFO] 2021-07-12 18:50:35,968 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 932
[INFO] 2021-07-12 18:50:35,968 [run_pretraining.py:  558]:	worker_index: 6, step: 932, cost: 8.293896, mlm loss: 8.293896, speed: 1.110008 steps/s, speed: 8.880066 samples/s, speed: 4546.593994 tokens/s, learning rate: 9.310e-06, loss_scalings: 13421.773438, pp_loss: 8.200027
[INFO] 2021-07-12 18:50:35,968 [run_pretraining.py:  512]:	********exe.run_932******* 
[INFO] 2021-07-12 18:50:36,886 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:36,887 [run_pretraining.py:  534]:	loss/total_loss, 8.180622100830078, 933
[INFO] 2021-07-12 18:50:36,887 [run_pretraining.py:  535]:	loss/mlm_loss, 8.180622100830078, 933
[INFO] 2021-07-12 18:50:36,887 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.31999966269359e-06, 933
[INFO] 2021-07-12 18:50:36,887 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 933
[INFO] 2021-07-12 18:50:36,887 [run_pretraining.py:  558]:	worker_index: 6, step: 933, cost: 8.180622, mlm loss: 8.180622, speed: 1.088344 steps/s, speed: 8.706750 samples/s, speed: 4457.856249 tokens/s, learning rate: 9.320e-06, loss_scalings: 13421.773438, pp_loss: 7.997556
[INFO] 2021-07-12 18:50:36,887 [run_pretraining.py:  512]:	********exe.run_933******* 
[INFO] 2021-07-12 18:50:37,814 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:37,814 [run_pretraining.py:  534]:	loss/total_loss, 8.426263809204102, 934
[INFO] 2021-07-12 18:50:37,814 [run_pretraining.py:  535]:	loss/mlm_loss, 8.426263809204102, 934
[INFO] 2021-07-12 18:50:37,814 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.329999556939583e-06, 934
[INFO] 2021-07-12 18:50:37,815 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 934
[INFO] 2021-07-12 18:50:37,815 [run_pretraining.py:  558]:	worker_index: 6, step: 934, cost: 8.426264, mlm loss: 8.426264, speed: 1.079026 steps/s, speed: 8.632211 samples/s, speed: 4419.692112 tokens/s, learning rate: 9.330e-06, loss_scalings: 13421.773438, pp_loss: 8.236205
[INFO] 2021-07-12 18:50:37,815 [run_pretraining.py:  512]:	********exe.run_934******* 
[INFO] 2021-07-12 18:50:38,738 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:38,739 [run_pretraining.py:  534]:	loss/total_loss, 7.850196838378906, 935
[INFO] 2021-07-12 18:50:38,739 [run_pretraining.py:  535]:	loss/mlm_loss, 7.850196838378906, 935
[INFO] 2021-07-12 18:50:38,739 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.340000360680278e-06, 935
[INFO] 2021-07-12 18:50:38,739 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 935
[INFO] 2021-07-12 18:50:38,739 [run_pretraining.py:  558]:	worker_index: 6, step: 935, cost: 7.850197, mlm loss: 7.850197, speed: 1.082678 steps/s, speed: 8.661426 samples/s, speed: 4434.649899 tokens/s, learning rate: 9.340e-06, loss_scalings: 13421.773438, pp_loss: 8.186426
[INFO] 2021-07-12 18:50:38,739 [run_pretraining.py:  512]:	********exe.run_935******* 
[INFO] 2021-07-12 18:50:39,875 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:39,875 [run_pretraining.py:  534]:	loss/total_loss, 8.51666259765625, 936
[INFO] 2021-07-12 18:50:39,875 [run_pretraining.py:  535]:	loss/mlm_loss, 8.51666259765625, 936
[INFO] 2021-07-12 18:50:39,876 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.350000254926272e-06, 936
[INFO] 2021-07-12 18:50:39,876 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 936
[INFO] 2021-07-12 18:50:39,876 [run_pretraining.py:  558]:	worker_index: 6, step: 936, cost: 8.516663, mlm loss: 8.516663, speed: 0.880270 steps/s, speed: 7.042159 samples/s, speed: 3605.585633 tokens/s, learning rate: 9.350e-06, loss_scalings: 13421.773438, pp_loss: 8.002453
[INFO] 2021-07-12 18:50:39,876 [run_pretraining.py:  512]:	********exe.run_936******* 
[INFO] 2021-07-12 18:50:40,798 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:40,799 [run_pretraining.py:  534]:	loss/total_loss, 7.862110614776611, 937
[INFO] 2021-07-12 18:50:40,799 [run_pretraining.py:  535]:	loss/mlm_loss, 7.862110614776611, 937
[INFO] 2021-07-12 18:50:40,799 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.359999239677563e-06, 937
[INFO] 2021-07-12 18:50:40,799 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 937
[INFO] 2021-07-12 18:50:40,799 [run_pretraining.py:  558]:	worker_index: 6, step: 937, cost: 7.862111, mlm loss: 7.862111, speed: 1.083919 steps/s, speed: 8.671348 samples/s, speed: 4439.730250 tokens/s, learning rate: 9.360e-06, loss_scalings: 13421.773438, pp_loss: 7.644168
[INFO] 2021-07-12 18:50:40,799 [run_pretraining.py:  512]:	********exe.run_937******* 
[INFO] 2021-07-12 18:50:41,763 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:41,764 [run_pretraining.py:  534]:	loss/total_loss, 8.191685676574707, 938
[INFO] 2021-07-12 18:50:41,764 [run_pretraining.py:  535]:	loss/mlm_loss, 8.191685676574707, 938
[INFO] 2021-07-12 18:50:41,764 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.370000043418258e-06, 938
[INFO] 2021-07-12 18:50:41,764 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 938
[INFO] 2021-07-12 18:50:41,764 [run_pretraining.py:  558]:	worker_index: 6, step: 938, cost: 8.191686, mlm loss: 8.191686, speed: 1.036709 steps/s, speed: 8.293670 samples/s, speed: 4246.359222 tokens/s, learning rate: 9.370e-06, loss_scalings: 13421.773438, pp_loss: 8.157142
[INFO] 2021-07-12 18:50:41,764 [run_pretraining.py:  512]:	********exe.run_938******* 
[INFO] 2021-07-12 18:50:42,671 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:42,671 [run_pretraining.py:  534]:	loss/total_loss, 7.787522315979004, 939
[INFO] 2021-07-12 18:50:42,672 [run_pretraining.py:  535]:	loss/mlm_loss, 7.787522315979004, 939
[INFO] 2021-07-12 18:50:42,672 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.379999937664252e-06, 939
[INFO] 2021-07-12 18:50:42,672 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 939
[INFO] 2021-07-12 18:50:42,672 [run_pretraining.py:  558]:	worker_index: 6, step: 939, cost: 7.787522, mlm loss: 7.787522, speed: 1.102749 steps/s, speed: 8.821993 samples/s, speed: 4516.860318 tokens/s, learning rate: 9.380e-06, loss_scalings: 13421.773438, pp_loss: 8.071404
[INFO] 2021-07-12 18:50:42,672 [run_pretraining.py:  512]:	********exe.run_939******* 
[INFO] 2021-07-12 18:50:43,583 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:43,583 [run_pretraining.py:  534]:	loss/total_loss, 7.416584014892578, 940
[INFO] 2021-07-12 18:50:43,583 [run_pretraining.py:  535]:	loss/mlm_loss, 7.416584014892578, 940
[INFO] 2021-07-12 18:50:43,584 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.389999831910245e-06, 940
[INFO] 2021-07-12 18:50:43,584 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 940
[INFO] 2021-07-12 18:50:43,584 [run_pretraining.py:  558]:	worker_index: 6, step: 940, cost: 7.416584, mlm loss: 7.416584, speed: 1.097508 steps/s, speed: 8.780063 samples/s, speed: 4495.392105 tokens/s, learning rate: 9.390e-06, loss_scalings: 13421.773438, pp_loss: 7.923926
[INFO] 2021-07-12 18:50:43,584 [run_pretraining.py:  512]:	********exe.run_940******* 
[INFO] 2021-07-12 18:50:44,500 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:44,500 [run_pretraining.py:  534]:	loss/total_loss, 8.094608306884766, 941
[INFO] 2021-07-12 18:50:44,500 [run_pretraining.py:  535]:	loss/mlm_loss, 8.094608306884766, 941
[INFO] 2021-07-12 18:50:44,500 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.399999726156238e-06, 941
[INFO] 2021-07-12 18:50:44,501 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 941
[INFO] 2021-07-12 18:50:44,501 [run_pretraining.py:  558]:	worker_index: 6, step: 941, cost: 8.094608, mlm loss: 8.094608, speed: 1.091409 steps/s, speed: 8.731269 samples/s, speed: 4470.409640 tokens/s, learning rate: 9.400e-06, loss_scalings: 13421.773438, pp_loss: 8.196402
[INFO] 2021-07-12 18:50:44,501 [run_pretraining.py:  512]:	********exe.run_941******* 
[INFO] 2021-07-12 18:50:45,413 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:45,414 [run_pretraining.py:  534]:	loss/total_loss, 8.016332626342773, 942
[INFO] 2021-07-12 18:50:45,414 [run_pretraining.py:  535]:	loss/mlm_loss, 8.016332626342773, 942
[INFO] 2021-07-12 18:50:45,414 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.409999620402232e-06, 942
[INFO] 2021-07-12 18:50:45,414 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 942
[INFO] 2021-07-12 18:50:45,414 [run_pretraining.py:  558]:	worker_index: 6, step: 942, cost: 8.016333, mlm loss: 8.016333, speed: 1.095529 steps/s, speed: 8.764230 samples/s, speed: 4487.285627 tokens/s, learning rate: 9.410e-06, loss_scalings: 13421.773438, pp_loss: 7.979171
[INFO] 2021-07-12 18:50:45,414 [run_pretraining.py:  512]:	********exe.run_942******* 
[INFO] 2021-07-12 18:50:46,338 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:46,338 [run_pretraining.py:  534]:	loss/total_loss, 7.376855850219727, 943
[INFO] 2021-07-12 18:50:46,339 [run_pretraining.py:  535]:	loss/mlm_loss, 7.376855850219727, 943
[INFO] 2021-07-12 18:50:46,339 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.419999514648225e-06, 943
[INFO] 2021-07-12 18:50:46,339 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 943
[INFO] 2021-07-12 18:50:46,339 [run_pretraining.py:  558]:	worker_index: 6, step: 943, cost: 7.376856, mlm loss: 7.376856, speed: 1.082394 steps/s, speed: 8.659155 samples/s, speed: 4433.487169 tokens/s, learning rate: 9.420e-06, loss_scalings: 13421.773438, pp_loss: 8.026665
[INFO] 2021-07-12 18:50:46,339 [run_pretraining.py:  512]:	********exe.run_943******* 
[INFO] 2021-07-12 18:50:47,242 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:47,243 [run_pretraining.py:  534]:	loss/total_loss, 7.968146324157715, 944
[INFO] 2021-07-12 18:50:47,243 [run_pretraining.py:  535]:	loss/mlm_loss, 7.968146324157715, 944
[INFO] 2021-07-12 18:50:47,243 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.43000031838892e-06, 944
[INFO] 2021-07-12 18:50:47,243 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 944
[INFO] 2021-07-12 18:50:47,243 [run_pretraining.py:  558]:	worker_index: 6, step: 944, cost: 7.968146, mlm loss: 7.968146, speed: 1.106639 steps/s, speed: 8.853113 samples/s, speed: 4532.793928 tokens/s, learning rate: 9.430e-06, loss_scalings: 13421.773438, pp_loss: 8.090393
[INFO] 2021-07-12 18:50:47,243 [run_pretraining.py:  512]:	********exe.run_944******* 
[INFO] 2021-07-12 18:50:48,155 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:48,156 [run_pretraining.py:  534]:	loss/total_loss, 8.06026554107666, 945
[INFO] 2021-07-12 18:50:48,156 [run_pretraining.py:  535]:	loss/mlm_loss, 8.06026554107666, 945
[INFO] 2021-07-12 18:50:48,156 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.440000212634914e-06, 945
[INFO] 2021-07-12 18:50:48,156 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 945
[INFO] 2021-07-12 18:50:48,156 [run_pretraining.py:  558]:	worker_index: 6, step: 945, cost: 8.060266, mlm loss: 8.060266, speed: 1.096235 steps/s, speed: 8.769876 samples/s, speed: 4490.176601 tokens/s, learning rate: 9.440e-06, loss_scalings: 13421.773438, pp_loss: 8.109804
[INFO] 2021-07-12 18:50:48,156 [run_pretraining.py:  512]:	********exe.run_945******* 
[INFO] 2021-07-12 18:50:49,077 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:49,077 [run_pretraining.py:  534]:	loss/total_loss, 8.266542434692383, 946
[INFO] 2021-07-12 18:50:49,077 [run_pretraining.py:  535]:	loss/mlm_loss, 8.266542434692383, 946
[INFO] 2021-07-12 18:50:49,077 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.449999197386205e-06, 946
[INFO] 2021-07-12 18:50:49,077 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 946
[INFO] 2021-07-12 18:50:49,077 [run_pretraining.py:  558]:	worker_index: 6, step: 946, cost: 8.266542, mlm loss: 8.266542, speed: 1.086050 steps/s, speed: 8.688401 samples/s, speed: 4448.461459 tokens/s, learning rate: 9.450e-06, loss_scalings: 13421.773438, pp_loss: 8.226663
[INFO] 2021-07-12 18:50:49,078 [run_pretraining.py:  512]:	********exe.run_946******* 
[INFO] 2021-07-12 18:50:50,058 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:50,058 [run_pretraining.py:  534]:	loss/total_loss, 8.301957130432129, 947
[INFO] 2021-07-12 18:50:50,058 [run_pretraining.py:  535]:	loss/mlm_loss, 8.301957130432129, 947
[INFO] 2021-07-12 18:50:50,058 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.4600000011269e-06, 947
[INFO] 2021-07-12 18:50:50,058 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 947
[INFO] 2021-07-12 18:50:50,058 [run_pretraining.py:  558]:	worker_index: 6, step: 947, cost: 8.301957, mlm loss: 8.301957, speed: 1.020120 steps/s, speed: 8.160962 samples/s, speed: 4178.412567 tokens/s, learning rate: 9.460e-06, loss_scalings: 13421.773438, pp_loss: 8.228180
[INFO] 2021-07-12 18:50:50,059 [run_pretraining.py:  512]:	********exe.run_947******* 
[INFO] 2021-07-12 18:50:51,128 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:51,129 [run_pretraining.py:  534]:	loss/total_loss, 7.927946090698242, 948
[INFO] 2021-07-12 18:50:51,129 [run_pretraining.py:  535]:	loss/mlm_loss, 7.927946090698242, 948
[INFO] 2021-07-12 18:50:51,129 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.469999895372894e-06, 948
[INFO] 2021-07-12 18:50:51,129 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 948
[INFO] 2021-07-12 18:50:51,129 [run_pretraining.py:  558]:	worker_index: 6, step: 948, cost: 7.927946, mlm loss: 7.927946, speed: 0.934782 steps/s, speed: 7.478256 samples/s, speed: 3828.866886 tokens/s, learning rate: 9.470e-06, loss_scalings: 13421.773438, pp_loss: 7.819751
[INFO] 2021-07-12 18:50:51,129 [run_pretraining.py:  512]:	********exe.run_948******* 
[INFO] 2021-07-12 18:50:52,191 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:52,192 [run_pretraining.py:  534]:	loss/total_loss, 7.881758689880371, 949
[INFO] 2021-07-12 18:50:52,192 [run_pretraining.py:  535]:	loss/mlm_loss, 7.881758689880371, 949
[INFO] 2021-07-12 18:50:52,192 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.479999789618887e-06, 949
[INFO] 2021-07-12 18:50:52,192 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 949
[INFO] 2021-07-12 18:50:52,192 [run_pretraining.py:  558]:	worker_index: 6, step: 949, cost: 7.881759, mlm loss: 7.881759, speed: 0.941177 steps/s, speed: 7.529417 samples/s, speed: 3855.061419 tokens/s, learning rate: 9.480e-06, loss_scalings: 13421.773438, pp_loss: 7.700689
[INFO] 2021-07-12 18:50:52,192 [run_pretraining.py:  512]:	********exe.run_949******* 
[INFO] 2021-07-12 18:50:53,248 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:53,249 [run_pretraining.py:  534]:	loss/total_loss, 7.5763139724731445, 950
[INFO] 2021-07-12 18:50:53,249 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5763139724731445, 950
[INFO] 2021-07-12 18:50:53,249 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.48999968386488e-06, 950
[INFO] 2021-07-12 18:50:53,249 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 950
[INFO] 2021-07-12 18:50:53,249 [run_pretraining.py:  558]:	worker_index: 6, step: 950, cost: 7.576314, mlm loss: 7.576314, speed: 0.946796 steps/s, speed: 7.574371 samples/s, speed: 3878.077810 tokens/s, learning rate: 9.490e-06, loss_scalings: 13421.773438, pp_loss: 7.930200
[INFO] 2021-07-12 18:50:53,249 [run_pretraining.py:  512]:	********exe.run_950******* 
[INFO] 2021-07-12 18:50:54,305 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:54,306 [run_pretraining.py:  534]:	loss/total_loss, 7.474902153015137, 951
[INFO] 2021-07-12 18:50:54,306 [run_pretraining.py:  535]:	loss/mlm_loss, 7.474902153015137, 951
[INFO] 2021-07-12 18:50:54,306 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.499999578110874e-06, 951
[INFO] 2021-07-12 18:50:54,306 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 951
[INFO] 2021-07-12 18:50:54,306 [run_pretraining.py:  558]:	worker_index: 6, step: 951, cost: 7.474902, mlm loss: 7.474902, speed: 0.946578 steps/s, speed: 7.572624 samples/s, speed: 3877.183343 tokens/s, learning rate: 9.500e-06, loss_scalings: 13421.773438, pp_loss: 7.801423
[INFO] 2021-07-12 18:50:54,306 [run_pretraining.py:  512]:	********exe.run_951******* 
[INFO] 2021-07-12 18:50:55,372 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:55,373 [run_pretraining.py:  534]:	loss/total_loss, 8.030856132507324, 952
[INFO] 2021-07-12 18:50:55,373 [run_pretraining.py:  535]:	loss/mlm_loss, 8.030856132507324, 952
[INFO] 2021-07-12 18:50:55,373 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.509999472356867e-06, 952
[INFO] 2021-07-12 18:50:55,373 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 952
[INFO] 2021-07-12 18:50:55,373 [run_pretraining.py:  558]:	worker_index: 6, step: 952, cost: 8.030856, mlm loss: 8.030856, speed: 0.937781 steps/s, speed: 7.502249 samples/s, speed: 3841.151564 tokens/s, learning rate: 9.510e-06, loss_scalings: 13421.773438, pp_loss: 7.836730
[INFO] 2021-07-12 18:50:55,373 [run_pretraining.py:  512]:	********exe.run_952******* 
[INFO] 2021-07-12 18:50:56,454 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:56,454 [run_pretraining.py:  534]:	loss/total_loss, 8.53775405883789, 953
[INFO] 2021-07-12 18:50:56,454 [run_pretraining.py:  535]:	loss/mlm_loss, 8.53775405883789, 953
[INFO] 2021-07-12 18:50:56,455 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.520000276097562e-06, 953
[INFO] 2021-07-12 18:50:56,455 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 953
[INFO] 2021-07-12 18:50:56,455 [run_pretraining.py:  558]:	worker_index: 6, step: 953, cost: 8.537754, mlm loss: 8.537754, speed: 0.925209 steps/s, speed: 7.401673 samples/s, speed: 3789.656406 tokens/s, learning rate: 9.520e-06, loss_scalings: 13421.773438, pp_loss: 8.073600
[INFO] 2021-07-12 18:50:56,455 [run_pretraining.py:  512]:	********exe.run_953******* 
[INFO] 2021-07-12 18:50:57,541 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:57,542 [run_pretraining.py:  534]:	loss/total_loss, 8.346977233886719, 954
[INFO] 2021-07-12 18:50:57,542 [run_pretraining.py:  535]:	loss/mlm_loss, 8.346977233886719, 954
[INFO] 2021-07-12 18:50:57,542 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.529999260848854e-06, 954
[INFO] 2021-07-12 18:50:57,542 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 954
[INFO] 2021-07-12 18:50:57,542 [run_pretraining.py:  558]:	worker_index: 6, step: 954, cost: 8.346977, mlm loss: 8.346977, speed: 0.920183 steps/s, speed: 7.361468 samples/s, speed: 3769.071567 tokens/s, learning rate: 9.530e-06, loss_scalings: 13421.773438, pp_loss: 8.194492
[INFO] 2021-07-12 18:50:57,542 [run_pretraining.py:  512]:	********exe.run_954******* 
[INFO] 2021-07-12 18:50:58,621 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:58,622 [run_pretraining.py:  534]:	loss/total_loss, 7.911529541015625, 955
[INFO] 2021-07-12 18:50:58,622 [run_pretraining.py:  535]:	loss/mlm_loss, 7.911529541015625, 955
[INFO] 2021-07-12 18:50:58,622 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.539999155094847e-06, 955
[INFO] 2021-07-12 18:50:58,622 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 955
[INFO] 2021-07-12 18:50:58,622 [run_pretraining.py:  558]:	worker_index: 6, step: 955, cost: 7.911530, mlm loss: 7.911530, speed: 0.926707 steps/s, speed: 7.413658 samples/s, speed: 3795.792997 tokens/s, learning rate: 9.540e-06, loss_scalings: 13421.773438, pp_loss: 8.075055
[INFO] 2021-07-12 18:50:58,622 [run_pretraining.py:  512]:	********exe.run_955******* 
[INFO] 2021-07-12 18:50:59,673 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:59,673 [run_pretraining.py:  534]:	loss/total_loss, 8.449301719665527, 956
[INFO] 2021-07-12 18:50:59,674 [run_pretraining.py:  535]:	loss/mlm_loss, 8.449301719665527, 956
[INFO] 2021-07-12 18:50:59,674 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.549999958835542e-06, 956
[INFO] 2021-07-12 18:50:59,674 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 956
[INFO] 2021-07-12 18:50:59,674 [run_pretraining.py:  558]:	worker_index: 6, step: 956, cost: 8.449302, mlm loss: 8.449302, speed: 0.951379 steps/s, speed: 7.611029 samples/s, speed: 3896.846906 tokens/s, learning rate: 9.550e-06, loss_scalings: 13421.773438, pp_loss: 8.192397
[INFO] 2021-07-12 18:50:59,674 [run_pretraining.py:  512]:	********exe.run_956******* 
[INFO] 2021-07-12 18:51:00,743 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:00,743 [run_pretraining.py:  534]:	loss/total_loss, 8.41870403289795, 957
[INFO] 2021-07-12 18:51:00,743 [run_pretraining.py:  535]:	loss/mlm_loss, 8.41870403289795, 957
[INFO] 2021-07-12 18:51:00,743 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.559999853081536e-06, 957
[INFO] 2021-07-12 18:51:00,744 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 957
[INFO] 2021-07-12 18:51:00,744 [run_pretraining.py:  558]:	worker_index: 6, step: 957, cost: 8.418704, mlm loss: 8.418704, speed: 0.935394 steps/s, speed: 7.483152 samples/s, speed: 3831.373925 tokens/s, learning rate: 9.560e-06, loss_scalings: 13421.773438, pp_loss: 8.184385
[INFO] 2021-07-12 18:51:00,744 [run_pretraining.py:  512]:	********exe.run_957******* 
[INFO] 2021-07-12 18:51:01,822 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:01,823 [run_pretraining.py:  534]:	loss/total_loss, 8.241868019104004, 958
[INFO] 2021-07-12 18:51:01,823 [run_pretraining.py:  535]:	loss/mlm_loss, 8.241868019104004, 958
[INFO] 2021-07-12 18:51:01,823 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.569999747327529e-06, 958
[INFO] 2021-07-12 18:51:01,823 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 958
[INFO] 2021-07-12 18:51:01,823 [run_pretraining.py:  558]:	worker_index: 6, step: 958, cost: 8.241868, mlm loss: 8.241868, speed: 0.927103 steps/s, speed: 7.416826 samples/s, speed: 3797.414817 tokens/s, learning rate: 9.570e-06, loss_scalings: 13421.773438, pp_loss: 7.892397
[INFO] 2021-07-12 18:51:01,823 [run_pretraining.py:  512]:	********exe.run_958******* 
[INFO] 2021-07-12 18:51:02,892 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:02,893 [run_pretraining.py:  534]:	loss/total_loss, 7.947958946228027, 959
[INFO] 2021-07-12 18:51:02,893 [run_pretraining.py:  535]:	loss/mlm_loss, 7.947958946228027, 959
[INFO] 2021-07-12 18:51:02,893 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.579999641573522e-06, 959
[INFO] 2021-07-12 18:51:02,893 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 959
[INFO] 2021-07-12 18:51:02,893 [run_pretraining.py:  558]:	worker_index: 6, step: 959, cost: 7.947959, mlm loss: 7.947959, speed: 0.934954 steps/s, speed: 7.479636 samples/s, speed: 3829.573580 tokens/s, learning rate: 9.580e-06, loss_scalings: 13421.773438, pp_loss: 7.697298
[INFO] 2021-07-12 18:51:02,893 [run_pretraining.py:  512]:	********exe.run_959******* 
[INFO] 2021-07-12 18:51:03,957 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:03,957 [run_pretraining.py:  534]:	loss/total_loss, 7.718729019165039, 960
[INFO] 2021-07-12 18:51:03,958 [run_pretraining.py:  535]:	loss/mlm_loss, 7.718729019165039, 960
[INFO] 2021-07-12 18:51:03,958 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.589999535819516e-06, 960
[INFO] 2021-07-12 18:51:03,958 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 960
[INFO] 2021-07-12 18:51:03,958 [run_pretraining.py:  558]:	worker_index: 6, step: 960, cost: 7.718729, mlm loss: 7.718729, speed: 0.939902 steps/s, speed: 7.519217 samples/s, speed: 3849.839257 tokens/s, learning rate: 9.590e-06, loss_scalings: 13421.773438, pp_loss: 7.121111
[INFO] 2021-07-12 18:51:03,958 [run_pretraining.py:  512]:	********exe.run_960******* 
[INFO] 2021-07-12 18:51:05,019 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:05,020 [run_pretraining.py:  534]:	loss/total_loss, 7.894286155700684, 961
[INFO] 2021-07-12 18:51:05,020 [run_pretraining.py:  535]:	loss/mlm_loss, 7.894286155700684, 961
[INFO] 2021-07-12 18:51:05,020 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.599999430065509e-06, 961
[INFO] 2021-07-12 18:51:05,020 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 961
[INFO] 2021-07-12 18:51:05,020 [run_pretraining.py:  558]:	worker_index: 6, step: 961, cost: 7.894286, mlm loss: 7.894286, speed: 0.942063 steps/s, speed: 7.536501 samples/s, speed: 3858.688535 tokens/s, learning rate: 9.600e-06, loss_scalings: 13421.773438, pp_loss: 7.843552
[INFO] 2021-07-12 18:51:05,020 [run_pretraining.py:  512]:	********exe.run_961******* 
[INFO] 2021-07-12 18:51:05,954 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:05,955 [run_pretraining.py:  534]:	loss/total_loss, 7.995950222015381, 962
[INFO] 2021-07-12 18:51:05,955 [run_pretraining.py:  535]:	loss/mlm_loss, 7.995950222015381, 962
[INFO] 2021-07-12 18:51:05,955 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.610000233806204e-06, 962
[INFO] 2021-07-12 18:51:05,955 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 962
[INFO] 2021-07-12 18:51:05,955 [run_pretraining.py:  558]:	worker_index: 6, step: 962, cost: 7.995950, mlm loss: 7.995950, speed: 1.070177 steps/s, speed: 8.561418 samples/s, speed: 4383.446059 tokens/s, learning rate: 9.610e-06, loss_scalings: 13421.773438, pp_loss: 7.971169
[INFO] 2021-07-12 18:51:05,955 [run_pretraining.py:  512]:	********exe.run_962******* 
[INFO] 2021-07-12 18:51:06,874 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:06,874 [run_pretraining.py:  534]:	loss/total_loss, 6.604528427124023, 963
[INFO] 2021-07-12 18:51:06,874 [run_pretraining.py:  535]:	loss/mlm_loss, 6.604528427124023, 963
[INFO] 2021-07-12 18:51:06,875 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.619999218557496e-06, 963
[INFO] 2021-07-12 18:51:06,875 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 963
[INFO] 2021-07-12 18:51:06,875 [run_pretraining.py:  558]:	worker_index: 6, step: 963, cost: 6.604528, mlm loss: 6.604528, speed: 1.088321 steps/s, speed: 8.706567 samples/s, speed: 4457.762556 tokens/s, learning rate: 9.620e-06, loss_scalings: 13421.773438, pp_loss: 7.401894
[INFO] 2021-07-12 18:51:06,875 [run_pretraining.py:  512]:	********exe.run_963******* 
[INFO] 2021-07-12 18:51:07,792 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:07,793 [run_pretraining.py:  534]:	loss/total_loss, 8.169071197509766, 964
[INFO] 2021-07-12 18:51:07,793 [run_pretraining.py:  535]:	loss/mlm_loss, 8.169071197509766, 964
[INFO] 2021-07-12 18:51:07,793 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.63000002229819e-06, 964
[INFO] 2021-07-12 18:51:07,793 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 964
[INFO] 2021-07-12 18:51:07,793 [run_pretraining.py:  558]:	worker_index: 6, step: 964, cost: 8.169071, mlm loss: 8.169071, speed: 1.089696 steps/s, speed: 8.717568 samples/s, speed: 4463.394607 tokens/s, learning rate: 9.630e-06, loss_scalings: 13421.773438, pp_loss: 8.022706
[INFO] 2021-07-12 18:51:07,793 [run_pretraining.py:  512]:	********exe.run_964******* 
[INFO] 2021-07-12 18:51:08,701 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:08,702 [run_pretraining.py:  534]:	loss/total_loss, 8.294666290283203, 965
[INFO] 2021-07-12 18:51:08,702 [run_pretraining.py:  535]:	loss/mlm_loss, 8.294666290283203, 965
[INFO] 2021-07-12 18:51:08,702 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.639999916544184e-06, 965
[INFO] 2021-07-12 18:51:08,702 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 965
[INFO] 2021-07-12 18:51:08,702 [run_pretraining.py:  558]:	worker_index: 6, step: 965, cost: 8.294666, mlm loss: 8.294666, speed: 1.100989 steps/s, speed: 8.807911 samples/s, speed: 4509.650327 tokens/s, learning rate: 9.640e-06, loss_scalings: 13421.773438, pp_loss: 7.962489
[INFO] 2021-07-12 18:51:08,702 [run_pretraining.py:  512]:	********exe.run_965******* 
[INFO] 2021-07-12 18:51:09,617 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:09,617 [run_pretraining.py:  534]:	loss/total_loss, 7.927894115447998, 966
[INFO] 2021-07-12 18:51:09,617 [run_pretraining.py:  535]:	loss/mlm_loss, 7.927894115447998, 966
[INFO] 2021-07-12 18:51:09,618 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.649999810790177e-06, 966
[INFO] 2021-07-12 18:51:09,618 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 966
[INFO] 2021-07-12 18:51:09,618 [run_pretraining.py:  558]:	worker_index: 6, step: 966, cost: 7.927894, mlm loss: 7.927894, speed: 1.092964 steps/s, speed: 8.743712 samples/s, speed: 4476.780546 tokens/s, learning rate: 9.650e-06, loss_scalings: 13421.773438, pp_loss: 7.797143
[INFO] 2021-07-12 18:51:09,618 [run_pretraining.py:  512]:	********exe.run_966******* 
[INFO] 2021-07-12 18:51:10,529 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:10,529 [run_pretraining.py:  534]:	loss/total_loss, 7.45355224609375, 967
[INFO] 2021-07-12 18:51:10,529 [run_pretraining.py:  535]:	loss/mlm_loss, 7.45355224609375, 967
[INFO] 2021-07-12 18:51:10,530 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.65999970503617e-06, 967
[INFO] 2021-07-12 18:51:10,530 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 967
[INFO] 2021-07-12 18:51:10,530 [run_pretraining.py:  558]:	worker_index: 6, step: 967, cost: 7.453552, mlm loss: 7.453552, speed: 1.097360 steps/s, speed: 8.778882 samples/s, speed: 4494.787572 tokens/s, learning rate: 9.660e-06, loss_scalings: 13421.773438, pp_loss: 7.944349
[INFO] 2021-07-12 18:51:10,530 [run_pretraining.py:  512]:	********exe.run_967******* 
[INFO] 2021-07-12 18:51:11,462 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:11,463 [run_pretraining.py:  534]:	loss/total_loss, 8.093162536621094, 968
[INFO] 2021-07-12 18:51:11,463 [run_pretraining.py:  535]:	loss/mlm_loss, 8.093162536621094, 968
[INFO] 2021-07-12 18:51:11,463 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.669999599282164e-06, 968
[INFO] 2021-07-12 18:51:11,463 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 968
[INFO] 2021-07-12 18:51:11,463 [run_pretraining.py:  558]:	worker_index: 6, step: 968, cost: 8.093163, mlm loss: 8.093163, speed: 1.071790 steps/s, speed: 8.574317 samples/s, speed: 4390.050298 tokens/s, learning rate: 9.670e-06, loss_scalings: 13421.773438, pp_loss: 7.770519
[INFO] 2021-07-12 18:51:11,464 [run_pretraining.py:  512]:	********exe.run_968******* 
[INFO] 2021-07-12 18:51:12,370 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:12,371 [run_pretraining.py:  534]:	loss/total_loss, 7.626035213470459, 969
[INFO] 2021-07-12 18:51:12,371 [run_pretraining.py:  535]:	loss/mlm_loss, 7.626035213470459, 969
[INFO] 2021-07-12 18:51:12,371 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.679999493528157e-06, 969
[INFO] 2021-07-12 18:51:12,371 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 969
[INFO] 2021-07-12 18:51:12,371 [run_pretraining.py:  558]:	worker_index: 6, step: 969, cost: 7.626035, mlm loss: 7.626035, speed: 1.102851 steps/s, speed: 8.822809 samples/s, speed: 4517.278375 tokens/s, learning rate: 9.680e-06, loss_scalings: 13421.773438, pp_loss: 8.115994
[INFO] 2021-07-12 18:51:12,371 [run_pretraining.py:  512]:	********exe.run_969******* 
[INFO] 2021-07-12 18:51:13,273 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:13,274 [run_pretraining.py:  534]:	loss/total_loss, 8.304534912109375, 970
[INFO] 2021-07-12 18:51:13,274 [run_pretraining.py:  535]:	loss/mlm_loss, 8.304534912109375, 970
[INFO] 2021-07-12 18:51:13,274 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.690000297268853e-06, 970
[INFO] 2021-07-12 18:51:13,274 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 970
[INFO] 2021-07-12 18:51:13,274 [run_pretraining.py:  558]:	worker_index: 6, step: 970, cost: 8.304535, mlm loss: 8.304535, speed: 1.108130 steps/s, speed: 8.865042 samples/s, speed: 4538.901478 tokens/s, learning rate: 9.690e-06, loss_scalings: 13421.773438, pp_loss: 8.206802
[INFO] 2021-07-12 18:51:13,274 [run_pretraining.py:  512]:	********exe.run_970******* 
[INFO] 2021-07-12 18:51:14,183 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:14,184 [run_pretraining.py:  534]:	loss/total_loss, 7.797500133514404, 971
[INFO] 2021-07-12 18:51:14,184 [run_pretraining.py:  535]:	loss/mlm_loss, 7.797500133514404, 971
[INFO] 2021-07-12 18:51:14,184 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.700000191514846e-06, 971
[INFO] 2021-07-12 18:51:14,184 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 971
[INFO] 2021-07-12 18:51:14,184 [run_pretraining.py:  558]:	worker_index: 6, step: 971, cost: 7.797500, mlm loss: 7.797500, speed: 1.099223 steps/s, speed: 8.793781 samples/s, speed: 4502.416119 tokens/s, learning rate: 9.700e-06, loss_scalings: 13421.773438, pp_loss: 7.381570
[INFO] 2021-07-12 18:51:14,185 [run_pretraining.py:  512]:	********exe.run_971******* 
[INFO] 2021-07-12 18:51:15,091 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:15,092 [run_pretraining.py:  534]:	loss/total_loss, 7.393057823181152, 972
[INFO] 2021-07-12 18:51:15,092 [run_pretraining.py:  535]:	loss/mlm_loss, 7.393057823181152, 972
[INFO] 2021-07-12 18:51:15,092 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.709999176266138e-06, 972
[INFO] 2021-07-12 18:51:15,092 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 972
[INFO] 2021-07-12 18:51:15,092 [run_pretraining.py:  558]:	worker_index: 6, step: 972, cost: 7.393058, mlm loss: 7.393058, speed: 1.102163 steps/s, speed: 8.817308 samples/s, speed: 4514.461545 tokens/s, learning rate: 9.710e-06, loss_scalings: 13421.773438, pp_loss: 7.588413
[INFO] 2021-07-12 18:51:15,093 [run_pretraining.py:  512]:	********exe.run_972******* 
[INFO] 2021-07-12 18:51:15,998 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:15,998 [run_pretraining.py:  534]:	loss/total_loss, 7.742342948913574, 973
[INFO] 2021-07-12 18:51:15,998 [run_pretraining.py:  535]:	loss/mlm_loss, 7.742342948913574, 973
[INFO] 2021-07-12 18:51:15,999 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.719999980006833e-06, 973
[INFO] 2021-07-12 18:51:15,999 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 973
[INFO] 2021-07-12 18:51:15,999 [run_pretraining.py:  558]:	worker_index: 6, step: 973, cost: 7.742343, mlm loss: 7.742343, speed: 1.104261 steps/s, speed: 8.834089 samples/s, speed: 4523.053580 tokens/s, learning rate: 9.720e-06, loss_scalings: 13421.773438, pp_loss: 7.889838
[INFO] 2021-07-12 18:51:15,999 [run_pretraining.py:  512]:	********exe.run_973******* 
[INFO] 2021-07-12 18:51:16,931 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:16,931 [run_pretraining.py:  534]:	loss/total_loss, 7.390936374664307, 974
[INFO] 2021-07-12 18:51:16,931 [run_pretraining.py:  535]:	loss/mlm_loss, 7.390936374664307, 974
[INFO] 2021-07-12 18:51:16,931 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.729999874252826e-06, 974
[INFO] 2021-07-12 18:51:16,931 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 974
[INFO] 2021-07-12 18:51:16,932 [run_pretraining.py:  558]:	worker_index: 6, step: 974, cost: 7.390936, mlm loss: 7.390936, speed: 1.072851 steps/s, speed: 8.582807 samples/s, speed: 4394.397122 tokens/s, learning rate: 9.730e-06, loss_scalings: 13421.773438, pp_loss: 7.693272
[INFO] 2021-07-12 18:51:16,932 [run_pretraining.py:  512]:	********exe.run_974******* 
[INFO] 2021-07-12 18:51:17,836 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:17,837 [run_pretraining.py:  534]:	loss/total_loss, 8.043487548828125, 975
[INFO] 2021-07-12 18:51:17,837 [run_pretraining.py:  535]:	loss/mlm_loss, 8.043487548828125, 975
[INFO] 2021-07-12 18:51:17,837 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.73999976849882e-06, 975
[INFO] 2021-07-12 18:51:17,837 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 975
[INFO] 2021-07-12 18:51:17,837 [run_pretraining.py:  558]:	worker_index: 6, step: 975, cost: 8.043488, mlm loss: 8.043488, speed: 1.104884 steps/s, speed: 8.839074 samples/s, speed: 4525.605741 tokens/s, learning rate: 9.740e-06, loss_scalings: 13421.773438, pp_loss: 8.200544
[INFO] 2021-07-12 18:51:17,837 [run_pretraining.py:  512]:	********exe.run_975******* 
[INFO] 2021-07-12 18:51:18,747 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:18,747 [run_pretraining.py:  534]:	loss/total_loss, 8.026501655578613, 976
[INFO] 2021-07-12 18:51:18,747 [run_pretraining.py:  535]:	loss/mlm_loss, 8.026501655578613, 976
[INFO] 2021-07-12 18:51:18,747 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.749999662744813e-06, 976
[INFO] 2021-07-12 18:51:18,748 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 976
[INFO] 2021-07-12 18:51:18,748 [run_pretraining.py:  558]:	worker_index: 6, step: 976, cost: 8.026502, mlm loss: 8.026502, speed: 1.099383 steps/s, speed: 8.795061 samples/s, speed: 4503.071098 tokens/s, learning rate: 9.750e-06, loss_scalings: 13421.773438, pp_loss: 7.972128
[INFO] 2021-07-12 18:51:18,748 [run_pretraining.py:  512]:	********exe.run_976******* 
[INFO] 2021-07-12 18:51:19,647 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:19,648 [run_pretraining.py:  534]:	loss/total_loss, 8.016938209533691, 977
[INFO] 2021-07-12 18:51:19,648 [run_pretraining.py:  535]:	loss/mlm_loss, 8.016938209533691, 977
[INFO] 2021-07-12 18:51:19,648 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.759999556990806e-06, 977
[INFO] 2021-07-12 18:51:19,648 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 977
[INFO] 2021-07-12 18:51:19,648 [run_pretraining.py:  558]:	worker_index: 6, step: 977, cost: 8.016938, mlm loss: 8.016938, speed: 1.111239 steps/s, speed: 8.889910 samples/s, speed: 4551.633934 tokens/s, learning rate: 9.760e-06, loss_scalings: 13421.773438, pp_loss: 7.995683
[INFO] 2021-07-12 18:51:19,648 [run_pretraining.py:  512]:	********exe.run_977******* 
[INFO] 2021-07-12 18:51:20,553 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:20,554 [run_pretraining.py:  534]:	loss/total_loss, 7.9322590827941895, 978
[INFO] 2021-07-12 18:51:20,554 [run_pretraining.py:  535]:	loss/mlm_loss, 7.9322590827941895, 978
[INFO] 2021-07-12 18:51:20,554 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.7699994512368e-06, 978
[INFO] 2021-07-12 18:51:20,554 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 978
[INFO] 2021-07-12 18:51:20,554 [run_pretraining.py:  558]:	worker_index: 6, step: 978, cost: 7.932259, mlm loss: 7.932259, speed: 1.104967 steps/s, speed: 8.839740 samples/s, speed: 4525.946724 tokens/s, learning rate: 9.770e-06, loss_scalings: 13421.773438, pp_loss: 7.871524
[INFO] 2021-07-12 18:51:20,554 [run_pretraining.py:  512]:	********exe.run_978******* 
[INFO] 2021-07-12 18:51:21,463 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:21,464 [run_pretraining.py:  534]:	loss/total_loss, 7.877568244934082, 979
[INFO] 2021-07-12 18:51:21,464 [run_pretraining.py:  535]:	loss/mlm_loss, 7.877568244934082, 979
[INFO] 2021-07-12 18:51:21,464 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.780000254977494e-06, 979
[INFO] 2021-07-12 18:51:21,464 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 979
[INFO] 2021-07-12 18:51:21,464 [run_pretraining.py:  558]:	worker_index: 6, step: 979, cost: 7.877568, mlm loss: 7.877568, speed: 1.099175 steps/s, speed: 8.793397 samples/s, speed: 4502.219072 tokens/s, learning rate: 9.780e-06, loss_scalings: 13421.773438, pp_loss: 7.845649
[INFO] 2021-07-12 18:51:21,465 [run_pretraining.py:  512]:	********exe.run_979******* 
[INFO] 2021-07-12 18:51:22,368 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:22,369 [run_pretraining.py:  534]:	loss/total_loss, 7.225639820098877, 980
[INFO] 2021-07-12 18:51:22,369 [run_pretraining.py:  535]:	loss/mlm_loss, 7.225639820098877, 980
[INFO] 2021-07-12 18:51:22,369 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.790000149223488e-06, 980
[INFO] 2021-07-12 18:51:22,369 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 980
[INFO] 2021-07-12 18:51:22,369 [run_pretraining.py:  558]:	worker_index: 6, step: 980, cost: 7.225640, mlm loss: 7.225640, speed: 1.106066 steps/s, speed: 8.848528 samples/s, speed: 4530.446304 tokens/s, learning rate: 9.790e-06, loss_scalings: 13421.773438, pp_loss: 7.779806
[INFO] 2021-07-12 18:51:22,369 [run_pretraining.py:  512]:	********exe.run_980******* 
[INFO] 2021-07-12 18:51:23,289 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:23,289 [run_pretraining.py:  534]:	loss/total_loss, 7.755439758300781, 981
[INFO] 2021-07-12 18:51:23,289 [run_pretraining.py:  535]:	loss/mlm_loss, 7.755439758300781, 981
[INFO] 2021-07-12 18:51:23,290 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.79999913397478e-06, 981
[INFO] 2021-07-12 18:51:23,290 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 981
[INFO] 2021-07-12 18:51:23,290 [run_pretraining.py:  558]:	worker_index: 6, step: 981, cost: 7.755440, mlm loss: 7.755440, speed: 1.087304 steps/s, speed: 8.698433 samples/s, speed: 4453.597768 tokens/s, learning rate: 9.800e-06, loss_scalings: 13421.773438, pp_loss: 8.034656
[INFO] 2021-07-12 18:51:23,290 [run_pretraining.py:  512]:	********exe.run_981******* 
[INFO] 2021-07-12 18:51:24,198 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:24,199 [run_pretraining.py:  534]:	loss/total_loss, 7.493000030517578, 982
[INFO] 2021-07-12 18:51:24,199 [run_pretraining.py:  535]:	loss/mlm_loss, 7.493000030517578, 982
[INFO] 2021-07-12 18:51:24,199 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.809999937715475e-06, 982
[INFO] 2021-07-12 18:51:24,199 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 982
[INFO] 2021-07-12 18:51:24,199 [run_pretraining.py:  558]:	worker_index: 6, step: 982, cost: 7.493000, mlm loss: 7.493000, speed: 1.100132 steps/s, speed: 8.801054 samples/s, speed: 4506.139645 tokens/s, learning rate: 9.810e-06, loss_scalings: 13421.773438, pp_loss: 8.187368
[INFO] 2021-07-12 18:51:24,199 [run_pretraining.py:  512]:	********exe.run_982******* 
[INFO] 2021-07-12 18:51:25,104 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:25,105 [run_pretraining.py:  534]:	loss/total_loss, 8.089378356933594, 983
[INFO] 2021-07-12 18:51:25,105 [run_pretraining.py:  535]:	loss/mlm_loss, 8.089378356933594, 983
[INFO] 2021-07-12 18:51:25,105 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.819999831961468e-06, 983
[INFO] 2021-07-12 18:51:25,105 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 983
[INFO] 2021-07-12 18:51:25,105 [run_pretraining.py:  558]:	worker_index: 6, step: 983, cost: 8.089378, mlm loss: 8.089378, speed: 1.104904 steps/s, speed: 8.839230 samples/s, speed: 4525.685617 tokens/s, learning rate: 9.820e-06, loss_scalings: 13421.773438, pp_loss: 7.872613
[INFO] 2021-07-12 18:51:25,105 [run_pretraining.py:  512]:	********exe.run_983******* 
[INFO] 2021-07-12 18:51:26,037 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:26,037 [run_pretraining.py:  534]:	loss/total_loss, 7.5801920890808105, 984
[INFO] 2021-07-12 18:51:26,038 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5801920890808105, 984
[INFO] 2021-07-12 18:51:26,038 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.829999726207461e-06, 984
[INFO] 2021-07-12 18:51:26,038 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 984
[INFO] 2021-07-12 18:51:26,038 [run_pretraining.py:  558]:	worker_index: 6, step: 984, cost: 7.580192, mlm loss: 7.580192, speed: 1.072950 steps/s, speed: 8.583599 samples/s, speed: 4394.802936 tokens/s, learning rate: 9.830e-06, loss_scalings: 13421.773438, pp_loss: 7.582850
[INFO] 2021-07-12 18:51:26,038 [run_pretraining.py:  512]:	********exe.run_984******* 
[INFO] 2021-07-12 18:51:26,941 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:26,942 [run_pretraining.py:  534]:	loss/total_loss, 7.602285385131836, 985
[INFO] 2021-07-12 18:51:26,942 [run_pretraining.py:  535]:	loss/mlm_loss, 7.602285385131836, 985
[INFO] 2021-07-12 18:51:26,942 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.839999620453455e-06, 985
[INFO] 2021-07-12 18:51:26,942 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 985
[INFO] 2021-07-12 18:51:26,942 [run_pretraining.py:  558]:	worker_index: 6, step: 985, cost: 7.602285, mlm loss: 7.602285, speed: 1.106502 steps/s, speed: 8.852018 samples/s, speed: 4532.233098 tokens/s, learning rate: 9.840e-06, loss_scalings: 13421.773438, pp_loss: 7.795822
[INFO] 2021-07-12 18:51:26,942 [run_pretraining.py:  512]:	********exe.run_985******* 
[INFO] 2021-07-12 18:51:27,892 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:27,892 [run_pretraining.py:  534]:	loss/total_loss, 8.8157320022583, 986
[INFO] 2021-07-12 18:51:27,892 [run_pretraining.py:  535]:	loss/mlm_loss, 8.8157320022583, 986
[INFO] 2021-07-12 18:51:27,893 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.849999514699448e-06, 986
[INFO] 2021-07-12 18:51:27,893 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 986
[INFO] 2021-07-12 18:51:27,893 [run_pretraining.py:  558]:	worker_index: 6, step: 986, cost: 8.815732, mlm loss: 8.815732, speed: 1.053000 steps/s, speed: 8.423999 samples/s, speed: 4313.087656 tokens/s, learning rate: 9.850e-06, loss_scalings: 13421.773438, pp_loss: 8.297150
[INFO] 2021-07-12 18:51:27,893 [run_pretraining.py:  512]:	********exe.run_986******* 
[INFO] 2021-07-12 18:51:28,811 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:28,812 [run_pretraining.py:  534]:	loss/total_loss, 7.9561333656311035, 987
[INFO] 2021-07-12 18:51:28,812 [run_pretraining.py:  535]:	loss/mlm_loss, 7.9561333656311035, 987
[INFO] 2021-07-12 18:51:28,812 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.859999408945441e-06, 987
[INFO] 2021-07-12 18:51:28,812 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 987
[INFO] 2021-07-12 18:51:28,812 [run_pretraining.py:  558]:	worker_index: 6, step: 987, cost: 7.956133, mlm loss: 7.956133, speed: 1.088411 steps/s, speed: 8.707286 samples/s, speed: 4458.130411 tokens/s, learning rate: 9.860e-06, loss_scalings: 13421.773438, pp_loss: 7.738532
[INFO] 2021-07-12 18:51:28,812 [run_pretraining.py:  512]:	********exe.run_987******* 
[INFO] 2021-07-12 18:51:29,715 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:29,715 [run_pretraining.py:  534]:	loss/total_loss, 7.623303413391113, 988
[INFO] 2021-07-12 18:51:29,716 [run_pretraining.py:  535]:	loss/mlm_loss, 7.623303413391113, 988
[INFO] 2021-07-12 18:51:29,716 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.870000212686136e-06, 988
[INFO] 2021-07-12 18:51:29,716 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 988
[INFO] 2021-07-12 18:51:29,716 [run_pretraining.py:  558]:	worker_index: 6, step: 988, cost: 7.623303, mlm loss: 7.623303, speed: 1.107548 steps/s, speed: 8.860386 samples/s, speed: 4536.517577 tokens/s, learning rate: 9.870e-06, loss_scalings: 13421.773438, pp_loss: 7.920359
[INFO] 2021-07-12 18:51:29,716 [run_pretraining.py:  512]:	********exe.run_988******* 
[INFO] 2021-07-12 18:51:30,623 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:30,623 [run_pretraining.py:  534]:	loss/total_loss, 8.00265121459961, 989
[INFO] 2021-07-12 18:51:30,623 [run_pretraining.py:  535]:	loss/mlm_loss, 8.00265121459961, 989
[INFO] 2021-07-12 18:51:30,624 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.88000010693213e-06, 989
[INFO] 2021-07-12 18:51:30,624 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 989
[INFO] 2021-07-12 18:51:30,624 [run_pretraining.py:  558]:	worker_index: 6, step: 989, cost: 8.002651, mlm loss: 8.002651, speed: 1.102287 steps/s, speed: 8.818293 samples/s, speed: 4514.965776 tokens/s, learning rate: 9.880e-06, loss_scalings: 13421.773438, pp_loss: 7.831404
[INFO] 2021-07-12 18:51:30,624 [run_pretraining.py:  512]:	********exe.run_989******* 
[INFO] 2021-07-12 18:51:31,526 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:31,526 [run_pretraining.py:  534]:	loss/total_loss, 7.689825534820557, 990
[INFO] 2021-07-12 18:51:31,526 [run_pretraining.py:  535]:	loss/mlm_loss, 7.689825534820557, 990
[INFO] 2021-07-12 18:51:31,527 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.889999091683421e-06, 990
[INFO] 2021-07-12 18:51:31,527 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 990
[INFO] 2021-07-12 18:51:31,527 [run_pretraining.py:  558]:	worker_index: 6, step: 990, cost: 7.689826, mlm loss: 7.689826, speed: 1.108281 steps/s, speed: 8.866248 samples/s, speed: 4539.519136 tokens/s, learning rate: 9.890e-06, loss_scalings: 13421.773438, pp_loss: 7.902281
[INFO] 2021-07-12 18:51:31,527 [run_pretraining.py:  512]:	********exe.run_990******* 
[INFO] 2021-07-12 18:51:32,438 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:32,439 [run_pretraining.py:  534]:	loss/total_loss, 8.291759490966797, 991
[INFO] 2021-07-12 18:51:32,439 [run_pretraining.py:  535]:	loss/mlm_loss, 8.291759490966797, 991
[INFO] 2021-07-12 18:51:32,439 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.899999895424116e-06, 991
[INFO] 2021-07-12 18:51:32,439 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 991
[INFO] 2021-07-12 18:51:32,439 [run_pretraining.py:  558]:	worker_index: 6, step: 991, cost: 8.291759, mlm loss: 8.291759, speed: 1.096835 steps/s, speed: 8.774678 samples/s, speed: 4492.635391 tokens/s, learning rate: 9.900e-06, loss_scalings: 13421.773438, pp_loss: 8.081192
[INFO] 2021-07-12 18:51:32,439 [run_pretraining.py:  512]:	********exe.run_991******* 
[INFO] 2021-07-12 18:51:33,353 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:33,354 [run_pretraining.py:  534]:	loss/total_loss, 7.999078273773193, 992
[INFO] 2021-07-12 18:51:33,354 [run_pretraining.py:  535]:	loss/mlm_loss, 7.999078273773193, 992
[INFO] 2021-07-12 18:51:33,354 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.90999978967011e-06, 992
[INFO] 2021-07-12 18:51:33,354 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 992
[INFO] 2021-07-12 18:51:33,354 [run_pretraining.py:  558]:	worker_index: 6, step: 992, cost: 7.999078, mlm loss: 7.999078, speed: 1.094006 steps/s, speed: 8.752050 samples/s, speed: 4481.049602 tokens/s, learning rate: 9.910e-06, loss_scalings: 13421.773438, pp_loss: 7.949815
[INFO] 2021-07-12 18:51:33,354 [run_pretraining.py:  512]:	********exe.run_992******* 
[INFO] 2021-07-12 18:51:34,267 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:34,268 [run_pretraining.py:  534]:	loss/total_loss, 7.889344215393066, 993
[INFO] 2021-07-12 18:51:34,268 [run_pretraining.py:  535]:	loss/mlm_loss, 7.889344215393066, 993
[INFO] 2021-07-12 18:51:34,268 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.919999683916103e-06, 993
[INFO] 2021-07-12 18:51:34,268 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 993
[INFO] 2021-07-12 18:51:34,268 [run_pretraining.py:  558]:	worker_index: 6, step: 993, cost: 7.889344, mlm loss: 7.889344, speed: 1.094817 steps/s, speed: 8.758536 samples/s, speed: 4484.370280 tokens/s, learning rate: 9.920e-06, loss_scalings: 13421.773438, pp_loss: 7.653943
[INFO] 2021-07-12 18:51:34,268 [run_pretraining.py:  512]:	********exe.run_993******* 
[INFO] 2021-07-12 18:51:35,172 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:35,173 [run_pretraining.py:  534]:	loss/total_loss, 7.838820457458496, 994
[INFO] 2021-07-12 18:51:35,173 [run_pretraining.py:  535]:	loss/mlm_loss, 7.838820457458496, 994
[INFO] 2021-07-12 18:51:35,173 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.929999578162096e-06, 994
[INFO] 2021-07-12 18:51:35,173 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 994
[INFO] 2021-07-12 18:51:35,173 [run_pretraining.py:  558]:	worker_index: 6, step: 994, cost: 7.838820, mlm loss: 7.838820, speed: 1.105525 steps/s, speed: 8.844199 samples/s, speed: 4528.230008 tokens/s, learning rate: 9.930e-06, loss_scalings: 13421.773438, pp_loss: 7.981172
[INFO] 2021-07-12 18:51:35,173 [run_pretraining.py:  512]:	********exe.run_994******* 
[INFO] 2021-07-12 18:51:36,110 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:36,110 [run_pretraining.py:  534]:	loss/total_loss, 7.709330081939697, 995
[INFO] 2021-07-12 18:51:36,110 [run_pretraining.py:  535]:	loss/mlm_loss, 7.709330081939697, 995
[INFO] 2021-07-12 18:51:36,110 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.93999947240809e-06, 995
[INFO] 2021-07-12 18:51:36,111 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 995
[INFO] 2021-07-12 18:51:36,111 [run_pretraining.py:  558]:	worker_index: 6, step: 995, cost: 7.709330, mlm loss: 7.709330, speed: 1.067541 steps/s, speed: 8.540329 samples/s, speed: 4372.648490 tokens/s, learning rate: 9.940e-06, loss_scalings: 13421.773438, pp_loss: 7.841475
[INFO] 2021-07-12 18:51:36,111 [run_pretraining.py:  512]:	********exe.run_995******* 
[INFO] 2021-07-12 18:51:37,027 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:37,027 [run_pretraining.py:  534]:	loss/total_loss, 7.895059585571289, 996
[INFO] 2021-07-12 18:51:37,028 [run_pretraining.py:  535]:	loss/mlm_loss, 7.895059585571289, 996
[INFO] 2021-07-12 18:51:37,028 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.949999366654083e-06, 996
[INFO] 2021-07-12 18:51:37,028 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 996
[INFO] 2021-07-12 18:51:37,028 [run_pretraining.py:  558]:	worker_index: 6, step: 996, cost: 7.895060, mlm loss: 7.895060, speed: 1.091235 steps/s, speed: 8.729881 samples/s, speed: 4469.699004 tokens/s, learning rate: 9.950e-06, loss_scalings: 13421.773438, pp_loss: 7.409686
[INFO] 2021-07-12 18:51:37,028 [run_pretraining.py:  512]:	********exe.run_996******* 
[INFO] 2021-07-12 18:51:37,941 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:37,942 [run_pretraining.py:  534]:	loss/total_loss, 7.155735492706299, 997
[INFO] 2021-07-12 18:51:37,942 [run_pretraining.py:  535]:	loss/mlm_loss, 7.155735492706299, 997
[INFO] 2021-07-12 18:51:37,942 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.960000170394778e-06, 997
[INFO] 2021-07-12 18:51:37,942 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 997
[INFO] 2021-07-12 18:51:37,942 [run_pretraining.py:  558]:	worker_index: 6, step: 997, cost: 7.155735, mlm loss: 7.155735, speed: 1.094749 steps/s, speed: 8.757992 samples/s, speed: 4484.091711 tokens/s, learning rate: 9.960e-06, loss_scalings: 13421.773438, pp_loss: 7.526232
[INFO] 2021-07-12 18:51:37,942 [run_pretraining.py:  512]:	********exe.run_997******* 
[INFO] 2021-07-12 18:51:38,857 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:38,857 [run_pretraining.py:  534]:	loss/total_loss, 7.85313606262207, 998
[INFO] 2021-07-12 18:51:38,857 [run_pretraining.py:  535]:	loss/mlm_loss, 7.85313606262207, 998
[INFO] 2021-07-12 18:51:38,858 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.96999915514607e-06, 998
[INFO] 2021-07-12 18:51:38,858 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 998
[INFO] 2021-07-12 18:51:38,858 [run_pretraining.py:  558]:	worker_index: 6, step: 998, cost: 7.853136, mlm loss: 7.853136, speed: 1.092769 steps/s, speed: 8.742149 samples/s, speed: 4475.980420 tokens/s, learning rate: 9.970e-06, loss_scalings: 13421.773438, pp_loss: 7.914766
[INFO] 2021-07-12 18:51:38,858 [run_pretraining.py:  512]:	********exe.run_998******* 
[INFO] 2021-07-12 18:51:39,845 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:39,845 [run_pretraining.py:  534]:	loss/total_loss, 7.236544609069824, 999
[INFO] 2021-07-12 18:51:39,846 [run_pretraining.py:  535]:	loss/mlm_loss, 7.236544609069824, 999
[INFO] 2021-07-12 18:51:39,846 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.979999958886765e-06, 999
[INFO] 2021-07-12 18:51:39,846 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 999
[INFO] 2021-07-12 18:51:39,846 [run_pretraining.py:  558]:	worker_index: 6, step: 999, cost: 7.236545, mlm loss: 7.236545, speed: 1.012816 steps/s, speed: 8.102530 samples/s, speed: 4148.495334 tokens/s, learning rate: 9.980e-06, loss_scalings: 13421.773438, pp_loss: 7.628296
[INFO] 2021-07-12 18:51:39,846 [run_pretraining.py:  512]:	********exe.run_999******* 
[INFO] 2021-07-12 18:51:40,754 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:40,754 [run_pretraining.py:  534]:	loss/total_loss, 7.826013565063477, 1000
[INFO] 2021-07-12 18:51:40,754 [run_pretraining.py:  535]:	loss/mlm_loss, 7.826013565063477, 1000
[INFO] 2021-07-12 18:51:40,754 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.989999853132758e-06, 1000
[INFO] 2021-07-12 18:51:40,754 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1000
[INFO] 2021-07-12 18:51:40,755 [run_pretraining.py:  558]:	worker_index: 6, step: 1000, cost: 7.826014, mlm loss: 7.826014, speed: 1.101236 steps/s, speed: 8.809890 samples/s, speed: 4510.663859 tokens/s, learning rate: 9.990e-06, loss_scalings: 13421.773438, pp_loss: 8.020736
[INFO] 2021-07-12 18:51:40,755 [run_pretraining.py:  512]:	********exe.run_1000******* 
[INFO] 2021-07-12 18:51:41,675 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:41,675 [run_pretraining.py:  534]:	loss/total_loss, 8.09607219696045, 1001
[INFO] 2021-07-12 18:51:41,676 [run_pretraining.py:  535]:	loss/mlm_loss, 8.09607219696045, 1001
[INFO] 2021-07-12 18:51:41,676 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.999999747378752e-06, 1001
[INFO] 2021-07-12 18:51:41,676 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1001
[INFO] 2021-07-12 18:51:41,676 [run_pretraining.py:  558]:	worker_index: 6, step: 1001, cost: 8.096072, mlm loss: 8.096072, speed: 1.086388 steps/s, speed: 8.691106 samples/s, speed: 4449.846426 tokens/s, learning rate: 1.000e-05, loss_scalings: 13421.773438, pp_loss: 7.868970
[INFO] 2021-07-12 18:51:41,676 [run_pretraining.py:  512]:	********exe.run_1001******* 
[INFO] 2021-07-12 18:51:42,585 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:42,586 [run_pretraining.py:  534]:	loss/total_loss, 7.841653823852539, 1002
[INFO] 2021-07-12 18:51:42,586 [run_pretraining.py:  535]:	loss/mlm_loss, 7.841653823852539, 1002
[INFO] 2021-07-12 18:51:42,586 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0009999641624745e-05, 1002
[INFO] 2021-07-12 18:51:42,586 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1002
[INFO] 2021-07-12 18:51:42,586 [run_pretraining.py:  558]:	worker_index: 6, step: 1002, cost: 7.841654, mlm loss: 7.841654, speed: 1.099060 steps/s, speed: 8.792480 samples/s, speed: 4501.749534 tokens/s, learning rate: 1.001e-05, loss_scalings: 13421.773438, pp_loss: 7.966009
[INFO] 2021-07-12 18:51:42,586 [run_pretraining.py:  512]:	********exe.run_1002******* 
[INFO] 2021-07-12 18:51:43,497 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:43,498 [run_pretraining.py:  534]:	loss/total_loss, 7.908375263214111, 1003
[INFO] 2021-07-12 18:51:43,498 [run_pretraining.py:  535]:	loss/mlm_loss, 7.908375263214111, 1003
[INFO] 2021-07-12 18:51:43,498 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0019999535870738e-05, 1003
[INFO] 2021-07-12 18:51:43,498 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1003
[INFO] 2021-07-12 18:51:43,498 [run_pretraining.py:  558]:	worker_index: 6, step: 1003, cost: 7.908375, mlm loss: 7.908375, speed: 1.097456 steps/s, speed: 8.779651 samples/s, speed: 4495.181559 tokens/s, learning rate: 1.002e-05, loss_scalings: 13421.773438, pp_loss: 8.204774
[INFO] 2021-07-12 18:51:43,498 [run_pretraining.py:  512]:	********exe.run_1003******* 
[INFO] 2021-07-12 18:52:09,823 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:09,824 [run_pretraining.py:  534]:	loss/total_loss, 7.816140174865723, 1004
[INFO] 2021-07-12 18:52:09,824 [run_pretraining.py:  535]:	loss/mlm_loss, 7.816140174865723, 1004
[INFO] 2021-07-12 18:52:09,824 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0029999430116732e-05, 1004
[INFO] 2021-07-12 18:52:09,824 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1004
[INFO] 2021-07-12 18:52:09,824 [run_pretraining.py:  558]:	worker_index: 6, step: 1004, cost: 7.816140, mlm loss: 7.816140, speed: 0.037986 steps/s, speed: 0.303888 samples/s, speed: 155.590845 tokens/s, learning rate: 1.003e-05, loss_scalings: 13421.773438, pp_loss: 7.891626
[INFO] 2021-07-12 18:52:09,825 [run_pretraining.py:  512]:	********exe.run_1004******* 
[INFO] 2021-07-12 18:52:10,750 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:10,750 [run_pretraining.py:  534]:	loss/total_loss, 7.629765510559082, 1005
[INFO] 2021-07-12 18:52:10,750 [run_pretraining.py:  535]:	loss/mlm_loss, 7.629765510559082, 1005
[INFO] 2021-07-12 18:52:10,751 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0040000233857427e-05, 1005
[INFO] 2021-07-12 18:52:10,751 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1005
[INFO] 2021-07-12 18:52:10,751 [run_pretraining.py:  558]:	worker_index: 6, step: 1005, cost: 7.629766, mlm loss: 7.629766, speed: 1.080350 steps/s, speed: 8.642799 samples/s, speed: 4425.113194 tokens/s, learning rate: 1.004e-05, loss_scalings: 13421.773438, pp_loss: 7.780502
[INFO] 2021-07-12 18:52:10,751 [run_pretraining.py:  512]:	********exe.run_1005******* 
[INFO] 2021-07-12 18:52:11,666 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:11,666 [run_pretraining.py:  534]:	loss/total_loss, 7.122725486755371, 1006
[INFO] 2021-07-12 18:52:11,666 [run_pretraining.py:  535]:	loss/mlm_loss, 7.122725486755371, 1006
[INFO] 2021-07-12 18:52:11,666 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.005000012810342e-05, 1006
[INFO] 2021-07-12 18:52:11,666 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1006
[INFO] 2021-07-12 18:52:11,666 [run_pretraining.py:  558]:	worker_index: 6, step: 1006, cost: 7.122725, mlm loss: 7.122725, speed: 1.092875 steps/s, speed: 8.743003 samples/s, speed: 4476.417771 tokens/s, learning rate: 1.005e-05, loss_scalings: 13421.773438, pp_loss: 7.527202
[INFO] 2021-07-12 18:52:11,667 [run_pretraining.py:  512]:	********exe.run_1006******* 
[INFO] 2021-07-12 18:52:12,584 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:12,584 [run_pretraining.py:  534]:	loss/total_loss, 7.4156060218811035, 1007
[INFO] 2021-07-12 18:52:12,584 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4156060218811035, 1007
[INFO] 2021-07-12 18:52:12,585 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0059999112854712e-05, 1007
[INFO] 2021-07-12 18:52:12,585 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1007
[INFO] 2021-07-12 18:52:12,585 [run_pretraining.py:  558]:	worker_index: 6, step: 1007, cost: 7.415606, mlm loss: 7.415606, speed: 1.089891 steps/s, speed: 8.719126 samples/s, speed: 4464.192559 tokens/s, learning rate: 1.006e-05, loss_scalings: 13421.773438, pp_loss: 7.613998
[INFO] 2021-07-12 18:52:12,585 [run_pretraining.py:  512]:	********exe.run_1007******* 
[INFO] 2021-07-12 18:52:13,506 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:13,507 [run_pretraining.py:  534]:	loss/total_loss, 8.108940124511719, 1008
[INFO] 2021-07-12 18:52:13,507 [run_pretraining.py:  535]:	loss/mlm_loss, 8.108940124511719, 1008
[INFO] 2021-07-12 18:52:13,507 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0069999916595407e-05, 1008
[INFO] 2021-07-12 18:52:13,507 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1008
[INFO] 2021-07-12 18:52:13,507 [run_pretraining.py:  558]:	worker_index: 6, step: 1008, cost: 8.108940, mlm loss: 8.108940, speed: 1.084705 steps/s, speed: 8.677643 samples/s, speed: 4442.953181 tokens/s, learning rate: 1.007e-05, loss_scalings: 13421.773438, pp_loss: 7.922732
[INFO] 2021-07-12 18:52:13,507 [run_pretraining.py:  512]:	********exe.run_1008******* 
[INFO] 2021-07-12 18:52:14,425 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:14,426 [run_pretraining.py:  534]:	loss/total_loss, 8.022194862365723, 1009
[INFO] 2021-07-12 18:52:14,426 [run_pretraining.py:  535]:	loss/mlm_loss, 8.022194862365723, 1009
[INFO] 2021-07-12 18:52:14,426 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.00799998108414e-05, 1009
[INFO] 2021-07-12 18:52:14,426 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1009
[INFO] 2021-07-12 18:52:14,426 [run_pretraining.py:  558]:	worker_index: 6, step: 1009, cost: 8.022195, mlm loss: 8.022195, speed: 1.088781 steps/s, speed: 8.710251 samples/s, speed: 4459.648745 tokens/s, learning rate: 1.008e-05, loss_scalings: 13421.773438, pp_loss: 8.037698
[INFO] 2021-07-12 18:52:14,427 [run_pretraining.py:  512]:	********exe.run_1009******* 
[INFO] 2021-07-12 18:52:15,347 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:15,348 [run_pretraining.py:  534]:	loss/total_loss, 8.051416397094727, 1010
[INFO] 2021-07-12 18:52:15,348 [run_pretraining.py:  535]:	loss/mlm_loss, 8.051416397094727, 1010
[INFO] 2021-07-12 18:52:15,348 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0089999705087394e-05, 1010
[INFO] 2021-07-12 18:52:15,348 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1010
[INFO] 2021-07-12 18:52:15,348 [run_pretraining.py:  558]:	worker_index: 6, step: 1010, cost: 8.051416, mlm loss: 8.051416, speed: 1.085746 steps/s, speed: 8.685968 samples/s, speed: 4447.215495 tokens/s, learning rate: 1.009e-05, loss_scalings: 13421.773438, pp_loss: 7.945811
[INFO] 2021-07-12 18:52:15,348 [run_pretraining.py:  512]:	********exe.run_1010******* 
[INFO] 2021-07-12 18:52:16,251 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:16,252 [run_pretraining.py:  534]:	loss/total_loss, 8.40296745300293, 1011
[INFO] 2021-07-12 18:52:16,252 [run_pretraining.py:  535]:	loss/mlm_loss, 8.40296745300293, 1011
[INFO] 2021-07-12 18:52:16,252 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0100000508828089e-05, 1011
[INFO] 2021-07-12 18:52:16,252 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1011
[INFO] 2021-07-12 18:52:16,252 [run_pretraining.py:  558]:	worker_index: 6, step: 1011, cost: 8.402967, mlm loss: 8.402967, speed: 1.107398 steps/s, speed: 8.859186 samples/s, speed: 4535.903131 tokens/s, learning rate: 1.010e-05, loss_scalings: 13421.773438, pp_loss: 7.990293
[INFO] 2021-07-12 18:52:16,252 [run_pretraining.py:  512]:	********exe.run_1011******* 
[INFO] 2021-07-12 18:52:17,164 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:17,164 [run_pretraining.py:  534]:	loss/total_loss, 8.005095481872559, 1012
[INFO] 2021-07-12 18:52:17,164 [run_pretraining.py:  535]:	loss/mlm_loss, 8.005095481872559, 1012
[INFO] 2021-07-12 18:52:17,165 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.010999949357938e-05, 1012
[INFO] 2021-07-12 18:52:17,165 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1012
[INFO] 2021-07-12 18:52:17,165 [run_pretraining.py:  558]:	worker_index: 6, step: 1012, cost: 8.005095, mlm loss: 8.005095, speed: 1.096348 steps/s, speed: 8.770786 samples/s, speed: 4490.642555 tokens/s, learning rate: 1.011e-05, loss_scalings: 13421.773438, pp_loss: 7.788593
[INFO] 2021-07-12 18:52:17,165 [run_pretraining.py:  512]:	********exe.run_1012******* 
[INFO] 2021-07-12 18:52:18,075 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:18,076 [run_pretraining.py:  534]:	loss/total_loss, 8.088501930236816, 1013
[INFO] 2021-07-12 18:52:18,076 [run_pretraining.py:  535]:	loss/mlm_loss, 8.088501930236816, 1013
[INFO] 2021-07-12 18:52:18,076 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0119999387825374e-05, 1013
[INFO] 2021-07-12 18:52:18,076 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1013
[INFO] 2021-07-12 18:52:18,076 [run_pretraining.py:  558]:	worker_index: 6, step: 1013, cost: 8.088502, mlm loss: 8.088502, speed: 1.098105 steps/s, speed: 8.784842 samples/s, speed: 4497.838948 tokens/s, learning rate: 1.012e-05, loss_scalings: 13421.773438, pp_loss: 7.706587
[INFO] 2021-07-12 18:52:18,076 [run_pretraining.py:  512]:	********exe.run_1013******* 
[INFO] 2021-07-12 18:52:18,987 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:18,988 [run_pretraining.py:  534]:	loss/total_loss, 7.986979007720947, 1014
[INFO] 2021-07-12 18:52:18,988 [run_pretraining.py:  535]:	loss/mlm_loss, 7.986979007720947, 1014
[INFO] 2021-07-12 18:52:18,988 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0130000191566069e-05, 1014
[INFO] 2021-07-12 18:52:18,988 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1014
[INFO] 2021-07-12 18:52:18,988 [run_pretraining.py:  558]:	worker_index: 6, step: 1014, cost: 7.986979, mlm loss: 7.986979, speed: 1.097038 steps/s, speed: 8.776306 samples/s, speed: 4493.468514 tokens/s, learning rate: 1.013e-05, loss_scalings: 13421.773438, pp_loss: 7.718268
[INFO] 2021-07-12 18:52:18,988 [run_pretraining.py:  512]:	********exe.run_1014******* 
[INFO] 2021-07-12 18:52:19,894 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:19,895 [run_pretraining.py:  534]:	loss/total_loss, 7.874015808105469, 1015
[INFO] 2021-07-12 18:52:19,895 [run_pretraining.py:  535]:	loss/mlm_loss, 7.874015808105469, 1015
[INFO] 2021-07-12 18:52:19,895 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0140000085812062e-05, 1015
[INFO] 2021-07-12 18:52:19,895 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1015
[INFO] 2021-07-12 18:52:19,895 [run_pretraining.py:  558]:	worker_index: 6, step: 1015, cost: 7.874016, mlm loss: 7.874016, speed: 1.103933 steps/s, speed: 8.831462 samples/s, speed: 4521.708362 tokens/s, learning rate: 1.014e-05, loss_scalings: 13421.773438, pp_loss: 7.846425
[INFO] 2021-07-12 18:52:19,895 [run_pretraining.py:  512]:	********exe.run_1015******* 
[INFO] 2021-07-12 18:52:20,804 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:20,804 [run_pretraining.py:  534]:	loss/total_loss, 6.162370204925537, 1016
[INFO] 2021-07-12 18:52:20,804 [run_pretraining.py:  535]:	loss/mlm_loss, 6.162370204925537, 1016
[INFO] 2021-07-12 18:52:20,804 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0149999070563354e-05, 1016
[INFO] 2021-07-12 18:52:20,805 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1016
[INFO] 2021-07-12 18:52:20,805 [run_pretraining.py:  558]:	worker_index: 6, step: 1016, cost: 6.162370, mlm loss: 6.162370, speed: 1.100025 steps/s, speed: 8.800202 samples/s, speed: 4505.703557 tokens/s, learning rate: 1.015e-05, loss_scalings: 13421.773438, pp_loss: 7.408707
[INFO] 2021-07-12 18:52:20,805 [run_pretraining.py:  512]:	********exe.run_1016******* 
[INFO] 2021-07-12 18:52:21,717 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:21,718 [run_pretraining.py:  534]:	loss/total_loss, 8.014484405517578, 1017
[INFO] 2021-07-12 18:52:21,718 [run_pretraining.py:  535]:	loss/mlm_loss, 8.014484405517578, 1017
[INFO] 2021-07-12 18:52:21,718 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0159999874304049e-05, 1017
[INFO] 2021-07-12 18:52:21,718 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1017
[INFO] 2021-07-12 18:52:21,718 [run_pretraining.py:  558]:	worker_index: 6, step: 1017, cost: 8.014484, mlm loss: 8.014484, speed: 1.095647 steps/s, speed: 8.765175 samples/s, speed: 4487.769738 tokens/s, learning rate: 1.016e-05, loss_scalings: 13421.773438, pp_loss: 6.820647
[INFO] 2021-07-12 18:52:21,718 [run_pretraining.py:  512]:	********exe.run_1017******* 
[INFO] 2021-07-12 18:52:22,623 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:22,624 [run_pretraining.py:  534]:	loss/total_loss, 8.429428100585938, 1018
[INFO] 2021-07-12 18:52:22,624 [run_pretraining.py:  535]:	loss/mlm_loss, 8.429428100585938, 1018
[INFO] 2021-07-12 18:52:22,624 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0169999768550042e-05, 1018
[INFO] 2021-07-12 18:52:22,624 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1018
[INFO] 2021-07-12 18:52:22,624 [run_pretraining.py:  558]:	worker_index: 6, step: 1018, cost: 8.429428, mlm loss: 8.429428, speed: 1.104488 steps/s, speed: 8.835904 samples/s, speed: 4523.982605 tokens/s, learning rate: 1.017e-05, loss_scalings: 13421.773438, pp_loss: 8.094368
[INFO] 2021-07-12 18:52:22,624 [run_pretraining.py:  512]:	********exe.run_1018******* 
[INFO] 2021-07-12 18:52:23,524 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:23,525 [run_pretraining.py:  534]:	loss/total_loss, 7.400864601135254, 1019
[INFO] 2021-07-12 18:52:23,525 [run_pretraining.py:  535]:	loss/mlm_loss, 7.400864601135254, 1019
[INFO] 2021-07-12 18:52:23,525 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0179999662796035e-05, 1019
[INFO] 2021-07-12 18:52:23,525 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1019
[INFO] 2021-07-12 18:52:23,525 [run_pretraining.py:  558]:	worker_index: 6, step: 1019, cost: 7.400865, mlm loss: 7.400865, speed: 1.110616 steps/s, speed: 8.884924 samples/s, speed: 4549.081249 tokens/s, learning rate: 1.018e-05, loss_scalings: 13421.773438, pp_loss: 7.841949
[INFO] 2021-07-12 18:52:23,525 [run_pretraining.py:  512]:	********exe.run_1019******* 
[INFO] 2021-07-12 18:52:24,435 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:24,435 [run_pretraining.py:  534]:	loss/total_loss, 7.97229528427124, 1020
[INFO] 2021-07-12 18:52:24,435 [run_pretraining.py:  535]:	loss/mlm_loss, 7.97229528427124, 1020
[INFO] 2021-07-12 18:52:24,435 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0189999557042029e-05, 1020
[INFO] 2021-07-12 18:52:24,435 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1020
[INFO] 2021-07-12 18:52:24,436 [run_pretraining.py:  558]:	worker_index: 6, step: 1020, cost: 7.972295, mlm loss: 7.972295, speed: 1.099485 steps/s, speed: 8.795884 samples/s, speed: 4503.492510 tokens/s, learning rate: 1.019e-05, loss_scalings: 13421.773438, pp_loss: 8.060152
[INFO] 2021-07-12 18:52:24,436 [run_pretraining.py:  512]:	********exe.run_1020******* 
[INFO] 2021-07-12 18:52:25,404 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:25,405 [run_pretraining.py:  534]:	loss/total_loss, 7.61819314956665, 1021
[INFO] 2021-07-12 18:52:25,405 [run_pretraining.py:  535]:	loss/mlm_loss, 7.61819314956665, 1021
[INFO] 2021-07-12 18:52:25,405 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0199999451288022e-05, 1021
[INFO] 2021-07-12 18:52:25,405 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1021
[INFO] 2021-07-12 18:52:25,405 [run_pretraining.py:  558]:	worker_index: 6, step: 1021, cost: 7.618193, mlm loss: 7.618193, speed: 1.032231 steps/s, speed: 8.257845 samples/s, speed: 4228.016652 tokens/s, learning rate: 1.020e-05, loss_scalings: 13421.773438, pp_loss: 7.583002
[INFO] 2021-07-12 18:52:25,405 [run_pretraining.py:  512]:	********exe.run_1021******* 
[INFO] 2021-07-12 18:52:26,463 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:26,464 [run_pretraining.py:  534]:	loss/total_loss, 7.783712863922119, 1022
[INFO] 2021-07-12 18:52:26,464 [run_pretraining.py:  535]:	loss/mlm_loss, 7.783712863922119, 1022
[INFO] 2021-07-12 18:52:26,464 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0209999345534015e-05, 1022
[INFO] 2021-07-12 18:52:26,464 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1022
[INFO] 2021-07-12 18:52:26,464 [run_pretraining.py:  558]:	worker_index: 6, step: 1022, cost: 7.783713, mlm loss: 7.783713, speed: 0.944649 steps/s, speed: 7.557189 samples/s, speed: 3869.280647 tokens/s, learning rate: 1.021e-05, loss_scalings: 13421.773438, pp_loss: 7.744591
[INFO] 2021-07-12 18:52:26,464 [run_pretraining.py:  512]:	********exe.run_1022******* 
[INFO] 2021-07-12 18:52:27,520 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:27,521 [run_pretraining.py:  534]:	loss/total_loss, 8.112471580505371, 1023
[INFO] 2021-07-12 18:52:27,521 [run_pretraining.py:  535]:	loss/mlm_loss, 8.112471580505371, 1023
[INFO] 2021-07-12 18:52:27,521 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.022000014927471e-05, 1023
[INFO] 2021-07-12 18:52:27,521 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1023
[INFO] 2021-07-12 18:52:27,521 [run_pretraining.py:  558]:	worker_index: 6, step: 1023, cost: 8.112472, mlm loss: 8.112472, speed: 0.946859 steps/s, speed: 7.574875 samples/s, speed: 3878.336074 tokens/s, learning rate: 1.022e-05, loss_scalings: 13421.773438, pp_loss: 7.816649
[INFO] 2021-07-12 18:52:27,521 [run_pretraining.py:  512]:	********exe.run_1023******* 
[INFO] 2021-07-12 18:52:28,581 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:28,582 [run_pretraining.py:  534]:	loss/total_loss, 7.642329692840576, 1024
[INFO] 2021-07-12 18:52:28,582 [run_pretraining.py:  535]:	loss/mlm_loss, 7.642329692840576, 1024
[INFO] 2021-07-12 18:52:28,582 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0230000043520704e-05, 1024
[INFO] 2021-07-12 18:52:28,582 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1024
[INFO] 2021-07-12 18:52:28,582 [run_pretraining.py:  558]:	worker_index: 6, step: 1024, cost: 7.642330, mlm loss: 7.642330, speed: 0.942963 steps/s, speed: 7.543702 samples/s, speed: 3862.375452 tokens/s, learning rate: 1.023e-05, loss_scalings: 13421.773438, pp_loss: 7.860431
[INFO] 2021-07-12 18:52:28,582 [run_pretraining.py:  512]:	********exe.run_1024******* 
[INFO] 2021-07-12 18:52:29,647 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:29,647 [run_pretraining.py:  534]:	loss/total_loss, 8.093633651733398, 1025
[INFO] 2021-07-12 18:52:29,648 [run_pretraining.py:  535]:	loss/mlm_loss, 8.093633651733398, 1025
[INFO] 2021-07-12 18:52:29,648 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0239999028271995e-05, 1025
[INFO] 2021-07-12 18:52:29,648 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1025
[INFO] 2021-07-12 18:52:29,648 [run_pretraining.py:  558]:	worker_index: 6, step: 1025, cost: 8.093634, mlm loss: 8.093634, speed: 0.939120 steps/s, speed: 7.512963 samples/s, speed: 3846.636951 tokens/s, learning rate: 1.024e-05, loss_scalings: 13421.773438, pp_loss: 7.616914
[INFO] 2021-07-12 18:52:29,648 [run_pretraining.py:  512]:	********exe.run_1025******* 
[INFO] 2021-07-12 18:52:30,707 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:30,708 [run_pretraining.py:  534]:	loss/total_loss, 7.741513252258301, 1026
[INFO] 2021-07-12 18:52:30,708 [run_pretraining.py:  535]:	loss/mlm_loss, 7.741513252258301, 1026
[INFO] 2021-07-12 18:52:30,708 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.024999983201269e-05, 1026
[INFO] 2021-07-12 18:52:30,708 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1026
[INFO] 2021-07-12 18:52:30,708 [run_pretraining.py:  558]:	worker_index: 6, step: 1026, cost: 7.741513, mlm loss: 7.741513, speed: 0.943753 steps/s, speed: 7.550027 samples/s, speed: 3865.613594 tokens/s, learning rate: 1.025e-05, loss_scalings: 13421.773438, pp_loss: 7.804560
[INFO] 2021-07-12 18:52:30,708 [run_pretraining.py:  512]:	********exe.run_1026******* 
[INFO] 2021-07-12 18:52:31,871 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:31,872 [run_pretraining.py:  534]:	loss/total_loss, 7.925709247589111, 1027
[INFO] 2021-07-12 18:52:31,872 [run_pretraining.py:  535]:	loss/mlm_loss, 7.925709247589111, 1027
[INFO] 2021-07-12 18:52:31,872 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0259999726258684e-05, 1027
[INFO] 2021-07-12 18:52:31,872 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1027
[INFO] 2021-07-12 18:52:31,872 [run_pretraining.py:  558]:	worker_index: 6, step: 1027, cost: 7.925709, mlm loss: 7.925709, speed: 0.859744 steps/s, speed: 6.877955 samples/s, speed: 3521.512791 tokens/s, learning rate: 1.026e-05, loss_scalings: 13421.773438, pp_loss: 7.997292
[INFO] 2021-07-12 18:52:31,872 [run_pretraining.py:  512]:	********exe.run_1027******* 
[INFO] 2021-07-12 18:52:32,919 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:32,920 [run_pretraining.py:  534]:	loss/total_loss, 7.6643147468566895, 1028
[INFO] 2021-07-12 18:52:32,920 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6643147468566895, 1028
[INFO] 2021-07-12 18:52:32,920 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0269999620504677e-05, 1028
[INFO] 2021-07-12 18:52:32,920 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1028
[INFO] 2021-07-12 18:52:32,920 [run_pretraining.py:  558]:	worker_index: 6, step: 1028, cost: 7.664315, mlm loss: 7.664315, speed: 0.954768 steps/s, speed: 7.638147 samples/s, speed: 3910.731120 tokens/s, learning rate: 1.027e-05, loss_scalings: 13421.773438, pp_loss: 7.730924
[INFO] 2021-07-12 18:52:32,920 [run_pretraining.py:  512]:	********exe.run_1028******* 
[INFO] 2021-07-12 18:52:33,973 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:33,973 [run_pretraining.py:  534]:	loss/total_loss, 7.814915180206299, 1029
[INFO] 2021-07-12 18:52:33,974 [run_pretraining.py:  535]:	loss/mlm_loss, 7.814915180206299, 1029
[INFO] 2021-07-12 18:52:33,974 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.027999951475067e-05, 1029
[INFO] 2021-07-12 18:52:33,974 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1029
[INFO] 2021-07-12 18:52:33,974 [run_pretraining.py:  558]:	worker_index: 6, step: 1029, cost: 7.814915, mlm loss: 7.814915, speed: 0.949546 steps/s, speed: 7.596371 samples/s, speed: 3889.341986 tokens/s, learning rate: 1.028e-05, loss_scalings: 13421.773438, pp_loss: 7.657726
[INFO] 2021-07-12 18:52:33,974 [run_pretraining.py:  512]:	********exe.run_1029******* 
[INFO] 2021-07-12 18:52:35,028 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:35,028 [run_pretraining.py:  534]:	loss/total_loss, 7.568098068237305, 1030
[INFO] 2021-07-12 18:52:35,028 [run_pretraining.py:  535]:	loss/mlm_loss, 7.568098068237305, 1030
[INFO] 2021-07-12 18:52:35,028 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0289999408996664e-05, 1030
[INFO] 2021-07-12 18:52:35,028 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1030
[INFO] 2021-07-12 18:52:35,028 [run_pretraining.py:  558]:	worker_index: 6, step: 1030, cost: 7.568098, mlm loss: 7.568098, speed: 0.948850 steps/s, speed: 7.590803 samples/s, speed: 3886.491237 tokens/s, learning rate: 1.029e-05, loss_scalings: 13421.773438, pp_loss: 7.928439
[INFO] 2021-07-12 18:52:35,029 [run_pretraining.py:  512]:	********exe.run_1030******* 
[INFO] 2021-07-12 18:52:36,090 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:36,091 [run_pretraining.py:  534]:	loss/total_loss, 7.880478382110596, 1031
[INFO] 2021-07-12 18:52:36,091 [run_pretraining.py:  535]:	loss/mlm_loss, 7.880478382110596, 1031
[INFO] 2021-07-12 18:52:36,091 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0299999303242657e-05, 1031
[INFO] 2021-07-12 18:52:36,091 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1031
[INFO] 2021-07-12 18:52:36,091 [run_pretraining.py:  558]:	worker_index: 6, step: 1031, cost: 7.880478, mlm loss: 7.880478, speed: 0.941394 steps/s, speed: 7.531152 samples/s, speed: 3855.950033 tokens/s, learning rate: 1.030e-05, loss_scalings: 13421.773438, pp_loss: 7.678125
[INFO] 2021-07-12 18:52:36,092 [run_pretraining.py:  512]:	********exe.run_1031******* 
[INFO] 2021-07-12 18:52:37,157 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:37,157 [run_pretraining.py:  534]:	loss/total_loss, 7.57570743560791, 1032
[INFO] 2021-07-12 18:52:37,157 [run_pretraining.py:  535]:	loss/mlm_loss, 7.57570743560791, 1032
[INFO] 2021-07-12 18:52:37,157 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0310000106983352e-05, 1032
[INFO] 2021-07-12 18:52:37,158 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1032
[INFO] 2021-07-12 18:52:37,158 [run_pretraining.py:  558]:	worker_index: 6, step: 1032, cost: 7.575707, mlm loss: 7.575707, speed: 0.938524 steps/s, speed: 7.508190 samples/s, speed: 3844.193341 tokens/s, learning rate: 1.031e-05, loss_scalings: 13421.773438, pp_loss: 7.790339
[INFO] 2021-07-12 18:52:37,158 [run_pretraining.py:  512]:	********exe.run_1032******* 
[INFO] 2021-07-12 18:52:38,215 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:38,216 [run_pretraining.py:  534]:	loss/total_loss, 8.08388900756836, 1033
[INFO] 2021-07-12 18:52:38,216 [run_pretraining.py:  535]:	loss/mlm_loss, 8.08388900756836, 1033
[INFO] 2021-07-12 18:52:38,216 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0320000001229346e-05, 1033
[INFO] 2021-07-12 18:52:38,216 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1033
[INFO] 2021-07-12 18:52:38,216 [run_pretraining.py:  558]:	worker_index: 6, step: 1033, cost: 8.083889, mlm loss: 8.083889, speed: 0.945156 steps/s, speed: 7.561245 samples/s, speed: 3871.357546 tokens/s, learning rate: 1.032e-05, loss_scalings: 13421.773438, pp_loss: 7.846013
[INFO] 2021-07-12 18:52:38,216 [run_pretraining.py:  512]:	********exe.run_1033******* 
[INFO] 2021-07-12 18:52:39,329 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:39,329 [run_pretraining.py:  534]:	loss/total_loss, 7.804819107055664, 1034
[INFO] 2021-07-12 18:52:39,329 [run_pretraining.py:  535]:	loss/mlm_loss, 7.804819107055664, 1034
[INFO] 2021-07-12 18:52:39,330 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0329999895475339e-05, 1034
[INFO] 2021-07-12 18:52:39,330 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1034
[INFO] 2021-07-12 18:52:39,330 [run_pretraining.py:  558]:	worker_index: 6, step: 1034, cost: 7.804819, mlm loss: 7.804819, speed: 0.898761 steps/s, speed: 7.190092 samples/s, speed: 3681.326913 tokens/s, learning rate: 1.033e-05, loss_scalings: 13421.773438, pp_loss: 7.654985
[INFO] 2021-07-12 18:52:39,330 [run_pretraining.py:  512]:	********exe.run_1034******* 
[INFO] 2021-07-12 18:52:40,366 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:40,367 [run_pretraining.py:  534]:	loss/total_loss, 7.714347839355469, 1035
[INFO] 2021-07-12 18:52:40,367 [run_pretraining.py:  535]:	loss/mlm_loss, 7.714347839355469, 1035
[INFO] 2021-07-12 18:52:40,367 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0339999789721332e-05, 1035
[INFO] 2021-07-12 18:52:40,367 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1035
[INFO] 2021-07-12 18:52:40,367 [run_pretraining.py:  558]:	worker_index: 6, step: 1035, cost: 7.714348, mlm loss: 7.714348, speed: 0.964570 steps/s, speed: 7.716558 samples/s, speed: 3950.877475 tokens/s, learning rate: 1.034e-05, loss_scalings: 13421.773438, pp_loss: 7.285578
[INFO] 2021-07-12 18:52:40,367 [run_pretraining.py:  512]:	********exe.run_1035******* 
[INFO] 2021-07-12 18:52:41,424 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:41,425 [run_pretraining.py:  534]:	loss/total_loss, 5.247079849243164, 1036
[INFO] 2021-07-12 18:52:41,425 [run_pretraining.py:  535]:	loss/mlm_loss, 5.247079849243164, 1036
[INFO] 2021-07-12 18:52:41,425 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0349999683967326e-05, 1036
[INFO] 2021-07-12 18:52:41,425 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1036
[INFO] 2021-07-12 18:52:41,425 [run_pretraining.py:  558]:	worker_index: 6, step: 1036, cost: 5.247080, mlm loss: 5.247080, speed: 0.945615 steps/s, speed: 7.564921 samples/s, speed: 3873.239316 tokens/s, learning rate: 1.035e-05, loss_scalings: 13421.773438, pp_loss: 7.428672
[INFO] 2021-07-12 18:52:41,425 [run_pretraining.py:  512]:	********exe.run_1036******* 
[INFO] 2021-07-12 18:52:42,489 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:42,490 [run_pretraining.py:  534]:	loss/total_loss, 8.914046287536621, 1037
[INFO] 2021-07-12 18:52:42,490 [run_pretraining.py:  535]:	loss/mlm_loss, 8.914046287536621, 1037
[INFO] 2021-07-12 18:52:42,490 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.035999957821332e-05, 1037
[INFO] 2021-07-12 18:52:42,490 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1037
[INFO] 2021-07-12 18:52:42,490 [run_pretraining.py:  558]:	worker_index: 6, step: 1037, cost: 8.914046, mlm loss: 8.914046, speed: 0.939785 steps/s, speed: 7.518277 samples/s, speed: 3849.357924 tokens/s, learning rate: 1.036e-05, loss_scalings: 13421.773438, pp_loss: 8.135424
[INFO] 2021-07-12 18:52:42,490 [run_pretraining.py:  512]:	********exe.run_1037******* 
[INFO] 2021-07-12 18:52:43,544 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:43,544 [run_pretraining.py:  534]:	loss/total_loss, 8.174731254577637, 1038
[INFO] 2021-07-12 18:52:43,544 [run_pretraining.py:  535]:	loss/mlm_loss, 8.174731254577637, 1038
[INFO] 2021-07-12 18:52:43,544 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0369999472459313e-05, 1038
[INFO] 2021-07-12 18:52:43,544 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1038
[INFO] 2021-07-12 18:52:43,544 [run_pretraining.py:  558]:	worker_index: 6, step: 1038, cost: 8.174731, mlm loss: 8.174731, speed: 0.949117 steps/s, speed: 7.592938 samples/s, speed: 3887.584410 tokens/s, learning rate: 1.037e-05, loss_scalings: 13421.773438, pp_loss: 8.094651
[INFO] 2021-07-12 18:52:43,545 [run_pretraining.py:  512]:	********exe.run_1038******* 
[INFO] 2021-07-12 18:52:44,522 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:44,522 [run_pretraining.py:  534]:	loss/total_loss, 7.6206278800964355, 1039
[INFO] 2021-07-12 18:52:44,522 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6206278800964355, 1039
[INFO] 2021-07-12 18:52:44,522 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0379999366705306e-05, 1039
[INFO] 2021-07-12 18:52:44,522 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1039
[INFO] 2021-07-12 18:52:44,523 [run_pretraining.py:  558]:	worker_index: 6, step: 1039, cost: 7.620628, mlm loss: 7.620628, speed: 1.023186 steps/s, speed: 8.185487 samples/s, speed: 4190.969437 tokens/s, learning rate: 1.038e-05, loss_scalings: 13421.773438, pp_loss: 7.887367
[INFO] 2021-07-12 18:52:44,523 [run_pretraining.py:  512]:	********exe.run_1039******* 
[INFO] 2021-07-12 18:52:45,484 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:45,485 [run_pretraining.py:  534]:	loss/total_loss, 7.418834686279297, 1040
[INFO] 2021-07-12 18:52:45,485 [run_pretraining.py:  535]:	loss/mlm_loss, 7.418834686279297, 1040
[INFO] 2021-07-12 18:52:45,485 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0390000170446001e-05, 1040
[INFO] 2021-07-12 18:52:45,485 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1040
[INFO] 2021-07-12 18:52:45,485 [run_pretraining.py:  558]:	worker_index: 6, step: 1040, cost: 7.418835, mlm loss: 7.418835, speed: 1.039774 steps/s, speed: 8.318192 samples/s, speed: 4258.914520 tokens/s, learning rate: 1.039e-05, loss_scalings: 13421.773438, pp_loss: 7.617652
[INFO] 2021-07-12 18:52:45,485 [run_pretraining.py:  512]:	********exe.run_1040******* 
[INFO] 2021-07-12 18:52:46,446 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:46,446 [run_pretraining.py:  534]:	loss/total_loss, 7.698044776916504, 1041
[INFO] 2021-07-12 18:52:46,447 [run_pretraining.py:  535]:	loss/mlm_loss, 7.698044776916504, 1041
[INFO] 2021-07-12 18:52:46,447 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0400000064691994e-05, 1041
[INFO] 2021-07-12 18:52:46,447 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1041
[INFO] 2021-07-12 18:52:46,447 [run_pretraining.py:  558]:	worker_index: 6, step: 1041, cost: 7.698045, mlm loss: 7.698045, speed: 1.040409 steps/s, speed: 8.323270 samples/s, speed: 4261.514408 tokens/s, learning rate: 1.040e-05, loss_scalings: 13421.773438, pp_loss: 7.926078
[INFO] 2021-07-12 18:52:46,447 [run_pretraining.py:  512]:	********exe.run_1041******* 
[INFO] 2021-07-12 18:52:47,397 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:47,397 [run_pretraining.py:  534]:	loss/total_loss, 8.043340682983398, 1042
[INFO] 2021-07-12 18:52:47,397 [run_pretraining.py:  535]:	loss/mlm_loss, 8.043340682983398, 1042
[INFO] 2021-07-12 18:52:47,397 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0409999049443286e-05, 1042
[INFO] 2021-07-12 18:52:47,397 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1042
[INFO] 2021-07-12 18:52:47,398 [run_pretraining.py:  558]:	worker_index: 6, step: 1042, cost: 8.043341, mlm loss: 8.043341, speed: 1.052610 steps/s, speed: 8.420879 samples/s, speed: 4311.490004 tokens/s, learning rate: 1.041e-05, loss_scalings: 13421.773438, pp_loss: 7.697060
[INFO] 2021-07-12 18:52:47,398 [run_pretraining.py:  512]:	********exe.run_1042******* 
[INFO] 2021-07-12 18:52:48,352 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:48,352 [run_pretraining.py:  534]:	loss/total_loss, 7.525911808013916, 1043
[INFO] 2021-07-12 18:52:48,352 [run_pretraining.py:  535]:	loss/mlm_loss, 7.525911808013916, 1043
[INFO] 2021-07-12 18:52:48,353 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0419999853183981e-05, 1043
[INFO] 2021-07-12 18:52:48,353 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1043
[INFO] 2021-07-12 18:52:48,353 [run_pretraining.py:  558]:	worker_index: 6, step: 1043, cost: 7.525912, mlm loss: 7.525912, speed: 1.047699 steps/s, speed: 8.381588 samples/s, speed: 4291.373271 tokens/s, learning rate: 1.042e-05, loss_scalings: 13421.773438, pp_loss: 7.610900
[INFO] 2021-07-12 18:52:48,353 [run_pretraining.py:  512]:	********exe.run_1043******* 
[INFO] 2021-07-12 18:52:49,313 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:49,314 [run_pretraining.py:  534]:	loss/total_loss, 7.991454124450684, 1044
[INFO] 2021-07-12 18:52:49,314 [run_pretraining.py:  535]:	loss/mlm_loss, 7.991454124450684, 1044
[INFO] 2021-07-12 18:52:49,314 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0429999747429974e-05, 1044
[INFO] 2021-07-12 18:52:49,314 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1044
[INFO] 2021-07-12 18:52:49,314 [run_pretraining.py:  558]:	worker_index: 6, step: 1044, cost: 7.991454, mlm loss: 7.991454, speed: 1.040615 steps/s, speed: 8.324916 samples/s, speed: 4262.357068 tokens/s, learning rate: 1.043e-05, loss_scalings: 13421.773438, pp_loss: 8.003424
[INFO] 2021-07-12 18:52:49,314 [run_pretraining.py:  512]:	********exe.run_1044******* 
[INFO] 2021-07-12 18:52:50,269 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:50,270 [run_pretraining.py:  534]:	loss/total_loss, 7.828639030456543, 1045
[INFO] 2021-07-12 18:52:50,270 [run_pretraining.py:  535]:	loss/mlm_loss, 7.828639030456543, 1045
[INFO] 2021-07-12 18:52:50,270 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0439999641675968e-05, 1045
[INFO] 2021-07-12 18:52:50,270 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1045
[INFO] 2021-07-12 18:52:50,270 [run_pretraining.py:  558]:	worker_index: 6, step: 1045, cost: 7.828639, mlm loss: 7.828639, speed: 1.046854 steps/s, speed: 8.374836 samples/s, speed: 4287.915818 tokens/s, learning rate: 1.044e-05, loss_scalings: 13421.773438, pp_loss: 7.835969
[INFO] 2021-07-12 18:52:50,270 [run_pretraining.py:  512]:	********exe.run_1045******* 
[INFO] 2021-07-12 18:52:51,173 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:51,174 [run_pretraining.py:  534]:	loss/total_loss, 8.041960716247559, 1046
[INFO] 2021-07-12 18:52:51,174 [run_pretraining.py:  535]:	loss/mlm_loss, 8.041960716247559, 1046
[INFO] 2021-07-12 18:52:51,174 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0450000445416663e-05, 1046
[INFO] 2021-07-12 18:52:51,174 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1046
[INFO] 2021-07-12 18:52:51,174 [run_pretraining.py:  558]:	worker_index: 6, step: 1046, cost: 8.041961, mlm loss: 8.041961, speed: 1.107199 steps/s, speed: 8.857591 samples/s, speed: 4535.086522 tokens/s, learning rate: 1.045e-05, loss_scalings: 13421.773438, pp_loss: 8.136873
[INFO] 2021-07-12 18:52:51,174 [run_pretraining.py:  512]:	********exe.run_1046******* 
[INFO] 2021-07-12 18:52:52,079 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:52,079 [run_pretraining.py:  534]:	loss/total_loss, 7.329564094543457, 1047
[INFO] 2021-07-12 18:52:52,079 [run_pretraining.py:  535]:	loss/mlm_loss, 7.329564094543457, 1047
[INFO] 2021-07-12 18:52:52,079 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0459999430167954e-05, 1047
[INFO] 2021-07-12 18:52:52,079 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1047
[INFO] 2021-07-12 18:52:52,080 [run_pretraining.py:  558]:	worker_index: 6, step: 1047, cost: 7.329564, mlm loss: 7.329564, speed: 1.105449 steps/s, speed: 8.843596 samples/s, speed: 4527.920903 tokens/s, learning rate: 1.046e-05, loss_scalings: 13421.773438, pp_loss: 7.742501
[INFO] 2021-07-12 18:52:52,080 [run_pretraining.py:  512]:	********exe.run_1047******* 
[INFO] 2021-07-12 18:52:52,985 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:52,985 [run_pretraining.py:  534]:	loss/total_loss, 8.320696830749512, 1048
[INFO] 2021-07-12 18:52:52,985 [run_pretraining.py:  535]:	loss/mlm_loss, 8.320696830749512, 1048
[INFO] 2021-07-12 18:52:52,985 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0469999324413948e-05, 1048
[INFO] 2021-07-12 18:52:52,986 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1048
[INFO] 2021-07-12 18:52:52,986 [run_pretraining.py:  558]:	worker_index: 6, step: 1048, cost: 8.320697, mlm loss: 8.320697, speed: 1.104469 steps/s, speed: 8.835752 samples/s, speed: 4523.905172 tokens/s, learning rate: 1.047e-05, loss_scalings: 13421.773438, pp_loss: 8.226151
[INFO] 2021-07-12 18:52:52,986 [run_pretraining.py:  512]:	********exe.run_1048******* 
[INFO] 2021-07-12 18:52:53,887 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:53,887 [run_pretraining.py:  534]:	loss/total_loss, 7.949047088623047, 1049
[INFO] 2021-07-12 18:52:53,888 [run_pretraining.py:  535]:	loss/mlm_loss, 7.949047088623047, 1049
[INFO] 2021-07-12 18:52:53,888 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0480000128154643e-05, 1049
[INFO] 2021-07-12 18:52:53,888 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1049
[INFO] 2021-07-12 18:52:53,888 [run_pretraining.py:  558]:	worker_index: 6, step: 1049, cost: 7.949047, mlm loss: 7.949047, speed: 1.109276 steps/s, speed: 8.874209 samples/s, speed: 4543.595091 tokens/s, learning rate: 1.048e-05, loss_scalings: 13421.773438, pp_loss: 7.864767
[INFO] 2021-07-12 18:52:53,888 [run_pretraining.py:  512]:	********exe.run_1049******* 
[INFO] 2021-07-12 18:52:54,796 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:54,796 [run_pretraining.py:  534]:	loss/total_loss, 7.6432881355285645, 1050
[INFO] 2021-07-12 18:52:54,796 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6432881355285645, 1050
[INFO] 2021-07-12 18:52:54,796 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0490000022400636e-05, 1050
[INFO] 2021-07-12 18:52:54,797 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1050
[INFO] 2021-07-12 18:52:54,797 [run_pretraining.py:  558]:	worker_index: 6, step: 1050, cost: 7.643288, mlm loss: 7.643288, speed: 1.101288 steps/s, speed: 8.810307 samples/s, speed: 4510.877042 tokens/s, learning rate: 1.049e-05, loss_scalings: 13421.773438, pp_loss: 7.732294
[INFO] 2021-07-12 18:52:54,797 [run_pretraining.py:  512]:	********exe.run_1050******* 
[INFO] 2021-07-12 18:52:55,704 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:55,705 [run_pretraining.py:  534]:	loss/total_loss, 8.0316743850708, 1051
[INFO] 2021-07-12 18:52:55,705 [run_pretraining.py:  535]:	loss/mlm_loss, 8.0316743850708, 1051
[INFO] 2021-07-12 18:52:55,705 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0499999007151928e-05, 1051
[INFO] 2021-07-12 18:52:55,705 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1051
[INFO] 2021-07-12 18:52:55,705 [run_pretraining.py:  558]:	worker_index: 6, step: 1051, cost: 8.031674, mlm loss: 8.031674, speed: 1.101523 steps/s, speed: 8.812183 samples/s, speed: 4511.837804 tokens/s, learning rate: 1.050e-05, loss_scalings: 13421.773438, pp_loss: 7.923808
[INFO] 2021-07-12 18:52:55,705 [run_pretraining.py:  512]:	********exe.run_1051******* 
[INFO] 2021-07-12 18:52:56,615 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:56,616 [run_pretraining.py:  534]:	loss/total_loss, 8.026311874389648, 1052
[INFO] 2021-07-12 18:52:56,616 [run_pretraining.py:  535]:	loss/mlm_loss, 8.026311874389648, 1052
[INFO] 2021-07-12 18:52:56,616 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0509999810892623e-05, 1052
[INFO] 2021-07-12 18:52:56,616 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1052
[INFO] 2021-07-12 18:52:56,616 [run_pretraining.py:  558]:	worker_index: 6, step: 1052, cost: 8.026312, mlm loss: 8.026312, speed: 1.098390 steps/s, speed: 8.787117 samples/s, speed: 4499.003870 tokens/s, learning rate: 1.051e-05, loss_scalings: 13421.773438, pp_loss: 7.950413
[INFO] 2021-07-12 18:52:56,616 [run_pretraining.py:  512]:	********exe.run_1052******* 
[INFO] 2021-07-12 18:52:57,517 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:57,518 [run_pretraining.py:  534]:	loss/total_loss, 7.868222713470459, 1053
[INFO] 2021-07-12 18:52:57,518 [run_pretraining.py:  535]:	loss/mlm_loss, 7.868222713470459, 1053
[INFO] 2021-07-12 18:52:57,518 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0519999705138616e-05, 1053
[INFO] 2021-07-12 18:52:57,518 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1053
[INFO] 2021-07-12 18:52:57,518 [run_pretraining.py:  558]:	worker_index: 6, step: 1053, cost: 7.868223, mlm loss: 7.868223, speed: 1.109263 steps/s, speed: 8.874104 samples/s, speed: 4543.541017 tokens/s, learning rate: 1.052e-05, loss_scalings: 13421.773438, pp_loss: 7.823142
[INFO] 2021-07-12 18:52:57,519 [run_pretraining.py:  512]:	********exe.run_1053******* 
[INFO] 2021-07-12 18:52:58,470 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:58,470 [run_pretraining.py:  534]:	loss/total_loss, 8.570586204528809, 1054
[INFO] 2021-07-12 18:52:58,471 [run_pretraining.py:  535]:	loss/mlm_loss, 8.570586204528809, 1054
[INFO] 2021-07-12 18:52:58,471 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.052999959938461e-05, 1054
[INFO] 2021-07-12 18:52:58,471 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1054
[INFO] 2021-07-12 18:52:58,471 [run_pretraining.py:  558]:	worker_index: 6, step: 1054, cost: 8.570586, mlm loss: 8.570586, speed: 1.050809 steps/s, speed: 8.406476 samples/s, speed: 4304.115694 tokens/s, learning rate: 1.053e-05, loss_scalings: 13421.773438, pp_loss: 6.504401
[INFO] 2021-07-12 18:52:58,471 [run_pretraining.py:  512]:	********exe.run_1054******* 
[INFO] 2021-07-12 18:52:59,534 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:59,535 [run_pretraining.py:  534]:	loss/total_loss, 8.073555946350098, 1055
[INFO] 2021-07-12 18:52:59,535 [run_pretraining.py:  535]:	loss/mlm_loss, 8.073555946350098, 1055
[INFO] 2021-07-12 18:52:59,535 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0540000403125305e-05, 1055
[INFO] 2021-07-12 18:52:59,535 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1055
[INFO] 2021-07-12 18:52:59,535 [run_pretraining.py:  558]:	worker_index: 6, step: 1055, cost: 8.073556, mlm loss: 8.073556, speed: 0.940059 steps/s, speed: 7.520473 samples/s, speed: 3850.482084 tokens/s, learning rate: 1.054e-05, loss_scalings: 13421.773438, pp_loss: 7.923348
[INFO] 2021-07-12 18:52:59,535 [run_pretraining.py:  512]:	********exe.run_1055******* 
[INFO] 2021-07-12 18:53:00,598 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:00,599 [run_pretraining.py:  534]:	loss/total_loss, 7.617548942565918, 1056
[INFO] 2021-07-12 18:53:00,599 [run_pretraining.py:  535]:	loss/mlm_loss, 7.617548942565918, 1056
[INFO] 2021-07-12 18:53:00,599 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0549999387876596e-05, 1056
[INFO] 2021-07-12 18:53:00,599 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1056
[INFO] 2021-07-12 18:53:00,599 [run_pretraining.py:  558]:	worker_index: 6, step: 1056, cost: 7.617549, mlm loss: 7.617549, speed: 0.940453 steps/s, speed: 7.523623 samples/s, speed: 3852.094841 tokens/s, learning rate: 1.055e-05, loss_scalings: 13421.773438, pp_loss: 7.494011
[INFO] 2021-07-12 18:53:00,599 [run_pretraining.py:  512]:	********exe.run_1056******* 
[INFO] 2021-07-12 18:53:01,686 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:01,687 [run_pretraining.py:  534]:	loss/total_loss, 7.748582363128662, 1057
[INFO] 2021-07-12 18:53:01,687 [run_pretraining.py:  535]:	loss/mlm_loss, 7.748582363128662, 1057
[INFO] 2021-07-12 18:53:01,687 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.055999928212259e-05, 1057
[INFO] 2021-07-12 18:53:01,687 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1057
[INFO] 2021-07-12 18:53:01,687 [run_pretraining.py:  558]:	worker_index: 6, step: 1057, cost: 7.748582, mlm loss: 7.748582, speed: 0.919906 steps/s, speed: 7.359245 samples/s, speed: 3767.933280 tokens/s, learning rate: 1.056e-05, loss_scalings: 13421.773438, pp_loss: 7.585920
[INFO] 2021-07-12 18:53:01,687 [run_pretraining.py:  512]:	********exe.run_1057******* 
[INFO] 2021-07-12 18:53:02,799 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:02,800 [run_pretraining.py:  534]:	loss/total_loss, 8.011079788208008, 1058
[INFO] 2021-07-12 18:53:02,800 [run_pretraining.py:  535]:	loss/mlm_loss, 8.011079788208008, 1058
[INFO] 2021-07-12 18:53:02,800 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0570000085863285e-05, 1058
[INFO] 2021-07-12 18:53:02,800 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1058
[INFO] 2021-07-12 18:53:02,800 [run_pretraining.py:  558]:	worker_index: 6, step: 1058, cost: 8.011080, mlm loss: 8.011080, speed: 0.898977 steps/s, speed: 7.191819 samples/s, speed: 3682.211415 tokens/s, learning rate: 1.057e-05, loss_scalings: 13421.773438, pp_loss: 7.553449
[INFO] 2021-07-12 18:53:02,800 [run_pretraining.py:  512]:	********exe.run_1058******* 
[INFO] 2021-07-12 18:53:03,889 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:03,890 [run_pretraining.py:  534]:	loss/total_loss, 7.623167037963867, 1059
[INFO] 2021-07-12 18:53:03,890 [run_pretraining.py:  535]:	loss/mlm_loss, 7.623167037963867, 1059
[INFO] 2021-07-12 18:53:03,890 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0579999980109278e-05, 1059
[INFO] 2021-07-12 18:53:03,890 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1059
[INFO] 2021-07-12 18:53:03,890 [run_pretraining.py:  558]:	worker_index: 6, step: 1059, cost: 7.623167, mlm loss: 7.623167, speed: 0.917818 steps/s, speed: 7.342547 samples/s, speed: 3759.383855 tokens/s, learning rate: 1.058e-05, loss_scalings: 13421.773438, pp_loss: 7.881473
[INFO] 2021-07-12 18:53:03,890 [run_pretraining.py:  512]:	********exe.run_1059******* 
[INFO] 2021-07-12 18:53:04,987 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:04,988 [run_pretraining.py:  534]:	loss/total_loss, 7.8249430656433105, 1060
[INFO] 2021-07-12 18:53:04,988 [run_pretraining.py:  535]:	loss/mlm_loss, 7.8249430656433105, 1060
[INFO] 2021-07-12 18:53:04,988 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0589999874355271e-05, 1060
[INFO] 2021-07-12 18:53:04,988 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1060
[INFO] 2021-07-12 18:53:04,988 [run_pretraining.py:  558]:	worker_index: 6, step: 1060, cost: 7.824943, mlm loss: 7.824943, speed: 0.911350 steps/s, speed: 7.290796 samples/s, speed: 3732.887727 tokens/s, learning rate: 1.059e-05, loss_scalings: 13421.773438, pp_loss: 7.901683
[INFO] 2021-07-12 18:53:04,988 [run_pretraining.py:  512]:	********exe.run_1060******* 
[INFO] 2021-07-12 18:53:06,071 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:06,071 [run_pretraining.py:  534]:	loss/total_loss, 8.003129005432129, 1061
[INFO] 2021-07-12 18:53:06,071 [run_pretraining.py:  535]:	loss/mlm_loss, 8.003129005432129, 1061
[INFO] 2021-07-12 18:53:06,071 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0599999768601265e-05, 1061
[INFO] 2021-07-12 18:53:06,071 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1061
[INFO] 2021-07-12 18:53:06,072 [run_pretraining.py:  558]:	worker_index: 6, step: 1061, cost: 8.003129, mlm loss: 8.003129, speed: 0.923814 steps/s, speed: 7.390514 samples/s, speed: 3783.942961 tokens/s, learning rate: 1.060e-05, loss_scalings: 13421.773438, pp_loss: 7.850489
[INFO] 2021-07-12 18:53:06,072 [run_pretraining.py:  512]:	********exe.run_1061******* 
[INFO] 2021-07-12 18:53:07,167 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:07,168 [run_pretraining.py:  534]:	loss/total_loss, 8.041426658630371, 1062
[INFO] 2021-07-12 18:53:07,168 [run_pretraining.py:  535]:	loss/mlm_loss, 8.041426658630371, 1062
[INFO] 2021-07-12 18:53:07,168 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0609999662847258e-05, 1062
[INFO] 2021-07-12 18:53:07,168 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1062
[INFO] 2021-07-12 18:53:07,168 [run_pretraining.py:  558]:	worker_index: 6, step: 1062, cost: 8.041427, mlm loss: 8.041427, speed: 0.912379 steps/s, speed: 7.299035 samples/s, speed: 3737.106110 tokens/s, learning rate: 1.061e-05, loss_scalings: 13421.773438, pp_loss: 7.979086
[INFO] 2021-07-12 18:53:07,168 [run_pretraining.py:  512]:	********exe.run_1062******* 
[INFO] 2021-07-12 18:53:08,260 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:08,261 [run_pretraining.py:  534]:	loss/total_loss, 7.716893672943115, 1063
[INFO] 2021-07-12 18:53:08,261 [run_pretraining.py:  535]:	loss/mlm_loss, 7.716893672943115, 1063
[INFO] 2021-07-12 18:53:08,261 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0619999557093251e-05, 1063
[INFO] 2021-07-12 18:53:08,261 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1063
[INFO] 2021-07-12 18:53:08,261 [run_pretraining.py:  558]:	worker_index: 6, step: 1063, cost: 7.716894, mlm loss: 7.716894, speed: 0.915378 steps/s, speed: 7.323022 samples/s, speed: 3749.387377 tokens/s, learning rate: 1.062e-05, loss_scalings: 13421.773438, pp_loss: 7.707655
[INFO] 2021-07-12 18:53:08,262 [run_pretraining.py:  512]:	********exe.run_1063******* 
[INFO] 2021-07-12 18:53:09,355 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:09,356 [run_pretraining.py:  534]:	loss/total_loss, 7.869943618774414, 1064
[INFO] 2021-07-12 18:53:09,356 [run_pretraining.py:  535]:	loss/mlm_loss, 7.869943618774414, 1064
[INFO] 2021-07-12 18:53:09,356 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0629999451339245e-05, 1064
[INFO] 2021-07-12 18:53:09,356 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1064
[INFO] 2021-07-12 18:53:09,356 [run_pretraining.py:  558]:	worker_index: 6, step: 1064, cost: 7.869944, mlm loss: 7.869944, speed: 0.914159 steps/s, speed: 7.313273 samples/s, speed: 3744.395990 tokens/s, learning rate: 1.063e-05, loss_scalings: 13421.773438, pp_loss: 7.909800
[INFO] 2021-07-12 18:53:09,356 [run_pretraining.py:  512]:	********exe.run_1064******* 
[INFO] 2021-07-12 18:53:10,300 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:10,300 [run_pretraining.py:  534]:	loss/total_loss, 7.8365373611450195, 1065
[INFO] 2021-07-12 18:53:10,300 [run_pretraining.py:  535]:	loss/mlm_loss, 7.8365373611450195, 1065
[INFO] 2021-07-12 18:53:10,300 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0639999345585238e-05, 1065
[INFO] 2021-07-12 18:53:10,301 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1065
[INFO] 2021-07-12 18:53:10,301 [run_pretraining.py:  558]:	worker_index: 6, step: 1065, cost: 7.836537, mlm loss: 7.836537, speed: 1.059496 steps/s, speed: 8.475966 samples/s, speed: 4339.694356 tokens/s, learning rate: 1.064e-05, loss_scalings: 13421.773438, pp_loss: 7.665487
[INFO] 2021-07-12 18:53:10,301 [run_pretraining.py:  512]:	********exe.run_1065******* 
[INFO] 2021-07-12 18:53:11,220 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:11,221 [run_pretraining.py:  534]:	loss/total_loss, 7.9069061279296875, 1066
[INFO] 2021-07-12 18:53:11,221 [run_pretraining.py:  535]:	loss/mlm_loss, 7.9069061279296875, 1066
[INFO] 2021-07-12 18:53:11,221 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0650000149325933e-05, 1066
[INFO] 2021-07-12 18:53:11,221 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1066
[INFO] 2021-07-12 18:53:11,221 [run_pretraining.py:  558]:	worker_index: 6, step: 1066, cost: 7.906906, mlm loss: 7.906906, speed: 1.086852 steps/s, speed: 8.694813 samples/s, speed: 4451.744378 tokens/s, learning rate: 1.065e-05, loss_scalings: 13421.773438, pp_loss: 7.824752
[INFO] 2021-07-12 18:53:11,221 [run_pretraining.py:  512]:	********exe.run_1066******* 
[INFO] 2021-07-12 18:53:12,125 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:12,126 [run_pretraining.py:  534]:	loss/total_loss, 7.727092742919922, 1067
[INFO] 2021-07-12 18:53:12,126 [run_pretraining.py:  535]:	loss/mlm_loss, 7.727092742919922, 1067
[INFO] 2021-07-12 18:53:12,126 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0660000043571927e-05, 1067
[INFO] 2021-07-12 18:53:12,126 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1067
[INFO] 2021-07-12 18:53:12,126 [run_pretraining.py:  558]:	worker_index: 6, step: 1067, cost: 7.727093, mlm loss: 7.727093, speed: 1.106431 steps/s, speed: 8.851450 samples/s, speed: 4531.942573 tokens/s, learning rate: 1.066e-05, loss_scalings: 13421.773438, pp_loss: 7.770133
[INFO] 2021-07-12 18:53:12,126 [run_pretraining.py:  512]:	********exe.run_1067******* 
[INFO] 2021-07-12 18:53:13,037 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:13,038 [run_pretraining.py:  534]:	loss/total_loss, 7.8202009201049805, 1068
[INFO] 2021-07-12 18:53:13,038 [run_pretraining.py:  535]:	loss/mlm_loss, 7.8202009201049805, 1068
[INFO] 2021-07-12 18:53:13,038 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.066999993781792e-05, 1068
[INFO] 2021-07-12 18:53:13,038 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1068
[INFO] 2021-07-12 18:53:13,038 [run_pretraining.py:  558]:	worker_index: 6, step: 1068, cost: 7.820201, mlm loss: 7.820201, speed: 1.096951 steps/s, speed: 8.775608 samples/s, speed: 4493.111256 tokens/s, learning rate: 1.067e-05, loss_scalings: 13421.773438, pp_loss: 7.779182
[INFO] 2021-07-12 18:53:13,038 [run_pretraining.py:  512]:	********exe.run_1068******* 
[INFO] 2021-07-12 18:53:13,941 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:13,941 [run_pretraining.py:  534]:	loss/total_loss, 7.611020565032959, 1069
[INFO] 2021-07-12 18:53:13,941 [run_pretraining.py:  535]:	loss/mlm_loss, 7.611020565032959, 1069
[INFO] 2021-07-12 18:53:13,942 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0679999832063913e-05, 1069
[INFO] 2021-07-12 18:53:13,942 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1069
[INFO] 2021-07-12 18:53:13,942 [run_pretraining.py:  558]:	worker_index: 6, step: 1069, cost: 7.611021, mlm loss: 7.611021, speed: 1.107680 steps/s, speed: 8.861439 samples/s, speed: 4537.056702 tokens/s, learning rate: 1.068e-05, loss_scalings: 13421.773438, pp_loss: 7.652792
[INFO] 2021-07-12 18:53:13,942 [run_pretraining.py:  512]:	********exe.run_1069******* 
[INFO] 2021-07-12 18:53:14,851 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:14,851 [run_pretraining.py:  534]:	loss/total_loss, 8.270059585571289, 1070
[INFO] 2021-07-12 18:53:14,852 [run_pretraining.py:  535]:	loss/mlm_loss, 8.270059585571289, 1070
[INFO] 2021-07-12 18:53:14,852 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0689999726309907e-05, 1070
[INFO] 2021-07-12 18:53:14,852 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1070
[INFO] 2021-07-12 18:53:14,852 [run_pretraining.py:  558]:	worker_index: 6, step: 1070, cost: 8.270060, mlm loss: 8.270060, speed: 1.099670 steps/s, speed: 8.797360 samples/s, speed: 4504.248179 tokens/s, learning rate: 1.069e-05, loss_scalings: 13421.773438, pp_loss: 7.732351
[INFO] 2021-07-12 18:53:14,852 [run_pretraining.py:  512]:	********exe.run_1070******* 
[INFO] 2021-07-12 18:53:15,760 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:15,761 [run_pretraining.py:  534]:	loss/total_loss, 7.820968151092529, 1071
[INFO] 2021-07-12 18:53:15,761 [run_pretraining.py:  535]:	loss/mlm_loss, 7.820968151092529, 1071
[INFO] 2021-07-12 18:53:15,761 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.06999996205559e-05, 1071
[INFO] 2021-07-12 18:53:15,761 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1071
[INFO] 2021-07-12 18:53:15,761 [run_pretraining.py:  558]:	worker_index: 6, step: 1071, cost: 7.820968, mlm loss: 7.820968, speed: 1.100696 steps/s, speed: 8.805572 samples/s, speed: 4508.452674 tokens/s, learning rate: 1.070e-05, loss_scalings: 13421.773438, pp_loss: 7.772094
[INFO] 2021-07-12 18:53:15,761 [run_pretraining.py:  512]:	********exe.run_1071******* 
[INFO] 2021-07-12 18:53:16,676 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:16,676 [run_pretraining.py:  534]:	loss/total_loss, 7.8997979164123535, 1072
[INFO] 2021-07-12 18:53:16,676 [run_pretraining.py:  535]:	loss/mlm_loss, 7.8997979164123535, 1072
[INFO] 2021-07-12 18:53:16,676 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0710000424296595e-05, 1072
[INFO] 2021-07-12 18:53:16,676 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1072
[INFO] 2021-07-12 18:53:16,677 [run_pretraining.py:  558]:	worker_index: 6, step: 1072, cost: 7.899798, mlm loss: 7.899798, speed: 1.093047 steps/s, speed: 8.744375 samples/s, speed: 4477.120044 tokens/s, learning rate: 1.071e-05, loss_scalings: 13421.773438, pp_loss: 7.719191
[INFO] 2021-07-12 18:53:16,677 [run_pretraining.py:  512]:	********exe.run_1072******* 
[INFO] 2021-07-12 18:53:17,581 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:17,582 [run_pretraining.py:  534]:	loss/total_loss, 7.5532755851745605, 1073
[INFO] 2021-07-12 18:53:17,582 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5532755851745605, 1073
[INFO] 2021-07-12 18:53:17,582 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0719999409047887e-05, 1073
[INFO] 2021-07-12 18:53:17,582 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1073
[INFO] 2021-07-12 18:53:17,582 [run_pretraining.py:  558]:	worker_index: 6, step: 1073, cost: 7.553276, mlm loss: 7.553276, speed: 1.104970 steps/s, speed: 8.839758 samples/s, speed: 4525.956263 tokens/s, learning rate: 1.072e-05, loss_scalings: 13421.773438, pp_loss: 7.669663
[INFO] 2021-07-12 18:53:17,582 [run_pretraining.py:  512]:	********exe.run_1073******* 
[INFO] 2021-07-12 18:53:18,492 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:18,493 [run_pretraining.py:  534]:	loss/total_loss, 7.955721378326416, 1074
[INFO] 2021-07-12 18:53:18,493 [run_pretraining.py:  535]:	loss/mlm_loss, 7.955721378326416, 1074
[INFO] 2021-07-12 18:53:18,493 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.072999930329388e-05, 1074
[INFO] 2021-07-12 18:53:18,493 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1074
[INFO] 2021-07-12 18:53:18,493 [run_pretraining.py:  558]:	worker_index: 6, step: 1074, cost: 7.955721, mlm loss: 7.955721, speed: 1.098788 steps/s, speed: 8.790307 samples/s, speed: 4500.637425 tokens/s, learning rate: 1.073e-05, loss_scalings: 13421.773438, pp_loss: 7.745944
[INFO] 2021-07-12 18:53:18,493 [run_pretraining.py:  512]:	********exe.run_1074******* 
[INFO] 2021-07-12 18:53:19,400 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:19,400 [run_pretraining.py:  534]:	loss/total_loss, 7.302791595458984, 1075
[INFO] 2021-07-12 18:53:19,400 [run_pretraining.py:  535]:	loss/mlm_loss, 7.302791595458984, 1075
[INFO] 2021-07-12 18:53:19,400 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0740000107034575e-05, 1075
[INFO] 2021-07-12 18:53:19,400 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1075
[INFO] 2021-07-12 18:53:19,400 [run_pretraining.py:  558]:	worker_index: 6, step: 1075, cost: 7.302792, mlm loss: 7.302792, speed: 1.102907 steps/s, speed: 8.823252 samples/s, speed: 4517.505252 tokens/s, learning rate: 1.074e-05, loss_scalings: 13421.773438, pp_loss: 7.717004
[INFO] 2021-07-12 18:53:19,401 [run_pretraining.py:  512]:	********exe.run_1075******* 
[INFO] 2021-07-12 18:53:20,304 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:20,305 [run_pretraining.py:  534]:	loss/total_loss, 7.456482887268066, 1076
[INFO] 2021-07-12 18:53:20,305 [run_pretraining.py:  535]:	loss/mlm_loss, 7.456482887268066, 1076
[INFO] 2021-07-12 18:53:20,305 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0750000001280569e-05, 1076
[INFO] 2021-07-12 18:53:20,305 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1076
[INFO] 2021-07-12 18:53:20,305 [run_pretraining.py:  558]:	worker_index: 6, step: 1076, cost: 7.456483, mlm loss: 7.456483, speed: 1.105999 steps/s, speed: 8.847994 samples/s, speed: 4530.172732 tokens/s, learning rate: 1.075e-05, loss_scalings: 13421.773438, pp_loss: 7.859472
[INFO] 2021-07-12 18:53:20,305 [run_pretraining.py:  512]:	********exe.run_1076******* 
[INFO] 2021-07-12 18:53:21,213 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:21,214 [run_pretraining.py:  534]:	loss/total_loss, 7.208292484283447, 1077
[INFO] 2021-07-12 18:53:21,214 [run_pretraining.py:  535]:	loss/mlm_loss, 7.208292484283447, 1077
[INFO] 2021-07-12 18:53:21,214 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0759999895526562e-05, 1077
[INFO] 2021-07-12 18:53:21,214 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1077
[INFO] 2021-07-12 18:53:21,214 [run_pretraining.py:  558]:	worker_index: 6, step: 1077, cost: 7.208292, mlm loss: 7.208292, speed: 1.100847 steps/s, speed: 8.806773 samples/s, speed: 4509.067990 tokens/s, learning rate: 1.076e-05, loss_scalings: 13421.773438, pp_loss: 7.347767
[INFO] 2021-07-12 18:53:21,215 [run_pretraining.py:  512]:	********exe.run_1077******* 
[INFO] 2021-07-12 18:53:22,118 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:22,119 [run_pretraining.py:  534]:	loss/total_loss, 7.92764139175415, 1078
[INFO] 2021-07-12 18:53:22,119 [run_pretraining.py:  535]:	loss/mlm_loss, 7.92764139175415, 1078
[INFO] 2021-07-12 18:53:22,119 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0769999789772555e-05, 1078
[INFO] 2021-07-12 18:53:22,119 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1078
[INFO] 2021-07-12 18:53:22,119 [run_pretraining.py:  558]:	worker_index: 6, step: 1078, cost: 7.927641, mlm loss: 7.927641, speed: 1.106219 steps/s, speed: 8.849751 samples/s, speed: 4531.072418 tokens/s, learning rate: 1.077e-05, loss_scalings: 13421.773438, pp_loss: 7.790333
[INFO] 2021-07-12 18:53:22,119 [run_pretraining.py:  512]:	********exe.run_1078******* 
[INFO] 2021-07-12 18:53:23,027 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:23,027 [run_pretraining.py:  534]:	loss/total_loss, 7.655754089355469, 1079
[INFO] 2021-07-12 18:53:23,027 [run_pretraining.py:  535]:	loss/mlm_loss, 7.655754089355469, 1079
[INFO] 2021-07-12 18:53:23,027 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0779999684018549e-05, 1079
[INFO] 2021-07-12 18:53:23,028 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1079
[INFO] 2021-07-12 18:53:23,028 [run_pretraining.py:  558]:	worker_index: 6, step: 1079, cost: 7.655754, mlm loss: 7.655754, speed: 1.101630 steps/s, speed: 8.813042 samples/s, speed: 4512.277450 tokens/s, learning rate: 1.078e-05, loss_scalings: 13421.773438, pp_loss: 7.711641
[INFO] 2021-07-12 18:53:23,028 [run_pretraining.py:  512]:	********exe.run_1079******* 
[INFO] 2021-07-12 18:53:23,925 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:23,926 [run_pretraining.py:  534]:	loss/total_loss, 7.848623752593994, 1080
[INFO] 2021-07-12 18:53:23,926 [run_pretraining.py:  535]:	loss/mlm_loss, 7.848623752593994, 1080
[INFO] 2021-07-12 18:53:23,926 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0789999578264542e-05, 1080
[INFO] 2021-07-12 18:53:23,926 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1080
[INFO] 2021-07-12 18:53:23,926 [run_pretraining.py:  558]:	worker_index: 6, step: 1080, cost: 7.848624, mlm loss: 7.848624, speed: 1.113853 steps/s, speed: 8.910827 samples/s, speed: 4562.343433 tokens/s, learning rate: 1.079e-05, loss_scalings: 13421.773438, pp_loss: 8.219891
[INFO] 2021-07-12 18:53:23,926 [run_pretraining.py:  512]:	********exe.run_1080******* 
[INFO] 2021-07-12 18:53:24,832 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:24,833 [run_pretraining.py:  534]:	loss/total_loss, 7.81732702255249, 1081
[INFO] 2021-07-12 18:53:24,833 [run_pretraining.py:  535]:	loss/mlm_loss, 7.81732702255249, 1081
[INFO] 2021-07-12 18:53:24,833 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0800000382005237e-05, 1081
[INFO] 2021-07-12 18:53:24,833 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1081
[INFO] 2021-07-12 18:53:24,833 [run_pretraining.py:  558]:	worker_index: 6, step: 1081, cost: 7.817327, mlm loss: 7.817327, speed: 1.103349 steps/s, speed: 8.826790 samples/s, speed: 4519.316327 tokens/s, learning rate: 1.080e-05, loss_scalings: 13421.773438, pp_loss: 7.480196
[INFO] 2021-07-12 18:53:24,833 [run_pretraining.py:  512]:	********exe.run_1081******* 
[INFO] 2021-07-12 18:53:25,741 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:25,742 [run_pretraining.py:  534]:	loss/total_loss, 7.249264717102051, 1082
[INFO] 2021-07-12 18:53:25,742 [run_pretraining.py:  535]:	loss/mlm_loss, 7.249264717102051, 1082
[INFO] 2021-07-12 18:53:25,742 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0809999366756529e-05, 1082
[INFO] 2021-07-12 18:53:25,742 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1082
[INFO] 2021-07-12 18:53:25,743 [run_pretraining.py:  558]:	worker_index: 6, step: 1082, cost: 7.249265, mlm loss: 7.249265, speed: 1.100510 steps/s, speed: 8.804079 samples/s, speed: 4507.688497 tokens/s, learning rate: 1.081e-05, loss_scalings: 13421.773438, pp_loss: 7.906031
[INFO] 2021-07-12 18:53:25,743 [run_pretraining.py:  512]:	********exe.run_1082******* 
[INFO] 2021-07-12 18:53:26,696 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:26,697 [run_pretraining.py:  534]:	loss/total_loss, 7.92063570022583, 1083
[INFO] 2021-07-12 18:53:26,697 [run_pretraining.py:  535]:	loss/mlm_loss, 7.92063570022583, 1083
[INFO] 2021-07-12 18:53:26,697 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0819999261002522e-05, 1083
[INFO] 2021-07-12 18:53:26,697 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1083
[INFO] 2021-07-12 18:53:26,697 [run_pretraining.py:  558]:	worker_index: 6, step: 1083, cost: 7.920636, mlm loss: 7.920636, speed: 1.048455 steps/s, speed: 8.387637 samples/s, speed: 4294.470211 tokens/s, learning rate: 1.082e-05, loss_scalings: 13421.773438, pp_loss: 7.777027
[INFO] 2021-07-12 18:53:26,697 [run_pretraining.py:  512]:	********exe.run_1083******* 
[INFO] 2021-07-12 18:53:27,605 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:27,606 [run_pretraining.py:  534]:	loss/total_loss, 7.908238410949707, 1084
[INFO] 2021-07-12 18:53:27,606 [run_pretraining.py:  535]:	loss/mlm_loss, 7.908238410949707, 1084
[INFO] 2021-07-12 18:53:27,606 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0830000064743217e-05, 1084
[INFO] 2021-07-12 18:53:27,606 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1084
[INFO] 2021-07-12 18:53:27,606 [run_pretraining.py:  558]:	worker_index: 6, step: 1084, cost: 7.908238, mlm loss: 7.908238, speed: 1.100974 steps/s, speed: 8.807791 samples/s, speed: 4509.588772 tokens/s, learning rate: 1.083e-05, loss_scalings: 13421.773438, pp_loss: 7.979483
[INFO] 2021-07-12 18:53:27,606 [run_pretraining.py:  512]:	********exe.run_1084******* 
[INFO] 2021-07-12 18:53:28,518 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:28,518 [run_pretraining.py:  534]:	loss/total_loss, 7.827367782592773, 1085
[INFO] 2021-07-12 18:53:28,518 [run_pretraining.py:  535]:	loss/mlm_loss, 7.827367782592773, 1085
[INFO] 2021-07-12 18:53:28,518 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.083999995898921e-05, 1085
[INFO] 2021-07-12 18:53:28,518 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1085
[INFO] 2021-07-12 18:53:28,519 [run_pretraining.py:  558]:	worker_index: 6, step: 1085, cost: 7.827368, mlm loss: 7.827368, speed: 1.096667 steps/s, speed: 8.773336 samples/s, speed: 4491.948209 tokens/s, learning rate: 1.084e-05, loss_scalings: 13421.773438, pp_loss: 7.473244
[INFO] 2021-07-12 18:53:28,519 [run_pretraining.py:  512]:	********exe.run_1085******* 
[INFO] 2021-07-12 18:53:29,424 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:29,425 [run_pretraining.py:  534]:	loss/total_loss, 7.870246410369873, 1086
[INFO] 2021-07-12 18:53:29,425 [run_pretraining.py:  535]:	loss/mlm_loss, 7.870246410369873, 1086
[INFO] 2021-07-12 18:53:29,425 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0849998943740502e-05, 1086
[INFO] 2021-07-12 18:53:29,425 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1086
[INFO] 2021-07-12 18:53:29,425 [run_pretraining.py:  558]:	worker_index: 6, step: 1086, cost: 7.870246, mlm loss: 7.870246, speed: 1.103796 steps/s, speed: 8.830369 samples/s, speed: 4521.149082 tokens/s, learning rate: 1.085e-05, loss_scalings: 13421.773438, pp_loss: 7.645525
[INFO] 2021-07-12 18:53:29,425 [run_pretraining.py:  512]:	********exe.run_1086******* 
[INFO] 2021-07-12 18:53:30,333 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:30,333 [run_pretraining.py:  534]:	loss/total_loss, 7.670344829559326, 1087
[INFO] 2021-07-12 18:53:30,333 [run_pretraining.py:  535]:	loss/mlm_loss, 7.670344829559326, 1087
[INFO] 2021-07-12 18:53:30,333 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0859999747481197e-05, 1087
[INFO] 2021-07-12 18:53:30,334 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1087
[INFO] 2021-07-12 18:53:30,334 [run_pretraining.py:  558]:	worker_index: 6, step: 1087, cost: 7.670345, mlm loss: 7.670345, speed: 1.101683 steps/s, speed: 8.813463 samples/s, speed: 4512.493157 tokens/s, learning rate: 1.086e-05, loss_scalings: 13421.773438, pp_loss: 7.688540
[INFO] 2021-07-12 18:53:30,334 [run_pretraining.py:  512]:	********exe.run_1087******* 
[INFO] 2021-07-12 18:53:31,238 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:31,238 [run_pretraining.py:  534]:	loss/total_loss, 8.541394233703613, 1088
[INFO] 2021-07-12 18:53:31,238 [run_pretraining.py:  535]:	loss/mlm_loss, 8.541394233703613, 1088
[INFO] 2021-07-12 18:53:31,239 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.086999964172719e-05, 1088
[INFO] 2021-07-12 18:53:31,239 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1088
[INFO] 2021-07-12 18:53:31,239 [run_pretraining.py:  558]:	worker_index: 6, step: 1088, cost: 8.541394, mlm loss: 8.541394, speed: 1.105699 steps/s, speed: 8.845591 samples/s, speed: 4528.942664 tokens/s, learning rate: 1.087e-05, loss_scalings: 13421.773438, pp_loss: 6.770710
[INFO] 2021-07-12 18:53:31,239 [run_pretraining.py:  512]:	********exe.run_1088******* 
[INFO] 2021-07-12 18:53:32,132 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:32,133 [run_pretraining.py:  534]:	loss/total_loss, 7.149008750915527, 1089
[INFO] 2021-07-12 18:53:32,133 [run_pretraining.py:  535]:	loss/mlm_loss, 7.149008750915527, 1089
[INFO] 2021-07-12 18:53:32,133 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0879999535973184e-05, 1089
[INFO] 2021-07-12 18:53:32,133 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1089
[INFO] 2021-07-12 18:53:32,133 [run_pretraining.py:  558]:	worker_index: 6, step: 1089, cost: 7.149009, mlm loss: 7.149009, speed: 1.119132 steps/s, speed: 8.953058 samples/s, speed: 4583.965706 tokens/s, learning rate: 1.088e-05, loss_scalings: 13421.773438, pp_loss: 7.578001
[INFO] 2021-07-12 18:53:32,133 [run_pretraining.py:  512]:	********exe.run_1089******* 
[INFO] 2021-07-12 18:53:33,081 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:33,082 [run_pretraining.py:  534]:	loss/total_loss, 7.72860860824585, 1090
[INFO] 2021-07-12 18:53:33,082 [run_pretraining.py:  535]:	loss/mlm_loss, 7.72860860824585, 1090
[INFO] 2021-07-12 18:53:33,082 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0890000339713879e-05, 1090
[INFO] 2021-07-12 18:53:33,082 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1090
[INFO] 2021-07-12 18:53:33,082 [run_pretraining.py:  558]:	worker_index: 6, step: 1090, cost: 7.728609, mlm loss: 7.728609, speed: 1.054164 steps/s, speed: 8.433309 samples/s, speed: 4317.854082 tokens/s, learning rate: 1.089e-05, loss_scalings: 13421.773438, pp_loss: 7.593072
[INFO] 2021-07-12 18:53:33,082 [run_pretraining.py:  512]:	********exe.run_1090******* 
[INFO] 2021-07-12 18:53:33,982 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:33,982 [run_pretraining.py:  534]:	loss/total_loss, 7.459087371826172, 1091
[INFO] 2021-07-12 18:53:33,983 [run_pretraining.py:  535]:	loss/mlm_loss, 7.459087371826172, 1091
[INFO] 2021-07-12 18:53:33,983 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.089999932446517e-05, 1091
[INFO] 2021-07-12 18:53:33,983 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1091
[INFO] 2021-07-12 18:53:33,983 [run_pretraining.py:  558]:	worker_index: 6, step: 1091, cost: 7.459087, mlm loss: 7.459087, speed: 1.111342 steps/s, speed: 8.890732 samples/s, speed: 4552.054835 tokens/s, learning rate: 1.090e-05, loss_scalings: 13421.773438, pp_loss: 7.532545
[INFO] 2021-07-12 18:53:33,983 [run_pretraining.py:  512]:	********exe.run_1091******* 
[INFO] 2021-07-12 18:53:34,886 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:34,887 [run_pretraining.py:  534]:	loss/total_loss, 7.421938896179199, 1092
[INFO] 2021-07-12 18:53:34,887 [run_pretraining.py:  535]:	loss/mlm_loss, 7.421938896179199, 1092
[INFO] 2021-07-12 18:53:34,887 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0909999218711164e-05, 1092
[INFO] 2021-07-12 18:53:34,887 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1092
[INFO] 2021-07-12 18:53:34,887 [run_pretraining.py:  558]:	worker_index: 6, step: 1092, cost: 7.421939, mlm loss: 7.421939, speed: 1.106374 steps/s, speed: 8.850993 samples/s, speed: 4531.708268 tokens/s, learning rate: 1.091e-05, loss_scalings: 13421.773438, pp_loss: 7.708806
[INFO] 2021-07-12 18:53:34,887 [run_pretraining.py:  512]:	********exe.run_1092******* 
[INFO] 2021-07-12 18:53:35,915 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:35,916 [run_pretraining.py:  534]:	loss/total_loss, 7.364825248718262, 1093
[INFO] 2021-07-12 18:53:35,916 [run_pretraining.py:  535]:	loss/mlm_loss, 7.364825248718262, 1093
[INFO] 2021-07-12 18:53:35,916 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0920000022451859e-05, 1093
[INFO] 2021-07-12 18:53:35,916 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1093
[INFO] 2021-07-12 18:53:35,916 [run_pretraining.py:  558]:	worker_index: 6, step: 1093, cost: 7.364825, mlm loss: 7.364825, speed: 0.972717 steps/s, speed: 7.781738 samples/s, speed: 3984.249614 tokens/s, learning rate: 1.092e-05, loss_scalings: 13421.773438, pp_loss: 7.762987
[INFO] 2021-07-12 18:53:35,916 [run_pretraining.py:  512]:	********exe.run_1093******* 
[INFO] 2021-07-12 18:53:36,829 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:36,830 [run_pretraining.py:  534]:	loss/total_loss, 7.4876532554626465, 1094
[INFO] 2021-07-12 18:53:36,830 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4876532554626465, 1094
[INFO] 2021-07-12 18:53:36,830 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0929999916697852e-05, 1094
[INFO] 2021-07-12 18:53:36,830 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1094
[INFO] 2021-07-12 18:53:36,830 [run_pretraining.py:  558]:	worker_index: 6, step: 1094, cost: 7.487653, mlm loss: 7.487653, speed: 1.094506 steps/s, speed: 8.756044 samples/s, speed: 4483.094764 tokens/s, learning rate: 1.093e-05, loss_scalings: 13421.773438, pp_loss: 7.777127
[INFO] 2021-07-12 18:53:36,831 [run_pretraining.py:  512]:	********exe.run_1094******* 
[INFO] 2021-07-12 18:53:37,731 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:37,732 [run_pretraining.py:  534]:	loss/total_loss, 7.165566921234131, 1095
[INFO] 2021-07-12 18:53:37,732 [run_pretraining.py:  535]:	loss/mlm_loss, 7.165566921234131, 1095
[INFO] 2021-07-12 18:53:37,732 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0939999810943846e-05, 1095
[INFO] 2021-07-12 18:53:37,732 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1095
[INFO] 2021-07-12 18:53:37,732 [run_pretraining.py:  558]:	worker_index: 6, step: 1095, cost: 7.165567, mlm loss: 7.165567, speed: 1.110050 steps/s, speed: 8.880398 samples/s, speed: 4546.763657 tokens/s, learning rate: 1.094e-05, loss_scalings: 13421.773438, pp_loss: 7.674854
[INFO] 2021-07-12 18:53:37,732 [run_pretraining.py:  512]:	********exe.run_1095******* 
[INFO] 2021-07-12 18:53:38,634 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:38,635 [run_pretraining.py:  534]:	loss/total_loss, 7.567001819610596, 1096
[INFO] 2021-07-12 18:53:38,635 [run_pretraining.py:  535]:	loss/mlm_loss, 7.567001819610596, 1096
[INFO] 2021-07-12 18:53:38,635 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0949999705189839e-05, 1096
[INFO] 2021-07-12 18:53:38,635 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1096
[INFO] 2021-07-12 18:53:38,635 [run_pretraining.py:  558]:	worker_index: 6, step: 1096, cost: 7.567002, mlm loss: 7.567002, speed: 1.108278 steps/s, speed: 8.866220 samples/s, speed: 4539.504742 tokens/s, learning rate: 1.095e-05, loss_scalings: 13421.773438, pp_loss: 7.862044
[INFO] 2021-07-12 18:53:38,635 [run_pretraining.py:  512]:	********exe.run_1096******* 
[INFO] 2021-07-12 18:53:39,546 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:39,547 [run_pretraining.py:  534]:	loss/total_loss, 7.432325839996338, 1097
[INFO] 2021-07-12 18:53:39,547 [run_pretraining.py:  535]:	loss/mlm_loss, 7.432325839996338, 1097
[INFO] 2021-07-12 18:53:39,547 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0959999599435832e-05, 1097
[INFO] 2021-07-12 18:53:39,547 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1097
[INFO] 2021-07-12 18:53:39,547 [run_pretraining.py:  558]:	worker_index: 6, step: 1097, cost: 7.432326, mlm loss: 7.432326, speed: 1.097382 steps/s, speed: 8.779059 samples/s, speed: 4494.878124 tokens/s, learning rate: 1.096e-05, loss_scalings: 13421.773438, pp_loss: 6.755108
[INFO] 2021-07-12 18:53:39,547 [run_pretraining.py:  512]:	********exe.run_1097******* 
[INFO] 2021-07-12 18:53:40,445 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:40,446 [run_pretraining.py:  534]:	loss/total_loss, 7.562013626098633, 1098
[INFO] 2021-07-12 18:53:40,446 [run_pretraining.py:  535]:	loss/mlm_loss, 7.562013626098633, 1098
[INFO] 2021-07-12 18:53:40,446 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0969999493681826e-05, 1098
[INFO] 2021-07-12 18:53:40,446 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1098
[INFO] 2021-07-12 18:53:40,446 [run_pretraining.py:  558]:	worker_index: 6, step: 1098, cost: 7.562014, mlm loss: 7.562014, speed: 1.113158 steps/s, speed: 8.905265 samples/s, speed: 4559.495549 tokens/s, learning rate: 1.097e-05, loss_scalings: 13421.773438, pp_loss: 7.476398
[INFO] 2021-07-12 18:53:40,446 [run_pretraining.py:  512]:	********exe.run_1098******* 
[INFO] 2021-07-12 18:53:41,358 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:41,358 [run_pretraining.py:  534]:	loss/total_loss, 7.217439651489258, 1099
[INFO] 2021-07-12 18:53:41,358 [run_pretraining.py:  535]:	loss/mlm_loss, 7.217439651489258, 1099
[INFO] 2021-07-12 18:53:41,359 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.098000029742252e-05, 1099
[INFO] 2021-07-12 18:53:41,359 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1099
[INFO] 2021-07-12 18:53:41,359 [run_pretraining.py:  558]:	worker_index: 6, step: 1099, cost: 7.217440, mlm loss: 7.217440, speed: 1.096549 steps/s, speed: 8.772389 samples/s, speed: 4491.463197 tokens/s, learning rate: 1.098e-05, loss_scalings: 13421.773438, pp_loss: 7.624563
[INFO] 2021-07-12 18:53:41,359 [run_pretraining.py:  512]:	********exe.run_1099******* 
[INFO] 2021-07-12 18:53:42,263 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:42,264 [run_pretraining.py:  534]:	loss/total_loss, 7.686467170715332, 1100
[INFO] 2021-07-12 18:53:42,264 [run_pretraining.py:  535]:	loss/mlm_loss, 7.686467170715332, 1100
[INFO] 2021-07-12 18:53:42,264 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0989999282173812e-05, 1100
[INFO] 2021-07-12 18:53:42,264 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1100
[INFO] 2021-07-12 18:53:42,264 [run_pretraining.py:  558]:	worker_index: 6, step: 1100, cost: 7.686467, mlm loss: 7.686467, speed: 1.105496 steps/s, speed: 8.843971 samples/s, speed: 4528.113044 tokens/s, learning rate: 1.099e-05, loss_scalings: 13421.773438, pp_loss: 7.641264
[INFO] 2021-07-12 18:53:42,264 [run_pretraining.py:  512]:	********exe.run_1100******* 
[INFO] 2021-07-12 18:53:43,226 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:43,226 [run_pretraining.py:  534]:	loss/total_loss, 8.009021759033203, 1101
[INFO] 2021-07-12 18:53:43,227 [run_pretraining.py:  535]:	loss/mlm_loss, 8.009021759033203, 1101
[INFO] 2021-07-12 18:53:43,227 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1000000085914508e-05, 1101
[INFO] 2021-07-12 18:53:43,227 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1101
[INFO] 2021-07-12 18:53:43,227 [run_pretraining.py:  558]:	worker_index: 6, step: 1101, cost: 8.009022, mlm loss: 8.009022, speed: 1.039341 steps/s, speed: 8.314725 samples/s, speed: 4257.139419 tokens/s, learning rate: 1.100e-05, loss_scalings: 13421.773438, pp_loss: 8.097490
[INFO] 2021-07-12 18:53:43,227 [run_pretraining.py:  512]:	********exe.run_1101******* 
[INFO] 2021-07-12 18:53:44,298 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:44,298 [run_pretraining.py:  534]:	loss/total_loss, 7.47594690322876, 1102
[INFO] 2021-07-12 18:53:44,298 [run_pretraining.py:  535]:	loss/mlm_loss, 7.47594690322876, 1102
[INFO] 2021-07-12 18:53:44,299 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1009999980160501e-05, 1102
[INFO] 2021-07-12 18:53:44,299 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1102
[INFO] 2021-07-12 18:53:44,299 [run_pretraining.py:  558]:	worker_index: 6, step: 1102, cost: 7.475947, mlm loss: 7.475947, speed: 0.933588 steps/s, speed: 7.468706 samples/s, speed: 3823.977542 tokens/s, learning rate: 1.101e-05, loss_scalings: 13421.773438, pp_loss: 7.741929
[INFO] 2021-07-12 18:53:44,299 [run_pretraining.py:  512]:	********exe.run_1102******* 
[INFO] 2021-07-12 18:53:45,376 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:45,377 [run_pretraining.py:  534]:	loss/total_loss, 7.921231746673584, 1103
[INFO] 2021-07-12 18:53:45,377 [run_pretraining.py:  535]:	loss/mlm_loss, 7.921231746673584, 1103
[INFO] 2021-07-12 18:53:45,377 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1019999874406494e-05, 1103
[INFO] 2021-07-12 18:53:45,377 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1103
[INFO] 2021-07-12 18:53:45,377 [run_pretraining.py:  558]:	worker_index: 6, step: 1103, cost: 7.921232, mlm loss: 7.921232, speed: 0.927624 steps/s, speed: 7.420996 samples/s, speed: 3799.549709 tokens/s, learning rate: 1.102e-05, loss_scalings: 13421.773438, pp_loss: 7.825300
[INFO] 2021-07-12 18:53:45,377 [run_pretraining.py:  512]:	********exe.run_1103******* 
[INFO] 2021-07-12 18:53:46,483 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:46,483 [run_pretraining.py:  534]:	loss/total_loss, 8.204832077026367, 1104
[INFO] 2021-07-12 18:53:46,484 [run_pretraining.py:  535]:	loss/mlm_loss, 8.204832077026367, 1104
[INFO] 2021-07-12 18:53:46,484 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1029999768652488e-05, 1104
[INFO] 2021-07-12 18:53:46,484 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1104
[INFO] 2021-07-12 18:53:46,484 [run_pretraining.py:  558]:	worker_index: 6, step: 1104, cost: 8.204832, mlm loss: 8.204832, speed: 0.904392 steps/s, speed: 7.235136 samples/s, speed: 3704.389451 tokens/s, learning rate: 1.103e-05, loss_scalings: 13421.773438, pp_loss: 7.148312
[INFO] 2021-07-12 18:53:46,484 [run_pretraining.py:  512]:	********exe.run_1104******* 
[INFO] 2021-07-12 18:53:47,583 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:47,583 [run_pretraining.py:  534]:	loss/total_loss, 7.373003959655762, 1105
[INFO] 2021-07-12 18:53:47,583 [run_pretraining.py:  535]:	loss/mlm_loss, 7.373003959655762, 1105
[INFO] 2021-07-12 18:53:47,584 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1039999662898481e-05, 1105
[INFO] 2021-07-12 18:53:47,584 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1105
[INFO] 2021-07-12 18:53:47,584 [run_pretraining.py:  558]:	worker_index: 6, step: 1105, cost: 7.373004, mlm loss: 7.373004, speed: 0.909771 steps/s, speed: 7.278170 samples/s, speed: 3726.423184 tokens/s, learning rate: 1.104e-05, loss_scalings: 13421.773438, pp_loss: 7.744502
[INFO] 2021-07-12 18:53:47,584 [run_pretraining.py:  512]:	********exe.run_1105******* 
[INFO] 2021-07-12 18:53:48,540 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:48,540 [run_pretraining.py:  534]:	loss/total_loss, 7.874334335327148, 1106
[INFO] 2021-07-12 18:53:48,540 [run_pretraining.py:  535]:	loss/mlm_loss, 7.874334335327148, 1106
[INFO] 2021-07-12 18:53:48,540 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1049999557144474e-05, 1106
[INFO] 2021-07-12 18:53:48,541 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1106
[INFO] 2021-07-12 18:53:48,541 [run_pretraining.py:  558]:	worker_index: 6, step: 1106, cost: 7.874334, mlm loss: 7.874334, speed: 1.045789 steps/s, speed: 8.366314 samples/s, speed: 4283.552699 tokens/s, learning rate: 1.105e-05, loss_scalings: 13421.773438, pp_loss: 8.009250
[INFO] 2021-07-12 18:53:48,541 [run_pretraining.py:  512]:	********exe.run_1106******* 
[INFO] 2021-07-12 18:53:49,444 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:49,445 [run_pretraining.py:  534]:	loss/total_loss, 8.206826210021973, 1107
[INFO] 2021-07-12 18:53:49,445 [run_pretraining.py:  535]:	loss/mlm_loss, 8.206826210021973, 1107
[INFO] 2021-07-12 18:53:49,445 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.106000036088517e-05, 1107
[INFO] 2021-07-12 18:53:49,445 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1107
[INFO] 2021-07-12 18:53:49,445 [run_pretraining.py:  558]:	worker_index: 6, step: 1107, cost: 8.206826, mlm loss: 8.206826, speed: 1.106792 steps/s, speed: 8.854337 samples/s, speed: 4533.420691 tokens/s, learning rate: 1.106e-05, loss_scalings: 13421.773438, pp_loss: 7.959569
[INFO] 2021-07-12 18:53:49,445 [run_pretraining.py:  512]:	********exe.run_1107******* 
[INFO] 2021-07-12 18:53:50,351 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:50,351 [run_pretraining.py:  534]:	loss/total_loss, 7.825940132141113, 1108
[INFO] 2021-07-12 18:53:50,351 [run_pretraining.py:  535]:	loss/mlm_loss, 7.825940132141113, 1108
[INFO] 2021-07-12 18:53:50,351 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1069999345636461e-05, 1108
[INFO] 2021-07-12 18:53:50,352 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1108
[INFO] 2021-07-12 18:53:50,352 [run_pretraining.py:  558]:	worker_index: 6, step: 1108, cost: 7.825940, mlm loss: 7.825940, speed: 1.103835 steps/s, speed: 8.830678 samples/s, speed: 4521.307332 tokens/s, learning rate: 1.107e-05, loss_scalings: 13421.773438, pp_loss: 7.883013
[INFO] 2021-07-12 18:53:50,352 [run_pretraining.py:  512]:	********exe.run_1108******* 
[INFO] 2021-07-12 18:53:51,275 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:51,276 [run_pretraining.py:  534]:	loss/total_loss, 7.730872631072998, 1109
[INFO] 2021-07-12 18:53:51,276 [run_pretraining.py:  535]:	loss/mlm_loss, 7.730872631072998, 1109
[INFO] 2021-07-12 18:53:51,276 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1079999239882454e-05, 1109
[INFO] 2021-07-12 18:53:51,276 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1109
[INFO] 2021-07-12 18:53:51,276 [run_pretraining.py:  558]:	worker_index: 6, step: 1109, cost: 7.730873, mlm loss: 7.730873, speed: 1.082616 steps/s, speed: 8.660929 samples/s, speed: 4434.395785 tokens/s, learning rate: 1.108e-05, loss_scalings: 13421.773438, pp_loss: 6.661285
[INFO] 2021-07-12 18:53:51,276 [run_pretraining.py:  512]:	********exe.run_1109******* 
[INFO] 2021-07-12 18:53:52,194 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:52,195 [run_pretraining.py:  534]:	loss/total_loss, 7.513234615325928, 1110
[INFO] 2021-07-12 18:53:52,195 [run_pretraining.py:  535]:	loss/mlm_loss, 7.513234615325928, 1110
[INFO] 2021-07-12 18:53:52,195 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.109000004362315e-05, 1110
[INFO] 2021-07-12 18:53:52,195 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1110
[INFO] 2021-07-12 18:53:52,195 [run_pretraining.py:  558]:	worker_index: 6, step: 1110, cost: 7.513235, mlm loss: 7.513235, speed: 1.088609 steps/s, speed: 8.708870 samples/s, speed: 4458.941526 tokens/s, learning rate: 1.109e-05, loss_scalings: 13421.773438, pp_loss: 7.549166
[INFO] 2021-07-12 18:53:52,195 [run_pretraining.py:  512]:	********exe.run_1110******* 
[INFO] 2021-07-12 18:53:53,094 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:53,095 [run_pretraining.py:  534]:	loss/total_loss, 7.348508358001709, 1111
[INFO] 2021-07-12 18:53:53,095 [run_pretraining.py:  535]:	loss/mlm_loss, 7.348508358001709, 1111
[INFO] 2021-07-12 18:53:53,095 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1099999937869143e-05, 1111
[INFO] 2021-07-12 18:53:53,095 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1111
[INFO] 2021-07-12 18:53:53,095 [run_pretraining.py:  558]:	worker_index: 6, step: 1111, cost: 7.348508, mlm loss: 7.348508, speed: 1.112088 steps/s, speed: 8.896708 samples/s, speed: 4555.114437 tokens/s, learning rate: 1.110e-05, loss_scalings: 13421.773438, pp_loss: 7.588642
[INFO] 2021-07-12 18:53:53,095 [run_pretraining.py:  512]:	********exe.run_1111******* 
[INFO] 2021-07-12 18:53:53,993 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:53,994 [run_pretraining.py:  534]:	loss/total_loss, 7.6461381912231445, 1112
[INFO] 2021-07-12 18:53:53,994 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6461381912231445, 1112
[INFO] 2021-07-12 18:53:53,994 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1109999832115136e-05, 1112
[INFO] 2021-07-12 18:53:53,994 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1112
[INFO] 2021-07-12 18:53:53,994 [run_pretraining.py:  558]:	worker_index: 6, step: 1112, cost: 7.646138, mlm loss: 7.646138, speed: 1.112904 steps/s, speed: 8.903233 samples/s, speed: 4558.455119 tokens/s, learning rate: 1.111e-05, loss_scalings: 13421.773438, pp_loss: 7.176601
[INFO] 2021-07-12 18:53:53,995 [run_pretraining.py:  512]:	********exe.run_1112******* 
[INFO] 2021-07-12 18:53:54,897 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:54,898 [run_pretraining.py:  534]:	loss/total_loss, 8.16668701171875, 1113
[INFO] 2021-07-12 18:53:54,898 [run_pretraining.py:  535]:	loss/mlm_loss, 8.16668701171875, 1113
[INFO] 2021-07-12 18:53:54,898 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.111999972636113e-05, 1113
[INFO] 2021-07-12 18:53:54,898 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1113
[INFO] 2021-07-12 18:53:54,898 [run_pretraining.py:  558]:	worker_index: 6, step: 1113, cost: 8.166687, mlm loss: 8.166687, speed: 1.107583 steps/s, speed: 8.860667 samples/s, speed: 4536.661331 tokens/s, learning rate: 1.112e-05, loss_scalings: 13421.773438, pp_loss: 7.179023
[INFO] 2021-07-12 18:53:54,898 [run_pretraining.py:  512]:	********exe.run_1113******* 
[INFO] 2021-07-12 18:53:55,867 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:55,868 [run_pretraining.py:  534]:	loss/total_loss, 7.502854347229004, 1114
[INFO] 2021-07-12 18:53:55,868 [run_pretraining.py:  535]:	loss/mlm_loss, 7.502854347229004, 1114
[INFO] 2021-07-12 18:53:55,868 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1129999620607123e-05, 1114
[INFO] 2021-07-12 18:53:55,868 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1114
[INFO] 2021-07-12 18:53:55,868 [run_pretraining.py:  558]:	worker_index: 6, step: 1114, cost: 7.502854, mlm loss: 7.502854, speed: 1.031198 steps/s, speed: 8.249586 samples/s, speed: 4223.788020 tokens/s, learning rate: 1.113e-05, loss_scalings: 13421.773438, pp_loss: 7.647141
[INFO] 2021-07-12 18:53:55,869 [run_pretraining.py:  512]:	********exe.run_1114******* 
[INFO] 2021-07-12 18:53:56,929 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:56,929 [run_pretraining.py:  534]:	loss/total_loss, 8.256551742553711, 1115
[INFO] 2021-07-12 18:53:56,929 [run_pretraining.py:  535]:	loss/mlm_loss, 8.256551742553711, 1115
[INFO] 2021-07-12 18:53:56,930 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1139999514853116e-05, 1115
[INFO] 2021-07-12 18:53:56,930 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1115
[INFO] 2021-07-12 18:53:56,930 [run_pretraining.py:  558]:	worker_index: 6, step: 1115, cost: 8.256552, mlm loss: 8.256552, speed: 0.942957 steps/s, speed: 7.543653 samples/s, speed: 3862.350270 tokens/s, learning rate: 1.114e-05, loss_scalings: 13421.773438, pp_loss: 7.002118
[INFO] 2021-07-12 18:53:56,930 [run_pretraining.py:  512]:	********exe.run_1115******* 
[INFO] 2021-07-12 18:53:57,999 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:58,000 [run_pretraining.py:  534]:	loss/total_loss, 7.925640106201172, 1116
[INFO] 2021-07-12 18:53:58,000 [run_pretraining.py:  535]:	loss/mlm_loss, 7.925640106201172, 1116
[INFO] 2021-07-12 18:53:58,000 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1150000318593811e-05, 1116
[INFO] 2021-07-12 18:53:58,000 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1116
[INFO] 2021-07-12 18:53:58,000 [run_pretraining.py:  558]:	worker_index: 6, step: 1116, cost: 7.925640, mlm loss: 7.925640, speed: 0.934884 steps/s, speed: 7.479071 samples/s, speed: 3829.284214 tokens/s, learning rate: 1.115e-05, loss_scalings: 13421.773438, pp_loss: 7.680016
[INFO] 2021-07-12 18:53:58,000 [run_pretraining.py:  512]:	********exe.run_1116******* 
[INFO] 2021-07-12 18:53:59,064 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:59,065 [run_pretraining.py:  534]:	loss/total_loss, 7.451809406280518, 1117
[INFO] 2021-07-12 18:53:59,065 [run_pretraining.py:  535]:	loss/mlm_loss, 7.451809406280518, 1117
[INFO] 2021-07-12 18:53:59,065 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1159999303345103e-05, 1117
[INFO] 2021-07-12 18:53:59,065 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1117
[INFO] 2021-07-12 18:53:59,065 [run_pretraining.py:  558]:	worker_index: 6, step: 1117, cost: 7.451809, mlm loss: 7.451809, speed: 0.939668 steps/s, speed: 7.517347 samples/s, speed: 3848.881885 tokens/s, learning rate: 1.116e-05, loss_scalings: 13421.773438, pp_loss: 7.536026
[INFO] 2021-07-12 18:53:59,065 [run_pretraining.py:  512]:	********exe.run_1117******* 
[INFO] 2021-07-12 18:54:00,152 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:00,153 [run_pretraining.py:  534]:	loss/total_loss, 7.590025424957275, 1118
[INFO] 2021-07-12 18:54:00,153 [run_pretraining.py:  535]:	loss/mlm_loss, 7.590025424957275, 1118
[INFO] 2021-07-12 18:54:00,153 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1169999197591096e-05, 1118
[INFO] 2021-07-12 18:54:00,153 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1118
[INFO] 2021-07-12 18:54:00,153 [run_pretraining.py:  558]:	worker_index: 6, step: 1118, cost: 7.590025, mlm loss: 7.590025, speed: 0.919359 steps/s, speed: 7.354872 samples/s, speed: 3765.694261 tokens/s, learning rate: 1.117e-05, loss_scalings: 13421.773438, pp_loss: 7.603742
[INFO] 2021-07-12 18:54:00,153 [run_pretraining.py:  512]:	********exe.run_1118******* 
[INFO] 2021-07-12 18:54:01,209 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:01,209 [run_pretraining.py:  534]:	loss/total_loss, 7.451652526855469, 1119
[INFO] 2021-07-12 18:54:01,209 [run_pretraining.py:  535]:	loss/mlm_loss, 7.451652526855469, 1119
[INFO] 2021-07-12 18:54:01,210 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1180000001331791e-05, 1119
[INFO] 2021-07-12 18:54:01,210 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1119
[INFO] 2021-07-12 18:54:01,210 [run_pretraining.py:  558]:	worker_index: 6, step: 1119, cost: 7.451653, mlm loss: 7.451653, speed: 0.947227 steps/s, speed: 7.577816 samples/s, speed: 3879.841694 tokens/s, learning rate: 1.118e-05, loss_scalings: 13421.773438, pp_loss: 7.679350
[INFO] 2021-07-12 18:54:01,210 [run_pretraining.py:  512]:	********exe.run_1119******* 
[INFO] 2021-07-12 18:54:02,270 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:02,271 [run_pretraining.py:  534]:	loss/total_loss, 7.145103454589844, 1120
[INFO] 2021-07-12 18:54:02,271 [run_pretraining.py:  535]:	loss/mlm_loss, 7.145103454589844, 1120
[INFO] 2021-07-12 18:54:02,271 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1189999895577785e-05, 1120
[INFO] 2021-07-12 18:54:02,271 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1120
[INFO] 2021-07-12 18:54:02,271 [run_pretraining.py:  558]:	worker_index: 6, step: 1120, cost: 7.145103, mlm loss: 7.145103, speed: 0.942689 steps/s, speed: 7.541511 samples/s, speed: 3861.253884 tokens/s, learning rate: 1.119e-05, loss_scalings: 13421.773438, pp_loss: 7.465233
[INFO] 2021-07-12 18:54:02,271 [run_pretraining.py:  512]:	********exe.run_1120******* 
[INFO] 2021-07-12 18:54:03,338 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:03,338 [run_pretraining.py:  534]:	loss/total_loss, 7.226215839385986, 1121
[INFO] 2021-07-12 18:54:03,338 [run_pretraining.py:  535]:	loss/mlm_loss, 7.226215839385986, 1121
[INFO] 2021-07-12 18:54:03,339 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1199999789823778e-05, 1121
[INFO] 2021-07-12 18:54:03,339 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1121
[INFO] 2021-07-12 18:54:03,339 [run_pretraining.py:  558]:	worker_index: 6, step: 1121, cost: 7.226216, mlm loss: 7.226216, speed: 0.937385 steps/s, speed: 7.499079 samples/s, speed: 3839.528218 tokens/s, learning rate: 1.120e-05, loss_scalings: 13421.773438, pp_loss: 7.390994
[INFO] 2021-07-12 18:54:03,339 [run_pretraining.py:  512]:	********exe.run_1121******* 
[INFO] 2021-07-12 18:54:04,398 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:04,399 [run_pretraining.py:  534]:	loss/total_loss, 8.133199691772461, 1122
[INFO] 2021-07-12 18:54:04,399 [run_pretraining.py:  535]:	loss/mlm_loss, 8.133199691772461, 1122
[INFO] 2021-07-12 18:54:04,399 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1209999684069771e-05, 1122
[INFO] 2021-07-12 18:54:04,399 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1122
[INFO] 2021-07-12 18:54:04,400 [run_pretraining.py:  558]:	worker_index: 6, step: 1122, cost: 8.133200, mlm loss: 8.133200, speed: 0.943391 steps/s, speed: 7.547131 samples/s, speed: 3864.131162 tokens/s, learning rate: 1.121e-05, loss_scalings: 13421.773438, pp_loss: 7.786041
[INFO] 2021-07-12 18:54:04,400 [run_pretraining.py:  512]:	********exe.run_1122******* 
[INFO] 2021-07-12 18:54:05,466 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:05,466 [run_pretraining.py:  534]:	loss/total_loss, 7.7525811195373535, 1123
[INFO] 2021-07-12 18:54:05,466 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7525811195373535, 1123
[INFO] 2021-07-12 18:54:05,466 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1219999578315765e-05, 1123
[INFO] 2021-07-12 18:54:05,467 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1123
[INFO] 2021-07-12 18:54:05,467 [run_pretraining.py:  558]:	worker_index: 6, step: 1123, cost: 7.752581, mlm loss: 7.752581, speed: 0.937690 steps/s, speed: 7.501516 samples/s, speed: 3840.776295 tokens/s, learning rate: 1.122e-05, loss_scalings: 13421.773438, pp_loss: 7.521115
[INFO] 2021-07-12 18:54:05,467 [run_pretraining.py:  512]:	********exe.run_1123******* 
[INFO] 2021-07-12 18:54:06,538 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:06,539 [run_pretraining.py:  534]:	loss/total_loss, 7.766114711761475, 1124
[INFO] 2021-07-12 18:54:06,539 [run_pretraining.py:  535]:	loss/mlm_loss, 7.766114711761475, 1124
[INFO] 2021-07-12 18:54:06,539 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1229999472561758e-05, 1124
[INFO] 2021-07-12 18:54:06,539 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1124
[INFO] 2021-07-12 18:54:06,539 [run_pretraining.py:  558]:	worker_index: 6, step: 1124, cost: 7.766115, mlm loss: 7.766115, speed: 0.933087 steps/s, speed: 7.464699 samples/s, speed: 3821.925648 tokens/s, learning rate: 1.123e-05, loss_scalings: 13421.773438, pp_loss: 7.551060
[INFO] 2021-07-12 18:54:06,539 [run_pretraining.py:  512]:	********exe.run_1124******* 
[INFO] 2021-07-12 18:54:07,494 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:07,494 [run_pretraining.py:  534]:	loss/total_loss, 7.347653865814209, 1125
[INFO] 2021-07-12 18:54:07,494 [run_pretraining.py:  535]:	loss/mlm_loss, 7.347653865814209, 1125
[INFO] 2021-07-12 18:54:07,494 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1240000276302453e-05, 1125
[INFO] 2021-07-12 18:54:07,494 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1125
[INFO] 2021-07-12 18:54:07,495 [run_pretraining.py:  558]:	worker_index: 6, step: 1125, cost: 7.347654, mlm loss: 7.347654, speed: 1.047306 steps/s, speed: 8.378449 samples/s, speed: 4289.765955 tokens/s, learning rate: 1.124e-05, loss_scalings: 13421.773438, pp_loss: 7.557851
[INFO] 2021-07-12 18:54:07,495 [run_pretraining.py:  512]:	********exe.run_1125******* 
[INFO] 2021-07-12 18:54:08,415 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:08,416 [run_pretraining.py:  534]:	loss/total_loss, 7.683228492736816, 1126
[INFO] 2021-07-12 18:54:08,416 [run_pretraining.py:  535]:	loss/mlm_loss, 7.683228492736816, 1126
[INFO] 2021-07-12 18:54:08,416 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1249999261053745e-05, 1126
[INFO] 2021-07-12 18:54:08,416 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1126
[INFO] 2021-07-12 18:54:08,416 [run_pretraining.py:  558]:	worker_index: 6, step: 1126, cost: 7.683228, mlm loss: 7.683228, speed: 1.086242 steps/s, speed: 8.689934 samples/s, speed: 4449.246014 tokens/s, learning rate: 1.125e-05, loss_scalings: 13421.773438, pp_loss: 7.389750
[INFO] 2021-07-12 18:54:08,416 [run_pretraining.py:  512]:	********exe.run_1126******* 
[INFO] 2021-07-12 18:54:09,329 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:09,329 [run_pretraining.py:  534]:	loss/total_loss, 8.261396408081055, 1127
[INFO] 2021-07-12 18:54:09,330 [run_pretraining.py:  535]:	loss/mlm_loss, 8.261396408081055, 1127
[INFO] 2021-07-12 18:54:09,330 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1259999155299738e-05, 1127
[INFO] 2021-07-12 18:54:09,330 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1127
[INFO] 2021-07-12 18:54:09,330 [run_pretraining.py:  558]:	worker_index: 6, step: 1127, cost: 8.261396, mlm loss: 8.261396, speed: 1.094995 steps/s, speed: 8.759960 samples/s, speed: 4485.099640 tokens/s, learning rate: 1.126e-05, loss_scalings: 13421.773438, pp_loss: 7.845339
[INFO] 2021-07-12 18:54:09,330 [run_pretraining.py:  512]:	********exe.run_1127******* 
[INFO] 2021-07-12 18:54:10,254 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:10,255 [run_pretraining.py:  534]:	loss/total_loss, 7.8381500244140625, 1128
[INFO] 2021-07-12 18:54:10,255 [run_pretraining.py:  535]:	loss/mlm_loss, 7.8381500244140625, 1128
[INFO] 2021-07-12 18:54:10,255 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1269999959040433e-05, 1128
[INFO] 2021-07-12 18:54:10,255 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1128
[INFO] 2021-07-12 18:54:10,255 [run_pretraining.py:  558]:	worker_index: 6, step: 1128, cost: 7.838150, mlm loss: 7.838150, speed: 1.081706 steps/s, speed: 8.653650 samples/s, speed: 4430.668710 tokens/s, learning rate: 1.127e-05, loss_scalings: 13421.773438, pp_loss: 7.655344
[INFO] 2021-07-12 18:54:10,255 [run_pretraining.py:  512]:	********exe.run_1128******* 
[INFO] 2021-07-12 18:54:11,182 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:11,183 [run_pretraining.py:  534]:	loss/total_loss, 7.538309574127197, 1129
[INFO] 2021-07-12 18:54:11,183 [run_pretraining.py:  535]:	loss/mlm_loss, 7.538309574127197, 1129
[INFO] 2021-07-12 18:54:11,183 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1279999853286427e-05, 1129
[INFO] 2021-07-12 18:54:11,183 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1129
[INFO] 2021-07-12 18:54:11,183 [run_pretraining.py:  558]:	worker_index: 6, step: 1129, cost: 7.538310, mlm loss: 7.538310, speed: 1.078521 steps/s, speed: 8.628171 samples/s, speed: 4417.623723 tokens/s, learning rate: 1.128e-05, loss_scalings: 13421.773438, pp_loss: 7.635941
[INFO] 2021-07-12 18:54:11,183 [run_pretraining.py:  512]:	********exe.run_1129******* 
[INFO] 2021-07-12 18:54:12,096 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:12,097 [run_pretraining.py:  534]:	loss/total_loss, 7.681235313415527, 1130
[INFO] 2021-07-12 18:54:12,097 [run_pretraining.py:  535]:	loss/mlm_loss, 7.681235313415527, 1130
[INFO] 2021-07-12 18:54:12,097 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.128999974753242e-05, 1130
[INFO] 2021-07-12 18:54:12,097 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1130
[INFO] 2021-07-12 18:54:12,097 [run_pretraining.py:  558]:	worker_index: 6, step: 1130, cost: 7.681235, mlm loss: 7.681235, speed: 1.094832 steps/s, speed: 8.758655 samples/s, speed: 4484.431149 tokens/s, learning rate: 1.129e-05, loss_scalings: 13421.773438, pp_loss: 7.610729
[INFO] 2021-07-12 18:54:12,097 [run_pretraining.py:  512]:	********exe.run_1130******* 
[INFO] 2021-07-12 18:54:13,010 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:13,010 [run_pretraining.py:  534]:	loss/total_loss, 7.145077228546143, 1131
[INFO] 2021-07-12 18:54:13,010 [run_pretraining.py:  535]:	loss/mlm_loss, 7.145077228546143, 1131
[INFO] 2021-07-12 18:54:13,010 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1299999641778413e-05, 1131
[INFO] 2021-07-12 18:54:13,011 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1131
[INFO] 2021-07-12 18:54:13,011 [run_pretraining.py:  558]:	worker_index: 6, step: 1131, cost: 7.145077, mlm loss: 7.145077, speed: 1.095542 steps/s, speed: 8.764335 samples/s, speed: 4487.339542 tokens/s, learning rate: 1.130e-05, loss_scalings: 13421.773438, pp_loss: 7.453506
[INFO] 2021-07-12 18:54:13,011 [run_pretraining.py:  512]:	********exe.run_1131******* 
[INFO] 2021-07-12 18:54:13,937 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:13,938 [run_pretraining.py:  534]:	loss/total_loss, 7.410571098327637, 1132
[INFO] 2021-07-12 18:54:13,938 [run_pretraining.py:  535]:	loss/mlm_loss, 7.410571098327637, 1132
[INFO] 2021-07-12 18:54:13,938 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1309999536024407e-05, 1132
[INFO] 2021-07-12 18:54:13,938 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1132
[INFO] 2021-07-12 18:54:13,938 [run_pretraining.py:  558]:	worker_index: 6, step: 1132, cost: 7.410571, mlm loss: 7.410571, speed: 1.078572 steps/s, speed: 8.628580 samples/s, speed: 4417.832747 tokens/s, learning rate: 1.131e-05, loss_scalings: 13421.773438, pp_loss: 7.588217
[INFO] 2021-07-12 18:54:13,939 [run_pretraining.py:  512]:	********exe.run_1132******* 
[INFO] 2021-07-12 18:54:14,844 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:14,845 [run_pretraining.py:  534]:	loss/total_loss, 7.391567230224609, 1133
[INFO] 2021-07-12 18:54:14,845 [run_pretraining.py:  535]:	loss/mlm_loss, 7.391567230224609, 1133
[INFO] 2021-07-12 18:54:14,845 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.13199994302704e-05, 1133
[INFO] 2021-07-12 18:54:14,845 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1133
[INFO] 2021-07-12 18:54:14,845 [run_pretraining.py:  558]:	worker_index: 6, step: 1133, cost: 7.391567, mlm loss: 7.391567, speed: 1.103470 steps/s, speed: 8.827763 samples/s, speed: 4519.814508 tokens/s, learning rate: 1.132e-05, loss_scalings: 13421.773438, pp_loss: 6.920478
[INFO] 2021-07-12 18:54:14,845 [run_pretraining.py:  512]:	********exe.run_1133******* 
[INFO] 2021-07-12 18:54:15,767 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:15,768 [run_pretraining.py:  534]:	loss/total_loss, 7.86325216293335, 1134
[INFO] 2021-07-12 18:54:15,768 [run_pretraining.py:  535]:	loss/mlm_loss, 7.86325216293335, 1134
[INFO] 2021-07-12 18:54:15,768 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1330000234011095e-05, 1134
[INFO] 2021-07-12 18:54:15,768 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1134
[INFO] 2021-07-12 18:54:15,768 [run_pretraining.py:  558]:	worker_index: 6, step: 1134, cost: 7.863252, mlm loss: 7.863252, speed: 1.084187 steps/s, speed: 8.673500 samples/s, speed: 4440.831973 tokens/s, learning rate: 1.133e-05, loss_scalings: 13421.773438, pp_loss: 7.690217
[INFO] 2021-07-12 18:54:15,769 [run_pretraining.py:  512]:	********exe.run_1134******* 
[INFO] 2021-07-12 18:54:16,698 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:16,699 [run_pretraining.py:  534]:	loss/total_loss, 8.228158950805664, 1135
[INFO] 2021-07-12 18:54:16,699 [run_pretraining.py:  535]:	loss/mlm_loss, 8.228158950805664, 1135
[INFO] 2021-07-12 18:54:16,699 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1339999218762387e-05, 1135
[INFO] 2021-07-12 18:54:16,699 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1135
[INFO] 2021-07-12 18:54:16,699 [run_pretraining.py:  558]:	worker_index: 6, step: 1135, cost: 8.228159, mlm loss: 8.228159, speed: 1.075408 steps/s, speed: 8.603266 samples/s, speed: 4404.872160 tokens/s, learning rate: 1.134e-05, loss_scalings: 13421.773438, pp_loss: 7.114702
[INFO] 2021-07-12 18:54:16,699 [run_pretraining.py:  512]:	********exe.run_1135******* 
[INFO] 2021-07-12 18:54:17,622 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:17,623 [run_pretraining.py:  534]:	loss/total_loss, 7.411019325256348, 1136
[INFO] 2021-07-12 18:54:17,623 [run_pretraining.py:  535]:	loss/mlm_loss, 7.411019325256348, 1136
[INFO] 2021-07-12 18:54:17,623 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1350000022503082e-05, 1136
[INFO] 2021-07-12 18:54:17,623 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1136
[INFO] 2021-07-12 18:54:17,623 [run_pretraining.py:  558]:	worker_index: 6, step: 1136, cost: 7.411019, mlm loss: 7.411019, speed: 1.082580 steps/s, speed: 8.660636 samples/s, speed: 4434.245850 tokens/s, learning rate: 1.135e-05, loss_scalings: 13421.773438, pp_loss: 7.990146
[INFO] 2021-07-12 18:54:17,624 [run_pretraining.py:  512]:	********exe.run_1136******* 
[INFO] 2021-07-12 18:54:18,542 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:18,543 [run_pretraining.py:  534]:	loss/total_loss, 7.8670759201049805, 1137
[INFO] 2021-07-12 18:54:18,543 [run_pretraining.py:  535]:	loss/mlm_loss, 7.8670759201049805, 1137
[INFO] 2021-07-12 18:54:18,543 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1359999916749075e-05, 1137
[INFO] 2021-07-12 18:54:18,543 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1137
[INFO] 2021-07-12 18:54:18,543 [run_pretraining.py:  558]:	worker_index: 6, step: 1137, cost: 7.867076, mlm loss: 7.867076, speed: 1.087891 steps/s, speed: 8.703126 samples/s, speed: 4456.000469 tokens/s, learning rate: 1.136e-05, loss_scalings: 13421.773438, pp_loss: 7.997263
[INFO] 2021-07-12 18:54:18,544 [run_pretraining.py:  512]:	********exe.run_1137******* 
[INFO] 2021-07-12 18:54:19,463 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:19,464 [run_pretraining.py:  534]:	loss/total_loss, 7.802033424377441, 1138
[INFO] 2021-07-12 18:54:19,464 [run_pretraining.py:  535]:	loss/mlm_loss, 7.802033424377441, 1138
[INFO] 2021-07-12 18:54:19,464 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1369999810995068e-05, 1138
[INFO] 2021-07-12 18:54:19,464 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1138
[INFO] 2021-07-12 18:54:19,464 [run_pretraining.py:  558]:	worker_index: 6, step: 1138, cost: 7.802033, mlm loss: 7.802033, speed: 1.087247 steps/s, speed: 8.697980 samples/s, speed: 4453.365721 tokens/s, learning rate: 1.137e-05, loss_scalings: 13421.773438, pp_loss: 7.830477
[INFO] 2021-07-12 18:54:19,464 [run_pretraining.py:  512]:	********exe.run_1138******* 
[INFO] 2021-07-12 18:54:20,384 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:20,385 [run_pretraining.py:  534]:	loss/total_loss, 7.69184684753418, 1139
[INFO] 2021-07-12 18:54:20,385 [run_pretraining.py:  535]:	loss/mlm_loss, 7.69184684753418, 1139
[INFO] 2021-07-12 18:54:20,385 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1379999705241062e-05, 1139
[INFO] 2021-07-12 18:54:20,385 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1139
[INFO] 2021-07-12 18:54:20,385 [run_pretraining.py:  558]:	worker_index: 6, step: 1139, cost: 7.691847, mlm loss: 7.691847, speed: 1.086173 steps/s, speed: 8.689385 samples/s, speed: 4448.964879 tokens/s, learning rate: 1.138e-05, loss_scalings: 13421.773438, pp_loss: 7.627201
[INFO] 2021-07-12 18:54:20,385 [run_pretraining.py:  512]:	********exe.run_1139******* 
[INFO] 2021-07-12 18:54:21,299 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:21,299 [run_pretraining.py:  534]:	loss/total_loss, 8.439733505249023, 1140
[INFO] 2021-07-12 18:54:21,299 [run_pretraining.py:  535]:	loss/mlm_loss, 8.439733505249023, 1140
[INFO] 2021-07-12 18:54:21,300 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1389999599487055e-05, 1140
[INFO] 2021-07-12 18:54:21,300 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1140
[INFO] 2021-07-12 18:54:21,300 [run_pretraining.py:  558]:	worker_index: 6, step: 1140, cost: 8.439734, mlm loss: 8.439734, speed: 1.094420 steps/s, speed: 8.755361 samples/s, speed: 4482.745001 tokens/s, learning rate: 1.139e-05, loss_scalings: 13421.773438, pp_loss: 7.730140
[INFO] 2021-07-12 18:54:21,300 [run_pretraining.py:  512]:	********exe.run_1140******* 
[INFO] 2021-07-12 18:54:22,221 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:22,222 [run_pretraining.py:  534]:	loss/total_loss, 7.870477676391602, 1141
[INFO] 2021-07-12 18:54:22,222 [run_pretraining.py:  535]:	loss/mlm_loss, 7.870477676391602, 1141
[INFO] 2021-07-12 18:54:22,222 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1399999493733048e-05, 1141
[INFO] 2021-07-12 18:54:22,222 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1141
[INFO] 2021-07-12 18:54:22,222 [run_pretraining.py:  558]:	worker_index: 6, step: 1141, cost: 7.870478, mlm loss: 7.870478, speed: 1.085131 steps/s, speed: 8.681046 samples/s, speed: 4444.695762 tokens/s, learning rate: 1.140e-05, loss_scalings: 13421.773438, pp_loss: 7.826180
[INFO] 2021-07-12 18:54:22,222 [run_pretraining.py:  512]:	********exe.run_1141******* 
[INFO] 2021-07-12 18:54:23,143 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:23,144 [run_pretraining.py:  534]:	loss/total_loss, 7.348597526550293, 1142
[INFO] 2021-07-12 18:54:23,144 [run_pretraining.py:  535]:	loss/mlm_loss, 7.348597526550293, 1142
[INFO] 2021-07-12 18:54:23,144 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1410000297473744e-05, 1142
[INFO] 2021-07-12 18:54:23,144 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1142
[INFO] 2021-07-12 18:54:23,144 [run_pretraining.py:  558]:	worker_index: 6, step: 1142, cost: 7.348598, mlm loss: 7.348598, speed: 1.085393 steps/s, speed: 8.683142 samples/s, speed: 4445.768888 tokens/s, learning rate: 1.141e-05, loss_scalings: 13421.773438, pp_loss: 6.379324
[INFO] 2021-07-12 18:54:23,144 [run_pretraining.py:  512]:	********exe.run_1142******* 
[INFO] 2021-07-12 18:54:24,080 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:24,081 [run_pretraining.py:  534]:	loss/total_loss, 7.162023544311523, 1143
[INFO] 2021-07-12 18:54:24,081 [run_pretraining.py:  535]:	loss/mlm_loss, 7.162023544311523, 1143
[INFO] 2021-07-12 18:54:24,081 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1420000191719737e-05, 1143
[INFO] 2021-07-12 18:54:24,081 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1143
[INFO] 2021-07-12 18:54:24,081 [run_pretraining.py:  558]:	worker_index: 6, step: 1143, cost: 7.162024, mlm loss: 7.162024, speed: 1.067939 steps/s, speed: 8.543515 samples/s, speed: 4374.279546 tokens/s, learning rate: 1.142e-05, loss_scalings: 13421.773438, pp_loss: 7.536166
[INFO] 2021-07-12 18:54:24,081 [run_pretraining.py:  512]:	********exe.run_1143******* 
[INFO] 2021-07-12 18:54:25,001 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:25,001 [run_pretraining.py:  534]:	loss/total_loss, 7.643562316894531, 1144
[INFO] 2021-07-12 18:54:25,001 [run_pretraining.py:  535]:	loss/mlm_loss, 7.643562316894531, 1144
[INFO] 2021-07-12 18:54:25,002 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1429999176471028e-05, 1144
[INFO] 2021-07-12 18:54:25,002 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1144
[INFO] 2021-07-12 18:54:25,002 [run_pretraining.py:  558]:	worker_index: 6, step: 1144, cost: 7.643562, mlm loss: 7.643562, speed: 1.087047 steps/s, speed: 8.696375 samples/s, speed: 4452.543939 tokens/s, learning rate: 1.143e-05, loss_scalings: 13421.773438, pp_loss: 7.617455
[INFO] 2021-07-12 18:54:25,002 [run_pretraining.py:  512]:	********exe.run_1144******* 
[INFO] 2021-07-12 18:54:25,918 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:25,919 [run_pretraining.py:  534]:	loss/total_loss, 7.971392631530762, 1145
[INFO] 2021-07-12 18:54:25,919 [run_pretraining.py:  535]:	loss/mlm_loss, 7.971392631530762, 1145
[INFO] 2021-07-12 18:54:25,919 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1439999980211724e-05, 1145
[INFO] 2021-07-12 18:54:25,919 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1145
[INFO] 2021-07-12 18:54:25,919 [run_pretraining.py:  558]:	worker_index: 6, step: 1145, cost: 7.971393, mlm loss: 7.971393, speed: 1.090537 steps/s, speed: 8.724295 samples/s, speed: 4466.838976 tokens/s, learning rate: 1.144e-05, loss_scalings: 13421.773438, pp_loss: 7.879085
[INFO] 2021-07-12 18:54:25,920 [run_pretraining.py:  512]:	********exe.run_1145******* 
[INFO] 2021-07-12 18:54:26,827 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:26,828 [run_pretraining.py:  534]:	loss/total_loss, 7.775356769561768, 1146
[INFO] 2021-07-12 18:54:26,828 [run_pretraining.py:  535]:	loss/mlm_loss, 7.775356769561768, 1146
[INFO] 2021-07-12 18:54:26,828 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1449999874457717e-05, 1146
[INFO] 2021-07-12 18:54:26,828 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1146
[INFO] 2021-07-12 18:54:26,828 [run_pretraining.py:  558]:	worker_index: 6, step: 1146, cost: 7.775357, mlm loss: 7.775357, speed: 1.101237 steps/s, speed: 8.809893 samples/s, speed: 4510.665043 tokens/s, learning rate: 1.145e-05, loss_scalings: 13421.773438, pp_loss: 7.494517
[INFO] 2021-07-12 18:54:26,828 [run_pretraining.py:  512]:	********exe.run_1146******* 
[INFO] 2021-07-12 18:54:27,754 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:27,755 [run_pretraining.py:  534]:	loss/total_loss, 7.187175273895264, 1147
[INFO] 2021-07-12 18:54:27,755 [run_pretraining.py:  535]:	loss/mlm_loss, 7.187175273895264, 1147
[INFO] 2021-07-12 18:54:27,755 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.145999976870371e-05, 1147
[INFO] 2021-07-12 18:54:27,755 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1147
[INFO] 2021-07-12 18:54:27,755 [run_pretraining.py:  558]:	worker_index: 6, step: 1147, cost: 7.187175, mlm loss: 7.187175, speed: 1.079290 steps/s, speed: 8.634321 samples/s, speed: 4420.772536 tokens/s, learning rate: 1.146e-05, loss_scalings: 13421.773438, pp_loss: 7.224284
[INFO] 2021-07-12 18:54:27,756 [run_pretraining.py:  512]:	********exe.run_1147******* 
[INFO] 2021-07-12 18:54:28,669 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:28,669 [run_pretraining.py:  534]:	loss/total_loss, 7.426253318786621, 1148
[INFO] 2021-07-12 18:54:28,669 [run_pretraining.py:  535]:	loss/mlm_loss, 7.426253318786621, 1148
[INFO] 2021-07-12 18:54:28,669 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1469999662949704e-05, 1148
[INFO] 2021-07-12 18:54:28,670 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1148
[INFO] 2021-07-12 18:54:28,670 [run_pretraining.py:  558]:	worker_index: 6, step: 1148, cost: 7.426253, mlm loss: 7.426253, speed: 1.094725 steps/s, speed: 8.757800 samples/s, speed: 4483.993401 tokens/s, learning rate: 1.147e-05, loss_scalings: 13421.773438, pp_loss: 7.844260
[INFO] 2021-07-12 18:54:28,670 [run_pretraining.py:  512]:	********exe.run_1148******* 
[INFO] 2021-07-12 18:54:29,577 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:29,578 [run_pretraining.py:  534]:	loss/total_loss, 7.728064060211182, 1149
[INFO] 2021-07-12 18:54:29,578 [run_pretraining.py:  535]:	loss/mlm_loss, 7.728064060211182, 1149
[INFO] 2021-07-12 18:54:29,578 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1479999557195697e-05, 1149
[INFO] 2021-07-12 18:54:29,578 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1149
[INFO] 2021-07-12 18:54:29,578 [run_pretraining.py:  558]:	worker_index: 6, step: 1149, cost: 7.728064, mlm loss: 7.728064, speed: 1.101569 steps/s, speed: 8.812549 samples/s, speed: 4512.025028 tokens/s, learning rate: 1.148e-05, loss_scalings: 13421.773438, pp_loss: 7.858624
[INFO] 2021-07-12 18:54:29,578 [run_pretraining.py:  512]:	********exe.run_1149******* 
[INFO] 2021-07-12 18:54:30,488 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:30,488 [run_pretraining.py:  534]:	loss/total_loss, 7.614801406860352, 1150
[INFO] 2021-07-12 18:54:30,488 [run_pretraining.py:  535]:	loss/mlm_loss, 7.614801406860352, 1150
[INFO] 2021-07-12 18:54:30,489 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.148999945144169e-05, 1150
[INFO] 2021-07-12 18:54:30,489 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1150
[INFO] 2021-07-12 18:54:30,489 [run_pretraining.py:  558]:	worker_index: 6, step: 1150, cost: 7.614801, mlm loss: 7.614801, speed: 1.099099 steps/s, speed: 8.792793 samples/s, speed: 4501.909968 tokens/s, learning rate: 1.149e-05, loss_scalings: 13421.773438, pp_loss: 7.798003
[INFO] 2021-07-12 18:54:30,489 [run_pretraining.py:  512]:	********exe.run_1150******* 
[INFO] 2021-07-12 18:54:31,406 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:31,406 [run_pretraining.py:  534]:	loss/total_loss, 7.775669574737549, 1151
[INFO] 2021-07-12 18:54:31,407 [run_pretraining.py:  535]:	loss/mlm_loss, 7.775669574737549, 1151
[INFO] 2021-07-12 18:54:31,407 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1500000255182385e-05, 1151
[INFO] 2021-07-12 18:54:31,407 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1151
[INFO] 2021-07-12 18:54:31,407 [run_pretraining.py:  558]:	worker_index: 6, step: 1151, cost: 7.775670, mlm loss: 7.775670, speed: 1.090043 steps/s, speed: 8.720343 samples/s, speed: 4464.815578 tokens/s, learning rate: 1.150e-05, loss_scalings: 13421.773438, pp_loss: 7.778529
[INFO] 2021-07-12 18:54:31,407 [run_pretraining.py:  512]:	********exe.run_1151******* 
[INFO] 2021-07-12 18:54:32,319 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:32,320 [run_pretraining.py:  534]:	loss/total_loss, 8.145625114440918, 1152
[INFO] 2021-07-12 18:54:32,320 [run_pretraining.py:  535]:	loss/mlm_loss, 8.145625114440918, 1152
[INFO] 2021-07-12 18:54:32,320 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1509999239933677e-05, 1152
[INFO] 2021-07-12 18:54:32,320 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1152
[INFO] 2021-07-12 18:54:32,320 [run_pretraining.py:  558]:	worker_index: 6, step: 1152, cost: 8.145625, mlm loss: 8.145625, speed: 1.095340 steps/s, speed: 8.762717 samples/s, speed: 4486.511033 tokens/s, learning rate: 1.151e-05, loss_scalings: 13421.773438, pp_loss: 7.053585
[INFO] 2021-07-12 18:54:32,321 [run_pretraining.py:  512]:	********exe.run_1152******* 
[INFO] 2021-07-12 18:54:33,229 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:33,229 [run_pretraining.py:  534]:	loss/total_loss, 7.453304767608643, 1153
[INFO] 2021-07-12 18:54:33,229 [run_pretraining.py:  535]:	loss/mlm_loss, 7.453304767608643, 1153
[INFO] 2021-07-12 18:54:33,230 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.151999913417967e-05, 1153
[INFO] 2021-07-12 18:54:33,230 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1153
[INFO] 2021-07-12 18:54:33,230 [run_pretraining.py:  558]:	worker_index: 6, step: 1153, cost: 7.453305, mlm loss: 7.453305, speed: 1.100673 steps/s, speed: 8.805382 samples/s, speed: 4508.355659 tokens/s, learning rate: 1.152e-05, loss_scalings: 13421.773438, pp_loss: 7.927849
[INFO] 2021-07-12 18:54:33,230 [run_pretraining.py:  512]:	********exe.run_1153******* 
[INFO] 2021-07-12 18:54:34,143 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:34,144 [run_pretraining.py:  534]:	loss/total_loss, 5.181300163269043, 1154
[INFO] 2021-07-12 18:54:34,144 [run_pretraining.py:  535]:	loss/mlm_loss, 5.181300163269043, 1154
[INFO] 2021-07-12 18:54:34,144 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1529999937920365e-05, 1154
[INFO] 2021-07-12 18:54:34,144 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1154
[INFO] 2021-07-12 18:54:34,144 [run_pretraining.py:  558]:	worker_index: 6, step: 1154, cost: 5.181300, mlm loss: 5.181300, speed: 1.094058 steps/s, speed: 8.752463 samples/s, speed: 4481.261165 tokens/s, learning rate: 1.153e-05, loss_scalings: 13421.773438, pp_loss: 7.169123
[INFO] 2021-07-12 18:54:34,145 [run_pretraining.py:  512]:	********exe.run_1154******* 
[INFO] 2021-07-12 18:54:35,069 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:35,070 [run_pretraining.py:  534]:	loss/total_loss, 7.7271623611450195, 1155
[INFO] 2021-07-12 18:54:35,070 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7271623611450195, 1155
[INFO] 2021-07-12 18:54:35,070 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1539999832166359e-05, 1155
[INFO] 2021-07-12 18:54:35,070 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1155
[INFO] 2021-07-12 18:54:35,070 [run_pretraining.py:  558]:	worker_index: 6, step: 1155, cost: 7.727162, mlm loss: 7.727162, speed: 1.081307 steps/s, speed: 8.650460 samples/s, speed: 4429.035302 tokens/s, learning rate: 1.154e-05, loss_scalings: 13421.773438, pp_loss: 7.761531
[INFO] 2021-07-12 18:54:35,070 [run_pretraining.py:  512]:	********exe.run_1155******* 
[INFO] 2021-07-12 18:54:35,978 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:35,979 [run_pretraining.py:  534]:	loss/total_loss, 7.574239730834961, 1156
[INFO] 2021-07-12 18:54:35,979 [run_pretraining.py:  535]:	loss/mlm_loss, 7.574239730834961, 1156
[INFO] 2021-07-12 18:54:35,979 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1549999726412352e-05, 1156
[INFO] 2021-07-12 18:54:35,979 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1156
[INFO] 2021-07-12 18:54:35,979 [run_pretraining.py:  558]:	worker_index: 6, step: 1156, cost: 7.574240, mlm loss: 7.574240, speed: 1.100891 steps/s, speed: 8.807125 samples/s, speed: 4509.247883 tokens/s, learning rate: 1.155e-05, loss_scalings: 13421.773438, pp_loss: 7.296306
[INFO] 2021-07-12 18:54:35,979 [run_pretraining.py:  512]:	********exe.run_1156******* 
[INFO] 2021-07-12 18:54:36,884 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:36,885 [run_pretraining.py:  534]:	loss/total_loss, 7.7359466552734375, 1157
[INFO] 2021-07-12 18:54:36,885 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7359466552734375, 1157
[INFO] 2021-07-12 18:54:36,885 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1559999620658346e-05, 1157
[INFO] 2021-07-12 18:54:36,885 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1157
[INFO] 2021-07-12 18:54:36,885 [run_pretraining.py:  558]:	worker_index: 6, step: 1157, cost: 7.735947, mlm loss: 7.735947, speed: 1.104711 steps/s, speed: 8.837691 samples/s, speed: 4524.897711 tokens/s, learning rate: 1.156e-05, loss_scalings: 13421.773438, pp_loss: 6.494025
[INFO] 2021-07-12 18:54:36,885 [run_pretraining.py:  512]:	********exe.run_1157******* 
[INFO] 2021-07-12 18:54:37,803 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:37,803 [run_pretraining.py:  534]:	loss/total_loss, 7.229024410247803, 1158
[INFO] 2021-07-12 18:54:37,803 [run_pretraining.py:  535]:	loss/mlm_loss, 7.229024410247803, 1158
[INFO] 2021-07-12 18:54:37,803 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1569999514904339e-05, 1158
[INFO] 2021-07-12 18:54:37,804 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1158
[INFO] 2021-07-12 18:54:37,804 [run_pretraining.py:  558]:	worker_index: 6, step: 1158, cost: 7.229024, mlm loss: 7.229024, speed: 1.089329 steps/s, speed: 8.714629 samples/s, speed: 4461.889945 tokens/s, learning rate: 1.157e-05, loss_scalings: 13421.773438, pp_loss: 7.599704
[INFO] 2021-07-12 18:54:37,804 [run_pretraining.py:  512]:	********exe.run_1158******* 
[INFO] 2021-07-12 18:54:38,709 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:38,709 [run_pretraining.py:  534]:	loss/total_loss, 7.937010288238525, 1159
[INFO] 2021-07-12 18:54:38,709 [run_pretraining.py:  535]:	loss/mlm_loss, 7.937010288238525, 1159
[INFO] 2021-07-12 18:54:38,709 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1579999409150332e-05, 1159
[INFO] 2021-07-12 18:54:38,710 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1159
[INFO] 2021-07-12 18:54:38,710 [run_pretraining.py:  558]:	worker_index: 6, step: 1159, cost: 7.937010, mlm loss: 7.937010, speed: 1.104645 steps/s, speed: 8.837162 samples/s, speed: 4524.627192 tokens/s, learning rate: 1.158e-05, loss_scalings: 13421.773438, pp_loss: 7.482163
[INFO] 2021-07-12 18:54:38,710 [run_pretraining.py:  512]:	********exe.run_1159******* 
[INFO] 2021-07-12 18:54:39,631 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:39,631 [run_pretraining.py:  534]:	loss/total_loss, 7.915700912475586, 1160
[INFO] 2021-07-12 18:54:39,632 [run_pretraining.py:  535]:	loss/mlm_loss, 7.915700912475586, 1160
[INFO] 2021-07-12 18:54:39,632 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1590000212891027e-05, 1160
[INFO] 2021-07-12 18:54:39,632 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1160
[INFO] 2021-07-12 18:54:39,632 [run_pretraining.py:  558]:	worker_index: 6, step: 1160, cost: 7.915701, mlm loss: 7.915701, speed: 1.085229 steps/s, speed: 8.681835 samples/s, speed: 4445.099418 tokens/s, learning rate: 1.159e-05, loss_scalings: 13421.773438, pp_loss: 7.737911
[INFO] 2021-07-12 18:54:39,632 [run_pretraining.py:  512]:	********exe.run_1160******* 
[INFO] 2021-07-12 18:54:40,537 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:40,538 [run_pretraining.py:  534]:	loss/total_loss, 7.396656036376953, 1161
[INFO] 2021-07-12 18:54:40,538 [run_pretraining.py:  535]:	loss/mlm_loss, 7.396656036376953, 1161
[INFO] 2021-07-12 18:54:40,538 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1599999197642319e-05, 1161
[INFO] 2021-07-12 18:54:40,538 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1161
[INFO] 2021-07-12 18:54:40,538 [run_pretraining.py:  558]:	worker_index: 6, step: 1161, cost: 7.396656, mlm loss: 7.396656, speed: 1.104460 steps/s, speed: 8.835680 samples/s, speed: 4523.868243 tokens/s, learning rate: 1.160e-05, loss_scalings: 13421.773438, pp_loss: 7.634400
[INFO] 2021-07-12 18:54:40,538 [run_pretraining.py:  512]:	********exe.run_1161******* 
[INFO] 2021-07-12 18:54:41,451 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:41,451 [run_pretraining.py:  534]:	loss/total_loss, 7.623603820800781, 1162
[INFO] 2021-07-12 18:54:41,452 [run_pretraining.py:  535]:	loss/mlm_loss, 7.623603820800781, 1162
[INFO] 2021-07-12 18:54:41,452 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1609999091888312e-05, 1162
[INFO] 2021-07-12 18:54:41,452 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1162
[INFO] 2021-07-12 18:54:41,452 [run_pretraining.py:  558]:	worker_index: 6, step: 1162, cost: 7.623604, mlm loss: 7.623604, speed: 1.095126 steps/s, speed: 8.761008 samples/s, speed: 4485.635982 tokens/s, learning rate: 1.161e-05, loss_scalings: 13421.773438, pp_loss: 7.745128
[INFO] 2021-07-12 18:54:41,452 [run_pretraining.py:  512]:	********exe.run_1162******* 
[INFO] 2021-07-12 18:54:42,371 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:42,371 [run_pretraining.py:  534]:	loss/total_loss, 4.333000183105469, 1163
[INFO] 2021-07-12 18:54:42,372 [run_pretraining.py:  535]:	loss/mlm_loss, 4.333000183105469, 1163
[INFO] 2021-07-12 18:54:42,372 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1619999895629007e-05, 1163
[INFO] 2021-07-12 18:54:42,372 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1163
[INFO] 2021-07-12 18:54:42,372 [run_pretraining.py:  558]:	worker_index: 6, step: 1163, cost: 4.333000, mlm loss: 4.333000, speed: 1.087729 steps/s, speed: 8.701830 samples/s, speed: 4455.337157 tokens/s, learning rate: 1.162e-05, loss_scalings: 13421.773438, pp_loss: 6.664466
[INFO] 2021-07-12 18:54:42,372 [run_pretraining.py:  512]:	********exe.run_1163******* 
[INFO] 2021-07-12 18:54:43,284 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:43,284 [run_pretraining.py:  534]:	loss/total_loss, 7.739312171936035, 1164
[INFO] 2021-07-12 18:54:43,285 [run_pretraining.py:  535]:	loss/mlm_loss, 7.739312171936035, 1164
[INFO] 2021-07-12 18:54:43,285 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1629999789875e-05, 1164
[INFO] 2021-07-12 18:54:43,285 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1164
[INFO] 2021-07-12 18:54:43,285 [run_pretraining.py:  558]:	worker_index: 6, step: 1164, cost: 7.739312, mlm loss: 7.739312, speed: 1.096271 steps/s, speed: 8.770165 samples/s, speed: 4490.324475 tokens/s, learning rate: 1.163e-05, loss_scalings: 13421.773438, pp_loss: 7.808799
[INFO] 2021-07-12 18:54:43,285 [run_pretraining.py:  512]:	********exe.run_1164******* 
[INFO] 2021-07-12 18:54:44,194 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:44,194 [run_pretraining.py:  534]:	loss/total_loss, 7.735592842102051, 1165
[INFO] 2021-07-12 18:54:44,195 [run_pretraining.py:  535]:	loss/mlm_loss, 7.735592842102051, 1165
[INFO] 2021-07-12 18:54:44,195 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1639999684120994e-05, 1165
[INFO] 2021-07-12 18:54:44,195 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1165
[INFO] 2021-07-12 18:54:44,195 [run_pretraining.py:  558]:	worker_index: 6, step: 1165, cost: 7.735593, mlm loss: 7.735593, speed: 1.099757 steps/s, speed: 8.798056 samples/s, speed: 4504.604849 tokens/s, learning rate: 1.164e-05, loss_scalings: 13421.773438, pp_loss: 7.845920
[INFO] 2021-07-12 18:54:44,195 [run_pretraining.py:  512]:	********exe.run_1165******* 
[INFO] 2021-07-12 18:54:45,115 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:45,115 [run_pretraining.py:  534]:	loss/total_loss, 6.6160736083984375, 1166
[INFO] 2021-07-12 18:54:45,115 [run_pretraining.py:  535]:	loss/mlm_loss, 6.6160736083984375, 1166
[INFO] 2021-07-12 18:54:45,115 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1649999578366987e-05, 1166
[INFO] 2021-07-12 18:54:45,115 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1166
[INFO] 2021-07-12 18:54:45,116 [run_pretraining.py:  558]:	worker_index: 6, step: 1166, cost: 6.616074, mlm loss: 6.616074, speed: 1.086881 steps/s, speed: 8.695050 samples/s, speed: 4451.865505 tokens/s, learning rate: 1.165e-05, loss_scalings: 13421.773438, pp_loss: 7.263355
[INFO] 2021-07-12 18:54:45,116 [run_pretraining.py:  512]:	********exe.run_1166******* 
[INFO] 2021-07-12 18:54:46,028 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:46,029 [run_pretraining.py:  534]:	loss/total_loss, 6.621129035949707, 1167
[INFO] 2021-07-12 18:54:46,029 [run_pretraining.py:  535]:	loss/mlm_loss, 6.621129035949707, 1167
[INFO] 2021-07-12 18:54:46,029 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.165999947261298e-05, 1167
[INFO] 2021-07-12 18:54:46,029 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1167
[INFO] 2021-07-12 18:54:46,029 [run_pretraining.py:  558]:	worker_index: 6, step: 1167, cost: 6.621129, mlm loss: 6.621129, speed: 1.095410 steps/s, speed: 8.763280 samples/s, speed: 4486.799277 tokens/s, learning rate: 1.166e-05, loss_scalings: 13421.773438, pp_loss: 7.172534
[INFO] 2021-07-12 18:54:46,029 [run_pretraining.py:  512]:	********exe.run_1167******* 
[INFO] 2021-07-12 18:54:46,934 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:46,934 [run_pretraining.py:  534]:	loss/total_loss, 7.627995491027832, 1168
[INFO] 2021-07-12 18:54:46,934 [run_pretraining.py:  535]:	loss/mlm_loss, 7.627995491027832, 1168
[INFO] 2021-07-12 18:54:46,934 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1669999366858974e-05, 1168
[INFO] 2021-07-12 18:54:46,935 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1168
[INFO] 2021-07-12 18:54:46,935 [run_pretraining.py:  558]:	worker_index: 6, step: 1168, cost: 7.627995, mlm loss: 7.627995, speed: 1.105257 steps/s, speed: 8.842057 samples/s, speed: 4527.133410 tokens/s, learning rate: 1.167e-05, loss_scalings: 13421.773438, pp_loss: 7.113078
[INFO] 2021-07-12 18:54:46,935 [run_pretraining.py:  512]:	********exe.run_1168******* 
[INFO] 2021-07-12 18:54:47,856 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:47,857 [run_pretraining.py:  534]:	loss/total_loss, 7.301034927368164, 1169
[INFO] 2021-07-12 18:54:47,857 [run_pretraining.py:  535]:	loss/mlm_loss, 7.301034927368164, 1169
[INFO] 2021-07-12 18:54:47,857 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.168000017059967e-05, 1169
[INFO] 2021-07-12 18:54:47,857 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1169
[INFO] 2021-07-12 18:54:47,857 [run_pretraining.py:  558]:	worker_index: 6, step: 1169, cost: 7.301035, mlm loss: 7.301035, speed: 1.084893 steps/s, speed: 8.679147 samples/s, speed: 4443.723150 tokens/s, learning rate: 1.168e-05, loss_scalings: 13421.773438, pp_loss: 7.878902
[INFO] 2021-07-12 18:54:47,857 [run_pretraining.py:  512]:	********exe.run_1169******* 
[INFO] 2021-07-12 18:54:48,773 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:48,773 [run_pretraining.py:  534]:	loss/total_loss, 7.647395610809326, 1170
[INFO] 2021-07-12 18:54:48,773 [run_pretraining.py:  535]:	loss/mlm_loss, 7.647395610809326, 1170
[INFO] 2021-07-12 18:54:48,773 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.168999915535096e-05, 1170
[INFO] 2021-07-12 18:54:48,773 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1170
[INFO] 2021-07-12 18:54:48,774 [run_pretraining.py:  558]:	worker_index: 6, step: 1170, cost: 7.647396, mlm loss: 7.647396, speed: 1.092017 steps/s, speed: 8.736136 samples/s, speed: 4472.901556 tokens/s, learning rate: 1.169e-05, loss_scalings: 13421.773438, pp_loss: 7.581276
[INFO] 2021-07-12 18:54:48,774 [run_pretraining.py:  512]:	********exe.run_1170******* 
[INFO] 2021-07-12 18:54:49,681 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:49,681 [run_pretraining.py:  534]:	loss/total_loss, 8.004188537597656, 1171
[INFO] 2021-07-12 18:54:49,681 [run_pretraining.py:  535]:	loss/mlm_loss, 8.004188537597656, 1171
[INFO] 2021-07-12 18:54:49,681 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1699999959091656e-05, 1171
[INFO] 2021-07-12 18:54:49,682 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1171
[INFO] 2021-07-12 18:54:49,682 [run_pretraining.py:  558]:	worker_index: 6, step: 1171, cost: 8.004189, mlm loss: 8.004189, speed: 1.102047 steps/s, speed: 8.816379 samples/s, speed: 4513.985891 tokens/s, learning rate: 1.170e-05, loss_scalings: 13421.773438, pp_loss: 7.548249
[INFO] 2021-07-12 18:54:49,682 [run_pretraining.py:  512]:	********exe.run_1171******* 
[INFO] 2021-07-12 18:54:50,597 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:50,598 [run_pretraining.py:  534]:	loss/total_loss, 7.4962358474731445, 1172
[INFO] 2021-07-12 18:54:50,598 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4962358474731445, 1172
[INFO] 2021-07-12 18:54:50,598 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.170999985333765e-05, 1172
[INFO] 2021-07-12 18:54:50,598 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1172
[INFO] 2021-07-12 18:54:50,598 [run_pretraining.py:  558]:	worker_index: 6, step: 1172, cost: 7.496236, mlm loss: 7.496236, speed: 1.091555 steps/s, speed: 8.732441 samples/s, speed: 4471.009960 tokens/s, learning rate: 1.171e-05, loss_scalings: 13421.773438, pp_loss: 7.476272
[INFO] 2021-07-12 18:54:50,599 [run_pretraining.py:  512]:	********exe.run_1172******* 
[INFO] 2021-07-12 18:54:51,513 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:51,514 [run_pretraining.py:  534]:	loss/total_loss, 7.332523822784424, 1173
[INFO] 2021-07-12 18:54:51,514 [run_pretraining.py:  535]:	loss/mlm_loss, 7.332523822784424, 1173
[INFO] 2021-07-12 18:54:51,514 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1719999747583643e-05, 1173
[INFO] 2021-07-12 18:54:51,514 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1173
[INFO] 2021-07-12 18:54:51,514 [run_pretraining.py:  558]:	worker_index: 6, step: 1173, cost: 7.332524, mlm loss: 7.332524, speed: 1.092897 steps/s, speed: 8.743177 samples/s, speed: 4476.506418 tokens/s, learning rate: 1.172e-05, loss_scalings: 13421.773438, pp_loss: 7.893716
[INFO] 2021-07-12 18:54:51,514 [run_pretraining.py:  512]:	********exe.run_1173******* 
[INFO] 2021-07-12 18:54:52,421 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:52,421 [run_pretraining.py:  534]:	loss/total_loss, 7.783707618713379, 1174
[INFO] 2021-07-12 18:54:52,421 [run_pretraining.py:  535]:	loss/mlm_loss, 7.783707618713379, 1174
[INFO] 2021-07-12 18:54:52,422 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1729999641829636e-05, 1174
[INFO] 2021-07-12 18:54:52,422 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1174
[INFO] 2021-07-12 18:54:52,422 [run_pretraining.py:  558]:	worker_index: 6, step: 1174, cost: 7.783708, mlm loss: 7.783708, speed: 1.102783 steps/s, speed: 8.822262 samples/s, speed: 4516.998078 tokens/s, learning rate: 1.173e-05, loss_scalings: 13421.773438, pp_loss: 7.647882
[INFO] 2021-07-12 18:54:52,422 [run_pretraining.py:  512]:	********exe.run_1174******* 
[INFO] 2021-07-12 18:54:53,335 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:53,335 [run_pretraining.py:  534]:	loss/total_loss, 8.265864372253418, 1175
[INFO] 2021-07-12 18:54:53,335 [run_pretraining.py:  535]:	loss/mlm_loss, 8.265864372253418, 1175
[INFO] 2021-07-12 18:54:53,335 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.173999953607563e-05, 1175
[INFO] 2021-07-12 18:54:53,336 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1175
[INFO] 2021-07-12 18:54:53,336 [run_pretraining.py:  558]:	worker_index: 6, step: 1175, cost: 8.265864, mlm loss: 8.265864, speed: 1.095062 steps/s, speed: 8.760500 samples/s, speed: 4485.375992 tokens/s, learning rate: 1.174e-05, loss_scalings: 13421.773438, pp_loss: 7.825415
[INFO] 2021-07-12 18:54:53,336 [run_pretraining.py:  512]:	********exe.run_1175******* 
[INFO] 2021-07-12 18:54:54,251 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:54,251 [run_pretraining.py:  534]:	loss/total_loss, 7.110469818115234, 1176
[INFO] 2021-07-12 18:54:54,251 [run_pretraining.py:  535]:	loss/mlm_loss, 7.110469818115234, 1176
[INFO] 2021-07-12 18:54:54,252 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1749999430321623e-05, 1176
[INFO] 2021-07-12 18:54:54,252 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1176
[INFO] 2021-07-12 18:54:54,252 [run_pretraining.py:  558]:	worker_index: 6, step: 1176, cost: 7.110470, mlm loss: 7.110470, speed: 1.092411 steps/s, speed: 8.739289 samples/s, speed: 4474.516208 tokens/s, learning rate: 1.175e-05, loss_scalings: 13421.773438, pp_loss: 7.340901
[INFO] 2021-07-12 18:54:54,252 [run_pretraining.py:  512]:	********exe.run_1176******* 
[INFO] 2021-07-12 18:54:55,164 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:55,165 [run_pretraining.py:  534]:	loss/total_loss, 6.952567100524902, 1177
[INFO] 2021-07-12 18:54:55,165 [run_pretraining.py:  535]:	loss/mlm_loss, 6.952567100524902, 1177
[INFO] 2021-07-12 18:54:55,165 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1760000234062318e-05, 1177
[INFO] 2021-07-12 18:54:55,165 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1177
[INFO] 2021-07-12 18:54:55,165 [run_pretraining.py:  558]:	worker_index: 6, step: 1177, cost: 6.952567, mlm loss: 6.952567, speed: 1.095344 steps/s, speed: 8.762751 samples/s, speed: 4486.528608 tokens/s, learning rate: 1.176e-05, loss_scalings: 13421.773438, pp_loss: 7.245744
[INFO] 2021-07-12 18:54:55,165 [run_pretraining.py:  512]:	********exe.run_1177******* 
[INFO] 2021-07-12 18:54:56,090 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:56,090 [run_pretraining.py:  534]:	loss/total_loss, 8.02695369720459, 1178
[INFO] 2021-07-12 18:54:56,091 [run_pretraining.py:  535]:	loss/mlm_loss, 8.02695369720459, 1178
[INFO] 2021-07-12 18:54:56,091 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1770000128308311e-05, 1178
[INFO] 2021-07-12 18:54:56,091 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1178
[INFO] 2021-07-12 18:54:56,091 [run_pretraining.py:  558]:	worker_index: 6, step: 1178, cost: 8.026954, mlm loss: 8.026954, speed: 1.081432 steps/s, speed: 8.651452 samples/s, speed: 4429.543471 tokens/s, learning rate: 1.177e-05, loss_scalings: 13421.773438, pp_loss: 6.463017
[INFO] 2021-07-12 18:54:56,091 [run_pretraining.py:  512]:	********exe.run_1178******* 
[INFO] 2021-07-12 18:54:57,002 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:57,003 [run_pretraining.py:  534]:	loss/total_loss, 7.504796028137207, 1179
[INFO] 2021-07-12 18:54:57,003 [run_pretraining.py:  535]:	loss/mlm_loss, 7.504796028137207, 1179
[INFO] 2021-07-12 18:54:57,003 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1779999113059603e-05, 1179
[INFO] 2021-07-12 18:54:57,003 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1179
[INFO] 2021-07-12 18:54:57,003 [run_pretraining.py:  558]:	worker_index: 6, step: 1179, cost: 7.504796, mlm loss: 7.504796, speed: 1.096878 steps/s, speed: 8.775023 samples/s, speed: 4492.811626 tokens/s, learning rate: 1.178e-05, loss_scalings: 13421.773438, pp_loss: 7.625234
[INFO] 2021-07-12 18:54:57,003 [run_pretraining.py:  512]:	********exe.run_1179******* 
[INFO] 2021-07-12 18:54:57,930 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:57,931 [run_pretraining.py:  534]:	loss/total_loss, 7.931037902832031, 1180
[INFO] 2021-07-12 18:54:57,931 [run_pretraining.py:  535]:	loss/mlm_loss, 7.931037902832031, 1180
[INFO] 2021-07-12 18:54:57,931 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1789999916800298e-05, 1180
[INFO] 2021-07-12 18:54:57,931 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1180
[INFO] 2021-07-12 18:54:57,931 [run_pretraining.py:  558]:	worker_index: 6, step: 1180, cost: 7.931038, mlm loss: 7.931038, speed: 1.078286 steps/s, speed: 8.626290 samples/s, speed: 4416.660651 tokens/s, learning rate: 1.179e-05, loss_scalings: 13421.773438, pp_loss: 7.745038
[INFO] 2021-07-12 18:54:57,931 [run_pretraining.py:  512]:	********exe.run_1180******* 
[INFO] 2021-07-12 18:54:58,853 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:58,854 [run_pretraining.py:  534]:	loss/total_loss, 7.789300918579102, 1181
[INFO] 2021-07-12 18:54:58,854 [run_pretraining.py:  535]:	loss/mlm_loss, 7.789300918579102, 1181
[INFO] 2021-07-12 18:54:58,854 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1799999811046291e-05, 1181
[INFO] 2021-07-12 18:54:58,854 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1181
[INFO] 2021-07-12 18:54:58,854 [run_pretraining.py:  558]:	worker_index: 6, step: 1181, cost: 7.789301, mlm loss: 7.789301, speed: 1.084690 steps/s, speed: 8.677517 samples/s, speed: 4442.888837 tokens/s, learning rate: 1.180e-05, loss_scalings: 13421.773438, pp_loss: 7.586237
[INFO] 2021-07-12 18:54:58,854 [run_pretraining.py:  512]:	********exe.run_1181******* 
[INFO] 2021-07-12 18:54:59,791 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:59,792 [run_pretraining.py:  534]:	loss/total_loss, 7.277886867523193, 1182
[INFO] 2021-07-12 18:54:59,792 [run_pretraining.py:  535]:	loss/mlm_loss, 7.277886867523193, 1182
[INFO] 2021-07-12 18:54:59,792 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1809999705292284e-05, 1182
[INFO] 2021-07-12 18:54:59,792 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1182
[INFO] 2021-07-12 18:54:59,792 [run_pretraining.py:  558]:	worker_index: 6, step: 1182, cost: 7.277887, mlm loss: 7.277887, speed: 1.066763 steps/s, speed: 8.534106 samples/s, speed: 4369.462258 tokens/s, learning rate: 1.181e-05, loss_scalings: 13421.773438, pp_loss: 7.716910
[INFO] 2021-07-12 18:54:59,792 [run_pretraining.py:  512]:	********exe.run_1182******* 
[INFO] 2021-07-12 18:55:00,709 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:00,709 [run_pretraining.py:  534]:	loss/total_loss, 6.949710845947266, 1183
[INFO] 2021-07-12 18:55:00,709 [run_pretraining.py:  535]:	loss/mlm_loss, 6.949710845947266, 1183
[INFO] 2021-07-12 18:55:00,709 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1819999599538278e-05, 1183
[INFO] 2021-07-12 18:55:00,710 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1183
[INFO] 2021-07-12 18:55:00,710 [run_pretraining.py:  558]:	worker_index: 6, step: 1183, cost: 6.949711, mlm loss: 6.949711, speed: 1.090718 steps/s, speed: 8.725747 samples/s, speed: 4467.582394 tokens/s, learning rate: 1.182e-05, loss_scalings: 13421.773438, pp_loss: 7.609826
[INFO] 2021-07-12 18:55:00,710 [run_pretraining.py:  512]:	********exe.run_1183******* 
[INFO] 2021-07-12 18:55:01,643 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:01,644 [run_pretraining.py:  534]:	loss/total_loss, 6.072059631347656, 1184
[INFO] 2021-07-12 18:55:01,644 [run_pretraining.py:  535]:	loss/mlm_loss, 6.072059631347656, 1184
[INFO] 2021-07-12 18:55:01,644 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1829999493784271e-05, 1184
[INFO] 2021-07-12 18:55:01,644 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1184
[INFO] 2021-07-12 18:55:01,644 [run_pretraining.py:  558]:	worker_index: 6, step: 1184, cost: 6.072060, mlm loss: 6.072060, speed: 1.070688 steps/s, speed: 8.565501 samples/s, speed: 4385.536295 tokens/s, learning rate: 1.183e-05, loss_scalings: 13421.773438, pp_loss: 7.455648
[INFO] 2021-07-12 18:55:01,644 [run_pretraining.py:  512]:	********exe.run_1184******* 
[INFO] 2021-07-12 18:55:02,560 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:02,561 [run_pretraining.py:  534]:	loss/total_loss, 7.5553765296936035, 1185
[INFO] 2021-07-12 18:55:02,561 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5553765296936035, 1185
[INFO] 2021-07-12 18:55:02,561 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1839999388030265e-05, 1185
[INFO] 2021-07-12 18:55:02,561 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1185
[INFO] 2021-07-12 18:55:02,561 [run_pretraining.py:  558]:	worker_index: 6, step: 1185, cost: 7.555377, mlm loss: 7.555377, speed: 1.091877 steps/s, speed: 8.735017 samples/s, speed: 4472.328670 tokens/s, learning rate: 1.184e-05, loss_scalings: 13421.773438, pp_loss: 7.518653
[INFO] 2021-07-12 18:55:02,561 [run_pretraining.py:  512]:	********exe.run_1185******* 
[INFO] 2021-07-12 18:55:03,479 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:03,479 [run_pretraining.py:  534]:	loss/total_loss, 7.555909156799316, 1186
[INFO] 2021-07-12 18:55:03,479 [run_pretraining.py:  535]:	loss/mlm_loss, 7.555909156799316, 1186
[INFO] 2021-07-12 18:55:03,480 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.185000019177096e-05, 1186
[INFO] 2021-07-12 18:55:03,480 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1186
[INFO] 2021-07-12 18:55:03,480 [run_pretraining.py:  558]:	worker_index: 6, step: 1186, cost: 7.555909, mlm loss: 7.555909, speed: 1.089154 steps/s, speed: 8.713235 samples/s, speed: 4461.176223 tokens/s, learning rate: 1.185e-05, loss_scalings: 13421.773438, pp_loss: 7.534503
[INFO] 2021-07-12 18:55:03,480 [run_pretraining.py:  512]:	********exe.run_1186******* 
[INFO] 2021-07-12 18:55:04,407 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:04,408 [run_pretraining.py:  534]:	loss/total_loss, 7.771141529083252, 1187
[INFO] 2021-07-12 18:55:04,408 [run_pretraining.py:  535]:	loss/mlm_loss, 7.771141529083252, 1187
[INFO] 2021-07-12 18:55:04,408 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1860000086016953e-05, 1187
[INFO] 2021-07-12 18:55:04,408 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1187
[INFO] 2021-07-12 18:55:04,408 [run_pretraining.py:  558]:	worker_index: 6, step: 1187, cost: 7.771142, mlm loss: 7.771142, speed: 1.077746 steps/s, speed: 8.621968 samples/s, speed: 4414.447632 tokens/s, learning rate: 1.186e-05, loss_scalings: 13421.773438, pp_loss: 7.641176
[INFO] 2021-07-12 18:55:04,408 [run_pretraining.py:  512]:	********exe.run_1187******* 
[INFO] 2021-07-12 18:55:05,322 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:05,322 [run_pretraining.py:  534]:	loss/total_loss, 7.540918350219727, 1188
[INFO] 2021-07-12 18:55:05,322 [run_pretraining.py:  535]:	loss/mlm_loss, 7.540918350219727, 1188
[INFO] 2021-07-12 18:55:05,322 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1869999070768245e-05, 1188
[INFO] 2021-07-12 18:55:05,323 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1188
[INFO] 2021-07-12 18:55:05,323 [run_pretraining.py:  558]:	worker_index: 6, step: 1188, cost: 7.540918, mlm loss: 7.540918, speed: 1.094642 steps/s, speed: 8.757137 samples/s, speed: 4483.654029 tokens/s, learning rate: 1.187e-05, loss_scalings: 13421.773438, pp_loss: 7.398360
[INFO] 2021-07-12 18:55:05,323 [run_pretraining.py:  512]:	********exe.run_1188******* 
[INFO] 2021-07-12 18:55:06,252 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:06,252 [run_pretraining.py:  534]:	loss/total_loss, 7.797229766845703, 1189
[INFO] 2021-07-12 18:55:06,252 [run_pretraining.py:  535]:	loss/mlm_loss, 7.797229766845703, 1189
[INFO] 2021-07-12 18:55:06,252 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.187999987450894e-05, 1189
[INFO] 2021-07-12 18:55:06,253 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1189
[INFO] 2021-07-12 18:55:06,253 [run_pretraining.py:  558]:	worker_index: 6, step: 1189, cost: 7.797230, mlm loss: 7.797230, speed: 1.076026 steps/s, speed: 8.608210 samples/s, speed: 4407.403464 tokens/s, learning rate: 1.188e-05, loss_scalings: 13421.773438, pp_loss: 7.891306
[INFO] 2021-07-12 18:55:06,253 [run_pretraining.py:  512]:	********exe.run_1189******* 
[INFO] 2021-07-12 18:55:07,174 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:07,174 [run_pretraining.py:  534]:	loss/total_loss, 7.998437881469727, 1190
[INFO] 2021-07-12 18:55:07,174 [run_pretraining.py:  535]:	loss/mlm_loss, 7.998437881469727, 1190
[INFO] 2021-07-12 18:55:07,174 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1889999768754933e-05, 1190
[INFO] 2021-07-12 18:55:07,174 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1190
[INFO] 2021-07-12 18:55:07,175 [run_pretraining.py:  558]:	worker_index: 6, step: 1190, cost: 7.998438, mlm loss: 7.998438, speed: 1.085598 steps/s, speed: 8.684783 samples/s, speed: 4446.608887 tokens/s, learning rate: 1.189e-05, loss_scalings: 13421.773438, pp_loss: 7.917225
[INFO] 2021-07-12 18:55:07,175 [run_pretraining.py:  512]:	********exe.run_1190******* 
[INFO] 2021-07-12 18:55:08,093 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:08,094 [run_pretraining.py:  534]:	loss/total_loss, 7.6110076904296875, 1191
[INFO] 2021-07-12 18:55:08,094 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6110076904296875, 1191
[INFO] 2021-07-12 18:55:08,094 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1899999663000926e-05, 1191
[INFO] 2021-07-12 18:55:08,094 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1191
[INFO] 2021-07-12 18:55:08,094 [run_pretraining.py:  558]:	worker_index: 6, step: 1191, cost: 7.611008, mlm loss: 7.611008, speed: 1.088277 steps/s, speed: 8.706213 samples/s, speed: 4457.580964 tokens/s, learning rate: 1.190e-05, loss_scalings: 13421.773438, pp_loss: 7.517579
[INFO] 2021-07-12 18:55:08,094 [run_pretraining.py:  512]:	********exe.run_1191******* 
[INFO] 2021-07-12 18:55:09,009 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:09,009 [run_pretraining.py:  534]:	loss/total_loss, 7.836137771606445, 1192
[INFO] 2021-07-12 18:55:09,009 [run_pretraining.py:  535]:	loss/mlm_loss, 7.836137771606445, 1192
[INFO] 2021-07-12 18:55:09,009 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.190999955724692e-05, 1192
[INFO] 2021-07-12 18:55:09,009 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1192
[INFO] 2021-07-12 18:55:09,010 [run_pretraining.py:  558]:	worker_index: 6, step: 1192, cost: 7.836138, mlm loss: 7.836138, speed: 1.093174 steps/s, speed: 8.745394 samples/s, speed: 4477.641642 tokens/s, learning rate: 1.191e-05, loss_scalings: 13421.773438, pp_loss: 7.956988
[INFO] 2021-07-12 18:55:09,010 [run_pretraining.py:  512]:	********exe.run_1192******* 
[INFO] 2021-07-12 18:55:09,945 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:09,945 [run_pretraining.py:  534]:	loss/total_loss, 7.269143104553223, 1193
[INFO] 2021-07-12 18:55:09,945 [run_pretraining.py:  535]:	loss/mlm_loss, 7.269143104553223, 1193
[INFO] 2021-07-12 18:55:09,945 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1919999451492913e-05, 1193
[INFO] 2021-07-12 18:55:09,945 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1193
[INFO] 2021-07-12 18:55:09,946 [run_pretraining.py:  558]:	worker_index: 6, step: 1193, cost: 7.269143, mlm loss: 7.269143, speed: 1.069171 steps/s, speed: 8.553365 samples/s, speed: 4379.322909 tokens/s, learning rate: 1.192e-05, loss_scalings: 13421.773438, pp_loss: 7.615446
[INFO] 2021-07-12 18:55:09,946 [run_pretraining.py:  512]:	********exe.run_1193******* 
[INFO] 2021-07-12 18:55:10,852 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:10,852 [run_pretraining.py:  534]:	loss/total_loss, 7.693558216094971, 1194
[INFO] 2021-07-12 18:55:10,853 [run_pretraining.py:  535]:	loss/mlm_loss, 7.693558216094971, 1194
[INFO] 2021-07-12 18:55:10,853 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1929999345738906e-05, 1194
[INFO] 2021-07-12 18:55:10,853 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1194
[INFO] 2021-07-12 18:55:10,853 [run_pretraining.py:  558]:	worker_index: 6, step: 1194, cost: 7.693558, mlm loss: 7.693558, speed: 1.103052 steps/s, speed: 8.824415 samples/s, speed: 4518.100465 tokens/s, learning rate: 1.193e-05, loss_scalings: 13421.773438, pp_loss: 7.717655
[INFO] 2021-07-12 18:55:10,853 [run_pretraining.py:  512]:	********exe.run_1194******* 
[INFO] 2021-07-12 18:55:11,776 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:11,777 [run_pretraining.py:  534]:	loss/total_loss, 7.700279712677002, 1195
[INFO] 2021-07-12 18:55:11,777 [run_pretraining.py:  535]:	loss/mlm_loss, 7.700279712677002, 1195
[INFO] 2021-07-12 18:55:11,777 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1940000149479602e-05, 1195
[INFO] 2021-07-12 18:55:11,777 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1195
[INFO] 2021-07-12 18:55:11,777 [run_pretraining.py:  558]:	worker_index: 6, step: 1195, cost: 7.700280, mlm loss: 7.700280, speed: 1.082431 steps/s, speed: 8.659447 samples/s, speed: 4433.637054 tokens/s, learning rate: 1.194e-05, loss_scalings: 13421.773438, pp_loss: 7.677609
[INFO] 2021-07-12 18:55:11,777 [run_pretraining.py:  512]:	********exe.run_1195******* 
[INFO] 2021-07-12 18:55:12,698 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:12,698 [run_pretraining.py:  534]:	loss/total_loss, 7.622993469238281, 1196
[INFO] 2021-07-12 18:55:12,698 [run_pretraining.py:  535]:	loss/mlm_loss, 7.622993469238281, 1196
[INFO] 2021-07-12 18:55:12,698 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1949999134230893e-05, 1196
[INFO] 2021-07-12 18:55:12,698 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1196
[INFO] 2021-07-12 18:55:12,699 [run_pretraining.py:  558]:	worker_index: 6, step: 1196, cost: 7.622993, mlm loss: 7.622993, speed: 1.086439 steps/s, speed: 8.691514 samples/s, speed: 4450.055052 tokens/s, learning rate: 1.195e-05, loss_scalings: 13421.773438, pp_loss: 7.770267
[INFO] 2021-07-12 18:55:12,699 [run_pretraining.py:  512]:	********exe.run_1196******* 
[INFO] 2021-07-12 18:55:13,605 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:13,606 [run_pretraining.py:  534]:	loss/total_loss, 8.190987586975098, 1197
[INFO] 2021-07-12 18:55:13,606 [run_pretraining.py:  535]:	loss/mlm_loss, 8.190987586975098, 1197
[INFO] 2021-07-12 18:55:13,606 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1959999937971588e-05, 1197
[INFO] 2021-07-12 18:55:13,606 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1197
[INFO] 2021-07-12 18:55:13,606 [run_pretraining.py:  558]:	worker_index: 6, step: 1197, cost: 8.190988, mlm loss: 8.190988, speed: 1.102793 steps/s, speed: 8.822343 samples/s, speed: 4517.039645 tokens/s, learning rate: 1.196e-05, loss_scalings: 13421.773438, pp_loss: 7.686462
[INFO] 2021-07-12 18:55:13,606 [run_pretraining.py:  512]:	********exe.run_1197******* 
[INFO] 2021-07-12 18:55:14,522 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:14,523 [run_pretraining.py:  534]:	loss/total_loss, 7.997134685516357, 1198
[INFO] 2021-07-12 18:55:14,523 [run_pretraining.py:  535]:	loss/mlm_loss, 7.997134685516357, 1198
[INFO] 2021-07-12 18:55:14,523 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1969999832217582e-05, 1198
[INFO] 2021-07-12 18:55:14,523 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1198
[INFO] 2021-07-12 18:55:14,523 [run_pretraining.py:  558]:	worker_index: 6, step: 1198, cost: 7.997135, mlm loss: 7.997135, speed: 1.091155 steps/s, speed: 8.729243 samples/s, speed: 4469.372258 tokens/s, learning rate: 1.197e-05, loss_scalings: 13421.773438, pp_loss: 7.338004
[INFO] 2021-07-12 18:55:14,523 [run_pretraining.py:  512]:	********exe.run_1198******* 
[INFO] 2021-07-12 18:55:15,473 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:15,473 [run_pretraining.py:  534]:	loss/total_loss, 7.7067670822143555, 1199
[INFO] 2021-07-12 18:55:15,473 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7067670822143555, 1199
[INFO] 2021-07-12 18:55:15,473 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1979999726463575e-05, 1199
[INFO] 2021-07-12 18:55:15,474 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1199
[INFO] 2021-07-12 18:55:15,474 [run_pretraining.py:  558]:	worker_index: 6, step: 1199, cost: 7.706767, mlm loss: 7.706767, speed: 1.052963 steps/s, speed: 8.423707 samples/s, speed: 4312.938231 tokens/s, learning rate: 1.198e-05, loss_scalings: 13421.773438, pp_loss: 7.534636
[INFO] 2021-07-12 18:55:15,474 [run_pretraining.py:  512]:	********exe.run_1199******* 
[INFO] 2021-07-12 18:55:16,399 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:16,400 [run_pretraining.py:  534]:	loss/total_loss, 7.744285583496094, 1200
[INFO] 2021-07-12 18:55:16,400 [run_pretraining.py:  535]:	loss/mlm_loss, 7.744285583496094, 1200
[INFO] 2021-07-12 18:55:16,400 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1989999620709568e-05, 1200
[INFO] 2021-07-12 18:55:16,400 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1200
[INFO] 2021-07-12 18:55:16,400 [run_pretraining.py:  558]:	worker_index: 6, step: 1200, cost: 7.744286, mlm loss: 7.744286, speed: 1.080055 steps/s, speed: 8.640440 samples/s, speed: 4423.905335 tokens/s, learning rate: 1.199e-05, loss_scalings: 13421.773438, pp_loss: 7.765238
[INFO] 2021-07-12 18:55:16,400 [run_pretraining.py:  512]:	********exe.run_1200******* 
[INFO] 2021-07-12 18:55:17,311 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:17,312 [run_pretraining.py:  534]:	loss/total_loss, 7.349765777587891, 1201
[INFO] 2021-07-12 18:55:17,312 [run_pretraining.py:  535]:	loss/mlm_loss, 7.349765777587891, 1201
[INFO] 2021-07-12 18:55:17,312 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1999999514955562e-05, 1201
[INFO] 2021-07-12 18:55:17,312 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1201
[INFO] 2021-07-12 18:55:17,312 [run_pretraining.py:  558]:	worker_index: 6, step: 1201, cost: 7.349766, mlm loss: 7.349766, speed: 1.097208 steps/s, speed: 8.777665 samples/s, speed: 4494.164391 tokens/s, learning rate: 1.200e-05, loss_scalings: 13421.773438, pp_loss: 7.460492
[INFO] 2021-07-12 18:55:17,312 [run_pretraining.py:  512]:	********exe.run_1201******* 
[INFO] 2021-07-12 18:55:18,221 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:18,222 [run_pretraining.py:  534]:	loss/total_loss, 7.473570823669434, 1202
[INFO] 2021-07-12 18:55:18,222 [run_pretraining.py:  535]:	loss/mlm_loss, 7.473570823669434, 1202
[INFO] 2021-07-12 18:55:18,222 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2009999409201555e-05, 1202
[INFO] 2021-07-12 18:55:18,222 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1202
[INFO] 2021-07-12 18:55:18,222 [run_pretraining.py:  558]:	worker_index: 6, step: 1202, cost: 7.473571, mlm loss: 7.473571, speed: 1.100244 steps/s, speed: 8.801952 samples/s, speed: 4506.599460 tokens/s, learning rate: 1.201e-05, loss_scalings: 13421.773438, pp_loss: 7.584271
[INFO] 2021-07-12 18:55:18,222 [run_pretraining.py:  512]:	********exe.run_1202******* 
[INFO] 2021-07-12 18:55:19,131 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:19,131 [run_pretraining.py:  534]:	loss/total_loss, 7.320557594299316, 1203
[INFO] 2021-07-12 18:55:19,131 [run_pretraining.py:  535]:	loss/mlm_loss, 7.320557594299316, 1203
[INFO] 2021-07-12 18:55:19,131 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.202000021294225e-05, 1203
[INFO] 2021-07-12 18:55:19,132 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1203
[INFO] 2021-07-12 18:55:19,132 [run_pretraining.py:  558]:	worker_index: 6, step: 1203, cost: 7.320558, mlm loss: 7.320558, speed: 1.100140 steps/s, speed: 8.801121 samples/s, speed: 4506.173921 tokens/s, learning rate: 1.202e-05, loss_scalings: 13421.773438, pp_loss: 7.761604
[INFO] 2021-07-12 18:55:19,132 [run_pretraining.py:  512]:	********exe.run_1203******* 
[INFO] 2021-07-12 18:55:20,045 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:20,046 [run_pretraining.py:  534]:	loss/total_loss, 7.872169494628906, 1204
[INFO] 2021-07-12 18:55:20,046 [run_pretraining.py:  535]:	loss/mlm_loss, 7.872169494628906, 1204
[INFO] 2021-07-12 18:55:20,046 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2030000107188243e-05, 1204
[INFO] 2021-07-12 18:55:20,046 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1204
[INFO] 2021-07-12 18:55:20,046 [run_pretraining.py:  558]:	worker_index: 6, step: 1204, cost: 7.872169, mlm loss: 7.872169, speed: 1.094452 steps/s, speed: 8.755615 samples/s, speed: 4482.874840 tokens/s, learning rate: 1.203e-05, loss_scalings: 13421.773438, pp_loss: 7.879632
[INFO] 2021-07-12 18:55:20,046 [run_pretraining.py:  512]:	********exe.run_1204******* 
[INFO] 2021-07-12 18:55:20,956 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:20,956 [run_pretraining.py:  534]:	loss/total_loss, 7.519387245178223, 1205
[INFO] 2021-07-12 18:55:20,956 [run_pretraining.py:  535]:	loss/mlm_loss, 7.519387245178223, 1205
[INFO] 2021-07-12 18:55:20,956 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2039999091939535e-05, 1205
[INFO] 2021-07-12 18:55:20,956 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1205
[INFO] 2021-07-12 18:55:20,957 [run_pretraining.py:  558]:	worker_index: 6, step: 1205, cost: 7.519387, mlm loss: 7.519387, speed: 1.099086 steps/s, speed: 8.792685 samples/s, speed: 4501.854522 tokens/s, learning rate: 1.204e-05, loss_scalings: 13421.773438, pp_loss: 7.755552
[INFO] 2021-07-12 18:55:20,957 [run_pretraining.py:  512]:	********exe.run_1205******* 
[INFO] 2021-07-12 18:55:21,870 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:21,871 [run_pretraining.py:  534]:	loss/total_loss, 8.158397674560547, 1206
[INFO] 2021-07-12 18:55:21,871 [run_pretraining.py:  535]:	loss/mlm_loss, 8.158397674560547, 1206
[INFO] 2021-07-12 18:55:21,871 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.204999989568023e-05, 1206
[INFO] 2021-07-12 18:55:21,871 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1206
[INFO] 2021-07-12 18:55:21,871 [run_pretraining.py:  558]:	worker_index: 6, step: 1206, cost: 8.158398, mlm loss: 8.158398, speed: 1.094309 steps/s, speed: 8.754468 samples/s, speed: 4482.287702 tokens/s, learning rate: 1.205e-05, loss_scalings: 13421.773438, pp_loss: 7.894046
[INFO] 2021-07-12 18:55:21,871 [run_pretraining.py:  512]:	********exe.run_1206******* 
[INFO] 2021-07-12 18:55:22,773 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:22,773 [run_pretraining.py:  534]:	loss/total_loss, 7.513128757476807, 1207
[INFO] 2021-07-12 18:55:22,773 [run_pretraining.py:  535]:	loss/mlm_loss, 7.513128757476807, 1207
[INFO] 2021-07-12 18:55:22,773 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2059999789926223e-05, 1207
[INFO] 2021-07-12 18:55:22,774 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1207
[INFO] 2021-07-12 18:55:22,774 [run_pretraining.py:  558]:	worker_index: 6, step: 1207, cost: 7.513129, mlm loss: 7.513129, speed: 1.108905 steps/s, speed: 8.871241 samples/s, speed: 4542.075507 tokens/s, learning rate: 1.206e-05, loss_scalings: 13421.773438, pp_loss: 7.542489
[INFO] 2021-07-12 18:55:22,774 [run_pretraining.py:  512]:	********exe.run_1207******* 
[INFO] 2021-07-12 18:55:23,687 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:23,688 [run_pretraining.py:  534]:	loss/total_loss, 7.159634590148926, 1208
[INFO] 2021-07-12 18:55:23,688 [run_pretraining.py:  535]:	loss/mlm_loss, 7.159634590148926, 1208
[INFO] 2021-07-12 18:55:23,688 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2069999684172217e-05, 1208
[INFO] 2021-07-12 18:55:23,688 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1208
[INFO] 2021-07-12 18:55:23,688 [run_pretraining.py:  558]:	worker_index: 6, step: 1208, cost: 7.159635, mlm loss: 7.159635, speed: 1.094416 steps/s, speed: 8.755329 samples/s, speed: 4482.728626 tokens/s, learning rate: 1.207e-05, loss_scalings: 13421.773438, pp_loss: 6.624208
[INFO] 2021-07-12 18:55:23,688 [run_pretraining.py:  512]:	********exe.run_1208******* 
[INFO] 2021-07-12 18:55:24,599 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:24,599 [run_pretraining.py:  534]:	loss/total_loss, 7.285192012786865, 1209
[INFO] 2021-07-12 18:55:24,599 [run_pretraining.py:  535]:	loss/mlm_loss, 7.285192012786865, 1209
[INFO] 2021-07-12 18:55:24,599 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2080000487912912e-05, 1209
[INFO] 2021-07-12 18:55:24,599 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1209
[INFO] 2021-07-12 18:55:24,600 [run_pretraining.py:  558]:	worker_index: 6, step: 1209, cost: 7.285192, mlm loss: 7.285192, speed: 1.098006 steps/s, speed: 8.784051 samples/s, speed: 4497.433900 tokens/s, learning rate: 1.208e-05, loss_scalings: 13421.773438, pp_loss: 7.603383
[INFO] 2021-07-12 18:55:24,600 [run_pretraining.py:  512]:	********exe.run_1209******* 
[INFO] 2021-07-12 18:55:25,500 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:25,501 [run_pretraining.py:  534]:	loss/total_loss, 7.5143585205078125, 1210
[INFO] 2021-07-12 18:55:25,501 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5143585205078125, 1210
[INFO] 2021-07-12 18:55:25,501 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2089999472664203e-05, 1210
[INFO] 2021-07-12 18:55:25,501 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1210
[INFO] 2021-07-12 18:55:25,501 [run_pretraining.py:  558]:	worker_index: 6, step: 1210, cost: 7.514359, mlm loss: 7.514359, speed: 1.109691 steps/s, speed: 8.877529 samples/s, speed: 4545.294865 tokens/s, learning rate: 1.209e-05, loss_scalings: 13421.773438, pp_loss: 7.214633
[INFO] 2021-07-12 18:55:25,501 [run_pretraining.py:  512]:	********exe.run_1210******* 
[INFO] 2021-07-12 18:55:26,439 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:26,440 [run_pretraining.py:  534]:	loss/total_loss, 7.3218584060668945, 1211
[INFO] 2021-07-12 18:55:26,440 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3218584060668945, 1211
[INFO] 2021-07-12 18:55:26,440 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2099999366910197e-05, 1211
[INFO] 2021-07-12 18:55:26,440 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1211
[INFO] 2021-07-12 18:55:26,440 [run_pretraining.py:  558]:	worker_index: 6, step: 1211, cost: 7.321858, mlm loss: 7.321858, speed: 1.065694 steps/s, speed: 8.525552 samples/s, speed: 4365.082525 tokens/s, learning rate: 1.210e-05, loss_scalings: 13421.773438, pp_loss: 7.320732
[INFO] 2021-07-12 18:55:26,441 [run_pretraining.py:  512]:	********exe.run_1211******* 
[INFO] 2021-07-12 18:55:27,349 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:27,350 [run_pretraining.py:  534]:	loss/total_loss, 8.275382995605469, 1212
[INFO] 2021-07-12 18:55:27,350 [run_pretraining.py:  535]:	loss/mlm_loss, 8.275382995605469, 1212
[INFO] 2021-07-12 18:55:27,350 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2110000170650892e-05, 1212
[INFO] 2021-07-12 18:55:27,350 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1212
[INFO] 2021-07-12 18:55:27,350 [run_pretraining.py:  558]:	worker_index: 6, step: 1212, cost: 8.275383, mlm loss: 8.275383, speed: 1.099845 steps/s, speed: 8.798760 samples/s, speed: 4504.965119 tokens/s, learning rate: 1.211e-05, loss_scalings: 13421.773438, pp_loss: 7.880660
[INFO] 2021-07-12 18:55:27,350 [run_pretraining.py:  512]:	********exe.run_1212******* 
[INFO] 2021-07-12 18:55:28,264 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:28,265 [run_pretraining.py:  534]:	loss/total_loss, 7.950695514678955, 1213
[INFO] 2021-07-12 18:55:28,265 [run_pretraining.py:  535]:	loss/mlm_loss, 7.950695514678955, 1213
[INFO] 2021-07-12 18:55:28,265 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2120000064896885e-05, 1213
[INFO] 2021-07-12 18:55:28,265 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1213
[INFO] 2021-07-12 18:55:28,265 [run_pretraining.py:  558]:	worker_index: 6, step: 1213, cost: 7.950696, mlm loss: 7.950696, speed: 1.094119 steps/s, speed: 8.752950 samples/s, speed: 4481.510156 tokens/s, learning rate: 1.212e-05, loss_scalings: 13421.773438, pp_loss: 7.789681
[INFO] 2021-07-12 18:55:28,265 [run_pretraining.py:  512]:	********exe.run_1213******* 
[INFO] 2021-07-12 18:55:29,172 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:29,173 [run_pretraining.py:  534]:	loss/total_loss, 7.587947368621826, 1214
[INFO] 2021-07-12 18:55:29,173 [run_pretraining.py:  535]:	loss/mlm_loss, 7.587947368621826, 1214
[INFO] 2021-07-12 18:55:29,173 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2129999049648177e-05, 1214
[INFO] 2021-07-12 18:55:29,173 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1214
[INFO] 2021-07-12 18:55:29,173 [run_pretraining.py:  558]:	worker_index: 6, step: 1214, cost: 7.587947, mlm loss: 7.587947, speed: 1.102391 steps/s, speed: 8.819132 samples/s, speed: 4515.395351 tokens/s, learning rate: 1.213e-05, loss_scalings: 13421.773438, pp_loss: 7.051038
[INFO] 2021-07-12 18:55:29,173 [run_pretraining.py:  512]:	********exe.run_1214******* 
[INFO] 2021-07-12 18:55:30,082 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:30,082 [run_pretraining.py:  534]:	loss/total_loss, 7.518595218658447, 1215
[INFO] 2021-07-12 18:55:30,082 [run_pretraining.py:  535]:	loss/mlm_loss, 7.518595218658447, 1215
[INFO] 2021-07-12 18:55:30,082 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2139999853388872e-05, 1215
[INFO] 2021-07-12 18:55:30,082 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1215
[INFO] 2021-07-12 18:55:30,083 [run_pretraining.py:  558]:	worker_index: 6, step: 1215, cost: 7.518595, mlm loss: 7.518595, speed: 1.100211 steps/s, speed: 8.801684 samples/s, speed: 4506.462333 tokens/s, learning rate: 1.214e-05, loss_scalings: 13421.773438, pp_loss: 7.476618
[INFO] 2021-07-12 18:55:30,083 [run_pretraining.py:  512]:	********exe.run_1215******* 
[INFO] 2021-07-12 18:55:31,000 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:31,000 [run_pretraining.py:  534]:	loss/total_loss, 7.6061272621154785, 1216
[INFO] 2021-07-12 18:55:31,000 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6061272621154785, 1216
[INFO] 2021-07-12 18:55:31,001 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2149999747634865e-05, 1216
[INFO] 2021-07-12 18:55:31,001 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1216
[INFO] 2021-07-12 18:55:31,001 [run_pretraining.py:  558]:	worker_index: 6, step: 1216, cost: 7.606127, mlm loss: 7.606127, speed: 1.089923 steps/s, speed: 8.719382 samples/s, speed: 4464.323646 tokens/s, learning rate: 1.215e-05, loss_scalings: 13421.773438, pp_loss: 7.204611
[INFO] 2021-07-12 18:55:31,001 [run_pretraining.py:  512]:	********exe.run_1216******* 
[INFO] 2021-07-12 18:55:31,909 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:31,910 [run_pretraining.py:  534]:	loss/total_loss, 7.906073570251465, 1217
[INFO] 2021-07-12 18:55:31,910 [run_pretraining.py:  535]:	loss/mlm_loss, 7.906073570251465, 1217
[INFO] 2021-07-12 18:55:31,910 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2159999641880859e-05, 1217
[INFO] 2021-07-12 18:55:31,910 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1217
[INFO] 2021-07-12 18:55:31,910 [run_pretraining.py:  558]:	worker_index: 6, step: 1217, cost: 7.906074, mlm loss: 7.906074, speed: 1.100092 steps/s, speed: 8.800735 samples/s, speed: 4505.976545 tokens/s, learning rate: 1.216e-05, loss_scalings: 13421.773438, pp_loss: 7.687418
[INFO] 2021-07-12 18:55:31,911 [run_pretraining.py:  512]:	********exe.run_1217******* 
[INFO] 2021-07-12 18:55:32,815 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:32,815 [run_pretraining.py:  534]:	loss/total_loss, 5.876504898071289, 1218
[INFO] 2021-07-12 18:55:32,815 [run_pretraining.py:  535]:	loss/mlm_loss, 5.876504898071289, 1218
[INFO] 2021-07-12 18:55:32,815 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2169999536126852e-05, 1218
[INFO] 2021-07-12 18:55:32,815 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1218
[INFO] 2021-07-12 18:55:32,816 [run_pretraining.py:  558]:	worker_index: 6, step: 1218, cost: 5.876505, mlm loss: 5.876505, speed: 1.105718 steps/s, speed: 8.845743 samples/s, speed: 4529.020270 tokens/s, learning rate: 1.217e-05, loss_scalings: 13421.773438, pp_loss: 7.210026
[INFO] 2021-07-12 18:55:32,816 [run_pretraining.py:  512]:	********exe.run_1218******* 
[INFO] 2021-07-12 18:55:33,721 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:33,722 [run_pretraining.py:  534]:	loss/total_loss, 7.729928970336914, 1219
[INFO] 2021-07-12 18:55:33,722 [run_pretraining.py:  535]:	loss/mlm_loss, 7.729928970336914, 1219
[INFO] 2021-07-12 18:55:33,722 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2179999430372845e-05, 1219
[INFO] 2021-07-12 18:55:33,722 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1219
[INFO] 2021-07-12 18:55:33,722 [run_pretraining.py:  558]:	worker_index: 6, step: 1219, cost: 7.729929, mlm loss: 7.729929, speed: 1.103612 steps/s, speed: 8.828894 samples/s, speed: 4520.393678 tokens/s, learning rate: 1.218e-05, loss_scalings: 13421.773438, pp_loss: 7.885624
[INFO] 2021-07-12 18:55:33,722 [run_pretraining.py:  512]:	********exe.run_1219******* 
[INFO] 2021-07-12 18:55:34,673 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:34,674 [run_pretraining.py:  534]:	loss/total_loss, 8.437559127807617, 1220
[INFO] 2021-07-12 18:55:34,674 [run_pretraining.py:  535]:	loss/mlm_loss, 8.437559127807617, 1220
[INFO] 2021-07-12 18:55:34,674 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2189999324618839e-05, 1220
[INFO] 2021-07-12 18:55:34,674 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1220
[INFO] 2021-07-12 18:55:34,674 [run_pretraining.py:  558]:	worker_index: 6, step: 1220, cost: 8.437559, mlm loss: 8.437559, speed: 1.051443 steps/s, speed: 8.411542 samples/s, speed: 4306.709540 tokens/s, learning rate: 1.219e-05, loss_scalings: 13421.773438, pp_loss: 7.796478
[INFO] 2021-07-12 18:55:34,674 [run_pretraining.py:  512]:	********exe.run_1220******* 
[INFO] 2021-07-12 18:55:35,577 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:35,578 [run_pretraining.py:  534]:	loss/total_loss, 7.839776992797852, 1221
[INFO] 2021-07-12 18:55:35,578 [run_pretraining.py:  535]:	loss/mlm_loss, 7.839776992797852, 1221
[INFO] 2021-07-12 18:55:35,578 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2200000128359534e-05, 1221
[INFO] 2021-07-12 18:55:35,578 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1221
[INFO] 2021-07-12 18:55:35,578 [run_pretraining.py:  558]:	worker_index: 6, step: 1221, cost: 7.839777, mlm loss: 7.839777, speed: 1.106726 steps/s, speed: 8.853812 samples/s, speed: 4533.151544 tokens/s, learning rate: 1.220e-05, loss_scalings: 13421.773438, pp_loss: 7.541507
[INFO] 2021-07-12 18:55:35,579 [run_pretraining.py:  512]:	********exe.run_1221******* 
[INFO] 2021-07-12 18:55:36,478 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:36,478 [run_pretraining.py:  534]:	loss/total_loss, 7.590372085571289, 1222
[INFO] 2021-07-12 18:55:36,478 [run_pretraining.py:  535]:	loss/mlm_loss, 7.590372085571289, 1222
[INFO] 2021-07-12 18:55:36,478 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2210000022605527e-05, 1222
[INFO] 2021-07-12 18:55:36,478 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1222
[INFO] 2021-07-12 18:55:36,478 [run_pretraining.py:  558]:	worker_index: 6, step: 1222, cost: 7.590372, mlm loss: 7.590372, speed: 1.111954 steps/s, speed: 8.895632 samples/s, speed: 4554.563767 tokens/s, learning rate: 1.221e-05, loss_scalings: 13421.773438, pp_loss: 7.560781
[INFO] 2021-07-12 18:55:36,479 [run_pretraining.py:  512]:	********exe.run_1222******* 
[INFO] 2021-07-12 18:55:37,382 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:37,383 [run_pretraining.py:  534]:	loss/total_loss, 7.201037406921387, 1223
[INFO] 2021-07-12 18:55:37,383 [run_pretraining.py:  535]:	loss/mlm_loss, 7.201037406921387, 1223
[INFO] 2021-07-12 18:55:37,383 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2219999007356819e-05, 1223
[INFO] 2021-07-12 18:55:37,383 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1223
[INFO] 2021-07-12 18:55:37,383 [run_pretraining.py:  558]:	worker_index: 6, step: 1223, cost: 7.201037, mlm loss: 7.201037, speed: 1.105888 steps/s, speed: 8.847102 samples/s, speed: 4529.716454 tokens/s, learning rate: 1.222e-05, loss_scalings: 13421.773438, pp_loss: 7.432773
[INFO] 2021-07-12 18:55:37,384 [run_pretraining.py:  512]:	********exe.run_1223******* 
[INFO] 2021-07-12 18:55:38,390 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:38,390 [run_pretraining.py:  534]:	loss/total_loss, 7.7823405265808105, 1224
[INFO] 2021-07-12 18:55:38,390 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7823405265808105, 1224
[INFO] 2021-07-12 18:55:38,390 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2229999811097514e-05, 1224
[INFO] 2021-07-12 18:55:38,390 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1224
[INFO] 2021-07-12 18:55:38,391 [run_pretraining.py:  558]:	worker_index: 6, step: 1224, cost: 7.782341, mlm loss: 7.782341, speed: 0.993658 steps/s, speed: 7.949266 samples/s, speed: 4070.024182 tokens/s, learning rate: 1.223e-05, loss_scalings: 13421.773438, pp_loss: 7.818932
[INFO] 2021-07-12 18:55:38,391 [run_pretraining.py:  512]:	********exe.run_1224******* 
[INFO] 2021-07-12 18:55:39,450 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:39,451 [run_pretraining.py:  534]:	loss/total_loss, 6.330010890960693, 1225
[INFO] 2021-07-12 18:55:39,451 [run_pretraining.py:  535]:	loss/mlm_loss, 6.330010890960693, 1225
[INFO] 2021-07-12 18:55:39,451 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2239999705343507e-05, 1225
[INFO] 2021-07-12 18:55:39,451 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1225
[INFO] 2021-07-12 18:55:39,451 [run_pretraining.py:  558]:	worker_index: 6, step: 1225, cost: 6.330011, mlm loss: 6.330011, speed: 0.943636 steps/s, speed: 7.549089 samples/s, speed: 3865.133527 tokens/s, learning rate: 1.224e-05, loss_scalings: 13421.773438, pp_loss: 7.264530
[INFO] 2021-07-12 18:55:39,451 [run_pretraining.py:  512]:	********exe.run_1225******* 
[INFO] 2021-07-12 18:55:40,474 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:40,475 [run_pretraining.py:  534]:	loss/total_loss, 7.44720983505249, 1226
[INFO] 2021-07-12 18:55:40,475 [run_pretraining.py:  535]:	loss/mlm_loss, 7.44720983505249, 1226
[INFO] 2021-07-12 18:55:40,475 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.22499995995895e-05, 1226
[INFO] 2021-07-12 18:55:40,475 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1226
[INFO] 2021-07-12 18:55:40,476 [run_pretraining.py:  558]:	worker_index: 6, step: 1226, cost: 7.447210, mlm loss: 7.447210, speed: 0.976760 steps/s, speed: 7.814082 samples/s, speed: 4000.809759 tokens/s, learning rate: 1.225e-05, loss_scalings: 13421.773438, pp_loss: 7.506402
[INFO] 2021-07-12 18:55:40,476 [run_pretraining.py:  512]:	********exe.run_1226******* 
[INFO] 2021-07-12 18:55:41,528 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:41,529 [run_pretraining.py:  534]:	loss/total_loss, 7.483766078948975, 1227
[INFO] 2021-07-12 18:55:41,529 [run_pretraining.py:  535]:	loss/mlm_loss, 7.483766078948975, 1227
[INFO] 2021-07-12 18:55:41,529 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2259999493835494e-05, 1227
[INFO] 2021-07-12 18:55:41,529 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1227
[INFO] 2021-07-12 18:55:41,529 [run_pretraining.py:  558]:	worker_index: 6, step: 1227, cost: 7.483766, mlm loss: 7.483766, speed: 0.949669 steps/s, speed: 7.597351 samples/s, speed: 3889.843940 tokens/s, learning rate: 1.226e-05, loss_scalings: 13421.773438, pp_loss: 7.663538
[INFO] 2021-07-12 18:55:41,529 [run_pretraining.py:  512]:	********exe.run_1227******* 
[INFO] 2021-07-12 18:55:42,596 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:42,596 [run_pretraining.py:  534]:	loss/total_loss, 7.390167236328125, 1228
[INFO] 2021-07-12 18:55:42,597 [run_pretraining.py:  535]:	loss/mlm_loss, 7.390167236328125, 1228
[INFO] 2021-07-12 18:55:42,597 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2269999388081487e-05, 1228
[INFO] 2021-07-12 18:55:42,597 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1228
[INFO] 2021-07-12 18:55:42,597 [run_pretraining.py:  558]:	worker_index: 6, step: 1228, cost: 7.390167, mlm loss: 7.390167, speed: 0.937330 steps/s, speed: 7.498639 samples/s, speed: 3839.303410 tokens/s, learning rate: 1.227e-05, loss_scalings: 13421.773438, pp_loss: 7.556188
[INFO] 2021-07-12 18:55:42,597 [run_pretraining.py:  512]:	********exe.run_1228******* 
[INFO] 2021-07-12 18:55:43,652 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:43,652 [run_pretraining.py:  534]:	loss/total_loss, 7.217598915100098, 1229
[INFO] 2021-07-12 18:55:43,652 [run_pretraining.py:  535]:	loss/mlm_loss, 7.217598915100098, 1229
[INFO] 2021-07-12 18:55:43,653 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.227999928232748e-05, 1229
[INFO] 2021-07-12 18:55:43,653 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1229
[INFO] 2021-07-12 18:55:43,653 [run_pretraining.py:  558]:	worker_index: 6, step: 1229, cost: 7.217599, mlm loss: 7.217599, speed: 0.947708 steps/s, speed: 7.581667 samples/s, speed: 3881.813291 tokens/s, learning rate: 1.228e-05, loss_scalings: 10737.418945, pp_loss: 7.465565
[INFO] 2021-07-12 18:55:43,653 [run_pretraining.py:  512]:	********exe.run_1229******* 
[INFO] 2021-07-12 18:55:44,709 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:44,710 [run_pretraining.py:  534]:	loss/total_loss, 5.880753993988037, 1230
[INFO] 2021-07-12 18:55:44,710 [run_pretraining.py:  535]:	loss/mlm_loss, 5.880753993988037, 1230
[INFO] 2021-07-12 18:55:44,710 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2290000086068176e-05, 1230
[INFO] 2021-07-12 18:55:44,710 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1230
[INFO] 2021-07-12 18:55:44,710 [run_pretraining.py:  558]:	worker_index: 6, step: 1230, cost: 5.880754, mlm loss: 5.880754, speed: 0.946020 steps/s, speed: 7.568161 samples/s, speed: 3874.898291 tokens/s, learning rate: 1.229e-05, loss_scalings: 10737.418945, pp_loss: 7.014770
[INFO] 2021-07-12 18:55:44,711 [run_pretraining.py:  512]:	********exe.run_1230******* 
[INFO] 2021-07-12 18:55:45,771 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:45,772 [run_pretraining.py:  534]:	loss/total_loss, 7.608808994293213, 1231
[INFO] 2021-07-12 18:55:45,772 [run_pretraining.py:  535]:	loss/mlm_loss, 7.608808994293213, 1231
[INFO] 2021-07-12 18:55:45,772 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2299999980314169e-05, 1231
[INFO] 2021-07-12 18:55:45,772 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1231
[INFO] 2021-07-12 18:55:45,772 [run_pretraining.py:  558]:	worker_index: 6, step: 1231, cost: 7.608809, mlm loss: 7.608809, speed: 0.942237 steps/s, speed: 7.537894 samples/s, speed: 3859.401946 tokens/s, learning rate: 1.230e-05, loss_scalings: 10737.418945, pp_loss: 7.696776
[INFO] 2021-07-12 18:55:45,773 [run_pretraining.py:  512]:	********exe.run_1231******* 
[INFO] 2021-07-12 18:55:46,823 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:46,823 [run_pretraining.py:  534]:	loss/total_loss, 8.200940132141113, 1232
[INFO] 2021-07-12 18:55:46,824 [run_pretraining.py:  535]:	loss/mlm_loss, 8.200940132141113, 1232
[INFO] 2021-07-12 18:55:46,824 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2309999874560162e-05, 1232
[INFO] 2021-07-12 18:55:46,824 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1232
[INFO] 2021-07-12 18:55:46,824 [run_pretraining.py:  558]:	worker_index: 6, step: 1232, cost: 8.200940, mlm loss: 8.200940, speed: 0.951880 steps/s, speed: 7.615042 samples/s, speed: 3898.901306 tokens/s, learning rate: 1.231e-05, loss_scalings: 10737.418945, pp_loss: 7.807531
[INFO] 2021-07-12 18:55:46,824 [run_pretraining.py:  512]:	********exe.run_1232******* 
[INFO] 2021-07-12 18:55:47,851 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:47,851 [run_pretraining.py:  534]:	loss/total_loss, 7.762229919433594, 1233
[INFO] 2021-07-12 18:55:47,852 [run_pretraining.py:  535]:	loss/mlm_loss, 7.762229919433594, 1233
[INFO] 2021-07-12 18:55:47,852 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2319999768806156e-05, 1233
[INFO] 2021-07-12 18:55:47,852 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1233
[INFO] 2021-07-12 18:55:47,852 [run_pretraining.py:  558]:	worker_index: 6, step: 1233, cost: 7.762230, mlm loss: 7.762230, speed: 0.973396 steps/s, speed: 7.787172 samples/s, speed: 3987.031879 tokens/s, learning rate: 1.232e-05, loss_scalings: 10737.418945, pp_loss: 7.641024
[INFO] 2021-07-12 18:55:47,852 [run_pretraining.py:  512]:	********exe.run_1233******* 
[INFO] 2021-07-12 18:55:48,908 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:48,909 [run_pretraining.py:  534]:	loss/total_loss, 8.075323104858398, 1234
[INFO] 2021-07-12 18:55:48,909 [run_pretraining.py:  535]:	loss/mlm_loss, 8.075323104858398, 1234
[INFO] 2021-07-12 18:55:48,909 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2329999663052149e-05, 1234
[INFO] 2021-07-12 18:55:48,910 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1234
[INFO] 2021-07-12 18:55:48,910 [run_pretraining.py:  558]:	worker_index: 6, step: 1234, cost: 8.075323, mlm loss: 8.075323, speed: 0.946018 steps/s, speed: 7.568140 samples/s, speed: 3874.887803 tokens/s, learning rate: 1.233e-05, loss_scalings: 10737.418945, pp_loss: 7.507677
[INFO] 2021-07-12 18:55:48,910 [run_pretraining.py:  512]:	********exe.run_1234******* 
[INFO] 2021-07-12 18:55:49,962 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:49,963 [run_pretraining.py:  534]:	loss/total_loss, 7.425919532775879, 1235
[INFO] 2021-07-12 18:55:49,963 [run_pretraining.py:  535]:	loss/mlm_loss, 7.425919532775879, 1235
[INFO] 2021-07-12 18:55:49,963 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2339999557298142e-05, 1235
[INFO] 2021-07-12 18:55:49,963 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1235
[INFO] 2021-07-12 18:55:49,963 [run_pretraining.py:  558]:	worker_index: 6, step: 1235, cost: 7.425920, mlm loss: 7.425920, speed: 0.949841 steps/s, speed: 7.598730 samples/s, speed: 3890.549535 tokens/s, learning rate: 1.234e-05, loss_scalings: 10737.418945, pp_loss: 6.614260
[INFO] 2021-07-12 18:55:49,963 [run_pretraining.py:  512]:	********exe.run_1235******* 
[INFO] 2021-07-12 18:55:50,883 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:50,884 [run_pretraining.py:  534]:	loss/total_loss, 7.871358871459961, 1236
[INFO] 2021-07-12 18:55:50,884 [run_pretraining.py:  535]:	loss/mlm_loss, 7.871358871459961, 1236
[INFO] 2021-07-12 18:55:50,884 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2349999451544136e-05, 1236
[INFO] 2021-07-12 18:55:50,884 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1236
[INFO] 2021-07-12 18:55:50,884 [run_pretraining.py:  558]:	worker_index: 6, step: 1236, cost: 7.871359, mlm loss: 7.871359, speed: 1.086774 steps/s, speed: 8.694196 samples/s, speed: 4451.428324 tokens/s, learning rate: 1.235e-05, loss_scalings: 10737.418945, pp_loss: 7.765250
[INFO] 2021-07-12 18:55:50,884 [run_pretraining.py:  512]:	********exe.run_1236******* 
[INFO] 2021-07-12 18:55:51,857 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:51,858 [run_pretraining.py:  534]:	loss/total_loss, 7.940146446228027, 1237
[INFO] 2021-07-12 18:55:51,858 [run_pretraining.py:  535]:	loss/mlm_loss, 7.940146446228027, 1237
[INFO] 2021-07-12 18:55:51,858 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.235999934579013e-05, 1237
[INFO] 2021-07-12 18:55:51,858 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1237
[INFO] 2021-07-12 18:55:51,858 [run_pretraining.py:  558]:	worker_index: 6, step: 1237, cost: 7.940146, mlm loss: 7.940146, speed: 1.027405 steps/s, speed: 8.219242 samples/s, speed: 4208.252054 tokens/s, learning rate: 1.236e-05, loss_scalings: 10737.418945, pp_loss: 8.065564
[INFO] 2021-07-12 18:55:51,858 [run_pretraining.py:  512]:	********exe.run_1237******* 
[INFO] 2021-07-12 18:55:52,809 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:52,810 [run_pretraining.py:  534]:	loss/total_loss, 7.835524559020996, 1238
[INFO] 2021-07-12 18:55:52,810 [run_pretraining.py:  535]:	loss/mlm_loss, 7.835524559020996, 1238
[INFO] 2021-07-12 18:55:52,810 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2370000149530824e-05, 1238
[INFO] 2021-07-12 18:55:52,810 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1238
[INFO] 2021-07-12 18:55:52,810 [run_pretraining.py:  558]:	worker_index: 6, step: 1238, cost: 7.835525, mlm loss: 7.835525, speed: 1.051284 steps/s, speed: 8.410269 samples/s, speed: 4306.057547 tokens/s, learning rate: 1.237e-05, loss_scalings: 10737.418945, pp_loss: 7.473222
[INFO] 2021-07-12 18:55:52,810 [run_pretraining.py:  512]:	********exe.run_1238******* 
[INFO] 2021-07-12 18:55:53,717 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:53,717 [run_pretraining.py:  534]:	loss/total_loss, 7.929866790771484, 1239
[INFO] 2021-07-12 18:55:53,717 [run_pretraining.py:  535]:	loss/mlm_loss, 7.929866790771484, 1239
[INFO] 2021-07-12 18:55:53,717 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2380000043776818e-05, 1239
[INFO] 2021-07-12 18:55:53,718 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1239
[INFO] 2021-07-12 18:55:53,718 [run_pretraining.py:  558]:	worker_index: 6, step: 1239, cost: 7.929867, mlm loss: 7.929867, speed: 1.102630 steps/s, speed: 8.821037 samples/s, speed: 4516.371098 tokens/s, learning rate: 1.238e-05, loss_scalings: 10737.418945, pp_loss: 7.803512
[INFO] 2021-07-12 18:55:53,718 [run_pretraining.py:  512]:	********exe.run_1239******* 
[INFO] 2021-07-12 18:55:54,634 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:54,634 [run_pretraining.py:  534]:	loss/total_loss, 7.579574108123779, 1240
[INFO] 2021-07-12 18:55:54,635 [run_pretraining.py:  535]:	loss/mlm_loss, 7.579574108123779, 1240
[INFO] 2021-07-12 18:55:54,635 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.238999902852811e-05, 1240
[INFO] 2021-07-12 18:55:54,635 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1240
[INFO] 2021-07-12 18:55:54,635 [run_pretraining.py:  558]:	worker_index: 6, step: 1240, cost: 7.579574, mlm loss: 7.579574, speed: 1.091087 steps/s, speed: 8.728693 samples/s, speed: 4469.090898 tokens/s, learning rate: 1.239e-05, loss_scalings: 10737.418945, pp_loss: 7.558517
[INFO] 2021-07-12 18:55:54,635 [run_pretraining.py:  512]:	********exe.run_1240******* 
[INFO] 2021-07-12 18:55:55,540 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:55,541 [run_pretraining.py:  534]:	loss/total_loss, 7.3634352684021, 1241
[INFO] 2021-07-12 18:55:55,541 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3634352684021, 1241
[INFO] 2021-07-12 18:55:55,541 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2399999832268804e-05, 1241
[INFO] 2021-07-12 18:55:55,541 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1241
[INFO] 2021-07-12 18:55:55,541 [run_pretraining.py:  558]:	worker_index: 6, step: 1241, cost: 7.363435, mlm loss: 7.363435, speed: 1.104319 steps/s, speed: 8.834550 samples/s, speed: 4523.289374 tokens/s, learning rate: 1.240e-05, loss_scalings: 10737.418945, pp_loss: 7.661345
[INFO] 2021-07-12 18:55:55,541 [run_pretraining.py:  512]:	********exe.run_1241******* 
[INFO] 2021-07-12 18:55:56,452 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:56,453 [run_pretraining.py:  534]:	loss/total_loss, 7.687624454498291, 1242
[INFO] 2021-07-12 18:55:56,453 [run_pretraining.py:  535]:	loss/mlm_loss, 7.687624454498291, 1242
[INFO] 2021-07-12 18:55:56,453 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2409999726514798e-05, 1242
[INFO] 2021-07-12 18:55:56,453 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1242
[INFO] 2021-07-12 18:55:56,453 [run_pretraining.py:  558]:	worker_index: 6, step: 1242, cost: 7.687624, mlm loss: 7.687624, speed: 1.097434 steps/s, speed: 8.779472 samples/s, speed: 4495.089818 tokens/s, learning rate: 1.241e-05, loss_scalings: 10737.418945, pp_loss: 7.564567
[INFO] 2021-07-12 18:55:56,453 [run_pretraining.py:  512]:	********exe.run_1242******* 
[INFO] 2021-07-12 18:55:57,360 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:57,361 [run_pretraining.py:  534]:	loss/total_loss, 7.664796829223633, 1243
[INFO] 2021-07-12 18:55:57,361 [run_pretraining.py:  535]:	loss/mlm_loss, 7.664796829223633, 1243
[INFO] 2021-07-12 18:55:57,361 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2419999620760791e-05, 1243
[INFO] 2021-07-12 18:55:57,361 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1243
[INFO] 2021-07-12 18:55:57,361 [run_pretraining.py:  558]:	worker_index: 6, step: 1243, cost: 7.664797, mlm loss: 7.664797, speed: 1.101922 steps/s, speed: 8.815378 samples/s, speed: 4513.473579 tokens/s, learning rate: 1.242e-05, loss_scalings: 10737.418945, pp_loss: 7.435127
[INFO] 2021-07-12 18:55:57,361 [run_pretraining.py:  512]:	********exe.run_1243******* 
[INFO] 2021-07-12 18:55:58,283 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:58,283 [run_pretraining.py:  534]:	loss/total_loss, 7.5020751953125, 1244
[INFO] 2021-07-12 18:55:58,283 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5020751953125, 1244
[INFO] 2021-07-12 18:55:58,284 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2430000424501486e-05, 1244
[INFO] 2021-07-12 18:55:58,284 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1244
[INFO] 2021-07-12 18:55:58,284 [run_pretraining.py:  558]:	worker_index: 6, step: 1244, cost: 7.502075, mlm loss: 7.502075, speed: 1.084836 steps/s, speed: 8.678684 samples/s, speed: 4443.486385 tokens/s, learning rate: 1.243e-05, loss_scalings: 10737.418945, pp_loss: 6.815412
[INFO] 2021-07-12 18:55:58,284 [run_pretraining.py:  512]:	********exe.run_1244******* 
[INFO] 2021-07-12 18:55:59,184 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:59,185 [run_pretraining.py:  534]:	loss/total_loss, 7.655030727386475, 1245
[INFO] 2021-07-12 18:55:59,185 [run_pretraining.py:  535]:	loss/mlm_loss, 7.655030727386475, 1245
[INFO] 2021-07-12 18:55:59,185 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2439999409252778e-05, 1245
[INFO] 2021-07-12 18:55:59,185 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1245
[INFO] 2021-07-12 18:55:59,185 [run_pretraining.py:  558]:	worker_index: 6, step: 1245, cost: 7.655031, mlm loss: 7.655031, speed: 1.109983 steps/s, speed: 8.879867 samples/s, speed: 4546.491721 tokens/s, learning rate: 1.244e-05, loss_scalings: 10737.418945, pp_loss: 7.768518
[INFO] 2021-07-12 18:55:59,185 [run_pretraining.py:  512]:	********exe.run_1245******* 
[INFO] 2021-07-12 18:56:00,102 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:00,103 [run_pretraining.py:  534]:	loss/total_loss, 7.249909400939941, 1246
[INFO] 2021-07-12 18:56:00,103 [run_pretraining.py:  535]:	loss/mlm_loss, 7.249909400939941, 1246
[INFO] 2021-07-12 18:56:00,103 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2449999303498771e-05, 1246
[INFO] 2021-07-12 18:56:00,103 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1246
[INFO] 2021-07-12 18:56:00,103 [run_pretraining.py:  558]:	worker_index: 6, step: 1246, cost: 7.249909, mlm loss: 7.249909, speed: 1.090119 steps/s, speed: 8.720953 samples/s, speed: 4465.127732 tokens/s, learning rate: 1.245e-05, loss_scalings: 10737.418945, pp_loss: 7.526126
[INFO] 2021-07-12 18:56:00,103 [run_pretraining.py:  512]:	********exe.run_1246******* 
[INFO] 2021-07-12 18:56:01,026 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:01,027 [run_pretraining.py:  534]:	loss/total_loss, 7.018657684326172, 1247
[INFO] 2021-07-12 18:56:01,027 [run_pretraining.py:  535]:	loss/mlm_loss, 7.018657684326172, 1247
[INFO] 2021-07-12 18:56:01,027 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2460000107239466e-05, 1247
[INFO] 2021-07-12 18:56:01,027 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1247
[INFO] 2021-07-12 18:56:01,027 [run_pretraining.py:  558]:	worker_index: 6, step: 1247, cost: 7.018658, mlm loss: 7.018658, speed: 1.083560 steps/s, speed: 8.668478 samples/s, speed: 4438.260990 tokens/s, learning rate: 1.246e-05, loss_scalings: 10737.418945, pp_loss: 7.553598
[INFO] 2021-07-12 18:56:01,027 [run_pretraining.py:  512]:	********exe.run_1247******* 
[INFO] 2021-07-12 18:56:01,936 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:01,937 [run_pretraining.py:  534]:	loss/total_loss, 7.705482006072998, 1248
[INFO] 2021-07-12 18:56:01,937 [run_pretraining.py:  535]:	loss/mlm_loss, 7.705482006072998, 1248
[INFO] 2021-07-12 18:56:01,937 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.247000000148546e-05, 1248
[INFO] 2021-07-12 18:56:01,937 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1248
[INFO] 2021-07-12 18:56:01,937 [run_pretraining.py:  558]:	worker_index: 6, step: 1248, cost: 7.705482, mlm loss: 7.705482, speed: 1.099587 steps/s, speed: 8.796696 samples/s, speed: 4503.908097 tokens/s, learning rate: 1.247e-05, loss_scalings: 10737.418945, pp_loss: 7.412499
[INFO] 2021-07-12 18:56:01,937 [run_pretraining.py:  512]:	********exe.run_1248******* 
[INFO] 2021-07-12 18:56:02,850 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:02,850 [run_pretraining.py:  534]:	loss/total_loss, 8.61111068725586, 1249
[INFO] 2021-07-12 18:56:02,851 [run_pretraining.py:  535]:	loss/mlm_loss, 8.61111068725586, 1249
[INFO] 2021-07-12 18:56:02,851 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2479998986236751e-05, 1249
[INFO] 2021-07-12 18:56:02,851 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1249
[INFO] 2021-07-12 18:56:02,851 [run_pretraining.py:  558]:	worker_index: 6, step: 1249, cost: 8.611111, mlm loss: 8.611111, speed: 1.095282 steps/s, speed: 8.762252 samples/s, speed: 4486.273201 tokens/s, learning rate: 1.248e-05, loss_scalings: 10737.418945, pp_loss: 7.745585
[INFO] 2021-07-12 18:56:02,851 [run_pretraining.py:  512]:	********exe.run_1249******* 
[INFO] 2021-07-12 18:56:03,758 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:03,759 [run_pretraining.py:  534]:	loss/total_loss, 7.592063903808594, 1250
[INFO] 2021-07-12 18:56:03,759 [run_pretraining.py:  535]:	loss/mlm_loss, 7.592063903808594, 1250
[INFO] 2021-07-12 18:56:03,759 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2489999789977446e-05, 1250
[INFO] 2021-07-12 18:56:03,759 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1250
[INFO] 2021-07-12 18:56:03,759 [run_pretraining.py:  558]:	worker_index: 6, step: 1250, cost: 7.592064, mlm loss: 7.592064, speed: 1.101713 steps/s, speed: 8.813704 samples/s, speed: 4512.616427 tokens/s, learning rate: 1.249e-05, loss_scalings: 10737.418945, pp_loss: 7.668255
[INFO] 2021-07-12 18:56:03,759 [run_pretraining.py:  512]:	********exe.run_1250******* 
[INFO] 2021-07-12 18:56:04,676 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:04,677 [run_pretraining.py:  534]:	loss/total_loss, 8.042344093322754, 1251
[INFO] 2021-07-12 18:56:04,677 [run_pretraining.py:  535]:	loss/mlm_loss, 8.042344093322754, 1251
[INFO] 2021-07-12 18:56:04,677 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.249999968422344e-05, 1251
[INFO] 2021-07-12 18:56:04,677 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1251
[INFO] 2021-07-12 18:56:04,677 [run_pretraining.py:  558]:	worker_index: 6, step: 1251, cost: 8.042344, mlm loss: 8.042344, speed: 1.090311 steps/s, speed: 8.722487 samples/s, speed: 4465.913534 tokens/s, learning rate: 1.250e-05, loss_scalings: 10737.418945, pp_loss: 7.225549
[INFO] 2021-07-12 18:56:04,677 [run_pretraining.py:  512]:	********exe.run_1251******* 
[INFO] 2021-07-12 18:56:05,608 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:05,608 [run_pretraining.py:  534]:	loss/total_loss, 7.937380790710449, 1252
[INFO] 2021-07-12 18:56:05,608 [run_pretraining.py:  535]:	loss/mlm_loss, 7.937380790710449, 1252
[INFO] 2021-07-12 18:56:05,608 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2509999578469433e-05, 1252
[INFO] 2021-07-12 18:56:05,608 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1252
[INFO] 2021-07-12 18:56:05,609 [run_pretraining.py:  558]:	worker_index: 6, step: 1252, cost: 7.937381, mlm loss: 7.937381, speed: 1.074456 steps/s, speed: 8.595651 samples/s, speed: 4400.973546 tokens/s, learning rate: 1.251e-05, loss_scalings: 10737.418945, pp_loss: 7.451503
[INFO] 2021-07-12 18:56:05,609 [run_pretraining.py:  512]:	********exe.run_1252******* 
[INFO] 2021-07-12 18:56:06,515 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:06,515 [run_pretraining.py:  534]:	loss/total_loss, 5.957549571990967, 1253
[INFO] 2021-07-12 18:56:06,515 [run_pretraining.py:  535]:	loss/mlm_loss, 5.957549571990967, 1253
[INFO] 2021-07-12 18:56:06,515 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2520000382210128e-05, 1253
[INFO] 2021-07-12 18:56:06,516 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1253
[INFO] 2021-07-12 18:56:06,516 [run_pretraining.py:  558]:	worker_index: 6, step: 1253, cost: 5.957550, mlm loss: 5.957550, speed: 1.103358 steps/s, speed: 8.826864 samples/s, speed: 4519.354370 tokens/s, learning rate: 1.252e-05, loss_scalings: 10737.418945, pp_loss: 6.464863
[INFO] 2021-07-12 18:56:06,516 [run_pretraining.py:  512]:	********exe.run_1253******* 
[INFO] 2021-07-12 18:56:07,427 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:07,428 [run_pretraining.py:  534]:	loss/total_loss, 7.706519603729248, 1254
[INFO] 2021-07-12 18:56:07,428 [run_pretraining.py:  535]:	loss/mlm_loss, 7.706519603729248, 1254
[INFO] 2021-07-12 18:56:07,428 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2530000276456121e-05, 1254
[INFO] 2021-07-12 18:56:07,428 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1254
[INFO] 2021-07-12 18:56:07,428 [run_pretraining.py:  558]:	worker_index: 6, step: 1254, cost: 7.706520, mlm loss: 7.706520, speed: 1.096353 steps/s, speed: 8.770821 samples/s, speed: 4490.660162 tokens/s, learning rate: 1.253e-05, loss_scalings: 10737.418945, pp_loss: 6.639353
[INFO] 2021-07-12 18:56:07,429 [run_pretraining.py:  512]:	********exe.run_1254******* 
[INFO] 2021-07-12 18:56:08,377 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:08,377 [run_pretraining.py:  534]:	loss/total_loss, 7.208498477935791, 1255
[INFO] 2021-07-12 18:56:08,377 [run_pretraining.py:  535]:	loss/mlm_loss, 7.208498477935791, 1255
[INFO] 2021-07-12 18:56:08,378 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2540000170702115e-05, 1255
[INFO] 2021-07-12 18:56:08,378 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1255
[INFO] 2021-07-12 18:56:08,378 [run_pretraining.py:  558]:	worker_index: 6, step: 1255, cost: 7.208498, mlm loss: 7.208498, speed: 1.054264 steps/s, speed: 8.434114 samples/s, speed: 4318.266503 tokens/s, learning rate: 1.254e-05, loss_scalings: 10737.418945, pp_loss: 7.335869
[INFO] 2021-07-12 18:56:08,378 [run_pretraining.py:  512]:	********exe.run_1255******* 
[INFO] 2021-07-12 18:56:09,336 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:09,336 [run_pretraining.py:  534]:	loss/total_loss, 7.329517364501953, 1256
[INFO] 2021-07-12 18:56:09,337 [run_pretraining.py:  535]:	loss/mlm_loss, 7.329517364501953, 1256
[INFO] 2021-07-12 18:56:09,337 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2549999155453406e-05, 1256
[INFO] 2021-07-12 18:56:09,337 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1256
[INFO] 2021-07-12 18:56:09,337 [run_pretraining.py:  558]:	worker_index: 6, step: 1256, cost: 7.329517, mlm loss: 7.329517, speed: 1.043395 steps/s, speed: 8.347160 samples/s, speed: 4273.746010 tokens/s, learning rate: 1.255e-05, loss_scalings: 10737.418945, pp_loss: 7.543316
[INFO] 2021-07-12 18:56:09,337 [run_pretraining.py:  512]:	********exe.run_1256******* 
[INFO] 2021-07-12 18:56:10,392 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:10,393 [run_pretraining.py:  534]:	loss/total_loss, 7.807254791259766, 1257
[INFO] 2021-07-12 18:56:10,393 [run_pretraining.py:  535]:	loss/mlm_loss, 7.807254791259766, 1257
[INFO] 2021-07-12 18:56:10,393 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.25599990496994e-05, 1257
[INFO] 2021-07-12 18:56:10,393 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1257
[INFO] 2021-07-12 18:56:10,393 [run_pretraining.py:  558]:	worker_index: 6, step: 1257, cost: 7.807255, mlm loss: 7.807255, speed: 0.947473 steps/s, speed: 7.579786 samples/s, speed: 3880.850474 tokens/s, learning rate: 1.256e-05, loss_scalings: 10737.418945, pp_loss: 7.473249
[INFO] 2021-07-12 18:56:10,393 [run_pretraining.py:  512]:	********exe.run_1257******* 
[INFO] 2021-07-12 18:56:11,454 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:11,455 [run_pretraining.py:  534]:	loss/total_loss, 6.801795959472656, 1258
[INFO] 2021-07-12 18:56:11,455 [run_pretraining.py:  535]:	loss/mlm_loss, 6.801795959472656, 1258
[INFO] 2021-07-12 18:56:11,455 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2569998943945393e-05, 1258
[INFO] 2021-07-12 18:56:11,455 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1258
[INFO] 2021-07-12 18:56:11,455 [run_pretraining.py:  558]:	worker_index: 6, step: 1258, cost: 6.801796, mlm loss: 6.801796, speed: 0.942152 steps/s, speed: 7.537219 samples/s, speed: 3859.056043 tokens/s, learning rate: 1.257e-05, loss_scalings: 10737.418945, pp_loss: 7.411465
[INFO] 2021-07-12 18:56:11,455 [run_pretraining.py:  512]:	********exe.run_1258******* 
[INFO] 2021-07-12 18:56:12,512 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:12,512 [run_pretraining.py:  534]:	loss/total_loss, 8.94922161102295, 1259
[INFO] 2021-07-12 18:56:12,512 [run_pretraining.py:  535]:	loss/mlm_loss, 8.94922161102295, 1259
[INFO] 2021-07-12 18:56:12,512 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2579999747686088e-05, 1259
[INFO] 2021-07-12 18:56:12,513 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1259
[INFO] 2021-07-12 18:56:12,513 [run_pretraining.py:  558]:	worker_index: 6, step: 1259, cost: 8.949222, mlm loss: 8.949222, speed: 0.946263 steps/s, speed: 7.570107 samples/s, speed: 3875.894883 tokens/s, learning rate: 1.258e-05, loss_scalings: 10737.418945, pp_loss: 8.206915
[INFO] 2021-07-12 18:56:12,513 [run_pretraining.py:  512]:	********exe.run_1259******* 
[INFO] 2021-07-12 18:56:13,442 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:13,443 [run_pretraining.py:  534]:	loss/total_loss, 7.79735803604126, 1260
[INFO] 2021-07-12 18:56:13,443 [run_pretraining.py:  535]:	loss/mlm_loss, 7.79735803604126, 1260
[INFO] 2021-07-12 18:56:13,443 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2589999641932081e-05, 1260
[INFO] 2021-07-12 18:56:13,443 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1260
[INFO] 2021-07-12 18:56:13,443 [run_pretraining.py:  558]:	worker_index: 6, step: 1260, cost: 7.797358, mlm loss: 7.797358, speed: 1.075320 steps/s, speed: 8.602558 samples/s, speed: 4404.509653 tokens/s, learning rate: 1.259e-05, loss_scalings: 10737.418945, pp_loss: 7.596581
[INFO] 2021-07-12 18:56:13,443 [run_pretraining.py:  512]:	********exe.run_1260******* 
[INFO] 2021-07-12 18:56:14,361 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:14,362 [run_pretraining.py:  534]:	loss/total_loss, 8.180157661437988, 1261
[INFO] 2021-07-12 18:56:14,362 [run_pretraining.py:  535]:	loss/mlm_loss, 8.180157661437988, 1261
[INFO] 2021-07-12 18:56:14,362 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2599999536178075e-05, 1261
[INFO] 2021-07-12 18:56:14,362 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1261
[INFO] 2021-07-12 18:56:14,362 [run_pretraining.py:  558]:	worker_index: 6, step: 1261, cost: 8.180158, mlm loss: 8.180158, speed: 1.089311 steps/s, speed: 8.714491 samples/s, speed: 4461.819258 tokens/s, learning rate: 1.260e-05, loss_scalings: 10737.418945, pp_loss: 7.983328
[INFO] 2021-07-12 18:56:14,362 [run_pretraining.py:  512]:	********exe.run_1261******* 
[INFO] 2021-07-12 18:56:15,277 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:15,278 [run_pretraining.py:  534]:	loss/total_loss, 7.289742946624756, 1262
[INFO] 2021-07-12 18:56:15,278 [run_pretraining.py:  535]:	loss/mlm_loss, 7.289742946624756, 1262
[INFO] 2021-07-12 18:56:15,278 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.261000033991877e-05, 1262
[INFO] 2021-07-12 18:56:15,278 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1262
[INFO] 2021-07-12 18:56:15,278 [run_pretraining.py:  558]:	worker_index: 6, step: 1262, cost: 7.289743, mlm loss: 7.289743, speed: 1.092145 steps/s, speed: 8.737160 samples/s, speed: 4473.425666 tokens/s, learning rate: 1.261e-05, loss_scalings: 10737.418945, pp_loss: 7.123229
[INFO] 2021-07-12 18:56:15,278 [run_pretraining.py:  512]:	********exe.run_1262******* 
[INFO] 2021-07-12 18:56:16,203 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:16,204 [run_pretraining.py:  534]:	loss/total_loss, 7.230123996734619, 1263
[INFO] 2021-07-12 18:56:16,204 [run_pretraining.py:  535]:	loss/mlm_loss, 7.230123996734619, 1263
[INFO] 2021-07-12 18:56:16,204 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2620000234164763e-05, 1263
[INFO] 2021-07-12 18:56:16,204 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1263
[INFO] 2021-07-12 18:56:16,204 [run_pretraining.py:  558]:	worker_index: 6, step: 1263, cost: 7.230124, mlm loss: 7.230124, speed: 1.080989 steps/s, speed: 8.647914 samples/s, speed: 4427.731725 tokens/s, learning rate: 1.262e-05, loss_scalings: 10737.418945, pp_loss: 7.535494
[INFO] 2021-07-12 18:56:16,204 [run_pretraining.py:  512]:	********exe.run_1263******* 
[INFO] 2021-07-12 18:56:17,106 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:17,107 [run_pretraining.py:  534]:	loss/total_loss, 7.258997917175293, 1264
[INFO] 2021-07-12 18:56:17,107 [run_pretraining.py:  535]:	loss/mlm_loss, 7.258997917175293, 1264
[INFO] 2021-07-12 18:56:17,107 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2630000128410757e-05, 1264
[INFO] 2021-07-12 18:56:17,107 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1264
[INFO] 2021-07-12 18:56:17,107 [run_pretraining.py:  558]:	worker_index: 6, step: 1264, cost: 7.258998, mlm loss: 7.258998, speed: 1.108100 steps/s, speed: 8.864798 samples/s, speed: 4538.776768 tokens/s, learning rate: 1.263e-05, loss_scalings: 10737.418945, pp_loss: 7.425414
[INFO] 2021-07-12 18:56:17,107 [run_pretraining.py:  512]:	********exe.run_1264******* 
[INFO] 2021-07-12 18:56:18,002 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:18,003 [run_pretraining.py:  534]:	loss/total_loss, 7.763123035430908, 1265
[INFO] 2021-07-12 18:56:18,003 [run_pretraining.py:  535]:	loss/mlm_loss, 7.763123035430908, 1265
[INFO] 2021-07-12 18:56:18,003 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2639999113162048e-05, 1265
[INFO] 2021-07-12 18:56:18,003 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1265
[INFO] 2021-07-12 18:56:18,003 [run_pretraining.py:  558]:	worker_index: 6, step: 1265, cost: 7.763123, mlm loss: 7.763123, speed: 1.116808 steps/s, speed: 8.934464 samples/s, speed: 4574.445320 tokens/s, learning rate: 1.264e-05, loss_scalings: 10737.418945, pp_loss: 7.903286
[INFO] 2021-07-12 18:56:18,004 [run_pretraining.py:  512]:	********exe.run_1265******* 
[INFO] 2021-07-12 18:56:18,935 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:18,936 [run_pretraining.py:  534]:	loss/total_loss, 4.643345832824707, 1266
[INFO] 2021-07-12 18:56:18,936 [run_pretraining.py:  535]:	loss/mlm_loss, 4.643345832824707, 1266
[INFO] 2021-07-12 18:56:18,936 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2649999007408042e-05, 1266
[INFO] 2021-07-12 18:56:18,936 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1266
[INFO] 2021-07-12 18:56:18,936 [run_pretraining.py:  558]:	worker_index: 6, step: 1266, cost: 4.643346, mlm loss: 4.643346, speed: 1.072911 steps/s, speed: 8.583285 samples/s, speed: 4394.642175 tokens/s, learning rate: 1.265e-05, loss_scalings: 10737.418945, pp_loss: 6.892532
[INFO] 2021-07-12 18:56:18,936 [run_pretraining.py:  512]:	********exe.run_1266******* 
[INFO] 2021-07-12 18:56:19,858 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:19,858 [run_pretraining.py:  534]:	loss/total_loss, 7.4072771072387695, 1267
[INFO] 2021-07-12 18:56:19,858 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4072771072387695, 1267
[INFO] 2021-07-12 18:56:19,858 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2659999811148737e-05, 1267
[INFO] 2021-07-12 18:56:19,859 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1267
[INFO] 2021-07-12 18:56:19,859 [run_pretraining.py:  558]:	worker_index: 6, step: 1267, cost: 7.407277, mlm loss: 7.407277, speed: 1.084944 steps/s, speed: 8.679553 samples/s, speed: 4443.931203 tokens/s, learning rate: 1.266e-05, loss_scalings: 10737.418945, pp_loss: 7.384237
[INFO] 2021-07-12 18:56:19,859 [run_pretraining.py:  512]:	********exe.run_1267******* 
[INFO] 2021-07-12 18:56:20,782 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:20,783 [run_pretraining.py:  534]:	loss/total_loss, 7.5284881591796875, 1268
[INFO] 2021-07-12 18:56:20,783 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5284881591796875, 1268
[INFO] 2021-07-12 18:56:20,783 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.266999970539473e-05, 1268
[INFO] 2021-07-12 18:56:20,783 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1268
[INFO] 2021-07-12 18:56:20,783 [run_pretraining.py:  558]:	worker_index: 6, step: 1268, cost: 7.528488, mlm loss: 7.528488, speed: 1.082244 steps/s, speed: 8.657955 samples/s, speed: 4432.872863 tokens/s, learning rate: 1.267e-05, loss_scalings: 10737.418945, pp_loss: 7.283465
[INFO] 2021-07-12 18:56:20,783 [run_pretraining.py:  512]:	********exe.run_1268******* 
[INFO] 2021-07-12 18:56:21,702 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:21,703 [run_pretraining.py:  534]:	loss/total_loss, 7.230820655822754, 1269
[INFO] 2021-07-12 18:56:21,703 [run_pretraining.py:  535]:	loss/mlm_loss, 7.230820655822754, 1269
[INFO] 2021-07-12 18:56:21,703 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2679999599640723e-05, 1269
[INFO] 2021-07-12 18:56:21,703 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1269
[INFO] 2021-07-12 18:56:21,703 [run_pretraining.py:  558]:	worker_index: 6, step: 1269, cost: 7.230821, mlm loss: 7.230821, speed: 1.087764 steps/s, speed: 8.702115 samples/s, speed: 4455.482745 tokens/s, learning rate: 1.268e-05, loss_scalings: 10737.418945, pp_loss: 7.416666
[INFO] 2021-07-12 18:56:21,704 [run_pretraining.py:  512]:	********exe.run_1269******* 
[INFO] 2021-07-12 18:56:22,615 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:22,616 [run_pretraining.py:  534]:	loss/total_loss, 7.247300624847412, 1270
[INFO] 2021-07-12 18:56:22,616 [run_pretraining.py:  535]:	loss/mlm_loss, 7.247300624847412, 1270
[INFO] 2021-07-12 18:56:22,616 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2689999493886717e-05, 1270
[INFO] 2021-07-12 18:56:22,616 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1270
[INFO] 2021-07-12 18:56:22,616 [run_pretraining.py:  558]:	worker_index: 6, step: 1270, cost: 7.247301, mlm loss: 7.247301, speed: 1.096297 steps/s, speed: 8.770378 samples/s, speed: 4490.433627 tokens/s, learning rate: 1.269e-05, loss_scalings: 10737.418945, pp_loss: 7.332672
[INFO] 2021-07-12 18:56:22,616 [run_pretraining.py:  512]:	********exe.run_1270******* 
[INFO] 2021-07-12 18:56:23,537 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:23,538 [run_pretraining.py:  534]:	loss/total_loss, 7.891263961791992, 1271
[INFO] 2021-07-12 18:56:23,538 [run_pretraining.py:  535]:	loss/mlm_loss, 7.891263961791992, 1271
[INFO] 2021-07-12 18:56:23,538 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2700000297627412e-05, 1271
[INFO] 2021-07-12 18:56:23,538 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1271
[INFO] 2021-07-12 18:56:23,538 [run_pretraining.py:  558]:	worker_index: 6, step: 1271, cost: 7.891264, mlm loss: 7.891264, speed: 1.085511 steps/s, speed: 8.684088 samples/s, speed: 4446.253287 tokens/s, learning rate: 1.270e-05, loss_scalings: 10737.418945, pp_loss: 7.756121
[INFO] 2021-07-12 18:56:23,538 [run_pretraining.py:  512]:	********exe.run_1271******* 
[INFO] 2021-07-12 18:56:24,459 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:24,459 [run_pretraining.py:  534]:	loss/total_loss, 7.666015148162842, 1272
[INFO] 2021-07-12 18:56:24,459 [run_pretraining.py:  535]:	loss/mlm_loss, 7.666015148162842, 1272
[INFO] 2021-07-12 18:56:24,459 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2710000191873405e-05, 1272
[INFO] 2021-07-12 18:56:24,460 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1272
[INFO] 2021-07-12 18:56:24,460 [run_pretraining.py:  558]:	worker_index: 6, step: 1272, cost: 7.666015, mlm loss: 7.666015, speed: 1.086073 steps/s, speed: 8.688584 samples/s, speed: 4448.554761 tokens/s, learning rate: 1.271e-05, loss_scalings: 10737.418945, pp_loss: 7.535094
[INFO] 2021-07-12 18:56:24,460 [run_pretraining.py:  512]:	********exe.run_1272******* 
[INFO] 2021-07-12 18:56:25,375 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:25,375 [run_pretraining.py:  534]:	loss/total_loss, 7.434750080108643, 1273
[INFO] 2021-07-12 18:56:25,375 [run_pretraining.py:  535]:	loss/mlm_loss, 7.434750080108643, 1273
[INFO] 2021-07-12 18:56:25,375 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2720000086119398e-05, 1273
[INFO] 2021-07-12 18:56:25,376 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1273
[INFO] 2021-07-12 18:56:25,376 [run_pretraining.py:  558]:	worker_index: 6, step: 1273, cost: 7.434750, mlm loss: 7.434750, speed: 1.092625 steps/s, speed: 8.740997 samples/s, speed: 4475.390423 tokens/s, learning rate: 1.272e-05, loss_scalings: 10737.418945, pp_loss: 7.715271
[INFO] 2021-07-12 18:56:25,376 [run_pretraining.py:  512]:	********exe.run_1273******* 
[INFO] 2021-07-12 18:56:26,296 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:26,296 [run_pretraining.py:  534]:	loss/total_loss, 7.594662666320801, 1274
[INFO] 2021-07-12 18:56:26,296 [run_pretraining.py:  535]:	loss/mlm_loss, 7.594662666320801, 1274
[INFO] 2021-07-12 18:56:26,297 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.272999907087069e-05, 1274
[INFO] 2021-07-12 18:56:26,297 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1274
[INFO] 2021-07-12 18:56:26,297 [run_pretraining.py:  558]:	worker_index: 6, step: 1274, cost: 7.594663, mlm loss: 7.594663, speed: 1.086492 steps/s, speed: 8.691935 samples/s, speed: 4450.270615 tokens/s, learning rate: 1.273e-05, loss_scalings: 10737.418945, pp_loss: 7.486740
[INFO] 2021-07-12 18:56:26,297 [run_pretraining.py:  512]:	********exe.run_1274******* 
[INFO] 2021-07-12 18:56:27,200 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:27,201 [run_pretraining.py:  534]:	loss/total_loss, 7.592895030975342, 1275
[INFO] 2021-07-12 18:56:27,201 [run_pretraining.py:  535]:	loss/mlm_loss, 7.592895030975342, 1275
[INFO] 2021-07-12 18:56:27,201 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2739998965116683e-05, 1275
[INFO] 2021-07-12 18:56:27,201 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1275
[INFO] 2021-07-12 18:56:27,201 [run_pretraining.py:  558]:	worker_index: 6, step: 1275, cost: 7.592895, mlm loss: 7.592895, speed: 1.106577 steps/s, speed: 8.852618 samples/s, speed: 4532.540401 tokens/s, learning rate: 1.274e-05, loss_scalings: 10737.418945, pp_loss: 7.598294
[INFO] 2021-07-12 18:56:27,201 [run_pretraining.py:  512]:	********exe.run_1275******* 
[INFO] 2021-07-12 18:56:28,101 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:28,101 [run_pretraining.py:  534]:	loss/total_loss, 7.332640647888184, 1276
[INFO] 2021-07-12 18:56:28,101 [run_pretraining.py:  535]:	loss/mlm_loss, 7.332640647888184, 1276
[INFO] 2021-07-12 18:56:28,101 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2749999768857379e-05, 1276
[INFO] 2021-07-12 18:56:28,102 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1276
[INFO] 2021-07-12 18:56:28,102 [run_pretraining.py:  558]:	worker_index: 6, step: 1276, cost: 7.332641, mlm loss: 7.332641, speed: 1.111364 steps/s, speed: 8.890911 samples/s, speed: 4552.146503 tokens/s, learning rate: 1.275e-05, loss_scalings: 10737.418945, pp_loss: 7.625616
[INFO] 2021-07-12 18:56:28,102 [run_pretraining.py:  512]:	********exe.run_1276******* 
[INFO] 2021-07-12 18:56:29,008 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:29,008 [run_pretraining.py:  534]:	loss/total_loss, 7.538116931915283, 1277
[INFO] 2021-07-12 18:56:29,008 [run_pretraining.py:  535]:	loss/mlm_loss, 7.538116931915283, 1277
[INFO] 2021-07-12 18:56:29,008 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2759999663103372e-05, 1277
[INFO] 2021-07-12 18:56:29,009 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1277
[INFO] 2021-07-12 18:56:29,009 [run_pretraining.py:  558]:	worker_index: 6, step: 1277, cost: 7.538117, mlm loss: 7.538117, speed: 1.103467 steps/s, speed: 8.827735 samples/s, speed: 4519.800239 tokens/s, learning rate: 1.276e-05, loss_scalings: 10737.418945, pp_loss: 7.939903
[INFO] 2021-07-12 18:56:29,009 [run_pretraining.py:  512]:	********exe.run_1277******* 
[INFO] 2021-07-12 18:56:29,909 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:29,909 [run_pretraining.py:  534]:	loss/total_loss, 7.3789472579956055, 1278
[INFO] 2021-07-12 18:56:29,910 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3789472579956055, 1278
[INFO] 2021-07-12 18:56:29,910 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2769999557349365e-05, 1278
[INFO] 2021-07-12 18:56:29,910 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1278
[INFO] 2021-07-12 18:56:29,910 [run_pretraining.py:  558]:	worker_index: 6, step: 1278, cost: 7.378947, mlm loss: 7.378947, speed: 1.110438 steps/s, speed: 8.883501 samples/s, speed: 4548.352609 tokens/s, learning rate: 1.277e-05, loss_scalings: 10737.418945, pp_loss: 7.455319
[INFO] 2021-07-12 18:56:29,910 [run_pretraining.py:  512]:	********exe.run_1278******* 
[INFO] 2021-07-12 18:56:30,806 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:30,807 [run_pretraining.py:  534]:	loss/total_loss, 7.8096723556518555, 1279
[INFO] 2021-07-12 18:56:30,807 [run_pretraining.py:  535]:	loss/mlm_loss, 7.8096723556518555, 1279
[INFO] 2021-07-12 18:56:30,807 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.278000036109006e-05, 1279
[INFO] 2021-07-12 18:56:30,807 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1279
[INFO] 2021-07-12 18:56:30,807 [run_pretraining.py:  558]:	worker_index: 6, step: 1279, cost: 7.809672, mlm loss: 7.809672, speed: 1.115117 steps/s, speed: 8.920933 samples/s, speed: 4567.517943 tokens/s, learning rate: 1.278e-05, loss_scalings: 10737.418945, pp_loss: 7.792253
[INFO] 2021-07-12 18:56:30,808 [run_pretraining.py:  512]:	********exe.run_1279******* 
[INFO] 2021-07-12 18:56:31,729 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:31,729 [run_pretraining.py:  534]:	loss/total_loss, 7.972683429718018, 1280
[INFO] 2021-07-12 18:56:31,730 [run_pretraining.py:  535]:	loss/mlm_loss, 7.972683429718018, 1280
[INFO] 2021-07-12 18:56:31,730 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2790000255336054e-05, 1280
[INFO] 2021-07-12 18:56:31,730 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1280
[INFO] 2021-07-12 18:56:31,730 [run_pretraining.py:  558]:	worker_index: 6, step: 1280, cost: 7.972683, mlm loss: 7.972683, speed: 1.085004 steps/s, speed: 8.680029 samples/s, speed: 4444.174914 tokens/s, learning rate: 1.279e-05, loss_scalings: 10737.418945, pp_loss: 7.558567
[INFO] 2021-07-12 18:56:31,730 [run_pretraining.py:  512]:	********exe.run_1280******* 
[INFO] 2021-07-12 18:56:32,713 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:32,714 [run_pretraining.py:  534]:	loss/total_loss, 7.842218399047852, 1281
[INFO] 2021-07-12 18:56:32,714 [run_pretraining.py:  535]:	loss/mlm_loss, 7.842218399047852, 1281
[INFO] 2021-07-12 18:56:32,714 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2800000149582047e-05, 1281
[INFO] 2021-07-12 18:56:32,714 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1281
[INFO] 2021-07-12 18:56:32,714 [run_pretraining.py:  558]:	worker_index: 6, step: 1281, cost: 7.842218, mlm loss: 7.842218, speed: 1.016516 steps/s, speed: 8.132127 samples/s, speed: 4163.648931 tokens/s, learning rate: 1.280e-05, loss_scalings: 10737.418945, pp_loss: 7.595805
[INFO] 2021-07-12 18:56:32,714 [run_pretraining.py:  512]:	********exe.run_1281******* 
[INFO] 2021-07-12 18:56:33,768 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:33,769 [run_pretraining.py:  534]:	loss/total_loss, 7.398735046386719, 1282
[INFO] 2021-07-12 18:56:33,769 [run_pretraining.py:  535]:	loss/mlm_loss, 7.398735046386719, 1282
[INFO] 2021-07-12 18:56:33,769 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2809999134333339e-05, 1282
[INFO] 2021-07-12 18:56:33,769 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1282
[INFO] 2021-07-12 18:56:33,769 [run_pretraining.py:  558]:	worker_index: 6, step: 1282, cost: 7.398735, mlm loss: 7.398735, speed: 0.948684 steps/s, speed: 7.589471 samples/s, speed: 3885.809085 tokens/s, learning rate: 1.281e-05, loss_scalings: 10737.418945, pp_loss: 7.549640
[INFO] 2021-07-12 18:56:33,769 [run_pretraining.py:  512]:	********exe.run_1282******* 
[INFO] 2021-07-12 18:56:34,819 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:34,820 [run_pretraining.py:  534]:	loss/total_loss, 7.229066848754883, 1283
[INFO] 2021-07-12 18:56:34,820 [run_pretraining.py:  535]:	loss/mlm_loss, 7.229066848754883, 1283
[INFO] 2021-07-12 18:56:34,820 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2819999028579332e-05, 1283
[INFO] 2021-07-12 18:56:34,820 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1283
[INFO] 2021-07-12 18:56:34,820 [run_pretraining.py:  558]:	worker_index: 6, step: 1283, cost: 7.229067, mlm loss: 7.229067, speed: 0.952261 steps/s, speed: 7.618086 samples/s, speed: 3900.460132 tokens/s, learning rate: 1.282e-05, loss_scalings: 10737.418945, pp_loss: 7.682105
[INFO] 2021-07-12 18:56:34,820 [run_pretraining.py:  512]:	********exe.run_1283******* 
[INFO] 2021-07-12 18:56:35,875 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:35,875 [run_pretraining.py:  534]:	loss/total_loss, 7.873813629150391, 1284
[INFO] 2021-07-12 18:56:35,876 [run_pretraining.py:  535]:	loss/mlm_loss, 7.873813629150391, 1284
[INFO] 2021-07-12 18:56:35,876 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2829998922825325e-05, 1284
[INFO] 2021-07-12 18:56:35,876 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1284
[INFO] 2021-07-12 18:56:35,876 [run_pretraining.py:  558]:	worker_index: 6, step: 1284, cost: 7.873814, mlm loss: 7.873814, speed: 0.947713 steps/s, speed: 7.581706 samples/s, speed: 3881.833465 tokens/s, learning rate: 1.283e-05, loss_scalings: 10737.418945, pp_loss: 7.450365
[INFO] 2021-07-12 18:56:35,876 [run_pretraining.py:  512]:	********exe.run_1284******* 
[INFO] 2021-07-12 18:56:36,926 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:36,927 [run_pretraining.py:  534]:	loss/total_loss, 6.778374671936035, 1285
[INFO] 2021-07-12 18:56:36,927 [run_pretraining.py:  535]:	loss/mlm_loss, 6.778374671936035, 1285
[INFO] 2021-07-12 18:56:36,927 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.283999972656602e-05, 1285
[INFO] 2021-07-12 18:56:36,927 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1285
[INFO] 2021-07-12 18:56:36,927 [run_pretraining.py:  558]:	worker_index: 6, step: 1285, cost: 6.778375, mlm loss: 6.778375, speed: 0.951503 steps/s, speed: 7.612024 samples/s, speed: 3897.356103 tokens/s, learning rate: 1.284e-05, loss_scalings: 10737.418945, pp_loss: 7.527102
[INFO] 2021-07-12 18:56:36,928 [run_pretraining.py:  512]:	********exe.run_1285******* 
[INFO] 2021-07-12 18:56:37,981 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:37,982 [run_pretraining.py:  534]:	loss/total_loss, 7.934321880340576, 1286
[INFO] 2021-07-12 18:56:37,982 [run_pretraining.py:  535]:	loss/mlm_loss, 7.934321880340576, 1286
[INFO] 2021-07-12 18:56:37,982 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2849999620812014e-05, 1286
[INFO] 2021-07-12 18:56:37,982 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1286
[INFO] 2021-07-12 18:56:37,982 [run_pretraining.py:  558]:	worker_index: 6, step: 1286, cost: 7.934322, mlm loss: 7.934322, speed: 0.948618 steps/s, speed: 7.588944 samples/s, speed: 3885.539280 tokens/s, learning rate: 1.285e-05, loss_scalings: 10737.418945, pp_loss: 7.357986
[INFO] 2021-07-12 18:56:37,982 [run_pretraining.py:  512]:	********exe.run_1286******* 
[INFO] 2021-07-12 18:56:39,044 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:39,045 [run_pretraining.py:  534]:	loss/total_loss, 7.223299026489258, 1287
[INFO] 2021-07-12 18:56:39,045 [run_pretraining.py:  535]:	loss/mlm_loss, 7.223299026489258, 1287
[INFO] 2021-07-12 18:56:39,045 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2859999515058007e-05, 1287
[INFO] 2021-07-12 18:56:39,045 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1287
[INFO] 2021-07-12 18:56:39,045 [run_pretraining.py:  558]:	worker_index: 6, step: 1287, cost: 7.223299, mlm loss: 7.223299, speed: 0.941442 steps/s, speed: 7.531536 samples/s, speed: 3856.146501 tokens/s, learning rate: 1.286e-05, loss_scalings: 10737.418945, pp_loss: 7.543231
[INFO] 2021-07-12 18:56:39,045 [run_pretraining.py:  512]:	********exe.run_1287******* 
[INFO] 2021-07-12 18:56:40,091 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:40,092 [run_pretraining.py:  534]:	loss/total_loss, 5.403660774230957, 1288
[INFO] 2021-07-12 18:56:40,092 [run_pretraining.py:  535]:	loss/mlm_loss, 5.403660774230957, 1288
[INFO] 2021-07-12 18:56:40,092 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2870000318798702e-05, 1288
[INFO] 2021-07-12 18:56:40,092 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1288
[INFO] 2021-07-12 18:56:40,092 [run_pretraining.py:  558]:	worker_index: 6, step: 1288, cost: 5.403661, mlm loss: 5.403661, speed: 0.956015 steps/s, speed: 7.648123 samples/s, speed: 3915.838727 tokens/s, learning rate: 1.287e-05, loss_scalings: 10737.418945, pp_loss: 6.741742
[INFO] 2021-07-12 18:56:40,092 [run_pretraining.py:  512]:	********exe.run_1288******* 
[INFO] 2021-07-12 18:56:41,203 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:41,204 [run_pretraining.py:  534]:	loss/total_loss, 7.627776145935059, 1289
[INFO] 2021-07-12 18:56:41,204 [run_pretraining.py:  535]:	loss/mlm_loss, 7.627776145935059, 1289
[INFO] 2021-07-12 18:56:41,204 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2880000213044696e-05, 1289
[INFO] 2021-07-12 18:56:41,204 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1289
[INFO] 2021-07-12 18:56:41,204 [run_pretraining.py:  558]:	worker_index: 6, step: 1289, cost: 7.627776, mlm loss: 7.627776, speed: 0.899771 steps/s, speed: 7.198171 samples/s, speed: 3685.463500 tokens/s, learning rate: 1.288e-05, loss_scalings: 10737.418945, pp_loss: 7.399961
[INFO] 2021-07-12 18:56:41,204 [run_pretraining.py:  512]:	********exe.run_1289******* 
[INFO] 2021-07-12 18:56:42,107 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:42,108 [run_pretraining.py:  534]:	loss/total_loss, 6.965933799743652, 1290
[INFO] 2021-07-12 18:56:42,108 [run_pretraining.py:  535]:	loss/mlm_loss, 6.965933799743652, 1290
[INFO] 2021-07-12 18:56:42,108 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2890000107290689e-05, 1290
[INFO] 2021-07-12 18:56:42,108 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1290
[INFO] 2021-07-12 18:56:42,108 [run_pretraining.py:  558]:	worker_index: 6, step: 1290, cost: 6.965934, mlm loss: 6.965934, speed: 1.106849 steps/s, speed: 8.854791 samples/s, speed: 4533.652781 tokens/s, learning rate: 1.289e-05, loss_scalings: 10737.418945, pp_loss: 6.578123
[INFO] 2021-07-12 18:56:42,108 [run_pretraining.py:  512]:	********exe.run_1290******* 
[INFO] 2021-07-12 18:56:43,007 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:43,007 [run_pretraining.py:  534]:	loss/total_loss, 7.572573661804199, 1291
[INFO] 2021-07-12 18:56:43,007 [run_pretraining.py:  535]:	loss/mlm_loss, 7.572573661804199, 1291
[INFO] 2021-07-12 18:56:43,007 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.289999909204198e-05, 1291
[INFO] 2021-07-12 18:56:43,008 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1291
[INFO] 2021-07-12 18:56:43,008 [run_pretraining.py:  558]:	worker_index: 6, step: 1291, cost: 7.572574, mlm loss: 7.572574, speed: 1.112779 steps/s, speed: 8.902231 samples/s, speed: 4557.942337 tokens/s, learning rate: 1.290e-05, loss_scalings: 10737.418945, pp_loss: 7.638012
[INFO] 2021-07-12 18:56:43,008 [run_pretraining.py:  512]:	********exe.run_1291******* 
[INFO] 2021-07-12 18:56:43,910 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:43,911 [run_pretraining.py:  534]:	loss/total_loss, 7.660580158233643, 1292
[INFO] 2021-07-12 18:56:43,911 [run_pretraining.py:  535]:	loss/mlm_loss, 7.660580158233643, 1292
[INFO] 2021-07-12 18:56:43,911 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2909998986287974e-05, 1292
[INFO] 2021-07-12 18:56:43,911 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1292
[INFO] 2021-07-12 18:56:43,911 [run_pretraining.py:  558]:	worker_index: 6, step: 1292, cost: 7.660580, mlm loss: 7.660580, speed: 1.107613 steps/s, speed: 8.860901 samples/s, speed: 4536.781133 tokens/s, learning rate: 1.291e-05, loss_scalings: 10737.418945, pp_loss: 7.730343
[INFO] 2021-07-12 18:56:43,911 [run_pretraining.py:  512]:	********exe.run_1292******* 
[INFO] 2021-07-12 18:56:44,817 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:44,817 [run_pretraining.py:  534]:	loss/total_loss, 7.41323709487915, 1293
[INFO] 2021-07-12 18:56:44,817 [run_pretraining.py:  535]:	loss/mlm_loss, 7.41323709487915, 1293
[INFO] 2021-07-12 18:56:44,817 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2919998880533967e-05, 1293
[INFO] 2021-07-12 18:56:44,818 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1293
[INFO] 2021-07-12 18:56:44,818 [run_pretraining.py:  558]:	worker_index: 6, step: 1293, cost: 7.413237, mlm loss: 7.413237, speed: 1.104083 steps/s, speed: 8.832661 samples/s, speed: 4522.322539 tokens/s, learning rate: 1.292e-05, loss_scalings: 10737.418945, pp_loss: 7.137672
[INFO] 2021-07-12 18:56:44,818 [run_pretraining.py:  512]:	********exe.run_1293******* 
[INFO] 2021-07-12 18:56:45,730 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:45,731 [run_pretraining.py:  534]:	loss/total_loss, 8.131194114685059, 1294
[INFO] 2021-07-12 18:56:45,731 [run_pretraining.py:  535]:	loss/mlm_loss, 8.131194114685059, 1294
[INFO] 2021-07-12 18:56:45,731 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2929999684274662e-05, 1294
[INFO] 2021-07-12 18:56:45,731 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1294
[INFO] 2021-07-12 18:56:45,731 [run_pretraining.py:  558]:	worker_index: 6, step: 1294, cost: 8.131194, mlm loss: 8.131194, speed: 1.095265 steps/s, speed: 8.762122 samples/s, speed: 4486.206425 tokens/s, learning rate: 1.293e-05, loss_scalings: 10737.418945, pp_loss: 7.863003
[INFO] 2021-07-12 18:56:45,731 [run_pretraining.py:  512]:	********exe.run_1294******* 
[INFO] 2021-07-12 18:56:46,624 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:46,625 [run_pretraining.py:  534]:	loss/total_loss, 7.610564231872559, 1295
[INFO] 2021-07-12 18:56:46,625 [run_pretraining.py:  535]:	loss/mlm_loss, 7.610564231872559, 1295
[INFO] 2021-07-12 18:56:46,625 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2939999578520656e-05, 1295
[INFO] 2021-07-12 18:56:46,625 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1295
[INFO] 2021-07-12 18:56:46,625 [run_pretraining.py:  558]:	worker_index: 6, step: 1295, cost: 7.610564, mlm loss: 7.610564, speed: 1.119360 steps/s, speed: 8.954876 samples/s, speed: 4584.896676 tokens/s, learning rate: 1.294e-05, loss_scalings: 10737.418945, pp_loss: 7.664027
[INFO] 2021-07-12 18:56:46,626 [run_pretraining.py:  512]:	********exe.run_1295******* 
[INFO] 2021-07-12 18:56:47,532 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:47,533 [run_pretraining.py:  534]:	loss/total_loss, 7.185601711273193, 1296
[INFO] 2021-07-12 18:56:47,533 [run_pretraining.py:  535]:	loss/mlm_loss, 7.185601711273193, 1296
[INFO] 2021-07-12 18:56:47,535 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2949999472766649e-05, 1296
[INFO] 2021-07-12 18:56:47,545 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1296
[INFO] 2021-07-12 18:56:47,550 [run_pretraining.py:  558]:	worker_index: 6, step: 1296, cost: 7.185602, mlm loss: 7.185602, speed: 1.102528 steps/s, speed: 8.820221 samples/s, speed: 4515.953208 tokens/s, learning rate: 1.295e-05, loss_scalings: 10737.418945, pp_loss: 7.578135
[INFO] 2021-07-12 18:56:47,555 [run_pretraining.py:  512]:	********exe.run_1296******* 
[INFO] 2021-07-12 18:56:48,438 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:48,438 [run_pretraining.py:  534]:	loss/total_loss, 7.881553649902344, 1297
[INFO] 2021-07-12 18:56:48,438 [run_pretraining.py:  535]:	loss/mlm_loss, 7.881553649902344, 1297
[INFO] 2021-07-12 18:56:48,439 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2960000276507344e-05, 1297
[INFO] 2021-07-12 18:56:48,439 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1297
[INFO] 2021-07-12 18:56:48,439 [run_pretraining.py:  558]:	worker_index: 6, step: 1297, cost: 7.881554, mlm loss: 7.881554, speed: 1.132258 steps/s, speed: 9.058067 samples/s, speed: 4637.730352 tokens/s, learning rate: 1.296e-05, loss_scalings: 10737.418945, pp_loss: 7.533145
[INFO] 2021-07-12 18:56:48,439 [run_pretraining.py:  512]:	********exe.run_1297******* 
[INFO] 2021-07-12 18:56:49,333 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:49,333 [run_pretraining.py:  534]:	loss/total_loss, 8.1412992477417, 1298
[INFO] 2021-07-12 18:56:49,333 [run_pretraining.py:  535]:	loss/mlm_loss, 8.1412992477417, 1298
[INFO] 2021-07-12 18:56:49,334 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2970000170753337e-05, 1298
[INFO] 2021-07-12 18:56:49,334 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1298
[INFO] 2021-07-12 18:56:49,334 [run_pretraining.py:  558]:	worker_index: 6, step: 1298, cost: 8.141299, mlm loss: 8.141299, speed: 1.118160 steps/s, speed: 8.945279 samples/s, speed: 4579.983078 tokens/s, learning rate: 1.297e-05, loss_scalings: 10737.418945, pp_loss: 7.673342
[INFO] 2021-07-12 18:56:49,334 [run_pretraining.py:  512]:	********exe.run_1298******* 
[INFO] 2021-07-12 18:56:50,240 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:50,240 [run_pretraining.py:  534]:	loss/total_loss, 7.147955417633057, 1299
[INFO] 2021-07-12 18:56:50,240 [run_pretraining.py:  535]:	loss/mlm_loss, 7.147955417633057, 1299
[INFO] 2021-07-12 18:56:50,241 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.298000006499933e-05, 1299
[INFO] 2021-07-12 18:56:50,241 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1299
[INFO] 2021-07-12 18:56:50,241 [run_pretraining.py:  558]:	worker_index: 6, step: 1299, cost: 7.147955, mlm loss: 7.147955, speed: 1.103498 steps/s, speed: 8.827986 samples/s, speed: 4519.928666 tokens/s, learning rate: 1.298e-05, loss_scalings: 10737.418945, pp_loss: 7.507546
[INFO] 2021-07-12 18:56:50,241 [run_pretraining.py:  512]:	********exe.run_1299******* 
[INFO] 2021-07-12 18:56:51,224 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:51,225 [run_pretraining.py:  534]:	loss/total_loss, 8.02987289428711, 1300
[INFO] 2021-07-12 18:56:51,225 [run_pretraining.py:  535]:	loss/mlm_loss, 8.02987289428711, 1300
[INFO] 2021-07-12 18:56:51,225 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2989999049750622e-05, 1300
[INFO] 2021-07-12 18:56:51,225 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1300
[INFO] 2021-07-12 18:56:51,225 [run_pretraining.py:  558]:	worker_index: 6, step: 1300, cost: 8.029873, mlm loss: 8.029873, speed: 1.016701 steps/s, speed: 8.133611 samples/s, speed: 4164.408912 tokens/s, learning rate: 1.299e-05, loss_scalings: 10737.418945, pp_loss: 7.511601
[INFO] 2021-07-12 18:56:51,225 [run_pretraining.py:  512]:	********exe.run_1300******* 
[INFO] 2021-07-12 18:56:52,148 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:52,148 [run_pretraining.py:  534]:	loss/total_loss, 4.997034549713135, 1301
[INFO] 2021-07-12 18:56:52,149 [run_pretraining.py:  535]:	loss/mlm_loss, 4.997034549713135, 1301
[INFO] 2021-07-12 18:56:52,149 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2999998943996616e-05, 1301
[INFO] 2021-07-12 18:56:52,149 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1301
[INFO] 2021-07-12 18:56:52,149 [run_pretraining.py:  558]:	worker_index: 6, step: 1301, cost: 4.997035, mlm loss: 4.997035, speed: 1.083212 steps/s, speed: 8.665698 samples/s, speed: 4436.837390 tokens/s, learning rate: 1.300e-05, loss_scalings: 10737.418945, pp_loss: 6.852387
[INFO] 2021-07-12 18:56:52,149 [run_pretraining.py:  512]:	********exe.run_1301******* 
[INFO] 2021-07-12 18:56:53,056 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:53,057 [run_pretraining.py:  534]:	loss/total_loss, 7.437295913696289, 1302
[INFO] 2021-07-12 18:56:53,057 [run_pretraining.py:  535]:	loss/mlm_loss, 7.437295913696289, 1302
[INFO] 2021-07-12 18:56:53,057 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.300999974773731e-05, 1302
[INFO] 2021-07-12 18:56:53,057 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1302
[INFO] 2021-07-12 18:56:53,057 [run_pretraining.py:  558]:	worker_index: 6, step: 1302, cost: 7.437296, mlm loss: 7.437296, speed: 1.101618 steps/s, speed: 8.812947 samples/s, speed: 4512.228859 tokens/s, learning rate: 1.301e-05, loss_scalings: 10737.418945, pp_loss: 7.601732
[INFO] 2021-07-12 18:56:53,057 [run_pretraining.py:  512]:	********exe.run_1302******* 
[INFO] 2021-07-12 18:56:53,952 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:53,953 [run_pretraining.py:  534]:	loss/total_loss, 7.787940502166748, 1303
[INFO] 2021-07-12 18:56:53,953 [run_pretraining.py:  535]:	loss/mlm_loss, 7.787940502166748, 1303
[INFO] 2021-07-12 18:56:53,953 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3019999641983304e-05, 1303
[INFO] 2021-07-12 18:56:53,953 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1303
[INFO] 2021-07-12 18:56:53,953 [run_pretraining.py:  558]:	worker_index: 6, step: 1303, cost: 7.787941, mlm loss: 7.787941, speed: 1.116897 steps/s, speed: 8.935180 samples/s, speed: 4574.811976 tokens/s, learning rate: 1.302e-05, loss_scalings: 10737.418945, pp_loss: 7.739240
[INFO] 2021-07-12 18:56:53,953 [run_pretraining.py:  512]:	********exe.run_1303******* 
[INFO] 2021-07-12 18:56:54,856 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:54,857 [run_pretraining.py:  534]:	loss/total_loss, 7.135340213775635, 1304
[INFO] 2021-07-12 18:56:54,857 [run_pretraining.py:  535]:	loss/mlm_loss, 7.135340213775635, 1304
[INFO] 2021-07-12 18:56:54,857 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3029999536229298e-05, 1304
[INFO] 2021-07-12 18:56:54,857 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1304
[INFO] 2021-07-12 18:56:54,857 [run_pretraining.py:  558]:	worker_index: 6, step: 1304, cost: 7.135340, mlm loss: 7.135340, speed: 1.107322 steps/s, speed: 8.858575 samples/s, speed: 4535.590581 tokens/s, learning rate: 1.303e-05, loss_scalings: 10737.418945, pp_loss: 7.423006
[INFO] 2021-07-12 18:56:54,857 [run_pretraining.py:  512]:	********exe.run_1304******* 
[INFO] 2021-07-12 18:56:55,774 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:55,775 [run_pretraining.py:  534]:	loss/total_loss, 8.029095649719238, 1305
[INFO] 2021-07-12 18:56:55,775 [run_pretraining.py:  535]:	loss/mlm_loss, 8.029095649719238, 1305
[INFO] 2021-07-12 18:56:55,775 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3039999430475291e-05, 1305
[INFO] 2021-07-12 18:56:55,775 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1305
[INFO] 2021-07-12 18:56:55,775 [run_pretraining.py:  558]:	worker_index: 6, step: 1305, cost: 8.029096, mlm loss: 8.029096, speed: 1.089948 steps/s, speed: 8.719584 samples/s, speed: 4464.426896 tokens/s, learning rate: 1.304e-05, loss_scalings: 10737.418945, pp_loss: 6.967056
[INFO] 2021-07-12 18:56:55,775 [run_pretraining.py:  512]:	********exe.run_1305******* 
[INFO] 2021-07-12 18:56:56,667 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:56,668 [run_pretraining.py:  534]:	loss/total_loss, 7.656157493591309, 1306
[INFO] 2021-07-12 18:56:56,668 [run_pretraining.py:  535]:	loss/mlm_loss, 7.656157493591309, 1306
[INFO] 2021-07-12 18:56:56,668 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3050000234215986e-05, 1306
[INFO] 2021-07-12 18:56:56,668 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1306
[INFO] 2021-07-12 18:56:56,668 [run_pretraining.py:  558]:	worker_index: 6, step: 1306, cost: 7.656157, mlm loss: 7.656157, speed: 1.121104 steps/s, speed: 8.968828 samples/s, speed: 4592.040149 tokens/s, learning rate: 1.305e-05, loss_scalings: 10737.418945, pp_loss: 7.541123
[INFO] 2021-07-12 18:56:56,668 [run_pretraining.py:  512]:	********exe.run_1306******* 
[INFO] 2021-07-12 18:56:57,597 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:57,598 [run_pretraining.py:  534]:	loss/total_loss, 7.736974716186523, 1307
[INFO] 2021-07-12 18:56:57,598 [run_pretraining.py:  535]:	loss/mlm_loss, 7.736974716186523, 1307
[INFO] 2021-07-12 18:56:57,598 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.306000012846198e-05, 1307
[INFO] 2021-07-12 18:56:57,598 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1307
[INFO] 2021-07-12 18:56:57,598 [run_pretraining.py:  558]:	worker_index: 6, step: 1307, cost: 7.736975, mlm loss: 7.736975, speed: 1.076046 steps/s, speed: 8.608364 samples/s, speed: 4407.482614 tokens/s, learning rate: 1.306e-05, loss_scalings: 10737.418945, pp_loss: 7.827914
[INFO] 2021-07-12 18:56:57,598 [run_pretraining.py:  512]:	********exe.run_1307******* 
[INFO] 2021-07-12 18:56:58,515 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:58,515 [run_pretraining.py:  534]:	loss/total_loss, 7.5542683601379395, 1308
[INFO] 2021-07-12 18:56:58,515 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5542683601379395, 1308
[INFO] 2021-07-12 18:56:58,515 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3070000022707973e-05, 1308
[INFO] 2021-07-12 18:56:58,516 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1308
[INFO] 2021-07-12 18:56:58,516 [run_pretraining.py:  558]:	worker_index: 6, step: 1308, cost: 7.554268, mlm loss: 7.554268, speed: 1.090674 steps/s, speed: 8.725391 samples/s, speed: 4467.400001 tokens/s, learning rate: 1.307e-05, loss_scalings: 10737.418945, pp_loss: 7.513126
[INFO] 2021-07-12 18:56:58,516 [run_pretraining.py:  512]:	********exe.run_1308******* 
[INFO] 2021-07-12 18:56:59,494 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:59,495 [run_pretraining.py:  534]:	loss/total_loss, 8.002655029296875, 1309
[INFO] 2021-07-12 18:56:59,495 [run_pretraining.py:  535]:	loss/mlm_loss, 8.002655029296875, 1309
[INFO] 2021-07-12 18:56:59,495 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3079999007459264e-05, 1309
[INFO] 2021-07-12 18:56:59,495 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1309
[INFO] 2021-07-12 18:56:59,495 [run_pretraining.py:  558]:	worker_index: 6, step: 1309, cost: 8.002655, mlm loss: 8.002655, speed: 1.021899 steps/s, speed: 8.175189 samples/s, speed: 4185.696548 tokens/s, learning rate: 1.308e-05, loss_scalings: 10737.418945, pp_loss: 7.443001
[INFO] 2021-07-12 18:56:59,495 [run_pretraining.py:  512]:	********exe.run_1309******* 
[INFO] 2021-07-12 18:57:00,557 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:57:00,557 [run_pretraining.py:  534]:	loss/total_loss, 7.517635345458984, 1310
[INFO] 2021-07-12 18:57:00,557 [run_pretraining.py:  535]:	loss/mlm_loss, 7.517635345458984, 1310
[INFO] 2021-07-12 18:57:00,558 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3089998901705258e-05, 1310
[INFO] 2021-07-12 18:57:00,558 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1310
[INFO] 2021-07-12 18:57:00,558 [run_pretraining.py:  558]:	worker_index: 6, step: 1310, cost: 7.517635, mlm loss: 7.517635, speed: 0.941555 steps/s, speed: 7.532439 samples/s, speed: 3856.608754 tokens/s, learning rate: 1.309e-05, loss_scalings: 10737.418945, pp_loss: 7.120610
[INFO] 2021-07-12 18:57:00,558 [run_pretraining.py:  512]:	********exe.run_1310******* 
[INFO] 2021-07-12 18:57:28,146 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:57:28,147 [run_pretraining.py:  534]:	loss/total_loss, 8.040999412536621, 1311
[INFO] 2021-07-12 18:57:28,147 [run_pretraining.py:  535]:	loss/mlm_loss, 8.040999412536621, 1311
[INFO] 2021-07-12 18:57:28,147 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3099999705445953e-05, 1311
[INFO] 2021-07-12 18:57:28,147 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1311
[INFO] 2021-07-12 18:57:28,147 [run_pretraining.py:  558]:	worker_index: 6, step: 1311, cost: 8.040999, mlm loss: 8.040999, speed: 0.036247 steps/s, speed: 0.289975 samples/s, speed: 148.467358 tokens/s, learning rate: 1.310e-05, loss_scalings: 10737.418945, pp_loss: 7.808847
[INFO] 2021-07-12 18:57:28,147 [run_pretraining.py:  512]:	********exe.run_1311******* 
[INFO] 2021-07-12 18:57:56,314 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:57:56,315 [run_pretraining.py:  534]:	loss/total_loss, 7.597214221954346, 1312
[INFO] 2021-07-12 18:57:56,315 [run_pretraining.py:  535]:	loss/mlm_loss, 7.597214221954346, 1312
[INFO] 2021-07-12 18:57:56,315 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3109999599691946e-05, 1312
[INFO] 2021-07-12 18:57:56,315 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1312
[INFO] 2021-07-12 18:57:56,315 [run_pretraining.py:  558]:	worker_index: 6, step: 1312, cost: 7.597214, mlm loss: 7.597214, speed: 0.035502 steps/s, speed: 0.284017 samples/s, speed: 145.416483 tokens/s, learning rate: 1.311e-05, loss_scalings: 10737.418945, pp_loss: 7.957086
[INFO] 2021-07-12 18:57:56,315 [run_pretraining.py:  512]:	********exe.run_1312******* 
[INFO] 2021-07-12 18:57:57,250 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:57:57,251 [run_pretraining.py:  534]:	loss/total_loss, 7.316786289215088, 1313
[INFO] 2021-07-12 18:57:57,251 [run_pretraining.py:  535]:	loss/mlm_loss, 7.316786289215088, 1313
[INFO] 2021-07-12 18:57:57,251 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.311999949393794e-05, 1313
[INFO] 2021-07-12 18:57:57,251 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1313
[INFO] 2021-07-12 18:57:57,252 [run_pretraining.py:  558]:	worker_index: 6, step: 1313, cost: 7.316786, mlm loss: 7.316786, speed: 1.068761 steps/s, speed: 8.550087 samples/s, speed: 4377.644586 tokens/s, learning rate: 1.312e-05, loss_scalings: 10737.418945, pp_loss: 7.286828
[INFO] 2021-07-12 18:57:57,252 [run_pretraining.py:  512]:	********exe.run_1313******* 
[INFO] 2021-07-12 18:57:58,173 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:57:58,174 [run_pretraining.py:  534]:	loss/total_loss, 7.535065650939941, 1314
[INFO] 2021-07-12 18:57:58,174 [run_pretraining.py:  535]:	loss/mlm_loss, 7.535065650939941, 1314
[INFO] 2021-07-12 18:57:58,174 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3130000297678635e-05, 1314
[INFO] 2021-07-12 18:57:58,174 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1314
[INFO] 2021-07-12 18:57:58,174 [run_pretraining.py:  558]:	worker_index: 6, step: 1314, cost: 7.535066, mlm loss: 7.535066, speed: 1.084879 steps/s, speed: 8.679030 samples/s, speed: 4443.663382 tokens/s, learning rate: 1.313e-05, loss_scalings: 10737.418945, pp_loss: 7.523341
[INFO] 2021-07-12 18:57:58,174 [run_pretraining.py:  512]:	********exe.run_1314******* 
[INFO] 2021-07-12 18:57:59,130 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:57:59,130 [run_pretraining.py:  534]:	loss/total_loss, 7.221179962158203, 1315
[INFO] 2021-07-12 18:57:59,131 [run_pretraining.py:  535]:	loss/mlm_loss, 7.221179962158203, 1315
[INFO] 2021-07-12 18:57:59,131 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3140000191924628e-05, 1315
[INFO] 2021-07-12 18:57:59,131 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1315
[INFO] 2021-07-12 18:57:59,131 [run_pretraining.py:  558]:	worker_index: 6, step: 1315, cost: 7.221180, mlm loss: 7.221180, speed: 1.045837 steps/s, speed: 8.366696 samples/s, speed: 4283.748160 tokens/s, learning rate: 1.314e-05, loss_scalings: 10737.418945, pp_loss: 7.115850
[INFO] 2021-07-12 18:57:59,131 [run_pretraining.py:  512]:	********exe.run_1315******* 
[INFO] 2021-07-12 18:58:00,191 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:00,192 [run_pretraining.py:  534]:	loss/total_loss, 7.449796676635742, 1316
[INFO] 2021-07-12 18:58:00,192 [run_pretraining.py:  535]:	loss/mlm_loss, 7.449796676635742, 1316
[INFO] 2021-07-12 18:58:00,192 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3150000086170621e-05, 1316
[INFO] 2021-07-12 18:58:00,192 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1316
[INFO] 2021-07-12 18:58:00,192 [run_pretraining.py:  558]:	worker_index: 6, step: 1316, cost: 7.449797, mlm loss: 7.449797, speed: 0.942734 steps/s, speed: 7.541871 samples/s, speed: 3861.437874 tokens/s, learning rate: 1.315e-05, loss_scalings: 10737.418945, pp_loss: 7.457226
[INFO] 2021-07-12 18:58:00,192 [run_pretraining.py:  512]:	********exe.run_1316******* 
[INFO] 2021-07-12 18:58:01,256 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:01,257 [run_pretraining.py:  534]:	loss/total_loss, 7.475024223327637, 1317
[INFO] 2021-07-12 18:58:01,257 [run_pretraining.py:  535]:	loss/mlm_loss, 7.475024223327637, 1317
[INFO] 2021-07-12 18:58:01,257 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3159999980416615e-05, 1317
[INFO] 2021-07-12 18:58:01,257 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1317
[INFO] 2021-07-12 18:58:01,257 [run_pretraining.py:  558]:	worker_index: 6, step: 1317, cost: 7.475024, mlm loss: 7.475024, speed: 0.939443 steps/s, speed: 7.515542 samples/s, speed: 3847.957741 tokens/s, learning rate: 1.316e-05, loss_scalings: 10737.418945, pp_loss: 7.310334
[INFO] 2021-07-12 18:58:01,258 [run_pretraining.py:  512]:	********exe.run_1317******* 
[INFO] 2021-07-12 18:58:02,341 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:02,342 [run_pretraining.py:  534]:	loss/total_loss, 6.411802291870117, 1318
[INFO] 2021-07-12 18:58:02,342 [run_pretraining.py:  535]:	loss/mlm_loss, 6.411802291870117, 1318
[INFO] 2021-07-12 18:58:02,342 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3169998965167906e-05, 1318
[INFO] 2021-07-12 18:58:02,342 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1318
[INFO] 2021-07-12 18:58:02,342 [run_pretraining.py:  558]:	worker_index: 6, step: 1318, cost: 6.411802, mlm loss: 6.411802, speed: 0.922784 steps/s, speed: 7.382268 samples/s, speed: 3779.721351 tokens/s, learning rate: 1.317e-05, loss_scalings: 10737.418945, pp_loss: 7.054558
[INFO] 2021-07-12 18:58:02,342 [run_pretraining.py:  512]:	********exe.run_1318******* 
[INFO] 2021-07-12 18:58:03,405 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:03,405 [run_pretraining.py:  534]:	loss/total_loss, 7.031712055206299, 1319
[INFO] 2021-07-12 18:58:03,405 [run_pretraining.py:  535]:	loss/mlm_loss, 7.031712055206299, 1319
[INFO] 2021-07-12 18:58:03,406 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.31799988594139e-05, 1319
[INFO] 2021-07-12 18:58:03,406 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1319
[INFO] 2021-07-12 18:58:03,406 [run_pretraining.py:  558]:	worker_index: 6, step: 1319, cost: 7.031712, mlm loss: 7.031712, speed: 0.940614 steps/s, speed: 7.524915 samples/s, speed: 3852.756566 tokens/s, learning rate: 1.318e-05, loss_scalings: 10737.418945, pp_loss: 7.702241
[INFO] 2021-07-12 18:58:03,406 [run_pretraining.py:  512]:	********exe.run_1319******* 
[INFO] 2021-07-12 18:58:04,469 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:04,469 [run_pretraining.py:  534]:	loss/total_loss, 7.90792179107666, 1320
[INFO] 2021-07-12 18:58:04,470 [run_pretraining.py:  535]:	loss/mlm_loss, 7.90792179107666, 1320
[INFO] 2021-07-12 18:58:04,470 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3189999663154595e-05, 1320
[INFO] 2021-07-12 18:58:04,470 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1320
[INFO] 2021-07-12 18:58:04,470 [run_pretraining.py:  558]:	worker_index: 6, step: 1320, cost: 7.907922, mlm loss: 7.907922, speed: 0.940429 steps/s, speed: 7.523434 samples/s, speed: 3851.998107 tokens/s, learning rate: 1.319e-05, loss_scalings: 10737.418945, pp_loss: 7.627342
[INFO] 2021-07-12 18:58:04,470 [run_pretraining.py:  512]:	********exe.run_1320******* 
[INFO] 2021-07-12 18:58:05,519 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:05,520 [run_pretraining.py:  534]:	loss/total_loss, 7.658090591430664, 1321
[INFO] 2021-07-12 18:58:05,520 [run_pretraining.py:  535]:	loss/mlm_loss, 7.658090591430664, 1321
[INFO] 2021-07-12 18:58:05,520 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3199999557400588e-05, 1321
[INFO] 2021-07-12 18:58:05,520 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1321
[INFO] 2021-07-12 18:58:05,520 [run_pretraining.py:  558]:	worker_index: 6, step: 1321, cost: 7.658091, mlm loss: 7.658091, speed: 0.952936 steps/s, speed: 7.623488 samples/s, speed: 3903.225885 tokens/s, learning rate: 1.320e-05, loss_scalings: 10737.418945, pp_loss: 7.653767
[INFO] 2021-07-12 18:58:05,520 [run_pretraining.py:  512]:	********exe.run_1321******* 
[INFO] 2021-07-12 18:58:06,583 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:06,584 [run_pretraining.py:  534]:	loss/total_loss, 7.932867050170898, 1322
[INFO] 2021-07-12 18:58:06,584 [run_pretraining.py:  535]:	loss/mlm_loss, 7.932867050170898, 1322
[INFO] 2021-07-12 18:58:06,584 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3209999451646581e-05, 1322
[INFO] 2021-07-12 18:58:06,584 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1322
[INFO] 2021-07-12 18:58:06,584 [run_pretraining.py:  558]:	worker_index: 6, step: 1322, cost: 7.932867, mlm loss: 7.932867, speed: 0.940086 steps/s, speed: 7.520690 samples/s, speed: 3850.593414 tokens/s, learning rate: 1.321e-05, loss_scalings: 10737.418945, pp_loss: 7.695752
[INFO] 2021-07-12 18:58:06,584 [run_pretraining.py:  512]:	********exe.run_1322******* 
[INFO] 2021-07-12 18:58:07,648 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:07,649 [run_pretraining.py:  534]:	loss/total_loss, 8.177996635437012, 1323
[INFO] 2021-07-12 18:58:07,649 [run_pretraining.py:  535]:	loss/mlm_loss, 8.177996635437012, 1323
[INFO] 2021-07-12 18:58:07,649 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3220000255387276e-05, 1323
[INFO] 2021-07-12 18:58:07,649 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1323
[INFO] 2021-07-12 18:58:07,649 [run_pretraining.py:  558]:	worker_index: 6, step: 1323, cost: 8.177997, mlm loss: 8.177997, speed: 0.939556 steps/s, speed: 7.516447 samples/s, speed: 3848.420620 tokens/s, learning rate: 1.322e-05, loss_scalings: 10737.418945, pp_loss: 7.539520
[INFO] 2021-07-12 18:58:07,649 [run_pretraining.py:  512]:	********exe.run_1323******* 
[INFO] 2021-07-12 18:58:08,703 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:08,704 [run_pretraining.py:  534]:	loss/total_loss, 7.859685897827148, 1324
[INFO] 2021-07-12 18:58:08,704 [run_pretraining.py:  535]:	loss/mlm_loss, 7.859685897827148, 1324
[INFO] 2021-07-12 18:58:08,704 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.323000014963327e-05, 1324
[INFO] 2021-07-12 18:58:08,704 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1324
[INFO] 2021-07-12 18:58:08,704 [run_pretraining.py:  558]:	worker_index: 6, step: 1324, cost: 7.859686, mlm loss: 7.859686, speed: 0.948506 steps/s, speed: 7.588045 samples/s, speed: 3885.078851 tokens/s, learning rate: 1.323e-05, loss_scalings: 10737.418945, pp_loss: 7.748245
[INFO] 2021-07-12 18:58:08,704 [run_pretraining.py:  512]:	********exe.run_1324******* 
[INFO] 2021-07-12 18:58:09,765 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:09,765 [run_pretraining.py:  534]:	loss/total_loss, 7.319119453430176, 1325
[INFO] 2021-07-12 18:58:09,765 [run_pretraining.py:  535]:	loss/mlm_loss, 7.319119453430176, 1325
[INFO] 2021-07-12 18:58:09,765 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3240000043879263e-05, 1325
[INFO] 2021-07-12 18:58:09,765 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1325
[INFO] 2021-07-12 18:58:09,766 [run_pretraining.py:  558]:	worker_index: 6, step: 1325, cost: 7.319119, mlm loss: 7.319119, speed: 0.942985 steps/s, speed: 7.543882 samples/s, speed: 3862.467498 tokens/s, learning rate: 1.324e-05, loss_scalings: 10737.418945, pp_loss: 7.460253
[INFO] 2021-07-12 18:58:09,766 [run_pretraining.py:  512]:	********exe.run_1325******* 
[INFO] 2021-07-12 18:58:10,829 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:10,829 [run_pretraining.py:  534]:	loss/total_loss, 7.2181077003479, 1326
[INFO] 2021-07-12 18:58:10,829 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2181077003479, 1326
[INFO] 2021-07-12 18:58:10,829 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3249999028630555e-05, 1326
[INFO] 2021-07-12 18:58:10,829 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1326
[INFO] 2021-07-12 18:58:10,830 [run_pretraining.py:  558]:	worker_index: 6, step: 1326, cost: 7.218108, mlm loss: 7.218108, speed: 0.940459 steps/s, speed: 7.523672 samples/s, speed: 3852.119889 tokens/s, learning rate: 1.325e-05, loss_scalings: 10737.418945, pp_loss: 7.234899
[INFO] 2021-07-12 18:58:10,830 [run_pretraining.py:  512]:	********exe.run_1326******* 
[INFO] 2021-07-12 18:58:11,889 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:11,890 [run_pretraining.py:  534]:	loss/total_loss, 6.770173072814941, 1327
[INFO] 2021-07-12 18:58:11,890 [run_pretraining.py:  535]:	loss/mlm_loss, 6.770173072814941, 1327
[INFO] 2021-07-12 18:58:11,890 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3259998922876548e-05, 1327
[INFO] 2021-07-12 18:58:11,890 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1327
[INFO] 2021-07-12 18:58:11,890 [run_pretraining.py:  558]:	worker_index: 6, step: 1327, cost: 6.770173, mlm loss: 6.770173, speed: 0.943417 steps/s, speed: 7.547338 samples/s, speed: 3864.237198 tokens/s, learning rate: 1.326e-05, loss_scalings: 10737.418945, pp_loss: 7.317001
[INFO] 2021-07-12 18:58:11,890 [run_pretraining.py:  512]:	********exe.run_1327******* 
[INFO] 2021-07-12 18:58:12,964 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:12,964 [run_pretraining.py:  534]:	loss/total_loss, 7.6043171882629395, 1328
[INFO] 2021-07-12 18:58:12,965 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6043171882629395, 1328
[INFO] 2021-07-12 18:58:12,965 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3269999726617243e-05, 1328
[INFO] 2021-07-12 18:58:12,965 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1328
[INFO] 2021-07-12 18:58:12,965 [run_pretraining.py:  558]:	worker_index: 6, step: 1328, cost: 7.604317, mlm loss: 7.604317, speed: 0.931272 steps/s, speed: 7.450173 samples/s, speed: 3814.488591 tokens/s, learning rate: 1.327e-05, loss_scalings: 10737.418945, pp_loss: 7.877146
[INFO] 2021-07-12 18:58:12,965 [run_pretraining.py:  512]:	********exe.run_1328******* 
[INFO] 2021-07-12 18:58:14,041 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:14,042 [run_pretraining.py:  534]:	loss/total_loss, 7.927229881286621, 1329
[INFO] 2021-07-12 18:58:14,042 [run_pretraining.py:  535]:	loss/mlm_loss, 7.927229881286621, 1329
[INFO] 2021-07-12 18:58:14,042 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3279999620863236e-05, 1329
[INFO] 2021-07-12 18:58:14,042 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1329
[INFO] 2021-07-12 18:58:14,042 [run_pretraining.py:  558]:	worker_index: 6, step: 1329, cost: 7.927230, mlm loss: 7.927230, speed: 0.928726 steps/s, speed: 7.429806 samples/s, speed: 3804.060851 tokens/s, learning rate: 1.328e-05, loss_scalings: 10737.418945, pp_loss: 7.686913
[INFO] 2021-07-12 18:58:14,042 [run_pretraining.py:  512]:	********exe.run_1329******* 
[INFO] 2021-07-12 18:58:15,110 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:15,110 [run_pretraining.py:  534]:	loss/total_loss, 7.369311332702637, 1330
[INFO] 2021-07-12 18:58:15,110 [run_pretraining.py:  535]:	loss/mlm_loss, 7.369311332702637, 1330
[INFO] 2021-07-12 18:58:15,110 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.328999951510923e-05, 1330
[INFO] 2021-07-12 18:58:15,111 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1330
[INFO] 2021-07-12 18:58:15,111 [run_pretraining.py:  558]:	worker_index: 6, step: 1330, cost: 7.369311, mlm loss: 7.369311, speed: 0.936610 steps/s, speed: 7.492879 samples/s, speed: 3836.354173 tokens/s, learning rate: 1.329e-05, loss_scalings: 10737.418945, pp_loss: 7.601846
[INFO] 2021-07-12 18:58:15,111 [run_pretraining.py:  512]:	********exe.run_1330******* 
[INFO] 2021-07-12 18:58:16,163 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:16,164 [run_pretraining.py:  534]:	loss/total_loss, 7.585968017578125, 1331
[INFO] 2021-07-12 18:58:16,164 [run_pretraining.py:  535]:	loss/mlm_loss, 7.585968017578125, 1331
[INFO] 2021-07-12 18:58:16,164 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3299999409355223e-05, 1331
[INFO] 2021-07-12 18:58:16,164 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1331
[INFO] 2021-07-12 18:58:16,164 [run_pretraining.py:  558]:	worker_index: 6, step: 1331, cost: 7.585968, mlm loss: 7.585968, speed: 0.949582 steps/s, speed: 7.596653 samples/s, speed: 3889.486395 tokens/s, learning rate: 1.330e-05, loss_scalings: 10737.418945, pp_loss: 7.514777
[INFO] 2021-07-12 18:58:16,164 [run_pretraining.py:  512]:	********exe.run_1331******* 
[INFO] 2021-07-12 18:58:17,233 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:17,234 [run_pretraining.py:  534]:	loss/total_loss, 7.538736820220947, 1332
[INFO] 2021-07-12 18:58:17,234 [run_pretraining.py:  535]:	loss/mlm_loss, 7.538736820220947, 1332
[INFO] 2021-07-12 18:58:17,234 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3310000213095918e-05, 1332
[INFO] 2021-07-12 18:58:17,234 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1332
[INFO] 2021-07-12 18:58:17,234 [run_pretraining.py:  558]:	worker_index: 6, step: 1332, cost: 7.538737, mlm loss: 7.538737, speed: 0.935140 steps/s, speed: 7.481120 samples/s, speed: 3830.333481 tokens/s, learning rate: 1.331e-05, loss_scalings: 10737.418945, pp_loss: 7.485281
[INFO] 2021-07-12 18:58:17,235 [run_pretraining.py:  512]:	********exe.run_1332******* 
[INFO] 2021-07-12 18:58:18,292 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:18,292 [run_pretraining.py:  534]:	loss/total_loss, 7.16603946685791, 1333
[INFO] 2021-07-12 18:58:18,293 [run_pretraining.py:  535]:	loss/mlm_loss, 7.16603946685791, 1333
[INFO] 2021-07-12 18:58:18,293 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3320000107341912e-05, 1333
[INFO] 2021-07-12 18:58:18,293 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1333
[INFO] 2021-07-12 18:58:18,293 [run_pretraining.py:  558]:	worker_index: 6, step: 1333, cost: 7.166039, mlm loss: 7.166039, speed: 0.945491 steps/s, speed: 7.563928 samples/s, speed: 3872.731163 tokens/s, learning rate: 1.332e-05, loss_scalings: 10737.418945, pp_loss: 7.635390
[INFO] 2021-07-12 18:58:18,293 [run_pretraining.py:  512]:	********exe.run_1333******* 
[INFO] 2021-07-12 18:58:47,360 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:47,360 [run_pretraining.py:  534]:	loss/total_loss, 7.798172473907471, 1334
[INFO] 2021-07-12 18:58:47,361 [run_pretraining.py:  535]:	loss/mlm_loss, 7.798172473907471, 1334
[INFO] 2021-07-12 18:58:47,361 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3330000001587905e-05, 1334
[INFO] 2021-07-12 18:58:47,361 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1334
[INFO] 2021-07-12 18:58:47,361 [run_pretraining.py:  558]:	worker_index: 6, step: 1334, cost: 7.798172, mlm loss: 7.798172, speed: 0.034403 steps/s, speed: 0.275224 samples/s, speed: 140.914570 tokens/s, learning rate: 1.333e-05, loss_scalings: 10737.418945, pp_loss: 7.863542
[INFO] 2021-07-12 18:58:47,361 [run_pretraining.py:  512]:	********exe.run_1334******* 
[INFO] 2021-07-12 18:58:48,254 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:48,255 [run_pretraining.py:  534]:	loss/total_loss, 6.6914472579956055, 1335
[INFO] 2021-07-12 18:58:48,255 [run_pretraining.py:  535]:	loss/mlm_loss, 6.6914472579956055, 1335
[INFO] 2021-07-12 18:58:48,255 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3339998986339197e-05, 1335
[INFO] 2021-07-12 18:58:48,255 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1335
[INFO] 2021-07-12 18:58:48,256 [run_pretraining.py:  558]:	worker_index: 6, step: 1335, cost: 6.691447, mlm loss: 6.691447, speed: 1.118622 steps/s, speed: 8.948980 samples/s, speed: 4581.877598 tokens/s, learning rate: 1.334e-05, loss_scalings: 10737.418945, pp_loss: 7.646137
[INFO] 2021-07-12 18:58:48,256 [run_pretraining.py:  512]:	********exe.run_1335******* 
[INFO] 2021-07-12 18:58:49,147 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:49,148 [run_pretraining.py:  534]:	loss/total_loss, 7.270875453948975, 1336
[INFO] 2021-07-12 18:58:49,148 [run_pretraining.py:  535]:	loss/mlm_loss, 7.270875453948975, 1336
[INFO] 2021-07-12 18:58:49,148 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.334999888058519e-05, 1336
[INFO] 2021-07-12 18:58:49,148 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1336
[INFO] 2021-07-12 18:58:49,148 [run_pretraining.py:  558]:	worker_index: 6, step: 1336, cost: 7.270875, mlm loss: 7.270875, speed: 1.120867 steps/s, speed: 8.966940 samples/s, speed: 4591.073150 tokens/s, learning rate: 1.335e-05, loss_scalings: 10737.418945, pp_loss: 7.354121
[INFO] 2021-07-12 18:58:49,148 [run_pretraining.py:  512]:	********exe.run_1336******* 
[INFO] 2021-07-12 18:58:50,052 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:50,053 [run_pretraining.py:  534]:	loss/total_loss, 5.251064300537109, 1337
[INFO] 2021-07-12 18:58:50,053 [run_pretraining.py:  535]:	loss/mlm_loss, 5.251064300537109, 1337
[INFO] 2021-07-12 18:58:50,053 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3359999684325885e-05, 1337
[INFO] 2021-07-12 18:58:50,053 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1337
[INFO] 2021-07-12 18:58:50,053 [run_pretraining.py:  558]:	worker_index: 6, step: 1337, cost: 5.251064, mlm loss: 5.251064, speed: 1.106083 steps/s, speed: 8.848668 samples/s, speed: 4530.517987 tokens/s, learning rate: 1.336e-05, loss_scalings: 10737.418945, pp_loss: 7.175144
[INFO] 2021-07-12 18:58:50,053 [run_pretraining.py:  512]:	********exe.run_1337******* 
[INFO] 2021-07-12 18:58:50,954 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:50,955 [run_pretraining.py:  534]:	loss/total_loss, 7.575926780700684, 1338
[INFO] 2021-07-12 18:58:50,955 [run_pretraining.py:  535]:	loss/mlm_loss, 7.575926780700684, 1338
[INFO] 2021-07-12 18:58:50,955 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3369999578571878e-05, 1338
[INFO] 2021-07-12 18:58:50,955 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1338
[INFO] 2021-07-12 18:58:50,955 [run_pretraining.py:  558]:	worker_index: 6, step: 1338, cost: 7.575927, mlm loss: 7.575927, speed: 1.109689 steps/s, speed: 8.877510 samples/s, speed: 4545.285245 tokens/s, learning rate: 1.337e-05, loss_scalings: 10737.418945, pp_loss: 7.618508
[INFO] 2021-07-12 18:58:50,955 [run_pretraining.py:  512]:	********exe.run_1338******* 
[INFO] 2021-07-12 18:58:51,846 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:51,847 [run_pretraining.py:  534]:	loss/total_loss, 7.1806817054748535, 1339
[INFO] 2021-07-12 18:58:51,847 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1806817054748535, 1339
[INFO] 2021-07-12 18:58:51,847 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3379999472817872e-05, 1339
[INFO] 2021-07-12 18:58:51,847 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1339
[INFO] 2021-07-12 18:58:51,847 [run_pretraining.py:  558]:	worker_index: 6, step: 1339, cost: 7.180682, mlm loss: 7.180682, speed: 1.121508 steps/s, speed: 8.972066 samples/s, speed: 4593.697758 tokens/s, learning rate: 1.338e-05, loss_scalings: 10737.418945, pp_loss: 7.788575
[INFO] 2021-07-12 18:58:51,848 [run_pretraining.py:  512]:	********exe.run_1339******* 
[INFO] 2021-07-12 18:58:52,767 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:52,767 [run_pretraining.py:  534]:	loss/total_loss, 8.135330200195312, 1340
[INFO] 2021-07-12 18:58:52,767 [run_pretraining.py:  535]:	loss/mlm_loss, 8.135330200195312, 1340
[INFO] 2021-07-12 18:58:52,767 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3390000276558567e-05, 1340
[INFO] 2021-07-12 18:58:52,768 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1340
[INFO] 2021-07-12 18:58:52,768 [run_pretraining.py:  558]:	worker_index: 6, step: 1340, cost: 8.135330, mlm loss: 8.135330, speed: 1.087581 steps/s, speed: 8.700648 samples/s, speed: 4454.731797 tokens/s, learning rate: 1.339e-05, loss_scalings: 10737.418945, pp_loss: 7.801630
[INFO] 2021-07-12 18:58:52,768 [run_pretraining.py:  512]:	********exe.run_1340******* 
[INFO] 2021-07-12 18:58:53,657 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:53,658 [run_pretraining.py:  534]:	loss/total_loss, 6.831409931182861, 1341
[INFO] 2021-07-12 18:58:53,658 [run_pretraining.py:  535]:	loss/mlm_loss, 6.831409931182861, 1341
[INFO] 2021-07-12 18:58:53,658 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.340000017080456e-05, 1341
[INFO] 2021-07-12 18:58:53,658 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1341
[INFO] 2021-07-12 18:58:53,658 [run_pretraining.py:  558]:	worker_index: 6, step: 1341, cost: 6.831410, mlm loss: 6.831410, speed: 1.123927 steps/s, speed: 8.991420 samples/s, speed: 4603.606914 tokens/s, learning rate: 1.340e-05, loss_scalings: 10737.418945, pp_loss: 7.597421
[INFO] 2021-07-12 18:58:53,658 [run_pretraining.py:  512]:	********exe.run_1341******* 
[INFO] 2021-07-12 18:58:54,565 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:54,565 [run_pretraining.py:  534]:	loss/total_loss, 7.584760665893555, 1342
[INFO] 2021-07-12 18:58:54,565 [run_pretraining.py:  535]:	loss/mlm_loss, 7.584760665893555, 1342
[INFO] 2021-07-12 18:58:54,566 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3410000065050554e-05, 1342
[INFO] 2021-07-12 18:58:54,566 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1342
[INFO] 2021-07-12 18:58:54,566 [run_pretraining.py:  558]:	worker_index: 6, step: 1342, cost: 7.584761, mlm loss: 7.584761, speed: 1.102649 steps/s, speed: 8.821190 samples/s, speed: 4516.449461 tokens/s, learning rate: 1.341e-05, loss_scalings: 10737.418945, pp_loss: 7.588680
[INFO] 2021-07-12 18:58:54,566 [run_pretraining.py:  512]:	********exe.run_1342******* 
[INFO] 2021-07-12 18:58:55,464 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:55,464 [run_pretraining.py:  534]:	loss/total_loss, 7.013088226318359, 1343
[INFO] 2021-07-12 18:58:55,464 [run_pretraining.py:  535]:	loss/mlm_loss, 7.013088226318359, 1343
[INFO] 2021-07-12 18:58:55,464 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3419999959296547e-05, 1343
[INFO] 2021-07-12 18:58:55,464 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1343
[INFO] 2021-07-12 18:58:55,465 [run_pretraining.py:  558]:	worker_index: 6, step: 1343, cost: 7.013088, mlm loss: 7.013088, speed: 1.113397 steps/s, speed: 8.907172 samples/s, speed: 4560.472292 tokens/s, learning rate: 1.342e-05, loss_scalings: 10737.418945, pp_loss: 7.230917
[INFO] 2021-07-12 18:58:55,465 [run_pretraining.py:  512]:	********exe.run_1343******* 
[INFO] 2021-07-12 18:58:56,374 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:56,375 [run_pretraining.py:  534]:	loss/total_loss, 7.912047386169434, 1344
[INFO] 2021-07-12 18:58:56,375 [run_pretraining.py:  535]:	loss/mlm_loss, 7.912047386169434, 1344
[INFO] 2021-07-12 18:58:56,375 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3429998944047838e-05, 1344
[INFO] 2021-07-12 18:58:56,375 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1344
[INFO] 2021-07-12 18:58:56,375 [run_pretraining.py:  558]:	worker_index: 6, step: 1344, cost: 7.912047, mlm loss: 7.912047, speed: 1.099018 steps/s, speed: 8.792143 samples/s, speed: 4501.577315 tokens/s, learning rate: 1.343e-05, loss_scalings: 10737.418945, pp_loss: 7.452948
[INFO] 2021-07-12 18:58:56,375 [run_pretraining.py:  512]:	********exe.run_1344******* 
[INFO] 2021-07-12 18:58:57,273 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:57,274 [run_pretraining.py:  534]:	loss/total_loss, 7.8090715408325195, 1345
[INFO] 2021-07-12 18:58:57,274 [run_pretraining.py:  535]:	loss/mlm_loss, 7.8090715408325195, 1345
[INFO] 2021-07-12 18:58:57,274 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3439998838293832e-05, 1345
[INFO] 2021-07-12 18:58:57,274 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1345
[INFO] 2021-07-12 18:58:57,274 [run_pretraining.py:  558]:	worker_index: 6, step: 1345, cost: 7.809072, mlm loss: 7.809072, speed: 1.113284 steps/s, speed: 8.906274 samples/s, speed: 4560.012312 tokens/s, learning rate: 1.344e-05, loss_scalings: 10737.418945, pp_loss: 7.645534
[INFO] 2021-07-12 18:58:57,274 [run_pretraining.py:  512]:	********exe.run_1345******* 
[INFO] 2021-07-12 18:58:58,236 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:58,237 [run_pretraining.py:  534]:	loss/total_loss, 7.104072570800781, 1346
[INFO] 2021-07-12 18:58:58,237 [run_pretraining.py:  535]:	loss/mlm_loss, 7.104072570800781, 1346
[INFO] 2021-07-12 18:58:58,237 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3449999642034527e-05, 1346
[INFO] 2021-07-12 18:58:58,237 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1346
[INFO] 2021-07-12 18:58:58,237 [run_pretraining.py:  558]:	worker_index: 6, step: 1346, cost: 7.104073, mlm loss: 7.104073, speed: 1.038969 steps/s, speed: 8.311753 samples/s, speed: 4255.617727 tokens/s, learning rate: 1.345e-05, loss_scalings: 10737.418945, pp_loss: 7.537159
[INFO] 2021-07-12 18:58:58,237 [run_pretraining.py:  512]:	********exe.run_1346******* 
[INFO] 2021-07-12 18:58:59,289 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:59,290 [run_pretraining.py:  534]:	loss/total_loss, 7.843539714813232, 1347
[INFO] 2021-07-12 18:58:59,290 [run_pretraining.py:  535]:	loss/mlm_loss, 7.843539714813232, 1347
[INFO] 2021-07-12 18:58:59,290 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.345999953628052e-05, 1347
[INFO] 2021-07-12 18:58:59,290 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1347
[INFO] 2021-07-12 18:58:59,290 [run_pretraining.py:  558]:	worker_index: 6, step: 1347, cost: 7.843540, mlm loss: 7.843540, speed: 0.950675 steps/s, speed: 7.605400 samples/s, speed: 3893.964849 tokens/s, learning rate: 1.346e-05, loss_scalings: 10737.418945, pp_loss: 7.742398
[INFO] 2021-07-12 18:58:59,290 [run_pretraining.py:  512]:	********exe.run_1347******* 
[INFO] 2021-07-12 18:59:00,350 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:00,351 [run_pretraining.py:  534]:	loss/total_loss, 6.963218688964844, 1348
[INFO] 2021-07-12 18:59:00,351 [run_pretraining.py:  535]:	loss/mlm_loss, 6.963218688964844, 1348
[INFO] 2021-07-12 18:59:00,351 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3469999430526514e-05, 1348
[INFO] 2021-07-12 18:59:00,351 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1348
[INFO] 2021-07-12 18:59:00,351 [run_pretraining.py:  558]:	worker_index: 6, step: 1348, cost: 6.963219, mlm loss: 6.963219, speed: 0.942989 steps/s, speed: 7.543914 samples/s, speed: 3862.483997 tokens/s, learning rate: 1.347e-05, loss_scalings: 10737.418945, pp_loss: 7.374290
[INFO] 2021-07-12 18:59:00,351 [run_pretraining.py:  512]:	********exe.run_1348******* 
[INFO] 2021-07-12 18:59:01,347 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:01,347 [run_pretraining.py:  534]:	loss/total_loss, 7.803036212921143, 1349
[INFO] 2021-07-12 18:59:01,347 [run_pretraining.py:  535]:	loss/mlm_loss, 7.803036212921143, 1349
[INFO] 2021-07-12 18:59:01,348 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3480000234267209e-05, 1349
[INFO] 2021-07-12 18:59:01,348 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1349
[INFO] 2021-07-12 18:59:01,348 [run_pretraining.py:  558]:	worker_index: 6, step: 1349, cost: 7.803036, mlm loss: 7.803036, speed: 1.004071 steps/s, speed: 8.032568 samples/s, speed: 4112.675032 tokens/s, learning rate: 1.348e-05, loss_scalings: 10737.418945, pp_loss: 7.732203
[INFO] 2021-07-12 18:59:01,348 [run_pretraining.py:  512]:	********exe.run_1349******* 
[INFO] 2021-07-12 18:59:02,248 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:02,249 [run_pretraining.py:  534]:	loss/total_loss, 6.742798328399658, 1350
[INFO] 2021-07-12 18:59:02,249 [run_pretraining.py:  535]:	loss/mlm_loss, 6.742798328399658, 1350
[INFO] 2021-07-12 18:59:02,249 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3490000128513202e-05, 1350
[INFO] 2021-07-12 18:59:02,249 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1350
[INFO] 2021-07-12 18:59:02,249 [run_pretraining.py:  558]:	worker_index: 6, step: 1350, cost: 6.742798, mlm loss: 6.742798, speed: 1.109891 steps/s, speed: 8.879124 samples/s, speed: 4546.111546 tokens/s, learning rate: 1.349e-05, loss_scalings: 10737.418945, pp_loss: 7.169366
[INFO] 2021-07-12 18:59:02,250 [run_pretraining.py:  512]:	********exe.run_1350******* 
[INFO] 2021-07-12 18:59:03,149 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:03,150 [run_pretraining.py:  534]:	loss/total_loss, 7.5033769607543945, 1351
[INFO] 2021-07-12 18:59:03,150 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5033769607543945, 1351
[INFO] 2021-07-12 18:59:03,150 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3500000022759195e-05, 1351
[INFO] 2021-07-12 18:59:03,150 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1351
[INFO] 2021-07-12 18:59:03,150 [run_pretraining.py:  558]:	worker_index: 6, step: 1351, cost: 7.503377, mlm loss: 7.503377, speed: 1.110713 steps/s, speed: 8.885708 samples/s, speed: 4549.482402 tokens/s, learning rate: 1.350e-05, loss_scalings: 10737.418945, pp_loss: 7.627707
[INFO] 2021-07-12 18:59:03,151 [run_pretraining.py:  512]:	********exe.run_1351******* 
[INFO] 2021-07-12 18:59:04,042 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:04,043 [run_pretraining.py:  534]:	loss/total_loss, 7.41140604019165, 1352
[INFO] 2021-07-12 18:59:04,043 [run_pretraining.py:  535]:	loss/mlm_loss, 7.41140604019165, 1352
[INFO] 2021-07-12 18:59:04,043 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3509999917005189e-05, 1352
[INFO] 2021-07-12 18:59:04,043 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1352
[INFO] 2021-07-12 18:59:04,043 [run_pretraining.py:  558]:	worker_index: 6, step: 1352, cost: 7.411406, mlm loss: 7.411406, speed: 1.121366 steps/s, speed: 8.970927 samples/s, speed: 4593.114389 tokens/s, learning rate: 1.351e-05, loss_scalings: 10737.418945, pp_loss: 7.438704
[INFO] 2021-07-12 18:59:04,043 [run_pretraining.py:  512]:	********exe.run_1352******* 
[INFO] 2021-07-12 18:59:04,940 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:04,941 [run_pretraining.py:  534]:	loss/total_loss, 7.005640029907227, 1353
[INFO] 2021-07-12 18:59:04,941 [run_pretraining.py:  535]:	loss/mlm_loss, 7.005640029907227, 1353
[INFO] 2021-07-12 18:59:04,941 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.351999890175648e-05, 1353
[INFO] 2021-07-12 18:59:04,941 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1353
[INFO] 2021-07-12 18:59:04,941 [run_pretraining.py:  558]:	worker_index: 6, step: 1353, cost: 7.005640, mlm loss: 7.005640, speed: 1.114374 steps/s, speed: 8.914989 samples/s, speed: 4564.474405 tokens/s, learning rate: 1.352e-05, loss_scalings: 10737.418945, pp_loss: 7.405193
[INFO] 2021-07-12 18:59:04,941 [run_pretraining.py:  512]:	********exe.run_1353******* 
[INFO] 2021-07-12 18:59:05,842 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:05,842 [run_pretraining.py:  534]:	loss/total_loss, 7.59025239944458, 1354
[INFO] 2021-07-12 18:59:05,843 [run_pretraining.py:  535]:	loss/mlm_loss, 7.59025239944458, 1354
[INFO] 2021-07-12 18:59:05,843 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3529998796002474e-05, 1354
[INFO] 2021-07-12 18:59:05,843 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1354
[INFO] 2021-07-12 18:59:05,843 [run_pretraining.py:  558]:	worker_index: 6, step: 1354, cost: 7.590252, mlm loss: 7.590252, speed: 1.109755 steps/s, speed: 8.878041 samples/s, speed: 4545.557037 tokens/s, learning rate: 1.353e-05, loss_scalings: 10737.418945, pp_loss: 7.286487
[INFO] 2021-07-12 18:59:05,843 [run_pretraining.py:  512]:	********exe.run_1354******* 
[INFO] 2021-07-12 18:59:06,743 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:06,744 [run_pretraining.py:  534]:	loss/total_loss, 7.318971633911133, 1355
[INFO] 2021-07-12 18:59:06,744 [run_pretraining.py:  535]:	loss/mlm_loss, 7.318971633911133, 1355
[INFO] 2021-07-12 18:59:06,744 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3539999599743169e-05, 1355
[INFO] 2021-07-12 18:59:06,744 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1355
[INFO] 2021-07-12 18:59:06,744 [run_pretraining.py:  558]:	worker_index: 6, step: 1355, cost: 7.318972, mlm loss: 7.318972, speed: 1.110367 steps/s, speed: 8.882934 samples/s, speed: 4548.062422 tokens/s, learning rate: 1.354e-05, loss_scalings: 10737.418945, pp_loss: 7.615384
[INFO] 2021-07-12 18:59:06,744 [run_pretraining.py:  512]:	********exe.run_1355******* 
[INFO] 2021-07-12 18:59:07,636 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:07,637 [run_pretraining.py:  534]:	loss/total_loss, 6.869090557098389, 1356
[INFO] 2021-07-12 18:59:07,637 [run_pretraining.py:  535]:	loss/mlm_loss, 6.869090557098389, 1356
[INFO] 2021-07-12 18:59:07,637 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3549999493989162e-05, 1356
[INFO] 2021-07-12 18:59:07,637 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1356
[INFO] 2021-07-12 18:59:07,637 [run_pretraining.py:  558]:	worker_index: 6, step: 1356, cost: 6.869091, mlm loss: 6.869091, speed: 1.120856 steps/s, speed: 8.966846 samples/s, speed: 4591.025301 tokens/s, learning rate: 1.355e-05, loss_scalings: 10737.418945, pp_loss: 7.330999
[INFO] 2021-07-12 18:59:07,637 [run_pretraining.py:  512]:	********exe.run_1356******* 
[INFO] 2021-07-12 18:59:08,542 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:08,543 [run_pretraining.py:  534]:	loss/total_loss, 7.230471611022949, 1357
[INFO] 2021-07-12 18:59:08,543 [run_pretraining.py:  535]:	loss/mlm_loss, 7.230471611022949, 1357
[INFO] 2021-07-12 18:59:08,543 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3559999388235155e-05, 1357
[INFO] 2021-07-12 18:59:08,543 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1357
[INFO] 2021-07-12 18:59:08,543 [run_pretraining.py:  558]:	worker_index: 6, step: 1357, cost: 7.230472, mlm loss: 7.230472, speed: 1.104565 steps/s, speed: 8.836518 samples/s, speed: 4524.297131 tokens/s, learning rate: 1.356e-05, loss_scalings: 10737.418945, pp_loss: 7.310929
[INFO] 2021-07-12 18:59:08,543 [run_pretraining.py:  512]:	********exe.run_1357******* 
[INFO] 2021-07-12 18:59:09,431 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:09,432 [run_pretraining.py:  534]:	loss/total_loss, 8.383363723754883, 1358
[INFO] 2021-07-12 18:59:09,432 [run_pretraining.py:  535]:	loss/mlm_loss, 8.383363723754883, 1358
[INFO] 2021-07-12 18:59:09,432 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.357000019197585e-05, 1358
[INFO] 2021-07-12 18:59:09,432 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1358
[INFO] 2021-07-12 18:59:09,432 [run_pretraining.py:  558]:	worker_index: 6, step: 1358, cost: 8.383364, mlm loss: 8.383364, speed: 1.125338 steps/s, speed: 9.002703 samples/s, speed: 4609.383731 tokens/s, learning rate: 1.357e-05, loss_scalings: 10737.418945, pp_loss: 7.353568
[INFO] 2021-07-12 18:59:09,432 [run_pretraining.py:  512]:	********exe.run_1358******* 
[INFO] 2021-07-12 18:59:10,334 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:10,334 [run_pretraining.py:  534]:	loss/total_loss, 7.17632532119751, 1359
[INFO] 2021-07-12 18:59:10,335 [run_pretraining.py:  535]:	loss/mlm_loss, 7.17632532119751, 1359
[INFO] 2021-07-12 18:59:10,335 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3580000086221844e-05, 1359
[INFO] 2021-07-12 18:59:10,335 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1359
[INFO] 2021-07-12 18:59:10,335 [run_pretraining.py:  558]:	worker_index: 6, step: 1359, cost: 7.176325, mlm loss: 7.176325, speed: 1.108919 steps/s, speed: 8.871354 samples/s, speed: 4542.133149 tokens/s, learning rate: 1.358e-05, loss_scalings: 10737.418945, pp_loss: 7.336721
[INFO] 2021-07-12 18:59:10,335 [run_pretraining.py:  512]:	********exe.run_1359******* 
[INFO] 2021-07-12 18:59:11,264 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:11,264 [run_pretraining.py:  534]:	loss/total_loss, 8.033388137817383, 1360
[INFO] 2021-07-12 18:59:11,264 [run_pretraining.py:  535]:	loss/mlm_loss, 8.033388137817383, 1360
[INFO] 2021-07-12 18:59:11,264 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3589999980467837e-05, 1360
[INFO] 2021-07-12 18:59:11,265 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1360
[INFO] 2021-07-12 18:59:11,265 [run_pretraining.py:  558]:	worker_index: 6, step: 1360, cost: 8.033388, mlm loss: 8.033388, speed: 1.076256 steps/s, speed: 8.610050 samples/s, speed: 4408.345535 tokens/s, learning rate: 1.359e-05, loss_scalings: 10737.418945, pp_loss: 6.757789
[INFO] 2021-07-12 18:59:11,265 [run_pretraining.py:  512]:	********exe.run_1360******* 
[INFO] 2021-07-12 18:59:12,165 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:12,165 [run_pretraining.py:  534]:	loss/total_loss, 5.928573131561279, 1361
[INFO] 2021-07-12 18:59:12,165 [run_pretraining.py:  535]:	loss/mlm_loss, 5.928573131561279, 1361
[INFO] 2021-07-12 18:59:12,166 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3600000784208532e-05, 1361
[INFO] 2021-07-12 18:59:12,166 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1361
[INFO] 2021-07-12 18:59:12,166 [run_pretraining.py:  558]:	worker_index: 6, step: 1361, cost: 5.928573, mlm loss: 5.928573, speed: 1.110675 steps/s, speed: 8.885402 samples/s, speed: 4549.325787 tokens/s, learning rate: 1.360e-05, loss_scalings: 10737.418945, pp_loss: 6.805779
[INFO] 2021-07-12 18:59:12,166 [run_pretraining.py:  512]:	********exe.run_1361******* 
[INFO] 2021-07-12 18:59:13,073 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:13,073 [run_pretraining.py:  534]:	loss/total_loss, 7.593994140625, 1362
[INFO] 2021-07-12 18:59:13,073 [run_pretraining.py:  535]:	loss/mlm_loss, 7.593994140625, 1362
[INFO] 2021-07-12 18:59:13,074 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3609998859465122e-05, 1362
[INFO] 2021-07-12 18:59:13,074 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1362
[INFO] 2021-07-12 18:59:13,074 [run_pretraining.py:  558]:	worker_index: 6, step: 1362, cost: 7.593994, mlm loss: 7.593994, speed: 1.102239 steps/s, speed: 8.817912 samples/s, speed: 4514.771189 tokens/s, learning rate: 1.361e-05, loss_scalings: 10737.418945, pp_loss: 7.156405
[INFO] 2021-07-12 18:59:13,074 [run_pretraining.py:  512]:	********exe.run_1362******* 
[INFO] 2021-07-12 18:59:13,969 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:13,969 [run_pretraining.py:  534]:	loss/total_loss, 7.424228191375732, 1363
[INFO] 2021-07-12 18:59:13,969 [run_pretraining.py:  535]:	loss/mlm_loss, 7.424228191375732, 1363
[INFO] 2021-07-12 18:59:13,969 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3619999663205817e-05, 1363
[INFO] 2021-07-12 18:59:13,969 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1363
[INFO] 2021-07-12 18:59:13,970 [run_pretraining.py:  558]:	worker_index: 6, step: 1363, cost: 7.424228, mlm loss: 7.424228, speed: 1.117114 steps/s, speed: 8.936910 samples/s, speed: 4575.697795 tokens/s, learning rate: 1.362e-05, loss_scalings: 10737.418945, pp_loss: 6.803480
[INFO] 2021-07-12 18:59:13,970 [run_pretraining.py:  512]:	********exe.run_1363******* 
[INFO] 2021-07-12 18:59:14,864 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:14,864 [run_pretraining.py:  534]:	loss/total_loss, 7.023076057434082, 1364
[INFO] 2021-07-12 18:59:14,864 [run_pretraining.py:  535]:	loss/mlm_loss, 7.023076057434082, 1364
[INFO] 2021-07-12 18:59:14,864 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.362999955745181e-05, 1364
[INFO] 2021-07-12 18:59:14,865 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1364
[INFO] 2021-07-12 18:59:14,865 [run_pretraining.py:  558]:	worker_index: 6, step: 1364, cost: 7.023076, mlm loss: 7.023076, speed: 1.118127 steps/s, speed: 8.945017 samples/s, speed: 4579.848774 tokens/s, learning rate: 1.363e-05, loss_scalings: 10737.418945, pp_loss: 7.188520
[INFO] 2021-07-12 18:59:14,865 [run_pretraining.py:  512]:	********exe.run_1364******* 
[INFO] 2021-07-12 18:59:15,840 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:15,841 [run_pretraining.py:  534]:	loss/total_loss, 7.294443607330322, 1365
[INFO] 2021-07-12 18:59:15,841 [run_pretraining.py:  535]:	loss/mlm_loss, 7.294443607330322, 1365
[INFO] 2021-07-12 18:59:15,841 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3639999451697804e-05, 1365
[INFO] 2021-07-12 18:59:15,841 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1365
[INFO] 2021-07-12 18:59:15,841 [run_pretraining.py:  558]:	worker_index: 6, step: 1365, cost: 7.294444, mlm loss: 7.294444, speed: 1.024522 steps/s, speed: 8.196172 samples/s, speed: 4196.440127 tokens/s, learning rate: 1.364e-05, loss_scalings: 10737.418945, pp_loss: 7.250075
[INFO] 2021-07-12 18:59:15,841 [run_pretraining.py:  512]:	********exe.run_1365******* 
[INFO] 2021-07-12 18:59:16,741 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:16,742 [run_pretraining.py:  534]:	loss/total_loss, 7.162468910217285, 1366
[INFO] 2021-07-12 18:59:16,742 [run_pretraining.py:  535]:	loss/mlm_loss, 7.162468910217285, 1366
[INFO] 2021-07-12 18:59:16,742 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3649999345943797e-05, 1366
[INFO] 2021-07-12 18:59:16,742 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1366
[INFO] 2021-07-12 18:59:16,742 [run_pretraining.py:  558]:	worker_index: 6, step: 1366, cost: 7.162469, mlm loss: 7.162469, speed: 1.110994 steps/s, speed: 8.887956 samples/s, speed: 4550.633248 tokens/s, learning rate: 1.365e-05, loss_scalings: 10737.418945, pp_loss: 7.420553
[INFO] 2021-07-12 18:59:16,742 [run_pretraining.py:  512]:	********exe.run_1366******* 
[INFO] 2021-07-12 18:59:17,646 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:17,646 [run_pretraining.py:  534]:	loss/total_loss, 7.47883415222168, 1367
[INFO] 2021-07-12 18:59:17,646 [run_pretraining.py:  535]:	loss/mlm_loss, 7.47883415222168, 1367
[INFO] 2021-07-12 18:59:17,646 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3660000149684492e-05, 1367
[INFO] 2021-07-12 18:59:17,646 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1367
[INFO] 2021-07-12 18:59:17,647 [run_pretraining.py:  558]:	worker_index: 6, step: 1367, cost: 7.478834, mlm loss: 7.478834, speed: 1.106621 steps/s, speed: 8.852966 samples/s, speed: 4532.718584 tokens/s, learning rate: 1.366e-05, loss_scalings: 10737.418945, pp_loss: 7.341328
[INFO] 2021-07-12 18:59:17,647 [run_pretraining.py:  512]:	********exe.run_1367******* 
[INFO] 2021-07-12 18:59:18,546 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:18,547 [run_pretraining.py:  534]:	loss/total_loss, 7.855730056762695, 1368
[INFO] 2021-07-12 18:59:18,547 [run_pretraining.py:  535]:	loss/mlm_loss, 7.855730056762695, 1368
[INFO] 2021-07-12 18:59:18,547 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3670000043930486e-05, 1368
[INFO] 2021-07-12 18:59:18,547 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1368
[INFO] 2021-07-12 18:59:18,547 [run_pretraining.py:  558]:	worker_index: 6, step: 1368, cost: 7.855730, mlm loss: 7.855730, speed: 1.111445 steps/s, speed: 8.891564 samples/s, speed: 4552.480640 tokens/s, learning rate: 1.367e-05, loss_scalings: 10737.418945, pp_loss: 7.394985
[INFO] 2021-07-12 18:59:18,547 [run_pretraining.py:  512]:	********exe.run_1368******* 
[INFO] 2021-07-12 18:59:19,442 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:19,443 [run_pretraining.py:  534]:	loss/total_loss, 7.611528396606445, 1369
[INFO] 2021-07-12 18:59:19,443 [run_pretraining.py:  535]:	loss/mlm_loss, 7.611528396606445, 1369
[INFO] 2021-07-12 18:59:19,443 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.367999993817648e-05, 1369
[INFO] 2021-07-12 18:59:19,443 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1369
[INFO] 2021-07-12 18:59:19,443 [run_pretraining.py:  558]:	worker_index: 6, step: 1369, cost: 7.611528, mlm loss: 7.611528, speed: 1.116825 steps/s, speed: 8.934601 samples/s, speed: 4574.515967 tokens/s, learning rate: 1.368e-05, loss_scalings: 10737.418945, pp_loss: 7.553864
[INFO] 2021-07-12 18:59:19,443 [run_pretraining.py:  512]:	********exe.run_1369******* 
[INFO] 2021-07-12 18:59:20,338 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:20,339 [run_pretraining.py:  534]:	loss/total_loss, 7.5733442306518555, 1370
[INFO] 2021-07-12 18:59:20,339 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5733442306518555, 1370
[INFO] 2021-07-12 18:59:20,339 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.368999892292777e-05, 1370
[INFO] 2021-07-12 18:59:20,339 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1370
[INFO] 2021-07-12 18:59:20,340 [run_pretraining.py:  558]:	worker_index: 6, step: 1370, cost: 7.573344, mlm loss: 7.573344, speed: 1.116536 steps/s, speed: 8.932285 samples/s, speed: 4573.329879 tokens/s, learning rate: 1.369e-05, loss_scalings: 10737.418945, pp_loss: 7.808492
[INFO] 2021-07-12 18:59:20,340 [run_pretraining.py:  512]:	********exe.run_1370******* 
[INFO] 2021-07-12 18:59:21,234 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:21,235 [run_pretraining.py:  534]:	loss/total_loss, 8.719278335571289, 1371
[INFO] 2021-07-12 18:59:21,235 [run_pretraining.py:  535]:	loss/mlm_loss, 8.719278335571289, 1371
[INFO] 2021-07-12 18:59:21,235 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3699998817173764e-05, 1371
[INFO] 2021-07-12 18:59:21,235 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1371
[INFO] 2021-07-12 18:59:21,235 [run_pretraining.py:  558]:	worker_index: 6, step: 1371, cost: 8.719278, mlm loss: 8.719278, speed: 1.117107 steps/s, speed: 8.936860 samples/s, speed: 4575.672203 tokens/s, learning rate: 1.370e-05, loss_scalings: 10737.418945, pp_loss: 7.749972
[INFO] 2021-07-12 18:59:21,235 [run_pretraining.py:  512]:	********exe.run_1371******* 
[INFO] 2021-07-12 18:59:22,150 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:22,151 [run_pretraining.py:  534]:	loss/total_loss, 9.47395133972168, 1372
[INFO] 2021-07-12 18:59:22,151 [run_pretraining.py:  535]:	loss/mlm_loss, 9.47395133972168, 1372
[INFO] 2021-07-12 18:59:22,151 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.370999962091446e-05, 1372
[INFO] 2021-07-12 18:59:22,151 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1372
[INFO] 2021-07-12 18:59:22,151 [run_pretraining.py:  558]:	worker_index: 6, step: 1372, cost: 9.473951, mlm loss: 9.473951, speed: 1.092930 steps/s, speed: 8.743441 samples/s, speed: 4476.641728 tokens/s, learning rate: 1.371e-05, loss_scalings: 10737.418945, pp_loss: 8.034735
[INFO] 2021-07-12 18:59:22,151 [run_pretraining.py:  512]:	********exe.run_1372******* 
[INFO] 2021-07-12 18:59:23,062 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:23,063 [run_pretraining.py:  534]:	loss/total_loss, 7.5032453536987305, 1373
[INFO] 2021-07-12 18:59:23,063 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5032453536987305, 1373
[INFO] 2021-07-12 18:59:23,063 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3719999515160453e-05, 1373
[INFO] 2021-07-12 18:59:23,063 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1373
[INFO] 2021-07-12 18:59:23,063 [run_pretraining.py:  558]:	worker_index: 6, step: 1373, cost: 7.503245, mlm loss: 7.503245, speed: 1.096885 steps/s, speed: 8.775078 samples/s, speed: 4492.839824 tokens/s, learning rate: 1.372e-05, loss_scalings: 10737.418945, pp_loss: 7.294659
[INFO] 2021-07-12 18:59:23,064 [run_pretraining.py:  512]:	********exe.run_1373******* 
[INFO] 2021-07-12 18:59:23,978 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:23,978 [run_pretraining.py:  534]:	loss/total_loss, 7.620558738708496, 1374
[INFO] 2021-07-12 18:59:23,978 [run_pretraining.py:  535]:	loss/mlm_loss, 7.620558738708496, 1374
[INFO] 2021-07-12 18:59:23,978 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3729999409406446e-05, 1374
[INFO] 2021-07-12 18:59:23,978 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1374
[INFO] 2021-07-12 18:59:23,979 [run_pretraining.py:  558]:	worker_index: 6, step: 1374, cost: 7.620559, mlm loss: 7.620559, speed: 1.093651 steps/s, speed: 8.749211 samples/s, speed: 4479.596089 tokens/s, learning rate: 1.373e-05, loss_scalings: 10737.418945, pp_loss: 7.334204
[INFO] 2021-07-12 18:59:23,979 [run_pretraining.py:  512]:	********exe.run_1374******* 
[INFO] 2021-07-12 18:59:24,887 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:24,887 [run_pretraining.py:  534]:	loss/total_loss, 7.83242130279541, 1375
[INFO] 2021-07-12 18:59:24,888 [run_pretraining.py:  535]:	loss/mlm_loss, 7.83242130279541, 1375
[INFO] 2021-07-12 18:59:24,888 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3740000213147141e-05, 1375
[INFO] 2021-07-12 18:59:24,888 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1375
[INFO] 2021-07-12 18:59:24,888 [run_pretraining.py:  558]:	worker_index: 6, step: 1375, cost: 7.832421, mlm loss: 7.832421, speed: 1.100651 steps/s, speed: 8.805211 samples/s, speed: 4508.268112 tokens/s, learning rate: 1.374e-05, loss_scalings: 10737.418945, pp_loss: 7.366847
[INFO] 2021-07-12 18:59:24,888 [run_pretraining.py:  512]:	********exe.run_1375******* 
[INFO] 2021-07-12 18:59:25,837 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:25,838 [run_pretraining.py:  534]:	loss/total_loss, 7.481790065765381, 1376
[INFO] 2021-07-12 18:59:25,838 [run_pretraining.py:  535]:	loss/mlm_loss, 7.481790065765381, 1376
[INFO] 2021-07-12 18:59:25,838 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3750000107393134e-05, 1376
[INFO] 2021-07-12 18:59:25,838 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1376
[INFO] 2021-07-12 18:59:25,838 [run_pretraining.py:  558]:	worker_index: 6, step: 1376, cost: 7.481790, mlm loss: 7.481790, speed: 1.053121 steps/s, speed: 8.424970 samples/s, speed: 4313.584728 tokens/s, learning rate: 1.375e-05, loss_scalings: 8589.935547, pp_loss: 7.380479
[INFO] 2021-07-12 18:59:25,838 [run_pretraining.py:  512]:	********exe.run_1376******* 
[INFO] 2021-07-12 18:59:26,735 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:26,736 [run_pretraining.py:  534]:	loss/total_loss, 7.591237545013428, 1377
[INFO] 2021-07-12 18:59:26,736 [run_pretraining.py:  535]:	loss/mlm_loss, 7.591237545013428, 1377
[INFO] 2021-07-12 18:59:26,736 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3760000001639128e-05, 1377
[INFO] 2021-07-12 18:59:26,736 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1377
[INFO] 2021-07-12 18:59:26,736 [run_pretraining.py:  558]:	worker_index: 6, step: 1377, cost: 7.591238, mlm loss: 7.591238, speed: 1.114051 steps/s, speed: 8.912408 samples/s, speed: 4563.152919 tokens/s, learning rate: 1.376e-05, loss_scalings: 8589.935547, pp_loss: 7.750767
[INFO] 2021-07-12 18:59:26,737 [run_pretraining.py:  512]:	********exe.run_1377******* 
[INFO] 2021-07-12 18:59:27,633 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:27,634 [run_pretraining.py:  534]:	loss/total_loss, 7.541675090789795, 1378
[INFO] 2021-07-12 18:59:27,634 [run_pretraining.py:  535]:	loss/mlm_loss, 7.541675090789795, 1378
[INFO] 2021-07-12 18:59:27,634 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3769999895885121e-05, 1378
[INFO] 2021-07-12 18:59:27,634 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1378
[INFO] 2021-07-12 18:59:27,634 [run_pretraining.py:  558]:	worker_index: 6, step: 1378, cost: 7.541675, mlm loss: 7.541675, speed: 1.114776 steps/s, speed: 8.918207 samples/s, speed: 4566.121878 tokens/s, learning rate: 1.377e-05, loss_scalings: 8589.935547, pp_loss: 7.403706
[INFO] 2021-07-12 18:59:27,634 [run_pretraining.py:  512]:	********exe.run_1378******* 
[INFO] 2021-07-12 18:59:28,530 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:28,531 [run_pretraining.py:  534]:	loss/total_loss, 7.5048346519470215, 1379
[INFO] 2021-07-12 18:59:28,531 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5048346519470215, 1379
[INFO] 2021-07-12 18:59:28,531 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3779998880636413e-05, 1379
[INFO] 2021-07-12 18:59:28,531 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1379
[INFO] 2021-07-12 18:59:28,531 [run_pretraining.py:  558]:	worker_index: 6, step: 1379, cost: 7.504835, mlm loss: 7.504835, speed: 1.115956 steps/s, speed: 8.927648 samples/s, speed: 4570.955900 tokens/s, learning rate: 1.378e-05, loss_scalings: 8589.935547, pp_loss: 7.492663
[INFO] 2021-07-12 18:59:28,531 [run_pretraining.py:  512]:	********exe.run_1379******* 
[INFO] 2021-07-12 18:59:29,426 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:29,427 [run_pretraining.py:  534]:	loss/total_loss, 6.940953254699707, 1380
[INFO] 2021-07-12 18:59:29,427 [run_pretraining.py:  535]:	loss/mlm_loss, 6.940953254699707, 1380
[INFO] 2021-07-12 18:59:29,427 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3789998774882406e-05, 1380
[INFO] 2021-07-12 18:59:29,427 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1380
[INFO] 2021-07-12 18:59:29,427 [run_pretraining.py:  558]:	worker_index: 6, step: 1380, cost: 6.940953, mlm loss: 6.940953, speed: 1.116859 steps/s, speed: 8.934875 samples/s, speed: 4574.656048 tokens/s, learning rate: 1.379e-05, loss_scalings: 8589.935547, pp_loss: 7.306715
[INFO] 2021-07-12 18:59:29,427 [run_pretraining.py:  512]:	********exe.run_1380******* 
[INFO] 2021-07-12 18:59:30,338 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:30,338 [run_pretraining.py:  534]:	loss/total_loss, 7.181911468505859, 1381
[INFO] 2021-07-12 18:59:30,339 [run_pretraining.py:  535]:	loss/mlm_loss, 7.181911468505859, 1381
[INFO] 2021-07-12 18:59:30,339 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3799999578623101e-05, 1381
[INFO] 2021-07-12 18:59:30,339 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1381
[INFO] 2021-07-12 18:59:30,339 [run_pretraining.py:  558]:	worker_index: 6, step: 1381, cost: 7.181911, mlm loss: 7.181911, speed: 1.097581 steps/s, speed: 8.780646 samples/s, speed: 4495.690903 tokens/s, learning rate: 1.380e-05, loss_scalings: 8589.935547, pp_loss: 7.376561
[INFO] 2021-07-12 18:59:30,339 [run_pretraining.py:  512]:	********exe.run_1381******* 
[INFO] 2021-07-12 18:59:31,243 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:31,244 [run_pretraining.py:  534]:	loss/total_loss, 7.1500139236450195, 1382
[INFO] 2021-07-12 18:59:31,244 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1500139236450195, 1382
[INFO] 2021-07-12 18:59:31,244 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3809999472869094e-05, 1382
[INFO] 2021-07-12 18:59:31,244 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1382
[INFO] 2021-07-12 18:59:31,244 [run_pretraining.py:  558]:	worker_index: 6, step: 1382, cost: 7.150014, mlm loss: 7.150014, speed: 1.105071 steps/s, speed: 8.840571 samples/s, speed: 4526.372428 tokens/s, learning rate: 1.381e-05, loss_scalings: 8589.935547, pp_loss: 7.511250
[INFO] 2021-07-12 18:59:31,245 [run_pretraining.py:  512]:	********exe.run_1382******* 
[INFO] 2021-07-12 18:59:32,179 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:32,180 [run_pretraining.py:  534]:	loss/total_loss, 8.250410079956055, 1383
[INFO] 2021-07-12 18:59:32,180 [run_pretraining.py:  535]:	loss/mlm_loss, 8.250410079956055, 1383
[INFO] 2021-07-12 18:59:32,180 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3819999367115088e-05, 1383
[INFO] 2021-07-12 18:59:32,180 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1383
[INFO] 2021-07-12 18:59:32,180 [run_pretraining.py:  558]:	worker_index: 6, step: 1383, cost: 8.250410, mlm loss: 8.250410, speed: 1.069613 steps/s, speed: 8.556901 samples/s, speed: 4381.133234 tokens/s, learning rate: 1.382e-05, loss_scalings: 8589.935547, pp_loss: 7.358791
[INFO] 2021-07-12 18:59:32,180 [run_pretraining.py:  512]:	********exe.run_1383******* 
[INFO] 2021-07-12 18:59:33,079 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:33,080 [run_pretraining.py:  534]:	loss/total_loss, 7.3974761962890625, 1384
[INFO] 2021-07-12 18:59:33,080 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3974761962890625, 1384
[INFO] 2021-07-12 18:59:33,080 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3830000170855783e-05, 1384
[INFO] 2021-07-12 18:59:33,080 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1384
[INFO] 2021-07-12 18:59:33,080 [run_pretraining.py:  558]:	worker_index: 6, step: 1384, cost: 7.397476, mlm loss: 7.397476, speed: 1.111811 steps/s, speed: 8.894491 samples/s, speed: 4553.979430 tokens/s, learning rate: 1.383e-05, loss_scalings: 8589.935547, pp_loss: 7.609916
[INFO] 2021-07-12 18:59:33,080 [run_pretraining.py:  512]:	********exe.run_1384******* 
[INFO] 2021-07-12 18:59:33,975 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:33,976 [run_pretraining.py:  534]:	loss/total_loss, 7.275796890258789, 1385
[INFO] 2021-07-12 18:59:33,976 [run_pretraining.py:  535]:	loss/mlm_loss, 7.275796890258789, 1385
[INFO] 2021-07-12 18:59:33,976 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3840000065101776e-05, 1385
[INFO] 2021-07-12 18:59:33,976 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1385
[INFO] 2021-07-12 18:59:33,976 [run_pretraining.py:  558]:	worker_index: 6, step: 1385, cost: 7.275797, mlm loss: 7.275797, speed: 1.116886 steps/s, speed: 8.935084 samples/s, speed: 4574.763247 tokens/s, learning rate: 1.384e-05, loss_scalings: 8589.935547, pp_loss: 7.825665
[INFO] 2021-07-12 18:59:33,976 [run_pretraining.py:  512]:	********exe.run_1385******* 
[INFO] 2021-07-12 18:59:34,875 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:34,876 [run_pretraining.py:  534]:	loss/total_loss, 8.060957908630371, 1386
[INFO] 2021-07-12 18:59:34,876 [run_pretraining.py:  535]:	loss/mlm_loss, 8.060957908630371, 1386
[INFO] 2021-07-12 18:59:34,876 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.384999995934777e-05, 1386
[INFO] 2021-07-12 18:59:34,876 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1386
[INFO] 2021-07-12 18:59:34,876 [run_pretraining.py:  558]:	worker_index: 6, step: 1386, cost: 8.060958, mlm loss: 8.060958, speed: 1.111901 steps/s, speed: 8.895210 samples/s, speed: 4554.347641 tokens/s, learning rate: 1.385e-05, loss_scalings: 8589.935547, pp_loss: 6.421294
[INFO] 2021-07-12 18:59:34,876 [run_pretraining.py:  512]:	********exe.run_1386******* 
[INFO] 2021-07-12 18:59:35,792 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:35,793 [run_pretraining.py:  534]:	loss/total_loss, 7.408451080322266, 1387
[INFO] 2021-07-12 18:59:35,793 [run_pretraining.py:  535]:	loss/mlm_loss, 7.408451080322266, 1387
[INFO] 2021-07-12 18:59:35,793 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3860000763088465e-05, 1387
[INFO] 2021-07-12 18:59:35,793 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1387
[INFO] 2021-07-12 18:59:35,793 [run_pretraining.py:  558]:	worker_index: 6, step: 1387, cost: 7.408451, mlm loss: 7.408451, speed: 1.091914 steps/s, speed: 8.735313 samples/s, speed: 4472.480028 tokens/s, learning rate: 1.386e-05, loss_scalings: 8589.935547, pp_loss: 7.574411
[INFO] 2021-07-12 18:59:35,793 [run_pretraining.py:  512]:	********exe.run_1387******* 
[INFO] 2021-07-12 18:59:36,683 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:36,684 [run_pretraining.py:  534]:	loss/total_loss, 5.151028633117676, 1388
[INFO] 2021-07-12 18:59:36,684 [run_pretraining.py:  535]:	loss/mlm_loss, 5.151028633117676, 1388
[INFO] 2021-07-12 18:59:36,684 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3869998838345055e-05, 1388
[INFO] 2021-07-12 18:59:36,684 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1388
[INFO] 2021-07-12 18:59:36,684 [run_pretraining.py:  558]:	worker_index: 6, step: 1388, cost: 5.151029, mlm loss: 5.151029, speed: 1.122916 steps/s, speed: 8.983324 samples/s, speed: 4599.462031 tokens/s, learning rate: 1.387e-05, loss_scalings: 8589.935547, pp_loss: 6.888437
[INFO] 2021-07-12 18:59:36,684 [run_pretraining.py:  512]:	********exe.run_1388******* 
[INFO] 2021-07-12 18:59:37,625 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:37,625 [run_pretraining.py:  534]:	loss/total_loss, 7.313038349151611, 1389
[INFO] 2021-07-12 18:59:37,625 [run_pretraining.py:  535]:	loss/mlm_loss, 7.313038349151611, 1389
[INFO] 2021-07-12 18:59:37,625 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3879998732591048e-05, 1389
[INFO] 2021-07-12 18:59:37,626 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1389
[INFO] 2021-07-12 18:59:37,626 [run_pretraining.py:  558]:	worker_index: 6, step: 1389, cost: 7.313038, mlm loss: 7.313038, speed: 1.062944 steps/s, speed: 8.503550 samples/s, speed: 4353.817852 tokens/s, learning rate: 1.388e-05, loss_scalings: 8589.935547, pp_loss: 6.865861
[INFO] 2021-07-12 18:59:37,626 [run_pretraining.py:  512]:	********exe.run_1389******* 
[INFO] 2021-07-12 18:59:38,541 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:38,541 [run_pretraining.py:  534]:	loss/total_loss, 7.367706775665283, 1390
[INFO] 2021-07-12 18:59:38,541 [run_pretraining.py:  535]:	loss/mlm_loss, 7.367706775665283, 1390
[INFO] 2021-07-12 18:59:38,541 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3889999536331743e-05, 1390
[INFO] 2021-07-12 18:59:38,541 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1390
[INFO] 2021-07-12 18:59:38,542 [run_pretraining.py:  558]:	worker_index: 6, step: 1390, cost: 7.367707, mlm loss: 7.367707, speed: 1.092686 steps/s, speed: 8.741489 samples/s, speed: 4475.642261 tokens/s, learning rate: 1.389e-05, loss_scalings: 8589.935547, pp_loss: 6.916101
[INFO] 2021-07-12 18:59:38,542 [run_pretraining.py:  512]:	********exe.run_1390******* 
[INFO] 2021-07-12 18:59:39,447 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:39,447 [run_pretraining.py:  534]:	loss/total_loss, 7.4206929206848145, 1391
[INFO] 2021-07-12 18:59:39,447 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4206929206848145, 1391
[INFO] 2021-07-12 18:59:39,448 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3899999430577736e-05, 1391
[INFO] 2021-07-12 18:59:39,448 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1391
[INFO] 2021-07-12 18:59:39,448 [run_pretraining.py:  558]:	worker_index: 6, step: 1391, cost: 7.420693, mlm loss: 7.420693, speed: 1.104352 steps/s, speed: 8.834819 samples/s, speed: 4523.427527 tokens/s, learning rate: 1.390e-05, loss_scalings: 8589.935547, pp_loss: 7.134879
[INFO] 2021-07-12 18:59:39,448 [run_pretraining.py:  512]:	********exe.run_1391******* 
[INFO] 2021-07-12 18:59:40,341 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:40,342 [run_pretraining.py:  534]:	loss/total_loss, 7.5374040603637695, 1392
[INFO] 2021-07-12 18:59:40,342 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5374040603637695, 1392
[INFO] 2021-07-12 18:59:40,342 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.390999932482373e-05, 1392
[INFO] 2021-07-12 18:59:40,342 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1392
[INFO] 2021-07-12 18:59:40,342 [run_pretraining.py:  558]:	worker_index: 6, step: 1392, cost: 7.537404, mlm loss: 7.537404, speed: 1.119075 steps/s, speed: 8.952602 samples/s, speed: 4583.732105 tokens/s, learning rate: 1.391e-05, loss_scalings: 8589.935547, pp_loss: 6.856180
[INFO] 2021-07-12 18:59:40,342 [run_pretraining.py:  512]:	********exe.run_1392******* 
[INFO] 2021-07-12 18:59:41,239 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:41,239 [run_pretraining.py:  534]:	loss/total_loss, 5.231961727142334, 1393
[INFO] 2021-07-12 18:59:41,240 [run_pretraining.py:  535]:	loss/mlm_loss, 5.231961727142334, 1393
[INFO] 2021-07-12 18:59:41,240 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3920000128564425e-05, 1393
[INFO] 2021-07-12 18:59:41,240 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1393
[INFO] 2021-07-12 18:59:41,240 [run_pretraining.py:  558]:	worker_index: 6, step: 1393, cost: 5.231962, mlm loss: 5.231962, speed: 1.114752 steps/s, speed: 8.918017 samples/s, speed: 4566.024792 tokens/s, learning rate: 1.392e-05, loss_scalings: 8589.935547, pp_loss: 6.696744
[INFO] 2021-07-12 18:59:41,240 [run_pretraining.py:  512]:	********exe.run_1393******* 
[INFO] 2021-07-12 18:59:42,145 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:42,146 [run_pretraining.py:  534]:	loss/total_loss, 7.1551713943481445, 1394
[INFO] 2021-07-12 18:59:42,146 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1551713943481445, 1394
[INFO] 2021-07-12 18:59:42,146 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3930000022810418e-05, 1394
[INFO] 2021-07-12 18:59:42,146 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1394
[INFO] 2021-07-12 18:59:42,146 [run_pretraining.py:  558]:	worker_index: 6, step: 1394, cost: 7.155171, mlm loss: 7.155171, speed: 1.103999 steps/s, speed: 8.831992 samples/s, speed: 4521.979722 tokens/s, learning rate: 1.393e-05, loss_scalings: 8589.935547, pp_loss: 7.212833
[INFO] 2021-07-12 18:59:42,146 [run_pretraining.py:  512]:	********exe.run_1394******* 
[INFO] 2021-07-12 18:59:43,042 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:43,043 [run_pretraining.py:  534]:	loss/total_loss, 6.945460319519043, 1395
[INFO] 2021-07-12 18:59:43,043 [run_pretraining.py:  535]:	loss/mlm_loss, 6.945460319519043, 1395
[INFO] 2021-07-12 18:59:43,043 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3939999917056412e-05, 1395
[INFO] 2021-07-12 18:59:43,043 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1395
[INFO] 2021-07-12 18:59:43,043 [run_pretraining.py:  558]:	worker_index: 6, step: 1395, cost: 6.945460, mlm loss: 6.945460, speed: 1.116299 steps/s, speed: 8.930393 samples/s, speed: 4572.361007 tokens/s, learning rate: 1.394e-05, loss_scalings: 8589.935547, pp_loss: 7.729858
[INFO] 2021-07-12 18:59:43,043 [run_pretraining.py:  512]:	********exe.run_1395******* 
[INFO] 2021-07-12 18:59:43,948 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:43,949 [run_pretraining.py:  534]:	loss/total_loss, 7.816797733306885, 1396
[INFO] 2021-07-12 18:59:43,949 [run_pretraining.py:  535]:	loss/mlm_loss, 7.816797733306885, 1396
[INFO] 2021-07-12 18:59:43,949 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3950000720797107e-05, 1396
[INFO] 2021-07-12 18:59:43,949 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1396
[INFO] 2021-07-12 18:59:43,949 [run_pretraining.py:  558]:	worker_index: 6, step: 1396, cost: 7.816798, mlm loss: 7.816798, speed: 1.104339 steps/s, speed: 8.834712 samples/s, speed: 4523.372741 tokens/s, learning rate: 1.395e-05, loss_scalings: 8589.935547, pp_loss: 7.552128
[INFO] 2021-07-12 18:59:43,949 [run_pretraining.py:  512]:	********exe.run_1396******* 
[INFO] 2021-07-12 18:59:44,847 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:44,847 [run_pretraining.py:  534]:	loss/total_loss, 7.070089340209961, 1397
[INFO] 2021-07-12 18:59:44,847 [run_pretraining.py:  535]:	loss/mlm_loss, 7.070089340209961, 1397
[INFO] 2021-07-12 18:59:44,848 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3959998796053696e-05, 1397
[INFO] 2021-07-12 18:59:44,848 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1397
[INFO] 2021-07-12 18:59:44,848 [run_pretraining.py:  558]:	worker_index: 6, step: 1397, cost: 7.070089, mlm loss: 7.070089, speed: 1.113686 steps/s, speed: 8.909485 samples/s, speed: 4561.656564 tokens/s, learning rate: 1.396e-05, loss_scalings: 8589.935547, pp_loss: 7.340570
[INFO] 2021-07-12 18:59:44,848 [run_pretraining.py:  512]:	********exe.run_1397******* 
[INFO] 2021-07-12 18:59:45,749 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:45,750 [run_pretraining.py:  534]:	loss/total_loss, 7.187039375305176, 1398
[INFO] 2021-07-12 18:59:45,750 [run_pretraining.py:  535]:	loss/mlm_loss, 7.187039375305176, 1398
[INFO] 2021-07-12 18:59:45,750 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3969999599794392e-05, 1398
[INFO] 2021-07-12 18:59:45,750 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1398
[INFO] 2021-07-12 18:59:45,750 [run_pretraining.py:  558]:	worker_index: 6, step: 1398, cost: 7.187039, mlm loss: 7.187039, speed: 1.109216 steps/s, speed: 8.873728 samples/s, speed: 4543.348765 tokens/s, learning rate: 1.397e-05, loss_scalings: 8589.935547, pp_loss: 7.236023
[INFO] 2021-07-12 18:59:45,750 [run_pretraining.py:  512]:	********exe.run_1398******* 
[INFO] 2021-07-12 18:59:46,653 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:46,654 [run_pretraining.py:  534]:	loss/total_loss, 7.618236541748047, 1399
[INFO] 2021-07-12 18:59:46,654 [run_pretraining.py:  535]:	loss/mlm_loss, 7.618236541748047, 1399
[INFO] 2021-07-12 18:59:46,654 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3979999494040385e-05, 1399
[INFO] 2021-07-12 18:59:46,654 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1399
[INFO] 2021-07-12 18:59:46,654 [run_pretraining.py:  558]:	worker_index: 6, step: 1399, cost: 7.618237, mlm loss: 7.618237, speed: 1.106794 steps/s, speed: 8.854354 samples/s, speed: 4533.429065 tokens/s, learning rate: 1.398e-05, loss_scalings: 8589.935547, pp_loss: 7.395158
[INFO] 2021-07-12 18:59:46,654 [run_pretraining.py:  512]:	********exe.run_1399******* 
[INFO] 2021-07-12 18:59:47,552 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:47,552 [run_pretraining.py:  534]:	loss/total_loss, 7.329042434692383, 1400
[INFO] 2021-07-12 18:59:47,552 [run_pretraining.py:  535]:	loss/mlm_loss, 7.329042434692383, 1400
[INFO] 2021-07-12 18:59:47,552 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3989999388286378e-05, 1400
[INFO] 2021-07-12 18:59:47,553 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1400
[INFO] 2021-07-12 18:59:47,553 [run_pretraining.py:  558]:	worker_index: 6, step: 1400, cost: 7.329042, mlm loss: 7.329042, speed: 1.113993 steps/s, speed: 8.911946 samples/s, speed: 4562.916587 tokens/s, learning rate: 1.399e-05, loss_scalings: 8589.935547, pp_loss: 7.724334
[INFO] 2021-07-12 18:59:47,553 [run_pretraining.py:  512]:	********exe.run_1400******* 
[INFO] 2021-07-12 18:59:48,445 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:48,445 [run_pretraining.py:  534]:	loss/total_loss, 7.93812894821167, 1401
[INFO] 2021-07-12 18:59:48,445 [run_pretraining.py:  535]:	loss/mlm_loss, 7.93812894821167, 1401
[INFO] 2021-07-12 18:59:48,445 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3999999282532372e-05, 1401
[INFO] 2021-07-12 18:59:48,446 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1401
[INFO] 2021-07-12 18:59:48,446 [run_pretraining.py:  558]:	worker_index: 6, step: 1401, cost: 7.938129, mlm loss: 7.938129, speed: 1.120652 steps/s, speed: 8.965212 samples/s, speed: 4590.188727 tokens/s, learning rate: 1.400e-05, loss_scalings: 8589.935547, pp_loss: 7.417428
[INFO] 2021-07-12 18:59:48,446 [run_pretraining.py:  512]:	********exe.run_1401******* 
[INFO] 2021-07-12 18:59:49,353 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:49,354 [run_pretraining.py:  534]:	loss/total_loss, 8.145275115966797, 1402
[INFO] 2021-07-12 18:59:49,354 [run_pretraining.py:  535]:	loss/mlm_loss, 8.145275115966797, 1402
[INFO] 2021-07-12 18:59:49,354 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4010000086273067e-05, 1402
[INFO] 2021-07-12 18:59:49,354 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1402
[INFO] 2021-07-12 18:59:49,354 [run_pretraining.py:  558]:	worker_index: 6, step: 1402, cost: 8.145275, mlm loss: 8.145275, speed: 1.101348 steps/s, speed: 8.810788 samples/s, speed: 4511.123413 tokens/s, learning rate: 1.401e-05, loss_scalings: 8589.935547, pp_loss: 7.756172
[INFO] 2021-07-12 18:59:49,354 [run_pretraining.py:  512]:	********exe.run_1402******* 
[INFO] 2021-07-12 18:59:50,246 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:50,247 [run_pretraining.py:  534]:	loss/total_loss, 7.36476469039917, 1403
[INFO] 2021-07-12 18:59:50,247 [run_pretraining.py:  535]:	loss/mlm_loss, 7.36476469039917, 1403
[INFO] 2021-07-12 18:59:50,247 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.401999998051906e-05, 1403
[INFO] 2021-07-12 18:59:50,247 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1403
[INFO] 2021-07-12 18:59:50,247 [run_pretraining.py:  558]:	worker_index: 6, step: 1403, cost: 7.364765, mlm loss: 7.364765, speed: 1.121146 steps/s, speed: 8.969169 samples/s, speed: 4592.214449 tokens/s, learning rate: 1.402e-05, loss_scalings: 8589.935547, pp_loss: 7.586541
[INFO] 2021-07-12 18:59:50,247 [run_pretraining.py:  512]:	********exe.run_1403******* 
[INFO] 2021-07-12 18:59:51,142 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:51,143 [run_pretraining.py:  534]:	loss/total_loss, 7.3731184005737305, 1404
[INFO] 2021-07-12 18:59:51,143 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3731184005737305, 1404
[INFO] 2021-07-12 18:59:51,143 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4029999874765053e-05, 1404
[INFO] 2021-07-12 18:59:51,143 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1404
[INFO] 2021-07-12 18:59:51,143 [run_pretraining.py:  558]:	worker_index: 6, step: 1404, cost: 7.373118, mlm loss: 7.373118, speed: 1.116933 steps/s, speed: 8.935465 samples/s, speed: 4574.958167 tokens/s, learning rate: 1.403e-05, loss_scalings: 8589.935547, pp_loss: 7.415726
[INFO] 2021-07-12 18:59:51,143 [run_pretraining.py:  512]:	********exe.run_1404******* 
[INFO] 2021-07-12 18:59:52,035 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:52,035 [run_pretraining.py:  534]:	loss/total_loss, 7.362630844116211, 1405
[INFO] 2021-07-12 18:59:52,035 [run_pretraining.py:  535]:	loss/mlm_loss, 7.362630844116211, 1405
[INFO] 2021-07-12 18:59:52,036 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4040000678505749e-05, 1405
[INFO] 2021-07-12 18:59:52,036 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1405
[INFO] 2021-07-12 18:59:52,036 [run_pretraining.py:  558]:	worker_index: 6, step: 1405, cost: 7.362631, mlm loss: 7.362631, speed: 1.121111 steps/s, speed: 8.968886 samples/s, speed: 4592.069608 tokens/s, learning rate: 1.404e-05, loss_scalings: 8589.935547, pp_loss: 7.488798
[INFO] 2021-07-12 18:59:52,036 [run_pretraining.py:  512]:	********exe.run_1405******* 
[INFO] 2021-07-12 18:59:52,937 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:52,937 [run_pretraining.py:  534]:	loss/total_loss, 4.838515281677246, 1406
[INFO] 2021-07-12 18:59:52,938 [run_pretraining.py:  535]:	loss/mlm_loss, 4.838515281677246, 1406
[INFO] 2021-07-12 18:59:52,938 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4049998753762338e-05, 1406
[INFO] 2021-07-12 18:59:52,938 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1406
[INFO] 2021-07-12 18:59:52,938 [run_pretraining.py:  558]:	worker_index: 6, step: 1406, cost: 4.838515, mlm loss: 4.838515, speed: 1.109402 steps/s, speed: 8.875216 samples/s, speed: 4544.110659 tokens/s, learning rate: 1.405e-05, loss_scalings: 8589.935547, pp_loss: 7.063091
[INFO] 2021-07-12 18:59:52,938 [run_pretraining.py:  512]:	********exe.run_1406******* 
[INFO] 2021-07-12 18:59:53,825 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:53,826 [run_pretraining.py:  534]:	loss/total_loss, 6.9949541091918945, 1407
[INFO] 2021-07-12 18:59:53,826 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9949541091918945, 1407
[INFO] 2021-07-12 18:59:53,826 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4059999557503033e-05, 1407
[INFO] 2021-07-12 18:59:53,826 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1407
[INFO] 2021-07-12 18:59:53,826 [run_pretraining.py:  558]:	worker_index: 6, step: 1407, cost: 6.994954, mlm loss: 6.994954, speed: 1.126682 steps/s, speed: 9.013452 samples/s, speed: 4614.887446 tokens/s, learning rate: 1.406e-05, loss_scalings: 8589.935547, pp_loss: 7.118945
[INFO] 2021-07-12 18:59:53,826 [run_pretraining.py:  512]:	********exe.run_1407******* 
[INFO] 2021-07-12 18:59:54,726 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:54,727 [run_pretraining.py:  534]:	loss/total_loss, 7.475360870361328, 1408
[INFO] 2021-07-12 18:59:54,727 [run_pretraining.py:  535]:	loss/mlm_loss, 7.475360870361328, 1408
[INFO] 2021-07-12 18:59:54,727 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4069999451749027e-05, 1408
[INFO] 2021-07-12 18:59:54,727 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1408
[INFO] 2021-07-12 18:59:54,727 [run_pretraining.py:  558]:	worker_index: 6, step: 1408, cost: 7.475361, mlm loss: 7.475361, speed: 1.110797 steps/s, speed: 8.886378 samples/s, speed: 4549.825787 tokens/s, learning rate: 1.407e-05, loss_scalings: 8589.935547, pp_loss: 7.583148
[INFO] 2021-07-12 18:59:54,727 [run_pretraining.py:  512]:	********exe.run_1408******* 
[INFO] 2021-07-12 18:59:55,630 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:55,631 [run_pretraining.py:  534]:	loss/total_loss, 7.325200080871582, 1409
[INFO] 2021-07-12 18:59:55,631 [run_pretraining.py:  535]:	loss/mlm_loss, 7.325200080871582, 1409
[INFO] 2021-07-12 18:59:55,631 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.407999934599502e-05, 1409
[INFO] 2021-07-12 18:59:55,631 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1409
[INFO] 2021-07-12 18:59:55,631 [run_pretraining.py:  558]:	worker_index: 6, step: 1409, cost: 7.325200, mlm loss: 7.325200, speed: 1.106679 steps/s, speed: 8.853428 samples/s, speed: 4532.955386 tokens/s, learning rate: 1.408e-05, loss_scalings: 8589.935547, pp_loss: 7.475920
[INFO] 2021-07-12 18:59:55,631 [run_pretraining.py:  512]:	********exe.run_1409******* 
[INFO] 2021-07-12 18:59:56,531 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:56,532 [run_pretraining.py:  534]:	loss/total_loss, 7.412437915802002, 1410
[INFO] 2021-07-12 18:59:56,532 [run_pretraining.py:  535]:	loss/mlm_loss, 7.412437915802002, 1410
[INFO] 2021-07-12 18:59:56,532 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4090000149735715e-05, 1410
[INFO] 2021-07-12 18:59:56,532 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1410
[INFO] 2021-07-12 18:59:56,532 [run_pretraining.py:  558]:	worker_index: 6, step: 1410, cost: 7.412438, mlm loss: 7.412438, speed: 1.110576 steps/s, speed: 8.884609 samples/s, speed: 4548.919844 tokens/s, learning rate: 1.409e-05, loss_scalings: 8589.935547, pp_loss: 7.624673
[INFO] 2021-07-12 18:59:56,533 [run_pretraining.py:  512]:	********exe.run_1410******* 
[INFO] 2021-07-12 18:59:57,514 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:57,515 [run_pretraining.py:  534]:	loss/total_loss, 7.287333965301514, 1411
[INFO] 2021-07-12 18:59:57,515 [run_pretraining.py:  535]:	loss/mlm_loss, 7.287333965301514, 1411
[INFO] 2021-07-12 18:59:57,515 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4100000043981709e-05, 1411
[INFO] 2021-07-12 18:59:57,515 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1411
[INFO] 2021-07-12 18:59:57,515 [run_pretraining.py:  558]:	worker_index: 6, step: 1411, cost: 7.287334, mlm loss: 7.287334, speed: 1.018611 steps/s, speed: 8.148884 samples/s, speed: 4172.228673 tokens/s, learning rate: 1.410e-05, loss_scalings: 8589.935547, pp_loss: 7.710144
[INFO] 2021-07-12 18:59:57,515 [run_pretraining.py:  512]:	********exe.run_1411******* 
[INFO] 2021-07-12 18:59:58,460 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:58,461 [run_pretraining.py:  534]:	loss/total_loss, 7.407939910888672, 1412
[INFO] 2021-07-12 18:59:58,461 [run_pretraining.py:  535]:	loss/mlm_loss, 7.407939910888672, 1412
[INFO] 2021-07-12 18:59:58,461 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4109999938227702e-05, 1412
[INFO] 2021-07-12 18:59:58,461 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1412
[INFO] 2021-07-12 18:59:58,461 [run_pretraining.py:  558]:	worker_index: 6, step: 1412, cost: 7.407940, mlm loss: 7.407940, speed: 1.057572 steps/s, speed: 8.460578 samples/s, speed: 4331.815888 tokens/s, learning rate: 1.411e-05, loss_scalings: 8589.935547, pp_loss: 7.708945
[INFO] 2021-07-12 18:59:58,461 [run_pretraining.py:  512]:	********exe.run_1412******* 
[INFO] 2021-07-12 19:00:23,915 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:23,916 [run_pretraining.py:  534]:	loss/total_loss, 7.778971195220947, 1413
[INFO] 2021-07-12 19:00:23,916 [run_pretraining.py:  535]:	loss/mlm_loss, 7.778971195220947, 1413
[INFO] 2021-07-12 19:00:23,916 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4119999832473695e-05, 1413
[INFO] 2021-07-12 19:00:23,916 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1413
[INFO] 2021-07-12 19:00:23,916 [run_pretraining.py:  558]:	worker_index: 6, step: 1413, cost: 7.778971, mlm loss: 7.778971, speed: 0.039286 steps/s, speed: 0.314286 samples/s, speed: 160.914533 tokens/s, learning rate: 1.412e-05, loss_scalings: 8589.935547, pp_loss: 8.010364
[INFO] 2021-07-12 19:00:23,917 [run_pretraining.py:  512]:	********exe.run_1413******* 
[INFO] 2021-07-12 19:00:24,818 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:24,818 [run_pretraining.py:  534]:	loss/total_loss, 7.529221057891846, 1414
[INFO] 2021-07-12 19:00:24,818 [run_pretraining.py:  535]:	loss/mlm_loss, 7.529221057891846, 1414
[INFO] 2021-07-12 19:00:24,818 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4129998817224987e-05, 1414
[INFO] 2021-07-12 19:00:24,819 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1414
[INFO] 2021-07-12 19:00:24,819 [run_pretraining.py:  558]:	worker_index: 6, step: 1414, cost: 7.529221, mlm loss: 7.529221, speed: 1.109332 steps/s, speed: 8.874653 samples/s, speed: 4543.822215 tokens/s, learning rate: 1.413e-05, loss_scalings: 8589.935547, pp_loss: 7.622620
[INFO] 2021-07-12 19:00:24,819 [run_pretraining.py:  512]:	********exe.run_1414******* 
[INFO] 2021-07-12 19:00:25,719 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:25,719 [run_pretraining.py:  534]:	loss/total_loss, 7.407327175140381, 1415
[INFO] 2021-07-12 19:00:25,719 [run_pretraining.py:  535]:	loss/mlm_loss, 7.407327175140381, 1415
[INFO] 2021-07-12 19:00:25,719 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.413999871147098e-05, 1415
[INFO] 2021-07-12 19:00:25,720 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1415
[INFO] 2021-07-12 19:00:25,720 [run_pretraining.py:  558]:	worker_index: 6, step: 1415, cost: 7.407327, mlm loss: 7.407327, speed: 1.110813 steps/s, speed: 8.886506 samples/s, speed: 4549.890856 tokens/s, learning rate: 1.414e-05, loss_scalings: 8589.935547, pp_loss: 6.703410
[INFO] 2021-07-12 19:00:25,720 [run_pretraining.py:  512]:	********exe.run_1415******* 
[INFO] 2021-07-12 19:00:26,715 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:26,716 [run_pretraining.py:  534]:	loss/total_loss, 7.18850564956665, 1416
[INFO] 2021-07-12 19:00:26,716 [run_pretraining.py:  535]:	loss/mlm_loss, 7.18850564956665, 1416
[INFO] 2021-07-12 19:00:26,716 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4149999515211675e-05, 1416
[INFO] 2021-07-12 19:00:26,716 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1416
[INFO] 2021-07-12 19:00:26,716 [run_pretraining.py:  558]:	worker_index: 6, step: 1416, cost: 7.188506, mlm loss: 7.188506, speed: 1.004274 steps/s, speed: 8.034192 samples/s, speed: 4113.506143 tokens/s, learning rate: 1.415e-05, loss_scalings: 8589.935547, pp_loss: 7.536232
[INFO] 2021-07-12 19:00:26,716 [run_pretraining.py:  512]:	********exe.run_1416******* 
[INFO] 2021-07-12 19:00:27,767 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:27,767 [run_pretraining.py:  534]:	loss/total_loss, 7.431941032409668, 1417
[INFO] 2021-07-12 19:00:27,767 [run_pretraining.py:  535]:	loss/mlm_loss, 7.431941032409668, 1417
[INFO] 2021-07-12 19:00:27,767 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4159999409457669e-05, 1417
[INFO] 2021-07-12 19:00:27,767 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1417
[INFO] 2021-07-12 19:00:27,768 [run_pretraining.py:  558]:	worker_index: 6, step: 1417, cost: 7.431941, mlm loss: 7.431941, speed: 0.951702 steps/s, speed: 7.613614 samples/s, speed: 3898.170565 tokens/s, learning rate: 1.416e-05, loss_scalings: 8589.935547, pp_loss: 6.814530
[INFO] 2021-07-12 19:00:27,768 [run_pretraining.py:  512]:	********exe.run_1417******* 
[INFO] 2021-07-12 19:00:28,819 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:28,819 [run_pretraining.py:  534]:	loss/total_loss, 7.923225402832031, 1418
[INFO] 2021-07-12 19:00:28,820 [run_pretraining.py:  535]:	loss/mlm_loss, 7.923225402832031, 1418
[INFO] 2021-07-12 19:00:28,820 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4169999303703662e-05, 1418
[INFO] 2021-07-12 19:00:28,820 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1418
[INFO] 2021-07-12 19:00:28,820 [run_pretraining.py:  558]:	worker_index: 6, step: 1418, cost: 7.923225, mlm loss: 7.923225, speed: 0.951011 steps/s, speed: 7.608085 samples/s, speed: 3895.339543 tokens/s, learning rate: 1.417e-05, loss_scalings: 8589.935547, pp_loss: 7.296637
[INFO] 2021-07-12 19:00:28,820 [run_pretraining.py:  512]:	********exe.run_1418******* 
[INFO] 2021-07-12 19:00:29,875 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:29,875 [run_pretraining.py:  534]:	loss/total_loss, 7.5033793449401855, 1419
[INFO] 2021-07-12 19:00:29,875 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5033793449401855, 1419
[INFO] 2021-07-12 19:00:29,876 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4180000107444357e-05, 1419
[INFO] 2021-07-12 19:00:29,876 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1419
[INFO] 2021-07-12 19:00:29,876 [run_pretraining.py:  558]:	worker_index: 6, step: 1419, cost: 7.503379, mlm loss: 7.503379, speed: 0.947727 steps/s, speed: 7.581812 samples/s, speed: 3881.887846 tokens/s, learning rate: 1.418e-05, loss_scalings: 8589.935547, pp_loss: 7.445211
[INFO] 2021-07-12 19:00:29,876 [run_pretraining.py:  512]:	********exe.run_1419******* 
[INFO] 2021-07-12 19:00:30,933 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:30,933 [run_pretraining.py:  534]:	loss/total_loss, 7.518768310546875, 1420
[INFO] 2021-07-12 19:00:30,933 [run_pretraining.py:  535]:	loss/mlm_loss, 7.518768310546875, 1420
[INFO] 2021-07-12 19:00:30,934 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.419000000169035e-05, 1420
[INFO] 2021-07-12 19:00:30,934 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1420
[INFO] 2021-07-12 19:00:30,934 [run_pretraining.py:  558]:	worker_index: 6, step: 1420, cost: 7.518768, mlm loss: 7.518768, speed: 0.945776 steps/s, speed: 7.566207 samples/s, speed: 3873.897844 tokens/s, learning rate: 1.419e-05, loss_scalings: 8589.935547, pp_loss: 7.577236
[INFO] 2021-07-12 19:00:30,934 [run_pretraining.py:  512]:	********exe.run_1420******* 
[INFO] 2021-07-12 19:00:31,983 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:31,984 [run_pretraining.py:  534]:	loss/total_loss, 7.911432266235352, 1421
[INFO] 2021-07-12 19:00:31,984 [run_pretraining.py:  535]:	loss/mlm_loss, 7.911432266235352, 1421
[INFO] 2021-07-12 19:00:31,984 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4199999895936344e-05, 1421
[INFO] 2021-07-12 19:00:31,984 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1421
[INFO] 2021-07-12 19:00:31,984 [run_pretraining.py:  558]:	worker_index: 6, step: 1421, cost: 7.911432, mlm loss: 7.911432, speed: 0.952393 steps/s, speed: 7.619143 samples/s, speed: 3901.001276 tokens/s, learning rate: 1.420e-05, loss_scalings: 8589.935547, pp_loss: 7.606956
[INFO] 2021-07-12 19:00:31,984 [run_pretraining.py:  512]:	********exe.run_1421******* 
[INFO] 2021-07-12 19:00:33,042 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:33,043 [run_pretraining.py:  534]:	loss/total_loss, 7.922129154205322, 1422
[INFO] 2021-07-12 19:00:33,043 [run_pretraining.py:  535]:	loss/mlm_loss, 7.922129154205322, 1422
[INFO] 2021-07-12 19:00:33,043 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4210000699677039e-05, 1422
[INFO] 2021-07-12 19:00:33,043 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1422
[INFO] 2021-07-12 19:00:33,043 [run_pretraining.py:  558]:	worker_index: 6, step: 1422, cost: 7.922129, mlm loss: 7.922129, speed: 0.945004 steps/s, speed: 7.560034 samples/s, speed: 3870.737382 tokens/s, learning rate: 1.421e-05, loss_scalings: 8589.935547, pp_loss: 7.539197
[INFO] 2021-07-12 19:00:33,043 [run_pretraining.py:  512]:	********exe.run_1422******* 
[INFO] 2021-07-12 19:00:34,094 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:34,095 [run_pretraining.py:  534]:	loss/total_loss, 7.018289566040039, 1423
[INFO] 2021-07-12 19:00:34,095 [run_pretraining.py:  535]:	loss/mlm_loss, 7.018289566040039, 1423
[INFO] 2021-07-12 19:00:34,095 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4219998774933629e-05, 1423
[INFO] 2021-07-12 19:00:34,095 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1423
[INFO] 2021-07-12 19:00:34,095 [run_pretraining.py:  558]:	worker_index: 6, step: 1423, cost: 7.018290, mlm loss: 7.018290, speed: 0.951392 steps/s, speed: 7.611133 samples/s, speed: 3896.899941 tokens/s, learning rate: 1.422e-05, loss_scalings: 8589.935547, pp_loss: 7.349555
[INFO] 2021-07-12 19:00:34,095 [run_pretraining.py:  512]:	********exe.run_1423******* 
[INFO] 2021-07-12 19:00:35,162 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:35,163 [run_pretraining.py:  534]:	loss/total_loss, 7.420193672180176, 1424
[INFO] 2021-07-12 19:00:35,163 [run_pretraining.py:  535]:	loss/mlm_loss, 7.420193672180176, 1424
[INFO] 2021-07-12 19:00:35,163 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4229998669179622e-05, 1424
[INFO] 2021-07-12 19:00:35,163 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1424
[INFO] 2021-07-12 19:00:35,163 [run_pretraining.py:  558]:	worker_index: 6, step: 1424, cost: 7.420194, mlm loss: 7.420194, speed: 0.936994 steps/s, speed: 7.495954 samples/s, speed: 3837.928536 tokens/s, learning rate: 1.423e-05, loss_scalings: 8589.935547, pp_loss: 7.378332
[INFO] 2021-07-12 19:00:35,163 [run_pretraining.py:  512]:	********exe.run_1424******* 
[INFO] 2021-07-12 19:00:36,229 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:36,230 [run_pretraining.py:  534]:	loss/total_loss, 7.680380821228027, 1425
[INFO] 2021-07-12 19:00:36,230 [run_pretraining.py:  535]:	loss/mlm_loss, 7.680380821228027, 1425
[INFO] 2021-07-12 19:00:36,230 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4239999472920317e-05, 1425
[INFO] 2021-07-12 19:00:36,230 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1425
[INFO] 2021-07-12 19:00:36,230 [run_pretraining.py:  558]:	worker_index: 6, step: 1425, cost: 7.680381, mlm loss: 7.680381, speed: 0.937748 steps/s, speed: 7.501984 samples/s, speed: 3841.015875 tokens/s, learning rate: 1.424e-05, loss_scalings: 8589.935547, pp_loss: 7.712364
[INFO] 2021-07-12 19:00:36,230 [run_pretraining.py:  512]:	********exe.run_1425******* 
[INFO] 2021-07-12 19:00:37,350 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:37,350 [run_pretraining.py:  534]:	loss/total_loss, 7.451616287231445, 1426
[INFO] 2021-07-12 19:00:37,351 [run_pretraining.py:  535]:	loss/mlm_loss, 7.451616287231445, 1426
[INFO] 2021-07-12 19:00:37,351 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.424999936716631e-05, 1426
[INFO] 2021-07-12 19:00:37,351 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1426
[INFO] 2021-07-12 19:00:37,351 [run_pretraining.py:  558]:	worker_index: 6, step: 1426, cost: 7.451616, mlm loss: 7.451616, speed: 0.892890 steps/s, speed: 7.143122 samples/s, speed: 3657.278697 tokens/s, learning rate: 1.425e-05, loss_scalings: 8589.935547, pp_loss: 7.296202
[INFO] 2021-07-12 19:00:37,351 [run_pretraining.py:  512]:	********exe.run_1426******* 
[INFO] 2021-07-12 19:00:38,323 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:38,324 [run_pretraining.py:  534]:	loss/total_loss, 7.941287994384766, 1427
[INFO] 2021-07-12 19:00:38,324 [run_pretraining.py:  535]:	loss/mlm_loss, 7.941287994384766, 1427
[INFO] 2021-07-12 19:00:38,324 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4259999261412304e-05, 1427
[INFO] 2021-07-12 19:00:38,324 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1427
[INFO] 2021-07-12 19:00:38,324 [run_pretraining.py:  558]:	worker_index: 6, step: 1427, cost: 7.941288, mlm loss: 7.941288, speed: 1.028258 steps/s, speed: 8.226063 samples/s, speed: 4211.744282 tokens/s, learning rate: 1.426e-05, loss_scalings: 8589.935547, pp_loss: 7.695614
[INFO] 2021-07-12 19:00:38,324 [run_pretraining.py:  512]:	********exe.run_1427******* 
[INFO] 2021-07-12 19:00:39,228 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:39,229 [run_pretraining.py:  534]:	loss/total_loss, 6.835367202758789, 1428
[INFO] 2021-07-12 19:00:39,229 [run_pretraining.py:  535]:	loss/mlm_loss, 6.835367202758789, 1428
[INFO] 2021-07-12 19:00:39,229 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4270000065152999e-05, 1428
[INFO] 2021-07-12 19:00:39,229 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1428
[INFO] 2021-07-12 19:00:39,229 [run_pretraining.py:  558]:	worker_index: 6, step: 1428, cost: 6.835367, mlm loss: 6.835367, speed: 1.105414 steps/s, speed: 8.843316 samples/s, speed: 4527.777702 tokens/s, learning rate: 1.427e-05, loss_scalings: 8589.935547, pp_loss: 7.241460
[INFO] 2021-07-12 19:00:39,230 [run_pretraining.py:  512]:	********exe.run_1428******* 
[INFO] 2021-07-12 19:00:40,127 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:40,127 [run_pretraining.py:  534]:	loss/total_loss, 7.954240798950195, 1429
[INFO] 2021-07-12 19:00:40,127 [run_pretraining.py:  535]:	loss/mlm_loss, 7.954240798950195, 1429
[INFO] 2021-07-12 19:00:40,127 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4279999959398992e-05, 1429
[INFO] 2021-07-12 19:00:40,128 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1429
[INFO] 2021-07-12 19:00:40,128 [run_pretraining.py:  558]:	worker_index: 6, step: 1429, cost: 7.954241, mlm loss: 7.954241, speed: 1.114255 steps/s, speed: 8.914042 samples/s, speed: 4563.989367 tokens/s, learning rate: 1.428e-05, loss_scalings: 8589.935547, pp_loss: 7.422839
[INFO] 2021-07-12 19:00:40,128 [run_pretraining.py:  512]:	********exe.run_1429******* 
[INFO] 2021-07-12 19:00:41,026 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:41,027 [run_pretraining.py:  534]:	loss/total_loss, 7.219487190246582, 1430
[INFO] 2021-07-12 19:00:41,027 [run_pretraining.py:  535]:	loss/mlm_loss, 7.219487190246582, 1430
[INFO] 2021-07-12 19:00:41,027 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4289999853644986e-05, 1430
[INFO] 2021-07-12 19:00:41,027 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1430
[INFO] 2021-07-12 19:00:41,027 [run_pretraining.py:  558]:	worker_index: 6, step: 1430, cost: 7.219487, mlm loss: 7.219487, speed: 1.112854 steps/s, speed: 8.902831 samples/s, speed: 4558.249508 tokens/s, learning rate: 1.429e-05, loss_scalings: 8589.935547, pp_loss: 7.228111
[INFO] 2021-07-12 19:00:41,027 [run_pretraining.py:  512]:	********exe.run_1430******* 
[INFO] 2021-07-12 19:00:41,922 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:41,923 [run_pretraining.py:  534]:	loss/total_loss, 7.203571796417236, 1431
[INFO] 2021-07-12 19:00:41,923 [run_pretraining.py:  535]:	loss/mlm_loss, 7.203571796417236, 1431
[INFO] 2021-07-12 19:00:41,923 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.430000065738568e-05, 1431
[INFO] 2021-07-12 19:00:41,923 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1431
[INFO] 2021-07-12 19:00:41,923 [run_pretraining.py:  558]:	worker_index: 6, step: 1431, cost: 7.203572, mlm loss: 7.203572, speed: 1.116929 steps/s, speed: 8.935434 samples/s, speed: 4574.942329 tokens/s, learning rate: 1.430e-05, loss_scalings: 8589.935547, pp_loss: 7.131906
[INFO] 2021-07-12 19:00:41,923 [run_pretraining.py:  512]:	********exe.run_1431******* 
[INFO] 2021-07-12 19:00:42,828 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:42,829 [run_pretraining.py:  534]:	loss/total_loss, 7.470686435699463, 1432
[INFO] 2021-07-12 19:00:42,829 [run_pretraining.py:  535]:	loss/mlm_loss, 7.470686435699463, 1432
[INFO] 2021-07-12 19:00:42,829 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.430999873264227e-05, 1432
[INFO] 2021-07-12 19:00:42,829 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1432
[INFO] 2021-07-12 19:00:42,829 [run_pretraining.py:  558]:	worker_index: 6, step: 1432, cost: 7.470686, mlm loss: 7.470686, speed: 1.104326 steps/s, speed: 8.834610 samples/s, speed: 4523.320338 tokens/s, learning rate: 1.431e-05, loss_scalings: 8589.935547, pp_loss: 7.415413
[INFO] 2021-07-12 19:00:42,829 [run_pretraining.py:  512]:	********exe.run_1432******* 
[INFO] 2021-07-12 19:00:43,726 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:43,727 [run_pretraining.py:  534]:	loss/total_loss, 6.876391410827637, 1433
[INFO] 2021-07-12 19:00:43,727 [run_pretraining.py:  535]:	loss/mlm_loss, 6.876391410827637, 1433
[INFO] 2021-07-12 19:00:43,727 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4319999536382966e-05, 1433
[INFO] 2021-07-12 19:00:43,727 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1433
[INFO] 2021-07-12 19:00:43,727 [run_pretraining.py:  558]:	worker_index: 6, step: 1433, cost: 6.876391, mlm loss: 6.876391, speed: 1.114626 steps/s, speed: 8.917008 samples/s, speed: 4565.507879 tokens/s, learning rate: 1.432e-05, loss_scalings: 8589.935547, pp_loss: 7.188182
[INFO] 2021-07-12 19:00:43,727 [run_pretraining.py:  512]:	********exe.run_1433******* 
[INFO] 2021-07-12 19:00:44,616 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:44,616 [run_pretraining.py:  534]:	loss/total_loss, 7.403301239013672, 1434
[INFO] 2021-07-12 19:00:44,617 [run_pretraining.py:  535]:	loss/mlm_loss, 7.403301239013672, 1434
[INFO] 2021-07-12 19:00:44,617 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4329999430628959e-05, 1434
[INFO] 2021-07-12 19:00:44,617 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1434
[INFO] 2021-07-12 19:00:44,617 [run_pretraining.py:  558]:	worker_index: 6, step: 1434, cost: 7.403301, mlm loss: 7.403301, speed: 1.124779 steps/s, speed: 8.998229 samples/s, speed: 4607.093257 tokens/s, learning rate: 1.433e-05, loss_scalings: 8589.935547, pp_loss: 7.397344
[INFO] 2021-07-12 19:00:44,617 [run_pretraining.py:  512]:	********exe.run_1434******* 
[INFO] 2021-07-12 19:00:45,510 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:45,511 [run_pretraining.py:  534]:	loss/total_loss, 7.707668781280518, 1435
[INFO] 2021-07-12 19:00:45,511 [run_pretraining.py:  535]:	loss/mlm_loss, 7.707668781280518, 1435
[INFO] 2021-07-12 19:00:45,511 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4339999324874952e-05, 1435
[INFO] 2021-07-12 19:00:45,511 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1435
[INFO] 2021-07-12 19:00:45,511 [run_pretraining.py:  558]:	worker_index: 6, step: 1435, cost: 7.707669, mlm loss: 7.707669, speed: 1.118629 steps/s, speed: 8.949030 samples/s, speed: 4581.903260 tokens/s, learning rate: 1.434e-05, loss_scalings: 8589.935547, pp_loss: 7.428360
[INFO] 2021-07-12 19:00:45,512 [run_pretraining.py:  512]:	********exe.run_1435******* 
[INFO] 2021-07-12 19:00:46,401 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:46,402 [run_pretraining.py:  534]:	loss/total_loss, 7.3045148849487305, 1436
[INFO] 2021-07-12 19:00:46,402 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3045148849487305, 1436
[INFO] 2021-07-12 19:00:46,402 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4349999219120946e-05, 1436
[INFO] 2021-07-12 19:00:46,402 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1436
[INFO] 2021-07-12 19:00:46,402 [run_pretraining.py:  558]:	worker_index: 6, step: 1436, cost: 7.304515, mlm loss: 7.304515, speed: 1.123679 steps/s, speed: 8.989432 samples/s, speed: 4602.589414 tokens/s, learning rate: 1.435e-05, loss_scalings: 8589.935547, pp_loss: 7.710984
[INFO] 2021-07-12 19:00:46,402 [run_pretraining.py:  512]:	********exe.run_1436******* 
[INFO] 2021-07-12 19:00:47,302 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:47,303 [run_pretraining.py:  534]:	loss/total_loss, 7.533461093902588, 1437
[INFO] 2021-07-12 19:00:47,303 [run_pretraining.py:  535]:	loss/mlm_loss, 7.533461093902588, 1437
[INFO] 2021-07-12 19:00:47,303 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4360000022861641e-05, 1437
[INFO] 2021-07-12 19:00:47,303 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1437
[INFO] 2021-07-12 19:00:47,303 [run_pretraining.py:  558]:	worker_index: 6, step: 1437, cost: 7.533461, mlm loss: 7.533461, speed: 1.110806 steps/s, speed: 8.886444 samples/s, speed: 4549.859526 tokens/s, learning rate: 1.436e-05, loss_scalings: 8589.935547, pp_loss: 7.711313
[INFO] 2021-07-12 19:00:47,303 [run_pretraining.py:  512]:	********exe.run_1437******* 
[INFO] 2021-07-12 19:00:48,193 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:48,193 [run_pretraining.py:  534]:	loss/total_loss, 7.446763038635254, 1438
[INFO] 2021-07-12 19:00:48,193 [run_pretraining.py:  535]:	loss/mlm_loss, 7.446763038635254, 1438
[INFO] 2021-07-12 19:00:48,194 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4369999917107634e-05, 1438
[INFO] 2021-07-12 19:00:48,194 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1438
[INFO] 2021-07-12 19:00:48,194 [run_pretraining.py:  558]:	worker_index: 6, step: 1438, cost: 7.446763, mlm loss: 7.446763, speed: 1.123629 steps/s, speed: 8.989033 samples/s, speed: 4602.384735 tokens/s, learning rate: 1.437e-05, loss_scalings: 8589.935547, pp_loss: 7.295767
[INFO] 2021-07-12 19:00:48,194 [run_pretraining.py:  512]:	********exe.run_1438******* 
[INFO] 2021-07-12 19:00:49,095 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:49,096 [run_pretraining.py:  534]:	loss/total_loss, 7.58321475982666, 1439
[INFO] 2021-07-12 19:00:49,096 [run_pretraining.py:  535]:	loss/mlm_loss, 7.58321475982666, 1439
[INFO] 2021-07-12 19:00:49,096 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4379999811353628e-05, 1439
[INFO] 2021-07-12 19:00:49,096 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1439
[INFO] 2021-07-12 19:00:49,096 [run_pretraining.py:  558]:	worker_index: 6, step: 1439, cost: 7.583215, mlm loss: 7.583215, speed: 1.108908 steps/s, speed: 8.871267 samples/s, speed: 4542.088717 tokens/s, learning rate: 1.438e-05, loss_scalings: 8589.935547, pp_loss: 7.540112
[INFO] 2021-07-12 19:00:49,096 [run_pretraining.py:  512]:	********exe.run_1439******* 
[INFO] 2021-07-12 19:00:49,994 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:49,994 [run_pretraining.py:  534]:	loss/total_loss, 7.802773475646973, 1440
[INFO] 2021-07-12 19:00:49,994 [run_pretraining.py:  535]:	loss/mlm_loss, 7.802773475646973, 1440
[INFO] 2021-07-12 19:00:49,995 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4390000615094323e-05, 1440
[INFO] 2021-07-12 19:00:49,995 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1440
[INFO] 2021-07-12 19:00:49,995 [run_pretraining.py:  558]:	worker_index: 6, step: 1440, cost: 7.802773, mlm loss: 7.802773, speed: 1.113837 steps/s, speed: 8.910697 samples/s, speed: 4562.276796 tokens/s, learning rate: 1.439e-05, loss_scalings: 8589.935547, pp_loss: 7.494501
[INFO] 2021-07-12 19:00:49,995 [run_pretraining.py:  512]:	********exe.run_1440******* 
[INFO] 2021-07-12 19:00:50,895 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:50,895 [run_pretraining.py:  534]:	loss/total_loss, 7.865927696228027, 1441
[INFO] 2021-07-12 19:00:50,895 [run_pretraining.py:  535]:	loss/mlm_loss, 7.865927696228027, 1441
[INFO] 2021-07-12 19:00:50,895 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4399998690350913e-05, 1441
[INFO] 2021-07-12 19:00:50,896 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1441
[INFO] 2021-07-12 19:00:50,896 [run_pretraining.py:  558]:	worker_index: 6, step: 1441, cost: 7.865928, mlm loss: 7.865928, speed: 1.111003 steps/s, speed: 8.888026 samples/s, speed: 4550.669410 tokens/s, learning rate: 1.440e-05, loss_scalings: 8589.935547, pp_loss: 7.512214
[INFO] 2021-07-12 19:00:50,896 [run_pretraining.py:  512]:	********exe.run_1441******* 
[INFO] 2021-07-12 19:00:51,790 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:51,791 [run_pretraining.py:  534]:	loss/total_loss, 7.72937536239624, 1442
[INFO] 2021-07-12 19:00:51,791 [run_pretraining.py:  535]:	loss/mlm_loss, 7.72937536239624, 1442
[INFO] 2021-07-12 19:00:51,791 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4409999494091608e-05, 1442
[INFO] 2021-07-12 19:00:51,791 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1442
[INFO] 2021-07-12 19:00:51,792 [run_pretraining.py:  558]:	worker_index: 6, step: 1442, cost: 7.729375, mlm loss: 7.729375, speed: 1.117127 steps/s, speed: 8.937019 samples/s, speed: 4575.753856 tokens/s, learning rate: 1.441e-05, loss_scalings: 8589.935547, pp_loss: 7.298036
[INFO] 2021-07-12 19:00:51,792 [run_pretraining.py:  512]:	********exe.run_1442******* 
[INFO] 2021-07-12 19:00:52,717 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:52,717 [run_pretraining.py:  534]:	loss/total_loss, 7.7118754386901855, 1443
[INFO] 2021-07-12 19:00:52,717 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7118754386901855, 1443
[INFO] 2021-07-12 19:00:52,717 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4419999388337601e-05, 1443
[INFO] 2021-07-12 19:00:52,717 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1443
[INFO] 2021-07-12 19:00:52,717 [run_pretraining.py:  558]:	worker_index: 6, step: 1443, cost: 7.711875, mlm loss: 7.711875, speed: 1.080733 steps/s, speed: 8.645864 samples/s, speed: 4426.682116 tokens/s, learning rate: 1.442e-05, loss_scalings: 8589.935547, pp_loss: 7.641612
[INFO] 2021-07-12 19:00:52,718 [run_pretraining.py:  512]:	********exe.run_1443******* 
[INFO] 2021-07-12 19:00:53,622 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:53,622 [run_pretraining.py:  534]:	loss/total_loss, 7.50408935546875, 1444
[INFO] 2021-07-12 19:00:53,622 [run_pretraining.py:  535]:	loss/mlm_loss, 7.50408935546875, 1444
[INFO] 2021-07-12 19:00:53,622 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4429999282583594e-05, 1444
[INFO] 2021-07-12 19:00:53,622 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1444
[INFO] 2021-07-12 19:00:53,623 [run_pretraining.py:  558]:	worker_index: 6, step: 1444, cost: 7.504089, mlm loss: 7.504089, speed: 1.105744 steps/s, speed: 8.845955 samples/s, speed: 4529.128923 tokens/s, learning rate: 1.443e-05, loss_scalings: 8589.935547, pp_loss: 7.473670
[INFO] 2021-07-12 19:00:53,623 [run_pretraining.py:  512]:	********exe.run_1444******* 
[INFO] 2021-07-12 19:00:54,543 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:54,543 [run_pretraining.py:  534]:	loss/total_loss, 7.734088897705078, 1445
[INFO] 2021-07-12 19:00:54,544 [run_pretraining.py:  535]:	loss/mlm_loss, 7.734088897705078, 1445
[INFO] 2021-07-12 19:00:54,544 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.444000008632429e-05, 1445
[INFO] 2021-07-12 19:00:54,544 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1445
[INFO] 2021-07-12 19:00:54,544 [run_pretraining.py:  558]:	worker_index: 6, step: 1445, cost: 7.734089, mlm loss: 7.734089, speed: 1.086306 steps/s, speed: 8.690449 samples/s, speed: 4449.509899 tokens/s, learning rate: 1.444e-05, loss_scalings: 8589.935547, pp_loss: 7.557659
[INFO] 2021-07-12 19:00:54,544 [run_pretraining.py:  512]:	********exe.run_1445******* 
[INFO] 2021-07-12 19:00:55,444 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:55,444 [run_pretraining.py:  534]:	loss/total_loss, 6.945703983306885, 1446
[INFO] 2021-07-12 19:00:55,444 [run_pretraining.py:  535]:	loss/mlm_loss, 6.945703983306885, 1446
[INFO] 2021-07-12 19:00:55,445 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4449999980570283e-05, 1446
[INFO] 2021-07-12 19:00:55,445 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1446
[INFO] 2021-07-12 19:00:55,445 [run_pretraining.py:  558]:	worker_index: 6, step: 1446, cost: 6.945704, mlm loss: 6.945704, speed: 1.110877 steps/s, speed: 8.887016 samples/s, speed: 4550.152353 tokens/s, learning rate: 1.445e-05, loss_scalings: 8589.935547, pp_loss: 7.141562
[INFO] 2021-07-12 19:00:55,445 [run_pretraining.py:  512]:	********exe.run_1446******* 
[INFO] 2021-07-12 19:00:56,346 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:56,347 [run_pretraining.py:  534]:	loss/total_loss, 6.885861396789551, 1447
[INFO] 2021-07-12 19:00:56,347 [run_pretraining.py:  535]:	loss/mlm_loss, 6.885861396789551, 1447
[INFO] 2021-07-12 19:00:56,347 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4459999874816276e-05, 1447
[INFO] 2021-07-12 19:00:56,347 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1447
[INFO] 2021-07-12 19:00:56,347 [run_pretraining.py:  558]:	worker_index: 6, step: 1447, cost: 6.885861, mlm loss: 6.885861, speed: 1.108910 steps/s, speed: 8.871276 samples/s, speed: 4542.093520 tokens/s, learning rate: 1.446e-05, loss_scalings: 8589.935547, pp_loss: 7.056556
[INFO] 2021-07-12 19:00:56,347 [run_pretraining.py:  512]:	********exe.run_1447******* 
[INFO] 2021-07-12 19:00:57,322 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:57,323 [run_pretraining.py:  534]:	loss/total_loss, 7.656930923461914, 1448
[INFO] 2021-07-12 19:00:57,323 [run_pretraining.py:  535]:	loss/mlm_loss, 7.656930923461914, 1448
[INFO] 2021-07-12 19:00:57,323 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.446999976906227e-05, 1448
[INFO] 2021-07-12 19:00:57,323 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1448
[INFO] 2021-07-12 19:00:57,323 [run_pretraining.py:  558]:	worker_index: 6, step: 1448, cost: 7.656931, mlm loss: 7.656931, speed: 1.025598 steps/s, speed: 8.204782 samples/s, speed: 4200.848339 tokens/s, learning rate: 1.447e-05, loss_scalings: 8589.935547, pp_loss: 7.380522
[INFO] 2021-07-12 19:00:57,323 [run_pretraining.py:  512]:	********exe.run_1448******* 
[INFO] 2021-07-12 19:00:58,255 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:58,255 [run_pretraining.py:  534]:	loss/total_loss, 7.594314098358154, 1449
[INFO] 2021-07-12 19:00:58,256 [run_pretraining.py:  535]:	loss/mlm_loss, 7.594314098358154, 1449
[INFO] 2021-07-12 19:00:58,256 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4480000572802965e-05, 1449
[INFO] 2021-07-12 19:00:58,256 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1449
[INFO] 2021-07-12 19:00:58,256 [run_pretraining.py:  558]:	worker_index: 6, step: 1449, cost: 7.594314, mlm loss: 7.594314, speed: 1.072893 steps/s, speed: 8.583145 samples/s, speed: 4394.570230 tokens/s, learning rate: 1.448e-05, loss_scalings: 8589.935547, pp_loss: 7.225817
[INFO] 2021-07-12 19:00:58,256 [run_pretraining.py:  512]:	********exe.run_1449******* 
[INFO] 2021-07-12 19:00:59,155 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:59,156 [run_pretraining.py:  534]:	loss/total_loss, 6.398165702819824, 1450
[INFO] 2021-07-12 19:00:59,156 [run_pretraining.py:  535]:	loss/mlm_loss, 6.398165702819824, 1450
[INFO] 2021-07-12 19:00:59,156 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4489998648059554e-05, 1450
[INFO] 2021-07-12 19:00:59,156 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1450
[INFO] 2021-07-12 19:00:59,156 [run_pretraining.py:  558]:	worker_index: 6, step: 1450, cost: 6.398166, mlm loss: 6.398166, speed: 1.111488 steps/s, speed: 8.891903 samples/s, speed: 4552.654362 tokens/s, learning rate: 1.449e-05, loss_scalings: 8589.935547, pp_loss: 7.093590
[INFO] 2021-07-12 19:00:59,156 [run_pretraining.py:  512]:	********exe.run_1450******* 
[INFO] 2021-07-12 19:01:00,059 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:00,059 [run_pretraining.py:  534]:	loss/total_loss, 7.485584259033203, 1451
[INFO] 2021-07-12 19:01:00,060 [run_pretraining.py:  535]:	loss/mlm_loss, 7.485584259033203, 1451
[INFO] 2021-07-12 19:01:00,060 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.449999945180025e-05, 1451
[INFO] 2021-07-12 19:01:00,060 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1451
[INFO] 2021-07-12 19:01:00,060 [run_pretraining.py:  558]:	worker_index: 6, step: 1451, cost: 7.485584, mlm loss: 7.485584, speed: 1.107525 steps/s, speed: 8.860203 samples/s, speed: 4536.424141 tokens/s, learning rate: 1.450e-05, loss_scalings: 8589.935547, pp_loss: 7.537879
[INFO] 2021-07-12 19:01:00,060 [run_pretraining.py:  512]:	********exe.run_1451******* 
[INFO] 2021-07-12 19:01:00,954 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:00,955 [run_pretraining.py:  534]:	loss/total_loss, 7.513578414916992, 1452
[INFO] 2021-07-12 19:01:00,955 [run_pretraining.py:  535]:	loss/mlm_loss, 7.513578414916992, 1452
[INFO] 2021-07-12 19:01:00,955 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4509999346046243e-05, 1452
[INFO] 2021-07-12 19:01:00,955 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1452
[INFO] 2021-07-12 19:01:00,955 [run_pretraining.py:  558]:	worker_index: 6, step: 1452, cost: 7.513578, mlm loss: 7.513578, speed: 1.118051 steps/s, speed: 8.944411 samples/s, speed: 4579.538685 tokens/s, learning rate: 1.451e-05, loss_scalings: 8589.935547, pp_loss: 7.258331
[INFO] 2021-07-12 19:01:00,955 [run_pretraining.py:  512]:	********exe.run_1452******* 
[INFO] 2021-07-12 19:01:01,860 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:01,860 [run_pretraining.py:  534]:	loss/total_loss, 7.495291233062744, 1453
[INFO] 2021-07-12 19:01:01,861 [run_pretraining.py:  535]:	loss/mlm_loss, 7.495291233062744, 1453
[INFO] 2021-07-12 19:01:01,861 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4519999240292236e-05, 1453
[INFO] 2021-07-12 19:01:01,861 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1453
[INFO] 2021-07-12 19:01:01,861 [run_pretraining.py:  558]:	worker_index: 6, step: 1453, cost: 7.495291, mlm loss: 7.495291, speed: 1.104748 steps/s, speed: 8.837986 samples/s, speed: 4525.049072 tokens/s, learning rate: 1.452e-05, loss_scalings: 8589.935547, pp_loss: 7.547090
[INFO] 2021-07-12 19:01:01,861 [run_pretraining.py:  512]:	********exe.run_1453******* 
[INFO] 2021-07-12 19:01:02,764 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:02,765 [run_pretraining.py:  534]:	loss/total_loss, 7.525317668914795, 1454
[INFO] 2021-07-12 19:01:02,765 [run_pretraining.py:  535]:	loss/mlm_loss, 7.525317668914795, 1454
[INFO] 2021-07-12 19:01:02,765 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4530000044032931e-05, 1454
[INFO] 2021-07-12 19:01:02,765 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1454
[INFO] 2021-07-12 19:01:02,765 [run_pretraining.py:  558]:	worker_index: 6, step: 1454, cost: 7.525318, mlm loss: 7.525318, speed: 1.106409 steps/s, speed: 8.851275 samples/s, speed: 4531.852913 tokens/s, learning rate: 1.453e-05, loss_scalings: 8589.935547, pp_loss: 7.606375
[INFO] 2021-07-12 19:01:02,765 [run_pretraining.py:  512]:	********exe.run_1454******* 
[INFO] 2021-07-12 19:01:03,663 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:03,663 [run_pretraining.py:  534]:	loss/total_loss, 7.7412590980529785, 1455
[INFO] 2021-07-12 19:01:03,663 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7412590980529785, 1455
[INFO] 2021-07-12 19:01:03,663 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4539999938278925e-05, 1455
[INFO] 2021-07-12 19:01:03,663 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1455
[INFO] 2021-07-12 19:01:03,664 [run_pretraining.py:  558]:	worker_index: 6, step: 1455, cost: 7.741259, mlm loss: 7.741259, speed: 1.114286 steps/s, speed: 8.914286 samples/s, speed: 4564.114255 tokens/s, learning rate: 1.454e-05, loss_scalings: 8589.935547, pp_loss: 7.705691
[INFO] 2021-07-12 19:01:03,664 [run_pretraining.py:  512]:	********exe.run_1455******* 
[INFO] 2021-07-12 19:01:04,560 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:04,561 [run_pretraining.py:  534]:	loss/total_loss, 7.595757961273193, 1456
[INFO] 2021-07-12 19:01:04,561 [run_pretraining.py:  535]:	loss/mlm_loss, 7.595757961273193, 1456
[INFO] 2021-07-12 19:01:04,561 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4549999832524918e-05, 1456
[INFO] 2021-07-12 19:01:04,561 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1456
[INFO] 2021-07-12 19:01:04,561 [run_pretraining.py:  558]:	worker_index: 6, step: 1456, cost: 7.595758, mlm loss: 7.595758, speed: 1.115030 steps/s, speed: 8.920239 samples/s, speed: 4567.162169 tokens/s, learning rate: 1.455e-05, loss_scalings: 8589.935547, pp_loss: 7.563212
[INFO] 2021-07-12 19:01:04,561 [run_pretraining.py:  512]:	********exe.run_1456******* 
[INFO] 2021-07-12 19:01:05,464 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:05,464 [run_pretraining.py:  534]:	loss/total_loss, 7.619484901428223, 1457
[INFO] 2021-07-12 19:01:05,464 [run_pretraining.py:  535]:	loss/mlm_loss, 7.619484901428223, 1457
[INFO] 2021-07-12 19:01:05,465 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4560000636265613e-05, 1457
[INFO] 2021-07-12 19:01:05,465 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1457
[INFO] 2021-07-12 19:01:05,465 [run_pretraining.py:  558]:	worker_index: 6, step: 1457, cost: 7.619485, mlm loss: 7.619485, speed: 1.107490 steps/s, speed: 8.859923 samples/s, speed: 4536.280402 tokens/s, learning rate: 1.456e-05, loss_scalings: 8589.935547, pp_loss: 7.516839
[INFO] 2021-07-12 19:01:05,465 [run_pretraining.py:  512]:	********exe.run_1457******* 
[INFO] 2021-07-12 19:01:31,536 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:31,536 [run_pretraining.py:  534]:	loss/total_loss, 7.577120304107666, 1458
[INFO] 2021-07-12 19:01:31,536 [run_pretraining.py:  535]:	loss/mlm_loss, 7.577120304107666, 1458
[INFO] 2021-07-12 19:01:31,537 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4569998711522203e-05, 1458
[INFO] 2021-07-12 19:01:31,537 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1458
[INFO] 2021-07-12 19:01:31,537 [run_pretraining.py:  558]:	worker_index: 6, step: 1458, cost: 7.577120, mlm loss: 7.577120, speed: 0.038356 steps/s, speed: 0.306851 samples/s, speed: 157.107868 tokens/s, learning rate: 1.457e-05, loss_scalings: 8589.935547, pp_loss: 7.347676
[INFO] 2021-07-12 19:01:31,537 [run_pretraining.py:  512]:	********exe.run_1458******* 
[INFO] 2021-07-12 19:01:32,460 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:32,460 [run_pretraining.py:  534]:	loss/total_loss, 7.811920166015625, 1459
[INFO] 2021-07-12 19:01:32,460 [run_pretraining.py:  535]:	loss/mlm_loss, 7.811920166015625, 1459
[INFO] 2021-07-12 19:01:32,460 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4579999515262898e-05, 1459
[INFO] 2021-07-12 19:01:32,460 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1459
[INFO] 2021-07-12 19:01:32,460 [run_pretraining.py:  558]:	worker_index: 6, step: 1459, cost: 7.811920, mlm loss: 7.811920, speed: 1.083373 steps/s, speed: 8.666983 samples/s, speed: 4437.495204 tokens/s, learning rate: 1.458e-05, loss_scalings: 8589.935547, pp_loss: 7.304988
[INFO] 2021-07-12 19:01:32,461 [run_pretraining.py:  512]:	********exe.run_1459******* 
[INFO] 2021-07-12 19:01:33,384 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:33,384 [run_pretraining.py:  534]:	loss/total_loss, 7.098273754119873, 1460
[INFO] 2021-07-12 19:01:33,384 [run_pretraining.py:  535]:	loss/mlm_loss, 7.098273754119873, 1460
[INFO] 2021-07-12 19:01:33,384 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4589999409508891e-05, 1460
[INFO] 2021-07-12 19:01:33,385 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1460
[INFO] 2021-07-12 19:01:33,385 [run_pretraining.py:  558]:	worker_index: 6, step: 1460, cost: 7.098274, mlm loss: 7.098274, speed: 1.082907 steps/s, speed: 8.663259 samples/s, speed: 4435.588767 tokens/s, learning rate: 1.459e-05, loss_scalings: 8589.935547, pp_loss: 7.366770
[INFO] 2021-07-12 19:01:33,385 [run_pretraining.py:  512]:	********exe.run_1460******* 
[INFO] 2021-07-12 19:01:34,291 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:34,292 [run_pretraining.py:  534]:	loss/total_loss, 7.617417812347412, 1461
[INFO] 2021-07-12 19:01:34,292 [run_pretraining.py:  535]:	loss/mlm_loss, 7.617417812347412, 1461
[INFO] 2021-07-12 19:01:34,292 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4599999303754885e-05, 1461
[INFO] 2021-07-12 19:01:34,292 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1461
[INFO] 2021-07-12 19:01:34,292 [run_pretraining.py:  558]:	worker_index: 6, step: 1461, cost: 7.617418, mlm loss: 7.617418, speed: 1.102763 steps/s, speed: 8.822102 samples/s, speed: 4516.916133 tokens/s, learning rate: 1.460e-05, loss_scalings: 8589.935547, pp_loss: 7.245204
[INFO] 2021-07-12 19:01:34,292 [run_pretraining.py:  512]:	********exe.run_1461******* 
[INFO] 2021-07-12 19:01:35,198 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:35,198 [run_pretraining.py:  534]:	loss/total_loss, 7.691738605499268, 1462
[INFO] 2021-07-12 19:01:35,198 [run_pretraining.py:  535]:	loss/mlm_loss, 7.691738605499268, 1462
[INFO] 2021-07-12 19:01:35,198 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4609999198000878e-05, 1462
[INFO] 2021-07-12 19:01:35,199 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1462
[INFO] 2021-07-12 19:01:35,199 [run_pretraining.py:  558]:	worker_index: 6, step: 1462, cost: 7.691739, mlm loss: 7.691739, speed: 1.104094 steps/s, speed: 8.832750 samples/s, speed: 4522.367776 tokens/s, learning rate: 1.461e-05, loss_scalings: 8589.935547, pp_loss: 7.346785
[INFO] 2021-07-12 19:01:35,199 [run_pretraining.py:  512]:	********exe.run_1462******* 
[INFO] 2021-07-12 19:01:36,121 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:36,122 [run_pretraining.py:  534]:	loss/total_loss, 7.400275230407715, 1463
[INFO] 2021-07-12 19:01:36,122 [run_pretraining.py:  535]:	loss/mlm_loss, 7.400275230407715, 1463
[INFO] 2021-07-12 19:01:36,122 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4620000001741573e-05, 1463
[INFO] 2021-07-12 19:01:36,122 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1463
[INFO] 2021-07-12 19:01:36,122 [run_pretraining.py:  558]:	worker_index: 6, step: 1463, cost: 7.400275, mlm loss: 7.400275, speed: 1.083893 steps/s, speed: 8.671146 samples/s, speed: 4439.626992 tokens/s, learning rate: 1.462e-05, loss_scalings: 8589.935547, pp_loss: 7.428711
[INFO] 2021-07-12 19:01:36,122 [run_pretraining.py:  512]:	********exe.run_1463******* 
[INFO] 2021-07-12 19:01:37,042 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:37,043 [run_pretraining.py:  534]:	loss/total_loss, 7.064375877380371, 1464
[INFO] 2021-07-12 19:01:37,043 [run_pretraining.py:  535]:	loss/mlm_loss, 7.064375877380371, 1464
[INFO] 2021-07-12 19:01:37,043 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4629999895987567e-05, 1464
[INFO] 2021-07-12 19:01:37,043 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1464
[INFO] 2021-07-12 19:01:37,044 [run_pretraining.py:  558]:	worker_index: 6, step: 1464, cost: 7.064376, mlm loss: 7.064376, speed: 1.085894 steps/s, speed: 8.687153 samples/s, speed: 4447.822268 tokens/s, learning rate: 1.463e-05, loss_scalings: 8589.935547, pp_loss: 6.988946
[INFO] 2021-07-12 19:01:37,044 [run_pretraining.py:  512]:	********exe.run_1464******* 
[INFO] 2021-07-12 19:01:37,955 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:37,956 [run_pretraining.py:  534]:	loss/total_loss, 7.720756530761719, 1465
[INFO] 2021-07-12 19:01:37,956 [run_pretraining.py:  535]:	loss/mlm_loss, 7.720756530761719, 1465
[INFO] 2021-07-12 19:01:37,956 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.463999979023356e-05, 1465
[INFO] 2021-07-12 19:01:37,956 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1465
[INFO] 2021-07-12 19:01:37,956 [run_pretraining.py:  558]:	worker_index: 6, step: 1465, cost: 7.720757, mlm loss: 7.720757, speed: 1.096471 steps/s, speed: 8.771770 samples/s, speed: 4491.146175 tokens/s, learning rate: 1.464e-05, loss_scalings: 8589.935547, pp_loss: 7.047361
[INFO] 2021-07-12 19:01:37,956 [run_pretraining.py:  512]:	********exe.run_1465******* 
[INFO] 2021-07-12 19:01:38,889 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:38,890 [run_pretraining.py:  534]:	loss/total_loss, 7.846457004547119, 1466
[INFO] 2021-07-12 19:01:38,890 [run_pretraining.py:  535]:	loss/mlm_loss, 7.846457004547119, 1466
[INFO] 2021-07-12 19:01:38,890 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4650000593974255e-05, 1466
[INFO] 2021-07-12 19:01:38,890 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1466
[INFO] 2021-07-12 19:01:38,890 [run_pretraining.py:  558]:	worker_index: 6, step: 1466, cost: 7.846457, mlm loss: 7.846457, speed: 1.071591 steps/s, speed: 8.572727 samples/s, speed: 4389.236015 tokens/s, learning rate: 1.465e-05, loss_scalings: 8589.935547, pp_loss: 7.277773
[INFO] 2021-07-12 19:01:38,890 [run_pretraining.py:  512]:	********exe.run_1466******* 
[INFO] 2021-07-12 19:01:39,807 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:39,808 [run_pretraining.py:  534]:	loss/total_loss, 7.527895927429199, 1467
[INFO] 2021-07-12 19:01:39,808 [run_pretraining.py:  535]:	loss/mlm_loss, 7.527895927429199, 1467
[INFO] 2021-07-12 19:01:39,808 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4659998669230845e-05, 1467
[INFO] 2021-07-12 19:01:39,808 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1467
[INFO] 2021-07-12 19:01:39,808 [run_pretraining.py:  558]:	worker_index: 6, step: 1467, cost: 7.527896, mlm loss: 7.527896, speed: 1.090040 steps/s, speed: 8.720320 samples/s, speed: 4464.803974 tokens/s, learning rate: 1.466e-05, loss_scalings: 8589.935547, pp_loss: 7.287990
[INFO] 2021-07-12 19:01:39,808 [run_pretraining.py:  512]:	********exe.run_1467******* 
[INFO] 2021-07-12 19:01:40,734 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:40,734 [run_pretraining.py:  534]:	loss/total_loss, 7.728850364685059, 1468
[INFO] 2021-07-12 19:01:40,734 [run_pretraining.py:  535]:	loss/mlm_loss, 7.728850364685059, 1468
[INFO] 2021-07-12 19:01:40,734 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.466999947297154e-05, 1468
[INFO] 2021-07-12 19:01:40,735 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1468
[INFO] 2021-07-12 19:01:40,735 [run_pretraining.py:  558]:	worker_index: 6, step: 1468, cost: 7.728850, mlm loss: 7.728850, speed: 1.080325 steps/s, speed: 8.642599 samples/s, speed: 4425.010614 tokens/s, learning rate: 1.467e-05, loss_scalings: 8589.935547, pp_loss: 7.583144
[INFO] 2021-07-12 19:01:40,735 [run_pretraining.py:  512]:	********exe.run_1468******* 
[INFO] 2021-07-12 19:01:41,661 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:41,661 [run_pretraining.py:  534]:	loss/total_loss, 7.563562393188477, 1469
[INFO] 2021-07-12 19:01:41,661 [run_pretraining.py:  535]:	loss/mlm_loss, 7.563562393188477, 1469
[INFO] 2021-07-12 19:01:41,661 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4679999367217533e-05, 1469
[INFO] 2021-07-12 19:01:41,662 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1469
[INFO] 2021-07-12 19:01:41,662 [run_pretraining.py:  558]:	worker_index: 6, step: 1469, cost: 7.563562, mlm loss: 7.563562, speed: 1.079519 steps/s, speed: 8.636153 samples/s, speed: 4421.710089 tokens/s, learning rate: 1.468e-05, loss_scalings: 8589.935547, pp_loss: 6.960482
[INFO] 2021-07-12 19:01:41,662 [run_pretraining.py:  512]:	********exe.run_1469******* 
[INFO] 2021-07-12 19:01:42,590 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:42,591 [run_pretraining.py:  534]:	loss/total_loss, 8.00582218170166, 1470
[INFO] 2021-07-12 19:01:42,591 [run_pretraining.py:  535]:	loss/mlm_loss, 8.00582218170166, 1470
[INFO] 2021-07-12 19:01:42,591 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4689999261463527e-05, 1470
[INFO] 2021-07-12 19:01:42,591 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1470
[INFO] 2021-07-12 19:01:42,591 [run_pretraining.py:  558]:	worker_index: 6, step: 1470, cost: 8.005822, mlm loss: 8.005822, speed: 1.076636 steps/s, speed: 8.613084 samples/s, speed: 4409.899191 tokens/s, learning rate: 1.469e-05, loss_scalings: 8589.935547, pp_loss: 7.376982
[INFO] 2021-07-12 19:01:42,591 [run_pretraining.py:  512]:	********exe.run_1470******* 
[INFO] 2021-07-12 19:01:43,508 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:43,508 [run_pretraining.py:  534]:	loss/total_loss, 7.712810516357422, 1471
[INFO] 2021-07-12 19:01:43,509 [run_pretraining.py:  535]:	loss/mlm_loss, 7.712810516357422, 1471
[INFO] 2021-07-12 19:01:43,509 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4700000065204222e-05, 1471
[INFO] 2021-07-12 19:01:43,509 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1471
[INFO] 2021-07-12 19:01:43,509 [run_pretraining.py:  558]:	worker_index: 6, step: 1471, cost: 7.712811, mlm loss: 7.712811, speed: 1.090507 steps/s, speed: 8.724057 samples/s, speed: 4466.717033 tokens/s, learning rate: 1.470e-05, loss_scalings: 8589.935547, pp_loss: 7.722007
[INFO] 2021-07-12 19:01:43,509 [run_pretraining.py:  512]:	********exe.run_1471******* 
[INFO] 2021-07-12 19:01:44,432 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:44,433 [run_pretraining.py:  534]:	loss/total_loss, 5.529623985290527, 1472
[INFO] 2021-07-12 19:01:44,433 [run_pretraining.py:  535]:	loss/mlm_loss, 5.529623985290527, 1472
[INFO] 2021-07-12 19:01:44,433 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4709999959450215e-05, 1472
[INFO] 2021-07-12 19:01:44,433 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1472
[INFO] 2021-07-12 19:01:44,433 [run_pretraining.py:  558]:	worker_index: 6, step: 1472, cost: 5.529624, mlm loss: 5.529624, speed: 1.082905 steps/s, speed: 8.663239 samples/s, speed: 4435.578460 tokens/s, learning rate: 1.471e-05, loss_scalings: 8589.935547, pp_loss: 6.644460
[INFO] 2021-07-12 19:01:44,433 [run_pretraining.py:  512]:	********exe.run_1472******* 
[INFO] 2021-07-12 19:01:45,362 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:45,363 [run_pretraining.py:  534]:	loss/total_loss, 8.335800170898438, 1473
[INFO] 2021-07-12 19:01:45,363 [run_pretraining.py:  535]:	loss/mlm_loss, 8.335800170898438, 1473
[INFO] 2021-07-12 19:01:45,363 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4719999853696208e-05, 1473
[INFO] 2021-07-12 19:01:45,363 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1473
[INFO] 2021-07-12 19:01:45,363 [run_pretraining.py:  558]:	worker_index: 6, step: 1473, cost: 8.335800, mlm loss: 8.335800, speed: 1.075583 steps/s, speed: 8.604662 samples/s, speed: 4405.587185 tokens/s, learning rate: 1.472e-05, loss_scalings: 8589.935547, pp_loss: 7.861598
[INFO] 2021-07-12 19:01:45,364 [run_pretraining.py:  512]:	********exe.run_1473******* 
[INFO] 2021-07-12 19:01:46,281 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:46,281 [run_pretraining.py:  534]:	loss/total_loss, 6.879620552062988, 1474
[INFO] 2021-07-12 19:01:46,281 [run_pretraining.py:  535]:	loss/mlm_loss, 6.879620552062988, 1474
[INFO] 2021-07-12 19:01:46,281 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4729999747942202e-05, 1474
[INFO] 2021-07-12 19:01:46,282 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1474
[INFO] 2021-07-12 19:01:46,282 [run_pretraining.py:  558]:	worker_index: 6, step: 1474, cost: 6.879621, mlm loss: 6.879621, speed: 1.089934 steps/s, speed: 8.719468 samples/s, speed: 4464.367729 tokens/s, learning rate: 1.473e-05, loss_scalings: 8589.935547, pp_loss: 7.430442
[INFO] 2021-07-12 19:01:46,282 [run_pretraining.py:  512]:	********exe.run_1474******* 
[INFO] 2021-07-12 19:01:47,214 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:47,215 [run_pretraining.py:  534]:	loss/total_loss, 7.162654876708984, 1475
[INFO] 2021-07-12 19:01:47,215 [run_pretraining.py:  535]:	loss/mlm_loss, 7.162654876708984, 1475
[INFO] 2021-07-12 19:01:47,215 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4740000551682897e-05, 1475
[INFO] 2021-07-12 19:01:47,215 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1475
[INFO] 2021-07-12 19:01:47,215 [run_pretraining.py:  558]:	worker_index: 6, step: 1475, cost: 7.162655, mlm loss: 7.162655, speed: 1.071830 steps/s, speed: 8.574641 samples/s, speed: 4390.216332 tokens/s, learning rate: 1.474e-05, loss_scalings: 8589.935547, pp_loss: 7.458226
[INFO] 2021-07-12 19:01:47,215 [run_pretraining.py:  512]:	********exe.run_1475******* 
[INFO] 2021-07-12 19:01:48,132 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:48,132 [run_pretraining.py:  534]:	loss/total_loss, 7.253342628479004, 1476
[INFO] 2021-07-12 19:01:48,132 [run_pretraining.py:  535]:	loss/mlm_loss, 7.253342628479004, 1476
[INFO] 2021-07-12 19:01:48,132 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4749998626939487e-05, 1476
[INFO] 2021-07-12 19:01:48,133 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1476
[INFO] 2021-07-12 19:01:48,133 [run_pretraining.py:  558]:	worker_index: 6, step: 1476, cost: 7.253343, mlm loss: 7.253343, speed: 1.091101 steps/s, speed: 8.728811 samples/s, speed: 4469.151353 tokens/s, learning rate: 1.475e-05, loss_scalings: 8589.935547, pp_loss: 6.936902
[INFO] 2021-07-12 19:01:48,133 [run_pretraining.py:  512]:	********exe.run_1476******* 
[INFO] 2021-07-12 19:01:49,061 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:49,062 [run_pretraining.py:  534]:	loss/total_loss, 7.164167404174805, 1477
[INFO] 2021-07-12 19:01:49,062 [run_pretraining.py:  535]:	loss/mlm_loss, 7.164167404174805, 1477
[INFO] 2021-07-12 19:01:49,062 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4759999430680182e-05, 1477
[INFO] 2021-07-12 19:01:49,062 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1477
[INFO] 2021-07-12 19:01:49,062 [run_pretraining.py:  558]:	worker_index: 6, step: 1477, cost: 7.164167, mlm loss: 7.164167, speed: 1.076581 steps/s, speed: 8.612651 samples/s, speed: 4409.677335 tokens/s, learning rate: 1.476e-05, loss_scalings: 8589.935547, pp_loss: 7.211270
[INFO] 2021-07-12 19:01:49,062 [run_pretraining.py:  512]:	********exe.run_1477******* 
[INFO] 2021-07-12 19:01:49,979 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:49,980 [run_pretraining.py:  534]:	loss/total_loss, 7.793936729431152, 1478
[INFO] 2021-07-12 19:01:49,980 [run_pretraining.py:  535]:	loss/mlm_loss, 7.793936729431152, 1478
[INFO] 2021-07-12 19:01:49,980 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4769999324926175e-05, 1478
[INFO] 2021-07-12 19:01:49,980 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1478
[INFO] 2021-07-12 19:01:49,980 [run_pretraining.py:  558]:	worker_index: 6, step: 1478, cost: 7.793937, mlm loss: 7.793937, speed: 1.090457 steps/s, speed: 8.723655 samples/s, speed: 4466.511486 tokens/s, learning rate: 1.477e-05, loss_scalings: 6871.948730, pp_loss: 7.564358
[INFO] 2021-07-12 19:01:49,980 [run_pretraining.py:  512]:	********exe.run_1478******* 
[INFO] 2021-07-12 19:01:50,906 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:50,907 [run_pretraining.py:  534]:	loss/total_loss, 7.657316207885742, 1479
[INFO] 2021-07-12 19:01:50,907 [run_pretraining.py:  535]:	loss/mlm_loss, 7.657316207885742, 1479
[INFO] 2021-07-12 19:01:50,907 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4779999219172169e-05, 1479
[INFO] 2021-07-12 19:01:50,907 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1479
[INFO] 2021-07-12 19:01:50,907 [run_pretraining.py:  558]:	worker_index: 6, step: 1479, cost: 7.657316, mlm loss: 7.657316, speed: 1.079120 steps/s, speed: 8.632962 samples/s, speed: 4420.076455 tokens/s, learning rate: 1.478e-05, loss_scalings: 6871.948730, pp_loss: 7.415331
[INFO] 2021-07-12 19:01:50,907 [run_pretraining.py:  512]:	********exe.run_1479******* 
[INFO] 2021-07-12 19:01:51,834 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:51,835 [run_pretraining.py:  534]:	loss/total_loss, 6.685914516448975, 1480
[INFO] 2021-07-12 19:01:51,835 [run_pretraining.py:  535]:	loss/mlm_loss, 6.685914516448975, 1480
[INFO] 2021-07-12 19:01:51,835 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4790000022912864e-05, 1480
[INFO] 2021-07-12 19:01:51,835 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1480
[INFO] 2021-07-12 19:01:51,835 [run_pretraining.py:  558]:	worker_index: 6, step: 1480, cost: 6.685915, mlm loss: 6.685915, speed: 1.078885 steps/s, speed: 8.631079 samples/s, speed: 4419.112313 tokens/s, learning rate: 1.479e-05, loss_scalings: 6871.948730, pp_loss: 6.582280
[INFO] 2021-07-12 19:01:51,835 [run_pretraining.py:  512]:	********exe.run_1480******* 
[INFO] 2021-07-12 19:01:52,760 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:52,761 [run_pretraining.py:  534]:	loss/total_loss, 7.160244464874268, 1481
[INFO] 2021-07-12 19:01:52,761 [run_pretraining.py:  535]:	loss/mlm_loss, 7.160244464874268, 1481
[INFO] 2021-07-12 19:01:52,761 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4799999917158857e-05, 1481
[INFO] 2021-07-12 19:01:52,761 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1481
[INFO] 2021-07-12 19:01:52,761 [run_pretraining.py:  558]:	worker_index: 6, step: 1481, cost: 7.160244, mlm loss: 7.160244, speed: 1.080714 steps/s, speed: 8.645714 samples/s, speed: 4426.605696 tokens/s, learning rate: 1.480e-05, loss_scalings: 6871.948730, pp_loss: 7.193059
[INFO] 2021-07-12 19:01:52,761 [run_pretraining.py:  512]:	********exe.run_1481******* 
[INFO] 2021-07-12 19:01:53,693 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:53,693 [run_pretraining.py:  534]:	loss/total_loss, 7.186501502990723, 1482
[INFO] 2021-07-12 19:01:53,693 [run_pretraining.py:  535]:	loss/mlm_loss, 7.186501502990723, 1482
[INFO] 2021-07-12 19:01:53,693 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.480999981140485e-05, 1482
[INFO] 2021-07-12 19:01:53,694 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1482
[INFO] 2021-07-12 19:01:53,694 [run_pretraining.py:  558]:	worker_index: 6, step: 1482, cost: 7.186502, mlm loss: 7.186502, speed: 1.072978 steps/s, speed: 8.583821 samples/s, speed: 4394.916487 tokens/s, learning rate: 1.481e-05, loss_scalings: 6871.948730, pp_loss: 7.467671
[INFO] 2021-07-12 19:01:53,694 [run_pretraining.py:  512]:	********exe.run_1482******* 
[INFO] 2021-07-12 19:01:54,624 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:54,625 [run_pretraining.py:  534]:	loss/total_loss, 7.970063209533691, 1483
[INFO] 2021-07-12 19:01:54,625 [run_pretraining.py:  535]:	loss/mlm_loss, 7.970063209533691, 1483
[INFO] 2021-07-12 19:01:54,625 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4819999705650844e-05, 1483
[INFO] 2021-07-12 19:01:54,625 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1483
[INFO] 2021-07-12 19:01:54,625 [run_pretraining.py:  558]:	worker_index: 6, step: 1483, cost: 7.970063, mlm loss: 7.970063, speed: 1.074527 steps/s, speed: 8.596215 samples/s, speed: 4401.262179 tokens/s, learning rate: 1.482e-05, loss_scalings: 6871.948730, pp_loss: 7.506100
[INFO] 2021-07-12 19:01:54,625 [run_pretraining.py:  512]:	********exe.run_1483******* 
[INFO] 2021-07-12 19:01:55,544 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:55,545 [run_pretraining.py:  534]:	loss/total_loss, 7.779756546020508, 1484
[INFO] 2021-07-12 19:01:55,545 [run_pretraining.py:  535]:	loss/mlm_loss, 7.779756546020508, 1484
[INFO] 2021-07-12 19:01:55,545 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4830000509391539e-05, 1484
[INFO] 2021-07-12 19:01:55,545 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1484
[INFO] 2021-07-12 19:01:55,545 [run_pretraining.py:  558]:	worker_index: 6, step: 1484, cost: 7.779757, mlm loss: 7.779757, speed: 1.087389 steps/s, speed: 8.699112 samples/s, speed: 4453.945306 tokens/s, learning rate: 1.483e-05, loss_scalings: 6871.948730, pp_loss: 7.421298
[INFO] 2021-07-12 19:01:55,545 [run_pretraining.py:  512]:	********exe.run_1484******* 
[INFO] 2021-07-12 19:01:56,473 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:56,474 [run_pretraining.py:  534]:	loss/total_loss, 7.179468154907227, 1485
[INFO] 2021-07-12 19:01:56,474 [run_pretraining.py:  535]:	loss/mlm_loss, 7.179468154907227, 1485
[INFO] 2021-07-12 19:01:56,474 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4839998584648129e-05, 1485
[INFO] 2021-07-12 19:01:56,474 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1485
[INFO] 2021-07-12 19:01:56,474 [run_pretraining.py:  558]:	worker_index: 6, step: 1485, cost: 7.179468, mlm loss: 7.179468, speed: 1.077728 steps/s, speed: 8.621822 samples/s, speed: 4414.372769 tokens/s, learning rate: 1.484e-05, loss_scalings: 6871.948730, pp_loss: 6.998347
[INFO] 2021-07-12 19:01:56,474 [run_pretraining.py:  512]:	********exe.run_1485******* 
[INFO] 2021-07-12 19:01:57,401 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:57,402 [run_pretraining.py:  534]:	loss/total_loss, 7.589382171630859, 1486
[INFO] 2021-07-12 19:01:57,402 [run_pretraining.py:  535]:	loss/mlm_loss, 7.589382171630859, 1486
[INFO] 2021-07-12 19:01:57,402 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4849999388388824e-05, 1486
[INFO] 2021-07-12 19:01:57,402 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1486
[INFO] 2021-07-12 19:01:57,402 [run_pretraining.py:  558]:	worker_index: 6, step: 1486, cost: 7.589382, mlm loss: 7.589382, speed: 1.077817 steps/s, speed: 8.622540 samples/s, speed: 4414.740304 tokens/s, learning rate: 1.485e-05, loss_scalings: 6871.948730, pp_loss: 7.122315
[INFO] 2021-07-12 19:01:57,403 [run_pretraining.py:  512]:	********exe.run_1486******* 
[INFO] 2021-07-12 19:01:58,323 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:58,324 [run_pretraining.py:  534]:	loss/total_loss, 7.602884292602539, 1487
[INFO] 2021-07-12 19:01:58,324 [run_pretraining.py:  535]:	loss/mlm_loss, 7.602884292602539, 1487
[INFO] 2021-07-12 19:01:58,324 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4859999282634817e-05, 1487
[INFO] 2021-07-12 19:01:58,324 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1487
[INFO] 2021-07-12 19:01:58,325 [run_pretraining.py:  558]:	worker_index: 6, step: 1487, cost: 7.602884, mlm loss: 7.602884, speed: 1.085342 steps/s, speed: 8.682733 samples/s, speed: 4445.559513 tokens/s, learning rate: 1.486e-05, loss_scalings: 6871.948730, pp_loss: 7.591002
[INFO] 2021-07-12 19:01:58,325 [run_pretraining.py:  512]:	********exe.run_1487******* 
[INFO] 2021-07-12 19:01:59,256 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:59,257 [run_pretraining.py:  534]:	loss/total_loss, 7.940765380859375, 1488
[INFO] 2021-07-12 19:01:59,257 [run_pretraining.py:  535]:	loss/mlm_loss, 7.940765380859375, 1488
[INFO] 2021-07-12 19:01:59,257 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.486999917688081e-05, 1488
[INFO] 2021-07-12 19:01:59,257 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1488
[INFO] 2021-07-12 19:01:59,257 [run_pretraining.py:  558]:	worker_index: 6, step: 1488, cost: 7.940765, mlm loss: 7.940765, speed: 1.073231 steps/s, speed: 8.585844 samples/s, speed: 4395.952209 tokens/s, learning rate: 1.487e-05, loss_scalings: 6871.948730, pp_loss: 7.659320
[INFO] 2021-07-12 19:01:59,257 [run_pretraining.py:  512]:	********exe.run_1488******* 
[INFO] 2021-07-12 19:02:00,192 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:00,192 [run_pretraining.py:  534]:	loss/total_loss, 7.391242027282715, 1489
[INFO] 2021-07-12 19:02:00,192 [run_pretraining.py:  535]:	loss/mlm_loss, 7.391242027282715, 1489
[INFO] 2021-07-12 19:02:00,193 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4879999980621506e-05, 1489
[INFO] 2021-07-12 19:02:00,193 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1489
[INFO] 2021-07-12 19:02:00,193 [run_pretraining.py:  558]:	worker_index: 6, step: 1489, cost: 7.391242, mlm loss: 7.391242, speed: 1.069560 steps/s, speed: 8.556482 samples/s, speed: 4380.918731 tokens/s, learning rate: 1.488e-05, loss_scalings: 6871.948730, pp_loss: 7.284944
[INFO] 2021-07-12 19:02:00,193 [run_pretraining.py:  512]:	********exe.run_1489******* 
[INFO] 2021-07-12 19:02:01,129 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:01,129 [run_pretraining.py:  534]:	loss/total_loss, 7.217870235443115, 1490
[INFO] 2021-07-12 19:02:01,130 [run_pretraining.py:  535]:	loss/mlm_loss, 7.217870235443115, 1490
[INFO] 2021-07-12 19:02:01,130 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4889999874867499e-05, 1490
[INFO] 2021-07-12 19:02:01,130 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1490
[INFO] 2021-07-12 19:02:01,130 [run_pretraining.py:  558]:	worker_index: 6, step: 1490, cost: 7.217870, mlm loss: 7.217870, speed: 1.067844 steps/s, speed: 8.542751 samples/s, speed: 4373.888649 tokens/s, learning rate: 1.489e-05, loss_scalings: 6871.948730, pp_loss: 7.294008
[INFO] 2021-07-12 19:02:01,130 [run_pretraining.py:  512]:	********exe.run_1490******* 
[INFO] 2021-07-12 19:02:02,038 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:02,039 [run_pretraining.py:  534]:	loss/total_loss, 7.527814865112305, 1491
[INFO] 2021-07-12 19:02:02,039 [run_pretraining.py:  535]:	loss/mlm_loss, 7.527814865112305, 1491
[INFO] 2021-07-12 19:02:02,039 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4899999769113492e-05, 1491
[INFO] 2021-07-12 19:02:02,039 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1491
[INFO] 2021-07-12 19:02:02,039 [run_pretraining.py:  558]:	worker_index: 6, step: 1491, cost: 7.527815, mlm loss: 7.527815, speed: 1.100400 steps/s, speed: 8.803199 samples/s, speed: 4507.237919 tokens/s, learning rate: 1.490e-05, loss_scalings: 6871.948730, pp_loss: 7.430052
[INFO] 2021-07-12 19:02:02,039 [run_pretraining.py:  512]:	********exe.run_1491******* 
[INFO] 2021-07-12 19:02:02,953 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:02,953 [run_pretraining.py:  534]:	loss/total_loss, 6.972993850708008, 1492
[INFO] 2021-07-12 19:02:02,954 [run_pretraining.py:  535]:	loss/mlm_loss, 6.972993850708008, 1492
[INFO] 2021-07-12 19:02:02,954 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4910000572854187e-05, 1492
[INFO] 2021-07-12 19:02:02,954 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1492
[INFO] 2021-07-12 19:02:02,954 [run_pretraining.py:  558]:	worker_index: 6, step: 1492, cost: 6.972994, mlm loss: 6.972994, speed: 1.094415 steps/s, speed: 8.755320 samples/s, speed: 4482.723947 tokens/s, learning rate: 1.491e-05, loss_scalings: 6871.948730, pp_loss: 7.089471
[INFO] 2021-07-12 19:02:02,954 [run_pretraining.py:  512]:	********exe.run_1492******* 
[INFO] 2021-07-12 19:02:03,860 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:03,861 [run_pretraining.py:  534]:	loss/total_loss, 7.349869728088379, 1493
[INFO] 2021-07-12 19:02:03,861 [run_pretraining.py:  535]:	loss/mlm_loss, 7.349869728088379, 1493
[INFO] 2021-07-12 19:02:03,861 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.492000046710018e-05, 1493
[INFO] 2021-07-12 19:02:03,861 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1493
[INFO] 2021-07-12 19:02:03,861 [run_pretraining.py:  558]:	worker_index: 6, step: 1493, cost: 7.349870, mlm loss: 7.349870, speed: 1.103122 steps/s, speed: 8.824974 samples/s, speed: 4518.386841 tokens/s, learning rate: 1.492e-05, loss_scalings: 6871.948730, pp_loss: 7.295857
[INFO] 2021-07-12 19:02:03,861 [run_pretraining.py:  512]:	********exe.run_1493******* 
[INFO] 2021-07-12 19:02:04,764 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:04,764 [run_pretraining.py:  534]:	loss/total_loss, 7.985448837280273, 1494
[INFO] 2021-07-12 19:02:04,764 [run_pretraining.py:  535]:	loss/mlm_loss, 7.985448837280273, 1494
[INFO] 2021-07-12 19:02:04,764 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4929999451851472e-05, 1494
[INFO] 2021-07-12 19:02:04,764 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1494
[INFO] 2021-07-12 19:02:04,764 [run_pretraining.py:  558]:	worker_index: 6, step: 1494, cost: 7.985449, mlm loss: 7.985449, speed: 1.107733 steps/s, speed: 8.861862 samples/s, speed: 4537.273586 tokens/s, learning rate: 1.493e-05, loss_scalings: 6871.948730, pp_loss: 7.684366
[INFO] 2021-07-12 19:02:04,765 [run_pretraining.py:  512]:	********exe.run_1494******* 
[INFO] 2021-07-12 19:02:05,679 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:05,679 [run_pretraining.py:  534]:	loss/total_loss, 7.325150966644287, 1495
[INFO] 2021-07-12 19:02:05,680 [run_pretraining.py:  535]:	loss/mlm_loss, 7.325150966644287, 1495
[INFO] 2021-07-12 19:02:05,680 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4939999346097466e-05, 1495
[INFO] 2021-07-12 19:02:05,680 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1495
[INFO] 2021-07-12 19:02:05,680 [run_pretraining.py:  558]:	worker_index: 6, step: 1495, cost: 7.325151, mlm loss: 7.325151, speed: 1.093361 steps/s, speed: 8.746887 samples/s, speed: 4478.406172 tokens/s, learning rate: 1.494e-05, loss_scalings: 6871.948730, pp_loss: 7.210589
[INFO] 2021-07-12 19:02:05,680 [run_pretraining.py:  512]:	********exe.run_1495******* 
[INFO] 2021-07-12 19:02:06,582 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:06,583 [run_pretraining.py:  534]:	loss/total_loss, 8.014313697814941, 1496
[INFO] 2021-07-12 19:02:06,583 [run_pretraining.py:  535]:	loss/mlm_loss, 8.014313697814941, 1496
[INFO] 2021-07-12 19:02:06,583 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4949999240343459e-05, 1496
[INFO] 2021-07-12 19:02:06,583 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1496
[INFO] 2021-07-12 19:02:06,583 [run_pretraining.py:  558]:	worker_index: 6, step: 1496, cost: 8.014314, mlm loss: 8.014314, speed: 1.107632 steps/s, speed: 8.861055 samples/s, speed: 4536.860206 tokens/s, learning rate: 1.495e-05, loss_scalings: 6871.948730, pp_loss: 7.718397
[INFO] 2021-07-12 19:02:06,583 [run_pretraining.py:  512]:	********exe.run_1496******* 
[INFO] 2021-07-12 19:02:07,484 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:07,485 [run_pretraining.py:  534]:	loss/total_loss, 7.500033378601074, 1497
[INFO] 2021-07-12 19:02:07,485 [run_pretraining.py:  535]:	loss/mlm_loss, 7.500033378601074, 1497
[INFO] 2021-07-12 19:02:07,485 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4959999134589452e-05, 1497
[INFO] 2021-07-12 19:02:07,485 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1497
[INFO] 2021-07-12 19:02:07,485 [run_pretraining.py:  558]:	worker_index: 6, step: 1497, cost: 7.500033, mlm loss: 7.500033, speed: 1.109496 steps/s, speed: 8.875970 samples/s, speed: 4544.496510 tokens/s, learning rate: 1.496e-05, loss_scalings: 6871.948730, pp_loss: 7.432322
[INFO] 2021-07-12 19:02:07,486 [run_pretraining.py:  512]:	********exe.run_1497******* 
[INFO] 2021-07-12 19:02:08,401 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:08,401 [run_pretraining.py:  534]:	loss/total_loss, 6.978496074676514, 1498
[INFO] 2021-07-12 19:02:08,401 [run_pretraining.py:  535]:	loss/mlm_loss, 6.978496074676514, 1498
[INFO] 2021-07-12 19:02:08,401 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4969999938330147e-05, 1498
[INFO] 2021-07-12 19:02:08,402 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1498
[INFO] 2021-07-12 19:02:08,402 [run_pretraining.py:  558]:	worker_index: 6, step: 1498, cost: 6.978496, mlm loss: 6.978496, speed: 1.092281 steps/s, speed: 8.738249 samples/s, speed: 4473.983687 tokens/s, learning rate: 1.497e-05, loss_scalings: 6871.948730, pp_loss: 7.142408
[INFO] 2021-07-12 19:02:08,402 [run_pretraining.py:  512]:	********exe.run_1498******* 
[INFO] 2021-07-12 19:02:09,303 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:09,304 [run_pretraining.py:  534]:	loss/total_loss, 7.1662983894348145, 1499
[INFO] 2021-07-12 19:02:09,304 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1662983894348145, 1499
[INFO] 2021-07-12 19:02:09,304 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.497999983257614e-05, 1499
[INFO] 2021-07-12 19:02:09,304 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1499
[INFO] 2021-07-12 19:02:09,304 [run_pretraining.py:  558]:	worker_index: 6, step: 1499, cost: 7.166298, mlm loss: 7.166298, speed: 1.108523 steps/s, speed: 8.868182 samples/s, speed: 4540.508938 tokens/s, learning rate: 1.498e-05, loss_scalings: 6871.948730, pp_loss: 7.281951
[INFO] 2021-07-12 19:02:09,305 [run_pretraining.py:  512]:	********exe.run_1499******* 
[INFO] 2021-07-12 19:02:10,218 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:10,219 [run_pretraining.py:  534]:	loss/total_loss, 7.35795783996582, 1500
[INFO] 2021-07-12 19:02:10,219 [run_pretraining.py:  535]:	loss/mlm_loss, 7.35795783996582, 1500
[INFO] 2021-07-12 19:02:10,219 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4989999726822134e-05, 1500
[INFO] 2021-07-12 19:02:10,219 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1500
[INFO] 2021-07-12 19:02:10,219 [run_pretraining.py:  558]:	worker_index: 6, step: 1500, cost: 7.357958, mlm loss: 7.357958, speed: 1.094221 steps/s, speed: 8.753772 samples/s, speed: 4481.931050 tokens/s, learning rate: 1.499e-05, loss_scalings: 6871.948730, pp_loss: 7.188901
[INFO] 2021-07-12 19:02:10,219 [run_pretraining.py:  512]:	********exe.run_1500******* 
[INFO] 2021-07-12 19:02:11,127 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:11,127 [run_pretraining.py:  534]:	loss/total_loss, 7.599305152893066, 1501
[INFO] 2021-07-12 19:02:11,128 [run_pretraining.py:  535]:	loss/mlm_loss, 7.599305152893066, 1501
[INFO] 2021-07-12 19:02:11,128 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.500000053056283e-05, 1501
[INFO] 2021-07-12 19:02:11,128 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1501
[INFO] 2021-07-12 19:02:11,128 [run_pretraining.py:  558]:	worker_index: 6, step: 1501, cost: 7.599305, mlm loss: 7.599305, speed: 1.101278 steps/s, speed: 8.810221 samples/s, speed: 4510.833220 tokens/s, learning rate: 1.500e-05, loss_scalings: 6871.948730, pp_loss: 7.773269
[INFO] 2021-07-12 19:02:11,128 [run_pretraining.py:  512]:	********exe.run_1501******* 
[INFO] 2021-07-12 19:02:12,030 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:12,030 [run_pretraining.py:  534]:	loss/total_loss, 7.501577377319336, 1502
[INFO] 2021-07-12 19:02:12,030 [run_pretraining.py:  535]:	loss/mlm_loss, 7.501577377319336, 1502
[INFO] 2021-07-12 19:02:12,030 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5009998605819419e-05, 1502
[INFO] 2021-07-12 19:02:12,030 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1502
[INFO] 2021-07-12 19:02:12,030 [run_pretraining.py:  558]:	worker_index: 6, step: 1502, cost: 7.501577, mlm loss: 7.501577, speed: 1.108689 steps/s, speed: 8.869511 samples/s, speed: 4541.189453 tokens/s, learning rate: 1.501e-05, loss_scalings: 6871.948730, pp_loss: 7.744675
[INFO] 2021-07-12 19:02:12,031 [run_pretraining.py:  512]:	********exe.run_1502******* 
[INFO] 2021-07-12 19:02:12,939 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:12,939 [run_pretraining.py:  534]:	loss/total_loss, 7.906530857086182, 1503
[INFO] 2021-07-12 19:02:12,939 [run_pretraining.py:  535]:	loss/mlm_loss, 7.906530857086182, 1503
[INFO] 2021-07-12 19:02:12,939 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5019999409560114e-05, 1503
[INFO] 2021-07-12 19:02:12,939 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1503
[INFO] 2021-07-12 19:02:12,940 [run_pretraining.py:  558]:	worker_index: 6, step: 1503, cost: 7.906531, mlm loss: 7.906531, speed: 1.100878 steps/s, speed: 8.807025 samples/s, speed: 4509.196990 tokens/s, learning rate: 1.502e-05, loss_scalings: 6871.948730, pp_loss: 7.508036
[INFO] 2021-07-12 19:02:12,940 [run_pretraining.py:  512]:	********exe.run_1503******* 
[INFO] 2021-07-12 19:02:13,849 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:13,850 [run_pretraining.py:  534]:	loss/total_loss, 6.851497650146484, 1504
[INFO] 2021-07-12 19:02:13,850 [run_pretraining.py:  535]:	loss/mlm_loss, 6.851497650146484, 1504
[INFO] 2021-07-12 19:02:13,850 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5029999303806107e-05, 1504
[INFO] 2021-07-12 19:02:13,850 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1504
[INFO] 2021-07-12 19:02:13,850 [run_pretraining.py:  558]:	worker_index: 6, step: 1504, cost: 6.851498, mlm loss: 6.851498, speed: 1.098898 steps/s, speed: 8.791183 samples/s, speed: 4501.085505 tokens/s, learning rate: 1.503e-05, loss_scalings: 6871.948730, pp_loss: 7.032756
[INFO] 2021-07-12 19:02:13,850 [run_pretraining.py:  512]:	********exe.run_1504******* 
[INFO] 2021-07-12 19:02:14,754 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:14,754 [run_pretraining.py:  534]:	loss/total_loss, 7.206589698791504, 1505
[INFO] 2021-07-12 19:02:14,754 [run_pretraining.py:  535]:	loss/mlm_loss, 7.206589698791504, 1505
[INFO] 2021-07-12 19:02:14,754 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.50399991980521e-05, 1505
[INFO] 2021-07-12 19:02:14,754 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1505
[INFO] 2021-07-12 19:02:14,755 [run_pretraining.py:  558]:	worker_index: 6, step: 1505, cost: 7.206590, mlm loss: 7.206590, speed: 1.106738 steps/s, speed: 8.853903 samples/s, speed: 4533.198194 tokens/s, learning rate: 1.504e-05, loss_scalings: 6871.948730, pp_loss: 7.230440
[INFO] 2021-07-12 19:02:14,755 [run_pretraining.py:  512]:	********exe.run_1505******* 
[INFO] 2021-07-12 19:02:15,669 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:15,670 [run_pretraining.py:  534]:	loss/total_loss, 7.169358253479004, 1506
[INFO] 2021-07-12 19:02:15,670 [run_pretraining.py:  535]:	loss/mlm_loss, 7.169358253479004, 1506
[INFO] 2021-07-12 19:02:15,670 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5050000001792796e-05, 1506
[INFO] 2021-07-12 19:02:15,670 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1506
[INFO] 2021-07-12 19:02:15,670 [run_pretraining.py:  558]:	worker_index: 6, step: 1506, cost: 7.169358, mlm loss: 7.169358, speed: 1.092876 steps/s, speed: 8.743008 samples/s, speed: 4476.420104 tokens/s, learning rate: 1.505e-05, loss_scalings: 6871.948730, pp_loss: 7.453526
[INFO] 2021-07-12 19:02:15,670 [run_pretraining.py:  512]:	********exe.run_1506******* 
[INFO] 2021-07-12 19:02:16,573 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:16,574 [run_pretraining.py:  534]:	loss/total_loss, 7.384658336639404, 1507
[INFO] 2021-07-12 19:02:16,574 [run_pretraining.py:  535]:	loss/mlm_loss, 7.384658336639404, 1507
[INFO] 2021-07-12 19:02:16,574 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.505999989603879e-05, 1507
[INFO] 2021-07-12 19:02:16,574 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1507
[INFO] 2021-07-12 19:02:16,574 [run_pretraining.py:  558]:	worker_index: 6, step: 1507, cost: 7.384658, mlm loss: 7.384658, speed: 1.107116 steps/s, speed: 8.856929 samples/s, speed: 4534.747752 tokens/s, learning rate: 1.506e-05, loss_scalings: 6871.948730, pp_loss: 7.547072
[INFO] 2021-07-12 19:02:16,574 [run_pretraining.py:  512]:	********exe.run_1507******* 
[INFO] 2021-07-12 19:02:17,493 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:17,493 [run_pretraining.py:  534]:	loss/total_loss, 7.036867141723633, 1508
[INFO] 2021-07-12 19:02:17,493 [run_pretraining.py:  535]:	loss/mlm_loss, 7.036867141723633, 1508
[INFO] 2021-07-12 19:02:17,494 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5069999790284783e-05, 1508
[INFO] 2021-07-12 19:02:17,494 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1508
[INFO] 2021-07-12 19:02:17,494 [run_pretraining.py:  558]:	worker_index: 6, step: 1508, cost: 7.036867, mlm loss: 7.036867, speed: 1.088364 steps/s, speed: 8.706909 samples/s, speed: 4457.937221 tokens/s, learning rate: 1.507e-05, loss_scalings: 6871.948730, pp_loss: 7.107000
[INFO] 2021-07-12 19:02:17,494 [run_pretraining.py:  512]:	********exe.run_1508******* 
[INFO] 2021-07-12 19:02:18,424 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:18,425 [run_pretraining.py:  534]:	loss/total_loss, 7.31020450592041, 1509
[INFO] 2021-07-12 19:02:18,425 [run_pretraining.py:  535]:	loss/mlm_loss, 7.31020450592041, 1509
[INFO] 2021-07-12 19:02:18,425 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5079999684530776e-05, 1509
[INFO] 2021-07-12 19:02:18,425 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1509
[INFO] 2021-07-12 19:02:18,425 [run_pretraining.py:  558]:	worker_index: 6, step: 1509, cost: 7.310205, mlm loss: 7.310205, speed: 1.074230 steps/s, speed: 8.593837 samples/s, speed: 4400.044765 tokens/s, learning rate: 1.508e-05, loss_scalings: 6871.948730, pp_loss: 7.386864
[INFO] 2021-07-12 19:02:18,425 [run_pretraining.py:  512]:	********exe.run_1509******* 
[INFO] 2021-07-12 19:02:19,324 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:19,324 [run_pretraining.py:  534]:	loss/total_loss, 8.007132530212402, 1510
[INFO] 2021-07-12 19:02:19,325 [run_pretraining.py:  535]:	loss/mlm_loss, 8.007132530212402, 1510
[INFO] 2021-07-12 19:02:19,325 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5090000488271471e-05, 1510
[INFO] 2021-07-12 19:02:19,325 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1510
[INFO] 2021-07-12 19:02:19,325 [run_pretraining.py:  558]:	worker_index: 6, step: 1510, cost: 8.007133, mlm loss: 8.007133, speed: 1.112685 steps/s, speed: 8.901478 samples/s, speed: 4557.556617 tokens/s, learning rate: 1.509e-05, loss_scalings: 6871.948730, pp_loss: 7.434453
[INFO] 2021-07-12 19:02:19,325 [run_pretraining.py:  512]:	********exe.run_1510******* 
[INFO] 2021-07-12 19:02:20,218 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:20,219 [run_pretraining.py:  534]:	loss/total_loss, 7.047849178314209, 1511
[INFO] 2021-07-12 19:02:20,219 [run_pretraining.py:  535]:	loss/mlm_loss, 7.047849178314209, 1511
[INFO] 2021-07-12 19:02:20,219 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5099998563528061e-05, 1511
[INFO] 2021-07-12 19:02:20,219 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1511
[INFO] 2021-07-12 19:02:20,219 [run_pretraining.py:  558]:	worker_index: 6, step: 1511, cost: 7.047849, mlm loss: 7.047849, speed: 1.118620 steps/s, speed: 8.948961 samples/s, speed: 4581.867823 tokens/s, learning rate: 1.510e-05, loss_scalings: 6871.948730, pp_loss: 7.287556
[INFO] 2021-07-12 19:02:20,220 [run_pretraining.py:  512]:	********exe.run_1511******* 
[INFO] 2021-07-12 19:02:21,131 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:21,132 [run_pretraining.py:  534]:	loss/total_loss, 8.018975257873535, 1512
[INFO] 2021-07-12 19:02:21,132 [run_pretraining.py:  535]:	loss/mlm_loss, 8.018975257873535, 1512
[INFO] 2021-07-12 19:02:21,132 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5109999367268756e-05, 1512
[INFO] 2021-07-12 19:02:21,132 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1512
[INFO] 2021-07-12 19:02:21,132 [run_pretraining.py:  558]:	worker_index: 6, step: 1512, cost: 8.018975, mlm loss: 8.018975, speed: 1.096145 steps/s, speed: 8.769159 samples/s, speed: 4489.809306 tokens/s, learning rate: 1.511e-05, loss_scalings: 6871.948730, pp_loss: 7.681096
[INFO] 2021-07-12 19:02:21,133 [run_pretraining.py:  512]:	********exe.run_1512******* 
[INFO] 2021-07-12 19:02:22,035 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:22,036 [run_pretraining.py:  534]:	loss/total_loss, 8.065873146057129, 1513
[INFO] 2021-07-12 19:02:22,036 [run_pretraining.py:  535]:	loss/mlm_loss, 8.065873146057129, 1513
[INFO] 2021-07-12 19:02:22,036 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.511999926151475e-05, 1513
[INFO] 2021-07-12 19:02:22,036 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1513
[INFO] 2021-07-12 19:02:22,036 [run_pretraining.py:  558]:	worker_index: 6, step: 1513, cost: 8.065873, mlm loss: 8.065873, speed: 1.107576 steps/s, speed: 8.860608 samples/s, speed: 4536.631381 tokens/s, learning rate: 1.512e-05, loss_scalings: 6871.948730, pp_loss: 7.515789
[INFO] 2021-07-12 19:02:22,036 [run_pretraining.py:  512]:	********exe.run_1513******* 
[INFO] 2021-07-12 19:02:22,962 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:22,963 [run_pretraining.py:  534]:	loss/total_loss, 7.440447807312012, 1514
[INFO] 2021-07-12 19:02:22,963 [run_pretraining.py:  535]:	loss/mlm_loss, 7.440447807312012, 1514
[INFO] 2021-07-12 19:02:22,963 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5129999155760743e-05, 1514
[INFO] 2021-07-12 19:02:22,963 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1514
[INFO] 2021-07-12 19:02:22,963 [run_pretraining.py:  558]:	worker_index: 6, step: 1514, cost: 7.440448, mlm loss: 7.440448, speed: 1.079638 steps/s, speed: 8.637104 samples/s, speed: 4422.197227 tokens/s, learning rate: 1.513e-05, loss_scalings: 6871.948730, pp_loss: 7.152842
[INFO] 2021-07-12 19:02:22,963 [run_pretraining.py:  512]:	********exe.run_1514******* 
[INFO] 2021-07-12 19:02:23,888 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:23,889 [run_pretraining.py:  534]:	loss/total_loss, 7.519811153411865, 1515
[INFO] 2021-07-12 19:02:23,889 [run_pretraining.py:  535]:	loss/mlm_loss, 7.519811153411865, 1515
[INFO] 2021-07-12 19:02:23,889 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5139999959501438e-05, 1515
[INFO] 2021-07-12 19:02:23,889 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1515
[INFO] 2021-07-12 19:02:23,889 [run_pretraining.py:  558]:	worker_index: 6, step: 1515, cost: 7.519811, mlm loss: 7.519811, speed: 1.080517 steps/s, speed: 8.644137 samples/s, speed: 4425.798320 tokens/s, learning rate: 1.514e-05, loss_scalings: 6871.948730, pp_loss: 7.479867
[INFO] 2021-07-12 19:02:23,889 [run_pretraining.py:  512]:	********exe.run_1515******* 
[INFO] 2021-07-12 19:02:24,783 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:24,783 [run_pretraining.py:  534]:	loss/total_loss, 7.144887447357178, 1516
[INFO] 2021-07-12 19:02:24,784 [run_pretraining.py:  535]:	loss/mlm_loss, 7.144887447357178, 1516
[INFO] 2021-07-12 19:02:24,784 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5149999853747431e-05, 1516
[INFO] 2021-07-12 19:02:24,784 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1516
[INFO] 2021-07-12 19:02:24,784 [run_pretraining.py:  558]:	worker_index: 6, step: 1516, cost: 7.144887, mlm loss: 7.144887, speed: 1.118687 steps/s, speed: 8.949498 samples/s, speed: 4582.142785 tokens/s, learning rate: 1.515e-05, loss_scalings: 6871.948730, pp_loss: 7.059035
[INFO] 2021-07-12 19:02:24,784 [run_pretraining.py:  512]:	********exe.run_1516******* 
[INFO] 2021-07-12 19:02:25,683 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:25,684 [run_pretraining.py:  534]:	loss/total_loss, 4.4105682373046875, 1517
[INFO] 2021-07-12 19:02:25,684 [run_pretraining.py:  535]:	loss/mlm_loss, 4.4105682373046875, 1517
[INFO] 2021-07-12 19:02:25,684 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5159999747993425e-05, 1517
[INFO] 2021-07-12 19:02:25,684 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1517
[INFO] 2021-07-12 19:02:25,684 [run_pretraining.py:  558]:	worker_index: 6, step: 1517, cost: 4.410568, mlm loss: 4.410568, speed: 1.111902 steps/s, speed: 8.895220 samples/s, speed: 4554.352471 tokens/s, learning rate: 1.516e-05, loss_scalings: 6871.948730, pp_loss: 6.568134
[INFO] 2021-07-12 19:02:25,684 [run_pretraining.py:  512]:	********exe.run_1517******* 
[INFO] 2021-07-12 19:02:26,571 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:26,571 [run_pretraining.py:  534]:	loss/total_loss, 7.109964370727539, 1518
[INFO] 2021-07-12 19:02:26,572 [run_pretraining.py:  535]:	loss/mlm_loss, 7.109964370727539, 1518
[INFO] 2021-07-12 19:02:26,572 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.517000055173412e-05, 1518
[INFO] 2021-07-12 19:02:26,572 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1518
[INFO] 2021-07-12 19:02:26,572 [run_pretraining.py:  558]:	worker_index: 6, step: 1518, cost: 7.109964, mlm loss: 7.109964, speed: 1.127109 steps/s, speed: 9.016870 samples/s, speed: 4616.637268 tokens/s, learning rate: 1.517e-05, loss_scalings: 6871.948730, pp_loss: 7.169349
[INFO] 2021-07-12 19:02:26,572 [run_pretraining.py:  512]:	********exe.run_1518******* 
[INFO] 2021-07-12 19:02:27,486 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:27,486 [run_pretraining.py:  534]:	loss/total_loss, 7.014347076416016, 1519
[INFO] 2021-07-12 19:02:27,487 [run_pretraining.py:  535]:	loss/mlm_loss, 7.014347076416016, 1519
[INFO] 2021-07-12 19:02:27,487 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5180000445980113e-05, 1519
[INFO] 2021-07-12 19:02:27,487 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1519
[INFO] 2021-07-12 19:02:27,487 [run_pretraining.py:  558]:	worker_index: 6, step: 1519, cost: 7.014347, mlm loss: 7.014347, speed: 1.093779 steps/s, speed: 8.750236 samples/s, speed: 4480.120600 tokens/s, learning rate: 1.518e-05, loss_scalings: 6871.948730, pp_loss: 7.417014
[INFO] 2021-07-12 19:02:27,487 [run_pretraining.py:  512]:	********exe.run_1519******* 
[INFO] 2021-07-12 19:02:28,391 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:28,392 [run_pretraining.py:  534]:	loss/total_loss, 7.944764614105225, 1520
[INFO] 2021-07-12 19:02:28,392 [run_pretraining.py:  535]:	loss/mlm_loss, 7.944764614105225, 1520
[INFO] 2021-07-12 19:02:28,392 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5189998521236703e-05, 1520
[INFO] 2021-07-12 19:02:28,392 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1520
[INFO] 2021-07-12 19:02:28,392 [run_pretraining.py:  558]:	worker_index: 6, step: 1520, cost: 7.944765, mlm loss: 7.944765, speed: 1.105359 steps/s, speed: 8.842873 samples/s, speed: 4527.550986 tokens/s, learning rate: 1.519e-05, loss_scalings: 6871.948730, pp_loss: 7.197626
[INFO] 2021-07-12 19:02:28,392 [run_pretraining.py:  512]:	********exe.run_1520******* 
[INFO] 2021-07-12 19:02:29,300 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:29,301 [run_pretraining.py:  534]:	loss/total_loss, 7.19935941696167, 1521
[INFO] 2021-07-12 19:02:29,301 [run_pretraining.py:  535]:	loss/mlm_loss, 7.19935941696167, 1521
[INFO] 2021-07-12 19:02:29,301 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5199999324977398e-05, 1521
[INFO] 2021-07-12 19:02:29,301 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1521
[INFO] 2021-07-12 19:02:29,301 [run_pretraining.py:  558]:	worker_index: 6, step: 1521, cost: 7.199359, mlm loss: 7.199359, speed: 1.101009 steps/s, speed: 8.808073 samples/s, speed: 4509.733192 tokens/s, learning rate: 1.520e-05, loss_scalings: 6871.948730, pp_loss: 6.378222
[INFO] 2021-07-12 19:02:29,301 [run_pretraining.py:  512]:	********exe.run_1521******* 
[INFO] 2021-07-12 19:02:30,214 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:30,214 [run_pretraining.py:  534]:	loss/total_loss, 5.893521785736084, 1522
[INFO] 2021-07-12 19:02:30,214 [run_pretraining.py:  535]:	loss/mlm_loss, 5.893521785736084, 1522
[INFO] 2021-07-12 19:02:30,214 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5209999219223391e-05, 1522
[INFO] 2021-07-12 19:02:30,215 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1522
[INFO] 2021-07-12 19:02:30,215 [run_pretraining.py:  558]:	worker_index: 6, step: 1522, cost: 5.893522, mlm loss: 5.893522, speed: 1.095617 steps/s, speed: 8.764939 samples/s, speed: 4487.648993 tokens/s, learning rate: 1.521e-05, loss_scalings: 6871.948730, pp_loss: 6.959820
[INFO] 2021-07-12 19:02:30,215 [run_pretraining.py:  512]:	********exe.run_1522******* 
[INFO] 2021-07-12 19:02:31,122 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:31,122 [run_pretraining.py:  534]:	loss/total_loss, 7.228946685791016, 1523
[INFO] 2021-07-12 19:02:31,122 [run_pretraining.py:  535]:	loss/mlm_loss, 7.228946685791016, 1523
[INFO] 2021-07-12 19:02:31,123 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5219999113469385e-05, 1523
[INFO] 2021-07-12 19:02:31,123 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1523
[INFO] 2021-07-12 19:02:31,123 [run_pretraining.py:  558]:	worker_index: 6, step: 1523, cost: 7.228947, mlm loss: 7.228947, speed: 1.101999 steps/s, speed: 8.815994 samples/s, speed: 4513.789017 tokens/s, learning rate: 1.522e-05, loss_scalings: 6871.948730, pp_loss: 6.451078
[INFO] 2021-07-12 19:02:31,123 [run_pretraining.py:  512]:	********exe.run_1523******* 
[INFO] 2021-07-12 19:02:32,031 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:32,031 [run_pretraining.py:  534]:	loss/total_loss, 7.268999099731445, 1524
[INFO] 2021-07-12 19:02:32,032 [run_pretraining.py:  535]:	loss/mlm_loss, 7.268999099731445, 1524
[INFO] 2021-07-12 19:02:32,032 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.522999991721008e-05, 1524
[INFO] 2021-07-12 19:02:32,032 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1524
[INFO] 2021-07-12 19:02:32,032 [run_pretraining.py:  558]:	worker_index: 6, step: 1524, cost: 7.268999, mlm loss: 7.268999, speed: 1.100945 steps/s, speed: 8.807559 samples/s, speed: 4509.470402 tokens/s, learning rate: 1.523e-05, loss_scalings: 6871.948730, pp_loss: 7.720495
[INFO] 2021-07-12 19:02:32,032 [run_pretraining.py:  512]:	********exe.run_1524******* 
[INFO] 2021-07-12 19:02:32,936 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:32,937 [run_pretraining.py:  534]:	loss/total_loss, 6.965053558349609, 1525
[INFO] 2021-07-12 19:02:32,937 [run_pretraining.py:  535]:	loss/mlm_loss, 6.965053558349609, 1525
[INFO] 2021-07-12 19:02:32,937 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5239999811456073e-05, 1525
[INFO] 2021-07-12 19:02:32,937 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1525
[INFO] 2021-07-12 19:02:32,937 [run_pretraining.py:  558]:	worker_index: 6, step: 1525, cost: 6.965054, mlm loss: 6.965054, speed: 1.105110 steps/s, speed: 8.840879 samples/s, speed: 4526.529852 tokens/s, learning rate: 1.524e-05, loss_scalings: 6871.948730, pp_loss: 7.182627
[INFO] 2021-07-12 19:02:32,938 [run_pretraining.py:  512]:	********exe.run_1525******* 
[INFO] 2021-07-12 19:02:33,841 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:33,842 [run_pretraining.py:  534]:	loss/total_loss, 6.533498764038086, 1526
[INFO] 2021-07-12 19:02:33,842 [run_pretraining.py:  535]:	loss/mlm_loss, 6.533498764038086, 1526
[INFO] 2021-07-12 19:02:33,842 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5249999705702066e-05, 1526
[INFO] 2021-07-12 19:02:33,842 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1526
[INFO] 2021-07-12 19:02:33,842 [run_pretraining.py:  558]:	worker_index: 6, step: 1526, cost: 6.533499, mlm loss: 6.533499, speed: 1.106423 steps/s, speed: 8.851385 samples/s, speed: 4531.909099 tokens/s, learning rate: 1.525e-05, loss_scalings: 6871.948730, pp_loss: 7.074015
[INFO] 2021-07-12 19:02:33,842 [run_pretraining.py:  512]:	********exe.run_1526******* 
[INFO] 2021-07-12 19:02:34,743 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:34,744 [run_pretraining.py:  534]:	loss/total_loss, 7.400518894195557, 1527
[INFO] 2021-07-12 19:02:34,744 [run_pretraining.py:  535]:	loss/mlm_loss, 7.400518894195557, 1527
[INFO] 2021-07-12 19:02:34,744 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.526000050944276e-05, 1527
[INFO] 2021-07-12 19:02:34,744 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1527
[INFO] 2021-07-12 19:02:34,744 [run_pretraining.py:  558]:	worker_index: 6, step: 1527, cost: 7.400519, mlm loss: 7.400519, speed: 1.108902 steps/s, speed: 8.871213 samples/s, speed: 4542.061097 tokens/s, learning rate: 1.526e-05, loss_scalings: 6871.948730, pp_loss: 7.294178
[INFO] 2021-07-12 19:02:34,745 [run_pretraining.py:  512]:	********exe.run_1527******* 
[INFO] 2021-07-12 19:02:35,652 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:35,652 [run_pretraining.py:  534]:	loss/total_loss, 7.543313503265381, 1528
[INFO] 2021-07-12 19:02:35,652 [run_pretraining.py:  535]:	loss/mlm_loss, 7.543313503265381, 1528
[INFO] 2021-07-12 19:02:35,652 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5269999494194053e-05, 1528
[INFO] 2021-07-12 19:02:35,653 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1528
[INFO] 2021-07-12 19:02:35,653 [run_pretraining.py:  558]:	worker_index: 6, step: 1528, cost: 7.543314, mlm loss: 7.543314, speed: 1.102018 steps/s, speed: 8.816140 samples/s, speed: 4513.863732 tokens/s, learning rate: 1.527e-05, loss_scalings: 6871.948730, pp_loss: 7.233694
[INFO] 2021-07-12 19:02:35,653 [run_pretraining.py:  512]:	********exe.run_1528******* 
[INFO] 2021-07-12 19:02:36,555 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:36,556 [run_pretraining.py:  534]:	loss/total_loss, 7.688169002532959, 1529
[INFO] 2021-07-12 19:02:36,556 [run_pretraining.py:  535]:	loss/mlm_loss, 7.688169002532959, 1529
[INFO] 2021-07-12 19:02:36,556 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5279998478945345e-05, 1529
[INFO] 2021-07-12 19:02:36,556 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1529
[INFO] 2021-07-12 19:02:36,556 [run_pretraining.py:  558]:	worker_index: 6, step: 1529, cost: 7.688169, mlm loss: 7.688169, speed: 1.107488 steps/s, speed: 8.859906 samples/s, speed: 4536.272018 tokens/s, learning rate: 1.528e-05, loss_scalings: 6871.948730, pp_loss: 6.758558
[INFO] 2021-07-12 19:02:36,556 [run_pretraining.py:  512]:	********exe.run_1529******* 
[INFO] 2021-07-12 19:02:37,461 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:37,462 [run_pretraining.py:  534]:	loss/total_loss, 7.284955024719238, 1530
[INFO] 2021-07-12 19:02:37,462 [run_pretraining.py:  535]:	loss/mlm_loss, 7.284955024719238, 1530
[INFO] 2021-07-12 19:02:37,462 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.528999928268604e-05, 1530
[INFO] 2021-07-12 19:02:37,462 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1530
[INFO] 2021-07-12 19:02:37,462 [run_pretraining.py:  558]:	worker_index: 6, step: 1530, cost: 7.284955, mlm loss: 7.284955, speed: 1.104784 steps/s, speed: 8.838275 samples/s, speed: 4525.196868 tokens/s, learning rate: 1.529e-05, loss_scalings: 6871.948730, pp_loss: 7.505447
[INFO] 2021-07-12 19:02:37,462 [run_pretraining.py:  512]:	********exe.run_1530******* 
[INFO] 2021-07-12 19:02:38,368 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:38,369 [run_pretraining.py:  534]:	loss/total_loss, 5.46886682510376, 1531
[INFO] 2021-07-12 19:02:38,369 [run_pretraining.py:  535]:	loss/mlm_loss, 5.46886682510376, 1531
[INFO] 2021-07-12 19:02:38,369 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5300000086426735e-05, 1531
[INFO] 2021-07-12 19:02:38,369 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1531
[INFO] 2021-07-12 19:02:38,369 [run_pretraining.py:  558]:	worker_index: 6, step: 1531, cost: 5.468867, mlm loss: 5.468867, speed: 1.103121 steps/s, speed: 8.824970 samples/s, speed: 4518.384464 tokens/s, learning rate: 1.530e-05, loss_scalings: 6871.948730, pp_loss: 6.916557
[INFO] 2021-07-12 19:02:38,369 [run_pretraining.py:  512]:	********exe.run_1531******* 
[INFO] 2021-07-12 19:02:39,275 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:39,276 [run_pretraining.py:  534]:	loss/total_loss, 7.516246795654297, 1532
[INFO] 2021-07-12 19:02:39,276 [run_pretraining.py:  535]:	loss/mlm_loss, 7.516246795654297, 1532
[INFO] 2021-07-12 19:02:39,276 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5309999071178026e-05, 1532
[INFO] 2021-07-12 19:02:39,276 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1532
[INFO] 2021-07-12 19:02:39,276 [run_pretraining.py:  558]:	worker_index: 6, step: 1532, cost: 7.516247, mlm loss: 7.516247, speed: 1.103453 steps/s, speed: 8.827626 samples/s, speed: 4519.744352 tokens/s, learning rate: 1.531e-05, loss_scalings: 6871.948730, pp_loss: 7.501182
[INFO] 2021-07-12 19:02:39,276 [run_pretraining.py:  512]:	********exe.run_1532******* 
[INFO] 2021-07-12 19:02:40,182 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:40,183 [run_pretraining.py:  534]:	loss/total_loss, 6.9571919441223145, 1533
[INFO] 2021-07-12 19:02:40,183 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9571919441223145, 1533
[INFO] 2021-07-12 19:02:40,183 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.531999987491872e-05, 1533
[INFO] 2021-07-12 19:02:40,183 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1533
[INFO] 2021-07-12 19:02:40,183 [run_pretraining.py:  558]:	worker_index: 6, step: 1533, cost: 6.957192, mlm loss: 6.957192, speed: 1.103337 steps/s, speed: 8.826697 samples/s, speed: 4519.268774 tokens/s, learning rate: 1.532e-05, loss_scalings: 6871.948730, pp_loss: 7.272206
[INFO] 2021-07-12 19:02:40,183 [run_pretraining.py:  512]:	********exe.run_1533******* 
[INFO] 2021-07-12 19:02:41,102 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:41,103 [run_pretraining.py:  534]:	loss/total_loss, 7.127804756164551, 1534
[INFO] 2021-07-12 19:02:41,103 [run_pretraining.py:  535]:	loss/mlm_loss, 7.127804756164551, 1534
[INFO] 2021-07-12 19:02:41,103 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5330000678659417e-05, 1534
[INFO] 2021-07-12 19:02:41,103 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1534
[INFO] 2021-07-12 19:02:41,103 [run_pretraining.py:  558]:	worker_index: 6, step: 1534, cost: 7.127805, mlm loss: 7.127805, speed: 1.088212 steps/s, speed: 8.705698 samples/s, speed: 4457.317278 tokens/s, learning rate: 1.533e-05, loss_scalings: 6871.948730, pp_loss: 6.902235
[INFO] 2021-07-12 19:02:41,103 [run_pretraining.py:  512]:	********exe.run_1534******* 
[INFO] 2021-07-12 19:02:42,006 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:42,007 [run_pretraining.py:  534]:	loss/total_loss, 7.53587007522583, 1535
[INFO] 2021-07-12 19:02:42,007 [run_pretraining.py:  535]:	loss/mlm_loss, 7.53587007522583, 1535
[INFO] 2021-07-12 19:02:42,007 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.533999966341071e-05, 1535
[INFO] 2021-07-12 19:02:42,007 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1535
[INFO] 2021-07-12 19:02:42,007 [run_pretraining.py:  558]:	worker_index: 6, step: 1535, cost: 7.535870, mlm loss: 7.535870, speed: 1.106955 steps/s, speed: 8.855641 samples/s, speed: 4534.088312 tokens/s, learning rate: 1.534e-05, loss_scalings: 6871.948730, pp_loss: 7.255836
[INFO] 2021-07-12 19:02:42,007 [run_pretraining.py:  512]:	********exe.run_1535******* 
[INFO] 2021-07-12 19:02:42,905 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:42,905 [run_pretraining.py:  534]:	loss/total_loss, 7.8740973472595215, 1536
[INFO] 2021-07-12 19:02:42,906 [run_pretraining.py:  535]:	loss/mlm_loss, 7.8740973472595215, 1536
[INFO] 2021-07-12 19:02:42,906 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5350000467151403e-05, 1536
[INFO] 2021-07-12 19:02:42,906 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1536
[INFO] 2021-07-12 19:02:42,906 [run_pretraining.py:  558]:	worker_index: 6, step: 1536, cost: 7.874097, mlm loss: 7.874097, speed: 1.113455 steps/s, speed: 8.907638 samples/s, speed: 4560.710792 tokens/s, learning rate: 1.535e-05, loss_scalings: 6871.948730, pp_loss: 7.443995
[INFO] 2021-07-12 19:02:42,906 [run_pretraining.py:  512]:	********exe.run_1536******* 
[INFO] 2021-07-12 19:02:43,809 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:43,810 [run_pretraining.py:  534]:	loss/total_loss, 7.499683380126953, 1537
[INFO] 2021-07-12 19:02:43,810 [run_pretraining.py:  535]:	loss/mlm_loss, 7.499683380126953, 1537
[INFO] 2021-07-12 19:02:43,810 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5359999451902695e-05, 1537
[INFO] 2021-07-12 19:02:43,810 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1537
[INFO] 2021-07-12 19:02:43,810 [run_pretraining.py:  558]:	worker_index: 6, step: 1537, cost: 7.499683, mlm loss: 7.499683, speed: 1.106965 steps/s, speed: 8.855716 samples/s, speed: 4534.126605 tokens/s, learning rate: 1.536e-05, loss_scalings: 6871.948730, pp_loss: 7.440404
[INFO] 2021-07-12 19:02:43,810 [run_pretraining.py:  512]:	********exe.run_1537******* 
[INFO] 2021-07-12 19:02:44,713 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:44,713 [run_pretraining.py:  534]:	loss/total_loss, 7.755589485168457, 1538
[INFO] 2021-07-12 19:02:44,713 [run_pretraining.py:  535]:	loss/mlm_loss, 7.755589485168457, 1538
[INFO] 2021-07-12 19:02:44,713 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5369998436653987e-05, 1538
[INFO] 2021-07-12 19:02:44,714 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1538
[INFO] 2021-07-12 19:02:44,714 [run_pretraining.py:  558]:	worker_index: 6, step: 1538, cost: 7.755589, mlm loss: 7.755589, speed: 1.107462 steps/s, speed: 8.859693 samples/s, speed: 4536.163022 tokens/s, learning rate: 1.537e-05, loss_scalings: 6871.948730, pp_loss: 7.554307
[INFO] 2021-07-12 19:02:44,714 [run_pretraining.py:  512]:	********exe.run_1538******* 
[INFO] 2021-07-12 19:02:45,623 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:45,623 [run_pretraining.py:  534]:	loss/total_loss, 7.54475736618042, 1539
[INFO] 2021-07-12 19:02:45,623 [run_pretraining.py:  535]:	loss/mlm_loss, 7.54475736618042, 1539
[INFO] 2021-07-12 19:02:45,623 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.537999924039468e-05, 1539
[INFO] 2021-07-12 19:02:45,624 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1539
[INFO] 2021-07-12 19:02:45,624 [run_pretraining.py:  558]:	worker_index: 6, step: 1539, cost: 7.544757, mlm loss: 7.544757, speed: 1.099802 steps/s, speed: 8.798414 samples/s, speed: 4504.787930 tokens/s, learning rate: 1.538e-05, loss_scalings: 6871.948730, pp_loss: 7.525618
[INFO] 2021-07-12 19:02:45,624 [run_pretraining.py:  512]:	********exe.run_1539******* 
[INFO] 2021-07-12 19:02:46,537 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:46,537 [run_pretraining.py:  534]:	loss/total_loss, 6.554088592529297, 1540
[INFO] 2021-07-12 19:02:46,537 [run_pretraining.py:  535]:	loss/mlm_loss, 6.554088592529297, 1540
[INFO] 2021-07-12 19:02:46,537 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5390000044135377e-05, 1540
[INFO] 2021-07-12 19:02:46,538 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1540
[INFO] 2021-07-12 19:02:46,538 [run_pretraining.py:  558]:	worker_index: 6, step: 1540, cost: 6.554089, mlm loss: 6.554089, speed: 1.094867 steps/s, speed: 8.758934 samples/s, speed: 4484.573962 tokens/s, learning rate: 1.539e-05, loss_scalings: 6871.948730, pp_loss: 7.094044
[INFO] 2021-07-12 19:02:46,538 [run_pretraining.py:  512]:	********exe.run_1540******* 
[INFO] 2021-07-12 19:02:47,440 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:47,441 [run_pretraining.py:  534]:	loss/total_loss, 7.401434898376465, 1541
[INFO] 2021-07-12 19:02:47,441 [run_pretraining.py:  535]:	loss/mlm_loss, 7.401434898376465, 1541
[INFO] 2021-07-12 19:02:47,441 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.539999902888667e-05, 1541
[INFO] 2021-07-12 19:02:47,441 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1541
[INFO] 2021-07-12 19:02:47,441 [run_pretraining.py:  558]:	worker_index: 6, step: 1541, cost: 7.401435, mlm loss: 7.401435, speed: 1.107407 steps/s, speed: 8.859256 samples/s, speed: 4535.939058 tokens/s, learning rate: 1.540e-05, loss_scalings: 6871.948730, pp_loss: 7.346262
[INFO] 2021-07-12 19:02:47,441 [run_pretraining.py:  512]:	********exe.run_1541******* 
[INFO] 2021-07-12 19:02:48,348 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:48,349 [run_pretraining.py:  534]:	loss/total_loss, 7.410988807678223, 1542
[INFO] 2021-07-12 19:02:48,349 [run_pretraining.py:  535]:	loss/mlm_loss, 7.410988807678223, 1542
[INFO] 2021-07-12 19:02:48,349 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5409999832627364e-05, 1542
[INFO] 2021-07-12 19:02:48,349 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1542
[INFO] 2021-07-12 19:02:48,349 [run_pretraining.py:  558]:	worker_index: 6, step: 1542, cost: 7.410989, mlm loss: 7.410989, speed: 1.102203 steps/s, speed: 8.817627 samples/s, speed: 4514.625259 tokens/s, learning rate: 1.541e-05, loss_scalings: 6871.948730, pp_loss: 7.149685
[INFO] 2021-07-12 19:02:48,349 [run_pretraining.py:  512]:	********exe.run_1542******* 
[INFO] 2021-07-12 19:02:49,391 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:49,391 [run_pretraining.py:  534]:	loss/total_loss, 7.420772552490234, 1543
[INFO] 2021-07-12 19:02:49,391 [run_pretraining.py:  535]:	loss/mlm_loss, 7.420772552490234, 1543
[INFO] 2021-07-12 19:02:49,391 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.542000063636806e-05, 1543
[INFO] 2021-07-12 19:02:49,392 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1543
[INFO] 2021-07-12 19:02:49,392 [run_pretraining.py:  558]:	worker_index: 6, step: 1543, cost: 7.420773, mlm loss: 7.420773, speed: 0.960128 steps/s, speed: 7.681023 samples/s, speed: 3932.683570 tokens/s, learning rate: 1.542e-05, loss_scalings: 6871.948730, pp_loss: 7.330917
[INFO] 2021-07-12 19:02:49,392 [run_pretraining.py:  512]:	********exe.run_1543******* 
[INFO] 2021-07-12 19:02:50,446 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:50,447 [run_pretraining.py:  534]:	loss/total_loss, 6.557826042175293, 1544
[INFO] 2021-07-12 19:02:50,447 [run_pretraining.py:  535]:	loss/mlm_loss, 6.557826042175293, 1544
[INFO] 2021-07-12 19:02:50,447 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.542999962111935e-05, 1544
[INFO] 2021-07-12 19:02:50,447 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1544
[INFO] 2021-07-12 19:02:50,447 [run_pretraining.py:  558]:	worker_index: 6, step: 1544, cost: 6.557826, mlm loss: 6.557826, speed: 0.948162 steps/s, speed: 7.585297 samples/s, speed: 3883.671880 tokens/s, learning rate: 1.543e-05, loss_scalings: 6871.948730, pp_loss: 7.323017
[INFO] 2021-07-12 19:02:50,447 [run_pretraining.py:  512]:	********exe.run_1544******* 
[INFO] 2021-07-12 19:02:51,499 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:51,500 [run_pretraining.py:  534]:	loss/total_loss, 7.688989162445068, 1545
[INFO] 2021-07-12 19:02:51,500 [run_pretraining.py:  535]:	loss/mlm_loss, 7.688989162445068, 1545
[INFO] 2021-07-12 19:02:51,500 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5440000424860045e-05, 1545
[INFO] 2021-07-12 19:02:51,500 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1545
[INFO] 2021-07-12 19:02:51,500 [run_pretraining.py:  558]:	worker_index: 6, step: 1545, cost: 7.688989, mlm loss: 7.688989, speed: 0.950383 steps/s, speed: 7.603065 samples/s, speed: 3892.769292 tokens/s, learning rate: 1.544e-05, loss_scalings: 6871.948730, pp_loss: 7.576921
[INFO] 2021-07-12 19:02:51,500 [run_pretraining.py:  512]:	********exe.run_1545******* 
[INFO] 2021-07-12 19:02:52,568 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:52,569 [run_pretraining.py:  534]:	loss/total_loss, 4.940769195556641, 1546
[INFO] 2021-07-12 19:02:52,569 [run_pretraining.py:  535]:	loss/mlm_loss, 4.940769195556641, 1546
[INFO] 2021-07-12 19:02:52,569 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5449999409611337e-05, 1546
[INFO] 2021-07-12 19:02:52,569 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1546
[INFO] 2021-07-12 19:02:52,570 [run_pretraining.py:  558]:	worker_index: 6, step: 1546, cost: 4.940769, mlm loss: 4.940769, speed: 0.935570 steps/s, speed: 7.484563 samples/s, speed: 3832.096075 tokens/s, learning rate: 1.545e-05, loss_scalings: 6871.948730, pp_loss: 6.780054
[INFO] 2021-07-12 19:02:52,570 [run_pretraining.py:  512]:	********exe.run_1546******* 
[INFO] 2021-07-12 19:02:53,642 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:53,643 [run_pretraining.py:  534]:	loss/total_loss, 7.777873516082764, 1547
[INFO] 2021-07-12 19:02:53,643 [run_pretraining.py:  535]:	loss/mlm_loss, 7.777873516082764, 1547
[INFO] 2021-07-12 19:02:53,643 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.545999839436263e-05, 1547
[INFO] 2021-07-12 19:02:53,643 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1547
[INFO] 2021-07-12 19:02:53,643 [run_pretraining.py:  558]:	worker_index: 6, step: 1547, cost: 7.777874, mlm loss: 7.777874, speed: 0.932201 steps/s, speed: 7.457608 samples/s, speed: 3818.295148 tokens/s, learning rate: 1.546e-05, loss_scalings: 6871.948730, pp_loss: 7.586549
[INFO] 2021-07-12 19:02:53,643 [run_pretraining.py:  512]:	********exe.run_1547******* 
[INFO] 2021-07-12 19:02:54,700 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:54,701 [run_pretraining.py:  534]:	loss/total_loss, 7.730781555175781, 1548
[INFO] 2021-07-12 19:02:54,701 [run_pretraining.py:  535]:	loss/mlm_loss, 7.730781555175781, 1548
[INFO] 2021-07-12 19:02:54,701 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5469999198103324e-05, 1548
[INFO] 2021-07-12 19:02:54,701 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1548
[INFO] 2021-07-12 19:02:54,701 [run_pretraining.py:  558]:	worker_index: 6, step: 1548, cost: 7.730782, mlm loss: 7.730782, speed: 0.945718 steps/s, speed: 7.565746 samples/s, speed: 3873.662006 tokens/s, learning rate: 1.547e-05, loss_scalings: 6871.948730, pp_loss: 7.376829
[INFO] 2021-07-12 19:02:54,701 [run_pretraining.py:  512]:	********exe.run_1548******* 
[INFO] 2021-07-12 19:02:55,761 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:55,762 [run_pretraining.py:  534]:	loss/total_loss, 6.700572967529297, 1549
[INFO] 2021-07-12 19:02:55,762 [run_pretraining.py:  535]:	loss/mlm_loss, 6.700572967529297, 1549
[INFO] 2021-07-12 19:02:55,762 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.548000000184402e-05, 1549
[INFO] 2021-07-12 19:02:55,762 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1549
[INFO] 2021-07-12 19:02:55,762 [run_pretraining.py:  558]:	worker_index: 6, step: 1549, cost: 6.700573, mlm loss: 6.700573, speed: 0.942911 steps/s, speed: 7.543292 samples/s, speed: 3862.165325 tokens/s, learning rate: 1.548e-05, loss_scalings: 6871.948730, pp_loss: 7.348511
[INFO] 2021-07-12 19:02:55,762 [run_pretraining.py:  512]:	********exe.run_1549******* 
[INFO] 2021-07-12 19:02:56,746 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:56,747 [run_pretraining.py:  534]:	loss/total_loss, 7.05252742767334, 1550
[INFO] 2021-07-12 19:02:56,747 [run_pretraining.py:  535]:	loss/mlm_loss, 7.05252742767334, 1550
[INFO] 2021-07-12 19:02:56,747 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.548999898659531e-05, 1550
[INFO] 2021-07-12 19:02:56,747 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1550
[INFO] 2021-07-12 19:02:56,747 [run_pretraining.py:  558]:	worker_index: 6, step: 1550, cost: 7.052527, mlm loss: 7.052527, speed: 1.015915 steps/s, speed: 8.127321 samples/s, speed: 4161.188216 tokens/s, learning rate: 1.549e-05, loss_scalings: 6871.948730, pp_loss: 7.099463
[INFO] 2021-07-12 19:02:56,747 [run_pretraining.py:  512]:	********exe.run_1550******* 
[INFO] 2021-07-12 19:02:57,699 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:57,699 [run_pretraining.py:  534]:	loss/total_loss, 7.968217372894287, 1551
[INFO] 2021-07-12 19:02:57,700 [run_pretraining.py:  535]:	loss/mlm_loss, 7.968217372894287, 1551
[INFO] 2021-07-12 19:02:57,700 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5499999790336005e-05, 1551
[INFO] 2021-07-12 19:02:57,700 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1551
[INFO] 2021-07-12 19:02:57,700 [run_pretraining.py:  558]:	worker_index: 6, step: 1551, cost: 7.968217, mlm loss: 7.968217, speed: 1.050673 steps/s, speed: 8.405381 samples/s, speed: 4303.555040 tokens/s, learning rate: 1.550e-05, loss_scalings: 6871.948730, pp_loss: 7.913903
[INFO] 2021-07-12 19:02:57,700 [run_pretraining.py:  512]:	********exe.run_1551******* 
[INFO] 2021-07-12 19:02:58,667 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:58,667 [run_pretraining.py:  534]:	loss/total_loss, 6.785821437835693, 1552
[INFO] 2021-07-12 19:02:58,667 [run_pretraining.py:  535]:	loss/mlm_loss, 6.785821437835693, 1552
[INFO] 2021-07-12 19:02:58,667 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.55100005940767e-05, 1552
[INFO] 2021-07-12 19:02:58,668 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1552
[INFO] 2021-07-12 19:02:58,668 [run_pretraining.py:  558]:	worker_index: 6, step: 1552, cost: 6.785821, mlm loss: 6.785821, speed: 1.034115 steps/s, speed: 8.272922 samples/s, speed: 4235.735825 tokens/s, learning rate: 1.551e-05, loss_scalings: 6871.948730, pp_loss: 7.214533
[INFO] 2021-07-12 19:02:58,668 [run_pretraining.py:  512]:	********exe.run_1552******* 
[INFO] 2021-07-12 19:02:59,622 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:59,622 [run_pretraining.py:  534]:	loss/total_loss, 7.578456878662109, 1553
[INFO] 2021-07-12 19:02:59,623 [run_pretraining.py:  535]:	loss/mlm_loss, 7.578456878662109, 1553
[INFO] 2021-07-12 19:02:59,623 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5519999578827992e-05, 1553
[INFO] 2021-07-12 19:02:59,623 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1553
[INFO] 2021-07-12 19:02:59,623 [run_pretraining.py:  558]:	worker_index: 6, step: 1553, cost: 7.578457, mlm loss: 7.578457, speed: 1.047585 steps/s, speed: 8.380682 samples/s, speed: 4290.909169 tokens/s, learning rate: 1.552e-05, loss_scalings: 6871.948730, pp_loss: 7.477751
[INFO] 2021-07-12 19:02:59,623 [run_pretraining.py:  512]:	********exe.run_1553******* 
[INFO] 2021-07-12 19:03:00,580 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:00,581 [run_pretraining.py:  534]:	loss/total_loss, 7.1396074295043945, 1554
[INFO] 2021-07-12 19:03:00,581 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1396074295043945, 1554
[INFO] 2021-07-12 19:03:00,581 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5530000382568687e-05, 1554
[INFO] 2021-07-12 19:03:00,581 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1554
[INFO] 2021-07-12 19:03:00,581 [run_pretraining.py:  558]:	worker_index: 6, step: 1554, cost: 7.139607, mlm loss: 7.139607, speed: 1.044190 steps/s, speed: 8.353519 samples/s, speed: 4277.001750 tokens/s, learning rate: 1.553e-05, loss_scalings: 6871.948730, pp_loss: 7.401369
[INFO] 2021-07-12 19:03:00,581 [run_pretraining.py:  512]:	********exe.run_1554******* 
[INFO] 2021-07-12 19:03:01,485 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:01,486 [run_pretraining.py:  534]:	loss/total_loss, 7.94902229309082, 1555
[INFO] 2021-07-12 19:03:01,486 [run_pretraining.py:  535]:	loss/mlm_loss, 7.94902229309082, 1555
[INFO] 2021-07-12 19:03:01,486 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.553999936731998e-05, 1555
[INFO] 2021-07-12 19:03:01,486 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1555
[INFO] 2021-07-12 19:03:01,486 [run_pretraining.py:  558]:	worker_index: 6, step: 1555, cost: 7.949022, mlm loss: 7.949022, speed: 1.106179 steps/s, speed: 8.849431 samples/s, speed: 4530.908703 tokens/s, learning rate: 1.554e-05, loss_scalings: 6871.948730, pp_loss: 7.622256
[INFO] 2021-07-12 19:03:01,486 [run_pretraining.py:  512]:	********exe.run_1555******* 
[INFO] 2021-07-12 19:03:02,419 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:02,420 [run_pretraining.py:  534]:	loss/total_loss, 7.174943447113037, 1556
[INFO] 2021-07-12 19:03:02,420 [run_pretraining.py:  535]:	loss/mlm_loss, 7.174943447113037, 1556
[INFO] 2021-07-12 19:03:02,420 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.554999835207127e-05, 1556
[INFO] 2021-07-12 19:03:02,420 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1556
[INFO] 2021-07-12 19:03:02,420 [run_pretraining.py:  558]:	worker_index: 6, step: 1556, cost: 7.174943, mlm loss: 7.174943, speed: 1.071139 steps/s, speed: 8.569110 samples/s, speed: 4387.384255 tokens/s, learning rate: 1.555e-05, loss_scalings: 6871.948730, pp_loss: 7.245892
[INFO] 2021-07-12 19:03:02,420 [run_pretraining.py:  512]:	********exe.run_1556******* 
[INFO] 2021-07-12 19:03:03,332 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:03,333 [run_pretraining.py:  534]:	loss/total_loss, 7.208416938781738, 1557
[INFO] 2021-07-12 19:03:03,333 [run_pretraining.py:  535]:	loss/mlm_loss, 7.208416938781738, 1557
[INFO] 2021-07-12 19:03:03,333 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5559999155811965e-05, 1557
[INFO] 2021-07-12 19:03:03,333 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1557
[INFO] 2021-07-12 19:03:03,333 [run_pretraining.py:  558]:	worker_index: 6, step: 1557, cost: 7.208417, mlm loss: 7.208417, speed: 1.096026 steps/s, speed: 8.768210 samples/s, speed: 4489.323582 tokens/s, learning rate: 1.556e-05, loss_scalings: 6871.948730, pp_loss: 6.580971
[INFO] 2021-07-12 19:03:03,333 [run_pretraining.py:  512]:	********exe.run_1557******* 
[INFO] 2021-07-12 19:03:04,241 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:04,241 [run_pretraining.py:  534]:	loss/total_loss, 7.954128742218018, 1558
[INFO] 2021-07-12 19:03:04,241 [run_pretraining.py:  535]:	loss/mlm_loss, 7.954128742218018, 1558
[INFO] 2021-07-12 19:03:04,241 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.556999995955266e-05, 1558
[INFO] 2021-07-12 19:03:04,241 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1558
[INFO] 2021-07-12 19:03:04,242 [run_pretraining.py:  558]:	worker_index: 6, step: 1558, cost: 7.954129, mlm loss: 7.954129, speed: 1.101951 steps/s, speed: 8.815610 samples/s, speed: 4513.592159 tokens/s, learning rate: 1.557e-05, loss_scalings: 6871.948730, pp_loss: 7.824412
[INFO] 2021-07-12 19:03:04,242 [run_pretraining.py:  512]:	********exe.run_1558******* 
[INFO] 2021-07-12 19:03:05,145 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:05,145 [run_pretraining.py:  534]:	loss/total_loss, 7.846355438232422, 1559
[INFO] 2021-07-12 19:03:05,145 [run_pretraining.py:  535]:	loss/mlm_loss, 7.846355438232422, 1559
[INFO] 2021-07-12 19:03:05,145 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5579998944303952e-05, 1559
[INFO] 2021-07-12 19:03:05,145 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1559
[INFO] 2021-07-12 19:03:05,146 [run_pretraining.py:  558]:	worker_index: 6, step: 1559, cost: 7.846355, mlm loss: 7.846355, speed: 1.107023 steps/s, speed: 8.856183 samples/s, speed: 4534.365948 tokens/s, learning rate: 1.558e-05, loss_scalings: 6871.948730, pp_loss: 7.113360
[INFO] 2021-07-12 19:03:05,146 [run_pretraining.py:  512]:	********exe.run_1559******* 
[INFO] 2021-07-12 19:03:06,085 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:06,086 [run_pretraining.py:  534]:	loss/total_loss, 7.058758735656738, 1560
[INFO] 2021-07-12 19:03:06,086 [run_pretraining.py:  535]:	loss/mlm_loss, 7.058758735656738, 1560
[INFO] 2021-07-12 19:03:06,086 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5589999748044647e-05, 1560
[INFO] 2021-07-12 19:03:06,086 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1560
[INFO] 2021-07-12 19:03:06,086 [run_pretraining.py:  558]:	worker_index: 6, step: 1560, cost: 7.058759, mlm loss: 7.058759, speed: 1.064116 steps/s, speed: 8.512929 samples/s, speed: 4358.619485 tokens/s, learning rate: 1.559e-05, loss_scalings: 6871.948730, pp_loss: 6.687669
[INFO] 2021-07-12 19:03:06,086 [run_pretraining.py:  512]:	********exe.run_1560******* 
[INFO] 2021-07-12 19:03:07,000 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:07,001 [run_pretraining.py:  534]:	loss/total_loss, 7.217902183532715, 1561
[INFO] 2021-07-12 19:03:07,001 [run_pretraining.py:  535]:	loss/mlm_loss, 7.217902183532715, 1561
[INFO] 2021-07-12 19:03:07,001 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5600000551785342e-05, 1561
[INFO] 2021-07-12 19:03:07,001 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1561
[INFO] 2021-07-12 19:03:07,001 [run_pretraining.py:  558]:	worker_index: 6, step: 1561, cost: 7.217902, mlm loss: 7.217902, speed: 1.093412 steps/s, speed: 8.747293 samples/s, speed: 4478.613982 tokens/s, learning rate: 1.560e-05, loss_scalings: 6871.948730, pp_loss: 7.402719
[INFO] 2021-07-12 19:03:07,001 [run_pretraining.py:  512]:	********exe.run_1561******* 
[INFO] 2021-07-12 19:03:07,913 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:07,914 [run_pretraining.py:  534]:	loss/total_loss, 7.3726959228515625, 1562
[INFO] 2021-07-12 19:03:07,914 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3726959228515625, 1562
[INFO] 2021-07-12 19:03:07,914 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5609999536536634e-05, 1562
[INFO] 2021-07-12 19:03:07,914 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1562
[INFO] 2021-07-12 19:03:07,914 [run_pretraining.py:  558]:	worker_index: 6, step: 1562, cost: 7.372696, mlm loss: 7.372696, speed: 1.096070 steps/s, speed: 8.768563 samples/s, speed: 4489.504249 tokens/s, learning rate: 1.561e-05, loss_scalings: 6871.948730, pp_loss: 7.328605
[INFO] 2021-07-12 19:03:07,914 [run_pretraining.py:  512]:	********exe.run_1562******* 
[INFO] 2021-07-12 19:03:08,811 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:08,812 [run_pretraining.py:  534]:	loss/total_loss, 7.540962219238281, 1563
[INFO] 2021-07-12 19:03:08,812 [run_pretraining.py:  535]:	loss/mlm_loss, 7.540962219238281, 1563
[INFO] 2021-07-12 19:03:08,812 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.562000034027733e-05, 1563
[INFO] 2021-07-12 19:03:08,812 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1563
[INFO] 2021-07-12 19:03:08,812 [run_pretraining.py:  558]:	worker_index: 6, step: 1563, cost: 7.540962, mlm loss: 7.540962, speed: 1.114735 steps/s, speed: 8.917880 samples/s, speed: 4565.954407 tokens/s, learning rate: 1.562e-05, loss_scalings: 6871.948730, pp_loss: 7.460193
[INFO] 2021-07-12 19:03:08,812 [run_pretraining.py:  512]:	********exe.run_1563******* 
[INFO] 2021-07-12 19:03:09,715 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:09,715 [run_pretraining.py:  534]:	loss/total_loss, 7.471706390380859, 1564
[INFO] 2021-07-12 19:03:09,716 [run_pretraining.py:  535]:	loss/mlm_loss, 7.471706390380859, 1564
[INFO] 2021-07-12 19:03:09,716 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.562999932502862e-05, 1564
[INFO] 2021-07-12 19:03:09,716 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1564
[INFO] 2021-07-12 19:03:09,716 [run_pretraining.py:  558]:	worker_index: 6, step: 1564, cost: 7.471706, mlm loss: 7.471706, speed: 1.107516 steps/s, speed: 8.860126 samples/s, speed: 4536.384612 tokens/s, learning rate: 1.563e-05, loss_scalings: 6871.948730, pp_loss: 7.462790
[INFO] 2021-07-12 19:03:09,716 [run_pretraining.py:  512]:	********exe.run_1564******* 
[INFO] 2021-07-12 19:03:10,628 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:10,628 [run_pretraining.py:  534]:	loss/total_loss, 8.109731674194336, 1565
[INFO] 2021-07-12 19:03:10,629 [run_pretraining.py:  535]:	loss/mlm_loss, 8.109731674194336, 1565
[INFO] 2021-07-12 19:03:10,629 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5639998309779912e-05, 1565
[INFO] 2021-07-12 19:03:10,629 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1565
[INFO] 2021-07-12 19:03:10,629 [run_pretraining.py:  558]:	worker_index: 6, step: 1565, cost: 8.109732, mlm loss: 8.109732, speed: 1.096148 steps/s, speed: 8.769184 samples/s, speed: 4489.822213 tokens/s, learning rate: 1.564e-05, loss_scalings: 6871.948730, pp_loss: 7.424635
[INFO] 2021-07-12 19:03:10,629 [run_pretraining.py:  512]:	********exe.run_1565******* 
[INFO] 2021-07-12 19:03:11,536 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:11,537 [run_pretraining.py:  534]:	loss/total_loss, 7.455171585083008, 1566
[INFO] 2021-07-12 19:03:11,537 [run_pretraining.py:  535]:	loss/mlm_loss, 7.455171585083008, 1566
[INFO] 2021-07-12 19:03:11,537 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5649999113520607e-05, 1566
[INFO] 2021-07-12 19:03:11,537 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1566
[INFO] 2021-07-12 19:03:11,537 [run_pretraining.py:  558]:	worker_index: 6, step: 1566, cost: 7.455172, mlm loss: 7.455172, speed: 1.102000 steps/s, speed: 8.815996 samples/s, speed: 4513.790203 tokens/s, learning rate: 1.565e-05, loss_scalings: 6871.948730, pp_loss: 7.074152
[INFO] 2021-07-12 19:03:11,537 [run_pretraining.py:  512]:	********exe.run_1566******* 
[INFO] 2021-07-12 19:03:12,439 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:12,440 [run_pretraining.py:  534]:	loss/total_loss, 7.173704147338867, 1567
[INFO] 2021-07-12 19:03:12,440 [run_pretraining.py:  535]:	loss/mlm_loss, 7.173704147338867, 1567
[INFO] 2021-07-12 19:03:12,440 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5659999917261302e-05, 1567
[INFO] 2021-07-12 19:03:12,440 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1567
[INFO] 2021-07-12 19:03:12,440 [run_pretraining.py:  558]:	worker_index: 6, step: 1567, cost: 7.173704, mlm loss: 7.173704, speed: 1.107668 steps/s, speed: 8.861341 samples/s, speed: 4537.006378 tokens/s, learning rate: 1.566e-05, loss_scalings: 6871.948730, pp_loss: 7.076218
[INFO] 2021-07-12 19:03:12,441 [run_pretraining.py:  512]:	********exe.run_1567******* 
[INFO] 2021-07-12 19:03:13,344 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:13,345 [run_pretraining.py:  534]:	loss/total_loss, 7.436856746673584, 1568
[INFO] 2021-07-12 19:03:13,345 [run_pretraining.py:  535]:	loss/mlm_loss, 7.436856746673584, 1568
[INFO] 2021-07-12 19:03:13,345 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5669998902012594e-05, 1568
[INFO] 2021-07-12 19:03:13,345 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1568
[INFO] 2021-07-12 19:03:13,345 [run_pretraining.py:  558]:	worker_index: 6, step: 1568, cost: 7.436857, mlm loss: 7.436857, speed: 1.105895 steps/s, speed: 8.847158 samples/s, speed: 4529.745118 tokens/s, learning rate: 1.567e-05, loss_scalings: 6871.948730, pp_loss: 7.305236
[INFO] 2021-07-12 19:03:13,345 [run_pretraining.py:  512]:	********exe.run_1568******* 
[INFO] 2021-07-12 19:03:14,258 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:14,258 [run_pretraining.py:  534]:	loss/total_loss, 6.962140083312988, 1569
[INFO] 2021-07-12 19:03:14,259 [run_pretraining.py:  535]:	loss/mlm_loss, 6.962140083312988, 1569
[INFO] 2021-07-12 19:03:14,259 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.567999970575329e-05, 1569
[INFO] 2021-07-12 19:03:14,259 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1569
[INFO] 2021-07-12 19:03:14,259 [run_pretraining.py:  558]:	worker_index: 6, step: 1569, cost: 6.962140, mlm loss: 6.962140, speed: 1.095665 steps/s, speed: 8.765317 samples/s, speed: 4487.842422 tokens/s, learning rate: 1.568e-05, loss_scalings: 6871.948730, pp_loss: 7.461299
[INFO] 2021-07-12 19:03:14,259 [run_pretraining.py:  512]:	********exe.run_1569******* 
[INFO] 2021-07-12 19:03:15,160 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:15,161 [run_pretraining.py:  534]:	loss/total_loss, 7.141449451446533, 1570
[INFO] 2021-07-12 19:03:15,161 [run_pretraining.py:  535]:	loss/mlm_loss, 7.141449451446533, 1570
[INFO] 2021-07-12 19:03:15,161 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5690000509493984e-05, 1570
[INFO] 2021-07-12 19:03:15,161 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1570
[INFO] 2021-07-12 19:03:15,161 [run_pretraining.py:  558]:	worker_index: 6, step: 1570, cost: 7.141449, mlm loss: 7.141449, speed: 1.108827 steps/s, speed: 8.870615 samples/s, speed: 4541.754903 tokens/s, learning rate: 1.569e-05, loss_scalings: 6871.948730, pp_loss: 7.420143
[INFO] 2021-07-12 19:03:15,161 [run_pretraining.py:  512]:	********exe.run_1570******* 
[INFO] 2021-07-12 19:03:16,068 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:16,069 [run_pretraining.py:  534]:	loss/total_loss, 7.579103469848633, 1571
[INFO] 2021-07-12 19:03:16,069 [run_pretraining.py:  535]:	loss/mlm_loss, 7.579103469848633, 1571
[INFO] 2021-07-12 19:03:16,069 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5699999494245276e-05, 1571
[INFO] 2021-07-12 19:03:16,069 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1571
[INFO] 2021-07-12 19:03:16,070 [run_pretraining.py:  558]:	worker_index: 6, step: 1571, cost: 7.579103, mlm loss: 7.579103, speed: 1.102035 steps/s, speed: 8.816279 samples/s, speed: 4513.934892 tokens/s, learning rate: 1.570e-05, loss_scalings: 6871.948730, pp_loss: 7.240613
[INFO] 2021-07-12 19:03:16,070 [run_pretraining.py:  512]:	********exe.run_1571******* 
[INFO] 2021-07-12 19:03:16,976 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:16,977 [run_pretraining.py:  534]:	loss/total_loss, 7.336827278137207, 1572
[INFO] 2021-07-12 19:03:16,977 [run_pretraining.py:  535]:	loss/mlm_loss, 7.336827278137207, 1572
[INFO] 2021-07-12 19:03:16,977 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.571000029798597e-05, 1572
[INFO] 2021-07-12 19:03:16,977 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1572
[INFO] 2021-07-12 19:03:16,977 [run_pretraining.py:  558]:	worker_index: 6, step: 1572, cost: 7.336827, mlm loss: 7.336827, speed: 1.102690 steps/s, speed: 8.821517 samples/s, speed: 4516.616882 tokens/s, learning rate: 1.571e-05, loss_scalings: 6871.948730, pp_loss: 7.331724
[INFO] 2021-07-12 19:03:16,977 [run_pretraining.py:  512]:	********exe.run_1572******* 
[INFO] 2021-07-12 19:03:17,902 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:17,903 [run_pretraining.py:  534]:	loss/total_loss, 7.237034320831299, 1573
[INFO] 2021-07-12 19:03:17,903 [run_pretraining.py:  535]:	loss/mlm_loss, 7.237034320831299, 1573
[INFO] 2021-07-12 19:03:17,903 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5719999282737263e-05, 1573
[INFO] 2021-07-12 19:03:17,903 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1573
[INFO] 2021-07-12 19:03:17,903 [run_pretraining.py:  558]:	worker_index: 6, step: 1573, cost: 7.237034, mlm loss: 7.237034, speed: 1.081000 steps/s, speed: 8.647998 samples/s, speed: 4427.775089 tokens/s, learning rate: 1.572e-05, loss_scalings: 6871.948730, pp_loss: 7.435162
[INFO] 2021-07-12 19:03:17,903 [run_pretraining.py:  512]:	********exe.run_1573******* 
[INFO] 2021-07-12 19:03:18,812 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:18,812 [run_pretraining.py:  534]:	loss/total_loss, 7.462407112121582, 1574
[INFO] 2021-07-12 19:03:18,812 [run_pretraining.py:  535]:	loss/mlm_loss, 7.462407112121582, 1574
[INFO] 2021-07-12 19:03:18,812 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5729998267488554e-05, 1574
[INFO] 2021-07-12 19:03:18,812 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1574
[INFO] 2021-07-12 19:03:18,813 [run_pretraining.py:  558]:	worker_index: 6, step: 1574, cost: 7.462407, mlm loss: 7.462407, speed: 1.100165 steps/s, speed: 8.801319 samples/s, speed: 4506.275570 tokens/s, learning rate: 1.573e-05, loss_scalings: 6871.948730, pp_loss: 7.516851
[INFO] 2021-07-12 19:03:18,813 [run_pretraining.py:  512]:	********exe.run_1574******* 
[INFO] 2021-07-12 19:03:19,725 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:19,725 [run_pretraining.py:  534]:	loss/total_loss, 6.8912200927734375, 1575
[INFO] 2021-07-12 19:03:19,726 [run_pretraining.py:  535]:	loss/mlm_loss, 6.8912200927734375, 1575
[INFO] 2021-07-12 19:03:19,726 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.573999907122925e-05, 1575
[INFO] 2021-07-12 19:03:19,726 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1575
[INFO] 2021-07-12 19:03:19,726 [run_pretraining.py:  558]:	worker_index: 6, step: 1575, cost: 6.891220, mlm loss: 6.891220, speed: 1.095834 steps/s, speed: 8.766675 samples/s, speed: 4488.537730 tokens/s, learning rate: 1.574e-05, loss_scalings: 6871.948730, pp_loss: 7.116149
[INFO] 2021-07-12 19:03:19,726 [run_pretraining.py:  512]:	********exe.run_1575******* 
[INFO] 2021-07-12 19:03:20,639 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:20,639 [run_pretraining.py:  534]:	loss/total_loss, 6.920858860015869, 1576
[INFO] 2021-07-12 19:03:20,639 [run_pretraining.py:  535]:	loss/mlm_loss, 6.920858860015869, 1576
[INFO] 2021-07-12 19:03:20,640 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5749999874969944e-05, 1576
[INFO] 2021-07-12 19:03:20,640 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1576
[INFO] 2021-07-12 19:03:20,640 [run_pretraining.py:  558]:	worker_index: 6, step: 1576, cost: 6.920859, mlm loss: 6.920859, speed: 1.095070 steps/s, speed: 8.760559 samples/s, speed: 4485.406440 tokens/s, learning rate: 1.575e-05, loss_scalings: 6871.948730, pp_loss: 7.587166
[INFO] 2021-07-12 19:03:20,640 [run_pretraining.py:  512]:	********exe.run_1576******* 
[INFO] 2021-07-12 19:03:21,553 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:21,553 [run_pretraining.py:  534]:	loss/total_loss, 7.041806697845459, 1577
[INFO] 2021-07-12 19:03:21,553 [run_pretraining.py:  535]:	loss/mlm_loss, 7.041806697845459, 1577
[INFO] 2021-07-12 19:03:21,553 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5759998859721236e-05, 1577
[INFO] 2021-07-12 19:03:21,554 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1577
[INFO] 2021-07-12 19:03:21,554 [run_pretraining.py:  558]:	worker_index: 6, step: 1577, cost: 7.041807, mlm loss: 7.041807, speed: 1.094990 steps/s, speed: 8.759919 samples/s, speed: 4485.078564 tokens/s, learning rate: 1.576e-05, loss_scalings: 6871.948730, pp_loss: 7.406994
[INFO] 2021-07-12 19:03:21,554 [run_pretraining.py:  512]:	********exe.run_1577******* 
[INFO] 2021-07-12 19:03:22,458 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:22,459 [run_pretraining.py:  534]:	loss/total_loss, 6.703736305236816, 1578
[INFO] 2021-07-12 19:03:22,459 [run_pretraining.py:  535]:	loss/mlm_loss, 6.703736305236816, 1578
[INFO] 2021-07-12 19:03:22,459 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.576999966346193e-05, 1578
[INFO] 2021-07-12 19:03:22,459 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1578
[INFO] 2021-07-12 19:03:22,459 [run_pretraining.py:  558]:	worker_index: 6, step: 1578, cost: 6.703736, mlm loss: 6.703736, speed: 1.105070 steps/s, speed: 8.840557 samples/s, speed: 4526.365273 tokens/s, learning rate: 1.577e-05, loss_scalings: 6871.948730, pp_loss: 7.121161
[INFO] 2021-07-12 19:03:22,459 [run_pretraining.py:  512]:	********exe.run_1578******* 
[INFO] 2021-07-12 19:03:47,811 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:47,811 [run_pretraining.py:  534]:	loss/total_loss, 6.977562427520752, 1579
[INFO] 2021-07-12 19:03:47,811 [run_pretraining.py:  535]:	loss/mlm_loss, 6.977562427520752, 1579
[INFO] 2021-07-12 19:03:47,811 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5780000467202626e-05, 1579
[INFO] 2021-07-12 19:03:47,812 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1579
[INFO] 2021-07-12 19:03:47,812 [run_pretraining.py:  558]:	worker_index: 6, step: 1579, cost: 6.977562, mlm loss: 6.977562, speed: 0.039445 steps/s, speed: 0.315562 samples/s, speed: 161.567574 tokens/s, learning rate: 1.578e-05, loss_scalings: 6871.948730, pp_loss: 7.197237
[INFO] 2021-07-12 19:03:47,812 [run_pretraining.py:  512]:	********exe.run_1579******* 
[INFO] 2021-07-12 19:03:48,750 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:48,750 [run_pretraining.py:  534]:	loss/total_loss, 7.5265398025512695, 1580
[INFO] 2021-07-12 19:03:48,750 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5265398025512695, 1580
[INFO] 2021-07-12 19:03:48,750 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5789999451953918e-05, 1580
[INFO] 2021-07-12 19:03:48,751 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1580
[INFO] 2021-07-12 19:03:48,751 [run_pretraining.py:  558]:	worker_index: 6, step: 1580, cost: 7.526540, mlm loss: 7.526540, speed: 1.065726 steps/s, speed: 8.525805 samples/s, speed: 4365.212292 tokens/s, learning rate: 1.579e-05, loss_scalings: 6871.948730, pp_loss: 7.335486
[INFO] 2021-07-12 19:03:48,751 [run_pretraining.py:  512]:	********exe.run_1580******* 
[INFO] 2021-07-12 19:03:49,677 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:49,678 [run_pretraining.py:  534]:	loss/total_loss, 8.29768180847168, 1581
[INFO] 2021-07-12 19:03:49,678 [run_pretraining.py:  535]:	loss/mlm_loss, 8.29768180847168, 1581
[INFO] 2021-07-12 19:03:49,678 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5800000255694613e-05, 1581
[INFO] 2021-07-12 19:03:49,678 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1581
[INFO] 2021-07-12 19:03:49,678 [run_pretraining.py:  558]:	worker_index: 6, step: 1581, cost: 8.297682, mlm loss: 8.297682, speed: 1.078842 steps/s, speed: 8.630735 samples/s, speed: 4418.936130 tokens/s, learning rate: 1.580e-05, loss_scalings: 6871.948730, pp_loss: 7.258649
[INFO] 2021-07-12 19:03:49,678 [run_pretraining.py:  512]:	********exe.run_1581******* 
[INFO] 2021-07-12 19:03:50,626 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:50,627 [run_pretraining.py:  534]:	loss/total_loss, 7.821386337280273, 1582
[INFO] 2021-07-12 19:03:50,627 [run_pretraining.py:  535]:	loss/mlm_loss, 7.821386337280273, 1582
[INFO] 2021-07-12 19:03:50,627 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5809999240445904e-05, 1582
[INFO] 2021-07-12 19:03:50,627 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1582
[INFO] 2021-07-12 19:03:50,627 [run_pretraining.py:  558]:	worker_index: 6, step: 1582, cost: 7.821386, mlm loss: 7.821386, speed: 1.054824 steps/s, speed: 8.438592 samples/s, speed: 4320.559047 tokens/s, learning rate: 1.581e-05, loss_scalings: 6871.948730, pp_loss: 7.482349
[INFO] 2021-07-12 19:03:50,627 [run_pretraining.py:  512]:	********exe.run_1582******* 
[INFO] 2021-07-12 19:03:51,566 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:51,566 [run_pretraining.py:  534]:	loss/total_loss, 7.278873920440674, 1583
[INFO] 2021-07-12 19:03:51,566 [run_pretraining.py:  535]:	loss/mlm_loss, 7.278873920440674, 1583
[INFO] 2021-07-12 19:03:51,567 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.58200000441866e-05, 1583
[INFO] 2021-07-12 19:03:51,567 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1583
[INFO] 2021-07-12 19:03:51,567 [run_pretraining.py:  558]:	worker_index: 6, step: 1583, cost: 7.278874, mlm loss: 7.278874, speed: 1.064982 steps/s, speed: 8.519854 samples/s, speed: 4362.165363 tokens/s, learning rate: 1.582e-05, loss_scalings: 6871.948730, pp_loss: 6.236682
[INFO] 2021-07-12 19:03:51,567 [run_pretraining.py:  512]:	********exe.run_1583******* 
[INFO] 2021-07-12 19:03:52,478 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:52,479 [run_pretraining.py:  534]:	loss/total_loss, 7.132353782653809, 1584
[INFO] 2021-07-12 19:03:52,479 [run_pretraining.py:  535]:	loss/mlm_loss, 7.132353782653809, 1584
[INFO] 2021-07-12 19:03:52,479 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.582999902893789e-05, 1584
[INFO] 2021-07-12 19:03:52,479 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1584
[INFO] 2021-07-12 19:03:52,479 [run_pretraining.py:  558]:	worker_index: 6, step: 1584, cost: 7.132354, mlm loss: 7.132354, speed: 1.096530 steps/s, speed: 8.772240 samples/s, speed: 4491.386872 tokens/s, learning rate: 1.583e-05, loss_scalings: 6871.948730, pp_loss: 6.747282
[INFO] 2021-07-12 19:03:52,480 [run_pretraining.py:  512]:	********exe.run_1584******* 
[INFO] 2021-07-12 19:03:53,402 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:53,403 [run_pretraining.py:  534]:	loss/total_loss, 7.665008068084717, 1585
[INFO] 2021-07-12 19:03:53,403 [run_pretraining.py:  535]:	loss/mlm_loss, 7.665008068084717, 1585
[INFO] 2021-07-12 19:03:53,403 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5839999832678586e-05, 1585
[INFO] 2021-07-12 19:03:53,403 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1585
[INFO] 2021-07-12 19:03:53,403 [run_pretraining.py:  558]:	worker_index: 6, step: 1585, cost: 7.665008, mlm loss: 7.665008, speed: 1.083117 steps/s, speed: 8.664939 samples/s, speed: 4436.448981 tokens/s, learning rate: 1.584e-05, loss_scalings: 6871.948730, pp_loss: 7.172743
[INFO] 2021-07-12 19:03:53,404 [run_pretraining.py:  512]:	********exe.run_1585******* 
[INFO] 2021-07-12 19:03:54,369 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:54,369 [run_pretraining.py:  534]:	loss/total_loss, 7.0411810874938965, 1586
[INFO] 2021-07-12 19:03:54,369 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0411810874938965, 1586
[INFO] 2021-07-12 19:03:54,369 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5849998817429878e-05, 1586
[INFO] 2021-07-12 19:03:54,369 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1586
[INFO] 2021-07-12 19:03:54,370 [run_pretraining.py:  558]:	worker_index: 6, step: 1586, cost: 7.041181, mlm loss: 7.041181, speed: 1.035846 steps/s, speed: 8.286772 samples/s, speed: 4242.827193 tokens/s, learning rate: 1.585e-05, loss_scalings: 6871.948730, pp_loss: 6.960036
[INFO] 2021-07-12 19:03:54,370 [run_pretraining.py:  512]:	********exe.run_1586******* 
[INFO] 2021-07-12 19:03:55,298 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:55,299 [run_pretraining.py:  534]:	loss/total_loss, 6.808148384094238, 1587
[INFO] 2021-07-12 19:03:55,299 [run_pretraining.py:  535]:	loss/mlm_loss, 6.808148384094238, 1587
[INFO] 2021-07-12 19:03:55,299 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5859999621170573e-05, 1587
[INFO] 2021-07-12 19:03:55,299 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1587
[INFO] 2021-07-12 19:03:55,299 [run_pretraining.py:  558]:	worker_index: 6, step: 1587, cost: 6.808148, mlm loss: 6.808148, speed: 1.076194 steps/s, speed: 8.609548 samples/s, speed: 4408.088772 tokens/s, learning rate: 1.586e-05, loss_scalings: 6871.948730, pp_loss: 7.070860
[INFO] 2021-07-12 19:03:55,300 [run_pretraining.py:  512]:	********exe.run_1587******* 
[INFO] 2021-07-12 19:03:56,202 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:56,203 [run_pretraining.py:  534]:	loss/total_loss, 7.090793609619141, 1588
[INFO] 2021-07-12 19:03:56,203 [run_pretraining.py:  535]:	loss/mlm_loss, 7.090793609619141, 1588
[INFO] 2021-07-12 19:03:56,203 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5870000424911268e-05, 1588
[INFO] 2021-07-12 19:03:56,203 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1588
[INFO] 2021-07-12 19:03:56,203 [run_pretraining.py:  558]:	worker_index: 6, step: 1588, cost: 7.090794, mlm loss: 7.090794, speed: 1.107449 steps/s, speed: 8.859595 samples/s, speed: 4536.112718 tokens/s, learning rate: 1.587e-05, loss_scalings: 6871.948730, pp_loss: 6.446994
[INFO] 2021-07-12 19:03:56,203 [run_pretraining.py:  512]:	********exe.run_1588******* 
[INFO] 2021-07-12 19:03:57,159 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:57,159 [run_pretraining.py:  534]:	loss/total_loss, 7.394803524017334, 1589
[INFO] 2021-07-12 19:03:57,159 [run_pretraining.py:  535]:	loss/mlm_loss, 7.394803524017334, 1589
[INFO] 2021-07-12 19:03:57,159 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.587999940966256e-05, 1589
[INFO] 2021-07-12 19:03:57,160 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1589
[INFO] 2021-07-12 19:03:57,160 [run_pretraining.py:  558]:	worker_index: 6, step: 1589, cost: 7.394804, mlm loss: 7.394804, speed: 1.046348 steps/s, speed: 8.370782 samples/s, speed: 4285.840598 tokens/s, learning rate: 1.588e-05, loss_scalings: 6871.948730, pp_loss: 7.502235
[INFO] 2021-07-12 19:03:57,160 [run_pretraining.py:  512]:	********exe.run_1589******* 
[INFO] 2021-07-12 19:03:58,070 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:58,070 [run_pretraining.py:  534]:	loss/total_loss, 6.954503059387207, 1590
[INFO] 2021-07-12 19:03:58,070 [run_pretraining.py:  535]:	loss/mlm_loss, 6.954503059387207, 1590
[INFO] 2021-07-12 19:03:58,070 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.588999839441385e-05, 1590
[INFO] 2021-07-12 19:03:58,071 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1590
[INFO] 2021-07-12 19:03:58,071 [run_pretraining.py:  558]:	worker_index: 6, step: 1590, cost: 6.954503, mlm loss: 6.954503, speed: 1.098456 steps/s, speed: 8.787649 samples/s, speed: 4499.276047 tokens/s, learning rate: 1.589e-05, loss_scalings: 6871.948730, pp_loss: 7.825974
[INFO] 2021-07-12 19:03:58,071 [run_pretraining.py:  512]:	********exe.run_1590******* 
[INFO] 2021-07-12 19:03:58,987 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:58,988 [run_pretraining.py:  534]:	loss/total_loss, 6.836929798126221, 1591
[INFO] 2021-07-12 19:03:58,988 [run_pretraining.py:  535]:	loss/mlm_loss, 6.836929798126221, 1591
[INFO] 2021-07-12 19:03:58,988 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5899999198154546e-05, 1591
[INFO] 2021-07-12 19:03:58,988 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1591
[INFO] 2021-07-12 19:03:58,988 [run_pretraining.py:  558]:	worker_index: 6, step: 1591, cost: 6.836930, mlm loss: 6.836930, speed: 1.090702 steps/s, speed: 8.725615 samples/s, speed: 4467.515011 tokens/s, learning rate: 1.590e-05, loss_scalings: 6871.948730, pp_loss: 6.991258
[INFO] 2021-07-12 19:03:58,988 [run_pretraining.py:  512]:	********exe.run_1591******* 
[INFO] 2021-07-12 19:03:59,902 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:59,902 [run_pretraining.py:  534]:	loss/total_loss, 7.462889671325684, 1592
[INFO] 2021-07-12 19:03:59,902 [run_pretraining.py:  535]:	loss/mlm_loss, 7.462889671325684, 1592
[INFO] 2021-07-12 19:03:59,902 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.591000000189524e-05, 1592
[INFO] 2021-07-12 19:03:59,902 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1592
[INFO] 2021-07-12 19:03:59,903 [run_pretraining.py:  558]:	worker_index: 6, step: 1592, cost: 7.462890, mlm loss: 7.462890, speed: 1.094557 steps/s, speed: 8.756458 samples/s, speed: 4483.306520 tokens/s, learning rate: 1.591e-05, loss_scalings: 6871.948730, pp_loss: 7.366984
[INFO] 2021-07-12 19:03:59,903 [run_pretraining.py:  512]:	********exe.run_1592******* 
[INFO] 2021-07-12 19:04:00,816 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:00,816 [run_pretraining.py:  534]:	loss/total_loss, 7.270418643951416, 1593
[INFO] 2021-07-12 19:04:00,816 [run_pretraining.py:  535]:	loss/mlm_loss, 7.270418643951416, 1593
[INFO] 2021-07-12 19:04:00,817 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5919998986646533e-05, 1593
[INFO] 2021-07-12 19:04:00,817 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1593
[INFO] 2021-07-12 19:04:00,817 [run_pretraining.py:  558]:	worker_index: 6, step: 1593, cost: 7.270419, mlm loss: 7.270419, speed: 1.094718 steps/s, speed: 8.757747 samples/s, speed: 4483.966483 tokens/s, learning rate: 1.592e-05, loss_scalings: 6871.948730, pp_loss: 7.287390
[INFO] 2021-07-12 19:04:00,817 [run_pretraining.py:  512]:	********exe.run_1593******* 
[INFO] 2021-07-12 19:04:01,720 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:01,721 [run_pretraining.py:  534]:	loss/total_loss, 6.769445419311523, 1594
[INFO] 2021-07-12 19:04:01,721 [run_pretraining.py:  535]:	loss/mlm_loss, 6.769445419311523, 1594
[INFO] 2021-07-12 19:04:01,721 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5929999790387228e-05, 1594
[INFO] 2021-07-12 19:04:01,721 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1594
[INFO] 2021-07-12 19:04:01,721 [run_pretraining.py:  558]:	worker_index: 6, step: 1594, cost: 6.769445, mlm loss: 6.769445, speed: 1.106151 steps/s, speed: 8.849207 samples/s, speed: 4530.793991 tokens/s, learning rate: 1.593e-05, loss_scalings: 6871.948730, pp_loss: 6.862002
[INFO] 2021-07-12 19:04:01,722 [run_pretraining.py:  512]:	********exe.run_1594******* 
[INFO] 2021-07-12 19:04:02,641 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:02,642 [run_pretraining.py:  534]:	loss/total_loss, 7.17278528213501, 1595
[INFO] 2021-07-12 19:04:02,642 [run_pretraining.py:  535]:	loss/mlm_loss, 7.17278528213501, 1595
[INFO] 2021-07-12 19:04:02,642 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5940000594127923e-05, 1595
[INFO] 2021-07-12 19:04:02,642 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1595
[INFO] 2021-07-12 19:04:02,642 [run_pretraining.py:  558]:	worker_index: 6, step: 1595, cost: 7.172785, mlm loss: 7.172785, speed: 1.087022 steps/s, speed: 8.696179 samples/s, speed: 4452.443546 tokens/s, learning rate: 1.594e-05, loss_scalings: 6871.948730, pp_loss: 7.316007
[INFO] 2021-07-12 19:04:02,642 [run_pretraining.py:  512]:	********exe.run_1595******* 
[INFO] 2021-07-12 19:04:03,537 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:03,538 [run_pretraining.py:  534]:	loss/total_loss, 7.524350643157959, 1596
[INFO] 2021-07-12 19:04:03,538 [run_pretraining.py:  535]:	loss/mlm_loss, 7.524350643157959, 1596
[INFO] 2021-07-12 19:04:03,538 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5949999578879215e-05, 1596
[INFO] 2021-07-12 19:04:03,538 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1596
[INFO] 2021-07-12 19:04:03,538 [run_pretraining.py:  558]:	worker_index: 6, step: 1596, cost: 7.524351, mlm loss: 7.524351, speed: 1.116883 steps/s, speed: 8.935063 samples/s, speed: 4574.752284 tokens/s, learning rate: 1.595e-05, loss_scalings: 6871.948730, pp_loss: 7.416103
[INFO] 2021-07-12 19:04:03,538 [run_pretraining.py:  512]:	********exe.run_1596******* 
[INFO] 2021-07-12 19:04:04,445 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:04,446 [run_pretraining.py:  534]:	loss/total_loss, 7.5226545333862305, 1597
[INFO] 2021-07-12 19:04:04,446 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5226545333862305, 1597
[INFO] 2021-07-12 19:04:04,446 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.596000038261991e-05, 1597
[INFO] 2021-07-12 19:04:04,446 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1597
[INFO] 2021-07-12 19:04:04,446 [run_pretraining.py:  558]:	worker_index: 6, step: 1597, cost: 7.522655, mlm loss: 7.522655, speed: 1.102139 steps/s, speed: 8.817115 samples/s, speed: 4514.363085 tokens/s, learning rate: 1.596e-05, loss_scalings: 6871.948730, pp_loss: 7.399849
[INFO] 2021-07-12 19:04:04,446 [run_pretraining.py:  512]:	********exe.run_1597******* 
[INFO] 2021-07-12 19:04:05,358 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:05,358 [run_pretraining.py:  534]:	loss/total_loss, 7.172272682189941, 1598
[INFO] 2021-07-12 19:04:05,358 [run_pretraining.py:  535]:	loss/mlm_loss, 7.172272682189941, 1598
[INFO] 2021-07-12 19:04:05,359 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.59699993673712e-05, 1598
[INFO] 2021-07-12 19:04:05,359 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1598
[INFO] 2021-07-12 19:04:05,359 [run_pretraining.py:  558]:	worker_index: 6, step: 1598, cost: 7.172273, mlm loss: 7.172273, speed: 1.096705 steps/s, speed: 8.773644 samples/s, speed: 4492.105596 tokens/s, learning rate: 1.597e-05, loss_scalings: 6871.948730, pp_loss: 7.175722
[INFO] 2021-07-12 19:04:05,359 [run_pretraining.py:  512]:	********exe.run_1598******* 
[INFO] 2021-07-12 19:04:06,274 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:06,275 [run_pretraining.py:  534]:	loss/total_loss, 7.794618606567383, 1599
[INFO] 2021-07-12 19:04:06,275 [run_pretraining.py:  535]:	loss/mlm_loss, 7.794618606567383, 1599
[INFO] 2021-07-12 19:04:06,275 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5979998352122493e-05, 1599
[INFO] 2021-07-12 19:04:06,275 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1599
[INFO] 2021-07-12 19:04:06,275 [run_pretraining.py:  558]:	worker_index: 6, step: 1599, cost: 7.794619, mlm loss: 7.794619, speed: 1.091699 steps/s, speed: 8.733589 samples/s, speed: 4471.597639 tokens/s, learning rate: 1.598e-05, loss_scalings: 6871.948730, pp_loss: 6.812667
[INFO] 2021-07-12 19:04:06,276 [run_pretraining.py:  512]:	********exe.run_1599******* 
[INFO] 2021-07-12 19:04:07,186 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:07,187 [run_pretraining.py:  534]:	loss/total_loss, 7.4900970458984375, 1600
[INFO] 2021-07-12 19:04:07,187 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4900970458984375, 1600
[INFO] 2021-07-12 19:04:07,187 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5989999155863188e-05, 1600
[INFO] 2021-07-12 19:04:07,187 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1600
[INFO] 2021-07-12 19:04:07,187 [run_pretraining.py:  558]:	worker_index: 6, step: 1600, cost: 7.490097, mlm loss: 7.490097, speed: 1.097638 steps/s, speed: 8.781104 samples/s, speed: 4495.925029 tokens/s, learning rate: 1.599e-05, loss_scalings: 6871.948730, pp_loss: 7.090803
[INFO] 2021-07-12 19:04:07,187 [run_pretraining.py:  512]:	********exe.run_1600******* 
[INFO] 2021-07-12 19:04:08,101 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:08,102 [run_pretraining.py:  534]:	loss/total_loss, 6.966726303100586, 1601
[INFO] 2021-07-12 19:04:08,102 [run_pretraining.py:  535]:	loss/mlm_loss, 6.966726303100586, 1601
[INFO] 2021-07-12 19:04:08,102 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5999999959603883e-05, 1601
[INFO] 2021-07-12 19:04:08,102 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1601
[INFO] 2021-07-12 19:04:08,102 [run_pretraining.py:  558]:	worker_index: 6, step: 1601, cost: 6.966726, mlm loss: 6.966726, speed: 1.094120 steps/s, speed: 8.752961 samples/s, speed: 4481.516001 tokens/s, learning rate: 1.600e-05, loss_scalings: 6871.948730, pp_loss: 6.929304
[INFO] 2021-07-12 19:04:08,102 [run_pretraining.py:  512]:	********exe.run_1601******* 
[INFO] 2021-07-12 19:04:09,090 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:09,091 [run_pretraining.py:  534]:	loss/total_loss, 6.886809349060059, 1602
[INFO] 2021-07-12 19:04:09,091 [run_pretraining.py:  535]:	loss/mlm_loss, 6.886809349060059, 1602
[INFO] 2021-07-12 19:04:09,091 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6009998944355175e-05, 1602
[INFO] 2021-07-12 19:04:09,091 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1602
[INFO] 2021-07-12 19:04:09,091 [run_pretraining.py:  558]:	worker_index: 6, step: 1602, cost: 6.886809, mlm loss: 6.886809, speed: 1.011463 steps/s, speed: 8.091707 samples/s, speed: 4142.954027 tokens/s, learning rate: 1.601e-05, loss_scalings: 6871.948730, pp_loss: 6.864542
[INFO] 2021-07-12 19:04:09,091 [run_pretraining.py:  512]:	********exe.run_1602******* 
[INFO] 2021-07-12 19:04:10,150 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:10,150 [run_pretraining.py:  534]:	loss/total_loss, 7.182366371154785, 1603
[INFO] 2021-07-12 19:04:10,151 [run_pretraining.py:  535]:	loss/mlm_loss, 7.182366371154785, 1603
[INFO] 2021-07-12 19:04:10,151 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.601999974809587e-05, 1603
[INFO] 2021-07-12 19:04:10,151 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1603
[INFO] 2021-07-12 19:04:10,151 [run_pretraining.py:  558]:	worker_index: 6, step: 1603, cost: 7.182366, mlm loss: 7.182366, speed: 0.944370 steps/s, speed: 7.554960 samples/s, speed: 3868.139389 tokens/s, learning rate: 1.602e-05, loss_scalings: 6871.948730, pp_loss: 7.237208
[INFO] 2021-07-12 19:04:10,151 [run_pretraining.py:  512]:	********exe.run_1603******* 
[INFO] 2021-07-12 19:04:11,228 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:11,228 [run_pretraining.py:  534]:	loss/total_loss, 7.490262985229492, 1604
[INFO] 2021-07-12 19:04:11,228 [run_pretraining.py:  535]:	loss/mlm_loss, 7.490262985229492, 1604
[INFO] 2021-07-12 19:04:11,229 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6030000551836565e-05, 1604
[INFO] 2021-07-12 19:04:11,229 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1604
[INFO] 2021-07-12 19:04:11,229 [run_pretraining.py:  558]:	worker_index: 6, step: 1604, cost: 7.490263, mlm loss: 7.490263, speed: 0.928384 steps/s, speed: 7.427068 samples/s, speed: 3802.658912 tokens/s, learning rate: 1.603e-05, loss_scalings: 6871.948730, pp_loss: 7.333201
[INFO] 2021-07-12 19:04:11,229 [run_pretraining.py:  512]:	********exe.run_1604******* 
[INFO] 2021-07-12 19:04:12,292 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:12,292 [run_pretraining.py:  534]:	loss/total_loss, 7.713994026184082, 1605
[INFO] 2021-07-12 19:04:12,292 [run_pretraining.py:  535]:	loss/mlm_loss, 7.713994026184082, 1605
[INFO] 2021-07-12 19:04:12,292 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6039999536587857e-05, 1605
[INFO] 2021-07-12 19:04:12,292 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1605
[INFO] 2021-07-12 19:04:12,293 [run_pretraining.py:  558]:	worker_index: 6, step: 1605, cost: 7.713994, mlm loss: 7.713994, speed: 0.940642 steps/s, speed: 7.525140 samples/s, speed: 3852.871484 tokens/s, learning rate: 1.604e-05, loss_scalings: 6871.948730, pp_loss: 7.474545
[INFO] 2021-07-12 19:04:12,293 [run_pretraining.py:  512]:	********exe.run_1605******* 
[INFO] 2021-07-12 19:04:13,353 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:13,353 [run_pretraining.py:  534]:	loss/total_loss, 6.7309417724609375, 1606
[INFO] 2021-07-12 19:04:13,353 [run_pretraining.py:  535]:	loss/mlm_loss, 6.7309417724609375, 1606
[INFO] 2021-07-12 19:04:13,353 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6050000340328552e-05, 1606
[INFO] 2021-07-12 19:04:13,354 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1606
[INFO] 2021-07-12 19:04:13,354 [run_pretraining.py:  558]:	worker_index: 6, step: 1606, cost: 6.730942, mlm loss: 6.730942, speed: 0.943097 steps/s, speed: 7.544779 samples/s, speed: 3862.926926 tokens/s, learning rate: 1.605e-05, loss_scalings: 6871.948730, pp_loss: 7.230874
[INFO] 2021-07-12 19:04:13,354 [run_pretraining.py:  512]:	********exe.run_1606******* 
[INFO] 2021-07-12 19:04:14,416 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:14,416 [run_pretraining.py:  534]:	loss/total_loss, 7.297840595245361, 1607
[INFO] 2021-07-12 19:04:14,416 [run_pretraining.py:  535]:	loss/mlm_loss, 7.297840595245361, 1607
[INFO] 2021-07-12 19:04:14,416 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6060001144069247e-05, 1607
[INFO] 2021-07-12 19:04:14,417 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1607
[INFO] 2021-07-12 19:04:14,417 [run_pretraining.py:  558]:	worker_index: 6, step: 1607, cost: 7.297841, mlm loss: 7.297841, speed: 0.941356 steps/s, speed: 7.530846 samples/s, speed: 3855.793393 tokens/s, learning rate: 1.606e-05, loss_scalings: 6871.948730, pp_loss: 7.404163
[INFO] 2021-07-12 19:04:14,417 [run_pretraining.py:  512]:	********exe.run_1607******* 
[INFO] 2021-07-12 19:04:15,487 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:15,488 [run_pretraining.py:  534]:	loss/total_loss, 7.330617904663086, 1608
[INFO] 2021-07-12 19:04:15,488 [run_pretraining.py:  535]:	loss/mlm_loss, 7.330617904663086, 1608
[INFO] 2021-07-12 19:04:15,488 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6069998309831135e-05, 1608
[INFO] 2021-07-12 19:04:15,488 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1608
[INFO] 2021-07-12 19:04:15,488 [run_pretraining.py:  558]:	worker_index: 6, step: 1608, cost: 7.330618, mlm loss: 7.330618, speed: 0.933588 steps/s, speed: 7.468703 samples/s, speed: 3823.975840 tokens/s, learning rate: 1.607e-05, loss_scalings: 6871.948730, pp_loss: 7.122924
[INFO] 2021-07-12 19:04:15,489 [run_pretraining.py:  512]:	********exe.run_1608******* 
[INFO] 2021-07-12 19:04:16,557 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:16,558 [run_pretraining.py:  534]:	loss/total_loss, 6.992367267608643, 1609
[INFO] 2021-07-12 19:04:16,558 [run_pretraining.py:  535]:	loss/mlm_loss, 6.992367267608643, 1609
[INFO] 2021-07-12 19:04:16,558 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.607999911357183e-05, 1609
[INFO] 2021-07-12 19:04:16,558 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1609
[INFO] 2021-07-12 19:04:16,558 [run_pretraining.py:  558]:	worker_index: 6, step: 1609, cost: 6.992367, mlm loss: 6.992367, speed: 0.935314 steps/s, speed: 7.482511 samples/s, speed: 3831.045842 tokens/s, learning rate: 1.608e-05, loss_scalings: 6871.948730, pp_loss: 7.006453
[INFO] 2021-07-12 19:04:16,558 [run_pretraining.py:  512]:	********exe.run_1609******* 
[INFO] 2021-07-12 19:04:17,708 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:17,709 [run_pretraining.py:  534]:	loss/total_loss, 7.083231449127197, 1610
[INFO] 2021-07-12 19:04:17,709 [run_pretraining.py:  535]:	loss/mlm_loss, 7.083231449127197, 1610
[INFO] 2021-07-12 19:04:17,709 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6089999917312525e-05, 1610
[INFO] 2021-07-12 19:04:17,709 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1610
[INFO] 2021-07-12 19:04:17,709 [run_pretraining.py:  558]:	worker_index: 6, step: 1610, cost: 7.083231, mlm loss: 7.083231, speed: 0.869277 steps/s, speed: 6.954219 samples/s, speed: 3560.559966 tokens/s, learning rate: 1.609e-05, loss_scalings: 6871.948730, pp_loss: 7.345301
[INFO] 2021-07-12 19:04:17,709 [run_pretraining.py:  512]:	********exe.run_1610******* 
[INFO] 2021-07-12 19:04:18,820 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:18,821 [run_pretraining.py:  534]:	loss/total_loss, 7.487785339355469, 1611
[INFO] 2021-07-12 19:04:18,821 [run_pretraining.py:  535]:	loss/mlm_loss, 7.487785339355469, 1611
[INFO] 2021-07-12 19:04:18,821 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6099998902063817e-05, 1611
[INFO] 2021-07-12 19:04:18,821 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1611
[INFO] 2021-07-12 19:04:18,821 [run_pretraining.py:  558]:	worker_index: 6, step: 1611, cost: 7.487785, mlm loss: 7.487785, speed: 0.899975 steps/s, speed: 7.199800 samples/s, speed: 3686.297786 tokens/s, learning rate: 1.610e-05, loss_scalings: 6871.948730, pp_loss: 7.210703
[INFO] 2021-07-12 19:04:18,821 [run_pretraining.py:  512]:	********exe.run_1611******* 
[INFO] 2021-07-12 19:04:19,917 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:19,918 [run_pretraining.py:  534]:	loss/total_loss, 7.826474189758301, 1612
[INFO] 2021-07-12 19:04:19,918 [run_pretraining.py:  535]:	loss/mlm_loss, 7.826474189758301, 1612
[INFO] 2021-07-12 19:04:19,918 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6109999705804512e-05, 1612
[INFO] 2021-07-12 19:04:19,918 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1612
[INFO] 2021-07-12 19:04:19,918 [run_pretraining.py:  558]:	worker_index: 6, step: 1612, cost: 7.826474, mlm loss: 7.826474, speed: 0.912366 steps/s, speed: 7.298926 samples/s, speed: 3737.050019 tokens/s, learning rate: 1.611e-05, loss_scalings: 6871.948730, pp_loss: 7.371310
[INFO] 2021-07-12 19:04:19,918 [run_pretraining.py:  512]:	********exe.run_1612******* 
[INFO] 2021-07-12 19:04:21,015 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:21,015 [run_pretraining.py:  534]:	loss/total_loss, 6.858199596405029, 1613
[INFO] 2021-07-12 19:04:21,015 [run_pretraining.py:  535]:	loss/mlm_loss, 6.858199596405029, 1613
[INFO] 2021-07-12 19:04:21,015 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6120000509545207e-05, 1613
[INFO] 2021-07-12 19:04:21,016 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1613
[INFO] 2021-07-12 19:04:21,016 [run_pretraining.py:  558]:	worker_index: 6, step: 1613, cost: 6.858200, mlm loss: 6.858200, speed: 0.911633 steps/s, speed: 7.293062 samples/s, speed: 3734.047948 tokens/s, learning rate: 1.612e-05, loss_scalings: 6871.948730, pp_loss: 7.268141
[INFO] 2021-07-12 19:04:21,016 [run_pretraining.py:  512]:	********exe.run_1613******* 
[INFO] 2021-07-12 19:04:22,112 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:22,113 [run_pretraining.py:  534]:	loss/total_loss, 6.833565711975098, 1614
[INFO] 2021-07-12 19:04:22,113 [run_pretraining.py:  535]:	loss/mlm_loss, 6.833565711975098, 1614
[INFO] 2021-07-12 19:04:22,113 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.61299994942965e-05, 1614
[INFO] 2021-07-12 19:04:22,113 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1614
[INFO] 2021-07-12 19:04:22,113 [run_pretraining.py:  558]:	worker_index: 6, step: 1614, cost: 6.833566, mlm loss: 6.833566, speed: 0.911537 steps/s, speed: 7.292292 samples/s, speed: 3733.653554 tokens/s, learning rate: 1.613e-05, loss_scalings: 6871.948730, pp_loss: 6.850335
[INFO] 2021-07-12 19:04:22,114 [run_pretraining.py:  512]:	********exe.run_1614******* 
[INFO] 2021-07-12 19:04:23,200 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:23,201 [run_pretraining.py:  534]:	loss/total_loss, 6.823454856872559, 1615
[INFO] 2021-07-12 19:04:23,201 [run_pretraining.py:  535]:	loss/mlm_loss, 6.823454856872559, 1615
[INFO] 2021-07-12 19:04:23,201 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6140000298037194e-05, 1615
[INFO] 2021-07-12 19:04:23,201 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1615
[INFO] 2021-07-12 19:04:23,201 [run_pretraining.py:  558]:	worker_index: 6, step: 1615, cost: 6.823455, mlm loss: 6.823455, speed: 0.919731 steps/s, speed: 7.357850 samples/s, speed: 3767.219412 tokens/s, learning rate: 1.614e-05, loss_scalings: 6871.948730, pp_loss: 7.290627
[INFO] 2021-07-12 19:04:23,202 [run_pretraining.py:  512]:	********exe.run_1615******* 
[INFO] 2021-07-12 19:04:24,300 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:24,300 [run_pretraining.py:  534]:	loss/total_loss, 7.554365634918213, 1616
[INFO] 2021-07-12 19:04:24,300 [run_pretraining.py:  535]:	loss/mlm_loss, 7.554365634918213, 1616
[INFO] 2021-07-12 19:04:24,300 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.615000110177789e-05, 1616
[INFO] 2021-07-12 19:04:24,300 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1616
[INFO] 2021-07-12 19:04:24,300 [run_pretraining.py:  558]:	worker_index: 6, step: 1616, cost: 7.554366, mlm loss: 7.554366, speed: 0.910452 steps/s, speed: 7.283613 samples/s, speed: 3729.209808 tokens/s, learning rate: 1.615e-05, loss_scalings: 6871.948730, pp_loss: 7.358690
[INFO] 2021-07-12 19:04:24,301 [run_pretraining.py:  512]:	********exe.run_1616******* 
[INFO] 2021-07-12 19:04:25,400 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:25,400 [run_pretraining.py:  534]:	loss/total_loss, 7.0850934982299805, 1617
[INFO] 2021-07-12 19:04:25,400 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0850934982299805, 1617
[INFO] 2021-07-12 19:04:25,400 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6159998267539777e-05, 1617
[INFO] 2021-07-12 19:04:25,400 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1617
[INFO] 2021-07-12 19:04:25,401 [run_pretraining.py:  558]:	worker_index: 6, step: 1617, cost: 7.085093, mlm loss: 7.085093, speed: 0.909596 steps/s, speed: 7.276770 samples/s, speed: 3725.706374 tokens/s, learning rate: 1.616e-05, loss_scalings: 6871.948730, pp_loss: 7.455160
[INFO] 2021-07-12 19:04:25,401 [run_pretraining.py:  512]:	********exe.run_1617******* 
[INFO] 2021-07-12 19:04:26,447 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:26,448 [run_pretraining.py:  534]:	loss/total_loss, 7.491364479064941, 1618
[INFO] 2021-07-12 19:04:26,448 [run_pretraining.py:  535]:	loss/mlm_loss, 7.491364479064941, 1618
[INFO] 2021-07-12 19:04:26,448 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6169999071280472e-05, 1618
[INFO] 2021-07-12 19:04:26,448 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1618
[INFO] 2021-07-12 19:04:26,448 [run_pretraining.py:  558]:	worker_index: 6, step: 1618, cost: 7.491364, mlm loss: 7.491364, speed: 0.955197 steps/s, speed: 7.641577 samples/s, speed: 3912.487417 tokens/s, learning rate: 1.617e-05, loss_scalings: 6871.948730, pp_loss: 7.345281
[INFO] 2021-07-12 19:04:26,448 [run_pretraining.py:  512]:	********exe.run_1618******* 
[INFO] 2021-07-12 19:04:27,359 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:27,359 [run_pretraining.py:  534]:	loss/total_loss, 2.81695818901062, 1619
[INFO] 2021-07-12 19:04:27,360 [run_pretraining.py:  535]:	loss/mlm_loss, 2.81695818901062, 1619
[INFO] 2021-07-12 19:04:27,360 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6179999875021167e-05, 1619
[INFO] 2021-07-12 19:04:27,360 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1619
[INFO] 2021-07-12 19:04:27,360 [run_pretraining.py:  558]:	worker_index: 6, step: 1619, cost: 2.816958, mlm loss: 2.816958, speed: 1.097777 steps/s, speed: 8.782214 samples/s, speed: 4496.493385 tokens/s, learning rate: 1.618e-05, loss_scalings: 6871.948730, pp_loss: 5.962553
[INFO] 2021-07-12 19:04:27,360 [run_pretraining.py:  512]:	********exe.run_1619******* 
[INFO] 2021-07-12 19:04:28,271 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:28,271 [run_pretraining.py:  534]:	loss/total_loss, 7.414493560791016, 1620
[INFO] 2021-07-12 19:04:28,272 [run_pretraining.py:  535]:	loss/mlm_loss, 7.414493560791016, 1620
[INFO] 2021-07-12 19:04:28,272 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.618999885977246e-05, 1620
[INFO] 2021-07-12 19:04:28,272 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1620
[INFO] 2021-07-12 19:04:28,272 [run_pretraining.py:  558]:	worker_index: 6, step: 1620, cost: 7.414494, mlm loss: 7.414494, speed: 1.097398 steps/s, speed: 8.779185 samples/s, speed: 4494.942807 tokens/s, learning rate: 1.619e-05, loss_scalings: 6871.948730, pp_loss: 7.158886
[INFO] 2021-07-12 19:04:28,272 [run_pretraining.py:  512]:	********exe.run_1620******* 
[INFO] 2021-07-12 19:04:29,184 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:29,184 [run_pretraining.py:  534]:	loss/total_loss, 5.67138147354126, 1621
[INFO] 2021-07-12 19:04:29,185 [run_pretraining.py:  535]:	loss/mlm_loss, 5.67138147354126, 1621
[INFO] 2021-07-12 19:04:29,185 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6199999663513154e-05, 1621
[INFO] 2021-07-12 19:04:29,185 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1621
[INFO] 2021-07-12 19:04:29,185 [run_pretraining.py:  558]:	worker_index: 6, step: 1621, cost: 5.671381, mlm loss: 5.671381, speed: 1.096188 steps/s, speed: 8.769503 samples/s, speed: 4489.985318 tokens/s, learning rate: 1.620e-05, loss_scalings: 6871.948730, pp_loss: 6.756780
[INFO] 2021-07-12 19:04:29,185 [run_pretraining.py:  512]:	********exe.run_1621******* 
[INFO] 2021-07-12 19:04:30,101 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:30,102 [run_pretraining.py:  534]:	loss/total_loss, 7.3683366775512695, 1622
[INFO] 2021-07-12 19:04:30,102 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3683366775512695, 1622
[INFO] 2021-07-12 19:04:30,102 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.621000046725385e-05, 1622
[INFO] 2021-07-12 19:04:30,102 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1622
[INFO] 2021-07-12 19:04:30,102 [run_pretraining.py:  558]:	worker_index: 6, step: 1622, cost: 7.368337, mlm loss: 7.368337, speed: 1.091223 steps/s, speed: 8.729781 samples/s, speed: 4469.647838 tokens/s, learning rate: 1.621e-05, loss_scalings: 6871.948730, pp_loss: 7.278420
[INFO] 2021-07-12 19:04:30,102 [run_pretraining.py:  512]:	********exe.run_1622******* 
[INFO] 2021-07-12 19:04:31,009 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:31,009 [run_pretraining.py:  534]:	loss/total_loss, 8.349571228027344, 1623
[INFO] 2021-07-12 19:04:31,009 [run_pretraining.py:  535]:	loss/mlm_loss, 8.349571228027344, 1623
[INFO] 2021-07-12 19:04:31,009 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.621999945200514e-05, 1623
[INFO] 2021-07-12 19:04:31,009 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1623
[INFO] 2021-07-12 19:04:31,010 [run_pretraining.py:  558]:	worker_index: 6, step: 1623, cost: 8.349571, mlm loss: 8.349571, speed: 1.102624 steps/s, speed: 8.820993 samples/s, speed: 4516.348540 tokens/s, learning rate: 1.622e-05, loss_scalings: 6871.948730, pp_loss: 7.262192
[INFO] 2021-07-12 19:04:31,010 [run_pretraining.py:  512]:	********exe.run_1623******* 
[INFO] 2021-07-12 19:04:31,917 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:31,917 [run_pretraining.py:  534]:	loss/total_loss, 7.666189670562744, 1624
[INFO] 2021-07-12 19:04:31,918 [run_pretraining.py:  535]:	loss/mlm_loss, 7.666189670562744, 1624
[INFO] 2021-07-12 19:04:31,918 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6230000255745836e-05, 1624
[INFO] 2021-07-12 19:04:31,918 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1624
[INFO] 2021-07-12 19:04:31,918 [run_pretraining.py:  558]:	worker_index: 6, step: 1624, cost: 7.666190, mlm loss: 7.666190, speed: 1.101888 steps/s, speed: 8.815105 samples/s, speed: 4513.333662 tokens/s, learning rate: 1.623e-05, loss_scalings: 6871.948730, pp_loss: 7.414804
[INFO] 2021-07-12 19:04:31,918 [run_pretraining.py:  512]:	********exe.run_1624******* 
[INFO] 2021-07-12 19:04:32,837 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:32,838 [run_pretraining.py:  534]:	loss/total_loss, 7.119757652282715, 1625
[INFO] 2021-07-12 19:04:32,838 [run_pretraining.py:  535]:	loss/mlm_loss, 7.119757652282715, 1625
[INFO] 2021-07-12 19:04:32,838 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.624000105948653e-05, 1625
[INFO] 2021-07-12 19:04:32,838 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1625
[INFO] 2021-07-12 19:04:32,838 [run_pretraining.py:  558]:	worker_index: 6, step: 1625, cost: 7.119758, mlm loss: 7.119758, speed: 1.087380 steps/s, speed: 8.699040 samples/s, speed: 4453.908356 tokens/s, learning rate: 1.624e-05, loss_scalings: 6871.948730, pp_loss: 7.326083
[INFO] 2021-07-12 19:04:32,838 [run_pretraining.py:  512]:	********exe.run_1625******* 
[INFO] 2021-07-12 19:04:33,758 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:33,758 [run_pretraining.py:  534]:	loss/total_loss, 7.290960788726807, 1626
[INFO] 2021-07-12 19:04:33,758 [run_pretraining.py:  535]:	loss/mlm_loss, 7.290960788726807, 1626
[INFO] 2021-07-12 19:04:33,758 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.624999822524842e-05, 1626
[INFO] 2021-07-12 19:04:33,759 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1626
[INFO] 2021-07-12 19:04:33,759 [run_pretraining.py:  558]:	worker_index: 6, step: 1626, cost: 7.290961, mlm loss: 7.290961, speed: 1.087230 steps/s, speed: 8.697840 samples/s, speed: 4453.294150 tokens/s, learning rate: 1.625e-05, loss_scalings: 6871.948730, pp_loss: 7.065698
[INFO] 2021-07-12 19:04:33,759 [run_pretraining.py:  512]:	********exe.run_1626******* 
[INFO] 2021-07-12 19:04:34,676 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:34,677 [run_pretraining.py:  534]:	loss/total_loss, 7.267485618591309, 1627
[INFO] 2021-07-12 19:04:34,677 [run_pretraining.py:  535]:	loss/mlm_loss, 7.267485618591309, 1627
[INFO] 2021-07-12 19:04:34,677 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6259999028989114e-05, 1627
[INFO] 2021-07-12 19:04:34,677 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1627
[INFO] 2021-07-12 19:04:34,677 [run_pretraining.py:  558]:	worker_index: 6, step: 1627, cost: 7.267486, mlm loss: 7.267486, speed: 1.089411 steps/s, speed: 8.715290 samples/s, speed: 4462.228348 tokens/s, learning rate: 1.626e-05, loss_scalings: 6871.948730, pp_loss: 7.195197
[INFO] 2021-07-12 19:04:34,677 [run_pretraining.py:  512]:	********exe.run_1627******* 
[INFO] 2021-07-12 19:04:35,596 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:35,597 [run_pretraining.py:  534]:	loss/total_loss, 7.7209649085998535, 1628
[INFO] 2021-07-12 19:04:35,597 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7209649085998535, 1628
[INFO] 2021-07-12 19:04:35,597 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.626999983272981e-05, 1628
[INFO] 2021-07-12 19:04:35,597 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1628
[INFO] 2021-07-12 19:04:35,597 [run_pretraining.py:  558]:	worker_index: 6, step: 1628, cost: 7.720965, mlm loss: 7.720965, speed: 1.087732 steps/s, speed: 8.701853 samples/s, speed: 4455.348711 tokens/s, learning rate: 1.627e-05, loss_scalings: 6871.948730, pp_loss: 7.490756
[INFO] 2021-07-12 19:04:35,597 [run_pretraining.py:  512]:	********exe.run_1628******* 
[INFO] 2021-07-12 19:04:36,508 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:36,509 [run_pretraining.py:  534]:	loss/total_loss, 7.0766801834106445, 1629
[INFO] 2021-07-12 19:04:36,509 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0766801834106445, 1629
[INFO] 2021-07-12 19:04:36,509 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.62799988174811e-05, 1629
[INFO] 2021-07-12 19:04:36,509 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1629
[INFO] 2021-07-12 19:04:36,509 [run_pretraining.py:  558]:	worker_index: 6, step: 1629, cost: 7.076680, mlm loss: 7.076680, speed: 1.097400 steps/s, speed: 8.779197 samples/s, speed: 4494.948687 tokens/s, learning rate: 1.628e-05, loss_scalings: 6871.948730, pp_loss: 7.622997
[INFO] 2021-07-12 19:04:36,509 [run_pretraining.py:  512]:	********exe.run_1629******* 
[INFO] 2021-07-12 19:04:37,433 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:37,434 [run_pretraining.py:  534]:	loss/total_loss, 7.733752727508545, 1630
[INFO] 2021-07-12 19:04:37,434 [run_pretraining.py:  535]:	loss/mlm_loss, 7.733752727508545, 1630
[INFO] 2021-07-12 19:04:37,434 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6289999621221796e-05, 1630
[INFO] 2021-07-12 19:04:37,434 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1630
[INFO] 2021-07-12 19:04:37,434 [run_pretraining.py:  558]:	worker_index: 6, step: 1630, cost: 7.733753, mlm loss: 7.733753, speed: 1.081986 steps/s, speed: 8.655889 samples/s, speed: 4431.815099 tokens/s, learning rate: 1.629e-05, loss_scalings: 6871.948730, pp_loss: 7.304247
[INFO] 2021-07-12 19:04:37,434 [run_pretraining.py:  512]:	********exe.run_1630******* 
[INFO] 2021-07-12 19:04:38,352 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:38,352 [run_pretraining.py:  534]:	loss/total_loss, 7.5873565673828125, 1631
[INFO] 2021-07-12 19:04:38,352 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5873565673828125, 1631
[INFO] 2021-07-12 19:04:38,352 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.630000042496249e-05, 1631
[INFO] 2021-07-12 19:04:38,352 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1631
[INFO] 2021-07-12 19:04:38,353 [run_pretraining.py:  558]:	worker_index: 6, step: 1631, cost: 7.587357, mlm loss: 7.587357, speed: 1.089757 steps/s, speed: 8.718059 samples/s, speed: 4463.646256 tokens/s, learning rate: 1.630e-05, loss_scalings: 6871.948730, pp_loss: 7.372492
[INFO] 2021-07-12 19:04:38,353 [run_pretraining.py:  512]:	********exe.run_1631******* 
[INFO] 2021-07-12 19:04:39,271 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:39,272 [run_pretraining.py:  534]:	loss/total_loss, 7.916645050048828, 1632
[INFO] 2021-07-12 19:04:39,272 [run_pretraining.py:  535]:	loss/mlm_loss, 7.916645050048828, 1632
[INFO] 2021-07-12 19:04:39,272 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6309999409713782e-05, 1632
[INFO] 2021-07-12 19:04:39,272 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1632
[INFO] 2021-07-12 19:04:39,272 [run_pretraining.py:  558]:	worker_index: 6, step: 1632, cost: 7.916645, mlm loss: 7.916645, speed: 1.088233 steps/s, speed: 8.705863 samples/s, speed: 4457.401700 tokens/s, learning rate: 1.631e-05, loss_scalings: 6871.948730, pp_loss: 7.674599
[INFO] 2021-07-12 19:04:39,272 [run_pretraining.py:  512]:	********exe.run_1632******* 
[INFO] 2021-07-12 19:04:40,189 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:40,190 [run_pretraining.py:  534]:	loss/total_loss, 7.621465682983398, 1633
[INFO] 2021-07-12 19:04:40,190 [run_pretraining.py:  535]:	loss/mlm_loss, 7.621465682983398, 1633
[INFO] 2021-07-12 19:04:40,190 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6320000213454477e-05, 1633
[INFO] 2021-07-12 19:04:40,190 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1633
[INFO] 2021-07-12 19:04:40,190 [run_pretraining.py:  558]:	worker_index: 6, step: 1633, cost: 7.621466, mlm loss: 7.621466, speed: 1.090240 steps/s, speed: 8.721916 samples/s, speed: 4465.621003 tokens/s, learning rate: 1.632e-05, loss_scalings: 6871.948730, pp_loss: 7.425098
[INFO] 2021-07-12 19:04:40,190 [run_pretraining.py:  512]:	********exe.run_1633******* 
[INFO] 2021-07-12 19:04:41,097 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:41,097 [run_pretraining.py:  534]:	loss/total_loss, 7.3892364501953125, 1634
[INFO] 2021-07-12 19:04:41,097 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3892364501953125, 1634
[INFO] 2021-07-12 19:04:41,098 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.632999919820577e-05, 1634
[INFO] 2021-07-12 19:04:41,098 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1634
[INFO] 2021-07-12 19:04:41,098 [run_pretraining.py:  558]:	worker_index: 6, step: 1634, cost: 7.389236, mlm loss: 7.389236, speed: 1.102606 steps/s, speed: 8.820852 samples/s, speed: 4516.276116 tokens/s, learning rate: 1.633e-05, loss_scalings: 6871.948730, pp_loss: 7.304384
[INFO] 2021-07-12 19:04:41,098 [run_pretraining.py:  512]:	********exe.run_1634******* 
[INFO] 2021-07-12 19:04:42,013 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:42,013 [run_pretraining.py:  534]:	loss/total_loss, 7.325904846191406, 1635
[INFO] 2021-07-12 19:04:42,013 [run_pretraining.py:  535]:	loss/mlm_loss, 7.325904846191406, 1635
[INFO] 2021-07-12 19:04:42,013 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.633999818295706e-05, 1635
[INFO] 2021-07-12 19:04:42,013 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1635
[INFO] 2021-07-12 19:04:42,014 [run_pretraining.py:  558]:	worker_index: 6, step: 1635, cost: 7.325905, mlm loss: 7.325905, speed: 1.092790 steps/s, speed: 8.742320 samples/s, speed: 4476.067884 tokens/s, learning rate: 1.634e-05, loss_scalings: 6871.948730, pp_loss: 7.198083
[INFO] 2021-07-12 19:04:42,014 [run_pretraining.py:  512]:	********exe.run_1635******* 
[INFO] 2021-07-12 19:04:42,918 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:42,918 [run_pretraining.py:  534]:	loss/total_loss, 7.344401836395264, 1636
[INFO] 2021-07-12 19:04:42,918 [run_pretraining.py:  535]:	loss/mlm_loss, 7.344401836395264, 1636
[INFO] 2021-07-12 19:04:42,918 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6349998986697756e-05, 1636
[INFO] 2021-07-12 19:04:42,919 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1636
[INFO] 2021-07-12 19:04:42,919 [run_pretraining.py:  558]:	worker_index: 6, step: 1636, cost: 7.344402, mlm loss: 7.344402, speed: 1.105744 steps/s, speed: 8.845955 samples/s, speed: 4529.128923 tokens/s, learning rate: 1.635e-05, loss_scalings: 6871.948730, pp_loss: 6.353090
[INFO] 2021-07-12 19:04:42,919 [run_pretraining.py:  512]:	********exe.run_1636******* 
[INFO] 2021-07-12 19:04:43,844 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:43,844 [run_pretraining.py:  534]:	loss/total_loss, 7.01120138168335, 1637
[INFO] 2021-07-12 19:04:43,844 [run_pretraining.py:  535]:	loss/mlm_loss, 7.01120138168335, 1637
[INFO] 2021-07-12 19:04:43,844 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.635999979043845e-05, 1637
[INFO] 2021-07-12 19:04:43,844 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1637
[INFO] 2021-07-12 19:04:43,844 [run_pretraining.py:  558]:	worker_index: 6, step: 1637, cost: 7.011201, mlm loss: 7.011201, speed: 1.080881 steps/s, speed: 8.647044 samples/s, speed: 4427.286721 tokens/s, learning rate: 1.636e-05, loss_scalings: 6871.948730, pp_loss: 7.178891
[INFO] 2021-07-12 19:04:43,845 [run_pretraining.py:  512]:	********exe.run_1637******* 
[INFO] 2021-07-12 19:04:44,756 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:44,757 [run_pretraining.py:  534]:	loss/total_loss, 6.6204047203063965, 1638
[INFO] 2021-07-12 19:04:44,757 [run_pretraining.py:  535]:	loss/mlm_loss, 6.6204047203063965, 1638
[INFO] 2021-07-12 19:04:44,757 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6369998775189742e-05, 1638
[INFO] 2021-07-12 19:04:44,757 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1638
[INFO] 2021-07-12 19:04:44,757 [run_pretraining.py:  558]:	worker_index: 6, step: 1638, cost: 6.620405, mlm loss: 6.620405, speed: 1.096507 steps/s, speed: 8.772054 samples/s, speed: 4491.291764 tokens/s, learning rate: 1.637e-05, loss_scalings: 6871.948730, pp_loss: 7.026944
[INFO] 2021-07-12 19:04:44,757 [run_pretraining.py:  512]:	********exe.run_1638******* 
[INFO] 2021-07-12 19:04:45,691 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:45,692 [run_pretraining.py:  534]:	loss/total_loss, 7.217781066894531, 1639
[INFO] 2021-07-12 19:04:45,692 [run_pretraining.py:  535]:	loss/mlm_loss, 7.217781066894531, 1639
[INFO] 2021-07-12 19:04:45,692 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6379999578930438e-05, 1639
[INFO] 2021-07-12 19:04:45,692 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1639
[INFO] 2021-07-12 19:04:45,692 [run_pretraining.py:  558]:	worker_index: 6, step: 1639, cost: 7.217781, mlm loss: 7.217781, speed: 1.070175 steps/s, speed: 8.561403 samples/s, speed: 4383.438230 tokens/s, learning rate: 1.638e-05, loss_scalings: 6871.948730, pp_loss: 7.442498
[INFO] 2021-07-12 19:04:45,692 [run_pretraining.py:  512]:	********exe.run_1639******* 
[INFO] 2021-07-12 19:04:46,602 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:46,602 [run_pretraining.py:  534]:	loss/total_loss, 6.765995979309082, 1640
[INFO] 2021-07-12 19:04:46,602 [run_pretraining.py:  535]:	loss/mlm_loss, 6.765995979309082, 1640
[INFO] 2021-07-12 19:04:46,602 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6390000382671133e-05, 1640
[INFO] 2021-07-12 19:04:46,603 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1640
[INFO] 2021-07-12 19:04:46,603 [run_pretraining.py:  558]:	worker_index: 6, step: 1640, cost: 6.765996, mlm loss: 6.765996, speed: 1.099333 steps/s, speed: 8.794664 samples/s, speed: 4502.868093 tokens/s, learning rate: 1.639e-05, loss_scalings: 6871.948730, pp_loss: 7.094467
[INFO] 2021-07-12 19:04:46,603 [run_pretraining.py:  512]:	********exe.run_1640******* 
[INFO] 2021-07-12 19:04:47,508 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:47,509 [run_pretraining.py:  534]:	loss/total_loss, 3.9856936931610107, 1641
[INFO] 2021-07-12 19:04:47,509 [run_pretraining.py:  535]:	loss/mlm_loss, 3.9856936931610107, 1641
[INFO] 2021-07-12 19:04:47,509 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6399999367422424e-05, 1641
[INFO] 2021-07-12 19:04:47,509 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1641
[INFO] 2021-07-12 19:04:47,509 [run_pretraining.py:  558]:	worker_index: 6, step: 1641, cost: 3.985694, mlm loss: 3.985694, speed: 1.104022 steps/s, speed: 8.832175 samples/s, speed: 4522.073754 tokens/s, learning rate: 1.640e-05, loss_scalings: 6871.948730, pp_loss: 6.291990
[INFO] 2021-07-12 19:04:47,509 [run_pretraining.py:  512]:	********exe.run_1641******* 
[INFO] 2021-07-12 19:04:48,413 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:48,413 [run_pretraining.py:  534]:	loss/total_loss, 7.0529279708862305, 1642
[INFO] 2021-07-12 19:04:48,413 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0529279708862305, 1642
[INFO] 2021-07-12 19:04:48,413 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.641000017116312e-05, 1642
[INFO] 2021-07-12 19:04:48,414 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1642
[INFO] 2021-07-12 19:04:48,414 [run_pretraining.py:  558]:	worker_index: 6, step: 1642, cost: 7.052928, mlm loss: 7.052928, speed: 1.106489 steps/s, speed: 8.851915 samples/s, speed: 4532.180490 tokens/s, learning rate: 1.641e-05, loss_scalings: 6871.948730, pp_loss: 6.986220
[INFO] 2021-07-12 19:04:48,414 [run_pretraining.py:  512]:	********exe.run_1642******* 
[INFO] 2021-07-12 19:04:49,335 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:49,336 [run_pretraining.py:  534]:	loss/total_loss, 7.727521896362305, 1643
[INFO] 2021-07-12 19:04:49,336 [run_pretraining.py:  535]:	loss/mlm_loss, 7.727521896362305, 1643
[INFO] 2021-07-12 19:04:49,336 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.641999915591441e-05, 1643
[INFO] 2021-07-12 19:04:49,336 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1643
[INFO] 2021-07-12 19:04:49,336 [run_pretraining.py:  558]:	worker_index: 6, step: 1643, cost: 7.727522, mlm loss: 7.727522, speed: 1.084564 steps/s, speed: 8.676512 samples/s, speed: 4442.374155 tokens/s, learning rate: 1.642e-05, loss_scalings: 6871.948730, pp_loss: 7.119015
[INFO] 2021-07-12 19:04:49,336 [run_pretraining.py:  512]:	********exe.run_1643******* 
[INFO] 2021-07-12 19:04:50,245 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:50,246 [run_pretraining.py:  534]:	loss/total_loss, 6.181131362915039, 1644
[INFO] 2021-07-12 19:04:50,246 [run_pretraining.py:  535]:	loss/mlm_loss, 6.181131362915039, 1644
[INFO] 2021-07-12 19:04:50,246 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6429999959655106e-05, 1644
[INFO] 2021-07-12 19:04:50,246 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1644
[INFO] 2021-07-12 19:04:50,246 [run_pretraining.py:  558]:	worker_index: 6, step: 1644, cost: 6.181131, mlm loss: 6.181131, speed: 1.100124 steps/s, speed: 8.800994 samples/s, speed: 4506.108915 tokens/s, learning rate: 1.643e-05, loss_scalings: 6871.948730, pp_loss: 7.235719
[INFO] 2021-07-12 19:04:50,246 [run_pretraining.py:  512]:	********exe.run_1644******* 
[INFO] 2021-07-12 19:04:51,311 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:51,312 [run_pretraining.py:  534]:	loss/total_loss, 7.382044315338135, 1645
[INFO] 2021-07-12 19:04:51,312 [run_pretraining.py:  535]:	loss/mlm_loss, 7.382044315338135, 1645
[INFO] 2021-07-12 19:04:51,312 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6439998944406398e-05, 1645
[INFO] 2021-07-12 19:04:51,312 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1645
[INFO] 2021-07-12 19:04:51,312 [run_pretraining.py:  558]:	worker_index: 6, step: 1645, cost: 7.382044, mlm loss: 7.382044, speed: 0.938405 steps/s, speed: 7.507238 samples/s, speed: 3843.705679 tokens/s, learning rate: 1.644e-05, loss_scalings: 6871.948730, pp_loss: 7.277431
[INFO] 2021-07-12 19:04:51,312 [run_pretraining.py:  512]:	********exe.run_1645******* 
[INFO] 2021-07-12 19:04:52,225 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:52,225 [run_pretraining.py:  534]:	loss/total_loss, 7.145554542541504, 1646
[INFO] 2021-07-12 19:04:52,225 [run_pretraining.py:  535]:	loss/mlm_loss, 7.145554542541504, 1646
[INFO] 2021-07-12 19:04:52,225 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6449999748147093e-05, 1646
[INFO] 2021-07-12 19:04:52,226 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1646
[INFO] 2021-07-12 19:04:52,226 [run_pretraining.py:  558]:	worker_index: 6, step: 1646, cost: 7.145555, mlm loss: 7.145555, speed: 1.095897 steps/s, speed: 8.767175 samples/s, speed: 4488.793395 tokens/s, learning rate: 1.645e-05, loss_scalings: 6871.948730, pp_loss: 7.052889
[INFO] 2021-07-12 19:04:52,226 [run_pretraining.py:  512]:	********exe.run_1646******* 
[INFO] 2021-07-12 19:04:53,130 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:53,131 [run_pretraining.py:  534]:	loss/total_loss, 7.701840400695801, 1647
[INFO] 2021-07-12 19:04:53,131 [run_pretraining.py:  535]:	loss/mlm_loss, 7.701840400695801, 1647
[INFO] 2021-07-12 19:04:53,131 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6459998732898384e-05, 1647
[INFO] 2021-07-12 19:04:53,131 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1647
[INFO] 2021-07-12 19:04:53,131 [run_pretraining.py:  558]:	worker_index: 6, step: 1647, cost: 7.701840, mlm loss: 7.701840, speed: 1.104878 steps/s, speed: 8.839022 samples/s, speed: 4525.579514 tokens/s, learning rate: 1.646e-05, loss_scalings: 6871.948730, pp_loss: 7.332768
[INFO] 2021-07-12 19:04:53,131 [run_pretraining.py:  512]:	********exe.run_1647******* 
[INFO] 2021-07-12 19:04:54,039 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:54,039 [run_pretraining.py:  534]:	loss/total_loss, 7.669919967651367, 1648
[INFO] 2021-07-12 19:04:54,039 [run_pretraining.py:  535]:	loss/mlm_loss, 7.669919967651367, 1648
[INFO] 2021-07-12 19:04:54,039 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.646999953663908e-05, 1648
[INFO] 2021-07-12 19:04:54,039 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1648
[INFO] 2021-07-12 19:04:54,040 [run_pretraining.py:  558]:	worker_index: 6, step: 1648, cost: 7.669920, mlm loss: 7.669920, speed: 1.102002 steps/s, speed: 8.816015 samples/s, speed: 4513.799690 tokens/s, learning rate: 1.647e-05, loss_scalings: 6871.948730, pp_loss: 7.298367
[INFO] 2021-07-12 19:04:54,040 [run_pretraining.py:  512]:	********exe.run_1648******* 
[INFO] 2021-07-12 19:04:55,102 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:55,103 [run_pretraining.py:  534]:	loss/total_loss, 7.135126113891602, 1649
[INFO] 2021-07-12 19:04:55,103 [run_pretraining.py:  535]:	loss/mlm_loss, 7.135126113891602, 1649
[INFO] 2021-07-12 19:04:55,103 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6480000340379775e-05, 1649
[INFO] 2021-07-12 19:04:55,103 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1649
[INFO] 2021-07-12 19:04:55,103 [run_pretraining.py:  558]:	worker_index: 6, step: 1649, cost: 7.135126, mlm loss: 7.135126, speed: 0.940557 steps/s, speed: 7.524458 samples/s, speed: 3852.522431 tokens/s, learning rate: 1.648e-05, loss_scalings: 6871.948730, pp_loss: 7.117571
[INFO] 2021-07-12 19:04:55,104 [run_pretraining.py:  512]:	********exe.run_1649******* 
[INFO] 2021-07-12 19:04:56,182 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:56,183 [run_pretraining.py:  534]:	loss/total_loss, 7.009746551513672, 1650
[INFO] 2021-07-12 19:04:56,183 [run_pretraining.py:  535]:	loss/mlm_loss, 7.009746551513672, 1650
[INFO] 2021-07-12 19:04:56,183 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6489999325131066e-05, 1650
[INFO] 2021-07-12 19:04:56,183 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1650
[INFO] 2021-07-12 19:04:56,183 [run_pretraining.py:  558]:	worker_index: 6, step: 1650, cost: 7.009747, mlm loss: 7.009747, speed: 0.926979 steps/s, speed: 7.415834 samples/s, speed: 3796.907063 tokens/s, learning rate: 1.649e-05, loss_scalings: 6871.948730, pp_loss: 7.352551
[INFO] 2021-07-12 19:04:56,183 [run_pretraining.py:  512]:	********exe.run_1650******* 
[INFO] 2021-07-12 19:04:57,238 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:57,238 [run_pretraining.py:  534]:	loss/total_loss, 6.628913879394531, 1651
[INFO] 2021-07-12 19:04:57,238 [run_pretraining.py:  535]:	loss/mlm_loss, 6.628913879394531, 1651
[INFO] 2021-07-12 19:04:57,238 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.650000012887176e-05, 1651
[INFO] 2021-07-12 19:04:57,238 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1651
[INFO] 2021-07-12 19:04:57,239 [run_pretraining.py:  558]:	worker_index: 6, step: 1651, cost: 6.628914, mlm loss: 6.628914, speed: 0.947965 steps/s, speed: 7.583723 samples/s, speed: 3882.866098 tokens/s, learning rate: 1.650e-05, loss_scalings: 6871.948730, pp_loss: 6.896420
[INFO] 2021-07-12 19:04:57,239 [run_pretraining.py:  512]:	********exe.run_1651******* 
[INFO] 2021-07-12 19:04:58,310 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:58,311 [run_pretraining.py:  534]:	loss/total_loss, 7.776495456695557, 1652
[INFO] 2021-07-12 19:04:58,311 [run_pretraining.py:  535]:	loss/mlm_loss, 7.776495456695557, 1652
[INFO] 2021-07-12 19:04:58,311 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6509999113623053e-05, 1652
[INFO] 2021-07-12 19:04:58,311 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1652
[INFO] 2021-07-12 19:04:58,311 [run_pretraining.py:  558]:	worker_index: 6, step: 1652, cost: 7.776495, mlm loss: 7.776495, speed: 0.932813 steps/s, speed: 7.462502 samples/s, speed: 3820.801103 tokens/s, learning rate: 1.651e-05, loss_scalings: 6871.948730, pp_loss: 7.490857
[INFO] 2021-07-12 19:04:58,311 [run_pretraining.py:  512]:	********exe.run_1652******* 
[INFO] 2021-07-12 19:04:59,365 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:59,365 [run_pretraining.py:  534]:	loss/total_loss, 7.699069976806641, 1653
[INFO] 2021-07-12 19:04:59,366 [run_pretraining.py:  535]:	loss/mlm_loss, 7.699069976806641, 1653
[INFO] 2021-07-12 19:04:59,366 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6519999917363748e-05, 1653
[INFO] 2021-07-12 19:04:59,366 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1653
[INFO] 2021-07-12 19:04:59,366 [run_pretraining.py:  558]:	worker_index: 6, step: 1653, cost: 7.699070, mlm loss: 7.699070, speed: 0.948925 steps/s, speed: 7.591403 samples/s, speed: 3886.798108 tokens/s, learning rate: 1.652e-05, loss_scalings: 6871.948730, pp_loss: 6.156944
[INFO] 2021-07-12 19:04:59,366 [run_pretraining.py:  512]:	********exe.run_1653******* 
[INFO] 2021-07-12 19:05:00,369 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:00,370 [run_pretraining.py:  534]:	loss/total_loss, 7.189080238342285, 1654
[INFO] 2021-07-12 19:05:00,370 [run_pretraining.py:  535]:	loss/mlm_loss, 7.189080238342285, 1654
[INFO] 2021-07-12 19:05:00,370 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.652999890211504e-05, 1654
[INFO] 2021-07-12 19:05:00,370 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1654
[INFO] 2021-07-12 19:05:00,370 [run_pretraining.py:  558]:	worker_index: 6, step: 1654, cost: 7.189080, mlm loss: 7.189080, speed: 0.996431 steps/s, speed: 7.971452 samples/s, speed: 4081.383401 tokens/s, learning rate: 1.653e-05, loss_scalings: 6871.948730, pp_loss: 7.308418
[INFO] 2021-07-12 19:05:00,370 [run_pretraining.py:  512]:	********exe.run_1654******* 
[INFO] 2021-07-12 19:05:01,293 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:01,294 [run_pretraining.py:  534]:	loss/total_loss, 6.9181647300720215, 1655
[INFO] 2021-07-12 19:05:01,294 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9181647300720215, 1655
[INFO] 2021-07-12 19:05:01,294 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6539999705855735e-05, 1655
[INFO] 2021-07-12 19:05:01,294 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1655
[INFO] 2021-07-12 19:05:01,294 [run_pretraining.py:  558]:	worker_index: 6, step: 1655, cost: 6.918165, mlm loss: 6.918165, speed: 1.083019 steps/s, speed: 8.664152 samples/s, speed: 4436.045750 tokens/s, learning rate: 1.654e-05, loss_scalings: 6871.948730, pp_loss: 6.574622
[INFO] 2021-07-12 19:05:01,294 [run_pretraining.py:  512]:	********exe.run_1655******* 
[INFO] 2021-07-12 19:05:02,203 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:02,204 [run_pretraining.py:  534]:	loss/total_loss, 7.3436360359191895, 1656
[INFO] 2021-07-12 19:05:02,204 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3436360359191895, 1656
[INFO] 2021-07-12 19:05:02,204 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6549998690607026e-05, 1656
[INFO] 2021-07-12 19:05:02,204 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1656
[INFO] 2021-07-12 19:05:02,204 [run_pretraining.py:  558]:	worker_index: 6, step: 1656, cost: 7.343636, mlm loss: 7.343636, speed: 1.100070 steps/s, speed: 8.800558 samples/s, speed: 4505.885545 tokens/s, learning rate: 1.655e-05, loss_scalings: 6871.948730, pp_loss: 7.543400
[INFO] 2021-07-12 19:05:02,204 [run_pretraining.py:  512]:	********exe.run_1656******* 
[INFO] 2021-07-12 19:05:03,119 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:03,120 [run_pretraining.py:  534]:	loss/total_loss, 6.954174518585205, 1657
[INFO] 2021-07-12 19:05:03,120 [run_pretraining.py:  535]:	loss/mlm_loss, 6.954174518585205, 1657
[INFO] 2021-07-12 19:05:03,120 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.655999949434772e-05, 1657
[INFO] 2021-07-12 19:05:03,120 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1657
[INFO] 2021-07-12 19:05:03,120 [run_pretraining.py:  558]:	worker_index: 6, step: 1657, cost: 6.954175, mlm loss: 6.954175, speed: 1.092258 steps/s, speed: 8.738067 samples/s, speed: 4473.890479 tokens/s, learning rate: 1.656e-05, loss_scalings: 6871.948730, pp_loss: 6.876146
[INFO] 2021-07-12 19:05:03,120 [run_pretraining.py:  512]:	********exe.run_1657******* 
[INFO] 2021-07-12 19:05:04,043 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:04,044 [run_pretraining.py:  534]:	loss/total_loss, 6.8120269775390625, 1658
[INFO] 2021-07-12 19:05:04,044 [run_pretraining.py:  535]:	loss/mlm_loss, 6.8120269775390625, 1658
[INFO] 2021-07-12 19:05:04,044 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6570000298088416e-05, 1658
[INFO] 2021-07-12 19:05:04,044 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1658
[INFO] 2021-07-12 19:05:04,044 [run_pretraining.py:  558]:	worker_index: 6, step: 1658, cost: 6.812027, mlm loss: 6.812027, speed: 1.083374 steps/s, speed: 8.666992 samples/s, speed: 4437.499789 tokens/s, learning rate: 1.657e-05, loss_scalings: 6871.948730, pp_loss: 7.355141
[INFO] 2021-07-12 19:05:04,044 [run_pretraining.py:  512]:	********exe.run_1658******* 
[INFO] 2021-07-12 19:05:04,958 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:04,958 [run_pretraining.py:  534]:	loss/total_loss, 7.540770530700684, 1659
[INFO] 2021-07-12 19:05:04,959 [run_pretraining.py:  535]:	loss/mlm_loss, 7.540770530700684, 1659
[INFO] 2021-07-12 19:05:04,959 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6579999282839708e-05, 1659
[INFO] 2021-07-12 19:05:04,959 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1659
[INFO] 2021-07-12 19:05:04,959 [run_pretraining.py:  558]:	worker_index: 6, step: 1659, cost: 7.540771, mlm loss: 7.540771, speed: 1.093810 steps/s, speed: 8.750477 samples/s, speed: 4480.244445 tokens/s, learning rate: 1.658e-05, loss_scalings: 6871.948730, pp_loss: 6.973708
[INFO] 2021-07-12 19:05:04,959 [run_pretraining.py:  512]:	********exe.run_1659******* 
[INFO] 2021-07-12 19:05:05,862 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:05,863 [run_pretraining.py:  534]:	loss/total_loss, 7.6084160804748535, 1660
[INFO] 2021-07-12 19:05:05,863 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6084160804748535, 1660
[INFO] 2021-07-12 19:05:05,863 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6590000086580403e-05, 1660
[INFO] 2021-07-12 19:05:05,863 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1660
[INFO] 2021-07-12 19:05:05,863 [run_pretraining.py:  558]:	worker_index: 6, step: 1660, cost: 7.608416, mlm loss: 7.608416, speed: 1.106624 steps/s, speed: 8.852989 samples/s, speed: 4532.730543 tokens/s, learning rate: 1.659e-05, loss_scalings: 6871.948730, pp_loss: 7.393925
[INFO] 2021-07-12 19:05:05,863 [run_pretraining.py:  512]:	********exe.run_1660******* 
[INFO] 2021-07-12 19:05:06,765 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:06,766 [run_pretraining.py:  534]:	loss/total_loss, 7.49147891998291, 1661
[INFO] 2021-07-12 19:05:06,766 [run_pretraining.py:  535]:	loss/mlm_loss, 7.49147891998291, 1661
[INFO] 2021-07-12 19:05:06,766 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6599999071331695e-05, 1661
[INFO] 2021-07-12 19:05:06,766 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1661
[INFO] 2021-07-12 19:05:06,766 [run_pretraining.py:  558]:	worker_index: 6, step: 1661, cost: 7.491479, mlm loss: 7.491479, speed: 1.108072 steps/s, speed: 8.864574 samples/s, speed: 4538.661656 tokens/s, learning rate: 1.660e-05, loss_scalings: 6871.948730, pp_loss: 7.171372
[INFO] 2021-07-12 19:05:06,766 [run_pretraining.py:  512]:	********exe.run_1661******* 
[INFO] 2021-07-12 19:05:07,796 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:07,797 [run_pretraining.py:  534]:	loss/total_loss, 7.855576515197754, 1662
[INFO] 2021-07-12 19:05:07,797 [run_pretraining.py:  535]:	loss/mlm_loss, 7.855576515197754, 1662
[INFO] 2021-07-12 19:05:07,797 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.660999987507239e-05, 1662
[INFO] 2021-07-12 19:05:07,797 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1662
[INFO] 2021-07-12 19:05:07,797 [run_pretraining.py:  558]:	worker_index: 6, step: 1662, cost: 7.855577, mlm loss: 7.855577, speed: 0.970892 steps/s, speed: 7.767134 samples/s, speed: 3976.772781 tokens/s, learning rate: 1.661e-05, loss_scalings: 6871.948730, pp_loss: 7.471473
[INFO] 2021-07-12 19:05:07,797 [run_pretraining.py:  512]:	********exe.run_1662******* 
[INFO] 2021-07-12 19:05:08,878 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:08,878 [run_pretraining.py:  534]:	loss/total_loss, 7.795727729797363, 1663
[INFO] 2021-07-12 19:05:08,878 [run_pretraining.py:  535]:	loss/mlm_loss, 7.795727729797363, 1663
[INFO] 2021-07-12 19:05:08,878 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.661999885982368e-05, 1663
[INFO] 2021-07-12 19:05:08,878 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1663
[INFO] 2021-07-12 19:05:08,879 [run_pretraining.py:  558]:	worker_index: 6, step: 1663, cost: 7.795728, mlm loss: 7.795728, speed: 0.925267 steps/s, speed: 7.402135 samples/s, speed: 3789.892994 tokens/s, learning rate: 1.662e-05, loss_scalings: 6871.948730, pp_loss: 7.584928
[INFO] 2021-07-12 19:05:08,879 [run_pretraining.py:  512]:	********exe.run_1663******* 
[INFO] 2021-07-12 19:05:09,937 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:09,938 [run_pretraining.py:  534]:	loss/total_loss, 7.357779026031494, 1664
[INFO] 2021-07-12 19:05:09,938 [run_pretraining.py:  535]:	loss/mlm_loss, 7.357779026031494, 1664
[INFO] 2021-07-12 19:05:09,938 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6629999663564377e-05, 1664
[INFO] 2021-07-12 19:05:09,938 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1664
[INFO] 2021-07-12 19:05:09,938 [run_pretraining.py:  558]:	worker_index: 6, step: 1664, cost: 7.357779, mlm loss: 7.357779, speed: 0.944607 steps/s, speed: 7.556859 samples/s, speed: 3869.111594 tokens/s, learning rate: 1.663e-05, loss_scalings: 6871.948730, pp_loss: 6.948593
[INFO] 2021-07-12 19:05:09,938 [run_pretraining.py:  512]:	********exe.run_1664******* 
[INFO] 2021-07-12 19:05:11,000 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:11,000 [run_pretraining.py:  534]:	loss/total_loss, 7.571841716766357, 1665
[INFO] 2021-07-12 19:05:11,001 [run_pretraining.py:  535]:	loss/mlm_loss, 7.571841716766357, 1665
[INFO] 2021-07-12 19:05:11,001 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.664000046730507e-05, 1665
[INFO] 2021-07-12 19:05:11,001 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1665
[INFO] 2021-07-12 19:05:11,001 [run_pretraining.py:  558]:	worker_index: 6, step: 1665, cost: 7.571842, mlm loss: 7.571842, speed: 0.941455 steps/s, speed: 7.531641 samples/s, speed: 3856.200165 tokens/s, learning rate: 1.664e-05, loss_scalings: 6871.948730, pp_loss: 7.446108
[INFO] 2021-07-12 19:05:11,001 [run_pretraining.py:  512]:	********exe.run_1665******* 
[INFO] 2021-07-12 19:05:12,056 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:12,057 [run_pretraining.py:  534]:	loss/total_loss, 7.713542938232422, 1666
[INFO] 2021-07-12 19:05:12,057 [run_pretraining.py:  535]:	loss/mlm_loss, 7.713542938232422, 1666
[INFO] 2021-07-12 19:05:12,057 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6649999452056363e-05, 1666
[INFO] 2021-07-12 19:05:12,057 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1666
[INFO] 2021-07-12 19:05:12,057 [run_pretraining.py:  558]:	worker_index: 6, step: 1666, cost: 7.713543, mlm loss: 7.713543, speed: 0.947458 steps/s, speed: 7.579668 samples/s, speed: 3880.789985 tokens/s, learning rate: 1.665e-05, loss_scalings: 6871.948730, pp_loss: 7.364924
[INFO] 2021-07-12 19:05:12,057 [run_pretraining.py:  512]:	********exe.run_1666******* 
[INFO] 2021-07-12 19:05:13,117 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:13,118 [run_pretraining.py:  534]:	loss/total_loss, 6.943821430206299, 1667
[INFO] 2021-07-12 19:05:13,118 [run_pretraining.py:  535]:	loss/mlm_loss, 6.943821430206299, 1667
[INFO] 2021-07-12 19:05:13,118 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.666000025579706e-05, 1667
[INFO] 2021-07-12 19:05:13,118 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1667
[INFO] 2021-07-12 19:05:13,118 [run_pretraining.py:  558]:	worker_index: 6, step: 1667, cost: 6.943821, mlm loss: 6.943821, speed: 0.943016 steps/s, speed: 7.544128 samples/s, speed: 3862.593417 tokens/s, learning rate: 1.666e-05, loss_scalings: 6871.948730, pp_loss: 7.378303
[INFO] 2021-07-12 19:05:13,118 [run_pretraining.py:  512]:	********exe.run_1667******* 
[INFO] 2021-07-12 19:05:14,178 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:14,179 [run_pretraining.py:  534]:	loss/total_loss, 7.413514614105225, 1668
[INFO] 2021-07-12 19:05:14,179 [run_pretraining.py:  535]:	loss/mlm_loss, 7.413514614105225, 1668
[INFO] 2021-07-12 19:05:14,179 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.666999924054835e-05, 1668
[INFO] 2021-07-12 19:05:14,179 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1668
[INFO] 2021-07-12 19:05:14,179 [run_pretraining.py:  558]:	worker_index: 6, step: 1668, cost: 7.413515, mlm loss: 7.413515, speed: 0.943125 steps/s, speed: 7.545000 samples/s, speed: 3863.039845 tokens/s, learning rate: 1.667e-05, loss_scalings: 6871.948730, pp_loss: 7.522304
[INFO] 2021-07-12 19:05:14,179 [run_pretraining.py:  512]:	********exe.run_1668******* 
[INFO] 2021-07-12 19:05:15,248 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:15,248 [run_pretraining.py:  534]:	loss/total_loss, 7.786593437194824, 1669
[INFO] 2021-07-12 19:05:15,249 [run_pretraining.py:  535]:	loss/mlm_loss, 7.786593437194824, 1669
[INFO] 2021-07-12 19:05:15,249 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6680000044289045e-05, 1669
[INFO] 2021-07-12 19:05:15,249 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1669
[INFO] 2021-07-12 19:05:15,249 [run_pretraining.py:  558]:	worker_index: 6, step: 1669, cost: 7.786593, mlm loss: 7.786593, speed: 0.935519 steps/s, speed: 7.484149 samples/s, speed: 3831.884102 tokens/s, learning rate: 1.668e-05, loss_scalings: 6871.948730, pp_loss: 7.431028
[INFO] 2021-07-12 19:05:15,249 [run_pretraining.py:  512]:	********exe.run_1669******* 
[INFO] 2021-07-12 19:05:40,456 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:40,457 [run_pretraining.py:  534]:	loss/total_loss, 6.8085455894470215, 1670
[INFO] 2021-07-12 19:05:40,457 [run_pretraining.py:  535]:	loss/mlm_loss, 6.8085455894470215, 1670
[INFO] 2021-07-12 19:05:40,457 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6689999029040337e-05, 1670
[INFO] 2021-07-12 19:05:40,457 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1670
[INFO] 2021-07-12 19:05:40,457 [run_pretraining.py:  558]:	worker_index: 6, step: 1670, cost: 6.808546, mlm loss: 6.808546, speed: 0.039671 steps/s, speed: 0.317365 samples/s, speed: 162.490701 tokens/s, learning rate: 1.669e-05, loss_scalings: 6871.948730, pp_loss: 7.362881
[INFO] 2021-07-12 19:05:40,457 [run_pretraining.py:  512]:	********exe.run_1670******* 
[INFO] 2021-07-12 19:05:41,369 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:41,370 [run_pretraining.py:  534]:	loss/total_loss, 7.589879035949707, 1671
[INFO] 2021-07-12 19:05:41,370 [run_pretraining.py:  535]:	loss/mlm_loss, 7.589879035949707, 1671
[INFO] 2021-07-12 19:05:41,370 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6699999832781032e-05, 1671
[INFO] 2021-07-12 19:05:41,370 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1671
[INFO] 2021-07-12 19:05:41,370 [run_pretraining.py:  558]:	worker_index: 6, step: 1671, cost: 7.589879, mlm loss: 7.589879, speed: 1.096342 steps/s, speed: 8.770736 samples/s, speed: 4490.616731 tokens/s, learning rate: 1.670e-05, loss_scalings: 6871.948730, pp_loss: 7.383584
[INFO] 2021-07-12 19:05:41,370 [run_pretraining.py:  512]:	********exe.run_1671******* 
[INFO] 2021-07-12 19:05:42,273 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:42,273 [run_pretraining.py:  534]:	loss/total_loss, 7.495063304901123, 1672
[INFO] 2021-07-12 19:05:42,274 [run_pretraining.py:  535]:	loss/mlm_loss, 7.495063304901123, 1672
[INFO] 2021-07-12 19:05:42,274 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6709998817532323e-05, 1672
[INFO] 2021-07-12 19:05:42,274 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1672
[INFO] 2021-07-12 19:05:42,274 [run_pretraining.py:  558]:	worker_index: 6, step: 1672, cost: 7.495063, mlm loss: 7.495063, speed: 1.107291 steps/s, speed: 8.858330 samples/s, speed: 4535.464855 tokens/s, learning rate: 1.671e-05, loss_scalings: 6871.948730, pp_loss: 7.225108
[INFO] 2021-07-12 19:05:42,274 [run_pretraining.py:  512]:	********exe.run_1672******* 
[INFO] 2021-07-12 19:05:43,267 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:43,273 [run_pretraining.py:  534]:	loss/total_loss, 7.072423934936523, 1673
[INFO] 2021-07-12 19:05:43,278 [run_pretraining.py:  535]:	loss/mlm_loss, 7.072423934936523, 1673
[INFO] 2021-07-12 19:05:43,283 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.671999962127302e-05, 1673
[INFO] 2021-07-12 19:05:43,289 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1673
[INFO] 2021-07-12 19:05:43,294 [run_pretraining.py:  558]:	worker_index: 6, step: 1673, cost: 7.072424, mlm loss: 7.072424, speed: 1.001096 steps/s, speed: 8.008770 samples/s, speed: 4100.490269 tokens/s, learning rate: 1.672e-05, loss_scalings: 6871.948730, pp_loss: 7.272604
[INFO] 2021-07-12 19:05:43,299 [run_pretraining.py:  512]:	********exe.run_1673******* 
[INFO] 2021-07-12 19:05:44,168 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:44,169 [run_pretraining.py:  534]:	loss/total_loss, 7.011322498321533, 1674
[INFO] 2021-07-12 19:05:44,169 [run_pretraining.py:  535]:	loss/mlm_loss, 7.011322498321533, 1674
[INFO] 2021-07-12 19:05:44,169 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6730000425013714e-05, 1674
[INFO] 2021-07-12 19:05:44,169 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1674
[INFO] 2021-07-12 19:05:44,169 [run_pretraining.py:  558]:	worker_index: 6, step: 1674, cost: 7.011322, mlm loss: 7.011322, speed: 1.150100 steps/s, speed: 9.200797 samples/s, speed: 4710.807982 tokens/s, learning rate: 1.673e-05, loss_scalings: 6871.948730, pp_loss: 7.171896
[INFO] 2021-07-12 19:05:44,169 [run_pretraining.py:  512]:	********exe.run_1674******* 
[INFO] 2021-07-12 19:05:45,079 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:45,080 [run_pretraining.py:  534]:	loss/total_loss, 6.789663314819336, 1675
[INFO] 2021-07-12 19:05:45,080 [run_pretraining.py:  535]:	loss/mlm_loss, 6.789663314819336, 1675
[INFO] 2021-07-12 19:05:45,080 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6739999409765005e-05, 1675
[INFO] 2021-07-12 19:05:45,080 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1675
[INFO] 2021-07-12 19:05:45,080 [run_pretraining.py:  558]:	worker_index: 6, step: 1675, cost: 6.789663, mlm loss: 6.789663, speed: 1.098034 steps/s, speed: 8.784274 samples/s, speed: 4497.548107 tokens/s, learning rate: 1.674e-05, loss_scalings: 6871.948730, pp_loss: 7.166963
[INFO] 2021-07-12 19:05:45,080 [run_pretraining.py:  512]:	********exe.run_1675******* 
[INFO] 2021-07-12 19:05:45,989 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:45,989 [run_pretraining.py:  534]:	loss/total_loss, 7.329902648925781, 1676
[INFO] 2021-07-12 19:05:45,989 [run_pretraining.py:  535]:	loss/mlm_loss, 7.329902648925781, 1676
[INFO] 2021-07-12 19:05:45,990 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.67500002135057e-05, 1676
[INFO] 2021-07-12 19:05:45,990 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1676
[INFO] 2021-07-12 19:05:45,990 [run_pretraining.py:  558]:	worker_index: 6, step: 1676, cost: 7.329903, mlm loss: 7.329903, speed: 1.100527 steps/s, speed: 8.804218 samples/s, speed: 4507.759462 tokens/s, learning rate: 1.675e-05, loss_scalings: 6871.948730, pp_loss: 6.906302
[INFO] 2021-07-12 19:05:45,990 [run_pretraining.py:  512]:	********exe.run_1676******* 
[INFO] 2021-07-12 19:05:46,897 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:46,898 [run_pretraining.py:  534]:	loss/total_loss, 7.210476398468018, 1677
[INFO] 2021-07-12 19:05:46,898 [run_pretraining.py:  535]:	loss/mlm_loss, 7.210476398468018, 1677
[INFO] 2021-07-12 19:05:46,898 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6760001017246395e-05, 1677
[INFO] 2021-07-12 19:05:46,898 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1677
[INFO] 2021-07-12 19:05:46,898 [run_pretraining.py:  558]:	worker_index: 6, step: 1677, cost: 7.210476, mlm loss: 7.210476, speed: 1.101955 steps/s, speed: 8.815640 samples/s, speed: 4513.607575 tokens/s, learning rate: 1.676e-05, loss_scalings: 6871.948730, pp_loss: 7.176105
[INFO] 2021-07-12 19:05:46,898 [run_pretraining.py:  512]:	********exe.run_1677******* 
[INFO] 2021-07-12 19:05:47,803 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:47,804 [run_pretraining.py:  534]:	loss/total_loss, 7.560904026031494, 1678
[INFO] 2021-07-12 19:05:47,804 [run_pretraining.py:  535]:	loss/mlm_loss, 7.560904026031494, 1678
[INFO] 2021-07-12 19:05:47,804 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6769998183008283e-05, 1678
[INFO] 2021-07-12 19:05:47,804 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1678
[INFO] 2021-07-12 19:05:47,804 [run_pretraining.py:  558]:	worker_index: 6, step: 1678, cost: 7.560904, mlm loss: 7.560904, speed: 1.104385 steps/s, speed: 8.835082 samples/s, speed: 4523.562115 tokens/s, learning rate: 1.677e-05, loss_scalings: 6871.948730, pp_loss: 7.427097
[INFO] 2021-07-12 19:05:47,804 [run_pretraining.py:  512]:	********exe.run_1678******* 
[INFO] 2021-07-12 19:05:48,717 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:48,717 [run_pretraining.py:  534]:	loss/total_loss, 6.766992568969727, 1679
[INFO] 2021-07-12 19:05:48,717 [run_pretraining.py:  535]:	loss/mlm_loss, 6.766992568969727, 1679
[INFO] 2021-07-12 19:05:48,717 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.677999898674898e-05, 1679
[INFO] 2021-07-12 19:05:48,717 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1679
[INFO] 2021-07-12 19:05:48,718 [run_pretraining.py:  558]:	worker_index: 6, step: 1679, cost: 6.766993, mlm loss: 6.766993, speed: 1.095570 steps/s, speed: 8.764562 samples/s, speed: 4487.455581 tokens/s, learning rate: 1.678e-05, loss_scalings: 6871.948730, pp_loss: 7.005044
[INFO] 2021-07-12 19:05:48,718 [run_pretraining.py:  512]:	********exe.run_1679******* 
[INFO] 2021-07-12 19:05:49,628 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:49,628 [run_pretraining.py:  534]:	loss/total_loss, 7.132238388061523, 1680
[INFO] 2021-07-12 19:05:49,628 [run_pretraining.py:  535]:	loss/mlm_loss, 7.132238388061523, 1680
[INFO] 2021-07-12 19:05:49,629 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6789999790489674e-05, 1680
[INFO] 2021-07-12 19:05:49,629 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1680
[INFO] 2021-07-12 19:05:49,629 [run_pretraining.py:  558]:	worker_index: 6, step: 1680, cost: 7.132238, mlm loss: 7.132238, speed: 1.098349 steps/s, speed: 8.786792 samples/s, speed: 4498.837752 tokens/s, learning rate: 1.679e-05, loss_scalings: 6871.948730, pp_loss: 7.486234
[INFO] 2021-07-12 19:05:49,629 [run_pretraining.py:  512]:	********exe.run_1680******* 
[INFO] 2021-07-12 19:05:50,548 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:50,548 [run_pretraining.py:  534]:	loss/total_loss, 7.330435752868652, 1681
[INFO] 2021-07-12 19:05:50,548 [run_pretraining.py:  535]:	loss/mlm_loss, 7.330435752868652, 1681
[INFO] 2021-07-12 19:05:50,548 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6799998775240965e-05, 1681
[INFO] 2021-07-12 19:05:50,549 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1681
[INFO] 2021-07-12 19:05:50,549 [run_pretraining.py:  558]:	worker_index: 6, step: 1681, cost: 7.330436, mlm loss: 7.330436, speed: 1.087885 steps/s, speed: 8.703076 samples/s, speed: 4455.975042 tokens/s, learning rate: 1.680e-05, loss_scalings: 6871.948730, pp_loss: 7.437831
[INFO] 2021-07-12 19:05:50,549 [run_pretraining.py:  512]:	********exe.run_1681******* 
[INFO] 2021-07-12 19:05:51,457 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:51,458 [run_pretraining.py:  534]:	loss/total_loss, 7.424935340881348, 1682
[INFO] 2021-07-12 19:05:51,458 [run_pretraining.py:  535]:	loss/mlm_loss, 7.424935340881348, 1682
[INFO] 2021-07-12 19:05:51,458 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.680999957898166e-05, 1682
[INFO] 2021-07-12 19:05:51,458 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1682
[INFO] 2021-07-12 19:05:51,458 [run_pretraining.py:  558]:	worker_index: 6, step: 1682, cost: 7.424935, mlm loss: 7.424935, speed: 1.100510 steps/s, speed: 8.804084 samples/s, speed: 4507.690862 tokens/s, learning rate: 1.681e-05, loss_scalings: 6871.948730, pp_loss: 7.314485
[INFO] 2021-07-12 19:05:51,458 [run_pretraining.py:  512]:	********exe.run_1682******* 
[INFO] 2021-07-12 19:05:52,368 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:52,369 [run_pretraining.py:  534]:	loss/total_loss, 7.651705741882324, 1683
[INFO] 2021-07-12 19:05:52,369 [run_pretraining.py:  535]:	loss/mlm_loss, 7.651705741882324, 1683
[INFO] 2021-07-12 19:05:52,369 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6820000382722355e-05, 1683
[INFO] 2021-07-12 19:05:52,369 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1683
[INFO] 2021-07-12 19:05:52,369 [run_pretraining.py:  558]:	worker_index: 6, step: 1683, cost: 7.651706, mlm loss: 7.651706, speed: 1.098365 steps/s, speed: 8.786917 samples/s, speed: 4498.901370 tokens/s, learning rate: 1.682e-05, loss_scalings: 6871.948730, pp_loss: 7.533268
[INFO] 2021-07-12 19:05:52,369 [run_pretraining.py:  512]:	********exe.run_1683******* 
[INFO] 2021-07-12 19:05:53,296 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:53,296 [run_pretraining.py:  534]:	loss/total_loss, 8.061506271362305, 1684
[INFO] 2021-07-12 19:05:53,296 [run_pretraining.py:  535]:	loss/mlm_loss, 8.061506271362305, 1684
[INFO] 2021-07-12 19:05:53,296 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6829999367473647e-05, 1684
[INFO] 2021-07-12 19:05:53,297 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1684
[INFO] 2021-07-12 19:05:53,297 [run_pretraining.py:  558]:	worker_index: 6, step: 1684, cost: 8.061506, mlm loss: 8.061506, speed: 1.078988 steps/s, speed: 8.631902 samples/s, speed: 4419.534074 tokens/s, learning rate: 1.683e-05, loss_scalings: 6871.948730, pp_loss: 7.429168
[INFO] 2021-07-12 19:05:53,297 [run_pretraining.py:  512]:	********exe.run_1684******* 
[INFO] 2021-07-12 19:05:54,213 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:54,213 [run_pretraining.py:  534]:	loss/total_loss, 7.028751373291016, 1685
[INFO] 2021-07-12 19:05:54,213 [run_pretraining.py:  535]:	loss/mlm_loss, 7.028751373291016, 1685
[INFO] 2021-07-12 19:05:54,213 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6840000171214342e-05, 1685
[INFO] 2021-07-12 19:05:54,214 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1685
[INFO] 2021-07-12 19:05:54,214 [run_pretraining.py:  558]:	worker_index: 6, step: 1685, cost: 7.028751, mlm loss: 7.028751, speed: 1.091396 steps/s, speed: 8.731169 samples/s, speed: 4470.358457 tokens/s, learning rate: 1.684e-05, loss_scalings: 6871.948730, pp_loss: 7.072423
[INFO] 2021-07-12 19:05:54,214 [run_pretraining.py:  512]:	********exe.run_1685******* 
[INFO] 2021-07-12 19:05:55,119 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:55,120 [run_pretraining.py:  534]:	loss/total_loss, 7.968059539794922, 1686
[INFO] 2021-07-12 19:05:55,120 [run_pretraining.py:  535]:	loss/mlm_loss, 7.968059539794922, 1686
[INFO] 2021-07-12 19:05:55,120 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6850000974955037e-05, 1686
[INFO] 2021-07-12 19:05:55,120 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1686
[INFO] 2021-07-12 19:05:55,120 [run_pretraining.py:  558]:	worker_index: 6, step: 1686, cost: 7.968060, mlm loss: 7.968060, speed: 1.103743 steps/s, speed: 8.829944 samples/s, speed: 4520.931357 tokens/s, learning rate: 1.685e-05, loss_scalings: 6871.948730, pp_loss: 7.526803
[INFO] 2021-07-12 19:05:55,120 [run_pretraining.py:  512]:	********exe.run_1686******* 
[INFO] 2021-07-12 19:05:56,029 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:56,030 [run_pretraining.py:  534]:	loss/total_loss, 6.829418182373047, 1687
[INFO] 2021-07-12 19:05:56,030 [run_pretraining.py:  535]:	loss/mlm_loss, 6.829418182373047, 1687
[INFO] 2021-07-12 19:05:56,030 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6859998140716925e-05, 1687
[INFO] 2021-07-12 19:05:56,030 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1687
[INFO] 2021-07-12 19:05:56,030 [run_pretraining.py:  558]:	worker_index: 6, step: 1687, cost: 6.829418, mlm loss: 6.829418, speed: 1.099872 steps/s, speed: 8.798977 samples/s, speed: 4505.076164 tokens/s, learning rate: 1.686e-05, loss_scalings: 6871.948730, pp_loss: 7.271263
[INFO] 2021-07-12 19:05:56,030 [run_pretraining.py:  512]:	********exe.run_1687******* 
[INFO] 2021-07-12 19:05:56,936 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:56,937 [run_pretraining.py:  534]:	loss/total_loss, 7.536060810089111, 1688
[INFO] 2021-07-12 19:05:56,937 [run_pretraining.py:  535]:	loss/mlm_loss, 7.536060810089111, 1688
[INFO] 2021-07-12 19:05:56,937 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.686999894445762e-05, 1688
[INFO] 2021-07-12 19:05:56,937 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1688
[INFO] 2021-07-12 19:05:56,937 [run_pretraining.py:  558]:	worker_index: 6, step: 1688, cost: 7.536061, mlm loss: 7.536061, speed: 1.103492 steps/s, speed: 8.827935 samples/s, speed: 4519.902504 tokens/s, learning rate: 1.687e-05, loss_scalings: 6871.948730, pp_loss: 7.515064
[INFO] 2021-07-12 19:05:56,937 [run_pretraining.py:  512]:	********exe.run_1688******* 
[INFO] 2021-07-12 19:05:57,893 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:57,894 [run_pretraining.py:  534]:	loss/total_loss, 7.284733772277832, 1689
[INFO] 2021-07-12 19:05:57,894 [run_pretraining.py:  535]:	loss/mlm_loss, 7.284733772277832, 1689
[INFO] 2021-07-12 19:05:57,894 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6879999748198316e-05, 1689
[INFO] 2021-07-12 19:05:57,894 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1689
[INFO] 2021-07-12 19:05:57,894 [run_pretraining.py:  558]:	worker_index: 6, step: 1689, cost: 7.284734, mlm loss: 7.284734, speed: 1.045359 steps/s, speed: 8.362869 samples/s, speed: 4281.789020 tokens/s, learning rate: 1.688e-05, loss_scalings: 6871.948730, pp_loss: 7.193978
[INFO] 2021-07-12 19:05:57,895 [run_pretraining.py:  512]:	********exe.run_1689******* 
[INFO] 2021-07-12 19:05:58,810 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:58,811 [run_pretraining.py:  534]:	loss/total_loss, 7.806286811828613, 1690
[INFO] 2021-07-12 19:05:58,811 [run_pretraining.py:  535]:	loss/mlm_loss, 7.806286811828613, 1690
[INFO] 2021-07-12 19:05:58,811 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6889998732949607e-05, 1690
[INFO] 2021-07-12 19:05:58,811 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1690
[INFO] 2021-07-12 19:05:58,811 [run_pretraining.py:  558]:	worker_index: 6, step: 1690, cost: 7.806287, mlm loss: 7.806287, speed: 1.091736 steps/s, speed: 8.733891 samples/s, speed: 4471.752439 tokens/s, learning rate: 1.689e-05, loss_scalings: 6871.948730, pp_loss: 7.258407
[INFO] 2021-07-12 19:05:58,811 [run_pretraining.py:  512]:	********exe.run_1690******* 
[INFO] 2021-07-12 19:05:59,727 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:59,728 [run_pretraining.py:  534]:	loss/total_loss, 7.1288743019104, 1691
[INFO] 2021-07-12 19:05:59,728 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1288743019104, 1691
[INFO] 2021-07-12 19:05:59,728 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6899999536690302e-05, 1691
[INFO] 2021-07-12 19:05:59,728 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1691
[INFO] 2021-07-12 19:05:59,728 [run_pretraining.py:  558]:	worker_index: 6, step: 1691, cost: 7.128874, mlm loss: 7.128874, speed: 1.091549 steps/s, speed: 8.732394 samples/s, speed: 4470.985525 tokens/s, learning rate: 1.690e-05, loss_scalings: 6871.948730, pp_loss: 7.040912
[INFO] 2021-07-12 19:05:59,728 [run_pretraining.py:  512]:	********exe.run_1691******* 
[INFO] 2021-07-12 19:06:00,647 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:00,648 [run_pretraining.py:  534]:	loss/total_loss, 7.519160270690918, 1692
[INFO] 2021-07-12 19:06:00,648 [run_pretraining.py:  535]:	loss/mlm_loss, 7.519160270690918, 1692
[INFO] 2021-07-12 19:06:00,648 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6910000340430997e-05, 1692
[INFO] 2021-07-12 19:06:00,648 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1692
[INFO] 2021-07-12 19:06:00,648 [run_pretraining.py:  558]:	worker_index: 6, step: 1692, cost: 7.519160, mlm loss: 7.519160, speed: 1.087624 steps/s, speed: 8.700993 samples/s, speed: 4454.908536 tokens/s, learning rate: 1.691e-05, loss_scalings: 6871.948730, pp_loss: 7.202583
[INFO] 2021-07-12 19:06:00,648 [run_pretraining.py:  512]:	********exe.run_1692******* 
[INFO] 2021-07-12 19:06:01,558 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:01,559 [run_pretraining.py:  534]:	loss/total_loss, 7.1797075271606445, 1693
[INFO] 2021-07-12 19:06:01,559 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1797075271606445, 1693
[INFO] 2021-07-12 19:06:01,559 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.691999932518229e-05, 1693
[INFO] 2021-07-12 19:06:01,559 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1693
[INFO] 2021-07-12 19:06:01,559 [run_pretraining.py:  558]:	worker_index: 6, step: 1693, cost: 7.179708, mlm loss: 7.179708, speed: 1.098443 steps/s, speed: 8.787545 samples/s, speed: 4499.223023 tokens/s, learning rate: 1.692e-05, loss_scalings: 6871.948730, pp_loss: 6.915927
[INFO] 2021-07-12 19:06:01,559 [run_pretraining.py:  512]:	********exe.run_1693******* 
[INFO] 2021-07-12 19:06:02,469 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:02,470 [run_pretraining.py:  534]:	loss/total_loss, 7.341122627258301, 1694
[INFO] 2021-07-12 19:06:02,470 [run_pretraining.py:  535]:	loss/mlm_loss, 7.341122627258301, 1694
[INFO] 2021-07-12 19:06:02,470 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6930000128922984e-05, 1694
[INFO] 2021-07-12 19:06:02,470 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1694
[INFO] 2021-07-12 19:06:02,470 [run_pretraining.py:  558]:	worker_index: 6, step: 1694, cost: 7.341123, mlm loss: 7.341123, speed: 1.098315 steps/s, speed: 8.786521 samples/s, speed: 4498.698741 tokens/s, learning rate: 1.693e-05, loss_scalings: 6871.948730, pp_loss: 7.123750
[INFO] 2021-07-12 19:06:02,470 [run_pretraining.py:  512]:	********exe.run_1694******* 
[INFO] 2021-07-12 19:06:03,386 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:03,386 [run_pretraining.py:  534]:	loss/total_loss, 7.928292751312256, 1695
[INFO] 2021-07-12 19:06:03,386 [run_pretraining.py:  535]:	loss/mlm_loss, 7.928292751312256, 1695
[INFO] 2021-07-12 19:06:03,386 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.694000093266368e-05, 1695
[INFO] 2021-07-12 19:06:03,387 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1695
[INFO] 2021-07-12 19:06:03,387 [run_pretraining.py:  558]:	worker_index: 6, step: 1695, cost: 7.928293, mlm loss: 7.928293, speed: 1.092178 steps/s, speed: 8.737421 samples/s, speed: 4473.559625 tokens/s, learning rate: 1.694e-05, loss_scalings: 6871.948730, pp_loss: 7.365437
[INFO] 2021-07-12 19:06:03,387 [run_pretraining.py:  512]:	********exe.run_1695******* 
[INFO] 2021-07-12 19:06:04,296 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:04,297 [run_pretraining.py:  534]:	loss/total_loss, 7.086362361907959, 1696
[INFO] 2021-07-12 19:06:04,297 [run_pretraining.py:  535]:	loss/mlm_loss, 7.086362361907959, 1696
[INFO] 2021-07-12 19:06:04,297 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6949998098425567e-05, 1696
[INFO] 2021-07-12 19:06:04,297 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1696
[INFO] 2021-07-12 19:06:04,297 [run_pretraining.py:  558]:	worker_index: 6, step: 1696, cost: 7.086362, mlm loss: 7.086362, speed: 1.098990 steps/s, speed: 8.791917 samples/s, speed: 4501.461724 tokens/s, learning rate: 1.695e-05, loss_scalings: 6871.948730, pp_loss: 7.207948
[INFO] 2021-07-12 19:06:04,297 [run_pretraining.py:  512]:	********exe.run_1696******* 
[INFO] 2021-07-12 19:06:05,220 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:05,220 [run_pretraining.py:  534]:	loss/total_loss, 5.817961692810059, 1697
[INFO] 2021-07-12 19:06:05,220 [run_pretraining.py:  535]:	loss/mlm_loss, 5.817961692810059, 1697
[INFO] 2021-07-12 19:06:05,220 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6959998902166262e-05, 1697
[INFO] 2021-07-12 19:06:05,221 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1697
[INFO] 2021-07-12 19:06:05,221 [run_pretraining.py:  558]:	worker_index: 6, step: 1697, cost: 5.817962, mlm loss: 5.817962, speed: 1.083841 steps/s, speed: 8.670732 samples/s, speed: 4439.414754 tokens/s, learning rate: 1.696e-05, loss_scalings: 6871.948730, pp_loss: 6.874052
[INFO] 2021-07-12 19:06:05,221 [run_pretraining.py:  512]:	********exe.run_1697******* 
[INFO] 2021-07-12 19:06:06,139 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:06,140 [run_pretraining.py:  534]:	loss/total_loss, 7.942018032073975, 1698
[INFO] 2021-07-12 19:06:06,140 [run_pretraining.py:  535]:	loss/mlm_loss, 7.942018032073975, 1698
[INFO] 2021-07-12 19:06:06,140 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6969999705906957e-05, 1698
[INFO] 2021-07-12 19:06:06,140 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1698
[INFO] 2021-07-12 19:06:06,140 [run_pretraining.py:  558]:	worker_index: 6, step: 1698, cost: 7.942018, mlm loss: 7.942018, speed: 1.088184 steps/s, speed: 8.705474 samples/s, speed: 4457.202792 tokens/s, learning rate: 1.697e-05, loss_scalings: 6871.948730, pp_loss: 7.143910
[INFO] 2021-07-12 19:06:06,140 [run_pretraining.py:  512]:	********exe.run_1698******* 
[INFO] 2021-07-12 19:06:07,067 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:07,068 [run_pretraining.py:  534]:	loss/total_loss, 8.23336124420166, 1699
[INFO] 2021-07-12 19:06:07,068 [run_pretraining.py:  535]:	loss/mlm_loss, 8.23336124420166, 1699
[INFO] 2021-07-12 19:06:07,068 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.697999869065825e-05, 1699
[INFO] 2021-07-12 19:06:07,068 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1699
[INFO] 2021-07-12 19:06:07,068 [run_pretraining.py:  558]:	worker_index: 6, step: 1699, cost: 8.233361, mlm loss: 8.233361, speed: 1.078487 steps/s, speed: 8.627898 samples/s, speed: 4417.484006 tokens/s, learning rate: 1.698e-05, loss_scalings: 6871.948730, pp_loss: 6.556046
[INFO] 2021-07-12 19:06:07,068 [run_pretraining.py:  512]:	********exe.run_1699******* 
[INFO] 2021-07-12 19:06:08,001 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:08,001 [run_pretraining.py:  534]:	loss/total_loss, 7.2518463134765625, 1700
[INFO] 2021-07-12 19:06:08,002 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2518463134765625, 1700
[INFO] 2021-07-12 19:06:08,002 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6989999494398944e-05, 1700
[INFO] 2021-07-12 19:06:08,002 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1700
[INFO] 2021-07-12 19:06:08,002 [run_pretraining.py:  558]:	worker_index: 6, step: 1700, cost: 7.251846, mlm loss: 7.251846, speed: 1.071875 steps/s, speed: 8.575003 samples/s, speed: 4390.401452 tokens/s, learning rate: 1.699e-05, loss_scalings: 6871.948730, pp_loss: 7.310085
[INFO] 2021-07-12 19:06:08,002 [run_pretraining.py:  512]:	********exe.run_1700******* 
[INFO] 2021-07-12 19:06:08,932 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:08,932 [run_pretraining.py:  534]:	loss/total_loss, 6.911252975463867, 1701
[INFO] 2021-07-12 19:06:08,932 [run_pretraining.py:  535]:	loss/mlm_loss, 6.911252975463867, 1701
[INFO] 2021-07-12 19:06:08,933 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.700000029813964e-05, 1701
[INFO] 2021-07-12 19:06:08,933 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1701
[INFO] 2021-07-12 19:06:08,933 [run_pretraining.py:  558]:	worker_index: 6, step: 1701, cost: 6.911253, mlm loss: 6.911253, speed: 1.074971 steps/s, speed: 8.599767 samples/s, speed: 4403.080535 tokens/s, learning rate: 1.700e-05, loss_scalings: 6871.948730, pp_loss: 7.344797
[INFO] 2021-07-12 19:06:08,933 [run_pretraining.py:  512]:	********exe.run_1701******* 
[INFO] 2021-07-12 19:06:09,861 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:09,862 [run_pretraining.py:  534]:	loss/total_loss, 7.452691078186035, 1702
[INFO] 2021-07-12 19:06:09,862 [run_pretraining.py:  535]:	loss/mlm_loss, 7.452691078186035, 1702
[INFO] 2021-07-12 19:06:09,862 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.700999928289093e-05, 1702
[INFO] 2021-07-12 19:06:09,862 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1702
[INFO] 2021-07-12 19:06:09,862 [run_pretraining.py:  558]:	worker_index: 6, step: 1702, cost: 7.452691, mlm loss: 7.452691, speed: 1.076711 steps/s, speed: 8.613686 samples/s, speed: 4410.207110 tokens/s, learning rate: 1.701e-05, loss_scalings: 6871.948730, pp_loss: 6.582438
[INFO] 2021-07-12 19:06:09,862 [run_pretraining.py:  512]:	********exe.run_1702******* 
[INFO] 2021-07-12 19:06:10,789 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:10,789 [run_pretraining.py:  534]:	loss/total_loss, 7.973797798156738, 1703
[INFO] 2021-07-12 19:06:10,790 [run_pretraining.py:  535]:	loss/mlm_loss, 7.973797798156738, 1703
[INFO] 2021-07-12 19:06:10,790 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7020000086631626e-05, 1703
[INFO] 2021-07-12 19:06:10,790 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1703
[INFO] 2021-07-12 19:06:10,790 [run_pretraining.py:  558]:	worker_index: 6, step: 1703, cost: 7.973798, mlm loss: 7.973798, speed: 1.078891 steps/s, speed: 8.631130 samples/s, speed: 4419.138458 tokens/s, learning rate: 1.702e-05, loss_scalings: 6871.948730, pp_loss: 7.232065
[INFO] 2021-07-12 19:06:10,790 [run_pretraining.py:  512]:	********exe.run_1703******* 
[INFO] 2021-07-12 19:06:11,711 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:11,711 [run_pretraining.py:  534]:	loss/total_loss, 6.7222371101379395, 1704
[INFO] 2021-07-12 19:06:11,711 [run_pretraining.py:  535]:	loss/mlm_loss, 6.7222371101379395, 1704
[INFO] 2021-07-12 19:06:11,711 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.703000089037232e-05, 1704
[INFO] 2021-07-12 19:06:11,712 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1704
[INFO] 2021-07-12 19:06:11,712 [run_pretraining.py:  558]:	worker_index: 6, step: 1704, cost: 6.722237, mlm loss: 6.722237, speed: 1.085690 steps/s, speed: 8.685520 samples/s, speed: 4446.986415 tokens/s, learning rate: 1.703e-05, loss_scalings: 6871.948730, pp_loss: 6.800967
[INFO] 2021-07-12 19:06:11,712 [run_pretraining.py:  512]:	********exe.run_1704******* 
[INFO] 2021-07-12 19:06:12,640 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:12,641 [run_pretraining.py:  534]:	loss/total_loss, 7.294311046600342, 1705
[INFO] 2021-07-12 19:06:12,641 [run_pretraining.py:  535]:	loss/mlm_loss, 7.294311046600342, 1705
[INFO] 2021-07-12 19:06:12,641 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.703999805613421e-05, 1705
[INFO] 2021-07-12 19:06:12,641 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1705
[INFO] 2021-07-12 19:06:12,641 [run_pretraining.py:  558]:	worker_index: 6, step: 1705, cost: 7.294311, mlm loss: 7.294311, speed: 1.076604 steps/s, speed: 8.612835 samples/s, speed: 4409.771282 tokens/s, learning rate: 1.704e-05, loss_scalings: 6871.948730, pp_loss: 7.369033
[INFO] 2021-07-12 19:06:12,641 [run_pretraining.py:  512]:	********exe.run_1705******* 
[INFO] 2021-07-12 19:06:13,559 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:13,560 [run_pretraining.py:  534]:	loss/total_loss, 7.116166591644287, 1706
[INFO] 2021-07-12 19:06:13,560 [run_pretraining.py:  535]:	loss/mlm_loss, 7.116166591644287, 1706
[INFO] 2021-07-12 19:06:13,560 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7049998859874904e-05, 1706
[INFO] 2021-07-12 19:06:13,560 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1706
[INFO] 2021-07-12 19:06:13,561 [run_pretraining.py:  558]:	worker_index: 6, step: 1706, cost: 7.116167, mlm loss: 7.116167, speed: 1.088552 steps/s, speed: 8.708418 samples/s, speed: 4458.710080 tokens/s, learning rate: 1.705e-05, loss_scalings: 6871.948730, pp_loss: 7.127044
[INFO] 2021-07-12 19:06:13,561 [run_pretraining.py:  512]:	********exe.run_1706******* 
[INFO] 2021-07-12 19:06:14,486 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:14,487 [run_pretraining.py:  534]:	loss/total_loss, 6.864790916442871, 1707
[INFO] 2021-07-12 19:06:14,487 [run_pretraining.py:  535]:	loss/mlm_loss, 6.864790916442871, 1707
[INFO] 2021-07-12 19:06:14,487 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.70599996636156e-05, 1707
[INFO] 2021-07-12 19:06:14,487 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1707
[INFO] 2021-07-12 19:06:14,487 [run_pretraining.py:  558]:	worker_index: 6, step: 1707, cost: 6.864791, mlm loss: 6.864791, speed: 1.079901 steps/s, speed: 8.639210 samples/s, speed: 4423.275459 tokens/s, learning rate: 1.706e-05, loss_scalings: 6871.948730, pp_loss: 6.972965
[INFO] 2021-07-12 19:06:14,487 [run_pretraining.py:  512]:	********exe.run_1707******* 
[INFO] 2021-07-12 19:06:15,399 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:15,400 [run_pretraining.py:  534]:	loss/total_loss, 6.688863277435303, 1708
[INFO] 2021-07-12 19:06:15,400 [run_pretraining.py:  535]:	loss/mlm_loss, 6.688863277435303, 1708
[INFO] 2021-07-12 19:06:15,400 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.706999864836689e-05, 1708
[INFO] 2021-07-12 19:06:15,400 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1708
[INFO] 2021-07-12 19:06:15,400 [run_pretraining.py:  558]:	worker_index: 6, step: 1708, cost: 6.688863, mlm loss: 6.688863, speed: 1.095891 steps/s, speed: 8.767131 samples/s, speed: 4488.771111 tokens/s, learning rate: 1.707e-05, loss_scalings: 6871.948730, pp_loss: 7.144208
[INFO] 2021-07-12 19:06:15,400 [run_pretraining.py:  512]:	********exe.run_1708******* 
[INFO] 2021-07-12 19:06:16,327 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:16,327 [run_pretraining.py:  534]:	loss/total_loss, 9.074806213378906, 1709
[INFO] 2021-07-12 19:06:16,327 [run_pretraining.py:  535]:	loss/mlm_loss, 9.074806213378906, 1709
[INFO] 2021-07-12 19:06:16,327 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7079999452107586e-05, 1709
[INFO] 2021-07-12 19:06:16,327 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1709
[INFO] 2021-07-12 19:06:16,328 [run_pretraining.py:  558]:	worker_index: 6, step: 1709, cost: 9.074806, mlm loss: 9.074806, speed: 1.079386 steps/s, speed: 8.635088 samples/s, speed: 4421.165031 tokens/s, learning rate: 1.708e-05, loss_scalings: 6871.948730, pp_loss: 7.783970
[INFO] 2021-07-12 19:06:16,328 [run_pretraining.py:  512]:	********exe.run_1709******* 
[INFO] 2021-07-12 19:06:17,250 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:17,251 [run_pretraining.py:  534]:	loss/total_loss, 7.118053436279297, 1710
[INFO] 2021-07-12 19:06:17,251 [run_pretraining.py:  535]:	loss/mlm_loss, 7.118053436279297, 1710
[INFO] 2021-07-12 19:06:17,251 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.709000025584828e-05, 1710
[INFO] 2021-07-12 19:06:17,251 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1710
[INFO] 2021-07-12 19:06:17,251 [run_pretraining.py:  558]:	worker_index: 6, step: 1710, cost: 7.118053, mlm loss: 7.118053, speed: 1.083244 steps/s, speed: 8.665953 samples/s, speed: 4436.968021 tokens/s, learning rate: 1.709e-05, loss_scalings: 6871.948730, pp_loss: 7.394172
[INFO] 2021-07-12 19:06:17,251 [run_pretraining.py:  512]:	********exe.run_1710******* 
[INFO] 2021-07-12 19:06:18,173 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:18,173 [run_pretraining.py:  534]:	loss/total_loss, 6.796611309051514, 1711
[INFO] 2021-07-12 19:06:18,173 [run_pretraining.py:  535]:	loss/mlm_loss, 6.796611309051514, 1711
[INFO] 2021-07-12 19:06:18,174 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7099999240599573e-05, 1711
[INFO] 2021-07-12 19:06:18,174 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1711
[INFO] 2021-07-12 19:06:18,174 [run_pretraining.py:  558]:	worker_index: 6, step: 1711, cost: 6.796611, mlm loss: 6.796611, speed: 1.085131 steps/s, speed: 8.681049 samples/s, speed: 4444.696912 tokens/s, learning rate: 1.710e-05, loss_scalings: 6871.948730, pp_loss: 7.031742
[INFO] 2021-07-12 19:06:18,174 [run_pretraining.py:  512]:	********exe.run_1711******* 
[INFO] 2021-07-12 19:06:19,097 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:19,098 [run_pretraining.py:  534]:	loss/total_loss, 6.5552167892456055, 1712
[INFO] 2021-07-12 19:06:19,098 [run_pretraining.py:  535]:	loss/mlm_loss, 6.5552167892456055, 1712
[INFO] 2021-07-12 19:06:19,098 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7110000044340268e-05, 1712
[INFO] 2021-07-12 19:06:19,098 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1712
[INFO] 2021-07-12 19:06:19,098 [run_pretraining.py:  558]:	worker_index: 6, step: 1712, cost: 6.555217, mlm loss: 6.555217, speed: 1.082409 steps/s, speed: 8.659273 samples/s, speed: 4433.547808 tokens/s, learning rate: 1.711e-05, loss_scalings: 6871.948730, pp_loss: 7.200061
[INFO] 2021-07-12 19:06:19,098 [run_pretraining.py:  512]:	********exe.run_1712******* 
[INFO] 2021-07-12 19:06:20,046 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:20,047 [run_pretraining.py:  534]:	loss/total_loss, 7.799106597900391, 1713
[INFO] 2021-07-12 19:06:20,047 [run_pretraining.py:  535]:	loss/mlm_loss, 7.799106597900391, 1713
[INFO] 2021-07-12 19:06:20,047 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7120000848080963e-05, 1713
[INFO] 2021-07-12 19:06:20,047 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1713
[INFO] 2021-07-12 19:06:20,047 [run_pretraining.py:  558]:	worker_index: 6, step: 1713, cost: 7.799107, mlm loss: 7.799107, speed: 1.054458 steps/s, speed: 8.435662 samples/s, speed: 4319.059007 tokens/s, learning rate: 1.712e-05, loss_scalings: 6871.948730, pp_loss: 7.305814
[INFO] 2021-07-12 19:06:20,047 [run_pretraining.py:  512]:	********exe.run_1713******* 
[INFO] 2021-07-12 19:06:20,982 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:20,982 [run_pretraining.py:  534]:	loss/total_loss, 7.068667411804199, 1714
[INFO] 2021-07-12 19:06:20,982 [run_pretraining.py:  535]:	loss/mlm_loss, 7.068667411804199, 1714
[INFO] 2021-07-12 19:06:20,982 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7129999832832254e-05, 1714
[INFO] 2021-07-12 19:06:20,982 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1714
[INFO] 2021-07-12 19:06:20,983 [run_pretraining.py:  558]:	worker_index: 6, step: 1714, cost: 7.068667, mlm loss: 7.068667, speed: 1.070096 steps/s, speed: 8.560772 samples/s, speed: 4383.115027 tokens/s, learning rate: 1.713e-05, loss_scalings: 6871.948730, pp_loss: 7.224207
[INFO] 2021-07-12 19:06:20,983 [run_pretraining.py:  512]:	********exe.run_1714******* 
[INFO] 2021-07-12 19:06:21,907 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:21,908 [run_pretraining.py:  534]:	loss/total_loss, 7.386273384094238, 1715
[INFO] 2021-07-12 19:06:21,908 [run_pretraining.py:  535]:	loss/mlm_loss, 7.386273384094238, 1715
[INFO] 2021-07-12 19:06:21,908 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7139998817583546e-05, 1715
[INFO] 2021-07-12 19:06:21,908 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1715
[INFO] 2021-07-12 19:06:21,908 [run_pretraining.py:  558]:	worker_index: 6, step: 1715, cost: 7.386273, mlm loss: 7.386273, speed: 1.081273 steps/s, speed: 8.650183 samples/s, speed: 4428.893720 tokens/s, learning rate: 1.714e-05, loss_scalings: 6871.948730, pp_loss: 7.149220
[INFO] 2021-07-12 19:06:21,908 [run_pretraining.py:  512]:	********exe.run_1715******* 
[INFO] 2021-07-12 19:06:22,824 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:22,824 [run_pretraining.py:  534]:	loss/total_loss, 7.07208251953125, 1716
[INFO] 2021-07-12 19:06:22,825 [run_pretraining.py:  535]:	loss/mlm_loss, 7.07208251953125, 1716
[INFO] 2021-07-12 19:06:22,825 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.714999962132424e-05, 1716
[INFO] 2021-07-12 19:06:22,825 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1716
[INFO] 2021-07-12 19:06:22,825 [run_pretraining.py:  558]:	worker_index: 6, step: 1716, cost: 7.072083, mlm loss: 7.072083, speed: 1.091658 steps/s, speed: 8.733266 samples/s, speed: 4471.432375 tokens/s, learning rate: 1.715e-05, loss_scalings: 6871.948730, pp_loss: 7.101920
[INFO] 2021-07-12 19:06:22,825 [run_pretraining.py:  512]:	********exe.run_1716******* 
[INFO] 2021-07-12 19:06:23,876 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:23,876 [run_pretraining.py:  534]:	loss/total_loss, 6.878959655761719, 1717
[INFO] 2021-07-12 19:06:23,877 [run_pretraining.py:  535]:	loss/mlm_loss, 6.878959655761719, 1717
[INFO] 2021-07-12 19:06:23,877 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7159998606075533e-05, 1717
[INFO] 2021-07-12 19:06:23,877 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1717
[INFO] 2021-07-12 19:06:23,877 [run_pretraining.py:  558]:	worker_index: 6, step: 1717, cost: 6.878960, mlm loss: 6.878960, speed: 0.951183 steps/s, speed: 7.609462 samples/s, speed: 3896.044483 tokens/s, learning rate: 1.716e-05, loss_scalings: 6871.948730, pp_loss: 7.146239
[INFO] 2021-07-12 19:06:23,877 [run_pretraining.py:  512]:	********exe.run_1717******* 
[INFO] 2021-07-12 19:06:24,940 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:24,940 [run_pretraining.py:  534]:	loss/total_loss, 7.340872287750244, 1718
[INFO] 2021-07-12 19:06:24,940 [run_pretraining.py:  535]:	loss/mlm_loss, 7.340872287750244, 1718
[INFO] 2021-07-12 19:06:24,940 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7169999409816228e-05, 1718
[INFO] 2021-07-12 19:06:24,941 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1718
[INFO] 2021-07-12 19:06:24,941 [run_pretraining.py:  558]:	worker_index: 6, step: 1718, cost: 7.340872, mlm loss: 7.340872, speed: 0.940646 steps/s, speed: 7.525168 samples/s, speed: 3852.886173 tokens/s, learning rate: 1.717e-05, loss_scalings: 6871.948730, pp_loss: 7.108447
[INFO] 2021-07-12 19:06:24,941 [run_pretraining.py:  512]:	********exe.run_1718******* 
[INFO] 2021-07-12 19:06:26,005 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:26,006 [run_pretraining.py:  534]:	loss/total_loss, 6.739404201507568, 1719
[INFO] 2021-07-12 19:06:26,006 [run_pretraining.py:  535]:	loss/mlm_loss, 6.739404201507568, 1719
[INFO] 2021-07-12 19:06:26,006 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7180000213556923e-05, 1719
[INFO] 2021-07-12 19:06:26,006 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1719
[INFO] 2021-07-12 19:06:26,006 [run_pretraining.py:  558]:	worker_index: 6, step: 1719, cost: 6.739404, mlm loss: 6.739404, speed: 0.939281 steps/s, speed: 7.514252 samples/s, speed: 3847.296802 tokens/s, learning rate: 1.718e-05, loss_scalings: 6871.948730, pp_loss: 7.134202
[INFO] 2021-07-12 19:06:26,006 [run_pretraining.py:  512]:	********exe.run_1719******* 
[INFO] 2021-07-12 19:06:27,061 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:27,061 [run_pretraining.py:  534]:	loss/total_loss, 7.5205078125, 1720
[INFO] 2021-07-12 19:06:27,061 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5205078125, 1720
[INFO] 2021-07-12 19:06:27,061 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7189999198308215e-05, 1720
[INFO] 2021-07-12 19:06:27,062 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1720
[INFO] 2021-07-12 19:06:27,062 [run_pretraining.py:  558]:	worker_index: 6, step: 1720, cost: 7.520508, mlm loss: 7.520508, speed: 0.947810 steps/s, speed: 7.582484 samples/s, speed: 3882.231714 tokens/s, learning rate: 1.719e-05, loss_scalings: 6871.948730, pp_loss: 7.578069
[INFO] 2021-07-12 19:06:27,062 [run_pretraining.py:  512]:	********exe.run_1720******* 
[INFO] 2021-07-12 19:06:28,134 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:28,134 [run_pretraining.py:  534]:	loss/total_loss, 7.106209754943848, 1721
[INFO] 2021-07-12 19:06:28,134 [run_pretraining.py:  535]:	loss/mlm_loss, 7.106209754943848, 1721
[INFO] 2021-07-12 19:06:28,135 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.720000000204891e-05, 1721
[INFO] 2021-07-12 19:06:28,135 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1721
[INFO] 2021-07-12 19:06:28,135 [run_pretraining.py:  558]:	worker_index: 6, step: 1721, cost: 7.106210, mlm loss: 7.106210, speed: 0.932562 steps/s, speed: 7.460495 samples/s, speed: 3819.773187 tokens/s, learning rate: 1.720e-05, loss_scalings: 6871.948730, pp_loss: 7.549708
[INFO] 2021-07-12 19:06:28,135 [run_pretraining.py:  512]:	********exe.run_1721******* 
[INFO] 2021-07-12 19:06:29,049 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:29,049 [run_pretraining.py:  534]:	loss/total_loss, 6.72146463394165, 1722
[INFO] 2021-07-12 19:06:29,049 [run_pretraining.py:  535]:	loss/mlm_loss, 6.72146463394165, 1722
[INFO] 2021-07-12 19:06:29,050 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.72099989868002e-05, 1722
[INFO] 2021-07-12 19:06:29,050 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1722
[INFO] 2021-07-12 19:06:29,050 [run_pretraining.py:  558]:	worker_index: 6, step: 1722, cost: 6.721465, mlm loss: 6.721465, speed: 1.093669 steps/s, speed: 8.749355 samples/s, speed: 4479.669676 tokens/s, learning rate: 1.721e-05, loss_scalings: 6871.948730, pp_loss: 7.404819
[INFO] 2021-07-12 19:06:29,050 [run_pretraining.py:  512]:	********exe.run_1722******* 
[INFO] 2021-07-12 19:06:29,956 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:29,957 [run_pretraining.py:  534]:	loss/total_loss, 7.233450889587402, 1723
[INFO] 2021-07-12 19:06:29,957 [run_pretraining.py:  535]:	loss/mlm_loss, 7.233450889587402, 1723
[INFO] 2021-07-12 19:06:29,957 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7219999790540896e-05, 1723
[INFO] 2021-07-12 19:06:29,957 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1723
[INFO] 2021-07-12 19:06:29,957 [run_pretraining.py:  558]:	worker_index: 6, step: 1723, cost: 7.233451, mlm loss: 7.233451, speed: 1.102628 steps/s, speed: 8.821026 samples/s, speed: 4516.365162 tokens/s, learning rate: 1.722e-05, loss_scalings: 6871.948730, pp_loss: 7.268564
[INFO] 2021-07-12 19:06:29,957 [run_pretraining.py:  512]:	********exe.run_1723******* 
[INFO] 2021-07-12 19:06:30,872 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:30,873 [run_pretraining.py:  534]:	loss/total_loss, 6.455717086791992, 1724
[INFO] 2021-07-12 19:06:30,873 [run_pretraining.py:  535]:	loss/mlm_loss, 6.455717086791992, 1724
[INFO] 2021-07-12 19:06:30,873 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7229998775292188e-05, 1724
[INFO] 2021-07-12 19:06:30,873 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1724
[INFO] 2021-07-12 19:06:30,873 [run_pretraining.py:  558]:	worker_index: 6, step: 1724, cost: 6.455717, mlm loss: 6.455717, speed: 1.092662 steps/s, speed: 8.741293 samples/s, speed: 4475.541989 tokens/s, learning rate: 1.723e-05, loss_scalings: 6871.948730, pp_loss: 7.102199
[INFO] 2021-07-12 19:06:30,873 [run_pretraining.py:  512]:	********exe.run_1724******* 
[INFO] 2021-07-12 19:06:31,779 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:31,780 [run_pretraining.py:  534]:	loss/total_loss, 6.904361248016357, 1725
[INFO] 2021-07-12 19:06:31,780 [run_pretraining.py:  535]:	loss/mlm_loss, 6.904361248016357, 1725
[INFO] 2021-07-12 19:06:31,780 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7239999579032883e-05, 1725
[INFO] 2021-07-12 19:06:31,780 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1725
[INFO] 2021-07-12 19:06:31,780 [run_pretraining.py:  558]:	worker_index: 6, step: 1725, cost: 6.904361, mlm loss: 6.904361, speed: 1.103683 steps/s, speed: 8.829465 samples/s, speed: 4520.686293 tokens/s, learning rate: 1.724e-05, loss_scalings: 6871.948730, pp_loss: 7.278756
[INFO] 2021-07-12 19:06:31,780 [run_pretraining.py:  512]:	********exe.run_1725******* 
[INFO] 2021-07-12 19:06:32,697 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:32,697 [run_pretraining.py:  534]:	loss/total_loss, 6.5822038650512695, 1726
[INFO] 2021-07-12 19:06:32,697 [run_pretraining.py:  535]:	loss/mlm_loss, 6.5822038650512695, 1726
[INFO] 2021-07-12 19:06:32,698 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7250000382773578e-05, 1726
[INFO] 2021-07-12 19:06:32,698 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1726
[INFO] 2021-07-12 19:06:32,698 [run_pretraining.py:  558]:	worker_index: 6, step: 1726, cost: 6.582204, mlm loss: 6.582204, speed: 1.090455 steps/s, speed: 8.723644 samples/s, speed: 4466.505680 tokens/s, learning rate: 1.725e-05, loss_scalings: 6871.948730, pp_loss: 7.232445
[INFO] 2021-07-12 19:06:32,698 [run_pretraining.py:  512]:	********exe.run_1726******* 
[INFO] 2021-07-12 19:06:33,601 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:33,602 [run_pretraining.py:  534]:	loss/total_loss, 4.315874099731445, 1727
[INFO] 2021-07-12 19:06:33,602 [run_pretraining.py:  535]:	loss/mlm_loss, 4.315874099731445, 1727
[INFO] 2021-07-12 19:06:33,602 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.725999936752487e-05, 1727
[INFO] 2021-07-12 19:06:33,602 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1727
[INFO] 2021-07-12 19:06:33,602 [run_pretraining.py:  558]:	worker_index: 6, step: 1727, cost: 4.315874, mlm loss: 4.315874, speed: 1.106870 steps/s, speed: 8.854964 samples/s, speed: 4533.741316 tokens/s, learning rate: 1.726e-05, loss_scalings: 6871.948730, pp_loss: 6.893123
[INFO] 2021-07-12 19:06:33,602 [run_pretraining.py:  512]:	********exe.run_1727******* 
[INFO] 2021-07-12 19:06:34,557 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:34,558 [run_pretraining.py:  534]:	loss/total_loss, 7.525768280029297, 1728
[INFO] 2021-07-12 19:06:34,558 [run_pretraining.py:  535]:	loss/mlm_loss, 7.525768280029297, 1728
[INFO] 2021-07-12 19:06:34,558 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7270000171265565e-05, 1728
[INFO] 2021-07-12 19:06:34,558 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1728
[INFO] 2021-07-12 19:06:34,558 [run_pretraining.py:  558]:	worker_index: 6, step: 1728, cost: 7.525768, mlm loss: 7.525768, speed: 1.046309 steps/s, speed: 8.370471 samples/s, speed: 4285.681296 tokens/s, learning rate: 1.727e-05, loss_scalings: 6871.948730, pp_loss: 7.449349
[INFO] 2021-07-12 19:06:34,558 [run_pretraining.py:  512]:	********exe.run_1728******* 
[INFO] 2021-07-12 19:06:35,606 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:35,606 [run_pretraining.py:  534]:	loss/total_loss, 7.133423328399658, 1729
[INFO] 2021-07-12 19:06:35,606 [run_pretraining.py:  535]:	loss/mlm_loss, 7.133423328399658, 1729
[INFO] 2021-07-12 19:06:35,606 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7279999156016856e-05, 1729
[INFO] 2021-07-12 19:06:35,607 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1729
[INFO] 2021-07-12 19:06:35,607 [run_pretraining.py:  558]:	worker_index: 6, step: 1729, cost: 7.133423, mlm loss: 7.133423, speed: 0.954521 steps/s, speed: 7.636169 samples/s, speed: 3909.718315 tokens/s, learning rate: 1.728e-05, loss_scalings: 6871.948730, pp_loss: 7.353278
[INFO] 2021-07-12 19:06:35,607 [run_pretraining.py:  512]:	********exe.run_1729******* 
[INFO] 2021-07-12 19:06:36,666 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:36,667 [run_pretraining.py:  534]:	loss/total_loss, 6.650412559509277, 1730
[INFO] 2021-07-12 19:06:36,667 [run_pretraining.py:  535]:	loss/mlm_loss, 6.650412559509277, 1730
[INFO] 2021-07-12 19:06:36,667 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.728999995975755e-05, 1730
[INFO] 2021-07-12 19:06:36,667 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1730
[INFO] 2021-07-12 19:06:36,667 [run_pretraining.py:  558]:	worker_index: 6, step: 1730, cost: 6.650413, mlm loss: 6.650413, speed: 0.943391 steps/s, speed: 7.547129 samples/s, speed: 3864.130293 tokens/s, learning rate: 1.729e-05, loss_scalings: 6871.948730, pp_loss: 7.196596
[INFO] 2021-07-12 19:06:36,668 [run_pretraining.py:  512]:	********exe.run_1730******* 
[INFO] 2021-07-12 19:06:37,727 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:37,728 [run_pretraining.py:  534]:	loss/total_loss, 7.5494232177734375, 1731
[INFO] 2021-07-12 19:06:37,728 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5494232177734375, 1731
[INFO] 2021-07-12 19:06:37,728 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7299998944508843e-05, 1731
[INFO] 2021-07-12 19:06:37,728 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1731
[INFO] 2021-07-12 19:06:37,728 [run_pretraining.py:  558]:	worker_index: 6, step: 1731, cost: 7.549423, mlm loss: 7.549423, speed: 0.943345 steps/s, speed: 7.546763 samples/s, speed: 3863.942570 tokens/s, learning rate: 1.730e-05, loss_scalings: 6871.948730, pp_loss: 7.400978
[INFO] 2021-07-12 19:06:37,728 [run_pretraining.py:  512]:	********exe.run_1731******* 
[INFO] 2021-07-12 19:06:38,784 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:38,784 [run_pretraining.py:  534]:	loss/total_loss, 7.518446922302246, 1732
[INFO] 2021-07-12 19:06:38,784 [run_pretraining.py:  535]:	loss/mlm_loss, 7.518446922302246, 1732
[INFO] 2021-07-12 19:06:38,785 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7309999748249538e-05, 1732
[INFO] 2021-07-12 19:06:38,785 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1732
[INFO] 2021-07-12 19:06:38,785 [run_pretraining.py:  558]:	worker_index: 6, step: 1732, cost: 7.518447, mlm loss: 7.518447, speed: 0.947141 steps/s, speed: 7.577124 samples/s, speed: 3879.487738 tokens/s, learning rate: 1.731e-05, loss_scalings: 6871.948730, pp_loss: 7.766125
[INFO] 2021-07-12 19:06:38,785 [run_pretraining.py:  512]:	********exe.run_1732******* 
[INFO] 2021-07-12 19:06:39,835 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:39,836 [run_pretraining.py:  534]:	loss/total_loss, 7.886531352996826, 1733
[INFO] 2021-07-12 19:06:39,836 [run_pretraining.py:  535]:	loss/mlm_loss, 7.886531352996826, 1733
[INFO] 2021-07-12 19:06:39,836 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.731999873300083e-05, 1733
[INFO] 2021-07-12 19:06:39,836 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1733
[INFO] 2021-07-12 19:06:39,836 [run_pretraining.py:  558]:	worker_index: 6, step: 1733, cost: 7.886531, mlm loss: 7.886531, speed: 0.951507 steps/s, speed: 7.612053 samples/s, speed: 3897.371134 tokens/s, learning rate: 1.732e-05, loss_scalings: 6871.948730, pp_loss: 7.534115
[INFO] 2021-07-12 19:06:39,836 [run_pretraining.py:  512]:	********exe.run_1733******* 
[INFO] 2021-07-12 19:06:40,905 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:40,905 [run_pretraining.py:  534]:	loss/total_loss, 7.782116413116455, 1734
[INFO] 2021-07-12 19:06:40,905 [run_pretraining.py:  535]:	loss/mlm_loss, 7.782116413116455, 1734
[INFO] 2021-07-12 19:06:40,905 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7329999536741525e-05, 1734
[INFO] 2021-07-12 19:06:40,906 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1734
[INFO] 2021-07-12 19:06:40,906 [run_pretraining.py:  558]:	worker_index: 6, step: 1734, cost: 7.782116, mlm loss: 7.782116, speed: 0.935847 steps/s, speed: 7.486777 samples/s, speed: 3833.229845 tokens/s, learning rate: 1.733e-05, loss_scalings: 6871.948730, pp_loss: 7.189034
[INFO] 2021-07-12 19:06:40,906 [run_pretraining.py:  512]:	********exe.run_1734******* 
[INFO] 2021-07-12 19:06:41,960 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:41,961 [run_pretraining.py:  534]:	loss/total_loss, 7.167351722717285, 1735
[INFO] 2021-07-12 19:06:41,961 [run_pretraining.py:  535]:	loss/mlm_loss, 7.167351722717285, 1735
[INFO] 2021-07-12 19:06:41,961 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.734000034048222e-05, 1735
[INFO] 2021-07-12 19:06:41,961 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1735
[INFO] 2021-07-12 19:06:41,961 [run_pretraining.py:  558]:	worker_index: 6, step: 1735, cost: 7.167352, mlm loss: 7.167352, speed: 0.947835 steps/s, speed: 7.582681 samples/s, speed: 3882.332605 tokens/s, learning rate: 1.734e-05, loss_scalings: 6871.948730, pp_loss: 7.179899
[INFO] 2021-07-12 19:06:41,961 [run_pretraining.py:  512]:	********exe.run_1735******* 
[INFO] 2021-07-12 19:06:43,018 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:43,018 [run_pretraining.py:  534]:	loss/total_loss, 7.468579292297363, 1736
[INFO] 2021-07-12 19:06:43,018 [run_pretraining.py:  535]:	loss/mlm_loss, 7.468579292297363, 1736
[INFO] 2021-07-12 19:06:43,018 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.734999932523351e-05, 1736
[INFO] 2021-07-12 19:06:43,019 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1736
[INFO] 2021-07-12 19:06:43,019 [run_pretraining.py:  558]:	worker_index: 6, step: 1736, cost: 7.468579, mlm loss: 7.468579, speed: 0.946505 steps/s, speed: 7.572038 samples/s, speed: 3876.883238 tokens/s, learning rate: 1.735e-05, loss_scalings: 6871.948730, pp_loss: 7.462525
[INFO] 2021-07-12 19:06:43,019 [run_pretraining.py:  512]:	********exe.run_1736******* 
[INFO] 2021-07-12 19:06:44,074 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:44,075 [run_pretraining.py:  534]:	loss/total_loss, 6.368268966674805, 1737
[INFO] 2021-07-12 19:06:44,075 [run_pretraining.py:  535]:	loss/mlm_loss, 6.368268966674805, 1737
[INFO] 2021-07-12 19:06:44,075 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7360000128974207e-05, 1737
[INFO] 2021-07-12 19:06:44,075 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1737
[INFO] 2021-07-12 19:06:44,075 [run_pretraining.py:  558]:	worker_index: 6, step: 1737, cost: 6.368269, mlm loss: 6.368269, speed: 0.946846 steps/s, speed: 7.574767 samples/s, speed: 3878.280916 tokens/s, learning rate: 1.736e-05, loss_scalings: 6871.948730, pp_loss: 7.126459
[INFO] 2021-07-12 19:06:44,076 [run_pretraining.py:  512]:	********exe.run_1737******* 
[INFO] 2021-07-12 19:06:45,137 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:45,137 [run_pretraining.py:  534]:	loss/total_loss, 7.279303550720215, 1738
[INFO] 2021-07-12 19:06:45,137 [run_pretraining.py:  535]:	loss/mlm_loss, 7.279303550720215, 1738
[INFO] 2021-07-12 19:06:45,137 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7370000932714902e-05, 1738
[INFO] 2021-07-12 19:06:45,137 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1738
[INFO] 2021-07-12 19:06:45,137 [run_pretraining.py:  558]:	worker_index: 6, step: 1738, cost: 7.279304, mlm loss: 7.279304, speed: 0.942186 steps/s, speed: 7.537488 samples/s, speed: 3859.193877 tokens/s, learning rate: 1.737e-05, loss_scalings: 6871.948730, pp_loss: 7.690563
[INFO] 2021-07-12 19:06:45,138 [run_pretraining.py:  512]:	********exe.run_1738******* 
[INFO] 2021-07-12 19:06:46,187 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:46,188 [run_pretraining.py:  534]:	loss/total_loss, 7.635818958282471, 1739
[INFO] 2021-07-12 19:06:46,188 [run_pretraining.py:  535]:	loss/mlm_loss, 7.635818958282471, 1739
[INFO] 2021-07-12 19:06:46,188 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7379999917466193e-05, 1739
[INFO] 2021-07-12 19:06:46,188 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1739
[INFO] 2021-07-12 19:06:46,188 [run_pretraining.py:  558]:	worker_index: 6, step: 1739, cost: 7.635819, mlm loss: 7.635819, speed: 0.952275 steps/s, speed: 7.618200 samples/s, speed: 3900.518579 tokens/s, learning rate: 1.738e-05, loss_scalings: 6871.948730, pp_loss: 7.140367
[INFO] 2021-07-12 19:06:46,188 [run_pretraining.py:  512]:	********exe.run_1739******* 
[INFO] 2021-07-12 19:06:47,255 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:47,255 [run_pretraining.py:  534]:	loss/total_loss, 6.709833145141602, 1740
[INFO] 2021-07-12 19:06:47,255 [run_pretraining.py:  535]:	loss/mlm_loss, 6.709833145141602, 1740
[INFO] 2021-07-12 19:06:47,255 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7389998902217485e-05, 1740
[INFO] 2021-07-12 19:06:47,256 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1740
[INFO] 2021-07-12 19:06:47,256 [run_pretraining.py:  558]:	worker_index: 6, step: 1740, cost: 6.709833, mlm loss: 6.709833, speed: 0.937569 steps/s, speed: 7.500552 samples/s, speed: 3840.282633 tokens/s, learning rate: 1.739e-05, loss_scalings: 6871.948730, pp_loss: 7.506679
[INFO] 2021-07-12 19:06:47,256 [run_pretraining.py:  512]:	********exe.run_1740******* 
[INFO] 2021-07-12 19:06:48,310 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:48,310 [run_pretraining.py:  534]:	loss/total_loss, 7.103058815002441, 1741
[INFO] 2021-07-12 19:06:48,310 [run_pretraining.py:  535]:	loss/mlm_loss, 7.103058815002441, 1741
[INFO] 2021-07-12 19:06:48,310 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.739999970595818e-05, 1741
[INFO] 2021-07-12 19:06:48,310 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1741
[INFO] 2021-07-12 19:06:48,311 [run_pretraining.py:  558]:	worker_index: 6, step: 1741, cost: 7.103059, mlm loss: 7.103059, speed: 0.948559 steps/s, speed: 7.588472 samples/s, speed: 3885.297629 tokens/s, learning rate: 1.740e-05, loss_scalings: 6871.948730, pp_loss: 7.083515
[INFO] 2021-07-12 19:06:48,311 [run_pretraining.py:  512]:	********exe.run_1741******* 
[INFO] 2021-07-12 19:07:13,833 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:13,834 [run_pretraining.py:  534]:	loss/total_loss, 5.463553428649902, 1742
[INFO] 2021-07-12 19:07:13,834 [run_pretraining.py:  535]:	loss/mlm_loss, 5.463553428649902, 1742
[INFO] 2021-07-12 19:07:13,834 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7409998690709472e-05, 1742
[INFO] 2021-07-12 19:07:13,834 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1742
[INFO] 2021-07-12 19:07:13,834 [run_pretraining.py:  558]:	worker_index: 6, step: 1742, cost: 5.463553, mlm loss: 5.463553, speed: 0.039181 steps/s, speed: 0.313447 samples/s, speed: 160.484847 tokens/s, learning rate: 1.741e-05, loss_scalings: 6871.948730, pp_loss: 6.678438
[INFO] 2021-07-12 19:07:13,834 [run_pretraining.py:  512]:	********exe.run_1742******* 
[INFO] 2021-07-12 19:07:14,840 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:14,841 [run_pretraining.py:  534]:	loss/total_loss, 7.842060565948486, 1743
[INFO] 2021-07-12 19:07:14,841 [run_pretraining.py:  535]:	loss/mlm_loss, 7.842060565948486, 1743
[INFO] 2021-07-12 19:07:14,841 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7419999494450167e-05, 1743
[INFO] 2021-07-12 19:07:14,841 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1743
[INFO] 2021-07-12 19:07:14,841 [run_pretraining.py:  558]:	worker_index: 6, step: 1743, cost: 7.842061, mlm loss: 7.842061, speed: 0.993593 steps/s, speed: 7.948741 samples/s, speed: 4069.755184 tokens/s, learning rate: 1.742e-05, loss_scalings: 6871.948730, pp_loss: 7.687335
[INFO] 2021-07-12 19:07:14,841 [run_pretraining.py:  512]:	********exe.run_1743******* 
[INFO] 2021-07-12 19:07:15,799 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:15,799 [run_pretraining.py:  534]:	loss/total_loss, 7.170647621154785, 1744
[INFO] 2021-07-12 19:07:15,799 [run_pretraining.py:  535]:	loss/mlm_loss, 7.170647621154785, 1744
[INFO] 2021-07-12 19:07:15,800 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7430000298190862e-05, 1744
[INFO] 2021-07-12 19:07:15,800 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1744
[INFO] 2021-07-12 19:07:15,800 [run_pretraining.py:  558]:	worker_index: 6, step: 1744, cost: 7.170648, mlm loss: 7.170648, speed: 1.043890 steps/s, speed: 8.351122 samples/s, speed: 4275.774414 tokens/s, learning rate: 1.743e-05, loss_scalings: 6871.948730, pp_loss: 6.433045
[INFO] 2021-07-12 19:07:15,800 [run_pretraining.py:  512]:	********exe.run_1744******* 
[INFO] 2021-07-12 19:07:16,758 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:16,758 [run_pretraining.py:  534]:	loss/total_loss, 7.129105567932129, 1745
[INFO] 2021-07-12 19:07:16,758 [run_pretraining.py:  535]:	loss/mlm_loss, 7.129105567932129, 1745
[INFO] 2021-07-12 19:07:16,759 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7439999282942154e-05, 1745
[INFO] 2021-07-12 19:07:16,759 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1745
[INFO] 2021-07-12 19:07:16,759 [run_pretraining.py:  558]:	worker_index: 6, step: 1745, cost: 7.129106, mlm loss: 7.129106, speed: 1.043578 steps/s, speed: 8.348624 samples/s, speed: 4274.495668 tokens/s, learning rate: 1.744e-05, loss_scalings: 6871.948730, pp_loss: 7.161480
[INFO] 2021-07-12 19:07:16,759 [run_pretraining.py:  512]:	********exe.run_1745******* 
[INFO] 2021-07-12 19:07:17,792 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:17,792 [run_pretraining.py:  534]:	loss/total_loss, 6.929568290710449, 1746
[INFO] 2021-07-12 19:07:17,793 [run_pretraining.py:  535]:	loss/mlm_loss, 6.929568290710449, 1746
[INFO] 2021-07-12 19:07:17,793 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.745000008668285e-05, 1746
[INFO] 2021-07-12 19:07:17,793 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1746
[INFO] 2021-07-12 19:07:17,793 [run_pretraining.py:  558]:	worker_index: 6, step: 1746, cost: 6.929568, mlm loss: 6.929568, speed: 0.967647 steps/s, speed: 7.741177 samples/s, speed: 3963.482434 tokens/s, learning rate: 1.745e-05, loss_scalings: 6871.948730, pp_loss: 7.227918
[INFO] 2021-07-12 19:07:17,793 [run_pretraining.py:  512]:	********exe.run_1746******* 
[INFO] 2021-07-12 19:07:18,733 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:18,734 [run_pretraining.py:  534]:	loss/total_loss, 7.0206170082092285, 1747
[INFO] 2021-07-12 19:07:18,734 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0206170082092285, 1747
[INFO] 2021-07-12 19:07:18,734 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7460000890423544e-05, 1747
[INFO] 2021-07-12 19:07:18,734 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1747
[INFO] 2021-07-12 19:07:18,734 [run_pretraining.py:  558]:	worker_index: 6, step: 1747, cost: 7.020617, mlm loss: 7.020617, speed: 1.062931 steps/s, speed: 8.503447 samples/s, speed: 4353.764891 tokens/s, learning rate: 1.746e-05, loss_scalings: 6871.948730, pp_loss: 7.221549
[INFO] 2021-07-12 19:07:18,734 [run_pretraining.py:  512]:	********exe.run_1747******* 
[INFO] 2021-07-12 19:07:19,668 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:19,669 [run_pretraining.py:  534]:	loss/total_loss, 7.626330375671387, 1748
[INFO] 2021-07-12 19:07:19,669 [run_pretraining.py:  535]:	loss/mlm_loss, 7.626330375671387, 1748
[INFO] 2021-07-12 19:07:19,669 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7469999875174835e-05, 1748
[INFO] 2021-07-12 19:07:19,669 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1748
[INFO] 2021-07-12 19:07:19,669 [run_pretraining.py:  558]:	worker_index: 6, step: 1748, cost: 7.626330, mlm loss: 7.626330, speed: 1.070209 steps/s, speed: 8.561671 samples/s, speed: 4383.575801 tokens/s, learning rate: 1.747e-05, loss_scalings: 6871.948730, pp_loss: 7.435248
[INFO] 2021-07-12 19:07:19,670 [run_pretraining.py:  512]:	********exe.run_1748******* 
[INFO] 2021-07-12 19:07:20,602 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:20,602 [run_pretraining.py:  534]:	loss/total_loss, 6.806582927703857, 1749
[INFO] 2021-07-12 19:07:20,602 [run_pretraining.py:  535]:	loss/mlm_loss, 6.806582927703857, 1749
[INFO] 2021-07-12 19:07:20,602 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7479998859926127e-05, 1749
[INFO] 2021-07-12 19:07:20,602 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1749
[INFO] 2021-07-12 19:07:20,603 [run_pretraining.py:  558]:	worker_index: 6, step: 1749, cost: 6.806583, mlm loss: 6.806583, speed: 1.072521 steps/s, speed: 8.580164 samples/s, speed: 4393.044204 tokens/s, learning rate: 1.748e-05, loss_scalings: 6871.948730, pp_loss: 7.069185
[INFO] 2021-07-12 19:07:20,603 [run_pretraining.py:  512]:	********exe.run_1749******* 
[INFO] 2021-07-12 19:07:21,537 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:21,537 [run_pretraining.py:  534]:	loss/total_loss, 7.524014472961426, 1750
[INFO] 2021-07-12 19:07:21,538 [run_pretraining.py:  535]:	loss/mlm_loss, 7.524014472961426, 1750
[INFO] 2021-07-12 19:07:21,538 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7489999663666822e-05, 1750
[INFO] 2021-07-12 19:07:21,538 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1750
[INFO] 2021-07-12 19:07:21,538 [run_pretraining.py:  558]:	worker_index: 6, step: 1750, cost: 7.524014, mlm loss: 7.524014, speed: 1.069943 steps/s, speed: 8.559546 samples/s, speed: 4382.487768 tokens/s, learning rate: 1.749e-05, loss_scalings: 6871.948730, pp_loss: 7.492739
[INFO] 2021-07-12 19:07:21,538 [run_pretraining.py:  512]:	********exe.run_1750******* 
[INFO] 2021-07-12 19:07:22,464 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:22,464 [run_pretraining.py:  534]:	loss/total_loss, 7.767534255981445, 1751
[INFO] 2021-07-12 19:07:22,464 [run_pretraining.py:  535]:	loss/mlm_loss, 7.767534255981445, 1751
[INFO] 2021-07-12 19:07:22,464 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7499998648418114e-05, 1751
[INFO] 2021-07-12 19:07:22,465 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1751
[INFO] 2021-07-12 19:07:22,465 [run_pretraining.py:  558]:	worker_index: 6, step: 1751, cost: 7.767534, mlm loss: 7.767534, speed: 1.079888 steps/s, speed: 8.639105 samples/s, speed: 4423.221933 tokens/s, learning rate: 1.750e-05, loss_scalings: 6871.948730, pp_loss: 7.411916
[INFO] 2021-07-12 19:07:22,465 [run_pretraining.py:  512]:	********exe.run_1751******* 
[INFO] 2021-07-12 19:07:23,391 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:23,392 [run_pretraining.py:  534]:	loss/total_loss, 7.354836463928223, 1752
[INFO] 2021-07-12 19:07:23,392 [run_pretraining.py:  535]:	loss/mlm_loss, 7.354836463928223, 1752
[INFO] 2021-07-12 19:07:23,392 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.750999945215881e-05, 1752
[INFO] 2021-07-12 19:07:23,392 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1752
[INFO] 2021-07-12 19:07:23,392 [run_pretraining.py:  558]:	worker_index: 6, step: 1752, cost: 7.354836, mlm loss: 7.354836, speed: 1.078879 steps/s, speed: 8.631034 samples/s, speed: 4419.089579 tokens/s, learning rate: 1.751e-05, loss_scalings: 6871.948730, pp_loss: 7.454665
[INFO] 2021-07-12 19:07:23,392 [run_pretraining.py:  512]:	********exe.run_1752******* 
[INFO] 2021-07-12 19:07:24,328 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:24,328 [run_pretraining.py:  534]:	loss/total_loss, 7.819103717803955, 1753
[INFO] 2021-07-12 19:07:24,328 [run_pretraining.py:  535]:	loss/mlm_loss, 7.819103717803955, 1753
[INFO] 2021-07-12 19:07:24,328 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7520000255899504e-05, 1753
[INFO] 2021-07-12 19:07:24,329 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1753
[INFO] 2021-07-12 19:07:24,329 [run_pretraining.py:  558]:	worker_index: 6, step: 1753, cost: 7.819104, mlm loss: 7.819104, speed: 1.068692 steps/s, speed: 8.549536 samples/s, speed: 4377.362388 tokens/s, learning rate: 1.752e-05, loss_scalings: 6871.948730, pp_loss: 7.003345
[INFO] 2021-07-12 19:07:24,329 [run_pretraining.py:  512]:	********exe.run_1753******* 
[INFO] 2021-07-12 19:07:25,262 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:25,263 [run_pretraining.py:  534]:	loss/total_loss, 8.09266185760498, 1754
[INFO] 2021-07-12 19:07:25,263 [run_pretraining.py:  535]:	loss/mlm_loss, 8.09266185760498, 1754
[INFO] 2021-07-12 19:07:25,263 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7529999240650795e-05, 1754
[INFO] 2021-07-12 19:07:25,263 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1754
[INFO] 2021-07-12 19:07:25,263 [run_pretraining.py:  558]:	worker_index: 6, step: 1754, cost: 8.092662, mlm loss: 8.092662, speed: 1.070671 steps/s, speed: 8.565365 samples/s, speed: 4385.466887 tokens/s, learning rate: 1.753e-05, loss_scalings: 6871.948730, pp_loss: 7.233889
[INFO] 2021-07-12 19:07:25,263 [run_pretraining.py:  512]:	********exe.run_1754******* 
[INFO] 2021-07-12 19:07:26,194 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:26,194 [run_pretraining.py:  534]:	loss/total_loss, 7.4268341064453125, 1755
[INFO] 2021-07-12 19:07:26,194 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4268341064453125, 1755
[INFO] 2021-07-12 19:07:26,194 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.754000004439149e-05, 1755
[INFO] 2021-07-12 19:07:26,194 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1755
[INFO] 2021-07-12 19:07:26,195 [run_pretraining.py:  558]:	worker_index: 6, step: 1755, cost: 7.426834, mlm loss: 7.426834, speed: 1.074772 steps/s, speed: 8.598173 samples/s, speed: 4402.264796 tokens/s, learning rate: 1.754e-05, loss_scalings: 6871.948730, pp_loss: 7.342331
[INFO] 2021-07-12 19:07:26,195 [run_pretraining.py:  512]:	********exe.run_1755******* 
[INFO] 2021-07-12 19:07:27,121 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:27,122 [run_pretraining.py:  534]:	loss/total_loss, 6.904026031494141, 1756
[INFO] 2021-07-12 19:07:27,122 [run_pretraining.py:  535]:	loss/mlm_loss, 6.904026031494141, 1756
[INFO] 2021-07-12 19:07:27,122 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7550000848132186e-05, 1756
[INFO] 2021-07-12 19:07:27,122 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1756
[INFO] 2021-07-12 19:07:27,122 [run_pretraining.py:  558]:	worker_index: 6, step: 1756, cost: 6.904026, mlm loss: 6.904026, speed: 1.078499 steps/s, speed: 8.627989 samples/s, speed: 4417.530577 tokens/s, learning rate: 1.755e-05, loss_scalings: 6871.948730, pp_loss: 7.014208
[INFO] 2021-07-12 19:07:27,122 [run_pretraining.py:  512]:	********exe.run_1756******* 
[INFO] 2021-07-12 19:07:28,058 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:28,059 [run_pretraining.py:  534]:	loss/total_loss, 7.928849697113037, 1757
[INFO] 2021-07-12 19:07:28,059 [run_pretraining.py:  535]:	loss/mlm_loss, 7.928849697113037, 1757
[INFO] 2021-07-12 19:07:28,059 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7559999832883477e-05, 1757
[INFO] 2021-07-12 19:07:28,059 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1757
[INFO] 2021-07-12 19:07:28,059 [run_pretraining.py:  558]:	worker_index: 6, step: 1757, cost: 7.928850, mlm loss: 7.928850, speed: 1.068633 steps/s, speed: 8.549068 samples/s, speed: 4377.122604 tokens/s, learning rate: 1.756e-05, loss_scalings: 6871.948730, pp_loss: 7.221749
[INFO] 2021-07-12 19:07:28,059 [run_pretraining.py:  512]:	********exe.run_1757******* 
[INFO] 2021-07-12 19:07:28,987 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:28,988 [run_pretraining.py:  534]:	loss/total_loss, 8.409467697143555, 1758
[INFO] 2021-07-12 19:07:28,988 [run_pretraining.py:  535]:	loss/mlm_loss, 8.409467697143555, 1758
[INFO] 2021-07-12 19:07:28,988 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.756999881763477e-05, 1758
[INFO] 2021-07-12 19:07:28,988 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1758
[INFO] 2021-07-12 19:07:28,988 [run_pretraining.py:  558]:	worker_index: 6, step: 1758, cost: 8.409468, mlm loss: 8.409468, speed: 1.077013 steps/s, speed: 8.616105 samples/s, speed: 4411.446014 tokens/s, learning rate: 1.757e-05, loss_scalings: 6871.948730, pp_loss: 7.814198
[INFO] 2021-07-12 19:07:28,988 [run_pretraining.py:  512]:	********exe.run_1758******* 
[INFO] 2021-07-12 19:07:29,912 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:29,913 [run_pretraining.py:  534]:	loss/total_loss, 7.255754470825195, 1759
[INFO] 2021-07-12 19:07:29,913 [run_pretraining.py:  535]:	loss/mlm_loss, 7.255754470825195, 1759
[INFO] 2021-07-12 19:07:29,913 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7579999621375464e-05, 1759
[INFO] 2021-07-12 19:07:29,913 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1759
[INFO] 2021-07-12 19:07:29,913 [run_pretraining.py:  558]:	worker_index: 6, step: 1759, cost: 7.255754, mlm loss: 7.255754, speed: 1.081694 steps/s, speed: 8.653549 samples/s, speed: 4430.617290 tokens/s, learning rate: 1.758e-05, loss_scalings: 6871.948730, pp_loss: 7.199547
[INFO] 2021-07-12 19:07:29,913 [run_pretraining.py:  512]:	********exe.run_1759******* 
[INFO] 2021-07-12 19:07:30,831 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:30,832 [run_pretraining.py:  534]:	loss/total_loss, 7.362082481384277, 1760
[INFO] 2021-07-12 19:07:30,832 [run_pretraining.py:  535]:	loss/mlm_loss, 7.362082481384277, 1760
[INFO] 2021-07-12 19:07:30,832 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7589998606126755e-05, 1760
[INFO] 2021-07-12 19:07:30,832 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1760
[INFO] 2021-07-12 19:07:30,832 [run_pretraining.py:  558]:	worker_index: 6, step: 1760, cost: 7.362082, mlm loss: 7.362082, speed: 1.089355 steps/s, speed: 8.714844 samples/s, speed: 4462.000036 tokens/s, learning rate: 1.759e-05, loss_scalings: 6871.948730, pp_loss: 7.333027
[INFO] 2021-07-12 19:07:30,832 [run_pretraining.py:  512]:	********exe.run_1760******* 
[INFO] 2021-07-12 19:07:31,811 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:31,812 [run_pretraining.py:  534]:	loss/total_loss, 7.480034828186035, 1761
[INFO] 2021-07-12 19:07:31,812 [run_pretraining.py:  535]:	loss/mlm_loss, 7.480034828186035, 1761
[INFO] 2021-07-12 19:07:31,812 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.759999940986745e-05, 1761
[INFO] 2021-07-12 19:07:31,812 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1761
[INFO] 2021-07-12 19:07:31,812 [run_pretraining.py:  558]:	worker_index: 6, step: 1761, cost: 7.480035, mlm loss: 7.480035, speed: 1.020834 steps/s, speed: 8.166673 samples/s, speed: 4181.336345 tokens/s, learning rate: 1.760e-05, loss_scalings: 6871.948730, pp_loss: 7.585977
[INFO] 2021-07-12 19:07:31,812 [run_pretraining.py:  512]:	********exe.run_1761******* 
[INFO] 2021-07-12 19:07:32,913 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:32,913 [run_pretraining.py:  534]:	loss/total_loss, 5.362587928771973, 1762
[INFO] 2021-07-12 19:07:32,913 [run_pretraining.py:  535]:	loss/mlm_loss, 5.362587928771973, 1762
[INFO] 2021-07-12 19:07:32,913 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7610000213608146e-05, 1762
[INFO] 2021-07-12 19:07:32,914 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1762
[INFO] 2021-07-12 19:07:32,914 [run_pretraining.py:  558]:	worker_index: 6, step: 1762, cost: 5.362588, mlm loss: 5.362588, speed: 0.908524 steps/s, speed: 7.268196 samples/s, speed: 3721.316174 tokens/s, learning rate: 1.761e-05, loss_scalings: 6871.948730, pp_loss: 6.668373
[INFO] 2021-07-12 19:07:32,914 [run_pretraining.py:  512]:	********exe.run_1762******* 
[INFO] 2021-07-12 19:07:34,003 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:34,004 [run_pretraining.py:  534]:	loss/total_loss, 9.650930404663086, 1763
[INFO] 2021-07-12 19:07:34,004 [run_pretraining.py:  535]:	loss/mlm_loss, 9.650930404663086, 1763
[INFO] 2021-07-12 19:07:34,004 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7619999198359437e-05, 1763
[INFO] 2021-07-12 19:07:34,004 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1763
[INFO] 2021-07-12 19:07:34,004 [run_pretraining.py:  558]:	worker_index: 6, step: 1763, cost: 9.650930, mlm loss: 9.650930, speed: 0.917402 steps/s, speed: 7.339217 samples/s, speed: 3757.679282 tokens/s, learning rate: 1.762e-05, loss_scalings: 6871.948730, pp_loss: 7.867831
[INFO] 2021-07-12 19:07:34,004 [run_pretraining.py:  512]:	********exe.run_1763******* 
[INFO] 2021-07-12 19:07:35,104 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:35,105 [run_pretraining.py:  534]:	loss/total_loss, 7.323553085327148, 1764
[INFO] 2021-07-12 19:07:35,105 [run_pretraining.py:  535]:	loss/mlm_loss, 7.323553085327148, 1764
[INFO] 2021-07-12 19:07:35,105 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7630000002100132e-05, 1764
[INFO] 2021-07-12 19:07:35,105 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1764
[INFO] 2021-07-12 19:07:35,105 [run_pretraining.py:  558]:	worker_index: 6, step: 1764, cost: 7.323553, mlm loss: 7.323553, speed: 0.909092 steps/s, speed: 7.272736 samples/s, speed: 3723.640722 tokens/s, learning rate: 1.763e-05, loss_scalings: 6871.948730, pp_loss: 6.930775
[INFO] 2021-07-12 19:07:35,105 [run_pretraining.py:  512]:	********exe.run_1764******* 
[INFO] 2021-07-12 19:07:36,108 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:36,109 [run_pretraining.py:  534]:	loss/total_loss, 7.108379364013672, 1765
[INFO] 2021-07-12 19:07:36,109 [run_pretraining.py:  535]:	loss/mlm_loss, 7.108379364013672, 1765
[INFO] 2021-07-12 19:07:36,109 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7640000805840828e-05, 1765
[INFO] 2021-07-12 19:07:36,109 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1765
[INFO] 2021-07-12 19:07:36,109 [run_pretraining.py:  558]:	worker_index: 6, step: 1765, cost: 7.108379, mlm loss: 7.108379, speed: 0.996369 steps/s, speed: 7.970956 samples/s, speed: 4081.129380 tokens/s, learning rate: 1.764e-05, loss_scalings: 6871.948730, pp_loss: 7.561627
[INFO] 2021-07-12 19:07:36,109 [run_pretraining.py:  512]:	********exe.run_1765******* 
[INFO] 2021-07-12 19:07:37,029 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:37,030 [run_pretraining.py:  534]:	loss/total_loss, 7.414664268493652, 1766
[INFO] 2021-07-12 19:07:37,030 [run_pretraining.py:  535]:	loss/mlm_loss, 7.414664268493652, 1766
[INFO] 2021-07-12 19:07:37,030 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7649997971602716e-05, 1766
[INFO] 2021-07-12 19:07:37,030 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1766
[INFO] 2021-07-12 19:07:37,030 [run_pretraining.py:  558]:	worker_index: 6, step: 1766, cost: 7.414664, mlm loss: 7.414664, speed: 1.086608 steps/s, speed: 8.692867 samples/s, speed: 4450.747924 tokens/s, learning rate: 1.765e-05, loss_scalings: 6871.948730, pp_loss: 7.354566
[INFO] 2021-07-12 19:07:37,030 [run_pretraining.py:  512]:	********exe.run_1766******* 
[INFO] 2021-07-12 19:08:03,473 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:03,474 [run_pretraining.py:  534]:	loss/total_loss, 7.043373107910156, 1767
[INFO] 2021-07-12 19:08:03,474 [run_pretraining.py:  535]:	loss/mlm_loss, 7.043373107910156, 1767
[INFO] 2021-07-12 19:08:03,474 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.765999877534341e-05, 1767
[INFO] 2021-07-12 19:08:03,474 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1767
[INFO] 2021-07-12 19:08:03,474 [run_pretraining.py:  558]:	worker_index: 6, step: 1767, cost: 7.043373, mlm loss: 7.043373, speed: 0.037817 steps/s, speed: 0.302537 samples/s, speed: 154.898713 tokens/s, learning rate: 1.766e-05, loss_scalings: 6871.948730, pp_loss: 7.312682
[INFO] 2021-07-12 19:08:03,474 [run_pretraining.py:  512]:	********exe.run_1767******* 
[INFO] 2021-07-12 19:08:04,424 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:04,425 [run_pretraining.py:  534]:	loss/total_loss, 7.731941223144531, 1768
[INFO] 2021-07-12 19:08:04,425 [run_pretraining.py:  535]:	loss/mlm_loss, 7.731941223144531, 1768
[INFO] 2021-07-12 19:08:04,425 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7669999579084106e-05, 1768
[INFO] 2021-07-12 19:08:04,425 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1768
[INFO] 2021-07-12 19:08:04,425 [run_pretraining.py:  558]:	worker_index: 6, step: 1768, cost: 7.731941, mlm loss: 7.731941, speed: 1.052201 steps/s, speed: 8.417607 samples/s, speed: 4309.814607 tokens/s, learning rate: 1.767e-05, loss_scalings: 6871.948730, pp_loss: 7.275210
[INFO] 2021-07-12 19:08:04,425 [run_pretraining.py:  512]:	********exe.run_1768******* 
[INFO] 2021-07-12 19:08:05,384 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:05,384 [run_pretraining.py:  534]:	loss/total_loss, 7.497385025024414, 1769
[INFO] 2021-07-12 19:08:05,384 [run_pretraining.py:  535]:	loss/mlm_loss, 7.497385025024414, 1769
[INFO] 2021-07-12 19:08:05,384 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7679998563835397e-05, 1769
[INFO] 2021-07-12 19:08:05,385 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1769
[INFO] 2021-07-12 19:08:05,385 [run_pretraining.py:  558]:	worker_index: 6, step: 1769, cost: 7.497385, mlm loss: 7.497385, speed: 1.043196 steps/s, speed: 8.345570 samples/s, speed: 4272.931787 tokens/s, learning rate: 1.768e-05, loss_scalings: 6871.948730, pp_loss: 7.381999
[INFO] 2021-07-12 19:08:05,385 [run_pretraining.py:  512]:	********exe.run_1769******* 
[INFO] 2021-07-12 19:08:06,345 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:06,345 [run_pretraining.py:  534]:	loss/total_loss, 6.852030277252197, 1770
[INFO] 2021-07-12 19:08:06,345 [run_pretraining.py:  535]:	loss/mlm_loss, 6.852030277252197, 1770
[INFO] 2021-07-12 19:08:06,346 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7689999367576092e-05, 1770
[INFO] 2021-07-12 19:08:06,346 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1770
[INFO] 2021-07-12 19:08:06,346 [run_pretraining.py:  558]:	worker_index: 6, step: 1770, cost: 6.852030, mlm loss: 6.852030, speed: 1.041238 steps/s, speed: 8.329903 samples/s, speed: 4264.910340 tokens/s, learning rate: 1.769e-05, loss_scalings: 6871.948730, pp_loss: 7.283490
[INFO] 2021-07-12 19:08:06,346 [run_pretraining.py:  512]:	********exe.run_1770******* 
[INFO] 2021-07-12 19:08:07,303 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:07,304 [run_pretraining.py:  534]:	loss/total_loss, 7.544660568237305, 1771
[INFO] 2021-07-12 19:08:07,304 [run_pretraining.py:  535]:	loss/mlm_loss, 7.544660568237305, 1771
[INFO] 2021-07-12 19:08:07,304 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7700000171316788e-05, 1771
[INFO] 2021-07-12 19:08:07,304 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1771
[INFO] 2021-07-12 19:08:07,304 [run_pretraining.py:  558]:	worker_index: 6, step: 1771, cost: 7.544661, mlm loss: 7.544661, speed: 1.044180 steps/s, speed: 8.353438 samples/s, speed: 4276.960224 tokens/s, learning rate: 1.770e-05, loss_scalings: 6871.948730, pp_loss: 7.260411
[INFO] 2021-07-12 19:08:07,304 [run_pretraining.py:  512]:	********exe.run_1771******* 
[INFO] 2021-07-12 19:08:08,256 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:08,256 [run_pretraining.py:  534]:	loss/total_loss, 7.515185832977295, 1772
[INFO] 2021-07-12 19:08:08,256 [run_pretraining.py:  535]:	loss/mlm_loss, 7.515185832977295, 1772
[INFO] 2021-07-12 19:08:08,256 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.770999915606808e-05, 1772
[INFO] 2021-07-12 19:08:08,256 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1772
[INFO] 2021-07-12 19:08:08,257 [run_pretraining.py:  558]:	worker_index: 6, step: 1772, cost: 7.515186, mlm loss: 7.515186, speed: 1.050779 steps/s, speed: 8.406234 samples/s, speed: 4303.991691 tokens/s, learning rate: 1.771e-05, loss_scalings: 6871.948730, pp_loss: 7.304453
[INFO] 2021-07-12 19:08:08,257 [run_pretraining.py:  512]:	********exe.run_1772******* 
[INFO] 2021-07-12 19:08:09,198 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:09,198 [run_pretraining.py:  534]:	loss/total_loss, 6.793281555175781, 1773
[INFO] 2021-07-12 19:08:09,198 [run_pretraining.py:  535]:	loss/mlm_loss, 6.793281555175781, 1773
[INFO] 2021-07-12 19:08:09,199 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7719999959808774e-05, 1773
[INFO] 2021-07-12 19:08:09,199 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1773
[INFO] 2021-07-12 19:08:09,199 [run_pretraining.py:  558]:	worker_index: 6, step: 1773, cost: 6.793282, mlm loss: 6.793282, speed: 1.062174 steps/s, speed: 8.497389 samples/s, speed: 4350.663401 tokens/s, learning rate: 1.772e-05, loss_scalings: 6871.948730, pp_loss: 7.436855
[INFO] 2021-07-12 19:08:09,199 [run_pretraining.py:  512]:	********exe.run_1773******* 
[INFO] 2021-07-12 19:08:10,132 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:10,133 [run_pretraining.py:  534]:	loss/total_loss, 7.110080242156982, 1774
[INFO] 2021-07-12 19:08:10,133 [run_pretraining.py:  535]:	loss/mlm_loss, 7.110080242156982, 1774
[INFO] 2021-07-12 19:08:10,133 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.773000076354947e-05, 1774
[INFO] 2021-07-12 19:08:10,133 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1774
[INFO] 2021-07-12 19:08:10,133 [run_pretraining.py:  558]:	worker_index: 6, step: 1774, cost: 7.110080, mlm loss: 7.110080, speed: 1.071082 steps/s, speed: 8.568657 samples/s, speed: 4387.152334 tokens/s, learning rate: 1.773e-05, loss_scalings: 6871.948730, pp_loss: 7.304009
[INFO] 2021-07-12 19:08:10,133 [run_pretraining.py:  512]:	********exe.run_1774******* 
[INFO] 2021-07-12 19:08:11,070 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:11,071 [run_pretraining.py:  534]:	loss/total_loss, 7.21390962600708, 1775
[INFO] 2021-07-12 19:08:11,071 [run_pretraining.py:  535]:	loss/mlm_loss, 7.21390962600708, 1775
[INFO] 2021-07-12 19:08:11,071 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.773999974830076e-05, 1775
[INFO] 2021-07-12 19:08:11,071 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1775
[INFO] 2021-07-12 19:08:11,071 [run_pretraining.py:  558]:	worker_index: 6, step: 1775, cost: 7.213910, mlm loss: 7.213910, speed: 1.067051 steps/s, speed: 8.536407 samples/s, speed: 4370.640567 tokens/s, learning rate: 1.774e-05, loss_scalings: 6871.948730, pp_loss: 7.173155
[INFO] 2021-07-12 19:08:11,071 [run_pretraining.py:  512]:	********exe.run_1775******* 
[INFO] 2021-07-12 19:08:12,014 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:12,014 [run_pretraining.py:  534]:	loss/total_loss, 8.465237617492676, 1776
[INFO] 2021-07-12 19:08:12,014 [run_pretraining.py:  535]:	loss/mlm_loss, 8.465237617492676, 1776
[INFO] 2021-07-12 19:08:12,014 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7749998733052053e-05, 1776
[INFO] 2021-07-12 19:08:12,014 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1776
[INFO] 2021-07-12 19:08:12,015 [run_pretraining.py:  558]:	worker_index: 6, step: 1776, cost: 8.465238, mlm loss: 8.465238, speed: 1.060526 steps/s, speed: 8.484208 samples/s, speed: 4343.914525 tokens/s, learning rate: 1.775e-05, loss_scalings: 6871.948730, pp_loss: 7.536025
[INFO] 2021-07-12 19:08:12,015 [run_pretraining.py:  512]:	********exe.run_1776******* 
[INFO] 2021-07-12 19:08:12,957 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:12,957 [run_pretraining.py:  534]:	loss/total_loss, 7.538825988769531, 1777
[INFO] 2021-07-12 19:08:12,958 [run_pretraining.py:  535]:	loss/mlm_loss, 7.538825988769531, 1777
[INFO] 2021-07-12 19:08:12,958 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7759999536792748e-05, 1777
[INFO] 2021-07-12 19:08:12,958 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1777
[INFO] 2021-07-12 19:08:12,958 [run_pretraining.py:  558]:	worker_index: 6, step: 1777, cost: 7.538826, mlm loss: 7.538826, speed: 1.060883 steps/s, speed: 8.487062 samples/s, speed: 4345.375828 tokens/s, learning rate: 1.776e-05, loss_scalings: 6871.948730, pp_loss: 7.129068
[INFO] 2021-07-12 19:08:12,958 [run_pretraining.py:  512]:	********exe.run_1777******* 
[INFO] 2021-07-12 19:08:13,901 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:13,901 [run_pretraining.py:  534]:	loss/total_loss, 7.8442792892456055, 1778
[INFO] 2021-07-12 19:08:13,901 [run_pretraining.py:  535]:	loss/mlm_loss, 7.8442792892456055, 1778
[INFO] 2021-07-12 19:08:13,901 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.776999852154404e-05, 1778
[INFO] 2021-07-12 19:08:13,901 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1778
[INFO] 2021-07-12 19:08:13,902 [run_pretraining.py:  558]:	worker_index: 6, step: 1778, cost: 7.844279, mlm loss: 7.844279, speed: 1.060451 steps/s, speed: 8.483607 samples/s, speed: 4343.607007 tokens/s, learning rate: 1.777e-05, loss_scalings: 6871.948730, pp_loss: 7.314675
[INFO] 2021-07-12 19:08:13,902 [run_pretraining.py:  512]:	********exe.run_1778******* 
[INFO] 2021-07-12 19:08:14,898 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:14,899 [run_pretraining.py:  534]:	loss/total_loss, 7.392616271972656, 1779
[INFO] 2021-07-12 19:08:14,899 [run_pretraining.py:  535]:	loss/mlm_loss, 7.392616271972656, 1779
[INFO] 2021-07-12 19:08:14,899 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7779999325284734e-05, 1779
[INFO] 2021-07-12 19:08:14,899 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1779
[INFO] 2021-07-12 19:08:14,899 [run_pretraining.py:  558]:	worker_index: 6, step: 1779, cost: 7.392616, mlm loss: 7.392616, speed: 1.003320 steps/s, speed: 8.026556 samples/s, speed: 4109.596743 tokens/s, learning rate: 1.778e-05, loss_scalings: 6871.948730, pp_loss: 7.374868
[INFO] 2021-07-12 19:08:14,899 [run_pretraining.py:  512]:	********exe.run_1779******* 
[INFO] 2021-07-12 19:08:15,908 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:15,909 [run_pretraining.py:  534]:	loss/total_loss, 7.525687217712402, 1780
[INFO] 2021-07-12 19:08:15,909 [run_pretraining.py:  535]:	loss/mlm_loss, 7.525687217712402, 1780
[INFO] 2021-07-12 19:08:15,909 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.779000012902543e-05, 1780
[INFO] 2021-07-12 19:08:15,909 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1780
[INFO] 2021-07-12 19:08:15,909 [run_pretraining.py:  558]:	worker_index: 6, step: 1780, cost: 7.525687, mlm loss: 7.525687, speed: 0.990320 steps/s, speed: 7.922561 samples/s, speed: 4056.351410 tokens/s, learning rate: 1.779e-05, loss_scalings: 6871.948730, pp_loss: 7.143592
[INFO] 2021-07-12 19:08:15,910 [run_pretraining.py:  512]:	********exe.run_1780******* 
[INFO] 2021-07-12 19:08:16,987 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:16,988 [run_pretraining.py:  534]:	loss/total_loss, 7.282483100891113, 1781
[INFO] 2021-07-12 19:08:16,988 [run_pretraining.py:  535]:	loss/mlm_loss, 7.282483100891113, 1781
[INFO] 2021-07-12 19:08:16,988 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.779999911377672e-05, 1781
[INFO] 2021-07-12 19:08:16,988 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1781
[INFO] 2021-07-12 19:08:16,988 [run_pretraining.py:  558]:	worker_index: 6, step: 1781, cost: 7.282483, mlm loss: 7.282483, speed: 0.927492 steps/s, speed: 7.419932 samples/s, speed: 3799.005260 tokens/s, learning rate: 1.780e-05, loss_scalings: 6871.948730, pp_loss: 6.895264
[INFO] 2021-07-12 19:08:16,988 [run_pretraining.py:  512]:	********exe.run_1781******* 
[INFO] 2021-07-12 19:08:18,060 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:18,061 [run_pretraining.py:  534]:	loss/total_loss, 7.107940673828125, 1782
[INFO] 2021-07-12 19:08:18,061 [run_pretraining.py:  535]:	loss/mlm_loss, 7.107940673828125, 1782
[INFO] 2021-07-12 19:08:18,061 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7809999917517416e-05, 1782
[INFO] 2021-07-12 19:08:18,061 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1782
[INFO] 2021-07-12 19:08:18,061 [run_pretraining.py:  558]:	worker_index: 6, step: 1782, cost: 7.107941, mlm loss: 7.107941, speed: 0.932746 steps/s, speed: 7.461966 samples/s, speed: 3820.526655 tokens/s, learning rate: 1.781e-05, loss_scalings: 6871.948730, pp_loss: 7.230336
[INFO] 2021-07-12 19:08:18,061 [run_pretraining.py:  512]:	********exe.run_1782******* 
[INFO] 2021-07-12 19:08:19,118 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:19,119 [run_pretraining.py:  534]:	loss/total_loss, 7.209713459014893, 1783
[INFO] 2021-07-12 19:08:19,119 [run_pretraining.py:  535]:	loss/mlm_loss, 7.209713459014893, 1783
[INFO] 2021-07-12 19:08:19,119 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.782000072125811e-05, 1783
[INFO] 2021-07-12 19:08:19,119 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1783
[INFO] 2021-07-12 19:08:19,119 [run_pretraining.py:  558]:	worker_index: 6, step: 1783, cost: 7.209713, mlm loss: 7.209713, speed: 0.945778 steps/s, speed: 7.566220 samples/s, speed: 3873.904832 tokens/s, learning rate: 1.782e-05, loss_scalings: 6871.948730, pp_loss: 7.490259
[INFO] 2021-07-12 19:08:19,119 [run_pretraining.py:  512]:	********exe.run_1783******* 
[INFO] 2021-07-12 19:08:20,188 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:20,189 [run_pretraining.py:  534]:	loss/total_loss, 7.5373215675354, 1784
[INFO] 2021-07-12 19:08:20,189 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5373215675354, 1784
[INFO] 2021-07-12 19:08:20,189 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7829999706009403e-05, 1784
[INFO] 2021-07-12 19:08:20,189 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1784
[INFO] 2021-07-12 19:08:20,189 [run_pretraining.py:  558]:	worker_index: 6, step: 1784, cost: 7.537322, mlm loss: 7.537322, speed: 0.934923 steps/s, speed: 7.479384 samples/s, speed: 3829.444683 tokens/s, learning rate: 1.783e-05, loss_scalings: 6871.948730, pp_loss: 7.587706
[INFO] 2021-07-12 19:08:20,190 [run_pretraining.py:  512]:	********exe.run_1784******* 
[INFO] 2021-07-12 19:08:21,271 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:21,272 [run_pretraining.py:  534]:	loss/total_loss, 7.160896301269531, 1785
[INFO] 2021-07-12 19:08:21,272 [run_pretraining.py:  535]:	loss/mlm_loss, 7.160896301269531, 1785
[INFO] 2021-07-12 19:08:21,272 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7839998690760694e-05, 1785
[INFO] 2021-07-12 19:08:21,272 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1785
[INFO] 2021-07-12 19:08:21,272 [run_pretraining.py:  558]:	worker_index: 6, step: 1785, cost: 7.160896, mlm loss: 7.160896, speed: 0.924181 steps/s, speed: 7.393450 samples/s, speed: 3785.446233 tokens/s, learning rate: 1.784e-05, loss_scalings: 6871.948730, pp_loss: 6.928843
[INFO] 2021-07-12 19:08:21,272 [run_pretraining.py:  512]:	********exe.run_1785******* 
[INFO] 2021-07-12 19:08:22,377 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:22,378 [run_pretraining.py:  534]:	loss/total_loss, 6.663196563720703, 1786
[INFO] 2021-07-12 19:08:22,378 [run_pretraining.py:  535]:	loss/mlm_loss, 6.663196563720703, 1786
[INFO] 2021-07-12 19:08:22,378 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.784999949450139e-05, 1786
[INFO] 2021-07-12 19:08:22,378 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1786
[INFO] 2021-07-12 19:08:22,378 [run_pretraining.py:  558]:	worker_index: 6, step: 1786, cost: 6.663197, mlm loss: 6.663197, speed: 0.904719 steps/s, speed: 7.237753 samples/s, speed: 3705.729447 tokens/s, learning rate: 1.785e-05, loss_scalings: 6871.948730, pp_loss: 7.238420
[INFO] 2021-07-12 19:08:22,378 [run_pretraining.py:  512]:	********exe.run_1786******* 
[INFO] 2021-07-12 19:08:23,592 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:23,593 [run_pretraining.py:  534]:	loss/total_loss, 6.689230442047119, 1787
[INFO] 2021-07-12 19:08:23,593 [run_pretraining.py:  535]:	loss/mlm_loss, 6.689230442047119, 1787
[INFO] 2021-07-12 19:08:23,593 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.785999847925268e-05, 1787
[INFO] 2021-07-12 19:08:23,593 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1787
[INFO] 2021-07-12 19:08:23,593 [run_pretraining.py:  558]:	worker_index: 6, step: 1787, cost: 6.689230, mlm loss: 6.689230, speed: 0.823401 steps/s, speed: 6.587206 samples/s, speed: 3372.649642 tokens/s, learning rate: 1.786e-05, loss_scalings: 6871.948730, pp_loss: 6.394022
[INFO] 2021-07-12 19:08:23,594 [run_pretraining.py:  512]:	********exe.run_1787******* 
[INFO] 2021-07-12 19:08:24,543 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:24,544 [run_pretraining.py:  534]:	loss/total_loss, 7.496937274932861, 1788
[INFO] 2021-07-12 19:08:24,544 [run_pretraining.py:  535]:	loss/mlm_loss, 7.496937274932861, 1788
[INFO] 2021-07-12 19:08:24,544 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7869999282993376e-05, 1788
[INFO] 2021-07-12 19:08:24,544 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1788
[INFO] 2021-07-12 19:08:24,544 [run_pretraining.py:  558]:	worker_index: 6, step: 1788, cost: 7.496937, mlm loss: 7.496937, speed: 1.052816 steps/s, speed: 8.422526 samples/s, speed: 4312.333061 tokens/s, learning rate: 1.787e-05, loss_scalings: 6871.948730, pp_loss: 7.228506
[INFO] 2021-07-12 19:08:24,544 [run_pretraining.py:  512]:	********exe.run_1788******* 
[INFO] 2021-07-12 19:08:25,510 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:25,510 [run_pretraining.py:  534]:	loss/total_loss, 6.51507568359375, 1789
[INFO] 2021-07-12 19:08:25,511 [run_pretraining.py:  535]:	loss/mlm_loss, 6.51507568359375, 1789
[INFO] 2021-07-12 19:08:25,511 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.788000008673407e-05, 1789
[INFO] 2021-07-12 19:08:25,511 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1789
[INFO] 2021-07-12 19:08:25,511 [run_pretraining.py:  558]:	worker_index: 6, step: 1789, cost: 6.515076, mlm loss: 6.515076, speed: 1.035056 steps/s, speed: 8.280449 samples/s, speed: 4239.589774 tokens/s, learning rate: 1.788e-05, loss_scalings: 6871.948730, pp_loss: 7.090619
[INFO] 2021-07-12 19:08:25,511 [run_pretraining.py:  512]:	********exe.run_1789******* 
[INFO] 2021-07-12 19:08:26,458 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:26,458 [run_pretraining.py:  534]:	loss/total_loss, 6.875922203063965, 1790
[INFO] 2021-07-12 19:08:26,459 [run_pretraining.py:  535]:	loss/mlm_loss, 6.875922203063965, 1790
[INFO] 2021-07-12 19:08:26,459 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7889999071485363e-05, 1790
[INFO] 2021-07-12 19:08:26,459 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1790
[INFO] 2021-07-12 19:08:26,459 [run_pretraining.py:  558]:	worker_index: 6, step: 1790, cost: 6.875922, mlm loss: 6.875922, speed: 1.055566 steps/s, speed: 8.444528 samples/s, speed: 4323.598163 tokens/s, learning rate: 1.789e-05, loss_scalings: 6871.948730, pp_loss: 6.989751
[INFO] 2021-07-12 19:08:26,459 [run_pretraining.py:  512]:	********exe.run_1790******* 
[INFO] 2021-07-12 19:08:27,404 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:27,405 [run_pretraining.py:  534]:	loss/total_loss, 7.365854740142822, 1791
[INFO] 2021-07-12 19:08:27,405 [run_pretraining.py:  535]:	loss/mlm_loss, 7.365854740142822, 1791
[INFO] 2021-07-12 19:08:27,405 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7899999875226058e-05, 1791
[INFO] 2021-07-12 19:08:27,405 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1791
[INFO] 2021-07-12 19:08:27,405 [run_pretraining.py:  558]:	worker_index: 6, step: 1791, cost: 7.365855, mlm loss: 7.365855, speed: 1.057652 steps/s, speed: 8.461218 samples/s, speed: 4332.143586 tokens/s, learning rate: 1.790e-05, loss_scalings: 6871.948730, pp_loss: 7.377589
[INFO] 2021-07-12 19:08:27,405 [run_pretraining.py:  512]:	********exe.run_1791******* 
[INFO] 2021-07-12 19:08:28,342 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:28,343 [run_pretraining.py:  534]:	loss/total_loss, 7.140767574310303, 1792
[INFO] 2021-07-12 19:08:28,343 [run_pretraining.py:  535]:	loss/mlm_loss, 7.140767574310303, 1792
[INFO] 2021-07-12 19:08:28,343 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7910000678966753e-05, 1792
[INFO] 2021-07-12 19:08:28,343 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1792
[INFO] 2021-07-12 19:08:28,343 [run_pretraining.py:  558]:	worker_index: 6, step: 1792, cost: 7.140768, mlm loss: 7.140768, speed: 1.066606 steps/s, speed: 8.532852 samples/s, speed: 4368.820014 tokens/s, learning rate: 1.791e-05, loss_scalings: 6871.948730, pp_loss: 7.142674
[INFO] 2021-07-12 19:08:28,343 [run_pretraining.py:  512]:	********exe.run_1792******* 
[INFO] 2021-07-12 19:08:29,287 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:29,288 [run_pretraining.py:  534]:	loss/total_loss, 7.153031349182129, 1793
[INFO] 2021-07-12 19:08:29,288 [run_pretraining.py:  535]:	loss/mlm_loss, 7.153031349182129, 1793
[INFO] 2021-07-12 19:08:29,288 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7919999663718045e-05, 1793
[INFO] 2021-07-12 19:08:29,288 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1793
[INFO] 2021-07-12 19:08:29,288 [run_pretraining.py:  558]:	worker_index: 6, step: 1793, cost: 7.153031, mlm loss: 7.153031, speed: 1.059362 steps/s, speed: 8.474893 samples/s, speed: 4339.145218 tokens/s, learning rate: 1.792e-05, loss_scalings: 6871.948730, pp_loss: 7.186444
[INFO] 2021-07-12 19:08:29,288 [run_pretraining.py:  512]:	********exe.run_1793******* 
[INFO] 2021-07-12 19:08:30,234 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:30,234 [run_pretraining.py:  534]:	loss/total_loss, 7.088109970092773, 1794
[INFO] 2021-07-12 19:08:30,234 [run_pretraining.py:  535]:	loss/mlm_loss, 7.088109970092773, 1794
[INFO] 2021-07-12 19:08:30,234 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7929998648469336e-05, 1794
[INFO] 2021-07-12 19:08:30,235 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1794
[INFO] 2021-07-12 19:08:30,235 [run_pretraining.py:  558]:	worker_index: 6, step: 1794, cost: 7.088110, mlm loss: 7.088110, speed: 1.057253 steps/s, speed: 8.458023 samples/s, speed: 4330.507773 tokens/s, learning rate: 1.793e-05, loss_scalings: 6871.948730, pp_loss: 7.161108
[INFO] 2021-07-12 19:08:30,235 [run_pretraining.py:  512]:	********exe.run_1794******* 
[INFO] 2021-07-12 19:08:31,196 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:31,197 [run_pretraining.py:  534]:	loss/total_loss, 7.00391149520874, 1795
[INFO] 2021-07-12 19:08:31,197 [run_pretraining.py:  535]:	loss/mlm_loss, 7.00391149520874, 1795
[INFO] 2021-07-12 19:08:31,197 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.793999945221003e-05, 1795
[INFO] 2021-07-12 19:08:31,197 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1795
[INFO] 2021-07-12 19:08:31,197 [run_pretraining.py:  558]:	worker_index: 6, step: 1795, cost: 7.003911, mlm loss: 7.003911, speed: 1.039436 steps/s, speed: 8.315490 samples/s, speed: 4257.530827 tokens/s, learning rate: 1.794e-05, loss_scalings: 6871.948730, pp_loss: 7.283465
[INFO] 2021-07-12 19:08:31,197 [run_pretraining.py:  512]:	********exe.run_1795******* 
[INFO] 2021-07-12 19:08:32,147 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:32,148 [run_pretraining.py:  534]:	loss/total_loss, 7.278393745422363, 1796
[INFO] 2021-07-12 19:08:32,148 [run_pretraining.py:  535]:	loss/mlm_loss, 7.278393745422363, 1796
[INFO] 2021-07-12 19:08:32,148 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7950000255950727e-05, 1796
[INFO] 2021-07-12 19:08:32,148 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1796
[INFO] 2021-07-12 19:08:32,148 [run_pretraining.py:  558]:	worker_index: 6, step: 1796, cost: 7.278394, mlm loss: 7.278394, speed: 1.052190 steps/s, speed: 8.417520 samples/s, speed: 4309.770279 tokens/s, learning rate: 1.795e-05, loss_scalings: 6871.948730, pp_loss: 6.977554
[INFO] 2021-07-12 19:08:32,149 [run_pretraining.py:  512]:	********exe.run_1796******* 
[INFO] 2021-07-12 19:08:33,095 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:33,096 [run_pretraining.py:  534]:	loss/total_loss, 7.033076286315918, 1797
[INFO] 2021-07-12 19:08:33,096 [run_pretraining.py:  535]:	loss/mlm_loss, 7.033076286315918, 1797
[INFO] 2021-07-12 19:08:33,096 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7959999240702018e-05, 1797
[INFO] 2021-07-12 19:08:33,096 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1797
[INFO] 2021-07-12 19:08:33,096 [run_pretraining.py:  558]:	worker_index: 6, step: 1797, cost: 7.033076, mlm loss: 7.033076, speed: 1.056235 steps/s, speed: 8.449878 samples/s, speed: 4326.337570 tokens/s, learning rate: 1.796e-05, loss_scalings: 6871.948730, pp_loss: 6.631720
[INFO] 2021-07-12 19:08:33,096 [run_pretraining.py:  512]:	********exe.run_1797******* 
[INFO] 2021-07-12 19:08:34,042 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:34,043 [run_pretraining.py:  534]:	loss/total_loss, 7.278518199920654, 1798
[INFO] 2021-07-12 19:08:34,043 [run_pretraining.py:  535]:	loss/mlm_loss, 7.278518199920654, 1798
[INFO] 2021-07-12 19:08:34,043 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7970000044442713e-05, 1798
[INFO] 2021-07-12 19:08:34,043 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1798
[INFO] 2021-07-12 19:08:34,043 [run_pretraining.py:  558]:	worker_index: 6, step: 1798, cost: 7.278518, mlm loss: 7.278518, speed: 1.056571 steps/s, speed: 8.452566 samples/s, speed: 4327.714026 tokens/s, learning rate: 1.797e-05, loss_scalings: 6871.948730, pp_loss: 7.444975
[INFO] 2021-07-12 19:08:34,043 [run_pretraining.py:  512]:	********exe.run_1798******* 
[INFO] 2021-07-12 19:08:34,982 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:34,982 [run_pretraining.py:  534]:	loss/total_loss, 6.993038654327393, 1799
[INFO] 2021-07-12 19:08:34,983 [run_pretraining.py:  535]:	loss/mlm_loss, 6.993038654327393, 1799
[INFO] 2021-07-12 19:08:34,983 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7979999029194005e-05, 1799
[INFO] 2021-07-12 19:08:34,983 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1799
[INFO] 2021-07-12 19:08:34,983 [run_pretraining.py:  558]:	worker_index: 6, step: 1799, cost: 6.993039, mlm loss: 6.993039, speed: 1.064916 steps/s, speed: 8.519329 samples/s, speed: 4361.896232 tokens/s, learning rate: 1.798e-05, loss_scalings: 6871.948730, pp_loss: 7.163713
[INFO] 2021-07-12 19:08:34,983 [run_pretraining.py:  512]:	********exe.run_1799******* 
[INFO] 2021-07-12 19:08:35,916 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:35,916 [run_pretraining.py:  534]:	loss/total_loss, 7.675945281982422, 1800
[INFO] 2021-07-12 19:08:35,917 [run_pretraining.py:  535]:	loss/mlm_loss, 7.675945281982422, 1800
[INFO] 2021-07-12 19:08:35,917 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.79899998329347e-05, 1800
[INFO] 2021-07-12 19:08:35,917 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1800
[INFO] 2021-07-12 19:08:35,917 [run_pretraining.py:  558]:	worker_index: 6, step: 1800, cost: 7.675945, mlm loss: 7.675945, speed: 1.071414 steps/s, speed: 8.571314 samples/s, speed: 4388.512836 tokens/s, learning rate: 1.799e-05, loss_scalings: 6871.948730, pp_loss: 7.446268
[INFO] 2021-07-12 19:08:35,917 [run_pretraining.py:  512]:	********exe.run_1800******* 
[INFO] 2021-07-12 19:08:36,858 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:36,858 [run_pretraining.py:  534]:	loss/total_loss, 7.06884765625, 1801
[INFO] 2021-07-12 19:08:36,858 [run_pretraining.py:  535]:	loss/mlm_loss, 7.06884765625, 1801
[INFO] 2021-07-12 19:08:36,859 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8000000636675395e-05, 1801
[INFO] 2021-07-12 19:08:36,859 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1801
[INFO] 2021-07-12 19:08:36,859 [run_pretraining.py:  558]:	worker_index: 6, step: 1801, cost: 7.068848, mlm loss: 7.068848, speed: 1.062536 steps/s, speed: 8.500289 samples/s, speed: 4352.147992 tokens/s, learning rate: 1.800e-05, loss_scalings: 6871.948730, pp_loss: 7.549500
[INFO] 2021-07-12 19:08:36,859 [run_pretraining.py:  512]:	********exe.run_1801******* 
[INFO] 2021-07-12 19:08:37,800 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:37,801 [run_pretraining.py:  534]:	loss/total_loss, 7.029390335083008, 1802
[INFO] 2021-07-12 19:08:37,801 [run_pretraining.py:  535]:	loss/mlm_loss, 7.029390335083008, 1802
[INFO] 2021-07-12 19:08:37,801 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8009999621426687e-05, 1802
[INFO] 2021-07-12 19:08:37,801 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1802
[INFO] 2021-07-12 19:08:37,801 [run_pretraining.py:  558]:	worker_index: 6, step: 1802, cost: 7.029390, mlm loss: 7.029390, speed: 1.062029 steps/s, speed: 8.496234 samples/s, speed: 4350.071831 tokens/s, learning rate: 1.801e-05, loss_scalings: 5497.559082, pp_loss: 7.518661
[INFO] 2021-07-12 19:08:37,801 [run_pretraining.py:  512]:	********exe.run_1802******* 
[INFO] 2021-07-12 19:08:38,751 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:38,752 [run_pretraining.py:  534]:	loss/total_loss, 7.66007661819458, 1803
[INFO] 2021-07-12 19:08:38,752 [run_pretraining.py:  535]:	loss/mlm_loss, 7.66007661819458, 1803
[INFO] 2021-07-12 19:08:38,752 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8019998606177978e-05, 1803
[INFO] 2021-07-12 19:08:38,752 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1803
[INFO] 2021-07-12 19:08:38,752 [run_pretraining.py:  558]:	worker_index: 6, step: 1803, cost: 7.660077, mlm loss: 7.660077, speed: 1.051889 steps/s, speed: 8.415116 samples/s, speed: 4308.539194 tokens/s, learning rate: 1.802e-05, loss_scalings: 5497.559082, pp_loss: 7.933868
[INFO] 2021-07-12 19:08:38,752 [run_pretraining.py:  512]:	********exe.run_1803******* 
[INFO] 2021-07-12 19:08:39,695 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:39,695 [run_pretraining.py:  534]:	loss/total_loss, 7.679721832275391, 1804
[INFO] 2021-07-12 19:08:39,696 [run_pretraining.py:  535]:	loss/mlm_loss, 7.679721832275391, 1804
[INFO] 2021-07-12 19:08:39,696 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8029999409918673e-05, 1804
[INFO] 2021-07-12 19:08:39,696 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1804
[INFO] 2021-07-12 19:08:39,696 [run_pretraining.py:  558]:	worker_index: 6, step: 1804, cost: 7.679722, mlm loss: 7.679722, speed: 1.060704 steps/s, speed: 8.485628 samples/s, speed: 4344.641758 tokens/s, learning rate: 1.803e-05, loss_scalings: 5497.559082, pp_loss: 7.669835
[INFO] 2021-07-12 19:08:39,696 [run_pretraining.py:  512]:	********exe.run_1804******* 
[INFO] 2021-07-12 19:08:40,637 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:40,638 [run_pretraining.py:  534]:	loss/total_loss, 7.652195930480957, 1805
[INFO] 2021-07-12 19:08:40,638 [run_pretraining.py:  535]:	loss/mlm_loss, 7.652195930480957, 1805
[INFO] 2021-07-12 19:08:40,638 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.804000021365937e-05, 1805
[INFO] 2021-07-12 19:08:40,638 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1805
[INFO] 2021-07-12 19:08:40,638 [run_pretraining.py:  558]:	worker_index: 6, step: 1805, cost: 7.652196, mlm loss: 7.652196, speed: 1.062248 steps/s, speed: 8.497986 samples/s, speed: 4350.968613 tokens/s, learning rate: 1.804e-05, loss_scalings: 5497.559082, pp_loss: 7.750593
[INFO] 2021-07-12 19:08:40,638 [run_pretraining.py:  512]:	********exe.run_1805******* 
[INFO] 2021-07-12 19:08:41,560 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:41,560 [run_pretraining.py:  534]:	loss/total_loss, 7.97355318069458, 1806
[INFO] 2021-07-12 19:08:41,560 [run_pretraining.py:  535]:	loss/mlm_loss, 7.97355318069458, 1806
[INFO] 2021-07-12 19:08:41,560 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.804999919841066e-05, 1806
[INFO] 2021-07-12 19:08:41,561 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1806
[INFO] 2021-07-12 19:08:41,561 [run_pretraining.py:  558]:	worker_index: 6, step: 1806, cost: 7.973553, mlm loss: 7.973553, speed: 1.084617 steps/s, speed: 8.676936 samples/s, speed: 4442.591272 tokens/s, learning rate: 1.805e-05, loss_scalings: 5497.559082, pp_loss: 7.485543
[INFO] 2021-07-12 19:08:41,561 [run_pretraining.py:  512]:	********exe.run_1806******* 
[INFO] 2021-07-12 19:08:42,504 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:42,505 [run_pretraining.py:  534]:	loss/total_loss, 7.536671161651611, 1807
[INFO] 2021-07-12 19:08:42,505 [run_pretraining.py:  535]:	loss/mlm_loss, 7.536671161651611, 1807
[INFO] 2021-07-12 19:08:42,505 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8060000002151355e-05, 1807
[INFO] 2021-07-12 19:08:42,505 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1807
[INFO] 2021-07-12 19:08:42,505 [run_pretraining.py:  558]:	worker_index: 6, step: 1807, cost: 7.536671, mlm loss: 7.536671, speed: 1.059236 steps/s, speed: 8.473885 samples/s, speed: 4338.629090 tokens/s, learning rate: 1.806e-05, loss_scalings: 5497.559082, pp_loss: 6.699212
[INFO] 2021-07-12 19:08:42,506 [run_pretraining.py:  512]:	********exe.run_1807******* 
[INFO] 2021-07-12 19:08:43,445 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:43,446 [run_pretraining.py:  534]:	loss/total_loss, 7.583881378173828, 1808
[INFO] 2021-07-12 19:08:43,446 [run_pretraining.py:  535]:	loss/mlm_loss, 7.583881378173828, 1808
[INFO] 2021-07-12 19:08:43,446 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.807000080589205e-05, 1808
[INFO] 2021-07-12 19:08:43,446 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1808
[INFO] 2021-07-12 19:08:43,446 [run_pretraining.py:  558]:	worker_index: 6, step: 1808, cost: 7.583881, mlm loss: 7.583881, speed: 1.064037 steps/s, speed: 8.512294 samples/s, speed: 4358.294403 tokens/s, learning rate: 1.807e-05, loss_scalings: 5497.559082, pp_loss: 7.365252
[INFO] 2021-07-12 19:08:43,446 [run_pretraining.py:  512]:	********exe.run_1808******* 
[INFO] 2021-07-12 19:08:44,363 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:44,364 [run_pretraining.py:  534]:	loss/total_loss, 6.812214374542236, 1809
[INFO] 2021-07-12 19:08:44,364 [run_pretraining.py:  535]:	loss/mlm_loss, 6.812214374542236, 1809
[INFO] 2021-07-12 19:08:44,364 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8079999790643342e-05, 1809
[INFO] 2021-07-12 19:08:44,364 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1809
[INFO] 2021-07-12 19:08:44,364 [run_pretraining.py:  558]:	worker_index: 6, step: 1809, cost: 6.812214, mlm loss: 6.812214, speed: 1.089879 steps/s, speed: 8.719029 samples/s, speed: 4464.142679 tokens/s, learning rate: 1.808e-05, loss_scalings: 5497.559082, pp_loss: 7.235756
[INFO] 2021-07-12 19:08:44,364 [run_pretraining.py:  512]:	********exe.run_1809******* 
[INFO] 2021-07-12 19:08:45,271 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:45,271 [run_pretraining.py:  534]:	loss/total_loss, 7.211243152618408, 1810
[INFO] 2021-07-12 19:08:45,272 [run_pretraining.py:  535]:	loss/mlm_loss, 7.211243152618408, 1810
[INFO] 2021-07-12 19:08:45,272 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8089998775394633e-05, 1810
[INFO] 2021-07-12 19:08:45,272 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1810
[INFO] 2021-07-12 19:08:45,272 [run_pretraining.py:  558]:	worker_index: 6, step: 1810, cost: 7.211243, mlm loss: 7.211243, speed: 1.102676 steps/s, speed: 8.821408 samples/s, speed: 4516.561074 tokens/s, learning rate: 1.809e-05, loss_scalings: 5497.559082, pp_loss: 7.531749
[INFO] 2021-07-12 19:08:45,272 [run_pretraining.py:  512]:	********exe.run_1810******* 
[INFO] 2021-07-12 19:08:46,320 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:46,321 [run_pretraining.py:  534]:	loss/total_loss, 7.482119560241699, 1811
[INFO] 2021-07-12 19:08:46,321 [run_pretraining.py:  535]:	loss/mlm_loss, 7.482119560241699, 1811
[INFO] 2021-07-12 19:08:46,321 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.809999957913533e-05, 1811
[INFO] 2021-07-12 19:08:46,321 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1811
[INFO] 2021-07-12 19:08:46,321 [run_pretraining.py:  558]:	worker_index: 6, step: 1811, cost: 7.482120, mlm loss: 7.482120, speed: 0.953551 steps/s, speed: 7.628405 samples/s, speed: 3905.743370 tokens/s, learning rate: 1.810e-05, loss_scalings: 5497.559082, pp_loss: 7.385356
[INFO] 2021-07-12 19:08:46,321 [run_pretraining.py:  512]:	********exe.run_1811******* 
[INFO] 2021-07-12 19:08:47,470 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:47,471 [run_pretraining.py:  534]:	loss/total_loss, 7.392483711242676, 1812
[INFO] 2021-07-12 19:08:47,471 [run_pretraining.py:  535]:	loss/mlm_loss, 7.392483711242676, 1812
[INFO] 2021-07-12 19:08:47,471 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.810999856388662e-05, 1812
[INFO] 2021-07-12 19:08:47,471 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1812
[INFO] 2021-07-12 19:08:47,471 [run_pretraining.py:  558]:	worker_index: 6, step: 1812, cost: 7.392484, mlm loss: 7.392484, speed: 0.870246 steps/s, speed: 6.961964 samples/s, speed: 3564.525601 tokens/s, learning rate: 1.811e-05, loss_scalings: 5497.559082, pp_loss: 7.154315
[INFO] 2021-07-12 19:08:47,471 [run_pretraining.py:  512]:	********exe.run_1812******* 
[INFO] 2021-07-12 19:08:48,717 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:48,717 [run_pretraining.py:  534]:	loss/total_loss, 7.452701568603516, 1813
[INFO] 2021-07-12 19:08:48,717 [run_pretraining.py:  535]:	loss/mlm_loss, 7.452701568603516, 1813
[INFO] 2021-07-12 19:08:48,717 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8119999367627315e-05, 1813
[INFO] 2021-07-12 19:08:48,717 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1813
[INFO] 2021-07-12 19:08:48,718 [run_pretraining.py:  558]:	worker_index: 6, step: 1813, cost: 7.452702, mlm loss: 7.452702, speed: 0.802663 steps/s, speed: 6.421306 samples/s, speed: 3287.708695 tokens/s, learning rate: 1.812e-05, loss_scalings: 5497.559082, pp_loss: 7.517798
[INFO] 2021-07-12 19:08:48,718 [run_pretraining.py:  512]:	********exe.run_1813******* 
[INFO] 2021-07-12 19:08:49,940 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:49,940 [run_pretraining.py:  534]:	loss/total_loss, 7.870512962341309, 1814
[INFO] 2021-07-12 19:08:49,941 [run_pretraining.py:  535]:	loss/mlm_loss, 7.870512962341309, 1814
[INFO] 2021-07-12 19:08:49,941 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.813000017136801e-05, 1814
[INFO] 2021-07-12 19:08:49,941 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1814
[INFO] 2021-07-12 19:08:49,941 [run_pretraining.py:  558]:	worker_index: 6, step: 1814, cost: 7.870513, mlm loss: 7.870513, speed: 0.817906 steps/s, speed: 6.543246 samples/s, speed: 3350.141862 tokens/s, learning rate: 1.813e-05, loss_scalings: 5497.559082, pp_loss: 7.373645
[INFO] 2021-07-12 19:08:49,941 [run_pretraining.py:  512]:	********exe.run_1814******* 
[INFO] 2021-07-12 19:08:51,222 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:51,222 [run_pretraining.py:  534]:	loss/total_loss, 6.886476039886475, 1815
[INFO] 2021-07-12 19:08:51,223 [run_pretraining.py:  535]:	loss/mlm_loss, 6.886476039886475, 1815
[INFO] 2021-07-12 19:08:51,223 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8139999156119302e-05, 1815
[INFO] 2021-07-12 19:08:51,223 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1815
[INFO] 2021-07-12 19:08:51,223 [run_pretraining.py:  558]:	worker_index: 6, step: 1815, cost: 6.886476, mlm loss: 6.886476, speed: 0.780462 steps/s, speed: 6.243697 samples/s, speed: 3196.772758 tokens/s, learning rate: 1.814e-05, loss_scalings: 5497.559082, pp_loss: 6.960736
[INFO] 2021-07-12 19:08:51,223 [run_pretraining.py:  512]:	********exe.run_1815******* 
[INFO] 2021-07-12 19:08:52,503 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:52,503 [run_pretraining.py:  534]:	loss/total_loss, 7.821314334869385, 1816
[INFO] 2021-07-12 19:08:52,503 [run_pretraining.py:  535]:	loss/mlm_loss, 7.821314334869385, 1816
[INFO] 2021-07-12 19:08:52,504 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8149999959859997e-05, 1816
[INFO] 2021-07-12 19:08:52,504 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1816
[INFO] 2021-07-12 19:08:52,504 [run_pretraining.py:  558]:	worker_index: 6, step: 1816, cost: 7.821314, mlm loss: 7.821314, speed: 0.781177 steps/s, speed: 6.249415 samples/s, speed: 3199.700288 tokens/s, learning rate: 1.815e-05, loss_scalings: 5497.559082, pp_loss: 7.219900
[INFO] 2021-07-12 19:08:52,504 [run_pretraining.py:  512]:	********exe.run_1816******* 
[INFO] 2021-07-12 19:08:53,792 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:53,793 [run_pretraining.py:  534]:	loss/total_loss, 7.664168357849121, 1817
[INFO] 2021-07-12 19:08:53,793 [run_pretraining.py:  535]:	loss/mlm_loss, 7.664168357849121, 1817
[INFO] 2021-07-12 19:08:53,793 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8160000763600692e-05, 1817
[INFO] 2021-07-12 19:08:53,793 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1817
[INFO] 2021-07-12 19:08:53,793 [run_pretraining.py:  558]:	worker_index: 6, step: 1817, cost: 7.664168, mlm loss: 7.664168, speed: 0.775970 steps/s, speed: 6.207763 samples/s, speed: 3178.374821 tokens/s, learning rate: 1.816e-05, loss_scalings: 5497.559082, pp_loss: 7.275077
[INFO] 2021-07-12 19:08:53,793 [run_pretraining.py:  512]:	********exe.run_1817******* 
[INFO] 2021-07-12 19:08:55,066 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:55,067 [run_pretraining.py:  534]:	loss/total_loss, 7.839259624481201, 1818
[INFO] 2021-07-12 19:08:55,067 [run_pretraining.py:  535]:	loss/mlm_loss, 7.839259624481201, 1818
[INFO] 2021-07-12 19:08:55,067 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8169999748351984e-05, 1818
[INFO] 2021-07-12 19:08:55,067 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1818
[INFO] 2021-07-12 19:08:55,067 [run_pretraining.py:  558]:	worker_index: 6, step: 1818, cost: 7.839260, mlm loss: 7.839260, speed: 0.785389 steps/s, speed: 6.283110 samples/s, speed: 3216.952153 tokens/s, learning rate: 1.817e-05, loss_scalings: 5497.559082, pp_loss: 7.212699
[INFO] 2021-07-12 19:08:55,067 [run_pretraining.py:  512]:	********exe.run_1818******* 
[INFO] 2021-07-12 19:08:56,149 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:56,150 [run_pretraining.py:  534]:	loss/total_loss, 6.97462797164917, 1819
[INFO] 2021-07-12 19:08:56,150 [run_pretraining.py:  535]:	loss/mlm_loss, 6.97462797164917, 1819
[INFO] 2021-07-12 19:08:56,150 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8179998733103275e-05, 1819
[INFO] 2021-07-12 19:08:56,150 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1819
[INFO] 2021-07-12 19:08:56,150 [run_pretraining.py:  558]:	worker_index: 6, step: 1819, cost: 6.974628, mlm loss: 6.974628, speed: 0.923685 steps/s, speed: 7.389482 samples/s, speed: 3783.414640 tokens/s, learning rate: 1.818e-05, loss_scalings: 5497.559082, pp_loss: 7.260653
[INFO] 2021-07-12 19:08:56,150 [run_pretraining.py:  512]:	********exe.run_1819******* 
[INFO] 2021-07-12 19:08:57,213 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:57,214 [run_pretraining.py:  534]:	loss/total_loss, 7.910634994506836, 1820
[INFO] 2021-07-12 19:08:57,214 [run_pretraining.py:  535]:	loss/mlm_loss, 7.910634994506836, 1820
[INFO] 2021-07-12 19:08:57,214 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.818999953684397e-05, 1820
[INFO] 2021-07-12 19:08:57,214 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1820
[INFO] 2021-07-12 19:08:57,214 [run_pretraining.py:  558]:	worker_index: 6, step: 1820, cost: 7.910635, mlm loss: 7.910635, speed: 0.940786 steps/s, speed: 7.526289 samples/s, speed: 3853.460006 tokens/s, learning rate: 1.819e-05, loss_scalings: 5497.559082, pp_loss: 7.372586
[INFO] 2021-07-12 19:08:57,214 [run_pretraining.py:  512]:	********exe.run_1820******* 
[INFO] 2021-07-12 19:08:58,270 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:58,271 [run_pretraining.py:  534]:	loss/total_loss, 7.088628768920898, 1821
[INFO] 2021-07-12 19:08:58,271 [run_pretraining.py:  535]:	loss/mlm_loss, 7.088628768920898, 1821
[INFO] 2021-07-12 19:08:58,271 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8199998521595262e-05, 1821
[INFO] 2021-07-12 19:08:58,271 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1821
[INFO] 2021-07-12 19:08:58,271 [run_pretraining.py:  558]:	worker_index: 6, step: 1821, cost: 7.088629, mlm loss: 7.088629, speed: 0.946353 steps/s, speed: 7.570821 samples/s, speed: 3876.260428 tokens/s, learning rate: 1.820e-05, loss_scalings: 5497.559082, pp_loss: 7.142964
[INFO] 2021-07-12 19:08:58,272 [run_pretraining.py:  512]:	********exe.run_1821******* 
[INFO] 2021-07-12 19:08:59,331 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:59,332 [run_pretraining.py:  534]:	loss/total_loss, 7.605734825134277, 1822
[INFO] 2021-07-12 19:08:59,332 [run_pretraining.py:  535]:	loss/mlm_loss, 7.605734825134277, 1822
[INFO] 2021-07-12 19:08:59,332 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8209999325335957e-05, 1822
[INFO] 2021-07-12 19:08:59,332 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1822
[INFO] 2021-07-12 19:08:59,332 [run_pretraining.py:  558]:	worker_index: 6, step: 1822, cost: 7.605735, mlm loss: 7.605735, speed: 0.943337 steps/s, speed: 7.546697 samples/s, speed: 3863.908678 tokens/s, learning rate: 1.821e-05, loss_scalings: 5497.559082, pp_loss: 7.470209
[INFO] 2021-07-12 19:08:59,332 [run_pretraining.py:  512]:	********exe.run_1822******* 
[INFO] 2021-07-12 19:09:00,411 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:00,411 [run_pretraining.py:  534]:	loss/total_loss, 7.475936412811279, 1823
[INFO] 2021-07-12 19:09:00,411 [run_pretraining.py:  535]:	loss/mlm_loss, 7.475936412811279, 1823
[INFO] 2021-07-12 19:09:00,412 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8220000129076652e-05, 1823
[INFO] 2021-07-12 19:09:00,412 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1823
[INFO] 2021-07-12 19:09:00,412 [run_pretraining.py:  558]:	worker_index: 6, step: 1823, cost: 7.475936, mlm loss: 7.475936, speed: 0.926995 steps/s, speed: 7.415959 samples/s, speed: 3796.970839 tokens/s, learning rate: 1.822e-05, loss_scalings: 5497.559082, pp_loss: 7.412187
[INFO] 2021-07-12 19:09:00,412 [run_pretraining.py:  512]:	********exe.run_1823******* 
[INFO] 2021-07-12 19:09:01,488 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:01,488 [run_pretraining.py:  534]:	loss/total_loss, 7.412236213684082, 1824
[INFO] 2021-07-12 19:09:01,489 [run_pretraining.py:  535]:	loss/mlm_loss, 7.412236213684082, 1824
[INFO] 2021-07-12 19:09:01,489 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8229999113827944e-05, 1824
[INFO] 2021-07-12 19:09:01,489 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1824
[INFO] 2021-07-12 19:09:01,489 [run_pretraining.py:  558]:	worker_index: 6, step: 1824, cost: 7.412236, mlm loss: 7.412236, speed: 0.929009 steps/s, speed: 7.432074 samples/s, speed: 3805.221917 tokens/s, learning rate: 1.823e-05, loss_scalings: 5497.559082, pp_loss: 7.265795
[INFO] 2021-07-12 19:09:01,489 [run_pretraining.py:  512]:	********exe.run_1824******* 
[INFO] 2021-07-12 19:09:02,567 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:02,568 [run_pretraining.py:  534]:	loss/total_loss, 6.616475582122803, 1825
[INFO] 2021-07-12 19:09:02,568 [run_pretraining.py:  535]:	loss/mlm_loss, 6.616475582122803, 1825
[INFO] 2021-07-12 19:09:02,568 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.823999991756864e-05, 1825
[INFO] 2021-07-12 19:09:02,568 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1825
[INFO] 2021-07-12 19:09:02,568 [run_pretraining.py:  558]:	worker_index: 6, step: 1825, cost: 6.616476, mlm loss: 6.616476, speed: 0.927019 steps/s, speed: 7.416152 samples/s, speed: 3797.069865 tokens/s, learning rate: 1.824e-05, loss_scalings: 5497.559082, pp_loss: 6.406673
[INFO] 2021-07-12 19:09:02,568 [run_pretraining.py:  512]:	********exe.run_1825******* 
[INFO] 2021-07-12 19:09:03,719 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:03,720 [run_pretraining.py:  534]:	loss/total_loss, 6.877948760986328, 1826
[INFO] 2021-07-12 19:09:03,720 [run_pretraining.py:  535]:	loss/mlm_loss, 6.877948760986328, 1826
[INFO] 2021-07-12 19:09:03,720 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8250000721309334e-05, 1826
[INFO] 2021-07-12 19:09:03,720 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1826
[INFO] 2021-07-12 19:09:03,720 [run_pretraining.py:  558]:	worker_index: 6, step: 1826, cost: 6.877949, mlm loss: 6.877949, speed: 0.868495 steps/s, speed: 6.947956 samples/s, speed: 3557.353587 tokens/s, learning rate: 1.825e-05, loss_scalings: 5497.559082, pp_loss: 7.039269
[INFO] 2021-07-12 19:09:03,721 [run_pretraining.py:  512]:	********exe.run_1826******* 
[INFO] 2021-07-12 19:09:04,823 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:04,824 [run_pretraining.py:  534]:	loss/total_loss, 7.011206150054932, 1827
[INFO] 2021-07-12 19:09:04,824 [run_pretraining.py:  535]:	loss/mlm_loss, 7.011206150054932, 1827
[INFO] 2021-07-12 19:09:04,824 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8259999706060626e-05, 1827
[INFO] 2021-07-12 19:09:04,824 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1827
[INFO] 2021-07-12 19:09:04,824 [run_pretraining.py:  558]:	worker_index: 6, step: 1827, cost: 7.011206, mlm loss: 7.011206, speed: 0.906711 steps/s, speed: 7.253685 samples/s, speed: 3713.886970 tokens/s, learning rate: 1.826e-05, loss_scalings: 5497.559082, pp_loss: 7.223330
[INFO] 2021-07-12 19:09:04,824 [run_pretraining.py:  512]:	********exe.run_1827******* 
[INFO] 2021-07-12 19:09:05,922 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:05,923 [run_pretraining.py:  534]:	loss/total_loss, 6.951059341430664, 1828
[INFO] 2021-07-12 19:09:05,923 [run_pretraining.py:  535]:	loss/mlm_loss, 6.951059341430664, 1828
[INFO] 2021-07-12 19:09:05,923 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8269998690811917e-05, 1828
[INFO] 2021-07-12 19:09:05,923 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1828
[INFO] 2021-07-12 19:09:05,923 [run_pretraining.py:  558]:	worker_index: 6, step: 1828, cost: 6.951059, mlm loss: 6.951059, speed: 0.910576 steps/s, speed: 7.284606 samples/s, speed: 3729.718240 tokens/s, learning rate: 1.827e-05, loss_scalings: 5497.559082, pp_loss: 7.165396
[INFO] 2021-07-12 19:09:05,923 [run_pretraining.py:  512]:	********exe.run_1828******* 
[INFO] 2021-07-12 19:09:07,018 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:07,018 [run_pretraining.py:  534]:	loss/total_loss, 7.132275581359863, 1829
[INFO] 2021-07-12 19:09:07,018 [run_pretraining.py:  535]:	loss/mlm_loss, 7.132275581359863, 1829
[INFO] 2021-07-12 19:09:07,018 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8279999494552612e-05, 1829
[INFO] 2021-07-12 19:09:07,019 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1829
[INFO] 2021-07-12 19:09:07,019 [run_pretraining.py:  558]:	worker_index: 6, step: 1829, cost: 7.132276, mlm loss: 7.132276, speed: 0.913242 steps/s, speed: 7.305936 samples/s, speed: 3740.639172 tokens/s, learning rate: 1.828e-05, loss_scalings: 5497.559082, pp_loss: 7.334618
[INFO] 2021-07-12 19:09:07,019 [run_pretraining.py:  512]:	********exe.run_1829******* 
[INFO] 2021-07-12 19:09:08,114 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:08,115 [run_pretraining.py:  534]:	loss/total_loss, 6.758840084075928, 1830
[INFO] 2021-07-12 19:09:08,115 [run_pretraining.py:  535]:	loss/mlm_loss, 6.758840084075928, 1830
[INFO] 2021-07-12 19:09:08,115 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8289998479303904e-05, 1830
[INFO] 2021-07-12 19:09:08,115 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1830
[INFO] 2021-07-12 19:09:08,115 [run_pretraining.py:  558]:	worker_index: 6, step: 1830, cost: 6.758840, mlm loss: 6.758840, speed: 0.912723 steps/s, speed: 7.301785 samples/s, speed: 3738.513815 tokens/s, learning rate: 1.829e-05, loss_scalings: 5497.559082, pp_loss: 7.307035
[INFO] 2021-07-12 19:09:08,115 [run_pretraining.py:  512]:	********exe.run_1830******* 
[INFO] 2021-07-12 19:09:09,214 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:09,215 [run_pretraining.py:  534]:	loss/total_loss, 7.054128170013428, 1831
[INFO] 2021-07-12 19:09:09,215 [run_pretraining.py:  535]:	loss/mlm_loss, 7.054128170013428, 1831
[INFO] 2021-07-12 19:09:09,215 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.82999992830446e-05, 1831
[INFO] 2021-07-12 19:09:09,215 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1831
[INFO] 2021-07-12 19:09:09,215 [run_pretraining.py:  558]:	worker_index: 6, step: 1831, cost: 7.054128, mlm loss: 7.054128, speed: 0.909364 steps/s, speed: 7.274910 samples/s, speed: 3724.754016 tokens/s, learning rate: 1.830e-05, loss_scalings: 5497.559082, pp_loss: 7.522266
[INFO] 2021-07-12 19:09:09,215 [run_pretraining.py:  512]:	********exe.run_1831******* 
[INFO] 2021-07-12 19:09:10,316 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:10,317 [run_pretraining.py:  534]:	loss/total_loss, 7.563915729522705, 1832
[INFO] 2021-07-12 19:09:10,317 [run_pretraining.py:  535]:	loss/mlm_loss, 7.563915729522705, 1832
[INFO] 2021-07-12 19:09:10,317 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8310000086785294e-05, 1832
[INFO] 2021-07-12 19:09:10,317 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1832
[INFO] 2021-07-12 19:09:10,317 [run_pretraining.py:  558]:	worker_index: 6, step: 1832, cost: 7.563916, mlm loss: 7.563916, speed: 0.908284 steps/s, speed: 7.266271 samples/s, speed: 3720.330610 tokens/s, learning rate: 1.831e-05, loss_scalings: 5497.559082, pp_loss: 7.710801
[INFO] 2021-07-12 19:09:10,317 [run_pretraining.py:  512]:	********exe.run_1832******* 
[INFO] 2021-07-12 19:09:11,416 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:11,416 [run_pretraining.py:  534]:	loss/total_loss, 7.511768341064453, 1833
[INFO] 2021-07-12 19:09:11,416 [run_pretraining.py:  535]:	loss/mlm_loss, 7.511768341064453, 1833
[INFO] 2021-07-12 19:09:11,416 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8319999071536586e-05, 1833
[INFO] 2021-07-12 19:09:11,417 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1833
[INFO] 2021-07-12 19:09:11,417 [run_pretraining.py:  558]:	worker_index: 6, step: 1833, cost: 7.511768, mlm loss: 7.511768, speed: 0.910000 steps/s, speed: 7.280000 samples/s, speed: 3727.360222 tokens/s, learning rate: 1.832e-05, loss_scalings: 5497.559082, pp_loss: 6.884201
[INFO] 2021-07-12 19:09:11,417 [run_pretraining.py:  512]:	********exe.run_1833******* 
[INFO] 2021-07-12 19:09:12,502 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:12,503 [run_pretraining.py:  534]:	loss/total_loss, 7.600067138671875, 1834
[INFO] 2021-07-12 19:09:12,503 [run_pretraining.py:  535]:	loss/mlm_loss, 7.600067138671875, 1834
[INFO] 2021-07-12 19:09:12,503 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.832999987527728e-05, 1834
[INFO] 2021-07-12 19:09:12,503 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1834
[INFO] 2021-07-12 19:09:12,503 [run_pretraining.py:  558]:	worker_index: 6, step: 1834, cost: 7.600067, mlm loss: 7.600067, speed: 0.920833 steps/s, speed: 7.366661 samples/s, speed: 3771.730246 tokens/s, learning rate: 1.833e-05, loss_scalings: 5497.559082, pp_loss: 7.475528
[INFO] 2021-07-12 19:09:12,503 [run_pretraining.py:  512]:	********exe.run_1834******* 
[INFO] 2021-07-12 19:09:13,599 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:13,600 [run_pretraining.py:  534]:	loss/total_loss, 3.893090009689331, 1835
[INFO] 2021-07-12 19:09:13,600 [run_pretraining.py:  535]:	loss/mlm_loss, 3.893090009689331, 1835
[INFO] 2021-07-12 19:09:13,600 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8340000679017976e-05, 1835
[INFO] 2021-07-12 19:09:13,600 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1835
[INFO] 2021-07-12 19:09:13,600 [run_pretraining.py:  558]:	worker_index: 6, step: 1835, cost: 3.893090, mlm loss: 3.893090, speed: 0.912092 steps/s, speed: 7.296739 samples/s, speed: 3735.930176 tokens/s, learning rate: 1.834e-05, loss_scalings: 5497.559082, pp_loss: 6.474483
[INFO] 2021-07-12 19:09:13,600 [run_pretraining.py:  512]:	********exe.run_1835******* 
[INFO] 2021-07-12 19:09:14,690 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:14,690 [run_pretraining.py:  534]:	loss/total_loss, 6.912113189697266, 1836
[INFO] 2021-07-12 19:09:14,690 [run_pretraining.py:  535]:	loss/mlm_loss, 6.912113189697266, 1836
[INFO] 2021-07-12 19:09:14,690 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8349999663769267e-05, 1836
[INFO] 2021-07-12 19:09:14,690 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1836
[INFO] 2021-07-12 19:09:14,691 [run_pretraining.py:  558]:	worker_index: 6, step: 1836, cost: 6.912113, mlm loss: 6.912113, speed: 0.917876 steps/s, speed: 7.343011 samples/s, speed: 3759.621615 tokens/s, learning rate: 1.835e-05, loss_scalings: 5497.559082, pp_loss: 7.089080
[INFO] 2021-07-12 19:09:14,691 [run_pretraining.py:  512]:	********exe.run_1836******* 
[INFO] 2021-07-12 19:09:15,779 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:15,780 [run_pretraining.py:  534]:	loss/total_loss, 7.84501838684082, 1837
[INFO] 2021-07-12 19:09:15,780 [run_pretraining.py:  535]:	loss/mlm_loss, 7.84501838684082, 1837
[INFO] 2021-07-12 19:09:15,780 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.835999864852056e-05, 1837
[INFO] 2021-07-12 19:09:15,780 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1837
[INFO] 2021-07-12 19:09:15,780 [run_pretraining.py:  558]:	worker_index: 6, step: 1837, cost: 7.845018, mlm loss: 7.845018, speed: 0.918495 steps/s, speed: 7.347960 samples/s, speed: 3762.155750 tokens/s, learning rate: 1.836e-05, loss_scalings: 5497.559082, pp_loss: 7.596275
[INFO] 2021-07-12 19:09:15,780 [run_pretraining.py:  512]:	********exe.run_1837******* 
[INFO] 2021-07-12 19:09:16,874 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:16,874 [run_pretraining.py:  534]:	loss/total_loss, 7.355832576751709, 1838
[INFO] 2021-07-12 19:09:16,874 [run_pretraining.py:  535]:	loss/mlm_loss, 7.355832576751709, 1838
[INFO] 2021-07-12 19:09:16,874 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8369999452261254e-05, 1838
[INFO] 2021-07-12 19:09:16,875 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1838
[INFO] 2021-07-12 19:09:16,875 [run_pretraining.py:  558]:	worker_index: 6, step: 1838, cost: 7.355833, mlm loss: 7.355833, speed: 0.914134 steps/s, speed: 7.313069 samples/s, speed: 3744.291532 tokens/s, learning rate: 1.837e-05, loss_scalings: 5497.559082, pp_loss: 7.640201
[INFO] 2021-07-12 19:09:16,875 [run_pretraining.py:  512]:	********exe.run_1838******* 
[INFO] 2021-07-12 19:09:17,975 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:17,976 [run_pretraining.py:  534]:	loss/total_loss, 7.456955909729004, 1839
[INFO] 2021-07-12 19:09:17,976 [run_pretraining.py:  535]:	loss/mlm_loss, 7.456955909729004, 1839
[INFO] 2021-07-12 19:09:17,976 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8379998437012546e-05, 1839
[INFO] 2021-07-12 19:09:17,976 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1839
[INFO] 2021-07-12 19:09:17,976 [run_pretraining.py:  558]:	worker_index: 6, step: 1839, cost: 7.456956, mlm loss: 7.456956, speed: 0.908359 steps/s, speed: 7.266875 samples/s, speed: 3720.640003 tokens/s, learning rate: 1.838e-05, loss_scalings: 5497.559082, pp_loss: 7.424617
[INFO] 2021-07-12 19:09:17,976 [run_pretraining.py:  512]:	********exe.run_1839******* 
[INFO] 2021-07-12 19:09:19,062 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:19,062 [run_pretraining.py:  534]:	loss/total_loss, 7.025090217590332, 1840
[INFO] 2021-07-12 19:09:19,062 [run_pretraining.py:  535]:	loss/mlm_loss, 7.025090217590332, 1840
[INFO] 2021-07-12 19:09:19,062 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.838999924075324e-05, 1840
[INFO] 2021-07-12 19:09:19,062 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1840
[INFO] 2021-07-12 19:09:19,063 [run_pretraining.py:  558]:	worker_index: 6, step: 1840, cost: 7.025090, mlm loss: 7.025090, speed: 0.921113 steps/s, speed: 7.368905 samples/s, speed: 3772.879114 tokens/s, learning rate: 1.839e-05, loss_scalings: 5497.559082, pp_loss: 7.271044
[INFO] 2021-07-12 19:09:19,063 [run_pretraining.py:  512]:	********exe.run_1840******* 
[INFO] 2021-07-12 19:09:20,156 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:20,156 [run_pretraining.py:  534]:	loss/total_loss, 7.364266395568848, 1841
[INFO] 2021-07-12 19:09:20,156 [run_pretraining.py:  535]:	loss/mlm_loss, 7.364266395568848, 1841
[INFO] 2021-07-12 19:09:20,156 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8400000044493936e-05, 1841
[INFO] 2021-07-12 19:09:20,156 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1841
[INFO] 2021-07-12 19:09:20,157 [run_pretraining.py:  558]:	worker_index: 6, step: 1841, cost: 7.364266, mlm loss: 7.364266, speed: 0.914700 steps/s, speed: 7.317604 samples/s, speed: 3746.613015 tokens/s, learning rate: 1.840e-05, loss_scalings: 5497.559082, pp_loss: 7.270161
[INFO] 2021-07-12 19:09:20,157 [run_pretraining.py:  512]:	********exe.run_1841******* 
[INFO] 2021-07-12 19:09:21,253 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:21,253 [run_pretraining.py:  534]:	loss/total_loss, 7.496862888336182, 1842
[INFO] 2021-07-12 19:09:21,254 [run_pretraining.py:  535]:	loss/mlm_loss, 7.496862888336182, 1842
[INFO] 2021-07-12 19:09:21,254 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8409999029245228e-05, 1842
[INFO] 2021-07-12 19:09:21,254 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1842
[INFO] 2021-07-12 19:09:21,254 [run_pretraining.py:  558]:	worker_index: 6, step: 1842, cost: 7.496863, mlm loss: 7.496863, speed: 0.911910 steps/s, speed: 7.295284 samples/s, speed: 3735.185341 tokens/s, learning rate: 1.841e-05, loss_scalings: 5497.559082, pp_loss: 7.368941
[INFO] 2021-07-12 19:09:21,254 [run_pretraining.py:  512]:	********exe.run_1842******* 
[INFO] 2021-07-12 19:09:22,399 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:22,400 [run_pretraining.py:  534]:	loss/total_loss, 7.202004909515381, 1843
[INFO] 2021-07-12 19:09:22,400 [run_pretraining.py:  535]:	loss/mlm_loss, 7.202004909515381, 1843
[INFO] 2021-07-12 19:09:22,400 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8419999832985923e-05, 1843
[INFO] 2021-07-12 19:09:22,400 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1843
[INFO] 2021-07-12 19:09:22,400 [run_pretraining.py:  558]:	worker_index: 6, step: 1843, cost: 7.202005, mlm loss: 7.202005, speed: 0.872939 steps/s, speed: 6.983509 samples/s, speed: 3575.556408 tokens/s, learning rate: 1.842e-05, loss_scalings: 5497.559082, pp_loss: 7.090647
[INFO] 2021-07-12 19:09:22,400 [run_pretraining.py:  512]:	********exe.run_1843******* 
[INFO] 2021-07-12 19:09:23,501 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:23,502 [run_pretraining.py:  534]:	loss/total_loss, 7.593671798706055, 1844
[INFO] 2021-07-12 19:09:23,502 [run_pretraining.py:  535]:	loss/mlm_loss, 7.593671798706055, 1844
[INFO] 2021-07-12 19:09:23,502 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8430000636726618e-05, 1844
[INFO] 2021-07-12 19:09:23,502 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1844
[INFO] 2021-07-12 19:09:23,502 [run_pretraining.py:  558]:	worker_index: 6, step: 1844, cost: 7.593672, mlm loss: 7.593672, speed: 0.907742 steps/s, speed: 7.261934 samples/s, speed: 3718.109970 tokens/s, learning rate: 1.843e-05, loss_scalings: 5497.559082, pp_loss: 7.575882
[INFO] 2021-07-12 19:09:23,502 [run_pretraining.py:  512]:	********exe.run_1844******* 
[INFO] 2021-07-12 19:09:24,679 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:24,679 [run_pretraining.py:  534]:	loss/total_loss, 7.878544807434082, 1845
[INFO] 2021-07-12 19:09:24,680 [run_pretraining.py:  535]:	loss/mlm_loss, 7.878544807434082, 1845
[INFO] 2021-07-12 19:09:24,680 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.843999962147791e-05, 1845
[INFO] 2021-07-12 19:09:24,680 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1845
[INFO] 2021-07-12 19:09:24,680 [run_pretraining.py:  558]:	worker_index: 6, step: 1845, cost: 7.878545, mlm loss: 7.878545, speed: 0.849831 steps/s, speed: 6.798649 samples/s, speed: 3480.908184 tokens/s, learning rate: 1.844e-05, loss_scalings: 5497.559082, pp_loss: 7.157002
[INFO] 2021-07-12 19:09:24,680 [run_pretraining.py:  512]:	********exe.run_1845******* 
[INFO] 2021-07-12 19:09:25,751 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:25,751 [run_pretraining.py:  534]:	loss/total_loss, 7.119619369506836, 1846
[INFO] 2021-07-12 19:09:25,752 [run_pretraining.py:  535]:	loss/mlm_loss, 7.119619369506836, 1846
[INFO] 2021-07-12 19:09:25,752 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.84499986062292e-05, 1846
[INFO] 2021-07-12 19:09:25,752 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1846
[INFO] 2021-07-12 19:09:25,752 [run_pretraining.py:  558]:	worker_index: 6, step: 1846, cost: 7.119619, mlm loss: 7.119619, speed: 0.933443 steps/s, speed: 7.467548 samples/s, speed: 3823.384376 tokens/s, learning rate: 1.845e-05, loss_scalings: 5497.559082, pp_loss: 7.137018
[INFO] 2021-07-12 19:09:25,752 [run_pretraining.py:  512]:	********exe.run_1846******* 
[INFO] 2021-07-12 19:09:26,808 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:26,809 [run_pretraining.py:  534]:	loss/total_loss, 6.956160068511963, 1847
[INFO] 2021-07-12 19:09:26,809 [run_pretraining.py:  535]:	loss/mlm_loss, 6.956160068511963, 1847
[INFO] 2021-07-12 19:09:26,809 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8459999409969896e-05, 1847
[INFO] 2021-07-12 19:09:26,809 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1847
[INFO] 2021-07-12 19:09:26,809 [run_pretraining.py:  558]:	worker_index: 6, step: 1847, cost: 6.956160, mlm loss: 6.956160, speed: 0.946483 steps/s, speed: 7.571865 samples/s, speed: 3876.794878 tokens/s, learning rate: 1.846e-05, loss_scalings: 5497.559082, pp_loss: 7.167112
[INFO] 2021-07-12 19:09:26,809 [run_pretraining.py:  512]:	********exe.run_1847******* 
[INFO] 2021-07-12 19:09:27,869 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:27,870 [run_pretraining.py:  534]:	loss/total_loss, 7.033385753631592, 1848
[INFO] 2021-07-12 19:09:27,870 [run_pretraining.py:  535]:	loss/mlm_loss, 7.033385753631592, 1848
[INFO] 2021-07-12 19:09:27,870 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8469998394721188e-05, 1848
[INFO] 2021-07-12 19:09:27,870 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1848
[INFO] 2021-07-12 19:09:27,870 [run_pretraining.py:  558]:	worker_index: 6, step: 1848, cost: 7.033386, mlm loss: 7.033386, speed: 0.943238 steps/s, speed: 7.545902 samples/s, speed: 3863.502016 tokens/s, learning rate: 1.847e-05, loss_scalings: 5497.559082, pp_loss: 7.516943
[INFO] 2021-07-12 19:09:27,870 [run_pretraining.py:  512]:	********exe.run_1848******* 
[INFO] 2021-07-12 19:09:28,930 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:28,931 [run_pretraining.py:  534]:	loss/total_loss, 7.22588586807251, 1849
[INFO] 2021-07-12 19:09:28,931 [run_pretraining.py:  535]:	loss/mlm_loss, 7.22588586807251, 1849
[INFO] 2021-07-12 19:09:28,931 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8479999198461883e-05, 1849
[INFO] 2021-07-12 19:09:28,931 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1849
[INFO] 2021-07-12 19:09:28,931 [run_pretraining.py:  558]:	worker_index: 6, step: 1849, cost: 7.225886, mlm loss: 7.225886, speed: 0.943090 steps/s, speed: 7.544721 samples/s, speed: 3862.897394 tokens/s, learning rate: 1.848e-05, loss_scalings: 5497.559082, pp_loss: 7.390953
[INFO] 2021-07-12 19:09:28,931 [run_pretraining.py:  512]:	********exe.run_1849******* 
[INFO] 2021-07-12 19:09:29,990 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:29,991 [run_pretraining.py:  534]:	loss/total_loss, 7.5475053787231445, 1850
[INFO] 2021-07-12 19:09:29,991 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5475053787231445, 1850
[INFO] 2021-07-12 19:09:29,991 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8490000002202578e-05, 1850
[INFO] 2021-07-12 19:09:29,991 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1850
[INFO] 2021-07-12 19:09:29,991 [run_pretraining.py:  558]:	worker_index: 6, step: 1850, cost: 7.547505, mlm loss: 7.547505, speed: 0.943711 steps/s, speed: 7.549685 samples/s, speed: 3865.438773 tokens/s, learning rate: 1.849e-05, loss_scalings: 5497.559082, pp_loss: 7.160160
[INFO] 2021-07-12 19:09:29,991 [run_pretraining.py:  512]:	********exe.run_1850******* 
[INFO] 2021-07-12 19:09:31,172 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:31,173 [run_pretraining.py:  534]:	loss/total_loss, 6.752523422241211, 1851
[INFO] 2021-07-12 19:09:31,173 [run_pretraining.py:  535]:	loss/mlm_loss, 6.752523422241211, 1851
[INFO] 2021-07-12 19:09:31,173 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.849999898695387e-05, 1851
[INFO] 2021-07-12 19:09:31,173 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1851
[INFO] 2021-07-12 19:09:31,173 [run_pretraining.py:  558]:	worker_index: 6, step: 1851, cost: 6.752523, mlm loss: 6.752523, speed: 0.846776 steps/s, speed: 6.774212 samples/s, speed: 3468.396406 tokens/s, learning rate: 1.850e-05, loss_scalings: 5497.559082, pp_loss: 7.103076
[INFO] 2021-07-12 19:09:31,173 [run_pretraining.py:  512]:	********exe.run_1851******* 
[INFO] 2021-07-12 19:09:32,335 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:32,335 [run_pretraining.py:  534]:	loss/total_loss, 7.106606483459473, 1852
[INFO] 2021-07-12 19:09:32,336 [run_pretraining.py:  535]:	loss/mlm_loss, 7.106606483459473, 1852
[INFO] 2021-07-12 19:09:32,336 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8509999790694565e-05, 1852
[INFO] 2021-07-12 19:09:32,336 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1852
[INFO] 2021-07-12 19:09:32,336 [run_pretraining.py:  558]:	worker_index: 6, step: 1852, cost: 7.106606, mlm loss: 7.106606, speed: 0.860514 steps/s, speed: 6.884108 samples/s, speed: 3524.663535 tokens/s, learning rate: 1.851e-05, loss_scalings: 5497.559082, pp_loss: 7.220062
[INFO] 2021-07-12 19:09:32,336 [run_pretraining.py:  512]:	********exe.run_1852******* 
[INFO] 2021-07-12 19:09:33,513 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:33,514 [run_pretraining.py:  534]:	loss/total_loss, 7.343149185180664, 1853
[INFO] 2021-07-12 19:09:33,514 [run_pretraining.py:  535]:	loss/mlm_loss, 7.343149185180664, 1853
[INFO] 2021-07-12 19:09:33,514 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.852000059443526e-05, 1853
[INFO] 2021-07-12 19:09:33,514 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1853
[INFO] 2021-07-12 19:09:33,514 [run_pretraining.py:  558]:	worker_index: 6, step: 1853, cost: 7.343149, mlm loss: 7.343149, speed: 0.849075 steps/s, speed: 6.792599 samples/s, speed: 3477.810506 tokens/s, learning rate: 1.852e-05, loss_scalings: 5497.559082, pp_loss: 7.196685
[INFO] 2021-07-12 19:09:33,514 [run_pretraining.py:  512]:	********exe.run_1853******* 
[INFO] 2021-07-12 19:09:34,703 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:34,704 [run_pretraining.py:  534]:	loss/total_loss, 7.889697551727295, 1854
[INFO] 2021-07-12 19:09:34,704 [run_pretraining.py:  535]:	loss/mlm_loss, 7.889697551727295, 1854
[INFO] 2021-07-12 19:09:34,704 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.852999957918655e-05, 1854
[INFO] 2021-07-12 19:09:34,704 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1854
[INFO] 2021-07-12 19:09:34,704 [run_pretraining.py:  558]:	worker_index: 6, step: 1854, cost: 7.889698, mlm loss: 7.889698, speed: 0.841037 steps/s, speed: 6.728298 samples/s, speed: 3444.888519 tokens/s, learning rate: 1.853e-05, loss_scalings: 5497.559082, pp_loss: 6.740172
[INFO] 2021-07-12 19:09:34,704 [run_pretraining.py:  512]:	********exe.run_1854******* 
[INFO] 2021-07-12 19:09:35,968 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:35,969 [run_pretraining.py:  534]:	loss/total_loss, 7.295083045959473, 1855
[INFO] 2021-07-12 19:09:35,969 [run_pretraining.py:  535]:	loss/mlm_loss, 7.295083045959473, 1855
[INFO] 2021-07-12 19:09:35,969 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8539998563937843e-05, 1855
[INFO] 2021-07-12 19:09:35,969 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1855
[INFO] 2021-07-12 19:09:35,969 [run_pretraining.py:  558]:	worker_index: 6, step: 1855, cost: 7.295083, mlm loss: 7.295083, speed: 0.790846 steps/s, speed: 6.326772 samples/s, speed: 3239.307082 tokens/s, learning rate: 1.854e-05, loss_scalings: 5497.559082, pp_loss: 7.741794
[INFO] 2021-07-12 19:09:35,969 [run_pretraining.py:  512]:	********exe.run_1855******* 
[INFO] 2021-07-12 19:09:37,153 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:37,154 [run_pretraining.py:  534]:	loss/total_loss, 7.3679399490356445, 1856
[INFO] 2021-07-12 19:09:37,154 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3679399490356445, 1856
[INFO] 2021-07-12 19:09:37,154 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8549999367678538e-05, 1856
[INFO] 2021-07-12 19:09:37,154 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1856
[INFO] 2021-07-12 19:09:37,154 [run_pretraining.py:  558]:	worker_index: 6, step: 1856, cost: 7.367940, mlm loss: 7.367940, speed: 0.844549 steps/s, speed: 6.756389 samples/s, speed: 3459.271337 tokens/s, learning rate: 1.855e-05, loss_scalings: 5497.559082, pp_loss: 7.143521
[INFO] 2021-07-12 19:09:37,154 [run_pretraining.py:  512]:	********exe.run_1856******* 
[INFO] 2021-07-12 19:09:38,299 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:38,300 [run_pretraining.py:  534]:	loss/total_loss, 6.606274604797363, 1857
[INFO] 2021-07-12 19:09:38,300 [run_pretraining.py:  535]:	loss/mlm_loss, 6.606274604797363, 1857
[INFO] 2021-07-12 19:09:38,300 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8560000171419233e-05, 1857
[INFO] 2021-07-12 19:09:38,300 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1857
[INFO] 2021-07-12 19:09:38,300 [run_pretraining.py:  558]:	worker_index: 6, step: 1857, cost: 6.606275, mlm loss: 6.606275, speed: 0.872815 steps/s, speed: 6.982523 samples/s, speed: 3575.051937 tokens/s, learning rate: 1.856e-05, loss_scalings: 5497.559082, pp_loss: 7.278615
[INFO] 2021-07-12 19:09:38,300 [run_pretraining.py:  512]:	********exe.run_1857******* 
[INFO] 2021-07-12 19:09:39,449 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:39,450 [run_pretraining.py:  534]:	loss/total_loss, 7.0653977394104, 1858
[INFO] 2021-07-12 19:09:39,450 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0653977394104, 1858
[INFO] 2021-07-12 19:09:39,450 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8569999156170525e-05, 1858
[INFO] 2021-07-12 19:09:39,450 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1858
[INFO] 2021-07-12 19:09:39,450 [run_pretraining.py:  558]:	worker_index: 6, step: 1858, cost: 7.065398, mlm loss: 7.065398, speed: 0.870382 steps/s, speed: 6.963058 samples/s, speed: 3565.085549 tokens/s, learning rate: 1.857e-05, loss_scalings: 5497.559082, pp_loss: 7.328662
[INFO] 2021-07-12 19:09:39,450 [run_pretraining.py:  512]:	********exe.run_1858******* 
[INFO] 2021-07-12 19:09:40,569 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:40,570 [run_pretraining.py:  534]:	loss/total_loss, 7.159513473510742, 1859
[INFO] 2021-07-12 19:09:40,570 [run_pretraining.py:  535]:	loss/mlm_loss, 7.159513473510742, 1859
[INFO] 2021-07-12 19:09:40,570 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.857999995991122e-05, 1859
[INFO] 2021-07-12 19:09:40,570 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1859
[INFO] 2021-07-12 19:09:40,570 [run_pretraining.py:  558]:	worker_index: 6, step: 1859, cost: 7.159513, mlm loss: 7.159513, speed: 0.893100 steps/s, speed: 7.144803 samples/s, speed: 3658.139216 tokens/s, learning rate: 1.858e-05, loss_scalings: 5497.559082, pp_loss: 7.454841
[INFO] 2021-07-12 19:09:40,570 [run_pretraining.py:  512]:	********exe.run_1859******* 
[INFO] 2021-07-12 19:09:41,635 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:41,636 [run_pretraining.py:  534]:	loss/total_loss, 7.726424217224121, 1860
[INFO] 2021-07-12 19:09:41,636 [run_pretraining.py:  535]:	loss/mlm_loss, 7.726424217224121, 1860
[INFO] 2021-07-12 19:09:41,636 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.858999894466251e-05, 1860
[INFO] 2021-07-12 19:09:41,636 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1860
[INFO] 2021-07-12 19:09:41,636 [run_pretraining.py:  558]:	worker_index: 6, step: 1860, cost: 7.726424, mlm loss: 7.726424, speed: 0.938921 steps/s, speed: 7.511365 samples/s, speed: 3845.818912 tokens/s, learning rate: 1.859e-05, loss_scalings: 5497.559082, pp_loss: 7.382612
[INFO] 2021-07-12 19:09:41,636 [run_pretraining.py:  512]:	********exe.run_1860******* 
[INFO] 2021-07-12 19:09:42,545 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:42,545 [run_pretraining.py:  534]:	loss/total_loss, 7.46898889541626, 1861
[INFO] 2021-07-12 19:09:42,545 [run_pretraining.py:  535]:	loss/mlm_loss, 7.46898889541626, 1861
[INFO] 2021-07-12 19:09:42,546 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8599999748403206e-05, 1861
[INFO] 2021-07-12 19:09:42,546 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1861
[INFO] 2021-07-12 19:09:42,546 [run_pretraining.py:  558]:	worker_index: 6, step: 1861, cost: 7.468989, mlm loss: 7.468989, speed: 1.100146 steps/s, speed: 8.801165 samples/s, speed: 4506.196378 tokens/s, learning rate: 1.860e-05, loss_scalings: 5497.559082, pp_loss: 7.398695
[INFO] 2021-07-12 19:09:42,546 [run_pretraining.py:  512]:	********exe.run_1861******* 
[INFO] 2021-07-12 19:09:43,462 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:43,462 [run_pretraining.py:  534]:	loss/total_loss, 7.854142665863037, 1862
[INFO] 2021-07-12 19:09:43,462 [run_pretraining.py:  535]:	loss/mlm_loss, 7.854142665863037, 1862
[INFO] 2021-07-12 19:09:43,462 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.86100005521439e-05, 1862
[INFO] 2021-07-12 19:09:43,463 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1862
[INFO] 2021-07-12 19:09:43,463 [run_pretraining.py:  558]:	worker_index: 6, step: 1862, cost: 7.854143, mlm loss: 7.854143, speed: 1.091529 steps/s, speed: 8.732232 samples/s, speed: 4470.902914 tokens/s, learning rate: 1.861e-05, loss_scalings: 5497.559082, pp_loss: 7.386903
[INFO] 2021-07-12 19:09:43,463 [run_pretraining.py:  512]:	********exe.run_1862******* 
[INFO] 2021-07-12 19:09:44,377 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:44,378 [run_pretraining.py:  534]:	loss/total_loss, 7.504901885986328, 1863
[INFO] 2021-07-12 19:09:44,378 [run_pretraining.py:  535]:	loss/mlm_loss, 7.504901885986328, 1863
[INFO] 2021-07-12 19:09:44,378 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8619999536895193e-05, 1863
[INFO] 2021-07-12 19:09:44,378 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1863
[INFO] 2021-07-12 19:09:44,378 [run_pretraining.py:  558]:	worker_index: 6, step: 1863, cost: 7.504902, mlm loss: 7.504902, speed: 1.093022 steps/s, speed: 8.744177 samples/s, speed: 4477.018539 tokens/s, learning rate: 1.862e-05, loss_scalings: 5497.559082, pp_loss: 7.382709
[INFO] 2021-07-12 19:09:44,378 [run_pretraining.py:  512]:	********exe.run_1863******* 
[INFO] 2021-07-12 19:09:45,287 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:45,288 [run_pretraining.py:  534]:	loss/total_loss, 7.7682695388793945, 1864
[INFO] 2021-07-12 19:09:45,288 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7682695388793945, 1864
[INFO] 2021-07-12 19:09:45,288 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8629998521646485e-05, 1864
[INFO] 2021-07-12 19:09:45,288 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1864
[INFO] 2021-07-12 19:09:45,288 [run_pretraining.py:  558]:	worker_index: 6, step: 1864, cost: 7.768270, mlm loss: 7.768270, speed: 1.099637 steps/s, speed: 8.797094 samples/s, speed: 4504.112376 tokens/s, learning rate: 1.863e-05, loss_scalings: 5497.559082, pp_loss: 7.573843
[INFO] 2021-07-12 19:09:45,288 [run_pretraining.py:  512]:	********exe.run_1864******* 
[INFO] 2021-07-12 19:09:46,228 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:46,229 [run_pretraining.py:  534]:	loss/total_loss, 7.4894232749938965, 1865
[INFO] 2021-07-12 19:09:46,229 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4894232749938965, 1865
[INFO] 2021-07-12 19:09:46,229 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.863999932538718e-05, 1865
[INFO] 2021-07-12 19:09:46,229 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1865
[INFO] 2021-07-12 19:09:46,229 [run_pretraining.py:  558]:	worker_index: 6, step: 1865, cost: 7.489423, mlm loss: 7.489423, speed: 1.063477 steps/s, speed: 8.507815 samples/s, speed: 4356.001410 tokens/s, learning rate: 1.864e-05, loss_scalings: 5497.559082, pp_loss: 7.529793
[INFO] 2021-07-12 19:09:46,229 [run_pretraining.py:  512]:	********exe.run_1865******* 
[INFO] 2021-07-12 19:09:47,141 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:47,141 [run_pretraining.py:  534]:	loss/total_loss, 6.800669193267822, 1866
[INFO] 2021-07-12 19:09:47,141 [run_pretraining.py:  535]:	loss/mlm_loss, 6.800669193267822, 1866
[INFO] 2021-07-12 19:09:47,141 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8650000129127875e-05, 1866
[INFO] 2021-07-12 19:09:47,141 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1866
[INFO] 2021-07-12 19:09:47,142 [run_pretraining.py:  558]:	worker_index: 6, step: 1866, cost: 6.800669, mlm loss: 6.800669, speed: 1.097143 steps/s, speed: 8.777146 samples/s, speed: 4493.898710 tokens/s, learning rate: 1.865e-05, loss_scalings: 5497.559082, pp_loss: 7.330960
[INFO] 2021-07-12 19:09:47,142 [run_pretraining.py:  512]:	********exe.run_1866******* 
[INFO] 2021-07-12 19:09:48,044 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:48,044 [run_pretraining.py:  534]:	loss/total_loss, 8.308629989624023, 1867
[INFO] 2021-07-12 19:09:48,044 [run_pretraining.py:  535]:	loss/mlm_loss, 8.308629989624023, 1867
[INFO] 2021-07-12 19:09:48,045 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8659999113879167e-05, 1867
[INFO] 2021-07-12 19:09:48,045 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1867
[INFO] 2021-07-12 19:09:48,045 [run_pretraining.py:  558]:	worker_index: 6, step: 1867, cost: 8.308630, mlm loss: 8.308630, speed: 1.108080 steps/s, speed: 8.864641 samples/s, speed: 4538.696429 tokens/s, learning rate: 1.866e-05, loss_scalings: 5497.559082, pp_loss: 7.529261
[INFO] 2021-07-12 19:09:48,045 [run_pretraining.py:  512]:	********exe.run_1867******* 
[INFO] 2021-07-12 19:09:48,956 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:48,957 [run_pretraining.py:  534]:	loss/total_loss, 7.342582702636719, 1868
[INFO] 2021-07-12 19:09:48,957 [run_pretraining.py:  535]:	loss/mlm_loss, 7.342582702636719, 1868
[INFO] 2021-07-12 19:09:48,957 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.866999991761986e-05, 1868
[INFO] 2021-07-12 19:09:48,957 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1868
[INFO] 2021-07-12 19:09:48,957 [run_pretraining.py:  558]:	worker_index: 6, step: 1868, cost: 7.342583, mlm loss: 7.342583, speed: 1.097071 steps/s, speed: 8.776570 samples/s, speed: 4493.603676 tokens/s, learning rate: 1.867e-05, loss_scalings: 5497.559082, pp_loss: 7.343900
[INFO] 2021-07-12 19:09:48,957 [run_pretraining.py:  512]:	********exe.run_1868******* 
[INFO] 2021-07-12 19:09:49,859 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:49,860 [run_pretraining.py:  534]:	loss/total_loss, 6.878739833831787, 1869
[INFO] 2021-07-12 19:09:49,860 [run_pretraining.py:  535]:	loss/mlm_loss, 6.878739833831787, 1869
[INFO] 2021-07-12 19:09:49,860 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8680000721360557e-05, 1869
[INFO] 2021-07-12 19:09:49,860 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1869
[INFO] 2021-07-12 19:09:49,860 [run_pretraining.py:  558]:	worker_index: 6, step: 1869, cost: 6.878740, mlm loss: 6.878740, speed: 1.107730 steps/s, speed: 8.861841 samples/s, speed: 4537.262801 tokens/s, learning rate: 1.868e-05, loss_scalings: 5497.559082, pp_loss: 7.688712
[INFO] 2021-07-12 19:09:49,860 [run_pretraining.py:  512]:	********exe.run_1869******* 
[INFO] 2021-07-12 19:09:50,775 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:50,776 [run_pretraining.py:  534]:	loss/total_loss, 7.736846923828125, 1870
[INFO] 2021-07-12 19:09:50,776 [run_pretraining.py:  535]:	loss/mlm_loss, 7.736846923828125, 1870
[INFO] 2021-07-12 19:09:50,776 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.868999970611185e-05, 1870
[INFO] 2021-07-12 19:09:50,776 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1870
[INFO] 2021-07-12 19:09:50,776 [run_pretraining.py:  558]:	worker_index: 6, step: 1870, cost: 7.736847, mlm loss: 7.736847, speed: 1.092807 steps/s, speed: 8.742452 samples/s, speed: 4476.135524 tokens/s, learning rate: 1.869e-05, loss_scalings: 5497.559082, pp_loss: 7.327511
[INFO] 2021-07-12 19:09:50,776 [run_pretraining.py:  512]:	********exe.run_1870******* 
[INFO] 2021-07-12 19:09:51,685 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:51,685 [run_pretraining.py:  534]:	loss/total_loss, 6.833205223083496, 1871
[INFO] 2021-07-12 19:09:51,686 [run_pretraining.py:  535]:	loss/mlm_loss, 6.833205223083496, 1871
[INFO] 2021-07-12 19:09:51,686 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8700000509852543e-05, 1871
[INFO] 2021-07-12 19:09:51,686 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1871
[INFO] 2021-07-12 19:09:51,686 [run_pretraining.py:  558]:	worker_index: 6, step: 1871, cost: 6.833205, mlm loss: 6.833205, speed: 1.100072 steps/s, speed: 8.800578 samples/s, speed: 4505.896182 tokens/s, learning rate: 1.870e-05, loss_scalings: 5497.559082, pp_loss: 7.402673
[INFO] 2021-07-12 19:09:51,686 [run_pretraining.py:  512]:	********exe.run_1871******* 
[INFO] 2021-07-12 19:09:52,589 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:52,590 [run_pretraining.py:  534]:	loss/total_loss, 6.972709655761719, 1872
[INFO] 2021-07-12 19:09:52,590 [run_pretraining.py:  535]:	loss/mlm_loss, 6.972709655761719, 1872
[INFO] 2021-07-12 19:09:52,590 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8709999494603835e-05, 1872
[INFO] 2021-07-12 19:09:52,590 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1872
[INFO] 2021-07-12 19:09:52,590 [run_pretraining.py:  558]:	worker_index: 6, step: 1872, cost: 6.972710, mlm loss: 6.972710, speed: 1.106834 steps/s, speed: 8.854674 samples/s, speed: 4533.592962 tokens/s, learning rate: 1.871e-05, loss_scalings: 5497.559082, pp_loss: 7.203323
[INFO] 2021-07-12 19:09:52,590 [run_pretraining.py:  512]:	********exe.run_1872******* 
[INFO] 2021-07-12 19:09:53,495 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:53,496 [run_pretraining.py:  534]:	loss/total_loss, 6.935446739196777, 1873
[INFO] 2021-07-12 19:09:53,496 [run_pretraining.py:  535]:	loss/mlm_loss, 6.935446739196777, 1873
[INFO] 2021-07-12 19:09:53,496 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8719998479355127e-05, 1873
[INFO] 2021-07-12 19:09:53,496 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1873
[INFO] 2021-07-12 19:09:53,496 [run_pretraining.py:  558]:	worker_index: 6, step: 1873, cost: 6.935447, mlm loss: 6.935447, speed: 1.104761 steps/s, speed: 8.838091 samples/s, speed: 4525.102707 tokens/s, learning rate: 1.872e-05, loss_scalings: 5497.559082, pp_loss: 7.055272
[INFO] 2021-07-12 19:09:53,496 [run_pretraining.py:  512]:	********exe.run_1873******* 
[INFO] 2021-07-12 19:09:54,396 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:54,396 [run_pretraining.py:  534]:	loss/total_loss, 7.204134941101074, 1874
[INFO] 2021-07-12 19:09:54,396 [run_pretraining.py:  535]:	loss/mlm_loss, 7.204134941101074, 1874
[INFO] 2021-07-12 19:09:54,397 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8729999283095822e-05, 1874
[INFO] 2021-07-12 19:09:54,397 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1874
[INFO] 2021-07-12 19:09:54,397 [run_pretraining.py:  558]:	worker_index: 6, step: 1874, cost: 7.204135, mlm loss: 7.204135, speed: 1.111012 steps/s, speed: 8.888094 samples/s, speed: 4550.704367 tokens/s, learning rate: 1.873e-05, loss_scalings: 5497.559082, pp_loss: 7.237632
[INFO] 2021-07-12 19:09:54,397 [run_pretraining.py:  512]:	********exe.run_1874******* 
[INFO] 2021-07-12 19:09:55,297 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:55,297 [run_pretraining.py:  534]:	loss/total_loss, 7.1987104415893555, 1875
[INFO] 2021-07-12 19:09:55,297 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1987104415893555, 1875
[INFO] 2021-07-12 19:09:55,297 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8740000086836517e-05, 1875
[INFO] 2021-07-12 19:09:55,297 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1875
[INFO] 2021-07-12 19:09:55,298 [run_pretraining.py:  558]:	worker_index: 6, step: 1875, cost: 7.198710, mlm loss: 7.198710, speed: 1.110910 steps/s, speed: 8.887280 samples/s, speed: 4550.287331 tokens/s, learning rate: 1.874e-05, loss_scalings: 5497.559082, pp_loss: 6.834900
[INFO] 2021-07-12 19:09:55,298 [run_pretraining.py:  512]:	********exe.run_1875******* 
[INFO] 2021-07-12 19:09:56,209 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:56,209 [run_pretraining.py:  534]:	loss/total_loss, 6.79919958114624, 1876
[INFO] 2021-07-12 19:09:56,209 [run_pretraining.py:  535]:	loss/mlm_loss, 6.79919958114624, 1876
[INFO] 2021-07-12 19:09:56,209 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.874999907158781e-05, 1876
[INFO] 2021-07-12 19:09:56,210 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1876
[INFO] 2021-07-12 19:09:56,210 [run_pretraining.py:  558]:	worker_index: 6, step: 1876, cost: 6.799200, mlm loss: 6.799200, speed: 1.097289 steps/s, speed: 8.778310 samples/s, speed: 4494.494773 tokens/s, learning rate: 1.875e-05, loss_scalings: 5497.559082, pp_loss: 6.965316
[INFO] 2021-07-12 19:09:56,210 [run_pretraining.py:  512]:	********exe.run_1876******* 
[INFO] 2021-07-12 19:09:57,146 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:57,146 [run_pretraining.py:  534]:	loss/total_loss, 7.5243988037109375, 1877
[INFO] 2021-07-12 19:09:57,147 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5243988037109375, 1877
[INFO] 2021-07-12 19:09:57,147 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8759999875328504e-05, 1877
[INFO] 2021-07-12 19:09:57,147 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1877
[INFO] 2021-07-12 19:09:57,147 [run_pretraining.py:  558]:	worker_index: 6, step: 1877, cost: 7.524399, mlm loss: 7.524399, speed: 1.067784 steps/s, speed: 8.542275 samples/s, speed: 4373.644792 tokens/s, learning rate: 1.876e-05, loss_scalings: 5497.559082, pp_loss: 7.352070
[INFO] 2021-07-12 19:09:57,147 [run_pretraining.py:  512]:	********exe.run_1877******* 
[INFO] 2021-07-12 19:09:58,054 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:58,055 [run_pretraining.py:  534]:	loss/total_loss, 6.861743927001953, 1878
[INFO] 2021-07-12 19:09:58,055 [run_pretraining.py:  535]:	loss/mlm_loss, 6.861743927001953, 1878
[INFO] 2021-07-12 19:09:58,055 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.87700006790692e-05, 1878
[INFO] 2021-07-12 19:09:58,055 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1878
[INFO] 2021-07-12 19:09:58,055 [run_pretraining.py:  558]:	worker_index: 6, step: 1878, cost: 6.861744, mlm loss: 6.861744, speed: 1.101960 steps/s, speed: 8.815681 samples/s, speed: 4513.628921 tokens/s, learning rate: 1.877e-05, loss_scalings: 5497.559082, pp_loss: 7.337971
[INFO] 2021-07-12 19:09:58,055 [run_pretraining.py:  512]:	********exe.run_1878******* 
[INFO] 2021-07-12 19:09:58,967 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:58,967 [run_pretraining.py:  534]:	loss/total_loss, 7.331333160400391, 1879
[INFO] 2021-07-12 19:09:58,967 [run_pretraining.py:  535]:	loss/mlm_loss, 7.331333160400391, 1879
[INFO] 2021-07-12 19:09:58,967 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.877999966382049e-05, 1879
[INFO] 2021-07-12 19:09:58,968 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1879
[INFO] 2021-07-12 19:09:58,968 [run_pretraining.py:  558]:	worker_index: 6, step: 1879, cost: 7.331333, mlm loss: 7.331333, speed: 1.096538 steps/s, speed: 8.772304 samples/s, speed: 4491.419750 tokens/s, learning rate: 1.878e-05, loss_scalings: 5497.559082, pp_loss: 7.127393
[INFO] 2021-07-12 19:09:58,968 [run_pretraining.py:  512]:	********exe.run_1879******* 
[INFO] 2021-07-12 19:09:59,918 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:59,919 [run_pretraining.py:  534]:	loss/total_loss, 6.7093987464904785, 1880
[INFO] 2021-07-12 19:09:59,919 [run_pretraining.py:  535]:	loss/mlm_loss, 6.7093987464904785, 1880
[INFO] 2021-07-12 19:09:59,919 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8790000467561185e-05, 1880
[INFO] 2021-07-12 19:09:59,919 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1880
[INFO] 2021-07-12 19:09:59,919 [run_pretraining.py:  558]:	worker_index: 6, step: 1880, cost: 6.709399, mlm loss: 6.709399, speed: 1.051478 steps/s, speed: 8.411820 samples/s, speed: 4306.852054 tokens/s, learning rate: 1.879e-05, loss_scalings: 5497.559082, pp_loss: 7.366483
[INFO] 2021-07-12 19:09:59,920 [run_pretraining.py:  512]:	********exe.run_1880******* 
[INFO] 2021-07-12 19:10:00,984 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:00,985 [run_pretraining.py:  534]:	loss/total_loss, 6.9137163162231445, 1881
[INFO] 2021-07-12 19:10:00,985 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9137163162231445, 1881
[INFO] 2021-07-12 19:10:00,985 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8799999452312477e-05, 1881
[INFO] 2021-07-12 19:10:00,985 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1881
[INFO] 2021-07-12 19:10:00,985 [run_pretraining.py:  558]:	worker_index: 6, step: 1881, cost: 6.913716, mlm loss: 6.913716, speed: 0.939127 steps/s, speed: 7.513015 samples/s, speed: 3846.663651 tokens/s, learning rate: 1.880e-05, loss_scalings: 5497.559082, pp_loss: 6.715754
[INFO] 2021-07-12 19:10:00,985 [run_pretraining.py:  512]:	********exe.run_1881******* 
[INFO] 2021-07-12 19:10:02,059 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:02,060 [run_pretraining.py:  534]:	loss/total_loss, 7.504316806793213, 1882
[INFO] 2021-07-12 19:10:02,060 [run_pretraining.py:  535]:	loss/mlm_loss, 7.504316806793213, 1882
[INFO] 2021-07-12 19:10:02,060 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.880999843706377e-05, 1882
[INFO] 2021-07-12 19:10:02,060 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1882
[INFO] 2021-07-12 19:10:02,060 [run_pretraining.py:  558]:	worker_index: 6, step: 1882, cost: 7.504317, mlm loss: 7.504317, speed: 0.930557 steps/s, speed: 7.444457 samples/s, speed: 3811.562119 tokens/s, learning rate: 1.881e-05, loss_scalings: 5497.559082, pp_loss: 7.281935
[INFO] 2021-07-12 19:10:02,060 [run_pretraining.py:  512]:	********exe.run_1882******* 
[INFO] 2021-07-12 19:10:03,105 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:03,106 [run_pretraining.py:  534]:	loss/total_loss, 7.019233703613281, 1883
[INFO] 2021-07-12 19:10:03,106 [run_pretraining.py:  535]:	loss/mlm_loss, 7.019233703613281, 1883
[INFO] 2021-07-12 19:10:03,106 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8819999240804464e-05, 1883
[INFO] 2021-07-12 19:10:03,106 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1883
[INFO] 2021-07-12 19:10:03,106 [run_pretraining.py:  558]:	worker_index: 6, step: 1883, cost: 7.019234, mlm loss: 7.019234, speed: 0.956811 steps/s, speed: 7.654491 samples/s, speed: 3919.099226 tokens/s, learning rate: 1.882e-05, loss_scalings: 5497.559082, pp_loss: 7.219836
[INFO] 2021-07-12 19:10:03,106 [run_pretraining.py:  512]:	********exe.run_1883******* 
[INFO] 2021-07-12 19:10:04,171 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:04,172 [run_pretraining.py:  534]:	loss/total_loss, 7.2601318359375, 1884
[INFO] 2021-07-12 19:10:04,172 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2601318359375, 1884
[INFO] 2021-07-12 19:10:04,172 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.883000004454516e-05, 1884
[INFO] 2021-07-12 19:10:04,172 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1884
[INFO] 2021-07-12 19:10:04,172 [run_pretraining.py:  558]:	worker_index: 6, step: 1884, cost: 7.260132, mlm loss: 7.260132, speed: 0.938763 steps/s, speed: 7.510106 samples/s, speed: 3845.174199 tokens/s, learning rate: 1.883e-05, loss_scalings: 5497.559082, pp_loss: 7.226064
[INFO] 2021-07-12 19:10:04,172 [run_pretraining.py:  512]:	********exe.run_1884******* 
[INFO] 2021-07-12 19:10:05,226 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:05,227 [run_pretraining.py:  534]:	loss/total_loss, 6.834954261779785, 1885
[INFO] 2021-07-12 19:10:05,227 [run_pretraining.py:  535]:	loss/mlm_loss, 6.834954261779785, 1885
[INFO] 2021-07-12 19:10:05,227 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.883999902929645e-05, 1885
[INFO] 2021-07-12 19:10:05,227 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1885
[INFO] 2021-07-12 19:10:05,227 [run_pretraining.py:  558]:	worker_index: 6, step: 1885, cost: 6.834954, mlm loss: 6.834954, speed: 0.948383 steps/s, speed: 7.587067 samples/s, speed: 3884.578126 tokens/s, learning rate: 1.884e-05, loss_scalings: 5497.559082, pp_loss: 7.178258
[INFO] 2021-07-12 19:10:05,227 [run_pretraining.py:  512]:	********exe.run_1885******* 
[INFO] 2021-07-12 19:10:06,431 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:06,432 [run_pretraining.py:  534]:	loss/total_loss, 4.100362300872803, 1886
[INFO] 2021-07-12 19:10:06,432 [run_pretraining.py:  535]:	loss/mlm_loss, 4.100362300872803, 1886
[INFO] 2021-07-12 19:10:06,432 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8849999833037145e-05, 1886
[INFO] 2021-07-12 19:10:06,432 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1886
[INFO] 2021-07-12 19:10:06,432 [run_pretraining.py:  558]:	worker_index: 6, step: 1886, cost: 4.100362, mlm loss: 4.100362, speed: 0.830476 steps/s, speed: 6.643810 samples/s, speed: 3401.630971 tokens/s, learning rate: 1.885e-05, loss_scalings: 5497.559082, pp_loss: 6.309067
[INFO] 2021-07-12 19:10:06,432 [run_pretraining.py:  512]:	********exe.run_1886******* 
[INFO] 2021-07-12 19:10:07,666 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:07,667 [run_pretraining.py:  534]:	loss/total_loss, 6.673063278198242, 1887
[INFO] 2021-07-12 19:10:07,667 [run_pretraining.py:  535]:	loss/mlm_loss, 6.673063278198242, 1887
[INFO] 2021-07-12 19:10:07,667 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.886000063677784e-05, 1887
[INFO] 2021-07-12 19:10:07,667 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1887
[INFO] 2021-07-12 19:10:07,668 [run_pretraining.py:  558]:	worker_index: 6, step: 1887, cost: 6.673063, mlm loss: 6.673063, speed: 0.809847 steps/s, speed: 6.478775 samples/s, speed: 3317.132906 tokens/s, learning rate: 1.886e-05, loss_scalings: 5497.559082, pp_loss: 7.292061
[INFO] 2021-07-12 19:10:07,668 [run_pretraining.py:  512]:	********exe.run_1887******* 
[INFO] 2021-07-12 19:10:08,936 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:08,937 [run_pretraining.py:  534]:	loss/total_loss, 8.447979927062988, 1888
[INFO] 2021-07-12 19:10:08,937 [run_pretraining.py:  535]:	loss/mlm_loss, 8.447979927062988, 1888
[INFO] 2021-07-12 19:10:08,937 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8869999621529132e-05, 1888
[INFO] 2021-07-12 19:10:08,937 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1888
[INFO] 2021-07-12 19:10:08,937 [run_pretraining.py:  558]:	worker_index: 6, step: 1888, cost: 8.447980, mlm loss: 8.447980, speed: 0.788206 steps/s, speed: 6.305646 samples/s, speed: 3228.490989 tokens/s, learning rate: 1.887e-05, loss_scalings: 5497.559082, pp_loss: 6.876508
[INFO] 2021-07-12 19:10:08,937 [run_pretraining.py:  512]:	********exe.run_1888******* 
[INFO] 2021-07-12 19:10:09,896 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:09,896 [run_pretraining.py:  534]:	loss/total_loss, 7.399233818054199, 1889
[INFO] 2021-07-12 19:10:09,896 [run_pretraining.py:  535]:	loss/mlm_loss, 7.399233818054199, 1889
[INFO] 2021-07-12 19:10:09,896 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8880000425269827e-05, 1889
[INFO] 2021-07-12 19:10:09,897 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1889
[INFO] 2021-07-12 19:10:09,897 [run_pretraining.py:  558]:	worker_index: 6, step: 1889, cost: 7.399234, mlm loss: 7.399234, speed: 1.042770 steps/s, speed: 8.342159 samples/s, speed: 4271.185336 tokens/s, learning rate: 1.888e-05, loss_scalings: 5497.559082, pp_loss: 7.067908
[INFO] 2021-07-12 19:10:09,897 [run_pretraining.py:  512]:	********exe.run_1889******* 
[INFO] 2021-07-12 19:10:10,807 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:10,808 [run_pretraining.py:  534]:	loss/total_loss, 7.310816287994385, 1890
[INFO] 2021-07-12 19:10:10,808 [run_pretraining.py:  535]:	loss/mlm_loss, 7.310816287994385, 1890
[INFO] 2021-07-12 19:10:10,808 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.888999941002112e-05, 1890
[INFO] 2021-07-12 19:10:10,808 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1890
[INFO] 2021-07-12 19:10:10,808 [run_pretraining.py:  558]:	worker_index: 6, step: 1890, cost: 7.310816, mlm loss: 7.310816, speed: 1.098122 steps/s, speed: 8.784977 samples/s, speed: 4497.908426 tokens/s, learning rate: 1.889e-05, loss_scalings: 5497.559082, pp_loss: 7.166232
[INFO] 2021-07-12 19:10:10,808 [run_pretraining.py:  512]:	********exe.run_1890******* 
[INFO] 2021-07-12 19:10:11,725 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:11,726 [run_pretraining.py:  534]:	loss/total_loss, 7.8962721824646, 1891
[INFO] 2021-07-12 19:10:11,726 [run_pretraining.py:  535]:	loss/mlm_loss, 7.8962721824646, 1891
[INFO] 2021-07-12 19:10:11,726 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.889999839477241e-05, 1891
[INFO] 2021-07-12 19:10:11,726 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1891
[INFO] 2021-07-12 19:10:11,726 [run_pretraining.py:  558]:	worker_index: 6, step: 1891, cost: 7.896272, mlm loss: 7.896272, speed: 1.089989 steps/s, speed: 8.719912 samples/s, speed: 4464.595123 tokens/s, learning rate: 1.890e-05, loss_scalings: 5497.559082, pp_loss: 7.931961
[INFO] 2021-07-12 19:10:11,726 [run_pretraining.py:  512]:	********exe.run_1891******* 
[INFO] 2021-07-12 19:10:12,642 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:12,643 [run_pretraining.py:  534]:	loss/total_loss, 7.040517807006836, 1892
[INFO] 2021-07-12 19:10:12,643 [run_pretraining.py:  535]:	loss/mlm_loss, 7.040517807006836, 1892
[INFO] 2021-07-12 19:10:12,643 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8909999198513106e-05, 1892
[INFO] 2021-07-12 19:10:12,643 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1892
[INFO] 2021-07-12 19:10:12,643 [run_pretraining.py:  558]:	worker_index: 6, step: 1892, cost: 7.040518, mlm loss: 7.040518, speed: 1.091533 steps/s, speed: 8.732262 samples/s, speed: 4470.918040 tokens/s, learning rate: 1.891e-05, loss_scalings: 5497.559082, pp_loss: 7.044930
[INFO] 2021-07-12 19:10:12,643 [run_pretraining.py:  512]:	********exe.run_1892******* 
[INFO] 2021-07-12 19:10:13,552 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:13,552 [run_pretraining.py:  534]:	loss/total_loss, 7.56785249710083, 1893
[INFO] 2021-07-12 19:10:13,553 [run_pretraining.py:  535]:	loss/mlm_loss, 7.56785249710083, 1893
[INFO] 2021-07-12 19:10:13,553 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.89200000022538e-05, 1893
[INFO] 2021-07-12 19:10:13,553 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1893
[INFO] 2021-07-12 19:10:13,553 [run_pretraining.py:  558]:	worker_index: 6, step: 1893, cost: 7.567852, mlm loss: 7.567852, speed: 1.099897 steps/s, speed: 8.799180 samples/s, speed: 4505.180127 tokens/s, learning rate: 1.892e-05, loss_scalings: 5497.559082, pp_loss: 7.390273
[INFO] 2021-07-12 19:10:13,553 [run_pretraining.py:  512]:	********exe.run_1893******* 
[INFO] 2021-07-12 19:10:14,465 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:14,466 [run_pretraining.py:  534]:	loss/total_loss, 7.182267189025879, 1894
[INFO] 2021-07-12 19:10:14,466 [run_pretraining.py:  535]:	loss/mlm_loss, 7.182267189025879, 1894
[INFO] 2021-07-12 19:10:14,466 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8929998987005092e-05, 1894
[INFO] 2021-07-12 19:10:14,466 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1894
[INFO] 2021-07-12 19:10:14,466 [run_pretraining.py:  558]:	worker_index: 6, step: 1894, cost: 7.182267, mlm loss: 7.182267, speed: 1.095757 steps/s, speed: 8.766052 samples/s, speed: 4488.218776 tokens/s, learning rate: 1.893e-05, loss_scalings: 5497.559082, pp_loss: 6.641289
[INFO] 2021-07-12 19:10:14,466 [run_pretraining.py:  512]:	********exe.run_1894******* 
[INFO] 2021-07-12 19:10:15,377 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:15,378 [run_pretraining.py:  534]:	loss/total_loss, 6.951099872589111, 1895
[INFO] 2021-07-12 19:10:15,378 [run_pretraining.py:  535]:	loss/mlm_loss, 6.951099872589111, 1895
[INFO] 2021-07-12 19:10:15,378 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8939999790745787e-05, 1895
[INFO] 2021-07-12 19:10:15,378 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1895
[INFO] 2021-07-12 19:10:15,378 [run_pretraining.py:  558]:	worker_index: 6, step: 1895, cost: 6.951100, mlm loss: 6.951100, speed: 1.097488 steps/s, speed: 8.779904 samples/s, speed: 4495.310943 tokens/s, learning rate: 1.894e-05, loss_scalings: 5497.559082, pp_loss: 7.371137
[INFO] 2021-07-12 19:10:15,378 [run_pretraining.py:  512]:	********exe.run_1895******* 
[INFO] 2021-07-12 19:10:16,288 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:16,288 [run_pretraining.py:  534]:	loss/total_loss, 7.007143497467041, 1896
[INFO] 2021-07-12 19:10:16,289 [run_pretraining.py:  535]:	loss/mlm_loss, 7.007143497467041, 1896
[INFO] 2021-07-12 19:10:16,289 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8950000594486482e-05, 1896
[INFO] 2021-07-12 19:10:16,289 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1896
[INFO] 2021-07-12 19:10:16,289 [run_pretraining.py:  558]:	worker_index: 6, step: 1896, cost: 7.007143, mlm loss: 7.007143, speed: 1.098811 steps/s, speed: 8.790485 samples/s, speed: 4500.728213 tokens/s, learning rate: 1.895e-05, loss_scalings: 5497.559082, pp_loss: 7.519912
[INFO] 2021-07-12 19:10:16,289 [run_pretraining.py:  512]:	********exe.run_1896******* 
[INFO] 2021-07-12 19:10:17,202 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:17,203 [run_pretraining.py:  534]:	loss/total_loss, 7.287895202636719, 1897
[INFO] 2021-07-12 19:10:17,203 [run_pretraining.py:  535]:	loss/mlm_loss, 7.287895202636719, 1897
[INFO] 2021-07-12 19:10:17,203 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8959999579237774e-05, 1897
[INFO] 2021-07-12 19:10:17,203 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1897
[INFO] 2021-07-12 19:10:17,203 [run_pretraining.py:  558]:	worker_index: 6, step: 1897, cost: 7.287895, mlm loss: 7.287895, speed: 1.094610 steps/s, speed: 8.756883 samples/s, speed: 4483.524146 tokens/s, learning rate: 1.896e-05, loss_scalings: 5497.559082, pp_loss: 7.262374
[INFO] 2021-07-12 19:10:17,203 [run_pretraining.py:  512]:	********exe.run_1897******* 
[INFO] 2021-07-12 19:10:18,111 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:18,111 [run_pretraining.py:  534]:	loss/total_loss, 7.84879207611084, 1898
[INFO] 2021-07-12 19:10:18,111 [run_pretraining.py:  535]:	loss/mlm_loss, 7.84879207611084, 1898
[INFO] 2021-07-12 19:10:18,112 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.897000038297847e-05, 1898
[INFO] 2021-07-12 19:10:18,112 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1898
[INFO] 2021-07-12 19:10:18,112 [run_pretraining.py:  558]:	worker_index: 6, step: 1898, cost: 7.848792, mlm loss: 7.848792, speed: 1.101399 steps/s, speed: 8.811193 samples/s, speed: 4511.330717 tokens/s, learning rate: 1.897e-05, loss_scalings: 5497.559082, pp_loss: 7.388777
[INFO] 2021-07-12 19:10:18,112 [run_pretraining.py:  512]:	********exe.run_1898******* 
[INFO] 2021-07-12 19:10:19,037 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:19,038 [run_pretraining.py:  534]:	loss/total_loss, 7.374273777008057, 1899
[INFO] 2021-07-12 19:10:19,038 [run_pretraining.py:  535]:	loss/mlm_loss, 7.374273777008057, 1899
[INFO] 2021-07-12 19:10:19,038 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.897999936772976e-05, 1899
[INFO] 2021-07-12 19:10:19,038 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1899
[INFO] 2021-07-12 19:10:19,038 [run_pretraining.py:  558]:	worker_index: 6, step: 1899, cost: 7.374274, mlm loss: 7.374274, speed: 1.080289 steps/s, speed: 8.642309 samples/s, speed: 4424.862452 tokens/s, learning rate: 1.898e-05, loss_scalings: 5497.559082, pp_loss: 7.383641
[INFO] 2021-07-12 19:10:19,038 [run_pretraining.py:  512]:	********exe.run_1899******* 
[INFO] 2021-07-12 19:10:19,957 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:19,957 [run_pretraining.py:  534]:	loss/total_loss, 7.72119140625, 1900
[INFO] 2021-07-12 19:10:19,957 [run_pretraining.py:  535]:	loss/mlm_loss, 7.72119140625, 1900
[INFO] 2021-07-12 19:10:19,957 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8989998352481052e-05, 1900
[INFO] 2021-07-12 19:10:19,958 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1900
[INFO] 2021-07-12 19:10:19,958 [run_pretraining.py:  558]:	worker_index: 6, step: 1900, cost: 7.721191, mlm loss: 7.721191, speed: 1.088370 steps/s, speed: 8.706958 samples/s, speed: 4457.962671 tokens/s, learning rate: 1.899e-05, loss_scalings: 5497.559082, pp_loss: 7.396725
[INFO] 2021-07-12 19:10:19,958 [run_pretraining.py:  512]:	********exe.run_1900******* 
[INFO] 2021-07-12 19:10:20,880 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:20,880 [run_pretraining.py:  534]:	loss/total_loss, 7.208652019500732, 1901
[INFO] 2021-07-12 19:10:20,881 [run_pretraining.py:  535]:	loss/mlm_loss, 7.208652019500732, 1901
[INFO] 2021-07-12 19:10:20,881 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8999999156221747e-05, 1901
[INFO] 2021-07-12 19:10:20,881 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1901
[INFO] 2021-07-12 19:10:20,881 [run_pretraining.py:  558]:	worker_index: 6, step: 1901, cost: 7.208652, mlm loss: 7.208652, speed: 1.083975 steps/s, speed: 8.671801 samples/s, speed: 4439.962026 tokens/s, learning rate: 1.900e-05, loss_scalings: 5497.559082, pp_loss: 7.244148
[INFO] 2021-07-12 19:10:20,881 [run_pretraining.py:  512]:	********exe.run_1901******* 
[INFO] 2021-07-12 19:10:21,806 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:21,807 [run_pretraining.py:  534]:	loss/total_loss, 7.900680065155029, 1902
[INFO] 2021-07-12 19:10:21,807 [run_pretraining.py:  535]:	loss/mlm_loss, 7.900680065155029, 1902
[INFO] 2021-07-12 19:10:21,807 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9009999959962443e-05, 1902
[INFO] 2021-07-12 19:10:21,807 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1902
[INFO] 2021-07-12 19:10:21,807 [run_pretraining.py:  558]:	worker_index: 6, step: 1902, cost: 7.900680, mlm loss: 7.900680, speed: 1.080660 steps/s, speed: 8.645282 samples/s, speed: 4426.384437 tokens/s, learning rate: 1.901e-05, loss_scalings: 5497.559082, pp_loss: 7.749390
[INFO] 2021-07-12 19:10:21,807 [run_pretraining.py:  512]:	********exe.run_1902******* 
[INFO] 2021-07-12 19:10:22,727 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:22,727 [run_pretraining.py:  534]:	loss/total_loss, 7.248260021209717, 1903
[INFO] 2021-07-12 19:10:22,728 [run_pretraining.py:  535]:	loss/mlm_loss, 7.248260021209717, 1903
[INFO] 2021-07-12 19:10:22,728 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9019998944713734e-05, 1903
[INFO] 2021-07-12 19:10:22,728 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1903
[INFO] 2021-07-12 19:10:22,728 [run_pretraining.py:  558]:	worker_index: 6, step: 1903, cost: 7.248260, mlm loss: 7.248260, speed: 1.086795 steps/s, speed: 8.694363 samples/s, speed: 4451.513677 tokens/s, learning rate: 1.902e-05, loss_scalings: 5497.559082, pp_loss: 6.811818
[INFO] 2021-07-12 19:10:22,728 [run_pretraining.py:  512]:	********exe.run_1903******* 
[INFO] 2021-07-12 19:10:23,662 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:23,663 [run_pretraining.py:  534]:	loss/total_loss, 7.521876335144043, 1904
[INFO] 2021-07-12 19:10:23,663 [run_pretraining.py:  535]:	loss/mlm_loss, 7.521876335144043, 1904
[INFO] 2021-07-12 19:10:23,663 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.902999974845443e-05, 1904
[INFO] 2021-07-12 19:10:23,663 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1904
[INFO] 2021-07-12 19:10:23,663 [run_pretraining.py:  558]:	worker_index: 6, step: 1904, cost: 7.521876, mlm loss: 7.521876, speed: 1.070013 steps/s, speed: 8.560108 samples/s, speed: 4382.775099 tokens/s, learning rate: 1.903e-05, loss_scalings: 5497.559082, pp_loss: 7.414506
[INFO] 2021-07-12 19:10:23,663 [run_pretraining.py:  512]:	********exe.run_1904******* 
[INFO] 2021-07-12 19:10:24,581 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:24,582 [run_pretraining.py:  534]:	loss/total_loss, 4.687916278839111, 1905
[INFO] 2021-07-12 19:10:24,582 [run_pretraining.py:  535]:	loss/mlm_loss, 4.687916278839111, 1905
[INFO] 2021-07-12 19:10:24,582 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9040000552195124e-05, 1905
[INFO] 2021-07-12 19:10:24,582 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1905
[INFO] 2021-07-12 19:10:24,582 [run_pretraining.py:  558]:	worker_index: 6, step: 1905, cost: 4.687916, mlm loss: 4.687916, speed: 1.088684 steps/s, speed: 8.709474 samples/s, speed: 4459.250545 tokens/s, learning rate: 1.904e-05, loss_scalings: 5497.559082, pp_loss: 6.405830
[INFO] 2021-07-12 19:10:24,582 [run_pretraining.py:  512]:	********exe.run_1905******* 
[INFO] 2021-07-12 19:10:25,508 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:25,508 [run_pretraining.py:  534]:	loss/total_loss, 7.954998970031738, 1906
[INFO] 2021-07-12 19:10:25,509 [run_pretraining.py:  535]:	loss/mlm_loss, 7.954998970031738, 1906
[INFO] 2021-07-12 19:10:25,509 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9049999536946416e-05, 1906
[INFO] 2021-07-12 19:10:25,509 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1906
[INFO] 2021-07-12 19:10:25,509 [run_pretraining.py:  558]:	worker_index: 6, step: 1906, cost: 7.954999, mlm loss: 7.954999, speed: 1.080064 steps/s, speed: 8.640511 samples/s, speed: 4423.941789 tokens/s, learning rate: 1.905e-05, loss_scalings: 5497.559082, pp_loss: 7.606035
[INFO] 2021-07-12 19:10:25,509 [run_pretraining.py:  512]:	********exe.run_1906******* 
[INFO] 2021-07-12 19:10:26,432 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:26,433 [run_pretraining.py:  534]:	loss/total_loss, 7.338764190673828, 1907
[INFO] 2021-07-12 19:10:26,433 [run_pretraining.py:  535]:	loss/mlm_loss, 7.338764190673828, 1907
[INFO] 2021-07-12 19:10:26,433 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9059998521697707e-05, 1907
[INFO] 2021-07-12 19:10:26,433 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1907
[INFO] 2021-07-12 19:10:26,433 [run_pretraining.py:  558]:	worker_index: 6, step: 1907, cost: 7.338764, mlm loss: 7.338764, speed: 1.082949 steps/s, speed: 8.663588 samples/s, speed: 4435.757118 tokens/s, learning rate: 1.906e-05, loss_scalings: 5497.559082, pp_loss: 7.613693
[INFO] 2021-07-12 19:10:26,433 [run_pretraining.py:  512]:	********exe.run_1907******* 
[INFO] 2021-07-12 19:10:27,385 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:27,386 [run_pretraining.py:  534]:	loss/total_loss, 7.592065811157227, 1908
[INFO] 2021-07-12 19:10:27,386 [run_pretraining.py:  535]:	loss/mlm_loss, 7.592065811157227, 1908
[INFO] 2021-07-12 19:10:27,386 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9069999325438403e-05, 1908
[INFO] 2021-07-12 19:10:27,386 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1908
[INFO] 2021-07-12 19:10:27,386 [run_pretraining.py:  558]:	worker_index: 6, step: 1908, cost: 7.592066, mlm loss: 7.592066, speed: 1.049555 steps/s, speed: 8.396444 samples/s, speed: 4298.979318 tokens/s, learning rate: 1.907e-05, loss_scalings: 5497.559082, pp_loss: 7.221575
[INFO] 2021-07-12 19:10:27,387 [run_pretraining.py:  512]:	********exe.run_1908******* 
[INFO] 2021-07-12 19:10:28,298 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:28,298 [run_pretraining.py:  534]:	loss/total_loss, 6.58217716217041, 1909
[INFO] 2021-07-12 19:10:28,298 [run_pretraining.py:  535]:	loss/mlm_loss, 6.58217716217041, 1909
[INFO] 2021-07-12 19:10:28,299 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9079998310189694e-05, 1909
[INFO] 2021-07-12 19:10:28,299 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1909
[INFO] 2021-07-12 19:10:28,299 [run_pretraining.py:  558]:	worker_index: 6, step: 1909, cost: 6.582177, mlm loss: 6.582177, speed: 1.096957 steps/s, speed: 8.775658 samples/s, speed: 4493.137108 tokens/s, learning rate: 1.908e-05, loss_scalings: 5497.559082, pp_loss: 7.109381
[INFO] 2021-07-12 19:10:28,299 [run_pretraining.py:  512]:	********exe.run_1909******* 
[INFO] 2021-07-12 19:10:29,229 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:29,230 [run_pretraining.py:  534]:	loss/total_loss, 7.653572082519531, 1910
[INFO] 2021-07-12 19:10:29,230 [run_pretraining.py:  535]:	loss/mlm_loss, 7.653572082519531, 1910
[INFO] 2021-07-12 19:10:29,230 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.908999911393039e-05, 1910
[INFO] 2021-07-12 19:10:29,230 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1910
[INFO] 2021-07-12 19:10:29,230 [run_pretraining.py:  558]:	worker_index: 6, step: 1910, cost: 7.653572, mlm loss: 7.653572, speed: 1.074205 steps/s, speed: 8.593637 samples/s, speed: 4399.942217 tokens/s, learning rate: 1.909e-05, loss_scalings: 5497.559082, pp_loss: 7.657977
[INFO] 2021-07-12 19:10:29,230 [run_pretraining.py:  512]:	********exe.run_1910******* 
[INFO] 2021-07-12 19:10:30,163 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:30,164 [run_pretraining.py:  534]:	loss/total_loss, 7.235371112823486, 1911
[INFO] 2021-07-12 19:10:30,164 [run_pretraining.py:  535]:	loss/mlm_loss, 7.235371112823486, 1911
[INFO] 2021-07-12 19:10:30,164 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9099999917671084e-05, 1911
[INFO] 2021-07-12 19:10:30,164 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1911
[INFO] 2021-07-12 19:10:30,164 [run_pretraining.py:  558]:	worker_index: 6, step: 1911, cost: 7.235371, mlm loss: 7.235371, speed: 1.071308 steps/s, speed: 8.570463 samples/s, speed: 4388.076801 tokens/s, learning rate: 1.910e-05, loss_scalings: 5497.559082, pp_loss: 7.376737
[INFO] 2021-07-12 19:10:30,165 [run_pretraining.py:  512]:	********exe.run_1911******* 
[INFO] 2021-07-12 19:10:31,086 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:31,086 [run_pretraining.py:  534]:	loss/total_loss, 7.863796234130859, 1912
[INFO] 2021-07-12 19:10:31,086 [run_pretraining.py:  535]:	loss/mlm_loss, 7.863796234130859, 1912
[INFO] 2021-07-12 19:10:31,087 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9109998902422376e-05, 1912
[INFO] 2021-07-12 19:10:31,087 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1912
[INFO] 2021-07-12 19:10:31,087 [run_pretraining.py:  558]:	worker_index: 6, step: 1912, cost: 7.863796, mlm loss: 7.863796, speed: 1.085105 steps/s, speed: 8.680840 samples/s, speed: 4444.589973 tokens/s, learning rate: 1.911e-05, loss_scalings: 5497.559082, pp_loss: 7.730778
[INFO] 2021-07-12 19:10:31,087 [run_pretraining.py:  512]:	********exe.run_1912******* 
[INFO] 2021-07-12 19:10:32,006 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:32,007 [run_pretraining.py:  534]:	loss/total_loss, 7.7106218338012695, 1913
[INFO] 2021-07-12 19:10:32,007 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7106218338012695, 1913
[INFO] 2021-07-12 19:10:32,007 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.911999970616307e-05, 1913
[INFO] 2021-07-12 19:10:32,007 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1913
[INFO] 2021-07-12 19:10:32,007 [run_pretraining.py:  558]:	worker_index: 6, step: 1913, cost: 7.710622, mlm loss: 7.710622, speed: 1.087209 steps/s, speed: 8.697671 samples/s, speed: 4453.207574 tokens/s, learning rate: 1.912e-05, loss_scalings: 5497.559082, pp_loss: 7.417248
[INFO] 2021-07-12 19:10:32,007 [run_pretraining.py:  512]:	********exe.run_1913******* 
[INFO] 2021-07-12 19:10:32,953 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:32,954 [run_pretraining.py:  534]:	loss/total_loss, 7.142335891723633, 1914
[INFO] 2021-07-12 19:10:32,954 [run_pretraining.py:  535]:	loss/mlm_loss, 7.142335891723633, 1914
[INFO] 2021-07-12 19:10:32,954 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9130000509903766e-05, 1914
[INFO] 2021-07-12 19:10:32,954 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1914
[INFO] 2021-07-12 19:10:32,954 [run_pretraining.py:  558]:	worker_index: 6, step: 1914, cost: 7.142336, mlm loss: 7.142336, speed: 1.057019 steps/s, speed: 8.456154 samples/s, speed: 4329.550664 tokens/s, learning rate: 1.913e-05, loss_scalings: 5497.559082, pp_loss: 7.219464
[INFO] 2021-07-12 19:10:32,954 [run_pretraining.py:  512]:	********exe.run_1914******* 
[INFO] 2021-07-12 19:10:33,891 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:33,892 [run_pretraining.py:  534]:	loss/total_loss, 7.194528579711914, 1915
[INFO] 2021-07-12 19:10:33,892 [run_pretraining.py:  535]:	loss/mlm_loss, 7.194528579711914, 1915
[INFO] 2021-07-12 19:10:33,892 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9139999494655058e-05, 1915
[INFO] 2021-07-12 19:10:33,892 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1915
[INFO] 2021-07-12 19:10:33,892 [run_pretraining.py:  558]:	worker_index: 6, step: 1915, cost: 7.194529, mlm loss: 7.194529, speed: 1.066992 steps/s, speed: 8.535938 samples/s, speed: 4370.400407 tokens/s, learning rate: 1.914e-05, loss_scalings: 5497.559082, pp_loss: 7.128069
[INFO] 2021-07-12 19:10:33,892 [run_pretraining.py:  512]:	********exe.run_1915******* 
[INFO] 2021-07-12 19:10:34,822 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:34,822 [run_pretraining.py:  534]:	loss/total_loss, 6.675694942474365, 1916
[INFO] 2021-07-12 19:10:34,823 [run_pretraining.py:  535]:	loss/mlm_loss, 6.675694942474365, 1916
[INFO] 2021-07-12 19:10:34,823 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.914999847940635e-05, 1916
[INFO] 2021-07-12 19:10:34,823 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1916
[INFO] 2021-07-12 19:10:34,823 [run_pretraining.py:  558]:	worker_index: 6, step: 1916, cost: 6.675695, mlm loss: 6.675695, speed: 1.075032 steps/s, speed: 8.600258 samples/s, speed: 4403.332201 tokens/s, learning rate: 1.915e-05, loss_scalings: 5497.559082, pp_loss: 7.358799
[INFO] 2021-07-12 19:10:34,823 [run_pretraining.py:  512]:	********exe.run_1916******* 
[INFO] 2021-07-12 19:10:35,771 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:35,771 [run_pretraining.py:  534]:	loss/total_loss, 8.241805076599121, 1917
[INFO] 2021-07-12 19:10:35,771 [run_pretraining.py:  535]:	loss/mlm_loss, 8.241805076599121, 1917
[INFO] 2021-07-12 19:10:35,771 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9159999283147044e-05, 1917
[INFO] 2021-07-12 19:10:35,771 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1917
[INFO] 2021-07-12 19:10:35,772 [run_pretraining.py:  558]:	worker_index: 6, step: 1917, cost: 8.241805, mlm loss: 8.241805, speed: 1.054855 steps/s, speed: 8.438840 samples/s, speed: 4320.686180 tokens/s, learning rate: 1.916e-05, loss_scalings: 5497.559082, pp_loss: 7.315569
[INFO] 2021-07-12 19:10:35,772 [run_pretraining.py:  512]:	********exe.run_1917******* 
[INFO] 2021-07-12 19:10:36,697 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:36,697 [run_pretraining.py:  534]:	loss/total_loss, 6.491547584533691, 1918
[INFO] 2021-07-12 19:10:36,698 [run_pretraining.py:  535]:	loss/mlm_loss, 6.491547584533691, 1918
[INFO] 2021-07-12 19:10:36,698 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9169998267898336e-05, 1918
[INFO] 2021-07-12 19:10:36,698 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1918
[INFO] 2021-07-12 19:10:36,698 [run_pretraining.py:  558]:	worker_index: 6, step: 1918, cost: 6.491548, mlm loss: 6.491548, speed: 1.080474 steps/s, speed: 8.643792 samples/s, speed: 4425.621603 tokens/s, learning rate: 1.917e-05, loss_scalings: 5497.559082, pp_loss: 7.061392
[INFO] 2021-07-12 19:10:36,698 [run_pretraining.py:  512]:	********exe.run_1918******* 
[INFO] 2021-07-12 19:10:37,639 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:37,639 [run_pretraining.py:  534]:	loss/total_loss, 7.488421440124512, 1919
[INFO] 2021-07-12 19:10:37,640 [run_pretraining.py:  535]:	loss/mlm_loss, 7.488421440124512, 1919
[INFO] 2021-07-12 19:10:37,640 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.917999907163903e-05, 1919
[INFO] 2021-07-12 19:10:37,640 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1919
[INFO] 2021-07-12 19:10:37,640 [run_pretraining.py:  558]:	worker_index: 6, step: 1919, cost: 7.488421, mlm loss: 7.488421, speed: 1.062339 steps/s, speed: 8.498709 samples/s, speed: 4351.338891 tokens/s, learning rate: 1.918e-05, loss_scalings: 5497.559082, pp_loss: 6.893897
[INFO] 2021-07-12 19:10:37,640 [run_pretraining.py:  512]:	********exe.run_1919******* 
[INFO] 2021-07-12 19:10:38,583 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:38,584 [run_pretraining.py:  534]:	loss/total_loss, 6.700156211853027, 1920
[INFO] 2021-07-12 19:10:38,584 [run_pretraining.py:  535]:	loss/mlm_loss, 6.700156211853027, 1920
[INFO] 2021-07-12 19:10:38,584 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9189999875379726e-05, 1920
[INFO] 2021-07-12 19:10:38,584 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1920
[INFO] 2021-07-12 19:10:38,584 [run_pretraining.py:  558]:	worker_index: 6, step: 1920, cost: 6.700156, mlm loss: 6.700156, speed: 1.059733 steps/s, speed: 8.477863 samples/s, speed: 4340.665826 tokens/s, learning rate: 1.919e-05, loss_scalings: 5497.559082, pp_loss: 7.035013
[INFO] 2021-07-12 19:10:38,584 [run_pretraining.py:  512]:	********exe.run_1920******* 
[INFO] 2021-07-12 19:10:39,491 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:39,491 [run_pretraining.py:  534]:	loss/total_loss, 7.750363349914551, 1921
[INFO] 2021-07-12 19:10:39,491 [run_pretraining.py:  535]:	loss/mlm_loss, 7.750363349914551, 1921
[INFO] 2021-07-12 19:10:39,491 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9199998860131018e-05, 1921
[INFO] 2021-07-12 19:10:39,491 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1921
[INFO] 2021-07-12 19:10:39,492 [run_pretraining.py:  558]:	worker_index: 6, step: 1921, cost: 7.750363, mlm loss: 7.750363, speed: 1.103005 steps/s, speed: 8.824039 samples/s, speed: 4517.907983 tokens/s, learning rate: 1.920e-05, loss_scalings: 5497.559082, pp_loss: 7.380235
[INFO] 2021-07-12 19:10:39,492 [run_pretraining.py:  512]:	********exe.run_1921******* 
[INFO] 2021-07-12 19:10:40,397 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:40,398 [run_pretraining.py:  534]:	loss/total_loss, 7.545134544372559, 1922
[INFO] 2021-07-12 19:10:40,398 [run_pretraining.py:  535]:	loss/mlm_loss, 7.545134544372559, 1922
[INFO] 2021-07-12 19:10:40,398 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9209999663871713e-05, 1922
[INFO] 2021-07-12 19:10:40,398 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1922
[INFO] 2021-07-12 19:10:40,398 [run_pretraining.py:  558]:	worker_index: 6, step: 1922, cost: 7.545135, mlm loss: 7.545135, speed: 1.104147 steps/s, speed: 8.833180 samples/s, speed: 4522.588020 tokens/s, learning rate: 1.921e-05, loss_scalings: 5497.559082, pp_loss: 7.681540
[INFO] 2021-07-12 19:10:40,398 [run_pretraining.py:  512]:	********exe.run_1922******* 
[INFO] 2021-07-12 19:10:41,322 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:41,323 [run_pretraining.py:  534]:	loss/total_loss, 7.353723049163818, 1923
[INFO] 2021-07-12 19:10:41,323 [run_pretraining.py:  535]:	loss/mlm_loss, 7.353723049163818, 1923
[INFO] 2021-07-12 19:10:41,323 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9220000467612408e-05, 1923
[INFO] 2021-07-12 19:10:41,323 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1923
[INFO] 2021-07-12 19:10:41,323 [run_pretraining.py:  558]:	worker_index: 6, step: 1923, cost: 7.353723, mlm loss: 7.353723, speed: 1.081287 steps/s, speed: 8.650299 samples/s, speed: 4428.953092 tokens/s, learning rate: 1.922e-05, loss_scalings: 5497.559082, pp_loss: 6.787344
[INFO] 2021-07-12 19:10:41,324 [run_pretraining.py:  512]:	********exe.run_1923******* 
[INFO] 2021-07-12 19:10:42,231 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:42,232 [run_pretraining.py:  534]:	loss/total_loss, 7.348762035369873, 1924
[INFO] 2021-07-12 19:10:42,232 [run_pretraining.py:  535]:	loss/mlm_loss, 7.348762035369873, 1924
[INFO] 2021-07-12 19:10:42,232 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.92299994523637e-05, 1924
[INFO] 2021-07-12 19:10:42,232 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1924
[INFO] 2021-07-12 19:10:42,232 [run_pretraining.py:  558]:	worker_index: 6, step: 1924, cost: 7.348762, mlm loss: 7.348762, speed: 1.101428 steps/s, speed: 8.811424 samples/s, speed: 4511.449185 tokens/s, learning rate: 1.923e-05, loss_scalings: 5497.559082, pp_loss: 7.479325
[INFO] 2021-07-12 19:10:42,232 [run_pretraining.py:  512]:	********exe.run_1924******* 
[INFO] 2021-07-12 19:10:43,164 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:43,164 [run_pretraining.py:  534]:	loss/total_loss, 7.879748344421387, 1925
[INFO] 2021-07-12 19:10:43,165 [run_pretraining.py:  535]:	loss/mlm_loss, 7.879748344421387, 1925
[INFO] 2021-07-12 19:10:43,165 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.923999843711499e-05, 1925
[INFO] 2021-07-12 19:10:43,165 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1925
[INFO] 2021-07-12 19:10:43,165 [run_pretraining.py:  558]:	worker_index: 6, step: 1925, cost: 7.879748, mlm loss: 7.879748, speed: 1.072861 steps/s, speed: 8.582886 samples/s, speed: 4394.437588 tokens/s, learning rate: 1.924e-05, loss_scalings: 5497.559082, pp_loss: 7.594885
[INFO] 2021-07-12 19:10:43,165 [run_pretraining.py:  512]:	********exe.run_1925******* 
[INFO] 2021-07-12 19:10:44,110 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:44,110 [run_pretraining.py:  534]:	loss/total_loss, 7.382080078125, 1926
[INFO] 2021-07-12 19:10:44,110 [run_pretraining.py:  535]:	loss/mlm_loss, 7.382080078125, 1926
[INFO] 2021-07-12 19:10:44,111 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9249999240855686e-05, 1926
[INFO] 2021-07-12 19:10:44,111 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1926
[INFO] 2021-07-12 19:10:44,111 [run_pretraining.py:  558]:	worker_index: 6, step: 1926, cost: 7.382080, mlm loss: 7.382080, speed: 1.057944 steps/s, speed: 8.463548 samples/s, speed: 4333.336827 tokens/s, learning rate: 1.925e-05, loss_scalings: 5497.559082, pp_loss: 7.396945
[INFO] 2021-07-12 19:10:44,111 [run_pretraining.py:  512]:	********exe.run_1926******* 
[INFO] 2021-07-12 19:10:45,074 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:45,075 [run_pretraining.py:  534]:	loss/total_loss, 6.806129455566406, 1927
[INFO] 2021-07-12 19:10:45,075 [run_pretraining.py:  535]:	loss/mlm_loss, 6.806129455566406, 1927
[INFO] 2021-07-12 19:10:45,075 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.926000004459638e-05, 1927
[INFO] 2021-07-12 19:10:45,075 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1927
[INFO] 2021-07-12 19:10:45,076 [run_pretraining.py:  558]:	worker_index: 6, step: 1927, cost: 6.806129, mlm loss: 6.806129, speed: 1.037319 steps/s, speed: 8.298550 samples/s, speed: 4248.857631 tokens/s, learning rate: 1.926e-05, loss_scalings: 5497.559082, pp_loss: 7.578737
[INFO] 2021-07-12 19:10:45,076 [run_pretraining.py:  512]:	********exe.run_1927******* 
[INFO] 2021-07-12 19:10:46,059 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:46,060 [run_pretraining.py:  534]:	loss/total_loss, 6.798348426818848, 1928
[INFO] 2021-07-12 19:10:46,060 [run_pretraining.py:  535]:	loss/mlm_loss, 6.798348426818848, 1928
[INFO] 2021-07-12 19:10:46,060 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9269999029347673e-05, 1928
[INFO] 2021-07-12 19:10:46,060 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1928
[INFO] 2021-07-12 19:10:46,060 [run_pretraining.py:  558]:	worker_index: 6, step: 1928, cost: 6.798348, mlm loss: 6.798348, speed: 1.016442 steps/s, speed: 8.131538 samples/s, speed: 4163.347236 tokens/s, learning rate: 1.927e-05, loss_scalings: 5497.559082, pp_loss: 7.329390
[INFO] 2021-07-12 19:10:46,060 [run_pretraining.py:  512]:	********exe.run_1928******* 
[INFO] 2021-07-12 19:10:47,014 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:47,014 [run_pretraining.py:  534]:	loss/total_loss, 7.018986701965332, 1929
[INFO] 2021-07-12 19:10:47,014 [run_pretraining.py:  535]:	loss/mlm_loss, 7.018986701965332, 1929
[INFO] 2021-07-12 19:10:47,015 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9279999833088368e-05, 1929
[INFO] 2021-07-12 19:10:47,015 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1929
[INFO] 2021-07-12 19:10:47,015 [run_pretraining.py:  558]:	worker_index: 6, step: 1929, cost: 7.018987, mlm loss: 7.018987, speed: 1.048254 steps/s, speed: 8.386033 samples/s, speed: 4293.649146 tokens/s, learning rate: 1.928e-05, loss_scalings: 5497.559082, pp_loss: 7.349265
[INFO] 2021-07-12 19:10:47,015 [run_pretraining.py:  512]:	********exe.run_1929******* 
[INFO] 2021-07-12 19:10:47,982 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:47,982 [run_pretraining.py:  534]:	loss/total_loss, 7.233398914337158, 1930
[INFO] 2021-07-12 19:10:47,982 [run_pretraining.py:  535]:	loss/mlm_loss, 7.233398914337158, 1930
[INFO] 2021-07-12 19:10:47,982 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.928999881783966e-05, 1930
[INFO] 2021-07-12 19:10:47,983 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1930
[INFO] 2021-07-12 19:10:47,983 [run_pretraining.py:  558]:	worker_index: 6, step: 1930, cost: 7.233399, mlm loss: 7.233399, speed: 1.033936 steps/s, speed: 8.271490 samples/s, speed: 4235.002832 tokens/s, learning rate: 1.929e-05, loss_scalings: 5497.559082, pp_loss: 7.480986
[INFO] 2021-07-12 19:10:47,983 [run_pretraining.py:  512]:	********exe.run_1930******* 
[INFO] 2021-07-12 19:10:48,948 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:48,949 [run_pretraining.py:  534]:	loss/total_loss, 6.753519058227539, 1931
[INFO] 2021-07-12 19:10:48,949 [run_pretraining.py:  535]:	loss/mlm_loss, 6.753519058227539, 1931
[INFO] 2021-07-12 19:10:48,949 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9299999621580355e-05, 1931
[INFO] 2021-07-12 19:10:48,949 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1931
[INFO] 2021-07-12 19:10:48,949 [run_pretraining.py:  558]:	worker_index: 6, step: 1931, cost: 6.753519, mlm loss: 6.753519, speed: 1.035229 steps/s, speed: 8.281832 samples/s, speed: 4240.298191 tokens/s, learning rate: 1.930e-05, loss_scalings: 5497.559082, pp_loss: 7.115399
[INFO] 2021-07-12 19:10:48,949 [run_pretraining.py:  512]:	********exe.run_1931******* 
[INFO] 2021-07-12 19:10:49,921 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:49,922 [run_pretraining.py:  534]:	loss/total_loss, 7.0378265380859375, 1932
[INFO] 2021-07-12 19:10:49,922 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0378265380859375, 1932
[INFO] 2021-07-12 19:10:49,922 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.931000042532105e-05, 1932
[INFO] 2021-07-12 19:10:49,922 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1932
[INFO] 2021-07-12 19:10:49,922 [run_pretraining.py:  558]:	worker_index: 6, step: 1932, cost: 7.037827, mlm loss: 7.037827, speed: 1.028571 steps/s, speed: 8.228566 samples/s, speed: 4213.026046 tokens/s, learning rate: 1.931e-05, loss_scalings: 5497.559082, pp_loss: 6.969174
[INFO] 2021-07-12 19:10:49,922 [run_pretraining.py:  512]:	********exe.run_1932******* 
[INFO] 2021-07-12 19:10:50,864 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:50,864 [run_pretraining.py:  534]:	loss/total_loss, 6.9314703941345215, 1933
[INFO] 2021-07-12 19:10:50,864 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9314703941345215, 1933
[INFO] 2021-07-12 19:10:50,864 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.931999941007234e-05, 1933
[INFO] 2021-07-12 19:10:50,864 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1933
[INFO] 2021-07-12 19:10:50,865 [run_pretraining.py:  558]:	worker_index: 6, step: 1933, cost: 6.931470, mlm loss: 6.931470, speed: 1.061888 steps/s, speed: 8.495105 samples/s, speed: 4349.493636 tokens/s, learning rate: 1.932e-05, loss_scalings: 5497.559082, pp_loss: 6.637921
[INFO] 2021-07-12 19:10:50,865 [run_pretraining.py:  512]:	********exe.run_1933******* 
[INFO] 2021-07-12 19:10:51,815 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:51,815 [run_pretraining.py:  534]:	loss/total_loss, 6.8233489990234375, 1934
[INFO] 2021-07-12 19:10:51,815 [run_pretraining.py:  535]:	loss/mlm_loss, 6.8233489990234375, 1934
[INFO] 2021-07-12 19:10:51,816 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9329998394823633e-05, 1934
[INFO] 2021-07-12 19:10:51,816 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1934
[INFO] 2021-07-12 19:10:51,816 [run_pretraining.py:  558]:	worker_index: 6, step: 1934, cost: 6.823349, mlm loss: 6.823349, speed: 1.052178 steps/s, speed: 8.417427 samples/s, speed: 4309.722709 tokens/s, learning rate: 1.933e-05, loss_scalings: 5497.559082, pp_loss: 7.438890
[INFO] 2021-07-12 19:10:51,816 [run_pretraining.py:  512]:	********exe.run_1934******* 
[INFO] 2021-07-12 19:10:52,761 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:52,762 [run_pretraining.py:  534]:	loss/total_loss, 6.550168991088867, 1935
[INFO] 2021-07-12 19:10:52,762 [run_pretraining.py:  535]:	loss/mlm_loss, 6.550168991088867, 1935
[INFO] 2021-07-12 19:10:52,762 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9339999198564328e-05, 1935
[INFO] 2021-07-12 19:10:52,762 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1935
[INFO] 2021-07-12 19:10:52,762 [run_pretraining.py:  558]:	worker_index: 6, step: 1935, cost: 6.550169, mlm loss: 6.550169, speed: 1.057067 steps/s, speed: 8.456539 samples/s, speed: 4329.748163 tokens/s, learning rate: 1.934e-05, loss_scalings: 5497.559082, pp_loss: 6.310375
[INFO] 2021-07-12 19:10:52,763 [run_pretraining.py:  512]:	********exe.run_1935******* 
[INFO] 2021-07-12 19:10:53,705 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:53,705 [run_pretraining.py:  534]:	loss/total_loss, 7.29752254486084, 1936
[INFO] 2021-07-12 19:10:53,705 [run_pretraining.py:  535]:	loss/mlm_loss, 7.29752254486084, 1936
[INFO] 2021-07-12 19:10:53,705 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9350000002305023e-05, 1936
[INFO] 2021-07-12 19:10:53,706 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1936
[INFO] 2021-07-12 19:10:53,706 [run_pretraining.py:  558]:	worker_index: 6, step: 1936, cost: 7.297523, mlm loss: 7.297523, speed: 1.060957 steps/s, speed: 8.487655 samples/s, speed: 4345.679199 tokens/s, learning rate: 1.935e-05, loss_scalings: 5497.559082, pp_loss: 7.429813
[INFO] 2021-07-12 19:10:53,706 [run_pretraining.py:  512]:	********exe.run_1936******* 
[INFO] 2021-07-12 19:10:54,630 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:54,630 [run_pretraining.py:  534]:	loss/total_loss, 7.47935676574707, 1937
[INFO] 2021-07-12 19:10:54,631 [run_pretraining.py:  535]:	loss/mlm_loss, 7.47935676574707, 1937
[INFO] 2021-07-12 19:10:54,631 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9359998987056315e-05, 1937
[INFO] 2021-07-12 19:10:54,631 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1937
[INFO] 2021-07-12 19:10:54,631 [run_pretraining.py:  558]:	worker_index: 6, step: 1937, cost: 7.479357, mlm loss: 7.479357, speed: 1.081746 steps/s, speed: 8.653971 samples/s, speed: 4430.833259 tokens/s, learning rate: 1.936e-05, loss_scalings: 5497.559082, pp_loss: 7.440103
[INFO] 2021-07-12 19:10:54,631 [run_pretraining.py:  512]:	********exe.run_1937******* 
[INFO] 2021-07-12 19:10:55,556 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:55,556 [run_pretraining.py:  534]:	loss/total_loss, 7.278603553771973, 1938
[INFO] 2021-07-12 19:10:55,557 [run_pretraining.py:  535]:	loss/mlm_loss, 7.278603553771973, 1938
[INFO] 2021-07-12 19:10:55,557 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.936999979079701e-05, 1938
[INFO] 2021-07-12 19:10:55,557 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1938
[INFO] 2021-07-12 19:10:55,557 [run_pretraining.py:  558]:	worker_index: 6, step: 1938, cost: 7.278604, mlm loss: 7.278604, speed: 1.080677 steps/s, speed: 8.645416 samples/s, speed: 4426.452865 tokens/s, learning rate: 1.937e-05, loss_scalings: 5497.559082, pp_loss: 7.148359
[INFO] 2021-07-12 19:10:55,557 [run_pretraining.py:  512]:	********exe.run_1938******* 
[INFO] 2021-07-12 19:10:56,480 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:56,481 [run_pretraining.py:  534]:	loss/total_loss, 7.917060852050781, 1939
[INFO] 2021-07-12 19:10:56,481 [run_pretraining.py:  535]:	loss/mlm_loss, 7.917060852050781, 1939
[INFO] 2021-07-12 19:10:56,481 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9380000594537705e-05, 1939
[INFO] 2021-07-12 19:10:56,481 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1939
[INFO] 2021-07-12 19:10:56,481 [run_pretraining.py:  558]:	worker_index: 6, step: 1939, cost: 7.917061, mlm loss: 7.917061, speed: 1.083030 steps/s, speed: 8.664239 samples/s, speed: 4436.090423 tokens/s, learning rate: 1.938e-05, loss_scalings: 5497.559082, pp_loss: 7.454446
[INFO] 2021-07-12 19:10:56,481 [run_pretraining.py:  512]:	********exe.run_1939******* 
[INFO] 2021-07-12 19:10:57,414 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:57,414 [run_pretraining.py:  534]:	loss/total_loss, 6.986998558044434, 1940
[INFO] 2021-07-12 19:10:57,414 [run_pretraining.py:  535]:	loss/mlm_loss, 6.986998558044434, 1940
[INFO] 2021-07-12 19:10:57,414 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9389999579288997e-05, 1940
[INFO] 2021-07-12 19:10:57,415 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1940
[INFO] 2021-07-12 19:10:57,415 [run_pretraining.py:  558]:	worker_index: 6, step: 1940, cost: 6.986999, mlm loss: 6.986999, speed: 1.071745 steps/s, speed: 8.573960 samples/s, speed: 4389.867451 tokens/s, learning rate: 1.939e-05, loss_scalings: 5497.559082, pp_loss: 7.553811
[INFO] 2021-07-12 19:10:57,415 [run_pretraining.py:  512]:	********exe.run_1940******* 
[INFO] 2021-07-12 19:10:58,342 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:58,342 [run_pretraining.py:  534]:	loss/total_loss, 8.186149597167969, 1941
[INFO] 2021-07-12 19:10:58,342 [run_pretraining.py:  535]:	loss/mlm_loss, 8.186149597167969, 1941
[INFO] 2021-07-12 19:10:58,342 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9400000383029692e-05, 1941
[INFO] 2021-07-12 19:10:58,343 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1941
[INFO] 2021-07-12 19:10:58,343 [run_pretraining.py:  558]:	worker_index: 6, step: 1941, cost: 8.186150, mlm loss: 8.186150, speed: 1.078477 steps/s, speed: 8.627816 samples/s, speed: 4417.441979 tokens/s, learning rate: 1.940e-05, loss_scalings: 5497.559082, pp_loss: 7.550255
[INFO] 2021-07-12 19:10:58,343 [run_pretraining.py:  512]:	********exe.run_1941******* 
[INFO] 2021-07-12 19:10:59,275 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:59,276 [run_pretraining.py:  534]:	loss/total_loss, 8.379926681518555, 1942
[INFO] 2021-07-12 19:10:59,276 [run_pretraining.py:  535]:	loss/mlm_loss, 8.379926681518555, 1942
[INFO] 2021-07-12 19:10:59,276 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9409999367780983e-05, 1942
[INFO] 2021-07-12 19:10:59,276 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1942
[INFO] 2021-07-12 19:10:59,276 [run_pretraining.py:  558]:	worker_index: 6, step: 1942, cost: 8.379927, mlm loss: 8.379927, speed: 1.072096 steps/s, speed: 8.576769 samples/s, speed: 4391.305962 tokens/s, learning rate: 1.941e-05, loss_scalings: 5497.559082, pp_loss: 7.524494
[INFO] 2021-07-12 19:10:59,276 [run_pretraining.py:  512]:	********exe.run_1942******* 
[INFO] 2021-07-12 19:11:00,197 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:00,197 [run_pretraining.py:  534]:	loss/total_loss, 7.939274787902832, 1943
[INFO] 2021-07-12 19:11:00,197 [run_pretraining.py:  535]:	loss/mlm_loss, 7.939274787902832, 1943
[INFO] 2021-07-12 19:11:00,197 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9419998352532275e-05, 1943
[INFO] 2021-07-12 19:11:00,197 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1943
[INFO] 2021-07-12 19:11:00,198 [run_pretraining.py:  558]:	worker_index: 6, step: 1943, cost: 7.939275, mlm loss: 7.939275, speed: 1.086011 steps/s, speed: 8.688089 samples/s, speed: 4448.301356 tokens/s, learning rate: 1.942e-05, loss_scalings: 5497.559082, pp_loss: 7.411996
[INFO] 2021-07-12 19:11:00,198 [run_pretraining.py:  512]:	********exe.run_1943******* 
[INFO] 2021-07-12 19:11:01,117 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:01,118 [run_pretraining.py:  534]:	loss/total_loss, 7.995090007781982, 1944
[INFO] 2021-07-12 19:11:01,118 [run_pretraining.py:  535]:	loss/mlm_loss, 7.995090007781982, 1944
[INFO] 2021-07-12 19:11:01,118 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.942999915627297e-05, 1944
[INFO] 2021-07-12 19:11:01,118 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1944
[INFO] 2021-07-12 19:11:01,118 [run_pretraining.py:  558]:	worker_index: 6, step: 1944, cost: 7.995090, mlm loss: 7.995090, speed: 1.087022 steps/s, speed: 8.696177 samples/s, speed: 4452.442392 tokens/s, learning rate: 1.943e-05, loss_scalings: 5497.559082, pp_loss: 7.464984
[INFO] 2021-07-12 19:11:01,118 [run_pretraining.py:  512]:	********exe.run_1944******* 
[INFO] 2021-07-12 19:11:02,046 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:02,046 [run_pretraining.py:  534]:	loss/total_loss, 6.928102016448975, 1945
[INFO] 2021-07-12 19:11:02,046 [run_pretraining.py:  535]:	loss/mlm_loss, 6.928102016448975, 1945
[INFO] 2021-07-12 19:11:02,046 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9439999960013665e-05, 1945
[INFO] 2021-07-12 19:11:02,047 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1945
[INFO] 2021-07-12 19:11:02,047 [run_pretraining.py:  558]:	worker_index: 6, step: 1945, cost: 6.928102, mlm loss: 6.928102, speed: 1.077946 steps/s, speed: 8.623570 samples/s, speed: 4415.267893 tokens/s, learning rate: 1.944e-05, loss_scalings: 4398.047363, pp_loss: 6.974146
[INFO] 2021-07-12 19:11:02,047 [run_pretraining.py:  512]:	********exe.run_1945******* 
[INFO] 2021-07-12 19:11:02,979 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:02,979 [run_pretraining.py:  534]:	loss/total_loss, 7.054917335510254, 1946
[INFO] 2021-07-12 19:11:02,979 [run_pretraining.py:  535]:	loss/mlm_loss, 7.054917335510254, 1946
[INFO] 2021-07-12 19:11:02,979 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9449998944764957e-05, 1946
[INFO] 2021-07-12 19:11:02,980 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1946
[INFO] 2021-07-12 19:11:02,980 [run_pretraining.py:  558]:	worker_index: 6, step: 1946, cost: 7.054917, mlm loss: 7.054917, speed: 1.072594 steps/s, speed: 8.580755 samples/s, speed: 4393.346404 tokens/s, learning rate: 1.945e-05, loss_scalings: 4398.047363, pp_loss: 7.418614
[INFO] 2021-07-12 19:11:02,980 [run_pretraining.py:  512]:	********exe.run_1946******* 
[INFO] 2021-07-12 19:11:29,606 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:29,607 [run_pretraining.py:  534]:	loss/total_loss, 7.3337721824646, 1947
[INFO] 2021-07-12 19:11:29,607 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3337721824646, 1947
[INFO] 2021-07-12 19:11:29,607 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9459999748505652e-05, 1947
[INFO] 2021-07-12 19:11:29,607 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1947
[INFO] 2021-07-12 19:11:29,607 [run_pretraining.py:  558]:	worker_index: 6, step: 1947, cost: 7.333772, mlm loss: 7.333772, speed: 0.037556 steps/s, speed: 0.300449 samples/s, speed: 153.829991 tokens/s, learning rate: 1.946e-05, loss_scalings: 4398.047363, pp_loss: 7.531442
[INFO] 2021-07-12 19:11:29,607 [run_pretraining.py:  512]:	********exe.run_1947******* 
[INFO] 2021-07-12 19:11:30,526 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:30,527 [run_pretraining.py:  534]:	loss/total_loss, 6.992733001708984, 1948
[INFO] 2021-07-12 19:11:30,527 [run_pretraining.py:  535]:	loss/mlm_loss, 6.992733001708984, 1948
[INFO] 2021-07-12 19:11:30,527 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9470000552246347e-05, 1948
[INFO] 2021-07-12 19:11:30,527 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1948
[INFO] 2021-07-12 19:11:30,527 [run_pretraining.py:  558]:	worker_index: 6, step: 1948, cost: 6.992733, mlm loss: 6.992733, speed: 1.087550 steps/s, speed: 8.700400 samples/s, speed: 4454.604739 tokens/s, learning rate: 1.947e-05, loss_scalings: 4398.047363, pp_loss: 7.236553
[INFO] 2021-07-12 19:11:30,528 [run_pretraining.py:  512]:	********exe.run_1948******* 
[INFO] 2021-07-12 19:11:31,452 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:31,452 [run_pretraining.py:  534]:	loss/total_loss, 7.552422523498535, 1949
[INFO] 2021-07-12 19:11:31,452 [run_pretraining.py:  535]:	loss/mlm_loss, 7.552422523498535, 1949
[INFO] 2021-07-12 19:11:31,452 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.947999953699764e-05, 1949
[INFO] 2021-07-12 19:11:31,453 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1949
[INFO] 2021-07-12 19:11:31,453 [run_pretraining.py:  558]:	worker_index: 6, step: 1949, cost: 7.552423, mlm loss: 7.552423, speed: 1.081649 steps/s, speed: 8.653195 samples/s, speed: 4430.435618 tokens/s, learning rate: 1.948e-05, loss_scalings: 4398.047363, pp_loss: 7.216566
[INFO] 2021-07-12 19:11:31,453 [run_pretraining.py:  512]:	********exe.run_1949******* 
[INFO] 2021-07-12 19:11:32,372 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:32,373 [run_pretraining.py:  534]:	loss/total_loss, 7.509216785430908, 1950
[INFO] 2021-07-12 19:11:32,373 [run_pretraining.py:  535]:	loss/mlm_loss, 7.509216785430908, 1950
[INFO] 2021-07-12 19:11:32,373 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9490000340738334e-05, 1950
[INFO] 2021-07-12 19:11:32,373 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1950
[INFO] 2021-07-12 19:11:32,373 [run_pretraining.py:  558]:	worker_index: 6, step: 1950, cost: 7.509217, mlm loss: 7.509217, speed: 1.087263 steps/s, speed: 8.698102 samples/s, speed: 4453.428060 tokens/s, learning rate: 1.949e-05, loss_scalings: 4398.047363, pp_loss: 6.991211
[INFO] 2021-07-12 19:11:32,373 [run_pretraining.py:  512]:	********exe.run_1950******* 
[INFO] 2021-07-12 19:11:33,299 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:33,299 [run_pretraining.py:  534]:	loss/total_loss, 7.816498756408691, 1951
[INFO] 2021-07-12 19:11:33,299 [run_pretraining.py:  535]:	loss/mlm_loss, 7.816498756408691, 1951
[INFO] 2021-07-12 19:11:33,300 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9499999325489625e-05, 1951
[INFO] 2021-07-12 19:11:33,300 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1951
[INFO] 2021-07-12 19:11:33,300 [run_pretraining.py:  558]:	worker_index: 6, step: 1951, cost: 7.816499, mlm loss: 7.816499, speed: 1.079976 steps/s, speed: 8.639808 samples/s, speed: 4423.581832 tokens/s, learning rate: 1.950e-05, loss_scalings: 4398.047363, pp_loss: 7.432583
[INFO] 2021-07-12 19:11:33,300 [run_pretraining.py:  512]:	********exe.run_1951******* 
[INFO] 2021-07-12 19:11:34,223 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:34,223 [run_pretraining.py:  534]:	loss/total_loss, 4.592319965362549, 1952
[INFO] 2021-07-12 19:11:34,223 [run_pretraining.py:  535]:	loss/mlm_loss, 4.592319965362549, 1952
[INFO] 2021-07-12 19:11:34,223 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9509998310240917e-05, 1952
[INFO] 2021-07-12 19:11:34,224 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1952
[INFO] 2021-07-12 19:11:34,224 [run_pretraining.py:  558]:	worker_index: 6, step: 1952, cost: 4.592320, mlm loss: 4.592320, speed: 1.083324 steps/s, speed: 8.666589 samples/s, speed: 4437.293485 tokens/s, learning rate: 1.951e-05, loss_scalings: 4398.047363, pp_loss: 6.728172
[INFO] 2021-07-12 19:11:34,224 [run_pretraining.py:  512]:	********exe.run_1952******* 
[INFO] 2021-07-12 19:11:35,150 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:35,150 [run_pretraining.py:  534]:	loss/total_loss, 7.129258632659912, 1953
[INFO] 2021-07-12 19:11:35,151 [run_pretraining.py:  535]:	loss/mlm_loss, 7.129258632659912, 1953
[INFO] 2021-07-12 19:11:35,151 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9519999113981612e-05, 1953
[INFO] 2021-07-12 19:11:35,151 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1953
[INFO] 2021-07-12 19:11:35,151 [run_pretraining.py:  558]:	worker_index: 6, step: 1953, cost: 7.129259, mlm loss: 7.129259, speed: 1.079335 steps/s, speed: 8.634677 samples/s, speed: 4420.954554 tokens/s, learning rate: 1.952e-05, loss_scalings: 4398.047363, pp_loss: 7.324502
[INFO] 2021-07-12 19:11:35,151 [run_pretraining.py:  512]:	********exe.run_1953******* 
[INFO] 2021-07-12 19:11:36,070 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:36,070 [run_pretraining.py:  534]:	loss/total_loss, 7.430498123168945, 1954
[INFO] 2021-07-12 19:11:36,070 [run_pretraining.py:  535]:	loss/mlm_loss, 7.430498123168945, 1954
[INFO] 2021-07-12 19:11:36,071 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9529999917722307e-05, 1954
[INFO] 2021-07-12 19:11:36,071 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1954
[INFO] 2021-07-12 19:11:36,071 [run_pretraining.py:  558]:	worker_index: 6, step: 1954, cost: 7.430498, mlm loss: 7.430498, speed: 1.087881 steps/s, speed: 8.703049 samples/s, speed: 4455.961173 tokens/s, learning rate: 1.953e-05, loss_scalings: 4398.047363, pp_loss: 7.365822
[INFO] 2021-07-12 19:11:36,071 [run_pretraining.py:  512]:	********exe.run_1954******* 
[INFO] 2021-07-12 19:11:37,025 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:37,026 [run_pretraining.py:  534]:	loss/total_loss, 7.526236534118652, 1955
[INFO] 2021-07-12 19:11:37,026 [run_pretraining.py:  535]:	loss/mlm_loss, 7.526236534118652, 1955
[INFO] 2021-07-12 19:11:37,026 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.95399989024736e-05, 1955
[INFO] 2021-07-12 19:11:37,026 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1955
[INFO] 2021-07-12 19:11:37,026 [run_pretraining.py:  558]:	worker_index: 6, step: 1955, cost: 7.526237, mlm loss: 7.526237, speed: 1.047623 steps/s, speed: 8.380985 samples/s, speed: 4291.064573 tokens/s, learning rate: 1.954e-05, loss_scalings: 4398.047363, pp_loss: 7.621114
[INFO] 2021-07-12 19:11:37,026 [run_pretraining.py:  512]:	********exe.run_1955******* 
[INFO] 2021-07-12 19:11:37,964 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:37,965 [run_pretraining.py:  534]:	loss/total_loss, 7.057352066040039, 1956
[INFO] 2021-07-12 19:11:37,965 [run_pretraining.py:  535]:	loss/mlm_loss, 7.057352066040039, 1956
[INFO] 2021-07-12 19:11:37,965 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9549999706214294e-05, 1956
[INFO] 2021-07-12 19:11:37,965 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1956
[INFO] 2021-07-12 19:11:37,965 [run_pretraining.py:  558]:	worker_index: 6, step: 1956, cost: 7.057352, mlm loss: 7.057352, speed: 1.065751 steps/s, speed: 8.526011 samples/s, speed: 4365.317664 tokens/s, learning rate: 1.955e-05, loss_scalings: 4398.047363, pp_loss: 7.636627
[INFO] 2021-07-12 19:11:37,965 [run_pretraining.py:  512]:	********exe.run_1956******* 
[INFO] 2021-07-12 19:11:38,894 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:38,895 [run_pretraining.py:  534]:	loss/total_loss, 7.879764556884766, 1957
[INFO] 2021-07-12 19:11:38,895 [run_pretraining.py:  535]:	loss/mlm_loss, 7.879764556884766, 1957
[INFO] 2021-07-12 19:11:38,895 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.956000050995499e-05, 1957
[INFO] 2021-07-12 19:11:38,895 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1957
[INFO] 2021-07-12 19:11:38,895 [run_pretraining.py:  558]:	worker_index: 6, step: 1957, cost: 7.879765, mlm loss: 7.879765, speed: 1.075752 steps/s, speed: 8.606013 samples/s, speed: 4406.278709 tokens/s, learning rate: 1.956e-05, loss_scalings: 4398.047363, pp_loss: 7.495710
[INFO] 2021-07-12 19:11:38,895 [run_pretraining.py:  512]:	********exe.run_1957******* 
[INFO] 2021-07-12 19:11:39,813 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:39,814 [run_pretraining.py:  534]:	loss/total_loss, 8.011917114257812, 1958
[INFO] 2021-07-12 19:11:39,814 [run_pretraining.py:  535]:	loss/mlm_loss, 8.011917114257812, 1958
[INFO] 2021-07-12 19:11:39,814 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.956999949470628e-05, 1958
[INFO] 2021-07-12 19:11:39,814 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1958
[INFO] 2021-07-12 19:11:39,814 [run_pretraining.py:  558]:	worker_index: 6, step: 1958, cost: 8.011917, mlm loss: 8.011917, speed: 1.089352 steps/s, speed: 8.714814 samples/s, speed: 4461.984971 tokens/s, learning rate: 1.957e-05, loss_scalings: 4398.047363, pp_loss: 8.067860
[INFO] 2021-07-12 19:11:39,814 [run_pretraining.py:  512]:	********exe.run_1958******* 
[INFO] 2021-07-12 19:11:40,739 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:40,740 [run_pretraining.py:  534]:	loss/total_loss, 6.480050086975098, 1959
[INFO] 2021-07-12 19:11:40,740 [run_pretraining.py:  535]:	loss/mlm_loss, 6.480050086975098, 1959
[INFO] 2021-07-12 19:11:40,740 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9580000298446976e-05, 1959
[INFO] 2021-07-12 19:11:40,740 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1959
[INFO] 2021-07-12 19:11:40,740 [run_pretraining.py:  558]:	worker_index: 6, step: 1959, cost: 6.480050, mlm loss: 6.480050, speed: 1.080839 steps/s, speed: 8.646715 samples/s, speed: 4427.117871 tokens/s, learning rate: 1.958e-05, loss_scalings: 4398.047363, pp_loss: 6.863255
[INFO] 2021-07-12 19:11:40,740 [run_pretraining.py:  512]:	********exe.run_1959******* 
[INFO] 2021-07-12 19:11:41,667 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:41,668 [run_pretraining.py:  534]:	loss/total_loss, 7.030671119689941, 1960
[INFO] 2021-07-12 19:11:41,668 [run_pretraining.py:  535]:	loss/mlm_loss, 7.030671119689941, 1960
[INFO] 2021-07-12 19:11:41,668 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9589999283198267e-05, 1960
[INFO] 2021-07-12 19:11:41,668 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1960
[INFO] 2021-07-12 19:11:41,668 [run_pretraining.py:  558]:	worker_index: 6, step: 1960, cost: 7.030671, mlm loss: 7.030671, speed: 1.078388 steps/s, speed: 8.627104 samples/s, speed: 4417.077401 tokens/s, learning rate: 1.959e-05, loss_scalings: 4398.047363, pp_loss: 7.140800
[INFO] 2021-07-12 19:11:41,668 [run_pretraining.py:  512]:	********exe.run_1960******* 
[INFO] 2021-07-12 19:11:42,575 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:42,575 [run_pretraining.py:  534]:	loss/total_loss, 7.862585544586182, 1961
[INFO] 2021-07-12 19:11:42,575 [run_pretraining.py:  535]:	loss/mlm_loss, 7.862585544586182, 1961
[INFO] 2021-07-12 19:11:42,575 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.959999826794956e-05, 1961
[INFO] 2021-07-12 19:11:42,576 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1961
[INFO] 2021-07-12 19:11:42,576 [run_pretraining.py:  558]:	worker_index: 6, step: 1961, cost: 7.862586, mlm loss: 7.862586, speed: 1.102549 steps/s, speed: 8.820390 samples/s, speed: 4516.039867 tokens/s, learning rate: 1.960e-05, loss_scalings: 4398.047363, pp_loss: 7.148628
[INFO] 2021-07-12 19:11:42,576 [run_pretraining.py:  512]:	********exe.run_1961******* 
[INFO] 2021-07-12 19:11:43,510 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:43,511 [run_pretraining.py:  534]:	loss/total_loss, 6.490005970001221, 1962
[INFO] 2021-07-12 19:11:43,511 [run_pretraining.py:  535]:	loss/mlm_loss, 6.490005970001221, 1962
[INFO] 2021-07-12 19:11:43,511 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9609999071690254e-05, 1962
[INFO] 2021-07-12 19:11:43,511 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1962
[INFO] 2021-07-12 19:11:43,511 [run_pretraining.py:  558]:	worker_index: 6, step: 1962, cost: 6.490006, mlm loss: 6.490006, speed: 1.070036 steps/s, speed: 8.560285 samples/s, speed: 4382.865667 tokens/s, learning rate: 1.961e-05, loss_scalings: 4398.047363, pp_loss: 6.537654
[INFO] 2021-07-12 19:11:43,511 [run_pretraining.py:  512]:	********exe.run_1962******* 
[INFO] 2021-07-12 19:11:44,439 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:44,440 [run_pretraining.py:  534]:	loss/total_loss, 6.81992244720459, 1963
[INFO] 2021-07-12 19:11:44,440 [run_pretraining.py:  535]:	loss/mlm_loss, 6.81992244720459, 1963
[INFO] 2021-07-12 19:11:44,440 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.961999987543095e-05, 1963
[INFO] 2021-07-12 19:11:44,440 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1963
[INFO] 2021-07-12 19:11:44,440 [run_pretraining.py:  558]:	worker_index: 6, step: 1963, cost: 6.819922, mlm loss: 6.819922, speed: 1.076721 steps/s, speed: 8.613768 samples/s, speed: 4410.249000 tokens/s, learning rate: 1.962e-05, loss_scalings: 4398.047363, pp_loss: 7.287303
[INFO] 2021-07-12 19:11:44,440 [run_pretraining.py:  512]:	********exe.run_1963******* 
[INFO] 2021-07-12 19:11:45,361 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:45,361 [run_pretraining.py:  534]:	loss/total_loss, 6.9701385498046875, 1964
[INFO] 2021-07-12 19:11:45,361 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9701385498046875, 1964
[INFO] 2021-07-12 19:11:45,362 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.962999886018224e-05, 1964
[INFO] 2021-07-12 19:11:45,362 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1964
[INFO] 2021-07-12 19:11:45,362 [run_pretraining.py:  558]:	worker_index: 6, step: 1964, cost: 6.970139, mlm loss: 6.970139, speed: 1.086150 steps/s, speed: 8.689202 samples/s, speed: 4448.871559 tokens/s, learning rate: 1.963e-05, loss_scalings: 4398.047363, pp_loss: 7.200113
[INFO] 2021-07-12 19:11:45,362 [run_pretraining.py:  512]:	********exe.run_1964******* 
[INFO] 2021-07-12 19:11:46,287 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:46,287 [run_pretraining.py:  534]:	loss/total_loss, 7.2858357429504395, 1965
[INFO] 2021-07-12 19:11:46,287 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2858357429504395, 1965
[INFO] 2021-07-12 19:11:46,287 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9639999663922936e-05, 1965
[INFO] 2021-07-12 19:11:46,288 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1965
[INFO] 2021-07-12 19:11:46,288 [run_pretraining.py:  558]:	worker_index: 6, step: 1965, cost: 7.285836, mlm loss: 7.285836, speed: 1.080912 steps/s, speed: 8.647298 samples/s, speed: 4427.416790 tokens/s, learning rate: 1.964e-05, loss_scalings: 4398.047363, pp_loss: 7.213526
[INFO] 2021-07-12 19:11:46,288 [run_pretraining.py:  512]:	********exe.run_1965******* 
[INFO] 2021-07-12 19:11:47,230 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:47,231 [run_pretraining.py:  534]:	loss/total_loss, 7.572211265563965, 1966
[INFO] 2021-07-12 19:11:47,231 [run_pretraining.py:  535]:	loss/mlm_loss, 7.572211265563965, 1966
[INFO] 2021-07-12 19:11:47,231 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.965000046766363e-05, 1966
[INFO] 2021-07-12 19:11:47,231 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1966
[INFO] 2021-07-12 19:11:47,231 [run_pretraining.py:  558]:	worker_index: 6, step: 1966, cost: 7.572211, mlm loss: 7.572211, speed: 1.060375 steps/s, speed: 8.483000 samples/s, speed: 4343.296239 tokens/s, learning rate: 1.965e-05, loss_scalings: 3518.437988, pp_loss: 7.401729
[INFO] 2021-07-12 19:11:47,231 [run_pretraining.py:  512]:	********exe.run_1966******* 
[INFO] 2021-07-12 19:11:48,147 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:48,147 [run_pretraining.py:  534]:	loss/total_loss, 7.120181083679199, 1967
[INFO] 2021-07-12 19:11:48,147 [run_pretraining.py:  535]:	loss/mlm_loss, 7.120181083679199, 1967
[INFO] 2021-07-12 19:11:48,148 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9659999452414922e-05, 1967
[INFO] 2021-07-12 19:11:48,148 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1967
[INFO] 2021-07-12 19:11:48,148 [run_pretraining.py:  558]:	worker_index: 6, step: 1967, cost: 7.120181, mlm loss: 7.120181, speed: 1.092244 steps/s, speed: 8.737954 samples/s, speed: 4473.832227 tokens/s, learning rate: 1.966e-05, loss_scalings: 3518.437988, pp_loss: 7.462619
[INFO] 2021-07-12 19:11:48,148 [run_pretraining.py:  512]:	********exe.run_1967******* 
[INFO] 2021-07-12 19:11:49,072 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:49,073 [run_pretraining.py:  534]:	loss/total_loss, 7.1508564949035645, 1968
[INFO] 2021-07-12 19:11:49,073 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1508564949035645, 1968
[INFO] 2021-07-12 19:11:49,073 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9670000256155618e-05, 1968
[INFO] 2021-07-12 19:11:49,073 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1968
[INFO] 2021-07-12 19:11:49,073 [run_pretraining.py:  558]:	worker_index: 6, step: 1968, cost: 7.150856, mlm loss: 7.150856, speed: 1.081331 steps/s, speed: 8.650647 samples/s, speed: 4429.131217 tokens/s, learning rate: 1.967e-05, loss_scalings: 3518.437988, pp_loss: 7.146091
[INFO] 2021-07-12 19:11:49,073 [run_pretraining.py:  512]:	********exe.run_1968******* 
[INFO] 2021-07-12 19:11:49,994 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:49,995 [run_pretraining.py:  534]:	loss/total_loss, 4.1061482429504395, 1969
[INFO] 2021-07-12 19:11:49,995 [run_pretraining.py:  535]:	loss/mlm_loss, 4.1061482429504395, 1969
[INFO] 2021-07-12 19:11:49,995 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.967999924090691e-05, 1969
[INFO] 2021-07-12 19:11:49,995 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1969
[INFO] 2021-07-12 19:11:49,995 [run_pretraining.py:  558]:	worker_index: 6, step: 1969, cost: 4.106148, mlm loss: 4.106148, speed: 1.085707 steps/s, speed: 8.685653 samples/s, speed: 4447.054331 tokens/s, learning rate: 1.968e-05, loss_scalings: 3518.437988, pp_loss: 6.595312
[INFO] 2021-07-12 19:11:49,995 [run_pretraining.py:  512]:	********exe.run_1969******* 
[INFO] 2021-07-12 19:11:50,921 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:50,922 [run_pretraining.py:  534]:	loss/total_loss, 6.489055633544922, 1970
[INFO] 2021-07-12 19:11:50,922 [run_pretraining.py:  535]:	loss/mlm_loss, 6.489055633544922, 1970
[INFO] 2021-07-12 19:11:50,922 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.96899982256582e-05, 1970
[INFO] 2021-07-12 19:11:50,922 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1970
[INFO] 2021-07-12 19:11:50,922 [run_pretraining.py:  558]:	worker_index: 6, step: 1970, cost: 6.489056, mlm loss: 6.489056, speed: 1.079069 steps/s, speed: 8.632553 samples/s, speed: 4419.867219 tokens/s, learning rate: 1.969e-05, loss_scalings: 3518.437988, pp_loss: 7.170604
[INFO] 2021-07-12 19:11:50,923 [run_pretraining.py:  512]:	********exe.run_1970******* 
[INFO] 2021-07-12 19:11:51,851 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:51,852 [run_pretraining.py:  534]:	loss/total_loss, 6.850427627563477, 1971
[INFO] 2021-07-12 19:11:51,852 [run_pretraining.py:  535]:	loss/mlm_loss, 6.850427627563477, 1971
[INFO] 2021-07-12 19:11:51,852 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9699999029398896e-05, 1971
[INFO] 2021-07-12 19:11:51,852 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1971
[INFO] 2021-07-12 19:11:51,852 [run_pretraining.py:  558]:	worker_index: 6, step: 1971, cost: 6.850428, mlm loss: 6.850428, speed: 1.076613 steps/s, speed: 8.612903 samples/s, speed: 4409.806371 tokens/s, learning rate: 1.970e-05, loss_scalings: 3518.437988, pp_loss: 7.071191
[INFO] 2021-07-12 19:11:51,852 [run_pretraining.py:  512]:	********exe.run_1971******* 
[INFO] 2021-07-12 19:11:52,766 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:52,767 [run_pretraining.py:  534]:	loss/total_loss, 7.577829360961914, 1972
[INFO] 2021-07-12 19:11:52,767 [run_pretraining.py:  535]:	loss/mlm_loss, 7.577829360961914, 1972
[INFO] 2021-07-12 19:11:52,767 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.970999983313959e-05, 1972
[INFO] 2021-07-12 19:11:52,767 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1972
[INFO] 2021-07-12 19:11:52,767 [run_pretraining.py:  558]:	worker_index: 6, step: 1972, cost: 7.577829, mlm loss: 7.577829, speed: 1.093777 steps/s, speed: 8.750215 samples/s, speed: 4480.110085 tokens/s, learning rate: 1.971e-05, loss_scalings: 3518.437988, pp_loss: 7.278268
[INFO] 2021-07-12 19:11:52,767 [run_pretraining.py:  512]:	********exe.run_1972******* 
[INFO] 2021-07-12 19:11:53,688 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:53,689 [run_pretraining.py:  534]:	loss/total_loss, 7.1665215492248535, 1973
[INFO] 2021-07-12 19:11:53,689 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1665215492248535, 1973
[INFO] 2021-07-12 19:11:53,689 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9719998817890882e-05, 1973
[INFO] 2021-07-12 19:11:53,689 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1973
[INFO] 2021-07-12 19:11:53,689 [run_pretraining.py:  558]:	worker_index: 6, step: 1973, cost: 7.166522, mlm loss: 7.166522, speed: 1.084797 steps/s, speed: 8.678377 samples/s, speed: 4443.328938 tokens/s, learning rate: 1.972e-05, loss_scalings: 3518.437988, pp_loss: 7.245775
[INFO] 2021-07-12 19:11:53,690 [run_pretraining.py:  512]:	********exe.run_1973******* 
[INFO] 2021-07-12 19:11:54,606 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:54,607 [run_pretraining.py:  534]:	loss/total_loss, 7.35976505279541, 1974
[INFO] 2021-07-12 19:11:54,607 [run_pretraining.py:  535]:	loss/mlm_loss, 7.35976505279541, 1974
[INFO] 2021-07-12 19:11:54,607 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9729999621631578e-05, 1974
[INFO] 2021-07-12 19:11:54,607 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1974
[INFO] 2021-07-12 19:11:54,607 [run_pretraining.py:  558]:	worker_index: 6, step: 1974, cost: 7.359765, mlm loss: 7.359765, speed: 1.090740 steps/s, speed: 8.725917 samples/s, speed: 4467.669529 tokens/s, learning rate: 1.973e-05, loss_scalings: 3518.437988, pp_loss: 6.512442
[INFO] 2021-07-12 19:11:54,607 [run_pretraining.py:  512]:	********exe.run_1974******* 
[INFO] 2021-07-12 19:11:55,560 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:55,560 [run_pretraining.py:  534]:	loss/total_loss, 6.921290397644043, 1975
[INFO] 2021-07-12 19:11:55,560 [run_pretraining.py:  535]:	loss/mlm_loss, 6.921290397644043, 1975
[INFO] 2021-07-12 19:11:55,561 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9740000425372273e-05, 1975
[INFO] 2021-07-12 19:11:55,561 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1975
[INFO] 2021-07-12 19:11:55,561 [run_pretraining.py:  558]:	worker_index: 6, step: 1975, cost: 6.921290, mlm loss: 6.921290, speed: 1.049236 steps/s, speed: 8.393886 samples/s, speed: 4297.669456 tokens/s, learning rate: 1.974e-05, loss_scalings: 3518.437988, pp_loss: 7.094679
[INFO] 2021-07-12 19:11:55,561 [run_pretraining.py:  512]:	********exe.run_1975******* 
[INFO] 2021-07-12 19:11:56,498 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:56,498 [run_pretraining.py:  534]:	loss/total_loss, 6.86033821105957, 1976
[INFO] 2021-07-12 19:11:56,499 [run_pretraining.py:  535]:	loss/mlm_loss, 6.86033821105957, 1976
[INFO] 2021-07-12 19:11:56,499 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9749999410123564e-05, 1976
[INFO] 2021-07-12 19:11:56,499 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1976
[INFO] 2021-07-12 19:11:56,499 [run_pretraining.py:  558]:	worker_index: 6, step: 1976, cost: 6.860338, mlm loss: 6.860338, speed: 1.066916 steps/s, speed: 8.535328 samples/s, speed: 4370.088016 tokens/s, learning rate: 1.975e-05, loss_scalings: 3518.437988, pp_loss: 7.294960
[INFO] 2021-07-12 19:11:56,499 [run_pretraining.py:  512]:	********exe.run_1976******* 
[INFO] 2021-07-12 19:11:57,424 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:57,424 [run_pretraining.py:  534]:	loss/total_loss, 4.252745151519775, 1977
[INFO] 2021-07-12 19:11:57,424 [run_pretraining.py:  535]:	loss/mlm_loss, 4.252745151519775, 1977
[INFO] 2021-07-12 19:11:57,424 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.976000021386426e-05, 1977
[INFO] 2021-07-12 19:11:57,425 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1977
[INFO] 2021-07-12 19:11:57,425 [run_pretraining.py:  558]:	worker_index: 6, step: 1977, cost: 4.252745, mlm loss: 4.252745, speed: 1.080884 steps/s, speed: 8.647076 samples/s, speed: 4427.302694 tokens/s, learning rate: 1.976e-05, loss_scalings: 3518.437988, pp_loss: 6.540114
[INFO] 2021-07-12 19:11:57,425 [run_pretraining.py:  512]:	********exe.run_1977******* 
[INFO] 2021-07-12 19:11:58,340 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:58,341 [run_pretraining.py:  534]:	loss/total_loss, 6.578797340393066, 1978
[INFO] 2021-07-12 19:11:58,341 [run_pretraining.py:  535]:	loss/mlm_loss, 6.578797340393066, 1978
[INFO] 2021-07-12 19:11:58,341 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.976999919861555e-05, 1978
[INFO] 2021-07-12 19:11:58,341 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1978
[INFO] 2021-07-12 19:11:58,341 [run_pretraining.py:  558]:	worker_index: 6, step: 1978, cost: 6.578797, mlm loss: 6.578797, speed: 1.091854 steps/s, speed: 8.734830 samples/s, speed: 4472.233203 tokens/s, learning rate: 1.977e-05, loss_scalings: 3518.437988, pp_loss: 7.167570
[INFO] 2021-07-12 19:11:58,341 [run_pretraining.py:  512]:	********exe.run_1978******* 
[INFO] 2021-07-12 19:11:59,261 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:59,262 [run_pretraining.py:  534]:	loss/total_loss, 6.959632873535156, 1979
[INFO] 2021-07-12 19:11:59,262 [run_pretraining.py:  535]:	loss/mlm_loss, 6.959632873535156, 1979
[INFO] 2021-07-12 19:11:59,262 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9779998183366843e-05, 1979
[INFO] 2021-07-12 19:11:59,262 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1979
[INFO] 2021-07-12 19:11:59,262 [run_pretraining.py:  558]:	worker_index: 6, step: 1979, cost: 6.959633, mlm loss: 6.959633, speed: 1.086387 steps/s, speed: 8.691095 samples/s, speed: 4449.840663 tokens/s, learning rate: 1.978e-05, loss_scalings: 3518.437988, pp_loss: 7.005545
[INFO] 2021-07-12 19:11:59,262 [run_pretraining.py:  512]:	********exe.run_1979******* 
[INFO] 2021-07-12 19:12:00,183 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:00,183 [run_pretraining.py:  534]:	loss/total_loss, 6.750580787658691, 1980
[INFO] 2021-07-12 19:12:00,183 [run_pretraining.py:  535]:	loss/mlm_loss, 6.750580787658691, 1980
[INFO] 2021-07-12 19:12:00,183 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9789998987107538e-05, 1980
[INFO] 2021-07-12 19:12:00,184 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1980
[INFO] 2021-07-12 19:12:00,184 [run_pretraining.py:  558]:	worker_index: 6, step: 1980, cost: 6.750581, mlm loss: 6.750581, speed: 1.086359 steps/s, speed: 8.690870 samples/s, speed: 4449.725408 tokens/s, learning rate: 1.979e-05, loss_scalings: 3518.437988, pp_loss: 6.920232
[INFO] 2021-07-12 19:12:00,184 [run_pretraining.py:  512]:	********exe.run_1980******* 
[INFO] 2021-07-12 19:12:01,116 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:01,116 [run_pretraining.py:  534]:	loss/total_loss, 6.961941242218018, 1981
[INFO] 2021-07-12 19:12:01,117 [run_pretraining.py:  535]:	loss/mlm_loss, 6.961941242218018, 1981
[INFO] 2021-07-12 19:12:01,117 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9799999790848233e-05, 1981
[INFO] 2021-07-12 19:12:01,117 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1981
[INFO] 2021-07-12 19:12:01,117 [run_pretraining.py:  558]:	worker_index: 6, step: 1981, cost: 6.961941, mlm loss: 6.961941, speed: 1.072376 steps/s, speed: 8.579006 samples/s, speed: 4392.451161 tokens/s, learning rate: 1.980e-05, loss_scalings: 3518.437988, pp_loss: 7.359691
[INFO] 2021-07-12 19:12:01,117 [run_pretraining.py:  512]:	********exe.run_1981******* 
[INFO] 2021-07-12 19:12:02,041 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:02,041 [run_pretraining.py:  534]:	loss/total_loss, 7.019898891448975, 1982
[INFO] 2021-07-12 19:12:02,041 [run_pretraining.py:  535]:	loss/mlm_loss, 7.019898891448975, 1982
[INFO] 2021-07-12 19:12:02,041 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9809998775599524e-05, 1982
[INFO] 2021-07-12 19:12:02,042 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1982
[INFO] 2021-07-12 19:12:02,042 [run_pretraining.py:  558]:	worker_index: 6, step: 1982, cost: 7.019899, mlm loss: 7.019899, speed: 1.082149 steps/s, speed: 8.657193 samples/s, speed: 4432.482861 tokens/s, learning rate: 1.981e-05, loss_scalings: 3518.437988, pp_loss: 7.208012
[INFO] 2021-07-12 19:12:02,042 [run_pretraining.py:  512]:	********exe.run_1982******* 
[INFO] 2021-07-12 19:12:02,969 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:02,970 [run_pretraining.py:  534]:	loss/total_loss, 8.050029754638672, 1983
[INFO] 2021-07-12 19:12:02,970 [run_pretraining.py:  535]:	loss/mlm_loss, 8.050029754638672, 1983
[INFO] 2021-07-12 19:12:02,970 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.981999957934022e-05, 1983
[INFO] 2021-07-12 19:12:02,970 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1983
[INFO] 2021-07-12 19:12:02,970 [run_pretraining.py:  558]:	worker_index: 6, step: 1983, cost: 8.050030, mlm loss: 8.050030, speed: 1.077712 steps/s, speed: 8.621693 samples/s, speed: 4414.306982 tokens/s, learning rate: 1.982e-05, loss_scalings: 3518.437988, pp_loss: 7.296728
[INFO] 2021-07-12 19:12:02,970 [run_pretraining.py:  512]:	********exe.run_1983******* 
[INFO] 2021-07-12 19:12:03,896 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:03,896 [run_pretraining.py:  534]:	loss/total_loss, 5.094423770904541, 1984
[INFO] 2021-07-12 19:12:03,897 [run_pretraining.py:  535]:	loss/mlm_loss, 5.094423770904541, 1984
[INFO] 2021-07-12 19:12:03,897 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9830000383080915e-05, 1984
[INFO] 2021-07-12 19:12:03,897 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1984
[INFO] 2021-07-12 19:12:03,897 [run_pretraining.py:  558]:	worker_index: 6, step: 1984, cost: 5.094424, mlm loss: 5.094424, speed: 1.080068 steps/s, speed: 8.640540 samples/s, speed: 4423.956599 tokens/s, learning rate: 1.983e-05, loss_scalings: 3518.437988, pp_loss: 6.908041
[INFO] 2021-07-12 19:12:03,897 [run_pretraining.py:  512]:	********exe.run_1984******* 
[INFO] 2021-07-12 19:12:04,823 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:04,823 [run_pretraining.py:  534]:	loss/total_loss, 7.371657848358154, 1985
[INFO] 2021-07-12 19:12:04,823 [run_pretraining.py:  535]:	loss/mlm_loss, 7.371657848358154, 1985
[INFO] 2021-07-12 19:12:04,823 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9839999367832206e-05, 1985
[INFO] 2021-07-12 19:12:04,824 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1985
[INFO] 2021-07-12 19:12:04,824 [run_pretraining.py:  558]:	worker_index: 6, step: 1985, cost: 7.371658, mlm loss: 7.371658, speed: 1.079813 steps/s, speed: 8.638500 samples/s, speed: 4422.912194 tokens/s, learning rate: 1.984e-05, loss_scalings: 3518.437988, pp_loss: 7.410678
[INFO] 2021-07-12 19:12:04,824 [run_pretraining.py:  512]:	********exe.run_1985******* 
[INFO] 2021-07-12 19:12:05,750 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:05,750 [run_pretraining.py:  534]:	loss/total_loss, 7.002077579498291, 1986
[INFO] 2021-07-12 19:12:05,751 [run_pretraining.py:  535]:	loss/mlm_loss, 7.002077579498291, 1986
[INFO] 2021-07-12 19:12:05,751 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.98500001715729e-05, 1986
[INFO] 2021-07-12 19:12:05,751 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1986
[INFO] 2021-07-12 19:12:05,751 [run_pretraining.py:  558]:	worker_index: 6, step: 1986, cost: 7.002078, mlm loss: 7.002078, speed: 1.079408 steps/s, speed: 8.635261 samples/s, speed: 4421.253778 tokens/s, learning rate: 1.985e-05, loss_scalings: 3518.437988, pp_loss: 7.438310
[INFO] 2021-07-12 19:12:05,751 [run_pretraining.py:  512]:	********exe.run_1986******* 
[INFO] 2021-07-12 19:12:06,693 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:06,694 [run_pretraining.py:  534]:	loss/total_loss, 7.503107070922852, 1987
[INFO] 2021-07-12 19:12:06,694 [run_pretraining.py:  535]:	loss/mlm_loss, 7.503107070922852, 1987
[INFO] 2021-07-12 19:12:06,694 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9859999156324193e-05, 1987
[INFO] 2021-07-12 19:12:06,694 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1987
[INFO] 2021-07-12 19:12:06,694 [run_pretraining.py:  558]:	worker_index: 6, step: 1987, cost: 7.503107, mlm loss: 7.503107, speed: 1.060881 steps/s, speed: 8.487051 samples/s, speed: 4345.370333 tokens/s, learning rate: 1.986e-05, loss_scalings: 3518.437988, pp_loss: 7.809579
[INFO] 2021-07-12 19:12:06,695 [run_pretraining.py:  512]:	********exe.run_1987******* 
[INFO] 2021-07-12 19:12:07,626 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:07,626 [run_pretraining.py:  534]:	loss/total_loss, 7.049861907958984, 1988
[INFO] 2021-07-12 19:12:07,626 [run_pretraining.py:  535]:	loss/mlm_loss, 7.049861907958984, 1988
[INFO] 2021-07-12 19:12:07,626 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9869999960064888e-05, 1988
[INFO] 2021-07-12 19:12:07,627 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1988
[INFO] 2021-07-12 19:12:07,627 [run_pretraining.py:  558]:	worker_index: 6, step: 1988, cost: 7.049862, mlm loss: 7.049862, speed: 1.073603 steps/s, speed: 8.588824 samples/s, speed: 4397.478005 tokens/s, learning rate: 1.987e-05, loss_scalings: 3518.437988, pp_loss: 6.512085
[INFO] 2021-07-12 19:12:07,627 [run_pretraining.py:  512]:	********exe.run_1988******* 
[INFO] 2021-07-12 19:12:08,554 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:08,555 [run_pretraining.py:  534]:	loss/total_loss, 7.16067361831665, 1989
[INFO] 2021-07-12 19:12:08,555 [run_pretraining.py:  535]:	loss/mlm_loss, 7.16067361831665, 1989
[INFO] 2021-07-12 19:12:08,555 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.987999894481618e-05, 1989
[INFO] 2021-07-12 19:12:08,555 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1989
[INFO] 2021-07-12 19:12:08,555 [run_pretraining.py:  558]:	worker_index: 6, step: 1989, cost: 7.160674, mlm loss: 7.160674, speed: 1.077609 steps/s, speed: 8.620876 samples/s, speed: 4413.888487 tokens/s, learning rate: 1.988e-05, loss_scalings: 3518.437988, pp_loss: 7.383044
[INFO] 2021-07-12 19:12:08,555 [run_pretraining.py:  512]:	********exe.run_1989******* 
[INFO] 2021-07-12 19:12:09,489 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:09,490 [run_pretraining.py:  534]:	loss/total_loss, 7.397198677062988, 1990
[INFO] 2021-07-12 19:12:09,490 [run_pretraining.py:  535]:	loss/mlm_loss, 7.397198677062988, 1990
[INFO] 2021-07-12 19:12:09,490 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9889999748556875e-05, 1990
[INFO] 2021-07-12 19:12:09,490 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1990
[INFO] 2021-07-12 19:12:09,490 [run_pretraining.py:  558]:	worker_index: 6, step: 1990, cost: 7.397199, mlm loss: 7.397199, speed: 1.070295 steps/s, speed: 8.562357 samples/s, speed: 4383.927039 tokens/s, learning rate: 1.989e-05, loss_scalings: 3518.437988, pp_loss: 7.252409
[INFO] 2021-07-12 19:12:09,490 [run_pretraining.py:  512]:	********exe.run_1990******* 
[INFO] 2021-07-12 19:12:10,438 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:10,439 [run_pretraining.py:  534]:	loss/total_loss, 7.113738536834717, 1991
[INFO] 2021-07-12 19:12:10,439 [run_pretraining.py:  535]:	loss/mlm_loss, 7.113738536834717, 1991
[INFO] 2021-07-12 19:12:10,439 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9899998733308166e-05, 1991
[INFO] 2021-07-12 19:12:10,439 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1991
[INFO] 2021-07-12 19:12:10,439 [run_pretraining.py:  558]:	worker_index: 6, step: 1991, cost: 7.113739, mlm loss: 7.113739, speed: 1.054489 steps/s, speed: 8.435914 samples/s, speed: 4319.188224 tokens/s, learning rate: 1.990e-05, loss_scalings: 3518.437988, pp_loss: 7.548654
[INFO] 2021-07-12 19:12:10,439 [run_pretraining.py:  512]:	********exe.run_1991******* 
[INFO] 2021-07-12 19:12:11,375 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:11,376 [run_pretraining.py:  534]:	loss/total_loss, 7.324620246887207, 1992
[INFO] 2021-07-12 19:12:11,376 [run_pretraining.py:  535]:	loss/mlm_loss, 7.324620246887207, 1992
[INFO] 2021-07-12 19:12:11,376 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.990999953704886e-05, 1992
[INFO] 2021-07-12 19:12:11,376 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1992
[INFO] 2021-07-12 19:12:11,376 [run_pretraining.py:  558]:	worker_index: 6, step: 1992, cost: 7.324620, mlm loss: 7.324620, speed: 1.068549 steps/s, speed: 8.548390 samples/s, speed: 4376.775801 tokens/s, learning rate: 1.991e-05, loss_scalings: 3518.437988, pp_loss: 7.115064
[INFO] 2021-07-12 19:12:11,376 [run_pretraining.py:  512]:	********exe.run_1992******* 
[INFO] 2021-07-12 19:12:12,313 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:12,314 [run_pretraining.py:  534]:	loss/total_loss, 7.171886920928955, 1993
[INFO] 2021-07-12 19:12:12,314 [run_pretraining.py:  535]:	loss/mlm_loss, 7.171886920928955, 1993
[INFO] 2021-07-12 19:12:12,314 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9920000340789557e-05, 1993
[INFO] 2021-07-12 19:12:12,314 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1993
[INFO] 2021-07-12 19:12:12,314 [run_pretraining.py:  558]:	worker_index: 6, step: 1993, cost: 7.171887, mlm loss: 7.171887, speed: 1.066686 steps/s, speed: 8.533490 samples/s, speed: 4369.146668 tokens/s, learning rate: 1.992e-05, loss_scalings: 3518.437988, pp_loss: 7.305994
[INFO] 2021-07-12 19:12:12,314 [run_pretraining.py:  512]:	********exe.run_1993******* 
[INFO] 2021-07-12 19:12:13,252 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:13,252 [run_pretraining.py:  534]:	loss/total_loss, 7.8534836769104, 1994
[INFO] 2021-07-12 19:12:13,252 [run_pretraining.py:  535]:	loss/mlm_loss, 7.8534836769104, 1994
[INFO] 2021-07-12 19:12:13,253 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9929999325540848e-05, 1994
[INFO] 2021-07-12 19:12:13,253 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1994
[INFO] 2021-07-12 19:12:13,253 [run_pretraining.py:  558]:	worker_index: 6, step: 1994, cost: 7.853484, mlm loss: 7.853484, speed: 1.066226 steps/s, speed: 8.529808 samples/s, speed: 4367.261857 tokens/s, learning rate: 1.993e-05, loss_scalings: 3518.437988, pp_loss: 7.746705
[INFO] 2021-07-12 19:12:13,253 [run_pretraining.py:  512]:	********exe.run_1994******* 
[INFO] 2021-07-12 19:12:14,201 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:14,201 [run_pretraining.py:  534]:	loss/total_loss, 7.644989490509033, 1995
[INFO] 2021-07-12 19:12:14,202 [run_pretraining.py:  535]:	loss/mlm_loss, 7.644989490509033, 1995
[INFO] 2021-07-12 19:12:14,202 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.993999831029214e-05, 1995
[INFO] 2021-07-12 19:12:14,202 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1995
[INFO] 2021-07-12 19:12:14,202 [run_pretraining.py:  558]:	worker_index: 6, step: 1995, cost: 7.644989, mlm loss: 7.644989, speed: 1.054409 steps/s, speed: 8.435274 samples/s, speed: 4318.860311 tokens/s, learning rate: 1.994e-05, loss_scalings: 3518.437988, pp_loss: 7.189432
[INFO] 2021-07-12 19:12:14,202 [run_pretraining.py:  512]:	********exe.run_1995******* 
[INFO] 2021-07-12 19:12:15,130 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:15,131 [run_pretraining.py:  534]:	loss/total_loss, 7.645747184753418, 1996
[INFO] 2021-07-12 19:12:15,131 [run_pretraining.py:  535]:	loss/mlm_loss, 7.645747184753418, 1996
[INFO] 2021-07-12 19:12:15,131 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9949999114032835e-05, 1996
[INFO] 2021-07-12 19:12:15,131 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1996
[INFO] 2021-07-12 19:12:15,131 [run_pretraining.py:  558]:	worker_index: 6, step: 1996, cost: 7.645747, mlm loss: 7.645747, speed: 1.076879 steps/s, speed: 8.615028 samples/s, speed: 4410.894423 tokens/s, learning rate: 1.995e-05, loss_scalings: 3518.437988, pp_loss: 7.496480
[INFO] 2021-07-12 19:12:15,131 [run_pretraining.py:  512]:	********exe.run_1996******* 
[INFO] 2021-07-12 19:12:16,043 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:16,044 [run_pretraining.py:  534]:	loss/total_loss, 5.362549304962158, 1997
[INFO] 2021-07-12 19:12:16,044 [run_pretraining.py:  535]:	loss/mlm_loss, 5.362549304962158, 1997
[INFO] 2021-07-12 19:12:16,044 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.995999991777353e-05, 1997
[INFO] 2021-07-12 19:12:16,044 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1997
[INFO] 2021-07-12 19:12:16,044 [run_pretraining.py:  558]:	worker_index: 6, step: 1997, cost: 5.362549, mlm loss: 5.362549, speed: 1.096320 steps/s, speed: 8.770559 samples/s, speed: 4490.526351 tokens/s, learning rate: 1.996e-05, loss_scalings: 3518.437988, pp_loss: 6.699368
[INFO] 2021-07-12 19:12:16,044 [run_pretraining.py:  512]:	********exe.run_1997******* 
[INFO] 2021-07-12 19:12:16,994 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:16,995 [run_pretraining.py:  534]:	loss/total_loss, 8.145118713378906, 1998
[INFO] 2021-07-12 19:12:16,995 [run_pretraining.py:  535]:	loss/mlm_loss, 8.145118713378906, 1998
[INFO] 2021-07-12 19:12:16,995 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.996999890252482e-05, 1998
[INFO] 2021-07-12 19:12:16,995 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1998
[INFO] 2021-07-12 19:12:16,995 [run_pretraining.py:  558]:	worker_index: 6, step: 1998, cost: 8.145119, mlm loss: 8.145119, speed: 1.052262 steps/s, speed: 8.418094 samples/s, speed: 4310.064374 tokens/s, learning rate: 1.997e-05, loss_scalings: 3518.437988, pp_loss: 7.672311
[INFO] 2021-07-12 19:12:16,995 [run_pretraining.py:  512]:	********exe.run_1998******* 
[INFO] 2021-07-12 19:12:17,908 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:17,909 [run_pretraining.py:  534]:	loss/total_loss, 6.834782123565674, 1999
[INFO] 2021-07-12 19:12:17,909 [run_pretraining.py:  535]:	loss/mlm_loss, 6.834782123565674, 1999
[INFO] 2021-07-12 19:12:17,909 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9979999706265517e-05, 1999
[INFO] 2021-07-12 19:12:17,909 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1999
[INFO] 2021-07-12 19:12:17,909 [run_pretraining.py:  558]:	worker_index: 6, step: 1999, cost: 6.834782, mlm loss: 6.834782, speed: 1.094501 steps/s, speed: 8.756008 samples/s, speed: 4483.076046 tokens/s, learning rate: 1.998e-05, loss_scalings: 3518.437988, pp_loss: 7.252964
[INFO] 2021-07-12 19:12:17,910 [run_pretraining.py:  512]:	********exe.run_1999******* 
[INFO] 2021-07-12 19:12:18,822 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:18,823 [run_pretraining.py:  534]:	loss/total_loss, 7.0419840812683105, 2000
[INFO] 2021-07-12 19:12:18,823 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0419840812683105, 2000
[INFO] 2021-07-12 19:12:18,823 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9990000510006212e-05, 2000
[INFO] 2021-07-12 19:12:18,823 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2000
[INFO] 2021-07-12 19:12:18,823 [run_pretraining.py:  558]:	worker_index: 6, step: 2000, cost: 7.041984, mlm loss: 7.041984, speed: 1.094998 steps/s, speed: 8.759985 samples/s, speed: 4485.112520 tokens/s, learning rate: 1.999e-05, loss_scalings: 3518.437988, pp_loss: 7.129367
[INFO] 2021-07-12 19:12:18,823 [run_pretraining.py:  512]:	********exe.run_2000******* 
[INFO] 2021-07-12 19:12:19,725 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:19,725 [run_pretraining.py:  534]:	loss/total_loss, 6.9374165534973145, 2001
[INFO] 2021-07-12 19:12:19,725 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9374165534973145, 2001
[INFO] 2021-07-12 19:12:19,726 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9999999494757503e-05, 2001
[INFO] 2021-07-12 19:12:19,726 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2001
[INFO] 2021-07-12 19:12:19,726 [run_pretraining.py:  558]:	worker_index: 6, step: 2001, cost: 6.937417, mlm loss: 6.937417, speed: 1.109108 steps/s, speed: 8.872865 samples/s, speed: 4542.906648 tokens/s, learning rate: 2.000e-05, loss_scalings: 3518.437988, pp_loss: 7.212976
[INFO] 2021-07-12 19:12:19,726 [run_pretraining.py:  512]:	********exe.run_2001******* 
[INFO] 2021-07-12 19:12:20,642 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:20,643 [run_pretraining.py:  534]:	loss/total_loss, 7.193793773651123, 2002
[INFO] 2021-07-12 19:12:20,643 [run_pretraining.py:  535]:	loss/mlm_loss, 7.193793773651123, 2002
[INFO] 2021-07-12 19:12:20,643 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.00100002984982e-05, 2002
[INFO] 2021-07-12 19:12:20,643 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2002
[INFO] 2021-07-12 19:12:20,643 [run_pretraining.py:  558]:	worker_index: 6, step: 2002, cost: 7.193794, mlm loss: 7.193794, speed: 1.090540 steps/s, speed: 8.724322 samples/s, speed: 4466.852913 tokens/s, learning rate: 2.001e-05, loss_scalings: 3518.437988, pp_loss: 7.047643
[INFO] 2021-07-12 19:12:20,644 [run_pretraining.py:  512]:	********exe.run_2002******* 
[INFO] 2021-07-12 19:12:21,566 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:21,566 [run_pretraining.py:  534]:	loss/total_loss, 7.8576860427856445, 2003
[INFO] 2021-07-12 19:12:21,566 [run_pretraining.py:  535]:	loss/mlm_loss, 7.8576860427856445, 2003
[INFO] 2021-07-12 19:12:21,566 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.001999928324949e-05, 2003
[INFO] 2021-07-12 19:12:21,566 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2003
[INFO] 2021-07-12 19:12:21,567 [run_pretraining.py:  558]:	worker_index: 6, step: 2003, cost: 7.857686, mlm loss: 7.857686, speed: 1.084157 steps/s, speed: 8.673256 samples/s, speed: 4440.706854 tokens/s, learning rate: 2.002e-05, loss_scalings: 3518.437988, pp_loss: 7.131826
[INFO] 2021-07-12 19:12:21,567 [run_pretraining.py:  512]:	********exe.run_2003******* 
[INFO] 2021-07-12 19:12:22,474 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:22,474 [run_pretraining.py:  534]:	loss/total_loss, 7.042671203613281, 2004
[INFO] 2021-07-12 19:12:22,474 [run_pretraining.py:  535]:	loss/mlm_loss, 7.042671203613281, 2004
[INFO] 2021-07-12 19:12:22,474 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.002999826800078e-05, 2004
[INFO] 2021-07-12 19:12:22,474 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2004
[INFO] 2021-07-12 19:12:22,475 [run_pretraining.py:  558]:	worker_index: 6, step: 2004, cost: 7.042671, mlm loss: 7.042671, speed: 1.102140 steps/s, speed: 8.817118 samples/s, speed: 4514.364271 tokens/s, learning rate: 2.003e-05, loss_scalings: 3518.437988, pp_loss: 6.849351
[INFO] 2021-07-12 19:12:22,475 [run_pretraining.py:  512]:	********exe.run_2004******* 
[INFO] 2021-07-12 19:12:23,395 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:23,395 [run_pretraining.py:  534]:	loss/total_loss, 6.749176979064941, 2005
[INFO] 2021-07-12 19:12:23,395 [run_pretraining.py:  535]:	loss/mlm_loss, 6.749176979064941, 2005
[INFO] 2021-07-12 19:12:23,396 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0039999071741477e-05, 2005
[INFO] 2021-07-12 19:12:23,396 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2005
[INFO] 2021-07-12 19:12:23,396 [run_pretraining.py:  558]:	worker_index: 6, step: 2005, cost: 6.749177, mlm loss: 6.749177, speed: 1.086368 steps/s, speed: 8.690946 samples/s, speed: 4449.764594 tokens/s, learning rate: 2.004e-05, loss_scalings: 3518.437988, pp_loss: 7.296792
[INFO] 2021-07-12 19:12:23,396 [run_pretraining.py:  512]:	********exe.run_2005******* 
[INFO] 2021-07-12 19:12:24,314 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:24,315 [run_pretraining.py:  534]:	loss/total_loss, 7.724603652954102, 2006
[INFO] 2021-07-12 19:12:24,315 [run_pretraining.py:  535]:	loss/mlm_loss, 7.724603652954102, 2006
[INFO] 2021-07-12 19:12:24,315 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0049999875482172e-05, 2006
[INFO] 2021-07-12 19:12:24,315 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2006
[INFO] 2021-07-12 19:12:24,316 [run_pretraining.py:  558]:	worker_index: 6, step: 2006, cost: 7.724604, mlm loss: 7.724604, speed: 1.088105 steps/s, speed: 8.704842 samples/s, speed: 4456.879026 tokens/s, learning rate: 2.005e-05, loss_scalings: 3518.437988, pp_loss: 7.401810
[INFO] 2021-07-12 19:12:24,316 [run_pretraining.py:  512]:	********exe.run_2006******* 
[INFO] 2021-07-12 19:12:25,229 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:25,229 [run_pretraining.py:  534]:	loss/total_loss, 7.190360069274902, 2007
[INFO] 2021-07-12 19:12:25,229 [run_pretraining.py:  535]:	loss/mlm_loss, 7.190360069274902, 2007
[INFO] 2021-07-12 19:12:25,229 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0059998860233463e-05, 2007
[INFO] 2021-07-12 19:12:25,229 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2007
[INFO] 2021-07-12 19:12:25,230 [run_pretraining.py:  558]:	worker_index: 6, step: 2007, cost: 7.190360, mlm loss: 7.190360, speed: 1.094893 steps/s, speed: 8.759142 samples/s, speed: 4484.680493 tokens/s, learning rate: 2.006e-05, loss_scalings: 3518.437988, pp_loss: 7.130441
[INFO] 2021-07-12 19:12:25,230 [run_pretraining.py:  512]:	********exe.run_2007******* 
[INFO] 2021-07-12 19:12:26,151 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:26,152 [run_pretraining.py:  534]:	loss/total_loss, 7.076377868652344, 2008
[INFO] 2021-07-12 19:12:26,152 [run_pretraining.py:  535]:	loss/mlm_loss, 7.076377868652344, 2008
[INFO] 2021-07-12 19:12:26,152 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.006999966397416e-05, 2008
[INFO] 2021-07-12 19:12:26,152 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2008
[INFO] 2021-07-12 19:12:26,152 [run_pretraining.py:  558]:	worker_index: 6, step: 2008, cost: 7.076378, mlm loss: 7.076378, speed: 1.084547 steps/s, speed: 8.676377 samples/s, speed: 4442.305234 tokens/s, learning rate: 2.007e-05, loss_scalings: 3518.437988, pp_loss: 7.451728
[INFO] 2021-07-12 19:12:26,152 [run_pretraining.py:  512]:	********exe.run_2008******* 
[INFO] 2021-07-12 19:12:27,092 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:27,092 [run_pretraining.py:  534]:	loss/total_loss, 8.139575004577637, 2009
[INFO] 2021-07-12 19:12:27,092 [run_pretraining.py:  535]:	loss/mlm_loss, 8.139575004577637, 2009
[INFO] 2021-07-12 19:12:27,092 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0080000467714854e-05, 2009
[INFO] 2021-07-12 19:12:27,092 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2009
[INFO] 2021-07-12 19:12:27,092 [run_pretraining.py:  558]:	worker_index: 6, step: 2009, cost: 8.139575, mlm loss: 8.139575, speed: 1.064447 steps/s, speed: 8.515580 samples/s, speed: 4359.976729 tokens/s, learning rate: 2.008e-05, loss_scalings: 3518.437988, pp_loss: 7.760148
[INFO] 2021-07-12 19:12:27,093 [run_pretraining.py:  512]:	********exe.run_2009******* 
[INFO] 2021-07-12 19:12:28,031 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:28,032 [run_pretraining.py:  534]:	loss/total_loss, 7.251728534698486, 2010
[INFO] 2021-07-12 19:12:28,032 [run_pretraining.py:  535]:	loss/mlm_loss, 7.251728534698486, 2010
[INFO] 2021-07-12 19:12:28,032 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0089999452466145e-05, 2010
[INFO] 2021-07-12 19:12:28,032 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2010
[INFO] 2021-07-12 19:12:28,032 [run_pretraining.py:  558]:	worker_index: 6, step: 2010, cost: 7.251729, mlm loss: 7.251729, speed: 1.064736 steps/s, speed: 8.517888 samples/s, speed: 4361.158783 tokens/s, learning rate: 2.009e-05, loss_scalings: 3518.437988, pp_loss: 6.334082
[INFO] 2021-07-12 19:12:28,032 [run_pretraining.py:  512]:	********exe.run_2010******* 
[INFO] 2021-07-12 19:12:29,018 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:29,019 [run_pretraining.py:  534]:	loss/total_loss, 5.76186466217041, 2011
[INFO] 2021-07-12 19:12:29,019 [run_pretraining.py:  535]:	loss/mlm_loss, 5.76186466217041, 2011
[INFO] 2021-07-12 19:12:29,019 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.010000025620684e-05, 2011
[INFO] 2021-07-12 19:12:29,019 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2011
[INFO] 2021-07-12 19:12:29,019 [run_pretraining.py:  558]:	worker_index: 6, step: 2011, cost: 5.761865, mlm loss: 5.761865, speed: 1.014259 steps/s, speed: 8.114070 samples/s, speed: 4154.404073 tokens/s, learning rate: 2.010e-05, loss_scalings: 3518.437988, pp_loss: 6.888853
[INFO] 2021-07-12 19:12:29,019 [run_pretraining.py:  512]:	********exe.run_2011******* 
[INFO] 2021-07-12 19:12:29,961 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:29,962 [run_pretraining.py:  534]:	loss/total_loss, 6.7283124923706055, 2012
[INFO] 2021-07-12 19:12:29,962 [run_pretraining.py:  535]:	loss/mlm_loss, 6.7283124923706055, 2012
[INFO] 2021-07-12 19:12:29,962 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0110001059947535e-05, 2012
[INFO] 2021-07-12 19:12:29,962 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2012
[INFO] 2021-07-12 19:12:29,962 [run_pretraining.py:  558]:	worker_index: 6, step: 2012, cost: 6.728312, mlm loss: 6.728312, speed: 1.061056 steps/s, speed: 8.488451 samples/s, speed: 4346.087059 tokens/s, learning rate: 2.011e-05, loss_scalings: 3518.437988, pp_loss: 6.981432
[INFO] 2021-07-12 19:12:29,962 [run_pretraining.py:  512]:	********exe.run_2012******* 
[INFO] 2021-07-12 19:12:30,898 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:30,899 [run_pretraining.py:  534]:	loss/total_loss, 7.094676971435547, 2013
[INFO] 2021-07-12 19:12:30,899 [run_pretraining.py:  535]:	loss/mlm_loss, 7.094676971435547, 2013
[INFO] 2021-07-12 19:12:30,899 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0119998225709423e-05, 2013
[INFO] 2021-07-12 19:12:30,899 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2013
[INFO] 2021-07-12 19:12:30,899 [run_pretraining.py:  558]:	worker_index: 6, step: 2013, cost: 7.094677, mlm loss: 7.094677, speed: 1.068156 steps/s, speed: 8.545251 samples/s, speed: 4375.168510 tokens/s, learning rate: 2.012e-05, loss_scalings: 3518.437988, pp_loss: 6.931705
[INFO] 2021-07-12 19:12:30,899 [run_pretraining.py:  512]:	********exe.run_2013******* 
[INFO] 2021-07-12 19:12:31,843 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:31,843 [run_pretraining.py:  534]:	loss/total_loss, 8.156865119934082, 2014
[INFO] 2021-07-12 19:12:31,843 [run_pretraining.py:  535]:	loss/mlm_loss, 8.156865119934082, 2014
[INFO] 2021-07-12 19:12:31,843 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.012999902945012e-05, 2014
[INFO] 2021-07-12 19:12:31,843 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2014
[INFO] 2021-07-12 19:12:31,844 [run_pretraining.py:  558]:	worker_index: 6, step: 2014, cost: 8.156865, mlm loss: 8.156865, speed: 1.059612 steps/s, speed: 8.476895 samples/s, speed: 4340.170168 tokens/s, learning rate: 2.013e-05, loss_scalings: 3518.437988, pp_loss: 7.540347
[INFO] 2021-07-12 19:12:31,844 [run_pretraining.py:  512]:	********exe.run_2014******* 
[INFO] 2021-07-12 19:12:32,772 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:32,772 [run_pretraining.py:  534]:	loss/total_loss, 7.521119117736816, 2015
[INFO] 2021-07-12 19:12:32,773 [run_pretraining.py:  535]:	loss/mlm_loss, 7.521119117736816, 2015
[INFO] 2021-07-12 19:12:32,773 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0139999833190814e-05, 2015
[INFO] 2021-07-12 19:12:32,773 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2015
[INFO] 2021-07-12 19:12:32,773 [run_pretraining.py:  558]:	worker_index: 6, step: 2015, cost: 7.521119, mlm loss: 7.521119, speed: 1.076796 steps/s, speed: 8.614371 samples/s, speed: 4410.558100 tokens/s, learning rate: 2.014e-05, loss_scalings: 3518.437988, pp_loss: 7.233157
[INFO] 2021-07-12 19:12:32,773 [run_pretraining.py:  512]:	********exe.run_2015******* 
[INFO] 2021-07-12 19:12:33,717 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:33,717 [run_pretraining.py:  534]:	loss/total_loss, 7.661360740661621, 2016
[INFO] 2021-07-12 19:12:33,717 [run_pretraining.py:  535]:	loss/mlm_loss, 7.661360740661621, 2016
[INFO] 2021-07-12 19:12:33,718 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0149998817942105e-05, 2016
[INFO] 2021-07-12 19:12:33,718 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2016
[INFO] 2021-07-12 19:12:33,718 [run_pretraining.py:  558]:	worker_index: 6, step: 2016, cost: 7.661361, mlm loss: 7.661361, speed: 1.059176 steps/s, speed: 8.473410 samples/s, speed: 4338.385862 tokens/s, learning rate: 2.015e-05, loss_scalings: 3518.437988, pp_loss: 7.254396
[INFO] 2021-07-12 19:12:33,718 [run_pretraining.py:  512]:	********exe.run_2016******* 
[INFO] 2021-07-12 19:12:34,646 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:34,647 [run_pretraining.py:  534]:	loss/total_loss, 6.931957244873047, 2017
[INFO] 2021-07-12 19:12:34,647 [run_pretraining.py:  535]:	loss/mlm_loss, 6.931957244873047, 2017
[INFO] 2021-07-12 19:12:34,647 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.01599996216828e-05, 2017
[INFO] 2021-07-12 19:12:34,647 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2017
[INFO] 2021-07-12 19:12:34,647 [run_pretraining.py:  558]:	worker_index: 6, step: 2017, cost: 6.931957, mlm loss: 6.931957, speed: 1.076816 steps/s, speed: 8.614531 samples/s, speed: 4410.639628 tokens/s, learning rate: 2.016e-05, loss_scalings: 3518.437988, pp_loss: 7.229991
[INFO] 2021-07-12 19:12:34,647 [run_pretraining.py:  512]:	********exe.run_2017******* 
[INFO] 2021-07-12 19:12:35,612 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:35,613 [run_pretraining.py:  534]:	loss/total_loss, 7.348362445831299, 2018
[INFO] 2021-07-12 19:12:35,613 [run_pretraining.py:  535]:	loss/mlm_loss, 7.348362445831299, 2018
[INFO] 2021-07-12 19:12:35,613 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0170000425423495e-05, 2018
[INFO] 2021-07-12 19:12:35,613 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2018
[INFO] 2021-07-12 19:12:35,613 [run_pretraining.py:  558]:	worker_index: 6, step: 2018, cost: 7.348362, mlm loss: 7.348362, speed: 1.035829 steps/s, speed: 8.286629 samples/s, speed: 4242.753846 tokens/s, learning rate: 2.017e-05, loss_scalings: 3518.437988, pp_loss: 7.171996
[INFO] 2021-07-12 19:12:35,613 [run_pretraining.py:  512]:	********exe.run_2018******* 
[INFO] 2021-07-12 19:12:36,575 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:36,575 [run_pretraining.py:  534]:	loss/total_loss, 7.419740200042725, 2019
[INFO] 2021-07-12 19:12:36,576 [run_pretraining.py:  535]:	loss/mlm_loss, 7.419740200042725, 2019
[INFO] 2021-07-12 19:12:36,576 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0179999410174787e-05, 2019
[INFO] 2021-07-12 19:12:36,576 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2019
[INFO] 2021-07-12 19:12:36,576 [run_pretraining.py:  558]:	worker_index: 6, step: 2019, cost: 7.419740, mlm loss: 7.419740, speed: 1.039543 steps/s, speed: 8.316341 samples/s, speed: 4257.966630 tokens/s, learning rate: 2.018e-05, loss_scalings: 3518.437988, pp_loss: 7.653405
[INFO] 2021-07-12 19:12:36,576 [run_pretraining.py:  512]:	********exe.run_2019******* 
[INFO] 2021-07-12 19:12:37,537 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:37,537 [run_pretraining.py:  534]:	loss/total_loss, 7.4217119216918945, 2020
[INFO] 2021-07-12 19:12:37,537 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4217119216918945, 2020
[INFO] 2021-07-12 19:12:37,537 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0190000213915482e-05, 2020
[INFO] 2021-07-12 19:12:37,537 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2020
[INFO] 2021-07-12 19:12:37,537 [run_pretraining.py:  558]:	worker_index: 6, step: 2020, cost: 7.421712, mlm loss: 7.421712, speed: 1.040640 steps/s, speed: 8.325119 samples/s, speed: 4262.460705 tokens/s, learning rate: 2.019e-05, loss_scalings: 3518.437988, pp_loss: 7.161885
[INFO] 2021-07-12 19:12:37,538 [run_pretraining.py:  512]:	********exe.run_2020******* 
[INFO] 2021-07-12 19:12:38,489 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:38,490 [run_pretraining.py:  534]:	loss/total_loss, 7.675390243530273, 2021
[INFO] 2021-07-12 19:12:38,490 [run_pretraining.py:  535]:	loss/mlm_loss, 7.675390243530273, 2021
[INFO] 2021-07-12 19:12:38,490 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0200001017656177e-05, 2021
[INFO] 2021-07-12 19:12:38,490 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2021
[INFO] 2021-07-12 19:12:38,490 [run_pretraining.py:  558]:	worker_index: 6, step: 2021, cost: 7.675390, mlm loss: 7.675390, speed: 1.050147 steps/s, speed: 8.401178 samples/s, speed: 4301.403271 tokens/s, learning rate: 2.020e-05, loss_scalings: 3518.437988, pp_loss: 7.130649
[INFO] 2021-07-12 19:12:38,491 [run_pretraining.py:  512]:	********exe.run_2021******* 
[INFO] 2021-07-12 19:12:39,444 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:39,445 [run_pretraining.py:  534]:	loss/total_loss, 5.815126895904541, 2022
[INFO] 2021-07-12 19:12:39,445 [run_pretraining.py:  535]:	loss/mlm_loss, 5.815126895904541, 2022
[INFO] 2021-07-12 19:12:39,445 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0209998183418065e-05, 2022
[INFO] 2021-07-12 19:12:39,445 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2022
[INFO] 2021-07-12 19:12:39,445 [run_pretraining.py:  558]:	worker_index: 6, step: 2022, cost: 5.815127, mlm loss: 5.815127, speed: 1.048261 steps/s, speed: 8.386086 samples/s, speed: 4293.675973 tokens/s, learning rate: 2.021e-05, loss_scalings: 3518.437988, pp_loss: 7.047408
[INFO] 2021-07-12 19:12:39,445 [run_pretraining.py:  512]:	********exe.run_2022******* 
[INFO] 2021-07-12 19:12:40,388 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:40,388 [run_pretraining.py:  534]:	loss/total_loss, 7.329100131988525, 2023
[INFO] 2021-07-12 19:12:40,388 [run_pretraining.py:  535]:	loss/mlm_loss, 7.329100131988525, 2023
[INFO] 2021-07-12 19:12:40,388 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.021999898715876e-05, 2023
[INFO] 2021-07-12 19:12:40,389 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2023
[INFO] 2021-07-12 19:12:40,389 [run_pretraining.py:  558]:	worker_index: 6, step: 2023, cost: 7.329100, mlm loss: 7.329100, speed: 1.060640 steps/s, speed: 8.485118 samples/s, speed: 4344.380277 tokens/s, learning rate: 2.022e-05, loss_scalings: 3518.437988, pp_loss: 7.411349
[INFO] 2021-07-12 19:12:40,389 [run_pretraining.py:  512]:	********exe.run_2023******* 
[INFO] 2021-07-12 19:12:41,326 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:41,326 [run_pretraining.py:  534]:	loss/total_loss, 7.165270805358887, 2024
[INFO] 2021-07-12 19:12:41,326 [run_pretraining.py:  535]:	loss/mlm_loss, 7.165270805358887, 2024
[INFO] 2021-07-12 19:12:41,327 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0229999790899456e-05, 2024
[INFO] 2021-07-12 19:12:41,327 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2024
[INFO] 2021-07-12 19:12:41,327 [run_pretraining.py:  558]:	worker_index: 6, step: 2024, cost: 7.165271, mlm loss: 7.165271, speed: 1.066841 steps/s, speed: 8.534725 samples/s, speed: 4369.779005 tokens/s, learning rate: 2.023e-05, loss_scalings: 3518.437988, pp_loss: 7.105801
[INFO] 2021-07-12 19:12:41,327 [run_pretraining.py:  512]:	********exe.run_2024******* 
[INFO] 2021-07-12 19:12:42,266 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:42,267 [run_pretraining.py:  534]:	loss/total_loss, 4.83799934387207, 2025
[INFO] 2021-07-12 19:12:42,267 [run_pretraining.py:  535]:	loss/mlm_loss, 4.83799934387207, 2025
[INFO] 2021-07-12 19:12:42,267 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0239998775650747e-05, 2025
[INFO] 2021-07-12 19:12:42,267 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2025
[INFO] 2021-07-12 19:12:42,267 [run_pretraining.py:  558]:	worker_index: 6, step: 2025, cost: 4.837999, mlm loss: 4.837999, speed: 1.064019 steps/s, speed: 8.512153 samples/s, speed: 4358.222538 tokens/s, learning rate: 2.024e-05, loss_scalings: 3518.437988, pp_loss: 6.836163
[INFO] 2021-07-12 19:12:42,267 [run_pretraining.py:  512]:	********exe.run_2025******* 
[INFO] 2021-07-12 19:12:43,196 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:43,196 [run_pretraining.py:  534]:	loss/total_loss, 7.447668552398682, 2026
[INFO] 2021-07-12 19:12:43,196 [run_pretraining.py:  535]:	loss/mlm_loss, 7.447668552398682, 2026
[INFO] 2021-07-12 19:12:43,196 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0249999579391442e-05, 2026
[INFO] 2021-07-12 19:12:43,197 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2026
[INFO] 2021-07-12 19:12:43,197 [run_pretraining.py:  558]:	worker_index: 6, step: 2026, cost: 7.447669, mlm loss: 7.447669, speed: 1.076796 steps/s, speed: 8.614365 samples/s, speed: 4410.554703 tokens/s, learning rate: 2.025e-05, loss_scalings: 3518.437988, pp_loss: 7.310936
[INFO] 2021-07-12 19:12:43,197 [run_pretraining.py:  512]:	********exe.run_2026******* 
[INFO] 2021-07-12 19:12:44,142 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:44,142 [run_pretraining.py:  534]:	loss/total_loss, 7.123617172241211, 2027
[INFO] 2021-07-12 19:12:44,142 [run_pretraining.py:  535]:	loss/mlm_loss, 7.123617172241211, 2027
[INFO] 2021-07-12 19:12:44,142 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0260000383132137e-05, 2027
[INFO] 2021-07-12 19:12:44,143 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2027
[INFO] 2021-07-12 19:12:44,143 [run_pretraining.py:  558]:	worker_index: 6, step: 2027, cost: 7.123617, mlm loss: 7.123617, speed: 1.057782 steps/s, speed: 8.462259 samples/s, speed: 4332.676748 tokens/s, learning rate: 2.026e-05, loss_scalings: 3518.437988, pp_loss: 7.228564
[INFO] 2021-07-12 19:12:44,143 [run_pretraining.py:  512]:	********exe.run_2027******* 
[INFO] 2021-07-12 19:12:45,087 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:45,088 [run_pretraining.py:  534]:	loss/total_loss, 6.853571891784668, 2028
[INFO] 2021-07-12 19:12:45,088 [run_pretraining.py:  535]:	loss/mlm_loss, 6.853571891784668, 2028
[INFO] 2021-07-12 19:12:45,088 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.026999936788343e-05, 2028
[INFO] 2021-07-12 19:12:45,088 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2028
[INFO] 2021-07-12 19:12:45,088 [run_pretraining.py:  558]:	worker_index: 6, step: 2028, cost: 6.853572, mlm loss: 6.853572, speed: 1.058672 steps/s, speed: 8.469374 samples/s, speed: 4336.319523 tokens/s, learning rate: 2.027e-05, loss_scalings: 3518.437988, pp_loss: 7.072322
[INFO] 2021-07-12 19:12:45,088 [run_pretraining.py:  512]:	********exe.run_2028******* 
[INFO] 2021-07-12 19:12:46,042 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:46,043 [run_pretraining.py:  534]:	loss/total_loss, 7.678918361663818, 2029
[INFO] 2021-07-12 19:12:46,043 [run_pretraining.py:  535]:	loss/mlm_loss, 7.678918361663818, 2029
[INFO] 2021-07-12 19:12:46,043 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0280000171624124e-05, 2029
[INFO] 2021-07-12 19:12:46,043 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2029
[INFO] 2021-07-12 19:12:46,043 [run_pretraining.py:  558]:	worker_index: 6, step: 2029, cost: 7.678918, mlm loss: 7.678918, speed: 1.047545 steps/s, speed: 8.380360 samples/s, speed: 4290.744131 tokens/s, learning rate: 2.028e-05, loss_scalings: 3518.437988, pp_loss: 7.554647
[INFO] 2021-07-12 19:12:46,043 [run_pretraining.py:  512]:	********exe.run_2029******* 
[INFO] 2021-07-12 19:12:46,999 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:46,999 [run_pretraining.py:  534]:	loss/total_loss, 6.9794697761535645, 2030
[INFO] 2021-07-12 19:12:47,000 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9794697761535645, 2030
[INFO] 2021-07-12 19:12:47,000 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.029000097536482e-05, 2030
[INFO] 2021-07-12 19:12:47,000 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2030
[INFO] 2021-07-12 19:12:47,000 [run_pretraining.py:  558]:	worker_index: 6, step: 2030, cost: 6.979470, mlm loss: 6.979470, speed: 1.046203 steps/s, speed: 8.369628 samples/s, speed: 4285.249422 tokens/s, learning rate: 2.029e-05, loss_scalings: 3518.437988, pp_loss: 6.793258
[INFO] 2021-07-12 19:12:47,000 [run_pretraining.py:  512]:	********exe.run_2030******* 
[INFO] 2021-07-12 19:12:47,946 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:47,946 [run_pretraining.py:  534]:	loss/total_loss, 7.183146953582764, 2031
[INFO] 2021-07-12 19:12:47,946 [run_pretraining.py:  535]:	loss/mlm_loss, 7.183146953582764, 2031
[INFO] 2021-07-12 19:12:47,946 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0299998141126707e-05, 2031
[INFO] 2021-07-12 19:12:47,947 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2031
[INFO] 2021-07-12 19:12:47,947 [run_pretraining.py:  558]:	worker_index: 6, step: 2031, cost: 7.183147, mlm loss: 7.183147, speed: 1.056909 steps/s, speed: 8.455269 samples/s, speed: 4329.097904 tokens/s, learning rate: 2.030e-05, loss_scalings: 3518.437988, pp_loss: 7.326694
[INFO] 2021-07-12 19:12:47,947 [run_pretraining.py:  512]:	********exe.run_2031******* 
[INFO] 2021-07-12 19:12:48,909 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:48,909 [run_pretraining.py:  534]:	loss/total_loss, 7.020910739898682, 2032
[INFO] 2021-07-12 19:12:48,909 [run_pretraining.py:  535]:	loss/mlm_loss, 7.020910739898682, 2032
[INFO] 2021-07-12 19:12:48,909 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0309998944867402e-05, 2032
[INFO] 2021-07-12 19:12:48,910 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2032
[INFO] 2021-07-12 19:12:48,910 [run_pretraining.py:  558]:	worker_index: 6, step: 2032, cost: 7.020911, mlm loss: 7.020911, speed: 1.039171 steps/s, speed: 8.313368 samples/s, speed: 4256.444346 tokens/s, learning rate: 2.031e-05, loss_scalings: 3518.437988, pp_loss: 7.210452
[INFO] 2021-07-12 19:12:48,910 [run_pretraining.py:  512]:	********exe.run_2032******* 
[INFO] 2021-07-12 19:13:15,571 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:15,572 [run_pretraining.py:  534]:	loss/total_loss, 7.520384788513184, 2033
[INFO] 2021-07-12 19:13:15,572 [run_pretraining.py:  535]:	loss/mlm_loss, 7.520384788513184, 2033
[INFO] 2021-07-12 19:13:15,572 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0319999748608097e-05, 2033
[INFO] 2021-07-12 19:13:15,572 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2033
[INFO] 2021-07-12 19:13:15,572 [run_pretraining.py:  558]:	worker_index: 6, step: 2033, cost: 7.520385, mlm loss: 7.520385, speed: 0.037507 steps/s, speed: 0.300053 samples/s, speed: 153.627197 tokens/s, learning rate: 2.032e-05, loss_scalings: 3518.437988, pp_loss: 7.521002
[INFO] 2021-07-12 19:13:15,572 [run_pretraining.py:  512]:	********exe.run_2033******* 
[INFO] 2021-07-12 19:13:41,710 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:41,711 [run_pretraining.py:  534]:	loss/total_loss, 7.615939617156982, 2034
[INFO] 2021-07-12 19:13:41,711 [run_pretraining.py:  535]:	loss/mlm_loss, 7.615939617156982, 2034
[INFO] 2021-07-12 19:13:41,711 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.032999873335939e-05, 2034
[INFO] 2021-07-12 19:13:41,711 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2034
[INFO] 2021-07-12 19:13:41,711 [run_pretraining.py:  558]:	worker_index: 6, step: 2034, cost: 7.615940, mlm loss: 7.615940, speed: 0.038258 steps/s, speed: 0.306066 samples/s, speed: 156.705763 tokens/s, learning rate: 2.033e-05, loss_scalings: 3518.437988, pp_loss: 7.395040
[INFO] 2021-07-12 19:13:41,711 [run_pretraining.py:  512]:	********exe.run_2034******* 
[INFO] 2021-07-12 19:13:42,622 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:42,622 [run_pretraining.py:  534]:	loss/total_loss, 7.489735126495361, 2035
[INFO] 2021-07-12 19:13:42,622 [run_pretraining.py:  535]:	loss/mlm_loss, 7.489735126495361, 2035
[INFO] 2021-07-12 19:13:42,623 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0339999537100084e-05, 2035
[INFO] 2021-07-12 19:13:42,623 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2035
[INFO] 2021-07-12 19:13:42,623 [run_pretraining.py:  558]:	worker_index: 6, step: 2035, cost: 7.489735, mlm loss: 7.489735, speed: 1.097886 steps/s, speed: 8.783089 samples/s, speed: 4496.941817 tokens/s, learning rate: 2.034e-05, loss_scalings: 3518.437988, pp_loss: 7.430985
[INFO] 2021-07-12 19:13:42,623 [run_pretraining.py:  512]:	********exe.run_2035******* 
[INFO] 2021-07-12 19:13:43,570 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:43,571 [run_pretraining.py:  534]:	loss/total_loss, 6.954737186431885, 2036
[INFO] 2021-07-12 19:13:43,571 [run_pretraining.py:  535]:	loss/mlm_loss, 6.954737186431885, 2036
[INFO] 2021-07-12 19:13:43,571 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.035000034084078e-05, 2036
[INFO] 2021-07-12 19:13:43,571 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2036
[INFO] 2021-07-12 19:13:43,571 [run_pretraining.py:  558]:	worker_index: 6, step: 2036, cost: 6.954737, mlm loss: 6.954737, speed: 1.055510 steps/s, speed: 8.444084 samples/s, speed: 4323.370761 tokens/s, learning rate: 2.035e-05, loss_scalings: 3518.437988, pp_loss: 6.989102
[INFO] 2021-07-12 19:13:43,571 [run_pretraining.py:  512]:	********exe.run_2036******* 
[INFO] 2021-07-12 19:13:44,492 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:44,492 [run_pretraining.py:  534]:	loss/total_loss, 6.880528450012207, 2037
[INFO] 2021-07-12 19:13:44,493 [run_pretraining.py:  535]:	loss/mlm_loss, 6.880528450012207, 2037
[INFO] 2021-07-12 19:13:44,493 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.035999932559207e-05, 2037
[INFO] 2021-07-12 19:13:44,493 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2037
[INFO] 2021-07-12 19:13:44,493 [run_pretraining.py:  558]:	worker_index: 6, step: 2037, cost: 6.880528, mlm loss: 6.880528, speed: 1.085495 steps/s, speed: 8.683958 samples/s, speed: 4446.186547 tokens/s, learning rate: 2.036e-05, loss_scalings: 3518.437988, pp_loss: 7.357205
[INFO] 2021-07-12 19:13:44,493 [run_pretraining.py:  512]:	********exe.run_2037******* 
[INFO] 2021-07-12 19:13:45,433 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:45,434 [run_pretraining.py:  534]:	loss/total_loss, 7.031243324279785, 2038
[INFO] 2021-07-12 19:13:45,434 [run_pretraining.py:  535]:	loss/mlm_loss, 7.031243324279785, 2038
[INFO] 2021-07-12 19:13:45,434 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0370000129332766e-05, 2038
[INFO] 2021-07-12 19:13:45,434 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2038
[INFO] 2021-07-12 19:13:45,434 [run_pretraining.py:  558]:	worker_index: 6, step: 2038, cost: 7.031243, mlm loss: 7.031243, speed: 1.062785 steps/s, speed: 8.502284 samples/s, speed: 4353.169168 tokens/s, learning rate: 2.037e-05, loss_scalings: 3518.437988, pp_loss: 7.106812
[INFO] 2021-07-12 19:13:45,435 [run_pretraining.py:  512]:	********exe.run_2038******* 
[INFO] 2021-07-12 19:13:46,374 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:46,375 [run_pretraining.py:  534]:	loss/total_loss, 7.542562007904053, 2039
[INFO] 2021-07-12 19:13:46,375 [run_pretraining.py:  535]:	loss/mlm_loss, 7.542562007904053, 2039
[INFO] 2021-07-12 19:13:46,375 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0379999114084058e-05, 2039
[INFO] 2021-07-12 19:13:46,375 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2039
[INFO] 2021-07-12 19:13:46,375 [run_pretraining.py:  558]:	worker_index: 6, step: 2039, cost: 7.542562, mlm loss: 7.542562, speed: 1.064043 steps/s, speed: 8.512346 samples/s, speed: 4358.320939 tokens/s, learning rate: 2.038e-05, loss_scalings: 3518.437988, pp_loss: 7.234049
[INFO] 2021-07-12 19:13:46,375 [run_pretraining.py:  512]:	********exe.run_2039******* 
[INFO] 2021-07-12 19:13:47,303 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:47,303 [run_pretraining.py:  534]:	loss/total_loss, 6.83425235748291, 2040
[INFO] 2021-07-12 19:13:47,304 [run_pretraining.py:  535]:	loss/mlm_loss, 6.83425235748291, 2040
[INFO] 2021-07-12 19:13:47,304 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.038999809883535e-05, 2040
[INFO] 2021-07-12 19:13:47,304 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2040
[INFO] 2021-07-12 19:13:47,304 [run_pretraining.py:  558]:	worker_index: 6, step: 2040, cost: 6.834252, mlm loss: 6.834252, speed: 1.077440 steps/s, speed: 8.619521 samples/s, speed: 4413.194572 tokens/s, learning rate: 2.039e-05, loss_scalings: 3518.437988, pp_loss: 7.309497
[INFO] 2021-07-12 19:13:47,304 [run_pretraining.py:  512]:	********exe.run_2040******* 
[INFO] 2021-07-12 19:13:48,222 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:48,222 [run_pretraining.py:  534]:	loss/total_loss, 6.8469319343566895, 2041
[INFO] 2021-07-12 19:13:48,222 [run_pretraining.py:  535]:	loss/mlm_loss, 6.8469319343566895, 2041
[INFO] 2021-07-12 19:13:48,223 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0399998902576044e-05, 2041
[INFO] 2021-07-12 19:13:48,223 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2041
[INFO] 2021-07-12 19:13:48,223 [run_pretraining.py:  558]:	worker_index: 6, step: 2041, cost: 6.846932, mlm loss: 6.846932, speed: 1.089128 steps/s, speed: 8.713024 samples/s, speed: 4461.068490 tokens/s, learning rate: 2.040e-05, loss_scalings: 3518.437988, pp_loss: 6.332195
[INFO] 2021-07-12 19:13:48,223 [run_pretraining.py:  512]:	********exe.run_2041******* 
[INFO] 2021-07-12 19:13:49,135 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:49,136 [run_pretraining.py:  534]:	loss/total_loss, 7.699743270874023, 2042
[INFO] 2021-07-12 19:13:49,136 [run_pretraining.py:  535]:	loss/mlm_loss, 7.699743270874023, 2042
[INFO] 2021-07-12 19:13:49,136 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.040999970631674e-05, 2042
[INFO] 2021-07-12 19:13:49,136 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2042
[INFO] 2021-07-12 19:13:49,136 [run_pretraining.py:  558]:	worker_index: 6, step: 2042, cost: 7.699743, mlm loss: 7.699743, speed: 1.095346 steps/s, speed: 8.762769 samples/s, speed: 4486.537981 tokens/s, learning rate: 2.041e-05, loss_scalings: 3518.437988, pp_loss: 7.500328
[INFO] 2021-07-12 19:13:49,136 [run_pretraining.py:  512]:	********exe.run_2042******* 
[INFO] 2021-07-12 19:13:50,061 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:50,062 [run_pretraining.py:  534]:	loss/total_loss, 7.246488094329834, 2043
[INFO] 2021-07-12 19:13:50,062 [run_pretraining.py:  535]:	loss/mlm_loss, 7.246488094329834, 2043
[INFO] 2021-07-12 19:13:50,062 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.041999869106803e-05, 2043
[INFO] 2021-07-12 19:13:50,062 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2043
[INFO] 2021-07-12 19:13:50,062 [run_pretraining.py:  558]:	worker_index: 6, step: 2043, cost: 7.246488, mlm loss: 7.246488, speed: 1.081123 steps/s, speed: 8.648981 samples/s, speed: 4428.278403 tokens/s, learning rate: 2.042e-05, loss_scalings: 3518.437988, pp_loss: 7.513869
[INFO] 2021-07-12 19:13:50,062 [run_pretraining.py:  512]:	********exe.run_2043******* 
[INFO] 2021-07-12 19:13:50,978 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:50,979 [run_pretraining.py:  534]:	loss/total_loss, 8.240968704223633, 2044
[INFO] 2021-07-12 19:13:50,979 [run_pretraining.py:  535]:	loss/mlm_loss, 8.240968704223633, 2044
[INFO] 2021-07-12 19:13:50,979 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0429999494808726e-05, 2044
[INFO] 2021-07-12 19:13:50,979 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2044
[INFO] 2021-07-12 19:13:50,979 [run_pretraining.py:  558]:	worker_index: 6, step: 2044, cost: 8.240969, mlm loss: 8.240969, speed: 1.091204 steps/s, speed: 8.729629 samples/s, speed: 4469.569928 tokens/s, learning rate: 2.043e-05, loss_scalings: 3518.437988, pp_loss: 7.603436
[INFO] 2021-07-12 19:13:50,979 [run_pretraining.py:  512]:	********exe.run_2044******* 
[INFO] 2021-07-12 19:13:51,908 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:51,908 [run_pretraining.py:  534]:	loss/total_loss, 7.21324348449707, 2045
[INFO] 2021-07-12 19:13:51,909 [run_pretraining.py:  535]:	loss/mlm_loss, 7.21324348449707, 2045
[INFO] 2021-07-12 19:13:51,909 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.044000029854942e-05, 2045
[INFO] 2021-07-12 19:13:51,909 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2045
[INFO] 2021-07-12 19:13:51,909 [run_pretraining.py:  558]:	worker_index: 6, step: 2045, cost: 7.213243, mlm loss: 7.213243, speed: 1.076489 steps/s, speed: 8.611913 samples/s, speed: 4409.299325 tokens/s, learning rate: 2.044e-05, loss_scalings: 3518.437988, pp_loss: 7.067839
[INFO] 2021-07-12 19:13:51,909 [run_pretraining.py:  512]:	********exe.run_2045******* 
[INFO] 2021-07-12 19:13:52,829 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:52,830 [run_pretraining.py:  534]:	loss/total_loss, 7.520205974578857, 2046
[INFO] 2021-07-12 19:13:52,830 [run_pretraining.py:  535]:	loss/mlm_loss, 7.520205974578857, 2046
[INFO] 2021-07-12 19:13:52,830 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0449999283300713e-05, 2046
[INFO] 2021-07-12 19:13:52,830 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2046
[INFO] 2021-07-12 19:13:52,830 [run_pretraining.py:  558]:	worker_index: 6, step: 2046, cost: 7.520206, mlm loss: 7.520206, speed: 1.086065 steps/s, speed: 8.688521 samples/s, speed: 4448.522508 tokens/s, learning rate: 2.045e-05, loss_scalings: 3518.437988, pp_loss: 6.701538
[INFO] 2021-07-12 19:13:52,830 [run_pretraining.py:  512]:	********exe.run_2046******* 
[INFO] 2021-07-12 19:13:53,783 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:53,784 [run_pretraining.py:  534]:	loss/total_loss, 7.580323219299316, 2047
[INFO] 2021-07-12 19:13:53,784 [run_pretraining.py:  535]:	loss/mlm_loss, 7.580323219299316, 2047
[INFO] 2021-07-12 19:13:53,784 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0460000087041408e-05, 2047
[INFO] 2021-07-12 19:13:53,784 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2047
[INFO] 2021-07-12 19:13:53,784 [run_pretraining.py:  558]:	worker_index: 6, step: 2047, cost: 7.580323, mlm loss: 7.580323, speed: 1.049110 steps/s, speed: 8.392882 samples/s, speed: 4297.155623 tokens/s, learning rate: 2.046e-05, loss_scalings: 3518.437988, pp_loss: 7.415202
[INFO] 2021-07-12 19:13:53,784 [run_pretraining.py:  512]:	********exe.run_2047******* 
[INFO] 2021-07-12 19:13:54,716 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:54,716 [run_pretraining.py:  534]:	loss/total_loss, 7.516724586486816, 2048
[INFO] 2021-07-12 19:13:54,716 [run_pretraining.py:  535]:	loss/mlm_loss, 7.516724586486816, 2048
[INFO] 2021-07-12 19:13:54,716 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.04699990717927e-05, 2048
[INFO] 2021-07-12 19:13:54,717 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2048
[INFO] 2021-07-12 19:13:54,717 [run_pretraining.py:  558]:	worker_index: 6, step: 2048, cost: 7.516725, mlm loss: 7.516725, speed: 1.073202 steps/s, speed: 8.585616 samples/s, speed: 4395.835230 tokens/s, learning rate: 2.047e-05, loss_scalings: 3518.437988, pp_loss: 7.270061
[INFO] 2021-07-12 19:13:54,717 [run_pretraining.py:  512]:	********exe.run_2048******* 
[INFO] 2021-07-12 19:13:55,646 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:55,647 [run_pretraining.py:  534]:	loss/total_loss, 6.886960506439209, 2049
[INFO] 2021-07-12 19:13:55,647 [run_pretraining.py:  535]:	loss/mlm_loss, 6.886960506439209, 2049
[INFO] 2021-07-12 19:13:55,647 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.047999805654399e-05, 2049
[INFO] 2021-07-12 19:13:55,647 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2049
[INFO] 2021-07-12 19:13:55,647 [run_pretraining.py:  558]:	worker_index: 6, step: 2049, cost: 6.886961, mlm loss: 6.886961, speed: 1.075804 steps/s, speed: 8.606428 samples/s, speed: 4406.491181 tokens/s, learning rate: 2.048e-05, loss_scalings: 3518.437988, pp_loss: 7.154656
[INFO] 2021-07-12 19:13:55,647 [run_pretraining.py:  512]:	********exe.run_2049******* 
[INFO] 2021-07-12 19:13:56,589 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:56,590 [run_pretraining.py:  534]:	loss/total_loss, 6.311339378356934, 2050
[INFO] 2021-07-12 19:13:56,590 [run_pretraining.py:  535]:	loss/mlm_loss, 6.311339378356934, 2050
[INFO] 2021-07-12 19:13:56,590 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0489998860284686e-05, 2050
[INFO] 2021-07-12 19:13:56,590 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2050
[INFO] 2021-07-12 19:13:56,590 [run_pretraining.py:  558]:	worker_index: 6, step: 2050, cost: 6.311339, mlm loss: 6.311339, speed: 1.060616 steps/s, speed: 8.484929 samples/s, speed: 4344.283603 tokens/s, learning rate: 2.049e-05, loss_scalings: 3518.437988, pp_loss: 7.209900
[INFO] 2021-07-12 19:13:56,591 [run_pretraining.py:  512]:	********exe.run_2050******* 
[INFO] 2021-07-12 19:13:57,539 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:57,539 [run_pretraining.py:  534]:	loss/total_loss, 8.584301948547363, 2051
[INFO] 2021-07-12 19:13:57,540 [run_pretraining.py:  535]:	loss/mlm_loss, 8.584301948547363, 2051
[INFO] 2021-07-12 19:13:57,540 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.049999966402538e-05, 2051
[INFO] 2021-07-12 19:13:57,540 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2051
[INFO] 2021-07-12 19:13:57,540 [run_pretraining.py:  558]:	worker_index: 6, step: 2051, cost: 8.584302, mlm loss: 8.584302, speed: 1.054122 steps/s, speed: 8.432976 samples/s, speed: 4317.683709 tokens/s, learning rate: 2.050e-05, loss_scalings: 3518.437988, pp_loss: 7.584620
[INFO] 2021-07-12 19:13:57,540 [run_pretraining.py:  512]:	********exe.run_2051******* 
[INFO] 2021-07-12 19:13:58,498 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:58,498 [run_pretraining.py:  534]:	loss/total_loss, 7.520608901977539, 2052
[INFO] 2021-07-12 19:13:58,499 [run_pretraining.py:  535]:	loss/mlm_loss, 7.520608901977539, 2052
[INFO] 2021-07-12 19:13:58,499 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0509998648776673e-05, 2052
[INFO] 2021-07-12 19:13:58,499 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2052
[INFO] 2021-07-12 19:13:58,499 [run_pretraining.py:  558]:	worker_index: 6, step: 2052, cost: 7.520609, mlm loss: 7.520609, speed: 1.043562 steps/s, speed: 8.348500 samples/s, speed: 4274.431857 tokens/s, learning rate: 2.051e-05, loss_scalings: 3518.437988, pp_loss: 7.456791
[INFO] 2021-07-12 19:13:58,499 [run_pretraining.py:  512]:	********exe.run_2052******* 
[INFO] 2021-07-12 19:13:59,430 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:59,431 [run_pretraining.py:  534]:	loss/total_loss, 6.764621734619141, 2053
[INFO] 2021-07-12 19:13:59,431 [run_pretraining.py:  535]:	loss/mlm_loss, 6.764621734619141, 2053
[INFO] 2021-07-12 19:13:59,431 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0519999452517368e-05, 2053
[INFO] 2021-07-12 19:13:59,431 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2053
[INFO] 2021-07-12 19:13:59,431 [run_pretraining.py:  558]:	worker_index: 6, step: 2053, cost: 6.764622, mlm loss: 6.764622, speed: 1.072993 steps/s, speed: 8.583946 samples/s, speed: 4394.980573 tokens/s, learning rate: 2.052e-05, loss_scalings: 3518.437988, pp_loss: 7.926002
[INFO] 2021-07-12 19:13:59,432 [run_pretraining.py:  512]:	********exe.run_2053******* 
[INFO] 2021-07-12 19:14:00,388 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:00,388 [run_pretraining.py:  534]:	loss/total_loss, 7.38068962097168, 2054
[INFO] 2021-07-12 19:14:00,388 [run_pretraining.py:  535]:	loss/mlm_loss, 7.38068962097168, 2054
[INFO] 2021-07-12 19:14:00,389 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0530000256258063e-05, 2054
[INFO] 2021-07-12 19:14:00,389 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2054
[INFO] 2021-07-12 19:14:00,389 [run_pretraining.py:  558]:	worker_index: 6, step: 2054, cost: 7.380690, mlm loss: 7.380690, speed: 1.045463 steps/s, speed: 8.363707 samples/s, speed: 4282.218062 tokens/s, learning rate: 2.053e-05, loss_scalings: 3518.437988, pp_loss: 7.269515
[INFO] 2021-07-12 19:14:00,389 [run_pretraining.py:  512]:	********exe.run_2054******* 
[INFO] 2021-07-12 19:14:01,332 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:01,333 [run_pretraining.py:  534]:	loss/total_loss, 7.19352912902832, 2055
[INFO] 2021-07-12 19:14:01,333 [run_pretraining.py:  535]:	loss/mlm_loss, 7.19352912902832, 2055
[INFO] 2021-07-12 19:14:01,333 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0539999241009355e-05, 2055
[INFO] 2021-07-12 19:14:01,333 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2055
[INFO] 2021-07-12 19:14:01,333 [run_pretraining.py:  558]:	worker_index: 6, step: 2055, cost: 7.193529, mlm loss: 7.193529, speed: 1.059823 steps/s, speed: 8.478583 samples/s, speed: 4341.034353 tokens/s, learning rate: 2.054e-05, loss_scalings: 3518.437988, pp_loss: 7.011440
[INFO] 2021-07-12 19:14:01,333 [run_pretraining.py:  512]:	********exe.run_2055******* 
[INFO] 2021-07-12 19:14:02,279 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:02,280 [run_pretraining.py:  534]:	loss/total_loss, 7.266378879547119, 2056
[INFO] 2021-07-12 19:14:02,280 [run_pretraining.py:  535]:	loss/mlm_loss, 7.266378879547119, 2056
[INFO] 2021-07-12 19:14:02,280 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.055000004475005e-05, 2056
[INFO] 2021-07-12 19:14:02,280 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2056
[INFO] 2021-07-12 19:14:02,280 [run_pretraining.py:  558]:	worker_index: 6, step: 2056, cost: 7.266379, mlm loss: 7.266379, speed: 1.056319 steps/s, speed: 8.450553 samples/s, speed: 4326.682964 tokens/s, learning rate: 2.055e-05, loss_scalings: 3518.437988, pp_loss: 7.272788
[INFO] 2021-07-12 19:14:02,280 [run_pretraining.py:  512]:	********exe.run_2056******* 
[INFO] 2021-07-12 19:14:03,219 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:03,219 [run_pretraining.py:  534]:	loss/total_loss, 7.48552942276001, 2057
[INFO] 2021-07-12 19:14:03,220 [run_pretraining.py:  535]:	loss/mlm_loss, 7.48552942276001, 2057
[INFO] 2021-07-12 19:14:03,220 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.055999902950134e-05, 2057
[INFO] 2021-07-12 19:14:03,220 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2057
[INFO] 2021-07-12 19:14:03,220 [run_pretraining.py:  558]:	worker_index: 6, step: 2057, cost: 7.485529, mlm loss: 7.485529, speed: 1.065238 steps/s, speed: 8.521908 samples/s, speed: 4363.216732 tokens/s, learning rate: 2.056e-05, loss_scalings: 3518.437988, pp_loss: 7.610595
[INFO] 2021-07-12 19:14:03,220 [run_pretraining.py:  512]:	********exe.run_2057******* 
[INFO] 2021-07-12 19:14:04,166 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:04,167 [run_pretraining.py:  534]:	loss/total_loss, 7.559073448181152, 2058
[INFO] 2021-07-12 19:14:04,167 [run_pretraining.py:  535]:	loss/mlm_loss, 7.559073448181152, 2058
[INFO] 2021-07-12 19:14:04,167 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0569999833242036e-05, 2058
[INFO] 2021-07-12 19:14:04,167 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2058
[INFO] 2021-07-12 19:14:04,167 [run_pretraining.py:  558]:	worker_index: 6, step: 2058, cost: 7.559073, mlm loss: 7.559073, speed: 1.056375 steps/s, speed: 8.451002 samples/s, speed: 4326.912894 tokens/s, learning rate: 2.057e-05, loss_scalings: 3518.437988, pp_loss: 7.175815
[INFO] 2021-07-12 19:14:04,167 [run_pretraining.py:  512]:	********exe.run_2058******* 
[INFO] 2021-07-12 19:14:05,110 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:05,111 [run_pretraining.py:  534]:	loss/total_loss, 7.664041042327881, 2059
[INFO] 2021-07-12 19:14:05,111 [run_pretraining.py:  535]:	loss/mlm_loss, 7.664041042327881, 2059
[INFO] 2021-07-12 19:14:05,111 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0579998817993328e-05, 2059
[INFO] 2021-07-12 19:14:05,111 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2059
[INFO] 2021-07-12 19:14:05,111 [run_pretraining.py:  558]:	worker_index: 6, step: 2059, cost: 7.664041, mlm loss: 7.664041, speed: 1.059778 steps/s, speed: 8.478227 samples/s, speed: 4340.852275 tokens/s, learning rate: 2.058e-05, loss_scalings: 3518.437988, pp_loss: 7.141334
[INFO] 2021-07-12 19:14:05,112 [run_pretraining.py:  512]:	********exe.run_2059******* 
[INFO] 2021-07-12 19:14:06,048 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:06,048 [run_pretraining.py:  534]:	loss/total_loss, 8.012052536010742, 2060
[INFO] 2021-07-12 19:14:06,049 [run_pretraining.py:  535]:	loss/mlm_loss, 8.012052536010742, 2060
[INFO] 2021-07-12 19:14:06,049 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0589999621734023e-05, 2060
[INFO] 2021-07-12 19:14:06,049 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2060
[INFO] 2021-07-12 19:14:06,049 [run_pretraining.py:  558]:	worker_index: 6, step: 2060, cost: 8.012053, mlm loss: 8.012053, speed: 1.067646 steps/s, speed: 8.541168 samples/s, speed: 4373.078124 tokens/s, learning rate: 2.059e-05, loss_scalings: 3518.437988, pp_loss: 7.329380
[INFO] 2021-07-12 19:14:06,049 [run_pretraining.py:  512]:	********exe.run_2060******* 
[INFO] 2021-07-12 19:14:06,995 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:06,995 [run_pretraining.py:  534]:	loss/total_loss, 7.455378532409668, 2061
[INFO] 2021-07-12 19:14:06,995 [run_pretraining.py:  535]:	loss/mlm_loss, 7.455378532409668, 2061
[INFO] 2021-07-12 19:14:06,996 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0599998606485315e-05, 2061
[INFO] 2021-07-12 19:14:06,996 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2061
[INFO] 2021-07-12 19:14:06,996 [run_pretraining.py:  558]:	worker_index: 6, step: 2061, cost: 7.455379, mlm loss: 7.455379, speed: 1.056870 steps/s, speed: 8.454960 samples/s, speed: 4328.939733 tokens/s, learning rate: 2.060e-05, loss_scalings: 3518.437988, pp_loss: 7.297218
[INFO] 2021-07-12 19:14:06,996 [run_pretraining.py:  512]:	********exe.run_2061******* 
[INFO] 2021-07-12 19:14:07,934 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:07,935 [run_pretraining.py:  534]:	loss/total_loss, 8.378276824951172, 2062
[INFO] 2021-07-12 19:14:07,935 [run_pretraining.py:  535]:	loss/mlm_loss, 8.378276824951172, 2062
[INFO] 2021-07-12 19:14:07,935 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.060999941022601e-05, 2062
[INFO] 2021-07-12 19:14:07,935 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2062
[INFO] 2021-07-12 19:14:07,935 [run_pretraining.py:  558]:	worker_index: 6, step: 2062, cost: 8.378277, mlm loss: 8.378277, speed: 1.064975 steps/s, speed: 8.519798 samples/s, speed: 4362.136565 tokens/s, learning rate: 2.061e-05, loss_scalings: 3518.437988, pp_loss: 7.744948
[INFO] 2021-07-12 19:14:07,936 [run_pretraining.py:  512]:	********exe.run_2062******* 
[INFO] 2021-07-12 19:14:08,875 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:08,875 [run_pretraining.py:  534]:	loss/total_loss, 6.935917854309082, 2063
[INFO] 2021-07-12 19:14:08,875 [run_pretraining.py:  535]:	loss/mlm_loss, 6.935917854309082, 2063
[INFO] 2021-07-12 19:14:08,875 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0620000213966705e-05, 2063
[INFO] 2021-07-12 19:14:08,876 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2063
[INFO] 2021-07-12 19:14:08,876 [run_pretraining.py:  558]:	worker_index: 6, step: 2063, cost: 6.935918, mlm loss: 6.935918, speed: 1.064466 steps/s, speed: 8.515731 samples/s, speed: 4360.054185 tokens/s, learning rate: 2.062e-05, loss_scalings: 3518.437988, pp_loss: 7.175978
[INFO] 2021-07-12 19:14:08,876 [run_pretraining.py:  512]:	********exe.run_2063******* 
[INFO] 2021-07-12 19:14:09,824 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:09,825 [run_pretraining.py:  534]:	loss/total_loss, 7.414668560028076, 2064
[INFO] 2021-07-12 19:14:09,825 [run_pretraining.py:  535]:	loss/mlm_loss, 7.414668560028076, 2064
[INFO] 2021-07-12 19:14:09,825 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0629999198717996e-05, 2064
[INFO] 2021-07-12 19:14:09,825 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2064
[INFO] 2021-07-12 19:14:09,825 [run_pretraining.py:  558]:	worker_index: 6, step: 2064, cost: 7.414669, mlm loss: 7.414669, speed: 1.054077 steps/s, speed: 8.432614 samples/s, speed: 4317.498160 tokens/s, learning rate: 2.063e-05, loss_scalings: 3518.437988, pp_loss: 7.539143
[INFO] 2021-07-12 19:14:09,825 [run_pretraining.py:  512]:	********exe.run_2064******* 
[INFO] 2021-07-12 19:14:10,764 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:10,764 [run_pretraining.py:  534]:	loss/total_loss, 7.01535177230835, 2065
[INFO] 2021-07-12 19:14:10,765 [run_pretraining.py:  535]:	loss/mlm_loss, 7.01535177230835, 2065
[INFO] 2021-07-12 19:14:10,765 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.064000000245869e-05, 2065
[INFO] 2021-07-12 19:14:10,765 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2065
[INFO] 2021-07-12 19:14:10,765 [run_pretraining.py:  558]:	worker_index: 6, step: 2065, cost: 7.015352, mlm loss: 7.015352, speed: 1.064911 steps/s, speed: 8.519292 samples/s, speed: 4361.877405 tokens/s, learning rate: 2.064e-05, loss_scalings: 3518.437988, pp_loss: 7.061688
[INFO] 2021-07-12 19:14:10,765 [run_pretraining.py:  512]:	********exe.run_2065******* 
[INFO] 2021-07-12 19:14:11,699 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:11,700 [run_pretraining.py:  534]:	loss/total_loss, 7.74443244934082, 2066
[INFO] 2021-07-12 19:14:11,700 [run_pretraining.py:  535]:	loss/mlm_loss, 7.74443244934082, 2066
[INFO] 2021-07-12 19:14:11,700 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0649998987209983e-05, 2066
[INFO] 2021-07-12 19:14:11,700 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2066
[INFO] 2021-07-12 19:14:11,700 [run_pretraining.py:  558]:	worker_index: 6, step: 2066, cost: 7.744432, mlm loss: 7.744432, speed: 1.069724 steps/s, speed: 8.557793 samples/s, speed: 4381.590240 tokens/s, learning rate: 2.065e-05, loss_scalings: 3518.437988, pp_loss: 7.258920
[INFO] 2021-07-12 19:14:11,700 [run_pretraining.py:  512]:	********exe.run_2066******* 
[INFO] 2021-07-12 19:14:12,636 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:12,637 [run_pretraining.py:  534]:	loss/total_loss, 7.240732192993164, 2067
[INFO] 2021-07-12 19:14:12,637 [run_pretraining.py:  535]:	loss/mlm_loss, 7.240732192993164, 2067
[INFO] 2021-07-12 19:14:12,637 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0659999790950678e-05, 2067
[INFO] 2021-07-12 19:14:12,637 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2067
[INFO] 2021-07-12 19:14:12,637 [run_pretraining.py:  558]:	worker_index: 6, step: 2067, cost: 7.240732, mlm loss: 7.240732, speed: 1.068528 steps/s, speed: 8.548220 samples/s, speed: 4376.688830 tokens/s, learning rate: 2.066e-05, loss_scalings: 3518.437988, pp_loss: 7.325836
[INFO] 2021-07-12 19:14:12,637 [run_pretraining.py:  512]:	********exe.run_2067******* 
[INFO] 2021-07-12 19:14:13,572 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:13,573 [run_pretraining.py:  534]:	loss/total_loss, 7.708812236785889, 2068
[INFO] 2021-07-12 19:14:13,573 [run_pretraining.py:  535]:	loss/mlm_loss, 7.708812236785889, 2068
[INFO] 2021-07-12 19:14:13,573 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.066999877570197e-05, 2068
[INFO] 2021-07-12 19:14:13,573 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2068
[INFO] 2021-07-12 19:14:13,573 [run_pretraining.py:  558]:	worker_index: 6, step: 2068, cost: 7.708812, mlm loss: 7.708812, speed: 1.068828 steps/s, speed: 8.550621 samples/s, speed: 4377.917895 tokens/s, learning rate: 2.067e-05, loss_scalings: 3518.437988, pp_loss: 7.276205
[INFO] 2021-07-12 19:14:13,573 [run_pretraining.py:  512]:	********exe.run_2068******* 
[INFO] 2021-07-12 19:14:14,498 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:14,498 [run_pretraining.py:  534]:	loss/total_loss, 6.507373809814453, 2069
[INFO] 2021-07-12 19:14:14,498 [run_pretraining.py:  535]:	loss/mlm_loss, 6.507373809814453, 2069
[INFO] 2021-07-12 19:14:14,499 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0679999579442665e-05, 2069
[INFO] 2021-07-12 19:14:14,499 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2069
[INFO] 2021-07-12 19:14:14,499 [run_pretraining.py:  558]:	worker_index: 6, step: 2069, cost: 6.507374, mlm loss: 6.507374, speed: 1.081268 steps/s, speed: 8.650141 samples/s, speed: 4428.872027 tokens/s, learning rate: 2.068e-05, loss_scalings: 3518.437988, pp_loss: 7.256642
[INFO] 2021-07-12 19:14:14,499 [run_pretraining.py:  512]:	********exe.run_2069******* 
[INFO] 2021-07-12 19:14:15,445 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:15,446 [run_pretraining.py:  534]:	loss/total_loss, 7.980147361755371, 2070
[INFO] 2021-07-12 19:14:15,446 [run_pretraining.py:  535]:	loss/mlm_loss, 7.980147361755371, 2070
[INFO] 2021-07-12 19:14:15,446 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.069000038318336e-05, 2070
[INFO] 2021-07-12 19:14:15,446 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2070
[INFO] 2021-07-12 19:14:15,446 [run_pretraining.py:  558]:	worker_index: 6, step: 2070, cost: 7.980147, mlm loss: 7.980147, speed: 1.056420 steps/s, speed: 8.451357 samples/s, speed: 4327.094894 tokens/s, learning rate: 2.069e-05, loss_scalings: 3518.437988, pp_loss: 7.413131
[INFO] 2021-07-12 19:14:15,446 [run_pretraining.py:  512]:	********exe.run_2070******* 
[INFO] 2021-07-12 19:14:16,370 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:16,371 [run_pretraining.py:  534]:	loss/total_loss, 7.255528450012207, 2071
[INFO] 2021-07-12 19:14:16,371 [run_pretraining.py:  535]:	loss/mlm_loss, 7.255528450012207, 2071
[INFO] 2021-07-12 19:14:16,371 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.069999936793465e-05, 2071
[INFO] 2021-07-12 19:14:16,371 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2071
[INFO] 2021-07-12 19:14:16,371 [run_pretraining.py:  558]:	worker_index: 6, step: 2071, cost: 7.255528, mlm loss: 7.255528, speed: 1.081535 steps/s, speed: 8.652282 samples/s, speed: 4429.968367 tokens/s, learning rate: 2.070e-05, loss_scalings: 3518.437988, pp_loss: 7.408859
[INFO] 2021-07-12 19:14:16,371 [run_pretraining.py:  512]:	********exe.run_2071******* 
[INFO] 2021-07-12 19:14:17,307 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:17,307 [run_pretraining.py:  534]:	loss/total_loss, 6.826015949249268, 2072
[INFO] 2021-07-12 19:14:17,307 [run_pretraining.py:  535]:	loss/mlm_loss, 6.826015949249268, 2072
[INFO] 2021-07-12 19:14:17,307 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0710000171675347e-05, 2072
[INFO] 2021-07-12 19:14:17,308 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2072
[INFO] 2021-07-12 19:14:17,308 [run_pretraining.py:  558]:	worker_index: 6, step: 2072, cost: 6.826016, mlm loss: 6.826016, speed: 1.068976 steps/s, speed: 8.551806 samples/s, speed: 4378.524875 tokens/s, learning rate: 2.071e-05, loss_scalings: 3518.437988, pp_loss: 7.202956
[INFO] 2021-07-12 19:14:17,308 [run_pretraining.py:  512]:	********exe.run_2072******* 
[INFO] 2021-07-12 19:14:18,229 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:18,230 [run_pretraining.py:  534]:	loss/total_loss, 8.578252792358398, 2073
[INFO] 2021-07-12 19:14:18,230 [run_pretraining.py:  535]:	loss/mlm_loss, 8.578252792358398, 2073
[INFO] 2021-07-12 19:14:18,230 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.071999915642664e-05, 2073
[INFO] 2021-07-12 19:14:18,230 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2073
[INFO] 2021-07-12 19:14:18,230 [run_pretraining.py:  558]:	worker_index: 6, step: 2073, cost: 8.578253, mlm loss: 8.578253, speed: 1.084657 steps/s, speed: 8.677255 samples/s, speed: 4442.754411 tokens/s, learning rate: 2.072e-05, loss_scalings: 3518.437988, pp_loss: 7.446505
[INFO] 2021-07-12 19:14:18,230 [run_pretraining.py:  512]:	********exe.run_2073******* 
[INFO] 2021-07-12 19:14:19,164 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:19,165 [run_pretraining.py:  534]:	loss/total_loss, 7.327249050140381, 2074
[INFO] 2021-07-12 19:14:19,165 [run_pretraining.py:  535]:	loss/mlm_loss, 7.327249050140381, 2074
[INFO] 2021-07-12 19:14:19,165 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0729999960167333e-05, 2074
[INFO] 2021-07-12 19:14:19,165 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2074
[INFO] 2021-07-12 19:14:19,165 [run_pretraining.py:  558]:	worker_index: 6, step: 2074, cost: 7.327249, mlm loss: 7.327249, speed: 1.070638 steps/s, speed: 8.565105 samples/s, speed: 4385.333674 tokens/s, learning rate: 2.073e-05, loss_scalings: 3518.437988, pp_loss: 7.391919
[INFO] 2021-07-12 19:14:19,165 [run_pretraining.py:  512]:	********exe.run_2074******* 
[INFO] 2021-07-12 19:14:20,091 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:20,091 [run_pretraining.py:  534]:	loss/total_loss, 6.914760589599609, 2075
[INFO] 2021-07-12 19:14:20,091 [run_pretraining.py:  535]:	loss/mlm_loss, 6.914760589599609, 2075
[INFO] 2021-07-12 19:14:20,092 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0739998944918625e-05, 2075
[INFO] 2021-07-12 19:14:20,092 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2075
[INFO] 2021-07-12 19:14:20,092 [run_pretraining.py:  558]:	worker_index: 6, step: 2075, cost: 6.914761, mlm loss: 6.914761, speed: 1.079908 steps/s, speed: 8.639263 samples/s, speed: 4423.302792 tokens/s, learning rate: 2.074e-05, loss_scalings: 3518.437988, pp_loss: 7.550928
[INFO] 2021-07-12 19:14:20,092 [run_pretraining.py:  512]:	********exe.run_2075******* 
[INFO] 2021-07-12 19:14:21,021 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:21,021 [run_pretraining.py:  534]:	loss/total_loss, 7.671854019165039, 2076
[INFO] 2021-07-12 19:14:21,022 [run_pretraining.py:  535]:	loss/mlm_loss, 7.671854019165039, 2076
[INFO] 2021-07-12 19:14:21,022 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.074999974865932e-05, 2076
[INFO] 2021-07-12 19:14:21,022 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2076
[INFO] 2021-07-12 19:14:21,022 [run_pretraining.py:  558]:	worker_index: 6, step: 2076, cost: 7.671854, mlm loss: 7.671854, speed: 1.075969 steps/s, speed: 8.607753 samples/s, speed: 4407.169422 tokens/s, learning rate: 2.075e-05, loss_scalings: 3518.437988, pp_loss: 7.178408
[INFO] 2021-07-12 19:14:21,022 [run_pretraining.py:  512]:	********exe.run_2076******* 
[INFO] 2021-07-12 19:14:21,986 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:21,986 [run_pretraining.py:  534]:	loss/total_loss, 7.331897735595703, 2077
[INFO] 2021-07-12 19:14:21,986 [run_pretraining.py:  535]:	loss/mlm_loss, 7.331897735595703, 2077
[INFO] 2021-07-12 19:14:21,986 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0759998733410612e-05, 2077
[INFO] 2021-07-12 19:14:21,986 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2077
[INFO] 2021-07-12 19:14:21,987 [run_pretraining.py:  558]:	worker_index: 6, step: 2077, cost: 7.331898, mlm loss: 7.331898, speed: 1.037302 steps/s, speed: 8.298415 samples/s, speed: 4248.788278 tokens/s, learning rate: 2.076e-05, loss_scalings: 3518.437988, pp_loss: 7.470512
[INFO] 2021-07-12 19:14:21,987 [run_pretraining.py:  512]:	********exe.run_2077******* 
[INFO] 2021-07-12 19:14:22,933 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:22,934 [run_pretraining.py:  534]:	loss/total_loss, 7.2377400398254395, 2078
[INFO] 2021-07-12 19:14:22,934 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2377400398254395, 2078
[INFO] 2021-07-12 19:14:22,934 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0769999537151307e-05, 2078
[INFO] 2021-07-12 19:14:22,934 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2078
[INFO] 2021-07-12 19:14:22,934 [run_pretraining.py:  558]:	worker_index: 6, step: 2078, cost: 7.237740, mlm loss: 7.237740, speed: 1.055735 steps/s, speed: 8.445882 samples/s, speed: 4324.291397 tokens/s, learning rate: 2.077e-05, loss_scalings: 3518.437988, pp_loss: 7.245751
[INFO] 2021-07-12 19:14:22,935 [run_pretraining.py:  512]:	********exe.run_2078******* 
[INFO] 2021-07-12 19:14:23,884 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:23,885 [run_pretraining.py:  534]:	loss/total_loss, 7.175779819488525, 2079
[INFO] 2021-07-12 19:14:23,885 [run_pretraining.py:  535]:	loss/mlm_loss, 7.175779819488525, 2079
[INFO] 2021-07-12 19:14:23,885 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0780000340892002e-05, 2079
[INFO] 2021-07-12 19:14:23,885 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2079
[INFO] 2021-07-12 19:14:23,885 [run_pretraining.py:  558]:	worker_index: 6, step: 2079, cost: 7.175780, mlm loss: 7.175780, speed: 1.052448 steps/s, speed: 8.419584 samples/s, speed: 4310.826828 tokens/s, learning rate: 2.078e-05, loss_scalings: 3518.437988, pp_loss: 7.307784
[INFO] 2021-07-12 19:14:23,885 [run_pretraining.py:  512]:	********exe.run_2079******* 
[INFO] 2021-07-12 19:14:24,817 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:24,818 [run_pretraining.py:  534]:	loss/total_loss, 7.502904415130615, 2080
[INFO] 2021-07-12 19:14:24,818 [run_pretraining.py:  535]:	loss/mlm_loss, 7.502904415130615, 2080
[INFO] 2021-07-12 19:14:24,818 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0789999325643294e-05, 2080
[INFO] 2021-07-12 19:14:24,818 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2080
[INFO] 2021-07-12 19:14:24,818 [run_pretraining.py:  558]:	worker_index: 6, step: 2080, cost: 7.502904, mlm loss: 7.502904, speed: 1.072462 steps/s, speed: 8.579697 samples/s, speed: 4392.804946 tokens/s, learning rate: 2.079e-05, loss_scalings: 3518.437988, pp_loss: 6.931540
[INFO] 2021-07-12 19:14:24,819 [run_pretraining.py:  512]:	********exe.run_2080******* 
[INFO] 2021-07-12 19:14:25,760 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:25,761 [run_pretraining.py:  534]:	loss/total_loss, 7.201712131500244, 2081
[INFO] 2021-07-12 19:14:25,761 [run_pretraining.py:  535]:	loss/mlm_loss, 7.201712131500244, 2081
[INFO] 2021-07-12 19:14:25,761 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.080000012938399e-05, 2081
[INFO] 2021-07-12 19:14:25,761 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2081
[INFO] 2021-07-12 19:14:25,761 [run_pretraining.py:  558]:	worker_index: 6, step: 2081, cost: 7.201712, mlm loss: 7.201712, speed: 1.061774 steps/s, speed: 8.494191 samples/s, speed: 4349.025685 tokens/s, learning rate: 2.080e-05, loss_scalings: 3518.437988, pp_loss: 7.146784
[INFO] 2021-07-12 19:14:25,761 [run_pretraining.py:  512]:	********exe.run_2081******* 
[INFO] 2021-07-12 19:14:26,710 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:26,710 [run_pretraining.py:  534]:	loss/total_loss, 7.575424671173096, 2082
[INFO] 2021-07-12 19:14:26,711 [run_pretraining.py:  535]:	loss/mlm_loss, 7.575424671173096, 2082
[INFO] 2021-07-12 19:14:26,711 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0810000933124684e-05, 2082
[INFO] 2021-07-12 19:14:26,711 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2082
[INFO] 2021-07-12 19:14:26,711 [run_pretraining.py:  558]:	worker_index: 6, step: 2082, cost: 7.575425, mlm loss: 7.575425, speed: 1.053542 steps/s, speed: 8.428333 samples/s, speed: 4315.306414 tokens/s, learning rate: 2.081e-05, loss_scalings: 3518.437988, pp_loss: 7.153165
[INFO] 2021-07-12 19:14:26,711 [run_pretraining.py:  512]:	********exe.run_2082******* 
[INFO] 2021-07-12 19:14:27,653 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:27,654 [run_pretraining.py:  534]:	loss/total_loss, 7.094320297241211, 2083
[INFO] 2021-07-12 19:14:27,654 [run_pretraining.py:  535]:	loss/mlm_loss, 7.094320297241211, 2083
[INFO] 2021-07-12 19:14:27,654 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0819998098886572e-05, 2083
[INFO] 2021-07-12 19:14:27,654 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2083
[INFO] 2021-07-12 19:14:27,654 [run_pretraining.py:  558]:	worker_index: 6, step: 2083, cost: 7.094320, mlm loss: 7.094320, speed: 1.060779 steps/s, speed: 8.486231 samples/s, speed: 4344.950521 tokens/s, learning rate: 2.082e-05, loss_scalings: 3518.437988, pp_loss: 6.960907
[INFO] 2021-07-12 19:14:27,654 [run_pretraining.py:  512]:	********exe.run_2083******* 
[INFO] 2021-07-12 19:14:28,585 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:28,586 [run_pretraining.py:  534]:	loss/total_loss, 7.599413871765137, 2084
[INFO] 2021-07-12 19:14:28,586 [run_pretraining.py:  535]:	loss/mlm_loss, 7.599413871765137, 2084
[INFO] 2021-07-12 19:14:28,586 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0829998902627267e-05, 2084
[INFO] 2021-07-12 19:14:28,586 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2084
[INFO] 2021-07-12 19:14:28,586 [run_pretraining.py:  558]:	worker_index: 6, step: 2084, cost: 7.599414, mlm loss: 7.599414, speed: 1.073783 steps/s, speed: 8.590260 samples/s, speed: 4398.213151 tokens/s, learning rate: 2.083e-05, loss_scalings: 3518.437988, pp_loss: 7.427232
[INFO] 2021-07-12 19:14:28,586 [run_pretraining.py:  512]:	********exe.run_2084******* 
[INFO] 2021-07-12 19:14:29,492 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:29,493 [run_pretraining.py:  534]:	loss/total_loss, 7.373863220214844, 2085
[INFO] 2021-07-12 19:14:29,493 [run_pretraining.py:  535]:	loss/mlm_loss, 7.373863220214844, 2085
[INFO] 2021-07-12 19:14:29,493 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0839999706367962e-05, 2085
[INFO] 2021-07-12 19:14:29,493 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2085
[INFO] 2021-07-12 19:14:29,493 [run_pretraining.py:  558]:	worker_index: 6, step: 2085, cost: 7.373863, mlm loss: 7.373863, speed: 1.103277 steps/s, speed: 8.826219 samples/s, speed: 4519.023890 tokens/s, learning rate: 2.084e-05, loss_scalings: 3518.437988, pp_loss: 7.453619
[INFO] 2021-07-12 19:14:29,493 [run_pretraining.py:  512]:	********exe.run_2085******* 
[INFO] 2021-07-12 19:14:30,410 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:30,411 [run_pretraining.py:  534]:	loss/total_loss, 7.42983341217041, 2086
[INFO] 2021-07-12 19:14:30,411 [run_pretraining.py:  535]:	loss/mlm_loss, 7.42983341217041, 2086
[INFO] 2021-07-12 19:14:30,411 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0849998691119254e-05, 2086
[INFO] 2021-07-12 19:14:30,411 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2086
[INFO] 2021-07-12 19:14:30,411 [run_pretraining.py:  558]:	worker_index: 6, step: 2086, cost: 7.429833, mlm loss: 7.429833, speed: 1.090441 steps/s, speed: 8.723526 samples/s, speed: 4466.445297 tokens/s, learning rate: 2.085e-05, loss_scalings: 3518.437988, pp_loss: 7.262964
[INFO] 2021-07-12 19:14:30,411 [run_pretraining.py:  512]:	********exe.run_2086******* 
[INFO] 2021-07-12 19:14:31,337 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:31,337 [run_pretraining.py:  534]:	loss/total_loss, 7.206421375274658, 2087
[INFO] 2021-07-12 19:14:31,338 [run_pretraining.py:  535]:	loss/mlm_loss, 7.206421375274658, 2087
[INFO] 2021-07-12 19:14:31,338 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.085999949485995e-05, 2087
[INFO] 2021-07-12 19:14:31,338 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2087
[INFO] 2021-07-12 19:14:31,338 [run_pretraining.py:  558]:	worker_index: 6, step: 2087, cost: 7.206421, mlm loss: 7.206421, speed: 1.080001 steps/s, speed: 8.640008 samples/s, speed: 4423.684345 tokens/s, learning rate: 2.086e-05, loss_scalings: 3518.437988, pp_loss: 7.057472
[INFO] 2021-07-12 19:14:31,338 [run_pretraining.py:  512]:	********exe.run_2087******* 
[INFO] 2021-07-12 19:14:32,264 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:32,265 [run_pretraining.py:  534]:	loss/total_loss, 6.816526889801025, 2088
[INFO] 2021-07-12 19:14:32,265 [run_pretraining.py:  535]:	loss/mlm_loss, 6.816526889801025, 2088
[INFO] 2021-07-12 19:14:32,265 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0870000298600644e-05, 2088
[INFO] 2021-07-12 19:14:32,265 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2088
[INFO] 2021-07-12 19:14:32,265 [run_pretraining.py:  558]:	worker_index: 6, step: 2088, cost: 6.816527, mlm loss: 6.816527, speed: 1.078914 steps/s, speed: 8.631312 samples/s, speed: 4419.231671 tokens/s, learning rate: 2.087e-05, loss_scalings: 3518.437988, pp_loss: 6.842425
[INFO] 2021-07-12 19:14:32,265 [run_pretraining.py:  512]:	********exe.run_2088******* 
[INFO] 2021-07-12 19:14:33,183 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:33,183 [run_pretraining.py:  534]:	loss/total_loss, 7.370558738708496, 2089
[INFO] 2021-07-12 19:14:33,183 [run_pretraining.py:  535]:	loss/mlm_loss, 7.370558738708496, 2089
[INFO] 2021-07-12 19:14:33,184 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0879999283351935e-05, 2089
[INFO] 2021-07-12 19:14:33,184 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2089
[INFO] 2021-07-12 19:14:33,184 [run_pretraining.py:  558]:	worker_index: 6, step: 2089, cost: 7.370559, mlm loss: 7.370559, speed: 1.089700 steps/s, speed: 8.717604 samples/s, speed: 4463.413161 tokens/s, learning rate: 2.088e-05, loss_scalings: 3518.437988, pp_loss: 7.273014
[INFO] 2021-07-12 19:14:33,184 [run_pretraining.py:  512]:	********exe.run_2089******* 
[INFO] 2021-07-12 19:14:34,099 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:34,100 [run_pretraining.py:  534]:	loss/total_loss, 7.657459259033203, 2090
[INFO] 2021-07-12 19:14:34,100 [run_pretraining.py:  535]:	loss/mlm_loss, 7.657459259033203, 2090
[INFO] 2021-07-12 19:14:34,100 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.089000008709263e-05, 2090
[INFO] 2021-07-12 19:14:34,100 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2090
[INFO] 2021-07-12 19:14:34,100 [run_pretraining.py:  558]:	worker_index: 6, step: 2090, cost: 7.657459, mlm loss: 7.657459, speed: 1.092041 steps/s, speed: 8.736325 samples/s, speed: 4472.998216 tokens/s, learning rate: 2.089e-05, loss_scalings: 3518.437988, pp_loss: 7.129445
[INFO] 2021-07-12 19:14:34,100 [run_pretraining.py:  512]:	********exe.run_2090******* 
[INFO] 2021-07-12 19:14:35,014 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:35,014 [run_pretraining.py:  534]:	loss/total_loss, 6.452391147613525, 2091
[INFO] 2021-07-12 19:14:35,014 [run_pretraining.py:  535]:	loss/mlm_loss, 6.452391147613525, 2091
[INFO] 2021-07-12 19:14:35,014 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0900000890833326e-05, 2091
[INFO] 2021-07-12 19:14:35,015 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2091
[INFO] 2021-07-12 19:14:35,015 [run_pretraining.py:  558]:	worker_index: 6, step: 2091, cost: 6.452391, mlm loss: 6.452391, speed: 1.094397 steps/s, speed: 8.755174 samples/s, speed: 4482.649089 tokens/s, learning rate: 2.090e-05, loss_scalings: 3518.437988, pp_loss: 6.634350
[INFO] 2021-07-12 19:14:35,015 [run_pretraining.py:  512]:	********exe.run_2091******* 
[INFO] 2021-07-12 19:14:35,939 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:35,939 [run_pretraining.py:  534]:	loss/total_loss, 6.7826714515686035, 2092
[INFO] 2021-07-12 19:14:35,939 [run_pretraining.py:  535]:	loss/mlm_loss, 6.7826714515686035, 2092
[INFO] 2021-07-12 19:14:35,940 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0909998056595214e-05, 2092
[INFO] 2021-07-12 19:14:35,940 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2092
[INFO] 2021-07-12 19:14:35,940 [run_pretraining.py:  558]:	worker_index: 6, step: 2092, cost: 6.782671, mlm loss: 6.782671, speed: 1.081817 steps/s, speed: 8.654536 samples/s, speed: 4431.122394 tokens/s, learning rate: 2.091e-05, loss_scalings: 3518.437988, pp_loss: 6.834942
[INFO] 2021-07-12 19:14:35,940 [run_pretraining.py:  512]:	********exe.run_2092******* 
[INFO] 2021-07-12 19:14:36,861 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:36,862 [run_pretraining.py:  534]:	loss/total_loss, 7.184335708618164, 2093
[INFO] 2021-07-12 19:14:36,862 [run_pretraining.py:  535]:	loss/mlm_loss, 7.184335708618164, 2093
[INFO] 2021-07-12 19:14:36,862 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.091999886033591e-05, 2093
[INFO] 2021-07-12 19:14:36,862 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2093
[INFO] 2021-07-12 19:14:36,862 [run_pretraining.py:  558]:	worker_index: 6, step: 2093, cost: 7.184336, mlm loss: 7.184336, speed: 1.084750 steps/s, speed: 8.677998 samples/s, speed: 4443.134731 tokens/s, learning rate: 2.092e-05, loss_scalings: 3518.437988, pp_loss: 7.411685
[INFO] 2021-07-12 19:14:36,862 [run_pretraining.py:  512]:	********exe.run_2093******* 
[INFO] 2021-07-12 19:14:37,779 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:37,780 [run_pretraining.py:  534]:	loss/total_loss, 6.7462663650512695, 2094
[INFO] 2021-07-12 19:14:37,780 [run_pretraining.py:  535]:	loss/mlm_loss, 6.7462663650512695, 2094
[INFO] 2021-07-12 19:14:37,780 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0929999664076604e-05, 2094
[INFO] 2021-07-12 19:14:37,780 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2094
[INFO] 2021-07-12 19:14:37,780 [run_pretraining.py:  558]:	worker_index: 6, step: 2094, cost: 6.746266, mlm loss: 6.746266, speed: 1.089927 steps/s, speed: 8.719416 samples/s, speed: 4464.341047 tokens/s, learning rate: 2.093e-05, loss_scalings: 3518.437988, pp_loss: 7.155457
[INFO] 2021-07-12 19:14:37,781 [run_pretraining.py:  512]:	********exe.run_2094******* 
[INFO] 2021-07-12 19:14:38,716 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:38,716 [run_pretraining.py:  534]:	loss/total_loss, 7.568977355957031, 2095
[INFO] 2021-07-12 19:14:38,716 [run_pretraining.py:  535]:	loss/mlm_loss, 7.568977355957031, 2095
[INFO] 2021-07-12 19:14:38,717 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0939998648827896e-05, 2095
[INFO] 2021-07-12 19:14:38,717 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2095
[INFO] 2021-07-12 19:14:38,717 [run_pretraining.py:  558]:	worker_index: 6, step: 2095, cost: 7.568977, mlm loss: 7.568977, speed: 1.068816 steps/s, speed: 8.550532 samples/s, speed: 4377.872155 tokens/s, learning rate: 2.094e-05, loss_scalings: 3518.437988, pp_loss: 7.253624
[INFO] 2021-07-12 19:14:38,717 [run_pretraining.py:  512]:	********exe.run_2095******* 
[INFO] 2021-07-12 19:14:39,626 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:39,627 [run_pretraining.py:  534]:	loss/total_loss, 6.843864440917969, 2096
[INFO] 2021-07-12 19:14:39,627 [run_pretraining.py:  535]:	loss/mlm_loss, 6.843864440917969, 2096
[INFO] 2021-07-12 19:14:39,627 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.094999945256859e-05, 2096
[INFO] 2021-07-12 19:14:39,627 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2096
[INFO] 2021-07-12 19:14:39,627 [run_pretraining.py:  558]:	worker_index: 6, step: 2096, cost: 6.843864, mlm loss: 6.843864, speed: 1.099105 steps/s, speed: 8.792844 samples/s, speed: 4501.935922 tokens/s, learning rate: 2.095e-05, loss_scalings: 3518.437988, pp_loss: 7.153073
[INFO] 2021-07-12 19:14:39,627 [run_pretraining.py:  512]:	********exe.run_2096******* 
[INFO] 2021-07-12 19:14:40,560 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:40,561 [run_pretraining.py:  534]:	loss/total_loss, 7.754311561584473, 2097
[INFO] 2021-07-12 19:14:40,561 [run_pretraining.py:  535]:	loss/mlm_loss, 7.754311561584473, 2097
[INFO] 2021-07-12 19:14:40,561 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0960000256309286e-05, 2097
[INFO] 2021-07-12 19:14:40,561 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2097
[INFO] 2021-07-12 19:14:40,561 [run_pretraining.py:  558]:	worker_index: 6, step: 2097, cost: 7.754312, mlm loss: 7.754312, speed: 1.071596 steps/s, speed: 8.572766 samples/s, speed: 4389.256200 tokens/s, learning rate: 2.096e-05, loss_scalings: 3518.437988, pp_loss: 7.054428
[INFO] 2021-07-12 19:14:40,561 [run_pretraining.py:  512]:	********exe.run_2097******* 
[INFO] 2021-07-12 19:14:41,475 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:41,476 [run_pretraining.py:  534]:	loss/total_loss, 6.732073783874512, 2098
[INFO] 2021-07-12 19:14:41,476 [run_pretraining.py:  535]:	loss/mlm_loss, 6.732073783874512, 2098
[INFO] 2021-07-12 19:14:41,476 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0969999241060577e-05, 2098
[INFO] 2021-07-12 19:14:41,476 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2098
[INFO] 2021-07-12 19:14:41,476 [run_pretraining.py:  558]:	worker_index: 6, step: 2098, cost: 6.732074, mlm loss: 6.732074, speed: 1.093495 steps/s, speed: 8.747963 samples/s, speed: 4478.957262 tokens/s, learning rate: 2.097e-05, loss_scalings: 3518.437988, pp_loss: 6.836196
[INFO] 2021-07-12 19:14:41,476 [run_pretraining.py:  512]:	********exe.run_2098******* 
[INFO] 2021-07-12 19:14:42,397 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:42,397 [run_pretraining.py:  534]:	loss/total_loss, 7.423060417175293, 2099
[INFO] 2021-07-12 19:14:42,397 [run_pretraining.py:  535]:	loss/mlm_loss, 7.423060417175293, 2099
[INFO] 2021-07-12 19:14:42,397 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0980000044801272e-05, 2099
[INFO] 2021-07-12 19:14:42,397 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2099
[INFO] 2021-07-12 19:14:42,398 [run_pretraining.py:  558]:	worker_index: 6, step: 2099, cost: 7.423060, mlm loss: 7.423060, speed: 1.086498 steps/s, speed: 8.691987 samples/s, speed: 4450.297129 tokens/s, learning rate: 2.098e-05, loss_scalings: 3518.437988, pp_loss: 7.396067
[INFO] 2021-07-12 19:14:42,398 [run_pretraining.py:  512]:	********exe.run_2099******* 
[INFO] 2021-07-12 19:14:43,306 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:43,307 [run_pretraining.py:  534]:	loss/total_loss, 7.4629106521606445, 2100
[INFO] 2021-07-12 19:14:43,307 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4629106521606445, 2100
[INFO] 2021-07-12 19:14:43,307 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0990000848541968e-05, 2100
[INFO] 2021-07-12 19:14:43,307 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2100
[INFO] 2021-07-12 19:14:43,307 [run_pretraining.py:  558]:	worker_index: 6, step: 2100, cost: 7.462911, mlm loss: 7.462911, speed: 1.100134 steps/s, speed: 8.801070 samples/s, speed: 4506.147918 tokens/s, learning rate: 2.099e-05, loss_scalings: 3518.437988, pp_loss: 6.444457
[INFO] 2021-07-12 19:14:43,307 [run_pretraining.py:  512]:	********exe.run_2100******* 
[INFO] 2021-07-12 19:14:44,221 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:44,222 [run_pretraining.py:  534]:	loss/total_loss, 7.216264247894287, 2101
[INFO] 2021-07-12 19:14:44,222 [run_pretraining.py:  535]:	loss/mlm_loss, 7.216264247894287, 2101
[INFO] 2021-07-12 19:14:44,222 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0999998014303856e-05, 2101
[INFO] 2021-07-12 19:14:44,222 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2101
[INFO] 2021-07-12 19:14:44,222 [run_pretraining.py:  558]:	worker_index: 6, step: 2101, cost: 7.216264, mlm loss: 7.216264, speed: 1.093819 steps/s, speed: 8.750548 samples/s, speed: 4480.280665 tokens/s, learning rate: 2.100e-05, loss_scalings: 3518.437988, pp_loss: 7.270053
[INFO] 2021-07-12 19:14:44,222 [run_pretraining.py:  512]:	********exe.run_2101******* 
[INFO] 2021-07-12 19:14:45,152 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:45,152 [run_pretraining.py:  534]:	loss/total_loss, 7.596153259277344, 2102
[INFO] 2021-07-12 19:14:45,153 [run_pretraining.py:  535]:	loss/mlm_loss, 7.596153259277344, 2102
[INFO] 2021-07-12 19:14:45,153 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.100999881804455e-05, 2102
[INFO] 2021-07-12 19:14:45,153 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2102
[INFO] 2021-07-12 19:14:45,153 [run_pretraining.py:  558]:	worker_index: 6, step: 2102, cost: 7.596153, mlm loss: 7.596153, speed: 1.075247 steps/s, speed: 8.601978 samples/s, speed: 4404.212691 tokens/s, learning rate: 2.101e-05, loss_scalings: 3518.437988, pp_loss: 7.251146
[INFO] 2021-07-12 19:14:45,153 [run_pretraining.py:  512]:	********exe.run_2102******* 
[INFO] 2021-07-12 19:14:46,069 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:46,070 [run_pretraining.py:  534]:	loss/total_loss, 7.499759674072266, 2103
[INFO] 2021-07-12 19:14:46,070 [run_pretraining.py:  535]:	loss/mlm_loss, 7.499759674072266, 2103
[INFO] 2021-07-12 19:14:46,070 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1019999621785246e-05, 2103
[INFO] 2021-07-12 19:14:46,070 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2103
[INFO] 2021-07-12 19:14:46,070 [run_pretraining.py:  558]:	worker_index: 6, step: 2103, cost: 7.499760, mlm loss: 7.499760, speed: 1.090765 steps/s, speed: 8.726117 samples/s, speed: 4467.771773 tokens/s, learning rate: 2.102e-05, loss_scalings: 3518.437988, pp_loss: 7.137373
[INFO] 2021-07-12 19:14:46,071 [run_pretraining.py:  512]:	********exe.run_2103******* 
[INFO] 2021-07-12 19:14:46,989 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:46,990 [run_pretraining.py:  534]:	loss/total_loss, 7.1030731201171875, 2104
[INFO] 2021-07-12 19:14:46,990 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1030731201171875, 2104
[INFO] 2021-07-12 19:14:46,990 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1029998606536537e-05, 2104
[INFO] 2021-07-12 19:14:46,990 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2104
[INFO] 2021-07-12 19:14:46,990 [run_pretraining.py:  558]:	worker_index: 6, step: 2104, cost: 7.103073, mlm loss: 7.103073, speed: 1.087945 steps/s, speed: 8.703559 samples/s, speed: 4456.222387 tokens/s, learning rate: 2.103e-05, loss_scalings: 3518.437988, pp_loss: 6.925491
[INFO] 2021-07-12 19:14:46,990 [run_pretraining.py:  512]:	********exe.run_2104******* 
[INFO] 2021-07-12 19:14:47,905 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:47,906 [run_pretraining.py:  534]:	loss/total_loss, 6.980226993560791, 2105
[INFO] 2021-07-12 19:14:47,906 [run_pretraining.py:  535]:	loss/mlm_loss, 6.980226993560791, 2105
[INFO] 2021-07-12 19:14:47,906 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1039999410277233e-05, 2105
[INFO] 2021-07-12 19:14:47,906 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2105
[INFO] 2021-07-12 19:14:47,906 [run_pretraining.py:  558]:	worker_index: 6, step: 2105, cost: 6.980227, mlm loss: 6.980227, speed: 1.092510 steps/s, speed: 8.740082 samples/s, speed: 4474.921801 tokens/s, learning rate: 2.104e-05, loss_scalings: 3518.437988, pp_loss: 7.261565
[INFO] 2021-07-12 19:14:47,907 [run_pretraining.py:  512]:	********exe.run_2105******* 
[INFO] 2021-07-12 19:14:48,823 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:48,824 [run_pretraining.py:  534]:	loss/total_loss, 3.5636799335479736, 2106
[INFO] 2021-07-12 19:14:48,824 [run_pretraining.py:  535]:	loss/mlm_loss, 3.5636799335479736, 2106
[INFO] 2021-07-12 19:14:48,824 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1050000214017928e-05, 2106
[INFO] 2021-07-12 19:14:48,824 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2106
[INFO] 2021-07-12 19:14:48,824 [run_pretraining.py:  558]:	worker_index: 6, step: 2106, cost: 3.563680, mlm loss: 3.563680, speed: 1.090373 steps/s, speed: 8.722982 samples/s, speed: 4466.166628 tokens/s, learning rate: 2.105e-05, loss_scalings: 3518.437988, pp_loss: 6.429563
[INFO] 2021-07-12 19:14:48,824 [run_pretraining.py:  512]:	********exe.run_2106******* 
[INFO] 2021-07-12 19:14:49,784 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:49,785 [run_pretraining.py:  534]:	loss/total_loss, 7.4027299880981445, 2107
[INFO] 2021-07-12 19:14:49,785 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4027299880981445, 2107
[INFO] 2021-07-12 19:14:49,785 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.105999919876922e-05, 2107
[INFO] 2021-07-12 19:14:49,785 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2107
[INFO] 2021-07-12 19:14:49,785 [run_pretraining.py:  558]:	worker_index: 6, step: 2107, cost: 7.402730, mlm loss: 7.402730, speed: 1.041178 steps/s, speed: 8.329425 samples/s, speed: 4264.665779 tokens/s, learning rate: 2.106e-05, loss_scalings: 3518.437988, pp_loss: 7.226575
[INFO] 2021-07-12 19:14:49,785 [run_pretraining.py:  512]:	********exe.run_2107******* 
[INFO] 2021-07-12 19:14:50,835 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:50,835 [run_pretraining.py:  534]:	loss/total_loss, 7.684277057647705, 2108
[INFO] 2021-07-12 19:14:50,835 [run_pretraining.py:  535]:	loss/mlm_loss, 7.684277057647705, 2108
[INFO] 2021-07-12 19:14:50,835 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1070000002509914e-05, 2108
[INFO] 2021-07-12 19:14:50,836 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2108
[INFO] 2021-07-12 19:14:50,836 [run_pretraining.py:  558]:	worker_index: 6, step: 2108, cost: 7.684277, mlm loss: 7.684277, speed: 0.952786 steps/s, speed: 7.622286 samples/s, speed: 3902.610540 tokens/s, learning rate: 2.107e-05, loss_scalings: 3518.437988, pp_loss: 7.380702
[INFO] 2021-07-12 19:14:50,836 [run_pretraining.py:  512]:	********exe.run_2108******* 
[INFO] 2021-07-12 19:14:51,899 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:51,899 [run_pretraining.py:  534]:	loss/total_loss, 7.8646745681762695, 2109
[INFO] 2021-07-12 19:14:51,899 [run_pretraining.py:  535]:	loss/mlm_loss, 7.8646745681762695, 2109
[INFO] 2021-07-12 19:14:51,900 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.108000080625061e-05, 2109
[INFO] 2021-07-12 19:14:51,900 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2109
[INFO] 2021-07-12 19:14:51,900 [run_pretraining.py:  558]:	worker_index: 6, step: 2109, cost: 7.864675, mlm loss: 7.864675, speed: 0.940418 steps/s, speed: 7.523344 samples/s, speed: 3851.952332 tokens/s, learning rate: 2.108e-05, loss_scalings: 3518.437988, pp_loss: 7.250679
[INFO] 2021-07-12 19:14:51,900 [run_pretraining.py:  512]:	********exe.run_2109******* 
[INFO] 2021-07-12 19:14:52,952 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:52,952 [run_pretraining.py:  534]:	loss/total_loss, 6.797344207763672, 2110
[INFO] 2021-07-12 19:14:52,952 [run_pretraining.py:  535]:	loss/mlm_loss, 6.797344207763672, 2110
[INFO] 2021-07-12 19:14:52,953 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1089997972012497e-05, 2110
[INFO] 2021-07-12 19:14:52,953 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2110
[INFO] 2021-07-12 19:14:52,953 [run_pretraining.py:  558]:	worker_index: 6, step: 2110, cost: 6.797344, mlm loss: 6.797344, speed: 0.950331 steps/s, speed: 7.602650 samples/s, speed: 3892.556728 tokens/s, learning rate: 2.109e-05, loss_scalings: 3518.437988, pp_loss: 7.524523
[INFO] 2021-07-12 19:14:52,953 [run_pretraining.py:  512]:	********exe.run_2110******* 
[INFO] 2021-07-12 19:14:54,017 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:54,018 [run_pretraining.py:  534]:	loss/total_loss, 6.830729961395264, 2111
[INFO] 2021-07-12 19:14:54,018 [run_pretraining.py:  535]:	loss/mlm_loss, 6.830729961395264, 2111
[INFO] 2021-07-12 19:14:54,018 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1099998775753193e-05, 2111
[INFO] 2021-07-12 19:14:54,018 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2111
[INFO] 2021-07-12 19:14:54,018 [run_pretraining.py:  558]:	worker_index: 6, step: 2111, cost: 6.830730, mlm loss: 6.830730, speed: 0.939078 steps/s, speed: 7.512623 samples/s, speed: 3846.462981 tokens/s, learning rate: 2.110e-05, loss_scalings: 3518.437988, pp_loss: 6.972760
[INFO] 2021-07-12 19:14:54,018 [run_pretraining.py:  512]:	********exe.run_2111******* 
[INFO] 2021-07-12 19:14:55,067 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:55,068 [run_pretraining.py:  534]:	loss/total_loss, 7.34908390045166, 2112
[INFO] 2021-07-12 19:14:55,068 [run_pretraining.py:  535]:	loss/mlm_loss, 7.34908390045166, 2112
[INFO] 2021-07-12 19:14:55,068 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1109999579493888e-05, 2112
[INFO] 2021-07-12 19:14:55,068 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2112
[INFO] 2021-07-12 19:14:55,068 [run_pretraining.py:  558]:	worker_index: 6, step: 2112, cost: 7.349084, mlm loss: 7.349084, speed: 0.952990 steps/s, speed: 7.623918 samples/s, speed: 3903.445825 tokens/s, learning rate: 2.111e-05, loss_scalings: 3518.437988, pp_loss: 7.167693
[INFO] 2021-07-12 19:14:55,068 [run_pretraining.py:  512]:	********exe.run_2112******* 
[INFO] 2021-07-12 19:14:56,127 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:56,127 [run_pretraining.py:  534]:	loss/total_loss, 7.086203575134277, 2113
[INFO] 2021-07-12 19:14:56,128 [run_pretraining.py:  535]:	loss/mlm_loss, 7.086203575134277, 2113
[INFO] 2021-07-12 19:14:56,128 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.111999856424518e-05, 2113
[INFO] 2021-07-12 19:14:56,128 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2113
[INFO] 2021-07-12 19:14:56,128 [run_pretraining.py:  558]:	worker_index: 6, step: 2113, cost: 7.086204, mlm loss: 7.086204, speed: 0.944519 steps/s, speed: 7.556154 samples/s, speed: 3868.750880 tokens/s, learning rate: 2.112e-05, loss_scalings: 3518.437988, pp_loss: 7.210677
[INFO] 2021-07-12 19:14:56,128 [run_pretraining.py:  512]:	********exe.run_2113******* 
[INFO] 2021-07-12 19:14:57,186 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:57,187 [run_pretraining.py:  534]:	loss/total_loss, 7.230376243591309, 2114
[INFO] 2021-07-12 19:14:57,187 [run_pretraining.py:  535]:	loss/mlm_loss, 7.230376243591309, 2114
[INFO] 2021-07-12 19:14:57,187 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1129999367985874e-05, 2114
[INFO] 2021-07-12 19:14:57,187 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2114
[INFO] 2021-07-12 19:14:57,187 [run_pretraining.py:  558]:	worker_index: 6, step: 2114, cost: 7.230376, mlm loss: 7.230376, speed: 0.944738 steps/s, speed: 7.557900 samples/s, speed: 3869.644946 tokens/s, learning rate: 2.113e-05, loss_scalings: 3518.437988, pp_loss: 7.187808
[INFO] 2021-07-12 19:14:57,187 [run_pretraining.py:  512]:	********exe.run_2114******* 
[INFO] 2021-07-12 19:14:58,252 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:58,252 [run_pretraining.py:  534]:	loss/total_loss, 6.9177961349487305, 2115
[INFO] 2021-07-12 19:14:58,252 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9177961349487305, 2115
[INFO] 2021-07-12 19:14:58,252 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.114000017172657e-05, 2115
[INFO] 2021-07-12 19:14:58,252 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2115
[INFO] 2021-07-12 19:14:58,253 [run_pretraining.py:  558]:	worker_index: 6, step: 2115, cost: 6.917796, mlm loss: 6.917796, speed: 0.939087 steps/s, speed: 7.512699 samples/s, speed: 3846.501735 tokens/s, learning rate: 2.114e-05, loss_scalings: 3518.437988, pp_loss: 7.324760
[INFO] 2021-07-12 19:14:58,253 [run_pretraining.py:  512]:	********exe.run_2115******* 
[INFO] 2021-07-12 19:14:59,312 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:59,313 [run_pretraining.py:  534]:	loss/total_loss, 7.474934101104736, 2116
[INFO] 2021-07-12 19:14:59,313 [run_pretraining.py:  535]:	loss/mlm_loss, 7.474934101104736, 2116
[INFO] 2021-07-12 19:14:59,313 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.114999915647786e-05, 2116
[INFO] 2021-07-12 19:14:59,313 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2116
[INFO] 2021-07-12 19:14:59,313 [run_pretraining.py:  558]:	worker_index: 6, step: 2116, cost: 7.474934, mlm loss: 7.474934, speed: 0.943268 steps/s, speed: 7.546142 samples/s, speed: 3863.624527 tokens/s, learning rate: 2.115e-05, loss_scalings: 3518.437988, pp_loss: 6.954535
[INFO] 2021-07-12 19:14:59,313 [run_pretraining.py:  512]:	********exe.run_2116******* 
[INFO] 2021-07-12 19:15:00,376 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:00,376 [run_pretraining.py:  534]:	loss/total_loss, 6.86018180847168, 2117
[INFO] 2021-07-12 19:15:00,377 [run_pretraining.py:  535]:	loss/mlm_loss, 6.86018180847168, 2117
[INFO] 2021-07-12 19:15:00,377 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1159999960218556e-05, 2117
[INFO] 2021-07-12 19:15:00,377 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2117
[INFO] 2021-07-12 19:15:00,377 [run_pretraining.py:  558]:	worker_index: 6, step: 2117, cost: 6.860182, mlm loss: 6.860182, speed: 0.940995 steps/s, speed: 7.527959 samples/s, speed: 3854.315022 tokens/s, learning rate: 2.116e-05, loss_scalings: 3518.437988, pp_loss: 7.431690
[INFO] 2021-07-12 19:15:00,377 [run_pretraining.py:  512]:	********exe.run_2117******* 
[INFO] 2021-07-12 19:15:01,439 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:01,440 [run_pretraining.py:  534]:	loss/total_loss, 7.275877952575684, 2118
[INFO] 2021-07-12 19:15:01,440 [run_pretraining.py:  535]:	loss/mlm_loss, 7.275877952575684, 2118
[INFO] 2021-07-12 19:15:01,440 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.117000076395925e-05, 2118
[INFO] 2021-07-12 19:15:01,440 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2118
[INFO] 2021-07-12 19:15:01,440 [run_pretraining.py:  558]:	worker_index: 6, step: 2118, cost: 7.275878, mlm loss: 7.275878, speed: 0.940737 steps/s, speed: 7.525899 samples/s, speed: 3853.260355 tokens/s, learning rate: 2.117e-05, loss_scalings: 3518.437988, pp_loss: 7.491110
[INFO] 2021-07-12 19:15:01,441 [run_pretraining.py:  512]:	********exe.run_2118******* 
[INFO] 2021-07-12 19:15:02,500 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:02,500 [run_pretraining.py:  534]:	loss/total_loss, 6.648397445678711, 2119
[INFO] 2021-07-12 19:15:02,500 [run_pretraining.py:  535]:	loss/mlm_loss, 6.648397445678711, 2119
[INFO] 2021-07-12 19:15:02,501 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1179999748710543e-05, 2119
[INFO] 2021-07-12 19:15:02,501 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2119
[INFO] 2021-07-12 19:15:02,501 [run_pretraining.py:  558]:	worker_index: 6, step: 2119, cost: 6.648397, mlm loss: 6.648397, speed: 0.943814 steps/s, speed: 7.550514 samples/s, speed: 3865.863241 tokens/s, learning rate: 2.118e-05, loss_scalings: 3518.437988, pp_loss: 7.341847
[INFO] 2021-07-12 19:15:02,501 [run_pretraining.py:  512]:	********exe.run_2119******* 
[INFO] 2021-07-12 19:15:03,556 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:03,556 [run_pretraining.py:  534]:	loss/total_loss, 7.747300148010254, 2120
[INFO] 2021-07-12 19:15:03,556 [run_pretraining.py:  535]:	loss/mlm_loss, 7.747300148010254, 2120
[INFO] 2021-07-12 19:15:03,556 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1189998733461834e-05, 2120
[INFO] 2021-07-12 19:15:03,556 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2120
[INFO] 2021-07-12 19:15:03,557 [run_pretraining.py:  558]:	worker_index: 6, step: 2120, cost: 7.747300, mlm loss: 7.747300, speed: 0.947761 steps/s, speed: 7.582091 samples/s, speed: 3882.030825 tokens/s, learning rate: 2.119e-05, loss_scalings: 3518.437988, pp_loss: 7.369523
[INFO] 2021-07-12 19:15:03,557 [run_pretraining.py:  512]:	********exe.run_2120******* 
[INFO] 2021-07-12 19:15:04,624 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:04,624 [run_pretraining.py:  534]:	loss/total_loss, 6.799676418304443, 2121
[INFO] 2021-07-12 19:15:04,625 [run_pretraining.py:  535]:	loss/mlm_loss, 6.799676418304443, 2121
[INFO] 2021-07-12 19:15:04,625 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.119999953720253e-05, 2121
[INFO] 2021-07-12 19:15:04,625 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2121
[INFO] 2021-07-12 19:15:04,625 [run_pretraining.py:  558]:	worker_index: 6, step: 2121, cost: 6.799676, mlm loss: 6.799676, speed: 0.936704 steps/s, speed: 7.493636 samples/s, speed: 3836.741430 tokens/s, learning rate: 2.120e-05, loss_scalings: 3518.437988, pp_loss: 7.394549
[INFO] 2021-07-12 19:15:04,625 [run_pretraining.py:  512]:	********exe.run_2121******* 
[INFO] 2021-07-12 19:15:05,684 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:05,684 [run_pretraining.py:  534]:	loss/total_loss, 7.109004497528076, 2122
[INFO] 2021-07-12 19:15:05,684 [run_pretraining.py:  535]:	loss/mlm_loss, 7.109004497528076, 2122
[INFO] 2021-07-12 19:15:05,684 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.120999852195382e-05, 2122
[INFO] 2021-07-12 19:15:05,685 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2122
[INFO] 2021-07-12 19:15:05,685 [run_pretraining.py:  558]:	worker_index: 6, step: 2122, cost: 7.109004, mlm loss: 7.109004, speed: 0.944182 steps/s, speed: 7.553456 samples/s, speed: 3867.369638 tokens/s, learning rate: 2.121e-05, loss_scalings: 3518.437988, pp_loss: 7.194785
[INFO] 2021-07-12 19:15:05,685 [run_pretraining.py:  512]:	********exe.run_2122******* 
[INFO] 2021-07-12 19:15:06,751 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:06,751 [run_pretraining.py:  534]:	loss/total_loss, 7.0646653175354, 2123
[INFO] 2021-07-12 19:15:06,752 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0646653175354, 2123
[INFO] 2021-07-12 19:15:06,752 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1219999325694516e-05, 2123
[INFO] 2021-07-12 19:15:06,752 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2123
[INFO] 2021-07-12 19:15:06,752 [run_pretraining.py:  558]:	worker_index: 6, step: 2123, cost: 7.064665, mlm loss: 7.064665, speed: 0.937679 steps/s, speed: 7.501429 samples/s, speed: 3840.731646 tokens/s, learning rate: 2.122e-05, loss_scalings: 3518.437988, pp_loss: 7.058289
[INFO] 2021-07-12 19:15:06,752 [run_pretraining.py:  512]:	********exe.run_2123******* 
[INFO] 2021-07-12 19:15:07,810 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:07,810 [run_pretraining.py:  534]:	loss/total_loss, 7.149362564086914, 2124
[INFO] 2021-07-12 19:15:07,811 [run_pretraining.py:  535]:	loss/mlm_loss, 7.149362564086914, 2124
[INFO] 2021-07-12 19:15:07,811 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.123000012943521e-05, 2124
[INFO] 2021-07-12 19:15:07,811 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2124
[INFO] 2021-07-12 19:15:07,811 [run_pretraining.py:  558]:	worker_index: 6, step: 2124, cost: 7.149363, mlm loss: 7.149363, speed: 0.944945 steps/s, speed: 7.559559 samples/s, speed: 3870.494081 tokens/s, learning rate: 2.123e-05, loss_scalings: 3518.437988, pp_loss: 7.373578
[INFO] 2021-07-12 19:15:07,811 [run_pretraining.py:  512]:	********exe.run_2124******* 
[INFO] 2021-07-12 19:15:08,866 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:08,867 [run_pretraining.py:  534]:	loss/total_loss, 7.582987308502197, 2125
[INFO] 2021-07-12 19:15:08,867 [run_pretraining.py:  535]:	loss/mlm_loss, 7.582987308502197, 2125
[INFO] 2021-07-12 19:15:08,867 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1239999114186503e-05, 2125
[INFO] 2021-07-12 19:15:08,867 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2125
[INFO] 2021-07-12 19:15:08,867 [run_pretraining.py:  558]:	worker_index: 6, step: 2125, cost: 7.582987, mlm loss: 7.582987, speed: 0.947258 steps/s, speed: 7.578066 samples/s, speed: 3879.969625 tokens/s, learning rate: 2.124e-05, loss_scalings: 3518.437988, pp_loss: 7.158089
[INFO] 2021-07-12 19:15:08,867 [run_pretraining.py:  512]:	********exe.run_2125******* 
[INFO] 2021-07-12 19:15:09,956 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:09,957 [run_pretraining.py:  534]:	loss/total_loss, 6.832806587219238, 2126
[INFO] 2021-07-12 19:15:09,957 [run_pretraining.py:  535]:	loss/mlm_loss, 6.832806587219238, 2126
[INFO] 2021-07-12 19:15:09,957 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1249999917927198e-05, 2126
[INFO] 2021-07-12 19:15:09,957 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2126
[INFO] 2021-07-12 19:15:09,957 [run_pretraining.py:  558]:	worker_index: 6, step: 2126, cost: 6.832807, mlm loss: 6.832807, speed: 0.918015 steps/s, speed: 7.344120 samples/s, speed: 3760.189399 tokens/s, learning rate: 2.125e-05, loss_scalings: 3518.437988, pp_loss: 6.841532
[INFO] 2021-07-12 19:15:09,957 [run_pretraining.py:  512]:	********exe.run_2126******* 
[INFO] 2021-07-12 19:15:11,034 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:11,035 [run_pretraining.py:  534]:	loss/total_loss, 6.9904561042785645, 2127
[INFO] 2021-07-12 19:15:11,035 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9904561042785645, 2127
[INFO] 2021-07-12 19:15:11,035 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.125999890267849e-05, 2127
[INFO] 2021-07-12 19:15:11,035 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2127
[INFO] 2021-07-12 19:15:11,035 [run_pretraining.py:  558]:	worker_index: 6, step: 2127, cost: 6.990456, mlm loss: 6.990456, speed: 0.928065 steps/s, speed: 7.424519 samples/s, speed: 3801.353891 tokens/s, learning rate: 2.126e-05, loss_scalings: 3518.437988, pp_loss: 7.246318
[INFO] 2021-07-12 19:15:11,035 [run_pretraining.py:  512]:	********exe.run_2127******* 
[INFO] 2021-07-12 19:15:12,093 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:12,094 [run_pretraining.py:  534]:	loss/total_loss, 6.881484508514404, 2128
[INFO] 2021-07-12 19:15:12,094 [run_pretraining.py:  535]:	loss/mlm_loss, 6.881484508514404, 2128
[INFO] 2021-07-12 19:15:12,094 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1269999706419185e-05, 2128
[INFO] 2021-07-12 19:15:12,094 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2128
[INFO] 2021-07-12 19:15:12,094 [run_pretraining.py:  558]:	worker_index: 6, step: 2128, cost: 6.881485, mlm loss: 6.881485, speed: 0.945210 steps/s, speed: 7.561678 samples/s, speed: 3871.579144 tokens/s, learning rate: 2.127e-05, loss_scalings: 3518.437988, pp_loss: 7.320460
[INFO] 2021-07-12 19:15:12,094 [run_pretraining.py:  512]:	********exe.run_2128******* 
[INFO] 2021-07-12 19:15:13,156 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:13,156 [run_pretraining.py:  534]:	loss/total_loss, 6.910154819488525, 2129
[INFO] 2021-07-12 19:15:13,156 [run_pretraining.py:  535]:	loss/mlm_loss, 6.910154819488525, 2129
[INFO] 2021-07-12 19:15:13,156 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1279998691170476e-05, 2129
[INFO] 2021-07-12 19:15:13,157 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2129
[INFO] 2021-07-12 19:15:13,157 [run_pretraining.py:  558]:	worker_index: 6, step: 2129, cost: 6.910155, mlm loss: 6.910155, speed: 0.941728 steps/s, speed: 7.533822 samples/s, speed: 3857.317066 tokens/s, learning rate: 2.128e-05, loss_scalings: 3518.437988, pp_loss: 7.182706
[INFO] 2021-07-12 19:15:13,157 [run_pretraining.py:  512]:	********exe.run_2129******* 
[INFO] 2021-07-12 19:15:14,211 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:14,212 [run_pretraining.py:  534]:	loss/total_loss, 7.457131385803223, 2130
[INFO] 2021-07-12 19:15:14,212 [run_pretraining.py:  535]:	loss/mlm_loss, 7.457131385803223, 2130
[INFO] 2021-07-12 19:15:14,212 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.128999949491117e-05, 2130
[INFO] 2021-07-12 19:15:14,212 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2130
[INFO] 2021-07-12 19:15:14,212 [run_pretraining.py:  558]:	worker_index: 6, step: 2130, cost: 7.457131, mlm loss: 7.457131, speed: 0.948250 steps/s, speed: 7.586001 samples/s, speed: 3884.032747 tokens/s, learning rate: 2.129e-05, loss_scalings: 3518.437988, pp_loss: 7.324685
[INFO] 2021-07-12 19:15:14,212 [run_pretraining.py:  512]:	********exe.run_2130******* 
[INFO] 2021-07-12 19:15:15,277 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:15,277 [run_pretraining.py:  534]:	loss/total_loss, 8.092098236083984, 2131
[INFO] 2021-07-12 19:15:15,278 [run_pretraining.py:  535]:	loss/mlm_loss, 8.092098236083984, 2131
[INFO] 2021-07-12 19:15:15,278 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1300000298651867e-05, 2131
[INFO] 2021-07-12 19:15:15,278 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2131
[INFO] 2021-07-12 19:15:15,278 [run_pretraining.py:  558]:	worker_index: 6, step: 2131, cost: 8.092098, mlm loss: 8.092098, speed: 0.938803 steps/s, speed: 7.510424 samples/s, speed: 3845.336863 tokens/s, learning rate: 2.130e-05, loss_scalings: 3518.437988, pp_loss: 7.571349
[INFO] 2021-07-12 19:15:15,278 [run_pretraining.py:  512]:	********exe.run_2131******* 
[INFO] 2021-07-12 19:15:16,339 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:16,340 [run_pretraining.py:  534]:	loss/total_loss, 7.806192398071289, 2132
[INFO] 2021-07-12 19:15:16,340 [run_pretraining.py:  535]:	loss/mlm_loss, 7.806192398071289, 2132
[INFO] 2021-07-12 19:15:16,340 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1309999283403158e-05, 2132
[INFO] 2021-07-12 19:15:16,340 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2132
[INFO] 2021-07-12 19:15:16,340 [run_pretraining.py:  558]:	worker_index: 6, step: 2132, cost: 7.806192, mlm loss: 7.806192, speed: 0.942057 steps/s, speed: 7.536457 samples/s, speed: 3858.666002 tokens/s, learning rate: 2.131e-05, loss_scalings: 3518.437988, pp_loss: 7.465044
[INFO] 2021-07-12 19:15:16,340 [run_pretraining.py:  512]:	********exe.run_2132******* 
[INFO] 2021-07-12 19:15:17,410 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:17,411 [run_pretraining.py:  534]:	loss/total_loss, 7.532414436340332, 2133
[INFO] 2021-07-12 19:15:17,411 [run_pretraining.py:  535]:	loss/mlm_loss, 7.532414436340332, 2133
[INFO] 2021-07-12 19:15:17,411 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1320000087143853e-05, 2133
[INFO] 2021-07-12 19:15:17,411 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2133
[INFO] 2021-07-12 19:15:17,411 [run_pretraining.py:  558]:	worker_index: 6, step: 2133, cost: 7.532414, mlm loss: 7.532414, speed: 0.934147 steps/s, speed: 7.473177 samples/s, speed: 3826.266828 tokens/s, learning rate: 2.132e-05, loss_scalings: 3518.437988, pp_loss: 7.795589
[INFO] 2021-07-12 19:15:17,411 [run_pretraining.py:  512]:	********exe.run_2133******* 
[INFO] 2021-07-12 19:15:18,488 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:18,489 [run_pretraining.py:  534]:	loss/total_loss, 7.17034912109375, 2134
[INFO] 2021-07-12 19:15:18,489 [run_pretraining.py:  535]:	loss/mlm_loss, 7.17034912109375, 2134
[INFO] 2021-07-12 19:15:18,489 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1329999071895145e-05, 2134
[INFO] 2021-07-12 19:15:18,489 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2134
[INFO] 2021-07-12 19:15:18,489 [run_pretraining.py:  558]:	worker_index: 6, step: 2134, cost: 7.170349, mlm loss: 7.170349, speed: 0.928224 steps/s, speed: 7.425794 samples/s, speed: 3802.006710 tokens/s, learning rate: 2.133e-05, loss_scalings: 3518.437988, pp_loss: 7.187440
[INFO] 2021-07-12 19:15:18,489 [run_pretraining.py:  512]:	********exe.run_2134******* 
[INFO] 2021-07-12 19:15:19,440 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:19,441 [run_pretraining.py:  534]:	loss/total_loss, 7.390653610229492, 2135
[INFO] 2021-07-12 19:15:19,441 [run_pretraining.py:  535]:	loss/mlm_loss, 7.390653610229492, 2135
[INFO] 2021-07-12 19:15:19,441 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.133999987563584e-05, 2135
[INFO] 2021-07-12 19:15:19,441 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2135
[INFO] 2021-07-12 19:15:19,441 [run_pretraining.py:  558]:	worker_index: 6, step: 2135, cost: 7.390654, mlm loss: 7.390654, speed: 1.051376 steps/s, speed: 8.411011 samples/s, speed: 4306.437492 tokens/s, learning rate: 2.134e-05, loss_scalings: 3518.437988, pp_loss: 7.327080
[INFO] 2021-07-12 19:15:19,441 [run_pretraining.py:  512]:	********exe.run_2135******* 
[INFO] 2021-07-12 19:15:20,352 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:20,353 [run_pretraining.py:  534]:	loss/total_loss, 7.46159553527832, 2136
[INFO] 2021-07-12 19:15:20,353 [run_pretraining.py:  535]:	loss/mlm_loss, 7.46159553527832, 2136
[INFO] 2021-07-12 19:15:20,353 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.134999886038713e-05, 2136
[INFO] 2021-07-12 19:15:20,353 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2136
[INFO] 2021-07-12 19:15:20,353 [run_pretraining.py:  558]:	worker_index: 6, step: 2136, cost: 7.461596, mlm loss: 7.461596, speed: 1.097267 steps/s, speed: 8.778138 samples/s, speed: 4494.406588 tokens/s, learning rate: 2.135e-05, loss_scalings: 3518.437988, pp_loss: 7.373524
[INFO] 2021-07-12 19:15:20,353 [run_pretraining.py:  512]:	********exe.run_2136******* 
[INFO] 2021-07-12 19:15:21,261 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:21,261 [run_pretraining.py:  534]:	loss/total_loss, 7.423039436340332, 2137
[INFO] 2021-07-12 19:15:21,261 [run_pretraining.py:  535]:	loss/mlm_loss, 7.423039436340332, 2137
[INFO] 2021-07-12 19:15:21,261 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1359999664127827e-05, 2137
[INFO] 2021-07-12 19:15:21,262 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2137
[INFO] 2021-07-12 19:15:21,262 [run_pretraining.py:  558]:	worker_index: 6, step: 2137, cost: 7.423039, mlm loss: 7.423039, speed: 1.101700 steps/s, speed: 8.813602 samples/s, speed: 4512.564273 tokens/s, learning rate: 2.136e-05, loss_scalings: 3518.437988, pp_loss: 7.252480
[INFO] 2021-07-12 19:15:21,262 [run_pretraining.py:  512]:	********exe.run_2137******* 
[INFO] 2021-07-12 19:15:22,168 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:22,169 [run_pretraining.py:  534]:	loss/total_loss, 7.317893981933594, 2138
[INFO] 2021-07-12 19:15:22,169 [run_pretraining.py:  535]:	loss/mlm_loss, 7.317893981933594, 2138
[INFO] 2021-07-12 19:15:22,169 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1369998648879118e-05, 2138
[INFO] 2021-07-12 19:15:22,169 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2138
[INFO] 2021-07-12 19:15:22,169 [run_pretraining.py:  558]:	worker_index: 6, step: 2138, cost: 7.317894, mlm loss: 7.317894, speed: 1.102458 steps/s, speed: 8.819660 samples/s, speed: 4515.665954 tokens/s, learning rate: 2.137e-05, loss_scalings: 3518.437988, pp_loss: 7.508183
[INFO] 2021-07-12 19:15:22,169 [run_pretraining.py:  512]:	********exe.run_2138******* 
[INFO] 2021-07-12 19:15:23,083 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:23,084 [run_pretraining.py:  534]:	loss/total_loss, 7.307611465454102, 2139
[INFO] 2021-07-12 19:15:23,084 [run_pretraining.py:  535]:	loss/mlm_loss, 7.307611465454102, 2139
[INFO] 2021-07-12 19:15:23,084 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1379999452619813e-05, 2139
[INFO] 2021-07-12 19:15:23,084 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2139
[INFO] 2021-07-12 19:15:23,084 [run_pretraining.py:  558]:	worker_index: 6, step: 2139, cost: 7.307611, mlm loss: 7.307611, speed: 1.093672 steps/s, speed: 8.749373 samples/s, speed: 4479.679021 tokens/s, learning rate: 2.138e-05, loss_scalings: 3518.437988, pp_loss: 7.203085
[INFO] 2021-07-12 19:15:23,085 [run_pretraining.py:  512]:	********exe.run_2139******* 
[INFO] 2021-07-12 19:15:23,985 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:23,985 [run_pretraining.py:  534]:	loss/total_loss, 7.70281457901001, 2140
[INFO] 2021-07-12 19:15:23,986 [run_pretraining.py:  535]:	loss/mlm_loss, 7.70281457901001, 2140
[INFO] 2021-07-12 19:15:23,986 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.139000025636051e-05, 2140
[INFO] 2021-07-12 19:15:23,986 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2140
[INFO] 2021-07-12 19:15:23,986 [run_pretraining.py:  558]:	worker_index: 6, step: 2140, cost: 7.702815, mlm loss: 7.702815, speed: 1.110305 steps/s, speed: 8.882438 samples/s, speed: 4547.808388 tokens/s, learning rate: 2.139e-05, loss_scalings: 3518.437988, pp_loss: 7.292085
[INFO] 2021-07-12 19:15:23,986 [run_pretraining.py:  512]:	********exe.run_2140******* 
[INFO] 2021-07-12 19:15:24,888 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:24,889 [run_pretraining.py:  534]:	loss/total_loss, 7.179555892944336, 2141
[INFO] 2021-07-12 19:15:24,889 [run_pretraining.py:  535]:	loss/mlm_loss, 7.179555892944336, 2141
[INFO] 2021-07-12 19:15:24,889 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.13999992411118e-05, 2141
[INFO] 2021-07-12 19:15:24,889 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2141
[INFO] 2021-07-12 19:15:24,889 [run_pretraining.py:  558]:	worker_index: 6, step: 2141, cost: 7.179556, mlm loss: 7.179556, speed: 1.108077 steps/s, speed: 8.864618 samples/s, speed: 4538.684438 tokens/s, learning rate: 2.140e-05, loss_scalings: 3518.437988, pp_loss: 7.092694
[INFO] 2021-07-12 19:15:24,889 [run_pretraining.py:  512]:	********exe.run_2141******* 
[INFO] 2021-07-12 19:15:25,797 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:25,798 [run_pretraining.py:  534]:	loss/total_loss, 7.055846214294434, 2142
[INFO] 2021-07-12 19:15:25,798 [run_pretraining.py:  535]:	loss/mlm_loss, 7.055846214294434, 2142
[INFO] 2021-07-12 19:15:25,798 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1410000044852495e-05, 2142
[INFO] 2021-07-12 19:15:25,798 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2142
[INFO] 2021-07-12 19:15:25,798 [run_pretraining.py:  558]:	worker_index: 6, step: 2142, cost: 7.055846, mlm loss: 7.055846, speed: 1.100479 steps/s, speed: 8.803832 samples/s, speed: 4507.561948 tokens/s, learning rate: 2.141e-05, loss_scalings: 3518.437988, pp_loss: 7.155002
[INFO] 2021-07-12 19:15:25,798 [run_pretraining.py:  512]:	********exe.run_2142******* 
[INFO] 2021-07-12 19:15:26,704 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:26,705 [run_pretraining.py:  534]:	loss/total_loss, 7.033480644226074, 2143
[INFO] 2021-07-12 19:15:26,705 [run_pretraining.py:  535]:	loss/mlm_loss, 7.033480644226074, 2143
[INFO] 2021-07-12 19:15:26,705 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.142000084859319e-05, 2143
[INFO] 2021-07-12 19:15:26,705 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2143
[INFO] 2021-07-12 19:15:26,705 [run_pretraining.py:  558]:	worker_index: 6, step: 2143, cost: 7.033481, mlm loss: 7.033481, speed: 1.103856 steps/s, speed: 8.830850 samples/s, speed: 4521.395386 tokens/s, learning rate: 2.142e-05, loss_scalings: 3518.437988, pp_loss: 7.247307
[INFO] 2021-07-12 19:15:26,705 [run_pretraining.py:  512]:	********exe.run_2143******* 
[INFO] 2021-07-12 19:15:27,627 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:27,627 [run_pretraining.py:  534]:	loss/total_loss, 8.29419994354248, 2144
[INFO] 2021-07-12 19:15:27,627 [run_pretraining.py:  535]:	loss/mlm_loss, 8.29419994354248, 2144
[INFO] 2021-07-12 19:15:27,627 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1429999833344482e-05, 2144
[INFO] 2021-07-12 19:15:27,627 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2144
[INFO] 2021-07-12 19:15:27,628 [run_pretraining.py:  558]:	worker_index: 6, step: 2144, cost: 8.294200, mlm loss: 8.294200, speed: 1.084795 steps/s, speed: 8.678359 samples/s, speed: 4443.319745 tokens/s, learning rate: 2.143e-05, loss_scalings: 3518.437988, pp_loss: 7.479817
[INFO] 2021-07-12 19:15:27,628 [run_pretraining.py:  512]:	********exe.run_2144******* 
[INFO] 2021-07-12 19:15:28,532 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:28,533 [run_pretraining.py:  534]:	loss/total_loss, 7.534725666046143, 2145
[INFO] 2021-07-12 19:15:28,533 [run_pretraining.py:  535]:	loss/mlm_loss, 7.534725666046143, 2145
[INFO] 2021-07-12 19:15:28,533 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1439998818095773e-05, 2145
[INFO] 2021-07-12 19:15:28,533 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2145
[INFO] 2021-07-12 19:15:28,533 [run_pretraining.py:  558]:	worker_index: 6, step: 2145, cost: 7.534726, mlm loss: 7.534726, speed: 1.105313 steps/s, speed: 8.842502 samples/s, speed: 4527.361278 tokens/s, learning rate: 2.144e-05, loss_scalings: 3518.437988, pp_loss: 6.281411
[INFO] 2021-07-12 19:15:28,533 [run_pretraining.py:  512]:	********exe.run_2145******* 
[INFO] 2021-07-12 19:15:29,470 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:29,471 [run_pretraining.py:  534]:	loss/total_loss, 6.673501014709473, 2146
[INFO] 2021-07-12 19:15:29,471 [run_pretraining.py:  535]:	loss/mlm_loss, 6.673501014709473, 2146
[INFO] 2021-07-12 19:15:29,471 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.144999962183647e-05, 2146
[INFO] 2021-07-12 19:15:29,471 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2146
[INFO] 2021-07-12 19:15:29,471 [run_pretraining.py:  558]:	worker_index: 6, step: 2146, cost: 6.673501, mlm loss: 6.673501, speed: 1.066900 steps/s, speed: 8.535198 samples/s, speed: 4370.021320 tokens/s, learning rate: 2.145e-05, loss_scalings: 3518.437988, pp_loss: 6.321617
[INFO] 2021-07-12 19:15:29,471 [run_pretraining.py:  512]:	********exe.run_2146******* 
[INFO] 2021-07-12 19:15:30,400 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:30,401 [run_pretraining.py:  534]:	loss/total_loss, 7.572683334350586, 2147
[INFO] 2021-07-12 19:15:30,401 [run_pretraining.py:  535]:	loss/mlm_loss, 7.572683334350586, 2147
[INFO] 2021-07-12 19:15:30,401 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.145999860658776e-05, 2147
[INFO] 2021-07-12 19:15:30,401 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2147
[INFO] 2021-07-12 19:15:30,401 [run_pretraining.py:  558]:	worker_index: 6, step: 2147, cost: 7.572683, mlm loss: 7.572683, speed: 1.075854 steps/s, speed: 8.606832 samples/s, speed: 4406.698023 tokens/s, learning rate: 2.146e-05, loss_scalings: 3518.437988, pp_loss: 7.281512
[INFO] 2021-07-12 19:15:30,401 [run_pretraining.py:  512]:	********exe.run_2147******* 
[INFO] 2021-07-12 19:15:31,293 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:31,294 [run_pretraining.py:  534]:	loss/total_loss, 6.636105537414551, 2148
[INFO] 2021-07-12 19:15:31,294 [run_pretraining.py:  535]:	loss/mlm_loss, 6.636105537414551, 2148
[INFO] 2021-07-12 19:15:31,294 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1469999410328455e-05, 2148
[INFO] 2021-07-12 19:15:31,294 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2148
[INFO] 2021-07-12 19:15:31,294 [run_pretraining.py:  558]:	worker_index: 6, step: 2148, cost: 6.636106, mlm loss: 6.636106, speed: 1.120317 steps/s, speed: 8.962538 samples/s, speed: 4588.819218 tokens/s, learning rate: 2.147e-05, loss_scalings: 3518.437988, pp_loss: 6.222909
[INFO] 2021-07-12 19:15:31,295 [run_pretraining.py:  512]:	********exe.run_2148******* 
[INFO] 2021-07-12 19:15:32,202 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:32,203 [run_pretraining.py:  534]:	loss/total_loss, 6.954237937927246, 2149
[INFO] 2021-07-12 19:15:32,203 [run_pretraining.py:  535]:	loss/mlm_loss, 6.954237937927246, 2149
[INFO] 2021-07-12 19:15:32,203 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.148000021406915e-05, 2149
[INFO] 2021-07-12 19:15:32,203 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2149
[INFO] 2021-07-12 19:15:32,203 [run_pretraining.py:  558]:	worker_index: 6, step: 2149, cost: 6.954238, mlm loss: 6.954238, speed: 1.101619 steps/s, speed: 8.812954 samples/s, speed: 4512.232415 tokens/s, learning rate: 2.148e-05, loss_scalings: 3518.437988, pp_loss: 7.096393
[INFO] 2021-07-12 19:15:32,203 [run_pretraining.py:  512]:	********exe.run_2149******* 
[INFO] 2021-07-12 19:15:33,103 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:33,103 [run_pretraining.py:  534]:	loss/total_loss, 6.901356220245361, 2150
[INFO] 2021-07-12 19:15:33,103 [run_pretraining.py:  535]:	loss/mlm_loss, 6.901356220245361, 2150
[INFO] 2021-07-12 19:15:33,103 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1489999198820442e-05, 2150
[INFO] 2021-07-12 19:15:33,103 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2150
[INFO] 2021-07-12 19:15:33,104 [run_pretraining.py:  558]:	worker_index: 6, step: 2150, cost: 6.901356, mlm loss: 6.901356, speed: 1.111215 steps/s, speed: 8.889724 samples/s, speed: 4551.538669 tokens/s, learning rate: 2.149e-05, loss_scalings: 3518.437988, pp_loss: 7.025166
[INFO] 2021-07-12 19:15:33,104 [run_pretraining.py:  512]:	********exe.run_2150******* 
[INFO] 2021-07-12 19:15:34,000 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:34,000 [run_pretraining.py:  534]:	loss/total_loss, 7.947482109069824, 2151
[INFO] 2021-07-12 19:15:34,001 [run_pretraining.py:  535]:	loss/mlm_loss, 7.947482109069824, 2151
[INFO] 2021-07-12 19:15:34,001 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1500000002561137e-05, 2151
[INFO] 2021-07-12 19:15:34,001 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2151
[INFO] 2021-07-12 19:15:34,001 [run_pretraining.py:  558]:	worker_index: 6, step: 2151, cost: 7.947482, mlm loss: 7.947482, speed: 1.115376 steps/s, speed: 8.923009 samples/s, speed: 4568.580739 tokens/s, learning rate: 2.150e-05, loss_scalings: 3518.437988, pp_loss: 7.500028
[INFO] 2021-07-12 19:15:34,001 [run_pretraining.py:  512]:	********exe.run_2151******* 
[INFO] 2021-07-12 19:15:34,903 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:34,903 [run_pretraining.py:  534]:	loss/total_loss, 6.476335048675537, 2152
[INFO] 2021-07-12 19:15:34,903 [run_pretraining.py:  535]:	loss/mlm_loss, 6.476335048675537, 2152
[INFO] 2021-07-12 19:15:34,904 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1510000806301832e-05, 2152
[INFO] 2021-07-12 19:15:34,904 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2152
[INFO] 2021-07-12 19:15:34,904 [run_pretraining.py:  558]:	worker_index: 6, step: 2152, cost: 6.476335, mlm loss: 6.476335, speed: 1.108344 steps/s, speed: 8.866750 samples/s, speed: 4539.775843 tokens/s, learning rate: 2.151e-05, loss_scalings: 3518.437988, pp_loss: 7.070507
[INFO] 2021-07-12 19:15:34,904 [run_pretraining.py:  512]:	********exe.run_2152******* 
[INFO] 2021-07-12 19:15:35,814 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:35,814 [run_pretraining.py:  534]:	loss/total_loss, 7.431807041168213, 2153
[INFO] 2021-07-12 19:15:35,814 [run_pretraining.py:  535]:	loss/mlm_loss, 7.431807041168213, 2153
[INFO] 2021-07-12 19:15:35,815 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1519999791053124e-05, 2153
[INFO] 2021-07-12 19:15:35,815 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2153
[INFO] 2021-07-12 19:15:35,815 [run_pretraining.py:  558]:	worker_index: 6, step: 2153, cost: 7.431807, mlm loss: 7.431807, speed: 1.098596 steps/s, speed: 8.788769 samples/s, speed: 4499.849965 tokens/s, learning rate: 2.152e-05, loss_scalings: 3518.437988, pp_loss: 6.185215
[INFO] 2021-07-12 19:15:35,815 [run_pretraining.py:  512]:	********exe.run_2153******* 
[INFO] 2021-07-12 19:15:36,709 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:36,709 [run_pretraining.py:  534]:	loss/total_loss, 6.772356986999512, 2154
[INFO] 2021-07-12 19:15:36,709 [run_pretraining.py:  535]:	loss/mlm_loss, 6.772356986999512, 2154
[INFO] 2021-07-12 19:15:36,709 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1529998775804415e-05, 2154
[INFO] 2021-07-12 19:15:36,709 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2154
[INFO] 2021-07-12 19:15:36,709 [run_pretraining.py:  558]:	worker_index: 6, step: 2154, cost: 6.772357, mlm loss: 6.772357, speed: 1.118480 steps/s, speed: 8.947837 samples/s, speed: 4581.292341 tokens/s, learning rate: 2.153e-05, loss_scalings: 3518.437988, pp_loss: 7.257676
[INFO] 2021-07-12 19:15:36,710 [run_pretraining.py:  512]:	********exe.run_2154******* 
[INFO] 2021-07-12 19:15:37,623 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:37,624 [run_pretraining.py:  534]:	loss/total_loss, 7.140993118286133, 2155
[INFO] 2021-07-12 19:15:37,624 [run_pretraining.py:  535]:	loss/mlm_loss, 7.140993118286133, 2155
[INFO] 2021-07-12 19:15:37,624 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.153999957954511e-05, 2155
[INFO] 2021-07-12 19:15:37,624 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2155
[INFO] 2021-07-12 19:15:37,624 [run_pretraining.py:  558]:	worker_index: 6, step: 2155, cost: 7.140993, mlm loss: 7.140993, speed: 1.093929 steps/s, speed: 8.751434 samples/s, speed: 4480.734049 tokens/s, learning rate: 2.154e-05, loss_scalings: 3518.437988, pp_loss: 7.351188
[INFO] 2021-07-12 19:15:37,624 [run_pretraining.py:  512]:	********exe.run_2155******* 
[INFO] 2021-07-12 19:15:38,529 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:38,529 [run_pretraining.py:  534]:	loss/total_loss, 7.569605827331543, 2156
[INFO] 2021-07-12 19:15:38,530 [run_pretraining.py:  535]:	loss/mlm_loss, 7.569605827331543, 2156
[INFO] 2021-07-12 19:15:38,530 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1549998564296402e-05, 2156
[INFO] 2021-07-12 19:15:38,530 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2156
[INFO] 2021-07-12 19:15:38,530 [run_pretraining.py:  558]:	worker_index: 6, step: 2156, cost: 7.569606, mlm loss: 7.569606, speed: 1.105227 steps/s, speed: 8.841813 samples/s, speed: 4527.008153 tokens/s, learning rate: 2.155e-05, loss_scalings: 3518.437988, pp_loss: 7.197525
[INFO] 2021-07-12 19:15:38,530 [run_pretraining.py:  512]:	********exe.run_2156******* 
[INFO] 2021-07-12 19:15:39,445 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:39,446 [run_pretraining.py:  534]:	loss/total_loss, 7.185494422912598, 2157
[INFO] 2021-07-12 19:15:39,446 [run_pretraining.py:  535]:	loss/mlm_loss, 7.185494422912598, 2157
[INFO] 2021-07-12 19:15:39,446 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1559999368037097e-05, 2157
[INFO] 2021-07-12 19:15:39,446 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2157
[INFO] 2021-07-12 19:15:39,446 [run_pretraining.py:  558]:	worker_index: 6, step: 2157, cost: 7.185494, mlm loss: 7.185494, speed: 1.092218 steps/s, speed: 8.737744 samples/s, speed: 4473.725046 tokens/s, learning rate: 2.156e-05, loss_scalings: 3518.437988, pp_loss: 7.369661
[INFO] 2021-07-12 19:15:39,446 [run_pretraining.py:  512]:	********exe.run_2157******* 
[INFO] 2021-07-12 19:15:40,356 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:40,357 [run_pretraining.py:  534]:	loss/total_loss, 6.661255359649658, 2158
[INFO] 2021-07-12 19:15:40,357 [run_pretraining.py:  535]:	loss/mlm_loss, 6.661255359649658, 2158
[INFO] 2021-07-12 19:15:40,357 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1570000171777792e-05, 2158
[INFO] 2021-07-12 19:15:40,357 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2158
[INFO] 2021-07-12 19:15:40,357 [run_pretraining.py:  558]:	worker_index: 6, step: 2158, cost: 6.661255, mlm loss: 6.661255, speed: 1.098750 steps/s, speed: 8.790004 samples/s, speed: 4500.481797 tokens/s, learning rate: 2.157e-05, loss_scalings: 3518.437988, pp_loss: 7.185015
[INFO] 2021-07-12 19:15:40,357 [run_pretraining.py:  512]:	********exe.run_2158******* 
[INFO] 2021-07-12 19:15:41,280 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:41,280 [run_pretraining.py:  534]:	loss/total_loss, 7.341897010803223, 2159
[INFO] 2021-07-12 19:15:41,280 [run_pretraining.py:  535]:	loss/mlm_loss, 7.341897010803223, 2159
[INFO] 2021-07-12 19:15:41,280 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1579999156529084e-05, 2159
[INFO] 2021-07-12 19:15:41,280 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2159
[INFO] 2021-07-12 19:15:41,281 [run_pretraining.py:  558]:	worker_index: 6, step: 2159, cost: 7.341897, mlm loss: 7.341897, speed: 1.083624 steps/s, speed: 8.668989 samples/s, speed: 4438.522427 tokens/s, learning rate: 2.158e-05, loss_scalings: 3518.437988, pp_loss: 7.350971
[INFO] 2021-07-12 19:15:41,281 [run_pretraining.py:  512]:	********exe.run_2159******* 
[INFO] 2021-07-12 19:15:42,204 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:42,205 [run_pretraining.py:  534]:	loss/total_loss, 7.402570724487305, 2160
[INFO] 2021-07-12 19:15:42,205 [run_pretraining.py:  535]:	loss/mlm_loss, 7.402570724487305, 2160
[INFO] 2021-07-12 19:15:42,205 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.158999996026978e-05, 2160
[INFO] 2021-07-12 19:15:42,205 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2160
[INFO] 2021-07-12 19:15:42,205 [run_pretraining.py:  558]:	worker_index: 6, step: 2160, cost: 7.402571, mlm loss: 7.402571, speed: 1.082173 steps/s, speed: 8.657383 samples/s, speed: 4432.580069 tokens/s, learning rate: 2.159e-05, loss_scalings: 3518.437988, pp_loss: 7.441627
[INFO] 2021-07-12 19:15:42,205 [run_pretraining.py:  512]:	********exe.run_2160******* 
[INFO] 2021-07-12 19:15:43,118 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:43,119 [run_pretraining.py:  534]:	loss/total_loss, 6.914238452911377, 2161
[INFO] 2021-07-12 19:15:43,119 [run_pretraining.py:  535]:	loss/mlm_loss, 6.914238452911377, 2161
[INFO] 2021-07-12 19:15:43,119 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1600000764010474e-05, 2161
[INFO] 2021-07-12 19:15:43,119 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2161
[INFO] 2021-07-12 19:15:43,119 [run_pretraining.py:  558]:	worker_index: 6, step: 2161, cost: 6.914238, mlm loss: 6.914238, speed: 1.094792 steps/s, speed: 8.758337 samples/s, speed: 4484.268446 tokens/s, learning rate: 2.160e-05, loss_scalings: 3518.437988, pp_loss: 7.156794
[INFO] 2021-07-12 19:15:43,119 [run_pretraining.py:  512]:	********exe.run_2161******* 
[INFO] 2021-07-12 19:15:44,027 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:44,027 [run_pretraining.py:  534]:	loss/total_loss, 7.307559013366699, 2162
[INFO] 2021-07-12 19:15:44,027 [run_pretraining.py:  535]:	loss/mlm_loss, 7.307559013366699, 2162
[INFO] 2021-07-12 19:15:44,027 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1609999748761766e-05, 2162
[INFO] 2021-07-12 19:15:44,028 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2162
[INFO] 2021-07-12 19:15:44,028 [run_pretraining.py:  558]:	worker_index: 6, step: 2162, cost: 7.307559, mlm loss: 7.307559, speed: 1.101931 steps/s, speed: 8.815448 samples/s, speed: 4513.509152 tokens/s, learning rate: 2.161e-05, loss_scalings: 3518.437988, pp_loss: 7.317963
[INFO] 2021-07-12 19:15:44,028 [run_pretraining.py:  512]:	********exe.run_2162******* 
[INFO] 2021-07-12 19:15:44,964 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:44,965 [run_pretraining.py:  534]:	loss/total_loss, 6.863270282745361, 2163
[INFO] 2021-07-12 19:15:44,965 [run_pretraining.py:  535]:	loss/mlm_loss, 6.863270282745361, 2163
[INFO] 2021-07-12 19:15:44,965 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1619998733513057e-05, 2163
[INFO] 2021-07-12 19:15:44,965 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2163
[INFO] 2021-07-12 19:15:44,965 [run_pretraining.py:  558]:	worker_index: 6, step: 2163, cost: 6.863270, mlm loss: 6.863270, speed: 1.067123 steps/s, speed: 8.536981 samples/s, speed: 4370.934131 tokens/s, learning rate: 2.162e-05, loss_scalings: 3518.437988, pp_loss: 7.075362
[INFO] 2021-07-12 19:15:44,966 [run_pretraining.py:  512]:	********exe.run_2163******* 
[INFO] 2021-07-12 19:15:45,931 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:45,932 [run_pretraining.py:  534]:	loss/total_loss, 7.1972432136535645, 2164
[INFO] 2021-07-12 19:15:45,932 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1972432136535645, 2164
[INFO] 2021-07-12 19:15:45,932 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1629999537253752e-05, 2164
[INFO] 2021-07-12 19:15:45,932 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2164
[INFO] 2021-07-12 19:15:45,932 [run_pretraining.py:  558]:	worker_index: 6, step: 2164, cost: 7.197243, mlm loss: 7.197243, speed: 1.035201 steps/s, speed: 8.281606 samples/s, speed: 4240.182024 tokens/s, learning rate: 2.163e-05, loss_scalings: 3518.437988, pp_loss: 7.358364
[INFO] 2021-07-12 19:15:45,932 [run_pretraining.py:  512]:	********exe.run_2164******* 
[INFO] 2021-07-12 19:15:46,849 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:46,850 [run_pretraining.py:  534]:	loss/total_loss, 7.2906036376953125, 2165
[INFO] 2021-07-12 19:15:46,850 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2906036376953125, 2165
[INFO] 2021-07-12 19:15:46,850 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1639998522005044e-05, 2165
[INFO] 2021-07-12 19:15:46,850 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2165
[INFO] 2021-07-12 19:15:46,850 [run_pretraining.py:  558]:	worker_index: 6, step: 2165, cost: 7.290604, mlm loss: 7.290604, speed: 1.089930 steps/s, speed: 8.719443 samples/s, speed: 4464.354968 tokens/s, learning rate: 2.164e-05, loss_scalings: 3518.437988, pp_loss: 7.581943
[INFO] 2021-07-12 19:15:46,850 [run_pretraining.py:  512]:	********exe.run_2165******* 
[INFO] 2021-07-12 19:15:47,761 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:47,761 [run_pretraining.py:  534]:	loss/total_loss, 7.999497890472412, 2166
[INFO] 2021-07-12 19:15:47,761 [run_pretraining.py:  535]:	loss/mlm_loss, 7.999497890472412, 2166
[INFO] 2021-07-12 19:15:47,762 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.164999932574574e-05, 2166
[INFO] 2021-07-12 19:15:47,762 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2166
[INFO] 2021-07-12 19:15:47,762 [run_pretraining.py:  558]:	worker_index: 6, step: 2166, cost: 7.999498, mlm loss: 7.999498, speed: 1.097997 steps/s, speed: 8.783979 samples/s, speed: 4497.397402 tokens/s, learning rate: 2.165e-05, loss_scalings: 3518.437988, pp_loss: 7.424112
[INFO] 2021-07-12 19:15:47,762 [run_pretraining.py:  512]:	********exe.run_2166******* 
[INFO] 2021-07-12 19:15:48,673 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:48,673 [run_pretraining.py:  534]:	loss/total_loss, 7.113875389099121, 2167
[INFO] 2021-07-12 19:15:48,674 [run_pretraining.py:  535]:	loss/mlm_loss, 7.113875389099121, 2167
[INFO] 2021-07-12 19:15:48,674 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1660000129486434e-05, 2167
[INFO] 2021-07-12 19:15:48,674 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2167
[INFO] 2021-07-12 19:15:48,674 [run_pretraining.py:  558]:	worker_index: 6, step: 2167, cost: 7.113875, mlm loss: 7.113875, speed: 1.097229 steps/s, speed: 8.777835 samples/s, speed: 4494.251391 tokens/s, learning rate: 2.166e-05, loss_scalings: 3518.437988, pp_loss: 7.395682
[INFO] 2021-07-12 19:15:48,674 [run_pretraining.py:  512]:	********exe.run_2167******* 
[INFO] 2021-07-12 19:15:49,583 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:49,584 [run_pretraining.py:  534]:	loss/total_loss, 6.901937961578369, 2168
[INFO] 2021-07-12 19:15:49,584 [run_pretraining.py:  535]:	loss/mlm_loss, 6.901937961578369, 2168
[INFO] 2021-07-12 19:15:49,584 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1669999114237726e-05, 2168
[INFO] 2021-07-12 19:15:49,584 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2168
[INFO] 2021-07-12 19:15:49,584 [run_pretraining.py:  558]:	worker_index: 6, step: 2168, cost: 6.901938, mlm loss: 6.901938, speed: 1.099361 steps/s, speed: 8.794886 samples/s, speed: 4502.981396 tokens/s, learning rate: 2.167e-05, loss_scalings: 3518.437988, pp_loss: 7.078394
[INFO] 2021-07-12 19:15:49,584 [run_pretraining.py:  512]:	********exe.run_2168******* 
[INFO] 2021-07-12 19:15:50,490 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:50,491 [run_pretraining.py:  534]:	loss/total_loss, 7.6434173583984375, 2169
[INFO] 2021-07-12 19:15:50,491 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6434173583984375, 2169
[INFO] 2021-07-12 19:15:50,491 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.167999991797842e-05, 2169
[INFO] 2021-07-12 19:15:50,491 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2169
[INFO] 2021-07-12 19:15:50,491 [run_pretraining.py:  558]:	worker_index: 6, step: 2169, cost: 7.643417, mlm loss: 7.643417, speed: 1.103663 steps/s, speed: 8.829307 samples/s, speed: 4520.605404 tokens/s, learning rate: 2.168e-05, loss_scalings: 3518.437988, pp_loss: 7.513556
[INFO] 2021-07-12 19:15:50,491 [run_pretraining.py:  512]:	********exe.run_2169******* 
[INFO] 2021-07-12 19:15:51,400 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:51,401 [run_pretraining.py:  534]:	loss/total_loss, 6.98486852645874, 2170
[INFO] 2021-07-12 19:15:51,401 [run_pretraining.py:  535]:	loss/mlm_loss, 6.98486852645874, 2170
[INFO] 2021-07-12 19:15:51,401 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1690000721719116e-05, 2170
[INFO] 2021-07-12 19:15:51,401 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2170
[INFO] 2021-07-12 19:15:51,401 [run_pretraining.py:  558]:	worker_index: 6, step: 2170, cost: 6.984869, mlm loss: 6.984869, speed: 1.099170 steps/s, speed: 8.793357 samples/s, speed: 4502.199014 tokens/s, learning rate: 2.169e-05, loss_scalings: 3518.437988, pp_loss: 7.278730
[INFO] 2021-07-12 19:15:51,402 [run_pretraining.py:  512]:	********exe.run_2170******* 
[INFO] 2021-07-12 19:15:52,304 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:52,305 [run_pretraining.py:  534]:	loss/total_loss, 7.561983108520508, 2171
[INFO] 2021-07-12 19:15:52,305 [run_pretraining.py:  535]:	loss/mlm_loss, 7.561983108520508, 2171
[INFO] 2021-07-12 19:15:52,305 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1699997887481004e-05, 2171
[INFO] 2021-07-12 19:15:52,305 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2171
[INFO] 2021-07-12 19:15:52,305 [run_pretraining.py:  558]:	worker_index: 6, step: 2171, cost: 7.561983, mlm loss: 7.561983, speed: 1.107476 steps/s, speed: 8.859810 samples/s, speed: 4536.222909 tokens/s, learning rate: 2.170e-05, loss_scalings: 3518.437988, pp_loss: 7.415181
[INFO] 2021-07-12 19:15:52,305 [run_pretraining.py:  512]:	********exe.run_2171******* 
[INFO] 2021-07-12 19:15:53,244 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:53,244 [run_pretraining.py:  534]:	loss/total_loss, 6.648376941680908, 2172
[INFO] 2021-07-12 19:15:53,245 [run_pretraining.py:  535]:	loss/mlm_loss, 6.648376941680908, 2172
[INFO] 2021-07-12 19:15:53,245 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.17099986912217e-05, 2172
[INFO] 2021-07-12 19:15:53,245 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2172
[INFO] 2021-07-12 19:15:53,245 [run_pretraining.py:  558]:	worker_index: 6, step: 2172, cost: 6.648377, mlm loss: 6.648377, speed: 1.064924 steps/s, speed: 8.519393 samples/s, speed: 4361.929456 tokens/s, learning rate: 2.171e-05, loss_scalings: 3518.437988, pp_loss: 7.260278
[INFO] 2021-07-12 19:15:53,245 [run_pretraining.py:  512]:	********exe.run_2172******* 
[INFO] 2021-07-12 19:15:54,161 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:54,162 [run_pretraining.py:  534]:	loss/total_loss, 7.054812431335449, 2173
[INFO] 2021-07-12 19:15:54,162 [run_pretraining.py:  535]:	loss/mlm_loss, 7.054812431335449, 2173
[INFO] 2021-07-12 19:15:54,162 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1719999494962394e-05, 2173
[INFO] 2021-07-12 19:15:54,162 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2173
[INFO] 2021-07-12 19:15:54,162 [run_pretraining.py:  558]:	worker_index: 6, step: 2173, cost: 7.054812, mlm loss: 7.054812, speed: 1.090872 steps/s, speed: 8.726975 samples/s, speed: 4468.211007 tokens/s, learning rate: 2.172e-05, loss_scalings: 3518.437988, pp_loss: 6.878622
[INFO] 2021-07-12 19:15:54,162 [run_pretraining.py:  512]:	********exe.run_2173******* 
[INFO] 2021-07-12 19:15:55,068 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:55,069 [run_pretraining.py:  534]:	loss/total_loss, 7.162868022918701, 2174
[INFO] 2021-07-12 19:15:55,069 [run_pretraining.py:  535]:	loss/mlm_loss, 7.162868022918701, 2174
[INFO] 2021-07-12 19:15:55,069 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1729998479713686e-05, 2174
[INFO] 2021-07-12 19:15:55,069 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2174
[INFO] 2021-07-12 19:15:55,069 [run_pretraining.py:  558]:	worker_index: 6, step: 2174, cost: 7.162868, mlm loss: 7.162868, speed: 1.103593 steps/s, speed: 8.828741 samples/s, speed: 4520.315178 tokens/s, learning rate: 2.173e-05, loss_scalings: 3518.437988, pp_loss: 7.619208
[INFO] 2021-07-12 19:15:55,069 [run_pretraining.py:  512]:	********exe.run_2174******* 
[INFO] 2021-07-12 19:15:55,977 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:55,978 [run_pretraining.py:  534]:	loss/total_loss, 7.313039302825928, 2175
[INFO] 2021-07-12 19:15:55,978 [run_pretraining.py:  535]:	loss/mlm_loss, 7.313039302825928, 2175
[INFO] 2021-07-12 19:15:55,978 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.173999928345438e-05, 2175
[INFO] 2021-07-12 19:15:55,978 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2175
[INFO] 2021-07-12 19:15:55,978 [run_pretraining.py:  558]:	worker_index: 6, step: 2175, cost: 7.313039, mlm loss: 7.313039, speed: 1.100888 steps/s, speed: 8.807102 samples/s, speed: 4509.236047 tokens/s, learning rate: 2.174e-05, loss_scalings: 3518.437988, pp_loss: 7.380243
[INFO] 2021-07-12 19:15:55,978 [run_pretraining.py:  512]:	********exe.run_2175******* 
[INFO] 2021-07-12 19:15:56,884 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:56,885 [run_pretraining.py:  534]:	loss/total_loss, 6.05100154876709, 2176
[INFO] 2021-07-12 19:15:56,885 [run_pretraining.py:  535]:	loss/mlm_loss, 6.05100154876709, 2176
[INFO] 2021-07-12 19:15:56,885 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1750000087195076e-05, 2176
[INFO] 2021-07-12 19:15:56,885 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2176
[INFO] 2021-07-12 19:15:56,885 [run_pretraining.py:  558]:	worker_index: 6, step: 2176, cost: 6.051002, mlm loss: 6.051002, speed: 1.103174 steps/s, speed: 8.825394 samples/s, speed: 4518.601943 tokens/s, learning rate: 2.175e-05, loss_scalings: 3518.437988, pp_loss: 6.403801
[INFO] 2021-07-12 19:15:56,885 [run_pretraining.py:  512]:	********exe.run_2176******* 
[INFO] 2021-07-12 19:15:57,790 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:57,791 [run_pretraining.py:  534]:	loss/total_loss, 7.013345241546631, 2177
[INFO] 2021-07-12 19:15:57,791 [run_pretraining.py:  535]:	loss/mlm_loss, 7.013345241546631, 2177
[INFO] 2021-07-12 19:15:57,791 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1759999071946368e-05, 2177
[INFO] 2021-07-12 19:15:57,791 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2177
[INFO] 2021-07-12 19:15:57,791 [run_pretraining.py:  558]:	worker_index: 6, step: 2177, cost: 7.013345, mlm loss: 7.013345, speed: 1.104532 steps/s, speed: 8.836257 samples/s, speed: 4524.163691 tokens/s, learning rate: 2.176e-05, loss_scalings: 3518.437988, pp_loss: 7.020216
[INFO] 2021-07-12 19:15:57,791 [run_pretraining.py:  512]:	********exe.run_2177******* 
[INFO] 2021-07-12 19:15:58,697 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:58,698 [run_pretraining.py:  534]:	loss/total_loss, 7.365976810455322, 2178
[INFO] 2021-07-12 19:15:58,698 [run_pretraining.py:  535]:	loss/mlm_loss, 7.365976810455322, 2178
[INFO] 2021-07-12 19:15:58,698 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1769999875687063e-05, 2178
[INFO] 2021-07-12 19:15:58,698 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2178
[INFO] 2021-07-12 19:15:58,698 [run_pretraining.py:  558]:	worker_index: 6, step: 2178, cost: 7.365977, mlm loss: 7.365977, speed: 1.103758 steps/s, speed: 8.830067 samples/s, speed: 4520.994412 tokens/s, learning rate: 2.177e-05, loss_scalings: 3518.437988, pp_loss: 7.402296
[INFO] 2021-07-12 19:15:58,698 [run_pretraining.py:  512]:	********exe.run_2178******* 
[INFO] 2021-07-12 19:15:59,607 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:59,608 [run_pretraining.py:  534]:	loss/total_loss, 6.7297468185424805, 2179
[INFO] 2021-07-12 19:15:59,608 [run_pretraining.py:  535]:	loss/mlm_loss, 6.7297468185424805, 2179
[INFO] 2021-07-12 19:15:59,608 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1780000679427758e-05, 2179
[INFO] 2021-07-12 19:15:59,608 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2179
[INFO] 2021-07-12 19:15:59,608 [run_pretraining.py:  558]:	worker_index: 6, step: 2179, cost: 6.729747, mlm loss: 6.729747, speed: 1.099493 steps/s, speed: 8.795946 samples/s, speed: 4503.524384 tokens/s, learning rate: 2.178e-05, loss_scalings: 3518.437988, pp_loss: 7.339391
[INFO] 2021-07-12 19:15:59,608 [run_pretraining.py:  512]:	********exe.run_2179******* 
[INFO] 2021-07-12 19:16:00,524 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:00,525 [run_pretraining.py:  534]:	loss/total_loss, 8.157854080200195, 2180
[INFO] 2021-07-12 19:16:00,525 [run_pretraining.py:  535]:	loss/mlm_loss, 8.157854080200195, 2180
[INFO] 2021-07-12 19:16:00,525 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.178999966417905e-05, 2180
[INFO] 2021-07-12 19:16:00,525 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2180
[INFO] 2021-07-12 19:16:00,525 [run_pretraining.py:  558]:	worker_index: 6, step: 2180, cost: 8.157854, mlm loss: 8.157854, speed: 1.091493 steps/s, speed: 8.731941 samples/s, speed: 4470.753990 tokens/s, learning rate: 2.179e-05, loss_scalings: 3518.437988, pp_loss: 6.728819
[INFO] 2021-07-12 19:16:00,525 [run_pretraining.py:  512]:	********exe.run_2180******* 
[INFO] 2021-07-12 19:16:01,431 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:01,432 [run_pretraining.py:  534]:	loss/total_loss, 7.247042655944824, 2181
[INFO] 2021-07-12 19:16:01,432 [run_pretraining.py:  535]:	loss/mlm_loss, 7.247042655944824, 2181
[INFO] 2021-07-12 19:16:01,432 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.179999864893034e-05, 2181
[INFO] 2021-07-12 19:16:01,432 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2181
[INFO] 2021-07-12 19:16:01,432 [run_pretraining.py:  558]:	worker_index: 6, step: 2181, cost: 7.247043, mlm loss: 7.247043, speed: 1.103285 steps/s, speed: 8.826277 samples/s, speed: 4519.053607 tokens/s, learning rate: 2.180e-05, loss_scalings: 3518.437988, pp_loss: 7.344165
[INFO] 2021-07-12 19:16:01,432 [run_pretraining.py:  512]:	********exe.run_2181******* 
[INFO] 2021-07-12 19:16:02,339 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:02,340 [run_pretraining.py:  534]:	loss/total_loss, 7.384479999542236, 2182
[INFO] 2021-07-12 19:16:02,340 [run_pretraining.py:  535]:	loss/mlm_loss, 7.384479999542236, 2182
[INFO] 2021-07-12 19:16:02,340 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1809999452671036e-05, 2182
[INFO] 2021-07-12 19:16:02,340 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2182
[INFO] 2021-07-12 19:16:02,340 [run_pretraining.py:  558]:	worker_index: 6, step: 2182, cost: 7.384480, mlm loss: 7.384480, speed: 1.102215 steps/s, speed: 8.817718 samples/s, speed: 4514.671529 tokens/s, learning rate: 2.181e-05, loss_scalings: 3518.437988, pp_loss: 6.784353
[INFO] 2021-07-12 19:16:02,340 [run_pretraining.py:  512]:	********exe.run_2182******* 
[INFO] 2021-07-12 19:16:03,245 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:03,245 [run_pretraining.py:  534]:	loss/total_loss, 7.528778553009033, 2183
[INFO] 2021-07-12 19:16:03,245 [run_pretraining.py:  535]:	loss/mlm_loss, 7.528778553009033, 2183
[INFO] 2021-07-12 19:16:03,246 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1819998437422328e-05, 2183
[INFO] 2021-07-12 19:16:03,246 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2183
[INFO] 2021-07-12 19:16:03,246 [run_pretraining.py:  558]:	worker_index: 6, step: 2183, cost: 7.528779, mlm loss: 7.528779, speed: 1.105166 steps/s, speed: 8.841328 samples/s, speed: 4526.760044 tokens/s, learning rate: 2.182e-05, loss_scalings: 3518.437988, pp_loss: 6.524065
[INFO] 2021-07-12 19:16:03,246 [run_pretraining.py:  512]:	********exe.run_2183******* 
[INFO] 2021-07-12 19:16:04,160 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:04,161 [run_pretraining.py:  534]:	loss/total_loss, 7.383547306060791, 2184
[INFO] 2021-07-12 19:16:04,161 [run_pretraining.py:  535]:	loss/mlm_loss, 7.383547306060791, 2184
[INFO] 2021-07-12 19:16:04,161 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1829999241163023e-05, 2184
[INFO] 2021-07-12 19:16:04,161 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2184
[INFO] 2021-07-12 19:16:04,161 [run_pretraining.py:  558]:	worker_index: 6, step: 2184, cost: 7.383547, mlm loss: 7.383547, speed: 1.093190 steps/s, speed: 8.745521 samples/s, speed: 4477.706996 tokens/s, learning rate: 2.183e-05, loss_scalings: 3518.437988, pp_loss: 7.239421
[INFO] 2021-07-12 19:16:04,161 [run_pretraining.py:  512]:	********exe.run_2184******* 
[INFO] 2021-07-12 19:16:05,075 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:05,075 [run_pretraining.py:  534]:	loss/total_loss, 4.874091625213623, 2185
[INFO] 2021-07-12 19:16:05,075 [run_pretraining.py:  535]:	loss/mlm_loss, 4.874091625213623, 2185
[INFO] 2021-07-12 19:16:05,075 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1840000044903718e-05, 2185
[INFO] 2021-07-12 19:16:05,075 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2185
[INFO] 2021-07-12 19:16:05,076 [run_pretraining.py:  558]:	worker_index: 6, step: 2185, cost: 4.874092, mlm loss: 4.874092, speed: 1.094583 steps/s, speed: 8.756664 samples/s, speed: 4483.411820 tokens/s, learning rate: 2.184e-05, loss_scalings: 3518.437988, pp_loss: 6.650501
[INFO] 2021-07-12 19:16:05,076 [run_pretraining.py:  512]:	********exe.run_2185******* 
[INFO] 2021-07-12 19:16:06,036 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:06,042 [run_pretraining.py:  534]:	loss/total_loss, 7.041747570037842, 2186
[INFO] 2021-07-12 19:16:06,047 [run_pretraining.py:  535]:	loss/mlm_loss, 7.041747570037842, 2186
[INFO] 2021-07-12 19:16:06,052 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.184999902965501e-05, 2186
[INFO] 2021-07-12 19:16:06,057 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2186
[INFO] 2021-07-12 19:16:06,063 [run_pretraining.py:  558]:	worker_index: 6, step: 2186, cost: 7.041748, mlm loss: 7.041748, speed: 1.035133 steps/s, speed: 8.281062 samples/s, speed: 4239.903667 tokens/s, learning rate: 2.185e-05, loss_scalings: 3518.437988, pp_loss: 6.676921
[INFO] 2021-07-12 19:16:06,068 [run_pretraining.py:  512]:	********exe.run_2186******* 
[INFO] 2021-07-12 19:16:06,938 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:06,938 [run_pretraining.py:  534]:	loss/total_loss, 3.9514272212982178, 2187
[INFO] 2021-07-12 19:16:06,938 [run_pretraining.py:  535]:	loss/mlm_loss, 3.9514272212982178, 2187
[INFO] 2021-07-12 19:16:06,939 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1859999833395705e-05, 2187
[INFO] 2021-07-12 19:16:06,939 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2187
[INFO] 2021-07-12 19:16:06,939 [run_pretraining.py:  558]:	worker_index: 6, step: 2187, cost: 3.951427, mlm loss: 3.951427, speed: 1.149033 steps/s, speed: 9.192262 samples/s, speed: 4706.438249 tokens/s, learning rate: 2.186e-05, loss_scalings: 3518.437988, pp_loss: 6.539656
[INFO] 2021-07-12 19:16:06,939 [run_pretraining.py:  512]:	********exe.run_2187******* 
[INFO] 2021-07-12 19:16:07,851 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:07,852 [run_pretraining.py:  534]:	loss/total_loss, 6.719881534576416, 2188
[INFO] 2021-07-12 19:16:07,852 [run_pretraining.py:  535]:	loss/mlm_loss, 6.719881534576416, 2188
[INFO] 2021-07-12 19:16:07,852 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.18700006371364e-05, 2188
[INFO] 2021-07-12 19:16:07,852 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2188
[INFO] 2021-07-12 19:16:07,852 [run_pretraining.py:  558]:	worker_index: 6, step: 2188, cost: 6.719882, mlm loss: 6.719882, speed: 1.095823 steps/s, speed: 8.766584 samples/s, speed: 4488.490822 tokens/s, learning rate: 2.187e-05, loss_scalings: 3518.437988, pp_loss: 7.089759
[INFO] 2021-07-12 19:16:07,852 [run_pretraining.py:  512]:	********exe.run_2188******* 
[INFO] 2021-07-12 19:16:08,760 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:08,760 [run_pretraining.py:  534]:	loss/total_loss, 7.417400360107422, 2189
[INFO] 2021-07-12 19:16:08,760 [run_pretraining.py:  535]:	loss/mlm_loss, 7.417400360107422, 2189
[INFO] 2021-07-12 19:16:08,760 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.187999962188769e-05, 2189
[INFO] 2021-07-12 19:16:08,760 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2189
[INFO] 2021-07-12 19:16:08,761 [run_pretraining.py:  558]:	worker_index: 6, step: 2189, cost: 7.417400, mlm loss: 7.417400, speed: 1.101485 steps/s, speed: 8.811882 samples/s, speed: 4511.683770 tokens/s, learning rate: 2.188e-05, loss_scalings: 3518.437988, pp_loss: 7.586626
[INFO] 2021-07-12 19:16:08,761 [run_pretraining.py:  512]:	********exe.run_2189******* 
[INFO] 2021-07-12 19:16:09,766 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:09,766 [run_pretraining.py:  534]:	loss/total_loss, 7.546467304229736, 2190
[INFO] 2021-07-12 19:16:09,766 [run_pretraining.py:  535]:	loss/mlm_loss, 7.546467304229736, 2190
[INFO] 2021-07-12 19:16:09,766 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1889998606638983e-05, 2190
[INFO] 2021-07-12 19:16:09,766 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2190
[INFO] 2021-07-12 19:16:09,767 [run_pretraining.py:  558]:	worker_index: 6, step: 2190, cost: 7.546467, mlm loss: 7.546467, speed: 0.994725 steps/s, speed: 7.957799 samples/s, speed: 4074.392906 tokens/s, learning rate: 2.189e-05, loss_scalings: 3518.437988, pp_loss: 8.046200
[INFO] 2021-07-12 19:16:09,767 [run_pretraining.py:  512]:	********exe.run_2190******* 
[INFO] 2021-07-12 19:16:10,666 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:10,667 [run_pretraining.py:  534]:	loss/total_loss, 7.161994934082031, 2191
[INFO] 2021-07-12 19:16:10,667 [run_pretraining.py:  535]:	loss/mlm_loss, 7.161994934082031, 2191
[INFO] 2021-07-12 19:16:10,667 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1899999410379678e-05, 2191
[INFO] 2021-07-12 19:16:10,667 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2191
[INFO] 2021-07-12 19:16:10,667 [run_pretraining.py:  558]:	worker_index: 6, step: 2191, cost: 7.161995, mlm loss: 7.161995, speed: 1.110958 steps/s, speed: 8.887661 samples/s, speed: 4550.482581 tokens/s, learning rate: 2.190e-05, loss_scalings: 3518.437988, pp_loss: 6.537923
[INFO] 2021-07-12 19:16:10,667 [run_pretraining.py:  512]:	********exe.run_2191******* 
[INFO] 2021-07-12 19:16:11,580 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:11,581 [run_pretraining.py:  534]:	loss/total_loss, 7.300689220428467, 2192
[INFO] 2021-07-12 19:16:11,581 [run_pretraining.py:  535]:	loss/mlm_loss, 7.300689220428467, 2192
[INFO] 2021-07-12 19:16:11,581 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.190999839513097e-05, 2192
[INFO] 2021-07-12 19:16:11,581 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2192
[INFO] 2021-07-12 19:16:11,581 [run_pretraining.py:  558]:	worker_index: 6, step: 2192, cost: 7.300689, mlm loss: 7.300689, speed: 1.095461 steps/s, speed: 8.763687 samples/s, speed: 4487.007867 tokens/s, learning rate: 2.191e-05, loss_scalings: 3518.437988, pp_loss: 7.175177
[INFO] 2021-07-12 19:16:11,581 [run_pretraining.py:  512]:	********exe.run_2192******* 
[INFO] 2021-07-12 19:16:12,493 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:12,493 [run_pretraining.py:  534]:	loss/total_loss, 4.793027400970459, 2193
[INFO] 2021-07-12 19:16:12,494 [run_pretraining.py:  535]:	loss/mlm_loss, 4.793027400970459, 2193
[INFO] 2021-07-12 19:16:12,494 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1919999198871665e-05, 2193
[INFO] 2021-07-12 19:16:12,494 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2193
[INFO] 2021-07-12 19:16:12,494 [run_pretraining.py:  558]:	worker_index: 6, step: 2193, cost: 4.793027, mlm loss: 4.793027, speed: 1.096312 steps/s, speed: 8.770497 samples/s, speed: 4490.494660 tokens/s, learning rate: 2.192e-05, loss_scalings: 3518.437988, pp_loss: 6.664132
[INFO] 2021-07-12 19:16:12,494 [run_pretraining.py:  512]:	********exe.run_2193******* 
[INFO] 2021-07-12 19:16:13,404 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:13,405 [run_pretraining.py:  534]:	loss/total_loss, 7.586551666259766, 2194
[INFO] 2021-07-12 19:16:13,405 [run_pretraining.py:  535]:	loss/mlm_loss, 7.586551666259766, 2194
[INFO] 2021-07-12 19:16:13,405 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.193000000261236e-05, 2194
[INFO] 2021-07-12 19:16:13,405 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2194
[INFO] 2021-07-12 19:16:13,405 [run_pretraining.py:  558]:	worker_index: 6, step: 2194, cost: 7.586552, mlm loss: 7.586552, speed: 1.098392 steps/s, speed: 8.787140 samples/s, speed: 4499.015652 tokens/s, learning rate: 2.193e-05, loss_scalings: 3518.437988, pp_loss: 6.898499
[INFO] 2021-07-12 19:16:13,405 [run_pretraining.py:  512]:	********exe.run_2194******* 
[INFO] 2021-07-12 19:16:14,316 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:14,317 [run_pretraining.py:  534]:	loss/total_loss, 8.232931137084961, 2195
[INFO] 2021-07-12 19:16:14,317 [run_pretraining.py:  535]:	loss/mlm_loss, 8.232931137084961, 2195
[INFO] 2021-07-12 19:16:14,317 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.193999898736365e-05, 2195
[INFO] 2021-07-12 19:16:14,317 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2195
[INFO] 2021-07-12 19:16:14,317 [run_pretraining.py:  558]:	worker_index: 6, step: 2195, cost: 8.232931, mlm loss: 8.232931, speed: 1.096745 steps/s, speed: 8.773958 samples/s, speed: 4492.266518 tokens/s, learning rate: 2.194e-05, loss_scalings: 3518.437988, pp_loss: 7.888370
[INFO] 2021-07-12 19:16:14,317 [run_pretraining.py:  512]:	********exe.run_2195******* 
[INFO] 2021-07-12 19:16:15,233 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:15,233 [run_pretraining.py:  534]:	loss/total_loss, 7.400254249572754, 2196
[INFO] 2021-07-12 19:16:15,234 [run_pretraining.py:  535]:	loss/mlm_loss, 7.400254249572754, 2196
[INFO] 2021-07-12 19:16:15,234 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1949999791104347e-05, 2196
[INFO] 2021-07-12 19:16:15,234 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2196
[INFO] 2021-07-12 19:16:15,234 [run_pretraining.py:  558]:	worker_index: 6, step: 2196, cost: 7.400254, mlm loss: 7.400254, speed: 1.092052 steps/s, speed: 8.736416 samples/s, speed: 4473.044801 tokens/s, learning rate: 2.195e-05, loss_scalings: 3518.437988, pp_loss: 7.433371
[INFO] 2021-07-12 19:16:15,234 [run_pretraining.py:  512]:	********exe.run_2196******* 
[INFO] 2021-07-12 19:16:16,134 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:16,135 [run_pretraining.py:  534]:	loss/total_loss, 7.682313919067383, 2197
[INFO] 2021-07-12 19:16:16,135 [run_pretraining.py:  535]:	loss/mlm_loss, 7.682313919067383, 2197
[INFO] 2021-07-12 19:16:16,135 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.196000059484504e-05, 2197
[INFO] 2021-07-12 19:16:16,135 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2197
[INFO] 2021-07-12 19:16:16,135 [run_pretraining.py:  558]:	worker_index: 6, step: 2197, cost: 7.682314, mlm loss: 7.682314, speed: 1.110018 steps/s, speed: 8.880146 samples/s, speed: 4546.634905 tokens/s, learning rate: 2.196e-05, loss_scalings: 3518.437988, pp_loss: 7.412523
[INFO] 2021-07-12 19:16:16,135 [run_pretraining.py:  512]:	********exe.run_2197******* 
[INFO] 2021-07-12 19:16:17,056 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:17,057 [run_pretraining.py:  534]:	loss/total_loss, 8.174973487854004, 2198
[INFO] 2021-07-12 19:16:17,057 [run_pretraining.py:  535]:	loss/mlm_loss, 8.174973487854004, 2198
[INFO] 2021-07-12 19:16:17,057 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1969999579596333e-05, 2198
[INFO] 2021-07-12 19:16:17,057 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2198
[INFO] 2021-07-12 19:16:17,057 [run_pretraining.py:  558]:	worker_index: 6, step: 2198, cost: 8.174973, mlm loss: 8.174973, speed: 1.085475 steps/s, speed: 8.683796 samples/s, speed: 4446.103699 tokens/s, learning rate: 2.197e-05, loss_scalings: 3518.437988, pp_loss: 8.303357
[INFO] 2021-07-12 19:16:17,057 [run_pretraining.py:  512]:	********exe.run_2198******* 
[INFO] 2021-07-12 19:16:17,966 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:17,966 [run_pretraining.py:  534]:	loss/total_loss, 7.4726996421813965, 2199
[INFO] 2021-07-12 19:16:17,966 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4726996421813965, 2199
[INFO] 2021-07-12 19:16:17,966 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1979998564347625e-05, 2199
[INFO] 2021-07-12 19:16:17,966 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2199
[INFO] 2021-07-12 19:16:17,967 [run_pretraining.py:  558]:	worker_index: 6, step: 2199, cost: 7.472700, mlm loss: 7.472700, speed: 1.100670 steps/s, speed: 8.805364 samples/s, speed: 4508.346194 tokens/s, learning rate: 2.198e-05, loss_scalings: 3518.437988, pp_loss: 7.668822
[INFO] 2021-07-12 19:16:17,967 [run_pretraining.py:  512]:	********exe.run_2199******* 
[INFO] 2021-07-12 19:16:18,881 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:18,882 [run_pretraining.py:  534]:	loss/total_loss, 8.174394607543945, 2200
[INFO] 2021-07-12 19:16:18,882 [run_pretraining.py:  535]:	loss/mlm_loss, 8.174394607543945, 2200
[INFO] 2021-07-12 19:16:18,882 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.198999936808832e-05, 2200
[INFO] 2021-07-12 19:16:18,882 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2200
[INFO] 2021-07-12 19:16:18,882 [run_pretraining.py:  558]:	worker_index: 6, step: 2200, cost: 8.174395, mlm loss: 8.174395, speed: 1.092752 steps/s, speed: 8.742013 samples/s, speed: 4475.910452 tokens/s, learning rate: 2.199e-05, loss_scalings: 3518.437988, pp_loss: 7.377337
[INFO] 2021-07-12 19:16:18,883 [run_pretraining.py:  512]:	********exe.run_2200******* 
[INFO] 2021-07-12 19:16:19,788 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:19,789 [run_pretraining.py:  534]:	loss/total_loss, 6.801225185394287, 2201
[INFO] 2021-07-12 19:16:19,789 [run_pretraining.py:  535]:	loss/mlm_loss, 6.801225185394287, 2201
[INFO] 2021-07-12 19:16:19,789 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2000000171829015e-05, 2201
[INFO] 2021-07-12 19:16:19,789 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2201
[INFO] 2021-07-12 19:16:19,789 [run_pretraining.py:  558]:	worker_index: 6, step: 2201, cost: 6.801225, mlm loss: 6.801225, speed: 1.103583 steps/s, speed: 8.828666 samples/s, speed: 4520.277119 tokens/s, learning rate: 2.200e-05, loss_scalings: 3518.437988, pp_loss: 6.245523
[INFO] 2021-07-12 19:16:19,789 [run_pretraining.py:  512]:	********exe.run_2201******* 
[INFO] 2021-07-12 19:16:20,730 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:20,731 [run_pretraining.py:  534]:	loss/total_loss, 7.389307022094727, 2202
[INFO] 2021-07-12 19:16:20,731 [run_pretraining.py:  535]:	loss/mlm_loss, 7.389307022094727, 2202
[INFO] 2021-07-12 19:16:20,731 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2009999156580307e-05, 2202
[INFO] 2021-07-12 19:16:20,731 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2202
[INFO] 2021-07-12 19:16:20,731 [run_pretraining.py:  558]:	worker_index: 6, step: 2202, cost: 7.389307, mlm loss: 7.389307, speed: 1.062292 steps/s, speed: 8.498334 samples/s, speed: 4351.147132 tokens/s, learning rate: 2.201e-05, loss_scalings: 3518.437988, pp_loss: 7.203298
[INFO] 2021-07-12 19:16:20,731 [run_pretraining.py:  512]:	********exe.run_2202******* 
[INFO] 2021-07-12 19:16:21,669 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:21,669 [run_pretraining.py:  534]:	loss/total_loss, 8.138607025146484, 2203
[INFO] 2021-07-12 19:16:21,670 [run_pretraining.py:  535]:	loss/mlm_loss, 8.138607025146484, 2203
[INFO] 2021-07-12 19:16:21,670 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2019999960321002e-05, 2203
[INFO] 2021-07-12 19:16:21,670 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2203
[INFO] 2021-07-12 19:16:21,670 [run_pretraining.py:  558]:	worker_index: 6, step: 2203, cost: 8.138607, mlm loss: 8.138607, speed: 1.066381 steps/s, speed: 8.531047 samples/s, speed: 4367.895869 tokens/s, learning rate: 2.202e-05, loss_scalings: 3518.437988, pp_loss: 7.422802
[INFO] 2021-07-12 19:16:21,670 [run_pretraining.py:  512]:	********exe.run_2203******* 
[INFO] 2021-07-12 19:16:22,573 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:22,573 [run_pretraining.py:  534]:	loss/total_loss, 7.4980340003967285, 2204
[INFO] 2021-07-12 19:16:22,573 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4980340003967285, 2204
[INFO] 2021-07-12 19:16:22,574 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2029998945072293e-05, 2204
[INFO] 2021-07-12 19:16:22,574 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2204
[INFO] 2021-07-12 19:16:22,574 [run_pretraining.py:  558]:	worker_index: 6, step: 2204, cost: 7.498034, mlm loss: 7.498034, speed: 1.107128 steps/s, speed: 8.857025 samples/s, speed: 4534.796828 tokens/s, learning rate: 2.203e-05, loss_scalings: 3518.437988, pp_loss: 7.336750
[INFO] 2021-07-12 19:16:22,574 [run_pretraining.py:  512]:	********exe.run_2204******* 
[INFO] 2021-07-12 19:16:23,488 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:23,489 [run_pretraining.py:  534]:	loss/total_loss, 7.779811859130859, 2205
[INFO] 2021-07-12 19:16:23,489 [run_pretraining.py:  535]:	loss/mlm_loss, 7.779811859130859, 2205
[INFO] 2021-07-12 19:16:23,489 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.203999974881299e-05, 2205
[INFO] 2021-07-12 19:16:23,489 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2205
[INFO] 2021-07-12 19:16:23,489 [run_pretraining.py:  558]:	worker_index: 6, step: 2205, cost: 7.779812, mlm loss: 7.779812, speed: 1.092856 steps/s, speed: 8.742851 samples/s, speed: 4476.339625 tokens/s, learning rate: 2.204e-05, loss_scalings: 3518.437988, pp_loss: 7.158136
[INFO] 2021-07-12 19:16:23,490 [run_pretraining.py:  512]:	********exe.run_2205******* 
[INFO] 2021-07-12 19:16:24,399 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:24,399 [run_pretraining.py:  534]:	loss/total_loss, 7.242867469787598, 2206
[INFO] 2021-07-12 19:16:24,399 [run_pretraining.py:  535]:	loss/mlm_loss, 7.242867469787598, 2206
[INFO] 2021-07-12 19:16:24,399 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2050000552553684e-05, 2206
[INFO] 2021-07-12 19:16:24,399 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2206
[INFO] 2021-07-12 19:16:24,400 [run_pretraining.py:  558]:	worker_index: 6, step: 2206, cost: 7.242867, mlm loss: 7.242867, speed: 1.099705 steps/s, speed: 8.797639 samples/s, speed: 4504.391076 tokens/s, learning rate: 2.205e-05, loss_scalings: 3518.437988, pp_loss: 7.139802
[INFO] 2021-07-12 19:16:24,400 [run_pretraining.py:  512]:	********exe.run_2206******* 
[INFO] 2021-07-12 19:16:25,301 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:25,302 [run_pretraining.py:  534]:	loss/total_loss, 7.468980312347412, 2207
[INFO] 2021-07-12 19:16:25,302 [run_pretraining.py:  535]:	loss/mlm_loss, 7.468980312347412, 2207
[INFO] 2021-07-12 19:16:25,302 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2059999537304975e-05, 2207
[INFO] 2021-07-12 19:16:25,302 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2207
[INFO] 2021-07-12 19:16:25,302 [run_pretraining.py:  558]:	worker_index: 6, step: 2207, cost: 7.468980, mlm loss: 7.468980, speed: 1.109030 steps/s, speed: 8.872238 samples/s, speed: 4542.585926 tokens/s, learning rate: 2.206e-05, loss_scalings: 3518.437988, pp_loss: 7.465816
[INFO] 2021-07-12 19:16:25,302 [run_pretraining.py:  512]:	********exe.run_2207******* 
[INFO] 2021-07-12 19:16:26,203 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:26,204 [run_pretraining.py:  534]:	loss/total_loss, 7.117654800415039, 2208
[INFO] 2021-07-12 19:16:26,204 [run_pretraining.py:  535]:	loss/mlm_loss, 7.117654800415039, 2208
[INFO] 2021-07-12 19:16:26,204 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2069998522056267e-05, 2208
[INFO] 2021-07-12 19:16:26,204 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2208
[INFO] 2021-07-12 19:16:26,204 [run_pretraining.py:  558]:	worker_index: 6, step: 2208, cost: 7.117655, mlm loss: 7.117655, speed: 1.109331 steps/s, speed: 8.874648 samples/s, speed: 4543.819812 tokens/s, learning rate: 2.207e-05, loss_scalings: 3518.437988, pp_loss: 7.669925
[INFO] 2021-07-12 19:16:26,204 [run_pretraining.py:  512]:	********exe.run_2208******* 
[INFO] 2021-07-12 19:16:27,113 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:27,114 [run_pretraining.py:  534]:	loss/total_loss, 7.30096960067749, 2209
[INFO] 2021-07-12 19:16:27,114 [run_pretraining.py:  535]:	loss/mlm_loss, 7.30096960067749, 2209
[INFO] 2021-07-12 19:16:27,114 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2079999325796962e-05, 2209
[INFO] 2021-07-12 19:16:27,114 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2209
[INFO] 2021-07-12 19:16:27,114 [run_pretraining.py:  558]:	worker_index: 6, step: 2209, cost: 7.300970, mlm loss: 7.300970, speed: 1.099352 steps/s, speed: 8.794814 samples/s, speed: 4502.944808 tokens/s, learning rate: 2.208e-05, loss_scalings: 3518.437988, pp_loss: 7.501835
[INFO] 2021-07-12 19:16:27,115 [run_pretraining.py:  512]:	********exe.run_2209******* 
[INFO] 2021-07-12 19:16:28,017 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:28,017 [run_pretraining.py:  534]:	loss/total_loss, 7.363106727600098, 2210
[INFO] 2021-07-12 19:16:28,017 [run_pretraining.py:  535]:	loss/mlm_loss, 7.363106727600098, 2210
[INFO] 2021-07-12 19:16:28,017 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2090000129537657e-05, 2210
[INFO] 2021-07-12 19:16:28,018 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2210
[INFO] 2021-07-12 19:16:28,018 [run_pretraining.py:  558]:	worker_index: 6, step: 2210, cost: 7.363107, mlm loss: 7.363107, speed: 1.107998 steps/s, speed: 8.863983 samples/s, speed: 4538.359517 tokens/s, learning rate: 2.209e-05, loss_scalings: 3518.437988, pp_loss: 6.626892
[INFO] 2021-07-12 19:16:28,018 [run_pretraining.py:  512]:	********exe.run_2210******* 
[INFO] 2021-07-12 19:16:29,015 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:29,016 [run_pretraining.py:  534]:	loss/total_loss, 6.691658973693848, 2211
[INFO] 2021-07-12 19:16:29,016 [run_pretraining.py:  535]:	loss/mlm_loss, 6.691658973693848, 2211
[INFO] 2021-07-12 19:16:29,016 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.209999911428895e-05, 2211
[INFO] 2021-07-12 19:16:29,016 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2211
[INFO] 2021-07-12 19:16:29,016 [run_pretraining.py:  558]:	worker_index: 6, step: 2211, cost: 6.691659, mlm loss: 6.691659, speed: 1.002320 steps/s, speed: 8.018558 samples/s, speed: 4105.501482 tokens/s, learning rate: 2.210e-05, loss_scalings: 3518.437988, pp_loss: 7.180820
[INFO] 2021-07-12 19:16:29,016 [run_pretraining.py:  512]:	********exe.run_2211******* 
[INFO] 2021-07-12 19:16:29,915 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:29,916 [run_pretraining.py:  534]:	loss/total_loss, 6.854889869689941, 2212
[INFO] 2021-07-12 19:16:29,916 [run_pretraining.py:  535]:	loss/mlm_loss, 6.854889869689941, 2212
[INFO] 2021-07-12 19:16:29,916 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2109999918029644e-05, 2212
[INFO] 2021-07-12 19:16:29,916 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2212
[INFO] 2021-07-12 19:16:29,916 [run_pretraining.py:  558]:	worker_index: 6, step: 2212, cost: 6.854890, mlm loss: 6.854890, speed: 1.111960 steps/s, speed: 8.895680 samples/s, speed: 4554.587916 tokens/s, learning rate: 2.211e-05, loss_scalings: 3518.437988, pp_loss: 7.194291
[INFO] 2021-07-12 19:16:29,916 [run_pretraining.py:  512]:	********exe.run_2212******* 
[INFO] 2021-07-12 19:16:30,827 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:30,828 [run_pretraining.py:  534]:	loss/total_loss, 7.292912483215332, 2213
[INFO] 2021-07-12 19:16:30,828 [run_pretraining.py:  535]:	loss/mlm_loss, 7.292912483215332, 2213
[INFO] 2021-07-12 19:16:30,828 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.212000072177034e-05, 2213
[INFO] 2021-07-12 19:16:30,828 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2213
[INFO] 2021-07-12 19:16:30,828 [run_pretraining.py:  558]:	worker_index: 6, step: 2213, cost: 7.292912, mlm loss: 7.292912, speed: 1.096978 steps/s, speed: 8.775824 samples/s, speed: 4493.221718 tokens/s, learning rate: 2.212e-05, loss_scalings: 3518.437988, pp_loss: 7.209450
[INFO] 2021-07-12 19:16:30,828 [run_pretraining.py:  512]:	********exe.run_2213******* 
[INFO] 2021-07-12 19:16:31,734 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:31,734 [run_pretraining.py:  534]:	loss/total_loss, 7.215545654296875, 2214
[INFO] 2021-07-12 19:16:31,734 [run_pretraining.py:  535]:	loss/mlm_loss, 7.215545654296875, 2214
[INFO] 2021-07-12 19:16:31,735 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.212999970652163e-05, 2214
[INFO] 2021-07-12 19:16:31,735 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2214
[INFO] 2021-07-12 19:16:31,735 [run_pretraining.py:  558]:	worker_index: 6, step: 2214, cost: 7.215546, mlm loss: 7.215546, speed: 1.104120 steps/s, speed: 8.832957 samples/s, speed: 4522.473729 tokens/s, learning rate: 2.213e-05, loss_scalings: 3518.437988, pp_loss: 7.196671
[INFO] 2021-07-12 19:16:31,735 [run_pretraining.py:  512]:	********exe.run_2214******* 
[INFO] 2021-07-12 19:16:32,646 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:32,647 [run_pretraining.py:  534]:	loss/total_loss, 6.962941646575928, 2215
[INFO] 2021-07-12 19:16:32,647 [run_pretraining.py:  535]:	loss/mlm_loss, 6.962941646575928, 2215
[INFO] 2021-07-12 19:16:32,647 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2139998691272922e-05, 2215
[INFO] 2021-07-12 19:16:32,647 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2215
[INFO] 2021-07-12 19:16:32,647 [run_pretraining.py:  558]:	worker_index: 6, step: 2215, cost: 6.962942, mlm loss: 6.962942, speed: 1.096812 steps/s, speed: 8.774495 samples/s, speed: 4492.541405 tokens/s, learning rate: 2.214e-05, loss_scalings: 2814.750488, pp_loss: 7.272265
[INFO] 2021-07-12 19:16:32,647 [run_pretraining.py:  512]:	********exe.run_2215******* 
[INFO] 2021-07-12 19:16:33,561 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:33,562 [run_pretraining.py:  534]:	loss/total_loss, 7.544860363006592, 2216
[INFO] 2021-07-12 19:16:33,562 [run_pretraining.py:  535]:	loss/mlm_loss, 7.544860363006592, 2216
[INFO] 2021-07-12 19:16:33,562 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2149999495013617e-05, 2216
[INFO] 2021-07-12 19:16:33,562 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2216
[INFO] 2021-07-12 19:16:33,562 [run_pretraining.py:  558]:	worker_index: 6, step: 2216, cost: 7.544860, mlm loss: 7.544860, speed: 1.094106 steps/s, speed: 8.752847 samples/s, speed: 4481.457550 tokens/s, learning rate: 2.215e-05, loss_scalings: 2814.750488, pp_loss: 7.505181
[INFO] 2021-07-12 19:16:33,562 [run_pretraining.py:  512]:	********exe.run_2216******* 
[INFO] 2021-07-12 19:16:34,473 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:34,474 [run_pretraining.py:  534]:	loss/total_loss, 6.374932289123535, 2217
[INFO] 2021-07-12 19:16:34,474 [run_pretraining.py:  535]:	loss/mlm_loss, 6.374932289123535, 2217
[INFO] 2021-07-12 19:16:34,474 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.215999847976491e-05, 2217
[INFO] 2021-07-12 19:16:34,474 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2217
[INFO] 2021-07-12 19:16:34,474 [run_pretraining.py:  558]:	worker_index: 6, step: 2217, cost: 6.374932, mlm loss: 6.374932, speed: 1.097124 steps/s, speed: 8.776992 samples/s, speed: 4493.819952 tokens/s, learning rate: 2.216e-05, loss_scalings: 2814.750488, pp_loss: 6.936575
[INFO] 2021-07-12 19:16:34,474 [run_pretraining.py:  512]:	********exe.run_2217******* 
[INFO] 2021-07-12 19:16:35,393 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:35,393 [run_pretraining.py:  534]:	loss/total_loss, 7.320034027099609, 2218
[INFO] 2021-07-12 19:16:35,393 [run_pretraining.py:  535]:	loss/mlm_loss, 7.320034027099609, 2218
[INFO] 2021-07-12 19:16:35,393 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2169999283505604e-05, 2218
[INFO] 2021-07-12 19:16:35,393 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2218
[INFO] 2021-07-12 19:16:35,394 [run_pretraining.py:  558]:	worker_index: 6, step: 2218, cost: 7.320034, mlm loss: 7.320034, speed: 1.088375 steps/s, speed: 8.707004 samples/s, speed: 4457.985806 tokens/s, learning rate: 2.217e-05, loss_scalings: 2814.750488, pp_loss: 7.322704
[INFO] 2021-07-12 19:16:35,394 [run_pretraining.py:  512]:	********exe.run_2218******* 
[INFO] 2021-07-12 19:16:36,304 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:36,304 [run_pretraining.py:  534]:	loss/total_loss, 6.895035743713379, 2219
[INFO] 2021-07-12 19:16:36,304 [run_pretraining.py:  535]:	loss/mlm_loss, 6.895035743713379, 2219
[INFO] 2021-07-12 19:16:36,305 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.21800000872463e-05, 2219
[INFO] 2021-07-12 19:16:36,305 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2219
[INFO] 2021-07-12 19:16:36,305 [run_pretraining.py:  558]:	worker_index: 6, step: 2219, cost: 6.895036, mlm loss: 6.895036, speed: 1.098310 steps/s, speed: 8.786482 samples/s, speed: 4498.678715 tokens/s, learning rate: 2.218e-05, loss_scalings: 2814.750488, pp_loss: 7.142179
[INFO] 2021-07-12 19:16:36,305 [run_pretraining.py:  512]:	********exe.run_2219******* 
[INFO] 2021-07-12 19:16:37,214 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:37,214 [run_pretraining.py:  534]:	loss/total_loss, 7.289783477783203, 2220
[INFO] 2021-07-12 19:16:37,215 [run_pretraining.py:  535]:	loss/mlm_loss, 7.289783477783203, 2220
[INFO] 2021-07-12 19:16:37,215 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.218999907199759e-05, 2220
[INFO] 2021-07-12 19:16:37,215 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2220
[INFO] 2021-07-12 19:16:37,215 [run_pretraining.py:  558]:	worker_index: 6, step: 2220, cost: 7.289783, mlm loss: 7.289783, speed: 1.099660 steps/s, speed: 8.797279 samples/s, speed: 4504.206847 tokens/s, learning rate: 2.219e-05, loss_scalings: 2814.750488, pp_loss: 7.148083
[INFO] 2021-07-12 19:16:37,215 [run_pretraining.py:  512]:	********exe.run_2220******* 
[INFO] 2021-07-12 19:16:38,132 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:38,132 [run_pretraining.py:  534]:	loss/total_loss, 7.326233386993408, 2221
[INFO] 2021-07-12 19:16:38,132 [run_pretraining.py:  535]:	loss/mlm_loss, 7.326233386993408, 2221
[INFO] 2021-07-12 19:16:38,132 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2199999875738285e-05, 2221
[INFO] 2021-07-12 19:16:38,132 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2221
[INFO] 2021-07-12 19:16:38,133 [run_pretraining.py:  558]:	worker_index: 6, step: 2221, cost: 7.326233, mlm loss: 7.326233, speed: 1.090547 steps/s, speed: 8.724377 samples/s, speed: 4466.880787 tokens/s, learning rate: 2.220e-05, loss_scalings: 2814.750488, pp_loss: 7.543670
[INFO] 2021-07-12 19:16:38,133 [run_pretraining.py:  512]:	********exe.run_2221******* 
[INFO] 2021-07-12 19:16:39,046 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:39,047 [run_pretraining.py:  534]:	loss/total_loss, 8.135951042175293, 2222
[INFO] 2021-07-12 19:16:39,047 [run_pretraining.py:  535]:	loss/mlm_loss, 8.135951042175293, 2222
[INFO] 2021-07-12 19:16:39,047 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.221000067947898e-05, 2222
[INFO] 2021-07-12 19:16:39,047 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2222
[INFO] 2021-07-12 19:16:39,047 [run_pretraining.py:  558]:	worker_index: 6, step: 2222, cost: 8.135951, mlm loss: 8.135951, speed: 1.094023 steps/s, speed: 8.752182 samples/s, speed: 4481.117394 tokens/s, learning rate: 2.221e-05, loss_scalings: 2814.750488, pp_loss: 7.553474
[INFO] 2021-07-12 19:16:39,047 [run_pretraining.py:  512]:	********exe.run_2222******* 
[INFO] 2021-07-12 19:16:39,958 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:39,959 [run_pretraining.py:  534]:	loss/total_loss, 3.686208486557007, 2223
[INFO] 2021-07-12 19:16:39,959 [run_pretraining.py:  535]:	loss/mlm_loss, 3.686208486557007, 2223
[INFO] 2021-07-12 19:16:39,959 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2219999664230272e-05, 2223
[INFO] 2021-07-12 19:16:39,959 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2223
[INFO] 2021-07-12 19:16:39,959 [run_pretraining.py:  558]:	worker_index: 6, step: 2223, cost: 3.686208, mlm loss: 3.686208, speed: 1.097764 steps/s, speed: 8.782113 samples/s, speed: 4496.441603 tokens/s, learning rate: 2.222e-05, loss_scalings: 2814.750488, pp_loss: 6.415086
[INFO] 2021-07-12 19:16:39,959 [run_pretraining.py:  512]:	********exe.run_2223******* 
[INFO] 2021-07-12 19:16:40,870 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:40,871 [run_pretraining.py:  534]:	loss/total_loss, 7.197108268737793, 2224
[INFO] 2021-07-12 19:16:40,871 [run_pretraining.py:  535]:	loss/mlm_loss, 7.197108268737793, 2224
[INFO] 2021-07-12 19:16:40,871 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2229998648981564e-05, 2224
[INFO] 2021-07-12 19:16:40,871 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2224
[INFO] 2021-07-12 19:16:40,871 [run_pretraining.py:  558]:	worker_index: 6, step: 2224, cost: 7.197108, mlm loss: 7.197108, speed: 1.096933 steps/s, speed: 8.775463 samples/s, speed: 4493.037226 tokens/s, learning rate: 2.223e-05, loss_scalings: 2814.750488, pp_loss: 7.168607
[INFO] 2021-07-12 19:16:40,871 [run_pretraining.py:  512]:	********exe.run_2224******* 
[INFO] 2021-07-12 19:16:41,783 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:41,784 [run_pretraining.py:  534]:	loss/total_loss, 6.8365888595581055, 2225
[INFO] 2021-07-12 19:16:41,784 [run_pretraining.py:  535]:	loss/mlm_loss, 6.8365888595581055, 2225
[INFO] 2021-07-12 19:16:41,784 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.223999945272226e-05, 2225
[INFO] 2021-07-12 19:16:41,784 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2225
[INFO] 2021-07-12 19:16:41,784 [run_pretraining.py:  558]:	worker_index: 6, step: 2225, cost: 6.836589, mlm loss: 6.836589, speed: 1.096133 steps/s, speed: 8.769067 samples/s, speed: 4489.762371 tokens/s, learning rate: 2.224e-05, loss_scalings: 2814.750488, pp_loss: 7.139347
[INFO] 2021-07-12 19:16:41,784 [run_pretraining.py:  512]:	********exe.run_2225******* 
[INFO] 2021-07-12 19:16:42,694 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:42,694 [run_pretraining.py:  534]:	loss/total_loss, 7.3589935302734375, 2226
[INFO] 2021-07-12 19:16:42,695 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3589935302734375, 2226
[INFO] 2021-07-12 19:16:42,695 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.224999843747355e-05, 2226
[INFO] 2021-07-12 19:16:42,695 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2226
[INFO] 2021-07-12 19:16:42,695 [run_pretraining.py:  558]:	worker_index: 6, step: 2226, cost: 7.358994, mlm loss: 7.358994, speed: 1.099050 steps/s, speed: 8.792401 samples/s, speed: 4501.709427 tokens/s, learning rate: 2.225e-05, loss_scalings: 2814.750488, pp_loss: 7.364461
[INFO] 2021-07-12 19:16:42,695 [run_pretraining.py:  512]:	********exe.run_2226******* 
[INFO] 2021-07-12 19:16:43,615 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:43,615 [run_pretraining.py:  534]:	loss/total_loss, 7.034793853759766, 2227
[INFO] 2021-07-12 19:16:43,615 [run_pretraining.py:  535]:	loss/mlm_loss, 7.034793853759766, 2227
[INFO] 2021-07-12 19:16:43,615 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2259999241214246e-05, 2227
[INFO] 2021-07-12 19:16:43,616 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2227
[INFO] 2021-07-12 19:16:43,616 [run_pretraining.py:  558]:	worker_index: 6, step: 2227, cost: 7.034794, mlm loss: 7.034794, speed: 1.086809 steps/s, speed: 8.694475 samples/s, speed: 4451.571350 tokens/s, learning rate: 2.226e-05, loss_scalings: 2814.750488, pp_loss: 7.125798
[INFO] 2021-07-12 19:16:43,616 [run_pretraining.py:  512]:	********exe.run_2227******* 
[INFO] 2021-07-12 19:16:44,535 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:44,535 [run_pretraining.py:  534]:	loss/total_loss, 7.13792085647583, 2228
[INFO] 2021-07-12 19:16:44,536 [run_pretraining.py:  535]:	loss/mlm_loss, 7.13792085647583, 2228
[INFO] 2021-07-12 19:16:44,536 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.227000004495494e-05, 2228
[INFO] 2021-07-12 19:16:44,536 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2228
[INFO] 2021-07-12 19:16:44,536 [run_pretraining.py:  558]:	worker_index: 6, step: 2228, cost: 7.137921, mlm loss: 7.137921, speed: 1.087588 steps/s, speed: 8.700704 samples/s, speed: 4454.760675 tokens/s, learning rate: 2.227e-05, loss_scalings: 2814.750488, pp_loss: 7.104585
[INFO] 2021-07-12 19:16:44,536 [run_pretraining.py:  512]:	********exe.run_2228******* 
[INFO] 2021-07-12 19:16:45,446 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:45,446 [run_pretraining.py:  534]:	loss/total_loss, 6.675179958343506, 2229
[INFO] 2021-07-12 19:16:45,446 [run_pretraining.py:  535]:	loss/mlm_loss, 6.675179958343506, 2229
[INFO] 2021-07-12 19:16:45,446 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2279999029706232e-05, 2229
[INFO] 2021-07-12 19:16:45,446 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2229
[INFO] 2021-07-12 19:16:45,446 [run_pretraining.py:  558]:	worker_index: 6, step: 2229, cost: 6.675180, mlm loss: 6.675180, speed: 1.098883 steps/s, speed: 8.791065 samples/s, speed: 4501.025362 tokens/s, learning rate: 2.228e-05, loss_scalings: 2814.750488, pp_loss: 6.973671
[INFO] 2021-07-12 19:16:45,447 [run_pretraining.py:  512]:	********exe.run_2229******* 
[INFO] 2021-07-12 19:16:46,368 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:46,369 [run_pretraining.py:  534]:	loss/total_loss, 6.8413543701171875, 2230
[INFO] 2021-07-12 19:16:46,369 [run_pretraining.py:  535]:	loss/mlm_loss, 6.8413543701171875, 2230
[INFO] 2021-07-12 19:16:46,369 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2289999833446927e-05, 2230
[INFO] 2021-07-12 19:16:46,369 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2230
[INFO] 2021-07-12 19:16:46,369 [run_pretraining.py:  558]:	worker_index: 6, step: 2230, cost: 6.841354, mlm loss: 6.841354, speed: 1.084399 steps/s, speed: 8.675195 samples/s, speed: 4441.699965 tokens/s, learning rate: 2.229e-05, loss_scalings: 2814.750488, pp_loss: 7.094098
[INFO] 2021-07-12 19:16:46,369 [run_pretraining.py:  512]:	********exe.run_2230******* 
[INFO] 2021-07-12 19:16:47,278 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:47,279 [run_pretraining.py:  534]:	loss/total_loss, 7.609109401702881, 2231
[INFO] 2021-07-12 19:16:47,279 [run_pretraining.py:  535]:	loss/mlm_loss, 7.609109401702881, 2231
[INFO] 2021-07-12 19:16:47,279 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2300000637187622e-05, 2231
[INFO] 2021-07-12 19:16:47,279 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2231
[INFO] 2021-07-12 19:16:47,279 [run_pretraining.py:  558]:	worker_index: 6, step: 2231, cost: 7.609109, mlm loss: 7.609109, speed: 1.099852 steps/s, speed: 8.798813 samples/s, speed: 4504.992289 tokens/s, learning rate: 2.230e-05, loss_scalings: 2814.750488, pp_loss: 7.192182
[INFO] 2021-07-12 19:16:47,279 [run_pretraining.py:  512]:	********exe.run_2231******* 
[INFO] 2021-07-12 19:16:48,190 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:48,191 [run_pretraining.py:  534]:	loss/total_loss, 7.740169525146484, 2232
[INFO] 2021-07-12 19:16:48,191 [run_pretraining.py:  535]:	loss/mlm_loss, 7.740169525146484, 2232
[INFO] 2021-07-12 19:16:48,191 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2309999621938914e-05, 2232
[INFO] 2021-07-12 19:16:48,191 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2232
[INFO] 2021-07-12 19:16:48,191 [run_pretraining.py:  558]:	worker_index: 6, step: 2232, cost: 7.740170, mlm loss: 7.740170, speed: 1.097210 steps/s, speed: 8.777679 samples/s, speed: 4494.171445 tokens/s, learning rate: 2.231e-05, loss_scalings: 2814.750488, pp_loss: 7.473009
[INFO] 2021-07-12 19:16:48,192 [run_pretraining.py:  512]:	********exe.run_2232******* 
[INFO] 2021-07-12 19:16:49,100 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:49,101 [run_pretraining.py:  534]:	loss/total_loss, 7.103124618530273, 2233
[INFO] 2021-07-12 19:16:49,101 [run_pretraining.py:  535]:	loss/mlm_loss, 7.103124618530273, 2233
[INFO] 2021-07-12 19:16:49,101 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2319998606690206e-05, 2233
[INFO] 2021-07-12 19:16:49,101 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2233
[INFO] 2021-07-12 19:16:49,101 [run_pretraining.py:  558]:	worker_index: 6, step: 2233, cost: 7.103125, mlm loss: 7.103125, speed: 1.099761 steps/s, speed: 8.798086 samples/s, speed: 4504.620203 tokens/s, learning rate: 2.232e-05, loss_scalings: 2814.750488, pp_loss: 7.405497
[INFO] 2021-07-12 19:16:49,102 [run_pretraining.py:  512]:	********exe.run_2233******* 
[INFO] 2021-07-12 19:16:50,028 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:50,028 [run_pretraining.py:  534]:	loss/total_loss, 6.753520488739014, 2234
[INFO] 2021-07-12 19:16:50,028 [run_pretraining.py:  535]:	loss/mlm_loss, 6.753520488739014, 2234
[INFO] 2021-07-12 19:16:50,028 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.23299994104309e-05, 2234
[INFO] 2021-07-12 19:16:50,028 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2234
[INFO] 2021-07-12 19:16:50,029 [run_pretraining.py:  558]:	worker_index: 6, step: 2234, cost: 6.753520, mlm loss: 6.753520, speed: 1.079491 steps/s, speed: 8.635928 samples/s, speed: 4421.595149 tokens/s, learning rate: 2.233e-05, loss_scalings: 2814.750488, pp_loss: 7.202021
[INFO] 2021-07-12 19:16:50,029 [run_pretraining.py:  512]:	********exe.run_2234******* 
[INFO] 2021-07-12 19:16:50,946 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:50,946 [run_pretraining.py:  534]:	loss/total_loss, 6.9489569664001465, 2235
[INFO] 2021-07-12 19:16:50,947 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9489569664001465, 2235
[INFO] 2021-07-12 19:16:50,947 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2339998395182192e-05, 2235
[INFO] 2021-07-12 19:16:50,947 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2235
[INFO] 2021-07-12 19:16:50,947 [run_pretraining.py:  558]:	worker_index: 6, step: 2235, cost: 6.948957, mlm loss: 6.948957, speed: 1.089794 steps/s, speed: 8.718351 samples/s, speed: 4463.795867 tokens/s, learning rate: 2.234e-05, loss_scalings: 2814.750488, pp_loss: 7.143501
[INFO] 2021-07-12 19:16:50,947 [run_pretraining.py:  512]:	********exe.run_2235******* 
[INFO] 2021-07-12 19:16:51,893 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:51,894 [run_pretraining.py:  534]:	loss/total_loss, 7.371520042419434, 2236
[INFO] 2021-07-12 19:16:51,894 [run_pretraining.py:  535]:	loss/mlm_loss, 7.371520042419434, 2236
[INFO] 2021-07-12 19:16:51,894 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2349999198922887e-05, 2236
[INFO] 2021-07-12 19:16:51,894 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2236
[INFO] 2021-07-12 19:16:51,894 [run_pretraining.py:  558]:	worker_index: 6, step: 2236, cost: 7.371520, mlm loss: 7.371520, speed: 1.056273 steps/s, speed: 8.450187 samples/s, speed: 4326.495551 tokens/s, learning rate: 2.235e-05, loss_scalings: 2814.750488, pp_loss: 7.222003
[INFO] 2021-07-12 19:16:51,894 [run_pretraining.py:  512]:	********exe.run_2236******* 
[INFO] 2021-07-12 19:16:52,834 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:52,835 [run_pretraining.py:  534]:	loss/total_loss, 8.131891250610352, 2237
[INFO] 2021-07-12 19:16:52,835 [run_pretraining.py:  535]:	loss/mlm_loss, 8.131891250610352, 2237
[INFO] 2021-07-12 19:16:52,835 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2360000002663583e-05, 2237
[INFO] 2021-07-12 19:16:52,835 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2237
[INFO] 2021-07-12 19:16:52,835 [run_pretraining.py:  558]:	worker_index: 6, step: 2237, cost: 8.131891, mlm loss: 8.131891, speed: 1.063753 steps/s, speed: 8.510020 samples/s, speed: 4357.130477 tokens/s, learning rate: 2.236e-05, loss_scalings: 2814.750488, pp_loss: 7.451180
[INFO] 2021-07-12 19:16:52,835 [run_pretraining.py:  512]:	********exe.run_2237******* 
[INFO] 2021-07-12 19:16:53,742 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:53,742 [run_pretraining.py:  534]:	loss/total_loss, 6.674560546875, 2238
[INFO] 2021-07-12 19:16:53,742 [run_pretraining.py:  535]:	loss/mlm_loss, 6.674560546875, 2238
[INFO] 2021-07-12 19:16:53,742 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2369998987414874e-05, 2238
[INFO] 2021-07-12 19:16:53,743 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2238
[INFO] 2021-07-12 19:16:53,743 [run_pretraining.py:  558]:	worker_index: 6, step: 2238, cost: 6.674561, mlm loss: 6.674561, speed: 1.102642 steps/s, speed: 8.821137 samples/s, speed: 4516.422153 tokens/s, learning rate: 2.237e-05, loss_scalings: 2814.750488, pp_loss: 7.085663
[INFO] 2021-07-12 19:16:53,743 [run_pretraining.py:  512]:	********exe.run_2238******* 
[INFO] 2021-07-12 19:16:54,658 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:54,659 [run_pretraining.py:  534]:	loss/total_loss, 7.38084602355957, 2239
[INFO] 2021-07-12 19:16:54,659 [run_pretraining.py:  535]:	loss/mlm_loss, 7.38084602355957, 2239
[INFO] 2021-07-12 19:16:54,659 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.237999979115557e-05, 2239
[INFO] 2021-07-12 19:16:54,659 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2239
[INFO] 2021-07-12 19:16:54,659 [run_pretraining.py:  558]:	worker_index: 6, step: 2239, cost: 7.380846, mlm loss: 7.380846, speed: 1.091902 steps/s, speed: 8.735217 samples/s, speed: 4472.431127 tokens/s, learning rate: 2.238e-05, loss_scalings: 2814.750488, pp_loss: 7.437721
[INFO] 2021-07-12 19:16:54,659 [run_pretraining.py:  512]:	********exe.run_2239******* 
[INFO] 2021-07-12 19:16:55,565 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:55,566 [run_pretraining.py:  534]:	loss/total_loss, 7.538983345031738, 2240
[INFO] 2021-07-12 19:16:55,566 [run_pretraining.py:  535]:	loss/mlm_loss, 7.538983345031738, 2240
[INFO] 2021-07-12 19:16:55,566 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2390000594896264e-05, 2240
[INFO] 2021-07-12 19:16:55,566 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2240
[INFO] 2021-07-12 19:16:55,566 [run_pretraining.py:  558]:	worker_index: 6, step: 2240, cost: 7.538983, mlm loss: 7.538983, speed: 1.103343 steps/s, speed: 8.826748 samples/s, speed: 4519.294928 tokens/s, learning rate: 2.239e-05, loss_scalings: 2814.750488, pp_loss: 7.356597
[INFO] 2021-07-12 19:16:55,566 [run_pretraining.py:  512]:	********exe.run_2240******* 
[INFO] 2021-07-12 19:16:56,471 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:56,471 [run_pretraining.py:  534]:	loss/total_loss, 6.7777533531188965, 2241
[INFO] 2021-07-12 19:16:56,471 [run_pretraining.py:  535]:	loss/mlm_loss, 6.7777533531188965, 2241
[INFO] 2021-07-12 19:16:56,471 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2399999579647556e-05, 2241
[INFO] 2021-07-12 19:16:56,472 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2241
[INFO] 2021-07-12 19:16:56,472 [run_pretraining.py:  558]:	worker_index: 6, step: 2241, cost: 6.777753, mlm loss: 6.777753, speed: 1.105316 steps/s, speed: 8.842530 samples/s, speed: 4527.375595 tokens/s, learning rate: 2.240e-05, loss_scalings: 2814.750488, pp_loss: 7.147945
[INFO] 2021-07-12 19:16:56,472 [run_pretraining.py:  512]:	********exe.run_2241******* 
[INFO] 2021-07-12 19:16:57,378 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:57,378 [run_pretraining.py:  534]:	loss/total_loss, 7.914266109466553, 2242
[INFO] 2021-07-12 19:16:57,378 [run_pretraining.py:  535]:	loss/mlm_loss, 7.914266109466553, 2242
[INFO] 2021-07-12 19:16:57,378 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2409998564398848e-05, 2242
[INFO] 2021-07-12 19:16:57,379 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2242
[INFO] 2021-07-12 19:16:57,379 [run_pretraining.py:  558]:	worker_index: 6, step: 2242, cost: 7.914266, mlm loss: 7.914266, speed: 1.103368 steps/s, speed: 8.826948 samples/s, speed: 4519.397170 tokens/s, learning rate: 2.241e-05, loss_scalings: 2814.750488, pp_loss: 7.631866
[INFO] 2021-07-12 19:16:57,379 [run_pretraining.py:  512]:	********exe.run_2242******* 
[INFO] 2021-07-12 19:16:58,293 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:58,294 [run_pretraining.py:  534]:	loss/total_loss, 7.476235389709473, 2243
[INFO] 2021-07-12 19:16:58,294 [run_pretraining.py:  535]:	loss/mlm_loss, 7.476235389709473, 2243
[INFO] 2021-07-12 19:16:58,294 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2419999368139543e-05, 2243
[INFO] 2021-07-12 19:16:58,294 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2243
[INFO] 2021-07-12 19:16:58,294 [run_pretraining.py:  558]:	worker_index: 6, step: 2243, cost: 7.476235, mlm loss: 7.476235, speed: 1.092797 steps/s, speed: 8.742379 samples/s, speed: 4476.098205 tokens/s, learning rate: 2.242e-05, loss_scalings: 2814.750488, pp_loss: 7.487659
[INFO] 2021-07-12 19:16:58,294 [run_pretraining.py:  512]:	********exe.run_2243******* 
[INFO] 2021-07-12 19:16:59,200 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:59,201 [run_pretraining.py:  534]:	loss/total_loss, 7.068236351013184, 2244
[INFO] 2021-07-12 19:16:59,201 [run_pretraining.py:  535]:	loss/mlm_loss, 7.068236351013184, 2244
[INFO] 2021-07-12 19:16:59,201 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2429998352890834e-05, 2244
[INFO] 2021-07-12 19:16:59,201 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2244
[INFO] 2021-07-12 19:16:59,201 [run_pretraining.py:  558]:	worker_index: 6, step: 2244, cost: 7.068236, mlm loss: 7.068236, speed: 1.103789 steps/s, speed: 8.830311 samples/s, speed: 4521.119337 tokens/s, learning rate: 2.243e-05, loss_scalings: 2814.750488, pp_loss: 7.168266
[INFO] 2021-07-12 19:16:59,201 [run_pretraining.py:  512]:	********exe.run_2244******* 
[INFO] 2021-07-12 19:17:00,100 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:00,101 [run_pretraining.py:  534]:	loss/total_loss, 7.383769989013672, 2245
[INFO] 2021-07-12 19:17:00,101 [run_pretraining.py:  535]:	loss/mlm_loss, 7.383769989013672, 2245
[INFO] 2021-07-12 19:17:00,101 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.243999915663153e-05, 2245
[INFO] 2021-07-12 19:17:00,101 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2245
[INFO] 2021-07-12 19:17:00,101 [run_pretraining.py:  558]:	worker_index: 6, step: 2245, cost: 7.383770, mlm loss: 7.383770, speed: 1.111901 steps/s, speed: 8.895208 samples/s, speed: 4554.346434 tokens/s, learning rate: 2.244e-05, loss_scalings: 2814.750488, pp_loss: 7.338502
[INFO] 2021-07-12 19:17:00,101 [run_pretraining.py:  512]:	********exe.run_2245******* 
[INFO] 2021-07-12 19:17:01,003 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:01,004 [run_pretraining.py:  534]:	loss/total_loss, 6.99683141708374, 2246
[INFO] 2021-07-12 19:17:01,004 [run_pretraining.py:  535]:	loss/mlm_loss, 6.99683141708374, 2246
[INFO] 2021-07-12 19:17:01,004 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2449999960372224e-05, 2246
[INFO] 2021-07-12 19:17:01,004 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2246
[INFO] 2021-07-12 19:17:01,004 [run_pretraining.py:  558]:	worker_index: 6, step: 2246, cost: 6.996831, mlm loss: 6.996831, speed: 1.108540 steps/s, speed: 8.868322 samples/s, speed: 4540.580941 tokens/s, learning rate: 2.245e-05, loss_scalings: 2814.750488, pp_loss: 7.207690
[INFO] 2021-07-12 19:17:01,004 [run_pretraining.py:  512]:	********exe.run_2246******* 
[INFO] 2021-07-12 19:17:01,912 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:01,912 [run_pretraining.py:  534]:	loss/total_loss, 7.960797309875488, 2247
[INFO] 2021-07-12 19:17:01,912 [run_pretraining.py:  535]:	loss/mlm_loss, 7.960797309875488, 2247
[INFO] 2021-07-12 19:17:01,912 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2459998945123516e-05, 2247
[INFO] 2021-07-12 19:17:01,912 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2247
[INFO] 2021-07-12 19:17:01,912 [run_pretraining.py:  558]:	worker_index: 6, step: 2247, cost: 7.960797, mlm loss: 7.960797, speed: 1.101489 steps/s, speed: 8.811915 samples/s, speed: 4511.700358 tokens/s, learning rate: 2.246e-05, loss_scalings: 2814.750488, pp_loss: 7.472604
[INFO] 2021-07-12 19:17:01,913 [run_pretraining.py:  512]:	********exe.run_2247******* 
[INFO] 2021-07-12 19:17:02,822 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:02,822 [run_pretraining.py:  534]:	loss/total_loss, 6.809326648712158, 2248
[INFO] 2021-07-12 19:17:02,822 [run_pretraining.py:  535]:	loss/mlm_loss, 6.809326648712158, 2248
[INFO] 2021-07-12 19:17:02,822 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.246999974886421e-05, 2248
[INFO] 2021-07-12 19:17:02,822 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2248
[INFO] 2021-07-12 19:17:02,823 [run_pretraining.py:  558]:	worker_index: 6, step: 2248, cost: 6.809327, mlm loss: 6.809327, speed: 1.099695 steps/s, speed: 8.797558 samples/s, speed: 4504.349742 tokens/s, learning rate: 2.247e-05, loss_scalings: 2814.750488, pp_loss: 7.058220
[INFO] 2021-07-12 19:17:02,823 [run_pretraining.py:  512]:	********exe.run_2248******* 
[INFO] 2021-07-12 19:17:03,731 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:03,732 [run_pretraining.py:  534]:	loss/total_loss, 7.081425666809082, 2249
[INFO] 2021-07-12 19:17:03,732 [run_pretraining.py:  535]:	loss/mlm_loss, 7.081425666809082, 2249
[INFO] 2021-07-12 19:17:03,732 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2480000552604906e-05, 2249
[INFO] 2021-07-12 19:17:03,732 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2249
[INFO] 2021-07-12 19:17:03,732 [run_pretraining.py:  558]:	worker_index: 6, step: 2249, cost: 7.081426, mlm loss: 7.081426, speed: 1.100531 steps/s, speed: 8.804245 samples/s, speed: 4507.773656 tokens/s, learning rate: 2.248e-05, loss_scalings: 2814.750488, pp_loss: 7.110541
[INFO] 2021-07-12 19:17:03,732 [run_pretraining.py:  512]:	********exe.run_2249******* 
[INFO] 2021-07-12 19:17:04,641 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:04,642 [run_pretraining.py:  534]:	loss/total_loss, 6.671138286590576, 2250
[INFO] 2021-07-12 19:17:04,642 [run_pretraining.py:  535]:	loss/mlm_loss, 6.671138286590576, 2250
[INFO] 2021-07-12 19:17:04,642 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2489999537356198e-05, 2250
[INFO] 2021-07-12 19:17:04,642 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2250
[INFO] 2021-07-12 19:17:04,642 [run_pretraining.py:  558]:	worker_index: 6, step: 2250, cost: 6.671138, mlm loss: 6.671138, speed: 1.099345 steps/s, speed: 8.794761 samples/s, speed: 4502.917662 tokens/s, learning rate: 2.249e-05, loss_scalings: 2814.750488, pp_loss: 7.066414
[INFO] 2021-07-12 19:17:04,642 [run_pretraining.py:  512]:	********exe.run_2250******* 
[INFO] 2021-07-12 19:17:05,553 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:05,554 [run_pretraining.py:  534]:	loss/total_loss, 6.733359336853027, 2251
[INFO] 2021-07-12 19:17:05,554 [run_pretraining.py:  535]:	loss/mlm_loss, 6.733359336853027, 2251
[INFO] 2021-07-12 19:17:05,554 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.249999852210749e-05, 2251
[INFO] 2021-07-12 19:17:05,554 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2251
[INFO] 2021-07-12 19:17:05,554 [run_pretraining.py:  558]:	worker_index: 6, step: 2251, cost: 6.733359, mlm loss: 6.733359, speed: 1.097146 steps/s, speed: 8.777164 samples/s, speed: 4493.908114 tokens/s, learning rate: 2.250e-05, loss_scalings: 2814.750488, pp_loss: 7.020302
[INFO] 2021-07-12 19:17:05,554 [run_pretraining.py:  512]:	********exe.run_2251******* 
[INFO] 2021-07-12 19:17:06,449 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:06,450 [run_pretraining.py:  534]:	loss/total_loss, 6.618898391723633, 2252
[INFO] 2021-07-12 19:17:06,450 [run_pretraining.py:  535]:	loss/mlm_loss, 6.618898391723633, 2252
[INFO] 2021-07-12 19:17:06,450 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2509999325848185e-05, 2252
[INFO] 2021-07-12 19:17:06,450 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2252
[INFO] 2021-07-12 19:17:06,450 [run_pretraining.py:  558]:	worker_index: 6, step: 2252, cost: 6.618898, mlm loss: 6.618898, speed: 1.117374 steps/s, speed: 8.938988 samples/s, speed: 4576.761963 tokens/s, learning rate: 2.251e-05, loss_scalings: 2814.750488, pp_loss: 7.482526
[INFO] 2021-07-12 19:17:06,450 [run_pretraining.py:  512]:	********exe.run_2252******* 
[INFO] 2021-07-12 19:17:07,354 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:07,355 [run_pretraining.py:  534]:	loss/total_loss, 8.020956993103027, 2253
[INFO] 2021-07-12 19:17:07,355 [run_pretraining.py:  535]:	loss/mlm_loss, 8.020956993103027, 2253
[INFO] 2021-07-12 19:17:07,355 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2519998310599476e-05, 2253
[INFO] 2021-07-12 19:17:07,355 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2253
[INFO] 2021-07-12 19:17:07,355 [run_pretraining.py:  558]:	worker_index: 6, step: 2253, cost: 8.020957, mlm loss: 8.020957, speed: 1.105497 steps/s, speed: 8.843978 samples/s, speed: 4528.116625 tokens/s, learning rate: 2.252e-05, loss_scalings: 2814.750488, pp_loss: 7.533263
[INFO] 2021-07-12 19:17:07,355 [run_pretraining.py:  512]:	********exe.run_2253******* 
[INFO] 2021-07-12 19:17:08,265 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:08,266 [run_pretraining.py:  534]:	loss/total_loss, 7.180912494659424, 2254
[INFO] 2021-07-12 19:17:08,266 [run_pretraining.py:  535]:	loss/mlm_loss, 7.180912494659424, 2254
[INFO] 2021-07-12 19:17:08,266 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.252999911434017e-05, 2254
[INFO] 2021-07-12 19:17:08,266 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2254
[INFO] 2021-07-12 19:17:08,266 [run_pretraining.py:  558]:	worker_index: 6, step: 2254, cost: 7.180912, mlm loss: 7.180912, speed: 1.098700 steps/s, speed: 8.789601 samples/s, speed: 4500.275489 tokens/s, learning rate: 2.253e-05, loss_scalings: 2814.750488, pp_loss: 7.100213
[INFO] 2021-07-12 19:17:08,266 [run_pretraining.py:  512]:	********exe.run_2254******* 
[INFO] 2021-07-12 19:17:09,215 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:09,216 [run_pretraining.py:  534]:	loss/total_loss, 8.095763206481934, 2255
[INFO] 2021-07-12 19:17:09,216 [run_pretraining.py:  535]:	loss/mlm_loss, 8.095763206481934, 2255
[INFO] 2021-07-12 19:17:09,216 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2539999918080866e-05, 2255
[INFO] 2021-07-12 19:17:09,216 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2255
[INFO] 2021-07-12 19:17:09,216 [run_pretraining.py:  558]:	worker_index: 6, step: 2255, cost: 8.095763, mlm loss: 8.095763, speed: 1.053573 steps/s, speed: 8.428583 samples/s, speed: 4315.434322 tokens/s, learning rate: 2.254e-05, loss_scalings: 2814.750488, pp_loss: 7.286773
[INFO] 2021-07-12 19:17:09,216 [run_pretraining.py:  512]:	********exe.run_2255******* 
[INFO] 2021-07-12 19:17:10,159 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:10,159 [run_pretraining.py:  534]:	loss/total_loss, 7.022946357727051, 2256
[INFO] 2021-07-12 19:17:10,159 [run_pretraining.py:  535]:	loss/mlm_loss, 7.022946357727051, 2256
[INFO] 2021-07-12 19:17:10,160 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2549998902832158e-05, 2256
[INFO] 2021-07-12 19:17:10,160 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2256
[INFO] 2021-07-12 19:17:10,160 [run_pretraining.py:  558]:	worker_index: 6, step: 2256, cost: 7.022946, mlm loss: 7.022946, speed: 1.060518 steps/s, speed: 8.484148 samples/s, speed: 4343.883771 tokens/s, learning rate: 2.255e-05, loss_scalings: 2814.750488, pp_loss: 7.225659
[INFO] 2021-07-12 19:17:10,160 [run_pretraining.py:  512]:	********exe.run_2256******* 
[INFO] 2021-07-12 19:17:11,074 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:11,074 [run_pretraining.py:  534]:	loss/total_loss, 6.7331366539001465, 2257
[INFO] 2021-07-12 19:17:11,074 [run_pretraining.py:  535]:	loss/mlm_loss, 6.7331366539001465, 2257
[INFO] 2021-07-12 19:17:11,074 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2559999706572853e-05, 2257
[INFO] 2021-07-12 19:17:11,074 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2257
[INFO] 2021-07-12 19:17:11,075 [run_pretraining.py:  558]:	worker_index: 6, step: 2257, cost: 6.733137, mlm loss: 6.733137, speed: 1.093909 steps/s, speed: 8.751274 samples/s, speed: 4480.652246 tokens/s, learning rate: 2.256e-05, loss_scalings: 2814.750488, pp_loss: 6.330856
[INFO] 2021-07-12 19:17:11,075 [run_pretraining.py:  512]:	********exe.run_2257******* 
[INFO] 2021-07-12 19:17:11,985 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:11,986 [run_pretraining.py:  534]:	loss/total_loss, 7.186341285705566, 2258
[INFO] 2021-07-12 19:17:11,986 [run_pretraining.py:  535]:	loss/mlm_loss, 7.186341285705566, 2258
[INFO] 2021-07-12 19:17:11,986 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2570000510313548e-05, 2258
[INFO] 2021-07-12 19:17:11,986 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2258
[INFO] 2021-07-12 19:17:11,986 [run_pretraining.py:  558]:	worker_index: 6, step: 2258, cost: 7.186341, mlm loss: 7.186341, speed: 1.097772 steps/s, speed: 8.782175 samples/s, speed: 4496.473378 tokens/s, learning rate: 2.257e-05, loss_scalings: 2814.750488, pp_loss: 7.275234
[INFO] 2021-07-12 19:17:11,986 [run_pretraining.py:  512]:	********exe.run_2258******* 
[INFO] 2021-07-12 19:17:12,905 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:12,906 [run_pretraining.py:  534]:	loss/total_loss, 7.337528228759766, 2259
[INFO] 2021-07-12 19:17:12,906 [run_pretraining.py:  535]:	loss/mlm_loss, 7.337528228759766, 2259
[INFO] 2021-07-12 19:17:12,906 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.257999949506484e-05, 2259
[INFO] 2021-07-12 19:17:12,906 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2259
[INFO] 2021-07-12 19:17:12,906 [run_pretraining.py:  558]:	worker_index: 6, step: 2259, cost: 7.337528, mlm loss: 7.337528, speed: 1.087798 steps/s, speed: 8.702388 samples/s, speed: 4455.622565 tokens/s, learning rate: 2.258e-05, loss_scalings: 2814.750488, pp_loss: 7.272877
[INFO] 2021-07-12 19:17:12,906 [run_pretraining.py:  512]:	********exe.run_2259******* 
[INFO] 2021-07-12 19:17:13,815 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:13,816 [run_pretraining.py:  534]:	loss/total_loss, 7.01973819732666, 2260
[INFO] 2021-07-12 19:17:13,816 [run_pretraining.py:  535]:	loss/mlm_loss, 7.01973819732666, 2260
[INFO] 2021-07-12 19:17:13,816 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.258999847981613e-05, 2260
[INFO] 2021-07-12 19:17:13,816 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2260
[INFO] 2021-07-12 19:17:13,816 [run_pretraining.py:  558]:	worker_index: 6, step: 2260, cost: 7.019738, mlm loss: 7.019738, speed: 1.099982 steps/s, speed: 8.799856 samples/s, speed: 4505.526310 tokens/s, learning rate: 2.259e-05, loss_scalings: 2814.750488, pp_loss: 7.291373
[INFO] 2021-07-12 19:17:13,816 [run_pretraining.py:  512]:	********exe.run_2260******* 
[INFO] 2021-07-12 19:17:14,723 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:14,723 [run_pretraining.py:  534]:	loss/total_loss, 7.080751895904541, 2261
[INFO] 2021-07-12 19:17:14,723 [run_pretraining.py:  535]:	loss/mlm_loss, 7.080751895904541, 2261
[INFO] 2021-07-12 19:17:14,723 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2599999283556826e-05, 2261
[INFO] 2021-07-12 19:17:14,724 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2261
[INFO] 2021-07-12 19:17:14,724 [run_pretraining.py:  558]:	worker_index: 6, step: 2261, cost: 7.080752, mlm loss: 7.080752, speed: 1.102638 steps/s, speed: 8.821105 samples/s, speed: 4516.405530 tokens/s, learning rate: 2.260e-05, loss_scalings: 2814.750488, pp_loss: 7.200885
[INFO] 2021-07-12 19:17:14,724 [run_pretraining.py:  512]:	********exe.run_2261******* 
[INFO] 2021-07-12 19:17:15,635 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:15,636 [run_pretraining.py:  534]:	loss/total_loss, 7.283937454223633, 2262
[INFO] 2021-07-12 19:17:15,636 [run_pretraining.py:  535]:	loss/mlm_loss, 7.283937454223633, 2262
[INFO] 2021-07-12 19:17:15,636 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.261000008729752e-05, 2262
[INFO] 2021-07-12 19:17:15,636 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2262
[INFO] 2021-07-12 19:17:15,636 [run_pretraining.py:  558]:	worker_index: 6, step: 2262, cost: 7.283937, mlm loss: 7.283937, speed: 1.096800 steps/s, speed: 8.774399 samples/s, speed: 4492.492064 tokens/s, learning rate: 2.261e-05, loss_scalings: 2814.750488, pp_loss: 7.256536
[INFO] 2021-07-12 19:17:15,636 [run_pretraining.py:  512]:	********exe.run_2262******* 
[INFO] 2021-07-12 19:17:16,549 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:16,550 [run_pretraining.py:  534]:	loss/total_loss, 6.431712627410889, 2263
[INFO] 2021-07-12 19:17:16,550 [run_pretraining.py:  535]:	loss/mlm_loss, 6.431712627410889, 2263
[INFO] 2021-07-12 19:17:16,550 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2619999072048813e-05, 2263
[INFO] 2021-07-12 19:17:16,550 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2263
[INFO] 2021-07-12 19:17:16,550 [run_pretraining.py:  558]:	worker_index: 6, step: 2263, cost: 6.431713, mlm loss: 6.431713, speed: 1.094907 steps/s, speed: 8.759256 samples/s, speed: 4484.739028 tokens/s, learning rate: 2.262e-05, loss_scalings: 2814.750488, pp_loss: 7.055070
[INFO] 2021-07-12 19:17:16,550 [run_pretraining.py:  512]:	********exe.run_2263******* 
[INFO] 2021-07-12 19:17:17,465 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:17,466 [run_pretraining.py:  534]:	loss/total_loss, 7.757909297943115, 2264
[INFO] 2021-07-12 19:17:17,466 [run_pretraining.py:  535]:	loss/mlm_loss, 7.757909297943115, 2264
[INFO] 2021-07-12 19:17:17,466 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2629999875789508e-05, 2264
[INFO] 2021-07-12 19:17:17,466 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2264
[INFO] 2021-07-12 19:17:17,466 [run_pretraining.py:  558]:	worker_index: 6, step: 2264, cost: 7.757909, mlm loss: 7.757909, speed: 1.092498 steps/s, speed: 8.739986 samples/s, speed: 4474.872846 tokens/s, learning rate: 2.263e-05, loss_scalings: 2814.750488, pp_loss: 7.363614
[INFO] 2021-07-12 19:17:17,466 [run_pretraining.py:  512]:	********exe.run_2264******* 
[INFO] 2021-07-12 19:17:18,394 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:18,394 [run_pretraining.py:  534]:	loss/total_loss, 7.24432897567749, 2265
[INFO] 2021-07-12 19:17:18,394 [run_pretraining.py:  535]:	loss/mlm_loss, 7.24432897567749, 2265
[INFO] 2021-07-12 19:17:18,394 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.26399988605408e-05, 2265
[INFO] 2021-07-12 19:17:18,395 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2265
[INFO] 2021-07-12 19:17:18,395 [run_pretraining.py:  558]:	worker_index: 6, step: 2265, cost: 7.244329, mlm loss: 7.244329, speed: 1.077795 steps/s, speed: 8.622358 samples/s, speed: 4414.647280 tokens/s, learning rate: 2.264e-05, loss_scalings: 2814.750488, pp_loss: 7.148774
[INFO] 2021-07-12 19:17:18,395 [run_pretraining.py:  512]:	********exe.run_2265******* 
[INFO] 2021-07-12 19:17:19,310 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:19,311 [run_pretraining.py:  534]:	loss/total_loss, 7.201035499572754, 2266
[INFO] 2021-07-12 19:17:19,311 [run_pretraining.py:  535]:	loss/mlm_loss, 7.201035499572754, 2266
[INFO] 2021-07-12 19:17:19,311 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2649999664281495e-05, 2266
[INFO] 2021-07-12 19:17:19,311 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2266
[INFO] 2021-07-12 19:17:19,311 [run_pretraining.py:  558]:	worker_index: 6, step: 2266, cost: 7.201035, mlm loss: 7.201035, speed: 1.091893 steps/s, speed: 8.735142 samples/s, speed: 4472.392705 tokens/s, learning rate: 2.265e-05, loss_scalings: 2814.750488, pp_loss: 7.197724
[INFO] 2021-07-12 19:17:19,311 [run_pretraining.py:  512]:	********exe.run_2266******* 
[INFO] 2021-07-12 19:17:20,216 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:20,217 [run_pretraining.py:  534]:	loss/total_loss, 7.222076416015625, 2267
[INFO] 2021-07-12 19:17:20,217 [run_pretraining.py:  535]:	loss/mlm_loss, 7.222076416015625, 2267
[INFO] 2021-07-12 19:17:20,217 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.266000046802219e-05, 2267
[INFO] 2021-07-12 19:17:20,217 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2267
[INFO] 2021-07-12 19:17:20,217 [run_pretraining.py:  558]:	worker_index: 6, step: 2267, cost: 7.222076, mlm loss: 7.222076, speed: 1.104730 steps/s, speed: 8.837840 samples/s, speed: 4524.973986 tokens/s, learning rate: 2.266e-05, loss_scalings: 2814.750488, pp_loss: 7.135751
[INFO] 2021-07-12 19:17:20,217 [run_pretraining.py:  512]:	********exe.run_2267******* 
[INFO] 2021-07-12 19:17:21,129 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:21,130 [run_pretraining.py:  534]:	loss/total_loss, 6.749807834625244, 2268
[INFO] 2021-07-12 19:17:21,130 [run_pretraining.py:  535]:	loss/mlm_loss, 6.749807834625244, 2268
[INFO] 2021-07-12 19:17:21,130 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.266999945277348e-05, 2268
[INFO] 2021-07-12 19:17:21,130 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2268
[INFO] 2021-07-12 19:17:21,130 [run_pretraining.py:  558]:	worker_index: 6, step: 2268, cost: 6.749808, mlm loss: 6.749808, speed: 1.095881 steps/s, speed: 8.767051 samples/s, speed: 4488.730062 tokens/s, learning rate: 2.267e-05, loss_scalings: 2814.750488, pp_loss: 6.929357
[INFO] 2021-07-12 19:17:21,130 [run_pretraining.py:  512]:	********exe.run_2268******* 
[INFO] 2021-07-12 19:17:22,046 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:22,047 [run_pretraining.py:  534]:	loss/total_loss, 7.33062744140625, 2269
[INFO] 2021-07-12 19:17:22,047 [run_pretraining.py:  535]:	loss/mlm_loss, 7.33062744140625, 2269
[INFO] 2021-07-12 19:17:22,047 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2679998437524773e-05, 2269
[INFO] 2021-07-12 19:17:22,047 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2269
[INFO] 2021-07-12 19:17:22,047 [run_pretraining.py:  558]:	worker_index: 6, step: 2269, cost: 7.330627, mlm loss: 7.330627, speed: 1.091611 steps/s, speed: 8.732891 samples/s, speed: 4471.240358 tokens/s, learning rate: 2.268e-05, loss_scalings: 2814.750488, pp_loss: 7.374031
[INFO] 2021-07-12 19:17:22,047 [run_pretraining.py:  512]:	********exe.run_2269******* 
[INFO] 2021-07-12 19:17:22,953 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:22,954 [run_pretraining.py:  534]:	loss/total_loss, 6.839345932006836, 2270
[INFO] 2021-07-12 19:17:22,954 [run_pretraining.py:  535]:	loss/mlm_loss, 6.839345932006836, 2270
[INFO] 2021-07-12 19:17:22,954 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2689999241265468e-05, 2270
[INFO] 2021-07-12 19:17:22,954 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2270
[INFO] 2021-07-12 19:17:22,954 [run_pretraining.py:  558]:	worker_index: 6, step: 2270, cost: 6.839346, mlm loss: 6.839346, speed: 1.103160 steps/s, speed: 8.825281 samples/s, speed: 4518.543709 tokens/s, learning rate: 2.269e-05, loss_scalings: 2814.750488, pp_loss: 6.935111
[INFO] 2021-07-12 19:17:22,954 [run_pretraining.py:  512]:	********exe.run_2270******* 
[INFO] 2021-07-12 19:17:23,894 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:23,895 [run_pretraining.py:  534]:	loss/total_loss, 7.188051223754883, 2271
[INFO] 2021-07-12 19:17:23,895 [run_pretraining.py:  535]:	loss/mlm_loss, 7.188051223754883, 2271
[INFO] 2021-07-12 19:17:23,895 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2700000045006163e-05, 2271
[INFO] 2021-07-12 19:17:23,895 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2271
[INFO] 2021-07-12 19:17:23,895 [run_pretraining.py:  558]:	worker_index: 6, step: 2271, cost: 7.188051, mlm loss: 7.188051, speed: 1.063503 steps/s, speed: 8.508027 samples/s, speed: 4356.109651 tokens/s, learning rate: 2.270e-05, loss_scalings: 2814.750488, pp_loss: 7.006309
[INFO] 2021-07-12 19:17:23,895 [run_pretraining.py:  512]:	********exe.run_2271******* 
[INFO] 2021-07-12 19:17:24,813 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:24,814 [run_pretraining.py:  534]:	loss/total_loss, 7.170368194580078, 2272
[INFO] 2021-07-12 19:17:24,814 [run_pretraining.py:  535]:	loss/mlm_loss, 7.170368194580078, 2272
[INFO] 2021-07-12 19:17:24,814 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2709999029757455e-05, 2272
[INFO] 2021-07-12 19:17:24,814 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2272
[INFO] 2021-07-12 19:17:24,814 [run_pretraining.py:  558]:	worker_index: 6, step: 2272, cost: 7.170368, mlm loss: 7.170368, speed: 1.089105 steps/s, speed: 8.712839 samples/s, speed: 4460.973503 tokens/s, learning rate: 2.271e-05, loss_scalings: 2814.750488, pp_loss: 6.956202
[INFO] 2021-07-12 19:17:24,814 [run_pretraining.py:  512]:	********exe.run_2272******* 
[INFO] 2021-07-12 19:17:25,719 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:25,719 [run_pretraining.py:  534]:	loss/total_loss, 5.376169681549072, 2273
[INFO] 2021-07-12 19:17:25,720 [run_pretraining.py:  535]:	loss/mlm_loss, 5.376169681549072, 2273
[INFO] 2021-07-12 19:17:25,720 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.271999983349815e-05, 2273
[INFO] 2021-07-12 19:17:25,720 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2273
[INFO] 2021-07-12 19:17:25,720 [run_pretraining.py:  558]:	worker_index: 6, step: 2273, cost: 5.376170, mlm loss: 5.376170, speed: 1.104975 steps/s, speed: 8.839798 samples/s, speed: 4525.976533 tokens/s, learning rate: 2.272e-05, loss_scalings: 2814.750488, pp_loss: 6.747577
[INFO] 2021-07-12 19:17:25,720 [run_pretraining.py:  512]:	********exe.run_2273******* 
[INFO] 2021-07-12 19:17:26,637 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:26,637 [run_pretraining.py:  534]:	loss/total_loss, 6.7269697189331055, 2274
[INFO] 2021-07-12 19:17:26,638 [run_pretraining.py:  535]:	loss/mlm_loss, 6.7269697189331055, 2274
[INFO] 2021-07-12 19:17:26,638 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2730000637238845e-05, 2274
[INFO] 2021-07-12 19:17:26,638 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2274
[INFO] 2021-07-12 19:17:26,638 [run_pretraining.py:  558]:	worker_index: 6, step: 2274, cost: 6.726970, mlm loss: 6.726970, speed: 1.090097 steps/s, speed: 8.720776 samples/s, speed: 4465.037215 tokens/s, learning rate: 2.273e-05, loss_scalings: 2814.750488, pp_loss: 6.269927
[INFO] 2021-07-12 19:17:26,638 [run_pretraining.py:  512]:	********exe.run_2274******* 
[INFO] 2021-07-12 19:17:52,505 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:52,506 [run_pretraining.py:  534]:	loss/total_loss, 7.258954048156738, 2275
[INFO] 2021-07-12 19:17:52,506 [run_pretraining.py:  535]:	loss/mlm_loss, 7.258954048156738, 2275
[INFO] 2021-07-12 19:17:52,506 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2739999621990137e-05, 2275
[INFO] 2021-07-12 19:17:52,506 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2275
[INFO] 2021-07-12 19:17:52,506 [run_pretraining.py:  558]:	worker_index: 6, step: 2275, cost: 7.258954, mlm loss: 7.258954, speed: 0.038658 steps/s, speed: 0.309266 samples/s, speed: 158.344094 tokens/s, learning rate: 2.274e-05, loss_scalings: 2814.750488, pp_loss: 6.343053
[INFO] 2021-07-12 19:17:52,506 [run_pretraining.py:  512]:	********exe.run_2275******* 
[INFO] 2021-07-12 19:17:53,416 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:53,416 [run_pretraining.py:  534]:	loss/total_loss, 7.37584924697876, 2276
[INFO] 2021-07-12 19:17:53,416 [run_pretraining.py:  535]:	loss/mlm_loss, 7.37584924697876, 2276
[INFO] 2021-07-12 19:17:53,416 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2750000425730832e-05, 2276
[INFO] 2021-07-12 19:17:53,417 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2276
[INFO] 2021-07-12 19:17:53,417 [run_pretraining.py:  558]:	worker_index: 6, step: 2276, cost: 7.375849, mlm loss: 7.375849, speed: 1.099357 steps/s, speed: 8.794856 samples/s, speed: 4502.966052 tokens/s, learning rate: 2.275e-05, loss_scalings: 2814.750488, pp_loss: 7.371719
[INFO] 2021-07-12 19:17:53,417 [run_pretraining.py:  512]:	********exe.run_2276******* 
[INFO] 2021-07-12 19:17:54,328 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:54,329 [run_pretraining.py:  534]:	loss/total_loss, 7.486458778381348, 2277
[INFO] 2021-07-12 19:17:54,329 [run_pretraining.py:  535]:	loss/mlm_loss, 7.486458778381348, 2277
[INFO] 2021-07-12 19:17:54,329 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2759999410482123e-05, 2277
[INFO] 2021-07-12 19:17:54,329 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2277
[INFO] 2021-07-12 19:17:54,329 [run_pretraining.py:  558]:	worker_index: 6, step: 2277, cost: 7.486459, mlm loss: 7.486459, speed: 1.096834 steps/s, speed: 8.774669 samples/s, speed: 4492.630692 tokens/s, learning rate: 2.276e-05, loss_scalings: 2814.750488, pp_loss: 7.455542
[INFO] 2021-07-12 19:17:54,329 [run_pretraining.py:  512]:	********exe.run_2277******* 
[INFO] 2021-07-12 19:17:55,239 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:55,240 [run_pretraining.py:  534]:	loss/total_loss, 6.8565802574157715, 2278
[INFO] 2021-07-12 19:17:55,240 [run_pretraining.py:  535]:	loss/mlm_loss, 6.8565802574157715, 2278
[INFO] 2021-07-12 19:17:55,240 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2769998395233415e-05, 2278
[INFO] 2021-07-12 19:17:55,240 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2278
[INFO] 2021-07-12 19:17:55,240 [run_pretraining.py:  558]:	worker_index: 6, step: 2278, cost: 6.856580, mlm loss: 6.856580, speed: 1.098330 steps/s, speed: 8.786643 samples/s, speed: 4498.761177 tokens/s, learning rate: 2.277e-05, loss_scalings: 2814.750488, pp_loss: 7.064256
[INFO] 2021-07-12 19:17:55,240 [run_pretraining.py:  512]:	********exe.run_2278******* 
[INFO] 2021-07-12 19:17:56,152 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:56,152 [run_pretraining.py:  534]:	loss/total_loss, 7.245692729949951, 2279
[INFO] 2021-07-12 19:17:56,152 [run_pretraining.py:  535]:	loss/mlm_loss, 7.245692729949951, 2279
[INFO] 2021-07-12 19:17:56,152 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.277999919897411e-05, 2279
[INFO] 2021-07-12 19:17:56,152 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2279
[INFO] 2021-07-12 19:17:56,153 [run_pretraining.py:  558]:	worker_index: 6, step: 2279, cost: 7.245693, mlm loss: 7.245693, speed: 1.096948 steps/s, speed: 8.775583 samples/s, speed: 4493.098330 tokens/s, learning rate: 2.278e-05, loss_scalings: 2814.750488, pp_loss: 7.395620
[INFO] 2021-07-12 19:17:56,153 [run_pretraining.py:  512]:	********exe.run_2279******* 
[INFO] 2021-07-12 19:17:57,065 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:57,066 [run_pretraining.py:  534]:	loss/total_loss, 7.404613018035889, 2280
[INFO] 2021-07-12 19:17:57,066 [run_pretraining.py:  535]:	loss/mlm_loss, 7.404613018035889, 2280
[INFO] 2021-07-12 19:17:57,066 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2790000002714805e-05, 2280
[INFO] 2021-07-12 19:17:57,066 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2280
[INFO] 2021-07-12 19:17:57,066 [run_pretraining.py:  558]:	worker_index: 6, step: 2280, cost: 7.404613, mlm loss: 7.404613, speed: 1.095564 steps/s, speed: 8.764509 samples/s, speed: 4487.428622 tokens/s, learning rate: 2.279e-05, loss_scalings: 2814.750488, pp_loss: 7.252486
[INFO] 2021-07-12 19:17:57,066 [run_pretraining.py:  512]:	********exe.run_2280******* 
[INFO] 2021-07-12 19:17:57,972 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:57,973 [run_pretraining.py:  534]:	loss/total_loss, 7.435357093811035, 2281
[INFO] 2021-07-12 19:17:57,973 [run_pretraining.py:  535]:	loss/mlm_loss, 7.435357093811035, 2281
[INFO] 2021-07-12 19:17:57,973 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2799998987466097e-05, 2281
[INFO] 2021-07-12 19:17:57,973 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2281
[INFO] 2021-07-12 19:17:57,973 [run_pretraining.py:  558]:	worker_index: 6, step: 2281, cost: 7.435357, mlm loss: 7.435357, speed: 1.103049 steps/s, speed: 8.824392 samples/s, speed: 4518.088583 tokens/s, learning rate: 2.280e-05, loss_scalings: 2814.750488, pp_loss: 7.066645
[INFO] 2021-07-12 19:17:57,973 [run_pretraining.py:  512]:	********exe.run_2281******* 
[INFO] 2021-07-12 19:17:58,906 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:58,907 [run_pretraining.py:  534]:	loss/total_loss, 7.836809158325195, 2282
[INFO] 2021-07-12 19:17:58,907 [run_pretraining.py:  535]:	loss/mlm_loss, 7.836809158325195, 2282
[INFO] 2021-07-12 19:17:58,907 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2809999791206792e-05, 2282
[INFO] 2021-07-12 19:17:58,907 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2282
[INFO] 2021-07-12 19:17:58,907 [run_pretraining.py:  558]:	worker_index: 6, step: 2282, cost: 7.836809, mlm loss: 7.836809, speed: 1.071715 steps/s, speed: 8.573721 samples/s, speed: 4389.745187 tokens/s, learning rate: 2.281e-05, loss_scalings: 2814.750488, pp_loss: 7.723732
[INFO] 2021-07-12 19:17:58,907 [run_pretraining.py:  512]:	********exe.run_2282******* 
[INFO] 2021-07-12 19:17:59,823 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:59,824 [run_pretraining.py:  534]:	loss/total_loss, 7.452939510345459, 2283
[INFO] 2021-07-12 19:17:59,824 [run_pretraining.py:  535]:	loss/mlm_loss, 7.452939510345459, 2283
[INFO] 2021-07-12 19:17:59,824 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2820000594947487e-05, 2283
[INFO] 2021-07-12 19:17:59,824 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2283
[INFO] 2021-07-12 19:17:59,824 [run_pretraining.py:  558]:	worker_index: 6, step: 2283, cost: 7.452940, mlm loss: 7.452940, speed: 1.090970 steps/s, speed: 8.727762 samples/s, speed: 4468.614296 tokens/s, learning rate: 2.282e-05, loss_scalings: 2814.750488, pp_loss: 7.080293
[INFO] 2021-07-12 19:17:59,825 [run_pretraining.py:  512]:	********exe.run_2283******* 
[INFO] 2021-07-12 19:18:00,739 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:00,739 [run_pretraining.py:  534]:	loss/total_loss, 7.757577419281006, 2284
[INFO] 2021-07-12 19:18:00,740 [run_pretraining.py:  535]:	loss/mlm_loss, 7.757577419281006, 2284
[INFO] 2021-07-12 19:18:00,740 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.282999957969878e-05, 2284
[INFO] 2021-07-12 19:18:00,740 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2284
[INFO] 2021-07-12 19:18:00,740 [run_pretraining.py:  558]:	worker_index: 6, step: 2284, cost: 7.757577, mlm loss: 7.757577, speed: 1.093268 steps/s, speed: 8.746144 samples/s, speed: 4478.025625 tokens/s, learning rate: 2.283e-05, loss_scalings: 2814.750488, pp_loss: 7.747590
[INFO] 2021-07-12 19:18:00,740 [run_pretraining.py:  512]:	********exe.run_2284******* 
[INFO] 2021-07-12 19:18:01,662 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:01,662 [run_pretraining.py:  534]:	loss/total_loss, 7.322610855102539, 2285
[INFO] 2021-07-12 19:18:01,663 [run_pretraining.py:  535]:	loss/mlm_loss, 7.322610855102539, 2285
[INFO] 2021-07-12 19:18:01,663 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2840000383439474e-05, 2285
[INFO] 2021-07-12 19:18:01,663 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2285
[INFO] 2021-07-12 19:18:01,663 [run_pretraining.py:  558]:	worker_index: 6, step: 2285, cost: 7.322611, mlm loss: 7.322611, speed: 1.084278 steps/s, speed: 8.674222 samples/s, speed: 4441.201632 tokens/s, learning rate: 2.284e-05, loss_scalings: 2814.750488, pp_loss: 7.223583
[INFO] 2021-07-12 19:18:01,663 [run_pretraining.py:  512]:	********exe.run_2285******* 
[INFO] 2021-07-12 19:18:02,572 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:02,573 [run_pretraining.py:  534]:	loss/total_loss, 8.026509284973145, 2286
[INFO] 2021-07-12 19:18:02,573 [run_pretraining.py:  535]:	loss/mlm_loss, 8.026509284973145, 2286
[INFO] 2021-07-12 19:18:02,573 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2849999368190765e-05, 2286
[INFO] 2021-07-12 19:18:02,573 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2286
[INFO] 2021-07-12 19:18:02,573 [run_pretraining.py:  558]:	worker_index: 6, step: 2286, cost: 8.026509, mlm loss: 8.026509, speed: 1.099396 steps/s, speed: 8.795169 samples/s, speed: 4503.126573 tokens/s, learning rate: 2.285e-05, loss_scalings: 2814.750488, pp_loss: 7.584282
[INFO] 2021-07-12 19:18:02,573 [run_pretraining.py:  512]:	********exe.run_2286******* 
[INFO] 2021-07-12 19:18:03,479 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:03,480 [run_pretraining.py:  534]:	loss/total_loss, 6.3944220542907715, 2287
[INFO] 2021-07-12 19:18:03,480 [run_pretraining.py:  535]:	loss/mlm_loss, 6.3944220542907715, 2287
[INFO] 2021-07-12 19:18:03,480 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2859998352942057e-05, 2287
[INFO] 2021-07-12 19:18:03,480 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2287
[INFO] 2021-07-12 19:18:03,480 [run_pretraining.py:  558]:	worker_index: 6, step: 2287, cost: 6.394422, mlm loss: 6.394422, speed: 1.103546 steps/s, speed: 8.828371 samples/s, speed: 4520.126076 tokens/s, learning rate: 2.286e-05, loss_scalings: 2814.750488, pp_loss: 7.039841
[INFO] 2021-07-12 19:18:03,480 [run_pretraining.py:  512]:	********exe.run_2287******* 
[INFO] 2021-07-12 19:18:04,395 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:04,395 [run_pretraining.py:  534]:	loss/total_loss, 6.577145576477051, 2288
[INFO] 2021-07-12 19:18:04,395 [run_pretraining.py:  535]:	loss/mlm_loss, 6.577145576477051, 2288
[INFO] 2021-07-12 19:18:04,395 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2869999156682752e-05, 2288
[INFO] 2021-07-12 19:18:04,396 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2288
[INFO] 2021-07-12 19:18:04,396 [run_pretraining.py:  558]:	worker_index: 6, step: 2288, cost: 6.577146, mlm loss: 6.577146, speed: 1.093013 steps/s, speed: 8.744106 samples/s, speed: 4476.982372 tokens/s, learning rate: 2.287e-05, loss_scalings: 2814.750488, pp_loss: 7.661523
[INFO] 2021-07-12 19:18:04,396 [run_pretraining.py:  512]:	********exe.run_2288******* 
[INFO] 2021-07-12 19:18:05,312 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:05,313 [run_pretraining.py:  534]:	loss/total_loss, 5.969949722290039, 2289
[INFO] 2021-07-12 19:18:05,313 [run_pretraining.py:  535]:	loss/mlm_loss, 5.969949722290039, 2289
[INFO] 2021-07-12 19:18:05,313 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2879999960423447e-05, 2289
[INFO] 2021-07-12 19:18:05,313 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2289
[INFO] 2021-07-12 19:18:05,313 [run_pretraining.py:  558]:	worker_index: 6, step: 2289, cost: 5.969950, mlm loss: 5.969950, speed: 1.090754 steps/s, speed: 8.726035 samples/s, speed: 4467.729945 tokens/s, learning rate: 2.288e-05, loss_scalings: 2814.750488, pp_loss: 6.912307
[INFO] 2021-07-12 19:18:05,313 [run_pretraining.py:  512]:	********exe.run_2289******* 
[INFO] 2021-07-12 19:18:06,219 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:06,220 [run_pretraining.py:  534]:	loss/total_loss, 7.441148281097412, 2290
[INFO] 2021-07-12 19:18:06,220 [run_pretraining.py:  535]:	loss/mlm_loss, 7.441148281097412, 2290
[INFO] 2021-07-12 19:18:06,220 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.288999894517474e-05, 2290
[INFO] 2021-07-12 19:18:06,220 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2290
[INFO] 2021-07-12 19:18:06,220 [run_pretraining.py:  558]:	worker_index: 6, step: 2290, cost: 7.441148, mlm loss: 7.441148, speed: 1.103408 steps/s, speed: 8.827263 samples/s, speed: 4519.558865 tokens/s, learning rate: 2.289e-05, loss_scalings: 2814.750488, pp_loss: 7.336040
[INFO] 2021-07-12 19:18:06,220 [run_pretraining.py:  512]:	********exe.run_2290******* 
[INFO] 2021-07-12 19:18:07,163 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:07,163 [run_pretraining.py:  534]:	loss/total_loss, 6.77777099609375, 2291
[INFO] 2021-07-12 19:18:07,164 [run_pretraining.py:  535]:	loss/mlm_loss, 6.77777099609375, 2291
[INFO] 2021-07-12 19:18:07,164 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2899999748915434e-05, 2291
[INFO] 2021-07-12 19:18:07,164 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2291
[INFO] 2021-07-12 19:18:07,164 [run_pretraining.py:  558]:	worker_index: 6, step: 2291, cost: 6.777771, mlm loss: 6.777771, speed: 1.060461 steps/s, speed: 8.483685 samples/s, speed: 4343.646543 tokens/s, learning rate: 2.290e-05, loss_scalings: 2814.750488, pp_loss: 7.162703
[INFO] 2021-07-12 19:18:07,164 [run_pretraining.py:  512]:	********exe.run_2291******* 
[INFO] 2021-07-12 19:18:08,071 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:08,072 [run_pretraining.py:  534]:	loss/total_loss, 7.128947734832764, 2292
[INFO] 2021-07-12 19:18:08,072 [run_pretraining.py:  535]:	loss/mlm_loss, 7.128947734832764, 2292
[INFO] 2021-07-12 19:18:08,072 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.291000055265613e-05, 2292
[INFO] 2021-07-12 19:18:08,072 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2292
[INFO] 2021-07-12 19:18:08,072 [run_pretraining.py:  558]:	worker_index: 6, step: 2292, cost: 7.128948, mlm loss: 7.128948, speed: 1.101666 steps/s, speed: 8.813331 samples/s, speed: 4512.425598 tokens/s, learning rate: 2.291e-05, loss_scalings: 2814.750488, pp_loss: 6.765503
[INFO] 2021-07-12 19:18:08,072 [run_pretraining.py:  512]:	********exe.run_2292******* 
[INFO] 2021-07-12 19:18:08,996 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:08,997 [run_pretraining.py:  534]:	loss/total_loss, 6.620643615722656, 2293
[INFO] 2021-07-12 19:18:08,997 [run_pretraining.py:  535]:	loss/mlm_loss, 6.620643615722656, 2293
[INFO] 2021-07-12 19:18:08,997 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.291999953740742e-05, 2293
[INFO] 2021-07-12 19:18:08,997 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2293
[INFO] 2021-07-12 19:18:08,997 [run_pretraining.py:  558]:	worker_index: 6, step: 2293, cost: 6.620644, mlm loss: 6.620644, speed: 1.081812 steps/s, speed: 8.654494 samples/s, speed: 4431.100679 tokens/s, learning rate: 2.292e-05, loss_scalings: 2814.750488, pp_loss: 6.926575
[INFO] 2021-07-12 19:18:08,997 [run_pretraining.py:  512]:	********exe.run_2293******* 
[INFO] 2021-07-12 19:18:09,907 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:09,908 [run_pretraining.py:  534]:	loss/total_loss, 7.405768871307373, 2294
[INFO] 2021-07-12 19:18:09,908 [run_pretraining.py:  535]:	loss/mlm_loss, 7.405768871307373, 2294
[INFO] 2021-07-12 19:18:09,908 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2930000341148116e-05, 2294
[INFO] 2021-07-12 19:18:09,908 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2294
[INFO] 2021-07-12 19:18:09,908 [run_pretraining.py:  558]:	worker_index: 6, step: 2294, cost: 7.405769, mlm loss: 7.405769, speed: 1.099064 steps/s, speed: 8.792512 samples/s, speed: 4501.766048 tokens/s, learning rate: 2.293e-05, loss_scalings: 2814.750488, pp_loss: 7.120728
[INFO] 2021-07-12 19:18:09,908 [run_pretraining.py:  512]:	********exe.run_2294******* 
[INFO] 2021-07-12 19:18:10,840 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:10,841 [run_pretraining.py:  534]:	loss/total_loss, 6.793935775756836, 2295
[INFO] 2021-07-12 19:18:10,841 [run_pretraining.py:  535]:	loss/mlm_loss, 6.793935775756836, 2295
[INFO] 2021-07-12 19:18:10,841 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2939999325899407e-05, 2295
[INFO] 2021-07-12 19:18:10,841 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2295
[INFO] 2021-07-12 19:18:10,841 [run_pretraining.py:  558]:	worker_index: 6, step: 2295, cost: 6.793936, mlm loss: 6.793936, speed: 1.072472 steps/s, speed: 8.579778 samples/s, speed: 4392.846505 tokens/s, learning rate: 2.294e-05, loss_scalings: 2814.750488, pp_loss: 6.733837
[INFO] 2021-07-12 19:18:10,841 [run_pretraining.py:  512]:	********exe.run_2295******* 
[INFO] 2021-07-12 19:18:11,902 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:11,902 [run_pretraining.py:  534]:	loss/total_loss, 6.868373870849609, 2296
[INFO] 2021-07-12 19:18:11,902 [run_pretraining.py:  535]:	loss/mlm_loss, 6.868373870849609, 2296
[INFO] 2021-07-12 19:18:11,903 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.29499983106507e-05, 2296
[INFO] 2021-07-12 19:18:11,903 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2296
[INFO] 2021-07-12 19:18:11,903 [run_pretraining.py:  558]:	worker_index: 6, step: 2296, cost: 6.868374, mlm loss: 6.868374, speed: 0.942520 steps/s, speed: 7.540161 samples/s, speed: 3860.562344 tokens/s, learning rate: 2.295e-05, loss_scalings: 2814.750488, pp_loss: 7.053207
[INFO] 2021-07-12 19:18:11,903 [run_pretraining.py:  512]:	********exe.run_2296******* 
[INFO] 2021-07-12 19:18:12,941 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:12,941 [run_pretraining.py:  534]:	loss/total_loss, 7.725481986999512, 2297
[INFO] 2021-07-12 19:18:12,941 [run_pretraining.py:  535]:	loss/mlm_loss, 7.725481986999512, 2297
[INFO] 2021-07-12 19:18:12,942 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2959999114391394e-05, 2297
[INFO] 2021-07-12 19:18:12,942 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2297
[INFO] 2021-07-12 19:18:12,942 [run_pretraining.py:  558]:	worker_index: 6, step: 2297, cost: 7.725482, mlm loss: 7.725482, speed: 0.963144 steps/s, speed: 7.705155 samples/s, speed: 3945.039347 tokens/s, learning rate: 2.296e-05, loss_scalings: 2814.750488, pp_loss: 7.188121
[INFO] 2021-07-12 19:18:12,942 [run_pretraining.py:  512]:	********exe.run_2297******* 
[INFO] 2021-07-12 19:18:13,997 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:13,998 [run_pretraining.py:  534]:	loss/total_loss, 7.4675679206848145, 2298
[INFO] 2021-07-12 19:18:13,998 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4675679206848145, 2298
[INFO] 2021-07-12 19:18:13,998 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.296999991813209e-05, 2298
[INFO] 2021-07-12 19:18:13,998 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2298
[INFO] 2021-07-12 19:18:13,998 [run_pretraining.py:  558]:	worker_index: 6, step: 2298, cost: 7.467568, mlm loss: 7.467568, speed: 0.947416 steps/s, speed: 7.579326 samples/s, speed: 3880.614665 tokens/s, learning rate: 2.297e-05, loss_scalings: 2814.750488, pp_loss: 7.437713
[INFO] 2021-07-12 19:18:13,998 [run_pretraining.py:  512]:	********exe.run_2298******* 
[INFO] 2021-07-12 19:18:15,054 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:15,054 [run_pretraining.py:  534]:	loss/total_loss, 7.1295061111450195, 2299
[INFO] 2021-07-12 19:18:15,054 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1295061111450195, 2299
[INFO] 2021-07-12 19:18:15,054 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.297999890288338e-05, 2299
[INFO] 2021-07-12 19:18:15,055 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2299
[INFO] 2021-07-12 19:18:15,055 [run_pretraining.py:  558]:	worker_index: 6, step: 2299, cost: 7.129506, mlm loss: 7.129506, speed: 0.946895 steps/s, speed: 7.575159 samples/s, speed: 3878.481417 tokens/s, learning rate: 2.298e-05, loss_scalings: 2814.750488, pp_loss: 7.140698
[INFO] 2021-07-12 19:18:15,055 [run_pretraining.py:  512]:	********exe.run_2299******* 
[INFO] 2021-07-12 19:18:40,219 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:40,219 [run_pretraining.py:  534]:	loss/total_loss, 7.63907527923584, 2300
[INFO] 2021-07-12 19:18:40,219 [run_pretraining.py:  535]:	loss/mlm_loss, 7.63907527923584, 2300
[INFO] 2021-07-12 19:18:40,220 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2989999706624076e-05, 2300
[INFO] 2021-07-12 19:18:40,220 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2300
[INFO] 2021-07-12 19:18:40,220 [run_pretraining.py:  558]:	worker_index: 6, step: 2300, cost: 7.639075, mlm loss: 7.639075, speed: 0.039739 steps/s, speed: 0.317910 samples/s, speed: 162.769824 tokens/s, learning rate: 2.299e-05, loss_scalings: 2814.750488, pp_loss: 7.499007
[INFO] 2021-07-12 19:18:40,220 [run_pretraining.py:  512]:	********exe.run_2300******* 
[INFO] 2021-07-12 19:18:41,145 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:41,146 [run_pretraining.py:  534]:	loss/total_loss, 8.139862060546875, 2301
[INFO] 2021-07-12 19:18:41,146 [run_pretraining.py:  535]:	loss/mlm_loss, 8.139862060546875, 2301
[INFO] 2021-07-12 19:18:41,146 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.300000051036477e-05, 2301
[INFO] 2021-07-12 19:18:41,146 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2301
[INFO] 2021-07-12 19:18:41,146 [run_pretraining.py:  558]:	worker_index: 6, step: 2301, cost: 8.139862, mlm loss: 8.139862, speed: 1.080102 steps/s, speed: 8.640814 samples/s, speed: 4424.096725 tokens/s, learning rate: 2.300e-05, loss_scalings: 2814.750488, pp_loss: 7.511320
[INFO] 2021-07-12 19:18:41,146 [run_pretraining.py:  512]:	********exe.run_2301******* 
[INFO] 2021-07-12 19:18:42,058 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:42,059 [run_pretraining.py:  534]:	loss/total_loss, 6.913482189178467, 2302
[INFO] 2021-07-12 19:18:42,059 [run_pretraining.py:  535]:	loss/mlm_loss, 6.913482189178467, 2302
[INFO] 2021-07-12 19:18:42,059 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3009999495116062e-05, 2302
[INFO] 2021-07-12 19:18:42,059 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2302
[INFO] 2021-07-12 19:18:42,059 [run_pretraining.py:  558]:	worker_index: 6, step: 2302, cost: 6.913482, mlm loss: 6.913482, speed: 1.095997 steps/s, speed: 8.767976 samples/s, speed: 4489.203927 tokens/s, learning rate: 2.301e-05, loss_scalings: 2814.750488, pp_loss: 7.093925
[INFO] 2021-07-12 19:18:42,060 [run_pretraining.py:  512]:	********exe.run_2302******* 
[INFO] 2021-07-12 19:18:43,003 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:43,004 [run_pretraining.py:  534]:	loss/total_loss, 8.0481538772583, 2303
[INFO] 2021-07-12 19:18:43,005 [run_pretraining.py:  535]:	loss/mlm_loss, 8.0481538772583, 2303
[INFO] 2021-07-12 19:18:43,005 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3019998479867354e-05, 2303
[INFO] 2021-07-12 19:18:43,007 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2303
[INFO] 2021-07-12 19:18:43,007 [run_pretraining.py:  558]:	worker_index: 6, step: 2303, cost: 8.048154, mlm loss: 8.048154, speed: 1.059452 steps/s, speed: 8.475617 samples/s, speed: 4339.515679 tokens/s, learning rate: 2.302e-05, loss_scalings: 2814.750488, pp_loss: 7.471552
[INFO] 2021-07-12 19:18:43,010 [run_pretraining.py:  512]:	********exe.run_2303******* 
[INFO] 2021-07-12 19:18:43,899 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:43,900 [run_pretraining.py:  534]:	loss/total_loss, 7.527041912078857, 2304
[INFO] 2021-07-12 19:18:43,900 [run_pretraining.py:  535]:	loss/mlm_loss, 7.527041912078857, 2304
[INFO] 2021-07-12 19:18:43,900 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.302999928360805e-05, 2304
[INFO] 2021-07-12 19:18:43,900 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2304
[INFO] 2021-07-12 19:18:43,900 [run_pretraining.py:  558]:	worker_index: 6, step: 2304, cost: 7.527042, mlm loss: 7.527042, speed: 1.123956 steps/s, speed: 8.991651 samples/s, speed: 4603.725344 tokens/s, learning rate: 2.303e-05, loss_scalings: 2814.750488, pp_loss: 7.166910
[INFO] 2021-07-12 19:18:43,900 [run_pretraining.py:  512]:	********exe.run_2304******* 
[INFO] 2021-07-12 19:18:44,820 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:44,820 [run_pretraining.py:  534]:	loss/total_loss, 7.302721977233887, 2305
[INFO] 2021-07-12 19:18:44,820 [run_pretraining.py:  535]:	loss/mlm_loss, 7.302721977233887, 2305
[INFO] 2021-07-12 19:18:44,820 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.303999826835934e-05, 2305
[INFO] 2021-07-12 19:18:44,821 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2305
[INFO] 2021-07-12 19:18:44,821 [run_pretraining.py:  558]:	worker_index: 6, step: 2305, cost: 7.302722, mlm loss: 7.302722, speed: 1.086951 steps/s, speed: 8.695606 samples/s, speed: 4452.150468 tokens/s, learning rate: 2.304e-05, loss_scalings: 2814.750488, pp_loss: 7.279377
[INFO] 2021-07-12 19:18:44,821 [run_pretraining.py:  512]:	********exe.run_2305******* 
[INFO] 2021-07-12 19:18:45,737 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:45,737 [run_pretraining.py:  534]:	loss/total_loss, 7.338479995727539, 2306
[INFO] 2021-07-12 19:18:45,738 [run_pretraining.py:  535]:	loss/mlm_loss, 7.338479995727539, 2306
[INFO] 2021-07-12 19:18:45,738 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3049999072100036e-05, 2306
[INFO] 2021-07-12 19:18:45,738 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2306
[INFO] 2021-07-12 19:18:45,738 [run_pretraining.py:  558]:	worker_index: 6, step: 2306, cost: 7.338480, mlm loss: 7.338480, speed: 1.091107 steps/s, speed: 8.728859 samples/s, speed: 4469.175767 tokens/s, learning rate: 2.305e-05, loss_scalings: 2814.750488, pp_loss: 6.279236
[INFO] 2021-07-12 19:18:45,738 [run_pretraining.py:  512]:	********exe.run_2306******* 
[INFO] 2021-07-12 19:18:46,655 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:46,656 [run_pretraining.py:  534]:	loss/total_loss, 7.586950302124023, 2307
[INFO] 2021-07-12 19:18:46,656 [run_pretraining.py:  535]:	loss/mlm_loss, 7.586950302124023, 2307
[INFO] 2021-07-12 19:18:46,656 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.305999987584073e-05, 2307
[INFO] 2021-07-12 19:18:46,656 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2307
[INFO] 2021-07-12 19:18:46,656 [run_pretraining.py:  558]:	worker_index: 6, step: 2307, cost: 7.586950, mlm loss: 7.586950, speed: 1.090027 steps/s, speed: 8.720218 samples/s, speed: 4464.751760 tokens/s, learning rate: 2.306e-05, loss_scalings: 2814.750488, pp_loss: 7.297596
[INFO] 2021-07-12 19:18:46,656 [run_pretraining.py:  512]:	********exe.run_2307******* 
[INFO] 2021-07-12 19:18:47,573 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:47,574 [run_pretraining.py:  534]:	loss/total_loss, 6.9599127769470215, 2308
[INFO] 2021-07-12 19:18:47,574 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9599127769470215, 2308
[INFO] 2021-07-12 19:18:47,574 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3069998860592023e-05, 2308
[INFO] 2021-07-12 19:18:47,574 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2308
[INFO] 2021-07-12 19:18:47,574 [run_pretraining.py:  558]:	worker_index: 6, step: 2308, cost: 6.959913, mlm loss: 6.959913, speed: 1.089584 steps/s, speed: 8.716675 samples/s, speed: 4462.937769 tokens/s, learning rate: 2.307e-05, loss_scalings: 2814.750488, pp_loss: 7.210569
[INFO] 2021-07-12 19:18:47,575 [run_pretraining.py:  512]:	********exe.run_2308******* 
[INFO] 2021-07-12 19:18:48,504 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:48,505 [run_pretraining.py:  534]:	loss/total_loss, 7.780878067016602, 2309
[INFO] 2021-07-12 19:18:48,505 [run_pretraining.py:  535]:	loss/mlm_loss, 7.780878067016602, 2309
[INFO] 2021-07-12 19:18:48,505 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3079999664332718e-05, 2309
[INFO] 2021-07-12 19:18:48,505 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2309
[INFO] 2021-07-12 19:18:48,505 [run_pretraining.py:  558]:	worker_index: 6, step: 2309, cost: 7.780878, mlm loss: 7.780878, speed: 1.075446 steps/s, speed: 8.603566 samples/s, speed: 4405.025763 tokens/s, learning rate: 2.308e-05, loss_scalings: 2814.750488, pp_loss: 7.474649
[INFO] 2021-07-12 19:18:48,505 [run_pretraining.py:  512]:	********exe.run_2309******* 
[INFO] 2021-07-12 19:18:49,419 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:49,419 [run_pretraining.py:  534]:	loss/total_loss, 7.138030052185059, 2310
[INFO] 2021-07-12 19:18:49,420 [run_pretraining.py:  535]:	loss/mlm_loss, 7.138030052185059, 2310
[INFO] 2021-07-12 19:18:49,420 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3090000468073413e-05, 2310
[INFO] 2021-07-12 19:18:49,420 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2310
[INFO] 2021-07-12 19:18:49,420 [run_pretraining.py:  558]:	worker_index: 6, step: 2310, cost: 7.138030, mlm loss: 7.138030, speed: 1.093886 steps/s, speed: 8.751091 samples/s, speed: 4480.558761 tokens/s, learning rate: 2.309e-05, loss_scalings: 2814.750488, pp_loss: 7.569543
[INFO] 2021-07-12 19:18:49,420 [run_pretraining.py:  512]:	********exe.run_2310******* 
[INFO] 2021-07-12 19:18:50,342 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:50,342 [run_pretraining.py:  534]:	loss/total_loss, 7.551666259765625, 2311
[INFO] 2021-07-12 19:18:50,342 [run_pretraining.py:  535]:	loss/mlm_loss, 7.551666259765625, 2311
[INFO] 2021-07-12 19:18:50,343 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3099999452824704e-05, 2311
[INFO] 2021-07-12 19:18:50,343 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2311
[INFO] 2021-07-12 19:18:50,343 [run_pretraining.py:  558]:	worker_index: 6, step: 2311, cost: 7.551666, mlm loss: 7.551666, speed: 1.084435 steps/s, speed: 8.675478 samples/s, speed: 4441.844663 tokens/s, learning rate: 2.310e-05, loss_scalings: 2814.750488, pp_loss: 7.574778
[INFO] 2021-07-12 19:18:50,343 [run_pretraining.py:  512]:	********exe.run_2311******* 
[INFO] 2021-07-12 19:18:51,258 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:51,259 [run_pretraining.py:  534]:	loss/total_loss, 6.835788249969482, 2312
[INFO] 2021-07-12 19:18:51,259 [run_pretraining.py:  535]:	loss/mlm_loss, 6.835788249969482, 2312
[INFO] 2021-07-12 19:18:51,259 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3109998437575996e-05, 2312
[INFO] 2021-07-12 19:18:51,259 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2312
[INFO] 2021-07-12 19:18:51,259 [run_pretraining.py:  558]:	worker_index: 6, step: 2312, cost: 6.835788, mlm loss: 6.835788, speed: 1.092105 steps/s, speed: 8.736836 samples/s, speed: 4473.260267 tokens/s, learning rate: 2.311e-05, loss_scalings: 2814.750488, pp_loss: 7.125602
[INFO] 2021-07-12 19:18:51,259 [run_pretraining.py:  512]:	********exe.run_2312******* 
[INFO] 2021-07-12 19:18:52,180 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:52,180 [run_pretraining.py:  534]:	loss/total_loss, 6.667941093444824, 2313
[INFO] 2021-07-12 19:18:52,180 [run_pretraining.py:  535]:	loss/mlm_loss, 6.667941093444824, 2313
[INFO] 2021-07-12 19:18:52,180 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.311999924131669e-05, 2313
[INFO] 2021-07-12 19:18:52,180 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2313
[INFO] 2021-07-12 19:18:52,181 [run_pretraining.py:  558]:	worker_index: 6, step: 2313, cost: 6.667941, mlm loss: 6.667941, speed: 1.086086 steps/s, speed: 8.688685 samples/s, speed: 4448.606598 tokens/s, learning rate: 2.312e-05, loss_scalings: 2814.750488, pp_loss: 6.711253
[INFO] 2021-07-12 19:18:52,181 [run_pretraining.py:  512]:	********exe.run_2313******* 
[INFO] 2021-07-12 19:18:53,110 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:53,110 [run_pretraining.py:  534]:	loss/total_loss, 7.235528945922852, 2314
[INFO] 2021-07-12 19:18:53,111 [run_pretraining.py:  535]:	loss/mlm_loss, 7.235528945922852, 2314
[INFO] 2021-07-12 19:18:53,111 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3129998226067983e-05, 2314
[INFO] 2021-07-12 19:18:53,111 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2314
[INFO] 2021-07-12 19:18:53,111 [run_pretraining.py:  558]:	worker_index: 6, step: 2314, cost: 7.235529, mlm loss: 7.235529, speed: 1.075644 steps/s, speed: 8.605150 samples/s, speed: 4405.836877 tokens/s, learning rate: 2.313e-05, loss_scalings: 2814.750488, pp_loss: 7.126543
[INFO] 2021-07-12 19:18:53,111 [run_pretraining.py:  512]:	********exe.run_2314******* 
[INFO] 2021-07-12 19:18:54,037 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:54,037 [run_pretraining.py:  534]:	loss/total_loss, 6.283308506011963, 2315
[INFO] 2021-07-12 19:18:54,037 [run_pretraining.py:  535]:	loss/mlm_loss, 6.283308506011963, 2315
[INFO] 2021-07-12 19:18:54,038 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3139999029808678e-05, 2315
[INFO] 2021-07-12 19:18:54,038 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2315
[INFO] 2021-07-12 19:18:54,038 [run_pretraining.py:  558]:	worker_index: 6, step: 2315, cost: 6.283309, mlm loss: 6.283309, speed: 1.079677 steps/s, speed: 8.637415 samples/s, speed: 4422.356594 tokens/s, learning rate: 2.314e-05, loss_scalings: 2814.750488, pp_loss: 6.938570
[INFO] 2021-07-12 19:18:54,038 [run_pretraining.py:  512]:	********exe.run_2315******* 
[INFO] 2021-07-12 19:18:54,952 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:54,953 [run_pretraining.py:  534]:	loss/total_loss, 6.866769313812256, 2316
[INFO] 2021-07-12 19:18:54,953 [run_pretraining.py:  535]:	loss/mlm_loss, 6.866769313812256, 2316
[INFO] 2021-07-12 19:18:54,953 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3149999833549373e-05, 2316
[INFO] 2021-07-12 19:18:54,953 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2316
[INFO] 2021-07-12 19:18:54,953 [run_pretraining.py:  558]:	worker_index: 6, step: 2316, cost: 6.866769, mlm loss: 6.866769, speed: 1.093355 steps/s, speed: 8.746839 samples/s, speed: 4478.381656 tokens/s, learning rate: 2.315e-05, loss_scalings: 2814.750488, pp_loss: 7.198442
[INFO] 2021-07-12 19:18:54,953 [run_pretraining.py:  512]:	********exe.run_2316******* 
[INFO] 2021-07-12 19:18:55,875 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:55,876 [run_pretraining.py:  534]:	loss/total_loss, 6.729341506958008, 2317
[INFO] 2021-07-12 19:18:55,876 [run_pretraining.py:  535]:	loss/mlm_loss, 6.729341506958008, 2317
[INFO] 2021-07-12 19:18:55,876 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3159998818300664e-05, 2317
[INFO] 2021-07-12 19:18:55,876 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2317
[INFO] 2021-07-12 19:18:55,876 [run_pretraining.py:  558]:	worker_index: 6, step: 2317, cost: 6.729342, mlm loss: 6.729342, speed: 1.084101 steps/s, speed: 8.672807 samples/s, speed: 4440.477297 tokens/s, learning rate: 2.316e-05, loss_scalings: 2814.750488, pp_loss: 7.227960
[INFO] 2021-07-12 19:18:55,876 [run_pretraining.py:  512]:	********exe.run_2317******* 
[INFO] 2021-07-12 19:18:56,789 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:56,790 [run_pretraining.py:  534]:	loss/total_loss, 6.827924728393555, 2318
[INFO] 2021-07-12 19:18:56,790 [run_pretraining.py:  535]:	loss/mlm_loss, 6.827924728393555, 2318
[INFO] 2021-07-12 19:18:56,790 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.316999962204136e-05, 2318
[INFO] 2021-07-12 19:18:56,790 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2318
[INFO] 2021-07-12 19:18:56,790 [run_pretraining.py:  558]:	worker_index: 6, step: 2318, cost: 6.827925, mlm loss: 6.827925, speed: 1.095096 steps/s, speed: 8.760765 samples/s, speed: 4485.511839 tokens/s, learning rate: 2.317e-05, loss_scalings: 2814.750488, pp_loss: 6.373227
[INFO] 2021-07-12 19:18:56,790 [run_pretraining.py:  512]:	********exe.run_2318******* 
[INFO] 2021-07-12 19:18:57,703 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:57,703 [run_pretraining.py:  534]:	loss/total_loss, 7.145815849304199, 2319
[INFO] 2021-07-12 19:18:57,703 [run_pretraining.py:  535]:	loss/mlm_loss, 7.145815849304199, 2319
[INFO] 2021-07-12 19:18:57,704 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3180000425782055e-05, 2319
[INFO] 2021-07-12 19:18:57,704 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2319
[INFO] 2021-07-12 19:18:57,704 [run_pretraining.py:  558]:	worker_index: 6, step: 2319, cost: 7.145816, mlm loss: 7.145816, speed: 1.095324 steps/s, speed: 8.762589 samples/s, speed: 4486.445422 tokens/s, learning rate: 2.318e-05, loss_scalings: 2814.750488, pp_loss: 7.355699
[INFO] 2021-07-12 19:18:57,704 [run_pretraining.py:  512]:	********exe.run_2319******* 
[INFO] 2021-07-12 19:18:58,618 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:58,618 [run_pretraining.py:  534]:	loss/total_loss, 7.223756313323975, 2320
[INFO] 2021-07-12 19:18:58,619 [run_pretraining.py:  535]:	loss/mlm_loss, 7.223756313323975, 2320
[INFO] 2021-07-12 19:18:58,619 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3189999410533346e-05, 2320
[INFO] 2021-07-12 19:18:58,619 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2320
[INFO] 2021-07-12 19:18:58,619 [run_pretraining.py:  558]:	worker_index: 6, step: 2320, cost: 7.223756, mlm loss: 7.223756, speed: 1.093576 steps/s, speed: 8.748607 samples/s, speed: 4479.286579 tokens/s, learning rate: 2.319e-05, loss_scalings: 2814.750488, pp_loss: 7.290096
[INFO] 2021-07-12 19:18:58,619 [run_pretraining.py:  512]:	********exe.run_2320******* 
[INFO] 2021-07-12 19:18:59,535 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:59,536 [run_pretraining.py:  534]:	loss/total_loss, 6.970766067504883, 2321
[INFO] 2021-07-12 19:18:59,536 [run_pretraining.py:  535]:	loss/mlm_loss, 6.970766067504883, 2321
[INFO] 2021-07-12 19:18:59,536 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3199998395284638e-05, 2321
[INFO] 2021-07-12 19:18:59,536 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2321
[INFO] 2021-07-12 19:18:59,536 [run_pretraining.py:  558]:	worker_index: 6, step: 2321, cost: 6.970766, mlm loss: 6.970766, speed: 1.091109 steps/s, speed: 8.728875 samples/s, speed: 4469.183906 tokens/s, learning rate: 2.320e-05, loss_scalings: 2814.750488, pp_loss: 7.552148
[INFO] 2021-07-12 19:18:59,536 [run_pretraining.py:  512]:	********exe.run_2321******* 
[INFO] 2021-07-12 19:19:00,453 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:00,453 [run_pretraining.py:  534]:	loss/total_loss, 7.237037658691406, 2322
[INFO] 2021-07-12 19:19:00,453 [run_pretraining.py:  535]:	loss/mlm_loss, 7.237037658691406, 2322
[INFO] 2021-07-12 19:19:00,454 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3209999199025333e-05, 2322
[INFO] 2021-07-12 19:19:00,454 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2322
[INFO] 2021-07-12 19:19:00,454 [run_pretraining.py:  558]:	worker_index: 6, step: 2322, cost: 7.237038, mlm loss: 7.237038, speed: 1.090578 steps/s, speed: 8.724624 samples/s, speed: 4467.007385 tokens/s, learning rate: 2.321e-05, loss_scalings: 2814.750488, pp_loss: 7.186184
[INFO] 2021-07-12 19:19:00,454 [run_pretraining.py:  512]:	********exe.run_2322******* 
[INFO] 2021-07-12 19:19:01,374 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:01,375 [run_pretraining.py:  534]:	loss/total_loss, 7.611804008483887, 2323
[INFO] 2021-07-12 19:19:01,375 [run_pretraining.py:  535]:	loss/mlm_loss, 7.611804008483887, 2323
[INFO] 2021-07-12 19:19:01,375 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3219998183776625e-05, 2323
[INFO] 2021-07-12 19:19:01,375 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2323
[INFO] 2021-07-12 19:19:01,375 [run_pretraining.py:  558]:	worker_index: 6, step: 2323, cost: 7.611804, mlm loss: 7.611804, speed: 1.085820 steps/s, speed: 8.686559 samples/s, speed: 4447.518285 tokens/s, learning rate: 2.322e-05, loss_scalings: 2814.750488, pp_loss: 7.144101
[INFO] 2021-07-12 19:19:01,375 [run_pretraining.py:  512]:	********exe.run_2323******* 
[INFO] 2021-07-12 19:19:02,293 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:02,294 [run_pretraining.py:  534]:	loss/total_loss, 6.245330333709717, 2324
[INFO] 2021-07-12 19:19:02,294 [run_pretraining.py:  535]:	loss/mlm_loss, 6.245330333709717, 2324
[INFO] 2021-07-12 19:19:02,294 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.322999898751732e-05, 2324
[INFO] 2021-07-12 19:19:02,294 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2324
[INFO] 2021-07-12 19:19:02,294 [run_pretraining.py:  558]:	worker_index: 6, step: 2324, cost: 6.245330, mlm loss: 6.245330, speed: 1.088862 steps/s, speed: 8.710894 samples/s, speed: 4459.977545 tokens/s, learning rate: 2.323e-05, loss_scalings: 2814.750488, pp_loss: 6.925731
[INFO] 2021-07-12 19:19:02,295 [run_pretraining.py:  512]:	********exe.run_2324******* 
[INFO] 2021-07-12 19:19:03,210 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:03,211 [run_pretraining.py:  534]:	loss/total_loss, 8.056933403015137, 2325
[INFO] 2021-07-12 19:19:03,211 [run_pretraining.py:  535]:	loss/mlm_loss, 8.056933403015137, 2325
[INFO] 2021-07-12 19:19:03,211 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3239999791258015e-05, 2325
[INFO] 2021-07-12 19:19:03,211 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2325
[INFO] 2021-07-12 19:19:03,211 [run_pretraining.py:  558]:	worker_index: 6, step: 2325, cost: 8.056933, mlm loss: 8.056933, speed: 1.091993 steps/s, speed: 8.735943 samples/s, speed: 4472.802572 tokens/s, learning rate: 2.324e-05, loss_scalings: 2814.750488, pp_loss: 7.039886
[INFO] 2021-07-12 19:19:03,211 [run_pretraining.py:  512]:	********exe.run_2325******* 
[INFO] 2021-07-12 19:19:04,125 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:04,125 [run_pretraining.py:  534]:	loss/total_loss, 7.619476795196533, 2326
[INFO] 2021-07-12 19:19:04,125 [run_pretraining.py:  535]:	loss/mlm_loss, 7.619476795196533, 2326
[INFO] 2021-07-12 19:19:04,125 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3249998776009306e-05, 2326
[INFO] 2021-07-12 19:19:04,125 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2326
[INFO] 2021-07-12 19:19:04,126 [run_pretraining.py:  558]:	worker_index: 6, step: 2326, cost: 7.619477, mlm loss: 7.619477, speed: 1.094267 steps/s, speed: 8.754137 samples/s, speed: 4482.118139 tokens/s, learning rate: 2.325e-05, loss_scalings: 2814.750488, pp_loss: 7.657787
[INFO] 2021-07-12 19:19:04,126 [run_pretraining.py:  512]:	********exe.run_2326******* 
[INFO] 2021-07-12 19:19:05,034 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:05,035 [run_pretraining.py:  534]:	loss/total_loss, 7.305443286895752, 2327
[INFO] 2021-07-12 19:19:05,035 [run_pretraining.py:  535]:	loss/mlm_loss, 7.305443286895752, 2327
[INFO] 2021-07-12 19:19:05,035 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.325999957975e-05, 2327
[INFO] 2021-07-12 19:19:05,035 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2327
[INFO] 2021-07-12 19:19:05,035 [run_pretraining.py:  558]:	worker_index: 6, step: 2327, cost: 7.305443, mlm loss: 7.305443, speed: 1.100337 steps/s, speed: 8.802696 samples/s, speed: 4506.980149 tokens/s, learning rate: 2.326e-05, loss_scalings: 2814.750488, pp_loss: 7.535553
[INFO] 2021-07-12 19:19:05,035 [run_pretraining.py:  512]:	********exe.run_2327******* 
[INFO] 2021-07-12 19:19:05,954 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:05,954 [run_pretraining.py:  534]:	loss/total_loss, 7.1556806564331055, 2328
[INFO] 2021-07-12 19:19:05,954 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1556806564331055, 2328
[INFO] 2021-07-12 19:19:05,955 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3270000383490697e-05, 2328
[INFO] 2021-07-12 19:19:05,955 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2328
[INFO] 2021-07-12 19:19:05,955 [run_pretraining.py:  558]:	worker_index: 6, step: 2328, cost: 7.155681, mlm loss: 7.155681, speed: 1.088180 steps/s, speed: 8.705438 samples/s, speed: 4457.184290 tokens/s, learning rate: 2.327e-05, loss_scalings: 2814.750488, pp_loss: 7.186422
[INFO] 2021-07-12 19:19:05,955 [run_pretraining.py:  512]:	********exe.run_2328******* 
[INFO] 2021-07-12 19:19:06,867 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:06,868 [run_pretraining.py:  534]:	loss/total_loss, 6.957819938659668, 2329
[INFO] 2021-07-12 19:19:06,868 [run_pretraining.py:  535]:	loss/mlm_loss, 6.957819938659668, 2329
[INFO] 2021-07-12 19:19:06,868 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3279999368241988e-05, 2329
[INFO] 2021-07-12 19:19:06,868 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2329
[INFO] 2021-07-12 19:19:06,868 [run_pretraining.py:  558]:	worker_index: 6, step: 2329, cost: 6.957820, mlm loss: 6.957820, speed: 1.095300 steps/s, speed: 8.762399 samples/s, speed: 4486.348180 tokens/s, learning rate: 2.328e-05, loss_scalings: 2814.750488, pp_loss: 7.268113
[INFO] 2021-07-12 19:19:06,868 [run_pretraining.py:  512]:	********exe.run_2329******* 
[INFO] 2021-07-12 19:19:07,782 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:07,782 [run_pretraining.py:  534]:	loss/total_loss, 6.4707489013671875, 2330
[INFO] 2021-07-12 19:19:07,783 [run_pretraining.py:  535]:	loss/mlm_loss, 6.4707489013671875, 2330
[INFO] 2021-07-12 19:19:07,783 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.328999835299328e-05, 2330
[INFO] 2021-07-12 19:19:07,783 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2330
[INFO] 2021-07-12 19:19:07,783 [run_pretraining.py:  558]:	worker_index: 6, step: 2330, cost: 6.470749, mlm loss: 6.470749, speed: 1.094420 steps/s, speed: 8.755361 samples/s, speed: 4482.745001 tokens/s, learning rate: 2.329e-05, loss_scalings: 2814.750488, pp_loss: 7.009748
[INFO] 2021-07-12 19:19:07,783 [run_pretraining.py:  512]:	********exe.run_2330******* 
[INFO] 2021-07-12 19:19:08,694 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:08,695 [run_pretraining.py:  534]:	loss/total_loss, 7.401241302490234, 2331
[INFO] 2021-07-12 19:19:08,695 [run_pretraining.py:  535]:	loss/mlm_loss, 7.401241302490234, 2331
[INFO] 2021-07-12 19:19:08,695 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3299999156733975e-05, 2331
[INFO] 2021-07-12 19:19:08,695 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2331
[INFO] 2021-07-12 19:19:08,695 [run_pretraining.py:  558]:	worker_index: 6, step: 2331, cost: 7.401241, mlm loss: 7.401241, speed: 1.096769 steps/s, speed: 8.774155 samples/s, speed: 4492.367541 tokens/s, learning rate: 2.330e-05, loss_scalings: 2814.750488, pp_loss: 7.406264
[INFO] 2021-07-12 19:19:08,695 [run_pretraining.py:  512]:	********exe.run_2331******* 
[INFO] 2021-07-12 19:19:09,615 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:09,616 [run_pretraining.py:  534]:	loss/total_loss, 7.567294597625732, 2332
[INFO] 2021-07-12 19:19:09,616 [run_pretraining.py:  535]:	loss/mlm_loss, 7.567294597625732, 2332
[INFO] 2021-07-12 19:19:09,616 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.330999996047467e-05, 2332
[INFO] 2021-07-12 19:19:09,616 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2332
[INFO] 2021-07-12 19:19:09,616 [run_pretraining.py:  558]:	worker_index: 6, step: 2332, cost: 7.567295, mlm loss: 7.567295, speed: 1.086570 steps/s, speed: 8.692556 samples/s, speed: 4450.588810 tokens/s, learning rate: 2.331e-05, loss_scalings: 2814.750488, pp_loss: 7.199337
[INFO] 2021-07-12 19:19:09,616 [run_pretraining.py:  512]:	********exe.run_2332******* 
[INFO] 2021-07-12 19:19:10,536 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:10,536 [run_pretraining.py:  534]:	loss/total_loss, 7.371711730957031, 2333
[INFO] 2021-07-12 19:19:10,536 [run_pretraining.py:  535]:	loss/mlm_loss, 7.371711730957031, 2333
[INFO] 2021-07-12 19:19:10,536 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.331999894522596e-05, 2333
[INFO] 2021-07-12 19:19:10,537 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2333
[INFO] 2021-07-12 19:19:10,537 [run_pretraining.py:  558]:	worker_index: 6, step: 2333, cost: 7.371712, mlm loss: 7.371712, speed: 1.087406 steps/s, speed: 8.699245 samples/s, speed: 4454.013435 tokens/s, learning rate: 2.332e-05, loss_scalings: 2814.750488, pp_loss: 7.546989
[INFO] 2021-07-12 19:19:10,537 [run_pretraining.py:  512]:	********exe.run_2333******* 
[INFO] 2021-07-12 19:19:36,250 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:36,251 [run_pretraining.py:  534]:	loss/total_loss, 7.864134788513184, 2334
[INFO] 2021-07-12 19:19:36,251 [run_pretraining.py:  535]:	loss/mlm_loss, 7.864134788513184, 2334
[INFO] 2021-07-12 19:19:36,251 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3329999748966657e-05, 2334
[INFO] 2021-07-12 19:19:36,251 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2334
[INFO] 2021-07-12 19:19:36,251 [run_pretraining.py:  558]:	worker_index: 6, step: 2334, cost: 7.864135, mlm loss: 7.864135, speed: 0.038890 steps/s, speed: 0.311116 samples/s, speed: 159.291538 tokens/s, learning rate: 2.333e-05, loss_scalings: 2814.750488, pp_loss: 7.238621
[INFO] 2021-07-12 19:19:36,251 [run_pretraining.py:  512]:	********exe.run_2334******* 
[INFO] 2021-07-12 19:19:37,168 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:37,169 [run_pretraining.py:  534]:	loss/total_loss, 7.359230041503906, 2335
[INFO] 2021-07-12 19:19:37,169 [run_pretraining.py:  535]:	loss/mlm_loss, 7.359230041503906, 2335
[INFO] 2021-07-12 19:19:37,169 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3339998733717948e-05, 2335
[INFO] 2021-07-12 19:19:37,169 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2335
[INFO] 2021-07-12 19:19:37,170 [run_pretraining.py:  558]:	worker_index: 6, step: 2335, cost: 7.359230, mlm loss: 7.359230, speed: 1.089937 steps/s, speed: 8.719498 samples/s, speed: 4464.382811 tokens/s, learning rate: 2.334e-05, loss_scalings: 2814.750488, pp_loss: 7.044237
[INFO] 2021-07-12 19:19:37,170 [run_pretraining.py:  512]:	********exe.run_2335******* 
[INFO] 2021-07-12 19:19:38,083 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:38,083 [run_pretraining.py:  534]:	loss/total_loss, 6.979543685913086, 2336
[INFO] 2021-07-12 19:19:38,083 [run_pretraining.py:  535]:	loss/mlm_loss, 6.979543685913086, 2336
[INFO] 2021-07-12 19:19:38,083 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3349999537458643e-05, 2336
[INFO] 2021-07-12 19:19:38,084 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2336
[INFO] 2021-07-12 19:19:38,084 [run_pretraining.py:  558]:	worker_index: 6, step: 2336, cost: 6.979544, mlm loss: 6.979544, speed: 1.094798 steps/s, speed: 8.758380 samples/s, speed: 4484.290686 tokens/s, learning rate: 2.335e-05, loss_scalings: 2814.750488, pp_loss: 6.806052
[INFO] 2021-07-12 19:19:38,084 [run_pretraining.py:  512]:	********exe.run_2336******* 
[INFO] 2021-07-12 19:19:38,998 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:38,998 [run_pretraining.py:  534]:	loss/total_loss, 7.443246841430664, 2337
[INFO] 2021-07-12 19:19:38,998 [run_pretraining.py:  535]:	loss/mlm_loss, 7.443246841430664, 2337
[INFO] 2021-07-12 19:19:38,998 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.336000034119934e-05, 2337
[INFO] 2021-07-12 19:19:38,999 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2337
[INFO] 2021-07-12 19:19:38,999 [run_pretraining.py:  558]:	worker_index: 6, step: 2337, cost: 7.443247, mlm loss: 7.443247, speed: 1.093762 steps/s, speed: 8.750096 samples/s, speed: 4480.049334 tokens/s, learning rate: 2.336e-05, loss_scalings: 2814.750488, pp_loss: 7.172738
[INFO] 2021-07-12 19:19:38,999 [run_pretraining.py:  512]:	********exe.run_2337******* 
[INFO] 2021-07-12 19:19:39,904 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:39,905 [run_pretraining.py:  534]:	loss/total_loss, 7.513580322265625, 2338
[INFO] 2021-07-12 19:19:39,905 [run_pretraining.py:  535]:	loss/mlm_loss, 7.513580322265625, 2338
[INFO] 2021-07-12 19:19:39,905 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.336999932595063e-05, 2338
[INFO] 2021-07-12 19:19:39,905 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2338
[INFO] 2021-07-12 19:19:39,905 [run_pretraining.py:  558]:	worker_index: 6, step: 2338, cost: 7.513580, mlm loss: 7.513580, speed: 1.103981 steps/s, speed: 8.831850 samples/s, speed: 4521.907118 tokens/s, learning rate: 2.337e-05, loss_scalings: 2814.750488, pp_loss: 7.221793
[INFO] 2021-07-12 19:19:39,905 [run_pretraining.py:  512]:	********exe.run_2338******* 
[INFO] 2021-07-12 19:19:40,826 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:40,826 [run_pretraining.py:  534]:	loss/total_loss, 7.394834995269775, 2339
[INFO] 2021-07-12 19:19:40,827 [run_pretraining.py:  535]:	loss/mlm_loss, 7.394834995269775, 2339
[INFO] 2021-07-12 19:19:40,827 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.337999831070192e-05, 2339
[INFO] 2021-07-12 19:19:40,827 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2339
[INFO] 2021-07-12 19:19:40,827 [run_pretraining.py:  558]:	worker_index: 6, step: 2339, cost: 7.394835, mlm loss: 7.394835, speed: 1.085815 steps/s, speed: 8.686519 samples/s, speed: 4447.497560 tokens/s, learning rate: 2.338e-05, loss_scalings: 2814.750488, pp_loss: 7.505824
[INFO] 2021-07-12 19:19:40,827 [run_pretraining.py:  512]:	********exe.run_2339******* 
[INFO] 2021-07-12 19:19:41,742 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:41,743 [run_pretraining.py:  534]:	loss/total_loss, 7.561853408813477, 2340
[INFO] 2021-07-12 19:19:41,743 [run_pretraining.py:  535]:	loss/mlm_loss, 7.561853408813477, 2340
[INFO] 2021-07-12 19:19:41,743 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3389999114442617e-05, 2340
[INFO] 2021-07-12 19:19:41,743 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2340
[INFO] 2021-07-12 19:19:41,743 [run_pretraining.py:  558]:	worker_index: 6, step: 2340, cost: 7.561853, mlm loss: 7.561853, speed: 1.092439 steps/s, speed: 8.739515 samples/s, speed: 4474.631585 tokens/s, learning rate: 2.339e-05, loss_scalings: 2814.750488, pp_loss: 7.218528
[INFO] 2021-07-12 19:19:41,743 [run_pretraining.py:  512]:	********exe.run_2340******* 
[INFO] 2021-07-12 19:19:42,655 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:42,656 [run_pretraining.py:  534]:	loss/total_loss, 6.886582851409912, 2341
[INFO] 2021-07-12 19:19:42,656 [run_pretraining.py:  535]:	loss/mlm_loss, 6.886582851409912, 2341
[INFO] 2021-07-12 19:19:42,656 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3399999918183312e-05, 2341
[INFO] 2021-07-12 19:19:42,656 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2341
[INFO] 2021-07-12 19:19:42,656 [run_pretraining.py:  558]:	worker_index: 6, step: 2341, cost: 6.886583, mlm loss: 6.886583, speed: 1.095488 steps/s, speed: 8.763905 samples/s, speed: 4487.119202 tokens/s, learning rate: 2.340e-05, loss_scalings: 2814.750488, pp_loss: 7.129086
[INFO] 2021-07-12 19:19:42,656 [run_pretraining.py:  512]:	********exe.run_2341******* 
[INFO] 2021-07-12 19:19:43,571 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:43,571 [run_pretraining.py:  534]:	loss/total_loss, 7.184578895568848, 2342
[INFO] 2021-07-12 19:19:43,572 [run_pretraining.py:  535]:	loss/mlm_loss, 7.184578895568848, 2342
[INFO] 2021-07-12 19:19:43,572 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3409998902934603e-05, 2342
[INFO] 2021-07-12 19:19:43,572 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2342
[INFO] 2021-07-12 19:19:43,572 [run_pretraining.py:  558]:	worker_index: 6, step: 2342, cost: 7.184579, mlm loss: 7.184579, speed: 1.093225 steps/s, speed: 8.745797 samples/s, speed: 4477.848214 tokens/s, learning rate: 2.341e-05, loss_scalings: 2814.750488, pp_loss: 6.734052
[INFO] 2021-07-12 19:19:43,572 [run_pretraining.py:  512]:	********exe.run_2342******* 
[INFO] 2021-07-12 19:19:44,494 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:44,494 [run_pretraining.py:  534]:	loss/total_loss, 6.863672256469727, 2343
[INFO] 2021-07-12 19:19:44,494 [run_pretraining.py:  535]:	loss/mlm_loss, 6.863672256469727, 2343
[INFO] 2021-07-12 19:19:44,494 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.34199997066753e-05, 2343
[INFO] 2021-07-12 19:19:44,494 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2343
[INFO] 2021-07-12 19:19:44,495 [run_pretraining.py:  558]:	worker_index: 6, step: 2343, cost: 6.863672, mlm loss: 6.863672, speed: 1.084622 steps/s, speed: 8.676976 samples/s, speed: 4442.611951 tokens/s, learning rate: 2.342e-05, loss_scalings: 2814.750488, pp_loss: 6.995460
[INFO] 2021-07-12 19:19:44,495 [run_pretraining.py:  512]:	********exe.run_2343******* 
[INFO] 2021-07-12 19:19:45,410 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:45,410 [run_pretraining.py:  534]:	loss/total_loss, 7.456305503845215, 2344
[INFO] 2021-07-12 19:19:45,410 [run_pretraining.py:  535]:	loss/mlm_loss, 7.456305503845215, 2344
[INFO] 2021-07-12 19:19:45,411 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3430000510415994e-05, 2344
[INFO] 2021-07-12 19:19:45,411 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2344
[INFO] 2021-07-12 19:19:45,411 [run_pretraining.py:  558]:	worker_index: 6, step: 2344, cost: 7.456306, mlm loss: 7.456306, speed: 1.092324 steps/s, speed: 8.738588 samples/s, speed: 4474.157296 tokens/s, learning rate: 2.343e-05, loss_scalings: 2814.750488, pp_loss: 6.765079
[INFO] 2021-07-12 19:19:45,411 [run_pretraining.py:  512]:	********exe.run_2344******* 
[INFO] 2021-07-12 19:19:46,330 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:46,331 [run_pretraining.py:  534]:	loss/total_loss, 7.119056701660156, 2345
[INFO] 2021-07-12 19:19:46,331 [run_pretraining.py:  535]:	loss/mlm_loss, 7.119056701660156, 2345
[INFO] 2021-07-12 19:19:46,331 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3439999495167285e-05, 2345
[INFO] 2021-07-12 19:19:46,331 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2345
[INFO] 2021-07-12 19:19:46,331 [run_pretraining.py:  558]:	worker_index: 6, step: 2345, cost: 7.119057, mlm loss: 7.119057, speed: 1.087442 steps/s, speed: 8.699538 samples/s, speed: 4454.163556 tokens/s, learning rate: 2.344e-05, loss_scalings: 2814.750488, pp_loss: 7.409537
[INFO] 2021-07-12 19:19:46,331 [run_pretraining.py:  512]:	********exe.run_2345******* 
[INFO] 2021-07-12 19:19:47,264 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:47,265 [run_pretraining.py:  534]:	loss/total_loss, 7.778460502624512, 2346
[INFO] 2021-07-12 19:19:47,265 [run_pretraining.py:  535]:	loss/mlm_loss, 7.778460502624512, 2346
[INFO] 2021-07-12 19:19:47,265 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.345000029890798e-05, 2346
[INFO] 2021-07-12 19:19:47,265 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2346
[INFO] 2021-07-12 19:19:47,265 [run_pretraining.py:  558]:	worker_index: 6, step: 2346, cost: 7.778461, mlm loss: 7.778461, speed: 1.071543 steps/s, speed: 8.572346 samples/s, speed: 4389.040901 tokens/s, learning rate: 2.345e-05, loss_scalings: 2814.750488, pp_loss: 7.455590
[INFO] 2021-07-12 19:19:47,265 [run_pretraining.py:  512]:	********exe.run_2346******* 
[INFO] 2021-07-12 19:19:48,182 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:48,183 [run_pretraining.py:  534]:	loss/total_loss, 7.442050933837891, 2347
[INFO] 2021-07-12 19:19:48,183 [run_pretraining.py:  535]:	loss/mlm_loss, 7.442050933837891, 2347
[INFO] 2021-07-12 19:19:48,183 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3459999283659272e-05, 2347
[INFO] 2021-07-12 19:19:48,183 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2347
[INFO] 2021-07-12 19:19:48,183 [run_pretraining.py:  558]:	worker_index: 6, step: 2347, cost: 7.442051, mlm loss: 7.442051, speed: 1.090036 steps/s, speed: 8.720289 samples/s, speed: 4464.787730 tokens/s, learning rate: 2.346e-05, loss_scalings: 2814.750488, pp_loss: 7.183853
[INFO] 2021-07-12 19:19:48,183 [run_pretraining.py:  512]:	********exe.run_2347******* 
[INFO] 2021-07-12 19:19:49,102 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:49,103 [run_pretraining.py:  534]:	loss/total_loss, 6.981369495391846, 2348
[INFO] 2021-07-12 19:19:49,103 [run_pretraining.py:  535]:	loss/mlm_loss, 6.981369495391846, 2348
[INFO] 2021-07-12 19:19:49,103 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3469998268410563e-05, 2348
[INFO] 2021-07-12 19:19:49,103 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2348
[INFO] 2021-07-12 19:19:49,103 [run_pretraining.py:  558]:	worker_index: 6, step: 2348, cost: 6.981369, mlm loss: 6.981369, speed: 1.087470 steps/s, speed: 8.699759 samples/s, speed: 4454.276730 tokens/s, learning rate: 2.347e-05, loss_scalings: 2814.750488, pp_loss: 7.338499
[INFO] 2021-07-12 19:19:49,103 [run_pretraining.py:  512]:	********exe.run_2348******* 
[INFO] 2021-07-12 19:19:50,011 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:50,012 [run_pretraining.py:  534]:	loss/total_loss, 7.588892936706543, 2349
[INFO] 2021-07-12 19:19:50,012 [run_pretraining.py:  535]:	loss/mlm_loss, 7.588892936706543, 2349
[INFO] 2021-07-12 19:19:50,012 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.347999907215126e-05, 2349
[INFO] 2021-07-12 19:19:50,012 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2349
[INFO] 2021-07-12 19:19:50,012 [run_pretraining.py:  558]:	worker_index: 6, step: 2349, cost: 7.588893, mlm loss: 7.588893, speed: 1.101305 steps/s, speed: 8.810439 samples/s, speed: 4510.944555 tokens/s, learning rate: 2.348e-05, loss_scalings: 2814.750488, pp_loss: 6.845597
[INFO] 2021-07-12 19:19:50,012 [run_pretraining.py:  512]:	********exe.run_2349******* 
[INFO] 2021-07-12 19:19:50,931 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:50,931 [run_pretraining.py:  534]:	loss/total_loss, 3.082118034362793, 2350
[INFO] 2021-07-12 19:19:50,931 [run_pretraining.py:  535]:	loss/mlm_loss, 3.082118034362793, 2350
[INFO] 2021-07-12 19:19:50,931 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3489999875891954e-05, 2350
[INFO] 2021-07-12 19:19:50,932 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2350
[INFO] 2021-07-12 19:19:50,932 [run_pretraining.py:  558]:	worker_index: 6, step: 2350, cost: 3.082118, mlm loss: 3.082118, speed: 1.088370 steps/s, speed: 8.706961 samples/s, speed: 4457.963827 tokens/s, learning rate: 2.349e-05, loss_scalings: 2814.750488, pp_loss: 5.892308
[INFO] 2021-07-12 19:19:50,932 [run_pretraining.py:  512]:	********exe.run_2350******* 
[INFO] 2021-07-12 19:19:51,839 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:51,839 [run_pretraining.py:  534]:	loss/total_loss, 7.319807052612305, 2351
[INFO] 2021-07-12 19:19:51,839 [run_pretraining.py:  535]:	loss/mlm_loss, 7.319807052612305, 2351
[INFO] 2021-07-12 19:19:51,839 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3499998860643245e-05, 2351
[INFO] 2021-07-12 19:19:51,839 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2351
[INFO] 2021-07-12 19:19:51,840 [run_pretraining.py:  558]:	worker_index: 6, step: 2351, cost: 7.319807, mlm loss: 7.319807, speed: 1.102270 steps/s, speed: 8.818160 samples/s, speed: 4514.898143 tokens/s, learning rate: 2.350e-05, loss_scalings: 2814.750488, pp_loss: 6.911849
[INFO] 2021-07-12 19:19:51,840 [run_pretraining.py:  512]:	********exe.run_2351******* 
[INFO] 2021-07-12 19:19:52,756 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:52,756 [run_pretraining.py:  534]:	loss/total_loss, 7.64880895614624, 2352
[INFO] 2021-07-12 19:19:52,756 [run_pretraining.py:  535]:	loss/mlm_loss, 7.64880895614624, 2352
[INFO] 2021-07-12 19:19:52,756 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.350999966438394e-05, 2352
[INFO] 2021-07-12 19:19:52,756 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2352
[INFO] 2021-07-12 19:19:52,757 [run_pretraining.py:  558]:	worker_index: 6, step: 2352, cost: 7.648809, mlm loss: 7.648809, speed: 1.091378 steps/s, speed: 8.731021 samples/s, speed: 4470.282849 tokens/s, learning rate: 2.351e-05, loss_scalings: 2814.750488, pp_loss: 7.552003
[INFO] 2021-07-12 19:19:52,757 [run_pretraining.py:  512]:	********exe.run_2352******* 
[INFO] 2021-07-12 19:19:53,664 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:53,664 [run_pretraining.py:  534]:	loss/total_loss, 7.282413482666016, 2353
[INFO] 2021-07-12 19:19:53,664 [run_pretraining.py:  535]:	loss/mlm_loss, 7.282413482666016, 2353
[INFO] 2021-07-12 19:19:53,664 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3520000468124636e-05, 2353
[INFO] 2021-07-12 19:19:53,664 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2353
[INFO] 2021-07-12 19:19:53,665 [run_pretraining.py:  558]:	worker_index: 6, step: 2353, cost: 7.282413, mlm loss: 7.282413, speed: 1.102169 steps/s, speed: 8.817354 samples/s, speed: 4514.485271 tokens/s, learning rate: 2.352e-05, loss_scalings: 2814.750488, pp_loss: 7.308637
[INFO] 2021-07-12 19:19:53,665 [run_pretraining.py:  512]:	********exe.run_2353******* 
[INFO] 2021-07-12 19:19:54,582 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:54,583 [run_pretraining.py:  534]:	loss/total_loss, 7.45603084564209, 2354
[INFO] 2021-07-12 19:19:54,583 [run_pretraining.py:  535]:	loss/mlm_loss, 7.45603084564209, 2354
[INFO] 2021-07-12 19:19:54,583 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3529999452875927e-05, 2354
[INFO] 2021-07-12 19:19:54,583 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2354
[INFO] 2021-07-12 19:19:54,583 [run_pretraining.py:  558]:	worker_index: 6, step: 2354, cost: 7.456031, mlm loss: 7.456031, speed: 1.089060 steps/s, speed: 8.712479 samples/s, speed: 4460.789333 tokens/s, learning rate: 2.353e-05, loss_scalings: 2814.750488, pp_loss: 6.770414
[INFO] 2021-07-12 19:19:54,584 [run_pretraining.py:  512]:	********exe.run_2354******* 
[INFO] 2021-07-12 19:19:55,492 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:55,493 [run_pretraining.py:  534]:	loss/total_loss, 7.15633487701416, 2355
[INFO] 2021-07-12 19:19:55,493 [run_pretraining.py:  535]:	loss/mlm_loss, 7.15633487701416, 2355
[INFO] 2021-07-12 19:19:55,493 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3540000256616622e-05, 2355
[INFO] 2021-07-12 19:19:55,493 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2355
[INFO] 2021-07-12 19:19:55,493 [run_pretraining.py:  558]:	worker_index: 6, step: 2355, cost: 7.156335, mlm loss: 7.156335, speed: 1.100353 steps/s, speed: 8.802820 samples/s, speed: 4507.043998 tokens/s, learning rate: 2.354e-05, loss_scalings: 2814.750488, pp_loss: 7.453071
[INFO] 2021-07-12 19:19:55,493 [run_pretraining.py:  512]:	********exe.run_2355******* 
[INFO] 2021-07-12 19:19:56,413 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:56,413 [run_pretraining.py:  534]:	loss/total_loss, 6.703250885009766, 2356
[INFO] 2021-07-12 19:19:56,413 [run_pretraining.py:  535]:	loss/mlm_loss, 6.703250885009766, 2356
[INFO] 2021-07-12 19:19:56,414 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3549999241367914e-05, 2356
[INFO] 2021-07-12 19:19:56,414 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2356
[INFO] 2021-07-12 19:19:56,414 [run_pretraining.py:  558]:	worker_index: 6, step: 2356, cost: 6.703251, mlm loss: 6.703251, speed: 1.086898 steps/s, speed: 8.695187 samples/s, speed: 4451.935877 tokens/s, learning rate: 2.355e-05, loss_scalings: 2814.750488, pp_loss: 7.052471
[INFO] 2021-07-12 19:19:56,414 [run_pretraining.py:  512]:	********exe.run_2356******* 
[INFO] 2021-07-12 19:19:57,333 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:57,334 [run_pretraining.py:  534]:	loss/total_loss, 7.16334867477417, 2357
[INFO] 2021-07-12 19:19:57,334 [run_pretraining.py:  535]:	loss/mlm_loss, 7.16334867477417, 2357
[INFO] 2021-07-12 19:19:57,334 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3559998226119205e-05, 2357
[INFO] 2021-07-12 19:19:57,334 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2357
[INFO] 2021-07-12 19:19:57,334 [run_pretraining.py:  558]:	worker_index: 6, step: 2357, cost: 7.163349, mlm loss: 7.163349, speed: 1.087301 steps/s, speed: 8.698406 samples/s, speed: 4453.583914 tokens/s, learning rate: 2.356e-05, loss_scalings: 2814.750488, pp_loss: 7.365416
[INFO] 2021-07-12 19:19:57,334 [run_pretraining.py:  512]:	********exe.run_2357******* 
[INFO] 2021-07-12 19:19:58,245 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:58,245 [run_pretraining.py:  534]:	loss/total_loss, 7.587841033935547, 2358
[INFO] 2021-07-12 19:19:58,245 [run_pretraining.py:  535]:	loss/mlm_loss, 7.587841033935547, 2358
[INFO] 2021-07-12 19:19:58,245 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.35699990298599e-05, 2358
[INFO] 2021-07-12 19:19:58,246 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2358
[INFO] 2021-07-12 19:19:58,246 [run_pretraining.py:  558]:	worker_index: 6, step: 2358, cost: 7.587841, mlm loss: 7.587841, speed: 1.097932 steps/s, speed: 8.783455 samples/s, speed: 4497.128984 tokens/s, learning rate: 2.357e-05, loss_scalings: 2814.750488, pp_loss: 7.377776
[INFO] 2021-07-12 19:19:58,246 [run_pretraining.py:  512]:	********exe.run_2358******* 
[INFO] 2021-07-12 19:19:59,212 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:59,212 [run_pretraining.py:  534]:	loss/total_loss, 7.387193202972412, 2359
[INFO] 2021-07-12 19:19:59,212 [run_pretraining.py:  535]:	loss/mlm_loss, 7.387193202972412, 2359
[INFO] 2021-07-12 19:19:59,212 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3579999833600596e-05, 2359
[INFO] 2021-07-12 19:19:59,212 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2359
[INFO] 2021-07-12 19:19:59,213 [run_pretraining.py:  558]:	worker_index: 6, step: 2359, cost: 7.387193, mlm loss: 7.387193, speed: 1.035007 steps/s, speed: 8.280059 samples/s, speed: 4239.389954 tokens/s, learning rate: 2.358e-05, loss_scalings: 2814.750488, pp_loss: 7.096980
[INFO] 2021-07-12 19:19:59,213 [run_pretraining.py:  512]:	********exe.run_2359******* 
[INFO] 2021-07-12 19:20:00,220 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:00,221 [run_pretraining.py:  534]:	loss/total_loss, 6.691676616668701, 2360
[INFO] 2021-07-12 19:20:00,221 [run_pretraining.py:  535]:	loss/mlm_loss, 6.691676616668701, 2360
[INFO] 2021-07-12 19:20:00,221 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3589998818351887e-05, 2360
[INFO] 2021-07-12 19:20:00,221 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2360
[INFO] 2021-07-12 19:20:00,221 [run_pretraining.py:  558]:	worker_index: 6, step: 2360, cost: 6.691677, mlm loss: 6.691677, speed: 0.991951 steps/s, speed: 7.935606 samples/s, speed: 4063.030231 tokens/s, learning rate: 2.359e-05, loss_scalings: 2814.750488, pp_loss: 7.324857
[INFO] 2021-07-12 19:20:00,221 [run_pretraining.py:  512]:	********exe.run_2360******* 
[INFO] 2021-07-12 19:20:01,193 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:01,194 [run_pretraining.py:  534]:	loss/total_loss, 7.74312686920166, 2361
[INFO] 2021-07-12 19:20:01,194 [run_pretraining.py:  535]:	loss/mlm_loss, 7.74312686920166, 2361
[INFO] 2021-07-12 19:20:01,194 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3599999622092582e-05, 2361
[INFO] 2021-07-12 19:20:01,194 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2361
[INFO] 2021-07-12 19:20:01,194 [run_pretraining.py:  558]:	worker_index: 6, step: 2361, cost: 7.743127, mlm loss: 7.743127, speed: 1.028511 steps/s, speed: 8.228086 samples/s, speed: 4212.780168 tokens/s, learning rate: 2.360e-05, loss_scalings: 2814.750488, pp_loss: 7.262489
[INFO] 2021-07-12 19:20:01,194 [run_pretraining.py:  512]:	********exe.run_2361******* 
[INFO] 2021-07-12 19:20:02,166 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:02,167 [run_pretraining.py:  534]:	loss/total_loss, 6.4927191734313965, 2362
[INFO] 2021-07-12 19:20:02,167 [run_pretraining.py:  535]:	loss/mlm_loss, 6.4927191734313965, 2362
[INFO] 2021-07-12 19:20:02,167 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3610000425833277e-05, 2362
[INFO] 2021-07-12 19:20:02,167 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2362
[INFO] 2021-07-12 19:20:02,167 [run_pretraining.py:  558]:	worker_index: 6, step: 2362, cost: 6.492719, mlm loss: 6.492719, speed: 1.028503 steps/s, speed: 8.228024 samples/s, speed: 4212.748144 tokens/s, learning rate: 2.361e-05, loss_scalings: 2814.750488, pp_loss: 7.379247
[INFO] 2021-07-12 19:20:02,167 [run_pretraining.py:  512]:	********exe.run_2362******* 
[INFO] 2021-07-12 19:20:03,149 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:03,150 [run_pretraining.py:  534]:	loss/total_loss, 7.809345245361328, 2363
[INFO] 2021-07-12 19:20:03,150 [run_pretraining.py:  535]:	loss/mlm_loss, 7.809345245361328, 2363
[INFO] 2021-07-12 19:20:03,150 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.361999941058457e-05, 2363
[INFO] 2021-07-12 19:20:03,150 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2363
[INFO] 2021-07-12 19:20:03,150 [run_pretraining.py:  558]:	worker_index: 6, step: 2363, cost: 7.809345, mlm loss: 7.809345, speed: 1.017912 steps/s, speed: 8.143297 samples/s, speed: 4169.368206 tokens/s, learning rate: 2.362e-05, loss_scalings: 2814.750488, pp_loss: 7.872115
[INFO] 2021-07-12 19:20:03,151 [run_pretraining.py:  512]:	********exe.run_2363******* 
[INFO] 2021-07-12 19:20:04,130 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:04,130 [run_pretraining.py:  534]:	loss/total_loss, 7.984180450439453, 2364
[INFO] 2021-07-12 19:20:04,130 [run_pretraining.py:  535]:	loss/mlm_loss, 7.984180450439453, 2364
[INFO] 2021-07-12 19:20:04,131 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3630000214325264e-05, 2364
[INFO] 2021-07-12 19:20:04,131 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2364
[INFO] 2021-07-12 19:20:04,131 [run_pretraining.py:  558]:	worker_index: 6, step: 2364, cost: 7.984180, mlm loss: 7.984180, speed: 1.020821 steps/s, speed: 8.166571 samples/s, speed: 4181.284444 tokens/s, learning rate: 2.363e-05, loss_scalings: 2814.750488, pp_loss: 7.749231
[INFO] 2021-07-12 19:20:04,131 [run_pretraining.py:  512]:	********exe.run_2364******* 
[INFO] 2021-07-12 19:20:05,100 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:05,101 [run_pretraining.py:  534]:	loss/total_loss, 7.191760063171387, 2365
[INFO] 2021-07-12 19:20:05,101 [run_pretraining.py:  535]:	loss/mlm_loss, 7.191760063171387, 2365
[INFO] 2021-07-12 19:20:05,101 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3639999199076556e-05, 2365
[INFO] 2021-07-12 19:20:05,101 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2365
[INFO] 2021-07-12 19:20:05,101 [run_pretraining.py:  558]:	worker_index: 6, step: 2365, cost: 7.191760, mlm loss: 7.191760, speed: 1.031085 steps/s, speed: 8.248679 samples/s, speed: 4223.323885 tokens/s, learning rate: 2.364e-05, loss_scalings: 2814.750488, pp_loss: 7.382196
[INFO] 2021-07-12 19:20:05,101 [run_pretraining.py:  512]:	********exe.run_2365******* 
[INFO] 2021-07-12 19:20:06,068 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:06,068 [run_pretraining.py:  534]:	loss/total_loss, 7.183084964752197, 2366
[INFO] 2021-07-12 19:20:06,069 [run_pretraining.py:  535]:	loss/mlm_loss, 7.183084964752197, 2366
[INFO] 2021-07-12 19:20:06,069 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3649998183827847e-05, 2366
[INFO] 2021-07-12 19:20:06,069 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2366
[INFO] 2021-07-12 19:20:06,069 [run_pretraining.py:  558]:	worker_index: 6, step: 2366, cost: 7.183085, mlm loss: 7.183085, speed: 1.034286 steps/s, speed: 8.274290 samples/s, speed: 4236.436687 tokens/s, learning rate: 2.365e-05, loss_scalings: 2814.750488, pp_loss: 7.325165
[INFO] 2021-07-12 19:20:06,069 [run_pretraining.py:  512]:	********exe.run_2366******* 
[INFO] 2021-07-12 19:20:07,054 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:07,055 [run_pretraining.py:  534]:	loss/total_loss, 7.77312707901001, 2367
[INFO] 2021-07-12 19:20:07,055 [run_pretraining.py:  535]:	loss/mlm_loss, 7.77312707901001, 2367
[INFO] 2021-07-12 19:20:07,055 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3659998987568542e-05, 2367
[INFO] 2021-07-12 19:20:07,055 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2367
[INFO] 2021-07-12 19:20:07,055 [run_pretraining.py:  558]:	worker_index: 6, step: 2367, cost: 7.773127, mlm loss: 7.773127, speed: 1.014549 steps/s, speed: 8.116392 samples/s, speed: 4155.592867 tokens/s, learning rate: 2.366e-05, loss_scalings: 2814.750488, pp_loss: 7.423015
[INFO] 2021-07-12 19:20:07,055 [run_pretraining.py:  512]:	********exe.run_2367******* 
[INFO] 2021-07-12 19:20:08,026 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:08,026 [run_pretraining.py:  534]:	loss/total_loss, 7.606762886047363, 2368
[INFO] 2021-07-12 19:20:08,026 [run_pretraining.py:  535]:	loss/mlm_loss, 7.606762886047363, 2368
[INFO] 2021-07-12 19:20:08,026 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3669999791309237e-05, 2368
[INFO] 2021-07-12 19:20:08,027 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2368
[INFO] 2021-07-12 19:20:08,027 [run_pretraining.py:  558]:	worker_index: 6, step: 2368, cost: 7.606763, mlm loss: 7.606763, speed: 1.030100 steps/s, speed: 8.240799 samples/s, speed: 4219.289072 tokens/s, learning rate: 2.367e-05, loss_scalings: 2814.750488, pp_loss: 7.586261
[INFO] 2021-07-12 19:20:08,027 [run_pretraining.py:  512]:	********exe.run_2368******* 
[INFO] 2021-07-12 19:20:09,007 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:09,008 [run_pretraining.py:  534]:	loss/total_loss, 6.89046573638916, 2369
[INFO] 2021-07-12 19:20:09,008 [run_pretraining.py:  535]:	loss/mlm_loss, 6.89046573638916, 2369
[INFO] 2021-07-12 19:20:09,008 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.367999877606053e-05, 2369
[INFO] 2021-07-12 19:20:09,008 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2369
[INFO] 2021-07-12 19:20:09,008 [run_pretraining.py:  558]:	worker_index: 6, step: 2369, cost: 6.890466, mlm loss: 6.890466, speed: 1.019484 steps/s, speed: 8.155870 samples/s, speed: 4175.805467 tokens/s, learning rate: 2.368e-05, loss_scalings: 2814.750488, pp_loss: 7.333909
[INFO] 2021-07-12 19:20:09,008 [run_pretraining.py:  512]:	********exe.run_2369******* 
[INFO] 2021-07-12 19:20:09,986 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:09,986 [run_pretraining.py:  534]:	loss/total_loss, 7.321854114532471, 2370
[INFO] 2021-07-12 19:20:09,986 [run_pretraining.py:  535]:	loss/mlm_loss, 7.321854114532471, 2370
[INFO] 2021-07-12 19:20:09,987 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3689999579801224e-05, 2370
[INFO] 2021-07-12 19:20:09,987 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2370
[INFO] 2021-07-12 19:20:09,987 [run_pretraining.py:  558]:	worker_index: 6, step: 2370, cost: 7.321854, mlm loss: 7.321854, speed: 1.022777 steps/s, speed: 8.182220 samples/s, speed: 4189.296482 tokens/s, learning rate: 2.369e-05, loss_scalings: 2814.750488, pp_loss: 7.381780
[INFO] 2021-07-12 19:20:09,987 [run_pretraining.py:  512]:	********exe.run_2370******* 
[INFO] 2021-07-12 19:20:10,996 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:10,996 [run_pretraining.py:  534]:	loss/total_loss, 8.037115097045898, 2371
[INFO] 2021-07-12 19:20:10,996 [run_pretraining.py:  535]:	loss/mlm_loss, 8.037115097045898, 2371
[INFO] 2021-07-12 19:20:10,997 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.370000038354192e-05, 2371
[INFO] 2021-07-12 19:20:10,997 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2371
[INFO] 2021-07-12 19:20:10,997 [run_pretraining.py:  558]:	worker_index: 6, step: 2371, cost: 8.037115, mlm loss: 8.037115, speed: 0.990756 steps/s, speed: 7.926048 samples/s, speed: 4058.136480 tokens/s, learning rate: 2.370e-05, loss_scalings: 2814.750488, pp_loss: 7.308258
[INFO] 2021-07-12 19:20:10,997 [run_pretraining.py:  512]:	********exe.run_2371******* 
[INFO] 2021-07-12 19:20:11,970 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:11,971 [run_pretraining.py:  534]:	loss/total_loss, 7.25531005859375, 2372
[INFO] 2021-07-12 19:20:11,971 [run_pretraining.py:  535]:	loss/mlm_loss, 7.25531005859375, 2372
[INFO] 2021-07-12 19:20:11,971 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.370999936829321e-05, 2372
[INFO] 2021-07-12 19:20:11,971 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2372
[INFO] 2021-07-12 19:20:11,971 [run_pretraining.py:  558]:	worker_index: 6, step: 2372, cost: 7.255310, mlm loss: 7.255310, speed: 1.027152 steps/s, speed: 8.217215 samples/s, speed: 4207.214273 tokens/s, learning rate: 2.371e-05, loss_scalings: 2814.750488, pp_loss: 7.234633
[INFO] 2021-07-12 19:20:11,971 [run_pretraining.py:  512]:	********exe.run_2372******* 
[INFO] 2021-07-12 19:20:12,945 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:12,945 [run_pretraining.py:  534]:	loss/total_loss, 7.176405906677246, 2373
[INFO] 2021-07-12 19:20:12,946 [run_pretraining.py:  535]:	loss/mlm_loss, 7.176405906677246, 2373
[INFO] 2021-07-12 19:20:12,946 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3720000172033906e-05, 2373
[INFO] 2021-07-12 19:20:12,946 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2373
[INFO] 2021-07-12 19:20:12,946 [run_pretraining.py:  558]:	worker_index: 6, step: 2373, cost: 7.176406, mlm loss: 7.176406, speed: 1.026513 steps/s, speed: 8.212103 samples/s, speed: 4204.596845 tokens/s, learning rate: 2.372e-05, loss_scalings: 2814.750488, pp_loss: 7.023371
[INFO] 2021-07-12 19:20:12,946 [run_pretraining.py:  512]:	********exe.run_2373******* 
[INFO] 2021-07-12 19:20:13,915 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:13,916 [run_pretraining.py:  534]:	loss/total_loss, 7.473426342010498, 2374
[INFO] 2021-07-12 19:20:13,916 [run_pretraining.py:  535]:	loss/mlm_loss, 7.473426342010498, 2374
[INFO] 2021-07-12 19:20:13,916 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3729999156785198e-05, 2374
[INFO] 2021-07-12 19:20:13,916 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2374
[INFO] 2021-07-12 19:20:13,916 [run_pretraining.py:  558]:	worker_index: 6, step: 2374, cost: 7.473426, mlm loss: 7.473426, speed: 1.031429 steps/s, speed: 8.251432 samples/s, speed: 4224.733219 tokens/s, learning rate: 2.373e-05, loss_scalings: 2814.750488, pp_loss: 7.116215
[INFO] 2021-07-12 19:20:13,916 [run_pretraining.py:  512]:	********exe.run_2374******* 
[INFO] 2021-07-12 19:20:14,895 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:14,896 [run_pretraining.py:  534]:	loss/total_loss, 7.176339149475098, 2375
[INFO] 2021-07-12 19:20:14,896 [run_pretraining.py:  535]:	loss/mlm_loss, 7.176339149475098, 2375
[INFO] 2021-07-12 19:20:14,896 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.373999814153649e-05, 2375
[INFO] 2021-07-12 19:20:14,896 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2375
[INFO] 2021-07-12 19:20:14,896 [run_pretraining.py:  558]:	worker_index: 6, step: 2375, cost: 7.176339, mlm loss: 7.176339, speed: 1.021104 steps/s, speed: 8.168834 samples/s, speed: 4182.442853 tokens/s, learning rate: 2.374e-05, loss_scalings: 2814.750488, pp_loss: 6.918518
[INFO] 2021-07-12 19:20:14,896 [run_pretraining.py:  512]:	********exe.run_2375******* 
[INFO] 2021-07-12 19:20:15,877 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:15,878 [run_pretraining.py:  534]:	loss/total_loss, 7.377030372619629, 2376
[INFO] 2021-07-12 19:20:15,878 [run_pretraining.py:  535]:	loss/mlm_loss, 7.377030372619629, 2376
[INFO] 2021-07-12 19:20:15,878 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3749998945277184e-05, 2376
[INFO] 2021-07-12 19:20:15,878 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2376
[INFO] 2021-07-12 19:20:15,878 [run_pretraining.py:  558]:	worker_index: 6, step: 2376, cost: 7.377030, mlm loss: 7.377030, speed: 1.019253 steps/s, speed: 8.154023 samples/s, speed: 4174.859713 tokens/s, learning rate: 2.375e-05, loss_scalings: 2814.750488, pp_loss: 7.582450
[INFO] 2021-07-12 19:20:15,878 [run_pretraining.py:  512]:	********exe.run_2376******* 
[INFO] 2021-07-12 19:20:16,849 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:16,850 [run_pretraining.py:  534]:	loss/total_loss, 7.617466926574707, 2377
[INFO] 2021-07-12 19:20:16,850 [run_pretraining.py:  535]:	loss/mlm_loss, 7.617466926574707, 2377
[INFO] 2021-07-12 19:20:16,850 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.375999974901788e-05, 2377
[INFO] 2021-07-12 19:20:16,850 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2377
[INFO] 2021-07-12 19:20:16,850 [run_pretraining.py:  558]:	worker_index: 6, step: 2377, cost: 7.617467, mlm loss: 7.617467, speed: 1.029110 steps/s, speed: 8.232881 samples/s, speed: 4215.235071 tokens/s, learning rate: 2.376e-05, loss_scalings: 2814.750488, pp_loss: 6.711435
[INFO] 2021-07-12 19:20:16,850 [run_pretraining.py:  512]:	********exe.run_2377******* 
[INFO] 2021-07-12 19:20:17,817 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:17,818 [run_pretraining.py:  534]:	loss/total_loss, 7.593913555145264, 2378
[INFO] 2021-07-12 19:20:17,818 [run_pretraining.py:  535]:	loss/mlm_loss, 7.593913555145264, 2378
[INFO] 2021-07-12 19:20:17,818 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.376999873376917e-05, 2378
[INFO] 2021-07-12 19:20:17,818 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2378
[INFO] 2021-07-12 19:20:17,818 [run_pretraining.py:  558]:	worker_index: 6, step: 2378, cost: 7.593914, mlm loss: 7.593914, speed: 1.034192 steps/s, speed: 8.273536 samples/s, speed: 4236.050192 tokens/s, learning rate: 2.377e-05, loss_scalings: 2814.750488, pp_loss: 7.456694
[INFO] 2021-07-12 19:20:17,818 [run_pretraining.py:  512]:	********exe.run_2378******* 
[INFO] 2021-07-12 19:20:18,726 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:18,727 [run_pretraining.py:  534]:	loss/total_loss, 7.242286205291748, 2379
[INFO] 2021-07-12 19:20:18,727 [run_pretraining.py:  535]:	loss/mlm_loss, 7.242286205291748, 2379
[INFO] 2021-07-12 19:20:18,727 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3779999537509866e-05, 2379
[INFO] 2021-07-12 19:20:18,727 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2379
[INFO] 2021-07-12 19:20:18,727 [run_pretraining.py:  558]:	worker_index: 6, step: 2379, cost: 7.242286, mlm loss: 7.242286, speed: 1.100820 steps/s, speed: 8.806556 samples/s, speed: 4508.956747 tokens/s, learning rate: 2.378e-05, loss_scalings: 2814.750488, pp_loss: 6.983511
[INFO] 2021-07-12 19:20:18,727 [run_pretraining.py:  512]:	********exe.run_2379******* 
[INFO] 2021-07-12 19:20:19,672 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:19,673 [run_pretraining.py:  534]:	loss/total_loss, 7.079249382019043, 2380
[INFO] 2021-07-12 19:20:19,673 [run_pretraining.py:  535]:	loss/mlm_loss, 7.079249382019043, 2380
[INFO] 2021-07-12 19:20:19,673 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.379000034125056e-05, 2380
[INFO] 2021-07-12 19:20:19,673 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2380
[INFO] 2021-07-12 19:20:19,673 [run_pretraining.py:  558]:	worker_index: 6, step: 2380, cost: 7.079249, mlm loss: 7.079249, speed: 1.058111 steps/s, speed: 8.464887 samples/s, speed: 4334.022254 tokens/s, learning rate: 2.379e-05, loss_scalings: 2814.750488, pp_loss: 7.074563
[INFO] 2021-07-12 19:20:19,673 [run_pretraining.py:  512]:	********exe.run_2380******* 
[INFO] 2021-07-12 19:20:20,599 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:20,599 [run_pretraining.py:  534]:	loss/total_loss, 7.399499416351318, 2381
[INFO] 2021-07-12 19:20:20,599 [run_pretraining.py:  535]:	loss/mlm_loss, 7.399499416351318, 2381
[INFO] 2021-07-12 19:20:20,599 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3799999326001853e-05, 2381
[INFO] 2021-07-12 19:20:20,600 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2381
[INFO] 2021-07-12 19:20:20,600 [run_pretraining.py:  558]:	worker_index: 6, step: 2381, cost: 7.399499, mlm loss: 7.399499, speed: 1.079963 steps/s, speed: 8.639704 samples/s, speed: 4423.528299 tokens/s, learning rate: 2.380e-05, loss_scalings: 2814.750488, pp_loss: 7.794371
[INFO] 2021-07-12 19:20:20,600 [run_pretraining.py:  512]:	********exe.run_2381******* 
[INFO] 2021-07-12 19:20:21,498 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:21,498 [run_pretraining.py:  534]:	loss/total_loss, 6.59349250793457, 2382
[INFO] 2021-07-12 19:20:21,499 [run_pretraining.py:  535]:	loss/mlm_loss, 6.59349250793457, 2382
[INFO] 2021-07-12 19:20:21,499 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3810000129742548e-05, 2382
[INFO] 2021-07-12 19:20:21,499 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2382
[INFO] 2021-07-12 19:20:21,499 [run_pretraining.py:  558]:	worker_index: 6, step: 2382, cost: 6.593493, mlm loss: 6.593493, speed: 1.112942 steps/s, speed: 8.903540 samples/s, speed: 4558.612363 tokens/s, learning rate: 2.381e-05, loss_scalings: 2814.750488, pp_loss: 7.196234
[INFO] 2021-07-12 19:20:21,499 [run_pretraining.py:  512]:	********exe.run_2382******* 
[INFO] 2021-07-12 19:20:22,413 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:22,413 [run_pretraining.py:  534]:	loss/total_loss, 7.4840593338012695, 2383
[INFO] 2021-07-12 19:20:22,414 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4840593338012695, 2383
[INFO] 2021-07-12 19:20:22,414 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.381999911449384e-05, 2383
[INFO] 2021-07-12 19:20:22,414 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2383
[INFO] 2021-07-12 19:20:22,414 [run_pretraining.py:  558]:	worker_index: 6, step: 2383, cost: 7.484059, mlm loss: 7.484059, speed: 1.093750 steps/s, speed: 8.749998 samples/s, speed: 4479.999099 tokens/s, learning rate: 2.382e-05, loss_scalings: 2814.750488, pp_loss: 7.402882
[INFO] 2021-07-12 19:20:22,414 [run_pretraining.py:  512]:	********exe.run_2383******* 
[INFO] 2021-07-12 19:20:23,318 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:23,319 [run_pretraining.py:  534]:	loss/total_loss, 6.84682559967041, 2384
[INFO] 2021-07-12 19:20:23,319 [run_pretraining.py:  535]:	loss/mlm_loss, 6.84682559967041, 2384
[INFO] 2021-07-12 19:20:23,319 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.382999809924513e-05, 2384
[INFO] 2021-07-12 19:20:23,319 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2384
[INFO] 2021-07-12 19:20:23,319 [run_pretraining.py:  558]:	worker_index: 6, step: 2384, cost: 6.846826, mlm loss: 6.846826, speed: 1.105272 steps/s, speed: 8.842179 samples/s, speed: 4527.195445 tokens/s, learning rate: 2.383e-05, loss_scalings: 2814.750488, pp_loss: 6.191545
[INFO] 2021-07-12 19:20:23,319 [run_pretraining.py:  512]:	********exe.run_2384******* 
[INFO] 2021-07-12 19:20:24,220 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:24,221 [run_pretraining.py:  534]:	loss/total_loss, 7.035000801086426, 2385
[INFO] 2021-07-12 19:20:24,221 [run_pretraining.py:  535]:	loss/mlm_loss, 7.035000801086426, 2385
[INFO] 2021-07-12 19:20:24,221 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3839998902985826e-05, 2385
[INFO] 2021-07-12 19:20:24,221 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2385
[INFO] 2021-07-12 19:20:24,221 [run_pretraining.py:  558]:	worker_index: 6, step: 2385, cost: 7.035001, mlm loss: 7.035001, speed: 1.109323 steps/s, speed: 8.874582 samples/s, speed: 4543.786162 tokens/s, learning rate: 2.384e-05, loss_scalings: 2814.750488, pp_loss: 7.936647
[INFO] 2021-07-12 19:20:24,222 [run_pretraining.py:  512]:	********exe.run_2385******* 
[INFO] 2021-07-12 19:20:25,122 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:25,122 [run_pretraining.py:  534]:	loss/total_loss, 7.877964019775391, 2386
[INFO] 2021-07-12 19:20:25,122 [run_pretraining.py:  535]:	loss/mlm_loss, 7.877964019775391, 2386
[INFO] 2021-07-12 19:20:25,123 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.384999970672652e-05, 2386
[INFO] 2021-07-12 19:20:25,123 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2386
[INFO] 2021-07-12 19:20:25,123 [run_pretraining.py:  558]:	worker_index: 6, step: 2386, cost: 7.877964, mlm loss: 7.877964, speed: 1.110330 steps/s, speed: 8.882643 samples/s, speed: 4547.913128 tokens/s, learning rate: 2.385e-05, loss_scalings: 2814.750488, pp_loss: 7.253125
[INFO] 2021-07-12 19:20:25,123 [run_pretraining.py:  512]:	********exe.run_2386******* 
[INFO] 2021-07-12 19:20:26,038 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:26,039 [run_pretraining.py:  534]:	loss/total_loss, 7.493288040161133, 2387
[INFO] 2021-07-12 19:20:26,039 [run_pretraining.py:  535]:	loss/mlm_loss, 7.493288040161133, 2387
[INFO] 2021-07-12 19:20:26,039 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3859998691477813e-05, 2387
[INFO] 2021-07-12 19:20:26,039 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2387
[INFO] 2021-07-12 19:20:26,039 [run_pretraining.py:  558]:	worker_index: 6, step: 2387, cost: 7.493288, mlm loss: 7.493288, speed: 1.091706 steps/s, speed: 8.733651 samples/s, speed: 4471.629063 tokens/s, learning rate: 2.386e-05, loss_scalings: 2814.750488, pp_loss: 7.127750
[INFO] 2021-07-12 19:20:26,040 [run_pretraining.py:  512]:	********exe.run_2387******* 
[INFO] 2021-07-12 19:20:26,936 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:26,937 [run_pretraining.py:  534]:	loss/total_loss, 7.835790634155273, 2388
[INFO] 2021-07-12 19:20:26,937 [run_pretraining.py:  535]:	loss/mlm_loss, 7.835790634155273, 2388
[INFO] 2021-07-12 19:20:26,937 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3869999495218508e-05, 2388
[INFO] 2021-07-12 19:20:26,937 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2388
[INFO] 2021-07-12 19:20:26,937 [run_pretraining.py:  558]:	worker_index: 6, step: 2388, cost: 7.835791, mlm loss: 7.835791, speed: 1.114621 steps/s, speed: 8.916970 samples/s, speed: 4565.488467 tokens/s, learning rate: 2.387e-05, loss_scalings: 2814.750488, pp_loss: 7.262357
[INFO] 2021-07-12 19:20:26,937 [run_pretraining.py:  512]:	********exe.run_2388******* 
[INFO] 2021-07-12 19:20:27,846 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:27,847 [run_pretraining.py:  534]:	loss/total_loss, 8.094873428344727, 2389
[INFO] 2021-07-12 19:20:27,847 [run_pretraining.py:  535]:	loss/mlm_loss, 8.094873428344727, 2389
[INFO] 2021-07-12 19:20:27,847 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3880000298959203e-05, 2389
[INFO] 2021-07-12 19:20:27,847 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2389
[INFO] 2021-07-12 19:20:27,847 [run_pretraining.py:  558]:	worker_index: 6, step: 2389, cost: 8.094873, mlm loss: 8.094873, speed: 1.100238 steps/s, speed: 8.801906 samples/s, speed: 4506.575817 tokens/s, learning rate: 2.388e-05, loss_scalings: 2814.750488, pp_loss: 7.204522
[INFO] 2021-07-12 19:20:27,847 [run_pretraining.py:  512]:	********exe.run_2389******* 
[INFO] 2021-07-12 19:20:28,790 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:28,791 [run_pretraining.py:  534]:	loss/total_loss, 8.02641487121582, 2390
[INFO] 2021-07-12 19:20:28,791 [run_pretraining.py:  535]:	loss/mlm_loss, 8.02641487121582, 2390
[INFO] 2021-07-12 19:20:28,791 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3889999283710495e-05, 2390
[INFO] 2021-07-12 19:20:28,791 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2390
[INFO] 2021-07-12 19:20:28,791 [run_pretraining.py:  558]:	worker_index: 6, step: 2390, cost: 8.026415, mlm loss: 8.026415, speed: 1.059985 steps/s, speed: 8.479883 samples/s, speed: 4341.700272 tokens/s, learning rate: 2.389e-05, loss_scalings: 2814.750488, pp_loss: 7.464122
[INFO] 2021-07-12 19:20:28,791 [run_pretraining.py:  512]:	********exe.run_2390******* 
[INFO] 2021-07-12 19:20:29,713 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:29,714 [run_pretraining.py:  534]:	loss/total_loss, 7.174466133117676, 2391
[INFO] 2021-07-12 19:20:29,714 [run_pretraining.py:  535]:	loss/mlm_loss, 7.174466133117676, 2391
[INFO] 2021-07-12 19:20:29,714 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3899998268461786e-05, 2391
[INFO] 2021-07-12 19:20:29,714 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2391
[INFO] 2021-07-12 19:20:29,714 [run_pretraining.py:  558]:	worker_index: 6, step: 2391, cost: 7.174466, mlm loss: 7.174466, speed: 1.084262 steps/s, speed: 8.674096 samples/s, speed: 4441.137339 tokens/s, learning rate: 2.390e-05, loss_scalings: 2814.750488, pp_loss: 7.161807
[INFO] 2021-07-12 19:20:29,714 [run_pretraining.py:  512]:	********exe.run_2391******* 
[INFO] 2021-07-12 19:20:30,618 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:30,619 [run_pretraining.py:  534]:	loss/total_loss, 6.941171646118164, 2392
[INFO] 2021-07-12 19:20:30,619 [run_pretraining.py:  535]:	loss/mlm_loss, 6.941171646118164, 2392
[INFO] 2021-07-12 19:20:30,619 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.390999907220248e-05, 2392
[INFO] 2021-07-12 19:20:30,619 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2392
[INFO] 2021-07-12 19:20:30,619 [run_pretraining.py:  558]:	worker_index: 6, step: 2392, cost: 6.941172, mlm loss: 6.941172, speed: 1.105937 steps/s, speed: 8.847497 samples/s, speed: 4529.918304 tokens/s, learning rate: 2.391e-05, loss_scalings: 2814.750488, pp_loss: 7.255966
[INFO] 2021-07-12 19:20:30,619 [run_pretraining.py:  512]:	********exe.run_2392******* 
[INFO] 2021-07-12 19:20:31,525 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:31,526 [run_pretraining.py:  534]:	loss/total_loss, 7.038729667663574, 2393
[INFO] 2021-07-12 19:20:31,526 [run_pretraining.py:  535]:	loss/mlm_loss, 7.038729667663574, 2393
[INFO] 2021-07-12 19:20:31,526 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3919999875943176e-05, 2393
[INFO] 2021-07-12 19:20:31,526 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2393
[INFO] 2021-07-12 19:20:31,526 [run_pretraining.py:  558]:	worker_index: 6, step: 2393, cost: 7.038730, mlm loss: 7.038730, speed: 1.102816 steps/s, speed: 8.822531 samples/s, speed: 4517.135847 tokens/s, learning rate: 2.392e-05, loss_scalings: 2814.750488, pp_loss: 7.402117
[INFO] 2021-07-12 19:20:31,527 [run_pretraining.py:  512]:	********exe.run_2393******* 
[INFO] 2021-07-12 19:20:32,429 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:32,429 [run_pretraining.py:  534]:	loss/total_loss, 7.196400165557861, 2394
[INFO] 2021-07-12 19:20:32,429 [run_pretraining.py:  535]:	loss/mlm_loss, 7.196400165557861, 2394
[INFO] 2021-07-12 19:20:32,430 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3929998860694468e-05, 2394
[INFO] 2021-07-12 19:20:32,430 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2394
[INFO] 2021-07-12 19:20:32,430 [run_pretraining.py:  558]:	worker_index: 6, step: 2394, cost: 7.196400, mlm loss: 7.196400, speed: 1.107929 steps/s, speed: 8.863436 samples/s, speed: 4538.078995 tokens/s, learning rate: 2.393e-05, loss_scalings: 2814.750488, pp_loss: 7.309214
[INFO] 2021-07-12 19:20:32,430 [run_pretraining.py:  512]:	********exe.run_2394******* 
[INFO] 2021-07-12 19:20:33,338 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:33,338 [run_pretraining.py:  534]:	loss/total_loss, 4.572343349456787, 2395
[INFO] 2021-07-12 19:20:33,338 [run_pretraining.py:  535]:	loss/mlm_loss, 4.572343349456787, 2395
[INFO] 2021-07-12 19:20:33,339 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3939999664435163e-05, 2395
[INFO] 2021-07-12 19:20:33,339 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2395
[INFO] 2021-07-12 19:20:33,339 [run_pretraining.py:  558]:	worker_index: 6, step: 2395, cost: 4.572343, mlm loss: 4.572343, speed: 1.100946 steps/s, speed: 8.807571 samples/s, speed: 4509.476320 tokens/s, learning rate: 2.394e-05, loss_scalings: 2814.750488, pp_loss: 6.708847
[INFO] 2021-07-12 19:20:33,339 [run_pretraining.py:  512]:	********exe.run_2395******* 
[INFO] 2021-07-12 19:20:34,245 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:34,245 [run_pretraining.py:  534]:	loss/total_loss, 7.048953056335449, 2396
[INFO] 2021-07-12 19:20:34,245 [run_pretraining.py:  535]:	loss/mlm_loss, 7.048953056335449, 2396
[INFO] 2021-07-12 19:20:34,245 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3949998649186455e-05, 2396
[INFO] 2021-07-12 19:20:34,246 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2396
[INFO] 2021-07-12 19:20:34,246 [run_pretraining.py:  558]:	worker_index: 6, step: 2396, cost: 7.048953, mlm loss: 7.048953, speed: 1.103502 steps/s, speed: 8.828016 samples/s, speed: 4519.944125 tokens/s, learning rate: 2.395e-05, loss_scalings: 2814.750488, pp_loss: 7.436385
[INFO] 2021-07-12 19:20:34,246 [run_pretraining.py:  512]:	********exe.run_2396******* 
[INFO] 2021-07-12 19:20:35,157 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:35,158 [run_pretraining.py:  534]:	loss/total_loss, 7.05572509765625, 2397
[INFO] 2021-07-12 19:20:35,158 [run_pretraining.py:  535]:	loss/mlm_loss, 7.05572509765625, 2397
[INFO] 2021-07-12 19:20:35,158 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.395999945292715e-05, 2397
[INFO] 2021-07-12 19:20:35,158 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2397
[INFO] 2021-07-12 19:20:35,158 [run_pretraining.py:  558]:	worker_index: 6, step: 2397, cost: 7.055725, mlm loss: 7.055725, speed: 1.096642 steps/s, speed: 8.773132 samples/s, speed: 4491.843682 tokens/s, learning rate: 2.396e-05, loss_scalings: 2814.750488, pp_loss: 7.325108
[INFO] 2021-07-12 19:20:35,158 [run_pretraining.py:  512]:	********exe.run_2397******* 
[INFO] 2021-07-12 19:20:36,062 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:36,062 [run_pretraining.py:  534]:	loss/total_loss, 7.277045249938965, 2398
[INFO] 2021-07-12 19:20:36,063 [run_pretraining.py:  535]:	loss/mlm_loss, 7.277045249938965, 2398
[INFO] 2021-07-12 19:20:36,063 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3970000256667845e-05, 2398
[INFO] 2021-07-12 19:20:36,063 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2398
[INFO] 2021-07-12 19:20:36,063 [run_pretraining.py:  558]:	worker_index: 6, step: 2398, cost: 7.277045, mlm loss: 7.277045, speed: 1.106303 steps/s, speed: 8.850425 samples/s, speed: 4531.417810 tokens/s, learning rate: 2.397e-05, loss_scalings: 2814.750488, pp_loss: 7.413335
[INFO] 2021-07-12 19:20:36,063 [run_pretraining.py:  512]:	********exe.run_2398******* 
[INFO] 2021-07-12 19:20:36,969 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:36,970 [run_pretraining.py:  534]:	loss/total_loss, 7.224837303161621, 2399
[INFO] 2021-07-12 19:20:36,970 [run_pretraining.py:  535]:	loss/mlm_loss, 7.224837303161621, 2399
[INFO] 2021-07-12 19:20:36,970 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3979999241419137e-05, 2399
[INFO] 2021-07-12 19:20:36,970 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2399
[INFO] 2021-07-12 19:20:36,970 [run_pretraining.py:  558]:	worker_index: 6, step: 2399, cost: 7.224837, mlm loss: 7.224837, speed: 1.103128 steps/s, speed: 8.825021 samples/s, speed: 4518.410608 tokens/s, learning rate: 2.398e-05, loss_scalings: 2814.750488, pp_loss: 7.251876
[INFO] 2021-07-12 19:20:36,970 [run_pretraining.py:  512]:	********exe.run_2399******* 
[INFO] 2021-07-12 19:20:37,868 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:37,869 [run_pretraining.py:  534]:	loss/total_loss, 7.230510234832764, 2400
[INFO] 2021-07-12 19:20:37,869 [run_pretraining.py:  535]:	loss/mlm_loss, 7.230510234832764, 2400
[INFO] 2021-07-12 19:20:37,869 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3989998226170428e-05, 2400
[INFO] 2021-07-12 19:20:37,869 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2400
[INFO] 2021-07-12 19:20:37,869 [run_pretraining.py:  558]:	worker_index: 6, step: 2400, cost: 7.230510, mlm loss: 7.230510, speed: 1.112875 steps/s, speed: 8.902999 samples/s, speed: 4558.335379 tokens/s, learning rate: 2.399e-05, loss_scalings: 2814.750488, pp_loss: 6.756293
[INFO] 2021-07-12 19:20:37,869 [run_pretraining.py:  512]:	********exe.run_2400******* 
[INFO] 2021-07-12 19:20:38,769 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:38,770 [run_pretraining.py:  534]:	loss/total_loss, 6.597338676452637, 2401
[INFO] 2021-07-12 19:20:38,770 [run_pretraining.py:  535]:	loss/mlm_loss, 6.597338676452637, 2401
[INFO] 2021-07-12 19:20:38,770 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3999999029911123e-05, 2401
[INFO] 2021-07-12 19:20:38,770 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2401
[INFO] 2021-07-12 19:20:38,770 [run_pretraining.py:  558]:	worker_index: 6, step: 2401, cost: 6.597339, mlm loss: 6.597339, speed: 1.110603 steps/s, speed: 8.884821 samples/s, speed: 4549.028249 tokens/s, learning rate: 2.400e-05, loss_scalings: 2814.750488, pp_loss: 7.086125
[INFO] 2021-07-12 19:20:38,770 [run_pretraining.py:  512]:	********exe.run_2401******* 
[INFO] 2021-07-12 19:20:39,684 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:39,685 [run_pretraining.py:  534]:	loss/total_loss, 6.920689582824707, 2402
[INFO] 2021-07-12 19:20:39,685 [run_pretraining.py:  535]:	loss/mlm_loss, 6.920689582824707, 2402
[INFO] 2021-07-12 19:20:39,685 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.400999983365182e-05, 2402
[INFO] 2021-07-12 19:20:39,685 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2402
[INFO] 2021-07-12 19:20:39,685 [run_pretraining.py:  558]:	worker_index: 6, step: 2402, cost: 6.920690, mlm loss: 6.920690, speed: 1.093975 steps/s, speed: 8.751803 samples/s, speed: 4480.923376 tokens/s, learning rate: 2.401e-05, loss_scalings: 2814.750488, pp_loss: 6.935818
[INFO] 2021-07-12 19:20:39,685 [run_pretraining.py:  512]:	********exe.run_2402******* 
[INFO] 2021-07-12 19:20:40,592 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:40,592 [run_pretraining.py:  534]:	loss/total_loss, 6.803372859954834, 2403
[INFO] 2021-07-12 19:20:40,592 [run_pretraining.py:  535]:	loss/mlm_loss, 6.803372859954834, 2403
[INFO] 2021-07-12 19:20:40,592 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.401999881840311e-05, 2403
[INFO] 2021-07-12 19:20:40,593 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2403
[INFO] 2021-07-12 19:20:40,593 [run_pretraining.py:  558]:	worker_index: 6, step: 2403, cost: 6.803373, mlm loss: 6.803373, speed: 1.102865 steps/s, speed: 8.822921 samples/s, speed: 4517.335389 tokens/s, learning rate: 2.402e-05, loss_scalings: 2814.750488, pp_loss: 6.794768
[INFO] 2021-07-12 19:20:40,593 [run_pretraining.py:  512]:	********exe.run_2403******* 
[INFO] 2021-07-12 19:20:41,488 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:41,488 [run_pretraining.py:  534]:	loss/total_loss, 7.663877964019775, 2404
[INFO] 2021-07-12 19:20:41,489 [run_pretraining.py:  535]:	loss/mlm_loss, 7.663877964019775, 2404
[INFO] 2021-07-12 19:20:41,489 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4029999622143805e-05, 2404
[INFO] 2021-07-12 19:20:41,489 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2404
[INFO] 2021-07-12 19:20:41,489 [run_pretraining.py:  558]:	worker_index: 6, step: 2404, cost: 7.663878, mlm loss: 7.663878, speed: 1.116699 steps/s, speed: 8.933588 samples/s, speed: 4573.997130 tokens/s, learning rate: 2.403e-05, loss_scalings: 2814.750488, pp_loss: 7.286348
[INFO] 2021-07-12 19:20:41,489 [run_pretraining.py:  512]:	********exe.run_2404******* 
[INFO] 2021-07-12 19:20:42,407 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:42,407 [run_pretraining.py:  534]:	loss/total_loss, 7.385251998901367, 2405
[INFO] 2021-07-12 19:20:42,407 [run_pretraining.py:  535]:	loss/mlm_loss, 7.385251998901367, 2405
[INFO] 2021-07-12 19:20:42,408 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.40400004258845e-05, 2405
[INFO] 2021-07-12 19:20:42,408 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2405
[INFO] 2021-07-12 19:20:42,408 [run_pretraining.py:  558]:	worker_index: 6, step: 2405, cost: 7.385252, mlm loss: 7.385252, speed: 1.089156 steps/s, speed: 8.713246 samples/s, speed: 4461.182016 tokens/s, learning rate: 2.404e-05, loss_scalings: 2814.750488, pp_loss: 7.532873
[INFO] 2021-07-12 19:20:42,408 [run_pretraining.py:  512]:	********exe.run_2405******* 
[INFO] 2021-07-12 19:20:43,346 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:43,347 [run_pretraining.py:  534]:	loss/total_loss, 7.293182849884033, 2406
[INFO] 2021-07-12 19:20:43,347 [run_pretraining.py:  535]:	loss/mlm_loss, 7.293182849884033, 2406
[INFO] 2021-07-12 19:20:43,347 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4049999410635792e-05, 2406
[INFO] 2021-07-12 19:20:43,347 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2406
[INFO] 2021-07-12 19:20:43,347 [run_pretraining.py:  558]:	worker_index: 6, step: 2406, cost: 7.293183, mlm loss: 7.293183, speed: 1.065415 steps/s, speed: 8.523319 samples/s, speed: 4363.939358 tokens/s, learning rate: 2.405e-05, loss_scalings: 2814.750488, pp_loss: 7.326234
[INFO] 2021-07-12 19:20:43,347 [run_pretraining.py:  512]:	********exe.run_2406******* 
[INFO] 2021-07-12 19:20:44,249 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:44,249 [run_pretraining.py:  534]:	loss/total_loss, 6.53556489944458, 2407
[INFO] 2021-07-12 19:20:44,249 [run_pretraining.py:  535]:	loss/mlm_loss, 6.53556489944458, 2407
[INFO] 2021-07-12 19:20:44,250 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4060000214376487e-05, 2407
[INFO] 2021-07-12 19:20:44,250 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2407
[INFO] 2021-07-12 19:20:44,250 [run_pretraining.py:  558]:	worker_index: 6, step: 2407, cost: 6.535565, mlm loss: 6.535565, speed: 1.108721 steps/s, speed: 8.869769 samples/s, speed: 4541.321499 tokens/s, learning rate: 2.406e-05, loss_scalings: 2814.750488, pp_loss: 7.066113
[INFO] 2021-07-12 19:20:44,250 [run_pretraining.py:  512]:	********exe.run_2407******* 
[INFO] 2021-07-12 19:20:45,155 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:45,156 [run_pretraining.py:  534]:	loss/total_loss, 7.17445707321167, 2408
[INFO] 2021-07-12 19:20:45,156 [run_pretraining.py:  535]:	loss/mlm_loss, 7.17445707321167, 2408
[INFO] 2021-07-12 19:20:45,156 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.406999919912778e-05, 2408
[INFO] 2021-07-12 19:20:45,156 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2408
[INFO] 2021-07-12 19:20:45,156 [run_pretraining.py:  558]:	worker_index: 6, step: 2408, cost: 7.174457, mlm loss: 7.174457, speed: 1.103924 steps/s, speed: 8.831392 samples/s, speed: 4521.672659 tokens/s, learning rate: 2.407e-05, loss_scalings: 2814.750488, pp_loss: 7.160169
[INFO] 2021-07-12 19:20:45,156 [run_pretraining.py:  512]:	********exe.run_2408******* 
[INFO] 2021-07-12 19:20:46,060 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:46,061 [run_pretraining.py:  534]:	loss/total_loss, 7.143375873565674, 2409
[INFO] 2021-07-12 19:20:46,061 [run_pretraining.py:  535]:	loss/mlm_loss, 7.143375873565674, 2409
[INFO] 2021-07-12 19:20:46,061 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.407999818387907e-05, 2409
[INFO] 2021-07-12 19:20:46,061 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2409
[INFO] 2021-07-12 19:20:46,061 [run_pretraining.py:  558]:	worker_index: 6, step: 2409, cost: 7.143376, mlm loss: 7.143376, speed: 1.105687 steps/s, speed: 8.845498 samples/s, speed: 4528.894908 tokens/s, learning rate: 2.408e-05, loss_scalings: 2814.750488, pp_loss: 7.113807
[INFO] 2021-07-12 19:20:46,061 [run_pretraining.py:  512]:	********exe.run_2409******* 
[INFO] 2021-07-12 19:20:46,967 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:46,967 [run_pretraining.py:  534]:	loss/total_loss, 7.222379684448242, 2410
[INFO] 2021-07-12 19:20:46,967 [run_pretraining.py:  535]:	loss/mlm_loss, 7.222379684448242, 2410
[INFO] 2021-07-12 19:20:46,967 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4089998987619765e-05, 2410
[INFO] 2021-07-12 19:20:46,968 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2410
[INFO] 2021-07-12 19:20:46,968 [run_pretraining.py:  558]:	worker_index: 6, step: 2410, cost: 7.222380, mlm loss: 7.222380, speed: 1.104310 steps/s, speed: 8.834480 samples/s, speed: 4523.253646 tokens/s, learning rate: 2.409e-05, loss_scalings: 2814.750488, pp_loss: 7.155142
[INFO] 2021-07-12 19:20:46,968 [run_pretraining.py:  512]:	********exe.run_2410******* 
[INFO] 2021-07-12 19:20:47,879 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:47,879 [run_pretraining.py:  534]:	loss/total_loss, 7.057840347290039, 2411
[INFO] 2021-07-12 19:20:47,879 [run_pretraining.py:  535]:	loss/mlm_loss, 7.057840347290039, 2411
[INFO] 2021-07-12 19:20:47,879 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.409999979136046e-05, 2411
[INFO] 2021-07-12 19:20:47,879 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2411
[INFO] 2021-07-12 19:20:47,880 [run_pretraining.py:  558]:	worker_index: 6, step: 2411, cost: 7.057840, mlm loss: 7.057840, speed: 1.097454 steps/s, speed: 8.779629 samples/s, speed: 4495.169797 tokens/s, learning rate: 2.410e-05, loss_scalings: 2814.750488, pp_loss: 7.282100
[INFO] 2021-07-12 19:20:47,880 [run_pretraining.py:  512]:	********exe.run_2411******* 
[INFO] 2021-07-12 19:20:48,779 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:48,780 [run_pretraining.py:  534]:	loss/total_loss, 7.347293853759766, 2412
[INFO] 2021-07-12 19:20:48,780 [run_pretraining.py:  535]:	loss/mlm_loss, 7.347293853759766, 2412
[INFO] 2021-07-12 19:20:48,780 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4109998776111752e-05, 2412
[INFO] 2021-07-12 19:20:48,780 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2412
[INFO] 2021-07-12 19:20:48,780 [run_pretraining.py:  558]:	worker_index: 6, step: 2412, cost: 7.347294, mlm loss: 7.347294, speed: 1.110954 steps/s, speed: 8.887633 samples/s, speed: 4550.468117 tokens/s, learning rate: 2.411e-05, loss_scalings: 2814.750488, pp_loss: 7.421860
[INFO] 2021-07-12 19:20:48,780 [run_pretraining.py:  512]:	********exe.run_2412******* 
[INFO] 2021-07-12 19:20:49,692 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:49,693 [run_pretraining.py:  534]:	loss/total_loss, 7.177825450897217, 2413
[INFO] 2021-07-12 19:20:49,693 [run_pretraining.py:  535]:	loss/mlm_loss, 7.177825450897217, 2413
[INFO] 2021-07-12 19:20:49,693 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4119999579852447e-05, 2413
[INFO] 2021-07-12 19:20:49,693 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2413
[INFO] 2021-07-12 19:20:49,693 [run_pretraining.py:  558]:	worker_index: 6, step: 2413, cost: 7.177825, mlm loss: 7.177825, speed: 1.096436 steps/s, speed: 8.771488 samples/s, speed: 4491.001769 tokens/s, learning rate: 2.412e-05, loss_scalings: 2814.750488, pp_loss: 7.430130
[INFO] 2021-07-12 19:20:49,693 [run_pretraining.py:  512]:	********exe.run_2413******* 
[INFO] 2021-07-12 19:20:50,597 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:50,597 [run_pretraining.py:  534]:	loss/total_loss, 6.796562671661377, 2414
[INFO] 2021-07-12 19:20:50,597 [run_pretraining.py:  535]:	loss/mlm_loss, 6.796562671661377, 2414
[INFO] 2021-07-12 19:20:50,597 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4130000383593142e-05, 2414
[INFO] 2021-07-12 19:20:50,597 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2414
[INFO] 2021-07-12 19:20:50,598 [run_pretraining.py:  558]:	worker_index: 6, step: 2414, cost: 6.796563, mlm loss: 6.796563, speed: 1.106571 steps/s, speed: 8.852571 samples/s, speed: 4532.516485 tokens/s, learning rate: 2.413e-05, loss_scalings: 2814.750488, pp_loss: 7.168406
[INFO] 2021-07-12 19:20:50,598 [run_pretraining.py:  512]:	********exe.run_2414******* 
[INFO] 2021-07-12 19:20:51,502 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:51,503 [run_pretraining.py:  534]:	loss/total_loss, 8.058442115783691, 2415
[INFO] 2021-07-12 19:20:51,503 [run_pretraining.py:  535]:	loss/mlm_loss, 8.058442115783691, 2415
[INFO] 2021-07-12 19:20:51,503 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4139999368344434e-05, 2415
[INFO] 2021-07-12 19:20:51,503 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2415
[INFO] 2021-07-12 19:20:51,503 [run_pretraining.py:  558]:	worker_index: 6, step: 2415, cost: 8.058442, mlm loss: 8.058442, speed: 1.104680 steps/s, speed: 8.837437 samples/s, speed: 4524.767810 tokens/s, learning rate: 2.414e-05, loss_scalings: 2814.750488, pp_loss: 7.575653
[INFO] 2021-07-12 19:20:51,504 [run_pretraining.py:  512]:	********exe.run_2415******* 
[INFO] 2021-07-12 19:20:52,410 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:52,411 [run_pretraining.py:  534]:	loss/total_loss, 7.328664302825928, 2416
[INFO] 2021-07-12 19:20:52,411 [run_pretraining.py:  535]:	loss/mlm_loss, 7.328664302825928, 2416
[INFO] 2021-07-12 19:20:52,411 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.415000017208513e-05, 2416
[INFO] 2021-07-12 19:20:52,411 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2416
[INFO] 2021-07-12 19:20:52,411 [run_pretraining.py:  558]:	worker_index: 6, step: 2416, cost: 7.328664, mlm loss: 7.328664, speed: 1.102906 steps/s, speed: 8.823248 samples/s, speed: 4517.502876 tokens/s, learning rate: 2.415e-05, loss_scalings: 2814.750488, pp_loss: 6.392616
[INFO] 2021-07-12 19:20:52,411 [run_pretraining.py:  512]:	********exe.run_2416******* 
[INFO] 2021-07-12 19:20:53,366 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:53,367 [run_pretraining.py:  534]:	loss/total_loss, 7.566653728485107, 2417
[INFO] 2021-07-12 19:20:53,367 [run_pretraining.py:  535]:	loss/mlm_loss, 7.566653728485107, 2417
[INFO] 2021-07-12 19:20:53,367 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4160000975825824e-05, 2417
[INFO] 2021-07-12 19:20:53,367 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2417
[INFO] 2021-07-12 19:20:53,367 [run_pretraining.py:  558]:	worker_index: 6, step: 2417, cost: 7.566654, mlm loss: 7.566654, speed: 1.046540 steps/s, speed: 8.372324 samples/s, speed: 4286.629801 tokens/s, learning rate: 2.416e-05, loss_scalings: 2814.750488, pp_loss: 7.422841
[INFO] 2021-07-12 19:20:53,367 [run_pretraining.py:  512]:	********exe.run_2417******* 
[INFO] 2021-07-12 19:20:54,300 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:54,300 [run_pretraining.py:  534]:	loss/total_loss, 7.754573345184326, 2418
[INFO] 2021-07-12 19:20:54,301 [run_pretraining.py:  535]:	loss/mlm_loss, 7.754573345184326, 2418
[INFO] 2021-07-12 19:20:54,301 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4169998141587712e-05, 2418
[INFO] 2021-07-12 19:20:54,301 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2418
[INFO] 2021-07-12 19:20:54,301 [run_pretraining.py:  558]:	worker_index: 6, step: 2418, cost: 7.754573, mlm loss: 7.754573, speed: 1.071844 steps/s, speed: 8.574749 samples/s, speed: 4390.271305 tokens/s, learning rate: 2.417e-05, loss_scalings: 2814.750488, pp_loss: 7.685988
[INFO] 2021-07-12 19:20:54,301 [run_pretraining.py:  512]:	********exe.run_2418******* 
[INFO] 2021-07-12 19:20:55,204 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:55,205 [run_pretraining.py:  534]:	loss/total_loss, 7.310988903045654, 2419
[INFO] 2021-07-12 19:20:55,205 [run_pretraining.py:  535]:	loss/mlm_loss, 7.310988903045654, 2419
[INFO] 2021-07-12 19:20:55,205 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4179998945328407e-05, 2419
[INFO] 2021-07-12 19:20:55,205 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2419
[INFO] 2021-07-12 19:20:55,205 [run_pretraining.py:  558]:	worker_index: 6, step: 2419, cost: 7.310989, mlm loss: 7.310989, speed: 1.106306 steps/s, speed: 8.850451 samples/s, speed: 4531.430958 tokens/s, learning rate: 2.418e-05, loss_scalings: 2814.750488, pp_loss: 7.440808
[INFO] 2021-07-12 19:20:55,206 [run_pretraining.py:  512]:	********exe.run_2419******* 
[INFO] 2021-07-12 19:20:56,111 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:56,112 [run_pretraining.py:  534]:	loss/total_loss, 7.692934513092041, 2420
[INFO] 2021-07-12 19:20:56,112 [run_pretraining.py:  535]:	loss/mlm_loss, 7.692934513092041, 2420
[INFO] 2021-07-12 19:20:56,112 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4189999749069102e-05, 2420
[INFO] 2021-07-12 19:20:56,112 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2420
[INFO] 2021-07-12 19:20:56,112 [run_pretraining.py:  558]:	worker_index: 6, step: 2420, cost: 7.692935, mlm loss: 7.692935, speed: 1.103617 steps/s, speed: 8.828936 samples/s, speed: 4520.415088 tokens/s, learning rate: 2.419e-05, loss_scalings: 2814.750488, pp_loss: 6.647734
[INFO] 2021-07-12 19:20:56,112 [run_pretraining.py:  512]:	********exe.run_2420******* 
[INFO] 2021-07-12 19:20:57,035 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:57,036 [run_pretraining.py:  534]:	loss/total_loss, 8.762262344360352, 2421
[INFO] 2021-07-12 19:20:57,036 [run_pretraining.py:  535]:	loss/mlm_loss, 8.762262344360352, 2421
[INFO] 2021-07-12 19:20:57,036 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4199998733820394e-05, 2421
[INFO] 2021-07-12 19:20:57,036 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2421
[INFO] 2021-07-12 19:20:57,036 [run_pretraining.py:  558]:	worker_index: 6, step: 2421, cost: 8.762262, mlm loss: 8.762262, speed: 1.083017 steps/s, speed: 8.664134 samples/s, speed: 4436.036586 tokens/s, learning rate: 2.420e-05, loss_scalings: 2814.750488, pp_loss: 7.672836
[INFO] 2021-07-12 19:20:57,036 [run_pretraining.py:  512]:	********exe.run_2421******* 
[INFO] 2021-07-12 19:20:57,945 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:57,945 [run_pretraining.py:  534]:	loss/total_loss, 7.8372392654418945, 2422
[INFO] 2021-07-12 19:20:57,945 [run_pretraining.py:  535]:	loss/mlm_loss, 7.8372392654418945, 2422
[INFO] 2021-07-12 19:20:57,945 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.420999953756109e-05, 2422
[INFO] 2021-07-12 19:20:57,946 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2422
[INFO] 2021-07-12 19:20:57,946 [run_pretraining.py:  558]:	worker_index: 6, step: 2422, cost: 7.837239, mlm loss: 7.837239, speed: 1.100632 steps/s, speed: 8.805054 samples/s, speed: 4508.187667 tokens/s, learning rate: 2.421e-05, loss_scalings: 2814.750488, pp_loss: 7.349937
[INFO] 2021-07-12 19:20:57,946 [run_pretraining.py:  512]:	********exe.run_2422******* 
[INFO] 2021-07-12 19:20:58,865 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:58,866 [run_pretraining.py:  534]:	loss/total_loss, 7.29354190826416, 2423
[INFO] 2021-07-12 19:20:58,866 [run_pretraining.py:  535]:	loss/mlm_loss, 7.29354190826416, 2423
[INFO] 2021-07-12 19:20:58,866 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4220000341301784e-05, 2423
[INFO] 2021-07-12 19:20:58,866 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2423
[INFO] 2021-07-12 19:20:58,866 [run_pretraining.py:  558]:	worker_index: 6, step: 2423, cost: 7.293542, mlm loss: 7.293542, speed: 1.086851 steps/s, speed: 8.694804 samples/s, speed: 4451.739764 tokens/s, learning rate: 2.422e-05, loss_scalings: 2814.750488, pp_loss: 7.042389
[INFO] 2021-07-12 19:20:58,866 [run_pretraining.py:  512]:	********exe.run_2423******* 
[INFO] 2021-07-12 19:20:59,777 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:59,777 [run_pretraining.py:  534]:	loss/total_loss, 7.425342559814453, 2424
[INFO] 2021-07-12 19:20:59,778 [run_pretraining.py:  535]:	loss/mlm_loss, 7.425342559814453, 2424
[INFO] 2021-07-12 19:20:59,778 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4229999326053075e-05, 2424
[INFO] 2021-07-12 19:20:59,778 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2424
[INFO] 2021-07-12 19:20:59,778 [run_pretraining.py:  558]:	worker_index: 6, step: 2424, cost: 7.425343, mlm loss: 7.425343, speed: 1.097954 steps/s, speed: 8.783634 samples/s, speed: 4497.220807 tokens/s, learning rate: 2.423e-05, loss_scalings: 2814.750488, pp_loss: 7.574043
[INFO] 2021-07-12 19:20:59,778 [run_pretraining.py:  512]:	********exe.run_2424******* 
[INFO] 2021-07-12 19:21:00,695 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:00,696 [run_pretraining.py:  534]:	loss/total_loss, 7.368059158325195, 2425
[INFO] 2021-07-12 19:21:00,696 [run_pretraining.py:  535]:	loss/mlm_loss, 7.368059158325195, 2425
[INFO] 2021-07-12 19:21:00,696 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.424000012979377e-05, 2425
[INFO] 2021-07-12 19:21:00,696 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2425
[INFO] 2021-07-12 19:21:00,696 [run_pretraining.py:  558]:	worker_index: 6, step: 2425, cost: 7.368059, mlm loss: 7.368059, speed: 1.090191 steps/s, speed: 8.721528 samples/s, speed: 4465.422521 tokens/s, learning rate: 2.424e-05, loss_scalings: 2814.750488, pp_loss: 7.391850
[INFO] 2021-07-12 19:21:00,696 [run_pretraining.py:  512]:	********exe.run_2425******* 
[INFO] 2021-07-12 19:21:01,606 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:01,607 [run_pretraining.py:  534]:	loss/total_loss, 7.84088134765625, 2426
[INFO] 2021-07-12 19:21:01,607 [run_pretraining.py:  535]:	loss/mlm_loss, 7.84088134765625, 2426
[INFO] 2021-07-12 19:21:01,607 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4250000933534466e-05, 2426
[INFO] 2021-07-12 19:21:01,607 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2426
[INFO] 2021-07-12 19:21:01,607 [run_pretraining.py:  558]:	worker_index: 6, step: 2426, cost: 7.840881, mlm loss: 7.840881, speed: 1.098187 steps/s, speed: 8.785500 samples/s, speed: 4498.175760 tokens/s, learning rate: 2.425e-05, loss_scalings: 2814.750488, pp_loss: 7.425829
[INFO] 2021-07-12 19:21:01,607 [run_pretraining.py:  512]:	********exe.run_2426******* 
[INFO] 2021-07-12 19:21:02,526 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:02,527 [run_pretraining.py:  534]:	loss/total_loss, 7.310868740081787, 2427
[INFO] 2021-07-12 19:21:02,527 [run_pretraining.py:  535]:	loss/mlm_loss, 7.310868740081787, 2427
[INFO] 2021-07-12 19:21:02,527 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4259998099296354e-05, 2427
[INFO] 2021-07-12 19:21:02,527 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2427
[INFO] 2021-07-12 19:21:02,527 [run_pretraining.py:  558]:	worker_index: 6, step: 2427, cost: 7.310869, mlm loss: 7.310869, speed: 1.087964 steps/s, speed: 8.703713 samples/s, speed: 4456.300989 tokens/s, learning rate: 2.426e-05, loss_scalings: 2814.750488, pp_loss: 7.339198
[INFO] 2021-07-12 19:21:02,527 [run_pretraining.py:  512]:	********exe.run_2427******* 
[INFO] 2021-07-12 19:21:03,445 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:03,446 [run_pretraining.py:  534]:	loss/total_loss, 4.866242408752441, 2428
[INFO] 2021-07-12 19:21:03,446 [run_pretraining.py:  535]:	loss/mlm_loss, 4.866242408752441, 2428
[INFO] 2021-07-12 19:21:03,446 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.426999890303705e-05, 2428
[INFO] 2021-07-12 19:21:03,446 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2428
[INFO] 2021-07-12 19:21:03,446 [run_pretraining.py:  558]:	worker_index: 6, step: 2428, cost: 4.866242, mlm loss: 4.866242, speed: 1.089124 steps/s, speed: 8.712995 samples/s, speed: 4461.053430 tokens/s, learning rate: 2.427e-05, loss_scalings: 2814.750488, pp_loss: 6.652218
[INFO] 2021-07-12 19:21:03,446 [run_pretraining.py:  512]:	********exe.run_2428******* 
[INFO] 2021-07-12 19:21:04,362 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:04,363 [run_pretraining.py:  534]:	loss/total_loss, 6.890313148498535, 2429
[INFO] 2021-07-12 19:21:04,363 [run_pretraining.py:  535]:	loss/mlm_loss, 6.890313148498535, 2429
[INFO] 2021-07-12 19:21:04,363 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4279999706777744e-05, 2429
[INFO] 2021-07-12 19:21:04,363 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2429
[INFO] 2021-07-12 19:21:04,363 [run_pretraining.py:  558]:	worker_index: 6, step: 2429, cost: 6.890313, mlm loss: 6.890313, speed: 1.090700 steps/s, speed: 8.725599 samples/s, speed: 4467.506879 tokens/s, learning rate: 2.428e-05, loss_scalings: 2814.750488, pp_loss: 7.012639
[INFO] 2021-07-12 19:21:04,364 [run_pretraining.py:  512]:	********exe.run_2429******* 
[INFO] 2021-07-12 19:21:05,277 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:05,277 [run_pretraining.py:  534]:	loss/total_loss, 6.953854084014893, 2430
[INFO] 2021-07-12 19:21:05,277 [run_pretraining.py:  535]:	loss/mlm_loss, 6.953854084014893, 2430
[INFO] 2021-07-12 19:21:05,277 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4289998691529036e-05, 2430
[INFO] 2021-07-12 19:21:05,277 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2430
[INFO] 2021-07-12 19:21:05,278 [run_pretraining.py:  558]:	worker_index: 6, step: 2430, cost: 6.953854, mlm loss: 6.953854, speed: 1.094845 steps/s, speed: 8.758760 samples/s, speed: 4484.484995 tokens/s, learning rate: 2.429e-05, loss_scalings: 2814.750488, pp_loss: 7.039627
[INFO] 2021-07-12 19:21:05,278 [run_pretraining.py:  512]:	********exe.run_2430******* 
[INFO] 2021-07-12 19:21:06,189 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:06,189 [run_pretraining.py:  534]:	loss/total_loss, 7.262328147888184, 2431
[INFO] 2021-07-12 19:21:06,189 [run_pretraining.py:  535]:	loss/mlm_loss, 7.262328147888184, 2431
[INFO] 2021-07-12 19:21:06,190 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.429999949526973e-05, 2431
[INFO] 2021-07-12 19:21:06,190 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2431
[INFO] 2021-07-12 19:21:06,190 [run_pretraining.py:  558]:	worker_index: 6, step: 2431, cost: 7.262328, mlm loss: 7.262328, speed: 1.097133 steps/s, speed: 8.777068 samples/s, speed: 4493.858743 tokens/s, learning rate: 2.430e-05, loss_scalings: 2814.750488, pp_loss: 6.871528
[INFO] 2021-07-12 19:21:06,190 [run_pretraining.py:  512]:	********exe.run_2431******* 
[INFO] 2021-07-12 19:21:07,099 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:07,100 [run_pretraining.py:  534]:	loss/total_loss, 7.379842758178711, 2432
[INFO] 2021-07-12 19:21:07,100 [run_pretraining.py:  535]:	loss/mlm_loss, 7.379842758178711, 2432
[INFO] 2021-07-12 19:21:07,100 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4310000299010426e-05, 2432
[INFO] 2021-07-12 19:21:07,100 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2432
[INFO] 2021-07-12 19:21:07,100 [run_pretraining.py:  558]:	worker_index: 6, step: 2432, cost: 7.379843, mlm loss: 7.379843, speed: 1.099334 steps/s, speed: 8.794676 samples/s, speed: 4502.873994 tokens/s, learning rate: 2.431e-05, loss_scalings: 2814.750488, pp_loss: 7.297049
[INFO] 2021-07-12 19:21:07,100 [run_pretraining.py:  512]:	********exe.run_2432******* 
[INFO] 2021-07-12 19:21:08,011 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:08,012 [run_pretraining.py:  534]:	loss/total_loss, 7.366386413574219, 2433
[INFO] 2021-07-12 19:21:08,012 [run_pretraining.py:  535]:	loss/mlm_loss, 7.366386413574219, 2433
[INFO] 2021-07-12 19:21:08,012 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4319999283761717e-05, 2433
[INFO] 2021-07-12 19:21:08,012 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2433
[INFO] 2021-07-12 19:21:08,012 [run_pretraining.py:  558]:	worker_index: 6, step: 2433, cost: 7.366386, mlm loss: 7.366386, speed: 1.097208 steps/s, speed: 8.777663 samples/s, speed: 4494.163216 tokens/s, learning rate: 2.432e-05, loss_scalings: 2814.750488, pp_loss: 7.097529
[INFO] 2021-07-12 19:21:08,012 [run_pretraining.py:  512]:	********exe.run_2433******* 
[INFO] 2021-07-12 19:21:08,922 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:08,922 [run_pretraining.py:  534]:	loss/total_loss, 7.295706272125244, 2434
[INFO] 2021-07-12 19:21:08,922 [run_pretraining.py:  535]:	loss/mlm_loss, 7.295706272125244, 2434
[INFO] 2021-07-12 19:21:08,922 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4330000087502412e-05, 2434
[INFO] 2021-07-12 19:21:08,922 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2434
[INFO] 2021-07-12 19:21:08,923 [run_pretraining.py:  558]:	worker_index: 6, step: 2434, cost: 7.295706, mlm loss: 7.295706, speed: 1.099350 steps/s, speed: 8.794798 samples/s, speed: 4502.936546 tokens/s, learning rate: 2.433e-05, loss_scalings: 2814.750488, pp_loss: 7.083980
[INFO] 2021-07-12 19:21:08,923 [run_pretraining.py:  512]:	********exe.run_2434******* 
[INFO] 2021-07-12 19:21:09,825 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:09,826 [run_pretraining.py:  534]:	loss/total_loss, 6.882434368133545, 2435
[INFO] 2021-07-12 19:21:09,826 [run_pretraining.py:  535]:	loss/mlm_loss, 6.882434368133545, 2435
[INFO] 2021-07-12 19:21:09,826 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4339999072253704e-05, 2435
[INFO] 2021-07-12 19:21:09,826 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2435
[INFO] 2021-07-12 19:21:09,826 [run_pretraining.py:  558]:	worker_index: 6, step: 2435, cost: 6.882434, mlm loss: 6.882434, speed: 1.107318 steps/s, speed: 8.858547 samples/s, speed: 4535.576212 tokens/s, learning rate: 2.434e-05, loss_scalings: 2814.750488, pp_loss: 7.203629
[INFO] 2021-07-12 19:21:09,826 [run_pretraining.py:  512]:	********exe.run_2435******* 
[INFO] 2021-07-12 19:21:10,742 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:10,743 [run_pretraining.py:  534]:	loss/total_loss, 6.183769226074219, 2436
[INFO] 2021-07-12 19:21:10,743 [run_pretraining.py:  535]:	loss/mlm_loss, 6.183769226074219, 2436
[INFO] 2021-07-12 19:21:10,743 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4349998057004996e-05, 2436
[INFO] 2021-07-12 19:21:10,743 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2436
[INFO] 2021-07-12 19:21:10,743 [run_pretraining.py:  558]:	worker_index: 6, step: 2436, cost: 6.183769, mlm loss: 6.183769, speed: 1.091846 steps/s, speed: 8.734767 samples/s, speed: 4472.200606 tokens/s, learning rate: 2.435e-05, loss_scalings: 2814.750488, pp_loss: 6.822851
[INFO] 2021-07-12 19:21:10,743 [run_pretraining.py:  512]:	********exe.run_2436******* 
[INFO] 2021-07-12 19:21:11,653 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:11,653 [run_pretraining.py:  534]:	loss/total_loss, 7.364628314971924, 2437
[INFO] 2021-07-12 19:21:11,654 [run_pretraining.py:  535]:	loss/mlm_loss, 7.364628314971924, 2437
[INFO] 2021-07-12 19:21:11,654 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.435999886074569e-05, 2437
[INFO] 2021-07-12 19:21:11,654 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2437
[INFO] 2021-07-12 19:21:11,654 [run_pretraining.py:  558]:	worker_index: 6, step: 2437, cost: 7.364628, mlm loss: 7.364628, speed: 1.098678 steps/s, speed: 8.789428 samples/s, speed: 4500.187077 tokens/s, learning rate: 2.436e-05, loss_scalings: 2814.750488, pp_loss: 7.147123
[INFO] 2021-07-12 19:21:11,654 [run_pretraining.py:  512]:	********exe.run_2437******* 
[INFO] 2021-07-12 19:21:12,562 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:12,563 [run_pretraining.py:  534]:	loss/total_loss, 7.404869079589844, 2438
[INFO] 2021-07-12 19:21:12,563 [run_pretraining.py:  535]:	loss/mlm_loss, 7.404869079589844, 2438
[INFO] 2021-07-12 19:21:12,563 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4369999664486386e-05, 2438
[INFO] 2021-07-12 19:21:12,563 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2438
[INFO] 2021-07-12 19:21:12,563 [run_pretraining.py:  558]:	worker_index: 6, step: 2438, cost: 7.404869, mlm loss: 7.404869, speed: 1.100798 steps/s, speed: 8.806387 samples/s, speed: 4508.870360 tokens/s, learning rate: 2.437e-05, loss_scalings: 2814.750488, pp_loss: 6.845193
[INFO] 2021-07-12 19:21:12,563 [run_pretraining.py:  512]:	********exe.run_2438******* 
[INFO] 2021-07-12 19:21:13,465 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:13,466 [run_pretraining.py:  534]:	loss/total_loss, 7.781764984130859, 2439
[INFO] 2021-07-12 19:21:13,466 [run_pretraining.py:  535]:	loss/mlm_loss, 7.781764984130859, 2439
[INFO] 2021-07-12 19:21:13,466 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4379998649237677e-05, 2439
[INFO] 2021-07-12 19:21:13,466 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2439
[INFO] 2021-07-12 19:21:13,466 [run_pretraining.py:  558]:	worker_index: 6, step: 2439, cost: 7.781765, mlm loss: 7.781765, speed: 1.107963 steps/s, speed: 8.863700 samples/s, speed: 4538.214456 tokens/s, learning rate: 2.438e-05, loss_scalings: 2814.750488, pp_loss: 7.407381
[INFO] 2021-07-12 19:21:13,466 [run_pretraining.py:  512]:	********exe.run_2439******* 
[INFO] 2021-07-12 19:21:14,380 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:14,381 [run_pretraining.py:  534]:	loss/total_loss, 7.1204729080200195, 2440
[INFO] 2021-07-12 19:21:14,381 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1204729080200195, 2440
[INFO] 2021-07-12 19:21:14,381 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4389999452978373e-05, 2440
[INFO] 2021-07-12 19:21:14,381 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2440
[INFO] 2021-07-12 19:21:14,381 [run_pretraining.py:  558]:	worker_index: 6, step: 2440, cost: 7.120473, mlm loss: 7.120473, speed: 1.093399 steps/s, speed: 8.747190 samples/s, speed: 4478.561444 tokens/s, learning rate: 2.439e-05, loss_scalings: 2814.750488, pp_loss: 7.170021
[INFO] 2021-07-12 19:21:14,382 [run_pretraining.py:  512]:	********exe.run_2440******* 
[INFO] 2021-07-12 19:21:15,292 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:15,293 [run_pretraining.py:  534]:	loss/total_loss, 5.820528507232666, 2441
[INFO] 2021-07-12 19:21:15,293 [run_pretraining.py:  535]:	loss/mlm_loss, 5.820528507232666, 2441
[INFO] 2021-07-12 19:21:15,293 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4400000256719068e-05, 2441
[INFO] 2021-07-12 19:21:15,293 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2441
[INFO] 2021-07-12 19:21:15,293 [run_pretraining.py:  558]:	worker_index: 6, step: 2441, cost: 5.820529, mlm loss: 5.820529, speed: 1.097544 steps/s, speed: 8.780350 samples/s, speed: 4495.539147 tokens/s, learning rate: 2.440e-05, loss_scalings: 2814.750488, pp_loss: 6.954684
[INFO] 2021-07-12 19:21:15,293 [run_pretraining.py:  512]:	********exe.run_2441******* 
[INFO] 2021-07-12 19:21:16,231 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:16,232 [run_pretraining.py:  534]:	loss/total_loss, 4.5200886726379395, 2442
[INFO] 2021-07-12 19:21:16,232 [run_pretraining.py:  535]:	loss/mlm_loss, 4.5200886726379395, 2442
[INFO] 2021-07-12 19:21:16,232 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.440999924147036e-05, 2442
[INFO] 2021-07-12 19:21:16,232 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2442
[INFO] 2021-07-12 19:21:16,232 [run_pretraining.py:  558]:	worker_index: 6, step: 2442, cost: 4.520089, mlm loss: 4.520089, speed: 1.066088 steps/s, speed: 8.528703 samples/s, speed: 4366.695732 tokens/s, learning rate: 2.441e-05, loss_scalings: 2814.750488, pp_loss: 6.889215
[INFO] 2021-07-12 19:21:16,232 [run_pretraining.py:  512]:	********exe.run_2442******* 
[INFO] 2021-07-12 19:21:17,153 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:17,153 [run_pretraining.py:  534]:	loss/total_loss, 7.72714900970459, 2443
[INFO] 2021-07-12 19:21:17,153 [run_pretraining.py:  535]:	loss/mlm_loss, 7.72714900970459, 2443
[INFO] 2021-07-12 19:21:17,153 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4420000045211054e-05, 2443
[INFO] 2021-07-12 19:21:17,154 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2443
[INFO] 2021-07-12 19:21:17,154 [run_pretraining.py:  558]:	worker_index: 6, step: 2443, cost: 7.727149, mlm loss: 7.727149, speed: 1.085847 steps/s, speed: 8.686777 samples/s, speed: 4447.629971 tokens/s, learning rate: 2.442e-05, loss_scalings: 2814.750488, pp_loss: 7.068293
[INFO] 2021-07-12 19:21:17,154 [run_pretraining.py:  512]:	********exe.run_2443******* 
[INFO] 2021-07-12 19:21:18,065 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:18,066 [run_pretraining.py:  534]:	loss/total_loss, 7.6997528076171875, 2444
[INFO] 2021-07-12 19:21:18,066 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6997528076171875, 2444
[INFO] 2021-07-12 19:21:18,066 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4429999029962346e-05, 2444
[INFO] 2021-07-12 19:21:18,066 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2444
[INFO] 2021-07-12 19:21:18,066 [run_pretraining.py:  558]:	worker_index: 6, step: 2444, cost: 7.699753, mlm loss: 7.699753, speed: 1.096844 steps/s, speed: 8.774750 samples/s, speed: 4492.671812 tokens/s, learning rate: 2.443e-05, loss_scalings: 2814.750488, pp_loss: 7.075324
[INFO] 2021-07-12 19:21:18,066 [run_pretraining.py:  512]:	********exe.run_2444******* 
[INFO] 2021-07-12 19:21:42,688 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:42,689 [run_pretraining.py:  534]:	loss/total_loss, 7.902626991271973, 2445
[INFO] 2021-07-12 19:21:42,689 [run_pretraining.py:  535]:	loss/mlm_loss, 7.902626991271973, 2445
[INFO] 2021-07-12 19:21:42,689 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4439998014713638e-05, 2445
[INFO] 2021-07-12 19:21:42,689 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2445
[INFO] 2021-07-12 19:21:42,689 [run_pretraining.py:  558]:	worker_index: 6, step: 2445, cost: 7.902627, mlm loss: 7.902627, speed: 0.040613 steps/s, speed: 0.324906 samples/s, speed: 166.351831 tokens/s, learning rate: 2.444e-05, loss_scalings: 2814.750488, pp_loss: 7.670107
[INFO] 2021-07-12 19:21:42,689 [run_pretraining.py:  512]:	********exe.run_2445******* 
[INFO] 2021-07-12 19:21:43,607 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:43,607 [run_pretraining.py:  534]:	loss/total_loss, 8.018925666809082, 2446
[INFO] 2021-07-12 19:21:43,607 [run_pretraining.py:  535]:	loss/mlm_loss, 8.018925666809082, 2446
[INFO] 2021-07-12 19:21:43,607 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4449998818454333e-05, 2446
[INFO] 2021-07-12 19:21:43,608 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2446
[INFO] 2021-07-12 19:21:43,608 [run_pretraining.py:  558]:	worker_index: 6, step: 2446, cost: 8.018926, mlm loss: 8.018926, speed: 1.089893 steps/s, speed: 8.719142 samples/s, speed: 4464.200680 tokens/s, learning rate: 2.445e-05, loss_scalings: 2814.750488, pp_loss: 7.667114
[INFO] 2021-07-12 19:21:43,608 [run_pretraining.py:  512]:	********exe.run_2446******* 
[INFO] 2021-07-12 19:21:44,522 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:44,522 [run_pretraining.py:  534]:	loss/total_loss, 7.371715545654297, 2447
[INFO] 2021-07-12 19:21:44,523 [run_pretraining.py:  535]:	loss/mlm_loss, 7.371715545654297, 2447
[INFO] 2021-07-12 19:21:44,523 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4459999622195028e-05, 2447
[INFO] 2021-07-12 19:21:44,523 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2447
[INFO] 2021-07-12 19:21:44,523 [run_pretraining.py:  558]:	worker_index: 6, step: 2447, cost: 7.371716, mlm loss: 7.371716, speed: 1.093407 steps/s, speed: 8.747256 samples/s, speed: 4478.595302 tokens/s, learning rate: 2.446e-05, loss_scalings: 2814.750488, pp_loss: 6.926582
[INFO] 2021-07-12 19:21:44,523 [run_pretraining.py:  512]:	********exe.run_2447******* 
[INFO] 2021-07-12 19:21:45,443 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:45,444 [run_pretraining.py:  534]:	loss/total_loss, 7.480460166931152, 2448
[INFO] 2021-07-12 19:21:45,444 [run_pretraining.py:  535]:	loss/mlm_loss, 7.480460166931152, 2448
[INFO] 2021-07-12 19:21:45,444 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.446999860694632e-05, 2448
[INFO] 2021-07-12 19:21:45,444 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2448
[INFO] 2021-07-12 19:21:45,444 [run_pretraining.py:  558]:	worker_index: 6, step: 2448, cost: 7.480460, mlm loss: 7.480460, speed: 1.085960 steps/s, speed: 8.687679 samples/s, speed: 4448.091742 tokens/s, learning rate: 2.447e-05, loss_scalings: 2814.750488, pp_loss: 7.253951
[INFO] 2021-07-12 19:21:45,444 [run_pretraining.py:  512]:	********exe.run_2448******* 
[INFO] 2021-07-12 19:21:46,361 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:46,362 [run_pretraining.py:  534]:	loss/total_loss, 6.34226655960083, 2449
[INFO] 2021-07-12 19:21:46,362 [run_pretraining.py:  535]:	loss/mlm_loss, 6.34226655960083, 2449
[INFO] 2021-07-12 19:21:46,362 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4479999410687014e-05, 2449
[INFO] 2021-07-12 19:21:46,362 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2449
[INFO] 2021-07-12 19:21:46,362 [run_pretraining.py:  558]:	worker_index: 6, step: 2449, cost: 6.342267, mlm loss: 6.342267, speed: 1.090266 steps/s, speed: 8.722125 samples/s, speed: 4465.727795 tokens/s, learning rate: 2.448e-05, loss_scalings: 2814.750488, pp_loss: 7.007038
[INFO] 2021-07-12 19:21:46,362 [run_pretraining.py:  512]:	********exe.run_2449******* 
[INFO] 2021-07-12 19:21:47,279 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:47,280 [run_pretraining.py:  534]:	loss/total_loss, 7.6929168701171875, 2450
[INFO] 2021-07-12 19:21:47,280 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6929168701171875, 2450
[INFO] 2021-07-12 19:21:47,280 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.449000021442771e-05, 2450
[INFO] 2021-07-12 19:21:47,280 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2450
[INFO] 2021-07-12 19:21:47,280 [run_pretraining.py:  558]:	worker_index: 6, step: 2450, cost: 7.692917, mlm loss: 7.692917, speed: 1.090533 steps/s, speed: 8.724268 samples/s, speed: 4466.825039 tokens/s, learning rate: 2.449e-05, loss_scalings: 2814.750488, pp_loss: 7.380397
[INFO] 2021-07-12 19:21:47,280 [run_pretraining.py:  512]:	********exe.run_2450******* 
[INFO] 2021-07-12 19:21:48,200 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:48,200 [run_pretraining.py:  534]:	loss/total_loss, 7.419268608093262, 2451
[INFO] 2021-07-12 19:21:48,200 [run_pretraining.py:  535]:	loss/mlm_loss, 7.419268608093262, 2451
[INFO] 2021-07-12 19:21:48,201 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4499999199179e-05, 2451
[INFO] 2021-07-12 19:21:48,201 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2451
[INFO] 2021-07-12 19:21:48,201 [run_pretraining.py:  558]:	worker_index: 6, step: 2451, cost: 7.419269, mlm loss: 7.419269, speed: 1.086989 steps/s, speed: 8.695913 samples/s, speed: 4452.307387 tokens/s, learning rate: 2.450e-05, loss_scalings: 2814.750488, pp_loss: 7.391389
[INFO] 2021-07-12 19:21:48,201 [run_pretraining.py:  512]:	********exe.run_2451******* 
[INFO] 2021-07-12 19:21:49,123 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:49,123 [run_pretraining.py:  534]:	loss/total_loss, 7.601183891296387, 2452
[INFO] 2021-07-12 19:21:49,123 [run_pretraining.py:  535]:	loss/mlm_loss, 7.601183891296387, 2452
[INFO] 2021-07-12 19:21:49,124 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4510000002919696e-05, 2452
[INFO] 2021-07-12 19:21:49,124 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2452
[INFO] 2021-07-12 19:21:49,124 [run_pretraining.py:  558]:	worker_index: 6, step: 2452, cost: 7.601184, mlm loss: 7.601184, speed: 1.084255 steps/s, speed: 8.674038 samples/s, speed: 4441.107489 tokens/s, learning rate: 2.451e-05, loss_scalings: 2814.750488, pp_loss: 7.520959
[INFO] 2021-07-12 19:21:49,124 [run_pretraining.py:  512]:	********exe.run_2452******* 
[INFO] 2021-07-12 19:21:50,039 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:50,040 [run_pretraining.py:  534]:	loss/total_loss, 7.168000221252441, 2453
[INFO] 2021-07-12 19:21:50,040 [run_pretraining.py:  535]:	loss/mlm_loss, 7.168000221252441, 2453
[INFO] 2021-07-12 19:21:50,040 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4519998987670988e-05, 2453
[INFO] 2021-07-12 19:21:50,040 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2453
[INFO] 2021-07-12 19:21:50,040 [run_pretraining.py:  558]:	worker_index: 6, step: 2453, cost: 7.168000, mlm loss: 7.168000, speed: 1.092246 steps/s, speed: 8.737965 samples/s, speed: 4473.838052 tokens/s, learning rate: 2.452e-05, loss_scalings: 2814.750488, pp_loss: 7.178079
[INFO] 2021-07-12 19:21:50,040 [run_pretraining.py:  512]:	********exe.run_2453******* 
[INFO] 2021-07-12 19:21:50,963 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:50,964 [run_pretraining.py:  534]:	loss/total_loss, 7.353847980499268, 2454
[INFO] 2021-07-12 19:21:50,964 [run_pretraining.py:  535]:	loss/mlm_loss, 7.353847980499268, 2454
[INFO] 2021-07-12 19:21:50,964 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.452999797242228e-05, 2454
[INFO] 2021-07-12 19:21:50,964 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2454
[INFO] 2021-07-12 19:21:50,964 [run_pretraining.py:  558]:	worker_index: 6, step: 2454, cost: 7.353848, mlm loss: 7.353848, speed: 1.082962 steps/s, speed: 8.663698 samples/s, speed: 4435.813238 tokens/s, learning rate: 2.453e-05, loss_scalings: 2814.750488, pp_loss: 7.138998
[INFO] 2021-07-12 19:21:50,964 [run_pretraining.py:  512]:	********exe.run_2454******* 
[INFO] 2021-07-12 19:21:51,889 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:51,889 [run_pretraining.py:  534]:	loss/total_loss, 7.252349376678467, 2455
[INFO] 2021-07-12 19:21:51,890 [run_pretraining.py:  535]:	loss/mlm_loss, 7.252349376678467, 2455
[INFO] 2021-07-12 19:21:51,890 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4539998776162975e-05, 2455
[INFO] 2021-07-12 19:21:51,890 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2455
[INFO] 2021-07-12 19:21:51,890 [run_pretraining.py:  558]:	worker_index: 6, step: 2455, cost: 7.252349, mlm loss: 7.252349, speed: 1.080947 steps/s, speed: 8.647575 samples/s, speed: 4427.558277 tokens/s, learning rate: 2.454e-05, loss_scalings: 2814.750488, pp_loss: 7.162910
[INFO] 2021-07-12 19:21:51,890 [run_pretraining.py:  512]:	********exe.run_2455******* 
[INFO] 2021-07-12 19:21:52,807 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:52,807 [run_pretraining.py:  534]:	loss/total_loss, 7.299402713775635, 2456
[INFO] 2021-07-12 19:21:52,808 [run_pretraining.py:  535]:	loss/mlm_loss, 7.299402713775635, 2456
[INFO] 2021-07-12 19:21:52,808 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.454999957990367e-05, 2456
[INFO] 2021-07-12 19:21:52,808 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2456
[INFO] 2021-07-12 19:21:52,808 [run_pretraining.py:  558]:	worker_index: 6, step: 2456, cost: 7.299403, mlm loss: 7.299403, speed: 1.090276 steps/s, speed: 8.722211 samples/s, speed: 4465.771907 tokens/s, learning rate: 2.455e-05, loss_scalings: 2814.750488, pp_loss: 7.494706
[INFO] 2021-07-12 19:21:52,808 [run_pretraining.py:  512]:	********exe.run_2456******* 
[INFO] 2021-07-12 19:21:53,757 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:53,758 [run_pretraining.py:  534]:	loss/total_loss, 7.0513081550598145, 2457
[INFO] 2021-07-12 19:21:53,758 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0513081550598145, 2457
[INFO] 2021-07-12 19:21:53,758 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.455999856465496e-05, 2457
[INFO] 2021-07-12 19:21:53,758 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2457
[INFO] 2021-07-12 19:21:53,758 [run_pretraining.py:  558]:	worker_index: 6, step: 2457, cost: 7.051308, mlm loss: 7.051308, speed: 1.053024 steps/s, speed: 8.424194 samples/s, speed: 4313.187277 tokens/s, learning rate: 2.456e-05, loss_scalings: 2814.750488, pp_loss: 7.086522
[INFO] 2021-07-12 19:21:53,758 [run_pretraining.py:  512]:	********exe.run_2457******* 
[INFO] 2021-07-12 19:21:54,682 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:54,683 [run_pretraining.py:  534]:	loss/total_loss, 7.097082614898682, 2458
[INFO] 2021-07-12 19:21:54,683 [run_pretraining.py:  535]:	loss/mlm_loss, 7.097082614898682, 2458
[INFO] 2021-07-12 19:21:54,683 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4569999368395656e-05, 2458
[INFO] 2021-07-12 19:21:54,683 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2458
[INFO] 2021-07-12 19:21:54,683 [run_pretraining.py:  558]:	worker_index: 6, step: 2458, cost: 7.097083, mlm loss: 7.097083, speed: 1.082041 steps/s, speed: 8.656329 samples/s, speed: 4432.040331 tokens/s, learning rate: 2.457e-05, loss_scalings: 2814.750488, pp_loss: 7.245012
[INFO] 2021-07-12 19:21:54,683 [run_pretraining.py:  512]:	********exe.run_2458******* 
[INFO] 2021-07-12 19:21:55,607 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:55,608 [run_pretraining.py:  534]:	loss/total_loss, 6.8665313720703125, 2459
[INFO] 2021-07-12 19:21:55,608 [run_pretraining.py:  535]:	loss/mlm_loss, 6.8665313720703125, 2459
[INFO] 2021-07-12 19:21:55,608 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.458000017213635e-05, 2459
[INFO] 2021-07-12 19:21:55,608 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2459
[INFO] 2021-07-12 19:21:55,608 [run_pretraining.py:  558]:	worker_index: 6, step: 2459, cost: 6.866531, mlm loss: 6.866531, speed: 1.081813 steps/s, speed: 8.654505 samples/s, speed: 4431.106393 tokens/s, learning rate: 2.458e-05, loss_scalings: 2814.750488, pp_loss: 7.126272
[INFO] 2021-07-12 19:21:55,608 [run_pretraining.py:  512]:	********exe.run_2459******* 
[INFO] 2021-07-12 19:21:56,523 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:56,524 [run_pretraining.py:  534]:	loss/total_loss, 6.313875198364258, 2460
[INFO] 2021-07-12 19:21:56,524 [run_pretraining.py:  535]:	loss/mlm_loss, 6.313875198364258, 2460
[INFO] 2021-07-12 19:21:56,524 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4589999156887643e-05, 2460
[INFO] 2021-07-12 19:21:56,524 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2460
[INFO] 2021-07-12 19:21:56,524 [run_pretraining.py:  558]:	worker_index: 6, step: 2460, cost: 6.313875, mlm loss: 6.313875, speed: 1.092595 steps/s, speed: 8.740758 samples/s, speed: 4475.268013 tokens/s, learning rate: 2.459e-05, loss_scalings: 2814.750488, pp_loss: 7.065842
[INFO] 2021-07-12 19:21:56,524 [run_pretraining.py:  512]:	********exe.run_2460******* 
[INFO] 2021-07-12 19:21:57,447 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:57,453 [run_pretraining.py:  534]:	loss/total_loss, 7.375174045562744, 2461
[INFO] 2021-07-12 19:21:57,458 [run_pretraining.py:  535]:	loss/mlm_loss, 7.375174045562744, 2461
[INFO] 2021-07-12 19:21:57,466 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4599999960628338e-05, 2461
[INFO] 2021-07-12 19:21:57,467 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2461
[INFO] 2021-07-12 19:21:57,467 [run_pretraining.py:  558]:	worker_index: 6, step: 2461, cost: 7.375174, mlm loss: 7.375174, speed: 1.076982 steps/s, speed: 8.615858 samples/s, speed: 4411.319147 tokens/s, learning rate: 2.460e-05, loss_scalings: 2814.750488, pp_loss: 7.213364
[INFO] 2021-07-12 19:21:57,468 [run_pretraining.py:  512]:	********exe.run_2461******* 
[INFO] 2021-07-12 19:21:58,344 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:58,345 [run_pretraining.py:  534]:	loss/total_loss, 6.6374616622924805, 2462
[INFO] 2021-07-12 19:21:58,345 [run_pretraining.py:  535]:	loss/mlm_loss, 6.6374616622924805, 2462
[INFO] 2021-07-12 19:21:58,345 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.460999894537963e-05, 2462
[INFO] 2021-07-12 19:21:58,345 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2462
[INFO] 2021-07-12 19:21:58,345 [run_pretraining.py:  558]:	worker_index: 6, step: 2462, cost: 6.637462, mlm loss: 6.637462, speed: 1.140753 steps/s, speed: 9.126020 samples/s, speed: 4672.522282 tokens/s, learning rate: 2.461e-05, loss_scalings: 2814.750488, pp_loss: 7.002987
[INFO] 2021-07-12 19:21:58,345 [run_pretraining.py:  512]:	********exe.run_2462******* 
[INFO] 2021-07-12 19:21:59,265 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:59,265 [run_pretraining.py:  534]:	loss/total_loss, 7.537888526916504, 2463
[INFO] 2021-07-12 19:21:59,265 [run_pretraining.py:  535]:	loss/mlm_loss, 7.537888526916504, 2463
[INFO] 2021-07-12 19:21:59,266 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4619999749120325e-05, 2463
[INFO] 2021-07-12 19:21:59,266 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2463
[INFO] 2021-07-12 19:21:59,266 [run_pretraining.py:  558]:	worker_index: 6, step: 2463, cost: 7.537889, mlm loss: 7.537889, speed: 1.087437 steps/s, speed: 8.699498 samples/s, speed: 4454.142769 tokens/s, learning rate: 2.462e-05, loss_scalings: 2814.750488, pp_loss: 7.255814
[INFO] 2021-07-12 19:21:59,266 [run_pretraining.py:  512]:	********exe.run_2463******* 
[INFO] 2021-07-12 19:22:00,179 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:00,179 [run_pretraining.py:  534]:	loss/total_loss, 7.616074562072754, 2464
[INFO] 2021-07-12 19:22:00,179 [run_pretraining.py:  535]:	loss/mlm_loss, 7.616074562072754, 2464
[INFO] 2021-07-12 19:22:00,180 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4629998733871616e-05, 2464
[INFO] 2021-07-12 19:22:00,180 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2464
[INFO] 2021-07-12 19:22:00,180 [run_pretraining.py:  558]:	worker_index: 6, step: 2464, cost: 7.616075, mlm loss: 7.616075, speed: 1.094850 steps/s, speed: 8.758803 samples/s, speed: 4484.507237 tokens/s, learning rate: 2.463e-05, loss_scalings: 2814.750488, pp_loss: 7.525534
[INFO] 2021-07-12 19:22:00,180 [run_pretraining.py:  512]:	********exe.run_2464******* 
[INFO] 2021-07-12 19:22:01,096 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:01,097 [run_pretraining.py:  534]:	loss/total_loss, 7.496543884277344, 2465
[INFO] 2021-07-12 19:22:01,097 [run_pretraining.py:  535]:	loss/mlm_loss, 7.496543884277344, 2465
[INFO] 2021-07-12 19:22:01,097 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.463999953761231e-05, 2465
[INFO] 2021-07-12 19:22:01,097 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2465
[INFO] 2021-07-12 19:22:01,097 [run_pretraining.py:  558]:	worker_index: 6, step: 2465, cost: 7.496544, mlm loss: 7.496544, speed: 1.090932 steps/s, speed: 8.727456 samples/s, speed: 4468.457388 tokens/s, learning rate: 2.464e-05, loss_scalings: 2814.750488, pp_loss: 7.215425
[INFO] 2021-07-12 19:22:01,097 [run_pretraining.py:  512]:	********exe.run_2465******* 
[INFO] 2021-07-12 19:22:02,009 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:02,010 [run_pretraining.py:  534]:	loss/total_loss, 4.045638084411621, 2466
[INFO] 2021-07-12 19:22:02,010 [run_pretraining.py:  535]:	loss/mlm_loss, 4.045638084411621, 2466
[INFO] 2021-07-12 19:22:02,010 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4649998522363603e-05, 2466
[INFO] 2021-07-12 19:22:02,010 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2466
[INFO] 2021-07-12 19:22:02,010 [run_pretraining.py:  558]:	worker_index: 6, step: 2466, cost: 4.045638, mlm loss: 4.045638, speed: 1.096210 steps/s, speed: 8.769677 samples/s, speed: 4490.074503 tokens/s, learning rate: 2.465e-05, loss_scalings: 2814.750488, pp_loss: 6.195541
[INFO] 2021-07-12 19:22:02,010 [run_pretraining.py:  512]:	********exe.run_2466******* 
[INFO] 2021-07-12 19:22:02,928 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:02,928 [run_pretraining.py:  534]:	loss/total_loss, 6.984469890594482, 2467
[INFO] 2021-07-12 19:22:02,928 [run_pretraining.py:  535]:	loss/mlm_loss, 6.984469890594482, 2467
[INFO] 2021-07-12 19:22:02,928 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4659999326104298e-05, 2467
[INFO] 2021-07-12 19:22:02,928 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2467
[INFO] 2021-07-12 19:22:02,929 [run_pretraining.py:  558]:	worker_index: 6, step: 2467, cost: 6.984470, mlm loss: 6.984470, speed: 1.089625 steps/s, speed: 8.716999 samples/s, speed: 4463.103565 tokens/s, learning rate: 2.466e-05, loss_scalings: 2814.750488, pp_loss: 7.117359
[INFO] 2021-07-12 19:22:02,929 [run_pretraining.py:  512]:	********exe.run_2467******* 
[INFO] 2021-07-12 19:22:03,848 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:03,849 [run_pretraining.py:  534]:	loss/total_loss, 7.8818769454956055, 2468
[INFO] 2021-07-12 19:22:03,849 [run_pretraining.py:  535]:	loss/mlm_loss, 7.8818769454956055, 2468
[INFO] 2021-07-12 19:22:03,849 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4670000129844993e-05, 2468
[INFO] 2021-07-12 19:22:03,849 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2468
[INFO] 2021-07-12 19:22:03,849 [run_pretraining.py:  558]:	worker_index: 6, step: 2468, cost: 7.881877, mlm loss: 7.881877, speed: 1.086942 steps/s, speed: 8.695534 samples/s, speed: 4452.113548 tokens/s, learning rate: 2.467e-05, loss_scalings: 2814.750488, pp_loss: 7.270335
[INFO] 2021-07-12 19:22:03,849 [run_pretraining.py:  512]:	********exe.run_2468******* 
[INFO] 2021-07-12 19:22:04,760 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:04,760 [run_pretraining.py:  534]:	loss/total_loss, 7.193299770355225, 2469
[INFO] 2021-07-12 19:22:04,760 [run_pretraining.py:  535]:	loss/mlm_loss, 7.193299770355225, 2469
[INFO] 2021-07-12 19:22:04,761 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4679999114596285e-05, 2469
[INFO] 2021-07-12 19:22:04,761 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2469
[INFO] 2021-07-12 19:22:04,761 [run_pretraining.py:  558]:	worker_index: 6, step: 2469, cost: 7.193300, mlm loss: 7.193300, speed: 1.097878 steps/s, speed: 8.783023 samples/s, speed: 4496.907681 tokens/s, learning rate: 2.468e-05, loss_scalings: 2814.750488, pp_loss: 7.173209
[INFO] 2021-07-12 19:22:04,761 [run_pretraining.py:  512]:	********exe.run_2469******* 
[INFO] 2021-07-12 19:22:05,684 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:05,684 [run_pretraining.py:  534]:	loss/total_loss, 8.018516540527344, 2470
[INFO] 2021-07-12 19:22:05,684 [run_pretraining.py:  535]:	loss/mlm_loss, 8.018516540527344, 2470
[INFO] 2021-07-12 19:22:05,684 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.468999991833698e-05, 2470
[INFO] 2021-07-12 19:22:05,685 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2470
[INFO] 2021-07-12 19:22:05,685 [run_pretraining.py:  558]:	worker_index: 6, step: 2470, cost: 8.018517, mlm loss: 8.018517, speed: 1.083203 steps/s, speed: 8.665624 samples/s, speed: 4436.799577 tokens/s, learning rate: 2.469e-05, loss_scalings: 2814.750488, pp_loss: 7.540087
[INFO] 2021-07-12 19:22:05,685 [run_pretraining.py:  512]:	********exe.run_2470******* 
[INFO] 2021-07-12 19:22:06,595 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:06,595 [run_pretraining.py:  534]:	loss/total_loss, 7.236140251159668, 2471
[INFO] 2021-07-12 19:22:06,595 [run_pretraining.py:  535]:	loss/mlm_loss, 7.236140251159668, 2471
[INFO] 2021-07-12 19:22:06,595 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.469999890308827e-05, 2471
[INFO] 2021-07-12 19:22:06,595 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2471
[INFO] 2021-07-12 19:22:06,596 [run_pretraining.py:  558]:	worker_index: 6, step: 2471, cost: 7.236140, mlm loss: 7.236140, speed: 1.098722 steps/s, speed: 8.789778 samples/s, speed: 4500.366262 tokens/s, learning rate: 2.470e-05, loss_scalings: 2814.750488, pp_loss: 7.212959
[INFO] 2021-07-12 19:22:06,596 [run_pretraining.py:  512]:	********exe.run_2471******* 
[INFO] 2021-07-12 19:22:07,504 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:07,505 [run_pretraining.py:  534]:	loss/total_loss, 6.935910224914551, 2472
[INFO] 2021-07-12 19:22:07,505 [run_pretraining.py:  535]:	loss/mlm_loss, 6.935910224914551, 2472
[INFO] 2021-07-12 19:22:07,505 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4709999706828967e-05, 2472
[INFO] 2021-07-12 19:22:07,505 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2472
[INFO] 2021-07-12 19:22:07,505 [run_pretraining.py:  558]:	worker_index: 6, step: 2472, cost: 6.935910, mlm loss: 6.935910, speed: 1.100328 steps/s, speed: 8.802624 samples/s, speed: 4506.943496 tokens/s, learning rate: 2.471e-05, loss_scalings: 2814.750488, pp_loss: 7.081983
[INFO] 2021-07-12 19:22:07,505 [run_pretraining.py:  512]:	********exe.run_2472******* 
[INFO] 2021-07-12 19:22:08,423 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:08,424 [run_pretraining.py:  534]:	loss/total_loss, 7.428778648376465, 2473
[INFO] 2021-07-12 19:22:08,424 [run_pretraining.py:  535]:	loss/mlm_loss, 7.428778648376465, 2473
[INFO] 2021-07-12 19:22:08,424 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.471999869158026e-05, 2473
[INFO] 2021-07-12 19:22:08,424 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2473
[INFO] 2021-07-12 19:22:08,424 [run_pretraining.py:  558]:	worker_index: 6, step: 2473, cost: 7.428779, mlm loss: 7.428779, speed: 1.088573 steps/s, speed: 8.708583 samples/s, speed: 4458.794555 tokens/s, learning rate: 2.472e-05, loss_scalings: 2814.750488, pp_loss: 6.453729
[INFO] 2021-07-12 19:22:08,424 [run_pretraining.py:  512]:	********exe.run_2473******* 
[INFO] 2021-07-12 19:22:09,343 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:09,343 [run_pretraining.py:  534]:	loss/total_loss, 7.410251617431641, 2474
[INFO] 2021-07-12 19:22:09,343 [run_pretraining.py:  535]:	loss/mlm_loss, 7.410251617431641, 2474
[INFO] 2021-07-12 19:22:09,343 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4729999495320953e-05, 2474
[INFO] 2021-07-12 19:22:09,344 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2474
[INFO] 2021-07-12 19:22:09,344 [run_pretraining.py:  558]:	worker_index: 6, step: 2474, cost: 7.410252, mlm loss: 7.410252, speed: 1.088703 steps/s, speed: 8.709625 samples/s, speed: 4459.328096 tokens/s, learning rate: 2.473e-05, loss_scalings: 2814.750488, pp_loss: 7.358584
[INFO] 2021-07-12 19:22:09,344 [run_pretraining.py:  512]:	********exe.run_2474******* 
[INFO] 2021-07-12 19:22:10,259 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:10,260 [run_pretraining.py:  534]:	loss/total_loss, 7.036706924438477, 2475
[INFO] 2021-07-12 19:22:10,260 [run_pretraining.py:  535]:	loss/mlm_loss, 7.036706924438477, 2475
[INFO] 2021-07-12 19:22:10,260 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.474000029906165e-05, 2475
[INFO] 2021-07-12 19:22:10,260 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2475
[INFO] 2021-07-12 19:22:10,260 [run_pretraining.py:  558]:	worker_index: 6, step: 2475, cost: 7.036707, mlm loss: 7.036707, speed: 1.092043 steps/s, speed: 8.736341 samples/s, speed: 4473.006368 tokens/s, learning rate: 2.474e-05, loss_scalings: 2814.750488, pp_loss: 7.326291
[INFO] 2021-07-12 19:22:10,260 [run_pretraining.py:  512]:	********exe.run_2475******* 
[INFO] 2021-07-12 19:22:11,168 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:11,169 [run_pretraining.py:  534]:	loss/total_loss, 6.654913902282715, 2476
[INFO] 2021-07-12 19:22:11,169 [run_pretraining.py:  535]:	loss/mlm_loss, 6.654913902282715, 2476
[INFO] 2021-07-12 19:22:11,169 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.474999928381294e-05, 2476
[INFO] 2021-07-12 19:22:11,169 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2476
[INFO] 2021-07-12 19:22:11,169 [run_pretraining.py:  558]:	worker_index: 6, step: 2476, cost: 6.654914, mlm loss: 6.654914, speed: 1.100704 steps/s, speed: 8.805629 samples/s, speed: 4508.482253 tokens/s, learning rate: 2.475e-05, loss_scalings: 2814.750488, pp_loss: 7.201571
[INFO] 2021-07-12 19:22:11,169 [run_pretraining.py:  512]:	********exe.run_2476******* 
[INFO] 2021-07-12 19:22:12,090 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:12,091 [run_pretraining.py:  534]:	loss/total_loss, 7.661540985107422, 2477
[INFO] 2021-07-12 19:22:12,091 [run_pretraining.py:  535]:	loss/mlm_loss, 7.661540985107422, 2477
[INFO] 2021-07-12 19:22:12,091 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4760000087553635e-05, 2477
[INFO] 2021-07-12 19:22:12,091 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2477
[INFO] 2021-07-12 19:22:12,091 [run_pretraining.py:  558]:	worker_index: 6, step: 2477, cost: 7.661541, mlm loss: 7.661541, speed: 1.085783 steps/s, speed: 8.686262 samples/s, speed: 4447.366309 tokens/s, learning rate: 2.476e-05, loss_scalings: 2814.750488, pp_loss: 7.385453
[INFO] 2021-07-12 19:22:12,091 [run_pretraining.py:  512]:	********exe.run_2477******* 
[INFO] 2021-07-12 19:22:13,011 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:13,012 [run_pretraining.py:  534]:	loss/total_loss, 7.541952610015869, 2478
[INFO] 2021-07-12 19:22:13,012 [run_pretraining.py:  535]:	loss/mlm_loss, 7.541952610015869, 2478
[INFO] 2021-07-12 19:22:13,012 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4769999072304927e-05, 2478
[INFO] 2021-07-12 19:22:13,012 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2478
[INFO] 2021-07-12 19:22:13,012 [run_pretraining.py:  558]:	worker_index: 6, step: 2478, cost: 7.541953, mlm loss: 7.541953, speed: 1.086763 steps/s, speed: 8.694106 samples/s, speed: 4451.382189 tokens/s, learning rate: 2.477e-05, loss_scalings: 2814.750488, pp_loss: 7.470079
[INFO] 2021-07-12 19:22:13,012 [run_pretraining.py:  512]:	********exe.run_2478******* 
[INFO] 2021-07-12 19:22:13,933 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:13,934 [run_pretraining.py:  534]:	loss/total_loss, 7.379609107971191, 2479
[INFO] 2021-07-12 19:22:13,934 [run_pretraining.py:  535]:	loss/mlm_loss, 7.379609107971191, 2479
[INFO] 2021-07-12 19:22:13,934 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.477999805705622e-05, 2479
[INFO] 2021-07-12 19:22:13,934 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2479
[INFO] 2021-07-12 19:22:13,934 [run_pretraining.py:  558]:	worker_index: 6, step: 2479, cost: 7.379609, mlm loss: 7.379609, speed: 1.084876 steps/s, speed: 8.679005 samples/s, speed: 4443.650739 tokens/s, learning rate: 2.478e-05, loss_scalings: 2814.750488, pp_loss: 7.272366
[INFO] 2021-07-12 19:22:13,934 [run_pretraining.py:  512]:	********exe.run_2479******* 
[INFO] 2021-07-12 19:22:14,844 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:14,844 [run_pretraining.py:  534]:	loss/total_loss, 7.581615924835205, 2480
[INFO] 2021-07-12 19:22:14,844 [run_pretraining.py:  535]:	loss/mlm_loss, 7.581615924835205, 2480
[INFO] 2021-07-12 19:22:14,844 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4789998860796914e-05, 2480
[INFO] 2021-07-12 19:22:14,845 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2480
[INFO] 2021-07-12 19:22:14,845 [run_pretraining.py:  558]:	worker_index: 6, step: 2480, cost: 7.581616, mlm loss: 7.581616, speed: 1.099467 steps/s, speed: 8.795734 samples/s, speed: 4503.415776 tokens/s, learning rate: 2.479e-05, loss_scalings: 2814.750488, pp_loss: 7.264583
[INFO] 2021-07-12 19:22:14,845 [run_pretraining.py:  512]:	********exe.run_2480******* 
[INFO] 2021-07-12 19:22:15,764 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:15,764 [run_pretraining.py:  534]:	loss/total_loss, 7.516046047210693, 2481
[INFO] 2021-07-12 19:22:15,764 [run_pretraining.py:  535]:	loss/mlm_loss, 7.516046047210693, 2481
[INFO] 2021-07-12 19:22:15,764 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.479999966453761e-05, 2481
[INFO] 2021-07-12 19:22:15,765 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2481
[INFO] 2021-07-12 19:22:15,765 [run_pretraining.py:  558]:	worker_index: 6, step: 2481, cost: 7.516046, mlm loss: 7.516046, speed: 1.087709 steps/s, speed: 8.701675 samples/s, speed: 4455.257434 tokens/s, learning rate: 2.480e-05, loss_scalings: 2814.750488, pp_loss: 7.484826
[INFO] 2021-07-12 19:22:15,765 [run_pretraining.py:  512]:	********exe.run_2481******* 
[INFO] 2021-07-12 19:22:16,684 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:16,684 [run_pretraining.py:  534]:	loss/total_loss, 7.250354766845703, 2482
[INFO] 2021-07-12 19:22:16,684 [run_pretraining.py:  535]:	loss/mlm_loss, 7.250354766845703, 2482
[INFO] 2021-07-12 19:22:16,684 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.48099986492889e-05, 2482
[INFO] 2021-07-12 19:22:16,684 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2482
[INFO] 2021-07-12 19:22:16,685 [run_pretraining.py:  558]:	worker_index: 6, step: 2482, cost: 7.250355, mlm loss: 7.250355, speed: 1.087986 steps/s, speed: 8.703884 samples/s, speed: 4456.388841 tokens/s, learning rate: 2.481e-05, loss_scalings: 2814.750488, pp_loss: 7.426449
[INFO] 2021-07-12 19:22:16,685 [run_pretraining.py:  512]:	********exe.run_2482******* 
[INFO] 2021-07-12 19:22:42,900 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:42,901 [run_pretraining.py:  534]:	loss/total_loss, 7.416568756103516, 2483
[INFO] 2021-07-12 19:22:42,901 [run_pretraining.py:  535]:	loss/mlm_loss, 7.416568756103516, 2483
[INFO] 2021-07-12 19:22:42,901 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4819999453029595e-05, 2483
[INFO] 2021-07-12 19:22:42,901 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2483
[INFO] 2021-07-12 19:22:42,901 [run_pretraining.py:  558]:	worker_index: 6, step: 2483, cost: 7.416569, mlm loss: 7.416569, speed: 0.038145 steps/s, speed: 0.305159 samples/s, speed: 156.241521 tokens/s, learning rate: 2.482e-05, loss_scalings: 2814.750488, pp_loss: 7.508493
[INFO] 2021-07-12 19:22:42,901 [run_pretraining.py:  512]:	********exe.run_2483******* 
[INFO] 2021-07-12 19:22:43,826 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:43,827 [run_pretraining.py:  534]:	loss/total_loss, 7.312252521514893, 2484
[INFO] 2021-07-12 19:22:43,827 [run_pretraining.py:  535]:	loss/mlm_loss, 7.312252521514893, 2484
[INFO] 2021-07-12 19:22:43,827 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.483000025677029e-05, 2484
[INFO] 2021-07-12 19:22:43,827 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2484
[INFO] 2021-07-12 19:22:43,827 [run_pretraining.py:  558]:	worker_index: 6, step: 2484, cost: 7.312253, mlm loss: 7.312253, speed: 1.080297 steps/s, speed: 8.642378 samples/s, speed: 4424.897782 tokens/s, learning rate: 2.483e-05, loss_scalings: 2814.750488, pp_loss: 7.400371
[INFO] 2021-07-12 19:22:43,828 [run_pretraining.py:  512]:	********exe.run_2484******* 
[INFO] 2021-07-12 19:22:44,749 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:44,750 [run_pretraining.py:  534]:	loss/total_loss, 8.42782974243164, 2485
[INFO] 2021-07-12 19:22:44,750 [run_pretraining.py:  535]:	loss/mlm_loss, 8.42782974243164, 2485
[INFO] 2021-07-12 19:22:44,750 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4839999241521582e-05, 2485
[INFO] 2021-07-12 19:22:44,750 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2485
[INFO] 2021-07-12 19:22:44,750 [run_pretraining.py:  558]:	worker_index: 6, step: 2485, cost: 8.427830, mlm loss: 8.427830, speed: 1.084605 steps/s, speed: 8.676842 samples/s, speed: 4442.543022 tokens/s, learning rate: 2.484e-05, loss_scalings: 2814.750488, pp_loss: 7.566887
[INFO] 2021-07-12 19:22:44,750 [run_pretraining.py:  512]:	********exe.run_2485******* 
[INFO] 2021-07-12 19:22:45,669 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:45,670 [run_pretraining.py:  534]:	loss/total_loss, 6.655434608459473, 2486
[INFO] 2021-07-12 19:22:45,670 [run_pretraining.py:  535]:	loss/mlm_loss, 6.655434608459473, 2486
[INFO] 2021-07-12 19:22:45,670 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4850000045262277e-05, 2486
[INFO] 2021-07-12 19:22:45,670 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2486
[INFO] 2021-07-12 19:22:45,670 [run_pretraining.py:  558]:	worker_index: 6, step: 2486, cost: 6.655435, mlm loss: 6.655435, speed: 1.087718 steps/s, speed: 8.701740 samples/s, speed: 4455.290940 tokens/s, learning rate: 2.485e-05, loss_scalings: 2814.750488, pp_loss: 7.077743
[INFO] 2021-07-12 19:22:45,670 [run_pretraining.py:  512]:	********exe.run_2486******* 
[INFO] 2021-07-12 19:22:46,592 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:46,592 [run_pretraining.py:  534]:	loss/total_loss, 7.308742523193359, 2487
[INFO] 2021-07-12 19:22:46,592 [run_pretraining.py:  535]:	loss/mlm_loss, 7.308742523193359, 2487
[INFO] 2021-07-12 19:22:46,592 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4860000849002972e-05, 2487
[INFO] 2021-07-12 19:22:46,593 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2487
[INFO] 2021-07-12 19:22:46,593 [run_pretraining.py:  558]:	worker_index: 6, step: 2487, cost: 7.308743, mlm loss: 7.308743, speed: 1.084881 steps/s, speed: 8.679050 samples/s, speed: 4443.673726 tokens/s, learning rate: 2.486e-05, loss_scalings: 2814.750488, pp_loss: 7.517734
[INFO] 2021-07-12 19:22:46,593 [run_pretraining.py:  512]:	********exe.run_2487******* 
[INFO] 2021-07-12 19:22:47,524 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:47,525 [run_pretraining.py:  534]:	loss/total_loss, 7.207308769226074, 2488
[INFO] 2021-07-12 19:22:47,525 [run_pretraining.py:  535]:	loss/mlm_loss, 7.207308769226074, 2488
[INFO] 2021-07-12 19:22:47,525 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.486999801476486e-05, 2488
[INFO] 2021-07-12 19:22:47,525 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2488
[INFO] 2021-07-12 19:22:47,525 [run_pretraining.py:  558]:	worker_index: 6, step: 2488, cost: 7.207309, mlm loss: 7.207309, speed: 1.073334 steps/s, speed: 8.586675 samples/s, speed: 4396.377435 tokens/s, learning rate: 2.487e-05, loss_scalings: 2814.750488, pp_loss: 7.058045
[INFO] 2021-07-12 19:22:47,525 [run_pretraining.py:  512]:	********exe.run_2488******* 
[INFO] 2021-07-12 19:22:48,452 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:48,453 [run_pretraining.py:  534]:	loss/total_loss, 7.385551929473877, 2489
[INFO] 2021-07-12 19:22:48,453 [run_pretraining.py:  535]:	loss/mlm_loss, 7.385551929473877, 2489
[INFO] 2021-07-12 19:22:48,453 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4879998818505555e-05, 2489
[INFO] 2021-07-12 19:22:48,453 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2489
[INFO] 2021-07-12 19:22:48,453 [run_pretraining.py:  558]:	worker_index: 6, step: 2489, cost: 7.385552, mlm loss: 7.385552, speed: 1.078306 steps/s, speed: 8.626446 samples/s, speed: 4416.740134 tokens/s, learning rate: 2.488e-05, loss_scalings: 2814.750488, pp_loss: 7.276700
[INFO] 2021-07-12 19:22:48,453 [run_pretraining.py:  512]:	********exe.run_2489******* 
[INFO] 2021-07-12 19:22:49,381 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:49,382 [run_pretraining.py:  534]:	loss/total_loss, 7.569825649261475, 2490
[INFO] 2021-07-12 19:22:49,382 [run_pretraining.py:  535]:	loss/mlm_loss, 7.569825649261475, 2490
[INFO] 2021-07-12 19:22:49,382 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.488999962224625e-05, 2490
[INFO] 2021-07-12 19:22:49,382 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2490
[INFO] 2021-07-12 19:22:49,382 [run_pretraining.py:  558]:	worker_index: 6, step: 2490, cost: 7.569826, mlm loss: 7.569826, speed: 1.077304 steps/s, speed: 8.618431 samples/s, speed: 4412.636877 tokens/s, learning rate: 2.489e-05, loss_scalings: 2814.750488, pp_loss: 7.308966
[INFO] 2021-07-12 19:22:49,382 [run_pretraining.py:  512]:	********exe.run_2490******* 
[INFO] 2021-07-12 19:22:50,328 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:50,328 [run_pretraining.py:  534]:	loss/total_loss, 7.229377746582031, 2491
[INFO] 2021-07-12 19:22:50,329 [run_pretraining.py:  535]:	loss/mlm_loss, 7.229377746582031, 2491
[INFO] 2021-07-12 19:22:50,329 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4899998606997542e-05, 2491
[INFO] 2021-07-12 19:22:50,329 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2491
[INFO] 2021-07-12 19:22:50,329 [run_pretraining.py:  558]:	worker_index: 6, step: 2491, cost: 7.229378, mlm loss: 7.229378, speed: 1.056995 steps/s, speed: 8.455964 samples/s, speed: 4329.453558 tokens/s, learning rate: 2.490e-05, loss_scalings: 2814.750488, pp_loss: 7.384609
[INFO] 2021-07-12 19:22:50,329 [run_pretraining.py:  512]:	********exe.run_2491******* 
[INFO] 2021-07-12 19:22:51,246 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:51,246 [run_pretraining.py:  534]:	loss/total_loss, 7.491491317749023, 2492
[INFO] 2021-07-12 19:22:51,246 [run_pretraining.py:  535]:	loss/mlm_loss, 7.491491317749023, 2492
[INFO] 2021-07-12 19:22:51,246 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4909999410738237e-05, 2492
[INFO] 2021-07-12 19:22:51,246 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2492
[INFO] 2021-07-12 19:22:51,247 [run_pretraining.py:  558]:	worker_index: 6, step: 2492, cost: 7.491491, mlm loss: 7.491491, speed: 1.090511 steps/s, speed: 8.724086 samples/s, speed: 4466.732130 tokens/s, learning rate: 2.491e-05, loss_scalings: 2814.750488, pp_loss: 7.262070
[INFO] 2021-07-12 19:22:51,247 [run_pretraining.py:  512]:	********exe.run_2492******* 
[INFO] 2021-07-12 19:22:52,164 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:52,164 [run_pretraining.py:  534]:	loss/total_loss, 7.796300888061523, 2493
[INFO] 2021-07-12 19:22:52,164 [run_pretraining.py:  535]:	loss/mlm_loss, 7.796300888061523, 2493
[INFO] 2021-07-12 19:22:52,164 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4920000214478932e-05, 2493
[INFO] 2021-07-12 19:22:52,164 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2493
[INFO] 2021-07-12 19:22:52,165 [run_pretraining.py:  558]:	worker_index: 6, step: 2493, cost: 7.796301, mlm loss: 7.796301, speed: 1.090138 steps/s, speed: 8.721104 samples/s, speed: 4465.205488 tokens/s, learning rate: 2.492e-05, loss_scalings: 2814.750488, pp_loss: 7.461381
[INFO] 2021-07-12 19:22:52,165 [run_pretraining.py:  512]:	********exe.run_2493******* 
[INFO] 2021-07-12 19:22:53,091 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:53,092 [run_pretraining.py:  534]:	loss/total_loss, 7.203473091125488, 2494
[INFO] 2021-07-12 19:22:53,092 [run_pretraining.py:  535]:	loss/mlm_loss, 7.203473091125488, 2494
[INFO] 2021-07-12 19:22:53,092 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4929999199230224e-05, 2494
[INFO] 2021-07-12 19:22:53,092 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2494
[INFO] 2021-07-12 19:22:53,092 [run_pretraining.py:  558]:	worker_index: 6, step: 2494, cost: 7.203473, mlm loss: 7.203473, speed: 1.079012 steps/s, speed: 8.632096 samples/s, speed: 4419.632989 tokens/s, learning rate: 2.493e-05, loss_scalings: 2814.750488, pp_loss: 7.573169
[INFO] 2021-07-12 19:22:53,092 [run_pretraining.py:  512]:	********exe.run_2494******* 
[INFO] 2021-07-12 19:22:54,017 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:54,018 [run_pretraining.py:  534]:	loss/total_loss, 7.632650852203369, 2495
[INFO] 2021-07-12 19:22:54,018 [run_pretraining.py:  535]:	loss/mlm_loss, 7.632650852203369, 2495
[INFO] 2021-07-12 19:22:54,018 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.494000000297092e-05, 2495
[INFO] 2021-07-12 19:22:54,018 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2495
[INFO] 2021-07-12 19:22:54,018 [run_pretraining.py:  558]:	worker_index: 6, step: 2495, cost: 7.632651, mlm loss: 7.632651, speed: 1.080928 steps/s, speed: 8.647428 samples/s, speed: 4427.482968 tokens/s, learning rate: 2.494e-05, loss_scalings: 2814.750488, pp_loss: 7.505755
[INFO] 2021-07-12 19:22:54,018 [run_pretraining.py:  512]:	********exe.run_2495******* 
[INFO] 2021-07-12 19:22:54,938 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:54,938 [run_pretraining.py:  534]:	loss/total_loss, 7.158240795135498, 2496
[INFO] 2021-07-12 19:22:54,938 [run_pretraining.py:  535]:	loss/mlm_loss, 7.158240795135498, 2496
[INFO] 2021-07-12 19:22:54,938 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4950000806711614e-05, 2496
[INFO] 2021-07-12 19:22:54,938 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2496
[INFO] 2021-07-12 19:22:54,939 [run_pretraining.py:  558]:	worker_index: 6, step: 2496, cost: 7.158241, mlm loss: 7.158241, speed: 1.087028 steps/s, speed: 8.696224 samples/s, speed: 4452.466624 tokens/s, learning rate: 2.495e-05, loss_scalings: 2814.750488, pp_loss: 7.355397
[INFO] 2021-07-12 19:22:54,939 [run_pretraining.py:  512]:	********exe.run_2496******* 
[INFO] 2021-07-12 19:22:55,860 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:55,861 [run_pretraining.py:  534]:	loss/total_loss, 7.143813610076904, 2497
[INFO] 2021-07-12 19:22:55,861 [run_pretraining.py:  535]:	loss/mlm_loss, 7.143813610076904, 2497
[INFO] 2021-07-12 19:22:55,861 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4959997972473502e-05, 2497
[INFO] 2021-07-12 19:22:55,861 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2497
[INFO] 2021-07-12 19:22:55,861 [run_pretraining.py:  558]:	worker_index: 6, step: 2497, cost: 7.143814, mlm loss: 7.143814, speed: 1.084818 steps/s, speed: 8.678547 samples/s, speed: 4443.416280 tokens/s, learning rate: 2.496e-05, loss_scalings: 2814.750488, pp_loss: 7.090847
[INFO] 2021-07-12 19:22:55,861 [run_pretraining.py:  512]:	********exe.run_2497******* 
[INFO] 2021-07-12 19:22:56,792 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:56,793 [run_pretraining.py:  534]:	loss/total_loss, 6.977644443511963, 2498
[INFO] 2021-07-12 19:22:56,793 [run_pretraining.py:  535]:	loss/mlm_loss, 6.977644443511963, 2498
[INFO] 2021-07-12 19:22:56,793 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4969998776214197e-05, 2498
[INFO] 2021-07-12 19:22:56,793 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2498
[INFO] 2021-07-12 19:22:56,793 [run_pretraining.py:  558]:	worker_index: 6, step: 2498, cost: 6.977644, mlm loss: 6.977644, speed: 1.073812 steps/s, speed: 8.590500 samples/s, speed: 4398.335886 tokens/s, learning rate: 2.497e-05, loss_scalings: 2814.750488, pp_loss: 7.185964
[INFO] 2021-07-12 19:22:56,793 [run_pretraining.py:  512]:	********exe.run_2498******* 
[INFO] 2021-07-12 19:22:57,711 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:57,711 [run_pretraining.py:  534]:	loss/total_loss, 7.199826240539551, 2499
[INFO] 2021-07-12 19:22:57,712 [run_pretraining.py:  535]:	loss/mlm_loss, 7.199826240539551, 2499
[INFO] 2021-07-12 19:22:57,712 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4979999579954892e-05, 2499
[INFO] 2021-07-12 19:22:57,712 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2499
[INFO] 2021-07-12 19:22:57,712 [run_pretraining.py:  558]:	worker_index: 6, step: 2499, cost: 7.199826, mlm loss: 7.199826, speed: 1.089249 steps/s, speed: 8.713993 samples/s, speed: 4461.564339 tokens/s, learning rate: 2.498e-05, loss_scalings: 2814.750488, pp_loss: 7.234046
[INFO] 2021-07-12 19:22:57,712 [run_pretraining.py:  512]:	********exe.run_2499******* 
[INFO] 2021-07-12 19:22:58,644 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:58,645 [run_pretraining.py:  534]:	loss/total_loss, 7.4275078773498535, 2500
[INFO] 2021-07-12 19:22:58,645 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4275078773498535, 2500
[INFO] 2021-07-12 19:22:58,645 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4989998564706184e-05, 2500
[INFO] 2021-07-12 19:22:58,645 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2500
[INFO] 2021-07-12 19:22:58,645 [run_pretraining.py:  558]:	worker_index: 6, step: 2500, cost: 7.427508, mlm loss: 7.427508, speed: 1.071940 steps/s, speed: 8.575518 samples/s, speed: 4390.665136 tokens/s, learning rate: 2.499e-05, loss_scalings: 2814.750488, pp_loss: 7.049220
[INFO] 2021-07-12 19:22:58,646 [run_pretraining.py:  512]:	********exe.run_2500******* 
[INFO] 2021-07-12 19:22:59,557 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:59,558 [run_pretraining.py:  534]:	loss/total_loss, 7.137293815612793, 2501
[INFO] 2021-07-12 19:22:59,558 [run_pretraining.py:  535]:	loss/mlm_loss, 7.137293815612793, 2501
[INFO] 2021-07-12 19:22:59,558 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.499999936844688e-05, 2501
[INFO] 2021-07-12 19:22:59,558 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2501
[INFO] 2021-07-12 19:22:59,558 [run_pretraining.py:  558]:	worker_index: 6, step: 2501, cost: 7.137294, mlm loss: 7.137294, speed: 1.096775 steps/s, speed: 8.774204 samples/s, speed: 4492.392210 tokens/s, learning rate: 2.500e-05, loss_scalings: 2814.750488, pp_loss: 7.049557
[INFO] 2021-07-12 19:22:59,558 [run_pretraining.py:  512]:	********exe.run_2501******* 
[INFO] 2021-07-12 19:23:00,480 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:00,481 [run_pretraining.py:  534]:	loss/total_loss, 7.520641803741455, 2502
[INFO] 2021-07-12 19:23:00,481 [run_pretraining.py:  535]:	loss/mlm_loss, 7.520641803741455, 2502
[INFO] 2021-07-12 19:23:00,481 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.500999835319817e-05, 2502
[INFO] 2021-07-12 19:23:00,481 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2502
[INFO] 2021-07-12 19:23:00,481 [run_pretraining.py:  558]:	worker_index: 6, step: 2502, cost: 7.520642, mlm loss: 7.520642, speed: 1.083930 steps/s, speed: 8.671438 samples/s, speed: 4439.776145 tokens/s, learning rate: 2.501e-05, loss_scalings: 2814.750488, pp_loss: 7.367504
[INFO] 2021-07-12 19:23:00,481 [run_pretraining.py:  512]:	********exe.run_2502******* 
[INFO] 2021-07-12 19:23:01,401 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:01,402 [run_pretraining.py:  534]:	loss/total_loss, 5.189088821411133, 2503
[INFO] 2021-07-12 19:23:01,402 [run_pretraining.py:  535]:	loss/mlm_loss, 5.189088821411133, 2503
[INFO] 2021-07-12 19:23:01,402 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5019999156938866e-05, 2503
[INFO] 2021-07-12 19:23:01,402 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2503
[INFO] 2021-07-12 19:23:01,402 [run_pretraining.py:  558]:	worker_index: 6, step: 2503, cost: 5.189089, mlm loss: 5.189089, speed: 1.086767 steps/s, speed: 8.694137 samples/s, speed: 4451.398336 tokens/s, learning rate: 2.502e-05, loss_scalings: 2814.750488, pp_loss: 6.830153
[INFO] 2021-07-12 19:23:01,402 [run_pretraining.py:  512]:	********exe.run_2503******* 
[INFO] 2021-07-12 19:23:02,320 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:02,321 [run_pretraining.py:  534]:	loss/total_loss, 7.306325912475586, 2504
[INFO] 2021-07-12 19:23:02,321 [run_pretraining.py:  535]:	loss/mlm_loss, 7.306325912475586, 2504
[INFO] 2021-07-12 19:23:02,321 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5029998141690157e-05, 2504
[INFO] 2021-07-12 19:23:02,321 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2504
[INFO] 2021-07-12 19:23:02,321 [run_pretraining.py:  558]:	worker_index: 6, step: 2504, cost: 7.306326, mlm loss: 7.306326, speed: 1.088524 steps/s, speed: 8.708190 samples/s, speed: 4458.593208 tokens/s, learning rate: 2.503e-05, loss_scalings: 2814.750488, pp_loss: 7.146182
[INFO] 2021-07-12 19:23:02,322 [run_pretraining.py:  512]:	********exe.run_2504******* 
[INFO] 2021-07-12 19:23:03,250 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:03,250 [run_pretraining.py:  534]:	loss/total_loss, 3.5257887840270996, 2505
[INFO] 2021-07-12 19:23:03,250 [run_pretraining.py:  535]:	loss/mlm_loss, 3.5257887840270996, 2505
[INFO] 2021-07-12 19:23:03,250 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5040000764420256e-05, 2505
[INFO] 2021-07-12 19:23:03,250 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2505
[INFO] 2021-07-12 19:23:03,251 [run_pretraining.py:  558]:	worker_index: 6, step: 2505, cost: 3.525789, mlm loss: 3.525789, speed: 1.077133 steps/s, speed: 8.617061 samples/s, speed: 4411.935425 tokens/s, learning rate: 2.504e-05, loss_scalings: 2814.750488, pp_loss: 6.157166
[INFO] 2021-07-12 19:23:03,251 [run_pretraining.py:  512]:	********exe.run_2505******* 
[INFO] 2021-07-12 19:23:04,171 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:04,172 [run_pretraining.py:  534]:	loss/total_loss, 7.146132469177246, 2506
[INFO] 2021-07-12 19:23:04,172 [run_pretraining.py:  535]:	loss/mlm_loss, 7.146132469177246, 2506
[INFO] 2021-07-12 19:23:04,172 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5049997930182144e-05, 2506
[INFO] 2021-07-12 19:23:04,172 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2506
[INFO] 2021-07-12 19:23:04,172 [run_pretraining.py:  558]:	worker_index: 6, step: 2506, cost: 7.146132, mlm loss: 7.146132, speed: 1.085582 steps/s, speed: 8.684653 samples/s, speed: 4446.542136 tokens/s, learning rate: 2.505e-05, loss_scalings: 2814.750488, pp_loss: 7.395285
[INFO] 2021-07-12 19:23:04,172 [run_pretraining.py:  512]:	********exe.run_2506******* 
[INFO] 2021-07-12 19:23:05,090 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:05,090 [run_pretraining.py:  534]:	loss/total_loss, 6.956984043121338, 2507
[INFO] 2021-07-12 19:23:05,091 [run_pretraining.py:  535]:	loss/mlm_loss, 6.956984043121338, 2507
[INFO] 2021-07-12 19:23:05,091 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5060000552912243e-05, 2507
[INFO] 2021-07-12 19:23:05,091 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2507
[INFO] 2021-07-12 19:23:05,091 [run_pretraining.py:  558]:	worker_index: 6, step: 2507, cost: 6.956984, mlm loss: 6.956984, speed: 1.089710 steps/s, speed: 8.717679 samples/s, speed: 4463.451429 tokens/s, learning rate: 2.506e-05, loss_scalings: 2814.750488, pp_loss: 7.067039
[INFO] 2021-07-12 19:23:05,091 [run_pretraining.py:  512]:	********exe.run_2507******* 
[INFO] 2021-07-12 19:23:06,013 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:06,014 [run_pretraining.py:  534]:	loss/total_loss, 7.3470988273620605, 2508
[INFO] 2021-07-12 19:23:06,014 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3470988273620605, 2508
[INFO] 2021-07-12 19:23:06,014 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5069999537663534e-05, 2508
[INFO] 2021-07-12 19:23:06,014 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2508
[INFO] 2021-07-12 19:23:06,014 [run_pretraining.py:  558]:	worker_index: 6, step: 2508, cost: 7.347099, mlm loss: 7.347099, speed: 1.083487 steps/s, speed: 8.667896 samples/s, speed: 4437.962899 tokens/s, learning rate: 2.507e-05, loss_scalings: 2814.750488, pp_loss: 7.024427
[INFO] 2021-07-12 19:23:06,014 [run_pretraining.py:  512]:	********exe.run_2508******* 
[INFO] 2021-07-12 19:23:06,930 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:06,931 [run_pretraining.py:  534]:	loss/total_loss, 7.026902198791504, 2509
[INFO] 2021-07-12 19:23:06,931 [run_pretraining.py:  535]:	loss/mlm_loss, 7.026902198791504, 2509
[INFO] 2021-07-12 19:23:06,931 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.508000034140423e-05, 2509
[INFO] 2021-07-12 19:23:06,931 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2509
[INFO] 2021-07-12 19:23:06,931 [run_pretraining.py:  558]:	worker_index: 6, step: 2509, cost: 7.026902, mlm loss: 7.026902, speed: 1.091715 steps/s, speed: 8.733721 samples/s, speed: 4471.665144 tokens/s, learning rate: 2.508e-05, loss_scalings: 2814.750488, pp_loss: 7.261383
[INFO] 2021-07-12 19:23:06,931 [run_pretraining.py:  512]:	********exe.run_2509******* 
[INFO] 2021-07-12 19:23:07,852 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:07,853 [run_pretraining.py:  534]:	loss/total_loss, 7.095171928405762, 2510
[INFO] 2021-07-12 19:23:07,853 [run_pretraining.py:  535]:	loss/mlm_loss, 7.095171928405762, 2510
[INFO] 2021-07-12 19:23:07,853 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.508999932615552e-05, 2510
[INFO] 2021-07-12 19:23:07,853 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2510
[INFO] 2021-07-12 19:23:07,853 [run_pretraining.py:  558]:	worker_index: 6, step: 2510, cost: 7.095172, mlm loss: 7.095172, speed: 1.085535 steps/s, speed: 8.684277 samples/s, speed: 4446.349950 tokens/s, learning rate: 2.509e-05, loss_scalings: 2814.750488, pp_loss: 7.089026
[INFO] 2021-07-12 19:23:07,853 [run_pretraining.py:  512]:	********exe.run_2510******* 
[INFO] 2021-07-12 19:23:08,763 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:08,763 [run_pretraining.py:  534]:	loss/total_loss, 7.057032585144043, 2511
[INFO] 2021-07-12 19:23:08,763 [run_pretraining.py:  535]:	loss/mlm_loss, 7.057032585144043, 2511
[INFO] 2021-07-12 19:23:08,764 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5099998310906813e-05, 2511
[INFO] 2021-07-12 19:23:08,764 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2511
[INFO] 2021-07-12 19:23:08,764 [run_pretraining.py:  558]:	worker_index: 6, step: 2511, cost: 7.057033, mlm loss: 7.057033, speed: 1.098938 steps/s, speed: 8.791503 samples/s, speed: 4501.249430 tokens/s, learning rate: 2.510e-05, loss_scalings: 2814.750488, pp_loss: 7.191331
[INFO] 2021-07-12 19:23:08,764 [run_pretraining.py:  512]:	********exe.run_2511******* 
[INFO] 2021-07-12 19:23:09,685 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:09,686 [run_pretraining.py:  534]:	loss/total_loss, 7.720592498779297, 2512
[INFO] 2021-07-12 19:23:09,686 [run_pretraining.py:  535]:	loss/mlm_loss, 7.720592498779297, 2512
[INFO] 2021-07-12 19:23:09,686 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5109999114647508e-05, 2512
[INFO] 2021-07-12 19:23:09,686 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2512
[INFO] 2021-07-12 19:23:09,686 [run_pretraining.py:  558]:	worker_index: 6, step: 2512, cost: 7.720592, mlm loss: 7.720592, speed: 1.084814 steps/s, speed: 8.678514 samples/s, speed: 4443.399041 tokens/s, learning rate: 2.511e-05, loss_scalings: 2814.750488, pp_loss: 7.405762
[INFO] 2021-07-12 19:23:09,686 [run_pretraining.py:  512]:	********exe.run_2512******* 
[INFO] 2021-07-12 19:23:10,601 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:10,601 [run_pretraining.py:  534]:	loss/total_loss, 8.239178657531738, 2513
[INFO] 2021-07-12 19:23:10,601 [run_pretraining.py:  535]:	loss/mlm_loss, 8.239178657531738, 2513
[INFO] 2021-07-12 19:23:10,601 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.51199980993988e-05, 2513
[INFO] 2021-07-12 19:23:10,602 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2513
[INFO] 2021-07-12 19:23:10,602 [run_pretraining.py:  558]:	worker_index: 6, step: 2513, cost: 8.239179, mlm loss: 8.239179, speed: 1.093188 steps/s, speed: 8.745508 samples/s, speed: 4477.699994 tokens/s, learning rate: 2.512e-05, loss_scalings: 2814.750488, pp_loss: 7.614994
[INFO] 2021-07-12 19:23:10,602 [run_pretraining.py:  512]:	********exe.run_2513******* 
[INFO] 2021-07-12 19:23:11,523 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:11,523 [run_pretraining.py:  534]:	loss/total_loss, 7.128654956817627, 2514
[INFO] 2021-07-12 19:23:11,523 [run_pretraining.py:  535]:	loss/mlm_loss, 7.128654956817627, 2514
[INFO] 2021-07-12 19:23:11,523 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5130000722128898e-05, 2514
[INFO] 2021-07-12 19:23:11,524 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2514
[INFO] 2021-07-12 19:23:11,524 [run_pretraining.py:  558]:	worker_index: 6, step: 2514, cost: 7.128655, mlm loss: 7.128655, speed: 1.085440 steps/s, speed: 8.683522 samples/s, speed: 4445.963325 tokens/s, learning rate: 2.513e-05, loss_scalings: 2814.750488, pp_loss: 7.296891
[INFO] 2021-07-12 19:23:11,524 [run_pretraining.py:  512]:	********exe.run_2514******* 
[INFO] 2021-07-12 19:23:12,442 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:12,443 [run_pretraining.py:  534]:	loss/total_loss, 7.531457424163818, 2515
[INFO] 2021-07-12 19:23:12,443 [run_pretraining.py:  535]:	loss/mlm_loss, 7.531457424163818, 2515
[INFO] 2021-07-12 19:23:12,443 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5139997887890786e-05, 2515
[INFO] 2021-07-12 19:23:12,443 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2515
[INFO] 2021-07-12 19:23:12,443 [run_pretraining.py:  558]:	worker_index: 6, step: 2515, cost: 7.531457, mlm loss: 7.531457, speed: 1.088574 steps/s, speed: 8.708592 samples/s, speed: 4458.799184 tokens/s, learning rate: 2.514e-05, loss_scalings: 2814.750488, pp_loss: 7.247773
[INFO] 2021-07-12 19:23:12,443 [run_pretraining.py:  512]:	********exe.run_2515******* 
[INFO] 2021-07-12 19:23:13,362 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:13,363 [run_pretraining.py:  534]:	loss/total_loss, 6.915480613708496, 2516
[INFO] 2021-07-12 19:23:13,363 [run_pretraining.py:  535]:	loss/mlm_loss, 6.915480613708496, 2516
[INFO] 2021-07-12 19:23:13,363 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5150000510620885e-05, 2516
[INFO] 2021-07-12 19:23:13,363 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2516
[INFO] 2021-07-12 19:23:13,363 [run_pretraining.py:  558]:	worker_index: 6, step: 2516, cost: 6.915481, mlm loss: 6.915481, speed: 1.087442 steps/s, speed: 8.699536 samples/s, speed: 4454.162401 tokens/s, learning rate: 2.515e-05, loss_scalings: 2814.750488, pp_loss: 7.502148
[INFO] 2021-07-12 19:23:13,363 [run_pretraining.py:  512]:	********exe.run_2516******* 
[INFO] 2021-07-12 19:23:14,290 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:14,291 [run_pretraining.py:  534]:	loss/total_loss, 7.0958967208862305, 2517
[INFO] 2021-07-12 19:23:14,291 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0958967208862305, 2517
[INFO] 2021-07-12 19:23:14,291 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5159999495372176e-05, 2517
[INFO] 2021-07-12 19:23:14,291 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2517
[INFO] 2021-07-12 19:23:14,291 [run_pretraining.py:  558]:	worker_index: 6, step: 2517, cost: 7.095897, mlm loss: 7.095897, speed: 1.078496 steps/s, speed: 8.627972 samples/s, speed: 4417.521490 tokens/s, learning rate: 2.516e-05, loss_scalings: 2814.750488, pp_loss: 7.322279
[INFO] 2021-07-12 19:23:14,291 [run_pretraining.py:  512]:	********exe.run_2517******* 
[INFO] 2021-07-12 19:23:15,231 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:15,231 [run_pretraining.py:  534]:	loss/total_loss, 3.5099055767059326, 2518
[INFO] 2021-07-12 19:23:15,232 [run_pretraining.py:  535]:	loss/mlm_loss, 3.5099055767059326, 2518
[INFO] 2021-07-12 19:23:15,232 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.517000029911287e-05, 2518
[INFO] 2021-07-12 19:23:15,232 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2518
[INFO] 2021-07-12 19:23:15,232 [run_pretraining.py:  558]:	worker_index: 6, step: 2518, cost: 3.509906, mlm loss: 3.509906, speed: 1.063895 steps/s, speed: 8.511162 samples/s, speed: 4357.715126 tokens/s, learning rate: 2.517e-05, loss_scalings: 2814.750488, pp_loss: 6.251294
[INFO] 2021-07-12 19:23:15,232 [run_pretraining.py:  512]:	********exe.run_2518******* 
[INFO] 2021-07-12 19:23:16,150 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:16,151 [run_pretraining.py:  534]:	loss/total_loss, 7.309512138366699, 2519
[INFO] 2021-07-12 19:23:16,151 [run_pretraining.py:  535]:	loss/mlm_loss, 7.309512138366699, 2519
[INFO] 2021-07-12 19:23:16,151 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5179999283864163e-05, 2519
[INFO] 2021-07-12 19:23:16,151 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2519
[INFO] 2021-07-12 19:23:16,151 [run_pretraining.py:  558]:	worker_index: 6, step: 2519, cost: 7.309512, mlm loss: 7.309512, speed: 1.088338 steps/s, speed: 8.706705 samples/s, speed: 4457.833114 tokens/s, learning rate: 2.518e-05, loss_scalings: 2814.750488, pp_loss: 7.250144
[INFO] 2021-07-12 19:23:16,151 [run_pretraining.py:  512]:	********exe.run_2519******* 
[INFO] 2021-07-12 19:23:17,078 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:17,078 [run_pretraining.py:  534]:	loss/total_loss, 7.076628684997559, 2520
[INFO] 2021-07-12 19:23:17,078 [run_pretraining.py:  535]:	loss/mlm_loss, 7.076628684997559, 2520
[INFO] 2021-07-12 19:23:17,078 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5189998268615454e-05, 2520
[INFO] 2021-07-12 19:23:17,079 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2520
[INFO] 2021-07-12 19:23:17,079 [run_pretraining.py:  558]:	worker_index: 6, step: 2520, cost: 7.076629, mlm loss: 7.076629, speed: 1.079266 steps/s, speed: 8.634126 samples/s, speed: 4420.672432 tokens/s, learning rate: 2.519e-05, loss_scalings: 2814.750488, pp_loss: 6.607725
[INFO] 2021-07-12 19:23:17,079 [run_pretraining.py:  512]:	********exe.run_2520******* 
[INFO] 2021-07-12 19:23:18,002 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:18,002 [run_pretraining.py:  534]:	loss/total_loss, 7.52933406829834, 2521
[INFO] 2021-07-12 19:23:18,002 [run_pretraining.py:  535]:	loss/mlm_loss, 7.52933406829834, 2521
[INFO] 2021-07-12 19:23:18,002 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.519999907235615e-05, 2521
[INFO] 2021-07-12 19:23:18,002 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2521
[INFO] 2021-07-12 19:23:18,003 [run_pretraining.py:  558]:	worker_index: 6, step: 2521, cost: 7.529334, mlm loss: 7.529334, speed: 1.083195 steps/s, speed: 8.665562 samples/s, speed: 4436.767494 tokens/s, learning rate: 2.520e-05, loss_scalings: 2814.750488, pp_loss: 7.427881
[INFO] 2021-07-12 19:23:18,003 [run_pretraining.py:  512]:	********exe.run_2521******* 
[INFO] 2021-07-12 19:23:18,924 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:18,925 [run_pretraining.py:  534]:	loss/total_loss, 7.519464492797852, 2522
[INFO] 2021-07-12 19:23:18,925 [run_pretraining.py:  535]:	loss/mlm_loss, 7.519464492797852, 2522
[INFO] 2021-07-12 19:23:18,925 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.520999805710744e-05, 2522
[INFO] 2021-07-12 19:23:18,925 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2522
[INFO] 2021-07-12 19:23:18,925 [run_pretraining.py:  558]:	worker_index: 6, step: 2522, cost: 7.519464, mlm loss: 7.519464, speed: 1.084740 steps/s, speed: 8.677921 samples/s, speed: 4443.095662 tokens/s, learning rate: 2.521e-05, loss_scalings: 2814.750488, pp_loss: 7.529071
[INFO] 2021-07-12 19:23:18,925 [run_pretraining.py:  512]:	********exe.run_2522******* 
[INFO] 2021-07-12 19:23:19,857 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:19,857 [run_pretraining.py:  534]:	loss/total_loss, 7.506776332855225, 2523
[INFO] 2021-07-12 19:23:19,857 [run_pretraining.py:  535]:	loss/mlm_loss, 7.506776332855225, 2523
[INFO] 2021-07-12 19:23:19,857 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.522000067983754e-05, 2523
[INFO] 2021-07-12 19:23:19,858 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2523
[INFO] 2021-07-12 19:23:19,858 [run_pretraining.py:  558]:	worker_index: 6, step: 2523, cost: 7.506776, mlm loss: 7.506776, speed: 1.073143 steps/s, speed: 8.585143 samples/s, speed: 4395.593418 tokens/s, learning rate: 2.522e-05, loss_scalings: 2814.750488, pp_loss: 7.363164
[INFO] 2021-07-12 19:23:19,858 [run_pretraining.py:  512]:	********exe.run_2523******* 
[INFO] 2021-07-12 19:23:20,842 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:20,843 [run_pretraining.py:  534]:	loss/total_loss, 7.432563781738281, 2524
[INFO] 2021-07-12 19:23:20,843 [run_pretraining.py:  535]:	loss/mlm_loss, 7.432563781738281, 2524
[INFO] 2021-07-12 19:23:20,843 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.522999966458883e-05, 2524
[INFO] 2021-07-12 19:23:20,843 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2524
[INFO] 2021-07-12 19:23:20,843 [run_pretraining.py:  558]:	worker_index: 6, step: 2524, cost: 7.432564, mlm loss: 7.432564, speed: 1.015439 steps/s, speed: 8.123515 samples/s, speed: 4159.239861 tokens/s, learning rate: 2.523e-05, loss_scalings: 2814.750488, pp_loss: 7.218675
[INFO] 2021-07-12 19:23:20,843 [run_pretraining.py:  512]:	********exe.run_2524******* 
[INFO] 2021-07-12 19:23:21,775 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:21,776 [run_pretraining.py:  534]:	loss/total_loss, 7.143411636352539, 2525
[INFO] 2021-07-12 19:23:21,776 [run_pretraining.py:  535]:	loss/mlm_loss, 7.143411636352539, 2525
[INFO] 2021-07-12 19:23:21,776 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5240000468329526e-05, 2525
[INFO] 2021-07-12 19:23:21,776 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2525
[INFO] 2021-07-12 19:23:21,776 [run_pretraining.py:  558]:	worker_index: 6, step: 2525, cost: 7.143412, mlm loss: 7.143412, speed: 1.072479 steps/s, speed: 8.579831 samples/s, speed: 4392.873463 tokens/s, learning rate: 2.524e-05, loss_scalings: 2814.750488, pp_loss: 7.088722
[INFO] 2021-07-12 19:23:21,776 [run_pretraining.py:  512]:	********exe.run_2525******* 
[INFO] 2021-07-12 19:23:22,728 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:22,729 [run_pretraining.py:  534]:	loss/total_loss, 6.7925639152526855, 2526
[INFO] 2021-07-12 19:23:22,729 [run_pretraining.py:  535]:	loss/mlm_loss, 6.7925639152526855, 2526
[INFO] 2021-07-12 19:23:22,729 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5249999453080818e-05, 2526
[INFO] 2021-07-12 19:23:22,729 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2526
[INFO] 2021-07-12 19:23:22,729 [run_pretraining.py:  558]:	worker_index: 6, step: 2526, cost: 6.792564, mlm loss: 6.792564, speed: 1.050287 steps/s, speed: 8.402297 samples/s, speed: 4301.976291 tokens/s, learning rate: 2.525e-05, loss_scalings: 2814.750488, pp_loss: 7.044318
[INFO] 2021-07-12 19:23:22,729 [run_pretraining.py:  512]:	********exe.run_2526******* 
[INFO] 2021-07-12 19:23:23,637 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:23,638 [run_pretraining.py:  534]:	loss/total_loss, 6.504988670349121, 2527
[INFO] 2021-07-12 19:23:23,638 [run_pretraining.py:  535]:	loss/mlm_loss, 6.504988670349121, 2527
[INFO] 2021-07-12 19:23:23,638 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5260000256821513e-05, 2527
[INFO] 2021-07-12 19:23:23,638 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2527
[INFO] 2021-07-12 19:23:23,638 [run_pretraining.py:  558]:	worker_index: 6, step: 2527, cost: 6.504989, mlm loss: 6.504989, speed: 1.101084 steps/s, speed: 8.808674 samples/s, speed: 4510.041004 tokens/s, learning rate: 2.526e-05, loss_scalings: 2814.750488, pp_loss: 7.164855
[INFO] 2021-07-12 19:23:23,638 [run_pretraining.py:  512]:	********exe.run_2527******* 
[INFO] 2021-07-12 19:23:24,552 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:24,552 [run_pretraining.py:  534]:	loss/total_loss, 7.036711692810059, 2528
[INFO] 2021-07-12 19:23:24,553 [run_pretraining.py:  535]:	loss/mlm_loss, 7.036711692810059, 2528
[INFO] 2021-07-12 19:23:24,553 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5269999241572805e-05, 2528
[INFO] 2021-07-12 19:23:24,553 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2528
[INFO] 2021-07-12 19:23:24,553 [run_pretraining.py:  558]:	worker_index: 6, step: 2528, cost: 7.036712, mlm loss: 7.036712, speed: 1.093878 steps/s, speed: 8.751025 samples/s, speed: 4480.524873 tokens/s, learning rate: 2.527e-05, loss_scalings: 2814.750488, pp_loss: 7.337353
[INFO] 2021-07-12 19:23:24,553 [run_pretraining.py:  512]:	********exe.run_2528******* 
[INFO] 2021-07-12 19:23:25,475 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:25,476 [run_pretraining.py:  534]:	loss/total_loss, 7.349479675292969, 2529
[INFO] 2021-07-12 19:23:25,476 [run_pretraining.py:  535]:	loss/mlm_loss, 7.349479675292969, 2529
[INFO] 2021-07-12 19:23:25,476 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5279998226324096e-05, 2529
[INFO] 2021-07-12 19:23:25,476 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2529
[INFO] 2021-07-12 19:23:25,476 [run_pretraining.py:  558]:	worker_index: 6, step: 2529, cost: 7.349480, mlm loss: 7.349480, speed: 1.083749 steps/s, speed: 8.669990 samples/s, speed: 4439.035069 tokens/s, learning rate: 2.528e-05, loss_scalings: 2814.750488, pp_loss: 7.097123
[INFO] 2021-07-12 19:23:25,476 [run_pretraining.py:  512]:	********exe.run_2529******* 
[INFO] 2021-07-12 19:23:26,384 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:26,385 [run_pretraining.py:  534]:	loss/total_loss, 6.316196441650391, 2530
[INFO] 2021-07-12 19:23:26,385 [run_pretraining.py:  535]:	loss/mlm_loss, 6.316196441650391, 2530
[INFO] 2021-07-12 19:23:26,385 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.528999903006479e-05, 2530
[INFO] 2021-07-12 19:23:26,385 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2530
[INFO] 2021-07-12 19:23:26,385 [run_pretraining.py:  558]:	worker_index: 6, step: 2530, cost: 6.316196, mlm loss: 6.316196, speed: 1.101221 steps/s, speed: 8.809770 samples/s, speed: 4510.602276 tokens/s, learning rate: 2.529e-05, loss_scalings: 2814.750488, pp_loss: 6.991878
[INFO] 2021-07-12 19:23:26,385 [run_pretraining.py:  512]:	********exe.run_2530******* 
[INFO] 2021-07-12 19:23:27,307 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:27,308 [run_pretraining.py:  534]:	loss/total_loss, 6.646907329559326, 2531
[INFO] 2021-07-12 19:23:27,308 [run_pretraining.py:  535]:	loss/mlm_loss, 6.646907329559326, 2531
[INFO] 2021-07-12 19:23:27,308 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5299998014816083e-05, 2531
[INFO] 2021-07-12 19:23:27,308 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2531
[INFO] 2021-07-12 19:23:27,308 [run_pretraining.py:  558]:	worker_index: 6, step: 2531, cost: 6.646907, mlm loss: 6.646907, speed: 1.084150 steps/s, speed: 8.673202 samples/s, speed: 4440.679306 tokens/s, learning rate: 2.530e-05, loss_scalings: 2814.750488, pp_loss: 7.216440
[INFO] 2021-07-12 19:23:27,308 [run_pretraining.py:  512]:	********exe.run_2531******* 
[INFO] 2021-07-12 19:23:28,216 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:28,217 [run_pretraining.py:  534]:	loss/total_loss, 7.161301136016846, 2532
[INFO] 2021-07-12 19:23:28,217 [run_pretraining.py:  535]:	loss/mlm_loss, 7.161301136016846, 2532
[INFO] 2021-07-12 19:23:28,217 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.531000063754618e-05, 2532
[INFO] 2021-07-12 19:23:28,217 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2532
[INFO] 2021-07-12 19:23:28,217 [run_pretraining.py:  558]:	worker_index: 6, step: 2532, cost: 7.161301, mlm loss: 7.161301, speed: 1.100974 steps/s, speed: 8.807788 samples/s, speed: 4509.587589 tokens/s, learning rate: 2.531e-05, loss_scalings: 2814.750488, pp_loss: 7.528539
[INFO] 2021-07-12 19:23:28,217 [run_pretraining.py:  512]:	********exe.run_2532******* 
[INFO] 2021-07-12 19:23:29,134 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:29,135 [run_pretraining.py:  534]:	loss/total_loss, 7.439949989318848, 2533
[INFO] 2021-07-12 19:23:29,135 [run_pretraining.py:  535]:	loss/mlm_loss, 7.439949989318848, 2533
[INFO] 2021-07-12 19:23:29,135 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5319999622297473e-05, 2533
[INFO] 2021-07-12 19:23:29,135 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2533
[INFO] 2021-07-12 19:23:29,135 [run_pretraining.py:  558]:	worker_index: 6, step: 2533, cost: 7.439950, mlm loss: 7.439950, speed: 1.090395 steps/s, speed: 8.723159 samples/s, speed: 4466.257192 tokens/s, learning rate: 2.532e-05, loss_scalings: 2814.750488, pp_loss: 7.127000
[INFO] 2021-07-12 19:23:29,135 [run_pretraining.py:  512]:	********exe.run_2533******* 
[INFO] 2021-07-12 19:23:30,044 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:30,044 [run_pretraining.py:  534]:	loss/total_loss, 7.387795925140381, 2534
[INFO] 2021-07-12 19:23:30,044 [run_pretraining.py:  535]:	loss/mlm_loss, 7.387795925140381, 2534
[INFO] 2021-07-12 19:23:30,045 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.533000042603817e-05, 2534
[INFO] 2021-07-12 19:23:30,045 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2534
[INFO] 2021-07-12 19:23:30,045 [run_pretraining.py:  558]:	worker_index: 6, step: 2534, cost: 7.387796, mlm loss: 7.387796, speed: 1.099936 steps/s, speed: 8.799485 samples/s, speed: 4505.336080 tokens/s, learning rate: 2.533e-05, loss_scalings: 2814.750488, pp_loss: 7.111732
[INFO] 2021-07-12 19:23:30,045 [run_pretraining.py:  512]:	********exe.run_2534******* 
[INFO] 2021-07-12 19:23:30,959 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:30,960 [run_pretraining.py:  534]:	loss/total_loss, 6.936511993408203, 2535
[INFO] 2021-07-12 19:23:30,960 [run_pretraining.py:  535]:	loss/mlm_loss, 6.936511993408203, 2535
[INFO] 2021-07-12 19:23:30,960 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.533999941078946e-05, 2535
[INFO] 2021-07-12 19:23:30,960 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2535
[INFO] 2021-07-12 19:23:30,960 [run_pretraining.py:  558]:	worker_index: 6, step: 2535, cost: 6.936512, mlm loss: 6.936512, speed: 1.093573 steps/s, speed: 8.748584 samples/s, speed: 4479.274901 tokens/s, learning rate: 2.534e-05, loss_scalings: 2814.750488, pp_loss: 6.743724
[INFO] 2021-07-12 19:23:30,960 [run_pretraining.py:  512]:	********exe.run_2535******* 
[INFO] 2021-07-12 19:23:31,864 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:31,865 [run_pretraining.py:  534]:	loss/total_loss, 7.2422637939453125, 2536
[INFO] 2021-07-12 19:23:31,865 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2422637939453125, 2536
[INFO] 2021-07-12 19:23:31,865 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5350000214530155e-05, 2536
[INFO] 2021-07-12 19:23:31,865 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2536
[INFO] 2021-07-12 19:23:31,865 [run_pretraining.py:  558]:	worker_index: 6, step: 2536, cost: 7.242264, mlm loss: 7.242264, speed: 1.105580 steps/s, speed: 8.844642 samples/s, speed: 4528.456792 tokens/s, learning rate: 2.535e-05, loss_scalings: 2814.750488, pp_loss: 6.370910
[INFO] 2021-07-12 19:23:31,865 [run_pretraining.py:  512]:	********exe.run_2536******* 
[INFO] 2021-07-12 19:23:32,782 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:32,782 [run_pretraining.py:  534]:	loss/total_loss, 6.625993728637695, 2537
[INFO] 2021-07-12 19:23:32,782 [run_pretraining.py:  535]:	loss/mlm_loss, 6.625993728637695, 2537
[INFO] 2021-07-12 19:23:32,782 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5359999199281447e-05, 2537
[INFO] 2021-07-12 19:23:32,783 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2537
[INFO] 2021-07-12 19:23:32,783 [run_pretraining.py:  558]:	worker_index: 6, step: 2537, cost: 6.625994, mlm loss: 6.625994, speed: 1.090742 steps/s, speed: 8.725933 samples/s, speed: 4467.677662 tokens/s, learning rate: 2.536e-05, loss_scalings: 2814.750488, pp_loss: 7.251942
[INFO] 2021-07-12 19:23:32,783 [run_pretraining.py:  512]:	********exe.run_2537******* 
[INFO] 2021-07-12 19:23:33,724 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:33,725 [run_pretraining.py:  534]:	loss/total_loss, 7.283254146575928, 2538
[INFO] 2021-07-12 19:23:33,725 [run_pretraining.py:  535]:	loss/mlm_loss, 7.283254146575928, 2538
[INFO] 2021-07-12 19:23:33,725 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5369998184032738e-05, 2538
[INFO] 2021-07-12 19:23:33,725 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2538
[INFO] 2021-07-12 19:23:33,725 [run_pretraining.py:  558]:	worker_index: 6, step: 2538, cost: 7.283254, mlm loss: 7.283254, speed: 1.061913 steps/s, speed: 8.495305 samples/s, speed: 4349.596048 tokens/s, learning rate: 2.537e-05, loss_scalings: 2814.750488, pp_loss: 7.201412
[INFO] 2021-07-12 19:23:33,725 [run_pretraining.py:  512]:	********exe.run_2538******* 
[INFO] 2021-07-12 19:23:34,665 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:34,666 [run_pretraining.py:  534]:	loss/total_loss, 6.135747909545898, 2539
[INFO] 2021-07-12 19:23:34,666 [run_pretraining.py:  535]:	loss/mlm_loss, 6.135747909545898, 2539
[INFO] 2021-07-12 19:23:34,666 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5379998987773433e-05, 2539
[INFO] 2021-07-12 19:23:34,666 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2539
[INFO] 2021-07-12 19:23:34,666 [run_pretraining.py:  558]:	worker_index: 6, step: 2539, cost: 6.135748, mlm loss: 6.135748, speed: 1.063152 steps/s, speed: 8.505217 samples/s, speed: 4354.670923 tokens/s, learning rate: 2.538e-05, loss_scalings: 2814.750488, pp_loss: 7.034286
[INFO] 2021-07-12 19:23:34,666 [run_pretraining.py:  512]:	********exe.run_2539******* 
[INFO] 2021-07-12 19:23:35,713 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:35,714 [run_pretraining.py:  534]:	loss/total_loss, 6.832700252532959, 2540
[INFO] 2021-07-12 19:23:35,714 [run_pretraining.py:  535]:	loss/mlm_loss, 6.832700252532959, 2540
[INFO] 2021-07-12 19:23:35,714 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5389997972524725e-05, 2540
[INFO] 2021-07-12 19:23:35,714 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2540
[INFO] 2021-07-12 19:23:35,714 [run_pretraining.py:  558]:	worker_index: 6, step: 2540, cost: 6.832700, mlm loss: 6.832700, speed: 0.955151 steps/s, speed: 7.641212 samples/s, speed: 3912.300312 tokens/s, learning rate: 2.539e-05, loss_scalings: 2814.750488, pp_loss: 6.889474
[INFO] 2021-07-12 19:23:35,714 [run_pretraining.py:  512]:	********exe.run_2540******* 
[INFO] 2021-07-12 19:23:36,776 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:36,777 [run_pretraining.py:  534]:	loss/total_loss, 7.510751724243164, 2541
[INFO] 2021-07-12 19:23:36,777 [run_pretraining.py:  535]:	loss/mlm_loss, 7.510751724243164, 2541
[INFO] 2021-07-12 19:23:36,777 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5400000595254824e-05, 2541
[INFO] 2021-07-12 19:23:36,777 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2541
[INFO] 2021-07-12 19:23:36,777 [run_pretraining.py:  558]:	worker_index: 6, step: 2541, cost: 7.510752, mlm loss: 7.510752, speed: 0.941398 steps/s, speed: 7.531186 samples/s, speed: 3855.967342 tokens/s, learning rate: 2.540e-05, loss_scalings: 2814.750488, pp_loss: 7.363271
[INFO] 2021-07-12 19:23:36,777 [run_pretraining.py:  512]:	********exe.run_2541******* 
[INFO] 2021-07-12 19:23:37,818 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:37,819 [run_pretraining.py:  534]:	loss/total_loss, 6.836084365844727, 2542
[INFO] 2021-07-12 19:23:37,819 [run_pretraining.py:  535]:	loss/mlm_loss, 6.836084365844727, 2542
[INFO] 2021-07-12 19:23:37,819 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5409999580006115e-05, 2542
[INFO] 2021-07-12 19:23:37,819 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2542
[INFO] 2021-07-12 19:23:37,819 [run_pretraining.py:  558]:	worker_index: 6, step: 2542, cost: 6.836084, mlm loss: 6.836084, speed: 0.959963 steps/s, speed: 7.679706 samples/s, speed: 3932.009406 tokens/s, learning rate: 2.541e-05, loss_scalings: 2814.750488, pp_loss: 7.088295
[INFO] 2021-07-12 19:23:37,819 [run_pretraining.py:  512]:	********exe.run_2542******* 
[INFO] 2021-07-12 19:23:38,867 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:38,868 [run_pretraining.py:  534]:	loss/total_loss, 7.050461769104004, 2543
[INFO] 2021-07-12 19:23:38,868 [run_pretraining.py:  535]:	loss/mlm_loss, 7.050461769104004, 2543
[INFO] 2021-07-12 19:23:38,868 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.542000038374681e-05, 2543
[INFO] 2021-07-12 19:23:38,868 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2543
[INFO] 2021-07-12 19:23:38,868 [run_pretraining.py:  558]:	worker_index: 6, step: 2543, cost: 7.050462, mlm loss: 7.050462, speed: 0.953869 steps/s, speed: 7.630954 samples/s, speed: 3907.048201 tokens/s, learning rate: 2.542e-05, loss_scalings: 2814.750488, pp_loss: 6.093452
[INFO] 2021-07-12 19:23:38,869 [run_pretraining.py:  512]:	********exe.run_2543******* 
[INFO] 2021-07-12 19:23:39,919 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:39,920 [run_pretraining.py:  534]:	loss/total_loss, 7.34987211227417, 2544
[INFO] 2021-07-12 19:23:39,920 [run_pretraining.py:  535]:	loss/mlm_loss, 7.34987211227417, 2544
[INFO] 2021-07-12 19:23:39,920 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5429999368498102e-05, 2544
[INFO] 2021-07-12 19:23:39,920 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2544
[INFO] 2021-07-12 19:23:39,920 [run_pretraining.py:  558]:	worker_index: 6, step: 2544, cost: 7.349872, mlm loss: 7.349872, speed: 0.951292 steps/s, speed: 7.610333 samples/s, speed: 3896.490724 tokens/s, learning rate: 2.543e-05, loss_scalings: 2814.750488, pp_loss: 6.748071
[INFO] 2021-07-12 19:23:39,920 [run_pretraining.py:  512]:	********exe.run_2544******* 
[INFO] 2021-07-12 19:23:40,966 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:40,967 [run_pretraining.py:  534]:	loss/total_loss, 7.76762580871582, 2545
[INFO] 2021-07-12 19:23:40,967 [run_pretraining.py:  535]:	loss/mlm_loss, 7.76762580871582, 2545
[INFO] 2021-07-12 19:23:40,967 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5440000172238797e-05, 2545
[INFO] 2021-07-12 19:23:40,967 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2545
[INFO] 2021-07-12 19:23:40,967 [run_pretraining.py:  558]:	worker_index: 6, step: 2545, cost: 7.767626, mlm loss: 7.767626, speed: 0.955877 steps/s, speed: 7.647012 samples/s, speed: 3915.270259 tokens/s, learning rate: 2.544e-05, loss_scalings: 2814.750488, pp_loss: 7.201131
[INFO] 2021-07-12 19:23:40,967 [run_pretraining.py:  512]:	********exe.run_2545******* 
[INFO] 2021-07-12 19:23:42,024 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:42,024 [run_pretraining.py:  534]:	loss/total_loss, 7.299749851226807, 2546
[INFO] 2021-07-12 19:23:42,024 [run_pretraining.py:  535]:	loss/mlm_loss, 7.299749851226807, 2546
[INFO] 2021-07-12 19:23:42,024 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.544999915699009e-05, 2546
[INFO] 2021-07-12 19:23:42,025 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2546
[INFO] 2021-07-12 19:23:42,025 [run_pretraining.py:  558]:	worker_index: 6, step: 2546, cost: 7.299750, mlm loss: 7.299750, speed: 0.946395 steps/s, speed: 7.571161 samples/s, speed: 3876.434480 tokens/s, learning rate: 2.545e-05, loss_scalings: 2814.750488, pp_loss: 7.246091
[INFO] 2021-07-12 19:23:42,025 [run_pretraining.py:  512]:	********exe.run_2546******* 
[INFO] 2021-07-12 19:23:43,082 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:43,082 [run_pretraining.py:  534]:	loss/total_loss, 7.559547424316406, 2547
[INFO] 2021-07-12 19:23:43,082 [run_pretraining.py:  535]:	loss/mlm_loss, 7.559547424316406, 2547
[INFO] 2021-07-12 19:23:43,082 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.545999814174138e-05, 2547
[INFO] 2021-07-12 19:23:43,082 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2547
[INFO] 2021-07-12 19:23:43,083 [run_pretraining.py:  558]:	worker_index: 6, step: 2547, cost: 7.559547, mlm loss: 7.559547, speed: 0.945880 steps/s, speed: 7.567039 samples/s, speed: 3874.324172 tokens/s, learning rate: 2.546e-05, loss_scalings: 2814.750488, pp_loss: 7.283954
[INFO] 2021-07-12 19:23:43,083 [run_pretraining.py:  512]:	********exe.run_2547******* 
[INFO] 2021-07-12 19:23:44,141 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:44,142 [run_pretraining.py:  534]:	loss/total_loss, 7.220973014831543, 2548
[INFO] 2021-07-12 19:23:44,142 [run_pretraining.py:  535]:	loss/mlm_loss, 7.220973014831543, 2548
[INFO] 2021-07-12 19:23:44,142 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.547000076447148e-05, 2548
[INFO] 2021-07-12 19:23:44,142 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2548
[INFO] 2021-07-12 19:23:44,142 [run_pretraining.py:  558]:	worker_index: 6, step: 2548, cost: 7.220973, mlm loss: 7.220973, speed: 0.944273 steps/s, speed: 7.554184 samples/s, speed: 3867.742285 tokens/s, learning rate: 2.547e-05, loss_scalings: 2814.750488, pp_loss: 7.324014
[INFO] 2021-07-12 19:23:44,142 [run_pretraining.py:  512]:	********exe.run_2548******* 
[INFO] 2021-07-12 19:23:45,206 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:45,207 [run_pretraining.py:  534]:	loss/total_loss, 6.384200096130371, 2549
[INFO] 2021-07-12 19:23:45,207 [run_pretraining.py:  535]:	loss/mlm_loss, 6.384200096130371, 2549
[INFO] 2021-07-12 19:23:45,207 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5479997930233367e-05, 2549
[INFO] 2021-07-12 19:23:45,207 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2549
[INFO] 2021-07-12 19:23:45,207 [run_pretraining.py:  558]:	worker_index: 6, step: 2549, cost: 6.384200, mlm loss: 6.384200, speed: 0.939799 steps/s, speed: 7.518392 samples/s, speed: 3849.416575 tokens/s, learning rate: 2.548e-05, loss_scalings: 2814.750488, pp_loss: 7.294420
[INFO] 2021-07-12 19:23:45,207 [run_pretraining.py:  512]:	********exe.run_2549******* 
[INFO] 2021-07-12 19:23:46,280 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:46,281 [run_pretraining.py:  534]:	loss/total_loss, 7.561804294586182, 2550
[INFO] 2021-07-12 19:23:46,281 [run_pretraining.py:  535]:	loss/mlm_loss, 7.561804294586182, 2550
[INFO] 2021-07-12 19:23:46,281 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5490000552963465e-05, 2550
[INFO] 2021-07-12 19:23:46,281 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2550
[INFO] 2021-07-12 19:23:46,281 [run_pretraining.py:  558]:	worker_index: 6, step: 2550, cost: 7.561804, mlm loss: 7.561804, speed: 0.931531 steps/s, speed: 7.452251 samples/s, speed: 3815.552645 tokens/s, learning rate: 2.549e-05, loss_scalings: 2814.750488, pp_loss: 7.318068
[INFO] 2021-07-12 19:23:46,281 [run_pretraining.py:  512]:	********exe.run_2550******* 
[INFO] 2021-07-12 19:23:47,336 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:47,337 [run_pretraining.py:  534]:	loss/total_loss, 6.759786128997803, 2551
[INFO] 2021-07-12 19:23:47,337 [run_pretraining.py:  535]:	loss/mlm_loss, 6.759786128997803, 2551
[INFO] 2021-07-12 19:23:47,337 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5499999537714757e-05, 2551
[INFO] 2021-07-12 19:23:47,337 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2551
[INFO] 2021-07-12 19:23:47,337 [run_pretraining.py:  558]:	worker_index: 6, step: 2551, cost: 6.759786, mlm loss: 6.759786, speed: 0.947823 steps/s, speed: 7.582587 samples/s, speed: 3882.284352 tokens/s, learning rate: 2.550e-05, loss_scalings: 2814.750488, pp_loss: 7.158168
[INFO] 2021-07-12 19:23:47,337 [run_pretraining.py:  512]:	********exe.run_2551******* 
[INFO] 2021-07-12 19:23:48,389 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:48,390 [run_pretraining.py:  534]:	loss/total_loss, 7.540228843688965, 2552
[INFO] 2021-07-12 19:23:48,390 [run_pretraining.py:  535]:	loss/mlm_loss, 7.540228843688965, 2552
[INFO] 2021-07-12 19:23:48,390 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5510000341455452e-05, 2552
[INFO] 2021-07-12 19:23:48,390 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2552
[INFO] 2021-07-12 19:23:48,390 [run_pretraining.py:  558]:	worker_index: 6, step: 2552, cost: 7.540229, mlm loss: 7.540229, speed: 0.950368 steps/s, speed: 7.602943 samples/s, speed: 3892.706667 tokens/s, learning rate: 2.551e-05, loss_scalings: 2814.750488, pp_loss: 6.455401
[INFO] 2021-07-12 19:23:48,390 [run_pretraining.py:  512]:	********exe.run_2552******* 
[INFO] 2021-07-12 19:23:49,451 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:49,452 [run_pretraining.py:  534]:	loss/total_loss, 7.119703769683838, 2553
[INFO] 2021-07-12 19:23:49,452 [run_pretraining.py:  535]:	loss/mlm_loss, 7.119703769683838, 2553
[INFO] 2021-07-12 19:23:49,452 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5519999326206744e-05, 2553
[INFO] 2021-07-12 19:23:49,452 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2553
[INFO] 2021-07-12 19:23:49,452 [run_pretraining.py:  558]:	worker_index: 6, step: 2553, cost: 7.119704, mlm loss: 7.119704, speed: 0.942196 steps/s, speed: 7.537571 samples/s, speed: 3859.236356 tokens/s, learning rate: 2.552e-05, loss_scalings: 2814.750488, pp_loss: 7.234783
[INFO] 2021-07-12 19:23:49,452 [run_pretraining.py:  512]:	********exe.run_2553******* 
[INFO] 2021-07-12 19:23:50,498 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:50,499 [run_pretraining.py:  534]:	loss/total_loss, 7.352138519287109, 2554
[INFO] 2021-07-12 19:23:50,499 [run_pretraining.py:  535]:	loss/mlm_loss, 7.352138519287109, 2554
[INFO] 2021-07-12 19:23:50,499 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5529998310958035e-05, 2554
[INFO] 2021-07-12 19:23:50,499 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2554
[INFO] 2021-07-12 19:23:50,499 [run_pretraining.py:  558]:	worker_index: 6, step: 2554, cost: 7.352139, mlm loss: 7.352139, speed: 0.955771 steps/s, speed: 7.646165 samples/s, speed: 3914.836657 tokens/s, learning rate: 2.553e-05, loss_scalings: 2814.750488, pp_loss: 6.960539
[INFO] 2021-07-12 19:23:50,499 [run_pretraining.py:  512]:	********exe.run_2554******* 
[INFO] 2021-07-12 19:23:51,554 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:51,555 [run_pretraining.py:  534]:	loss/total_loss, 7.267690181732178, 2555
[INFO] 2021-07-12 19:23:51,555 [run_pretraining.py:  535]:	loss/mlm_loss, 7.267690181732178, 2555
[INFO] 2021-07-12 19:23:51,555 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.553999911469873e-05, 2555
[INFO] 2021-07-12 19:23:51,555 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2555
[INFO] 2021-07-12 19:23:51,555 [run_pretraining.py:  558]:	worker_index: 6, step: 2555, cost: 7.267690, mlm loss: 7.267690, speed: 0.947357 steps/s, speed: 7.578855 samples/s, speed: 3880.373626 tokens/s, learning rate: 2.554e-05, loss_scalings: 2814.750488, pp_loss: 7.572442
[INFO] 2021-07-12 19:23:51,555 [run_pretraining.py:  512]:	********exe.run_2555******* 
[INFO] 2021-07-12 19:23:52,530 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:52,531 [run_pretraining.py:  534]:	loss/total_loss, 7.096439838409424, 2556
[INFO] 2021-07-12 19:23:52,531 [run_pretraining.py:  535]:	loss/mlm_loss, 7.096439838409424, 2556
[INFO] 2021-07-12 19:23:52,531 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5549998099450022e-05, 2556
[INFO] 2021-07-12 19:23:52,531 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2556
[INFO] 2021-07-12 19:23:52,531 [run_pretraining.py:  558]:	worker_index: 6, step: 2556, cost: 7.096440, mlm loss: 7.096440, speed: 1.025594 steps/s, speed: 8.204754 samples/s, speed: 4200.833958 tokens/s, learning rate: 2.555e-05, loss_scalings: 2814.750488, pp_loss: 7.212909
[INFO] 2021-07-12 19:23:52,531 [run_pretraining.py:  512]:	********exe.run_2556******* 
[INFO] 2021-07-12 19:23:53,501 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:53,501 [run_pretraining.py:  534]:	loss/total_loss, 7.569629669189453, 2557
[INFO] 2021-07-12 19:23:53,501 [run_pretraining.py:  535]:	loss/mlm_loss, 7.569629669189453, 2557
[INFO] 2021-07-12 19:23:53,501 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.556000072218012e-05, 2557
[INFO] 2021-07-12 19:23:53,501 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2557
[INFO] 2021-07-12 19:23:53,501 [run_pretraining.py:  558]:	worker_index: 6, step: 2557, cost: 7.569630, mlm loss: 7.569630, speed: 1.031187 steps/s, speed: 8.249495 samples/s, speed: 4223.741291 tokens/s, learning rate: 2.556e-05, loss_scalings: 2814.750488, pp_loss: 7.383101
[INFO] 2021-07-12 19:23:53,502 [run_pretraining.py:  512]:	********exe.run_2557******* 
[INFO] 2021-07-12 19:23:54,477 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:54,477 [run_pretraining.py:  534]:	loss/total_loss, 7.443158149719238, 2558
[INFO] 2021-07-12 19:23:54,478 [run_pretraining.py:  535]:	loss/mlm_loss, 7.443158149719238, 2558
[INFO] 2021-07-12 19:23:54,478 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.556999788794201e-05, 2558
[INFO] 2021-07-12 19:23:54,478 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2558
[INFO] 2021-07-12 19:23:54,478 [run_pretraining.py:  558]:	worker_index: 6, step: 2558, cost: 7.443158, mlm loss: 7.443158, speed: 1.025001 steps/s, speed: 8.200012 samples/s, speed: 4198.406056 tokens/s, learning rate: 2.557e-05, loss_scalings: 2814.750488, pp_loss: 7.627351
[INFO] 2021-07-12 19:23:54,478 [run_pretraining.py:  512]:	********exe.run_2558******* 
[INFO] 2021-07-12 19:23:55,461 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:55,461 [run_pretraining.py:  534]:	loss/total_loss, 7.684000015258789, 2559
[INFO] 2021-07-12 19:23:55,461 [run_pretraining.py:  535]:	loss/mlm_loss, 7.684000015258789, 2559
[INFO] 2021-07-12 19:23:55,461 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5580000510672107e-05, 2559
[INFO] 2021-07-12 19:23:55,462 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2559
[INFO] 2021-07-12 19:23:55,462 [run_pretraining.py:  558]:	worker_index: 6, step: 2559, cost: 7.684000, mlm loss: 7.684000, speed: 1.017109 steps/s, speed: 8.136870 samples/s, speed: 4166.077200 tokens/s, learning rate: 2.558e-05, loss_scalings: 2814.750488, pp_loss: 7.314660
[INFO] 2021-07-12 19:23:55,462 [run_pretraining.py:  512]:	********exe.run_2559******* 
[INFO] 2021-07-12 19:23:56,432 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:56,432 [run_pretraining.py:  534]:	loss/total_loss, 7.412936687469482, 2560
[INFO] 2021-07-12 19:23:56,432 [run_pretraining.py:  535]:	loss/mlm_loss, 7.412936687469482, 2560
[INFO] 2021-07-12 19:23:56,433 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.55899994954234e-05, 2560
[INFO] 2021-07-12 19:23:56,433 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2560
[INFO] 2021-07-12 19:23:56,433 [run_pretraining.py:  558]:	worker_index: 6, step: 2560, cost: 7.412937, mlm loss: 7.412937, speed: 1.030542 steps/s, speed: 8.244334 samples/s, speed: 4221.099117 tokens/s, learning rate: 2.559e-05, loss_scalings: 2814.750488, pp_loss: 7.202502
[INFO] 2021-07-12 19:23:56,433 [run_pretraining.py:  512]:	********exe.run_2560******* 
[INFO] 2021-07-12 19:23:57,401 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:57,401 [run_pretraining.py:  534]:	loss/total_loss, 7.32209587097168, 2561
[INFO] 2021-07-12 19:23:57,402 [run_pretraining.py:  535]:	loss/mlm_loss, 7.32209587097168, 2561
[INFO] 2021-07-12 19:23:57,402 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5600000299164094e-05, 2561
[INFO] 2021-07-12 19:23:57,402 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2561
[INFO] 2021-07-12 19:23:57,402 [run_pretraining.py:  558]:	worker_index: 6, step: 2561, cost: 7.322096, mlm loss: 7.322096, speed: 1.032634 steps/s, speed: 8.261069 samples/s, speed: 4229.667573 tokens/s, learning rate: 2.560e-05, loss_scalings: 2814.750488, pp_loss: 7.253791
[INFO] 2021-07-12 19:23:57,402 [run_pretraining.py:  512]:	********exe.run_2561******* 
[INFO] 2021-07-12 19:23:58,388 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:58,389 [run_pretraining.py:  534]:	loss/total_loss, 7.9616875648498535, 2562
[INFO] 2021-07-12 19:23:58,389 [run_pretraining.py:  535]:	loss/mlm_loss, 7.9616875648498535, 2562
[INFO] 2021-07-12 19:23:58,389 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5609999283915386e-05, 2562
[INFO] 2021-07-12 19:23:58,389 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2562
[INFO] 2021-07-12 19:23:58,389 [run_pretraining.py:  558]:	worker_index: 6, step: 2562, cost: 7.961688, mlm loss: 7.961688, speed: 1.013261 steps/s, speed: 8.106089 samples/s, speed: 4150.317324 tokens/s, learning rate: 2.561e-05, loss_scalings: 2814.750488, pp_loss: 7.343305
[INFO] 2021-07-12 19:23:58,390 [run_pretraining.py:  512]:	********exe.run_2562******* 
[INFO] 2021-07-12 19:23:59,375 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:59,376 [run_pretraining.py:  534]:	loss/total_loss, 6.98163366317749, 2563
[INFO] 2021-07-12 19:23:59,376 [run_pretraining.py:  535]:	loss/mlm_loss, 6.98163366317749, 2563
[INFO] 2021-07-12 19:23:59,376 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5619998268666677e-05, 2563
[INFO] 2021-07-12 19:23:59,376 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2563
[INFO] 2021-07-12 19:23:59,376 [run_pretraining.py:  558]:	worker_index: 6, step: 2563, cost: 6.981634, mlm loss: 6.981634, speed: 1.014389 steps/s, speed: 8.115109 samples/s, speed: 4154.935580 tokens/s, learning rate: 2.562e-05, loss_scalings: 2814.750488, pp_loss: 7.107046
[INFO] 2021-07-12 19:23:59,376 [run_pretraining.py:  512]:	********exe.run_2563******* 
[INFO] 2021-07-12 19:24:00,353 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:00,353 [run_pretraining.py:  534]:	loss/total_loss, 8.138821601867676, 2564
[INFO] 2021-07-12 19:24:00,354 [run_pretraining.py:  535]:	loss/mlm_loss, 8.138821601867676, 2564
[INFO] 2021-07-12 19:24:00,354 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5629999072407372e-05, 2564
[INFO] 2021-07-12 19:24:00,354 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2564
[INFO] 2021-07-12 19:24:00,354 [run_pretraining.py:  558]:	worker_index: 6, step: 2564, cost: 8.138822, mlm loss: 8.138822, speed: 1.023435 steps/s, speed: 8.187478 samples/s, speed: 4191.988990 tokens/s, learning rate: 2.563e-05, loss_scalings: 2814.750488, pp_loss: 7.113901
[INFO] 2021-07-12 19:24:00,354 [run_pretraining.py:  512]:	********exe.run_2564******* 
[INFO] 2021-07-12 19:24:01,349 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:01,350 [run_pretraining.py:  534]:	loss/total_loss, 6.96732234954834, 2565
[INFO] 2021-07-12 19:24:01,350 [run_pretraining.py:  535]:	loss/mlm_loss, 6.96732234954834, 2565
[INFO] 2021-07-12 19:24:01,350 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5639998057158664e-05, 2565
[INFO] 2021-07-12 19:24:01,350 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2565
[INFO] 2021-07-12 19:24:01,350 [run_pretraining.py:  558]:	worker_index: 6, step: 2565, cost: 6.967322, mlm loss: 6.967322, speed: 1.004595 steps/s, speed: 8.036757 samples/s, speed: 4114.819471 tokens/s, learning rate: 2.564e-05, loss_scalings: 2814.750488, pp_loss: 7.224269
[INFO] 2021-07-12 19:24:01,350 [run_pretraining.py:  512]:	********exe.run_2565******* 
[INFO] 2021-07-12 19:24:02,319 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:02,320 [run_pretraining.py:  534]:	loss/total_loss, 7.7510528564453125, 2566
[INFO] 2021-07-12 19:24:02,320 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7510528564453125, 2566
[INFO] 2021-07-12 19:24:02,320 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5650000679888763e-05, 2566
[INFO] 2021-07-12 19:24:02,320 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2566
[INFO] 2021-07-12 19:24:02,320 [run_pretraining.py:  558]:	worker_index: 6, step: 2566, cost: 7.751053, mlm loss: 7.751053, speed: 1.031144 steps/s, speed: 8.249154 samples/s, speed: 4223.566843 tokens/s, learning rate: 2.565e-05, loss_scalings: 2814.750488, pp_loss: 7.438190
[INFO] 2021-07-12 19:24:02,321 [run_pretraining.py:  512]:	********exe.run_2566******* 
[INFO] 2021-07-12 19:24:03,299 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:03,300 [run_pretraining.py:  534]:	loss/total_loss, 7.508508682250977, 2567
[INFO] 2021-07-12 19:24:03,300 [run_pretraining.py:  535]:	loss/mlm_loss, 7.508508682250977, 2567
[INFO] 2021-07-12 19:24:03,300 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.565999784565065e-05, 2567
[INFO] 2021-07-12 19:24:03,300 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2567
[INFO] 2021-07-12 19:24:03,300 [run_pretraining.py:  558]:	worker_index: 6, step: 2567, cost: 7.508509, mlm loss: 7.508509, speed: 1.021520 steps/s, speed: 8.172158 samples/s, speed: 4184.144986 tokens/s, learning rate: 2.566e-05, loss_scalings: 2814.750488, pp_loss: 7.453270
[INFO] 2021-07-12 19:24:03,300 [run_pretraining.py:  512]:	********exe.run_2567******* 
[INFO] 2021-07-12 19:24:04,270 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:04,271 [run_pretraining.py:  534]:	loss/total_loss, 6.502906322479248, 2568
[INFO] 2021-07-12 19:24:04,271 [run_pretraining.py:  535]:	loss/mlm_loss, 6.502906322479248, 2568
[INFO] 2021-07-12 19:24:04,271 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.567000046838075e-05, 2568
[INFO] 2021-07-12 19:24:04,271 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2568
[INFO] 2021-07-12 19:24:04,271 [run_pretraining.py:  558]:	worker_index: 6, step: 2568, cost: 6.502906, mlm loss: 6.502906, speed: 1.030198 steps/s, speed: 8.241580 samples/s, speed: 4219.689097 tokens/s, learning rate: 2.567e-05, loss_scalings: 2814.750488, pp_loss: 7.101377
[INFO] 2021-07-12 19:24:04,272 [run_pretraining.py:  512]:	********exe.run_2568******* 
[INFO] 2021-07-12 19:24:05,244 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:05,245 [run_pretraining.py:  534]:	loss/total_loss, 6.837186813354492, 2569
[INFO] 2021-07-12 19:24:05,245 [run_pretraining.py:  535]:	loss/mlm_loss, 6.837186813354492, 2569
[INFO] 2021-07-12 19:24:05,245 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.567999945313204e-05, 2569
[INFO] 2021-07-12 19:24:05,245 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2569
[INFO] 2021-07-12 19:24:05,245 [run_pretraining.py:  558]:	worker_index: 6, step: 2569, cost: 6.837187, mlm loss: 6.837187, speed: 1.027471 steps/s, speed: 8.219768 samples/s, speed: 4208.521116 tokens/s, learning rate: 2.568e-05, loss_scalings: 2814.750488, pp_loss: 6.933601
[INFO] 2021-07-12 19:24:05,246 [run_pretraining.py:  512]:	********exe.run_2569******* 
[INFO] 2021-07-12 19:24:06,234 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:06,235 [run_pretraining.py:  534]:	loss/total_loss, 7.2565765380859375, 2570
[INFO] 2021-07-12 19:24:06,235 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2565765380859375, 2570
[INFO] 2021-07-12 19:24:06,235 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5690000256872736e-05, 2570
[INFO] 2021-07-12 19:24:06,235 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2570
[INFO] 2021-07-12 19:24:06,235 [run_pretraining.py:  558]:	worker_index: 6, step: 2570, cost: 7.256577, mlm loss: 7.256577, speed: 1.011165 steps/s, speed: 8.089319 samples/s, speed: 4141.731513 tokens/s, learning rate: 2.569e-05, loss_scalings: 2814.750488, pp_loss: 7.337721
[INFO] 2021-07-12 19:24:06,235 [run_pretraining.py:  512]:	********exe.run_2570******* 
[INFO] 2021-07-12 19:24:07,227 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:07,228 [run_pretraining.py:  534]:	loss/total_loss, 7.849818706512451, 2571
[INFO] 2021-07-12 19:24:07,228 [run_pretraining.py:  535]:	loss/mlm_loss, 7.849818706512451, 2571
[INFO] 2021-07-12 19:24:07,228 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5699999241624027e-05, 2571
[INFO] 2021-07-12 19:24:07,228 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2571
[INFO] 2021-07-12 19:24:07,228 [run_pretraining.py:  558]:	worker_index: 6, step: 2571, cost: 7.849819, mlm loss: 7.849819, speed: 1.007853 steps/s, speed: 8.062824 samples/s, speed: 4128.165666 tokens/s, learning rate: 2.570e-05, loss_scalings: 2814.750488, pp_loss: 7.410293
[INFO] 2021-07-12 19:24:07,228 [run_pretraining.py:  512]:	********exe.run_2571******* 
[INFO] 2021-07-12 19:24:08,210 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:08,210 [run_pretraining.py:  534]:	loss/total_loss, 7.1355438232421875, 2572
[INFO] 2021-07-12 19:24:08,210 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1355438232421875, 2572
[INFO] 2021-07-12 19:24:08,211 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.570999822637532e-05, 2572
[INFO] 2021-07-12 19:24:08,211 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2572
[INFO] 2021-07-12 19:24:08,211 [run_pretraining.py:  558]:	worker_index: 6, step: 2572, cost: 7.135544, mlm loss: 7.135544, speed: 1.018418 steps/s, speed: 8.147341 samples/s, speed: 4171.438488 tokens/s, learning rate: 2.571e-05, loss_scalings: 2814.750488, pp_loss: 7.314179
[INFO] 2021-07-12 19:24:08,211 [run_pretraining.py:  512]:	********exe.run_2572******* 
[INFO] 2021-07-12 19:24:09,185 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:09,185 [run_pretraining.py:  534]:	loss/total_loss, 7.231522560119629, 2573
[INFO] 2021-07-12 19:24:09,186 [run_pretraining.py:  535]:	loss/mlm_loss, 7.231522560119629, 2573
[INFO] 2021-07-12 19:24:09,186 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5719999030116014e-05, 2573
[INFO] 2021-07-12 19:24:09,186 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2573
[INFO] 2021-07-12 19:24:09,186 [run_pretraining.py:  558]:	worker_index: 6, step: 2573, cost: 7.231523, mlm loss: 7.231523, speed: 1.026289 steps/s, speed: 8.210315 samples/s, speed: 4203.681206 tokens/s, learning rate: 2.572e-05, loss_scalings: 2814.750488, pp_loss: 7.530547
[INFO] 2021-07-12 19:24:09,186 [run_pretraining.py:  512]:	********exe.run_2573******* 
[INFO] 2021-07-12 19:24:10,161 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:10,162 [run_pretraining.py:  534]:	loss/total_loss, 7.012452125549316, 2574
[INFO] 2021-07-12 19:24:10,162 [run_pretraining.py:  535]:	loss/mlm_loss, 7.012452125549316, 2574
[INFO] 2021-07-12 19:24:10,162 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5729998014867306e-05, 2574
[INFO] 2021-07-12 19:24:10,162 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2574
[INFO] 2021-07-12 19:24:10,162 [run_pretraining.py:  558]:	worker_index: 6, step: 2574, cost: 7.012452, mlm loss: 7.012452, speed: 1.024867 steps/s, speed: 8.198938 samples/s, speed: 4197.856190 tokens/s, learning rate: 2.573e-05, loss_scalings: 2814.750488, pp_loss: 7.149524
[INFO] 2021-07-12 19:24:10,162 [run_pretraining.py:  512]:	********exe.run_2574******* 
[INFO] 2021-07-12 19:24:11,115 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:11,116 [run_pretraining.py:  534]:	loss/total_loss, 7.22694206237793, 2575
[INFO] 2021-07-12 19:24:11,116 [run_pretraining.py:  535]:	loss/mlm_loss, 7.22694206237793, 2575
[INFO] 2021-07-12 19:24:11,116 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5740000637597404e-05, 2575
[INFO] 2021-07-12 19:24:11,116 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2575
[INFO] 2021-07-12 19:24:11,116 [run_pretraining.py:  558]:	worker_index: 6, step: 2575, cost: 7.226942, mlm loss: 7.226942, speed: 1.049081 steps/s, speed: 8.392649 samples/s, speed: 4297.036319 tokens/s, learning rate: 2.574e-05, loss_scalings: 2814.750488, pp_loss: 7.495283
[INFO] 2021-07-12 19:24:11,116 [run_pretraining.py:  512]:	********exe.run_2575******* 
[INFO] 2021-07-12 19:24:12,029 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:12,030 [run_pretraining.py:  534]:	loss/total_loss, 7.811310291290283, 2576
[INFO] 2021-07-12 19:24:12,030 [run_pretraining.py:  535]:	loss/mlm_loss, 7.811310291290283, 2576
[INFO] 2021-07-12 19:24:12,030 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5749997803359292e-05, 2576
[INFO] 2021-07-12 19:24:12,030 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2576
[INFO] 2021-07-12 19:24:12,030 [run_pretraining.py:  558]:	worker_index: 6, step: 2576, cost: 7.811310, mlm loss: 7.811310, speed: 1.095018 steps/s, speed: 8.760145 samples/s, speed: 4485.194486 tokens/s, learning rate: 2.575e-05, loss_scalings: 2814.750488, pp_loss: 7.395832
[INFO] 2021-07-12 19:24:12,030 [run_pretraining.py:  512]:	********exe.run_2576******* 
[INFO] 2021-07-12 19:24:12,936 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:12,936 [run_pretraining.py:  534]:	loss/total_loss, 7.11679220199585, 2577
[INFO] 2021-07-12 19:24:12,936 [run_pretraining.py:  535]:	loss/mlm_loss, 7.11679220199585, 2577
[INFO] 2021-07-12 19:24:12,936 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.576000042608939e-05, 2577
[INFO] 2021-07-12 19:24:12,936 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2577
[INFO] 2021-07-12 19:24:12,936 [run_pretraining.py:  558]:	worker_index: 6, step: 2577, cost: 7.116792, mlm loss: 7.116792, speed: 1.104230 steps/s, speed: 8.833840 samples/s, speed: 4522.926167 tokens/s, learning rate: 2.576e-05, loss_scalings: 2814.750488, pp_loss: 7.537419
[INFO] 2021-07-12 19:24:12,937 [run_pretraining.py:  512]:	********exe.run_2577******* 
[INFO] 2021-07-12 19:24:13,842 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:13,843 [run_pretraining.py:  534]:	loss/total_loss, 7.270176410675049, 2578
[INFO] 2021-07-12 19:24:13,843 [run_pretraining.py:  535]:	loss/mlm_loss, 7.270176410675049, 2578
[INFO] 2021-07-12 19:24:13,843 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5769999410840683e-05, 2578
[INFO] 2021-07-12 19:24:13,843 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2578
[INFO] 2021-07-12 19:24:13,843 [run_pretraining.py:  558]:	worker_index: 6, step: 2578, cost: 7.270176, mlm loss: 7.270176, speed: 1.103871 steps/s, speed: 8.830964 samples/s, speed: 4521.453694 tokens/s, learning rate: 2.577e-05, loss_scalings: 2814.750488, pp_loss: 7.461939
[INFO] 2021-07-12 19:24:13,843 [run_pretraining.py:  512]:	********exe.run_2578******* 
[INFO] 2021-07-12 19:24:14,756 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:14,756 [run_pretraining.py:  534]:	loss/total_loss, 3.828184127807617, 2579
[INFO] 2021-07-12 19:24:14,757 [run_pretraining.py:  535]:	loss/mlm_loss, 3.828184127807617, 2579
[INFO] 2021-07-12 19:24:14,757 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5780000214581378e-05, 2579
[INFO] 2021-07-12 19:24:14,757 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2579
[INFO] 2021-07-12 19:24:14,757 [run_pretraining.py:  558]:	worker_index: 6, step: 2579, cost: 3.828184, mlm loss: 3.828184, speed: 1.095185 steps/s, speed: 8.761484 samples/s, speed: 4485.879603 tokens/s, learning rate: 2.578e-05, loss_scalings: 2814.750488, pp_loss: 6.708527
[INFO] 2021-07-12 19:24:14,757 [run_pretraining.py:  512]:	********exe.run_2579******* 
[INFO] 2021-07-12 19:24:15,666 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:15,667 [run_pretraining.py:  534]:	loss/total_loss, 7.535756587982178, 2580
[INFO] 2021-07-12 19:24:15,667 [run_pretraining.py:  535]:	loss/mlm_loss, 7.535756587982178, 2580
[INFO] 2021-07-12 19:24:15,667 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.578999919933267e-05, 2580
[INFO] 2021-07-12 19:24:15,667 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2580
[INFO] 2021-07-12 19:24:15,667 [run_pretraining.py:  558]:	worker_index: 6, step: 2580, cost: 7.535757, mlm loss: 7.535757, speed: 1.099175 steps/s, speed: 8.793401 samples/s, speed: 4502.221432 tokens/s, learning rate: 2.579e-05, loss_scalings: 2814.750488, pp_loss: 7.545162
[INFO] 2021-07-12 19:24:15,667 [run_pretraining.py:  512]:	********exe.run_2580******* 
[INFO] 2021-07-12 19:24:16,574 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:16,574 [run_pretraining.py:  534]:	loss/total_loss, 7.11064338684082, 2581
[INFO] 2021-07-12 19:24:16,574 [run_pretraining.py:  535]:	loss/mlm_loss, 7.11064338684082, 2581
[INFO] 2021-07-12 19:24:16,574 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.579999818408396e-05, 2581
[INFO] 2021-07-12 19:24:16,575 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2581
[INFO] 2021-07-12 19:24:16,575 [run_pretraining.py:  558]:	worker_index: 6, step: 2581, cost: 7.110643, mlm loss: 7.110643, speed: 1.103052 steps/s, speed: 8.824415 samples/s, speed: 4518.100465 tokens/s, learning rate: 2.580e-05, loss_scalings: 2814.750488, pp_loss: 7.290374
[INFO] 2021-07-12 19:24:16,575 [run_pretraining.py:  512]:	********exe.run_2581******* 
[INFO] 2021-07-12 19:24:17,490 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:17,490 [run_pretraining.py:  534]:	loss/total_loss, 7.498646259307861, 2582
[INFO] 2021-07-12 19:24:17,491 [run_pretraining.py:  535]:	loss/mlm_loss, 7.498646259307861, 2582
[INFO] 2021-07-12 19:24:17,491 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5809998987824656e-05, 2582
[INFO] 2021-07-12 19:24:17,491 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2582
[INFO] 2021-07-12 19:24:17,491 [run_pretraining.py:  558]:	worker_index: 6, step: 2582, cost: 7.498646, mlm loss: 7.498646, speed: 1.092312 steps/s, speed: 8.738497 samples/s, speed: 4474.110688 tokens/s, learning rate: 2.581e-05, loss_scalings: 2814.750488, pp_loss: 7.194897
[INFO] 2021-07-12 19:24:17,491 [run_pretraining.py:  512]:	********exe.run_2582******* 
[INFO] 2021-07-12 19:24:18,407 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:18,408 [run_pretraining.py:  534]:	loss/total_loss, 7.262289524078369, 2583
[INFO] 2021-07-12 19:24:18,408 [run_pretraining.py:  535]:	loss/mlm_loss, 7.262289524078369, 2583
[INFO] 2021-07-12 19:24:18,408 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5819997972575948e-05, 2583
[INFO] 2021-07-12 19:24:18,408 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2583
[INFO] 2021-07-12 19:24:18,408 [run_pretraining.py:  558]:	worker_index: 6, step: 2583, cost: 7.262290, mlm loss: 7.262290, speed: 1.091050 steps/s, speed: 8.728400 samples/s, speed: 4468.940932 tokens/s, learning rate: 2.582e-05, loss_scalings: 2814.750488, pp_loss: 6.973382
[INFO] 2021-07-12 19:24:18,408 [run_pretraining.py:  512]:	********exe.run_2583******* 
[INFO] 2021-07-12 19:24:19,325 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:19,326 [run_pretraining.py:  534]:	loss/total_loss, 6.570984363555908, 2584
[INFO] 2021-07-12 19:24:19,326 [run_pretraining.py:  535]:	loss/mlm_loss, 6.570984363555908, 2584
[INFO] 2021-07-12 19:24:19,326 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5830000595306046e-05, 2584
[INFO] 2021-07-12 19:24:19,326 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2584
[INFO] 2021-07-12 19:24:19,326 [run_pretraining.py:  558]:	worker_index: 6, step: 2584, cost: 6.570984, mlm loss: 6.570984, speed: 1.089803 steps/s, speed: 8.718422 samples/s, speed: 4463.831822 tokens/s, learning rate: 2.583e-05, loss_scalings: 2814.750488, pp_loss: 6.236431
[INFO] 2021-07-12 19:24:19,326 [run_pretraining.py:  512]:	********exe.run_2584******* 
[INFO] 2021-07-12 19:24:20,237 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:20,238 [run_pretraining.py:  534]:	loss/total_loss, 7.409250259399414, 2585
[INFO] 2021-07-12 19:24:20,238 [run_pretraining.py:  535]:	loss/mlm_loss, 7.409250259399414, 2585
[INFO] 2021-07-12 19:24:20,238 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5839997761067934e-05, 2585
[INFO] 2021-07-12 19:24:20,238 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2585
[INFO] 2021-07-12 19:24:20,238 [run_pretraining.py:  558]:	worker_index: 6, step: 2585, cost: 7.409250, mlm loss: 7.409250, speed: 1.097621 steps/s, speed: 8.780970 samples/s, speed: 4495.856789 tokens/s, learning rate: 2.584e-05, loss_scalings: 2814.750488, pp_loss: 7.030450
[INFO] 2021-07-12 19:24:20,238 [run_pretraining.py:  512]:	********exe.run_2585******* 
[INFO] 2021-07-12 19:24:21,150 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:21,151 [run_pretraining.py:  534]:	loss/total_loss, 8.81754207611084, 2586
[INFO] 2021-07-12 19:24:21,151 [run_pretraining.py:  535]:	loss/mlm_loss, 8.81754207611084, 2586
[INFO] 2021-07-12 19:24:21,151 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5850000383798033e-05, 2586
[INFO] 2021-07-12 19:24:21,151 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2586
[INFO] 2021-07-12 19:24:21,151 [run_pretraining.py:  558]:	worker_index: 6, step: 2586, cost: 8.817542, mlm loss: 8.817542, speed: 1.095990 steps/s, speed: 8.767924 samples/s, speed: 4489.176947 tokens/s, learning rate: 2.585e-05, loss_scalings: 2814.750488, pp_loss: 7.533182
[INFO] 2021-07-12 19:24:21,151 [run_pretraining.py:  512]:	********exe.run_2586******* 
[INFO] 2021-07-12 19:24:22,066 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:22,067 [run_pretraining.py:  534]:	loss/total_loss, 7.16241455078125, 2587
[INFO] 2021-07-12 19:24:22,067 [run_pretraining.py:  535]:	loss/mlm_loss, 7.16241455078125, 2587
[INFO] 2021-07-12 19:24:22,067 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5859999368549325e-05, 2587
[INFO] 2021-07-12 19:24:22,067 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2587
[INFO] 2021-07-12 19:24:22,067 [run_pretraining.py:  558]:	worker_index: 6, step: 2587, cost: 7.162415, mlm loss: 7.162415, speed: 1.093047 steps/s, speed: 8.744377 samples/s, speed: 4477.121211 tokens/s, learning rate: 2.586e-05, loss_scalings: 2814.750488, pp_loss: 7.344687
[INFO] 2021-07-12 19:24:22,067 [run_pretraining.py:  512]:	********exe.run_2587******* 
[INFO] 2021-07-12 19:24:22,976 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:22,976 [run_pretraining.py:  534]:	loss/total_loss, 8.052942276000977, 2588
[INFO] 2021-07-12 19:24:22,976 [run_pretraining.py:  535]:	loss/mlm_loss, 8.052942276000977, 2588
[INFO] 2021-07-12 19:24:22,976 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.587000017229002e-05, 2588
[INFO] 2021-07-12 19:24:22,976 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2588
[INFO] 2021-07-12 19:24:22,976 [run_pretraining.py:  558]:	worker_index: 6, step: 2588, cost: 8.052942, mlm loss: 8.052942, speed: 1.100237 steps/s, speed: 8.801892 samples/s, speed: 4506.568724 tokens/s, learning rate: 2.587e-05, loss_scalings: 2814.750488, pp_loss: 7.443549
[INFO] 2021-07-12 19:24:22,977 [run_pretraining.py:  512]:	********exe.run_2588******* 
[INFO] 2021-07-12 19:24:23,883 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:23,884 [run_pretraining.py:  534]:	loss/total_loss, 7.07377290725708, 2589
[INFO] 2021-07-12 19:24:23,884 [run_pretraining.py:  535]:	loss/mlm_loss, 7.07377290725708, 2589
[INFO] 2021-07-12 19:24:23,884 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.587999915704131e-05, 2589
[INFO] 2021-07-12 19:24:23,884 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2589
[INFO] 2021-07-12 19:24:23,884 [run_pretraining.py:  558]:	worker_index: 6, step: 2589, cost: 7.073773, mlm loss: 7.073773, speed: 1.102699 steps/s, speed: 8.821594 samples/s, speed: 4516.656067 tokens/s, learning rate: 2.588e-05, loss_scalings: 2814.750488, pp_loss: 7.234174
[INFO] 2021-07-12 19:24:23,884 [run_pretraining.py:  512]:	********exe.run_2589******* 
[INFO] 2021-07-12 19:24:24,875 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:24,876 [run_pretraining.py:  534]:	loss/total_loss, 7.473761558532715, 2590
[INFO] 2021-07-12 19:24:24,876 [run_pretraining.py:  535]:	loss/mlm_loss, 7.473761558532715, 2590
[INFO] 2021-07-12 19:24:24,876 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5889998141792603e-05, 2590
[INFO] 2021-07-12 19:24:24,876 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2590
[INFO] 2021-07-12 19:24:24,876 [run_pretraining.py:  558]:	worker_index: 6, step: 2590, cost: 7.473762, mlm loss: 7.473762, speed: 1.008628 steps/s, speed: 8.069024 samples/s, speed: 4131.340395 tokens/s, learning rate: 2.589e-05, loss_scalings: 2814.750488, pp_loss: 7.446379
[INFO] 2021-07-12 19:24:24,876 [run_pretraining.py:  512]:	********exe.run_2590******* 
[INFO] 2021-07-12 19:24:25,936 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:25,936 [run_pretraining.py:  534]:	loss/total_loss, 7.295245170593262, 2591
[INFO] 2021-07-12 19:24:25,936 [run_pretraining.py:  535]:	loss/mlm_loss, 7.295245170593262, 2591
[INFO] 2021-07-12 19:24:25,937 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5899998945533298e-05, 2591
[INFO] 2021-07-12 19:24:25,937 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2591
[INFO] 2021-07-12 19:24:25,937 [run_pretraining.py:  558]:	worker_index: 6, step: 2591, cost: 7.295245, mlm loss: 7.295245, speed: 0.943596 steps/s, speed: 7.548768 samples/s, speed: 3864.969183 tokens/s, learning rate: 2.590e-05, loss_scalings: 2814.750488, pp_loss: 7.430601
[INFO] 2021-07-12 19:24:25,937 [run_pretraining.py:  512]:	********exe.run_2591******* 
[INFO] 2021-07-12 19:24:26,987 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:26,987 [run_pretraining.py:  534]:	loss/total_loss, 6.6678314208984375, 2592
[INFO] 2021-07-12 19:24:26,987 [run_pretraining.py:  535]:	loss/mlm_loss, 6.6678314208984375, 2592
[INFO] 2021-07-12 19:24:26,987 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.590999793028459e-05, 2592
[INFO] 2021-07-12 19:24:26,987 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2592
[INFO] 2021-07-12 19:24:26,987 [run_pretraining.py:  558]:	worker_index: 6, step: 2592, cost: 6.667831, mlm loss: 6.667831, speed: 0.952315 steps/s, speed: 7.618520 samples/s, speed: 3900.682417 tokens/s, learning rate: 2.591e-05, loss_scalings: 2814.750488, pp_loss: 7.114495
[INFO] 2021-07-12 19:24:26,988 [run_pretraining.py:  512]:	********exe.run_2592******* 
[INFO] 2021-07-12 19:24:28,039 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:28,040 [run_pretraining.py:  534]:	loss/total_loss, 7.46634578704834, 2593
[INFO] 2021-07-12 19:24:28,040 [run_pretraining.py:  535]:	loss/mlm_loss, 7.46634578704834, 2593
[INFO] 2021-07-12 19:24:28,040 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5920000553014688e-05, 2593
[INFO] 2021-07-12 19:24:28,040 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2593
[INFO] 2021-07-12 19:24:28,040 [run_pretraining.py:  558]:	worker_index: 6, step: 2593, cost: 7.466346, mlm loss: 7.466346, speed: 0.950639 steps/s, speed: 7.605111 samples/s, speed: 3893.816578 tokens/s, learning rate: 2.592e-05, loss_scalings: 2814.750488, pp_loss: 7.182406
[INFO] 2021-07-12 19:24:28,040 [run_pretraining.py:  512]:	********exe.run_2593******* 
[INFO] 2021-07-12 19:24:29,104 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:29,104 [run_pretraining.py:  534]:	loss/total_loss, 6.6740312576293945, 2594
[INFO] 2021-07-12 19:24:29,104 [run_pretraining.py:  535]:	loss/mlm_loss, 6.6740312576293945, 2594
[INFO] 2021-07-12 19:24:29,105 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.592999953776598e-05, 2594
[INFO] 2021-07-12 19:24:29,105 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2594
[INFO] 2021-07-12 19:24:29,105 [run_pretraining.py:  558]:	worker_index: 6, step: 2594, cost: 6.674031, mlm loss: 6.674031, speed: 0.939969 steps/s, speed: 7.519748 samples/s, speed: 3850.111030 tokens/s, learning rate: 2.593e-05, loss_scalings: 2814.750488, pp_loss: 6.177381
[INFO] 2021-07-12 19:24:29,105 [run_pretraining.py:  512]:	********exe.run_2594******* 
[INFO] 2021-07-12 19:24:30,167 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:30,167 [run_pretraining.py:  534]:	loss/total_loss, 7.34182071685791, 2595
[INFO] 2021-07-12 19:24:30,168 [run_pretraining.py:  535]:	loss/mlm_loss, 7.34182071685791, 2595
[INFO] 2021-07-12 19:24:30,168 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5940000341506675e-05, 2595
[INFO] 2021-07-12 19:24:30,168 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2595
[INFO] 2021-07-12 19:24:30,168 [run_pretraining.py:  558]:	worker_index: 6, step: 2595, cost: 7.341821, mlm loss: 7.341821, speed: 0.941268 steps/s, speed: 7.530145 samples/s, speed: 3855.434293 tokens/s, learning rate: 2.594e-05, loss_scalings: 2814.750488, pp_loss: 7.489817
[INFO] 2021-07-12 19:24:30,168 [run_pretraining.py:  512]:	********exe.run_2595******* 
[INFO] 2021-07-12 19:24:31,222 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:31,222 [run_pretraining.py:  534]:	loss/total_loss, 7.040163040161133, 2596
[INFO] 2021-07-12 19:24:31,223 [run_pretraining.py:  535]:	loss/mlm_loss, 7.040163040161133, 2596
[INFO] 2021-07-12 19:24:31,223 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5949999326257966e-05, 2596
[INFO] 2021-07-12 19:24:31,223 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2596
[INFO] 2021-07-12 19:24:31,223 [run_pretraining.py:  558]:	worker_index: 6, step: 2596, cost: 7.040163, mlm loss: 7.040163, speed: 0.948511 steps/s, speed: 7.588084 samples/s, speed: 3885.099058 tokens/s, learning rate: 2.595e-05, loss_scalings: 2814.750488, pp_loss: 7.169217
[INFO] 2021-07-12 19:24:31,223 [run_pretraining.py:  512]:	********exe.run_2596******* 
[INFO] 2021-07-12 19:24:32,271 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:32,271 [run_pretraining.py:  534]:	loss/total_loss, 4.822235107421875, 2597
[INFO] 2021-07-12 19:24:32,272 [run_pretraining.py:  535]:	loss/mlm_loss, 4.822235107421875, 2597
[INFO] 2021-07-12 19:24:32,272 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.596000012999866e-05, 2597
[INFO] 2021-07-12 19:24:32,272 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2597
[INFO] 2021-07-12 19:24:32,272 [run_pretraining.py:  558]:	worker_index: 6, step: 2597, cost: 4.822235, mlm loss: 4.822235, speed: 0.953986 steps/s, speed: 7.631889 samples/s, speed: 3907.527184 tokens/s, learning rate: 2.596e-05, loss_scalings: 2814.750488, pp_loss: 6.479428
[INFO] 2021-07-12 19:24:32,272 [run_pretraining.py:  512]:	********exe.run_2597******* 
[INFO] 2021-07-12 19:24:33,342 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:33,343 [run_pretraining.py:  534]:	loss/total_loss, 6.748559951782227, 2598
[INFO] 2021-07-12 19:24:33,343 [run_pretraining.py:  535]:	loss/mlm_loss, 6.748559951782227, 2598
[INFO] 2021-07-12 19:24:33,343 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5969999114749953e-05, 2598
[INFO] 2021-07-12 19:24:33,343 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2598
[INFO] 2021-07-12 19:24:33,343 [run_pretraining.py:  558]:	worker_index: 6, step: 2598, cost: 6.748560, mlm loss: 6.748560, speed: 0.934006 steps/s, speed: 7.472047 samples/s, speed: 3825.688286 tokens/s, learning rate: 2.597e-05, loss_scalings: 2814.750488, pp_loss: 6.793707
[INFO] 2021-07-12 19:24:33,343 [run_pretraining.py:  512]:	********exe.run_2598******* 
[INFO] 2021-07-12 19:24:34,404 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:34,404 [run_pretraining.py:  534]:	loss/total_loss, 6.019186019897461, 2599
[INFO] 2021-07-12 19:24:34,404 [run_pretraining.py:  535]:	loss/mlm_loss, 6.019186019897461, 2599
[INFO] 2021-07-12 19:24:34,404 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5979998099501245e-05, 2599
[INFO] 2021-07-12 19:24:34,405 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2599
[INFO] 2021-07-12 19:24:34,405 [run_pretraining.py:  558]:	worker_index: 6, step: 2599, cost: 6.019186, mlm loss: 6.019186, speed: 0.942673 steps/s, speed: 7.541381 samples/s, speed: 3861.187062 tokens/s, learning rate: 2.598e-05, loss_scalings: 2814.750488, pp_loss: 5.741862
[INFO] 2021-07-12 19:24:34,405 [run_pretraining.py:  512]:	********exe.run_2599******* 
[INFO] 2021-07-12 19:24:59,799 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:59,800 [run_pretraining.py:  534]:	loss/total_loss, 6.717806816101074, 2600
[INFO] 2021-07-12 19:24:59,800 [run_pretraining.py:  535]:	loss/mlm_loss, 6.717806816101074, 2600
[INFO] 2021-07-12 19:24:59,800 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.598999890324194e-05, 2600
[INFO] 2021-07-12 19:24:59,800 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2600
[INFO] 2021-07-12 19:24:59,800 [run_pretraining.py:  558]:	worker_index: 6, step: 2600, cost: 6.717807, mlm loss: 6.717807, speed: 0.039378 steps/s, speed: 0.315025 samples/s, speed: 161.292785 tokens/s, learning rate: 2.599e-05, loss_scalings: 2814.750488, pp_loss: 6.945414
[INFO] 2021-07-12 19:24:59,800 [run_pretraining.py:  512]:	********exe.run_2600******* 
[INFO] 2021-07-12 19:25:00,860 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:00,861 [run_pretraining.py:  534]:	loss/total_loss, 7.103003025054932, 2601
[INFO] 2021-07-12 19:25:00,861 [run_pretraining.py:  535]:	loss/mlm_loss, 7.103003025054932, 2601
[INFO] 2021-07-12 19:25:00,861 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.599999788799323e-05, 2601
[INFO] 2021-07-12 19:25:00,861 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2601
[INFO] 2021-07-12 19:25:00,861 [run_pretraining.py:  558]:	worker_index: 6, step: 2601, cost: 7.103003, mlm loss: 7.103003, speed: 0.943188 steps/s, speed: 7.545507 samples/s, speed: 3863.299585 tokens/s, learning rate: 2.600e-05, loss_scalings: 2814.750488, pp_loss: 7.530696
[INFO] 2021-07-12 19:25:00,861 [run_pretraining.py:  512]:	********exe.run_2601******* 
[INFO] 2021-07-12 19:25:01,920 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:01,921 [run_pretraining.py:  534]:	loss/total_loss, 7.50085973739624, 2602
[INFO] 2021-07-12 19:25:01,921 [run_pretraining.py:  535]:	loss/mlm_loss, 7.50085973739624, 2602
[INFO] 2021-07-12 19:25:01,921 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.601000051072333e-05, 2602
[INFO] 2021-07-12 19:25:01,921 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2602
[INFO] 2021-07-12 19:25:01,921 [run_pretraining.py:  558]:	worker_index: 6, step: 2602, cost: 7.500860, mlm loss: 7.500860, speed: 0.943860 steps/s, speed: 7.550881 samples/s, speed: 3866.051151 tokens/s, learning rate: 2.601e-05, loss_scalings: 2814.750488, pp_loss: 7.380588
[INFO] 2021-07-12 19:25:01,921 [run_pretraining.py:  512]:	********exe.run_2602******* 
[INFO] 2021-07-12 19:25:02,977 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:02,977 [run_pretraining.py:  534]:	loss/total_loss, 7.837745666503906, 2603
[INFO] 2021-07-12 19:25:02,978 [run_pretraining.py:  535]:	loss/mlm_loss, 7.837745666503906, 2603
[INFO] 2021-07-12 19:25:02,978 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.601999949547462e-05, 2603
[INFO] 2021-07-12 19:25:02,978 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2603
[INFO] 2021-07-12 19:25:02,978 [run_pretraining.py:  558]:	worker_index: 6, step: 2603, cost: 7.837746, mlm loss: 7.837746, speed: 0.947113 steps/s, speed: 7.576902 samples/s, speed: 3879.373854 tokens/s, learning rate: 2.602e-05, loss_scalings: 2814.750488, pp_loss: 7.732423
[INFO] 2021-07-12 19:25:02,978 [run_pretraining.py:  512]:	********exe.run_2603******* 
[INFO] 2021-07-12 19:25:04,039 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:04,039 [run_pretraining.py:  534]:	loss/total_loss, 7.568822383880615, 2604
[INFO] 2021-07-12 19:25:04,040 [run_pretraining.py:  535]:	loss/mlm_loss, 7.568822383880615, 2604
[INFO] 2021-07-12 19:25:04,040 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6030000299215317e-05, 2604
[INFO] 2021-07-12 19:25:04,040 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2604
[INFO] 2021-07-12 19:25:04,040 [run_pretraining.py:  558]:	worker_index: 6, step: 2604, cost: 7.568822, mlm loss: 7.568822, speed: 0.942306 steps/s, speed: 7.538450 samples/s, speed: 3859.686344 tokens/s, learning rate: 2.603e-05, loss_scalings: 2814.750488, pp_loss: 7.597125
[INFO] 2021-07-12 19:25:04,040 [run_pretraining.py:  512]:	********exe.run_2604******* 
[INFO] 2021-07-12 19:25:05,092 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:05,092 [run_pretraining.py:  534]:	loss/total_loss, 6.992632865905762, 2605
[INFO] 2021-07-12 19:25:05,092 [run_pretraining.py:  535]:	loss/mlm_loss, 6.992632865905762, 2605
[INFO] 2021-07-12 19:25:05,092 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.603999928396661e-05, 2605
[INFO] 2021-07-12 19:25:05,092 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2605
[INFO] 2021-07-12 19:25:05,093 [run_pretraining.py:  558]:	worker_index: 6, step: 2605, cost: 6.992633, mlm loss: 6.992633, speed: 0.950535 steps/s, speed: 7.604280 samples/s, speed: 3893.391243 tokens/s, learning rate: 2.604e-05, loss_scalings: 2814.750488, pp_loss: 7.672368
[INFO] 2021-07-12 19:25:05,093 [run_pretraining.py:  512]:	********exe.run_2605******* 
[INFO] 2021-07-12 19:25:06,153 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:06,153 [run_pretraining.py:  534]:	loss/total_loss, 8.241580963134766, 2606
[INFO] 2021-07-12 19:25:06,153 [run_pretraining.py:  535]:	loss/mlm_loss, 8.241580963134766, 2606
[INFO] 2021-07-12 19:25:06,153 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6050000087707303e-05, 2606
[INFO] 2021-07-12 19:25:06,154 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2606
[INFO] 2021-07-12 19:25:06,154 [run_pretraining.py:  558]:	worker_index: 6, step: 2606, cost: 8.241581, mlm loss: 8.241581, speed: 0.943100 steps/s, speed: 7.544798 samples/s, speed: 3862.936480 tokens/s, learning rate: 2.605e-05, loss_scalings: 2814.750488, pp_loss: 7.856113
[INFO] 2021-07-12 19:25:06,154 [run_pretraining.py:  512]:	********exe.run_2606******* 
[INFO] 2021-07-12 19:25:07,219 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:07,220 [run_pretraining.py:  534]:	loss/total_loss, 5.9805192947387695, 2607
[INFO] 2021-07-12 19:25:07,220 [run_pretraining.py:  535]:	loss/mlm_loss, 5.9805192947387695, 2607
[INFO] 2021-07-12 19:25:07,220 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6059999072458595e-05, 2607
[INFO] 2021-07-12 19:25:07,220 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2607
[INFO] 2021-07-12 19:25:07,220 [run_pretraining.py:  558]:	worker_index: 6, step: 2607, cost: 5.980519, mlm loss: 5.980519, speed: 0.938152 steps/s, speed: 7.505216 samples/s, speed: 3842.670561 tokens/s, learning rate: 2.606e-05, loss_scalings: 2814.750488, pp_loss: 6.985026
[INFO] 2021-07-12 19:25:07,220 [run_pretraining.py:  512]:	********exe.run_2607******* 
[INFO] 2021-07-12 19:25:08,270 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:08,271 [run_pretraining.py:  534]:	loss/total_loss, 7.177448749542236, 2608
[INFO] 2021-07-12 19:25:08,271 [run_pretraining.py:  535]:	loss/mlm_loss, 7.177448749542236, 2608
[INFO] 2021-07-12 19:25:08,271 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6069998057209887e-05, 2608
[INFO] 2021-07-12 19:25:08,271 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2608
[INFO] 2021-07-12 19:25:08,271 [run_pretraining.py:  558]:	worker_index: 6, step: 2608, cost: 7.177449, mlm loss: 7.177449, speed: 0.952310 steps/s, speed: 7.618482 samples/s, speed: 3900.662932 tokens/s, learning rate: 2.607e-05, loss_scalings: 2814.750488, pp_loss: 7.451096
[INFO] 2021-07-12 19:25:08,271 [run_pretraining.py:  512]:	********exe.run_2608******* 
[INFO] 2021-07-12 19:25:09,328 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:09,329 [run_pretraining.py:  534]:	loss/total_loss, 7.445719242095947, 2609
[INFO] 2021-07-12 19:25:09,329 [run_pretraining.py:  535]:	loss/mlm_loss, 7.445719242095947, 2609
[INFO] 2021-07-12 19:25:09,329 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6079998860950582e-05, 2609
[INFO] 2021-07-12 19:25:09,329 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2609
[INFO] 2021-07-12 19:25:09,329 [run_pretraining.py:  558]:	worker_index: 6, step: 2609, cost: 7.445719, mlm loss: 7.445719, speed: 0.945820 steps/s, speed: 7.566563 samples/s, speed: 3874.080420 tokens/s, learning rate: 2.608e-05, loss_scalings: 2814.750488, pp_loss: 7.112355
[INFO] 2021-07-12 19:25:09,329 [run_pretraining.py:  512]:	********exe.run_2609******* 
[INFO] 2021-07-12 19:25:10,275 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:10,275 [run_pretraining.py:  534]:	loss/total_loss, 7.262016296386719, 2610
[INFO] 2021-07-12 19:25:10,275 [run_pretraining.py:  535]:	loss/mlm_loss, 7.262016296386719, 2610
[INFO] 2021-07-12 19:25:10,275 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6089997845701873e-05, 2610
[INFO] 2021-07-12 19:25:10,276 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2610
[INFO] 2021-07-12 19:25:10,276 [run_pretraining.py:  558]:	worker_index: 6, step: 2610, cost: 7.262016, mlm loss: 7.262016, speed: 1.057226 steps/s, speed: 8.457806 samples/s, speed: 4330.396434 tokens/s, learning rate: 2.609e-05, loss_scalings: 2814.750488, pp_loss: 7.225761
[INFO] 2021-07-12 19:25:10,276 [run_pretraining.py:  512]:	********exe.run_2610******* 
[INFO] 2021-07-12 19:25:11,187 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:11,188 [run_pretraining.py:  534]:	loss/total_loss, 7.090049743652344, 2611
[INFO] 2021-07-12 19:25:11,188 [run_pretraining.py:  535]:	loss/mlm_loss, 7.090049743652344, 2611
[INFO] 2021-07-12 19:25:11,188 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6100000468431972e-05, 2611
[INFO] 2021-07-12 19:25:11,188 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2611
[INFO] 2021-07-12 19:25:11,188 [run_pretraining.py:  558]:	worker_index: 6, step: 2611, cost: 7.090050, mlm loss: 7.090050, speed: 1.096851 steps/s, speed: 8.774812 samples/s, speed: 4492.703533 tokens/s, learning rate: 2.610e-05, loss_scalings: 2814.750488, pp_loss: 7.223731
[INFO] 2021-07-12 19:25:11,188 [run_pretraining.py:  512]:	********exe.run_2611******* 
[INFO] 2021-07-12 19:25:12,092 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:12,092 [run_pretraining.py:  534]:	loss/total_loss, 7.411313056945801, 2612
[INFO] 2021-07-12 19:25:12,092 [run_pretraining.py:  535]:	loss/mlm_loss, 7.411313056945801, 2612
[INFO] 2021-07-12 19:25:12,092 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6109999453183264e-05, 2612
[INFO] 2021-07-12 19:25:12,093 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2612
[INFO] 2021-07-12 19:25:12,093 [run_pretraining.py:  558]:	worker_index: 6, step: 2612, cost: 7.411313, mlm loss: 7.411313, speed: 1.106334 steps/s, speed: 8.850673 samples/s, speed: 4531.544507 tokens/s, learning rate: 2.611e-05, loss_scalings: 2814.750488, pp_loss: 7.417535
[INFO] 2021-07-12 19:25:12,093 [run_pretraining.py:  512]:	********exe.run_2612******* 
[INFO] 2021-07-12 19:25:13,002 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:13,002 [run_pretraining.py:  534]:	loss/total_loss, 7.079864501953125, 2613
[INFO] 2021-07-12 19:25:13,002 [run_pretraining.py:  535]:	loss/mlm_loss, 7.079864501953125, 2613
[INFO] 2021-07-12 19:25:13,002 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.612000025692396e-05, 2613
[INFO] 2021-07-12 19:25:13,003 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2613
[INFO] 2021-07-12 19:25:13,003 [run_pretraining.py:  558]:	worker_index: 6, step: 2613, cost: 7.079865, mlm loss: 7.079865, speed: 1.099671 steps/s, speed: 8.797369 samples/s, speed: 4504.252903 tokens/s, learning rate: 2.612e-05, loss_scalings: 2814.750488, pp_loss: 7.257387
[INFO] 2021-07-12 19:25:13,003 [run_pretraining.py:  512]:	********exe.run_2613******* 
[INFO] 2021-07-12 19:25:13,912 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:13,913 [run_pretraining.py:  534]:	loss/total_loss, 7.4324445724487305, 2614
[INFO] 2021-07-12 19:25:13,913 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4324445724487305, 2614
[INFO] 2021-07-12 19:25:13,913 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.612999924167525e-05, 2614
[INFO] 2021-07-12 19:25:13,913 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2614
[INFO] 2021-07-12 19:25:13,913 [run_pretraining.py:  558]:	worker_index: 6, step: 2614, cost: 7.432445, mlm loss: 7.432445, speed: 1.099096 steps/s, speed: 8.792768 samples/s, speed: 4501.896991 tokens/s, learning rate: 2.613e-05, loss_scalings: 2814.750488, pp_loss: 7.327041
[INFO] 2021-07-12 19:25:13,913 [run_pretraining.py:  512]:	********exe.run_2614******* 
[INFO] 2021-07-12 19:25:14,820 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:14,820 [run_pretraining.py:  534]:	loss/total_loss, 7.509069442749023, 2615
[INFO] 2021-07-12 19:25:14,820 [run_pretraining.py:  535]:	loss/mlm_loss, 7.509069442749023, 2615
[INFO] 2021-07-12 19:25:14,820 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6140000045415945e-05, 2615
[INFO] 2021-07-12 19:25:14,821 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2615
[INFO] 2021-07-12 19:25:14,821 [run_pretraining.py:  558]:	worker_index: 6, step: 2615, cost: 7.509069, mlm loss: 7.509069, speed: 1.102857 steps/s, speed: 8.822853 samples/s, speed: 4517.300943 tokens/s, learning rate: 2.614e-05, loss_scalings: 2814.750488, pp_loss: 7.533738
[INFO] 2021-07-12 19:25:14,821 [run_pretraining.py:  512]:	********exe.run_2615******* 
[INFO] 2021-07-12 19:25:15,730 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:15,731 [run_pretraining.py:  534]:	loss/total_loss, 6.951383590698242, 2616
[INFO] 2021-07-12 19:25:15,731 [run_pretraining.py:  535]:	loss/mlm_loss, 6.951383590698242, 2616
[INFO] 2021-07-12 19:25:15,731 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6149999030167237e-05, 2616
[INFO] 2021-07-12 19:25:15,731 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2616
[INFO] 2021-07-12 19:25:15,731 [run_pretraining.py:  558]:	worker_index: 6, step: 2616, cost: 6.951384, mlm loss: 6.951384, speed: 1.098949 steps/s, speed: 8.791593 samples/s, speed: 4501.295425 tokens/s, learning rate: 2.615e-05, loss_scalings: 2814.750488, pp_loss: 7.349561
[INFO] 2021-07-12 19:25:15,731 [run_pretraining.py:  512]:	********exe.run_2616******* 
[INFO] 2021-07-12 19:25:16,647 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:16,648 [run_pretraining.py:  534]:	loss/total_loss, 6.965841293334961, 2617
[INFO] 2021-07-12 19:25:16,648 [run_pretraining.py:  535]:	loss/mlm_loss, 6.965841293334961, 2617
[INFO] 2021-07-12 19:25:16,648 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.615999801491853e-05, 2617
[INFO] 2021-07-12 19:25:16,648 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2617
[INFO] 2021-07-12 19:25:16,648 [run_pretraining.py:  558]:	worker_index: 6, step: 2617, cost: 6.965841, mlm loss: 6.965841, speed: 1.091570 steps/s, speed: 8.732560 samples/s, speed: 4471.070466 tokens/s, learning rate: 2.616e-05, loss_scalings: 2814.750488, pp_loss: 7.069780
[INFO] 2021-07-12 19:25:16,648 [run_pretraining.py:  512]:	********exe.run_2617******* 
[INFO] 2021-07-12 19:25:17,551 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:17,551 [run_pretraining.py:  534]:	loss/total_loss, 6.584812641143799, 2618
[INFO] 2021-07-12 19:25:17,552 [run_pretraining.py:  535]:	loss/mlm_loss, 6.584812641143799, 2618
[INFO] 2021-07-12 19:25:17,552 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6170000637648627e-05, 2618
[INFO] 2021-07-12 19:25:17,552 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2618
[INFO] 2021-07-12 19:25:17,552 [run_pretraining.py:  558]:	worker_index: 6, step: 2618, cost: 6.584813, mlm loss: 6.584813, speed: 1.107468 steps/s, speed: 8.859747 samples/s, speed: 4536.190570 tokens/s, learning rate: 2.617e-05, loss_scalings: 2814.750488, pp_loss: 6.910389
[INFO] 2021-07-12 19:25:17,552 [run_pretraining.py:  512]:	********exe.run_2618******* 
[INFO] 2021-07-12 19:25:18,471 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:18,471 [run_pretraining.py:  534]:	loss/total_loss, 6.761624336242676, 2619
[INFO] 2021-07-12 19:25:18,471 [run_pretraining.py:  535]:	loss/mlm_loss, 6.761624336242676, 2619
[INFO] 2021-07-12 19:25:18,471 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6179997803410515e-05, 2619
[INFO] 2021-07-12 19:25:18,471 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2619
[INFO] 2021-07-12 19:25:18,472 [run_pretraining.py:  558]:	worker_index: 6, step: 2619, cost: 6.761624, mlm loss: 6.761624, speed: 1.088152 steps/s, speed: 8.705212 samples/s, speed: 4457.068654 tokens/s, learning rate: 2.618e-05, loss_scalings: 2814.750488, pp_loss: 6.772988
[INFO] 2021-07-12 19:25:18,472 [run_pretraining.py:  512]:	********exe.run_2619******* 
[INFO] 2021-07-12 19:25:19,380 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:19,381 [run_pretraining.py:  534]:	loss/total_loss, 6.570904731750488, 2620
[INFO] 2021-07-12 19:25:19,381 [run_pretraining.py:  535]:	loss/mlm_loss, 6.570904731750488, 2620
[INFO] 2021-07-12 19:25:19,381 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6190000426140614e-05, 2620
[INFO] 2021-07-12 19:25:19,381 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2620
[INFO] 2021-07-12 19:25:19,381 [run_pretraining.py:  558]:	worker_index: 6, step: 2620, cost: 6.570905, mlm loss: 6.570905, speed: 1.100196 steps/s, speed: 8.801569 samples/s, speed: 4506.403229 tokens/s, learning rate: 2.619e-05, loss_scalings: 2814.750488, pp_loss: 6.970893
[INFO] 2021-07-12 19:25:19,381 [run_pretraining.py:  512]:	********exe.run_2620******* 
[INFO] 2021-07-12 19:25:20,306 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:20,307 [run_pretraining.py:  534]:	loss/total_loss, 7.010175704956055, 2621
[INFO] 2021-07-12 19:25:20,307 [run_pretraining.py:  535]:	loss/mlm_loss, 7.010175704956055, 2621
[INFO] 2021-07-12 19:25:20,307 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6199999410891905e-05, 2621
[INFO] 2021-07-12 19:25:20,307 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2621
[INFO] 2021-07-12 19:25:20,307 [run_pretraining.py:  558]:	worker_index: 6, step: 2621, cost: 7.010176, mlm loss: 7.010176, speed: 1.080817 steps/s, speed: 8.646534 samples/s, speed: 4427.025466 tokens/s, learning rate: 2.620e-05, loss_scalings: 2814.750488, pp_loss: 7.265457
[INFO] 2021-07-12 19:25:20,307 [run_pretraining.py:  512]:	********exe.run_2621******* 
[INFO] 2021-07-12 19:25:21,223 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:21,224 [run_pretraining.py:  534]:	loss/total_loss, 7.0038652420043945, 2622
[INFO] 2021-07-12 19:25:21,224 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0038652420043945, 2622
[INFO] 2021-07-12 19:25:21,224 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.62100002146326e-05, 2622
[INFO] 2021-07-12 19:25:21,224 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2622
[INFO] 2021-07-12 19:25:21,224 [run_pretraining.py:  558]:	worker_index: 6, step: 2622, cost: 7.003865, mlm loss: 7.003865, speed: 1.091388 steps/s, speed: 8.731108 samples/s, speed: 4470.327050 tokens/s, learning rate: 2.621e-05, loss_scalings: 2814.750488, pp_loss: 6.817474
[INFO] 2021-07-12 19:25:21,224 [run_pretraining.py:  512]:	********exe.run_2622******* 
[INFO] 2021-07-12 19:25:22,132 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:22,133 [run_pretraining.py:  534]:	loss/total_loss, 7.23347806930542, 2623
[INFO] 2021-07-12 19:25:22,133 [run_pretraining.py:  535]:	loss/mlm_loss, 7.23347806930542, 2623
[INFO] 2021-07-12 19:25:22,133 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6219999199383892e-05, 2623
[INFO] 2021-07-12 19:25:22,133 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2623
[INFO] 2021-07-12 19:25:22,133 [run_pretraining.py:  558]:	worker_index: 6, step: 2623, cost: 7.233478, mlm loss: 7.233478, speed: 1.100598 steps/s, speed: 8.804784 samples/s, speed: 4508.049260 tokens/s, learning rate: 2.622e-05, loss_scalings: 2814.750488, pp_loss: 7.373827
[INFO] 2021-07-12 19:25:22,133 [run_pretraining.py:  512]:	********exe.run_2623******* 
[INFO] 2021-07-12 19:25:23,057 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:23,058 [run_pretraining.py:  534]:	loss/total_loss, 7.6365885734558105, 2624
[INFO] 2021-07-12 19:25:23,058 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6365885734558105, 2624
[INFO] 2021-07-12 19:25:23,058 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6230000003124587e-05, 2624
[INFO] 2021-07-12 19:25:23,058 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2624
[INFO] 2021-07-12 19:25:23,058 [run_pretraining.py:  558]:	worker_index: 6, step: 2624, cost: 7.636589, mlm loss: 7.636589, speed: 1.082326 steps/s, speed: 8.658609 samples/s, speed: 4433.208022 tokens/s, learning rate: 2.623e-05, loss_scalings: 2814.750488, pp_loss: 7.105485
[INFO] 2021-07-12 19:25:23,058 [run_pretraining.py:  512]:	********exe.run_2624******* 
[INFO] 2021-07-12 19:25:23,988 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:23,989 [run_pretraining.py:  534]:	loss/total_loss, 7.592694282531738, 2625
[INFO] 2021-07-12 19:25:23,989 [run_pretraining.py:  535]:	loss/mlm_loss, 7.592694282531738, 2625
[INFO] 2021-07-12 19:25:23,989 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.623999898787588e-05, 2625
[INFO] 2021-07-12 19:25:23,989 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2625
[INFO] 2021-07-12 19:25:23,989 [run_pretraining.py:  558]:	worker_index: 6, step: 2625, cost: 7.592694, mlm loss: 7.592694, speed: 1.074678 steps/s, speed: 8.597424 samples/s, speed: 4401.881289 tokens/s, learning rate: 2.624e-05, loss_scalings: 2814.750488, pp_loss: 7.327529
[INFO] 2021-07-12 19:25:23,989 [run_pretraining.py:  512]:	********exe.run_2625******* 
[INFO] 2021-07-12 19:25:24,902 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:24,902 [run_pretraining.py:  534]:	loss/total_loss, 7.66172981262207, 2626
[INFO] 2021-07-12 19:25:24,902 [run_pretraining.py:  535]:	loss/mlm_loss, 7.66172981262207, 2626
[INFO] 2021-07-12 19:25:24,902 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.624999797262717e-05, 2626
[INFO] 2021-07-12 19:25:24,903 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2626
[INFO] 2021-07-12 19:25:24,903 [run_pretraining.py:  558]:	worker_index: 6, step: 2626, cost: 7.661730, mlm loss: 7.661730, speed: 1.095676 steps/s, speed: 8.765411 samples/s, speed: 4487.890488 tokens/s, learning rate: 2.625e-05, loss_scalings: 2814.750488, pp_loss: 6.475669
[INFO] 2021-07-12 19:25:24,903 [run_pretraining.py:  512]:	********exe.run_2626******* 
[INFO] 2021-07-12 19:25:25,816 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:25,816 [run_pretraining.py:  534]:	loss/total_loss, 6.910338401794434, 2627
[INFO] 2021-07-12 19:25:25,816 [run_pretraining.py:  535]:	loss/mlm_loss, 6.910338401794434, 2627
[INFO] 2021-07-12 19:25:25,817 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.626000059535727e-05, 2627
[INFO] 2021-07-12 19:25:25,817 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2627
[INFO] 2021-07-12 19:25:25,817 [run_pretraining.py:  558]:	worker_index: 6, step: 2627, cost: 6.910338, mlm loss: 6.910338, speed: 1.094790 steps/s, speed: 8.758319 samples/s, speed: 4484.259083 tokens/s, learning rate: 2.626e-05, loss_scalings: 2814.750488, pp_loss: 6.972819
[INFO] 2021-07-12 19:25:25,817 [run_pretraining.py:  512]:	********exe.run_2627******* 
[INFO] 2021-07-12 19:25:26,743 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:26,743 [run_pretraining.py:  534]:	loss/total_loss, 7.12515115737915, 2628
[INFO] 2021-07-12 19:25:26,743 [run_pretraining.py:  535]:	loss/mlm_loss, 7.12515115737915, 2628
[INFO] 2021-07-12 19:25:26,744 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6269997761119157e-05, 2628
[INFO] 2021-07-12 19:25:26,744 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2628
[INFO] 2021-07-12 19:25:26,744 [run_pretraining.py:  558]:	worker_index: 6, step: 2628, cost: 7.125151, mlm loss: 7.125151, speed: 1.079617 steps/s, speed: 8.636937 samples/s, speed: 4422.111856 tokens/s, learning rate: 2.627e-05, loss_scalings: 2814.750488, pp_loss: 7.001728
[INFO] 2021-07-12 19:25:26,744 [run_pretraining.py:  512]:	********exe.run_2628******* 
[INFO] 2021-07-12 19:25:27,673 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:27,674 [run_pretraining.py:  534]:	loss/total_loss, 6.770626544952393, 2629
[INFO] 2021-07-12 19:25:27,674 [run_pretraining.py:  535]:	loss/mlm_loss, 6.770626544952393, 2629
[INFO] 2021-07-12 19:25:27,674 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6280000383849256e-05, 2629
[INFO] 2021-07-12 19:25:27,674 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2629
[INFO] 2021-07-12 19:25:27,674 [run_pretraining.py:  558]:	worker_index: 6, step: 2629, cost: 6.770627, mlm loss: 6.770627, speed: 1.075923 steps/s, speed: 8.607386 samples/s, speed: 4406.981755 tokens/s, learning rate: 2.628e-05, loss_scalings: 2814.750488, pp_loss: 7.054235
[INFO] 2021-07-12 19:25:27,674 [run_pretraining.py:  512]:	********exe.run_2629******* 
[INFO] 2021-07-12 19:25:28,586 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:28,586 [run_pretraining.py:  534]:	loss/total_loss, 8.060361862182617, 2630
[INFO] 2021-07-12 19:25:28,587 [run_pretraining.py:  535]:	loss/mlm_loss, 8.060361862182617, 2630
[INFO] 2021-07-12 19:25:28,587 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6289999368600547e-05, 2630
[INFO] 2021-07-12 19:25:28,587 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2630
[INFO] 2021-07-12 19:25:28,587 [run_pretraining.py:  558]:	worker_index: 6, step: 2630, cost: 8.060362, mlm loss: 8.060362, speed: 1.096150 steps/s, speed: 8.769202 samples/s, speed: 4489.831600 tokens/s, learning rate: 2.629e-05, loss_scalings: 2814.750488, pp_loss: 7.244644
[INFO] 2021-07-12 19:25:28,587 [run_pretraining.py:  512]:	********exe.run_2630******* 
[INFO] 2021-07-12 19:25:29,504 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:29,505 [run_pretraining.py:  534]:	loss/total_loss, 6.887398719787598, 2631
[INFO] 2021-07-12 19:25:29,505 [run_pretraining.py:  535]:	loss/mlm_loss, 6.887398719787598, 2631
[INFO] 2021-07-12 19:25:29,505 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6300000172341242e-05, 2631
[INFO] 2021-07-12 19:25:29,505 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2631
[INFO] 2021-07-12 19:25:29,505 [run_pretraining.py:  558]:	worker_index: 6, step: 2631, cost: 6.887399, mlm loss: 6.887399, speed: 1.089759 steps/s, speed: 8.718073 samples/s, speed: 4463.653215 tokens/s, learning rate: 2.630e-05, loss_scalings: 2814.750488, pp_loss: 6.236248
[INFO] 2021-07-12 19:25:29,505 [run_pretraining.py:  512]:	********exe.run_2631******* 
[INFO] 2021-07-12 19:25:30,425 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:30,425 [run_pretraining.py:  534]:	loss/total_loss, 7.86256217956543, 2632
[INFO] 2021-07-12 19:25:30,425 [run_pretraining.py:  535]:	loss/mlm_loss, 7.86256217956543, 2632
[INFO] 2021-07-12 19:25:30,425 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6309999157092534e-05, 2632
[INFO] 2021-07-12 19:25:30,425 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2632
[INFO] 2021-07-12 19:25:30,426 [run_pretraining.py:  558]:	worker_index: 6, step: 2632, cost: 7.862562, mlm loss: 7.862562, speed: 1.087376 steps/s, speed: 8.699010 samples/s, speed: 4453.893345 tokens/s, learning rate: 2.631e-05, loss_scalings: 2814.750488, pp_loss: 7.686257
[INFO] 2021-07-12 19:25:30,426 [run_pretraining.py:  512]:	********exe.run_2632******* 
[INFO] 2021-07-12 19:25:31,348 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:31,348 [run_pretraining.py:  534]:	loss/total_loss, 6.932925224304199, 2633
[INFO] 2021-07-12 19:25:31,349 [run_pretraining.py:  535]:	loss/mlm_loss, 6.932925224304199, 2633
[INFO] 2021-07-12 19:25:31,349 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.631999996083323e-05, 2633
[INFO] 2021-07-12 19:25:31,349 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2633
[INFO] 2021-07-12 19:25:31,349 [run_pretraining.py:  558]:	worker_index: 6, step: 2633, cost: 6.932925, mlm loss: 6.932925, speed: 1.084012 steps/s, speed: 8.672092 samples/s, speed: 4440.111201 tokens/s, learning rate: 2.632e-05, loss_scalings: 2814.750488, pp_loss: 7.410805
[INFO] 2021-07-12 19:25:31,349 [run_pretraining.py:  512]:	********exe.run_2633******* 
[INFO] 2021-07-12 19:25:32,265 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:32,265 [run_pretraining.py:  534]:	loss/total_loss, 6.573443412780762, 2634
[INFO] 2021-07-12 19:25:32,266 [run_pretraining.py:  535]:	loss/mlm_loss, 6.573443412780762, 2634
[INFO] 2021-07-12 19:25:32,266 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.632999894558452e-05, 2634
[INFO] 2021-07-12 19:25:32,266 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2634
[INFO] 2021-07-12 19:25:32,266 [run_pretraining.py:  558]:	worker_index: 6, step: 2634, cost: 6.573443, mlm loss: 6.573443, speed: 1.091289 steps/s, speed: 8.730312 samples/s, speed: 4469.919963 tokens/s, learning rate: 2.633e-05, loss_scalings: 2814.750488, pp_loss: 6.315357
[INFO] 2021-07-12 19:25:32,266 [run_pretraining.py:  512]:	********exe.run_2634******* 
[INFO] 2021-07-12 19:25:33,179 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:33,180 [run_pretraining.py:  534]:	loss/total_loss, 7.77495002746582, 2635
[INFO] 2021-07-12 19:25:33,180 [run_pretraining.py:  535]:	loss/mlm_loss, 7.77495002746582, 2635
[INFO] 2021-07-12 19:25:33,180 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6339997930335812e-05, 2635
[INFO] 2021-07-12 19:25:33,180 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2635
[INFO] 2021-07-12 19:25:33,180 [run_pretraining.py:  558]:	worker_index: 6, step: 2635, cost: 7.774950, mlm loss: 7.774950, speed: 1.094640 steps/s, speed: 8.757116 samples/s, speed: 4483.643498 tokens/s, learning rate: 2.634e-05, loss_scalings: 2814.750488, pp_loss: 7.579558
[INFO] 2021-07-12 19:25:33,180 [run_pretraining.py:  512]:	********exe.run_2635******* 
[INFO] 2021-07-12 19:25:34,099 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:34,100 [run_pretraining.py:  534]:	loss/total_loss, 7.283177375793457, 2636
[INFO] 2021-07-12 19:25:34,100 [run_pretraining.py:  535]:	loss/mlm_loss, 7.283177375793457, 2636
[INFO] 2021-07-12 19:25:34,100 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.635000055306591e-05, 2636
[INFO] 2021-07-12 19:25:34,100 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2636
[INFO] 2021-07-12 19:25:34,100 [run_pretraining.py:  558]:	worker_index: 6, step: 2636, cost: 7.283177, mlm loss: 7.283177, speed: 1.087666 steps/s, speed: 8.701329 samples/s, speed: 4455.080668 tokens/s, learning rate: 2.635e-05, loss_scalings: 2814.750488, pp_loss: 7.094246
[INFO] 2021-07-12 19:25:34,100 [run_pretraining.py:  512]:	********exe.run_2636******* 
[INFO] 2021-07-12 19:25:35,025 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:35,026 [run_pretraining.py:  534]:	loss/total_loss, 6.965429782867432, 2637
[INFO] 2021-07-12 19:25:35,026 [run_pretraining.py:  535]:	loss/mlm_loss, 6.965429782867432, 2637
[INFO] 2021-07-12 19:25:35,026 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.63599977188278e-05, 2637
[INFO] 2021-07-12 19:25:35,026 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2637
[INFO] 2021-07-12 19:25:35,026 [run_pretraining.py:  558]:	worker_index: 6, step: 2637, cost: 6.965430, mlm loss: 6.965430, speed: 1.080816 steps/s, speed: 8.646530 samples/s, speed: 4427.023184 tokens/s, learning rate: 2.636e-05, loss_scalings: 2814.750488, pp_loss: 7.402217
[INFO] 2021-07-12 19:25:35,026 [run_pretraining.py:  512]:	********exe.run_2637******* 
[INFO] 2021-07-12 19:25:35,945 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:35,945 [run_pretraining.py:  534]:	loss/total_loss, 7.711145401000977, 2638
[INFO] 2021-07-12 19:25:35,945 [run_pretraining.py:  535]:	loss/mlm_loss, 7.711145401000977, 2638
[INFO] 2021-07-12 19:25:35,945 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6370000341557898e-05, 2638
[INFO] 2021-07-12 19:25:35,946 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2638
[INFO] 2021-07-12 19:25:35,946 [run_pretraining.py:  558]:	worker_index: 6, step: 2638, cost: 7.711145, mlm loss: 7.711145, speed: 1.088411 steps/s, speed: 8.707290 samples/s, speed: 4458.132725 tokens/s, learning rate: 2.637e-05, loss_scalings: 2814.750488, pp_loss: 7.343821
[INFO] 2021-07-12 19:25:35,946 [run_pretraining.py:  512]:	********exe.run_2638******* 
[INFO] 2021-07-12 19:25:36,860 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:36,861 [run_pretraining.py:  534]:	loss/total_loss, 7.735542297363281, 2639
[INFO] 2021-07-12 19:25:36,861 [run_pretraining.py:  535]:	loss/mlm_loss, 7.735542297363281, 2639
[INFO] 2021-07-12 19:25:36,861 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.637999932630919e-05, 2639
[INFO] 2021-07-12 19:25:36,861 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2639
[INFO] 2021-07-12 19:25:36,861 [run_pretraining.py:  558]:	worker_index: 6, step: 2639, cost: 7.735542, mlm loss: 7.735542, speed: 1.093012 steps/s, speed: 8.744095 samples/s, speed: 4476.976539 tokens/s, learning rate: 2.638e-05, loss_scalings: 2814.750488, pp_loss: 7.476582
[INFO] 2021-07-12 19:25:36,861 [run_pretraining.py:  512]:	********exe.run_2639******* 
[INFO] 2021-07-12 19:25:37,774 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:37,774 [run_pretraining.py:  534]:	loss/total_loss, 7.289373397827148, 2640
[INFO] 2021-07-12 19:25:37,774 [run_pretraining.py:  535]:	loss/mlm_loss, 7.289373397827148, 2640
[INFO] 2021-07-12 19:25:37,774 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6390000130049884e-05, 2640
[INFO] 2021-07-12 19:25:37,775 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2640
[INFO] 2021-07-12 19:25:37,775 [run_pretraining.py:  558]:	worker_index: 6, step: 2640, cost: 7.289373, mlm loss: 7.289373, speed: 1.095692 steps/s, speed: 8.765539 samples/s, speed: 4487.956142 tokens/s, learning rate: 2.639e-05, loss_scalings: 2814.750488, pp_loss: 7.037364
[INFO] 2021-07-12 19:25:37,775 [run_pretraining.py:  512]:	********exe.run_2640******* 
[INFO] 2021-07-12 19:26:03,400 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:03,401 [run_pretraining.py:  534]:	loss/total_loss, 7.081516265869141, 2641
[INFO] 2021-07-12 19:26:03,401 [run_pretraining.py:  535]:	loss/mlm_loss, 7.081516265869141, 2641
[INFO] 2021-07-12 19:26:03,401 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6399999114801176e-05, 2641
[INFO] 2021-07-12 19:26:03,401 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2641
[INFO] 2021-07-12 19:26:03,401 [run_pretraining.py:  558]:	worker_index: 6, step: 2641, cost: 7.081516, mlm loss: 7.081516, speed: 0.039023 steps/s, speed: 0.312183 samples/s, speed: 159.837569 tokens/s, learning rate: 2.640e-05, loss_scalings: 2814.750488, pp_loss: 6.851545
[INFO] 2021-07-12 19:26:03,401 [run_pretraining.py:  512]:	********exe.run_2641******* 
[INFO] 2021-07-12 19:26:04,314 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:04,315 [run_pretraining.py:  534]:	loss/total_loss, 7.19908332824707, 2642
[INFO] 2021-07-12 19:26:04,315 [run_pretraining.py:  535]:	loss/mlm_loss, 7.19908332824707, 2642
[INFO] 2021-07-12 19:26:04,315 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6409998099552467e-05, 2642
[INFO] 2021-07-12 19:26:04,315 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2642
[INFO] 2021-07-12 19:26:04,315 [run_pretraining.py:  558]:	worker_index: 6, step: 2642, cost: 7.199083, mlm loss: 7.199083, speed: 1.095388 steps/s, speed: 8.763106 samples/s, speed: 4486.710222 tokens/s, learning rate: 2.641e-05, loss_scalings: 2814.750488, pp_loss: 7.411065
[INFO] 2021-07-12 19:26:04,315 [run_pretraining.py:  512]:	********exe.run_2642******* 
[INFO] 2021-07-12 19:26:05,231 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:05,231 [run_pretraining.py:  534]:	loss/total_loss, 7.867430686950684, 2643
[INFO] 2021-07-12 19:26:05,231 [run_pretraining.py:  535]:	loss/mlm_loss, 7.867430686950684, 2643
[INFO] 2021-07-12 19:26:05,231 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6419998903293163e-05, 2643
[INFO] 2021-07-12 19:26:05,231 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2643
[INFO] 2021-07-12 19:26:05,232 [run_pretraining.py:  558]:	worker_index: 6, step: 2643, cost: 7.867431, mlm loss: 7.867431, speed: 1.091907 steps/s, speed: 8.735256 samples/s, speed: 4472.450920 tokens/s, learning rate: 2.642e-05, loss_scalings: 2814.750488, pp_loss: 7.004772
[INFO] 2021-07-12 19:26:05,232 [run_pretraining.py:  512]:	********exe.run_2643******* 
[INFO] 2021-07-12 19:26:06,149 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:06,149 [run_pretraining.py:  534]:	loss/total_loss, 7.372053146362305, 2644
[INFO] 2021-07-12 19:26:06,150 [run_pretraining.py:  535]:	loss/mlm_loss, 7.372053146362305, 2644
[INFO] 2021-07-12 19:26:06,150 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6429997888044454e-05, 2644
[INFO] 2021-07-12 19:26:06,150 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2644
[INFO] 2021-07-12 19:26:06,150 [run_pretraining.py:  558]:	worker_index: 6, step: 2644, cost: 7.372053, mlm loss: 7.372053, speed: 1.089875 steps/s, speed: 8.718997 samples/s, speed: 4464.126439 tokens/s, learning rate: 2.643e-05, loss_scalings: 2814.750488, pp_loss: 7.200020
[INFO] 2021-07-12 19:26:06,150 [run_pretraining.py:  512]:	********exe.run_2644******* 
[INFO] 2021-07-12 19:26:07,061 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:07,062 [run_pretraining.py:  534]:	loss/total_loss, 7.705649375915527, 2645
[INFO] 2021-07-12 19:26:07,062 [run_pretraining.py:  535]:	loss/mlm_loss, 7.705649375915527, 2645
[INFO] 2021-07-12 19:26:07,062 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6440000510774553e-05, 2645
[INFO] 2021-07-12 19:26:07,062 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2645
[INFO] 2021-07-12 19:26:07,062 [run_pretraining.py:  558]:	worker_index: 6, step: 2645, cost: 7.705649, mlm loss: 7.705649, speed: 1.096807 steps/s, speed: 8.774456 samples/s, speed: 4492.521434 tokens/s, learning rate: 2.644e-05, loss_scalings: 2814.750488, pp_loss: 7.688622
[INFO] 2021-07-12 19:26:07,062 [run_pretraining.py:  512]:	********exe.run_2645******* 
[INFO] 2021-07-12 19:26:07,980 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:07,980 [run_pretraining.py:  534]:	loss/total_loss, 5.094639301300049, 2646
[INFO] 2021-07-12 19:26:07,980 [run_pretraining.py:  535]:	loss/mlm_loss, 5.094639301300049, 2646
[INFO] 2021-07-12 19:26:07,980 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.644999767653644e-05, 2646
[INFO] 2021-07-12 19:26:07,980 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2646
[INFO] 2021-07-12 19:26:07,981 [run_pretraining.py:  558]:	worker_index: 6, step: 2646, cost: 5.094639, mlm loss: 5.094639, speed: 1.089787 steps/s, speed: 8.718297 samples/s, speed: 4463.768032 tokens/s, learning rate: 2.645e-05, loss_scalings: 2814.750488, pp_loss: 6.785412
[INFO] 2021-07-12 19:26:07,981 [run_pretraining.py:  512]:	********exe.run_2646******* 
[INFO] 2021-07-12 19:26:08,898 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:08,899 [run_pretraining.py:  534]:	loss/total_loss, 7.407232284545898, 2647
[INFO] 2021-07-12 19:26:08,899 [run_pretraining.py:  535]:	loss/mlm_loss, 7.407232284545898, 2647
[INFO] 2021-07-12 19:26:08,899 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.646000029926654e-05, 2647
[INFO] 2021-07-12 19:26:08,899 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2647
[INFO] 2021-07-12 19:26:08,899 [run_pretraining.py:  558]:	worker_index: 6, step: 2647, cost: 7.407232, mlm loss: 7.407232, speed: 1.089628 steps/s, speed: 8.717024 samples/s, speed: 4463.116319 tokens/s, learning rate: 2.646e-05, loss_scalings: 2814.750488, pp_loss: 7.083523
[INFO] 2021-07-12 19:26:08,899 [run_pretraining.py:  512]:	********exe.run_2647******* 
[INFO] 2021-07-12 19:26:09,812 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:09,813 [run_pretraining.py:  534]:	loss/total_loss, 7.28751802444458, 2648
[INFO] 2021-07-12 19:26:09,813 [run_pretraining.py:  535]:	loss/mlm_loss, 7.28751802444458, 2648
[INFO] 2021-07-12 19:26:09,813 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.646999928401783e-05, 2648
[INFO] 2021-07-12 19:26:09,813 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2648
[INFO] 2021-07-12 19:26:09,813 [run_pretraining.py:  558]:	worker_index: 6, step: 2648, cost: 7.287518, mlm loss: 7.287518, speed: 1.094339 steps/s, speed: 8.754708 samples/s, speed: 4482.410497 tokens/s, learning rate: 2.647e-05, loss_scalings: 2814.750488, pp_loss: 7.174351
[INFO] 2021-07-12 19:26:09,814 [run_pretraining.py:  512]:	********exe.run_2648******* 
[INFO] 2021-07-12 19:26:10,731 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:10,732 [run_pretraining.py:  534]:	loss/total_loss, 6.758291244506836, 2649
[INFO] 2021-07-12 19:26:10,732 [run_pretraining.py:  535]:	loss/mlm_loss, 6.758291244506836, 2649
[INFO] 2021-07-12 19:26:10,732 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6480000087758526e-05, 2649
[INFO] 2021-07-12 19:26:10,732 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2649
[INFO] 2021-07-12 19:26:10,732 [run_pretraining.py:  558]:	worker_index: 6, step: 2649, cost: 6.758291, mlm loss: 6.758291, speed: 1.088969 steps/s, speed: 8.711755 samples/s, speed: 4460.418723 tokens/s, learning rate: 2.648e-05, loss_scalings: 2814.750488, pp_loss: 6.853289
[INFO] 2021-07-12 19:26:10,733 [run_pretraining.py:  512]:	********exe.run_2649******* 
[INFO] 2021-07-12 19:26:11,643 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:11,644 [run_pretraining.py:  534]:	loss/total_loss, 7.168179035186768, 2650
[INFO] 2021-07-12 19:26:11,644 [run_pretraining.py:  535]:	loss/mlm_loss, 7.168179035186768, 2650
[INFO] 2021-07-12 19:26:11,644 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6489999072509818e-05, 2650
[INFO] 2021-07-12 19:26:11,644 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2650
[INFO] 2021-07-12 19:26:11,644 [run_pretraining.py:  558]:	worker_index: 6, step: 2650, cost: 7.168179, mlm loss: 7.168179, speed: 1.097350 steps/s, speed: 8.778804 samples/s, speed: 4494.747589 tokens/s, learning rate: 2.649e-05, loss_scalings: 2814.750488, pp_loss: 7.269787
[INFO] 2021-07-12 19:26:11,645 [run_pretraining.py:  512]:	********exe.run_2650******* 
[INFO] 2021-07-12 19:26:12,561 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:12,562 [run_pretraining.py:  534]:	loss/total_loss, 7.702948093414307, 2651
[INFO] 2021-07-12 19:26:12,562 [run_pretraining.py:  535]:	loss/mlm_loss, 7.702948093414307, 2651
[INFO] 2021-07-12 19:26:12,562 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.649999805726111e-05, 2651
[INFO] 2021-07-12 19:26:12,562 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2651
[INFO] 2021-07-12 19:26:12,562 [run_pretraining.py:  558]:	worker_index: 6, step: 2651, cost: 7.702948, mlm loss: 7.702948, speed: 1.090423 steps/s, speed: 8.723383 samples/s, speed: 4466.372143 tokens/s, learning rate: 2.650e-05, loss_scalings: 2814.750488, pp_loss: 7.497452
[INFO] 2021-07-12 19:26:12,562 [run_pretraining.py:  512]:	********exe.run_2651******* 
[INFO] 2021-07-12 19:26:13,472 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:13,473 [run_pretraining.py:  534]:	loss/total_loss, 7.342377185821533, 2652
[INFO] 2021-07-12 19:26:13,473 [run_pretraining.py:  535]:	loss/mlm_loss, 7.342377185821533, 2652
[INFO] 2021-07-12 19:26:13,473 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6509998861001804e-05, 2652
[INFO] 2021-07-12 19:26:13,473 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2652
[INFO] 2021-07-12 19:26:13,473 [run_pretraining.py:  558]:	worker_index: 6, step: 2652, cost: 7.342377, mlm loss: 7.342377, speed: 1.098884 steps/s, speed: 8.791070 samples/s, speed: 4501.027721 tokens/s, learning rate: 2.651e-05, loss_scalings: 2814.750488, pp_loss: 6.827642
[INFO] 2021-07-12 19:26:13,473 [run_pretraining.py:  512]:	********exe.run_2652******* 
[INFO] 2021-07-12 19:26:14,383 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:14,383 [run_pretraining.py:  534]:	loss/total_loss, 7.285269737243652, 2653
[INFO] 2021-07-12 19:26:14,384 [run_pretraining.py:  535]:	loss/mlm_loss, 7.285269737243652, 2653
[INFO] 2021-07-12 19:26:14,384 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6519997845753096e-05, 2653
[INFO] 2021-07-12 19:26:14,384 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2653
[INFO] 2021-07-12 19:26:14,384 [run_pretraining.py:  558]:	worker_index: 6, step: 2653, cost: 7.285270, mlm loss: 7.285270, speed: 1.098771 steps/s, speed: 8.790169 samples/s, speed: 4500.566684 tokens/s, learning rate: 2.652e-05, loss_scalings: 2814.750488, pp_loss: 7.243716
[INFO] 2021-07-12 19:26:14,384 [run_pretraining.py:  512]:	********exe.run_2653******* 
[INFO] 2021-07-12 19:26:15,300 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:15,301 [run_pretraining.py:  534]:	loss/total_loss, 7.693877696990967, 2654
[INFO] 2021-07-12 19:26:15,301 [run_pretraining.py:  535]:	loss/mlm_loss, 7.693877696990967, 2654
[INFO] 2021-07-12 19:26:15,301 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6530000468483195e-05, 2654
[INFO] 2021-07-12 19:26:15,301 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2654
[INFO] 2021-07-12 19:26:15,301 [run_pretraining.py:  558]:	worker_index: 6, step: 2654, cost: 7.693878, mlm loss: 7.693878, speed: 1.090859 steps/s, speed: 8.726870 samples/s, speed: 4468.157551 tokens/s, learning rate: 2.653e-05, loss_scalings: 2814.750488, pp_loss: 6.923544
[INFO] 2021-07-12 19:26:15,301 [run_pretraining.py:  512]:	********exe.run_2654******* 
[INFO] 2021-07-12 19:26:16,220 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:16,220 [run_pretraining.py:  534]:	loss/total_loss, 6.538372039794922, 2655
[INFO] 2021-07-12 19:26:16,220 [run_pretraining.py:  535]:	loss/mlm_loss, 6.538372039794922, 2655
[INFO] 2021-07-12 19:26:16,221 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6539999453234486e-05, 2655
[INFO] 2021-07-12 19:26:16,221 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2655
[INFO] 2021-07-12 19:26:16,221 [run_pretraining.py:  558]:	worker_index: 6, step: 2655, cost: 6.538372, mlm loss: 6.538372, speed: 1.088379 steps/s, speed: 8.707031 samples/s, speed: 4457.999688 tokens/s, learning rate: 2.654e-05, loss_scalings: 2814.750488, pp_loss: 6.903078
[INFO] 2021-07-12 19:26:16,221 [run_pretraining.py:  512]:	********exe.run_2655******* 
[INFO] 2021-07-12 19:26:17,134 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:17,135 [run_pretraining.py:  534]:	loss/total_loss, 8.100236892700195, 2656
[INFO] 2021-07-12 19:26:17,135 [run_pretraining.py:  535]:	loss/mlm_loss, 8.100236892700195, 2656
[INFO] 2021-07-12 19:26:17,135 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.655000025697518e-05, 2656
[INFO] 2021-07-12 19:26:17,135 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2656
[INFO] 2021-07-12 19:26:17,135 [run_pretraining.py:  558]:	worker_index: 6, step: 2656, cost: 8.100237, mlm loss: 8.100237, speed: 1.094712 steps/s, speed: 8.757694 samples/s, speed: 4483.939566 tokens/s, learning rate: 2.655e-05, loss_scalings: 2814.750488, pp_loss: 7.360599
[INFO] 2021-07-12 19:26:17,135 [run_pretraining.py:  512]:	********exe.run_2656******* 
[INFO] 2021-07-12 19:26:18,045 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:18,046 [run_pretraining.py:  534]:	loss/total_loss, 7.69706916809082, 2657
[INFO] 2021-07-12 19:26:18,046 [run_pretraining.py:  535]:	loss/mlm_loss, 7.69706916809082, 2657
[INFO] 2021-07-12 19:26:18,046 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6559999241726473e-05, 2657
[INFO] 2021-07-12 19:26:18,046 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2657
[INFO] 2021-07-12 19:26:18,046 [run_pretraining.py:  558]:	worker_index: 6, step: 2657, cost: 7.697069, mlm loss: 7.697069, speed: 1.098237 steps/s, speed: 8.785897 samples/s, speed: 4498.379519 tokens/s, learning rate: 2.656e-05, loss_scalings: 2814.750488, pp_loss: 7.405040
[INFO] 2021-07-12 19:26:18,046 [run_pretraining.py:  512]:	********exe.run_2657******* 
[INFO] 2021-07-12 19:26:18,966 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:18,966 [run_pretraining.py:  534]:	loss/total_loss, 7.946390151977539, 2658
[INFO] 2021-07-12 19:26:18,966 [run_pretraining.py:  535]:	loss/mlm_loss, 7.946390151977539, 2658
[INFO] 2021-07-12 19:26:18,966 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6570000045467168e-05, 2658
[INFO] 2021-07-12 19:26:18,967 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2658
[INFO] 2021-07-12 19:26:18,967 [run_pretraining.py:  558]:	worker_index: 6, step: 2658, cost: 7.946390, mlm loss: 7.946390, speed: 1.087256 steps/s, speed: 8.698050 samples/s, speed: 4453.401508 tokens/s, learning rate: 2.657e-05, loss_scalings: 2814.750488, pp_loss: 7.191242
[INFO] 2021-07-12 19:26:18,967 [run_pretraining.py:  512]:	********exe.run_2658******* 
[INFO] 2021-07-12 19:26:19,879 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:19,879 [run_pretraining.py:  534]:	loss/total_loss, 7.457561492919922, 2659
[INFO] 2021-07-12 19:26:19,880 [run_pretraining.py:  535]:	loss/mlm_loss, 7.457561492919922, 2659
[INFO] 2021-07-12 19:26:19,880 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.657999903021846e-05, 2659
[INFO] 2021-07-12 19:26:19,880 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2659
[INFO] 2021-07-12 19:26:19,880 [run_pretraining.py:  558]:	worker_index: 6, step: 2659, cost: 7.457561, mlm loss: 7.457561, speed: 1.095885 steps/s, speed: 8.767076 samples/s, speed: 4488.742963 tokens/s, learning rate: 2.658e-05, loss_scalings: 2814.750488, pp_loss: 6.887088
[INFO] 2021-07-12 19:26:19,880 [run_pretraining.py:  512]:	********exe.run_2659******* 
[INFO] 2021-07-12 19:26:20,807 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:20,808 [run_pretraining.py:  534]:	loss/total_loss, 6.8514509201049805, 2660
[INFO] 2021-07-12 19:26:20,808 [run_pretraining.py:  535]:	loss/mlm_loss, 6.8514509201049805, 2660
[INFO] 2021-07-12 19:26:20,808 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.658999801496975e-05, 2660
[INFO] 2021-07-12 19:26:20,808 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2660
[INFO] 2021-07-12 19:26:20,808 [run_pretraining.py:  558]:	worker_index: 6, step: 2660, cost: 6.851451, mlm loss: 6.851451, speed: 1.077880 steps/s, speed: 8.623038 samples/s, speed: 4414.995573 tokens/s, learning rate: 2.659e-05, loss_scalings: 2814.750488, pp_loss: 6.912784
[INFO] 2021-07-12 19:26:20,808 [run_pretraining.py:  512]:	********exe.run_2660******* 
[INFO] 2021-07-12 19:26:21,731 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:21,732 [run_pretraining.py:  534]:	loss/total_loss, 6.766197204589844, 2661
[INFO] 2021-07-12 19:26:21,732 [run_pretraining.py:  535]:	loss/mlm_loss, 6.766197204589844, 2661
[INFO] 2021-07-12 19:26:21,732 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6599998818710446e-05, 2661
[INFO] 2021-07-12 19:26:21,732 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2661
[INFO] 2021-07-12 19:26:21,732 [run_pretraining.py:  558]:	worker_index: 6, step: 2661, cost: 6.766197, mlm loss: 6.766197, speed: 1.082972 steps/s, speed: 8.663774 samples/s, speed: 4435.852179 tokens/s, learning rate: 2.660e-05, loss_scalings: 2814.750488, pp_loss: 7.245633
[INFO] 2021-07-12 19:26:21,733 [run_pretraining.py:  512]:	********exe.run_2661******* 
[INFO] 2021-07-12 19:26:22,648 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:22,649 [run_pretraining.py:  534]:	loss/total_loss, 6.6138997077941895, 2662
[INFO] 2021-07-12 19:26:22,649 [run_pretraining.py:  535]:	loss/mlm_loss, 6.6138997077941895, 2662
[INFO] 2021-07-12 19:26:22,649 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6609997803461738e-05, 2662
[INFO] 2021-07-12 19:26:22,649 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2662
[INFO] 2021-07-12 19:26:22,649 [run_pretraining.py:  558]:	worker_index: 6, step: 2662, cost: 6.613900, mlm loss: 6.613900, speed: 1.091792 steps/s, speed: 8.734335 samples/s, speed: 4471.979421 tokens/s, learning rate: 2.661e-05, loss_scalings: 2814.750488, pp_loss: 7.131736
[INFO] 2021-07-12 19:26:22,649 [run_pretraining.py:  512]:	********exe.run_2662******* 
[INFO] 2021-07-12 19:26:23,570 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:23,570 [run_pretraining.py:  534]:	loss/total_loss, 7.516180038452148, 2663
[INFO] 2021-07-12 19:26:23,571 [run_pretraining.py:  535]:	loss/mlm_loss, 7.516180038452148, 2663
[INFO] 2021-07-12 19:26:23,571 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6620000426191837e-05, 2663
[INFO] 2021-07-12 19:26:23,571 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2663
[INFO] 2021-07-12 19:26:23,571 [run_pretraining.py:  558]:	worker_index: 6, step: 2663, cost: 7.516180, mlm loss: 7.516180, speed: 1.085700 steps/s, speed: 8.685601 samples/s, speed: 4447.027855 tokens/s, learning rate: 2.662e-05, loss_scalings: 2814.750488, pp_loss: 7.163007
[INFO] 2021-07-12 19:26:23,571 [run_pretraining.py:  512]:	********exe.run_2663******* 
[INFO] 2021-07-12 19:26:24,481 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:24,481 [run_pretraining.py:  534]:	loss/total_loss, 7.50789737701416, 2664
[INFO] 2021-07-12 19:26:24,481 [run_pretraining.py:  535]:	loss/mlm_loss, 7.50789737701416, 2664
[INFO] 2021-07-12 19:26:24,481 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6629999410943128e-05, 2664
[INFO] 2021-07-12 19:26:24,481 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2664
[INFO] 2021-07-12 19:26:24,482 [run_pretraining.py:  558]:	worker_index: 6, step: 2664, cost: 7.507897, mlm loss: 7.507897, speed: 1.098923 steps/s, speed: 8.791381 samples/s, speed: 4501.186924 tokens/s, learning rate: 2.663e-05, loss_scalings: 2814.750488, pp_loss: 7.440685
[INFO] 2021-07-12 19:26:24,482 [run_pretraining.py:  512]:	********exe.run_2664******* 
[INFO] 2021-07-12 19:26:25,392 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:25,392 [run_pretraining.py:  534]:	loss/total_loss, 6.928633213043213, 2665
[INFO] 2021-07-12 19:26:25,392 [run_pretraining.py:  535]:	loss/mlm_loss, 6.928633213043213, 2665
[INFO] 2021-07-12 19:26:25,393 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6640000214683823e-05, 2665
[INFO] 2021-07-12 19:26:25,393 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2665
[INFO] 2021-07-12 19:26:25,393 [run_pretraining.py:  558]:	worker_index: 6, step: 2665, cost: 6.928633, mlm loss: 6.928633, speed: 1.098347 steps/s, speed: 8.786774 samples/s, speed: 4498.828328 tokens/s, learning rate: 2.664e-05, loss_scalings: 2814.750488, pp_loss: 6.883856
[INFO] 2021-07-12 19:26:25,393 [run_pretraining.py:  512]:	********exe.run_2665******* 
[INFO] 2021-07-12 19:26:26,316 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:26,317 [run_pretraining.py:  534]:	loss/total_loss, 7.266861438751221, 2666
[INFO] 2021-07-12 19:26:26,317 [run_pretraining.py:  535]:	loss/mlm_loss, 7.266861438751221, 2666
[INFO] 2021-07-12 19:26:26,317 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6649999199435115e-05, 2666
[INFO] 2021-07-12 19:26:26,317 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2666
[INFO] 2021-07-12 19:26:26,317 [run_pretraining.py:  558]:	worker_index: 6, step: 2666, cost: 7.266861, mlm loss: 7.266861, speed: 1.082302 steps/s, speed: 8.658420 samples/s, speed: 4433.110786 tokens/s, learning rate: 2.665e-05, loss_scalings: 2814.750488, pp_loss: 7.184476
[INFO] 2021-07-12 19:26:26,318 [run_pretraining.py:  512]:	********exe.run_2666******* 
[INFO] 2021-07-12 19:26:27,233 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:27,234 [run_pretraining.py:  534]:	loss/total_loss, 7.146881103515625, 2667
[INFO] 2021-07-12 19:26:27,234 [run_pretraining.py:  535]:	loss/mlm_loss, 7.146881103515625, 2667
[INFO] 2021-07-12 19:26:27,234 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.666000000317581e-05, 2667
[INFO] 2021-07-12 19:26:27,234 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2667
[INFO] 2021-07-12 19:26:27,234 [run_pretraining.py:  558]:	worker_index: 6, step: 2667, cost: 7.146881, mlm loss: 7.146881, speed: 1.091509 steps/s, speed: 8.732069 samples/s, speed: 4470.819143 tokens/s, learning rate: 2.666e-05, loss_scalings: 2814.750488, pp_loss: 7.245672
[INFO] 2021-07-12 19:26:27,234 [run_pretraining.py:  512]:	********exe.run_2667******* 
[INFO] 2021-07-12 19:26:28,150 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:28,151 [run_pretraining.py:  534]:	loss/total_loss, 7.29592227935791, 2668
[INFO] 2021-07-12 19:26:28,151 [run_pretraining.py:  535]:	loss/mlm_loss, 7.29592227935791, 2668
[INFO] 2021-07-12 19:26:28,151 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.66699989879271e-05, 2668
[INFO] 2021-07-12 19:26:28,151 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2668
[INFO] 2021-07-12 19:26:28,151 [run_pretraining.py:  558]:	worker_index: 6, step: 2668, cost: 7.295922, mlm loss: 7.295922, speed: 1.091647 steps/s, speed: 8.733173 samples/s, speed: 4471.384660 tokens/s, learning rate: 2.667e-05, loss_scalings: 2814.750488, pp_loss: 7.286783
[INFO] 2021-07-12 19:26:28,151 [run_pretraining.py:  512]:	********exe.run_2668******* 
[INFO] 2021-07-12 19:26:29,074 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:29,074 [run_pretraining.py:  534]:	loss/total_loss, 7.82873010635376, 2669
[INFO] 2021-07-12 19:26:29,074 [run_pretraining.py:  535]:	loss/mlm_loss, 7.82873010635376, 2669
[INFO] 2021-07-12 19:26:29,074 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6679997972678393e-05, 2669
[INFO] 2021-07-12 19:26:29,075 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2669
[INFO] 2021-07-12 19:26:29,075 [run_pretraining.py:  558]:	worker_index: 6, step: 2669, cost: 7.828730, mlm loss: 7.828730, speed: 1.083527 steps/s, speed: 8.668216 samples/s, speed: 4438.126844 tokens/s, learning rate: 2.668e-05, loss_scalings: 2814.750488, pp_loss: 6.540822
[INFO] 2021-07-12 19:26:29,075 [run_pretraining.py:  512]:	********exe.run_2669******* 
[INFO] 2021-07-12 19:26:29,993 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:29,994 [run_pretraining.py:  534]:	loss/total_loss, 7.359221935272217, 2670
[INFO] 2021-07-12 19:26:29,994 [run_pretraining.py:  535]:	loss/mlm_loss, 7.359221935272217, 2670
[INFO] 2021-07-12 19:26:29,994 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6689998776419088e-05, 2670
[INFO] 2021-07-12 19:26:29,994 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2670
[INFO] 2021-07-12 19:26:29,994 [run_pretraining.py:  558]:	worker_index: 6, step: 2670, cost: 7.359222, mlm loss: 7.359222, speed: 1.088366 steps/s, speed: 8.706931 samples/s, speed: 4457.948789 tokens/s, learning rate: 2.669e-05, loss_scalings: 2814.750488, pp_loss: 7.244404
[INFO] 2021-07-12 19:26:29,994 [run_pretraining.py:  512]:	********exe.run_2670******* 
[INFO] 2021-07-12 19:26:31,029 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:31,030 [run_pretraining.py:  534]:	loss/total_loss, 7.197174549102783, 2671
[INFO] 2021-07-12 19:26:31,030 [run_pretraining.py:  535]:	loss/mlm_loss, 7.197174549102783, 2671
[INFO] 2021-07-12 19:26:31,030 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.669999776117038e-05, 2671
[INFO] 2021-07-12 19:26:31,030 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2671
[INFO] 2021-07-12 19:26:31,030 [run_pretraining.py:  558]:	worker_index: 6, step: 2671, cost: 7.197175, mlm loss: 7.197175, speed: 0.966073 steps/s, speed: 7.728585 samples/s, speed: 3957.035477 tokens/s, learning rate: 2.670e-05, loss_scalings: 2814.750488, pp_loss: 7.186202
[INFO] 2021-07-12 19:26:31,030 [run_pretraining.py:  512]:	********exe.run_2671******* 
[INFO] 2021-07-12 19:26:32,124 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:32,125 [run_pretraining.py:  534]:	loss/total_loss, 5.0395073890686035, 2672
[INFO] 2021-07-12 19:26:32,125 [run_pretraining.py:  535]:	loss/mlm_loss, 5.0395073890686035, 2672
[INFO] 2021-07-12 19:26:32,125 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.671000038390048e-05, 2672
[INFO] 2021-07-12 19:26:32,125 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2672
[INFO] 2021-07-12 19:26:32,125 [run_pretraining.py:  558]:	worker_index: 6, step: 2672, cost: 5.039507, mlm loss: 5.039507, speed: 0.913730 steps/s, speed: 7.309842 samples/s, speed: 3742.638934 tokens/s, learning rate: 2.671e-05, loss_scalings: 2814.750488, pp_loss: 6.400452
[INFO] 2021-07-12 19:26:32,125 [run_pretraining.py:  512]:	********exe.run_2672******* 
[INFO] 2021-07-12 19:26:33,224 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:33,225 [run_pretraining.py:  534]:	loss/total_loss, 6.38463830947876, 2673
[INFO] 2021-07-12 19:26:33,225 [run_pretraining.py:  535]:	loss/mlm_loss, 6.38463830947876, 2673
[INFO] 2021-07-12 19:26:33,225 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.671999936865177e-05, 2673
[INFO] 2021-07-12 19:26:33,225 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2673
[INFO] 2021-07-12 19:26:33,225 [run_pretraining.py:  558]:	worker_index: 6, step: 2673, cost: 6.384638, mlm loss: 6.384638, speed: 0.909682 steps/s, speed: 7.277452 samples/s, speed: 3726.055451 tokens/s, learning rate: 2.672e-05, loss_scalings: 2814.750488, pp_loss: 7.269710
[INFO] 2021-07-12 19:26:33,225 [run_pretraining.py:  512]:	********exe.run_2673******* 
[INFO] 2021-07-12 19:26:34,314 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:34,315 [run_pretraining.py:  534]:	loss/total_loss, 7.950385093688965, 2674
[INFO] 2021-07-12 19:26:34,315 [run_pretraining.py:  535]:	loss/mlm_loss, 7.950385093688965, 2674
[INFO] 2021-07-12 19:26:34,315 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6730000172392465e-05, 2674
[INFO] 2021-07-12 19:26:34,315 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2674
[INFO] 2021-07-12 19:26:34,315 [run_pretraining.py:  558]:	worker_index: 6, step: 2674, cost: 7.950385, mlm loss: 7.950385, speed: 0.918089 steps/s, speed: 7.344711 samples/s, speed: 3760.492288 tokens/s, learning rate: 2.673e-05, loss_scalings: 2814.750488, pp_loss: 7.361844
[INFO] 2021-07-12 19:26:34,315 [run_pretraining.py:  512]:	********exe.run_2674******* 
[INFO] 2021-07-12 19:26:35,407 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:35,408 [run_pretraining.py:  534]:	loss/total_loss, 7.625744342803955, 2675
[INFO] 2021-07-12 19:26:35,408 [run_pretraining.py:  535]:	loss/mlm_loss, 7.625744342803955, 2675
[INFO] 2021-07-12 19:26:35,408 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6739999157143757e-05, 2675
[INFO] 2021-07-12 19:26:35,408 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2675
[INFO] 2021-07-12 19:26:35,408 [run_pretraining.py:  558]:	worker_index: 6, step: 2675, cost: 7.625744, mlm loss: 7.625744, speed: 0.915497 steps/s, speed: 7.323978 samples/s, speed: 3749.876771 tokens/s, learning rate: 2.674e-05, loss_scalings: 2814.750488, pp_loss: 7.243304
[INFO] 2021-07-12 19:26:35,408 [run_pretraining.py:  512]:	********exe.run_2675******* 
[INFO] 2021-07-12 19:26:36,510 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:36,511 [run_pretraining.py:  534]:	loss/total_loss, 6.701105117797852, 2676
[INFO] 2021-07-12 19:26:36,511 [run_pretraining.py:  535]:	loss/mlm_loss, 6.701105117797852, 2676
[INFO] 2021-07-12 19:26:36,511 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6749999960884452e-05, 2676
[INFO] 2021-07-12 19:26:36,511 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2676
[INFO] 2021-07-12 19:26:36,511 [run_pretraining.py:  558]:	worker_index: 6, step: 2676, cost: 6.701105, mlm loss: 6.701105, speed: 0.907213 steps/s, speed: 7.257704 samples/s, speed: 3715.944222 tokens/s, learning rate: 2.675e-05, loss_scalings: 2814.750488, pp_loss: 6.714583
[INFO] 2021-07-12 19:26:36,511 [run_pretraining.py:  512]:	********exe.run_2676******* 
[INFO] 2021-07-12 19:26:37,600 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:37,600 [run_pretraining.py:  534]:	loss/total_loss, 7.536322593688965, 2677
[INFO] 2021-07-12 19:26:37,600 [run_pretraining.py:  535]:	loss/mlm_loss, 7.536322593688965, 2677
[INFO] 2021-07-12 19:26:37,601 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6759998945635743e-05, 2677
[INFO] 2021-07-12 19:26:37,601 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2677
[INFO] 2021-07-12 19:26:37,601 [run_pretraining.py:  558]:	worker_index: 6, step: 2677, cost: 7.536323, mlm loss: 7.536323, speed: 0.918225 steps/s, speed: 7.345802 samples/s, speed: 3761.050454 tokens/s, learning rate: 2.676e-05, loss_scalings: 2814.750488, pp_loss: 7.290191
[INFO] 2021-07-12 19:26:37,601 [run_pretraining.py:  512]:	********exe.run_2677******* 
[INFO] 2021-07-12 19:26:38,691 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:38,691 [run_pretraining.py:  534]:	loss/total_loss, 7.492406368255615, 2678
[INFO] 2021-07-12 19:26:38,692 [run_pretraining.py:  535]:	loss/mlm_loss, 7.492406368255615, 2678
[INFO] 2021-07-12 19:26:38,692 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6769997930387035e-05, 2678
[INFO] 2021-07-12 19:26:38,692 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2678
[INFO] 2021-07-12 19:26:38,692 [run_pretraining.py:  558]:	worker_index: 6, step: 2678, cost: 7.492406, mlm loss: 7.492406, speed: 0.917164 steps/s, speed: 7.337314 samples/s, speed: 3756.704760 tokens/s, learning rate: 2.677e-05, loss_scalings: 2814.750488, pp_loss: 7.326287
[INFO] 2021-07-12 19:26:38,692 [run_pretraining.py:  512]:	********exe.run_2678******* 
[INFO] 2021-07-12 19:26:39,796 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:39,796 [run_pretraining.py:  534]:	loss/total_loss, 7.094974994659424, 2679
[INFO] 2021-07-12 19:26:39,796 [run_pretraining.py:  535]:	loss/mlm_loss, 7.094974994659424, 2679
[INFO] 2021-07-12 19:26:39,797 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6780000553117134e-05, 2679
[INFO] 2021-07-12 19:26:39,797 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2679
[INFO] 2021-07-12 19:26:39,797 [run_pretraining.py:  558]:	worker_index: 6, step: 2679, cost: 7.094975, mlm loss: 7.094975, speed: 0.905615 steps/s, speed: 7.244920 samples/s, speed: 3709.398817 tokens/s, learning rate: 2.678e-05, loss_scalings: 2814.750488, pp_loss: 7.036777
[INFO] 2021-07-12 19:26:39,797 [run_pretraining.py:  512]:	********exe.run_2679******* 
[INFO] 2021-07-12 19:26:40,882 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:40,882 [run_pretraining.py:  534]:	loss/total_loss, 7.5041961669921875, 2680
[INFO] 2021-07-12 19:26:40,883 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5041961669921875, 2680
[INFO] 2021-07-12 19:26:40,883 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6789997718879022e-05, 2680
[INFO] 2021-07-12 19:26:40,883 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2680
[INFO] 2021-07-12 19:26:40,883 [run_pretraining.py:  558]:	worker_index: 6, step: 2680, cost: 7.504196, mlm loss: 7.504196, speed: 0.921327 steps/s, speed: 7.370619 samples/s, speed: 3773.756767 tokens/s, learning rate: 2.679e-05, loss_scalings: 2814.750488, pp_loss: 7.243852
[INFO] 2021-07-12 19:26:40,883 [run_pretraining.py:  512]:	********exe.run_2680******* 
[INFO] 2021-07-12 19:26:41,974 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:41,974 [run_pretraining.py:  534]:	loss/total_loss, 7.346591949462891, 2681
[INFO] 2021-07-12 19:26:41,974 [run_pretraining.py:  535]:	loss/mlm_loss, 7.346591949462891, 2681
[INFO] 2021-07-12 19:26:41,974 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.680000034160912e-05, 2681
[INFO] 2021-07-12 19:26:41,975 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2681
[INFO] 2021-07-12 19:26:41,975 [run_pretraining.py:  558]:	worker_index: 6, step: 2681, cost: 7.346592, mlm loss: 7.346592, speed: 0.916477 steps/s, speed: 7.331818 samples/s, speed: 3753.890853 tokens/s, learning rate: 2.680e-05, loss_scalings: 2814.750488, pp_loss: 7.470850
[INFO] 2021-07-12 19:26:41,975 [run_pretraining.py:  512]:	********exe.run_2681******* 
[INFO] 2021-07-12 19:26:43,076 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:43,076 [run_pretraining.py:  534]:	loss/total_loss, 7.774594306945801, 2682
[INFO] 2021-07-12 19:26:43,077 [run_pretraining.py:  535]:	loss/mlm_loss, 7.774594306945801, 2682
[INFO] 2021-07-12 19:26:43,077 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6809999326360412e-05, 2682
[INFO] 2021-07-12 19:26:43,077 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2682
[INFO] 2021-07-12 19:26:43,077 [run_pretraining.py:  558]:	worker_index: 6, step: 2682, cost: 7.774594, mlm loss: 7.774594, speed: 0.907891 steps/s, speed: 7.263128 samples/s, speed: 3718.721630 tokens/s, learning rate: 2.681e-05, loss_scalings: 2814.750488, pp_loss: 7.321781
[INFO] 2021-07-12 19:26:43,077 [run_pretraining.py:  512]:	********exe.run_2682******* 
[INFO] 2021-07-12 19:26:44,168 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:44,169 [run_pretraining.py:  534]:	loss/total_loss, 7.621677875518799, 2683
[INFO] 2021-07-12 19:26:44,169 [run_pretraining.py:  535]:	loss/mlm_loss, 7.621677875518799, 2683
[INFO] 2021-07-12 19:26:44,169 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6820000130101107e-05, 2683
[INFO] 2021-07-12 19:26:44,169 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2683
[INFO] 2021-07-12 19:26:44,169 [run_pretraining.py:  558]:	worker_index: 6, step: 2683, cost: 7.621678, mlm loss: 7.621678, speed: 0.916146 steps/s, speed: 7.329169 samples/s, speed: 3752.534659 tokens/s, learning rate: 2.682e-05, loss_scalings: 2814.750488, pp_loss: 7.207305
[INFO] 2021-07-12 19:26:44,169 [run_pretraining.py:  512]:	********exe.run_2683******* 
[INFO] 2021-07-12 19:26:45,258 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:45,259 [run_pretraining.py:  534]:	loss/total_loss, 6.874145984649658, 2684
[INFO] 2021-07-12 19:26:45,259 [run_pretraining.py:  535]:	loss/mlm_loss, 6.874145984649658, 2684
[INFO] 2021-07-12 19:26:45,259 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.68299991148524e-05, 2684
[INFO] 2021-07-12 19:26:45,259 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2684
[INFO] 2021-07-12 19:26:45,259 [run_pretraining.py:  558]:	worker_index: 6, step: 2684, cost: 6.874146, mlm loss: 6.874146, speed: 0.917861 steps/s, speed: 7.342889 samples/s, speed: 3759.559087 tokens/s, learning rate: 2.683e-05, loss_scalings: 2814.750488, pp_loss: 7.097806
[INFO] 2021-07-12 19:26:45,259 [run_pretraining.py:  512]:	********exe.run_2684******* 
[INFO] 2021-07-12 19:26:46,390 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:46,391 [run_pretraining.py:  534]:	loss/total_loss, 6.978489398956299, 2685
[INFO] 2021-07-12 19:26:46,391 [run_pretraining.py:  535]:	loss/mlm_loss, 6.978489398956299, 2685
[INFO] 2021-07-12 19:26:46,391 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6839999918593094e-05, 2685
[INFO] 2021-07-12 19:26:46,391 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2685
[INFO] 2021-07-12 19:26:46,391 [run_pretraining.py:  558]:	worker_index: 6, step: 2685, cost: 6.978489, mlm loss: 6.978489, speed: 0.884133 steps/s, speed: 7.073063 samples/s, speed: 3621.408035 tokens/s, learning rate: 2.684e-05, loss_scalings: 2814.750488, pp_loss: 6.906449
[INFO] 2021-07-12 19:26:46,391 [run_pretraining.py:  512]:	********exe.run_2685******* 
[INFO] 2021-07-12 19:26:47,483 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:47,484 [run_pretraining.py:  534]:	loss/total_loss, 7.488832473754883, 2686
[INFO] 2021-07-12 19:26:47,484 [run_pretraining.py:  535]:	loss/mlm_loss, 7.488832473754883, 2686
[INFO] 2021-07-12 19:26:47,484 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6849998903344385e-05, 2686
[INFO] 2021-07-12 19:26:47,484 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2686
[INFO] 2021-07-12 19:26:47,484 [run_pretraining.py:  558]:	worker_index: 6, step: 2686, cost: 7.488832, mlm loss: 7.488832, speed: 0.915213 steps/s, speed: 7.321704 samples/s, speed: 3748.712420 tokens/s, learning rate: 2.685e-05, loss_scalings: 2814.750488, pp_loss: 7.026005
[INFO] 2021-07-12 19:26:47,484 [run_pretraining.py:  512]:	********exe.run_2686******* 
[INFO] 2021-07-12 19:26:48,574 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:48,575 [run_pretraining.py:  534]:	loss/total_loss, 7.070716381072998, 2687
[INFO] 2021-07-12 19:26:48,575 [run_pretraining.py:  535]:	loss/mlm_loss, 7.070716381072998, 2687
[INFO] 2021-07-12 19:26:48,575 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6859997888095677e-05, 2687
[INFO] 2021-07-12 19:26:48,575 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2687
[INFO] 2021-07-12 19:26:48,575 [run_pretraining.py:  558]:	worker_index: 6, step: 2687, cost: 7.070716, mlm loss: 7.070716, speed: 0.917122 steps/s, speed: 7.336975 samples/s, speed: 3756.531436 tokens/s, learning rate: 2.686e-05, loss_scalings: 2814.750488, pp_loss: 7.107560
[INFO] 2021-07-12 19:26:48,576 [run_pretraining.py:  512]:	********exe.run_2687******* 
[INFO] 2021-07-12 19:26:49,664 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:49,665 [run_pretraining.py:  534]:	loss/total_loss, 7.500246047973633, 2688
[INFO] 2021-07-12 19:26:49,665 [run_pretraining.py:  535]:	loss/mlm_loss, 7.500246047973633, 2688
[INFO] 2021-07-12 19:26:49,665 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6870000510825776e-05, 2688
[INFO] 2021-07-12 19:26:49,665 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2688
[INFO] 2021-07-12 19:26:49,665 [run_pretraining.py:  558]:	worker_index: 6, step: 2688, cost: 7.500246, mlm loss: 7.500246, speed: 0.918451 steps/s, speed: 7.347606 samples/s, speed: 3761.974509 tokens/s, learning rate: 2.687e-05, loss_scalings: 2814.750488, pp_loss: 7.082325
[INFO] 2021-07-12 19:26:49,665 [run_pretraining.py:  512]:	********exe.run_2688******* 
[INFO] 2021-07-12 19:26:50,758 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:50,759 [run_pretraining.py:  534]:	loss/total_loss, 7.413568019866943, 2689
[INFO] 2021-07-12 19:26:50,759 [run_pretraining.py:  535]:	loss/mlm_loss, 7.413568019866943, 2689
[INFO] 2021-07-12 19:26:50,759 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6879997676587664e-05, 2689
[INFO] 2021-07-12 19:26:50,759 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2689
[INFO] 2021-07-12 19:26:50,759 [run_pretraining.py:  558]:	worker_index: 6, step: 2689, cost: 7.413568, mlm loss: 7.413568, speed: 0.914279 steps/s, speed: 7.314233 samples/s, speed: 3744.887347 tokens/s, learning rate: 2.688e-05, loss_scalings: 2814.750488, pp_loss: 7.049675
[INFO] 2021-07-12 19:26:50,759 [run_pretraining.py:  512]:	********exe.run_2689******* 
[INFO] 2021-07-12 19:26:51,856 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:51,857 [run_pretraining.py:  534]:	loss/total_loss, 7.625370979309082, 2690
[INFO] 2021-07-12 19:26:51,857 [run_pretraining.py:  535]:	loss/mlm_loss, 7.625370979309082, 2690
[INFO] 2021-07-12 19:26:51,857 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6890000299317762e-05, 2690
[INFO] 2021-07-12 19:26:51,857 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2690
[INFO] 2021-07-12 19:26:51,857 [run_pretraining.py:  558]:	worker_index: 6, step: 2690, cost: 7.625371, mlm loss: 7.625371, speed: 0.911300 steps/s, speed: 7.290399 samples/s, speed: 3732.684154 tokens/s, learning rate: 2.689e-05, loss_scalings: 2814.750488, pp_loss: 7.262793
[INFO] 2021-07-12 19:26:51,858 [run_pretraining.py:  512]:	********exe.run_2690******* 
[INFO] 2021-07-12 19:26:52,950 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:52,951 [run_pretraining.py:  534]:	loss/total_loss, 7.142154693603516, 2691
[INFO] 2021-07-12 19:26:52,951 [run_pretraining.py:  535]:	loss/mlm_loss, 7.142154693603516, 2691
[INFO] 2021-07-12 19:26:52,951 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6899999284069054e-05, 2691
[INFO] 2021-07-12 19:26:52,951 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2691
[INFO] 2021-07-12 19:26:52,951 [run_pretraining.py:  558]:	worker_index: 6, step: 2691, cost: 7.142155, mlm loss: 7.142155, speed: 0.914949 steps/s, speed: 7.319592 samples/s, speed: 3747.631358 tokens/s, learning rate: 2.690e-05, loss_scalings: 2814.750488, pp_loss: 7.277641
[INFO] 2021-07-12 19:26:52,951 [run_pretraining.py:  512]:	********exe.run_2691******* 
[INFO] 2021-07-12 19:26:54,045 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:54,046 [run_pretraining.py:  534]:	loss/total_loss, 7.289239883422852, 2692
[INFO] 2021-07-12 19:26:54,046 [run_pretraining.py:  535]:	loss/mlm_loss, 7.289239883422852, 2692
[INFO] 2021-07-12 19:26:54,046 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.691000008780975e-05, 2692
[INFO] 2021-07-12 19:26:54,046 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2692
[INFO] 2021-07-12 19:26:54,046 [run_pretraining.py:  558]:	worker_index: 6, step: 2692, cost: 7.289240, mlm loss: 7.289240, speed: 0.913681 steps/s, speed: 7.309447 samples/s, speed: 3742.436742 tokens/s, learning rate: 2.691e-05, loss_scalings: 2814.750488, pp_loss: 7.992579
[INFO] 2021-07-12 19:26:54,046 [run_pretraining.py:  512]:	********exe.run_2692******* 
[INFO] 2021-07-12 19:26:55,145 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:55,145 [run_pretraining.py:  534]:	loss/total_loss, 6.831073760986328, 2693
[INFO] 2021-07-12 19:26:55,145 [run_pretraining.py:  535]:	loss/mlm_loss, 6.831073760986328, 2693
[INFO] 2021-07-12 19:26:55,145 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.691999907256104e-05, 2693
[INFO] 2021-07-12 19:26:55,146 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2693
[INFO] 2021-07-12 19:26:55,146 [run_pretraining.py:  558]:	worker_index: 6, step: 2693, cost: 6.831074, mlm loss: 6.831074, speed: 0.910190 steps/s, speed: 7.281519 samples/s, speed: 3728.137537 tokens/s, learning rate: 2.692e-05, loss_scalings: 2814.750488, pp_loss: 7.148265
[INFO] 2021-07-12 19:26:55,146 [run_pretraining.py:  512]:	********exe.run_2693******* 
[INFO] 2021-07-12 19:26:56,237 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:56,238 [run_pretraining.py:  534]:	loss/total_loss, 6.916281700134277, 2694
[INFO] 2021-07-12 19:26:56,238 [run_pretraining.py:  535]:	loss/mlm_loss, 6.916281700134277, 2694
[INFO] 2021-07-12 19:26:56,238 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6929999876301736e-05, 2694
[INFO] 2021-07-12 19:26:56,238 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2694
[INFO] 2021-07-12 19:26:56,238 [run_pretraining.py:  558]:	worker_index: 6, step: 2694, cost: 6.916282, mlm loss: 6.916282, speed: 0.915996 steps/s, speed: 7.327970 samples/s, speed: 3751.920840 tokens/s, learning rate: 2.693e-05, loss_scalings: 2814.750488, pp_loss: 7.451348
[INFO] 2021-07-12 19:26:56,238 [run_pretraining.py:  512]:	********exe.run_2694******* 
[INFO] 2021-07-12 19:26:57,339 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:57,339 [run_pretraining.py:  534]:	loss/total_loss, 6.562047481536865, 2695
[INFO] 2021-07-12 19:26:57,339 [run_pretraining.py:  535]:	loss/mlm_loss, 6.562047481536865, 2695
[INFO] 2021-07-12 19:26:57,339 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6939998861053027e-05, 2695
[INFO] 2021-07-12 19:26:57,340 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2695
[INFO] 2021-07-12 19:26:57,340 [run_pretraining.py:  558]:	worker_index: 6, step: 2695, cost: 6.562047, mlm loss: 6.562047, speed: 0.908412 steps/s, speed: 7.267298 samples/s, speed: 3720.856770 tokens/s, learning rate: 2.694e-05, loss_scalings: 2814.750488, pp_loss: 7.071477
[INFO] 2021-07-12 19:26:57,340 [run_pretraining.py:  512]:	********exe.run_2695******* 
[INFO] 2021-07-12 19:26:58,436 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:58,437 [run_pretraining.py:  534]:	loss/total_loss, 7.169572353363037, 2696
[INFO] 2021-07-12 19:26:58,437 [run_pretraining.py:  535]:	loss/mlm_loss, 7.169572353363037, 2696
[INFO] 2021-07-12 19:26:58,437 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.694999784580432e-05, 2696
[INFO] 2021-07-12 19:26:58,437 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2696
[INFO] 2021-07-12 19:26:58,437 [run_pretraining.py:  558]:	worker_index: 6, step: 2696, cost: 7.169572, mlm loss: 7.169572, speed: 0.911697 steps/s, speed: 7.293574 samples/s, speed: 3734.310112 tokens/s, learning rate: 2.695e-05, loss_scalings: 2814.750488, pp_loss: 7.279458
[INFO] 2021-07-12 19:26:58,437 [run_pretraining.py:  512]:	********exe.run_2696******* 
[INFO] 2021-07-12 19:26:59,522 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:59,522 [run_pretraining.py:  534]:	loss/total_loss, 7.644139289855957, 2697
[INFO] 2021-07-12 19:26:59,523 [run_pretraining.py:  535]:	loss/mlm_loss, 7.644139289855957, 2697
[INFO] 2021-07-12 19:26:59,523 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6960000468534417e-05, 2697
[INFO] 2021-07-12 19:26:59,523 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2697
[INFO] 2021-07-12 19:26:59,523 [run_pretraining.py:  558]:	worker_index: 6, step: 2697, cost: 7.644139, mlm loss: 7.644139, speed: 0.921717 steps/s, speed: 7.373740 samples/s, speed: 3775.354829 tokens/s, learning rate: 2.696e-05, loss_scalings: 2814.750488, pp_loss: 7.449628
[INFO] 2021-07-12 19:26:59,523 [run_pretraining.py:  512]:	********exe.run_2697******* 
[INFO] 2021-07-12 19:27:00,617 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:00,617 [run_pretraining.py:  534]:	loss/total_loss, 7.426914215087891, 2698
[INFO] 2021-07-12 19:27:00,617 [run_pretraining.py:  535]:	loss/mlm_loss, 7.426914215087891, 2698
[INFO] 2021-07-12 19:27:00,617 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6969997634296305e-05, 2698
[INFO] 2021-07-12 19:27:00,617 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2698
[INFO] 2021-07-12 19:27:00,618 [run_pretraining.py:  558]:	worker_index: 6, step: 2698, cost: 7.426914, mlm loss: 7.426914, speed: 0.914026 steps/s, speed: 7.312206 samples/s, speed: 3743.849283 tokens/s, learning rate: 2.697e-05, loss_scalings: 2814.750488, pp_loss: 7.218592
[INFO] 2021-07-12 19:27:00,618 [run_pretraining.py:  512]:	********exe.run_2698******* 
[INFO] 2021-07-12 19:27:01,716 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:01,716 [run_pretraining.py:  534]:	loss/total_loss, 9.431314468383789, 2699
[INFO] 2021-07-12 19:27:01,717 [run_pretraining.py:  535]:	loss/mlm_loss, 9.431314468383789, 2699
[INFO] 2021-07-12 19:27:01,717 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6980000257026404e-05, 2699
[INFO] 2021-07-12 19:27:01,717 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2699
[INFO] 2021-07-12 19:27:01,717 [run_pretraining.py:  558]:	worker_index: 6, step: 2699, cost: 9.431314, mlm loss: 9.431314, speed: 0.910244 steps/s, speed: 7.281950 samples/s, speed: 3728.358415 tokens/s, learning rate: 2.698e-05, loss_scalings: 2814.750488, pp_loss: 7.056205
[INFO] 2021-07-12 19:27:01,717 [run_pretraining.py:  512]:	********exe.run_2699******* 
[INFO] 2021-07-12 19:27:02,813 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:02,813 [run_pretraining.py:  534]:	loss/total_loss, 6.478128433227539, 2700
[INFO] 2021-07-12 19:27:02,813 [run_pretraining.py:  535]:	loss/mlm_loss, 6.478128433227539, 2700
[INFO] 2021-07-12 19:27:02,813 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6989999241777696e-05, 2700
[INFO] 2021-07-12 19:27:02,813 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2700
[INFO] 2021-07-12 19:27:02,813 [run_pretraining.py:  558]:	worker_index: 6, step: 2700, cost: 6.478128, mlm loss: 6.478128, speed: 0.912500 steps/s, speed: 7.299996 samples/s, speed: 3737.597995 tokens/s, learning rate: 2.699e-05, loss_scalings: 2814.750488, pp_loss: 7.339873
[INFO] 2021-07-12 19:27:02,814 [run_pretraining.py:  512]:	********exe.run_2700******* 
[INFO] 2021-07-12 19:27:03,924 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:03,925 [run_pretraining.py:  534]:	loss/total_loss, 7.764132022857666, 2701
[INFO] 2021-07-12 19:27:03,925 [run_pretraining.py:  535]:	loss/mlm_loss, 7.764132022857666, 2701
[INFO] 2021-07-12 19:27:03,925 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.700000004551839e-05, 2701
[INFO] 2021-07-12 19:27:03,925 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2701
[INFO] 2021-07-12 19:27:03,925 [run_pretraining.py:  558]:	worker_index: 6, step: 2701, cost: 7.764132, mlm loss: 7.764132, speed: 0.900080 steps/s, speed: 7.200636 samples/s, speed: 3686.725751 tokens/s, learning rate: 2.700e-05, loss_scalings: 2814.750488, pp_loss: 7.482864
[INFO] 2021-07-12 19:27:03,925 [run_pretraining.py:  512]:	********exe.run_2701******* 
[INFO] 2021-07-12 19:27:05,019 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:05,020 [run_pretraining.py:  534]:	loss/total_loss, 6.248743057250977, 2702
[INFO] 2021-07-12 19:27:05,020 [run_pretraining.py:  535]:	loss/mlm_loss, 6.248743057250977, 2702
[INFO] 2021-07-12 19:27:05,020 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7009999030269682e-05, 2702
[INFO] 2021-07-12 19:27:05,020 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2702
[INFO] 2021-07-12 19:27:05,020 [run_pretraining.py:  558]:	worker_index: 6, step: 2702, cost: 6.248743, mlm loss: 6.248743, speed: 0.914051 steps/s, speed: 7.312410 samples/s, speed: 3743.953716 tokens/s, learning rate: 2.701e-05, loss_scalings: 2814.750488, pp_loss: 7.343295
[INFO] 2021-07-12 19:27:05,020 [run_pretraining.py:  512]:	********exe.run_2702******* 
[INFO] 2021-07-12 19:27:06,120 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:06,120 [run_pretraining.py:  534]:	loss/total_loss, 7.53306245803833, 2703
[INFO] 2021-07-12 19:27:06,120 [run_pretraining.py:  535]:	loss/mlm_loss, 7.53306245803833, 2703
[INFO] 2021-07-12 19:27:06,120 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7019999834010378e-05, 2703
[INFO] 2021-07-12 19:27:06,121 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2703
[INFO] 2021-07-12 19:27:06,121 [run_pretraining.py:  558]:	worker_index: 6, step: 2703, cost: 7.533062, mlm loss: 7.533062, speed: 0.909114 steps/s, speed: 7.272915 samples/s, speed: 3723.732731 tokens/s, learning rate: 2.702e-05, loss_scalings: 2814.750488, pp_loss: 7.148002
[INFO] 2021-07-12 19:27:06,121 [run_pretraining.py:  512]:	********exe.run_2703******* 
[INFO] 2021-07-12 19:27:07,217 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:07,218 [run_pretraining.py:  534]:	loss/total_loss, 7.167567729949951, 2704
[INFO] 2021-07-12 19:27:07,218 [run_pretraining.py:  535]:	loss/mlm_loss, 7.167567729949951, 2704
[INFO] 2021-07-12 19:27:07,218 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.702999881876167e-05, 2704
[INFO] 2021-07-12 19:27:07,218 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2704
[INFO] 2021-07-12 19:27:07,218 [run_pretraining.py:  558]:	worker_index: 6, step: 2704, cost: 7.167568, mlm loss: 7.167568, speed: 0.911513 steps/s, speed: 7.292107 samples/s, speed: 3733.558620 tokens/s, learning rate: 2.703e-05, loss_scalings: 2814.750488, pp_loss: 7.389315
[INFO] 2021-07-12 19:27:07,219 [run_pretraining.py:  512]:	********exe.run_2704******* 
[INFO] 2021-07-12 19:27:08,314 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:08,314 [run_pretraining.py:  534]:	loss/total_loss, 7.0735626220703125, 2705
[INFO] 2021-07-12 19:27:08,315 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0735626220703125, 2705
[INFO] 2021-07-12 19:27:08,315 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.703999780351296e-05, 2705
[INFO] 2021-07-12 19:27:08,315 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2705
[INFO] 2021-07-12 19:27:08,315 [run_pretraining.py:  558]:	worker_index: 6, step: 2705, cost: 7.073563, mlm loss: 7.073563, speed: 0.912619 steps/s, speed: 7.300955 samples/s, speed: 3738.089196 tokens/s, learning rate: 2.704e-05, loss_scalings: 2814.750488, pp_loss: 6.932944
[INFO] 2021-07-12 19:27:08,315 [run_pretraining.py:  512]:	********exe.run_2705******* 
[INFO] 2021-07-12 19:27:09,418 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:09,419 [run_pretraining.py:  534]:	loss/total_loss, 7.218814849853516, 2706
[INFO] 2021-07-12 19:27:09,419 [run_pretraining.py:  535]:	loss/mlm_loss, 7.218814849853516, 2706
[INFO] 2021-07-12 19:27:09,419 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.705000042624306e-05, 2706
[INFO] 2021-07-12 19:27:09,419 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2706
[INFO] 2021-07-12 19:27:09,419 [run_pretraining.py:  558]:	worker_index: 6, step: 2706, cost: 7.218815, mlm loss: 7.218815, speed: 0.906307 steps/s, speed: 7.250454 samples/s, speed: 3712.232219 tokens/s, learning rate: 2.705e-05, loss_scalings: 2814.750488, pp_loss: 7.273190
[INFO] 2021-07-12 19:27:09,419 [run_pretraining.py:  512]:	********exe.run_2706******* 
[INFO] 2021-07-12 19:27:10,518 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:10,519 [run_pretraining.py:  534]:	loss/total_loss, 7.325711250305176, 2707
[INFO] 2021-07-12 19:27:10,519 [run_pretraining.py:  535]:	loss/mlm_loss, 7.325711250305176, 2707
[INFO] 2021-07-12 19:27:10,519 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7059997592004947e-05, 2707
[INFO] 2021-07-12 19:27:10,519 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2707
[INFO] 2021-07-12 19:27:10,519 [run_pretraining.py:  558]:	worker_index: 6, step: 2707, cost: 7.325711, mlm loss: 7.325711, speed: 0.909467 steps/s, speed: 7.275740 samples/s, speed: 3725.178841 tokens/s, learning rate: 2.706e-05, loss_scalings: 2814.750488, pp_loss: 6.810152
[INFO] 2021-07-12 19:27:10,519 [run_pretraining.py:  512]:	********exe.run_2707******* 
[INFO] 2021-07-12 19:27:11,603 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:11,604 [run_pretraining.py:  534]:	loss/total_loss, 7.909492492675781, 2708
[INFO] 2021-07-12 19:27:11,604 [run_pretraining.py:  535]:	loss/mlm_loss, 7.909492492675781, 2708
[INFO] 2021-07-12 19:27:11,604 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7070000214735046e-05, 2708
[INFO] 2021-07-12 19:27:11,604 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2708
[INFO] 2021-07-12 19:27:11,604 [run_pretraining.py:  558]:	worker_index: 6, step: 2708, cost: 7.909492, mlm loss: 7.909492, speed: 0.922166 steps/s, speed: 7.377331 samples/s, speed: 3777.193402 tokens/s, learning rate: 2.707e-05, loss_scalings: 2814.750488, pp_loss: 7.129694
[INFO] 2021-07-12 19:27:11,604 [run_pretraining.py:  512]:	********exe.run_2708******* 
[INFO] 2021-07-12 19:27:12,700 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:12,701 [run_pretraining.py:  534]:	loss/total_loss, 7.1952314376831055, 2709
[INFO] 2021-07-12 19:27:12,701 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1952314376831055, 2709
[INFO] 2021-07-12 19:27:12,701 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7079999199486338e-05, 2709
[INFO] 2021-07-12 19:27:12,701 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2709
[INFO] 2021-07-12 19:27:12,701 [run_pretraining.py:  558]:	worker_index: 6, step: 2709, cost: 7.195231, mlm loss: 7.195231, speed: 0.912542 steps/s, speed: 7.300336 samples/s, speed: 3737.772015 tokens/s, learning rate: 2.708e-05, loss_scalings: 2814.750488, pp_loss: 7.205444
[INFO] 2021-07-12 19:27:12,701 [run_pretraining.py:  512]:	********exe.run_2709******* 
[INFO] 2021-07-12 19:27:13,800 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:13,801 [run_pretraining.py:  534]:	loss/total_loss, 7.69949197769165, 2710
[INFO] 2021-07-12 19:27:13,801 [run_pretraining.py:  535]:	loss/mlm_loss, 7.69949197769165, 2710
[INFO] 2021-07-12 19:27:13,801 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7090000003227033e-05, 2710
[INFO] 2021-07-12 19:27:13,801 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2710
[INFO] 2021-07-12 19:27:13,801 [run_pretraining.py:  558]:	worker_index: 6, step: 2710, cost: 7.699492, mlm loss: 7.699492, speed: 0.909593 steps/s, speed: 7.276747 samples/s, speed: 3725.694254 tokens/s, learning rate: 2.709e-05, loss_scalings: 2814.750488, pp_loss: 7.360557
[INFO] 2021-07-12 19:27:13,801 [run_pretraining.py:  512]:	********exe.run_2710******* 
[INFO] 2021-07-12 19:27:14,765 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:14,766 [run_pretraining.py:  534]:	loss/total_loss, 7.5962114334106445, 2711
[INFO] 2021-07-12 19:27:14,766 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5962114334106445, 2711
[INFO] 2021-07-12 19:27:14,766 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7099998987978324e-05, 2711
[INFO] 2021-07-12 19:27:14,766 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2711
[INFO] 2021-07-12 19:27:14,766 [run_pretraining.py:  558]:	worker_index: 6, step: 2711, cost: 7.596211, mlm loss: 7.596211, speed: 1.036550 steps/s, speed: 8.292404 samples/s, speed: 4245.710684 tokens/s, learning rate: 2.710e-05, loss_scalings: 2814.750488, pp_loss: 7.433152
[INFO] 2021-07-12 19:27:14,767 [run_pretraining.py:  512]:	********exe.run_2711******* 
[INFO] 2021-07-12 19:27:15,691 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:15,692 [run_pretraining.py:  534]:	loss/total_loss, 7.831111907958984, 2712
[INFO] 2021-07-12 19:27:15,692 [run_pretraining.py:  535]:	loss/mlm_loss, 7.831111907958984, 2712
[INFO] 2021-07-12 19:27:15,692 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7110001610708423e-05, 2712
[INFO] 2021-07-12 19:27:15,692 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2712
[INFO] 2021-07-12 19:27:15,692 [run_pretraining.py:  558]:	worker_index: 6, step: 2712, cost: 7.831112, mlm loss: 7.831112, speed: 1.081366 steps/s, speed: 8.650930 samples/s, speed: 4429.276239 tokens/s, learning rate: 2.711e-05, loss_scalings: 2814.750488, pp_loss: 7.493475
[INFO] 2021-07-12 19:27:15,692 [run_pretraining.py:  512]:	********exe.run_2712******* 
[INFO] 2021-07-12 19:27:16,612 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:16,612 [run_pretraining.py:  534]:	loss/total_loss, 6.882875442504883, 2713
[INFO] 2021-07-12 19:27:16,612 [run_pretraining.py:  535]:	loss/mlm_loss, 6.882875442504883, 2713
[INFO] 2021-07-12 19:27:16,613 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.711999877647031e-05, 2713
[INFO] 2021-07-12 19:27:16,613 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2713
[INFO] 2021-07-12 19:27:16,613 [run_pretraining.py:  558]:	worker_index: 6, step: 2713, cost: 6.882875, mlm loss: 6.882875, speed: 1.086867 steps/s, speed: 8.694939 samples/s, speed: 4451.808978 tokens/s, learning rate: 2.712e-05, loss_scalings: 2814.750488, pp_loss: 7.217367
[INFO] 2021-07-12 19:27:16,613 [run_pretraining.py:  512]:	********exe.run_2713******* 
[INFO] 2021-07-12 19:27:17,529 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:17,530 [run_pretraining.py:  534]:	loss/total_loss, 7.298664569854736, 2714
[INFO] 2021-07-12 19:27:17,530 [run_pretraining.py:  535]:	loss/mlm_loss, 7.298664569854736, 2714
[INFO] 2021-07-12 19:27:17,530 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7129997761221603e-05, 2714
[INFO] 2021-07-12 19:27:17,530 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2714
[INFO] 2021-07-12 19:27:17,530 [run_pretraining.py:  558]:	worker_index: 6, step: 2714, cost: 7.298665, mlm loss: 7.298665, speed: 1.090721 steps/s, speed: 8.725767 samples/s, speed: 4467.592850 tokens/s, learning rate: 2.713e-05, loss_scalings: 2814.750488, pp_loss: 7.471194
[INFO] 2021-07-12 19:27:17,530 [run_pretraining.py:  512]:	********exe.run_2714******* 
[INFO] 2021-07-12 19:27:18,441 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:18,442 [run_pretraining.py:  534]:	loss/total_loss, 6.562834739685059, 2715
[INFO] 2021-07-12 19:27:18,442 [run_pretraining.py:  535]:	loss/mlm_loss, 6.562834739685059, 2715
[INFO] 2021-07-12 19:27:18,442 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.71400003839517e-05, 2715
[INFO] 2021-07-12 19:27:18,442 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2715
[INFO] 2021-07-12 19:27:18,442 [run_pretraining.py:  558]:	worker_index: 6, step: 2715, cost: 6.562835, mlm loss: 6.562835, speed: 1.097384 steps/s, speed: 8.779075 samples/s, speed: 4494.886356 tokens/s, learning rate: 2.714e-05, loss_scalings: 2814.750488, pp_loss: 7.066624
[INFO] 2021-07-12 19:27:18,442 [run_pretraining.py:  512]:	********exe.run_2715******* 
[INFO] 2021-07-12 19:27:19,369 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:19,370 [run_pretraining.py:  534]:	loss/total_loss, 6.970772743225098, 2716
[INFO] 2021-07-12 19:27:19,370 [run_pretraining.py:  535]:	loss/mlm_loss, 6.970772743225098, 2716
[INFO] 2021-07-12 19:27:19,370 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.714999754971359e-05, 2716
[INFO] 2021-07-12 19:27:19,370 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2716
[INFO] 2021-07-12 19:27:19,370 [run_pretraining.py:  558]:	worker_index: 6, step: 2716, cost: 6.970773, mlm loss: 6.970773, speed: 1.078385 steps/s, speed: 8.627080 samples/s, speed: 4417.064908 tokens/s, learning rate: 2.715e-05, loss_scalings: 2814.750488, pp_loss: 6.578159
[INFO] 2021-07-12 19:27:19,370 [run_pretraining.py:  512]:	********exe.run_2716******* 
[INFO] 2021-07-12 19:27:20,295 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:20,295 [run_pretraining.py:  534]:	loss/total_loss, 7.011090278625488, 2717
[INFO] 2021-07-12 19:27:20,295 [run_pretraining.py:  535]:	loss/mlm_loss, 7.011090278625488, 2717
[INFO] 2021-07-12 19:27:20,295 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7160000172443688e-05, 2717
[INFO] 2021-07-12 19:27:20,295 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2717
[INFO] 2021-07-12 19:27:20,296 [run_pretraining.py:  558]:	worker_index: 6, step: 2717, cost: 7.011090, mlm loss: 7.011090, speed: 1.081580 steps/s, speed: 8.652637 samples/s, speed: 4430.150001 tokens/s, learning rate: 2.716e-05, loss_scalings: 2814.750488, pp_loss: 6.571610
[INFO] 2021-07-12 19:27:20,296 [run_pretraining.py:  512]:	********exe.run_2717******* 
[INFO] 2021-07-12 19:27:21,235 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:21,235 [run_pretraining.py:  534]:	loss/total_loss, 7.1798505783081055, 2718
[INFO] 2021-07-12 19:27:21,235 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1798505783081055, 2718
[INFO] 2021-07-12 19:27:21,235 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.716999915719498e-05, 2718
[INFO] 2021-07-12 19:27:21,235 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2718
[INFO] 2021-07-12 19:27:21,236 [run_pretraining.py:  558]:	worker_index: 6, step: 2718, cost: 7.179851, mlm loss: 7.179851, speed: 1.064662 steps/s, speed: 8.517298 samples/s, speed: 4360.856568 tokens/s, learning rate: 2.717e-05, loss_scalings: 2814.750488, pp_loss: 7.235167
[INFO] 2021-07-12 19:27:21,236 [run_pretraining.py:  512]:	********exe.run_2718******* 
[INFO] 2021-07-12 19:27:22,160 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:22,161 [run_pretraining.py:  534]:	loss/total_loss, 6.719890117645264, 2719
[INFO] 2021-07-12 19:27:22,161 [run_pretraining.py:  535]:	loss/mlm_loss, 6.719890117645264, 2719
[INFO] 2021-07-12 19:27:22,161 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7179999960935675e-05, 2719
[INFO] 2021-07-12 19:27:22,161 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2719
[INFO] 2021-07-12 19:27:22,161 [run_pretraining.py:  558]:	worker_index: 6, step: 2719, cost: 6.719890, mlm loss: 6.719890, speed: 1.081386 steps/s, speed: 8.651091 samples/s, speed: 4429.358461 tokens/s, learning rate: 2.718e-05, loss_scalings: 2814.750488, pp_loss: 7.223831
[INFO] 2021-07-12 19:27:22,161 [run_pretraining.py:  512]:	********exe.run_2719******* 
[INFO] 2021-07-12 19:27:23,085 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:23,085 [run_pretraining.py:  534]:	loss/total_loss, 8.715717315673828, 2720
[INFO] 2021-07-12 19:27:23,085 [run_pretraining.py:  535]:	loss/mlm_loss, 8.715717315673828, 2720
[INFO] 2021-07-12 19:27:23,085 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7189998945686966e-05, 2720
[INFO] 2021-07-12 19:27:23,086 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2720
[INFO] 2021-07-12 19:27:23,086 [run_pretraining.py:  558]:	worker_index: 6, step: 2720, cost: 8.715717, mlm loss: 8.715717, speed: 1.082274 steps/s, speed: 8.658189 samples/s, speed: 4432.992965 tokens/s, learning rate: 2.719e-05, loss_scalings: 2814.750488, pp_loss: 7.674917
[INFO] 2021-07-12 19:27:23,086 [run_pretraining.py:  512]:	********exe.run_2720******* 
[INFO] 2021-07-12 19:27:24,010 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:24,010 [run_pretraining.py:  534]:	loss/total_loss, 7.347355365753174, 2721
[INFO] 2021-07-12 19:27:24,011 [run_pretraining.py:  535]:	loss/mlm_loss, 7.347355365753174, 2721
[INFO] 2021-07-12 19:27:24,011 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7200001568417065e-05, 2721
[INFO] 2021-07-12 19:27:24,011 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2721
[INFO] 2021-07-12 19:27:24,011 [run_pretraining.py:  558]:	worker_index: 6, step: 2721, cost: 7.347355, mlm loss: 7.347355, speed: 1.081741 steps/s, speed: 8.653929 samples/s, speed: 4430.811547 tokens/s, learning rate: 2.720e-05, loss_scalings: 2814.750488, pp_loss: 7.589485
[INFO] 2021-07-12 19:27:24,011 [run_pretraining.py:  512]:	********exe.run_2721******* 
[INFO] 2021-07-12 19:27:24,931 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:24,932 [run_pretraining.py:  534]:	loss/total_loss, 7.555124282836914, 2722
[INFO] 2021-07-12 19:27:24,932 [run_pretraining.py:  535]:	loss/mlm_loss, 7.555124282836914, 2722
[INFO] 2021-07-12 19:27:24,932 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7209998734178953e-05, 2722
[INFO] 2021-07-12 19:27:24,932 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2722
[INFO] 2021-07-12 19:27:24,932 [run_pretraining.py:  558]:	worker_index: 6, step: 2722, cost: 7.555124, mlm loss: 7.555124, speed: 1.085888 steps/s, speed: 8.687103 samples/s, speed: 4447.796935 tokens/s, learning rate: 2.721e-05, loss_scalings: 2814.750488, pp_loss: 7.440124
[INFO] 2021-07-12 19:27:24,933 [run_pretraining.py:  512]:	********exe.run_2722******* 
[INFO] 2021-07-12 19:27:25,853 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:25,854 [run_pretraining.py:  534]:	loss/total_loss, 7.437122344970703, 2723
[INFO] 2021-07-12 19:27:25,854 [run_pretraining.py:  535]:	loss/mlm_loss, 7.437122344970703, 2723
[INFO] 2021-07-12 19:27:25,854 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7219997718930244e-05, 2723
[INFO] 2021-07-12 19:27:25,854 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2723
[INFO] 2021-07-12 19:27:25,854 [run_pretraining.py:  558]:	worker_index: 6, step: 2723, cost: 7.437122, mlm loss: 7.437122, speed: 1.085770 steps/s, speed: 8.686161 samples/s, speed: 4447.314502 tokens/s, learning rate: 2.722e-05, loss_scalings: 2814.750488, pp_loss: 7.199857
[INFO] 2021-07-12 19:27:25,854 [run_pretraining.py:  512]:	********exe.run_2723******* 
[INFO] 2021-07-12 19:27:26,788 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:26,789 [run_pretraining.py:  534]:	loss/total_loss, 7.322683334350586, 2724
[INFO] 2021-07-12 19:27:26,789 [run_pretraining.py:  535]:	loss/mlm_loss, 7.322683334350586, 2724
[INFO] 2021-07-12 19:27:26,789 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7230000341660343e-05, 2724
[INFO] 2021-07-12 19:27:26,789 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2724
[INFO] 2021-07-12 19:27:26,789 [run_pretraining.py:  558]:	worker_index: 6, step: 2724, cost: 7.322683, mlm loss: 7.322683, speed: 1.070056 steps/s, speed: 8.560446 samples/s, speed: 4382.948411 tokens/s, learning rate: 2.723e-05, loss_scalings: 2814.750488, pp_loss: 7.250115
[INFO] 2021-07-12 19:27:26,789 [run_pretraining.py:  512]:	********exe.run_2724******* 
[INFO] 2021-07-12 19:27:27,711 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:27,711 [run_pretraining.py:  534]:	loss/total_loss, 7.106329441070557, 2725
[INFO] 2021-07-12 19:27:27,711 [run_pretraining.py:  535]:	loss/mlm_loss, 7.106329441070557, 2725
[INFO] 2021-07-12 19:27:27,711 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7239999326411635e-05, 2725
[INFO] 2021-07-12 19:27:27,712 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2725
[INFO] 2021-07-12 19:27:27,712 [run_pretraining.py:  558]:	worker_index: 6, step: 2725, cost: 7.106329, mlm loss: 7.106329, speed: 1.085210 steps/s, speed: 8.681682 samples/s, speed: 4445.021211 tokens/s, learning rate: 2.724e-05, loss_scalings: 2814.750488, pp_loss: 7.111863
[INFO] 2021-07-12 19:27:27,712 [run_pretraining.py:  512]:	********exe.run_2725******* 
[INFO] 2021-07-12 19:27:28,650 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:28,651 [run_pretraining.py:  534]:	loss/total_loss, 7.730453014373779, 2726
[INFO] 2021-07-12 19:27:28,651 [run_pretraining.py:  535]:	loss/mlm_loss, 7.730453014373779, 2726
[INFO] 2021-07-12 19:27:28,651 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.725000013015233e-05, 2726
[INFO] 2021-07-12 19:27:28,651 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2726
[INFO] 2021-07-12 19:27:28,651 [run_pretraining.py:  558]:	worker_index: 6, step: 2726, cost: 7.730453, mlm loss: 7.730453, speed: 1.065199 steps/s, speed: 8.521592 samples/s, speed: 4363.054950 tokens/s, learning rate: 2.725e-05, loss_scalings: 2814.750488, pp_loss: 7.081100
[INFO] 2021-07-12 19:27:28,651 [run_pretraining.py:  512]:	********exe.run_2726******* 
[INFO] 2021-07-12 19:27:29,574 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:29,575 [run_pretraining.py:  534]:	loss/total_loss, 7.406447887420654, 2727
[INFO] 2021-07-12 19:27:29,575 [run_pretraining.py:  535]:	loss/mlm_loss, 7.406447887420654, 2727
[INFO] 2021-07-12 19:27:29,575 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.725999911490362e-05, 2727
[INFO] 2021-07-12 19:27:29,575 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2727
[INFO] 2021-07-12 19:27:29,575 [run_pretraining.py:  558]:	worker_index: 6, step: 2727, cost: 7.406448, mlm loss: 7.406448, speed: 1.083278 steps/s, speed: 8.666222 samples/s, speed: 4437.105535 tokens/s, learning rate: 2.726e-05, loss_scalings: 2814.750488, pp_loss: 7.252664
[INFO] 2021-07-12 19:27:29,575 [run_pretraining.py:  512]:	********exe.run_2727******* 
[INFO] 2021-07-12 19:27:30,504 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:30,505 [run_pretraining.py:  534]:	loss/total_loss, 7.3443827629089355, 2728
[INFO] 2021-07-12 19:27:30,505 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3443827629089355, 2728
[INFO] 2021-07-12 19:27:30,505 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7269999918644316e-05, 2728
[INFO] 2021-07-12 19:27:30,505 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2728
[INFO] 2021-07-12 19:27:30,505 [run_pretraining.py:  558]:	worker_index: 6, step: 2728, cost: 7.344383, mlm loss: 7.344383, speed: 1.075818 steps/s, speed: 8.606543 samples/s, speed: 4406.549954 tokens/s, learning rate: 2.727e-05, loss_scalings: 2814.750488, pp_loss: 7.034712
[INFO] 2021-07-12 19:27:30,505 [run_pretraining.py:  512]:	********exe.run_2728******* 
[INFO] 2021-07-12 19:27:31,436 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:31,437 [run_pretraining.py:  534]:	loss/total_loss, 7.268566131591797, 2729
[INFO] 2021-07-12 19:27:31,437 [run_pretraining.py:  535]:	loss/mlm_loss, 7.268566131591797, 2729
[INFO] 2021-07-12 19:27:31,437 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7279998903395608e-05, 2729
[INFO] 2021-07-12 19:27:31,437 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2729
[INFO] 2021-07-12 19:27:31,437 [run_pretraining.py:  558]:	worker_index: 6, step: 2729, cost: 7.268566, mlm loss: 7.268566, speed: 1.073629 steps/s, speed: 8.589031 samples/s, speed: 4397.583815 tokens/s, learning rate: 2.728e-05, loss_scalings: 2814.750488, pp_loss: 7.139776
[INFO] 2021-07-12 19:27:31,437 [run_pretraining.py:  512]:	********exe.run_2729******* 
[INFO] 2021-07-12 19:27:32,378 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:32,379 [run_pretraining.py:  534]:	loss/total_loss, 6.7863569259643555, 2730
[INFO] 2021-07-12 19:27:32,379 [run_pretraining.py:  535]:	loss/mlm_loss, 6.7863569259643555, 2730
[INFO] 2021-07-12 19:27:32,379 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.72899978881469e-05, 2730
[INFO] 2021-07-12 19:27:32,379 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2730
[INFO] 2021-07-12 19:27:32,379 [run_pretraining.py:  558]:	worker_index: 6, step: 2730, cost: 6.786357, mlm loss: 6.786357, speed: 1.062622 steps/s, speed: 8.500976 samples/s, speed: 4352.499725 tokens/s, learning rate: 2.729e-05, loss_scalings: 2814.750488, pp_loss: 7.194278
[INFO] 2021-07-12 19:27:32,379 [run_pretraining.py:  512]:	********exe.run_2730******* 
[INFO] 2021-07-12 19:27:33,312 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:33,313 [run_pretraining.py:  534]:	loss/total_loss, 7.25965690612793, 2731
[INFO] 2021-07-12 19:27:33,313 [run_pretraining.py:  535]:	loss/mlm_loss, 7.25965690612793, 2731
[INFO] 2021-07-12 19:27:33,313 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7299998691887595e-05, 2731
[INFO] 2021-07-12 19:27:33,313 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2731
[INFO] 2021-07-12 19:27:33,313 [run_pretraining.py:  558]:	worker_index: 6, step: 2731, cost: 7.259657, mlm loss: 7.259657, speed: 1.071374 steps/s, speed: 8.570994 samples/s, speed: 4388.349172 tokens/s, learning rate: 2.730e-05, loss_scalings: 2814.750488, pp_loss: 7.327623
[INFO] 2021-07-12 19:27:33,313 [run_pretraining.py:  512]:	********exe.run_2731******* 
[INFO] 2021-07-12 19:27:34,260 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:34,260 [run_pretraining.py:  534]:	loss/total_loss, 6.9703168869018555, 2732
[INFO] 2021-07-12 19:27:34,260 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9703168869018555, 2732
[INFO] 2021-07-12 19:27:34,260 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7309997676638886e-05, 2732
[INFO] 2021-07-12 19:27:34,261 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2732
[INFO] 2021-07-12 19:27:34,261 [run_pretraining.py:  558]:	worker_index: 6, step: 2732, cost: 6.970317, mlm loss: 6.970317, speed: 1.056173 steps/s, speed: 8.449382 samples/s, speed: 4326.083735 tokens/s, learning rate: 2.731e-05, loss_scalings: 2814.750488, pp_loss: 7.027491
[INFO] 2021-07-12 19:27:34,261 [run_pretraining.py:  512]:	********exe.run_2732******* 
[INFO] 2021-07-12 19:27:35,198 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:35,198 [run_pretraining.py:  534]:	loss/total_loss, 7.218057155609131, 2733
[INFO] 2021-07-12 19:27:35,198 [run_pretraining.py:  535]:	loss/mlm_loss, 7.218057155609131, 2733
[INFO] 2021-07-12 19:27:35,198 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7320000299368985e-05, 2733
[INFO] 2021-07-12 19:27:35,199 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2733
[INFO] 2021-07-12 19:27:35,199 [run_pretraining.py:  558]:	worker_index: 6, step: 2733, cost: 7.218057, mlm loss: 7.218057, speed: 1.066949 steps/s, speed: 8.535595 samples/s, speed: 4370.224751 tokens/s, learning rate: 2.732e-05, loss_scalings: 2814.750488, pp_loss: 7.246698
[INFO] 2021-07-12 19:27:35,199 [run_pretraining.py:  512]:	********exe.run_2733******* 
[INFO] 2021-07-12 19:27:36,128 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:36,128 [run_pretraining.py:  534]:	loss/total_loss, 6.822116851806641, 2734
[INFO] 2021-07-12 19:27:36,129 [run_pretraining.py:  535]:	loss/mlm_loss, 6.822116851806641, 2734
[INFO] 2021-07-12 19:27:36,129 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7329999284120277e-05, 2734
[INFO] 2021-07-12 19:27:36,129 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2734
[INFO] 2021-07-12 19:27:36,129 [run_pretraining.py:  558]:	worker_index: 6, step: 2734, cost: 6.822117, mlm loss: 6.822117, speed: 1.075836 steps/s, speed: 8.606691 samples/s, speed: 4406.625683 tokens/s, learning rate: 2.733e-05, loss_scalings: 2814.750488, pp_loss: 7.099050
[INFO] 2021-07-12 19:27:36,129 [run_pretraining.py:  512]:	********exe.run_2734******* 
[INFO] 2021-07-12 19:27:37,049 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:37,050 [run_pretraining.py:  534]:	loss/total_loss, 7.215592384338379, 2735
[INFO] 2021-07-12 19:27:37,050 [run_pretraining.py:  535]:	loss/mlm_loss, 7.215592384338379, 2735
[INFO] 2021-07-12 19:27:37,050 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.734000008786097e-05, 2735
[INFO] 2021-07-12 19:27:37,050 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2735
[INFO] 2021-07-12 19:27:37,050 [run_pretraining.py:  558]:	worker_index: 6, step: 2735, cost: 7.215592, mlm loss: 7.215592, speed: 1.086225 steps/s, speed: 8.689801 samples/s, speed: 4449.178031 tokens/s, learning rate: 2.734e-05, loss_scalings: 2814.750488, pp_loss: 7.502922
[INFO] 2021-07-12 19:27:37,050 [run_pretraining.py:  512]:	********exe.run_2735******* 
[INFO] 2021-07-12 19:27:37,970 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:37,971 [run_pretraining.py:  534]:	loss/total_loss, 7.527270793914795, 2736
[INFO] 2021-07-12 19:27:37,971 [run_pretraining.py:  535]:	loss/mlm_loss, 7.527270793914795, 2736
[INFO] 2021-07-12 19:27:37,971 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7349999072612263e-05, 2736
[INFO] 2021-07-12 19:27:37,971 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2736
[INFO] 2021-07-12 19:27:37,971 [run_pretraining.py:  558]:	worker_index: 6, step: 2736, cost: 7.527271, mlm loss: 7.527271, speed: 1.086258 steps/s, speed: 8.690064 samples/s, speed: 4449.312846 tokens/s, learning rate: 2.735e-05, loss_scalings: 2814.750488, pp_loss: 7.396164
[INFO] 2021-07-12 19:27:37,972 [run_pretraining.py:  512]:	********exe.run_2736******* 
[INFO] 2021-07-12 19:27:38,894 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:38,895 [run_pretraining.py:  534]:	loss/total_loss, 7.070456504821777, 2737
[INFO] 2021-07-12 19:27:38,895 [run_pretraining.py:  535]:	loss/mlm_loss, 7.070456504821777, 2737
[INFO] 2021-07-12 19:27:38,895 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.735999987635296e-05, 2737
[INFO] 2021-07-12 19:27:38,895 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2737
[INFO] 2021-07-12 19:27:38,895 [run_pretraining.py:  558]:	worker_index: 6, step: 2737, cost: 7.070457, mlm loss: 7.070457, speed: 1.083363 steps/s, speed: 8.666907 samples/s, speed: 4437.456234 tokens/s, learning rate: 2.736e-05, loss_scalings: 2814.750488, pp_loss: 6.858057
[INFO] 2021-07-12 19:27:38,895 [run_pretraining.py:  512]:	********exe.run_2737******* 
[INFO] 2021-07-12 19:27:39,819 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:39,820 [run_pretraining.py:  534]:	loss/total_loss, 8.358647346496582, 2738
[INFO] 2021-07-12 19:27:39,820 [run_pretraining.py:  535]:	loss/mlm_loss, 8.358647346496582, 2738
[INFO] 2021-07-12 19:27:39,820 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.736999886110425e-05, 2738
[INFO] 2021-07-12 19:27:39,820 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2738
[INFO] 2021-07-12 19:27:39,820 [run_pretraining.py:  558]:	worker_index: 6, step: 2738, cost: 8.358647, mlm loss: 8.358647, speed: 1.081791 steps/s, speed: 8.654326 samples/s, speed: 4431.014964 tokens/s, learning rate: 2.737e-05, loss_scalings: 2814.750488, pp_loss: 7.699824
[INFO] 2021-07-12 19:27:39,820 [run_pretraining.py:  512]:	********exe.run_2738******* 
[INFO] 2021-07-12 19:27:40,748 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:40,748 [run_pretraining.py:  534]:	loss/total_loss, 6.748247146606445, 2739
[INFO] 2021-07-12 19:27:40,748 [run_pretraining.py:  535]:	loss/mlm_loss, 6.748247146606445, 2739
[INFO] 2021-07-12 19:27:40,749 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.737999784585554e-05, 2739
[INFO] 2021-07-12 19:27:40,749 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2739
[INFO] 2021-07-12 19:27:40,749 [run_pretraining.py:  558]:	worker_index: 6, step: 2739, cost: 6.748247, mlm loss: 6.748247, speed: 1.077920 steps/s, speed: 8.623362 samples/s, speed: 4415.161230 tokens/s, learning rate: 2.738e-05, loss_scalings: 2814.750488, pp_loss: 6.824298
[INFO] 2021-07-12 19:27:40,749 [run_pretraining.py:  512]:	********exe.run_2739******* 
[INFO] 2021-07-12 19:27:41,673 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:41,674 [run_pretraining.py:  534]:	loss/total_loss, 7.414897918701172, 2740
[INFO] 2021-07-12 19:27:41,674 [run_pretraining.py:  535]:	loss/mlm_loss, 7.414897918701172, 2740
[INFO] 2021-07-12 19:27:41,674 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7389998649596237e-05, 2740
[INFO] 2021-07-12 19:27:41,674 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2740
[INFO] 2021-07-12 19:27:41,674 [run_pretraining.py:  558]:	worker_index: 6, step: 2740, cost: 7.414898, mlm loss: 7.414898, speed: 1.081092 steps/s, speed: 8.648736 samples/s, speed: 4428.152849 tokens/s, learning rate: 2.739e-05, loss_scalings: 2814.750488, pp_loss: 6.811579
[INFO] 2021-07-12 19:27:41,675 [run_pretraining.py:  512]:	********exe.run_2740******* 
[INFO] 2021-07-12 19:27:42,597 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:42,597 [run_pretraining.py:  534]:	loss/total_loss, 6.6959309577941895, 2741
[INFO] 2021-07-12 19:27:42,597 [run_pretraining.py:  535]:	loss/mlm_loss, 6.6959309577941895, 2741
[INFO] 2021-07-12 19:27:42,598 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7399997634347528e-05, 2741
[INFO] 2021-07-12 19:27:42,598 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2741
[INFO] 2021-07-12 19:27:42,598 [run_pretraining.py:  558]:	worker_index: 6, step: 2741, cost: 6.695931, mlm loss: 6.695931, speed: 1.083884 steps/s, speed: 8.671073 samples/s, speed: 4439.589132 tokens/s, learning rate: 2.740e-05, loss_scalings: 2814.750488, pp_loss: 6.956645
[INFO] 2021-07-12 19:27:42,598 [run_pretraining.py:  512]:	********exe.run_2741******* 
[INFO] 2021-07-12 19:27:43,513 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:43,514 [run_pretraining.py:  534]:	loss/total_loss, 7.261331558227539, 2742
[INFO] 2021-07-12 19:27:43,514 [run_pretraining.py:  535]:	loss/mlm_loss, 7.261331558227539, 2742
[INFO] 2021-07-12 19:27:43,514 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7410000257077627e-05, 2742
[INFO] 2021-07-12 19:27:43,514 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2742
[INFO] 2021-07-12 19:27:43,514 [run_pretraining.py:  558]:	worker_index: 6, step: 2742, cost: 7.261332, mlm loss: 7.261332, speed: 1.092395 steps/s, speed: 8.739162 samples/s, speed: 4474.450947 tokens/s, learning rate: 2.741e-05, loss_scalings: 2814.750488, pp_loss: 7.418772
[INFO] 2021-07-12 19:27:43,514 [run_pretraining.py:  512]:	********exe.run_2742******* 
[INFO] 2021-07-12 19:27:44,445 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:44,445 [run_pretraining.py:  534]:	loss/total_loss, 6.95064115524292, 2743
[INFO] 2021-07-12 19:27:44,446 [run_pretraining.py:  535]:	loss/mlm_loss, 6.95064115524292, 2743
[INFO] 2021-07-12 19:27:44,446 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.741999924182892e-05, 2743
[INFO] 2021-07-12 19:27:44,446 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2743
[INFO] 2021-07-12 19:27:44,446 [run_pretraining.py:  558]:	worker_index: 6, step: 2743, cost: 6.950641, mlm loss: 6.950641, speed: 1.073812 steps/s, speed: 8.590493 samples/s, speed: 4398.332508 tokens/s, learning rate: 2.742e-05, loss_scalings: 2814.750488, pp_loss: 7.183784
[INFO] 2021-07-12 19:27:44,446 [run_pretraining.py:  512]:	********exe.run_2743******* 
[INFO] 2021-07-12 19:27:45,370 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:45,371 [run_pretraining.py:  534]:	loss/total_loss, 7.136626720428467, 2744
[INFO] 2021-07-12 19:27:45,371 [run_pretraining.py:  535]:	loss/mlm_loss, 7.136626720428467, 2744
[INFO] 2021-07-12 19:27:45,371 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7430000045569614e-05, 2744
[INFO] 2021-07-12 19:27:45,371 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2744
[INFO] 2021-07-12 19:27:45,371 [run_pretraining.py:  558]:	worker_index: 6, step: 2744, cost: 7.136627, mlm loss: 7.136627, speed: 1.081624 steps/s, speed: 8.652996 samples/s, speed: 4430.333934 tokens/s, learning rate: 2.743e-05, loss_scalings: 2814.750488, pp_loss: 7.281780
[INFO] 2021-07-12 19:27:45,371 [run_pretraining.py:  512]:	********exe.run_2744******* 
[INFO] 2021-07-12 19:27:46,294 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:46,295 [run_pretraining.py:  534]:	loss/total_loss, 6.860073566436768, 2745
[INFO] 2021-07-12 19:27:46,295 [run_pretraining.py:  535]:	loss/mlm_loss, 6.860073566436768, 2745
[INFO] 2021-07-12 19:27:46,295 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7439999030320905e-05, 2745
[INFO] 2021-07-12 19:27:46,295 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2745
[INFO] 2021-07-12 19:27:46,295 [run_pretraining.py:  558]:	worker_index: 6, step: 2745, cost: 6.860074, mlm loss: 6.860074, speed: 1.083104 steps/s, speed: 8.664830 samples/s, speed: 4436.392845 tokens/s, learning rate: 2.744e-05, loss_scalings: 2814.750488, pp_loss: 7.217331
[INFO] 2021-07-12 19:27:46,295 [run_pretraining.py:  512]:	********exe.run_2745******* 
[INFO] 2021-07-12 19:27:47,209 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:47,209 [run_pretraining.py:  534]:	loss/total_loss, 7.420455455780029, 2746
[INFO] 2021-07-12 19:27:47,209 [run_pretraining.py:  535]:	loss/mlm_loss, 7.420455455780029, 2746
[INFO] 2021-07-12 19:27:47,210 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.74499998340616e-05, 2746
[INFO] 2021-07-12 19:27:47,210 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2746
[INFO] 2021-07-12 19:27:47,210 [run_pretraining.py:  558]:	worker_index: 6, step: 2746, cost: 7.420455, mlm loss: 7.420455, speed: 1.094213 steps/s, speed: 8.753705 samples/s, speed: 4481.897142 tokens/s, learning rate: 2.745e-05, loss_scalings: 2814.750488, pp_loss: 7.194285
[INFO] 2021-07-12 19:27:47,210 [run_pretraining.py:  512]:	********exe.run_2746******* 
[INFO] 2021-07-12 19:27:48,135 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:48,136 [run_pretraining.py:  534]:	loss/total_loss, 6.938726425170898, 2747
[INFO] 2021-07-12 19:27:48,136 [run_pretraining.py:  535]:	loss/mlm_loss, 6.938726425170898, 2747
[INFO] 2021-07-12 19:27:48,136 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7459998818812892e-05, 2747
[INFO] 2021-07-12 19:27:48,136 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2747
[INFO] 2021-07-12 19:27:48,136 [run_pretraining.py:  558]:	worker_index: 6, step: 2747, cost: 6.938726, mlm loss: 6.938726, speed: 1.080350 steps/s, speed: 8.642801 samples/s, speed: 4425.114334 tokens/s, learning rate: 2.746e-05, loss_scalings: 2814.750488, pp_loss: 7.099797
[INFO] 2021-07-12 19:27:48,136 [run_pretraining.py:  512]:	********exe.run_2747******* 
[INFO] 2021-07-12 19:27:49,069 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:49,070 [run_pretraining.py:  534]:	loss/total_loss, 6.9757256507873535, 2748
[INFO] 2021-07-12 19:27:49,070 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9757256507873535, 2748
[INFO] 2021-07-12 19:27:49,070 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7469997803564183e-05, 2748
[INFO] 2021-07-12 19:27:49,070 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2748
[INFO] 2021-07-12 19:27:49,070 [run_pretraining.py:  558]:	worker_index: 6, step: 2748, cost: 6.975726, mlm loss: 6.975726, speed: 1.071068 steps/s, speed: 8.568545 samples/s, speed: 4387.095198 tokens/s, learning rate: 2.747e-05, loss_scalings: 2814.750488, pp_loss: 7.379753
[INFO] 2021-07-12 19:27:49,070 [run_pretraining.py:  512]:	********exe.run_2748******* 
[INFO] 2021-07-12 19:27:49,988 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:49,988 [run_pretraining.py:  534]:	loss/total_loss, 7.598148822784424, 2749
[INFO] 2021-07-12 19:27:49,988 [run_pretraining.py:  535]:	loss/mlm_loss, 7.598148822784424, 2749
[INFO] 2021-07-12 19:27:49,989 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7480000426294282e-05, 2749
[INFO] 2021-07-12 19:27:49,989 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2749
[INFO] 2021-07-12 19:27:49,989 [run_pretraining.py:  558]:	worker_index: 6, step: 2749, cost: 7.598149, mlm loss: 7.598149, speed: 1.089783 steps/s, speed: 8.718265 samples/s, speed: 4463.751795 tokens/s, learning rate: 2.748e-05, loss_scalings: 2814.750488, pp_loss: 7.431347
[INFO] 2021-07-12 19:27:49,989 [run_pretraining.py:  512]:	********exe.run_2749******* 
[INFO] 2021-07-12 19:27:50,917 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:50,917 [run_pretraining.py:  534]:	loss/total_loss, 7.464127063751221, 2750
[INFO] 2021-07-12 19:27:50,917 [run_pretraining.py:  535]:	loss/mlm_loss, 7.464127063751221, 2750
[INFO] 2021-07-12 19:27:50,917 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.748999759205617e-05, 2750
[INFO] 2021-07-12 19:27:50,917 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2750
[INFO] 2021-07-12 19:27:50,918 [run_pretraining.py:  558]:	worker_index: 6, step: 2750, cost: 7.464127, mlm loss: 7.464127, speed: 1.077476 steps/s, speed: 8.619804 samples/s, speed: 4413.339686 tokens/s, learning rate: 2.749e-05, loss_scalings: 2814.750488, pp_loss: 7.461479
[INFO] 2021-07-12 19:27:50,918 [run_pretraining.py:  512]:	********exe.run_2750******* 
[INFO] 2021-07-12 19:27:51,833 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:51,834 [run_pretraining.py:  534]:	loss/total_loss, 7.687884330749512, 2751
[INFO] 2021-07-12 19:27:51,834 [run_pretraining.py:  535]:	loss/mlm_loss, 7.687884330749512, 2751
[INFO] 2021-07-12 19:27:51,834 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.750000021478627e-05, 2751
[INFO] 2021-07-12 19:27:51,834 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2751
[INFO] 2021-07-12 19:27:51,834 [run_pretraining.py:  558]:	worker_index: 6, step: 2751, cost: 7.687884, mlm loss: 7.687884, speed: 1.091553 steps/s, speed: 8.732428 samples/s, speed: 4471.002979 tokens/s, learning rate: 2.750e-05, loss_scalings: 2814.750488, pp_loss: 7.304065
[INFO] 2021-07-12 19:27:51,834 [run_pretraining.py:  512]:	********exe.run_2751******* 
[INFO] 2021-07-12 19:27:52,756 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:52,757 [run_pretraining.py:  534]:	loss/total_loss, 7.175938606262207, 2752
[INFO] 2021-07-12 19:27:52,757 [run_pretraining.py:  535]:	loss/mlm_loss, 7.175938606262207, 2752
[INFO] 2021-07-12 19:27:52,757 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.750999919953756e-05, 2752
[INFO] 2021-07-12 19:27:52,757 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2752
[INFO] 2021-07-12 19:27:52,757 [run_pretraining.py:  558]:	worker_index: 6, step: 2752, cost: 7.175939, mlm loss: 7.175939, speed: 1.084150 steps/s, speed: 8.673202 samples/s, speed: 4440.679306 tokens/s, learning rate: 2.751e-05, loss_scalings: 2814.750488, pp_loss: 7.204543
[INFO] 2021-07-12 19:27:52,758 [run_pretraining.py:  512]:	********exe.run_2752******* 
[INFO] 2021-07-12 19:27:53,679 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:53,679 [run_pretraining.py:  534]:	loss/total_loss, 7.067327499389648, 2753
[INFO] 2021-07-12 19:27:53,680 [run_pretraining.py:  535]:	loss/mlm_loss, 7.067327499389648, 2753
[INFO] 2021-07-12 19:27:53,680 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7520000003278255e-05, 2753
[INFO] 2021-07-12 19:27:53,680 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2753
[INFO] 2021-07-12 19:27:53,680 [run_pretraining.py:  558]:	worker_index: 6, step: 2753, cost: 7.067327, mlm loss: 7.067327, speed: 1.085084 steps/s, speed: 8.680669 samples/s, speed: 4444.502585 tokens/s, learning rate: 2.752e-05, loss_scalings: 2814.750488, pp_loss: 6.982201
[INFO] 2021-07-12 19:27:53,680 [run_pretraining.py:  512]:	********exe.run_2753******* 
[INFO] 2021-07-12 19:27:54,597 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:54,598 [run_pretraining.py:  534]:	loss/total_loss, 7.6486101150512695, 2754
[INFO] 2021-07-12 19:27:54,598 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6486101150512695, 2754
[INFO] 2021-07-12 19:27:54,598 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7529998988029547e-05, 2754
[INFO] 2021-07-12 19:27:54,598 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2754
[INFO] 2021-07-12 19:27:54,598 [run_pretraining.py:  558]:	worker_index: 6, step: 2754, cost: 7.648610, mlm loss: 7.648610, speed: 1.089465 steps/s, speed: 8.715722 samples/s, speed: 4462.449728 tokens/s, learning rate: 2.753e-05, loss_scalings: 2814.750488, pp_loss: 7.231387
[INFO] 2021-07-12 19:27:54,598 [run_pretraining.py:  512]:	********exe.run_2754******* 
[INFO] 2021-07-12 19:27:55,525 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:55,525 [run_pretraining.py:  534]:	loss/total_loss, 7.141427993774414, 2755
[INFO] 2021-07-12 19:27:55,525 [run_pretraining.py:  535]:	loss/mlm_loss, 7.141427993774414, 2755
[INFO] 2021-07-12 19:27:55,526 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7539999791770242e-05, 2755
[INFO] 2021-07-12 19:27:55,526 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2755
[INFO] 2021-07-12 19:27:55,526 [run_pretraining.py:  558]:	worker_index: 6, step: 2755, cost: 7.141428, mlm loss: 7.141428, speed: 1.079155 steps/s, speed: 8.633237 samples/s, speed: 4420.217473 tokens/s, learning rate: 2.754e-05, loss_scalings: 2814.750488, pp_loss: 7.112846
[INFO] 2021-07-12 19:27:55,526 [run_pretraining.py:  512]:	********exe.run_2755******* 
[INFO] 2021-07-12 19:27:56,455 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:56,456 [run_pretraining.py:  534]:	loss/total_loss, 8.139955520629883, 2756
[INFO] 2021-07-12 19:27:56,456 [run_pretraining.py:  535]:	loss/mlm_loss, 8.139955520629883, 2756
[INFO] 2021-07-12 19:27:56,456 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7549998776521534e-05, 2756
[INFO] 2021-07-12 19:27:56,456 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2756
[INFO] 2021-07-12 19:27:56,456 [run_pretraining.py:  558]:	worker_index: 6, step: 2756, cost: 8.139956, mlm loss: 8.139956, speed: 1.075487 steps/s, speed: 8.603899 samples/s, speed: 4405.196321 tokens/s, learning rate: 2.755e-05, loss_scalings: 2814.750488, pp_loss: 7.406291
[INFO] 2021-07-12 19:27:56,456 [run_pretraining.py:  512]:	********exe.run_2756******* 
[INFO] 2021-07-12 19:27:57,375 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:57,375 [run_pretraining.py:  534]:	loss/total_loss, 7.370270252227783, 2757
[INFO] 2021-07-12 19:27:57,376 [run_pretraining.py:  535]:	loss/mlm_loss, 7.370270252227783, 2757
[INFO] 2021-07-12 19:27:57,376 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7559997761272825e-05, 2757
[INFO] 2021-07-12 19:27:57,376 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2757
[INFO] 2021-07-12 19:27:57,376 [run_pretraining.py:  558]:	worker_index: 6, step: 2757, cost: 7.370270, mlm loss: 7.370270, speed: 1.088344 steps/s, speed: 8.706750 samples/s, speed: 4457.856249 tokens/s, learning rate: 2.756e-05, loss_scalings: 2814.750488, pp_loss: 7.478826
[INFO] 2021-07-12 19:27:57,376 [run_pretraining.py:  512]:	********exe.run_2757******* 
[INFO] 2021-07-12 19:27:58,385 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:58,385 [run_pretraining.py:  534]:	loss/total_loss, 7.29685115814209, 2758
[INFO] 2021-07-12 19:27:58,386 [run_pretraining.py:  535]:	loss/mlm_loss, 7.29685115814209, 2758
[INFO] 2021-07-12 19:27:58,386 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7570000384002924e-05, 2758
[INFO] 2021-07-12 19:27:58,386 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2758
[INFO] 2021-07-12 19:27:58,386 [run_pretraining.py:  558]:	worker_index: 6, step: 2758, cost: 7.296851, mlm loss: 7.296851, speed: 0.990796 steps/s, speed: 7.926366 samples/s, speed: 4058.299447 tokens/s, learning rate: 2.757e-05, loss_scalings: 2814.750488, pp_loss: 7.230738
[INFO] 2021-07-12 19:27:58,386 [run_pretraining.py:  512]:	********exe.run_2758******* 
[INFO] 2021-07-12 19:27:59,457 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:59,458 [run_pretraining.py:  534]:	loss/total_loss, 7.846781253814697, 2759
[INFO] 2021-07-12 19:27:59,458 [run_pretraining.py:  535]:	loss/mlm_loss, 7.846781253814697, 2759
[INFO] 2021-07-12 19:27:59,458 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7579997549764812e-05, 2759
[INFO] 2021-07-12 19:27:59,458 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2759
[INFO] 2021-07-12 19:27:59,458 [run_pretraining.py:  558]:	worker_index: 6, step: 2759, cost: 7.846781, mlm loss: 7.846781, speed: 0.933148 steps/s, speed: 7.465187 samples/s, speed: 3822.175636 tokens/s, learning rate: 2.758e-05, loss_scalings: 2814.750488, pp_loss: 7.600242
[INFO] 2021-07-12 19:27:59,458 [run_pretraining.py:  512]:	********exe.run_2759******* 
[INFO] 2021-07-12 19:28:00,521 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:00,522 [run_pretraining.py:  534]:	loss/total_loss, 6.6456990242004395, 2760
[INFO] 2021-07-12 19:28:00,522 [run_pretraining.py:  535]:	loss/mlm_loss, 6.6456990242004395, 2760
[INFO] 2021-07-12 19:28:00,522 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.759000017249491e-05, 2760
[INFO] 2021-07-12 19:28:00,522 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2760
[INFO] 2021-07-12 19:28:00,522 [run_pretraining.py:  558]:	worker_index: 6, step: 2760, cost: 6.645699, mlm loss: 6.645699, speed: 0.940451 steps/s, speed: 7.523608 samples/s, speed: 3852.087068 tokens/s, learning rate: 2.759e-05, loss_scalings: 2814.750488, pp_loss: 6.994994
[INFO] 2021-07-12 19:28:00,522 [run_pretraining.py:  512]:	********exe.run_2760******* 
[INFO] 2021-07-12 19:28:01,589 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:01,590 [run_pretraining.py:  534]:	loss/total_loss, 6.64063024520874, 2761
[INFO] 2021-07-12 19:28:01,590 [run_pretraining.py:  535]:	loss/mlm_loss, 6.64063024520874, 2761
[INFO] 2021-07-12 19:28:01,590 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7599999157246202e-05, 2761
[INFO] 2021-07-12 19:28:01,590 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2761
[INFO] 2021-07-12 19:28:01,590 [run_pretraining.py:  558]:	worker_index: 6, step: 2761, cost: 6.640630, mlm loss: 6.640630, speed: 0.937018 steps/s, speed: 7.496142 samples/s, speed: 3838.024565 tokens/s, learning rate: 2.760e-05, loss_scalings: 2814.750488, pp_loss: 7.007066
[INFO] 2021-07-12 19:28:01,590 [run_pretraining.py:  512]:	********exe.run_2761******* 
[INFO] 2021-07-12 19:28:02,688 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:02,688 [run_pretraining.py:  534]:	loss/total_loss, 7.3079071044921875, 2762
[INFO] 2021-07-12 19:28:02,689 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3079071044921875, 2762
[INFO] 2021-07-12 19:28:02,689 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7609999960986897e-05, 2762
[INFO] 2021-07-12 19:28:02,689 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2762
[INFO] 2021-07-12 19:28:02,689 [run_pretraining.py:  558]:	worker_index: 6, step: 2762, cost: 7.307907, mlm loss: 7.307907, speed: 0.910687 steps/s, speed: 7.285496 samples/s, speed: 3730.174165 tokens/s, learning rate: 2.761e-05, loss_scalings: 2814.750488, pp_loss: 7.264324
[INFO] 2021-07-12 19:28:02,689 [run_pretraining.py:  512]:	********exe.run_2762******* 
[INFO] 2021-07-12 19:28:03,757 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:03,758 [run_pretraining.py:  534]:	loss/total_loss, 7.1234965324401855, 2763
[INFO] 2021-07-12 19:28:03,758 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1234965324401855, 2763
[INFO] 2021-07-12 19:28:03,758 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.761999894573819e-05, 2763
[INFO] 2021-07-12 19:28:03,758 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2763
[INFO] 2021-07-12 19:28:03,758 [run_pretraining.py:  558]:	worker_index: 6, step: 2763, cost: 7.123497, mlm loss: 7.123497, speed: 0.935816 steps/s, speed: 7.486528 samples/s, speed: 3833.102412 tokens/s, learning rate: 2.762e-05, loss_scalings: 2814.750488, pp_loss: 7.056683
[INFO] 2021-07-12 19:28:03,758 [run_pretraining.py:  512]:	********exe.run_2763******* 
[INFO] 2021-07-12 19:28:04,835 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:04,835 [run_pretraining.py:  534]:	loss/total_loss, 7.235222339630127, 2764
[INFO] 2021-07-12 19:28:04,835 [run_pretraining.py:  535]:	loss/mlm_loss, 7.235222339630127, 2764
[INFO] 2021-07-12 19:28:04,835 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7629999749478884e-05, 2764
[INFO] 2021-07-12 19:28:04,836 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2764
[INFO] 2021-07-12 19:28:04,836 [run_pretraining.py:  558]:	worker_index: 6, step: 2764, cost: 7.235222, mlm loss: 7.235222, speed: 0.928746 steps/s, speed: 7.429968 samples/s, speed: 3804.143400 tokens/s, learning rate: 2.763e-05, loss_scalings: 2814.750488, pp_loss: 7.233652
[INFO] 2021-07-12 19:28:04,836 [run_pretraining.py:  512]:	********exe.run_2764******* 
[INFO] 2021-07-12 19:28:05,897 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:05,898 [run_pretraining.py:  534]:	loss/total_loss, 7.610627174377441, 2765
[INFO] 2021-07-12 19:28:05,898 [run_pretraining.py:  535]:	loss/mlm_loss, 7.610627174377441, 2765
[INFO] 2021-07-12 19:28:05,898 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7639998734230176e-05, 2765
[INFO] 2021-07-12 19:28:05,898 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2765
[INFO] 2021-07-12 19:28:05,898 [run_pretraining.py:  558]:	worker_index: 6, step: 2765, cost: 7.610627, mlm loss: 7.610627, speed: 0.941731 steps/s, speed: 7.533849 samples/s, speed: 3857.330923 tokens/s, learning rate: 2.764e-05, loss_scalings: 2814.750488, pp_loss: 6.988327
[INFO] 2021-07-12 19:28:05,898 [run_pretraining.py:  512]:	********exe.run_2765******* 
[INFO] 2021-07-12 19:28:06,954 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:06,955 [run_pretraining.py:  534]:	loss/total_loss, 7.555792331695557, 2766
[INFO] 2021-07-12 19:28:06,955 [run_pretraining.py:  535]:	loss/mlm_loss, 7.555792331695557, 2766
[INFO] 2021-07-12 19:28:06,955 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7649997718981467e-05, 2766
[INFO] 2021-07-12 19:28:06,955 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2766
[INFO] 2021-07-12 19:28:06,955 [run_pretraining.py:  558]:	worker_index: 6, step: 2766, cost: 7.555792, mlm loss: 7.555792, speed: 0.946599 steps/s, speed: 7.572791 samples/s, speed: 3877.269096 tokens/s, learning rate: 2.765e-05, loss_scalings: 2814.750488, pp_loss: 7.239657
[INFO] 2021-07-12 19:28:06,955 [run_pretraining.py:  512]:	********exe.run_2766******* 
[INFO] 2021-07-12 19:28:08,018 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:08,019 [run_pretraining.py:  534]:	loss/total_loss, 7.172270774841309, 2767
[INFO] 2021-07-12 19:28:08,019 [run_pretraining.py:  535]:	loss/mlm_loss, 7.172270774841309, 2767
[INFO] 2021-07-12 19:28:08,019 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7660000341711566e-05, 2767
[INFO] 2021-07-12 19:28:08,019 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2767
[INFO] 2021-07-12 19:28:08,019 [run_pretraining.py:  558]:	worker_index: 6, step: 2767, cost: 7.172271, mlm loss: 7.172271, speed: 0.940389 steps/s, speed: 7.523112 samples/s, speed: 3851.833151 tokens/s, learning rate: 2.766e-05, loss_scalings: 2814.750488, pp_loss: 7.511971
[INFO] 2021-07-12 19:28:08,020 [run_pretraining.py:  512]:	********exe.run_2767******* 
[INFO] 2021-07-12 19:28:09,092 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:09,093 [run_pretraining.py:  534]:	loss/total_loss, 6.8101301193237305, 2768
[INFO] 2021-07-12 19:28:09,093 [run_pretraining.py:  535]:	loss/mlm_loss, 6.8101301193237305, 2768
[INFO] 2021-07-12 19:28:09,093 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7669997507473454e-05, 2768
[INFO] 2021-07-12 19:28:09,093 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2768
[INFO] 2021-07-12 19:28:09,093 [run_pretraining.py:  558]:	worker_index: 6, step: 2768, cost: 6.810130, mlm loss: 6.810130, speed: 0.931900 steps/s, speed: 7.455203 samples/s, speed: 3817.064181 tokens/s, learning rate: 2.767e-05, loss_scalings: 2814.750488, pp_loss: 7.105515
[INFO] 2021-07-12 19:28:09,093 [run_pretraining.py:  512]:	********exe.run_2768******* 
[INFO] 2021-07-12 19:28:10,163 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:10,164 [run_pretraining.py:  534]:	loss/total_loss, 6.82251501083374, 2769
[INFO] 2021-07-12 19:28:10,164 [run_pretraining.py:  535]:	loss/mlm_loss, 6.82251501083374, 2769
[INFO] 2021-07-12 19:28:10,164 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7680000130203553e-05, 2769
[INFO] 2021-07-12 19:28:10,164 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2769
[INFO] 2021-07-12 19:28:10,164 [run_pretraining.py:  558]:	worker_index: 6, step: 2769, cost: 6.822515, mlm loss: 6.822515, speed: 0.934353 steps/s, speed: 7.474822 samples/s, speed: 3827.108966 tokens/s, learning rate: 2.768e-05, loss_scalings: 2814.750488, pp_loss: 6.845698
[INFO] 2021-07-12 19:28:10,164 [run_pretraining.py:  512]:	********exe.run_2769******* 
[INFO] 2021-07-12 19:28:11,219 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:11,219 [run_pretraining.py:  534]:	loss/total_loss, 7.024363040924072, 2770
[INFO] 2021-07-12 19:28:11,219 [run_pretraining.py:  535]:	loss/mlm_loss, 7.024363040924072, 2770
[INFO] 2021-07-12 19:28:11,219 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7689999114954844e-05, 2770
[INFO] 2021-07-12 19:28:11,219 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2770
[INFO] 2021-07-12 19:28:11,220 [run_pretraining.py:  558]:	worker_index: 6, step: 2770, cost: 7.024363, mlm loss: 7.024363, speed: 0.948186 steps/s, speed: 7.585490 samples/s, speed: 3883.771090 tokens/s, learning rate: 2.769e-05, loss_scalings: 2814.750488, pp_loss: 7.131396
[INFO] 2021-07-12 19:28:11,220 [run_pretraining.py:  512]:	********exe.run_2770******* 
[INFO] 2021-07-12 19:28:12,291 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:12,291 [run_pretraining.py:  534]:	loss/total_loss, 7.504793167114258, 2771
[INFO] 2021-07-12 19:28:12,291 [run_pretraining.py:  535]:	loss/mlm_loss, 7.504793167114258, 2771
[INFO] 2021-07-12 19:28:12,291 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.769999991869554e-05, 2771
[INFO] 2021-07-12 19:28:12,292 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2771
[INFO] 2021-07-12 19:28:12,292 [run_pretraining.py:  558]:	worker_index: 6, step: 2771, cost: 7.504793, mlm loss: 7.504793, speed: 0.933356 steps/s, speed: 7.466850 samples/s, speed: 3823.027034 tokens/s, learning rate: 2.770e-05, loss_scalings: 2814.750488, pp_loss: 7.140643
[INFO] 2021-07-12 19:28:12,292 [run_pretraining.py:  512]:	********exe.run_2771******* 
[INFO] 2021-07-12 19:28:13,357 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:13,357 [run_pretraining.py:  534]:	loss/total_loss, 6.997154235839844, 2772
[INFO] 2021-07-12 19:28:13,358 [run_pretraining.py:  535]:	loss/mlm_loss, 6.997154235839844, 2772
[INFO] 2021-07-12 19:28:13,358 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.770999890344683e-05, 2772
[INFO] 2021-07-12 19:28:13,358 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2772
[INFO] 2021-07-12 19:28:13,358 [run_pretraining.py:  558]:	worker_index: 6, step: 2772, cost: 6.997154, mlm loss: 6.997154, speed: 0.938615 steps/s, speed: 7.508918 samples/s, speed: 3844.565836 tokens/s, learning rate: 2.771e-05, loss_scalings: 2814.750488, pp_loss: 6.915968
[INFO] 2021-07-12 19:28:13,358 [run_pretraining.py:  512]:	********exe.run_2772******* 
[INFO] 2021-07-12 19:28:14,422 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:14,422 [run_pretraining.py:  534]:	loss/total_loss, 7.33753776550293, 2773
[INFO] 2021-07-12 19:28:14,423 [run_pretraining.py:  535]:	loss/mlm_loss, 7.33753776550293, 2773
[INFO] 2021-07-12 19:28:14,423 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.772000152617693e-05, 2773
[INFO] 2021-07-12 19:28:14,423 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2773
[INFO] 2021-07-12 19:28:14,423 [run_pretraining.py:  558]:	worker_index: 6, step: 2773, cost: 7.337538, mlm loss: 7.337538, speed: 0.939575 steps/s, speed: 7.516598 samples/s, speed: 3848.498208 tokens/s, learning rate: 2.772e-05, loss_scalings: 2814.750488, pp_loss: 6.282298
[INFO] 2021-07-12 19:28:14,423 [run_pretraining.py:  512]:	********exe.run_2773******* 
[INFO] 2021-07-12 19:28:15,474 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:15,475 [run_pretraining.py:  534]:	loss/total_loss, 6.594053745269775, 2774
[INFO] 2021-07-12 19:28:15,475 [run_pretraining.py:  535]:	loss/mlm_loss, 6.594053745269775, 2774
[INFO] 2021-07-12 19:28:15,475 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7729998691938818e-05, 2774
[INFO] 2021-07-12 19:28:15,475 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2774
[INFO] 2021-07-12 19:28:15,475 [run_pretraining.py:  558]:	worker_index: 6, step: 2774, cost: 6.594054, mlm loss: 6.594054, speed: 0.950754 steps/s, speed: 7.606031 samples/s, speed: 3894.287907 tokens/s, learning rate: 2.773e-05, loss_scalings: 2814.750488, pp_loss: 7.055225
[INFO] 2021-07-12 19:28:15,475 [run_pretraining.py:  512]:	********exe.run_2774******* 
[INFO] 2021-07-12 19:28:16,417 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:16,417 [run_pretraining.py:  534]:	loss/total_loss, 7.598050117492676, 2775
[INFO] 2021-07-12 19:28:16,418 [run_pretraining.py:  535]:	loss/mlm_loss, 7.598050117492676, 2775
[INFO] 2021-07-12 19:28:16,418 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.773999767669011e-05, 2775
[INFO] 2021-07-12 19:28:16,418 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2775
[INFO] 2021-07-12 19:28:16,418 [run_pretraining.py:  558]:	worker_index: 6, step: 2775, cost: 7.598050, mlm loss: 7.598050, speed: 1.061859 steps/s, speed: 8.494868 samples/s, speed: 4349.372509 tokens/s, learning rate: 2.774e-05, loss_scalings: 2814.750488, pp_loss: 7.129765
[INFO] 2021-07-12 19:28:16,418 [run_pretraining.py:  512]:	********exe.run_2775******* 
[INFO] 2021-07-12 19:28:17,342 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:17,342 [run_pretraining.py:  534]:	loss/total_loss, 7.499929904937744, 2776
[INFO] 2021-07-12 19:28:17,343 [run_pretraining.py:  535]:	loss/mlm_loss, 7.499929904937744, 2776
[INFO] 2021-07-12 19:28:17,343 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7750000299420208e-05, 2776
[INFO] 2021-07-12 19:28:17,343 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2776
[INFO] 2021-07-12 19:28:17,343 [run_pretraining.py:  558]:	worker_index: 6, step: 2776, cost: 7.499930, mlm loss: 7.499930, speed: 1.081885 steps/s, speed: 8.655078 samples/s, speed: 4431.400136 tokens/s, learning rate: 2.775e-05, loss_scalings: 2814.750488, pp_loss: 7.291588
[INFO] 2021-07-12 19:28:17,343 [run_pretraining.py:  512]:	********exe.run_2776******* 
[INFO] 2021-07-12 19:28:18,264 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:18,265 [run_pretraining.py:  534]:	loss/total_loss, 7.22084903717041, 2777
[INFO] 2021-07-12 19:28:18,265 [run_pretraining.py:  535]:	loss/mlm_loss, 7.22084903717041, 2777
[INFO] 2021-07-12 19:28:18,265 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7759997465182096e-05, 2777
[INFO] 2021-07-12 19:28:18,265 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2777
[INFO] 2021-07-12 19:28:18,265 [run_pretraining.py:  558]:	worker_index: 6, step: 2777, cost: 7.220849, mlm loss: 7.220849, speed: 1.084690 steps/s, speed: 8.677524 samples/s, speed: 4442.892284 tokens/s, learning rate: 2.776e-05, loss_scalings: 2814.750488, pp_loss: 7.097028
[INFO] 2021-07-12 19:28:18,266 [run_pretraining.py:  512]:	********exe.run_2777******* 
[INFO] 2021-07-12 19:28:19,187 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:19,188 [run_pretraining.py:  534]:	loss/total_loss, 6.8136138916015625, 2778
[INFO] 2021-07-12 19:28:19,188 [run_pretraining.py:  535]:	loss/mlm_loss, 6.8136138916015625, 2778
[INFO] 2021-07-12 19:28:19,188 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7770000087912194e-05, 2778
[INFO] 2021-07-12 19:28:19,188 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2778
[INFO] 2021-07-12 19:28:19,188 [run_pretraining.py:  558]:	worker_index: 6, step: 2778, cost: 6.813614, mlm loss: 6.813614, speed: 1.084320 steps/s, speed: 8.674563 samples/s, speed: 4441.376150 tokens/s, learning rate: 2.777e-05, loss_scalings: 2814.750488, pp_loss: 7.321552
[INFO] 2021-07-12 19:28:19,189 [run_pretraining.py:  512]:	********exe.run_2778******* 
[INFO] 2021-07-12 19:28:20,111 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:20,111 [run_pretraining.py:  534]:	loss/total_loss, 7.178051948547363, 2779
[INFO] 2021-07-12 19:28:20,111 [run_pretraining.py:  535]:	loss/mlm_loss, 7.178051948547363, 2779
[INFO] 2021-07-12 19:28:20,111 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7779999072663486e-05, 2779
[INFO] 2021-07-12 19:28:20,111 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2779
[INFO] 2021-07-12 19:28:20,112 [run_pretraining.py:  558]:	worker_index: 6, step: 2779, cost: 7.178052, mlm loss: 7.178052, speed: 1.084120 steps/s, speed: 8.672962 samples/s, speed: 4440.556491 tokens/s, learning rate: 2.778e-05, loss_scalings: 2814.750488, pp_loss: 6.366576
[INFO] 2021-07-12 19:28:20,112 [run_pretraining.py:  512]:	********exe.run_2779******* 
[INFO] 2021-07-12 19:28:21,034 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:21,034 [run_pretraining.py:  534]:	loss/total_loss, 7.443836212158203, 2780
[INFO] 2021-07-12 19:28:21,035 [run_pretraining.py:  535]:	loss/mlm_loss, 7.443836212158203, 2780
[INFO] 2021-07-12 19:28:21,035 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.778999987640418e-05, 2780
[INFO] 2021-07-12 19:28:21,035 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2780
[INFO] 2021-07-12 19:28:21,035 [run_pretraining.py:  558]:	worker_index: 6, step: 2780, cost: 7.443836, mlm loss: 7.443836, speed: 1.083978 steps/s, speed: 8.671828 samples/s, speed: 4439.975795 tokens/s, learning rate: 2.779e-05, loss_scalings: 2814.750488, pp_loss: 7.458836
[INFO] 2021-07-12 19:28:21,035 [run_pretraining.py:  512]:	********exe.run_2780******* 
[INFO] 2021-07-12 19:28:21,956 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:21,956 [run_pretraining.py:  534]:	loss/total_loss, 7.607087135314941, 2781
[INFO] 2021-07-12 19:28:21,956 [run_pretraining.py:  535]:	loss/mlm_loss, 7.607087135314941, 2781
[INFO] 2021-07-12 19:28:21,957 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7799998861155473e-05, 2781
[INFO] 2021-07-12 19:28:21,957 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2781
[INFO] 2021-07-12 19:28:21,957 [run_pretraining.py:  558]:	worker_index: 6, step: 2781, cost: 7.607087, mlm loss: 7.607087, speed: 1.085448 steps/s, speed: 8.683581 samples/s, speed: 4445.993240 tokens/s, learning rate: 2.780e-05, loss_scalings: 2814.750488, pp_loss: 7.265642
[INFO] 2021-07-12 19:28:21,957 [run_pretraining.py:  512]:	********exe.run_2781******* 
[INFO] 2021-07-12 19:28:22,869 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:22,869 [run_pretraining.py:  534]:	loss/total_loss, 6.96006441116333, 2782
[INFO] 2021-07-12 19:28:22,869 [run_pretraining.py:  535]:	loss/mlm_loss, 6.96006441116333, 2782
[INFO] 2021-07-12 19:28:22,869 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.781000148388557e-05, 2782
[INFO] 2021-07-12 19:28:22,870 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2782
[INFO] 2021-07-12 19:28:22,870 [run_pretraining.py:  558]:	worker_index: 6, step: 2782, cost: 6.960064, mlm loss: 6.960064, speed: 1.096342 steps/s, speed: 8.770734 samples/s, speed: 4490.615557 tokens/s, learning rate: 2.781e-05, loss_scalings: 2814.750488, pp_loss: 7.670907
[INFO] 2021-07-12 19:28:22,870 [run_pretraining.py:  512]:	********exe.run_2782******* 
[INFO] 2021-07-12 19:28:23,799 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:23,800 [run_pretraining.py:  534]:	loss/total_loss, 6.652774810791016, 2783
[INFO] 2021-07-12 19:28:23,800 [run_pretraining.py:  535]:	loss/mlm_loss, 6.652774810791016, 2783
[INFO] 2021-07-12 19:28:23,800 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.781999864964746e-05, 2783
[INFO] 2021-07-12 19:28:23,800 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2783
[INFO] 2021-07-12 19:28:23,800 [run_pretraining.py:  558]:	worker_index: 6, step: 2783, cost: 6.652775, mlm loss: 6.652775, speed: 1.075186 steps/s, speed: 8.601488 samples/s, speed: 4403.962054 tokens/s, learning rate: 2.782e-05, loss_scalings: 2814.750488, pp_loss: 6.967519
[INFO] 2021-07-12 19:28:23,800 [run_pretraining.py:  512]:	********exe.run_2783******* 
[INFO] 2021-07-12 19:28:24,720 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:24,721 [run_pretraining.py:  534]:	loss/total_loss, 7.650033950805664, 2784
[INFO] 2021-07-12 19:28:24,721 [run_pretraining.py:  535]:	loss/mlm_loss, 7.650033950805664, 2784
[INFO] 2021-07-12 19:28:24,721 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.782999763439875e-05, 2784
[INFO] 2021-07-12 19:28:24,721 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2784
[INFO] 2021-07-12 19:28:24,721 [run_pretraining.py:  558]:	worker_index: 6, step: 2784, cost: 7.650034, mlm loss: 7.650034, speed: 1.086505 steps/s, speed: 8.692036 samples/s, speed: 4450.322491 tokens/s, learning rate: 2.783e-05, loss_scalings: 2814.750488, pp_loss: 7.388311
[INFO] 2021-07-12 19:28:24,722 [run_pretraining.py:  512]:	********exe.run_2784******* 
[INFO] 2021-07-12 19:28:25,635 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:25,636 [run_pretraining.py:  534]:	loss/total_loss, 7.752952575683594, 2785
[INFO] 2021-07-12 19:28:25,636 [run_pretraining.py:  535]:	loss/mlm_loss, 7.752952575683594, 2785
[INFO] 2021-07-12 19:28:25,636 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.784000025712885e-05, 2785
[INFO] 2021-07-12 19:28:25,636 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2785
[INFO] 2021-07-12 19:28:25,636 [run_pretraining.py:  558]:	worker_index: 6, step: 2785, cost: 7.752953, mlm loss: 7.752953, speed: 1.094086 steps/s, speed: 8.752689 samples/s, speed: 4481.376890 tokens/s, learning rate: 2.784e-05, loss_scalings: 2814.750488, pp_loss: 7.365663
[INFO] 2021-07-12 19:28:25,636 [run_pretraining.py:  512]:	********exe.run_2785******* 
[INFO] 2021-07-12 19:28:26,565 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:26,566 [run_pretraining.py:  534]:	loss/total_loss, 6.865983009338379, 2786
[INFO] 2021-07-12 19:28:26,566 [run_pretraining.py:  535]:	loss/mlm_loss, 6.865983009338379, 2786
[INFO] 2021-07-12 19:28:26,566 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.784999924188014e-05, 2786
[INFO] 2021-07-12 19:28:26,566 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2786
[INFO] 2021-07-12 19:28:26,566 [run_pretraining.py:  558]:	worker_index: 6, step: 2786, cost: 6.865983, mlm loss: 6.865983, speed: 1.075941 steps/s, speed: 8.607532 samples/s, speed: 4407.056368 tokens/s, learning rate: 2.785e-05, loss_scalings: 2814.750488, pp_loss: 7.033241
[INFO] 2021-07-12 19:28:26,566 [run_pretraining.py:  512]:	********exe.run_2786******* 
[INFO] 2021-07-12 19:28:27,478 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:27,479 [run_pretraining.py:  534]:	loss/total_loss, 7.41297721862793, 2787
[INFO] 2021-07-12 19:28:27,479 [run_pretraining.py:  535]:	loss/mlm_loss, 7.41297721862793, 2787
[INFO] 2021-07-12 19:28:27,479 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7860000045620836e-05, 2787
[INFO] 2021-07-12 19:28:27,479 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2787
[INFO] 2021-07-12 19:28:27,479 [run_pretraining.py:  558]:	worker_index: 6, step: 2787, cost: 7.412977, mlm loss: 7.412977, speed: 1.096278 steps/s, speed: 8.770220 samples/s, speed: 4490.352643 tokens/s, learning rate: 2.786e-05, loss_scalings: 2814.750488, pp_loss: 7.087998
[INFO] 2021-07-12 19:28:27,479 [run_pretraining.py:  512]:	********exe.run_2787******* 
[INFO] 2021-07-12 19:28:28,390 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:28,391 [run_pretraining.py:  534]:	loss/total_loss, 6.9463396072387695, 2788
[INFO] 2021-07-12 19:28:28,391 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9463396072387695, 2788
[INFO] 2021-07-12 19:28:28,391 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7869999030372128e-05, 2788
[INFO] 2021-07-12 19:28:28,391 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2788
[INFO] 2021-07-12 19:28:28,391 [run_pretraining.py:  558]:	worker_index: 6, step: 2788, cost: 6.946340, mlm loss: 6.946340, speed: 1.097539 steps/s, speed: 8.780313 samples/s, speed: 4495.520325 tokens/s, learning rate: 2.787e-05, loss_scalings: 2814.750488, pp_loss: 7.109843
[INFO] 2021-07-12 19:28:28,391 [run_pretraining.py:  512]:	********exe.run_2788******* 
[INFO] 2021-07-12 19:28:29,311 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:29,312 [run_pretraining.py:  534]:	loss/total_loss, 7.145301342010498, 2789
[INFO] 2021-07-12 19:28:29,312 [run_pretraining.py:  535]:	loss/mlm_loss, 7.145301342010498, 2789
[INFO] 2021-07-12 19:28:29,312 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7879999834112823e-05, 2789
[INFO] 2021-07-12 19:28:29,312 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2789
[INFO] 2021-07-12 19:28:29,312 [run_pretraining.py:  558]:	worker_index: 6, step: 2789, cost: 7.145301, mlm loss: 7.145301, speed: 1.086356 steps/s, speed: 8.690850 samples/s, speed: 4449.715036 tokens/s, learning rate: 2.788e-05, loss_scalings: 2814.750488, pp_loss: 7.392562
[INFO] 2021-07-12 19:28:29,312 [run_pretraining.py:  512]:	********exe.run_2789******* 
[INFO] 2021-07-12 19:28:30,223 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:30,224 [run_pretraining.py:  534]:	loss/total_loss, 7.05888032913208, 2790
[INFO] 2021-07-12 19:28:30,224 [run_pretraining.py:  535]:	loss/mlm_loss, 7.05888032913208, 2790
[INFO] 2021-07-12 19:28:30,224 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7889998818864115e-05, 2790
[INFO] 2021-07-12 19:28:30,224 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2790
[INFO] 2021-07-12 19:28:30,224 [run_pretraining.py:  558]:	worker_index: 6, step: 2790, cost: 7.058880, mlm loss: 7.058880, speed: 1.097329 steps/s, speed: 8.778632 samples/s, speed: 4494.659395 tokens/s, learning rate: 2.789e-05, loss_scalings: 2814.750488, pp_loss: 7.119623
[INFO] 2021-07-12 19:28:30,224 [run_pretraining.py:  512]:	********exe.run_2790******* 
[INFO] 2021-07-12 19:28:31,183 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:31,183 [run_pretraining.py:  534]:	loss/total_loss, 7.706553936004639, 2791
[INFO] 2021-07-12 19:28:31,183 [run_pretraining.py:  535]:	loss/mlm_loss, 7.706553936004639, 2791
[INFO] 2021-07-12 19:28:31,183 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7900001441594213e-05, 2791
[INFO] 2021-07-12 19:28:31,183 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2791
[INFO] 2021-07-12 19:28:31,184 [run_pretraining.py:  558]:	worker_index: 6, step: 2791, cost: 7.706554, mlm loss: 7.706554, speed: 1.043183 steps/s, speed: 8.345464 samples/s, speed: 4272.877587 tokens/s, learning rate: 2.790e-05, loss_scalings: 2814.750488, pp_loss: 7.359405
[INFO] 2021-07-12 19:28:31,184 [run_pretraining.py:  512]:	********exe.run_2791******* 
[INFO] 2021-07-12 19:28:32,140 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:32,140 [run_pretraining.py:  534]:	loss/total_loss, 6.8113508224487305, 2792
[INFO] 2021-07-12 19:28:32,140 [run_pretraining.py:  535]:	loss/mlm_loss, 6.8113508224487305, 2792
[INFO] 2021-07-12 19:28:32,140 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.79099986073561e-05, 2792
[INFO] 2021-07-12 19:28:32,141 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2792
[INFO] 2021-07-12 19:28:32,141 [run_pretraining.py:  558]:	worker_index: 6, step: 2792, cost: 6.811351, mlm loss: 6.811351, speed: 1.045602 steps/s, speed: 8.364812 samples/s, speed: 4282.783847 tokens/s, learning rate: 2.791e-05, loss_scalings: 2814.750488, pp_loss: 7.087581
[INFO] 2021-07-12 19:28:32,141 [run_pretraining.py:  512]:	********exe.run_2792******* 
[INFO] 2021-07-12 19:28:33,065 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:33,066 [run_pretraining.py:  534]:	loss/total_loss, 7.140637397766113, 2793
[INFO] 2021-07-12 19:28:33,066 [run_pretraining.py:  535]:	loss/mlm_loss, 7.140637397766113, 2793
[INFO] 2021-07-12 19:28:33,066 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7919997592107393e-05, 2793
[INFO] 2021-07-12 19:28:33,066 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2793
[INFO] 2021-07-12 19:28:33,066 [run_pretraining.py:  558]:	worker_index: 6, step: 2793, cost: 7.140637, mlm loss: 7.140637, speed: 1.081332 steps/s, speed: 8.650658 samples/s, speed: 4429.136926 tokens/s, learning rate: 2.792e-05, loss_scalings: 2814.750488, pp_loss: 7.586335
[INFO] 2021-07-12 19:28:33,066 [run_pretraining.py:  512]:	********exe.run_2793******* 
[INFO] 2021-07-12 19:28:33,987 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:33,987 [run_pretraining.py:  534]:	loss/total_loss, 8.002758026123047, 2794
[INFO] 2021-07-12 19:28:33,987 [run_pretraining.py:  535]:	loss/mlm_loss, 8.002758026123047, 2794
[INFO] 2021-07-12 19:28:33,987 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.793000021483749e-05, 2794
[INFO] 2021-07-12 19:28:33,988 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2794
[INFO] 2021-07-12 19:28:33,988 [run_pretraining.py:  558]:	worker_index: 6, step: 2794, cost: 8.002758, mlm loss: 8.002758, speed: 1.086098 steps/s, speed: 8.688784 samples/s, speed: 4448.657284 tokens/s, learning rate: 2.793e-05, loss_scalings: 2814.750488, pp_loss: 7.667040
[INFO] 2021-07-12 19:28:33,988 [run_pretraining.py:  512]:	********exe.run_2794******* 
[INFO] 2021-07-12 19:28:34,900 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:34,901 [run_pretraining.py:  534]:	loss/total_loss, 7.697000503540039, 2795
[INFO] 2021-07-12 19:28:34,901 [run_pretraining.py:  535]:	loss/mlm_loss, 7.697000503540039, 2795
[INFO] 2021-07-12 19:28:34,901 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7939999199588783e-05, 2795
[INFO] 2021-07-12 19:28:34,901 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2795
[INFO] 2021-07-12 19:28:34,901 [run_pretraining.py:  558]:	worker_index: 6, step: 2795, cost: 7.697001, mlm loss: 7.697001, speed: 1.095541 steps/s, speed: 8.764330 samples/s, speed: 4487.337198 tokens/s, learning rate: 2.794e-05, loss_scalings: 2814.750488, pp_loss: 7.579761
[INFO] 2021-07-12 19:28:34,901 [run_pretraining.py:  512]:	********exe.run_2795******* 
[INFO] 2021-07-12 19:28:35,827 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:35,828 [run_pretraining.py:  534]:	loss/total_loss, 7.6623358726501465, 2796
[INFO] 2021-07-12 19:28:35,828 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6623358726501465, 2796
[INFO] 2021-07-12 19:28:35,828 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7950000003329478e-05, 2796
[INFO] 2021-07-12 19:28:35,828 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2796
[INFO] 2021-07-12 19:28:35,828 [run_pretraining.py:  558]:	worker_index: 6, step: 2796, cost: 7.662336, mlm loss: 7.662336, speed: 1.079375 steps/s, speed: 8.635004 samples/s, speed: 4421.121796 tokens/s, learning rate: 2.795e-05, loss_scalings: 2814.750488, pp_loss: 7.352629
[INFO] 2021-07-12 19:28:35,828 [run_pretraining.py:  512]:	********exe.run_2796******* 
[INFO] 2021-07-12 19:28:36,751 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:36,752 [run_pretraining.py:  534]:	loss/total_loss, 7.203736782073975, 2797
[INFO] 2021-07-12 19:28:36,752 [run_pretraining.py:  535]:	loss/mlm_loss, 7.203736782073975, 2797
[INFO] 2021-07-12 19:28:36,752 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.795999898808077e-05, 2797
[INFO] 2021-07-12 19:28:36,752 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2797
[INFO] 2021-07-12 19:28:36,752 [run_pretraining.py:  558]:	worker_index: 6, step: 2797, cost: 7.203737, mlm loss: 7.203737, speed: 1.083072 steps/s, speed: 8.664575 samples/s, speed: 4436.262249 tokens/s, learning rate: 2.796e-05, loss_scalings: 2814.750488, pp_loss: 7.542608
[INFO] 2021-07-12 19:28:36,752 [run_pretraining.py:  512]:	********exe.run_2797******* 
[INFO] 2021-07-12 19:28:37,678 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:37,679 [run_pretraining.py:  534]:	loss/total_loss, 7.400535583496094, 2798
[INFO] 2021-07-12 19:28:37,679 [run_pretraining.py:  535]:	loss/mlm_loss, 7.400535583496094, 2798
[INFO] 2021-07-12 19:28:37,679 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7969999791821465e-05, 2798
[INFO] 2021-07-12 19:28:37,679 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2798
[INFO] 2021-07-12 19:28:37,679 [run_pretraining.py:  558]:	worker_index: 6, step: 2798, cost: 7.400536, mlm loss: 7.400536, speed: 1.079610 steps/s, speed: 8.636877 samples/s, speed: 4422.081123 tokens/s, learning rate: 2.797e-05, loss_scalings: 2814.750488, pp_loss: 7.579935
[INFO] 2021-07-12 19:28:37,679 [run_pretraining.py:  512]:	********exe.run_2798******* 
[INFO] 2021-07-12 19:28:38,604 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:38,604 [run_pretraining.py:  534]:	loss/total_loss, 7.4405670166015625, 2799
[INFO] 2021-07-12 19:28:38,604 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4405670166015625, 2799
[INFO] 2021-07-12 19:28:38,604 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7979998776572756e-05, 2799
[INFO] 2021-07-12 19:28:38,604 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2799
[INFO] 2021-07-12 19:28:38,605 [run_pretraining.py:  558]:	worker_index: 6, step: 2799, cost: 7.440567, mlm loss: 7.440567, speed: 1.081631 steps/s, speed: 8.653045 samples/s, speed: 4430.359069 tokens/s, learning rate: 2.798e-05, loss_scalings: 2814.750488, pp_loss: 8.010087
[INFO] 2021-07-12 19:28:38,605 [run_pretraining.py:  512]:	********exe.run_2799******* 
[INFO] 2021-07-12 19:28:39,533 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:39,534 [run_pretraining.py:  534]:	loss/total_loss, 7.170936584472656, 2800
[INFO] 2021-07-12 19:28:39,534 [run_pretraining.py:  535]:	loss/mlm_loss, 7.170936584472656, 2800
[INFO] 2021-07-12 19:28:39,534 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7990001399302855e-05, 2800
[INFO] 2021-07-12 19:28:39,534 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2800
[INFO] 2021-07-12 19:28:39,534 [run_pretraining.py:  558]:	worker_index: 6, step: 2800, cost: 7.170937, mlm loss: 7.170937, speed: 1.076207 steps/s, speed: 8.609654 samples/s, speed: 4408.143063 tokens/s, learning rate: 2.799e-05, loss_scalings: 2814.750488, pp_loss: 7.461580
[INFO] 2021-07-12 19:28:39,535 [run_pretraining.py:  512]:	********exe.run_2800******* 
[INFO] 2021-07-12 19:28:40,450 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:40,451 [run_pretraining.py:  534]:	loss/total_loss, 6.840699195861816, 2801
[INFO] 2021-07-12 19:28:40,451 [run_pretraining.py:  535]:	loss/mlm_loss, 6.840699195861816, 2801
[INFO] 2021-07-12 19:28:40,451 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7999998565064743e-05, 2801
[INFO] 2021-07-12 19:28:40,451 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2801
[INFO] 2021-07-12 19:28:40,451 [run_pretraining.py:  558]:	worker_index: 6, step: 2801, cost: 6.840699, mlm loss: 6.840699, speed: 1.091707 steps/s, speed: 8.733657 samples/s, speed: 4471.632555 tokens/s, learning rate: 2.800e-05, loss_scalings: 2814.750488, pp_loss: 7.212273
[INFO] 2021-07-12 19:28:40,451 [run_pretraining.py:  512]:	********exe.run_2801******* 
[INFO] 2021-07-12 19:28:41,382 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:41,383 [run_pretraining.py:  534]:	loss/total_loss, 6.936740875244141, 2802
[INFO] 2021-07-12 19:28:41,383 [run_pretraining.py:  535]:	loss/mlm_loss, 6.936740875244141, 2802
[INFO] 2021-07-12 19:28:41,383 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8009997549816035e-05, 2802
[INFO] 2021-07-12 19:28:41,383 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2802
[INFO] 2021-07-12 19:28:41,383 [run_pretraining.py:  558]:	worker_index: 6, step: 2802, cost: 6.936741, mlm loss: 6.936741, speed: 1.073738 steps/s, speed: 8.589906 samples/s, speed: 4398.031874 tokens/s, learning rate: 2.801e-05, loss_scalings: 2814.750488, pp_loss: 6.895979
[INFO] 2021-07-12 19:28:41,383 [run_pretraining.py:  512]:	********exe.run_2802******* 
[INFO] 2021-07-12 19:28:42,295 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:42,295 [run_pretraining.py:  534]:	loss/total_loss, 7.747517108917236, 2803
[INFO] 2021-07-12 19:28:42,295 [run_pretraining.py:  535]:	loss/mlm_loss, 7.747517108917236, 2803
[INFO] 2021-07-12 19:28:42,295 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8020000172546133e-05, 2803
[INFO] 2021-07-12 19:28:42,296 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2803
[INFO] 2021-07-12 19:28:42,296 [run_pretraining.py:  558]:	worker_index: 6, step: 2803, cost: 7.747517, mlm loss: 7.747517, speed: 1.096781 steps/s, speed: 8.774247 samples/s, speed: 4492.414530 tokens/s, learning rate: 2.802e-05, loss_scalings: 2814.750488, pp_loss: 7.565168
[INFO] 2021-07-12 19:28:42,296 [run_pretraining.py:  512]:	********exe.run_2803******* 
[INFO] 2021-07-12 19:28:43,224 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:43,225 [run_pretraining.py:  534]:	loss/total_loss, 4.431950569152832, 2804
[INFO] 2021-07-12 19:28:43,225 [run_pretraining.py:  535]:	loss/mlm_loss, 4.431950569152832, 2804
[INFO] 2021-07-12 19:28:43,225 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8029999157297425e-05, 2804
[INFO] 2021-07-12 19:28:43,225 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2804
[INFO] 2021-07-12 19:28:43,225 [run_pretraining.py:  558]:	worker_index: 6, step: 2804, cost: 4.431951, mlm loss: 4.431951, speed: 1.076462 steps/s, speed: 8.611694 samples/s, speed: 4409.187293 tokens/s, learning rate: 2.803e-05, loss_scalings: 2814.750488, pp_loss: 6.548485
[INFO] 2021-07-12 19:28:43,225 [run_pretraining.py:  512]:	********exe.run_2804******* 
[INFO] 2021-07-12 19:28:44,150 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:44,150 [run_pretraining.py:  534]:	loss/total_loss, 8.146627426147461, 2805
[INFO] 2021-07-12 19:28:44,151 [run_pretraining.py:  535]:	loss/mlm_loss, 8.146627426147461, 2805
[INFO] 2021-07-12 19:28:44,151 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.803999996103812e-05, 2805
[INFO] 2021-07-12 19:28:44,151 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2805
[INFO] 2021-07-12 19:28:44,151 [run_pretraining.py:  558]:	worker_index: 6, step: 2805, cost: 8.146627, mlm loss: 8.146627, speed: 1.081273 steps/s, speed: 8.650185 samples/s, speed: 4428.894862 tokens/s, learning rate: 2.804e-05, loss_scalings: 2814.750488, pp_loss: 7.605965
[INFO] 2021-07-12 19:28:44,151 [run_pretraining.py:  512]:	********exe.run_2805******* 
[INFO] 2021-07-12 19:28:45,069 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:45,069 [run_pretraining.py:  534]:	loss/total_loss, 7.130435943603516, 2806
[INFO] 2021-07-12 19:28:45,069 [run_pretraining.py:  535]:	loss/mlm_loss, 7.130435943603516, 2806
[INFO] 2021-07-12 19:28:45,069 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.804999894578941e-05, 2806
[INFO] 2021-07-12 19:28:45,070 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2806
[INFO] 2021-07-12 19:28:45,070 [run_pretraining.py:  558]:	worker_index: 6, step: 2806, cost: 7.130436, mlm loss: 7.130436, speed: 1.089266 steps/s, speed: 8.714129 samples/s, speed: 4461.633860 tokens/s, learning rate: 2.805e-05, loss_scalings: 2814.750488, pp_loss: 7.103823
[INFO] 2021-07-12 19:28:45,070 [run_pretraining.py:  512]:	********exe.run_2806******* 
[INFO] 2021-07-12 19:28:45,982 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:45,983 [run_pretraining.py:  534]:	loss/total_loss, 7.061030864715576, 2807
[INFO] 2021-07-12 19:28:45,983 [run_pretraining.py:  535]:	loss/mlm_loss, 7.061030864715576, 2807
[INFO] 2021-07-12 19:28:45,983 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8059999749530107e-05, 2807
[INFO] 2021-07-12 19:28:45,983 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2807
[INFO] 2021-07-12 19:28:45,983 [run_pretraining.py:  558]:	worker_index: 6, step: 2807, cost: 7.061031, mlm loss: 7.061031, speed: 1.095624 steps/s, speed: 8.764990 samples/s, speed: 4487.674783 tokens/s, learning rate: 2.806e-05, loss_scalings: 2814.750488, pp_loss: 7.055243
[INFO] 2021-07-12 19:28:45,983 [run_pretraining.py:  512]:	********exe.run_2807******* 
[INFO] 2021-07-12 19:28:46,905 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:46,905 [run_pretraining.py:  534]:	loss/total_loss, 7.842595100402832, 2808
[INFO] 2021-07-12 19:28:46,905 [run_pretraining.py:  535]:	loss/mlm_loss, 7.842595100402832, 2808
[INFO] 2021-07-12 19:28:46,905 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.80699987342814e-05, 2808
[INFO] 2021-07-12 19:28:46,905 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2808
[INFO] 2021-07-12 19:28:46,906 [run_pretraining.py:  558]:	worker_index: 6, step: 2808, cost: 7.842595, mlm loss: 7.842595, speed: 1.084884 steps/s, speed: 8.679075 samples/s, speed: 4443.686370 tokens/s, learning rate: 2.807e-05, loss_scalings: 2814.750488, pp_loss: 7.566359
[INFO] 2021-07-12 19:28:46,906 [run_pretraining.py:  512]:	********exe.run_2808******* 
[INFO] 2021-07-12 19:28:47,808 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:47,808 [run_pretraining.py:  534]:	loss/total_loss, 8.655990600585938, 2809
[INFO] 2021-07-12 19:28:47,808 [run_pretraining.py:  535]:	loss/mlm_loss, 8.655990600585938, 2809
[INFO] 2021-07-12 19:28:47,808 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8080001357011497e-05, 2809
[INFO] 2021-07-12 19:28:47,808 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2809
[INFO] 2021-07-12 19:28:47,809 [run_pretraining.py:  558]:	worker_index: 6, step: 2809, cost: 8.655991, mlm loss: 8.655991, speed: 1.108216 steps/s, speed: 8.865728 samples/s, speed: 4539.252863 tokens/s, learning rate: 2.808e-05, loss_scalings: 2814.750488, pp_loss: 7.769269
[INFO] 2021-07-12 19:28:47,809 [run_pretraining.py:  512]:	********exe.run_2809******* 
[INFO] 2021-07-12 19:28:48,733 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:48,733 [run_pretraining.py:  534]:	loss/total_loss, 6.821769714355469, 2810
[INFO] 2021-07-12 19:28:48,733 [run_pretraining.py:  535]:	loss/mlm_loss, 6.821769714355469, 2810
[INFO] 2021-07-12 19:28:48,733 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.809000034176279e-05, 2810
[INFO] 2021-07-12 19:28:48,733 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2810
[INFO] 2021-07-12 19:28:48,734 [run_pretraining.py:  558]:	worker_index: 6, step: 2810, cost: 6.821770, mlm loss: 6.821770, speed: 1.081958 steps/s, speed: 8.655661 samples/s, speed: 4431.698489 tokens/s, learning rate: 2.809e-05, loss_scalings: 2814.750488, pp_loss: 7.213010
[INFO] 2021-07-12 19:28:48,734 [run_pretraining.py:  512]:	********exe.run_2810******* 
[INFO] 2021-07-12 19:28:49,664 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:49,665 [run_pretraining.py:  534]:	loss/total_loss, 7.09736442565918, 2811
[INFO] 2021-07-12 19:28:49,665 [run_pretraining.py:  535]:	loss/mlm_loss, 7.09736442565918, 2811
[INFO] 2021-07-12 19:28:49,665 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8099997507524677e-05, 2811
[INFO] 2021-07-12 19:28:49,665 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2811
[INFO] 2021-07-12 19:28:49,665 [run_pretraining.py:  558]:	worker_index: 6, step: 2811, cost: 7.097364, mlm loss: 7.097364, speed: 1.074158 steps/s, speed: 8.593265 samples/s, speed: 4399.751784 tokens/s, learning rate: 2.810e-05, loss_scalings: 2814.750488, pp_loss: 7.289899
[INFO] 2021-07-12 19:28:49,665 [run_pretraining.py:  512]:	********exe.run_2811******* 
[INFO] 2021-07-12 19:28:50,578 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:50,579 [run_pretraining.py:  534]:	loss/total_loss, 6.891256332397461, 2812
[INFO] 2021-07-12 19:28:50,579 [run_pretraining.py:  535]:	loss/mlm_loss, 6.891256332397461, 2812
[INFO] 2021-07-12 19:28:50,579 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8110000130254775e-05, 2812
[INFO] 2021-07-12 19:28:50,579 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2812
[INFO] 2021-07-12 19:28:50,579 [run_pretraining.py:  558]:	worker_index: 6, step: 2812, cost: 6.891256, mlm loss: 6.891256, speed: 1.095244 steps/s, speed: 8.761955 samples/s, speed: 4486.120908 tokens/s, learning rate: 2.811e-05, loss_scalings: 2814.750488, pp_loss: 7.093914
[INFO] 2021-07-12 19:28:50,579 [run_pretraining.py:  512]:	********exe.run_2812******* 
[INFO] 2021-07-12 19:28:51,499 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:51,500 [run_pretraining.py:  534]:	loss/total_loss, 7.0868706703186035, 2813
[INFO] 2021-07-12 19:28:51,500 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0868706703186035, 2813
[INFO] 2021-07-12 19:28:51,500 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8119999115006067e-05, 2813
[INFO] 2021-07-12 19:28:51,500 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2813
[INFO] 2021-07-12 19:28:51,500 [run_pretraining.py:  558]:	worker_index: 6, step: 2813, cost: 7.086871, mlm loss: 7.086871, speed: 1.086028 steps/s, speed: 8.688221 samples/s, speed: 4448.369312 tokens/s, learning rate: 2.812e-05, loss_scalings: 2814.750488, pp_loss: 6.509677
[INFO] 2021-07-12 19:28:51,501 [run_pretraining.py:  512]:	********exe.run_2813******* 
[INFO] 2021-07-12 19:28:52,414 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:52,415 [run_pretraining.py:  534]:	loss/total_loss, 7.477142333984375, 2814
[INFO] 2021-07-12 19:28:52,415 [run_pretraining.py:  535]:	loss/mlm_loss, 7.477142333984375, 2814
[INFO] 2021-07-12 19:28:52,415 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8129999918746762e-05, 2814
[INFO] 2021-07-12 19:28:52,415 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2814
[INFO] 2021-07-12 19:28:52,415 [run_pretraining.py:  558]:	worker_index: 6, step: 2814, cost: 7.477142, mlm loss: 7.477142, speed: 1.093777 steps/s, speed: 8.750217 samples/s, speed: 4480.111254 tokens/s, learning rate: 2.813e-05, loss_scalings: 2814.750488, pp_loss: 7.285934
[INFO] 2021-07-12 19:28:52,416 [run_pretraining.py:  512]:	********exe.run_2814******* 
[INFO] 2021-07-12 19:28:53,348 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:53,349 [run_pretraining.py:  534]:	loss/total_loss, 7.29994010925293, 2815
[INFO] 2021-07-12 19:28:53,349 [run_pretraining.py:  535]:	loss/mlm_loss, 7.29994010925293, 2815
[INFO] 2021-07-12 19:28:53,349 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8139998903498054e-05, 2815
[INFO] 2021-07-12 19:28:53,349 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2815
[INFO] 2021-07-12 19:28:53,349 [run_pretraining.py:  558]:	worker_index: 6, step: 2815, cost: 7.299940, mlm loss: 7.299940, speed: 1.071734 steps/s, speed: 8.573870 samples/s, speed: 4389.821461 tokens/s, learning rate: 2.814e-05, loss_scalings: 2814.750488, pp_loss: 7.070178
[INFO] 2021-07-12 19:28:53,349 [run_pretraining.py:  512]:	********exe.run_2815******* 
[INFO] 2021-07-12 19:28:54,263 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:54,264 [run_pretraining.py:  534]:	loss/total_loss, 7.309834003448486, 2816
[INFO] 2021-07-12 19:28:54,264 [run_pretraining.py:  535]:	loss/mlm_loss, 7.309834003448486, 2816
[INFO] 2021-07-12 19:28:54,264 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.814999970723875e-05, 2816
[INFO] 2021-07-12 19:28:54,264 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2816
[INFO] 2021-07-12 19:28:54,264 [run_pretraining.py:  558]:	worker_index: 6, step: 2816, cost: 7.309834, mlm loss: 7.309834, speed: 1.094132 steps/s, speed: 8.753059 samples/s, speed: 4481.566271 tokens/s, learning rate: 2.815e-05, loss_scalings: 2814.750488, pp_loss: 7.249136
[INFO] 2021-07-12 19:28:54,264 [run_pretraining.py:  512]:	********exe.run_2816******* 
[INFO] 2021-07-12 19:28:55,185 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:55,185 [run_pretraining.py:  534]:	loss/total_loss, 8.141094207763672, 2817
[INFO] 2021-07-12 19:28:55,185 [run_pretraining.py:  535]:	loss/mlm_loss, 8.141094207763672, 2817
[INFO] 2021-07-12 19:28:55,186 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.815999869199004e-05, 2817
[INFO] 2021-07-12 19:28:55,186 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2817
[INFO] 2021-07-12 19:28:55,186 [run_pretraining.py:  558]:	worker_index: 6, step: 2817, cost: 8.141094, mlm loss: 8.141094, speed: 1.085627 steps/s, speed: 8.685017 samples/s, speed: 4446.728584 tokens/s, learning rate: 2.816e-05, loss_scalings: 2814.750488, pp_loss: 7.736368
[INFO] 2021-07-12 19:28:55,186 [run_pretraining.py:  512]:	********exe.run_2817******* 
[INFO] 2021-07-12 19:28:56,097 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:56,098 [run_pretraining.py:  534]:	loss/total_loss, 7.400162696838379, 2818
[INFO] 2021-07-12 19:28:56,098 [run_pretraining.py:  535]:	loss/mlm_loss, 7.400162696838379, 2818
[INFO] 2021-07-12 19:28:56,098 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8169997676741332e-05, 2818
[INFO] 2021-07-12 19:28:56,098 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2818
[INFO] 2021-07-12 19:28:56,098 [run_pretraining.py:  558]:	worker_index: 6, step: 2818, cost: 7.400163, mlm loss: 7.400163, speed: 1.096884 steps/s, speed: 8.775071 samples/s, speed: 4492.836299 tokens/s, learning rate: 2.817e-05, loss_scalings: 2814.750488, pp_loss: 6.478254
[INFO] 2021-07-12 19:28:56,098 [run_pretraining.py:  512]:	********exe.run_2818******* 
[INFO] 2021-07-12 19:28:57,013 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:57,013 [run_pretraining.py:  534]:	loss/total_loss, 7.347659111022949, 2819
[INFO] 2021-07-12 19:28:57,013 [run_pretraining.py:  535]:	loss/mlm_loss, 7.347659111022949, 2819
[INFO] 2021-07-12 19:28:57,013 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.818000029947143e-05, 2819
[INFO] 2021-07-12 19:28:57,014 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2819
[INFO] 2021-07-12 19:28:57,014 [run_pretraining.py:  558]:	worker_index: 6, step: 2819, cost: 7.347659, mlm loss: 7.347659, speed: 1.093095 steps/s, speed: 8.744763 samples/s, speed: 4477.318400 tokens/s, learning rate: 2.818e-05, loss_scalings: 2814.750488, pp_loss: 7.549676
[INFO] 2021-07-12 19:28:57,014 [run_pretraining.py:  512]:	********exe.run_2819******* 
[INFO] 2021-07-12 19:28:57,939 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:57,940 [run_pretraining.py:  534]:	loss/total_loss, 6.71806526184082, 2820
[INFO] 2021-07-12 19:28:57,940 [run_pretraining.py:  535]:	loss/mlm_loss, 6.71806526184082, 2820
[INFO] 2021-07-12 19:28:57,940 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.818999746523332e-05, 2820
[INFO] 2021-07-12 19:28:57,940 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2820
[INFO] 2021-07-12 19:28:57,940 [run_pretraining.py:  558]:	worker_index: 6, step: 2820, cost: 6.718065, mlm loss: 6.718065, speed: 1.080282 steps/s, speed: 8.642258 samples/s, speed: 4424.836240 tokens/s, learning rate: 2.819e-05, loss_scalings: 2814.750488, pp_loss: 7.435115
[INFO] 2021-07-12 19:28:57,940 [run_pretraining.py:  512]:	********exe.run_2820******* 
[INFO] 2021-07-12 19:28:58,853 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:58,854 [run_pretraining.py:  534]:	loss/total_loss, 5.4619951248168945, 2821
[INFO] 2021-07-12 19:28:58,854 [run_pretraining.py:  535]:	loss/mlm_loss, 5.4619951248168945, 2821
[INFO] 2021-07-12 19:28:58,854 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8200000087963417e-05, 2821
[INFO] 2021-07-12 19:28:58,854 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2821
[INFO] 2021-07-12 19:28:58,854 [run_pretraining.py:  558]:	worker_index: 6, step: 2821, cost: 5.461995, mlm loss: 5.461995, speed: 1.094512 steps/s, speed: 8.756097 samples/s, speed: 4483.121671 tokens/s, learning rate: 2.820e-05, loss_scalings: 2814.750488, pp_loss: 6.636050
[INFO] 2021-07-12 19:28:58,854 [run_pretraining.py:  512]:	********exe.run_2821******* 
[INFO] 2021-07-12 19:28:59,772 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:59,773 [run_pretraining.py:  534]:	loss/total_loss, 7.536018371582031, 2822
[INFO] 2021-07-12 19:28:59,773 [run_pretraining.py:  535]:	loss/mlm_loss, 7.536018371582031, 2822
[INFO] 2021-07-12 19:28:59,773 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.820999907271471e-05, 2822
[INFO] 2021-07-12 19:28:59,773 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2822
[INFO] 2021-07-12 19:28:59,773 [run_pretraining.py:  558]:	worker_index: 6, step: 2822, cost: 7.536018, mlm loss: 7.536018, speed: 1.089271 steps/s, speed: 8.714167 samples/s, speed: 4461.653557 tokens/s, learning rate: 2.821e-05, loss_scalings: 2814.750488, pp_loss: 7.228193
[INFO] 2021-07-12 19:28:59,773 [run_pretraining.py:  512]:	********exe.run_2822******* 
[INFO] 2021-07-12 19:29:00,683 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:00,684 [run_pretraining.py:  534]:	loss/total_loss, 7.789080619812012, 2823
[INFO] 2021-07-12 19:29:00,684 [run_pretraining.py:  535]:	loss/mlm_loss, 7.789080619812012, 2823
[INFO] 2021-07-12 19:29:00,684 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8219999876455404e-05, 2823
[INFO] 2021-07-12 19:29:00,684 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2823
[INFO] 2021-07-12 19:29:00,684 [run_pretraining.py:  558]:	worker_index: 6, step: 2823, cost: 7.789081, mlm loss: 7.789081, speed: 1.098774 steps/s, speed: 8.790195 samples/s, speed: 4500.579653 tokens/s, learning rate: 2.822e-05, loss_scalings: 2814.750488, pp_loss: 7.182635
[INFO] 2021-07-12 19:29:00,684 [run_pretraining.py:  512]:	********exe.run_2823******* 
[INFO] 2021-07-12 19:29:01,594 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:01,595 [run_pretraining.py:  534]:	loss/total_loss, 7.23533296585083, 2824
[INFO] 2021-07-12 19:29:01,595 [run_pretraining.py:  535]:	loss/mlm_loss, 7.23533296585083, 2824
[INFO] 2021-07-12 19:29:01,595 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8229998861206695e-05, 2824
[INFO] 2021-07-12 19:29:01,595 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2824
[INFO] 2021-07-12 19:29:01,595 [run_pretraining.py:  558]:	worker_index: 6, step: 2824, cost: 7.235333, mlm loss: 7.235333, speed: 1.098437 steps/s, speed: 8.787497 samples/s, speed: 4499.198279 tokens/s, learning rate: 2.823e-05, loss_scalings: 2814.750488, pp_loss: 7.378274
[INFO] 2021-07-12 19:29:01,595 [run_pretraining.py:  512]:	********exe.run_2824******* 
[INFO] 2021-07-12 19:29:02,505 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:02,506 [run_pretraining.py:  534]:	loss/total_loss, 6.921170234680176, 2825
[INFO] 2021-07-12 19:29:02,506 [run_pretraining.py:  535]:	loss/mlm_loss, 6.921170234680176, 2825
[INFO] 2021-07-12 19:29:02,506 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.823999966494739e-05, 2825
[INFO] 2021-07-12 19:29:02,506 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2825
[INFO] 2021-07-12 19:29:02,506 [run_pretraining.py:  558]:	worker_index: 6, step: 2825, cost: 6.921170, mlm loss: 6.921170, speed: 1.098504 steps/s, speed: 8.788031 samples/s, speed: 4499.471657 tokens/s, learning rate: 2.824e-05, loss_scalings: 2814.750488, pp_loss: 7.088856
[INFO] 2021-07-12 19:29:02,506 [run_pretraining.py:  512]:	********exe.run_2825******* 
[INFO] 2021-07-12 19:29:03,412 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:03,413 [run_pretraining.py:  534]:	loss/total_loss, 7.495343208312988, 2826
[INFO] 2021-07-12 19:29:03,413 [run_pretraining.py:  535]:	loss/mlm_loss, 7.495343208312988, 2826
[INFO] 2021-07-12 19:29:03,413 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8249998649698682e-05, 2826
[INFO] 2021-07-12 19:29:03,413 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2826
[INFO] 2021-07-12 19:29:03,413 [run_pretraining.py:  558]:	worker_index: 6, step: 2826, cost: 7.495343, mlm loss: 7.495343, speed: 1.103007 steps/s, speed: 8.824055 samples/s, speed: 4517.916300 tokens/s, learning rate: 2.825e-05, loss_scalings: 2814.750488, pp_loss: 7.297618
[INFO] 2021-07-12 19:29:03,414 [run_pretraining.py:  512]:	********exe.run_2826******* 
[INFO] 2021-07-12 19:29:04,328 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:04,328 [run_pretraining.py:  534]:	loss/total_loss, 7.2582902908325195, 2827
[INFO] 2021-07-12 19:29:04,328 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2582902908325195, 2827
[INFO] 2021-07-12 19:29:04,328 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8259997634449974e-05, 2827
[INFO] 2021-07-12 19:29:04,328 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2827
[INFO] 2021-07-12 19:29:04,329 [run_pretraining.py:  558]:	worker_index: 6, step: 2827, cost: 7.258290, mlm loss: 7.258290, speed: 1.093609 steps/s, speed: 8.748871 samples/s, speed: 4479.422057 tokens/s, learning rate: 2.826e-05, loss_scalings: 2814.750488, pp_loss: 7.271590
[INFO] 2021-07-12 19:29:04,329 [run_pretraining.py:  512]:	********exe.run_2827******* 
[INFO] 2021-07-12 19:29:05,243 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:05,243 [run_pretraining.py:  534]:	loss/total_loss, 7.628247261047363, 2828
[INFO] 2021-07-12 19:29:05,244 [run_pretraining.py:  535]:	loss/mlm_loss, 7.628247261047363, 2828
[INFO] 2021-07-12 19:29:05,244 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8270000257180072e-05, 2828
[INFO] 2021-07-12 19:29:05,244 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2828
[INFO] 2021-07-12 19:29:05,244 [run_pretraining.py:  558]:	worker_index: 6, step: 2828, cost: 7.628247, mlm loss: 7.628247, speed: 1.093459 steps/s, speed: 8.747674 samples/s, speed: 4478.808968 tokens/s, learning rate: 2.827e-05, loss_scalings: 2814.750488, pp_loss: 7.361560
[INFO] 2021-07-12 19:29:05,244 [run_pretraining.py:  512]:	********exe.run_2828******* 
[INFO] 2021-07-12 19:29:06,162 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:06,163 [run_pretraining.py:  534]:	loss/total_loss, 6.557410717010498, 2829
[INFO] 2021-07-12 19:29:06,163 [run_pretraining.py:  535]:	loss/mlm_loss, 6.557410717010498, 2829
[INFO] 2021-07-12 19:29:06,163 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.827999742294196e-05, 2829
[INFO] 2021-07-12 19:29:06,163 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2829
[INFO] 2021-07-12 19:29:06,163 [run_pretraining.py:  558]:	worker_index: 6, step: 2829, cost: 6.557411, mlm loss: 6.557411, speed: 1.088630 steps/s, speed: 8.709042 samples/s, speed: 4459.029483 tokens/s, learning rate: 2.828e-05, loss_scalings: 2814.750488, pp_loss: 6.964107
[INFO] 2021-07-12 19:29:06,163 [run_pretraining.py:  512]:	********exe.run_2829******* 
[INFO] 2021-07-12 19:29:07,078 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:07,079 [run_pretraining.py:  534]:	loss/total_loss, 7.4732136726379395, 2830
[INFO] 2021-07-12 19:29:07,079 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4732136726379395, 2830
[INFO] 2021-07-12 19:29:07,079 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.829000004567206e-05, 2830
[INFO] 2021-07-12 19:29:07,079 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2830
[INFO] 2021-07-12 19:29:07,079 [run_pretraining.py:  558]:	worker_index: 6, step: 2830, cost: 7.473214, mlm loss: 7.473214, speed: 1.092742 steps/s, speed: 8.741937 samples/s, speed: 4475.871970 tokens/s, learning rate: 2.829e-05, loss_scalings: 2814.750488, pp_loss: 7.308862
[INFO] 2021-07-12 19:29:07,079 [run_pretraining.py:  512]:	********exe.run_2830******* 
[INFO] 2021-07-12 19:29:08,016 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:08,017 [run_pretraining.py:  534]:	loss/total_loss, 7.138298034667969, 2831
[INFO] 2021-07-12 19:29:08,017 [run_pretraining.py:  535]:	loss/mlm_loss, 7.138298034667969, 2831
[INFO] 2021-07-12 19:29:08,017 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.829999903042335e-05, 2831
[INFO] 2021-07-12 19:29:08,017 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2831
[INFO] 2021-07-12 19:29:08,017 [run_pretraining.py:  558]:	worker_index: 6, step: 2831, cost: 7.138298, mlm loss: 7.138298, speed: 1.066516 steps/s, speed: 8.532131 samples/s, speed: 4368.451198 tokens/s, learning rate: 2.830e-05, loss_scalings: 2814.750488, pp_loss: 7.222914
[INFO] 2021-07-12 19:29:08,017 [run_pretraining.py:  512]:	********exe.run_2831******* 
[INFO] 2021-07-12 19:29:09,081 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:09,081 [run_pretraining.py:  534]:	loss/total_loss, 8.381930351257324, 2832
[INFO] 2021-07-12 19:29:09,081 [run_pretraining.py:  535]:	loss/mlm_loss, 8.381930351257324, 2832
[INFO] 2021-07-12 19:29:09,081 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8309999834164046e-05, 2832
[INFO] 2021-07-12 19:29:09,082 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2832
[INFO] 2021-07-12 19:29:09,082 [run_pretraining.py:  558]:	worker_index: 6, step: 2832, cost: 8.381930, mlm loss: 8.381930, speed: 0.940154 steps/s, speed: 7.521230 samples/s, speed: 3850.869609 tokens/s, learning rate: 2.831e-05, loss_scalings: 2814.750488, pp_loss: 7.575223
[INFO] 2021-07-12 19:29:09,082 [run_pretraining.py:  512]:	********exe.run_2832******* 
[INFO] 2021-07-12 19:29:10,140 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:10,140 [run_pretraining.py:  534]:	loss/total_loss, 6.852163791656494, 2833
[INFO] 2021-07-12 19:29:10,141 [run_pretraining.py:  535]:	loss/mlm_loss, 6.852163791656494, 2833
[INFO] 2021-07-12 19:29:10,141 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8319998818915337e-05, 2833
[INFO] 2021-07-12 19:29:10,141 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2833
[INFO] 2021-07-12 19:29:10,141 [run_pretraining.py:  558]:	worker_index: 6, step: 2833, cost: 6.852164, mlm loss: 6.852164, speed: 0.944826 steps/s, speed: 7.558607 samples/s, speed: 3870.006698 tokens/s, learning rate: 2.832e-05, loss_scalings: 2814.750488, pp_loss: 7.330669
[INFO] 2021-07-12 19:29:10,141 [run_pretraining.py:  512]:	********exe.run_2833******* 
[INFO] 2021-07-12 19:29:11,201 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:11,201 [run_pretraining.py:  534]:	loss/total_loss, 7.94294548034668, 2834
[INFO] 2021-07-12 19:29:11,201 [run_pretraining.py:  535]:	loss/mlm_loss, 7.94294548034668, 2834
[INFO] 2021-07-12 19:29:11,201 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8329999622656032e-05, 2834
[INFO] 2021-07-12 19:29:11,201 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2834
[INFO] 2021-07-12 19:29:11,202 [run_pretraining.py:  558]:	worker_index: 6, step: 2834, cost: 7.942945, mlm loss: 7.942945, speed: 0.943371 steps/s, speed: 7.546972 samples/s, speed: 3864.049466 tokens/s, learning rate: 2.833e-05, loss_scalings: 2814.750488, pp_loss: 7.530046
[INFO] 2021-07-12 19:29:11,202 [run_pretraining.py:  512]:	********exe.run_2834******* 
[INFO] 2021-07-12 19:29:12,266 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:12,266 [run_pretraining.py:  534]:	loss/total_loss, 7.0917768478393555, 2835
[INFO] 2021-07-12 19:29:12,267 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0917768478393555, 2835
[INFO] 2021-07-12 19:29:12,267 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8339998607407324e-05, 2835
[INFO] 2021-07-12 19:29:12,267 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2835
[INFO] 2021-07-12 19:29:12,267 [run_pretraining.py:  558]:	worker_index: 6, step: 2835, cost: 7.091777, mlm loss: 7.091777, speed: 0.939389 steps/s, speed: 7.515115 samples/s, speed: 3847.738839 tokens/s, learning rate: 2.834e-05, loss_scalings: 2814.750488, pp_loss: 7.287443
[INFO] 2021-07-12 19:29:12,267 [run_pretraining.py:  512]:	********exe.run_2835******* 
[INFO] 2021-07-12 19:29:13,310 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:13,311 [run_pretraining.py:  534]:	loss/total_loss, 7.136844635009766, 2836
[INFO] 2021-07-12 19:29:13,311 [run_pretraining.py:  535]:	loss/mlm_loss, 7.136844635009766, 2836
[INFO] 2021-07-12 19:29:13,311 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8349997592158616e-05, 2836
[INFO] 2021-07-12 19:29:13,311 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2836
[INFO] 2021-07-12 19:29:13,311 [run_pretraining.py:  558]:	worker_index: 6, step: 2836, cost: 7.136845, mlm loss: 7.136845, speed: 0.958189 steps/s, speed: 7.665514 samples/s, speed: 3924.743315 tokens/s, learning rate: 2.835e-05, loss_scalings: 2814.750488, pp_loss: 7.059450
[INFO] 2021-07-12 19:29:13,311 [run_pretraining.py:  512]:	********exe.run_2836******* 
[INFO] 2021-07-12 19:29:14,372 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:14,373 [run_pretraining.py:  534]:	loss/total_loss, 6.938668251037598, 2837
[INFO] 2021-07-12 19:29:14,373 [run_pretraining.py:  535]:	loss/mlm_loss, 6.938668251037598, 2837
[INFO] 2021-07-12 19:29:14,373 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8360000214888714e-05, 2837
[INFO] 2021-07-12 19:29:14,373 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2837
[INFO] 2021-07-12 19:29:14,373 [run_pretraining.py:  558]:	worker_index: 6, step: 2837, cost: 6.938668, mlm loss: 6.938668, speed: 0.942226 steps/s, speed: 7.537805 samples/s, speed: 3859.355996 tokens/s, learning rate: 2.836e-05, loss_scalings: 2814.750488, pp_loss: 7.180955
[INFO] 2021-07-12 19:29:14,373 [run_pretraining.py:  512]:	********exe.run_2837******* 
[INFO] 2021-07-12 19:29:15,427 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:15,428 [run_pretraining.py:  534]:	loss/total_loss, 6.980545520782471, 2838
[INFO] 2021-07-12 19:29:15,428 [run_pretraining.py:  535]:	loss/mlm_loss, 6.980545520782471, 2838
[INFO] 2021-07-12 19:29:15,428 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8369997380650602e-05, 2838
[INFO] 2021-07-12 19:29:15,428 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2838
[INFO] 2021-07-12 19:29:15,428 [run_pretraining.py:  558]:	worker_index: 6, step: 2838, cost: 6.980546, mlm loss: 6.980546, speed: 0.948419 steps/s, speed: 7.587353 samples/s, speed: 3884.724816 tokens/s, learning rate: 2.837e-05, loss_scalings: 2814.750488, pp_loss: 6.473451
[INFO] 2021-07-12 19:29:15,428 [run_pretraining.py:  512]:	********exe.run_2838******* 
[INFO] 2021-07-12 19:29:16,506 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:16,507 [run_pretraining.py:  534]:	loss/total_loss, 7.2368011474609375, 2839
[INFO] 2021-07-12 19:29:16,507 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2368011474609375, 2839
[INFO] 2021-07-12 19:29:16,507 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.83800000033807e-05, 2839
[INFO] 2021-07-12 19:29:16,507 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2839
[INFO] 2021-07-12 19:29:16,507 [run_pretraining.py:  558]:	worker_index: 6, step: 2839, cost: 7.236801, mlm loss: 7.236801, speed: 0.927552 steps/s, speed: 7.420413 samples/s, speed: 3799.251419 tokens/s, learning rate: 2.838e-05, loss_scalings: 2814.750488, pp_loss: 7.208274
[INFO] 2021-07-12 19:29:16,507 [run_pretraining.py:  512]:	********exe.run_2839******* 
[INFO] 2021-07-12 19:29:17,570 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:17,571 [run_pretraining.py:  534]:	loss/total_loss, 6.677695274353027, 2840
[INFO] 2021-07-12 19:29:17,571 [run_pretraining.py:  535]:	loss/mlm_loss, 6.677695274353027, 2840
[INFO] 2021-07-12 19:29:17,571 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8389998988131993e-05, 2840
[INFO] 2021-07-12 19:29:17,571 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2840
[INFO] 2021-07-12 19:29:17,571 [run_pretraining.py:  558]:	worker_index: 6, step: 2840, cost: 6.677695, mlm loss: 6.677695, speed: 0.940138 steps/s, speed: 7.521105 samples/s, speed: 3850.805735 tokens/s, learning rate: 2.839e-05, loss_scalings: 2814.750488, pp_loss: 7.285372
[INFO] 2021-07-12 19:29:17,571 [run_pretraining.py:  512]:	********exe.run_2840******* 
[INFO] 2021-07-12 19:29:18,626 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:18,626 [run_pretraining.py:  534]:	loss/total_loss, 4.227635860443115, 2841
[INFO] 2021-07-12 19:29:18,626 [run_pretraining.py:  535]:	loss/mlm_loss, 4.227635860443115, 2841
[INFO] 2021-07-12 19:29:18,626 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8399999791872688e-05, 2841
[INFO] 2021-07-12 19:29:18,627 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2841
[INFO] 2021-07-12 19:29:18,627 [run_pretraining.py:  558]:	worker_index: 6, step: 2841, cost: 4.227636, mlm loss: 4.227636, speed: 0.948260 steps/s, speed: 7.586077 samples/s, speed: 3884.071384 tokens/s, learning rate: 2.840e-05, loss_scalings: 2814.750488, pp_loss: 6.587149
[INFO] 2021-07-12 19:29:18,627 [run_pretraining.py:  512]:	********exe.run_2841******* 
[INFO] 2021-07-12 19:29:19,702 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:19,702 [run_pretraining.py:  534]:	loss/total_loss, 6.47969388961792, 2842
[INFO] 2021-07-12 19:29:19,702 [run_pretraining.py:  535]:	loss/mlm_loss, 6.47969388961792, 2842
[INFO] 2021-07-12 19:29:19,702 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.840999877662398e-05, 2842
[INFO] 2021-07-12 19:29:19,702 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2842
[INFO] 2021-07-12 19:29:19,703 [run_pretraining.py:  558]:	worker_index: 6, step: 2842, cost: 6.479694, mlm loss: 6.479694, speed: 0.930068 steps/s, speed: 7.440545 samples/s, speed: 3809.559002 tokens/s, learning rate: 2.841e-05, loss_scalings: 2814.750488, pp_loss: 6.209296
[INFO] 2021-07-12 19:29:19,703 [run_pretraining.py:  512]:	********exe.run_2842******* 
[INFO] 2021-07-12 19:29:20,629 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:20,629 [run_pretraining.py:  534]:	loss/total_loss, 7.5421648025512695, 2843
[INFO] 2021-07-12 19:29:20,629 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5421648025512695, 2843
[INFO] 2021-07-12 19:29:20,629 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8420001399354078e-05, 2843
[INFO] 2021-07-12 19:29:20,629 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2843
[INFO] 2021-07-12 19:29:20,630 [run_pretraining.py:  558]:	worker_index: 6, step: 2843, cost: 7.542165, mlm loss: 7.542165, speed: 1.079665 steps/s, speed: 8.637317 samples/s, speed: 4422.306506 tokens/s, learning rate: 2.842e-05, loss_scalings: 2814.750488, pp_loss: 7.300032
[INFO] 2021-07-12 19:29:20,630 [run_pretraining.py:  512]:	********exe.run_2843******* 
[INFO] 2021-07-12 19:29:21,547 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:21,548 [run_pretraining.py:  534]:	loss/total_loss, 6.836524486541748, 2844
[INFO] 2021-07-12 19:29:21,548 [run_pretraining.py:  535]:	loss/mlm_loss, 6.836524486541748, 2844
[INFO] 2021-07-12 19:29:21,548 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8429998565115966e-05, 2844
[INFO] 2021-07-12 19:29:21,548 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2844
[INFO] 2021-07-12 19:29:21,548 [run_pretraining.py:  558]:	worker_index: 6, step: 2844, cost: 6.836524, mlm loss: 6.836524, speed: 1.089421 steps/s, speed: 8.715371 samples/s, speed: 4462.270072 tokens/s, learning rate: 2.843e-05, loss_scalings: 2814.750488, pp_loss: 7.211968
[INFO] 2021-07-12 19:29:21,548 [run_pretraining.py:  512]:	********exe.run_2844******* 
[INFO] 2021-07-12 19:29:22,476 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:22,477 [run_pretraining.py:  534]:	loss/total_loss, 7.0041961669921875, 2845
[INFO] 2021-07-12 19:29:22,477 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0041961669921875, 2845
[INFO] 2021-07-12 19:29:22,477 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8439997549867257e-05, 2845
[INFO] 2021-07-12 19:29:22,477 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2845
[INFO] 2021-07-12 19:29:22,477 [run_pretraining.py:  558]:	worker_index: 6, step: 2845, cost: 7.004196, mlm loss: 7.004196, speed: 1.077155 steps/s, speed: 8.617236 samples/s, speed: 4412.024936 tokens/s, learning rate: 2.844e-05, loss_scalings: 2814.750488, pp_loss: 6.930903
[INFO] 2021-07-12 19:29:22,477 [run_pretraining.py:  512]:	********exe.run_2845******* 
[INFO] 2021-07-12 19:29:23,403 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:23,404 [run_pretraining.py:  534]:	loss/total_loss, 7.786238670349121, 2846
[INFO] 2021-07-12 19:29:23,404 [run_pretraining.py:  535]:	loss/mlm_loss, 7.786238670349121, 2846
[INFO] 2021-07-12 19:29:23,404 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8450000172597356e-05, 2846
[INFO] 2021-07-12 19:29:23,404 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2846
[INFO] 2021-07-12 19:29:23,404 [run_pretraining.py:  558]:	worker_index: 6, step: 2846, cost: 7.786239, mlm loss: 7.786239, speed: 1.079431 steps/s, speed: 8.635448 samples/s, speed: 4421.349357 tokens/s, learning rate: 2.845e-05, loss_scalings: 2814.750488, pp_loss: 7.665872
[INFO] 2021-07-12 19:29:23,404 [run_pretraining.py:  512]:	********exe.run_2846******* 
[INFO] 2021-07-12 19:29:24,321 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:24,322 [run_pretraining.py:  534]:	loss/total_loss, 7.407249450683594, 2847
[INFO] 2021-07-12 19:29:24,322 [run_pretraining.py:  535]:	loss/mlm_loss, 7.407249450683594, 2847
[INFO] 2021-07-12 19:29:24,322 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8459997338359244e-05, 2847
[INFO] 2021-07-12 19:29:24,322 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2847
[INFO] 2021-07-12 19:29:24,322 [run_pretraining.py:  558]:	worker_index: 6, step: 2847, cost: 7.407249, mlm loss: 7.407249, speed: 1.090392 steps/s, speed: 8.723136 samples/s, speed: 4466.245581 tokens/s, learning rate: 2.846e-05, loss_scalings: 2814.750488, pp_loss: 7.181608
[INFO] 2021-07-12 19:29:24,322 [run_pretraining.py:  512]:	********exe.run_2847******* 
[INFO] 2021-07-12 19:29:25,375 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:25,375 [run_pretraining.py:  534]:	loss/total_loss, 6.584174633026123, 2848
[INFO] 2021-07-12 19:29:25,375 [run_pretraining.py:  535]:	loss/mlm_loss, 6.584174633026123, 2848
[INFO] 2021-07-12 19:29:25,375 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8469999961089343e-05, 2848
[INFO] 2021-07-12 19:29:25,375 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2848
[INFO] 2021-07-12 19:29:25,376 [run_pretraining.py:  558]:	worker_index: 6, step: 2848, cost: 6.584175, mlm loss: 6.584175, speed: 0.949984 steps/s, speed: 7.599869 samples/s, speed: 3891.132880 tokens/s, learning rate: 2.847e-05, loss_scalings: 2814.750488, pp_loss: 6.141699
[INFO] 2021-07-12 19:29:25,376 [run_pretraining.py:  512]:	********exe.run_2848******* 
[INFO] 2021-07-12 19:29:26,288 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:26,288 [run_pretraining.py:  534]:	loss/total_loss, 7.421525955200195, 2849
[INFO] 2021-07-12 19:29:26,289 [run_pretraining.py:  535]:	loss/mlm_loss, 7.421525955200195, 2849
[INFO] 2021-07-12 19:29:26,289 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8479998945840634e-05, 2849
[INFO] 2021-07-12 19:29:26,289 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2849
[INFO] 2021-07-12 19:29:26,289 [run_pretraining.py:  558]:	worker_index: 6, step: 2849, cost: 7.421526, mlm loss: 7.421526, speed: 1.095856 steps/s, speed: 8.766845 samples/s, speed: 4488.624512 tokens/s, learning rate: 2.848e-05, loss_scalings: 2814.750488, pp_loss: 7.255714
[INFO] 2021-07-12 19:29:26,289 [run_pretraining.py:  512]:	********exe.run_2849******* 
[INFO] 2021-07-12 19:29:27,207 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:27,207 [run_pretraining.py:  534]:	loss/total_loss, 7.166219711303711, 2850
[INFO] 2021-07-12 19:29:27,207 [run_pretraining.py:  535]:	loss/mlm_loss, 7.166219711303711, 2850
[INFO] 2021-07-12 19:29:27,207 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.848999974958133e-05, 2850
[INFO] 2021-07-12 19:29:27,208 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2850
[INFO] 2021-07-12 19:29:27,208 [run_pretraining.py:  558]:	worker_index: 6, step: 2850, cost: 7.166220, mlm loss: 7.166220, speed: 1.089232 steps/s, speed: 8.713855 samples/s, speed: 4461.493662 tokens/s, learning rate: 2.849e-05, loss_scalings: 2814.750488, pp_loss: 7.544080
[INFO] 2021-07-12 19:29:27,208 [run_pretraining.py:  512]:	********exe.run_2850******* 
[INFO] 2021-07-12 19:29:28,126 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:28,127 [run_pretraining.py:  534]:	loss/total_loss, 6.980879783630371, 2851
[INFO] 2021-07-12 19:29:28,127 [run_pretraining.py:  535]:	loss/mlm_loss, 6.980879783630371, 2851
[INFO] 2021-07-12 19:29:28,127 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.849999873433262e-05, 2851
[INFO] 2021-07-12 19:29:28,127 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2851
[INFO] 2021-07-12 19:29:28,127 [run_pretraining.py:  558]:	worker_index: 6, step: 2851, cost: 6.980880, mlm loss: 6.980880, speed: 1.088142 steps/s, speed: 8.705138 samples/s, speed: 4457.030496 tokens/s, learning rate: 2.850e-05, loss_scalings: 2814.750488, pp_loss: 7.171092
[INFO] 2021-07-12 19:29:28,127 [run_pretraining.py:  512]:	********exe.run_2851******* 
[INFO] 2021-07-12 19:29:29,045 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:29,046 [run_pretraining.py:  534]:	loss/total_loss, 7.5843377113342285, 2852
[INFO] 2021-07-12 19:29:29,046 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5843377113342285, 2852
[INFO] 2021-07-12 19:29:29,046 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.851000135706272e-05, 2852
[INFO] 2021-07-12 19:29:29,046 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2852
[INFO] 2021-07-12 19:29:29,046 [run_pretraining.py:  558]:	worker_index: 6, step: 2852, cost: 7.584338, mlm loss: 7.584338, speed: 1.089075 steps/s, speed: 8.712599 samples/s, speed: 4460.850721 tokens/s, learning rate: 2.851e-05, loss_scalings: 2814.750488, pp_loss: 7.286613
[INFO] 2021-07-12 19:29:29,046 [run_pretraining.py:  512]:	********exe.run_2852******* 
[INFO] 2021-07-12 19:29:30,076 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:30,077 [run_pretraining.py:  534]:	loss/total_loss, 7.451920509338379, 2853
[INFO] 2021-07-12 19:29:30,077 [run_pretraining.py:  535]:	loss/mlm_loss, 7.451920509338379, 2853
[INFO] 2021-07-12 19:29:30,077 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8519998522824608e-05, 2853
[INFO] 2021-07-12 19:29:30,077 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2853
[INFO] 2021-07-12 19:29:30,077 [run_pretraining.py:  558]:	worker_index: 6, step: 2853, cost: 7.451921, mlm loss: 7.451921, speed: 0.970873 steps/s, speed: 7.766983 samples/s, speed: 3976.695458 tokens/s, learning rate: 2.852e-05, loss_scalings: 2814.750488, pp_loss: 7.385765
[INFO] 2021-07-12 19:29:30,077 [run_pretraining.py:  512]:	********exe.run_2853******* 
[INFO] 2021-07-12 19:29:31,133 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:31,134 [run_pretraining.py:  534]:	loss/total_loss, 7.536079406738281, 2854
[INFO] 2021-07-12 19:29:31,134 [run_pretraining.py:  535]:	loss/mlm_loss, 7.536079406738281, 2854
[INFO] 2021-07-12 19:29:31,134 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.85299975075759e-05, 2854
[INFO] 2021-07-12 19:29:31,134 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2854
[INFO] 2021-07-12 19:29:31,134 [run_pretraining.py:  558]:	worker_index: 6, step: 2854, cost: 7.536079, mlm loss: 7.536079, speed: 0.946575 steps/s, speed: 7.572603 samples/s, speed: 3877.172843 tokens/s, learning rate: 2.853e-05, loss_scalings: 2814.750488, pp_loss: 7.196210
[INFO] 2021-07-12 19:29:31,134 [run_pretraining.py:  512]:	********exe.run_2854******* 
[INFO] 2021-07-12 19:29:32,194 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:32,195 [run_pretraining.py:  534]:	loss/total_loss, 7.709249496459961, 2855
[INFO] 2021-07-12 19:29:32,195 [run_pretraining.py:  535]:	loss/mlm_loss, 7.709249496459961, 2855
[INFO] 2021-07-12 19:29:32,195 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8540000130305998e-05, 2855
[INFO] 2021-07-12 19:29:32,195 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2855
[INFO] 2021-07-12 19:29:32,195 [run_pretraining.py:  558]:	worker_index: 6, step: 2855, cost: 7.709249, mlm loss: 7.709249, speed: 0.943132 steps/s, speed: 7.545059 samples/s, speed: 3863.070248 tokens/s, learning rate: 2.854e-05, loss_scalings: 2814.750488, pp_loss: 7.539350
[INFO] 2021-07-12 19:29:32,195 [run_pretraining.py:  512]:	********exe.run_2855******* 
[INFO] 2021-07-12 19:29:33,272 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:33,272 [run_pretraining.py:  534]:	loss/total_loss, 7.306013107299805, 2856
[INFO] 2021-07-12 19:29:33,273 [run_pretraining.py:  535]:	loss/mlm_loss, 7.306013107299805, 2856
[INFO] 2021-07-12 19:29:33,273 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.854999911505729e-05, 2856
[INFO] 2021-07-12 19:29:33,273 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2856
[INFO] 2021-07-12 19:29:33,273 [run_pretraining.py:  558]:	worker_index: 6, step: 2856, cost: 7.306013, mlm loss: 7.306013, speed: 0.928535 steps/s, speed: 7.428283 samples/s, speed: 3803.281027 tokens/s, learning rate: 2.855e-05, loss_scalings: 2814.750488, pp_loss: 7.510677
[INFO] 2021-07-12 19:29:33,273 [run_pretraining.py:  512]:	********exe.run_2856******* 
[INFO] 2021-07-12 19:29:34,344 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:34,345 [run_pretraining.py:  534]:	loss/total_loss, 7.854079246520996, 2857
[INFO] 2021-07-12 19:29:34,345 [run_pretraining.py:  535]:	loss/mlm_loss, 7.854079246520996, 2857
[INFO] 2021-07-12 19:29:34,345 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8559999918797985e-05, 2857
[INFO] 2021-07-12 19:29:34,345 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2857
[INFO] 2021-07-12 19:29:34,345 [run_pretraining.py:  558]:	worker_index: 6, step: 2857, cost: 7.854079, mlm loss: 7.854079, speed: 0.933315 steps/s, speed: 7.466522 samples/s, speed: 3822.859446 tokens/s, learning rate: 2.856e-05, loss_scalings: 2814.750488, pp_loss: 7.322530
[INFO] 2021-07-12 19:29:34,345 [run_pretraining.py:  512]:	********exe.run_2857******* 
[INFO] 2021-07-12 19:29:35,406 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:35,407 [run_pretraining.py:  534]:	loss/total_loss, 7.592045783996582, 2858
[INFO] 2021-07-12 19:29:35,407 [run_pretraining.py:  535]:	loss/mlm_loss, 7.592045783996582, 2858
[INFO] 2021-07-12 19:29:35,407 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8569998903549276e-05, 2858
[INFO] 2021-07-12 19:29:35,407 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2858
[INFO] 2021-07-12 19:29:35,407 [run_pretraining.py:  558]:	worker_index: 6, step: 2858, cost: 7.592046, mlm loss: 7.592046, speed: 0.941825 steps/s, speed: 7.534599 samples/s, speed: 3857.714631 tokens/s, learning rate: 2.857e-05, loss_scalings: 2814.750488, pp_loss: 7.286438
[INFO] 2021-07-12 19:29:35,408 [run_pretraining.py:  512]:	********exe.run_2858******* 
[INFO] 2021-07-12 19:29:36,469 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:36,470 [run_pretraining.py:  534]:	loss/total_loss, 7.24751091003418, 2859
[INFO] 2021-07-12 19:29:36,470 [run_pretraining.py:  535]:	loss/mlm_loss, 7.24751091003418, 2859
[INFO] 2021-07-12 19:29:36,470 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.857999970728997e-05, 2859
[INFO] 2021-07-12 19:29:36,470 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2859
[INFO] 2021-07-12 19:29:36,470 [run_pretraining.py:  558]:	worker_index: 6, step: 2859, cost: 7.247511, mlm loss: 7.247511, speed: 0.941462 steps/s, speed: 7.531695 samples/s, speed: 3856.227863 tokens/s, learning rate: 2.858e-05, loss_scalings: 2814.750488, pp_loss: 6.982384
[INFO] 2021-07-12 19:29:36,470 [run_pretraining.py:  512]:	********exe.run_2859******* 
[INFO] 2021-07-12 19:29:37,526 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:37,527 [run_pretraining.py:  534]:	loss/total_loss, 7.295742034912109, 2860
[INFO] 2021-07-12 19:29:37,527 [run_pretraining.py:  535]:	loss/mlm_loss, 7.295742034912109, 2860
[INFO] 2021-07-12 19:29:37,527 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8589998692041263e-05, 2860
[INFO] 2021-07-12 19:29:37,527 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2860
[INFO] 2021-07-12 19:29:37,527 [run_pretraining.py:  558]:	worker_index: 6, step: 2860, cost: 7.295742, mlm loss: 7.295742, speed: 0.946770 steps/s, speed: 7.574160 samples/s, speed: 3877.970137 tokens/s, learning rate: 2.859e-05, loss_scalings: 2814.750488, pp_loss: 7.199400
[INFO] 2021-07-12 19:29:37,527 [run_pretraining.py:  512]:	********exe.run_2860******* 
[INFO] 2021-07-12 19:29:38,590 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:38,590 [run_pretraining.py:  534]:	loss/total_loss, 6.675333023071289, 2861
[INFO] 2021-07-12 19:29:38,590 [run_pretraining.py:  535]:	loss/mlm_loss, 6.675333023071289, 2861
[INFO] 2021-07-12 19:29:38,590 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.860000131477136e-05, 2861
[INFO] 2021-07-12 19:29:38,591 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2861
[INFO] 2021-07-12 19:29:38,591 [run_pretraining.py:  558]:	worker_index: 6, step: 2861, cost: 6.675333, mlm loss: 6.675333, speed: 0.941081 steps/s, speed: 7.528645 samples/s, speed: 3854.666130 tokens/s, learning rate: 2.860e-05, loss_scalings: 2814.750488, pp_loss: 7.011058
[INFO] 2021-07-12 19:29:38,591 [run_pretraining.py:  512]:	********exe.run_2861******* 
[INFO] 2021-07-12 19:29:39,520 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:39,521 [run_pretraining.py:  534]:	loss/total_loss, 7.542789936065674, 2862
[INFO] 2021-07-12 19:29:39,521 [run_pretraining.py:  535]:	loss/mlm_loss, 7.542789936065674, 2862
[INFO] 2021-07-12 19:29:39,521 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.860999848053325e-05, 2862
[INFO] 2021-07-12 19:29:39,521 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2862
[INFO] 2021-07-12 19:29:39,521 [run_pretraining.py:  558]:	worker_index: 6, step: 2862, cost: 7.542790, mlm loss: 7.542790, speed: 1.075394 steps/s, speed: 8.603149 samples/s, speed: 4404.812303 tokens/s, learning rate: 2.861e-05, loss_scalings: 2814.750488, pp_loss: 7.121346
[INFO] 2021-07-12 19:29:39,521 [run_pretraining.py:  512]:	********exe.run_2862******* 
[INFO] 2021-07-12 19:29:40,433 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:40,434 [run_pretraining.py:  534]:	loss/total_loss, 7.267207145690918, 2863
[INFO] 2021-07-12 19:29:40,434 [run_pretraining.py:  535]:	loss/mlm_loss, 7.267207145690918, 2863
[INFO] 2021-07-12 19:29:40,434 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.861999746528454e-05, 2863
[INFO] 2021-07-12 19:29:40,434 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2863
[INFO] 2021-07-12 19:29:40,434 [run_pretraining.py:  558]:	worker_index: 6, step: 2863, cost: 7.267207, mlm loss: 7.267207, speed: 1.095800 steps/s, speed: 8.766403 samples/s, speed: 4488.398182 tokens/s, learning rate: 2.862e-05, loss_scalings: 2814.750488, pp_loss: 7.141602
[INFO] 2021-07-12 19:29:40,435 [run_pretraining.py:  512]:	********exe.run_2863******* 
[INFO] 2021-07-12 19:29:41,339 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:41,340 [run_pretraining.py:  534]:	loss/total_loss, 6.910069465637207, 2864
[INFO] 2021-07-12 19:29:41,340 [run_pretraining.py:  535]:	loss/mlm_loss, 6.910069465637207, 2864
[INFO] 2021-07-12 19:29:41,340 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.863000008801464e-05, 2864
[INFO] 2021-07-12 19:29:41,340 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2864
[INFO] 2021-07-12 19:29:41,340 [run_pretraining.py:  558]:	worker_index: 6, step: 2864, cost: 6.910069, mlm loss: 6.910069, speed: 1.105286 steps/s, speed: 8.842286 samples/s, speed: 4527.250324 tokens/s, learning rate: 2.863e-05, loss_scalings: 2814.750488, pp_loss: 6.939795
[INFO] 2021-07-12 19:29:41,340 [run_pretraining.py:  512]:	********exe.run_2864******* 
[INFO] 2021-07-12 19:29:42,274 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:42,275 [run_pretraining.py:  534]:	loss/total_loss, 7.059769153594971, 2865
[INFO] 2021-07-12 19:29:42,275 [run_pretraining.py:  535]:	loss/mlm_loss, 7.059769153594971, 2865
[INFO] 2021-07-12 19:29:42,275 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.863999907276593e-05, 2865
[INFO] 2021-07-12 19:29:42,275 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2865
[INFO] 2021-07-12 19:29:42,275 [run_pretraining.py:  558]:	worker_index: 6, step: 2865, cost: 7.059769, mlm loss: 7.059769, speed: 1.070333 steps/s, speed: 8.562668 samples/s, speed: 4384.085898 tokens/s, learning rate: 2.864e-05, loss_scalings: 2814.750488, pp_loss: 7.227774
[INFO] 2021-07-12 19:29:42,275 [run_pretraining.py:  512]:	********exe.run_2865******* 
[INFO] 2021-07-12 19:29:43,175 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:43,176 [run_pretraining.py:  534]:	loss/total_loss, 7.580308437347412, 2866
[INFO] 2021-07-12 19:29:43,176 [run_pretraining.py:  535]:	loss/mlm_loss, 7.580308437347412, 2866
[INFO] 2021-07-12 19:29:43,176 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8649999876506627e-05, 2866
[INFO] 2021-07-12 19:29:43,176 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2866
[INFO] 2021-07-12 19:29:43,176 [run_pretraining.py:  558]:	worker_index: 6, step: 2866, cost: 7.580308, mlm loss: 7.580308, speed: 1.110287 steps/s, speed: 8.882297 samples/s, speed: 4547.736156 tokens/s, learning rate: 2.865e-05, loss_scalings: 2814.750488, pp_loss: 7.256264
[INFO] 2021-07-12 19:29:43,176 [run_pretraining.py:  512]:	********exe.run_2866******* 
[INFO] 2021-07-12 19:29:44,104 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:44,104 [run_pretraining.py:  534]:	loss/total_loss, 7.471958637237549, 2867
[INFO] 2021-07-12 19:29:44,104 [run_pretraining.py:  535]:	loss/mlm_loss, 7.471958637237549, 2867
[INFO] 2021-07-12 19:29:44,104 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8659998861257918e-05, 2867
[INFO] 2021-07-12 19:29:44,105 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2867
[INFO] 2021-07-12 19:29:44,105 [run_pretraining.py:  558]:	worker_index: 6, step: 2867, cost: 7.471959, mlm loss: 7.471959, speed: 1.077986 steps/s, speed: 8.623887 samples/s, speed: 4415.430166 tokens/s, learning rate: 2.866e-05, loss_scalings: 2814.750488, pp_loss: 5.820598
[INFO] 2021-07-12 19:29:44,105 [run_pretraining.py:  512]:	********exe.run_2867******* 
[INFO] 2021-07-12 19:29:45,025 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:45,026 [run_pretraining.py:  534]:	loss/total_loss, 7.214435577392578, 2868
[INFO] 2021-07-12 19:29:45,026 [run_pretraining.py:  535]:	loss/mlm_loss, 7.214435577392578, 2868
[INFO] 2021-07-12 19:29:45,026 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8669999664998613e-05, 2868
[INFO] 2021-07-12 19:29:45,026 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2868
[INFO] 2021-07-12 19:29:45,026 [run_pretraining.py:  558]:	worker_index: 6, step: 2868, cost: 7.214436, mlm loss: 7.214436, speed: 1.086275 steps/s, speed: 8.690204 samples/s, speed: 4449.384290 tokens/s, learning rate: 2.867e-05, loss_scalings: 2814.750488, pp_loss: 6.997717
[INFO] 2021-07-12 19:29:45,026 [run_pretraining.py:  512]:	********exe.run_2868******* 
[INFO] 2021-07-12 19:29:45,938 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:45,939 [run_pretraining.py:  534]:	loss/total_loss, 7.849590301513672, 2869
[INFO] 2021-07-12 19:29:45,939 [run_pretraining.py:  535]:	loss/mlm_loss, 7.849590301513672, 2869
[INFO] 2021-07-12 19:29:45,939 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8679998649749905e-05, 2869
[INFO] 2021-07-12 19:29:45,939 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2869
[INFO] 2021-07-12 19:29:45,939 [run_pretraining.py:  558]:	worker_index: 6, step: 2869, cost: 7.849590, mlm loss: 7.849590, speed: 1.095778 steps/s, speed: 8.766224 samples/s, speed: 4488.306718 tokens/s, learning rate: 2.868e-05, loss_scalings: 2814.750488, pp_loss: 7.558384
[INFO] 2021-07-12 19:29:45,939 [run_pretraining.py:  512]:	********exe.run_2869******* 
[INFO] 2021-07-12 19:29:46,908 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:46,909 [run_pretraining.py:  534]:	loss/total_loss, 7.178928375244141, 2870
[INFO] 2021-07-12 19:29:46,909 [run_pretraining.py:  535]:	loss/mlm_loss, 7.178928375244141, 2870
[INFO] 2021-07-12 19:29:46,909 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8690001272480004e-05, 2870
[INFO] 2021-07-12 19:29:46,909 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2870
[INFO] 2021-07-12 19:29:46,909 [run_pretraining.py:  558]:	worker_index: 6, step: 2870, cost: 7.178928, mlm loss: 7.178928, speed: 1.031709 steps/s, speed: 8.253673 samples/s, speed: 4225.880489 tokens/s, learning rate: 2.869e-05, loss_scalings: 2814.750488, pp_loss: 7.637462
[INFO] 2021-07-12 19:29:46,909 [run_pretraining.py:  512]:	********exe.run_2870******* 
[INFO] 2021-07-12 19:29:47,925 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:47,926 [run_pretraining.py:  534]:	loss/total_loss, 7.080098628997803, 2871
[INFO] 2021-07-12 19:29:47,926 [run_pretraining.py:  535]:	loss/mlm_loss, 7.080098628997803, 2871
[INFO] 2021-07-12 19:29:47,926 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.869999843824189e-05, 2871
[INFO] 2021-07-12 19:29:47,926 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2871
[INFO] 2021-07-12 19:29:47,926 [run_pretraining.py:  558]:	worker_index: 6, step: 2871, cost: 7.080099, mlm loss: 7.080099, speed: 0.984183 steps/s, speed: 7.873461 samples/s, speed: 4031.212140 tokens/s, learning rate: 2.870e-05, loss_scalings: 2814.750488, pp_loss: 7.085124
[INFO] 2021-07-12 19:29:47,926 [run_pretraining.py:  512]:	********exe.run_2871******* 
[INFO] 2021-07-12 19:29:48,900 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:48,901 [run_pretraining.py:  534]:	loss/total_loss, 7.862472057342529, 2872
[INFO] 2021-07-12 19:29:48,901 [run_pretraining.py:  535]:	loss/mlm_loss, 7.862472057342529, 2872
[INFO] 2021-07-12 19:29:48,901 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8709997422993183e-05, 2872
[INFO] 2021-07-12 19:29:48,901 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2872
[INFO] 2021-07-12 19:29:48,901 [run_pretraining.py:  558]:	worker_index: 6, step: 2872, cost: 7.862472, mlm loss: 7.862472, speed: 1.026167 steps/s, speed: 8.209335 samples/s, speed: 4203.179317 tokens/s, learning rate: 2.871e-05, loss_scalings: 2814.750488, pp_loss: 7.616428
[INFO] 2021-07-12 19:29:48,901 [run_pretraining.py:  512]:	********exe.run_2872******* 
[INFO] 2021-07-12 19:29:49,884 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:49,884 [run_pretraining.py:  534]:	loss/total_loss, 7.1937994956970215, 2873
[INFO] 2021-07-12 19:29:49,885 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1937994956970215, 2873
[INFO] 2021-07-12 19:29:49,885 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8720000045723282e-05, 2873
[INFO] 2021-07-12 19:29:49,885 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2873
[INFO] 2021-07-12 19:29:49,885 [run_pretraining.py:  558]:	worker_index: 6, step: 2873, cost: 7.193799, mlm loss: 7.193799, speed: 1.017327 steps/s, speed: 8.138616 samples/s, speed: 4166.971475 tokens/s, learning rate: 2.872e-05, loss_scalings: 2814.750488, pp_loss: 7.544021
[INFO] 2021-07-12 19:29:49,885 [run_pretraining.py:  512]:	********exe.run_2873******* 
[INFO] 2021-07-12 19:29:50,863 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:50,864 [run_pretraining.py:  534]:	loss/total_loss, 5.96527099609375, 2874
[INFO] 2021-07-12 19:29:50,864 [run_pretraining.py:  535]:	loss/mlm_loss, 5.96527099609375, 2874
[INFO] 2021-07-12 19:29:50,864 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8729999030474573e-05, 2874
[INFO] 2021-07-12 19:29:50,864 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2874
[INFO] 2021-07-12 19:29:50,864 [run_pretraining.py:  558]:	worker_index: 6, step: 2874, cost: 5.965271, mlm loss: 5.965271, speed: 1.022165 steps/s, speed: 8.177320 samples/s, speed: 4186.788020 tokens/s, learning rate: 2.873e-05, loss_scalings: 2814.750488, pp_loss: 6.676990
[INFO] 2021-07-12 19:29:50,864 [run_pretraining.py:  512]:	********exe.run_2874******* 
[INFO] 2021-07-12 19:29:51,852 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:51,853 [run_pretraining.py:  534]:	loss/total_loss, 7.404867649078369, 2875
[INFO] 2021-07-12 19:29:51,853 [run_pretraining.py:  535]:	loss/mlm_loss, 7.404867649078369, 2875
[INFO] 2021-07-12 19:29:51,853 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.873999983421527e-05, 2875
[INFO] 2021-07-12 19:29:51,853 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2875
[INFO] 2021-07-12 19:29:51,853 [run_pretraining.py:  558]:	worker_index: 6, step: 2875, cost: 7.404868, mlm loss: 7.404868, speed: 1.011842 steps/s, speed: 8.094739 samples/s, speed: 4144.506180 tokens/s, learning rate: 2.874e-05, loss_scalings: 2814.750488, pp_loss: 7.174485
[INFO] 2021-07-12 19:29:51,853 [run_pretraining.py:  512]:	********exe.run_2875******* 
[INFO] 2021-07-12 19:29:52,845 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:52,846 [run_pretraining.py:  534]:	loss/total_loss, 7.370166778564453, 2876
[INFO] 2021-07-12 19:29:52,846 [run_pretraining.py:  535]:	loss/mlm_loss, 7.370166778564453, 2876
[INFO] 2021-07-12 19:29:52,846 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.874999881896656e-05, 2876
[INFO] 2021-07-12 19:29:52,846 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2876
[INFO] 2021-07-12 19:29:52,846 [run_pretraining.py:  558]:	worker_index: 6, step: 2876, cost: 7.370167, mlm loss: 7.370167, speed: 1.007221 steps/s, speed: 8.057768 samples/s, speed: 4125.577281 tokens/s, learning rate: 2.875e-05, loss_scalings: 2814.750488, pp_loss: 7.412838
[INFO] 2021-07-12 19:29:52,847 [run_pretraining.py:  512]:	********exe.run_2876******* 
[INFO] 2021-07-12 19:29:53,856 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:53,856 [run_pretraining.py:  534]:	loss/total_loss, 7.3117241859436035, 2877
[INFO] 2021-07-12 19:29:53,856 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3117241859436035, 2877
[INFO] 2021-07-12 19:29:53,856 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8759999622707255e-05, 2877
[INFO] 2021-07-12 19:29:53,857 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2877
[INFO] 2021-07-12 19:29:53,857 [run_pretraining.py:  558]:	worker_index: 6, step: 2877, cost: 7.311724, mlm loss: 7.311724, speed: 0.990639 steps/s, speed: 7.925112 samples/s, speed: 4057.657241 tokens/s, learning rate: 2.876e-05, loss_scalings: 2814.750488, pp_loss: 7.281241
[INFO] 2021-07-12 19:29:53,857 [run_pretraining.py:  512]:	********exe.run_2877******* 
[INFO] 2021-07-12 19:29:54,767 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:54,768 [run_pretraining.py:  534]:	loss/total_loss, 7.676029205322266, 2878
[INFO] 2021-07-12 19:29:54,768 [run_pretraining.py:  535]:	loss/mlm_loss, 7.676029205322266, 2878
[INFO] 2021-07-12 19:29:54,768 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8769998607458547e-05, 2878
[INFO] 2021-07-12 19:29:54,768 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2878
[INFO] 2021-07-12 19:29:54,768 [run_pretraining.py:  558]:	worker_index: 6, step: 2878, cost: 7.676029, mlm loss: 7.676029, speed: 1.097864 steps/s, speed: 8.782910 samples/s, speed: 4496.850004 tokens/s, learning rate: 2.877e-05, loss_scalings: 2814.750488, pp_loss: 7.411628
[INFO] 2021-07-12 19:29:54,768 [run_pretraining.py:  512]:	********exe.run_2878******* 
[INFO] 2021-07-12 19:29:55,677 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:55,678 [run_pretraining.py:  534]:	loss/total_loss, 7.2206830978393555, 2879
[INFO] 2021-07-12 19:29:55,678 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2206830978393555, 2879
[INFO] 2021-07-12 19:29:55,678 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8780001230188645e-05, 2879
[INFO] 2021-07-12 19:29:55,678 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2879
[INFO] 2021-07-12 19:29:55,678 [run_pretraining.py:  558]:	worker_index: 6, step: 2879, cost: 7.220683, mlm loss: 7.220683, speed: 1.099615 steps/s, speed: 8.796917 samples/s, speed: 4504.021452 tokens/s, learning rate: 2.878e-05, loss_scalings: 2814.750488, pp_loss: 7.144378
[INFO] 2021-07-12 19:29:55,678 [run_pretraining.py:  512]:	********exe.run_2879******* 
[INFO] 2021-07-12 19:29:56,596 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:56,597 [run_pretraining.py:  534]:	loss/total_loss, 7.104984283447266, 2880
[INFO] 2021-07-12 19:29:56,597 [run_pretraining.py:  535]:	loss/mlm_loss, 7.104984283447266, 2880
[INFO] 2021-07-12 19:29:56,597 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8790000214939937e-05, 2880
[INFO] 2021-07-12 19:29:56,597 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2880
[INFO] 2021-07-12 19:29:56,597 [run_pretraining.py:  558]:	worker_index: 6, step: 2880, cost: 7.104984, mlm loss: 7.104984, speed: 1.088982 steps/s, speed: 8.711859 samples/s, speed: 4460.471994 tokens/s, learning rate: 2.879e-05, loss_scalings: 2814.750488, pp_loss: 7.234704
[INFO] 2021-07-12 19:29:56,597 [run_pretraining.py:  512]:	********exe.run_2880******* 
[INFO] 2021-07-12 19:29:57,509 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:57,510 [run_pretraining.py:  534]:	loss/total_loss, 7.171176433563232, 2881
[INFO] 2021-07-12 19:29:57,510 [run_pretraining.py:  535]:	loss/mlm_loss, 7.171176433563232, 2881
[INFO] 2021-07-12 19:29:57,510 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8799997380701825e-05, 2881
[INFO] 2021-07-12 19:29:57,510 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2881
[INFO] 2021-07-12 19:29:57,510 [run_pretraining.py:  558]:	worker_index: 6, step: 2881, cost: 7.171176, mlm loss: 7.171176, speed: 1.096425 steps/s, speed: 8.771398 samples/s, speed: 4490.955983 tokens/s, learning rate: 2.880e-05, loss_scalings: 2814.750488, pp_loss: 6.444311
[INFO] 2021-07-12 19:29:57,510 [run_pretraining.py:  512]:	********exe.run_2881******* 
[INFO] 2021-07-12 19:29:58,416 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:58,417 [run_pretraining.py:  534]:	loss/total_loss, 7.4720916748046875, 2882
[INFO] 2021-07-12 19:29:58,417 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4720916748046875, 2882
[INFO] 2021-07-12 19:29:58,417 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8810000003431924e-05, 2882
[INFO] 2021-07-12 19:29:58,417 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2882
[INFO] 2021-07-12 19:29:58,417 [run_pretraining.py:  558]:	worker_index: 6, step: 2882, cost: 7.472092, mlm loss: 7.472092, speed: 1.102987 steps/s, speed: 8.823893 samples/s, speed: 4517.833134 tokens/s, learning rate: 2.881e-05, loss_scalings: 2814.750488, pp_loss: 7.680922
[INFO] 2021-07-12 19:29:58,417 [run_pretraining.py:  512]:	********exe.run_2882******* 
[INFO] 2021-07-12 19:29:59,338 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:59,338 [run_pretraining.py:  534]:	loss/total_loss, 7.492849826812744, 2883
[INFO] 2021-07-12 19:29:59,339 [run_pretraining.py:  535]:	loss/mlm_loss, 7.492849826812744, 2883
[INFO] 2021-07-12 19:29:59,339 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8819998988183215e-05, 2883
[INFO] 2021-07-12 19:29:59,339 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2883
[INFO] 2021-07-12 19:29:59,339 [run_pretraining.py:  558]:	worker_index: 6, step: 2883, cost: 7.492850, mlm loss: 7.492850, speed: 1.086055 steps/s, speed: 8.688440 samples/s, speed: 4448.481040 tokens/s, learning rate: 2.882e-05, loss_scalings: 2814.750488, pp_loss: 7.097947
[INFO] 2021-07-12 19:29:59,339 [run_pretraining.py:  512]:	********exe.run_2883******* 
[INFO] 2021-07-12 19:30:00,255 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:00,256 [run_pretraining.py:  534]:	loss/total_loss, 7.428110122680664, 2884
[INFO] 2021-07-12 19:30:00,256 [run_pretraining.py:  535]:	loss/mlm_loss, 7.428110122680664, 2884
[INFO] 2021-07-12 19:30:00,256 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.882999979192391e-05, 2884
[INFO] 2021-07-12 19:30:00,256 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2884
[INFO] 2021-07-12 19:30:00,256 [run_pretraining.py:  558]:	worker_index: 6, step: 2884, cost: 7.428110, mlm loss: 7.428110, speed: 1.091269 steps/s, speed: 8.730153 samples/s, speed: 4469.838555 tokens/s, learning rate: 2.883e-05, loss_scalings: 2814.750488, pp_loss: 7.489094
[INFO] 2021-07-12 19:30:00,256 [run_pretraining.py:  512]:	********exe.run_2884******* 
[INFO] 2021-07-12 19:30:01,185 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:01,186 [run_pretraining.py:  534]:	loss/total_loss, 6.419742584228516, 2885
[INFO] 2021-07-12 19:30:01,186 [run_pretraining.py:  535]:	loss/mlm_loss, 6.419742584228516, 2885
[INFO] 2021-07-12 19:30:01,186 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8839998776675202e-05, 2885
[INFO] 2021-07-12 19:30:01,186 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2885
[INFO] 2021-07-12 19:30:01,186 [run_pretraining.py:  558]:	worker_index: 6, step: 2885, cost: 6.419743, mlm loss: 6.419743, speed: 1.076082 steps/s, speed: 8.608654 samples/s, speed: 4407.630745 tokens/s, learning rate: 2.884e-05, loss_scalings: 2814.750488, pp_loss: 6.621585
[INFO] 2021-07-12 19:30:01,186 [run_pretraining.py:  512]:	********exe.run_2885******* 
[INFO] 2021-07-12 19:30:02,096 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:02,096 [run_pretraining.py:  534]:	loss/total_loss, 8.103863716125488, 2886
[INFO] 2021-07-12 19:30:02,096 [run_pretraining.py:  535]:	loss/mlm_loss, 8.103863716125488, 2886
[INFO] 2021-07-12 19:30:02,096 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8849999580415897e-05, 2886
[INFO] 2021-07-12 19:30:02,097 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2886
[INFO] 2021-07-12 19:30:02,097 [run_pretraining.py:  558]:	worker_index: 6, step: 2886, cost: 8.103864, mlm loss: 8.103864, speed: 1.098913 steps/s, speed: 8.791305 samples/s, speed: 4501.148007 tokens/s, learning rate: 2.885e-05, loss_scalings: 2814.750488, pp_loss: 7.109316
[INFO] 2021-07-12 19:30:02,097 [run_pretraining.py:  512]:	********exe.run_2886******* 
[INFO] 2021-07-12 19:30:03,013 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:03,014 [run_pretraining.py:  534]:	loss/total_loss, 7.661202430725098, 2887
[INFO] 2021-07-12 19:30:03,014 [run_pretraining.py:  535]:	loss/mlm_loss, 7.661202430725098, 2887
[INFO] 2021-07-12 19:30:03,014 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.885999856516719e-05, 2887
[INFO] 2021-07-12 19:30:03,014 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2887
[INFO] 2021-07-12 19:30:03,014 [run_pretraining.py:  558]:	worker_index: 6, step: 2887, cost: 7.661202, mlm loss: 7.661202, speed: 1.090833 steps/s, speed: 8.726661 samples/s, speed: 4468.050642 tokens/s, learning rate: 2.886e-05, loss_scalings: 2814.750488, pp_loss: 7.564257
[INFO] 2021-07-12 19:30:03,014 [run_pretraining.py:  512]:	********exe.run_2887******* 
[INFO] 2021-07-12 19:30:03,926 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:03,927 [run_pretraining.py:  534]:	loss/total_loss, 7.2838311195373535, 2888
[INFO] 2021-07-12 19:30:03,927 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2838311195373535, 2888
[INFO] 2021-07-12 19:30:03,927 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8870001187897287e-05, 2888
[INFO] 2021-07-12 19:30:03,927 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2888
[INFO] 2021-07-12 19:30:03,927 [run_pretraining.py:  558]:	worker_index: 6, step: 2888, cost: 7.283831, mlm loss: 7.283831, speed: 1.095799 steps/s, speed: 8.766394 samples/s, speed: 4488.393491 tokens/s, learning rate: 2.887e-05, loss_scalings: 2814.750488, pp_loss: 7.316265
[INFO] 2021-07-12 19:30:03,927 [run_pretraining.py:  512]:	********exe.run_2888******* 
[INFO] 2021-07-12 19:30:04,841 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:04,842 [run_pretraining.py:  534]:	loss/total_loss, 6.789713382720947, 2889
[INFO] 2021-07-12 19:30:04,842 [run_pretraining.py:  535]:	loss/mlm_loss, 6.789713382720947, 2889
[INFO] 2021-07-12 19:30:04,842 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.888000017264858e-05, 2889
[INFO] 2021-07-12 19:30:04,842 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2889
[INFO] 2021-07-12 19:30:04,842 [run_pretraining.py:  558]:	worker_index: 6, step: 2889, cost: 6.789713, mlm loss: 6.789713, speed: 1.093825 steps/s, speed: 8.750601 samples/s, speed: 4480.307538 tokens/s, learning rate: 2.888e-05, loss_scalings: 2814.750488, pp_loss: 7.231925
[INFO] 2021-07-12 19:30:04,842 [run_pretraining.py:  512]:	********exe.run_2889******* 
[INFO] 2021-07-12 19:30:05,760 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:05,761 [run_pretraining.py:  534]:	loss/total_loss, 6.925838470458984, 2890
[INFO] 2021-07-12 19:30:05,761 [run_pretraining.py:  535]:	loss/mlm_loss, 6.925838470458984, 2890
[INFO] 2021-07-12 19:30:05,761 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8889997338410467e-05, 2890
[INFO] 2021-07-12 19:30:05,761 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2890
[INFO] 2021-07-12 19:30:05,761 [run_pretraining.py:  558]:	worker_index: 6, step: 2890, cost: 6.925838, mlm loss: 6.925838, speed: 1.089237 steps/s, speed: 8.713893 samples/s, speed: 4461.513359 tokens/s, learning rate: 2.889e-05, loss_scalings: 2814.750488, pp_loss: 7.101241
[INFO] 2021-07-12 19:30:05,761 [run_pretraining.py:  512]:	********exe.run_2890******* 
[INFO] 2021-07-12 19:30:06,674 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:06,675 [run_pretraining.py:  534]:	loss/total_loss, 7.497438430786133, 2891
[INFO] 2021-07-12 19:30:06,675 [run_pretraining.py:  535]:	loss/mlm_loss, 7.497438430786133, 2891
[INFO] 2021-07-12 19:30:06,675 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8899999961140566e-05, 2891
[INFO] 2021-07-12 19:30:06,675 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2891
[INFO] 2021-07-12 19:30:06,675 [run_pretraining.py:  558]:	worker_index: 6, step: 2891, cost: 7.497438, mlm loss: 7.497438, speed: 1.094993 steps/s, speed: 8.759944 samples/s, speed: 4485.091444 tokens/s, learning rate: 2.890e-05, loss_scalings: 2814.750488, pp_loss: 6.515760
[INFO] 2021-07-12 19:30:06,675 [run_pretraining.py:  512]:	********exe.run_2891******* 
[INFO] 2021-07-12 19:30:07,587 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:07,588 [run_pretraining.py:  534]:	loss/total_loss, 7.700139045715332, 2892
[INFO] 2021-07-12 19:30:07,588 [run_pretraining.py:  535]:	loss/mlm_loss, 7.700139045715332, 2892
[INFO] 2021-07-12 19:30:07,588 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8909998945891857e-05, 2892
[INFO] 2021-07-12 19:30:07,588 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2892
[INFO] 2021-07-12 19:30:07,588 [run_pretraining.py:  558]:	worker_index: 6, step: 2892, cost: 7.700139, mlm loss: 7.700139, speed: 1.095648 steps/s, speed: 8.765187 samples/s, speed: 4487.775599 tokens/s, learning rate: 2.891e-05, loss_scalings: 2814.750488, pp_loss: 7.450317
[INFO] 2021-07-12 19:30:07,589 [run_pretraining.py:  512]:	********exe.run_2892******* 
[INFO] 2021-07-12 19:30:08,502 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:08,502 [run_pretraining.py:  534]:	loss/total_loss, 6.66495943069458, 2893
[INFO] 2021-07-12 19:30:08,502 [run_pretraining.py:  535]:	loss/mlm_loss, 6.66495943069458, 2893
[INFO] 2021-07-12 19:30:08,502 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8919999749632552e-05, 2893
[INFO] 2021-07-12 19:30:08,502 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2893
[INFO] 2021-07-12 19:30:08,503 [run_pretraining.py:  558]:	worker_index: 6, step: 2893, cost: 6.664959, mlm loss: 6.664959, speed: 1.094802 steps/s, speed: 8.758412 samples/s, speed: 4484.307072 tokens/s, learning rate: 2.892e-05, loss_scalings: 2814.750488, pp_loss: 7.262844
[INFO] 2021-07-12 19:30:08,503 [run_pretraining.py:  512]:	********exe.run_2893******* 
[INFO] 2021-07-12 19:30:09,419 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:09,419 [run_pretraining.py:  534]:	loss/total_loss, 7.647309303283691, 2894
[INFO] 2021-07-12 19:30:09,420 [run_pretraining.py:  535]:	loss/mlm_loss, 7.647309303283691, 2894
[INFO] 2021-07-12 19:30:09,420 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8929998734383844e-05, 2894
[INFO] 2021-07-12 19:30:09,420 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2894
[INFO] 2021-07-12 19:30:09,420 [run_pretraining.py:  558]:	worker_index: 6, step: 2894, cost: 7.647309, mlm loss: 7.647309, speed: 1.090988 steps/s, speed: 8.727901 samples/s, speed: 4468.685199 tokens/s, learning rate: 2.893e-05, loss_scalings: 2814.750488, pp_loss: 7.058207
[INFO] 2021-07-12 19:30:09,420 [run_pretraining.py:  512]:	********exe.run_2894******* 
[INFO] 2021-07-12 19:30:10,346 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:10,346 [run_pretraining.py:  534]:	loss/total_loss, 7.933285713195801, 2895
[INFO] 2021-07-12 19:30:10,346 [run_pretraining.py:  535]:	loss/mlm_loss, 7.933285713195801, 2895
[INFO] 2021-07-12 19:30:10,347 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.893999953812454e-05, 2895
[INFO] 2021-07-12 19:30:10,347 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2895
[INFO] 2021-07-12 19:30:10,347 [run_pretraining.py:  558]:	worker_index: 6, step: 2895, cost: 7.933286, mlm loss: 7.933286, speed: 1.079737 steps/s, speed: 8.637898 samples/s, speed: 4422.603637 tokens/s, learning rate: 2.894e-05, loss_scalings: 2814.750488, pp_loss: 7.428570
[INFO] 2021-07-12 19:30:10,347 [run_pretraining.py:  512]:	********exe.run_2895******* 
[INFO] 2021-07-12 19:30:11,263 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:11,264 [run_pretraining.py:  534]:	loss/total_loss, 6.526900291442871, 2896
[INFO] 2021-07-12 19:30:11,264 [run_pretraining.py:  535]:	loss/mlm_loss, 6.526900291442871, 2896
[INFO] 2021-07-12 19:30:11,264 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.894999852287583e-05, 2896
[INFO] 2021-07-12 19:30:11,264 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2896
[INFO] 2021-07-12 19:30:11,264 [run_pretraining.py:  558]:	worker_index: 6, step: 2896, cost: 6.526900, mlm loss: 6.526900, speed: 1.090860 steps/s, speed: 8.726879 samples/s, speed: 4468.162199 tokens/s, learning rate: 2.895e-05, loss_scalings: 2814.750488, pp_loss: 6.518484
[INFO] 2021-07-12 19:30:11,264 [run_pretraining.py:  512]:	********exe.run_2896******* 
[INFO] 2021-07-12 19:30:12,178 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:12,178 [run_pretraining.py:  534]:	loss/total_loss, 7.304755210876465, 2897
[INFO] 2021-07-12 19:30:12,179 [run_pretraining.py:  535]:	loss/mlm_loss, 7.304755210876465, 2897
[INFO] 2021-07-12 19:30:12,179 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.896000114560593e-05, 2897
[INFO] 2021-07-12 19:30:12,179 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2897
[INFO] 2021-07-12 19:30:12,179 [run_pretraining.py:  558]:	worker_index: 6, step: 2897, cost: 7.304755, mlm loss: 7.304755, speed: 1.094131 steps/s, speed: 8.753050 samples/s, speed: 4481.561595 tokens/s, learning rate: 2.896e-05, loss_scalings: 2814.750488, pp_loss: 7.338813
[INFO] 2021-07-12 19:30:12,179 [run_pretraining.py:  512]:	********exe.run_2897******* 
[INFO] 2021-07-12 19:30:13,089 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:13,090 [run_pretraining.py:  534]:	loss/total_loss, 7.5217976570129395, 2898
[INFO] 2021-07-12 19:30:13,090 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5217976570129395, 2898
[INFO] 2021-07-12 19:30:13,090 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.897000013035722e-05, 2898
[INFO] 2021-07-12 19:30:13,090 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2898
[INFO] 2021-07-12 19:30:13,090 [run_pretraining.py:  558]:	worker_index: 6, step: 2898, cost: 7.521798, mlm loss: 7.521798, speed: 1.098245 steps/s, speed: 8.785957 samples/s, speed: 4498.410144 tokens/s, learning rate: 2.897e-05, loss_scalings: 2814.750488, pp_loss: 7.281793
[INFO] 2021-07-12 19:30:13,090 [run_pretraining.py:  512]:	********exe.run_2898******* 
[INFO] 2021-07-12 19:30:13,996 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:13,996 [run_pretraining.py:  534]:	loss/total_loss, 7.253068923950195, 2899
[INFO] 2021-07-12 19:30:13,996 [run_pretraining.py:  535]:	loss/mlm_loss, 7.253068923950195, 2899
[INFO] 2021-07-12 19:30:13,996 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.897999729611911e-05, 2899
[INFO] 2021-07-12 19:30:13,997 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2899
[INFO] 2021-07-12 19:30:13,997 [run_pretraining.py:  558]:	worker_index: 6, step: 2899, cost: 7.253069, mlm loss: 7.253069, speed: 1.103968 steps/s, speed: 8.831743 samples/s, speed: 4521.852369 tokens/s, learning rate: 2.898e-05, loss_scalings: 2814.750488, pp_loss: 7.561061
[INFO] 2021-07-12 19:30:13,997 [run_pretraining.py:  512]:	********exe.run_2899******* 
[INFO] 2021-07-12 19:30:14,911 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:14,911 [run_pretraining.py:  534]:	loss/total_loss, 6.914986610412598, 2900
[INFO] 2021-07-12 19:30:14,911 [run_pretraining.py:  535]:	loss/mlm_loss, 6.914986610412598, 2900
[INFO] 2021-07-12 19:30:14,911 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8989999918849207e-05, 2900
[INFO] 2021-07-12 19:30:14,911 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2900
[INFO] 2021-07-12 19:30:14,912 [run_pretraining.py:  558]:	worker_index: 6, step: 2900, cost: 6.914987, mlm loss: 6.914987, speed: 1.093785 steps/s, speed: 8.750277 samples/s, speed: 4480.141630 tokens/s, learning rate: 2.899e-05, loss_scalings: 2814.750488, pp_loss: 6.977676
[INFO] 2021-07-12 19:30:14,912 [run_pretraining.py:  512]:	********exe.run_2900******* 
[INFO] 2021-07-12 19:30:15,840 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:15,841 [run_pretraining.py:  534]:	loss/total_loss, 7.420178413391113, 2901
[INFO] 2021-07-12 19:30:15,841 [run_pretraining.py:  535]:	loss/mlm_loss, 7.420178413391113, 2901
[INFO] 2021-07-12 19:30:15,841 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.89999989036005e-05, 2901
[INFO] 2021-07-12 19:30:15,841 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2901
[INFO] 2021-07-12 19:30:15,841 [run_pretraining.py:  558]:	worker_index: 6, step: 2901, cost: 7.420178, mlm loss: 7.420178, speed: 1.076483 steps/s, speed: 8.611862 samples/s, speed: 4409.273297 tokens/s, learning rate: 2.900e-05, loss_scalings: 2814.750488, pp_loss: 6.856379
[INFO] 2021-07-12 19:30:15,841 [run_pretraining.py:  512]:	********exe.run_2901******* 
[INFO] 2021-07-12 19:30:16,751 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:16,752 [run_pretraining.py:  534]:	loss/total_loss, 7.537708759307861, 2902
[INFO] 2021-07-12 19:30:16,752 [run_pretraining.py:  535]:	loss/mlm_loss, 7.537708759307861, 2902
[INFO] 2021-07-12 19:30:16,752 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9009999707341194e-05, 2902
[INFO] 2021-07-12 19:30:16,752 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2902
[INFO] 2021-07-12 19:30:16,752 [run_pretraining.py:  558]:	worker_index: 6, step: 2902, cost: 7.537709, mlm loss: 7.537709, speed: 1.098684 steps/s, speed: 8.789472 samples/s, speed: 4500.209475 tokens/s, learning rate: 2.901e-05, loss_scalings: 2814.750488, pp_loss: 7.160754
[INFO] 2021-07-12 19:30:16,752 [run_pretraining.py:  512]:	********exe.run_2902******* 
[INFO] 2021-07-12 19:30:17,661 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:17,662 [run_pretraining.py:  534]:	loss/total_loss, 8.247318267822266, 2903
[INFO] 2021-07-12 19:30:17,662 [run_pretraining.py:  535]:	loss/mlm_loss, 8.247318267822266, 2903
[INFO] 2021-07-12 19:30:17,662 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9019998692092486e-05, 2903
[INFO] 2021-07-12 19:30:17,662 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2903
[INFO] 2021-07-12 19:30:17,662 [run_pretraining.py:  558]:	worker_index: 6, step: 2903, cost: 8.247318, mlm loss: 8.247318, speed: 1.099404 steps/s, speed: 8.795229 samples/s, speed: 4503.157263 tokens/s, learning rate: 2.902e-05, loss_scalings: 2814.750488, pp_loss: 7.468303
[INFO] 2021-07-12 19:30:17,662 [run_pretraining.py:  512]:	********exe.run_2903******* 
[INFO] 2021-07-12 19:30:18,609 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:18,610 [run_pretraining.py:  534]:	loss/total_loss, 3.4806220531463623, 2904
[INFO] 2021-07-12 19:30:18,610 [run_pretraining.py:  535]:	loss/mlm_loss, 3.4806220531463623, 2904
[INFO] 2021-07-12 19:30:18,610 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9030001314822584e-05, 2904
[INFO] 2021-07-12 19:30:18,610 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2904
[INFO] 2021-07-12 19:30:18,610 [run_pretraining.py:  558]:	worker_index: 6, step: 2904, cost: 3.480622, mlm loss: 3.480622, speed: 1.055876 steps/s, speed: 8.447006 samples/s, speed: 4324.867266 tokens/s, learning rate: 2.903e-05, loss_scalings: 2814.750488, pp_loss: 6.044636
[INFO] 2021-07-12 19:30:18,610 [run_pretraining.py:  512]:	********exe.run_2904******* 
[INFO] 2021-07-12 19:30:19,528 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:19,529 [run_pretraining.py:  534]:	loss/total_loss, 7.555602073669434, 2905
[INFO] 2021-07-12 19:30:19,529 [run_pretraining.py:  535]:	loss/mlm_loss, 7.555602073669434, 2905
[INFO] 2021-07-12 19:30:19,529 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9039998480584472e-05, 2905
[INFO] 2021-07-12 19:30:19,529 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2905
[INFO] 2021-07-12 19:30:19,529 [run_pretraining.py:  558]:	worker_index: 6, step: 2905, cost: 7.555602, mlm loss: 7.555602, speed: 1.089060 steps/s, speed: 8.712481 samples/s, speed: 4460.790491 tokens/s, learning rate: 2.904e-05, loss_scalings: 2814.750488, pp_loss: 7.422483
[INFO] 2021-07-12 19:30:19,529 [run_pretraining.py:  512]:	********exe.run_2905******* 
[INFO] 2021-07-12 19:30:20,447 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:20,448 [run_pretraining.py:  534]:	loss/total_loss, 6.931345462799072, 2906
[INFO] 2021-07-12 19:30:20,448 [run_pretraining.py:  535]:	loss/mlm_loss, 6.931345462799072, 2906
[INFO] 2021-07-12 19:30:20,448 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9049997465335764e-05, 2906
[INFO] 2021-07-12 19:30:20,448 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2906
[INFO] 2021-07-12 19:30:20,448 [run_pretraining.py:  558]:	worker_index: 6, step: 2906, cost: 6.931345, mlm loss: 6.931345, speed: 1.088812 steps/s, speed: 8.710493 samples/s, speed: 4459.772618 tokens/s, learning rate: 2.905e-05, loss_scalings: 2814.750488, pp_loss: 7.282053
[INFO] 2021-07-12 19:30:20,448 [run_pretraining.py:  512]:	********exe.run_2906******* 
[INFO] 2021-07-12 19:30:21,364 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:21,365 [run_pretraining.py:  534]:	loss/total_loss, 7.230876445770264, 2907
[INFO] 2021-07-12 19:30:21,365 [run_pretraining.py:  535]:	loss/mlm_loss, 7.230876445770264, 2907
[INFO] 2021-07-12 19:30:21,365 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9060000088065863e-05, 2907
[INFO] 2021-07-12 19:30:21,365 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2907
[INFO] 2021-07-12 19:30:21,365 [run_pretraining.py:  558]:	worker_index: 6, step: 2907, cost: 7.230876, mlm loss: 7.230876, speed: 1.091462 steps/s, speed: 8.731696 samples/s, speed: 4470.628342 tokens/s, learning rate: 2.906e-05, loss_scalings: 2814.750488, pp_loss: 7.326204
[INFO] 2021-07-12 19:30:21,365 [run_pretraining.py:  512]:	********exe.run_2907******* 
[INFO] 2021-07-12 19:30:22,278 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:22,279 [run_pretraining.py:  534]:	loss/total_loss, 7.173303604125977, 2908
[INFO] 2021-07-12 19:30:22,279 [run_pretraining.py:  535]:	loss/mlm_loss, 7.173303604125977, 2908
[INFO] 2021-07-12 19:30:22,279 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.906999725382775e-05, 2908
[INFO] 2021-07-12 19:30:22,279 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2908
[INFO] 2021-07-12 19:30:22,279 [run_pretraining.py:  558]:	worker_index: 6, step: 2908, cost: 7.173304, mlm loss: 7.173304, speed: 1.094958 steps/s, speed: 8.759665 samples/s, speed: 4484.948597 tokens/s, learning rate: 2.907e-05, loss_scalings: 2814.750488, pp_loss: 7.293650
[INFO] 2021-07-12 19:30:22,279 [run_pretraining.py:  512]:	********exe.run_2908******* 
[INFO] 2021-07-12 19:30:23,212 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:23,212 [run_pretraining.py:  534]:	loss/total_loss, 7.747269153594971, 2909
[INFO] 2021-07-12 19:30:23,212 [run_pretraining.py:  535]:	loss/mlm_loss, 7.747269153594971, 2909
[INFO] 2021-07-12 19:30:23,212 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.907999987655785e-05, 2909
[INFO] 2021-07-12 19:30:23,212 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2909
[INFO] 2021-07-12 19:30:23,213 [run_pretraining.py:  558]:	worker_index: 6, step: 2909, cost: 7.747269, mlm loss: 7.747269, speed: 1.072147 steps/s, speed: 8.577173 samples/s, speed: 4391.512503 tokens/s, learning rate: 2.908e-05, loss_scalings: 2814.750488, pp_loss: 7.089621
[INFO] 2021-07-12 19:30:23,213 [run_pretraining.py:  512]:	********exe.run_2909******* 
[INFO] 2021-07-12 19:30:24,123 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:24,123 [run_pretraining.py:  534]:	loss/total_loss, 7.123330116271973, 2910
[INFO] 2021-07-12 19:30:24,123 [run_pretraining.py:  535]:	loss/mlm_loss, 7.123330116271973, 2910
[INFO] 2021-07-12 19:30:24,124 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.908999886130914e-05, 2910
[INFO] 2021-07-12 19:30:24,124 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2910
[INFO] 2021-07-12 19:30:24,124 [run_pretraining.py:  558]:	worker_index: 6, step: 2910, cost: 7.123330, mlm loss: 7.123330, speed: 1.098353 steps/s, speed: 8.786827 samples/s, speed: 4498.855424 tokens/s, learning rate: 2.909e-05, loss_scalings: 2814.750488, pp_loss: 7.305866
[INFO] 2021-07-12 19:30:24,124 [run_pretraining.py:  512]:	********exe.run_2910******* 
[INFO] 2021-07-12 19:30:25,026 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:25,027 [run_pretraining.py:  534]:	loss/total_loss, 7.116089820861816, 2911
[INFO] 2021-07-12 19:30:25,027 [run_pretraining.py:  535]:	loss/mlm_loss, 7.116089820861816, 2911
[INFO] 2021-07-12 19:30:25,027 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9099999665049836e-05, 2911
[INFO] 2021-07-12 19:30:25,027 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2911
[INFO] 2021-07-12 19:30:25,027 [run_pretraining.py:  558]:	worker_index: 6, step: 2911, cost: 7.116090, mlm loss: 7.116090, speed: 1.108013 steps/s, speed: 8.864101 samples/s, speed: 4538.419462 tokens/s, learning rate: 2.910e-05, loss_scalings: 2814.750488, pp_loss: 7.031966
[INFO] 2021-07-12 19:30:25,027 [run_pretraining.py:  512]:	********exe.run_2911******* 
[INFO] 2021-07-12 19:30:25,942 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:25,943 [run_pretraining.py:  534]:	loss/total_loss, 8.078414916992188, 2912
[INFO] 2021-07-12 19:30:25,943 [run_pretraining.py:  535]:	loss/mlm_loss, 8.078414916992188, 2912
[INFO] 2021-07-12 19:30:25,943 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9109998649801128e-05, 2912
[INFO] 2021-07-12 19:30:25,943 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2912
[INFO] 2021-07-12 19:30:25,943 [run_pretraining.py:  558]:	worker_index: 6, step: 2912, cost: 8.078415, mlm loss: 8.078415, speed: 1.092579 steps/s, speed: 8.740633 samples/s, speed: 4475.203895 tokens/s, learning rate: 2.911e-05, loss_scalings: 2814.750488, pp_loss: 7.610670
[INFO] 2021-07-12 19:30:25,943 [run_pretraining.py:  512]:	********exe.run_2912******* 
[INFO] 2021-07-12 19:30:26,851 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:26,852 [run_pretraining.py:  534]:	loss/total_loss, 7.733888149261475, 2913
[INFO] 2021-07-12 19:30:26,852 [run_pretraining.py:  535]:	loss/mlm_loss, 7.733888149261475, 2913
[INFO] 2021-07-12 19:30:26,852 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9120001272531226e-05, 2913
[INFO] 2021-07-12 19:30:26,852 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2913
[INFO] 2021-07-12 19:30:26,852 [run_pretraining.py:  558]:	worker_index: 6, step: 2913, cost: 7.733888, mlm loss: 7.733888, speed: 1.100776 steps/s, speed: 8.806205 samples/s, speed: 4508.776877 tokens/s, learning rate: 2.912e-05, loss_scalings: 2814.750488, pp_loss: 7.231341
[INFO] 2021-07-12 19:30:26,852 [run_pretraining.py:  512]:	********exe.run_2913******* 
[INFO] 2021-07-12 19:30:27,759 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:27,760 [run_pretraining.py:  534]:	loss/total_loss, 7.984196662902832, 2914
[INFO] 2021-07-12 19:30:27,760 [run_pretraining.py:  535]:	loss/mlm_loss, 7.984196662902832, 2914
[INFO] 2021-07-12 19:30:27,760 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9129998438293114e-05, 2914
[INFO] 2021-07-12 19:30:27,760 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2914
[INFO] 2021-07-12 19:30:27,760 [run_pretraining.py:  558]:	worker_index: 6, step: 2914, cost: 7.984197, mlm loss: 7.984197, speed: 1.101678 steps/s, speed: 8.813424 samples/s, speed: 4512.473007 tokens/s, learning rate: 2.913e-05, loss_scalings: 2814.750488, pp_loss: 7.484219
[INFO] 2021-07-12 19:30:27,761 [run_pretraining.py:  512]:	********exe.run_2914******* 
[INFO] 2021-07-12 19:30:28,665 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:28,666 [run_pretraining.py:  534]:	loss/total_loss, 7.6297607421875, 2915
[INFO] 2021-07-12 19:30:28,666 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6297607421875, 2915
[INFO] 2021-07-12 19:30:28,666 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9139997423044406e-05, 2915
[INFO] 2021-07-12 19:30:28,666 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2915
[INFO] 2021-07-12 19:30:28,666 [run_pretraining.py:  558]:	worker_index: 6, step: 2915, cost: 7.629761, mlm loss: 7.629761, speed: 1.104895 steps/s, speed: 8.839160 samples/s, speed: 4525.649852 tokens/s, learning rate: 2.914e-05, loss_scalings: 2814.750488, pp_loss: 7.253051
[INFO] 2021-07-12 19:30:28,666 [run_pretraining.py:  512]:	********exe.run_2915******* 
[INFO] 2021-07-12 19:30:29,575 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:29,576 [run_pretraining.py:  534]:	loss/total_loss, 7.959880352020264, 2916
[INFO] 2021-07-12 19:30:29,576 [run_pretraining.py:  535]:	loss/mlm_loss, 7.959880352020264, 2916
[INFO] 2021-07-12 19:30:29,576 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9150000045774505e-05, 2916
[INFO] 2021-07-12 19:30:29,576 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2916
[INFO] 2021-07-12 19:30:29,576 [run_pretraining.py:  558]:	worker_index: 6, step: 2916, cost: 7.959880, mlm loss: 7.959880, speed: 1.099731 steps/s, speed: 8.797844 samples/s, speed: 4504.496188 tokens/s, learning rate: 2.915e-05, loss_scalings: 2814.750488, pp_loss: 7.528419
[INFO] 2021-07-12 19:30:29,576 [run_pretraining.py:  512]:	********exe.run_2916******* 
[INFO] 2021-07-12 19:30:30,482 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:30,483 [run_pretraining.py:  534]:	loss/total_loss, 6.8672003746032715, 2917
[INFO] 2021-07-12 19:30:30,483 [run_pretraining.py:  535]:	loss/mlm_loss, 6.8672003746032715, 2917
[INFO] 2021-07-12 19:30:30,483 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9159999030525796e-05, 2917
[INFO] 2021-07-12 19:30:30,483 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2917
[INFO] 2021-07-12 19:30:30,483 [run_pretraining.py:  558]:	worker_index: 6, step: 2917, cost: 6.867200, mlm loss: 6.867200, speed: 1.103492 steps/s, speed: 8.827932 samples/s, speed: 4519.901315 tokens/s, learning rate: 2.916e-05, loss_scalings: 2814.750488, pp_loss: 7.170645
[INFO] 2021-07-12 19:30:30,483 [run_pretraining.py:  512]:	********exe.run_2917******* 
[INFO] 2021-07-12 19:30:31,383 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:31,384 [run_pretraining.py:  534]:	loss/total_loss, 7.413105487823486, 2918
[INFO] 2021-07-12 19:30:31,384 [run_pretraining.py:  535]:	loss/mlm_loss, 7.413105487823486, 2918
[INFO] 2021-07-12 19:30:31,384 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.916999983426649e-05, 2918
[INFO] 2021-07-12 19:30:31,384 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2918
[INFO] 2021-07-12 19:30:31,384 [run_pretraining.py:  558]:	worker_index: 6, step: 2918, cost: 7.413105, mlm loss: 7.413105, speed: 1.110697 steps/s, speed: 8.885576 samples/s, speed: 4549.414936 tokens/s, learning rate: 2.917e-05, loss_scalings: 2814.750488, pp_loss: 7.319262
[INFO] 2021-07-12 19:30:31,384 [run_pretraining.py:  512]:	********exe.run_2918******* 
[INFO] 2021-07-12 19:30:32,297 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:32,297 [run_pretraining.py:  534]:	loss/total_loss, 7.209324836730957, 2919
[INFO] 2021-07-12 19:30:32,297 [run_pretraining.py:  535]:	loss/mlm_loss, 7.209324836730957, 2919
[INFO] 2021-07-12 19:30:32,297 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9179998819017783e-05, 2919
[INFO] 2021-07-12 19:30:32,297 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2919
[INFO] 2021-07-12 19:30:32,297 [run_pretraining.py:  558]:	worker_index: 6, step: 2919, cost: 7.209325, mlm loss: 7.209325, speed: 1.095900 steps/s, speed: 8.767198 samples/s, speed: 4488.805123 tokens/s, learning rate: 2.918e-05, loss_scalings: 2814.750488, pp_loss: 7.287734
[INFO] 2021-07-12 19:30:32,298 [run_pretraining.py:  512]:	********exe.run_2919******* 
[INFO] 2021-07-12 19:30:33,200 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:33,200 [run_pretraining.py:  534]:	loss/total_loss, 7.906503677368164, 2920
[INFO] 2021-07-12 19:30:33,200 [run_pretraining.py:  535]:	loss/mlm_loss, 7.906503677368164, 2920
[INFO] 2021-07-12 19:30:33,200 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9189999622758478e-05, 2920
[INFO] 2021-07-12 19:30:33,201 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2920
[INFO] 2021-07-12 19:30:33,201 [run_pretraining.py:  558]:	worker_index: 6, step: 2920, cost: 7.906504, mlm loss: 7.906504, speed: 1.108154 steps/s, speed: 8.865229 samples/s, speed: 4538.997414 tokens/s, learning rate: 2.919e-05, loss_scalings: 2814.750488, pp_loss: 7.506217
[INFO] 2021-07-12 19:30:33,201 [run_pretraining.py:  512]:	********exe.run_2920******* 
[INFO] 2021-07-12 19:30:34,106 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:34,107 [run_pretraining.py:  534]:	loss/total_loss, 7.336396217346191, 2921
[INFO] 2021-07-12 19:30:34,107 [run_pretraining.py:  535]:	loss/mlm_loss, 7.336396217346191, 2921
[INFO] 2021-07-12 19:30:34,107 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.919999860750977e-05, 2921
[INFO] 2021-07-12 19:30:34,107 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2921
[INFO] 2021-07-12 19:30:34,107 [run_pretraining.py:  558]:	worker_index: 6, step: 2921, cost: 7.336396, mlm loss: 7.336396, speed: 1.103888 steps/s, speed: 8.831106 samples/s, speed: 4521.526283 tokens/s, learning rate: 2.920e-05, loss_scalings: 2814.750488, pp_loss: 7.576797
[INFO] 2021-07-12 19:30:34,107 [run_pretraining.py:  512]:	********exe.run_2921******* 
[INFO] 2021-07-12 19:30:35,014 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:35,015 [run_pretraining.py:  534]:	loss/total_loss, 6.6655731201171875, 2922
[INFO] 2021-07-12 19:30:35,015 [run_pretraining.py:  535]:	loss/mlm_loss, 6.6655731201171875, 2922
[INFO] 2021-07-12 19:30:35,015 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9210001230239868e-05, 2922
[INFO] 2021-07-12 19:30:35,015 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2922
[INFO] 2021-07-12 19:30:35,015 [run_pretraining.py:  558]:	worker_index: 6, step: 2922, cost: 6.665573, mlm loss: 6.665573, speed: 1.102444 steps/s, speed: 8.819549 samples/s, speed: 4515.608982 tokens/s, learning rate: 2.921e-05, loss_scalings: 2814.750488, pp_loss: 5.562000
[INFO] 2021-07-12 19:30:35,015 [run_pretraining.py:  512]:	********exe.run_2922******* 
[INFO] 2021-07-12 19:30:35,927 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:35,927 [run_pretraining.py:  534]:	loss/total_loss, 7.7394208908081055, 2923
[INFO] 2021-07-12 19:30:35,928 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7394208908081055, 2923
[INFO] 2021-07-12 19:30:35,928 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9219998396001756e-05, 2923
[INFO] 2021-07-12 19:30:35,928 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2923
[INFO] 2021-07-12 19:30:35,928 [run_pretraining.py:  558]:	worker_index: 6, step: 2923, cost: 7.739421, mlm loss: 7.739421, speed: 1.096327 steps/s, speed: 8.770612 samples/s, speed: 4490.553347 tokens/s, learning rate: 2.922e-05, loss_scalings: 2814.750488, pp_loss: 7.145862
[INFO] 2021-07-12 19:30:35,928 [run_pretraining.py:  512]:	********exe.run_2923******* 
[INFO] 2021-07-12 19:30:36,870 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:36,871 [run_pretraining.py:  534]:	loss/total_loss, 7.100278854370117, 2924
[INFO] 2021-07-12 19:30:36,871 [run_pretraining.py:  535]:	loss/mlm_loss, 7.100278854370117, 2924
[INFO] 2021-07-12 19:30:36,871 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9229997380753048e-05, 2924
[INFO] 2021-07-12 19:30:36,871 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2924
[INFO] 2021-07-12 19:30:36,871 [run_pretraining.py:  558]:	worker_index: 6, step: 2924, cost: 7.100279, mlm loss: 7.100279, speed: 1.060867 steps/s, speed: 8.486936 samples/s, speed: 4345.310983 tokens/s, learning rate: 2.923e-05, loss_scalings: 2814.750488, pp_loss: 7.090157
[INFO] 2021-07-12 19:30:36,871 [run_pretraining.py:  512]:	********exe.run_2924******* 
[INFO] 2021-07-12 19:30:37,780 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:37,780 [run_pretraining.py:  534]:	loss/total_loss, 4.064154148101807, 2925
[INFO] 2021-07-12 19:30:37,781 [run_pretraining.py:  535]:	loss/mlm_loss, 4.064154148101807, 2925
[INFO] 2021-07-12 19:30:37,781 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9240000003483146e-05, 2925
[INFO] 2021-07-12 19:30:37,781 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2925
[INFO] 2021-07-12 19:30:37,781 [run_pretraining.py:  558]:	worker_index: 6, step: 2925, cost: 4.064154, mlm loss: 4.064154, speed: 1.100202 steps/s, speed: 8.801617 samples/s, speed: 4506.428053 tokens/s, learning rate: 2.924e-05, loss_scalings: 2814.750488, pp_loss: 6.143984
[INFO] 2021-07-12 19:30:37,781 [run_pretraining.py:  512]:	********exe.run_2925******* 
[INFO] 2021-07-12 19:30:38,689 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:38,689 [run_pretraining.py:  534]:	loss/total_loss, 4.0884785652160645, 2926
[INFO] 2021-07-12 19:30:38,689 [run_pretraining.py:  535]:	loss/mlm_loss, 4.0884785652160645, 2926
[INFO] 2021-07-12 19:30:38,690 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9249998988234438e-05, 2926
[INFO] 2021-07-12 19:30:38,690 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2926
[INFO] 2021-07-12 19:30:38,690 [run_pretraining.py:  558]:	worker_index: 6, step: 2926, cost: 4.088479, mlm loss: 4.088479, speed: 1.101037 steps/s, speed: 8.808292 samples/s, speed: 4509.845657 tokens/s, learning rate: 2.925e-05, loss_scalings: 2814.750488, pp_loss: 6.717896
[INFO] 2021-07-12 19:30:38,690 [run_pretraining.py:  512]:	********exe.run_2926******* 
[INFO] 2021-07-12 19:30:39,601 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:39,602 [run_pretraining.py:  534]:	loss/total_loss, 7.5501484870910645, 2927
[INFO] 2021-07-12 19:30:39,602 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5501484870910645, 2927
[INFO] 2021-07-12 19:30:39,602 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9259999791975133e-05, 2927
[INFO] 2021-07-12 19:30:39,602 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2927
[INFO] 2021-07-12 19:30:39,602 [run_pretraining.py:  558]:	worker_index: 6, step: 2927, cost: 7.550148, mlm loss: 7.550148, speed: 1.096605 steps/s, speed: 8.772843 samples/s, speed: 4491.695708 tokens/s, learning rate: 2.926e-05, loss_scalings: 2814.750488, pp_loss: 7.610636
[INFO] 2021-07-12 19:30:39,602 [run_pretraining.py:  512]:	********exe.run_2927******* 
[INFO] 2021-07-12 19:30:40,505 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:40,505 [run_pretraining.py:  534]:	loss/total_loss, 7.3494954109191895, 2928
[INFO] 2021-07-12 19:30:40,505 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3494954109191895, 2928
[INFO] 2021-07-12 19:30:40,505 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9269998776726425e-05, 2928
[INFO] 2021-07-12 19:30:40,506 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2928
[INFO] 2021-07-12 19:30:40,506 [run_pretraining.py:  558]:	worker_index: 6, step: 2928, cost: 7.349495, mlm loss: 7.349495, speed: 1.107880 steps/s, speed: 8.863040 samples/s, speed: 4537.876417 tokens/s, learning rate: 2.927e-05, loss_scalings: 2814.750488, pp_loss: 7.387149
[INFO] 2021-07-12 19:30:40,506 [run_pretraining.py:  512]:	********exe.run_2928******* 
[INFO] 2021-07-12 19:30:41,409 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:41,409 [run_pretraining.py:  534]:	loss/total_loss, 8.189178466796875, 2929
[INFO] 2021-07-12 19:30:41,409 [run_pretraining.py:  535]:	loss/mlm_loss, 8.189178466796875, 2929
[INFO] 2021-07-12 19:30:41,409 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.927999958046712e-05, 2929
[INFO] 2021-07-12 19:30:41,409 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2929
[INFO] 2021-07-12 19:30:41,409 [run_pretraining.py:  558]:	worker_index: 6, step: 2929, cost: 8.189178, mlm loss: 8.189178, speed: 1.107259 steps/s, speed: 8.858073 samples/s, speed: 4535.333150 tokens/s, learning rate: 2.928e-05, loss_scalings: 2814.750488, pp_loss: 7.700884
[INFO] 2021-07-12 19:30:41,410 [run_pretraining.py:  512]:	********exe.run_2929******* 
[INFO] 2021-07-12 19:30:42,323 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:42,324 [run_pretraining.py:  534]:	loss/total_loss, 7.462821006774902, 2930
[INFO] 2021-07-12 19:30:42,324 [run_pretraining.py:  535]:	loss/mlm_loss, 7.462821006774902, 2930
[INFO] 2021-07-12 19:30:42,324 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.928999856521841e-05, 2930
[INFO] 2021-07-12 19:30:42,325 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2930
[INFO] 2021-07-12 19:30:42,325 [run_pretraining.py:  558]:	worker_index: 6, step: 2930, cost: 7.462821, mlm loss: 7.462821, speed: 1.093669 steps/s, speed: 8.749355 samples/s, speed: 4479.669676 tokens/s, learning rate: 2.929e-05, loss_scalings: 2814.750488, pp_loss: 7.112923
[INFO] 2021-07-12 19:30:42,325 [run_pretraining.py:  512]:	********exe.run_2930******* 
[INFO] 2021-07-12 19:30:43,236 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:43,237 [run_pretraining.py:  534]:	loss/total_loss, 6.910828590393066, 2931
[INFO] 2021-07-12 19:30:43,237 [run_pretraining.py:  535]:	loss/mlm_loss, 6.910828590393066, 2931
[INFO] 2021-07-12 19:30:43,237 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.930000118794851e-05, 2931
[INFO] 2021-07-12 19:30:43,237 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2931
[INFO] 2021-07-12 19:30:43,237 [run_pretraining.py:  558]:	worker_index: 6, step: 2931, cost: 6.910829, mlm loss: 6.910829, speed: 1.097173 steps/s, speed: 8.777382 samples/s, speed: 4494.019791 tokens/s, learning rate: 2.930e-05, loss_scalings: 2814.750488, pp_loss: 7.116307
[INFO] 2021-07-12 19:30:43,237 [run_pretraining.py:  512]:	********exe.run_2931******* 
[INFO] 2021-07-12 19:30:44,140 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:44,141 [run_pretraining.py:  534]:	loss/total_loss, 7.352125644683838, 2932
[INFO] 2021-07-12 19:30:44,141 [run_pretraining.py:  535]:	loss/mlm_loss, 7.352125644683838, 2932
[INFO] 2021-07-12 19:30:44,141 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9309998353710398e-05, 2932
[INFO] 2021-07-12 19:30:44,141 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2932
[INFO] 2021-07-12 19:30:44,141 [run_pretraining.py:  558]:	worker_index: 6, step: 2932, cost: 7.352126, mlm loss: 7.352126, speed: 1.107195 steps/s, speed: 8.857563 samples/s, speed: 4535.072156 tokens/s, learning rate: 2.931e-05, loss_scalings: 2814.750488, pp_loss: 7.457266
[INFO] 2021-07-12 19:30:44,141 [run_pretraining.py:  512]:	********exe.run_2932******* 
[INFO] 2021-07-12 19:30:45,046 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:45,046 [run_pretraining.py:  534]:	loss/total_loss, 7.365111351013184, 2933
[INFO] 2021-07-12 19:30:45,046 [run_pretraining.py:  535]:	loss/mlm_loss, 7.365111351013184, 2933
[INFO] 2021-07-12 19:30:45,046 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.931999733846169e-05, 2933
[INFO] 2021-07-12 19:30:45,047 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2933
[INFO] 2021-07-12 19:30:45,047 [run_pretraining.py:  558]:	worker_index: 6, step: 2933, cost: 7.365111, mlm loss: 7.365111, speed: 1.105361 steps/s, speed: 8.842887 samples/s, speed: 4527.558145 tokens/s, learning rate: 2.932e-05, loss_scalings: 2814.750488, pp_loss: 6.512003
[INFO] 2021-07-12 19:30:45,047 [run_pretraining.py:  512]:	********exe.run_2933******* 
[INFO] 2021-07-12 19:30:45,952 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:45,952 [run_pretraining.py:  534]:	loss/total_loss, 6.845751762390137, 2934
[INFO] 2021-07-12 19:30:45,952 [run_pretraining.py:  535]:	loss/mlm_loss, 6.845751762390137, 2934
[INFO] 2021-07-12 19:30:45,953 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.932999996119179e-05, 2934
[INFO] 2021-07-12 19:30:45,953 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2934
[INFO] 2021-07-12 19:30:45,953 [run_pretraining.py:  558]:	worker_index: 6, step: 2934, cost: 6.845752, mlm loss: 6.845752, speed: 1.104450 steps/s, speed: 8.835601 samples/s, speed: 4523.827741 tokens/s, learning rate: 2.933e-05, loss_scalings: 2814.750488, pp_loss: 7.140923
[INFO] 2021-07-12 19:30:45,953 [run_pretraining.py:  512]:	********exe.run_2934******* 
[INFO] 2021-07-12 19:30:46,852 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:46,853 [run_pretraining.py:  534]:	loss/total_loss, 7.521824836730957, 2935
[INFO] 2021-07-12 19:30:46,853 [run_pretraining.py:  535]:	loss/mlm_loss, 7.521824836730957, 2935
[INFO] 2021-07-12 19:30:46,853 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.933999894594308e-05, 2935
[INFO] 2021-07-12 19:30:46,853 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2935
[INFO] 2021-07-12 19:30:46,853 [run_pretraining.py:  558]:	worker_index: 6, step: 2935, cost: 7.521825, mlm loss: 7.521825, speed: 1.111125 steps/s, speed: 8.888999 samples/s, speed: 4551.167294 tokens/s, learning rate: 2.934e-05, loss_scalings: 2814.750488, pp_loss: 7.214005
[INFO] 2021-07-12 19:30:46,854 [run_pretraining.py:  512]:	********exe.run_2935******* 
[INFO] 2021-07-12 19:30:47,763 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:47,764 [run_pretraining.py:  534]:	loss/total_loss, 7.208434104919434, 2936
[INFO] 2021-07-12 19:30:47,764 [run_pretraining.py:  535]:	loss/mlm_loss, 7.208434104919434, 2936
[INFO] 2021-07-12 19:30:47,764 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9349999749683775e-05, 2936
[INFO] 2021-07-12 19:30:47,764 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2936
[INFO] 2021-07-12 19:30:47,764 [run_pretraining.py:  558]:	worker_index: 6, step: 2936, cost: 7.208434, mlm loss: 7.208434, speed: 1.098704 steps/s, speed: 8.789628 samples/s, speed: 4500.289635 tokens/s, learning rate: 2.935e-05, loss_scalings: 2814.750488, pp_loss: 7.325320
[INFO] 2021-07-12 19:30:47,764 [run_pretraining.py:  512]:	********exe.run_2936******* 
[INFO] 2021-07-12 19:30:48,670 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:48,670 [run_pretraining.py:  534]:	loss/total_loss, 7.335033893585205, 2937
[INFO] 2021-07-12 19:30:48,670 [run_pretraining.py:  535]:	loss/mlm_loss, 7.335033893585205, 2937
[INFO] 2021-07-12 19:30:48,670 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9359998734435067e-05, 2937
[INFO] 2021-07-12 19:30:48,670 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2937
[INFO] 2021-07-12 19:30:48,671 [run_pretraining.py:  558]:	worker_index: 6, step: 2937, cost: 7.335034, mlm loss: 7.335034, speed: 1.104278 steps/s, speed: 8.834222 samples/s, speed: 4523.121458 tokens/s, learning rate: 2.936e-05, loss_scalings: 2814.750488, pp_loss: 7.360868
[INFO] 2021-07-12 19:30:48,671 [run_pretraining.py:  512]:	********exe.run_2937******* 
[INFO] 2021-07-12 19:30:49,575 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:49,576 [run_pretraining.py:  534]:	loss/total_loss, 8.91910457611084, 2938
[INFO] 2021-07-12 19:30:49,576 [run_pretraining.py:  535]:	loss/mlm_loss, 8.91910457611084, 2938
[INFO] 2021-07-12 19:30:49,576 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9369999538175762e-05, 2938
[INFO] 2021-07-12 19:30:49,576 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2938
[INFO] 2021-07-12 19:30:49,576 [run_pretraining.py:  558]:	worker_index: 6, step: 2938, cost: 8.919105, mlm loss: 8.919105, speed: 1.105193 steps/s, speed: 8.841540 samples/s, speed: 4526.868588 tokens/s, learning rate: 2.937e-05, loss_scalings: 2814.750488, pp_loss: 7.775162
[INFO] 2021-07-12 19:30:49,576 [run_pretraining.py:  512]:	********exe.run_2938******* 
[INFO] 2021-07-12 19:30:50,472 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:50,473 [run_pretraining.py:  534]:	loss/total_loss, 7.009862422943115, 2939
[INFO] 2021-07-12 19:30:50,473 [run_pretraining.py:  535]:	loss/mlm_loss, 7.009862422943115, 2939
[INFO] 2021-07-12 19:30:50,473 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9379998522927053e-05, 2939
[INFO] 2021-07-12 19:30:50,473 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2939
[INFO] 2021-07-12 19:30:50,473 [run_pretraining.py:  558]:	worker_index: 6, step: 2939, cost: 7.009862, mlm loss: 7.009862, speed: 1.115295 steps/s, speed: 8.922364 samples/s, speed: 4568.250308 tokens/s, learning rate: 2.938e-05, loss_scalings: 2814.750488, pp_loss: 7.278554
[INFO] 2021-07-12 19:30:50,474 [run_pretraining.py:  512]:	********exe.run_2939******* 
[INFO] 2021-07-12 19:30:51,372 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:51,372 [run_pretraining.py:  534]:	loss/total_loss, 7.277532577514648, 2940
[INFO] 2021-07-12 19:30:51,372 [run_pretraining.py:  535]:	loss/mlm_loss, 7.277532577514648, 2940
[INFO] 2021-07-12 19:30:51,373 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9390001145657152e-05, 2940
[INFO] 2021-07-12 19:30:51,373 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2940
[INFO] 2021-07-12 19:30:51,373 [run_pretraining.py:  558]:	worker_index: 6, step: 2940, cost: 7.277533, mlm loss: 7.277533, speed: 1.112887 steps/s, speed: 8.903098 samples/s, speed: 4558.386177 tokens/s, learning rate: 2.939e-05, loss_scalings: 2814.750488, pp_loss: 6.140297
[INFO] 2021-07-12 19:30:51,373 [run_pretraining.py:  512]:	********exe.run_2940******* 
[INFO] 2021-07-12 19:30:52,283 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:52,284 [run_pretraining.py:  534]:	loss/total_loss, 6.996011734008789, 2941
[INFO] 2021-07-12 19:30:52,284 [run_pretraining.py:  535]:	loss/mlm_loss, 6.996011734008789, 2941
[INFO] 2021-07-12 19:30:52,284 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9400000130408444e-05, 2941
[INFO] 2021-07-12 19:30:52,284 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2941
[INFO] 2021-07-12 19:30:52,284 [run_pretraining.py:  558]:	worker_index: 6, step: 2941, cost: 6.996012, mlm loss: 6.996012, speed: 1.098087 steps/s, speed: 8.784697 samples/s, speed: 4497.764762 tokens/s, learning rate: 2.940e-05, loss_scalings: 2814.750488, pp_loss: 7.377470
[INFO] 2021-07-12 19:30:52,284 [run_pretraining.py:  512]:	********exe.run_2941******* 
[INFO] 2021-07-12 19:30:53,196 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:53,197 [run_pretraining.py:  534]:	loss/total_loss, 8.480048179626465, 2942
[INFO] 2021-07-12 19:30:53,197 [run_pretraining.py:  535]:	loss/mlm_loss, 8.480048179626465, 2942
[INFO] 2021-07-12 19:30:53,197 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.940999729617033e-05, 2942
[INFO] 2021-07-12 19:30:53,197 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2942
[INFO] 2021-07-12 19:30:53,197 [run_pretraining.py:  558]:	worker_index: 6, step: 2942, cost: 8.480048, mlm loss: 8.480048, speed: 1.096068 steps/s, speed: 8.768540 samples/s, speed: 4489.492517 tokens/s, learning rate: 2.941e-05, loss_scalings: 2814.750488, pp_loss: 7.433755
[INFO] 2021-07-12 19:30:53,197 [run_pretraining.py:  512]:	********exe.run_2942******* 
[INFO] 2021-07-12 19:30:54,104 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:54,104 [run_pretraining.py:  534]:	loss/total_loss, 7.155664920806885, 2943
[INFO] 2021-07-12 19:30:54,104 [run_pretraining.py:  535]:	loss/mlm_loss, 7.155664920806885, 2943
[INFO] 2021-07-12 19:30:54,105 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.941999991890043e-05, 2943
[INFO] 2021-07-12 19:30:54,105 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2943
[INFO] 2021-07-12 19:30:54,105 [run_pretraining.py:  558]:	worker_index: 6, step: 2943, cost: 7.155665, mlm loss: 7.155665, speed: 1.102616 steps/s, speed: 8.820926 samples/s, speed: 4516.314109 tokens/s, learning rate: 2.942e-05, loss_scalings: 2814.750488, pp_loss: 7.229942
[INFO] 2021-07-12 19:30:54,105 [run_pretraining.py:  512]:	********exe.run_2943******* 
[INFO] 2021-07-12 19:30:55,002 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:55,003 [run_pretraining.py:  534]:	loss/total_loss, 7.854755401611328, 2944
[INFO] 2021-07-12 19:30:55,003 [run_pretraining.py:  535]:	loss/mlm_loss, 7.854755401611328, 2944
[INFO] 2021-07-12 19:30:55,003 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9429998903651722e-05, 2944
[INFO] 2021-07-12 19:30:55,003 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2944
[INFO] 2021-07-12 19:30:55,003 [run_pretraining.py:  558]:	worker_index: 6, step: 2944, cost: 7.854755, mlm loss: 7.854755, speed: 1.113911 steps/s, speed: 8.911291 samples/s, speed: 4562.580917 tokens/s, learning rate: 2.943e-05, loss_scalings: 2814.750488, pp_loss: 7.510677
[INFO] 2021-07-12 19:30:55,003 [run_pretraining.py:  512]:	********exe.run_2944******* 
[INFO] 2021-07-12 19:30:55,904 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:55,905 [run_pretraining.py:  534]:	loss/total_loss, 7.564827919006348, 2945
[INFO] 2021-07-12 19:30:55,905 [run_pretraining.py:  535]:	loss/mlm_loss, 7.564827919006348, 2945
[INFO] 2021-07-12 19:30:55,905 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9439999707392417e-05, 2945
[INFO] 2021-07-12 19:30:55,905 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2945
[INFO] 2021-07-12 19:30:55,905 [run_pretraining.py:  558]:	worker_index: 6, step: 2945, cost: 7.564828, mlm loss: 7.564828, speed: 1.109798 steps/s, speed: 8.878384 samples/s, speed: 4545.732637 tokens/s, learning rate: 2.944e-05, loss_scalings: 2814.750488, pp_loss: 7.703026
[INFO] 2021-07-12 19:30:55,905 [run_pretraining.py:  512]:	********exe.run_2945******* 
[INFO] 2021-07-12 19:30:56,813 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:56,814 [run_pretraining.py:  534]:	loss/total_loss, 6.637833595275879, 2946
[INFO] 2021-07-12 19:30:56,814 [run_pretraining.py:  535]:	loss/mlm_loss, 6.637833595275879, 2946
[INFO] 2021-07-12 19:30:56,814 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.944999869214371e-05, 2946
[INFO] 2021-07-12 19:30:56,814 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2946
[INFO] 2021-07-12 19:30:56,814 [run_pretraining.py:  558]:	worker_index: 6, step: 2946, cost: 6.637834, mlm loss: 6.637834, speed: 1.100835 steps/s, speed: 8.806681 samples/s, speed: 4509.020652 tokens/s, learning rate: 2.945e-05, loss_scalings: 2814.750488, pp_loss: 7.064262
[INFO] 2021-07-12 19:30:56,814 [run_pretraining.py:  512]:	********exe.run_2946******* 
[INFO] 2021-07-12 19:30:57,711 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:57,711 [run_pretraining.py:  534]:	loss/total_loss, 7.474094390869141, 2947
[INFO] 2021-07-12 19:30:57,712 [run_pretraining.py:  535]:	loss/mlm_loss, 7.474094390869141, 2947
[INFO] 2021-07-12 19:30:57,712 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9459999495884404e-05, 2947
[INFO] 2021-07-12 19:30:57,712 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2947
[INFO] 2021-07-12 19:30:57,712 [run_pretraining.py:  558]:	worker_index: 6, step: 2947, cost: 7.474094, mlm loss: 7.474094, speed: 1.114687 steps/s, speed: 8.917493 samples/s, speed: 4565.756614 tokens/s, learning rate: 2.946e-05, loss_scalings: 2814.750488, pp_loss: 7.293526
[INFO] 2021-07-12 19:30:57,712 [run_pretraining.py:  512]:	********exe.run_2947******* 
[INFO] 2021-07-12 19:30:58,618 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:58,618 [run_pretraining.py:  534]:	loss/total_loss, 7.252749443054199, 2948
[INFO] 2021-07-12 19:30:58,618 [run_pretraining.py:  535]:	loss/mlm_loss, 7.252749443054199, 2948
[INFO] 2021-07-12 19:30:58,619 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9469998480635695e-05, 2948
[INFO] 2021-07-12 19:30:58,619 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2948
[INFO] 2021-07-12 19:30:58,619 [run_pretraining.py:  558]:	worker_index: 6, step: 2948, cost: 7.252749, mlm loss: 7.252749, speed: 1.103537 steps/s, speed: 8.828297 samples/s, speed: 4520.088020 tokens/s, learning rate: 2.947e-05, loss_scalings: 2814.750488, pp_loss: 7.070380
[INFO] 2021-07-12 19:30:58,619 [run_pretraining.py:  512]:	********exe.run_2948******* 
[INFO] 2021-07-12 19:30:59,518 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:59,518 [run_pretraining.py:  534]:	loss/total_loss, 7.037693023681641, 2949
[INFO] 2021-07-12 19:30:59,519 [run_pretraining.py:  535]:	loss/mlm_loss, 7.037693023681641, 2949
[INFO] 2021-07-12 19:30:59,519 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9480001103365794e-05, 2949
[INFO] 2021-07-12 19:30:59,519 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2949
[INFO] 2021-07-12 19:30:59,519 [run_pretraining.py:  558]:	worker_index: 6, step: 2949, cost: 7.037693, mlm loss: 7.037693, speed: 1.111867 steps/s, speed: 8.894937 samples/s, speed: 4554.207593 tokens/s, learning rate: 2.948e-05, loss_scalings: 2814.750488, pp_loss: 7.403929
[INFO] 2021-07-12 19:30:59,519 [run_pretraining.py:  512]:	********exe.run_2949******* 
[INFO] 2021-07-12 19:31:00,425 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:00,425 [run_pretraining.py:  534]:	loss/total_loss, 7.57911491394043, 2950
[INFO] 2021-07-12 19:31:00,425 [run_pretraining.py:  535]:	loss/mlm_loss, 7.57911491394043, 2950
[INFO] 2021-07-12 19:31:00,426 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9490000088117085e-05, 2950
[INFO] 2021-07-12 19:31:00,426 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2950
[INFO] 2021-07-12 19:31:00,426 [run_pretraining.py:  558]:	worker_index: 6, step: 2950, cost: 7.579115, mlm loss: 7.579115, speed: 1.103523 steps/s, speed: 8.828183 samples/s, speed: 4520.029747 tokens/s, learning rate: 2.949e-05, loss_scalings: 2814.750488, pp_loss: 7.622707
[INFO] 2021-07-12 19:31:00,426 [run_pretraining.py:  512]:	********exe.run_2950******* 
[INFO] 2021-07-12 19:31:01,370 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:01,370 [run_pretraining.py:  534]:	loss/total_loss, 7.346634864807129, 2951
[INFO] 2021-07-12 19:31:01,370 [run_pretraining.py:  535]:	loss/mlm_loss, 7.346634864807129, 2951
[INFO] 2021-07-12 19:31:01,370 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9499997253878973e-05, 2951
[INFO] 2021-07-12 19:31:01,371 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2951
[INFO] 2021-07-12 19:31:01,371 [run_pretraining.py:  558]:	worker_index: 6, step: 2951, cost: 7.346635, mlm loss: 7.346635, speed: 1.059128 steps/s, speed: 8.473027 samples/s, speed: 4338.189765 tokens/s, learning rate: 2.950e-05, loss_scalings: 2814.750488, pp_loss: 7.396094
[INFO] 2021-07-12 19:31:01,371 [run_pretraining.py:  512]:	********exe.run_2951******* 
[INFO] 2021-07-12 19:31:02,279 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:02,280 [run_pretraining.py:  534]:	loss/total_loss, 6.728887557983398, 2952
[INFO] 2021-07-12 19:31:02,280 [run_pretraining.py:  535]:	loss/mlm_loss, 6.728887557983398, 2952
[INFO] 2021-07-12 19:31:02,280 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9509999876609072e-05, 2952
[INFO] 2021-07-12 19:31:02,280 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2952
[INFO] 2021-07-12 19:31:02,280 [run_pretraining.py:  558]:	worker_index: 6, step: 2952, cost: 6.728888, mlm loss: 6.728888, speed: 1.100275 steps/s, speed: 8.802197 samples/s, speed: 4506.724773 tokens/s, learning rate: 2.951e-05, loss_scalings: 2814.750488, pp_loss: 7.241235
[INFO] 2021-07-12 19:31:02,280 [run_pretraining.py:  512]:	********exe.run_2952******* 
[INFO] 2021-07-12 19:31:03,184 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:03,184 [run_pretraining.py:  534]:	loss/total_loss, 7.609445095062256, 2953
[INFO] 2021-07-12 19:31:03,184 [run_pretraining.py:  535]:	loss/mlm_loss, 7.609445095062256, 2953
[INFO] 2021-07-12 19:31:03,184 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9519998861360364e-05, 2953
[INFO] 2021-07-12 19:31:03,184 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2953
[INFO] 2021-07-12 19:31:03,184 [run_pretraining.py:  558]:	worker_index: 6, step: 2953, cost: 7.609445, mlm loss: 7.609445, speed: 1.106653 steps/s, speed: 8.853228 samples/s, speed: 4532.852530 tokens/s, learning rate: 2.952e-05, loss_scalings: 2814.750488, pp_loss: 7.688468
[INFO] 2021-07-12 19:31:03,185 [run_pretraining.py:  512]:	********exe.run_2953******* 
[INFO] 2021-07-12 19:31:04,084 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:04,085 [run_pretraining.py:  534]:	loss/total_loss, 7.252612113952637, 2954
[INFO] 2021-07-12 19:31:04,085 [run_pretraining.py:  535]:	loss/mlm_loss, 7.252612113952637, 2954
[INFO] 2021-07-12 19:31:04,085 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.952999966510106e-05, 2954
[INFO] 2021-07-12 19:31:04,085 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2954
[INFO] 2021-07-12 19:31:04,085 [run_pretraining.py:  558]:	worker_index: 6, step: 2954, cost: 7.252612, mlm loss: 7.252612, speed: 1.111038 steps/s, speed: 8.888302 samples/s, speed: 4550.810446 tokens/s, learning rate: 2.953e-05, loss_scalings: 2814.750488, pp_loss: 7.346515
[INFO] 2021-07-12 19:31:04,085 [run_pretraining.py:  512]:	********exe.run_2954******* 
[INFO] 2021-07-12 19:31:04,979 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:04,980 [run_pretraining.py:  534]:	loss/total_loss, 7.282792091369629, 2955
[INFO] 2021-07-12 19:31:04,980 [run_pretraining.py:  535]:	loss/mlm_loss, 7.282792091369629, 2955
[INFO] 2021-07-12 19:31:04,980 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.953999864985235e-05, 2955
[INFO] 2021-07-12 19:31:04,980 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2955
[INFO] 2021-07-12 19:31:04,980 [run_pretraining.py:  558]:	worker_index: 6, step: 2955, cost: 7.282792, mlm loss: 7.282792, speed: 1.118595 steps/s, speed: 8.948763 samples/s, speed: 4581.766400 tokens/s, learning rate: 2.954e-05, loss_scalings: 2814.750488, pp_loss: 7.318035
[INFO] 2021-07-12 19:31:04,980 [run_pretraining.py:  512]:	********exe.run_2955******* 
[INFO] 2021-07-12 19:31:05,889 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:05,890 [run_pretraining.py:  534]:	loss/total_loss, 6.8682756423950195, 2956
[INFO] 2021-07-12 19:31:05,890 [run_pretraining.py:  535]:	loss/mlm_loss, 6.8682756423950195, 2956
[INFO] 2021-07-12 19:31:05,890 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9549999453593045e-05, 2956
[INFO] 2021-07-12 19:31:05,890 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2956
[INFO] 2021-07-12 19:31:05,890 [run_pretraining.py:  558]:	worker_index: 6, step: 2956, cost: 6.868276, mlm loss: 6.868276, speed: 1.099517 steps/s, speed: 8.796133 samples/s, speed: 4503.620011 tokens/s, learning rate: 2.955e-05, loss_scalings: 2814.750488, pp_loss: 7.181324
[INFO] 2021-07-12 19:31:05,890 [run_pretraining.py:  512]:	********exe.run_2956******* 
[INFO] 2021-07-12 19:31:06,798 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:06,798 [run_pretraining.py:  534]:	loss/total_loss, 7.066347599029541, 2957
[INFO] 2021-07-12 19:31:06,799 [run_pretraining.py:  535]:	loss/mlm_loss, 7.066347599029541, 2957
[INFO] 2021-07-12 19:31:06,799 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9559998438344337e-05, 2957
[INFO] 2021-07-12 19:31:06,799 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2957
[INFO] 2021-07-12 19:31:06,799 [run_pretraining.py:  558]:	worker_index: 6, step: 2957, cost: 7.066348, mlm loss: 7.066348, speed: 1.101354 steps/s, speed: 8.810832 samples/s, speed: 4511.145920 tokens/s, learning rate: 2.956e-05, loss_scalings: 2814.750488, pp_loss: 7.395841
[INFO] 2021-07-12 19:31:06,799 [run_pretraining.py:  512]:	********exe.run_2957******* 
[INFO] 2021-07-12 19:31:07,708 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:07,709 [run_pretraining.py:  534]:	loss/total_loss, 7.454550743103027, 2958
[INFO] 2021-07-12 19:31:07,709 [run_pretraining.py:  535]:	loss/mlm_loss, 7.454550743103027, 2958
[INFO] 2021-07-12 19:31:07,709 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9570001061074436e-05, 2958
[INFO] 2021-07-12 19:31:07,709 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2958
[INFO] 2021-07-12 19:31:07,709 [run_pretraining.py:  558]:	worker_index: 6, step: 2958, cost: 7.454551, mlm loss: 7.454551, speed: 1.099424 steps/s, speed: 8.795393 samples/s, speed: 4503.241070 tokens/s, learning rate: 2.957e-05, loss_scalings: 2814.750488, pp_loss: 7.144539
[INFO] 2021-07-12 19:31:07,709 [run_pretraining.py:  512]:	********exe.run_2958******* 
[INFO] 2021-07-12 19:31:08,616 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:08,617 [run_pretraining.py:  534]:	loss/total_loss, 4.599092960357666, 2959
[INFO] 2021-07-12 19:31:08,617 [run_pretraining.py:  535]:	loss/mlm_loss, 4.599092960357666, 2959
[INFO] 2021-07-12 19:31:08,617 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9580000045825727e-05, 2959
[INFO] 2021-07-12 19:31:08,617 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2959
[INFO] 2021-07-12 19:31:08,617 [run_pretraining.py:  558]:	worker_index: 6, step: 2959, cost: 4.599093, mlm loss: 4.599093, speed: 1.102012 steps/s, speed: 8.816096 samples/s, speed: 4513.841199 tokens/s, learning rate: 2.958e-05, loss_scalings: 2814.750488, pp_loss: 6.574607
[INFO] 2021-07-12 19:31:08,617 [run_pretraining.py:  512]:	********exe.run_2959******* 
[INFO] 2021-07-12 19:31:09,527 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:09,528 [run_pretraining.py:  534]:	loss/total_loss, 7.2684431076049805, 2960
[INFO] 2021-07-12 19:31:09,528 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2684431076049805, 2960
[INFO] 2021-07-12 19:31:09,528 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9589997211587615e-05, 2960
[INFO] 2021-07-12 19:31:09,528 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2960
[INFO] 2021-07-12 19:31:09,528 [run_pretraining.py:  558]:	worker_index: 6, step: 2960, cost: 7.268443, mlm loss: 7.268443, speed: 1.098664 steps/s, speed: 8.789308 samples/s, speed: 4500.125780 tokens/s, learning rate: 2.959e-05, loss_scalings: 2814.750488, pp_loss: 7.023829
[INFO] 2021-07-12 19:31:09,528 [run_pretraining.py:  512]:	********exe.run_2960******* 
[INFO] 2021-07-12 19:31:10,436 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:10,436 [run_pretraining.py:  534]:	loss/total_loss, 6.990827560424805, 2961
[INFO] 2021-07-12 19:31:10,436 [run_pretraining.py:  535]:	loss/mlm_loss, 6.990827560424805, 2961
[INFO] 2021-07-12 19:31:10,436 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9599999834317714e-05, 2961
[INFO] 2021-07-12 19:31:10,437 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2961
[INFO] 2021-07-12 19:31:10,437 [run_pretraining.py:  558]:	worker_index: 6, step: 2961, cost: 6.990828, mlm loss: 6.990828, speed: 1.101581 steps/s, speed: 8.812648 samples/s, speed: 4512.075984 tokens/s, learning rate: 2.960e-05, loss_scalings: 2814.750488, pp_loss: 7.205901
[INFO] 2021-07-12 19:31:10,437 [run_pretraining.py:  512]:	********exe.run_2961******* 
[INFO] 2021-07-12 19:31:11,344 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:11,344 [run_pretraining.py:  534]:	loss/total_loss, 7.222898960113525, 2962
[INFO] 2021-07-12 19:31:11,344 [run_pretraining.py:  535]:	loss/mlm_loss, 7.222898960113525, 2962
[INFO] 2021-07-12 19:31:11,344 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9609998819069006e-05, 2962
[INFO] 2021-07-12 19:31:11,345 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2962
[INFO] 2021-07-12 19:31:11,345 [run_pretraining.py:  558]:	worker_index: 6, step: 2962, cost: 7.222899, mlm loss: 7.222899, speed: 1.102232 steps/s, speed: 8.817855 samples/s, speed: 4514.741528 tokens/s, learning rate: 2.961e-05, loss_scalings: 2814.750488, pp_loss: 6.845841
[INFO] 2021-07-12 19:31:11,345 [run_pretraining.py:  512]:	********exe.run_2962******* 
[INFO] 2021-07-12 19:31:12,255 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:12,256 [run_pretraining.py:  534]:	loss/total_loss, 7.380647659301758, 2963
[INFO] 2021-07-12 19:31:12,256 [run_pretraining.py:  535]:	loss/mlm_loss, 7.380647659301758, 2963
[INFO] 2021-07-12 19:31:12,256 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.96199996228097e-05, 2963
[INFO] 2021-07-12 19:31:12,256 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2963
[INFO] 2021-07-12 19:31:12,256 [run_pretraining.py:  558]:	worker_index: 6, step: 2963, cost: 7.380648, mlm loss: 7.380648, speed: 1.097917 steps/s, speed: 8.783338 samples/s, speed: 4497.068947 tokens/s, learning rate: 2.962e-05, loss_scalings: 2814.750488, pp_loss: 7.334878
[INFO] 2021-07-12 19:31:12,256 [run_pretraining.py:  512]:	********exe.run_2963******* 
[INFO] 2021-07-12 19:31:13,165 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:13,165 [run_pretraining.py:  534]:	loss/total_loss, 6.924816131591797, 2964
[INFO] 2021-07-12 19:31:13,165 [run_pretraining.py:  535]:	loss/mlm_loss, 6.924816131591797, 2964
[INFO] 2021-07-12 19:31:13,165 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9629998607560992e-05, 2964
[INFO] 2021-07-12 19:31:13,165 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2964
[INFO] 2021-07-12 19:31:13,166 [run_pretraining.py:  558]:	worker_index: 6, step: 2964, cost: 6.924816, mlm loss: 6.924816, speed: 1.100444 steps/s, speed: 8.803555 samples/s, speed: 4507.420032 tokens/s, learning rate: 2.963e-05, loss_scalings: 2814.750488, pp_loss: 7.145351
[INFO] 2021-07-12 19:31:13,166 [run_pretraining.py:  512]:	********exe.run_2964******* 
[INFO] 2021-07-12 19:31:14,067 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:14,068 [run_pretraining.py:  534]:	loss/total_loss, 7.242124557495117, 2965
[INFO] 2021-07-12 19:31:14,068 [run_pretraining.py:  535]:	loss/mlm_loss, 7.242124557495117, 2965
[INFO] 2021-07-12 19:31:14,068 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9639999411301687e-05, 2965
[INFO] 2021-07-12 19:31:14,068 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2965
[INFO] 2021-07-12 19:31:14,068 [run_pretraining.py:  558]:	worker_index: 6, step: 2965, cost: 7.242125, mlm loss: 7.242125, speed: 1.109079 steps/s, speed: 8.872630 samples/s, speed: 4542.786522 tokens/s, learning rate: 2.964e-05, loss_scalings: 2814.750488, pp_loss: 7.661501
[INFO] 2021-07-12 19:31:14,068 [run_pretraining.py:  512]:	********exe.run_2965******* 
[INFO] 2021-07-12 19:31:14,972 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:14,973 [run_pretraining.py:  534]:	loss/total_loss, 6.959627151489258, 2966
[INFO] 2021-07-12 19:31:14,973 [run_pretraining.py:  535]:	loss/mlm_loss, 6.959627151489258, 2966
[INFO] 2021-07-12 19:31:14,973 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.964999839605298e-05, 2966
[INFO] 2021-07-12 19:31:14,973 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2966
[INFO] 2021-07-12 19:31:14,973 [run_pretraining.py:  558]:	worker_index: 6, step: 2966, cost: 6.959627, mlm loss: 6.959627, speed: 1.105679 steps/s, speed: 8.845430 samples/s, speed: 4528.860285 tokens/s, learning rate: 2.965e-05, loss_scalings: 2814.750488, pp_loss: 7.563588
[INFO] 2021-07-12 19:31:14,973 [run_pretraining.py:  512]:	********exe.run_2966******* 
[INFO] 2021-07-12 19:31:15,887 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:15,888 [run_pretraining.py:  534]:	loss/total_loss, 7.38575553894043, 2967
[INFO] 2021-07-12 19:31:15,888 [run_pretraining.py:  535]:	loss/mlm_loss, 7.38575553894043, 2967
[INFO] 2021-07-12 19:31:15,888 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9660001018783078e-05, 2967
[INFO] 2021-07-12 19:31:15,888 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2967
[INFO] 2021-07-12 19:31:15,888 [run_pretraining.py:  558]:	worker_index: 6, step: 2967, cost: 7.385756, mlm loss: 7.385756, speed: 1.093347 steps/s, speed: 8.746780 samples/s, speed: 4478.351304 tokens/s, learning rate: 2.966e-05, loss_scalings: 2814.750488, pp_loss: 7.323535
[INFO] 2021-07-12 19:31:15,888 [run_pretraining.py:  512]:	********exe.run_2967******* 
[INFO] 2021-07-12 19:31:16,816 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:16,817 [run_pretraining.py:  534]:	loss/total_loss, 6.891241073608398, 2968
[INFO] 2021-07-12 19:31:16,817 [run_pretraining.py:  535]:	loss/mlm_loss, 6.891241073608398, 2968
[INFO] 2021-07-12 19:31:16,817 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.967000000353437e-05, 2968
[INFO] 2021-07-12 19:31:16,817 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2968
[INFO] 2021-07-12 19:31:16,817 [run_pretraining.py:  558]:	worker_index: 6, step: 2968, cost: 6.891241, mlm loss: 6.891241, speed: 1.077756 steps/s, speed: 8.622048 samples/s, speed: 4414.488468 tokens/s, learning rate: 2.967e-05, loss_scalings: 2814.750488, pp_loss: 7.195205
[INFO] 2021-07-12 19:31:16,817 [run_pretraining.py:  512]:	********exe.run_2968******* 
[INFO] 2021-07-12 19:31:17,873 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:17,874 [run_pretraining.py:  534]:	loss/total_loss, 6.298374176025391, 2969
[INFO] 2021-07-12 19:31:17,874 [run_pretraining.py:  535]:	loss/mlm_loss, 6.298374176025391, 2969
[INFO] 2021-07-12 19:31:17,874 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9679997169296257e-05, 2969
[INFO] 2021-07-12 19:31:17,874 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2969
[INFO] 2021-07-12 19:31:17,874 [run_pretraining.py:  558]:	worker_index: 6, step: 2969, cost: 6.298374, mlm loss: 6.298374, speed: 0.946654 steps/s, speed: 7.573230 samples/s, speed: 3877.493997 tokens/s, learning rate: 2.968e-05, loss_scalings: 2814.750488, pp_loss: 7.140579
[INFO] 2021-07-12 19:31:17,874 [run_pretraining.py:  512]:	********exe.run_2969******* 
[INFO] 2021-07-12 19:31:18,934 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:18,935 [run_pretraining.py:  534]:	loss/total_loss, 7.246201515197754, 2970
[INFO] 2021-07-12 19:31:18,935 [run_pretraining.py:  535]:	loss/mlm_loss, 7.246201515197754, 2970
[INFO] 2021-07-12 19:31:18,935 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9689999792026356e-05, 2970
[INFO] 2021-07-12 19:31:18,935 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2970
[INFO] 2021-07-12 19:31:18,935 [run_pretraining.py:  558]:	worker_index: 6, step: 2970, cost: 7.246202, mlm loss: 7.246202, speed: 0.943202 steps/s, speed: 7.545614 samples/s, speed: 3863.354317 tokens/s, learning rate: 2.969e-05, loss_scalings: 2814.750488, pp_loss: 7.032880
[INFO] 2021-07-12 19:31:18,935 [run_pretraining.py:  512]:	********exe.run_2970******* 
[INFO] 2021-07-12 19:31:19,994 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:19,995 [run_pretraining.py:  534]:	loss/total_loss, 6.512569427490234, 2971
[INFO] 2021-07-12 19:31:19,995 [run_pretraining.py:  535]:	loss/mlm_loss, 6.512569427490234, 2971
[INFO] 2021-07-12 19:31:19,995 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9699998776777647e-05, 2971
[INFO] 2021-07-12 19:31:19,995 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2971
[INFO] 2021-07-12 19:31:19,995 [run_pretraining.py:  558]:	worker_index: 6, step: 2971, cost: 6.512569, mlm loss: 6.512569, speed: 0.943840 steps/s, speed: 7.550723 samples/s, speed: 3865.970243 tokens/s, learning rate: 2.970e-05, loss_scalings: 2814.750488, pp_loss: 6.996050
[INFO] 2021-07-12 19:31:19,995 [run_pretraining.py:  512]:	********exe.run_2971******* 
[INFO] 2021-07-12 19:31:21,035 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:21,036 [run_pretraining.py:  534]:	loss/total_loss, 7.681234836578369, 2972
[INFO] 2021-07-12 19:31:21,036 [run_pretraining.py:  535]:	loss/mlm_loss, 7.681234836578369, 2972
[INFO] 2021-07-12 19:31:21,036 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9709999580518343e-05, 2972
[INFO] 2021-07-12 19:31:21,036 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2972
[INFO] 2021-07-12 19:31:21,036 [run_pretraining.py:  558]:	worker_index: 6, step: 2972, cost: 7.681235, mlm loss: 7.681235, speed: 0.961036 steps/s, speed: 7.688288 samples/s, speed: 3936.403274 tokens/s, learning rate: 2.971e-05, loss_scalings: 2814.750488, pp_loss: 7.507290
[INFO] 2021-07-12 19:31:21,036 [run_pretraining.py:  512]:	********exe.run_2972******* 
[INFO] 2021-07-12 19:31:22,093 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:22,094 [run_pretraining.py:  534]:	loss/total_loss, 7.0717878341674805, 2973
[INFO] 2021-07-12 19:31:22,094 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0717878341674805, 2973
[INFO] 2021-07-12 19:31:22,094 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9719998565269634e-05, 2973
[INFO] 2021-07-12 19:31:22,094 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2973
[INFO] 2021-07-12 19:31:22,094 [run_pretraining.py:  558]:	worker_index: 6, step: 2973, cost: 7.071788, mlm loss: 7.071788, speed: 0.945717 steps/s, speed: 7.565732 samples/s, speed: 3873.655018 tokens/s, learning rate: 2.972e-05, loss_scalings: 2814.750488, pp_loss: 6.965313
[INFO] 2021-07-12 19:31:22,095 [run_pretraining.py:  512]:	********exe.run_2973******* 
[INFO] 2021-07-12 19:31:23,143 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:23,143 [run_pretraining.py:  534]:	loss/total_loss, 6.845385551452637, 2974
[INFO] 2021-07-12 19:31:23,143 [run_pretraining.py:  535]:	loss/mlm_loss, 6.845385551452637, 2974
[INFO] 2021-07-12 19:31:23,144 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9730001187999733e-05, 2974
[INFO] 2021-07-12 19:31:23,144 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2974
[INFO] 2021-07-12 19:31:23,144 [run_pretraining.py:  558]:	worker_index: 6, step: 2974, cost: 6.845386, mlm loss: 6.845386, speed: 0.953740 steps/s, speed: 7.629919 samples/s, speed: 3906.518702 tokens/s, learning rate: 2.973e-05, loss_scalings: 2814.750488, pp_loss: 7.106453
[INFO] 2021-07-12 19:31:23,144 [run_pretraining.py:  512]:	********exe.run_2974******* 
[INFO] 2021-07-12 19:31:24,205 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:24,206 [run_pretraining.py:  534]:	loss/total_loss, 7.3872575759887695, 2975
[INFO] 2021-07-12 19:31:24,206 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3872575759887695, 2975
[INFO] 2021-07-12 19:31:24,206 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.973999835376162e-05, 2975
[INFO] 2021-07-12 19:31:24,206 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2975
[INFO] 2021-07-12 19:31:24,206 [run_pretraining.py:  558]:	worker_index: 6, step: 2975, cost: 7.387258, mlm loss: 7.387258, speed: 0.941563 steps/s, speed: 7.532507 samples/s, speed: 3856.643385 tokens/s, learning rate: 2.974e-05, loss_scalings: 2814.750488, pp_loss: 7.270185
[INFO] 2021-07-12 19:31:24,207 [run_pretraining.py:  512]:	********exe.run_2975******* 
[INFO] 2021-07-12 19:31:25,261 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:25,261 [run_pretraining.py:  534]:	loss/total_loss, 6.916891574859619, 2976
[INFO] 2021-07-12 19:31:25,262 [run_pretraining.py:  535]:	loss/mlm_loss, 6.916891574859619, 2976
[INFO] 2021-07-12 19:31:25,262 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.975000097649172e-05, 2976
[INFO] 2021-07-12 19:31:25,262 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2976
[INFO] 2021-07-12 19:31:25,262 [run_pretraining.py:  558]:	worker_index: 6, step: 2976, cost: 6.916892, mlm loss: 6.916892, speed: 0.948230 steps/s, speed: 7.585840 samples/s, speed: 3883.950207 tokens/s, learning rate: 2.975e-05, loss_scalings: 2814.750488, pp_loss: 6.928823
[INFO] 2021-07-12 19:31:25,262 [run_pretraining.py:  512]:	********exe.run_2976******* 
[INFO] 2021-07-12 19:31:26,316 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:26,317 [run_pretraining.py:  534]:	loss/total_loss, 7.12978458404541, 2977
[INFO] 2021-07-12 19:31:26,317 [run_pretraining.py:  535]:	loss/mlm_loss, 7.12978458404541, 2977
[INFO] 2021-07-12 19:31:26,317 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.975999996124301e-05, 2977
[INFO] 2021-07-12 19:31:26,317 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2977
[INFO] 2021-07-12 19:31:26,317 [run_pretraining.py:  558]:	worker_index: 6, step: 2977, cost: 7.129785, mlm loss: 7.129785, speed: 0.948057 steps/s, speed: 7.584453 samples/s, speed: 3883.239981 tokens/s, learning rate: 2.976e-05, loss_scalings: 2814.750488, pp_loss: 7.112024
[INFO] 2021-07-12 19:31:26,317 [run_pretraining.py:  512]:	********exe.run_2977******* 
[INFO] 2021-07-12 19:31:27,373 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:27,373 [run_pretraining.py:  534]:	loss/total_loss, 6.78306770324707, 2978
[INFO] 2021-07-12 19:31:27,373 [run_pretraining.py:  535]:	loss/mlm_loss, 6.78306770324707, 2978
[INFO] 2021-07-12 19:31:27,373 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9769998945994303e-05, 2978
[INFO] 2021-07-12 19:31:27,374 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2978
[INFO] 2021-07-12 19:31:27,374 [run_pretraining.py:  558]:	worker_index: 6, step: 2978, cost: 6.783068, mlm loss: 6.783068, speed: 0.947353 steps/s, speed: 7.578826 samples/s, speed: 3880.358727 tokens/s, learning rate: 2.977e-05, loss_scalings: 2814.750488, pp_loss: 7.057633
[INFO] 2021-07-12 19:31:27,374 [run_pretraining.py:  512]:	********exe.run_2978******* 
[INFO] 2021-07-12 19:31:28,411 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:28,412 [run_pretraining.py:  534]:	loss/total_loss, 6.786688327789307, 2979
[INFO] 2021-07-12 19:31:28,412 [run_pretraining.py:  535]:	loss/mlm_loss, 6.786688327789307, 2979
[INFO] 2021-07-12 19:31:28,412 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9779999749734998e-05, 2979
[INFO] 2021-07-12 19:31:28,412 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2979
[INFO] 2021-07-12 19:31:28,412 [run_pretraining.py:  558]:	worker_index: 6, step: 2979, cost: 6.786688, mlm loss: 6.786688, speed: 0.963599 steps/s, speed: 7.708791 samples/s, speed: 3946.900955 tokens/s, learning rate: 2.978e-05, loss_scalings: 2814.750488, pp_loss: 7.294946
[INFO] 2021-07-12 19:31:28,412 [run_pretraining.py:  512]:	********exe.run_2979******* 
[INFO] 2021-07-12 19:31:29,475 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:29,476 [run_pretraining.py:  534]:	loss/total_loss, 7.6204729080200195, 2980
[INFO] 2021-07-12 19:31:29,476 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6204729080200195, 2980
[INFO] 2021-07-12 19:31:29,476 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.978999873448629e-05, 2980
[INFO] 2021-07-12 19:31:29,476 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2980
[INFO] 2021-07-12 19:31:29,476 [run_pretraining.py:  558]:	worker_index: 6, step: 2980, cost: 7.620473, mlm loss: 7.620473, speed: 0.940594 steps/s, speed: 7.524748 samples/s, speed: 3852.671030 tokens/s, learning rate: 2.979e-05, loss_scalings: 2814.750488, pp_loss: 7.237919
[INFO] 2021-07-12 19:31:29,476 [run_pretraining.py:  512]:	********exe.run_2980******* 
[INFO] 2021-07-12 19:31:30,535 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:30,535 [run_pretraining.py:  534]:	loss/total_loss, 6.785658359527588, 2981
[INFO] 2021-07-12 19:31:30,535 [run_pretraining.py:  535]:	loss/mlm_loss, 6.785658359527588, 2981
[INFO] 2021-07-12 19:31:30,536 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9799999538226984e-05, 2981
[INFO] 2021-07-12 19:31:30,536 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2981
[INFO] 2021-07-12 19:31:30,536 [run_pretraining.py:  558]:	worker_index: 6, step: 2981, cost: 6.785658, mlm loss: 6.785658, speed: 0.944260 steps/s, speed: 7.554077 samples/s, speed: 3867.687428 tokens/s, learning rate: 2.980e-05, loss_scalings: 2814.750488, pp_loss: 7.140080
[INFO] 2021-07-12 19:31:30,536 [run_pretraining.py:  512]:	********exe.run_2981******* 
[INFO] 2021-07-12 19:31:31,599 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:31,599 [run_pretraining.py:  534]:	loss/total_loss, 7.189043045043945, 2982
[INFO] 2021-07-12 19:31:31,600 [run_pretraining.py:  535]:	loss/mlm_loss, 7.189043045043945, 2982
[INFO] 2021-07-12 19:31:31,600 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9809998522978276e-05, 2982
[INFO] 2021-07-12 19:31:31,600 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2982
[INFO] 2021-07-12 19:31:31,600 [run_pretraining.py:  558]:	worker_index: 6, step: 2982, cost: 7.189043, mlm loss: 7.189043, speed: 0.940364 steps/s, speed: 7.522911 samples/s, speed: 3851.730385 tokens/s, learning rate: 2.981e-05, loss_scalings: 2814.750488, pp_loss: 6.945391
[INFO] 2021-07-12 19:31:31,600 [run_pretraining.py:  512]:	********exe.run_2982******* 
[INFO] 2021-07-12 19:31:32,647 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:32,648 [run_pretraining.py:  534]:	loss/total_loss, 8.771262168884277, 2983
[INFO] 2021-07-12 19:31:32,648 [run_pretraining.py:  535]:	loss/mlm_loss, 8.771262168884277, 2983
[INFO] 2021-07-12 19:31:32,648 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9820001145708375e-05, 2983
[INFO] 2021-07-12 19:31:32,648 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2983
[INFO] 2021-07-12 19:31:32,648 [run_pretraining.py:  558]:	worker_index: 6, step: 2983, cost: 8.771262, mlm loss: 8.771262, speed: 0.954348 steps/s, speed: 7.634787 samples/s, speed: 3909.011086 tokens/s, learning rate: 2.982e-05, loss_scalings: 2814.750488, pp_loss: 7.482035
[INFO] 2021-07-12 19:31:32,648 [run_pretraining.py:  512]:	********exe.run_2983******* 
[INFO] 2021-07-12 19:31:33,712 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:33,713 [run_pretraining.py:  534]:	loss/total_loss, 7.000860214233398, 2984
[INFO] 2021-07-12 19:31:33,713 [run_pretraining.py:  535]:	loss/mlm_loss, 7.000860214233398, 2984
[INFO] 2021-07-12 19:31:33,713 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9829998311470263e-05, 2984
[INFO] 2021-07-12 19:31:33,713 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2984
[INFO] 2021-07-12 19:31:33,713 [run_pretraining.py:  558]:	worker_index: 6, step: 2984, cost: 7.000860, mlm loss: 7.000860, speed: 0.939659 steps/s, speed: 7.517272 samples/s, speed: 3848.843083 tokens/s, learning rate: 2.983e-05, loss_scalings: 2814.750488, pp_loss: 6.896232
[INFO] 2021-07-12 19:31:33,713 [run_pretraining.py:  512]:	********exe.run_2984******* 
[INFO] 2021-07-12 19:31:34,765 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:34,766 [run_pretraining.py:  534]:	loss/total_loss, 5.433079719543457, 2985
[INFO] 2021-07-12 19:31:34,766 [run_pretraining.py:  535]:	loss/mlm_loss, 5.433079719543457, 2985
[INFO] 2021-07-12 19:31:34,766 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.984000093420036e-05, 2985
[INFO] 2021-07-12 19:31:34,766 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2985
[INFO] 2021-07-12 19:31:34,766 [run_pretraining.py:  558]:	worker_index: 6, step: 2985, cost: 5.433080, mlm loss: 5.433080, speed: 0.950226 steps/s, speed: 7.601808 samples/s, speed: 3892.125496 tokens/s, learning rate: 2.984e-05, loss_scalings: 2814.750488, pp_loss: 6.805988
[INFO] 2021-07-12 19:31:34,766 [run_pretraining.py:  512]:	********exe.run_2985******* 
[INFO] 2021-07-12 19:31:35,917 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:35,918 [run_pretraining.py:  534]:	loss/total_loss, 7.063321590423584, 2986
[INFO] 2021-07-12 19:31:35,918 [run_pretraining.py:  535]:	loss/mlm_loss, 7.063321590423584, 2986
[INFO] 2021-07-12 19:31:35,918 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9849999918951653e-05, 2986
[INFO] 2021-07-12 19:31:35,918 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2986
[INFO] 2021-07-12 19:31:35,918 [run_pretraining.py:  558]:	worker_index: 6, step: 2986, cost: 7.063322, mlm loss: 7.063322, speed: 0.868563 steps/s, speed: 6.948503 samples/s, speed: 3557.633519 tokens/s, learning rate: 2.985e-05, loss_scalings: 2814.750488, pp_loss: 7.226905
[INFO] 2021-07-12 19:31:35,919 [run_pretraining.py:  512]:	********exe.run_2986******* 
[INFO] 2021-07-12 19:31:37,044 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:37,045 [run_pretraining.py:  534]:	loss/total_loss, 7.098017692565918, 2987
[INFO] 2021-07-12 19:31:37,045 [run_pretraining.py:  535]:	loss/mlm_loss, 7.098017692565918, 2987
[INFO] 2021-07-12 19:31:37,045 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9859998903702945e-05, 2987
[INFO] 2021-07-12 19:31:37,045 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2987
[INFO] 2021-07-12 19:31:37,045 [run_pretraining.py:  558]:	worker_index: 6, step: 2987, cost: 7.098018, mlm loss: 7.098018, speed: 0.888155 steps/s, speed: 7.105239 samples/s, speed: 3637.882115 tokens/s, learning rate: 2.986e-05, loss_scalings: 2814.750488, pp_loss: 6.989332
[INFO] 2021-07-12 19:31:37,045 [run_pretraining.py:  512]:	********exe.run_2987******* 
[INFO] 2021-07-12 19:31:38,129 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:38,129 [run_pretraining.py:  534]:	loss/total_loss, 7.395720481872559, 2988
[INFO] 2021-07-12 19:31:38,129 [run_pretraining.py:  535]:	loss/mlm_loss, 7.395720481872559, 2988
[INFO] 2021-07-12 19:31:38,129 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.986999970744364e-05, 2988
[INFO] 2021-07-12 19:31:38,130 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2988
[INFO] 2021-07-12 19:31:38,130 [run_pretraining.py:  558]:	worker_index: 6, step: 2988, cost: 7.395720, mlm loss: 7.395720, speed: 0.922676 steps/s, speed: 7.381408 samples/s, speed: 3779.280669 tokens/s, learning rate: 2.987e-05, loss_scalings: 2814.750488, pp_loss: 7.292965
[INFO] 2021-07-12 19:31:38,130 [run_pretraining.py:  512]:	********exe.run_2988******* 
[INFO] 2021-07-12 19:31:39,162 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:39,163 [run_pretraining.py:  534]:	loss/total_loss, 7.3178277015686035, 2989
[INFO] 2021-07-12 19:31:39,163 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3178277015686035, 2989
[INFO] 2021-07-12 19:31:39,163 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.987999869219493e-05, 2989
[INFO] 2021-07-12 19:31:39,163 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2989
[INFO] 2021-07-12 19:31:39,163 [run_pretraining.py:  558]:	worker_index: 6, step: 2989, cost: 7.317828, mlm loss: 7.317828, speed: 0.968356 steps/s, speed: 7.746851 samples/s, speed: 3966.387767 tokens/s, learning rate: 2.988e-05, loss_scalings: 2814.750488, pp_loss: 7.351846
[INFO] 2021-07-12 19:31:39,163 [run_pretraining.py:  512]:	********exe.run_2989******* 
[INFO] 2021-07-12 19:31:40,069 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:40,070 [run_pretraining.py:  534]:	loss/total_loss, 7.092867374420166, 2990
[INFO] 2021-07-12 19:31:40,070 [run_pretraining.py:  535]:	loss/mlm_loss, 7.092867374420166, 2990
[INFO] 2021-07-12 19:31:40,070 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9889999495935626e-05, 2990
[INFO] 2021-07-12 19:31:40,070 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2990
[INFO] 2021-07-12 19:31:40,070 [run_pretraining.py:  558]:	worker_index: 6, step: 2990, cost: 7.092867, mlm loss: 7.092867, speed: 1.103086 steps/s, speed: 8.824684 samples/s, speed: 4518.238301 tokens/s, learning rate: 2.989e-05, loss_scalings: 2814.750488, pp_loss: 7.415491
[INFO] 2021-07-12 19:31:40,070 [run_pretraining.py:  512]:	********exe.run_2990******* 
[INFO] 2021-07-12 19:31:40,977 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:40,977 [run_pretraining.py:  534]:	loss/total_loss, 6.8757805824279785, 2991
[INFO] 2021-07-12 19:31:40,978 [run_pretraining.py:  535]:	loss/mlm_loss, 6.8757805824279785, 2991
[INFO] 2021-07-12 19:31:40,978 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9899998480686918e-05, 2991
[INFO] 2021-07-12 19:31:40,978 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2991
[INFO] 2021-07-12 19:31:40,978 [run_pretraining.py:  558]:	worker_index: 6, step: 2991, cost: 6.875781, mlm loss: 6.875781, speed: 1.102652 steps/s, speed: 8.821218 samples/s, speed: 4516.463709 tokens/s, learning rate: 2.990e-05, loss_scalings: 2814.750488, pp_loss: 6.971143
[INFO] 2021-07-12 19:31:40,978 [run_pretraining.py:  512]:	********exe.run_2991******* 
[INFO] 2021-07-12 19:31:41,884 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:41,885 [run_pretraining.py:  534]:	loss/total_loss, 7.890573024749756, 2992
[INFO] 2021-07-12 19:31:41,885 [run_pretraining.py:  535]:	loss/mlm_loss, 7.890573024749756, 2992
[INFO] 2021-07-12 19:31:41,885 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9910001103417017e-05, 2992
[INFO] 2021-07-12 19:31:41,885 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2992
[INFO] 2021-07-12 19:31:41,885 [run_pretraining.py:  558]:	worker_index: 6, step: 2992, cost: 7.890573, mlm loss: 7.890573, speed: 1.103122 steps/s, speed: 8.824979 samples/s, speed: 4518.389217 tokens/s, learning rate: 2.991e-05, loss_scalings: 2814.750488, pp_loss: 7.717336
[INFO] 2021-07-12 19:31:41,885 [run_pretraining.py:  512]:	********exe.run_2992******* 
[INFO] 2021-07-12 19:31:42,789 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:42,790 [run_pretraining.py:  534]:	loss/total_loss, 6.687685489654541, 2993
[INFO] 2021-07-12 19:31:42,790 [run_pretraining.py:  535]:	loss/mlm_loss, 6.687685489654541, 2993
[INFO] 2021-07-12 19:31:42,790 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9919998269178905e-05, 2993
[INFO] 2021-07-12 19:31:42,790 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2993
[INFO] 2021-07-12 19:31:42,790 [run_pretraining.py:  558]:	worker_index: 6, step: 2993, cost: 6.687685, mlm loss: 6.687685, speed: 1.105382 steps/s, speed: 8.843059 samples/s, speed: 4527.646442 tokens/s, learning rate: 2.992e-05, loss_scalings: 2814.750488, pp_loss: 6.694241
[INFO] 2021-07-12 19:31:42,791 [run_pretraining.py:  512]:	********exe.run_2993******* 
[INFO] 2021-07-12 19:31:43,698 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:43,699 [run_pretraining.py:  534]:	loss/total_loss, 7.624037742614746, 2994
[INFO] 2021-07-12 19:31:43,699 [run_pretraining.py:  535]:	loss/mlm_loss, 7.624037742614746, 2994
[INFO] 2021-07-12 19:31:43,699 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9929997253930196e-05, 2994
[INFO] 2021-07-12 19:31:43,699 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2994
[INFO] 2021-07-12 19:31:43,699 [run_pretraining.py:  558]:	worker_index: 6, step: 2994, cost: 7.624038, mlm loss: 7.624038, speed: 1.101628 steps/s, speed: 8.813023 samples/s, speed: 4512.267969 tokens/s, learning rate: 2.993e-05, loss_scalings: 2814.750488, pp_loss: 7.245848
[INFO] 2021-07-12 19:31:43,699 [run_pretraining.py:  512]:	********exe.run_2994******* 
[INFO] 2021-07-12 19:31:44,607 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:44,608 [run_pretraining.py:  534]:	loss/total_loss, 6.929236888885498, 2995
[INFO] 2021-07-12 19:31:44,608 [run_pretraining.py:  535]:	loss/mlm_loss, 6.929236888885498, 2995
[INFO] 2021-07-12 19:31:44,608 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9939999876660295e-05, 2995
[INFO] 2021-07-12 19:31:44,608 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2995
[INFO] 2021-07-12 19:31:44,608 [run_pretraining.py:  558]:	worker_index: 6, step: 2995, cost: 6.929237, mlm loss: 6.929237, speed: 1.100795 steps/s, speed: 8.806362 samples/s, speed: 4508.857343 tokens/s, learning rate: 2.994e-05, loss_scalings: 2814.750488, pp_loss: 7.109171
[INFO] 2021-07-12 19:31:44,608 [run_pretraining.py:  512]:	********exe.run_2995******* 
[INFO] 2021-07-12 19:31:45,507 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:45,508 [run_pretraining.py:  534]:	loss/total_loss, 7.967097759246826, 2996
[INFO] 2021-07-12 19:31:45,508 [run_pretraining.py:  535]:	loss/mlm_loss, 7.967097759246826, 2996
[INFO] 2021-07-12 19:31:45,508 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9949998861411586e-05, 2996
[INFO] 2021-07-12 19:31:45,508 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2996
[INFO] 2021-07-12 19:31:45,508 [run_pretraining.py:  558]:	worker_index: 6, step: 2996, cost: 7.967098, mlm loss: 7.967098, speed: 1.111598 steps/s, speed: 8.892782 samples/s, speed: 4553.104412 tokens/s, learning rate: 2.995e-05, loss_scalings: 2814.750488, pp_loss: 7.619374
[INFO] 2021-07-12 19:31:45,508 [run_pretraining.py:  512]:	********exe.run_2996******* 
[INFO] 2021-07-12 19:31:46,408 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:46,408 [run_pretraining.py:  534]:	loss/total_loss, 6.400069236755371, 2997
[INFO] 2021-07-12 19:31:46,409 [run_pretraining.py:  535]:	loss/mlm_loss, 6.400069236755371, 2997
[INFO] 2021-07-12 19:31:46,409 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.995999966515228e-05, 2997
[INFO] 2021-07-12 19:31:46,409 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2997
[INFO] 2021-07-12 19:31:46,409 [run_pretraining.py:  558]:	worker_index: 6, step: 2997, cost: 6.400069, mlm loss: 6.400069, speed: 1.111408 steps/s, speed: 8.891267 samples/s, speed: 4552.328644 tokens/s, learning rate: 2.996e-05, loss_scalings: 2814.750488, pp_loss: 6.812159
[INFO] 2021-07-12 19:31:46,409 [run_pretraining.py:  512]:	********exe.run_2997******* 
[INFO] 2021-07-12 19:31:47,313 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:47,314 [run_pretraining.py:  534]:	loss/total_loss, 7.731919288635254, 2998
[INFO] 2021-07-12 19:31:47,314 [run_pretraining.py:  535]:	loss/mlm_loss, 7.731919288635254, 2998
[INFO] 2021-07-12 19:31:47,314 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9969998649903573e-05, 2998
[INFO] 2021-07-12 19:31:47,314 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2998
[INFO] 2021-07-12 19:31:47,314 [run_pretraining.py:  558]:	worker_index: 6, step: 2998, cost: 7.731919, mlm loss: 7.731919, speed: 1.105433 steps/s, speed: 8.843465 samples/s, speed: 4527.854074 tokens/s, learning rate: 2.997e-05, loss_scalings: 2814.750488, pp_loss: 7.351823
[INFO] 2021-07-12 19:31:47,314 [run_pretraining.py:  512]:	********exe.run_2998******* 
[INFO] 2021-07-12 19:31:48,218 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:48,219 [run_pretraining.py:  534]:	loss/total_loss, 7.1219377517700195, 2999
[INFO] 2021-07-12 19:31:48,219 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1219377517700195, 2999
[INFO] 2021-07-12 19:31:48,219 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9979999453644268e-05, 2999
[INFO] 2021-07-12 19:31:48,219 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2999
[INFO] 2021-07-12 19:31:48,219 [run_pretraining.py:  558]:	worker_index: 6, step: 2999, cost: 7.121938, mlm loss: 7.121938, speed: 1.105638 steps/s, speed: 8.845106 samples/s, speed: 4528.694343 tokens/s, learning rate: 2.998e-05, loss_scalings: 2814.750488, pp_loss: 7.252821
[INFO] 2021-07-12 19:31:48,219 [run_pretraining.py:  512]:	********exe.run_2999******* 
[INFO] 2021-07-12 19:31:49,130 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:49,130 [run_pretraining.py:  534]:	loss/total_loss, 7.195384979248047, 3000
[INFO] 2021-07-12 19:31:49,130 [run_pretraining.py:  535]:	loss/mlm_loss, 7.195384979248047, 3000
[INFO] 2021-07-12 19:31:49,131 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.998999843839556e-05, 3000
[INFO] 2021-07-12 19:31:49,131 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 3000
[INFO] 2021-07-12 19:31:49,131 [run_pretraining.py:  558]:	worker_index: 6, step: 3000, cost: 7.195385, mlm loss: 7.195385, speed: 1.098063 steps/s, speed: 8.784504 samples/s, speed: 4497.665852 tokens/s, learning rate: 2.999e-05, loss_scalings: 2814.750488, pp_loss: 6.617212
[DEBUG] 2021-07-12 19:31:50,187 [run_pretraining.py:  575]:	saving final models to output/step3000-3p-bs8-npu_6/final_step_3000
[DEBUG] 2021-07-12 19:31:50,188 [run_pretraining.py:  576]:	end of training, total steps: 3000
I0712 19:31:50.188360 48407 lod_tensor_blocking_queue.h:59] LoDTensorBlockingQueue close
I0712 19:31:50.188390 48407 blocking_queue.h:132] close queue
I0712 19:31:50.189071 51935 lod_tensor_blocking_queue.h:59] LoDTensorBlockingQueue close
I0712 19:31:50.189107 51935 blocking_queue.h:132] close queue
I0712 19:31:57.573778 48407 reader.h:164] ~ReaderHolder
I0712 19:31:57.573884 48407 buffered_reader.cc:22] ~BufferedReader
I0712 19:31:57.573894 48407 lod_tensor_blocking_queue.h:59] LoDTensorBlockingQueue close
I0712 19:31:57.573900 48407 blocking_queue.h:132] close queue
I0712 19:31:57.574087 48407 reader.cc:76] ~DecoratedReader
I0712 19:31:57.574100 48407 lod_tensor_blocking_queue.h:59] LoDTensorBlockingQueue close
I0712 19:31:57.574105 48407 blocking_queue.h:132] close queue
I0712 19:31:57.574112 48407 lod_tensor_blocking_queue.h:59] LoDTensorBlockingQueue close
I0712 19:31:57.574144 48407 blocking_queue.h:132] close queue
I0712 19:31:57.575567 48407 reader.h:164] ~ReaderHolder
