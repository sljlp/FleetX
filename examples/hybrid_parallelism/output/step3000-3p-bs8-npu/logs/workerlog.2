/home/gongwb/.local/lib/python3.7/site-packages/setuptools/depends.py:2: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0712 16:56:03.076486 48391 init.cc:88] Before Parse: argc is 2, Init commandline: dummy --tryfromenv=check_nan_inf,benchmark,eager_delete_scope,fraction_of_cpu_memory_to_use,initial_cpu_memory_in_mb,init_allocated_mem,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_system_allocator,enable_unused_var_check,free_idle_chunk,free_when_no_cache_hit,call_stack_level,sort_sum_gradient,max_inplace_grad_add,use_pinned_memory,cpu_deterministic,selected_npus,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,gpu_memory_limit_mb 
I0712 16:56:03.076715 48391 init.cc:95] After Parse: argc is 1
-----------  Configuration Arguments -----------
data_dir: ./data
debug: False
do_eval: True
epoch: 100
ernie_config_file: config/ernie_base_config.json
eval_batch_size: 35
eval_data_path: ./data
eval_steps: -1
global_bsz: 8
global_steps: 0
grad_merge: 0
init_checkpoint: 
learning_rate: 0.0001
log_steps: 1
max_seq_len: 512
micro_bsz: 1
num_dp: 2
num_mp: 2
num_pp: 2
num_sharding: 1
num_train_steps: 3000
output_dir: output/step3000-3p-bs8-npu
preln: False
save_steps: 4000
seed: 2021
use_amp: True
use_hybrid_dp: True
use_lamb: False
use_offload: False
use_recompute: True
use_sharding: True
vocab_file: ./config/30k-clean.vocab.albert
warmup_steps: 10000
weight_decay: 0.01
------------------------------------------------
to run startup
[INFO] 2021-07-12 16:56:03,968 [run_pretraining.py:  216]:	pretraining start
[INFO] 2021-07-12 16:56:03,969 [run_pretraining.py:  234]:	using recompute.
[INFO] 2021-07-12 16:56:03,969 [run_pretraining.py:  279]:	using globa_bsz: 8 micro_bsz: 1, acc_steps: 4
[DEBUG] 2021-07-12 16:56:04,033 [run_pretraining.py:  118]:	========= dp_sharding worker: 0 of 2 ==========
[INFO] 2021-07-12 16:56:04,033 [pretraining_ds_mlm.py:  289]:	Apply sharding in distribution env 0/2
[INFO] 2021-07-12 16:56:04,033 [pretraining_ds_mlm.py:  291]:	read from ./data/part-00000.104,./data/part-00000.107,./data/part-00000.10,./data/part-00000.101,./data/part-00000.106,./data/part-00000.108
I0712 16:56:04.033989 48391 reader_py.cc:387] init_lod_tensor_blocking_queue
INFO:root:places would be ommited when DataLoader is not iterable
/home/liupeng51/github/Paddle/build/build_ubuntu_develop_release_ascend_y_none_3.7.5/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /home/liupeng51/github/FleetX/examples/hybrid_parallelism/model/ernie.py:158
The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
/home/liupeng51/github/Paddle/build/build_ubuntu_develop_release_ascend_y_none_3.7.5/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /home/liupeng51/github/FleetX/examples/hybrid_parallelism/model/ernie.py:159
The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
/home/liupeng51/github/Paddle/build/build_ubuntu_develop_release_ascend_y_none_3.7.5/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /home/liupeng51/github/FleetX/examples/hybrid_parallelism/model/transformer_encoder.py:170
The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
/home/liupeng51/github/Paddle/build/build_ubuntu_develop_release_ascend_y_none_3.7.5/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /home/liupeng51/github/FleetX/examples/hybrid_parallelism/model/transformer_encoder.py:280
The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
/home/liupeng51/github/Paddle/build/build_ubuntu_develop_release_ascend_y_none_3.7.5/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /home/liupeng51/github/FleetX/examples/hybrid_parallelism/model/transformer_encoder.py:43
The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
/home/liupeng51/github/Paddle/build/build_ubuntu_develop_release_ascend_y_none_3.7.5/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /home/liupeng51/github/FleetX/examples/hybrid_parallelism/model/transformer_encoder.py:44
The behavior of expression A * B has been unified with elementwise_mul(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_mul(X, Y, axis=0) instead of A * B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
[DEBUG] 2021-07-12 16:56:04,848 [run_pretraining.py:  315]:	base lr: 0.0001
/home/liupeng51/github/Paddle/build/build_ubuntu_develop_release_ascend_y_none_3.7.5/python/paddle/distributed/fleet/base/fleet_base.py:818: UserWarning: It is recommended to use DistributedStrategy in fleet.init(). The strategy here is only for compatibility. If the strategy in fleet.distributed_optimizer() is not None, then it will overwrite the DistributedStrategy in fleet.init(), which will take effect in distributed training.
  "It is recommended to use DistributedStrategy "
2021-07-12 16:56:04 INFO     Gradient merge in [pp_gm], acc step = [4]
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:Gradient merge in [pp_gm], acc step = [4]
Mon Jul 12 16:56:05-INFO: recompute segment[0]
Mon Jul 12 16:56:05-INFO: segment start op: [squeeze2]: [['shard_index_0.tmp_0']]
Mon Jul 12 16:56:05-INFO: segment end op: [layer_norm]: [['encoder_layer_0_post_ffn_layer_norm_bias', 'encoder_layer_0_post_ffn_layer_norm_scale', 'tmp_10']]
Mon Jul 12 16:56:05-INFO: recompute segment[0]
Mon Jul 12 16:56:05-INFO: segment start op: [squeeze2]: [['shard_index_0.tmp_0']]
Mon Jul 12 16:56:05-INFO: segment end op: [layer_norm]: [['encoder_layer_0_post_ffn_layer_norm_bias', 'encoder_layer_0_post_ffn_layer_norm_scale', 'tmp_10']]
Mon Jul 12 16:56:05-INFO: found [0] vars which cross recompute segment: [set()], better checkpoints might be set to reduce those vars
pp_rank: 1
2021-07-12 16:56:10 INFO     Hybrid DP mode turn on !
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:Hybrid DP mode turn on !
2021-07-12 16:56:10 INFO     global word size: 8
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:global word size: 8
2021-07-12 16:56:10 INFO     global rank: 2
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:global rank: 2
2021-07-12 16:56:10 INFO     global endpoints: ['192.168.206.27:6170', '192.168.206.27:6171', '192.168.206.27:6172', '192.168.206.27:6173', '192.168.206.27:6174', '192.168.206.27:6175', '192.168.206.27:6176', '192.168.206.27:6177']
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:global endpoints: ['192.168.206.27:6170', '192.168.206.27:6171', '192.168.206.27:6172', '192.168.206.27:6173', '192.168.206.27:6174', '192.168.206.27:6175', '192.168.206.27:6176', '192.168.206.27:6177']
2021-07-12 16:56:10 INFO     global ring id: 3
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:global ring id: 3
2021-07-12 16:56:10 INFO     ##############################
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:##############################
2021-07-12 16:56:10 INFO     mp group size: 2
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:mp group size: 2
2021-07-12 16:56:10 INFO     mp rank: 0
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:mp rank: 0
2021-07-12 16:56:10 INFO     mp group id: 1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:mp group id: 1
2021-07-12 16:56:10 INFO     mp group endpoints: ['192.168.206.27:6172', '192.168.206.27:6173']
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:mp group endpoints: ['192.168.206.27:6172', '192.168.206.27:6173']
2021-07-12 16:56:10 INFO     mp ring id: 0
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:mp ring id: 0
2021-07-12 16:56:10 INFO     ##############################
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:##############################
2021-07-12 16:56:10 INFO     sharding group size: 1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:sharding group size: 1
2021-07-12 16:56:10 INFO     sharding rank: -1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:sharding rank: -1
2021-07-12 16:56:10 INFO     sharding group id: -1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:sharding group id: -1
2021-07-12 16:56:10 INFO     sharding group endpoints: []
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:sharding group endpoints: []
2021-07-12 16:56:10 INFO     sharding ring id: -1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:sharding ring id: -1
2021-07-12 16:56:10 INFO     ##############################
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:##############################
2021-07-12 16:56:10 INFO     pp group size: 2
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pp group size: 2
2021-07-12 16:56:10 INFO     pp rank: 1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pp rank: 1
2021-07-12 16:56:10 INFO     pp group id: 0
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pp group id: 0
2021-07-12 16:56:10 INFO     pp group endpoints: ['192.168.206.27:6170', '192.168.206.27:6172']
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pp group endpoints: ['192.168.206.27:6170', '192.168.206.27:6172']
2021-07-12 16:56:10 INFO     pp ring id: 20
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pp ring id: 20
2021-07-12 16:56:10 INFO     ##############################
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:##############################
2021-07-12 16:56:10 INFO     pure dp group size: 2
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pure dp group size: 2
2021-07-12 16:56:10 INFO     pure dp rank: 0
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pure dp rank: 0
2021-07-12 16:56:10 INFO     pure dp group endpoints: ['192.168.206.27:6172', '192.168.206.27:6176']
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pure dp group endpoints: ['192.168.206.27:6172', '192.168.206.27:6176']
2021-07-12 16:56:10 INFO     pure dp ring id: 2
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pure dp ring id: 2
2021-07-12 16:56:10 INFO     ##############################
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:##############################
pp pair:(0, 1), ring_id: 20
pp pair:(1, 0), ring_id: 21
I0712 16:56:30.210343 48391 gen_hccl_id_op_helper.cc:181] Server listening on: 192.168.206.27:6172 successful.
I0712 16:56:31.352090 48391 collective_helper_npu.cc:83] initialized comm: 0xffffea59ff80, nranks: 8, hccl_id: 0x3a9b2fd4, rank: 2
I0712 16:56:34.234571 48391 collective_helper_npu.cc:88] initialized comm: 0xffffea59ff80, nranks: 8, hccl_id: 0x3a9b2fd4, rank: 2
I0712 16:56:34.234807 48391 collective_helper_npu.cc:93] hccl communicator of rank 2 in ring 3 has been created on device 2, with comm: 0x3a77c520
I0712 16:56:36.120864 48391 collective_helper_npu.cc:83] initialized comm: 0xffffea59ff80, nranks: 2, hccl_id: 0x3a91d034, rank: 0
I0712 16:56:37.340236 48391 collective_helper_npu.cc:88] initialized comm: 0xffffea59ff80, nranks: 2, hccl_id: 0x3a91d034, rank: 0
I0712 16:56:37.341540 48391 collective_helper_npu.cc:93] hccl communicator of rank 0 in ring 0 has been created on device 2, with comm: 0x3a9c00f0
I0712 16:56:37.670349 48391 gen_hccl_id_op_helper.cc:181] Server listening on: 192.168.206.27:6172 successful.
I0712 16:56:37.671144 48391 collective_helper_npu.cc:83] initialized comm: 0xffffea59ff80, nranks: 2, hccl_id: 0x3a927a24, rank: 1
I0712 16:56:38.889678 48391 collective_helper_npu.cc:88] initialized comm: 0xffffea59ff80, nranks: 2, hccl_id: 0x3a927a24, rank: 1
I0712 16:56:38.889884 48391 collective_helper_npu.cc:93] hccl communicator of rank 1 in ring 20 has been created on device 2, with comm: 0x3a792980
I0712 16:56:39.223120 48391 collective_helper_npu.cc:83] initialized comm: 0xffffea59ff80, nranks: 2, hccl_id: 0x3a928a54, rank: 0
I0712 16:56:40.643553 48391 collective_helper_npu.cc:88] initialized comm: 0xffffea59ff80, nranks: 2, hccl_id: 0x3a928a54, rank: 0
I0712 16:56:40.644017 48391 collective_helper_npu.cc:93] hccl communicator of rank 0 in ring 21 has been created on device 2, with comm: 0x3a7f7b70
W0712 16:56:40.983584 48391 gen_hccl_id_op_helper.cc:120] connect addr=192.168.206.27:6176 failed 1 times with reason: Connection refused retry after 0.5 seconds
I0712 16:56:41.484302 48391 collective_helper_npu.cc:83] initialized comm: 0xffffea59ff80, nranks: 2, hccl_id: 0x3a92f404, rank: 0
I0712 16:56:42.701994 48391 collective_helper_npu.cc:88] initialized comm: 0xffffea59ff80, nranks: 2, hccl_id: 0x3a92f404, rank: 0
I0712 16:56:42.702199 48391 collective_helper_npu.cc:93] hccl communicator of rank 0 in ring 2 has been created on device 2, with comm: 0x3a86de60
Done broadcast
[INFO] 2021-07-12 16:56:43,034 [run_pretraining.py:  512]:	********exe.run_0******* 
I0712 16:56:45.778401 51979 lod_tensor_blocking_queue.h:104] Init queue with size 1
I0712 16:56:45.778595 51979 buffered_reader.cc:41] BufferedReader
[INFO] 2021-07-12 17:00:09,939 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:00:09,940 [run_pretraining.py:  534]:	loss/total_loss, 10.46152400970459, 1
[INFO] 2021-07-12 17:00:09,940 [run_pretraining.py:  535]:	loss/mlm_loss, 10.46152400970459, 1
[INFO] 2021-07-12 17:00:09,940 [run_pretraining.py:  536]:	lr/scheduled_lr, 0.0, 1
[INFO] 2021-07-12 17:00:09,940 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 1
[INFO] 2021-07-12 17:00:09,940 [run_pretraining.py:  558]:	worker_index: 2, step: 1, cost: 10.461524, mlm loss: 10.461524, speed: 0.004833 steps/s, speed: 0.038665 samples/s, speed: 19.796404 tokens/s, learning rate: 0.000e+00, loss_scalings: 32768.000000, pp_loss: 10.452024
[INFO] 2021-07-12 17:00:09,940 [run_pretraining.py:  512]:	********exe.run_1******* 
[INFO] 2021-07-12 17:01:50,859 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:01:50,860 [run_pretraining.py:  534]:	loss/total_loss, 10.485716819763184, 2
[INFO] 2021-07-12 17:01:50,861 [run_pretraining.py:  535]:	loss/mlm_loss, 10.485716819763184, 2
[INFO] 2021-07-12 17:01:50,861 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.99999905104687e-09, 2
[INFO] 2021-07-12 17:01:50,861 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 2
[INFO] 2021-07-12 17:01:50,861 [run_pretraining.py:  558]:	worker_index: 2, step: 2, cost: 10.485717, mlm loss: 10.485717, speed: 0.009909 steps/s, speed: 0.079271 samples/s, speed: 40.586629 tokens/s, learning rate: 1.000e-08, loss_scalings: 32768.000000, pp_loss: 9.525708
[INFO] 2021-07-12 17:01:50,861 [run_pretraining.py:  512]:	********exe.run_2******* 
[INFO] 2021-07-12 17:03:30,513 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:03:30,513 [run_pretraining.py:  534]:	loss/total_loss, 10.414789199829102, 3
[INFO] 2021-07-12 17:03:30,513 [run_pretraining.py:  535]:	loss/mlm_loss, 10.414789199829102, 3
[INFO] 2021-07-12 17:03:30,513 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.999999810209374e-08, 3
[INFO] 2021-07-12 17:03:30,514 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 3
[INFO] 2021-07-12 17:03:30,514 [run_pretraining.py:  558]:	worker_index: 2, step: 3, cost: 10.414789, mlm loss: 10.414789, speed: 0.010035 steps/s, speed: 0.080279 samples/s, speed: 41.103024 tokens/s, learning rate: 2.000e-08, loss_scalings: 32768.000000, pp_loss: 10.411291
[INFO] 2021-07-12 17:03:30,514 [run_pretraining.py:  512]:	********exe.run_3******* 
[INFO] 2021-07-12 17:05:10,852 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:05:10,852 [run_pretraining.py:  534]:	loss/total_loss, 10.420588493347168, 4
[INFO] 2021-07-12 17:05:10,852 [run_pretraining.py:  535]:	loss/mlm_loss, 10.420588493347168, 4
[INFO] 2021-07-12 17:05:10,853 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.999999892949745e-08, 4
[INFO] 2021-07-12 17:05:10,853 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 4
[INFO] 2021-07-12 17:05:10,853 [run_pretraining.py:  558]:	worker_index: 2, step: 4, cost: 10.420588, mlm loss: 10.420588, speed: 0.009966 steps/s, speed: 0.079730 samples/s, speed: 40.821892 tokens/s, learning rate: 3.000e-08, loss_scalings: 32768.000000, pp_loss: 10.433510
[INFO] 2021-07-12 17:05:10,853 [run_pretraining.py:  512]:	********exe.run_4******* 
[INFO] 2021-07-12 17:06:52,479 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:06:52,479 [run_pretraining.py:  534]:	loss/total_loss, 10.704609870910645, 5
[INFO] 2021-07-12 17:06:52,480 [run_pretraining.py:  535]:	loss/mlm_loss, 10.704609870910645, 5
[INFO] 2021-07-12 17:06:52,480 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.999999620418748e-08, 5
[INFO] 2021-07-12 17:06:52,480 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 5
[INFO] 2021-07-12 17:06:52,480 [run_pretraining.py:  558]:	worker_index: 2, step: 5, cost: 10.704610, mlm loss: 10.704610, speed: 0.009840 steps/s, speed: 0.078720 samples/s, speed: 40.304461 tokens/s, learning rate: 4.000e-08, loss_scalings: 26214.400391, pp_loss: 10.469618
[INFO] 2021-07-12 17:06:52,480 [run_pretraining.py:  512]:	********exe.run_5******* 
[INFO] 2021-07-12 17:08:33,475 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:08:33,476 [run_pretraining.py:  534]:	loss/total_loss, 10.260292053222656, 6
[INFO] 2021-07-12 17:08:33,476 [run_pretraining.py:  535]:	loss/mlm_loss, 10.260292053222656, 6
[INFO] 2021-07-12 17:08:33,476 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.000000058430487e-08, 6
[INFO] 2021-07-12 17:08:33,476 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 6
[INFO] 2021-07-12 17:08:33,476 [run_pretraining.py:  558]:	worker_index: 2, step: 6, cost: 10.260292, mlm loss: 10.260292, speed: 0.009901 steps/s, speed: 0.079211 samples/s, speed: 40.556196 tokens/s, learning rate: 5.000e-08, loss_scalings: 26214.400391, pp_loss: 10.401776
[INFO] 2021-07-12 17:08:33,477 [run_pretraining.py:  512]:	********exe.run_6******* 
[INFO] 2021-07-12 17:10:13,732 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:10:13,732 [run_pretraining.py:  534]:	loss/total_loss, 7.716341018676758, 7
[INFO] 2021-07-12 17:10:13,732 [run_pretraining.py:  535]:	loss/mlm_loss, 7.716341018676758, 7
[INFO] 2021-07-12 17:10:13,732 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.99999978589949e-08, 7
[INFO] 2021-07-12 17:10:13,733 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 7
[INFO] 2021-07-12 17:10:13,733 [run_pretraining.py:  558]:	worker_index: 2, step: 7, cost: 7.716341, mlm loss: 7.716341, speed: 0.009975 steps/s, speed: 0.079796 samples/s, speed: 40.855608 tokens/s, learning rate: 6.000e-08, loss_scalings: 26214.400391, pp_loss: 9.702873
[INFO] 2021-07-12 17:10:13,733 [run_pretraining.py:  512]:	********exe.run_7******* 
[INFO] 2021-07-12 17:11:53,682 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:11:53,682 [run_pretraining.py:  534]:	loss/total_loss, 10.556614875793457, 8
[INFO] 2021-07-12 17:11:53,682 [run_pretraining.py:  535]:	loss/mlm_loss, 10.556614875793457, 8
[INFO] 2021-07-12 17:11:53,683 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.999999868639861e-08, 8
[INFO] 2021-07-12 17:11:53,683 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 8
[INFO] 2021-07-12 17:11:53,683 [run_pretraining.py:  558]:	worker_index: 2, step: 8, cost: 10.556615, mlm loss: 10.556615, speed: 0.010005 steps/s, speed: 0.080041 samples/s, speed: 40.980760 tokens/s, learning rate: 7.000e-08, loss_scalings: 26214.400391, pp_loss: 10.507907
[INFO] 2021-07-12 17:11:53,683 [run_pretraining.py:  512]:	********exe.run_8******* 
[INFO] 2021-07-12 17:13:32,338 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:13:32,338 [run_pretraining.py:  534]:	loss/total_loss, 10.402817726135254, 9
[INFO] 2021-07-12 17:13:32,338 [run_pretraining.py:  535]:	loss/mlm_loss, 10.402817726135254, 9
[INFO] 2021-07-12 17:13:32,338 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.999999240837496e-08, 9
[INFO] 2021-07-12 17:13:32,339 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 9
[INFO] 2021-07-12 17:13:32,339 [run_pretraining.py:  558]:	worker_index: 2, step: 9, cost: 10.402818, mlm loss: 10.402818, speed: 0.010136 steps/s, speed: 0.081090 samples/s, speed: 41.518315 tokens/s, learning rate: 8.000e-08, loss_scalings: 26214.400391, pp_loss: 10.362304
[INFO] 2021-07-12 17:13:32,339 [run_pretraining.py:  512]:	********exe.run_9******* 
[INFO] 2021-07-12 17:15:11,265 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:15:11,266 [run_pretraining.py:  534]:	loss/total_loss, 10.449244499206543, 10
[INFO] 2021-07-12 17:15:11,266 [run_pretraining.py:  535]:	loss/mlm_loss, 10.449244499206543, 10
[INFO] 2021-07-12 17:15:11,266 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.999999323577867e-08, 10
[INFO] 2021-07-12 17:15:11,266 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 10
[INFO] 2021-07-12 17:15:11,266 [run_pretraining.py:  558]:	worker_index: 2, step: 10, cost: 10.449244, mlm loss: 10.449244, speed: 0.010108 steps/s, speed: 0.080868 samples/s, speed: 41.404220 tokens/s, learning rate: 9.000e-08, loss_scalings: 26214.400391, pp_loss: 10.477252
[INFO] 2021-07-12 17:15:11,267 [run_pretraining.py:  512]:	********exe.run_10******* 
[INFO] 2021-07-12 17:16:00,902 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:16:00,902 [run_pretraining.py:  534]:	loss/total_loss, 10.340970993041992, 11
[INFO] 2021-07-12 17:16:00,902 [run_pretraining.py:  535]:	loss/mlm_loss, 10.340970993041992, 11
[INFO] 2021-07-12 17:16:00,902 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0000000116860974e-07, 11
[INFO] 2021-07-12 17:16:00,902 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 11
[INFO] 2021-07-12 17:16:00,903 [run_pretraining.py:  558]:	worker_index: 2, step: 11, cost: 10.340971, mlm loss: 10.340971, speed: 0.020147 steps/s, speed: 0.161175 samples/s, speed: 82.521706 tokens/s, learning rate: 1.000e-07, loss_scalings: 26214.400391, pp_loss: 10.377746
[INFO] 2021-07-12 17:16:00,903 [run_pretraining.py:  512]:	********exe.run_11******* 
[INFO] 2021-07-12 17:17:35,423 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:17:35,424 [run_pretraining.py:  534]:	loss/total_loss, 10.360536575317383, 12
[INFO] 2021-07-12 17:17:35,424 [run_pretraining.py:  535]:	loss/mlm_loss, 10.360536575317383, 12
[INFO] 2021-07-12 17:17:35,424 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.099999948905861e-07, 12
[INFO] 2021-07-12 17:17:35,424 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 12
[INFO] 2021-07-12 17:17:35,424 [run_pretraining.py:  558]:	worker_index: 2, step: 12, cost: 10.360537, mlm loss: 10.360537, speed: 0.010580 steps/s, speed: 0.084637 samples/s, speed: 43.334368 tokens/s, learning rate: 1.100e-07, loss_scalings: 26214.400391, pp_loss: 10.396097
[INFO] 2021-07-12 17:17:35,424 [run_pretraining.py:  512]:	********exe.run_12******* 
[INFO] 2021-07-12 17:18:51,080 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:18:51,081 [run_pretraining.py:  534]:	loss/total_loss, 10.251988410949707, 13
[INFO] 2021-07-12 17:18:51,081 [run_pretraining.py:  535]:	loss/mlm_loss, 10.251988410949707, 13
[INFO] 2021-07-12 17:18:51,081 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.199999957179898e-07, 13
[INFO] 2021-07-12 17:18:51,081 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 13
[INFO] 2021-07-12 17:18:51,081 [run_pretraining.py:  558]:	worker_index: 2, step: 13, cost: 10.251988, mlm loss: 10.251988, speed: 0.013218 steps/s, speed: 0.105741 samples/s, speed: 54.139644 tokens/s, learning rate: 1.200e-07, loss_scalings: 26214.400391, pp_loss: 10.422384
[INFO] 2021-07-12 17:18:51,081 [run_pretraining.py:  512]:	********exe.run_13******* 
[INFO] 2021-07-12 17:20:05,861 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:20:05,862 [run_pretraining.py:  534]:	loss/total_loss, 10.467621803283691, 14
[INFO] 2021-07-12 17:20:05,862 [run_pretraining.py:  535]:	loss/mlm_loss, 10.467621803283691, 14
[INFO] 2021-07-12 17:20:05,862 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3000000365082087e-07, 14
[INFO] 2021-07-12 17:20:05,862 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 14
[INFO] 2021-07-12 17:20:05,862 [run_pretraining.py:  558]:	worker_index: 2, step: 14, cost: 10.467622, mlm loss: 10.467622, speed: 0.013372 steps/s, speed: 0.106980 samples/s, speed: 54.773597 tokens/s, learning rate: 1.300e-07, loss_scalings: 26214.400391, pp_loss: 9.199184
[INFO] 2021-07-12 17:20:05,862 [run_pretraining.py:  512]:	********exe.run_14******* 
[INFO] 2021-07-12 17:21:43,819 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:21:43,819 [run_pretraining.py:  534]:	loss/total_loss, 10.466593742370605, 15
[INFO] 2021-07-12 17:21:43,819 [run_pretraining.py:  535]:	loss/mlm_loss, 10.466593742370605, 15
[INFO] 2021-07-12 17:21:43,820 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3999999737279722e-07, 15
[INFO] 2021-07-12 17:21:43,820 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 15
[INFO] 2021-07-12 17:21:43,820 [run_pretraining.py:  558]:	worker_index: 2, step: 15, cost: 10.466594, mlm loss: 10.466594, speed: 0.010209 steps/s, speed: 0.081669 samples/s, speed: 41.814379 tokens/s, learning rate: 1.400e-07, loss_scalings: 26214.400391, pp_loss: 10.456573
[INFO] 2021-07-12 17:21:43,820 [run_pretraining.py:  512]:	********exe.run_15******* 
[INFO] 2021-07-12 17:22:59,146 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:22:59,147 [run_pretraining.py:  534]:	loss/total_loss, 10.492429733276367, 16
[INFO] 2021-07-12 17:22:59,147 [run_pretraining.py:  535]:	loss/mlm_loss, 10.492429733276367, 16
[INFO] 2021-07-12 17:22:59,147 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4999999109477358e-07, 16
[INFO] 2021-07-12 17:22:59,147 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 16
[INFO] 2021-07-12 17:22:59,147 [run_pretraining.py:  558]:	worker_index: 2, step: 16, cost: 10.492430, mlm loss: 10.492430, speed: 0.013275 steps/s, speed: 0.106204 samples/s, speed: 54.376258 tokens/s, learning rate: 1.500e-07, loss_scalings: 26214.400391, pp_loss: 10.435429
[INFO] 2021-07-12 17:22:59,148 [run_pretraining.py:  512]:	********exe.run_16******* 
[INFO] 2021-07-12 17:23:49,297 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:23:49,298 [run_pretraining.py:  534]:	loss/total_loss, 7.600086688995361, 17
[INFO] 2021-07-12 17:23:49,298 [run_pretraining.py:  535]:	loss/mlm_loss, 7.600086688995361, 17
[INFO] 2021-07-12 17:23:49,298 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5999998481674993e-07, 17
[INFO] 2021-07-12 17:23:49,298 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 17
[INFO] 2021-07-12 17:23:49,298 [run_pretraining.py:  558]:	worker_index: 2, step: 17, cost: 7.600087, mlm loss: 7.600087, speed: 0.019940 steps/s, speed: 0.159521 samples/s, speed: 81.674683 tokens/s, learning rate: 1.600e-07, loss_scalings: 26214.400391, pp_loss: 9.717973
[INFO] 2021-07-12 17:23:49,298 [run_pretraining.py:  512]:	********exe.run_17******* 
[INFO] 2021-07-12 17:25:28,092 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:25:28,093 [run_pretraining.py:  534]:	loss/total_loss, 6.413821220397949, 18
[INFO] 2021-07-12 17:25:28,093 [run_pretraining.py:  535]:	loss/mlm_loss, 6.413821220397949, 18
[INFO] 2021-07-12 17:25:28,093 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.69999992749581e-07, 18
[INFO] 2021-07-12 17:25:28,093 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 18
[INFO] 2021-07-12 17:25:28,093 [run_pretraining.py:  558]:	worker_index: 2, step: 18, cost: 6.413821, mlm loss: 6.413821, speed: 0.010122 steps/s, speed: 0.080977 samples/s, speed: 41.460005 tokens/s, learning rate: 1.700e-07, loss_scalings: 26214.400391, pp_loss: 9.380110
[INFO] 2021-07-12 17:25:28,093 [run_pretraining.py:  512]:	********exe.run_18******* 
[INFO] 2021-07-12 17:27:03,433 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:27:03,433 [run_pretraining.py:  534]:	loss/total_loss, 10.44345474243164, 19
[INFO] 2021-07-12 17:27:03,434 [run_pretraining.py:  535]:	loss/mlm_loss, 10.44345474243164, 19
[INFO] 2021-07-12 17:27:03,434 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7999998647155735e-07, 19
[INFO] 2021-07-12 17:27:03,434 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 19
[INFO] 2021-07-12 17:27:03,435 [run_pretraining.py:  558]:	worker_index: 2, step: 19, cost: 10.443455, mlm loss: 10.443455, speed: 0.010489 steps/s, speed: 0.083910 samples/s, speed: 42.961930 tokens/s, learning rate: 1.800e-07, loss_scalings: 26214.400391, pp_loss: 10.403332
[INFO] 2021-07-12 17:27:03,435 [run_pretraining.py:  512]:	********exe.run_19******* 
[INFO] 2021-07-12 17:28:18,378 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:28:18,379 [run_pretraining.py:  534]:	loss/total_loss, 10.3706693649292, 20
[INFO] 2021-07-12 17:28:18,379 [run_pretraining.py:  535]:	loss/mlm_loss, 10.3706693649292, 20
[INFO] 2021-07-12 17:28:18,379 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8999999440438842e-07, 20
[INFO] 2021-07-12 17:28:18,379 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 20
[INFO] 2021-07-12 17:28:18,379 [run_pretraining.py:  558]:	worker_index: 2, step: 20, cost: 10.370669, mlm loss: 10.370669, speed: 0.013343 steps/s, speed: 0.106747 samples/s, speed: 54.654407 tokens/s, learning rate: 1.900e-07, loss_scalings: 26214.400391, pp_loss: 10.449478
[INFO] 2021-07-12 17:28:18,379 [run_pretraining.py:  512]:	********exe.run_20******* 
[INFO] 2021-07-12 17:29:07,957 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:29:07,957 [run_pretraining.py:  534]:	loss/total_loss, 10.456209182739258, 21
[INFO] 2021-07-12 17:29:07,957 [run_pretraining.py:  535]:	loss/mlm_loss, 10.456209182739258, 21
[INFO] 2021-07-12 17:29:07,957 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0000000233721948e-07, 21
[INFO] 2021-07-12 17:29:07,957 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 21
[INFO] 2021-07-12 17:29:07,957 [run_pretraining.py:  558]:	worker_index: 2, step: 21, cost: 10.456209, mlm loss: 10.456209, speed: 0.020170 steps/s, speed: 0.161363 samples/s, speed: 82.617763 tokens/s, learning rate: 2.000e-07, loss_scalings: 26214.400391, pp_loss: 10.421322
[INFO] 2021-07-12 17:29:07,957 [run_pretraining.py:  512]:	********exe.run_21******* 
[INFO] 2021-07-12 17:30:23,121 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:30:23,122 [run_pretraining.py:  534]:	loss/total_loss, 10.367354393005371, 22
[INFO] 2021-07-12 17:30:23,122 [run_pretraining.py:  535]:	loss/mlm_loss, 10.367354393005371, 22
[INFO] 2021-07-12 17:30:23,122 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0999998184834112e-07, 22
[INFO] 2021-07-12 17:30:23,122 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 22
[INFO] 2021-07-12 17:30:23,122 [run_pretraining.py:  558]:	worker_index: 2, step: 22, cost: 10.367354, mlm loss: 10.367354, speed: 0.013304 steps/s, speed: 0.106434 samples/s, speed: 54.493965 tokens/s, learning rate: 2.100e-07, loss_scalings: 26214.400391, pp_loss: 10.397345
[INFO] 2021-07-12 17:30:23,122 [run_pretraining.py:  512]:	********exe.run_22******* 
[INFO] 2021-07-12 17:32:00,385 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:32:00,386 [run_pretraining.py:  534]:	loss/total_loss, 10.398898124694824, 23
[INFO] 2021-07-12 17:32:00,386 [run_pretraining.py:  535]:	loss/mlm_loss, 10.398898124694824, 23
[INFO] 2021-07-12 17:32:00,386 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.199999897811722e-07, 23
[INFO] 2021-07-12 17:32:00,386 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 23
[INFO] 2021-07-12 17:32:00,386 [run_pretraining.py:  558]:	worker_index: 2, step: 23, cost: 10.398898, mlm loss: 10.398898, speed: 0.010281 steps/s, speed: 0.082251 samples/s, speed: 42.112483 tokens/s, learning rate: 2.200e-07, loss_scalings: 26214.400391, pp_loss: 10.415967
[INFO] 2021-07-12 17:32:00,386 [run_pretraining.py:  512]:	********exe.run_23******* 
[INFO] 2021-07-12 17:33:12,809 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:33:12,809 [run_pretraining.py:  534]:	loss/total_loss, 10.489948272705078, 24
[INFO] 2021-07-12 17:33:12,809 [run_pretraining.py:  535]:	loss/mlm_loss, 10.489948272705078, 24
[INFO] 2021-07-12 17:33:12,809 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2999999771400326e-07, 24
[INFO] 2021-07-12 17:33:12,809 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 24
[INFO] 2021-07-12 17:33:12,810 [run_pretraining.py:  558]:	worker_index: 2, step: 24, cost: 10.489948, mlm loss: 10.489948, speed: 0.013808 steps/s, speed: 0.110463 samples/s, speed: 56.556923 tokens/s, learning rate: 2.300e-07, loss_scalings: 26214.400391, pp_loss: 10.426266
[INFO] 2021-07-12 17:33:12,810 [run_pretraining.py:  512]:	********exe.run_24******* 
[INFO] 2021-07-12 17:34:27,396 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:34:27,396 [run_pretraining.py:  534]:	loss/total_loss, 10.378793716430664, 25
[INFO] 2021-07-12 17:34:27,396 [run_pretraining.py:  535]:	loss/mlm_loss, 10.378793716430664, 25
[INFO] 2021-07-12 17:34:27,396 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.399999914359796e-07, 25
[INFO] 2021-07-12 17:34:27,397 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 25
[INFO] 2021-07-12 17:34:27,397 [run_pretraining.py:  558]:	worker_index: 2, step: 25, cost: 10.378794, mlm loss: 10.378794, speed: 0.013407 steps/s, speed: 0.107258 samples/s, speed: 54.916128 tokens/s, learning rate: 2.400e-07, loss_scalings: 26214.400391, pp_loss: 10.433697
[INFO] 2021-07-12 17:34:27,397 [run_pretraining.py:  512]:	********exe.run_25******* 
[INFO] 2021-07-12 17:36:04,223 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:36:04,224 [run_pretraining.py:  534]:	loss/total_loss, 10.404026985168457, 26
[INFO] 2021-07-12 17:36:04,224 [run_pretraining.py:  535]:	loss/mlm_loss, 10.404026985168457, 26
[INFO] 2021-07-12 17:36:04,224 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.499999993688107e-07, 26
[INFO] 2021-07-12 17:36:04,224 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 26
[INFO] 2021-07-12 17:36:04,224 [run_pretraining.py:  558]:	worker_index: 2, step: 26, cost: 10.404027, mlm loss: 10.404027, speed: 0.010328 steps/s, speed: 0.082622 samples/s, speed: 42.302376 tokens/s, learning rate: 2.500e-07, loss_scalings: 26214.400391, pp_loss: 10.378476
[INFO] 2021-07-12 17:36:04,224 [run_pretraining.py:  512]:	********exe.run_26******* 
[INFO] 2021-07-12 17:37:41,312 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:37:41,312 [run_pretraining.py:  534]:	loss/total_loss, 10.48907470703125, 27
[INFO] 2021-07-12 17:37:41,312 [run_pretraining.py:  535]:	loss/mlm_loss, 10.48907470703125, 27
[INFO] 2021-07-12 17:37:41,312 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6000000730164174e-07, 27
[INFO] 2021-07-12 17:37:41,312 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 27
[INFO] 2021-07-12 17:37:41,313 [run_pretraining.py:  558]:	worker_index: 2, step: 27, cost: 10.489075, mlm loss: 10.489075, speed: 0.010300 steps/s, speed: 0.082400 samples/s, speed: 42.188555 tokens/s, learning rate: 2.600e-07, loss_scalings: 26214.400391, pp_loss: 10.326438
[INFO] 2021-07-12 17:37:41,313 [run_pretraining.py:  512]:	********exe.run_27******* 
[INFO] 2021-07-12 17:38:32,245 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:38:32,245 [run_pretraining.py:  534]:	loss/total_loss, 10.372662544250488, 28
[INFO] 2021-07-12 17:38:32,246 [run_pretraining.py:  535]:	loss/mlm_loss, 10.372662544250488, 28
[INFO] 2021-07-12 17:38:32,246 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.699999868127634e-07, 28
[INFO] 2021-07-12 17:38:32,246 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 28
[INFO] 2021-07-12 17:38:32,246 [run_pretraining.py:  558]:	worker_index: 2, step: 28, cost: 10.372663, mlm loss: 10.372663, speed: 0.019634 steps/s, speed: 0.157070 samples/s, speed: 80.419824 tokens/s, learning rate: 2.700e-07, loss_scalings: 26214.400391, pp_loss: 10.438712
[INFO] 2021-07-12 17:38:32,246 [run_pretraining.py:  512]:	********exe.run_28******* 
[INFO] 2021-07-12 17:39:43,320 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:39:43,321 [run_pretraining.py:  534]:	loss/total_loss, 10.416122436523438, 29
[INFO] 2021-07-12 17:39:43,321 [run_pretraining.py:  535]:	loss/mlm_loss, 10.416122436523438, 29
[INFO] 2021-07-12 17:39:43,321 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7999999474559445e-07, 29
[INFO] 2021-07-12 17:39:43,321 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 29
[INFO] 2021-07-12 17:39:43,321 [run_pretraining.py:  558]:	worker_index: 2, step: 29, cost: 10.416122, mlm loss: 10.416122, speed: 0.014070 steps/s, speed: 0.112558 samples/s, speed: 57.629544 tokens/s, learning rate: 2.800e-07, loss_scalings: 26214.400391, pp_loss: 10.161335
[INFO] 2021-07-12 17:39:43,321 [run_pretraining.py:  512]:	********exe.run_29******* 
[INFO] 2021-07-12 17:40:32,213 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:40:32,214 [run_pretraining.py:  534]:	loss/total_loss, 10.377140045166016, 30
[INFO] 2021-07-12 17:40:32,214 [run_pretraining.py:  535]:	loss/mlm_loss, 10.377140045166016, 30
[INFO] 2021-07-12 17:40:32,214 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.900000026784255e-07, 30
[INFO] 2021-07-12 17:40:32,214 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 30
[INFO] 2021-07-12 17:40:32,214 [run_pretraining.py:  558]:	worker_index: 2, step: 30, cost: 10.377140, mlm loss: 10.377140, speed: 0.020453 steps/s, speed: 0.163624 samples/s, speed: 83.775424 tokens/s, learning rate: 2.900e-07, loss_scalings: 26214.400391, pp_loss: 10.414763
[INFO] 2021-07-12 17:40:32,214 [run_pretraining.py:  512]:	********exe.run_30******* 
[INFO] 2021-07-12 17:41:23,348 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:41:23,349 [run_pretraining.py:  534]:	loss/total_loss, 10.37355899810791, 31
[INFO] 2021-07-12 17:41:23,349 [run_pretraining.py:  535]:	loss/mlm_loss, 10.37355899810791, 31
[INFO] 2021-07-12 17:41:23,349 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9999998218954715e-07, 31
[INFO] 2021-07-12 17:41:23,349 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 31
[INFO] 2021-07-12 17:41:23,349 [run_pretraining.py:  558]:	worker_index: 2, step: 31, cost: 10.373559, mlm loss: 10.373559, speed: 0.019556 steps/s, speed: 0.156451 samples/s, speed: 80.102753 tokens/s, learning rate: 3.000e-07, loss_scalings: 26214.400391, pp_loss: 10.417791
[INFO] 2021-07-12 17:41:23,349 [run_pretraining.py:  512]:	********exe.run_31******* 
[INFO] 2021-07-12 17:42:13,621 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:42:13,621 [run_pretraining.py:  534]:	loss/total_loss, 10.358739852905273, 32
[INFO] 2021-07-12 17:42:13,621 [run_pretraining.py:  535]:	loss/mlm_loss, 10.358739852905273, 32
[INFO] 2021-07-12 17:42:13,622 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.099999901223782e-07, 32
[INFO] 2021-07-12 17:42:13,622 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 32
[INFO] 2021-07-12 17:42:13,622 [run_pretraining.py:  558]:	worker_index: 2, step: 32, cost: 10.358740, mlm loss: 10.358740, speed: 0.019892 steps/s, speed: 0.159135 samples/s, speed: 81.477165 tokens/s, learning rate: 3.100e-07, loss_scalings: 26214.400391, pp_loss: 10.425428
[INFO] 2021-07-12 17:42:13,622 [run_pretraining.py:  512]:	********exe.run_32******* 
[INFO] 2021-07-12 17:43:03,044 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:43:03,045 [run_pretraining.py:  534]:	loss/total_loss, 10.366271018981934, 33
[INFO] 2021-07-12 17:43:03,045 [run_pretraining.py:  535]:	loss/mlm_loss, 10.366271018981934, 33
[INFO] 2021-07-12 17:43:03,045 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.1999996963349986e-07, 33
[INFO] 2021-07-12 17:43:03,045 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 33
[INFO] 2021-07-12 17:43:03,045 [run_pretraining.py:  558]:	worker_index: 2, step: 33, cost: 10.366271, mlm loss: 10.366271, speed: 0.020234 steps/s, speed: 0.161868 samples/s, speed: 82.876536 tokens/s, learning rate: 3.200e-07, loss_scalings: 26214.400391, pp_loss: 10.342483
[INFO] 2021-07-12 17:43:03,045 [run_pretraining.py:  512]:	********exe.run_33******* 
[INFO] 2021-07-12 17:43:29,438 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:43:29,439 [run_pretraining.py:  534]:	loss/total_loss, 10.355934143066406, 34
[INFO] 2021-07-12 17:43:29,439 [run_pretraining.py:  535]:	loss/mlm_loss, 10.355934143066406, 34
[INFO] 2021-07-12 17:43:29,439 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.2999997756633093e-07, 34
[INFO] 2021-07-12 17:43:29,439 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 34
[INFO] 2021-07-12 17:43:29,439 [run_pretraining.py:  558]:	worker_index: 2, step: 34, cost: 10.355934, mlm loss: 10.355934, speed: 0.037889 steps/s, speed: 0.303110 samples/s, speed: 155.192231 tokens/s, learning rate: 3.300e-07, loss_scalings: 26214.400391, pp_loss: 10.417729
[INFO] 2021-07-12 17:43:29,439 [run_pretraining.py:  512]:	********exe.run_34******* 
[INFO] 2021-07-12 17:44:17,415 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:44:17,416 [run_pretraining.py:  534]:	loss/total_loss, 10.395453453063965, 35
[INFO] 2021-07-12 17:44:17,416 [run_pretraining.py:  535]:	loss/mlm_loss, 10.395453453063965, 35
[INFO] 2021-07-12 17:44:17,416 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.39999985499162e-07, 35
[INFO] 2021-07-12 17:44:17,416 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 35
[INFO] 2021-07-12 17:44:17,416 [run_pretraining.py:  558]:	worker_index: 2, step: 35, cost: 10.395453, mlm loss: 10.395453, speed: 0.020844 steps/s, speed: 0.166749 samples/s, speed: 85.375296 tokens/s, learning rate: 3.400e-07, loss_scalings: 26214.400391, pp_loss: 10.407569
[INFO] 2021-07-12 17:44:17,416 [run_pretraining.py:  512]:	********exe.run_35******* 
[INFO] 2021-07-12 17:44:42,784 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:44:42,785 [run_pretraining.py:  534]:	loss/total_loss, 10.3474760055542, 36
[INFO] 2021-07-12 17:44:42,785 [run_pretraining.py:  535]:	loss/mlm_loss, 10.3474760055542, 36
[INFO] 2021-07-12 17:44:42,785 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.4999999343199306e-07, 36
[INFO] 2021-07-12 17:44:42,785 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 36
[INFO] 2021-07-12 17:44:42,785 [run_pretraining.py:  558]:	worker_index: 2, step: 36, cost: 10.347476, mlm loss: 10.347476, speed: 0.039419 steps/s, speed: 0.315348 samples/s, speed: 161.458358 tokens/s, learning rate: 3.500e-07, loss_scalings: 26214.400391, pp_loss: 10.325488
[INFO] 2021-07-12 17:44:42,785 [run_pretraining.py:  512]:	********exe.run_36******* 
[INFO] 2021-07-12 17:45:32,283 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:45:32,283 [run_pretraining.py:  534]:	loss/total_loss, 10.369026184082031, 37
[INFO] 2021-07-12 17:45:32,283 [run_pretraining.py:  535]:	loss/mlm_loss, 10.369026184082031, 37
[INFO] 2021-07-12 17:45:32,283 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.599999729431147e-07, 37
[INFO] 2021-07-12 17:45:32,283 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 37
[INFO] 2021-07-12 17:45:32,283 [run_pretraining.py:  558]:	worker_index: 2, step: 37, cost: 10.369026, mlm loss: 10.369026, speed: 0.020203 steps/s, speed: 0.161624 samples/s, speed: 82.751664 tokens/s, learning rate: 3.600e-07, loss_scalings: 26214.400391, pp_loss: 10.361475
[INFO] 2021-07-12 17:45:32,284 [run_pretraining.py:  512]:	********exe.run_37******* 
[INFO] 2021-07-12 17:45:33,248 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:45:33,248 [run_pretraining.py:  534]:	loss/total_loss, 9.19563102722168, 38
[INFO] 2021-07-12 17:45:33,248 [run_pretraining.py:  535]:	loss/mlm_loss, 9.19563102722168, 38
[INFO] 2021-07-12 17:45:33,248 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.6999998087594577e-07, 38
[INFO] 2021-07-12 17:45:33,248 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 38
[INFO] 2021-07-12 17:45:33,248 [run_pretraining.py:  558]:	worker_index: 2, step: 38, cost: 9.195631, mlm loss: 9.195631, speed: 1.036899 steps/s, speed: 8.295196 samples/s, speed: 4247.140250 tokens/s, learning rate: 3.700e-07, loss_scalings: 26214.400391, pp_loss: 10.066525
[INFO] 2021-07-12 17:45:33,249 [run_pretraining.py:  512]:	********exe.run_38******* 
[INFO] 2021-07-12 17:46:46,187 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:46:46,187 [run_pretraining.py:  534]:	loss/total_loss, 10.514869689941406, 39
[INFO] 2021-07-12 17:46:46,187 [run_pretraining.py:  535]:	loss/mlm_loss, 10.514869689941406, 39
[INFO] 2021-07-12 17:46:46,188 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.7999998880877683e-07, 39
[INFO] 2021-07-12 17:46:46,188 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 39
[INFO] 2021-07-12 17:46:46,188 [run_pretraining.py:  558]:	worker_index: 2, step: 39, cost: 10.514870, mlm loss: 10.514870, speed: 0.013710 steps/s, speed: 0.109681 samples/s, speed: 56.156788 tokens/s, learning rate: 3.800e-07, loss_scalings: 26214.400391, pp_loss: 10.411705
[INFO] 2021-07-12 17:46:46,188 [run_pretraining.py:  512]:	********exe.run_39******* 
[INFO] 2021-07-12 17:47:10,247 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:47:10,247 [run_pretraining.py:  534]:	loss/total_loss, 10.543925285339355, 40
[INFO] 2021-07-12 17:47:10,247 [run_pretraining.py:  535]:	loss/mlm_loss, 10.543925285339355, 40
[INFO] 2021-07-12 17:47:10,247 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.8999996831989847e-07, 40
[INFO] 2021-07-12 17:47:10,247 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 40
[INFO] 2021-07-12 17:47:10,247 [run_pretraining.py:  558]:	worker_index: 2, step: 40, cost: 10.543925, mlm loss: 10.543925, speed: 0.041564 steps/s, speed: 0.332515 samples/s, speed: 170.247578 tokens/s, learning rate: 3.900e-07, loss_scalings: 26214.400391, pp_loss: 10.453760
[INFO] 2021-07-12 17:47:10,248 [run_pretraining.py:  512]:	********exe.run_40******* 
[INFO] 2021-07-12 17:48:26,852 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:48:26,853 [run_pretraining.py:  534]:	loss/total_loss, 10.395049095153809, 41
[INFO] 2021-07-12 17:48:26,853 [run_pretraining.py:  535]:	loss/mlm_loss, 10.395049095153809, 41
[INFO] 2021-07-12 17:48:26,853 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.0000000467443897e-07, 41
[INFO] 2021-07-12 17:48:26,853 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 41
[INFO] 2021-07-12 17:48:26,853 [run_pretraining.py:  558]:	worker_index: 2, step: 41, cost: 10.395049, mlm loss: 10.395049, speed: 0.013054 steps/s, speed: 0.104432 samples/s, speed: 53.469227 tokens/s, learning rate: 4.000e-07, loss_scalings: 26214.400391, pp_loss: 10.413787
[INFO] 2021-07-12 17:48:26,853 [run_pretraining.py:  512]:	********exe.run_41******* 
[INFO] 2021-07-12 17:49:41,991 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:49:41,992 [run_pretraining.py:  534]:	loss/total_loss, 10.55478286743164, 42
[INFO] 2021-07-12 17:49:41,992 [run_pretraining.py:  535]:	loss/mlm_loss, 10.55478286743164, 42
[INFO] 2021-07-12 17:49:41,992 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.099999841855606e-07, 42
[INFO] 2021-07-12 17:49:41,992 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 42
[INFO] 2021-07-12 17:49:41,992 [run_pretraining.py:  558]:	worker_index: 2, step: 42, cost: 10.554783, mlm loss: 10.554783, speed: 0.013309 steps/s, speed: 0.106470 samples/s, speed: 54.512429 tokens/s, learning rate: 4.100e-07, loss_scalings: 26214.400391, pp_loss: 10.438859
[INFO] 2021-07-12 17:49:41,992 [run_pretraining.py:  512]:	********exe.run_42******* 
[INFO] 2021-07-12 17:50:07,113 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:50:07,113 [run_pretraining.py:  534]:	loss/total_loss, 10.412137031555176, 43
[INFO] 2021-07-12 17:50:07,113 [run_pretraining.py:  535]:	loss/mlm_loss, 10.412137031555176, 43
[INFO] 2021-07-12 17:50:07,113 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.1999996369668224e-07, 43
[INFO] 2021-07-12 17:50:07,113 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 43
[INFO] 2021-07-12 17:50:07,113 [run_pretraining.py:  558]:	worker_index: 2, step: 43, cost: 10.412137, mlm loss: 10.412137, speed: 0.039808 steps/s, speed: 0.318464 samples/s, speed: 163.053760 tokens/s, learning rate: 4.200e-07, loss_scalings: 26214.400391, pp_loss: 10.391992
[INFO] 2021-07-12 17:50:07,114 [run_pretraining.py:  512]:	********exe.run_43******* 
[INFO] 2021-07-12 17:50:31,955 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:50:31,956 [run_pretraining.py:  534]:	loss/total_loss, 10.402585983276367, 44
[INFO] 2021-07-12 17:50:31,956 [run_pretraining.py:  535]:	loss/mlm_loss, 10.402585983276367, 44
[INFO] 2021-07-12 17:50:31,956 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.3000000005122274e-07, 44
[INFO] 2021-07-12 17:50:31,956 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 44
[INFO] 2021-07-12 17:50:31,956 [run_pretraining.py:  558]:	worker_index: 2, step: 44, cost: 10.402586, mlm loss: 10.402586, speed: 0.040254 steps/s, speed: 0.322035 samples/s, speed: 164.882002 tokens/s, learning rate: 4.300e-07, loss_scalings: 26214.400391, pp_loss: 10.406654
[INFO] 2021-07-12 17:50:31,956 [run_pretraining.py:  512]:	********exe.run_44******* 
[INFO] 2021-07-12 17:51:21,598 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:51:21,599 [run_pretraining.py:  534]:	loss/total_loss, 10.279544830322266, 45
[INFO] 2021-07-12 17:51:21,599 [run_pretraining.py:  535]:	loss/mlm_loss, 10.279544830322266, 45
[INFO] 2021-07-12 17:51:21,599 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.399999795623444e-07, 45
[INFO] 2021-07-12 17:51:21,599 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 45
[INFO] 2021-07-12 17:51:21,599 [run_pretraining.py:  558]:	worker_index: 2, step: 45, cost: 10.279545, mlm loss: 10.279545, speed: 0.020144 steps/s, speed: 0.161153 samples/s, speed: 82.510225 tokens/s, learning rate: 4.400e-07, loss_scalings: 26214.400391, pp_loss: 10.258840
[INFO] 2021-07-12 17:51:21,599 [run_pretraining.py:  512]:	********exe.run_45******* 
[INFO] 2021-07-12 17:51:48,536 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:51:48,537 [run_pretraining.py:  534]:	loss/total_loss, 10.483705520629883, 46
[INFO] 2021-07-12 17:51:48,537 [run_pretraining.py:  535]:	loss/mlm_loss, 10.483705520629883, 46
[INFO] 2021-07-12 17:51:48,537 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.49999959073466e-07, 46
[INFO] 2021-07-12 17:51:48,537 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 46
[INFO] 2021-07-12 17:51:48,537 [run_pretraining.py:  558]:	worker_index: 2, step: 46, cost: 10.483706, mlm loss: 10.483706, speed: 0.037123 steps/s, speed: 0.296982 samples/s, speed: 152.054785 tokens/s, learning rate: 4.500e-07, loss_scalings: 26214.400391, pp_loss: 10.326888
[INFO] 2021-07-12 17:51:48,538 [run_pretraining.py:  512]:	********exe.run_46******* 
[INFO] 2021-07-12 17:52:37,781 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:52:37,782 [run_pretraining.py:  534]:	loss/total_loss, 10.2330961227417, 47
[INFO] 2021-07-12 17:52:37,782 [run_pretraining.py:  535]:	loss/mlm_loss, 10.2330961227417, 47
[INFO] 2021-07-12 17:52:37,782 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.599999954280065e-07, 47
[INFO] 2021-07-12 17:52:37,782 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 47
[INFO] 2021-07-12 17:52:37,782 [run_pretraining.py:  558]:	worker_index: 2, step: 47, cost: 10.233096, mlm loss: 10.233096, speed: 0.020307 steps/s, speed: 0.162457 samples/s, speed: 83.177859 tokens/s, learning rate: 4.600e-07, loss_scalings: 26214.400391, pp_loss: 10.306396
[INFO] 2021-07-12 17:52:37,782 [run_pretraining.py:  512]:	********exe.run_47******* 
[INFO] 2021-07-12 17:53:01,998 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:53:01,998 [run_pretraining.py:  534]:	loss/total_loss, 10.39791488647461, 48
[INFO] 2021-07-12 17:53:01,998 [run_pretraining.py:  535]:	loss/mlm_loss, 10.39791488647461, 48
[INFO] 2021-07-12 17:53:01,998 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.6999997493912815e-07, 48
[INFO] 2021-07-12 17:53:01,999 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 48
[INFO] 2021-07-12 17:53:01,999 [run_pretraining.py:  558]:	worker_index: 2, step: 48, cost: 10.397915, mlm loss: 10.397915, speed: 0.041295 steps/s, speed: 0.330359 samples/s, speed: 169.143676 tokens/s, learning rate: 4.700e-07, loss_scalings: 26214.400391, pp_loss: 10.369006
[INFO] 2021-07-12 17:53:01,999 [run_pretraining.py:  512]:	********exe.run_48******* 
[INFO] 2021-07-12 17:54:14,143 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:54:14,144 [run_pretraining.py:  534]:	loss/total_loss, 10.262491226196289, 49
[INFO] 2021-07-12 17:54:14,144 [run_pretraining.py:  535]:	loss/mlm_loss, 10.262491226196289, 49
[INFO] 2021-07-12 17:54:14,144 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.799999828719592e-07, 49
[INFO] 2021-07-12 17:54:14,144 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 49
[INFO] 2021-07-12 17:54:14,144 [run_pretraining.py:  558]:	worker_index: 2, step: 49, cost: 10.262491, mlm loss: 10.262491, speed: 0.013861 steps/s, speed: 0.110888 samples/s, speed: 56.774558 tokens/s, learning rate: 4.800e-07, loss_scalings: 26214.400391, pp_loss: 9.536865
[INFO] 2021-07-12 17:54:14,144 [run_pretraining.py:  512]:	********exe.run_49******* 
[INFO] 2021-07-12 17:54:39,251 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:54:39,251 [run_pretraining.py:  534]:	loss/total_loss, 10.42474365234375, 50
[INFO] 2021-07-12 17:54:39,251 [run_pretraining.py:  535]:	loss/mlm_loss, 10.42474365234375, 50
[INFO] 2021-07-12 17:54:39,251 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.899999908047903e-07, 50
[INFO] 2021-07-12 17:54:39,251 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 50
[INFO] 2021-07-12 17:54:39,251 [run_pretraining.py:  558]:	worker_index: 2, step: 50, cost: 10.424744, mlm loss: 10.424744, speed: 0.039830 steps/s, speed: 0.318642 samples/s, speed: 163.144907 tokens/s, learning rate: 4.900e-07, loss_scalings: 26214.400391, pp_loss: 10.424154
[INFO] 2021-07-12 17:54:39,251 [run_pretraining.py:  512]:	********exe.run_50******* 
[INFO] 2021-07-12 17:55:04,391 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:55:04,391 [run_pretraining.py:  534]:	loss/total_loss, 10.489302635192871, 51
[INFO] 2021-07-12 17:55:04,392 [run_pretraining.py:  535]:	loss/mlm_loss, 10.489302635192871, 51
[INFO] 2021-07-12 17:55:04,392 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.999999987376214e-07, 51
[INFO] 2021-07-12 17:55:04,392 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 51
[INFO] 2021-07-12 17:55:04,392 [run_pretraining.py:  558]:	worker_index: 2, step: 51, cost: 10.489303, mlm loss: 10.489303, speed: 0.039778 steps/s, speed: 0.318221 samples/s, speed: 162.929250 tokens/s, learning rate: 5.000e-07, loss_scalings: 26214.400391, pp_loss: 10.397749
[INFO] 2021-07-12 17:55:04,392 [run_pretraining.py:  512]:	********exe.run_51******* 
[INFO] 2021-07-12 17:56:38,498 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:56:38,498 [run_pretraining.py:  534]:	loss/total_loss, 10.411470413208008, 52
[INFO] 2021-07-12 17:56:38,498 [run_pretraining.py:  535]:	loss/mlm_loss, 10.411470413208008, 52
[INFO] 2021-07-12 17:56:38,498 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.100000066704524e-07, 52
[INFO] 2021-07-12 17:56:38,498 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 52
[INFO] 2021-07-12 17:56:38,499 [run_pretraining.py:  558]:	worker_index: 2, step: 52, cost: 10.411470, mlm loss: 10.411470, speed: 0.010626 steps/s, speed: 0.085010 samples/s, speed: 43.525338 tokens/s, learning rate: 5.100e-07, loss_scalings: 26214.400391, pp_loss: 10.398243
[INFO] 2021-07-12 17:56:38,499 [run_pretraining.py:  512]:	********exe.run_52******* 
[INFO] 2021-07-12 17:57:01,480 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:57:01,481 [run_pretraining.py:  534]:	loss/total_loss, 10.443428039550781, 53
[INFO] 2021-07-12 17:57:01,481 [run_pretraining.py:  535]:	loss/mlm_loss, 10.443428039550781, 53
[INFO] 2021-07-12 17:57:01,481 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.200000146032835e-07, 53
[INFO] 2021-07-12 17:57:01,481 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 53
[INFO] 2021-07-12 17:57:01,481 [run_pretraining.py:  558]:	worker_index: 2, step: 53, cost: 10.443428, mlm loss: 10.443428, speed: 0.043513 steps/s, speed: 0.348103 samples/s, speed: 178.228665 tokens/s, learning rate: 5.200e-07, loss_scalings: 26214.400391, pp_loss: 10.485648
[INFO] 2021-07-12 17:57:01,481 [run_pretraining.py:  512]:	********exe.run_53******* 
[INFO] 2021-07-12 17:57:26,472 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:57:26,473 [run_pretraining.py:  534]:	loss/total_loss, 10.411895751953125, 54
[INFO] 2021-07-12 17:57:26,473 [run_pretraining.py:  535]:	loss/mlm_loss, 10.411895751953125, 54
[INFO] 2021-07-12 17:57:26,473 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.299999656926957e-07, 54
[INFO] 2021-07-12 17:57:26,473 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 54
[INFO] 2021-07-12 17:57:26,473 [run_pretraining.py:  558]:	worker_index: 2, step: 54, cost: 10.411896, mlm loss: 10.411896, speed: 0.040014 steps/s, speed: 0.320109 samples/s, speed: 163.895880 tokens/s, learning rate: 5.300e-07, loss_scalings: 26214.400391, pp_loss: 10.436691
[INFO] 2021-07-12 17:57:26,473 [run_pretraining.py:  512]:	********exe.run_54******* 
[INFO] 2021-07-12 17:57:51,314 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:57:51,315 [run_pretraining.py:  534]:	loss/total_loss, 10.251775741577148, 55
[INFO] 2021-07-12 17:57:51,315 [run_pretraining.py:  535]:	loss/mlm_loss, 10.251775741577148, 55
[INFO] 2021-07-12 17:57:51,315 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.399999736255268e-07, 55
[INFO] 2021-07-12 17:57:51,315 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 55
[INFO] 2021-07-12 17:57:51,315 [run_pretraining.py:  558]:	worker_index: 2, step: 55, cost: 10.251776, mlm loss: 10.251776, speed: 0.040255 steps/s, speed: 0.322042 samples/s, speed: 164.885685 tokens/s, learning rate: 5.400e-07, loss_scalings: 26214.400391, pp_loss: 10.312038
[INFO] 2021-07-12 17:57:51,315 [run_pretraining.py:  512]:	********exe.run_55******* 
[INFO] 2021-07-12 17:57:52,304 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:57:52,304 [run_pretraining.py:  534]:	loss/total_loss, 10.309179306030273, 56
[INFO] 2021-07-12 17:57:52,304 [run_pretraining.py:  535]:	loss/mlm_loss, 10.309179306030273, 56
[INFO] 2021-07-12 17:57:52,304 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.499999815583578e-07, 56
[INFO] 2021-07-12 17:57:52,304 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 56
[INFO] 2021-07-12 17:57:52,304 [run_pretraining.py:  558]:	worker_index: 2, step: 56, cost: 10.309179, mlm loss: 10.309179, speed: 1.011467 steps/s, speed: 8.091736 samples/s, speed: 4142.969013 tokens/s, learning rate: 5.500e-07, loss_scalings: 26214.400391, pp_loss: 10.368515
[INFO] 2021-07-12 17:57:52,304 [run_pretraining.py:  512]:	********exe.run_56******* 
[INFO] 2021-07-12 17:58:15,803 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:58:15,804 [run_pretraining.py:  534]:	loss/total_loss, 9.281118392944336, 57
[INFO] 2021-07-12 17:58:15,804 [run_pretraining.py:  535]:	loss/mlm_loss, 9.281118392944336, 57
[INFO] 2021-07-12 17:58:15,804 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.599999894911889e-07, 57
[INFO] 2021-07-12 17:58:15,804 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 57
[INFO] 2021-07-12 17:58:15,804 [run_pretraining.py:  558]:	worker_index: 2, step: 57, cost: 9.281118, mlm loss: 9.281118, speed: 0.042555 steps/s, speed: 0.340440 samples/s, speed: 174.305070 tokens/s, learning rate: 5.600e-07, loss_scalings: 26214.400391, pp_loss: 10.123127
[INFO] 2021-07-12 17:58:15,804 [run_pretraining.py:  512]:	********exe.run_57******* 
[INFO] 2021-07-12 17:58:42,073 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:58:42,074 [run_pretraining.py:  534]:	loss/total_loss, 10.307228088378906, 58
[INFO] 2021-07-12 17:58:42,074 [run_pretraining.py:  535]:	loss/mlm_loss, 10.307228088378906, 58
[INFO] 2021-07-12 17:58:42,074 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.6999999742402e-07, 58
[INFO] 2021-07-12 17:58:42,074 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 58
[INFO] 2021-07-12 17:58:42,074 [run_pretraining.py:  558]:	worker_index: 2, step: 58, cost: 10.307228, mlm loss: 10.307228, speed: 0.038067 steps/s, speed: 0.304534 samples/s, speed: 155.921340 tokens/s, learning rate: 5.700e-07, loss_scalings: 26214.400391, pp_loss: 9.400990
[INFO] 2021-07-12 17:58:42,074 [run_pretraining.py:  512]:	********exe.run_58******* 
[INFO] 2021-07-12 17:59:06,976 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:59:06,976 [run_pretraining.py:  534]:	loss/total_loss, 6.266635417938232, 59
[INFO] 2021-07-12 17:59:06,976 [run_pretraining.py:  535]:	loss/mlm_loss, 6.266635417938232, 59
[INFO] 2021-07-12 17:59:06,976 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.80000005356851e-07, 59
[INFO] 2021-07-12 17:59:06,976 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 59
[INFO] 2021-07-12 17:59:06,976 [run_pretraining.py:  558]:	worker_index: 2, step: 59, cost: 6.266635, mlm loss: 6.266635, speed: 0.040158 steps/s, speed: 0.321266 samples/s, speed: 164.488181 tokens/s, learning rate: 5.800e-07, loss_scalings: 26214.400391, pp_loss: 9.343257
[INFO] 2021-07-12 17:59:06,976 [run_pretraining.py:  512]:	********exe.run_59******* 
[INFO] 2021-07-12 17:59:07,933 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:59:07,934 [run_pretraining.py:  534]:	loss/total_loss, 10.473075866699219, 60
[INFO] 2021-07-12 17:59:07,934 [run_pretraining.py:  535]:	loss/mlm_loss, 10.473075866699219, 60
[INFO] 2021-07-12 17:59:07,934 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.900000132896821e-07, 60
[INFO] 2021-07-12 17:59:07,934 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 60
[INFO] 2021-07-12 17:59:07,934 [run_pretraining.py:  558]:	worker_index: 2, step: 60, cost: 10.473076, mlm loss: 10.473076, speed: 1.044715 steps/s, speed: 8.357720 samples/s, speed: 4279.152618 tokens/s, learning rate: 5.900e-07, loss_scalings: 26214.400391, pp_loss: 10.367050
[INFO] 2021-07-12 17:59:07,934 [run_pretraining.py:  512]:	********exe.run_60******* 
[INFO] 2021-07-12 17:59:34,479 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:59:34,480 [run_pretraining.py:  534]:	loss/total_loss, 10.406335830688477, 61
[INFO] 2021-07-12 17:59:34,480 [run_pretraining.py:  535]:	loss/mlm_loss, 10.406335830688477, 61
[INFO] 2021-07-12 17:59:34,480 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.999999643790943e-07, 61
[INFO] 2021-07-12 17:59:34,480 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 61
[INFO] 2021-07-12 17:59:34,480 [run_pretraining.py:  558]:	worker_index: 2, step: 61, cost: 10.406336, mlm loss: 10.406336, speed: 0.037671 steps/s, speed: 0.301369 samples/s, speed: 154.301010 tokens/s, learning rate: 6.000e-07, loss_scalings: 26214.400391, pp_loss: 10.385300
[INFO] 2021-07-12 17:59:34,480 [run_pretraining.py:  512]:	********exe.run_61******* 
[INFO] 2021-07-12 17:59:57,531 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:59:57,531 [run_pretraining.py:  534]:	loss/total_loss, 7.793421745300293, 62
[INFO] 2021-07-12 17:59:57,532 [run_pretraining.py:  535]:	loss/mlm_loss, 7.793421745300293, 62
[INFO] 2021-07-12 17:59:57,532 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.099999723119254e-07, 62
[INFO] 2021-07-12 17:59:57,532 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 62
[INFO] 2021-07-12 17:59:57,532 [run_pretraining.py:  558]:	worker_index: 2, step: 62, cost: 7.793422, mlm loss: 7.793422, speed: 0.043382 steps/s, speed: 0.347059 samples/s, speed: 177.694419 tokens/s, learning rate: 6.100e-07, loss_scalings: 26214.400391, pp_loss: 9.735353
[INFO] 2021-07-12 17:59:57,532 [run_pretraining.py:  512]:	********exe.run_62******* 
[INFO] 2021-07-12 18:00:22,665 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:00:22,665 [run_pretraining.py:  534]:	loss/total_loss, 10.353873252868652, 63
[INFO] 2021-07-12 18:00:22,665 [run_pretraining.py:  535]:	loss/mlm_loss, 10.353873252868652, 63
[INFO] 2021-07-12 18:00:22,665 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.199999802447564e-07, 63
[INFO] 2021-07-12 18:00:22,665 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 63
[INFO] 2021-07-12 18:00:22,665 [run_pretraining.py:  558]:	worker_index: 2, step: 63, cost: 10.353873, mlm loss: 10.353873, speed: 0.039788 steps/s, speed: 0.318307 samples/s, speed: 162.973091 tokens/s, learning rate: 6.200e-07, loss_scalings: 26214.400391, pp_loss: 10.337012
[INFO] 2021-07-12 18:00:22,665 [run_pretraining.py:  512]:	********exe.run_63******* 
[INFO] 2021-07-12 18:00:47,670 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:00:47,670 [run_pretraining.py:  534]:	loss/total_loss, 10.27823257446289, 64
[INFO] 2021-07-12 18:00:47,671 [run_pretraining.py:  535]:	loss/mlm_loss, 10.27823257446289, 64
[INFO] 2021-07-12 18:00:47,671 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.299999881775875e-07, 64
[INFO] 2021-07-12 18:00:47,671 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 64
[INFO] 2021-07-12 18:00:47,671 [run_pretraining.py:  558]:	worker_index: 2, step: 64, cost: 10.278233, mlm loss: 10.278233, speed: 0.039992 steps/s, speed: 0.319938 samples/s, speed: 163.808205 tokens/s, learning rate: 6.300e-07, loss_scalings: 26214.400391, pp_loss: 10.318019
[INFO] 2021-07-12 18:00:47,671 [run_pretraining.py:  512]:	********exe.run_64******* 
[INFO] 2021-07-12 18:01:34,934 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:01:34,934 [run_pretraining.py:  534]:	loss/total_loss, 11.298370361328125, 65
[INFO] 2021-07-12 18:01:34,934 [run_pretraining.py:  535]:	loss/mlm_loss, 11.298370361328125, 65
[INFO] 2021-07-12 18:01:34,934 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.399999392669997e-07, 65
[INFO] 2021-07-12 18:01:34,934 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 65
[INFO] 2021-07-12 18:01:34,935 [run_pretraining.py:  558]:	worker_index: 2, step: 65, cost: 11.298370, mlm loss: 11.298370, speed: 0.021158 steps/s, speed: 0.169265 samples/s, speed: 86.663877 tokens/s, learning rate: 6.400e-07, loss_scalings: 26214.400391, pp_loss: 10.584487
[INFO] 2021-07-12 18:01:34,935 [run_pretraining.py:  512]:	********exe.run_65******* 
[INFO] 2021-07-12 18:01:58,670 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:01:58,671 [run_pretraining.py:  534]:	loss/total_loss, 10.295726776123047, 66
[INFO] 2021-07-12 18:01:58,671 [run_pretraining.py:  535]:	loss/mlm_loss, 10.295726776123047, 66
[INFO] 2021-07-12 18:01:58,671 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.500000040432496e-07, 66
[INFO] 2021-07-12 18:01:58,671 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 66
[INFO] 2021-07-12 18:01:58,671 [run_pretraining.py:  558]:	worker_index: 2, step: 66, cost: 10.295727, mlm loss: 10.295727, speed: 0.042130 steps/s, speed: 0.337044 samples/s, speed: 172.566509 tokens/s, learning rate: 6.500e-07, loss_scalings: 26214.400391, pp_loss: 10.206257
[INFO] 2021-07-12 18:01:58,671 [run_pretraining.py:  512]:	********exe.run_66******* 
[INFO] 2021-07-12 18:02:24,257 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:02:24,257 [run_pretraining.py:  534]:	loss/total_loss, 10.291280746459961, 67
[INFO] 2021-07-12 18:02:24,258 [run_pretraining.py:  535]:	loss/mlm_loss, 10.291280746459961, 67
[INFO] 2021-07-12 18:02:24,258 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.599999551326619e-07, 67
[INFO] 2021-07-12 18:02:24,258 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 67
[INFO] 2021-07-12 18:02:24,258 [run_pretraining.py:  558]:	worker_index: 2, step: 67, cost: 10.291281, mlm loss: 10.291281, speed: 0.039084 steps/s, speed: 0.312669 samples/s, speed: 160.086300 tokens/s, learning rate: 6.600e-07, loss_scalings: 26214.400391, pp_loss: 10.259850
[INFO] 2021-07-12 18:02:24,258 [run_pretraining.py:  512]:	********exe.run_67******* 
[INFO] 2021-07-12 18:03:12,741 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:03:12,742 [run_pretraining.py:  534]:	loss/total_loss, 6.420650005340576, 68
[INFO] 2021-07-12 18:03:12,742 [run_pretraining.py:  535]:	loss/mlm_loss, 6.420650005340576, 68
[INFO] 2021-07-12 18:03:12,742 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.699999630654929e-07, 68
[INFO] 2021-07-12 18:03:12,742 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 68
[INFO] 2021-07-12 18:03:12,742 [run_pretraining.py:  558]:	worker_index: 2, step: 68, cost: 6.420650, mlm loss: 6.420650, speed: 0.020625 steps/s, speed: 0.165004 samples/s, speed: 84.481932 tokens/s, learning rate: 6.700e-07, loss_scalings: 26214.400391, pp_loss: 9.371325
[INFO] 2021-07-12 18:03:12,742 [run_pretraining.py:  512]:	********exe.run_68******* 
[INFO] 2021-07-12 18:03:37,911 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:03:37,911 [run_pretraining.py:  534]:	loss/total_loss, 8.135577201843262, 69
[INFO] 2021-07-12 18:03:37,911 [run_pretraining.py:  535]:	loss/mlm_loss, 8.135577201843262, 69
[INFO] 2021-07-12 18:03:37,911 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.79999970998324e-07, 69
[INFO] 2021-07-12 18:03:37,911 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 69
[INFO] 2021-07-12 18:03:37,911 [run_pretraining.py:  558]:	worker_index: 2, step: 69, cost: 8.135577, mlm loss: 8.135577, speed: 0.039732 steps/s, speed: 0.317856 samples/s, speed: 162.742367 tokens/s, learning rate: 6.800e-07, loss_scalings: 26214.400391, pp_loss: 9.802297
[INFO] 2021-07-12 18:03:37,911 [run_pretraining.py:  512]:	********exe.run_69******* 
[INFO] 2021-07-12 18:04:03,907 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:04:03,907 [run_pretraining.py:  534]:	loss/total_loss, 10.282761573791504, 70
[INFO] 2021-07-12 18:04:03,907 [run_pretraining.py:  535]:	loss/mlm_loss, 10.282761573791504, 70
[INFO] 2021-07-12 18:04:03,908 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.899999789311551e-07, 70
[INFO] 2021-07-12 18:04:03,908 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 70
[INFO] 2021-07-12 18:04:03,908 [run_pretraining.py:  558]:	worker_index: 2, step: 70, cost: 10.282762, mlm loss: 10.282762, speed: 0.038468 steps/s, speed: 0.307744 samples/s, speed: 157.564953 tokens/s, learning rate: 6.900e-07, loss_scalings: 26214.400391, pp_loss: 10.350060
[INFO] 2021-07-12 18:04:03,908 [run_pretraining.py:  512]:	********exe.run_70******* 
[INFO] 2021-07-12 18:04:28,997 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:04:28,997 [run_pretraining.py:  534]:	loss/total_loss, 10.206418991088867, 71
[INFO] 2021-07-12 18:04:28,997 [run_pretraining.py:  535]:	loss/mlm_loss, 10.206418991088867, 71
[INFO] 2021-07-12 18:04:28,997 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.999999868639861e-07, 71
[INFO] 2021-07-12 18:04:28,997 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 71
[INFO] 2021-07-12 18:04:28,998 [run_pretraining.py:  558]:	worker_index: 2, step: 71, cost: 10.206419, mlm loss: 10.206419, speed: 0.039858 steps/s, speed: 0.318862 samples/s, speed: 163.257190 tokens/s, learning rate: 7.000e-07, loss_scalings: 26214.400391, pp_loss: 9.549265
[INFO] 2021-07-12 18:04:28,998 [run_pretraining.py:  512]:	********exe.run_71******* 
[INFO] 2021-07-12 18:04:54,341 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:04:54,341 [run_pretraining.py:  534]:	loss/total_loss, 10.29256534576416, 72
[INFO] 2021-07-12 18:04:54,341 [run_pretraining.py:  535]:	loss/mlm_loss, 10.29256534576416, 72
[INFO] 2021-07-12 18:04:54,341 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.099999947968172e-07, 72
[INFO] 2021-07-12 18:04:54,342 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 72
[INFO] 2021-07-12 18:04:54,342 [run_pretraining.py:  558]:	worker_index: 2, step: 72, cost: 10.292565, mlm loss: 10.292565, speed: 0.039458 steps/s, speed: 0.315663 samples/s, speed: 161.619450 tokens/s, learning rate: 7.100e-07, loss_scalings: 26214.400391, pp_loss: 10.325702
[INFO] 2021-07-12 18:04:54,342 [run_pretraining.py:  512]:	********exe.run_72******* 
[INFO] 2021-07-12 18:06:07,144 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:06:07,145 [run_pretraining.py:  534]:	loss/total_loss, 10.368208885192871, 73
[INFO] 2021-07-12 18:06:07,145 [run_pretraining.py:  535]:	loss/mlm_loss, 10.368208885192871, 73
[INFO] 2021-07-12 18:06:07,145 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.199999458862294e-07, 73
[INFO] 2021-07-12 18:06:07,145 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 73
[INFO] 2021-07-12 18:06:07,145 [run_pretraining.py:  558]:	worker_index: 2, step: 73, cost: 10.368209, mlm loss: 10.368209, speed: 0.013736 steps/s, speed: 0.109885 samples/s, speed: 56.261369 tokens/s, learning rate: 7.200e-07, loss_scalings: 26214.400391, pp_loss: 10.351359
[INFO] 2021-07-12 18:06:07,145 [run_pretraining.py:  512]:	********exe.run_73******* 
[INFO] 2021-07-12 18:06:30,300 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:06:30,301 [run_pretraining.py:  534]:	loss/total_loss, 10.359312057495117, 74
[INFO] 2021-07-12 18:06:30,301 [run_pretraining.py:  535]:	loss/mlm_loss, 10.359312057495117, 74
[INFO] 2021-07-12 18:06:30,301 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.300000106624793e-07, 74
[INFO] 2021-07-12 18:06:30,301 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 74
[INFO] 2021-07-12 18:06:30,301 [run_pretraining.py:  558]:	worker_index: 2, step: 74, cost: 10.359312, mlm loss: 10.359312, speed: 0.043187 steps/s, speed: 0.345495 samples/s, speed: 176.893688 tokens/s, learning rate: 7.300e-07, loss_scalings: 26214.400391, pp_loss: 10.362252
[INFO] 2021-07-12 18:06:30,301 [run_pretraining.py:  512]:	********exe.run_74******* 
[INFO] 2021-07-12 18:07:18,877 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:07:18,878 [run_pretraining.py:  534]:	loss/total_loss, 10.352325439453125, 75
[INFO] 2021-07-12 18:07:18,878 [run_pretraining.py:  535]:	loss/mlm_loss, 10.352325439453125, 75
[INFO] 2021-07-12 18:07:18,878 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.399999617518915e-07, 75
[INFO] 2021-07-12 18:07:18,878 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 75
[INFO] 2021-07-12 18:07:18,878 [run_pretraining.py:  558]:	worker_index: 2, step: 75, cost: 10.352325, mlm loss: 10.352325, speed: 0.020586 steps/s, speed: 0.164690 samples/s, speed: 84.321231 tokens/s, learning rate: 7.400e-07, loss_scalings: 26214.400391, pp_loss: 10.340771
[INFO] 2021-07-12 18:07:18,878 [run_pretraining.py:  512]:	********exe.run_75******* 
[INFO] 2021-07-12 18:07:19,851 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:07:19,852 [run_pretraining.py:  534]:	loss/total_loss, 10.363799095153809, 76
[INFO] 2021-07-12 18:07:19,852 [run_pretraining.py:  535]:	loss/mlm_loss, 10.363799095153809, 76
[INFO] 2021-07-12 18:07:19,852 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.499999696847226e-07, 76
[INFO] 2021-07-12 18:07:19,852 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 76
[INFO] 2021-07-12 18:07:19,852 [run_pretraining.py:  558]:	worker_index: 2, step: 76, cost: 10.363799, mlm loss: 10.363799, speed: 1.027162 steps/s, speed: 8.217298 samples/s, speed: 4207.256516 tokens/s, learning rate: 7.500e-07, loss_scalings: 26214.400391, pp_loss: 10.306805
[INFO] 2021-07-12 18:07:19,852 [run_pretraining.py:  512]:	********exe.run_76******* 
[INFO] 2021-07-12 18:07:20,835 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:07:20,836 [run_pretraining.py:  534]:	loss/total_loss, 10.503866195678711, 77
[INFO] 2021-07-12 18:07:20,836 [run_pretraining.py:  535]:	loss/mlm_loss, 10.503866195678711, 77
[INFO] 2021-07-12 18:07:20,836 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.599999776175537e-07, 77
[INFO] 2021-07-12 18:07:20,836 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 77
[INFO] 2021-07-12 18:07:20,836 [run_pretraining.py:  558]:	worker_index: 2, step: 77, cost: 10.503866, mlm loss: 10.503866, speed: 1.016940 steps/s, speed: 8.135520 samples/s, speed: 4165.386294 tokens/s, learning rate: 7.600e-07, loss_scalings: 26214.400391, pp_loss: 10.335499
[INFO] 2021-07-12 18:07:20,836 [run_pretraining.py:  512]:	********exe.run_77******* 
[INFO] 2021-07-12 18:08:10,243 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:08:10,244 [run_pretraining.py:  534]:	loss/total_loss, 10.239591598510742, 78
[INFO] 2021-07-12 18:08:10,244 [run_pretraining.py:  535]:	loss/mlm_loss, 10.239591598510742, 78
[INFO] 2021-07-12 18:08:10,244 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.699999855503847e-07, 78
[INFO] 2021-07-12 18:08:10,244 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 78
[INFO] 2021-07-12 18:08:10,244 [run_pretraining.py:  558]:	worker_index: 2, step: 78, cost: 10.239592, mlm loss: 10.239592, speed: 0.020240 steps/s, speed: 0.161918 samples/s, speed: 82.902135 tokens/s, learning rate: 7.700e-07, loss_scalings: 26214.400391, pp_loss: 10.336257
[INFO] 2021-07-12 18:08:10,244 [run_pretraining.py:  512]:	********exe.run_78******* 
[INFO] 2021-07-12 18:08:34,204 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:08:34,205 [run_pretraining.py:  534]:	loss/total_loss, 10.322235107421875, 79
[INFO] 2021-07-12 18:08:34,205 [run_pretraining.py:  535]:	loss/mlm_loss, 10.322235107421875, 79
[INFO] 2021-07-12 18:08:34,205 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.799999366397969e-07, 79
[INFO] 2021-07-12 18:08:34,205 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 79
[INFO] 2021-07-12 18:08:34,205 [run_pretraining.py:  558]:	worker_index: 2, step: 79, cost: 10.322235, mlm loss: 10.322235, speed: 0.041736 steps/s, speed: 0.333888 samples/s, speed: 170.950645 tokens/s, learning rate: 7.800e-07, loss_scalings: 26214.400391, pp_loss: 10.225423
[INFO] 2021-07-12 18:08:34,205 [run_pretraining.py:  512]:	********exe.run_79******* 
[INFO] 2021-07-12 18:08:35,168 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:08:35,169 [run_pretraining.py:  534]:	loss/total_loss, 10.173568725585938, 80
[INFO] 2021-07-12 18:08:35,169 [run_pretraining.py:  535]:	loss/mlm_loss, 10.173568725585938, 80
[INFO] 2021-07-12 18:08:35,169 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.89999944572628e-07, 80
[INFO] 2021-07-12 18:08:35,169 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 80
[INFO] 2021-07-12 18:08:35,170 [run_pretraining.py:  558]:	worker_index: 2, step: 80, cost: 10.173569, mlm loss: 10.173569, speed: 1.037452 steps/s, speed: 8.299613 samples/s, speed: 4249.402020 tokens/s, learning rate: 7.900e-07, loss_scalings: 26214.400391, pp_loss: 10.292534
[INFO] 2021-07-12 18:08:35,170 [run_pretraining.py:  512]:	********exe.run_80******* 
[INFO] 2021-07-12 18:09:23,448 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:09:23,448 [run_pretraining.py:  534]:	loss/total_loss, 10.351139068603516, 81
[INFO] 2021-07-12 18:09:23,448 [run_pretraining.py:  535]:	loss/mlm_loss, 10.351139068603516, 81
[INFO] 2021-07-12 18:09:23,448 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.000000093488779e-07, 81
[INFO] 2021-07-12 18:09:23,448 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 81
[INFO] 2021-07-12 18:09:23,448 [run_pretraining.py:  558]:	worker_index: 2, step: 81, cost: 10.351139, mlm loss: 10.351139, speed: 0.020713 steps/s, speed: 0.165706 samples/s, speed: 84.841576 tokens/s, learning rate: 8.000e-07, loss_scalings: 26214.400391, pp_loss: 10.351559
[INFO] 2021-07-12 18:09:23,448 [run_pretraining.py:  512]:	********exe.run_81******* 
[INFO] 2021-07-12 18:09:24,412 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:09:24,412 [run_pretraining.py:  534]:	loss/total_loss, 10.436531066894531, 82
[INFO] 2021-07-12 18:09:24,412 [run_pretraining.py:  535]:	loss/mlm_loss, 10.436531066894531, 82
[INFO] 2021-07-12 18:09:24,413 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.10000017281709e-07, 82
[INFO] 2021-07-12 18:09:24,413 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 82
[INFO] 2021-07-12 18:09:24,413 [run_pretraining.py:  558]:	worker_index: 2, step: 82, cost: 10.436531, mlm loss: 10.436531, speed: 1.037643 steps/s, speed: 8.301147 samples/s, speed: 4250.187322 tokens/s, learning rate: 8.100e-07, loss_scalings: 26214.400391, pp_loss: 10.346497
[INFO] 2021-07-12 18:09:24,413 [run_pretraining.py:  512]:	********exe.run_82******* 
[INFO] 2021-07-12 18:09:25,353 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:09:25,353 [run_pretraining.py:  534]:	loss/total_loss, 10.433260917663574, 83
[INFO] 2021-07-12 18:09:25,353 [run_pretraining.py:  535]:	loss/mlm_loss, 10.433260917663574, 83
[INFO] 2021-07-12 18:09:25,353 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.199999683711212e-07, 83
[INFO] 2021-07-12 18:09:25,353 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 83
[INFO] 2021-07-12 18:09:25,354 [run_pretraining.py:  558]:	worker_index: 2, step: 83, cost: 10.433261, mlm loss: 10.433261, speed: 1.063542 steps/s, speed: 8.508335 samples/s, speed: 4356.267605 tokens/s, learning rate: 8.200e-07, loss_scalings: 26214.400391, pp_loss: 10.341183
[INFO] 2021-07-12 18:09:25,354 [run_pretraining.py:  512]:	********exe.run_83******* 
[INFO] 2021-07-12 18:09:26,288 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:09:26,289 [run_pretraining.py:  534]:	loss/total_loss, 10.264873504638672, 84
[INFO] 2021-07-12 18:09:26,289 [run_pretraining.py:  535]:	loss/mlm_loss, 10.264873504638672, 84
[INFO] 2021-07-12 18:09:26,289 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.299999763039523e-07, 84
[INFO] 2021-07-12 18:09:26,289 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 84
[INFO] 2021-07-12 18:09:26,289 [run_pretraining.py:  558]:	worker_index: 2, step: 84, cost: 10.264874, mlm loss: 10.264874, speed: 1.069346 steps/s, speed: 8.554772 samples/s, speed: 4380.043062 tokens/s, learning rate: 8.300e-07, loss_scalings: 26214.400391, pp_loss: 10.330541
[INFO] 2021-07-12 18:09:26,289 [run_pretraining.py:  512]:	********exe.run_84******* 
[INFO] 2021-07-12 18:09:27,224 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:09:27,224 [run_pretraining.py:  534]:	loss/total_loss, 10.13062858581543, 85
[INFO] 2021-07-12 18:09:27,224 [run_pretraining.py:  535]:	loss/mlm_loss, 10.13062858581543, 85
[INFO] 2021-07-12 18:09:27,224 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.399999273933645e-07, 85
[INFO] 2021-07-12 18:09:27,224 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 85
[INFO] 2021-07-12 18:09:27,224 [run_pretraining.py:  558]:	worker_index: 2, step: 85, cost: 10.130629, mlm loss: 10.130629, speed: 1.070105 steps/s, speed: 8.560841 samples/s, speed: 4383.150811 tokens/s, learning rate: 8.400e-07, loss_scalings: 26214.400391, pp_loss: 10.199217
[INFO] 2021-07-12 18:09:27,224 [run_pretraining.py:  512]:	********exe.run_85******* 
[INFO] 2021-07-12 18:09:51,413 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:09:51,414 [run_pretraining.py:  534]:	loss/total_loss, 10.237432479858398, 86
[INFO] 2021-07-12 18:09:51,414 [run_pretraining.py:  535]:	loss/mlm_loss, 10.237432479858398, 86
[INFO] 2021-07-12 18:09:51,414 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.500000490130333e-07, 86
[INFO] 2021-07-12 18:09:51,415 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 86
[INFO] 2021-07-12 18:09:51,415 [run_pretraining.py:  558]:	worker_index: 2, step: 86, cost: 10.237432, mlm loss: 10.237432, speed: 0.041340 steps/s, speed: 0.330720 samples/s, speed: 169.328823 tokens/s, learning rate: 8.500e-07, loss_scalings: 26214.400391, pp_loss: 10.212475
[INFO] 2021-07-12 18:09:51,415 [run_pretraining.py:  512]:	********exe.run_86******* 
[INFO] 2021-07-12 18:10:17,851 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:10:17,852 [run_pretraining.py:  534]:	loss/total_loss, 10.231393814086914, 87
[INFO] 2021-07-12 18:10:17,852 [run_pretraining.py:  535]:	loss/mlm_loss, 10.231393814086914, 87
[INFO] 2021-07-12 18:10:17,852 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.600000001024455e-07, 87
[INFO] 2021-07-12 18:10:17,852 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 87
[INFO] 2021-07-12 18:10:17,852 [run_pretraining.py:  558]:	worker_index: 2, step: 87, cost: 10.231394, mlm loss: 10.231394, speed: 0.037826 steps/s, speed: 0.302610 samples/s, speed: 154.936084 tokens/s, learning rate: 8.600e-07, loss_scalings: 26214.400391, pp_loss: 10.244003
[INFO] 2021-07-12 18:10:17,852 [run_pretraining.py:  512]:	********exe.run_87******* 
[INFO] 2021-07-12 18:10:43,553 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:10:43,554 [run_pretraining.py:  534]:	loss/total_loss, 10.224283218383789, 88
[INFO] 2021-07-12 18:10:43,554 [run_pretraining.py:  535]:	loss/mlm_loss, 10.224283218383789, 88
[INFO] 2021-07-12 18:10:43,554 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.700000080352766e-07, 88
[INFO] 2021-07-12 18:10:43,554 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 88
[INFO] 2021-07-12 18:10:43,554 [run_pretraining.py:  558]:	worker_index: 2, step: 88, cost: 10.224283, mlm loss: 10.224283, speed: 0.038908 steps/s, speed: 0.311267 samples/s, speed: 159.368842 tokens/s, learning rate: 8.700e-07, loss_scalings: 26214.400391, pp_loss: 10.266420
[INFO] 2021-07-12 18:10:43,554 [run_pretraining.py:  512]:	********exe.run_88******* 
[INFO] 2021-07-12 18:11:07,455 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:11:07,455 [run_pretraining.py:  534]:	loss/total_loss, 10.256138801574707, 89
[INFO] 2021-07-12 18:11:07,456 [run_pretraining.py:  535]:	loss/mlm_loss, 10.256138801574707, 89
[INFO] 2021-07-12 18:11:07,456 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.799999591246888e-07, 89
[INFO] 2021-07-12 18:11:07,456 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 89
[INFO] 2021-07-12 18:11:07,456 [run_pretraining.py:  558]:	worker_index: 2, step: 89, cost: 10.256139, mlm loss: 10.256139, speed: 0.041839 steps/s, speed: 0.334711 samples/s, speed: 171.372041 tokens/s, learning rate: 8.800e-07, loss_scalings: 26214.400391, pp_loss: 10.304767
[INFO] 2021-07-12 18:11:07,456 [run_pretraining.py:  512]:	********exe.run_89******* 
[INFO] 2021-07-12 18:11:57,427 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:11:57,428 [run_pretraining.py:  534]:	loss/total_loss, 10.220775604248047, 90
[INFO] 2021-07-12 18:11:57,428 [run_pretraining.py:  535]:	loss/mlm_loss, 10.220775604248047, 90
[INFO] 2021-07-12 18:11:57,428 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.899999670575198e-07, 90
[INFO] 2021-07-12 18:11:57,428 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 90
[INFO] 2021-07-12 18:11:57,428 [run_pretraining.py:  558]:	worker_index: 2, step: 90, cost: 10.220776, mlm loss: 10.220776, speed: 0.020011 steps/s, speed: 0.160091 samples/s, speed: 81.966668 tokens/s, learning rate: 8.900e-07, loss_scalings: 26214.400391, pp_loss: 10.271681
[INFO] 2021-07-12 18:11:57,428 [run_pretraining.py:  512]:	********exe.run_90******* 
[INFO] 2021-07-12 18:11:58,366 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:11:58,367 [run_pretraining.py:  534]:	loss/total_loss, 10.359872817993164, 91
[INFO] 2021-07-12 18:11:58,367 [run_pretraining.py:  535]:	loss/mlm_loss, 10.359872817993164, 91
[INFO] 2021-07-12 18:11:58,367 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.99999918146932e-07, 91
[INFO] 2021-07-12 18:11:58,367 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 91
[INFO] 2021-07-12 18:11:58,367 [run_pretraining.py:  558]:	worker_index: 2, step: 91, cost: 10.359873, mlm loss: 10.359873, speed: 1.065376 steps/s, speed: 8.523005 samples/s, speed: 4363.778630 tokens/s, learning rate: 9.000e-07, loss_scalings: 26214.400391, pp_loss: 10.205502
[INFO] 2021-07-12 18:11:58,367 [run_pretraining.py:  512]:	********exe.run_91******* 
[INFO] 2021-07-12 18:11:59,303 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:11:59,303 [run_pretraining.py:  534]:	loss/total_loss, 10.284867286682129, 92
[INFO] 2021-07-12 18:11:59,304 [run_pretraining.py:  535]:	loss/mlm_loss, 10.284867286682129, 92
[INFO] 2021-07-12 18:11:59,304 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.100000397666008e-07, 92
[INFO] 2021-07-12 18:11:59,304 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 92
[INFO] 2021-07-12 18:11:59,304 [run_pretraining.py:  558]:	worker_index: 2, step: 92, cost: 10.284867, mlm loss: 10.284867, speed: 1.068321 steps/s, speed: 8.546570 samples/s, speed: 4375.843830 tokens/s, learning rate: 9.100e-07, loss_scalings: 26214.400391, pp_loss: 10.251138
[INFO] 2021-07-12 18:11:59,304 [run_pretraining.py:  512]:	********exe.run_92******* 
[INFO] 2021-07-12 18:12:00,242 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:12:00,242 [run_pretraining.py:  534]:	loss/total_loss, 10.293634414672852, 93
[INFO] 2021-07-12 18:12:00,242 [run_pretraining.py:  535]:	loss/mlm_loss, 10.293634414672852, 93
[INFO] 2021-07-12 18:12:00,242 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.19999990856013e-07, 93
[INFO] 2021-07-12 18:12:00,243 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 93
[INFO] 2021-07-12 18:12:00,243 [run_pretraining.py:  558]:	worker_index: 2, step: 93, cost: 10.293634, mlm loss: 10.293634, speed: 1.065874 steps/s, speed: 8.526990 samples/s, speed: 4365.819082 tokens/s, learning rate: 9.200e-07, loss_scalings: 26214.400391, pp_loss: 10.342854
[INFO] 2021-07-12 18:12:00,243 [run_pretraining.py:  512]:	********exe.run_93******* 
[INFO] 2021-07-12 18:12:01,185 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:12:01,186 [run_pretraining.py:  534]:	loss/total_loss, 7.369881629943848, 94
[INFO] 2021-07-12 18:12:01,186 [run_pretraining.py:  535]:	loss/mlm_loss, 7.369881629943848, 94
[INFO] 2021-07-12 18:12:01,186 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.299999987888441e-07, 94
[INFO] 2021-07-12 18:12:01,186 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 94
[INFO] 2021-07-12 18:12:01,186 [run_pretraining.py:  558]:	worker_index: 2, step: 94, cost: 7.369882, mlm loss: 7.369882, speed: 1.060642 steps/s, speed: 8.485133 samples/s, speed: 4344.387967 tokens/s, learning rate: 9.300e-07, loss_scalings: 26214.400391, pp_loss: 9.548684
[INFO] 2021-07-12 18:12:01,186 [run_pretraining.py:  512]:	********exe.run_94******* 
[INFO] 2021-07-12 18:12:26,861 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:12:26,861 [run_pretraining.py:  534]:	loss/total_loss, 10.289851188659668, 95
[INFO] 2021-07-12 18:12:26,861 [run_pretraining.py:  535]:	loss/mlm_loss, 10.289851188659668, 95
[INFO] 2021-07-12 18:12:26,861 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.399999498782563e-07, 95
[INFO] 2021-07-12 18:12:26,861 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 95
[INFO] 2021-07-12 18:12:26,862 [run_pretraining.py:  558]:	worker_index: 2, step: 95, cost: 10.289851, mlm loss: 10.289851, speed: 0.038948 steps/s, speed: 0.311588 samples/s, speed: 159.532830 tokens/s, learning rate: 9.400e-07, loss_scalings: 26214.400391, pp_loss: 10.257021
[INFO] 2021-07-12 18:12:26,862 [run_pretraining.py:  512]:	********exe.run_95******* 
[INFO] 2021-07-12 18:12:27,822 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:12:27,822 [run_pretraining.py:  534]:	loss/total_loss, 10.196121215820312, 96
[INFO] 2021-07-12 18:12:27,822 [run_pretraining.py:  535]:	loss/mlm_loss, 10.196121215820312, 96
[INFO] 2021-07-12 18:12:27,822 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.499999578110874e-07, 96
[INFO] 2021-07-12 18:12:27,822 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 96
[INFO] 2021-07-12 18:12:27,822 [run_pretraining.py:  558]:	worker_index: 2, step: 96, cost: 10.196121, mlm loss: 10.196121, speed: 1.041269 steps/s, speed: 8.330153 samples/s, speed: 4265.038455 tokens/s, learning rate: 9.500e-07, loss_scalings: 26214.400391, pp_loss: 9.051498
[INFO] 2021-07-12 18:12:27,823 [run_pretraining.py:  512]:	********exe.run_96******* 
[INFO] 2021-07-12 18:12:51,359 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:12:51,359 [run_pretraining.py:  534]:	loss/total_loss, 10.273256301879883, 97
[INFO] 2021-07-12 18:12:51,359 [run_pretraining.py:  535]:	loss/mlm_loss, 10.273256301879883, 97
[INFO] 2021-07-12 18:12:51,359 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.599999657439184e-07, 97
[INFO] 2021-07-12 18:12:51,359 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 97
[INFO] 2021-07-12 18:12:51,359 [run_pretraining.py:  558]:	worker_index: 2, step: 97, cost: 10.273256, mlm loss: 10.273256, speed: 0.042488 steps/s, speed: 0.339900 samples/s, speed: 174.028969 tokens/s, learning rate: 9.600e-07, loss_scalings: 26214.400391, pp_loss: 9.150740
[INFO] 2021-07-12 18:12:51,360 [run_pretraining.py:  512]:	********exe.run_97******* 
[INFO] 2021-07-12 18:12:52,323 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:12:52,324 [run_pretraining.py:  534]:	loss/total_loss, 5.492053985595703, 98
[INFO] 2021-07-12 18:12:52,324 [run_pretraining.py:  535]:	loss/mlm_loss, 5.492053985595703, 98
[INFO] 2021-07-12 18:12:52,324 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.699999736767495e-07, 98
[INFO] 2021-07-12 18:12:52,324 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 98
[INFO] 2021-07-12 18:12:52,324 [run_pretraining.py:  558]:	worker_index: 2, step: 98, cost: 5.492054, mlm loss: 5.492054, speed: 1.037390 steps/s, speed: 8.299121 samples/s, speed: 4249.149776 tokens/s, learning rate: 9.700e-07, loss_scalings: 26214.400391, pp_loss: 8.216187
[INFO] 2021-07-12 18:12:52,324 [run_pretraining.py:  512]:	********exe.run_98******* 
[INFO] 2021-07-12 18:13:17,572 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:13:17,573 [run_pretraining.py:  534]:	loss/total_loss, 10.190572738647461, 99
[INFO] 2021-07-12 18:13:17,573 [run_pretraining.py:  535]:	loss/mlm_loss, 10.190572738647461, 99
[INFO] 2021-07-12 18:13:17,573 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.799999816095806e-07, 99
[INFO] 2021-07-12 18:13:17,573 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 99
[INFO] 2021-07-12 18:13:17,573 [run_pretraining.py:  558]:	worker_index: 2, step: 99, cost: 10.190573, mlm loss: 10.190573, speed: 0.039607 steps/s, speed: 0.316852 samples/s, speed: 162.228322 tokens/s, learning rate: 9.800e-07, loss_scalings: 26214.400391, pp_loss: 10.253580
[INFO] 2021-07-12 18:13:17,573 [run_pretraining.py:  512]:	********exe.run_99******* 
[INFO] 2021-07-12 18:13:18,518 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:13:18,518 [run_pretraining.py:  534]:	loss/total_loss, 10.23381233215332, 100
[INFO] 2021-07-12 18:13:18,518 [run_pretraining.py:  535]:	loss/mlm_loss, 10.23381233215332, 100
[INFO] 2021-07-12 18:13:18,519 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.899999895424116e-07, 100
[INFO] 2021-07-12 18:13:18,519 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 100
[INFO] 2021-07-12 18:13:18,519 [run_pretraining.py:  558]:	worker_index: 2, step: 100, cost: 10.233812, mlm loss: 10.233812, speed: 1.058001 steps/s, speed: 8.464005 samples/s, speed: 4333.570744 tokens/s, learning rate: 9.900e-07, loss_scalings: 26214.400391, pp_loss: 10.228578
[INFO] 2021-07-12 18:13:18,519 [run_pretraining.py:  512]:	********exe.run_100******* 
[INFO] 2021-07-12 18:13:19,460 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:13:19,461 [run_pretraining.py:  534]:	loss/total_loss, 10.333770751953125, 101
[INFO] 2021-07-12 18:13:19,461 [run_pretraining.py:  535]:	loss/mlm_loss, 10.333770751953125, 101
[INFO] 2021-07-12 18:13:19,461 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.999999974752427e-07, 101
[INFO] 2021-07-12 18:13:19,461 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 101
[INFO] 2021-07-12 18:13:19,461 [run_pretraining.py:  558]:	worker_index: 2, step: 101, cost: 10.333771, mlm loss: 10.333771, speed: 1.061635 steps/s, speed: 8.493081 samples/s, speed: 4348.457674 tokens/s, learning rate: 1.000e-06, loss_scalings: 26214.400391, pp_loss: 10.311298
[INFO] 2021-07-12 18:13:19,461 [run_pretraining.py:  512]:	********exe.run_101******* 
[INFO] 2021-07-12 18:13:44,833 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:13:44,833 [run_pretraining.py:  534]:	loss/total_loss, 10.159448623657227, 102
[INFO] 2021-07-12 18:13:44,833 [run_pretraining.py:  535]:	loss/mlm_loss, 10.159448623657227, 102
[INFO] 2021-07-12 18:13:44,833 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.009999891721236e-06, 102
[INFO] 2021-07-12 18:13:44,833 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 102
[INFO] 2021-07-12 18:13:44,833 [run_pretraining.py:  558]:	worker_index: 2, step: 102, cost: 10.159449, mlm loss: 10.159449, speed: 0.039414 steps/s, speed: 0.315313 samples/s, speed: 161.440339 tokens/s, learning rate: 1.010e-06, loss_scalings: 26214.400391, pp_loss: 10.183710
[INFO] 2021-07-12 18:13:44,834 [run_pretraining.py:  512]:	********exe.run_102******* 
[INFO] 2021-07-12 18:13:45,823 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:13:45,824 [run_pretraining.py:  534]:	loss/total_loss, 10.238718032836914, 103
[INFO] 2021-07-12 18:13:45,824 [run_pretraining.py:  535]:	loss/mlm_loss, 10.238718032836914, 103
[INFO] 2021-07-12 18:13:45,824 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0200000133409048e-06, 103
[INFO] 2021-07-12 18:13:45,824 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 103
[INFO] 2021-07-12 18:13:45,824 [run_pretraining.py:  558]:	worker_index: 2, step: 103, cost: 10.238718, mlm loss: 10.238718, speed: 1.010282 steps/s, speed: 8.082258 samples/s, speed: 4138.116142 tokens/s, learning rate: 1.020e-06, loss_scalings: 26214.400391, pp_loss: 8.381435
[INFO] 2021-07-12 18:13:45,824 [run_pretraining.py:  512]:	********exe.run_103******* 
[INFO] 2021-07-12 18:14:11,863 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:14:11,864 [run_pretraining.py:  534]:	loss/total_loss, 10.103836059570312, 104
[INFO] 2021-07-12 18:14:11,864 [run_pretraining.py:  535]:	loss/mlm_loss, 10.103836059570312, 104
[INFO] 2021-07-12 18:14:11,864 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.030000021273736e-06, 104
[INFO] 2021-07-12 18:14:11,864 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 104
[INFO] 2021-07-12 18:14:11,864 [run_pretraining.py:  558]:	worker_index: 2, step: 104, cost: 10.103836, mlm loss: 10.103836, speed: 0.038403 steps/s, speed: 0.307227 samples/s, speed: 157.300177 tokens/s, learning rate: 1.030e-06, loss_scalings: 26214.400391, pp_loss: 10.168509
[INFO] 2021-07-12 18:14:11,864 [run_pretraining.py:  512]:	********exe.run_104******* 
[INFO] 2021-07-12 18:14:37,273 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:14:37,273 [run_pretraining.py:  534]:	loss/total_loss, 10.25300121307373, 105
[INFO] 2021-07-12 18:14:37,273 [run_pretraining.py:  535]:	loss/mlm_loss, 10.25300121307373, 105
[INFO] 2021-07-12 18:14:37,274 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.040000029206567e-06, 105
[INFO] 2021-07-12 18:14:37,274 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 105
[INFO] 2021-07-12 18:14:37,274 [run_pretraining.py:  558]:	worker_index: 2, step: 105, cost: 10.253001, mlm loss: 10.253001, speed: 0.039356 steps/s, speed: 0.314846 samples/s, speed: 161.201361 tokens/s, learning rate: 1.040e-06, loss_scalings: 26214.400391, pp_loss: 10.261580
[INFO] 2021-07-12 18:14:37,274 [run_pretraining.py:  512]:	********exe.run_105******* 
[INFO] 2021-07-12 18:14:38,255 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:14:38,255 [run_pretraining.py:  534]:	loss/total_loss, 10.239213943481445, 106
[INFO] 2021-07-12 18:14:38,255 [run_pretraining.py:  535]:	loss/mlm_loss, 10.239213943481445, 106
[INFO] 2021-07-12 18:14:38,255 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0499999234525603e-06, 106
[INFO] 2021-07-12 18:14:38,255 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 106
[INFO] 2021-07-12 18:14:38,256 [run_pretraining.py:  558]:	worker_index: 2, step: 106, cost: 10.239214, mlm loss: 10.239214, speed: 1.019160 steps/s, speed: 8.153282 samples/s, speed: 4174.480314 tokens/s, learning rate: 1.050e-06, loss_scalings: 26214.400391, pp_loss: 10.239925
[INFO] 2021-07-12 18:14:38,256 [run_pretraining.py:  512]:	********exe.run_106******* 
[INFO] 2021-07-12 18:14:39,224 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:14:39,224 [run_pretraining.py:  534]:	loss/total_loss, 10.283784866333008, 107
[INFO] 2021-07-12 18:14:39,224 [run_pretraining.py:  535]:	loss/mlm_loss, 10.283784866333008, 107
[INFO] 2021-07-12 18:14:39,225 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0599999313853914e-06, 107
[INFO] 2021-07-12 18:14:39,225 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 107
[INFO] 2021-07-12 18:14:39,225 [run_pretraining.py:  558]:	worker_index: 2, step: 107, cost: 10.283785, mlm loss: 10.283785, speed: 1.032477 steps/s, speed: 8.259817 samples/s, speed: 4229.026205 tokens/s, learning rate: 1.060e-06, loss_scalings: 26214.400391, pp_loss: 10.191004
[INFO] 2021-07-12 18:14:39,225 [run_pretraining.py:  512]:	********exe.run_107******* 
[INFO] 2021-07-12 18:14:40,188 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:14:40,188 [run_pretraining.py:  534]:	loss/total_loss, 10.279525756835938, 108
[INFO] 2021-07-12 18:14:40,189 [run_pretraining.py:  535]:	loss/mlm_loss, 10.279525756835938, 108
[INFO] 2021-07-12 18:14:40,189 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0700000530050602e-06, 108
[INFO] 2021-07-12 18:14:40,189 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 108
[INFO] 2021-07-12 18:14:40,189 [run_pretraining.py:  558]:	worker_index: 2, step: 108, cost: 10.279526, mlm loss: 10.279526, speed: 1.037816 steps/s, speed: 8.302529 samples/s, speed: 4250.895079 tokens/s, learning rate: 1.070e-06, loss_scalings: 26214.400391, pp_loss: 10.108216
[INFO] 2021-07-12 18:14:40,189 [run_pretraining.py:  512]:	********exe.run_108******* 
[INFO] 2021-07-12 18:14:41,128 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:14:41,128 [run_pretraining.py:  534]:	loss/total_loss, 9.785470962524414, 109
[INFO] 2021-07-12 18:14:41,128 [run_pretraining.py:  535]:	loss/mlm_loss, 9.785470962524414, 109
[INFO] 2021-07-12 18:14:41,129 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0799999472510535e-06, 109
[INFO] 2021-07-12 18:14:41,129 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 109
[INFO] 2021-07-12 18:14:41,129 [run_pretraining.py:  558]:	worker_index: 2, step: 109, cost: 9.785471, mlm loss: 9.785471, speed: 1.064590 steps/s, speed: 8.516719 samples/s, speed: 4360.559929 tokens/s, learning rate: 1.080e-06, loss_scalings: 26214.400391, pp_loss: 10.108683
[INFO] 2021-07-12 18:14:41,129 [run_pretraining.py:  512]:	********exe.run_109******* 
[INFO] 2021-07-12 18:14:42,060 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:14:42,060 [run_pretraining.py:  534]:	loss/total_loss, 10.102741241455078, 110
[INFO] 2021-07-12 18:14:42,060 [run_pretraining.py:  535]:	loss/mlm_loss, 10.102741241455078, 110
[INFO] 2021-07-12 18:14:42,061 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0899999551838846e-06, 110
[INFO] 2021-07-12 18:14:42,061 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 110
[INFO] 2021-07-12 18:14:42,061 [run_pretraining.py:  558]:	worker_index: 2, step: 110, cost: 10.102741, mlm loss: 10.102741, speed: 1.073695 steps/s, speed: 8.589561 samples/s, speed: 4397.855116 tokens/s, learning rate: 1.090e-06, loss_scalings: 26214.400391, pp_loss: 9.276188
[INFO] 2021-07-12 18:14:42,061 [run_pretraining.py:  512]:	********exe.run_110******* 
[INFO] 2021-07-12 18:14:43,000 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:14:43,000 [run_pretraining.py:  534]:	loss/total_loss, 10.22667121887207, 111
[INFO] 2021-07-12 18:14:43,000 [run_pretraining.py:  535]:	loss/mlm_loss, 10.22667121887207, 111
[INFO] 2021-07-12 18:14:43,000 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0999999631167157e-06, 111
[INFO] 2021-07-12 18:14:43,000 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 111
[INFO] 2021-07-12 18:14:43,000 [run_pretraining.py:  558]:	worker_index: 2, step: 111, cost: 10.226671, mlm loss: 10.226671, speed: 1.064887 steps/s, speed: 8.519097 samples/s, speed: 4361.777736 tokens/s, learning rate: 1.100e-06, loss_scalings: 26214.400391, pp_loss: 9.018845
[INFO] 2021-07-12 18:14:43,000 [run_pretraining.py:  512]:	********exe.run_111******* 
[INFO] 2021-07-12 18:14:43,935 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:14:43,936 [run_pretraining.py:  534]:	loss/total_loss, 10.1371431350708, 112
[INFO] 2021-07-12 18:14:43,936 [run_pretraining.py:  535]:	loss/mlm_loss, 10.1371431350708, 112
[INFO] 2021-07-12 18:14:43,936 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1099999710495467e-06, 112
[INFO] 2021-07-12 18:14:43,936 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 112
[INFO] 2021-07-12 18:14:43,936 [run_pretraining.py:  558]:	worker_index: 2, step: 112, cost: 10.137143, mlm loss: 10.137143, speed: 1.069343 steps/s, speed: 8.554741 samples/s, speed: 4380.027429 tokens/s, learning rate: 1.110e-06, loss_scalings: 26214.400391, pp_loss: 9.546557
[INFO] 2021-07-12 18:14:43,936 [run_pretraining.py:  512]:	********exe.run_112******* 
[INFO] 2021-07-12 18:14:44,867 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:14:44,868 [run_pretraining.py:  534]:	loss/total_loss, 10.225438117980957, 113
[INFO] 2021-07-12 18:14:44,868 [run_pretraining.py:  535]:	loss/mlm_loss, 10.225438117980957, 113
[INFO] 2021-07-12 18:14:44,868 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1199999789823778e-06, 113
[INFO] 2021-07-12 18:14:44,868 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 113
[INFO] 2021-07-12 18:14:44,868 [run_pretraining.py:  558]:	worker_index: 2, step: 113, cost: 10.225438, mlm loss: 10.225438, speed: 1.073634 steps/s, speed: 8.589075 samples/s, speed: 4397.606328 tokens/s, learning rate: 1.120e-06, loss_scalings: 26214.400391, pp_loss: 10.143627
[INFO] 2021-07-12 18:14:44,868 [run_pretraining.py:  512]:	********exe.run_113******* 
[INFO] 2021-07-12 18:15:08,569 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:15:08,570 [run_pretraining.py:  534]:	loss/total_loss, 10.147421836853027, 114
[INFO] 2021-07-12 18:15:08,570 [run_pretraining.py:  535]:	loss/mlm_loss, 10.147421836853027, 114
[INFO] 2021-07-12 18:15:08,570 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1299999869152089e-06, 114
[INFO] 2021-07-12 18:15:08,570 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 114
[INFO] 2021-07-12 18:15:08,570 [run_pretraining.py:  558]:	worker_index: 2, step: 114, cost: 10.147422, mlm loss: 10.147422, speed: 0.042192 steps/s, speed: 0.337534 samples/s, speed: 172.817390 tokens/s, learning rate: 1.130e-06, loss_scalings: 26214.400391, pp_loss: 10.165155
[INFO] 2021-07-12 18:15:08,570 [run_pretraining.py:  512]:	********exe.run_114******* 
[INFO] 2021-07-12 18:15:33,779 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:15:33,780 [run_pretraining.py:  534]:	loss/total_loss, 10.15625, 115
[INFO] 2021-07-12 18:15:33,780 [run_pretraining.py:  535]:	loss/mlm_loss, 10.15625, 115
[INFO] 2021-07-12 18:15:33,780 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.13999999484804e-06, 115
[INFO] 2021-07-12 18:15:33,780 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 115
[INFO] 2021-07-12 18:15:33,780 [run_pretraining.py:  558]:	worker_index: 2, step: 115, cost: 10.156250, mlm loss: 10.156250, speed: 0.039668 steps/s, speed: 0.317341 samples/s, speed: 162.478539 tokens/s, learning rate: 1.140e-06, loss_scalings: 26214.400391, pp_loss: 10.170643
[INFO] 2021-07-12 18:15:33,780 [run_pretraining.py:  512]:	********exe.run_115******* 
[INFO] 2021-07-12 18:15:34,735 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:15:34,735 [run_pretraining.py:  534]:	loss/total_loss, 10.149320602416992, 116
[INFO] 2021-07-12 18:15:34,735 [run_pretraining.py:  535]:	loss/mlm_loss, 10.149320602416992, 116
[INFO] 2021-07-12 18:15:34,735 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.150000002780871e-06, 116
[INFO] 2021-07-12 18:15:34,736 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 116
[INFO] 2021-07-12 18:15:34,736 [run_pretraining.py:  558]:	worker_index: 2, step: 116, cost: 10.149321, mlm loss: 10.149321, speed: 1.047249 steps/s, speed: 8.377993 samples/s, speed: 4289.532458 tokens/s, learning rate: 1.150e-06, loss_scalings: 26214.400391, pp_loss: 10.157918
[INFO] 2021-07-12 18:15:34,736 [run_pretraining.py:  512]:	********exe.run_116******* 
[INFO] 2021-07-12 18:15:35,672 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:15:35,672 [run_pretraining.py:  534]:	loss/total_loss, 10.09721565246582, 117
[INFO] 2021-07-12 18:15:35,672 [run_pretraining.py:  535]:	loss/mlm_loss, 10.09721565246582, 117
[INFO] 2021-07-12 18:15:35,672 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.160000010713702e-06, 117
[INFO] 2021-07-12 18:15:35,673 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 117
[INFO] 2021-07-12 18:15:35,673 [run_pretraining.py:  558]:	worker_index: 2, step: 117, cost: 10.097216, mlm loss: 10.097216, speed: 1.067948 steps/s, speed: 8.543582 samples/s, speed: 4374.314073 tokens/s, learning rate: 1.160e-06, loss_scalings: 26214.400391, pp_loss: 10.224460
[INFO] 2021-07-12 18:15:35,673 [run_pretraining.py:  512]:	********exe.run_117******* 
[INFO] 2021-07-12 18:16:01,598 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:16:01,598 [run_pretraining.py:  534]:	loss/total_loss, 10.203388214111328, 118
[INFO] 2021-07-12 18:16:01,599 [run_pretraining.py:  535]:	loss/mlm_loss, 10.203388214111328, 118
[INFO] 2021-07-12 18:16:01,599 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1699999049596954e-06, 118
[INFO] 2021-07-12 18:16:01,599 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 118
[INFO] 2021-07-12 18:16:01,599 [run_pretraining.py:  558]:	worker_index: 2, step: 118, cost: 10.203388, mlm loss: 10.203388, speed: 0.038572 steps/s, speed: 0.308575 samples/s, speed: 157.990275 tokens/s, learning rate: 1.170e-06, loss_scalings: 26214.400391, pp_loss: 10.172343
[INFO] 2021-07-12 18:16:01,599 [run_pretraining.py:  512]:	********exe.run_118******* 
[INFO] 2021-07-12 18:16:02,552 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:16:02,553 [run_pretraining.py:  534]:	loss/total_loss, 10.190254211425781, 119
[INFO] 2021-07-12 18:16:02,553 [run_pretraining.py:  535]:	loss/mlm_loss, 10.190254211425781, 119
[INFO] 2021-07-12 18:16:02,553 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1800000265793642e-06, 119
[INFO] 2021-07-12 18:16:02,553 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 119
[INFO] 2021-07-12 18:16:02,553 [run_pretraining.py:  558]:	worker_index: 2, step: 119, cost: 10.190254, mlm loss: 10.190254, speed: 1.048637 steps/s, speed: 8.389099 samples/s, speed: 4295.218566 tokens/s, learning rate: 1.180e-06, loss_scalings: 26214.400391, pp_loss: 10.201545
[INFO] 2021-07-12 18:16:02,553 [run_pretraining.py:  512]:	********exe.run_119******* 
[INFO] 2021-07-12 18:16:03,486 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:16:03,486 [run_pretraining.py:  534]:	loss/total_loss, 10.167705535888672, 120
[INFO] 2021-07-12 18:16:03,486 [run_pretraining.py:  535]:	loss/mlm_loss, 10.167705535888672, 120
[INFO] 2021-07-12 18:16:03,486 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1900000345121953e-06, 120
[INFO] 2021-07-12 18:16:03,486 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 120
[INFO] 2021-07-12 18:16:03,487 [run_pretraining.py:  558]:	worker_index: 2, step: 120, cost: 10.167706, mlm loss: 10.167706, speed: 1.071949 steps/s, speed: 8.575592 samples/s, speed: 4390.703288 tokens/s, learning rate: 1.190e-06, loss_scalings: 26214.400391, pp_loss: 10.150122
[INFO] 2021-07-12 18:16:03,487 [run_pretraining.py:  512]:	********exe.run_120******* 
[INFO] 2021-07-12 18:16:04,414 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:16:04,414 [run_pretraining.py:  534]:	loss/total_loss, 10.175970077514648, 121
[INFO] 2021-07-12 18:16:04,415 [run_pretraining.py:  535]:	loss/mlm_loss, 10.175970077514648, 121
[INFO] 2021-07-12 18:16:04,415 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1999999287581886e-06, 121
[INFO] 2021-07-12 18:16:04,415 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 121
[INFO] 2021-07-12 18:16:04,415 [run_pretraining.py:  558]:	worker_index: 2, step: 121, cost: 10.175970, mlm loss: 10.175970, speed: 1.078056 steps/s, speed: 8.624450 samples/s, speed: 4415.718428 tokens/s, learning rate: 1.200e-06, loss_scalings: 26214.400391, pp_loss: 10.022676
[INFO] 2021-07-12 18:16:04,415 [run_pretraining.py:  512]:	********exe.run_121******* 
[INFO] 2021-07-12 18:16:30,645 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:16:30,646 [run_pretraining.py:  534]:	loss/total_loss, 10.027994155883789, 122
[INFO] 2021-07-12 18:16:30,646 [run_pretraining.py:  535]:	loss/mlm_loss, 10.027994155883789, 122
[INFO] 2021-07-12 18:16:30,646 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2099999366910197e-06, 122
[INFO] 2021-07-12 18:16:30,646 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 122
[INFO] 2021-07-12 18:16:30,646 [run_pretraining.py:  558]:	worker_index: 2, step: 122, cost: 10.027994, mlm loss: 10.027994, speed: 0.038123 steps/s, speed: 0.304985 samples/s, speed: 156.152497 tokens/s, learning rate: 1.210e-06, loss_scalings: 26214.400391, pp_loss: 10.141068
[INFO] 2021-07-12 18:16:30,646 [run_pretraining.py:  512]:	********exe.run_122******* 
[INFO] 2021-07-12 18:16:31,605 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:16:31,606 [run_pretraining.py:  534]:	loss/total_loss, 10.157757759094238, 123
[INFO] 2021-07-12 18:16:31,606 [run_pretraining.py:  535]:	loss/mlm_loss, 10.157757759094238, 123
[INFO] 2021-07-12 18:16:31,606 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2199999446238508e-06, 123
[INFO] 2021-07-12 18:16:31,606 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 123
[INFO] 2021-07-12 18:16:31,606 [run_pretraining.py:  558]:	worker_index: 2, step: 123, cost: 10.157758, mlm loss: 10.157758, speed: 1.042098 steps/s, speed: 8.336780 samples/s, speed: 4268.431524 tokens/s, learning rate: 1.220e-06, loss_scalings: 26214.400391, pp_loss: 8.935140
[INFO] 2021-07-12 18:16:31,606 [run_pretraining.py:  512]:	********exe.run_123******* 
[INFO] 2021-07-12 18:16:32,550 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:16:32,550 [run_pretraining.py:  534]:	loss/total_loss, 10.154870986938477, 124
[INFO] 2021-07-12 18:16:32,550 [run_pretraining.py:  535]:	loss/mlm_loss, 10.154870986938477, 124
[INFO] 2021-07-12 18:16:32,550 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2299999525566818e-06, 124
[INFO] 2021-07-12 18:16:32,550 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 124
[INFO] 2021-07-12 18:16:32,551 [run_pretraining.py:  558]:	worker_index: 2, step: 124, cost: 10.154871, mlm loss: 10.154871, speed: 1.059734 steps/s, speed: 8.477869 samples/s, speed: 4340.669116 tokens/s, learning rate: 1.230e-06, loss_scalings: 26214.400391, pp_loss: 10.168983
[INFO] 2021-07-12 18:16:32,551 [run_pretraining.py:  512]:	********exe.run_124******* 
[INFO] 2021-07-12 18:16:33,485 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:16:33,485 [run_pretraining.py:  534]:	loss/total_loss, 10.146169662475586, 125
[INFO] 2021-07-12 18:16:33,485 [run_pretraining.py:  535]:	loss/mlm_loss, 10.146169662475586, 125
[INFO] 2021-07-12 18:16:33,485 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2399999604895129e-06, 125
[INFO] 2021-07-12 18:16:33,485 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 125
[INFO] 2021-07-12 18:16:33,485 [run_pretraining.py:  558]:	worker_index: 2, step: 125, cost: 10.146170, mlm loss: 10.146170, speed: 1.070351 steps/s, speed: 8.562810 samples/s, speed: 4384.158619 tokens/s, learning rate: 1.240e-06, loss_scalings: 26214.400391, pp_loss: 10.182219
[INFO] 2021-07-12 18:16:33,485 [run_pretraining.py:  512]:	********exe.run_125******* 
[INFO] 2021-07-12 18:16:58,775 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:16:58,776 [run_pretraining.py:  534]:	loss/total_loss, 10.264825820922852, 126
[INFO] 2021-07-12 18:16:58,776 [run_pretraining.py:  535]:	loss/mlm_loss, 10.264825820922852, 126
[INFO] 2021-07-12 18:16:58,776 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.249999968422344e-06, 126
[INFO] 2021-07-12 18:16:58,776 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 126
[INFO] 2021-07-12 18:16:58,776 [run_pretraining.py:  558]:	worker_index: 2, step: 126, cost: 10.264826, mlm loss: 10.264826, speed: 0.039541 steps/s, speed: 0.316330 samples/s, speed: 161.961056 tokens/s, learning rate: 1.250e-06, loss_scalings: 26214.400391, pp_loss: 10.109880
[INFO] 2021-07-12 18:16:58,776 [run_pretraining.py:  512]:	********exe.run_126******* 
[INFO] 2021-07-12 18:16:59,709 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:16:59,710 [run_pretraining.py:  534]:	loss/total_loss, 10.198980331420898, 127
[INFO] 2021-07-12 18:16:59,710 [run_pretraining.py:  535]:	loss/mlm_loss, 10.198980331420898, 127
[INFO] 2021-07-12 18:16:59,710 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.259999976355175e-06, 127
[INFO] 2021-07-12 18:16:59,710 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 127
[INFO] 2021-07-12 18:16:59,710 [run_pretraining.py:  558]:	worker_index: 2, step: 127, cost: 10.198980, mlm loss: 10.198980, speed: 1.071312 steps/s, speed: 8.570498 samples/s, speed: 4388.094734 tokens/s, learning rate: 1.260e-06, loss_scalings: 26214.400391, pp_loss: 10.157987
[INFO] 2021-07-12 18:16:59,710 [run_pretraining.py:  512]:	********exe.run_127******* 
[INFO] 2021-07-12 18:17:26,179 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:17:26,180 [run_pretraining.py:  534]:	loss/total_loss, 10.061135292053223, 128
[INFO] 2021-07-12 18:17:26,180 [run_pretraining.py:  535]:	loss/mlm_loss, 10.061135292053223, 128
[INFO] 2021-07-12 18:17:26,180 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.269999984288006e-06, 128
[INFO] 2021-07-12 18:17:26,180 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 128
[INFO] 2021-07-12 18:17:26,180 [run_pretraining.py:  558]:	worker_index: 2, step: 128, cost: 10.061135, mlm loss: 10.061135, speed: 0.037779 steps/s, speed: 0.302235 samples/s, speed: 154.744065 tokens/s, learning rate: 1.270e-06, loss_scalings: 26214.400391, pp_loss: 10.063387
[INFO] 2021-07-12 18:17:26,180 [run_pretraining.py:  512]:	********exe.run_128******* 
[INFO] 2021-07-12 18:18:14,900 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:18:14,901 [run_pretraining.py:  534]:	loss/total_loss, 9.583300590515137, 129
[INFO] 2021-07-12 18:18:14,901 [run_pretraining.py:  535]:	loss/mlm_loss, 9.583300590515137, 129
[INFO] 2021-07-12 18:18:14,901 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2799998785339994e-06, 129
[INFO] 2021-07-12 18:18:14,901 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 129
[INFO] 2021-07-12 18:18:14,901 [run_pretraining.py:  558]:	worker_index: 2, step: 129, cost: 9.583301, mlm loss: 9.583301, speed: 0.020525 steps/s, speed: 0.164202 samples/s, speed: 84.071605 tokens/s, learning rate: 1.280e-06, loss_scalings: 26214.400391, pp_loss: 9.990428
[INFO] 2021-07-12 18:18:14,901 [run_pretraining.py:  512]:	********exe.run_129******* 
[INFO] 2021-07-12 18:18:15,863 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:18:15,863 [run_pretraining.py:  534]:	loss/total_loss, 10.17300796508789, 130
[INFO] 2021-07-12 18:18:15,863 [run_pretraining.py:  535]:	loss/mlm_loss, 10.17300796508789, 130
[INFO] 2021-07-12 18:18:15,863 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2900000001536682e-06, 130
[INFO] 2021-07-12 18:18:15,863 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 130
[INFO] 2021-07-12 18:18:15,864 [run_pretraining.py:  558]:	worker_index: 2, step: 130, cost: 10.173008, mlm loss: 10.173008, speed: 1.039811 steps/s, speed: 8.318491 samples/s, speed: 4259.067615 tokens/s, learning rate: 1.290e-06, loss_scalings: 26214.400391, pp_loss: 10.137020
[INFO] 2021-07-12 18:18:15,864 [run_pretraining.py:  512]:	********exe.run_130******* 
[INFO] 2021-07-12 18:19:03,084 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:19:03,085 [run_pretraining.py:  534]:	loss/total_loss, 10.243566513061523, 131
[INFO] 2021-07-12 18:19:03,085 [run_pretraining.py:  535]:	loss/mlm_loss, 10.243566513061523, 131
[INFO] 2021-07-12 18:19:03,085 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3000000080864993e-06, 131
[INFO] 2021-07-12 18:19:03,085 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 131
[INFO] 2021-07-12 18:19:03,085 [run_pretraining.py:  558]:	worker_index: 2, step: 131, cost: 10.243567, mlm loss: 10.243567, speed: 0.021177 steps/s, speed: 0.169416 samples/s, speed: 86.740895 tokens/s, learning rate: 1.300e-06, loss_scalings: 26214.400391, pp_loss: 10.141508
[INFO] 2021-07-12 18:19:03,085 [run_pretraining.py:  512]:	********exe.run_131******* 
[INFO] 2021-07-12 18:19:04,034 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:19:04,035 [run_pretraining.py:  534]:	loss/total_loss, 10.176712036132812, 132
[INFO] 2021-07-12 18:19:04,035 [run_pretraining.py:  535]:	loss/mlm_loss, 10.176712036132812, 132
[INFO] 2021-07-12 18:19:04,035 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3100000160193304e-06, 132
[INFO] 2021-07-12 18:19:04,035 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 132
[INFO] 2021-07-12 18:19:04,035 [run_pretraining.py:  558]:	worker_index: 2, step: 132, cost: 10.176712, mlm loss: 10.176712, speed: 1.053530 steps/s, speed: 8.428242 samples/s, speed: 4315.259805 tokens/s, learning rate: 1.310e-06, loss_scalings: 26214.400391, pp_loss: 10.118958
[INFO] 2021-07-12 18:19:04,035 [run_pretraining.py:  512]:	********exe.run_132******* 
[INFO] 2021-07-12 18:19:04,977 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:19:04,978 [run_pretraining.py:  534]:	loss/total_loss, 10.171241760253906, 133
[INFO] 2021-07-12 18:19:04,978 [run_pretraining.py:  535]:	loss/mlm_loss, 10.171241760253906, 133
[INFO] 2021-07-12 18:19:04,978 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3199999102653237e-06, 133
[INFO] 2021-07-12 18:19:04,978 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 133
[INFO] 2021-07-12 18:19:04,978 [run_pretraining.py:  558]:	worker_index: 2, step: 133, cost: 10.171242, mlm loss: 10.171242, speed: 1.060935 steps/s, speed: 8.487476 samples/s, speed: 4345.587964 tokens/s, learning rate: 1.320e-06, loss_scalings: 26214.400391, pp_loss: 10.115871
[INFO] 2021-07-12 18:19:04,978 [run_pretraining.py:  512]:	********exe.run_133******* 
[INFO] 2021-07-12 18:19:05,919 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:19:05,919 [run_pretraining.py:  534]:	loss/total_loss, 10.193801879882812, 134
[INFO] 2021-07-12 18:19:05,919 [run_pretraining.py:  535]:	loss/mlm_loss, 10.193801879882812, 134
[INFO] 2021-07-12 18:19:05,919 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3299999181981548e-06, 134
[INFO] 2021-07-12 18:19:05,919 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 134
[INFO] 2021-07-12 18:19:05,919 [run_pretraining.py:  558]:	worker_index: 2, step: 134, cost: 10.193802, mlm loss: 10.193802, speed: 1.063195 steps/s, speed: 8.505562 samples/s, speed: 4354.847538 tokens/s, learning rate: 1.330e-06, loss_scalings: 26214.400391, pp_loss: 9.574755
[INFO] 2021-07-12 18:19:05,919 [run_pretraining.py:  512]:	********exe.run_134******* 
[INFO] 2021-07-12 18:19:52,316 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:19:52,317 [run_pretraining.py:  534]:	loss/total_loss, 10.231224060058594, 135
[INFO] 2021-07-12 18:19:52,317 [run_pretraining.py:  535]:	loss/mlm_loss, 10.231224060058594, 135
[INFO] 2021-07-12 18:19:52,317 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3399999261309858e-06, 135
[INFO] 2021-07-12 18:19:52,317 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 135
[INFO] 2021-07-12 18:19:52,317 [run_pretraining.py:  558]:	worker_index: 2, step: 135, cost: 10.231224, mlm loss: 10.231224, speed: 0.021553 steps/s, speed: 0.172425 samples/s, speed: 88.281565 tokens/s, learning rate: 1.340e-06, loss_scalings: 26214.400391, pp_loss: 9.139049
[INFO] 2021-07-12 18:19:52,317 [run_pretraining.py:  512]:	********exe.run_135******* 
[INFO] 2021-07-12 18:19:53,248 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:19:53,248 [run_pretraining.py:  534]:	loss/total_loss, 10.053855895996094, 136
[INFO] 2021-07-12 18:19:53,248 [run_pretraining.py:  535]:	loss/mlm_loss, 10.053855895996094, 136
[INFO] 2021-07-12 18:19:53,249 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3500000477506546e-06, 136
[INFO] 2021-07-12 18:19:53,249 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 136
[INFO] 2021-07-12 18:19:53,249 [run_pretraining.py:  558]:	worker_index: 2, step: 136, cost: 10.053856, mlm loss: 10.053856, speed: 1.073950 steps/s, speed: 8.591604 samples/s, speed: 4398.901235 tokens/s, learning rate: 1.350e-06, loss_scalings: 26214.400391, pp_loss: 10.162003
[INFO] 2021-07-12 18:19:53,249 [run_pretraining.py:  512]:	********exe.run_136******* 
[INFO] 2021-07-12 18:19:54,182 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:19:54,182 [run_pretraining.py:  534]:	loss/total_loss, 10.075152397155762, 137
[INFO] 2021-07-12 18:19:54,182 [run_pretraining.py:  535]:	loss/mlm_loss, 10.075152397155762, 137
[INFO] 2021-07-12 18:19:54,182 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.359999941996648e-06, 137
[INFO] 2021-07-12 18:19:54,182 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 137
[INFO] 2021-07-12 18:19:54,182 [run_pretraining.py:  558]:	worker_index: 2, step: 137, cost: 10.075152, mlm loss: 10.075152, speed: 1.071757 steps/s, speed: 8.574054 samples/s, speed: 4389.915685 tokens/s, learning rate: 1.360e-06, loss_scalings: 26214.400391, pp_loss: 10.170456
[INFO] 2021-07-12 18:19:54,182 [run_pretraining.py:  512]:	********exe.run_137******* 
[INFO] 2021-07-12 18:19:55,119 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:19:55,120 [run_pretraining.py:  534]:	loss/total_loss, 10.101038932800293, 138
[INFO] 2021-07-12 18:19:55,120 [run_pretraining.py:  535]:	loss/mlm_loss, 10.101038932800293, 138
[INFO] 2021-07-12 18:19:55,120 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.369999949929479e-06, 138
[INFO] 2021-07-12 18:19:55,120 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 138
[INFO] 2021-07-12 18:19:55,120 [run_pretraining.py:  558]:	worker_index: 2, step: 138, cost: 10.101039, mlm loss: 10.101039, speed: 1.067041 steps/s, speed: 8.536331 samples/s, speed: 4370.601650 tokens/s, learning rate: 1.370e-06, loss_scalings: 26214.400391, pp_loss: 10.046395
[INFO] 2021-07-12 18:19:55,120 [run_pretraining.py:  512]:	********exe.run_138******* 
[INFO] 2021-07-12 18:19:56,057 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:19:56,057 [run_pretraining.py:  534]:	loss/total_loss, 9.999738693237305, 139
[INFO] 2021-07-12 18:19:56,057 [run_pretraining.py:  535]:	loss/mlm_loss, 9.999738693237305, 139
[INFO] 2021-07-12 18:19:56,057 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3799999578623101e-06, 139
[INFO] 2021-07-12 18:19:56,058 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 139
[INFO] 2021-07-12 18:19:56,058 [run_pretraining.py:  558]:	worker_index: 2, step: 139, cost: 9.999739, mlm loss: 9.999739, speed: 1.067344 steps/s, speed: 8.538753 samples/s, speed: 4371.841762 tokens/s, learning rate: 1.380e-06, loss_scalings: 26214.400391, pp_loss: 9.897690
[INFO] 2021-07-12 18:19:56,058 [run_pretraining.py:  512]:	********exe.run_139******* 
[INFO] 2021-07-12 18:20:19,889 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:20:19,890 [run_pretraining.py:  534]:	loss/total_loss, 10.085803031921387, 140
[INFO] 2021-07-12 18:20:19,890 [run_pretraining.py:  535]:	loss/mlm_loss, 10.085803031921387, 140
[INFO] 2021-07-12 18:20:19,890 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3899999657951412e-06, 140
[INFO] 2021-07-12 18:20:19,890 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 140
[INFO] 2021-07-12 18:20:19,890 [run_pretraining.py:  558]:	worker_index: 2, step: 140, cost: 10.085803, mlm loss: 10.085803, speed: 0.041961 steps/s, speed: 0.335687 samples/s, speed: 171.871557 tokens/s, learning rate: 1.390e-06, loss_scalings: 26214.400391, pp_loss: 10.074787
[INFO] 2021-07-12 18:20:19,890 [run_pretraining.py:  512]:	********exe.run_140******* 
[INFO] 2021-07-12 18:20:20,818 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:20:20,819 [run_pretraining.py:  534]:	loss/total_loss, 10.018532752990723, 141
[INFO] 2021-07-12 18:20:20,819 [run_pretraining.py:  535]:	loss/mlm_loss, 10.018532752990723, 141
[INFO] 2021-07-12 18:20:20,819 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3999999737279722e-06, 141
[INFO] 2021-07-12 18:20:20,819 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 141
[INFO] 2021-07-12 18:20:20,819 [run_pretraining.py:  558]:	worker_index: 2, step: 141, cost: 10.018533, mlm loss: 10.018533, speed: 1.077165 steps/s, speed: 8.617318 samples/s, speed: 4412.066860 tokens/s, learning rate: 1.400e-06, loss_scalings: 26214.400391, pp_loss: 10.012213
[INFO] 2021-07-12 18:20:20,819 [run_pretraining.py:  512]:	********exe.run_141******* 
[INFO] 2021-07-12 18:20:21,759 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:20:21,759 [run_pretraining.py:  534]:	loss/total_loss, 10.105388641357422, 142
[INFO] 2021-07-12 18:20:21,760 [run_pretraining.py:  535]:	loss/mlm_loss, 10.105388641357422, 142
[INFO] 2021-07-12 18:20:21,760 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4099999816608033e-06, 142
[INFO] 2021-07-12 18:20:21,760 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 142
[INFO] 2021-07-12 18:20:21,760 [run_pretraining.py:  558]:	worker_index: 2, step: 142, cost: 10.105389, mlm loss: 10.105389, speed: 1.063494 steps/s, speed: 8.507953 samples/s, speed: 4356.072097 tokens/s, learning rate: 1.410e-06, loss_scalings: 26214.400391, pp_loss: 9.212915
[INFO] 2021-07-12 18:20:21,760 [run_pretraining.py:  512]:	********exe.run_142******* 
[INFO] 2021-07-12 18:20:45,284 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:20:45,284 [run_pretraining.py:  534]:	loss/total_loss, 10.238107681274414, 143
[INFO] 2021-07-12 18:20:45,285 [run_pretraining.py:  535]:	loss/mlm_loss, 10.238107681274414, 143
[INFO] 2021-07-12 18:20:45,285 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4199999895936344e-06, 143
[INFO] 2021-07-12 18:20:45,285 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 143
[INFO] 2021-07-12 18:20:45,285 [run_pretraining.py:  558]:	worker_index: 2, step: 143, cost: 10.238108, mlm loss: 10.238108, speed: 0.042509 steps/s, speed: 0.340072 samples/s, speed: 174.116716 tokens/s, learning rate: 1.420e-06, loss_scalings: 26214.400391, pp_loss: 10.101395
[INFO] 2021-07-12 18:20:45,285 [run_pretraining.py:  512]:	********exe.run_143******* 
[INFO] 2021-07-12 18:21:08,576 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:21:08,576 [run_pretraining.py:  534]:	loss/total_loss, 10.001385688781738, 144
[INFO] 2021-07-12 18:21:08,577 [run_pretraining.py:  535]:	loss/mlm_loss, 10.001385688781738, 144
[INFO] 2021-07-12 18:21:08,577 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4299999975264654e-06, 144
[INFO] 2021-07-12 18:21:08,577 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 144
[INFO] 2021-07-12 18:21:08,577 [run_pretraining.py:  558]:	worker_index: 2, step: 144, cost: 10.001386, mlm loss: 10.001386, speed: 0.042934 steps/s, speed: 0.343475 samples/s, speed: 175.858968 tokens/s, learning rate: 1.430e-06, loss_scalings: 26214.400391, pp_loss: 9.943913
[INFO] 2021-07-12 18:21:08,577 [run_pretraining.py:  512]:	********exe.run_144******* 
[INFO] 2021-07-12 18:21:09,532 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:21:09,533 [run_pretraining.py:  534]:	loss/total_loss, 10.19344711303711, 145
[INFO] 2021-07-12 18:21:09,533 [run_pretraining.py:  535]:	loss/mlm_loss, 10.19344711303711, 145
[INFO] 2021-07-12 18:21:09,533 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4399998917724588e-06, 145
[INFO] 2021-07-12 18:21:09,533 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 145
[INFO] 2021-07-12 18:21:09,533 [run_pretraining.py:  558]:	worker_index: 2, step: 145, cost: 10.193447, mlm loss: 10.193447, speed: 1.046278 steps/s, speed: 8.370225 samples/s, speed: 4285.555146 tokens/s, learning rate: 1.440e-06, loss_scalings: 26214.400391, pp_loss: 10.112129
[INFO] 2021-07-12 18:21:09,533 [run_pretraining.py:  512]:	********exe.run_145******* 
[INFO] 2021-07-12 18:21:10,475 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:21:10,475 [run_pretraining.py:  534]:	loss/total_loss, 10.115832328796387, 146
[INFO] 2021-07-12 18:21:10,475 [run_pretraining.py:  535]:	loss/mlm_loss, 10.115832328796387, 146
[INFO] 2021-07-12 18:21:10,475 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4499998997052899e-06, 146
[INFO] 2021-07-12 18:21:10,475 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 146
[INFO] 2021-07-12 18:21:10,475 [run_pretraining.py:  558]:	worker_index: 2, step: 146, cost: 10.115832, mlm loss: 10.115832, speed: 1.061942 steps/s, speed: 8.495535 samples/s, speed: 4349.713882 tokens/s, learning rate: 1.450e-06, loss_scalings: 26214.400391, pp_loss: 10.109447
[INFO] 2021-07-12 18:21:10,476 [run_pretraining.py:  512]:	********exe.run_146******* 
[INFO] 2021-07-12 18:21:11,464 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:21:11,464 [run_pretraining.py:  534]:	loss/total_loss, 9.936738967895508, 147
[INFO] 2021-07-12 18:21:11,464 [run_pretraining.py:  535]:	loss/mlm_loss, 9.936738967895508, 147
[INFO] 2021-07-12 18:21:11,464 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4600000213249587e-06, 147
[INFO] 2021-07-12 18:21:11,464 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 147
[INFO] 2021-07-12 18:21:11,464 [run_pretraining.py:  558]:	worker_index: 2, step: 147, cost: 9.936739, mlm loss: 9.936739, speed: 1.011856 steps/s, speed: 8.094844 samples/s, speed: 4144.560171 tokens/s, learning rate: 1.460e-06, loss_scalings: 26214.400391, pp_loss: 8.884666
[INFO] 2021-07-12 18:21:11,464 [run_pretraining.py:  512]:	********exe.run_147******* 
[INFO] 2021-07-12 18:21:12,413 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:21:12,414 [run_pretraining.py:  534]:	loss/total_loss, 10.12714672088623, 148
[INFO] 2021-07-12 18:21:12,414 [run_pretraining.py:  535]:	loss/mlm_loss, 10.12714672088623, 148
[INFO] 2021-07-12 18:21:12,414 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4700000292577897e-06, 148
[INFO] 2021-07-12 18:21:12,414 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 148
[INFO] 2021-07-12 18:21:12,414 [run_pretraining.py:  558]:	worker_index: 2, step: 148, cost: 10.127147, mlm loss: 10.127147, speed: 1.053705 steps/s, speed: 8.429639 samples/s, speed: 4315.975306 tokens/s, learning rate: 1.470e-06, loss_scalings: 26214.400391, pp_loss: 10.065960
[INFO] 2021-07-12 18:21:12,414 [run_pretraining.py:  512]:	********exe.run_148******* 
[INFO] 2021-07-12 18:21:13,356 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:21:13,356 [run_pretraining.py:  534]:	loss/total_loss, 9.965635299682617, 149
[INFO] 2021-07-12 18:21:13,357 [run_pretraining.py:  535]:	loss/mlm_loss, 9.965635299682617, 149
[INFO] 2021-07-12 18:21:13,357 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.479999923503783e-06, 149
[INFO] 2021-07-12 18:21:13,357 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 149
[INFO] 2021-07-12 18:21:13,357 [run_pretraining.py:  558]:	worker_index: 2, step: 149, cost: 9.965635, mlm loss: 9.965635, speed: 1.061354 steps/s, speed: 8.490836 samples/s, speed: 4347.307795 tokens/s, learning rate: 1.480e-06, loss_scalings: 26214.400391, pp_loss: 10.099848
[INFO] 2021-07-12 18:21:13,357 [run_pretraining.py:  512]:	********exe.run_149******* 
[INFO] 2021-07-12 18:21:14,299 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:21:14,299 [run_pretraining.py:  534]:	loss/total_loss, 9.968467712402344, 150
[INFO] 2021-07-12 18:21:14,300 [run_pretraining.py:  535]:	loss/mlm_loss, 9.968467712402344, 150
[INFO] 2021-07-12 18:21:14,300 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4899999314366141e-06, 150
[INFO] 2021-07-12 18:21:14,300 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 150
[INFO] 2021-07-12 18:21:14,300 [run_pretraining.py:  558]:	worker_index: 2, step: 150, cost: 9.968468, mlm loss: 9.968468, speed: 1.061092 steps/s, speed: 8.488739 samples/s, speed: 4346.234390 tokens/s, learning rate: 1.490e-06, loss_scalings: 26214.400391, pp_loss: 10.047433
[INFO] 2021-07-12 18:21:14,300 [run_pretraining.py:  512]:	********exe.run_150******* 
[INFO] 2021-07-12 18:21:15,238 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:21:15,238 [run_pretraining.py:  534]:	loss/total_loss, 10.054871559143066, 151
[INFO] 2021-07-12 18:21:15,238 [run_pretraining.py:  535]:	loss/mlm_loss, 10.054871559143066, 151
[INFO] 2021-07-12 18:21:15,238 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4999999393694452e-06, 151
[INFO] 2021-07-12 18:21:15,239 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 151
[INFO] 2021-07-12 18:21:15,239 [run_pretraining.py:  558]:	worker_index: 2, step: 151, cost: 10.054872, mlm loss: 10.054872, speed: 1.065842 steps/s, speed: 8.526739 samples/s, speed: 4365.690389 tokens/s, learning rate: 1.500e-06, loss_scalings: 26214.400391, pp_loss: 9.987130
[INFO] 2021-07-12 18:21:15,239 [run_pretraining.py:  512]:	********exe.run_151******* 
[INFO] 2021-07-12 18:21:16,188 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:21:16,188 [run_pretraining.py:  534]:	loss/total_loss, 9.980351448059082, 152
[INFO] 2021-07-12 18:21:16,188 [run_pretraining.py:  535]:	loss/mlm_loss, 9.980351448059082, 152
[INFO] 2021-07-12 18:21:16,188 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.510000060989114e-06, 152
[INFO] 2021-07-12 18:21:16,188 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 152
[INFO] 2021-07-12 18:21:16,188 [run_pretraining.py:  558]:	worker_index: 2, step: 152, cost: 9.980351, mlm loss: 9.980351, speed: 1.053459 steps/s, speed: 8.427674 samples/s, speed: 4314.969336 tokens/s, learning rate: 1.510e-06, loss_scalings: 26214.400391, pp_loss: 9.973965
[INFO] 2021-07-12 18:21:16,189 [run_pretraining.py:  512]:	********exe.run_152******* 
[INFO] 2021-07-12 18:21:17,139 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:21:17,139 [run_pretraining.py:  534]:	loss/total_loss, 10.138038635253906, 153
[INFO] 2021-07-12 18:21:17,139 [run_pretraining.py:  535]:	loss/mlm_loss, 10.138038635253906, 153
[INFO] 2021-07-12 18:21:17,139 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5199999552351073e-06, 153
[INFO] 2021-07-12 18:21:17,139 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 153
[INFO] 2021-07-12 18:21:17,139 [run_pretraining.py:  558]:	worker_index: 2, step: 153, cost: 10.138039, mlm loss: 10.138039, speed: 1.052321 steps/s, speed: 8.418565 samples/s, speed: 4310.305518 tokens/s, learning rate: 1.520e-06, loss_scalings: 26214.400391, pp_loss: 10.013098
[INFO] 2021-07-12 18:21:17,139 [run_pretraining.py:  512]:	********exe.run_153******* 
[INFO] 2021-07-12 18:21:42,894 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:21:42,894 [run_pretraining.py:  534]:	loss/total_loss, 9.859636306762695, 154
[INFO] 2021-07-12 18:21:42,895 [run_pretraining.py:  535]:	loss/mlm_loss, 9.859636306762695, 154
[INFO] 2021-07-12 18:21:42,895 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5299999631679384e-06, 154
[INFO] 2021-07-12 18:21:42,895 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 154
[INFO] 2021-07-12 18:21:42,895 [run_pretraining.py:  558]:	worker_index: 2, step: 154, cost: 9.859636, mlm loss: 9.859636, speed: 0.038828 steps/s, speed: 0.310621 samples/s, speed: 159.038147 tokens/s, learning rate: 1.530e-06, loss_scalings: 26214.400391, pp_loss: 8.751393
[INFO] 2021-07-12 18:21:42,895 [run_pretraining.py:  512]:	********exe.run_154******* 
[INFO] 2021-07-12 18:21:43,893 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:21:43,893 [run_pretraining.py:  534]:	loss/total_loss, 9.982450485229492, 155
[INFO] 2021-07-12 18:21:43,893 [run_pretraining.py:  535]:	loss/mlm_loss, 9.982450485229492, 155
[INFO] 2021-07-12 18:21:43,893 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5399999711007695e-06, 155
[INFO] 2021-07-12 18:21:43,893 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 155
[INFO] 2021-07-12 18:21:43,893 [run_pretraining.py:  558]:	worker_index: 2, step: 155, cost: 9.982450, mlm loss: 9.982450, speed: 1.001972 steps/s, speed: 8.015774 samples/s, speed: 4104.076441 tokens/s, learning rate: 1.540e-06, loss_scalings: 26214.400391, pp_loss: 8.959836
[INFO] 2021-07-12 18:21:43,893 [run_pretraining.py:  512]:	********exe.run_155******* 
[INFO] 2021-07-12 18:21:44,857 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:21:44,858 [run_pretraining.py:  534]:	loss/total_loss, 9.985370635986328, 156
[INFO] 2021-07-12 18:21:44,858 [run_pretraining.py:  535]:	loss/mlm_loss, 9.985370635986328, 156
[INFO] 2021-07-12 18:21:44,858 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5499999790336005e-06, 156
[INFO] 2021-07-12 18:21:44,858 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 156
[INFO] 2021-07-12 18:21:44,858 [run_pretraining.py:  558]:	worker_index: 2, step: 156, cost: 9.985371, mlm loss: 9.985371, speed: 1.037056 steps/s, speed: 8.296447 samples/s, speed: 4247.780823 tokens/s, learning rate: 1.550e-06, loss_scalings: 26214.400391, pp_loss: 10.001005
[INFO] 2021-07-12 18:21:44,858 [run_pretraining.py:  512]:	********exe.run_156******* 
[INFO] 2021-07-12 18:21:45,828 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:21:45,829 [run_pretraining.py:  534]:	loss/total_loss, 10.023406982421875, 157
[INFO] 2021-07-12 18:21:45,829 [run_pretraining.py:  535]:	loss/mlm_loss, 10.023406982421875, 157
[INFO] 2021-07-12 18:21:45,829 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5599998732795939e-06, 157
[INFO] 2021-07-12 18:21:45,829 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 157
[INFO] 2021-07-12 18:21:45,829 [run_pretraining.py:  558]:	worker_index: 2, step: 157, cost: 10.023407, mlm loss: 10.023407, speed: 1.030796 steps/s, speed: 8.246370 samples/s, speed: 4222.141685 tokens/s, learning rate: 1.560e-06, loss_scalings: 26214.400391, pp_loss: 9.972765
[INFO] 2021-07-12 18:21:45,829 [run_pretraining.py:  512]:	********exe.run_157******* 
[INFO] 2021-07-12 18:22:11,580 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:11,581 [run_pretraining.py:  534]:	loss/total_loss, 10.13087272644043, 158
[INFO] 2021-07-12 18:22:11,581 [run_pretraining.py:  535]:	loss/mlm_loss, 10.13087272644043, 158
[INFO] 2021-07-12 18:22:11,581 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.569999881212425e-06, 158
[INFO] 2021-07-12 18:22:11,581 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 158
[INFO] 2021-07-12 18:22:11,581 [run_pretraining.py:  558]:	worker_index: 2, step: 158, cost: 10.130873, mlm loss: 10.130873, speed: 0.038833 steps/s, speed: 0.310663 samples/s, speed: 159.059232 tokens/s, learning rate: 1.570e-06, loss_scalings: 26214.400391, pp_loss: 9.997479
[INFO] 2021-07-12 18:22:11,581 [run_pretraining.py:  512]:	********exe.run_158******* 
[INFO] 2021-07-12 18:22:12,583 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:12,584 [run_pretraining.py:  534]:	loss/total_loss, 10.07024097442627, 159
[INFO] 2021-07-12 18:22:12,584 [run_pretraining.py:  535]:	loss/mlm_loss, 10.07024097442627, 159
[INFO] 2021-07-12 18:22:12,584 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.579999889145256e-06, 159
[INFO] 2021-07-12 18:22:12,584 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 159
[INFO] 2021-07-12 18:22:12,584 [run_pretraining.py:  558]:	worker_index: 2, step: 159, cost: 10.070241, mlm loss: 10.070241, speed: 0.997433 steps/s, speed: 7.979461 samples/s, speed: 4085.484099 tokens/s, learning rate: 1.580e-06, loss_scalings: 26214.400391, pp_loss: 10.009831
[INFO] 2021-07-12 18:22:12,584 [run_pretraining.py:  512]:	********exe.run_159******* 
[INFO] 2021-07-12 18:22:13,550 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:13,550 [run_pretraining.py:  534]:	loss/total_loss, 10.019373893737793, 160
[INFO] 2021-07-12 18:22:13,550 [run_pretraining.py:  535]:	loss/mlm_loss, 10.019373893737793, 160
[INFO] 2021-07-12 18:22:13,550 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5900000107649248e-06, 160
[INFO] 2021-07-12 18:22:13,550 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 160
[INFO] 2021-07-12 18:22:13,550 [run_pretraining.py:  558]:	worker_index: 2, step: 160, cost: 10.019374, mlm loss: 10.019374, speed: 1.035619 steps/s, speed: 8.284953 samples/s, speed: 4241.895876 tokens/s, learning rate: 1.590e-06, loss_scalings: 26214.400391, pp_loss: 10.101654
[INFO] 2021-07-12 18:22:13,550 [run_pretraining.py:  512]:	********exe.run_160******* 
[INFO] 2021-07-12 18:22:14,519 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:14,520 [run_pretraining.py:  534]:	loss/total_loss, 10.003576278686523, 161
[INFO] 2021-07-12 18:22:14,520 [run_pretraining.py:  535]:	loss/mlm_loss, 10.003576278686523, 161
[INFO] 2021-07-12 18:22:14,520 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6000000186977559e-06, 161
[INFO] 2021-07-12 18:22:14,520 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 161
[INFO] 2021-07-12 18:22:14,520 [run_pretraining.py:  558]:	worker_index: 2, step: 161, cost: 10.003576, mlm loss: 10.003576, speed: 1.031769 steps/s, speed: 8.254154 samples/s, speed: 4226.126859 tokens/s, learning rate: 1.600e-06, loss_scalings: 26214.400391, pp_loss: 9.987064
[INFO] 2021-07-12 18:22:14,520 [run_pretraining.py:  512]:	********exe.run_161******* 
[INFO] 2021-07-12 18:22:15,490 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:15,490 [run_pretraining.py:  534]:	loss/total_loss, 10.094446182250977, 162
[INFO] 2021-07-12 18:22:15,490 [run_pretraining.py:  535]:	loss/mlm_loss, 10.094446182250977, 162
[INFO] 2021-07-12 18:22:15,490 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.610000026630587e-06, 162
[INFO] 2021-07-12 18:22:15,491 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 162
[INFO] 2021-07-12 18:22:15,491 [run_pretraining.py:  558]:	worker_index: 2, step: 162, cost: 10.094446, mlm loss: 10.094446, speed: 1.031152 steps/s, speed: 8.249219 samples/s, speed: 4223.600070 tokens/s, learning rate: 1.610e-06, loss_scalings: 26214.400391, pp_loss: 9.972099
[INFO] 2021-07-12 18:22:15,491 [run_pretraining.py:  512]:	********exe.run_162******* 
[INFO] 2021-07-12 18:22:16,458 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:16,458 [run_pretraining.py:  534]:	loss/total_loss, 10.100482940673828, 163
[INFO] 2021-07-12 18:22:16,458 [run_pretraining.py:  535]:	loss/mlm_loss, 10.100482940673828, 163
[INFO] 2021-07-12 18:22:16,458 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.620000034563418e-06, 163
[INFO] 2021-07-12 18:22:16,459 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 163
[INFO] 2021-07-12 18:22:16,459 [run_pretraining.py:  558]:	worker_index: 2, step: 163, cost: 10.100483, mlm loss: 10.100483, speed: 1.033650 steps/s, speed: 8.269203 samples/s, speed: 4233.831823 tokens/s, learning rate: 1.620e-06, loss_scalings: 26214.400391, pp_loss: 10.010353
[INFO] 2021-07-12 18:22:16,459 [run_pretraining.py:  512]:	********exe.run_163******* 
[INFO] 2021-07-12 18:22:17,434 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:17,434 [run_pretraining.py:  534]:	loss/total_loss, 10.060209274291992, 164
[INFO] 2021-07-12 18:22:17,435 [run_pretraining.py:  535]:	loss/mlm_loss, 10.060209274291992, 164
[INFO] 2021-07-12 18:22:17,435 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6299999288094114e-06, 164
[INFO] 2021-07-12 18:22:17,435 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 164
[INFO] 2021-07-12 18:22:17,435 [run_pretraining.py:  558]:	worker_index: 2, step: 164, cost: 10.060209, mlm loss: 10.060209, speed: 1.024992 steps/s, speed: 8.199938 samples/s, speed: 4198.368094 tokens/s, learning rate: 1.630e-06, loss_scalings: 26214.400391, pp_loss: 9.937662
[INFO] 2021-07-12 18:22:17,435 [run_pretraining.py:  512]:	********exe.run_164******* 
[INFO] 2021-07-12 18:22:18,403 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:18,403 [run_pretraining.py:  534]:	loss/total_loss, 9.846288681030273, 165
[INFO] 2021-07-12 18:22:18,404 [run_pretraining.py:  535]:	loss/mlm_loss, 9.846288681030273, 165
[INFO] 2021-07-12 18:22:18,404 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6399999367422424e-06, 165
[INFO] 2021-07-12 18:22:18,404 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 165
[INFO] 2021-07-12 18:22:18,404 [run_pretraining.py:  558]:	worker_index: 2, step: 165, cost: 9.846289, mlm loss: 9.846289, speed: 1.032628 steps/s, speed: 8.261027 samples/s, speed: 4229.645705 tokens/s, learning rate: 1.640e-06, loss_scalings: 26214.400391, pp_loss: 9.921234
[INFO] 2021-07-12 18:22:18,404 [run_pretraining.py:  512]:	********exe.run_165******* 
[INFO] 2021-07-12 18:22:19,368 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:19,368 [run_pretraining.py:  534]:	loss/total_loss, 9.82199478149414, 166
[INFO] 2021-07-12 18:22:19,368 [run_pretraining.py:  535]:	loss/mlm_loss, 9.82199478149414, 166
[INFO] 2021-07-12 18:22:19,369 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6499999446750735e-06, 166
[INFO] 2021-07-12 18:22:19,369 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 166
[INFO] 2021-07-12 18:22:19,369 [run_pretraining.py:  558]:	worker_index: 2, step: 166, cost: 9.821995, mlm loss: 9.821995, speed: 1.037094 steps/s, speed: 8.296753 samples/s, speed: 4247.937320 tokens/s, learning rate: 1.650e-06, loss_scalings: 26214.400391, pp_loss: 9.957441
[INFO] 2021-07-12 18:22:19,369 [run_pretraining.py:  512]:	********exe.run_166******* 
[INFO] 2021-07-12 18:22:20,338 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:20,338 [run_pretraining.py:  534]:	loss/total_loss, 9.90365219116211, 167
[INFO] 2021-07-12 18:22:20,338 [run_pretraining.py:  535]:	loss/mlm_loss, 9.90365219116211, 167
[INFO] 2021-07-12 18:22:20,338 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6599999526079046e-06, 167
[INFO] 2021-07-12 18:22:20,339 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 167
[INFO] 2021-07-12 18:22:20,339 [run_pretraining.py:  558]:	worker_index: 2, step: 167, cost: 9.903652, mlm loss: 9.903652, speed: 1.031633 steps/s, speed: 8.253062 samples/s, speed: 4225.567630 tokens/s, learning rate: 1.660e-06, loss_scalings: 26214.400391, pp_loss: 10.033308
[INFO] 2021-07-12 18:22:20,339 [run_pretraining.py:  512]:	********exe.run_167******* 
[INFO] 2021-07-12 18:22:21,301 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:21,301 [run_pretraining.py:  534]:	loss/total_loss, 10.026839256286621, 168
[INFO] 2021-07-12 18:22:21,302 [run_pretraining.py:  535]:	loss/mlm_loss, 10.026839256286621, 168
[INFO] 2021-07-12 18:22:21,302 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6699999605407356e-06, 168
[INFO] 2021-07-12 18:22:21,302 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 168
[INFO] 2021-07-12 18:22:21,302 [run_pretraining.py:  558]:	worker_index: 2, step: 168, cost: 10.026839, mlm loss: 10.026839, speed: 1.038875 steps/s, speed: 8.310998 samples/s, speed: 4255.230886 tokens/s, learning rate: 1.670e-06, loss_scalings: 26214.400391, pp_loss: 9.999998
[INFO] 2021-07-12 18:22:21,302 [run_pretraining.py:  512]:	********exe.run_168******* 
[INFO] 2021-07-12 18:22:22,369 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:22,370 [run_pretraining.py:  534]:	loss/total_loss, 10.112932205200195, 169
[INFO] 2021-07-12 18:22:22,370 [run_pretraining.py:  535]:	loss/mlm_loss, 10.112932205200195, 169
[INFO] 2021-07-12 18:22:22,370 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.679999854786729e-06, 169
[INFO] 2021-07-12 18:22:22,370 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 169
[INFO] 2021-07-12 18:22:22,370 [run_pretraining.py:  558]:	worker_index: 2, step: 169, cost: 10.112932, mlm loss: 10.112932, speed: 0.936545 steps/s, speed: 7.492364 samples/s, speed: 3836.090334 tokens/s, learning rate: 1.680e-06, loss_scalings: 26214.400391, pp_loss: 10.073626
[INFO] 2021-07-12 18:22:22,370 [run_pretraining.py:  512]:	********exe.run_169******* 
[INFO] 2021-07-12 18:22:23,439 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:23,440 [run_pretraining.py:  534]:	loss/total_loss, 10.220046997070312, 170
[INFO] 2021-07-12 18:22:23,440 [run_pretraining.py:  535]:	loss/mlm_loss, 10.220046997070312, 170
[INFO] 2021-07-12 18:22:23,440 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.68999986271956e-06, 170
[INFO] 2021-07-12 18:22:23,440 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 170
[INFO] 2021-07-12 18:22:23,440 [run_pretraining.py:  558]:	worker_index: 2, step: 170, cost: 10.220047, mlm loss: 10.220047, speed: 0.935089 steps/s, speed: 7.480715 samples/s, speed: 3830.125972 tokens/s, learning rate: 1.690e-06, loss_scalings: 26214.400391, pp_loss: 10.021110
[INFO] 2021-07-12 18:22:23,440 [run_pretraining.py:  512]:	********exe.run_170******* 
[INFO] 2021-07-12 18:22:24,489 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:24,489 [run_pretraining.py:  534]:	loss/total_loss, 9.991203308105469, 171
[INFO] 2021-07-12 18:22:24,489 [run_pretraining.py:  535]:	loss/mlm_loss, 9.991203308105469, 171
[INFO] 2021-07-12 18:22:24,490 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7000000980260666e-06, 171
[INFO] 2021-07-12 18:22:24,490 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 171
[INFO] 2021-07-12 18:22:24,490 [run_pretraining.py:  558]:	worker_index: 2, step: 171, cost: 9.991203, mlm loss: 9.991203, speed: 0.953384 steps/s, speed: 7.627073 samples/s, speed: 3905.061545 tokens/s, learning rate: 1.700e-06, loss_scalings: 26214.400391, pp_loss: 9.960703
[INFO] 2021-07-12 18:22:24,490 [run_pretraining.py:  512]:	********exe.run_171******* 
[INFO] 2021-07-12 18:22:25,539 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:25,539 [run_pretraining.py:  534]:	loss/total_loss, 9.902390480041504, 172
[INFO] 2021-07-12 18:22:25,539 [run_pretraining.py:  535]:	loss/mlm_loss, 9.902390480041504, 172
[INFO] 2021-07-12 18:22:25,539 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.70999999227206e-06, 172
[INFO] 2021-07-12 18:22:25,539 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 172
[INFO] 2021-07-12 18:22:25,539 [run_pretraining.py:  558]:	worker_index: 2, step: 172, cost: 9.902390, mlm loss: 9.902390, speed: 0.953153 steps/s, speed: 7.625224 samples/s, speed: 3904.114665 tokens/s, learning rate: 1.710e-06, loss_scalings: 26214.400391, pp_loss: 9.989311
[INFO] 2021-07-12 18:22:25,540 [run_pretraining.py:  512]:	********exe.run_172******* 
[INFO] 2021-07-12 18:22:26,598 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:26,598 [run_pretraining.py:  534]:	loss/total_loss, 9.928531646728516, 173
[INFO] 2021-07-12 18:22:26,599 [run_pretraining.py:  535]:	loss/mlm_loss, 9.928531646728516, 173
[INFO] 2021-07-12 18:22:26,599 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.720000000204891e-06, 173
[INFO] 2021-07-12 18:22:26,599 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 173
[INFO] 2021-07-12 18:22:26,599 [run_pretraining.py:  558]:	worker_index: 2, step: 173, cost: 9.928532, mlm loss: 9.928532, speed: 0.944517 steps/s, speed: 7.556139 samples/s, speed: 3868.743039 tokens/s, learning rate: 1.720e-06, loss_scalings: 26214.400391, pp_loss: 9.800774
[INFO] 2021-07-12 18:22:26,599 [run_pretraining.py:  512]:	********exe.run_173******* 
[INFO] 2021-07-12 18:22:52,557 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:52,557 [run_pretraining.py:  534]:	loss/total_loss, 9.868230819702148, 174
[INFO] 2021-07-12 18:22:52,557 [run_pretraining.py:  535]:	loss/mlm_loss, 9.868230819702148, 174
[INFO] 2021-07-12 18:22:52,558 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.730000008137722e-06, 174
[INFO] 2021-07-12 18:22:52,558 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 174
[INFO] 2021-07-12 18:22:52,558 [run_pretraining.py:  558]:	worker_index: 2, step: 174, cost: 9.868231, mlm loss: 9.868231, speed: 0.038523 steps/s, speed: 0.308186 samples/s, speed: 157.791179 tokens/s, learning rate: 1.730e-06, loss_scalings: 26214.400391, pp_loss: 8.791359
[INFO] 2021-07-12 18:22:52,558 [run_pretraining.py:  512]:	********exe.run_174******* 
[INFO] 2021-07-12 18:23:41,447 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:23:41,447 [run_pretraining.py:  534]:	loss/total_loss, 9.862947463989258, 175
[INFO] 2021-07-12 18:23:41,447 [run_pretraining.py:  535]:	loss/mlm_loss, 9.862947463989258, 175
[INFO] 2021-07-12 18:23:41,447 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.740000016070553e-06, 175
[INFO] 2021-07-12 18:23:41,447 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 175
[INFO] 2021-07-12 18:23:41,448 [run_pretraining.py:  558]:	worker_index: 2, step: 175, cost: 9.862947, mlm loss: 9.862947, speed: 0.020454 steps/s, speed: 0.163635 samples/s, speed: 83.781336 tokens/s, learning rate: 1.740e-06, loss_scalings: 26214.400391, pp_loss: 9.936090
[INFO] 2021-07-12 18:23:41,448 [run_pretraining.py:  512]:	********exe.run_175******* 
[INFO] 2021-07-12 18:23:42,429 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:23:42,430 [run_pretraining.py:  534]:	loss/total_loss, 9.675029754638672, 176
[INFO] 2021-07-12 18:23:42,430 [run_pretraining.py:  535]:	loss/mlm_loss, 9.675029754638672, 176
[INFO] 2021-07-12 18:23:42,430 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7499999103165464e-06, 176
[INFO] 2021-07-12 18:23:42,430 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 176
[INFO] 2021-07-12 18:23:42,430 [run_pretraining.py:  558]:	worker_index: 2, step: 176, cost: 9.675030, mlm loss: 9.675030, speed: 1.018305 steps/s, speed: 8.146441 samples/s, speed: 4170.977685 tokens/s, learning rate: 1.750e-06, loss_scalings: 26214.400391, pp_loss: 9.868256
[INFO] 2021-07-12 18:23:42,430 [run_pretraining.py:  512]:	********exe.run_176******* 
[INFO] 2021-07-12 18:23:43,396 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:23:43,403 [run_pretraining.py:  534]:	loss/total_loss, 10.146860122680664, 177
[INFO] 2021-07-12 18:23:43,407 [run_pretraining.py:  535]:	loss/mlm_loss, 10.146860122680664, 177
[INFO] 2021-07-12 18:23:43,409 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7599999182493775e-06, 177
[INFO] 2021-07-12 18:23:43,412 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 177
[INFO] 2021-07-12 18:23:43,413 [run_pretraining.py:  558]:	worker_index: 2, step: 177, cost: 10.146860, mlm loss: 10.146860, speed: 1.027985 steps/s, speed: 8.223882 samples/s, speed: 4210.627377 tokens/s, learning rate: 1.760e-06, loss_scalings: 26214.400391, pp_loss: 9.961666
[INFO] 2021-07-12 18:23:43,414 [run_pretraining.py:  512]:	********exe.run_177******* 
[INFO] 2021-07-12 18:23:44,365 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:23:44,366 [run_pretraining.py:  534]:	loss/total_loss, 9.764769554138184, 178
[INFO] 2021-07-12 18:23:44,366 [run_pretraining.py:  535]:	loss/mlm_loss, 9.764769554138184, 178
[INFO] 2021-07-12 18:23:44,366 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7699999261822086e-06, 178
[INFO] 2021-07-12 18:23:44,366 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 178
[INFO] 2021-07-12 18:23:44,366 [run_pretraining.py:  558]:	worker_index: 2, step: 178, cost: 9.764770, mlm loss: 9.764770, speed: 1.050644 steps/s, speed: 8.405156 samples/s, speed: 4303.439693 tokens/s, learning rate: 1.770e-06, loss_scalings: 26214.400391, pp_loss: 8.996402
[INFO] 2021-07-12 18:23:44,366 [run_pretraining.py:  512]:	********exe.run_178******* 
[INFO] 2021-07-12 18:23:45,420 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:23:45,420 [run_pretraining.py:  534]:	loss/total_loss, 10.109967231750488, 179
[INFO] 2021-07-12 18:23:45,420 [run_pretraining.py:  535]:	loss/mlm_loss, 10.109967231750488, 179
[INFO] 2021-07-12 18:23:45,420 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7799999341150397e-06, 179
[INFO] 2021-07-12 18:23:45,420 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 179
[INFO] 2021-07-12 18:23:45,420 [run_pretraining.py:  558]:	worker_index: 2, step: 179, cost: 10.109967, mlm loss: 10.109967, speed: 0.949084 steps/s, speed: 7.592675 samples/s, speed: 3887.449819 tokens/s, learning rate: 1.780e-06, loss_scalings: 26214.400391, pp_loss: 9.876058
[INFO] 2021-07-12 18:23:45,421 [run_pretraining.py:  512]:	********exe.run_179******* 
[INFO] 2021-07-12 18:23:46,484 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:23:46,484 [run_pretraining.py:  534]:	loss/total_loss, 9.96208381652832, 180
[INFO] 2021-07-12 18:23:46,485 [run_pretraining.py:  535]:	loss/mlm_loss, 9.96208381652832, 180
[INFO] 2021-07-12 18:23:46,485 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7899999420478707e-06, 180
[INFO] 2021-07-12 18:23:46,485 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 180
[INFO] 2021-07-12 18:23:46,485 [run_pretraining.py:  558]:	worker_index: 2, step: 180, cost: 9.962084, mlm loss: 9.962084, speed: 0.940059 steps/s, speed: 7.520469 samples/s, speed: 3850.480358 tokens/s, learning rate: 1.790e-06, loss_scalings: 26214.400391, pp_loss: 9.118296
[INFO] 2021-07-12 18:23:46,485 [run_pretraining.py:  512]:	********exe.run_180******* 
[INFO] 2021-07-12 18:24:11,804 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:24:11,804 [run_pretraining.py:  534]:	loss/total_loss, 10.021120071411133, 181
[INFO] 2021-07-12 18:24:11,804 [run_pretraining.py:  535]:	loss/mlm_loss, 10.021120071411133, 181
[INFO] 2021-07-12 18:24:11,804 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.799999836293864e-06, 181
[INFO] 2021-07-12 18:24:11,805 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 181
[INFO] 2021-07-12 18:24:11,805 [run_pretraining.py:  558]:	worker_index: 2, step: 181, cost: 10.021120, mlm loss: 10.021120, speed: 0.039496 steps/s, speed: 0.315967 samples/s, speed: 161.775231 tokens/s, learning rate: 1.800e-06, loss_scalings: 26214.400391, pp_loss: 9.955332
[INFO] 2021-07-12 18:24:11,805 [run_pretraining.py:  512]:	********exe.run_181******* 
[INFO] 2021-07-12 18:24:12,834 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:24:12,834 [run_pretraining.py:  534]:	loss/total_loss, 9.951160430908203, 182
[INFO] 2021-07-12 18:24:12,835 [run_pretraining.py:  535]:	loss/mlm_loss, 9.951160430908203, 182
[INFO] 2021-07-12 18:24:12,835 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8100000716003706e-06, 182
[INFO] 2021-07-12 18:24:12,835 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 182
[INFO] 2021-07-12 18:24:12,835 [run_pretraining.py:  558]:	worker_index: 2, step: 182, cost: 9.951160, mlm loss: 9.951160, speed: 0.971291 steps/s, speed: 7.770331 samples/s, speed: 3978.409250 tokens/s, learning rate: 1.810e-06, loss_scalings: 26214.400391, pp_loss: 9.919935
[INFO] 2021-07-12 18:24:12,835 [run_pretraining.py:  512]:	********exe.run_182******* 
[INFO] 2021-07-12 18:24:13,883 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:24:13,883 [run_pretraining.py:  534]:	loss/total_loss, 9.923238754272461, 183
[INFO] 2021-07-12 18:24:13,883 [run_pretraining.py:  535]:	loss/mlm_loss, 9.923238754272461, 183
[INFO] 2021-07-12 18:24:13,884 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8200000795332016e-06, 183
[INFO] 2021-07-12 18:24:13,884 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 183
[INFO] 2021-07-12 18:24:13,884 [run_pretraining.py:  558]:	worker_index: 2, step: 183, cost: 9.923239, mlm loss: 9.923239, speed: 0.953923 steps/s, speed: 7.631384 samples/s, speed: 3907.268572 tokens/s, learning rate: 1.820e-06, loss_scalings: 26214.400391, pp_loss: 9.969903
[INFO] 2021-07-12 18:24:13,884 [run_pretraining.py:  512]:	********exe.run_183******* 
[INFO] 2021-07-12 18:24:39,784 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:24:39,785 [run_pretraining.py:  534]:	loss/total_loss, 10.088679313659668, 184
[INFO] 2021-07-12 18:24:39,785 [run_pretraining.py:  535]:	loss/mlm_loss, 10.088679313659668, 184
[INFO] 2021-07-12 18:24:39,785 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.829999973779195e-06, 184
[INFO] 2021-07-12 18:24:39,785 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 184
[INFO] 2021-07-12 18:24:39,785 [run_pretraining.py:  558]:	worker_index: 2, step: 184, cost: 10.088679, mlm loss: 10.088679, speed: 0.038609 steps/s, speed: 0.308872 samples/s, speed: 158.142570 tokens/s, learning rate: 1.830e-06, loss_scalings: 26214.400391, pp_loss: 9.982827
[INFO] 2021-07-12 18:24:39,785 [run_pretraining.py:  512]:	********exe.run_184******* 
[INFO] 2021-07-12 18:24:40,762 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:24:40,762 [run_pretraining.py:  534]:	loss/total_loss, 9.942330360412598, 185
[INFO] 2021-07-12 18:24:40,762 [run_pretraining.py:  535]:	loss/mlm_loss, 9.942330360412598, 185
[INFO] 2021-07-12 18:24:40,763 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.839999981712026e-06, 185
[INFO] 2021-07-12 18:24:40,763 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 185
[INFO] 2021-07-12 18:24:40,763 [run_pretraining.py:  558]:	worker_index: 2, step: 185, cost: 9.942330, mlm loss: 9.942330, speed: 1.023340 steps/s, speed: 8.186717 samples/s, speed: 4191.599313 tokens/s, learning rate: 1.840e-06, loss_scalings: 26214.400391, pp_loss: 9.902343
[INFO] 2021-07-12 18:24:40,763 [run_pretraining.py:  512]:	********exe.run_185******* 
[INFO] 2021-07-12 18:24:41,721 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:24:41,721 [run_pretraining.py:  534]:	loss/total_loss, 10.138137817382812, 186
[INFO] 2021-07-12 18:24:41,721 [run_pretraining.py:  535]:	loss/mlm_loss, 10.138137817382812, 186
[INFO] 2021-07-12 18:24:41,722 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8499999896448571e-06, 186
[INFO] 2021-07-12 18:24:41,722 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 186
[INFO] 2021-07-12 18:24:41,722 [run_pretraining.py:  558]:	worker_index: 2, step: 186, cost: 10.138138, mlm loss: 10.138138, speed: 1.043392 steps/s, speed: 8.347137 samples/s, speed: 4273.734315 tokens/s, learning rate: 1.850e-06, loss_scalings: 26214.400391, pp_loss: 9.959693
[INFO] 2021-07-12 18:24:41,722 [run_pretraining.py:  512]:	********exe.run_186******* 
[INFO] 2021-07-12 18:24:42,675 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:24:42,676 [run_pretraining.py:  534]:	loss/total_loss, 9.97297477722168, 187
[INFO] 2021-07-12 18:24:42,676 [run_pretraining.py:  535]:	loss/mlm_loss, 9.97297477722168, 187
[INFO] 2021-07-12 18:24:42,676 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8599999975776882e-06, 187
[INFO] 2021-07-12 18:24:42,676 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 187
[INFO] 2021-07-12 18:24:42,676 [run_pretraining.py:  558]:	worker_index: 2, step: 187, cost: 9.972975, mlm loss: 9.972975, speed: 1.048698 steps/s, speed: 8.389587 samples/s, speed: 4295.468792 tokens/s, learning rate: 1.860e-06, loss_scalings: 26214.400391, pp_loss: 10.039579
[INFO] 2021-07-12 18:24:42,676 [run_pretraining.py:  512]:	********exe.run_187******* 
[INFO] 2021-07-12 18:25:06,931 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:25:06,931 [run_pretraining.py:  534]:	loss/total_loss, 10.054727554321289, 188
[INFO] 2021-07-12 18:25:06,931 [run_pretraining.py:  535]:	loss/mlm_loss, 10.054727554321289, 188
[INFO] 2021-07-12 18:25:06,931 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8699998918236815e-06, 188
[INFO] 2021-07-12 18:25:06,931 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 188
[INFO] 2021-07-12 18:25:06,931 [run_pretraining.py:  558]:	worker_index: 2, step: 188, cost: 10.054728, mlm loss: 10.054728, speed: 0.041229 steps/s, speed: 0.329830 samples/s, speed: 168.872936 tokens/s, learning rate: 1.870e-06, loss_scalings: 26214.400391, pp_loss: 9.954532
[INFO] 2021-07-12 18:25:06,932 [run_pretraining.py:  512]:	********exe.run_188******* 
[INFO] 2021-07-12 18:25:07,891 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:25:07,892 [run_pretraining.py:  534]:	loss/total_loss, 9.903087615966797, 189
[INFO] 2021-07-12 18:25:07,892 [run_pretraining.py:  535]:	loss/mlm_loss, 9.903087615966797, 189
[INFO] 2021-07-12 18:25:07,892 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8799998997565126e-06, 189
[INFO] 2021-07-12 18:25:07,892 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 189
[INFO] 2021-07-12 18:25:07,892 [run_pretraining.py:  558]:	worker_index: 2, step: 189, cost: 9.903088, mlm loss: 9.903088, speed: 1.041882 steps/s, speed: 8.335059 samples/s, speed: 4267.550418 tokens/s, learning rate: 1.880e-06, loss_scalings: 26214.400391, pp_loss: 8.964863
[INFO] 2021-07-12 18:25:07,892 [run_pretraining.py:  512]:	********exe.run_189******* 
[INFO] 2021-07-12 18:25:30,889 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:25:30,889 [run_pretraining.py:  534]:	loss/total_loss, 10.020679473876953, 190
[INFO] 2021-07-12 18:25:30,889 [run_pretraining.py:  535]:	loss/mlm_loss, 10.020679473876953, 190
[INFO] 2021-07-12 18:25:30,890 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8899999076893437e-06, 190
[INFO] 2021-07-12 18:25:30,890 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 190
[INFO] 2021-07-12 18:25:30,890 [run_pretraining.py:  558]:	worker_index: 2, step: 190, cost: 10.020679, mlm loss: 10.020679, speed: 0.043484 steps/s, speed: 0.347868 samples/s, speed: 178.108599 tokens/s, learning rate: 1.890e-06, loss_scalings: 26214.400391, pp_loss: 9.541109
[INFO] 2021-07-12 18:25:30,890 [run_pretraining.py:  512]:	********exe.run_190******* 
[INFO] 2021-07-12 18:25:31,865 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:25:31,866 [run_pretraining.py:  534]:	loss/total_loss, 10.014911651611328, 191
[INFO] 2021-07-12 18:25:31,866 [run_pretraining.py:  535]:	loss/mlm_loss, 10.014911651611328, 191
[INFO] 2021-07-12 18:25:31,866 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8999999156221747e-06, 191
[INFO] 2021-07-12 18:25:31,866 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 191
[INFO] 2021-07-12 18:25:31,866 [run_pretraining.py:  558]:	worker_index: 2, step: 191, cost: 10.014912, mlm loss: 10.014912, speed: 1.024620 steps/s, speed: 8.196957 samples/s, speed: 4196.841983 tokens/s, learning rate: 1.900e-06, loss_scalings: 26214.400391, pp_loss: 9.981041
[INFO] 2021-07-12 18:25:31,866 [run_pretraining.py:  512]:	********exe.run_191******* 
[INFO] 2021-07-12 18:25:32,817 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:25:32,817 [run_pretraining.py:  534]:	loss/total_loss, 9.93429946899414, 192
[INFO] 2021-07-12 18:25:32,817 [run_pretraining.py:  535]:	loss/mlm_loss, 9.93429946899414, 192
[INFO] 2021-07-12 18:25:32,817 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.909999809868168e-06, 192
[INFO] 2021-07-12 18:25:32,817 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 192
[INFO] 2021-07-12 18:25:32,818 [run_pretraining.py:  558]:	worker_index: 2, step: 192, cost: 9.934299, mlm loss: 9.934299, speed: 1.051899 steps/s, speed: 8.415194 samples/s, speed: 4308.579175 tokens/s, learning rate: 1.910e-06, loss_scalings: 26214.400391, pp_loss: 9.821343
[INFO] 2021-07-12 18:25:32,818 [run_pretraining.py:  512]:	********exe.run_192******* 
[INFO] 2021-07-12 18:25:58,163 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:25:58,164 [run_pretraining.py:  534]:	loss/total_loss, 9.830827713012695, 193
[INFO] 2021-07-12 18:25:58,164 [run_pretraining.py:  535]:	loss/mlm_loss, 9.830827713012695, 193
[INFO] 2021-07-12 18:25:58,164 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.919999931487837e-06, 193
[INFO] 2021-07-12 18:25:58,164 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 193
[INFO] 2021-07-12 18:25:58,164 [run_pretraining.py:  558]:	worker_index: 2, step: 193, cost: 9.830828, mlm loss: 9.830828, speed: 0.039454 steps/s, speed: 0.315632 samples/s, speed: 161.603329 tokens/s, learning rate: 1.920e-06, loss_scalings: 26214.400391, pp_loss: 9.772945
[INFO] 2021-07-12 18:25:58,164 [run_pretraining.py:  512]:	********exe.run_193******* 
[INFO] 2021-07-12 18:26:21,181 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:26:21,182 [run_pretraining.py:  534]:	loss/total_loss, 9.95158576965332, 194
[INFO] 2021-07-12 18:26:21,182 [run_pretraining.py:  535]:	loss/mlm_loss, 9.95158576965332, 194
[INFO] 2021-07-12 18:26:21,182 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9300000531075057e-06, 194
[INFO] 2021-07-12 18:26:21,182 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 194
[INFO] 2021-07-12 18:26:21,182 [run_pretraining.py:  558]:	worker_index: 2, step: 194, cost: 9.951586, mlm loss: 9.951586, speed: 0.043445 steps/s, speed: 0.347562 samples/s, speed: 177.951723 tokens/s, learning rate: 1.930e-06, loss_scalings: 26214.400391, pp_loss: 9.502119
[INFO] 2021-07-12 18:26:21,182 [run_pretraining.py:  512]:	********exe.run_194******* 
[INFO] 2021-07-12 18:26:22,138 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:26:22,139 [run_pretraining.py:  534]:	loss/total_loss, 9.929752349853516, 195
[INFO] 2021-07-12 18:26:22,139 [run_pretraining.py:  535]:	loss/mlm_loss, 9.929752349853516, 195
[INFO] 2021-07-12 18:26:22,139 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.939999947353499e-06, 195
[INFO] 2021-07-12 18:26:22,139 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 195
[INFO] 2021-07-12 18:26:22,139 [run_pretraining.py:  558]:	worker_index: 2, step: 195, cost: 9.929752, mlm loss: 9.929752, speed: 1.045670 steps/s, speed: 8.365363 samples/s, speed: 4283.065727 tokens/s, learning rate: 1.940e-06, loss_scalings: 26214.400391, pp_loss: 9.938612
[INFO] 2021-07-12 18:26:22,139 [run_pretraining.py:  512]:	********exe.run_195******* 
[INFO] 2021-07-12 18:26:23,100 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:26:23,101 [run_pretraining.py:  534]:	loss/total_loss, 9.713776588439941, 196
[INFO] 2021-07-12 18:26:23,101 [run_pretraining.py:  535]:	loss/mlm_loss, 9.713776588439941, 196
[INFO] 2021-07-12 18:26:23,101 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.950000068973168e-06, 196
[INFO] 2021-07-12 18:26:23,101 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 196
[INFO] 2021-07-12 18:26:23,101 [run_pretraining.py:  558]:	worker_index: 2, step: 196, cost: 9.713777, mlm loss: 9.713777, speed: 1.039956 steps/s, speed: 8.319644 samples/s, speed: 4259.657927 tokens/s, learning rate: 1.950e-06, loss_scalings: 26214.400391, pp_loss: 9.881034
[INFO] 2021-07-12 18:26:23,101 [run_pretraining.py:  512]:	********exe.run_196******* 
[INFO] 2021-07-12 18:26:24,063 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:26:24,064 [run_pretraining.py:  534]:	loss/total_loss, 9.953661918640137, 197
[INFO] 2021-07-12 18:26:24,064 [run_pretraining.py:  535]:	loss/mlm_loss, 9.953661918640137, 197
[INFO] 2021-07-12 18:26:24,064 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.959999963219161e-06, 197
[INFO] 2021-07-12 18:26:24,064 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 197
[INFO] 2021-07-12 18:26:24,064 [run_pretraining.py:  558]:	worker_index: 2, step: 197, cost: 9.953662, mlm loss: 9.953662, speed: 1.039423 steps/s, speed: 8.315381 samples/s, speed: 4257.474908 tokens/s, learning rate: 1.960e-06, loss_scalings: 26214.400391, pp_loss: 9.883722
[INFO] 2021-07-12 18:26:24,064 [run_pretraining.py:  512]:	********exe.run_197******* 
[INFO] 2021-07-12 18:26:25,026 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:26:25,027 [run_pretraining.py:  534]:	loss/total_loss, 5.295657634735107, 198
[INFO] 2021-07-12 18:26:25,027 [run_pretraining.py:  535]:	loss/mlm_loss, 5.295657634735107, 198
[INFO] 2021-07-12 18:26:25,027 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9699998574651545e-06, 198
[INFO] 2021-07-12 18:26:25,027 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 198
[INFO] 2021-07-12 18:26:25,027 [run_pretraining.py:  558]:	worker_index: 2, step: 198, cost: 5.295658, mlm loss: 5.295658, speed: 1.038828 steps/s, speed: 8.310623 samples/s, speed: 4255.039073 tokens/s, learning rate: 1.970e-06, loss_scalings: 26214.400391, pp_loss: 8.749477
[INFO] 2021-07-12 18:26:25,027 [run_pretraining.py:  512]:	********exe.run_198******* 
[INFO] 2021-07-12 18:27:15,711 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:27:15,712 [run_pretraining.py:  534]:	loss/total_loss, 9.870620727539062, 199
[INFO] 2021-07-12 18:27:15,712 [run_pretraining.py:  535]:	loss/mlm_loss, 9.870620727539062, 199
[INFO] 2021-07-12 18:27:15,712 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9799999790848233e-06, 199
[INFO] 2021-07-12 18:27:15,712 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 199
[INFO] 2021-07-12 18:27:15,712 [run_pretraining.py:  558]:	worker_index: 2, step: 199, cost: 9.870621, mlm loss: 9.870621, speed: 0.019730 steps/s, speed: 0.157840 samples/s, speed: 80.814074 tokens/s, learning rate: 1.980e-06, loss_scalings: 26214.400391, pp_loss: 9.954379
[INFO] 2021-07-12 18:27:15,712 [run_pretraining.py:  512]:	********exe.run_199******* 
[INFO] 2021-07-12 18:27:40,970 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:27:40,970 [run_pretraining.py:  534]:	loss/total_loss, 9.668193817138672, 200
[INFO] 2021-07-12 18:27:40,970 [run_pretraining.py:  535]:	loss/mlm_loss, 9.668193817138672, 200
[INFO] 2021-07-12 18:27:40,970 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9899998733308166e-06, 200
[INFO] 2021-07-12 18:27:40,971 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 200
[INFO] 2021-07-12 18:27:40,971 [run_pretraining.py:  558]:	worker_index: 2, step: 200, cost: 9.668194, mlm loss: 9.668194, speed: 0.039592 steps/s, speed: 0.316733 samples/s, speed: 162.167508 tokens/s, learning rate: 1.990e-06, loss_scalings: 26214.400391, pp_loss: 9.844855
[INFO] 2021-07-12 18:27:40,971 [run_pretraining.py:  512]:	********exe.run_200******* 
[INFO] 2021-07-12 18:28:05,990 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:05,991 [run_pretraining.py:  534]:	loss/total_loss, 9.741480827331543, 201
[INFO] 2021-07-12 18:28:05,991 [run_pretraining.py:  535]:	loss/mlm_loss, 9.741480827331543, 201
[INFO] 2021-07-12 18:28:05,991 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9999999949504854e-06, 201
[INFO] 2021-07-12 18:28:05,991 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 201
[INFO] 2021-07-12 18:28:05,991 [run_pretraining.py:  558]:	worker_index: 2, step: 201, cost: 9.741481, mlm loss: 9.741481, speed: 0.039968 steps/s, speed: 0.319742 samples/s, speed: 163.708113 tokens/s, learning rate: 2.000e-06, loss_scalings: 26214.400391, pp_loss: 9.885590
[INFO] 2021-07-12 18:28:05,991 [run_pretraining.py:  512]:	********exe.run_201******* 
[INFO] 2021-07-12 18:28:06,917 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:06,918 [run_pretraining.py:  534]:	loss/total_loss, 9.905625343322754, 202
[INFO] 2021-07-12 18:28:06,918 [run_pretraining.py:  535]:	loss/mlm_loss, 9.905625343322754, 202
[INFO] 2021-07-12 18:28:06,918 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0099998891964788e-06, 202
[INFO] 2021-07-12 18:28:06,918 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 202
[INFO] 2021-07-12 18:28:06,918 [run_pretraining.py:  558]:	worker_index: 2, step: 202, cost: 9.905625, mlm loss: 9.905625, speed: 1.080005 steps/s, speed: 8.640037 samples/s, speed: 4423.699153 tokens/s, learning rate: 2.010e-06, loss_scalings: 26214.400391, pp_loss: 9.905133
[INFO] 2021-07-12 18:28:06,918 [run_pretraining.py:  512]:	********exe.run_202******* 
[INFO] 2021-07-12 18:28:07,937 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:07,938 [run_pretraining.py:  534]:	loss/total_loss, 9.862564086914062, 203
[INFO] 2021-07-12 18:28:07,938 [run_pretraining.py:  535]:	loss/mlm_loss, 9.862564086914062, 203
[INFO] 2021-07-12 18:28:07,938 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.019999783442472e-06, 203
[INFO] 2021-07-12 18:28:07,938 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 203
[INFO] 2021-07-12 18:28:07,938 [run_pretraining.py:  558]:	worker_index: 2, step: 203, cost: 9.862564, mlm loss: 9.862564, speed: 0.980963 steps/s, speed: 7.847703 samples/s, speed: 4018.023988 tokens/s, learning rate: 2.020e-06, loss_scalings: 26214.400391, pp_loss: 9.898283
[INFO] 2021-07-12 18:28:07,938 [run_pretraining.py:  512]:	********exe.run_203******* 
[INFO] 2021-07-12 18:28:08,858 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:08,858 [run_pretraining.py:  534]:	loss/total_loss, 9.793456077575684, 204
[INFO] 2021-07-12 18:28:08,858 [run_pretraining.py:  535]:	loss/mlm_loss, 9.793456077575684, 204
[INFO] 2021-07-12 18:28:08,858 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0300001324358163e-06, 204
[INFO] 2021-07-12 18:28:08,858 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 204
[INFO] 2021-07-12 18:28:08,859 [run_pretraining.py:  558]:	worker_index: 2, step: 204, cost: 9.793456, mlm loss: 9.793456, speed: 1.086889 steps/s, speed: 8.695111 samples/s, speed: 4451.896653 tokens/s, learning rate: 2.030e-06, loss_scalings: 26214.400391, pp_loss: 9.788409
[INFO] 2021-07-12 18:28:08,859 [run_pretraining.py:  512]:	********exe.run_204******* 
[INFO] 2021-07-12 18:28:09,772 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:09,772 [run_pretraining.py:  534]:	loss/total_loss, 9.795381546020508, 205
[INFO] 2021-07-12 18:28:09,772 [run_pretraining.py:  535]:	loss/mlm_loss, 9.795381546020508, 205
[INFO] 2021-07-12 18:28:09,772 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0400000266818097e-06, 205
[INFO] 2021-07-12 18:28:09,772 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 205
[INFO] 2021-07-12 18:28:09,773 [run_pretraining.py:  558]:	worker_index: 2, step: 205, cost: 9.795382, mlm loss: 9.795382, speed: 1.094792 steps/s, speed: 8.758339 samples/s, speed: 4484.269617 tokens/s, learning rate: 2.040e-06, loss_scalings: 26214.400391, pp_loss: 9.835131
[INFO] 2021-07-12 18:28:09,773 [run_pretraining.py:  512]:	********exe.run_205******* 
[INFO] 2021-07-12 18:28:10,683 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:10,683 [run_pretraining.py:  534]:	loss/total_loss, 9.97593879699707, 206
[INFO] 2021-07-12 18:28:10,683 [run_pretraining.py:  535]:	loss/mlm_loss, 9.97593879699707, 206
[INFO] 2021-07-12 18:28:10,684 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.049999920927803e-06, 206
[INFO] 2021-07-12 18:28:10,684 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 206
[INFO] 2021-07-12 18:28:10,684 [run_pretraining.py:  558]:	worker_index: 2, step: 206, cost: 9.975939, mlm loss: 9.975939, speed: 1.098253 steps/s, speed: 8.786022 samples/s, speed: 4498.443125 tokens/s, learning rate: 2.050e-06, loss_scalings: 26214.400391, pp_loss: 9.847679
[INFO] 2021-07-12 18:28:10,684 [run_pretraining.py:  512]:	********exe.run_206******* 
[INFO] 2021-07-12 18:28:11,588 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:11,589 [run_pretraining.py:  534]:	loss/total_loss, 9.751205444335938, 207
[INFO] 2021-07-12 18:28:11,589 [run_pretraining.py:  535]:	loss/mlm_loss, 9.751205444335938, 207
[INFO] 2021-07-12 18:28:11,589 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.060000042547472e-06, 207
[INFO] 2021-07-12 18:28:11,589 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 207
[INFO] 2021-07-12 18:28:11,589 [run_pretraining.py:  558]:	worker_index: 2, step: 207, cost: 9.751205, mlm loss: 9.751205, speed: 1.105507 steps/s, speed: 8.844057 samples/s, speed: 4528.157204 tokens/s, learning rate: 2.060e-06, loss_scalings: 26214.400391, pp_loss: 9.817622
[INFO] 2021-07-12 18:28:11,589 [run_pretraining.py:  512]:	********exe.run_207******* 
[INFO] 2021-07-12 18:28:12,503 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:12,504 [run_pretraining.py:  534]:	loss/total_loss, 10.02884578704834, 208
[INFO] 2021-07-12 18:28:12,504 [run_pretraining.py:  535]:	loss/mlm_loss, 10.02884578704834, 208
[INFO] 2021-07-12 18:28:12,504 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.069999936793465e-06, 208
[INFO] 2021-07-12 18:28:12,504 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 208
[INFO] 2021-07-12 18:28:12,504 [run_pretraining.py:  558]:	worker_index: 2, step: 208, cost: 10.028846, mlm loss: 10.028846, speed: 1.093629 steps/s, speed: 8.749033 samples/s, speed: 4479.504983 tokens/s, learning rate: 2.070e-06, loss_scalings: 26214.400391, pp_loss: 9.845547
[INFO] 2021-07-12 18:28:12,504 [run_pretraining.py:  512]:	********exe.run_208******* 
[INFO] 2021-07-12 18:28:13,441 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:13,441 [run_pretraining.py:  534]:	loss/total_loss, 9.810038566589355, 209
[INFO] 2021-07-12 18:28:13,441 [run_pretraining.py:  535]:	loss/mlm_loss, 9.810038566589355, 209
[INFO] 2021-07-12 18:28:13,442 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.080000058413134e-06, 209
[INFO] 2021-07-12 18:28:13,442 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 209
[INFO] 2021-07-12 18:28:13,442 [run_pretraining.py:  558]:	worker_index: 2, step: 209, cost: 9.810039, mlm loss: 9.810039, speed: 1.067030 steps/s, speed: 8.536240 samples/s, speed: 4370.554951 tokens/s, learning rate: 2.080e-06, loss_scalings: 26214.400391, pp_loss: 9.774968
[INFO] 2021-07-12 18:28:13,442 [run_pretraining.py:  512]:	********exe.run_209******* 
[INFO] 2021-07-12 18:28:14,353 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:14,354 [run_pretraining.py:  534]:	loss/total_loss, 9.794278144836426, 210
[INFO] 2021-07-12 18:28:14,354 [run_pretraining.py:  535]:	loss/mlm_loss, 9.794278144836426, 210
[INFO] 2021-07-12 18:28:14,354 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0899999526591273e-06, 210
[INFO] 2021-07-12 18:28:14,354 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 210
[INFO] 2021-07-12 18:28:14,354 [run_pretraining.py:  558]:	worker_index: 2, step: 210, cost: 9.794278, mlm loss: 9.794278, speed: 1.096596 steps/s, speed: 8.772770 samples/s, speed: 4491.658128 tokens/s, learning rate: 2.090e-06, loss_scalings: 26214.400391, pp_loss: 9.908601
[INFO] 2021-07-12 18:28:14,354 [run_pretraining.py:  512]:	********exe.run_210******* 
[INFO] 2021-07-12 18:28:15,262 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:15,263 [run_pretraining.py:  534]:	loss/total_loss, 9.51151180267334, 211
[INFO] 2021-07-12 18:28:15,263 [run_pretraining.py:  535]:	loss/mlm_loss, 9.51151180267334, 211
[INFO] 2021-07-12 18:28:15,263 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0999998469051206e-06, 211
[INFO] 2021-07-12 18:28:15,263 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 211
[INFO] 2021-07-12 18:28:15,263 [run_pretraining.py:  558]:	worker_index: 2, step: 211, cost: 9.511512, mlm loss: 9.511512, speed: 1.100778 steps/s, speed: 8.806223 samples/s, speed: 4508.786344 tokens/s, learning rate: 2.100e-06, loss_scalings: 26214.400391, pp_loss: 9.764735
[INFO] 2021-07-12 18:28:15,263 [run_pretraining.py:  512]:	********exe.run_211******* 
[INFO] 2021-07-12 18:28:16,174 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:16,175 [run_pretraining.py:  534]:	loss/total_loss, 9.674503326416016, 212
[INFO] 2021-07-12 18:28:16,175 [run_pretraining.py:  535]:	loss/mlm_loss, 9.674503326416016, 212
[INFO] 2021-07-12 18:28:16,175 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1099999685247894e-06, 212
[INFO] 2021-07-12 18:28:16,175 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 212
[INFO] 2021-07-12 18:28:16,175 [run_pretraining.py:  558]:	worker_index: 2, step: 212, cost: 9.674503, mlm loss: 9.674503, speed: 1.097528 steps/s, speed: 8.780224 samples/s, speed: 4495.474447 tokens/s, learning rate: 2.110e-06, loss_scalings: 26214.400391, pp_loss: 9.878990
[INFO] 2021-07-12 18:28:16,175 [run_pretraining.py:  512]:	********exe.run_212******* 
[INFO] 2021-07-12 18:28:17,078 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:17,079 [run_pretraining.py:  534]:	loss/total_loss, 9.780691146850586, 213
[INFO] 2021-07-12 18:28:17,079 [run_pretraining.py:  535]:	loss/mlm_loss, 9.780691146850586, 213
[INFO] 2021-07-12 18:28:17,079 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1199998627707828e-06, 213
[INFO] 2021-07-12 18:28:17,079 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 213
[INFO] 2021-07-12 18:28:17,079 [run_pretraining.py:  558]:	worker_index: 2, step: 213, cost: 9.780691, mlm loss: 9.780691, speed: 1.106930 steps/s, speed: 8.855440 samples/s, speed: 4533.985405 tokens/s, learning rate: 2.120e-06, loss_scalings: 26214.400391, pp_loss: 9.817982
[INFO] 2021-07-12 18:28:17,079 [run_pretraining.py:  512]:	********exe.run_213******* 
[INFO] 2021-07-12 18:28:17,988 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:17,989 [run_pretraining.py:  534]:	loss/total_loss, 9.751974105834961, 214
[INFO] 2021-07-12 18:28:17,989 [run_pretraining.py:  535]:	loss/mlm_loss, 9.751974105834961, 214
[INFO] 2021-07-12 18:28:17,989 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.129999757016776e-06, 214
[INFO] 2021-07-12 18:28:17,989 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 214
[INFO] 2021-07-12 18:28:17,989 [run_pretraining.py:  558]:	worker_index: 2, step: 214, cost: 9.751974, mlm loss: 9.751974, speed: 1.099277 steps/s, speed: 8.794212 samples/s, speed: 4502.636784 tokens/s, learning rate: 2.130e-06, loss_scalings: 26214.400391, pp_loss: 9.840553
[INFO] 2021-07-12 18:28:17,989 [run_pretraining.py:  512]:	********exe.run_214******* 
[INFO] 2021-07-12 18:28:18,900 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:18,901 [run_pretraining.py:  534]:	loss/total_loss, 9.440608024597168, 215
[INFO] 2021-07-12 18:28:18,901 [run_pretraining.py:  535]:	loss/mlm_loss, 9.440608024597168, 215
[INFO] 2021-07-12 18:28:18,901 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1400001060101204e-06, 215
[INFO] 2021-07-12 18:28:18,901 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 215
[INFO] 2021-07-12 18:28:18,901 [run_pretraining.py:  558]:	worker_index: 2, step: 215, cost: 9.440608, mlm loss: 9.440608, speed: 1.097204 steps/s, speed: 8.777628 samples/s, speed: 4494.145581 tokens/s, learning rate: 2.140e-06, loss_scalings: 26214.400391, pp_loss: 9.708472
[INFO] 2021-07-12 18:28:18,901 [run_pretraining.py:  512]:	********exe.run_215******* 
[INFO] 2021-07-12 18:28:19,810 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:19,811 [run_pretraining.py:  534]:	loss/total_loss, 9.724733352661133, 216
[INFO] 2021-07-12 18:28:19,811 [run_pretraining.py:  535]:	loss/mlm_loss, 9.724733352661133, 216
[INFO] 2021-07-12 18:28:19,811 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1500000002561137e-06, 216
[INFO] 2021-07-12 18:28:19,811 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 216
[INFO] 2021-07-12 18:28:19,811 [run_pretraining.py:  558]:	worker_index: 2, step: 216, cost: 9.724733, mlm loss: 9.724733, speed: 1.099996 steps/s, speed: 8.799971 samples/s, speed: 4505.585391 tokens/s, learning rate: 2.150e-06, loss_scalings: 26214.400391, pp_loss: 9.766884
[INFO] 2021-07-12 18:28:19,811 [run_pretraining.py:  512]:	********exe.run_216******* 
[INFO] 2021-07-12 18:28:20,721 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:20,721 [run_pretraining.py:  534]:	loss/total_loss, 9.991362571716309, 217
[INFO] 2021-07-12 18:28:20,721 [run_pretraining.py:  535]:	loss/mlm_loss, 9.991362571716309, 217
[INFO] 2021-07-12 18:28:20,721 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.159999894502107e-06, 217
[INFO] 2021-07-12 18:28:20,721 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 217
[INFO] 2021-07-12 18:28:20,721 [run_pretraining.py:  558]:	worker_index: 2, step: 217, cost: 9.991363, mlm loss: 9.991363, speed: 1.098989 steps/s, speed: 8.791913 samples/s, speed: 4501.459365 tokens/s, learning rate: 2.160e-06, loss_scalings: 26214.400391, pp_loss: 9.727760
[INFO] 2021-07-12 18:28:20,722 [run_pretraining.py:  512]:	********exe.run_217******* 
[INFO] 2021-07-12 18:28:46,546 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:46,547 [run_pretraining.py:  534]:	loss/total_loss, 9.833831787109375, 218
[INFO] 2021-07-12 18:28:46,547 [run_pretraining.py:  535]:	loss/mlm_loss, 9.833831787109375, 218
[INFO] 2021-07-12 18:28:46,547 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.170000016121776e-06, 218
[INFO] 2021-07-12 18:28:46,547 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 218
[INFO] 2021-07-12 18:28:46,547 [run_pretraining.py:  558]:	worker_index: 2, step: 218, cost: 9.833832, mlm loss: 9.833832, speed: 0.038722 steps/s, speed: 0.309777 samples/s, speed: 158.605570 tokens/s, learning rate: 2.170e-06, loss_scalings: 26214.400391, pp_loss: 9.730017
[INFO] 2021-07-12 18:28:46,547 [run_pretraining.py:  512]:	********exe.run_218******* 
[INFO] 2021-07-12 18:28:47,460 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:47,461 [run_pretraining.py:  534]:	loss/total_loss, 9.972526550292969, 219
[INFO] 2021-07-12 18:28:47,461 [run_pretraining.py:  535]:	loss/mlm_loss, 9.972526550292969, 219
[INFO] 2021-07-12 18:28:47,461 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.179999910367769e-06, 219
[INFO] 2021-07-12 18:28:47,461 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 219
[INFO] 2021-07-12 18:28:47,461 [run_pretraining.py:  558]:	worker_index: 2, step: 219, cost: 9.972527, mlm loss: 9.972527, speed: 1.095166 steps/s, speed: 8.761330 samples/s, speed: 4485.801126 tokens/s, learning rate: 2.180e-06, loss_scalings: 26214.400391, pp_loss: 9.774761
[INFO] 2021-07-12 18:28:47,461 [run_pretraining.py:  512]:	********exe.run_219******* 
[INFO] 2021-07-12 18:28:48,368 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:48,368 [run_pretraining.py:  534]:	loss/total_loss, 9.75101375579834, 220
[INFO] 2021-07-12 18:28:48,369 [run_pretraining.py:  535]:	loss/mlm_loss, 9.75101375579834, 220
[INFO] 2021-07-12 18:28:48,369 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.190000031987438e-06, 220
[INFO] 2021-07-12 18:28:48,369 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 220
[INFO] 2021-07-12 18:28:48,369 [run_pretraining.py:  558]:	worker_index: 2, step: 220, cost: 9.751014, mlm loss: 9.751014, speed: 1.102166 steps/s, speed: 8.817329 samples/s, speed: 4514.472222 tokens/s, learning rate: 2.190e-06, loss_scalings: 26214.400391, pp_loss: 9.770392
[INFO] 2021-07-12 18:28:48,369 [run_pretraining.py:  512]:	********exe.run_220******* 
[INFO] 2021-07-12 18:28:49,277 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:49,277 [run_pretraining.py:  534]:	loss/total_loss, 9.828079223632812, 221
[INFO] 2021-07-12 18:28:49,277 [run_pretraining.py:  535]:	loss/mlm_loss, 9.828079223632812, 221
[INFO] 2021-07-12 18:28:49,278 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1999999262334313e-06, 221
[INFO] 2021-07-12 18:28:49,278 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 221
[INFO] 2021-07-12 18:28:49,278 [run_pretraining.py:  558]:	worker_index: 2, step: 221, cost: 9.828079, mlm loss: 9.828079, speed: 1.100924 steps/s, speed: 8.807391 samples/s, speed: 4509.383996 tokens/s, learning rate: 2.200e-06, loss_scalings: 26214.400391, pp_loss: 9.696037
[INFO] 2021-07-12 18:28:49,278 [run_pretraining.py:  512]:	********exe.run_221******* 
[INFO] 2021-07-12 18:28:50,190 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:50,190 [run_pretraining.py:  534]:	loss/total_loss, 9.439648628234863, 222
[INFO] 2021-07-12 18:28:50,190 [run_pretraining.py:  535]:	loss/mlm_loss, 9.439648628234863, 222
[INFO] 2021-07-12 18:28:50,190 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2099998204794247e-06, 222
[INFO] 2021-07-12 18:28:50,190 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 222
[INFO] 2021-07-12 18:28:50,190 [run_pretraining.py:  558]:	worker_index: 2, step: 222, cost: 9.439649, mlm loss: 9.439649, speed: 1.096295 steps/s, speed: 8.770358 samples/s, speed: 4490.423063 tokens/s, learning rate: 2.210e-06, loss_scalings: 26214.400391, pp_loss: 9.638648
[INFO] 2021-07-12 18:28:50,191 [run_pretraining.py:  512]:	********exe.run_222******* 
[INFO] 2021-07-12 18:28:51,094 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:51,095 [run_pretraining.py:  534]:	loss/total_loss, 9.708891868591309, 223
[INFO] 2021-07-12 18:28:51,095 [run_pretraining.py:  535]:	loss/mlm_loss, 9.708891868591309, 223
[INFO] 2021-07-12 18:28:51,095 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2199999420990935e-06, 223
[INFO] 2021-07-12 18:28:51,095 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 223
[INFO] 2021-07-12 18:28:51,095 [run_pretraining.py:  558]:	worker_index: 2, step: 223, cost: 9.708892, mlm loss: 9.708892, speed: 1.105902 steps/s, speed: 8.847214 samples/s, speed: 4529.773782 tokens/s, learning rate: 2.220e-06, loss_scalings: 26214.400391, pp_loss: 9.843925
[INFO] 2021-07-12 18:28:51,095 [run_pretraining.py:  512]:	********exe.run_223******* 
[INFO] 2021-07-12 18:28:52,014 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:52,014 [run_pretraining.py:  534]:	loss/total_loss, 5.3963623046875, 224
[INFO] 2021-07-12 18:28:52,014 [run_pretraining.py:  535]:	loss/mlm_loss, 5.3963623046875, 224
[INFO] 2021-07-12 18:28:52,014 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.229999836345087e-06, 224
[INFO] 2021-07-12 18:28:52,014 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 224
[INFO] 2021-07-12 18:28:52,015 [run_pretraining.py:  558]:	worker_index: 2, step: 224, cost: 5.396362, mlm loss: 5.396362, speed: 1.088586 steps/s, speed: 8.708689 samples/s, speed: 4458.848945 tokens/s, learning rate: 2.230e-06, loss_scalings: 26214.400391, pp_loss: 8.636688
[INFO] 2021-07-12 18:28:52,015 [run_pretraining.py:  512]:	********exe.run_224******* 
[INFO] 2021-07-12 18:28:52,922 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:52,923 [run_pretraining.py:  534]:	loss/total_loss, 9.70832347869873, 225
[INFO] 2021-07-12 18:28:52,923 [run_pretraining.py:  535]:	loss/mlm_loss, 9.70832347869873, 225
[INFO] 2021-07-12 18:28:52,923 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2399999579647556e-06, 225
[INFO] 2021-07-12 18:28:52,923 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 225
[INFO] 2021-07-12 18:28:52,923 [run_pretraining.py:  558]:	worker_index: 2, step: 225, cost: 9.708323, mlm loss: 9.708323, speed: 1.101153 steps/s, speed: 8.809224 samples/s, speed: 4510.322807 tokens/s, learning rate: 2.240e-06, loss_scalings: 26214.400391, pp_loss: 9.706889
[INFO] 2021-07-12 18:28:52,923 [run_pretraining.py:  512]:	********exe.run_225******* 
[INFO] 2021-07-12 18:28:53,843 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:53,843 [run_pretraining.py:  534]:	loss/total_loss, 9.616698265075684, 226
[INFO] 2021-07-12 18:28:53,844 [run_pretraining.py:  535]:	loss/mlm_loss, 9.616698265075684, 226
[INFO] 2021-07-12 18:28:53,844 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2500000795844244e-06, 226
[INFO] 2021-07-12 18:28:53,844 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 226
[INFO] 2021-07-12 18:28:53,844 [run_pretraining.py:  558]:	worker_index: 2, step: 226, cost: 9.616698, mlm loss: 9.616698, speed: 1.087095 steps/s, speed: 8.696763 samples/s, speed: 4452.742432 tokens/s, learning rate: 2.250e-06, loss_scalings: 26214.400391, pp_loss: 9.761266
[INFO] 2021-07-12 18:28:53,844 [run_pretraining.py:  512]:	********exe.run_226******* 
[INFO] 2021-07-12 18:28:54,749 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:54,750 [run_pretraining.py:  534]:	loss/total_loss, 9.670507431030273, 227
[INFO] 2021-07-12 18:28:54,750 [run_pretraining.py:  535]:	loss/mlm_loss, 9.670507431030273, 227
[INFO] 2021-07-12 18:28:54,750 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2599999738304177e-06, 227
[INFO] 2021-07-12 18:28:54,750 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 227
[INFO] 2021-07-12 18:28:54,750 [run_pretraining.py:  558]:	worker_index: 2, step: 227, cost: 9.670507, mlm loss: 9.670507, speed: 1.104448 steps/s, speed: 8.835582 samples/s, speed: 4523.818212 tokens/s, learning rate: 2.260e-06, loss_scalings: 26214.400391, pp_loss: 9.744972
[INFO] 2021-07-12 18:28:54,750 [run_pretraining.py:  512]:	********exe.run_227******* 
[INFO] 2021-07-12 18:28:55,655 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:55,656 [run_pretraining.py:  534]:	loss/total_loss, 9.69576644897461, 228
[INFO] 2021-07-12 18:28:55,656 [run_pretraining.py:  535]:	loss/mlm_loss, 9.69576644897461, 228
[INFO] 2021-07-12 18:28:55,656 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2700000954500865e-06, 228
[INFO] 2021-07-12 18:28:55,656 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 228
[INFO] 2021-07-12 18:28:55,656 [run_pretraining.py:  558]:	worker_index: 2, step: 228, cost: 9.695766, mlm loss: 9.695766, speed: 1.104253 steps/s, speed: 8.834026 samples/s, speed: 4523.021429 tokens/s, learning rate: 2.270e-06, loss_scalings: 26214.400391, pp_loss: 9.728854
[INFO] 2021-07-12 18:28:55,656 [run_pretraining.py:  512]:	********exe.run_228******* 
[INFO] 2021-07-12 18:28:56,557 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:56,558 [run_pretraining.py:  534]:	loss/total_loss, 9.591347694396973, 229
[INFO] 2021-07-12 18:28:56,558 [run_pretraining.py:  535]:	loss/mlm_loss, 9.591347694396973, 229
[INFO] 2021-07-12 18:28:56,558 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.27999998969608e-06, 229
[INFO] 2021-07-12 18:28:56,558 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 229
[INFO] 2021-07-12 18:28:56,558 [run_pretraining.py:  558]:	worker_index: 2, step: 229, cost: 9.591348, mlm loss: 9.591348, speed: 1.109207 steps/s, speed: 8.873653 samples/s, speed: 4543.310317 tokens/s, learning rate: 2.280e-06, loss_scalings: 26214.400391, pp_loss: 9.702878
[INFO] 2021-07-12 18:28:56,558 [run_pretraining.py:  512]:	********exe.run_229******* 
[INFO] 2021-07-12 18:28:57,470 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:57,471 [run_pretraining.py:  534]:	loss/total_loss, 9.576539993286133, 230
[INFO] 2021-07-12 18:28:57,471 [run_pretraining.py:  535]:	loss/mlm_loss, 9.576539993286133, 230
[INFO] 2021-07-12 18:28:57,471 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.289999883942073e-06, 230
[INFO] 2021-07-12 18:28:57,471 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 230
[INFO] 2021-07-12 18:28:57,471 [run_pretraining.py:  558]:	worker_index: 2, step: 230, cost: 9.576540, mlm loss: 9.576540, speed: 1.096017 steps/s, speed: 8.768137 samples/s, speed: 4489.286042 tokens/s, learning rate: 2.290e-06, loss_scalings: 26214.400391, pp_loss: 9.537710
[INFO] 2021-07-12 18:28:57,471 [run_pretraining.py:  512]:	********exe.run_230******* 
[INFO] 2021-07-12 18:28:58,380 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:58,381 [run_pretraining.py:  534]:	loss/total_loss, 9.917226791381836, 231
[INFO] 2021-07-12 18:28:58,381 [run_pretraining.py:  535]:	loss/mlm_loss, 9.917226791381836, 231
[INFO] 2021-07-12 18:28:58,381 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.300000005561742e-06, 231
[INFO] 2021-07-12 18:28:58,381 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 231
[INFO] 2021-07-12 18:28:58,381 [run_pretraining.py:  558]:	worker_index: 2, step: 231, cost: 9.917227, mlm loss: 9.917227, speed: 1.099970 steps/s, speed: 8.799761 samples/s, speed: 4505.477865 tokens/s, learning rate: 2.300e-06, loss_scalings: 26214.400391, pp_loss: 9.741693
[INFO] 2021-07-12 18:28:58,381 [run_pretraining.py:  512]:	********exe.run_231******* 
[INFO] 2021-07-12 18:28:59,294 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:59,294 [run_pretraining.py:  534]:	loss/total_loss, 9.717802047729492, 232
[INFO] 2021-07-12 18:28:59,294 [run_pretraining.py:  535]:	loss/mlm_loss, 9.717802047729492, 232
[INFO] 2021-07-12 18:28:59,295 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3099998998077353e-06, 232
[INFO] 2021-07-12 18:28:59,295 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 232
[INFO] 2021-07-12 18:28:59,295 [run_pretraining.py:  558]:	worker_index: 2, step: 232, cost: 9.717802, mlm loss: 9.717802, speed: 1.095079 steps/s, speed: 8.760628 samples/s, speed: 4485.441572 tokens/s, learning rate: 2.310e-06, loss_scalings: 26214.400391, pp_loss: 9.808466
[INFO] 2021-07-12 18:28:59,295 [run_pretraining.py:  512]:	********exe.run_232******* 
[INFO] 2021-07-12 18:29:00,208 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:00,208 [run_pretraining.py:  534]:	loss/total_loss, 9.956939697265625, 233
[INFO] 2021-07-12 18:29:00,208 [run_pretraining.py:  535]:	loss/mlm_loss, 9.956939697265625, 233
[INFO] 2021-07-12 18:29:00,208 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.320000021427404e-06, 233
[INFO] 2021-07-12 18:29:00,208 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 233
[INFO] 2021-07-12 18:29:00,208 [run_pretraining.py:  558]:	worker_index: 2, step: 233, cost: 9.956940, mlm loss: 9.956940, speed: 1.095172 steps/s, speed: 8.761374 samples/s, speed: 4485.823380 tokens/s, learning rate: 2.320e-06, loss_scalings: 26214.400391, pp_loss: 9.744595
[INFO] 2021-07-12 18:29:00,208 [run_pretraining.py:  512]:	********exe.run_233******* 
[INFO] 2021-07-12 18:29:01,114 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:01,115 [run_pretraining.py:  534]:	loss/total_loss, 9.647896766662598, 234
[INFO] 2021-07-12 18:29:01,115 [run_pretraining.py:  535]:	loss/mlm_loss, 9.647896766662598, 234
[INFO] 2021-07-12 18:29:01,115 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3299999156733975e-06, 234
[INFO] 2021-07-12 18:29:01,115 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 234
[INFO] 2021-07-12 18:29:01,115 [run_pretraining.py:  558]:	worker_index: 2, step: 234, cost: 9.647897, mlm loss: 9.647897, speed: 1.103790 steps/s, speed: 8.830323 samples/s, speed: 4521.125286 tokens/s, learning rate: 2.330e-06, loss_scalings: 26214.400391, pp_loss: 9.696092
[INFO] 2021-07-12 18:29:01,115 [run_pretraining.py:  512]:	********exe.run_234******* 
[INFO] 2021-07-12 18:29:02,017 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:02,017 [run_pretraining.py:  534]:	loss/total_loss, 9.72034740447998, 235
[INFO] 2021-07-12 18:29:02,017 [run_pretraining.py:  535]:	loss/mlm_loss, 9.72034740447998, 235
[INFO] 2021-07-12 18:29:02,017 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.339999809919391e-06, 235
[INFO] 2021-07-12 18:29:02,017 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 235
[INFO] 2021-07-12 18:29:02,017 [run_pretraining.py:  558]:	worker_index: 2, step: 235, cost: 9.720347, mlm loss: 9.720347, speed: 1.108851 steps/s, speed: 8.870807 samples/s, speed: 4541.853361 tokens/s, learning rate: 2.340e-06, loss_scalings: 26214.400391, pp_loss: 9.794412
[INFO] 2021-07-12 18:29:02,017 [run_pretraining.py:  512]:	********exe.run_235******* 
[INFO] 2021-07-12 18:29:02,930 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:02,931 [run_pretraining.py:  534]:	loss/total_loss, 9.558878898620605, 236
[INFO] 2021-07-12 18:29:02,931 [run_pretraining.py:  535]:	loss/mlm_loss, 9.558878898620605, 236
[INFO] 2021-07-12 18:29:02,931 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3499999315390596e-06, 236
[INFO] 2021-07-12 18:29:02,931 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 236
[INFO] 2021-07-12 18:29:02,931 [run_pretraining.py:  558]:	worker_index: 2, step: 236, cost: 9.558879, mlm loss: 9.558879, speed: 1.095039 steps/s, speed: 8.760312 samples/s, speed: 4485.279968 tokens/s, learning rate: 2.350e-06, loss_scalings: 26214.400391, pp_loss: 9.633696
[INFO] 2021-07-12 18:29:02,931 [run_pretraining.py:  512]:	********exe.run_236******* 
[INFO] 2021-07-12 18:29:03,856 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:03,856 [run_pretraining.py:  534]:	loss/total_loss, 9.444860458374023, 237
[INFO] 2021-07-12 18:29:03,857 [run_pretraining.py:  535]:	loss/mlm_loss, 9.444860458374023, 237
[INFO] 2021-07-12 18:29:03,857 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3600000531587284e-06, 237
[INFO] 2021-07-12 18:29:03,857 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 237
[INFO] 2021-07-12 18:29:03,857 [run_pretraining.py:  558]:	worker_index: 2, step: 237, cost: 9.444860, mlm loss: 9.444860, speed: 1.081049 steps/s, speed: 8.648391 samples/s, speed: 4427.975944 tokens/s, learning rate: 2.360e-06, loss_scalings: 26214.400391, pp_loss: 9.646706
[INFO] 2021-07-12 18:29:03,857 [run_pretraining.py:  512]:	********exe.run_237******* 
[INFO] 2021-07-12 18:29:04,762 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:04,762 [run_pretraining.py:  534]:	loss/total_loss, 9.550779342651367, 238
[INFO] 2021-07-12 18:29:04,763 [run_pretraining.py:  535]:	loss/mlm_loss, 9.550779342651367, 238
[INFO] 2021-07-12 18:29:04,763 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3699999474047218e-06, 238
[INFO] 2021-07-12 18:29:04,763 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 238
[INFO] 2021-07-12 18:29:04,763 [run_pretraining.py:  558]:	worker_index: 2, step: 238, cost: 9.550779, mlm loss: 9.550779, speed: 1.104530 steps/s, speed: 8.836243 samples/s, speed: 4524.156542 tokens/s, learning rate: 2.370e-06, loss_scalings: 26214.400391, pp_loss: 9.706118
[INFO] 2021-07-12 18:29:04,763 [run_pretraining.py:  512]:	********exe.run_238******* 
[INFO] 2021-07-12 18:29:27,914 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:27,914 [run_pretraining.py:  534]:	loss/total_loss, 9.551873207092285, 239
[INFO] 2021-07-12 18:29:27,915 [run_pretraining.py:  535]:	loss/mlm_loss, 9.551873207092285, 239
[INFO] 2021-07-12 18:29:27,915 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3800000690243905e-06, 239
[INFO] 2021-07-12 18:29:27,915 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 239
[INFO] 2021-07-12 18:29:27,915 [run_pretraining.py:  558]:	worker_index: 2, step: 239, cost: 9.551873, mlm loss: 9.551873, speed: 0.043194 steps/s, speed: 0.345551 samples/s, speed: 176.922136 tokens/s, learning rate: 2.380e-06, loss_scalings: 26214.400391, pp_loss: 9.709621
[INFO] 2021-07-12 18:29:27,915 [run_pretraining.py:  512]:	********exe.run_239******* 
[INFO] 2021-07-12 18:29:28,820 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:28,821 [run_pretraining.py:  534]:	loss/total_loss, 9.489433288574219, 240
[INFO] 2021-07-12 18:29:28,821 [run_pretraining.py:  535]:	loss/mlm_loss, 9.489433288574219, 240
[INFO] 2021-07-12 18:29:28,821 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.389999963270384e-06, 240
[INFO] 2021-07-12 18:29:28,821 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 240
[INFO] 2021-07-12 18:29:28,821 [run_pretraining.py:  558]:	worker_index: 2, step: 240, cost: 9.489433, mlm loss: 9.489433, speed: 1.103905 steps/s, speed: 8.831236 samples/s, speed: 4521.592925 tokens/s, learning rate: 2.390e-06, loss_scalings: 26214.400391, pp_loss: 9.642681
[INFO] 2021-07-12 18:29:28,821 [run_pretraining.py:  512]:	********exe.run_240******* 
[INFO] 2021-07-12 18:29:29,727 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:29,727 [run_pretraining.py:  534]:	loss/total_loss, 9.24139404296875, 241
[INFO] 2021-07-12 18:29:29,727 [run_pretraining.py:  535]:	loss/mlm_loss, 9.24139404296875, 241
[INFO] 2021-07-12 18:29:29,727 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3999998575163772e-06, 241
[INFO] 2021-07-12 18:29:29,727 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 241
[INFO] 2021-07-12 18:29:29,727 [run_pretraining.py:  558]:	worker_index: 2, step: 241, cost: 9.241394, mlm loss: 9.241394, speed: 1.104293 steps/s, speed: 8.834347 samples/s, speed: 4523.185765 tokens/s, learning rate: 2.400e-06, loss_scalings: 26214.400391, pp_loss: 9.480052
[INFO] 2021-07-12 18:29:29,728 [run_pretraining.py:  512]:	********exe.run_241******* 
[INFO] 2021-07-12 18:29:30,630 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:30,631 [run_pretraining.py:  534]:	loss/total_loss, 9.606051445007324, 242
[INFO] 2021-07-12 18:29:30,631 [run_pretraining.py:  535]:	loss/mlm_loss, 9.606051445007324, 242
[INFO] 2021-07-12 18:29:30,631 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.409999979136046e-06, 242
[INFO] 2021-07-12 18:29:30,631 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 242
[INFO] 2021-07-12 18:29:30,631 [run_pretraining.py:  558]:	worker_index: 2, step: 242, cost: 9.606051, mlm loss: 9.606051, speed: 1.107388 steps/s, speed: 8.859102 samples/s, speed: 4535.860018 tokens/s, learning rate: 2.410e-06, loss_scalings: 26214.400391, pp_loss: 9.779203
[INFO] 2021-07-12 18:29:30,631 [run_pretraining.py:  512]:	********exe.run_242******* 
[INFO] 2021-07-12 18:29:31,541 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:31,542 [run_pretraining.py:  534]:	loss/total_loss, 9.649023056030273, 243
[INFO] 2021-07-12 18:29:31,542 [run_pretraining.py:  535]:	loss/mlm_loss, 9.649023056030273, 243
[INFO] 2021-07-12 18:29:31,542 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4199998733820394e-06, 243
[INFO] 2021-07-12 18:29:31,542 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 243
[INFO] 2021-07-12 18:29:31,542 [run_pretraining.py:  558]:	worker_index: 2, step: 243, cost: 9.649023, mlm loss: 9.649023, speed: 1.098135 steps/s, speed: 8.785076 samples/s, speed: 4497.959064 tokens/s, learning rate: 2.420e-06, loss_scalings: 26214.400391, pp_loss: 9.664606
[INFO] 2021-07-12 18:29:31,542 [run_pretraining.py:  512]:	********exe.run_243******* 
[INFO] 2021-07-12 18:29:32,448 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:32,448 [run_pretraining.py:  534]:	loss/total_loss, 9.795143127441406, 244
[INFO] 2021-07-12 18:29:32,448 [run_pretraining.py:  535]:	loss/mlm_loss, 9.795143127441406, 244
[INFO] 2021-07-12 18:29:32,448 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.429999995001708e-06, 244
[INFO] 2021-07-12 18:29:32,448 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 244
[INFO] 2021-07-12 18:29:32,449 [run_pretraining.py:  558]:	worker_index: 2, step: 244, cost: 9.795143, mlm loss: 9.795143, speed: 1.104351 steps/s, speed: 8.834805 samples/s, speed: 4523.420381 tokens/s, learning rate: 2.430e-06, loss_scalings: 26214.400391, pp_loss: 9.555368
[INFO] 2021-07-12 18:29:32,449 [run_pretraining.py:  512]:	********exe.run_244******* 
[INFO] 2021-07-12 18:29:33,351 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:33,351 [run_pretraining.py:  534]:	loss/total_loss, 9.619930267333984, 245
[INFO] 2021-07-12 18:29:33,351 [run_pretraining.py:  535]:	loss/mlm_loss, 9.619930267333984, 245
[INFO] 2021-07-12 18:29:33,351 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4399998892477015e-06, 245
[INFO] 2021-07-12 18:29:33,351 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 245
[INFO] 2021-07-12 18:29:33,352 [run_pretraining.py:  558]:	worker_index: 2, step: 245, cost: 9.619930, mlm loss: 9.619930, speed: 1.108147 steps/s, speed: 8.865175 samples/s, speed: 4538.969832 tokens/s, learning rate: 2.440e-06, loss_scalings: 26214.400391, pp_loss: 9.594567
[INFO] 2021-07-12 18:29:33,352 [run_pretraining.py:  512]:	********exe.run_245******* 
[INFO] 2021-07-12 18:29:34,253 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:34,254 [run_pretraining.py:  534]:	loss/total_loss, 9.612754821777344, 246
[INFO] 2021-07-12 18:29:34,254 [run_pretraining.py:  535]:	loss/mlm_loss, 9.612754821777344, 246
[INFO] 2021-07-12 18:29:34,254 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.449999783493695e-06, 246
[INFO] 2021-07-12 18:29:34,254 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 246
[INFO] 2021-07-12 18:29:34,254 [run_pretraining.py:  558]:	worker_index: 2, step: 246, cost: 9.612755, mlm loss: 9.612755, speed: 1.108860 steps/s, speed: 8.870880 samples/s, speed: 4541.890584 tokens/s, learning rate: 2.450e-06, loss_scalings: 26214.400391, pp_loss: 9.669786
[INFO] 2021-07-12 18:29:34,254 [run_pretraining.py:  512]:	********exe.run_246******* 
[INFO] 2021-07-12 18:29:35,160 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:35,160 [run_pretraining.py:  534]:	loss/total_loss, 9.760286331176758, 247
[INFO] 2021-07-12 18:29:35,160 [run_pretraining.py:  535]:	loss/mlm_loss, 9.760286331176758, 247
[INFO] 2021-07-12 18:29:35,161 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4599999051133636e-06, 247
[INFO] 2021-07-12 18:29:35,161 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 247
[INFO] 2021-07-12 18:29:35,161 [run_pretraining.py:  558]:	worker_index: 2, step: 247, cost: 9.760286, mlm loss: 9.760286, speed: 1.103553 steps/s, speed: 8.828422 samples/s, speed: 4520.152240 tokens/s, learning rate: 2.460e-06, loss_scalings: 26214.400391, pp_loss: 9.752983
[INFO] 2021-07-12 18:29:35,161 [run_pretraining.py:  512]:	********exe.run_247******* 
[INFO] 2021-07-12 18:29:36,063 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:36,063 [run_pretraining.py:  534]:	loss/total_loss, 9.493067741394043, 248
[INFO] 2021-07-12 18:29:36,063 [run_pretraining.py:  535]:	loss/mlm_loss, 9.493067741394043, 248
[INFO] 2021-07-12 18:29:36,063 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4700000267330324e-06, 248
[INFO] 2021-07-12 18:29:36,063 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 248
[INFO] 2021-07-12 18:29:36,063 [run_pretraining.py:  558]:	worker_index: 2, step: 248, cost: 9.493068, mlm loss: 9.493068, speed: 1.108547 steps/s, speed: 8.868378 samples/s, speed: 4540.609742 tokens/s, learning rate: 2.470e-06, loss_scalings: 26214.400391, pp_loss: 9.609267
[INFO] 2021-07-12 18:29:36,063 [run_pretraining.py:  512]:	********exe.run_248******* 
[INFO] 2021-07-12 18:29:36,972 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:36,972 [run_pretraining.py:  534]:	loss/total_loss, 9.718925476074219, 249
[INFO] 2021-07-12 18:29:36,973 [run_pretraining.py:  535]:	loss/mlm_loss, 9.718925476074219, 249
[INFO] 2021-07-12 18:29:36,973 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4799999209790258e-06, 249
[INFO] 2021-07-12 18:29:36,973 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 249
[INFO] 2021-07-12 18:29:36,973 [run_pretraining.py:  558]:	worker_index: 2, step: 249, cost: 9.718925, mlm loss: 9.718925, speed: 1.100368 steps/s, speed: 8.802940 samples/s, speed: 4507.105483 tokens/s, learning rate: 2.480e-06, loss_scalings: 26214.400391, pp_loss: 9.731250
[INFO] 2021-07-12 18:29:36,973 [run_pretraining.py:  512]:	********exe.run_249******* 
[INFO] 2021-07-12 18:30:02,769 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:02,770 [run_pretraining.py:  534]:	loss/total_loss, 9.506704330444336, 250
[INFO] 2021-07-12 18:30:02,770 [run_pretraining.py:  535]:	loss/mlm_loss, 9.506704330444336, 250
[INFO] 2021-07-12 18:30:02,770 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4900000425986946e-06, 250
[INFO] 2021-07-12 18:30:02,770 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 250
[INFO] 2021-07-12 18:30:02,770 [run_pretraining.py:  558]:	worker_index: 2, step: 250, cost: 9.506704, mlm loss: 9.506704, speed: 0.038765 steps/s, speed: 0.310120 samples/s, speed: 158.781405 tokens/s, learning rate: 2.490e-06, loss_scalings: 26214.400391, pp_loss: 9.652885
[INFO] 2021-07-12 18:30:02,770 [run_pretraining.py:  512]:	********exe.run_250******* 
[INFO] 2021-07-12 18:30:03,689 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:03,689 [run_pretraining.py:  534]:	loss/total_loss, 9.665182113647461, 251
[INFO] 2021-07-12 18:30:03,689 [run_pretraining.py:  535]:	loss/mlm_loss, 9.665182113647461, 251
[INFO] 2021-07-12 18:30:03,690 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.499999936844688e-06, 251
[INFO] 2021-07-12 18:30:03,690 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 251
[INFO] 2021-07-12 18:30:03,690 [run_pretraining.py:  558]:	worker_index: 2, step: 251, cost: 9.665182, mlm loss: 9.665182, speed: 1.087933 steps/s, speed: 8.703467 samples/s, speed: 4456.174997 tokens/s, learning rate: 2.500e-06, loss_scalings: 26214.400391, pp_loss: 9.671164
[INFO] 2021-07-12 18:30:03,690 [run_pretraining.py:  512]:	********exe.run_251******* 
[INFO] 2021-07-12 18:30:04,599 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:04,600 [run_pretraining.py:  534]:	loss/total_loss, 9.336477279663086, 252
[INFO] 2021-07-12 18:30:04,600 [run_pretraining.py:  535]:	loss/mlm_loss, 9.336477279663086, 252
[INFO] 2021-07-12 18:30:04,600 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5100000584643567e-06, 252
[INFO] 2021-07-12 18:30:04,600 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 252
[INFO] 2021-07-12 18:30:04,600 [run_pretraining.py:  558]:	worker_index: 2, step: 252, cost: 9.336477, mlm loss: 9.336477, speed: 1.099332 steps/s, speed: 8.794655 samples/s, speed: 4502.863372 tokens/s, learning rate: 2.510e-06, loss_scalings: 26214.400391, pp_loss: 9.486901
[INFO] 2021-07-12 18:30:04,600 [run_pretraining.py:  512]:	********exe.run_252******* 
[INFO] 2021-07-12 18:30:05,516 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:05,516 [run_pretraining.py:  534]:	loss/total_loss, 9.634711265563965, 253
[INFO] 2021-07-12 18:30:05,516 [run_pretraining.py:  535]:	loss/mlm_loss, 9.634711265563965, 253
[INFO] 2021-07-12 18:30:05,516 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.51999995271035e-06, 253
[INFO] 2021-07-12 18:30:05,516 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 253
[INFO] 2021-07-12 18:30:05,517 [run_pretraining.py:  558]:	worker_index: 2, step: 253, cost: 9.634711, mlm loss: 9.634711, speed: 1.091734 steps/s, speed: 8.733873 samples/s, speed: 4471.743127 tokens/s, learning rate: 2.520e-06, loss_scalings: 26214.400391, pp_loss: 9.819263
[INFO] 2021-07-12 18:30:05,517 [run_pretraining.py:  512]:	********exe.run_253******* 
[INFO] 2021-07-12 18:30:06,434 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:06,434 [run_pretraining.py:  534]:	loss/total_loss, 9.457961082458496, 254
[INFO] 2021-07-12 18:30:06,434 [run_pretraining.py:  535]:	loss/mlm_loss, 9.457961082458496, 254
[INFO] 2021-07-12 18:30:06,435 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5299998469563434e-06, 254
[INFO] 2021-07-12 18:30:06,435 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 254
[INFO] 2021-07-12 18:30:06,435 [run_pretraining.py:  558]:	worker_index: 2, step: 254, cost: 9.457961, mlm loss: 9.457961, speed: 1.089855 steps/s, speed: 8.718841 samples/s, speed: 4464.046401 tokens/s, learning rate: 2.530e-06, loss_scalings: 26214.400391, pp_loss: 9.450374
[INFO] 2021-07-12 18:30:06,435 [run_pretraining.py:  512]:	********exe.run_254******* 
[INFO] 2021-07-12 18:30:07,402 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:07,402 [run_pretraining.py:  534]:	loss/total_loss, 9.49111557006836, 255
[INFO] 2021-07-12 18:30:07,402 [run_pretraining.py:  535]:	loss/mlm_loss, 9.49111557006836, 255
[INFO] 2021-07-12 18:30:07,402 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.539999968576012e-06, 255
[INFO] 2021-07-12 18:30:07,402 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 255
[INFO] 2021-07-12 18:30:07,402 [run_pretraining.py:  558]:	worker_index: 2, step: 255, cost: 9.491116, mlm loss: 9.491116, speed: 1.034000 steps/s, speed: 8.272002 samples/s, speed: 4235.264885 tokens/s, learning rate: 2.540e-06, loss_scalings: 26214.400391, pp_loss: 8.526009
[INFO] 2021-07-12 18:30:07,402 [run_pretraining.py:  512]:	********exe.run_255******* 
[INFO] 2021-07-12 18:30:33,995 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:33,995 [run_pretraining.py:  534]:	loss/total_loss, 9.610882759094238, 256
[INFO] 2021-07-12 18:30:33,995 [run_pretraining.py:  535]:	loss/mlm_loss, 9.610882759094238, 256
[INFO] 2021-07-12 18:30:33,996 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5499998628220055e-06, 256
[INFO] 2021-07-12 18:30:33,996 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 256
[INFO] 2021-07-12 18:30:33,996 [run_pretraining.py:  558]:	worker_index: 2, step: 256, cost: 9.610883, mlm loss: 9.610883, speed: 0.037604 steps/s, speed: 0.300835 samples/s, speed: 154.027323 tokens/s, learning rate: 2.550e-06, loss_scalings: 26214.400391, pp_loss: 9.705166
[INFO] 2021-07-12 18:30:33,996 [run_pretraining.py:  512]:	********exe.run_256******* 
[INFO] 2021-07-12 18:30:34,959 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:34,959 [run_pretraining.py:  534]:	loss/total_loss, 9.249467849731445, 257
[INFO] 2021-07-12 18:30:34,959 [run_pretraining.py:  535]:	loss/mlm_loss, 9.249467849731445, 257
[INFO] 2021-07-12 18:30:34,960 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.559999757067999e-06, 257
[INFO] 2021-07-12 18:30:34,960 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 257
[INFO] 2021-07-12 18:30:34,960 [run_pretraining.py:  558]:	worker_index: 2, step: 257, cost: 9.249468, mlm loss: 9.249468, speed: 1.038033 steps/s, speed: 8.304268 samples/s, speed: 4251.785104 tokens/s, learning rate: 2.560e-06, loss_scalings: 26214.400391, pp_loss: 9.521215
[INFO] 2021-07-12 18:30:34,960 [run_pretraining.py:  512]:	********exe.run_257******* 
[INFO] 2021-07-12 18:30:35,865 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:35,865 [run_pretraining.py:  534]:	loss/total_loss, 9.886356353759766, 258
[INFO] 2021-07-12 18:30:35,866 [run_pretraining.py:  535]:	loss/mlm_loss, 9.886356353759766, 258
[INFO] 2021-07-12 18:30:35,866 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5699998786876677e-06, 258
[INFO] 2021-07-12 18:30:35,866 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 258
[INFO] 2021-07-12 18:30:35,866 [run_pretraining.py:  558]:	worker_index: 2, step: 258, cost: 9.886356, mlm loss: 9.886356, speed: 1.104284 steps/s, speed: 8.834268 samples/s, speed: 4523.145275 tokens/s, learning rate: 2.570e-06, loss_scalings: 26214.400391, pp_loss: 9.706635
[INFO] 2021-07-12 18:30:35,866 [run_pretraining.py:  512]:	********exe.run_258******* 
[INFO] 2021-07-12 18:30:36,777 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:36,778 [run_pretraining.py:  534]:	loss/total_loss, 9.514284133911133, 259
[INFO] 2021-07-12 18:30:36,778 [run_pretraining.py:  535]:	loss/mlm_loss, 9.514284133911133, 259
[INFO] 2021-07-12 18:30:36,778 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5800000003073364e-06, 259
[INFO] 2021-07-12 18:30:36,778 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 259
[INFO] 2021-07-12 18:30:36,778 [run_pretraining.py:  558]:	worker_index: 2, step: 259, cost: 9.514284, mlm loss: 9.514284, speed: 1.096838 steps/s, speed: 8.774704 samples/s, speed: 4492.648314 tokens/s, learning rate: 2.580e-06, loss_scalings: 26214.400391, pp_loss: 9.603395
[INFO] 2021-07-12 18:30:36,778 [run_pretraining.py:  512]:	********exe.run_259******* 
[INFO] 2021-07-12 18:30:37,695 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:37,696 [run_pretraining.py:  534]:	loss/total_loss, 9.56984806060791, 260
[INFO] 2021-07-12 18:30:37,696 [run_pretraining.py:  535]:	loss/mlm_loss, 9.56984806060791, 260
[INFO] 2021-07-12 18:30:37,696 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.58999989455333e-06, 260
[INFO] 2021-07-12 18:30:37,696 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 260
[INFO] 2021-07-12 18:30:37,696 [run_pretraining.py:  558]:	worker_index: 2, step: 260, cost: 9.569848, mlm loss: 9.569848, speed: 1.090132 steps/s, speed: 8.721052 samples/s, speed: 4465.178795 tokens/s, learning rate: 2.590e-06, loss_scalings: 26214.400391, pp_loss: 9.607283
[INFO] 2021-07-12 18:30:37,696 [run_pretraining.py:  512]:	********exe.run_260******* 
[INFO] 2021-07-12 18:30:38,605 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:38,605 [run_pretraining.py:  534]:	loss/total_loss, 9.707584381103516, 261
[INFO] 2021-07-12 18:30:38,605 [run_pretraining.py:  535]:	loss/mlm_loss, 9.707584381103516, 261
[INFO] 2021-07-12 18:30:38,606 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6000000161729986e-06, 261
[INFO] 2021-07-12 18:30:38,606 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 261
[INFO] 2021-07-12 18:30:38,606 [run_pretraining.py:  558]:	worker_index: 2, step: 261, cost: 9.707584, mlm loss: 9.707584, speed: 1.100057 steps/s, speed: 8.800456 samples/s, speed: 4505.833547 tokens/s, learning rate: 2.600e-06, loss_scalings: 26214.400391, pp_loss: 9.701692
[INFO] 2021-07-12 18:30:38,606 [run_pretraining.py:  512]:	********exe.run_261******* 
[INFO] 2021-07-12 18:30:39,515 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:39,515 [run_pretraining.py:  534]:	loss/total_loss, 9.840457916259766, 262
[INFO] 2021-07-12 18:30:39,515 [run_pretraining.py:  535]:	loss/mlm_loss, 9.840457916259766, 262
[INFO] 2021-07-12 18:30:39,515 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.609999910418992e-06, 262
[INFO] 2021-07-12 18:30:39,515 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 262
[INFO] 2021-07-12 18:30:39,515 [run_pretraining.py:  558]:	worker_index: 2, step: 262, cost: 9.840458, mlm loss: 9.840458, speed: 1.100005 steps/s, speed: 8.800041 samples/s, speed: 4505.620840 tokens/s, learning rate: 2.610e-06, loss_scalings: 26214.400391, pp_loss: 9.626500
[INFO] 2021-07-12 18:30:39,515 [run_pretraining.py:  512]:	********exe.run_262******* 
[INFO] 2021-07-12 18:30:40,423 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:40,423 [run_pretraining.py:  534]:	loss/total_loss, 9.631348609924316, 263
[INFO] 2021-07-12 18:30:40,424 [run_pretraining.py:  535]:	loss/mlm_loss, 9.631348609924316, 263
[INFO] 2021-07-12 18:30:40,424 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6200000320386607e-06, 263
[INFO] 2021-07-12 18:30:40,424 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 263
[INFO] 2021-07-12 18:30:40,424 [run_pretraining.py:  558]:	worker_index: 2, step: 263, cost: 9.631349, mlm loss: 9.631349, speed: 1.101530 steps/s, speed: 8.812241 samples/s, speed: 4511.867427 tokens/s, learning rate: 2.620e-06, loss_scalings: 26214.400391, pp_loss: 9.588398
[INFO] 2021-07-12 18:30:40,424 [run_pretraining.py:  512]:	********exe.run_263******* 
[INFO] 2021-07-12 18:30:41,329 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:41,330 [run_pretraining.py:  534]:	loss/total_loss, 9.629589080810547, 264
[INFO] 2021-07-12 18:30:41,330 [run_pretraining.py:  535]:	loss/mlm_loss, 9.629589080810547, 264
[INFO] 2021-07-12 18:30:41,330 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.629999926284654e-06, 264
[INFO] 2021-07-12 18:30:41,330 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 264
[INFO] 2021-07-12 18:30:41,330 [run_pretraining.py:  558]:	worker_index: 2, step: 264, cost: 9.629589, mlm loss: 9.629589, speed: 1.104188 steps/s, speed: 8.833503 samples/s, speed: 4522.753515 tokens/s, learning rate: 2.630e-06, loss_scalings: 26214.400391, pp_loss: 9.648293
[INFO] 2021-07-12 18:30:41,330 [run_pretraining.py:  512]:	********exe.run_264******* 
[INFO] 2021-07-12 18:30:42,241 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:42,241 [run_pretraining.py:  534]:	loss/total_loss, 9.537532806396484, 265
[INFO] 2021-07-12 18:30:42,241 [run_pretraining.py:  535]:	loss/mlm_loss, 9.537532806396484, 265
[INFO] 2021-07-12 18:30:42,241 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6399998205306474e-06, 265
[INFO] 2021-07-12 18:30:42,242 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 265
[INFO] 2021-07-12 18:30:42,242 [run_pretraining.py:  558]:	worker_index: 2, step: 265, cost: 9.537533, mlm loss: 9.537533, speed: 1.097767 steps/s, speed: 8.782133 samples/s, speed: 4496.452195 tokens/s, learning rate: 2.640e-06, loss_scalings: 26214.400391, pp_loss: 9.598206
[INFO] 2021-07-12 18:30:42,242 [run_pretraining.py:  512]:	********exe.run_265******* 
[INFO] 2021-07-12 18:30:43,169 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:43,170 [run_pretraining.py:  534]:	loss/total_loss, 9.73465347290039, 266
[INFO] 2021-07-12 18:30:43,170 [run_pretraining.py:  535]:	loss/mlm_loss, 9.73465347290039, 266
[INFO] 2021-07-12 18:30:43,170 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.649999942150316e-06, 266
[INFO] 2021-07-12 18:30:43,170 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 266
[INFO] 2021-07-12 18:30:43,170 [run_pretraining.py:  558]:	worker_index: 2, step: 266, cost: 9.734653, mlm loss: 9.734653, speed: 1.077755 steps/s, speed: 8.622039 samples/s, speed: 4414.483930 tokens/s, learning rate: 2.650e-06, loss_scalings: 26214.400391, pp_loss: 9.826527
[INFO] 2021-07-12 18:30:43,170 [run_pretraining.py:  512]:	********exe.run_266******* 
[INFO] 2021-07-12 18:30:44,233 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:44,233 [run_pretraining.py:  534]:	loss/total_loss, 9.636757850646973, 267
[INFO] 2021-07-12 18:30:44,233 [run_pretraining.py:  535]:	loss/mlm_loss, 9.636757850646973, 267
[INFO] 2021-07-12 18:30:44,233 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6599998363963095e-06, 267
[INFO] 2021-07-12 18:30:44,234 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 267
[INFO] 2021-07-12 18:30:44,234 [run_pretraining.py:  558]:	worker_index: 2, step: 267, cost: 9.636758, mlm loss: 9.636758, speed: 0.940814 steps/s, speed: 7.526512 samples/s, speed: 3853.574101 tokens/s, learning rate: 2.660e-06, loss_scalings: 26214.400391, pp_loss: 9.599513
[INFO] 2021-07-12 18:30:44,234 [run_pretraining.py:  512]:	********exe.run_267******* 
[INFO] 2021-07-12 18:30:45,285 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:45,286 [run_pretraining.py:  534]:	loss/total_loss, 9.47026252746582, 268
[INFO] 2021-07-12 18:30:45,286 [run_pretraining.py:  535]:	loss/mlm_loss, 9.47026252746582, 268
[INFO] 2021-07-12 18:30:45,286 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6699999580159783e-06, 268
[INFO] 2021-07-12 18:30:45,286 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 268
[INFO] 2021-07-12 18:30:45,286 [run_pretraining.py:  558]:	worker_index: 2, step: 268, cost: 9.470263, mlm loss: 9.470263, speed: 0.950488 steps/s, speed: 7.603902 samples/s, speed: 3893.198020 tokens/s, learning rate: 2.670e-06, loss_scalings: 26214.400391, pp_loss: 9.619387
[INFO] 2021-07-12 18:30:45,286 [run_pretraining.py:  512]:	********exe.run_268******* 
[INFO] 2021-07-12 18:30:46,338 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:46,338 [run_pretraining.py:  534]:	loss/total_loss, 9.92017936706543, 269
[INFO] 2021-07-12 18:30:46,338 [run_pretraining.py:  535]:	loss/mlm_loss, 9.92017936706543, 269
[INFO] 2021-07-12 18:30:46,338 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6799998522619717e-06, 269
[INFO] 2021-07-12 18:30:46,339 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 269
[INFO] 2021-07-12 18:30:46,339 [run_pretraining.py:  558]:	worker_index: 2, step: 269, cost: 9.920179, mlm loss: 9.920179, speed: 0.950853 steps/s, speed: 7.606824 samples/s, speed: 3894.694013 tokens/s, learning rate: 2.680e-06, loss_scalings: 26214.400391, pp_loss: 9.730036
[INFO] 2021-07-12 18:30:46,339 [run_pretraining.py:  512]:	********exe.run_269******* 
[INFO] 2021-07-12 18:30:47,396 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:47,396 [run_pretraining.py:  534]:	loss/total_loss, 9.566965103149414, 270
[INFO] 2021-07-12 18:30:47,396 [run_pretraining.py:  535]:	loss/mlm_loss, 9.566965103149414, 270
[INFO] 2021-07-12 18:30:47,397 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6899999738816405e-06, 270
[INFO] 2021-07-12 18:30:47,397 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 270
[INFO] 2021-07-12 18:30:47,397 [run_pretraining.py:  558]:	worker_index: 2, step: 270, cost: 9.566965, mlm loss: 9.566965, speed: 0.945627 steps/s, speed: 7.565013 samples/s, speed: 3873.286471 tokens/s, learning rate: 2.690e-06, loss_scalings: 26214.400391, pp_loss: 9.626221
[INFO] 2021-07-12 18:30:47,397 [run_pretraining.py:  512]:	********exe.run_270******* 
[INFO] 2021-07-12 18:30:48,458 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:48,459 [run_pretraining.py:  534]:	loss/total_loss, 9.919391632080078, 271
[INFO] 2021-07-12 18:30:48,459 [run_pretraining.py:  535]:	loss/mlm_loss, 9.919391632080078, 271
[INFO] 2021-07-12 18:30:48,459 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7000000955013093e-06, 271
[INFO] 2021-07-12 18:30:48,459 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 271
[INFO] 2021-07-12 18:30:48,459 [run_pretraining.py:  558]:	worker_index: 2, step: 271, cost: 9.919392, mlm loss: 9.919392, speed: 0.941718 steps/s, speed: 7.533741 samples/s, speed: 3857.275495 tokens/s, learning rate: 2.700e-06, loss_scalings: 26214.400391, pp_loss: 9.616920
[INFO] 2021-07-12 18:30:48,459 [run_pretraining.py:  512]:	********exe.run_271******* 
[INFO] 2021-07-12 18:30:49,530 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:49,531 [run_pretraining.py:  534]:	loss/total_loss, 9.566271781921387, 272
[INFO] 2021-07-12 18:30:49,531 [run_pretraining.py:  535]:	loss/mlm_loss, 9.566271781921387, 272
[INFO] 2021-07-12 18:30:49,531 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7099999897473026e-06, 272
[INFO] 2021-07-12 18:30:49,531 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 272
[INFO] 2021-07-12 18:30:49,531 [run_pretraining.py:  558]:	worker_index: 2, step: 272, cost: 9.566272, mlm loss: 9.566272, speed: 0.933554 steps/s, speed: 7.468435 samples/s, speed: 3823.838808 tokens/s, learning rate: 2.710e-06, loss_scalings: 26214.400391, pp_loss: 8.757276
[INFO] 2021-07-12 18:30:49,531 [run_pretraining.py:  512]:	********exe.run_272******* 
[INFO] 2021-07-12 18:30:50,595 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:50,595 [run_pretraining.py:  534]:	loss/total_loss, 9.801015853881836, 273
[INFO] 2021-07-12 18:30:50,595 [run_pretraining.py:  535]:	loss/mlm_loss, 9.801015853881836, 273
[INFO] 2021-07-12 18:30:50,596 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.719999883993296e-06, 273
[INFO] 2021-07-12 18:30:50,596 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 273
[INFO] 2021-07-12 18:30:50,596 [run_pretraining.py:  558]:	worker_index: 2, step: 273, cost: 9.801016, mlm loss: 9.801016, speed: 0.939711 steps/s, speed: 7.517688 samples/s, speed: 3849.056074 tokens/s, learning rate: 2.720e-06, loss_scalings: 26214.400391, pp_loss: 9.474176
[INFO] 2021-07-12 18:30:50,596 [run_pretraining.py:  512]:	********exe.run_273******* 
[INFO] 2021-07-12 18:30:51,647 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:51,647 [run_pretraining.py:  534]:	loss/total_loss, 9.734437942504883, 274
[INFO] 2021-07-12 18:30:51,647 [run_pretraining.py:  535]:	loss/mlm_loss, 9.734437942504883, 274
[INFO] 2021-07-12 18:30:51,647 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7300000056129647e-06, 274
[INFO] 2021-07-12 18:30:51,647 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 274
[INFO] 2021-07-12 18:30:51,647 [run_pretraining.py:  558]:	worker_index: 2, step: 274, cost: 9.734438, mlm loss: 9.734438, speed: 0.951366 steps/s, speed: 7.610926 samples/s, speed: 3896.793872 tokens/s, learning rate: 2.730e-06, loss_scalings: 26214.400391, pp_loss: 9.737377
[INFO] 2021-07-12 18:30:51,648 [run_pretraining.py:  512]:	********exe.run_274******* 
[INFO] 2021-07-12 18:30:52,704 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:52,704 [run_pretraining.py:  534]:	loss/total_loss, 9.642212867736816, 275
[INFO] 2021-07-12 18:30:52,705 [run_pretraining.py:  535]:	loss/mlm_loss, 9.642212867736816, 275
[INFO] 2021-07-12 18:30:52,705 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.739999899858958e-06, 275
[INFO] 2021-07-12 18:30:52,705 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 275
[INFO] 2021-07-12 18:30:52,705 [run_pretraining.py:  558]:	worker_index: 2, step: 275, cost: 9.642213, mlm loss: 9.642213, speed: 0.946314 steps/s, speed: 7.570514 samples/s, speed: 3876.103008 tokens/s, learning rate: 2.740e-06, loss_scalings: 26214.400391, pp_loss: 9.544477
[INFO] 2021-07-12 18:30:52,705 [run_pretraining.py:  512]:	********exe.run_275******* 
[INFO] 2021-07-12 18:30:53,839 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:53,840 [run_pretraining.py:  534]:	loss/total_loss, 9.813584327697754, 276
[INFO] 2021-07-12 18:30:53,840 [run_pretraining.py:  535]:	loss/mlm_loss, 9.813584327697754, 276
[INFO] 2021-07-12 18:30:53,840 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.750000021478627e-06, 276
[INFO] 2021-07-12 18:30:53,840 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 276
[INFO] 2021-07-12 18:30:53,840 [run_pretraining.py:  558]:	worker_index: 2, step: 276, cost: 9.813584, mlm loss: 9.813584, speed: 0.881344 steps/s, speed: 7.050751 samples/s, speed: 3609.984474 tokens/s, learning rate: 2.750e-06, loss_scalings: 26214.400391, pp_loss: 9.661500
[INFO] 2021-07-12 18:30:53,840 [run_pretraining.py:  512]:	********exe.run_276******* 
[INFO] 2021-07-12 18:30:54,932 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:54,933 [run_pretraining.py:  534]:	loss/total_loss, 9.703142166137695, 277
[INFO] 2021-07-12 18:30:54,933 [run_pretraining.py:  535]:	loss/mlm_loss, 9.703142166137695, 277
[INFO] 2021-07-12 18:30:54,933 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7599999157246202e-06, 277
[INFO] 2021-07-12 18:30:54,933 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 277
[INFO] 2021-07-12 18:30:54,933 [run_pretraining.py:  558]:	worker_index: 2, step: 277, cost: 9.703142, mlm loss: 9.703142, speed: 0.915512 steps/s, speed: 7.324100 samples/s, speed: 3749.938978 tokens/s, learning rate: 2.760e-06, loss_scalings: 26214.400391, pp_loss: 9.073360
[INFO] 2021-07-12 18:30:54,933 [run_pretraining.py:  512]:	********exe.run_277******* 
[INFO] 2021-07-12 18:30:56,003 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:56,004 [run_pretraining.py:  534]:	loss/total_loss, 9.406472206115723, 278
[INFO] 2021-07-12 18:30:56,004 [run_pretraining.py:  535]:	loss/mlm_loss, 9.406472206115723, 278
[INFO] 2021-07-12 18:30:56,004 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7699998099706136e-06, 278
[INFO] 2021-07-12 18:30:56,004 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 278
[INFO] 2021-07-12 18:30:56,004 [run_pretraining.py:  558]:	worker_index: 2, step: 278, cost: 9.406472, mlm loss: 9.406472, speed: 0.933872 steps/s, speed: 7.470979 samples/s, speed: 3825.141431 tokens/s, learning rate: 2.770e-06, loss_scalings: 26214.400391, pp_loss: 9.313784
[INFO] 2021-07-12 18:30:56,004 [run_pretraining.py:  512]:	********exe.run_278******* 
[INFO] 2021-07-12 18:30:57,094 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:57,094 [run_pretraining.py:  534]:	loss/total_loss, 6.232369899749756, 279
[INFO] 2021-07-12 18:30:57,094 [run_pretraining.py:  535]:	loss/mlm_loss, 6.232369899749756, 279
[INFO] 2021-07-12 18:30:57,095 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7799999315902824e-06, 279
[INFO] 2021-07-12 18:30:57,095 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 279
[INFO] 2021-07-12 18:30:57,095 [run_pretraining.py:  558]:	worker_index: 2, step: 279, cost: 6.232370, mlm loss: 6.232370, speed: 0.917669 steps/s, speed: 7.341355 samples/s, speed: 3758.773551 tokens/s, learning rate: 2.780e-06, loss_scalings: 26214.400391, pp_loss: 8.752408
[INFO] 2021-07-12 18:30:57,095 [run_pretraining.py:  512]:	********exe.run_279******* 
[INFO] 2021-07-12 18:30:58,181 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:58,181 [run_pretraining.py:  534]:	loss/total_loss, 9.615598678588867, 280
[INFO] 2021-07-12 18:30:58,181 [run_pretraining.py:  535]:	loss/mlm_loss, 9.615598678588867, 280
[INFO] 2021-07-12 18:30:58,182 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7899998258362757e-06, 280
[INFO] 2021-07-12 18:30:58,182 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 280
[INFO] 2021-07-12 18:30:58,182 [run_pretraining.py:  558]:	worker_index: 2, step: 280, cost: 9.615599, mlm loss: 9.615599, speed: 0.920416 steps/s, speed: 7.363329 samples/s, speed: 3770.024388 tokens/s, learning rate: 2.790e-06, loss_scalings: 26214.400391, pp_loss: 9.724773
[INFO] 2021-07-12 18:30:58,182 [run_pretraining.py:  512]:	********exe.run_280******* 
[INFO] 2021-07-12 18:30:59,266 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:59,266 [run_pretraining.py:  534]:	loss/total_loss, 9.503658294677734, 281
[INFO] 2021-07-12 18:30:59,267 [run_pretraining.py:  535]:	loss/mlm_loss, 9.503658294677734, 281
[INFO] 2021-07-12 18:30:59,267 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7999999474559445e-06, 281
[INFO] 2021-07-12 18:30:59,267 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 281
[INFO] 2021-07-12 18:30:59,267 [run_pretraining.py:  558]:	worker_index: 2, step: 281, cost: 9.503658, mlm loss: 9.503658, speed: 0.922081 steps/s, speed: 7.376651 samples/s, speed: 3776.845471 tokens/s, learning rate: 2.800e-06, loss_scalings: 26214.400391, pp_loss: 9.560246
[INFO] 2021-07-12 18:30:59,267 [run_pretraining.py:  512]:	********exe.run_281******* 
[INFO] 2021-07-12 18:31:00,353 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:00,353 [run_pretraining.py:  534]:	loss/total_loss, 9.526925086975098, 282
[INFO] 2021-07-12 18:31:00,353 [run_pretraining.py:  535]:	loss/mlm_loss, 9.526925086975098, 282
[INFO] 2021-07-12 18:31:00,354 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8100000690756133e-06, 282
[INFO] 2021-07-12 18:31:00,354 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 282
[INFO] 2021-07-12 18:31:00,354 [run_pretraining.py:  558]:	worker_index: 2, step: 282, cost: 9.526925, mlm loss: 9.526925, speed: 0.920581 steps/s, speed: 7.364644 samples/s, speed: 3770.697939 tokens/s, learning rate: 2.810e-06, loss_scalings: 26214.400391, pp_loss: 9.508928
[INFO] 2021-07-12 18:31:00,354 [run_pretraining.py:  512]:	********exe.run_282******* 
[INFO] 2021-07-12 18:31:01,444 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:01,445 [run_pretraining.py:  534]:	loss/total_loss, 9.67750072479248, 283
[INFO] 2021-07-12 18:31:01,445 [run_pretraining.py:  535]:	loss/mlm_loss, 9.67750072479248, 283
[INFO] 2021-07-12 18:31:01,445 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8199999633216066e-06, 283
[INFO] 2021-07-12 18:31:01,445 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 283
[INFO] 2021-07-12 18:31:01,445 [run_pretraining.py:  558]:	worker_index: 2, step: 283, cost: 9.677501, mlm loss: 9.677501, speed: 0.916582 steps/s, speed: 7.332653 samples/s, speed: 3754.318249 tokens/s, learning rate: 2.820e-06, loss_scalings: 26214.400391, pp_loss: 9.610784
[INFO] 2021-07-12 18:31:01,445 [run_pretraining.py:  512]:	********exe.run_283******* 
[INFO] 2021-07-12 18:31:02,542 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:02,543 [run_pretraining.py:  534]:	loss/total_loss, 9.624070167541504, 284
[INFO] 2021-07-12 18:31:02,543 [run_pretraining.py:  535]:	loss/mlm_loss, 9.624070167541504, 284
[INFO] 2021-07-12 18:31:02,543 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8299998575676e-06, 284
[INFO] 2021-07-12 18:31:02,543 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 284
[INFO] 2021-07-12 18:31:02,543 [run_pretraining.py:  558]:	worker_index: 2, step: 284, cost: 9.624070, mlm loss: 9.624070, speed: 0.911228 steps/s, speed: 7.289821 samples/s, speed: 3732.388161 tokens/s, learning rate: 2.830e-06, loss_scalings: 26214.400391, pp_loss: 9.615181
[INFO] 2021-07-12 18:31:02,543 [run_pretraining.py:  512]:	********exe.run_284******* 
[INFO] 2021-07-12 18:31:03,629 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:03,629 [run_pretraining.py:  534]:	loss/total_loss, 9.805964469909668, 285
[INFO] 2021-07-12 18:31:03,629 [run_pretraining.py:  535]:	loss/mlm_loss, 9.805964469909668, 285
[INFO] 2021-07-12 18:31:03,630 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8399999791872688e-06, 285
[INFO] 2021-07-12 18:31:03,630 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 285
[INFO] 2021-07-12 18:31:03,630 [run_pretraining.py:  558]:	worker_index: 2, step: 285, cost: 9.805964, mlm loss: 9.805964, speed: 0.921010 steps/s, speed: 7.368083 samples/s, speed: 3772.458250 tokens/s, learning rate: 2.840e-06, loss_scalings: 26214.400391, pp_loss: 9.586056
[INFO] 2021-07-12 18:31:03,630 [run_pretraining.py:  512]:	********exe.run_285******* 
[INFO] 2021-07-12 18:31:04,721 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:04,721 [run_pretraining.py:  534]:	loss/total_loss, 9.922442436218262, 286
[INFO] 2021-07-12 18:31:04,721 [run_pretraining.py:  535]:	loss/mlm_loss, 9.922442436218262, 286
[INFO] 2021-07-12 18:31:04,721 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.849999873433262e-06, 286
[INFO] 2021-07-12 18:31:04,721 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 286
[INFO] 2021-07-12 18:31:04,721 [run_pretraining.py:  558]:	worker_index: 2, step: 286, cost: 9.922442, mlm loss: 9.922442, speed: 0.916457 steps/s, speed: 7.331655 samples/s, speed: 3753.807190 tokens/s, learning rate: 2.850e-06, loss_scalings: 26214.400391, pp_loss: 9.718399
[INFO] 2021-07-12 18:31:04,722 [run_pretraining.py:  512]:	********exe.run_286******* 
[INFO] 2021-07-12 18:31:05,829 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:05,830 [run_pretraining.py:  534]:	loss/total_loss, 9.495687484741211, 287
[INFO] 2021-07-12 18:31:05,830 [run_pretraining.py:  535]:	loss/mlm_loss, 9.495687484741211, 287
[INFO] 2021-07-12 18:31:05,830 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.859999995052931e-06, 287
[INFO] 2021-07-12 18:31:05,830 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 287
[INFO] 2021-07-12 18:31:05,830 [run_pretraining.py:  558]:	worker_index: 2, step: 287, cost: 9.495687, mlm loss: 9.495687, speed: 0.902628 steps/s, speed: 7.221026 samples/s, speed: 3697.165252 tokens/s, learning rate: 2.860e-06, loss_scalings: 26214.400391, pp_loss: 9.363699
[INFO] 2021-07-12 18:31:05,830 [run_pretraining.py:  512]:	********exe.run_287******* 
[INFO] 2021-07-12 18:31:06,902 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:06,903 [run_pretraining.py:  534]:	loss/total_loss, 6.6686320304870605, 288
[INFO] 2021-07-12 18:31:06,903 [run_pretraining.py:  535]:	loss/mlm_loss, 6.6686320304870605, 288
[INFO] 2021-07-12 18:31:06,903 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8699998892989242e-06, 288
[INFO] 2021-07-12 18:31:06,903 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 288
[INFO] 2021-07-12 18:31:06,903 [run_pretraining.py:  558]:	worker_index: 2, step: 288, cost: 6.668632, mlm loss: 6.668632, speed: 0.932143 steps/s, speed: 7.457144 samples/s, speed: 3818.057546 tokens/s, learning rate: 2.870e-06, loss_scalings: 26214.400391, pp_loss: 8.885443
[INFO] 2021-07-12 18:31:06,903 [run_pretraining.py:  512]:	********exe.run_288******* 
[INFO] 2021-07-12 18:31:07,991 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:07,991 [run_pretraining.py:  534]:	loss/total_loss, 5.858255386352539, 289
[INFO] 2021-07-12 18:31:07,991 [run_pretraining.py:  535]:	loss/mlm_loss, 5.858255386352539, 289
[INFO] 2021-07-12 18:31:07,992 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8799997835449176e-06, 289
[INFO] 2021-07-12 18:31:07,992 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 289
[INFO] 2021-07-12 18:31:07,992 [run_pretraining.py:  558]:	worker_index: 2, step: 289, cost: 5.858255, mlm loss: 5.858255, speed: 0.919321 steps/s, speed: 7.354565 samples/s, speed: 3765.537439 tokens/s, learning rate: 2.880e-06, loss_scalings: 26214.400391, pp_loss: 8.635695
[INFO] 2021-07-12 18:31:07,992 [run_pretraining.py:  512]:	********exe.run_289******* 
[INFO] 2021-07-12 18:31:09,086 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:09,087 [run_pretraining.py:  534]:	loss/total_loss, 9.615478515625, 290
[INFO] 2021-07-12 18:31:09,087 [run_pretraining.py:  535]:	loss/mlm_loss, 9.615478515625, 290
[INFO] 2021-07-12 18:31:09,087 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8899999051645864e-06, 290
[INFO] 2021-07-12 18:31:09,087 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 290
[INFO] 2021-07-12 18:31:09,087 [run_pretraining.py:  558]:	worker_index: 2, step: 290, cost: 9.615479, mlm loss: 9.615479, speed: 0.913278 steps/s, speed: 7.306227 samples/s, speed: 3740.788224 tokens/s, learning rate: 2.890e-06, loss_scalings: 26214.400391, pp_loss: 9.581122
[INFO] 2021-07-12 18:31:09,087 [run_pretraining.py:  512]:	********exe.run_290******* 
[INFO] 2021-07-12 18:31:10,163 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:10,163 [run_pretraining.py:  534]:	loss/total_loss, 9.44643497467041, 291
[INFO] 2021-07-12 18:31:10,163 [run_pretraining.py:  535]:	loss/mlm_loss, 9.44643497467041, 291
[INFO] 2021-07-12 18:31:10,163 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8999997994105797e-06, 291
[INFO] 2021-07-12 18:31:10,163 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 291
[INFO] 2021-07-12 18:31:10,163 [run_pretraining.py:  558]:	worker_index: 2, step: 291, cost: 9.446435, mlm loss: 9.446435, speed: 0.929750 steps/s, speed: 7.437998 samples/s, speed: 3808.255151 tokens/s, learning rate: 2.900e-06, loss_scalings: 26214.400391, pp_loss: 9.514082
[INFO] 2021-07-12 18:31:10,164 [run_pretraining.py:  512]:	********exe.run_291******* 
[INFO] 2021-07-12 18:31:11,253 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:11,254 [run_pretraining.py:  534]:	loss/total_loss, 9.568078994750977, 292
[INFO] 2021-07-12 18:31:11,254 [run_pretraining.py:  535]:	loss/mlm_loss, 9.568078994750977, 292
[INFO] 2021-07-12 18:31:11,254 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9099999210302485e-06, 292
[INFO] 2021-07-12 18:31:11,254 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 292
[INFO] 2021-07-12 18:31:11,254 [run_pretraining.py:  558]:	worker_index: 2, step: 292, cost: 9.568079, mlm loss: 9.568079, speed: 0.917592 steps/s, speed: 7.340738 samples/s, speed: 3758.457783 tokens/s, learning rate: 2.910e-06, loss_scalings: 26214.400391, pp_loss: 9.562012
[INFO] 2021-07-12 18:31:11,254 [run_pretraining.py:  512]:	********exe.run_292******* 
[INFO] 2021-07-12 18:31:12,349 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:12,349 [run_pretraining.py:  534]:	loss/total_loss, 9.638307571411133, 293
[INFO] 2021-07-12 18:31:12,349 [run_pretraining.py:  535]:	loss/mlm_loss, 9.638307571411133, 293
[INFO] 2021-07-12 18:31:12,349 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9200000426499173e-06, 293
[INFO] 2021-07-12 18:31:12,349 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 293
[INFO] 2021-07-12 18:31:12,350 [run_pretraining.py:  558]:	worker_index: 2, step: 293, cost: 9.638308, mlm loss: 9.638308, speed: 0.913213 steps/s, speed: 7.305705 samples/s, speed: 3740.521078 tokens/s, learning rate: 2.920e-06, loss_scalings: 26214.400391, pp_loss: 9.607533
[INFO] 2021-07-12 18:31:12,350 [run_pretraining.py:  512]:	********exe.run_293******* 
[INFO] 2021-07-12 18:31:13,432 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:13,432 [run_pretraining.py:  534]:	loss/total_loss, 9.835895538330078, 294
[INFO] 2021-07-12 18:31:13,432 [run_pretraining.py:  535]:	loss/mlm_loss, 9.835895538330078, 294
[INFO] 2021-07-12 18:31:13,432 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9299999368959107e-06, 294
[INFO] 2021-07-12 18:31:13,432 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 294
[INFO] 2021-07-12 18:31:13,432 [run_pretraining.py:  558]:	worker_index: 2, step: 294, cost: 9.835896, mlm loss: 9.835896, speed: 0.924021 steps/s, speed: 7.392171 samples/s, speed: 3784.791584 tokens/s, learning rate: 2.930e-06, loss_scalings: 26214.400391, pp_loss: 9.657083
[INFO] 2021-07-12 18:31:13,432 [run_pretraining.py:  512]:	********exe.run_294******* 
[INFO] 2021-07-12 18:31:14,525 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:14,525 [run_pretraining.py:  534]:	loss/total_loss, 10.003213882446289, 295
[INFO] 2021-07-12 18:31:14,525 [run_pretraining.py:  535]:	loss/mlm_loss, 10.003213882446289, 295
[INFO] 2021-07-12 18:31:14,525 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9400000585155794e-06, 295
[INFO] 2021-07-12 18:31:14,526 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 295
[INFO] 2021-07-12 18:31:14,526 [run_pretraining.py:  558]:	worker_index: 2, step: 295, cost: 10.003214, mlm loss: 10.003214, speed: 0.915192 steps/s, speed: 7.321533 samples/s, speed: 3748.624897 tokens/s, learning rate: 2.940e-06, loss_scalings: 26214.400391, pp_loss: 9.920944
[INFO] 2021-07-12 18:31:14,526 [run_pretraining.py:  512]:	********exe.run_295******* 
[INFO] 2021-07-12 18:31:15,611 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:15,611 [run_pretraining.py:  534]:	loss/total_loss, 9.329044342041016, 296
[INFO] 2021-07-12 18:31:15,611 [run_pretraining.py:  535]:	loss/mlm_loss, 9.329044342041016, 296
[INFO] 2021-07-12 18:31:15,611 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9499999527615728e-06, 296
[INFO] 2021-07-12 18:31:15,611 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 296
[INFO] 2021-07-12 18:31:15,611 [run_pretraining.py:  558]:	worker_index: 2, step: 296, cost: 9.329044, mlm loss: 9.329044, speed: 0.921527 steps/s, speed: 7.372217 samples/s, speed: 3774.575117 tokens/s, learning rate: 2.950e-06, loss_scalings: 26214.400391, pp_loss: 8.487071
[INFO] 2021-07-12 18:31:15,611 [run_pretraining.py:  512]:	********exe.run_296******* 
[INFO] 2021-07-12 18:31:16,696 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:16,697 [run_pretraining.py:  534]:	loss/total_loss, 9.535400390625, 297
[INFO] 2021-07-12 18:31:16,697 [run_pretraining.py:  535]:	loss/mlm_loss, 9.535400390625, 297
[INFO] 2021-07-12 18:31:16,697 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.959999847007566e-06, 297
[INFO] 2021-07-12 18:31:16,697 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 297
[INFO] 2021-07-12 18:31:16,697 [run_pretraining.py:  558]:	worker_index: 2, step: 297, cost: 9.535400, mlm loss: 9.535400, speed: 0.921612 steps/s, speed: 7.372897 samples/s, speed: 3774.923459 tokens/s, learning rate: 2.960e-06, loss_scalings: 26214.400391, pp_loss: 9.573683
[INFO] 2021-07-12 18:31:16,697 [run_pretraining.py:  512]:	********exe.run_297******* 
[INFO] 2021-07-12 18:31:42,956 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:42,957 [run_pretraining.py:  534]:	loss/total_loss, 9.698607444763184, 298
[INFO] 2021-07-12 18:31:42,957 [run_pretraining.py:  535]:	loss/mlm_loss, 9.698607444763184, 298
[INFO] 2021-07-12 18:31:42,957 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.969999968627235e-06, 298
[INFO] 2021-07-12 18:31:42,957 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 298
[INFO] 2021-07-12 18:31:42,957 [run_pretraining.py:  558]:	worker_index: 2, step: 298, cost: 9.698607, mlm loss: 9.698607, speed: 0.038082 steps/s, speed: 0.304655 samples/s, speed: 155.983129 tokens/s, learning rate: 2.970e-06, loss_scalings: 26214.400391, pp_loss: 9.576390
[INFO] 2021-07-12 18:31:42,957 [run_pretraining.py:  512]:	********exe.run_298******* 
[INFO] 2021-07-12 18:31:43,905 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:43,906 [run_pretraining.py:  534]:	loss/total_loss, 9.485193252563477, 299
[INFO] 2021-07-12 18:31:43,906 [run_pretraining.py:  535]:	loss/mlm_loss, 9.485193252563477, 299
[INFO] 2021-07-12 18:31:43,906 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9799998628732283e-06, 299
[INFO] 2021-07-12 18:31:43,906 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 299
[INFO] 2021-07-12 18:31:43,906 [run_pretraining.py:  558]:	worker_index: 2, step: 299, cost: 9.485193, mlm loss: 9.485193, speed: 1.053912 steps/s, speed: 8.431298 samples/s, speed: 4316.824457 tokens/s, learning rate: 2.980e-06, loss_scalings: 26214.400391, pp_loss: 9.468117
[INFO] 2021-07-12 18:31:43,906 [run_pretraining.py:  512]:	********exe.run_299******* 
[INFO] 2021-07-12 18:31:44,850 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:44,850 [run_pretraining.py:  534]:	loss/total_loss, 9.472896575927734, 300
[INFO] 2021-07-12 18:31:44,850 [run_pretraining.py:  535]:	loss/mlm_loss, 9.472896575927734, 300
[INFO] 2021-07-12 18:31:44,850 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.989999984492897e-06, 300
[INFO] 2021-07-12 18:31:44,850 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 300
[INFO] 2021-07-12 18:31:44,850 [run_pretraining.py:  558]:	worker_index: 2, step: 300, cost: 9.472897, mlm loss: 9.472897, speed: 1.059847 steps/s, speed: 8.478773 samples/s, speed: 4341.131979 tokens/s, learning rate: 2.990e-06, loss_scalings: 26214.400391, pp_loss: 9.376640
[INFO] 2021-07-12 18:31:44,851 [run_pretraining.py:  512]:	********exe.run_300******* 
[INFO] 2021-07-12 18:31:45,773 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:45,774 [run_pretraining.py:  534]:	loss/total_loss, 9.337936401367188, 301
[INFO] 2021-07-12 18:31:45,774 [run_pretraining.py:  535]:	loss/mlm_loss, 9.337936401367188, 301
[INFO] 2021-07-12 18:31:45,774 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9999998787388904e-06, 301
[INFO] 2021-07-12 18:31:45,774 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 301
[INFO] 2021-07-12 18:31:45,774 [run_pretraining.py:  558]:	worker_index: 2, step: 301, cost: 9.337936, mlm loss: 9.337936, speed: 1.083100 steps/s, speed: 8.664803 samples/s, speed: 4436.379098 tokens/s, learning rate: 3.000e-06, loss_scalings: 26214.400391, pp_loss: 9.453774
[INFO] 2021-07-12 18:31:45,774 [run_pretraining.py:  512]:	********exe.run_301******* 
[INFO] 2021-07-12 18:31:46,697 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:46,697 [run_pretraining.py:  534]:	loss/total_loss, 9.412778854370117, 302
[INFO] 2021-07-12 18:31:46,697 [run_pretraining.py:  535]:	loss/mlm_loss, 9.412778854370117, 302
[INFO] 2021-07-12 18:31:46,698 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.0099997729848837e-06, 302
[INFO] 2021-07-12 18:31:46,698 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 302
[INFO] 2021-07-12 18:31:46,698 [run_pretraining.py:  558]:	worker_index: 2, step: 302, cost: 9.412779, mlm loss: 9.412779, speed: 1.083636 steps/s, speed: 8.669090 samples/s, speed: 4438.574030 tokens/s, learning rate: 3.010e-06, loss_scalings: 26214.400391, pp_loss: 9.552399
[INFO] 2021-07-12 18:31:46,698 [run_pretraining.py:  512]:	********exe.run_302******* 
[INFO] 2021-07-12 18:31:47,610 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:47,611 [run_pretraining.py:  534]:	loss/total_loss, 9.389084815979004, 303
[INFO] 2021-07-12 18:31:47,611 [run_pretraining.py:  535]:	loss/mlm_loss, 9.389084815979004, 303
[INFO] 2021-07-12 18:31:47,611 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.020000121978228e-06, 303
[INFO] 2021-07-12 18:31:47,611 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 303
[INFO] 2021-07-12 18:31:47,611 [run_pretraining.py:  558]:	worker_index: 2, step: 303, cost: 9.389085, mlm loss: 9.389085, speed: 1.095709 steps/s, speed: 8.765672 samples/s, speed: 4488.024143 tokens/s, learning rate: 3.020e-06, loss_scalings: 26214.400391, pp_loss: 9.448861
[INFO] 2021-07-12 18:31:47,611 [run_pretraining.py:  512]:	********exe.run_303******* 
[INFO] 2021-07-12 18:31:48,522 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:48,522 [run_pretraining.py:  534]:	loss/total_loss, 9.725838661193848, 304
[INFO] 2021-07-12 18:31:48,523 [run_pretraining.py:  535]:	loss/mlm_loss, 9.725838661193848, 304
[INFO] 2021-07-12 18:31:48,523 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.0300000162242213e-06, 304
[INFO] 2021-07-12 18:31:48,523 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 304
[INFO] 2021-07-12 18:31:48,523 [run_pretraining.py:  558]:	worker_index: 2, step: 304, cost: 9.725839, mlm loss: 9.725839, speed: 1.097493 steps/s, speed: 8.779946 samples/s, speed: 4495.332115 tokens/s, learning rate: 3.030e-06, loss_scalings: 26214.400391, pp_loss: 8.916667
[INFO] 2021-07-12 18:31:48,523 [run_pretraining.py:  512]:	********exe.run_304******* 
[INFO] 2021-07-12 18:31:49,431 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:49,432 [run_pretraining.py:  534]:	loss/total_loss, 9.649163246154785, 305
[INFO] 2021-07-12 18:31:49,432 [run_pretraining.py:  535]:	loss/mlm_loss, 9.649163246154785, 305
[INFO] 2021-07-12 18:31:49,432 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.0399999104702147e-06, 305
[INFO] 2021-07-12 18:31:49,432 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 305
[INFO] 2021-07-12 18:31:49,432 [run_pretraining.py:  558]:	worker_index: 2, step: 305, cost: 9.649163, mlm loss: 9.649163, speed: 1.100197 steps/s, speed: 8.801578 samples/s, speed: 4506.407957 tokens/s, learning rate: 3.040e-06, loss_scalings: 26214.400391, pp_loss: 9.260413
[INFO] 2021-07-12 18:31:49,432 [run_pretraining.py:  512]:	********exe.run_305******* 
[INFO] 2021-07-12 18:31:50,348 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:50,348 [run_pretraining.py:  534]:	loss/total_loss, 9.497373580932617, 306
[INFO] 2021-07-12 18:31:50,348 [run_pretraining.py:  535]:	loss/mlm_loss, 9.497373580932617, 306
[INFO] 2021-07-12 18:31:50,348 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.0500000320898835e-06, 306
[INFO] 2021-07-12 18:31:50,348 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 306
[INFO] 2021-07-12 18:31:50,349 [run_pretraining.py:  558]:	worker_index: 2, step: 306, cost: 9.497374, mlm loss: 9.497374, speed: 1.092071 steps/s, speed: 8.736568 samples/s, speed: 4473.122832 tokens/s, learning rate: 3.050e-06, loss_scalings: 26214.400391, pp_loss: 8.288515
[INFO] 2021-07-12 18:31:50,349 [run_pretraining.py:  512]:	********exe.run_306******* 
[INFO] 2021-07-12 18:31:51,252 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:51,252 [run_pretraining.py:  534]:	loss/total_loss, 9.158927917480469, 307
[INFO] 2021-07-12 18:31:51,252 [run_pretraining.py:  535]:	loss/mlm_loss, 9.158927917480469, 307
[INFO] 2021-07-12 18:31:51,252 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.059999926335877e-06, 307
[INFO] 2021-07-12 18:31:51,252 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 307
[INFO] 2021-07-12 18:31:51,252 [run_pretraining.py:  558]:	worker_index: 2, step: 307, cost: 9.158928, mlm loss: 9.158928, speed: 1.107052 steps/s, speed: 8.856417 samples/s, speed: 4534.485629 tokens/s, learning rate: 3.060e-06, loss_scalings: 26214.400391, pp_loss: 9.409151
[INFO] 2021-07-12 18:31:51,253 [run_pretraining.py:  512]:	********exe.run_307******* 
[INFO] 2021-07-12 18:31:52,170 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:52,170 [run_pretraining.py:  534]:	loss/total_loss, 9.283702850341797, 308
[INFO] 2021-07-12 18:31:52,170 [run_pretraining.py:  535]:	loss/mlm_loss, 9.283702850341797, 308
[INFO] 2021-07-12 18:31:52,170 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.06999982058187e-06, 308
[INFO] 2021-07-12 18:31:52,170 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 308
[INFO] 2021-07-12 18:31:52,170 [run_pretraining.py:  558]:	worker_index: 2, step: 308, cost: 9.283703, mlm loss: 9.283703, speed: 1.090128 steps/s, speed: 8.721025 samples/s, speed: 4465.164869 tokens/s, learning rate: 3.070e-06, loss_scalings: 26214.400391, pp_loss: 9.259143
[INFO] 2021-07-12 18:31:52,170 [run_pretraining.py:  512]:	********exe.run_308******* 
[INFO] 2021-07-12 18:31:53,081 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:53,082 [run_pretraining.py:  534]:	loss/total_loss, 9.58237075805664, 309
[INFO] 2021-07-12 18:31:53,082 [run_pretraining.py:  535]:	loss/mlm_loss, 9.58237075805664, 309
[INFO] 2021-07-12 18:31:53,082 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.079999942201539e-06, 309
[INFO] 2021-07-12 18:31:53,082 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 309
[INFO] 2021-07-12 18:31:53,082 [run_pretraining.py:  558]:	worker_index: 2, step: 309, cost: 9.582371, mlm loss: 9.582371, speed: 1.097747 steps/s, speed: 8.781979 samples/s, speed: 4496.373347 tokens/s, learning rate: 3.080e-06, loss_scalings: 26214.400391, pp_loss: 9.480762
[INFO] 2021-07-12 18:31:53,082 [run_pretraining.py:  512]:	********exe.run_309******* 
[INFO] 2021-07-12 18:32:18,917 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:32:18,918 [run_pretraining.py:  534]:	loss/total_loss, 9.659075736999512, 310
[INFO] 2021-07-12 18:32:18,918 [run_pretraining.py:  535]:	loss/mlm_loss, 9.659075736999512, 310
[INFO] 2021-07-12 18:32:18,918 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.0899998364475323e-06, 310
[INFO] 2021-07-12 18:32:18,918 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 310
[INFO] 2021-07-12 18:32:18,918 [run_pretraining.py:  558]:	worker_index: 2, step: 310, cost: 9.659076, mlm loss: 9.659076, speed: 0.038706 steps/s, speed: 0.309648 samples/s, speed: 158.540019 tokens/s, learning rate: 3.090e-06, loss_scalings: 26214.400391, pp_loss: 9.530499
[INFO] 2021-07-12 18:32:18,918 [run_pretraining.py:  512]:	********exe.run_310******* 
[INFO] 2021-07-12 18:32:19,822 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:32:19,822 [run_pretraining.py:  534]:	loss/total_loss, 9.531912803649902, 311
[INFO] 2021-07-12 18:32:19,822 [run_pretraining.py:  535]:	loss/mlm_loss, 9.531912803649902, 311
[INFO] 2021-07-12 18:32:19,823 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.099999958067201e-06, 311
[INFO] 2021-07-12 18:32:19,823 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 311
[INFO] 2021-07-12 18:32:19,823 [run_pretraining.py:  558]:	worker_index: 2, step: 311, cost: 9.531913, mlm loss: 9.531913, speed: 1.106431 steps/s, speed: 8.851446 samples/s, speed: 4531.940182 tokens/s, learning rate: 3.100e-06, loss_scalings: 26214.400391, pp_loss: 9.696679
[INFO] 2021-07-12 18:32:19,823 [run_pretraining.py:  512]:	********exe.run_311******* 
[INFO] 2021-07-12 18:32:20,732 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:32:20,732 [run_pretraining.py:  534]:	loss/total_loss, 9.554540634155273, 312
[INFO] 2021-07-12 18:32:20,733 [run_pretraining.py:  535]:	loss/mlm_loss, 9.554540634155273, 312
[INFO] 2021-07-12 18:32:20,733 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.1099998523131944e-06, 312
[INFO] 2021-07-12 18:32:20,733 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 312
[INFO] 2021-07-12 18:32:20,733 [run_pretraining.py:  558]:	worker_index: 2, step: 312, cost: 9.554541, mlm loss: 9.554541, speed: 1.099519 steps/s, speed: 8.796151 samples/s, speed: 4503.629456 tokens/s, learning rate: 3.110e-06, loss_scalings: 26214.400391, pp_loss: 9.570139
[INFO] 2021-07-12 18:32:20,733 [run_pretraining.py:  512]:	********exe.run_312******* 
[INFO] 2021-07-12 18:32:21,645 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:32:21,646 [run_pretraining.py:  534]:	loss/total_loss, 9.599264144897461, 313
[INFO] 2021-07-12 18:32:21,646 [run_pretraining.py:  535]:	loss/mlm_loss, 9.599264144897461, 313
[INFO] 2021-07-12 18:32:21,646 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.1199997465591878e-06, 313
[INFO] 2021-07-12 18:32:21,646 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 313
[INFO] 2021-07-12 18:32:21,646 [run_pretraining.py:  558]:	worker_index: 2, step: 313, cost: 9.599264, mlm loss: 9.599264, speed: 1.095384 steps/s, speed: 8.763072 samples/s, speed: 4486.692646 tokens/s, learning rate: 3.120e-06, loss_scalings: 26214.400391, pp_loss: 9.644892
[INFO] 2021-07-12 18:32:21,646 [run_pretraining.py:  512]:	********exe.run_313******* 
[INFO] 2021-07-12 18:32:48,137 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:32:48,137 [run_pretraining.py:  534]:	loss/total_loss, 9.331765174865723, 314
[INFO] 2021-07-12 18:32:48,138 [run_pretraining.py:  535]:	loss/mlm_loss, 9.331765174865723, 314
[INFO] 2021-07-12 18:32:48,138 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.130000095552532e-06, 314
[INFO] 2021-07-12 18:32:48,138 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 314
[INFO] 2021-07-12 18:32:48,138 [run_pretraining.py:  558]:	worker_index: 2, step: 314, cost: 9.331765, mlm loss: 9.331765, speed: 0.037749 steps/s, speed: 0.301991 samples/s, speed: 154.619552 tokens/s, learning rate: 3.130e-06, loss_scalings: 26214.400391, pp_loss: 8.621998
[INFO] 2021-07-12 18:32:48,138 [run_pretraining.py:  512]:	********exe.run_314******* 
[INFO] 2021-07-12 18:33:14,239 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:14,240 [run_pretraining.py:  534]:	loss/total_loss, 9.360827445983887, 315
[INFO] 2021-07-12 18:33:14,240 [run_pretraining.py:  535]:	loss/mlm_loss, 9.360827445983887, 315
[INFO] 2021-07-12 18:33:14,240 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.13999976242485e-06, 315
[INFO] 2021-07-12 18:33:14,240 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 315
[INFO] 2021-07-12 18:33:14,240 [run_pretraining.py:  558]:	worker_index: 2, step: 315, cost: 9.360827, mlm loss: 9.360827, speed: 0.038312 steps/s, speed: 0.306494 samples/s, speed: 156.925069 tokens/s, learning rate: 3.140e-06, loss_scalings: 26214.400391, pp_loss: 9.537373
[INFO] 2021-07-12 18:33:14,240 [run_pretraining.py:  512]:	********exe.run_315******* 
[INFO] 2021-07-12 18:33:15,170 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:15,171 [run_pretraining.py:  534]:	loss/total_loss, 9.59498119354248, 316
[INFO] 2021-07-12 18:33:15,171 [run_pretraining.py:  535]:	loss/mlm_loss, 9.59498119354248, 316
[INFO] 2021-07-12 18:33:15,171 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.1499998840445187e-06, 316
[INFO] 2021-07-12 18:33:15,171 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 316
[INFO] 2021-07-12 18:33:15,171 [run_pretraining.py:  558]:	worker_index: 2, step: 316, cost: 9.594981, mlm loss: 9.594981, speed: 1.074511 steps/s, speed: 8.596092 samples/s, speed: 4401.199037 tokens/s, learning rate: 3.150e-06, loss_scalings: 26214.400391, pp_loss: 8.255053
[INFO] 2021-07-12 18:33:15,171 [run_pretraining.py:  512]:	********exe.run_316******* 
[INFO] 2021-07-12 18:33:16,090 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:16,091 [run_pretraining.py:  534]:	loss/total_loss, 9.520463943481445, 317
[INFO] 2021-07-12 18:33:16,091 [run_pretraining.py:  535]:	loss/mlm_loss, 9.520463943481445, 317
[INFO] 2021-07-12 18:33:16,091 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.159999778290512e-06, 317
[INFO] 2021-07-12 18:33:16,091 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 317
[INFO] 2021-07-12 18:33:16,091 [run_pretraining.py:  558]:	worker_index: 2, step: 317, cost: 9.520464, mlm loss: 9.520464, speed: 1.087881 steps/s, speed: 8.703047 samples/s, speed: 4455.960017 tokens/s, learning rate: 3.160e-06, loss_scalings: 26214.400391, pp_loss: 9.561968
[INFO] 2021-07-12 18:33:16,091 [run_pretraining.py:  512]:	********exe.run_317******* 
[INFO] 2021-07-12 18:33:17,006 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:17,006 [run_pretraining.py:  534]:	loss/total_loss, 9.326910018920898, 318
[INFO] 2021-07-12 18:33:17,006 [run_pretraining.py:  535]:	loss/mlm_loss, 9.326910018920898, 318
[INFO] 2021-07-12 18:33:17,006 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.169999899910181e-06, 318
[INFO] 2021-07-12 18:33:17,006 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 318
[INFO] 2021-07-12 18:33:17,006 [run_pretraining.py:  558]:	worker_index: 2, step: 318, cost: 9.326910, mlm loss: 9.326910, speed: 1.093329 steps/s, speed: 8.746632 samples/s, speed: 4478.275424 tokens/s, learning rate: 3.170e-06, loss_scalings: 26214.400391, pp_loss: 9.335222
[INFO] 2021-07-12 18:33:17,006 [run_pretraining.py:  512]:	********exe.run_318******* 
[INFO] 2021-07-12 18:33:17,914 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:17,914 [run_pretraining.py:  534]:	loss/total_loss, 9.196855545043945, 319
[INFO] 2021-07-12 18:33:17,914 [run_pretraining.py:  535]:	loss/mlm_loss, 9.196855545043945, 319
[INFO] 2021-07-12 18:33:17,914 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.1800000215298496e-06, 319
[INFO] 2021-07-12 18:33:17,914 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 319
[INFO] 2021-07-12 18:33:17,914 [run_pretraining.py:  558]:	worker_index: 2, step: 319, cost: 9.196856, mlm loss: 9.196856, speed: 1.101915 steps/s, speed: 8.815318 samples/s, speed: 4513.442749 tokens/s, learning rate: 3.180e-06, loss_scalings: 26214.400391, pp_loss: 9.371117
[INFO] 2021-07-12 18:33:17,915 [run_pretraining.py:  512]:	********exe.run_319******* 
[INFO] 2021-07-12 18:33:18,828 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:18,829 [run_pretraining.py:  534]:	loss/total_loss, 9.55301284790039, 320
[INFO] 2021-07-12 18:33:18,829 [run_pretraining.py:  535]:	loss/mlm_loss, 9.55301284790039, 320
[INFO] 2021-07-12 18:33:18,829 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.189999915775843e-06, 320
[INFO] 2021-07-12 18:33:18,829 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 320
[INFO] 2021-07-12 18:33:18,829 [run_pretraining.py:  558]:	worker_index: 2, step: 320, cost: 9.553013, mlm loss: 9.553013, speed: 1.094317 steps/s, speed: 8.754539 samples/s, speed: 4482.323955 tokens/s, learning rate: 3.190e-06, loss_scalings: 26214.400391, pp_loss: 9.423842
[INFO] 2021-07-12 18:33:18,829 [run_pretraining.py:  512]:	********exe.run_320******* 
[INFO] 2021-07-12 18:33:19,742 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:19,742 [run_pretraining.py:  534]:	loss/total_loss, 9.621932983398438, 321
[INFO] 2021-07-12 18:33:19,742 [run_pretraining.py:  535]:	loss/mlm_loss, 9.621932983398438, 321
[INFO] 2021-07-12 18:33:19,743 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.2000000373955118e-06, 321
[INFO] 2021-07-12 18:33:19,743 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 321
[INFO] 2021-07-12 18:33:19,743 [run_pretraining.py:  558]:	worker_index: 2, step: 321, cost: 9.621933, mlm loss: 9.621933, speed: 1.095036 steps/s, speed: 8.760287 samples/s, speed: 4485.267087 tokens/s, learning rate: 3.200e-06, loss_scalings: 26214.400391, pp_loss: 9.313606
[INFO] 2021-07-12 18:33:19,743 [run_pretraining.py:  512]:	********exe.run_321******* 
[INFO] 2021-07-12 18:33:20,648 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:20,648 [run_pretraining.py:  534]:	loss/total_loss, 9.458962440490723, 322
[INFO] 2021-07-12 18:33:20,648 [run_pretraining.py:  535]:	loss/mlm_loss, 9.458962440490723, 322
[INFO] 2021-07-12 18:33:20,648 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.209999931641505e-06, 322
[INFO] 2021-07-12 18:33:20,648 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 322
[INFO] 2021-07-12 18:33:20,648 [run_pretraining.py:  558]:	worker_index: 2, step: 322, cost: 9.458962, mlm loss: 9.458962, speed: 1.104828 steps/s, speed: 8.838627 samples/s, speed: 4525.376859 tokens/s, learning rate: 3.210e-06, loss_scalings: 26214.400391, pp_loss: 9.363411
[INFO] 2021-07-12 18:33:20,649 [run_pretraining.py:  512]:	********exe.run_322******* 
[INFO] 2021-07-12 18:33:21,560 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:21,560 [run_pretraining.py:  534]:	loss/total_loss, 9.151984214782715, 323
[INFO] 2021-07-12 18:33:21,560 [run_pretraining.py:  535]:	loss/mlm_loss, 9.151984214782715, 323
[INFO] 2021-07-12 18:33:21,560 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.220000053261174e-06, 323
[INFO] 2021-07-12 18:33:21,560 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 323
[INFO] 2021-07-12 18:33:21,560 [run_pretraining.py:  558]:	worker_index: 2, step: 323, cost: 9.151984, mlm loss: 9.151984, speed: 1.097203 steps/s, speed: 8.777626 samples/s, speed: 4494.144405 tokens/s, learning rate: 3.220e-06, loss_scalings: 26214.400391, pp_loss: 9.363906
[INFO] 2021-07-12 18:33:21,561 [run_pretraining.py:  512]:	********exe.run_323******* 
[INFO] 2021-07-12 18:33:22,472 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:22,473 [run_pretraining.py:  534]:	loss/total_loss, 9.5037841796875, 324
[INFO] 2021-07-12 18:33:22,473 [run_pretraining.py:  535]:	loss/mlm_loss, 9.5037841796875, 324
[INFO] 2021-07-12 18:33:22,473 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.229999720133492e-06, 324
[INFO] 2021-07-12 18:33:22,473 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 324
[INFO] 2021-07-12 18:33:22,473 [run_pretraining.py:  558]:	worker_index: 2, step: 324, cost: 9.503784, mlm loss: 9.503784, speed: 1.096574 steps/s, speed: 8.772591 samples/s, speed: 4491.566532 tokens/s, learning rate: 3.230e-06, loss_scalings: 26214.400391, pp_loss: 9.476084
[INFO] 2021-07-12 18:33:22,473 [run_pretraining.py:  512]:	********exe.run_324******* 
[INFO] 2021-07-12 18:33:23,387 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:23,387 [run_pretraining.py:  534]:	loss/total_loss, 9.154708862304688, 325
[INFO] 2021-07-12 18:33:23,387 [run_pretraining.py:  535]:	loss/mlm_loss, 9.154708862304688, 325
[INFO] 2021-07-12 18:33:23,387 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.240000069126836e-06, 325
[INFO] 2021-07-12 18:33:23,388 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 325
[INFO] 2021-07-12 18:33:23,388 [run_pretraining.py:  558]:	worker_index: 2, step: 325, cost: 9.154709, mlm loss: 9.154709, speed: 1.094073 steps/s, speed: 8.752582 samples/s, speed: 4481.321949 tokens/s, learning rate: 3.240e-06, loss_scalings: 26214.400391, pp_loss: 9.454706
[INFO] 2021-07-12 18:33:23,388 [run_pretraining.py:  512]:	********exe.run_325******* 
[INFO] 2021-07-12 18:33:49,756 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:49,757 [run_pretraining.py:  534]:	loss/total_loss, 9.483832359313965, 326
[INFO] 2021-07-12 18:33:49,757 [run_pretraining.py:  535]:	loss/mlm_loss, 9.483832359313965, 326
[INFO] 2021-07-12 18:33:49,757 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.249999735999154e-06, 326
[INFO] 2021-07-12 18:33:49,757 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 326
[INFO] 2021-07-12 18:33:49,757 [run_pretraining.py:  558]:	worker_index: 2, step: 326, cost: 9.483832, mlm loss: 9.483832, speed: 0.037923 steps/s, speed: 0.303388 samples/s, speed: 155.334615 tokens/s, learning rate: 3.250e-06, loss_scalings: 20971.521484, pp_loss: 9.428920
[INFO] 2021-07-12 18:33:49,757 [run_pretraining.py:  512]:	********exe.run_326******* 
[INFO] 2021-07-12 18:33:50,685 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:50,686 [run_pretraining.py:  534]:	loss/total_loss, 9.591270446777344, 327
[INFO] 2021-07-12 18:33:50,686 [run_pretraining.py:  535]:	loss/mlm_loss, 9.591270446777344, 327
[INFO] 2021-07-12 18:33:50,686 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.2599998576188227e-06, 327
[INFO] 2021-07-12 18:33:50,686 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 327
[INFO] 2021-07-12 18:33:50,686 [run_pretraining.py:  558]:	worker_index: 2, step: 327, cost: 9.591270, mlm loss: 9.591270, speed: 1.077297 steps/s, speed: 8.618376 samples/s, speed: 4412.608543 tokens/s, learning rate: 3.260e-06, loss_scalings: 20971.521484, pp_loss: 9.411824
[INFO] 2021-07-12 18:33:50,686 [run_pretraining.py:  512]:	********exe.run_327******* 
[INFO] 2021-07-12 18:33:51,614 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:51,614 [run_pretraining.py:  534]:	loss/total_loss, 9.443730354309082, 328
[INFO] 2021-07-12 18:33:51,614 [run_pretraining.py:  535]:	loss/mlm_loss, 9.443730354309082, 328
[INFO] 2021-07-12 18:33:51,614 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.269999751864816e-06, 328
[INFO] 2021-07-12 18:33:51,614 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 328
[INFO] 2021-07-12 18:33:51,614 [run_pretraining.py:  558]:	worker_index: 2, step: 328, cost: 9.443730, mlm loss: 9.443730, speed: 1.077681 steps/s, speed: 8.621445 samples/s, speed: 4414.179950 tokens/s, learning rate: 3.270e-06, loss_scalings: 20971.521484, pp_loss: 9.245497
[INFO] 2021-07-12 18:33:51,615 [run_pretraining.py:  512]:	********exe.run_328******* 
[INFO] 2021-07-12 18:33:52,541 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:52,542 [run_pretraining.py:  534]:	loss/total_loss, 9.404245376586914, 329
[INFO] 2021-07-12 18:33:52,542 [run_pretraining.py:  535]:	loss/mlm_loss, 9.404245376586914, 329
[INFO] 2021-07-12 18:33:52,542 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.279999873484485e-06, 329
[INFO] 2021-07-12 18:33:52,542 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 329
[INFO] 2021-07-12 18:33:52,542 [run_pretraining.py:  558]:	worker_index: 2, step: 329, cost: 9.404245, mlm loss: 9.404245, speed: 1.078763 steps/s, speed: 8.630106 samples/s, speed: 4418.614490 tokens/s, learning rate: 3.280e-06, loss_scalings: 20971.521484, pp_loss: 9.368671
[INFO] 2021-07-12 18:33:52,542 [run_pretraining.py:  512]:	********exe.run_329******* 
[INFO] 2021-07-12 18:33:53,474 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:53,474 [run_pretraining.py:  534]:	loss/total_loss, 9.48947811126709, 330
[INFO] 2021-07-12 18:33:53,475 [run_pretraining.py:  535]:	loss/mlm_loss, 9.48947811126709, 330
[INFO] 2021-07-12 18:33:53,475 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.2899999951041536e-06, 330
[INFO] 2021-07-12 18:33:53,475 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 330
[INFO] 2021-07-12 18:33:53,475 [run_pretraining.py:  558]:	worker_index: 2, step: 330, cost: 9.489478, mlm loss: 9.489478, speed: 1.072724 steps/s, speed: 8.581795 samples/s, speed: 4393.879005 tokens/s, learning rate: 3.290e-06, loss_scalings: 20971.521484, pp_loss: 8.474627
[INFO] 2021-07-12 18:33:53,475 [run_pretraining.py:  512]:	********exe.run_330******* 
[INFO] 2021-07-12 18:33:54,409 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:54,410 [run_pretraining.py:  534]:	loss/total_loss, 8.705005645751953, 331
[INFO] 2021-07-12 18:33:54,410 [run_pretraining.py:  535]:	loss/mlm_loss, 8.705005645751953, 331
[INFO] 2021-07-12 18:33:54,410 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.299999889350147e-06, 331
[INFO] 2021-07-12 18:33:54,410 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 331
[INFO] 2021-07-12 18:33:54,410 [run_pretraining.py:  558]:	worker_index: 2, step: 331, cost: 8.705006, mlm loss: 8.705006, speed: 1.070001 steps/s, speed: 8.560007 samples/s, speed: 4382.723668 tokens/s, learning rate: 3.300e-06, loss_scalings: 20971.521484, pp_loss: 9.243198
[INFO] 2021-07-12 18:33:54,410 [run_pretraining.py:  512]:	********exe.run_331******* 
[INFO] 2021-07-12 18:33:55,344 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:55,344 [run_pretraining.py:  534]:	loss/total_loss, 9.555124282836914, 332
[INFO] 2021-07-12 18:33:55,344 [run_pretraining.py:  535]:	loss/mlm_loss, 9.555124282836914, 332
[INFO] 2021-07-12 18:33:55,345 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.3100000109698158e-06, 332
[INFO] 2021-07-12 18:33:55,345 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 332
[INFO] 2021-07-12 18:33:55,345 [run_pretraining.py:  558]:	worker_index: 2, step: 332, cost: 9.555124, mlm loss: 9.555124, speed: 1.070617 steps/s, speed: 8.564932 samples/s, speed: 4385.245244 tokens/s, learning rate: 3.310e-06, loss_scalings: 20971.521484, pp_loss: 9.367958
[INFO] 2021-07-12 18:33:55,345 [run_pretraining.py:  512]:	********exe.run_332******* 
[INFO] 2021-07-12 18:33:56,267 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:56,268 [run_pretraining.py:  534]:	loss/total_loss, 9.68231201171875, 333
[INFO] 2021-07-12 18:33:56,268 [run_pretraining.py:  535]:	loss/mlm_loss, 9.68231201171875, 333
[INFO] 2021-07-12 18:33:56,268 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.319999905215809e-06, 333
[INFO] 2021-07-12 18:33:56,268 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 333
[INFO] 2021-07-12 18:33:56,268 [run_pretraining.py:  558]:	worker_index: 2, step: 333, cost: 9.682312, mlm loss: 9.682312, speed: 1.083710 steps/s, speed: 8.669683 samples/s, speed: 4438.877938 tokens/s, learning rate: 3.320e-06, loss_scalings: 20971.521484, pp_loss: 9.629805
[INFO] 2021-07-12 18:33:56,268 [run_pretraining.py:  512]:	********exe.run_333******* 
[INFO] 2021-07-12 18:33:57,190 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:57,190 [run_pretraining.py:  534]:	loss/total_loss, 9.385540008544922, 334
[INFO] 2021-07-12 18:33:57,190 [run_pretraining.py:  535]:	loss/mlm_loss, 9.385540008544922, 334
[INFO] 2021-07-12 18:33:57,190 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.330000026835478e-06, 334
[INFO] 2021-07-12 18:33:57,190 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 334
[INFO] 2021-07-12 18:33:57,190 [run_pretraining.py:  558]:	worker_index: 2, step: 334, cost: 9.385540, mlm loss: 9.385540, speed: 1.084803 steps/s, speed: 8.678422 samples/s, speed: 4443.351923 tokens/s, learning rate: 3.330e-06, loss_scalings: 20971.521484, pp_loss: 8.703871
[INFO] 2021-07-12 18:33:57,190 [run_pretraining.py:  512]:	********exe.run_334******* 
[INFO] 2021-07-12 18:33:58,124 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:58,125 [run_pretraining.py:  534]:	loss/total_loss, 8.866903305053711, 335
[INFO] 2021-07-12 18:33:58,125 [run_pretraining.py:  535]:	loss/mlm_loss, 8.866903305053711, 335
[INFO] 2021-07-12 18:33:58,125 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.3399999210814713e-06, 335
[INFO] 2021-07-12 18:33:58,125 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 335
[INFO] 2021-07-12 18:33:58,125 [run_pretraining.py:  558]:	worker_index: 2, step: 335, cost: 8.866903, mlm loss: 8.866903, speed: 1.070456 steps/s, speed: 8.563645 samples/s, speed: 4384.586042 tokens/s, learning rate: 3.340e-06, loss_scalings: 20971.521484, pp_loss: 9.228428
[INFO] 2021-07-12 18:33:58,125 [run_pretraining.py:  512]:	********exe.run_335******* 
[INFO] 2021-07-12 18:33:59,046 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:59,046 [run_pretraining.py:  534]:	loss/total_loss, 9.22372055053711, 336
[INFO] 2021-07-12 18:33:59,046 [run_pretraining.py:  535]:	loss/mlm_loss, 9.22372055053711, 336
[INFO] 2021-07-12 18:33:59,046 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.35000004270114e-06, 336
[INFO] 2021-07-12 18:33:59,047 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 336
[INFO] 2021-07-12 18:33:59,047 [run_pretraining.py:  558]:	worker_index: 2, step: 336, cost: 9.223721, mlm loss: 9.223721, speed: 1.086012 steps/s, speed: 8.688095 samples/s, speed: 4448.304811 tokens/s, learning rate: 3.350e-06, loss_scalings: 20971.521484, pp_loss: 9.389555
[INFO] 2021-07-12 18:33:59,047 [run_pretraining.py:  512]:	********exe.run_336******* 
[INFO] 2021-07-12 18:33:59,972 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:59,973 [run_pretraining.py:  534]:	loss/total_loss, 9.018068313598633, 337
[INFO] 2021-07-12 18:33:59,973 [run_pretraining.py:  535]:	loss/mlm_loss, 9.018068313598633, 337
[INFO] 2021-07-12 18:33:59,973 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.359999709573458e-06, 337
[INFO] 2021-07-12 18:33:59,973 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 337
[INFO] 2021-07-12 18:33:59,973 [run_pretraining.py:  558]:	worker_index: 2, step: 337, cost: 9.018068, mlm loss: 9.018068, speed: 1.080317 steps/s, speed: 8.642537 samples/s, speed: 4424.978701 tokens/s, learning rate: 3.360e-06, loss_scalings: 20971.521484, pp_loss: 9.372849
[INFO] 2021-07-12 18:33:59,973 [run_pretraining.py:  512]:	********exe.run_337******* 
[INFO] 2021-07-12 18:34:00,895 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:00,895 [run_pretraining.py:  534]:	loss/total_loss, 9.41100788116455, 338
[INFO] 2021-07-12 18:34:00,896 [run_pretraining.py:  535]:	loss/mlm_loss, 9.41100788116455, 338
[INFO] 2021-07-12 18:34:00,896 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.370000058566802e-06, 338
[INFO] 2021-07-12 18:34:00,896 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 338
[INFO] 2021-07-12 18:34:00,896 [run_pretraining.py:  558]:	worker_index: 2, step: 338, cost: 9.411008, mlm loss: 9.411008, speed: 1.084186 steps/s, speed: 8.673484 samples/s, speed: 4440.823938 tokens/s, learning rate: 3.370e-06, loss_scalings: 20971.521484, pp_loss: 8.987988
[INFO] 2021-07-12 18:34:00,896 [run_pretraining.py:  512]:	********exe.run_338******* 
[INFO] 2021-07-12 18:34:01,822 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:01,823 [run_pretraining.py:  534]:	loss/total_loss, 9.651491165161133, 339
[INFO] 2021-07-12 18:34:01,823 [run_pretraining.py:  535]:	loss/mlm_loss, 9.651491165161133, 339
[INFO] 2021-07-12 18:34:01,823 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.37999972543912e-06, 339
[INFO] 2021-07-12 18:34:01,823 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 339
[INFO] 2021-07-12 18:34:01,823 [run_pretraining.py:  558]:	worker_index: 2, step: 339, cost: 9.651491, mlm loss: 9.651491, speed: 1.079212 steps/s, speed: 8.633695 samples/s, speed: 4420.451765 tokens/s, learning rate: 3.380e-06, loss_scalings: 20971.521484, pp_loss: 9.380465
[INFO] 2021-07-12 18:34:01,823 [run_pretraining.py:  512]:	********exe.run_339******* 
[INFO] 2021-07-12 18:34:02,750 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:02,751 [run_pretraining.py:  534]:	loss/total_loss, 9.345781326293945, 340
[INFO] 2021-07-12 18:34:02,751 [run_pretraining.py:  535]:	loss/mlm_loss, 9.345781326293945, 340
[INFO] 2021-07-12 18:34:02,751 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.389999847058789e-06, 340
[INFO] 2021-07-12 18:34:02,751 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 340
[INFO] 2021-07-12 18:34:02,751 [run_pretraining.py:  558]:	worker_index: 2, step: 340, cost: 9.345781, mlm loss: 9.345781, speed: 1.078075 steps/s, speed: 8.624603 samples/s, speed: 4415.796742 tokens/s, learning rate: 3.390e-06, loss_scalings: 20971.521484, pp_loss: 9.385208
[INFO] 2021-07-12 18:34:02,751 [run_pretraining.py:  512]:	********exe.run_340******* 
[INFO] 2021-07-12 18:34:03,673 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:03,673 [run_pretraining.py:  534]:	loss/total_loss, 9.342751502990723, 341
[INFO] 2021-07-12 18:34:03,673 [run_pretraining.py:  535]:	loss/mlm_loss, 9.342751502990723, 341
[INFO] 2021-07-12 18:34:03,674 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.400000196052133e-06, 341
[INFO] 2021-07-12 18:34:03,674 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 341
[INFO] 2021-07-12 18:34:03,674 [run_pretraining.py:  558]:	worker_index: 2, step: 341, cost: 9.342752, mlm loss: 9.342752, speed: 1.084663 steps/s, speed: 8.677306 samples/s, speed: 4442.780836 tokens/s, learning rate: 3.400e-06, loss_scalings: 20971.521484, pp_loss: 9.197783
[INFO] 2021-07-12 18:34:03,674 [run_pretraining.py:  512]:	********exe.run_341******* 
[INFO] 2021-07-12 18:34:04,596 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:04,597 [run_pretraining.py:  534]:	loss/total_loss, 8.967155456542969, 342
[INFO] 2021-07-12 18:34:04,597 [run_pretraining.py:  535]:	loss/mlm_loss, 8.967155456542969, 342
[INFO] 2021-07-12 18:34:04,597 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.409999862924451e-06, 342
[INFO] 2021-07-12 18:34:04,597 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 342
[INFO] 2021-07-12 18:34:04,597 [run_pretraining.py:  558]:	worker_index: 2, step: 342, cost: 8.967155, mlm loss: 8.967155, speed: 1.083444 steps/s, speed: 8.667556 samples/s, speed: 4437.788648 tokens/s, learning rate: 3.410e-06, loss_scalings: 20971.521484, pp_loss: 9.230240
[INFO] 2021-07-12 18:34:04,597 [run_pretraining.py:  512]:	********exe.run_342******* 
[INFO] 2021-07-12 18:34:30,468 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:30,469 [run_pretraining.py:  534]:	loss/total_loss, 9.032692909240723, 343
[INFO] 2021-07-12 18:34:30,469 [run_pretraining.py:  535]:	loss/mlm_loss, 9.032692909240723, 343
[INFO] 2021-07-12 18:34:30,469 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.41999998454412e-06, 343
[INFO] 2021-07-12 18:34:30,469 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 343
[INFO] 2021-07-12 18:34:30,469 [run_pretraining.py:  558]:	worker_index: 2, step: 343, cost: 9.032693, mlm loss: 9.032693, speed: 0.038653 steps/s, speed: 0.309222 samples/s, speed: 158.321507 tokens/s, learning rate: 3.420e-06, loss_scalings: 20971.521484, pp_loss: 9.086960
[INFO] 2021-07-12 18:34:30,469 [run_pretraining.py:  512]:	********exe.run_343******* 
[INFO] 2021-07-12 18:34:31,389 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:31,389 [run_pretraining.py:  534]:	loss/total_loss, 9.772619247436523, 344
[INFO] 2021-07-12 18:34:31,389 [run_pretraining.py:  535]:	loss/mlm_loss, 9.772619247436523, 344
[INFO] 2021-07-12 18:34:31,390 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.429999878790113e-06, 344
[INFO] 2021-07-12 18:34:31,390 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 344
[INFO] 2021-07-12 18:34:31,390 [run_pretraining.py:  558]:	worker_index: 2, step: 344, cost: 9.772619, mlm loss: 9.772619, speed: 1.087327 steps/s, speed: 8.698614 samples/s, speed: 4453.690132 tokens/s, learning rate: 3.430e-06, loss_scalings: 20971.521484, pp_loss: 9.465992
[INFO] 2021-07-12 18:34:31,390 [run_pretraining.py:  512]:	********exe.run_344******* 
[INFO] 2021-07-12 18:34:32,312 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:32,313 [run_pretraining.py:  534]:	loss/total_loss, 9.340498924255371, 345
[INFO] 2021-07-12 18:34:32,313 [run_pretraining.py:  535]:	loss/mlm_loss, 9.340498924255371, 345
[INFO] 2021-07-12 18:34:32,313 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.440000000409782e-06, 345
[INFO] 2021-07-12 18:34:32,313 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 345
[INFO] 2021-07-12 18:34:32,313 [run_pretraining.py:  558]:	worker_index: 2, step: 345, cost: 9.340499, mlm loss: 9.340499, speed: 1.083426 steps/s, speed: 8.667408 samples/s, speed: 4437.712991 tokens/s, learning rate: 3.440e-06, loss_scalings: 20971.521484, pp_loss: 9.259084
[INFO] 2021-07-12 18:34:32,313 [run_pretraining.py:  512]:	********exe.run_345******* 
[INFO] 2021-07-12 18:34:33,229 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:33,230 [run_pretraining.py:  534]:	loss/total_loss, 9.439356803894043, 346
[INFO] 2021-07-12 18:34:33,230 [run_pretraining.py:  535]:	loss/mlm_loss, 9.439356803894043, 346
[INFO] 2021-07-12 18:34:33,230 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.4499998946557753e-06, 346
[INFO] 2021-07-12 18:34:33,230 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 346
[INFO] 2021-07-12 18:34:33,230 [run_pretraining.py:  558]:	worker_index: 2, step: 346, cost: 9.439357, mlm loss: 9.439357, speed: 1.091569 steps/s, speed: 8.732555 samples/s, speed: 4471.068139 tokens/s, learning rate: 3.450e-06, loss_scalings: 20971.521484, pp_loss: 8.410708
[INFO] 2021-07-12 18:34:33,230 [run_pretraining.py:  512]:	********exe.run_346******* 
[INFO] 2021-07-12 18:34:34,153 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:34,153 [run_pretraining.py:  534]:	loss/total_loss, 9.348076820373535, 347
[INFO] 2021-07-12 18:34:34,154 [run_pretraining.py:  535]:	loss/mlm_loss, 9.348076820373535, 347
[INFO] 2021-07-12 18:34:34,154 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.460000016275444e-06, 347
[INFO] 2021-07-12 18:34:34,154 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 347
[INFO] 2021-07-12 18:34:34,154 [run_pretraining.py:  558]:	worker_index: 2, step: 347, cost: 9.348077, mlm loss: 9.348077, speed: 1.083191 steps/s, speed: 8.665530 samples/s, speed: 4436.751453 tokens/s, learning rate: 3.460e-06, loss_scalings: 20971.521484, pp_loss: 9.272778
[INFO] 2021-07-12 18:34:34,154 [run_pretraining.py:  512]:	********exe.run_347******* 
[INFO] 2021-07-12 18:34:35,079 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:35,080 [run_pretraining.py:  534]:	loss/total_loss, 9.60560417175293, 348
[INFO] 2021-07-12 18:34:35,080 [run_pretraining.py:  535]:	loss/mlm_loss, 9.60560417175293, 348
[INFO] 2021-07-12 18:34:35,080 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.469999683147762e-06, 348
[INFO] 2021-07-12 18:34:35,080 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 348
[INFO] 2021-07-12 18:34:35,080 [run_pretraining.py:  558]:	worker_index: 2, step: 348, cost: 9.605604, mlm loss: 9.605604, speed: 1.080152 steps/s, speed: 8.641214 samples/s, speed: 4424.301805 tokens/s, learning rate: 3.470e-06, loss_scalings: 20971.521484, pp_loss: 9.371271
[INFO] 2021-07-12 18:34:35,080 [run_pretraining.py:  512]:	********exe.run_348******* 
[INFO] 2021-07-12 18:34:35,995 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:35,995 [run_pretraining.py:  534]:	loss/total_loss, 9.671707153320312, 349
[INFO] 2021-07-12 18:34:35,995 [run_pretraining.py:  535]:	loss/mlm_loss, 9.671707153320312, 349
[INFO] 2021-07-12 18:34:35,995 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.480000032141106e-06, 349
[INFO] 2021-07-12 18:34:35,996 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 349
[INFO] 2021-07-12 18:34:35,996 [run_pretraining.py:  558]:	worker_index: 2, step: 349, cost: 9.671707, mlm loss: 9.671707, speed: 1.093050 steps/s, speed: 8.744400 samples/s, speed: 4477.132879 tokens/s, learning rate: 3.480e-06, loss_scalings: 20971.521484, pp_loss: 9.515658
[INFO] 2021-07-12 18:34:35,996 [run_pretraining.py:  512]:	********exe.run_349******* 
[INFO] 2021-07-12 18:34:36,916 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:36,917 [run_pretraining.py:  534]:	loss/total_loss, 9.490325927734375, 350
[INFO] 2021-07-12 18:34:36,917 [run_pretraining.py:  535]:	loss/mlm_loss, 9.490325927734375, 350
[INFO] 2021-07-12 18:34:36,917 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.489999699013424e-06, 350
[INFO] 2021-07-12 18:34:36,917 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 350
[INFO] 2021-07-12 18:34:36,917 [run_pretraining.py:  558]:	worker_index: 2, step: 350, cost: 9.490326, mlm loss: 9.490326, speed: 1.085679 steps/s, speed: 8.685428 samples/s, speed: 4446.939220 tokens/s, learning rate: 3.490e-06, loss_scalings: 20971.521484, pp_loss: 9.389497
[INFO] 2021-07-12 18:34:36,917 [run_pretraining.py:  512]:	********exe.run_350******* 
[INFO] 2021-07-12 18:34:37,837 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:37,838 [run_pretraining.py:  534]:	loss/total_loss, 9.21867847442627, 351
[INFO] 2021-07-12 18:34:37,838 [run_pretraining.py:  535]:	loss/mlm_loss, 9.21867847442627, 351
[INFO] 2021-07-12 18:34:37,838 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.499999820633093e-06, 351
[INFO] 2021-07-12 18:34:37,838 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 351
[INFO] 2021-07-12 18:34:37,838 [run_pretraining.py:  558]:	worker_index: 2, step: 351, cost: 9.218678, mlm loss: 9.218678, speed: 1.086708 steps/s, speed: 8.693667 samples/s, speed: 4451.157293 tokens/s, learning rate: 3.500e-06, loss_scalings: 20971.521484, pp_loss: 9.269459
[INFO] 2021-07-12 18:34:37,838 [run_pretraining.py:  512]:	********exe.run_351******* 
[INFO] 2021-07-12 18:34:38,763 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:38,763 [run_pretraining.py:  534]:	loss/total_loss, 9.651695251464844, 352
[INFO] 2021-07-12 18:34:38,763 [run_pretraining.py:  535]:	loss/mlm_loss, 9.651695251464844, 352
[INFO] 2021-07-12 18:34:38,764 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.510000169626437e-06, 352
[INFO] 2021-07-12 18:34:38,764 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 352
[INFO] 2021-07-12 18:34:38,764 [run_pretraining.py:  558]:	worker_index: 2, step: 352, cost: 9.651695, mlm loss: 9.651695, speed: 1.081131 steps/s, speed: 8.649050 samples/s, speed: 4428.313788 tokens/s, learning rate: 3.510e-06, loss_scalings: 20971.521484, pp_loss: 9.278533
[INFO] 2021-07-12 18:34:38,764 [run_pretraining.py:  512]:	********exe.run_352******* 
[INFO] 2021-07-12 18:34:39,694 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:39,694 [run_pretraining.py:  534]:	loss/total_loss, 9.223283767700195, 353
[INFO] 2021-07-12 18:34:39,694 [run_pretraining.py:  535]:	loss/mlm_loss, 9.223283767700195, 353
[INFO] 2021-07-12 18:34:39,695 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.519999836498755e-06, 353
[INFO] 2021-07-12 18:34:39,695 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 353
[INFO] 2021-07-12 18:34:39,695 [run_pretraining.py:  558]:	worker_index: 2, step: 353, cost: 9.223284, mlm loss: 9.223284, speed: 1.074776 steps/s, speed: 8.598204 samples/s, speed: 4402.280589 tokens/s, learning rate: 3.520e-06, loss_scalings: 20971.521484, pp_loss: 9.241718
[INFO] 2021-07-12 18:34:39,695 [run_pretraining.py:  512]:	********exe.run_353******* 
[INFO] 2021-07-12 18:34:40,619 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:40,620 [run_pretraining.py:  534]:	loss/total_loss, 9.263124465942383, 354
[INFO] 2021-07-12 18:34:40,620 [run_pretraining.py:  535]:	loss/mlm_loss, 9.263124465942383, 354
[INFO] 2021-07-12 18:34:40,620 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.529999958118424e-06, 354
[INFO] 2021-07-12 18:34:40,620 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 354
[INFO] 2021-07-12 18:34:40,620 [run_pretraining.py:  558]:	worker_index: 2, step: 354, cost: 9.263124, mlm loss: 9.263124, speed: 1.081305 steps/s, speed: 8.650440 samples/s, speed: 4429.025025 tokens/s, learning rate: 3.530e-06, loss_scalings: 20971.521484, pp_loss: 8.680868
[INFO] 2021-07-12 18:34:40,620 [run_pretraining.py:  512]:	********exe.run_354******* 
[INFO] 2021-07-12 18:34:41,539 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:41,540 [run_pretraining.py:  534]:	loss/total_loss, 9.720771789550781, 355
[INFO] 2021-07-12 18:34:41,540 [run_pretraining.py:  535]:	loss/mlm_loss, 9.720771789550781, 355
[INFO] 2021-07-12 18:34:41,540 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.539999852364417e-06, 355
[INFO] 2021-07-12 18:34:41,540 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 355
[INFO] 2021-07-12 18:34:41,540 [run_pretraining.py:  558]:	worker_index: 2, step: 355, cost: 9.720772, mlm loss: 9.720772, speed: 1.087383 steps/s, speed: 8.699065 samples/s, speed: 4453.921058 tokens/s, learning rate: 3.540e-06, loss_scalings: 16777.216797, pp_loss: 9.522422
[INFO] 2021-07-12 18:34:41,540 [run_pretraining.py:  512]:	********exe.run_355******* 
[INFO] 2021-07-12 18:34:42,507 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:42,507 [run_pretraining.py:  534]:	loss/total_loss, 9.575502395629883, 356
[INFO] 2021-07-12 18:34:42,507 [run_pretraining.py:  535]:	loss/mlm_loss, 9.575502395629883, 356
[INFO] 2021-07-12 18:34:42,507 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.549999973984086e-06, 356
[INFO] 2021-07-12 18:34:42,507 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 356
[INFO] 2021-07-12 18:34:42,508 [run_pretraining.py:  558]:	worker_index: 2, step: 356, cost: 9.575502, mlm loss: 9.575502, speed: 1.034619 steps/s, speed: 8.276950 samples/s, speed: 4237.798337 tokens/s, learning rate: 3.550e-06, loss_scalings: 16777.216797, pp_loss: 9.461927
[INFO] 2021-07-12 18:34:42,508 [run_pretraining.py:  512]:	********exe.run_356******* 
[INFO] 2021-07-12 18:34:43,437 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:43,437 [run_pretraining.py:  534]:	loss/total_loss, 9.282638549804688, 357
[INFO] 2021-07-12 18:34:43,437 [run_pretraining.py:  535]:	loss/mlm_loss, 9.282638549804688, 357
[INFO] 2021-07-12 18:34:43,437 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.5599998682300793e-06, 357
[INFO] 2021-07-12 18:34:43,437 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 357
[INFO] 2021-07-12 18:34:43,437 [run_pretraining.py:  558]:	worker_index: 2, step: 357, cost: 9.282639, mlm loss: 9.282639, speed: 1.076124 steps/s, speed: 8.608990 samples/s, speed: 4407.802636 tokens/s, learning rate: 3.560e-06, loss_scalings: 16777.216797, pp_loss: 8.542801
[INFO] 2021-07-12 18:34:43,437 [run_pretraining.py:  512]:	********exe.run_357******* 
[INFO] 2021-07-12 18:34:44,359 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:44,359 [run_pretraining.py:  534]:	loss/total_loss, 9.385543823242188, 358
[INFO] 2021-07-12 18:34:44,359 [run_pretraining.py:  535]:	loss/mlm_loss, 9.385543823242188, 358
[INFO] 2021-07-12 18:34:44,359 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.569999989849748e-06, 358
[INFO] 2021-07-12 18:34:44,359 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 358
[INFO] 2021-07-12 18:34:44,360 [run_pretraining.py:  558]:	worker_index: 2, step: 358, cost: 9.385544, mlm loss: 9.385544, speed: 1.085139 steps/s, speed: 8.681114 samples/s, speed: 4444.730260 tokens/s, learning rate: 3.570e-06, loss_scalings: 16777.216797, pp_loss: 9.332450
[INFO] 2021-07-12 18:34:44,360 [run_pretraining.py:  512]:	********exe.run_358******* 
[INFO] 2021-07-12 18:34:45,282 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:45,282 [run_pretraining.py:  534]:	loss/total_loss, 9.647167205810547, 359
[INFO] 2021-07-12 18:34:45,282 [run_pretraining.py:  535]:	loss/mlm_loss, 9.647167205810547, 359
[INFO] 2021-07-12 18:34:45,282 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.5799998840957414e-06, 359
[INFO] 2021-07-12 18:34:45,282 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 359
[INFO] 2021-07-12 18:34:45,282 [run_pretraining.py:  558]:	worker_index: 2, step: 359, cost: 9.647167, mlm loss: 9.647167, speed: 1.084177 steps/s, speed: 8.673415 samples/s, speed: 4440.788353 tokens/s, learning rate: 3.580e-06, loss_scalings: 16777.216797, pp_loss: 9.521080
[INFO] 2021-07-12 18:34:45,283 [run_pretraining.py:  512]:	********exe.run_359******* 
[INFO] 2021-07-12 18:34:46,206 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:46,206 [run_pretraining.py:  534]:	loss/total_loss, 9.278088569641113, 360
[INFO] 2021-07-12 18:34:46,206 [run_pretraining.py:  535]:	loss/mlm_loss, 9.278088569641113, 360
[INFO] 2021-07-12 18:34:46,206 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.5900000057154102e-06, 360
[INFO] 2021-07-12 18:34:46,207 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 360
[INFO] 2021-07-12 18:34:46,207 [run_pretraining.py:  558]:	worker_index: 2, step: 360, cost: 9.278089, mlm loss: 9.278089, speed: 1.082770 steps/s, speed: 8.662157 samples/s, speed: 4435.024253 tokens/s, learning rate: 3.590e-06, loss_scalings: 16777.216797, pp_loss: 9.406517
[INFO] 2021-07-12 18:34:46,207 [run_pretraining.py:  512]:	********exe.run_360******* 
[INFO] 2021-07-12 18:34:47,125 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:47,125 [run_pretraining.py:  534]:	loss/total_loss, 9.40744400024414, 361
[INFO] 2021-07-12 18:34:47,125 [run_pretraining.py:  535]:	loss/mlm_loss, 9.40744400024414, 361
[INFO] 2021-07-12 18:34:47,125 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.599999672587728e-06, 361
[INFO] 2021-07-12 18:34:47,126 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 361
[INFO] 2021-07-12 18:34:47,126 [run_pretraining.py:  558]:	worker_index: 2, step: 361, cost: 9.407444, mlm loss: 9.407444, speed: 1.088885 steps/s, speed: 8.711084 samples/s, speed: 4460.074805 tokens/s, learning rate: 3.600e-06, loss_scalings: 16777.216797, pp_loss: 9.482599
[INFO] 2021-07-12 18:34:47,126 [run_pretraining.py:  512]:	********exe.run_361******* 
[INFO] 2021-07-12 18:34:48,055 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:48,056 [run_pretraining.py:  534]:	loss/total_loss, 9.29106330871582, 362
[INFO] 2021-07-12 18:34:48,056 [run_pretraining.py:  535]:	loss/mlm_loss, 9.29106330871582, 362
[INFO] 2021-07-12 18:34:48,056 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.6100000215810724e-06, 362
[INFO] 2021-07-12 18:34:48,056 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 362
[INFO] 2021-07-12 18:34:48,056 [run_pretraining.py:  558]:	worker_index: 2, step: 362, cost: 9.291063, mlm loss: 9.291063, speed: 1.075154 steps/s, speed: 8.601228 samples/s, speed: 4403.828844 tokens/s, learning rate: 3.610e-06, loss_scalings: 16777.216797, pp_loss: 9.425943
[INFO] 2021-07-12 18:34:48,056 [run_pretraining.py:  512]:	********exe.run_362******* 
[INFO] 2021-07-12 18:34:48,973 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:48,974 [run_pretraining.py:  534]:	loss/total_loss, 9.253351211547852, 363
[INFO] 2021-07-12 18:34:48,974 [run_pretraining.py:  535]:	loss/mlm_loss, 9.253351211547852, 363
[INFO] 2021-07-12 18:34:48,974 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.620000143200741e-06, 363
[INFO] 2021-07-12 18:34:48,974 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 363
[INFO] 2021-07-12 18:34:48,974 [run_pretraining.py:  558]:	worker_index: 2, step: 363, cost: 9.253351, mlm loss: 9.253351, speed: 1.090015 steps/s, speed: 8.720116 samples/s, speed: 4464.699546 tokens/s, learning rate: 3.620e-06, loss_scalings: 16777.216797, pp_loss: 9.361931
[INFO] 2021-07-12 18:34:48,974 [run_pretraining.py:  512]:	********exe.run_363******* 
[INFO] 2021-07-12 18:34:49,895 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:49,895 [run_pretraining.py:  534]:	loss/total_loss, 9.659300804138184, 364
[INFO] 2021-07-12 18:34:49,895 [run_pretraining.py:  535]:	loss/mlm_loss, 9.659300804138184, 364
[INFO] 2021-07-12 18:34:49,895 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.629999810073059e-06, 364
[INFO] 2021-07-12 18:34:49,895 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 364
[INFO] 2021-07-12 18:34:49,895 [run_pretraining.py:  558]:	worker_index: 2, step: 364, cost: 9.659301, mlm loss: 9.659301, speed: 1.086445 steps/s, speed: 8.691563 samples/s, speed: 4450.080411 tokens/s, learning rate: 3.630e-06, loss_scalings: 16777.216797, pp_loss: 9.303905
[INFO] 2021-07-12 18:34:49,895 [run_pretraining.py:  512]:	********exe.run_364******* 
[INFO] 2021-07-12 18:34:50,813 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:50,813 [run_pretraining.py:  534]:	loss/total_loss, 9.474392890930176, 365
[INFO] 2021-07-12 18:34:50,813 [run_pretraining.py:  535]:	loss/mlm_loss, 9.474392890930176, 365
[INFO] 2021-07-12 18:34:50,813 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.6400001590664033e-06, 365
[INFO] 2021-07-12 18:34:50,813 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 365
[INFO] 2021-07-12 18:34:50,814 [run_pretraining.py:  558]:	worker_index: 2, step: 365, cost: 9.474393, mlm loss: 9.474393, speed: 1.089876 steps/s, speed: 8.719006 samples/s, speed: 4464.131079 tokens/s, learning rate: 3.640e-06, loss_scalings: 16777.216797, pp_loss: 9.394520
[INFO] 2021-07-12 18:34:50,814 [run_pretraining.py:  512]:	********exe.run_365******* 
[INFO] 2021-07-12 18:34:51,743 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:51,743 [run_pretraining.py:  534]:	loss/total_loss, 9.263457298278809, 366
[INFO] 2021-07-12 18:34:51,744 [run_pretraining.py:  535]:	loss/mlm_loss, 9.263457298278809, 366
[INFO] 2021-07-12 18:34:51,744 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.649999825938721e-06, 366
[INFO] 2021-07-12 18:34:51,744 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 366
[INFO] 2021-07-12 18:34:51,744 [run_pretraining.py:  558]:	worker_index: 2, step: 366, cost: 9.263457, mlm loss: 9.263457, speed: 1.075630 steps/s, speed: 8.605040 samples/s, speed: 4405.780383 tokens/s, learning rate: 3.650e-06, loss_scalings: 16777.216797, pp_loss: 9.330608
[INFO] 2021-07-12 18:34:51,744 [run_pretraining.py:  512]:	********exe.run_366******* 
[INFO] 2021-07-12 18:34:52,676 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:52,677 [run_pretraining.py:  534]:	loss/total_loss, 8.952535629272461, 367
[INFO] 2021-07-12 18:34:52,677 [run_pretraining.py:  535]:	loss/mlm_loss, 8.952535629272461, 367
[INFO] 2021-07-12 18:34:52,677 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.65999994755839e-06, 367
[INFO] 2021-07-12 18:34:52,677 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 367
[INFO] 2021-07-12 18:34:52,677 [run_pretraining.py:  558]:	worker_index: 2, step: 367, cost: 8.952536, mlm loss: 8.952536, speed: 1.072379 steps/s, speed: 8.579028 samples/s, speed: 4392.462391 tokens/s, learning rate: 3.660e-06, loss_scalings: 16777.216797, pp_loss: 9.288748
[INFO] 2021-07-12 18:34:52,677 [run_pretraining.py:  512]:	********exe.run_367******* 
[INFO] 2021-07-12 18:34:53,603 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:53,603 [run_pretraining.py:  534]:	loss/total_loss, 9.170825004577637, 368
[INFO] 2021-07-12 18:34:53,603 [run_pretraining.py:  535]:	loss/mlm_loss, 9.170825004577637, 368
[INFO] 2021-07-12 18:34:53,604 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.6699998418043833e-06, 368
[INFO] 2021-07-12 18:34:53,604 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 368
[INFO] 2021-07-12 18:34:53,604 [run_pretraining.py:  558]:	worker_index: 2, step: 368, cost: 9.170825, mlm loss: 9.170825, speed: 1.079772 steps/s, speed: 8.638178 samples/s, speed: 4422.747094 tokens/s, learning rate: 3.670e-06, loss_scalings: 16777.216797, pp_loss: 9.392266
[INFO] 2021-07-12 18:34:53,604 [run_pretraining.py:  512]:	********exe.run_368******* 
[INFO] 2021-07-12 18:35:19,225 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:19,225 [run_pretraining.py:  534]:	loss/total_loss, 7.087308406829834, 369
[INFO] 2021-07-12 18:35:19,225 [run_pretraining.py:  535]:	loss/mlm_loss, 7.087308406829834, 369
[INFO] 2021-07-12 18:35:19,225 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.679999963424052e-06, 369
[INFO] 2021-07-12 18:35:19,225 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 369
[INFO] 2021-07-12 18:35:19,225 [run_pretraining.py:  558]:	worker_index: 2, step: 369, cost: 7.087308, mlm loss: 7.087308, speed: 0.039030 steps/s, speed: 0.312242 samples/s, speed: 159.867817 tokens/s, learning rate: 3.680e-06, loss_scalings: 16777.216797, pp_loss: 8.745742
[INFO] 2021-07-12 18:35:19,226 [run_pretraining.py:  512]:	********exe.run_369******* 
[INFO] 2021-07-12 18:35:20,165 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:20,166 [run_pretraining.py:  534]:	loss/total_loss, 9.47618579864502, 370
[INFO] 2021-07-12 18:35:20,166 [run_pretraining.py:  535]:	loss/mlm_loss, 9.47618579864502, 370
[INFO] 2021-07-12 18:35:20,166 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.6899998576700455e-06, 370
[INFO] 2021-07-12 18:35:20,166 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 370
[INFO] 2021-07-12 18:35:20,166 [run_pretraining.py:  558]:	worker_index: 2, step: 370, cost: 9.476186, mlm loss: 9.476186, speed: 1.063789 steps/s, speed: 8.510310 samples/s, speed: 4357.278558 tokens/s, learning rate: 3.690e-06, loss_scalings: 16777.216797, pp_loss: 9.199629
[INFO] 2021-07-12 18:35:20,166 [run_pretraining.py:  512]:	********exe.run_370******* 
[INFO] 2021-07-12 18:35:21,083 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:21,084 [run_pretraining.py:  534]:	loss/total_loss, 9.441261291503906, 371
[INFO] 2021-07-12 18:35:21,084 [run_pretraining.py:  535]:	loss/mlm_loss, 9.441261291503906, 371
[INFO] 2021-07-12 18:35:21,084 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.6999999792897142e-06, 371
[INFO] 2021-07-12 18:35:21,084 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 371
[INFO] 2021-07-12 18:35:21,084 [run_pretraining.py:  558]:	worker_index: 2, step: 371, cost: 9.441261, mlm loss: 9.441261, speed: 1.090215 steps/s, speed: 8.721723 samples/s, speed: 4465.522340 tokens/s, learning rate: 3.700e-06, loss_scalings: 16777.216797, pp_loss: 9.409966
[INFO] 2021-07-12 18:35:21,084 [run_pretraining.py:  512]:	********exe.run_371******* 
[INFO] 2021-07-12 18:35:22,005 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:22,005 [run_pretraining.py:  534]:	loss/total_loss, 9.501871109008789, 372
[INFO] 2021-07-12 18:35:22,005 [run_pretraining.py:  535]:	loss/mlm_loss, 9.501871109008789, 372
[INFO] 2021-07-12 18:35:22,006 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.709999646162032e-06, 372
[INFO] 2021-07-12 18:35:22,006 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 372
[INFO] 2021-07-12 18:35:22,006 [run_pretraining.py:  558]:	worker_index: 2, step: 372, cost: 9.501871, mlm loss: 9.501871, speed: 1.085584 steps/s, speed: 8.684675 samples/s, speed: 4446.553645 tokens/s, learning rate: 3.710e-06, loss_scalings: 16777.216797, pp_loss: 9.430290
[INFO] 2021-07-12 18:35:22,006 [run_pretraining.py:  512]:	********exe.run_372******* 
[INFO] 2021-07-12 18:35:22,929 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:22,929 [run_pretraining.py:  534]:	loss/total_loss, 5.291935920715332, 373
[INFO] 2021-07-12 18:35:22,929 [run_pretraining.py:  535]:	loss/mlm_loss, 5.291935920715332, 373
[INFO] 2021-07-12 18:35:22,929 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.7199999951553764e-06, 373
[INFO] 2021-07-12 18:35:22,930 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 373
[INFO] 2021-07-12 18:35:22,930 [run_pretraining.py:  558]:	worker_index: 2, step: 373, cost: 5.291936, mlm loss: 5.291936, speed: 1.083079 steps/s, speed: 8.664633 samples/s, speed: 4436.292033 tokens/s, learning rate: 3.720e-06, loss_scalings: 16777.216797, pp_loss: 8.638235
[INFO] 2021-07-12 18:35:22,930 [run_pretraining.py:  512]:	********exe.run_373******* 
[INFO] 2021-07-12 18:35:23,855 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:23,855 [run_pretraining.py:  534]:	loss/total_loss, 9.311888694763184, 374
[INFO] 2021-07-12 18:35:23,855 [run_pretraining.py:  535]:	loss/mlm_loss, 9.311888694763184, 374
[INFO] 2021-07-12 18:35:23,856 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.730000116775045e-06, 374
[INFO] 2021-07-12 18:35:23,856 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 374
[INFO] 2021-07-12 18:35:23,856 [run_pretraining.py:  558]:	worker_index: 2, step: 374, cost: 9.311889, mlm loss: 9.311889, speed: 1.080584 steps/s, speed: 8.644674 samples/s, speed: 4426.073114 tokens/s, learning rate: 3.730e-06, loss_scalings: 13421.773438, pp_loss: 9.152605
[INFO] 2021-07-12 18:35:23,856 [run_pretraining.py:  512]:	********exe.run_374******* 
[INFO] 2021-07-12 18:35:24,764 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:24,765 [run_pretraining.py:  534]:	loss/total_loss, 5.032961368560791, 375
[INFO] 2021-07-12 18:35:24,765 [run_pretraining.py:  535]:	loss/mlm_loss, 5.032961368560791, 375
[INFO] 2021-07-12 18:35:24,765 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.739999783647363e-06, 375
[INFO] 2021-07-12 18:35:24,765 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 375
[INFO] 2021-07-12 18:35:24,765 [run_pretraining.py:  558]:	worker_index: 2, step: 375, cost: 5.032961, mlm loss: 5.032961, speed: 1.100481 steps/s, speed: 8.803846 samples/s, speed: 4507.569044 tokens/s, learning rate: 3.740e-06, loss_scalings: 13421.773438, pp_loss: 8.176418
[INFO] 2021-07-12 18:35:24,765 [run_pretraining.py:  512]:	********exe.run_375******* 
[INFO] 2021-07-12 18:35:25,695 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:25,695 [run_pretraining.py:  534]:	loss/total_loss, 9.284037590026855, 376
[INFO] 2021-07-12 18:35:25,695 [run_pretraining.py:  535]:	loss/mlm_loss, 9.284037590026855, 376
[INFO] 2021-07-12 18:35:25,695 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.7500001326407073e-06, 376
[INFO] 2021-07-12 18:35:25,696 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 376
[INFO] 2021-07-12 18:35:25,696 [run_pretraining.py:  558]:	worker_index: 2, step: 376, cost: 9.284038, mlm loss: 9.284038, speed: 1.075337 steps/s, speed: 8.602695 samples/s, speed: 4404.579666 tokens/s, learning rate: 3.750e-06, loss_scalings: 13421.773438, pp_loss: 9.371407
[INFO] 2021-07-12 18:35:25,696 [run_pretraining.py:  512]:	********exe.run_376******* 
[INFO] 2021-07-12 18:35:26,618 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:26,619 [run_pretraining.py:  534]:	loss/total_loss, 9.198152542114258, 377
[INFO] 2021-07-12 18:35:26,619 [run_pretraining.py:  535]:	loss/mlm_loss, 9.198152542114258, 377
[INFO] 2021-07-12 18:35:26,619 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.759999799513025e-06, 377
[INFO] 2021-07-12 18:35:26,619 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 377
[INFO] 2021-07-12 18:35:26,619 [run_pretraining.py:  558]:	worker_index: 2, step: 377, cost: 9.198153, mlm loss: 9.198153, speed: 1.083532 steps/s, speed: 8.668252 samples/s, speed: 4438.145188 tokens/s, learning rate: 3.760e-06, loss_scalings: 13421.773438, pp_loss: 9.248877
[INFO] 2021-07-12 18:35:26,619 [run_pretraining.py:  512]:	********exe.run_377******* 
[INFO] 2021-07-12 18:35:53,329 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:53,329 [run_pretraining.py:  534]:	loss/total_loss, 9.298517227172852, 378
[INFO] 2021-07-12 18:35:53,330 [run_pretraining.py:  535]:	loss/mlm_loss, 9.298517227172852, 378
[INFO] 2021-07-12 18:35:53,330 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.769999921132694e-06, 378
[INFO] 2021-07-12 18:35:53,330 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 378
[INFO] 2021-07-12 18:35:53,330 [run_pretraining.py:  558]:	worker_index: 2, step: 378, cost: 9.298517, mlm loss: 9.298517, speed: 0.037439 steps/s, speed: 0.299512 samples/s, speed: 153.350163 tokens/s, learning rate: 3.770e-06, loss_scalings: 13421.773438, pp_loss: 9.251398
[INFO] 2021-07-12 18:35:53,330 [run_pretraining.py:  512]:	********exe.run_378******* 
[INFO] 2021-07-12 18:35:54,250 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:54,250 [run_pretraining.py:  534]:	loss/total_loss, 8.742432594299316, 379
[INFO] 2021-07-12 18:35:54,250 [run_pretraining.py:  535]:	loss/mlm_loss, 8.742432594299316, 379
[INFO] 2021-07-12 18:35:54,250 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.7799998153786873e-06, 379
[INFO] 2021-07-12 18:35:54,250 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 379
[INFO] 2021-07-12 18:35:54,250 [run_pretraining.py:  558]:	worker_index: 2, step: 379, cost: 8.742433, mlm loss: 8.742433, speed: 1.086994 steps/s, speed: 8.695953 samples/s, speed: 4452.328156 tokens/s, learning rate: 3.780e-06, loss_scalings: 13421.773438, pp_loss: 8.559660
[INFO] 2021-07-12 18:35:54,250 [run_pretraining.py:  512]:	********exe.run_379******* 
[INFO] 2021-07-12 18:35:55,174 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:55,174 [run_pretraining.py:  534]:	loss/total_loss, 9.5823392868042, 380
[INFO] 2021-07-12 18:35:55,174 [run_pretraining.py:  535]:	loss/mlm_loss, 9.5823392868042, 380
[INFO] 2021-07-12 18:35:55,174 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.789999936998356e-06, 380
[INFO] 2021-07-12 18:35:55,174 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 380
[INFO] 2021-07-12 18:35:55,174 [run_pretraining.py:  558]:	worker_index: 2, step: 380, cost: 9.582339, mlm loss: 9.582339, speed: 1.082956 steps/s, speed: 8.663651 samples/s, speed: 4435.789186 tokens/s, learning rate: 3.790e-06, loss_scalings: 13421.773438, pp_loss: 9.412964
[INFO] 2021-07-12 18:35:55,174 [run_pretraining.py:  512]:	********exe.run_380******* 
[INFO] 2021-07-12 18:35:56,083 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:56,084 [run_pretraining.py:  534]:	loss/total_loss, 9.087215423583984, 381
[INFO] 2021-07-12 18:35:56,084 [run_pretraining.py:  535]:	loss/mlm_loss, 9.087215423583984, 381
[INFO] 2021-07-12 18:35:56,084 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.7999998312443495e-06, 381
[INFO] 2021-07-12 18:35:56,084 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 381
[INFO] 2021-07-12 18:35:56,084 [run_pretraining.py:  558]:	worker_index: 2, step: 381, cost: 9.087215, mlm loss: 9.087215, speed: 1.100098 steps/s, speed: 8.800782 samples/s, speed: 4506.000182 tokens/s, learning rate: 3.800e-06, loss_scalings: 13421.773438, pp_loss: 9.320915
[INFO] 2021-07-12 18:35:56,084 [run_pretraining.py:  512]:	********exe.run_381******* 
[INFO] 2021-07-12 18:35:57,146 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:57,146 [run_pretraining.py:  534]:	loss/total_loss, 9.393072128295898, 382
[INFO] 2021-07-12 18:35:57,147 [run_pretraining.py:  535]:	loss/mlm_loss, 9.393072128295898, 382
[INFO] 2021-07-12 18:35:57,147 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.8099999528640183e-06, 382
[INFO] 2021-07-12 18:35:57,147 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 382
[INFO] 2021-07-12 18:35:57,147 [run_pretraining.py:  558]:	worker_index: 2, step: 382, cost: 9.393072, mlm loss: 9.393072, speed: 0.941460 steps/s, speed: 7.531678 samples/s, speed: 3856.219207 tokens/s, learning rate: 3.810e-06, loss_scalings: 13421.773438, pp_loss: 9.083075
[INFO] 2021-07-12 18:35:57,147 [run_pretraining.py:  512]:	********exe.run_382******* 
[INFO] 2021-07-12 18:35:58,054 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:58,054 [run_pretraining.py:  534]:	loss/total_loss, 9.242005348205566, 383
[INFO] 2021-07-12 18:35:58,055 [run_pretraining.py:  535]:	loss/mlm_loss, 9.242005348205566, 383
[INFO] 2021-07-12 18:35:58,055 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.819999619736336e-06, 383
[INFO] 2021-07-12 18:35:58,055 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 383
[INFO] 2021-07-12 18:35:58,055 [run_pretraining.py:  558]:	worker_index: 2, step: 383, cost: 9.242005, mlm loss: 9.242005, speed: 1.101991 steps/s, speed: 8.815932 samples/s, speed: 4513.756997 tokens/s, learning rate: 3.820e-06, loss_scalings: 13421.773438, pp_loss: 9.304141
[INFO] 2021-07-12 18:35:58,055 [run_pretraining.py:  512]:	********exe.run_383******* 
[INFO] 2021-07-12 18:35:58,963 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:58,964 [run_pretraining.py:  534]:	loss/total_loss, 9.307211875915527, 384
[INFO] 2021-07-12 18:35:58,964 [run_pretraining.py:  535]:	loss/mlm_loss, 9.307211875915527, 384
[INFO] 2021-07-12 18:35:58,964 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.82999996872968e-06, 384
[INFO] 2021-07-12 18:35:58,964 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 384
[INFO] 2021-07-12 18:35:58,964 [run_pretraining.py:  558]:	worker_index: 2, step: 384, cost: 9.307212, mlm loss: 9.307212, speed: 1.100570 steps/s, speed: 8.804560 samples/s, speed: 4507.934520 tokens/s, learning rate: 3.830e-06, loss_scalings: 13421.773438, pp_loss: 9.295285
[INFO] 2021-07-12 18:35:58,964 [run_pretraining.py:  512]:	********exe.run_384******* 
[INFO] 2021-07-12 18:35:59,868 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:59,869 [run_pretraining.py:  534]:	loss/total_loss, 9.010761260986328, 385
[INFO] 2021-07-12 18:35:59,869 [run_pretraining.py:  535]:	loss/mlm_loss, 9.010761260986328, 385
[INFO] 2021-07-12 18:35:59,869 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.839999862975674e-06, 385
[INFO] 2021-07-12 18:35:59,869 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 385
[INFO] 2021-07-12 18:35:59,869 [run_pretraining.py:  558]:	worker_index: 2, step: 385, cost: 9.010761, mlm loss: 9.010761, speed: 1.105755 steps/s, speed: 8.846039 samples/s, speed: 4529.171908 tokens/s, learning rate: 3.840e-06, loss_scalings: 13421.773438, pp_loss: 9.242443
[INFO] 2021-07-12 18:35:59,869 [run_pretraining.py:  512]:	********exe.run_385******* 
[INFO] 2021-07-12 18:36:25,750 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:25,751 [run_pretraining.py:  534]:	loss/total_loss, 9.501713752746582, 386
[INFO] 2021-07-12 18:36:25,751 [run_pretraining.py:  535]:	loss/mlm_loss, 9.501713752746582, 386
[INFO] 2021-07-12 18:36:25,751 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.849999757221667e-06, 386
[INFO] 2021-07-12 18:36:25,751 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 386
[INFO] 2021-07-12 18:36:25,751 [run_pretraining.py:  558]:	worker_index: 2, step: 386, cost: 9.501714, mlm loss: 9.501714, speed: 0.038638 steps/s, speed: 0.309104 samples/s, speed: 158.261213 tokens/s, learning rate: 3.850e-06, loss_scalings: 13421.773438, pp_loss: 9.086734
[INFO] 2021-07-12 18:36:25,751 [run_pretraining.py:  512]:	********exe.run_386******* 
[INFO] 2021-07-12 18:36:26,659 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:26,660 [run_pretraining.py:  534]:	loss/total_loss, 9.39310073852539, 387
[INFO] 2021-07-12 18:36:26,660 [run_pretraining.py:  535]:	loss/mlm_loss, 9.39310073852539, 387
[INFO] 2021-07-12 18:36:26,660 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.860000106215011e-06, 387
[INFO] 2021-07-12 18:36:26,660 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 387
[INFO] 2021-07-12 18:36:26,660 [run_pretraining.py:  558]:	worker_index: 2, step: 387, cost: 9.393101, mlm loss: 9.393101, speed: 1.100390 steps/s, speed: 8.803123 samples/s, speed: 4507.198897 tokens/s, learning rate: 3.860e-06, loss_scalings: 13421.773438, pp_loss: 9.519636
[INFO] 2021-07-12 18:36:26,660 [run_pretraining.py:  512]:	********exe.run_387******* 
[INFO] 2021-07-12 18:36:27,570 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:27,570 [run_pretraining.py:  534]:	loss/total_loss, 9.328573226928711, 388
[INFO] 2021-07-12 18:36:27,570 [run_pretraining.py:  535]:	loss/mlm_loss, 9.328573226928711, 388
[INFO] 2021-07-12 18:36:27,570 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.870000000461005e-06, 388
[INFO] 2021-07-12 18:36:27,570 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 388
[INFO] 2021-07-12 18:36:27,571 [run_pretraining.py:  558]:	worker_index: 2, step: 388, cost: 9.328573, mlm loss: 9.328573, speed: 1.099268 steps/s, speed: 8.794143 samples/s, speed: 4502.601382 tokens/s, learning rate: 3.870e-06, loss_scalings: 13421.773438, pp_loss: 9.327359
[INFO] 2021-07-12 18:36:27,571 [run_pretraining.py:  512]:	********exe.run_388******* 
[INFO] 2021-07-12 18:36:28,485 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:28,486 [run_pretraining.py:  534]:	loss/total_loss, 9.106447219848633, 389
[INFO] 2021-07-12 18:36:28,486 [run_pretraining.py:  535]:	loss/mlm_loss, 9.106447219848633, 389
[INFO] 2021-07-12 18:36:28,486 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.879999894706998e-06, 389
[INFO] 2021-07-12 18:36:28,486 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 389
[INFO] 2021-07-12 18:36:28,486 [run_pretraining.py:  558]:	worker_index: 2, step: 389, cost: 9.106447, mlm loss: 9.106447, speed: 1.093170 steps/s, speed: 8.745362 samples/s, speed: 4477.625304 tokens/s, learning rate: 3.880e-06, loss_scalings: 13421.773438, pp_loss: 9.211720
[INFO] 2021-07-12 18:36:28,486 [run_pretraining.py:  512]:	********exe.run_389******* 
[INFO] 2021-07-12 18:36:29,405 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:29,405 [run_pretraining.py:  534]:	loss/total_loss, 9.558927536010742, 390
[INFO] 2021-07-12 18:36:29,405 [run_pretraining.py:  535]:	loss/mlm_loss, 9.558927536010742, 390
[INFO] 2021-07-12 18:36:29,405 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.889999788952991e-06, 390
[INFO] 2021-07-12 18:36:29,405 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 390
[INFO] 2021-07-12 18:36:29,405 [run_pretraining.py:  558]:	worker_index: 2, step: 390, cost: 9.558928, mlm loss: 9.558928, speed: 1.088207 steps/s, speed: 8.705653 samples/s, speed: 4457.294149 tokens/s, learning rate: 3.890e-06, loss_scalings: 13421.773438, pp_loss: 7.404225
[INFO] 2021-07-12 18:36:29,405 [run_pretraining.py:  512]:	********exe.run_390******* 
[INFO] 2021-07-12 18:36:30,314 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:30,315 [run_pretraining.py:  534]:	loss/total_loss, 9.473937034606934, 391
[INFO] 2021-07-12 18:36:30,315 [run_pretraining.py:  535]:	loss/mlm_loss, 9.473937034606934, 391
[INFO] 2021-07-12 18:36:30,315 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.900000137946336e-06, 391
[INFO] 2021-07-12 18:36:30,315 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 391
[INFO] 2021-07-12 18:36:30,315 [run_pretraining.py:  558]:	worker_index: 2, step: 391, cost: 9.473937, mlm loss: 9.473937, speed: 1.099857 steps/s, speed: 8.798859 samples/s, speed: 4505.015916 tokens/s, learning rate: 3.900e-06, loss_scalings: 13421.773438, pp_loss: 9.269403
[INFO] 2021-07-12 18:36:30,315 [run_pretraining.py:  512]:	********exe.run_391******* 
[INFO] 2021-07-12 18:36:31,224 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:31,225 [run_pretraining.py:  534]:	loss/total_loss, 9.20166015625, 392
[INFO] 2021-07-12 18:36:31,225 [run_pretraining.py:  535]:	loss/mlm_loss, 9.20166015625, 392
[INFO] 2021-07-12 18:36:31,225 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.909999577444978e-06, 392
[INFO] 2021-07-12 18:36:31,225 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 392
[INFO] 2021-07-12 18:36:31,225 [run_pretraining.py:  558]:	worker_index: 2, step: 392, cost: 9.201660, mlm loss: 9.201660, speed: 1.099825 steps/s, speed: 8.798601 samples/s, speed: 4504.883610 tokens/s, learning rate: 3.910e-06, loss_scalings: 13421.773438, pp_loss: 9.256135
[INFO] 2021-07-12 18:36:31,225 [run_pretraining.py:  512]:	********exe.run_392******* 
[INFO] 2021-07-12 18:36:32,134 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:32,135 [run_pretraining.py:  534]:	loss/total_loss, 9.63796615600586, 393
[INFO] 2021-07-12 18:36:32,135 [run_pretraining.py:  535]:	loss/mlm_loss, 9.63796615600586, 393
[INFO] 2021-07-12 18:36:32,135 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.919999926438322e-06, 393
[INFO] 2021-07-12 18:36:32,135 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 393
[INFO] 2021-07-12 18:36:32,135 [run_pretraining.py:  558]:	worker_index: 2, step: 393, cost: 9.637966, mlm loss: 9.637966, speed: 1.099664 steps/s, speed: 8.797314 samples/s, speed: 4504.224561 tokens/s, learning rate: 3.920e-06, loss_scalings: 13421.773438, pp_loss: 8.696768
[INFO] 2021-07-12 18:36:32,135 [run_pretraining.py:  512]:	********exe.run_393******* 
[INFO] 2021-07-12 18:36:33,048 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:33,048 [run_pretraining.py:  534]:	loss/total_loss, 9.1925048828125, 394
[INFO] 2021-07-12 18:36:33,049 [run_pretraining.py:  535]:	loss/mlm_loss, 9.1925048828125, 394
[INFO] 2021-07-12 18:36:33,049 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.929999820684316e-06, 394
[INFO] 2021-07-12 18:36:33,049 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 394
[INFO] 2021-07-12 18:36:33,049 [run_pretraining.py:  558]:	worker_index: 2, step: 394, cost: 9.192505, mlm loss: 9.192505, speed: 1.095086 steps/s, speed: 8.760690 samples/s, speed: 4485.473192 tokens/s, learning rate: 3.930e-06, loss_scalings: 13421.773438, pp_loss: 9.148632
[INFO] 2021-07-12 18:36:33,049 [run_pretraining.py:  512]:	********exe.run_394******* 
[INFO] 2021-07-12 18:36:33,957 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:33,957 [run_pretraining.py:  534]:	loss/total_loss, 9.34152889251709, 395
[INFO] 2021-07-12 18:36:33,957 [run_pretraining.py:  535]:	loss/mlm_loss, 9.34152889251709, 395
[INFO] 2021-07-12 18:36:33,957 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.939999714930309e-06, 395
[INFO] 2021-07-12 18:36:33,957 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 395
[INFO] 2021-07-12 18:36:33,957 [run_pretraining.py:  558]:	worker_index: 2, step: 395, cost: 9.341529, mlm loss: 9.341529, speed: 1.101202 steps/s, speed: 8.809613 samples/s, speed: 4510.521747 tokens/s, learning rate: 3.940e-06, loss_scalings: 13421.773438, pp_loss: 9.269874
[INFO] 2021-07-12 18:36:33,958 [run_pretraining.py:  512]:	********exe.run_395******* 
[INFO] 2021-07-12 18:36:34,866 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:34,867 [run_pretraining.py:  534]:	loss/total_loss, 9.367865562438965, 396
[INFO] 2021-07-12 18:36:34,867 [run_pretraining.py:  535]:	loss/mlm_loss, 9.367865562438965, 396
[INFO] 2021-07-12 18:36:34,867 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.950000063923653e-06, 396
[INFO] 2021-07-12 18:36:34,867 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 396
[INFO] 2021-07-12 18:36:34,867 [run_pretraining.py:  558]:	worker_index: 2, step: 396, cost: 9.367866, mlm loss: 9.367866, speed: 1.100308 steps/s, speed: 8.802465 samples/s, speed: 4506.861916 tokens/s, learning rate: 3.950e-06, loss_scalings: 13421.773438, pp_loss: 9.200006
[INFO] 2021-07-12 18:36:34,867 [run_pretraining.py:  512]:	********exe.run_396******* 
[INFO] 2021-07-12 18:36:35,773 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:35,774 [run_pretraining.py:  534]:	loss/total_loss, 9.329355239868164, 397
[INFO] 2021-07-12 18:36:35,774 [run_pretraining.py:  535]:	loss/mlm_loss, 9.329355239868164, 397
[INFO] 2021-07-12 18:36:35,774 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.9599999581696466e-06, 397
[INFO] 2021-07-12 18:36:35,774 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 397
[INFO] 2021-07-12 18:36:35,774 [run_pretraining.py:  558]:	worker_index: 2, step: 397, cost: 9.329355, mlm loss: 9.329355, speed: 1.103066 steps/s, speed: 8.824529 samples/s, speed: 4518.158687 tokens/s, learning rate: 3.960e-06, loss_scalings: 13421.773438, pp_loss: 9.332493
[INFO] 2021-07-12 18:36:35,774 [run_pretraining.py:  512]:	********exe.run_397******* 
[INFO] 2021-07-12 18:36:36,685 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:36,685 [run_pretraining.py:  534]:	loss/total_loss, 9.932817459106445, 398
[INFO] 2021-07-12 18:36:36,686 [run_pretraining.py:  535]:	loss/mlm_loss, 9.932817459106445, 398
[INFO] 2021-07-12 18:36:36,686 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.96999985241564e-06, 398
[INFO] 2021-07-12 18:36:36,686 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 398
[INFO] 2021-07-12 18:36:36,686 [run_pretraining.py:  558]:	worker_index: 2, step: 398, cost: 9.932817, mlm loss: 9.932817, speed: 1.097498 steps/s, speed: 8.779987 samples/s, speed: 4495.353288 tokens/s, learning rate: 3.970e-06, loss_scalings: 13421.773438, pp_loss: 9.551077
[INFO] 2021-07-12 18:36:36,686 [run_pretraining.py:  512]:	********exe.run_398******* 
[INFO] 2021-07-12 18:36:37,594 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:37,595 [run_pretraining.py:  534]:	loss/total_loss, 9.348791122436523, 399
[INFO] 2021-07-12 18:36:37,595 [run_pretraining.py:  535]:	loss/mlm_loss, 9.348791122436523, 399
[INFO] 2021-07-12 18:36:37,595 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.979999746661633e-06, 399
[INFO] 2021-07-12 18:36:37,595 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 399
[INFO] 2021-07-12 18:36:37,595 [run_pretraining.py:  558]:	worker_index: 2, step: 399, cost: 9.348791, mlm loss: 9.348791, speed: 1.100296 steps/s, speed: 8.802370 samples/s, speed: 4506.813442 tokens/s, learning rate: 3.980e-06, loss_scalings: 13421.773438, pp_loss: 9.255895
[INFO] 2021-07-12 18:36:37,595 [run_pretraining.py:  512]:	********exe.run_399******* 
[INFO] 2021-07-12 18:36:38,505 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:38,505 [run_pretraining.py:  534]:	loss/total_loss, 9.294913291931152, 400
[INFO] 2021-07-12 18:36:38,505 [run_pretraining.py:  535]:	loss/mlm_loss, 9.294913291931152, 400
[INFO] 2021-07-12 18:36:38,506 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.9900000956549775e-06, 400
[INFO] 2021-07-12 18:36:38,506 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 400
[INFO] 2021-07-12 18:36:38,506 [run_pretraining.py:  558]:	worker_index: 2, step: 400, cost: 9.294913, mlm loss: 9.294913, speed: 1.099181 steps/s, speed: 8.793445 samples/s, speed: 4502.243849 tokens/s, learning rate: 3.990e-06, loss_scalings: 13421.773438, pp_loss: 9.173244
[INFO] 2021-07-12 18:36:38,506 [run_pretraining.py:  512]:	********exe.run_400******* 
[INFO] 2021-07-12 18:36:39,414 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:39,415 [run_pretraining.py:  534]:	loss/total_loss, 9.54231071472168, 401
[INFO] 2021-07-12 18:36:39,415 [run_pretraining.py:  535]:	loss/mlm_loss, 9.54231071472168, 401
[INFO] 2021-07-12 18:36:39,415 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.999999989900971e-06, 401
[INFO] 2021-07-12 18:36:39,415 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 401
[INFO] 2021-07-12 18:36:39,415 [run_pretraining.py:  558]:	worker_index: 2, step: 401, cost: 9.542311, mlm loss: 9.542311, speed: 1.100424 steps/s, speed: 8.803395 samples/s, speed: 4507.338434 tokens/s, learning rate: 4.000e-06, loss_scalings: 13421.773438, pp_loss: 9.289005
[INFO] 2021-07-12 18:36:39,415 [run_pretraining.py:  512]:	********exe.run_401******* 
[INFO] 2021-07-12 18:36:40,329 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:40,330 [run_pretraining.py:  534]:	loss/total_loss, 8.792253494262695, 402
[INFO] 2021-07-12 18:36:40,330 [run_pretraining.py:  535]:	loss/mlm_loss, 8.792253494262695, 402
[INFO] 2021-07-12 18:36:40,330 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.009999884146964e-06, 402
[INFO] 2021-07-12 18:36:40,330 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 402
[INFO] 2021-07-12 18:36:40,330 [run_pretraining.py:  558]:	worker_index: 2, step: 402, cost: 8.792253, mlm loss: 8.792253, speed: 1.093428 steps/s, speed: 8.747421 samples/s, speed: 4478.679365 tokens/s, learning rate: 4.010e-06, loss_scalings: 13421.773438, pp_loss: 9.155107
[INFO] 2021-07-12 18:36:40,330 [run_pretraining.py:  512]:	********exe.run_402******* 
[INFO] 2021-07-12 18:36:41,236 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:41,237 [run_pretraining.py:  534]:	loss/total_loss, 9.261458396911621, 403
[INFO] 2021-07-12 18:36:41,237 [run_pretraining.py:  535]:	loss/mlm_loss, 9.261458396911621, 403
[INFO] 2021-07-12 18:36:41,237 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.0199997783929575e-06, 403
[INFO] 2021-07-12 18:36:41,237 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 403
[INFO] 2021-07-12 18:36:41,237 [run_pretraining.py:  558]:	worker_index: 2, step: 403, cost: 9.261458, mlm loss: 9.261458, speed: 1.103068 steps/s, speed: 8.824543 samples/s, speed: 4518.165817 tokens/s, learning rate: 4.020e-06, loss_scalings: 13421.773438, pp_loss: 9.136664
[INFO] 2021-07-12 18:36:41,237 [run_pretraining.py:  512]:	********exe.run_403******* 
[INFO] 2021-07-12 18:36:42,155 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:42,155 [run_pretraining.py:  534]:	loss/total_loss, 8.842973709106445, 404
[INFO] 2021-07-12 18:36:42,156 [run_pretraining.py:  535]:	loss/mlm_loss, 8.842973709106445, 404
[INFO] 2021-07-12 18:36:42,156 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.030000127386302e-06, 404
[INFO] 2021-07-12 18:36:42,156 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 404
[INFO] 2021-07-12 18:36:42,156 [run_pretraining.py:  558]:	worker_index: 2, step: 404, cost: 8.842974, mlm loss: 8.842974, speed: 1.089470 steps/s, speed: 8.715761 samples/s, speed: 4462.469433 tokens/s, learning rate: 4.030e-06, loss_scalings: 13421.773438, pp_loss: 9.112225
[INFO] 2021-07-12 18:36:42,156 [run_pretraining.py:  512]:	********exe.run_404******* 
[INFO] 2021-07-12 18:36:43,073 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:43,074 [run_pretraining.py:  534]:	loss/total_loss, 9.033487319946289, 405
[INFO] 2021-07-12 18:36:43,074 [run_pretraining.py:  535]:	loss/mlm_loss, 9.033487319946289, 405
[INFO] 2021-07-12 18:36:43,074 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.039999566884944e-06, 405
[INFO] 2021-07-12 18:36:43,074 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 405
[INFO] 2021-07-12 18:36:43,074 [run_pretraining.py:  558]:	worker_index: 2, step: 405, cost: 9.033487, mlm loss: 9.033487, speed: 1.089885 steps/s, speed: 8.719076 samples/s, speed: 4464.167039 tokens/s, learning rate: 4.040e-06, loss_scalings: 13421.773438, pp_loss: 9.263382
[INFO] 2021-07-12 18:36:43,074 [run_pretraining.py:  512]:	********exe.run_405******* 
[INFO] 2021-07-12 18:36:43,988 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:43,988 [run_pretraining.py:  534]:	loss/total_loss, 9.493422508239746, 406
[INFO] 2021-07-12 18:36:43,988 [run_pretraining.py:  535]:	loss/mlm_loss, 9.493422508239746, 406
[INFO] 2021-07-12 18:36:43,988 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.0499999158782884e-06, 406
[INFO] 2021-07-12 18:36:43,988 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 406
[INFO] 2021-07-12 18:36:43,988 [run_pretraining.py:  558]:	worker_index: 2, step: 406, cost: 9.493423, mlm loss: 9.493423, speed: 1.094266 steps/s, speed: 8.754126 samples/s, speed: 4482.112292 tokens/s, learning rate: 4.050e-06, loss_scalings: 13421.773438, pp_loss: 9.322812
[INFO] 2021-07-12 18:36:43,988 [run_pretraining.py:  512]:	********exe.run_406******* 
[INFO] 2021-07-12 18:36:44,888 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:44,889 [run_pretraining.py:  534]:	loss/total_loss, 9.28321647644043, 407
[INFO] 2021-07-12 18:36:44,889 [run_pretraining.py:  535]:	loss/mlm_loss, 9.28321647644043, 407
[INFO] 2021-07-12 18:36:44,889 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.060000264871633e-06, 407
[INFO] 2021-07-12 18:36:44,889 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 407
[INFO] 2021-07-12 18:36:44,889 [run_pretraining.py:  558]:	worker_index: 2, step: 407, cost: 9.283216, mlm loss: 9.283216, speed: 1.110815 steps/s, speed: 8.886522 samples/s, speed: 4549.899291 tokens/s, learning rate: 4.060e-06, loss_scalings: 13421.773438, pp_loss: 9.189468
[INFO] 2021-07-12 18:36:44,889 [run_pretraining.py:  512]:	********exe.run_407******* 
[INFO] 2021-07-12 18:36:45,799 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:45,800 [run_pretraining.py:  534]:	loss/total_loss, 9.349480628967285, 408
[INFO] 2021-07-12 18:36:45,800 [run_pretraining.py:  535]:	loss/mlm_loss, 9.349480628967285, 408
[INFO] 2021-07-12 18:36:45,800 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.069999704370275e-06, 408
[INFO] 2021-07-12 18:36:45,800 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 408
[INFO] 2021-07-12 18:36:45,800 [run_pretraining.py:  558]:	worker_index: 2, step: 408, cost: 9.349481, mlm loss: 9.349481, speed: 1.098796 steps/s, speed: 8.790365 samples/s, speed: 4500.666901 tokens/s, learning rate: 4.070e-06, loss_scalings: 13421.773438, pp_loss: 9.195178
[INFO] 2021-07-12 18:36:45,800 [run_pretraining.py:  512]:	********exe.run_408******* 
[INFO] 2021-07-12 18:36:46,699 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:46,700 [run_pretraining.py:  534]:	loss/total_loss, 9.410948753356934, 409
[INFO] 2021-07-12 18:36:46,700 [run_pretraining.py:  535]:	loss/mlm_loss, 9.410948753356934, 409
[INFO] 2021-07-12 18:36:46,700 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.080000053363619e-06, 409
[INFO] 2021-07-12 18:36:46,700 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 409
[INFO] 2021-07-12 18:36:46,700 [run_pretraining.py:  558]:	worker_index: 2, step: 409, cost: 9.410949, mlm loss: 9.410949, speed: 1.111465 steps/s, speed: 8.891722 samples/s, speed: 4552.561467 tokens/s, learning rate: 4.080e-06, loss_scalings: 13421.773438, pp_loss: 9.256783
[INFO] 2021-07-12 18:36:46,700 [run_pretraining.py:  512]:	********exe.run_409******* 
[INFO] 2021-07-12 18:36:47,652 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:47,652 [run_pretraining.py:  534]:	loss/total_loss, 9.246721267700195, 410
[INFO] 2021-07-12 18:36:47,653 [run_pretraining.py:  535]:	loss/mlm_loss, 9.246721267700195, 410
[INFO] 2021-07-12 18:36:47,653 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.089999947609613e-06, 410
[INFO] 2021-07-12 18:36:47,653 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 410
[INFO] 2021-07-12 18:36:47,653 [run_pretraining.py:  558]:	worker_index: 2, step: 410, cost: 9.246721, mlm loss: 9.246721, speed: 1.050432 steps/s, speed: 8.403455 samples/s, speed: 4302.568860 tokens/s, learning rate: 4.090e-06, loss_scalings: 13421.773438, pp_loss: 8.280346
[INFO] 2021-07-12 18:36:47,653 [run_pretraining.py:  512]:	********exe.run_410******* 
[INFO] 2021-07-12 18:36:48,700 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:48,701 [run_pretraining.py:  534]:	loss/total_loss, 8.848413467407227, 411
[INFO] 2021-07-12 18:36:48,701 [run_pretraining.py:  535]:	loss/mlm_loss, 8.848413467407227, 411
[INFO] 2021-07-12 18:36:48,701 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.099999841855606e-06, 411
[INFO] 2021-07-12 18:36:48,701 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 411
[INFO] 2021-07-12 18:36:48,701 [run_pretraining.py:  558]:	worker_index: 2, step: 411, cost: 8.848413, mlm loss: 8.848413, speed: 0.954409 steps/s, speed: 7.635270 samples/s, speed: 3909.258365 tokens/s, learning rate: 4.100e-06, loss_scalings: 13421.773438, pp_loss: 9.193769
[INFO] 2021-07-12 18:36:48,701 [run_pretraining.py:  512]:	********exe.run_411******* 
[INFO] 2021-07-12 18:36:49,744 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:49,744 [run_pretraining.py:  534]:	loss/total_loss, 9.09244155883789, 412
[INFO] 2021-07-12 18:36:49,744 [run_pretraining.py:  535]:	loss/mlm_loss, 9.09244155883789, 412
[INFO] 2021-07-12 18:36:49,744 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.109999736101599e-06, 412
[INFO] 2021-07-12 18:36:49,744 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 412
[INFO] 2021-07-12 18:36:49,744 [run_pretraining.py:  558]:	worker_index: 2, step: 412, cost: 9.092442, mlm loss: 9.092442, speed: 0.959122 steps/s, speed: 7.672978 samples/s, speed: 3928.564790 tokens/s, learning rate: 4.110e-06, loss_scalings: 13421.773438, pp_loss: 9.261200
[INFO] 2021-07-12 18:36:49,744 [run_pretraining.py:  512]:	********exe.run_412******* 
[INFO] 2021-07-12 18:36:50,799 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:50,799 [run_pretraining.py:  534]:	loss/total_loss, 9.314128875732422, 413
[INFO] 2021-07-12 18:36:50,800 [run_pretraining.py:  535]:	loss/mlm_loss, 9.314128875732422, 413
[INFO] 2021-07-12 18:36:50,800 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.120000085094944e-06, 413
[INFO] 2021-07-12 18:36:50,800 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 413
[INFO] 2021-07-12 18:36:50,800 [run_pretraining.py:  558]:	worker_index: 2, step: 413, cost: 9.314129, mlm loss: 9.314129, speed: 0.947972 steps/s, speed: 7.583774 samples/s, speed: 3882.892425 tokens/s, learning rate: 4.120e-06, loss_scalings: 13421.773438, pp_loss: 9.337070
[INFO] 2021-07-12 18:36:50,800 [run_pretraining.py:  512]:	********exe.run_413******* 
[INFO] 2021-07-12 18:36:51,858 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:51,858 [run_pretraining.py:  534]:	loss/total_loss, 6.5529046058654785, 414
[INFO] 2021-07-12 18:36:51,858 [run_pretraining.py:  535]:	loss/mlm_loss, 6.5529046058654785, 414
[INFO] 2021-07-12 18:36:51,858 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.129999979340937e-06, 414
[INFO] 2021-07-12 18:36:51,859 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 414
[INFO] 2021-07-12 18:36:51,859 [run_pretraining.py:  558]:	worker_index: 2, step: 414, cost: 6.552905, mlm loss: 6.552905, speed: 0.945002 steps/s, speed: 7.560017 samples/s, speed: 3870.728661 tokens/s, learning rate: 4.130e-06, loss_scalings: 13421.773438, pp_loss: 8.543155
[INFO] 2021-07-12 18:36:51,859 [run_pretraining.py:  512]:	********exe.run_414******* 
[INFO] 2021-07-12 18:36:52,911 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:52,911 [run_pretraining.py:  534]:	loss/total_loss, 9.261208534240723, 415
[INFO] 2021-07-12 18:36:52,911 [run_pretraining.py:  535]:	loss/mlm_loss, 9.261208534240723, 415
[INFO] 2021-07-12 18:36:52,912 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.13999987358693e-06, 415
[INFO] 2021-07-12 18:36:52,912 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 415
[INFO] 2021-07-12 18:36:52,912 [run_pretraining.py:  558]:	worker_index: 2, step: 415, cost: 9.261209, mlm loss: 9.261209, speed: 0.950179 steps/s, speed: 7.601429 samples/s, speed: 3891.931517 tokens/s, learning rate: 4.140e-06, loss_scalings: 13421.773438, pp_loss: 9.240945
[INFO] 2021-07-12 18:36:52,912 [run_pretraining.py:  512]:	********exe.run_415******* 
[INFO] 2021-07-12 18:36:53,964 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:53,965 [run_pretraining.py:  534]:	loss/total_loss, 9.571798324584961, 416
[INFO] 2021-07-12 18:36:53,965 [run_pretraining.py:  535]:	loss/mlm_loss, 9.571798324584961, 416
[INFO] 2021-07-12 18:36:53,965 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.149999767832924e-06, 416
[INFO] 2021-07-12 18:36:53,965 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 416
[INFO] 2021-07-12 18:36:53,965 [run_pretraining.py:  558]:	worker_index: 2, step: 416, cost: 9.571798, mlm loss: 9.571798, speed: 0.949679 steps/s, speed: 7.597436 samples/s, speed: 3889.887096 tokens/s, learning rate: 4.150e-06, loss_scalings: 13421.773438, pp_loss: 9.252343
[INFO] 2021-07-12 18:36:53,965 [run_pretraining.py:  512]:	********exe.run_416******* 
[INFO] 2021-07-12 18:36:55,023 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:55,024 [run_pretraining.py:  534]:	loss/total_loss, 9.46804428100586, 417
[INFO] 2021-07-12 18:36:55,024 [run_pretraining.py:  535]:	loss/mlm_loss, 9.46804428100586, 417
[INFO] 2021-07-12 18:36:55,024 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.160000116826268e-06, 417
[INFO] 2021-07-12 18:36:55,024 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 417
[INFO] 2021-07-12 18:36:55,024 [run_pretraining.py:  558]:	worker_index: 2, step: 417, cost: 9.468044, mlm loss: 9.468044, speed: 0.945130 steps/s, speed: 7.561042 samples/s, speed: 3871.253736 tokens/s, learning rate: 4.160e-06, loss_scalings: 13421.773438, pp_loss: 9.257633
[INFO] 2021-07-12 18:36:55,024 [run_pretraining.py:  512]:	********exe.run_417******* 
[INFO] 2021-07-12 18:36:56,075 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:56,076 [run_pretraining.py:  534]:	loss/total_loss, 9.129718780517578, 418
[INFO] 2021-07-12 18:36:56,076 [run_pretraining.py:  535]:	loss/mlm_loss, 9.129718780517578, 418
[INFO] 2021-07-12 18:36:56,076 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.170000011072261e-06, 418
[INFO] 2021-07-12 18:36:56,076 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 418
[INFO] 2021-07-12 18:36:56,076 [run_pretraining.py:  558]:	worker_index: 2, step: 418, cost: 9.129719, mlm loss: 9.129719, speed: 0.950804 steps/s, speed: 7.606433 samples/s, speed: 3894.493598 tokens/s, learning rate: 4.170e-06, loss_scalings: 13421.773438, pp_loss: 9.105957
[INFO] 2021-07-12 18:36:56,076 [run_pretraining.py:  512]:	********exe.run_418******* 
[INFO] 2021-07-12 18:36:57,125 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:57,126 [run_pretraining.py:  534]:	loss/total_loss, 9.173337936401367, 419
[INFO] 2021-07-12 18:36:57,126 [run_pretraining.py:  535]:	loss/mlm_loss, 9.173337936401367, 419
[INFO] 2021-07-12 18:36:57,126 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.179999905318255e-06, 419
[INFO] 2021-07-12 18:36:57,126 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 419
[INFO] 2021-07-12 18:36:57,126 [run_pretraining.py:  558]:	worker_index: 2, step: 419, cost: 9.173338, mlm loss: 9.173338, speed: 0.953044 steps/s, speed: 7.624356 samples/s, speed: 3903.670224 tokens/s, learning rate: 4.180e-06, loss_scalings: 13421.773438, pp_loss: 9.166960
[INFO] 2021-07-12 18:36:57,126 [run_pretraining.py:  512]:	********exe.run_419******* 
[INFO] 2021-07-12 18:36:58,180 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:58,180 [run_pretraining.py:  534]:	loss/total_loss, 8.976383209228516, 420
[INFO] 2021-07-12 18:36:58,180 [run_pretraining.py:  535]:	loss/mlm_loss, 8.976383209228516, 420
[INFO] 2021-07-12 18:36:58,180 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.190000254311599e-06, 420
[INFO] 2021-07-12 18:36:58,180 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 420
[INFO] 2021-07-12 18:36:58,180 [run_pretraining.py:  558]:	worker_index: 2, step: 420, cost: 8.976383, mlm loss: 8.976383, speed: 0.949114 steps/s, speed: 7.592914 samples/s, speed: 3887.572094 tokens/s, learning rate: 4.190e-06, loss_scalings: 13421.773438, pp_loss: 9.107395
[INFO] 2021-07-12 18:36:58,180 [run_pretraining.py:  512]:	********exe.run_420******* 
[INFO] 2021-07-12 18:36:59,246 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:59,246 [run_pretraining.py:  534]:	loss/total_loss, 8.899768829345703, 421
[INFO] 2021-07-12 18:36:59,246 [run_pretraining.py:  535]:	loss/mlm_loss, 8.899768829345703, 421
[INFO] 2021-07-12 18:36:59,246 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.199999693810241e-06, 421
[INFO] 2021-07-12 18:36:59,246 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 421
[INFO] 2021-07-12 18:36:59,247 [run_pretraining.py:  558]:	worker_index: 2, step: 421, cost: 8.899769, mlm loss: 8.899769, speed: 0.938421 steps/s, speed: 7.507369 samples/s, speed: 3843.772757 tokens/s, learning rate: 4.200e-06, loss_scalings: 13421.773438, pp_loss: 9.190563
[INFO] 2021-07-12 18:36:59,247 [run_pretraining.py:  512]:	********exe.run_421******* 
[INFO] 2021-07-12 18:37:00,294 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:00,294 [run_pretraining.py:  534]:	loss/total_loss, 8.421577453613281, 422
[INFO] 2021-07-12 18:37:00,295 [run_pretraining.py:  535]:	loss/mlm_loss, 8.421577453613281, 422
[INFO] 2021-07-12 18:37:00,295 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.2100000428035855e-06, 422
[INFO] 2021-07-12 18:37:00,295 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 422
[INFO] 2021-07-12 18:37:00,295 [run_pretraining.py:  558]:	worker_index: 2, step: 422, cost: 8.421577, mlm loss: 8.421577, speed: 0.954479 steps/s, speed: 7.635831 samples/s, speed: 3909.545710 tokens/s, learning rate: 4.210e-06, loss_scalings: 13421.773438, pp_loss: 9.035894
[INFO] 2021-07-12 18:37:00,295 [run_pretraining.py:  512]:	********exe.run_422******* 
[INFO] 2021-07-12 18:37:01,349 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:01,349 [run_pretraining.py:  534]:	loss/total_loss, 9.194113731384277, 423
[INFO] 2021-07-12 18:37:01,349 [run_pretraining.py:  535]:	loss/mlm_loss, 9.194113731384277, 423
[INFO] 2021-07-12 18:37:01,349 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.219999937049579e-06, 423
[INFO] 2021-07-12 18:37:01,349 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 423
[INFO] 2021-07-12 18:37:01,350 [run_pretraining.py:  558]:	worker_index: 2, step: 423, cost: 9.194114, mlm loss: 9.194114, speed: 0.948701 steps/s, speed: 7.589608 samples/s, speed: 3885.879399 tokens/s, learning rate: 4.220e-06, loss_scalings: 13421.773438, pp_loss: 9.183009
[INFO] 2021-07-12 18:37:01,350 [run_pretraining.py:  512]:	********exe.run_423******* 
[INFO] 2021-07-12 18:37:02,402 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:02,403 [run_pretraining.py:  534]:	loss/total_loss, 9.150148391723633, 424
[INFO] 2021-07-12 18:37:02,403 [run_pretraining.py:  535]:	loss/mlm_loss, 9.150148391723633, 424
[INFO] 2021-07-12 18:37:02,403 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.229999831295572e-06, 424
[INFO] 2021-07-12 18:37:02,403 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 424
[INFO] 2021-07-12 18:37:02,403 [run_pretraining.py:  558]:	worker_index: 2, step: 424, cost: 9.150148, mlm loss: 9.150148, speed: 0.949801 steps/s, speed: 7.598408 samples/s, speed: 3890.384785 tokens/s, learning rate: 4.230e-06, loss_scalings: 13421.773438, pp_loss: 9.118074
[INFO] 2021-07-12 18:37:02,403 [run_pretraining.py:  512]:	********exe.run_424******* 
[INFO] 2021-07-12 18:37:03,462 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:03,463 [run_pretraining.py:  534]:	loss/total_loss, 9.419069290161133, 425
[INFO] 2021-07-12 18:37:03,463 [run_pretraining.py:  535]:	loss/mlm_loss, 9.419069290161133, 425
[INFO] 2021-07-12 18:37:03,463 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.2399997255415656e-06, 425
[INFO] 2021-07-12 18:37:03,463 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 425
[INFO] 2021-07-12 18:37:03,463 [run_pretraining.py:  558]:	worker_index: 2, step: 425, cost: 9.419069, mlm loss: 9.419069, speed: 0.943971 steps/s, speed: 7.551765 samples/s, speed: 3866.503599 tokens/s, learning rate: 4.240e-06, loss_scalings: 13421.773438, pp_loss: 9.368036
[INFO] 2021-07-12 18:37:03,463 [run_pretraining.py:  512]:	********exe.run_425******* 
[INFO] 2021-07-12 18:37:04,517 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:04,518 [run_pretraining.py:  534]:	loss/total_loss, 9.481376647949219, 426
[INFO] 2021-07-12 18:37:04,518 [run_pretraining.py:  535]:	loss/mlm_loss, 9.481376647949219, 426
[INFO] 2021-07-12 18:37:04,518 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.25000007453491e-06, 426
[INFO] 2021-07-12 18:37:04,518 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 426
[INFO] 2021-07-12 18:37:04,518 [run_pretraining.py:  558]:	worker_index: 2, step: 426, cost: 9.481377, mlm loss: 9.481377, speed: 0.948288 steps/s, speed: 7.586302 samples/s, speed: 3884.186422 tokens/s, learning rate: 4.250e-06, loss_scalings: 13421.773438, pp_loss: 9.396059
[INFO] 2021-07-12 18:37:04,518 [run_pretraining.py:  512]:	********exe.run_426******* 
[INFO] 2021-07-12 18:37:05,643 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:05,644 [run_pretraining.py:  534]:	loss/total_loss, 9.171697616577148, 427
[INFO] 2021-07-12 18:37:05,644 [run_pretraining.py:  535]:	loss/mlm_loss, 9.171697616577148, 427
[INFO] 2021-07-12 18:37:05,644 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.259999514033552e-06, 427
[INFO] 2021-07-12 18:37:05,644 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 427
[INFO] 2021-07-12 18:37:05,644 [run_pretraining.py:  558]:	worker_index: 2, step: 427, cost: 9.171698, mlm loss: 9.171698, speed: 0.888404 steps/s, speed: 7.107236 samples/s, speed: 3638.904631 tokens/s, learning rate: 4.260e-06, loss_scalings: 13421.773438, pp_loss: 9.044601
[INFO] 2021-07-12 18:37:05,644 [run_pretraining.py:  512]:	********exe.run_427******* 
[INFO] 2021-07-12 18:37:06,744 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:06,744 [run_pretraining.py:  534]:	loss/total_loss, 9.258066177368164, 428
[INFO] 2021-07-12 18:37:06,744 [run_pretraining.py:  535]:	loss/mlm_loss, 9.258066177368164, 428
[INFO] 2021-07-12 18:37:06,744 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.2699998630268965e-06, 428
[INFO] 2021-07-12 18:37:06,744 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 428
[INFO] 2021-07-12 18:37:06,744 [run_pretraining.py:  558]:	worker_index: 2, step: 428, cost: 9.258066, mlm loss: 9.258066, speed: 0.909534 steps/s, speed: 7.276275 samples/s, speed: 3725.452687 tokens/s, learning rate: 4.270e-06, loss_scalings: 13421.773438, pp_loss: 8.926437
[INFO] 2021-07-12 18:37:06,744 [run_pretraining.py:  512]:	********exe.run_428******* 
[INFO] 2021-07-12 18:37:07,839 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:07,839 [run_pretraining.py:  534]:	loss/total_loss, 9.255176544189453, 429
[INFO] 2021-07-12 18:37:07,839 [run_pretraining.py:  535]:	loss/mlm_loss, 9.255176544189453, 429
[INFO] 2021-07-12 18:37:07,839 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.280000212020241e-06, 429
[INFO] 2021-07-12 18:37:07,839 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 429
[INFO] 2021-07-12 18:37:07,839 [run_pretraining.py:  558]:	worker_index: 2, step: 429, cost: 9.255177, mlm loss: 9.255177, speed: 0.913720 steps/s, speed: 7.309759 samples/s, speed: 3742.596537 tokens/s, learning rate: 4.280e-06, loss_scalings: 13421.773438, pp_loss: 9.259420
[INFO] 2021-07-12 18:37:07,839 [run_pretraining.py:  512]:	********exe.run_429******* 
[INFO] 2021-07-12 18:37:08,889 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:08,890 [run_pretraining.py:  534]:	loss/total_loss, 9.200953483581543, 430
[INFO] 2021-07-12 18:37:08,890 [run_pretraining.py:  535]:	loss/mlm_loss, 9.200953483581543, 430
[INFO] 2021-07-12 18:37:08,890 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.289999651518883e-06, 430
[INFO] 2021-07-12 18:37:08,890 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 430
[INFO] 2021-07-12 18:37:08,890 [run_pretraining.py:  558]:	worker_index: 2, step: 430, cost: 9.200953, mlm loss: 9.200953, speed: 0.952401 steps/s, speed: 7.619211 samples/s, speed: 3901.035822 tokens/s, learning rate: 4.290e-06, loss_scalings: 13421.773438, pp_loss: 9.249372
[INFO] 2021-07-12 18:37:08,890 [run_pretraining.py:  512]:	********exe.run_430******* 
[INFO] 2021-07-12 18:37:09,948 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:09,948 [run_pretraining.py:  534]:	loss/total_loss, 9.281351089477539, 431
[INFO] 2021-07-12 18:37:09,948 [run_pretraining.py:  535]:	loss/mlm_loss, 9.281351089477539, 431
[INFO] 2021-07-12 18:37:09,948 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.300000000512227e-06, 431
[INFO] 2021-07-12 18:37:09,948 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 431
[INFO] 2021-07-12 18:37:09,948 [run_pretraining.py:  558]:	worker_index: 2, step: 431, cost: 9.281351, mlm loss: 9.281351, speed: 0.945219 steps/s, speed: 7.561753 samples/s, speed: 3871.617534 tokens/s, learning rate: 4.300e-06, loss_scalings: 13421.773438, pp_loss: 9.297722
[INFO] 2021-07-12 18:37:09,949 [run_pretraining.py:  512]:	********exe.run_431******* 
[INFO] 2021-07-12 18:37:11,008 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:11,008 [run_pretraining.py:  534]:	loss/total_loss, 9.454492568969727, 432
[INFO] 2021-07-12 18:37:11,008 [run_pretraining.py:  535]:	loss/mlm_loss, 9.454492568969727, 432
[INFO] 2021-07-12 18:37:11,009 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.309999894758221e-06, 432
[INFO] 2021-07-12 18:37:11,009 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 432
[INFO] 2021-07-12 18:37:11,009 [run_pretraining.py:  558]:	worker_index: 2, step: 432, cost: 9.454493, mlm loss: 9.454493, speed: 0.943715 steps/s, speed: 7.549719 samples/s, speed: 3865.456168 tokens/s, learning rate: 4.310e-06, loss_scalings: 13421.773438, pp_loss: 9.298667
[INFO] 2021-07-12 18:37:11,009 [run_pretraining.py:  512]:	********exe.run_432******* 
[INFO] 2021-07-12 18:37:12,065 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:12,066 [run_pretraining.py:  534]:	loss/total_loss, 8.92136287689209, 433
[INFO] 2021-07-12 18:37:12,066 [run_pretraining.py:  535]:	loss/mlm_loss, 8.92136287689209, 433
[INFO] 2021-07-12 18:37:12,066 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.319999789004214e-06, 433
[INFO] 2021-07-12 18:37:12,066 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 433
[INFO] 2021-07-12 18:37:12,066 [run_pretraining.py:  558]:	worker_index: 2, step: 433, cost: 8.921363, mlm loss: 8.921363, speed: 0.946290 steps/s, speed: 7.570322 samples/s, speed: 3876.005064 tokens/s, learning rate: 4.320e-06, loss_scalings: 13421.773438, pp_loss: 9.020355
[INFO] 2021-07-12 18:37:12,066 [run_pretraining.py:  512]:	********exe.run_433******* 
[INFO] 2021-07-12 18:37:13,102 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:13,102 [run_pretraining.py:  534]:	loss/total_loss, 9.218544006347656, 434
[INFO] 2021-07-12 18:37:13,103 [run_pretraining.py:  535]:	loss/mlm_loss, 9.218544006347656, 434
[INFO] 2021-07-12 18:37:13,103 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.3299996832502075e-06, 434
[INFO] 2021-07-12 18:37:13,103 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 434
[INFO] 2021-07-12 18:37:13,103 [run_pretraining.py:  558]:	worker_index: 2, step: 434, cost: 9.218544, mlm loss: 9.218544, speed: 0.965183 steps/s, speed: 7.721462 samples/s, speed: 3953.388592 tokens/s, learning rate: 4.330e-06, loss_scalings: 13421.773438, pp_loss: 9.220533
[INFO] 2021-07-12 18:37:13,103 [run_pretraining.py:  512]:	********exe.run_434******* 
[INFO] 2021-07-12 18:37:14,156 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:14,157 [run_pretraining.py:  534]:	loss/total_loss, 8.922161102294922, 435
[INFO] 2021-07-12 18:37:14,157 [run_pretraining.py:  535]:	loss/mlm_loss, 8.922161102294922, 435
[INFO] 2021-07-12 18:37:14,157 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.340000032243552e-06, 435
[INFO] 2021-07-12 18:37:14,157 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 435
[INFO] 2021-07-12 18:37:14,157 [run_pretraining.py:  558]:	worker_index: 2, step: 435, cost: 8.922161, mlm loss: 8.922161, speed: 0.949155 steps/s, speed: 7.593239 samples/s, speed: 3887.738365 tokens/s, learning rate: 4.340e-06, loss_scalings: 13421.773438, pp_loss: 9.088880
[INFO] 2021-07-12 18:37:14,157 [run_pretraining.py:  512]:	********exe.run_435******* 
[INFO] 2021-07-12 18:37:15,207 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:15,208 [run_pretraining.py:  534]:	loss/total_loss, 9.34700870513916, 436
[INFO] 2021-07-12 18:37:15,208 [run_pretraining.py:  535]:	loss/mlm_loss, 9.34700870513916, 436
[INFO] 2021-07-12 18:37:15,208 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.349999926489545e-06, 436
[INFO] 2021-07-12 18:37:15,208 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 436
[INFO] 2021-07-12 18:37:15,208 [run_pretraining.py:  558]:	worker_index: 2, step: 436, cost: 9.347009, mlm loss: 9.347009, speed: 0.951969 steps/s, speed: 7.615754 samples/s, speed: 3899.265894 tokens/s, learning rate: 4.350e-06, loss_scalings: 13421.773438, pp_loss: 9.126913
[INFO] 2021-07-12 18:37:15,208 [run_pretraining.py:  512]:	********exe.run_436******* 
[INFO] 2021-07-12 18:37:16,262 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:16,262 [run_pretraining.py:  534]:	loss/total_loss, 9.075939178466797, 437
[INFO] 2021-07-12 18:37:16,262 [run_pretraining.py:  535]:	loss/mlm_loss, 9.075939178466797, 437
[INFO] 2021-07-12 18:37:16,262 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.359999820735538e-06, 437
[INFO] 2021-07-12 18:37:16,262 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 437
[INFO] 2021-07-12 18:37:16,262 [run_pretraining.py:  558]:	worker_index: 2, step: 437, cost: 9.075939, mlm loss: 9.075939, speed: 0.948904 steps/s, speed: 7.591231 samples/s, speed: 3886.710174 tokens/s, learning rate: 4.360e-06, loss_scalings: 13421.773438, pp_loss: 9.222418
[INFO] 2021-07-12 18:37:16,262 [run_pretraining.py:  512]:	********exe.run_437******* 
[INFO] 2021-07-12 18:37:17,315 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:17,316 [run_pretraining.py:  534]:	loss/total_loss, 9.276631355285645, 438
[INFO] 2021-07-12 18:37:17,316 [run_pretraining.py:  535]:	loss/mlm_loss, 9.276631355285645, 438
[INFO] 2021-07-12 18:37:17,316 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.369999714981532e-06, 438
[INFO] 2021-07-12 18:37:17,316 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 438
[INFO] 2021-07-12 18:37:17,316 [run_pretraining.py:  558]:	worker_index: 2, step: 438, cost: 9.276631, mlm loss: 9.276631, speed: 0.949552 steps/s, speed: 7.596412 samples/s, speed: 3889.363119 tokens/s, learning rate: 4.370e-06, loss_scalings: 13421.773438, pp_loss: 9.055027
[INFO] 2021-07-12 18:37:17,316 [run_pretraining.py:  512]:	********exe.run_438******* 
[INFO] 2021-07-12 18:37:18,371 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:18,372 [run_pretraining.py:  534]:	loss/total_loss, 9.086816787719727, 439
[INFO] 2021-07-12 18:37:18,372 [run_pretraining.py:  535]:	loss/mlm_loss, 9.086816787719727, 439
[INFO] 2021-07-12 18:37:18,372 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.380000063974876e-06, 439
[INFO] 2021-07-12 18:37:18,372 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 439
[INFO] 2021-07-12 18:37:18,372 [run_pretraining.py:  558]:	worker_index: 2, step: 439, cost: 9.086817, mlm loss: 9.086817, speed: 0.947595 steps/s, speed: 7.580759 samples/s, speed: 3881.348484 tokens/s, learning rate: 4.380e-06, loss_scalings: 13421.773438, pp_loss: 9.123215
[INFO] 2021-07-12 18:37:18,372 [run_pretraining.py:  512]:	********exe.run_439******* 
[INFO] 2021-07-12 18:37:19,421 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:19,422 [run_pretraining.py:  534]:	loss/total_loss, 9.36458969116211, 440
[INFO] 2021-07-12 18:37:19,422 [run_pretraining.py:  535]:	loss/mlm_loss, 9.36458969116211, 440
[INFO] 2021-07-12 18:37:19,422 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.389999958220869e-06, 440
[INFO] 2021-07-12 18:37:19,422 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 440
[INFO] 2021-07-12 18:37:19,422 [run_pretraining.py:  558]:	worker_index: 2, step: 440, cost: 9.364590, mlm loss: 9.364590, speed: 0.953037 steps/s, speed: 7.624299 samples/s, speed: 3903.640953 tokens/s, learning rate: 4.390e-06, loss_scalings: 13421.773438, pp_loss: 9.330490
[INFO] 2021-07-12 18:37:19,422 [run_pretraining.py:  512]:	********exe.run_440******* 
[INFO] 2021-07-12 18:37:20,480 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:20,481 [run_pretraining.py:  534]:	loss/total_loss, 9.154946327209473, 441
[INFO] 2021-07-12 18:37:20,481 [run_pretraining.py:  535]:	loss/mlm_loss, 9.154946327209473, 441
[INFO] 2021-07-12 18:37:20,481 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.399999852466863e-06, 441
[INFO] 2021-07-12 18:37:20,481 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 441
[INFO] 2021-07-12 18:37:20,481 [run_pretraining.py:  558]:	worker_index: 2, step: 441, cost: 9.154946, mlm loss: 9.154946, speed: 0.944795 steps/s, speed: 7.558358 samples/s, speed: 3869.879423 tokens/s, learning rate: 4.400e-06, loss_scalings: 13421.773438, pp_loss: 9.218688
[INFO] 2021-07-12 18:37:20,481 [run_pretraining.py:  512]:	********exe.run_441******* 
[INFO] 2021-07-12 18:37:21,534 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:21,534 [run_pretraining.py:  534]:	loss/total_loss, 8.557615280151367, 442
[INFO] 2021-07-12 18:37:21,534 [run_pretraining.py:  535]:	loss/mlm_loss, 8.557615280151367, 442
[INFO] 2021-07-12 18:37:21,535 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.410000201460207e-06, 442
[INFO] 2021-07-12 18:37:21,535 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 442
[INFO] 2021-07-12 18:37:21,535 [run_pretraining.py:  558]:	worker_index: 2, step: 442, cost: 8.557615, mlm loss: 8.557615, speed: 0.949538 steps/s, speed: 7.596301 samples/s, speed: 3889.305886 tokens/s, learning rate: 4.410e-06, loss_scalings: 13421.773438, pp_loss: 8.885931
[INFO] 2021-07-12 18:37:21,535 [run_pretraining.py:  512]:	********exe.run_442******* 
[INFO] 2021-07-12 18:37:22,618 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:22,618 [run_pretraining.py:  534]:	loss/total_loss, 8.644262313842773, 443
[INFO] 2021-07-12 18:37:22,618 [run_pretraining.py:  535]:	loss/mlm_loss, 8.644262313842773, 443
[INFO] 2021-07-12 18:37:22,619 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.419999640958849e-06, 443
[INFO] 2021-07-12 18:37:22,619 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 443
[INFO] 2021-07-12 18:37:22,619 [run_pretraining.py:  558]:	worker_index: 2, step: 443, cost: 8.644262, mlm loss: 8.644262, speed: 0.923008 steps/s, speed: 7.384067 samples/s, speed: 3780.642125 tokens/s, learning rate: 4.420e-06, loss_scalings: 13421.773438, pp_loss: 8.867744
[INFO] 2021-07-12 18:37:22,619 [run_pretraining.py:  512]:	********exe.run_443******* 
[INFO] 2021-07-12 18:37:23,684 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:23,685 [run_pretraining.py:  534]:	loss/total_loss, 9.02401351928711, 444
[INFO] 2021-07-12 18:37:23,685 [run_pretraining.py:  535]:	loss/mlm_loss, 9.02401351928711, 444
[INFO] 2021-07-12 18:37:23,685 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.4299999899521936e-06, 444
[INFO] 2021-07-12 18:37:23,685 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 444
[INFO] 2021-07-12 18:37:23,685 [run_pretraining.py:  558]:	worker_index: 2, step: 444, cost: 9.024014, mlm loss: 9.024014, speed: 0.938085 steps/s, speed: 7.504679 samples/s, speed: 3842.395540 tokens/s, learning rate: 4.430e-06, loss_scalings: 13421.773438, pp_loss: 8.997915
[INFO] 2021-07-12 18:37:23,685 [run_pretraining.py:  512]:	********exe.run_444******* 
[INFO] 2021-07-12 18:37:24,738 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:24,739 [run_pretraining.py:  534]:	loss/total_loss, 8.953004837036133, 445
[INFO] 2021-07-12 18:37:24,739 [run_pretraining.py:  535]:	loss/mlm_loss, 8.953004837036133, 445
[INFO] 2021-07-12 18:37:24,739 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.439999884198187e-06, 445
[INFO] 2021-07-12 18:37:24,739 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 445
[INFO] 2021-07-12 18:37:24,739 [run_pretraining.py:  558]:	worker_index: 2, step: 445, cost: 8.953005, mlm loss: 8.953005, speed: 0.949658 steps/s, speed: 7.597265 samples/s, speed: 3889.799903 tokens/s, learning rate: 4.440e-06, loss_scalings: 13421.773438, pp_loss: 9.233368
[INFO] 2021-07-12 18:37:24,739 [run_pretraining.py:  512]:	********exe.run_445******* 
[INFO] 2021-07-12 18:37:25,789 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:25,789 [run_pretraining.py:  534]:	loss/total_loss, 9.096271514892578, 446
[INFO] 2021-07-12 18:37:25,789 [run_pretraining.py:  535]:	loss/mlm_loss, 9.096271514892578, 446
[INFO] 2021-07-12 18:37:25,790 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.44999977844418e-06, 446
[INFO] 2021-07-12 18:37:25,790 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 446
[INFO] 2021-07-12 18:37:25,790 [run_pretraining.py:  558]:	worker_index: 2, step: 446, cost: 9.096272, mlm loss: 9.096272, speed: 0.952183 steps/s, speed: 7.617465 samples/s, speed: 3900.142246 tokens/s, learning rate: 4.450e-06, loss_scalings: 13421.773438, pp_loss: 9.422464
[INFO] 2021-07-12 18:37:25,790 [run_pretraining.py:  512]:	********exe.run_446******* 
[INFO] 2021-07-12 18:37:26,846 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:26,847 [run_pretraining.py:  534]:	loss/total_loss, 8.649031639099121, 447
[INFO] 2021-07-12 18:37:26,847 [run_pretraining.py:  535]:	loss/mlm_loss, 8.649031639099121, 447
[INFO] 2021-07-12 18:37:26,847 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.459999672690174e-06, 447
[INFO] 2021-07-12 18:37:26,847 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 447
[INFO] 2021-07-12 18:37:26,847 [run_pretraining.py:  558]:	worker_index: 2, step: 447, cost: 8.649032, mlm loss: 8.649032, speed: 0.946108 steps/s, speed: 7.568862 samples/s, speed: 3875.257529 tokens/s, learning rate: 4.460e-06, loss_scalings: 13421.773438, pp_loss: 8.966952
[INFO] 2021-07-12 18:37:26,847 [run_pretraining.py:  512]:	********exe.run_447******* 
[INFO] 2021-07-12 18:37:27,899 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:27,900 [run_pretraining.py:  534]:	loss/total_loss, 9.019262313842773, 448
[INFO] 2021-07-12 18:37:27,900 [run_pretraining.py:  535]:	loss/mlm_loss, 9.019262313842773, 448
[INFO] 2021-07-12 18:37:27,900 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.470000021683518e-06, 448
[INFO] 2021-07-12 18:37:27,900 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 448
[INFO] 2021-07-12 18:37:27,900 [run_pretraining.py:  558]:	worker_index: 2, step: 448, cost: 9.019262, mlm loss: 9.019262, speed: 0.950618 steps/s, speed: 7.604947 samples/s, speed: 3893.732739 tokens/s, learning rate: 4.470e-06, loss_scalings: 13421.773438, pp_loss: 8.920584
[INFO] 2021-07-12 18:37:27,900 [run_pretraining.py:  512]:	********exe.run_448******* 
[INFO] 2021-07-12 18:37:28,950 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:28,951 [run_pretraining.py:  534]:	loss/total_loss, 8.99170207977295, 449
[INFO] 2021-07-12 18:37:28,951 [run_pretraining.py:  535]:	loss/mlm_loss, 8.99170207977295, 449
[INFO] 2021-07-12 18:37:28,951 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.479999915929511e-06, 449
[INFO] 2021-07-12 18:37:28,951 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 449
[INFO] 2021-07-12 18:37:28,951 [run_pretraining.py:  558]:	worker_index: 2, step: 449, cost: 8.991702, mlm loss: 8.991702, speed: 0.951611 steps/s, speed: 7.612885 samples/s, speed: 3897.797338 tokens/s, learning rate: 4.480e-06, loss_scalings: 13421.773438, pp_loss: 9.124427
[INFO] 2021-07-12 18:37:28,951 [run_pretraining.py:  512]:	********exe.run_449******* 
[INFO] 2021-07-12 18:37:30,001 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:30,002 [run_pretraining.py:  534]:	loss/total_loss, 9.270282745361328, 450
[INFO] 2021-07-12 18:37:30,002 [run_pretraining.py:  535]:	loss/mlm_loss, 9.270282745361328, 450
[INFO] 2021-07-12 18:37:30,002 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.4899998101755045e-06, 450
[INFO] 2021-07-12 18:37:30,002 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 450
[INFO] 2021-07-12 18:37:30,002 [run_pretraining.py:  558]:	worker_index: 2, step: 450, cost: 9.270283, mlm loss: 9.270283, speed: 0.952268 steps/s, speed: 7.618142 samples/s, speed: 3900.488469 tokens/s, learning rate: 4.490e-06, loss_scalings: 13421.773438, pp_loss: 9.167614
[INFO] 2021-07-12 18:37:30,002 [run_pretraining.py:  512]:	********exe.run_450******* 
[INFO] 2021-07-12 18:37:31,053 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:31,053 [run_pretraining.py:  534]:	loss/total_loss, 9.236509323120117, 451
[INFO] 2021-07-12 18:37:31,053 [run_pretraining.py:  535]:	loss/mlm_loss, 9.236509323120117, 451
[INFO] 2021-07-12 18:37:31,054 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.500000159168849e-06, 451
[INFO] 2021-07-12 18:37:31,054 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 451
[INFO] 2021-07-12 18:37:31,054 [run_pretraining.py:  558]:	worker_index: 2, step: 451, cost: 9.236509, mlm loss: 9.236509, speed: 0.951370 steps/s, speed: 7.610957 samples/s, speed: 3896.809782 tokens/s, learning rate: 4.500e-06, loss_scalings: 13421.773438, pp_loss: 9.030885
[INFO] 2021-07-12 18:37:31,054 [run_pretraining.py:  512]:	********exe.run_451******* 
[INFO] 2021-07-12 18:37:56,800 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:56,800 [run_pretraining.py:  534]:	loss/total_loss, 8.87820053100586, 452
[INFO] 2021-07-12 18:37:56,800 [run_pretraining.py:  535]:	loss/mlm_loss, 8.87820053100586, 452
[INFO] 2021-07-12 18:37:56,800 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.510000053414842e-06, 452
[INFO] 2021-07-12 18:37:56,801 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 452
[INFO] 2021-07-12 18:37:56,801 [run_pretraining.py:  558]:	worker_index: 2, step: 452, cost: 8.878201, mlm loss: 8.878201, speed: 0.038841 steps/s, speed: 0.310725 samples/s, speed: 159.090986 tokens/s, learning rate: 4.510e-06, loss_scalings: 13421.773438, pp_loss: 8.859294
[INFO] 2021-07-12 18:37:56,801 [run_pretraining.py:  512]:	********exe.run_452******* 
[INFO] 2021-07-12 18:37:57,722 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:57,723 [run_pretraining.py:  534]:	loss/total_loss, 10.030744552612305, 453
[INFO] 2021-07-12 18:37:57,723 [run_pretraining.py:  535]:	loss/mlm_loss, 10.030744552612305, 453
[INFO] 2021-07-12 18:37:57,723 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.5199999476608355e-06, 453
[INFO] 2021-07-12 18:37:57,723 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 453
[INFO] 2021-07-12 18:37:57,723 [run_pretraining.py:  558]:	worker_index: 2, step: 453, cost: 10.030745, mlm loss: 10.030745, speed: 1.084711 steps/s, speed: 8.677688 samples/s, speed: 4442.976161 tokens/s, learning rate: 4.520e-06, loss_scalings: 13421.773438, pp_loss: 9.225342
[INFO] 2021-07-12 18:37:57,723 [run_pretraining.py:  512]:	********exe.run_453******* 
[INFO] 2021-07-12 18:37:58,634 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:58,635 [run_pretraining.py:  534]:	loss/total_loss, 9.25485897064209, 454
[INFO] 2021-07-12 18:37:58,635 [run_pretraining.py:  535]:	loss/mlm_loss, 9.25485897064209, 454
[INFO] 2021-07-12 18:37:58,635 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.529999841906829e-06, 454
[INFO] 2021-07-12 18:37:58,635 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 454
[INFO] 2021-07-12 18:37:58,635 [run_pretraining.py:  558]:	worker_index: 2, step: 454, cost: 9.254859, mlm loss: 9.254859, speed: 1.097461 steps/s, speed: 8.779686 samples/s, speed: 4495.199202 tokens/s, learning rate: 4.530e-06, loss_scalings: 13421.773438, pp_loss: 9.112206
[INFO] 2021-07-12 18:37:58,635 [run_pretraining.py:  512]:	********exe.run_454******* 
[INFO] 2021-07-12 18:37:59,535 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:59,536 [run_pretraining.py:  534]:	loss/total_loss, 9.171255111694336, 455
[INFO] 2021-07-12 18:37:59,536 [run_pretraining.py:  535]:	loss/mlm_loss, 9.171255111694336, 455
[INFO] 2021-07-12 18:37:59,536 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.540000190900173e-06, 455
[INFO] 2021-07-12 18:37:59,536 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 455
[INFO] 2021-07-12 18:37:59,536 [run_pretraining.py:  558]:	worker_index: 2, step: 455, cost: 9.171255, mlm loss: 9.171255, speed: 1.110533 steps/s, speed: 8.884266 samples/s, speed: 4548.743998 tokens/s, learning rate: 4.540e-06, loss_scalings: 13421.773438, pp_loss: 9.204105
[INFO] 2021-07-12 18:37:59,536 [run_pretraining.py:  512]:	********exe.run_455******* 
[INFO] 2021-07-12 18:38:00,442 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:00,442 [run_pretraining.py:  534]:	loss/total_loss, 5.44659948348999, 456
[INFO] 2021-07-12 18:38:00,442 [run_pretraining.py:  535]:	loss/mlm_loss, 5.44659948348999, 456
[INFO] 2021-07-12 18:38:00,442 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.5499996303988155e-06, 456
[INFO] 2021-07-12 18:38:00,443 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 456
[INFO] 2021-07-12 18:38:00,443 [run_pretraining.py:  558]:	worker_index: 2, step: 456, cost: 5.446599, mlm loss: 5.446599, speed: 1.103751 steps/s, speed: 8.830007 samples/s, speed: 4520.963479 tokens/s, learning rate: 4.550e-06, loss_scalings: 13421.773438, pp_loss: 7.885789
[INFO] 2021-07-12 18:38:00,443 [run_pretraining.py:  512]:	********exe.run_456******* 
[INFO] 2021-07-12 18:38:01,352 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:01,353 [run_pretraining.py:  534]:	loss/total_loss, 9.344858169555664, 457
[INFO] 2021-07-12 18:38:01,353 [run_pretraining.py:  535]:	loss/mlm_loss, 9.344858169555664, 457
[INFO] 2021-07-12 18:38:01,353 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.55999997939216e-06, 457
[INFO] 2021-07-12 18:38:01,353 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 457
[INFO] 2021-07-12 18:38:01,353 [run_pretraining.py:  558]:	worker_index: 2, step: 457, cost: 9.344858, mlm loss: 9.344858, speed: 1.098781 steps/s, speed: 8.790248 samples/s, speed: 4500.606770 tokens/s, learning rate: 4.560e-06, loss_scalings: 13421.773438, pp_loss: 9.126871
[INFO] 2021-07-12 18:38:01,353 [run_pretraining.py:  512]:	********exe.run_457******* 
[INFO] 2021-07-12 18:38:02,255 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:02,255 [run_pretraining.py:  534]:	loss/total_loss, 9.120338439941406, 458
[INFO] 2021-07-12 18:38:02,256 [run_pretraining.py:  535]:	loss/mlm_loss, 9.120338439941406, 458
[INFO] 2021-07-12 18:38:02,256 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.569999873638153e-06, 458
[INFO] 2021-07-12 18:38:02,256 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 458
[INFO] 2021-07-12 18:38:02,256 [run_pretraining.py:  558]:	worker_index: 2, step: 458, cost: 9.120338, mlm loss: 9.120338, speed: 1.108767 steps/s, speed: 8.870134 samples/s, speed: 4541.508777 tokens/s, learning rate: 4.570e-06, loss_scalings: 13421.773438, pp_loss: 9.240734
[INFO] 2021-07-12 18:38:02,256 [run_pretraining.py:  512]:	********exe.run_458******* 
[INFO] 2021-07-12 18:38:03,173 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:03,173 [run_pretraining.py:  534]:	loss/total_loss, 9.385477066040039, 459
[INFO] 2021-07-12 18:38:03,173 [run_pretraining.py:  535]:	loss/mlm_loss, 9.385477066040039, 459
[INFO] 2021-07-12 18:38:03,173 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.579999767884146e-06, 459
[INFO] 2021-07-12 18:38:03,173 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 459
[INFO] 2021-07-12 18:38:03,173 [run_pretraining.py:  558]:	worker_index: 2, step: 459, cost: 9.385477, mlm loss: 9.385477, speed: 1.090589 steps/s, speed: 8.724712 samples/s, speed: 4467.052683 tokens/s, learning rate: 4.580e-06, loss_scalings: 13421.773438, pp_loss: 9.120254
[INFO] 2021-07-12 18:38:03,173 [run_pretraining.py:  512]:	********exe.run_459******* 
[INFO] 2021-07-12 18:38:04,084 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:04,084 [run_pretraining.py:  534]:	loss/total_loss, 9.039552688598633, 460
[INFO] 2021-07-12 18:38:04,085 [run_pretraining.py:  535]:	loss/mlm_loss, 9.039552688598633, 460
[INFO] 2021-07-12 18:38:04,085 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.58999966213014e-06, 460
[INFO] 2021-07-12 18:38:04,085 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 460
[INFO] 2021-07-12 18:38:04,085 [run_pretraining.py:  558]:	worker_index: 2, step: 460, cost: 9.039553, mlm loss: 9.039553, speed: 1.097874 steps/s, speed: 8.782991 samples/s, speed: 4496.891202 tokens/s, learning rate: 4.590e-06, loss_scalings: 13421.773438, pp_loss: 9.133332
[INFO] 2021-07-12 18:38:04,085 [run_pretraining.py:  512]:	********exe.run_460******* 
[INFO] 2021-07-12 18:38:04,987 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:04,988 [run_pretraining.py:  534]:	loss/total_loss, 5.395012378692627, 461
[INFO] 2021-07-12 18:38:04,988 [run_pretraining.py:  535]:	loss/mlm_loss, 5.395012378692627, 461
[INFO] 2021-07-12 18:38:04,988 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.600000011123484e-06, 461
[INFO] 2021-07-12 18:38:04,988 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 461
[INFO] 2021-07-12 18:38:04,988 [run_pretraining.py:  558]:	worker_index: 2, step: 461, cost: 5.395012, mlm loss: 5.395012, speed: 1.107637 steps/s, speed: 8.861095 samples/s, speed: 4536.880573 tokens/s, learning rate: 4.600e-06, loss_scalings: 13421.773438, pp_loss: 7.276077
[INFO] 2021-07-12 18:38:04,988 [run_pretraining.py:  512]:	********exe.run_461******* 
[INFO] 2021-07-12 18:38:05,902 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:05,902 [run_pretraining.py:  534]:	loss/total_loss, 8.830059051513672, 462
[INFO] 2021-07-12 18:38:05,903 [run_pretraining.py:  535]:	loss/mlm_loss, 8.830059051513672, 462
[INFO] 2021-07-12 18:38:05,903 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.609999905369477e-06, 462
[INFO] 2021-07-12 18:38:05,903 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 462
[INFO] 2021-07-12 18:38:05,903 [run_pretraining.py:  558]:	worker_index: 2, step: 462, cost: 8.830059, mlm loss: 8.830059, speed: 1.094134 steps/s, speed: 8.753068 samples/s, speed: 4481.570947 tokens/s, learning rate: 4.610e-06, loss_scalings: 13421.773438, pp_loss: 9.123598
[INFO] 2021-07-12 18:38:05,903 [run_pretraining.py:  512]:	********exe.run_462******* 
[INFO] 2021-07-12 18:38:06,805 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:06,806 [run_pretraining.py:  534]:	loss/total_loss, 8.910415649414062, 463
[INFO] 2021-07-12 18:38:06,806 [run_pretraining.py:  535]:	loss/mlm_loss, 8.910415649414062, 463
[INFO] 2021-07-12 18:38:06,806 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.619999799615471e-06, 463
[INFO] 2021-07-12 18:38:06,806 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 463
[INFO] 2021-07-12 18:38:06,806 [run_pretraining.py:  558]:	worker_index: 2, step: 463, cost: 8.910416, mlm loss: 8.910416, speed: 1.107579 steps/s, speed: 8.860634 samples/s, speed: 4536.644559 tokens/s, learning rate: 4.620e-06, loss_scalings: 13421.773438, pp_loss: 8.918121
[INFO] 2021-07-12 18:38:06,806 [run_pretraining.py:  512]:	********exe.run_463******* 
[INFO] 2021-07-12 18:38:07,715 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:07,716 [run_pretraining.py:  534]:	loss/total_loss, 9.175497055053711, 464
[INFO] 2021-07-12 18:38:07,716 [run_pretraining.py:  535]:	loss/mlm_loss, 9.175497055053711, 464
[INFO] 2021-07-12 18:38:07,716 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.630000148608815e-06, 464
[INFO] 2021-07-12 18:38:07,716 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 464
[INFO] 2021-07-12 18:38:07,716 [run_pretraining.py:  558]:	worker_index: 2, step: 464, cost: 9.175497, mlm loss: 9.175497, speed: 1.099950 steps/s, speed: 8.799602 samples/s, speed: 4505.396337 tokens/s, learning rate: 4.630e-06, loss_scalings: 13421.773438, pp_loss: 9.222757
[INFO] 2021-07-12 18:38:07,716 [run_pretraining.py:  512]:	********exe.run_464******* 
[INFO] 2021-07-12 18:38:08,624 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:08,625 [run_pretraining.py:  534]:	loss/total_loss, 9.183021545410156, 465
[INFO] 2021-07-12 18:38:08,625 [run_pretraining.py:  535]:	loss/mlm_loss, 9.183021545410156, 465
[INFO] 2021-07-12 18:38:08,625 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.640000042854808e-06, 465
[INFO] 2021-07-12 18:38:08,625 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 465
[INFO] 2021-07-12 18:38:08,625 [run_pretraining.py:  558]:	worker_index: 2, step: 465, cost: 9.183022, mlm loss: 9.183022, speed: 1.100642 steps/s, speed: 8.805137 samples/s, speed: 4508.230255 tokens/s, learning rate: 4.640e-06, loss_scalings: 13421.773438, pp_loss: 9.198003
[INFO] 2021-07-12 18:38:08,625 [run_pretraining.py:  512]:	********exe.run_465******* 
[INFO] 2021-07-12 18:38:09,535 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:09,535 [run_pretraining.py:  534]:	loss/total_loss, 9.326470375061035, 466
[INFO] 2021-07-12 18:38:09,535 [run_pretraining.py:  535]:	loss/mlm_loss, 9.326470375061035, 466
[INFO] 2021-07-12 18:38:09,535 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.649999937100802e-06, 466
[INFO] 2021-07-12 18:38:09,535 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 466
[INFO] 2021-07-12 18:38:09,536 [run_pretraining.py:  558]:	worker_index: 2, step: 466, cost: 9.326470, mlm loss: 9.326470, speed: 1.099194 steps/s, speed: 8.793551 samples/s, speed: 4502.298125 tokens/s, learning rate: 4.650e-06, loss_scalings: 13421.773438, pp_loss: 9.044452
[INFO] 2021-07-12 18:38:09,536 [run_pretraining.py:  512]:	********exe.run_466******* 
[INFO] 2021-07-12 18:38:10,440 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:10,441 [run_pretraining.py:  534]:	loss/total_loss, 9.255392074584961, 467
[INFO] 2021-07-12 18:38:10,441 [run_pretraining.py:  535]:	loss/mlm_loss, 9.255392074584961, 467
[INFO] 2021-07-12 18:38:10,441 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.659999831346795e-06, 467
[INFO] 2021-07-12 18:38:10,441 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 467
[INFO] 2021-07-12 18:38:10,441 [run_pretraining.py:  558]:	worker_index: 2, step: 467, cost: 9.255392, mlm loss: 9.255392, speed: 1.105087 steps/s, speed: 8.840695 samples/s, speed: 4526.435635 tokens/s, learning rate: 4.660e-06, loss_scalings: 13421.773438, pp_loss: 9.183393
[INFO] 2021-07-12 18:38:10,441 [run_pretraining.py:  512]:	********exe.run_467******* 
[INFO] 2021-07-12 18:38:11,354 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:11,354 [run_pretraining.py:  534]:	loss/total_loss, 8.791175842285156, 468
[INFO] 2021-07-12 18:38:11,354 [run_pretraining.py:  535]:	loss/mlm_loss, 8.791175842285156, 468
[INFO] 2021-07-12 18:38:11,354 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.670000180340139e-06, 468
[INFO] 2021-07-12 18:38:11,354 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 468
[INFO] 2021-07-12 18:38:11,354 [run_pretraining.py:  558]:	worker_index: 2, step: 468, cost: 8.791176, mlm loss: 8.791176, speed: 1.095494 steps/s, speed: 8.763953 samples/s, speed: 4487.143813 tokens/s, learning rate: 4.670e-06, loss_scalings: 13421.773438, pp_loss: 9.246474
[INFO] 2021-07-12 18:38:11,355 [run_pretraining.py:  512]:	********exe.run_468******* 
[INFO] 2021-07-12 18:38:12,263 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:12,263 [run_pretraining.py:  534]:	loss/total_loss, 9.58775520324707, 469
[INFO] 2021-07-12 18:38:12,264 [run_pretraining.py:  535]:	loss/mlm_loss, 9.58775520324707, 469
[INFO] 2021-07-12 18:38:12,264 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.679999619838782e-06, 469
[INFO] 2021-07-12 18:38:12,264 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 469
[INFO] 2021-07-12 18:38:12,264 [run_pretraining.py:  558]:	worker_index: 2, step: 469, cost: 9.587755, mlm loss: 9.587755, speed: 1.100443 steps/s, speed: 8.803543 samples/s, speed: 4507.414119 tokens/s, learning rate: 4.680e-06, loss_scalings: 13421.773438, pp_loss: 9.235201
[INFO] 2021-07-12 18:38:12,264 [run_pretraining.py:  512]:	********exe.run_469******* 
[INFO] 2021-07-12 18:38:13,177 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:13,177 [run_pretraining.py:  534]:	loss/total_loss, 9.314122200012207, 470
[INFO] 2021-07-12 18:38:13,177 [run_pretraining.py:  535]:	loss/mlm_loss, 9.314122200012207, 470
[INFO] 2021-07-12 18:38:13,178 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.689999968832126e-06, 470
[INFO] 2021-07-12 18:38:13,178 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 470
[INFO] 2021-07-12 18:38:13,178 [run_pretraining.py:  558]:	worker_index: 2, step: 470, cost: 9.314122, mlm loss: 9.314122, speed: 1.094870 steps/s, speed: 8.758956 samples/s, speed: 4484.585668 tokens/s, learning rate: 4.690e-06, loss_scalings: 13421.773438, pp_loss: 8.863375
[INFO] 2021-07-12 18:38:13,178 [run_pretraining.py:  512]:	********exe.run_470******* 
[INFO] 2021-07-12 18:38:14,087 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:14,088 [run_pretraining.py:  534]:	loss/total_loss, 8.950743675231934, 471
[INFO] 2021-07-12 18:38:14,088 [run_pretraining.py:  535]:	loss/mlm_loss, 8.950743675231934, 471
[INFO] 2021-07-12 18:38:14,088 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.699999863078119e-06, 471
[INFO] 2021-07-12 18:38:14,088 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 471
[INFO] 2021-07-12 18:38:14,088 [run_pretraining.py:  558]:	worker_index: 2, step: 471, cost: 8.950744, mlm loss: 8.950744, speed: 1.099143 steps/s, speed: 8.793145 samples/s, speed: 4502.090470 tokens/s, learning rate: 4.700e-06, loss_scalings: 13421.773438, pp_loss: 9.092983
[INFO] 2021-07-12 18:38:14,088 [run_pretraining.py:  512]:	********exe.run_471******* 
[INFO] 2021-07-12 18:38:14,998 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:14,999 [run_pretraining.py:  534]:	loss/total_loss, 8.992260932922363, 472
[INFO] 2021-07-12 18:38:14,999 [run_pretraining.py:  535]:	loss/mlm_loss, 8.992260932922363, 472
[INFO] 2021-07-12 18:38:14,999 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.709999757324113e-06, 472
[INFO] 2021-07-12 18:38:14,999 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 472
[INFO] 2021-07-12 18:38:14,999 [run_pretraining.py:  558]:	worker_index: 2, step: 472, cost: 8.992261, mlm loss: 8.992261, speed: 1.098368 steps/s, speed: 8.786947 samples/s, speed: 4498.916686 tokens/s, learning rate: 4.710e-06, loss_scalings: 13421.773438, pp_loss: 9.161778
[INFO] 2021-07-12 18:38:14,999 [run_pretraining.py:  512]:	********exe.run_472******* 
[INFO] 2021-07-12 18:38:15,941 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:15,942 [run_pretraining.py:  534]:	loss/total_loss, 9.146604537963867, 473
[INFO] 2021-07-12 18:38:15,942 [run_pretraining.py:  535]:	loss/mlm_loss, 9.146604537963867, 473
[INFO] 2021-07-12 18:38:15,942 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.720000106317457e-06, 473
[INFO] 2021-07-12 18:38:15,942 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 473
[INFO] 2021-07-12 18:38:15,942 [run_pretraining.py:  558]:	worker_index: 2, step: 473, cost: 9.146605, mlm loss: 9.146605, speed: 1.061311 steps/s, speed: 8.490492 samples/s, speed: 4347.131791 tokens/s, learning rate: 4.720e-06, loss_scalings: 13421.773438, pp_loss: 8.975526
[INFO] 2021-07-12 18:38:15,942 [run_pretraining.py:  512]:	********exe.run_473******* 
[INFO] 2021-07-12 18:38:16,845 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:16,846 [run_pretraining.py:  534]:	loss/total_loss, 9.19149398803711, 474
[INFO] 2021-07-12 18:38:16,846 [run_pretraining.py:  535]:	loss/mlm_loss, 9.19149398803711, 474
[INFO] 2021-07-12 18:38:16,846 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.73000000056345e-06, 474
[INFO] 2021-07-12 18:38:16,846 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 474
[INFO] 2021-07-12 18:38:16,846 [run_pretraining.py:  558]:	worker_index: 2, step: 474, cost: 9.191494, mlm loss: 9.191494, speed: 1.106993 steps/s, speed: 8.855945 samples/s, speed: 4534.243880 tokens/s, learning rate: 4.730e-06, loss_scalings: 13421.773438, pp_loss: 8.938052
[INFO] 2021-07-12 18:38:16,846 [run_pretraining.py:  512]:	********exe.run_474******* 
[INFO] 2021-07-12 18:38:17,755 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:17,755 [run_pretraining.py:  534]:	loss/total_loss, 9.070984840393066, 475
[INFO] 2021-07-12 18:38:17,755 [run_pretraining.py:  535]:	loss/mlm_loss, 9.070984840393066, 475
[INFO] 2021-07-12 18:38:17,755 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.7399998948094435e-06, 475
[INFO] 2021-07-12 18:38:17,756 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 475
[INFO] 2021-07-12 18:38:17,756 [run_pretraining.py:  558]:	worker_index: 2, step: 475, cost: 9.070985, mlm loss: 9.070985, speed: 1.100025 steps/s, speed: 8.800200 samples/s, speed: 4505.702375 tokens/s, learning rate: 4.740e-06, loss_scalings: 13421.773438, pp_loss: 9.032454
[INFO] 2021-07-12 18:38:17,756 [run_pretraining.py:  512]:	********exe.run_475******* 
[INFO] 2021-07-12 18:38:18,668 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:18,668 [run_pretraining.py:  534]:	loss/total_loss, 9.195840835571289, 476
[INFO] 2021-07-12 18:38:18,668 [run_pretraining.py:  535]:	loss/mlm_loss, 9.195840835571289, 476
[INFO] 2021-07-12 18:38:18,668 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.749999789055437e-06, 476
[INFO] 2021-07-12 18:38:18,668 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 476
[INFO] 2021-07-12 18:38:18,668 [run_pretraining.py:  558]:	worker_index: 2, step: 476, cost: 9.195841, mlm loss: 9.195841, speed: 1.096252 steps/s, speed: 8.770018 samples/s, speed: 4490.249363 tokens/s, learning rate: 4.750e-06, loss_scalings: 13421.773438, pp_loss: 9.091600
[INFO] 2021-07-12 18:38:18,668 [run_pretraining.py:  512]:	********exe.run_476******* 
[INFO] 2021-07-12 18:38:19,582 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:19,582 [run_pretraining.py:  534]:	loss/total_loss, 9.315707206726074, 477
[INFO] 2021-07-12 18:38:19,582 [run_pretraining.py:  535]:	loss/mlm_loss, 9.315707206726074, 477
[INFO] 2021-07-12 18:38:19,582 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.760000138048781e-06, 477
[INFO] 2021-07-12 18:38:19,582 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 477
[INFO] 2021-07-12 18:38:19,582 [run_pretraining.py:  558]:	worker_index: 2, step: 477, cost: 9.315707, mlm loss: 9.315707, speed: 1.094803 steps/s, speed: 8.758426 samples/s, speed: 4484.314095 tokens/s, learning rate: 4.760e-06, loss_scalings: 13421.773438, pp_loss: 9.084866
[INFO] 2021-07-12 18:38:19,582 [run_pretraining.py:  512]:	********exe.run_477******* 
[INFO] 2021-07-12 18:38:20,503 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:20,503 [run_pretraining.py:  534]:	loss/total_loss, 5.95721960067749, 478
[INFO] 2021-07-12 18:38:20,503 [run_pretraining.py:  535]:	loss/mlm_loss, 5.95721960067749, 478
[INFO] 2021-07-12 18:38:20,503 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.7699995775474235e-06, 478
[INFO] 2021-07-12 18:38:20,503 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 478
[INFO] 2021-07-12 18:38:20,503 [run_pretraining.py:  558]:	worker_index: 2, step: 478, cost: 5.957220, mlm loss: 5.957220, speed: 1.086446 steps/s, speed: 8.691568 samples/s, speed: 4450.082717 tokens/s, learning rate: 4.770e-06, loss_scalings: 13421.773438, pp_loss: 7.647799
[INFO] 2021-07-12 18:38:20,504 [run_pretraining.py:  512]:	********exe.run_478******* 
[INFO] 2021-07-12 18:38:21,419 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:21,420 [run_pretraining.py:  534]:	loss/total_loss, 9.12698745727539, 479
[INFO] 2021-07-12 18:38:21,420 [run_pretraining.py:  535]:	loss/mlm_loss, 9.12698745727539, 479
[INFO] 2021-07-12 18:38:21,420 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.779999926540768e-06, 479
[INFO] 2021-07-12 18:38:21,420 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 479
[INFO] 2021-07-12 18:38:21,420 [run_pretraining.py:  558]:	worker_index: 2, step: 479, cost: 9.126987, mlm loss: 9.126987, speed: 1.091864 steps/s, speed: 8.734912 samples/s, speed: 4472.275115 tokens/s, learning rate: 4.780e-06, loss_scalings: 13421.773438, pp_loss: 9.027549
[INFO] 2021-07-12 18:38:21,420 [run_pretraining.py:  512]:	********exe.run_479******* 
[INFO] 2021-07-12 18:38:22,330 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:22,331 [run_pretraining.py:  534]:	loss/total_loss, 8.989887237548828, 480
[INFO] 2021-07-12 18:38:22,331 [run_pretraining.py:  535]:	loss/mlm_loss, 8.989887237548828, 480
[INFO] 2021-07-12 18:38:22,331 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.789999820786761e-06, 480
[INFO] 2021-07-12 18:38:22,331 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 480
[INFO] 2021-07-12 18:38:22,331 [run_pretraining.py:  558]:	worker_index: 2, step: 480, cost: 8.989887, mlm loss: 8.989887, speed: 1.098278 steps/s, speed: 8.786226 samples/s, speed: 4498.547959 tokens/s, learning rate: 4.790e-06, loss_scalings: 13421.773438, pp_loss: 9.020168
[INFO] 2021-07-12 18:38:22,331 [run_pretraining.py:  512]:	********exe.run_480******* 
[INFO] 2021-07-12 18:38:23,240 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:23,241 [run_pretraining.py:  534]:	loss/total_loss, 9.503236770629883, 481
[INFO] 2021-07-12 18:38:23,241 [run_pretraining.py:  535]:	loss/mlm_loss, 9.503236770629883, 481
[INFO] 2021-07-12 18:38:23,241 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.7999997150327545e-06, 481
[INFO] 2021-07-12 18:38:23,241 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 481
[INFO] 2021-07-12 18:38:23,241 [run_pretraining.py:  558]:	worker_index: 2, step: 481, cost: 9.503237, mlm loss: 9.503237, speed: 1.099817 steps/s, speed: 8.798534 samples/s, speed: 4504.849354 tokens/s, learning rate: 4.800e-06, loss_scalings: 13421.773438, pp_loss: 9.105256
[INFO] 2021-07-12 18:38:23,241 [run_pretraining.py:  512]:	********exe.run_481******* 
[INFO] 2021-07-12 18:38:24,138 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:24,139 [run_pretraining.py:  534]:	loss/total_loss, 9.446353912353516, 482
[INFO] 2021-07-12 18:38:24,139 [run_pretraining.py:  535]:	loss/mlm_loss, 9.446353912353516, 482
[INFO] 2021-07-12 18:38:24,139 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.809999609278748e-06, 482
[INFO] 2021-07-12 18:38:24,139 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 482
[INFO] 2021-07-12 18:38:24,139 [run_pretraining.py:  558]:	worker_index: 2, step: 482, cost: 9.446354, mlm loss: 9.446354, speed: 1.114314 steps/s, speed: 8.914515 samples/s, speed: 4564.231873 tokens/s, learning rate: 4.810e-06, loss_scalings: 13421.773438, pp_loss: 9.243086
[INFO] 2021-07-12 18:38:24,139 [run_pretraining.py:  512]:	********exe.run_482******* 
[INFO] 2021-07-12 18:38:25,041 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:25,042 [run_pretraining.py:  534]:	loss/total_loss, 8.906408309936523, 483
[INFO] 2021-07-12 18:38:25,042 [run_pretraining.py:  535]:	loss/mlm_loss, 8.906408309936523, 483
[INFO] 2021-07-12 18:38:25,042 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.819999958272092e-06, 483
[INFO] 2021-07-12 18:38:25,042 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 483
[INFO] 2021-07-12 18:38:25,042 [run_pretraining.py:  558]:	worker_index: 2, step: 483, cost: 8.906408, mlm loss: 8.906408, speed: 1.107657 steps/s, speed: 8.861254 samples/s, speed: 4536.962046 tokens/s, learning rate: 4.820e-06, loss_scalings: 13421.773438, pp_loss: 9.000607
[INFO] 2021-07-12 18:38:25,042 [run_pretraining.py:  512]:	********exe.run_483******* 
[INFO] 2021-07-12 18:38:25,950 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:25,951 [run_pretraining.py:  534]:	loss/total_loss, 8.776676177978516, 484
[INFO] 2021-07-12 18:38:25,951 [run_pretraining.py:  535]:	loss/mlm_loss, 8.776676177978516, 484
[INFO] 2021-07-12 18:38:25,951 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.829999852518085e-06, 484
[INFO] 2021-07-12 18:38:25,951 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 484
[INFO] 2021-07-12 18:38:25,951 [run_pretraining.py:  558]:	worker_index: 2, step: 484, cost: 8.776676, mlm loss: 8.776676, speed: 1.101073 steps/s, speed: 8.808581 samples/s, speed: 4509.993646 tokens/s, learning rate: 4.830e-06, loss_scalings: 13421.773438, pp_loss: 8.959848
[INFO] 2021-07-12 18:38:25,951 [run_pretraining.py:  512]:	********exe.run_484******* 
[INFO] 2021-07-12 18:38:51,798 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:51,799 [run_pretraining.py:  534]:	loss/total_loss, 8.898309707641602, 485
[INFO] 2021-07-12 18:38:51,799 [run_pretraining.py:  535]:	loss/mlm_loss, 8.898309707641602, 485
[INFO] 2021-07-12 18:38:51,799 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.839999746764079e-06, 485
[INFO] 2021-07-12 18:38:51,799 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 485
[INFO] 2021-07-12 18:38:51,799 [run_pretraining.py:  558]:	worker_index: 2, step: 485, cost: 8.898310, mlm loss: 8.898310, speed: 0.038689 steps/s, speed: 0.309510 samples/s, speed: 158.469088 tokens/s, learning rate: 4.840e-06, loss_scalings: 13421.773438, pp_loss: 8.935280
[INFO] 2021-07-12 18:38:51,799 [run_pretraining.py:  512]:	********exe.run_485******* 
[INFO] 2021-07-12 18:38:52,690 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:52,690 [run_pretraining.py:  534]:	loss/total_loss, 9.089401245117188, 486
[INFO] 2021-07-12 18:38:52,690 [run_pretraining.py:  535]:	loss/mlm_loss, 9.089401245117188, 486
[INFO] 2021-07-12 18:38:52,691 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.850000095757423e-06, 486
[INFO] 2021-07-12 18:38:52,691 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 486
[INFO] 2021-07-12 18:38:52,691 [run_pretraining.py:  558]:	worker_index: 2, step: 486, cost: 9.089401, mlm loss: 9.089401, speed: 1.122186 steps/s, speed: 8.977486 samples/s, speed: 4596.472938 tokens/s, learning rate: 4.850e-06, loss_scalings: 13421.773438, pp_loss: 7.894561
[INFO] 2021-07-12 18:38:52,691 [run_pretraining.py:  512]:	********exe.run_486******* 
[INFO] 2021-07-12 18:39:19,133 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:19,133 [run_pretraining.py:  534]:	loss/total_loss, 9.673439025878906, 487
[INFO] 2021-07-12 18:39:19,133 [run_pretraining.py:  535]:	loss/mlm_loss, 9.673439025878906, 487
[INFO] 2021-07-12 18:39:19,133 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.859999990003416e-06, 487
[INFO] 2021-07-12 18:39:19,134 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 487
[INFO] 2021-07-12 18:39:19,134 [run_pretraining.py:  558]:	worker_index: 2, step: 487, cost: 9.673439, mlm loss: 9.673439, speed: 0.037818 steps/s, speed: 0.302547 samples/s, speed: 154.903870 tokens/s, learning rate: 4.860e-06, loss_scalings: 13421.773438, pp_loss: 9.143762
[INFO] 2021-07-12 18:39:19,134 [run_pretraining.py:  512]:	********exe.run_487******* 
[INFO] 2021-07-12 18:39:44,489 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:44,489 [run_pretraining.py:  534]:	loss/total_loss, 8.633017539978027, 488
[INFO] 2021-07-12 18:39:44,489 [run_pretraining.py:  535]:	loss/mlm_loss, 8.633017539978027, 488
[INFO] 2021-07-12 18:39:44,489 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.86999988424941e-06, 488
[INFO] 2021-07-12 18:39:44,489 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 488
[INFO] 2021-07-12 18:39:44,490 [run_pretraining.py:  558]:	worker_index: 2, step: 488, cost: 8.633018, mlm loss: 8.633018, speed: 0.039439 steps/s, speed: 0.315516 samples/s, speed: 161.544112 tokens/s, learning rate: 4.870e-06, loss_scalings: 13421.773438, pp_loss: 8.840269
[INFO] 2021-07-12 18:39:44,490 [run_pretraining.py:  512]:	********exe.run_488******* 
[INFO] 2021-07-12 18:39:45,400 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:45,401 [run_pretraining.py:  534]:	loss/total_loss, 9.078685760498047, 489
[INFO] 2021-07-12 18:39:45,401 [run_pretraining.py:  535]:	loss/mlm_loss, 9.078685760498047, 489
[INFO] 2021-07-12 18:39:45,401 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.879999778495403e-06, 489
[INFO] 2021-07-12 18:39:45,401 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 489
[INFO] 2021-07-12 18:39:45,401 [run_pretraining.py:  558]:	worker_index: 2, step: 489, cost: 9.078686, mlm loss: 9.078686, speed: 1.097850 steps/s, speed: 8.782800 samples/s, speed: 4496.793506 tokens/s, learning rate: 4.880e-06, loss_scalings: 13421.773438, pp_loss: 9.188776
[INFO] 2021-07-12 18:39:45,401 [run_pretraining.py:  512]:	********exe.run_489******* 
[INFO] 2021-07-12 18:39:46,304 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:46,305 [run_pretraining.py:  534]:	loss/total_loss, 9.369044303894043, 490
[INFO] 2021-07-12 18:39:46,305 [run_pretraining.py:  535]:	loss/mlm_loss, 9.369044303894043, 490
[INFO] 2021-07-12 18:39:46,305 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.890000127488747e-06, 490
[INFO] 2021-07-12 18:39:46,305 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 490
[INFO] 2021-07-12 18:39:46,305 [run_pretraining.py:  558]:	worker_index: 2, step: 490, cost: 9.369044, mlm loss: 9.369044, speed: 1.106734 steps/s, speed: 8.853875 samples/s, speed: 4533.183840 tokens/s, learning rate: 4.890e-06, loss_scalings: 13421.773438, pp_loss: 9.170303
[INFO] 2021-07-12 18:39:46,305 [run_pretraining.py:  512]:	********exe.run_490******* 
[INFO] 2021-07-12 18:39:47,218 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:47,218 [run_pretraining.py:  534]:	loss/total_loss, 8.969964981079102, 491
[INFO] 2021-07-12 18:39:47,218 [run_pretraining.py:  535]:	loss/mlm_loss, 8.969964981079102, 491
[INFO] 2021-07-12 18:39:47,218 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.89999956698739e-06, 491
[INFO] 2021-07-12 18:39:47,218 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 491
[INFO] 2021-07-12 18:39:47,218 [run_pretraining.py:  558]:	worker_index: 2, step: 491, cost: 8.969965, mlm loss: 8.969965, speed: 1.095617 steps/s, speed: 8.764939 samples/s, speed: 4487.648993 tokens/s, learning rate: 4.900e-06, loss_scalings: 13421.773438, pp_loss: 9.021952
[INFO] 2021-07-12 18:39:47,219 [run_pretraining.py:  512]:	********exe.run_491******* 
[INFO] 2021-07-12 18:39:48,122 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:48,122 [run_pretraining.py:  534]:	loss/total_loss, 9.148639678955078, 492
[INFO] 2021-07-12 18:39:48,122 [run_pretraining.py:  535]:	loss/mlm_loss, 9.148639678955078, 492
[INFO] 2021-07-12 18:39:48,122 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.909999915980734e-06, 492
[INFO] 2021-07-12 18:39:48,122 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 492
[INFO] 2021-07-12 18:39:48,122 [run_pretraining.py:  558]:	worker_index: 2, step: 492, cost: 9.148640, mlm loss: 9.148640, speed: 1.107025 steps/s, speed: 8.856202 samples/s, speed: 4534.375522 tokens/s, learning rate: 4.910e-06, loss_scalings: 13421.773438, pp_loss: 8.996001
[INFO] 2021-07-12 18:39:48,122 [run_pretraining.py:  512]:	********exe.run_492******* 
[INFO] 2021-07-12 18:39:49,034 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:49,035 [run_pretraining.py:  534]:	loss/total_loss, 9.191441535949707, 493
[INFO] 2021-07-12 18:39:49,035 [run_pretraining.py:  535]:	loss/mlm_loss, 9.191441535949707, 493
[INFO] 2021-07-12 18:39:49,035 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.919999810226727e-06, 493
[INFO] 2021-07-12 18:39:49,035 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 493
[INFO] 2021-07-12 18:39:49,035 [run_pretraining.py:  558]:	worker_index: 2, step: 493, cost: 9.191442, mlm loss: 9.191442, speed: 1.096349 steps/s, speed: 8.770795 samples/s, speed: 4490.647250 tokens/s, learning rate: 4.920e-06, loss_scalings: 13421.773438, pp_loss: 9.184998
[INFO] 2021-07-12 18:39:49,035 [run_pretraining.py:  512]:	********exe.run_493******* 
[INFO] 2021-07-12 18:39:49,933 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:49,933 [run_pretraining.py:  534]:	loss/total_loss, 8.830838203430176, 494
[INFO] 2021-07-12 18:39:49,933 [run_pretraining.py:  535]:	loss/mlm_loss, 8.830838203430176, 494
[INFO] 2021-07-12 18:39:49,933 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.929999704472721e-06, 494
[INFO] 2021-07-12 18:39:49,933 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 494
[INFO] 2021-07-12 18:39:49,933 [run_pretraining.py:  558]:	worker_index: 2, step: 494, cost: 8.830838, mlm loss: 8.830838, speed: 1.114025 steps/s, speed: 8.912202 samples/s, speed: 4563.047476 tokens/s, learning rate: 4.930e-06, loss_scalings: 13421.773438, pp_loss: 8.995401
[INFO] 2021-07-12 18:39:49,933 [run_pretraining.py:  512]:	********exe.run_494******* 
[INFO] 2021-07-12 18:39:50,835 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:50,835 [run_pretraining.py:  534]:	loss/total_loss, 9.24539566040039, 495
[INFO] 2021-07-12 18:39:50,836 [run_pretraining.py:  535]:	loss/mlm_loss, 9.24539566040039, 495
[INFO] 2021-07-12 18:39:50,836 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.940000053466065e-06, 495
[INFO] 2021-07-12 18:39:50,836 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 495
[INFO] 2021-07-12 18:39:50,836 [run_pretraining.py:  558]:	worker_index: 2, step: 495, cost: 9.245396, mlm loss: 9.245396, speed: 1.108795 steps/s, speed: 8.870362 samples/s, speed: 4541.625233 tokens/s, learning rate: 4.940e-06, loss_scalings: 13421.773438, pp_loss: 9.064487
[INFO] 2021-07-12 18:39:50,836 [run_pretraining.py:  512]:	********exe.run_495******* 
[INFO] 2021-07-12 18:39:51,745 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:51,746 [run_pretraining.py:  534]:	loss/total_loss, 8.965296745300293, 496
[INFO] 2021-07-12 18:39:51,746 [run_pretraining.py:  535]:	loss/mlm_loss, 8.965296745300293, 496
[INFO] 2021-07-12 18:39:51,746 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.949999947712058e-06, 496
[INFO] 2021-07-12 18:39:51,746 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 496
[INFO] 2021-07-12 18:39:51,746 [run_pretraining.py:  558]:	worker_index: 2, step: 496, cost: 8.965297, mlm loss: 8.965297, speed: 1.099090 steps/s, speed: 8.792719 samples/s, speed: 4501.872218 tokens/s, learning rate: 4.950e-06, loss_scalings: 13421.773438, pp_loss: 8.939803
[INFO] 2021-07-12 18:39:51,746 [run_pretraining.py:  512]:	********exe.run_496******* 
[INFO] 2021-07-12 18:39:52,660 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:52,660 [run_pretraining.py:  534]:	loss/total_loss, 8.978836059570312, 497
[INFO] 2021-07-12 18:39:52,660 [run_pretraining.py:  535]:	loss/mlm_loss, 8.978836059570312, 497
[INFO] 2021-07-12 18:39:52,660 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.9599998419580515e-06, 497
[INFO] 2021-07-12 18:39:52,660 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 497
[INFO] 2021-07-12 18:39:52,661 [run_pretraining.py:  558]:	worker_index: 2, step: 497, cost: 8.978836, mlm loss: 8.978836, speed: 1.094506 steps/s, speed: 8.756047 samples/s, speed: 4483.095934 tokens/s, learning rate: 4.960e-06, loss_scalings: 13421.773438, pp_loss: 9.021591
[INFO] 2021-07-12 18:39:52,661 [run_pretraining.py:  512]:	********exe.run_497******* 
[INFO] 2021-07-12 18:39:53,570 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:53,571 [run_pretraining.py:  534]:	loss/total_loss, 9.166772842407227, 498
[INFO] 2021-07-12 18:39:53,571 [run_pretraining.py:  535]:	loss/mlm_loss, 9.166772842407227, 498
[INFO] 2021-07-12 18:39:53,571 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.969999736204045e-06, 498
[INFO] 2021-07-12 18:39:53,571 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 498
[INFO] 2021-07-12 18:39:53,571 [run_pretraining.py:  558]:	worker_index: 2, step: 498, cost: 9.166773, mlm loss: 9.166773, speed: 1.099149 steps/s, speed: 8.793194 samples/s, speed: 4502.115246 tokens/s, learning rate: 4.970e-06, loss_scalings: 13421.773438, pp_loss: 8.938139
[INFO] 2021-07-12 18:39:53,571 [run_pretraining.py:  512]:	********exe.run_498******* 
[INFO] 2021-07-12 18:39:54,480 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:54,481 [run_pretraining.py:  534]:	loss/total_loss, 9.022884368896484, 499
[INFO] 2021-07-12 18:39:54,481 [run_pretraining.py:  535]:	loss/mlm_loss, 9.022884368896484, 499
[INFO] 2021-07-12 18:39:54,481 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.980000085197389e-06, 499
[INFO] 2021-07-12 18:39:54,481 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 499
[INFO] 2021-07-12 18:39:54,481 [run_pretraining.py:  558]:	worker_index: 2, step: 499, cost: 9.022884, mlm loss: 9.022884, speed: 1.099574 steps/s, speed: 8.796592 samples/s, speed: 4503.854963 tokens/s, learning rate: 4.980e-06, loss_scalings: 13421.773438, pp_loss: 8.399375
[INFO] 2021-07-12 18:39:54,481 [run_pretraining.py:  512]:	********exe.run_499******* 
[INFO] 2021-07-12 18:39:55,393 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:55,394 [run_pretraining.py:  534]:	loss/total_loss, 9.106962203979492, 500
[INFO] 2021-07-12 18:39:55,394 [run_pretraining.py:  535]:	loss/mlm_loss, 9.106962203979492, 500
[INFO] 2021-07-12 18:39:55,394 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.9899999794433825e-06, 500
[INFO] 2021-07-12 18:39:55,394 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 500
[INFO] 2021-07-12 18:39:55,394 [run_pretraining.py:  558]:	worker_index: 2, step: 500, cost: 9.106962, mlm loss: 9.106962, speed: 1.095755 steps/s, speed: 8.766041 samples/s, speed: 4488.212913 tokens/s, learning rate: 4.990e-06, loss_scalings: 13421.773438, pp_loss: 9.226019
[INFO] 2021-07-12 18:39:55,394 [run_pretraining.py:  512]:	********exe.run_500******* 
[INFO] 2021-07-12 18:39:56,298 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:56,298 [run_pretraining.py:  534]:	loss/total_loss, 8.824640274047852, 501
[INFO] 2021-07-12 18:39:56,299 [run_pretraining.py:  535]:	loss/mlm_loss, 8.824640274047852, 501
[INFO] 2021-07-12 18:39:56,299 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.999999873689376e-06, 501
[INFO] 2021-07-12 18:39:56,299 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 501
[INFO] 2021-07-12 18:39:56,299 [run_pretraining.py:  558]:	worker_index: 2, step: 501, cost: 8.824640, mlm loss: 8.824640, speed: 1.106241 steps/s, speed: 8.849926 samples/s, speed: 4531.162047 tokens/s, learning rate: 5.000e-06, loss_scalings: 13421.773438, pp_loss: 8.945980
[INFO] 2021-07-12 18:39:56,299 [run_pretraining.py:  512]:	********exe.run_501******* 
[INFO] 2021-07-12 18:39:57,208 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:57,209 [run_pretraining.py:  534]:	loss/total_loss, 8.979157447814941, 502
[INFO] 2021-07-12 18:39:57,209 [run_pretraining.py:  535]:	loss/mlm_loss, 8.979157447814941, 502
[INFO] 2021-07-12 18:39:57,209 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.009999767935369e-06, 502
[INFO] 2021-07-12 18:39:57,209 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 502
[INFO] 2021-07-12 18:39:57,209 [run_pretraining.py:  558]:	worker_index: 2, step: 502, cost: 8.979157, mlm loss: 8.979157, speed: 1.099025 steps/s, speed: 8.792201 samples/s, speed: 4501.606804 tokens/s, learning rate: 5.010e-06, loss_scalings: 13421.773438, pp_loss: 9.094910
[INFO] 2021-07-12 18:39:57,209 [run_pretraining.py:  512]:	********exe.run_502******* 
[INFO] 2021-07-12 18:39:58,116 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:58,116 [run_pretraining.py:  534]:	loss/total_loss, 9.23603630065918, 503
[INFO] 2021-07-12 18:39:58,116 [run_pretraining.py:  535]:	loss/mlm_loss, 9.23603630065918, 503
[INFO] 2021-07-12 18:39:58,116 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.020000116928713e-06, 503
[INFO] 2021-07-12 18:39:58,116 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 503
[INFO] 2021-07-12 18:39:58,116 [run_pretraining.py:  558]:	worker_index: 2, step: 503, cost: 9.236036, mlm loss: 9.236036, speed: 1.102992 steps/s, speed: 8.823932 samples/s, speed: 4517.853331 tokens/s, learning rate: 5.020e-06, loss_scalings: 13421.773438, pp_loss: 9.205509
[INFO] 2021-07-12 18:39:58,117 [run_pretraining.py:  512]:	********exe.run_503******* 
[INFO] 2021-07-12 18:39:59,025 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:59,025 [run_pretraining.py:  534]:	loss/total_loss, 8.86943244934082, 504
[INFO] 2021-07-12 18:39:59,025 [run_pretraining.py:  535]:	loss/mlm_loss, 8.86943244934082, 504
[INFO] 2021-07-12 18:39:59,025 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.029999556427356e-06, 504
[INFO] 2021-07-12 18:39:59,025 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 504
[INFO] 2021-07-12 18:39:59,025 [run_pretraining.py:  558]:	worker_index: 2, step: 504, cost: 8.869432, mlm loss: 8.869432, speed: 1.100881 steps/s, speed: 8.807046 samples/s, speed: 4509.207642 tokens/s, learning rate: 5.030e-06, loss_scalings: 13421.773438, pp_loss: 8.537072
[INFO] 2021-07-12 18:39:59,026 [run_pretraining.py:  512]:	********exe.run_504******* 
[INFO] 2021-07-12 18:39:59,934 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:59,935 [run_pretraining.py:  534]:	loss/total_loss, 8.667238235473633, 505
[INFO] 2021-07-12 18:39:59,935 [run_pretraining.py:  535]:	loss/mlm_loss, 8.667238235473633, 505
[INFO] 2021-07-12 18:39:59,935 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.0399999054207e-06, 505
[INFO] 2021-07-12 18:39:59,935 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 505
[INFO] 2021-07-12 18:39:59,935 [run_pretraining.py:  558]:	worker_index: 2, step: 505, cost: 8.667238, mlm loss: 8.667238, speed: 1.100069 steps/s, speed: 8.800553 samples/s, speed: 4505.883182 tokens/s, learning rate: 5.040e-06, loss_scalings: 13421.773438, pp_loss: 9.016323
[INFO] 2021-07-12 18:39:59,935 [run_pretraining.py:  512]:	********exe.run_505******* 
[INFO] 2021-07-12 18:40:00,841 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:00,842 [run_pretraining.py:  534]:	loss/total_loss, 9.2028169631958, 506
[INFO] 2021-07-12 18:40:00,842 [run_pretraining.py:  535]:	loss/mlm_loss, 9.2028169631958, 506
[INFO] 2021-07-12 18:40:00,842 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.050000254414044e-06, 506
[INFO] 2021-07-12 18:40:00,842 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 506
[INFO] 2021-07-12 18:40:00,842 [run_pretraining.py:  558]:	worker_index: 2, step: 506, cost: 9.202817, mlm loss: 9.202817, speed: 1.103056 steps/s, speed: 8.824447 samples/s, speed: 4518.117100 tokens/s, learning rate: 5.050e-06, loss_scalings: 13421.773438, pp_loss: 9.308105
[INFO] 2021-07-12 18:40:00,842 [run_pretraining.py:  512]:	********exe.run_506******* 
[INFO] 2021-07-12 18:40:01,756 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:01,757 [run_pretraining.py:  534]:	loss/total_loss, 9.256938934326172, 507
[INFO] 2021-07-12 18:40:01,757 [run_pretraining.py:  535]:	loss/mlm_loss, 9.256938934326172, 507
[INFO] 2021-07-12 18:40:01,757 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.059999693912687e-06, 507
[INFO] 2021-07-12 18:40:01,757 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 507
[INFO] 2021-07-12 18:40:01,757 [run_pretraining.py:  558]:	worker_index: 2, step: 507, cost: 9.256939, mlm loss: 9.256939, speed: 1.093583 steps/s, speed: 8.748661 samples/s, speed: 4479.314609 tokens/s, learning rate: 5.060e-06, loss_scalings: 13421.773438, pp_loss: 9.149240
[INFO] 2021-07-12 18:40:01,757 [run_pretraining.py:  512]:	********exe.run_507******* 
[INFO] 2021-07-12 18:40:02,668 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:02,668 [run_pretraining.py:  534]:	loss/total_loss, 9.099982261657715, 508
[INFO] 2021-07-12 18:40:02,668 [run_pretraining.py:  535]:	loss/mlm_loss, 9.099982261657715, 508
[INFO] 2021-07-12 18:40:02,668 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.070000042906031e-06, 508
[INFO] 2021-07-12 18:40:02,668 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 508
[INFO] 2021-07-12 18:40:02,668 [run_pretraining.py:  558]:	worker_index: 2, step: 508, cost: 9.099982, mlm loss: 9.099982, speed: 1.098295 steps/s, speed: 8.786358 samples/s, speed: 4498.615103 tokens/s, learning rate: 5.070e-06, loss_scalings: 13421.773438, pp_loss: 9.078673
[INFO] 2021-07-12 18:40:02,668 [run_pretraining.py:  512]:	********exe.run_508******* 
[INFO] 2021-07-12 18:40:03,575 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:03,576 [run_pretraining.py:  534]:	loss/total_loss, 9.256834030151367, 509
[INFO] 2021-07-12 18:40:03,576 [run_pretraining.py:  535]:	loss/mlm_loss, 9.256834030151367, 509
[INFO] 2021-07-12 18:40:03,576 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.079999937152024e-06, 509
[INFO] 2021-07-12 18:40:03,576 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 509
[INFO] 2021-07-12 18:40:03,576 [run_pretraining.py:  558]:	worker_index: 2, step: 509, cost: 9.256834, mlm loss: 9.256834, speed: 1.102355 steps/s, speed: 8.818839 samples/s, speed: 4515.245821 tokens/s, learning rate: 5.080e-06, loss_scalings: 13421.773438, pp_loss: 9.336601
[INFO] 2021-07-12 18:40:03,576 [run_pretraining.py:  512]:	********exe.run_509******* 
[INFO] 2021-07-12 18:40:04,485 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:04,486 [run_pretraining.py:  534]:	loss/total_loss, 8.75107479095459, 510
[INFO] 2021-07-12 18:40:04,486 [run_pretraining.py:  535]:	loss/mlm_loss, 8.75107479095459, 510
[INFO] 2021-07-12 18:40:04,486 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.089999831398018e-06, 510
[INFO] 2021-07-12 18:40:04,486 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 510
[INFO] 2021-07-12 18:40:04,486 [run_pretraining.py:  558]:	worker_index: 2, step: 510, cost: 8.751075, mlm loss: 8.751075, speed: 1.099542 steps/s, speed: 8.796336 samples/s, speed: 4503.723907 tokens/s, learning rate: 5.090e-06, loss_scalings: 13421.773438, pp_loss: 8.835840
[INFO] 2021-07-12 18:40:04,486 [run_pretraining.py:  512]:	********exe.run_510******* 
[INFO] 2021-07-12 18:40:05,414 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:05,414 [run_pretraining.py:  534]:	loss/total_loss, 8.662300109863281, 511
[INFO] 2021-07-12 18:40:05,414 [run_pretraining.py:  535]:	loss/mlm_loss, 8.662300109863281, 511
[INFO] 2021-07-12 18:40:05,414 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.099999725644011e-06, 511
[INFO] 2021-07-12 18:40:05,415 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 511
[INFO] 2021-07-12 18:40:05,415 [run_pretraining.py:  558]:	worker_index: 2, step: 511, cost: 8.662300, mlm loss: 8.662300, speed: 1.077745 steps/s, speed: 8.621961 samples/s, speed: 4414.444229 tokens/s, learning rate: 5.100e-06, loss_scalings: 13421.773438, pp_loss: 8.873072
[INFO] 2021-07-12 18:40:05,415 [run_pretraining.py:  512]:	********exe.run_511******* 
[INFO] 2021-07-12 18:40:06,349 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:06,349 [run_pretraining.py:  534]:	loss/total_loss, 9.116836547851562, 512
[INFO] 2021-07-12 18:40:06,349 [run_pretraining.py:  535]:	loss/mlm_loss, 9.116836547851562, 512
[INFO] 2021-07-12 18:40:06,349 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.110000074637355e-06, 512
[INFO] 2021-07-12 18:40:06,349 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 512
[INFO] 2021-07-12 18:40:06,350 [run_pretraining.py:  558]:	worker_index: 2, step: 512, cost: 9.116837, mlm loss: 9.116837, speed: 1.070296 steps/s, speed: 8.562366 samples/s, speed: 4383.931514 tokens/s, learning rate: 5.110e-06, loss_scalings: 13421.773438, pp_loss: 8.991753
[INFO] 2021-07-12 18:40:06,350 [run_pretraining.py:  512]:	********exe.run_512******* 
[INFO] 2021-07-12 18:40:07,252 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:07,252 [run_pretraining.py:  534]:	loss/total_loss, 8.654561042785645, 513
[INFO] 2021-07-12 18:40:07,252 [run_pretraining.py:  535]:	loss/mlm_loss, 8.654561042785645, 513
[INFO] 2021-07-12 18:40:07,252 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.119999514135998e-06, 513
[INFO] 2021-07-12 18:40:07,252 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 513
[INFO] 2021-07-12 18:40:07,253 [run_pretraining.py:  558]:	worker_index: 2, step: 513, cost: 8.654561, mlm loss: 8.654561, speed: 1.108166 steps/s, speed: 8.865328 samples/s, speed: 4539.047782 tokens/s, learning rate: 5.120e-06, loss_scalings: 13421.773438, pp_loss: 9.062085
[INFO] 2021-07-12 18:40:07,253 [run_pretraining.py:  512]:	********exe.run_513******* 
[INFO] 2021-07-12 18:40:08,165 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:08,165 [run_pretraining.py:  534]:	loss/total_loss, 9.326835632324219, 514
[INFO] 2021-07-12 18:40:08,165 [run_pretraining.py:  535]:	loss/mlm_loss, 9.326835632324219, 514
[INFO] 2021-07-12 18:40:08,165 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.129999863129342e-06, 514
[INFO] 2021-07-12 18:40:08,165 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 514
[INFO] 2021-07-12 18:40:08,165 [run_pretraining.py:  558]:	worker_index: 2, step: 514, cost: 9.326836, mlm loss: 9.326836, speed: 1.096150 steps/s, speed: 8.769200 samples/s, speed: 4489.830426 tokens/s, learning rate: 5.130e-06, loss_scalings: 13421.773438, pp_loss: 9.141243
[INFO] 2021-07-12 18:40:08,165 [run_pretraining.py:  512]:	********exe.run_514******* 
[INFO] 2021-07-12 18:40:09,070 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:09,070 [run_pretraining.py:  534]:	loss/total_loss, 9.227982521057129, 515
[INFO] 2021-07-12 18:40:09,070 [run_pretraining.py:  535]:	loss/mlm_loss, 9.227982521057129, 515
[INFO] 2021-07-12 18:40:09,070 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.139999757375335e-06, 515
[INFO] 2021-07-12 18:40:09,070 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 515
[INFO] 2021-07-12 18:40:09,070 [run_pretraining.py:  558]:	worker_index: 2, step: 515, cost: 9.227983, mlm loss: 9.227983, speed: 1.105720 steps/s, speed: 8.845761 samples/s, speed: 4529.029822 tokens/s, learning rate: 5.140e-06, loss_scalings: 13421.773438, pp_loss: 9.119884
[INFO] 2021-07-12 18:40:09,070 [run_pretraining.py:  512]:	********exe.run_515******* 
[INFO] 2021-07-12 18:40:09,981 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:09,982 [run_pretraining.py:  534]:	loss/total_loss, 9.111493110656738, 516
[INFO] 2021-07-12 18:40:09,982 [run_pretraining.py:  535]:	loss/mlm_loss, 9.111493110656738, 516
[INFO] 2021-07-12 18:40:09,982 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.149999651621329e-06, 516
[INFO] 2021-07-12 18:40:09,982 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 516
[INFO] 2021-07-12 18:40:09,982 [run_pretraining.py:  558]:	worker_index: 2, step: 516, cost: 9.111493, mlm loss: 9.111493, speed: 1.097362 steps/s, speed: 8.778898 samples/s, speed: 4494.795804 tokens/s, learning rate: 5.150e-06, loss_scalings: 13421.773438, pp_loss: 7.934054
[INFO] 2021-07-12 18:40:09,982 [run_pretraining.py:  512]:	********exe.run_516******* 
[INFO] 2021-07-12 18:40:10,881 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:10,881 [run_pretraining.py:  534]:	loss/total_loss, 9.180315971374512, 517
[INFO] 2021-07-12 18:40:10,882 [run_pretraining.py:  535]:	loss/mlm_loss, 9.180315971374512, 517
[INFO] 2021-07-12 18:40:10,882 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.160000000614673e-06, 517
[INFO] 2021-07-12 18:40:10,882 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 517
[INFO] 2021-07-12 18:40:10,882 [run_pretraining.py:  558]:	worker_index: 2, step: 517, cost: 9.180316, mlm loss: 9.180316, speed: 1.112464 steps/s, speed: 8.899712 samples/s, speed: 4556.652427 tokens/s, learning rate: 5.160e-06, loss_scalings: 13421.773438, pp_loss: 9.038552
[INFO] 2021-07-12 18:40:10,882 [run_pretraining.py:  512]:	********exe.run_517******* 
[INFO] 2021-07-12 18:40:11,788 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:11,789 [run_pretraining.py:  534]:	loss/total_loss, 8.992157936096191, 518
[INFO] 2021-07-12 18:40:11,789 [run_pretraining.py:  535]:	loss/mlm_loss, 8.992157936096191, 518
[INFO] 2021-07-12 18:40:11,789 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.169999894860666e-06, 518
[INFO] 2021-07-12 18:40:11,789 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 518
[INFO] 2021-07-12 18:40:11,789 [run_pretraining.py:  558]:	worker_index: 2, step: 518, cost: 8.992158, mlm loss: 8.992158, speed: 1.102810 steps/s, speed: 8.822478 samples/s, speed: 4517.108530 tokens/s, learning rate: 5.170e-06, loss_scalings: 13421.773438, pp_loss: 8.736425
[INFO] 2021-07-12 18:40:11,789 [run_pretraining.py:  512]:	********exe.run_518******* 
[INFO] 2021-07-12 18:40:12,688 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:12,689 [run_pretraining.py:  534]:	loss/total_loss, 9.221000671386719, 519
[INFO] 2021-07-12 18:40:12,689 [run_pretraining.py:  535]:	loss/mlm_loss, 9.221000671386719, 519
[INFO] 2021-07-12 18:40:12,689 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.17999978910666e-06, 519
[INFO] 2021-07-12 18:40:12,689 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 519
[INFO] 2021-07-12 18:40:12,689 [run_pretraining.py:  558]:	worker_index: 2, step: 519, cost: 9.221001, mlm loss: 9.221001, speed: 1.112005 steps/s, speed: 8.896038 samples/s, speed: 4554.771460 tokens/s, learning rate: 5.180e-06, loss_scalings: 13421.773438, pp_loss: 8.935411
[INFO] 2021-07-12 18:40:12,689 [run_pretraining.py:  512]:	********exe.run_519******* 
[INFO] 2021-07-12 18:40:13,594 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:13,595 [run_pretraining.py:  534]:	loss/total_loss, 8.996624946594238, 520
[INFO] 2021-07-12 18:40:13,595 [run_pretraining.py:  535]:	loss/mlm_loss, 8.996624946594238, 520
[INFO] 2021-07-12 18:40:13,595 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.189999683352653e-06, 520
[INFO] 2021-07-12 18:40:13,595 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 520
[INFO] 2021-07-12 18:40:13,595 [run_pretraining.py:  558]:	worker_index: 2, step: 520, cost: 8.996625, mlm loss: 8.996625, speed: 1.104421 steps/s, speed: 8.835366 samples/s, speed: 4523.707431 tokens/s, learning rate: 5.190e-06, loss_scalings: 13421.773438, pp_loss: 8.945129
[INFO] 2021-07-12 18:40:13,595 [run_pretraining.py:  512]:	********exe.run_520******* 
[INFO] 2021-07-12 18:40:14,499 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:14,499 [run_pretraining.py:  534]:	loss/total_loss, 9.033519744873047, 521
[INFO] 2021-07-12 18:40:14,499 [run_pretraining.py:  535]:	loss/mlm_loss, 9.033519744873047, 521
[INFO] 2021-07-12 18:40:14,500 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.200000032345997e-06, 521
[INFO] 2021-07-12 18:40:14,500 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 521
[INFO] 2021-07-12 18:40:14,500 [run_pretraining.py:  558]:	worker_index: 2, step: 521, cost: 9.033520, mlm loss: 9.033520, speed: 1.106217 steps/s, speed: 8.849739 samples/s, speed: 4531.066442 tokens/s, learning rate: 5.200e-06, loss_scalings: 13421.773438, pp_loss: 9.075527
[INFO] 2021-07-12 18:40:14,500 [run_pretraining.py:  512]:	********exe.run_521******* 
[INFO] 2021-07-12 18:40:15,444 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:15,444 [run_pretraining.py:  534]:	loss/total_loss, 8.671442031860352, 522
[INFO] 2021-07-12 18:40:15,444 [run_pretraining.py:  535]:	loss/mlm_loss, 8.671442031860352, 522
[INFO] 2021-07-12 18:40:15,445 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.2099999265919905e-06, 522
[INFO] 2021-07-12 18:40:15,445 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 522
[INFO] 2021-07-12 18:40:15,445 [run_pretraining.py:  558]:	worker_index: 2, step: 522, cost: 8.671442, mlm loss: 8.671442, speed: 1.058838 steps/s, speed: 8.470704 samples/s, speed: 4337.000420 tokens/s, learning rate: 5.210e-06, loss_scalings: 13421.773438, pp_loss: 8.862404
[INFO] 2021-07-12 18:40:15,445 [run_pretraining.py:  512]:	********exe.run_522******* 
[INFO] 2021-07-12 18:40:16,353 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:16,353 [run_pretraining.py:  534]:	loss/total_loss, 9.032234191894531, 523
[INFO] 2021-07-12 18:40:16,353 [run_pretraining.py:  535]:	loss/mlm_loss, 9.032234191894531, 523
[INFO] 2021-07-12 18:40:16,354 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.219999820837984e-06, 523
[INFO] 2021-07-12 18:40:16,354 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 523
[INFO] 2021-07-12 18:40:16,354 [run_pretraining.py:  558]:	worker_index: 2, step: 523, cost: 9.032234, mlm loss: 9.032234, speed: 1.100760 steps/s, speed: 8.806078 samples/s, speed: 4508.711796 tokens/s, learning rate: 5.220e-06, loss_scalings: 13421.773438, pp_loss: 8.906109
[INFO] 2021-07-12 18:40:16,354 [run_pretraining.py:  512]:	********exe.run_523******* 
[INFO] 2021-07-12 18:40:17,260 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:17,260 [run_pretraining.py:  534]:	loss/total_loss, 9.102628707885742, 524
[INFO] 2021-07-12 18:40:17,261 [run_pretraining.py:  535]:	loss/mlm_loss, 9.102628707885742, 524
[INFO] 2021-07-12 18:40:17,261 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.229999715083977e-06, 524
[INFO] 2021-07-12 18:40:17,261 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 524
[INFO] 2021-07-12 18:40:17,261 [run_pretraining.py:  558]:	worker_index: 2, step: 524, cost: 9.102629, mlm loss: 9.102629, speed: 1.103158 steps/s, speed: 8.825264 samples/s, speed: 4518.535390 tokens/s, learning rate: 5.230e-06, loss_scalings: 13421.773438, pp_loss: 9.196610
[INFO] 2021-07-12 18:40:17,261 [run_pretraining.py:  512]:	********exe.run_524******* 
[INFO] 2021-07-12 18:40:18,163 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:18,163 [run_pretraining.py:  534]:	loss/total_loss, 9.263168334960938, 525
[INFO] 2021-07-12 18:40:18,163 [run_pretraining.py:  535]:	loss/mlm_loss, 9.263168334960938, 525
[INFO] 2021-07-12 18:40:18,164 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.2400000640773214e-06, 525
[INFO] 2021-07-12 18:40:18,164 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 525
[INFO] 2021-07-12 18:40:18,164 [run_pretraining.py:  558]:	worker_index: 2, step: 525, cost: 9.263168, mlm loss: 9.263168, speed: 1.108318 steps/s, speed: 8.866544 samples/s, speed: 4539.670278 tokens/s, learning rate: 5.240e-06, loss_scalings: 13421.773438, pp_loss: 8.974486
[INFO] 2021-07-12 18:40:18,164 [run_pretraining.py:  512]:	********exe.run_525******* 
[INFO] 2021-07-12 18:40:19,070 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:19,070 [run_pretraining.py:  534]:	loss/total_loss, 9.178988456726074, 526
[INFO] 2021-07-12 18:40:19,070 [run_pretraining.py:  535]:	loss/mlm_loss, 9.178988456726074, 526
[INFO] 2021-07-12 18:40:19,070 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.249999503575964e-06, 526
[INFO] 2021-07-12 18:40:19,070 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 526
[INFO] 2021-07-12 18:40:19,070 [run_pretraining.py:  558]:	worker_index: 2, step: 526, cost: 9.178988, mlm loss: 9.178988, speed: 1.103660 steps/s, speed: 8.829280 samples/s, speed: 4520.591129 tokens/s, learning rate: 5.250e-06, loss_scalings: 13421.773438, pp_loss: 8.756898
[INFO] 2021-07-12 18:40:19,070 [run_pretraining.py:  512]:	********exe.run_526******* 
[INFO] 2021-07-12 18:40:19,978 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:19,978 [run_pretraining.py:  534]:	loss/total_loss, 8.65677261352539, 527
[INFO] 2021-07-12 18:40:19,979 [run_pretraining.py:  535]:	loss/mlm_loss, 8.65677261352539, 527
[INFO] 2021-07-12 18:40:19,979 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.259999852569308e-06, 527
[INFO] 2021-07-12 18:40:19,979 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 527
[INFO] 2021-07-12 18:40:19,979 [run_pretraining.py:  558]:	worker_index: 2, step: 527, cost: 8.656773, mlm loss: 8.656773, speed: 1.101499 steps/s, speed: 8.811996 samples/s, speed: 4511.741828 tokens/s, learning rate: 5.260e-06, loss_scalings: 13421.773438, pp_loss: 8.639025
[INFO] 2021-07-12 18:40:19,979 [run_pretraining.py:  512]:	********exe.run_527******* 
[INFO] 2021-07-12 18:40:20,891 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:20,892 [run_pretraining.py:  534]:	loss/total_loss, 9.042146682739258, 528
[INFO] 2021-07-12 18:40:20,892 [run_pretraining.py:  535]:	loss/mlm_loss, 9.042146682739258, 528
[INFO] 2021-07-12 18:40:20,892 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.270000201562652e-06, 528
[INFO] 2021-07-12 18:40:20,892 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 528
[INFO] 2021-07-12 18:40:20,892 [run_pretraining.py:  558]:	worker_index: 2, step: 528, cost: 9.042147, mlm loss: 9.042147, speed: 1.095498 steps/s, speed: 8.763980 samples/s, speed: 4487.157877 tokens/s, learning rate: 5.270e-06, loss_scalings: 13421.773438, pp_loss: 9.039228
[INFO] 2021-07-12 18:40:20,892 [run_pretraining.py:  512]:	********exe.run_528******* 
[INFO] 2021-07-12 18:40:21,793 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:21,793 [run_pretraining.py:  534]:	loss/total_loss, 8.961591720581055, 529
[INFO] 2021-07-12 18:40:21,793 [run_pretraining.py:  535]:	loss/mlm_loss, 8.961591720581055, 529
[INFO] 2021-07-12 18:40:21,793 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.279999641061295e-06, 529
[INFO] 2021-07-12 18:40:21,793 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 529
[INFO] 2021-07-12 18:40:21,793 [run_pretraining.py:  558]:	worker_index: 2, step: 529, cost: 8.961592, mlm loss: 8.961592, speed: 1.110356 steps/s, speed: 8.882847 samples/s, speed: 4548.017873 tokens/s, learning rate: 5.280e-06, loss_scalings: 13421.773438, pp_loss: 8.192112
[INFO] 2021-07-12 18:40:21,794 [run_pretraining.py:  512]:	********exe.run_529******* 
[INFO] 2021-07-12 18:40:22,699 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:22,700 [run_pretraining.py:  534]:	loss/total_loss, 8.426617622375488, 530
[INFO] 2021-07-12 18:40:22,700 [run_pretraining.py:  535]:	loss/mlm_loss, 8.426617622375488, 530
[INFO] 2021-07-12 18:40:22,700 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.289999990054639e-06, 530
[INFO] 2021-07-12 18:40:22,700 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 530
[INFO] 2021-07-12 18:40:22,700 [run_pretraining.py:  558]:	worker_index: 2, step: 530, cost: 8.426618, mlm loss: 8.426618, speed: 1.103917 steps/s, speed: 8.831338 samples/s, speed: 4521.645287 tokens/s, learning rate: 5.290e-06, loss_scalings: 13421.773438, pp_loss: 8.659377
[INFO] 2021-07-12 18:40:22,700 [run_pretraining.py:  512]:	********exe.run_530******* 
[INFO] 2021-07-12 18:40:23,609 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:23,610 [run_pretraining.py:  534]:	loss/total_loss, 8.826772689819336, 531
[INFO] 2021-07-12 18:40:23,610 [run_pretraining.py:  535]:	loss/mlm_loss, 8.826772689819336, 531
[INFO] 2021-07-12 18:40:23,610 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.299999884300632e-06, 531
[INFO] 2021-07-12 18:40:23,610 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 531
[INFO] 2021-07-12 18:40:23,610 [run_pretraining.py:  558]:	worker_index: 2, step: 531, cost: 8.826773, mlm loss: 8.826773, speed: 1.099494 steps/s, speed: 8.795953 samples/s, speed: 4503.527926 tokens/s, learning rate: 5.300e-06, loss_scalings: 13421.773438, pp_loss: 8.899336
[INFO] 2021-07-12 18:40:23,610 [run_pretraining.py:  512]:	********exe.run_531******* 
[INFO] 2021-07-12 18:40:24,519 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:24,520 [run_pretraining.py:  534]:	loss/total_loss, 9.018880844116211, 532
[INFO] 2021-07-12 18:40:24,520 [run_pretraining.py:  535]:	loss/mlm_loss, 9.018880844116211, 532
[INFO] 2021-07-12 18:40:24,520 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.309999778546626e-06, 532
[INFO] 2021-07-12 18:40:24,520 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 532
[INFO] 2021-07-12 18:40:24,520 [run_pretraining.py:  558]:	worker_index: 2, step: 532, cost: 9.018881, mlm loss: 9.018881, speed: 1.099440 steps/s, speed: 8.795520 samples/s, speed: 4503.305993 tokens/s, learning rate: 5.310e-06, loss_scalings: 13421.773438, pp_loss: 8.926139
[INFO] 2021-07-12 18:40:24,520 [run_pretraining.py:  512]:	********exe.run_532******* 
[INFO] 2021-07-12 18:40:25,424 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:25,425 [run_pretraining.py:  534]:	loss/total_loss, 8.758262634277344, 533
[INFO] 2021-07-12 18:40:25,425 [run_pretraining.py:  535]:	loss/mlm_loss, 8.758262634277344, 533
[INFO] 2021-07-12 18:40:25,425 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.319999672792619e-06, 533
[INFO] 2021-07-12 18:40:25,425 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 533
[INFO] 2021-07-12 18:40:25,425 [run_pretraining.py:  558]:	worker_index: 2, step: 533, cost: 8.758263, mlm loss: 8.758263, speed: 1.105644 steps/s, speed: 8.845155 samples/s, speed: 4528.719413 tokens/s, learning rate: 5.320e-06, loss_scalings: 13421.773438, pp_loss: 8.960476
[INFO] 2021-07-12 18:40:25,425 [run_pretraining.py:  512]:	********exe.run_533******* 
[INFO] 2021-07-12 18:40:26,353 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:26,353 [run_pretraining.py:  534]:	loss/total_loss, 8.963232040405273, 534
[INFO] 2021-07-12 18:40:26,353 [run_pretraining.py:  535]:	loss/mlm_loss, 8.963232040405273, 534
[INFO] 2021-07-12 18:40:26,353 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.330000021785963e-06, 534
[INFO] 2021-07-12 18:40:26,353 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 534
[INFO] 2021-07-12 18:40:26,353 [run_pretraining.py:  558]:	worker_index: 2, step: 534, cost: 8.963232, mlm loss: 8.963232, speed: 1.078160 steps/s, speed: 8.625281 samples/s, speed: 4416.144082 tokens/s, learning rate: 5.330e-06, loss_scalings: 13421.773438, pp_loss: 8.222458
[INFO] 2021-07-12 18:40:26,353 [run_pretraining.py:  512]:	********exe.run_534******* 
[INFO] 2021-07-12 18:40:27,251 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:27,251 [run_pretraining.py:  534]:	loss/total_loss, 9.234500885009766, 535
[INFO] 2021-07-12 18:40:27,251 [run_pretraining.py:  535]:	loss/mlm_loss, 9.234500885009766, 535
[INFO] 2021-07-12 18:40:27,252 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.339999916031957e-06, 535
[INFO] 2021-07-12 18:40:27,252 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 535
[INFO] 2021-07-12 18:40:27,252 [run_pretraining.py:  558]:	worker_index: 2, step: 535, cost: 9.234501, mlm loss: 9.234501, speed: 1.113940 steps/s, speed: 8.911518 samples/s, speed: 4562.697245 tokens/s, learning rate: 5.340e-06, loss_scalings: 13421.773438, pp_loss: 9.354279
[INFO] 2021-07-12 18:40:27,252 [run_pretraining.py:  512]:	********exe.run_535******* 
[INFO] 2021-07-12 18:40:28,158 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:28,158 [run_pretraining.py:  534]:	loss/total_loss, 9.530678749084473, 536
[INFO] 2021-07-12 18:40:28,159 [run_pretraining.py:  535]:	loss/mlm_loss, 9.530678749084473, 536
[INFO] 2021-07-12 18:40:28,159 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.34999981027795e-06, 536
[INFO] 2021-07-12 18:40:28,159 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 536
[INFO] 2021-07-12 18:40:28,159 [run_pretraining.py:  558]:	worker_index: 2, step: 536, cost: 9.530679, mlm loss: 9.530679, speed: 1.103099 steps/s, speed: 8.824796 samples/s, speed: 4518.295339 tokens/s, learning rate: 5.350e-06, loss_scalings: 13421.773438, pp_loss: 8.934904
[INFO] 2021-07-12 18:40:28,159 [run_pretraining.py:  512]:	********exe.run_536******* 
[INFO] 2021-07-12 18:40:29,065 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:29,065 [run_pretraining.py:  534]:	loss/total_loss, 9.056794166564941, 537
[INFO] 2021-07-12 18:40:29,065 [run_pretraining.py:  535]:	loss/mlm_loss, 9.056794166564941, 537
[INFO] 2021-07-12 18:40:29,065 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.359999704523943e-06, 537
[INFO] 2021-07-12 18:40:29,065 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 537
[INFO] 2021-07-12 18:40:29,065 [run_pretraining.py:  558]:	worker_index: 2, step: 537, cost: 9.056794, mlm loss: 9.056794, speed: 1.103841 steps/s, speed: 8.830732 samples/s, speed: 4521.334700 tokens/s, learning rate: 5.360e-06, loss_scalings: 13421.773438, pp_loss: 9.063487
[INFO] 2021-07-12 18:40:29,065 [run_pretraining.py:  512]:	********exe.run_537******* 
[INFO] 2021-07-12 18:40:30,022 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:30,023 [run_pretraining.py:  534]:	loss/total_loss, 8.97288703918457, 538
[INFO] 2021-07-12 18:40:30,023 [run_pretraining.py:  535]:	loss/mlm_loss, 8.97288703918457, 538
[INFO] 2021-07-12 18:40:30,023 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.370000053517288e-06, 538
[INFO] 2021-07-12 18:40:30,023 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 538
[INFO] 2021-07-12 18:40:30,023 [run_pretraining.py:  558]:	worker_index: 2, step: 538, cost: 8.972887, mlm loss: 8.972887, speed: 1.044845 steps/s, speed: 8.358763 samples/s, speed: 4279.686675 tokens/s, learning rate: 5.370e-06, loss_scalings: 13421.773438, pp_loss: 9.022618
[INFO] 2021-07-12 18:40:30,023 [run_pretraining.py:  512]:	********exe.run_538******* 
[INFO] 2021-07-12 18:40:30,982 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:30,982 [run_pretraining.py:  534]:	loss/total_loss, 8.94874382019043, 539
[INFO] 2021-07-12 18:40:30,982 [run_pretraining.py:  535]:	loss/mlm_loss, 8.94874382019043, 539
[INFO] 2021-07-12 18:40:30,983 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.379999947763281e-06, 539
[INFO] 2021-07-12 18:40:30,983 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 539
[INFO] 2021-07-12 18:40:30,983 [run_pretraining.py:  558]:	worker_index: 2, step: 539, cost: 8.948744, mlm loss: 8.948744, speed: 1.042697 steps/s, speed: 8.341576 samples/s, speed: 4270.886968 tokens/s, learning rate: 5.380e-06, loss_scalings: 13421.773438, pp_loss: 8.782715
[INFO] 2021-07-12 18:40:30,983 [run_pretraining.py:  512]:	********exe.run_539******* 
[INFO] 2021-07-12 18:40:31,886 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:31,887 [run_pretraining.py:  534]:	loss/total_loss, 8.989808082580566, 540
[INFO] 2021-07-12 18:40:31,887 [run_pretraining.py:  535]:	loss/mlm_loss, 8.989808082580566, 540
[INFO] 2021-07-12 18:40:31,887 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.389999842009274e-06, 540
[INFO] 2021-07-12 18:40:31,887 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 540
[INFO] 2021-07-12 18:40:31,887 [run_pretraining.py:  558]:	worker_index: 2, step: 540, cost: 8.989808, mlm loss: 8.989808, speed: 1.106271 steps/s, speed: 8.850166 samples/s, speed: 4531.285144 tokens/s, learning rate: 5.390e-06, loss_scalings: 13421.773438, pp_loss: 9.008686
[INFO] 2021-07-12 18:40:31,887 [run_pretraining.py:  512]:	********exe.run_540******* 
[INFO] 2021-07-12 18:40:32,784 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:32,784 [run_pretraining.py:  534]:	loss/total_loss, 8.958706855773926, 541
[INFO] 2021-07-12 18:40:32,784 [run_pretraining.py:  535]:	loss/mlm_loss, 8.958706855773926, 541
[INFO] 2021-07-12 18:40:32,784 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.4000001910026185e-06, 541
[INFO] 2021-07-12 18:40:32,784 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 541
[INFO] 2021-07-12 18:40:32,784 [run_pretraining.py:  558]:	worker_index: 2, step: 541, cost: 8.958707, mlm loss: 8.958707, speed: 1.115336 steps/s, speed: 8.922689 samples/s, speed: 4568.416732 tokens/s, learning rate: 5.400e-06, loss_scalings: 13421.773438, pp_loss: 9.100866
[INFO] 2021-07-12 18:40:32,784 [run_pretraining.py:  512]:	********exe.run_541******* 
[INFO] 2021-07-12 18:40:33,698 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:33,698 [run_pretraining.py:  534]:	loss/total_loss, 8.880241394042969, 542
[INFO] 2021-07-12 18:40:33,698 [run_pretraining.py:  535]:	loss/mlm_loss, 8.880241394042969, 542
[INFO] 2021-07-12 18:40:33,698 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.409999630501261e-06, 542
[INFO] 2021-07-12 18:40:33,698 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 542
[INFO] 2021-07-12 18:40:33,699 [run_pretraining.py:  558]:	worker_index: 2, step: 542, cost: 8.880241, mlm loss: 8.880241, speed: 1.094637 steps/s, speed: 8.757098 samples/s, speed: 4483.634137 tokens/s, learning rate: 5.410e-06, loss_scalings: 13421.773438, pp_loss: 8.897305
[INFO] 2021-07-12 18:40:33,699 [run_pretraining.py:  512]:	********exe.run_542******* 
[INFO] 2021-07-12 18:40:34,609 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:34,610 [run_pretraining.py:  534]:	loss/total_loss, 9.526875495910645, 543
[INFO] 2021-07-12 18:40:34,610 [run_pretraining.py:  535]:	loss/mlm_loss, 9.526875495910645, 543
[INFO] 2021-07-12 18:40:34,610 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.419999979494605e-06, 543
[INFO] 2021-07-12 18:40:34,610 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 543
[INFO] 2021-07-12 18:40:34,610 [run_pretraining.py:  558]:	worker_index: 2, step: 543, cost: 9.526875, mlm loss: 9.526875, speed: 1.097886 steps/s, speed: 8.783089 samples/s, speed: 4496.941817 tokens/s, learning rate: 5.420e-06, loss_scalings: 13421.773438, pp_loss: 9.147828
[INFO] 2021-07-12 18:40:34,610 [run_pretraining.py:  512]:	********exe.run_543******* 
[INFO] 2021-07-12 18:40:35,588 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:35,589 [run_pretraining.py:  534]:	loss/total_loss, 9.083955764770508, 544
[INFO] 2021-07-12 18:40:35,589 [run_pretraining.py:  535]:	loss/mlm_loss, 9.083955764770508, 544
[INFO] 2021-07-12 18:40:35,589 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.4299998737405986e-06, 544
[INFO] 2021-07-12 18:40:35,589 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 544
[INFO] 2021-07-12 18:40:35,589 [run_pretraining.py:  558]:	worker_index: 2, step: 544, cost: 9.083956, mlm loss: 9.083956, speed: 1.021769 steps/s, speed: 8.174149 samples/s, speed: 4185.164280 tokens/s, learning rate: 5.430e-06, loss_scalings: 13421.773438, pp_loss: 9.018449
[INFO] 2021-07-12 18:40:35,589 [run_pretraining.py:  512]:	********exe.run_544******* 
[INFO] 2021-07-12 18:40:36,656 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:36,657 [run_pretraining.py:  534]:	loss/total_loss, 9.46938705444336, 545
[INFO] 2021-07-12 18:40:36,657 [run_pretraining.py:  535]:	loss/mlm_loss, 9.46938705444336, 545
[INFO] 2021-07-12 18:40:36,657 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.439999767986592e-06, 545
[INFO] 2021-07-12 18:40:36,657 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 545
[INFO] 2021-07-12 18:40:36,657 [run_pretraining.py:  558]:	worker_index: 2, step: 545, cost: 9.469387, mlm loss: 9.469387, speed: 0.936959 steps/s, speed: 7.495675 samples/s, speed: 3837.785358 tokens/s, learning rate: 5.440e-06, loss_scalings: 13421.773438, pp_loss: 8.951029
[INFO] 2021-07-12 18:40:36,657 [run_pretraining.py:  512]:	********exe.run_545******* 
[INFO] 2021-07-12 18:40:37,715 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:37,716 [run_pretraining.py:  534]:	loss/total_loss, 8.863790512084961, 546
[INFO] 2021-07-12 18:40:37,716 [run_pretraining.py:  535]:	loss/mlm_loss, 8.863790512084961, 546
[INFO] 2021-07-12 18:40:37,716 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.449999662232585e-06, 546
[INFO] 2021-07-12 18:40:37,716 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 546
[INFO] 2021-07-12 18:40:37,716 [run_pretraining.py:  558]:	worker_index: 2, step: 546, cost: 8.863791, mlm loss: 8.863791, speed: 0.944870 steps/s, speed: 7.558961 samples/s, speed: 3870.188035 tokens/s, learning rate: 5.450e-06, loss_scalings: 13421.773438, pp_loss: 8.817209
[INFO] 2021-07-12 18:40:37,716 [run_pretraining.py:  512]:	********exe.run_546******* 
[INFO] 2021-07-12 18:40:38,773 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:38,773 [run_pretraining.py:  534]:	loss/total_loss, 8.704066276550293, 547
[INFO] 2021-07-12 18:40:38,773 [run_pretraining.py:  535]:	loss/mlm_loss, 8.704066276550293, 547
[INFO] 2021-07-12 18:40:38,773 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.4600000112259295e-06, 547
[INFO] 2021-07-12 18:40:38,773 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 547
[INFO] 2021-07-12 18:40:38,773 [run_pretraining.py:  558]:	worker_index: 2, step: 547, cost: 8.704066, mlm loss: 8.704066, speed: 0.946252 steps/s, speed: 7.570015 samples/s, speed: 3875.847664 tokens/s, learning rate: 5.460e-06, loss_scalings: 13421.773438, pp_loss: 8.632709
[INFO] 2021-07-12 18:40:38,774 [run_pretraining.py:  512]:	********exe.run_547******* 
[INFO] 2021-07-12 18:40:39,827 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:39,827 [run_pretraining.py:  534]:	loss/total_loss, 9.230695724487305, 548
[INFO] 2021-07-12 18:40:39,828 [run_pretraining.py:  535]:	loss/mlm_loss, 9.230695724487305, 548
[INFO] 2021-07-12 18:40:39,828 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.469999905471923e-06, 548
[INFO] 2021-07-12 18:40:39,828 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 548
[INFO] 2021-07-12 18:40:39,828 [run_pretraining.py:  558]:	worker_index: 2, step: 548, cost: 9.230696, mlm loss: 9.230696, speed: 0.948992 steps/s, speed: 7.591937 samples/s, speed: 3887.071606 tokens/s, learning rate: 5.470e-06, loss_scalings: 13421.773438, pp_loss: 7.956572
[INFO] 2021-07-12 18:40:39,828 [run_pretraining.py:  512]:	********exe.run_548******* 
[INFO] 2021-07-12 18:40:40,884 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:40,884 [run_pretraining.py:  534]:	loss/total_loss, 8.432600021362305, 549
[INFO] 2021-07-12 18:40:40,884 [run_pretraining.py:  535]:	loss/mlm_loss, 8.432600021362305, 549
[INFO] 2021-07-12 18:40:40,884 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.479999799717916e-06, 549
[INFO] 2021-07-12 18:40:40,884 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 549
[INFO] 2021-07-12 18:40:40,885 [run_pretraining.py:  558]:	worker_index: 2, step: 549, cost: 8.432600, mlm loss: 8.432600, speed: 0.946872 steps/s, speed: 7.574978 samples/s, speed: 3878.388606 tokens/s, learning rate: 5.480e-06, loss_scalings: 13421.773438, pp_loss: 8.956497
[INFO] 2021-07-12 18:40:40,885 [run_pretraining.py:  512]:	********exe.run_549******* 
[INFO] 2021-07-12 18:40:41,940 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:41,940 [run_pretraining.py:  534]:	loss/total_loss, 8.747492790222168, 550
[INFO] 2021-07-12 18:40:41,940 [run_pretraining.py:  535]:	loss/mlm_loss, 8.747492790222168, 550
[INFO] 2021-07-12 18:40:41,941 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.49000014871126e-06, 550
[INFO] 2021-07-12 18:40:41,941 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 550
[INFO] 2021-07-12 18:40:41,941 [run_pretraining.py:  558]:	worker_index: 2, step: 550, cost: 8.747493, mlm loss: 8.747493, speed: 0.947350 steps/s, speed: 7.578802 samples/s, speed: 3880.346457 tokens/s, learning rate: 5.490e-06, loss_scalings: 13421.773438, pp_loss: 8.937198
[INFO] 2021-07-12 18:40:41,941 [run_pretraining.py:  512]:	********exe.run_550******* 
[INFO] 2021-07-12 18:40:43,013 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:43,013 [run_pretraining.py:  534]:	loss/total_loss, 8.787402153015137, 551
[INFO] 2021-07-12 18:40:43,014 [run_pretraining.py:  535]:	loss/mlm_loss, 8.787402153015137, 551
[INFO] 2021-07-12 18:40:43,014 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.500000042957254e-06, 551
[INFO] 2021-07-12 18:40:43,014 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 551
[INFO] 2021-07-12 18:40:43,014 [run_pretraining.py:  558]:	worker_index: 2, step: 551, cost: 8.787402, mlm loss: 8.787402, speed: 0.932430 steps/s, speed: 7.459438 samples/s, speed: 3819.232267 tokens/s, learning rate: 5.500e-06, loss_scalings: 13421.773438, pp_loss: 8.012608
[INFO] 2021-07-12 18:40:43,014 [run_pretraining.py:  512]:	********exe.run_551******* 
[INFO] 2021-07-12 18:40:44,090 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:44,091 [run_pretraining.py:  534]:	loss/total_loss, 8.98835277557373, 552
[INFO] 2021-07-12 18:40:44,091 [run_pretraining.py:  535]:	loss/mlm_loss, 8.98835277557373, 552
[INFO] 2021-07-12 18:40:44,091 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.509999937203247e-06, 552
[INFO] 2021-07-12 18:40:44,091 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 552
[INFO] 2021-07-12 18:40:44,091 [run_pretraining.py:  558]:	worker_index: 2, step: 552, cost: 8.988353, mlm loss: 8.988353, speed: 0.928967 steps/s, speed: 7.431738 samples/s, speed: 3805.049987 tokens/s, learning rate: 5.510e-06, loss_scalings: 13421.773438, pp_loss: 8.867725
[INFO] 2021-07-12 18:40:44,091 [run_pretraining.py:  512]:	********exe.run_552******* 
[INFO] 2021-07-12 18:40:45,142 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:45,143 [run_pretraining.py:  534]:	loss/total_loss, 9.042256355285645, 553
[INFO] 2021-07-12 18:40:45,143 [run_pretraining.py:  535]:	loss/mlm_loss, 9.042256355285645, 553
[INFO] 2021-07-12 18:40:45,143 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.5199998314492404e-06, 553
[INFO] 2021-07-12 18:40:45,143 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 553
[INFO] 2021-07-12 18:40:45,143 [run_pretraining.py:  558]:	worker_index: 2, step: 553, cost: 9.042256, mlm loss: 9.042256, speed: 0.950754 steps/s, speed: 7.606035 samples/s, speed: 3894.289673 tokens/s, learning rate: 5.520e-06, loss_scalings: 13421.773438, pp_loss: 8.787841
[INFO] 2021-07-12 18:40:45,143 [run_pretraining.py:  512]:	********exe.run_553******* 
[INFO] 2021-07-12 18:40:46,200 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:46,201 [run_pretraining.py:  534]:	loss/total_loss, 8.657052040100098, 554
[INFO] 2021-07-12 18:40:46,201 [run_pretraining.py:  535]:	loss/mlm_loss, 8.657052040100098, 554
[INFO] 2021-07-12 18:40:46,201 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.530000180442585e-06, 554
[INFO] 2021-07-12 18:40:46,201 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 554
[INFO] 2021-07-12 18:40:46,201 [run_pretraining.py:  558]:	worker_index: 2, step: 554, cost: 8.657052, mlm loss: 8.657052, speed: 0.945881 steps/s, speed: 7.567051 samples/s, speed: 3874.330288 tokens/s, learning rate: 5.530e-06, loss_scalings: 13421.773438, pp_loss: 8.815723
[INFO] 2021-07-12 18:40:46,201 [run_pretraining.py:  512]:	********exe.run_554******* 
[INFO] 2021-07-12 18:40:47,264 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:47,264 [run_pretraining.py:  534]:	loss/total_loss, 8.61435604095459, 555
[INFO] 2021-07-12 18:40:47,264 [run_pretraining.py:  535]:	loss/mlm_loss, 8.61435604095459, 555
[INFO] 2021-07-12 18:40:47,264 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.539999619941227e-06, 555
[INFO] 2021-07-12 18:40:47,264 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 555
[INFO] 2021-07-12 18:40:47,264 [run_pretraining.py:  558]:	worker_index: 2, step: 555, cost: 8.614356, mlm loss: 8.614356, speed: 0.940935 steps/s, speed: 7.527479 samples/s, speed: 3854.069458 tokens/s, learning rate: 5.540e-06, loss_scalings: 13421.773438, pp_loss: 8.650778
[INFO] 2021-07-12 18:40:47,265 [run_pretraining.py:  512]:	********exe.run_555******* 
[INFO] 2021-07-12 18:40:48,319 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:48,320 [run_pretraining.py:  534]:	loss/total_loss, 9.002593994140625, 556
[INFO] 2021-07-12 18:40:48,320 [run_pretraining.py:  535]:	loss/mlm_loss, 9.002593994140625, 556
[INFO] 2021-07-12 18:40:48,320 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.549999968934571e-06, 556
[INFO] 2021-07-12 18:40:48,320 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 556
[INFO] 2021-07-12 18:40:48,320 [run_pretraining.py:  558]:	worker_index: 2, step: 556, cost: 9.002594, mlm loss: 9.002594, speed: 0.947973 steps/s, speed: 7.583786 samples/s, speed: 3882.898568 tokens/s, learning rate: 5.550e-06, loss_scalings: 13421.773438, pp_loss: 9.045404
[INFO] 2021-07-12 18:40:48,320 [run_pretraining.py:  512]:	********exe.run_556******* 
[INFO] 2021-07-12 18:40:49,399 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:49,400 [run_pretraining.py:  534]:	loss/total_loss, 8.568013191223145, 557
[INFO] 2021-07-12 18:40:49,400 [run_pretraining.py:  535]:	loss/mlm_loss, 8.568013191223145, 557
[INFO] 2021-07-12 18:40:49,400 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.559999863180565e-06, 557
[INFO] 2021-07-12 18:40:49,400 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 557
[INFO] 2021-07-12 18:40:49,400 [run_pretraining.py:  558]:	worker_index: 2, step: 557, cost: 8.568013, mlm loss: 8.568013, speed: 0.926114 steps/s, speed: 7.408911 samples/s, speed: 3793.362445 tokens/s, learning rate: 5.560e-06, loss_scalings: 13421.773438, pp_loss: 8.828237
[INFO] 2021-07-12 18:40:49,400 [run_pretraining.py:  512]:	********exe.run_557******* 
[INFO] 2021-07-12 18:40:50,480 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:50,480 [run_pretraining.py:  534]:	loss/total_loss, 8.482809066772461, 558
[INFO] 2021-07-12 18:40:50,480 [run_pretraining.py:  535]:	loss/mlm_loss, 8.482809066772461, 558
[INFO] 2021-07-12 18:40:50,480 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.569999757426558e-06, 558
[INFO] 2021-07-12 18:40:50,480 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 558
[INFO] 2021-07-12 18:40:50,480 [run_pretraining.py:  558]:	worker_index: 2, step: 558, cost: 8.482809, mlm loss: 8.482809, speed: 0.926306 steps/s, speed: 7.410449 samples/s, speed: 3794.149938 tokens/s, learning rate: 5.570e-06, loss_scalings: 13421.773438, pp_loss: 8.684288
[INFO] 2021-07-12 18:40:50,481 [run_pretraining.py:  512]:	********exe.run_558******* 
[INFO] 2021-07-12 18:40:51,532 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:51,532 [run_pretraining.py:  534]:	loss/total_loss, 8.687385559082031, 559
[INFO] 2021-07-12 18:40:51,533 [run_pretraining.py:  535]:	loss/mlm_loss, 8.687385559082031, 559
[INFO] 2021-07-12 18:40:51,533 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.579999651672551e-06, 559
[INFO] 2021-07-12 18:40:51,533 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 559
[INFO] 2021-07-12 18:40:51,533 [run_pretraining.py:  558]:	worker_index: 2, step: 559, cost: 8.687386, mlm loss: 8.687386, speed: 0.950819 steps/s, speed: 7.606552 samples/s, speed: 3894.554515 tokens/s, learning rate: 5.580e-06, loss_scalings: 13421.773438, pp_loss: 8.068289
[INFO] 2021-07-12 18:40:51,533 [run_pretraining.py:  512]:	********exe.run_559******* 
[INFO] 2021-07-12 18:40:52,594 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:52,594 [run_pretraining.py:  534]:	loss/total_loss, 8.672289848327637, 560
[INFO] 2021-07-12 18:40:52,594 [run_pretraining.py:  535]:	loss/mlm_loss, 8.672289848327637, 560
[INFO] 2021-07-12 18:40:52,594 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.590000000665896e-06, 560
[INFO] 2021-07-12 18:40:52,594 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 560
[INFO] 2021-07-12 18:40:52,594 [run_pretraining.py:  558]:	worker_index: 2, step: 560, cost: 8.672290, mlm loss: 8.672290, speed: 0.942505 steps/s, speed: 7.540044 samples/s, speed: 3860.502486 tokens/s, learning rate: 5.590e-06, loss_scalings: 13421.773438, pp_loss: 8.741739
[INFO] 2021-07-12 18:40:52,594 [run_pretraining.py:  512]:	********exe.run_560******* 
[INFO] 2021-07-12 18:40:53,659 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:53,659 [run_pretraining.py:  534]:	loss/total_loss, 8.893580436706543, 561
[INFO] 2021-07-12 18:40:53,660 [run_pretraining.py:  535]:	loss/mlm_loss, 8.893580436706543, 561
[INFO] 2021-07-12 18:40:53,660 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.599999894911889e-06, 561
[INFO] 2021-07-12 18:40:53,660 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 561
[INFO] 2021-07-12 18:40:53,660 [run_pretraining.py:  558]:	worker_index: 2, step: 561, cost: 8.893580, mlm loss: 8.893580, speed: 0.939129 steps/s, speed: 7.513033 samples/s, speed: 3846.673125 tokens/s, learning rate: 5.600e-06, loss_scalings: 13421.773438, pp_loss: 8.653882
[INFO] 2021-07-12 18:40:53,660 [run_pretraining.py:  512]:	********exe.run_561******* 
[INFO] 2021-07-12 18:40:54,716 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:54,716 [run_pretraining.py:  534]:	loss/total_loss, 9.281694412231445, 562
[INFO] 2021-07-12 18:40:54,716 [run_pretraining.py:  535]:	loss/mlm_loss, 9.281694412231445, 562
[INFO] 2021-07-12 18:40:54,716 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.609999789157882e-06, 562
[INFO] 2021-07-12 18:40:54,717 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 562
[INFO] 2021-07-12 18:40:54,717 [run_pretraining.py:  558]:	worker_index: 2, step: 562, cost: 9.281694, mlm loss: 9.281694, speed: 0.946784 steps/s, speed: 7.574273 samples/s, speed: 3878.027912 tokens/s, learning rate: 5.610e-06, loss_scalings: 13421.773438, pp_loss: 9.011086
[INFO] 2021-07-12 18:40:54,717 [run_pretraining.py:  512]:	********exe.run_562******* 
[INFO] 2021-07-12 18:40:55,776 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:55,776 [run_pretraining.py:  534]:	loss/total_loss, 9.21084213256836, 563
[INFO] 2021-07-12 18:40:55,776 [run_pretraining.py:  535]:	loss/mlm_loss, 9.21084213256836, 563
[INFO] 2021-07-12 18:40:55,776 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.6200001381512266e-06, 563
[INFO] 2021-07-12 18:40:55,776 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 563
[INFO] 2021-07-12 18:40:55,776 [run_pretraining.py:  558]:	worker_index: 2, step: 563, cost: 9.210842, mlm loss: 9.210842, speed: 0.944100 steps/s, speed: 7.552803 samples/s, speed: 3867.035362 tokens/s, learning rate: 5.620e-06, loss_scalings: 13421.773438, pp_loss: 8.900081
[INFO] 2021-07-12 18:40:55,776 [run_pretraining.py:  512]:	********exe.run_563******* 
[INFO] 2021-07-12 18:40:56,823 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:56,823 [run_pretraining.py:  534]:	loss/total_loss, 8.764273643493652, 564
[INFO] 2021-07-12 18:40:56,823 [run_pretraining.py:  535]:	loss/mlm_loss, 8.764273643493652, 564
[INFO] 2021-07-12 18:40:56,823 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.629999577649869e-06, 564
[INFO] 2021-07-12 18:40:56,823 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 564
[INFO] 2021-07-12 18:40:56,824 [run_pretraining.py:  558]:	worker_index: 2, step: 564, cost: 8.764274, mlm loss: 8.764274, speed: 0.955551 steps/s, speed: 7.644409 samples/s, speed: 3913.937639 tokens/s, learning rate: 5.630e-06, loss_scalings: 13421.773438, pp_loss: 8.893147
[INFO] 2021-07-12 18:40:56,824 [run_pretraining.py:  512]:	********exe.run_564******* 
[INFO] 2021-07-12 18:40:57,879 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:57,879 [run_pretraining.py:  534]:	loss/total_loss, 8.63166332244873, 565
[INFO] 2021-07-12 18:40:57,879 [run_pretraining.py:  535]:	loss/mlm_loss, 8.63166332244873, 565
[INFO] 2021-07-12 18:40:57,880 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.639999926643213e-06, 565
[INFO] 2021-07-12 18:40:57,880 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 565
[INFO] 2021-07-12 18:40:57,880 [run_pretraining.py:  558]:	worker_index: 2, step: 565, cost: 8.631663, mlm loss: 8.631663, speed: 0.947430 steps/s, speed: 7.579444 samples/s, speed: 3880.675149 tokens/s, learning rate: 5.640e-06, loss_scalings: 13421.773438, pp_loss: 7.889708
[INFO] 2021-07-12 18:40:57,880 [run_pretraining.py:  512]:	********exe.run_565******* 
[INFO] 2021-07-12 18:40:58,934 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:58,934 [run_pretraining.py:  534]:	loss/total_loss, 5.841017246246338, 566
[INFO] 2021-07-12 18:40:58,934 [run_pretraining.py:  535]:	loss/mlm_loss, 5.841017246246338, 566
[INFO] 2021-07-12 18:40:58,935 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.649999820889207e-06, 566
[INFO] 2021-07-12 18:40:58,935 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 566
[INFO] 2021-07-12 18:40:58,935 [run_pretraining.py:  558]:	worker_index: 2, step: 566, cost: 5.841017, mlm loss: 5.841017, speed: 0.948396 steps/s, speed: 7.587164 samples/s, speed: 3884.628193 tokens/s, learning rate: 5.650e-06, loss_scalings: 13421.773438, pp_loss: 8.068922
[INFO] 2021-07-12 18:40:58,935 [run_pretraining.py:  512]:	********exe.run_566******* 
[INFO] 2021-07-12 18:40:59,999 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:59,999 [run_pretraining.py:  534]:	loss/total_loss, 8.800113677978516, 567
[INFO] 2021-07-12 18:41:00,000 [run_pretraining.py:  535]:	loss/mlm_loss, 8.800113677978516, 567
[INFO] 2021-07-12 18:41:00,000 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.6599997151352e-06, 567
[INFO] 2021-07-12 18:41:00,000 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 567
[INFO] 2021-07-12 18:41:00,000 [run_pretraining.py:  558]:	worker_index: 2, step: 567, cost: 8.800114, mlm loss: 8.800114, speed: 0.939425 steps/s, speed: 7.515403 samples/s, speed: 3847.886207 tokens/s, learning rate: 5.660e-06, loss_scalings: 13421.773438, pp_loss: 8.938861
[INFO] 2021-07-12 18:41:00,000 [run_pretraining.py:  512]:	********exe.run_567******* 
[INFO] 2021-07-12 18:41:01,045 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:01,045 [run_pretraining.py:  534]:	loss/total_loss, 8.850388526916504, 568
[INFO] 2021-07-12 18:41:01,045 [run_pretraining.py:  535]:	loss/mlm_loss, 8.850388526916504, 568
[INFO] 2021-07-12 18:41:01,045 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.669999609381193e-06, 568
[INFO] 2021-07-12 18:41:01,045 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 568
[INFO] 2021-07-12 18:41:01,046 [run_pretraining.py:  558]:	worker_index: 2, step: 568, cost: 8.850389, mlm loss: 8.850389, speed: 0.956779 steps/s, speed: 7.654234 samples/s, speed: 3918.967808 tokens/s, learning rate: 5.670e-06, loss_scalings: 13421.773438, pp_loss: 8.676327
[INFO] 2021-07-12 18:41:01,046 [run_pretraining.py:  512]:	********exe.run_568******* 
[INFO] 2021-07-12 18:41:01,959 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:01,960 [run_pretraining.py:  534]:	loss/total_loss, 8.832056999206543, 569
[INFO] 2021-07-12 18:41:01,960 [run_pretraining.py:  535]:	loss/mlm_loss, 8.832056999206543, 569
[INFO] 2021-07-12 18:41:01,960 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.6799999583745375e-06, 569
[INFO] 2021-07-12 18:41:01,960 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 569
[INFO] 2021-07-12 18:41:01,960 [run_pretraining.py:  558]:	worker_index: 2, step: 569, cost: 8.832057, mlm loss: 8.832057, speed: 1.093870 steps/s, speed: 8.750959 samples/s, speed: 4480.490986 tokens/s, learning rate: 5.680e-06, loss_scalings: 13421.773438, pp_loss: 8.988738
[INFO] 2021-07-12 18:41:01,960 [run_pretraining.py:  512]:	********exe.run_569******* 
[INFO] 2021-07-12 18:41:02,877 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:02,877 [run_pretraining.py:  534]:	loss/total_loss, 8.662149429321289, 570
[INFO] 2021-07-12 18:41:02,877 [run_pretraining.py:  535]:	loss/mlm_loss, 8.662149429321289, 570
[INFO] 2021-07-12 18:41:02,878 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.689999852620531e-06, 570
[INFO] 2021-07-12 18:41:02,878 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 570
[INFO] 2021-07-12 18:41:02,878 [run_pretraining.py:  558]:	worker_index: 2, step: 570, cost: 8.662149, mlm loss: 8.662149, speed: 1.090782 steps/s, speed: 8.726260 samples/s, speed: 4467.844972 tokens/s, learning rate: 5.690e-06, loss_scalings: 13421.773438, pp_loss: 8.780077
[INFO] 2021-07-12 18:41:02,878 [run_pretraining.py:  512]:	********exe.run_570******* 
[INFO] 2021-07-12 18:41:03,797 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:03,797 [run_pretraining.py:  534]:	loss/total_loss, 8.716084480285645, 571
[INFO] 2021-07-12 18:41:03,798 [run_pretraining.py:  535]:	loss/mlm_loss, 8.716084480285645, 571
[INFO] 2021-07-12 18:41:03,798 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.699999746866524e-06, 571
[INFO] 2021-07-12 18:41:03,798 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 571
[INFO] 2021-07-12 18:41:03,798 [run_pretraining.py:  558]:	worker_index: 2, step: 571, cost: 8.716084, mlm loss: 8.716084, speed: 1.087489 steps/s, speed: 8.699910 samples/s, speed: 4454.354108 tokens/s, learning rate: 5.700e-06, loss_scalings: 13421.773438, pp_loss: 8.912090
[INFO] 2021-07-12 18:41:03,798 [run_pretraining.py:  512]:	********exe.run_571******* 
[INFO] 2021-07-12 18:41:04,815 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:04,816 [run_pretraining.py:  534]:	loss/total_loss, 8.852208137512207, 572
[INFO] 2021-07-12 18:41:04,816 [run_pretraining.py:  535]:	loss/mlm_loss, 8.852208137512207, 572
[INFO] 2021-07-12 18:41:04,816 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.7100000958598685e-06, 572
[INFO] 2021-07-12 18:41:04,816 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 572
[INFO] 2021-07-12 18:41:04,816 [run_pretraining.py:  558]:	worker_index: 2, step: 572, cost: 8.852208, mlm loss: 8.852208, speed: 0.982667 steps/s, speed: 7.861338 samples/s, speed: 4025.005168 tokens/s, learning rate: 5.710e-06, loss_scalings: 13421.773438, pp_loss: 9.049215
[INFO] 2021-07-12 18:41:04,816 [run_pretraining.py:  512]:	********exe.run_572******* 
[INFO] 2021-07-12 18:41:05,874 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:05,875 [run_pretraining.py:  534]:	loss/total_loss, 8.732178688049316, 573
[INFO] 2021-07-12 18:41:05,875 [run_pretraining.py:  535]:	loss/mlm_loss, 8.732178688049316, 573
[INFO] 2021-07-12 18:41:05,875 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.719999990105862e-06, 573
[INFO] 2021-07-12 18:41:05,875 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 573
[INFO] 2021-07-12 18:41:05,875 [run_pretraining.py:  558]:	worker_index: 2, step: 573, cost: 8.732179, mlm loss: 8.732179, speed: 0.944616 steps/s, speed: 7.556932 samples/s, speed: 3869.149063 tokens/s, learning rate: 5.720e-06, loss_scalings: 13421.773438, pp_loss: 8.704947
[INFO] 2021-07-12 18:41:05,875 [run_pretraining.py:  512]:	********exe.run_573******* 
[INFO] 2021-07-12 18:41:06,928 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:06,929 [run_pretraining.py:  534]:	loss/total_loss, 8.92851734161377, 574
[INFO] 2021-07-12 18:41:06,929 [run_pretraining.py:  535]:	loss/mlm_loss, 8.92851734161377, 574
[INFO] 2021-07-12 18:41:06,929 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.729999884351855e-06, 574
[INFO] 2021-07-12 18:41:06,929 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 574
[INFO] 2021-07-12 18:41:06,929 [run_pretraining.py:  558]:	worker_index: 2, step: 574, cost: 8.928517, mlm loss: 8.928517, speed: 0.949661 steps/s, speed: 7.597291 samples/s, speed: 3889.813114 tokens/s, learning rate: 5.730e-06, loss_scalings: 13421.773438, pp_loss: 8.889379
[INFO] 2021-07-12 18:41:06,929 [run_pretraining.py:  512]:	********exe.run_574******* 
[INFO] 2021-07-12 18:41:07,912 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:07,913 [run_pretraining.py:  534]:	loss/total_loss, 6.827065944671631, 575
[INFO] 2021-07-12 18:41:07,913 [run_pretraining.py:  535]:	loss/mlm_loss, 6.827065944671631, 575
[INFO] 2021-07-12 18:41:07,913 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.7399997785978485e-06, 575
[INFO] 2021-07-12 18:41:07,913 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 575
[INFO] 2021-07-12 18:41:07,913 [run_pretraining.py:  558]:	worker_index: 2, step: 575, cost: 6.827066, mlm loss: 6.827066, speed: 1.016784 steps/s, speed: 8.134272 samples/s, speed: 4164.747107 tokens/s, learning rate: 5.740e-06, loss_scalings: 13421.773438, pp_loss: 8.288953
[INFO] 2021-07-12 18:41:07,913 [run_pretraining.py:  512]:	********exe.run_575******* 
[INFO] 2021-07-12 18:41:08,822 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:08,822 [run_pretraining.py:  534]:	loss/total_loss, 8.936118125915527, 576
[INFO] 2021-07-12 18:41:08,822 [run_pretraining.py:  535]:	loss/mlm_loss, 8.936118125915527, 576
[INFO] 2021-07-12 18:41:08,822 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.750000127591193e-06, 576
[INFO] 2021-07-12 18:41:08,823 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 576
[INFO] 2021-07-12 18:41:08,823 [run_pretraining.py:  558]:	worker_index: 2, step: 576, cost: 8.936118, mlm loss: 8.936118, speed: 1.100058 steps/s, speed: 8.800461 samples/s, speed: 4505.835911 tokens/s, learning rate: 5.750e-06, loss_scalings: 13421.773438, pp_loss: 8.803675
[INFO] 2021-07-12 18:41:08,823 [run_pretraining.py:  512]:	********exe.run_576******* 
[INFO] 2021-07-12 18:41:09,734 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:09,734 [run_pretraining.py:  534]:	loss/total_loss, 8.821136474609375, 577
[INFO] 2021-07-12 18:41:09,734 [run_pretraining.py:  535]:	loss/mlm_loss, 8.821136474609375, 577
[INFO] 2021-07-12 18:41:09,734 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.759999567089835e-06, 577
[INFO] 2021-07-12 18:41:09,734 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 577
[INFO] 2021-07-12 18:41:09,734 [run_pretraining.py:  558]:	worker_index: 2, step: 577, cost: 8.821136, mlm loss: 8.821136, speed: 1.097466 steps/s, speed: 8.779732 samples/s, speed: 4495.222726 tokens/s, learning rate: 5.760e-06, loss_scalings: 13421.773438, pp_loss: 8.668562
[INFO] 2021-07-12 18:41:09,734 [run_pretraining.py:  512]:	********exe.run_577******* 
[INFO] 2021-07-12 18:41:10,666 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:10,666 [run_pretraining.py:  534]:	loss/total_loss, 8.40818977355957, 578
[INFO] 2021-07-12 18:41:10,666 [run_pretraining.py:  535]:	loss/mlm_loss, 8.40818977355957, 578
[INFO] 2021-07-12 18:41:10,666 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.769999916083179e-06, 578
[INFO] 2021-07-12 18:41:10,666 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 578
[INFO] 2021-07-12 18:41:10,666 [run_pretraining.py:  558]:	worker_index: 2, step: 578, cost: 8.408190, mlm loss: 8.408190, speed: 1.073518 steps/s, speed: 8.588147 samples/s, speed: 4397.131345 tokens/s, learning rate: 5.770e-06, loss_scalings: 13421.773438, pp_loss: 8.758625
[INFO] 2021-07-12 18:41:10,667 [run_pretraining.py:  512]:	********exe.run_578******* 
[INFO] 2021-07-12 18:41:11,582 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:11,582 [run_pretraining.py:  534]:	loss/total_loss, 9.548216819763184, 579
[INFO] 2021-07-12 18:41:11,583 [run_pretraining.py:  535]:	loss/mlm_loss, 9.548216819763184, 579
[INFO] 2021-07-12 18:41:11,583 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.779999810329173e-06, 579
[INFO] 2021-07-12 18:41:11,583 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 579
[INFO] 2021-07-12 18:41:11,583 [run_pretraining.py:  558]:	worker_index: 2, step: 579, cost: 9.548217, mlm loss: 9.548217, speed: 1.091999 steps/s, speed: 8.735993 samples/s, speed: 4472.828191 tokens/s, learning rate: 5.780e-06, loss_scalings: 13421.773438, pp_loss: 8.529558
[INFO] 2021-07-12 18:41:11,583 [run_pretraining.py:  512]:	********exe.run_579******* 
[INFO] 2021-07-12 18:41:12,501 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:12,501 [run_pretraining.py:  534]:	loss/total_loss, 9.017348289489746, 580
[INFO] 2021-07-12 18:41:12,501 [run_pretraining.py:  535]:	loss/mlm_loss, 9.017348289489746, 580
[INFO] 2021-07-12 18:41:12,501 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.789999704575166e-06, 580
[INFO] 2021-07-12 18:41:12,501 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 580
[INFO] 2021-07-12 18:41:12,502 [run_pretraining.py:  558]:	worker_index: 2, step: 580, cost: 9.017348, mlm loss: 9.017348, speed: 1.089201 steps/s, speed: 8.713608 samples/s, speed: 4461.367376 tokens/s, learning rate: 5.790e-06, loss_scalings: 13421.773438, pp_loss: 8.811579
[INFO] 2021-07-12 18:41:12,502 [run_pretraining.py:  512]:	********exe.run_580******* 
[INFO] 2021-07-12 18:41:13,419 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:13,419 [run_pretraining.py:  534]:	loss/total_loss, 8.723262786865234, 581
[INFO] 2021-07-12 18:41:13,419 [run_pretraining.py:  535]:	loss/mlm_loss, 8.723262786865234, 581
[INFO] 2021-07-12 18:41:13,419 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.7999995988211595e-06, 581
[INFO] 2021-07-12 18:41:13,419 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 581
[INFO] 2021-07-12 18:41:13,420 [run_pretraining.py:  558]:	worker_index: 2, step: 581, cost: 8.723263, mlm loss: 8.723263, speed: 1.090028 steps/s, speed: 8.720221 samples/s, speed: 4464.752920 tokens/s, learning rate: 5.800e-06, loss_scalings: 13421.773438, pp_loss: 8.691194
[INFO] 2021-07-12 18:41:13,420 [run_pretraining.py:  512]:	********exe.run_581******* 
[INFO] 2021-07-12 18:41:14,334 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:14,334 [run_pretraining.py:  534]:	loss/total_loss, 8.458563804626465, 582
[INFO] 2021-07-12 18:41:14,334 [run_pretraining.py:  535]:	loss/mlm_loss, 8.458563804626465, 582
[INFO] 2021-07-12 18:41:14,334 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.809999947814504e-06, 582
[INFO] 2021-07-12 18:41:14,335 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 582
[INFO] 2021-07-12 18:41:14,335 [run_pretraining.py:  558]:	worker_index: 2, step: 582, cost: 8.458564, mlm loss: 8.458564, speed: 1.093542 steps/s, speed: 8.748337 samples/s, speed: 4479.148774 tokens/s, learning rate: 5.810e-06, loss_scalings: 13421.773438, pp_loss: 8.574512
[INFO] 2021-07-12 18:41:14,335 [run_pretraining.py:  512]:	********exe.run_582******* 
[INFO] 2021-07-12 18:41:15,254 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:15,254 [run_pretraining.py:  534]:	loss/total_loss, 8.509632110595703, 583
[INFO] 2021-07-12 18:41:15,254 [run_pretraining.py:  535]:	loss/mlm_loss, 8.509632110595703, 583
[INFO] 2021-07-12 18:41:15,254 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.819999842060497e-06, 583
[INFO] 2021-07-12 18:41:15,254 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 583
[INFO] 2021-07-12 18:41:15,254 [run_pretraining.py:  558]:	worker_index: 2, step: 583, cost: 8.509632, mlm loss: 8.509632, speed: 1.087791 steps/s, speed: 8.702329 samples/s, speed: 4455.592520 tokens/s, learning rate: 5.820e-06, loss_scalings: 13421.773438, pp_loss: 8.516635
[INFO] 2021-07-12 18:41:15,255 [run_pretraining.py:  512]:	********exe.run_583******* 
[INFO] 2021-07-12 18:41:16,167 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:16,168 [run_pretraining.py:  534]:	loss/total_loss, 8.561237335205078, 584
[INFO] 2021-07-12 18:41:16,168 [run_pretraining.py:  535]:	loss/mlm_loss, 8.561237335205078, 584
[INFO] 2021-07-12 18:41:16,168 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.82999973630649e-06, 584
[INFO] 2021-07-12 18:41:16,168 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 584
[INFO] 2021-07-12 18:41:16,168 [run_pretraining.py:  558]:	worker_index: 2, step: 584, cost: 8.561237, mlm loss: 8.561237, speed: 1.095300 steps/s, speed: 8.762397 samples/s, speed: 4486.347008 tokens/s, learning rate: 5.830e-06, loss_scalings: 13421.773438, pp_loss: 8.389364
[INFO] 2021-07-12 18:41:16,168 [run_pretraining.py:  512]:	********exe.run_584******* 
[INFO] 2021-07-12 18:41:17,081 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:17,081 [run_pretraining.py:  534]:	loss/total_loss, 5.3050689697265625, 585
[INFO] 2021-07-12 18:41:17,082 [run_pretraining.py:  535]:	loss/mlm_loss, 5.3050689697265625, 585
[INFO] 2021-07-12 18:41:17,082 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.840000085299835e-06, 585
[INFO] 2021-07-12 18:41:17,082 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 585
[INFO] 2021-07-12 18:41:17,082 [run_pretraining.py:  558]:	worker_index: 2, step: 585, cost: 5.305069, mlm loss: 5.305069, speed: 1.095205 steps/s, speed: 8.761637 samples/s, speed: 4485.958083 tokens/s, learning rate: 5.840e-06, loss_scalings: 13421.773438, pp_loss: 7.930862
[INFO] 2021-07-12 18:41:17,082 [run_pretraining.py:  512]:	********exe.run_585******* 
[INFO] 2021-07-12 18:41:17,995 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:17,995 [run_pretraining.py:  534]:	loss/total_loss, 9.022734642028809, 586
[INFO] 2021-07-12 18:41:17,996 [run_pretraining.py:  535]:	loss/mlm_loss, 9.022734642028809, 586
[INFO] 2021-07-12 18:41:17,996 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.849999979545828e-06, 586
[INFO] 2021-07-12 18:41:17,996 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 586
[INFO] 2021-07-12 18:41:17,996 [run_pretraining.py:  558]:	worker_index: 2, step: 586, cost: 9.022735, mlm loss: 9.022735, speed: 1.094816 steps/s, speed: 8.758529 samples/s, speed: 4484.366769 tokens/s, learning rate: 5.850e-06, loss_scalings: 13421.773438, pp_loss: 8.704404
[INFO] 2021-07-12 18:41:17,996 [run_pretraining.py:  512]:	********exe.run_586******* 
[INFO] 2021-07-12 18:41:18,900 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:18,900 [run_pretraining.py:  534]:	loss/total_loss, 8.863553047180176, 587
[INFO] 2021-07-12 18:41:18,900 [run_pretraining.py:  535]:	loss/mlm_loss, 8.863553047180176, 587
[INFO] 2021-07-12 18:41:18,901 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.859999873791821e-06, 587
[INFO] 2021-07-12 18:41:18,901 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 587
[INFO] 2021-07-12 18:41:18,901 [run_pretraining.py:  558]:	worker_index: 2, step: 587, cost: 8.863553, mlm loss: 8.863553, speed: 1.105790 steps/s, speed: 8.846316 samples/s, speed: 4529.314002 tokens/s, learning rate: 5.860e-06, loss_scalings: 13421.773438, pp_loss: 8.833390
[INFO] 2021-07-12 18:41:18,901 [run_pretraining.py:  512]:	********exe.run_587******* 
[INFO] 2021-07-12 18:41:19,802 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:19,802 [run_pretraining.py:  534]:	loss/total_loss, 6.309574604034424, 588
[INFO] 2021-07-12 18:41:19,802 [run_pretraining.py:  535]:	loss/mlm_loss, 6.309574604034424, 588
[INFO] 2021-07-12 18:41:19,803 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.869999768037815e-06, 588
[INFO] 2021-07-12 18:41:19,803 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 588
[INFO] 2021-07-12 18:41:19,803 [run_pretraining.py:  558]:	worker_index: 2, step: 588, cost: 6.309575, mlm loss: 6.309575, speed: 1.109402 steps/s, speed: 8.875214 samples/s, speed: 4544.109457 tokens/s, learning rate: 5.870e-06, loss_scalings: 13421.773438, pp_loss: 8.306354
[INFO] 2021-07-12 18:41:19,803 [run_pretraining.py:  512]:	********exe.run_588******* 
[INFO] 2021-07-12 18:41:20,710 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:20,711 [run_pretraining.py:  534]:	loss/total_loss, 8.734371185302734, 589
[INFO] 2021-07-12 18:41:20,711 [run_pretraining.py:  535]:	loss/mlm_loss, 8.734371185302734, 589
[INFO] 2021-07-12 18:41:20,711 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.880000117031159e-06, 589
[INFO] 2021-07-12 18:41:20,711 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 589
[INFO] 2021-07-12 18:41:20,711 [run_pretraining.py:  558]:	worker_index: 2, step: 589, cost: 8.734371, mlm loss: 8.734371, speed: 1.101399 steps/s, speed: 8.811188 samples/s, speed: 4511.328348 tokens/s, learning rate: 5.880e-06, loss_scalings: 13421.773438, pp_loss: 8.743537
[INFO] 2021-07-12 18:41:20,711 [run_pretraining.py:  512]:	********exe.run_589******* 
[INFO] 2021-07-12 18:41:21,674 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:21,674 [run_pretraining.py:  534]:	loss/total_loss, 8.876447677612305, 590
[INFO] 2021-07-12 18:41:21,674 [run_pretraining.py:  535]:	loss/mlm_loss, 8.876447677612305, 590
[INFO] 2021-07-12 18:41:21,674 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.889999556529801e-06, 590
[INFO] 2021-07-12 18:41:21,675 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 590
[INFO] 2021-07-12 18:41:21,675 [run_pretraining.py:  558]:	worker_index: 2, step: 590, cost: 8.876448, mlm loss: 8.876448, speed: 1.038636 steps/s, speed: 8.309086 samples/s, speed: 4254.251977 tokens/s, learning rate: 5.890e-06, loss_scalings: 13421.773438, pp_loss: 8.130388
[INFO] 2021-07-12 18:41:21,675 [run_pretraining.py:  512]:	********exe.run_590******* 
[INFO] 2021-07-12 18:41:22,578 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:22,578 [run_pretraining.py:  534]:	loss/total_loss, 8.627103805541992, 591
[INFO] 2021-07-12 18:41:22,578 [run_pretraining.py:  535]:	loss/mlm_loss, 8.627103805541992, 591
[INFO] 2021-07-12 18:41:22,578 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.8999999055231456e-06, 591
[INFO] 2021-07-12 18:41:22,579 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 591
[INFO] 2021-07-12 18:41:22,579 [run_pretraining.py:  558]:	worker_index: 2, step: 591, cost: 8.627104, mlm loss: 8.627104, speed: 1.106931 steps/s, speed: 8.855452 samples/s, speed: 4533.991387 tokens/s, learning rate: 5.900e-06, loss_scalings: 13421.773438, pp_loss: 8.984060
[INFO] 2021-07-12 18:41:22,579 [run_pretraining.py:  512]:	********exe.run_591******* 
[INFO] 2021-07-12 18:41:23,487 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:23,488 [run_pretraining.py:  534]:	loss/total_loss, 8.919927597045898, 592
[INFO] 2021-07-12 18:41:23,488 [run_pretraining.py:  535]:	loss/mlm_loss, 8.919927597045898, 592
[INFO] 2021-07-12 18:41:23,488 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.909999799769139e-06, 592
[INFO] 2021-07-12 18:41:23,488 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 592
[INFO] 2021-07-12 18:41:23,488 [run_pretraining.py:  558]:	worker_index: 2, step: 592, cost: 8.919928, mlm loss: 8.919928, speed: 1.100503 steps/s, speed: 8.804026 samples/s, speed: 4507.661294 tokens/s, learning rate: 5.910e-06, loss_scalings: 13421.773438, pp_loss: 9.113023
[INFO] 2021-07-12 18:41:23,488 [run_pretraining.py:  512]:	********exe.run_592******* 
[INFO] 2021-07-12 18:41:24,404 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:24,405 [run_pretraining.py:  534]:	loss/total_loss, 9.165494918823242, 593
[INFO] 2021-07-12 18:41:24,405 [run_pretraining.py:  535]:	loss/mlm_loss, 9.165494918823242, 593
[INFO] 2021-07-12 18:41:24,405 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.919999694015132e-06, 593
[INFO] 2021-07-12 18:41:24,405 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 593
[INFO] 2021-07-12 18:41:24,405 [run_pretraining.py:  558]:	worker_index: 2, step: 593, cost: 9.165495, mlm loss: 9.165495, speed: 1.091177 steps/s, speed: 8.729413 samples/s, speed: 4469.459463 tokens/s, learning rate: 5.920e-06, loss_scalings: 13421.773438, pp_loss: 8.997013
[INFO] 2021-07-12 18:41:24,405 [run_pretraining.py:  512]:	********exe.run_593******* 
[INFO] 2021-07-12 18:41:25,364 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:25,364 [run_pretraining.py:  534]:	loss/total_loss, 8.954920768737793, 594
[INFO] 2021-07-12 18:41:25,364 [run_pretraining.py:  535]:	loss/mlm_loss, 8.954920768737793, 594
[INFO] 2021-07-12 18:41:25,364 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.9300000430084765e-06, 594
[INFO] 2021-07-12 18:41:25,364 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 594
[INFO] 2021-07-12 18:41:25,365 [run_pretraining.py:  558]:	worker_index: 2, step: 594, cost: 8.954921, mlm loss: 8.954921, speed: 1.042755 steps/s, speed: 8.342043 samples/s, speed: 4271.125871 tokens/s, learning rate: 5.930e-06, loss_scalings: 13421.773438, pp_loss: 8.871871
[INFO] 2021-07-12 18:41:25,365 [run_pretraining.py:  512]:	********exe.run_594******* 
[INFO] 2021-07-12 18:41:26,292 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:26,292 [run_pretraining.py:  534]:	loss/total_loss, 8.743919372558594, 595
[INFO] 2021-07-12 18:41:26,292 [run_pretraining.py:  535]:	loss/mlm_loss, 8.743919372558594, 595
[INFO] 2021-07-12 18:41:26,292 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.93999993725447e-06, 595
[INFO] 2021-07-12 18:41:26,292 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 595
[INFO] 2021-07-12 18:41:26,292 [run_pretraining.py:  558]:	worker_index: 2, step: 595, cost: 8.743919, mlm loss: 8.743919, speed: 1.078420 steps/s, speed: 8.627364 samples/s, speed: 4417.210278 tokens/s, learning rate: 5.940e-06, loss_scalings: 13421.773438, pp_loss: 8.965361
[INFO] 2021-07-12 18:41:26,292 [run_pretraining.py:  512]:	********exe.run_595******* 
[INFO] 2021-07-12 18:41:27,231 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:27,232 [run_pretraining.py:  534]:	loss/total_loss, 8.668916702270508, 596
[INFO] 2021-07-12 18:41:27,232 [run_pretraining.py:  535]:	loss/mlm_loss, 8.668916702270508, 596
[INFO] 2021-07-12 18:41:27,232 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.949999831500463e-06, 596
[INFO] 2021-07-12 18:41:27,232 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 596
[INFO] 2021-07-12 18:41:27,232 [run_pretraining.py:  558]:	worker_index: 2, step: 596, cost: 8.668917, mlm loss: 8.668917, speed: 1.065028 steps/s, speed: 8.520222 samples/s, speed: 4362.353664 tokens/s, learning rate: 5.950e-06, loss_scalings: 13421.773438, pp_loss: 8.646174
[INFO] 2021-07-12 18:41:27,232 [run_pretraining.py:  512]:	********exe.run_596******* 
[INFO] 2021-07-12 18:41:28,140 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:28,141 [run_pretraining.py:  534]:	loss/total_loss, 8.368831634521484, 597
[INFO] 2021-07-12 18:41:28,141 [run_pretraining.py:  535]:	loss/mlm_loss, 8.368831634521484, 597
[INFO] 2021-07-12 18:41:28,141 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.9599997257464565e-06, 597
[INFO] 2021-07-12 18:41:28,141 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 597
[INFO] 2021-07-12 18:41:28,141 [run_pretraining.py:  558]:	worker_index: 2, step: 597, cost: 8.368832, mlm loss: 8.368832, speed: 1.100384 steps/s, speed: 8.803074 samples/s, speed: 4507.174065 tokens/s, learning rate: 5.960e-06, loss_scalings: 13421.773438, pp_loss: 8.198442
[INFO] 2021-07-12 18:41:28,141 [run_pretraining.py:  512]:	********exe.run_597******* 
[INFO] 2021-07-12 18:41:29,051 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:29,052 [run_pretraining.py:  534]:	loss/total_loss, 8.669708251953125, 598
[INFO] 2021-07-12 18:41:29,052 [run_pretraining.py:  535]:	loss/mlm_loss, 8.669708251953125, 598
[INFO] 2021-07-12 18:41:29,052 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.970000074739801e-06, 598
[INFO] 2021-07-12 18:41:29,052 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 598
[INFO] 2021-07-12 18:41:29,052 [run_pretraining.py:  558]:	worker_index: 2, step: 598, cost: 8.669708, mlm loss: 8.669708, speed: 1.098395 steps/s, speed: 8.787163 samples/s, speed: 4499.027434 tokens/s, learning rate: 5.970e-06, loss_scalings: 13421.773438, pp_loss: 8.643952
[INFO] 2021-07-12 18:41:29,052 [run_pretraining.py:  512]:	********exe.run_598******* 
[INFO] 2021-07-12 18:41:29,968 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:29,968 [run_pretraining.py:  534]:	loss/total_loss, 8.59683609008789, 599
[INFO] 2021-07-12 18:41:29,968 [run_pretraining.py:  535]:	loss/mlm_loss, 8.59683609008789, 599
[INFO] 2021-07-12 18:41:29,969 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.979999968985794e-06, 599
[INFO] 2021-07-12 18:41:29,969 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 599
[INFO] 2021-07-12 18:41:29,969 [run_pretraining.py:  558]:	worker_index: 2, step: 599, cost: 8.596836, mlm loss: 8.596836, speed: 1.092037 steps/s, speed: 8.736295 samples/s, speed: 4472.983076 tokens/s, learning rate: 5.980e-06, loss_scalings: 13421.773438, pp_loss: 8.777397
[INFO] 2021-07-12 18:41:29,969 [run_pretraining.py:  512]:	********exe.run_599******* 
[INFO] 2021-07-12 18:41:30,887 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:30,887 [run_pretraining.py:  534]:	loss/total_loss, 8.73710823059082, 600
[INFO] 2021-07-12 18:41:30,887 [run_pretraining.py:  535]:	loss/mlm_loss, 8.73710823059082, 600
[INFO] 2021-07-12 18:41:30,888 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.9899998632317875e-06, 600
[INFO] 2021-07-12 18:41:30,888 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 600
[INFO] 2021-07-12 18:41:30,888 [run_pretraining.py:  558]:	worker_index: 2, step: 600, cost: 8.737108, mlm loss: 8.737108, speed: 1.088819 steps/s, speed: 8.710554 samples/s, speed: 4459.803877 tokens/s, learning rate: 5.990e-06, loss_scalings: 13421.773438, pp_loss: 8.818579
[INFO] 2021-07-12 18:41:30,888 [run_pretraining.py:  512]:	********exe.run_600******* 
[INFO] 2021-07-12 18:41:31,800 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:31,801 [run_pretraining.py:  534]:	loss/total_loss, 8.553457260131836, 601
[INFO] 2021-07-12 18:41:31,801 [run_pretraining.py:  535]:	loss/mlm_loss, 8.553457260131836, 601
[INFO] 2021-07-12 18:41:31,801 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.999999757477781e-06, 601
[INFO] 2021-07-12 18:41:31,801 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 601
[INFO] 2021-07-12 18:41:31,801 [run_pretraining.py:  558]:	worker_index: 2, step: 601, cost: 8.553457, mlm loss: 8.553457, speed: 1.095687 steps/s, speed: 8.765494 samples/s, speed: 4487.932694 tokens/s, learning rate: 6.000e-06, loss_scalings: 13421.773438, pp_loss: 8.508833
[INFO] 2021-07-12 18:41:31,801 [run_pretraining.py:  512]:	********exe.run_601******* 
[INFO] 2021-07-12 18:41:32,714 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:32,714 [run_pretraining.py:  534]:	loss/total_loss, 8.760313987731934, 602
[INFO] 2021-07-12 18:41:32,714 [run_pretraining.py:  535]:	loss/mlm_loss, 8.760313987731934, 602
[INFO] 2021-07-12 18:41:32,714 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.010000106471125e-06, 602
[INFO] 2021-07-12 18:41:32,714 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 602
[INFO] 2021-07-12 18:41:32,714 [run_pretraining.py:  558]:	worker_index: 2, step: 602, cost: 8.760314, mlm loss: 8.760314, speed: 1.095467 steps/s, speed: 8.763738 samples/s, speed: 4487.033650 tokens/s, learning rate: 6.010e-06, loss_scalings: 13421.773438, pp_loss: 9.014646
[INFO] 2021-07-12 18:41:32,714 [run_pretraining.py:  512]:	********exe.run_602******* 
[INFO] 2021-07-12 18:41:33,627 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:33,628 [run_pretraining.py:  534]:	loss/total_loss, 8.539926528930664, 603
[INFO] 2021-07-12 18:41:33,628 [run_pretraining.py:  535]:	loss/mlm_loss, 8.539926528930664, 603
[INFO] 2021-07-12 18:41:33,628 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.0199995459697675e-06, 603
[INFO] 2021-07-12 18:41:33,628 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 603
[INFO] 2021-07-12 18:41:33,628 [run_pretraining.py:  558]:	worker_index: 2, step: 603, cost: 8.539927, mlm loss: 8.539927, speed: 1.095154 steps/s, speed: 8.761232 samples/s, speed: 4485.750762 tokens/s, learning rate: 6.020e-06, loss_scalings: 13421.773438, pp_loss: 8.768694
[INFO] 2021-07-12 18:41:33,628 [run_pretraining.py:  512]:	********exe.run_603******* 
[INFO] 2021-07-12 18:41:34,544 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:34,545 [run_pretraining.py:  534]:	loss/total_loss, 8.578778266906738, 604
[INFO] 2021-07-12 18:41:34,545 [run_pretraining.py:  535]:	loss/mlm_loss, 8.578778266906738, 604
[INFO] 2021-07-12 18:41:34,545 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.029999894963112e-06, 604
[INFO] 2021-07-12 18:41:34,545 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 604
[INFO] 2021-07-12 18:41:34,545 [run_pretraining.py:  558]:	worker_index: 2, step: 604, cost: 8.578778, mlm loss: 8.578778, speed: 1.091171 steps/s, speed: 8.729368 samples/s, speed: 4469.436208 tokens/s, learning rate: 6.030e-06, loss_scalings: 13421.773438, pp_loss: 8.493067
[INFO] 2021-07-12 18:41:34,545 [run_pretraining.py:  512]:	********exe.run_604******* 
[INFO] 2021-07-12 18:41:35,462 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:35,462 [run_pretraining.py:  534]:	loss/total_loss, 9.110908508300781, 605
[INFO] 2021-07-12 18:41:35,462 [run_pretraining.py:  535]:	loss/mlm_loss, 9.110908508300781, 605
[INFO] 2021-07-12 18:41:35,463 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.040000243956456e-06, 605
[INFO] 2021-07-12 18:41:35,463 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 605
[INFO] 2021-07-12 18:41:35,463 [run_pretraining.py:  558]:	worker_index: 2, step: 605, cost: 9.110909, mlm loss: 9.110909, speed: 1.090570 steps/s, speed: 8.724560 samples/s, speed: 4466.974864 tokens/s, learning rate: 6.040e-06, loss_scalings: 13421.773438, pp_loss: 8.845985
[INFO] 2021-07-12 18:41:35,463 [run_pretraining.py:  512]:	********exe.run_605******* 
[INFO] 2021-07-12 18:41:36,370 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:36,370 [run_pretraining.py:  534]:	loss/total_loss, 5.657505035400391, 606
[INFO] 2021-07-12 18:41:36,371 [run_pretraining.py:  535]:	loss/mlm_loss, 5.657505035400391, 606
[INFO] 2021-07-12 18:41:36,371 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.049999683455098e-06, 606
[INFO] 2021-07-12 18:41:36,371 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 606
[INFO] 2021-07-12 18:41:36,371 [run_pretraining.py:  558]:	worker_index: 2, step: 606, cost: 5.657505, mlm loss: 5.657505, speed: 1.101815 steps/s, speed: 8.814521 samples/s, speed: 4513.034885 tokens/s, learning rate: 6.050e-06, loss_scalings: 13421.773438, pp_loss: 7.994677
[INFO] 2021-07-12 18:41:36,371 [run_pretraining.py:  512]:	********exe.run_606******* 
[INFO] 2021-07-12 18:41:37,282 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:37,282 [run_pretraining.py:  534]:	loss/total_loss, 8.081005096435547, 607
[INFO] 2021-07-12 18:41:37,283 [run_pretraining.py:  535]:	loss/mlm_loss, 8.081005096435547, 607
[INFO] 2021-07-12 18:41:37,283 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.060000032448443e-06, 607
[INFO] 2021-07-12 18:41:37,283 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 607
[INFO] 2021-07-12 18:41:37,283 [run_pretraining.py:  558]:	worker_index: 2, step: 607, cost: 8.081005, mlm loss: 8.081005, speed: 1.097298 steps/s, speed: 8.778386 samples/s, speed: 4494.533576 tokens/s, learning rate: 6.060e-06, loss_scalings: 13421.773438, pp_loss: 7.724044
[INFO] 2021-07-12 18:41:37,283 [run_pretraining.py:  512]:	********exe.run_607******* 
[INFO] 2021-07-12 18:41:38,200 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:38,200 [run_pretraining.py:  534]:	loss/total_loss, 9.050466537475586, 608
[INFO] 2021-07-12 18:41:38,200 [run_pretraining.py:  535]:	loss/mlm_loss, 9.050466537475586, 608
[INFO] 2021-07-12 18:41:38,200 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.069999926694436e-06, 608
[INFO] 2021-07-12 18:41:38,200 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 608
[INFO] 2021-07-12 18:41:38,201 [run_pretraining.py:  558]:	worker_index: 2, step: 608, cost: 9.050467, mlm loss: 9.050467, speed: 1.090331 steps/s, speed: 8.722648 samples/s, speed: 4465.995961 tokens/s, learning rate: 6.070e-06, loss_scalings: 13421.773438, pp_loss: 8.940651
[INFO] 2021-07-12 18:41:38,201 [run_pretraining.py:  512]:	********exe.run_608******* 
[INFO] 2021-07-12 18:41:39,117 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:39,117 [run_pretraining.py:  534]:	loss/total_loss, 9.052311897277832, 609
[INFO] 2021-07-12 18:41:39,117 [run_pretraining.py:  535]:	loss/mlm_loss, 9.052311897277832, 609
[INFO] 2021-07-12 18:41:39,117 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.079999820940429e-06, 609
[INFO] 2021-07-12 18:41:39,117 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 609
[INFO] 2021-07-12 18:41:39,118 [run_pretraining.py:  558]:	worker_index: 2, step: 609, cost: 9.052312, mlm loss: 9.052312, speed: 1.091224 steps/s, speed: 8.729790 samples/s, speed: 4469.652489 tokens/s, learning rate: 6.080e-06, loss_scalings: 13421.773438, pp_loss: 8.820968
[INFO] 2021-07-12 18:41:39,118 [run_pretraining.py:  512]:	********exe.run_609******* 
[INFO] 2021-07-12 18:41:40,042 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:40,042 [run_pretraining.py:  534]:	loss/total_loss, 9.088555335998535, 610
[INFO] 2021-07-12 18:41:40,042 [run_pretraining.py:  535]:	loss/mlm_loss, 9.088555335998535, 610
[INFO] 2021-07-12 18:41:40,042 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.089999715186423e-06, 610
[INFO] 2021-07-12 18:41:40,042 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 610
[INFO] 2021-07-12 18:41:40,042 [run_pretraining.py:  558]:	worker_index: 2, step: 610, cost: 9.088555, mlm loss: 9.088555, speed: 1.081998 steps/s, speed: 8.655985 samples/s, speed: 4431.864259 tokens/s, learning rate: 6.090e-06, loss_scalings: 13421.773438, pp_loss: 8.812640
[INFO] 2021-07-12 18:41:40,042 [run_pretraining.py:  512]:	********exe.run_610******* 
[INFO] 2021-07-12 18:41:40,954 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:40,954 [run_pretraining.py:  534]:	loss/total_loss, 7.841350555419922, 611
[INFO] 2021-07-12 18:41:40,954 [run_pretraining.py:  535]:	loss/mlm_loss, 7.841350555419922, 611
[INFO] 2021-07-12 18:41:40,955 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.100000064179767e-06, 611
[INFO] 2021-07-12 18:41:40,955 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 611
[INFO] 2021-07-12 18:41:40,955 [run_pretraining.py:  558]:	worker_index: 2, step: 611, cost: 7.841351, mlm loss: 7.841351, speed: 1.096741 steps/s, speed: 8.773928 samples/s, speed: 4492.251248 tokens/s, learning rate: 6.100e-06, loss_scalings: 13421.773438, pp_loss: 8.392864
[INFO] 2021-07-12 18:41:40,955 [run_pretraining.py:  512]:	********exe.run_611******* 
[INFO] 2021-07-12 18:41:41,875 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:41,876 [run_pretraining.py:  534]:	loss/total_loss, 8.625072479248047, 612
[INFO] 2021-07-12 18:41:41,876 [run_pretraining.py:  535]:	loss/mlm_loss, 8.625072479248047, 612
[INFO] 2021-07-12 18:41:41,876 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.109999503678409e-06, 612
[INFO] 2021-07-12 18:41:41,876 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 612
[INFO] 2021-07-12 18:41:41,876 [run_pretraining.py:  558]:	worker_index: 2, step: 612, cost: 8.625072, mlm loss: 8.625072, speed: 1.086182 steps/s, speed: 8.689457 samples/s, speed: 4449.001747 tokens/s, learning rate: 6.110e-06, loss_scalings: 13421.773438, pp_loss: 8.597202
[INFO] 2021-07-12 18:41:41,876 [run_pretraining.py:  512]:	********exe.run_612******* 
[INFO] 2021-07-12 18:41:42,788 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:42,788 [run_pretraining.py:  534]:	loss/total_loss, 8.139762878417969, 613
[INFO] 2021-07-12 18:41:42,788 [run_pretraining.py:  535]:	loss/mlm_loss, 8.139762878417969, 613
[INFO] 2021-07-12 18:41:42,788 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.119999852671754e-06, 613
[INFO] 2021-07-12 18:41:42,788 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 613
[INFO] 2021-07-12 18:41:42,788 [run_pretraining.py:  558]:	worker_index: 2, step: 613, cost: 8.139763, mlm loss: 8.139763, speed: 1.096763 steps/s, speed: 8.774105 samples/s, speed: 4492.341698 tokens/s, learning rate: 6.120e-06, loss_scalings: 13421.773438, pp_loss: 8.280128
[INFO] 2021-07-12 18:41:42,788 [run_pretraining.py:  512]:	********exe.run_613******* 
[INFO] 2021-07-12 18:41:43,705 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:43,705 [run_pretraining.py:  534]:	loss/total_loss, 9.004807472229004, 614
[INFO] 2021-07-12 18:41:43,705 [run_pretraining.py:  535]:	loss/mlm_loss, 9.004807472229004, 614
[INFO] 2021-07-12 18:41:43,706 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.129999746917747e-06, 614
[INFO] 2021-07-12 18:41:43,706 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 614
[INFO] 2021-07-12 18:41:43,706 [run_pretraining.py:  558]:	worker_index: 2, step: 614, cost: 9.004807, mlm loss: 9.004807, speed: 1.090853 steps/s, speed: 8.726825 samples/s, speed: 4468.134309 tokens/s, learning rate: 6.130e-06, loss_scalings: 13421.773438, pp_loss: 8.812205
[INFO] 2021-07-12 18:41:43,706 [run_pretraining.py:  512]:	********exe.run_614******* 
[INFO] 2021-07-12 18:41:44,622 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:44,623 [run_pretraining.py:  534]:	loss/total_loss, 8.81161880493164, 615
[INFO] 2021-07-12 18:41:44,623 [run_pretraining.py:  535]:	loss/mlm_loss, 8.81161880493164, 615
[INFO] 2021-07-12 18:41:44,623 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.13999964116374e-06, 615
[INFO] 2021-07-12 18:41:44,623 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 615
[INFO] 2021-07-12 18:41:44,623 [run_pretraining.py:  558]:	worker_index: 2, step: 615, cost: 8.811619, mlm loss: 8.811619, speed: 1.090573 steps/s, speed: 8.724588 samples/s, speed: 4466.988801 tokens/s, learning rate: 6.140e-06, loss_scalings: 13421.773438, pp_loss: 8.615462
[INFO] 2021-07-12 18:41:44,623 [run_pretraining.py:  512]:	********exe.run_615******* 
[INFO] 2021-07-12 18:42:10,727 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:10,728 [run_pretraining.py:  534]:	loss/total_loss, 8.57276725769043, 616
[INFO] 2021-07-12 18:42:10,728 [run_pretraining.py:  535]:	loss/mlm_loss, 8.57276725769043, 616
[INFO] 2021-07-12 18:42:10,728 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.1499999901570845e-06, 616
[INFO] 2021-07-12 18:42:10,728 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 616
[INFO] 2021-07-12 18:42:10,728 [run_pretraining.py:  558]:	worker_index: 2, step: 616, cost: 8.572767, mlm loss: 8.572767, speed: 0.038307 steps/s, speed: 0.306459 samples/s, speed: 156.907262 tokens/s, learning rate: 6.150e-06, loss_scalings: 13421.773438, pp_loss: 8.708822
[INFO] 2021-07-12 18:42:10,729 [run_pretraining.py:  512]:	********exe.run_616******* 
[INFO] 2021-07-12 18:42:11,636 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:11,637 [run_pretraining.py:  534]:	loss/total_loss, 8.231118202209473, 617
[INFO] 2021-07-12 18:42:11,637 [run_pretraining.py:  535]:	loss/mlm_loss, 8.231118202209473, 617
[INFO] 2021-07-12 18:42:11,637 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.159999884403078e-06, 617
[INFO] 2021-07-12 18:42:11,637 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 617
[INFO] 2021-07-12 18:42:11,637 [run_pretraining.py:  558]:	worker_index: 2, step: 617, cost: 8.231118, mlm loss: 8.231118, speed: 1.101084 steps/s, speed: 8.808674 samples/s, speed: 4510.041004 tokens/s, learning rate: 6.160e-06, loss_scalings: 13421.773438, pp_loss: 8.623140
[INFO] 2021-07-12 18:42:11,637 [run_pretraining.py:  512]:	********exe.run_617******* 
[INFO] 2021-07-12 18:42:12,558 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:12,558 [run_pretraining.py:  534]:	loss/total_loss, 8.715097427368164, 618
[INFO] 2021-07-12 18:42:12,559 [run_pretraining.py:  535]:	loss/mlm_loss, 8.715097427368164, 618
[INFO] 2021-07-12 18:42:12,559 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.169999778649071e-06, 618
[INFO] 2021-07-12 18:42:12,559 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 618
[INFO] 2021-07-12 18:42:12,559 [run_pretraining.py:  558]:	worker_index: 2, step: 618, cost: 8.715097, mlm loss: 8.715097, speed: 1.085843 steps/s, speed: 8.686746 samples/s, speed: 4447.613851 tokens/s, learning rate: 6.170e-06, loss_scalings: 13421.773438, pp_loss: 8.608513
[INFO] 2021-07-12 18:42:12,559 [run_pretraining.py:  512]:	********exe.run_618******* 
[INFO] 2021-07-12 18:42:13,473 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:13,473 [run_pretraining.py:  534]:	loss/total_loss, 8.594911575317383, 619
[INFO] 2021-07-12 18:42:13,473 [run_pretraining.py:  535]:	loss/mlm_loss, 8.594911575317383, 619
[INFO] 2021-07-12 18:42:13,474 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.179999672895065e-06, 619
[INFO] 2021-07-12 18:42:13,474 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 619
[INFO] 2021-07-12 18:42:13,474 [run_pretraining.py:  558]:	worker_index: 2, step: 619, cost: 8.594912, mlm loss: 8.594912, speed: 1.093732 steps/s, speed: 8.749859 samples/s, speed: 4479.927837 tokens/s, learning rate: 6.180e-06, loss_scalings: 13421.773438, pp_loss: 8.487321
[INFO] 2021-07-12 18:42:13,474 [run_pretraining.py:  512]:	********exe.run_619******* 
[INFO] 2021-07-12 18:42:14,385 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:14,386 [run_pretraining.py:  534]:	loss/total_loss, 8.640277862548828, 620
[INFO] 2021-07-12 18:42:14,386 [run_pretraining.py:  535]:	loss/mlm_loss, 8.640277862548828, 620
[INFO] 2021-07-12 18:42:14,386 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.190000021888409e-06, 620
[INFO] 2021-07-12 18:42:14,386 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 620
[INFO] 2021-07-12 18:42:14,386 [run_pretraining.py:  558]:	worker_index: 2, step: 620, cost: 8.640278, mlm loss: 8.640278, speed: 1.096708 steps/s, speed: 8.773662 samples/s, speed: 4492.114993 tokens/s, learning rate: 6.190e-06, loss_scalings: 13421.773438, pp_loss: 8.540537
[INFO] 2021-07-12 18:42:14,386 [run_pretraining.py:  512]:	********exe.run_620******* 
[INFO] 2021-07-12 18:42:15,298 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:15,298 [run_pretraining.py:  534]:	loss/total_loss, 8.550185203552246, 621
[INFO] 2021-07-12 18:42:15,298 [run_pretraining.py:  535]:	loss/mlm_loss, 8.550185203552246, 621
[INFO] 2021-07-12 18:42:15,298 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.199999916134402e-06, 621
[INFO] 2021-07-12 18:42:15,298 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 621
[INFO] 2021-07-12 18:42:15,299 [run_pretraining.py:  558]:	worker_index: 2, step: 621, cost: 8.550185, mlm loss: 8.550185, speed: 1.096646 steps/s, speed: 8.773169 samples/s, speed: 4491.862473 tokens/s, learning rate: 6.200e-06, loss_scalings: 13421.773438, pp_loss: 8.489979
[INFO] 2021-07-12 18:42:15,299 [run_pretraining.py:  512]:	********exe.run_621******* 
[INFO] 2021-07-12 18:42:16,210 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:16,210 [run_pretraining.py:  534]:	loss/total_loss, 9.087640762329102, 622
[INFO] 2021-07-12 18:42:16,210 [run_pretraining.py:  535]:	loss/mlm_loss, 9.087640762329102, 622
[INFO] 2021-07-12 18:42:16,210 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.2099998103803955e-06, 622
[INFO] 2021-07-12 18:42:16,210 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 622
[INFO] 2021-07-12 18:42:16,210 [run_pretraining.py:  558]:	worker_index: 2, step: 622, cost: 9.087641, mlm loss: 9.087641, speed: 1.097387 steps/s, speed: 8.779098 samples/s, speed: 4494.898117 tokens/s, learning rate: 6.210e-06, loss_scalings: 13421.773438, pp_loss: 8.835669
[INFO] 2021-07-12 18:42:16,210 [run_pretraining.py:  512]:	********exe.run_622******* 
[INFO] 2021-07-12 18:42:17,123 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:17,124 [run_pretraining.py:  534]:	loss/total_loss, 8.68569564819336, 623
[INFO] 2021-07-12 18:42:17,124 [run_pretraining.py:  535]:	loss/mlm_loss, 8.68569564819336, 623
[INFO] 2021-07-12 18:42:17,124 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.219999704626389e-06, 623
[INFO] 2021-07-12 18:42:17,124 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 623
[INFO] 2021-07-12 18:42:17,124 [run_pretraining.py:  558]:	worker_index: 2, step: 623, cost: 8.685696, mlm loss: 8.685696, speed: 1.095294 steps/s, speed: 8.762351 samples/s, speed: 4486.323577 tokens/s, learning rate: 6.220e-06, loss_scalings: 13421.773438, pp_loss: 8.723699
[INFO] 2021-07-12 18:42:17,124 [run_pretraining.py:  512]:	********exe.run_623******* 
[INFO] 2021-07-12 18:42:18,042 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:18,043 [run_pretraining.py:  534]:	loss/total_loss, 8.457707405090332, 624
[INFO] 2021-07-12 18:42:18,043 [run_pretraining.py:  535]:	loss/mlm_loss, 8.457707405090332, 624
[INFO] 2021-07-12 18:42:18,043 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.230000053619733e-06, 624
[INFO] 2021-07-12 18:42:18,043 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 624
[INFO] 2021-07-12 18:42:18,043 [run_pretraining.py:  558]:	worker_index: 2, step: 624, cost: 8.457707, mlm loss: 8.457707, speed: 1.088581 steps/s, speed: 8.708646 samples/s, speed: 4458.826957 tokens/s, learning rate: 6.230e-06, loss_scalings: 13421.773438, pp_loss: 8.594737
[INFO] 2021-07-12 18:42:18,043 [run_pretraining.py:  512]:	********exe.run_624******* 
[INFO] 2021-07-12 18:42:18,957 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:18,957 [run_pretraining.py:  534]:	loss/total_loss, 8.661323547363281, 625
[INFO] 2021-07-12 18:42:18,957 [run_pretraining.py:  535]:	loss/mlm_loss, 8.661323547363281, 625
[INFO] 2021-07-12 18:42:18,957 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.2399994931183755e-06, 625
[INFO] 2021-07-12 18:42:18,957 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 625
[INFO] 2021-07-12 18:42:18,957 [run_pretraining.py:  558]:	worker_index: 2, step: 625, cost: 8.661324, mlm loss: 8.661324, speed: 1.094552 steps/s, speed: 8.756415 samples/s, speed: 4483.284290 tokens/s, learning rate: 6.240e-06, loss_scalings: 13421.773438, pp_loss: 8.652481
[INFO] 2021-07-12 18:42:18,958 [run_pretraining.py:  512]:	********exe.run_625******* 
[INFO] 2021-07-12 18:42:19,870 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:19,870 [run_pretraining.py:  534]:	loss/total_loss, 8.911823272705078, 626
[INFO] 2021-07-12 18:42:19,870 [run_pretraining.py:  535]:	loss/mlm_loss, 8.911823272705078, 626
[INFO] 2021-07-12 18:42:19,871 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.24999984211172e-06, 626
[INFO] 2021-07-12 18:42:19,871 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 626
[INFO] 2021-07-12 18:42:19,871 [run_pretraining.py:  558]:	worker_index: 2, step: 626, cost: 8.911823, mlm loss: 8.911823, speed: 1.095720 steps/s, speed: 8.765759 samples/s, speed: 4488.068696 tokens/s, learning rate: 6.250e-06, loss_scalings: 13421.773438, pp_loss: 8.652932
[INFO] 2021-07-12 18:42:19,871 [run_pretraining.py:  512]:	********exe.run_626******* 
[INFO] 2021-07-12 18:42:20,778 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:20,779 [run_pretraining.py:  534]:	loss/total_loss, 8.624208450317383, 627
[INFO] 2021-07-12 18:42:20,779 [run_pretraining.py:  535]:	loss/mlm_loss, 8.624208450317383, 627
[INFO] 2021-07-12 18:42:20,779 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.260000191105064e-06, 627
[INFO] 2021-07-12 18:42:20,779 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 627
[INFO] 2021-07-12 18:42:20,779 [run_pretraining.py:  558]:	worker_index: 2, step: 627, cost: 8.624208, mlm loss: 8.624208, speed: 1.101515 steps/s, speed: 8.812118 samples/s, speed: 4511.804626 tokens/s, learning rate: 6.260e-06, loss_scalings: 13421.773438, pp_loss: 8.799704
[INFO] 2021-07-12 18:42:20,779 [run_pretraining.py:  512]:	********exe.run_627******* 
[INFO] 2021-07-12 18:42:21,692 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:21,692 [run_pretraining.py:  534]:	loss/total_loss, 9.403814315795898, 628
[INFO] 2021-07-12 18:42:21,692 [run_pretraining.py:  535]:	loss/mlm_loss, 9.403814315795898, 628
[INFO] 2021-07-12 18:42:21,693 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.270000085351057e-06, 628
[INFO] 2021-07-12 18:42:21,693 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 628
[INFO] 2021-07-12 18:42:21,693 [run_pretraining.py:  558]:	worker_index: 2, step: 628, cost: 9.403814, mlm loss: 9.403814, speed: 1.095392 steps/s, speed: 8.763136 samples/s, speed: 4486.725455 tokens/s, learning rate: 6.270e-06, loss_scalings: 13421.773438, pp_loss: 8.813446
[INFO] 2021-07-12 18:42:21,693 [run_pretraining.py:  512]:	********exe.run_628******* 
[INFO] 2021-07-12 18:42:22,614 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:22,614 [run_pretraining.py:  534]:	loss/total_loss, 8.705910682678223, 629
[INFO] 2021-07-12 18:42:22,614 [run_pretraining.py:  535]:	loss/mlm_loss, 8.705910682678223, 629
[INFO] 2021-07-12 18:42:22,615 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.2799995248497e-06, 629
[INFO] 2021-07-12 18:42:22,615 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 629
[INFO] 2021-07-12 18:42:22,615 [run_pretraining.py:  558]:	worker_index: 2, step: 629, cost: 8.705911, mlm loss: 8.705911, speed: 1.085295 steps/s, speed: 8.682358 samples/s, speed: 4445.367412 tokens/s, learning rate: 6.280e-06, loss_scalings: 13421.773438, pp_loss: 8.484637
[INFO] 2021-07-12 18:42:22,615 [run_pretraining.py:  512]:	********exe.run_629******* 
[INFO] 2021-07-12 18:42:23,532 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:23,533 [run_pretraining.py:  534]:	loss/total_loss, 8.667107582092285, 630
[INFO] 2021-07-12 18:42:23,533 [run_pretraining.py:  535]:	loss/mlm_loss, 8.667107582092285, 630
[INFO] 2021-07-12 18:42:23,533 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.289999873843044e-06, 630
[INFO] 2021-07-12 18:42:23,533 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 630
[INFO] 2021-07-12 18:42:23,533 [run_pretraining.py:  558]:	worker_index: 2, step: 630, cost: 8.667108, mlm loss: 8.667108, speed: 1.089380 steps/s, speed: 8.715036 samples/s, speed: 4462.098544 tokens/s, learning rate: 6.290e-06, loss_scalings: 13421.773438, pp_loss: 8.667736
[INFO] 2021-07-12 18:42:23,533 [run_pretraining.py:  512]:	********exe.run_630******* 
[INFO] 2021-07-12 18:42:24,451 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:24,452 [run_pretraining.py:  534]:	loss/total_loss, 8.820737838745117, 631
[INFO] 2021-07-12 18:42:24,452 [run_pretraining.py:  535]:	loss/mlm_loss, 8.820737838745117, 631
[INFO] 2021-07-12 18:42:24,452 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.299999768089037e-06, 631
[INFO] 2021-07-12 18:42:24,452 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 631
[INFO] 2021-07-12 18:42:24,452 [run_pretraining.py:  558]:	worker_index: 2, step: 631, cost: 8.820738, mlm loss: 8.820738, speed: 1.089075 steps/s, speed: 8.712597 samples/s, speed: 4460.849563 tokens/s, learning rate: 6.300e-06, loss_scalings: 13421.773438, pp_loss: 8.549294
[INFO] 2021-07-12 18:42:24,452 [run_pretraining.py:  512]:	********exe.run_631******* 
[INFO] 2021-07-12 18:42:25,372 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:25,372 [run_pretraining.py:  534]:	loss/total_loss, 8.8593168258667, 632
[INFO] 2021-07-12 18:42:25,372 [run_pretraining.py:  535]:	loss/mlm_loss, 8.8593168258667, 632
[INFO] 2021-07-12 18:42:25,372 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.310000117082382e-06, 632
[INFO] 2021-07-12 18:42:25,372 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 632
[INFO] 2021-07-12 18:42:25,372 [run_pretraining.py:  558]:	worker_index: 2, step: 632, cost: 8.859317, mlm loss: 8.859317, speed: 1.087272 steps/s, speed: 8.698176 samples/s, speed: 4453.466157 tokens/s, learning rate: 6.310e-06, loss_scalings: 13421.773438, pp_loss: 8.627260
[INFO] 2021-07-12 18:42:25,372 [run_pretraining.py:  512]:	********exe.run_632******* 
[INFO] 2021-07-12 18:42:26,298 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:26,299 [run_pretraining.py:  534]:	loss/total_loss, 8.743414878845215, 633
[INFO] 2021-07-12 18:42:26,299 [run_pretraining.py:  535]:	loss/mlm_loss, 8.743414878845215, 633
[INFO] 2021-07-12 18:42:26,299 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.319999556581024e-06, 633
[INFO] 2021-07-12 18:42:26,299 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 633
[INFO] 2021-07-12 18:42:26,299 [run_pretraining.py:  558]:	worker_index: 2, step: 633, cost: 8.743415, mlm loss: 8.743415, speed: 1.079681 steps/s, speed: 8.637451 samples/s, speed: 4422.374809 tokens/s, learning rate: 6.320e-06, loss_scalings: 13421.773438, pp_loss: 8.570026
[INFO] 2021-07-12 18:42:26,299 [run_pretraining.py:  512]:	********exe.run_633******* 
[INFO] 2021-07-12 18:42:27,212 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:27,213 [run_pretraining.py:  534]:	loss/total_loss, 7.37335205078125, 634
[INFO] 2021-07-12 18:42:27,213 [run_pretraining.py:  535]:	loss/mlm_loss, 7.37335205078125, 634
[INFO] 2021-07-12 18:42:27,213 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.329999905574368e-06, 634
[INFO] 2021-07-12 18:42:27,213 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 634
[INFO] 2021-07-12 18:42:27,213 [run_pretraining.py:  558]:	worker_index: 2, step: 634, cost: 7.373352, mlm loss: 7.373352, speed: 1.094958 steps/s, speed: 8.759663 samples/s, speed: 4484.947427 tokens/s, learning rate: 6.330e-06, loss_scalings: 13421.773438, pp_loss: 8.447626
[INFO] 2021-07-12 18:42:27,213 [run_pretraining.py:  512]:	********exe.run_634******* 
[INFO] 2021-07-12 18:42:28,152 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:28,158 [run_pretraining.py:  534]:	loss/total_loss, 8.677841186523438, 635
[INFO] 2021-07-12 18:42:28,163 [run_pretraining.py:  535]:	loss/mlm_loss, 8.677841186523438, 635
[INFO] 2021-07-12 18:42:28,168 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.339999799820362e-06, 635
[INFO] 2021-07-12 18:42:28,173 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 635
[INFO] 2021-07-12 18:42:28,178 [run_pretraining.py:  558]:	worker_index: 2, step: 635, cost: 8.677841, mlm loss: 8.677841, speed: 1.058814 steps/s, speed: 8.470509 samples/s, speed: 4336.900790 tokens/s, learning rate: 6.340e-06, loss_scalings: 13421.773438, pp_loss: 8.558179
[INFO] 2021-07-12 18:42:28,183 [run_pretraining.py:  512]:	********exe.run_635******* 
[INFO] 2021-07-12 18:42:29,083 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:29,084 [run_pretraining.py:  534]:	loss/total_loss, 8.864680290222168, 636
[INFO] 2021-07-12 18:42:29,084 [run_pretraining.py:  535]:	loss/mlm_loss, 8.864680290222168, 636
[INFO] 2021-07-12 18:42:29,084 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.350000148813706e-06, 636
[INFO] 2021-07-12 18:42:29,084 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 636
[INFO] 2021-07-12 18:42:29,084 [run_pretraining.py:  558]:	worker_index: 2, step: 636, cost: 8.864680, mlm loss: 8.864680, speed: 1.111173 steps/s, speed: 8.889382 samples/s, speed: 4551.363826 tokens/s, learning rate: 6.350e-06, loss_scalings: 13421.773438, pp_loss: 8.577416
[INFO] 2021-07-12 18:42:29,084 [run_pretraining.py:  512]:	********exe.run_636******* 
[INFO] 2021-07-12 18:42:30,007 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:30,007 [run_pretraining.py:  534]:	loss/total_loss, 8.448812484741211, 637
[INFO] 2021-07-12 18:42:30,007 [run_pretraining.py:  535]:	loss/mlm_loss, 8.448812484741211, 637
[INFO] 2021-07-12 18:42:30,008 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.360000043059699e-06, 637
[INFO] 2021-07-12 18:42:30,008 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 637
[INFO] 2021-07-12 18:42:30,008 [run_pretraining.py:  558]:	worker_index: 2, step: 637, cost: 8.448812, mlm loss: 8.448812, speed: 1.083280 steps/s, speed: 8.666242 samples/s, speed: 4437.115849 tokens/s, learning rate: 6.360e-06, loss_scalings: 13421.773438, pp_loss: 8.493925
[INFO] 2021-07-12 18:42:30,008 [run_pretraining.py:  512]:	********exe.run_637******* 
[INFO] 2021-07-12 18:42:30,936 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:30,936 [run_pretraining.py:  534]:	loss/total_loss, 8.512130737304688, 638
[INFO] 2021-07-12 18:42:30,937 [run_pretraining.py:  535]:	loss/mlm_loss, 8.512130737304688, 638
[INFO] 2021-07-12 18:42:30,937 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.369999482558342e-06, 638
[INFO] 2021-07-12 18:42:30,937 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 638
[INFO] 2021-07-12 18:42:30,937 [run_pretraining.py:  558]:	worker_index: 2, step: 638, cost: 8.512131, mlm loss: 8.512131, speed: 1.076986 steps/s, speed: 8.615884 samples/s, speed: 4411.332740 tokens/s, learning rate: 6.370e-06, loss_scalings: 13421.773438, pp_loss: 8.611505
[INFO] 2021-07-12 18:42:30,937 [run_pretraining.py:  512]:	********exe.run_638******* 
[INFO] 2021-07-12 18:42:31,840 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:31,841 [run_pretraining.py:  534]:	loss/total_loss, 8.328107833862305, 639
[INFO] 2021-07-12 18:42:31,841 [run_pretraining.py:  535]:	loss/mlm_loss, 8.328107833862305, 639
[INFO] 2021-07-12 18:42:31,841 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.379999831551686e-06, 639
[INFO] 2021-07-12 18:42:31,841 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 639
[INFO] 2021-07-12 18:42:31,841 [run_pretraining.py:  558]:	worker_index: 2, step: 639, cost: 8.328108, mlm loss: 8.328108, speed: 1.106541 steps/s, speed: 8.852328 samples/s, speed: 4532.392125 tokens/s, learning rate: 6.380e-06, loss_scalings: 13421.773438, pp_loss: 8.351084
[INFO] 2021-07-12 18:42:31,841 [run_pretraining.py:  512]:	********exe.run_639******* 
[INFO] 2021-07-12 18:42:32,835 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:32,835 [run_pretraining.py:  534]:	loss/total_loss, 8.486873626708984, 640
[INFO] 2021-07-12 18:42:32,835 [run_pretraining.py:  535]:	loss/mlm_loss, 8.486873626708984, 640
[INFO] 2021-07-12 18:42:32,835 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.39000018054503e-06, 640
[INFO] 2021-07-12 18:42:32,835 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 640
[INFO] 2021-07-12 18:42:32,835 [run_pretraining.py:  558]:	worker_index: 2, step: 640, cost: 8.486874, mlm loss: 8.486874, speed: 1.006393 steps/s, speed: 8.051140 samples/s, speed: 4122.183897 tokens/s, learning rate: 6.390e-06, loss_scalings: 13421.773438, pp_loss: 8.558653
[INFO] 2021-07-12 18:42:32,835 [run_pretraining.py:  512]:	********exe.run_640******* 
[INFO] 2021-07-12 18:42:33,734 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:33,734 [run_pretraining.py:  534]:	loss/total_loss, 9.021832466125488, 641
[INFO] 2021-07-12 18:42:33,734 [run_pretraining.py:  535]:	loss/mlm_loss, 9.021832466125488, 641
[INFO] 2021-07-12 18:42:33,734 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.4000000747910235e-06, 641
[INFO] 2021-07-12 18:42:33,734 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 641
[INFO] 2021-07-12 18:42:33,735 [run_pretraining.py:  558]:	worker_index: 2, step: 641, cost: 9.021832, mlm loss: 9.021832, speed: 1.112890 steps/s, speed: 8.903122 samples/s, speed: 4558.398272 tokens/s, learning rate: 6.400e-06, loss_scalings: 13421.773438, pp_loss: 8.792370
[INFO] 2021-07-12 18:42:33,735 [run_pretraining.py:  512]:	********exe.run_641******* 
[INFO] 2021-07-12 18:42:34,647 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:34,647 [run_pretraining.py:  534]:	loss/total_loss, 9.025898933410645, 642
[INFO] 2021-07-12 18:42:34,647 [run_pretraining.py:  535]:	loss/mlm_loss, 9.025898933410645, 642
[INFO] 2021-07-12 18:42:34,647 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.409999514289666e-06, 642
[INFO] 2021-07-12 18:42:34,647 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 642
[INFO] 2021-07-12 18:42:34,647 [run_pretraining.py:  558]:	worker_index: 2, step: 642, cost: 9.025899, mlm loss: 9.025899, speed: 1.096197 steps/s, speed: 8.769578 samples/s, speed: 4490.024043 tokens/s, learning rate: 6.410e-06, loss_scalings: 13421.773438, pp_loss: 8.693392
[INFO] 2021-07-12 18:42:34,647 [run_pretraining.py:  512]:	********exe.run_642******* 
[INFO] 2021-07-12 18:42:35,554 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:35,555 [run_pretraining.py:  534]:	loss/total_loss, 8.202095985412598, 643
[INFO] 2021-07-12 18:42:35,555 [run_pretraining.py:  535]:	loss/mlm_loss, 8.202095985412598, 643
[INFO] 2021-07-12 18:42:35,555 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.41999986328301e-06, 643
[INFO] 2021-07-12 18:42:35,555 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 643
[INFO] 2021-07-12 18:42:35,555 [run_pretraining.py:  558]:	worker_index: 2, step: 643, cost: 8.202096, mlm loss: 8.202096, speed: 1.102417 steps/s, speed: 8.819338 samples/s, speed: 4515.500977 tokens/s, learning rate: 6.420e-06, loss_scalings: 13421.773438, pp_loss: 8.410842
[INFO] 2021-07-12 18:42:35,555 [run_pretraining.py:  512]:	********exe.run_643******* 
[INFO] 2021-07-12 18:42:36,465 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:36,466 [run_pretraining.py:  534]:	loss/total_loss, 8.69857406616211, 644
[INFO] 2021-07-12 18:42:36,466 [run_pretraining.py:  535]:	loss/mlm_loss, 8.69857406616211, 644
[INFO] 2021-07-12 18:42:36,466 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.4299997575290035e-06, 644
[INFO] 2021-07-12 18:42:36,466 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 644
[INFO] 2021-07-12 18:42:36,466 [run_pretraining.py:  558]:	worker_index: 2, step: 644, cost: 8.698574, mlm loss: 8.698574, speed: 1.098619 steps/s, speed: 8.788954 samples/s, speed: 4499.944257 tokens/s, learning rate: 6.430e-06, loss_scalings: 13421.773438, pp_loss: 8.473877
[INFO] 2021-07-12 18:42:36,466 [run_pretraining.py:  512]:	********exe.run_644******* 
[INFO] 2021-07-12 18:42:37,525 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:37,525 [run_pretraining.py:  534]:	loss/total_loss, 8.184684753417969, 645
[INFO] 2021-07-12 18:42:37,525 [run_pretraining.py:  535]:	loss/mlm_loss, 8.184684753417969, 645
[INFO] 2021-07-12 18:42:37,525 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.440000106522348e-06, 645
[INFO] 2021-07-12 18:42:37,525 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 645
[INFO] 2021-07-12 18:42:37,525 [run_pretraining.py:  558]:	worker_index: 2, step: 645, cost: 8.184685, mlm loss: 8.184685, speed: 0.944420 steps/s, speed: 7.555361 samples/s, speed: 3868.344940 tokens/s, learning rate: 6.440e-06, loss_scalings: 13421.773438, pp_loss: 8.179231
[INFO] 2021-07-12 18:42:37,525 [run_pretraining.py:  512]:	********exe.run_645******* 
[INFO] 2021-07-12 18:42:38,602 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:38,602 [run_pretraining.py:  534]:	loss/total_loss, 8.898262977600098, 646
[INFO] 2021-07-12 18:42:38,603 [run_pretraining.py:  535]:	loss/mlm_loss, 8.898262977600098, 646
[INFO] 2021-07-12 18:42:38,603 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.44999954602099e-06, 646
[INFO] 2021-07-12 18:42:38,603 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 646
[INFO] 2021-07-12 18:42:38,603 [run_pretraining.py:  558]:	worker_index: 2, step: 646, cost: 8.898263, mlm loss: 8.898263, speed: 0.928646 steps/s, speed: 7.429171 samples/s, speed: 3803.735745 tokens/s, learning rate: 6.450e-06, loss_scalings: 13421.773438, pp_loss: 8.646008
[INFO] 2021-07-12 18:42:38,603 [run_pretraining.py:  512]:	********exe.run_646******* 
[INFO] 2021-07-12 18:42:39,713 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:39,714 [run_pretraining.py:  534]:	loss/total_loss, 8.92425537109375, 647
[INFO] 2021-07-12 18:42:39,714 [run_pretraining.py:  535]:	loss/mlm_loss, 8.92425537109375, 647
[INFO] 2021-07-12 18:42:39,714 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.459999440266984e-06, 647
[INFO] 2021-07-12 18:42:39,714 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 647
[INFO] 2021-07-12 18:42:39,714 [run_pretraining.py:  558]:	worker_index: 2, step: 647, cost: 8.924255, mlm loss: 8.924255, speed: 0.900338 steps/s, speed: 7.202707 samples/s, speed: 3687.786205 tokens/s, learning rate: 6.460e-06, loss_scalings: 13421.773438, pp_loss: 8.865365
[INFO] 2021-07-12 18:42:39,714 [run_pretraining.py:  512]:	********exe.run_647******* 
[INFO] 2021-07-12 18:42:40,776 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:40,776 [run_pretraining.py:  534]:	loss/total_loss, 8.496077537536621, 648
[INFO] 2021-07-12 18:42:40,776 [run_pretraining.py:  535]:	loss/mlm_loss, 8.496077537536621, 648
[INFO] 2021-07-12 18:42:40,776 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.469999789260328e-06, 648
[INFO] 2021-07-12 18:42:40,776 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 648
[INFO] 2021-07-12 18:42:40,777 [run_pretraining.py:  558]:	worker_index: 2, step: 648, cost: 8.496078, mlm loss: 8.496078, speed: 0.941758 steps/s, speed: 7.534064 samples/s, speed: 3857.440917 tokens/s, learning rate: 6.470e-06, loss_scalings: 13421.773438, pp_loss: 8.679247
[INFO] 2021-07-12 18:42:40,777 [run_pretraining.py:  512]:	********exe.run_648******* 
[INFO] 2021-07-12 18:42:41,819 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:41,819 [run_pretraining.py:  534]:	loss/total_loss, 9.079057693481445, 649
[INFO] 2021-07-12 18:42:41,819 [run_pretraining.py:  535]:	loss/mlm_loss, 9.079057693481445, 649
[INFO] 2021-07-12 18:42:41,819 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.480000138253672e-06, 649
[INFO] 2021-07-12 18:42:41,819 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 649
[INFO] 2021-07-12 18:42:41,819 [run_pretraining.py:  558]:	worker_index: 2, step: 649, cost: 9.079058, mlm loss: 9.079058, speed: 0.959513 steps/s, speed: 7.676101 samples/s, speed: 3930.163614 tokens/s, learning rate: 6.480e-06, loss_scalings: 13421.773438, pp_loss: 8.658190
[INFO] 2021-07-12 18:42:41,819 [run_pretraining.py:  512]:	********exe.run_649******* 
[INFO] 2021-07-12 18:42:42,766 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:42,767 [run_pretraining.py:  534]:	loss/total_loss, 8.616753578186035, 650
[INFO] 2021-07-12 18:42:42,767 [run_pretraining.py:  535]:	loss/mlm_loss, 8.616753578186035, 650
[INFO] 2021-07-12 18:42:42,767 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.490000032499665e-06, 650
[INFO] 2021-07-12 18:42:42,767 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 650
[INFO] 2021-07-12 18:42:42,767 [run_pretraining.py:  558]:	worker_index: 2, step: 650, cost: 8.616754, mlm loss: 8.616754, speed: 1.055892 steps/s, speed: 8.447138 samples/s, speed: 4324.934769 tokens/s, learning rate: 6.490e-06, loss_scalings: 13421.773438, pp_loss: 8.704981
[INFO] 2021-07-12 18:42:42,767 [run_pretraining.py:  512]:	********exe.run_650******* 
[INFO] 2021-07-12 18:42:43,666 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:43,666 [run_pretraining.py:  534]:	loss/total_loss, 8.741150856018066, 651
[INFO] 2021-07-12 18:42:43,666 [run_pretraining.py:  535]:	loss/mlm_loss, 8.741150856018066, 651
[INFO] 2021-07-12 18:42:43,666 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.499999471998308e-06, 651
[INFO] 2021-07-12 18:42:43,666 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 651
[INFO] 2021-07-12 18:42:43,667 [run_pretraining.py:  558]:	worker_index: 2, step: 651, cost: 8.741151, mlm loss: 8.741151, speed: 1.112446 steps/s, speed: 8.899565 samples/s, speed: 4556.577497 tokens/s, learning rate: 6.500e-06, loss_scalings: 13421.773438, pp_loss: 8.415586
[INFO] 2021-07-12 18:42:43,667 [run_pretraining.py:  512]:	********exe.run_651******* 
[INFO] 2021-07-12 18:42:44,575 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:44,575 [run_pretraining.py:  534]:	loss/total_loss, 8.794022560119629, 652
[INFO] 2021-07-12 18:42:44,575 [run_pretraining.py:  535]:	loss/mlm_loss, 8.794022560119629, 652
[INFO] 2021-07-12 18:42:44,576 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.509999820991652e-06, 652
[INFO] 2021-07-12 18:42:44,576 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 652
[INFO] 2021-07-12 18:42:44,576 [run_pretraining.py:  558]:	worker_index: 2, step: 652, cost: 8.794023, mlm loss: 8.794023, speed: 1.100594 steps/s, speed: 8.804754 samples/s, speed: 4508.033882 tokens/s, learning rate: 6.510e-06, loss_scalings: 13421.773438, pp_loss: 8.718316
[INFO] 2021-07-12 18:42:44,576 [run_pretraining.py:  512]:	********exe.run_652******* 
[INFO] 2021-07-12 18:42:45,489 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:45,489 [run_pretraining.py:  534]:	loss/total_loss, 8.263628005981445, 653
[INFO] 2021-07-12 18:42:45,490 [run_pretraining.py:  535]:	loss/mlm_loss, 8.263628005981445, 653
[INFO] 2021-07-12 18:42:45,490 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.5199997152376454e-06, 653
[INFO] 2021-07-12 18:42:45,490 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 653
[INFO] 2021-07-12 18:42:45,490 [run_pretraining.py:  558]:	worker_index: 2, step: 653, cost: 8.263628, mlm loss: 8.263628, speed: 1.094733 steps/s, speed: 8.757864 samples/s, speed: 4484.026170 tokens/s, learning rate: 6.520e-06, loss_scalings: 13421.773438, pp_loss: 8.007374
[INFO] 2021-07-12 18:42:45,490 [run_pretraining.py:  512]:	********exe.run_653******* 
[INFO] 2021-07-12 18:42:46,395 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:46,396 [run_pretraining.py:  534]:	loss/total_loss, 9.0208158493042, 654
[INFO] 2021-07-12 18:42:46,396 [run_pretraining.py:  535]:	loss/mlm_loss, 9.0208158493042, 654
[INFO] 2021-07-12 18:42:46,396 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.53000006423099e-06, 654
[INFO] 2021-07-12 18:42:46,396 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 654
[INFO] 2021-07-12 18:42:46,396 [run_pretraining.py:  558]:	worker_index: 2, step: 654, cost: 9.020816, mlm loss: 9.020816, speed: 1.104431 steps/s, speed: 8.835445 samples/s, speed: 4523.747931 tokens/s, learning rate: 6.530e-06, loss_scalings: 13421.773438, pp_loss: 8.757162
[INFO] 2021-07-12 18:42:46,396 [run_pretraining.py:  512]:	********exe.run_654******* 
[INFO] 2021-07-12 18:42:47,307 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:47,308 [run_pretraining.py:  534]:	loss/total_loss, 8.193293571472168, 655
[INFO] 2021-07-12 18:42:47,308 [run_pretraining.py:  535]:	loss/mlm_loss, 8.193293571472168, 655
[INFO] 2021-07-12 18:42:47,308 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.539999503729632e-06, 655
[INFO] 2021-07-12 18:42:47,308 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 655
[INFO] 2021-07-12 18:42:47,308 [run_pretraining.py:  558]:	worker_index: 2, step: 655, cost: 8.193294, mlm loss: 8.193294, speed: 1.097217 steps/s, speed: 8.777734 samples/s, speed: 4494.199661 tokens/s, learning rate: 6.540e-06, loss_scalings: 13421.773438, pp_loss: 8.343264
[INFO] 2021-07-12 18:42:47,308 [run_pretraining.py:  512]:	********exe.run_655******* 
[INFO] 2021-07-12 18:42:48,208 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:48,209 [run_pretraining.py:  534]:	loss/total_loss, 8.584519386291504, 656
[INFO] 2021-07-12 18:42:48,209 [run_pretraining.py:  535]:	loss/mlm_loss, 8.584519386291504, 656
[INFO] 2021-07-12 18:42:48,209 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.549999852722976e-06, 656
[INFO] 2021-07-12 18:42:48,209 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 656
[INFO] 2021-07-12 18:42:48,209 [run_pretraining.py:  558]:	worker_index: 2, step: 656, cost: 8.584519, mlm loss: 8.584519, speed: 1.110093 steps/s, speed: 8.880743 samples/s, speed: 4546.940554 tokens/s, learning rate: 6.550e-06, loss_scalings: 13421.773438, pp_loss: 8.717415
[INFO] 2021-07-12 18:42:48,209 [run_pretraining.py:  512]:	********exe.run_656******* 
[INFO] 2021-07-12 18:42:49,111 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:49,112 [run_pretraining.py:  534]:	loss/total_loss, 9.105789184570312, 657
[INFO] 2021-07-12 18:42:49,112 [run_pretraining.py:  535]:	loss/mlm_loss, 9.105789184570312, 657
[INFO] 2021-07-12 18:42:49,112 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.55999974696897e-06, 657
[INFO] 2021-07-12 18:42:49,112 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 657
[INFO] 2021-07-12 18:42:49,112 [run_pretraining.py:  558]:	worker_index: 2, step: 657, cost: 9.105789, mlm loss: 9.105789, speed: 1.108588 steps/s, speed: 8.868702 samples/s, speed: 4540.775359 tokens/s, learning rate: 6.560e-06, loss_scalings: 13421.773438, pp_loss: 8.684567
[INFO] 2021-07-12 18:42:49,112 [run_pretraining.py:  512]:	********exe.run_657******* 
[INFO] 2021-07-12 18:42:50,012 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:50,012 [run_pretraining.py:  534]:	loss/total_loss, 8.711240768432617, 658
[INFO] 2021-07-12 18:42:50,013 [run_pretraining.py:  535]:	loss/mlm_loss, 8.711240768432617, 658
[INFO] 2021-07-12 18:42:50,013 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.570000095962314e-06, 658
[INFO] 2021-07-12 18:42:50,013 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 658
[INFO] 2021-07-12 18:42:50,013 [run_pretraining.py:  558]:	worker_index: 2, step: 658, cost: 8.711241, mlm loss: 8.711241, speed: 1.110837 steps/s, speed: 8.886699 samples/s, speed: 4549.989667 tokens/s, learning rate: 6.570e-06, loss_scalings: 13421.773438, pp_loss: 8.420216
[INFO] 2021-07-12 18:42:50,013 [run_pretraining.py:  512]:	********exe.run_658******* 
[INFO] 2021-07-12 18:42:50,924 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:50,925 [run_pretraining.py:  534]:	loss/total_loss, 9.0294771194458, 659
[INFO] 2021-07-12 18:42:50,925 [run_pretraining.py:  535]:	loss/mlm_loss, 9.0294771194458, 659
[INFO] 2021-07-12 18:42:50,925 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.579999990208307e-06, 659
[INFO] 2021-07-12 18:42:50,925 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 659
[INFO] 2021-07-12 18:42:50,925 [run_pretraining.py:  558]:	worker_index: 2, step: 659, cost: 9.029477, mlm loss: 9.029477, speed: 1.097098 steps/s, speed: 8.776785 samples/s, speed: 4493.714163 tokens/s, learning rate: 6.580e-06, loss_scalings: 13421.773438, pp_loss: 8.469805
[INFO] 2021-07-12 18:42:50,925 [run_pretraining.py:  512]:	********exe.run_659******* 
[INFO] 2021-07-12 18:42:51,832 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:51,832 [run_pretraining.py:  534]:	loss/total_loss, 8.42906665802002, 660
[INFO] 2021-07-12 18:42:51,832 [run_pretraining.py:  535]:	loss/mlm_loss, 8.42906665802002, 660
[INFO] 2021-07-12 18:42:51,832 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.58999942970695e-06, 660
[INFO] 2021-07-12 18:42:51,832 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 660
[INFO] 2021-07-12 18:42:51,832 [run_pretraining.py:  558]:	worker_index: 2, step: 660, cost: 8.429067, mlm loss: 8.429067, speed: 1.102692 steps/s, speed: 8.821534 samples/s, speed: 4516.625194 tokens/s, learning rate: 6.590e-06, loss_scalings: 13421.773438, pp_loss: 8.485368
[INFO] 2021-07-12 18:42:51,832 [run_pretraining.py:  512]:	********exe.run_660******* 
[INFO] 2021-07-12 18:42:52,737 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:52,737 [run_pretraining.py:  534]:	loss/total_loss, 8.890668869018555, 661
[INFO] 2021-07-12 18:42:52,737 [run_pretraining.py:  535]:	loss/mlm_loss, 8.890668869018555, 661
[INFO] 2021-07-12 18:42:52,737 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.599999778700294e-06, 661
[INFO] 2021-07-12 18:42:52,737 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 661
[INFO] 2021-07-12 18:42:52,737 [run_pretraining.py:  558]:	worker_index: 2, step: 661, cost: 8.890669, mlm loss: 8.890669, speed: 1.105706 steps/s, speed: 8.845649 samples/s, speed: 4528.972512 tokens/s, learning rate: 6.600e-06, loss_scalings: 13421.773438, pp_loss: 8.754810
[INFO] 2021-07-12 18:42:52,737 [run_pretraining.py:  512]:	********exe.run_661******* 
[INFO] 2021-07-12 18:42:53,644 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:53,645 [run_pretraining.py:  534]:	loss/total_loss, 8.57342529296875, 662
[INFO] 2021-07-12 18:42:53,645 [run_pretraining.py:  535]:	loss/mlm_loss, 8.57342529296875, 662
[INFO] 2021-07-12 18:42:53,645 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.610000127693638e-06, 662
[INFO] 2021-07-12 18:42:53,645 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 662
[INFO] 2021-07-12 18:42:53,645 [run_pretraining.py:  558]:	worker_index: 2, step: 662, cost: 8.573425, mlm loss: 8.573425, speed: 1.102504 steps/s, speed: 8.820033 samples/s, speed: 4515.857057 tokens/s, learning rate: 6.610e-06, loss_scalings: 13421.773438, pp_loss: 8.478636
[INFO] 2021-07-12 18:42:53,645 [run_pretraining.py:  512]:	********exe.run_662******* 
[INFO] 2021-07-12 18:42:54,544 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:54,544 [run_pretraining.py:  534]:	loss/total_loss, 8.176666259765625, 663
[INFO] 2021-07-12 18:42:54,544 [run_pretraining.py:  535]:	loss/mlm_loss, 8.176666259765625, 663
[INFO] 2021-07-12 18:42:54,544 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.6200000219396316e-06, 663
[INFO] 2021-07-12 18:42:54,544 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 663
[INFO] 2021-07-12 18:42:54,544 [run_pretraining.py:  558]:	worker_index: 2, step: 663, cost: 8.176666, mlm loss: 8.176666, speed: 1.112456 steps/s, speed: 8.899650 samples/s, speed: 4556.621005 tokens/s, learning rate: 6.620e-06, loss_scalings: 13421.773438, pp_loss: 7.980757
[INFO] 2021-07-12 18:42:54,545 [run_pretraining.py:  512]:	********exe.run_663******* 
[INFO] 2021-07-12 18:42:55,450 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:55,450 [run_pretraining.py:  534]:	loss/total_loss, 8.439855575561523, 664
[INFO] 2021-07-12 18:42:55,450 [run_pretraining.py:  535]:	loss/mlm_loss, 8.439855575561523, 664
[INFO] 2021-07-12 18:42:55,450 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.629999461438274e-06, 664
[INFO] 2021-07-12 18:42:55,450 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 664
[INFO] 2021-07-12 18:42:55,450 [run_pretraining.py:  558]:	worker_index: 2, step: 664, cost: 8.439856, mlm loss: 8.439856, speed: 1.104574 steps/s, speed: 8.836595 samples/s, speed: 4524.336450 tokens/s, learning rate: 6.630e-06, loss_scalings: 13421.773438, pp_loss: 8.667212
[INFO] 2021-07-12 18:42:55,450 [run_pretraining.py:  512]:	********exe.run_664******* 
[INFO] 2021-07-12 18:42:56,359 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:56,359 [run_pretraining.py:  534]:	loss/total_loss, 8.848057746887207, 665
[INFO] 2021-07-12 18:42:56,359 [run_pretraining.py:  535]:	loss/mlm_loss, 8.848057746887207, 665
[INFO] 2021-07-12 18:42:56,359 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.639999810431618e-06, 665
[INFO] 2021-07-12 18:42:56,360 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 665
[INFO] 2021-07-12 18:42:56,360 [run_pretraining.py:  558]:	worker_index: 2, step: 665, cost: 8.848058, mlm loss: 8.848058, speed: 1.100648 steps/s, speed: 8.805183 samples/s, speed: 4508.253916 tokens/s, learning rate: 6.640e-06, loss_scalings: 13421.773438, pp_loss: 8.673192
[INFO] 2021-07-12 18:42:56,360 [run_pretraining.py:  512]:	********exe.run_665******* 
[INFO] 2021-07-12 18:43:19,349 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:19,350 [run_pretraining.py:  534]:	loss/total_loss, 8.625236511230469, 666
[INFO] 2021-07-12 18:43:19,350 [run_pretraining.py:  535]:	loss/mlm_loss, 8.625236511230469, 666
[INFO] 2021-07-12 18:43:19,350 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.649999704677612e-06, 666
[INFO] 2021-07-12 18:43:19,350 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 666
[INFO] 2021-07-12 18:43:19,350 [run_pretraining.py:  558]:	worker_index: 2, step: 666, cost: 8.625237, mlm loss: 8.625237, speed: 0.043497 steps/s, speed: 0.347976 samples/s, speed: 178.163675 tokens/s, learning rate: 6.650e-06, loss_scalings: 13421.773438, pp_loss: 8.415747
[INFO] 2021-07-12 18:43:19,350 [run_pretraining.py:  512]:	********exe.run_666******* 
[INFO] 2021-07-12 18:43:20,307 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:20,307 [run_pretraining.py:  534]:	loss/total_loss, 8.61075210571289, 667
[INFO] 2021-07-12 18:43:20,308 [run_pretraining.py:  535]:	loss/mlm_loss, 8.61075210571289, 667
[INFO] 2021-07-12 18:43:20,308 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.660000053670956e-06, 667
[INFO] 2021-07-12 18:43:20,308 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 667
[INFO] 2021-07-12 18:43:20,308 [run_pretraining.py:  558]:	worker_index: 2, step: 667, cost: 8.610752, mlm loss: 8.610752, speed: 1.045123 steps/s, speed: 8.360983 samples/s, speed: 4280.823455 tokens/s, learning rate: 6.660e-06, loss_scalings: 13421.773438, pp_loss: 8.843377
[INFO] 2021-07-12 18:43:20,308 [run_pretraining.py:  512]:	********exe.run_667******* 
[INFO] 2021-07-12 18:43:21,249 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:21,250 [run_pretraining.py:  534]:	loss/total_loss, 8.971031188964844, 668
[INFO] 2021-07-12 18:43:21,250 [run_pretraining.py:  535]:	loss/mlm_loss, 8.971031188964844, 668
[INFO] 2021-07-12 18:43:21,250 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.669999493169598e-06, 668
[INFO] 2021-07-12 18:43:21,250 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 668
[INFO] 2021-07-12 18:43:21,250 [run_pretraining.py:  558]:	worker_index: 2, step: 668, cost: 8.971031, mlm loss: 8.971031, speed: 1.061955 steps/s, speed: 8.495638 samples/s, speed: 4349.766745 tokens/s, learning rate: 6.670e-06, loss_scalings: 13421.773438, pp_loss: 8.708565
[INFO] 2021-07-12 18:43:21,250 [run_pretraining.py:  512]:	********exe.run_668******* 
[INFO] 2021-07-12 18:43:22,190 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:22,191 [run_pretraining.py:  534]:	loss/total_loss, 8.559431076049805, 669
[INFO] 2021-07-12 18:43:22,191 [run_pretraining.py:  535]:	loss/mlm_loss, 8.559431076049805, 669
[INFO] 2021-07-12 18:43:22,191 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.6799998421629425e-06, 669
[INFO] 2021-07-12 18:43:22,191 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 669
[INFO] 2021-07-12 18:43:22,191 [run_pretraining.py:  558]:	worker_index: 2, step: 669, cost: 8.559431, mlm loss: 8.559431, speed: 1.063194 steps/s, speed: 8.505549 samples/s, speed: 4354.840915 tokens/s, learning rate: 6.680e-06, loss_scalings: 13421.773438, pp_loss: 8.602601
[INFO] 2021-07-12 18:43:22,191 [run_pretraining.py:  512]:	********exe.run_669******* 
[INFO] 2021-07-12 18:43:23,255 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:23,255 [run_pretraining.py:  534]:	loss/total_loss, 8.499443054199219, 670
[INFO] 2021-07-12 18:43:23,255 [run_pretraining.py:  535]:	loss/mlm_loss, 8.499443054199219, 670
[INFO] 2021-07-12 18:43:23,255 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.689999736408936e-06, 670
[INFO] 2021-07-12 18:43:23,255 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 670
[INFO] 2021-07-12 18:43:23,255 [run_pretraining.py:  558]:	worker_index: 2, step: 670, cost: 8.499443, mlm loss: 8.499443, speed: 0.940181 steps/s, speed: 7.521449 samples/s, speed: 3850.981825 tokens/s, learning rate: 6.690e-06, loss_scalings: 13421.773438, pp_loss: 8.524633
[INFO] 2021-07-12 18:43:23,255 [run_pretraining.py:  512]:	********exe.run_670******* 
[INFO] 2021-07-12 18:43:49,165 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:49,165 [run_pretraining.py:  534]:	loss/total_loss, 7.075537204742432, 671
[INFO] 2021-07-12 18:43:49,165 [run_pretraining.py:  535]:	loss/mlm_loss, 7.075537204742432, 671
[INFO] 2021-07-12 18:43:49,166 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.70000008540228e-06, 671
[INFO] 2021-07-12 18:43:49,166 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 671
[INFO] 2021-07-12 18:43:49,166 [run_pretraining.py:  558]:	worker_index: 2, step: 671, cost: 7.075537, mlm loss: 7.075537, speed: 0.038596 steps/s, speed: 0.308765 samples/s, speed: 158.087646 tokens/s, learning rate: 6.700e-06, loss_scalings: 13421.773438, pp_loss: 8.111284
[INFO] 2021-07-12 18:43:49,166 [run_pretraining.py:  512]:	********exe.run_671******* 
[INFO] 2021-07-12 18:43:50,202 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:50,202 [run_pretraining.py:  534]:	loss/total_loss, 8.140292167663574, 672
[INFO] 2021-07-12 18:43:50,203 [run_pretraining.py:  535]:	loss/mlm_loss, 8.140292167663574, 672
[INFO] 2021-07-12 18:43:50,203 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.7099999796482734e-06, 672
[INFO] 2021-07-12 18:43:50,203 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 672
[INFO] 2021-07-12 18:43:50,203 [run_pretraining.py:  558]:	worker_index: 2, step: 672, cost: 8.140292, mlm loss: 8.140292, speed: 0.964806 steps/s, speed: 7.718448 samples/s, speed: 3951.845359 tokens/s, learning rate: 6.710e-06, loss_scalings: 13421.773438, pp_loss: 8.216464
[INFO] 2021-07-12 18:43:50,203 [run_pretraining.py:  512]:	********exe.run_672******* 
[INFO] 2021-07-12 18:43:51,244 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:51,245 [run_pretraining.py:  534]:	loss/total_loss, 8.858753204345703, 673
[INFO] 2021-07-12 18:43:51,245 [run_pretraining.py:  535]:	loss/mlm_loss, 8.858753204345703, 673
[INFO] 2021-07-12 18:43:51,245 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.719999419146916e-06, 673
[INFO] 2021-07-12 18:43:51,245 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 673
[INFO] 2021-07-12 18:43:51,245 [run_pretraining.py:  558]:	worker_index: 2, step: 673, cost: 8.858753, mlm loss: 8.858753, speed: 0.959864 steps/s, speed: 7.678911 samples/s, speed: 3931.602679 tokens/s, learning rate: 6.720e-06, loss_scalings: 13421.773438, pp_loss: 8.653841
[INFO] 2021-07-12 18:43:51,245 [run_pretraining.py:  512]:	********exe.run_673******* 
[INFO] 2021-07-12 18:43:52,339 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:52,340 [run_pretraining.py:  534]:	loss/total_loss, 8.713199615478516, 674
[INFO] 2021-07-12 18:43:52,340 [run_pretraining.py:  535]:	loss/mlm_loss, 8.713199615478516, 674
[INFO] 2021-07-12 18:43:52,340 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.72999976814026e-06, 674
[INFO] 2021-07-12 18:43:52,340 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 674
[INFO] 2021-07-12 18:43:52,340 [run_pretraining.py:  558]:	worker_index: 2, step: 674, cost: 8.713200, mlm loss: 8.713200, speed: 0.913756 steps/s, speed: 7.310046 samples/s, speed: 3742.743300 tokens/s, learning rate: 6.730e-06, loss_scalings: 13421.773438, pp_loss: 8.527016
[INFO] 2021-07-12 18:43:52,340 [run_pretraining.py:  512]:	********exe.run_674******* 
[INFO] 2021-07-12 18:43:53,375 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:53,375 [run_pretraining.py:  534]:	loss/total_loss, 8.564120292663574, 675
[INFO] 2021-07-12 18:43:53,375 [run_pretraining.py:  535]:	loss/mlm_loss, 8.564120292663574, 675
[INFO] 2021-07-12 18:43:53,375 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.740000117133604e-06, 675
[INFO] 2021-07-12 18:43:53,375 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 675
[INFO] 2021-07-12 18:43:53,376 [run_pretraining.py:  558]:	worker_index: 2, step: 675, cost: 8.564120, mlm loss: 8.564120, speed: 0.966372 steps/s, speed: 7.730975 samples/s, speed: 3958.258985 tokens/s, learning rate: 6.740e-06, loss_scalings: 13421.773438, pp_loss: 8.467553
[INFO] 2021-07-12 18:43:53,376 [run_pretraining.py:  512]:	********exe.run_675******* 
[INFO] 2021-07-12 18:43:54,421 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:54,422 [run_pretraining.py:  534]:	loss/total_loss, 8.424903869628906, 676
[INFO] 2021-07-12 18:43:54,422 [run_pretraining.py:  535]:	loss/mlm_loss, 8.424903869628906, 676
[INFO] 2021-07-12 18:43:54,422 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.750000011379598e-06, 676
[INFO] 2021-07-12 18:43:54,422 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 676
[INFO] 2021-07-12 18:43:54,422 [run_pretraining.py:  558]:	worker_index: 2, step: 676, cost: 8.424904, mlm loss: 8.424904, speed: 0.956054 steps/s, speed: 7.648431 samples/s, speed: 3915.996714 tokens/s, learning rate: 6.750e-06, loss_scalings: 13421.773438, pp_loss: 8.374193
[INFO] 2021-07-12 18:43:54,422 [run_pretraining.py:  512]:	********exe.run_676******* 
[INFO] 2021-07-12 18:43:55,356 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:55,356 [run_pretraining.py:  534]:	loss/total_loss, 8.70892333984375, 677
[INFO] 2021-07-12 18:43:55,356 [run_pretraining.py:  535]:	loss/mlm_loss, 8.70892333984375, 677
[INFO] 2021-07-12 18:43:55,356 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.75999945087824e-06, 677
[INFO] 2021-07-12 18:43:55,356 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 677
[INFO] 2021-07-12 18:43:55,356 [run_pretraining.py:  558]:	worker_index: 2, step: 677, cost: 8.708923, mlm loss: 8.708923, speed: 1.071055 steps/s, speed: 8.568440 samples/s, speed: 4387.041425 tokens/s, learning rate: 6.760e-06, loss_scalings: 13421.773438, pp_loss: 8.601337
[INFO] 2021-07-12 18:43:55,356 [run_pretraining.py:  512]:	********exe.run_677******* 
[INFO] 2021-07-12 18:43:56,278 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:56,278 [run_pretraining.py:  534]:	loss/total_loss, 8.470298767089844, 678
[INFO] 2021-07-12 18:43:56,278 [run_pretraining.py:  535]:	loss/mlm_loss, 8.470298767089844, 678
[INFO] 2021-07-12 18:43:56,279 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.769999799871584e-06, 678
[INFO] 2021-07-12 18:43:56,279 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 678
[INFO] 2021-07-12 18:43:56,279 [run_pretraining.py:  558]:	worker_index: 2, step: 678, cost: 8.470299, mlm loss: 8.470299, speed: 1.084999 steps/s, speed: 8.679995 samples/s, speed: 4444.157669 tokens/s, learning rate: 6.770e-06, loss_scalings: 13421.773438, pp_loss: 8.436224
[INFO] 2021-07-12 18:43:56,279 [run_pretraining.py:  512]:	********exe.run_678******* 
[INFO] 2021-07-12 18:43:57,201 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:57,202 [run_pretraining.py:  534]:	loss/total_loss, 8.728042602539062, 679
[INFO] 2021-07-12 18:43:57,202 [run_pretraining.py:  535]:	loss/mlm_loss, 8.728042602539062, 679
[INFO] 2021-07-12 18:43:57,202 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.779999694117578e-06, 679
[INFO] 2021-07-12 18:43:57,202 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 679
[INFO] 2021-07-12 18:43:57,202 [run_pretraining.py:  558]:	worker_index: 2, step: 679, cost: 8.728043, mlm loss: 8.728043, speed: 1.083685 steps/s, speed: 8.669477 samples/s, speed: 4438.772426 tokens/s, learning rate: 6.780e-06, loss_scalings: 13421.773438, pp_loss: 8.565470
[INFO] 2021-07-12 18:43:57,202 [run_pretraining.py:  512]:	********exe.run_679******* 
[INFO] 2021-07-12 18:43:58,121 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:58,121 [run_pretraining.py:  534]:	loss/total_loss, 8.697639465332031, 680
[INFO] 2021-07-12 18:43:58,122 [run_pretraining.py:  535]:	loss/mlm_loss, 8.697639465332031, 680
[INFO] 2021-07-12 18:43:58,122 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.790000043110922e-06, 680
[INFO] 2021-07-12 18:43:58,122 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 680
[INFO] 2021-07-12 18:43:58,122 [run_pretraining.py:  558]:	worker_index: 2, step: 680, cost: 8.697639, mlm loss: 8.697639, speed: 1.087954 steps/s, speed: 8.703629 samples/s, speed: 4456.258220 tokens/s, learning rate: 6.790e-06, loss_scalings: 13421.773438, pp_loss: 7.555996
[INFO] 2021-07-12 18:43:58,122 [run_pretraining.py:  512]:	********exe.run_680******* 
[INFO] 2021-07-12 18:43:59,042 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:59,043 [run_pretraining.py:  534]:	loss/total_loss, 8.097063064575195, 681
[INFO] 2021-07-12 18:43:59,043 [run_pretraining.py:  535]:	loss/mlm_loss, 8.097063064575195, 681
[INFO] 2021-07-12 18:43:59,043 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.800000392104266e-06, 681
[INFO] 2021-07-12 18:43:59,043 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 681
[INFO] 2021-07-12 18:43:59,043 [run_pretraining.py:  558]:	worker_index: 2, step: 681, cost: 8.097063, mlm loss: 8.097063, speed: 1.086176 steps/s, speed: 8.689405 samples/s, speed: 4448.975248 tokens/s, learning rate: 6.800e-06, loss_scalings: 13421.773438, pp_loss: 8.297756
[INFO] 2021-07-12 18:43:59,043 [run_pretraining.py:  512]:	********exe.run_681******* 
[INFO] 2021-07-12 18:43:59,962 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:59,963 [run_pretraining.py:  534]:	loss/total_loss, 8.531325340270996, 682
[INFO] 2021-07-12 18:43:59,963 [run_pretraining.py:  535]:	loss/mlm_loss, 8.531325340270996, 682
[INFO] 2021-07-12 18:43:59,963 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.809999831602909e-06, 682
[INFO] 2021-07-12 18:43:59,963 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 682
[INFO] 2021-07-12 18:43:59,963 [run_pretraining.py:  558]:	worker_index: 2, step: 682, cost: 8.531325, mlm loss: 8.531325, speed: 1.087844 steps/s, speed: 8.702756 samples/s, speed: 4455.810931 tokens/s, learning rate: 6.810e-06, loss_scalings: 13421.773438, pp_loss: 8.457735
[INFO] 2021-07-12 18:43:59,963 [run_pretraining.py:  512]:	********exe.run_682******* 
[INFO] 2021-07-12 18:44:00,881 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:00,881 [run_pretraining.py:  534]:	loss/total_loss, 8.80966567993164, 683
[INFO] 2021-07-12 18:44:00,881 [run_pretraining.py:  535]:	loss/mlm_loss, 8.80966567993164, 683
[INFO] 2021-07-12 18:44:00,882 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.819999725848902e-06, 683
[INFO] 2021-07-12 18:44:00,882 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 683
[INFO] 2021-07-12 18:44:00,882 [run_pretraining.py:  558]:	worker_index: 2, step: 683, cost: 8.809666, mlm loss: 8.809666, speed: 1.089118 steps/s, speed: 8.712947 samples/s, speed: 4461.029104 tokens/s, learning rate: 6.820e-06, loss_scalings: 13421.773438, pp_loss: 8.622124
[INFO] 2021-07-12 18:44:00,882 [run_pretraining.py:  512]:	********exe.run_683******* 
[INFO] 2021-07-12 18:44:01,812 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:01,812 [run_pretraining.py:  534]:	loss/total_loss, 7.879129409790039, 684
[INFO] 2021-07-12 18:44:01,812 [run_pretraining.py:  535]:	loss/mlm_loss, 7.879129409790039, 684
[INFO] 2021-07-12 18:44:01,812 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.830000074842246e-06, 684
[INFO] 2021-07-12 18:44:01,812 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 684
[INFO] 2021-07-12 18:44:01,813 [run_pretraining.py:  558]:	worker_index: 2, step: 684, cost: 7.879129, mlm loss: 7.879129, speed: 1.075000 steps/s, speed: 8.599998 samples/s, speed: 4403.199029 tokens/s, learning rate: 6.830e-06, loss_scalings: 13421.773438, pp_loss: 7.761263
[INFO] 2021-07-12 18:44:01,813 [run_pretraining.py:  512]:	********exe.run_684******* 
[INFO] 2021-07-12 18:44:02,738 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:02,739 [run_pretraining.py:  534]:	loss/total_loss, 8.28856086730957, 685
[INFO] 2021-07-12 18:44:02,739 [run_pretraining.py:  535]:	loss/mlm_loss, 8.28856086730957, 685
[INFO] 2021-07-12 18:44:02,739 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.83999996908824e-06, 685
[INFO] 2021-07-12 18:44:02,739 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 685
[INFO] 2021-07-12 18:44:02,739 [run_pretraining.py:  558]:	worker_index: 2, step: 685, cost: 8.288561, mlm loss: 8.288561, speed: 1.080076 steps/s, speed: 8.640607 samples/s, speed: 4423.990775 tokens/s, learning rate: 6.840e-06, loss_scalings: 13421.773438, pp_loss: 8.412622
[INFO] 2021-07-12 18:44:02,739 [run_pretraining.py:  512]:	********exe.run_685******* 
[INFO] 2021-07-12 18:44:03,668 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:03,669 [run_pretraining.py:  534]:	loss/total_loss, 8.771918296813965, 686
[INFO] 2021-07-12 18:44:03,669 [run_pretraining.py:  535]:	loss/mlm_loss, 8.771918296813965, 686
[INFO] 2021-07-12 18:44:03,669 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.849999408586882e-06, 686
[INFO] 2021-07-12 18:44:03,669 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 686
[INFO] 2021-07-12 18:44:03,669 [run_pretraining.py:  558]:	worker_index: 2, step: 686, cost: 8.771918, mlm loss: 8.771918, speed: 1.076002 steps/s, speed: 8.608016 samples/s, speed: 4407.303965 tokens/s, learning rate: 6.850e-06, loss_scalings: 13421.773438, pp_loss: 8.689850
[INFO] 2021-07-12 18:44:03,669 [run_pretraining.py:  512]:	********exe.run_686******* 
[INFO] 2021-07-12 18:44:04,591 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:04,591 [run_pretraining.py:  534]:	loss/total_loss, 8.306159973144531, 687
[INFO] 2021-07-12 18:44:04,592 [run_pretraining.py:  535]:	loss/mlm_loss, 8.306159973144531, 687
[INFO] 2021-07-12 18:44:04,592 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.859999757580226e-06, 687
[INFO] 2021-07-12 18:44:04,592 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 687
[INFO] 2021-07-12 18:44:04,592 [run_pretraining.py:  558]:	worker_index: 2, step: 687, cost: 8.306160, mlm loss: 8.306160, speed: 1.084350 steps/s, speed: 8.674796 samples/s, speed: 4441.495566 tokens/s, learning rate: 6.860e-06, loss_scalings: 13421.773438, pp_loss: 8.492073
[INFO] 2021-07-12 18:44:04,592 [run_pretraining.py:  512]:	********exe.run_687******* 
[INFO] 2021-07-12 18:44:05,509 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:05,510 [run_pretraining.py:  534]:	loss/total_loss, 8.696388244628906, 688
[INFO] 2021-07-12 18:44:05,510 [run_pretraining.py:  535]:	loss/mlm_loss, 8.696388244628906, 688
[INFO] 2021-07-12 18:44:05,510 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.8700001065735705e-06, 688
[INFO] 2021-07-12 18:44:05,510 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 688
[INFO] 2021-07-12 18:44:05,510 [run_pretraining.py:  558]:	worker_index: 2, step: 688, cost: 8.696388, mlm loss: 8.696388, speed: 1.089958 steps/s, speed: 8.719661 samples/s, speed: 4464.466341 tokens/s, learning rate: 6.870e-06, loss_scalings: 13421.773438, pp_loss: 8.595576
[INFO] 2021-07-12 18:44:05,510 [run_pretraining.py:  512]:	********exe.run_688******* 
[INFO] 2021-07-12 18:44:06,430 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:06,431 [run_pretraining.py:  534]:	loss/total_loss, 9.111295700073242, 689
[INFO] 2021-07-12 18:44:06,431 [run_pretraining.py:  535]:	loss/mlm_loss, 9.111295700073242, 689
[INFO] 2021-07-12 18:44:06,431 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.880000000819564e-06, 689
[INFO] 2021-07-12 18:44:06,431 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 689
[INFO] 2021-07-12 18:44:06,431 [run_pretraining.py:  558]:	worker_index: 2, step: 689, cost: 9.111296, mlm loss: 9.111296, speed: 1.086505 steps/s, speed: 8.692038 samples/s, speed: 4450.323644 tokens/s, learning rate: 6.880e-06, loss_scalings: 13421.773438, pp_loss: 8.469105
[INFO] 2021-07-12 18:44:06,431 [run_pretraining.py:  512]:	********exe.run_689******* 
[INFO] 2021-07-12 18:44:07,353 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:07,354 [run_pretraining.py:  534]:	loss/total_loss, 8.196174621582031, 690
[INFO] 2021-07-12 18:44:07,354 [run_pretraining.py:  535]:	loss/mlm_loss, 8.196174621582031, 690
[INFO] 2021-07-12 18:44:07,354 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.889999440318206e-06, 690
[INFO] 2021-07-12 18:44:07,354 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 690
[INFO] 2021-07-12 18:44:07,354 [run_pretraining.py:  558]:	worker_index: 2, step: 690, cost: 8.196175, mlm loss: 8.196175, speed: 1.084134 steps/s, speed: 8.673074 samples/s, speed: 4440.613881 tokens/s, learning rate: 6.890e-06, loss_scalings: 13421.773438, pp_loss: 8.503937
[INFO] 2021-07-12 18:44:07,354 [run_pretraining.py:  512]:	********exe.run_690******* 
[INFO] 2021-07-12 18:44:08,274 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:08,275 [run_pretraining.py:  534]:	loss/total_loss, 8.153913497924805, 691
[INFO] 2021-07-12 18:44:08,275 [run_pretraining.py:  535]:	loss/mlm_loss, 8.153913497924805, 691
[INFO] 2021-07-12 18:44:08,275 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.8999997893115506e-06, 691
[INFO] 2021-07-12 18:44:08,275 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 691
[INFO] 2021-07-12 18:44:08,275 [run_pretraining.py:  558]:	worker_index: 2, step: 691, cost: 8.153913, mlm loss: 8.153913, speed: 1.086352 steps/s, speed: 8.690816 samples/s, speed: 4449.697748 tokens/s, learning rate: 6.900e-06, loss_scalings: 13421.773438, pp_loss: 7.536924
[INFO] 2021-07-12 18:44:08,275 [run_pretraining.py:  512]:	********exe.run_691******* 
[INFO] 2021-07-12 18:44:09,211 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:09,212 [run_pretraining.py:  534]:	loss/total_loss, 8.849234580993652, 692
[INFO] 2021-07-12 18:44:09,212 [run_pretraining.py:  535]:	loss/mlm_loss, 8.849234580993652, 692
[INFO] 2021-07-12 18:44:09,212 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.909999683557544e-06, 692
[INFO] 2021-07-12 18:44:09,212 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 692
[INFO] 2021-07-12 18:44:09,212 [run_pretraining.py:  558]:	worker_index: 2, step: 692, cost: 8.849235, mlm loss: 8.849235, speed: 1.067819 steps/s, speed: 8.542556 samples/s, speed: 4373.788431 tokens/s, learning rate: 6.910e-06, loss_scalings: 13421.773438, pp_loss: 8.503026
[INFO] 2021-07-12 18:44:09,212 [run_pretraining.py:  512]:	********exe.run_692******* 
[INFO] 2021-07-12 18:44:10,134 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:10,134 [run_pretraining.py:  534]:	loss/total_loss, 8.514495849609375, 693
[INFO] 2021-07-12 18:44:10,134 [run_pretraining.py:  535]:	loss/mlm_loss, 8.514495849609375, 693
[INFO] 2021-07-12 18:44:10,134 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.920000032550888e-06, 693
[INFO] 2021-07-12 18:44:10,134 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 693
[INFO] 2021-07-12 18:44:10,134 [run_pretraining.py:  558]:	worker_index: 2, step: 693, cost: 8.514496, mlm loss: 8.514496, speed: 1.084940 steps/s, speed: 8.679522 samples/s, speed: 4443.915110 tokens/s, learning rate: 6.920e-06, loss_scalings: 13421.773438, pp_loss: 8.485985
[INFO] 2021-07-12 18:44:10,134 [run_pretraining.py:  512]:	********exe.run_693******* 
[INFO] 2021-07-12 18:44:11,047 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:11,048 [run_pretraining.py:  534]:	loss/total_loss, 8.431291580200195, 694
[INFO] 2021-07-12 18:44:11,048 [run_pretraining.py:  535]:	loss/mlm_loss, 8.431291580200195, 694
[INFO] 2021-07-12 18:44:11,048 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.930000381544232e-06, 694
[INFO] 2021-07-12 18:44:11,048 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 694
[INFO] 2021-07-12 18:44:11,048 [run_pretraining.py:  558]:	worker_index: 2, step: 694, cost: 8.431292, mlm loss: 8.431292, speed: 1.095168 steps/s, speed: 8.761342 samples/s, speed: 4485.806982 tokens/s, learning rate: 6.930e-06, loss_scalings: 13421.773438, pp_loss: 8.382607
[INFO] 2021-07-12 18:44:11,048 [run_pretraining.py:  512]:	********exe.run_694******* 
[INFO] 2021-07-12 18:44:11,962 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:11,962 [run_pretraining.py:  534]:	loss/total_loss, 7.958667755126953, 695
[INFO] 2021-07-12 18:44:11,963 [run_pretraining.py:  535]:	loss/mlm_loss, 7.958667755126953, 695
[INFO] 2021-07-12 18:44:11,963 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.939999366295524e-06, 695
[INFO] 2021-07-12 18:44:11,963 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 695
[INFO] 2021-07-12 18:44:11,963 [run_pretraining.py:  558]:	worker_index: 2, step: 695, cost: 7.958668, mlm loss: 7.958668, speed: 1.093980 steps/s, speed: 8.751838 samples/s, speed: 4480.940907 tokens/s, learning rate: 6.940e-06, loss_scalings: 13421.773438, pp_loss: 8.367175
[INFO] 2021-07-12 18:44:11,963 [run_pretraining.py:  512]:	********exe.run_695******* 
[INFO] 2021-07-12 18:44:12,875 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:12,875 [run_pretraining.py:  534]:	loss/total_loss, 7.933520317077637, 696
[INFO] 2021-07-12 18:44:12,875 [run_pretraining.py:  535]:	loss/mlm_loss, 7.933520317077637, 696
[INFO] 2021-07-12 18:44:12,876 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.949999715288868e-06, 696
[INFO] 2021-07-12 18:44:12,876 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 696
[INFO] 2021-07-12 18:44:12,876 [run_pretraining.py:  558]:	worker_index: 2, step: 696, cost: 7.933520, mlm loss: 7.933520, speed: 1.096236 steps/s, speed: 8.769890 samples/s, speed: 4490.183643 tokens/s, learning rate: 6.950e-06, loss_scalings: 13421.773438, pp_loss: 8.476543
[INFO] 2021-07-12 18:44:12,876 [run_pretraining.py:  512]:	********exe.run_696******* 
[INFO] 2021-07-12 18:44:13,790 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:13,790 [run_pretraining.py:  534]:	loss/total_loss, 8.072509765625, 697
[INFO] 2021-07-12 18:44:13,790 [run_pretraining.py:  535]:	loss/mlm_loss, 8.072509765625, 697
[INFO] 2021-07-12 18:44:13,790 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.960000064282212e-06, 697
[INFO] 2021-07-12 18:44:13,790 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 697
[INFO] 2021-07-12 18:44:13,791 [run_pretraining.py:  558]:	worker_index: 2, step: 697, cost: 8.072510, mlm loss: 8.072510, speed: 1.093796 steps/s, speed: 8.750366 samples/s, speed: 4480.187195 tokens/s, learning rate: 6.960e-06, loss_scalings: 13421.773438, pp_loss: 8.608537
[INFO] 2021-07-12 18:44:13,791 [run_pretraining.py:  512]:	********exe.run_697******* 
[INFO] 2021-07-12 18:44:14,704 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:14,704 [run_pretraining.py:  534]:	loss/total_loss, 8.565572738647461, 698
[INFO] 2021-07-12 18:44:14,704 [run_pretraining.py:  535]:	loss/mlm_loss, 8.565572738647461, 698
[INFO] 2021-07-12 18:44:14,704 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.969999958528206e-06, 698
[INFO] 2021-07-12 18:44:14,704 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 698
[INFO] 2021-07-12 18:44:14,704 [run_pretraining.py:  558]:	worker_index: 2, step: 698, cost: 8.565573, mlm loss: 8.565573, speed: 1.094978 steps/s, speed: 8.759828 samples/s, speed: 4485.031728 tokens/s, learning rate: 6.970e-06, loss_scalings: 13421.773438, pp_loss: 8.462246
[INFO] 2021-07-12 18:44:14,704 [run_pretraining.py:  512]:	********exe.run_698******* 
[INFO] 2021-07-12 18:44:15,614 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:15,615 [run_pretraining.py:  534]:	loss/total_loss, 8.47235107421875, 699
[INFO] 2021-07-12 18:44:15,615 [run_pretraining.py:  535]:	loss/mlm_loss, 8.47235107421875, 699
[INFO] 2021-07-12 18:44:15,615 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.979999398026848e-06, 699
[INFO] 2021-07-12 18:44:15,615 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 699
[INFO] 2021-07-12 18:44:15,615 [run_pretraining.py:  558]:	worker_index: 2, step: 699, cost: 8.472351, mlm loss: 8.472351, speed: 1.098560 steps/s, speed: 8.788482 samples/s, speed: 4499.702641 tokens/s, learning rate: 6.980e-06, loss_scalings: 13421.773438, pp_loss: 8.514764
[INFO] 2021-07-12 18:44:15,615 [run_pretraining.py:  512]:	********exe.run_699******* 
[INFO] 2021-07-12 18:44:16,554 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:16,555 [run_pretraining.py:  534]:	loss/total_loss, 8.614492416381836, 700
[INFO] 2021-07-12 18:44:16,555 [run_pretraining.py:  535]:	loss/mlm_loss, 8.614492416381836, 700
[INFO] 2021-07-12 18:44:16,555 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.9899997470201924e-06, 700
[INFO] 2021-07-12 18:44:16,555 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 700
[INFO] 2021-07-12 18:44:16,555 [run_pretraining.py:  558]:	worker_index: 2, step: 700, cost: 8.614492, mlm loss: 8.614492, speed: 1.064406 steps/s, speed: 8.515247 samples/s, speed: 4359.806336 tokens/s, learning rate: 6.990e-06, loss_scalings: 13421.773438, pp_loss: 8.592575
[INFO] 2021-07-12 18:44:16,555 [run_pretraining.py:  512]:	********exe.run_700******* 
[INFO] 2021-07-12 18:44:17,469 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:17,469 [run_pretraining.py:  534]:	loss/total_loss, 8.788747787475586, 701
[INFO] 2021-07-12 18:44:17,469 [run_pretraining.py:  535]:	loss/mlm_loss, 8.788747787475586, 701
[INFO] 2021-07-12 18:44:17,469 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.999999641266186e-06, 701
[INFO] 2021-07-12 18:44:17,470 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 701
[INFO] 2021-07-12 18:44:17,470 [run_pretraining.py:  558]:	worker_index: 2, step: 701, cost: 8.788748, mlm loss: 8.788748, speed: 1.094512 steps/s, speed: 8.756092 samples/s, speed: 4483.119331 tokens/s, learning rate: 7.000e-06, loss_scalings: 13421.773438, pp_loss: 8.154615
[INFO] 2021-07-12 18:44:17,470 [run_pretraining.py:  512]:	********exe.run_701******* 
[INFO] 2021-07-12 18:44:18,377 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:18,378 [run_pretraining.py:  534]:	loss/total_loss, 7.850280284881592, 702
[INFO] 2021-07-12 18:44:18,378 [run_pretraining.py:  535]:	loss/mlm_loss, 7.850280284881592, 702
[INFO] 2021-07-12 18:44:18,378 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.00999999025953e-06, 702
[INFO] 2021-07-12 18:44:18,378 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 702
[INFO] 2021-07-12 18:44:18,378 [run_pretraining.py:  558]:	worker_index: 2, step: 702, cost: 7.850280, mlm loss: 7.850280, speed: 1.101235 steps/s, speed: 8.809879 samples/s, speed: 4510.657937 tokens/s, learning rate: 7.010e-06, loss_scalings: 13421.773438, pp_loss: 8.355981
[INFO] 2021-07-12 18:44:18,378 [run_pretraining.py:  512]:	********exe.run_702******* 
[INFO] 2021-07-12 18:44:19,292 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:19,293 [run_pretraining.py:  534]:	loss/total_loss, 8.270753860473633, 703
[INFO] 2021-07-12 18:44:19,293 [run_pretraining.py:  535]:	loss/mlm_loss, 8.270753860473633, 703
[INFO] 2021-07-12 18:44:19,293 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.020000339252874e-06, 703
[INFO] 2021-07-12 18:44:19,293 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 703
[INFO] 2021-07-12 18:44:19,293 [run_pretraining.py:  558]:	worker_index: 2, step: 703, cost: 8.270754, mlm loss: 8.270754, speed: 1.093622 steps/s, speed: 8.748978 samples/s, speed: 4479.476952 tokens/s, learning rate: 7.020e-06, loss_scalings: 13421.773438, pp_loss: 8.240213
[INFO] 2021-07-12 18:44:19,293 [run_pretraining.py:  512]:	********exe.run_703******* 
[INFO] 2021-07-12 18:44:20,210 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:20,210 [run_pretraining.py:  534]:	loss/total_loss, 8.376806259155273, 704
[INFO] 2021-07-12 18:44:20,211 [run_pretraining.py:  535]:	loss/mlm_loss, 8.376806259155273, 704
[INFO] 2021-07-12 18:44:20,211 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.029999778751517e-06, 704
[INFO] 2021-07-12 18:44:20,211 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 704
[INFO] 2021-07-12 18:44:20,211 [run_pretraining.py:  558]:	worker_index: 2, step: 704, cost: 8.376806, mlm loss: 8.376806, speed: 1.090560 steps/s, speed: 8.724481 samples/s, speed: 4466.934213 tokens/s, learning rate: 7.030e-06, loss_scalings: 13421.773438, pp_loss: 8.380821
[INFO] 2021-07-12 18:44:20,211 [run_pretraining.py:  512]:	********exe.run_704******* 
[INFO] 2021-07-12 18:44:21,127 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:21,128 [run_pretraining.py:  534]:	loss/total_loss, 8.351113319396973, 705
[INFO] 2021-07-12 18:44:21,128 [run_pretraining.py:  535]:	loss/mlm_loss, 8.351113319396973, 705
[INFO] 2021-07-12 18:44:21,128 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.03999967299751e-06, 705
[INFO] 2021-07-12 18:44:21,128 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 705
[INFO] 2021-07-12 18:44:21,128 [run_pretraining.py:  558]:	worker_index: 2, step: 705, cost: 8.351113, mlm loss: 8.351113, speed: 1.090655 steps/s, speed: 8.725243 samples/s, speed: 4467.324493 tokens/s, learning rate: 7.040e-06, loss_scalings: 13421.773438, pp_loss: 8.346042
[INFO] 2021-07-12 18:44:21,128 [run_pretraining.py:  512]:	********exe.run_705******* 
[INFO] 2021-07-12 18:44:22,048 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:22,049 [run_pretraining.py:  534]:	loss/total_loss, 8.110800743103027, 706
[INFO] 2021-07-12 18:44:22,049 [run_pretraining.py:  535]:	loss/mlm_loss, 8.110800743103027, 706
[INFO] 2021-07-12 18:44:22,049 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.050000021990854e-06, 706
[INFO] 2021-07-12 18:44:22,049 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 706
[INFO] 2021-07-12 18:44:22,049 [run_pretraining.py:  558]:	worker_index: 2, step: 706, cost: 8.110801, mlm loss: 8.110801, speed: 1.086567 steps/s, speed: 8.692536 samples/s, speed: 4450.578433 tokens/s, learning rate: 7.050e-06, loss_scalings: 13421.773438, pp_loss: 8.795454
[INFO] 2021-07-12 18:44:22,049 [run_pretraining.py:  512]:	********exe.run_706******* 
[INFO] 2021-07-12 18:44:23,001 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:23,001 [run_pretraining.py:  534]:	loss/total_loss, 8.913108825683594, 707
[INFO] 2021-07-12 18:44:23,001 [run_pretraining.py:  535]:	loss/mlm_loss, 8.913108825683594, 707
[INFO] 2021-07-12 18:44:23,001 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.059999916236848e-06, 707
[INFO] 2021-07-12 18:44:23,001 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 707
[INFO] 2021-07-12 18:44:23,002 [run_pretraining.py:  558]:	worker_index: 2, step: 707, cost: 8.913109, mlm loss: 8.913109, speed: 1.050736 steps/s, speed: 8.405884 samples/s, speed: 4303.812707 tokens/s, learning rate: 7.060e-06, loss_scalings: 13421.773438, pp_loss: 8.549446
[INFO] 2021-07-12 18:44:23,002 [run_pretraining.py:  512]:	********exe.run_707******* 
[INFO] 2021-07-12 18:44:23,936 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:23,936 [run_pretraining.py:  534]:	loss/total_loss, 8.141526222229004, 708
[INFO] 2021-07-12 18:44:23,936 [run_pretraining.py:  535]:	loss/mlm_loss, 8.141526222229004, 708
[INFO] 2021-07-12 18:44:23,936 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.06999935573549e-06, 708
[INFO] 2021-07-12 18:44:23,936 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 708
[INFO] 2021-07-12 18:44:23,936 [run_pretraining.py:  558]:	worker_index: 2, step: 708, cost: 8.141526, mlm loss: 8.141526, speed: 1.070340 steps/s, speed: 8.562718 samples/s, speed: 4384.111630 tokens/s, learning rate: 7.070e-06, loss_scalings: 13421.773438, pp_loss: 8.329363
[INFO] 2021-07-12 18:44:23,936 [run_pretraining.py:  512]:	********exe.run_708******* 
[INFO] 2021-07-12 18:44:24,852 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:24,852 [run_pretraining.py:  534]:	loss/total_loss, 8.449464797973633, 709
[INFO] 2021-07-12 18:44:24,852 [run_pretraining.py:  535]:	loss/mlm_loss, 8.449464797973633, 709
[INFO] 2021-07-12 18:44:24,852 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.079999704728834e-06, 709
[INFO] 2021-07-12 18:44:24,852 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 709
[INFO] 2021-07-12 18:44:24,852 [run_pretraining.py:  558]:	worker_index: 2, step: 709, cost: 8.449465, mlm loss: 8.449465, speed: 1.092369 steps/s, speed: 8.738953 samples/s, speed: 4474.343736 tokens/s, learning rate: 7.080e-06, loss_scalings: 13421.773438, pp_loss: 8.514404
[INFO] 2021-07-12 18:44:24,853 [run_pretraining.py:  512]:	********exe.run_709******* 
[INFO] 2021-07-12 18:44:25,768 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:25,768 [run_pretraining.py:  534]:	loss/total_loss, 8.244119644165039, 710
[INFO] 2021-07-12 18:44:25,768 [run_pretraining.py:  535]:	loss/mlm_loss, 8.244119644165039, 710
[INFO] 2021-07-12 18:44:25,768 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.0900000537221786e-06, 710
[INFO] 2021-07-12 18:44:25,768 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 710
[INFO] 2021-07-12 18:44:25,768 [run_pretraining.py:  558]:	worker_index: 2, step: 710, cost: 8.244120, mlm loss: 8.244120, speed: 1.092498 steps/s, speed: 8.739981 samples/s, speed: 4474.870515 tokens/s, learning rate: 7.090e-06, loss_scalings: 13421.773438, pp_loss: 8.298517
[INFO] 2021-07-12 18:44:25,768 [run_pretraining.py:  512]:	********exe.run_710******* 
[INFO] 2021-07-12 18:44:26,686 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:26,687 [run_pretraining.py:  534]:	loss/total_loss, 8.34824275970459, 711
[INFO] 2021-07-12 18:44:26,687 [run_pretraining.py:  535]:	loss/mlm_loss, 8.34824275970459, 711
[INFO] 2021-07-12 18:44:26,687 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.099999947968172e-06, 711
[INFO] 2021-07-12 18:44:26,687 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 711
[INFO] 2021-07-12 18:44:26,687 [run_pretraining.py:  558]:	worker_index: 2, step: 711, cost: 8.348243, mlm loss: 8.348243, speed: 1.089103 steps/s, speed: 8.712823 samples/s, speed: 4460.965395 tokens/s, learning rate: 7.100e-06, loss_scalings: 13421.773438, pp_loss: 8.473623
[INFO] 2021-07-12 18:44:26,687 [run_pretraining.py:  512]:	********exe.run_711******* 
[INFO] 2021-07-12 18:44:27,607 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:27,608 [run_pretraining.py:  534]:	loss/total_loss, 8.188679695129395, 712
[INFO] 2021-07-12 18:44:27,608 [run_pretraining.py:  535]:	loss/mlm_loss, 8.188679695129395, 712
[INFO] 2021-07-12 18:44:27,608 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.109999387466814e-06, 712
[INFO] 2021-07-12 18:44:27,608 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 712
[INFO] 2021-07-12 18:44:27,608 [run_pretraining.py:  558]:	worker_index: 2, step: 712, cost: 8.188680, mlm loss: 8.188680, speed: 1.086685 steps/s, speed: 8.693482 samples/s, speed: 4451.062728 tokens/s, learning rate: 7.110e-06, loss_scalings: 13421.773438, pp_loss: 8.498862
[INFO] 2021-07-12 18:44:27,608 [run_pretraining.py:  512]:	********exe.run_712******* 
[INFO] 2021-07-12 18:44:28,566 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:28,567 [run_pretraining.py:  534]:	loss/total_loss, 8.674786567687988, 713
[INFO] 2021-07-12 18:44:28,567 [run_pretraining.py:  535]:	loss/mlm_loss, 8.674786567687988, 713
[INFO] 2021-07-12 18:44:28,567 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.119999736460159e-06, 713
[INFO] 2021-07-12 18:44:28,567 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 713
[INFO] 2021-07-12 18:44:28,567 [run_pretraining.py:  558]:	worker_index: 2, step: 713, cost: 8.674787, mlm loss: 8.674787, speed: 1.043350 steps/s, speed: 8.346803 samples/s, speed: 4273.563155 tokens/s, learning rate: 7.120e-06, loss_scalings: 13421.773438, pp_loss: 8.507523
[INFO] 2021-07-12 18:44:28,567 [run_pretraining.py:  512]:	********exe.run_713******* 
[INFO] 2021-07-12 18:44:29,641 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:29,642 [run_pretraining.py:  534]:	loss/total_loss, 8.383383750915527, 714
[INFO] 2021-07-12 18:44:29,642 [run_pretraining.py:  535]:	loss/mlm_loss, 8.383383750915527, 714
[INFO] 2021-07-12 18:44:29,642 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.129999630706152e-06, 714
[INFO] 2021-07-12 18:44:29,642 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 714
[INFO] 2021-07-12 18:44:29,642 [run_pretraining.py:  558]:	worker_index: 2, step: 714, cost: 8.383384, mlm loss: 8.383384, speed: 0.930749 steps/s, speed: 7.445989 samples/s, speed: 3812.346189 tokens/s, learning rate: 7.130e-06, loss_scalings: 13421.773438, pp_loss: 8.381680
[INFO] 2021-07-12 18:44:29,642 [run_pretraining.py:  512]:	********exe.run_714******* 
[INFO] 2021-07-12 18:44:30,715 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:30,715 [run_pretraining.py:  534]:	loss/total_loss, 8.367269515991211, 715
[INFO] 2021-07-12 18:44:30,716 [run_pretraining.py:  535]:	loss/mlm_loss, 8.367269515991211, 715
[INFO] 2021-07-12 18:44:30,716 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.139999979699496e-06, 715
[INFO] 2021-07-12 18:44:30,716 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 715
[INFO] 2021-07-12 18:44:30,716 [run_pretraining.py:  558]:	worker_index: 2, step: 715, cost: 8.367270, mlm loss: 8.367270, speed: 0.931899 steps/s, speed: 7.455192 samples/s, speed: 3817.058244 tokens/s, learning rate: 7.140e-06, loss_scalings: 13421.773438, pp_loss: 8.320950
[INFO] 2021-07-12 18:44:30,716 [run_pretraining.py:  512]:	********exe.run_715******* 
[INFO] 2021-07-12 18:44:31,782 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:31,783 [run_pretraining.py:  534]:	loss/total_loss, 8.756710052490234, 716
[INFO] 2021-07-12 18:44:31,783 [run_pretraining.py:  535]:	loss/mlm_loss, 8.756710052490234, 716
[INFO] 2021-07-12 18:44:31,783 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.15000032869284e-06, 716
[INFO] 2021-07-12 18:44:31,783 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 716
[INFO] 2021-07-12 18:44:31,783 [run_pretraining.py:  558]:	worker_index: 2, step: 716, cost: 8.756710, mlm loss: 8.756710, speed: 0.937599 steps/s, speed: 7.500788 samples/s, speed: 3840.403676 tokens/s, learning rate: 7.150e-06, loss_scalings: 13421.773438, pp_loss: 8.462053
[INFO] 2021-07-12 18:44:31,783 [run_pretraining.py:  512]:	********exe.run_716******* 
[INFO] 2021-07-12 18:44:32,850 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:32,850 [run_pretraining.py:  534]:	loss/total_loss, 8.02527904510498, 717
[INFO] 2021-07-12 18:44:32,850 [run_pretraining.py:  535]:	loss/mlm_loss, 8.02527904510498, 717
[INFO] 2021-07-12 18:44:32,850 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.159999768191483e-06, 717
[INFO] 2021-07-12 18:44:32,850 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 717
[INFO] 2021-07-12 18:44:32,851 [run_pretraining.py:  558]:	worker_index: 2, step: 717, cost: 8.025279, mlm loss: 8.025279, speed: 0.937152 steps/s, speed: 7.497217 samples/s, speed: 3838.575110 tokens/s, learning rate: 7.160e-06, loss_scalings: 13421.773438, pp_loss: 8.512955
[INFO] 2021-07-12 18:44:32,851 [run_pretraining.py:  512]:	********exe.run_717******* 
[INFO] 2021-07-12 18:44:33,918 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:33,919 [run_pretraining.py:  534]:	loss/total_loss, 9.123629570007324, 718
[INFO] 2021-07-12 18:44:33,919 [run_pretraining.py:  535]:	loss/mlm_loss, 9.123629570007324, 718
[INFO] 2021-07-12 18:44:33,919 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.169999662437476e-06, 718
[INFO] 2021-07-12 18:44:33,919 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 718
[INFO] 2021-07-12 18:44:33,919 [run_pretraining.py:  558]:	worker_index: 2, step: 718, cost: 9.123630, mlm loss: 9.123630, speed: 0.936403 steps/s, speed: 7.491221 samples/s, speed: 3835.505393 tokens/s, learning rate: 7.170e-06, loss_scalings: 13421.773438, pp_loss: 8.602857
[INFO] 2021-07-12 18:44:33,919 [run_pretraining.py:  512]:	********exe.run_718******* 
[INFO] 2021-07-12 18:44:34,986 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:34,986 [run_pretraining.py:  534]:	loss/total_loss, 8.836953163146973, 719
[INFO] 2021-07-12 18:44:34,986 [run_pretraining.py:  535]:	loss/mlm_loss, 8.836953163146973, 719
[INFO] 2021-07-12 18:44:34,986 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.1800000114308205e-06, 719
[INFO] 2021-07-12 18:44:34,986 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 719
[INFO] 2021-07-12 18:44:34,987 [run_pretraining.py:  558]:	worker_index: 2, step: 719, cost: 8.836953, mlm loss: 8.836953, speed: 0.937364 steps/s, speed: 7.498916 samples/s, speed: 3839.444985 tokens/s, learning rate: 7.180e-06, loss_scalings: 13421.773438, pp_loss: 8.392929
[INFO] 2021-07-12 18:44:34,987 [run_pretraining.py:  512]:	********exe.run_719******* 
[INFO] 2021-07-12 18:44:36,054 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:36,055 [run_pretraining.py:  534]:	loss/total_loss, 8.356450080871582, 720
[INFO] 2021-07-12 18:44:36,055 [run_pretraining.py:  535]:	loss/mlm_loss, 8.356450080871582, 720
[INFO] 2021-07-12 18:44:36,055 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.189999905676814e-06, 720
[INFO] 2021-07-12 18:44:36,055 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 720
[INFO] 2021-07-12 18:44:36,055 [run_pretraining.py:  558]:	worker_index: 2, step: 720, cost: 8.356450, mlm loss: 8.356450, speed: 0.936472 steps/s, speed: 7.491775 samples/s, speed: 3835.788849 tokens/s, learning rate: 7.190e-06, loss_scalings: 13421.773438, pp_loss: 8.521650
[INFO] 2021-07-12 18:44:36,055 [run_pretraining.py:  512]:	********exe.run_720******* 
[INFO] 2021-07-12 18:44:37,127 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:37,127 [run_pretraining.py:  534]:	loss/total_loss, 8.604515075683594, 721
[INFO] 2021-07-12 18:44:37,128 [run_pretraining.py:  535]:	loss/mlm_loss, 8.604515075683594, 721
[INFO] 2021-07-12 18:44:37,128 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.199999345175456e-06, 721
[INFO] 2021-07-12 18:44:37,128 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 721
[INFO] 2021-07-12 18:44:37,128 [run_pretraining.py:  558]:	worker_index: 2, step: 721, cost: 8.604515, mlm loss: 8.604515, speed: 0.932656 steps/s, speed: 7.461251 samples/s, speed: 3820.160502 tokens/s, learning rate: 7.200e-06, loss_scalings: 13421.773438, pp_loss: 8.414818
[INFO] 2021-07-12 18:44:37,128 [run_pretraining.py:  512]:	********exe.run_721******* 
[INFO] 2021-07-12 18:44:38,210 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:38,210 [run_pretraining.py:  534]:	loss/total_loss, 8.215001106262207, 722
[INFO] 2021-07-12 18:44:38,210 [run_pretraining.py:  535]:	loss/mlm_loss, 8.215001106262207, 722
[INFO] 2021-07-12 18:44:38,210 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.2099996941688005e-06, 722
[INFO] 2021-07-12 18:44:38,211 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 722
[INFO] 2021-07-12 18:44:38,211 [run_pretraining.py:  558]:	worker_index: 2, step: 722, cost: 8.215001, mlm loss: 8.215001, speed: 0.924054 steps/s, speed: 7.392432 samples/s, speed: 3784.924997 tokens/s, learning rate: 7.210e-06, loss_scalings: 13421.773438, pp_loss: 8.286139
[INFO] 2021-07-12 18:44:38,211 [run_pretraining.py:  512]:	********exe.run_722******* 
[INFO] 2021-07-12 18:44:39,323 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:39,324 [run_pretraining.py:  534]:	loss/total_loss, 8.642516136169434, 723
[INFO] 2021-07-12 18:44:39,324 [run_pretraining.py:  535]:	loss/mlm_loss, 8.642516136169434, 723
[INFO] 2021-07-12 18:44:39,324 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.220000043162145e-06, 723
[INFO] 2021-07-12 18:44:39,324 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 723
[INFO] 2021-07-12 18:44:39,324 [run_pretraining.py:  558]:	worker_index: 2, step: 723, cost: 8.642516, mlm loss: 8.642516, speed: 0.898447 steps/s, speed: 7.187575 samples/s, speed: 3680.038400 tokens/s, learning rate: 7.220e-06, loss_scalings: 13421.773438, pp_loss: 8.436193
[INFO] 2021-07-12 18:44:39,324 [run_pretraining.py:  512]:	********exe.run_723******* 
[INFO] 2021-07-12 18:44:40,392 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:40,393 [run_pretraining.py:  534]:	loss/total_loss, 8.263975143432617, 724
[INFO] 2021-07-12 18:44:40,393 [run_pretraining.py:  535]:	loss/mlm_loss, 8.263975143432617, 724
[INFO] 2021-07-12 18:44:40,393 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.229999937408138e-06, 724
[INFO] 2021-07-12 18:44:40,393 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 724
[INFO] 2021-07-12 18:44:40,393 [run_pretraining.py:  558]:	worker_index: 2, step: 724, cost: 8.263975, mlm loss: 8.263975, speed: 0.936269 steps/s, speed: 7.490155 samples/s, speed: 3834.959152 tokens/s, learning rate: 7.230e-06, loss_scalings: 13421.773438, pp_loss: 8.265724
[INFO] 2021-07-12 18:44:40,393 [run_pretraining.py:  512]:	********exe.run_724******* 
[INFO] 2021-07-12 18:44:41,457 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:41,457 [run_pretraining.py:  534]:	loss/total_loss, 8.480589866638184, 725
[INFO] 2021-07-12 18:44:41,457 [run_pretraining.py:  535]:	loss/mlm_loss, 8.480589866638184, 725
[INFO] 2021-07-12 18:44:41,457 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.240000286401482e-06, 725
[INFO] 2021-07-12 18:44:41,457 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 725
[INFO] 2021-07-12 18:44:41,457 [run_pretraining.py:  558]:	worker_index: 2, step: 725, cost: 8.480590, mlm loss: 8.480590, speed: 0.939977 steps/s, speed: 7.519814 samples/s, speed: 3850.144680 tokens/s, learning rate: 7.240e-06, loss_scalings: 13421.773438, pp_loss: 7.678296
[INFO] 2021-07-12 18:44:41,457 [run_pretraining.py:  512]:	********exe.run_725******* 
[INFO] 2021-07-12 18:44:42,517 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:42,518 [run_pretraining.py:  534]:	loss/total_loss, 8.581955909729004, 726
[INFO] 2021-07-12 18:44:42,518 [run_pretraining.py:  535]:	loss/mlm_loss, 8.581955909729004, 726
[INFO] 2021-07-12 18:44:42,518 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.249999725900125e-06, 726
[INFO] 2021-07-12 18:44:42,518 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 726
[INFO] 2021-07-12 18:44:42,518 [run_pretraining.py:  558]:	worker_index: 2, step: 726, cost: 8.581956, mlm loss: 8.581956, speed: 0.943066 steps/s, speed: 7.544526 samples/s, speed: 3862.797511 tokens/s, learning rate: 7.250e-06, loss_scalings: 13421.773438, pp_loss: 8.219683
[INFO] 2021-07-12 18:44:42,518 [run_pretraining.py:  512]:	********exe.run_726******* 
[INFO] 2021-07-12 18:44:43,586 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:43,587 [run_pretraining.py:  534]:	loss/total_loss, 8.170454978942871, 727
[INFO] 2021-07-12 18:44:43,587 [run_pretraining.py:  535]:	loss/mlm_loss, 8.170454978942871, 727
[INFO] 2021-07-12 18:44:43,587 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.259999620146118e-06, 727
[INFO] 2021-07-12 18:44:43,587 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 727
[INFO] 2021-07-12 18:44:43,587 [run_pretraining.py:  558]:	worker_index: 2, step: 727, cost: 8.170455, mlm loss: 8.170455, speed: 0.936168 steps/s, speed: 7.489340 samples/s, speed: 3834.542299 tokens/s, learning rate: 7.260e-06, loss_scalings: 13421.773438, pp_loss: 8.336872
[INFO] 2021-07-12 18:44:43,587 [run_pretraining.py:  512]:	********exe.run_727******* 
[INFO] 2021-07-12 18:44:44,630 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:44,630 [run_pretraining.py:  534]:	loss/total_loss, 8.296443939208984, 728
[INFO] 2021-07-12 18:44:44,630 [run_pretraining.py:  535]:	loss/mlm_loss, 8.296443939208984, 728
[INFO] 2021-07-12 18:44:44,630 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.269999969139462e-06, 728
[INFO] 2021-07-12 18:44:44,631 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 728
[INFO] 2021-07-12 18:44:44,631 [run_pretraining.py:  558]:	worker_index: 2, step: 728, cost: 8.296444, mlm loss: 8.296444, speed: 0.958832 steps/s, speed: 7.670654 samples/s, speed: 3927.374830 tokens/s, learning rate: 7.270e-06, loss_scalings: 13421.773438, pp_loss: 7.535233
[INFO] 2021-07-12 18:44:44,631 [run_pretraining.py:  512]:	********exe.run_728******* 
[INFO] 2021-07-12 18:44:45,687 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:45,688 [run_pretraining.py:  534]:	loss/total_loss, 8.666810035705566, 729
[INFO] 2021-07-12 18:44:45,688 [run_pretraining.py:  535]:	loss/mlm_loss, 8.666810035705566, 729
[INFO] 2021-07-12 18:44:45,688 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.2800003181328066e-06, 729
[INFO] 2021-07-12 18:44:45,688 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 729
[INFO] 2021-07-12 18:44:45,688 [run_pretraining.py:  558]:	worker_index: 2, step: 729, cost: 8.666810, mlm loss: 8.666810, speed: 0.946040 steps/s, speed: 7.568316 samples/s, speed: 3874.977824 tokens/s, learning rate: 7.280e-06, loss_scalings: 13421.773438, pp_loss: 8.513439
[INFO] 2021-07-12 18:44:45,688 [run_pretraining.py:  512]:	********exe.run_729******* 
[INFO] 2021-07-12 18:44:46,754 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:46,755 [run_pretraining.py:  534]:	loss/total_loss, 8.43349552154541, 730
[INFO] 2021-07-12 18:44:46,755 [run_pretraining.py:  535]:	loss/mlm_loss, 8.43349552154541, 730
[INFO] 2021-07-12 18:44:46,755 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.289999757631449e-06, 730
[INFO] 2021-07-12 18:44:46,755 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 730
[INFO] 2021-07-12 18:44:46,755 [run_pretraining.py:  558]:	worker_index: 2, step: 730, cost: 8.433496, mlm loss: 8.433496, speed: 0.937874 steps/s, speed: 7.502991 samples/s, speed: 3841.531200 tokens/s, learning rate: 7.290e-06, loss_scalings: 13421.773438, pp_loss: 8.465961
[INFO] 2021-07-12 18:44:46,755 [run_pretraining.py:  512]:	********exe.run_730******* 
[INFO] 2021-07-12 18:44:47,820 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:47,821 [run_pretraining.py:  534]:	loss/total_loss, 8.220216751098633, 731
[INFO] 2021-07-12 18:44:47,821 [run_pretraining.py:  535]:	loss/mlm_loss, 8.220216751098633, 731
[INFO] 2021-07-12 18:44:47,821 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.299999651877442e-06, 731
[INFO] 2021-07-12 18:44:47,821 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 731
[INFO] 2021-07-12 18:44:47,821 [run_pretraining.py:  558]:	worker_index: 2, step: 731, cost: 8.220217, mlm loss: 8.220217, speed: 0.938448 steps/s, speed: 7.507587 samples/s, speed: 3843.884560 tokens/s, learning rate: 7.300e-06, loss_scalings: 13421.773438, pp_loss: 8.570688
[INFO] 2021-07-12 18:44:47,821 [run_pretraining.py:  512]:	********exe.run_731******* 
[INFO] 2021-07-12 18:44:48,886 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:48,887 [run_pretraining.py:  534]:	loss/total_loss, 8.823508262634277, 732
[INFO] 2021-07-12 18:44:48,887 [run_pretraining.py:  535]:	loss/mlm_loss, 8.823508262634277, 732
[INFO] 2021-07-12 18:44:48,887 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.310000000870787e-06, 732
[INFO] 2021-07-12 18:44:48,887 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 732
[INFO] 2021-07-12 18:44:48,887 [run_pretraining.py:  558]:	worker_index: 2, step: 732, cost: 8.823508, mlm loss: 8.823508, speed: 0.939003 steps/s, speed: 7.512028 samples/s, speed: 3846.158141 tokens/s, learning rate: 7.310e-06, loss_scalings: 13421.773438, pp_loss: 8.631524
[INFO] 2021-07-12 18:44:48,887 [run_pretraining.py:  512]:	********exe.run_732******* 
[INFO] 2021-07-12 18:44:49,957 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:49,957 [run_pretraining.py:  534]:	loss/total_loss, 8.762076377868652, 733
[INFO] 2021-07-12 18:44:49,957 [run_pretraining.py:  535]:	loss/mlm_loss, 8.762076377868652, 733
[INFO] 2021-07-12 18:44:49,957 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.31999989511678e-06, 733
[INFO] 2021-07-12 18:44:49,957 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 733
[INFO] 2021-07-12 18:44:49,957 [run_pretraining.py:  558]:	worker_index: 2, step: 733, cost: 8.762076, mlm loss: 8.762076, speed: 0.934641 steps/s, speed: 7.477127 samples/s, speed: 3828.289264 tokens/s, learning rate: 7.320e-06, loss_scalings: 13421.773438, pp_loss: 7.515976
[INFO] 2021-07-12 18:44:49,957 [run_pretraining.py:  512]:	********exe.run_733******* 
[INFO] 2021-07-12 18:44:51,032 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:51,033 [run_pretraining.py:  534]:	loss/total_loss, 9.107686996459961, 734
[INFO] 2021-07-12 18:44:51,033 [run_pretraining.py:  535]:	loss/mlm_loss, 9.107686996459961, 734
[INFO] 2021-07-12 18:44:51,033 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.329999334615422e-06, 734
[INFO] 2021-07-12 18:44:51,033 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 734
[INFO] 2021-07-12 18:44:51,033 [run_pretraining.py:  558]:	worker_index: 2, step: 734, cost: 9.107687, mlm loss: 9.107687, speed: 0.930036 steps/s, speed: 7.440289 samples/s, speed: 3809.428070 tokens/s, learning rate: 7.330e-06, loss_scalings: 13421.773438, pp_loss: 8.517235
[INFO] 2021-07-12 18:44:51,033 [run_pretraining.py:  512]:	********exe.run_734******* 
[INFO] 2021-07-12 18:44:52,071 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:52,071 [run_pretraining.py:  534]:	loss/total_loss, 8.498912811279297, 735
[INFO] 2021-07-12 18:44:52,071 [run_pretraining.py:  535]:	loss/mlm_loss, 8.498912811279297, 735
[INFO] 2021-07-12 18:44:52,071 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.339999683608767e-06, 735
[INFO] 2021-07-12 18:44:52,071 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 735
[INFO] 2021-07-12 18:44:52,071 [run_pretraining.py:  558]:	worker_index: 2, step: 735, cost: 8.498913, mlm loss: 8.498913, speed: 0.963837 steps/s, speed: 7.710695 samples/s, speed: 3947.875963 tokens/s, learning rate: 7.340e-06, loss_scalings: 13421.773438, pp_loss: 8.424691
[INFO] 2021-07-12 18:44:52,071 [run_pretraining.py:  512]:	********exe.run_735******* 
[INFO] 2021-07-12 18:44:52,987 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:52,988 [run_pretraining.py:  534]:	loss/total_loss, 8.579147338867188, 736
[INFO] 2021-07-12 18:44:52,988 [run_pretraining.py:  535]:	loss/mlm_loss, 8.579147338867188, 736
[INFO] 2021-07-12 18:44:52,988 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.350000032602111e-06, 736
[INFO] 2021-07-12 18:44:52,988 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 736
[INFO] 2021-07-12 18:44:52,988 [run_pretraining.py:  558]:	worker_index: 2, step: 736, cost: 8.579147, mlm loss: 8.579147, speed: 1.091723 steps/s, speed: 8.733782 samples/s, speed: 4471.696570 tokens/s, learning rate: 7.350e-06, loss_scalings: 13421.773438, pp_loss: 8.427051
[INFO] 2021-07-12 18:44:52,988 [run_pretraining.py:  512]:	********exe.run_736******* 
[INFO] 2021-07-12 18:44:53,900 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:53,900 [run_pretraining.py:  534]:	loss/total_loss, 7.929616928100586, 737
[INFO] 2021-07-12 18:44:53,900 [run_pretraining.py:  535]:	loss/mlm_loss, 7.929616928100586, 737
[INFO] 2021-07-12 18:44:53,900 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.359999926848104e-06, 737
[INFO] 2021-07-12 18:44:53,900 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 737
[INFO] 2021-07-12 18:44:53,901 [run_pretraining.py:  558]:	worker_index: 2, step: 737, cost: 7.929617, mlm loss: 7.929617, speed: 1.096528 steps/s, speed: 8.772224 samples/s, speed: 4491.378653 tokens/s, learning rate: 7.360e-06, loss_scalings: 13421.773438, pp_loss: 8.123795
[INFO] 2021-07-12 18:44:53,901 [run_pretraining.py:  512]:	********exe.run_737******* 
[INFO] 2021-07-12 18:44:54,814 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:54,814 [run_pretraining.py:  534]:	loss/total_loss, 8.629032135009766, 738
[INFO] 2021-07-12 18:44:54,814 [run_pretraining.py:  535]:	loss/mlm_loss, 8.629032135009766, 738
[INFO] 2021-07-12 18:44:54,814 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.3700002758414485e-06, 738
[INFO] 2021-07-12 18:44:54,814 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 738
[INFO] 2021-07-12 18:44:54,814 [run_pretraining.py:  558]:	worker_index: 2, step: 738, cost: 8.629032, mlm loss: 8.629032, speed: 1.094952 steps/s, speed: 8.759613 samples/s, speed: 4484.921668 tokens/s, learning rate: 7.370e-06, loss_scalings: 13421.773438, pp_loss: 8.481381
[INFO] 2021-07-12 18:44:54,814 [run_pretraining.py:  512]:	********exe.run_738******* 
[INFO] 2021-07-12 18:44:55,723 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:55,723 [run_pretraining.py:  534]:	loss/total_loss, 8.279685974121094, 739
[INFO] 2021-07-12 18:44:55,723 [run_pretraining.py:  535]:	loss/mlm_loss, 8.279685974121094, 739
[INFO] 2021-07-12 18:44:55,723 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.379999715340091e-06, 739
[INFO] 2021-07-12 18:44:55,723 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 739
[INFO] 2021-07-12 18:44:55,723 [run_pretraining.py:  558]:	worker_index: 2, step: 739, cost: 8.279686, mlm loss: 8.279686, speed: 1.100847 steps/s, speed: 8.806778 samples/s, speed: 4509.070356 tokens/s, learning rate: 7.380e-06, loss_scalings: 13421.773438, pp_loss: 8.439999
[INFO] 2021-07-12 18:44:55,723 [run_pretraining.py:  512]:	********exe.run_739******* 
[INFO] 2021-07-12 18:44:56,642 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:56,642 [run_pretraining.py:  534]:	loss/total_loss, 8.613473892211914, 740
[INFO] 2021-07-12 18:44:56,642 [run_pretraining.py:  535]:	loss/mlm_loss, 8.613473892211914, 740
[INFO] 2021-07-12 18:44:56,642 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.389999609586084e-06, 740
[INFO] 2021-07-12 18:44:56,642 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 740
[INFO] 2021-07-12 18:44:56,642 [run_pretraining.py:  558]:	worker_index: 2, step: 740, cost: 8.613474, mlm loss: 8.613474, speed: 1.088812 steps/s, speed: 8.710496 samples/s, speed: 4459.773776 tokens/s, learning rate: 7.390e-06, loss_scalings: 13421.773438, pp_loss: 8.477449
[INFO] 2021-07-12 18:44:56,642 [run_pretraining.py:  512]:	********exe.run_740******* 
[INFO] 2021-07-12 18:44:57,556 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:57,556 [run_pretraining.py:  534]:	loss/total_loss, 8.190544128417969, 741
[INFO] 2021-07-12 18:44:57,556 [run_pretraining.py:  535]:	loss/mlm_loss, 8.190544128417969, 741
[INFO] 2021-07-12 18:44:57,556 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.3999999585794285e-06, 741
[INFO] 2021-07-12 18:44:57,556 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 741
[INFO] 2021-07-12 18:44:57,556 [run_pretraining.py:  558]:	worker_index: 2, step: 741, cost: 8.190544, mlm loss: 8.190544, speed: 1.094819 steps/s, speed: 8.758549 samples/s, speed: 4484.377303 tokens/s, learning rate: 7.400e-06, loss_scalings: 13421.773438, pp_loss: 8.286583
[INFO] 2021-07-12 18:44:57,556 [run_pretraining.py:  512]:	********exe.run_741******* 
[INFO] 2021-07-12 18:44:58,471 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:58,471 [run_pretraining.py:  534]:	loss/total_loss, 8.389347076416016, 742
[INFO] 2021-07-12 18:44:58,471 [run_pretraining.py:  535]:	loss/mlm_loss, 8.389347076416016, 742
[INFO] 2021-07-12 18:44:58,471 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.409999852825422e-06, 742
[INFO] 2021-07-12 18:44:58,471 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 742
[INFO] 2021-07-12 18:44:58,471 [run_pretraining.py:  558]:	worker_index: 2, step: 742, cost: 8.389347, mlm loss: 8.389347, speed: 1.093700 steps/s, speed: 8.749599 samples/s, speed: 4479.794664 tokens/s, learning rate: 7.410e-06, loss_scalings: 13421.773438, pp_loss: 8.351681
[INFO] 2021-07-12 18:44:58,471 [run_pretraining.py:  512]:	********exe.run_742******* 
[INFO] 2021-07-12 18:44:59,394 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:59,395 [run_pretraining.py:  534]:	loss/total_loss, 5.340747356414795, 743
[INFO] 2021-07-12 18:44:59,395 [run_pretraining.py:  535]:	loss/mlm_loss, 5.340747356414795, 743
[INFO] 2021-07-12 18:44:59,395 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.419999292324064e-06, 743
[INFO] 2021-07-12 18:44:59,395 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 743
[INFO] 2021-07-12 18:44:59,395 [run_pretraining.py:  558]:	worker_index: 2, step: 743, cost: 5.340747, mlm loss: 5.340747, speed: 1.083534 steps/s, speed: 8.668270 samples/s, speed: 4438.154361 tokens/s, learning rate: 7.420e-06, loss_scalings: 13421.773438, pp_loss: 7.268487
[INFO] 2021-07-12 18:44:59,395 [run_pretraining.py:  512]:	********exe.run_743******* 
[INFO] 2021-07-12 18:45:00,298 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:00,298 [run_pretraining.py:  534]:	loss/total_loss, 8.043306350708008, 744
[INFO] 2021-07-12 18:45:00,298 [run_pretraining.py:  535]:	loss/mlm_loss, 8.043306350708008, 744
[INFO] 2021-07-12 18:45:00,298 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.4299996413174085e-06, 744
[INFO] 2021-07-12 18:45:00,298 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 744
[INFO] 2021-07-12 18:45:00,298 [run_pretraining.py:  558]:	worker_index: 2, step: 744, cost: 8.043306, mlm loss: 8.043306, speed: 1.107490 steps/s, speed: 8.859920 samples/s, speed: 4536.279205 tokens/s, learning rate: 7.430e-06, loss_scalings: 13421.773438, pp_loss: 8.304050
[INFO] 2021-07-12 18:45:00,299 [run_pretraining.py:  512]:	********exe.run_744******* 
[INFO] 2021-07-12 18:45:01,212 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:01,213 [run_pretraining.py:  534]:	loss/total_loss, 8.92470645904541, 745
[INFO] 2021-07-12 18:45:01,213 [run_pretraining.py:  535]:	loss/mlm_loss, 8.92470645904541, 745
[INFO] 2021-07-12 18:45:01,213 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.439999990310753e-06, 745
[INFO] 2021-07-12 18:45:01,213 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 745
[INFO] 2021-07-12 18:45:01,213 [run_pretraining.py:  558]:	worker_index: 2, step: 745, cost: 8.924706, mlm loss: 8.924706, speed: 1.094292 steps/s, speed: 8.754336 samples/s, speed: 4482.219875 tokens/s, learning rate: 7.440e-06, loss_scalings: 13421.773438, pp_loss: 8.380745
[INFO] 2021-07-12 18:45:01,213 [run_pretraining.py:  512]:	********exe.run_745******* 
[INFO] 2021-07-12 18:45:02,130 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:02,131 [run_pretraining.py:  534]:	loss/total_loss, 8.279977798461914, 746
[INFO] 2021-07-12 18:45:02,131 [run_pretraining.py:  535]:	loss/mlm_loss, 8.279977798461914, 746
[INFO] 2021-07-12 18:45:02,131 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.449999884556746e-06, 746
[INFO] 2021-07-12 18:45:02,131 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 746
[INFO] 2021-07-12 18:45:02,131 [run_pretraining.py:  558]:	worker_index: 2, step: 746, cost: 8.279978, mlm loss: 8.279978, speed: 1.089493 steps/s, speed: 8.715946 samples/s, speed: 4462.564483 tokens/s, learning rate: 7.450e-06, loss_scalings: 13421.773438, pp_loss: 8.685324
[INFO] 2021-07-12 18:45:02,131 [run_pretraining.py:  512]:	********exe.run_746******* 
[INFO] 2021-07-12 18:45:03,043 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:03,043 [run_pretraining.py:  534]:	loss/total_loss, 8.774602890014648, 747
[INFO] 2021-07-12 18:45:03,043 [run_pretraining.py:  535]:	loss/mlm_loss, 8.774602890014648, 747
[INFO] 2021-07-12 18:45:03,044 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.46000023355009e-06, 747
[INFO] 2021-07-12 18:45:03,044 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 747
[INFO] 2021-07-12 18:45:03,044 [run_pretraining.py:  558]:	worker_index: 2, step: 747, cost: 8.774603, mlm loss: 8.774603, speed: 1.096781 steps/s, speed: 8.774252 samples/s, speed: 4492.416880 tokens/s, learning rate: 7.460e-06, loss_scalings: 13421.773438, pp_loss: 8.412749
[INFO] 2021-07-12 18:45:03,044 [run_pretraining.py:  512]:	********exe.run_747******* 
[INFO] 2021-07-12 18:45:03,967 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:03,967 [run_pretraining.py:  534]:	loss/total_loss, 8.73520278930664, 748
[INFO] 2021-07-12 18:45:03,967 [run_pretraining.py:  535]:	loss/mlm_loss, 8.73520278930664, 748
[INFO] 2021-07-12 18:45:03,967 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.469999673048733e-06, 748
[INFO] 2021-07-12 18:45:03,967 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 748
[INFO] 2021-07-12 18:45:03,968 [run_pretraining.py:  558]:	worker_index: 2, step: 748, cost: 8.735203, mlm loss: 8.735203, speed: 1.083206 steps/s, speed: 8.665649 samples/s, speed: 4436.812181 tokens/s, learning rate: 7.470e-06, loss_scalings: 13421.773438, pp_loss: 8.590119
[INFO] 2021-07-12 18:45:03,968 [run_pretraining.py:  512]:	********exe.run_748******* 
[INFO] 2021-07-12 18:45:04,882 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:04,882 [run_pretraining.py:  534]:	loss/total_loss, 7.864640235900879, 749
[INFO] 2021-07-12 18:45:04,882 [run_pretraining.py:  535]:	loss/mlm_loss, 7.864640235900879, 749
[INFO] 2021-07-12 18:45:04,882 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.479999567294726e-06, 749
[INFO] 2021-07-12 18:45:04,882 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 749
[INFO] 2021-07-12 18:45:04,883 [run_pretraining.py:  558]:	worker_index: 2, step: 749, cost: 7.864640, mlm loss: 7.864640, speed: 1.093626 steps/s, speed: 8.749006 samples/s, speed: 4479.490967 tokens/s, learning rate: 7.480e-06, loss_scalings: 13421.773438, pp_loss: 8.206161
[INFO] 2021-07-12 18:45:04,883 [run_pretraining.py:  512]:	********exe.run_749******* 
[INFO] 2021-07-12 18:45:05,794 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:05,794 [run_pretraining.py:  534]:	loss/total_loss, 8.136421203613281, 750
[INFO] 2021-07-12 18:45:05,794 [run_pretraining.py:  535]:	loss/mlm_loss, 8.136421203613281, 750
[INFO] 2021-07-12 18:45:05,795 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.48999991628807e-06, 750
[INFO] 2021-07-12 18:45:05,795 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 750
[INFO] 2021-07-12 18:45:05,795 [run_pretraining.py:  558]:	worker_index: 2, step: 750, cost: 8.136421, mlm loss: 8.136421, speed: 1.096926 steps/s, speed: 8.775406 samples/s, speed: 4493.007849 tokens/s, learning rate: 7.490e-06, loss_scalings: 13421.773438, pp_loss: 7.501021
[INFO] 2021-07-12 18:45:05,795 [run_pretraining.py:  512]:	********exe.run_750******* 
[INFO] 2021-07-12 18:45:06,698 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:06,698 [run_pretraining.py:  534]:	loss/total_loss, 8.142790794372559, 751
[INFO] 2021-07-12 18:45:06,698 [run_pretraining.py:  535]:	loss/mlm_loss, 8.142790794372559, 751
[INFO] 2021-07-12 18:45:06,698 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.500000265281415e-06, 751
[INFO] 2021-07-12 18:45:06,698 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 751
[INFO] 2021-07-12 18:45:06,698 [run_pretraining.py:  558]:	worker_index: 2, step: 751, cost: 8.142791, mlm loss: 8.142791, speed: 1.107305 steps/s, speed: 8.858442 samples/s, speed: 4535.522329 tokens/s, learning rate: 7.500e-06, loss_scalings: 13421.773438, pp_loss: 8.673271
[INFO] 2021-07-12 18:45:06,698 [run_pretraining.py:  512]:	********exe.run_751******* 
[INFO] 2021-07-12 18:45:07,611 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:07,612 [run_pretraining.py:  534]:	loss/total_loss, 8.481151580810547, 752
[INFO] 2021-07-12 18:45:07,612 [run_pretraining.py:  535]:	loss/mlm_loss, 8.481151580810547, 752
[INFO] 2021-07-12 18:45:07,612 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.509999704780057e-06, 752
[INFO] 2021-07-12 18:45:07,612 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 752
[INFO] 2021-07-12 18:45:07,612 [run_pretraining.py:  558]:	worker_index: 2, step: 752, cost: 8.481152, mlm loss: 8.481152, speed: 1.094971 steps/s, speed: 8.759768 samples/s, speed: 4485.001285 tokens/s, learning rate: 7.510e-06, loss_scalings: 13421.773438, pp_loss: 8.407959
[INFO] 2021-07-12 18:45:07,612 [run_pretraining.py:  512]:	********exe.run_752******* 
[INFO] 2021-07-12 18:45:08,519 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:08,520 [run_pretraining.py:  534]:	loss/total_loss, 8.0584716796875, 753
[INFO] 2021-07-12 18:45:08,520 [run_pretraining.py:  535]:	loss/mlm_loss, 8.0584716796875, 753
[INFO] 2021-07-12 18:45:08,520 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.51999959902605e-06, 753
[INFO] 2021-07-12 18:45:08,520 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 753
[INFO] 2021-07-12 18:45:08,520 [run_pretraining.py:  558]:	worker_index: 2, step: 753, cost: 8.058472, mlm loss: 8.058472, speed: 1.102026 steps/s, speed: 8.816205 samples/s, speed: 4513.896940 tokens/s, learning rate: 7.520e-06, loss_scalings: 13421.773438, pp_loss: 8.276363
[INFO] 2021-07-12 18:45:08,520 [run_pretraining.py:  512]:	********exe.run_753******* 
[INFO] 2021-07-12 18:45:09,426 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:09,426 [run_pretraining.py:  534]:	loss/total_loss, 7.9417524337768555, 754
[INFO] 2021-07-12 18:45:09,427 [run_pretraining.py:  535]:	loss/mlm_loss, 7.9417524337768555, 754
[INFO] 2021-07-12 18:45:09,427 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.529999948019395e-06, 754
[INFO] 2021-07-12 18:45:09,427 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 754
[INFO] 2021-07-12 18:45:09,427 [run_pretraining.py:  558]:	worker_index: 2, step: 754, cost: 7.941752, mlm loss: 7.941752, speed: 1.103882 steps/s, speed: 8.831057 samples/s, speed: 4521.501293 tokens/s, learning rate: 7.530e-06, loss_scalings: 13421.773438, pp_loss: 8.161402
[INFO] 2021-07-12 18:45:09,427 [run_pretraining.py:  512]:	********exe.run_754******* 
[INFO] 2021-07-12 18:45:10,326 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:10,326 [run_pretraining.py:  534]:	loss/total_loss, 8.684148788452148, 755
[INFO] 2021-07-12 18:45:10,326 [run_pretraining.py:  535]:	loss/mlm_loss, 8.684148788452148, 755
[INFO] 2021-07-12 18:45:10,326 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.539999842265388e-06, 755
[INFO] 2021-07-12 18:45:10,326 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 755
[INFO] 2021-07-12 18:45:10,326 [run_pretraining.py:  558]:	worker_index: 2, step: 755, cost: 8.684149, mlm loss: 8.684149, speed: 1.112327 steps/s, speed: 8.898619 samples/s, speed: 4556.092928 tokens/s, learning rate: 7.540e-06, loss_scalings: 13421.773438, pp_loss: 8.441914
[INFO] 2021-07-12 18:45:10,327 [run_pretraining.py:  512]:	********exe.run_755******* 
[INFO] 2021-07-12 18:45:11,227 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:11,227 [run_pretraining.py:  534]:	loss/total_loss, 8.317420959472656, 756
[INFO] 2021-07-12 18:45:11,227 [run_pretraining.py:  535]:	loss/mlm_loss, 8.317420959472656, 756
[INFO] 2021-07-12 18:45:11,227 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.5499992817640305e-06, 756
[INFO] 2021-07-12 18:45:11,228 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 756
[INFO] 2021-07-12 18:45:11,228 [run_pretraining.py:  558]:	worker_index: 2, step: 756, cost: 8.317421, mlm loss: 8.317421, speed: 1.110420 steps/s, speed: 8.883358 samples/s, speed: 4548.279155 tokens/s, learning rate: 7.550e-06, loss_scalings: 13421.773438, pp_loss: 8.134716
[INFO] 2021-07-12 18:45:11,228 [run_pretraining.py:  512]:	********exe.run_756******* 
[INFO] 2021-07-12 18:45:12,131 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:12,132 [run_pretraining.py:  534]:	loss/total_loss, 7.80535364151001, 757
[INFO] 2021-07-12 18:45:12,132 [run_pretraining.py:  535]:	loss/mlm_loss, 7.80535364151001, 757
[INFO] 2021-07-12 18:45:12,132 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.559999630757375e-06, 757
[INFO] 2021-07-12 18:45:12,132 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 757
[INFO] 2021-07-12 18:45:12,132 [run_pretraining.py:  558]:	worker_index: 2, step: 757, cost: 7.805354, mlm loss: 7.805354, speed: 1.106487 steps/s, speed: 8.851896 samples/s, speed: 4532.170925 tokens/s, learning rate: 7.560e-06, loss_scalings: 13421.773438, pp_loss: 7.957012
[INFO] 2021-07-12 18:45:12,132 [run_pretraining.py:  512]:	********exe.run_757******* 
[INFO] 2021-07-12 18:45:13,039 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:13,039 [run_pretraining.py:  534]:	loss/total_loss, 8.105107307434082, 758
[INFO] 2021-07-12 18:45:13,040 [run_pretraining.py:  535]:	loss/mlm_loss, 8.105107307434082, 758
[INFO] 2021-07-12 18:45:13,040 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.569999979750719e-06, 758
[INFO] 2021-07-12 18:45:13,040 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 758
[INFO] 2021-07-12 18:45:13,040 [run_pretraining.py:  558]:	worker_index: 2, step: 758, cost: 8.105107, mlm loss: 8.105107, speed: 1.102259 steps/s, speed: 8.818075 samples/s, speed: 4514.854242 tokens/s, learning rate: 7.570e-06, loss_scalings: 13421.773438, pp_loss: 8.325254
[INFO] 2021-07-12 18:45:13,040 [run_pretraining.py:  512]:	********exe.run_758******* 
[INFO] 2021-07-12 18:45:13,943 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:13,944 [run_pretraining.py:  534]:	loss/total_loss, 8.989972114562988, 759
[INFO] 2021-07-12 18:45:13,944 [run_pretraining.py:  535]:	loss/mlm_loss, 8.989972114562988, 759
[INFO] 2021-07-12 18:45:13,944 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.579999873996712e-06, 759
[INFO] 2021-07-12 18:45:13,944 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 759
[INFO] 2021-07-12 18:45:13,944 [run_pretraining.py:  558]:	worker_index: 2, step: 759, cost: 8.989972, mlm loss: 8.989972, speed: 1.106769 steps/s, speed: 8.854153 samples/s, speed: 4533.326187 tokens/s, learning rate: 7.580e-06, loss_scalings: 13421.773438, pp_loss: 8.656278
[INFO] 2021-07-12 18:45:13,944 [run_pretraining.py:  512]:	********exe.run_759******* 
[INFO] 2021-07-12 18:45:14,849 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:14,849 [run_pretraining.py:  534]:	loss/total_loss, 8.671607971191406, 760
[INFO] 2021-07-12 18:45:14,849 [run_pretraining.py:  535]:	loss/mlm_loss, 8.671607971191406, 760
[INFO] 2021-07-12 18:45:14,849 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.5900002229900565e-06, 760
[INFO] 2021-07-12 18:45:14,849 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 760
[INFO] 2021-07-12 18:45:14,850 [run_pretraining.py:  558]:	worker_index: 2, step: 760, cost: 8.671608, mlm loss: 8.671608, speed: 1.105045 steps/s, speed: 8.840359 samples/s, speed: 4526.263908 tokens/s, learning rate: 7.590e-06, loss_scalings: 13421.773438, pp_loss: 8.646967
[INFO] 2021-07-12 18:45:14,850 [run_pretraining.py:  512]:	********exe.run_760******* 
[INFO] 2021-07-12 18:45:15,750 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:15,751 [run_pretraining.py:  534]:	loss/total_loss, 8.047822952270508, 761
[INFO] 2021-07-12 18:45:15,751 [run_pretraining.py:  535]:	loss/mlm_loss, 8.047822952270508, 761
[INFO] 2021-07-12 18:45:15,751 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.599999662488699e-06, 761
[INFO] 2021-07-12 18:45:15,751 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 761
[INFO] 2021-07-12 18:45:15,751 [run_pretraining.py:  558]:	worker_index: 2, step: 761, cost: 8.047823, mlm loss: 8.047823, speed: 1.109986 steps/s, speed: 8.879885 samples/s, speed: 4546.501346 tokens/s, learning rate: 7.600e-06, loss_scalings: 13421.773438, pp_loss: 8.442814
[INFO] 2021-07-12 18:45:15,751 [run_pretraining.py:  512]:	********exe.run_761******* 
[INFO] 2021-07-12 18:45:16,654 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:16,655 [run_pretraining.py:  534]:	loss/total_loss, 5.269359111785889, 762
[INFO] 2021-07-12 18:45:16,655 [run_pretraining.py:  535]:	loss/mlm_loss, 5.269359111785889, 762
[INFO] 2021-07-12 18:45:16,655 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.609999556734692e-06, 762
[INFO] 2021-07-12 18:45:16,655 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 762
[INFO] 2021-07-12 18:45:16,655 [run_pretraining.py:  558]:	worker_index: 2, step: 762, cost: 5.269359, mlm loss: 5.269359, speed: 1.106760 steps/s, speed: 8.854078 samples/s, speed: 4533.287908 tokens/s, learning rate: 7.610e-06, loss_scalings: 13421.773438, pp_loss: 7.601970
[INFO] 2021-07-12 18:45:16,655 [run_pretraining.py:  512]:	********exe.run_762******* 
[INFO] 2021-07-12 18:45:17,558 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:17,558 [run_pretraining.py:  534]:	loss/total_loss, 8.174960136413574, 763
[INFO] 2021-07-12 18:45:17,558 [run_pretraining.py:  535]:	loss/mlm_loss, 8.174960136413574, 763
[INFO] 2021-07-12 18:45:17,558 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.6199999057280365e-06, 763
[INFO] 2021-07-12 18:45:17,559 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 763
[INFO] 2021-07-12 18:45:17,559 [run_pretraining.py:  558]:	worker_index: 2, step: 763, cost: 8.174960, mlm loss: 8.174960, speed: 1.107599 steps/s, speed: 8.860793 samples/s, speed: 4536.726023 tokens/s, learning rate: 7.620e-06, loss_scalings: 13421.773438, pp_loss: 8.394868
[INFO] 2021-07-12 18:45:17,559 [run_pretraining.py:  512]:	********exe.run_763******* 
[INFO] 2021-07-12 18:45:18,471 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:18,472 [run_pretraining.py:  534]:	loss/total_loss, 8.505817413330078, 764
[INFO] 2021-07-12 18:45:18,472 [run_pretraining.py:  535]:	loss/mlm_loss, 8.505817413330078, 764
[INFO] 2021-07-12 18:45:18,472 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.63000025472138e-06, 764
[INFO] 2021-07-12 18:45:18,472 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 764
[INFO] 2021-07-12 18:45:18,472 [run_pretraining.py:  558]:	worker_index: 2, step: 764, cost: 8.505817, mlm loss: 8.505817, speed: 1.095649 steps/s, speed: 8.765196 samples/s, speed: 4487.780288 tokens/s, learning rate: 7.630e-06, loss_scalings: 13421.773438, pp_loss: 8.462350
[INFO] 2021-07-12 18:45:18,472 [run_pretraining.py:  512]:	********exe.run_764******* 
[INFO] 2021-07-12 18:45:19,376 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:19,377 [run_pretraining.py:  534]:	loss/total_loss, 8.363393783569336, 765
[INFO] 2021-07-12 18:45:19,377 [run_pretraining.py:  535]:	loss/mlm_loss, 8.363393783569336, 765
[INFO] 2021-07-12 18:45:19,377 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.639999239472672e-06, 765
[INFO] 2021-07-12 18:45:19,377 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 765
[INFO] 2021-07-12 18:45:19,377 [run_pretraining.py:  558]:	worker_index: 2, step: 765, cost: 8.363394, mlm loss: 8.363394, speed: 1.105640 steps/s, speed: 8.845120 samples/s, speed: 4528.701506 tokens/s, learning rate: 7.640e-06, loss_scalings: 13421.773438, pp_loss: 8.385225
[INFO] 2021-07-12 18:45:19,377 [run_pretraining.py:  512]:	********exe.run_765******* 
[INFO] 2021-07-12 18:45:20,300 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:20,300 [run_pretraining.py:  534]:	loss/total_loss, 7.849130153656006, 766
[INFO] 2021-07-12 18:45:20,300 [run_pretraining.py:  535]:	loss/mlm_loss, 7.849130153656006, 766
[INFO] 2021-07-12 18:45:20,300 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.650000043213367e-06, 766
[INFO] 2021-07-12 18:45:20,300 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 766
[INFO] 2021-07-12 18:45:20,301 [run_pretraining.py:  558]:	worker_index: 2, step: 766, cost: 7.849130, mlm loss: 7.849130, speed: 1.083510 steps/s, speed: 8.668078 samples/s, speed: 4438.055761 tokens/s, learning rate: 7.650e-06, loss_scalings: 13421.773438, pp_loss: 8.185497
[INFO] 2021-07-12 18:45:20,301 [run_pretraining.py:  512]:	********exe.run_766******* 
[INFO] 2021-07-12 18:45:21,207 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:21,207 [run_pretraining.py:  534]:	loss/total_loss, 8.902643203735352, 767
[INFO] 2021-07-12 18:45:21,207 [run_pretraining.py:  535]:	loss/mlm_loss, 8.902643203735352, 767
[INFO] 2021-07-12 18:45:21,207 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.65999993745936e-06, 767
[INFO] 2021-07-12 18:45:21,207 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 767
[INFO] 2021-07-12 18:45:21,207 [run_pretraining.py:  558]:	worker_index: 2, step: 767, cost: 8.902643, mlm loss: 8.902643, speed: 1.103415 steps/s, speed: 8.827321 samples/s, speed: 4519.588589 tokens/s, learning rate: 7.660e-06, loss_scalings: 13421.773438, pp_loss: 8.509090
[INFO] 2021-07-12 18:45:21,208 [run_pretraining.py:  512]:	********exe.run_767******* 
[INFO] 2021-07-12 18:45:22,119 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:22,119 [run_pretraining.py:  534]:	loss/total_loss, 8.76645278930664, 768
[INFO] 2021-07-12 18:45:22,120 [run_pretraining.py:  535]:	loss/mlm_loss, 8.76645278930664, 768
[INFO] 2021-07-12 18:45:22,120 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.669999831705354e-06, 768
[INFO] 2021-07-12 18:45:22,120 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 768
[INFO] 2021-07-12 18:45:22,120 [run_pretraining.py:  558]:	worker_index: 2, step: 768, cost: 8.766453, mlm loss: 8.766453, speed: 1.096793 steps/s, speed: 8.774346 samples/s, speed: 4492.465044 tokens/s, learning rate: 7.670e-06, loss_scalings: 13421.773438, pp_loss: 8.336268
[INFO] 2021-07-12 18:45:22,120 [run_pretraining.py:  512]:	********exe.run_768******* 
[INFO] 2021-07-12 18:45:23,031 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:23,032 [run_pretraining.py:  534]:	loss/total_loss, 8.3318510055542, 769
[INFO] 2021-07-12 18:45:23,032 [run_pretraining.py:  535]:	loss/mlm_loss, 8.3318510055542, 769
[INFO] 2021-07-12 18:45:23,032 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.679999725951348e-06, 769
[INFO] 2021-07-12 18:45:23,032 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 769
[INFO] 2021-07-12 18:45:23,032 [run_pretraining.py:  558]:	worker_index: 2, step: 769, cost: 8.331851, mlm loss: 8.331851, speed: 1.096847 steps/s, speed: 8.774773 samples/s, speed: 4492.683560 tokens/s, learning rate: 7.680e-06, loss_scalings: 13421.773438, pp_loss: 8.420683
[INFO] 2021-07-12 18:45:23,032 [run_pretraining.py:  512]:	********exe.run_769******* 
[INFO] 2021-07-12 18:45:23,947 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:23,947 [run_pretraining.py:  534]:	loss/total_loss, 7.866711139678955, 770
[INFO] 2021-07-12 18:45:23,947 [run_pretraining.py:  535]:	loss/mlm_loss, 7.866711139678955, 770
[INFO] 2021-07-12 18:45:23,947 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.68999962019734e-06, 770
[INFO] 2021-07-12 18:45:23,947 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 770
[INFO] 2021-07-12 18:45:23,947 [run_pretraining.py:  558]:	worker_index: 2, step: 770, cost: 7.866711, mlm loss: 7.866711, speed: 1.093155 steps/s, speed: 8.745241 samples/s, speed: 4477.563453 tokens/s, learning rate: 7.690e-06, loss_scalings: 13421.773438, pp_loss: 8.208877
[INFO] 2021-07-12 18:45:23,948 [run_pretraining.py:  512]:	********exe.run_770******* 
[INFO] 2021-07-12 18:45:24,859 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:24,860 [run_pretraining.py:  534]:	loss/total_loss, 8.763474464416504, 771
[INFO] 2021-07-12 18:45:24,860 [run_pretraining.py:  535]:	loss/mlm_loss, 8.763474464416504, 771
[INFO] 2021-07-12 18:45:24,860 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.699999514443334e-06, 771
[INFO] 2021-07-12 18:45:24,860 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 771
[INFO] 2021-07-12 18:45:24,860 [run_pretraining.py:  558]:	worker_index: 2, step: 771, cost: 8.763474, mlm loss: 8.763474, speed: 1.096208 steps/s, speed: 8.769668 samples/s, speed: 4490.069809 tokens/s, learning rate: 7.700e-06, loss_scalings: 13421.773438, pp_loss: 8.333611
[INFO] 2021-07-12 18:45:24,860 [run_pretraining.py:  512]:	********exe.run_771******* 
[INFO] 2021-07-12 18:45:25,793 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:25,793 [run_pretraining.py:  534]:	loss/total_loss, 8.595991134643555, 772
[INFO] 2021-07-12 18:45:25,793 [run_pretraining.py:  535]:	loss/mlm_loss, 8.595991134643555, 772
[INFO] 2021-07-12 18:45:25,793 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.71000031818403e-06, 772
[INFO] 2021-07-12 18:45:25,793 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 772
[INFO] 2021-07-12 18:45:25,793 [run_pretraining.py:  558]:	worker_index: 2, step: 772, cost: 8.595991, mlm loss: 8.595991, speed: 1.072378 steps/s, speed: 8.579024 samples/s, speed: 4392.460145 tokens/s, learning rate: 7.710e-06, loss_scalings: 13421.773438, pp_loss: 8.327829
[INFO] 2021-07-12 18:45:25,794 [run_pretraining.py:  512]:	********exe.run_772******* 
[INFO] 2021-07-12 18:45:26,847 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:26,848 [run_pretraining.py:  534]:	loss/total_loss, 8.949258804321289, 773
[INFO] 2021-07-12 18:45:26,848 [run_pretraining.py:  535]:	loss/mlm_loss, 8.949258804321289, 773
[INFO] 2021-07-12 18:45:26,848 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.720000212430023e-06, 773
[INFO] 2021-07-12 18:45:26,848 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 773
[INFO] 2021-07-12 18:45:26,848 [run_pretraining.py:  558]:	worker_index: 2, step: 773, cost: 8.949259, mlm loss: 8.949259, speed: 0.948968 steps/s, speed: 7.591746 samples/s, speed: 3886.973987 tokens/s, learning rate: 7.720e-06, loss_scalings: 13421.773438, pp_loss: 8.638223
[INFO] 2021-07-12 18:45:26,848 [run_pretraining.py:  512]:	********exe.run_773******* 
[INFO] 2021-07-12 18:45:27,908 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:27,909 [run_pretraining.py:  534]:	loss/total_loss, 8.188566207885742, 774
[INFO] 2021-07-12 18:45:27,909 [run_pretraining.py:  535]:	loss/mlm_loss, 8.188566207885742, 774
[INFO] 2021-07-12 18:45:27,909 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.729999197181314e-06, 774
[INFO] 2021-07-12 18:45:27,909 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 774
[INFO] 2021-07-12 18:45:27,909 [run_pretraining.py:  558]:	worker_index: 2, step: 774, cost: 8.188566, mlm loss: 8.188566, speed: 0.942763 steps/s, speed: 7.542101 samples/s, speed: 3861.555914 tokens/s, learning rate: 7.730e-06, loss_scalings: 13421.773438, pp_loss: 8.490332
[INFO] 2021-07-12 18:45:27,909 [run_pretraining.py:  512]:	********exe.run_774******* 
[INFO] 2021-07-12 18:45:28,967 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:28,967 [run_pretraining.py:  534]:	loss/total_loss, 8.642698287963867, 775
[INFO] 2021-07-12 18:45:28,967 [run_pretraining.py:  535]:	loss/mlm_loss, 8.642698287963867, 775
[INFO] 2021-07-12 18:45:28,967 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.74000000092201e-06, 775
[INFO] 2021-07-12 18:45:28,967 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 775
[INFO] 2021-07-12 18:45:28,967 [run_pretraining.py:  558]:	worker_index: 2, step: 775, cost: 8.642698, mlm loss: 8.642698, speed: 0.945534 steps/s, speed: 7.564271 samples/s, speed: 3872.906644 tokens/s, learning rate: 7.740e-06, loss_scalings: 13421.773438, pp_loss: 8.681028
[INFO] 2021-07-12 18:45:28,967 [run_pretraining.py:  512]:	********exe.run_775******* 
[INFO] 2021-07-12 18:45:30,040 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:30,041 [run_pretraining.py:  534]:	loss/total_loss, 8.588485717773438, 776
[INFO] 2021-07-12 18:45:30,041 [run_pretraining.py:  535]:	loss/mlm_loss, 8.588485717773438, 776
[INFO] 2021-07-12 18:45:30,041 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.749999895168003e-06, 776
[INFO] 2021-07-12 18:45:30,041 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 776
[INFO] 2021-07-12 18:45:30,041 [run_pretraining.py:  558]:	worker_index: 2, step: 776, cost: 8.588486, mlm loss: 8.588486, speed: 0.931784 steps/s, speed: 7.454271 samples/s, speed: 3816.586769 tokens/s, learning rate: 7.750e-06, loss_scalings: 13421.773438, pp_loss: 8.632540
[INFO] 2021-07-12 18:45:30,041 [run_pretraining.py:  512]:	********exe.run_776******* 
[INFO] 2021-07-12 18:45:31,120 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:31,121 [run_pretraining.py:  534]:	loss/total_loss, 8.4571533203125, 777
[INFO] 2021-07-12 18:45:31,121 [run_pretraining.py:  535]:	loss/mlm_loss, 8.4571533203125, 777
[INFO] 2021-07-12 18:45:31,121 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.759999789413996e-06, 777
[INFO] 2021-07-12 18:45:31,121 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 777
[INFO] 2021-07-12 18:45:31,121 [run_pretraining.py:  558]:	worker_index: 2, step: 777, cost: 8.457153, mlm loss: 8.457153, speed: 0.926447 steps/s, speed: 7.411579 samples/s, speed: 3794.728200 tokens/s, learning rate: 7.760e-06, loss_scalings: 13421.773438, pp_loss: 8.537027
[INFO] 2021-07-12 18:45:31,121 [run_pretraining.py:  512]:	********exe.run_777******* 
[INFO] 2021-07-12 18:45:32,182 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:32,183 [run_pretraining.py:  534]:	loss/total_loss, 8.279348373413086, 778
[INFO] 2021-07-12 18:45:32,183 [run_pretraining.py:  535]:	loss/mlm_loss, 8.279348373413086, 778
[INFO] 2021-07-12 18:45:32,183 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.76999968365999e-06, 778
[INFO] 2021-07-12 18:45:32,183 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 778
[INFO] 2021-07-12 18:45:32,183 [run_pretraining.py:  558]:	worker_index: 2, step: 778, cost: 8.279348, mlm loss: 8.279348, speed: 0.942461 steps/s, speed: 7.539692 samples/s, speed: 3860.322055 tokens/s, learning rate: 7.770e-06, loss_scalings: 13421.773438, pp_loss: 8.452017
[INFO] 2021-07-12 18:45:32,183 [run_pretraining.py:  512]:	********exe.run_778******* 
[INFO] 2021-07-12 18:45:33,241 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:33,242 [run_pretraining.py:  534]:	loss/total_loss, 8.11055850982666, 779
[INFO] 2021-07-12 18:45:33,242 [run_pretraining.py:  535]:	loss/mlm_loss, 8.11055850982666, 779
[INFO] 2021-07-12 18:45:33,242 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.779999577905983e-06, 779
[INFO] 2021-07-12 18:45:33,242 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 779
[INFO] 2021-07-12 18:45:33,242 [run_pretraining.py:  558]:	worker_index: 2, step: 779, cost: 8.110559, mlm loss: 8.110559, speed: 0.944787 steps/s, speed: 7.558295 samples/s, speed: 3869.847170 tokens/s, learning rate: 7.780e-06, loss_scalings: 13421.773438, pp_loss: 8.249454
[INFO] 2021-07-12 18:45:33,242 [run_pretraining.py:  512]:	********exe.run_779******* 
[INFO] 2021-07-12 18:45:34,304 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:34,304 [run_pretraining.py:  534]:	loss/total_loss, 6.034550666809082, 780
[INFO] 2021-07-12 18:45:34,304 [run_pretraining.py:  535]:	loss/mlm_loss, 6.034550666809082, 780
[INFO] 2021-07-12 18:45:34,305 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.789999472151976e-06, 780
[INFO] 2021-07-12 18:45:34,305 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 780
[INFO] 2021-07-12 18:45:34,305 [run_pretraining.py:  558]:	worker_index: 2, step: 780, cost: 6.034551, mlm loss: 6.034551, speed: 0.941467 steps/s, speed: 7.531732 samples/s, speed: 3856.246906 tokens/s, learning rate: 7.790e-06, loss_scalings: 13421.773438, pp_loss: 7.821402
[INFO] 2021-07-12 18:45:34,305 [run_pretraining.py:  512]:	********exe.run_780******* 
[INFO] 2021-07-12 18:45:35,377 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:35,378 [run_pretraining.py:  534]:	loss/total_loss, 8.364996910095215, 781
[INFO] 2021-07-12 18:45:35,378 [run_pretraining.py:  535]:	loss/mlm_loss, 8.364996910095215, 781
[INFO] 2021-07-12 18:45:35,378 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.800000275892671e-06, 781
[INFO] 2021-07-12 18:45:35,378 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 781
[INFO] 2021-07-12 18:45:35,378 [run_pretraining.py:  558]:	worker_index: 2, step: 781, cost: 8.364997, mlm loss: 8.364997, speed: 0.932274 steps/s, speed: 7.458190 samples/s, speed: 3818.593041 tokens/s, learning rate: 7.800e-06, loss_scalings: 13421.773438, pp_loss: 8.327650
[INFO] 2021-07-12 18:45:35,378 [run_pretraining.py:  512]:	********exe.run_781******* 
[INFO] 2021-07-12 18:45:36,433 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:36,434 [run_pretraining.py:  534]:	loss/total_loss, 8.387951850891113, 782
[INFO] 2021-07-12 18:45:36,434 [run_pretraining.py:  535]:	loss/mlm_loss, 8.387951850891113, 782
[INFO] 2021-07-12 18:45:36,434 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.810000170138665e-06, 782
[INFO] 2021-07-12 18:45:36,434 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 782
[INFO] 2021-07-12 18:45:36,434 [run_pretraining.py:  558]:	worker_index: 2, step: 782, cost: 8.387952, mlm loss: 8.387952, speed: 0.947349 steps/s, speed: 7.578793 samples/s, speed: 3880.342074 tokens/s, learning rate: 7.810e-06, loss_scalings: 13421.773438, pp_loss: 8.403286
[INFO] 2021-07-12 18:45:36,434 [run_pretraining.py:  512]:	********exe.run_782******* 
[INFO] 2021-07-12 18:45:37,498 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:37,498 [run_pretraining.py:  534]:	loss/total_loss, 8.497514724731445, 783
[INFO] 2021-07-12 18:45:37,498 [run_pretraining.py:  535]:	loss/mlm_loss, 8.497514724731445, 783
[INFO] 2021-07-12 18:45:37,498 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.819999154889956e-06, 783
[INFO] 2021-07-12 18:45:37,498 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 783
[INFO] 2021-07-12 18:45:37,498 [run_pretraining.py:  558]:	worker_index: 2, step: 783, cost: 8.497515, mlm loss: 8.497515, speed: 0.940221 steps/s, speed: 7.521766 samples/s, speed: 3851.144118 tokens/s, learning rate: 7.820e-06, loss_scalings: 13421.773438, pp_loss: 8.333561
[INFO] 2021-07-12 18:45:37,498 [run_pretraining.py:  512]:	********exe.run_783******* 
[INFO] 2021-07-12 18:45:38,555 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:38,555 [run_pretraining.py:  534]:	loss/total_loss, 8.225482940673828, 784
[INFO] 2021-07-12 18:45:38,555 [run_pretraining.py:  535]:	loss/mlm_loss, 8.225482940673828, 784
[INFO] 2021-07-12 18:45:38,556 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.829999958630651e-06, 784
[INFO] 2021-07-12 18:45:38,556 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 784
[INFO] 2021-07-12 18:45:38,556 [run_pretraining.py:  558]:	worker_index: 2, step: 784, cost: 8.225483, mlm loss: 8.225483, speed: 0.946309 steps/s, speed: 7.570474 samples/s, speed: 3876.082894 tokens/s, learning rate: 7.830e-06, loss_scalings: 13421.773438, pp_loss: 8.324358
[INFO] 2021-07-12 18:45:38,556 [run_pretraining.py:  512]:	********exe.run_784******* 
[INFO] 2021-07-12 18:45:39,621 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:39,622 [run_pretraining.py:  534]:	loss/total_loss, 8.348315238952637, 785
[INFO] 2021-07-12 18:45:39,622 [run_pretraining.py:  535]:	loss/mlm_loss, 8.348315238952637, 785
[INFO] 2021-07-12 18:45:39,622 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.839999852876645e-06, 785
[INFO] 2021-07-12 18:45:39,622 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 785
[INFO] 2021-07-12 18:45:39,622 [run_pretraining.py:  558]:	worker_index: 2, step: 785, cost: 8.348315, mlm loss: 8.348315, speed: 0.938349 steps/s, speed: 7.506789 samples/s, speed: 3843.476082 tokens/s, learning rate: 7.840e-06, loss_scalings: 13421.773438, pp_loss: 8.580399
[INFO] 2021-07-12 18:45:39,622 [run_pretraining.py:  512]:	********exe.run_785******* 
[INFO] 2021-07-12 18:45:40,644 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:40,644 [run_pretraining.py:  534]:	loss/total_loss, 8.551668167114258, 786
[INFO] 2021-07-12 18:45:40,645 [run_pretraining.py:  535]:	loss/mlm_loss, 8.551668167114258, 786
[INFO] 2021-07-12 18:45:40,645 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.849999747122638e-06, 786
[INFO] 2021-07-12 18:45:40,645 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 786
[INFO] 2021-07-12 18:45:40,645 [run_pretraining.py:  558]:	worker_index: 2, step: 786, cost: 8.551668, mlm loss: 8.551668, speed: 0.978252 steps/s, speed: 7.826015 samples/s, speed: 4006.919846 tokens/s, learning rate: 7.850e-06, loss_scalings: 13421.773438, pp_loss: 8.529312
[INFO] 2021-07-12 18:45:40,645 [run_pretraining.py:  512]:	********exe.run_786******* 
[INFO] 2021-07-12 18:45:41,555 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:41,555 [run_pretraining.py:  534]:	loss/total_loss, 8.034736633300781, 787
[INFO] 2021-07-12 18:45:41,555 [run_pretraining.py:  535]:	loss/mlm_loss, 8.034736633300781, 787
[INFO] 2021-07-12 18:45:41,556 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.859999641368631e-06, 787
[INFO] 2021-07-12 18:45:41,556 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 787
[INFO] 2021-07-12 18:45:41,556 [run_pretraining.py:  558]:	worker_index: 2, step: 787, cost: 8.034737, mlm loss: 8.034737, speed: 1.098623 steps/s, speed: 8.788986 samples/s, speed: 4499.960758 tokens/s, learning rate: 7.860e-06, loss_scalings: 13421.773438, pp_loss: 8.121933
[INFO] 2021-07-12 18:45:41,556 [run_pretraining.py:  512]:	********exe.run_787******* 
[INFO] 2021-07-12 18:45:42,475 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:42,475 [run_pretraining.py:  534]:	loss/total_loss, 8.96284294128418, 788
[INFO] 2021-07-12 18:45:42,475 [run_pretraining.py:  535]:	loss/mlm_loss, 8.96284294128418, 788
[INFO] 2021-07-12 18:45:42,475 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.869999535614625e-06, 788
[INFO] 2021-07-12 18:45:42,475 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 788
[INFO] 2021-07-12 18:45:42,475 [run_pretraining.py:  558]:	worker_index: 2, step: 788, cost: 8.962843, mlm loss: 8.962843, speed: 1.087925 steps/s, speed: 8.703404 samples/s, speed: 4456.142633 tokens/s, learning rate: 7.870e-06, loss_scalings: 13421.773438, pp_loss: 8.544497
[INFO] 2021-07-12 18:45:42,476 [run_pretraining.py:  512]:	********exe.run_788******* 
[INFO] 2021-07-12 18:45:43,391 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:43,392 [run_pretraining.py:  534]:	loss/total_loss, 8.645279884338379, 789
[INFO] 2021-07-12 18:45:43,392 [run_pretraining.py:  535]:	loss/mlm_loss, 8.645279884338379, 789
[INFO] 2021-07-12 18:45:43,392 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.879999429860618e-06, 789
[INFO] 2021-07-12 18:45:43,392 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 789
[INFO] 2021-07-12 18:45:43,393 [run_pretraining.py:  558]:	worker_index: 2, step: 789, cost: 8.645280, mlm loss: 8.645280, speed: 1.091231 steps/s, speed: 8.729849 samples/s, speed: 4469.682724 tokens/s, learning rate: 7.880e-06, loss_scalings: 13421.773438, pp_loss: 8.302426
[INFO] 2021-07-12 18:45:43,393 [run_pretraining.py:  512]:	********exe.run_789******* 
[INFO] 2021-07-12 18:46:08,291 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:08,292 [run_pretraining.py:  534]:	loss/total_loss, 8.663291931152344, 790
[INFO] 2021-07-12 18:46:08,292 [run_pretraining.py:  535]:	loss/mlm_loss, 8.663291931152344, 790
[INFO] 2021-07-12 18:46:08,292 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.890000233601313e-06, 790
[INFO] 2021-07-12 18:46:08,292 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 790
[INFO] 2021-07-12 18:46:08,292 [run_pretraining.py:  558]:	worker_index: 2, step: 790, cost: 8.663292, mlm loss: 8.663292, speed: 0.040163 steps/s, speed: 0.321300 samples/s, speed: 164.505818 tokens/s, learning rate: 7.890e-06, loss_scalings: 13421.773438, pp_loss: 8.418638
[INFO] 2021-07-12 18:46:08,292 [run_pretraining.py:  512]:	********exe.run_790******* 
[INFO] 2021-07-12 18:46:09,202 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:09,203 [run_pretraining.py:  534]:	loss/total_loss, 8.59611701965332, 791
[INFO] 2021-07-12 18:46:09,203 [run_pretraining.py:  535]:	loss/mlm_loss, 8.59611701965332, 791
[INFO] 2021-07-12 18:46:09,203 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.900000127847306e-06, 791
[INFO] 2021-07-12 18:46:09,203 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 791
[INFO] 2021-07-12 18:46:09,203 [run_pretraining.py:  558]:	worker_index: 2, step: 791, cost: 8.596117, mlm loss: 8.596117, speed: 1.098332 steps/s, speed: 8.786657 samples/s, speed: 4498.768246 tokens/s, learning rate: 7.900e-06, loss_scalings: 13421.773438, pp_loss: 8.538992
[INFO] 2021-07-12 18:46:09,203 [run_pretraining.py:  512]:	********exe.run_791******* 
[INFO] 2021-07-12 18:46:10,131 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:10,131 [run_pretraining.py:  534]:	loss/total_loss, 8.486520767211914, 792
[INFO] 2021-07-12 18:46:10,131 [run_pretraining.py:  535]:	loss/mlm_loss, 8.486520767211914, 792
[INFO] 2021-07-12 18:46:10,132 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.9100000220933e-06, 792
[INFO] 2021-07-12 18:46:10,132 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 792
[INFO] 2021-07-12 18:46:10,132 [run_pretraining.py:  558]:	worker_index: 2, step: 792, cost: 8.486521, mlm loss: 8.486521, speed: 1.077665 steps/s, speed: 8.621319 samples/s, speed: 4414.115303 tokens/s, learning rate: 7.910e-06, loss_scalings: 13421.773438, pp_loss: 7.425581
[INFO] 2021-07-12 18:46:10,132 [run_pretraining.py:  512]:	********exe.run_792******* 
[INFO] 2021-07-12 18:46:11,047 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:11,047 [run_pretraining.py:  534]:	loss/total_loss, 8.306085586547852, 793
[INFO] 2021-07-12 18:46:11,047 [run_pretraining.py:  535]:	loss/mlm_loss, 8.306085586547852, 793
[INFO] 2021-07-12 18:46:11,048 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.919999916339293e-06, 793
[INFO] 2021-07-12 18:46:11,048 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 793
[INFO] 2021-07-12 18:46:11,048 [run_pretraining.py:  558]:	worker_index: 2, step: 793, cost: 8.306086, mlm loss: 8.306086, speed: 1.092387 steps/s, speed: 8.739094 samples/s, speed: 4474.415986 tokens/s, learning rate: 7.920e-06, loss_scalings: 13421.773438, pp_loss: 8.404221
[INFO] 2021-07-12 18:46:11,048 [run_pretraining.py:  512]:	********exe.run_793******* 
[INFO] 2021-07-12 18:46:36,796 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:36,797 [run_pretraining.py:  534]:	loss/total_loss, 8.683838844299316, 794
[INFO] 2021-07-12 18:46:36,797 [run_pretraining.py:  535]:	loss/mlm_loss, 8.683838844299316, 794
[INFO] 2021-07-12 18:46:36,797 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.929999810585286e-06, 794
[INFO] 2021-07-12 18:46:36,797 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 794
[INFO] 2021-07-12 18:46:36,797 [run_pretraining.py:  558]:	worker_index: 2, step: 794, cost: 8.683839, mlm loss: 8.683839, speed: 0.038837 steps/s, speed: 0.310696 samples/s, speed: 159.076354 tokens/s, learning rate: 7.930e-06, loss_scalings: 13421.773438, pp_loss: 8.274165
[INFO] 2021-07-12 18:46:36,797 [run_pretraining.py:  512]:	********exe.run_794******* 
[INFO] 2021-07-12 18:46:37,715 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:37,716 [run_pretraining.py:  534]:	loss/total_loss, 8.234716415405273, 795
[INFO] 2021-07-12 18:46:37,716 [run_pretraining.py:  535]:	loss/mlm_loss, 8.234716415405273, 795
[INFO] 2021-07-12 18:46:37,716 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.93999970483128e-06, 795
[INFO] 2021-07-12 18:46:37,716 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 795
[INFO] 2021-07-12 18:46:37,716 [run_pretraining.py:  558]:	worker_index: 2, step: 795, cost: 8.234716, mlm loss: 8.234716, speed: 1.088708 steps/s, speed: 8.709666 samples/s, speed: 4459.348931 tokens/s, learning rate: 7.940e-06, loss_scalings: 13421.773438, pp_loss: 8.278997
[INFO] 2021-07-12 18:46:37,716 [run_pretraining.py:  512]:	********exe.run_795******* 
[INFO] 2021-07-12 18:46:38,662 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:38,662 [run_pretraining.py:  534]:	loss/total_loss, 8.21349048614502, 796
[INFO] 2021-07-12 18:46:38,662 [run_pretraining.py:  535]:	loss/mlm_loss, 8.21349048614502, 796
[INFO] 2021-07-12 18:46:38,662 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.949999599077273e-06, 796
[INFO] 2021-07-12 18:46:38,663 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 796
[INFO] 2021-07-12 18:46:38,663 [run_pretraining.py:  558]:	worker_index: 2, step: 796, cost: 8.213490, mlm loss: 8.213490, speed: 1.057134 steps/s, speed: 8.457072 samples/s, speed: 4330.020981 tokens/s, learning rate: 7.950e-06, loss_scalings: 13421.773438, pp_loss: 8.299643
[INFO] 2021-07-12 18:46:38,663 [run_pretraining.py:  512]:	********exe.run_796******* 
[INFO] 2021-07-12 18:46:39,747 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:39,748 [run_pretraining.py:  534]:	loss/total_loss, 8.45395278930664, 797
[INFO] 2021-07-12 18:46:39,748 [run_pretraining.py:  535]:	loss/mlm_loss, 8.45395278930664, 797
[INFO] 2021-07-12 18:46:39,748 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.959999493323267e-06, 797
[INFO] 2021-07-12 18:46:39,748 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 797
[INFO] 2021-07-12 18:46:39,748 [run_pretraining.py:  558]:	worker_index: 2, step: 797, cost: 8.453953, mlm loss: 8.453953, speed: 0.921622 steps/s, speed: 7.372978 samples/s, speed: 3774.964933 tokens/s, learning rate: 7.960e-06, loss_scalings: 13421.773438, pp_loss: 8.490986
[INFO] 2021-07-12 18:46:39,748 [run_pretraining.py:  512]:	********exe.run_797******* 
[INFO] 2021-07-12 18:46:40,802 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:40,802 [run_pretraining.py:  534]:	loss/total_loss, 8.225086212158203, 798
[INFO] 2021-07-12 18:46:40,802 [run_pretraining.py:  535]:	loss/mlm_loss, 8.225086212158203, 798
[INFO] 2021-07-12 18:46:40,803 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.970000297063962e-06, 798
[INFO] 2021-07-12 18:46:40,803 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 798
[INFO] 2021-07-12 18:46:40,803 [run_pretraining.py:  558]:	worker_index: 2, step: 798, cost: 8.225086, mlm loss: 8.225086, speed: 0.948850 steps/s, speed: 7.590798 samples/s, speed: 3886.488600 tokens/s, learning rate: 7.970e-06, loss_scalings: 13421.773438, pp_loss: 8.377294
[INFO] 2021-07-12 18:46:40,803 [run_pretraining.py:  512]:	********exe.run_798******* 
[INFO] 2021-07-12 18:46:41,873 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:41,873 [run_pretraining.py:  534]:	loss/total_loss, 8.154389381408691, 799
[INFO] 2021-07-12 18:46:41,873 [run_pretraining.py:  535]:	loss/mlm_loss, 8.154389381408691, 799
[INFO] 2021-07-12 18:46:41,873 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.980000191309955e-06, 799
[INFO] 2021-07-12 18:46:41,874 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 799
[INFO] 2021-07-12 18:46:41,874 [run_pretraining.py:  558]:	worker_index: 2, step: 799, cost: 8.154389, mlm loss: 8.154389, speed: 0.934386 steps/s, speed: 7.475087 samples/s, speed: 3827.244526 tokens/s, learning rate: 7.980e-06, loss_scalings: 13421.773438, pp_loss: 8.402121
[INFO] 2021-07-12 18:46:41,874 [run_pretraining.py:  512]:	********exe.run_799******* 
[INFO] 2021-07-12 18:46:42,809 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:42,809 [run_pretraining.py:  534]:	loss/total_loss, 8.67603874206543, 800
[INFO] 2021-07-12 18:46:42,809 [run_pretraining.py:  535]:	loss/mlm_loss, 8.67603874206543, 800
[INFO] 2021-07-12 18:46:42,809 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.989999176061247e-06, 800
[INFO] 2021-07-12 18:46:42,809 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 800
[INFO] 2021-07-12 18:46:42,809 [run_pretraining.py:  558]:	worker_index: 2, step: 800, cost: 8.676039, mlm loss: 8.676039, speed: 1.069170 steps/s, speed: 8.553356 samples/s, speed: 4379.318443 tokens/s, learning rate: 7.990e-06, loss_scalings: 13421.773438, pp_loss: 8.481079
[INFO] 2021-07-12 18:46:42,810 [run_pretraining.py:  512]:	********exe.run_800******* 
[INFO] 2021-07-12 18:46:43,726 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:43,727 [run_pretraining.py:  534]:	loss/total_loss, 9.008883476257324, 801
[INFO] 2021-07-12 18:46:43,727 [run_pretraining.py:  535]:	loss/mlm_loss, 9.008883476257324, 801
[INFO] 2021-07-12 18:46:43,727 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.999999979801942e-06, 801
[INFO] 2021-07-12 18:46:43,727 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 801
[INFO] 2021-07-12 18:46:43,727 [run_pretraining.py:  558]:	worker_index: 2, step: 801, cost: 9.008883, mlm loss: 9.008883, speed: 1.090530 steps/s, speed: 8.724243 samples/s, speed: 4466.812264 tokens/s, learning rate: 8.000e-06, loss_scalings: 13421.773438, pp_loss: 8.696333
[INFO] 2021-07-12 18:46:43,727 [run_pretraining.py:  512]:	********exe.run_801******* 
[INFO] 2021-07-12 18:46:44,646 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:44,646 [run_pretraining.py:  534]:	loss/total_loss, 8.429014205932617, 802
[INFO] 2021-07-12 18:46:44,646 [run_pretraining.py:  535]:	loss/mlm_loss, 8.429014205932617, 802
[INFO] 2021-07-12 18:46:44,646 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.009999874047935e-06, 802
[INFO] 2021-07-12 18:46:44,646 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 802
[INFO] 2021-07-12 18:46:44,646 [run_pretraining.py:  558]:	worker_index: 2, step: 802, cost: 8.429014, mlm loss: 8.429014, speed: 1.088495 steps/s, speed: 8.707959 samples/s, speed: 4458.475186 tokens/s, learning rate: 8.010e-06, loss_scalings: 13421.773438, pp_loss: 8.568396
[INFO] 2021-07-12 18:46:44,646 [run_pretraining.py:  512]:	********exe.run_802******* 
[INFO] 2021-07-12 18:46:45,565 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:45,566 [run_pretraining.py:  534]:	loss/total_loss, 8.946863174438477, 803
[INFO] 2021-07-12 18:46:45,566 [run_pretraining.py:  535]:	loss/mlm_loss, 8.946863174438477, 803
[INFO] 2021-07-12 18:46:45,566 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.019999768293928e-06, 803
[INFO] 2021-07-12 18:46:45,566 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 803
[INFO] 2021-07-12 18:46:45,566 [run_pretraining.py:  558]:	worker_index: 2, step: 803, cost: 8.946863, mlm loss: 8.946863, speed: 1.088198 steps/s, speed: 8.705583 samples/s, speed: 4457.258299 tokens/s, learning rate: 8.020e-06, loss_scalings: 13421.773438, pp_loss: 8.575311
[INFO] 2021-07-12 18:46:45,566 [run_pretraining.py:  512]:	********exe.run_803******* 
[INFO] 2021-07-12 18:46:46,492 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:46,493 [run_pretraining.py:  534]:	loss/total_loss, 8.42193603515625, 804
[INFO] 2021-07-12 18:46:46,493 [run_pretraining.py:  535]:	loss/mlm_loss, 8.42193603515625, 804
[INFO] 2021-07-12 18:46:46,493 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.030000572034623e-06, 804
[INFO] 2021-07-12 18:46:46,493 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 804
[INFO] 2021-07-12 18:46:46,493 [run_pretraining.py:  558]:	worker_index: 2, step: 804, cost: 8.421936, mlm loss: 8.421936, speed: 1.079482 steps/s, speed: 8.635859 samples/s, speed: 4421.559871 tokens/s, learning rate: 8.030e-06, loss_scalings: 13421.773438, pp_loss: 8.492670
[INFO] 2021-07-12 18:46:46,493 [run_pretraining.py:  512]:	********exe.run_804******* 
[INFO] 2021-07-12 18:46:47,403 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:47,404 [run_pretraining.py:  534]:	loss/total_loss, 8.575244903564453, 805
[INFO] 2021-07-12 18:46:47,404 [run_pretraining.py:  535]:	loss/mlm_loss, 8.575244903564453, 805
[INFO] 2021-07-12 18:46:47,404 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.039999556785915e-06, 805
[INFO] 2021-07-12 18:46:47,404 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 805
[INFO] 2021-07-12 18:46:47,404 [run_pretraining.py:  558]:	worker_index: 2, step: 805, cost: 8.575245, mlm loss: 8.575245, speed: 1.097961 steps/s, speed: 8.783685 samples/s, speed: 4497.246707 tokens/s, learning rate: 8.040e-06, loss_scalings: 13421.773438, pp_loss: 8.565363
[INFO] 2021-07-12 18:46:47,404 [run_pretraining.py:  512]:	********exe.run_805******* 
[INFO] 2021-07-12 18:46:48,394 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:48,394 [run_pretraining.py:  534]:	loss/total_loss, 8.853548049926758, 806
[INFO] 2021-07-12 18:46:48,395 [run_pretraining.py:  535]:	loss/mlm_loss, 8.853548049926758, 806
[INFO] 2021-07-12 18:46:48,395 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.049999451031908e-06, 806
[INFO] 2021-07-12 18:46:48,395 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 806
[INFO] 2021-07-12 18:46:48,395 [run_pretraining.py:  558]:	worker_index: 2, step: 806, cost: 8.853548, mlm loss: 8.853548, speed: 1.010191 steps/s, speed: 8.081524 samples/s, speed: 4137.740402 tokens/s, learning rate: 8.050e-06, loss_scalings: 13421.773438, pp_loss: 8.534996
[INFO] 2021-07-12 18:46:48,395 [run_pretraining.py:  512]:	********exe.run_806******* 
[INFO] 2021-07-12 18:46:49,459 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:49,460 [run_pretraining.py:  534]:	loss/total_loss, 8.188411712646484, 807
[INFO] 2021-07-12 18:46:49,460 [run_pretraining.py:  535]:	loss/mlm_loss, 8.188411712646484, 807
[INFO] 2021-07-12 18:46:49,460 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.060000254772604e-06, 807
[INFO] 2021-07-12 18:46:49,460 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 807
[INFO] 2021-07-12 18:46:49,460 [run_pretraining.py:  558]:	worker_index: 2, step: 807, cost: 8.188412, mlm loss: 8.188412, speed: 0.939037 steps/s, speed: 7.512293 samples/s, speed: 3846.294194 tokens/s, learning rate: 8.060e-06, loss_scalings: 13421.773438, pp_loss: 8.314047
[INFO] 2021-07-12 18:46:49,460 [run_pretraining.py:  512]:	********exe.run_807******* 
[INFO] 2021-07-12 18:46:50,523 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:50,523 [run_pretraining.py:  534]:	loss/total_loss, 8.692588806152344, 808
[INFO] 2021-07-12 18:46:50,523 [run_pretraining.py:  535]:	loss/mlm_loss, 8.692588806152344, 808
[INFO] 2021-07-12 18:46:50,523 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.070000149018597e-06, 808
[INFO] 2021-07-12 18:46:50,523 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 808
[INFO] 2021-07-12 18:46:50,523 [run_pretraining.py:  558]:	worker_index: 2, step: 808, cost: 8.692589, mlm loss: 8.692589, speed: 0.941252 steps/s, speed: 7.530017 samples/s, speed: 3855.368537 tokens/s, learning rate: 8.070e-06, loss_scalings: 13421.773438, pp_loss: 8.503716
[INFO] 2021-07-12 18:46:50,523 [run_pretraining.py:  512]:	********exe.run_808******* 
[INFO] 2021-07-12 18:47:16,738 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:16,738 [run_pretraining.py:  534]:	loss/total_loss, 8.615531921386719, 809
[INFO] 2021-07-12 18:47:16,738 [run_pretraining.py:  535]:	loss/mlm_loss, 8.615531921386719, 809
[INFO] 2021-07-12 18:47:16,739 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.079999133769888e-06, 809
[INFO] 2021-07-12 18:47:16,739 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 809
[INFO] 2021-07-12 18:47:16,739 [run_pretraining.py:  558]:	worker_index: 2, step: 809, cost: 8.615532, mlm loss: 8.615532, speed: 0.038147 steps/s, speed: 0.305172 samples/s, speed: 156.248186 tokens/s, learning rate: 8.080e-06, loss_scalings: 13421.773438, pp_loss: 8.447582
[INFO] 2021-07-12 18:47:16,739 [run_pretraining.py:  512]:	********exe.run_809******* 
[INFO] 2021-07-12 18:47:17,830 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:17,831 [run_pretraining.py:  534]:	loss/total_loss, 7.898068428039551, 810
[INFO] 2021-07-12 18:47:17,831 [run_pretraining.py:  535]:	loss/mlm_loss, 7.898068428039551, 810
[INFO] 2021-07-12 18:47:17,831 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.089999937510584e-06, 810
[INFO] 2021-07-12 18:47:17,831 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 810
[INFO] 2021-07-12 18:47:17,831 [run_pretraining.py:  558]:	worker_index: 2, step: 810, cost: 7.898068, mlm loss: 7.898068, speed: 0.915697 steps/s, speed: 7.325577 samples/s, speed: 3750.695441 tokens/s, learning rate: 8.090e-06, loss_scalings: 13421.773438, pp_loss: 8.318935
[INFO] 2021-07-12 18:47:17,831 [run_pretraining.py:  512]:	********exe.run_810******* 
[INFO] 2021-07-12 18:47:18,753 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:18,753 [run_pretraining.py:  534]:	loss/total_loss, 8.451667785644531, 811
[INFO] 2021-07-12 18:47:18,753 [run_pretraining.py:  535]:	loss/mlm_loss, 8.451667785644531, 811
[INFO] 2021-07-12 18:47:18,754 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.099999831756577e-06, 811
[INFO] 2021-07-12 18:47:18,754 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 811
[INFO] 2021-07-12 18:47:18,754 [run_pretraining.py:  558]:	worker_index: 2, step: 811, cost: 8.451668, mlm loss: 8.451668, speed: 1.084918 steps/s, speed: 8.679342 samples/s, speed: 4443.823151 tokens/s, learning rate: 8.100e-06, loss_scalings: 13421.773438, pp_loss: 8.383490
[INFO] 2021-07-12 18:47:18,754 [run_pretraining.py:  512]:	********exe.run_811******* 
[INFO] 2021-07-12 18:47:19,669 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:19,669 [run_pretraining.py:  534]:	loss/total_loss, 8.93653678894043, 812
[INFO] 2021-07-12 18:47:19,669 [run_pretraining.py:  535]:	loss/mlm_loss, 8.93653678894043, 812
[INFO] 2021-07-12 18:47:19,670 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.10999972600257e-06, 812
[INFO] 2021-07-12 18:47:19,670 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 812
[INFO] 2021-07-12 18:47:19,670 [run_pretraining.py:  558]:	worker_index: 2, step: 812, cost: 8.936537, mlm loss: 8.936537, speed: 1.092440 steps/s, speed: 8.739524 samples/s, speed: 4474.636247 tokens/s, learning rate: 8.110e-06, loss_scalings: 13421.773438, pp_loss: 7.582428
[INFO] 2021-07-12 18:47:19,670 [run_pretraining.py:  512]:	********exe.run_812******* 
[INFO] 2021-07-12 18:47:20,599 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:20,600 [run_pretraining.py:  534]:	loss/total_loss, 8.156438827514648, 813
[INFO] 2021-07-12 18:47:20,600 [run_pretraining.py:  535]:	loss/mlm_loss, 8.156438827514648, 813
[INFO] 2021-07-12 18:47:20,600 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.120000529743265e-06, 813
[INFO] 2021-07-12 18:47:20,600 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 813
[INFO] 2021-07-12 18:47:20,600 [run_pretraining.py:  558]:	worker_index: 2, step: 813, cost: 8.156439, mlm loss: 8.156439, speed: 1.075643 steps/s, speed: 8.605141 samples/s, speed: 4405.832357 tokens/s, learning rate: 8.120e-06, loss_scalings: 13421.773438, pp_loss: 8.332340
[INFO] 2021-07-12 18:47:20,600 [run_pretraining.py:  512]:	********exe.run_813******* 
[INFO] 2021-07-12 18:47:21,518 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:21,518 [run_pretraining.py:  534]:	loss/total_loss, 7.845552921295166, 814
[INFO] 2021-07-12 18:47:21,518 [run_pretraining.py:  535]:	loss/mlm_loss, 7.845552921295166, 814
[INFO] 2021-07-12 18:47:21,519 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.129999514494557e-06, 814
[INFO] 2021-07-12 18:47:21,519 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 814
[INFO] 2021-07-12 18:47:21,519 [run_pretraining.py:  558]:	worker_index: 2, step: 814, cost: 7.845553, mlm loss: 7.845553, speed: 1.089105 steps/s, speed: 8.712837 samples/s, speed: 4460.972345 tokens/s, learning rate: 8.130e-06, loss_scalings: 13421.773438, pp_loss: 8.130594
[INFO] 2021-07-12 18:47:21,519 [run_pretraining.py:  512]:	********exe.run_814******* 
[INFO] 2021-07-12 18:47:22,444 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:22,445 [run_pretraining.py:  534]:	loss/total_loss, 8.62663745880127, 815
[INFO] 2021-07-12 18:47:22,445 [run_pretraining.py:  535]:	loss/mlm_loss, 8.62663745880127, 815
[INFO] 2021-07-12 18:47:22,445 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.13999940874055e-06, 815
[INFO] 2021-07-12 18:47:22,445 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 815
[INFO] 2021-07-12 18:47:22,445 [run_pretraining.py:  558]:	worker_index: 2, step: 815, cost: 8.626637, mlm loss: 8.626637, speed: 1.080307 steps/s, speed: 8.642456 samples/s, speed: 4424.937672 tokens/s, learning rate: 8.140e-06, loss_scalings: 13421.773438, pp_loss: 8.277032
[INFO] 2021-07-12 18:47:22,445 [run_pretraining.py:  512]:	********exe.run_815******* 
[INFO] 2021-07-12 18:47:23,388 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:23,389 [run_pretraining.py:  534]:	loss/total_loss, 7.978103160858154, 816
[INFO] 2021-07-12 18:47:23,389 [run_pretraining.py:  535]:	loss/mlm_loss, 7.978103160858154, 816
[INFO] 2021-07-12 18:47:23,389 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.150000212481245e-06, 816
[INFO] 2021-07-12 18:47:23,389 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 816
[INFO] 2021-07-12 18:47:23,389 [run_pretraining.py:  558]:	worker_index: 2, step: 816, cost: 7.978103, mlm loss: 7.978103, speed: 1.059701 steps/s, speed: 8.477608 samples/s, speed: 4340.535321 tokens/s, learning rate: 8.150e-06, loss_scalings: 13421.773438, pp_loss: 8.226808
[INFO] 2021-07-12 18:47:23,389 [run_pretraining.py:  512]:	********exe.run_816******* 
[INFO] 2021-07-12 18:47:24,309 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:24,310 [run_pretraining.py:  534]:	loss/total_loss, 8.477520942687988, 817
[INFO] 2021-07-12 18:47:24,310 [run_pretraining.py:  535]:	loss/mlm_loss, 8.477520942687988, 817
[INFO] 2021-07-12 18:47:24,310 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.160000106727239e-06, 817
[INFO] 2021-07-12 18:47:24,310 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 817
[INFO] 2021-07-12 18:47:24,310 [run_pretraining.py:  558]:	worker_index: 2, step: 817, cost: 8.477521, mlm loss: 8.477521, speed: 1.086812 steps/s, speed: 8.694493 samples/s, speed: 4451.580578 tokens/s, learning rate: 8.160e-06, loss_scalings: 13421.773438, pp_loss: 8.517097
[INFO] 2021-07-12 18:47:24,310 [run_pretraining.py:  512]:	********exe.run_817******* 
[INFO] 2021-07-12 18:47:25,232 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:25,232 [run_pretraining.py:  534]:	loss/total_loss, 8.226457595825195, 818
[INFO] 2021-07-12 18:47:25,232 [run_pretraining.py:  535]:	loss/mlm_loss, 8.226457595825195, 818
[INFO] 2021-07-12 18:47:25,232 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.16999909147853e-06, 818
[INFO] 2021-07-12 18:47:25,232 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 818
[INFO] 2021-07-12 18:47:25,232 [run_pretraining.py:  558]:	worker_index: 2, step: 818, cost: 8.226458, mlm loss: 8.226458, speed: 1.084911 steps/s, speed: 8.679288 samples/s, speed: 4443.795564 tokens/s, learning rate: 8.170e-06, loss_scalings: 13421.773438, pp_loss: 8.303811
[INFO] 2021-07-12 18:47:25,232 [run_pretraining.py:  512]:	********exe.run_818******* 
[INFO] 2021-07-12 18:47:26,147 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:26,148 [run_pretraining.py:  534]:	loss/total_loss, 8.70804214477539, 819
[INFO] 2021-07-12 18:47:26,148 [run_pretraining.py:  535]:	loss/mlm_loss, 8.70804214477539, 819
[INFO] 2021-07-12 18:47:26,148 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.179999895219225e-06, 819
[INFO] 2021-07-12 18:47:26,148 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 819
[INFO] 2021-07-12 18:47:26,148 [run_pretraining.py:  558]:	worker_index: 2, step: 819, cost: 8.708042, mlm loss: 8.708042, speed: 1.092604 steps/s, speed: 8.740828 samples/s, speed: 4475.304152 tokens/s, learning rate: 8.180e-06, loss_scalings: 13421.773438, pp_loss: 8.428377
[INFO] 2021-07-12 18:47:26,148 [run_pretraining.py:  512]:	********exe.run_819******* 
[INFO] 2021-07-12 18:47:27,061 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:27,062 [run_pretraining.py:  534]:	loss/total_loss, 8.46656608581543, 820
[INFO] 2021-07-12 18:47:27,062 [run_pretraining.py:  535]:	loss/mlm_loss, 8.46656608581543, 820
[INFO] 2021-07-12 18:47:27,062 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.189999789465219e-06, 820
[INFO] 2021-07-12 18:47:27,062 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 820
[INFO] 2021-07-12 18:47:27,062 [run_pretraining.py:  558]:	worker_index: 2, step: 820, cost: 8.466566, mlm loss: 8.466566, speed: 1.095010 steps/s, speed: 8.760084 samples/s, speed: 4485.162870 tokens/s, learning rate: 8.190e-06, loss_scalings: 13421.773438, pp_loss: 8.592456
[INFO] 2021-07-12 18:47:27,062 [run_pretraining.py:  512]:	********exe.run_820******* 
[INFO] 2021-07-12 18:47:28,015 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:28,016 [run_pretraining.py:  534]:	loss/total_loss, 9.101615905761719, 821
[INFO] 2021-07-12 18:47:28,016 [run_pretraining.py:  535]:	loss/mlm_loss, 9.101615905761719, 821
[INFO] 2021-07-12 18:47:28,016 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.199999683711212e-06, 821
[INFO] 2021-07-12 18:47:28,016 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 821
[INFO] 2021-07-12 18:47:28,016 [run_pretraining.py:  558]:	worker_index: 2, step: 821, cost: 9.101616, mlm loss: 9.101616, speed: 1.048687 steps/s, speed: 8.389499 samples/s, speed: 4295.423685 tokens/s, learning rate: 8.200e-06, loss_scalings: 13421.773438, pp_loss: 8.505007
[INFO] 2021-07-12 18:47:28,016 [run_pretraining.py:  512]:	********exe.run_821******* 
[INFO] 2021-07-12 18:47:29,028 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:29,028 [run_pretraining.py:  534]:	loss/total_loss, 7.946794509887695, 822
[INFO] 2021-07-12 18:47:29,028 [run_pretraining.py:  535]:	loss/mlm_loss, 7.946794509887695, 822
[INFO] 2021-07-12 18:47:29,028 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.209999577957205e-06, 822
[INFO] 2021-07-12 18:47:29,028 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 822
[INFO] 2021-07-12 18:47:29,028 [run_pretraining.py:  558]:	worker_index: 2, step: 822, cost: 7.946795, mlm loss: 7.946795, speed: 0.988485 steps/s, speed: 7.907880 samples/s, speed: 4048.834592 tokens/s, learning rate: 8.210e-06, loss_scalings: 13421.773438, pp_loss: 8.166729
[INFO] 2021-07-12 18:47:29,029 [run_pretraining.py:  512]:	********exe.run_822******* 
[INFO] 2021-07-12 18:47:30,093 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:30,094 [run_pretraining.py:  534]:	loss/total_loss, 8.006393432617188, 823
[INFO] 2021-07-12 18:47:30,094 [run_pretraining.py:  535]:	loss/mlm_loss, 8.006393432617188, 823
[INFO] 2021-07-12 18:47:30,094 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.219999472203199e-06, 823
[INFO] 2021-07-12 18:47:30,094 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 823
[INFO] 2021-07-12 18:47:30,094 [run_pretraining.py:  558]:	worker_index: 2, step: 823, cost: 8.006393, mlm loss: 8.006393, speed: 0.938913 steps/s, speed: 7.511308 samples/s, speed: 3845.789642 tokens/s, learning rate: 8.220e-06, loss_scalings: 13421.773438, pp_loss: 7.593205
[INFO] 2021-07-12 18:47:30,094 [run_pretraining.py:  512]:	********exe.run_823******* 
[INFO] 2021-07-12 18:47:31,135 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:31,136 [run_pretraining.py:  534]:	loss/total_loss, 8.548543930053711, 824
[INFO] 2021-07-12 18:47:31,136 [run_pretraining.py:  535]:	loss/mlm_loss, 8.548543930053711, 824
[INFO] 2021-07-12 18:47:31,136 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.229999366449192e-06, 824
[INFO] 2021-07-12 18:47:31,136 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 824
[INFO] 2021-07-12 18:47:31,136 [run_pretraining.py:  558]:	worker_index: 2, step: 824, cost: 8.548544, mlm loss: 8.548544, speed: 0.960300 steps/s, speed: 7.682398 samples/s, speed: 3933.387683 tokens/s, learning rate: 8.230e-06, loss_scalings: 13421.773438, pp_loss: 8.519299
[INFO] 2021-07-12 18:47:31,136 [run_pretraining.py:  512]:	********exe.run_824******* 
[INFO] 2021-07-12 18:47:32,201 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:32,201 [run_pretraining.py:  534]:	loss/total_loss, 10.376325607299805, 825
[INFO] 2021-07-12 18:47:32,201 [run_pretraining.py:  535]:	loss/mlm_loss, 10.376325607299805, 825
[INFO] 2021-07-12 18:47:32,201 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.240000170189887e-06, 825
[INFO] 2021-07-12 18:47:32,201 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 825
[INFO] 2021-07-12 18:47:32,202 [run_pretraining.py:  558]:	worker_index: 2, step: 825, cost: 10.376326, mlm loss: 10.376326, speed: 0.939092 steps/s, speed: 7.512734 samples/s, speed: 3846.519821 tokens/s, learning rate: 8.240e-06, loss_scalings: 13421.773438, pp_loss: 8.725039
[INFO] 2021-07-12 18:47:32,202 [run_pretraining.py:  512]:	********exe.run_825******* 
[INFO] 2021-07-12 18:47:33,266 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:33,266 [run_pretraining.py:  534]:	loss/total_loss, 8.306985855102539, 826
[INFO] 2021-07-12 18:47:33,266 [run_pretraining.py:  535]:	loss/mlm_loss, 8.306985855102539, 826
[INFO] 2021-07-12 18:47:33,266 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.25000006443588e-06, 826
[INFO] 2021-07-12 18:47:33,266 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 826
[INFO] 2021-07-12 18:47:33,267 [run_pretraining.py:  558]:	worker_index: 2, step: 826, cost: 8.306986, mlm loss: 8.306986, speed: 0.939479 steps/s, speed: 7.515835 samples/s, speed: 3848.107712 tokens/s, learning rate: 8.250e-06, loss_scalings: 13421.773438, pp_loss: 7.857074
[INFO] 2021-07-12 18:47:33,267 [run_pretraining.py:  512]:	********exe.run_826******* 
[INFO] 2021-07-12 18:47:34,333 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:34,334 [run_pretraining.py:  534]:	loss/total_loss, 8.340154647827148, 827
[INFO] 2021-07-12 18:47:34,334 [run_pretraining.py:  535]:	loss/mlm_loss, 8.340154647827148, 827
[INFO] 2021-07-12 18:47:34,334 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.259999958681874e-06, 827
[INFO] 2021-07-12 18:47:34,334 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 827
[INFO] 2021-07-12 18:47:34,334 [run_pretraining.py:  558]:	worker_index: 2, step: 827, cost: 8.340155, mlm loss: 8.340155, speed: 0.937088 steps/s, speed: 7.496706 samples/s, speed: 3838.313539 tokens/s, learning rate: 8.260e-06, loss_scalings: 13421.773438, pp_loss: 8.218469
[INFO] 2021-07-12 18:47:34,334 [run_pretraining.py:  512]:	********exe.run_827******* 
[INFO] 2021-07-12 18:47:35,404 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:35,405 [run_pretraining.py:  534]:	loss/total_loss, 8.031729698181152, 828
[INFO] 2021-07-12 18:47:35,405 [run_pretraining.py:  535]:	loss/mlm_loss, 8.031729698181152, 828
[INFO] 2021-07-12 18:47:35,405 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.269999852927867e-06, 828
[INFO] 2021-07-12 18:47:35,405 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 828
[INFO] 2021-07-12 18:47:35,405 [run_pretraining.py:  558]:	worker_index: 2, step: 828, cost: 8.031730, mlm loss: 8.031730, speed: 0.934328 steps/s, speed: 7.474627 samples/s, speed: 3827.009219 tokens/s, learning rate: 8.270e-06, loss_scalings: 13421.773438, pp_loss: 7.544866
[INFO] 2021-07-12 18:47:35,405 [run_pretraining.py:  512]:	********exe.run_828******* 
[INFO] 2021-07-12 18:47:36,467 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:36,468 [run_pretraining.py:  534]:	loss/total_loss, 8.166264533996582, 829
[INFO] 2021-07-12 18:47:36,468 [run_pretraining.py:  535]:	loss/mlm_loss, 8.166264533996582, 829
[INFO] 2021-07-12 18:47:36,468 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.27999974717386e-06, 829
[INFO] 2021-07-12 18:47:36,468 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 829
[INFO] 2021-07-12 18:47:36,468 [run_pretraining.py:  558]:	worker_index: 2, step: 829, cost: 8.166265, mlm loss: 8.166265, speed: 0.941274 steps/s, speed: 7.530196 samples/s, speed: 3855.460249 tokens/s, learning rate: 8.280e-06, loss_scalings: 13421.773438, pp_loss: 8.493176
[INFO] 2021-07-12 18:47:36,468 [run_pretraining.py:  512]:	********exe.run_829******* 
[INFO] 2021-07-12 18:47:37,540 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:37,540 [run_pretraining.py:  534]:	loss/total_loss, 8.220805168151855, 830
[INFO] 2021-07-12 18:47:37,540 [run_pretraining.py:  535]:	loss/mlm_loss, 8.220805168151855, 830
[INFO] 2021-07-12 18:47:37,540 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.289999641419854e-06, 830
[INFO] 2021-07-12 18:47:37,541 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 830
[INFO] 2021-07-12 18:47:37,541 [run_pretraining.py:  558]:	worker_index: 2, step: 830, cost: 8.220805, mlm loss: 8.220805, speed: 0.932931 steps/s, speed: 7.463445 samples/s, speed: 3821.283820 tokens/s, learning rate: 8.290e-06, loss_scalings: 13421.773438, pp_loss: 8.221016
[INFO] 2021-07-12 18:47:37,541 [run_pretraining.py:  512]:	********exe.run_830******* 
[INFO] 2021-07-12 18:47:38,609 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:38,610 [run_pretraining.py:  534]:	loss/total_loss, 8.171074867248535, 831
[INFO] 2021-07-12 18:47:38,610 [run_pretraining.py:  535]:	loss/mlm_loss, 8.171074867248535, 831
[INFO] 2021-07-12 18:47:38,610 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.299999535665847e-06, 831
[INFO] 2021-07-12 18:47:38,610 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 831
[INFO] 2021-07-12 18:47:38,610 [run_pretraining.py:  558]:	worker_index: 2, step: 831, cost: 8.171075, mlm loss: 8.171075, speed: 0.935609 steps/s, speed: 7.484870 samples/s, speed: 3832.253361 tokens/s, learning rate: 8.300e-06, loss_scalings: 13421.773438, pp_loss: 8.270610
[INFO] 2021-07-12 18:47:38,610 [run_pretraining.py:  512]:	********exe.run_831******* 
[INFO] 2021-07-12 18:47:39,672 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:39,672 [run_pretraining.py:  534]:	loss/total_loss, 8.470553398132324, 832
[INFO] 2021-07-12 18:47:39,672 [run_pretraining.py:  535]:	loss/mlm_loss, 8.470553398132324, 832
[INFO] 2021-07-12 18:47:39,672 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.30999942991184e-06, 832
[INFO] 2021-07-12 18:47:39,673 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 832
[INFO] 2021-07-12 18:47:39,673 [run_pretraining.py:  558]:	worker_index: 2, step: 832, cost: 8.470553, mlm loss: 8.470553, speed: 0.941627 steps/s, speed: 7.533012 samples/s, speed: 3856.902265 tokens/s, learning rate: 8.310e-06, loss_scalings: 13421.773438, pp_loss: 8.126085
[INFO] 2021-07-12 18:47:39,673 [run_pretraining.py:  512]:	********exe.run_832******* 
[INFO] 2021-07-12 18:47:40,738 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:40,738 [run_pretraining.py:  534]:	loss/total_loss, 8.078556060791016, 833
[INFO] 2021-07-12 18:47:40,739 [run_pretraining.py:  535]:	loss/mlm_loss, 8.078556060791016, 833
[INFO] 2021-07-12 18:47:40,739 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.320000233652536e-06, 833
[INFO] 2021-07-12 18:47:40,739 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 833
[INFO] 2021-07-12 18:47:40,739 [run_pretraining.py:  558]:	worker_index: 2, step: 833, cost: 8.078556, mlm loss: 8.078556, speed: 0.938443 steps/s, speed: 7.507542 samples/s, speed: 3843.861339 tokens/s, learning rate: 8.320e-06, loss_scalings: 13421.773438, pp_loss: 8.395858
[INFO] 2021-07-12 18:47:40,739 [run_pretraining.py:  512]:	********exe.run_833******* 
[INFO] 2021-07-12 18:47:41,733 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:41,733 [run_pretraining.py:  534]:	loss/total_loss, 8.20595932006836, 834
[INFO] 2021-07-12 18:47:41,733 [run_pretraining.py:  535]:	loss/mlm_loss, 8.20595932006836, 834
[INFO] 2021-07-12 18:47:41,733 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.33000012789853e-06, 834
[INFO] 2021-07-12 18:47:41,734 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 834
[INFO] 2021-07-12 18:47:41,734 [run_pretraining.py:  558]:	worker_index: 2, step: 834, cost: 8.205959, mlm loss: 8.205959, speed: 1.005863 steps/s, speed: 8.046906 samples/s, speed: 4120.015968 tokens/s, learning rate: 8.330e-06, loss_scalings: 13421.773438, pp_loss: 8.217831
[INFO] 2021-07-12 18:47:41,734 [run_pretraining.py:  512]:	********exe.run_834******* 
[INFO] 2021-07-12 18:47:42,649 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:42,649 [run_pretraining.py:  534]:	loss/total_loss, 8.43630313873291, 835
[INFO] 2021-07-12 18:47:42,649 [run_pretraining.py:  535]:	loss/mlm_loss, 8.43630313873291, 835
[INFO] 2021-07-12 18:47:42,650 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.340000022144523e-06, 835
[INFO] 2021-07-12 18:47:42,650 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 835
[INFO] 2021-07-12 18:47:42,650 [run_pretraining.py:  558]:	worker_index: 2, step: 835, cost: 8.436303, mlm loss: 8.436303, speed: 1.092253 steps/s, speed: 8.738024 samples/s, speed: 4473.868343 tokens/s, learning rate: 8.340e-06, loss_scalings: 13421.773438, pp_loss: 8.285599
[INFO] 2021-07-12 18:47:42,650 [run_pretraining.py:  512]:	********exe.run_835******* 
[INFO] 2021-07-12 18:47:43,564 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:43,565 [run_pretraining.py:  534]:	loss/total_loss, 8.441329956054688, 836
[INFO] 2021-07-12 18:47:43,565 [run_pretraining.py:  535]:	loss/mlm_loss, 8.441329956054688, 836
[INFO] 2021-07-12 18:47:43,565 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.349999916390516e-06, 836
[INFO] 2021-07-12 18:47:43,565 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 836
[INFO] 2021-07-12 18:47:43,565 [run_pretraining.py:  558]:	worker_index: 2, step: 836, cost: 8.441330, mlm loss: 8.441330, speed: 1.093024 steps/s, speed: 8.744195 samples/s, speed: 4477.027873 tokens/s, learning rate: 8.350e-06, loss_scalings: 13421.773438, pp_loss: 8.061838
[INFO] 2021-07-12 18:47:43,565 [run_pretraining.py:  512]:	********exe.run_836******* 
[INFO] 2021-07-12 18:47:44,483 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:44,484 [run_pretraining.py:  534]:	loss/total_loss, 7.982751846313477, 837
[INFO] 2021-07-12 18:47:44,484 [run_pretraining.py:  535]:	loss/mlm_loss, 7.982751846313477, 837
[INFO] 2021-07-12 18:47:44,484 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.35999981063651e-06, 837
[INFO] 2021-07-12 18:47:44,484 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 837
[INFO] 2021-07-12 18:47:44,484 [run_pretraining.py:  558]:	worker_index: 2, step: 837, cost: 7.982752, mlm loss: 7.982752, speed: 1.089010 steps/s, speed: 8.712079 samples/s, speed: 4460.584332 tokens/s, learning rate: 8.360e-06, loss_scalings: 13421.773438, pp_loss: 7.396374
[INFO] 2021-07-12 18:47:44,484 [run_pretraining.py:  512]:	********exe.run_837******* 
[INFO] 2021-07-12 18:47:45,401 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:45,402 [run_pretraining.py:  534]:	loss/total_loss, 8.376626014709473, 838
[INFO] 2021-07-12 18:47:45,402 [run_pretraining.py:  535]:	loss/mlm_loss, 8.376626014709473, 838
[INFO] 2021-07-12 18:47:45,402 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.369999704882503e-06, 838
[INFO] 2021-07-12 18:47:45,402 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 838
[INFO] 2021-07-12 18:47:45,402 [run_pretraining.py:  558]:	worker_index: 2, step: 838, cost: 8.376626, mlm loss: 8.376626, speed: 1.089907 steps/s, speed: 8.719253 samples/s, speed: 4464.257522 tokens/s, learning rate: 8.370e-06, loss_scalings: 13421.773438, pp_loss: 8.325359
[INFO] 2021-07-12 18:47:45,402 [run_pretraining.py:  512]:	********exe.run_838******* 
[INFO] 2021-07-12 18:47:46,319 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:46,320 [run_pretraining.py:  534]:	loss/total_loss, 8.628222465515137, 839
[INFO] 2021-07-12 18:47:46,320 [run_pretraining.py:  535]:	loss/mlm_loss, 8.628222465515137, 839
[INFO] 2021-07-12 18:47:46,320 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.380000508623198e-06, 839
[INFO] 2021-07-12 18:47:46,320 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 839
[INFO] 2021-07-12 18:47:46,320 [run_pretraining.py:  558]:	worker_index: 2, step: 839, cost: 8.628222, mlm loss: 8.628222, speed: 1.089966 steps/s, speed: 8.719724 samples/s, speed: 4464.498826 tokens/s, learning rate: 8.380e-06, loss_scalings: 13421.773438, pp_loss: 8.422718
[INFO] 2021-07-12 18:47:46,320 [run_pretraining.py:  512]:	********exe.run_839******* 
[INFO] 2021-07-12 18:47:47,250 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:47,250 [run_pretraining.py:  534]:	loss/total_loss, 7.951486587524414, 840
[INFO] 2021-07-12 18:47:47,250 [run_pretraining.py:  535]:	loss/mlm_loss, 7.951486587524414, 840
[INFO] 2021-07-12 18:47:47,250 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.38999949337449e-06, 840
[INFO] 2021-07-12 18:47:47,250 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 840
[INFO] 2021-07-12 18:47:47,251 [run_pretraining.py:  558]:	worker_index: 2, step: 840, cost: 7.951487, mlm loss: 7.951487, speed: 1.075643 steps/s, speed: 8.605146 samples/s, speed: 4405.834617 tokens/s, learning rate: 8.390e-06, loss_scalings: 13421.773438, pp_loss: 8.057964
[INFO] 2021-07-12 18:47:47,251 [run_pretraining.py:  512]:	********exe.run_840******* 
[INFO] 2021-07-12 18:47:48,310 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:48,310 [run_pretraining.py:  534]:	loss/total_loss, 7.986123085021973, 841
[INFO] 2021-07-12 18:47:48,310 [run_pretraining.py:  535]:	loss/mlm_loss, 7.986123085021973, 841
[INFO] 2021-07-12 18:47:48,310 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.399999387620483e-06, 841
[INFO] 2021-07-12 18:47:48,311 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 841
[INFO] 2021-07-12 18:47:48,311 [run_pretraining.py:  558]:	worker_index: 2, step: 841, cost: 7.986123, mlm loss: 7.986123, speed: 0.943874 steps/s, speed: 7.550995 samples/s, speed: 3866.109441 tokens/s, learning rate: 8.400e-06, loss_scalings: 13421.773438, pp_loss: 8.125872
[INFO] 2021-07-12 18:47:48,311 [run_pretraining.py:  512]:	********exe.run_841******* 
[INFO] 2021-07-12 18:47:49,369 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:49,369 [run_pretraining.py:  534]:	loss/total_loss, 8.421453475952148, 842
[INFO] 2021-07-12 18:47:49,369 [run_pretraining.py:  535]:	loss/mlm_loss, 8.421453475952148, 842
[INFO] 2021-07-12 18:47:49,369 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.410000191361178e-06, 842
[INFO] 2021-07-12 18:47:49,369 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 842
[INFO] 2021-07-12 18:47:49,370 [run_pretraining.py:  558]:	worker_index: 2, step: 842, cost: 8.421453, mlm loss: 8.421453, speed: 0.944870 steps/s, speed: 7.558963 samples/s, speed: 3870.188907 tokens/s, learning rate: 8.410e-06, loss_scalings: 13421.773438, pp_loss: 8.341299
[INFO] 2021-07-12 18:47:49,370 [run_pretraining.py:  512]:	********exe.run_842******* 
[INFO] 2021-07-12 18:47:50,433 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:50,433 [run_pretraining.py:  534]:	loss/total_loss, 8.210777282714844, 843
[INFO] 2021-07-12 18:47:50,434 [run_pretraining.py:  535]:	loss/mlm_loss, 8.210777282714844, 843
[INFO] 2021-07-12 18:47:50,434 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.420000085607171e-06, 843
[INFO] 2021-07-12 18:47:50,434 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 843
[INFO] 2021-07-12 18:47:50,434 [run_pretraining.py:  558]:	worker_index: 2, step: 843, cost: 8.210777, mlm loss: 8.210777, speed: 0.940149 steps/s, speed: 7.521193 samples/s, speed: 3850.850619 tokens/s, learning rate: 8.420e-06, loss_scalings: 13421.773438, pp_loss: 8.182812
[INFO] 2021-07-12 18:47:50,434 [run_pretraining.py:  512]:	********exe.run_843******* 
[INFO] 2021-07-12 18:47:51,498 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:51,498 [run_pretraining.py:  534]:	loss/total_loss, 8.335886001586914, 844
[INFO] 2021-07-12 18:47:51,498 [run_pretraining.py:  535]:	loss/mlm_loss, 8.335886001586914, 844
[INFO] 2021-07-12 18:47:51,498 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.429999070358463e-06, 844
[INFO] 2021-07-12 18:47:51,498 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 844
[INFO] 2021-07-12 18:47:51,498 [run_pretraining.py:  558]:	worker_index: 2, step: 844, cost: 8.335886, mlm loss: 8.335886, speed: 0.939861 steps/s, speed: 7.518887 samples/s, speed: 3849.670173 tokens/s, learning rate: 8.430e-06, loss_scalings: 13421.773438, pp_loss: 8.362766
[INFO] 2021-07-12 18:47:51,498 [run_pretraining.py:  512]:	********exe.run_844******* 
[INFO] 2021-07-12 18:47:52,557 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:52,557 [run_pretraining.py:  534]:	loss/total_loss, 3.9782042503356934, 845
[INFO] 2021-07-12 18:47:52,558 [run_pretraining.py:  535]:	loss/mlm_loss, 3.9782042503356934, 845
[INFO] 2021-07-12 18:47:52,558 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.439999874099158e-06, 845
[INFO] 2021-07-12 18:47:52,558 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 845
[INFO] 2021-07-12 18:47:52,558 [run_pretraining.py:  558]:	worker_index: 2, step: 845, cost: 3.978204, mlm loss: 3.978204, speed: 0.944470 steps/s, speed: 7.555759 samples/s, speed: 3868.548771 tokens/s, learning rate: 8.440e-06, loss_scalings: 13421.773438, pp_loss: 7.090227
[INFO] 2021-07-12 18:47:52,558 [run_pretraining.py:  512]:	********exe.run_845******* 
[INFO] 2021-07-12 18:47:53,624 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:53,625 [run_pretraining.py:  534]:	loss/total_loss, 8.135631561279297, 846
[INFO] 2021-07-12 18:47:53,625 [run_pretraining.py:  535]:	loss/mlm_loss, 8.135631561279297, 846
[INFO] 2021-07-12 18:47:53,625 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.449999768345151e-06, 846
[INFO] 2021-07-12 18:47:53,625 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 846
[INFO] 2021-07-12 18:47:53,625 [run_pretraining.py:  558]:	worker_index: 2, step: 846, cost: 8.135632, mlm loss: 8.135632, speed: 0.937450 steps/s, speed: 7.499596 samples/s, speed: 3839.793388 tokens/s, learning rate: 8.450e-06, loss_scalings: 13421.773438, pp_loss: 7.143351
[INFO] 2021-07-12 18:47:53,625 [run_pretraining.py:  512]:	********exe.run_846******* 
[INFO] 2021-07-12 18:47:54,679 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:54,680 [run_pretraining.py:  534]:	loss/total_loss, 7.823002815246582, 847
[INFO] 2021-07-12 18:47:54,680 [run_pretraining.py:  535]:	loss/mlm_loss, 7.823002815246582, 847
[INFO] 2021-07-12 18:47:54,680 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.459999662591144e-06, 847
[INFO] 2021-07-12 18:47:54,680 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 847
[INFO] 2021-07-12 18:47:54,680 [run_pretraining.py:  558]:	worker_index: 2, step: 847, cost: 7.823003, mlm loss: 7.823003, speed: 0.948538 steps/s, speed: 7.588305 samples/s, speed: 3885.212399 tokens/s, learning rate: 8.460e-06, loss_scalings: 13421.773438, pp_loss: 8.140475
[INFO] 2021-07-12 18:47:54,680 [run_pretraining.py:  512]:	********exe.run_847******* 
[INFO] 2021-07-12 18:47:55,754 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:55,754 [run_pretraining.py:  534]:	loss/total_loss, 8.071950912475586, 848
[INFO] 2021-07-12 18:47:55,754 [run_pretraining.py:  535]:	loss/mlm_loss, 8.071950912475586, 848
[INFO] 2021-07-12 18:47:55,755 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.47000046633184e-06, 848
[INFO] 2021-07-12 18:47:55,755 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 848
[INFO] 2021-07-12 18:47:55,755 [run_pretraining.py:  558]:	worker_index: 2, step: 848, cost: 8.071951, mlm loss: 8.071951, speed: 0.930920 steps/s, speed: 7.447360 samples/s, speed: 3813.048490 tokens/s, learning rate: 8.470e-06, loss_scalings: 13421.773438, pp_loss: 8.272850
[INFO] 2021-07-12 18:47:55,755 [run_pretraining.py:  512]:	********exe.run_848******* 
[INFO] 2021-07-12 18:47:56,819 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:56,819 [run_pretraining.py:  534]:	loss/total_loss, 7.8224921226501465, 849
[INFO] 2021-07-12 18:47:56,819 [run_pretraining.py:  535]:	loss/mlm_loss, 7.8224921226501465, 849
[INFO] 2021-07-12 18:47:56,820 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.479999451083131e-06, 849
[INFO] 2021-07-12 18:47:56,820 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 849
[INFO] 2021-07-12 18:47:56,820 [run_pretraining.py:  558]:	worker_index: 2, step: 849, cost: 7.822492, mlm loss: 7.822492, speed: 0.939510 steps/s, speed: 7.516079 samples/s, speed: 3848.232697 tokens/s, learning rate: 8.480e-06, loss_scalings: 13421.773438, pp_loss: 8.235073
[INFO] 2021-07-12 18:47:56,820 [run_pretraining.py:  512]:	********exe.run_849******* 
[INFO] 2021-07-12 18:47:57,884 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:57,885 [run_pretraining.py:  534]:	loss/total_loss, 8.388151168823242, 850
[INFO] 2021-07-12 18:47:57,885 [run_pretraining.py:  535]:	loss/mlm_loss, 8.388151168823242, 850
[INFO] 2021-07-12 18:47:57,885 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.489999345329124e-06, 850
[INFO] 2021-07-12 18:47:57,885 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 850
[INFO] 2021-07-12 18:47:57,885 [run_pretraining.py:  558]:	worker_index: 2, step: 850, cost: 8.388151, mlm loss: 8.388151, speed: 0.939262 steps/s, speed: 7.514098 samples/s, speed: 3847.218401 tokens/s, learning rate: 8.490e-06, loss_scalings: 13421.773438, pp_loss: 8.306295
[INFO] 2021-07-12 18:47:57,885 [run_pretraining.py:  512]:	********exe.run_850******* 
[INFO] 2021-07-12 18:47:59,145 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:59,151 [run_pretraining.py:  534]:	loss/total_loss, 8.073138236999512, 851
[INFO] 2021-07-12 18:47:59,156 [run_pretraining.py:  535]:	loss/mlm_loss, 8.073138236999512, 851
[INFO] 2021-07-12 18:47:59,161 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.50000014906982e-06, 851
[INFO] 2021-07-12 18:47:59,166 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 851
[INFO] 2021-07-12 18:47:59,171 [run_pretraining.py:  558]:	worker_index: 2, step: 851, cost: 8.073138, mlm loss: 8.073138, speed: 0.790306 steps/s, speed: 6.322447 samples/s, speed: 3237.092689 tokens/s, learning rate: 8.500e-06, loss_scalings: 13421.773438, pp_loss: 8.323628
[INFO] 2021-07-12 18:47:59,171 [run_pretraining.py:  512]:	********exe.run_851******* 
[INFO] 2021-07-12 18:48:00,188 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:00,188 [run_pretraining.py:  534]:	loss/total_loss, 8.409994125366211, 852
[INFO] 2021-07-12 18:48:00,189 [run_pretraining.py:  535]:	loss/mlm_loss, 8.409994125366211, 852
[INFO] 2021-07-12 18:48:00,189 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.510000043315813e-06, 852
[INFO] 2021-07-12 18:48:00,189 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 852
[INFO] 2021-07-12 18:48:00,189 [run_pretraining.py:  558]:	worker_index: 2, step: 852, cost: 8.409994, mlm loss: 8.409994, speed: 0.983344 steps/s, speed: 7.866753 samples/s, speed: 4027.777619 tokens/s, learning rate: 8.510e-06, loss_scalings: 13421.773438, pp_loss: 8.476472
[INFO] 2021-07-12 18:48:00,189 [run_pretraining.py:  512]:	********exe.run_852******* 
[INFO] 2021-07-12 18:48:01,251 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:01,251 [run_pretraining.py:  534]:	loss/total_loss, 8.471163749694824, 853
[INFO] 2021-07-12 18:48:01,251 [run_pretraining.py:  535]:	loss/mlm_loss, 8.471163749694824, 853
[INFO] 2021-07-12 18:48:01,252 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.519999028067105e-06, 853
[INFO] 2021-07-12 18:48:01,252 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 853
[INFO] 2021-07-12 18:48:01,252 [run_pretraining.py:  558]:	worker_index: 2, step: 853, cost: 8.471164, mlm loss: 8.471164, speed: 0.941380 steps/s, speed: 7.531041 samples/s, speed: 3855.892914 tokens/s, learning rate: 8.520e-06, loss_scalings: 13421.773438, pp_loss: 8.364007
[INFO] 2021-07-12 18:48:01,252 [run_pretraining.py:  512]:	********exe.run_853******* 
[INFO] 2021-07-12 18:48:02,373 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:02,373 [run_pretraining.py:  534]:	loss/total_loss, 8.19560432434082, 854
[INFO] 2021-07-12 18:48:02,373 [run_pretraining.py:  535]:	loss/mlm_loss, 8.19560432434082, 854
[INFO] 2021-07-12 18:48:02,374 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.5299998318078e-06, 854
[INFO] 2021-07-12 18:48:02,374 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 854
[INFO] 2021-07-12 18:48:02,374 [run_pretraining.py:  558]:	worker_index: 2, step: 854, cost: 8.195604, mlm loss: 8.195604, speed: 0.891743 steps/s, speed: 7.133944 samples/s, speed: 3652.579081 tokens/s, learning rate: 8.530e-06, loss_scalings: 13421.773438, pp_loss: 8.269085
[INFO] 2021-07-12 18:48:02,374 [run_pretraining.py:  512]:	********exe.run_854******* 
[INFO] 2021-07-12 18:48:03,442 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:03,442 [run_pretraining.py:  534]:	loss/total_loss, 8.319280624389648, 855
[INFO] 2021-07-12 18:48:03,442 [run_pretraining.py:  535]:	loss/mlm_loss, 8.319280624389648, 855
[INFO] 2021-07-12 18:48:03,442 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.539999726053793e-06, 855
[INFO] 2021-07-12 18:48:03,442 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 855
[INFO] 2021-07-12 18:48:03,443 [run_pretraining.py:  558]:	worker_index: 2, step: 855, cost: 8.319281, mlm loss: 8.319281, speed: 0.936126 steps/s, speed: 7.489009 samples/s, speed: 3834.372844 tokens/s, learning rate: 8.540e-06, loss_scalings: 13421.773438, pp_loss: 8.218651
[INFO] 2021-07-12 18:48:03,443 [run_pretraining.py:  512]:	********exe.run_855******* 
[INFO] 2021-07-12 18:48:04,507 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:04,507 [run_pretraining.py:  534]:	loss/total_loss, 8.145031929016113, 856
[INFO] 2021-07-12 18:48:04,507 [run_pretraining.py:  535]:	loss/mlm_loss, 8.145031929016113, 856
[INFO] 2021-07-12 18:48:04,507 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.549999620299786e-06, 856
[INFO] 2021-07-12 18:48:04,507 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 856
[INFO] 2021-07-12 18:48:04,508 [run_pretraining.py:  558]:	worker_index: 2, step: 856, cost: 8.145032, mlm loss: 8.145032, speed: 0.939503 steps/s, speed: 7.516026 samples/s, speed: 3848.205113 tokens/s, learning rate: 8.550e-06, loss_scalings: 13421.773438, pp_loss: 8.163341
[INFO] 2021-07-12 18:48:04,508 [run_pretraining.py:  512]:	********exe.run_856******* 
[INFO] 2021-07-12 18:48:05,538 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:05,538 [run_pretraining.py:  534]:	loss/total_loss, 8.113444328308105, 857
[INFO] 2021-07-12 18:48:05,538 [run_pretraining.py:  535]:	loss/mlm_loss, 8.113444328308105, 857
[INFO] 2021-07-12 18:48:05,539 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.560000424040481e-06, 857
[INFO] 2021-07-12 18:48:05,539 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 857
[INFO] 2021-07-12 18:48:05,539 [run_pretraining.py:  558]:	worker_index: 2, step: 857, cost: 8.113444, mlm loss: 8.113444, speed: 0.970341 steps/s, speed: 7.762730 samples/s, speed: 3974.517822 tokens/s, learning rate: 8.560e-06, loss_scalings: 13421.773438, pp_loss: 8.319139
[INFO] 2021-07-12 18:48:05,539 [run_pretraining.py:  512]:	********exe.run_857******* 
[INFO] 2021-07-12 18:48:06,457 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:06,458 [run_pretraining.py:  534]:	loss/total_loss, 8.375141143798828, 858
[INFO] 2021-07-12 18:48:06,458 [run_pretraining.py:  535]:	loss/mlm_loss, 8.375141143798828, 858
[INFO] 2021-07-12 18:48:06,458 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.569999408791773e-06, 858
[INFO] 2021-07-12 18:48:06,458 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 858
[INFO] 2021-07-12 18:48:06,458 [run_pretraining.py:  558]:	worker_index: 2, step: 858, cost: 8.375141, mlm loss: 8.375141, speed: 1.088535 steps/s, speed: 8.708278 samples/s, speed: 4458.638336 tokens/s, learning rate: 8.570e-06, loss_scalings: 13421.773438, pp_loss: 8.346043
[INFO] 2021-07-12 18:48:06,458 [run_pretraining.py:  512]:	********exe.run_858******* 
[INFO] 2021-07-12 18:48:07,367 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:07,367 [run_pretraining.py:  534]:	loss/total_loss, 8.326891899108887, 859
[INFO] 2021-07-12 18:48:07,367 [run_pretraining.py:  535]:	loss/mlm_loss, 8.326891899108887, 859
[INFO] 2021-07-12 18:48:07,367 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.579999303037766e-06, 859
[INFO] 2021-07-12 18:48:07,367 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 859
[INFO] 2021-07-12 18:48:07,367 [run_pretraining.py:  558]:	worker_index: 2, step: 859, cost: 8.326892, mlm loss: 8.326892, speed: 1.100286 steps/s, speed: 8.802291 samples/s, speed: 4506.773245 tokens/s, learning rate: 8.580e-06, loss_scalings: 13421.773438, pp_loss: 8.597225
[INFO] 2021-07-12 18:48:07,368 [run_pretraining.py:  512]:	********exe.run_859******* 
[INFO] 2021-07-12 18:48:08,325 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:08,325 [run_pretraining.py:  534]:	loss/total_loss, 8.695772171020508, 860
[INFO] 2021-07-12 18:48:08,325 [run_pretraining.py:  535]:	loss/mlm_loss, 8.695772171020508, 860
[INFO] 2021-07-12 18:48:08,325 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.590000106778461e-06, 860
[INFO] 2021-07-12 18:48:08,325 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 860
[INFO] 2021-07-12 18:48:08,325 [run_pretraining.py:  558]:	worker_index: 2, step: 860, cost: 8.695772, mlm loss: 8.695772, speed: 1.044566 steps/s, speed: 8.356531 samples/s, speed: 4278.544104 tokens/s, learning rate: 8.590e-06, loss_scalings: 13421.773438, pp_loss: 8.337635
[INFO] 2021-07-12 18:48:08,325 [run_pretraining.py:  512]:	********exe.run_860******* 
[INFO] 2021-07-12 18:48:09,238 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:09,238 [run_pretraining.py:  534]:	loss/total_loss, 7.729859828948975, 861
[INFO] 2021-07-12 18:48:09,238 [run_pretraining.py:  535]:	loss/mlm_loss, 7.729859828948975, 861
[INFO] 2021-07-12 18:48:09,238 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.600000001024455e-06, 861
[INFO] 2021-07-12 18:48:09,238 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 861
[INFO] 2021-07-12 18:48:09,238 [run_pretraining.py:  558]:	worker_index: 2, step: 861, cost: 7.729860, mlm loss: 7.729860, speed: 1.096000 steps/s, speed: 8.768004 samples/s, speed: 4489.218004 tokens/s, learning rate: 8.600e-06, loss_scalings: 13421.773438, pp_loss: 8.127471
[INFO] 2021-07-12 18:48:09,238 [run_pretraining.py:  512]:	********exe.run_861******* 
[INFO] 2021-07-12 18:48:10,163 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:10,163 [run_pretraining.py:  534]:	loss/total_loss, 7.978096008300781, 862
[INFO] 2021-07-12 18:48:10,164 [run_pretraining.py:  535]:	loss/mlm_loss, 7.978096008300781, 862
[INFO] 2021-07-12 18:48:10,164 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.609999895270448e-06, 862
[INFO] 2021-07-12 18:48:10,164 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 862
[INFO] 2021-07-12 18:48:10,164 [run_pretraining.py:  558]:	worker_index: 2, step: 862, cost: 7.978096, mlm loss: 7.978096, speed: 1.081427 steps/s, speed: 8.651419 samples/s, speed: 4429.526340 tokens/s, learning rate: 8.610e-06, loss_scalings: 13421.773438, pp_loss: 8.122144
[INFO] 2021-07-12 18:48:10,164 [run_pretraining.py:  512]:	********exe.run_862******* 
[INFO] 2021-07-12 18:48:11,079 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:11,080 [run_pretraining.py:  534]:	loss/total_loss, 8.259114265441895, 863
[INFO] 2021-07-12 18:48:11,080 [run_pretraining.py:  535]:	loss/mlm_loss, 8.259114265441895, 863
[INFO] 2021-07-12 18:48:11,080 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.619999789516442e-06, 863
[INFO] 2021-07-12 18:48:11,080 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 863
[INFO] 2021-07-12 18:48:11,080 [run_pretraining.py:  558]:	worker_index: 2, step: 863, cost: 8.259114, mlm loss: 8.259114, speed: 1.092123 steps/s, speed: 8.736984 samples/s, speed: 4473.335976 tokens/s, learning rate: 8.620e-06, loss_scalings: 13421.773438, pp_loss: 8.305197
[INFO] 2021-07-12 18:48:11,080 [run_pretraining.py:  512]:	********exe.run_863******* 
[INFO] 2021-07-12 18:48:12,006 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:12,006 [run_pretraining.py:  534]:	loss/total_loss, 8.274689674377441, 864
[INFO] 2021-07-12 18:48:12,006 [run_pretraining.py:  535]:	loss/mlm_loss, 8.274689674377441, 864
[INFO] 2021-07-12 18:48:12,006 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.629999683762435e-06, 864
[INFO] 2021-07-12 18:48:12,006 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 864
[INFO] 2021-07-12 18:48:12,006 [run_pretraining.py:  558]:	worker_index: 2, step: 864, cost: 8.274690, mlm loss: 8.274690, speed: 1.080255 steps/s, speed: 8.642042 samples/s, speed: 4424.725696 tokens/s, learning rate: 8.630e-06, loss_scalings: 13421.773438, pp_loss: 8.224288
[INFO] 2021-07-12 18:48:12,006 [run_pretraining.py:  512]:	********exe.run_864******* 
[INFO] 2021-07-12 18:48:12,920 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:12,921 [run_pretraining.py:  534]:	loss/total_loss, 8.356762886047363, 865
[INFO] 2021-07-12 18:48:12,921 [run_pretraining.py:  535]:	loss/mlm_loss, 8.356762886047363, 865
[INFO] 2021-07-12 18:48:12,921 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.639999578008428e-06, 865
[INFO] 2021-07-12 18:48:12,921 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 865
[INFO] 2021-07-12 18:48:12,921 [run_pretraining.py:  558]:	worker_index: 2, step: 865, cost: 8.356763, mlm loss: 8.356763, speed: 1.093894 steps/s, speed: 8.751153 samples/s, speed: 4480.590312 tokens/s, learning rate: 8.640e-06, loss_scalings: 13421.773438, pp_loss: 8.192152
[INFO] 2021-07-12 18:48:12,921 [run_pretraining.py:  512]:	********exe.run_865******* 
[INFO] 2021-07-12 18:48:13,840 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:13,841 [run_pretraining.py:  534]:	loss/total_loss, 8.414058685302734, 866
[INFO] 2021-07-12 18:48:13,841 [run_pretraining.py:  535]:	loss/mlm_loss, 8.414058685302734, 866
[INFO] 2021-07-12 18:48:13,841 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.649999472254422e-06, 866
[INFO] 2021-07-12 18:48:13,841 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 866
[INFO] 2021-07-12 18:48:13,841 [run_pretraining.py:  558]:	worker_index: 2, step: 866, cost: 8.414059, mlm loss: 8.414059, speed: 1.087567 steps/s, speed: 8.700540 samples/s, speed: 4454.676353 tokens/s, learning rate: 8.650e-06, loss_scalings: 13421.773438, pp_loss: 8.386382
[INFO] 2021-07-12 18:48:13,841 [run_pretraining.py:  512]:	********exe.run_866******* 
[INFO] 2021-07-12 18:48:14,756 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:14,756 [run_pretraining.py:  534]:	loss/total_loss, 8.704553604125977, 867
[INFO] 2021-07-12 18:48:14,756 [run_pretraining.py:  535]:	loss/mlm_loss, 8.704553604125977, 867
[INFO] 2021-07-12 18:48:14,757 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.659999366500415e-06, 867
[INFO] 2021-07-12 18:48:14,757 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 867
[INFO] 2021-07-12 18:48:14,757 [run_pretraining.py:  558]:	worker_index: 2, step: 867, cost: 8.704554, mlm loss: 8.704554, speed: 1.093002 steps/s, speed: 8.744015 samples/s, speed: 4476.935705 tokens/s, learning rate: 8.660e-06, loss_scalings: 13421.773438, pp_loss: 8.304884
[INFO] 2021-07-12 18:48:14,757 [run_pretraining.py:  512]:	********exe.run_867******* 
[INFO] 2021-07-12 18:48:15,667 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:15,667 [run_pretraining.py:  534]:	loss/total_loss, 8.13975715637207, 868
[INFO] 2021-07-12 18:48:15,667 [run_pretraining.py:  535]:	loss/mlm_loss, 8.13975715637207, 868
[INFO] 2021-07-12 18:48:15,667 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.67000017024111e-06, 868
[INFO] 2021-07-12 18:48:15,667 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 868
[INFO] 2021-07-12 18:48:15,667 [run_pretraining.py:  558]:	worker_index: 2, step: 868, cost: 8.139757, mlm loss: 8.139757, speed: 1.098807 steps/s, speed: 8.790457 samples/s, speed: 4500.714064 tokens/s, learning rate: 8.670e-06, loss_scalings: 13421.773438, pp_loss: 8.365823
[INFO] 2021-07-12 18:48:15,667 [run_pretraining.py:  512]:	********exe.run_868******* 
[INFO] 2021-07-12 18:48:16,579 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:16,580 [run_pretraining.py:  534]:	loss/total_loss, 8.66102123260498, 869
[INFO] 2021-07-12 18:48:16,580 [run_pretraining.py:  535]:	loss/mlm_loss, 8.66102123260498, 869
[INFO] 2021-07-12 18:48:16,580 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.680000064487103e-06, 869
[INFO] 2021-07-12 18:48:16,580 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 869
[INFO] 2021-07-12 18:48:16,580 [run_pretraining.py:  558]:	worker_index: 2, step: 869, cost: 8.661021, mlm loss: 8.661021, speed: 1.096423 steps/s, speed: 8.771387 samples/s, speed: 4490.950113 tokens/s, learning rate: 8.680e-06, loss_scalings: 13421.773438, pp_loss: 8.407254
[INFO] 2021-07-12 18:48:16,580 [run_pretraining.py:  512]:	********exe.run_869******* 
[INFO] 2021-07-12 18:48:17,507 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:17,507 [run_pretraining.py:  534]:	loss/total_loss, 8.557682991027832, 870
[INFO] 2021-07-12 18:48:17,507 [run_pretraining.py:  535]:	loss/mlm_loss, 8.557682991027832, 870
[INFO] 2021-07-12 18:48:17,508 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.689999958733097e-06, 870
[INFO] 2021-07-12 18:48:17,508 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 870
[INFO] 2021-07-12 18:48:17,508 [run_pretraining.py:  558]:	worker_index: 2, step: 870, cost: 8.557683, mlm loss: 8.557683, speed: 1.078780 steps/s, speed: 8.630237 samples/s, speed: 4418.681542 tokens/s, learning rate: 8.690e-06, loss_scalings: 13421.773438, pp_loss: 8.253886
[INFO] 2021-07-12 18:48:17,508 [run_pretraining.py:  512]:	********exe.run_870******* 
[INFO] 2021-07-12 18:48:44,182 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:44,182 [run_pretraining.py:  534]:	loss/total_loss, 8.438786506652832, 871
[INFO] 2021-07-12 18:48:44,183 [run_pretraining.py:  535]:	loss/mlm_loss, 8.438786506652832, 871
[INFO] 2021-07-12 18:48:44,183 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.69999985297909e-06, 871
[INFO] 2021-07-12 18:48:44,183 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 871
[INFO] 2021-07-12 18:48:44,183 [run_pretraining.py:  558]:	worker_index: 2, step: 871, cost: 8.438787, mlm loss: 8.438787, speed: 0.037489 steps/s, speed: 0.299912 samples/s, speed: 153.554693 tokens/s, learning rate: 8.700e-06, loss_scalings: 13421.773438, pp_loss: 8.308311
[INFO] 2021-07-12 18:48:44,183 [run_pretraining.py:  512]:	********exe.run_871******* 
[INFO] 2021-07-12 18:48:45,086 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:45,087 [run_pretraining.py:  534]:	loss/total_loss, 8.31982135772705, 872
[INFO] 2021-07-12 18:48:45,087 [run_pretraining.py:  535]:	loss/mlm_loss, 8.31982135772705, 872
[INFO] 2021-07-12 18:48:45,087 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.709999747225083e-06, 872
[INFO] 2021-07-12 18:48:45,087 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 872
[INFO] 2021-07-12 18:48:45,087 [run_pretraining.py:  558]:	worker_index: 2, step: 872, cost: 8.319821, mlm loss: 8.319821, speed: 1.106520 steps/s, speed: 8.852163 samples/s, speed: 4532.307229 tokens/s, learning rate: 8.710e-06, loss_scalings: 13421.773438, pp_loss: 8.421465
[INFO] 2021-07-12 18:48:45,087 [run_pretraining.py:  512]:	********exe.run_872******* 
[INFO] 2021-07-12 18:49:12,328 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:12,334 [run_pretraining.py:  534]:	loss/total_loss, 8.219443321228027, 873
[INFO] 2021-07-12 18:49:12,339 [run_pretraining.py:  535]:	loss/mlm_loss, 8.219443321228027, 873
[INFO] 2021-07-12 18:49:12,344 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.719999641471077e-06, 873
[INFO] 2021-07-12 18:49:12,349 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 873
[INFO] 2021-07-12 18:49:12,355 [run_pretraining.py:  558]:	worker_index: 2, step: 873, cost: 8.219443, mlm loss: 8.219443, speed: 0.036702 steps/s, speed: 0.293615 samples/s, speed: 150.331130 tokens/s, learning rate: 8.720e-06, loss_scalings: 13421.773438, pp_loss: 8.270288
[INFO] 2021-07-12 18:49:12,360 [run_pretraining.py:  512]:	********exe.run_873******* 
[INFO] 2021-07-12 18:49:13,253 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:13,253 [run_pretraining.py:  534]:	loss/total_loss, 8.62169075012207, 874
[INFO] 2021-07-12 18:49:13,253 [run_pretraining.py:  535]:	loss/mlm_loss, 8.62169075012207, 874
[INFO] 2021-07-12 18:49:13,254 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.730000445211772e-06, 874
[INFO] 2021-07-12 18:49:13,254 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 874
[INFO] 2021-07-12 18:49:13,254 [run_pretraining.py:  558]:	worker_index: 2, step: 874, cost: 8.621691, mlm loss: 8.621691, speed: 1.119186 steps/s, speed: 8.953488 samples/s, speed: 4584.185875 tokens/s, learning rate: 8.730e-06, loss_scalings: 13421.773438, pp_loss: 8.407612
[INFO] 2021-07-12 18:49:13,254 [run_pretraining.py:  512]:	********exe.run_874******* 
[INFO] 2021-07-12 18:49:14,156 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:14,157 [run_pretraining.py:  534]:	loss/total_loss, 8.67636489868164, 875
[INFO] 2021-07-12 18:49:14,157 [run_pretraining.py:  535]:	loss/mlm_loss, 8.67636489868164, 875
[INFO] 2021-07-12 18:49:14,157 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.739999429963063e-06, 875
[INFO] 2021-07-12 18:49:14,157 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 875
[INFO] 2021-07-12 18:49:14,157 [run_pretraining.py:  558]:	worker_index: 2, step: 875, cost: 8.676365, mlm loss: 8.676365, speed: 1.107506 steps/s, speed: 8.860049 samples/s, speed: 4536.345084 tokens/s, learning rate: 8.740e-06, loss_scalings: 13421.773438, pp_loss: 8.390421
[INFO] 2021-07-12 18:49:14,157 [run_pretraining.py:  512]:	********exe.run_875******* 
[INFO] 2021-07-12 18:49:40,911 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:40,911 [run_pretraining.py:  534]:	loss/total_loss, 8.087274551391602, 876
[INFO] 2021-07-12 18:49:40,912 [run_pretraining.py:  535]:	loss/mlm_loss, 8.087274551391602, 876
[INFO] 2021-07-12 18:49:40,912 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.749999324209057e-06, 876
[INFO] 2021-07-12 18:49:40,912 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 876
[INFO] 2021-07-12 18:49:40,912 [run_pretraining.py:  558]:	worker_index: 2, step: 876, cost: 8.087275, mlm loss: 8.087275, speed: 0.037378 steps/s, speed: 0.299021 samples/s, speed: 153.098759 tokens/s, learning rate: 8.750e-06, loss_scalings: 13421.773438, pp_loss: 8.021681
[INFO] 2021-07-12 18:49:40,912 [run_pretraining.py:  512]:	********exe.run_876******* 
[INFO] 2021-07-12 18:49:41,843 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:41,843 [run_pretraining.py:  534]:	loss/total_loss, 8.16050910949707, 877
[INFO] 2021-07-12 18:49:41,844 [run_pretraining.py:  535]:	loss/mlm_loss, 8.16050910949707, 877
[INFO] 2021-07-12 18:49:41,844 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.760000127949752e-06, 877
[INFO] 2021-07-12 18:49:41,844 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 877
[INFO] 2021-07-12 18:49:41,844 [run_pretraining.py:  558]:	worker_index: 2, step: 877, cost: 8.160509, mlm loss: 8.160509, speed: 1.073642 steps/s, speed: 8.589139 samples/s, speed: 4397.638973 tokens/s, learning rate: 8.760e-06, loss_scalings: 13421.773438, pp_loss: 7.893216
[INFO] 2021-07-12 18:49:41,844 [run_pretraining.py:  512]:	********exe.run_877******* 
[INFO] 2021-07-12 18:49:42,777 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:42,778 [run_pretraining.py:  534]:	loss/total_loss, 8.460023880004883, 878
[INFO] 2021-07-12 18:49:42,778 [run_pretraining.py:  535]:	loss/mlm_loss, 8.460023880004883, 878
[INFO] 2021-07-12 18:49:42,778 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.770000022195745e-06, 878
[INFO] 2021-07-12 18:49:42,778 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 878
[INFO] 2021-07-12 18:49:42,778 [run_pretraining.py:  558]:	worker_index: 2, step: 878, cost: 8.460024, mlm loss: 8.460024, speed: 1.071237 steps/s, speed: 8.569898 samples/s, speed: 4387.787653 tokens/s, learning rate: 8.770e-06, loss_scalings: 13421.773438, pp_loss: 7.840184
[INFO] 2021-07-12 18:49:42,778 [run_pretraining.py:  512]:	********exe.run_878******* 
[INFO] 2021-07-12 18:49:43,792 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:43,792 [run_pretraining.py:  534]:	loss/total_loss, 8.585684776306152, 879
[INFO] 2021-07-12 18:49:43,792 [run_pretraining.py:  535]:	loss/mlm_loss, 8.585684776306152, 879
[INFO] 2021-07-12 18:49:43,792 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.779999916441739e-06, 879
[INFO] 2021-07-12 18:49:43,792 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 879
[INFO] 2021-07-12 18:49:43,792 [run_pretraining.py:  558]:	worker_index: 2, step: 879, cost: 8.585685, mlm loss: 8.585685, speed: 0.986360 steps/s, speed: 7.890881 samples/s, speed: 4040.130984 tokens/s, learning rate: 8.780e-06, loss_scalings: 13421.773438, pp_loss: 8.338620
[INFO] 2021-07-12 18:49:43,792 [run_pretraining.py:  512]:	********exe.run_879******* 
[INFO] 2021-07-12 18:49:44,723 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:44,723 [run_pretraining.py:  534]:	loss/total_loss, 7.934952735900879, 880
[INFO] 2021-07-12 18:49:44,723 [run_pretraining.py:  535]:	loss/mlm_loss, 7.934952735900879, 880
[INFO] 2021-07-12 18:49:44,723 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.789999810687732e-06, 880
[INFO] 2021-07-12 18:49:44,723 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 880
[INFO] 2021-07-12 18:49:44,723 [run_pretraining.py:  558]:	worker_index: 2, step: 880, cost: 7.934953, mlm loss: 7.934953, speed: 1.074725 steps/s, speed: 8.597801 samples/s, speed: 4402.074162 tokens/s, learning rate: 8.790e-06, loss_scalings: 13421.773438, pp_loss: 8.369972
[INFO] 2021-07-12 18:49:44,724 [run_pretraining.py:  512]:	********exe.run_880******* 
[INFO] 2021-07-12 18:49:45,720 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:45,721 [run_pretraining.py:  534]:	loss/total_loss, 8.157517433166504, 881
[INFO] 2021-07-12 18:49:45,721 [run_pretraining.py:  535]:	loss/mlm_loss, 8.157517433166504, 881
[INFO] 2021-07-12 18:49:45,721 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.799999704933725e-06, 881
[INFO] 2021-07-12 18:49:45,721 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 881
[INFO] 2021-07-12 18:49:45,721 [run_pretraining.py:  558]:	worker_index: 2, step: 881, cost: 8.157517, mlm loss: 8.157517, speed: 1.002973 steps/s, speed: 8.023786 samples/s, speed: 4108.178682 tokens/s, learning rate: 8.800e-06, loss_scalings: 13421.773438, pp_loss: 8.266497
[INFO] 2021-07-12 18:49:45,721 [run_pretraining.py:  512]:	********exe.run_881******* 
[INFO] 2021-07-12 18:49:46,788 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:46,789 [run_pretraining.py:  534]:	loss/total_loss, 8.672719955444336, 882
[INFO] 2021-07-12 18:49:46,789 [run_pretraining.py:  535]:	loss/mlm_loss, 8.672719955444336, 882
[INFO] 2021-07-12 18:49:46,789 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.809999599179719e-06, 882
[INFO] 2021-07-12 18:49:46,789 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 882
[INFO] 2021-07-12 18:49:46,789 [run_pretraining.py:  558]:	worker_index: 2, step: 882, cost: 8.672720, mlm loss: 8.672720, speed: 0.936819 steps/s, speed: 7.494553 samples/s, speed: 3837.211042 tokens/s, learning rate: 8.810e-06, loss_scalings: 13421.773438, pp_loss: 8.433296
[INFO] 2021-07-12 18:49:46,789 [run_pretraining.py:  512]:	********exe.run_882******* 
[INFO] 2021-07-12 18:49:47,845 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:47,845 [run_pretraining.py:  534]:	loss/total_loss, 8.53487777709961, 883
[INFO] 2021-07-12 18:49:47,845 [run_pretraining.py:  535]:	loss/mlm_loss, 8.53487777709961, 883
[INFO] 2021-07-12 18:49:47,845 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.820000402920414e-06, 883
[INFO] 2021-07-12 18:49:47,846 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 883
[INFO] 2021-07-12 18:49:47,846 [run_pretraining.py:  558]:	worker_index: 2, step: 883, cost: 8.534878, mlm loss: 8.534878, speed: 0.947077 steps/s, speed: 7.576618 samples/s, speed: 3879.228444 tokens/s, learning rate: 8.820e-06, loss_scalings: 13421.773438, pp_loss: 8.315160
[INFO] 2021-07-12 18:49:47,846 [run_pretraining.py:  512]:	********exe.run_883******* 
[INFO] 2021-07-12 18:49:48,908 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:48,909 [run_pretraining.py:  534]:	loss/total_loss, 8.415010452270508, 884
[INFO] 2021-07-12 18:49:48,909 [run_pretraining.py:  535]:	loss/mlm_loss, 8.415010452270508, 884
[INFO] 2021-07-12 18:49:48,909 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.829999387671705e-06, 884
[INFO] 2021-07-12 18:49:48,909 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 884
[INFO] 2021-07-12 18:49:48,909 [run_pretraining.py:  558]:	worker_index: 2, step: 884, cost: 8.415010, mlm loss: 8.415010, speed: 0.941034 steps/s, speed: 7.528270 samples/s, speed: 3854.474137 tokens/s, learning rate: 8.830e-06, loss_scalings: 13421.773438, pp_loss: 8.403254
[INFO] 2021-07-12 18:49:48,909 [run_pretraining.py:  512]:	********exe.run_884******* 
[INFO] 2021-07-12 18:49:49,989 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:49,989 [run_pretraining.py:  534]:	loss/total_loss, 8.192606925964355, 885
[INFO] 2021-07-12 18:49:49,989 [run_pretraining.py:  535]:	loss/mlm_loss, 8.192606925964355, 885
[INFO] 2021-07-12 18:49:49,989 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.839999281917699e-06, 885
[INFO] 2021-07-12 18:49:49,989 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 885
[INFO] 2021-07-12 18:49:49,990 [run_pretraining.py:  558]:	worker_index: 2, step: 885, cost: 8.192607, mlm loss: 8.192607, speed: 0.925859 steps/s, speed: 7.406868 samples/s, speed: 3792.316590 tokens/s, learning rate: 8.840e-06, loss_scalings: 13421.773438, pp_loss: 8.191838
[INFO] 2021-07-12 18:49:49,990 [run_pretraining.py:  512]:	********exe.run_885******* 
[INFO] 2021-07-12 18:49:51,073 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:51,073 [run_pretraining.py:  534]:	loss/total_loss, 7.998308181762695, 886
[INFO] 2021-07-12 18:49:51,074 [run_pretraining.py:  535]:	loss/mlm_loss, 7.998308181762695, 886
[INFO] 2021-07-12 18:49:51,074 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.850000085658394e-06, 886
[INFO] 2021-07-12 18:49:51,074 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 886
[INFO] 2021-07-12 18:49:51,074 [run_pretraining.py:  558]:	worker_index: 2, step: 886, cost: 7.998308, mlm loss: 7.998308, speed: 0.922820 steps/s, speed: 7.382564 samples/s, speed: 3779.872703 tokens/s, learning rate: 8.850e-06, loss_scalings: 13421.773438, pp_loss: 8.165001
[INFO] 2021-07-12 18:49:51,074 [run_pretraining.py:  512]:	********exe.run_886******* 
[INFO] 2021-07-12 18:49:52,149 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:52,149 [run_pretraining.py:  534]:	loss/total_loss, 7.8482818603515625, 887
[INFO] 2021-07-12 18:49:52,149 [run_pretraining.py:  535]:	loss/mlm_loss, 7.8482818603515625, 887
[INFO] 2021-07-12 18:49:52,150 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.859999979904387e-06, 887
[INFO] 2021-07-12 18:49:52,150 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 887
[INFO] 2021-07-12 18:49:52,150 [run_pretraining.py:  558]:	worker_index: 2, step: 887, cost: 7.848282, mlm loss: 7.848282, speed: 0.929922 steps/s, speed: 7.439374 samples/s, speed: 3808.959322 tokens/s, learning rate: 8.860e-06, loss_scalings: 13421.773438, pp_loss: 8.019482
[INFO] 2021-07-12 18:49:52,150 [run_pretraining.py:  512]:	********exe.run_887******* 
[INFO] 2021-07-12 18:49:53,214 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:53,214 [run_pretraining.py:  534]:	loss/total_loss, 8.147493362426758, 888
[INFO] 2021-07-12 18:49:53,214 [run_pretraining.py:  535]:	loss/mlm_loss, 8.147493362426758, 888
[INFO] 2021-07-12 18:49:53,214 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.86999987415038e-06, 888
[INFO] 2021-07-12 18:49:53,214 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 888
[INFO] 2021-07-12 18:49:53,214 [run_pretraining.py:  558]:	worker_index: 2, step: 888, cost: 8.147493, mlm loss: 8.147493, speed: 0.939858 steps/s, speed: 7.518865 samples/s, speed: 3849.658958 tokens/s, learning rate: 8.870e-06, loss_scalings: 13421.773438, pp_loss: 8.247189
[INFO] 2021-07-12 18:49:53,214 [run_pretraining.py:  512]:	********exe.run_888******* 
[INFO] 2021-07-12 18:49:54,286 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:54,287 [run_pretraining.py:  534]:	loss/total_loss, 8.255023002624512, 889
[INFO] 2021-07-12 18:49:54,287 [run_pretraining.py:  535]:	loss/mlm_loss, 8.255023002624512, 889
[INFO] 2021-07-12 18:49:54,287 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.879999768396374e-06, 889
[INFO] 2021-07-12 18:49:54,287 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 889
[INFO] 2021-07-12 18:49:54,287 [run_pretraining.py:  558]:	worker_index: 2, step: 889, cost: 8.255023, mlm loss: 8.255023, speed: 0.932858 steps/s, speed: 7.462862 samples/s, speed: 3820.985507 tokens/s, learning rate: 8.880e-06, loss_scalings: 13421.773438, pp_loss: 8.436833
[INFO] 2021-07-12 18:49:54,287 [run_pretraining.py:  512]:	********exe.run_889******* 
[INFO] 2021-07-12 18:49:55,203 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:55,204 [run_pretraining.py:  534]:	loss/total_loss, 8.502891540527344, 890
[INFO] 2021-07-12 18:49:55,204 [run_pretraining.py:  535]:	loss/mlm_loss, 8.502891540527344, 890
[INFO] 2021-07-12 18:49:55,204 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.889999662642367e-06, 890
[INFO] 2021-07-12 18:49:55,204 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 890
[INFO] 2021-07-12 18:49:55,204 [run_pretraining.py:  558]:	worker_index: 2, step: 890, cost: 8.502892, mlm loss: 8.502892, speed: 1.090905 steps/s, speed: 8.727238 samples/s, speed: 4468.345816 tokens/s, learning rate: 8.890e-06, loss_scalings: 13421.773438, pp_loss: 8.351604
[INFO] 2021-07-12 18:49:55,204 [run_pretraining.py:  512]:	********exe.run_890******* 
[INFO] 2021-07-12 18:49:56,110 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:56,110 [run_pretraining.py:  534]:	loss/total_loss, 7.93228006362915, 891
[INFO] 2021-07-12 18:49:56,110 [run_pretraining.py:  535]:	loss/mlm_loss, 7.93228006362915, 891
[INFO] 2021-07-12 18:49:56,111 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.89999955688836e-06, 891
[INFO] 2021-07-12 18:49:56,111 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 891
[INFO] 2021-07-12 18:49:56,111 [run_pretraining.py:  558]:	worker_index: 2, step: 891, cost: 7.932280, mlm loss: 7.932280, speed: 1.103913 steps/s, speed: 8.831301 samples/s, speed: 4521.626246 tokens/s, learning rate: 8.900e-06, loss_scalings: 13421.773438, pp_loss: 8.288584
[INFO] 2021-07-12 18:49:56,111 [run_pretraining.py:  512]:	********exe.run_891******* 
[INFO] 2021-07-12 18:49:57,024 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:57,024 [run_pretraining.py:  534]:	loss/total_loss, 8.377111434936523, 892
[INFO] 2021-07-12 18:49:57,024 [run_pretraining.py:  535]:	loss/mlm_loss, 8.377111434936523, 892
[INFO] 2021-07-12 18:49:57,025 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.910000360629056e-06, 892
[INFO] 2021-07-12 18:49:57,025 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 892
[INFO] 2021-07-12 18:49:57,025 [run_pretraining.py:  558]:	worker_index: 2, step: 892, cost: 8.377111, mlm loss: 8.377111, speed: 1.094775 steps/s, speed: 8.758202 samples/s, speed: 4484.199389 tokens/s, learning rate: 8.910e-06, loss_scalings: 13421.773438, pp_loss: 8.005973
[INFO] 2021-07-12 18:49:57,025 [run_pretraining.py:  512]:	********exe.run_892******* 
[INFO] 2021-07-12 18:49:57,936 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:57,936 [run_pretraining.py:  534]:	loss/total_loss, 8.33778190612793, 893
[INFO] 2021-07-12 18:49:57,936 [run_pretraining.py:  535]:	loss/mlm_loss, 8.33778190612793, 893
[INFO] 2021-07-12 18:49:57,937 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.919999345380347e-06, 893
[INFO] 2021-07-12 18:49:57,937 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 893
[INFO] 2021-07-12 18:49:57,937 [run_pretraining.py:  558]:	worker_index: 2, step: 893, cost: 8.337782, mlm loss: 8.337782, speed: 1.097141 steps/s, speed: 8.777128 samples/s, speed: 4493.889306 tokens/s, learning rate: 8.920e-06, loss_scalings: 13421.773438, pp_loss: 8.395107
[INFO] 2021-07-12 18:49:57,937 [run_pretraining.py:  512]:	********exe.run_893******* 
[INFO] 2021-07-12 18:49:58,846 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:58,847 [run_pretraining.py:  534]:	loss/total_loss, 8.713266372680664, 894
[INFO] 2021-07-12 18:49:58,847 [run_pretraining.py:  535]:	loss/mlm_loss, 8.713266372680664, 894
[INFO] 2021-07-12 18:49:58,847 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.92999923962634e-06, 894
[INFO] 2021-07-12 18:49:58,847 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 894
[INFO] 2021-07-12 18:49:58,847 [run_pretraining.py:  558]:	worker_index: 2, step: 894, cost: 8.713266, mlm loss: 8.713266, speed: 1.099394 steps/s, speed: 8.795155 samples/s, speed: 4503.119491 tokens/s, learning rate: 8.930e-06, loss_scalings: 13421.773438, pp_loss: 8.198027
[INFO] 2021-07-12 18:49:58,847 [run_pretraining.py:  512]:	********exe.run_894******* 
[INFO] 2021-07-12 18:49:59,756 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:59,756 [run_pretraining.py:  534]:	loss/total_loss, 8.16532039642334, 895
[INFO] 2021-07-12 18:49:59,756 [run_pretraining.py:  535]:	loss/mlm_loss, 8.16532039642334, 895
[INFO] 2021-07-12 18:49:59,756 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.940000043367036e-06, 895
[INFO] 2021-07-12 18:49:59,756 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 895
[INFO] 2021-07-12 18:49:59,756 [run_pretraining.py:  558]:	worker_index: 2, step: 895, cost: 8.165320, mlm loss: 8.165320, speed: 1.100221 steps/s, speed: 8.801772 samples/s, speed: 4506.507253 tokens/s, learning rate: 8.940e-06, loss_scalings: 13421.773438, pp_loss: 8.286921
[INFO] 2021-07-12 18:49:59,756 [run_pretraining.py:  512]:	********exe.run_895******* 
[INFO] 2021-07-12 18:50:00,689 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:00,689 [run_pretraining.py:  534]:	loss/total_loss, 8.452934265136719, 896
[INFO] 2021-07-12 18:50:00,689 [run_pretraining.py:  535]:	loss/mlm_loss, 8.452934265136719, 896
[INFO] 2021-07-12 18:50:00,689 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.949999937613029e-06, 896
[INFO] 2021-07-12 18:50:00,689 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 896
[INFO] 2021-07-12 18:50:00,689 [run_pretraining.py:  558]:	worker_index: 2, step: 896, cost: 8.452934, mlm loss: 8.452934, speed: 1.072590 steps/s, speed: 8.580717 samples/s, speed: 4393.327304 tokens/s, learning rate: 8.950e-06, loss_scalings: 13421.773438, pp_loss: 8.154560
[INFO] 2021-07-12 18:50:00,689 [run_pretraining.py:  512]:	********exe.run_896******* 
[INFO] 2021-07-12 18:50:01,603 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:01,603 [run_pretraining.py:  534]:	loss/total_loss, 8.903583526611328, 897
[INFO] 2021-07-12 18:50:01,603 [run_pretraining.py:  535]:	loss/mlm_loss, 8.903583526611328, 897
[INFO] 2021-07-12 18:50:01,604 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.959999831859022e-06, 897
[INFO] 2021-07-12 18:50:01,604 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 897
[INFO] 2021-07-12 18:50:01,604 [run_pretraining.py:  558]:	worker_index: 2, step: 897, cost: 8.903584, mlm loss: 8.903584, speed: 1.094407 steps/s, speed: 8.755256 samples/s, speed: 4482.691197 tokens/s, learning rate: 8.960e-06, loss_scalings: 13421.773438, pp_loss: 8.336386
[INFO] 2021-07-12 18:50:01,604 [run_pretraining.py:  512]:	********exe.run_897******* 
[INFO] 2021-07-12 18:50:02,521 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:02,521 [run_pretraining.py:  534]:	loss/total_loss, 8.48330307006836, 898
[INFO] 2021-07-12 18:50:02,521 [run_pretraining.py:  535]:	loss/mlm_loss, 8.48330307006836, 898
[INFO] 2021-07-12 18:50:02,521 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.969999726105016e-06, 898
[INFO] 2021-07-12 18:50:02,521 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 898
[INFO] 2021-07-12 18:50:02,522 [run_pretraining.py:  558]:	worker_index: 2, step: 898, cost: 8.483303, mlm loss: 8.483303, speed: 1.090282 steps/s, speed: 8.722258 samples/s, speed: 4465.796285 tokens/s, learning rate: 8.970e-06, loss_scalings: 13421.773438, pp_loss: 8.217860
[INFO] 2021-07-12 18:50:02,522 [run_pretraining.py:  512]:	********exe.run_898******* 
[INFO] 2021-07-12 18:50:03,443 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:03,443 [run_pretraining.py:  534]:	loss/total_loss, 8.284100532531738, 899
[INFO] 2021-07-12 18:50:03,444 [run_pretraining.py:  535]:	loss/mlm_loss, 8.284100532531738, 899
[INFO] 2021-07-12 18:50:03,444 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.979999620351009e-06, 899
[INFO] 2021-07-12 18:50:03,444 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 899
[INFO] 2021-07-12 18:50:03,444 [run_pretraining.py:  558]:	worker_index: 2, step: 899, cost: 8.284101, mlm loss: 8.284101, speed: 1.085011 steps/s, speed: 8.680092 samples/s, speed: 4444.207104 tokens/s, learning rate: 8.980e-06, loss_scalings: 13421.773438, pp_loss: 8.374951
[INFO] 2021-07-12 18:50:03,444 [run_pretraining.py:  512]:	********exe.run_899******* 
[INFO] 2021-07-12 18:50:04,365 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:04,366 [run_pretraining.py:  534]:	loss/total_loss, 8.83875560760498, 900
[INFO] 2021-07-12 18:50:04,366 [run_pretraining.py:  535]:	loss/mlm_loss, 8.83875560760498, 900
[INFO] 2021-07-12 18:50:04,366 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.989999514597002e-06, 900
[INFO] 2021-07-12 18:50:04,366 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 900
[INFO] 2021-07-12 18:50:04,366 [run_pretraining.py:  558]:	worker_index: 2, step: 900, cost: 8.838756, mlm loss: 8.838756, speed: 1.085154 steps/s, speed: 8.681233 samples/s, speed: 4444.791207 tokens/s, learning rate: 8.990e-06, loss_scalings: 13421.773438, pp_loss: 8.273384
[INFO] 2021-07-12 18:50:04,366 [run_pretraining.py:  512]:	********exe.run_900******* 
[INFO] 2021-07-12 18:50:05,425 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:05,425 [run_pretraining.py:  534]:	loss/total_loss, 8.443085670471191, 901
[INFO] 2021-07-12 18:50:05,425 [run_pretraining.py:  535]:	loss/mlm_loss, 8.443085670471191, 901
[INFO] 2021-07-12 18:50:05,425 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.000000318337698e-06, 901
[INFO] 2021-07-12 18:50:05,425 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 901
[INFO] 2021-07-12 18:50:05,425 [run_pretraining.py:  558]:	worker_index: 2, step: 901, cost: 8.443086, mlm loss: 8.443086, speed: 0.944328 steps/s, speed: 7.554625 samples/s, speed: 3867.967823 tokens/s, learning rate: 9.000e-06, loss_scalings: 13421.773438, pp_loss: 8.020419
[INFO] 2021-07-12 18:50:05,426 [run_pretraining.py:  512]:	********exe.run_901******* 
[INFO] 2021-07-12 18:50:06,484 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:06,484 [run_pretraining.py:  534]:	loss/total_loss, 8.504083633422852, 902
[INFO] 2021-07-12 18:50:06,485 [run_pretraining.py:  535]:	loss/mlm_loss, 8.504083633422852, 902
[INFO] 2021-07-12 18:50:06,485 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.009999303088989e-06, 902
[INFO] 2021-07-12 18:50:06,485 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 902
[INFO] 2021-07-12 18:50:06,485 [run_pretraining.py:  558]:	worker_index: 2, step: 902, cost: 8.504084, mlm loss: 8.504084, speed: 0.944528 steps/s, speed: 7.556220 samples/s, speed: 3868.784858 tokens/s, learning rate: 9.010e-06, loss_scalings: 13421.773438, pp_loss: 8.555914
[INFO] 2021-07-12 18:50:06,485 [run_pretraining.py:  512]:	********exe.run_902******* 
[INFO] 2021-07-12 18:50:07,556 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:07,557 [run_pretraining.py:  534]:	loss/total_loss, 8.358193397521973, 903
[INFO] 2021-07-12 18:50:07,557 [run_pretraining.py:  535]:	loss/mlm_loss, 8.358193397521973, 903
[INFO] 2021-07-12 18:50:07,557 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.020000106829684e-06, 903
[INFO] 2021-07-12 18:50:07,557 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 903
[INFO] 2021-07-12 18:50:07,557 [run_pretraining.py:  558]:	worker_index: 2, step: 903, cost: 8.358193, mlm loss: 8.358193, speed: 0.932921 steps/s, speed: 7.463367 samples/s, speed: 3821.243872 tokens/s, learning rate: 9.020e-06, loss_scalings: 13421.773438, pp_loss: 8.118959
[INFO] 2021-07-12 18:50:07,557 [run_pretraining.py:  512]:	********exe.run_903******* 
[INFO] 2021-07-12 18:50:08,629 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:08,629 [run_pretraining.py:  534]:	loss/total_loss, 8.256189346313477, 904
[INFO] 2021-07-12 18:50:08,629 [run_pretraining.py:  535]:	loss/mlm_loss, 8.256189346313477, 904
[INFO] 2021-07-12 18:50:08,629 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.030000001075678e-06, 904
[INFO] 2021-07-12 18:50:08,629 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 904
[INFO] 2021-07-12 18:50:08,630 [run_pretraining.py:  558]:	worker_index: 2, step: 904, cost: 8.256189, mlm loss: 8.256189, speed: 0.933158 steps/s, speed: 7.465262 samples/s, speed: 3822.213903 tokens/s, learning rate: 9.030e-06, loss_scalings: 13421.773438, pp_loss: 8.433777
[INFO] 2021-07-12 18:50:08,630 [run_pretraining.py:  512]:	********exe.run_904******* 
[INFO] 2021-07-12 18:50:09,696 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:09,696 [run_pretraining.py:  534]:	loss/total_loss, 7.752241134643555, 905
[INFO] 2021-07-12 18:50:09,697 [run_pretraining.py:  535]:	loss/mlm_loss, 7.752241134643555, 905
[INFO] 2021-07-12 18:50:09,697 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.039999895321671e-06, 905
[INFO] 2021-07-12 18:50:09,697 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 905
[INFO] 2021-07-12 18:50:09,697 [run_pretraining.py:  558]:	worker_index: 2, step: 905, cost: 7.752241, mlm loss: 7.752241, speed: 0.937487 steps/s, speed: 7.499898 samples/s, speed: 3839.947873 tokens/s, learning rate: 9.040e-06, loss_scalings: 13421.773438, pp_loss: 8.290696
[INFO] 2021-07-12 18:50:09,697 [run_pretraining.py:  512]:	********exe.run_905******* 
[INFO] 2021-07-12 18:50:10,779 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:10,779 [run_pretraining.py:  534]:	loss/total_loss, 8.484228134155273, 906
[INFO] 2021-07-12 18:50:10,779 [run_pretraining.py:  535]:	loss/mlm_loss, 8.484228134155273, 906
[INFO] 2021-07-12 18:50:10,779 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.049999789567664e-06, 906
[INFO] 2021-07-12 18:50:10,779 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 906
[INFO] 2021-07-12 18:50:10,779 [run_pretraining.py:  558]:	worker_index: 2, step: 906, cost: 8.484228, mlm loss: 8.484228, speed: 0.924278 steps/s, speed: 7.394220 samples/s, speed: 3785.840800 tokens/s, learning rate: 9.050e-06, loss_scalings: 13421.773438, pp_loss: 8.444640
[INFO] 2021-07-12 18:50:10,779 [run_pretraining.py:  512]:	********exe.run_906******* 
[INFO] 2021-07-12 18:50:11,851 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:11,851 [run_pretraining.py:  534]:	loss/total_loss, 8.535419464111328, 907
[INFO] 2021-07-12 18:50:11,851 [run_pretraining.py:  535]:	loss/mlm_loss, 8.535419464111328, 907
[INFO] 2021-07-12 18:50:11,852 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.059999683813658e-06, 907
[INFO] 2021-07-12 18:50:11,852 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 907
[INFO] 2021-07-12 18:50:11,852 [run_pretraining.py:  558]:	worker_index: 2, step: 907, cost: 8.535419, mlm loss: 8.535419, speed: 0.933080 steps/s, speed: 7.464637 samples/s, speed: 3821.894189 tokens/s, learning rate: 9.060e-06, loss_scalings: 13421.773438, pp_loss: 8.239096
[INFO] 2021-07-12 18:50:11,852 [run_pretraining.py:  512]:	********exe.run_907******* 
[INFO] 2021-07-12 18:50:12,912 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:12,912 [run_pretraining.py:  534]:	loss/total_loss, 8.393755912780762, 908
[INFO] 2021-07-12 18:50:12,913 [run_pretraining.py:  535]:	loss/mlm_loss, 8.393755912780762, 908
[INFO] 2021-07-12 18:50:12,913 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.069999578059651e-06, 908
[INFO] 2021-07-12 18:50:12,913 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 908
[INFO] 2021-07-12 18:50:12,913 [run_pretraining.py:  558]:	worker_index: 2, step: 908, cost: 8.393756, mlm loss: 8.393756, speed: 0.942918 steps/s, speed: 7.543343 samples/s, speed: 3862.191373 tokens/s, learning rate: 9.070e-06, loss_scalings: 13421.773438, pp_loss: 8.251746
[INFO] 2021-07-12 18:50:12,913 [run_pretraining.py:  512]:	********exe.run_908******* 
[INFO] 2021-07-12 18:50:13,978 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:13,978 [run_pretraining.py:  534]:	loss/total_loss, 8.478459358215332, 909
[INFO] 2021-07-12 18:50:13,978 [run_pretraining.py:  535]:	loss/mlm_loss, 8.478459358215332, 909
[INFO] 2021-07-12 18:50:13,978 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.080000381800346e-06, 909
[INFO] 2021-07-12 18:50:13,978 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 909
[INFO] 2021-07-12 18:50:13,978 [run_pretraining.py:  558]:	worker_index: 2, step: 909, cost: 8.478459, mlm loss: 8.478459, speed: 0.939039 steps/s, speed: 7.512310 samples/s, speed: 3846.302805 tokens/s, learning rate: 9.080e-06, loss_scalings: 13421.773438, pp_loss: 8.349467
[INFO] 2021-07-12 18:50:13,978 [run_pretraining.py:  512]:	********exe.run_909******* 
[INFO] 2021-07-12 18:50:15,048 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:15,049 [run_pretraining.py:  534]:	loss/total_loss, 8.060443878173828, 910
[INFO] 2021-07-12 18:50:15,049 [run_pretraining.py:  535]:	loss/mlm_loss, 8.060443878173828, 910
[INFO] 2021-07-12 18:50:15,049 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.089999366551638e-06, 910
[INFO] 2021-07-12 18:50:15,049 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 910
[INFO] 2021-07-12 18:50:15,049 [run_pretraining.py:  558]:	worker_index: 2, step: 910, cost: 8.060444, mlm loss: 8.060444, speed: 0.934552 steps/s, speed: 7.476419 samples/s, speed: 3827.926739 tokens/s, learning rate: 9.090e-06, loss_scalings: 13421.773438, pp_loss: 8.071953
[INFO] 2021-07-12 18:50:15,049 [run_pretraining.py:  512]:	********exe.run_910******* 
[INFO] 2021-07-12 18:50:16,104 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:16,104 [run_pretraining.py:  534]:	loss/total_loss, 8.180997848510742, 911
[INFO] 2021-07-12 18:50:16,104 [run_pretraining.py:  535]:	loss/mlm_loss, 8.180997848510742, 911
[INFO] 2021-07-12 18:50:16,104 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.099999260797631e-06, 911
[INFO] 2021-07-12 18:50:16,104 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 911
[INFO] 2021-07-12 18:50:16,104 [run_pretraining.py:  558]:	worker_index: 2, step: 911, cost: 8.180998, mlm loss: 8.180998, speed: 0.947994 steps/s, speed: 7.583956 samples/s, speed: 3882.985452 tokens/s, learning rate: 9.100e-06, loss_scalings: 13421.773438, pp_loss: 8.253891
[INFO] 2021-07-12 18:50:16,104 [run_pretraining.py:  512]:	********exe.run_911******* 
[INFO] 2021-07-12 18:50:17,158 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:17,158 [run_pretraining.py:  534]:	loss/total_loss, 8.399429321289062, 912
[INFO] 2021-07-12 18:50:17,158 [run_pretraining.py:  535]:	loss/mlm_loss, 8.399429321289062, 912
[INFO] 2021-07-12 18:50:17,159 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.110000064538326e-06, 912
[INFO] 2021-07-12 18:50:17,159 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 912
[INFO] 2021-07-12 18:50:17,159 [run_pretraining.py:  558]:	worker_index: 2, step: 912, cost: 8.399429, mlm loss: 8.399429, speed: 0.949048 steps/s, speed: 7.592387 samples/s, speed: 3887.302043 tokens/s, learning rate: 9.110e-06, loss_scalings: 13421.773438, pp_loss: 7.926093
[INFO] 2021-07-12 18:50:17,159 [run_pretraining.py:  512]:	********exe.run_912******* 
[INFO] 2021-07-12 18:50:18,216 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:18,216 [run_pretraining.py:  534]:	loss/total_loss, 8.346810340881348, 913
[INFO] 2021-07-12 18:50:18,216 [run_pretraining.py:  535]:	loss/mlm_loss, 8.346810340881348, 913
[INFO] 2021-07-12 18:50:18,217 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.11999995878432e-06, 913
[INFO] 2021-07-12 18:50:18,217 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 913
[INFO] 2021-07-12 18:50:18,217 [run_pretraining.py:  558]:	worker_index: 2, step: 913, cost: 8.346810, mlm loss: 8.346810, speed: 0.945710 steps/s, speed: 7.565683 samples/s, speed: 3873.629689 tokens/s, learning rate: 9.120e-06, loss_scalings: 13421.773438, pp_loss: 8.387467
[INFO] 2021-07-12 18:50:18,217 [run_pretraining.py:  512]:	********exe.run_913******* 
[INFO] 2021-07-12 18:50:19,279 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:19,279 [run_pretraining.py:  534]:	loss/total_loss, 8.931461334228516, 914
[INFO] 2021-07-12 18:50:19,279 [run_pretraining.py:  535]:	loss/mlm_loss, 8.931461334228516, 914
[INFO] 2021-07-12 18:50:19,280 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.129999853030313e-06, 914
[INFO] 2021-07-12 18:50:19,280 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 914
[INFO] 2021-07-12 18:50:19,280 [run_pretraining.py:  558]:	worker_index: 2, step: 914, cost: 8.931461, mlm loss: 8.931461, speed: 0.941314 steps/s, speed: 7.530510 samples/s, speed: 3855.621189 tokens/s, learning rate: 9.130e-06, loss_scalings: 13421.773438, pp_loss: 8.556385
[INFO] 2021-07-12 18:50:19,280 [run_pretraining.py:  512]:	********exe.run_914******* 
[INFO] 2021-07-12 18:50:20,344 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:20,344 [run_pretraining.py:  534]:	loss/total_loss, 8.027609825134277, 915
[INFO] 2021-07-12 18:50:20,344 [run_pretraining.py:  535]:	loss/mlm_loss, 8.027609825134277, 915
[INFO] 2021-07-12 18:50:20,345 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.139999747276306e-06, 915
[INFO] 2021-07-12 18:50:20,345 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 915
[INFO] 2021-07-12 18:50:20,345 [run_pretraining.py:  558]:	worker_index: 2, step: 915, cost: 8.027610, mlm loss: 8.027610, speed: 0.939501 steps/s, speed: 7.516010 samples/s, speed: 3848.197355 tokens/s, learning rate: 9.140e-06, loss_scalings: 13421.773438, pp_loss: 8.304235
[INFO] 2021-07-12 18:50:20,345 [run_pretraining.py:  512]:	********exe.run_915******* 
[INFO] 2021-07-12 18:50:21,295 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:21,295 [run_pretraining.py:  534]:	loss/total_loss, 7.990866661071777, 916
[INFO] 2021-07-12 18:50:21,295 [run_pretraining.py:  535]:	loss/mlm_loss, 7.990866661071777, 916
[INFO] 2021-07-12 18:50:21,295 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.1499996415223e-06, 916
[INFO] 2021-07-12 18:50:21,295 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 916
[INFO] 2021-07-12 18:50:21,295 [run_pretraining.py:  558]:	worker_index: 2, step: 916, cost: 7.990867, mlm loss: 7.990867, speed: 1.052470 steps/s, speed: 8.419761 samples/s, speed: 4310.917691 tokens/s, learning rate: 9.150e-06, loss_scalings: 13421.773438, pp_loss: 8.095067
[INFO] 2021-07-12 18:50:21,296 [run_pretraining.py:  512]:	********exe.run_916******* 
[INFO] 2021-07-12 18:50:22,204 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:22,204 [run_pretraining.py:  534]:	loss/total_loss, 8.20148754119873, 917
[INFO] 2021-07-12 18:50:22,204 [run_pretraining.py:  535]:	loss/mlm_loss, 8.20148754119873, 917
[INFO] 2021-07-12 18:50:22,204 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.159999535768293e-06, 917
[INFO] 2021-07-12 18:50:22,205 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 917
[INFO] 2021-07-12 18:50:22,205 [run_pretraining.py:  558]:	worker_index: 2, step: 917, cost: 8.201488, mlm loss: 8.201488, speed: 1.100616 steps/s, speed: 8.804927 samples/s, speed: 4508.122603 tokens/s, learning rate: 9.160e-06, loss_scalings: 13421.773438, pp_loss: 8.277842
[INFO] 2021-07-12 18:50:22,205 [run_pretraining.py:  512]:	********exe.run_917******* 
[INFO] 2021-07-12 18:50:23,123 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:23,123 [run_pretraining.py:  534]:	loss/total_loss, 7.960453033447266, 918
[INFO] 2021-07-12 18:50:23,123 [run_pretraining.py:  535]:	loss/mlm_loss, 7.960453033447266, 918
[INFO] 2021-07-12 18:50:23,124 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.170000339508988e-06, 918
[INFO] 2021-07-12 18:50:23,124 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 918
[INFO] 2021-07-12 18:50:23,124 [run_pretraining.py:  558]:	worker_index: 2, step: 918, cost: 7.960453, mlm loss: 7.960453, speed: 1.088812 steps/s, speed: 8.710496 samples/s, speed: 4459.773776 tokens/s, learning rate: 9.170e-06, loss_scalings: 13421.773438, pp_loss: 8.296428
[INFO] 2021-07-12 18:50:23,124 [run_pretraining.py:  512]:	********exe.run_918******* 
[INFO] 2021-07-12 18:50:24,034 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:24,034 [run_pretraining.py:  534]:	loss/total_loss, 7.869581699371338, 919
[INFO] 2021-07-12 18:50:24,034 [run_pretraining.py:  535]:	loss/mlm_loss, 7.869581699371338, 919
[INFO] 2021-07-12 18:50:24,034 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.17999932426028e-06, 919
[INFO] 2021-07-12 18:50:24,034 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 919
[INFO] 2021-07-12 18:50:24,035 [run_pretraining.py:  558]:	worker_index: 2, step: 919, cost: 7.869582, mlm loss: 7.869582, speed: 1.098586 steps/s, speed: 8.788689 samples/s, speed: 4499.808713 tokens/s, learning rate: 9.180e-06, loss_scalings: 13421.773438, pp_loss: 7.190972
[INFO] 2021-07-12 18:50:24,035 [run_pretraining.py:  512]:	********exe.run_919******* 
[INFO] 2021-07-12 18:50:24,950 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:24,951 [run_pretraining.py:  534]:	loss/total_loss, 8.11929702758789, 920
[INFO] 2021-07-12 18:50:24,951 [run_pretraining.py:  535]:	loss/mlm_loss, 8.11929702758789, 920
[INFO] 2021-07-12 18:50:24,951 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.189999218506273e-06, 920
[INFO] 2021-07-12 18:50:24,951 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 920
[INFO] 2021-07-12 18:50:24,951 [run_pretraining.py:  558]:	worker_index: 2, step: 920, cost: 8.119297, mlm loss: 8.119297, speed: 1.091902 steps/s, speed: 8.735219 samples/s, speed: 4472.432291 tokens/s, learning rate: 9.190e-06, loss_scalings: 13421.773438, pp_loss: 8.148600
[INFO] 2021-07-12 18:50:24,951 [run_pretraining.py:  512]:	********exe.run_920******* 
[INFO] 2021-07-12 18:50:25,868 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:25,869 [run_pretraining.py:  534]:	loss/total_loss, 8.018044471740723, 921
[INFO] 2021-07-12 18:50:25,869 [run_pretraining.py:  535]:	loss/mlm_loss, 8.018044471740723, 921
[INFO] 2021-07-12 18:50:25,869 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.200000022246968e-06, 921
[INFO] 2021-07-12 18:50:25,869 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 921
[INFO] 2021-07-12 18:50:25,869 [run_pretraining.py:  558]:	worker_index: 2, step: 921, cost: 8.018044, mlm loss: 8.018044, speed: 1.089735 steps/s, speed: 8.717880 samples/s, speed: 4463.554639 tokens/s, learning rate: 9.200e-06, loss_scalings: 13421.773438, pp_loss: 8.229715
[INFO] 2021-07-12 18:50:25,869 [run_pretraining.py:  512]:	********exe.run_921******* 
[INFO] 2021-07-12 18:50:26,786 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:26,787 [run_pretraining.py:  534]:	loss/total_loss, 8.28821086883545, 922
[INFO] 2021-07-12 18:50:26,787 [run_pretraining.py:  535]:	loss/mlm_loss, 8.28821086883545, 922
[INFO] 2021-07-12 18:50:26,787 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.209999916492961e-06, 922
[INFO] 2021-07-12 18:50:26,787 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 922
[INFO] 2021-07-12 18:50:26,787 [run_pretraining.py:  558]:	worker_index: 2, step: 922, cost: 8.288211, mlm loss: 8.288211, speed: 1.089939 steps/s, speed: 8.719516 samples/s, speed: 4464.392092 tokens/s, learning rate: 9.210e-06, loss_scalings: 13421.773438, pp_loss: 8.128337
[INFO] 2021-07-12 18:50:26,787 [run_pretraining.py:  512]:	********exe.run_922******* 
[INFO] 2021-07-12 18:50:27,708 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:27,708 [run_pretraining.py:  534]:	loss/total_loss, 8.364437103271484, 923
[INFO] 2021-07-12 18:50:27,709 [run_pretraining.py:  535]:	loss/mlm_loss, 8.364437103271484, 923
[INFO] 2021-07-12 18:50:27,709 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.219999810738955e-06, 923
[INFO] 2021-07-12 18:50:27,709 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 923
[INFO] 2021-07-12 18:50:27,709 [run_pretraining.py:  558]:	worker_index: 2, step: 923, cost: 8.364437, mlm loss: 8.364437, speed: 1.085975 steps/s, speed: 8.687803 samples/s, speed: 4448.155085 tokens/s, learning rate: 9.220e-06, loss_scalings: 13421.773438, pp_loss: 8.316248
[INFO] 2021-07-12 18:50:27,709 [run_pretraining.py:  512]:	********exe.run_923******* 
[INFO] 2021-07-12 18:50:28,630 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:28,630 [run_pretraining.py:  534]:	loss/total_loss, 8.473567008972168, 924
[INFO] 2021-07-12 18:50:28,631 [run_pretraining.py:  535]:	loss/mlm_loss, 8.473567008972168, 924
[INFO] 2021-07-12 18:50:28,631 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.229999704984948e-06, 924
[INFO] 2021-07-12 18:50:28,631 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 924
[INFO] 2021-07-12 18:50:28,631 [run_pretraining.py:  558]:	worker_index: 2, step: 924, cost: 8.473567, mlm loss: 8.473567, speed: 1.085304 steps/s, speed: 8.682430 samples/s, speed: 4445.404220 tokens/s, learning rate: 9.230e-06, loss_scalings: 13421.773438, pp_loss: 8.069804
[INFO] 2021-07-12 18:50:28,631 [run_pretraining.py:  512]:	********exe.run_924******* 
[INFO] 2021-07-12 18:50:29,546 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:29,547 [run_pretraining.py:  534]:	loss/total_loss, 8.061663627624512, 925
[INFO] 2021-07-12 18:50:29,547 [run_pretraining.py:  535]:	loss/mlm_loss, 8.061663627624512, 925
[INFO] 2021-07-12 18:50:29,547 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.239999599230941e-06, 925
[INFO] 2021-07-12 18:50:29,547 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 925
[INFO] 2021-07-12 18:50:29,547 [run_pretraining.py:  558]:	worker_index: 2, step: 925, cost: 8.061664, mlm loss: 8.061664, speed: 1.092058 steps/s, speed: 8.736463 samples/s, speed: 4473.069258 tokens/s, learning rate: 9.240e-06, loss_scalings: 13421.773438, pp_loss: 8.394461
[INFO] 2021-07-12 18:50:29,547 [run_pretraining.py:  512]:	********exe.run_925******* 
[INFO] 2021-07-12 18:50:30,473 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:30,473 [run_pretraining.py:  534]:	loss/total_loss, 7.772758960723877, 926
[INFO] 2021-07-12 18:50:30,474 [run_pretraining.py:  535]:	loss/mlm_loss, 7.772758960723877, 926
[INFO] 2021-07-12 18:50:30,474 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.249999493476935e-06, 926
[INFO] 2021-07-12 18:50:30,474 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 926
[INFO] 2021-07-12 18:50:30,474 [run_pretraining.py:  558]:	worker_index: 2, step: 926, cost: 7.772759, mlm loss: 7.772759, speed: 1.079718 steps/s, speed: 8.637742 samples/s, speed: 4422.523943 tokens/s, learning rate: 9.250e-06, loss_scalings: 13421.773438, pp_loss: 7.932129
[INFO] 2021-07-12 18:50:30,474 [run_pretraining.py:  512]:	********exe.run_926******* 
[INFO] 2021-07-12 18:50:31,392 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:31,392 [run_pretraining.py:  534]:	loss/total_loss, 6.870555400848389, 927
[INFO] 2021-07-12 18:50:31,392 [run_pretraining.py:  535]:	loss/mlm_loss, 6.870555400848389, 927
[INFO] 2021-07-12 18:50:31,392 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.26000029721763e-06, 927
[INFO] 2021-07-12 18:50:31,392 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 927
[INFO] 2021-07-12 18:50:31,392 [run_pretraining.py:  558]:	worker_index: 2, step: 927, cost: 6.870555, mlm loss: 6.870555, speed: 1.089337 steps/s, speed: 8.714697 samples/s, speed: 4461.924710 tokens/s, learning rate: 9.260e-06, loss_scalings: 13421.773438, pp_loss: 7.766623
[INFO] 2021-07-12 18:50:31,392 [run_pretraining.py:  512]:	********exe.run_927******* 
[INFO] 2021-07-12 18:50:32,319 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:32,320 [run_pretraining.py:  534]:	loss/total_loss, 8.545418739318848, 928
[INFO] 2021-07-12 18:50:32,320 [run_pretraining.py:  535]:	loss/mlm_loss, 8.545418739318848, 928
[INFO] 2021-07-12 18:50:32,320 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.269999281968921e-06, 928
[INFO] 2021-07-12 18:50:32,320 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 928
[INFO] 2021-07-12 18:50:32,320 [run_pretraining.py:  558]:	worker_index: 2, step: 928, cost: 8.545419, mlm loss: 8.545419, speed: 1.078466 steps/s, speed: 8.627725 samples/s, speed: 4417.395410 tokens/s, learning rate: 9.270e-06, loss_scalings: 13421.773438, pp_loss: 8.756837
[INFO] 2021-07-12 18:50:32,320 [run_pretraining.py:  512]:	********exe.run_928******* 
[INFO] 2021-07-12 18:50:33,238 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:33,239 [run_pretraining.py:  534]:	loss/total_loss, 7.963629245758057, 929
[INFO] 2021-07-12 18:50:33,239 [run_pretraining.py:  535]:	loss/mlm_loss, 7.963629245758057, 929
[INFO] 2021-07-12 18:50:33,239 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.280000085709617e-06, 929
[INFO] 2021-07-12 18:50:33,239 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 929
[INFO] 2021-07-12 18:50:33,239 [run_pretraining.py:  558]:	worker_index: 2, step: 929, cost: 7.963629, mlm loss: 7.963629, speed: 1.089134 steps/s, speed: 8.713072 samples/s, speed: 4461.092816 tokens/s, learning rate: 9.280e-06, loss_scalings: 13421.773438, pp_loss: 7.974811
[INFO] 2021-07-12 18:50:33,239 [run_pretraining.py:  512]:	********exe.run_929******* 
[INFO] 2021-07-12 18:50:34,156 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:34,156 [run_pretraining.py:  534]:	loss/total_loss, 8.532886505126953, 930
[INFO] 2021-07-12 18:50:34,156 [run_pretraining.py:  535]:	loss/mlm_loss, 8.532886505126953, 930
[INFO] 2021-07-12 18:50:34,156 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.28999997995561e-06, 930
[INFO] 2021-07-12 18:50:34,156 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 930
[INFO] 2021-07-12 18:50:34,156 [run_pretraining.py:  558]:	worker_index: 2, step: 930, cost: 8.532887, mlm loss: 8.532887, speed: 1.090753 steps/s, speed: 8.726024 samples/s, speed: 4467.724136 tokens/s, learning rate: 9.290e-06, loss_scalings: 13421.773438, pp_loss: 8.147138
[INFO] 2021-07-12 18:50:34,156 [run_pretraining.py:  512]:	********exe.run_930******* 
[INFO] 2021-07-12 18:50:35,070 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:35,071 [run_pretraining.py:  534]:	loss/total_loss, 8.675093650817871, 931
[INFO] 2021-07-12 18:50:35,071 [run_pretraining.py:  535]:	loss/mlm_loss, 8.675093650817871, 931
[INFO] 2021-07-12 18:50:35,071 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.299999874201603e-06, 931
[INFO] 2021-07-12 18:50:35,071 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 931
[INFO] 2021-07-12 18:50:35,071 [run_pretraining.py:  558]:	worker_index: 2, step: 931, cost: 8.675094, mlm loss: 8.675094, speed: 1.093688 steps/s, speed: 8.749503 samples/s, speed: 4479.745603 tokens/s, learning rate: 9.300e-06, loss_scalings: 13421.773438, pp_loss: 8.152261
[INFO] 2021-07-12 18:50:35,071 [run_pretraining.py:  512]:	********exe.run_931******* 
[INFO] 2021-07-12 18:50:35,977 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:35,977 [run_pretraining.py:  534]:	loss/total_loss, 8.034504890441895, 932
[INFO] 2021-07-12 18:50:35,977 [run_pretraining.py:  535]:	loss/mlm_loss, 8.034504890441895, 932
[INFO] 2021-07-12 18:50:35,977 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.309999768447597e-06, 932
[INFO] 2021-07-12 18:50:35,977 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 932
[INFO] 2021-07-12 18:50:35,977 [run_pretraining.py:  558]:	worker_index: 2, step: 932, cost: 8.034505, mlm loss: 8.034505, speed: 1.104389 steps/s, speed: 8.835115 samples/s, speed: 4523.578790 tokens/s, learning rate: 9.310e-06, loss_scalings: 13421.773438, pp_loss: 7.959230
[INFO] 2021-07-12 18:50:35,977 [run_pretraining.py:  512]:	********exe.run_932******* 
[INFO] 2021-07-12 18:50:36,897 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:36,898 [run_pretraining.py:  534]:	loss/total_loss, 7.673586845397949, 933
[INFO] 2021-07-12 18:50:36,898 [run_pretraining.py:  535]:	loss/mlm_loss, 7.673586845397949, 933
[INFO] 2021-07-12 18:50:36,898 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.31999966269359e-06, 933
[INFO] 2021-07-12 18:50:36,898 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 933
[INFO] 2021-07-12 18:50:36,898 [run_pretraining.py:  558]:	worker_index: 2, step: 933, cost: 7.673587, mlm loss: 7.673587, speed: 1.086793 steps/s, speed: 8.694345 samples/s, speed: 4451.504450 tokens/s, learning rate: 9.320e-06, loss_scalings: 13421.773438, pp_loss: 7.818370
[INFO] 2021-07-12 18:50:36,898 [run_pretraining.py:  512]:	********exe.run_933******* 
[INFO] 2021-07-12 18:50:37,818 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:37,819 [run_pretraining.py:  534]:	loss/total_loss, 7.3777055740356445, 934
[INFO] 2021-07-12 18:50:37,819 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3777055740356445, 934
[INFO] 2021-07-12 18:50:37,819 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.329999556939583e-06, 934
[INFO] 2021-07-12 18:50:37,819 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 934
[INFO] 2021-07-12 18:50:37,819 [run_pretraining.py:  558]:	worker_index: 2, step: 934, cost: 7.377706, mlm loss: 7.377706, speed: 1.086373 steps/s, speed: 8.690982 samples/s, speed: 4449.783035 tokens/s, learning rate: 9.330e-06, loss_scalings: 13421.773438, pp_loss: 7.920394
[INFO] 2021-07-12 18:50:37,819 [run_pretraining.py:  512]:	********exe.run_934******* 
[INFO] 2021-07-12 18:50:38,746 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:38,746 [run_pretraining.py:  534]:	loss/total_loss, 8.14976692199707, 935
[INFO] 2021-07-12 18:50:38,747 [run_pretraining.py:  535]:	loss/mlm_loss, 8.14976692199707, 935
[INFO] 2021-07-12 18:50:38,747 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.340000360680278e-06, 935
[INFO] 2021-07-12 18:50:38,747 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 935
[INFO] 2021-07-12 18:50:38,747 [run_pretraining.py:  558]:	worker_index: 2, step: 935, cost: 8.149767, mlm loss: 8.149767, speed: 1.078814 steps/s, speed: 8.630508 samples/s, speed: 4418.820198 tokens/s, learning rate: 9.340e-06, loss_scalings: 13421.773438, pp_loss: 8.047800
[INFO] 2021-07-12 18:50:38,747 [run_pretraining.py:  512]:	********exe.run_935******* 
[INFO] 2021-07-12 18:50:39,879 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:39,880 [run_pretraining.py:  534]:	loss/total_loss, 8.430051803588867, 936
[INFO] 2021-07-12 18:50:39,880 [run_pretraining.py:  535]:	loss/mlm_loss, 8.430051803588867, 936
[INFO] 2021-07-12 18:50:39,880 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.350000254926272e-06, 936
[INFO] 2021-07-12 18:50:39,880 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 936
[INFO] 2021-07-12 18:50:39,880 [run_pretraining.py:  558]:	worker_index: 2, step: 936, cost: 8.430052, mlm loss: 8.430052, speed: 0.882767 steps/s, speed: 7.062139 samples/s, speed: 3615.815078 tokens/s, learning rate: 9.350e-06, loss_scalings: 13421.773438, pp_loss: 8.205853
[INFO] 2021-07-12 18:50:39,880 [run_pretraining.py:  512]:	********exe.run_936******* 
[INFO] 2021-07-12 18:50:40,846 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:40,851 [run_pretraining.py:  534]:	loss/total_loss, 8.169967651367188, 937
[INFO] 2021-07-12 18:50:40,856 [run_pretraining.py:  535]:	loss/mlm_loss, 8.169967651367188, 937
[INFO] 2021-07-12 18:50:40,862 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.359999239677563e-06, 937
[INFO] 2021-07-12 18:50:40,867 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 937
[INFO] 2021-07-12 18:50:40,872 [run_pretraining.py:  558]:	worker_index: 2, step: 937, cost: 8.169968, mlm loss: 8.169968, speed: 1.030020 steps/s, speed: 8.240157 samples/s, speed: 4218.960611 tokens/s, learning rate: 9.360e-06, loss_scalings: 13421.773438, pp_loss: 8.282845
[INFO] 2021-07-12 18:50:40,877 [run_pretraining.py:  512]:	********exe.run_937******* 
[INFO] 2021-07-12 18:50:41,767 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:41,768 [run_pretraining.py:  534]:	loss/total_loss, 8.238901138305664, 938
[INFO] 2021-07-12 18:50:41,768 [run_pretraining.py:  535]:	loss/mlm_loss, 8.238901138305664, 938
[INFO] 2021-07-12 18:50:41,768 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.370000043418258e-06, 938
[INFO] 2021-07-12 18:50:41,768 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 938
[INFO] 2021-07-12 18:50:41,768 [run_pretraining.py:  558]:	worker_index: 2, step: 938, cost: 8.238901, mlm loss: 8.238901, speed: 1.123085 steps/s, speed: 8.984679 samples/s, speed: 4600.155406 tokens/s, learning rate: 9.370e-06, loss_scalings: 13421.773438, pp_loss: 8.028080
[INFO] 2021-07-12 18:50:41,768 [run_pretraining.py:  512]:	********exe.run_938******* 
[INFO] 2021-07-12 18:50:42,679 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:42,679 [run_pretraining.py:  534]:	loss/total_loss, 8.15560531616211, 939
[INFO] 2021-07-12 18:50:42,679 [run_pretraining.py:  535]:	loss/mlm_loss, 8.15560531616211, 939
[INFO] 2021-07-12 18:50:42,679 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.379999937664252e-06, 939
[INFO] 2021-07-12 18:50:42,679 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 939
[INFO] 2021-07-12 18:50:42,679 [run_pretraining.py:  558]:	worker_index: 2, step: 939, cost: 8.155605, mlm loss: 8.155605, speed: 1.098040 steps/s, speed: 8.784322 samples/s, speed: 4497.572833 tokens/s, learning rate: 9.380e-06, loss_scalings: 13421.773438, pp_loss: 8.044707
[INFO] 2021-07-12 18:50:42,679 [run_pretraining.py:  512]:	********exe.run_939******* 
[INFO] 2021-07-12 18:50:43,595 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:43,596 [run_pretraining.py:  534]:	loss/total_loss, 8.576789855957031, 940
[INFO] 2021-07-12 18:50:43,596 [run_pretraining.py:  535]:	loss/mlm_loss, 8.576789855957031, 940
[INFO] 2021-07-12 18:50:43,596 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.389999831910245e-06, 940
[INFO] 2021-07-12 18:50:43,596 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 940
[INFO] 2021-07-12 18:50:43,596 [run_pretraining.py:  558]:	worker_index: 2, step: 940, cost: 8.576790, mlm loss: 8.576790, speed: 1.091367 steps/s, speed: 8.730935 samples/s, speed: 4470.238648 tokens/s, learning rate: 9.390e-06, loss_scalings: 13421.773438, pp_loss: 8.253592
[INFO] 2021-07-12 18:50:43,596 [run_pretraining.py:  512]:	********exe.run_940******* 
[INFO] 2021-07-12 18:50:44,507 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:44,508 [run_pretraining.py:  534]:	loss/total_loss, 8.243218421936035, 941
[INFO] 2021-07-12 18:50:44,508 [run_pretraining.py:  535]:	loss/mlm_loss, 8.243218421936035, 941
[INFO] 2021-07-12 18:50:44,508 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.399999726156238e-06, 941
[INFO] 2021-07-12 18:50:44,508 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 941
[INFO] 2021-07-12 18:50:44,508 [run_pretraining.py:  558]:	worker_index: 2, step: 941, cost: 8.243218, mlm loss: 8.243218, speed: 1.097632 steps/s, speed: 8.781058 samples/s, speed: 4495.901498 tokens/s, learning rate: 9.400e-06, loss_scalings: 13421.773438, pp_loss: 8.159550
[INFO] 2021-07-12 18:50:44,508 [run_pretraining.py:  512]:	********exe.run_941******* 
[INFO] 2021-07-12 18:50:45,421 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:45,422 [run_pretraining.py:  534]:	loss/total_loss, 8.168864250183105, 942
[INFO] 2021-07-12 18:50:45,422 [run_pretraining.py:  535]:	loss/mlm_loss, 8.168864250183105, 942
[INFO] 2021-07-12 18:50:45,422 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.409999620402232e-06, 942
[INFO] 2021-07-12 18:50:45,422 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 942
[INFO] 2021-07-12 18:50:45,422 [run_pretraining.py:  558]:	worker_index: 2, step: 942, cost: 8.168864, mlm loss: 8.168864, speed: 1.094565 steps/s, speed: 8.756517 samples/s, speed: 4483.336939 tokens/s, learning rate: 9.410e-06, loss_scalings: 13421.773438, pp_loss: 8.146511
[INFO] 2021-07-12 18:50:45,422 [run_pretraining.py:  512]:	********exe.run_942******* 
[INFO] 2021-07-12 18:50:46,343 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:46,343 [run_pretraining.py:  534]:	loss/total_loss, 8.270675659179688, 943
[INFO] 2021-07-12 18:50:46,344 [run_pretraining.py:  535]:	loss/mlm_loss, 8.270675659179688, 943
[INFO] 2021-07-12 18:50:46,344 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.419999514648225e-06, 943
[INFO] 2021-07-12 18:50:46,344 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 943
[INFO] 2021-07-12 18:50:46,344 [run_pretraining.py:  558]:	worker_index: 2, step: 943, cost: 8.270676, mlm loss: 8.270676, speed: 1.085692 steps/s, speed: 8.685534 samples/s, speed: 4446.993321 tokens/s, learning rate: 9.420e-06, loss_scalings: 13421.773438, pp_loss: 8.156305
[INFO] 2021-07-12 18:50:46,344 [run_pretraining.py:  512]:	********exe.run_943******* 
[INFO] 2021-07-12 18:50:47,255 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:47,256 [run_pretraining.py:  534]:	loss/total_loss, 8.232244491577148, 944
[INFO] 2021-07-12 18:50:47,256 [run_pretraining.py:  535]:	loss/mlm_loss, 8.232244491577148, 944
[INFO] 2021-07-12 18:50:47,256 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.43000031838892e-06, 944
[INFO] 2021-07-12 18:50:47,256 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 944
[INFO] 2021-07-12 18:50:47,256 [run_pretraining.py:  558]:	worker_index: 2, step: 944, cost: 8.232244, mlm loss: 8.232244, speed: 1.097118 steps/s, speed: 8.776946 samples/s, speed: 4493.796443 tokens/s, learning rate: 9.430e-06, loss_scalings: 13421.773438, pp_loss: 8.332314
[INFO] 2021-07-12 18:50:47,256 [run_pretraining.py:  512]:	********exe.run_944******* 
[INFO] 2021-07-12 18:50:48,169 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:48,169 [run_pretraining.py:  534]:	loss/total_loss, 6.752173900604248, 945
[INFO] 2021-07-12 18:50:48,169 [run_pretraining.py:  535]:	loss/mlm_loss, 6.752173900604248, 945
[INFO] 2021-07-12 18:50:48,169 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.440000212634914e-06, 945
[INFO] 2021-07-12 18:50:48,169 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 945
[INFO] 2021-07-12 18:50:48,169 [run_pretraining.py:  558]:	worker_index: 2, step: 945, cost: 6.752174, mlm loss: 6.752174, speed: 1.095401 steps/s, speed: 8.763211 samples/s, speed: 4486.764124 tokens/s, learning rate: 9.440e-06, loss_scalings: 13421.773438, pp_loss: 7.707118
[INFO] 2021-07-12 18:50:48,169 [run_pretraining.py:  512]:	********exe.run_945******* 
[INFO] 2021-07-12 18:50:49,083 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:49,083 [run_pretraining.py:  534]:	loss/total_loss, 8.692047119140625, 946
[INFO] 2021-07-12 18:50:49,083 [run_pretraining.py:  535]:	loss/mlm_loss, 8.692047119140625, 946
[INFO] 2021-07-12 18:50:49,083 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.449999197386205e-06, 946
[INFO] 2021-07-12 18:50:49,084 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 946
[INFO] 2021-07-12 18:50:49,084 [run_pretraining.py:  558]:	worker_index: 2, step: 946, cost: 8.692047, mlm loss: 8.692047, speed: 1.094530 steps/s, speed: 8.756239 samples/s, speed: 4483.194205 tokens/s, learning rate: 9.450e-06, loss_scalings: 13421.773438, pp_loss: 8.392861
[INFO] 2021-07-12 18:50:49,084 [run_pretraining.py:  512]:	********exe.run_946******* 
[INFO] 2021-07-12 18:50:50,066 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:50,066 [run_pretraining.py:  534]:	loss/total_loss, 8.954354286193848, 947
[INFO] 2021-07-12 18:50:50,066 [run_pretraining.py:  535]:	loss/mlm_loss, 8.954354286193848, 947
[INFO] 2021-07-12 18:50:50,066 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.4600000011269e-06, 947
[INFO] 2021-07-12 18:50:50,066 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 947
[INFO] 2021-07-12 18:50:50,066 [run_pretraining.py:  558]:	worker_index: 2, step: 947, cost: 8.954354, mlm loss: 8.954354, speed: 1.018194 steps/s, speed: 8.145553 samples/s, speed: 4170.523058 tokens/s, learning rate: 9.460e-06, loss_scalings: 13421.773438, pp_loss: 8.467329
[INFO] 2021-07-12 18:50:50,066 [run_pretraining.py:  512]:	********exe.run_947******* 
[INFO] 2021-07-12 18:50:51,133 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:51,133 [run_pretraining.py:  534]:	loss/total_loss, 8.357548713684082, 948
[INFO] 2021-07-12 18:50:51,133 [run_pretraining.py:  535]:	loss/mlm_loss, 8.357548713684082, 948
[INFO] 2021-07-12 18:50:51,133 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.469999895372894e-06, 948
[INFO] 2021-07-12 18:50:51,133 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 948
[INFO] 2021-07-12 18:50:51,133 [run_pretraining.py:  558]:	worker_index: 2, step: 948, cost: 8.357549, mlm loss: 8.357549, speed: 0.937634 steps/s, speed: 7.501072 samples/s, speed: 3840.548765 tokens/s, learning rate: 9.470e-06, loss_scalings: 13421.773438, pp_loss: 7.549554
[INFO] 2021-07-12 18:50:51,134 [run_pretraining.py:  512]:	********exe.run_948******* 
[INFO] 2021-07-12 18:50:52,195 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:52,196 [run_pretraining.py:  534]:	loss/total_loss, 8.155807495117188, 949
[INFO] 2021-07-12 18:50:52,196 [run_pretraining.py:  535]:	loss/mlm_loss, 8.155807495117188, 949
[INFO] 2021-07-12 18:50:52,196 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.479999789618887e-06, 949
[INFO] 2021-07-12 18:50:52,196 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 949
[INFO] 2021-07-12 18:50:52,196 [run_pretraining.py:  558]:	worker_index: 2, step: 949, cost: 8.155807, mlm loss: 8.155807, speed: 0.941644 steps/s, speed: 7.533151 samples/s, speed: 3856.973269 tokens/s, learning rate: 9.480e-06, loss_scalings: 13421.773438, pp_loss: 8.530396
[INFO] 2021-07-12 18:50:52,196 [run_pretraining.py:  512]:	********exe.run_949******* 
[INFO] 2021-07-12 18:50:53,254 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:53,254 [run_pretraining.py:  534]:	loss/total_loss, 8.666712760925293, 950
[INFO] 2021-07-12 18:50:53,254 [run_pretraining.py:  535]:	loss/mlm_loss, 8.666712760925293, 950
[INFO] 2021-07-12 18:50:53,254 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.48999968386488e-06, 950
[INFO] 2021-07-12 18:50:53,254 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 950
[INFO] 2021-07-12 18:50:53,255 [run_pretraining.py:  558]:	worker_index: 2, step: 950, cost: 8.666713, mlm loss: 8.666713, speed: 0.945271 steps/s, speed: 7.562171 samples/s, speed: 3871.831308 tokens/s, learning rate: 9.490e-06, loss_scalings: 13421.773438, pp_loss: 8.138408
[INFO] 2021-07-12 18:50:53,255 [run_pretraining.py:  512]:	********exe.run_950******* 
[INFO] 2021-07-12 18:50:54,318 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:54,318 [run_pretraining.py:  534]:	loss/total_loss, 8.109113693237305, 951
[INFO] 2021-07-12 18:50:54,319 [run_pretraining.py:  535]:	loss/mlm_loss, 8.109113693237305, 951
[INFO] 2021-07-12 18:50:54,319 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.499999578110874e-06, 951
[INFO] 2021-07-12 18:50:54,319 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 951
[INFO] 2021-07-12 18:50:54,319 [run_pretraining.py:  558]:	worker_index: 2, step: 951, cost: 8.109114, mlm loss: 8.109114, speed: 0.940118 steps/s, speed: 7.520945 samples/s, speed: 3850.723739 tokens/s, learning rate: 9.500e-06, loss_scalings: 13421.773438, pp_loss: 8.215979
[INFO] 2021-07-12 18:50:54,319 [run_pretraining.py:  512]:	********exe.run_951******* 
[INFO] 2021-07-12 18:50:55,382 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:55,382 [run_pretraining.py:  534]:	loss/total_loss, 8.067461013793945, 952
[INFO] 2021-07-12 18:50:55,382 [run_pretraining.py:  535]:	loss/mlm_loss, 8.067461013793945, 952
[INFO] 2021-07-12 18:50:55,383 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.509999472356867e-06, 952
[INFO] 2021-07-12 18:50:55,383 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 952
[INFO] 2021-07-12 18:50:55,383 [run_pretraining.py:  558]:	worker_index: 2, step: 952, cost: 8.067461, mlm loss: 8.067461, speed: 0.940543 steps/s, speed: 7.524343 samples/s, speed: 3852.463686 tokens/s, learning rate: 9.510e-06, loss_scalings: 13421.773438, pp_loss: 8.095161
[INFO] 2021-07-12 18:50:55,383 [run_pretraining.py:  512]:	********exe.run_952******* 
[INFO] 2021-07-12 18:50:56,462 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:56,463 [run_pretraining.py:  534]:	loss/total_loss, 8.154731750488281, 953
[INFO] 2021-07-12 18:50:56,463 [run_pretraining.py:  535]:	loss/mlm_loss, 8.154731750488281, 953
[INFO] 2021-07-12 18:50:56,463 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.520000276097562e-06, 953
[INFO] 2021-07-12 18:50:56,463 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 953
[INFO] 2021-07-12 18:50:56,463 [run_pretraining.py:  558]:	worker_index: 2, step: 953, cost: 8.154732, mlm loss: 8.154732, speed: 0.926177 steps/s, speed: 7.409415 samples/s, speed: 3793.620439 tokens/s, learning rate: 9.520e-06, loss_scalings: 13421.773438, pp_loss: 8.083700
[INFO] 2021-07-12 18:50:56,463 [run_pretraining.py:  512]:	********exe.run_953******* 
[INFO] 2021-07-12 18:50:57,548 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:57,549 [run_pretraining.py:  534]:	loss/total_loss, 7.7845587730407715, 954
[INFO] 2021-07-12 18:50:57,549 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7845587730407715, 954
[INFO] 2021-07-12 18:50:57,549 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.529999260848854e-06, 954
[INFO] 2021-07-12 18:50:57,549 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 954
[INFO] 2021-07-12 18:50:57,549 [run_pretraining.py:  558]:	worker_index: 2, step: 954, cost: 7.784559, mlm loss: 7.784559, speed: 0.921363 steps/s, speed: 7.370902 samples/s, speed: 3773.901839 tokens/s, learning rate: 9.530e-06, loss_scalings: 13421.773438, pp_loss: 8.134711
[INFO] 2021-07-12 18:50:57,549 [run_pretraining.py:  512]:	********exe.run_954******* 
[INFO] 2021-07-12 18:50:58,618 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:58,618 [run_pretraining.py:  534]:	loss/total_loss, 8.202417373657227, 955
[INFO] 2021-07-12 18:50:58,618 [run_pretraining.py:  535]:	loss/mlm_loss, 8.202417373657227, 955
[INFO] 2021-07-12 18:50:58,619 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.539999155094847e-06, 955
[INFO] 2021-07-12 18:50:58,619 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 955
[INFO] 2021-07-12 18:50:58,619 [run_pretraining.py:  558]:	worker_index: 2, step: 955, cost: 8.202417, mlm loss: 8.202417, speed: 0.935315 steps/s, speed: 7.482523 samples/s, speed: 3831.051822 tokens/s, learning rate: 9.540e-06, loss_scalings: 13421.773438, pp_loss: 8.114477
[INFO] 2021-07-12 18:50:58,619 [run_pretraining.py:  512]:	********exe.run_955******* 
[INFO] 2021-07-12 18:50:59,685 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:59,686 [run_pretraining.py:  534]:	loss/total_loss, 8.103328704833984, 956
[INFO] 2021-07-12 18:50:59,686 [run_pretraining.py:  535]:	loss/mlm_loss, 8.103328704833984, 956
[INFO] 2021-07-12 18:50:59,686 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.549999958835542e-06, 956
[INFO] 2021-07-12 18:50:59,686 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 956
[INFO] 2021-07-12 18:50:59,686 [run_pretraining.py:  558]:	worker_index: 2, step: 956, cost: 8.103329, mlm loss: 8.103329, speed: 0.937300 steps/s, speed: 7.498398 samples/s, speed: 3839.179863 tokens/s, learning rate: 9.550e-06, loss_scalings: 13421.773438, pp_loss: 8.016788
[INFO] 2021-07-12 18:50:59,686 [run_pretraining.py:  512]:	********exe.run_956******* 
[INFO] 2021-07-12 18:51:00,750 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:00,751 [run_pretraining.py:  534]:	loss/total_loss, 8.129034996032715, 957
[INFO] 2021-07-12 18:51:00,751 [run_pretraining.py:  535]:	loss/mlm_loss, 8.129034996032715, 957
[INFO] 2021-07-12 18:51:00,751 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.559999853081536e-06, 957
[INFO] 2021-07-12 18:51:00,751 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 957
[INFO] 2021-07-12 18:51:00,751 [run_pretraining.py:  558]:	worker_index: 2, step: 957, cost: 8.129035, mlm loss: 8.129035, speed: 0.939459 steps/s, speed: 7.515674 samples/s, speed: 3848.024968 tokens/s, learning rate: 9.560e-06, loss_scalings: 13421.773438, pp_loss: 7.942739
[INFO] 2021-07-12 18:51:00,751 [run_pretraining.py:  512]:	********exe.run_957******* 
[INFO] 2021-07-12 18:51:01,830 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:01,830 [run_pretraining.py:  534]:	loss/total_loss, 8.15925121307373, 958
[INFO] 2021-07-12 18:51:01,830 [run_pretraining.py:  535]:	loss/mlm_loss, 8.15925121307373, 958
[INFO] 2021-07-12 18:51:01,830 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.569999747327529e-06, 958
[INFO] 2021-07-12 18:51:01,830 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 958
[INFO] 2021-07-12 18:51:01,830 [run_pretraining.py:  558]:	worker_index: 2, step: 958, cost: 8.159251, mlm loss: 8.159251, speed: 0.927150 steps/s, speed: 7.417200 samples/s, speed: 3797.606204 tokens/s, learning rate: 9.570e-06, loss_scalings: 13421.773438, pp_loss: 7.979009
[INFO] 2021-07-12 18:51:01,830 [run_pretraining.py:  512]:	********exe.run_958******* 
[INFO] 2021-07-12 18:51:02,896 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:02,897 [run_pretraining.py:  534]:	loss/total_loss, 8.261707305908203, 959
[INFO] 2021-07-12 18:51:02,897 [run_pretraining.py:  535]:	loss/mlm_loss, 8.261707305908203, 959
[INFO] 2021-07-12 18:51:02,897 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.579999641573522e-06, 959
[INFO] 2021-07-12 18:51:02,897 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 959
[INFO] 2021-07-12 18:51:02,897 [run_pretraining.py:  558]:	worker_index: 2, step: 959, cost: 8.261707, mlm loss: 8.261707, speed: 0.937916 steps/s, speed: 7.503330 samples/s, speed: 3841.704725 tokens/s, learning rate: 9.580e-06, loss_scalings: 13421.773438, pp_loss: 8.099638
[INFO] 2021-07-12 18:51:02,897 [run_pretraining.py:  512]:	********exe.run_959******* 
[INFO] 2021-07-12 18:51:03,964 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:03,965 [run_pretraining.py:  534]:	loss/total_loss, 8.333486557006836, 960
[INFO] 2021-07-12 18:51:03,965 [run_pretraining.py:  535]:	loss/mlm_loss, 8.333486557006836, 960
[INFO] 2021-07-12 18:51:03,965 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.589999535819516e-06, 960
[INFO] 2021-07-12 18:51:03,965 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 960
[INFO] 2021-07-12 18:51:03,965 [run_pretraining.py:  558]:	worker_index: 2, step: 960, cost: 8.333487, mlm loss: 8.333487, speed: 0.936751 steps/s, speed: 7.494007 samples/s, speed: 3836.931661 tokens/s, learning rate: 9.590e-06, loss_scalings: 13421.773438, pp_loss: 8.280434
[INFO] 2021-07-12 18:51:03,965 [run_pretraining.py:  512]:	********exe.run_960******* 
[INFO] 2021-07-12 18:51:05,024 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:05,024 [run_pretraining.py:  534]:	loss/total_loss, 8.037650108337402, 961
[INFO] 2021-07-12 18:51:05,024 [run_pretraining.py:  535]:	loss/mlm_loss, 8.037650108337402, 961
[INFO] 2021-07-12 18:51:05,024 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.599999430065509e-06, 961
[INFO] 2021-07-12 18:51:05,024 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 961
[INFO] 2021-07-12 18:51:05,024 [run_pretraining.py:  558]:	worker_index: 2, step: 961, cost: 8.037650, mlm loss: 8.037650, speed: 0.944723 steps/s, speed: 7.557783 samples/s, speed: 3869.584806 tokens/s, learning rate: 9.600e-06, loss_scalings: 13421.773438, pp_loss: 8.042365
[INFO] 2021-07-12 18:51:05,024 [run_pretraining.py:  512]:	********exe.run_961******* 
[INFO] 2021-07-12 18:51:05,967 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:05,968 [run_pretraining.py:  534]:	loss/total_loss, 7.860180854797363, 962
[INFO] 2021-07-12 18:51:05,968 [run_pretraining.py:  535]:	loss/mlm_loss, 7.860180854797363, 962
[INFO] 2021-07-12 18:51:05,968 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.610000233806204e-06, 962
[INFO] 2021-07-12 18:51:05,968 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 962
[INFO] 2021-07-12 18:51:05,968 [run_pretraining.py:  558]:	worker_index: 2, step: 962, cost: 7.860181, mlm loss: 7.860181, speed: 1.060257 steps/s, speed: 8.482059 samples/s, speed: 4342.814252 tokens/s, learning rate: 9.610e-06, loss_scalings: 13421.773438, pp_loss: 7.981781
[INFO] 2021-07-12 18:51:05,968 [run_pretraining.py:  512]:	********exe.run_962******* 
[INFO] 2021-07-12 18:51:06,878 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:06,879 [run_pretraining.py:  534]:	loss/total_loss, 7.932926654815674, 963
[INFO] 2021-07-12 18:51:06,879 [run_pretraining.py:  535]:	loss/mlm_loss, 7.932926654815674, 963
[INFO] 2021-07-12 18:51:06,879 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.619999218557496e-06, 963
[INFO] 2021-07-12 18:51:06,879 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 963
[INFO] 2021-07-12 18:51:06,879 [run_pretraining.py:  558]:	worker_index: 2, step: 963, cost: 7.932927, mlm loss: 7.932927, speed: 1.098466 steps/s, speed: 8.787729 samples/s, speed: 4499.317289 tokens/s, learning rate: 9.620e-06, loss_scalings: 13421.773438, pp_loss: 8.040180
[INFO] 2021-07-12 18:51:06,879 [run_pretraining.py:  512]:	********exe.run_963******* 
[INFO] 2021-07-12 18:51:07,800 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:07,800 [run_pretraining.py:  534]:	loss/total_loss, 7.966578006744385, 964
[INFO] 2021-07-12 18:51:07,800 [run_pretraining.py:  535]:	loss/mlm_loss, 7.966578006744385, 964
[INFO] 2021-07-12 18:51:07,800 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.63000002229819e-06, 964
[INFO] 2021-07-12 18:51:07,800 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 964
[INFO] 2021-07-12 18:51:07,801 [run_pretraining.py:  558]:	worker_index: 2, step: 964, cost: 7.966578, mlm loss: 7.966578, speed: 1.085986 steps/s, speed: 8.687891 samples/s, speed: 4448.200002 tokens/s, learning rate: 9.630e-06, loss_scalings: 13421.773438, pp_loss: 8.023813
[INFO] 2021-07-12 18:51:07,801 [run_pretraining.py:  512]:	********exe.run_964******* 
[INFO] 2021-07-12 18:51:08,711 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:08,712 [run_pretraining.py:  534]:	loss/total_loss, 7.714420318603516, 965
[INFO] 2021-07-12 18:51:08,712 [run_pretraining.py:  535]:	loss/mlm_loss, 7.714420318603516, 965
[INFO] 2021-07-12 18:51:08,712 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.639999916544184e-06, 965
[INFO] 2021-07-12 18:51:08,712 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 965
[INFO] 2021-07-12 18:51:08,712 [run_pretraining.py:  558]:	worker_index: 2, step: 965, cost: 7.714420, mlm loss: 7.714420, speed: 1.097522 steps/s, speed: 8.780178 samples/s, speed: 4495.450921 tokens/s, learning rate: 9.640e-06, loss_scalings: 13421.773438, pp_loss: 8.076216
[INFO] 2021-07-12 18:51:08,712 [run_pretraining.py:  512]:	********exe.run_965******* 
[INFO] 2021-07-12 18:51:09,627 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:09,628 [run_pretraining.py:  534]:	loss/total_loss, 7.979450702667236, 966
[INFO] 2021-07-12 18:51:09,628 [run_pretraining.py:  535]:	loss/mlm_loss, 7.979450702667236, 966
[INFO] 2021-07-12 18:51:09,628 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.649999810790177e-06, 966
[INFO] 2021-07-12 18:51:09,628 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 966
[INFO] 2021-07-12 18:51:09,628 [run_pretraining.py:  558]:	worker_index: 2, step: 966, cost: 7.979451, mlm loss: 7.979451, speed: 1.092894 steps/s, speed: 8.743152 samples/s, speed: 4476.493587 tokens/s, learning rate: 9.650e-06, loss_scalings: 13421.773438, pp_loss: 7.918772
[INFO] 2021-07-12 18:51:09,628 [run_pretraining.py:  512]:	********exe.run_966******* 
[INFO] 2021-07-12 18:51:10,538 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:10,539 [run_pretraining.py:  534]:	loss/total_loss, 8.191095352172852, 967
[INFO] 2021-07-12 18:51:10,539 [run_pretraining.py:  535]:	loss/mlm_loss, 8.191095352172852, 967
[INFO] 2021-07-12 18:51:10,539 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.65999970503617e-06, 967
[INFO] 2021-07-12 18:51:10,539 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 967
[INFO] 2021-07-12 18:51:10,539 [run_pretraining.py:  558]:	worker_index: 2, step: 967, cost: 8.191095, mlm loss: 8.191095, speed: 1.098340 steps/s, speed: 8.786723 samples/s, speed: 4498.802410 tokens/s, learning rate: 9.660e-06, loss_scalings: 13421.773438, pp_loss: 8.174852
[INFO] 2021-07-12 18:51:10,539 [run_pretraining.py:  512]:	********exe.run_967******* 
[INFO] 2021-07-12 18:51:11,470 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:11,471 [run_pretraining.py:  534]:	loss/total_loss, 8.073962211608887, 968
[INFO] 2021-07-12 18:51:11,471 [run_pretraining.py:  535]:	loss/mlm_loss, 8.073962211608887, 968
[INFO] 2021-07-12 18:51:11,471 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.669999599282164e-06, 968
[INFO] 2021-07-12 18:51:11,471 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 968
[INFO] 2021-07-12 18:51:11,471 [run_pretraining.py:  558]:	worker_index: 2, step: 968, cost: 8.073962, mlm loss: 8.073962, speed: 1.073714 steps/s, speed: 8.589715 samples/s, speed: 4397.933924 tokens/s, learning rate: 9.670e-06, loss_scalings: 13421.773438, pp_loss: 8.170156
[INFO] 2021-07-12 18:51:11,471 [run_pretraining.py:  512]:	********exe.run_968******* 
[INFO] 2021-07-12 18:51:12,375 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:12,375 [run_pretraining.py:  534]:	loss/total_loss, 8.498629570007324, 969
[INFO] 2021-07-12 18:51:12,375 [run_pretraining.py:  535]:	loss/mlm_loss, 8.498629570007324, 969
[INFO] 2021-07-12 18:51:12,375 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.679999493528157e-06, 969
[INFO] 2021-07-12 18:51:12,375 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 969
[INFO] 2021-07-12 18:51:12,375 [run_pretraining.py:  558]:	worker_index: 2, step: 969, cost: 8.498630, mlm loss: 8.498630, speed: 1.106226 steps/s, speed: 8.849809 samples/s, speed: 4531.102294 tokens/s, learning rate: 9.680e-06, loss_scalings: 13421.773438, pp_loss: 8.141436
[INFO] 2021-07-12 18:51:12,376 [run_pretraining.py:  512]:	********exe.run_969******* 
[INFO] 2021-07-12 18:51:13,282 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:13,282 [run_pretraining.py:  534]:	loss/total_loss, 8.137564659118652, 970
[INFO] 2021-07-12 18:51:13,283 [run_pretraining.py:  535]:	loss/mlm_loss, 8.137564659118652, 970
[INFO] 2021-07-12 18:51:13,283 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.690000297268853e-06, 970
[INFO] 2021-07-12 18:51:13,283 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 970
[INFO] 2021-07-12 18:51:13,283 [run_pretraining.py:  558]:	worker_index: 2, step: 970, cost: 8.137565, mlm loss: 8.137565, speed: 1.102892 steps/s, speed: 8.823136 samples/s, speed: 4517.445858 tokens/s, learning rate: 9.690e-06, loss_scalings: 13421.773438, pp_loss: 8.171918
[INFO] 2021-07-12 18:51:13,283 [run_pretraining.py:  512]:	********exe.run_970******* 
[INFO] 2021-07-12 18:51:14,189 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:14,189 [run_pretraining.py:  534]:	loss/total_loss, 8.597978591918945, 971
[INFO] 2021-07-12 18:51:14,189 [run_pretraining.py:  535]:	loss/mlm_loss, 8.597978591918945, 971
[INFO] 2021-07-12 18:51:14,189 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.700000191514846e-06, 971
[INFO] 2021-07-12 18:51:14,190 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 971
[INFO] 2021-07-12 18:51:14,190 [run_pretraining.py:  558]:	worker_index: 2, step: 971, cost: 8.597979, mlm loss: 8.597979, speed: 1.103431 steps/s, speed: 8.827445 samples/s, speed: 4519.651606 tokens/s, learning rate: 9.700e-06, loss_scalings: 13421.773438, pp_loss: 8.270590
[INFO] 2021-07-12 18:51:14,190 [run_pretraining.py:  512]:	********exe.run_971******* 
[INFO] 2021-07-12 18:51:15,101 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:15,101 [run_pretraining.py:  534]:	loss/total_loss, 8.599197387695312, 972
[INFO] 2021-07-12 18:51:15,101 [run_pretraining.py:  535]:	loss/mlm_loss, 8.599197387695312, 972
[INFO] 2021-07-12 18:51:15,101 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.709999176266138e-06, 972
[INFO] 2021-07-12 18:51:15,101 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 972
[INFO] 2021-07-12 18:51:15,101 [run_pretraining.py:  558]:	worker_index: 2, step: 972, cost: 8.599197, mlm loss: 8.599197, speed: 1.097438 steps/s, speed: 8.779502 samples/s, speed: 4495.105108 tokens/s, learning rate: 9.710e-06, loss_scalings: 13421.773438, pp_loss: 8.097334
[INFO] 2021-07-12 18:51:15,102 [run_pretraining.py:  512]:	********exe.run_972******* 
[INFO] 2021-07-12 18:51:16,008 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:16,008 [run_pretraining.py:  534]:	loss/total_loss, 8.525552749633789, 973
[INFO] 2021-07-12 18:51:16,008 [run_pretraining.py:  535]:	loss/mlm_loss, 8.525552749633789, 973
[INFO] 2021-07-12 18:51:16,008 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.719999980006833e-06, 973
[INFO] 2021-07-12 18:51:16,008 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 973
[INFO] 2021-07-12 18:51:16,008 [run_pretraining.py:  558]:	worker_index: 2, step: 973, cost: 8.525553, mlm loss: 8.525553, speed: 1.103265 steps/s, speed: 8.826121 samples/s, speed: 4518.973965 tokens/s, learning rate: 9.720e-06, loss_scalings: 13421.773438, pp_loss: 8.351665
[INFO] 2021-07-12 18:51:16,009 [run_pretraining.py:  512]:	********exe.run_973******* 
[INFO] 2021-07-12 18:51:16,939 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:16,940 [run_pretraining.py:  534]:	loss/total_loss, 7.991734981536865, 974
[INFO] 2021-07-12 18:51:16,940 [run_pretraining.py:  535]:	loss/mlm_loss, 7.991734981536865, 974
[INFO] 2021-07-12 18:51:16,940 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.729999874252826e-06, 974
[INFO] 2021-07-12 18:51:16,940 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 974
[INFO] 2021-07-12 18:51:16,940 [run_pretraining.py:  558]:	worker_index: 2, step: 974, cost: 7.991735, mlm loss: 7.991735, speed: 1.074255 steps/s, speed: 8.594040 samples/s, speed: 4400.148444 tokens/s, learning rate: 9.730e-06, loss_scalings: 13421.773438, pp_loss: 7.984639
[INFO] 2021-07-12 18:51:16,940 [run_pretraining.py:  512]:	********exe.run_974******* 
[INFO] 2021-07-12 18:51:17,839 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:17,840 [run_pretraining.py:  534]:	loss/total_loss, 8.18879508972168, 975
[INFO] 2021-07-12 18:51:17,840 [run_pretraining.py:  535]:	loss/mlm_loss, 8.18879508972168, 975
[INFO] 2021-07-12 18:51:17,840 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.73999976849882e-06, 975
[INFO] 2021-07-12 18:51:17,840 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 975
[INFO] 2021-07-12 18:51:17,840 [run_pretraining.py:  558]:	worker_index: 2, step: 975, cost: 8.188795, mlm loss: 8.188795, speed: 1.111447 steps/s, speed: 8.891573 samples/s, speed: 4552.485465 tokens/s, learning rate: 9.740e-06, loss_scalings: 13421.773438, pp_loss: 8.261854
[INFO] 2021-07-12 18:51:17,840 [run_pretraining.py:  512]:	********exe.run_975******* 
[INFO] 2021-07-12 18:51:18,752 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:18,752 [run_pretraining.py:  534]:	loss/total_loss, 8.175334930419922, 976
[INFO] 2021-07-12 18:51:18,752 [run_pretraining.py:  535]:	loss/mlm_loss, 8.175334930419922, 976
[INFO] 2021-07-12 18:51:18,752 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.749999662744813e-06, 976
[INFO] 2021-07-12 18:51:18,752 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 976
[INFO] 2021-07-12 18:51:18,752 [run_pretraining.py:  558]:	worker_index: 2, step: 976, cost: 8.175335, mlm loss: 8.175335, speed: 1.097099 steps/s, speed: 8.776795 samples/s, speed: 4493.718864 tokens/s, learning rate: 9.750e-06, loss_scalings: 13421.773438, pp_loss: 8.262744
[INFO] 2021-07-12 18:51:18,752 [run_pretraining.py:  512]:	********exe.run_976******* 
[INFO] 2021-07-12 18:51:19,658 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:19,659 [run_pretraining.py:  534]:	loss/total_loss, 8.0258207321167, 977
[INFO] 2021-07-12 18:51:19,659 [run_pretraining.py:  535]:	loss/mlm_loss, 8.0258207321167, 977
[INFO] 2021-07-12 18:51:19,659 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.759999556990806e-06, 977
[INFO] 2021-07-12 18:51:19,659 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 977
[INFO] 2021-07-12 18:51:19,659 [run_pretraining.py:  558]:	worker_index: 2, step: 977, cost: 8.025821, mlm loss: 8.025821, speed: 1.103650 steps/s, speed: 8.829201 samples/s, speed: 4520.550686 tokens/s, learning rate: 9.760e-06, loss_scalings: 13421.773438, pp_loss: 8.126430
[INFO] 2021-07-12 18:51:19,659 [run_pretraining.py:  512]:	********exe.run_977******* 
[INFO] 2021-07-12 18:51:20,567 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:20,567 [run_pretraining.py:  534]:	loss/total_loss, 7.857083320617676, 978
[INFO] 2021-07-12 18:51:20,568 [run_pretraining.py:  535]:	loss/mlm_loss, 7.857083320617676, 978
[INFO] 2021-07-12 18:51:20,568 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.7699994512368e-06, 978
[INFO] 2021-07-12 18:51:20,568 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 978
[INFO] 2021-07-12 18:51:20,568 [run_pretraining.py:  558]:	worker_index: 2, step: 978, cost: 7.857083, mlm loss: 7.857083, speed: 1.101129 steps/s, speed: 8.809032 samples/s, speed: 4510.224527 tokens/s, learning rate: 9.770e-06, loss_scalings: 13421.773438, pp_loss: 8.069323
[INFO] 2021-07-12 18:51:20,568 [run_pretraining.py:  512]:	********exe.run_978******* 
[INFO] 2021-07-12 18:51:21,469 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:21,470 [run_pretraining.py:  534]:	loss/total_loss, 8.270986557006836, 979
[INFO] 2021-07-12 18:51:21,470 [run_pretraining.py:  535]:	loss/mlm_loss, 8.270986557006836, 979
[INFO] 2021-07-12 18:51:21,470 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.780000254977494e-06, 979
[INFO] 2021-07-12 18:51:21,470 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 979
[INFO] 2021-07-12 18:51:21,470 [run_pretraining.py:  558]:	worker_index: 2, step: 979, cost: 8.270987, mlm loss: 8.270987, speed: 1.108852 steps/s, speed: 8.870812 samples/s, speed: 4541.855762 tokens/s, learning rate: 9.780e-06, loss_scalings: 13421.773438, pp_loss: 8.231119
[INFO] 2021-07-12 18:51:21,470 [run_pretraining.py:  512]:	********exe.run_979******* 
[INFO] 2021-07-12 18:51:22,378 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:22,379 [run_pretraining.py:  534]:	loss/total_loss, 8.49414348602295, 980
[INFO] 2021-07-12 18:51:22,379 [run_pretraining.py:  535]:	loss/mlm_loss, 8.49414348602295, 980
[INFO] 2021-07-12 18:51:22,379 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.790000149223488e-06, 980
[INFO] 2021-07-12 18:51:22,379 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 980
[INFO] 2021-07-12 18:51:22,379 [run_pretraining.py:  558]:	worker_index: 2, step: 980, cost: 8.494143, mlm loss: 8.494143, speed: 1.101297 steps/s, speed: 8.810374 samples/s, speed: 4510.911391 tokens/s, learning rate: 9.790e-06, loss_scalings: 13421.773438, pp_loss: 7.539627
[INFO] 2021-07-12 18:51:22,379 [run_pretraining.py:  512]:	********exe.run_980******* 
[INFO] 2021-07-12 18:51:23,294 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:23,294 [run_pretraining.py:  534]:	loss/total_loss, 7.965029716491699, 981
[INFO] 2021-07-12 18:51:23,295 [run_pretraining.py:  535]:	loss/mlm_loss, 7.965029716491699, 981
[INFO] 2021-07-12 18:51:23,295 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.79999913397478e-06, 981
[INFO] 2021-07-12 18:51:23,295 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 981
[INFO] 2021-07-12 18:51:23,295 [run_pretraining.py:  558]:	worker_index: 2, step: 981, cost: 7.965030, mlm loss: 7.965030, speed: 1.092473 steps/s, speed: 8.739781 samples/s, speed: 4474.767947 tokens/s, learning rate: 9.800e-06, loss_scalings: 13421.773438, pp_loss: 8.106112
[INFO] 2021-07-12 18:51:23,295 [run_pretraining.py:  512]:	********exe.run_981******* 
[INFO] 2021-07-12 18:51:24,203 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:24,203 [run_pretraining.py:  534]:	loss/total_loss, 7.5639753341674805, 982
[INFO] 2021-07-12 18:51:24,203 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5639753341674805, 982
[INFO] 2021-07-12 18:51:24,203 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.809999937715475e-06, 982
[INFO] 2021-07-12 18:51:24,204 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 982
[INFO] 2021-07-12 18:51:24,204 [run_pretraining.py:  558]:	worker_index: 2, step: 982, cost: 7.563975, mlm loss: 7.563975, speed: 1.101079 steps/s, speed: 8.808630 samples/s, speed: 4510.018509 tokens/s, learning rate: 9.810e-06, loss_scalings: 13421.773438, pp_loss: 8.000101
[INFO] 2021-07-12 18:51:24,204 [run_pretraining.py:  512]:	********exe.run_982******* 
[INFO] 2021-07-12 18:51:25,116 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:25,117 [run_pretraining.py:  534]:	loss/total_loss, 8.523687362670898, 983
[INFO] 2021-07-12 18:51:25,117 [run_pretraining.py:  535]:	loss/mlm_loss, 8.523687362670898, 983
[INFO] 2021-07-12 18:51:25,117 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.819999831961468e-06, 983
[INFO] 2021-07-12 18:51:25,117 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 983
[INFO] 2021-07-12 18:51:25,117 [run_pretraining.py:  558]:	worker_index: 2, step: 983, cost: 8.523687, mlm loss: 8.523687, speed: 1.095448 steps/s, speed: 8.763584 samples/s, speed: 4486.955132 tokens/s, learning rate: 9.820e-06, loss_scalings: 13421.773438, pp_loss: 8.375957
[INFO] 2021-07-12 18:51:25,117 [run_pretraining.py:  512]:	********exe.run_983******* 
[INFO] 2021-07-12 18:51:26,042 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:26,042 [run_pretraining.py:  534]:	loss/total_loss, 8.30334186553955, 984
[INFO] 2021-07-12 18:51:26,042 [run_pretraining.py:  535]:	loss/mlm_loss, 8.30334186553955, 984
[INFO] 2021-07-12 18:51:26,043 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.829999726207461e-06, 984
[INFO] 2021-07-12 18:51:26,043 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 984
[INFO] 2021-07-12 18:51:26,043 [run_pretraining.py:  558]:	worker_index: 2, step: 984, cost: 8.303342, mlm loss: 8.303342, speed: 1.081132 steps/s, speed: 8.649055 samples/s, speed: 4428.316071 tokens/s, learning rate: 9.830e-06, loss_scalings: 13421.773438, pp_loss: 8.043828
[INFO] 2021-07-12 18:51:26,043 [run_pretraining.py:  512]:	********exe.run_984******* 
[INFO] 2021-07-12 18:51:26,950 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:26,951 [run_pretraining.py:  534]:	loss/total_loss, 8.48331356048584, 985
[INFO] 2021-07-12 18:51:26,951 [run_pretraining.py:  535]:	loss/mlm_loss, 8.48331356048584, 985
[INFO] 2021-07-12 18:51:26,951 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.839999620453455e-06, 985
[INFO] 2021-07-12 18:51:26,951 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 985
[INFO] 2021-07-12 18:51:26,951 [run_pretraining.py:  558]:	worker_index: 2, step: 985, cost: 8.483314, mlm loss: 8.483314, speed: 1.101763 steps/s, speed: 8.814102 samples/s, speed: 4512.820312 tokens/s, learning rate: 9.840e-06, loss_scalings: 13421.773438, pp_loss: 7.790227
[INFO] 2021-07-12 18:51:26,951 [run_pretraining.py:  512]:	********exe.run_985******* 
[INFO] 2021-07-12 18:51:27,894 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:27,894 [run_pretraining.py:  534]:	loss/total_loss, 8.675016403198242, 986
[INFO] 2021-07-12 18:51:27,894 [run_pretraining.py:  535]:	loss/mlm_loss, 8.675016403198242, 986
[INFO] 2021-07-12 18:51:27,894 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.849999514699448e-06, 986
[INFO] 2021-07-12 18:51:27,894 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 986
[INFO] 2021-07-12 18:51:27,895 [run_pretraining.py:  558]:	worker_index: 2, step: 986, cost: 8.675016, mlm loss: 8.675016, speed: 1.060416 steps/s, speed: 8.483329 samples/s, speed: 4343.464246 tokens/s, learning rate: 9.850e-06, loss_scalings: 13421.773438, pp_loss: 8.284185
[INFO] 2021-07-12 18:51:27,895 [run_pretraining.py:  512]:	********exe.run_986******* 
[INFO] 2021-07-12 18:51:28,814 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:28,814 [run_pretraining.py:  534]:	loss/total_loss, 7.6141180992126465, 987
[INFO] 2021-07-12 18:51:28,815 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6141180992126465, 987
[INFO] 2021-07-12 18:51:28,815 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.859999408945441e-06, 987
[INFO] 2021-07-12 18:51:28,815 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 987
[INFO] 2021-07-12 18:51:28,815 [run_pretraining.py:  558]:	worker_index: 2, step: 987, cost: 7.614118, mlm loss: 7.614118, speed: 1.087318 steps/s, speed: 8.698544 samples/s, speed: 4453.654340 tokens/s, learning rate: 9.860e-06, loss_scalings: 13421.773438, pp_loss: 7.927319
[INFO] 2021-07-12 18:51:28,815 [run_pretraining.py:  512]:	********exe.run_987******* 
[INFO] 2021-07-12 18:51:29,719 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:29,719 [run_pretraining.py:  534]:	loss/total_loss, 7.952725410461426, 988
[INFO] 2021-07-12 18:51:29,719 [run_pretraining.py:  535]:	loss/mlm_loss, 7.952725410461426, 988
[INFO] 2021-07-12 18:51:29,719 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.870000212686136e-06, 988
[INFO] 2021-07-12 18:51:29,719 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 988
[INFO] 2021-07-12 18:51:29,719 [run_pretraining.py:  558]:	worker_index: 2, step: 988, cost: 7.952725, mlm loss: 7.952725, speed: 1.106179 steps/s, speed: 8.849431 samples/s, speed: 4530.908703 tokens/s, learning rate: 9.870e-06, loss_scalings: 13421.773438, pp_loss: 8.089586
[INFO] 2021-07-12 18:51:29,720 [run_pretraining.py:  512]:	********exe.run_988******* 
[INFO] 2021-07-12 18:51:30,626 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:30,626 [run_pretraining.py:  534]:	loss/total_loss, 8.169605255126953, 989
[INFO] 2021-07-12 18:51:30,627 [run_pretraining.py:  535]:	loss/mlm_loss, 8.169605255126953, 989
[INFO] 2021-07-12 18:51:30,627 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.88000010693213e-06, 989
[INFO] 2021-07-12 18:51:30,627 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 989
[INFO] 2021-07-12 18:51:30,627 [run_pretraining.py:  558]:	worker_index: 2, step: 989, cost: 8.169605, mlm loss: 8.169605, speed: 1.102795 steps/s, speed: 8.822364 samples/s, speed: 4517.050334 tokens/s, learning rate: 9.880e-06, loss_scalings: 13421.773438, pp_loss: 8.115942
[INFO] 2021-07-12 18:51:30,627 [run_pretraining.py:  512]:	********exe.run_989******* 
[INFO] 2021-07-12 18:51:31,537 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:31,538 [run_pretraining.py:  534]:	loss/total_loss, 8.0615816116333, 990
[INFO] 2021-07-12 18:51:31,538 [run_pretraining.py:  535]:	loss/mlm_loss, 8.0615816116333, 990
[INFO] 2021-07-12 18:51:31,538 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.889999091683421e-06, 990
[INFO] 2021-07-12 18:51:31,538 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 990
[INFO] 2021-07-12 18:51:31,538 [run_pretraining.py:  558]:	worker_index: 2, step: 990, cost: 8.061582, mlm loss: 8.061582, speed: 1.098007 steps/s, speed: 8.784053 samples/s, speed: 4497.435077 tokens/s, learning rate: 9.890e-06, loss_scalings: 13421.773438, pp_loss: 8.190023
[INFO] 2021-07-12 18:51:31,538 [run_pretraining.py:  512]:	********exe.run_990******* 
[INFO] 2021-07-12 18:51:32,449 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:32,450 [run_pretraining.py:  534]:	loss/total_loss, 7.9007158279418945, 991
[INFO] 2021-07-12 18:51:32,450 [run_pretraining.py:  535]:	loss/mlm_loss, 7.9007158279418945, 991
[INFO] 2021-07-12 18:51:32,450 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.899999895424116e-06, 991
[INFO] 2021-07-12 18:51:32,450 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 991
[INFO] 2021-07-12 18:51:32,450 [run_pretraining.py:  558]:	worker_index: 2, step: 991, cost: 7.900716, mlm loss: 7.900716, speed: 1.097242 steps/s, speed: 8.777933 samples/s, speed: 4494.301947 tokens/s, learning rate: 9.900e-06, loss_scalings: 13421.773438, pp_loss: 7.809019
[INFO] 2021-07-12 18:51:32,450 [run_pretraining.py:  512]:	********exe.run_991******* 
[INFO] 2021-07-12 18:51:33,357 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:33,358 [run_pretraining.py:  534]:	loss/total_loss, 7.951962471008301, 992
[INFO] 2021-07-12 18:51:33,358 [run_pretraining.py:  535]:	loss/mlm_loss, 7.951962471008301, 992
[INFO] 2021-07-12 18:51:33,358 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.90999978967011e-06, 992
[INFO] 2021-07-12 18:51:33,358 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 992
[INFO] 2021-07-12 18:51:33,358 [run_pretraining.py:  558]:	worker_index: 2, step: 992, cost: 7.951962, mlm loss: 7.951962, speed: 1.101844 steps/s, speed: 8.814751 samples/s, speed: 4513.152257 tokens/s, learning rate: 9.910e-06, loss_scalings: 13421.773438, pp_loss: 7.859525
[INFO] 2021-07-12 18:51:33,358 [run_pretraining.py:  512]:	********exe.run_992******* 
[INFO] 2021-07-12 18:51:34,273 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:34,273 [run_pretraining.py:  534]:	loss/total_loss, 8.293824195861816, 993
[INFO] 2021-07-12 18:51:34,273 [run_pretraining.py:  535]:	loss/mlm_loss, 8.293824195861816, 993
[INFO] 2021-07-12 18:51:34,273 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.919999683916103e-06, 993
[INFO] 2021-07-12 18:51:34,273 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 993
[INFO] 2021-07-12 18:51:34,273 [run_pretraining.py:  558]:	worker_index: 2, step: 993, cost: 8.293824, mlm loss: 8.293824, speed: 1.093444 steps/s, speed: 8.747555 samples/s, speed: 4478.748252 tokens/s, learning rate: 9.920e-06, loss_scalings: 13421.773438, pp_loss: 8.153384
[INFO] 2021-07-12 18:51:34,273 [run_pretraining.py:  512]:	********exe.run_993******* 
[INFO] 2021-07-12 18:51:35,186 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:35,187 [run_pretraining.py:  534]:	loss/total_loss, 8.23580265045166, 994
[INFO] 2021-07-12 18:51:35,187 [run_pretraining.py:  535]:	loss/mlm_loss, 8.23580265045166, 994
[INFO] 2021-07-12 18:51:35,187 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.929999578162096e-06, 994
[INFO] 2021-07-12 18:51:35,187 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 994
[INFO] 2021-07-12 18:51:35,187 [run_pretraining.py:  558]:	worker_index: 2, step: 994, cost: 8.235803, mlm loss: 8.235803, speed: 1.094970 steps/s, speed: 8.759757 samples/s, speed: 4484.995431 tokens/s, learning rate: 9.930e-06, loss_scalings: 13421.773438, pp_loss: 7.972728
[INFO] 2021-07-12 18:51:35,187 [run_pretraining.py:  512]:	********exe.run_994******* 
[INFO] 2021-07-12 18:51:36,115 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:36,116 [run_pretraining.py:  534]:	loss/total_loss, 8.22785758972168, 995
[INFO] 2021-07-12 18:51:36,116 [run_pretraining.py:  535]:	loss/mlm_loss, 8.22785758972168, 995
[INFO] 2021-07-12 18:51:36,116 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.93999947240809e-06, 995
[INFO] 2021-07-12 18:51:36,116 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 995
[INFO] 2021-07-12 18:51:36,116 [run_pretraining.py:  558]:	worker_index: 2, step: 995, cost: 8.227858, mlm loss: 8.227858, speed: 1.077348 steps/s, speed: 8.618788 samples/s, speed: 4412.819359 tokens/s, learning rate: 9.940e-06, loss_scalings: 13421.773438, pp_loss: 8.002838
[INFO] 2021-07-12 18:51:36,116 [run_pretraining.py:  512]:	********exe.run_995******* 
[INFO] 2021-07-12 18:51:37,035 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:37,035 [run_pretraining.py:  534]:	loss/total_loss, 8.210407257080078, 996
[INFO] 2021-07-12 18:51:37,035 [run_pretraining.py:  535]:	loss/mlm_loss, 8.210407257080078, 996
[INFO] 2021-07-12 18:51:37,035 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.949999366654083e-06, 996
[INFO] 2021-07-12 18:51:37,035 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 996
[INFO] 2021-07-12 18:51:37,035 [run_pretraining.py:  558]:	worker_index: 2, step: 996, cost: 8.210407, mlm loss: 8.210407, speed: 1.088395 steps/s, speed: 8.707162 samples/s, speed: 4458.066784 tokens/s, learning rate: 9.950e-06, loss_scalings: 13421.773438, pp_loss: 8.194414
[INFO] 2021-07-12 18:51:37,036 [run_pretraining.py:  512]:	********exe.run_996******* 
[INFO] 2021-07-12 18:51:37,945 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:37,945 [run_pretraining.py:  534]:	loss/total_loss, 7.937563896179199, 997
[INFO] 2021-07-12 18:51:37,945 [run_pretraining.py:  535]:	loss/mlm_loss, 7.937563896179199, 997
[INFO] 2021-07-12 18:51:37,946 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.960000170394778e-06, 997
[INFO] 2021-07-12 18:51:37,946 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 997
[INFO] 2021-07-12 18:51:37,946 [run_pretraining.py:  558]:	worker_index: 2, step: 997, cost: 7.937564, mlm loss: 7.937564, speed: 1.099387 steps/s, speed: 8.795095 samples/s, speed: 4503.088803 tokens/s, learning rate: 9.960e-06, loss_scalings: 13421.773438, pp_loss: 8.217262
[INFO] 2021-07-12 18:51:37,946 [run_pretraining.py:  512]:	********exe.run_997******* 
[INFO] 2021-07-12 18:51:38,864 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:38,864 [run_pretraining.py:  534]:	loss/total_loss, 7.6567864418029785, 998
[INFO] 2021-07-12 18:51:38,864 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6567864418029785, 998
[INFO] 2021-07-12 18:51:38,865 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.96999915514607e-06, 998
[INFO] 2021-07-12 18:51:38,865 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 998
[INFO] 2021-07-12 18:51:38,865 [run_pretraining.py:  558]:	worker_index: 2, step: 998, cost: 7.656786, mlm loss: 7.656786, speed: 1.088792 steps/s, speed: 8.710333 samples/s, speed: 4459.690421 tokens/s, learning rate: 9.970e-06, loss_scalings: 13421.773438, pp_loss: 7.973726
[INFO] 2021-07-12 18:51:38,865 [run_pretraining.py:  512]:	********exe.run_998******* 
[INFO] 2021-07-12 18:51:39,854 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:39,855 [run_pretraining.py:  534]:	loss/total_loss, 8.046586990356445, 999
[INFO] 2021-07-12 18:51:39,855 [run_pretraining.py:  535]:	loss/mlm_loss, 8.046586990356445, 999
[INFO] 2021-07-12 18:51:39,855 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.979999958886765e-06, 999
[INFO] 2021-07-12 18:51:39,855 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 999
[INFO] 2021-07-12 18:51:39,855 [run_pretraining.py:  558]:	worker_index: 2, step: 999, cost: 8.046587, mlm loss: 8.046587, speed: 1.010283 steps/s, speed: 8.082262 samples/s, speed: 4138.118135 tokens/s, learning rate: 9.980e-06, loss_scalings: 13421.773438, pp_loss: 8.079884
[INFO] 2021-07-12 18:51:39,855 [run_pretraining.py:  512]:	********exe.run_999******* 
[INFO] 2021-07-12 18:51:40,766 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:40,766 [run_pretraining.py:  534]:	loss/total_loss, 6.178483009338379, 1000
[INFO] 2021-07-12 18:51:40,767 [run_pretraining.py:  535]:	loss/mlm_loss, 6.178483009338379, 1000
[INFO] 2021-07-12 18:51:40,767 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.989999853132758e-06, 1000
[INFO] 2021-07-12 18:51:40,767 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1000
[INFO] 2021-07-12 18:51:40,767 [run_pretraining.py:  558]:	worker_index: 2, step: 1000, cost: 6.178483, mlm loss: 6.178483, speed: 1.097598 steps/s, speed: 8.780786 samples/s, speed: 4495.762668 tokens/s, learning rate: 9.990e-06, loss_scalings: 13421.773438, pp_loss: 7.619868
[INFO] 2021-07-12 18:51:40,767 [run_pretraining.py:  512]:	********exe.run_1000******* 
[INFO] 2021-07-12 18:51:41,679 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:41,680 [run_pretraining.py:  534]:	loss/total_loss, 8.059652328491211, 1001
[INFO] 2021-07-12 18:51:41,680 [run_pretraining.py:  535]:	loss/mlm_loss, 8.059652328491211, 1001
[INFO] 2021-07-12 18:51:41,680 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.999999747378752e-06, 1001
[INFO] 2021-07-12 18:51:41,680 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1001
[INFO] 2021-07-12 18:51:41,680 [run_pretraining.py:  558]:	worker_index: 2, step: 1001, cost: 8.059652, mlm loss: 8.059652, speed: 1.095856 steps/s, speed: 8.766852 samples/s, speed: 4488.628030 tokens/s, learning rate: 1.000e-05, loss_scalings: 13421.773438, pp_loss: 8.167936
[INFO] 2021-07-12 18:51:41,680 [run_pretraining.py:  512]:	********exe.run_1001******* 
[INFO] 2021-07-12 18:51:42,593 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:42,594 [run_pretraining.py:  534]:	loss/total_loss, 7.6469879150390625, 1002
[INFO] 2021-07-12 18:51:42,594 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6469879150390625, 1002
[INFO] 2021-07-12 18:51:42,594 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0009999641624745e-05, 1002
[INFO] 2021-07-12 18:51:42,594 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1002
[INFO] 2021-07-12 18:51:42,594 [run_pretraining.py:  558]:	worker_index: 2, step: 1002, cost: 7.646988, mlm loss: 7.646988, speed: 1.094560 steps/s, speed: 8.756483 samples/s, speed: 4483.319389 tokens/s, learning rate: 1.001e-05, loss_scalings: 13421.773438, pp_loss: 8.078210
[INFO] 2021-07-12 18:51:42,594 [run_pretraining.py:  512]:	********exe.run_1002******* 
[INFO] 2021-07-12 18:51:43,506 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:43,507 [run_pretraining.py:  534]:	loss/total_loss, 8.061378479003906, 1003
[INFO] 2021-07-12 18:51:43,507 [run_pretraining.py:  535]:	loss/mlm_loss, 8.061378479003906, 1003
[INFO] 2021-07-12 18:51:43,507 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0019999535870738e-05, 1003
[INFO] 2021-07-12 18:51:43,507 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1003
[INFO] 2021-07-12 18:51:43,507 [run_pretraining.py:  558]:	worker_index: 2, step: 1003, cost: 8.061378, mlm loss: 8.061378, speed: 1.096028 steps/s, speed: 8.768222 samples/s, speed: 4489.329447 tokens/s, learning rate: 1.002e-05, loss_scalings: 13421.773438, pp_loss: 8.270428
[INFO] 2021-07-12 18:51:43,507 [run_pretraining.py:  512]:	********exe.run_1003******* 
[INFO] 2021-07-12 18:52:09,833 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:09,834 [run_pretraining.py:  534]:	loss/total_loss, 7.660153388977051, 1004
[INFO] 2021-07-12 18:52:09,834 [run_pretraining.py:  535]:	loss/mlm_loss, 7.660153388977051, 1004
[INFO] 2021-07-12 18:52:09,834 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0029999430116732e-05, 1004
[INFO] 2021-07-12 18:52:09,834 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1004
[INFO] 2021-07-12 18:52:09,834 [run_pretraining.py:  558]:	worker_index: 2, step: 1004, cost: 7.660153, mlm loss: 7.660153, speed: 0.037985 steps/s, speed: 0.303879 samples/s, speed: 155.585845 tokens/s, learning rate: 1.003e-05, loss_scalings: 13421.773438, pp_loss: 7.980577
[INFO] 2021-07-12 18:52:09,834 [run_pretraining.py:  512]:	********exe.run_1004******* 
[INFO] 2021-07-12 18:52:10,752 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:10,753 [run_pretraining.py:  534]:	loss/total_loss, 8.428216934204102, 1005
[INFO] 2021-07-12 18:52:10,753 [run_pretraining.py:  535]:	loss/mlm_loss, 8.428216934204102, 1005
[INFO] 2021-07-12 18:52:10,753 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0040000233857427e-05, 1005
[INFO] 2021-07-12 18:52:10,753 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1005
[INFO] 2021-07-12 18:52:10,753 [run_pretraining.py:  558]:	worker_index: 2, step: 1005, cost: 8.428217, mlm loss: 8.428217, speed: 1.088459 steps/s, speed: 8.707670 samples/s, speed: 4458.327088 tokens/s, learning rate: 1.004e-05, loss_scalings: 13421.773438, pp_loss: 7.599444
[INFO] 2021-07-12 18:52:10,753 [run_pretraining.py:  512]:	********exe.run_1005******* 
[INFO] 2021-07-12 18:52:11,678 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:11,678 [run_pretraining.py:  534]:	loss/total_loss, 8.272075653076172, 1006
[INFO] 2021-07-12 18:52:11,678 [run_pretraining.py:  535]:	loss/mlm_loss, 8.272075653076172, 1006
[INFO] 2021-07-12 18:52:11,678 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.005000012810342e-05, 1006
[INFO] 2021-07-12 18:52:11,678 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1006
[INFO] 2021-07-12 18:52:11,678 [run_pretraining.py:  558]:	worker_index: 2, step: 1006, cost: 8.272076, mlm loss: 8.272076, speed: 1.081796 steps/s, speed: 8.654371 samples/s, speed: 4431.037821 tokens/s, learning rate: 1.005e-05, loss_scalings: 13421.773438, pp_loss: 8.122078
[INFO] 2021-07-12 18:52:11,678 [run_pretraining.py:  512]:	********exe.run_1006******* 
[INFO] 2021-07-12 18:52:12,586 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:12,586 [run_pretraining.py:  534]:	loss/total_loss, 8.044780731201172, 1007
[INFO] 2021-07-12 18:52:12,586 [run_pretraining.py:  535]:	loss/mlm_loss, 8.044780731201172, 1007
[INFO] 2021-07-12 18:52:12,586 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0059999112854712e-05, 1007
[INFO] 2021-07-12 18:52:12,586 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1007
[INFO] 2021-07-12 18:52:12,586 [run_pretraining.py:  558]:	worker_index: 2, step: 1007, cost: 8.044781, mlm loss: 8.044781, speed: 1.101929 steps/s, speed: 8.815431 samples/s, speed: 4513.500852 tokens/s, learning rate: 1.006e-05, loss_scalings: 13421.773438, pp_loss: 8.249035
[INFO] 2021-07-12 18:52:12,587 [run_pretraining.py:  512]:	********exe.run_1007******* 
[INFO] 2021-07-12 18:52:13,512 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:13,513 [run_pretraining.py:  534]:	loss/total_loss, 8.052970886230469, 1008
[INFO] 2021-07-12 18:52:13,513 [run_pretraining.py:  535]:	loss/mlm_loss, 8.052970886230469, 1008
[INFO] 2021-07-12 18:52:13,513 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0069999916595407e-05, 1008
[INFO] 2021-07-12 18:52:13,513 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1008
[INFO] 2021-07-12 18:52:13,513 [run_pretraining.py:  558]:	worker_index: 2, step: 1008, cost: 8.052971, mlm loss: 8.052971, speed: 1.080034 steps/s, speed: 8.640269 samples/s, speed: 4423.817620 tokens/s, learning rate: 1.007e-05, loss_scalings: 13421.773438, pp_loss: 8.185736
[INFO] 2021-07-12 18:52:13,513 [run_pretraining.py:  512]:	********exe.run_1008******* 
[INFO] 2021-07-12 18:52:14,431 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:14,432 [run_pretraining.py:  534]:	loss/total_loss, 7.22838020324707, 1009
[INFO] 2021-07-12 18:52:14,432 [run_pretraining.py:  535]:	loss/mlm_loss, 7.22838020324707, 1009
[INFO] 2021-07-12 18:52:14,432 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.00799998108414e-05, 1009
[INFO] 2021-07-12 18:52:14,432 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1009
[INFO] 2021-07-12 18:52:14,432 [run_pretraining.py:  558]:	worker_index: 2, step: 1009, cost: 7.228380, mlm loss: 7.228380, speed: 1.088578 steps/s, speed: 8.708624 samples/s, speed: 4458.815385 tokens/s, learning rate: 1.008e-05, loss_scalings: 13421.773438, pp_loss: 7.780019
[INFO] 2021-07-12 18:52:14,432 [run_pretraining.py:  512]:	********exe.run_1009******* 
[INFO] 2021-07-12 18:52:15,350 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:15,351 [run_pretraining.py:  534]:	loss/total_loss, 7.888085842132568, 1010
[INFO] 2021-07-12 18:52:15,351 [run_pretraining.py:  535]:	loss/mlm_loss, 7.888085842132568, 1010
[INFO] 2021-07-12 18:52:15,351 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0089999705087394e-05, 1010
[INFO] 2021-07-12 18:52:15,351 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1010
[INFO] 2021-07-12 18:52:15,351 [run_pretraining.py:  558]:	worker_index: 2, step: 1010, cost: 7.888086, mlm loss: 7.888086, speed: 1.088686 steps/s, speed: 8.709492 samples/s, speed: 4459.259805 tokens/s, learning rate: 1.009e-05, loss_scalings: 13421.773438, pp_loss: 7.931932
[INFO] 2021-07-12 18:52:15,351 [run_pretraining.py:  512]:	********exe.run_1010******* 
[INFO] 2021-07-12 18:52:16,255 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:16,256 [run_pretraining.py:  534]:	loss/total_loss, 7.763282775878906, 1011
[INFO] 2021-07-12 18:52:16,256 [run_pretraining.py:  535]:	loss/mlm_loss, 7.763282775878906, 1011
[INFO] 2021-07-12 18:52:16,256 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0100000508828089e-05, 1011
[INFO] 2021-07-12 18:52:16,256 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1011
[INFO] 2021-07-12 18:52:16,256 [run_pretraining.py:  558]:	worker_index: 2, step: 1011, cost: 7.763283, mlm loss: 7.763283, speed: 1.105885 steps/s, speed: 8.847084 samples/s, speed: 4529.706899 tokens/s, learning rate: 1.010e-05, loss_scalings: 13421.773438, pp_loss: 8.009610
[INFO] 2021-07-12 18:52:16,256 [run_pretraining.py:  512]:	********exe.run_1011******* 
[INFO] 2021-07-12 18:52:17,169 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:17,170 [run_pretraining.py:  534]:	loss/total_loss, 8.28013801574707, 1012
[INFO] 2021-07-12 18:52:17,170 [run_pretraining.py:  535]:	loss/mlm_loss, 8.28013801574707, 1012
[INFO] 2021-07-12 18:52:17,170 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.010999949357938e-05, 1012
[INFO] 2021-07-12 18:52:17,170 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1012
[INFO] 2021-07-12 18:52:17,170 [run_pretraining.py:  558]:	worker_index: 2, step: 1012, cost: 8.280138, mlm loss: 8.280138, speed: 1.095159 steps/s, speed: 8.761271 samples/s, speed: 4485.770673 tokens/s, learning rate: 1.011e-05, loss_scalings: 13421.773438, pp_loss: 8.016522
[INFO] 2021-07-12 18:52:17,170 [run_pretraining.py:  512]:	********exe.run_1012******* 
[INFO] 2021-07-12 18:52:18,078 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:18,078 [run_pretraining.py:  534]:	loss/total_loss, 8.229251861572266, 1013
[INFO] 2021-07-12 18:52:18,078 [run_pretraining.py:  535]:	loss/mlm_loss, 8.229251861572266, 1013
[INFO] 2021-07-12 18:52:18,078 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0119999387825374e-05, 1013
[INFO] 2021-07-12 18:52:18,078 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1013
[INFO] 2021-07-12 18:52:18,078 [run_pretraining.py:  558]:	worker_index: 2, step: 1013, cost: 8.229252, mlm loss: 8.229252, speed: 1.101377 steps/s, speed: 8.811012 samples/s, speed: 4511.238317 tokens/s, learning rate: 1.012e-05, loss_scalings: 13421.773438, pp_loss: 8.127059
[INFO] 2021-07-12 18:52:18,078 [run_pretraining.py:  512]:	********exe.run_1013******* 
[INFO] 2021-07-12 18:52:18,992 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:18,993 [run_pretraining.py:  534]:	loss/total_loss, 8.285333633422852, 1014
[INFO] 2021-07-12 18:52:18,993 [run_pretraining.py:  535]:	loss/mlm_loss, 8.285333633422852, 1014
[INFO] 2021-07-12 18:52:18,993 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0130000191566069e-05, 1014
[INFO] 2021-07-12 18:52:18,993 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1014
[INFO] 2021-07-12 18:52:18,993 [run_pretraining.py:  558]:	worker_index: 2, step: 1014, cost: 8.285334, mlm loss: 8.285334, speed: 1.094052 steps/s, speed: 8.752415 samples/s, speed: 4481.236618 tokens/s, learning rate: 1.013e-05, loss_scalings: 13421.773438, pp_loss: 7.243171
[INFO] 2021-07-12 18:52:18,993 [run_pretraining.py:  512]:	********exe.run_1014******* 
[INFO] 2021-07-12 18:52:19,895 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:19,896 [run_pretraining.py:  534]:	loss/total_loss, 7.961243629455566, 1015
[INFO] 2021-07-12 18:52:19,896 [run_pretraining.py:  535]:	loss/mlm_loss, 7.961243629455566, 1015
[INFO] 2021-07-12 18:52:19,896 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0140000085812062e-05, 1015
[INFO] 2021-07-12 18:52:19,896 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1015
[INFO] 2021-07-12 18:52:19,896 [run_pretraining.py:  558]:	worker_index: 2, step: 1015, cost: 7.961244, mlm loss: 7.961244, speed: 1.108292 steps/s, speed: 8.866333 samples/s, speed: 4539.562318 tokens/s, learning rate: 1.014e-05, loss_scalings: 13421.773438, pp_loss: 8.049142
[INFO] 2021-07-12 18:52:19,896 [run_pretraining.py:  512]:	********exe.run_1015******* 
[INFO] 2021-07-12 18:52:20,811 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:20,811 [run_pretraining.py:  534]:	loss/total_loss, 7.74916934967041, 1016
[INFO] 2021-07-12 18:52:20,811 [run_pretraining.py:  535]:	loss/mlm_loss, 7.74916934967041, 1016
[INFO] 2021-07-12 18:52:20,812 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0149999070563354e-05, 1016
[INFO] 2021-07-12 18:52:20,812 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1016
[INFO] 2021-07-12 18:52:20,812 [run_pretraining.py:  558]:	worker_index: 2, step: 1016, cost: 7.749169, mlm loss: 7.749169, speed: 1.092709 steps/s, speed: 8.741671 samples/s, speed: 4475.735541 tokens/s, learning rate: 1.015e-05, loss_scalings: 13421.773438, pp_loss: 8.092904
[INFO] 2021-07-12 18:52:20,812 [run_pretraining.py:  512]:	********exe.run_1016******* 
[INFO] 2021-07-12 18:52:21,718 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:21,719 [run_pretraining.py:  534]:	loss/total_loss, 8.126659393310547, 1017
[INFO] 2021-07-12 18:52:21,719 [run_pretraining.py:  535]:	loss/mlm_loss, 8.126659393310547, 1017
[INFO] 2021-07-12 18:52:21,719 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0159999874304049e-05, 1017
[INFO] 2021-07-12 18:52:21,719 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1017
[INFO] 2021-07-12 18:52:21,719 [run_pretraining.py:  558]:	worker_index: 2, step: 1017, cost: 8.126659, mlm loss: 8.126659, speed: 1.102664 steps/s, speed: 8.821311 samples/s, speed: 4516.511204 tokens/s, learning rate: 1.016e-05, loss_scalings: 13421.773438, pp_loss: 8.158019
[INFO] 2021-07-12 18:52:21,719 [run_pretraining.py:  512]:	********exe.run_1017******* 
[INFO] 2021-07-12 18:52:22,627 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:22,628 [run_pretraining.py:  534]:	loss/total_loss, 8.334420204162598, 1018
[INFO] 2021-07-12 18:52:22,628 [run_pretraining.py:  535]:	loss/mlm_loss, 8.334420204162598, 1018
[INFO] 2021-07-12 18:52:22,628 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0169999768550042e-05, 1018
[INFO] 2021-07-12 18:52:22,628 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1018
[INFO] 2021-07-12 18:52:22,628 [run_pretraining.py:  558]:	worker_index: 2, step: 1018, cost: 8.334420, mlm loss: 8.334420, speed: 1.101075 steps/s, speed: 8.808600 samples/s, speed: 4510.003117 tokens/s, learning rate: 1.017e-05, loss_scalings: 13421.773438, pp_loss: 8.079429
[INFO] 2021-07-12 18:52:22,628 [run_pretraining.py:  512]:	********exe.run_1018******* 
[INFO] 2021-07-12 18:52:23,527 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:23,527 [run_pretraining.py:  534]:	loss/total_loss, 7.658351898193359, 1019
[INFO] 2021-07-12 18:52:23,527 [run_pretraining.py:  535]:	loss/mlm_loss, 7.658351898193359, 1019
[INFO] 2021-07-12 18:52:23,527 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0179999662796035e-05, 1019
[INFO] 2021-07-12 18:52:23,528 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1019
[INFO] 2021-07-12 18:52:23,528 [run_pretraining.py:  558]:	worker_index: 2, step: 1019, cost: 7.658352, mlm loss: 7.658352, speed: 1.112382 steps/s, speed: 8.899058 samples/s, speed: 4556.317678 tokens/s, learning rate: 1.018e-05, loss_scalings: 13421.773438, pp_loss: 8.035660
[INFO] 2021-07-12 18:52:23,528 [run_pretraining.py:  512]:	********exe.run_1019******* 
[INFO] 2021-07-12 18:52:24,435 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:24,436 [run_pretraining.py:  534]:	loss/total_loss, 8.331735610961914, 1020
[INFO] 2021-07-12 18:52:24,436 [run_pretraining.py:  535]:	loss/mlm_loss, 8.331735610961914, 1020
[INFO] 2021-07-12 18:52:24,436 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0189999557042029e-05, 1020
[INFO] 2021-07-12 18:52:24,436 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1020
[INFO] 2021-07-12 18:52:24,436 [run_pretraining.py:  558]:	worker_index: 2, step: 1020, cost: 8.331736, mlm loss: 8.331736, speed: 1.101596 steps/s, speed: 8.812764 samples/s, speed: 4512.135237 tokens/s, learning rate: 1.019e-05, loss_scalings: 13421.773438, pp_loss: 8.057003
[INFO] 2021-07-12 18:52:24,436 [run_pretraining.py:  512]:	********exe.run_1020******* 
[INFO] 2021-07-12 18:52:25,413 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:25,414 [run_pretraining.py:  534]:	loss/total_loss, 8.224308013916016, 1021
[INFO] 2021-07-12 18:52:25,414 [run_pretraining.py:  535]:	loss/mlm_loss, 8.224308013916016, 1021
[INFO] 2021-07-12 18:52:25,414 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0199999451288022e-05, 1021
[INFO] 2021-07-12 18:52:25,414 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1021
[INFO] 2021-07-12 18:52:25,414 [run_pretraining.py:  558]:	worker_index: 2, step: 1021, cost: 8.224308, mlm loss: 8.224308, speed: 1.023139 steps/s, speed: 8.185114 samples/s, speed: 4190.778262 tokens/s, learning rate: 1.020e-05, loss_scalings: 13421.773438, pp_loss: 8.295586
[INFO] 2021-07-12 18:52:25,414 [run_pretraining.py:  512]:	********exe.run_1021******* 
[INFO] 2021-07-12 18:52:26,468 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:26,468 [run_pretraining.py:  534]:	loss/total_loss, 8.22597885131836, 1022
[INFO] 2021-07-12 18:52:26,469 [run_pretraining.py:  535]:	loss/mlm_loss, 8.22597885131836, 1022
[INFO] 2021-07-12 18:52:26,469 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0209999345534015e-05, 1022
[INFO] 2021-07-12 18:52:26,469 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1022
[INFO] 2021-07-12 18:52:26,469 [run_pretraining.py:  558]:	worker_index: 2, step: 1022, cost: 8.225979, mlm loss: 8.225979, speed: 0.948503 steps/s, speed: 7.588026 samples/s, speed: 3885.069186 tokens/s, learning rate: 1.021e-05, loss_scalings: 13421.773438, pp_loss: 8.319246
[INFO] 2021-07-12 18:52:26,469 [run_pretraining.py:  512]:	********exe.run_1022******* 
[INFO] 2021-07-12 18:52:27,531 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:27,532 [run_pretraining.py:  534]:	loss/total_loss, 8.18106460571289, 1023
[INFO] 2021-07-12 18:52:27,532 [run_pretraining.py:  535]:	loss/mlm_loss, 8.18106460571289, 1023
[INFO] 2021-07-12 18:52:27,532 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.022000014927471e-05, 1023
[INFO] 2021-07-12 18:52:27,532 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1023
[INFO] 2021-07-12 18:52:27,532 [run_pretraining.py:  558]:	worker_index: 2, step: 1023, cost: 8.181065, mlm loss: 8.181065, speed: 0.941239 steps/s, speed: 7.529912 samples/s, speed: 3855.314896 tokens/s, learning rate: 1.022e-05, loss_scalings: 13421.773438, pp_loss: 8.049035
[INFO] 2021-07-12 18:52:27,532 [run_pretraining.py:  512]:	********exe.run_1023******* 
[INFO] 2021-07-12 18:52:28,591 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:28,592 [run_pretraining.py:  534]:	loss/total_loss, 7.969829559326172, 1024
[INFO] 2021-07-12 18:52:28,592 [run_pretraining.py:  535]:	loss/mlm_loss, 7.969829559326172, 1024
[INFO] 2021-07-12 18:52:28,592 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0230000043520704e-05, 1024
[INFO] 2021-07-12 18:52:28,592 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1024
[INFO] 2021-07-12 18:52:28,592 [run_pretraining.py:  558]:	worker_index: 2, step: 1024, cost: 7.969830, mlm loss: 7.969830, speed: 0.943637 steps/s, speed: 7.549099 samples/s, speed: 3865.138744 tokens/s, learning rate: 1.023e-05, loss_scalings: 13421.773438, pp_loss: 8.032739
[INFO] 2021-07-12 18:52:28,592 [run_pretraining.py:  512]:	********exe.run_1024******* 
[INFO] 2021-07-12 18:52:29,653 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:29,653 [run_pretraining.py:  534]:	loss/total_loss, 8.137930870056152, 1025
[INFO] 2021-07-12 18:52:29,653 [run_pretraining.py:  535]:	loss/mlm_loss, 8.137930870056152, 1025
[INFO] 2021-07-12 18:52:29,653 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0239999028271995e-05, 1025
[INFO] 2021-07-12 18:52:29,653 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1025
[INFO] 2021-07-12 18:52:29,653 [run_pretraining.py:  558]:	worker_index: 2, step: 1025, cost: 8.137931, mlm loss: 8.137931, speed: 0.942929 steps/s, speed: 7.543434 samples/s, speed: 3862.238259 tokens/s, learning rate: 1.024e-05, loss_scalings: 13421.773438, pp_loss: 8.260297
[INFO] 2021-07-12 18:52:29,653 [run_pretraining.py:  512]:	********exe.run_1025******* 
[INFO] 2021-07-12 18:52:30,711 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:30,711 [run_pretraining.py:  534]:	loss/total_loss, 7.735539436340332, 1026
[INFO] 2021-07-12 18:52:30,711 [run_pretraining.py:  535]:	loss/mlm_loss, 7.735539436340332, 1026
[INFO] 2021-07-12 18:52:30,711 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.024999983201269e-05, 1026
[INFO] 2021-07-12 18:52:30,711 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1026
[INFO] 2021-07-12 18:52:30,711 [run_pretraining.py:  558]:	worker_index: 2, step: 1026, cost: 7.735539, mlm loss: 7.735539, speed: 0.945577 steps/s, speed: 7.564617 samples/s, speed: 3873.083887 tokens/s, learning rate: 1.025e-05, loss_scalings: 13421.773438, pp_loss: 8.011875
[INFO] 2021-07-12 18:52:30,712 [run_pretraining.py:  512]:	********exe.run_1026******* 
[INFO] 2021-07-12 18:52:31,877 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:31,878 [run_pretraining.py:  534]:	loss/total_loss, 8.355672836303711, 1027
[INFO] 2021-07-12 18:52:31,878 [run_pretraining.py:  535]:	loss/mlm_loss, 8.355672836303711, 1027
[INFO] 2021-07-12 18:52:31,878 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0259999726258684e-05, 1027
[INFO] 2021-07-12 18:52:31,878 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1027
[INFO] 2021-07-12 18:52:31,878 [run_pretraining.py:  558]:	worker_index: 2, step: 1027, cost: 8.355673, mlm loss: 8.355673, speed: 0.857771 steps/s, speed: 6.862171 samples/s, speed: 3513.431654 tokens/s, learning rate: 1.026e-05, loss_scalings: 13421.773438, pp_loss: 8.298763
[INFO] 2021-07-12 18:52:31,878 [run_pretraining.py:  512]:	********exe.run_1027******* 
[INFO] 2021-07-12 18:52:32,925 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:32,925 [run_pretraining.py:  534]:	loss/total_loss, 7.870990753173828, 1028
[INFO] 2021-07-12 18:52:32,925 [run_pretraining.py:  535]:	loss/mlm_loss, 7.870990753173828, 1028
[INFO] 2021-07-12 18:52:32,925 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0269999620504677e-05, 1028
[INFO] 2021-07-12 18:52:32,925 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1028
[INFO] 2021-07-12 18:52:32,925 [run_pretraining.py:  558]:	worker_index: 2, step: 1028, cost: 7.870991, mlm loss: 7.870991, speed: 0.955186 steps/s, speed: 7.641488 samples/s, speed: 3912.441975 tokens/s, learning rate: 1.027e-05, loss_scalings: 13421.773438, pp_loss: 8.103994
[INFO] 2021-07-12 18:52:32,925 [run_pretraining.py:  512]:	********exe.run_1028******* 
[INFO] 2021-07-12 18:52:33,982 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:33,982 [run_pretraining.py:  534]:	loss/total_loss, 8.330121040344238, 1029
[INFO] 2021-07-12 18:52:33,982 [run_pretraining.py:  535]:	loss/mlm_loss, 8.330121040344238, 1029
[INFO] 2021-07-12 18:52:33,982 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.027999951475067e-05, 1029
[INFO] 2021-07-12 18:52:33,983 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1029
[INFO] 2021-07-12 18:52:33,983 [run_pretraining.py:  558]:	worker_index: 2, step: 1029, cost: 8.330121, mlm loss: 8.330121, speed: 0.946462 steps/s, speed: 7.571699 samples/s, speed: 3876.710021 tokens/s, learning rate: 1.028e-05, loss_scalings: 13421.773438, pp_loss: 7.960520
[INFO] 2021-07-12 18:52:33,983 [run_pretraining.py:  512]:	********exe.run_1029******* 
[INFO] 2021-07-12 18:52:35,038 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:35,039 [run_pretraining.py:  534]:	loss/total_loss, 7.630437850952148, 1030
[INFO] 2021-07-12 18:52:35,039 [run_pretraining.py:  535]:	loss/mlm_loss, 7.630437850952148, 1030
[INFO] 2021-07-12 18:52:35,039 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0289999408996664e-05, 1030
[INFO] 2021-07-12 18:52:35,039 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1030
[INFO] 2021-07-12 18:52:35,039 [run_pretraining.py:  558]:	worker_index: 2, step: 1030, cost: 7.630438, mlm loss: 7.630438, speed: 0.947144 steps/s, speed: 7.577152 samples/s, speed: 3879.501754 tokens/s, learning rate: 1.029e-05, loss_scalings: 13421.773438, pp_loss: 6.961763
[INFO] 2021-07-12 18:52:35,039 [run_pretraining.py:  512]:	********exe.run_1030******* 
[INFO] 2021-07-12 18:52:36,094 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:36,094 [run_pretraining.py:  534]:	loss/total_loss, 8.247349739074707, 1031
[INFO] 2021-07-12 18:52:36,094 [run_pretraining.py:  535]:	loss/mlm_loss, 8.247349739074707, 1031
[INFO] 2021-07-12 18:52:36,094 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0299999303242657e-05, 1031
[INFO] 2021-07-12 18:52:36,094 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1031
[INFO] 2021-07-12 18:52:36,094 [run_pretraining.py:  558]:	worker_index: 2, step: 1031, cost: 8.247350, mlm loss: 8.247350, speed: 0.948036 steps/s, speed: 7.584292 samples/s, speed: 3883.157475 tokens/s, learning rate: 1.030e-05, loss_scalings: 13421.773438, pp_loss: 8.225991
[INFO] 2021-07-12 18:52:36,094 [run_pretraining.py:  512]:	********exe.run_1031******* 
[INFO] 2021-07-12 18:52:37,157 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:37,157 [run_pretraining.py:  534]:	loss/total_loss, 7.519539833068848, 1032
[INFO] 2021-07-12 18:52:37,157 [run_pretraining.py:  535]:	loss/mlm_loss, 7.519539833068848, 1032
[INFO] 2021-07-12 18:52:37,157 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0310000106983352e-05, 1032
[INFO] 2021-07-12 18:52:37,157 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1032
[INFO] 2021-07-12 18:52:37,157 [run_pretraining.py:  558]:	worker_index: 2, step: 1032, cost: 7.519540, mlm loss: 7.519540, speed: 0.941227 steps/s, speed: 7.529817 samples/s, speed: 3855.266447 tokens/s, learning rate: 1.031e-05, loss_scalings: 13421.773438, pp_loss: 7.049364
[INFO] 2021-07-12 18:52:37,158 [run_pretraining.py:  512]:	********exe.run_1032******* 
[INFO] 2021-07-12 18:52:38,217 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:38,217 [run_pretraining.py:  534]:	loss/total_loss, 7.965850830078125, 1033
[INFO] 2021-07-12 18:52:38,217 [run_pretraining.py:  535]:	loss/mlm_loss, 7.965850830078125, 1033
[INFO] 2021-07-12 18:52:38,218 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0320000001229346e-05, 1033
[INFO] 2021-07-12 18:52:38,218 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1033
[INFO] 2021-07-12 18:52:38,218 [run_pretraining.py:  558]:	worker_index: 2, step: 1033, cost: 7.965851, mlm loss: 7.965851, speed: 0.943735 steps/s, speed: 7.549879 samples/s, speed: 3865.537923 tokens/s, learning rate: 1.032e-05, loss_scalings: 13421.773438, pp_loss: 7.877522
[INFO] 2021-07-12 18:52:38,218 [run_pretraining.py:  512]:	********exe.run_1033******* 
[INFO] 2021-07-12 18:52:39,333 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:39,334 [run_pretraining.py:  534]:	loss/total_loss, 8.080815315246582, 1034
[INFO] 2021-07-12 18:52:39,334 [run_pretraining.py:  535]:	loss/mlm_loss, 8.080815315246582, 1034
[INFO] 2021-07-12 18:52:39,334 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0329999895475339e-05, 1034
[INFO] 2021-07-12 18:52:39,334 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1034
[INFO] 2021-07-12 18:52:39,334 [run_pretraining.py:  558]:	worker_index: 2, step: 1034, cost: 8.080815, mlm loss: 8.080815, speed: 0.896170 steps/s, speed: 7.169360 samples/s, speed: 3670.712212 tokens/s, learning rate: 1.033e-05, loss_scalings: 13421.773438, pp_loss: 7.168344
[INFO] 2021-07-12 18:52:39,334 [run_pretraining.py:  512]:	********exe.run_1034******* 
[INFO] 2021-07-12 18:52:40,372 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:40,372 [run_pretraining.py:  534]:	loss/total_loss, 7.944279670715332, 1035
[INFO] 2021-07-12 18:52:40,373 [run_pretraining.py:  535]:	loss/mlm_loss, 7.944279670715332, 1035
[INFO] 2021-07-12 18:52:40,373 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0339999789721332e-05, 1035
[INFO] 2021-07-12 18:52:40,373 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1035
[INFO] 2021-07-12 18:52:40,373 [run_pretraining.py:  558]:	worker_index: 2, step: 1035, cost: 7.944280, mlm loss: 7.944280, speed: 0.963320 steps/s, speed: 7.706564 samples/s, speed: 3945.760580 tokens/s, learning rate: 1.034e-05, loss_scalings: 13421.773438, pp_loss: 7.887389
[INFO] 2021-07-12 18:52:40,373 [run_pretraining.py:  512]:	********exe.run_1035******* 
[INFO] 2021-07-12 18:52:41,431 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:41,432 [run_pretraining.py:  534]:	loss/total_loss, 8.090340614318848, 1036
[INFO] 2021-07-12 18:52:41,432 [run_pretraining.py:  535]:	loss/mlm_loss, 8.090340614318848, 1036
[INFO] 2021-07-12 18:52:41,432 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0349999683967326e-05, 1036
[INFO] 2021-07-12 18:52:41,432 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1036
[INFO] 2021-07-12 18:52:41,432 [run_pretraining.py:  558]:	worker_index: 2, step: 1036, cost: 8.090341, mlm loss: 8.090341, speed: 0.944480 steps/s, speed: 7.555843 samples/s, speed: 3868.591456 tokens/s, learning rate: 1.035e-05, loss_scalings: 13421.773438, pp_loss: 7.902746
[INFO] 2021-07-12 18:52:41,432 [run_pretraining.py:  512]:	********exe.run_1036******* 
[INFO] 2021-07-12 18:52:42,496 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:42,497 [run_pretraining.py:  534]:	loss/total_loss, 7.24733304977417, 1037
[INFO] 2021-07-12 18:52:42,497 [run_pretraining.py:  535]:	loss/mlm_loss, 7.24733304977417, 1037
[INFO] 2021-07-12 18:52:42,497 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.035999957821332e-05, 1037
[INFO] 2021-07-12 18:52:42,497 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1037
[INFO] 2021-07-12 18:52:42,497 [run_pretraining.py:  558]:	worker_index: 2, step: 1037, cost: 7.247333, mlm loss: 7.247333, speed: 0.939680 steps/s, speed: 7.517443 samples/s, speed: 3848.931036 tokens/s, learning rate: 1.036e-05, loss_scalings: 13421.773438, pp_loss: 7.779026
[INFO] 2021-07-12 18:52:42,497 [run_pretraining.py:  512]:	********exe.run_1037******* 
[INFO] 2021-07-12 18:52:43,549 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:43,549 [run_pretraining.py:  534]:	loss/total_loss, 8.483842849731445, 1038
[INFO] 2021-07-12 18:52:43,550 [run_pretraining.py:  535]:	loss/mlm_loss, 8.483842849731445, 1038
[INFO] 2021-07-12 18:52:43,550 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0369999472459313e-05, 1038
[INFO] 2021-07-12 18:52:43,550 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1038
[INFO] 2021-07-12 18:52:43,550 [run_pretraining.py:  558]:	worker_index: 2, step: 1038, cost: 8.483843, mlm loss: 8.483843, speed: 0.950390 steps/s, speed: 7.603120 samples/s, speed: 3892.797518 tokens/s, learning rate: 1.037e-05, loss_scalings: 13421.773438, pp_loss: 8.260021
[INFO] 2021-07-12 18:52:43,550 [run_pretraining.py:  512]:	********exe.run_1038******* 
[INFO] 2021-07-12 18:52:44,521 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:44,521 [run_pretraining.py:  534]:	loss/total_loss, 7.814955711364746, 1039
[INFO] 2021-07-12 18:52:44,521 [run_pretraining.py:  535]:	loss/mlm_loss, 7.814955711364746, 1039
[INFO] 2021-07-12 18:52:44,521 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0379999366705306e-05, 1039
[INFO] 2021-07-12 18:52:44,521 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1039
[INFO] 2021-07-12 18:52:44,522 [run_pretraining.py:  558]:	worker_index: 2, step: 1039, cost: 7.814956, mlm loss: 7.814956, speed: 1.029765 steps/s, speed: 8.238122 samples/s, speed: 4217.918577 tokens/s, learning rate: 1.038e-05, loss_scalings: 13421.773438, pp_loss: 7.693732
[INFO] 2021-07-12 18:52:44,522 [run_pretraining.py:  512]:	********exe.run_1039******* 
[INFO] 2021-07-12 18:52:45,488 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:45,489 [run_pretraining.py:  534]:	loss/total_loss, 7.67521333694458, 1040
[INFO] 2021-07-12 18:52:45,489 [run_pretraining.py:  535]:	loss/mlm_loss, 7.67521333694458, 1040
[INFO] 2021-07-12 18:52:45,489 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0390000170446001e-05, 1040
[INFO] 2021-07-12 18:52:45,489 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1040
[INFO] 2021-07-12 18:52:45,489 [run_pretraining.py:  558]:	worker_index: 2, step: 1040, cost: 7.675213, mlm loss: 7.675213, speed: 1.034385 steps/s, speed: 8.275082 samples/s, speed: 4236.842060 tokens/s, learning rate: 1.039e-05, loss_scalings: 13421.773438, pp_loss: 8.002866
[INFO] 2021-07-12 18:52:45,489 [run_pretraining.py:  512]:	********exe.run_1040******* 
[INFO] 2021-07-12 18:52:46,447 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:46,448 [run_pretraining.py:  534]:	loss/total_loss, 8.361992835998535, 1041
[INFO] 2021-07-12 18:52:46,448 [run_pretraining.py:  535]:	loss/mlm_loss, 8.361992835998535, 1041
[INFO] 2021-07-12 18:52:46,448 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0400000064691994e-05, 1041
[INFO] 2021-07-12 18:52:46,448 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1041
[INFO] 2021-07-12 18:52:46,448 [run_pretraining.py:  558]:	worker_index: 2, step: 1041, cost: 8.361993, mlm loss: 8.361993, speed: 1.043068 steps/s, speed: 8.344547 samples/s, speed: 4272.407914 tokens/s, learning rate: 1.040e-05, loss_scalings: 13421.773438, pp_loss: 8.236545
[INFO] 2021-07-12 18:52:46,448 [run_pretraining.py:  512]:	********exe.run_1041******* 
[INFO] 2021-07-12 18:52:47,398 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:47,399 [run_pretraining.py:  534]:	loss/total_loss, 7.9492387771606445, 1042
[INFO] 2021-07-12 18:52:47,399 [run_pretraining.py:  535]:	loss/mlm_loss, 7.9492387771606445, 1042
[INFO] 2021-07-12 18:52:47,399 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0409999049443286e-05, 1042
[INFO] 2021-07-12 18:52:47,399 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1042
[INFO] 2021-07-12 18:52:47,399 [run_pretraining.py:  558]:	worker_index: 2, step: 1042, cost: 7.949239, mlm loss: 7.949239, speed: 1.052322 steps/s, speed: 8.418574 samples/s, speed: 4310.309844 tokens/s, learning rate: 1.041e-05, loss_scalings: 13421.773438, pp_loss: 7.814779
[INFO] 2021-07-12 18:52:47,399 [run_pretraining.py:  512]:	********exe.run_1042******* 
[INFO] 2021-07-12 18:52:48,353 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:48,354 [run_pretraining.py:  534]:	loss/total_loss, 7.745232105255127, 1043
[INFO] 2021-07-12 18:52:48,354 [run_pretraining.py:  535]:	loss/mlm_loss, 7.745232105255127, 1043
[INFO] 2021-07-12 18:52:48,354 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0419999853183981e-05, 1043
[INFO] 2021-07-12 18:52:48,354 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1043
[INFO] 2021-07-12 18:52:48,354 [run_pretraining.py:  558]:	worker_index: 2, step: 1043, cost: 7.745232, mlm loss: 7.745232, speed: 1.047788 steps/s, speed: 8.382300 samples/s, speed: 4291.737763 tokens/s, learning rate: 1.042e-05, loss_scalings: 13421.773438, pp_loss: 7.552566
[INFO] 2021-07-12 18:52:48,354 [run_pretraining.py:  512]:	********exe.run_1043******* 
[INFO] 2021-07-12 18:52:49,322 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:49,322 [run_pretraining.py:  534]:	loss/total_loss, 8.091569900512695, 1044
[INFO] 2021-07-12 18:52:49,322 [run_pretraining.py:  535]:	loss/mlm_loss, 8.091569900512695, 1044
[INFO] 2021-07-12 18:52:49,322 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0429999747429974e-05, 1044
[INFO] 2021-07-12 18:52:49,322 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1044
[INFO] 2021-07-12 18:52:49,322 [run_pretraining.py:  558]:	worker_index: 2, step: 1044, cost: 8.091570, mlm loss: 8.091570, speed: 1.033247 steps/s, speed: 8.265978 samples/s, speed: 4232.180778 tokens/s, learning rate: 1.043e-05, loss_scalings: 13421.773438, pp_loss: 7.778263
[INFO] 2021-07-12 18:52:49,323 [run_pretraining.py:  512]:	********exe.run_1044******* 
[INFO] 2021-07-12 18:52:50,277 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:50,277 [run_pretraining.py:  534]:	loss/total_loss, 8.984474182128906, 1045
[INFO] 2021-07-12 18:52:50,277 [run_pretraining.py:  535]:	loss/mlm_loss, 8.984474182128906, 1045
[INFO] 2021-07-12 18:52:50,277 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0439999641675968e-05, 1045
[INFO] 2021-07-12 18:52:50,278 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1045
[INFO] 2021-07-12 18:52:50,278 [run_pretraining.py:  558]:	worker_index: 2, step: 1045, cost: 8.984474, mlm loss: 8.984474, speed: 1.047591 steps/s, speed: 8.380730 samples/s, speed: 4290.933818 tokens/s, learning rate: 1.044e-05, loss_scalings: 13421.773438, pp_loss: 8.383810
[INFO] 2021-07-12 18:52:50,278 [run_pretraining.py:  512]:	********exe.run_1045******* 
[INFO] 2021-07-12 18:52:51,176 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:51,176 [run_pretraining.py:  534]:	loss/total_loss, 7.533881664276123, 1046
[INFO] 2021-07-12 18:52:51,176 [run_pretraining.py:  535]:	loss/mlm_loss, 7.533881664276123, 1046
[INFO] 2021-07-12 18:52:51,176 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0450000445416663e-05, 1046
[INFO] 2021-07-12 18:52:51,176 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1046
[INFO] 2021-07-12 18:52:51,177 [run_pretraining.py:  558]:	worker_index: 2, step: 1046, cost: 7.533882, mlm loss: 7.533882, speed: 1.113179 steps/s, speed: 8.905433 samples/s, speed: 4559.581467 tokens/s, learning rate: 1.045e-05, loss_scalings: 13421.773438, pp_loss: 6.949184
[INFO] 2021-07-12 18:52:51,177 [run_pretraining.py:  512]:	********exe.run_1046******* 
[INFO] 2021-07-12 18:52:52,085 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:52,085 [run_pretraining.py:  534]:	loss/total_loss, 8.032602310180664, 1047
[INFO] 2021-07-12 18:52:52,086 [run_pretraining.py:  535]:	loss/mlm_loss, 8.032602310180664, 1047
[INFO] 2021-07-12 18:52:52,086 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0459999430167954e-05, 1047
[INFO] 2021-07-12 18:52:52,086 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1047
[INFO] 2021-07-12 18:52:52,086 [run_pretraining.py:  558]:	worker_index: 2, step: 1047, cost: 8.032602, mlm loss: 8.032602, speed: 1.100467 steps/s, speed: 8.803740 samples/s, speed: 4507.514641 tokens/s, learning rate: 1.046e-05, loss_scalings: 13421.773438, pp_loss: 8.021517
[INFO] 2021-07-12 18:52:52,086 [run_pretraining.py:  512]:	********exe.run_1047******* 
[INFO] 2021-07-12 18:52:52,990 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:52,990 [run_pretraining.py:  534]:	loss/total_loss, 8.192207336425781, 1048
[INFO] 2021-07-12 18:52:52,990 [run_pretraining.py:  535]:	loss/mlm_loss, 8.192207336425781, 1048
[INFO] 2021-07-12 18:52:52,990 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0469999324413948e-05, 1048
[INFO] 2021-07-12 18:52:52,990 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1048
[INFO] 2021-07-12 18:52:52,990 [run_pretraining.py:  558]:	worker_index: 2, step: 1048, cost: 8.192207, mlm loss: 8.192207, speed: 1.106116 steps/s, speed: 8.848927 samples/s, speed: 4530.650608 tokens/s, learning rate: 1.047e-05, loss_scalings: 13421.773438, pp_loss: 8.005873
[INFO] 2021-07-12 18:52:52,991 [run_pretraining.py:  512]:	********exe.run_1048******* 
[INFO] 2021-07-12 18:52:53,895 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:53,895 [run_pretraining.py:  534]:	loss/total_loss, 8.059493064880371, 1049
[INFO] 2021-07-12 18:52:53,895 [run_pretraining.py:  535]:	loss/mlm_loss, 8.059493064880371, 1049
[INFO] 2021-07-12 18:52:53,895 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0480000128154643e-05, 1049
[INFO] 2021-07-12 18:52:53,895 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1049
[INFO] 2021-07-12 18:52:53,895 [run_pretraining.py:  558]:	worker_index: 2, step: 1049, cost: 8.059493, mlm loss: 8.059493, speed: 1.105923 steps/s, speed: 8.847385 samples/s, speed: 4529.860972 tokens/s, learning rate: 1.048e-05, loss_scalings: 13421.773438, pp_loss: 7.986300
[INFO] 2021-07-12 18:52:53,895 [run_pretraining.py:  512]:	********exe.run_1049******* 
[INFO] 2021-07-12 18:52:54,802 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:54,802 [run_pretraining.py:  534]:	loss/total_loss, 8.00601577758789, 1050
[INFO] 2021-07-12 18:52:54,802 [run_pretraining.py:  535]:	loss/mlm_loss, 8.00601577758789, 1050
[INFO] 2021-07-12 18:52:54,802 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0490000022400636e-05, 1050
[INFO] 2021-07-12 18:52:54,803 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1050
[INFO] 2021-07-12 18:52:54,803 [run_pretraining.py:  558]:	worker_index: 2, step: 1050, cost: 8.006016, mlm loss: 8.006016, speed: 1.102946 steps/s, speed: 8.823570 samples/s, speed: 4517.667999 tokens/s, learning rate: 1.049e-05, loss_scalings: 13421.773438, pp_loss: 8.021631
[INFO] 2021-07-12 18:52:54,803 [run_pretraining.py:  512]:	********exe.run_1050******* 
[INFO] 2021-07-12 18:52:55,714 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:55,714 [run_pretraining.py:  534]:	loss/total_loss, 7.693995475769043, 1051
[INFO] 2021-07-12 18:52:55,714 [run_pretraining.py:  535]:	loss/mlm_loss, 7.693995475769043, 1051
[INFO] 2021-07-12 18:52:55,715 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0499999007151928e-05, 1051
[INFO] 2021-07-12 18:52:55,715 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1051
[INFO] 2021-07-12 18:52:55,715 [run_pretraining.py:  558]:	worker_index: 2, step: 1051, cost: 7.693995, mlm loss: 7.693995, speed: 1.097155 steps/s, speed: 8.777240 samples/s, speed: 4493.946907 tokens/s, learning rate: 1.050e-05, loss_scalings: 13421.773438, pp_loss: 7.895749
[INFO] 2021-07-12 18:52:55,715 [run_pretraining.py:  512]:	********exe.run_1051******* 
[INFO] 2021-07-12 18:52:56,618 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:56,619 [run_pretraining.py:  534]:	loss/total_loss, 7.812412261962891, 1052
[INFO] 2021-07-12 18:52:56,619 [run_pretraining.py:  535]:	loss/mlm_loss, 7.812412261962891, 1052
[INFO] 2021-07-12 18:52:56,619 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0509999810892623e-05, 1052
[INFO] 2021-07-12 18:52:56,619 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1052
[INFO] 2021-07-12 18:52:56,619 [run_pretraining.py:  558]:	worker_index: 2, step: 1052, cost: 7.812412, mlm loss: 7.812412, speed: 1.106627 steps/s, speed: 8.853015 samples/s, speed: 4532.743699 tokens/s, learning rate: 1.051e-05, loss_scalings: 13421.773438, pp_loss: 7.243649
[INFO] 2021-07-12 18:52:56,619 [run_pretraining.py:  512]:	********exe.run_1052******* 
[INFO] 2021-07-12 18:52:57,524 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:57,525 [run_pretraining.py:  534]:	loss/total_loss, 7.7353644371032715, 1053
[INFO] 2021-07-12 18:52:57,525 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7353644371032715, 1053
[INFO] 2021-07-12 18:52:57,525 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0519999705138616e-05, 1053
[INFO] 2021-07-12 18:52:57,525 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1053
[INFO] 2021-07-12 18:52:57,525 [run_pretraining.py:  558]:	worker_index: 2, step: 1053, cost: 7.735364, mlm loss: 7.735364, speed: 1.104004 steps/s, speed: 8.832029 samples/s, speed: 4521.998766 tokens/s, learning rate: 1.052e-05, loss_scalings: 13421.773438, pp_loss: 8.015712
[INFO] 2021-07-12 18:52:57,525 [run_pretraining.py:  512]:	********exe.run_1053******* 
[INFO] 2021-07-12 18:52:58,478 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:58,478 [run_pretraining.py:  534]:	loss/total_loss, 8.415302276611328, 1054
[INFO] 2021-07-12 18:52:58,479 [run_pretraining.py:  535]:	loss/mlm_loss, 8.415302276611328, 1054
[INFO] 2021-07-12 18:52:58,479 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.052999959938461e-05, 1054
[INFO] 2021-07-12 18:52:58,479 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1054
[INFO] 2021-07-12 18:52:58,479 [run_pretraining.py:  558]:	worker_index: 2, step: 1054, cost: 8.415302, mlm loss: 8.415302, speed: 1.049416 steps/s, speed: 8.395326 samples/s, speed: 4298.407096 tokens/s, learning rate: 1.053e-05, loss_scalings: 13421.773438, pp_loss: 8.116128
[INFO] 2021-07-12 18:52:58,479 [run_pretraining.py:  512]:	********exe.run_1054******* 
[INFO] 2021-07-12 18:52:59,538 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:59,538 [run_pretraining.py:  534]:	loss/total_loss, 8.724143981933594, 1055
[INFO] 2021-07-12 18:52:59,538 [run_pretraining.py:  535]:	loss/mlm_loss, 8.724143981933594, 1055
[INFO] 2021-07-12 18:52:59,539 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0540000403125305e-05, 1055
[INFO] 2021-07-12 18:52:59,539 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1055
[INFO] 2021-07-12 18:52:59,539 [run_pretraining.py:  558]:	worker_index: 2, step: 1055, cost: 8.724144, mlm loss: 8.724144, speed: 0.944007 steps/s, speed: 7.552054 samples/s, speed: 3866.651538 tokens/s, learning rate: 1.054e-05, loss_scalings: 13421.773438, pp_loss: 8.349077
[INFO] 2021-07-12 18:52:59,539 [run_pretraining.py:  512]:	********exe.run_1055******* 
[INFO] 2021-07-12 18:53:00,595 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:00,596 [run_pretraining.py:  534]:	loss/total_loss, 7.79707145690918, 1056
[INFO] 2021-07-12 18:53:00,596 [run_pretraining.py:  535]:	loss/mlm_loss, 7.79707145690918, 1056
[INFO] 2021-07-12 18:53:00,596 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0549999387876596e-05, 1056
[INFO] 2021-07-12 18:53:00,596 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1056
[INFO] 2021-07-12 18:53:00,596 [run_pretraining.py:  558]:	worker_index: 2, step: 1056, cost: 7.797071, mlm loss: 7.797071, speed: 0.946391 steps/s, speed: 7.571125 samples/s, speed: 3876.416112 tokens/s, learning rate: 1.055e-05, loss_scalings: 13421.773438, pp_loss: 7.925816
[INFO] 2021-07-12 18:53:00,596 [run_pretraining.py:  512]:	********exe.run_1056******* 
[INFO] 2021-07-12 18:53:01,684 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:01,684 [run_pretraining.py:  534]:	loss/total_loss, 7.884869575500488, 1057
[INFO] 2021-07-12 18:53:01,684 [run_pretraining.py:  535]:	loss/mlm_loss, 7.884869575500488, 1057
[INFO] 2021-07-12 18:53:01,684 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.055999928212259e-05, 1057
[INFO] 2021-07-12 18:53:01,684 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1057
[INFO] 2021-07-12 18:53:01,685 [run_pretraining.py:  558]:	worker_index: 2, step: 1057, cost: 7.884870, mlm loss: 7.884870, speed: 0.919157 steps/s, speed: 7.353255 samples/s, speed: 3764.866555 tokens/s, learning rate: 1.056e-05, loss_scalings: 13421.773438, pp_loss: 7.885790
[INFO] 2021-07-12 18:53:01,685 [run_pretraining.py:  512]:	********exe.run_1057******* 
[INFO] 2021-07-12 18:53:02,800 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:02,801 [run_pretraining.py:  534]:	loss/total_loss, 8.004444122314453, 1058
[INFO] 2021-07-12 18:53:02,801 [run_pretraining.py:  535]:	loss/mlm_loss, 8.004444122314453, 1058
[INFO] 2021-07-12 18:53:02,801 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0570000085863285e-05, 1058
[INFO] 2021-07-12 18:53:02,801 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1058
[INFO] 2021-07-12 18:53:02,801 [run_pretraining.py:  558]:	worker_index: 2, step: 1058, cost: 8.004444, mlm loss: 8.004444, speed: 0.896029 steps/s, speed: 7.168233 samples/s, speed: 3670.135060 tokens/s, learning rate: 1.057e-05, loss_scalings: 13421.773438, pp_loss: 8.073917
[INFO] 2021-07-12 18:53:02,801 [run_pretraining.py:  512]:	********exe.run_1058******* 
[INFO] 2021-07-12 18:53:03,894 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:03,895 [run_pretraining.py:  534]:	loss/total_loss, 7.816307067871094, 1059
[INFO] 2021-07-12 18:53:03,895 [run_pretraining.py:  535]:	loss/mlm_loss, 7.816307067871094, 1059
[INFO] 2021-07-12 18:53:03,895 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0579999980109278e-05, 1059
[INFO] 2021-07-12 18:53:03,895 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1059
[INFO] 2021-07-12 18:53:03,895 [run_pretraining.py:  558]:	worker_index: 2, step: 1059, cost: 7.816307, mlm loss: 7.816307, speed: 0.914873 steps/s, speed: 7.318987 samples/s, speed: 3747.321546 tokens/s, learning rate: 1.058e-05, loss_scalings: 13421.773438, pp_loss: 7.901011
[INFO] 2021-07-12 18:53:03,895 [run_pretraining.py:  512]:	********exe.run_1059******* 
[INFO] 2021-07-12 18:53:04,985 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:04,986 [run_pretraining.py:  534]:	loss/total_loss, 8.021944999694824, 1060
[INFO] 2021-07-12 18:53:04,986 [run_pretraining.py:  535]:	loss/mlm_loss, 8.021944999694824, 1060
[INFO] 2021-07-12 18:53:04,986 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0589999874355271e-05, 1060
[INFO] 2021-07-12 18:53:04,986 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1060
[INFO] 2021-07-12 18:53:04,986 [run_pretraining.py:  558]:	worker_index: 2, step: 1060, cost: 8.021945, mlm loss: 8.021945, speed: 0.916732 steps/s, speed: 7.333858 samples/s, speed: 3754.935315 tokens/s, learning rate: 1.059e-05, loss_scalings: 13421.773438, pp_loss: 8.097618
[INFO] 2021-07-12 18:53:04,986 [run_pretraining.py:  512]:	********exe.run_1060******* 
[INFO] 2021-07-12 18:53:06,079 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:06,079 [run_pretraining.py:  534]:	loss/total_loss, 8.366837501525879, 1061
[INFO] 2021-07-12 18:53:06,079 [run_pretraining.py:  535]:	loss/mlm_loss, 8.366837501525879, 1061
[INFO] 2021-07-12 18:53:06,079 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0599999768601265e-05, 1061
[INFO] 2021-07-12 18:53:06,079 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1061
[INFO] 2021-07-12 18:53:06,079 [run_pretraining.py:  558]:	worker_index: 2, step: 1061, cost: 8.366838, mlm loss: 8.366838, speed: 0.915286 steps/s, speed: 7.322286 samples/s, speed: 3749.010189 tokens/s, learning rate: 1.060e-05, loss_scalings: 13421.773438, pp_loss: 8.164984
[INFO] 2021-07-12 18:53:06,080 [run_pretraining.py:  512]:	********exe.run_1061******* 
[INFO] 2021-07-12 18:53:07,172 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:07,173 [run_pretraining.py:  534]:	loss/total_loss, 8.198103904724121, 1062
[INFO] 2021-07-12 18:53:07,173 [run_pretraining.py:  535]:	loss/mlm_loss, 8.198103904724121, 1062
[INFO] 2021-07-12 18:53:07,173 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0609999662847258e-05, 1062
[INFO] 2021-07-12 18:53:07,173 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1062
[INFO] 2021-07-12 18:53:07,173 [run_pretraining.py:  558]:	worker_index: 2, step: 1062, cost: 8.198104, mlm loss: 8.198104, speed: 0.914894 steps/s, speed: 7.319153 samples/s, speed: 3747.406555 tokens/s, learning rate: 1.061e-05, loss_scalings: 13421.773438, pp_loss: 8.275446
[INFO] 2021-07-12 18:53:07,173 [run_pretraining.py:  512]:	********exe.run_1062******* 
[INFO] 2021-07-12 18:53:08,271 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:08,271 [run_pretraining.py:  534]:	loss/total_loss, 8.161749839782715, 1063
[INFO] 2021-07-12 18:53:08,271 [run_pretraining.py:  535]:	loss/mlm_loss, 8.161749839782715, 1063
[INFO] 2021-07-12 18:53:08,271 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0619999557093251e-05, 1063
[INFO] 2021-07-12 18:53:08,271 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1063
[INFO] 2021-07-12 18:53:08,272 [run_pretraining.py:  558]:	worker_index: 2, step: 1063, cost: 8.161750, mlm loss: 8.161750, speed: 0.910885 steps/s, speed: 7.287083 samples/s, speed: 3730.986685 tokens/s, learning rate: 1.062e-05, loss_scalings: 13421.773438, pp_loss: 8.110551
[INFO] 2021-07-12 18:53:08,272 [run_pretraining.py:  512]:	********exe.run_1063******* 
[INFO] 2021-07-12 18:53:09,361 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:09,361 [run_pretraining.py:  534]:	loss/total_loss, 7.850825309753418, 1064
[INFO] 2021-07-12 18:53:09,361 [run_pretraining.py:  535]:	loss/mlm_loss, 7.850825309753418, 1064
[INFO] 2021-07-12 18:53:09,362 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0629999451339245e-05, 1064
[INFO] 2021-07-12 18:53:09,362 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1064
[INFO] 2021-07-12 18:53:09,362 [run_pretraining.py:  558]:	worker_index: 2, step: 1064, cost: 7.850825, mlm loss: 7.850825, speed: 0.917831 steps/s, speed: 7.342645 samples/s, speed: 3759.434038 tokens/s, learning rate: 1.063e-05, loss_scalings: 13421.773438, pp_loss: 8.054397
[INFO] 2021-07-12 18:53:09,362 [run_pretraining.py:  512]:	********exe.run_1064******* 
[INFO] 2021-07-12 18:53:10,310 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:10,310 [run_pretraining.py:  534]:	loss/total_loss, 8.354718208312988, 1065
[INFO] 2021-07-12 18:53:10,311 [run_pretraining.py:  535]:	loss/mlm_loss, 8.354718208312988, 1065
[INFO] 2021-07-12 18:53:10,311 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0639999345585238e-05, 1065
[INFO] 2021-07-12 18:53:10,311 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1065
[INFO] 2021-07-12 18:53:10,311 [run_pretraining.py:  558]:	worker_index: 2, step: 1065, cost: 8.354718, mlm loss: 8.354718, speed: 1.054287 steps/s, speed: 8.434297 samples/s, speed: 4318.359851 tokens/s, learning rate: 1.064e-05, loss_scalings: 13421.773438, pp_loss: 8.329364
[INFO] 2021-07-12 18:53:10,311 [run_pretraining.py:  512]:	********exe.run_1065******* 
[INFO] 2021-07-12 18:53:11,226 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:11,226 [run_pretraining.py:  534]:	loss/total_loss, 8.14112377166748, 1066
[INFO] 2021-07-12 18:53:11,226 [run_pretraining.py:  535]:	loss/mlm_loss, 8.14112377166748, 1066
[INFO] 2021-07-12 18:53:11,227 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0650000149325933e-05, 1066
[INFO] 2021-07-12 18:53:11,227 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1066
[INFO] 2021-07-12 18:53:11,227 [run_pretraining.py:  558]:	worker_index: 2, step: 1066, cost: 8.141124, mlm loss: 8.141124, speed: 1.092503 steps/s, speed: 8.740022 samples/s, speed: 4474.891496 tokens/s, learning rate: 1.065e-05, loss_scalings: 13421.773438, pp_loss: 7.910243
[INFO] 2021-07-12 18:53:11,227 [run_pretraining.py:  512]:	********exe.run_1066******* 
[INFO] 2021-07-12 18:53:12,131 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:12,132 [run_pretraining.py:  534]:	loss/total_loss, 7.519906044006348, 1067
[INFO] 2021-07-12 18:53:12,132 [run_pretraining.py:  535]:	loss/mlm_loss, 7.519906044006348, 1067
[INFO] 2021-07-12 18:53:12,132 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0660000043571927e-05, 1067
[INFO] 2021-07-12 18:53:12,132 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1067
[INFO] 2021-07-12 18:53:12,132 [run_pretraining.py:  558]:	worker_index: 2, step: 1067, cost: 7.519906, mlm loss: 7.519906, speed: 1.105287 steps/s, speed: 8.842297 samples/s, speed: 4527.256289 tokens/s, learning rate: 1.066e-05, loss_scalings: 13421.773438, pp_loss: 7.874879
[INFO] 2021-07-12 18:53:12,132 [run_pretraining.py:  512]:	********exe.run_1067******* 
[INFO] 2021-07-12 18:53:13,041 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:13,041 [run_pretraining.py:  534]:	loss/total_loss, 7.335972785949707, 1068
[INFO] 2021-07-12 18:53:13,042 [run_pretraining.py:  535]:	loss/mlm_loss, 7.335972785949707, 1068
[INFO] 2021-07-12 18:53:13,042 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.066999993781792e-05, 1068
[INFO] 2021-07-12 18:53:13,042 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1068
[INFO] 2021-07-12 18:53:13,042 [run_pretraining.py:  558]:	worker_index: 2, step: 1068, cost: 7.335973, mlm loss: 7.335973, speed: 1.099953 steps/s, speed: 8.799628 samples/s, speed: 4505.409334 tokens/s, learning rate: 1.067e-05, loss_scalings: 13421.773438, pp_loss: 7.866875
[INFO] 2021-07-12 18:53:13,042 [run_pretraining.py:  512]:	********exe.run_1068******* 
[INFO] 2021-07-12 18:53:13,948 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:13,948 [run_pretraining.py:  534]:	loss/total_loss, 8.272473335266113, 1069
[INFO] 2021-07-12 18:53:13,948 [run_pretraining.py:  535]:	loss/mlm_loss, 8.272473335266113, 1069
[INFO] 2021-07-12 18:53:13,949 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0679999832063913e-05, 1069
[INFO] 2021-07-12 18:53:13,949 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1069
[INFO] 2021-07-12 18:53:13,949 [run_pretraining.py:  558]:	worker_index: 2, step: 1069, cost: 8.272473, mlm loss: 8.272473, speed: 1.103290 steps/s, speed: 8.826321 samples/s, speed: 4519.076193 tokens/s, learning rate: 1.068e-05, loss_scalings: 13421.773438, pp_loss: 7.881302
[INFO] 2021-07-12 18:53:13,949 [run_pretraining.py:  512]:	********exe.run_1069******* 
[INFO] 2021-07-12 18:53:14,861 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:14,861 [run_pretraining.py:  534]:	loss/total_loss, 7.561717987060547, 1070
[INFO] 2021-07-12 18:53:14,861 [run_pretraining.py:  535]:	loss/mlm_loss, 7.561717987060547, 1070
[INFO] 2021-07-12 18:53:14,861 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0689999726309907e-05, 1070
[INFO] 2021-07-12 18:53:14,861 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1070
[INFO] 2021-07-12 18:53:14,861 [run_pretraining.py:  558]:	worker_index: 2, step: 1070, cost: 7.561718, mlm loss: 7.561718, speed: 1.096490 steps/s, speed: 8.771924 samples/s, speed: 4491.224839 tokens/s, learning rate: 1.069e-05, loss_scalings: 13421.773438, pp_loss: 7.949151
[INFO] 2021-07-12 18:53:14,861 [run_pretraining.py:  512]:	********exe.run_1070******* 
[INFO] 2021-07-12 18:53:15,765 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:15,765 [run_pretraining.py:  534]:	loss/total_loss, 8.238919258117676, 1071
[INFO] 2021-07-12 18:53:15,765 [run_pretraining.py:  535]:	loss/mlm_loss, 8.238919258117676, 1071
[INFO] 2021-07-12 18:53:15,765 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.06999996205559e-05, 1071
[INFO] 2021-07-12 18:53:15,765 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1071
[INFO] 2021-07-12 18:53:15,765 [run_pretraining.py:  558]:	worker_index: 2, step: 1071, cost: 8.238919, mlm loss: 8.238919, speed: 1.106804 steps/s, speed: 8.854431 samples/s, speed: 4533.468543 tokens/s, learning rate: 1.070e-05, loss_scalings: 13421.773438, pp_loss: 7.989536
[INFO] 2021-07-12 18:53:15,766 [run_pretraining.py:  512]:	********exe.run_1071******* 
[INFO] 2021-07-12 18:53:16,685 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:16,686 [run_pretraining.py:  534]:	loss/total_loss, 8.050360679626465, 1072
[INFO] 2021-07-12 18:53:16,686 [run_pretraining.py:  535]:	loss/mlm_loss, 8.050360679626465, 1072
[INFO] 2021-07-12 18:53:16,686 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0710000424296595e-05, 1072
[INFO] 2021-07-12 18:53:16,686 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1072
[INFO] 2021-07-12 18:53:16,686 [run_pretraining.py:  558]:	worker_index: 2, step: 1072, cost: 8.050361, mlm loss: 8.050361, speed: 1.087049 steps/s, speed: 8.696391 samples/s, speed: 4452.552017 tokens/s, learning rate: 1.071e-05, loss_scalings: 13421.773438, pp_loss: 7.793341
[INFO] 2021-07-12 18:53:16,686 [run_pretraining.py:  512]:	********exe.run_1072******* 
[INFO] 2021-07-12 18:53:17,588 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:17,588 [run_pretraining.py:  534]:	loss/total_loss, 7.825827121734619, 1073
[INFO] 2021-07-12 18:53:17,588 [run_pretraining.py:  535]:	loss/mlm_loss, 7.825827121734619, 1073
[INFO] 2021-07-12 18:53:17,589 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0719999409047887e-05, 1073
[INFO] 2021-07-12 18:53:17,589 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1073
[INFO] 2021-07-12 18:53:17,589 [run_pretraining.py:  558]:	worker_index: 2, step: 1073, cost: 7.825827, mlm loss: 7.825827, speed: 1.108569 steps/s, speed: 8.868550 samples/s, speed: 4540.697350 tokens/s, learning rate: 1.072e-05, loss_scalings: 13421.773438, pp_loss: 7.909752
[INFO] 2021-07-12 18:53:17,589 [run_pretraining.py:  512]:	********exe.run_1073******* 
[INFO] 2021-07-12 18:53:18,496 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:18,497 [run_pretraining.py:  534]:	loss/total_loss, 8.060691833496094, 1074
[INFO] 2021-07-12 18:53:18,497 [run_pretraining.py:  535]:	loss/mlm_loss, 8.060691833496094, 1074
[INFO] 2021-07-12 18:53:18,497 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.072999930329388e-05, 1074
[INFO] 2021-07-12 18:53:18,497 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1074
[INFO] 2021-07-12 18:53:18,497 [run_pretraining.py:  558]:	worker_index: 2, step: 1074, cost: 8.060692, mlm loss: 8.060692, speed: 1.101320 steps/s, speed: 8.810557 samples/s, speed: 4511.004962 tokens/s, learning rate: 1.073e-05, loss_scalings: 13421.773438, pp_loss: 7.992539
[INFO] 2021-07-12 18:53:18,497 [run_pretraining.py:  512]:	********exe.run_1074******* 
[INFO] 2021-07-12 18:53:19,403 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:19,404 [run_pretraining.py:  534]:	loss/total_loss, 7.947543144226074, 1075
[INFO] 2021-07-12 18:53:19,404 [run_pretraining.py:  535]:	loss/mlm_loss, 7.947543144226074, 1075
[INFO] 2021-07-12 18:53:19,404 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0740000107034575e-05, 1075
[INFO] 2021-07-12 18:53:19,404 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1075
[INFO] 2021-07-12 18:53:19,404 [run_pretraining.py:  558]:	worker_index: 2, step: 1075, cost: 7.947543, mlm loss: 7.947543, speed: 1.103650 steps/s, speed: 8.829198 samples/s, speed: 4520.549497 tokens/s, learning rate: 1.074e-05, loss_scalings: 13421.773438, pp_loss: 7.991671
[INFO] 2021-07-12 18:53:19,404 [run_pretraining.py:  512]:	********exe.run_1075******* 
[INFO] 2021-07-12 18:53:20,313 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:20,314 [run_pretraining.py:  534]:	loss/total_loss, 7.635639190673828, 1076
[INFO] 2021-07-12 18:53:20,314 [run_pretraining.py:  535]:	loss/mlm_loss, 7.635639190673828, 1076
[INFO] 2021-07-12 18:53:20,314 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0750000001280569e-05, 1076
[INFO] 2021-07-12 18:53:20,314 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1076
[INFO] 2021-07-12 18:53:20,314 [run_pretraining.py:  558]:	worker_index: 2, step: 1076, cost: 7.635639, mlm loss: 7.635639, speed: 1.099712 steps/s, speed: 8.797694 samples/s, speed: 4504.419421 tokens/s, learning rate: 1.075e-05, loss_scalings: 13421.773438, pp_loss: 7.919679
[INFO] 2021-07-12 18:53:20,314 [run_pretraining.py:  512]:	********exe.run_1076******* 
[INFO] 2021-07-12 18:53:21,216 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:21,216 [run_pretraining.py:  534]:	loss/total_loss, 8.186534881591797, 1077
[INFO] 2021-07-12 18:53:21,216 [run_pretraining.py:  535]:	loss/mlm_loss, 8.186534881591797, 1077
[INFO] 2021-07-12 18:53:21,217 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0759999895526562e-05, 1077
[INFO] 2021-07-12 18:53:21,217 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1077
[INFO] 2021-07-12 18:53:21,217 [run_pretraining.py:  558]:	worker_index: 2, step: 1077, cost: 8.186535, mlm loss: 8.186535, speed: 1.108414 steps/s, speed: 8.867312 samples/s, speed: 4540.063774 tokens/s, learning rate: 1.076e-05, loss_scalings: 13421.773438, pp_loss: 7.914913
[INFO] 2021-07-12 18:53:21,217 [run_pretraining.py:  512]:	********exe.run_1077******* 
[INFO] 2021-07-12 18:53:22,122 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:22,123 [run_pretraining.py:  534]:	loss/total_loss, 7.6382246017456055, 1078
[INFO] 2021-07-12 18:53:22,123 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6382246017456055, 1078
[INFO] 2021-07-12 18:53:22,123 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0769999789772555e-05, 1078
[INFO] 2021-07-12 18:53:22,123 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1078
[INFO] 2021-07-12 18:53:22,123 [run_pretraining.py:  558]:	worker_index: 2, step: 1078, cost: 7.638225, mlm loss: 7.638225, speed: 1.104021 steps/s, speed: 8.832166 samples/s, speed: 4522.068992 tokens/s, learning rate: 1.077e-05, loss_scalings: 13421.773438, pp_loss: 7.817880
[INFO] 2021-07-12 18:53:22,123 [run_pretraining.py:  512]:	********exe.run_1078******* 
[INFO] 2021-07-12 18:53:23,028 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:23,028 [run_pretraining.py:  534]:	loss/total_loss, 8.013023376464844, 1079
[INFO] 2021-07-12 18:53:23,028 [run_pretraining.py:  535]:	loss/mlm_loss, 8.013023376464844, 1079
[INFO] 2021-07-12 18:53:23,028 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0779999684018549e-05, 1079
[INFO] 2021-07-12 18:53:23,029 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1079
[INFO] 2021-07-12 18:53:23,029 [run_pretraining.py:  558]:	worker_index: 2, step: 1079, cost: 8.013023, mlm loss: 8.013023, speed: 1.104980 steps/s, speed: 8.839838 samples/s, speed: 4525.996803 tokens/s, learning rate: 1.078e-05, loss_scalings: 13421.773438, pp_loss: 7.582053
[INFO] 2021-07-12 18:53:23,029 [run_pretraining.py:  512]:	********exe.run_1079******* 
[INFO] 2021-07-12 18:53:23,933 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:23,934 [run_pretraining.py:  534]:	loss/total_loss, 7.61033821105957, 1080
[INFO] 2021-07-12 18:53:23,934 [run_pretraining.py:  535]:	loss/mlm_loss, 7.61033821105957, 1080
[INFO] 2021-07-12 18:53:23,934 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0789999578264542e-05, 1080
[INFO] 2021-07-12 18:53:23,934 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1080
[INFO] 2021-07-12 18:53:23,934 [run_pretraining.py:  558]:	worker_index: 2, step: 1080, cost: 7.610338, mlm loss: 7.610338, speed: 1.105183 steps/s, speed: 8.841463 samples/s, speed: 4526.829226 tokens/s, learning rate: 1.079e-05, loss_scalings: 13421.773438, pp_loss: 7.904839
[INFO] 2021-07-12 18:53:23,934 [run_pretraining.py:  512]:	********exe.run_1080******* 
[INFO] 2021-07-12 18:53:24,838 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:24,838 [run_pretraining.py:  534]:	loss/total_loss, 7.837375640869141, 1081
[INFO] 2021-07-12 18:53:24,838 [run_pretraining.py:  535]:	loss/mlm_loss, 7.837375640869141, 1081
[INFO] 2021-07-12 18:53:24,838 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0800000382005237e-05, 1081
[INFO] 2021-07-12 18:53:24,839 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1081
[INFO] 2021-07-12 18:53:24,839 [run_pretraining.py:  558]:	worker_index: 2, step: 1081, cost: 7.837376, mlm loss: 7.837376, speed: 1.106272 steps/s, speed: 8.850173 samples/s, speed: 4531.288730 tokens/s, learning rate: 1.080e-05, loss_scalings: 13421.773438, pp_loss: 7.746237
[INFO] 2021-07-12 18:53:24,839 [run_pretraining.py:  512]:	********exe.run_1081******* 
[INFO] 2021-07-12 18:53:25,747 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:25,747 [run_pretraining.py:  534]:	loss/total_loss, 7.748073577880859, 1082
[INFO] 2021-07-12 18:53:25,748 [run_pretraining.py:  535]:	loss/mlm_loss, 7.748073577880859, 1082
[INFO] 2021-07-12 18:53:25,748 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0809999366756529e-05, 1082
[INFO] 2021-07-12 18:53:25,748 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1082
[INFO] 2021-07-12 18:53:25,748 [run_pretraining.py:  558]:	worker_index: 2, step: 1082, cost: 7.748074, mlm loss: 7.748074, speed: 1.100588 steps/s, speed: 8.804703 samples/s, speed: 4508.007858 tokens/s, learning rate: 1.081e-05, loss_scalings: 13421.773438, pp_loss: 7.633207
[INFO] 2021-07-12 18:53:25,748 [run_pretraining.py:  512]:	********exe.run_1082******* 
[INFO] 2021-07-12 18:53:26,707 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:26,707 [run_pretraining.py:  534]:	loss/total_loss, 8.308570861816406, 1083
[INFO] 2021-07-12 18:53:26,708 [run_pretraining.py:  535]:	loss/mlm_loss, 8.308570861816406, 1083
[INFO] 2021-07-12 18:53:26,708 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0819999261002522e-05, 1083
[INFO] 2021-07-12 18:53:26,708 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1083
[INFO] 2021-07-12 18:53:26,708 [run_pretraining.py:  558]:	worker_index: 2, step: 1083, cost: 8.308571, mlm loss: 8.308571, speed: 1.042401 steps/s, speed: 8.339209 samples/s, speed: 4269.674810 tokens/s, learning rate: 1.082e-05, loss_scalings: 13421.773438, pp_loss: 7.982129
[INFO] 2021-07-12 18:53:26,708 [run_pretraining.py:  512]:	********exe.run_1083******* 
[INFO] 2021-07-12 18:53:27,606 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:27,607 [run_pretraining.py:  534]:	loss/total_loss, 7.7049994468688965, 1084
[INFO] 2021-07-12 18:53:27,607 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7049994468688965, 1084
[INFO] 2021-07-12 18:53:27,607 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0830000064743217e-05, 1084
[INFO] 2021-07-12 18:53:27,607 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1084
[INFO] 2021-07-12 18:53:27,607 [run_pretraining.py:  558]:	worker_index: 2, step: 1084, cost: 7.704999, mlm loss: 7.704999, speed: 1.112853 steps/s, speed: 8.902822 samples/s, speed: 4558.244671 tokens/s, learning rate: 1.083e-05, loss_scalings: 13421.773438, pp_loss: 7.673851
[INFO] 2021-07-12 18:53:27,607 [run_pretraining.py:  512]:	********exe.run_1084******* 
[INFO] 2021-07-12 18:53:28,527 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:28,527 [run_pretraining.py:  534]:	loss/total_loss, 4.506311416625977, 1085
[INFO] 2021-07-12 18:53:28,527 [run_pretraining.py:  535]:	loss/mlm_loss, 4.506311416625977, 1085
[INFO] 2021-07-12 18:53:28,527 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.083999995898921e-05, 1085
[INFO] 2021-07-12 18:53:28,527 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1085
[INFO] 2021-07-12 18:53:28,527 [run_pretraining.py:  558]:	worker_index: 2, step: 1085, cost: 4.506311, mlm loss: 4.506311, speed: 1.087073 steps/s, speed: 8.696582 samples/s, speed: 4452.650107 tokens/s, learning rate: 1.084e-05, loss_scalings: 13421.773438, pp_loss: 7.061636
[INFO] 2021-07-12 18:53:28,528 [run_pretraining.py:  512]:	********exe.run_1085******* 
[INFO] 2021-07-12 18:53:29,433 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:29,434 [run_pretraining.py:  534]:	loss/total_loss, 8.358641624450684, 1086
[INFO] 2021-07-12 18:53:29,434 [run_pretraining.py:  535]:	loss/mlm_loss, 8.358641624450684, 1086
[INFO] 2021-07-12 18:53:29,434 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0849998943740502e-05, 1086
[INFO] 2021-07-12 18:53:29,434 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1086
[INFO] 2021-07-12 18:53:29,434 [run_pretraining.py:  558]:	worker_index: 2, step: 1086, cost: 8.358642, mlm loss: 8.358642, speed: 1.103672 steps/s, speed: 8.829372 samples/s, speed: 4520.638711 tokens/s, learning rate: 1.085e-05, loss_scalings: 13421.773438, pp_loss: 8.078842
[INFO] 2021-07-12 18:53:29,434 [run_pretraining.py:  512]:	********exe.run_1086******* 
[INFO] 2021-07-12 18:53:30,338 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:30,339 [run_pretraining.py:  534]:	loss/total_loss, 8.269472122192383, 1087
[INFO] 2021-07-12 18:53:30,339 [run_pretraining.py:  535]:	loss/mlm_loss, 8.269472122192383, 1087
[INFO] 2021-07-12 18:53:30,339 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0859999747481197e-05, 1087
[INFO] 2021-07-12 18:53:30,339 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1087
[INFO] 2021-07-12 18:53:30,339 [run_pretraining.py:  558]:	worker_index: 2, step: 1087, cost: 8.269472, mlm loss: 8.269472, speed: 1.105678 steps/s, speed: 8.845426 samples/s, speed: 4528.857898 tokens/s, learning rate: 1.086e-05, loss_scalings: 13421.773438, pp_loss: 7.791089
[INFO] 2021-07-12 18:53:30,339 [run_pretraining.py:  512]:	********exe.run_1087******* 
[INFO] 2021-07-12 18:53:31,241 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:31,242 [run_pretraining.py:  534]:	loss/total_loss, 7.608443260192871, 1088
[INFO] 2021-07-12 18:53:31,242 [run_pretraining.py:  535]:	loss/mlm_loss, 7.608443260192871, 1088
[INFO] 2021-07-12 18:53:31,242 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.086999964172719e-05, 1088
[INFO] 2021-07-12 18:53:31,242 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1088
[INFO] 2021-07-12 18:53:31,242 [run_pretraining.py:  558]:	worker_index: 2, step: 1088, cost: 7.608443, mlm loss: 7.608443, speed: 1.108287 steps/s, speed: 8.866295 samples/s, speed: 4539.543126 tokens/s, learning rate: 1.087e-05, loss_scalings: 13421.773438, pp_loss: 7.796372
[INFO] 2021-07-12 18:53:31,242 [run_pretraining.py:  512]:	********exe.run_1088******* 
[INFO] 2021-07-12 18:53:32,161 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:32,166 [run_pretraining.py:  534]:	loss/total_loss, 7.324545860290527, 1089
[INFO] 2021-07-12 18:53:32,172 [run_pretraining.py:  535]:	loss/mlm_loss, 7.324545860290527, 1089
[INFO] 2021-07-12 18:53:32,177 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0879999535973184e-05, 1089
[INFO] 2021-07-12 18:53:32,182 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1089
[INFO] 2021-07-12 18:53:32,187 [run_pretraining.py:  558]:	worker_index: 2, step: 1089, cost: 7.324546, mlm loss: 7.324546, speed: 1.082273 steps/s, speed: 8.658185 samples/s, speed: 4432.990677 tokens/s, learning rate: 1.088e-05, loss_scalings: 13421.773438, pp_loss: 7.664411
[INFO] 2021-07-12 18:53:32,192 [run_pretraining.py:  512]:	********exe.run_1089******* 
[INFO] 2021-07-12 18:53:33,087 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:33,088 [run_pretraining.py:  534]:	loss/total_loss, 7.352004051208496, 1090
[INFO] 2021-07-12 18:53:33,088 [run_pretraining.py:  535]:	loss/mlm_loss, 7.352004051208496, 1090
[INFO] 2021-07-12 18:53:33,088 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0890000339713879e-05, 1090
[INFO] 2021-07-12 18:53:33,088 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1090
[INFO] 2021-07-12 18:53:33,088 [run_pretraining.py:  558]:	worker_index: 2, step: 1090, cost: 7.352004, mlm loss: 7.352004, speed: 1.116952 steps/s, speed: 8.935613 samples/s, speed: 4575.033703 tokens/s, learning rate: 1.089e-05, loss_scalings: 13421.773438, pp_loss: 7.762920
[INFO] 2021-07-12 18:53:33,088 [run_pretraining.py:  512]:	********exe.run_1090******* 
[INFO] 2021-07-12 18:53:33,992 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:33,993 [run_pretraining.py:  534]:	loss/total_loss, 7.844512939453125, 1091
[INFO] 2021-07-12 18:53:33,993 [run_pretraining.py:  535]:	loss/mlm_loss, 7.844512939453125, 1091
[INFO] 2021-07-12 18:53:33,993 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.089999932446517e-05, 1091
[INFO] 2021-07-12 18:53:33,993 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1091
[INFO] 2021-07-12 18:53:33,993 [run_pretraining.py:  558]:	worker_index: 2, step: 1091, cost: 7.844513, mlm loss: 7.844513, speed: 1.105747 steps/s, speed: 8.845978 samples/s, speed: 4529.140863 tokens/s, learning rate: 1.090e-05, loss_scalings: 13421.773438, pp_loss: 7.934817
[INFO] 2021-07-12 18:53:33,993 [run_pretraining.py:  512]:	********exe.run_1091******* 
[INFO] 2021-07-12 18:53:34,890 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:34,890 [run_pretraining.py:  534]:	loss/total_loss, 7.52743673324585, 1092
[INFO] 2021-07-12 18:53:34,890 [run_pretraining.py:  535]:	loss/mlm_loss, 7.52743673324585, 1092
[INFO] 2021-07-12 18:53:34,890 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0909999218711164e-05, 1092
[INFO] 2021-07-12 18:53:34,890 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1092
[INFO] 2021-07-12 18:53:34,890 [run_pretraining.py:  558]:	worker_index: 2, step: 1092, cost: 7.527437, mlm loss: 7.527437, speed: 1.114945 steps/s, speed: 8.919563 samples/s, speed: 4566.816162 tokens/s, learning rate: 1.091e-05, loss_scalings: 13421.773438, pp_loss: 7.957327
[INFO] 2021-07-12 18:53:34,891 [run_pretraining.py:  512]:	********exe.run_1092******* 
[INFO] 2021-07-12 18:53:35,917 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:35,917 [run_pretraining.py:  534]:	loss/total_loss, 8.24414348602295, 1093
[INFO] 2021-07-12 18:53:35,917 [run_pretraining.py:  535]:	loss/mlm_loss, 8.24414348602295, 1093
[INFO] 2021-07-12 18:53:35,917 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0920000022451859e-05, 1093
[INFO] 2021-07-12 18:53:35,917 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1093
[INFO] 2021-07-12 18:53:35,917 [run_pretraining.py:  558]:	worker_index: 2, step: 1093, cost: 8.244143, mlm loss: 8.244143, speed: 0.974363 steps/s, speed: 7.794903 samples/s, speed: 3990.990511 tokens/s, learning rate: 1.092e-05, loss_scalings: 13421.773438, pp_loss: 7.960396
[INFO] 2021-07-12 18:53:35,917 [run_pretraining.py:  512]:	********exe.run_1093******* 
[INFO] 2021-07-12 18:53:36,829 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:36,829 [run_pretraining.py:  534]:	loss/total_loss, 7.999070644378662, 1094
[INFO] 2021-07-12 18:53:36,829 [run_pretraining.py:  535]:	loss/mlm_loss, 7.999070644378662, 1094
[INFO] 2021-07-12 18:53:36,830 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0929999916697852e-05, 1094
[INFO] 2021-07-12 18:53:36,830 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1094
[INFO] 2021-07-12 18:53:36,830 [run_pretraining.py:  558]:	worker_index: 2, step: 1094, cost: 7.999071, mlm loss: 7.999071, speed: 1.096795 steps/s, speed: 8.774362 samples/s, speed: 4492.473268 tokens/s, learning rate: 1.093e-05, loss_scalings: 13421.773438, pp_loss: 7.736825
[INFO] 2021-07-12 18:53:36,830 [run_pretraining.py:  512]:	********exe.run_1094******* 
[INFO] 2021-07-12 18:53:37,731 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:37,731 [run_pretraining.py:  534]:	loss/total_loss, 8.240645408630371, 1095
[INFO] 2021-07-12 18:53:37,731 [run_pretraining.py:  535]:	loss/mlm_loss, 8.240645408630371, 1095
[INFO] 2021-07-12 18:53:37,731 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0939999810943846e-05, 1095
[INFO] 2021-07-12 18:53:37,731 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1095
[INFO] 2021-07-12 18:53:37,731 [run_pretraining.py:  558]:	worker_index: 2, step: 1095, cost: 8.240645, mlm loss: 8.240645, speed: 1.109780 steps/s, speed: 8.878243 samples/s, speed: 4545.660471 tokens/s, learning rate: 1.094e-05, loss_scalings: 13421.773438, pp_loss: 8.111666
[INFO] 2021-07-12 18:53:37,731 [run_pretraining.py:  512]:	********exe.run_1095******* 
[INFO] 2021-07-12 18:53:38,635 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:38,635 [run_pretraining.py:  534]:	loss/total_loss, 7.4311628341674805, 1096
[INFO] 2021-07-12 18:53:38,636 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4311628341674805, 1096
[INFO] 2021-07-12 18:53:38,636 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0949999705189839e-05, 1096
[INFO] 2021-07-12 18:53:38,636 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1096
[INFO] 2021-07-12 18:53:38,636 [run_pretraining.py:  558]:	worker_index: 2, step: 1096, cost: 7.431163, mlm loss: 7.431163, speed: 1.106533 steps/s, speed: 8.852268 samples/s, speed: 4532.361036 tokens/s, learning rate: 1.095e-05, loss_scalings: 13421.773438, pp_loss: 7.932741
[INFO] 2021-07-12 18:53:38,636 [run_pretraining.py:  512]:	********exe.run_1096******* 
[INFO] 2021-07-12 18:53:39,549 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:39,549 [run_pretraining.py:  534]:	loss/total_loss, 8.290767669677734, 1097
[INFO] 2021-07-12 18:53:39,549 [run_pretraining.py:  535]:	loss/mlm_loss, 8.290767669677734, 1097
[INFO] 2021-07-12 18:53:39,549 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0959999599435832e-05, 1097
[INFO] 2021-07-12 18:53:39,549 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1097
[INFO] 2021-07-12 18:53:39,549 [run_pretraining.py:  558]:	worker_index: 2, step: 1097, cost: 8.290768, mlm loss: 8.290768, speed: 1.095178 steps/s, speed: 8.761426 samples/s, speed: 4485.850320 tokens/s, learning rate: 1.096e-05, loss_scalings: 13421.773438, pp_loss: 8.136901
[INFO] 2021-07-12 18:53:39,550 [run_pretraining.py:  512]:	********exe.run_1097******* 
[INFO] 2021-07-12 18:53:40,454 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:40,455 [run_pretraining.py:  534]:	loss/total_loss, 7.94653844833374, 1098
[INFO] 2021-07-12 18:53:40,455 [run_pretraining.py:  535]:	loss/mlm_loss, 7.94653844833374, 1098
[INFO] 2021-07-12 18:53:40,455 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0969999493681826e-05, 1098
[INFO] 2021-07-12 18:53:40,455 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1098
[INFO] 2021-07-12 18:53:40,455 [run_pretraining.py:  558]:	worker_index: 2, step: 1098, cost: 7.946538, mlm loss: 7.946538, speed: 1.105137 steps/s, speed: 8.841098 samples/s, speed: 4526.641963 tokens/s, learning rate: 1.097e-05, loss_scalings: 13421.773438, pp_loss: 8.107970
[INFO] 2021-07-12 18:53:40,455 [run_pretraining.py:  512]:	********exe.run_1098******* 
[INFO] 2021-07-12 18:53:41,359 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:41,359 [run_pretraining.py:  534]:	loss/total_loss, 8.501029968261719, 1099
[INFO] 2021-07-12 18:53:41,359 [run_pretraining.py:  535]:	loss/mlm_loss, 8.501029968261719, 1099
[INFO] 2021-07-12 18:53:41,359 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.098000029742252e-05, 1099
[INFO] 2021-07-12 18:53:41,360 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1099
[INFO] 2021-07-12 18:53:41,360 [run_pretraining.py:  558]:	worker_index: 2, step: 1099, cost: 8.501030, mlm loss: 8.501030, speed: 1.106143 steps/s, speed: 8.849144 samples/s, speed: 4530.761729 tokens/s, learning rate: 1.098e-05, loss_scalings: 13421.773438, pp_loss: 8.146656
[INFO] 2021-07-12 18:53:41,360 [run_pretraining.py:  512]:	********exe.run_1099******* 
[INFO] 2021-07-12 18:53:42,266 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:42,266 [run_pretraining.py:  534]:	loss/total_loss, 7.242893695831299, 1100
[INFO] 2021-07-12 18:53:42,266 [run_pretraining.py:  535]:	loss/mlm_loss, 7.242893695831299, 1100
[INFO] 2021-07-12 18:53:42,266 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0989999282173812e-05, 1100
[INFO] 2021-07-12 18:53:42,266 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1100
[INFO] 2021-07-12 18:53:42,267 [run_pretraining.py:  558]:	worker_index: 2, step: 1100, cost: 7.242894, mlm loss: 7.242894, speed: 1.103378 steps/s, speed: 8.827027 samples/s, speed: 4519.437592 tokens/s, learning rate: 1.099e-05, loss_scalings: 13421.773438, pp_loss: 7.624384
[INFO] 2021-07-12 18:53:42,267 [run_pretraining.py:  512]:	********exe.run_1100******* 
[INFO] 2021-07-12 18:53:43,233 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:43,234 [run_pretraining.py:  534]:	loss/total_loss, 8.17922592163086, 1101
[INFO] 2021-07-12 18:53:43,234 [run_pretraining.py:  535]:	loss/mlm_loss, 8.17922592163086, 1101
[INFO] 2021-07-12 18:53:43,234 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1000000085914508e-05, 1101
[INFO] 2021-07-12 18:53:43,234 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1101
[INFO] 2021-07-12 18:53:43,234 [run_pretraining.py:  558]:	worker_index: 2, step: 1101, cost: 8.179226, mlm loss: 8.179226, speed: 1.034244 steps/s, speed: 8.273950 samples/s, speed: 4236.262233 tokens/s, learning rate: 1.100e-05, loss_scalings: 13421.773438, pp_loss: 8.064015
[INFO] 2021-07-12 18:53:43,234 [run_pretraining.py:  512]:	********exe.run_1101******* 
[INFO] 2021-07-12 18:53:44,300 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:44,301 [run_pretraining.py:  534]:	loss/total_loss, 7.682217121124268, 1102
[INFO] 2021-07-12 18:53:44,301 [run_pretraining.py:  535]:	loss/mlm_loss, 7.682217121124268, 1102
[INFO] 2021-07-12 18:53:44,301 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1009999980160501e-05, 1102
[INFO] 2021-07-12 18:53:44,301 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1102
[INFO] 2021-07-12 18:53:44,301 [run_pretraining.py:  558]:	worker_index: 2, step: 1102, cost: 7.682217, mlm loss: 7.682217, speed: 0.937506 steps/s, speed: 7.500044 samples/s, speed: 3840.022545 tokens/s, learning rate: 1.101e-05, loss_scalings: 13421.773438, pp_loss: 7.872806
[INFO] 2021-07-12 18:53:44,301 [run_pretraining.py:  512]:	********exe.run_1102******* 
[INFO] 2021-07-12 18:53:45,378 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:45,379 [run_pretraining.py:  534]:	loss/total_loss, 8.093603134155273, 1103
[INFO] 2021-07-12 18:53:45,379 [run_pretraining.py:  535]:	loss/mlm_loss, 8.093603134155273, 1103
[INFO] 2021-07-12 18:53:45,379 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1019999874406494e-05, 1103
[INFO] 2021-07-12 18:53:45,379 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1103
[INFO] 2021-07-12 18:53:45,379 [run_pretraining.py:  558]:	worker_index: 2, step: 1103, cost: 8.093603, mlm loss: 8.093603, speed: 0.928297 steps/s, speed: 7.426376 samples/s, speed: 3802.304591 tokens/s, learning rate: 1.102e-05, loss_scalings: 13421.773438, pp_loss: 7.704763
[INFO] 2021-07-12 18:53:45,379 [run_pretraining.py:  512]:	********exe.run_1103******* 
[INFO] 2021-07-12 18:53:46,489 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:46,489 [run_pretraining.py:  534]:	loss/total_loss, 7.3164381980896, 1104
[INFO] 2021-07-12 18:53:46,489 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3164381980896, 1104
[INFO] 2021-07-12 18:53:46,489 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1029999768652488e-05, 1104
[INFO] 2021-07-12 18:53:46,489 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1104
[INFO] 2021-07-12 18:53:46,489 [run_pretraining.py:  558]:	worker_index: 2, step: 1104, cost: 7.316438, mlm loss: 7.316438, speed: 0.901187 steps/s, speed: 7.209500 samples/s, speed: 3691.263860 tokens/s, learning rate: 1.103e-05, loss_scalings: 13421.773438, pp_loss: 7.818449
[INFO] 2021-07-12 18:53:46,489 [run_pretraining.py:  512]:	********exe.run_1104******* 
[INFO] 2021-07-12 18:53:47,584 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:47,584 [run_pretraining.py:  534]:	loss/total_loss, 7.617532730102539, 1105
[INFO] 2021-07-12 18:53:47,584 [run_pretraining.py:  535]:	loss/mlm_loss, 7.617532730102539, 1105
[INFO] 2021-07-12 18:53:47,584 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1039999662898481e-05, 1105
[INFO] 2021-07-12 18:53:47,585 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1105
[INFO] 2021-07-12 18:53:47,585 [run_pretraining.py:  558]:	worker_index: 2, step: 1105, cost: 7.617533, mlm loss: 7.617533, speed: 0.913561 steps/s, speed: 7.308490 samples/s, speed: 3741.946843 tokens/s, learning rate: 1.104e-05, loss_scalings: 13421.773438, pp_loss: 7.889019
[INFO] 2021-07-12 18:53:47,585 [run_pretraining.py:  512]:	********exe.run_1105******* 
[INFO] 2021-07-12 18:53:48,546 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:48,546 [run_pretraining.py:  534]:	loss/total_loss, 7.652822494506836, 1106
[INFO] 2021-07-12 18:53:48,546 [run_pretraining.py:  535]:	loss/mlm_loss, 7.652822494506836, 1106
[INFO] 2021-07-12 18:53:48,546 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1049999557144474e-05, 1106
[INFO] 2021-07-12 18:53:48,546 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1106
[INFO] 2021-07-12 18:53:48,546 [run_pretraining.py:  558]:	worker_index: 2, step: 1106, cost: 7.652822, mlm loss: 7.652822, speed: 1.040299 steps/s, speed: 8.322389 samples/s, speed: 4261.063082 tokens/s, learning rate: 1.105e-05, loss_scalings: 13421.773438, pp_loss: 7.866828
[INFO] 2021-07-12 18:53:48,547 [run_pretraining.py:  512]:	********exe.run_1106******* 
[INFO] 2021-07-12 18:53:49,450 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:49,451 [run_pretraining.py:  534]:	loss/total_loss, 8.453611373901367, 1107
[INFO] 2021-07-12 18:53:49,451 [run_pretraining.py:  535]:	loss/mlm_loss, 8.453611373901367, 1107
[INFO] 2021-07-12 18:53:49,451 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.106000036088517e-05, 1107
[INFO] 2021-07-12 18:53:49,451 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1107
[INFO] 2021-07-12 18:53:49,451 [run_pretraining.py:  558]:	worker_index: 2, step: 1107, cost: 8.453611, mlm loss: 8.453611, speed: 1.105905 steps/s, speed: 8.847238 samples/s, speed: 4529.785726 tokens/s, learning rate: 1.106e-05, loss_scalings: 13421.773438, pp_loss: 7.892209
[INFO] 2021-07-12 18:53:49,451 [run_pretraining.py:  512]:	********exe.run_1107******* 
[INFO] 2021-07-12 18:53:50,357 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:50,357 [run_pretraining.py:  534]:	loss/total_loss, 8.129971504211426, 1108
[INFO] 2021-07-12 18:53:50,357 [run_pretraining.py:  535]:	loss/mlm_loss, 8.129971504211426, 1108
[INFO] 2021-07-12 18:53:50,357 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1069999345636461e-05, 1108
[INFO] 2021-07-12 18:53:50,357 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1108
[INFO] 2021-07-12 18:53:50,357 [run_pretraining.py:  558]:	worker_index: 2, step: 1108, cost: 8.129972, mlm loss: 8.129972, speed: 1.104436 steps/s, speed: 8.835487 samples/s, speed: 4523.769372 tokens/s, learning rate: 1.107e-05, loss_scalings: 13421.773438, pp_loss: 6.992993
[INFO] 2021-07-12 18:53:50,357 [run_pretraining.py:  512]:	********exe.run_1108******* 
[INFO] 2021-07-12 18:53:51,276 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:51,277 [run_pretraining.py:  534]:	loss/total_loss, 8.024964332580566, 1109
[INFO] 2021-07-12 18:53:51,277 [run_pretraining.py:  535]:	loss/mlm_loss, 8.024964332580566, 1109
[INFO] 2021-07-12 18:53:51,277 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1079999239882454e-05, 1109
[INFO] 2021-07-12 18:53:51,277 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1109
[INFO] 2021-07-12 18:53:51,277 [run_pretraining.py:  558]:	worker_index: 2, step: 1109, cost: 8.024964, mlm loss: 8.024964, speed: 1.088033 steps/s, speed: 8.704262 samples/s, speed: 4456.581896 tokens/s, learning rate: 1.108e-05, loss_scalings: 13421.773438, pp_loss: 8.022486
[INFO] 2021-07-12 18:53:51,277 [run_pretraining.py:  512]:	********exe.run_1109******* 
[INFO] 2021-07-12 18:53:52,195 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:52,196 [run_pretraining.py:  534]:	loss/total_loss, 7.902121543884277, 1110
[INFO] 2021-07-12 18:53:52,196 [run_pretraining.py:  535]:	loss/mlm_loss, 7.902121543884277, 1110
[INFO] 2021-07-12 18:53:52,196 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.109000004362315e-05, 1110
[INFO] 2021-07-12 18:53:52,196 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1110
[INFO] 2021-07-12 18:53:52,196 [run_pretraining.py:  558]:	worker_index: 2, step: 1110, cost: 7.902122, mlm loss: 7.902122, speed: 1.088546 steps/s, speed: 8.708368 samples/s, speed: 4458.684622 tokens/s, learning rate: 1.109e-05, loss_scalings: 13421.773438, pp_loss: 7.993096
[INFO] 2021-07-12 18:53:52,196 [run_pretraining.py:  512]:	********exe.run_1110******* 
[INFO] 2021-07-12 18:53:53,100 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:53,100 [run_pretraining.py:  534]:	loss/total_loss, 7.824462413787842, 1111
[INFO] 2021-07-12 18:53:53,100 [run_pretraining.py:  535]:	loss/mlm_loss, 7.824462413787842, 1111
[INFO] 2021-07-12 18:53:53,100 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1099999937869143e-05, 1111
[INFO] 2021-07-12 18:53:53,100 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1111
[INFO] 2021-07-12 18:53:53,101 [run_pretraining.py:  558]:	worker_index: 2, step: 1111, cost: 7.824462, mlm loss: 7.824462, speed: 1.106664 steps/s, speed: 8.853314 samples/s, speed: 4532.896782 tokens/s, learning rate: 1.110e-05, loss_scalings: 13421.773438, pp_loss: 7.848966
[INFO] 2021-07-12 18:53:53,101 [run_pretraining.py:  512]:	********exe.run_1111******* 
[INFO] 2021-07-12 18:53:54,000 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:54,000 [run_pretraining.py:  534]:	loss/total_loss, 8.139558792114258, 1112
[INFO] 2021-07-12 18:53:54,000 [run_pretraining.py:  535]:	loss/mlm_loss, 8.139558792114258, 1112
[INFO] 2021-07-12 18:53:54,000 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1109999832115136e-05, 1112
[INFO] 2021-07-12 18:53:54,001 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1112
[INFO] 2021-07-12 18:53:54,001 [run_pretraining.py:  558]:	worker_index: 2, step: 1112, cost: 8.139559, mlm loss: 8.139559, speed: 1.111787 steps/s, speed: 8.894295 samples/s, speed: 4553.879239 tokens/s, learning rate: 1.111e-05, loss_scalings: 13421.773438, pp_loss: 7.833143
[INFO] 2021-07-12 18:53:54,001 [run_pretraining.py:  512]:	********exe.run_1112******* 
[INFO] 2021-07-12 18:53:54,908 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:54,908 [run_pretraining.py:  534]:	loss/total_loss, 7.947463512420654, 1113
[INFO] 2021-07-12 18:53:54,908 [run_pretraining.py:  535]:	loss/mlm_loss, 7.947463512420654, 1113
[INFO] 2021-07-12 18:53:54,908 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.111999972636113e-05, 1113
[INFO] 2021-07-12 18:53:54,908 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1113
[INFO] 2021-07-12 18:53:54,908 [run_pretraining.py:  558]:	worker_index: 2, step: 1113, cost: 7.947464, mlm loss: 7.947464, speed: 1.102289 steps/s, speed: 8.818316 samples/s, speed: 4514.977641 tokens/s, learning rate: 1.112e-05, loss_scalings: 13421.773438, pp_loss: 7.829708
[INFO] 2021-07-12 18:53:54,908 [run_pretraining.py:  512]:	********exe.run_1113******* 
[INFO] 2021-07-12 18:53:55,869 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:55,870 [run_pretraining.py:  534]:	loss/total_loss, 8.24880313873291, 1114
[INFO] 2021-07-12 18:53:55,870 [run_pretraining.py:  535]:	loss/mlm_loss, 8.24880313873291, 1114
[INFO] 2021-07-12 18:53:55,870 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1129999620607123e-05, 1114
[INFO] 2021-07-12 18:53:55,870 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1114
[INFO] 2021-07-12 18:53:55,870 [run_pretraining.py:  558]:	worker_index: 2, step: 1114, cost: 8.248803, mlm loss: 8.248803, speed: 1.040440 steps/s, speed: 8.323520 samples/s, speed: 4261.642318 tokens/s, learning rate: 1.113e-05, loss_scalings: 13421.773438, pp_loss: 8.048227
[INFO] 2021-07-12 18:53:55,870 [run_pretraining.py:  512]:	********exe.run_1114******* 
[INFO] 2021-07-12 18:53:56,936 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:56,936 [run_pretraining.py:  534]:	loss/total_loss, 7.750344276428223, 1115
[INFO] 2021-07-12 18:53:56,936 [run_pretraining.py:  535]:	loss/mlm_loss, 7.750344276428223, 1115
[INFO] 2021-07-12 18:53:56,936 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1139999514853116e-05, 1115
[INFO] 2021-07-12 18:53:56,936 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1115
[INFO] 2021-07-12 18:53:56,937 [run_pretraining.py:  558]:	worker_index: 2, step: 1115, cost: 7.750344, mlm loss: 7.750344, speed: 0.938271 steps/s, speed: 7.506166 samples/s, speed: 3843.157100 tokens/s, learning rate: 1.114e-05, loss_scalings: 13421.773438, pp_loss: 7.825732
[INFO] 2021-07-12 18:53:56,937 [run_pretraining.py:  512]:	********exe.run_1115******* 
[INFO] 2021-07-12 18:53:58,001 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:58,001 [run_pretraining.py:  534]:	loss/total_loss, 7.841790676116943, 1116
[INFO] 2021-07-12 18:53:58,001 [run_pretraining.py:  535]:	loss/mlm_loss, 7.841790676116943, 1116
[INFO] 2021-07-12 18:53:58,001 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1150000318593811e-05, 1116
[INFO] 2021-07-12 18:53:58,002 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1116
[INFO] 2021-07-12 18:53:58,002 [run_pretraining.py:  558]:	worker_index: 2, step: 1116, cost: 7.841791, mlm loss: 7.841791, speed: 0.939437 steps/s, speed: 7.515495 samples/s, speed: 3847.933609 tokens/s, learning rate: 1.115e-05, loss_scalings: 13421.773438, pp_loss: 7.411861
[INFO] 2021-07-12 18:53:58,002 [run_pretraining.py:  512]:	********exe.run_1116******* 
[INFO] 2021-07-12 18:53:59,069 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:59,070 [run_pretraining.py:  534]:	loss/total_loss, 8.022843360900879, 1117
[INFO] 2021-07-12 18:53:59,070 [run_pretraining.py:  535]:	loss/mlm_loss, 8.022843360900879, 1117
[INFO] 2021-07-12 18:53:59,070 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1159999303345103e-05, 1117
[INFO] 2021-07-12 18:53:59,070 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1117
[INFO] 2021-07-12 18:53:59,070 [run_pretraining.py:  558]:	worker_index: 2, step: 1117, cost: 8.022843, mlm loss: 8.022843, speed: 0.936502 steps/s, speed: 7.492013 samples/s, speed: 3835.910465 tokens/s, learning rate: 1.116e-05, loss_scalings: 13421.773438, pp_loss: 8.182660
[INFO] 2021-07-12 18:53:59,070 [run_pretraining.py:  512]:	********exe.run_1117******* 
[INFO] 2021-07-12 18:54:00,151 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:00,152 [run_pretraining.py:  534]:	loss/total_loss, 7.989846706390381, 1118
[INFO] 2021-07-12 18:54:00,152 [run_pretraining.py:  535]:	loss/mlm_loss, 7.989846706390381, 1118
[INFO] 2021-07-12 18:54:00,152 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1169999197591096e-05, 1118
[INFO] 2021-07-12 18:54:00,152 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1118
[INFO] 2021-07-12 18:54:00,152 [run_pretraining.py:  558]:	worker_index: 2, step: 1118, cost: 7.989847, mlm loss: 7.989847, speed: 0.924452 steps/s, speed: 7.395614 samples/s, speed: 3786.554232 tokens/s, learning rate: 1.117e-05, loss_scalings: 13421.773438, pp_loss: 7.906088
[INFO] 2021-07-12 18:54:00,152 [run_pretraining.py:  512]:	********exe.run_1118******* 
[INFO] 2021-07-12 18:54:01,218 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:01,219 [run_pretraining.py:  534]:	loss/total_loss, 7.641190528869629, 1119
[INFO] 2021-07-12 18:54:01,219 [run_pretraining.py:  535]:	loss/mlm_loss, 7.641190528869629, 1119
[INFO] 2021-07-12 18:54:01,219 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1180000001331791e-05, 1119
[INFO] 2021-07-12 18:54:01,219 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1119
[INFO] 2021-07-12 18:54:01,219 [run_pretraining.py:  558]:	worker_index: 2, step: 1119, cost: 7.641191, mlm loss: 7.641191, speed: 0.937916 steps/s, speed: 7.503325 samples/s, speed: 3841.702147 tokens/s, learning rate: 1.118e-05, loss_scalings: 13421.773438, pp_loss: 7.927081
[INFO] 2021-07-12 18:54:01,219 [run_pretraining.py:  512]:	********exe.run_1119******* 
[INFO] 2021-07-12 18:54:02,280 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:02,280 [run_pretraining.py:  534]:	loss/total_loss, 7.799272537231445, 1120
[INFO] 2021-07-12 18:54:02,281 [run_pretraining.py:  535]:	loss/mlm_loss, 7.799272537231445, 1120
[INFO] 2021-07-12 18:54:02,281 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1189999895577785e-05, 1120
[INFO] 2021-07-12 18:54:02,281 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1120
[INFO] 2021-07-12 18:54:02,281 [run_pretraining.py:  558]:	worker_index: 2, step: 1120, cost: 7.799273, mlm loss: 7.799273, speed: 0.942474 steps/s, speed: 7.539793 samples/s, speed: 3860.374101 tokens/s, learning rate: 1.119e-05, loss_scalings: 13421.773438, pp_loss: 7.624184
[INFO] 2021-07-12 18:54:02,281 [run_pretraining.py:  512]:	********exe.run_1120******* 
[INFO] 2021-07-12 18:54:03,350 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:03,350 [run_pretraining.py:  534]:	loss/total_loss, 8.006491661071777, 1121
[INFO] 2021-07-12 18:54:03,350 [run_pretraining.py:  535]:	loss/mlm_loss, 8.006491661071777, 1121
[INFO] 2021-07-12 18:54:03,350 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1199999789823778e-05, 1121
[INFO] 2021-07-12 18:54:03,351 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1121
[INFO] 2021-07-12 18:54:03,351 [run_pretraining.py:  558]:	worker_index: 2, step: 1121, cost: 8.006492, mlm loss: 8.006492, speed: 0.935224 steps/s, speed: 7.481792 samples/s, speed: 3830.677670 tokens/s, learning rate: 1.120e-05, loss_scalings: 13421.773438, pp_loss: 7.949759
[INFO] 2021-07-12 18:54:03,351 [run_pretraining.py:  512]:	********exe.run_1121******* 
[INFO] 2021-07-12 18:54:04,409 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:04,410 [run_pretraining.py:  534]:	loss/total_loss, 7.511357307434082, 1122
[INFO] 2021-07-12 18:54:04,410 [run_pretraining.py:  535]:	loss/mlm_loss, 7.511357307434082, 1122
[INFO] 2021-07-12 18:54:04,410 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1209999684069771e-05, 1122
[INFO] 2021-07-12 18:54:04,410 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1122
[INFO] 2021-07-12 18:54:04,410 [run_pretraining.py:  558]:	worker_index: 2, step: 1122, cost: 7.511357, mlm loss: 7.511357, speed: 0.944596 steps/s, speed: 7.556772 samples/s, speed: 3869.067155 tokens/s, learning rate: 1.121e-05, loss_scalings: 13421.773438, pp_loss: 7.758067
[INFO] 2021-07-12 18:54:04,410 [run_pretraining.py:  512]:	********exe.run_1122******* 
[INFO] 2021-07-12 18:54:05,469 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:05,469 [run_pretraining.py:  534]:	loss/total_loss, 7.667494773864746, 1123
[INFO] 2021-07-12 18:54:05,469 [run_pretraining.py:  535]:	loss/mlm_loss, 7.667494773864746, 1123
[INFO] 2021-07-12 18:54:05,469 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1219999578315765e-05, 1123
[INFO] 2021-07-12 18:54:05,469 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1123
[INFO] 2021-07-12 18:54:05,469 [run_pretraining.py:  558]:	worker_index: 2, step: 1123, cost: 7.667495, mlm loss: 7.667495, speed: 0.944361 steps/s, speed: 7.554890 samples/s, speed: 3868.103681 tokens/s, learning rate: 1.122e-05, loss_scalings: 13421.773438, pp_loss: 7.880596
[INFO] 2021-07-12 18:54:05,469 [run_pretraining.py:  512]:	********exe.run_1123******* 
[INFO] 2021-07-12 18:54:06,542 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:06,543 [run_pretraining.py:  534]:	loss/total_loss, 7.86718225479126, 1124
[INFO] 2021-07-12 18:54:06,543 [run_pretraining.py:  535]:	loss/mlm_loss, 7.86718225479126, 1124
[INFO] 2021-07-12 18:54:06,543 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1229999472561758e-05, 1124
[INFO] 2021-07-12 18:54:06,543 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1124
[INFO] 2021-07-12 18:54:06,543 [run_pretraining.py:  558]:	worker_index: 2, step: 1124, cost: 7.867182, mlm loss: 7.867182, speed: 0.931809 steps/s, speed: 7.454475 samples/s, speed: 3816.691060 tokens/s, learning rate: 1.123e-05, loss_scalings: 13421.773438, pp_loss: 7.957031
[INFO] 2021-07-12 18:54:06,543 [run_pretraining.py:  512]:	********exe.run_1124******* 
[INFO] 2021-07-12 18:54:07,498 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:07,498 [run_pretraining.py:  534]:	loss/total_loss, 8.128984451293945, 1125
[INFO] 2021-07-12 18:54:07,498 [run_pretraining.py:  535]:	loss/mlm_loss, 8.128984451293945, 1125
[INFO] 2021-07-12 18:54:07,499 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1240000276302453e-05, 1125
[INFO] 2021-07-12 18:54:07,499 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1125
[INFO] 2021-07-12 18:54:07,499 [run_pretraining.py:  558]:	worker_index: 2, step: 1125, cost: 8.128984, mlm loss: 8.128984, speed: 1.047174 steps/s, speed: 8.377391 samples/s, speed: 4289.224025 tokens/s, learning rate: 1.124e-05, loss_scalings: 13421.773438, pp_loss: 7.330666
[INFO] 2021-07-12 18:54:07,499 [run_pretraining.py:  512]:	********exe.run_1125******* 
[INFO] 2021-07-12 18:54:08,418 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:08,419 [run_pretraining.py:  534]:	loss/total_loss, 8.162856101989746, 1126
[INFO] 2021-07-12 18:54:08,419 [run_pretraining.py:  535]:	loss/mlm_loss, 8.162856101989746, 1126
[INFO] 2021-07-12 18:54:08,419 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1249999261053745e-05, 1126
[INFO] 2021-07-12 18:54:08,419 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1126
[INFO] 2021-07-12 18:54:08,419 [run_pretraining.py:  558]:	worker_index: 2, step: 1126, cost: 8.162856, mlm loss: 8.162856, speed: 1.087511 steps/s, speed: 8.700089 samples/s, speed: 4454.445348 tokens/s, learning rate: 1.125e-05, loss_scalings: 13421.773438, pp_loss: 7.805090
[INFO] 2021-07-12 18:54:08,419 [run_pretraining.py:  512]:	********exe.run_1126******* 
[INFO] 2021-07-12 18:54:09,339 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:09,339 [run_pretraining.py:  534]:	loss/total_loss, 7.5586090087890625, 1127
[INFO] 2021-07-12 18:54:09,339 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5586090087890625, 1127
[INFO] 2021-07-12 18:54:09,339 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1259999155299738e-05, 1127
[INFO] 2021-07-12 18:54:09,339 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1127
[INFO] 2021-07-12 18:54:09,340 [run_pretraining.py:  558]:	worker_index: 2, step: 1127, cost: 7.558609, mlm loss: 7.558609, speed: 1.086910 steps/s, speed: 8.695280 samples/s, speed: 4451.983178 tokens/s, learning rate: 1.126e-05, loss_scalings: 13421.773438, pp_loss: 7.686142
[INFO] 2021-07-12 18:54:09,340 [run_pretraining.py:  512]:	********exe.run_1127******* 
[INFO] 2021-07-12 18:54:10,263 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:10,263 [run_pretraining.py:  534]:	loss/total_loss, 7.822279930114746, 1128
[INFO] 2021-07-12 18:54:10,263 [run_pretraining.py:  535]:	loss/mlm_loss, 7.822279930114746, 1128
[INFO] 2021-07-12 18:54:10,264 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1269999959040433e-05, 1128
[INFO] 2021-07-12 18:54:10,264 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1128
[INFO] 2021-07-12 18:54:10,264 [run_pretraining.py:  558]:	worker_index: 2, step: 1128, cost: 7.822280, mlm loss: 7.822280, speed: 1.082793 steps/s, speed: 8.662345 samples/s, speed: 4435.120428 tokens/s, learning rate: 1.127e-05, loss_scalings: 13421.773438, pp_loss: 7.777651
[INFO] 2021-07-12 18:54:10,264 [run_pretraining.py:  512]:	********exe.run_1128******* 
[INFO] 2021-07-12 18:54:11,189 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:11,190 [run_pretraining.py:  534]:	loss/total_loss, 7.383495807647705, 1129
[INFO] 2021-07-12 18:54:11,190 [run_pretraining.py:  535]:	loss/mlm_loss, 7.383495807647705, 1129
[INFO] 2021-07-12 18:54:11,190 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1279999853286427e-05, 1129
[INFO] 2021-07-12 18:54:11,190 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1129
[INFO] 2021-07-12 18:54:11,190 [run_pretraining.py:  558]:	worker_index: 2, step: 1129, cost: 7.383496, mlm loss: 7.383496, speed: 1.079917 steps/s, speed: 8.639332 samples/s, speed: 4423.338097 tokens/s, learning rate: 1.128e-05, loss_scalings: 13421.773438, pp_loss: 7.749151
[INFO] 2021-07-12 18:54:11,190 [run_pretraining.py:  512]:	********exe.run_1129******* 
[INFO] 2021-07-12 18:54:12,101 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:12,101 [run_pretraining.py:  534]:	loss/total_loss, 8.1030855178833, 1130
[INFO] 2021-07-12 18:54:12,101 [run_pretraining.py:  535]:	loss/mlm_loss, 8.1030855178833, 1130
[INFO] 2021-07-12 18:54:12,101 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.128999974753242e-05, 1130
[INFO] 2021-07-12 18:54:12,101 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1130
[INFO] 2021-07-12 18:54:12,101 [run_pretraining.py:  558]:	worker_index: 2, step: 1130, cost: 8.103086, mlm loss: 8.103086, speed: 1.098241 steps/s, speed: 8.785930 samples/s, speed: 4498.396010 tokens/s, learning rate: 1.129e-05, loss_scalings: 13421.773438, pp_loss: 7.958880
[INFO] 2021-07-12 18:54:12,101 [run_pretraining.py:  512]:	********exe.run_1130******* 
[INFO] 2021-07-12 18:54:13,020 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:13,021 [run_pretraining.py:  534]:	loss/total_loss, 7.7093963623046875, 1131
[INFO] 2021-07-12 18:54:13,021 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7093963623046875, 1131
[INFO] 2021-07-12 18:54:13,021 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1299999641778413e-05, 1131
[INFO] 2021-07-12 18:54:13,021 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1131
[INFO] 2021-07-12 18:54:13,021 [run_pretraining.py:  558]:	worker_index: 2, step: 1131, cost: 7.709396, mlm loss: 7.709396, speed: 1.088009 steps/s, speed: 8.704074 samples/s, speed: 4456.485944 tokens/s, learning rate: 1.130e-05, loss_scalings: 13421.773438, pp_loss: 7.965209
[INFO] 2021-07-12 18:54:13,021 [run_pretraining.py:  512]:	********exe.run_1131******* 
[INFO] 2021-07-12 18:54:13,945 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:13,945 [run_pretraining.py:  534]:	loss/total_loss, 4.480338096618652, 1132
[INFO] 2021-07-12 18:54:13,945 [run_pretraining.py:  535]:	loss/mlm_loss, 4.480338096618652, 1132
[INFO] 2021-07-12 18:54:13,945 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1309999536024407e-05, 1132
[INFO] 2021-07-12 18:54:13,945 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1132
[INFO] 2021-07-12 18:54:13,945 [run_pretraining.py:  558]:	worker_index: 2, step: 1132, cost: 4.480338, mlm loss: 4.480338, speed: 1.082614 steps/s, speed: 8.660911 samples/s, speed: 4434.386629 tokens/s, learning rate: 1.131e-05, loss_scalings: 13421.773438, pp_loss: 7.254039
[INFO] 2021-07-12 18:54:13,945 [run_pretraining.py:  512]:	********exe.run_1132******* 
[INFO] 2021-07-12 18:54:14,856 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:14,856 [run_pretraining.py:  534]:	loss/total_loss, 7.698479175567627, 1133
[INFO] 2021-07-12 18:54:14,856 [run_pretraining.py:  535]:	loss/mlm_loss, 7.698479175567627, 1133
[INFO] 2021-07-12 18:54:14,856 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.13199994302704e-05, 1133
[INFO] 2021-07-12 18:54:14,856 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1133
[INFO] 2021-07-12 18:54:14,856 [run_pretraining.py:  558]:	worker_index: 2, step: 1133, cost: 7.698479, mlm loss: 7.698479, speed: 1.098460 steps/s, speed: 8.787678 samples/s, speed: 4499.291365 tokens/s, learning rate: 1.132e-05, loss_scalings: 13421.773438, pp_loss: 7.864267
[INFO] 2021-07-12 18:54:14,856 [run_pretraining.py:  512]:	********exe.run_1133******* 
[INFO] 2021-07-12 18:54:15,772 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:15,772 [run_pretraining.py:  534]:	loss/total_loss, 8.035046577453613, 1134
[INFO] 2021-07-12 18:54:15,772 [run_pretraining.py:  535]:	loss/mlm_loss, 8.035046577453613, 1134
[INFO] 2021-07-12 18:54:15,773 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1330000234011095e-05, 1134
[INFO] 2021-07-12 18:54:15,773 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1134
[INFO] 2021-07-12 18:54:15,773 [run_pretraining.py:  558]:	worker_index: 2, step: 1134, cost: 8.035047, mlm loss: 8.035047, speed: 1.092017 steps/s, speed: 8.736138 samples/s, speed: 4472.902721 tokens/s, learning rate: 1.133e-05, loss_scalings: 13421.773438, pp_loss: 7.862185
[INFO] 2021-07-12 18:54:15,773 [run_pretraining.py:  512]:	********exe.run_1134******* 
[INFO] 2021-07-12 18:54:16,704 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:16,704 [run_pretraining.py:  534]:	loss/total_loss, 7.545615196228027, 1135
[INFO] 2021-07-12 18:54:16,704 [run_pretraining.py:  535]:	loss/mlm_loss, 7.545615196228027, 1135
[INFO] 2021-07-12 18:54:16,705 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1339999218762387e-05, 1135
[INFO] 2021-07-12 18:54:16,705 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1135
[INFO] 2021-07-12 18:54:16,705 [run_pretraining.py:  558]:	worker_index: 2, step: 1135, cost: 7.545615, mlm loss: 7.545615, speed: 1.073695 steps/s, speed: 8.589559 samples/s, speed: 4397.853991 tokens/s, learning rate: 1.134e-05, loss_scalings: 13421.773438, pp_loss: 7.729203
[INFO] 2021-07-12 18:54:16,705 [run_pretraining.py:  512]:	********exe.run_1135******* 
[INFO] 2021-07-12 18:54:17,629 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:17,630 [run_pretraining.py:  534]:	loss/total_loss, 7.733131408691406, 1136
[INFO] 2021-07-12 18:54:17,630 [run_pretraining.py:  535]:	loss/mlm_loss, 7.733131408691406, 1136
[INFO] 2021-07-12 18:54:17,630 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1350000022503082e-05, 1136
[INFO] 2021-07-12 18:54:17,630 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1136
[INFO] 2021-07-12 18:54:17,630 [run_pretraining.py:  558]:	worker_index: 2, step: 1136, cost: 7.733131, mlm loss: 7.733131, speed: 1.081567 steps/s, speed: 8.652534 samples/s, speed: 4430.097451 tokens/s, learning rate: 1.135e-05, loss_scalings: 13421.773438, pp_loss: 7.708776
[INFO] 2021-07-12 18:54:17,630 [run_pretraining.py:  512]:	********exe.run_1136******* 
[INFO] 2021-07-12 18:54:18,549 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:18,550 [run_pretraining.py:  534]:	loss/total_loss, 7.983450412750244, 1137
[INFO] 2021-07-12 18:54:18,550 [run_pretraining.py:  535]:	loss/mlm_loss, 7.983450412750244, 1137
[INFO] 2021-07-12 18:54:18,550 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1359999916749075e-05, 1137
[INFO] 2021-07-12 18:54:18,550 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1137
[INFO] 2021-07-12 18:54:18,550 [run_pretraining.py:  558]:	worker_index: 2, step: 1137, cost: 7.983450, mlm loss: 7.983450, speed: 1.087225 steps/s, speed: 8.697797 samples/s, speed: 4453.272217 tokens/s, learning rate: 1.136e-05, loss_scalings: 13421.773438, pp_loss: 7.639102
[INFO] 2021-07-12 18:54:18,550 [run_pretraining.py:  512]:	********exe.run_1137******* 
[INFO] 2021-07-12 18:54:19,474 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:19,474 [run_pretraining.py:  534]:	loss/total_loss, 7.8972883224487305, 1138
[INFO] 2021-07-12 18:54:19,474 [run_pretraining.py:  535]:	loss/mlm_loss, 7.8972883224487305, 1138
[INFO] 2021-07-12 18:54:19,474 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1369999810995068e-05, 1138
[INFO] 2021-07-12 18:54:19,474 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1138
[INFO] 2021-07-12 18:54:19,474 [run_pretraining.py:  558]:	worker_index: 2, step: 1138, cost: 7.897288, mlm loss: 7.897288, speed: 1.082748 steps/s, speed: 8.661987 samples/s, speed: 4434.937242 tokens/s, learning rate: 1.137e-05, loss_scalings: 13421.773438, pp_loss: 7.886541
[INFO] 2021-07-12 18:54:19,475 [run_pretraining.py:  512]:	********exe.run_1138******* 
[INFO] 2021-07-12 18:54:20,390 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:20,390 [run_pretraining.py:  534]:	loss/total_loss, 8.015783309936523, 1139
[INFO] 2021-07-12 18:54:20,390 [run_pretraining.py:  535]:	loss/mlm_loss, 8.015783309936523, 1139
[INFO] 2021-07-12 18:54:20,390 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1379999705241062e-05, 1139
[INFO] 2021-07-12 18:54:20,390 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1139
[INFO] 2021-07-12 18:54:20,390 [run_pretraining.py:  558]:	worker_index: 2, step: 1139, cost: 8.015783, mlm loss: 8.015783, speed: 1.092488 steps/s, speed: 8.739906 samples/s, speed: 4474.832052 tokens/s, learning rate: 1.138e-05, loss_scalings: 13421.773438, pp_loss: 8.030136
[INFO] 2021-07-12 18:54:20,390 [run_pretraining.py:  512]:	********exe.run_1139******* 
[INFO] 2021-07-12 18:54:21,311 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:21,311 [run_pretraining.py:  534]:	loss/total_loss, 8.119808197021484, 1140
[INFO] 2021-07-12 18:54:21,311 [run_pretraining.py:  535]:	loss/mlm_loss, 8.119808197021484, 1140
[INFO] 2021-07-12 18:54:21,311 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1389999599487055e-05, 1140
[INFO] 2021-07-12 18:54:21,312 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1140
[INFO] 2021-07-12 18:54:21,312 [run_pretraining.py:  558]:	worker_index: 2, step: 1140, cost: 8.119808, mlm loss: 8.119808, speed: 1.086298 steps/s, speed: 8.690381 samples/s, speed: 4449.475327 tokens/s, learning rate: 1.139e-05, loss_scalings: 13421.773438, pp_loss: 8.102327
[INFO] 2021-07-12 18:54:21,312 [run_pretraining.py:  512]:	********exe.run_1140******* 
[INFO] 2021-07-12 18:54:22,231 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:22,232 [run_pretraining.py:  534]:	loss/total_loss, 8.269283294677734, 1141
[INFO] 2021-07-12 18:54:22,232 [run_pretraining.py:  535]:	loss/mlm_loss, 8.269283294677734, 1141
[INFO] 2021-07-12 18:54:22,232 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1399999493733048e-05, 1141
[INFO] 2021-07-12 18:54:22,232 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1141
[INFO] 2021-07-12 18:54:22,232 [run_pretraining.py:  558]:	worker_index: 2, step: 1141, cost: 8.269283, mlm loss: 8.269283, speed: 1.087239 steps/s, speed: 8.697915 samples/s, speed: 4453.332244 tokens/s, learning rate: 1.140e-05, loss_scalings: 13421.773438, pp_loss: 7.910376
[INFO] 2021-07-12 18:54:22,232 [run_pretraining.py:  512]:	********exe.run_1141******* 
[INFO] 2021-07-12 18:54:23,151 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:23,152 [run_pretraining.py:  534]:	loss/total_loss, 7.612123489379883, 1142
[INFO] 2021-07-12 18:54:23,152 [run_pretraining.py:  535]:	loss/mlm_loss, 7.612123489379883, 1142
[INFO] 2021-07-12 18:54:23,152 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1410000297473744e-05, 1142
[INFO] 2021-07-12 18:54:23,152 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1142
[INFO] 2021-07-12 18:54:23,152 [run_pretraining.py:  558]:	worker_index: 2, step: 1142, cost: 7.612123, mlm loss: 7.612123, speed: 1.087667 steps/s, speed: 8.701336 samples/s, speed: 4455.084134 tokens/s, learning rate: 1.141e-05, loss_scalings: 13421.773438, pp_loss: 7.606787
[INFO] 2021-07-12 18:54:23,152 [run_pretraining.py:  512]:	********exe.run_1142******* 
[INFO] 2021-07-12 18:54:24,090 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:24,090 [run_pretraining.py:  534]:	loss/total_loss, 7.684983730316162, 1143
[INFO] 2021-07-12 18:54:24,090 [run_pretraining.py:  535]:	loss/mlm_loss, 7.684983730316162, 1143
[INFO] 2021-07-12 18:54:24,090 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1420000191719737e-05, 1143
[INFO] 2021-07-12 18:54:24,090 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1143
[INFO] 2021-07-12 18:54:24,090 [run_pretraining.py:  558]:	worker_index: 2, step: 1143, cost: 7.684984, mlm loss: 7.684984, speed: 1.066278 steps/s, speed: 8.530220 samples/s, speed: 4367.472804 tokens/s, learning rate: 1.142e-05, loss_scalings: 13421.773438, pp_loss: 7.735586
[INFO] 2021-07-12 18:54:24,090 [run_pretraining.py:  512]:	********exe.run_1143******* 
[INFO] 2021-07-12 18:54:25,005 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:25,006 [run_pretraining.py:  534]:	loss/total_loss, 7.439622402191162, 1144
[INFO] 2021-07-12 18:54:25,006 [run_pretraining.py:  535]:	loss/mlm_loss, 7.439622402191162, 1144
[INFO] 2021-07-12 18:54:25,006 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1429999176471028e-05, 1144
[INFO] 2021-07-12 18:54:25,006 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1144
[INFO] 2021-07-12 18:54:25,006 [run_pretraining.py:  558]:	worker_index: 2, step: 1144, cost: 7.439622, mlm loss: 7.439622, speed: 1.092499 steps/s, speed: 8.739995 samples/s, speed: 4474.877509 tokens/s, learning rate: 1.143e-05, loss_scalings: 13421.773438, pp_loss: 7.577631
[INFO] 2021-07-12 18:54:25,006 [run_pretraining.py:  512]:	********exe.run_1144******* 
[INFO] 2021-07-12 18:54:25,924 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:25,925 [run_pretraining.py:  534]:	loss/total_loss, 8.047119140625, 1145
[INFO] 2021-07-12 18:54:25,925 [run_pretraining.py:  535]:	loss/mlm_loss, 8.047119140625, 1145
[INFO] 2021-07-12 18:54:25,925 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1439999980211724e-05, 1145
[INFO] 2021-07-12 18:54:25,925 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1145
[INFO] 2021-07-12 18:54:25,925 [run_pretraining.py:  558]:	worker_index: 2, step: 1145, cost: 8.047119, mlm loss: 8.047119, speed: 1.088842 steps/s, speed: 8.710735 samples/s, speed: 4459.896498 tokens/s, learning rate: 1.144e-05, loss_scalings: 13421.773438, pp_loss: 7.950174
[INFO] 2021-07-12 18:54:25,925 [run_pretraining.py:  512]:	********exe.run_1145******* 
[INFO] 2021-07-12 18:54:26,840 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:26,841 [run_pretraining.py:  534]:	loss/total_loss, 7.575406074523926, 1146
[INFO] 2021-07-12 18:54:26,841 [run_pretraining.py:  535]:	loss/mlm_loss, 7.575406074523926, 1146
[INFO] 2021-07-12 18:54:26,841 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1449999874457717e-05, 1146
[INFO] 2021-07-12 18:54:26,841 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1146
[INFO] 2021-07-12 18:54:26,841 [run_pretraining.py:  558]:	worker_index: 2, step: 1146, cost: 7.575406, mlm loss: 7.575406, speed: 1.092869 steps/s, speed: 8.742949 samples/s, speed: 4476.389778 tokens/s, learning rate: 1.145e-05, loss_scalings: 13421.773438, pp_loss: 7.493739
[INFO] 2021-07-12 18:54:26,841 [run_pretraining.py:  512]:	********exe.run_1146******* 
[INFO] 2021-07-12 18:54:27,774 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:27,774 [run_pretraining.py:  534]:	loss/total_loss, 4.635283946990967, 1147
[INFO] 2021-07-12 18:54:27,774 [run_pretraining.py:  535]:	loss/mlm_loss, 4.635283946990967, 1147
[INFO] 2021-07-12 18:54:27,774 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.145999976870371e-05, 1147
[INFO] 2021-07-12 18:54:27,775 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1147
[INFO] 2021-07-12 18:54:27,775 [run_pretraining.py:  558]:	worker_index: 2, step: 1147, cost: 4.635284, mlm loss: 4.635284, speed: 1.071734 steps/s, speed: 8.573872 samples/s, speed: 4389.822582 tokens/s, learning rate: 1.146e-05, loss_scalings: 13421.773438, pp_loss: 7.109047
[INFO] 2021-07-12 18:54:27,775 [run_pretraining.py:  512]:	********exe.run_1147******* 
[INFO] 2021-07-12 18:54:28,676 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:28,676 [run_pretraining.py:  534]:	loss/total_loss, 7.989983081817627, 1148
[INFO] 2021-07-12 18:54:28,677 [run_pretraining.py:  535]:	loss/mlm_loss, 7.989983081817627, 1148
[INFO] 2021-07-12 18:54:28,677 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1469999662949704e-05, 1148
[INFO] 2021-07-12 18:54:28,677 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1148
[INFO] 2021-07-12 18:54:28,677 [run_pretraining.py:  558]:	worker_index: 2, step: 1148, cost: 7.989983, mlm loss: 7.989983, speed: 1.109113 steps/s, speed: 8.872904 samples/s, speed: 4542.927070 tokens/s, learning rate: 1.147e-05, loss_scalings: 13421.773438, pp_loss: 8.082417
[INFO] 2021-07-12 18:54:28,677 [run_pretraining.py:  512]:	********exe.run_1148******* 
[INFO] 2021-07-12 18:54:29,582 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:29,582 [run_pretraining.py:  534]:	loss/total_loss, 7.725800037384033, 1149
[INFO] 2021-07-12 18:54:29,582 [run_pretraining.py:  535]:	loss/mlm_loss, 7.725800037384033, 1149
[INFO] 2021-07-12 18:54:29,582 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1479999557195697e-05, 1149
[INFO] 2021-07-12 18:54:29,582 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1149
[INFO] 2021-07-12 18:54:29,583 [run_pretraining.py:  558]:	worker_index: 2, step: 1149, cost: 7.725800, mlm loss: 7.725800, speed: 1.104855 steps/s, speed: 8.838836 samples/s, speed: 4525.484145 tokens/s, learning rate: 1.148e-05, loss_scalings: 13421.773438, pp_loss: 7.916660
[INFO] 2021-07-12 18:54:29,583 [run_pretraining.py:  512]:	********exe.run_1149******* 
[INFO] 2021-07-12 18:54:30,503 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:30,503 [run_pretraining.py:  534]:	loss/total_loss, 7.653217792510986, 1150
[INFO] 2021-07-12 18:54:30,504 [run_pretraining.py:  535]:	loss/mlm_loss, 7.653217792510986, 1150
[INFO] 2021-07-12 18:54:30,504 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.148999945144169e-05, 1150
[INFO] 2021-07-12 18:54:30,504 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1150
[INFO] 2021-07-12 18:54:30,504 [run_pretraining.py:  558]:	worker_index: 2, step: 1150, cost: 7.653218, mlm loss: 7.653218, speed: 1.086245 steps/s, speed: 8.689958 samples/s, speed: 4449.258689 tokens/s, learning rate: 1.149e-05, loss_scalings: 13421.773438, pp_loss: 7.675400
[INFO] 2021-07-12 18:54:30,504 [run_pretraining.py:  512]:	********exe.run_1150******* 
[INFO] 2021-07-12 18:54:31,415 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:31,415 [run_pretraining.py:  534]:	loss/total_loss, 8.026089668273926, 1151
[INFO] 2021-07-12 18:54:31,415 [run_pretraining.py:  535]:	loss/mlm_loss, 8.026089668273926, 1151
[INFO] 2021-07-12 18:54:31,415 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1500000255182385e-05, 1151
[INFO] 2021-07-12 18:54:31,415 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1151
[INFO] 2021-07-12 18:54:31,415 [run_pretraining.py:  558]:	worker_index: 2, step: 1151, cost: 8.026090, mlm loss: 8.026090, speed: 1.097653 steps/s, speed: 8.781223 samples/s, speed: 4495.986212 tokens/s, learning rate: 1.150e-05, loss_scalings: 13421.773438, pp_loss: 7.980576
[INFO] 2021-07-12 18:54:31,415 [run_pretraining.py:  512]:	********exe.run_1151******* 
[INFO] 2021-07-12 18:54:32,329 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:32,329 [run_pretraining.py:  534]:	loss/total_loss, 7.924415588378906, 1152
[INFO] 2021-07-12 18:54:32,329 [run_pretraining.py:  535]:	loss/mlm_loss, 7.924415588378906, 1152
[INFO] 2021-07-12 18:54:32,329 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1509999239933677e-05, 1152
[INFO] 2021-07-12 18:54:32,329 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1152
[INFO] 2021-07-12 18:54:32,329 [run_pretraining.py:  558]:	worker_index: 2, step: 1152, cost: 7.924416, mlm loss: 7.924416, speed: 1.094844 steps/s, speed: 8.758755 samples/s, speed: 4484.482654 tokens/s, learning rate: 1.151e-05, loss_scalings: 13421.773438, pp_loss: 7.795728
[INFO] 2021-07-12 18:54:32,329 [run_pretraining.py:  512]:	********exe.run_1152******* 
[INFO] 2021-07-12 18:54:33,241 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:33,241 [run_pretraining.py:  534]:	loss/total_loss, 7.659534454345703, 1153
[INFO] 2021-07-12 18:54:33,242 [run_pretraining.py:  535]:	loss/mlm_loss, 7.659534454345703, 1153
[INFO] 2021-07-12 18:54:33,242 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.151999913417967e-05, 1153
[INFO] 2021-07-12 18:54:33,242 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1153
[INFO] 2021-07-12 18:54:33,242 [run_pretraining.py:  558]:	worker_index: 2, step: 1153, cost: 7.659534, mlm loss: 7.659534, speed: 1.096663 steps/s, speed: 8.773302 samples/s, speed: 4491.930592 tokens/s, learning rate: 1.152e-05, loss_scalings: 13421.773438, pp_loss: 7.774756
[INFO] 2021-07-12 18:54:33,242 [run_pretraining.py:  512]:	********exe.run_1153******* 
[INFO] 2021-07-12 18:54:34,161 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:34,162 [run_pretraining.py:  534]:	loss/total_loss, 7.637149810791016, 1154
[INFO] 2021-07-12 18:54:34,162 [run_pretraining.py:  535]:	loss/mlm_loss, 7.637149810791016, 1154
[INFO] 2021-07-12 18:54:34,162 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1529999937920365e-05, 1154
[INFO] 2021-07-12 18:54:34,162 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1154
[INFO] 2021-07-12 18:54:34,162 [run_pretraining.py:  558]:	worker_index: 2, step: 1154, cost: 7.637150, mlm loss: 7.637150, speed: 1.087359 steps/s, speed: 8.698873 samples/s, speed: 4453.822911 tokens/s, learning rate: 1.153e-05, loss_scalings: 13421.773438, pp_loss: 7.980196
[INFO] 2021-07-12 18:54:34,162 [run_pretraining.py:  512]:	********exe.run_1154******* 
[INFO] 2021-07-12 18:54:35,069 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:35,070 [run_pretraining.py:  534]:	loss/total_loss, 7.96957540512085, 1155
[INFO] 2021-07-12 18:54:35,070 [run_pretraining.py:  535]:	loss/mlm_loss, 7.96957540512085, 1155
[INFO] 2021-07-12 18:54:35,070 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1539999832166359e-05, 1155
[INFO] 2021-07-12 18:54:35,070 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1155
[INFO] 2021-07-12 18:54:35,070 [run_pretraining.py:  558]:	worker_index: 2, step: 1155, cost: 7.969575, mlm loss: 7.969575, speed: 1.102316 steps/s, speed: 8.818524 samples/s, speed: 4515.084435 tokens/s, learning rate: 1.154e-05, loss_scalings: 13421.773438, pp_loss: 7.866711
[INFO] 2021-07-12 18:54:35,070 [run_pretraining.py:  512]:	********exe.run_1155******* 
[INFO] 2021-07-12 18:54:35,981 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:35,982 [run_pretraining.py:  534]:	loss/total_loss, 7.807248592376709, 1156
[INFO] 2021-07-12 18:54:35,982 [run_pretraining.py:  535]:	loss/mlm_loss, 7.807248592376709, 1156
[INFO] 2021-07-12 18:54:35,982 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1549999726412352e-05, 1156
[INFO] 2021-07-12 18:54:35,982 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1156
[INFO] 2021-07-12 18:54:35,982 [run_pretraining.py:  558]:	worker_index: 2, step: 1156, cost: 7.807249, mlm loss: 7.807249, speed: 1.097093 steps/s, speed: 8.776742 samples/s, speed: 4493.691830 tokens/s, learning rate: 1.155e-05, loss_scalings: 13421.773438, pp_loss: 7.880546
[INFO] 2021-07-12 18:54:35,982 [run_pretraining.py:  512]:	********exe.run_1156******* 
[INFO] 2021-07-12 18:54:36,891 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:36,891 [run_pretraining.py:  534]:	loss/total_loss, 7.83531379699707, 1157
[INFO] 2021-07-12 18:54:36,891 [run_pretraining.py:  535]:	loss/mlm_loss, 7.83531379699707, 1157
[INFO] 2021-07-12 18:54:36,892 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1559999620658346e-05, 1157
[INFO] 2021-07-12 18:54:36,892 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1157
[INFO] 2021-07-12 18:54:36,892 [run_pretraining.py:  558]:	worker_index: 2, step: 1157, cost: 7.835314, mlm loss: 7.835314, speed: 1.099984 steps/s, speed: 8.799875 samples/s, speed: 4505.535763 tokens/s, learning rate: 1.156e-05, loss_scalings: 13421.773438, pp_loss: 7.143364
[INFO] 2021-07-12 18:54:36,892 [run_pretraining.py:  512]:	********exe.run_1157******* 
[INFO] 2021-07-12 18:54:37,806 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:37,807 [run_pretraining.py:  534]:	loss/total_loss, 7.8452067375183105, 1158
[INFO] 2021-07-12 18:54:37,807 [run_pretraining.py:  535]:	loss/mlm_loss, 7.8452067375183105, 1158
[INFO] 2021-07-12 18:54:37,807 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1569999514904339e-05, 1158
[INFO] 2021-07-12 18:54:37,807 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1158
[INFO] 2021-07-12 18:54:37,807 [run_pretraining.py:  558]:	worker_index: 2, step: 1158, cost: 7.845207, mlm loss: 7.845207, speed: 1.093094 steps/s, speed: 8.744753 samples/s, speed: 4477.313733 tokens/s, learning rate: 1.157e-05, loss_scalings: 13421.773438, pp_loss: 7.966510
[INFO] 2021-07-12 18:54:37,807 [run_pretraining.py:  512]:	********exe.run_1158******* 
[INFO] 2021-07-12 18:54:38,718 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:38,719 [run_pretraining.py:  534]:	loss/total_loss, 8.007970809936523, 1159
[INFO] 2021-07-12 18:54:38,719 [run_pretraining.py:  535]:	loss/mlm_loss, 8.007970809936523, 1159
[INFO] 2021-07-12 18:54:38,719 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1579999409150332e-05, 1159
[INFO] 2021-07-12 18:54:38,719 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1159
[INFO] 2021-07-12 18:54:38,719 [run_pretraining.py:  558]:	worker_index: 2, step: 1159, cost: 8.007971, mlm loss: 8.007971, speed: 1.097145 steps/s, speed: 8.777157 samples/s, speed: 4493.904588 tokens/s, learning rate: 1.158e-05, loss_scalings: 13421.773438, pp_loss: 8.039854
[INFO] 2021-07-12 18:54:38,719 [run_pretraining.py:  512]:	********exe.run_1159******* 
[INFO] 2021-07-12 18:54:39,636 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:39,637 [run_pretraining.py:  534]:	loss/total_loss, 7.564580917358398, 1160
[INFO] 2021-07-12 18:54:39,637 [run_pretraining.py:  535]:	loss/mlm_loss, 7.564580917358398, 1160
[INFO] 2021-07-12 18:54:39,637 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1590000212891027e-05, 1160
[INFO] 2021-07-12 18:54:39,637 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1160
[INFO] 2021-07-12 18:54:39,637 [run_pretraining.py:  558]:	worker_index: 2, step: 1160, cost: 7.564581, mlm loss: 7.564581, speed: 1.090431 steps/s, speed: 8.723451 samples/s, speed: 4466.406978 tokens/s, learning rate: 1.159e-05, loss_scalings: 13421.773438, pp_loss: 7.835358
[INFO] 2021-07-12 18:54:39,637 [run_pretraining.py:  512]:	********exe.run_1160******* 
[INFO] 2021-07-12 18:54:40,545 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:40,545 [run_pretraining.py:  534]:	loss/total_loss, 7.816554069519043, 1161
[INFO] 2021-07-12 18:54:40,545 [run_pretraining.py:  535]:	loss/mlm_loss, 7.816554069519043, 1161
[INFO] 2021-07-12 18:54:40,545 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1599999197642319e-05, 1161
[INFO] 2021-07-12 18:54:40,545 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1161
[INFO] 2021-07-12 18:54:40,545 [run_pretraining.py:  558]:	worker_index: 2, step: 1161, cost: 7.816554, mlm loss: 7.816554, speed: 1.101449 steps/s, speed: 8.811593 samples/s, speed: 4511.535671 tokens/s, learning rate: 1.160e-05, loss_scalings: 13421.773438, pp_loss: 7.739917
[INFO] 2021-07-12 18:54:40,545 [run_pretraining.py:  512]:	********exe.run_1161******* 
[INFO] 2021-07-12 18:54:41,454 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:41,455 [run_pretraining.py:  534]:	loss/total_loss, 7.945454120635986, 1162
[INFO] 2021-07-12 18:54:41,455 [run_pretraining.py:  535]:	loss/mlm_loss, 7.945454120635986, 1162
[INFO] 2021-07-12 18:54:41,455 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1609999091888312e-05, 1162
[INFO] 2021-07-12 18:54:41,455 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1162
[INFO] 2021-07-12 18:54:41,455 [run_pretraining.py:  558]:	worker_index: 2, step: 1162, cost: 7.945454, mlm loss: 7.945454, speed: 1.100228 steps/s, speed: 8.801820 samples/s, speed: 4506.532078 tokens/s, learning rate: 1.161e-05, loss_scalings: 13421.773438, pp_loss: 7.589110
[INFO] 2021-07-12 18:54:41,455 [run_pretraining.py:  512]:	********exe.run_1162******* 
[INFO] 2021-07-12 18:54:42,371 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:42,371 [run_pretraining.py:  534]:	loss/total_loss, 7.842861175537109, 1163
[INFO] 2021-07-12 18:54:42,371 [run_pretraining.py:  535]:	loss/mlm_loss, 7.842861175537109, 1163
[INFO] 2021-07-12 18:54:42,371 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1619999895629007e-05, 1163
[INFO] 2021-07-12 18:54:42,371 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1163
[INFO] 2021-07-12 18:54:42,371 [run_pretraining.py:  558]:	worker_index: 2, step: 1163, cost: 7.842861, mlm loss: 7.842861, speed: 1.091756 steps/s, speed: 8.734046 samples/s, speed: 4471.831589 tokens/s, learning rate: 1.162e-05, loss_scalings: 13421.773438, pp_loss: 7.905804
[INFO] 2021-07-12 18:54:42,372 [run_pretraining.py:  512]:	********exe.run_1163******* 
[INFO] 2021-07-12 18:54:43,285 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:43,285 [run_pretraining.py:  534]:	loss/total_loss, 7.822686195373535, 1164
[INFO] 2021-07-12 18:54:43,285 [run_pretraining.py:  535]:	loss/mlm_loss, 7.822686195373535, 1164
[INFO] 2021-07-12 18:54:43,286 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1629999789875e-05, 1164
[INFO] 2021-07-12 18:54:43,286 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1164
[INFO] 2021-07-12 18:54:43,286 [run_pretraining.py:  558]:	worker_index: 2, step: 1164, cost: 7.822686, mlm loss: 7.822686, speed: 1.094482 steps/s, speed: 8.755857 samples/s, speed: 4482.998837 tokens/s, learning rate: 1.163e-05, loss_scalings: 13421.773438, pp_loss: 7.949331
[INFO] 2021-07-12 18:54:43,286 [run_pretraining.py:  512]:	********exe.run_1164******* 
[INFO] 2021-07-12 18:54:44,203 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:44,204 [run_pretraining.py:  534]:	loss/total_loss, 8.078837394714355, 1165
[INFO] 2021-07-12 18:54:44,204 [run_pretraining.py:  535]:	loss/mlm_loss, 8.078837394714355, 1165
[INFO] 2021-07-12 18:54:44,204 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1639999684120994e-05, 1165
[INFO] 2021-07-12 18:54:44,204 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1165
[INFO] 2021-07-12 18:54:44,204 [run_pretraining.py:  558]:	worker_index: 2, step: 1165, cost: 8.078837, mlm loss: 8.078837, speed: 1.089597 steps/s, speed: 8.716775 samples/s, speed: 4462.988782 tokens/s, learning rate: 1.164e-05, loss_scalings: 13421.773438, pp_loss: 7.823890
[INFO] 2021-07-12 18:54:44,204 [run_pretraining.py:  512]:	********exe.run_1165******* 
[INFO] 2021-07-12 18:54:45,119 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:45,119 [run_pretraining.py:  534]:	loss/total_loss, 7.7764739990234375, 1166
[INFO] 2021-07-12 18:54:45,120 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7764739990234375, 1166
[INFO] 2021-07-12 18:54:45,120 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1649999578366987e-05, 1166
[INFO] 2021-07-12 18:54:45,120 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1166
[INFO] 2021-07-12 18:54:45,120 [run_pretraining.py:  558]:	worker_index: 2, step: 1166, cost: 7.776474, mlm loss: 7.776474, speed: 1.092776 steps/s, speed: 8.742211 samples/s, speed: 4476.011907 tokens/s, learning rate: 1.165e-05, loss_scalings: 13421.773438, pp_loss: 7.752189
[INFO] 2021-07-12 18:54:45,120 [run_pretraining.py:  512]:	********exe.run_1166******* 
[INFO] 2021-07-12 18:54:46,033 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:46,033 [run_pretraining.py:  534]:	loss/total_loss, 8.24579906463623, 1167
[INFO] 2021-07-12 18:54:46,033 [run_pretraining.py:  535]:	loss/mlm_loss, 8.24579906463623, 1167
[INFO] 2021-07-12 18:54:46,033 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.165999947261298e-05, 1167
[INFO] 2021-07-12 18:54:46,033 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1167
[INFO] 2021-07-12 18:54:46,033 [run_pretraining.py:  558]:	worker_index: 2, step: 1167, cost: 8.245799, mlm loss: 8.245799, speed: 1.095272 steps/s, speed: 8.762175 samples/s, speed: 4486.233369 tokens/s, learning rate: 1.166e-05, loss_scalings: 13421.773438, pp_loss: 7.887629
[INFO] 2021-07-12 18:54:46,034 [run_pretraining.py:  512]:	********exe.run_1167******* 
[INFO] 2021-07-12 18:54:46,941 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:46,941 [run_pretraining.py:  534]:	loss/total_loss, 8.335003852844238, 1168
[INFO] 2021-07-12 18:54:46,941 [run_pretraining.py:  535]:	loss/mlm_loss, 8.335003852844238, 1168
[INFO] 2021-07-12 18:54:46,941 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1669999366858974e-05, 1168
[INFO] 2021-07-12 18:54:46,942 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1168
[INFO] 2021-07-12 18:54:46,942 [run_pretraining.py:  558]:	worker_index: 2, step: 1168, cost: 8.335004, mlm loss: 8.335004, speed: 1.101877 steps/s, speed: 8.815014 samples/s, speed: 4513.287420 tokens/s, learning rate: 1.167e-05, loss_scalings: 13421.773438, pp_loss: 7.865976
[INFO] 2021-07-12 18:54:46,942 [run_pretraining.py:  512]:	********exe.run_1168******* 
[INFO] 2021-07-12 18:54:47,858 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:47,859 [run_pretraining.py:  534]:	loss/total_loss, 7.967175483703613, 1169
[INFO] 2021-07-12 18:54:47,859 [run_pretraining.py:  535]:	loss/mlm_loss, 7.967175483703613, 1169
[INFO] 2021-07-12 18:54:47,859 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.168000017059967e-05, 1169
[INFO] 2021-07-12 18:54:47,859 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1169
[INFO] 2021-07-12 18:54:47,859 [run_pretraining.py:  558]:	worker_index: 2, step: 1169, cost: 7.967175, mlm loss: 7.967175, speed: 1.090316 steps/s, speed: 8.722528 samples/s, speed: 4465.934431 tokens/s, learning rate: 1.168e-05, loss_scalings: 13421.773438, pp_loss: 8.020603
[INFO] 2021-07-12 18:54:47,859 [run_pretraining.py:  512]:	********exe.run_1169******* 
[INFO] 2021-07-12 18:54:48,776 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:48,776 [run_pretraining.py:  534]:	loss/total_loss, 7.734013557434082, 1170
[INFO] 2021-07-12 18:54:48,776 [run_pretraining.py:  535]:	loss/mlm_loss, 7.734013557434082, 1170
[INFO] 2021-07-12 18:54:48,777 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.168999915535096e-05, 1170
[INFO] 2021-07-12 18:54:48,777 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1170
[INFO] 2021-07-12 18:54:48,777 [run_pretraining.py:  558]:	worker_index: 2, step: 1170, cost: 7.734014, mlm loss: 7.734014, speed: 1.090840 steps/s, speed: 8.726723 samples/s, speed: 4468.082017 tokens/s, learning rate: 1.169e-05, loss_scalings: 13421.773438, pp_loss: 7.775454
[INFO] 2021-07-12 18:54:48,777 [run_pretraining.py:  512]:	********exe.run_1170******* 
[INFO] 2021-07-12 18:54:49,683 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:49,684 [run_pretraining.py:  534]:	loss/total_loss, 7.813621997833252, 1171
[INFO] 2021-07-12 18:54:49,684 [run_pretraining.py:  535]:	loss/mlm_loss, 7.813621997833252, 1171
[INFO] 2021-07-12 18:54:49,684 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1699999959091656e-05, 1171
[INFO] 2021-07-12 18:54:49,684 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1171
[INFO] 2021-07-12 18:54:49,684 [run_pretraining.py:  558]:	worker_index: 2, step: 1171, cost: 7.813622, mlm loss: 7.813622, speed: 1.102555 steps/s, speed: 8.820437 samples/s, speed: 4516.063609 tokens/s, learning rate: 1.170e-05, loss_scalings: 13421.773438, pp_loss: 7.908508
[INFO] 2021-07-12 18:54:49,684 [run_pretraining.py:  512]:	********exe.run_1171******* 
[INFO] 2021-07-12 18:54:50,597 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:50,597 [run_pretraining.py:  534]:	loss/total_loss, 8.294248580932617, 1172
[INFO] 2021-07-12 18:54:50,598 [run_pretraining.py:  535]:	loss/mlm_loss, 8.294248580932617, 1172
[INFO] 2021-07-12 18:54:50,598 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.170999985333765e-05, 1172
[INFO] 2021-07-12 18:54:50,598 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1172
[INFO] 2021-07-12 18:54:50,598 [run_pretraining.py:  558]:	worker_index: 2, step: 1172, cost: 8.294249, mlm loss: 8.294249, speed: 1.095381 steps/s, speed: 8.763049 samples/s, speed: 4486.680929 tokens/s, learning rate: 1.171e-05, loss_scalings: 13421.773438, pp_loss: 8.181759
[INFO] 2021-07-12 18:54:50,598 [run_pretraining.py:  512]:	********exe.run_1172******* 
[INFO] 2021-07-12 18:54:51,514 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:51,514 [run_pretraining.py:  534]:	loss/total_loss, 7.138192176818848, 1173
[INFO] 2021-07-12 18:54:51,514 [run_pretraining.py:  535]:	loss/mlm_loss, 7.138192176818848, 1173
[INFO] 2021-07-12 18:54:51,514 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1719999747583643e-05, 1173
[INFO] 2021-07-12 18:54:51,514 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1173
[INFO] 2021-07-12 18:54:51,514 [run_pretraining.py:  558]:	worker_index: 2, step: 1173, cost: 7.138192, mlm loss: 7.138192, speed: 1.091638 steps/s, speed: 8.733105 samples/s, speed: 4471.349747 tokens/s, learning rate: 1.172e-05, loss_scalings: 13421.773438, pp_loss: 7.799037
[INFO] 2021-07-12 18:54:51,515 [run_pretraining.py:  512]:	********exe.run_1173******* 
[INFO] 2021-07-12 18:54:52,429 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:52,429 [run_pretraining.py:  534]:	loss/total_loss, 7.759411811828613, 1174
[INFO] 2021-07-12 18:54:52,429 [run_pretraining.py:  535]:	loss/mlm_loss, 7.759411811828613, 1174
[INFO] 2021-07-12 18:54:52,429 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1729999641829636e-05, 1174
[INFO] 2021-07-12 18:54:52,429 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1174
[INFO] 2021-07-12 18:54:52,430 [run_pretraining.py:  558]:	worker_index: 2, step: 1174, cost: 7.759412, mlm loss: 7.759412, speed: 1.093548 steps/s, speed: 8.748381 samples/s, speed: 4479.170962 tokens/s, learning rate: 1.173e-05, loss_scalings: 13421.773438, pp_loss: 7.823469
[INFO] 2021-07-12 18:54:52,430 [run_pretraining.py:  512]:	********exe.run_1174******* 
[INFO] 2021-07-12 18:54:53,338 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:53,339 [run_pretraining.py:  534]:	loss/total_loss, 7.490017414093018, 1175
[INFO] 2021-07-12 18:54:53,339 [run_pretraining.py:  535]:	loss/mlm_loss, 7.490017414093018, 1175
[INFO] 2021-07-12 18:54:53,339 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.173999953607563e-05, 1175
[INFO] 2021-07-12 18:54:53,339 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1175
[INFO] 2021-07-12 18:54:53,339 [run_pretraining.py:  558]:	worker_index: 2, step: 1175, cost: 7.490017, mlm loss: 7.490017, speed: 1.099990 steps/s, speed: 8.799916 samples/s, speed: 4505.557032 tokens/s, learning rate: 1.174e-05, loss_scalings: 13421.773438, pp_loss: 7.960916
[INFO] 2021-07-12 18:54:53,339 [run_pretraining.py:  512]:	********exe.run_1175******* 
[INFO] 2021-07-12 18:54:54,254 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:54,254 [run_pretraining.py:  534]:	loss/total_loss, 7.963176727294922, 1176
[INFO] 2021-07-12 18:54:54,254 [run_pretraining.py:  535]:	loss/mlm_loss, 7.963176727294922, 1176
[INFO] 2021-07-12 18:54:54,255 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1749999430321623e-05, 1176
[INFO] 2021-07-12 18:54:54,255 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1176
[INFO] 2021-07-12 18:54:54,255 [run_pretraining.py:  558]:	worker_index: 2, step: 1176, cost: 7.963177, mlm loss: 7.963177, speed: 1.093123 steps/s, speed: 8.744984 samples/s, speed: 4477.431588 tokens/s, learning rate: 1.175e-05, loss_scalings: 13421.773438, pp_loss: 8.006975
[INFO] 2021-07-12 18:54:54,255 [run_pretraining.py:  512]:	********exe.run_1176******* 
[INFO] 2021-07-12 18:54:55,173 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:55,173 [run_pretraining.py:  534]:	loss/total_loss, 7.643847465515137, 1177
[INFO] 2021-07-12 18:54:55,174 [run_pretraining.py:  535]:	loss/mlm_loss, 7.643847465515137, 1177
[INFO] 2021-07-12 18:54:55,174 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1760000234062318e-05, 1177
[INFO] 2021-07-12 18:54:55,174 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1177
[INFO] 2021-07-12 18:54:55,174 [run_pretraining.py:  558]:	worker_index: 2, step: 1177, cost: 7.643847, mlm loss: 7.643847, speed: 1.088646 steps/s, speed: 8.709171 samples/s, speed: 4459.095452 tokens/s, learning rate: 1.176e-05, loss_scalings: 13421.773438, pp_loss: 7.542898
[INFO] 2021-07-12 18:54:55,174 [run_pretraining.py:  512]:	********exe.run_1177******* 
[INFO] 2021-07-12 18:54:56,090 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:56,090 [run_pretraining.py:  534]:	loss/total_loss, 7.929792881011963, 1178
[INFO] 2021-07-12 18:54:56,090 [run_pretraining.py:  535]:	loss/mlm_loss, 7.929792881011963, 1178
[INFO] 2021-07-12 18:54:56,091 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1770000128308311e-05, 1178
[INFO] 2021-07-12 18:54:56,091 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1178
[INFO] 2021-07-12 18:54:56,091 [run_pretraining.py:  558]:	worker_index: 2, step: 1178, cost: 7.929793, mlm loss: 7.929793, speed: 1.091383 steps/s, speed: 8.731067 samples/s, speed: 4470.306113 tokens/s, learning rate: 1.177e-05, loss_scalings: 13421.773438, pp_loss: 8.118345
[INFO] 2021-07-12 18:54:56,091 [run_pretraining.py:  512]:	********exe.run_1178******* 
[INFO] 2021-07-12 18:54:57,002 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:57,003 [run_pretraining.py:  534]:	loss/total_loss, 8.008598327636719, 1179
[INFO] 2021-07-12 18:54:57,003 [run_pretraining.py:  535]:	loss/mlm_loss, 8.008598327636719, 1179
[INFO] 2021-07-12 18:54:57,003 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1779999113059603e-05, 1179
[INFO] 2021-07-12 18:54:57,003 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1179
[INFO] 2021-07-12 18:54:57,003 [run_pretraining.py:  558]:	worker_index: 2, step: 1179, cost: 8.008598, mlm loss: 8.008598, speed: 1.096855 steps/s, speed: 8.774839 samples/s, speed: 4492.717632 tokens/s, learning rate: 1.178e-05, loss_scalings: 13421.773438, pp_loss: 7.951726
[INFO] 2021-07-12 18:54:57,003 [run_pretraining.py:  512]:	********exe.run_1179******* 
[INFO] 2021-07-12 18:54:57,932 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:57,933 [run_pretraining.py:  534]:	loss/total_loss, 8.34937858581543, 1180
[INFO] 2021-07-12 18:54:57,933 [run_pretraining.py:  535]:	loss/mlm_loss, 8.34937858581543, 1180
[INFO] 2021-07-12 18:54:57,933 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1789999916800298e-05, 1180
[INFO] 2021-07-12 18:54:57,933 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1180
[INFO] 2021-07-12 18:54:57,933 [run_pretraining.py:  558]:	worker_index: 2, step: 1180, cost: 8.349379, mlm loss: 8.349379, speed: 1.076031 steps/s, speed: 8.608247 samples/s, speed: 4407.422686 tokens/s, learning rate: 1.179e-05, loss_scalings: 13421.773438, pp_loss: 8.061108
[INFO] 2021-07-12 18:54:57,933 [run_pretraining.py:  512]:	********exe.run_1180******* 
[INFO] 2021-07-12 18:54:58,862 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:58,863 [run_pretraining.py:  534]:	loss/total_loss, 7.783846855163574, 1181
[INFO] 2021-07-12 18:54:58,863 [run_pretraining.py:  535]:	loss/mlm_loss, 7.783846855163574, 1181
[INFO] 2021-07-12 18:54:58,863 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1799999811046291e-05, 1181
[INFO] 2021-07-12 18:54:58,863 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1181
[INFO] 2021-07-12 18:54:58,863 [run_pretraining.py:  558]:	worker_index: 2, step: 1181, cost: 7.783847, mlm loss: 7.783847, speed: 1.075613 steps/s, speed: 8.604903 samples/s, speed: 4405.710332 tokens/s, learning rate: 1.180e-05, loss_scalings: 13421.773438, pp_loss: 7.520564
[INFO] 2021-07-12 18:54:58,863 [run_pretraining.py:  512]:	********exe.run_1181******* 
[INFO] 2021-07-12 18:54:59,791 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:59,791 [run_pretraining.py:  534]:	loss/total_loss, 7.954564571380615, 1182
[INFO] 2021-07-12 18:54:59,791 [run_pretraining.py:  535]:	loss/mlm_loss, 7.954564571380615, 1182
[INFO] 2021-07-12 18:54:59,792 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1809999705292284e-05, 1182
[INFO] 2021-07-12 18:54:59,792 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1182
[INFO] 2021-07-12 18:54:59,792 [run_pretraining.py:  558]:	worker_index: 2, step: 1182, cost: 7.954565, mlm loss: 7.954565, speed: 1.077889 steps/s, speed: 8.623111 samples/s, speed: 4415.033015 tokens/s, learning rate: 1.181e-05, loss_scalings: 13421.773438, pp_loss: 8.146979
[INFO] 2021-07-12 18:54:59,792 [run_pretraining.py:  512]:	********exe.run_1182******* 
[INFO] 2021-07-12 18:55:00,713 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:00,714 [run_pretraining.py:  534]:	loss/total_loss, 8.049161911010742, 1183
[INFO] 2021-07-12 18:55:00,714 [run_pretraining.py:  535]:	loss/mlm_loss, 8.049161911010742, 1183
[INFO] 2021-07-12 18:55:00,714 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1819999599538278e-05, 1183
[INFO] 2021-07-12 18:55:00,714 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1183
[INFO] 2021-07-12 18:55:00,714 [run_pretraining.py:  558]:	worker_index: 2, step: 1183, cost: 8.049162, mlm loss: 8.049162, speed: 1.084631 steps/s, speed: 8.677048 samples/s, speed: 4442.648714 tokens/s, learning rate: 1.182e-05, loss_scalings: 13421.773438, pp_loss: 8.095865
[INFO] 2021-07-12 18:55:00,714 [run_pretraining.py:  512]:	********exe.run_1183******* 
[INFO] 2021-07-12 18:55:01,647 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:01,647 [run_pretraining.py:  534]:	loss/total_loss, 8.091856956481934, 1184
[INFO] 2021-07-12 18:55:01,647 [run_pretraining.py:  535]:	loss/mlm_loss, 8.091856956481934, 1184
[INFO] 2021-07-12 18:55:01,647 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1829999493784271e-05, 1184
[INFO] 2021-07-12 18:55:01,647 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1184
[INFO] 2021-07-12 18:55:01,648 [run_pretraining.py:  558]:	worker_index: 2, step: 1184, cost: 8.091857, mlm loss: 8.091857, speed: 1.072191 steps/s, speed: 8.577526 samples/s, speed: 4391.693242 tokens/s, learning rate: 1.183e-05, loss_scalings: 13421.773438, pp_loss: 7.419748
[INFO] 2021-07-12 18:55:01,648 [run_pretraining.py:  512]:	********exe.run_1184******* 
[INFO] 2021-07-12 18:55:02,564 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:02,565 [run_pretraining.py:  534]:	loss/total_loss, 8.088129997253418, 1185
[INFO] 2021-07-12 18:55:02,565 [run_pretraining.py:  535]:	loss/mlm_loss, 8.088129997253418, 1185
[INFO] 2021-07-12 18:55:02,565 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1839999388030265e-05, 1185
[INFO] 2021-07-12 18:55:02,565 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1185
[INFO] 2021-07-12 18:55:02,565 [run_pretraining.py:  558]:	worker_index: 2, step: 1185, cost: 8.088130, mlm loss: 8.088130, speed: 1.090535 steps/s, speed: 8.724279 samples/s, speed: 4466.830846 tokens/s, learning rate: 1.184e-05, loss_scalings: 13421.773438, pp_loss: 8.060940
[INFO] 2021-07-12 18:55:02,565 [run_pretraining.py:  512]:	********exe.run_1185******* 
[INFO] 2021-07-12 18:55:03,488 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:03,488 [run_pretraining.py:  534]:	loss/total_loss, 7.605623245239258, 1186
[INFO] 2021-07-12 18:55:03,488 [run_pretraining.py:  535]:	loss/mlm_loss, 7.605623245239258, 1186
[INFO] 2021-07-12 18:55:03,488 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.185000019177096e-05, 1186
[INFO] 2021-07-12 18:55:03,488 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1186
[INFO] 2021-07-12 18:55:03,489 [run_pretraining.py:  558]:	worker_index: 2, step: 1186, cost: 7.605623, mlm loss: 7.605623, speed: 1.083583 steps/s, speed: 8.668667 samples/s, speed: 4438.357305 tokens/s, learning rate: 1.185e-05, loss_scalings: 13421.773438, pp_loss: 7.662710
[INFO] 2021-07-12 18:55:03,489 [run_pretraining.py:  512]:	********exe.run_1186******* 
[INFO] 2021-07-12 18:55:04,407 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:04,408 [run_pretraining.py:  534]:	loss/total_loss, 7.467767715454102, 1187
[INFO] 2021-07-12 18:55:04,408 [run_pretraining.py:  535]:	loss/mlm_loss, 7.467767715454102, 1187
[INFO] 2021-07-12 18:55:04,408 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1860000086016953e-05, 1187
[INFO] 2021-07-12 18:55:04,408 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1187
[INFO] 2021-07-12 18:55:04,408 [run_pretraining.py:  558]:	worker_index: 2, step: 1187, cost: 7.467768, mlm loss: 7.467768, speed: 1.088037 steps/s, speed: 8.704298 samples/s, speed: 4456.600393 tokens/s, learning rate: 1.186e-05, loss_scalings: 13421.773438, pp_loss: 7.970603
[INFO] 2021-07-12 18:55:04,408 [run_pretraining.py:  512]:	********exe.run_1187******* 
[INFO] 2021-07-12 18:55:05,327 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:05,328 [run_pretraining.py:  534]:	loss/total_loss, 8.199897766113281, 1188
[INFO] 2021-07-12 18:55:05,328 [run_pretraining.py:  535]:	loss/mlm_loss, 8.199897766113281, 1188
[INFO] 2021-07-12 18:55:05,328 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1869999070768245e-05, 1188
[INFO] 2021-07-12 18:55:05,328 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1188
[INFO] 2021-07-12 18:55:05,328 [run_pretraining.py:  558]:	worker_index: 2, step: 1188, cost: 8.199898, mlm loss: 8.199898, speed: 1.087722 steps/s, speed: 8.701776 samples/s, speed: 4455.309427 tokens/s, learning rate: 1.187e-05, loss_scalings: 13421.773438, pp_loss: 8.034388
[INFO] 2021-07-12 18:55:05,328 [run_pretraining.py:  512]:	********exe.run_1188******* 
[INFO] 2021-07-12 18:55:06,257 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:06,257 [run_pretraining.py:  534]:	loss/total_loss, 7.922900199890137, 1189
[INFO] 2021-07-12 18:55:06,257 [run_pretraining.py:  535]:	loss/mlm_loss, 7.922900199890137, 1189
[INFO] 2021-07-12 18:55:06,257 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.187999987450894e-05, 1189
[INFO] 2021-07-12 18:55:06,258 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1189
[INFO] 2021-07-12 18:55:06,258 [run_pretraining.py:  558]:	worker_index: 2, step: 1189, cost: 7.922900, mlm loss: 7.922900, speed: 1.076675 steps/s, speed: 8.613401 samples/s, speed: 4410.061070 tokens/s, learning rate: 1.188e-05, loss_scalings: 13421.773438, pp_loss: 8.001194
[INFO] 2021-07-12 18:55:06,258 [run_pretraining.py:  512]:	********exe.run_1189******* 
[INFO] 2021-07-12 18:55:07,180 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:07,181 [run_pretraining.py:  534]:	loss/total_loss, 7.93250846862793, 1190
[INFO] 2021-07-12 18:55:07,181 [run_pretraining.py:  535]:	loss/mlm_loss, 7.93250846862793, 1190
[INFO] 2021-07-12 18:55:07,181 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1889999768754933e-05, 1190
[INFO] 2021-07-12 18:55:07,181 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1190
[INFO] 2021-07-12 18:55:07,181 [run_pretraining.py:  558]:	worker_index: 2, step: 1190, cost: 7.932508, mlm loss: 7.932508, speed: 1.083302 steps/s, speed: 8.666412 samples/s, speed: 4437.202946 tokens/s, learning rate: 1.189e-05, loss_scalings: 13421.773438, pp_loss: 7.613126
[INFO] 2021-07-12 18:55:07,181 [run_pretraining.py:  512]:	********exe.run_1190******* 
[INFO] 2021-07-12 18:55:08,095 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:08,095 [run_pretraining.py:  534]:	loss/total_loss, 7.669955253601074, 1191
[INFO] 2021-07-12 18:55:08,095 [run_pretraining.py:  535]:	loss/mlm_loss, 7.669955253601074, 1191
[INFO] 2021-07-12 18:55:08,096 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1899999663000926e-05, 1191
[INFO] 2021-07-12 18:55:08,096 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1191
[INFO] 2021-07-12 18:55:08,096 [run_pretraining.py:  558]:	worker_index: 2, step: 1191, cost: 7.669955, mlm loss: 7.669955, speed: 1.094275 steps/s, speed: 8.754196 samples/s, speed: 4482.148542 tokens/s, learning rate: 1.190e-05, loss_scalings: 13421.773438, pp_loss: 7.548098
[INFO] 2021-07-12 18:55:08,096 [run_pretraining.py:  512]:	********exe.run_1191******* 
[INFO] 2021-07-12 18:55:09,014 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:09,015 [run_pretraining.py:  534]:	loss/total_loss, 7.8768439292907715, 1192
[INFO] 2021-07-12 18:55:09,015 [run_pretraining.py:  535]:	loss/mlm_loss, 7.8768439292907715, 1192
[INFO] 2021-07-12 18:55:09,015 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.190999955724692e-05, 1192
[INFO] 2021-07-12 18:55:09,015 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1192
[INFO] 2021-07-12 18:55:09,015 [run_pretraining.py:  558]:	worker_index: 2, step: 1192, cost: 7.876844, mlm loss: 7.876844, speed: 1.088188 steps/s, speed: 8.705504 samples/s, speed: 4457.217825 tokens/s, learning rate: 1.191e-05, loss_scalings: 13421.773438, pp_loss: 6.736130
[INFO] 2021-07-12 18:55:09,015 [run_pretraining.py:  512]:	********exe.run_1192******* 
[INFO] 2021-07-12 18:55:09,946 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:09,947 [run_pretraining.py:  534]:	loss/total_loss, 7.889316082000732, 1193
[INFO] 2021-07-12 18:55:09,947 [run_pretraining.py:  535]:	loss/mlm_loss, 7.889316082000732, 1193
[INFO] 2021-07-12 18:55:09,947 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1919999451492913e-05, 1193
[INFO] 2021-07-12 18:55:09,947 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1193
[INFO] 2021-07-12 18:55:09,947 [run_pretraining.py:  558]:	worker_index: 2, step: 1193, cost: 7.889316, mlm loss: 7.889316, speed: 1.073854 steps/s, speed: 8.590832 samples/s, speed: 4398.505926 tokens/s, learning rate: 1.192e-05, loss_scalings: 13421.773438, pp_loss: 7.816773
[INFO] 2021-07-12 18:55:09,947 [run_pretraining.py:  512]:	********exe.run_1193******* 
[INFO] 2021-07-12 18:55:10,861 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:10,862 [run_pretraining.py:  534]:	loss/total_loss, 7.402766227722168, 1194
[INFO] 2021-07-12 18:55:10,862 [run_pretraining.py:  535]:	loss/mlm_loss, 7.402766227722168, 1194
[INFO] 2021-07-12 18:55:10,862 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1929999345738906e-05, 1194
[INFO] 2021-07-12 18:55:10,862 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1194
[INFO] 2021-07-12 18:55:10,862 [run_pretraining.py:  558]:	worker_index: 2, step: 1194, cost: 7.402766, mlm loss: 7.402766, speed: 1.093809 steps/s, speed: 8.750468 samples/s, speed: 4480.239771 tokens/s, learning rate: 1.193e-05, loss_scalings: 13421.773438, pp_loss: 7.616417
[INFO] 2021-07-12 18:55:10,862 [run_pretraining.py:  512]:	********exe.run_1194******* 
[INFO] 2021-07-12 18:55:11,780 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:11,781 [run_pretraining.py:  534]:	loss/total_loss, 7.7961907386779785, 1195
[INFO] 2021-07-12 18:55:11,781 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7961907386779785, 1195
[INFO] 2021-07-12 18:55:11,781 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1940000149479602e-05, 1195
[INFO] 2021-07-12 18:55:11,781 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1195
[INFO] 2021-07-12 18:55:11,781 [run_pretraining.py:  558]:	worker_index: 2, step: 1195, cost: 7.796191, mlm loss: 7.796191, speed: 1.088847 steps/s, speed: 8.710774 samples/s, speed: 4459.916181 tokens/s, learning rate: 1.194e-05, loss_scalings: 13421.773438, pp_loss: 7.703680
[INFO] 2021-07-12 18:55:11,781 [run_pretraining.py:  512]:	********exe.run_1195******* 
[INFO] 2021-07-12 18:55:12,694 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:12,694 [run_pretraining.py:  534]:	loss/total_loss, 7.815334320068359, 1196
[INFO] 2021-07-12 18:55:12,694 [run_pretraining.py:  535]:	loss/mlm_loss, 7.815334320068359, 1196
[INFO] 2021-07-12 18:55:12,695 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1949999134230893e-05, 1196
[INFO] 2021-07-12 18:55:12,695 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1196
[INFO] 2021-07-12 18:55:12,695 [run_pretraining.py:  558]:	worker_index: 2, step: 1196, cost: 7.815334, mlm loss: 7.815334, speed: 1.095095 steps/s, speed: 8.760758 samples/s, speed: 4485.508326 tokens/s, learning rate: 1.195e-05, loss_scalings: 13421.773438, pp_loss: 7.933424
[INFO] 2021-07-12 18:55:12,695 [run_pretraining.py:  512]:	********exe.run_1196******* 
[INFO] 2021-07-12 18:55:13,610 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:13,610 [run_pretraining.py:  534]:	loss/total_loss, 7.424651145935059, 1197
[INFO] 2021-07-12 18:55:13,610 [run_pretraining.py:  535]:	loss/mlm_loss, 7.424651145935059, 1197
[INFO] 2021-07-12 18:55:13,610 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1959999937971588e-05, 1197
[INFO] 2021-07-12 18:55:13,610 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1197
[INFO] 2021-07-12 18:55:13,610 [run_pretraining.py:  558]:	worker_index: 2, step: 1197, cost: 7.424651, mlm loss: 7.424651, speed: 1.092779 steps/s, speed: 8.742229 samples/s, speed: 4476.021236 tokens/s, learning rate: 1.196e-05, loss_scalings: 13421.773438, pp_loss: 7.486769
[INFO] 2021-07-12 18:55:13,610 [run_pretraining.py:  512]:	********exe.run_1197******* 
[INFO] 2021-07-12 18:55:14,521 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:14,522 [run_pretraining.py:  534]:	loss/total_loss, 7.508504390716553, 1198
[INFO] 2021-07-12 18:55:14,522 [run_pretraining.py:  535]:	loss/mlm_loss, 7.508504390716553, 1198
[INFO] 2021-07-12 18:55:14,522 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1969999832217582e-05, 1198
[INFO] 2021-07-12 18:55:14,522 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1198
[INFO] 2021-07-12 18:55:14,522 [run_pretraining.py:  558]:	worker_index: 2, step: 1198, cost: 7.508504, mlm loss: 7.508504, speed: 1.097477 steps/s, speed: 8.779817 samples/s, speed: 4495.266246 tokens/s, learning rate: 1.197e-05, loss_scalings: 13421.773438, pp_loss: 7.691894
[INFO] 2021-07-12 18:55:14,522 [run_pretraining.py:  512]:	********exe.run_1198******* 
[INFO] 2021-07-12 18:55:15,476 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:15,477 [run_pretraining.py:  534]:	loss/total_loss, 8.06215763092041, 1199
[INFO] 2021-07-12 18:55:15,477 [run_pretraining.py:  535]:	loss/mlm_loss, 8.06215763092041, 1199
[INFO] 2021-07-12 18:55:15,477 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1979999726463575e-05, 1199
[INFO] 2021-07-12 18:55:15,477 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1199
[INFO] 2021-07-12 18:55:15,477 [run_pretraining.py:  558]:	worker_index: 2, step: 1199, cost: 8.062158, mlm loss: 8.062158, speed: 1.048053 steps/s, speed: 8.384422 samples/s, speed: 4292.824104 tokens/s, learning rate: 1.198e-05, loss_scalings: 13421.773438, pp_loss: 8.167348
[INFO] 2021-07-12 18:55:15,477 [run_pretraining.py:  512]:	********exe.run_1199******* 
[INFO] 2021-07-12 18:55:16,403 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:16,403 [run_pretraining.py:  534]:	loss/total_loss, 7.766706466674805, 1200
[INFO] 2021-07-12 18:55:16,404 [run_pretraining.py:  535]:	loss/mlm_loss, 7.766706466674805, 1200
[INFO] 2021-07-12 18:55:16,404 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1989999620709568e-05, 1200
[INFO] 2021-07-12 18:55:16,404 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1200
[INFO] 2021-07-12 18:55:16,404 [run_pretraining.py:  558]:	worker_index: 2, step: 1200, cost: 7.766706, mlm loss: 7.766706, speed: 1.079643 steps/s, speed: 8.637144 samples/s, speed: 4422.217716 tokens/s, learning rate: 1.199e-05, loss_scalings: 13421.773438, pp_loss: 7.879642
[INFO] 2021-07-12 18:55:16,404 [run_pretraining.py:  512]:	********exe.run_1200******* 
[INFO] 2021-07-12 18:55:17,319 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:17,319 [run_pretraining.py:  534]:	loss/total_loss, 8.316680908203125, 1201
[INFO] 2021-07-12 18:55:17,320 [run_pretraining.py:  535]:	loss/mlm_loss, 8.316680908203125, 1201
[INFO] 2021-07-12 18:55:17,320 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1999999514955562e-05, 1201
[INFO] 2021-07-12 18:55:17,320 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1201
[INFO] 2021-07-12 18:55:17,320 [run_pretraining.py:  558]:	worker_index: 2, step: 1201, cost: 8.316681, mlm loss: 8.316681, speed: 1.092466 steps/s, speed: 8.739729 samples/s, speed: 4474.741140 tokens/s, learning rate: 1.200e-05, loss_scalings: 13421.773438, pp_loss: 7.789189
[INFO] 2021-07-12 18:55:17,320 [run_pretraining.py:  512]:	********exe.run_1201******* 
[INFO] 2021-07-12 18:55:18,224 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:18,225 [run_pretraining.py:  534]:	loss/total_loss, 4.698968410491943, 1202
[INFO] 2021-07-12 18:55:18,225 [run_pretraining.py:  535]:	loss/mlm_loss, 4.698968410491943, 1202
[INFO] 2021-07-12 18:55:18,225 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2009999409201555e-05, 1202
[INFO] 2021-07-12 18:55:18,225 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1202
[INFO] 2021-07-12 18:55:18,225 [run_pretraining.py:  558]:	worker_index: 2, step: 1202, cost: 4.698968, mlm loss: 4.698968, speed: 1.105234 steps/s, speed: 8.841871 samples/s, speed: 4527.037975 tokens/s, learning rate: 1.201e-05, loss_scalings: 13421.773438, pp_loss: 7.096149
[INFO] 2021-07-12 18:55:18,225 [run_pretraining.py:  512]:	********exe.run_1202******* 
[INFO] 2021-07-12 18:55:19,135 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:19,135 [run_pretraining.py:  534]:	loss/total_loss, 8.283624649047852, 1203
[INFO] 2021-07-12 18:55:19,136 [run_pretraining.py:  535]:	loss/mlm_loss, 8.283624649047852, 1203
[INFO] 2021-07-12 18:55:19,136 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.202000021294225e-05, 1203
[INFO] 2021-07-12 18:55:19,136 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1203
[INFO] 2021-07-12 18:55:19,136 [run_pretraining.py:  558]:	worker_index: 2, step: 1203, cost: 8.283625, mlm loss: 8.283625, speed: 1.098951 steps/s, speed: 8.791611 samples/s, speed: 4501.304860 tokens/s, learning rate: 1.202e-05, loss_scalings: 13421.773438, pp_loss: 8.305773
[INFO] 2021-07-12 18:55:19,136 [run_pretraining.py:  512]:	********exe.run_1203******* 
[INFO] 2021-07-12 18:55:20,049 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:20,049 [run_pretraining.py:  534]:	loss/total_loss, 8.299515724182129, 1204
[INFO] 2021-07-12 18:55:20,049 [run_pretraining.py:  535]:	loss/mlm_loss, 8.299515724182129, 1204
[INFO] 2021-07-12 18:55:20,049 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2030000107188243e-05, 1204
[INFO] 2021-07-12 18:55:20,050 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1204
[INFO] 2021-07-12 18:55:20,050 [run_pretraining.py:  558]:	worker_index: 2, step: 1204, cost: 8.299516, mlm loss: 8.299516, speed: 1.094980 steps/s, speed: 8.759837 samples/s, speed: 4485.036412 tokens/s, learning rate: 1.203e-05, loss_scalings: 13421.773438, pp_loss: 8.005972
[INFO] 2021-07-12 18:55:20,050 [run_pretraining.py:  512]:	********exe.run_1204******* 
[INFO] 2021-07-12 18:55:20,961 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:20,962 [run_pretraining.py:  534]:	loss/total_loss, 8.177054405212402, 1205
[INFO] 2021-07-12 18:55:20,962 [run_pretraining.py:  535]:	loss/mlm_loss, 8.177054405212402, 1205
[INFO] 2021-07-12 18:55:20,962 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2039999091939535e-05, 1205
[INFO] 2021-07-12 18:55:20,962 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1205
[INFO] 2021-07-12 18:55:20,962 [run_pretraining.py:  558]:	worker_index: 2, step: 1205, cost: 8.177054, mlm loss: 8.177054, speed: 1.096668 steps/s, speed: 8.773348 samples/s, speed: 4491.954081 tokens/s, learning rate: 1.204e-05, loss_scalings: 13421.773438, pp_loss: 7.730770
[INFO] 2021-07-12 18:55:20,962 [run_pretraining.py:  512]:	********exe.run_1205******* 
[INFO] 2021-07-12 18:55:21,874 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:21,874 [run_pretraining.py:  534]:	loss/total_loss, 7.057449817657471, 1206
[INFO] 2021-07-12 18:55:21,874 [run_pretraining.py:  535]:	loss/mlm_loss, 7.057449817657471, 1206
[INFO] 2021-07-12 18:55:21,875 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.204999989568023e-05, 1206
[INFO] 2021-07-12 18:55:21,875 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1206
[INFO] 2021-07-12 18:55:21,875 [run_pretraining.py:  558]:	worker_index: 2, step: 1206, cost: 7.057450, mlm loss: 7.057450, speed: 1.096413 steps/s, speed: 8.771304 samples/s, speed: 4490.907851 tokens/s, learning rate: 1.205e-05, loss_scalings: 13421.773438, pp_loss: 7.851196
[INFO] 2021-07-12 18:55:21,875 [run_pretraining.py:  512]:	********exe.run_1206******* 
[INFO] 2021-07-12 18:55:22,778 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:22,778 [run_pretraining.py:  534]:	loss/total_loss, 7.558304309844971, 1207
[INFO] 2021-07-12 18:55:22,778 [run_pretraining.py:  535]:	loss/mlm_loss, 7.558304309844971, 1207
[INFO] 2021-07-12 18:55:22,778 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2059999789926223e-05, 1207
[INFO] 2021-07-12 18:55:22,778 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1207
[INFO] 2021-07-12 18:55:22,778 [run_pretraining.py:  558]:	worker_index: 2, step: 1207, cost: 7.558304, mlm loss: 7.558304, speed: 1.107256 steps/s, speed: 8.858044 samples/s, speed: 4535.318783 tokens/s, learning rate: 1.206e-05, loss_scalings: 13421.773438, pp_loss: 6.925065
[INFO] 2021-07-12 18:55:22,779 [run_pretraining.py:  512]:	********exe.run_1207******* 
[INFO] 2021-07-12 18:55:23,693 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:23,694 [run_pretraining.py:  534]:	loss/total_loss, 7.709063529968262, 1208
[INFO] 2021-07-12 18:55:23,694 [run_pretraining.py:  535]:	loss/mlm_loss, 7.709063529968262, 1208
[INFO] 2021-07-12 18:55:23,694 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2069999684172217e-05, 1208
[INFO] 2021-07-12 18:55:23,694 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1208
[INFO] 2021-07-12 18:55:23,694 [run_pretraining.py:  558]:	worker_index: 2, step: 1208, cost: 7.709064, mlm loss: 7.709064, speed: 1.092655 steps/s, speed: 8.741243 samples/s, speed: 4475.516338 tokens/s, learning rate: 1.207e-05, loss_scalings: 13421.773438, pp_loss: 7.901795
[INFO] 2021-07-12 18:55:23,694 [run_pretraining.py:  512]:	********exe.run_1208******* 
[INFO] 2021-07-12 18:55:24,600 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:24,601 [run_pretraining.py:  534]:	loss/total_loss, 7.675445079803467, 1209
[INFO] 2021-07-12 18:55:24,601 [run_pretraining.py:  535]:	loss/mlm_loss, 7.675445079803467, 1209
[INFO] 2021-07-12 18:55:24,601 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2080000487912912e-05, 1209
[INFO] 2021-07-12 18:55:24,601 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1209
[INFO] 2021-07-12 18:55:24,601 [run_pretraining.py:  558]:	worker_index: 2, step: 1209, cost: 7.675445, mlm loss: 7.675445, speed: 1.103716 steps/s, speed: 8.829728 samples/s, speed: 4520.820718 tokens/s, learning rate: 1.208e-05, loss_scalings: 13421.773438, pp_loss: 8.072867
[INFO] 2021-07-12 18:55:24,601 [run_pretraining.py:  512]:	********exe.run_1209******* 
[INFO] 2021-07-12 18:55:25,507 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:25,508 [run_pretraining.py:  534]:	loss/total_loss, 7.742974758148193, 1210
[INFO] 2021-07-12 18:55:25,508 [run_pretraining.py:  535]:	loss/mlm_loss, 7.742974758148193, 1210
[INFO] 2021-07-12 18:55:25,508 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2089999472664203e-05, 1210
[INFO] 2021-07-12 18:55:25,508 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1210
[INFO] 2021-07-12 18:55:25,508 [run_pretraining.py:  558]:	worker_index: 2, step: 1210, cost: 7.742975, mlm loss: 7.742975, speed: 1.102968 steps/s, speed: 8.823747 samples/s, speed: 4517.758287 tokens/s, learning rate: 1.209e-05, loss_scalings: 13421.773438, pp_loss: 7.968678
[INFO] 2021-07-12 18:55:25,508 [run_pretraining.py:  512]:	********exe.run_1210******* 
[INFO] 2021-07-12 18:55:26,441 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:26,442 [run_pretraining.py:  534]:	loss/total_loss, 7.586780548095703, 1211
[INFO] 2021-07-12 18:55:26,442 [run_pretraining.py:  535]:	loss/mlm_loss, 7.586780548095703, 1211
[INFO] 2021-07-12 18:55:26,442 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2099999366910197e-05, 1211
[INFO] 2021-07-12 18:55:26,442 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1211
[INFO] 2021-07-12 18:55:26,442 [run_pretraining.py:  558]:	worker_index: 2, step: 1211, cost: 7.586781, mlm loss: 7.586781, speed: 1.071485 steps/s, speed: 8.571877 samples/s, speed: 4388.800958 tokens/s, learning rate: 1.210e-05, loss_scalings: 13421.773438, pp_loss: 7.821238
[INFO] 2021-07-12 18:55:26,442 [run_pretraining.py:  512]:	********exe.run_1211******* 
[INFO] 2021-07-12 18:55:27,358 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:27,359 [run_pretraining.py:  534]:	loss/total_loss, 7.034846305847168, 1212
[INFO] 2021-07-12 18:55:27,359 [run_pretraining.py:  535]:	loss/mlm_loss, 7.034846305847168, 1212
[INFO] 2021-07-12 18:55:27,359 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2110000170650892e-05, 1212
[INFO] 2021-07-12 18:55:27,359 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1212
[INFO] 2021-07-12 18:55:27,359 [run_pretraining.py:  558]:	worker_index: 2, step: 1212, cost: 7.034846, mlm loss: 7.034846, speed: 1.091169 steps/s, speed: 8.729354 samples/s, speed: 4469.429231 tokens/s, learning rate: 1.211e-05, loss_scalings: 13421.773438, pp_loss: 7.411559
[INFO] 2021-07-12 18:55:27,359 [run_pretraining.py:  512]:	********exe.run_1212******* 
[INFO] 2021-07-12 18:55:28,268 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:28,268 [run_pretraining.py:  534]:	loss/total_loss, 7.439968585968018, 1213
[INFO] 2021-07-12 18:55:28,268 [run_pretraining.py:  535]:	loss/mlm_loss, 7.439968585968018, 1213
[INFO] 2021-07-12 18:55:28,268 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2120000064896885e-05, 1213
[INFO] 2021-07-12 18:55:28,268 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1213
[INFO] 2021-07-12 18:55:28,268 [run_pretraining.py:  558]:	worker_index: 2, step: 1213, cost: 7.439969, mlm loss: 7.439969, speed: 1.100450 steps/s, speed: 8.803596 samples/s, speed: 4507.441319 tokens/s, learning rate: 1.212e-05, loss_scalings: 13421.773438, pp_loss: 7.427198
[INFO] 2021-07-12 18:55:28,268 [run_pretraining.py:  512]:	********exe.run_1213******* 
[INFO] 2021-07-12 18:55:29,181 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:29,181 [run_pretraining.py:  534]:	loss/total_loss, 7.854917049407959, 1214
[INFO] 2021-07-12 18:55:29,181 [run_pretraining.py:  535]:	loss/mlm_loss, 7.854917049407959, 1214
[INFO] 2021-07-12 18:55:29,181 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2129999049648177e-05, 1214
[INFO] 2021-07-12 18:55:29,181 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1214
[INFO] 2021-07-12 18:55:29,181 [run_pretraining.py:  558]:	worker_index: 2, step: 1214, cost: 7.854917, mlm loss: 7.854917, speed: 1.096069 steps/s, speed: 8.768549 samples/s, speed: 4489.497210 tokens/s, learning rate: 1.213e-05, loss_scalings: 13421.773438, pp_loss: 7.807285
[INFO] 2021-07-12 18:55:29,181 [run_pretraining.py:  512]:	********exe.run_1214******* 
[INFO] 2021-07-12 18:55:30,088 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:30,088 [run_pretraining.py:  534]:	loss/total_loss, 7.145682334899902, 1215
[INFO] 2021-07-12 18:55:30,088 [run_pretraining.py:  535]:	loss/mlm_loss, 7.145682334899902, 1215
[INFO] 2021-07-12 18:55:30,089 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2139999853388872e-05, 1215
[INFO] 2021-07-12 18:55:30,089 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1215
[INFO] 2021-07-12 18:55:30,089 [run_pretraining.py:  558]:	worker_index: 2, step: 1215, cost: 7.145682, mlm loss: 7.145682, speed: 1.102861 steps/s, speed: 8.822888 samples/s, speed: 4517.318760 tokens/s, learning rate: 1.214e-05, loss_scalings: 13421.773438, pp_loss: 7.781803
[INFO] 2021-07-12 18:55:30,089 [run_pretraining.py:  512]:	********exe.run_1215******* 
[INFO] 2021-07-12 18:55:31,002 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:31,003 [run_pretraining.py:  534]:	loss/total_loss, 4.738892555236816, 1216
[INFO] 2021-07-12 18:55:31,003 [run_pretraining.py:  535]:	loss/mlm_loss, 4.738892555236816, 1216
[INFO] 2021-07-12 18:55:31,003 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2149999747634865e-05, 1216
[INFO] 2021-07-12 18:55:31,003 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1216
[INFO] 2021-07-12 18:55:31,003 [run_pretraining.py:  558]:	worker_index: 2, step: 1216, cost: 4.738893, mlm loss: 4.738893, speed: 1.094210 steps/s, speed: 8.753683 samples/s, speed: 4481.885449 tokens/s, learning rate: 1.215e-05, loss_scalings: 13421.773438, pp_loss: 7.383825
[INFO] 2021-07-12 18:55:31,003 [run_pretraining.py:  512]:	********exe.run_1216******* 
[INFO] 2021-07-12 18:55:31,910 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:31,911 [run_pretraining.py:  534]:	loss/total_loss, 8.143351554870605, 1217
[INFO] 2021-07-12 18:55:31,911 [run_pretraining.py:  535]:	loss/mlm_loss, 8.143351554870605, 1217
[INFO] 2021-07-12 18:55:31,911 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2159999641880859e-05, 1217
[INFO] 2021-07-12 18:55:31,911 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1217
[INFO] 2021-07-12 18:55:31,911 [run_pretraining.py:  558]:	worker_index: 2, step: 1217, cost: 8.143352, mlm loss: 8.143352, speed: 1.101948 steps/s, speed: 8.815587 samples/s, speed: 4513.580301 tokens/s, learning rate: 1.216e-05, loss_scalings: 13421.773438, pp_loss: 7.805399
[INFO] 2021-07-12 18:55:31,911 [run_pretraining.py:  512]:	********exe.run_1217******* 
[INFO] 2021-07-12 18:55:32,816 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:32,816 [run_pretraining.py:  534]:	loss/total_loss, 7.682911396026611, 1218
[INFO] 2021-07-12 18:55:32,817 [run_pretraining.py:  535]:	loss/mlm_loss, 7.682911396026611, 1218
[INFO] 2021-07-12 18:55:32,817 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2169999536126852e-05, 1218
[INFO] 2021-07-12 18:55:32,817 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1218
[INFO] 2021-07-12 18:55:32,817 [run_pretraining.py:  558]:	worker_index: 2, step: 1218, cost: 7.682911, mlm loss: 7.682911, speed: 1.105089 steps/s, speed: 8.840709 samples/s, speed: 4526.442791 tokens/s, learning rate: 1.217e-05, loss_scalings: 13421.773438, pp_loss: 7.875525
[INFO] 2021-07-12 18:55:32,817 [run_pretraining.py:  512]:	********exe.run_1218******* 
[INFO] 2021-07-12 18:55:33,724 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:33,725 [run_pretraining.py:  534]:	loss/total_loss, 8.130475997924805, 1219
[INFO] 2021-07-12 18:55:33,725 [run_pretraining.py:  535]:	loss/mlm_loss, 8.130475997924805, 1219
[INFO] 2021-07-12 18:55:33,725 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2179999430372845e-05, 1219
[INFO] 2021-07-12 18:55:33,725 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1219
[INFO] 2021-07-12 18:55:33,725 [run_pretraining.py:  558]:	worker_index: 2, step: 1219, cost: 8.130476, mlm loss: 8.130476, speed: 1.101739 steps/s, speed: 8.813912 samples/s, speed: 4512.723109 tokens/s, learning rate: 1.218e-05, loss_scalings: 13421.773438, pp_loss: 7.665332
[INFO] 2021-07-12 18:55:33,725 [run_pretraining.py:  512]:	********exe.run_1219******* 
[INFO] 2021-07-12 18:55:34,674 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:34,674 [run_pretraining.py:  534]:	loss/total_loss, 8.168031692504883, 1220
[INFO] 2021-07-12 18:55:34,674 [run_pretraining.py:  535]:	loss/mlm_loss, 8.168031692504883, 1220
[INFO] 2021-07-12 18:55:34,674 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2189999324618839e-05, 1220
[INFO] 2021-07-12 18:55:34,674 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1220
[INFO] 2021-07-12 18:55:34,674 [run_pretraining.py:  558]:	worker_index: 2, step: 1220, cost: 8.168032, mlm loss: 8.168032, speed: 1.053942 steps/s, speed: 8.431539 samples/s, speed: 4316.948117 tokens/s, learning rate: 1.219e-05, loss_scalings: 13421.773438, pp_loss: 6.900340
[INFO] 2021-07-12 18:55:34,675 [run_pretraining.py:  512]:	********exe.run_1220******* 
[INFO] 2021-07-12 18:55:35,581 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:35,582 [run_pretraining.py:  534]:	loss/total_loss, 7.962005615234375, 1221
[INFO] 2021-07-12 18:55:35,582 [run_pretraining.py:  535]:	loss/mlm_loss, 7.962005615234375, 1221
[INFO] 2021-07-12 18:55:35,582 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2200000128359534e-05, 1221
[INFO] 2021-07-12 18:55:35,582 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1221
[INFO] 2021-07-12 18:55:35,582 [run_pretraining.py:  558]:	worker_index: 2, step: 1221, cost: 7.962006, mlm loss: 7.962006, speed: 1.102647 steps/s, speed: 8.821176 samples/s, speed: 4516.442337 tokens/s, learning rate: 1.220e-05, loss_scalings: 13421.773438, pp_loss: 7.677269
[INFO] 2021-07-12 18:55:35,582 [run_pretraining.py:  512]:	********exe.run_1221******* 
[INFO] 2021-07-12 18:55:36,483 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:36,483 [run_pretraining.py:  534]:	loss/total_loss, 7.259995937347412, 1222
[INFO] 2021-07-12 18:55:36,483 [run_pretraining.py:  535]:	loss/mlm_loss, 7.259995937347412, 1222
[INFO] 2021-07-12 18:55:36,483 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2210000022605527e-05, 1222
[INFO] 2021-07-12 18:55:36,483 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1222
[INFO] 2021-07-12 18:55:36,483 [run_pretraining.py:  558]:	worker_index: 2, step: 1222, cost: 7.259996, mlm loss: 7.259996, speed: 1.109964 steps/s, speed: 8.879712 samples/s, speed: 4546.412312 tokens/s, learning rate: 1.221e-05, loss_scalings: 13421.773438, pp_loss: 7.704010
[INFO] 2021-07-12 18:55:36,484 [run_pretraining.py:  512]:	********exe.run_1222******* 
[INFO] 2021-07-12 18:55:37,383 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:37,384 [run_pretraining.py:  534]:	loss/total_loss, 8.059284210205078, 1223
[INFO] 2021-07-12 18:55:37,384 [run_pretraining.py:  535]:	loss/mlm_loss, 8.059284210205078, 1223
[INFO] 2021-07-12 18:55:37,384 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2219999007356819e-05, 1223
[INFO] 2021-07-12 18:55:37,384 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1223
[INFO] 2021-07-12 18:55:37,384 [run_pretraining.py:  558]:	worker_index: 2, step: 1223, cost: 8.059284, mlm loss: 8.059284, speed: 1.111079 steps/s, speed: 8.888636 samples/s, speed: 4550.981630 tokens/s, learning rate: 1.222e-05, loss_scalings: 13421.773438, pp_loss: 7.843944
[INFO] 2021-07-12 18:55:37,384 [run_pretraining.py:  512]:	********exe.run_1223******* 
[INFO] 2021-07-12 18:55:38,397 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:38,397 [run_pretraining.py:  534]:	loss/total_loss, 8.3130464553833, 1224
[INFO] 2021-07-12 18:55:38,397 [run_pretraining.py:  535]:	loss/mlm_loss, 8.3130464553833, 1224
[INFO] 2021-07-12 18:55:38,397 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2229999811097514e-05, 1224
[INFO] 2021-07-12 18:55:38,397 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1224
[INFO] 2021-07-12 18:55:38,397 [run_pretraining.py:  558]:	worker_index: 2, step: 1224, cost: 8.313046, mlm loss: 8.313046, speed: 0.987485 steps/s, speed: 7.899876 samples/s, speed: 4044.736631 tokens/s, learning rate: 1.223e-05, loss_scalings: 13421.773438, pp_loss: 7.962028
[INFO] 2021-07-12 18:55:38,397 [run_pretraining.py:  512]:	********exe.run_1224******* 
[INFO] 2021-07-12 18:55:39,455 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:39,456 [run_pretraining.py:  534]:	loss/total_loss, 8.079776763916016, 1225
[INFO] 2021-07-12 18:55:39,456 [run_pretraining.py:  535]:	loss/mlm_loss, 8.079776763916016, 1225
[INFO] 2021-07-12 18:55:39,456 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2239999705343507e-05, 1225
[INFO] 2021-07-12 18:55:39,456 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1225
[INFO] 2021-07-12 18:55:39,456 [run_pretraining.py:  558]:	worker_index: 2, step: 1225, cost: 8.079777, mlm loss: 8.079777, speed: 0.945174 steps/s, speed: 7.561392 samples/s, speed: 3871.432573 tokens/s, learning rate: 1.224e-05, loss_scalings: 13421.773438, pp_loss: 7.971503
[INFO] 2021-07-12 18:55:39,456 [run_pretraining.py:  512]:	********exe.run_1225******* 
[INFO] 2021-07-12 18:55:40,486 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:40,486 [run_pretraining.py:  534]:	loss/total_loss, 8.173720359802246, 1226
[INFO] 2021-07-12 18:55:40,486 [run_pretraining.py:  535]:	loss/mlm_loss, 8.173720359802246, 1226
[INFO] 2021-07-12 18:55:40,486 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.22499995995895e-05, 1226
[INFO] 2021-07-12 18:55:40,487 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1226
[INFO] 2021-07-12 18:55:40,487 [run_pretraining.py:  558]:	worker_index: 2, step: 1226, cost: 8.173720, mlm loss: 8.173720, speed: 0.970849 steps/s, speed: 7.766793 samples/s, speed: 3976.597887 tokens/s, learning rate: 1.225e-05, loss_scalings: 13421.773438, pp_loss: 6.507322
[INFO] 2021-07-12 18:55:40,487 [run_pretraining.py:  512]:	********exe.run_1226******* 
[INFO] 2021-07-12 18:55:41,533 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:41,533 [run_pretraining.py:  534]:	loss/total_loss, 7.447757720947266, 1227
[INFO] 2021-07-12 18:55:41,533 [run_pretraining.py:  535]:	loss/mlm_loss, 7.447757720947266, 1227
[INFO] 2021-07-12 18:55:41,534 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2259999493835494e-05, 1227
[INFO] 2021-07-12 18:55:41,534 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1227
[INFO] 2021-07-12 18:55:41,534 [run_pretraining.py:  558]:	worker_index: 2, step: 1227, cost: 7.447758, mlm loss: 7.447758, speed: 0.955579 steps/s, speed: 7.644636 samples/s, speed: 3914.053561 tokens/s, learning rate: 1.226e-05, loss_scalings: 13421.773438, pp_loss: 7.858171
[INFO] 2021-07-12 18:55:41,534 [run_pretraining.py:  512]:	********exe.run_1227******* 
[INFO] 2021-07-12 18:55:42,598 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:42,599 [run_pretraining.py:  534]:	loss/total_loss, 7.842857837677002, 1228
[INFO] 2021-07-12 18:55:42,599 [run_pretraining.py:  535]:	loss/mlm_loss, 7.842857837677002, 1228
[INFO] 2021-07-12 18:55:42,599 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2269999388081487e-05, 1228
[INFO] 2021-07-12 18:55:42,599 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1228
[INFO] 2021-07-12 18:55:42,599 [run_pretraining.py:  558]:	worker_index: 2, step: 1228, cost: 7.842858, mlm loss: 7.842858, speed: 0.938957 steps/s, speed: 7.511656 samples/s, speed: 3845.967856 tokens/s, learning rate: 1.227e-05, loss_scalings: 13421.773438, pp_loss: 7.646217
[INFO] 2021-07-12 18:55:42,599 [run_pretraining.py:  512]:	********exe.run_1228******* 
[INFO] 2021-07-12 18:55:43,656 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:43,657 [run_pretraining.py:  534]:	loss/total_loss, 7.163946151733398, 1229
[INFO] 2021-07-12 18:55:43,657 [run_pretraining.py:  535]:	loss/mlm_loss, 7.163946151733398, 1229
[INFO] 2021-07-12 18:55:43,657 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.227999928232748e-05, 1229
[INFO] 2021-07-12 18:55:43,657 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1229
[INFO] 2021-07-12 18:55:43,657 [run_pretraining.py:  558]:	worker_index: 2, step: 1229, cost: 7.163946, mlm loss: 7.163946, speed: 0.946076 steps/s, speed: 7.568606 samples/s, speed: 3875.126413 tokens/s, learning rate: 1.228e-05, loss_scalings: 10737.418945, pp_loss: 7.386850
[INFO] 2021-07-12 18:55:43,657 [run_pretraining.py:  512]:	********exe.run_1229******* 
[INFO] 2021-07-12 18:55:44,714 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:44,715 [run_pretraining.py:  534]:	loss/total_loss, 8.429047584533691, 1230
[INFO] 2021-07-12 18:55:44,715 [run_pretraining.py:  535]:	loss/mlm_loss, 8.429047584533691, 1230
[INFO] 2021-07-12 18:55:44,715 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2290000086068176e-05, 1230
[INFO] 2021-07-12 18:55:44,715 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1230
[INFO] 2021-07-12 18:55:44,715 [run_pretraining.py:  558]:	worker_index: 2, step: 1230, cost: 8.429048, mlm loss: 8.429048, speed: 0.945770 steps/s, speed: 7.566161 samples/s, speed: 3873.874259 tokens/s, learning rate: 1.229e-05, loss_scalings: 10737.418945, pp_loss: 7.808599
[INFO] 2021-07-12 18:55:44,715 [run_pretraining.py:  512]:	********exe.run_1230******* 
[INFO] 2021-07-12 18:55:45,775 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:45,776 [run_pretraining.py:  534]:	loss/total_loss, 7.583366394042969, 1231
[INFO] 2021-07-12 18:55:45,776 [run_pretraining.py:  535]:	loss/mlm_loss, 7.583366394042969, 1231
[INFO] 2021-07-12 18:55:45,776 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2299999980314169e-05, 1231
[INFO] 2021-07-12 18:55:45,776 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1231
[INFO] 2021-07-12 18:55:45,776 [run_pretraining.py:  558]:	worker_index: 2, step: 1231, cost: 7.583366, mlm loss: 7.583366, speed: 0.942649 steps/s, speed: 7.541191 samples/s, speed: 3861.089870 tokens/s, learning rate: 1.230e-05, loss_scalings: 10737.418945, pp_loss: 7.737062
[INFO] 2021-07-12 18:55:45,776 [run_pretraining.py:  512]:	********exe.run_1231******* 
[INFO] 2021-07-12 18:55:46,829 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:46,829 [run_pretraining.py:  534]:	loss/total_loss, 7.676914691925049, 1232
[INFO] 2021-07-12 18:55:46,829 [run_pretraining.py:  535]:	loss/mlm_loss, 7.676914691925049, 1232
[INFO] 2021-07-12 18:55:46,829 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2309999874560162e-05, 1232
[INFO] 2021-07-12 18:55:46,829 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1232
[INFO] 2021-07-12 18:55:46,829 [run_pretraining.py:  558]:	worker_index: 2, step: 1232, cost: 7.676915, mlm loss: 7.676915, speed: 0.950158 steps/s, speed: 7.601263 samples/s, speed: 3891.846878 tokens/s, learning rate: 1.231e-05, loss_scalings: 10737.418945, pp_loss: 7.597464
[INFO] 2021-07-12 18:55:46,829 [run_pretraining.py:  512]:	********exe.run_1232******* 
[INFO] 2021-07-12 18:55:47,856 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:47,856 [run_pretraining.py:  534]:	loss/total_loss, 7.733925819396973, 1233
[INFO] 2021-07-12 18:55:47,856 [run_pretraining.py:  535]:	loss/mlm_loss, 7.733925819396973, 1233
[INFO] 2021-07-12 18:55:47,857 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2319999768806156e-05, 1233
[INFO] 2021-07-12 18:55:47,857 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1233
[INFO] 2021-07-12 18:55:47,857 [run_pretraining.py:  558]:	worker_index: 2, step: 1233, cost: 7.733926, mlm loss: 7.733926, speed: 0.973964 steps/s, speed: 7.791712 samples/s, speed: 3989.356646 tokens/s, learning rate: 1.232e-05, loss_scalings: 10737.418945, pp_loss: 7.817615
[INFO] 2021-07-12 18:55:47,857 [run_pretraining.py:  512]:	********exe.run_1233******* 
[INFO] 2021-07-12 18:55:48,931 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:48,937 [run_pretraining.py:  534]:	loss/total_loss, 8.342434883117676, 1234
[INFO] 2021-07-12 18:55:48,942 [run_pretraining.py:  535]:	loss/mlm_loss, 8.342434883117676, 1234
[INFO] 2021-07-12 18:55:48,947 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2329999663052149e-05, 1234
[INFO] 2021-07-12 18:55:48,952 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1234
[INFO] 2021-07-12 18:55:48,957 [run_pretraining.py:  558]:	worker_index: 2, step: 1234, cost: 8.342435, mlm loss: 8.342435, speed: 0.926288 steps/s, speed: 7.410305 samples/s, speed: 3794.076201 tokens/s, learning rate: 1.233e-05, loss_scalings: 10737.418945, pp_loss: 8.036673
[INFO] 2021-07-12 18:55:48,963 [run_pretraining.py:  512]:	********exe.run_1234******* 
[INFO] 2021-07-12 18:55:49,971 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:49,971 [run_pretraining.py:  534]:	loss/total_loss, 7.724706172943115, 1235
[INFO] 2021-07-12 18:55:49,971 [run_pretraining.py:  535]:	loss/mlm_loss, 7.724706172943115, 1235
[INFO] 2021-07-12 18:55:49,971 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2339999557298142e-05, 1235
[INFO] 2021-07-12 18:55:49,971 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1235
[INFO] 2021-07-12 18:55:49,972 [run_pretraining.py:  558]:	worker_index: 2, step: 1235, cost: 7.724706, mlm loss: 7.724706, speed: 0.992357 steps/s, speed: 7.938856 samples/s, speed: 4064.694238 tokens/s, learning rate: 1.234e-05, loss_scalings: 10737.418945, pp_loss: 6.969792
[INFO] 2021-07-12 18:55:49,972 [run_pretraining.py:  512]:	********exe.run_1235******* 
[INFO] 2021-07-12 18:55:50,890 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:50,891 [run_pretraining.py:  534]:	loss/total_loss, 7.592747211456299, 1236
[INFO] 2021-07-12 18:55:50,891 [run_pretraining.py:  535]:	loss/mlm_loss, 7.592747211456299, 1236
[INFO] 2021-07-12 18:55:50,891 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2349999451544136e-05, 1236
[INFO] 2021-07-12 18:55:50,891 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1236
[INFO] 2021-07-12 18:55:50,891 [run_pretraining.py:  558]:	worker_index: 2, step: 1236, cost: 7.592747, mlm loss: 7.592747, speed: 1.088030 steps/s, speed: 8.704241 samples/s, speed: 4456.571491 tokens/s, learning rate: 1.235e-05, loss_scalings: 10737.418945, pp_loss: 7.667888
[INFO] 2021-07-12 18:55:50,891 [run_pretraining.py:  512]:	********exe.run_1236******* 
[INFO] 2021-07-12 18:55:51,862 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:51,863 [run_pretraining.py:  534]:	loss/total_loss, 7.599075794219971, 1237
[INFO] 2021-07-12 18:55:51,863 [run_pretraining.py:  535]:	loss/mlm_loss, 7.599075794219971, 1237
[INFO] 2021-07-12 18:55:51,863 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.235999934579013e-05, 1237
[INFO] 2021-07-12 18:55:51,863 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1237
[INFO] 2021-07-12 18:55:51,863 [run_pretraining.py:  558]:	worker_index: 2, step: 1237, cost: 7.599076, mlm loss: 7.599076, speed: 1.029722 steps/s, speed: 8.237774 samples/s, speed: 4217.740468 tokens/s, learning rate: 1.236e-05, loss_scalings: 10737.418945, pp_loss: 7.843955
[INFO] 2021-07-12 18:55:51,863 [run_pretraining.py:  512]:	********exe.run_1237******* 
[INFO] 2021-07-12 18:55:52,818 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:52,818 [run_pretraining.py:  534]:	loss/total_loss, 7.856409072875977, 1238
[INFO] 2021-07-12 18:55:52,818 [run_pretraining.py:  535]:	loss/mlm_loss, 7.856409072875977, 1238
[INFO] 2021-07-12 18:55:52,819 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2370000149530824e-05, 1238
[INFO] 2021-07-12 18:55:52,819 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1238
[INFO] 2021-07-12 18:55:52,819 [run_pretraining.py:  558]:	worker_index: 2, step: 1238, cost: 7.856409, mlm loss: 7.856409, speed: 1.046981 steps/s, speed: 8.375849 samples/s, speed: 4288.434937 tokens/s, learning rate: 1.237e-05, loss_scalings: 10737.418945, pp_loss: 6.984518
[INFO] 2021-07-12 18:55:52,819 [run_pretraining.py:  512]:	********exe.run_1238******* 
[INFO] 2021-07-12 18:55:53,727 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:53,728 [run_pretraining.py:  534]:	loss/total_loss, 7.665363788604736, 1239
[INFO] 2021-07-12 18:55:53,728 [run_pretraining.py:  535]:	loss/mlm_loss, 7.665363788604736, 1239
[INFO] 2021-07-12 18:55:53,728 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2380000043776818e-05, 1239
[INFO] 2021-07-12 18:55:53,728 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1239
[INFO] 2021-07-12 18:55:53,728 [run_pretraining.py:  558]:	worker_index: 2, step: 1239, cost: 7.665364, mlm loss: 7.665364, speed: 1.100512 steps/s, speed: 8.804095 samples/s, speed: 4507.696776 tokens/s, learning rate: 1.238e-05, loss_scalings: 10737.418945, pp_loss: 7.668468
[INFO] 2021-07-12 18:55:53,728 [run_pretraining.py:  512]:	********exe.run_1239******* 
[INFO] 2021-07-12 18:55:54,639 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:54,640 [run_pretraining.py:  534]:	loss/total_loss, 7.581960678100586, 1240
[INFO] 2021-07-12 18:55:54,640 [run_pretraining.py:  535]:	loss/mlm_loss, 7.581960678100586, 1240
[INFO] 2021-07-12 18:55:54,640 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.238999902852811e-05, 1240
[INFO] 2021-07-12 18:55:54,640 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1240
[INFO] 2021-07-12 18:55:54,640 [run_pretraining.py:  558]:	worker_index: 2, step: 1240, cost: 7.581961, mlm loss: 7.581961, speed: 1.097045 steps/s, speed: 8.776356 samples/s, speed: 4493.494371 tokens/s, learning rate: 1.239e-05, loss_scalings: 10737.418945, pp_loss: 7.654478
[INFO] 2021-07-12 18:55:54,640 [run_pretraining.py:  512]:	********exe.run_1240******* 
[INFO] 2021-07-12 18:55:55,539 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:55,540 [run_pretraining.py:  534]:	loss/total_loss, 7.411183834075928, 1241
[INFO] 2021-07-12 18:55:55,540 [run_pretraining.py:  535]:	loss/mlm_loss, 7.411183834075928, 1241
[INFO] 2021-07-12 18:55:55,540 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2399999832268804e-05, 1241
[INFO] 2021-07-12 18:55:55,540 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1241
[INFO] 2021-07-12 18:55:55,540 [run_pretraining.py:  558]:	worker_index: 2, step: 1241, cost: 7.411184, mlm loss: 7.411184, speed: 1.111847 steps/s, speed: 8.894774 samples/s, speed: 4554.124293 tokens/s, learning rate: 1.240e-05, loss_scalings: 10737.418945, pp_loss: 8.045449
[INFO] 2021-07-12 18:55:55,540 [run_pretraining.py:  512]:	********exe.run_1241******* 
[INFO] 2021-07-12 18:55:56,454 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:56,455 [run_pretraining.py:  534]:	loss/total_loss, 7.761383056640625, 1242
[INFO] 2021-07-12 18:55:56,455 [run_pretraining.py:  535]:	loss/mlm_loss, 7.761383056640625, 1242
[INFO] 2021-07-12 18:55:56,455 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2409999726514798e-05, 1242
[INFO] 2021-07-12 18:55:56,455 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1242
[INFO] 2021-07-12 18:55:56,455 [run_pretraining.py:  558]:	worker_index: 2, step: 1242, cost: 7.761383, mlm loss: 7.761383, speed: 1.093550 steps/s, speed: 8.748404 samples/s, speed: 4479.182640 tokens/s, learning rate: 1.241e-05, loss_scalings: 10737.418945, pp_loss: 7.542394
[INFO] 2021-07-12 18:55:56,455 [run_pretraining.py:  512]:	********exe.run_1242******* 
[INFO] 2021-07-12 18:55:57,364 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:57,365 [run_pretraining.py:  534]:	loss/total_loss, 7.313677787780762, 1243
[INFO] 2021-07-12 18:55:57,365 [run_pretraining.py:  535]:	loss/mlm_loss, 7.313677787780762, 1243
[INFO] 2021-07-12 18:55:57,365 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2419999620760791e-05, 1243
[INFO] 2021-07-12 18:55:57,365 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1243
[INFO] 2021-07-12 18:55:57,365 [run_pretraining.py:  558]:	worker_index: 2, step: 1243, cost: 7.313678, mlm loss: 7.313678, speed: 1.099669 steps/s, speed: 8.797353 samples/s, speed: 4504.244636 tokens/s, learning rate: 1.242e-05, loss_scalings: 10737.418945, pp_loss: 7.210933
[INFO] 2021-07-12 18:55:57,365 [run_pretraining.py:  512]:	********exe.run_1243******* 
[INFO] 2021-07-12 18:55:58,285 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:58,285 [run_pretraining.py:  534]:	loss/total_loss, 7.128483295440674, 1244
[INFO] 2021-07-12 18:55:58,285 [run_pretraining.py:  535]:	loss/mlm_loss, 7.128483295440674, 1244
[INFO] 2021-07-12 18:55:58,285 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2430000424501486e-05, 1244
[INFO] 2021-07-12 18:55:58,285 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1244
[INFO] 2021-07-12 18:55:58,286 [run_pretraining.py:  558]:	worker_index: 2, step: 1244, cost: 7.128483, mlm loss: 7.128483, speed: 1.087223 steps/s, speed: 8.697786 samples/s, speed: 4453.266445 tokens/s, learning rate: 1.243e-05, loss_scalings: 10737.418945, pp_loss: 6.696759
[INFO] 2021-07-12 18:55:58,286 [run_pretraining.py:  512]:	********exe.run_1244******* 
[INFO] 2021-07-12 18:55:59,195 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:59,196 [run_pretraining.py:  534]:	loss/total_loss, 7.429890155792236, 1245
[INFO] 2021-07-12 18:55:59,196 [run_pretraining.py:  535]:	loss/mlm_loss, 7.429890155792236, 1245
[INFO] 2021-07-12 18:55:59,196 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2439999409252778e-05, 1245
[INFO] 2021-07-12 18:55:59,196 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1245
[INFO] 2021-07-12 18:55:59,196 [run_pretraining.py:  558]:	worker_index: 2, step: 1245, cost: 7.429890, mlm loss: 7.429890, speed: 1.098872 steps/s, speed: 8.790973 samples/s, speed: 4500.978193 tokens/s, learning rate: 1.244e-05, loss_scalings: 10737.418945, pp_loss: 7.847375
[INFO] 2021-07-12 18:55:59,196 [run_pretraining.py:  512]:	********exe.run_1245******* 
[INFO] 2021-07-12 18:56:00,106 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:00,107 [run_pretraining.py:  534]:	loss/total_loss, 7.899710178375244, 1246
[INFO] 2021-07-12 18:56:00,107 [run_pretraining.py:  535]:	loss/mlm_loss, 7.899710178375244, 1246
[INFO] 2021-07-12 18:56:00,107 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2449999303498771e-05, 1246
[INFO] 2021-07-12 18:56:00,107 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1246
[INFO] 2021-07-12 18:56:00,107 [run_pretraining.py:  558]:	worker_index: 2, step: 1246, cost: 7.899710, mlm loss: 7.899710, speed: 1.098613 steps/s, speed: 8.788901 samples/s, speed: 4499.917147 tokens/s, learning rate: 1.245e-05, loss_scalings: 10737.418945, pp_loss: 7.618232
[INFO] 2021-07-12 18:56:00,107 [run_pretraining.py:  512]:	********exe.run_1246******* 
[INFO] 2021-07-12 18:56:01,026 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:01,026 [run_pretraining.py:  534]:	loss/total_loss, 8.308760643005371, 1247
[INFO] 2021-07-12 18:56:01,026 [run_pretraining.py:  535]:	loss/mlm_loss, 8.308760643005371, 1247
[INFO] 2021-07-12 18:56:01,027 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2460000107239466e-05, 1247
[INFO] 2021-07-12 18:56:01,027 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1247
[INFO] 2021-07-12 18:56:01,027 [run_pretraining.py:  558]:	worker_index: 2, step: 1247, cost: 8.308761, mlm loss: 8.308761, speed: 1.087944 steps/s, speed: 8.703548 samples/s, speed: 4456.216608 tokens/s, learning rate: 1.246e-05, loss_scalings: 10737.418945, pp_loss: 7.907420
[INFO] 2021-07-12 18:56:01,027 [run_pretraining.py:  512]:	********exe.run_1247******* 
[INFO] 2021-07-12 18:56:01,939 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:01,939 [run_pretraining.py:  534]:	loss/total_loss, 7.819421768188477, 1248
[INFO] 2021-07-12 18:56:01,939 [run_pretraining.py:  535]:	loss/mlm_loss, 7.819421768188477, 1248
[INFO] 2021-07-12 18:56:01,939 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.247000000148546e-05, 1248
[INFO] 2021-07-12 18:56:01,939 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1248
[INFO] 2021-07-12 18:56:01,940 [run_pretraining.py:  558]:	worker_index: 2, step: 1248, cost: 7.819422, mlm loss: 7.819422, speed: 1.096219 steps/s, speed: 8.769755 samples/s, speed: 4490.114403 tokens/s, learning rate: 1.247e-05, loss_scalings: 10737.418945, pp_loss: 7.723885
[INFO] 2021-07-12 18:56:01,940 [run_pretraining.py:  512]:	********exe.run_1248******* 
[INFO] 2021-07-12 18:56:02,853 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:02,853 [run_pretraining.py:  534]:	loss/total_loss, 7.712121963500977, 1249
[INFO] 2021-07-12 18:56:02,853 [run_pretraining.py:  535]:	loss/mlm_loss, 7.712121963500977, 1249
[INFO] 2021-07-12 18:56:02,854 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2479998986236751e-05, 1249
[INFO] 2021-07-12 18:56:02,854 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1249
[INFO] 2021-07-12 18:56:02,854 [run_pretraining.py:  558]:	worker_index: 2, step: 1249, cost: 7.712122, mlm loss: 7.712122, speed: 1.094664 steps/s, speed: 8.757308 samples/s, speed: 4483.741793 tokens/s, learning rate: 1.248e-05, loss_scalings: 10737.418945, pp_loss: 7.661619
[INFO] 2021-07-12 18:56:02,854 [run_pretraining.py:  512]:	********exe.run_1249******* 
[INFO] 2021-07-12 18:56:03,767 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:03,767 [run_pretraining.py:  534]:	loss/total_loss, 7.420299530029297, 1250
[INFO] 2021-07-12 18:56:03,767 [run_pretraining.py:  535]:	loss/mlm_loss, 7.420299530029297, 1250
[INFO] 2021-07-12 18:56:03,767 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2489999789977446e-05, 1250
[INFO] 2021-07-12 18:56:03,767 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1250
[INFO] 2021-07-12 18:56:03,768 [run_pretraining.py:  558]:	worker_index: 2, step: 1250, cost: 7.420300, mlm loss: 7.420300, speed: 1.095026 steps/s, speed: 8.760205 samples/s, speed: 4485.224931 tokens/s, learning rate: 1.249e-05, loss_scalings: 10737.418945, pp_loss: 7.466777
[INFO] 2021-07-12 18:56:03,768 [run_pretraining.py:  512]:	********exe.run_1250******* 
[INFO] 2021-07-12 18:56:04,680 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:04,681 [run_pretraining.py:  534]:	loss/total_loss, 7.435884952545166, 1251
[INFO] 2021-07-12 18:56:04,681 [run_pretraining.py:  535]:	loss/mlm_loss, 7.435884952545166, 1251
[INFO] 2021-07-12 18:56:04,681 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.249999968422344e-05, 1251
[INFO] 2021-07-12 18:56:04,681 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1251
[INFO] 2021-07-12 18:56:04,681 [run_pretraining.py:  558]:	worker_index: 2, step: 1251, cost: 7.435885, mlm loss: 7.435885, speed: 1.095219 steps/s, speed: 8.761749 samples/s, speed: 4486.015480 tokens/s, learning rate: 1.250e-05, loss_scalings: 10737.418945, pp_loss: 7.675731
[INFO] 2021-07-12 18:56:04,681 [run_pretraining.py:  512]:	********exe.run_1251******* 
[INFO] 2021-07-12 18:56:05,610 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:05,611 [run_pretraining.py:  534]:	loss/total_loss, 7.387728691101074, 1252
[INFO] 2021-07-12 18:56:05,611 [run_pretraining.py:  535]:	loss/mlm_loss, 7.387728691101074, 1252
[INFO] 2021-07-12 18:56:05,611 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2509999578469433e-05, 1252
[INFO] 2021-07-12 18:56:05,611 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1252
[INFO] 2021-07-12 18:56:05,611 [run_pretraining.py:  558]:	worker_index: 2, step: 1252, cost: 7.387729, mlm loss: 7.387729, speed: 1.076321 steps/s, speed: 8.610567 samples/s, speed: 4408.610247 tokens/s, learning rate: 1.251e-05, loss_scalings: 10737.418945, pp_loss: 7.449542
[INFO] 2021-07-12 18:56:05,611 [run_pretraining.py:  512]:	********exe.run_1252******* 
[INFO] 2021-07-12 18:56:06,527 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:06,527 [run_pretraining.py:  534]:	loss/total_loss, 7.829673767089844, 1253
[INFO] 2021-07-12 18:56:06,527 [run_pretraining.py:  535]:	loss/mlm_loss, 7.829673767089844, 1253
[INFO] 2021-07-12 18:56:06,527 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2520000382210128e-05, 1253
[INFO] 2021-07-12 18:56:06,528 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1253
[INFO] 2021-07-12 18:56:06,528 [run_pretraining.py:  558]:	worker_index: 2, step: 1253, cost: 7.829674, mlm loss: 7.829674, speed: 1.091578 steps/s, speed: 8.732625 samples/s, speed: 4471.104211 tokens/s, learning rate: 1.252e-05, loss_scalings: 10737.418945, pp_loss: 7.633951
[INFO] 2021-07-12 18:56:06,528 [run_pretraining.py:  512]:	********exe.run_1253******* 
[INFO] 2021-07-12 18:56:07,432 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:07,433 [run_pretraining.py:  534]:	loss/total_loss, 6.598801612854004, 1254
[INFO] 2021-07-12 18:56:07,433 [run_pretraining.py:  535]:	loss/mlm_loss, 6.598801612854004, 1254
[INFO] 2021-07-12 18:56:07,433 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2530000276456121e-05, 1254
[INFO] 2021-07-12 18:56:07,433 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1254
[INFO] 2021-07-12 18:56:07,433 [run_pretraining.py:  558]:	worker_index: 2, step: 1254, cost: 6.598802, mlm loss: 6.598802, speed: 1.104985 steps/s, speed: 8.839882 samples/s, speed: 4526.019458 tokens/s, learning rate: 1.253e-05, loss_scalings: 10737.418945, pp_loss: 7.436201
[INFO] 2021-07-12 18:56:07,433 [run_pretraining.py:  512]:	********exe.run_1254******* 
[INFO] 2021-07-12 18:56:08,377 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:08,377 [run_pretraining.py:  534]:	loss/total_loss, 7.756561279296875, 1255
[INFO] 2021-07-12 18:56:08,378 [run_pretraining.py:  535]:	loss/mlm_loss, 7.756561279296875, 1255
[INFO] 2021-07-12 18:56:08,378 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2540000170702115e-05, 1255
[INFO] 2021-07-12 18:56:08,378 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1255
[INFO] 2021-07-12 18:56:08,378 [run_pretraining.py:  558]:	worker_index: 2, step: 1255, cost: 7.756561, mlm loss: 7.756561, speed: 1.059302 steps/s, speed: 8.474416 samples/s, speed: 4338.900836 tokens/s, learning rate: 1.254e-05, loss_scalings: 10737.418945, pp_loss: 7.361513
[INFO] 2021-07-12 18:56:08,378 [run_pretraining.py:  512]:	********exe.run_1255******* 
[INFO] 2021-07-12 18:56:09,339 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:09,340 [run_pretraining.py:  534]:	loss/total_loss, 8.074214935302734, 1256
[INFO] 2021-07-12 18:56:09,340 [run_pretraining.py:  535]:	loss/mlm_loss, 8.074214935302734, 1256
[INFO] 2021-07-12 18:56:09,340 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2549999155453406e-05, 1256
[INFO] 2021-07-12 18:56:09,340 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1256
[INFO] 2021-07-12 18:56:09,340 [run_pretraining.py:  558]:	worker_index: 2, step: 1256, cost: 8.074215, mlm loss: 8.074215, speed: 1.040062 steps/s, speed: 8.320496 samples/s, speed: 4260.094165 tokens/s, learning rate: 1.255e-05, loss_scalings: 10737.418945, pp_loss: 7.731285
[INFO] 2021-07-12 18:56:09,340 [run_pretraining.py:  512]:	********exe.run_1256******* 
[INFO] 2021-07-12 18:56:10,404 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:10,404 [run_pretraining.py:  534]:	loss/total_loss, 7.269237041473389, 1257
[INFO] 2021-07-12 18:56:10,404 [run_pretraining.py:  535]:	loss/mlm_loss, 7.269237041473389, 1257
[INFO] 2021-07-12 18:56:10,404 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.25599990496994e-05, 1257
[INFO] 2021-07-12 18:56:10,405 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1257
[INFO] 2021-07-12 18:56:10,405 [run_pretraining.py:  558]:	worker_index: 2, step: 1257, cost: 7.269237, mlm loss: 7.269237, speed: 0.939723 steps/s, speed: 7.517785 samples/s, speed: 3849.106092 tokens/s, learning rate: 1.256e-05, loss_scalings: 10737.418945, pp_loss: 7.591473
[INFO] 2021-07-12 18:56:10,405 [run_pretraining.py:  512]:	********exe.run_1257******* 
[INFO] 2021-07-12 18:56:11,464 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:11,465 [run_pretraining.py:  534]:	loss/total_loss, 7.794114112854004, 1258
[INFO] 2021-07-12 18:56:11,465 [run_pretraining.py:  535]:	loss/mlm_loss, 7.794114112854004, 1258
[INFO] 2021-07-12 18:56:11,465 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2569998943945393e-05, 1258
[INFO] 2021-07-12 18:56:11,465 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1258
[INFO] 2021-07-12 18:56:11,465 [run_pretraining.py:  558]:	worker_index: 2, step: 1258, cost: 7.794114, mlm loss: 7.794114, speed: 0.943480 steps/s, speed: 7.547839 samples/s, speed: 3864.493622 tokens/s, learning rate: 1.257e-05, loss_scalings: 10737.418945, pp_loss: 7.813352
[INFO] 2021-07-12 18:56:11,465 [run_pretraining.py:  512]:	********exe.run_1258******* 
[INFO] 2021-07-12 18:56:12,516 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:12,517 [run_pretraining.py:  534]:	loss/total_loss, 7.60124397277832, 1259
[INFO] 2021-07-12 18:56:12,517 [run_pretraining.py:  535]:	loss/mlm_loss, 7.60124397277832, 1259
[INFO] 2021-07-12 18:56:12,517 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2579999747686088e-05, 1259
[INFO] 2021-07-12 18:56:12,517 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1259
[INFO] 2021-07-12 18:56:12,517 [run_pretraining.py:  558]:	worker_index: 2, step: 1259, cost: 7.601244, mlm loss: 7.601244, speed: 0.951198 steps/s, speed: 7.609581 samples/s, speed: 3896.105449 tokens/s, learning rate: 1.258e-05, loss_scalings: 10737.418945, pp_loss: 6.894138
[INFO] 2021-07-12 18:56:12,517 [run_pretraining.py:  512]:	********exe.run_1259******* 
[INFO] 2021-07-12 18:56:13,445 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:13,445 [run_pretraining.py:  534]:	loss/total_loss, 7.541586875915527, 1260
[INFO] 2021-07-12 18:56:13,445 [run_pretraining.py:  535]:	loss/mlm_loss, 7.541586875915527, 1260
[INFO] 2021-07-12 18:56:13,445 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2589999641932081e-05, 1260
[INFO] 2021-07-12 18:56:13,445 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1260
[INFO] 2021-07-12 18:56:13,446 [run_pretraining.py:  558]:	worker_index: 2, step: 1260, cost: 7.541587, mlm loss: 7.541587, speed: 1.077726 steps/s, speed: 8.621806 samples/s, speed: 4414.364829 tokens/s, learning rate: 1.259e-05, loss_scalings: 10737.418945, pp_loss: 7.650653
[INFO] 2021-07-12 18:56:13,446 [run_pretraining.py:  512]:	********exe.run_1260******* 
[INFO] 2021-07-12 18:56:14,368 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:14,368 [run_pretraining.py:  534]:	loss/total_loss, 8.057520866394043, 1261
[INFO] 2021-07-12 18:56:14,368 [run_pretraining.py:  535]:	loss/mlm_loss, 8.057520866394043, 1261
[INFO] 2021-07-12 18:56:14,368 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2599999536178075e-05, 1261
[INFO] 2021-07-12 18:56:14,368 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1261
[INFO] 2021-07-12 18:56:14,369 [run_pretraining.py:  558]:	worker_index: 2, step: 1261, cost: 8.057521, mlm loss: 8.057521, speed: 1.084122 steps/s, speed: 8.672980 samples/s, speed: 4440.565673 tokens/s, learning rate: 1.260e-05, loss_scalings: 10737.418945, pp_loss: 7.652252
[INFO] 2021-07-12 18:56:14,369 [run_pretraining.py:  512]:	********exe.run_1261******* 
[INFO] 2021-07-12 18:56:15,282 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:15,283 [run_pretraining.py:  534]:	loss/total_loss, 7.6431379318237305, 1262
[INFO] 2021-07-12 18:56:15,283 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6431379318237305, 1262
[INFO] 2021-07-12 18:56:15,283 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.261000033991877e-05, 1262
[INFO] 2021-07-12 18:56:15,283 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1262
[INFO] 2021-07-12 18:56:15,283 [run_pretraining.py:  558]:	worker_index: 2, step: 1262, cost: 7.643138, mlm loss: 7.643138, speed: 1.094257 steps/s, speed: 8.754059 samples/s, speed: 4482.078381 tokens/s, learning rate: 1.261e-05, loss_scalings: 10737.418945, pp_loss: 7.738263
[INFO] 2021-07-12 18:56:15,283 [run_pretraining.py:  512]:	********exe.run_1262******* 
[INFO] 2021-07-12 18:56:16,207 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:16,207 [run_pretraining.py:  534]:	loss/total_loss, 7.859426021575928, 1263
[INFO] 2021-07-12 18:56:16,208 [run_pretraining.py:  535]:	loss/mlm_loss, 7.859426021575928, 1263
[INFO] 2021-07-12 18:56:16,208 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2620000234164763e-05, 1263
[INFO] 2021-07-12 18:56:16,208 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1263
[INFO] 2021-07-12 18:56:16,208 [run_pretraining.py:  558]:	worker_index: 2, step: 1263, cost: 7.859426, mlm loss: 7.859426, speed: 1.082036 steps/s, speed: 8.656291 samples/s, speed: 4432.020894 tokens/s, learning rate: 1.262e-05, loss_scalings: 10737.418945, pp_loss: 7.702714
[INFO] 2021-07-12 18:56:16,208 [run_pretraining.py:  512]:	********exe.run_1263******* 
[INFO] 2021-07-12 18:56:17,112 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:17,113 [run_pretraining.py:  534]:	loss/total_loss, 6.9806060791015625, 1264
[INFO] 2021-07-12 18:56:17,113 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9806060791015625, 1264
[INFO] 2021-07-12 18:56:17,113 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2630000128410757e-05, 1264
[INFO] 2021-07-12 18:56:17,113 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1264
[INFO] 2021-07-12 18:56:17,113 [run_pretraining.py:  558]:	worker_index: 2, step: 1264, cost: 6.980606, mlm loss: 6.980606, speed: 1.105338 steps/s, speed: 8.842703 samples/s, speed: 4527.463885 tokens/s, learning rate: 1.263e-05, loss_scalings: 10737.418945, pp_loss: 7.539695
[INFO] 2021-07-12 18:56:17,113 [run_pretraining.py:  512]:	********exe.run_1264******* 
[INFO] 2021-07-12 18:56:18,014 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:18,015 [run_pretraining.py:  534]:	loss/total_loss, 7.951221466064453, 1265
[INFO] 2021-07-12 18:56:18,015 [run_pretraining.py:  535]:	loss/mlm_loss, 7.951221466064453, 1265
[INFO] 2021-07-12 18:56:18,015 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2639999113162048e-05, 1265
[INFO] 2021-07-12 18:56:18,015 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1265
[INFO] 2021-07-12 18:56:18,015 [run_pretraining.py:  558]:	worker_index: 2, step: 1265, cost: 7.951221, mlm loss: 7.951221, speed: 1.109302 steps/s, speed: 8.874416 samples/s, speed: 4543.700839 tokens/s, learning rate: 1.264e-05, loss_scalings: 10737.418945, pp_loss: 7.798291
[INFO] 2021-07-12 18:56:18,015 [run_pretraining.py:  512]:	********exe.run_1265******* 
[INFO] 2021-07-12 18:56:18,941 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:18,941 [run_pretraining.py:  534]:	loss/total_loss, 7.904437065124512, 1266
[INFO] 2021-07-12 18:56:18,941 [run_pretraining.py:  535]:	loss/mlm_loss, 7.904437065124512, 1266
[INFO] 2021-07-12 18:56:18,941 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2649999007408042e-05, 1266
[INFO] 2021-07-12 18:56:18,941 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1266
[INFO] 2021-07-12 18:56:18,941 [run_pretraining.py:  558]:	worker_index: 2, step: 1266, cost: 7.904437, mlm loss: 7.904437, speed: 1.080320 steps/s, speed: 8.642561 samples/s, speed: 4424.991239 tokens/s, learning rate: 1.265e-05, loss_scalings: 10737.418945, pp_loss: 7.738184
[INFO] 2021-07-12 18:56:18,941 [run_pretraining.py:  512]:	********exe.run_1266******* 
[INFO] 2021-07-12 18:56:19,860 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:19,861 [run_pretraining.py:  534]:	loss/total_loss, 7.606968402862549, 1267
[INFO] 2021-07-12 18:56:19,861 [run_pretraining.py:  535]:	loss/mlm_loss, 7.606968402862549, 1267
[INFO] 2021-07-12 18:56:19,861 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2659999811148737e-05, 1267
[INFO] 2021-07-12 18:56:19,861 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1267
[INFO] 2021-07-12 18:56:19,861 [run_pretraining.py:  558]:	worker_index: 2, step: 1267, cost: 7.606968, mlm loss: 7.606968, speed: 1.087778 steps/s, speed: 8.702223 samples/s, speed: 4455.538210 tokens/s, learning rate: 1.266e-05, loss_scalings: 10737.418945, pp_loss: 7.706537
[INFO] 2021-07-12 18:56:19,861 [run_pretraining.py:  512]:	********exe.run_1267******* 
[INFO] 2021-07-12 18:56:20,787 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:20,787 [run_pretraining.py:  534]:	loss/total_loss, 7.594521522521973, 1268
[INFO] 2021-07-12 18:56:20,787 [run_pretraining.py:  535]:	loss/mlm_loss, 7.594521522521973, 1268
[INFO] 2021-07-12 18:56:20,787 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.266999970539473e-05, 1268
[INFO] 2021-07-12 18:56:20,787 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1268
[INFO] 2021-07-12 18:56:20,787 [run_pretraining.py:  558]:	worker_index: 2, step: 1268, cost: 7.594522, mlm loss: 7.594522, speed: 1.080435 steps/s, speed: 8.643478 samples/s, speed: 4425.460860 tokens/s, learning rate: 1.267e-05, loss_scalings: 10737.418945, pp_loss: 7.262908
[INFO] 2021-07-12 18:56:20,788 [run_pretraining.py:  512]:	********exe.run_1268******* 
[INFO] 2021-07-12 18:56:21,708 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:21,708 [run_pretraining.py:  534]:	loss/total_loss, 7.774872779846191, 1269
[INFO] 2021-07-12 18:56:21,708 [run_pretraining.py:  535]:	loss/mlm_loss, 7.774872779846191, 1269
[INFO] 2021-07-12 18:56:21,708 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2679999599640723e-05, 1269
[INFO] 2021-07-12 18:56:21,708 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1269
[INFO] 2021-07-12 18:56:21,708 [run_pretraining.py:  558]:	worker_index: 2, step: 1269, cost: 7.774873, mlm loss: 7.774873, speed: 1.086497 steps/s, speed: 8.691973 samples/s, speed: 4450.290212 tokens/s, learning rate: 1.268e-05, loss_scalings: 10737.418945, pp_loss: 7.642257
[INFO] 2021-07-12 18:56:21,708 [run_pretraining.py:  512]:	********exe.run_1269******* 
[INFO] 2021-07-12 18:56:22,626 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:22,627 [run_pretraining.py:  534]:	loss/total_loss, 7.1345086097717285, 1270
[INFO] 2021-07-12 18:56:22,627 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1345086097717285, 1270
[INFO] 2021-07-12 18:56:22,627 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2689999493886717e-05, 1270
[INFO] 2021-07-12 18:56:22,627 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1270
[INFO] 2021-07-12 18:56:22,627 [run_pretraining.py:  558]:	worker_index: 2, step: 1270, cost: 7.134509, mlm loss: 7.134509, speed: 1.089077 steps/s, speed: 8.712613 samples/s, speed: 4460.857671 tokens/s, learning rate: 1.269e-05, loss_scalings: 10737.418945, pp_loss: 7.617709
[INFO] 2021-07-12 18:56:22,627 [run_pretraining.py:  512]:	********exe.run_1270******* 
[INFO] 2021-07-12 18:56:23,545 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:23,545 [run_pretraining.py:  534]:	loss/total_loss, 7.540661811828613, 1271
[INFO] 2021-07-12 18:56:23,545 [run_pretraining.py:  535]:	loss/mlm_loss, 7.540661811828613, 1271
[INFO] 2021-07-12 18:56:23,545 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2700000297627412e-05, 1271
[INFO] 2021-07-12 18:56:23,545 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1271
[INFO] 2021-07-12 18:56:23,546 [run_pretraining.py:  558]:	worker_index: 2, step: 1271, cost: 7.540662, mlm loss: 7.540662, speed: 1.089704 steps/s, speed: 8.717631 samples/s, speed: 4463.427077 tokens/s, learning rate: 1.270e-05, loss_scalings: 10737.418945, pp_loss: 7.844148
[INFO] 2021-07-12 18:56:23,546 [run_pretraining.py:  512]:	********exe.run_1271******* 
[INFO] 2021-07-12 18:56:24,464 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:24,465 [run_pretraining.py:  534]:	loss/total_loss, 7.457313060760498, 1272
[INFO] 2021-07-12 18:56:24,465 [run_pretraining.py:  535]:	loss/mlm_loss, 7.457313060760498, 1272
[INFO] 2021-07-12 18:56:24,465 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2710000191873405e-05, 1272
[INFO] 2021-07-12 18:56:24,465 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1272
[INFO] 2021-07-12 18:56:24,465 [run_pretraining.py:  558]:	worker_index: 2, step: 1272, cost: 7.457313, mlm loss: 7.457313, speed: 1.088106 steps/s, speed: 8.704849 samples/s, speed: 4456.882494 tokens/s, learning rate: 1.271e-05, loss_scalings: 10737.418945, pp_loss: 7.534339
[INFO] 2021-07-12 18:56:24,465 [run_pretraining.py:  512]:	********exe.run_1272******* 
[INFO] 2021-07-12 18:56:25,381 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:25,381 [run_pretraining.py:  534]:	loss/total_loss, 8.149967193603516, 1273
[INFO] 2021-07-12 18:56:25,381 [run_pretraining.py:  535]:	loss/mlm_loss, 8.149967193603516, 1273
[INFO] 2021-07-12 18:56:25,381 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2720000086119398e-05, 1273
[INFO] 2021-07-12 18:56:25,382 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1273
[INFO] 2021-07-12 18:56:25,382 [run_pretraining.py:  558]:	worker_index: 2, step: 1273, cost: 8.149967, mlm loss: 8.149967, speed: 1.091800 steps/s, speed: 8.734398 samples/s, speed: 4472.012016 tokens/s, learning rate: 1.272e-05, loss_scalings: 10737.418945, pp_loss: 7.705276
[INFO] 2021-07-12 18:56:25,382 [run_pretraining.py:  512]:	********exe.run_1273******* 
[INFO] 2021-07-12 18:56:26,302 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:26,302 [run_pretraining.py:  534]:	loss/total_loss, 7.510288715362549, 1274
[INFO] 2021-07-12 18:56:26,302 [run_pretraining.py:  535]:	loss/mlm_loss, 7.510288715362549, 1274
[INFO] 2021-07-12 18:56:26,303 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.272999907087069e-05, 1274
[INFO] 2021-07-12 18:56:26,303 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1274
[INFO] 2021-07-12 18:56:26,303 [run_pretraining.py:  558]:	worker_index: 2, step: 1274, cost: 7.510289, mlm loss: 7.510289, speed: 1.086463 steps/s, speed: 8.691707 samples/s, speed: 4450.154185 tokens/s, learning rate: 1.273e-05, loss_scalings: 10737.418945, pp_loss: 7.532319
[INFO] 2021-07-12 18:56:26,303 [run_pretraining.py:  512]:	********exe.run_1274******* 
[INFO] 2021-07-12 18:56:27,203 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:27,203 [run_pretraining.py:  534]:	loss/total_loss, 7.6656880378723145, 1275
[INFO] 2021-07-12 18:56:27,203 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6656880378723145, 1275
[INFO] 2021-07-12 18:56:27,204 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2739998965116683e-05, 1275
[INFO] 2021-07-12 18:56:27,204 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1275
[INFO] 2021-07-12 18:56:27,204 [run_pretraining.py:  558]:	worker_index: 2, step: 1275, cost: 7.665688, mlm loss: 7.665688, speed: 1.110618 steps/s, speed: 8.884943 samples/s, speed: 4549.090886 tokens/s, learning rate: 1.274e-05, loss_scalings: 10737.418945, pp_loss: 7.506980
[INFO] 2021-07-12 18:56:27,204 [run_pretraining.py:  512]:	********exe.run_1275******* 
[INFO] 2021-07-12 18:56:28,106 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:28,107 [run_pretraining.py:  534]:	loss/total_loss, 7.76222038269043, 1276
[INFO] 2021-07-12 18:56:28,107 [run_pretraining.py:  535]:	loss/mlm_loss, 7.76222038269043, 1276
[INFO] 2021-07-12 18:56:28,107 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2749999768857379e-05, 1276
[INFO] 2021-07-12 18:56:28,107 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1276
[INFO] 2021-07-12 18:56:28,107 [run_pretraining.py:  558]:	worker_index: 2, step: 1276, cost: 7.762220, mlm loss: 7.762220, speed: 1.107417 steps/s, speed: 8.859333 samples/s, speed: 4535.978580 tokens/s, learning rate: 1.275e-05, loss_scalings: 10737.418945, pp_loss: 7.720122
[INFO] 2021-07-12 18:56:28,107 [run_pretraining.py:  512]:	********exe.run_1276******* 
[INFO] 2021-07-12 18:56:29,018 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:29,018 [run_pretraining.py:  534]:	loss/total_loss, 7.773325443267822, 1277
[INFO] 2021-07-12 18:56:29,018 [run_pretraining.py:  535]:	loss/mlm_loss, 7.773325443267822, 1277
[INFO] 2021-07-12 18:56:29,018 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2759999663103372e-05, 1277
[INFO] 2021-07-12 18:56:29,019 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1277
[INFO] 2021-07-12 18:56:29,019 [run_pretraining.py:  558]:	worker_index: 2, step: 1277, cost: 7.773325, mlm loss: 7.773325, speed: 1.098071 steps/s, speed: 8.784568 samples/s, speed: 4497.698822 tokens/s, learning rate: 1.276e-05, loss_scalings: 10737.418945, pp_loss: 7.812995
[INFO] 2021-07-12 18:56:29,019 [run_pretraining.py:  512]:	********exe.run_1277******* 
[INFO] 2021-07-12 18:56:29,917 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:29,917 [run_pretraining.py:  534]:	loss/total_loss, 7.299291610717773, 1278
[INFO] 2021-07-12 18:56:29,917 [run_pretraining.py:  535]:	loss/mlm_loss, 7.299291610717773, 1278
[INFO] 2021-07-12 18:56:29,918 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2769999557349365e-05, 1278
[INFO] 2021-07-12 18:56:29,918 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1278
[INFO] 2021-07-12 18:56:29,918 [run_pretraining.py:  558]:	worker_index: 2, step: 1278, cost: 7.299292, mlm loss: 7.299292, speed: 1.112898 steps/s, speed: 8.903181 samples/s, speed: 4558.428509 tokens/s, learning rate: 1.277e-05, loss_scalings: 10737.418945, pp_loss: 7.536864
[INFO] 2021-07-12 18:56:29,918 [run_pretraining.py:  512]:	********exe.run_1278******* 
[INFO] 2021-07-12 18:56:30,832 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:30,834 [run_pretraining.py:  534]:	loss/total_loss, 7.139839172363281, 1279
[INFO] 2021-07-12 18:56:30,837 [run_pretraining.py:  535]:	loss/mlm_loss, 7.139839172363281, 1279
[INFO] 2021-07-12 18:56:30,838 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.278000036109006e-05, 1279
[INFO] 2021-07-12 18:56:30,841 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1279
[INFO] 2021-07-12 18:56:30,843 [run_pretraining.py:  558]:	worker_index: 2, step: 1279, cost: 7.139839, mlm loss: 7.139839, speed: 1.091521 steps/s, speed: 8.732166 samples/s, speed: 4470.869173 tokens/s, learning rate: 1.278e-05, loss_scalings: 10737.418945, pp_loss: 7.554609
[INFO] 2021-07-12 18:56:30,844 [run_pretraining.py:  512]:	********exe.run_1279******* 
[INFO] 2021-07-12 18:56:31,733 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:31,733 [run_pretraining.py:  534]:	loss/total_loss, 7.522773265838623, 1280
[INFO] 2021-07-12 18:56:31,733 [run_pretraining.py:  535]:	loss/mlm_loss, 7.522773265838623, 1280
[INFO] 2021-07-12 18:56:31,733 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2790000255336054e-05, 1280
[INFO] 2021-07-12 18:56:31,734 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1280
[INFO] 2021-07-12 18:56:31,734 [run_pretraining.py:  558]:	worker_index: 2, step: 1280, cost: 7.522773, mlm loss: 7.522773, speed: 1.124210 steps/s, speed: 8.993683 samples/s, speed: 4604.765562 tokens/s, learning rate: 1.279e-05, loss_scalings: 10737.418945, pp_loss: 7.491736
[INFO] 2021-07-12 18:56:31,734 [run_pretraining.py:  512]:	********exe.run_1280******* 
[INFO] 2021-07-12 18:56:32,718 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:32,719 [run_pretraining.py:  534]:	loss/total_loss, 6.989659309387207, 1281
[INFO] 2021-07-12 18:56:32,719 [run_pretraining.py:  535]:	loss/mlm_loss, 6.989659309387207, 1281
[INFO] 2021-07-12 18:56:32,719 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2800000149582047e-05, 1281
[INFO] 2021-07-12 18:56:32,719 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1281
[INFO] 2021-07-12 18:56:32,719 [run_pretraining.py:  558]:	worker_index: 2, step: 1281, cost: 6.989659, mlm loss: 6.989659, speed: 1.015138 steps/s, speed: 8.121103 samples/s, speed: 4158.004700 tokens/s, learning rate: 1.280e-05, loss_scalings: 10737.418945, pp_loss: 7.719496
[INFO] 2021-07-12 18:56:32,719 [run_pretraining.py:  512]:	********exe.run_1281******* 
[INFO] 2021-07-12 18:56:33,773 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:33,773 [run_pretraining.py:  534]:	loss/total_loss, 7.54404354095459, 1282
[INFO] 2021-07-12 18:56:33,773 [run_pretraining.py:  535]:	loss/mlm_loss, 7.54404354095459, 1282
[INFO] 2021-07-12 18:56:33,774 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2809999134333339e-05, 1282
[INFO] 2021-07-12 18:56:33,774 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1282
[INFO] 2021-07-12 18:56:33,774 [run_pretraining.py:  558]:	worker_index: 2, step: 1282, cost: 7.544044, mlm loss: 7.544044, speed: 0.948903 steps/s, speed: 7.591221 samples/s, speed: 3886.704898 tokens/s, learning rate: 1.281e-05, loss_scalings: 10737.418945, pp_loss: 7.498806
[INFO] 2021-07-12 18:56:33,774 [run_pretraining.py:  512]:	********exe.run_1282******* 
[INFO] 2021-07-12 18:56:34,829 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:34,829 [run_pretraining.py:  534]:	loss/total_loss, 7.493405342102051, 1283
[INFO] 2021-07-12 18:56:34,829 [run_pretraining.py:  535]:	loss/mlm_loss, 7.493405342102051, 1283
[INFO] 2021-07-12 18:56:34,829 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2819999028579332e-05, 1283
[INFO] 2021-07-12 18:56:34,829 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1283
[INFO] 2021-07-12 18:56:34,830 [run_pretraining.py:  558]:	worker_index: 2, step: 1283, cost: 7.493405, mlm loss: 7.493405, speed: 0.947671 steps/s, speed: 7.581370 samples/s, speed: 3881.661559 tokens/s, learning rate: 1.282e-05, loss_scalings: 10737.418945, pp_loss: 7.586258
[INFO] 2021-07-12 18:56:34,830 [run_pretraining.py:  512]:	********exe.run_1283******* 
[INFO] 2021-07-12 18:56:35,886 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:35,886 [run_pretraining.py:  534]:	loss/total_loss, 7.379193305969238, 1284
[INFO] 2021-07-12 18:56:35,886 [run_pretraining.py:  535]:	loss/mlm_loss, 7.379193305969238, 1284
[INFO] 2021-07-12 18:56:35,886 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2829998922825325e-05, 1284
[INFO] 2021-07-12 18:56:35,886 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1284
[INFO] 2021-07-12 18:56:35,887 [run_pretraining.py:  558]:	worker_index: 2, step: 1284, cost: 7.379193, mlm loss: 7.379193, speed: 0.946652 steps/s, speed: 7.573217 samples/s, speed: 3877.486996 tokens/s, learning rate: 1.283e-05, loss_scalings: 10737.418945, pp_loss: 7.695394
[INFO] 2021-07-12 18:56:35,887 [run_pretraining.py:  512]:	********exe.run_1284******* 
[INFO] 2021-07-12 18:56:36,937 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:36,937 [run_pretraining.py:  534]:	loss/total_loss, 7.6494598388671875, 1285
[INFO] 2021-07-12 18:56:36,937 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6494598388671875, 1285
[INFO] 2021-07-12 18:56:36,937 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.283999972656602e-05, 1285
[INFO] 2021-07-12 18:56:36,937 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1285
[INFO] 2021-07-12 18:56:36,937 [run_pretraining.py:  558]:	worker_index: 2, step: 1285, cost: 7.649460, mlm loss: 7.649460, speed: 0.952121 steps/s, speed: 7.616969 samples/s, speed: 3899.888152 tokens/s, learning rate: 1.284e-05, loss_scalings: 10737.418945, pp_loss: 7.543836
[INFO] 2021-07-12 18:56:36,937 [run_pretraining.py:  512]:	********exe.run_1285******* 
[INFO] 2021-07-12 18:56:37,989 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:37,989 [run_pretraining.py:  534]:	loss/total_loss, 6.995339870452881, 1286
[INFO] 2021-07-12 18:56:37,989 [run_pretraining.py:  535]:	loss/mlm_loss, 6.995339870452881, 1286
[INFO] 2021-07-12 18:56:37,990 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2849999620812014e-05, 1286
[INFO] 2021-07-12 18:56:37,990 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1286
[INFO] 2021-07-12 18:56:37,990 [run_pretraining.py:  558]:	worker_index: 2, step: 1286, cost: 6.995340, mlm loss: 6.995340, speed: 0.950800 steps/s, speed: 7.606402 samples/s, speed: 3894.477707 tokens/s, learning rate: 1.285e-05, loss_scalings: 10737.418945, pp_loss: 7.401054
[INFO] 2021-07-12 18:56:37,990 [run_pretraining.py:  512]:	********exe.run_1286******* 
[INFO] 2021-07-12 18:56:39,048 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:39,048 [run_pretraining.py:  534]:	loss/total_loss, 7.531738758087158, 1287
[INFO] 2021-07-12 18:56:39,048 [run_pretraining.py:  535]:	loss/mlm_loss, 7.531738758087158, 1287
[INFO] 2021-07-12 18:56:39,048 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2859999515058007e-05, 1287
[INFO] 2021-07-12 18:56:39,049 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1287
[INFO] 2021-07-12 18:56:39,049 [run_pretraining.py:  558]:	worker_index: 2, step: 1287, cost: 7.531739, mlm loss: 7.531739, speed: 0.944904 steps/s, speed: 7.559233 samples/s, speed: 3870.327537 tokens/s, learning rate: 1.286e-05, loss_scalings: 10737.418945, pp_loss: 7.501105
[INFO] 2021-07-12 18:56:39,049 [run_pretraining.py:  512]:	********exe.run_1287******* 
[INFO] 2021-07-12 18:56:40,092 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:40,093 [run_pretraining.py:  534]:	loss/total_loss, 7.680417060852051, 1288
[INFO] 2021-07-12 18:56:40,093 [run_pretraining.py:  535]:	loss/mlm_loss, 7.680417060852051, 1288
[INFO] 2021-07-12 18:56:40,093 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2870000318798702e-05, 1288
[INFO] 2021-07-12 18:56:40,093 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1288
[INFO] 2021-07-12 18:56:40,093 [run_pretraining.py:  558]:	worker_index: 2, step: 1288, cost: 7.680417, mlm loss: 7.680417, speed: 0.958176 steps/s, speed: 7.665407 samples/s, speed: 3924.688623 tokens/s, learning rate: 1.287e-05, loss_scalings: 10737.418945, pp_loss: 7.756228
[INFO] 2021-07-12 18:56:40,093 [run_pretraining.py:  512]:	********exe.run_1288******* 
[INFO] 2021-07-12 18:56:41,212 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:41,213 [run_pretraining.py:  534]:	loss/total_loss, 7.587691783905029, 1289
[INFO] 2021-07-12 18:56:41,213 [run_pretraining.py:  535]:	loss/mlm_loss, 7.587691783905029, 1289
[INFO] 2021-07-12 18:56:41,213 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2880000213044696e-05, 1289
[INFO] 2021-07-12 18:56:41,213 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1289
[INFO] 2021-07-12 18:56:41,213 [run_pretraining.py:  558]:	worker_index: 2, step: 1289, cost: 7.587692, mlm loss: 7.587692, speed: 0.893210 steps/s, speed: 7.145680 samples/s, speed: 3658.587937 tokens/s, learning rate: 1.288e-05, loss_scalings: 10737.418945, pp_loss: 7.529172
[INFO] 2021-07-12 18:56:41,213 [run_pretraining.py:  512]:	********exe.run_1289******* 
[INFO] 2021-07-12 18:56:42,108 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:42,108 [run_pretraining.py:  534]:	loss/total_loss, 6.9946184158325195, 1290
[INFO] 2021-07-12 18:56:42,108 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9946184158325195, 1290
[INFO] 2021-07-12 18:56:42,109 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2890000107290689e-05, 1290
[INFO] 2021-07-12 18:56:42,109 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1290
[INFO] 2021-07-12 18:56:42,109 [run_pretraining.py:  558]:	worker_index: 2, step: 1290, cost: 6.994618, mlm loss: 6.994618, speed: 1.117281 steps/s, speed: 8.938250 samples/s, speed: 4576.384023 tokens/s, learning rate: 1.289e-05, loss_scalings: 10737.418945, pp_loss: 7.438664
[INFO] 2021-07-12 18:56:42,109 [run_pretraining.py:  512]:	********exe.run_1290******* 
[INFO] 2021-07-12 18:56:43,016 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:43,017 [run_pretraining.py:  534]:	loss/total_loss, 7.813446998596191, 1291
[INFO] 2021-07-12 18:56:43,017 [run_pretraining.py:  535]:	loss/mlm_loss, 7.813446998596191, 1291
[INFO] 2021-07-12 18:56:43,017 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.289999909204198e-05, 1291
[INFO] 2021-07-12 18:56:43,017 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1291
[INFO] 2021-07-12 18:56:43,017 [run_pretraining.py:  558]:	worker_index: 2, step: 1291, cost: 7.813447, mlm loss: 7.813447, speed: 1.101407 steps/s, speed: 8.811258 samples/s, speed: 4511.363888 tokens/s, learning rate: 1.290e-05, loss_scalings: 10737.418945, pp_loss: 7.448955
[INFO] 2021-07-12 18:56:43,017 [run_pretraining.py:  512]:	********exe.run_1291******* 
[INFO] 2021-07-12 18:56:43,921 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:43,921 [run_pretraining.py:  534]:	loss/total_loss, 7.94101619720459, 1292
[INFO] 2021-07-12 18:56:43,921 [run_pretraining.py:  535]:	loss/mlm_loss, 7.94101619720459, 1292
[INFO] 2021-07-12 18:56:43,921 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2909998986287974e-05, 1292
[INFO] 2021-07-12 18:56:43,921 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1292
[INFO] 2021-07-12 18:56:43,921 [run_pretraining.py:  558]:	worker_index: 2, step: 1292, cost: 7.941016, mlm loss: 7.941016, speed: 1.106687 steps/s, speed: 8.853494 samples/s, speed: 4532.988876 tokens/s, learning rate: 1.291e-05, loss_scalings: 10737.418945, pp_loss: 7.377585
[INFO] 2021-07-12 18:56:43,921 [run_pretraining.py:  512]:	********exe.run_1292******* 
[INFO] 2021-07-12 18:56:44,823 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:44,824 [run_pretraining.py:  534]:	loss/total_loss, 7.450584411621094, 1293
[INFO] 2021-07-12 18:56:44,824 [run_pretraining.py:  535]:	loss/mlm_loss, 7.450584411621094, 1293
[INFO] 2021-07-12 18:56:44,824 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2919998880533967e-05, 1293
[INFO] 2021-07-12 18:56:44,824 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1293
[INFO] 2021-07-12 18:56:44,824 [run_pretraining.py:  558]:	worker_index: 2, step: 1293, cost: 7.450584, mlm loss: 7.450584, speed: 1.108714 steps/s, speed: 8.869712 samples/s, speed: 4541.292688 tokens/s, learning rate: 1.292e-05, loss_scalings: 10737.418945, pp_loss: 7.482897
[INFO] 2021-07-12 18:56:44,824 [run_pretraining.py:  512]:	********exe.run_1293******* 
[INFO] 2021-07-12 18:56:45,732 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:45,733 [run_pretraining.py:  534]:	loss/total_loss, 7.758953094482422, 1294
[INFO] 2021-07-12 18:56:45,733 [run_pretraining.py:  535]:	loss/mlm_loss, 7.758953094482422, 1294
[INFO] 2021-07-12 18:56:45,733 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2929999684274662e-05, 1294
[INFO] 2021-07-12 18:56:45,733 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1294
[INFO] 2021-07-12 18:56:45,733 [run_pretraining.py:  558]:	worker_index: 2, step: 1294, cost: 7.758953, mlm loss: 7.758953, speed: 1.100552 steps/s, speed: 8.804414 samples/s, speed: 4507.860000 tokens/s, learning rate: 1.293e-05, loss_scalings: 10737.418945, pp_loss: 7.549974
[INFO] 2021-07-12 18:56:45,733 [run_pretraining.py:  512]:	********exe.run_1294******* 
[INFO] 2021-07-12 18:56:46,632 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:46,633 [run_pretraining.py:  534]:	loss/total_loss, 7.650385856628418, 1295
[INFO] 2021-07-12 18:56:46,633 [run_pretraining.py:  535]:	loss/mlm_loss, 7.650385856628418, 1295
[INFO] 2021-07-12 18:56:46,633 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2939999578520656e-05, 1295
[INFO] 2021-07-12 18:56:46,633 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1295
[INFO] 2021-07-12 18:56:46,633 [run_pretraining.py:  558]:	worker_index: 2, step: 1295, cost: 7.650386, mlm loss: 7.650386, speed: 1.112129 steps/s, speed: 8.897029 samples/s, speed: 4555.278697 tokens/s, learning rate: 1.294e-05, loss_scalings: 10737.418945, pp_loss: 7.524374
[INFO] 2021-07-12 18:56:46,633 [run_pretraining.py:  512]:	********exe.run_1295******* 
[INFO] 2021-07-12 18:56:47,535 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:47,536 [run_pretraining.py:  534]:	loss/total_loss, 7.236392021179199, 1296
[INFO] 2021-07-12 18:56:47,536 [run_pretraining.py:  535]:	loss/mlm_loss, 7.236392021179199, 1296
[INFO] 2021-07-12 18:56:47,536 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2949999472766649e-05, 1296
[INFO] 2021-07-12 18:56:47,536 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1296
[INFO] 2021-07-12 18:56:47,536 [run_pretraining.py:  558]:	worker_index: 2, step: 1296, cost: 7.236392, mlm loss: 7.236392, speed: 1.108092 steps/s, speed: 8.864737 samples/s, speed: 4538.745591 tokens/s, learning rate: 1.295e-05, loss_scalings: 10737.418945, pp_loss: 6.901274
[INFO] 2021-07-12 18:56:47,536 [run_pretraining.py:  512]:	********exe.run_1296******* 
[INFO] 2021-07-12 18:56:48,442 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:48,442 [run_pretraining.py:  534]:	loss/total_loss, 7.792137145996094, 1297
[INFO] 2021-07-12 18:56:48,442 [run_pretraining.py:  535]:	loss/mlm_loss, 7.792137145996094, 1297
[INFO] 2021-07-12 18:56:48,442 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2960000276507344e-05, 1297
[INFO] 2021-07-12 18:56:48,443 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1297
[INFO] 2021-07-12 18:56:48,443 [run_pretraining.py:  558]:	worker_index: 2, step: 1297, cost: 7.792137, mlm loss: 7.792137, speed: 1.103686 steps/s, speed: 8.829486 samples/s, speed: 4520.696999 tokens/s, learning rate: 1.296e-05, loss_scalings: 10737.418945, pp_loss: 7.446535
[INFO] 2021-07-12 18:56:48,443 [run_pretraining.py:  512]:	********exe.run_1297******* 
[INFO] 2021-07-12 18:56:49,337 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:49,338 [run_pretraining.py:  534]:	loss/total_loss, 7.3850297927856445, 1298
[INFO] 2021-07-12 18:56:49,338 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3850297927856445, 1298
[INFO] 2021-07-12 18:56:49,338 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2970000170753337e-05, 1298
[INFO] 2021-07-12 18:56:49,338 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1298
[INFO] 2021-07-12 18:56:49,338 [run_pretraining.py:  558]:	worker_index: 2, step: 1298, cost: 7.385030, mlm loss: 7.385030, speed: 1.117444 steps/s, speed: 8.939553 samples/s, speed: 4577.050946 tokens/s, learning rate: 1.297e-05, loss_scalings: 10737.418945, pp_loss: 7.557703
[INFO] 2021-07-12 18:56:49,338 [run_pretraining.py:  512]:	********exe.run_1298******* 
[INFO] 2021-07-12 18:56:50,244 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:50,244 [run_pretraining.py:  534]:	loss/total_loss, 7.186263084411621, 1299
[INFO] 2021-07-12 18:56:50,244 [run_pretraining.py:  535]:	loss/mlm_loss, 7.186263084411621, 1299
[INFO] 2021-07-12 18:56:50,245 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.298000006499933e-05, 1299
[INFO] 2021-07-12 18:56:50,245 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1299
[INFO] 2021-07-12 18:56:50,245 [run_pretraining.py:  558]:	worker_index: 2, step: 1299, cost: 7.186263, mlm loss: 7.186263, speed: 1.103800 steps/s, speed: 8.830397 samples/s, speed: 4521.163359 tokens/s, learning rate: 1.298e-05, loss_scalings: 10737.418945, pp_loss: 7.608583
[INFO] 2021-07-12 18:56:50,245 [run_pretraining.py:  512]:	********exe.run_1299******* 
[INFO] 2021-07-12 18:56:51,232 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:51,232 [run_pretraining.py:  534]:	loss/total_loss, 7.495275497436523, 1300
[INFO] 2021-07-12 18:56:51,232 [run_pretraining.py:  535]:	loss/mlm_loss, 7.495275497436523, 1300
[INFO] 2021-07-12 18:56:51,232 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2989999049750622e-05, 1300
[INFO] 2021-07-12 18:56:51,233 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1300
[INFO] 2021-07-12 18:56:51,233 [run_pretraining.py:  558]:	worker_index: 2, step: 1300, cost: 7.495275, mlm loss: 7.495275, speed: 1.012838 steps/s, speed: 8.102708 samples/s, speed: 4148.586496 tokens/s, learning rate: 1.299e-05, loss_scalings: 10737.418945, pp_loss: 7.817587
[INFO] 2021-07-12 18:56:51,233 [run_pretraining.py:  512]:	********exe.run_1300******* 
[INFO] 2021-07-12 18:56:52,158 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:52,159 [run_pretraining.py:  534]:	loss/total_loss, 8.04621696472168, 1301
[INFO] 2021-07-12 18:56:52,159 [run_pretraining.py:  535]:	loss/mlm_loss, 8.04621696472168, 1301
[INFO] 2021-07-12 18:56:52,159 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2999998943996616e-05, 1301
[INFO] 2021-07-12 18:56:52,159 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1301
[INFO] 2021-07-12 18:56:52,159 [run_pretraining.py:  558]:	worker_index: 2, step: 1301, cost: 8.046217, mlm loss: 8.046217, speed: 1.079900 steps/s, speed: 8.639199 samples/s, speed: 4423.269765 tokens/s, learning rate: 1.300e-05, loss_scalings: 10737.418945, pp_loss: 7.724694
[INFO] 2021-07-12 18:56:52,159 [run_pretraining.py:  512]:	********exe.run_1301******* 
[INFO] 2021-07-12 18:56:53,062 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:53,062 [run_pretraining.py:  534]:	loss/total_loss, 6.8048095703125, 1302
[INFO] 2021-07-12 18:56:53,062 [run_pretraining.py:  535]:	loss/mlm_loss, 6.8048095703125, 1302
[INFO] 2021-07-12 18:56:53,062 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.300999974773731e-05, 1302
[INFO] 2021-07-12 18:56:53,062 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1302
[INFO] 2021-07-12 18:56:53,063 [run_pretraining.py:  558]:	worker_index: 2, step: 1302, cost: 6.804810, mlm loss: 6.804810, speed: 1.107711 steps/s, speed: 8.861685 samples/s, speed: 4537.182516 tokens/s, learning rate: 1.301e-05, loss_scalings: 10737.418945, pp_loss: 7.312005
[INFO] 2021-07-12 18:56:53,063 [run_pretraining.py:  512]:	********exe.run_1302******* 
[INFO] 2021-07-12 18:56:53,965 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:53,966 [run_pretraining.py:  534]:	loss/total_loss, 7.615635871887207, 1303
[INFO] 2021-07-12 18:56:53,966 [run_pretraining.py:  535]:	loss/mlm_loss, 7.615635871887207, 1303
[INFO] 2021-07-12 18:56:53,966 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3019999641983304e-05, 1303
[INFO] 2021-07-12 18:56:53,966 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1303
[INFO] 2021-07-12 18:56:53,966 [run_pretraining.py:  558]:	worker_index: 2, step: 1303, cost: 7.615636, mlm loss: 7.615636, speed: 1.107633 steps/s, speed: 8.861067 samples/s, speed: 4536.866196 tokens/s, learning rate: 1.302e-05, loss_scalings: 10737.418945, pp_loss: 7.607827
[INFO] 2021-07-12 18:56:53,966 [run_pretraining.py:  512]:	********exe.run_1303******* 
[INFO] 2021-07-12 18:56:54,868 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:54,869 [run_pretraining.py:  534]:	loss/total_loss, 7.669185161590576, 1304
[INFO] 2021-07-12 18:56:54,869 [run_pretraining.py:  535]:	loss/mlm_loss, 7.669185161590576, 1304
[INFO] 2021-07-12 18:56:54,869 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3029999536229298e-05, 1304
[INFO] 2021-07-12 18:56:54,869 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1304
[INFO] 2021-07-12 18:56:54,869 [run_pretraining.py:  558]:	worker_index: 2, step: 1304, cost: 7.669185, mlm loss: 7.669185, speed: 1.108175 steps/s, speed: 8.865403 samples/s, speed: 4539.086158 tokens/s, learning rate: 1.303e-05, loss_scalings: 10737.418945, pp_loss: 7.593683
[INFO] 2021-07-12 18:56:54,869 [run_pretraining.py:  512]:	********exe.run_1304******* 
[INFO] 2021-07-12 18:56:55,779 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:55,780 [run_pretraining.py:  534]:	loss/total_loss, 7.797979354858398, 1305
[INFO] 2021-07-12 18:56:55,780 [run_pretraining.py:  535]:	loss/mlm_loss, 7.797979354858398, 1305
[INFO] 2021-07-12 18:56:55,780 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3039999430475291e-05, 1305
[INFO] 2021-07-12 18:56:55,780 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1305
[INFO] 2021-07-12 18:56:55,780 [run_pretraining.py:  558]:	worker_index: 2, step: 1305, cost: 7.797979, mlm loss: 7.797979, speed: 1.098510 steps/s, speed: 8.788084 samples/s, speed: 4499.498761 tokens/s, learning rate: 1.304e-05, loss_scalings: 10737.418945, pp_loss: 7.708854
[INFO] 2021-07-12 18:56:55,780 [run_pretraining.py:  512]:	********exe.run_1305******* 
[INFO] 2021-07-12 18:56:56,677 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:56,677 [run_pretraining.py:  534]:	loss/total_loss, 7.547177791595459, 1306
[INFO] 2021-07-12 18:56:56,677 [run_pretraining.py:  535]:	loss/mlm_loss, 7.547177791595459, 1306
[INFO] 2021-07-12 18:56:56,678 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3050000234215986e-05, 1306
[INFO] 2021-07-12 18:56:56,678 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1306
[INFO] 2021-07-12 18:56:56,678 [run_pretraining.py:  558]:	worker_index: 2, step: 1306, cost: 7.547178, mlm loss: 7.547178, speed: 1.114513 steps/s, speed: 8.916107 samples/s, speed: 4565.046882 tokens/s, learning rate: 1.305e-05, loss_scalings: 10737.418945, pp_loss: 7.713959
[INFO] 2021-07-12 18:56:56,678 [run_pretraining.py:  512]:	********exe.run_1306******* 
[INFO] 2021-07-12 18:56:57,606 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:57,606 [run_pretraining.py:  534]:	loss/total_loss, 7.3345818519592285, 1307
[INFO] 2021-07-12 18:56:57,606 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3345818519592285, 1307
[INFO] 2021-07-12 18:56:57,606 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.306000012846198e-05, 1307
[INFO] 2021-07-12 18:56:57,606 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1307
[INFO] 2021-07-12 18:56:57,606 [run_pretraining.py:  558]:	worker_index: 2, step: 1307, cost: 7.334582, mlm loss: 7.334582, speed: 1.077403 steps/s, speed: 8.619224 samples/s, speed: 4413.042666 tokens/s, learning rate: 1.306e-05, loss_scalings: 10737.418945, pp_loss: 7.820532
[INFO] 2021-07-12 18:56:57,607 [run_pretraining.py:  512]:	********exe.run_1307******* 
[INFO] 2021-07-12 18:56:58,519 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:58,519 [run_pretraining.py:  534]:	loss/total_loss, 7.450155258178711, 1308
[INFO] 2021-07-12 18:56:58,520 [run_pretraining.py:  535]:	loss/mlm_loss, 7.450155258178711, 1308
[INFO] 2021-07-12 18:56:58,520 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3070000022707973e-05, 1308
[INFO] 2021-07-12 18:56:58,520 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1308
[INFO] 2021-07-12 18:56:58,520 [run_pretraining.py:  558]:	worker_index: 2, step: 1308, cost: 7.450155, mlm loss: 7.450155, speed: 1.095617 steps/s, speed: 8.764935 samples/s, speed: 4487.646649 tokens/s, learning rate: 1.307e-05, loss_scalings: 10737.418945, pp_loss: 7.692254
[INFO] 2021-07-12 18:56:58,520 [run_pretraining.py:  512]:	********exe.run_1308******* 
[INFO] 2021-07-12 18:56:59,499 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:59,499 [run_pretraining.py:  534]:	loss/total_loss, 8.159311294555664, 1309
[INFO] 2021-07-12 18:56:59,500 [run_pretraining.py:  535]:	loss/mlm_loss, 8.159311294555664, 1309
[INFO] 2021-07-12 18:56:59,500 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3079999007459264e-05, 1309
[INFO] 2021-07-12 18:56:59,500 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1309
[INFO] 2021-07-12 18:56:59,500 [run_pretraining.py:  558]:	worker_index: 2, step: 1309, cost: 8.159311, mlm loss: 8.159311, speed: 1.021055 steps/s, speed: 8.168442 samples/s, speed: 4182.242274 tokens/s, learning rate: 1.308e-05, loss_scalings: 10737.418945, pp_loss: 7.790907
[INFO] 2021-07-12 18:56:59,500 [run_pretraining.py:  512]:	********exe.run_1309******* 
[INFO] 2021-07-12 18:57:00,558 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:57:00,558 [run_pretraining.py:  534]:	loss/total_loss, 8.178881645202637, 1310
[INFO] 2021-07-12 18:57:00,558 [run_pretraining.py:  535]:	loss/mlm_loss, 8.178881645202637, 1310
[INFO] 2021-07-12 18:57:00,559 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3089998901705258e-05, 1310
[INFO] 2021-07-12 18:57:00,559 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1310
[INFO] 2021-07-12 18:57:00,559 [run_pretraining.py:  558]:	worker_index: 2, step: 1310, cost: 8.178882, mlm loss: 8.178882, speed: 0.944948 steps/s, speed: 7.559584 samples/s, speed: 3870.507161 tokens/s, learning rate: 1.309e-05, loss_scalings: 10737.418945, pp_loss: 7.865814
[INFO] 2021-07-12 18:57:00,559 [run_pretraining.py:  512]:	********exe.run_1310******* 
[INFO] 2021-07-12 18:57:28,156 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:57:28,156 [run_pretraining.py:  534]:	loss/total_loss, 8.028671264648438, 1311
[INFO] 2021-07-12 18:57:28,156 [run_pretraining.py:  535]:	loss/mlm_loss, 8.028671264648438, 1311
[INFO] 2021-07-12 18:57:28,157 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3099999705445953e-05, 1311
[INFO] 2021-07-12 18:57:28,157 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1311
[INFO] 2021-07-12 18:57:28,157 [run_pretraining.py:  558]:	worker_index: 2, step: 1311, cost: 8.028671, mlm loss: 8.028671, speed: 0.036235 steps/s, speed: 0.289883 samples/s, speed: 148.419926 tokens/s, learning rate: 1.310e-05, loss_scalings: 10737.418945, pp_loss: 7.530785
[INFO] 2021-07-12 18:57:28,157 [run_pretraining.py:  512]:	********exe.run_1311******* 
[INFO] 2021-07-12 18:57:56,318 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:57:56,319 [run_pretraining.py:  534]:	loss/total_loss, 7.599447250366211, 1312
[INFO] 2021-07-12 18:57:56,319 [run_pretraining.py:  535]:	loss/mlm_loss, 7.599447250366211, 1312
[INFO] 2021-07-12 18:57:56,319 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3109999599691946e-05, 1312
[INFO] 2021-07-12 18:57:56,319 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1312
[INFO] 2021-07-12 18:57:56,319 [run_pretraining.py:  558]:	worker_index: 2, step: 1312, cost: 7.599447, mlm loss: 7.599447, speed: 0.035509 steps/s, speed: 0.284071 samples/s, speed: 145.444462 tokens/s, learning rate: 1.311e-05, loss_scalings: 10737.418945, pp_loss: 7.374271
[INFO] 2021-07-12 18:57:56,319 [run_pretraining.py:  512]:	********exe.run_1312******* 
[INFO] 2021-07-12 18:57:57,256 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:57:57,257 [run_pretraining.py:  534]:	loss/total_loss, 7.341687202453613, 1313
[INFO] 2021-07-12 18:57:57,257 [run_pretraining.py:  535]:	loss/mlm_loss, 7.341687202453613, 1313
[INFO] 2021-07-12 18:57:57,257 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.311999949393794e-05, 1313
[INFO] 2021-07-12 18:57:57,257 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1313
[INFO] 2021-07-12 18:57:57,257 [run_pretraining.py:  558]:	worker_index: 2, step: 1313, cost: 7.341687, mlm loss: 7.341687, speed: 1.067128 steps/s, speed: 8.537022 samples/s, speed: 4370.955260 tokens/s, learning rate: 1.312e-05, loss_scalings: 10737.418945, pp_loss: 7.503040
[INFO] 2021-07-12 18:57:57,257 [run_pretraining.py:  512]:	********exe.run_1313******* 
[INFO] 2021-07-12 18:57:58,174 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:57:58,175 [run_pretraining.py:  534]:	loss/total_loss, 8.047611236572266, 1314
[INFO] 2021-07-12 18:57:58,175 [run_pretraining.py:  535]:	loss/mlm_loss, 8.047611236572266, 1314
[INFO] 2021-07-12 18:57:58,175 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3130000297678635e-05, 1314
[INFO] 2021-07-12 18:57:58,175 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1314
[INFO] 2021-07-12 18:57:58,175 [run_pretraining.py:  558]:	worker_index: 2, step: 1314, cost: 8.047611, mlm loss: 8.047611, speed: 1.089615 steps/s, speed: 8.716922 samples/s, speed: 4463.064144 tokens/s, learning rate: 1.313e-05, loss_scalings: 10737.418945, pp_loss: 7.764611
[INFO] 2021-07-12 18:57:58,175 [run_pretraining.py:  512]:	********exe.run_1314******* 
[INFO] 2021-07-12 18:57:59,132 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:57:59,133 [run_pretraining.py:  534]:	loss/total_loss, 7.346445560455322, 1315
[INFO] 2021-07-12 18:57:59,133 [run_pretraining.py:  535]:	loss/mlm_loss, 7.346445560455322, 1315
[INFO] 2021-07-12 18:57:59,133 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3140000191924628e-05, 1315
[INFO] 2021-07-12 18:57:59,133 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1315
[INFO] 2021-07-12 18:57:59,133 [run_pretraining.py:  558]:	worker_index: 2, step: 1315, cost: 7.346446, mlm loss: 7.346446, speed: 1.044814 steps/s, speed: 8.358513 samples/s, speed: 4279.558745 tokens/s, learning rate: 1.314e-05, loss_scalings: 10737.418945, pp_loss: 7.216531
[INFO] 2021-07-12 18:57:59,133 [run_pretraining.py:  512]:	********exe.run_1315******* 
[INFO] 2021-07-12 18:58:00,193 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:00,194 [run_pretraining.py:  534]:	loss/total_loss, 7.629926681518555, 1316
[INFO] 2021-07-12 18:58:00,194 [run_pretraining.py:  535]:	loss/mlm_loss, 7.629926681518555, 1316
[INFO] 2021-07-12 18:58:00,194 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3150000086170621e-05, 1316
[INFO] 2021-07-12 18:58:00,194 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1316
[INFO] 2021-07-12 18:58:00,194 [run_pretraining.py:  558]:	worker_index: 2, step: 1316, cost: 7.629927, mlm loss: 7.629927, speed: 0.942970 steps/s, speed: 7.543763 samples/s, speed: 3862.406712 tokens/s, learning rate: 1.315e-05, loss_scalings: 10737.418945, pp_loss: 8.108685
[INFO] 2021-07-12 18:58:00,194 [run_pretraining.py:  512]:	********exe.run_1316******* 
[INFO] 2021-07-12 18:58:01,256 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:01,256 [run_pretraining.py:  534]:	loss/total_loss, 4.3397722244262695, 1317
[INFO] 2021-07-12 18:58:01,257 [run_pretraining.py:  535]:	loss/mlm_loss, 4.3397722244262695, 1317
[INFO] 2021-07-12 18:58:01,257 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3159999980416615e-05, 1317
[INFO] 2021-07-12 18:58:01,257 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1317
[INFO] 2021-07-12 18:58:01,257 [run_pretraining.py:  558]:	worker_index: 2, step: 1317, cost: 4.339772, mlm loss: 4.339772, speed: 0.941468 steps/s, speed: 7.531747 samples/s, speed: 3856.254696 tokens/s, learning rate: 1.316e-05, loss_scalings: 10737.418945, pp_loss: 6.727599
[INFO] 2021-07-12 18:58:01,257 [run_pretraining.py:  512]:	********exe.run_1317******* 
[INFO] 2021-07-12 18:58:02,344 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:02,344 [run_pretraining.py:  534]:	loss/total_loss, 7.6266913414001465, 1318
[INFO] 2021-07-12 18:58:02,344 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6266913414001465, 1318
[INFO] 2021-07-12 18:58:02,344 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3169998965167906e-05, 1318
[INFO] 2021-07-12 18:58:02,345 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1318
[INFO] 2021-07-12 18:58:02,345 [run_pretraining.py:  558]:	worker_index: 2, step: 1318, cost: 7.626691, mlm loss: 7.626691, speed: 0.919846 steps/s, speed: 7.358767 samples/s, speed: 3767.688684 tokens/s, learning rate: 1.317e-05, loss_scalings: 10737.418945, pp_loss: 7.652698
[INFO] 2021-07-12 18:58:02,345 [run_pretraining.py:  512]:	********exe.run_1318******* 
[INFO] 2021-07-12 18:58:03,408 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:03,409 [run_pretraining.py:  534]:	loss/total_loss, 7.2836012840271, 1319
[INFO] 2021-07-12 18:58:03,409 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2836012840271, 1319
[INFO] 2021-07-12 18:58:03,409 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.31799988594139e-05, 1319
[INFO] 2021-07-12 18:58:03,409 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1319
[INFO] 2021-07-12 18:58:03,409 [run_pretraining.py:  558]:	worker_index: 2, step: 1319, cost: 7.283601, mlm loss: 7.283601, speed: 0.939946 steps/s, speed: 7.519566 samples/s, speed: 3850.017846 tokens/s, learning rate: 1.318e-05, loss_scalings: 10737.418945, pp_loss: 7.586635
[INFO] 2021-07-12 18:58:03,409 [run_pretraining.py:  512]:	********exe.run_1319******* 
[INFO] 2021-07-12 18:58:04,478 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:04,478 [run_pretraining.py:  534]:	loss/total_loss, 7.4889020919799805, 1320
[INFO] 2021-07-12 18:58:04,478 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4889020919799805, 1320
[INFO] 2021-07-12 18:58:04,479 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3189999663154595e-05, 1320
[INFO] 2021-07-12 18:58:04,479 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1320
[INFO] 2021-07-12 18:58:04,479 [run_pretraining.py:  558]:	worker_index: 2, step: 1320, cost: 7.488902, mlm loss: 7.488902, speed: 0.935483 steps/s, speed: 7.483862 samples/s, speed: 3831.737102 tokens/s, learning rate: 1.319e-05, loss_scalings: 10737.418945, pp_loss: 7.436802
[INFO] 2021-07-12 18:58:04,479 [run_pretraining.py:  512]:	********exe.run_1320******* 
[INFO] 2021-07-12 18:58:05,527 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:05,527 [run_pretraining.py:  534]:	loss/total_loss, 7.577017307281494, 1321
[INFO] 2021-07-12 18:58:05,527 [run_pretraining.py:  535]:	loss/mlm_loss, 7.577017307281494, 1321
[INFO] 2021-07-12 18:58:05,527 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3199999557400588e-05, 1321
[INFO] 2021-07-12 18:58:05,528 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1321
[INFO] 2021-07-12 18:58:05,528 [run_pretraining.py:  558]:	worker_index: 2, step: 1321, cost: 7.577017, mlm loss: 7.577017, speed: 0.953895 steps/s, speed: 7.631162 samples/s, speed: 3907.154829 tokens/s, learning rate: 1.320e-05, loss_scalings: 10737.418945, pp_loss: 7.275115
[INFO] 2021-07-12 18:58:05,528 [run_pretraining.py:  512]:	********exe.run_1321******* 
[INFO] 2021-07-12 18:58:06,585 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:06,586 [run_pretraining.py:  534]:	loss/total_loss, 7.4523396492004395, 1322
[INFO] 2021-07-12 18:58:06,586 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4523396492004395, 1322
[INFO] 2021-07-12 18:58:06,586 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3209999451646581e-05, 1322
[INFO] 2021-07-12 18:58:06,586 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1322
[INFO] 2021-07-12 18:58:06,586 [run_pretraining.py:  558]:	worker_index: 2, step: 1322, cost: 7.452340, mlm loss: 7.452340, speed: 0.945351 steps/s, speed: 7.562808 samples/s, speed: 3872.157686 tokens/s, learning rate: 1.321e-05, loss_scalings: 10737.418945, pp_loss: 7.765130
[INFO] 2021-07-12 18:58:06,586 [run_pretraining.py:  512]:	********exe.run_1322******* 
[INFO] 2021-07-12 18:58:07,652 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:07,652 [run_pretraining.py:  534]:	loss/total_loss, 7.765166282653809, 1323
[INFO] 2021-07-12 18:58:07,652 [run_pretraining.py:  535]:	loss/mlm_loss, 7.765166282653809, 1323
[INFO] 2021-07-12 18:58:07,653 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3220000255387276e-05, 1323
[INFO] 2021-07-12 18:58:07,653 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1323
[INFO] 2021-07-12 18:58:07,653 [run_pretraining.py:  558]:	worker_index: 2, step: 1323, cost: 7.765166, mlm loss: 7.765166, speed: 0.938001 steps/s, speed: 7.504004 samples/s, speed: 3842.050101 tokens/s, learning rate: 1.322e-05, loss_scalings: 10737.418945, pp_loss: 7.642061
[INFO] 2021-07-12 18:58:07,653 [run_pretraining.py:  512]:	********exe.run_1323******* 
[INFO] 2021-07-12 18:58:08,706 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:08,706 [run_pretraining.py:  534]:	loss/total_loss, 8.237180709838867, 1324
[INFO] 2021-07-12 18:58:08,707 [run_pretraining.py:  535]:	loss/mlm_loss, 8.237180709838867, 1324
[INFO] 2021-07-12 18:58:08,707 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.323000014963327e-05, 1324
[INFO] 2021-07-12 18:58:08,707 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1324
[INFO] 2021-07-12 18:58:08,707 [run_pretraining.py:  558]:	worker_index: 2, step: 1324, cost: 8.237181, mlm loss: 8.237181, speed: 0.949185 steps/s, speed: 7.593480 samples/s, speed: 3887.861539 tokens/s, learning rate: 1.323e-05, loss_scalings: 10737.418945, pp_loss: 7.682754
[INFO] 2021-07-12 18:58:08,707 [run_pretraining.py:  512]:	********exe.run_1324******* 
[INFO] 2021-07-12 18:58:09,770 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:09,771 [run_pretraining.py:  534]:	loss/total_loss, 7.4701690673828125, 1325
[INFO] 2021-07-12 18:58:09,771 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4701690673828125, 1325
[INFO] 2021-07-12 18:58:09,771 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3240000043879263e-05, 1325
[INFO] 2021-07-12 18:58:09,771 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1325
[INFO] 2021-07-12 18:58:09,771 [run_pretraining.py:  558]:	worker_index: 2, step: 1325, cost: 7.470169, mlm loss: 7.470169, speed: 0.940026 steps/s, speed: 7.520207 samples/s, speed: 3850.345735 tokens/s, learning rate: 1.324e-05, loss_scalings: 10737.418945, pp_loss: 7.742070
[INFO] 2021-07-12 18:58:09,771 [run_pretraining.py:  512]:	********exe.run_1325******* 
[INFO] 2021-07-12 18:58:10,832 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:10,832 [run_pretraining.py:  534]:	loss/total_loss, 7.922638893127441, 1326
[INFO] 2021-07-12 18:58:10,832 [run_pretraining.py:  535]:	loss/mlm_loss, 7.922638893127441, 1326
[INFO] 2021-07-12 18:58:10,832 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3249999028630555e-05, 1326
[INFO] 2021-07-12 18:58:10,832 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1326
[INFO] 2021-07-12 18:58:10,832 [run_pretraining.py:  558]:	worker_index: 2, step: 1326, cost: 7.922639, mlm loss: 7.922639, speed: 0.942885 steps/s, speed: 7.543081 samples/s, speed: 3862.057666 tokens/s, learning rate: 1.325e-05, loss_scalings: 10737.418945, pp_loss: 7.711246
[INFO] 2021-07-12 18:58:10,832 [run_pretraining.py:  512]:	********exe.run_1326******* 
[INFO] 2021-07-12 18:58:11,893 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:11,893 [run_pretraining.py:  534]:	loss/total_loss, 7.744196891784668, 1327
[INFO] 2021-07-12 18:58:11,893 [run_pretraining.py:  535]:	loss/mlm_loss, 7.744196891784668, 1327
[INFO] 2021-07-12 18:58:11,894 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3259998922876548e-05, 1327
[INFO] 2021-07-12 18:58:11,894 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1327
[INFO] 2021-07-12 18:58:11,894 [run_pretraining.py:  558]:	worker_index: 2, step: 1327, cost: 7.744197, mlm loss: 7.744197, speed: 0.942709 steps/s, speed: 7.541674 samples/s, speed: 3861.337198 tokens/s, learning rate: 1.326e-05, loss_scalings: 10737.418945, pp_loss: 7.600880
[INFO] 2021-07-12 18:58:11,894 [run_pretraining.py:  512]:	********exe.run_1327******* 
[INFO] 2021-07-12 18:58:12,968 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:12,968 [run_pretraining.py:  534]:	loss/total_loss, 7.4864702224731445, 1328
[INFO] 2021-07-12 18:58:12,968 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4864702224731445, 1328
[INFO] 2021-07-12 18:58:12,969 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3269999726617243e-05, 1328
[INFO] 2021-07-12 18:58:12,969 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1328
[INFO] 2021-07-12 18:58:12,969 [run_pretraining.py:  558]:	worker_index: 2, step: 1328, cost: 7.486470, mlm loss: 7.486470, speed: 0.930804 steps/s, speed: 7.446431 samples/s, speed: 3812.572928 tokens/s, learning rate: 1.327e-05, loss_scalings: 10737.418945, pp_loss: 7.787533
[INFO] 2021-07-12 18:58:12,969 [run_pretraining.py:  512]:	********exe.run_1328******* 
[INFO] 2021-07-12 18:58:14,048 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:14,049 [run_pretraining.py:  534]:	loss/total_loss, 7.119763374328613, 1329
[INFO] 2021-07-12 18:58:14,049 [run_pretraining.py:  535]:	loss/mlm_loss, 7.119763374328613, 1329
[INFO] 2021-07-12 18:58:14,049 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3279999620863236e-05, 1329
[INFO] 2021-07-12 18:58:14,049 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1329
[INFO] 2021-07-12 18:58:14,049 [run_pretraining.py:  558]:	worker_index: 2, step: 1329, cost: 7.119763, mlm loss: 7.119763, speed: 0.926279 steps/s, speed: 7.410235 samples/s, speed: 3794.040172 tokens/s, learning rate: 1.328e-05, loss_scalings: 10737.418945, pp_loss: 7.147758
[INFO] 2021-07-12 18:58:14,049 [run_pretraining.py:  512]:	********exe.run_1329******* 
[INFO] 2021-07-12 18:58:15,110 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:15,110 [run_pretraining.py:  534]:	loss/total_loss, 7.517909049987793, 1330
[INFO] 2021-07-12 18:58:15,110 [run_pretraining.py:  535]:	loss/mlm_loss, 7.517909049987793, 1330
[INFO] 2021-07-12 18:58:15,111 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.328999951510923e-05, 1330
[INFO] 2021-07-12 18:58:15,111 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1330
[INFO] 2021-07-12 18:58:15,111 [run_pretraining.py:  558]:	worker_index: 2, step: 1330, cost: 7.517909, mlm loss: 7.517909, speed: 0.942328 steps/s, speed: 7.538621 samples/s, speed: 3859.773926 tokens/s, learning rate: 1.329e-05, loss_scalings: 10737.418945, pp_loss: 7.632775
[INFO] 2021-07-12 18:58:15,111 [run_pretraining.py:  512]:	********exe.run_1330******* 
[INFO] 2021-07-12 18:58:16,170 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:16,171 [run_pretraining.py:  534]:	loss/total_loss, 10.730454444885254, 1331
[INFO] 2021-07-12 18:58:16,171 [run_pretraining.py:  535]:	loss/mlm_loss, 10.730454444885254, 1331
[INFO] 2021-07-12 18:58:16,171 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3299999409355223e-05, 1331
[INFO] 2021-07-12 18:58:16,171 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1331
[INFO] 2021-07-12 18:58:16,171 [run_pretraining.py:  558]:	worker_index: 2, step: 1331, cost: 10.730454, mlm loss: 10.730454, speed: 0.943505 steps/s, speed: 7.548043 samples/s, speed: 3864.597940 tokens/s, learning rate: 1.330e-05, loss_scalings: 10737.418945, pp_loss: 8.287408
[INFO] 2021-07-12 18:58:16,171 [run_pretraining.py:  512]:	********exe.run_1331******* 
[INFO] 2021-07-12 18:58:17,238 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:17,239 [run_pretraining.py:  534]:	loss/total_loss, 7.46670389175415, 1332
[INFO] 2021-07-12 18:58:17,239 [run_pretraining.py:  535]:	loss/mlm_loss, 7.46670389175415, 1332
[INFO] 2021-07-12 18:58:17,239 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3310000213095918e-05, 1332
[INFO] 2021-07-12 18:58:17,239 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1332
[INFO] 2021-07-12 18:58:17,239 [run_pretraining.py:  558]:	worker_index: 2, step: 1332, cost: 7.466704, mlm loss: 7.466704, speed: 0.936897 steps/s, speed: 7.495174 samples/s, speed: 3837.529038 tokens/s, learning rate: 1.331e-05, loss_scalings: 10737.418945, pp_loss: 7.641746
[INFO] 2021-07-12 18:58:17,239 [run_pretraining.py:  512]:	********exe.run_1332******* 
[INFO] 2021-07-12 18:58:18,294 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:18,294 [run_pretraining.py:  534]:	loss/total_loss, 7.501735687255859, 1333
[INFO] 2021-07-12 18:58:18,295 [run_pretraining.py:  535]:	loss/mlm_loss, 7.501735687255859, 1333
[INFO] 2021-07-12 18:58:18,295 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3320000107341912e-05, 1333
[INFO] 2021-07-12 18:58:18,295 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1333
[INFO] 2021-07-12 18:58:18,295 [run_pretraining.py:  558]:	worker_index: 2, step: 1333, cost: 7.501736, mlm loss: 7.501736, speed: 0.947848 steps/s, speed: 7.582784 samples/s, speed: 3882.385245 tokens/s, learning rate: 1.332e-05, loss_scalings: 10737.418945, pp_loss: 7.485517
[INFO] 2021-07-12 18:58:18,295 [run_pretraining.py:  512]:	********exe.run_1333******* 
[INFO] 2021-07-12 18:58:47,364 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:47,365 [run_pretraining.py:  534]:	loss/total_loss, 7.318249702453613, 1334
[INFO] 2021-07-12 18:58:47,365 [run_pretraining.py:  535]:	loss/mlm_loss, 7.318249702453613, 1334
[INFO] 2021-07-12 18:58:47,365 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3330000001587905e-05, 1334
[INFO] 2021-07-12 18:58:47,365 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1334
[INFO] 2021-07-12 18:58:47,365 [run_pretraining.py:  558]:	worker_index: 2, step: 1334, cost: 7.318250, mlm loss: 7.318250, speed: 0.034400 steps/s, speed: 0.275202 samples/s, speed: 140.903484 tokens/s, learning rate: 1.333e-05, loss_scalings: 10737.418945, pp_loss: 7.421684
[INFO] 2021-07-12 18:58:47,365 [run_pretraining.py:  512]:	********exe.run_1334******* 
[INFO] 2021-07-12 18:58:48,257 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:48,258 [run_pretraining.py:  534]:	loss/total_loss, 7.997115612030029, 1335
[INFO] 2021-07-12 18:58:48,258 [run_pretraining.py:  535]:	loss/mlm_loss, 7.997115612030029, 1335
[INFO] 2021-07-12 18:58:48,258 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3339998986339197e-05, 1335
[INFO] 2021-07-12 18:58:48,258 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1335
[INFO] 2021-07-12 18:58:48,258 [run_pretraining.py:  558]:	worker_index: 2, step: 1335, cost: 7.997116, mlm loss: 7.997116, speed: 1.120458 steps/s, speed: 8.963660 samples/s, speed: 4589.394140 tokens/s, learning rate: 1.334e-05, loss_scalings: 10737.418945, pp_loss: 7.551232
[INFO] 2021-07-12 18:58:48,258 [run_pretraining.py:  512]:	********exe.run_1335******* 
[INFO] 2021-07-12 18:58:49,155 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:49,155 [run_pretraining.py:  534]:	loss/total_loss, 7.850330829620361, 1336
[INFO] 2021-07-12 18:58:49,155 [run_pretraining.py:  535]:	loss/mlm_loss, 7.850330829620361, 1336
[INFO] 2021-07-12 18:58:49,155 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.334999888058519e-05, 1336
[INFO] 2021-07-12 18:58:49,155 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1336
[INFO] 2021-07-12 18:58:49,155 [run_pretraining.py:  558]:	worker_index: 2, step: 1336, cost: 7.850331, mlm loss: 7.850331, speed: 1.115022 steps/s, speed: 8.920179 samples/s, speed: 4567.131815 tokens/s, learning rate: 1.335e-05, loss_scalings: 10737.418945, pp_loss: 7.905106
[INFO] 2021-07-12 18:58:49,156 [run_pretraining.py:  512]:	********exe.run_1336******* 
[INFO] 2021-07-12 18:58:50,052 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:50,053 [run_pretraining.py:  534]:	loss/total_loss, 7.827488899230957, 1337
[INFO] 2021-07-12 18:58:50,053 [run_pretraining.py:  535]:	loss/mlm_loss, 7.827488899230957, 1337
[INFO] 2021-07-12 18:58:50,053 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3359999684325885e-05, 1337
[INFO] 2021-07-12 18:58:50,053 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1337
[INFO] 2021-07-12 18:58:50,053 [run_pretraining.py:  558]:	worker_index: 2, step: 1337, cost: 7.827489, mlm loss: 7.827489, speed: 1.114767 steps/s, speed: 8.918138 samples/s, speed: 4566.086683 tokens/s, learning rate: 1.336e-05, loss_scalings: 10737.418945, pp_loss: 7.347748
[INFO] 2021-07-12 18:58:50,053 [run_pretraining.py:  512]:	********exe.run_1337******* 
[INFO] 2021-07-12 18:58:50,959 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:50,959 [run_pretraining.py:  534]:	loss/total_loss, 6.9982829093933105, 1338
[INFO] 2021-07-12 18:58:50,959 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9982829093933105, 1338
[INFO] 2021-07-12 18:58:50,959 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3369999578571878e-05, 1338
[INFO] 2021-07-12 18:58:50,959 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1338
[INFO] 2021-07-12 18:58:50,959 [run_pretraining.py:  558]:	worker_index: 2, step: 1338, cost: 6.998283, mlm loss: 6.998283, speed: 1.104088 steps/s, speed: 8.832703 samples/s, speed: 4522.343967 tokens/s, learning rate: 1.337e-05, loss_scalings: 10737.418945, pp_loss: 7.460683
[INFO] 2021-07-12 18:58:50,959 [run_pretraining.py:  512]:	********exe.run_1338******* 
[INFO] 2021-07-12 18:58:51,854 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:51,854 [run_pretraining.py:  534]:	loss/total_loss, 7.120939254760742, 1339
[INFO] 2021-07-12 18:58:51,854 [run_pretraining.py:  535]:	loss/mlm_loss, 7.120939254760742, 1339
[INFO] 2021-07-12 18:58:51,854 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3379999472817872e-05, 1339
[INFO] 2021-07-12 18:58:51,854 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1339
[INFO] 2021-07-12 18:58:51,854 [run_pretraining.py:  558]:	worker_index: 2, step: 1339, cost: 7.120939, mlm loss: 7.120939, speed: 1.118044 steps/s, speed: 8.944352 samples/s, speed: 4579.508167 tokens/s, learning rate: 1.338e-05, loss_scalings: 10737.418945, pp_loss: 7.325689
[INFO] 2021-07-12 18:58:51,854 [run_pretraining.py:  512]:	********exe.run_1339******* 
[INFO] 2021-07-12 18:58:52,774 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:52,774 [run_pretraining.py:  534]:	loss/total_loss, 8.282768249511719, 1340
[INFO] 2021-07-12 18:58:52,774 [run_pretraining.py:  535]:	loss/mlm_loss, 8.282768249511719, 1340
[INFO] 2021-07-12 18:58:52,774 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3390000276558567e-05, 1340
[INFO] 2021-07-12 18:58:52,774 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1340
[INFO] 2021-07-12 18:58:52,774 [run_pretraining.py:  558]:	worker_index: 2, step: 1340, cost: 8.282768, mlm loss: 8.282768, speed: 1.087729 steps/s, speed: 8.701835 samples/s, speed: 4455.339468 tokens/s, learning rate: 1.339e-05, loss_scalings: 10737.418945, pp_loss: 7.511947
[INFO] 2021-07-12 18:58:52,774 [run_pretraining.py:  512]:	********exe.run_1340******* 
[INFO] 2021-07-12 18:58:53,667 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:53,668 [run_pretraining.py:  534]:	loss/total_loss, 7.230457305908203, 1341
[INFO] 2021-07-12 18:58:53,668 [run_pretraining.py:  535]:	loss/mlm_loss, 7.230457305908203, 1341
[INFO] 2021-07-12 18:58:53,668 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.340000017080456e-05, 1341
[INFO] 2021-07-12 18:58:53,668 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1341
[INFO] 2021-07-12 18:58:53,668 [run_pretraining.py:  558]:	worker_index: 2, step: 1341, cost: 7.230457, mlm loss: 7.230457, speed: 1.119922 steps/s, speed: 8.959379 samples/s, speed: 4587.201872 tokens/s, learning rate: 1.340e-05, loss_scalings: 10737.418945, pp_loss: 7.212968
[INFO] 2021-07-12 18:58:53,668 [run_pretraining.py:  512]:	********exe.run_1341******* 
[INFO] 2021-07-12 18:58:54,565 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:54,566 [run_pretraining.py:  534]:	loss/total_loss, 8.09909725189209, 1342
[INFO] 2021-07-12 18:58:54,566 [run_pretraining.py:  535]:	loss/mlm_loss, 8.09909725189209, 1342
[INFO] 2021-07-12 18:58:54,566 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3410000065050554e-05, 1342
[INFO] 2021-07-12 18:58:54,566 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1342
[INFO] 2021-07-12 18:58:54,566 [run_pretraining.py:  558]:	worker_index: 2, step: 1342, cost: 8.099097, mlm loss: 8.099097, speed: 1.113931 steps/s, speed: 8.911449 samples/s, speed: 4562.662104 tokens/s, learning rate: 1.341e-05, loss_scalings: 10737.418945, pp_loss: 7.264219
[INFO] 2021-07-12 18:58:54,566 [run_pretraining.py:  512]:	********exe.run_1342******* 
[INFO] 2021-07-12 18:58:55,471 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:55,472 [run_pretraining.py:  534]:	loss/total_loss, 7.107665061950684, 1343
[INFO] 2021-07-12 18:58:55,472 [run_pretraining.py:  535]:	loss/mlm_loss, 7.107665061950684, 1343
[INFO] 2021-07-12 18:58:55,472 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3419999959296547e-05, 1343
[INFO] 2021-07-12 18:58:55,472 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1343
[INFO] 2021-07-12 18:58:55,472 [run_pretraining.py:  558]:	worker_index: 2, step: 1343, cost: 7.107665, mlm loss: 7.107665, speed: 1.104376 steps/s, speed: 8.835008 samples/s, speed: 4523.524001 tokens/s, learning rate: 1.342e-05, loss_scalings: 10737.418945, pp_loss: 7.374961
[INFO] 2021-07-12 18:58:55,472 [run_pretraining.py:  512]:	********exe.run_1343******* 
[INFO] 2021-07-12 18:58:56,372 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:56,373 [run_pretraining.py:  534]:	loss/total_loss, 7.838582992553711, 1344
[INFO] 2021-07-12 18:58:56,373 [run_pretraining.py:  535]:	loss/mlm_loss, 7.838582992553711, 1344
[INFO] 2021-07-12 18:58:56,373 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3429998944047838e-05, 1344
[INFO] 2021-07-12 18:58:56,373 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1344
[INFO] 2021-07-12 18:58:56,373 [run_pretraining.py:  558]:	worker_index: 2, step: 1344, cost: 7.838583, mlm loss: 7.838583, speed: 1.110664 steps/s, speed: 8.885310 samples/s, speed: 4549.278805 tokens/s, learning rate: 1.343e-05, loss_scalings: 10737.418945, pp_loss: 7.544553
[INFO] 2021-07-12 18:58:56,373 [run_pretraining.py:  512]:	********exe.run_1344******* 
[INFO] 2021-07-12 18:58:57,281 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:57,281 [run_pretraining.py:  534]:	loss/total_loss, 7.360019683837891, 1345
[INFO] 2021-07-12 18:58:57,281 [run_pretraining.py:  535]:	loss/mlm_loss, 7.360019683837891, 1345
[INFO] 2021-07-12 18:58:57,281 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3439998838293832e-05, 1345
[INFO] 2021-07-12 18:58:57,282 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1345
[INFO] 2021-07-12 18:58:57,282 [run_pretraining.py:  558]:	worker_index: 2, step: 1345, cost: 7.360020, mlm loss: 7.360020, speed: 1.101603 steps/s, speed: 8.812827 samples/s, speed: 4512.167234 tokens/s, learning rate: 1.344e-05, loss_scalings: 10737.418945, pp_loss: 7.538246
[INFO] 2021-07-12 18:58:57,282 [run_pretraining.py:  512]:	********exe.run_1345******* 
[INFO] 2021-07-12 18:58:58,241 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:58,241 [run_pretraining.py:  534]:	loss/total_loss, 6.971404075622559, 1346
[INFO] 2021-07-12 18:58:58,241 [run_pretraining.py:  535]:	loss/mlm_loss, 6.971404075622559, 1346
[INFO] 2021-07-12 18:58:58,241 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3449999642034527e-05, 1346
[INFO] 2021-07-12 18:58:58,242 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1346
[INFO] 2021-07-12 18:58:58,242 [run_pretraining.py:  558]:	worker_index: 2, step: 1346, cost: 6.971404, mlm loss: 6.971404, speed: 1.042263 steps/s, speed: 8.338104 samples/s, speed: 4269.109301 tokens/s, learning rate: 1.345e-05, loss_scalings: 10737.418945, pp_loss: 6.682418
[INFO] 2021-07-12 18:58:58,242 [run_pretraining.py:  512]:	********exe.run_1346******* 
[INFO] 2021-07-12 18:58:59,296 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:59,297 [run_pretraining.py:  534]:	loss/total_loss, 7.589502811431885, 1347
[INFO] 2021-07-12 18:58:59,297 [run_pretraining.py:  535]:	loss/mlm_loss, 7.589502811431885, 1347
[INFO] 2021-07-12 18:58:59,297 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.345999953628052e-05, 1347
[INFO] 2021-07-12 18:58:59,297 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1347
[INFO] 2021-07-12 18:58:59,297 [run_pretraining.py:  558]:	worker_index: 2, step: 1347, cost: 7.589503, mlm loss: 7.589503, speed: 0.948008 steps/s, speed: 7.584064 samples/s, speed: 3883.040743 tokens/s, learning rate: 1.346e-05, loss_scalings: 10737.418945, pp_loss: 7.418546
[INFO] 2021-07-12 18:58:59,297 [run_pretraining.py:  512]:	********exe.run_1347******* 
[INFO] 2021-07-12 18:59:00,355 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:00,355 [run_pretraining.py:  534]:	loss/total_loss, 7.622753620147705, 1348
[INFO] 2021-07-12 18:59:00,355 [run_pretraining.py:  535]:	loss/mlm_loss, 7.622753620147705, 1348
[INFO] 2021-07-12 18:59:00,355 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3469999430526514e-05, 1348
[INFO] 2021-07-12 18:59:00,355 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1348
[INFO] 2021-07-12 18:59:00,356 [run_pretraining.py:  558]:	worker_index: 2, step: 1348, cost: 7.622754, mlm loss: 7.622754, speed: 0.945323 steps/s, speed: 7.562585 samples/s, speed: 3872.043360 tokens/s, learning rate: 1.347e-05, loss_scalings: 10737.418945, pp_loss: 7.595065
[INFO] 2021-07-12 18:59:00,356 [run_pretraining.py:  512]:	********exe.run_1348******* 
[INFO] 2021-07-12 18:59:01,352 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:01,352 [run_pretraining.py:  534]:	loss/total_loss, 7.183778285980225, 1349
[INFO] 2021-07-12 18:59:01,352 [run_pretraining.py:  535]:	loss/mlm_loss, 7.183778285980225, 1349
[INFO] 2021-07-12 18:59:01,353 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3480000234267209e-05, 1349
[INFO] 2021-07-12 18:59:01,353 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1349
[INFO] 2021-07-12 18:59:01,353 [run_pretraining.py:  558]:	worker_index: 2, step: 1349, cost: 7.183778, mlm loss: 7.183778, speed: 1.003483 steps/s, speed: 8.027866 samples/s, speed: 4110.267297 tokens/s, learning rate: 1.348e-05, loss_scalings: 10737.418945, pp_loss: 7.567294
[INFO] 2021-07-12 18:59:01,353 [run_pretraining.py:  512]:	********exe.run_1349******* 
[INFO] 2021-07-12 18:59:02,253 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:02,254 [run_pretraining.py:  534]:	loss/total_loss, 8.240336418151855, 1350
[INFO] 2021-07-12 18:59:02,254 [run_pretraining.py:  535]:	loss/mlm_loss, 8.240336418151855, 1350
[INFO] 2021-07-12 18:59:02,254 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3490000128513202e-05, 1350
[INFO] 2021-07-12 18:59:02,254 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1350
[INFO] 2021-07-12 18:59:02,254 [run_pretraining.py:  558]:	worker_index: 2, step: 1350, cost: 8.240336, mlm loss: 8.240336, speed: 1.110017 steps/s, speed: 8.880139 samples/s, speed: 4546.631295 tokens/s, learning rate: 1.349e-05, loss_scalings: 10737.418945, pp_loss: 7.155848
[INFO] 2021-07-12 18:59:02,254 [run_pretraining.py:  512]:	********exe.run_1350******* 
[INFO] 2021-07-12 18:59:03,154 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:03,155 [run_pretraining.py:  534]:	loss/total_loss, 7.9074482917785645, 1351
[INFO] 2021-07-12 18:59:03,155 [run_pretraining.py:  535]:	loss/mlm_loss, 7.9074482917785645, 1351
[INFO] 2021-07-12 18:59:03,155 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3500000022759195e-05, 1351
[INFO] 2021-07-12 18:59:03,155 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1351
[INFO] 2021-07-12 18:59:03,155 [run_pretraining.py:  558]:	worker_index: 2, step: 1351, cost: 7.907448, mlm loss: 7.907448, speed: 1.110701 steps/s, speed: 8.885611 samples/s, speed: 4549.433007 tokens/s, learning rate: 1.350e-05, loss_scalings: 10737.418945, pp_loss: 7.878138
[INFO] 2021-07-12 18:59:03,155 [run_pretraining.py:  512]:	********exe.run_1351******* 
[INFO] 2021-07-12 18:59:04,049 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:04,049 [run_pretraining.py:  534]:	loss/total_loss, 7.211480140686035, 1352
[INFO] 2021-07-12 18:59:04,050 [run_pretraining.py:  535]:	loss/mlm_loss, 7.211480140686035, 1352
[INFO] 2021-07-12 18:59:04,050 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3509999917005189e-05, 1352
[INFO] 2021-07-12 18:59:04,050 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1352
[INFO] 2021-07-12 18:59:04,050 [run_pretraining.py:  558]:	worker_index: 2, step: 1352, cost: 7.211480, mlm loss: 7.211480, speed: 1.118475 steps/s, speed: 8.947803 samples/s, speed: 4581.275237 tokens/s, learning rate: 1.351e-05, loss_scalings: 10737.418945, pp_loss: 7.508766
[INFO] 2021-07-12 18:59:04,050 [run_pretraining.py:  512]:	********exe.run_1352******* 
[INFO] 2021-07-12 18:59:04,942 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:04,943 [run_pretraining.py:  534]:	loss/total_loss, 8.03106689453125, 1353
[INFO] 2021-07-12 18:59:04,943 [run_pretraining.py:  535]:	loss/mlm_loss, 8.03106689453125, 1353
[INFO] 2021-07-12 18:59:04,943 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.351999890175648e-05, 1353
[INFO] 2021-07-12 18:59:04,943 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1353
[INFO] 2021-07-12 18:59:04,943 [run_pretraining.py:  558]:	worker_index: 2, step: 1353, cost: 8.031067, mlm loss: 8.031067, speed: 1.120268 steps/s, speed: 8.962140 samples/s, speed: 4588.615762 tokens/s, learning rate: 1.352e-05, loss_scalings: 10737.418945, pp_loss: 7.599734
[INFO] 2021-07-12 18:59:04,943 [run_pretraining.py:  512]:	********exe.run_1353******* 
[INFO] 2021-07-12 18:59:05,846 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:05,847 [run_pretraining.py:  534]:	loss/total_loss, 7.014800071716309, 1354
[INFO] 2021-07-12 18:59:05,847 [run_pretraining.py:  535]:	loss/mlm_loss, 7.014800071716309, 1354
[INFO] 2021-07-12 18:59:05,847 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3529998796002474e-05, 1354
[INFO] 2021-07-12 18:59:05,847 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1354
[INFO] 2021-07-12 18:59:05,847 [run_pretraining.py:  558]:	worker_index: 2, step: 1354, cost: 7.014800, mlm loss: 7.014800, speed: 1.106698 steps/s, speed: 8.853583 samples/s, speed: 4533.034326 tokens/s, learning rate: 1.353e-05, loss_scalings: 10737.418945, pp_loss: 7.477014
[INFO] 2021-07-12 18:59:05,847 [run_pretraining.py:  512]:	********exe.run_1354******* 
[INFO] 2021-07-12 18:59:06,747 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:06,747 [run_pretraining.py:  534]:	loss/total_loss, 9.070816040039062, 1355
[INFO] 2021-07-12 18:59:06,747 [run_pretraining.py:  535]:	loss/mlm_loss, 9.070816040039062, 1355
[INFO] 2021-07-12 18:59:06,747 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3539999599743169e-05, 1355
[INFO] 2021-07-12 18:59:06,747 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1355
[INFO] 2021-07-12 18:59:06,748 [run_pretraining.py:  558]:	worker_index: 2, step: 1355, cost: 9.070816, mlm loss: 9.070816, speed: 1.111433 steps/s, speed: 8.891460 samples/s, speed: 4552.427560 tokens/s, learning rate: 1.354e-05, loss_scalings: 10737.418945, pp_loss: 7.792258
[INFO] 2021-07-12 18:59:06,748 [run_pretraining.py:  512]:	********exe.run_1355******* 
[INFO] 2021-07-12 18:59:07,638 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:07,638 [run_pretraining.py:  534]:	loss/total_loss, 8.046655654907227, 1356
[INFO] 2021-07-12 18:59:07,639 [run_pretraining.py:  535]:	loss/mlm_loss, 8.046655654907227, 1356
[INFO] 2021-07-12 18:59:07,639 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3549999493989162e-05, 1356
[INFO] 2021-07-12 18:59:07,639 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1356
[INFO] 2021-07-12 18:59:07,639 [run_pretraining.py:  558]:	worker_index: 2, step: 1356, cost: 8.046656, mlm loss: 8.046656, speed: 1.122685 steps/s, speed: 8.981480 samples/s, speed: 4598.517752 tokens/s, learning rate: 1.355e-05, loss_scalings: 10737.418945, pp_loss: 7.793185
[INFO] 2021-07-12 18:59:07,639 [run_pretraining.py:  512]:	********exe.run_1356******* 
[INFO] 2021-07-12 18:59:08,545 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:08,546 [run_pretraining.py:  534]:	loss/total_loss, 7.11515998840332, 1357
[INFO] 2021-07-12 18:59:08,546 [run_pretraining.py:  535]:	loss/mlm_loss, 7.11515998840332, 1357
[INFO] 2021-07-12 18:59:08,546 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3559999388235155e-05, 1357
[INFO] 2021-07-12 18:59:08,546 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1357
[INFO] 2021-07-12 18:59:08,546 [run_pretraining.py:  558]:	worker_index: 2, step: 1357, cost: 7.115160, mlm loss: 7.115160, speed: 1.102982 steps/s, speed: 8.823856 samples/s, speed: 4517.814125 tokens/s, learning rate: 1.356e-05, loss_scalings: 10737.418945, pp_loss: 7.398125
[INFO] 2021-07-12 18:59:08,546 [run_pretraining.py:  512]:	********exe.run_1357******* 
[INFO] 2021-07-12 18:59:09,435 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:09,435 [run_pretraining.py:  534]:	loss/total_loss, 7.896324157714844, 1358
[INFO] 2021-07-12 18:59:09,435 [run_pretraining.py:  535]:	loss/mlm_loss, 7.896324157714844, 1358
[INFO] 2021-07-12 18:59:09,435 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.357000019197585e-05, 1358
[INFO] 2021-07-12 18:59:09,436 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1358
[INFO] 2021-07-12 18:59:09,436 [run_pretraining.py:  558]:	worker_index: 2, step: 1358, cost: 7.896324, mlm loss: 7.896324, speed: 1.124980 steps/s, speed: 8.999836 samples/s, speed: 4607.916231 tokens/s, learning rate: 1.357e-05, loss_scalings: 10737.418945, pp_loss: 7.693703
[INFO] 2021-07-12 18:59:09,436 [run_pretraining.py:  512]:	********exe.run_1358******* 
[INFO] 2021-07-12 18:59:10,343 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:10,344 [run_pretraining.py:  534]:	loss/total_loss, 7.158937454223633, 1359
[INFO] 2021-07-12 18:59:10,344 [run_pretraining.py:  535]:	loss/mlm_loss, 7.158937454223633, 1359
[INFO] 2021-07-12 18:59:10,344 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3580000086221844e-05, 1359
[INFO] 2021-07-12 18:59:10,344 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1359
[INFO] 2021-07-12 18:59:10,344 [run_pretraining.py:  558]:	worker_index: 2, step: 1359, cost: 7.158937, mlm loss: 7.158937, speed: 1.101371 steps/s, speed: 8.810966 samples/s, speed: 4511.214625 tokens/s, learning rate: 1.358e-05, loss_scalings: 10737.418945, pp_loss: 7.835460
[INFO] 2021-07-12 18:59:10,344 [run_pretraining.py:  512]:	********exe.run_1359******* 
[INFO] 2021-07-12 18:59:11,272 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:11,272 [run_pretraining.py:  534]:	loss/total_loss, 7.3899383544921875, 1360
[INFO] 2021-07-12 18:59:11,272 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3899383544921875, 1360
[INFO] 2021-07-12 18:59:11,272 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3589999980467837e-05, 1360
[INFO] 2021-07-12 18:59:11,273 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1360
[INFO] 2021-07-12 18:59:11,273 [run_pretraining.py:  558]:	worker_index: 2, step: 1360, cost: 7.389938, mlm loss: 7.389938, speed: 1.077769 steps/s, speed: 8.622150 samples/s, speed: 4414.540648 tokens/s, learning rate: 1.359e-05, loss_scalings: 10737.418945, pp_loss: 6.684594
[INFO] 2021-07-12 18:59:11,273 [run_pretraining.py:  512]:	********exe.run_1360******* 
[INFO] 2021-07-12 18:59:12,174 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:12,174 [run_pretraining.py:  534]:	loss/total_loss, 7.531723976135254, 1361
[INFO] 2021-07-12 18:59:12,174 [run_pretraining.py:  535]:	loss/mlm_loss, 7.531723976135254, 1361
[INFO] 2021-07-12 18:59:12,174 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3600000784208532e-05, 1361
[INFO] 2021-07-12 18:59:12,175 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1361
[INFO] 2021-07-12 18:59:12,175 [run_pretraining.py:  558]:	worker_index: 2, step: 1361, cost: 7.531724, mlm loss: 7.531724, speed: 1.109330 steps/s, speed: 8.874636 samples/s, speed: 4543.813803 tokens/s, learning rate: 1.360e-05, loss_scalings: 10737.418945, pp_loss: 7.498104
[INFO] 2021-07-12 18:59:12,175 [run_pretraining.py:  512]:	********exe.run_1361******* 
[INFO] 2021-07-12 18:59:13,075 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:13,075 [run_pretraining.py:  534]:	loss/total_loss, 6.690250396728516, 1362
[INFO] 2021-07-12 18:59:13,076 [run_pretraining.py:  535]:	loss/mlm_loss, 6.690250396728516, 1362
[INFO] 2021-07-12 18:59:13,076 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3609998859465122e-05, 1362
[INFO] 2021-07-12 18:59:13,076 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1362
[INFO] 2021-07-12 18:59:13,076 [run_pretraining.py:  558]:	worker_index: 2, step: 1362, cost: 6.690250, mlm loss: 6.690250, speed: 1.110379 steps/s, speed: 8.883033 samples/s, speed: 4548.112991 tokens/s, learning rate: 1.361e-05, loss_scalings: 10737.418945, pp_loss: 7.378952
[INFO] 2021-07-12 18:59:13,076 [run_pretraining.py:  512]:	********exe.run_1362******* 
[INFO] 2021-07-12 18:59:13,973 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:13,974 [run_pretraining.py:  534]:	loss/total_loss, 6.894252777099609, 1363
[INFO] 2021-07-12 18:59:13,974 [run_pretraining.py:  535]:	loss/mlm_loss, 6.894252777099609, 1363
[INFO] 2021-07-12 18:59:13,974 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3619999663205817e-05, 1363
[INFO] 2021-07-12 18:59:13,974 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1363
[INFO] 2021-07-12 18:59:13,974 [run_pretraining.py:  558]:	worker_index: 2, step: 1363, cost: 6.894253, mlm loss: 6.894253, speed: 1.113942 steps/s, speed: 8.911535 samples/s, speed: 4562.705727 tokens/s, learning rate: 1.362e-05, loss_scalings: 10737.418945, pp_loss: 7.469188
[INFO] 2021-07-12 18:59:13,974 [run_pretraining.py:  512]:	********exe.run_1363******* 
[INFO] 2021-07-12 18:59:14,868 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:14,869 [run_pretraining.py:  534]:	loss/total_loss, 7.76591682434082, 1364
[INFO] 2021-07-12 18:59:14,869 [run_pretraining.py:  535]:	loss/mlm_loss, 7.76591682434082, 1364
[INFO] 2021-07-12 18:59:14,869 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.362999955745181e-05, 1364
[INFO] 2021-07-12 18:59:14,869 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1364
[INFO] 2021-07-12 18:59:14,869 [run_pretraining.py:  558]:	worker_index: 2, step: 1364, cost: 7.765917, mlm loss: 7.765917, speed: 1.117952 steps/s, speed: 8.943618 samples/s, speed: 4579.132214 tokens/s, learning rate: 1.363e-05, loss_scalings: 10737.418945, pp_loss: 7.411676
[INFO] 2021-07-12 18:59:14,869 [run_pretraining.py:  512]:	********exe.run_1364******* 
[INFO] 2021-07-12 18:59:15,851 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:15,851 [run_pretraining.py:  534]:	loss/total_loss, 7.729830741882324, 1365
[INFO] 2021-07-12 18:59:15,851 [run_pretraining.py:  535]:	loss/mlm_loss, 7.729830741882324, 1365
[INFO] 2021-07-12 18:59:15,851 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3639999451697804e-05, 1365
[INFO] 2021-07-12 18:59:15,851 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1365
[INFO] 2021-07-12 18:59:15,851 [run_pretraining.py:  558]:	worker_index: 2, step: 1365, cost: 7.729831, mlm loss: 7.729831, speed: 1.018716 steps/s, speed: 8.149725 samples/s, speed: 4172.659348 tokens/s, learning rate: 1.364e-05, loss_scalings: 10737.418945, pp_loss: 6.394219
[INFO] 2021-07-12 18:59:15,852 [run_pretraining.py:  512]:	********exe.run_1365******* 
[INFO] 2021-07-12 18:59:16,745 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:16,745 [run_pretraining.py:  534]:	loss/total_loss, 6.996417999267578, 1366
[INFO] 2021-07-12 18:59:16,745 [run_pretraining.py:  535]:	loss/mlm_loss, 6.996417999267578, 1366
[INFO] 2021-07-12 18:59:16,745 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3649999345943797e-05, 1366
[INFO] 2021-07-12 18:59:16,745 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1366
[INFO] 2021-07-12 18:59:16,745 [run_pretraining.py:  558]:	worker_index: 2, step: 1366, cost: 6.996418, mlm loss: 6.996418, speed: 1.119469 steps/s, speed: 8.955753 samples/s, speed: 4585.345781 tokens/s, learning rate: 1.365e-05, loss_scalings: 10737.418945, pp_loss: 7.532032
[INFO] 2021-07-12 18:59:16,745 [run_pretraining.py:  512]:	********exe.run_1366******* 
[INFO] 2021-07-12 18:59:17,649 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:17,650 [run_pretraining.py:  534]:	loss/total_loss, 7.656736373901367, 1367
[INFO] 2021-07-12 18:59:17,650 [run_pretraining.py:  535]:	loss/mlm_loss, 7.656736373901367, 1367
[INFO] 2021-07-12 18:59:17,650 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3660000149684492e-05, 1367
[INFO] 2021-07-12 18:59:17,650 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1367
[INFO] 2021-07-12 18:59:17,650 [run_pretraining.py:  558]:	worker_index: 2, step: 1367, cost: 7.656736, mlm loss: 7.656736, speed: 1.105926 steps/s, speed: 8.847410 samples/s, speed: 4529.874110 tokens/s, learning rate: 1.366e-05, loss_scalings: 10737.418945, pp_loss: 7.643369
[INFO] 2021-07-12 18:59:17,650 [run_pretraining.py:  512]:	********exe.run_1367******* 
[INFO] 2021-07-12 18:59:18,546 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:18,546 [run_pretraining.py:  534]:	loss/total_loss, 7.131514072418213, 1368
[INFO] 2021-07-12 18:59:18,547 [run_pretraining.py:  535]:	loss/mlm_loss, 7.131514072418213, 1368
[INFO] 2021-07-12 18:59:18,547 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3670000043930486e-05, 1368
[INFO] 2021-07-12 18:59:18,547 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1368
[INFO] 2021-07-12 18:59:18,547 [run_pretraining.py:  558]:	worker_index: 2, step: 1368, cost: 7.131514, mlm loss: 7.131514, speed: 1.115971 steps/s, speed: 8.927769 samples/s, speed: 4571.017925 tokens/s, learning rate: 1.367e-05, loss_scalings: 10737.418945, pp_loss: 7.465708
[INFO] 2021-07-12 18:59:18,547 [run_pretraining.py:  512]:	********exe.run_1368******* 
[INFO] 2021-07-12 18:59:19,450 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:19,450 [run_pretraining.py:  534]:	loss/total_loss, 7.733005523681641, 1369
[INFO] 2021-07-12 18:59:19,451 [run_pretraining.py:  535]:	loss/mlm_loss, 7.733005523681641, 1369
[INFO] 2021-07-12 18:59:19,451 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.367999993817648e-05, 1369
[INFO] 2021-07-12 18:59:19,451 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1369
[INFO] 2021-07-12 18:59:19,451 [run_pretraining.py:  558]:	worker_index: 2, step: 1369, cost: 7.733006, mlm loss: 7.733006, speed: 1.106996 steps/s, speed: 8.855971 samples/s, speed: 4534.257044 tokens/s, learning rate: 1.368e-05, loss_scalings: 10737.418945, pp_loss: 7.767219
[INFO] 2021-07-12 18:59:19,451 [run_pretraining.py:  512]:	********exe.run_1369******* 
[INFO] 2021-07-12 18:59:20,347 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:20,348 [run_pretraining.py:  534]:	loss/total_loss, 7.597729682922363, 1370
[INFO] 2021-07-12 18:59:20,348 [run_pretraining.py:  535]:	loss/mlm_loss, 7.597729682922363, 1370
[INFO] 2021-07-12 18:59:20,348 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.368999892292777e-05, 1370
[INFO] 2021-07-12 18:59:20,348 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1370
[INFO] 2021-07-12 18:59:20,348 [run_pretraining.py:  558]:	worker_index: 2, step: 1370, cost: 7.597730, mlm loss: 7.597730, speed: 1.115177 steps/s, speed: 8.921413 samples/s, speed: 4567.763253 tokens/s, learning rate: 1.369e-05, loss_scalings: 10737.418945, pp_loss: 7.740400
[INFO] 2021-07-12 18:59:20,348 [run_pretraining.py:  512]:	********exe.run_1370******* 
[INFO] 2021-07-12 18:59:21,245 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:21,245 [run_pretraining.py:  534]:	loss/total_loss, 7.511534690856934, 1371
[INFO] 2021-07-12 18:59:21,245 [run_pretraining.py:  535]:	loss/mlm_loss, 7.511534690856934, 1371
[INFO] 2021-07-12 18:59:21,245 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3699998817173764e-05, 1371
[INFO] 2021-07-12 18:59:21,245 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1371
[INFO] 2021-07-12 18:59:21,245 [run_pretraining.py:  558]:	worker_index: 2, step: 1371, cost: 7.511535, mlm loss: 7.511535, speed: 1.115214 steps/s, speed: 8.921709 samples/s, speed: 4567.915067 tokens/s, learning rate: 1.370e-05, loss_scalings: 10737.418945, pp_loss: 7.574191
[INFO] 2021-07-12 18:59:21,245 [run_pretraining.py:  512]:	********exe.run_1371******* 
[INFO] 2021-07-12 18:59:22,152 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:22,153 [run_pretraining.py:  534]:	loss/total_loss, 7.937031269073486, 1372
[INFO] 2021-07-12 18:59:22,153 [run_pretraining.py:  535]:	loss/mlm_loss, 7.937031269073486, 1372
[INFO] 2021-07-12 18:59:22,153 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.370999962091446e-05, 1372
[INFO] 2021-07-12 18:59:22,153 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1372
[INFO] 2021-07-12 18:59:22,153 [run_pretraining.py:  558]:	worker_index: 2, step: 1372, cost: 7.937031, mlm loss: 7.937031, speed: 1.102180 steps/s, speed: 8.817437 samples/s, speed: 4514.527978 tokens/s, learning rate: 1.371e-05, loss_scalings: 10737.418945, pp_loss: 7.865741
[INFO] 2021-07-12 18:59:22,153 [run_pretraining.py:  512]:	********exe.run_1372******* 
[INFO] 2021-07-12 18:59:23,065 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:23,065 [run_pretraining.py:  534]:	loss/total_loss, 4.648179531097412, 1373
[INFO] 2021-07-12 18:59:23,065 [run_pretraining.py:  535]:	loss/mlm_loss, 4.648179531097412, 1373
[INFO] 2021-07-12 18:59:23,066 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3719999515160453e-05, 1373
[INFO] 2021-07-12 18:59:23,066 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1373
[INFO] 2021-07-12 18:59:23,066 [run_pretraining.py:  558]:	worker_index: 2, step: 1373, cost: 4.648180, mlm loss: 4.648180, speed: 1.096707 steps/s, speed: 8.773660 samples/s, speed: 4492.113818 tokens/s, learning rate: 1.372e-05, loss_scalings: 10737.418945, pp_loss: 6.810432
[INFO] 2021-07-12 18:59:23,066 [run_pretraining.py:  512]:	********exe.run_1373******* 
[INFO] 2021-07-12 18:59:23,978 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:23,978 [run_pretraining.py:  534]:	loss/total_loss, 7.629798412322998, 1374
[INFO] 2021-07-12 18:59:23,978 [run_pretraining.py:  535]:	loss/mlm_loss, 7.629798412322998, 1374
[INFO] 2021-07-12 18:59:23,978 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3729999409406446e-05, 1374
[INFO] 2021-07-12 18:59:23,978 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1374
[INFO] 2021-07-12 18:59:23,978 [run_pretraining.py:  558]:	worker_index: 2, step: 1374, cost: 7.629798, mlm loss: 7.629798, speed: 1.096456 steps/s, speed: 8.771648 samples/s, speed: 4491.083950 tokens/s, learning rate: 1.373e-05, loss_scalings: 10737.418945, pp_loss: 7.887599
[INFO] 2021-07-12 18:59:23,978 [run_pretraining.py:  512]:	********exe.run_1374******* 
[INFO] 2021-07-12 18:59:24,894 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:24,894 [run_pretraining.py:  534]:	loss/total_loss, 7.273829936981201, 1375
[INFO] 2021-07-12 18:59:24,894 [run_pretraining.py:  535]:	loss/mlm_loss, 7.273829936981201, 1375
[INFO] 2021-07-12 18:59:24,894 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3740000213147141e-05, 1375
[INFO] 2021-07-12 18:59:24,894 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1375
[INFO] 2021-07-12 18:59:24,894 [run_pretraining.py:  558]:	worker_index: 2, step: 1375, cost: 7.273830, mlm loss: 7.273830, speed: 1.092304 steps/s, speed: 8.738436 samples/s, speed: 4474.079228 tokens/s, learning rate: 1.374e-05, loss_scalings: 10737.418945, pp_loss: 7.611094
[INFO] 2021-07-12 18:59:24,895 [run_pretraining.py:  512]:	********exe.run_1375******* 
[INFO] 2021-07-12 18:59:25,840 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:25,840 [run_pretraining.py:  534]:	loss/total_loss, 7.673145294189453, 1376
[INFO] 2021-07-12 18:59:25,841 [run_pretraining.py:  535]:	loss/mlm_loss, 7.673145294189453, 1376
[INFO] 2021-07-12 18:59:25,841 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3750000107393134e-05, 1376
[INFO] 2021-07-12 18:59:25,841 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1376
[INFO] 2021-07-12 18:59:25,841 [run_pretraining.py:  558]:	worker_index: 2, step: 1376, cost: 7.673145, mlm loss: 7.673145, speed: 1.057339 steps/s, speed: 8.458714 samples/s, speed: 4330.861476 tokens/s, learning rate: 1.375e-05, loss_scalings: 8589.935547, pp_loss: 7.650827
[INFO] 2021-07-12 18:59:25,841 [run_pretraining.py:  512]:	********exe.run_1376******* 
[INFO] 2021-07-12 18:59:26,734 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:26,734 [run_pretraining.py:  534]:	loss/total_loss, 7.775054454803467, 1377
[INFO] 2021-07-12 18:59:26,734 [run_pretraining.py:  535]:	loss/mlm_loss, 7.775054454803467, 1377
[INFO] 2021-07-12 18:59:26,734 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3760000001639128e-05, 1377
[INFO] 2021-07-12 18:59:26,734 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1377
[INFO] 2021-07-12 18:59:26,734 [run_pretraining.py:  558]:	worker_index: 2, step: 1377, cost: 7.775054, mlm loss: 7.775054, speed: 1.119918 steps/s, speed: 8.959340 samples/s, speed: 4587.182275 tokens/s, learning rate: 1.376e-05, loss_scalings: 8589.935547, pp_loss: 6.884247
[INFO] 2021-07-12 18:59:26,734 [run_pretraining.py:  512]:	********exe.run_1377******* 
[INFO] 2021-07-12 18:59:27,632 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:27,632 [run_pretraining.py:  534]:	loss/total_loss, 4.958838939666748, 1378
[INFO] 2021-07-12 18:59:27,632 [run_pretraining.py:  535]:	loss/mlm_loss, 4.958838939666748, 1378
[INFO] 2021-07-12 18:59:27,632 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3769999895885121e-05, 1378
[INFO] 2021-07-12 18:59:27,632 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1378
[INFO] 2021-07-12 18:59:27,632 [run_pretraining.py:  558]:	worker_index: 2, step: 1378, cost: 4.958839, mlm loss: 4.958839, speed: 1.114222 steps/s, speed: 8.913779 samples/s, speed: 4563.854788 tokens/s, learning rate: 1.377e-05, loss_scalings: 8589.935547, pp_loss: 6.946096
[INFO] 2021-07-12 18:59:27,632 [run_pretraining.py:  512]:	********exe.run_1378******* 
[INFO] 2021-07-12 18:59:28,531 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:28,531 [run_pretraining.py:  534]:	loss/total_loss, 7.958398818969727, 1379
[INFO] 2021-07-12 18:59:28,532 [run_pretraining.py:  535]:	loss/mlm_loss, 7.958398818969727, 1379
[INFO] 2021-07-12 18:59:28,532 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3779998880636413e-05, 1379
[INFO] 2021-07-12 18:59:28,532 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1379
[INFO] 2021-07-12 18:59:28,532 [run_pretraining.py:  558]:	worker_index: 2, step: 1379, cost: 7.958399, mlm loss: 7.958399, speed: 1.112684 steps/s, speed: 8.901473 samples/s, speed: 4557.554199 tokens/s, learning rate: 1.378e-05, loss_scalings: 8589.935547, pp_loss: 7.207150
[INFO] 2021-07-12 18:59:28,532 [run_pretraining.py:  512]:	********exe.run_1379******* 
[INFO] 2021-07-12 18:59:29,430 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:29,431 [run_pretraining.py:  534]:	loss/total_loss, 7.279275894165039, 1380
[INFO] 2021-07-12 18:59:29,431 [run_pretraining.py:  535]:	loss/mlm_loss, 7.279275894165039, 1380
[INFO] 2021-07-12 18:59:29,431 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3789998774882406e-05, 1380
[INFO] 2021-07-12 18:59:29,431 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1380
[INFO] 2021-07-12 18:59:29,431 [run_pretraining.py:  558]:	worker_index: 2, step: 1380, cost: 7.279276, mlm loss: 7.279276, speed: 1.112494 steps/s, speed: 8.899953 samples/s, speed: 4556.775705 tokens/s, learning rate: 1.379e-05, loss_scalings: 8589.935547, pp_loss: 7.832032
[INFO] 2021-07-12 18:59:29,431 [run_pretraining.py:  512]:	********exe.run_1380******* 
[INFO] 2021-07-12 18:59:30,345 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:30,346 [run_pretraining.py:  534]:	loss/total_loss, 4.684767246246338, 1381
[INFO] 2021-07-12 18:59:30,346 [run_pretraining.py:  535]:	loss/mlm_loss, 4.684767246246338, 1381
[INFO] 2021-07-12 18:59:30,346 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3799999578623101e-05, 1381
[INFO] 2021-07-12 18:59:30,346 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1381
[INFO] 2021-07-12 18:59:30,346 [run_pretraining.py:  558]:	worker_index: 2, step: 1381, cost: 4.684767, mlm loss: 4.684767, speed: 1.094066 steps/s, speed: 8.752525 samples/s, speed: 4481.292726 tokens/s, learning rate: 1.380e-05, loss_scalings: 8589.935547, pp_loss: 7.046238
[INFO] 2021-07-12 18:59:30,346 [run_pretraining.py:  512]:	********exe.run_1381******* 
[INFO] 2021-07-12 18:59:31,267 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:31,273 [run_pretraining.py:  534]:	loss/total_loss, 7.549623012542725, 1382
[INFO] 2021-07-12 18:59:31,278 [run_pretraining.py:  535]:	loss/mlm_loss, 7.549623012542725, 1382
[INFO] 2021-07-12 18:59:31,283 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3809999472869094e-05, 1382
[INFO] 2021-07-12 18:59:31,288 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1382
[INFO] 2021-07-12 18:59:31,294 [run_pretraining.py:  558]:	worker_index: 2, step: 1382, cost: 7.549623, mlm loss: 7.549623, speed: 1.078918 steps/s, speed: 8.631341 samples/s, speed: 4419.246449 tokens/s, learning rate: 1.381e-05, loss_scalings: 8589.935547, pp_loss: 7.514548
[INFO] 2021-07-12 18:59:31,299 [run_pretraining.py:  512]:	********exe.run_1382******* 
[INFO] 2021-07-12 18:59:32,180 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:32,180 [run_pretraining.py:  534]:	loss/total_loss, 8.191058158874512, 1383
[INFO] 2021-07-12 18:59:32,180 [run_pretraining.py:  535]:	loss/mlm_loss, 8.191058158874512, 1383
[INFO] 2021-07-12 18:59:32,180 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3819999367115088e-05, 1383
[INFO] 2021-07-12 18:59:32,180 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1383
[INFO] 2021-07-12 18:59:32,181 [run_pretraining.py:  558]:	worker_index: 2, step: 1383, cost: 8.191058, mlm loss: 8.191058, speed: 1.134719 steps/s, speed: 9.077755 samples/s, speed: 4647.810476 tokens/s, learning rate: 1.382e-05, loss_scalings: 8589.935547, pp_loss: 7.052807
[INFO] 2021-07-12 18:59:32,181 [run_pretraining.py:  512]:	********exe.run_1383******* 
[INFO] 2021-07-12 18:59:33,080 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:33,080 [run_pretraining.py:  534]:	loss/total_loss, 7.244250297546387, 1384
[INFO] 2021-07-12 18:59:33,080 [run_pretraining.py:  535]:	loss/mlm_loss, 7.244250297546387, 1384
[INFO] 2021-07-12 18:59:33,080 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3830000170855783e-05, 1384
[INFO] 2021-07-12 18:59:33,080 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1384
[INFO] 2021-07-12 18:59:33,081 [run_pretraining.py:  558]:	worker_index: 2, step: 1384, cost: 7.244250, mlm loss: 7.244250, speed: 1.111859 steps/s, speed: 8.894868 samples/s, speed: 4554.172583 tokens/s, learning rate: 1.383e-05, loss_scalings: 8589.935547, pp_loss: 7.289880
[INFO] 2021-07-12 18:59:33,081 [run_pretraining.py:  512]:	********exe.run_1384******* 
[INFO] 2021-07-12 18:59:33,979 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:33,979 [run_pretraining.py:  534]:	loss/total_loss, 7.140744686126709, 1385
[INFO] 2021-07-12 18:59:33,979 [run_pretraining.py:  535]:	loss/mlm_loss, 7.140744686126709, 1385
[INFO] 2021-07-12 18:59:33,979 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3840000065101776e-05, 1385
[INFO] 2021-07-12 18:59:33,979 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1385
[INFO] 2021-07-12 18:59:33,979 [run_pretraining.py:  558]:	worker_index: 2, step: 1385, cost: 7.140745, mlm loss: 7.140745, speed: 1.113354 steps/s, speed: 8.906830 samples/s, speed: 4560.296762 tokens/s, learning rate: 1.384e-05, loss_scalings: 8589.935547, pp_loss: 7.323709
[INFO] 2021-07-12 18:59:33,979 [run_pretraining.py:  512]:	********exe.run_1385******* 
[INFO] 2021-07-12 18:59:34,881 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:34,882 [run_pretraining.py:  534]:	loss/total_loss, 7.617396831512451, 1386
[INFO] 2021-07-12 18:59:34,882 [run_pretraining.py:  535]:	loss/mlm_loss, 7.617396831512451, 1386
[INFO] 2021-07-12 18:59:34,882 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.384999995934777e-05, 1386
[INFO] 2021-07-12 18:59:34,882 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1386
[INFO] 2021-07-12 18:59:34,882 [run_pretraining.py:  558]:	worker_index: 2, step: 1386, cost: 7.617397, mlm loss: 7.617397, speed: 1.108575 steps/s, speed: 8.868599 samples/s, speed: 4540.722552 tokens/s, learning rate: 1.385e-05, loss_scalings: 8589.935547, pp_loss: 7.335660
[INFO] 2021-07-12 18:59:34,882 [run_pretraining.py:  512]:	********exe.run_1386******* 
[INFO] 2021-07-12 18:59:35,796 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:35,797 [run_pretraining.py:  534]:	loss/total_loss, 7.588022232055664, 1387
[INFO] 2021-07-12 18:59:35,797 [run_pretraining.py:  535]:	loss/mlm_loss, 7.588022232055664, 1387
[INFO] 2021-07-12 18:59:35,797 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3860000763088465e-05, 1387
[INFO] 2021-07-12 18:59:35,797 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1387
[INFO] 2021-07-12 18:59:35,797 [run_pretraining.py:  558]:	worker_index: 2, step: 1387, cost: 7.588022, mlm loss: 7.588022, speed: 1.093793 steps/s, speed: 8.750347 samples/s, speed: 4480.177848 tokens/s, learning rate: 1.386e-05, loss_scalings: 8589.935547, pp_loss: 7.440627
[INFO] 2021-07-12 18:59:35,797 [run_pretraining.py:  512]:	********exe.run_1387******* 
[INFO] 2021-07-12 18:59:36,688 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:36,689 [run_pretraining.py:  534]:	loss/total_loss, 7.564695358276367, 1388
[INFO] 2021-07-12 18:59:36,689 [run_pretraining.py:  535]:	loss/mlm_loss, 7.564695358276367, 1388
[INFO] 2021-07-12 18:59:36,689 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3869998838345055e-05, 1388
[INFO] 2021-07-12 18:59:36,689 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1388
[INFO] 2021-07-12 18:59:36,689 [run_pretraining.py:  558]:	worker_index: 2, step: 1388, cost: 7.564695, mlm loss: 7.564695, speed: 1.121249 steps/s, speed: 8.969989 samples/s, speed: 4592.634295 tokens/s, learning rate: 1.387e-05, loss_scalings: 8589.935547, pp_loss: 7.306765
[INFO] 2021-07-12 18:59:36,689 [run_pretraining.py:  512]:	********exe.run_1388******* 
[INFO] 2021-07-12 18:59:37,630 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:37,631 [run_pretraining.py:  534]:	loss/total_loss, 7.071660041809082, 1389
[INFO] 2021-07-12 18:59:37,631 [run_pretraining.py:  535]:	loss/mlm_loss, 7.071660041809082, 1389
[INFO] 2021-07-12 18:59:37,631 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3879998732591048e-05, 1389
[INFO] 2021-07-12 18:59:37,631 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1389
[INFO] 2021-07-12 18:59:37,631 [run_pretraining.py:  558]:	worker_index: 2, step: 1389, cost: 7.071660, mlm loss: 7.071660, speed: 1.062392 steps/s, speed: 8.499139 samples/s, speed: 4351.559325 tokens/s, learning rate: 1.388e-05, loss_scalings: 8589.935547, pp_loss: 6.978616
[INFO] 2021-07-12 18:59:37,631 [run_pretraining.py:  512]:	********exe.run_1389******* 
[INFO] 2021-07-12 18:59:38,546 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:38,546 [run_pretraining.py:  534]:	loss/total_loss, 7.6151323318481445, 1390
[INFO] 2021-07-12 18:59:38,546 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6151323318481445, 1390
[INFO] 2021-07-12 18:59:38,546 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3889999536331743e-05, 1390
[INFO] 2021-07-12 18:59:38,546 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1390
[INFO] 2021-07-12 18:59:38,547 [run_pretraining.py:  558]:	worker_index: 2, step: 1390, cost: 7.615132, mlm loss: 7.615132, speed: 1.093212 steps/s, speed: 8.745699 samples/s, speed: 4477.798028 tokens/s, learning rate: 1.389e-05, loss_scalings: 8589.935547, pp_loss: 7.670562
[INFO] 2021-07-12 18:59:38,547 [run_pretraining.py:  512]:	********exe.run_1390******* 
[INFO] 2021-07-12 18:59:39,445 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:39,446 [run_pretraining.py:  534]:	loss/total_loss, 7.76628303527832, 1391
[INFO] 2021-07-12 18:59:39,446 [run_pretraining.py:  535]:	loss/mlm_loss, 7.76628303527832, 1391
[INFO] 2021-07-12 18:59:39,446 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3899999430577736e-05, 1391
[INFO] 2021-07-12 18:59:39,446 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1391
[INFO] 2021-07-12 18:59:39,446 [run_pretraining.py:  558]:	worker_index: 2, step: 1391, cost: 7.766283, mlm loss: 7.766283, speed: 1.112142 steps/s, speed: 8.897140 samples/s, speed: 4555.335466 tokens/s, learning rate: 1.390e-05, loss_scalings: 8589.935547, pp_loss: 7.656085
[INFO] 2021-07-12 18:59:39,446 [run_pretraining.py:  512]:	********exe.run_1391******* 
[INFO] 2021-07-12 18:59:40,343 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:40,344 [run_pretraining.py:  534]:	loss/total_loss, 7.4997663497924805, 1392
[INFO] 2021-07-12 18:59:40,344 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4997663497924805, 1392
[INFO] 2021-07-12 18:59:40,344 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.390999932482373e-05, 1392
[INFO] 2021-07-12 18:59:40,344 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1392
[INFO] 2021-07-12 18:59:40,344 [run_pretraining.py:  558]:	worker_index: 2, step: 1392, cost: 7.499766, mlm loss: 7.499766, speed: 1.114538 steps/s, speed: 8.916304 samples/s, speed: 4565.147566 tokens/s, learning rate: 1.391e-05, loss_scalings: 8589.935547, pp_loss: 6.436101
[INFO] 2021-07-12 18:59:40,344 [run_pretraining.py:  512]:	********exe.run_1392******* 
[INFO] 2021-07-12 18:59:41,248 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:41,249 [run_pretraining.py:  534]:	loss/total_loss, 4.36093807220459, 1393
[INFO] 2021-07-12 18:59:41,249 [run_pretraining.py:  535]:	loss/mlm_loss, 4.36093807220459, 1393
[INFO] 2021-07-12 18:59:41,249 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3920000128564425e-05, 1393
[INFO] 2021-07-12 18:59:41,249 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1393
[INFO] 2021-07-12 18:59:41,249 [run_pretraining.py:  558]:	worker_index: 2, step: 1393, cost: 4.360938, mlm loss: 4.360938, speed: 1.105704 steps/s, speed: 8.845635 samples/s, speed: 4528.965349 tokens/s, learning rate: 1.392e-05, loss_scalings: 8589.935547, pp_loss: 6.591275
[INFO] 2021-07-12 18:59:41,249 [run_pretraining.py:  512]:	********exe.run_1393******* 
[INFO] 2021-07-12 18:59:42,148 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:42,148 [run_pretraining.py:  534]:	loss/total_loss, 7.16628885269165, 1394
[INFO] 2021-07-12 18:59:42,148 [run_pretraining.py:  535]:	loss/mlm_loss, 7.16628885269165, 1394
[INFO] 2021-07-12 18:59:42,148 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3930000022810418e-05, 1394
[INFO] 2021-07-12 18:59:42,148 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1394
[INFO] 2021-07-12 18:59:42,149 [run_pretraining.py:  558]:	worker_index: 2, step: 1394, cost: 7.166289, mlm loss: 7.166289, speed: 1.112670 steps/s, speed: 8.901362 samples/s, speed: 4557.497375 tokens/s, learning rate: 1.393e-05, loss_scalings: 8589.935547, pp_loss: 7.540201
[INFO] 2021-07-12 18:59:42,149 [run_pretraining.py:  512]:	********exe.run_1394******* 
[INFO] 2021-07-12 18:59:43,049 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:43,050 [run_pretraining.py:  534]:	loss/total_loss, 7.787686347961426, 1395
[INFO] 2021-07-12 18:59:43,050 [run_pretraining.py:  535]:	loss/mlm_loss, 7.787686347961426, 1395
[INFO] 2021-07-12 18:59:43,050 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3939999917056412e-05, 1395
[INFO] 2021-07-12 18:59:43,050 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1395
[INFO] 2021-07-12 18:59:43,050 [run_pretraining.py:  558]:	worker_index: 2, step: 1395, cost: 7.787686, mlm loss: 7.787686, speed: 1.109686 steps/s, speed: 8.877487 samples/s, speed: 4545.273220 tokens/s, learning rate: 1.394e-05, loss_scalings: 8589.935547, pp_loss: 7.755373
[INFO] 2021-07-12 18:59:43,050 [run_pretraining.py:  512]:	********exe.run_1395******* 
[INFO] 2021-07-12 18:59:43,949 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:43,950 [run_pretraining.py:  534]:	loss/total_loss, 4.068175315856934, 1396
[INFO] 2021-07-12 18:59:43,950 [run_pretraining.py:  535]:	loss/mlm_loss, 4.068175315856934, 1396
[INFO] 2021-07-12 18:59:43,950 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3950000720797107e-05, 1396
[INFO] 2021-07-12 18:59:43,950 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1396
[INFO] 2021-07-12 18:59:43,950 [run_pretraining.py:  558]:	worker_index: 2, step: 1396, cost: 4.068175, mlm loss: 4.068175, speed: 1.111833 steps/s, speed: 8.894661 samples/s, speed: 4554.066347 tokens/s, learning rate: 1.395e-05, loss_scalings: 8589.935547, pp_loss: 6.789731
[INFO] 2021-07-12 18:59:43,950 [run_pretraining.py:  512]:	********exe.run_1396******* 
[INFO] 2021-07-12 18:59:44,854 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:44,855 [run_pretraining.py:  534]:	loss/total_loss, 7.621693134307861, 1397
[INFO] 2021-07-12 18:59:44,855 [run_pretraining.py:  535]:	loss/mlm_loss, 7.621693134307861, 1397
[INFO] 2021-07-12 18:59:44,855 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3959998796053696e-05, 1397
[INFO] 2021-07-12 18:59:44,855 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1397
[INFO] 2021-07-12 18:59:44,855 [run_pretraining.py:  558]:	worker_index: 2, step: 1397, cost: 7.621693, mlm loss: 7.621693, speed: 1.106064 steps/s, speed: 8.848509 samples/s, speed: 4530.436746 tokens/s, learning rate: 1.396e-05, loss_scalings: 8589.935547, pp_loss: 7.733829
[INFO] 2021-07-12 18:59:44,855 [run_pretraining.py:  512]:	********exe.run_1397******* 
[INFO] 2021-07-12 18:59:45,747 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:45,748 [run_pretraining.py:  534]:	loss/total_loss, 7.214624881744385, 1398
[INFO] 2021-07-12 18:59:45,748 [run_pretraining.py:  535]:	loss/mlm_loss, 7.214624881744385, 1398
[INFO] 2021-07-12 18:59:45,748 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3969999599794392e-05, 1398
[INFO] 2021-07-12 18:59:45,748 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1398
[INFO] 2021-07-12 18:59:45,748 [run_pretraining.py:  558]:	worker_index: 2, step: 1398, cost: 7.214625, mlm loss: 7.214625, speed: 1.120546 steps/s, speed: 8.964369 samples/s, speed: 4589.757065 tokens/s, learning rate: 1.397e-05, loss_scalings: 8589.935547, pp_loss: 6.826692
[INFO] 2021-07-12 18:59:45,748 [run_pretraining.py:  512]:	********exe.run_1398******* 
[INFO] 2021-07-12 18:59:46,650 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:46,650 [run_pretraining.py:  534]:	loss/total_loss, 7.591285705566406, 1399
[INFO] 2021-07-12 18:59:46,650 [run_pretraining.py:  535]:	loss/mlm_loss, 7.591285705566406, 1399
[INFO] 2021-07-12 18:59:46,650 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3979999494040385e-05, 1399
[INFO] 2021-07-12 18:59:46,651 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1399
[INFO] 2021-07-12 18:59:46,651 [run_pretraining.py:  558]:	worker_index: 2, step: 1399, cost: 7.591286, mlm loss: 7.591286, speed: 1.108638 steps/s, speed: 8.869105 samples/s, speed: 4540.981796 tokens/s, learning rate: 1.398e-05, loss_scalings: 8589.935547, pp_loss: 7.521006
[INFO] 2021-07-12 18:59:46,651 [run_pretraining.py:  512]:	********exe.run_1399******* 
[INFO] 2021-07-12 18:59:47,553 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:47,554 [run_pretraining.py:  534]:	loss/total_loss, 8.042669296264648, 1400
[INFO] 2021-07-12 18:59:47,554 [run_pretraining.py:  535]:	loss/mlm_loss, 8.042669296264648, 1400
[INFO] 2021-07-12 18:59:47,554 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3989999388286378e-05, 1400
[INFO] 2021-07-12 18:59:47,554 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1400
[INFO] 2021-07-12 18:59:47,554 [run_pretraining.py:  558]:	worker_index: 2, step: 1400, cost: 8.042669, mlm loss: 8.042669, speed: 1.107516 steps/s, speed: 8.860131 samples/s, speed: 4536.387008 tokens/s, learning rate: 1.399e-05, loss_scalings: 8589.935547, pp_loss: 7.538936
[INFO] 2021-07-12 18:59:47,554 [run_pretraining.py:  512]:	********exe.run_1400******* 
[INFO] 2021-07-12 18:59:48,454 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:48,455 [run_pretraining.py:  534]:	loss/total_loss, 8.10260009765625, 1401
[INFO] 2021-07-12 18:59:48,455 [run_pretraining.py:  535]:	loss/mlm_loss, 8.10260009765625, 1401
[INFO] 2021-07-12 18:59:48,455 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3999999282532372e-05, 1401
[INFO] 2021-07-12 18:59:48,455 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1401
[INFO] 2021-07-12 18:59:48,455 [run_pretraining.py:  558]:	worker_index: 2, step: 1401, cost: 8.102600, mlm loss: 8.102600, speed: 1.110833 steps/s, speed: 8.886663 samples/s, speed: 4549.971591 tokens/s, learning rate: 1.400e-05, loss_scalings: 8589.935547, pp_loss: 7.701467
[INFO] 2021-07-12 18:59:48,455 [run_pretraining.py:  512]:	********exe.run_1401******* 
[INFO] 2021-07-12 18:59:49,356 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:49,357 [run_pretraining.py:  534]:	loss/total_loss, 7.724031448364258, 1402
[INFO] 2021-07-12 18:59:49,357 [run_pretraining.py:  535]:	loss/mlm_loss, 7.724031448364258, 1402
[INFO] 2021-07-12 18:59:49,357 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4010000086273067e-05, 1402
[INFO] 2021-07-12 18:59:49,357 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1402
[INFO] 2021-07-12 18:59:49,357 [run_pretraining.py:  558]:	worker_index: 2, step: 1402, cost: 7.724031, mlm loss: 7.724031, speed: 1.109250 steps/s, speed: 8.873998 samples/s, speed: 4543.486945 tokens/s, learning rate: 1.401e-05, loss_scalings: 8589.935547, pp_loss: 7.390069
[INFO] 2021-07-12 18:59:49,357 [run_pretraining.py:  512]:	********exe.run_1402******* 
[INFO] 2021-07-12 18:59:50,252 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:50,253 [run_pretraining.py:  534]:	loss/total_loss, 7.607910633087158, 1403
[INFO] 2021-07-12 18:59:50,253 [run_pretraining.py:  535]:	loss/mlm_loss, 7.607910633087158, 1403
[INFO] 2021-07-12 18:59:50,253 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.401999998051906e-05, 1403
[INFO] 2021-07-12 18:59:50,253 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1403
[INFO] 2021-07-12 18:59:50,253 [run_pretraining.py:  558]:	worker_index: 2, step: 1403, cost: 7.607911, mlm loss: 7.607911, speed: 1.116597 steps/s, speed: 8.932780 samples/s, speed: 4573.583119 tokens/s, learning rate: 1.402e-05, loss_scalings: 8589.935547, pp_loss: 7.525301
[INFO] 2021-07-12 18:59:50,253 [run_pretraining.py:  512]:	********exe.run_1403******* 
[INFO] 2021-07-12 18:59:51,151 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:51,151 [run_pretraining.py:  534]:	loss/total_loss, 6.9259443283081055, 1404
[INFO] 2021-07-12 18:59:51,151 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9259443283081055, 1404
[INFO] 2021-07-12 18:59:51,152 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4029999874765053e-05, 1404
[INFO] 2021-07-12 18:59:51,152 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1404
[INFO] 2021-07-12 18:59:51,152 [run_pretraining.py:  558]:	worker_index: 2, step: 1404, cost: 6.925944, mlm loss: 6.925944, speed: 1.113879 steps/s, speed: 8.911033 samples/s, speed: 4562.448844 tokens/s, learning rate: 1.403e-05, loss_scalings: 8589.935547, pp_loss: 7.534152
[INFO] 2021-07-12 18:59:51,152 [run_pretraining.py:  512]:	********exe.run_1404******* 
[INFO] 2021-07-12 18:59:52,042 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:52,043 [run_pretraining.py:  534]:	loss/total_loss, 7.202897071838379, 1405
[INFO] 2021-07-12 18:59:52,043 [run_pretraining.py:  535]:	loss/mlm_loss, 7.202897071838379, 1405
[INFO] 2021-07-12 18:59:52,043 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4040000678505749e-05, 1405
[INFO] 2021-07-12 18:59:52,043 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1405
[INFO] 2021-07-12 18:59:52,043 [run_pretraining.py:  558]:	worker_index: 2, step: 1405, cost: 7.202897, mlm loss: 7.202897, speed: 1.122292 steps/s, speed: 8.978337 samples/s, speed: 4596.908324 tokens/s, learning rate: 1.404e-05, loss_scalings: 8589.935547, pp_loss: 7.423304
[INFO] 2021-07-12 18:59:52,043 [run_pretraining.py:  512]:	********exe.run_1405******* 
[INFO] 2021-07-12 18:59:52,940 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:52,941 [run_pretraining.py:  534]:	loss/total_loss, 7.792348861694336, 1406
[INFO] 2021-07-12 18:59:52,941 [run_pretraining.py:  535]:	loss/mlm_loss, 7.792348861694336, 1406
[INFO] 2021-07-12 18:59:52,941 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4049998753762338e-05, 1406
[INFO] 2021-07-12 18:59:52,941 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1406
[INFO] 2021-07-12 18:59:52,941 [run_pretraining.py:  558]:	worker_index: 2, step: 1406, cost: 7.792349, mlm loss: 7.792349, speed: 1.114799 steps/s, speed: 8.918389 samples/s, speed: 4566.215327 tokens/s, learning rate: 1.405e-05, loss_scalings: 8589.935547, pp_loss: 7.838590
[INFO] 2021-07-12 18:59:52,941 [run_pretraining.py:  512]:	********exe.run_1406******* 
[INFO] 2021-07-12 18:59:53,835 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:53,835 [run_pretraining.py:  534]:	loss/total_loss, 5.9655070304870605, 1407
[INFO] 2021-07-12 18:59:53,835 [run_pretraining.py:  535]:	loss/mlm_loss, 5.9655070304870605, 1407
[INFO] 2021-07-12 18:59:53,835 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4059999557503033e-05, 1407
[INFO] 2021-07-12 18:59:53,835 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1407
[INFO] 2021-07-12 18:59:53,835 [run_pretraining.py:  558]:	worker_index: 2, step: 1407, cost: 5.965507, mlm loss: 5.965507, speed: 1.118689 steps/s, speed: 8.949512 samples/s, speed: 4582.150118 tokens/s, learning rate: 1.406e-05, loss_scalings: 8589.935547, pp_loss: 7.036698
[INFO] 2021-07-12 18:59:53,836 [run_pretraining.py:  512]:	********exe.run_1407******* 
[INFO] 2021-07-12 18:59:54,730 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:54,730 [run_pretraining.py:  534]:	loss/total_loss, 7.3374128341674805, 1408
[INFO] 2021-07-12 18:59:54,731 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3374128341674805, 1408
[INFO] 2021-07-12 18:59:54,731 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4069999451749027e-05, 1408
[INFO] 2021-07-12 18:59:54,731 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1408
[INFO] 2021-07-12 18:59:54,731 [run_pretraining.py:  558]:	worker_index: 2, step: 1408, cost: 7.337413, mlm loss: 7.337413, speed: 1.117642 steps/s, speed: 8.941139 samples/s, speed: 4577.863221 tokens/s, learning rate: 1.407e-05, loss_scalings: 8589.935547, pp_loss: 7.413369
[INFO] 2021-07-12 18:59:54,731 [run_pretraining.py:  512]:	********exe.run_1408******* 
[INFO] 2021-07-12 18:59:55,631 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:55,632 [run_pretraining.py:  534]:	loss/total_loss, 7.075664043426514, 1409
[INFO] 2021-07-12 18:59:55,632 [run_pretraining.py:  535]:	loss/mlm_loss, 7.075664043426514, 1409
[INFO] 2021-07-12 18:59:55,632 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.407999934599502e-05, 1409
[INFO] 2021-07-12 18:59:55,632 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1409
[INFO] 2021-07-12 18:59:55,632 [run_pretraining.py:  558]:	worker_index: 2, step: 1409, cost: 7.075664, mlm loss: 7.075664, speed: 1.110229 steps/s, speed: 8.881829 samples/s, speed: 4547.496604 tokens/s, learning rate: 1.408e-05, loss_scalings: 8589.935547, pp_loss: 7.352593
[INFO] 2021-07-12 18:59:55,632 [run_pretraining.py:  512]:	********exe.run_1409******* 
[INFO] 2021-07-12 18:59:56,534 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:56,534 [run_pretraining.py:  534]:	loss/total_loss, 6.917361259460449, 1410
[INFO] 2021-07-12 18:59:56,534 [run_pretraining.py:  535]:	loss/mlm_loss, 6.917361259460449, 1410
[INFO] 2021-07-12 18:59:56,534 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4090000149735715e-05, 1410
[INFO] 2021-07-12 18:59:56,534 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1410
[INFO] 2021-07-12 18:59:56,535 [run_pretraining.py:  558]:	worker_index: 2, step: 1410, cost: 6.917361, mlm loss: 6.917361, speed: 1.108884 steps/s, speed: 8.871072 samples/s, speed: 4541.989048 tokens/s, learning rate: 1.409e-05, loss_scalings: 8589.935547, pp_loss: 6.585257
[INFO] 2021-07-12 18:59:56,535 [run_pretraining.py:  512]:	********exe.run_1410******* 
[INFO] 2021-07-12 18:59:57,514 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:57,515 [run_pretraining.py:  534]:	loss/total_loss, 7.338164329528809, 1411
[INFO] 2021-07-12 18:59:57,515 [run_pretraining.py:  535]:	loss/mlm_loss, 7.338164329528809, 1411
[INFO] 2021-07-12 18:59:57,515 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4100000043981709e-05, 1411
[INFO] 2021-07-12 18:59:57,515 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1411
[INFO] 2021-07-12 18:59:57,515 [run_pretraining.py:  558]:	worker_index: 2, step: 1411, cost: 7.338164, mlm loss: 7.338164, speed: 1.020659 steps/s, speed: 8.165271 samples/s, speed: 4180.619005 tokens/s, learning rate: 1.410e-05, loss_scalings: 8589.935547, pp_loss: 7.775956
[INFO] 2021-07-12 18:59:57,515 [run_pretraining.py:  512]:	********exe.run_1411******* 
[INFO] 2021-07-12 18:59:58,458 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:58,458 [run_pretraining.py:  534]:	loss/total_loss, 6.9890570640563965, 1412
[INFO] 2021-07-12 18:59:58,458 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9890570640563965, 1412
[INFO] 2021-07-12 18:59:58,459 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4109999938227702e-05, 1412
[INFO] 2021-07-12 18:59:58,459 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1412
[INFO] 2021-07-12 18:59:58,459 [run_pretraining.py:  558]:	worker_index: 2, step: 1412, cost: 6.989057, mlm loss: 6.989057, speed: 1.060198 steps/s, speed: 8.481587 samples/s, speed: 4342.572750 tokens/s, learning rate: 1.411e-05, loss_scalings: 8589.935547, pp_loss: 7.139593
[INFO] 2021-07-12 18:59:58,459 [run_pretraining.py:  512]:	********exe.run_1412******* 
[INFO] 2021-07-12 19:00:23,917 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:23,918 [run_pretraining.py:  534]:	loss/total_loss, 7.664124965667725, 1413
[INFO] 2021-07-12 19:00:23,918 [run_pretraining.py:  535]:	loss/mlm_loss, 7.664124965667725, 1413
[INFO] 2021-07-12 19:00:23,918 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4119999832473695e-05, 1413
[INFO] 2021-07-12 19:00:23,918 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1413
[INFO] 2021-07-12 19:00:23,918 [run_pretraining.py:  558]:	worker_index: 2, step: 1413, cost: 7.664125, mlm loss: 7.664125, speed: 0.039279 steps/s, speed: 0.314233 samples/s, speed: 160.887515 tokens/s, learning rate: 1.412e-05, loss_scalings: 8589.935547, pp_loss: 7.563540
[INFO] 2021-07-12 19:00:23,918 [run_pretraining.py:  512]:	********exe.run_1413******* 
[INFO] 2021-07-12 19:00:24,821 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:24,821 [run_pretraining.py:  534]:	loss/total_loss, 7.680337905883789, 1414
[INFO] 2021-07-12 19:00:24,822 [run_pretraining.py:  535]:	loss/mlm_loss, 7.680337905883789, 1414
[INFO] 2021-07-12 19:00:24,822 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4129998817224987e-05, 1414
[INFO] 2021-07-12 19:00:24,822 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1414
[INFO] 2021-07-12 19:00:24,822 [run_pretraining.py:  558]:	worker_index: 2, step: 1414, cost: 7.680338, mlm loss: 7.680338, speed: 1.107374 steps/s, speed: 8.858994 samples/s, speed: 4535.804930 tokens/s, learning rate: 1.413e-05, loss_scalings: 8589.935547, pp_loss: 7.812793
[INFO] 2021-07-12 19:00:24,822 [run_pretraining.py:  512]:	********exe.run_1414******* 
[INFO] 2021-07-12 19:00:25,727 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:25,728 [run_pretraining.py:  534]:	loss/total_loss, 6.9422993659973145, 1415
[INFO] 2021-07-12 19:00:25,728 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9422993659973145, 1415
[INFO] 2021-07-12 19:00:25,728 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.413999871147098e-05, 1415
[INFO] 2021-07-12 19:00:25,728 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1415
[INFO] 2021-07-12 19:00:25,728 [run_pretraining.py:  558]:	worker_index: 2, step: 1415, cost: 6.942299, mlm loss: 6.942299, speed: 1.104194 steps/s, speed: 8.833554 samples/s, speed: 4522.779710 tokens/s, learning rate: 1.414e-05, loss_scalings: 8589.935547, pp_loss: 6.582076
[INFO] 2021-07-12 19:00:25,728 [run_pretraining.py:  512]:	********exe.run_1415******* 
[INFO] 2021-07-12 19:00:26,714 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:26,714 [run_pretraining.py:  534]:	loss/total_loss, 8.615135192871094, 1416
[INFO] 2021-07-12 19:00:26,715 [run_pretraining.py:  535]:	loss/mlm_loss, 8.615135192871094, 1416
[INFO] 2021-07-12 19:00:26,715 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4149999515211675e-05, 1416
[INFO] 2021-07-12 19:00:26,715 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1416
[INFO] 2021-07-12 19:00:26,715 [run_pretraining.py:  558]:	worker_index: 2, step: 1416, cost: 8.615135, mlm loss: 8.615135, speed: 1.014048 steps/s, speed: 8.112385 samples/s, speed: 4153.541292 tokens/s, learning rate: 1.415e-05, loss_scalings: 8589.935547, pp_loss: 7.786397
[INFO] 2021-07-12 19:00:26,715 [run_pretraining.py:  512]:	********exe.run_1416******* 
[INFO] 2021-07-12 19:00:27,767 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:27,767 [run_pretraining.py:  534]:	loss/total_loss, 6.909748077392578, 1417
[INFO] 2021-07-12 19:00:27,767 [run_pretraining.py:  535]:	loss/mlm_loss, 6.909748077392578, 1417
[INFO] 2021-07-12 19:00:27,768 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4159999409457669e-05, 1417
[INFO] 2021-07-12 19:00:27,768 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1417
[INFO] 2021-07-12 19:00:27,768 [run_pretraining.py:  558]:	worker_index: 2, step: 1417, cost: 6.909748, mlm loss: 6.909748, speed: 0.950298 steps/s, speed: 7.602383 samples/s, speed: 3892.420028 tokens/s, learning rate: 1.416e-05, loss_scalings: 8589.935547, pp_loss: 6.957647
[INFO] 2021-07-12 19:00:27,768 [run_pretraining.py:  512]:	********exe.run_1417******* 
[INFO] 2021-07-12 19:00:28,824 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:28,824 [run_pretraining.py:  534]:	loss/total_loss, 7.400734901428223, 1418
[INFO] 2021-07-12 19:00:28,824 [run_pretraining.py:  535]:	loss/mlm_loss, 7.400734901428223, 1418
[INFO] 2021-07-12 19:00:28,825 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4169999303703662e-05, 1418
[INFO] 2021-07-12 19:00:28,825 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1418
[INFO] 2021-07-12 19:00:28,825 [run_pretraining.py:  558]:	worker_index: 2, step: 1418, cost: 7.400735, mlm loss: 7.400735, speed: 0.946660 steps/s, speed: 7.573278 samples/s, speed: 3877.518501 tokens/s, learning rate: 1.417e-05, loss_scalings: 8589.935547, pp_loss: 7.245988
[INFO] 2021-07-12 19:00:28,825 [run_pretraining.py:  512]:	********exe.run_1418******* 
[INFO] 2021-07-12 19:00:29,879 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:29,880 [run_pretraining.py:  534]:	loss/total_loss, 7.150081157684326, 1419
[INFO] 2021-07-12 19:00:29,880 [run_pretraining.py:  535]:	loss/mlm_loss, 7.150081157684326, 1419
[INFO] 2021-07-12 19:00:29,880 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4180000107444357e-05, 1419
[INFO] 2021-07-12 19:00:29,880 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1419
[INFO] 2021-07-12 19:00:29,880 [run_pretraining.py:  558]:	worker_index: 2, step: 1419, cost: 7.150081, mlm loss: 7.150081, speed: 0.948143 steps/s, speed: 7.585146 samples/s, speed: 3883.594623 tokens/s, learning rate: 1.418e-05, loss_scalings: 8589.935547, pp_loss: 7.535167
[INFO] 2021-07-12 19:00:29,880 [run_pretraining.py:  512]:	********exe.run_1419******* 
[INFO] 2021-07-12 19:00:30,940 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:30,940 [run_pretraining.py:  534]:	loss/total_loss, 7.0361456871032715, 1420
[INFO] 2021-07-12 19:00:30,940 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0361456871032715, 1420
[INFO] 2021-07-12 19:00:30,941 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.419000000169035e-05, 1420
[INFO] 2021-07-12 19:00:30,941 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1420
[INFO] 2021-07-12 19:00:30,941 [run_pretraining.py:  558]:	worker_index: 2, step: 1420, cost: 7.036146, mlm loss: 7.036146, speed: 0.943268 steps/s, speed: 7.546145 samples/s, speed: 3863.626264 tokens/s, learning rate: 1.419e-05, loss_scalings: 8589.935547, pp_loss: 7.500019
[INFO] 2021-07-12 19:00:30,941 [run_pretraining.py:  512]:	********exe.run_1420******* 
[INFO] 2021-07-12 19:00:31,992 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:31,992 [run_pretraining.py:  534]:	loss/total_loss, 8.226158142089844, 1421
[INFO] 2021-07-12 19:00:31,992 [run_pretraining.py:  535]:	loss/mlm_loss, 8.226158142089844, 1421
[INFO] 2021-07-12 19:00:31,993 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4199999895936344e-05, 1421
[INFO] 2021-07-12 19:00:31,993 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1421
[INFO] 2021-07-12 19:00:31,993 [run_pretraining.py:  558]:	worker_index: 2, step: 1421, cost: 8.226158, mlm loss: 8.226158, speed: 0.951085 steps/s, speed: 7.608682 samples/s, speed: 3895.645163 tokens/s, learning rate: 1.420e-05, loss_scalings: 8589.935547, pp_loss: 7.472188
[INFO] 2021-07-12 19:00:31,993 [run_pretraining.py:  512]:	********exe.run_1421******* 
[INFO] 2021-07-12 19:00:33,041 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:33,041 [run_pretraining.py:  534]:	loss/total_loss, 7.481574058532715, 1422
[INFO] 2021-07-12 19:00:33,041 [run_pretraining.py:  535]:	loss/mlm_loss, 7.481574058532715, 1422
[INFO] 2021-07-12 19:00:33,041 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4210000699677039e-05, 1422
[INFO] 2021-07-12 19:00:33,041 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1422
[INFO] 2021-07-12 19:00:33,041 [run_pretraining.py:  558]:	worker_index: 2, step: 1422, cost: 7.481574, mlm loss: 7.481574, speed: 0.954100 steps/s, speed: 7.632802 samples/s, speed: 3907.994727 tokens/s, learning rate: 1.421e-05, loss_scalings: 8589.935547, pp_loss: 7.626769
[INFO] 2021-07-12 19:00:33,041 [run_pretraining.py:  512]:	********exe.run_1422******* 
[INFO] 2021-07-12 19:00:34,094 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:34,094 [run_pretraining.py:  534]:	loss/total_loss, 7.455005168914795, 1423
[INFO] 2021-07-12 19:00:34,094 [run_pretraining.py:  535]:	loss/mlm_loss, 7.455005168914795, 1423
[INFO] 2021-07-12 19:00:34,095 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4219998774933629e-05, 1423
[INFO] 2021-07-12 19:00:34,095 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1423
[INFO] 2021-07-12 19:00:34,095 [run_pretraining.py:  558]:	worker_index: 2, step: 1423, cost: 7.455005, mlm loss: 7.455005, speed: 0.949949 steps/s, speed: 7.599588 samples/s, speed: 3890.989230 tokens/s, learning rate: 1.422e-05, loss_scalings: 8589.935547, pp_loss: 7.359052
[INFO] 2021-07-12 19:00:34,095 [run_pretraining.py:  512]:	********exe.run_1423******* 
[INFO] 2021-07-12 19:00:35,170 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:35,170 [run_pretraining.py:  534]:	loss/total_loss, 7.222504138946533, 1424
[INFO] 2021-07-12 19:00:35,171 [run_pretraining.py:  535]:	loss/mlm_loss, 7.222504138946533, 1424
[INFO] 2021-07-12 19:00:35,171 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4229998669179622e-05, 1424
[INFO] 2021-07-12 19:00:35,171 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1424
[INFO] 2021-07-12 19:00:35,171 [run_pretraining.py:  558]:	worker_index: 2, step: 1424, cost: 7.222504, mlm loss: 7.222504, speed: 0.929831 steps/s, speed: 7.438650 samples/s, speed: 3808.588629 tokens/s, learning rate: 1.423e-05, loss_scalings: 8589.935547, pp_loss: 7.376260
[INFO] 2021-07-12 19:00:35,171 [run_pretraining.py:  512]:	********exe.run_1424******* 
[INFO] 2021-07-12 19:00:36,237 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:36,237 [run_pretraining.py:  534]:	loss/total_loss, 8.146479606628418, 1425
[INFO] 2021-07-12 19:00:36,237 [run_pretraining.py:  535]:	loss/mlm_loss, 8.146479606628418, 1425
[INFO] 2021-07-12 19:00:36,237 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4239999472920317e-05, 1425
[INFO] 2021-07-12 19:00:36,237 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1425
[INFO] 2021-07-12 19:00:36,237 [run_pretraining.py:  558]:	worker_index: 2, step: 1425, cost: 8.146480, mlm loss: 8.146480, speed: 0.938067 steps/s, speed: 7.504533 samples/s, speed: 3842.320776 tokens/s, learning rate: 1.424e-05, loss_scalings: 8589.935547, pp_loss: 7.580335
[INFO] 2021-07-12 19:00:36,237 [run_pretraining.py:  512]:	********exe.run_1425******* 
[INFO] 2021-07-12 19:00:37,350 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:37,350 [run_pretraining.py:  534]:	loss/total_loss, 7.970129489898682, 1426
[INFO] 2021-07-12 19:00:37,350 [run_pretraining.py:  535]:	loss/mlm_loss, 7.970129489898682, 1426
[INFO] 2021-07-12 19:00:37,350 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.424999936716631e-05, 1426
[INFO] 2021-07-12 19:00:37,351 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1426
[INFO] 2021-07-12 19:00:37,351 [run_pretraining.py:  558]:	worker_index: 2, step: 1426, cost: 7.970129, mlm loss: 7.970129, speed: 0.898798 steps/s, speed: 7.190384 samples/s, speed: 3681.476799 tokens/s, learning rate: 1.425e-05, loss_scalings: 8589.935547, pp_loss: 7.483197
[INFO] 2021-07-12 19:00:37,351 [run_pretraining.py:  512]:	********exe.run_1426******* 
[INFO] 2021-07-12 19:00:38,320 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:38,321 [run_pretraining.py:  534]:	loss/total_loss, 5.095930576324463, 1427
[INFO] 2021-07-12 19:00:38,321 [run_pretraining.py:  535]:	loss/mlm_loss, 5.095930576324463, 1427
[INFO] 2021-07-12 19:00:38,321 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4259999261412304e-05, 1427
[INFO] 2021-07-12 19:00:38,321 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1427
[INFO] 2021-07-12 19:00:38,321 [run_pretraining.py:  558]:	worker_index: 2, step: 1427, cost: 5.095931, mlm loss: 5.095931, speed: 1.031045 steps/s, speed: 8.248357 samples/s, speed: 4223.158815 tokens/s, learning rate: 1.426e-05, loss_scalings: 8589.935547, pp_loss: 6.413146
[INFO] 2021-07-12 19:00:38,321 [run_pretraining.py:  512]:	********exe.run_1427******* 
[INFO] 2021-07-12 19:00:39,230 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:39,230 [run_pretraining.py:  534]:	loss/total_loss, 7.501849174499512, 1428
[INFO] 2021-07-12 19:00:39,230 [run_pretraining.py:  535]:	loss/mlm_loss, 7.501849174499512, 1428
[INFO] 2021-07-12 19:00:39,231 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4270000065152999e-05, 1428
[INFO] 2021-07-12 19:00:39,231 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1428
[INFO] 2021-07-12 19:00:39,231 [run_pretraining.py:  558]:	worker_index: 2, step: 1428, cost: 7.501849, mlm loss: 7.501849, speed: 1.100153 steps/s, speed: 8.801225 samples/s, speed: 4506.227109 tokens/s, learning rate: 1.427e-05, loss_scalings: 8589.935547, pp_loss: 7.624388
[INFO] 2021-07-12 19:00:39,231 [run_pretraining.py:  512]:	********exe.run_1428******* 
[INFO] 2021-07-12 19:00:40,128 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:40,129 [run_pretraining.py:  534]:	loss/total_loss, 7.4764180183410645, 1429
[INFO] 2021-07-12 19:00:40,129 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4764180183410645, 1429
[INFO] 2021-07-12 19:00:40,129 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4279999959398992e-05, 1429
[INFO] 2021-07-12 19:00:40,129 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1429
[INFO] 2021-07-12 19:00:40,129 [run_pretraining.py:  558]:	worker_index: 2, step: 1429, cost: 7.476418, mlm loss: 7.476418, speed: 1.113880 steps/s, speed: 8.911042 samples/s, speed: 4562.453690 tokens/s, learning rate: 1.428e-05, loss_scalings: 8589.935547, pp_loss: 7.402571
[INFO] 2021-07-12 19:00:40,129 [run_pretraining.py:  512]:	********exe.run_1429******* 
[INFO] 2021-07-12 19:00:41,029 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:41,030 [run_pretraining.py:  534]:	loss/total_loss, 7.22797155380249, 1430
[INFO] 2021-07-12 19:00:41,030 [run_pretraining.py:  535]:	loss/mlm_loss, 7.22797155380249, 1430
[INFO] 2021-07-12 19:00:41,030 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4289999853644986e-05, 1430
[INFO] 2021-07-12 19:00:41,030 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1430
[INFO] 2021-07-12 19:00:41,030 [run_pretraining.py:  558]:	worker_index: 2, step: 1430, cost: 7.227972, mlm loss: 7.227972, speed: 1.110797 steps/s, speed: 8.886374 samples/s, speed: 4549.823378 tokens/s, learning rate: 1.429e-05, loss_scalings: 8589.935547, pp_loss: 7.204343
[INFO] 2021-07-12 19:00:41,030 [run_pretraining.py:  512]:	********exe.run_1430******* 
[INFO] 2021-07-12 19:00:41,923 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:41,923 [run_pretraining.py:  534]:	loss/total_loss, 7.797957420349121, 1431
[INFO] 2021-07-12 19:00:41,923 [run_pretraining.py:  535]:	loss/mlm_loss, 7.797957420349121, 1431
[INFO] 2021-07-12 19:00:41,923 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.430000065738568e-05, 1431
[INFO] 2021-07-12 19:00:41,923 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1431
[INFO] 2021-07-12 19:00:41,924 [run_pretraining.py:  558]:	worker_index: 2, step: 1431, cost: 7.797957, mlm loss: 7.797957, speed: 1.119775 steps/s, speed: 8.958202 samples/s, speed: 4586.599335 tokens/s, learning rate: 1.430e-05, loss_scalings: 8589.935547, pp_loss: 7.914289
[INFO] 2021-07-12 19:00:41,924 [run_pretraining.py:  512]:	********exe.run_1431******* 
[INFO] 2021-07-12 19:00:42,830 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:42,831 [run_pretraining.py:  534]:	loss/total_loss, 7.730227470397949, 1432
[INFO] 2021-07-12 19:00:42,831 [run_pretraining.py:  535]:	loss/mlm_loss, 7.730227470397949, 1432
[INFO] 2021-07-12 19:00:42,831 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.430999873264227e-05, 1432
[INFO] 2021-07-12 19:00:42,831 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1432
[INFO] 2021-07-12 19:00:42,831 [run_pretraining.py:  558]:	worker_index: 2, step: 1432, cost: 7.730227, mlm loss: 7.730227, speed: 1.102602 steps/s, speed: 8.820812 samples/s, speed: 4516.255933 tokens/s, learning rate: 1.431e-05, loss_scalings: 8589.935547, pp_loss: 7.527615
[INFO] 2021-07-12 19:00:42,831 [run_pretraining.py:  512]:	********exe.run_1432******* 
[INFO] 2021-07-12 19:00:43,728 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:43,728 [run_pretraining.py:  534]:	loss/total_loss, 8.590521812438965, 1433
[INFO] 2021-07-12 19:00:43,729 [run_pretraining.py:  535]:	loss/mlm_loss, 8.590521812438965, 1433
[INFO] 2021-07-12 19:00:43,729 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4319999536382966e-05, 1433
[INFO] 2021-07-12 19:00:43,729 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1433
[INFO] 2021-07-12 19:00:43,729 [run_pretraining.py:  558]:	worker_index: 2, step: 1433, cost: 8.590522, mlm loss: 8.590522, speed: 1.114622 steps/s, speed: 8.916972 samples/s, speed: 4565.489680 tokens/s, learning rate: 1.432e-05, loss_scalings: 8589.935547, pp_loss: 7.691767
[INFO] 2021-07-12 19:00:43,729 [run_pretraining.py:  512]:	********exe.run_1433******* 
[INFO] 2021-07-12 19:00:44,615 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:44,616 [run_pretraining.py:  534]:	loss/total_loss, 7.421799659729004, 1434
[INFO] 2021-07-12 19:00:44,616 [run_pretraining.py:  535]:	loss/mlm_loss, 7.421799659729004, 1434
[INFO] 2021-07-12 19:00:44,616 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4329999430628959e-05, 1434
[INFO] 2021-07-12 19:00:44,616 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1434
[INFO] 2021-07-12 19:00:44,616 [run_pretraining.py:  558]:	worker_index: 2, step: 1434, cost: 7.421800, mlm loss: 7.421800, speed: 1.127821 steps/s, speed: 9.022567 samples/s, speed: 4619.554520 tokens/s, learning rate: 1.433e-05, loss_scalings: 8589.935547, pp_loss: 7.244209
[INFO] 2021-07-12 19:00:44,616 [run_pretraining.py:  512]:	********exe.run_1434******* 
[INFO] 2021-07-12 19:00:45,509 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:45,510 [run_pretraining.py:  534]:	loss/total_loss, 7.175355911254883, 1435
[INFO] 2021-07-12 19:00:45,510 [run_pretraining.py:  535]:	loss/mlm_loss, 7.175355911254883, 1435
[INFO] 2021-07-12 19:00:45,510 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4339999324874952e-05, 1435
[INFO] 2021-07-12 19:00:45,510 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1435
[INFO] 2021-07-12 19:00:45,510 [run_pretraining.py:  558]:	worker_index: 2, step: 1435, cost: 7.175356, mlm loss: 7.175356, speed: 1.119376 steps/s, speed: 8.955005 samples/s, speed: 4584.962751 tokens/s, learning rate: 1.434e-05, loss_scalings: 8589.935547, pp_loss: 7.409361
[INFO] 2021-07-12 19:00:45,510 [run_pretraining.py:  512]:	********exe.run_1435******* 
[INFO] 2021-07-12 19:00:46,414 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:46,415 [run_pretraining.py:  534]:	loss/total_loss, 7.2153096199035645, 1436
[INFO] 2021-07-12 19:00:46,415 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2153096199035645, 1436
[INFO] 2021-07-12 19:00:46,415 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4349999219120946e-05, 1436
[INFO] 2021-07-12 19:00:46,415 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1436
[INFO] 2021-07-12 19:00:46,415 [run_pretraining.py:  558]:	worker_index: 2, step: 1436, cost: 7.215310, mlm loss: 7.215310, speed: 1.105641 steps/s, speed: 8.845127 samples/s, speed: 4528.705087 tokens/s, learning rate: 1.435e-05, loss_scalings: 8589.935547, pp_loss: 7.088107
[INFO] 2021-07-12 19:00:46,415 [run_pretraining.py:  512]:	********exe.run_1436******* 
[INFO] 2021-07-12 19:00:47,302 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:47,302 [run_pretraining.py:  534]:	loss/total_loss, 7.463871002197266, 1437
[INFO] 2021-07-12 19:00:47,303 [run_pretraining.py:  535]:	loss/mlm_loss, 7.463871002197266, 1437
[INFO] 2021-07-12 19:00:47,303 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4360000022861641e-05, 1437
[INFO] 2021-07-12 19:00:47,303 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1437
[INFO] 2021-07-12 19:00:47,303 [run_pretraining.py:  558]:	worker_index: 2, step: 1437, cost: 7.463871, mlm loss: 7.463871, speed: 1.127164 steps/s, speed: 9.017313 samples/s, speed: 4616.864309 tokens/s, learning rate: 1.436e-05, loss_scalings: 8589.935547, pp_loss: 7.657854
[INFO] 2021-07-12 19:00:47,303 [run_pretraining.py:  512]:	********exe.run_1437******* 
[INFO] 2021-07-12 19:00:48,199 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:48,199 [run_pretraining.py:  534]:	loss/total_loss, 7.6101908683776855, 1438
[INFO] 2021-07-12 19:00:48,199 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6101908683776855, 1438
[INFO] 2021-07-12 19:00:48,200 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4369999917107634e-05, 1438
[INFO] 2021-07-12 19:00:48,200 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1438
[INFO] 2021-07-12 19:00:48,200 [run_pretraining.py:  558]:	worker_index: 2, step: 1438, cost: 7.610191, mlm loss: 7.610191, speed: 1.115714 steps/s, speed: 8.925713 samples/s, speed: 4569.964936 tokens/s, learning rate: 1.437e-05, loss_scalings: 8589.935547, pp_loss: 7.590902
[INFO] 2021-07-12 19:00:48,200 [run_pretraining.py:  512]:	********exe.run_1438******* 
[INFO] 2021-07-12 19:00:49,097 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:49,098 [run_pretraining.py:  534]:	loss/total_loss, 7.101180076599121, 1439
[INFO] 2021-07-12 19:00:49,098 [run_pretraining.py:  535]:	loss/mlm_loss, 7.101180076599121, 1439
[INFO] 2021-07-12 19:00:49,098 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4379999811353628e-05, 1439
[INFO] 2021-07-12 19:00:49,098 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1439
[INFO] 2021-07-12 19:00:49,098 [run_pretraining.py:  558]:	worker_index: 2, step: 1439, cost: 7.101180, mlm loss: 7.101180, speed: 1.114000 steps/s, speed: 8.912001 samples/s, speed: 4562.944461 tokens/s, learning rate: 1.438e-05, loss_scalings: 8589.935547, pp_loss: 7.166820
[INFO] 2021-07-12 19:00:49,098 [run_pretraining.py:  512]:	********exe.run_1439******* 
[INFO] 2021-07-12 19:00:49,996 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:49,996 [run_pretraining.py:  534]:	loss/total_loss, 7.819963455200195, 1440
[INFO] 2021-07-12 19:00:49,996 [run_pretraining.py:  535]:	loss/mlm_loss, 7.819963455200195, 1440
[INFO] 2021-07-12 19:00:49,996 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4390000615094323e-05, 1440
[INFO] 2021-07-12 19:00:49,996 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1440
[INFO] 2021-07-12 19:00:49,997 [run_pretraining.py:  558]:	worker_index: 2, step: 1440, cost: 7.819963, mlm loss: 7.819963, speed: 1.113699 steps/s, speed: 8.909590 samples/s, speed: 4561.709859 tokens/s, learning rate: 1.439e-05, loss_scalings: 8589.935547, pp_loss: 7.679385
[INFO] 2021-07-12 19:00:49,997 [run_pretraining.py:  512]:	********exe.run_1440******* 
[INFO] 2021-07-12 19:00:50,895 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:50,896 [run_pretraining.py:  534]:	loss/total_loss, 3.901772975921631, 1441
[INFO] 2021-07-12 19:00:50,896 [run_pretraining.py:  535]:	loss/mlm_loss, 3.901772975921631, 1441
[INFO] 2021-07-12 19:00:50,896 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4399998690350913e-05, 1441
[INFO] 2021-07-12 19:00:50,896 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1441
[INFO] 2021-07-12 19:00:50,896 [run_pretraining.py:  558]:	worker_index: 2, step: 1441, cost: 3.901773, mlm loss: 3.901773, speed: 1.112229 steps/s, speed: 8.897831 samples/s, speed: 4555.689400 tokens/s, learning rate: 1.440e-05, loss_scalings: 8589.935547, pp_loss: 6.745762
[INFO] 2021-07-12 19:00:50,896 [run_pretraining.py:  512]:	********exe.run_1441******* 
[INFO] 2021-07-12 19:00:51,797 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:51,798 [run_pretraining.py:  534]:	loss/total_loss, 7.536956787109375, 1442
[INFO] 2021-07-12 19:00:51,798 [run_pretraining.py:  535]:	loss/mlm_loss, 7.536956787109375, 1442
[INFO] 2021-07-12 19:00:51,798 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4409999494091608e-05, 1442
[INFO] 2021-07-12 19:00:51,798 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1442
[INFO] 2021-07-12 19:00:51,798 [run_pretraining.py:  558]:	worker_index: 2, step: 1442, cost: 7.536957, mlm loss: 7.536957, speed: 1.109525 steps/s, speed: 8.876202 samples/s, speed: 4544.615524 tokens/s, learning rate: 1.441e-05, loss_scalings: 8589.935547, pp_loss: 7.689705
[INFO] 2021-07-12 19:00:51,798 [run_pretraining.py:  512]:	********exe.run_1442******* 
[INFO] 2021-07-12 19:00:52,723 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:52,723 [run_pretraining.py:  534]:	loss/total_loss, 7.616818428039551, 1443
[INFO] 2021-07-12 19:00:52,723 [run_pretraining.py:  535]:	loss/mlm_loss, 7.616818428039551, 1443
[INFO] 2021-07-12 19:00:52,723 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4419999388337601e-05, 1443
[INFO] 2021-07-12 19:00:52,723 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1443
[INFO] 2021-07-12 19:00:52,724 [run_pretraining.py:  558]:	worker_index: 2, step: 1443, cost: 7.616818, mlm loss: 7.616818, speed: 1.081308 steps/s, speed: 8.650462 samples/s, speed: 4429.036444 tokens/s, learning rate: 1.442e-05, loss_scalings: 8589.935547, pp_loss: 7.449109
[INFO] 2021-07-12 19:00:52,724 [run_pretraining.py:  512]:	********exe.run_1443******* 
[INFO] 2021-07-12 19:00:53,621 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:53,622 [run_pretraining.py:  534]:	loss/total_loss, 7.474422931671143, 1444
[INFO] 2021-07-12 19:00:53,622 [run_pretraining.py:  535]:	loss/mlm_loss, 7.474422931671143, 1444
[INFO] 2021-07-12 19:00:53,622 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4429999282583594e-05, 1444
[INFO] 2021-07-12 19:00:53,622 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1444
[INFO] 2021-07-12 19:00:53,622 [run_pretraining.py:  558]:	worker_index: 2, step: 1444, cost: 7.474423, mlm loss: 7.474423, speed: 1.113341 steps/s, speed: 8.906726 samples/s, speed: 4560.243501 tokens/s, learning rate: 1.443e-05, loss_scalings: 8589.935547, pp_loss: 7.662321
[INFO] 2021-07-12 19:00:53,622 [run_pretraining.py:  512]:	********exe.run_1444******* 
[INFO] 2021-07-12 19:00:54,543 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:54,544 [run_pretraining.py:  534]:	loss/total_loss, 7.395005702972412, 1445
[INFO] 2021-07-12 19:00:54,544 [run_pretraining.py:  535]:	loss/mlm_loss, 7.395005702972412, 1445
[INFO] 2021-07-12 19:00:54,544 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.444000008632429e-05, 1445
[INFO] 2021-07-12 19:00:54,544 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1445
[INFO] 2021-07-12 19:00:54,544 [run_pretraining.py:  558]:	worker_index: 2, step: 1445, cost: 7.395006, mlm loss: 7.395006, speed: 1.085441 steps/s, speed: 8.683531 samples/s, speed: 4445.967928 tokens/s, learning rate: 1.444e-05, loss_scalings: 8589.935547, pp_loss: 7.554871
[INFO] 2021-07-12 19:00:54,544 [run_pretraining.py:  512]:	********exe.run_1445******* 
[INFO] 2021-07-12 19:00:55,447 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:55,447 [run_pretraining.py:  534]:	loss/total_loss, 7.179654598236084, 1446
[INFO] 2021-07-12 19:00:55,447 [run_pretraining.py:  535]:	loss/mlm_loss, 7.179654598236084, 1446
[INFO] 2021-07-12 19:00:55,448 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4449999980570283e-05, 1446
[INFO] 2021-07-12 19:00:55,448 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1446
[INFO] 2021-07-12 19:00:55,448 [run_pretraining.py:  558]:	worker_index: 2, step: 1446, cost: 7.179655, mlm loss: 7.179655, speed: 1.107494 steps/s, speed: 8.859948 samples/s, speed: 4536.293578 tokens/s, learning rate: 1.445e-05, loss_scalings: 8589.935547, pp_loss: 7.328456
[INFO] 2021-07-12 19:00:55,448 [run_pretraining.py:  512]:	********exe.run_1446******* 
[INFO] 2021-07-12 19:00:56,346 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:56,346 [run_pretraining.py:  534]:	loss/total_loss, 7.37307071685791, 1447
[INFO] 2021-07-12 19:00:56,346 [run_pretraining.py:  535]:	loss/mlm_loss, 7.37307071685791, 1447
[INFO] 2021-07-12 19:00:56,347 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4459999874816276e-05, 1447
[INFO] 2021-07-12 19:00:56,347 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1447
[INFO] 2021-07-12 19:00:56,347 [run_pretraining.py:  558]:	worker_index: 2, step: 1447, cost: 7.373071, mlm loss: 7.373071, speed: 1.113135 steps/s, speed: 8.905078 samples/s, speed: 4559.399955 tokens/s, learning rate: 1.446e-05, loss_scalings: 8589.935547, pp_loss: 7.611601
[INFO] 2021-07-12 19:00:56,347 [run_pretraining.py:  512]:	********exe.run_1447******* 
[INFO] 2021-07-12 19:00:57,326 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:57,326 [run_pretraining.py:  534]:	loss/total_loss, 7.997291564941406, 1448
[INFO] 2021-07-12 19:00:57,326 [run_pretraining.py:  535]:	loss/mlm_loss, 7.997291564941406, 1448
[INFO] 2021-07-12 19:00:57,326 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.446999976906227e-05, 1448
[INFO] 2021-07-12 19:00:57,326 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1448
[INFO] 2021-07-12 19:00:57,327 [run_pretraining.py:  558]:	worker_index: 2, step: 1448, cost: 7.997292, mlm loss: 7.997292, speed: 1.021311 steps/s, speed: 8.170487 samples/s, speed: 4183.289163 tokens/s, learning rate: 1.447e-05, loss_scalings: 8589.935547, pp_loss: 7.664440
[INFO] 2021-07-12 19:00:57,327 [run_pretraining.py:  512]:	********exe.run_1448******* 
[INFO] 2021-07-12 19:00:58,254 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:58,254 [run_pretraining.py:  534]:	loss/total_loss, 7.146902084350586, 1449
[INFO] 2021-07-12 19:00:58,255 [run_pretraining.py:  535]:	loss/mlm_loss, 7.146902084350586, 1449
[INFO] 2021-07-12 19:00:58,255 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4480000572802965e-05, 1449
[INFO] 2021-07-12 19:00:58,255 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1449
[INFO] 2021-07-12 19:00:58,255 [run_pretraining.py:  558]:	worker_index: 2, step: 1449, cost: 7.146902, mlm loss: 7.146902, speed: 1.077983 steps/s, speed: 8.623860 samples/s, speed: 4415.416548 tokens/s, learning rate: 1.448e-05, loss_scalings: 8589.935547, pp_loss: 7.242161
[INFO] 2021-07-12 19:00:58,255 [run_pretraining.py:  512]:	********exe.run_1449******* 
[INFO] 2021-07-12 19:00:59,155 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:59,155 [run_pretraining.py:  534]:	loss/total_loss, 7.2897725105285645, 1450
[INFO] 2021-07-12 19:00:59,156 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2897725105285645, 1450
[INFO] 2021-07-12 19:00:59,156 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4489998648059554e-05, 1450
[INFO] 2021-07-12 19:00:59,156 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1450
[INFO] 2021-07-12 19:00:59,156 [run_pretraining.py:  558]:	worker_index: 2, step: 1450, cost: 7.289773, mlm loss: 7.289773, speed: 1.110614 steps/s, speed: 8.884915 samples/s, speed: 4549.076431 tokens/s, learning rate: 1.449e-05, loss_scalings: 8589.935547, pp_loss: 7.738636
[INFO] 2021-07-12 19:00:59,156 [run_pretraining.py:  512]:	********exe.run_1450******* 
[INFO] 2021-07-12 19:01:00,057 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:00,058 [run_pretraining.py:  534]:	loss/total_loss, 7.0998125076293945, 1451
[INFO] 2021-07-12 19:01:00,058 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0998125076293945, 1451
[INFO] 2021-07-12 19:01:00,058 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.449999945180025e-05, 1451
[INFO] 2021-07-12 19:01:00,058 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1451
[INFO] 2021-07-12 19:01:00,058 [run_pretraining.py:  558]:	worker_index: 2, step: 1451, cost: 7.099813, mlm loss: 7.099813, speed: 1.108956 steps/s, speed: 8.871652 samples/s, speed: 4542.285666 tokens/s, learning rate: 1.450e-05, loss_scalings: 8589.935547, pp_loss: 7.433943
[INFO] 2021-07-12 19:01:00,058 [run_pretraining.py:  512]:	********exe.run_1451******* 
[INFO] 2021-07-12 19:01:00,959 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:00,959 [run_pretraining.py:  534]:	loss/total_loss, 7.368546009063721, 1452
[INFO] 2021-07-12 19:01:00,959 [run_pretraining.py:  535]:	loss/mlm_loss, 7.368546009063721, 1452
[INFO] 2021-07-12 19:01:00,959 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4509999346046243e-05, 1452
[INFO] 2021-07-12 19:01:00,959 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1452
[INFO] 2021-07-12 19:01:00,959 [run_pretraining.py:  558]:	worker_index: 2, step: 1452, cost: 7.368546, mlm loss: 7.368546, speed: 1.110303 steps/s, speed: 8.882424 samples/s, speed: 4547.801165 tokens/s, learning rate: 1.451e-05, loss_scalings: 8589.935547, pp_loss: 7.615401
[INFO] 2021-07-12 19:01:00,959 [run_pretraining.py:  512]:	********exe.run_1452******* 
[INFO] 2021-07-12 19:01:01,861 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:01,861 [run_pretraining.py:  534]:	loss/total_loss, 6.837289810180664, 1453
[INFO] 2021-07-12 19:01:01,861 [run_pretraining.py:  535]:	loss/mlm_loss, 6.837289810180664, 1453
[INFO] 2021-07-12 19:01:01,861 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4519999240292236e-05, 1453
[INFO] 2021-07-12 19:01:01,861 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1453
[INFO] 2021-07-12 19:01:01,861 [run_pretraining.py:  558]:	worker_index: 2, step: 1453, cost: 6.837290, mlm loss: 6.837290, speed: 1.109424 steps/s, speed: 8.875390 samples/s, speed: 4544.199604 tokens/s, learning rate: 1.452e-05, loss_scalings: 8589.935547, pp_loss: 7.268856
[INFO] 2021-07-12 19:01:01,861 [run_pretraining.py:  512]:	********exe.run_1453******* 
[INFO] 2021-07-12 19:01:02,767 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:02,767 [run_pretraining.py:  534]:	loss/total_loss, 7.488045692443848, 1454
[INFO] 2021-07-12 19:01:02,767 [run_pretraining.py:  535]:	loss/mlm_loss, 7.488045692443848, 1454
[INFO] 2021-07-12 19:01:02,767 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4530000044032931e-05, 1454
[INFO] 2021-07-12 19:01:02,767 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1454
[INFO] 2021-07-12 19:01:02,767 [run_pretraining.py:  558]:	worker_index: 2, step: 1454, cost: 7.488046, mlm loss: 7.488046, speed: 1.104378 steps/s, speed: 8.835026 samples/s, speed: 4523.533529 tokens/s, learning rate: 1.453e-05, loss_scalings: 8589.935547, pp_loss: 7.408852
[INFO] 2021-07-12 19:01:02,768 [run_pretraining.py:  512]:	********exe.run_1454******* 
[INFO] 2021-07-12 19:01:03,663 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:03,663 [run_pretraining.py:  534]:	loss/total_loss, 7.4297099113464355, 1455
[INFO] 2021-07-12 19:01:03,663 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4297099113464355, 1455
[INFO] 2021-07-12 19:01:03,663 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4539999938278925e-05, 1455
[INFO] 2021-07-12 19:01:03,664 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1455
[INFO] 2021-07-12 19:01:03,664 [run_pretraining.py:  558]:	worker_index: 2, step: 1455, cost: 7.429710, mlm loss: 7.429710, speed: 1.116683 steps/s, speed: 8.933462 samples/s, speed: 4573.932588 tokens/s, learning rate: 1.454e-05, loss_scalings: 8589.935547, pp_loss: 7.427262
[INFO] 2021-07-12 19:01:03,664 [run_pretraining.py:  512]:	********exe.run_1455******* 
[INFO] 2021-07-12 19:01:04,566 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:04,566 [run_pretraining.py:  534]:	loss/total_loss, 7.310216903686523, 1456
[INFO] 2021-07-12 19:01:04,567 [run_pretraining.py:  535]:	loss/mlm_loss, 7.310216903686523, 1456
[INFO] 2021-07-12 19:01:04,567 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4549999832524918e-05, 1456
[INFO] 2021-07-12 19:01:04,567 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1456
[INFO] 2021-07-12 19:01:04,567 [run_pretraining.py:  558]:	worker_index: 2, step: 1456, cost: 7.310217, mlm loss: 7.310217, speed: 1.107943 steps/s, speed: 8.863546 samples/s, speed: 4538.135336 tokens/s, learning rate: 1.455e-05, loss_scalings: 8589.935547, pp_loss: 7.426542
[INFO] 2021-07-12 19:01:04,567 [run_pretraining.py:  512]:	********exe.run_1456******* 
[INFO] 2021-07-12 19:01:05,464 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:05,464 [run_pretraining.py:  534]:	loss/total_loss, 7.405117034912109, 1457
[INFO] 2021-07-12 19:01:05,465 [run_pretraining.py:  535]:	loss/mlm_loss, 7.405117034912109, 1457
[INFO] 2021-07-12 19:01:05,465 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4560000636265613e-05, 1457
[INFO] 2021-07-12 19:01:05,465 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1457
[INFO] 2021-07-12 19:01:05,465 [run_pretraining.py:  558]:	worker_index: 2, step: 1457, cost: 7.405117, mlm loss: 7.405117, speed: 1.114261 steps/s, speed: 8.914084 samples/s, speed: 4564.011192 tokens/s, learning rate: 1.456e-05, loss_scalings: 8589.935547, pp_loss: 7.497491
[INFO] 2021-07-12 19:01:05,465 [run_pretraining.py:  512]:	********exe.run_1457******* 
[INFO] 2021-07-12 19:01:31,547 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:31,548 [run_pretraining.py:  534]:	loss/total_loss, 7.7901387214660645, 1458
[INFO] 2021-07-12 19:01:31,548 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7901387214660645, 1458
[INFO] 2021-07-12 19:01:31,548 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4569998711522203e-05, 1458
[INFO] 2021-07-12 19:01:31,548 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1458
[INFO] 2021-07-12 19:01:31,548 [run_pretraining.py:  558]:	worker_index: 2, step: 1458, cost: 7.790139, mlm loss: 7.790139, speed: 0.038340 steps/s, speed: 0.306717 samples/s, speed: 157.039153 tokens/s, learning rate: 1.457e-05, loss_scalings: 8589.935547, pp_loss: 7.521020
[INFO] 2021-07-12 19:01:31,548 [run_pretraining.py:  512]:	********exe.run_1458******* 
[INFO] 2021-07-12 19:01:32,463 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:32,464 [run_pretraining.py:  534]:	loss/total_loss, 7.366397857666016, 1459
[INFO] 2021-07-12 19:01:32,464 [run_pretraining.py:  535]:	loss/mlm_loss, 7.366397857666016, 1459
[INFO] 2021-07-12 19:01:32,464 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4579999515262898e-05, 1459
[INFO] 2021-07-12 19:01:32,464 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1459
[INFO] 2021-07-12 19:01:32,464 [run_pretraining.py:  558]:	worker_index: 2, step: 1459, cost: 7.366398, mlm loss: 7.366398, speed: 1.092485 steps/s, speed: 8.739879 samples/s, speed: 4474.818065 tokens/s, learning rate: 1.458e-05, loss_scalings: 8589.935547, pp_loss: 7.505669
[INFO] 2021-07-12 19:01:32,464 [run_pretraining.py:  512]:	********exe.run_1459******* 
[INFO] 2021-07-12 19:01:33,389 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:33,390 [run_pretraining.py:  534]:	loss/total_loss, 7.318846702575684, 1460
[INFO] 2021-07-12 19:01:33,390 [run_pretraining.py:  535]:	loss/mlm_loss, 7.318846702575684, 1460
[INFO] 2021-07-12 19:01:33,390 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4589999409508891e-05, 1460
[INFO] 2021-07-12 19:01:33,390 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1460
[INFO] 2021-07-12 19:01:33,390 [run_pretraining.py:  558]:	worker_index: 2, step: 1460, cost: 7.318847, mlm loss: 7.318847, speed: 1.080745 steps/s, speed: 8.645964 samples/s, speed: 4426.733444 tokens/s, learning rate: 1.459e-05, loss_scalings: 8589.935547, pp_loss: 7.382638
[INFO] 2021-07-12 19:01:33,390 [run_pretraining.py:  512]:	********exe.run_1460******* 
[INFO] 2021-07-12 19:01:34,292 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:34,293 [run_pretraining.py:  534]:	loss/total_loss, 7.522750377655029, 1461
[INFO] 2021-07-12 19:01:34,293 [run_pretraining.py:  535]:	loss/mlm_loss, 7.522750377655029, 1461
[INFO] 2021-07-12 19:01:34,293 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4599999303754885e-05, 1461
[INFO] 2021-07-12 19:01:34,293 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1461
[INFO] 2021-07-12 19:01:34,293 [run_pretraining.py:  558]:	worker_index: 2, step: 1461, cost: 7.522750, mlm loss: 7.522750, speed: 1.107800 steps/s, speed: 8.862401 samples/s, speed: 4537.549215 tokens/s, learning rate: 1.460e-05, loss_scalings: 8589.935547, pp_loss: 7.223125
[INFO] 2021-07-12 19:01:34,293 [run_pretraining.py:  512]:	********exe.run_1461******* 
[INFO] 2021-07-12 19:01:35,209 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:35,209 [run_pretraining.py:  534]:	loss/total_loss, 7.8846235275268555, 1462
[INFO] 2021-07-12 19:01:35,219 [run_pretraining.py:  535]:	loss/mlm_loss, 7.8846235275268555, 1462
[INFO] 2021-07-12 19:01:35,223 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4609999198000878e-05, 1462
[INFO] 2021-07-12 19:01:35,223 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1462
[INFO] 2021-07-12 19:01:35,223 [run_pretraining.py:  558]:	worker_index: 2, step: 1462, cost: 7.884624, mlm loss: 7.884624, speed: 1.091707 steps/s, speed: 8.733655 samples/s, speed: 4471.631391 tokens/s, learning rate: 1.461e-05, loss_scalings: 8589.935547, pp_loss: 7.282898
[INFO] 2021-07-12 19:01:35,223 [run_pretraining.py:  512]:	********exe.run_1462******* 
[INFO] 2021-07-12 19:01:36,127 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:36,127 [run_pretraining.py:  534]:	loss/total_loss, 7.364782333374023, 1463
[INFO] 2021-07-12 19:01:36,127 [run_pretraining.py:  535]:	loss/mlm_loss, 7.364782333374023, 1463
[INFO] 2021-07-12 19:01:36,127 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4620000001741573e-05, 1463
[INFO] 2021-07-12 19:01:36,127 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1463
[INFO] 2021-07-12 19:01:36,127 [run_pretraining.py:  558]:	worker_index: 2, step: 1463, cost: 7.364782, mlm loss: 7.364782, speed: 1.106013 steps/s, speed: 8.848101 samples/s, speed: 4530.227682 tokens/s, learning rate: 1.462e-05, loss_scalings: 8589.935547, pp_loss: 7.332624
[INFO] 2021-07-12 19:01:36,128 [run_pretraining.py:  512]:	********exe.run_1463******* 
[INFO] 2021-07-12 19:01:37,045 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:37,045 [run_pretraining.py:  534]:	loss/total_loss, 7.470816135406494, 1464
[INFO] 2021-07-12 19:01:37,045 [run_pretraining.py:  535]:	loss/mlm_loss, 7.470816135406494, 1464
[INFO] 2021-07-12 19:01:37,045 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4629999895987567e-05, 1464
[INFO] 2021-07-12 19:01:37,045 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1464
[INFO] 2021-07-12 19:01:37,045 [run_pretraining.py:  558]:	worker_index: 2, step: 1464, cost: 7.470816, mlm loss: 7.470816, speed: 1.090061 steps/s, speed: 8.720488 samples/s, speed: 4464.889841 tokens/s, learning rate: 1.463e-05, loss_scalings: 8589.935547, pp_loss: 7.325047
[INFO] 2021-07-12 19:01:37,046 [run_pretraining.py:  512]:	********exe.run_1464******* 
[INFO] 2021-07-12 19:01:37,956 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:37,956 [run_pretraining.py:  534]:	loss/total_loss, 6.9000067710876465, 1465
[INFO] 2021-07-12 19:01:37,956 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9000067710876465, 1465
[INFO] 2021-07-12 19:01:37,956 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.463999979023356e-05, 1465
[INFO] 2021-07-12 19:01:37,956 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1465
[INFO] 2021-07-12 19:01:37,957 [run_pretraining.py:  558]:	worker_index: 2, step: 1465, cost: 6.900007, mlm loss: 6.900007, speed: 1.098289 steps/s, speed: 8.786309 samples/s, speed: 4498.590366 tokens/s, learning rate: 1.464e-05, loss_scalings: 8589.935547, pp_loss: 7.266054
[INFO] 2021-07-12 19:01:37,957 [run_pretraining.py:  512]:	********exe.run_1465******* 
[INFO] 2021-07-12 19:01:38,891 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:38,891 [run_pretraining.py:  534]:	loss/total_loss, 6.992555141448975, 1466
[INFO] 2021-07-12 19:01:38,891 [run_pretraining.py:  535]:	loss/mlm_loss, 6.992555141448975, 1466
[INFO] 2021-07-12 19:01:38,891 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4650000593974255e-05, 1466
[INFO] 2021-07-12 19:01:38,891 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1466
[INFO] 2021-07-12 19:01:38,892 [run_pretraining.py:  558]:	worker_index: 2, step: 1466, cost: 6.992555, mlm loss: 6.992555, speed: 1.070256 steps/s, speed: 8.562045 samples/s, speed: 4383.767074 tokens/s, learning rate: 1.465e-05, loss_scalings: 8589.935547, pp_loss: 7.528565
[INFO] 2021-07-12 19:01:38,892 [run_pretraining.py:  512]:	********exe.run_1466******* 
[INFO] 2021-07-12 19:01:39,811 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:39,812 [run_pretraining.py:  534]:	loss/total_loss, 7.322465896606445, 1467
[INFO] 2021-07-12 19:01:39,812 [run_pretraining.py:  535]:	loss/mlm_loss, 7.322465896606445, 1467
[INFO] 2021-07-12 19:01:39,812 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4659998669230845e-05, 1467
[INFO] 2021-07-12 19:01:39,812 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1467
[INFO] 2021-07-12 19:01:39,812 [run_pretraining.py:  558]:	worker_index: 2, step: 1467, cost: 7.322466, mlm loss: 7.322466, speed: 1.087018 steps/s, speed: 8.696147 samples/s, speed: 4452.427391 tokens/s, learning rate: 1.466e-05, loss_scalings: 8589.935547, pp_loss: 7.602529
[INFO] 2021-07-12 19:01:39,812 [run_pretraining.py:  512]:	********exe.run_1467******* 
[INFO] 2021-07-12 19:01:40,743 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:40,744 [run_pretraining.py:  534]:	loss/total_loss, 6.918524742126465, 1468
[INFO] 2021-07-12 19:01:40,744 [run_pretraining.py:  535]:	loss/mlm_loss, 6.918524742126465, 1468
[INFO] 2021-07-12 19:01:40,744 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.466999947297154e-05, 1468
[INFO] 2021-07-12 19:01:40,744 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1468
[INFO] 2021-07-12 19:01:40,744 [run_pretraining.py:  558]:	worker_index: 2, step: 1468, cost: 6.918525, mlm loss: 6.918525, speed: 1.073542 steps/s, speed: 8.588336 samples/s, speed: 4397.228134 tokens/s, learning rate: 1.467e-05, loss_scalings: 8589.935547, pp_loss: 6.474211
[INFO] 2021-07-12 19:01:40,744 [run_pretraining.py:  512]:	********exe.run_1468******* 
[INFO] 2021-07-12 19:01:41,668 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:41,668 [run_pretraining.py:  534]:	loss/total_loss, 7.9239501953125, 1469
[INFO] 2021-07-12 19:01:41,669 [run_pretraining.py:  535]:	loss/mlm_loss, 7.9239501953125, 1469
[INFO] 2021-07-12 19:01:41,669 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4679999367217533e-05, 1469
[INFO] 2021-07-12 19:01:41,669 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1469
[INFO] 2021-07-12 19:01:41,669 [run_pretraining.py:  558]:	worker_index: 2, step: 1469, cost: 7.923950, mlm loss: 7.923950, speed: 1.082209 steps/s, speed: 8.657673 samples/s, speed: 4432.728748 tokens/s, learning rate: 1.468e-05, loss_scalings: 8589.935547, pp_loss: 7.362640
[INFO] 2021-07-12 19:01:41,669 [run_pretraining.py:  512]:	********exe.run_1469******* 
[INFO] 2021-07-12 19:01:42,593 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:42,594 [run_pretraining.py:  534]:	loss/total_loss, 7.136870384216309, 1470
[INFO] 2021-07-12 19:01:42,594 [run_pretraining.py:  535]:	loss/mlm_loss, 7.136870384216309, 1470
[INFO] 2021-07-12 19:01:42,594 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4689999261463527e-05, 1470
[INFO] 2021-07-12 19:01:42,594 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1470
[INFO] 2021-07-12 19:01:42,594 [run_pretraining.py:  558]:	worker_index: 2, step: 1470, cost: 7.136870, mlm loss: 7.136870, speed: 1.081181 steps/s, speed: 8.649447 samples/s, speed: 4428.516975 tokens/s, learning rate: 1.469e-05, loss_scalings: 8589.935547, pp_loss: 7.306889
[INFO] 2021-07-12 19:01:42,594 [run_pretraining.py:  512]:	********exe.run_1470******* 
[INFO] 2021-07-12 19:01:43,514 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:43,514 [run_pretraining.py:  534]:	loss/total_loss, 7.62606954574585, 1471
[INFO] 2021-07-12 19:01:43,514 [run_pretraining.py:  535]:	loss/mlm_loss, 7.62606954574585, 1471
[INFO] 2021-07-12 19:01:43,514 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4700000065204222e-05, 1471
[INFO] 2021-07-12 19:01:43,514 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1471
[INFO] 2021-07-12 19:01:43,514 [run_pretraining.py:  558]:	worker_index: 2, step: 1471, cost: 7.626070, mlm loss: 7.626070, speed: 1.087596 steps/s, speed: 8.700768 samples/s, speed: 4454.793019 tokens/s, learning rate: 1.470e-05, loss_scalings: 8589.935547, pp_loss: 7.597125
[INFO] 2021-07-12 19:01:43,514 [run_pretraining.py:  512]:	********exe.run_1471******* 
[INFO] 2021-07-12 19:01:44,442 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:44,442 [run_pretraining.py:  534]:	loss/total_loss, 7.8644866943359375, 1472
[INFO] 2021-07-12 19:01:44,442 [run_pretraining.py:  535]:	loss/mlm_loss, 7.8644866943359375, 1472
[INFO] 2021-07-12 19:01:44,442 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4709999959450215e-05, 1472
[INFO] 2021-07-12 19:01:44,442 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1472
[INFO] 2021-07-12 19:01:44,443 [run_pretraining.py:  558]:	worker_index: 2, step: 1472, cost: 7.864487, mlm loss: 7.864487, speed: 1.078135 steps/s, speed: 8.625080 samples/s, speed: 4416.040782 tokens/s, learning rate: 1.471e-05, loss_scalings: 8589.935547, pp_loss: 7.480482
[INFO] 2021-07-12 19:01:44,443 [run_pretraining.py:  512]:	********exe.run_1472******* 
[INFO] 2021-07-12 19:01:45,365 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:45,365 [run_pretraining.py:  534]:	loss/total_loss, 7.39969539642334, 1473
[INFO] 2021-07-12 19:01:45,365 [run_pretraining.py:  535]:	loss/mlm_loss, 7.39969539642334, 1473
[INFO] 2021-07-12 19:01:45,366 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4719999853696208e-05, 1473
[INFO] 2021-07-12 19:01:45,366 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1473
[INFO] 2021-07-12 19:01:45,366 [run_pretraining.py:  558]:	worker_index: 2, step: 1473, cost: 7.399695, mlm loss: 7.399695, speed: 1.083952 steps/s, speed: 8.671615 samples/s, speed: 4439.866789 tokens/s, learning rate: 1.472e-05, loss_scalings: 8589.935547, pp_loss: 7.346794
[INFO] 2021-07-12 19:01:45,366 [run_pretraining.py:  512]:	********exe.run_1473******* 
[INFO] 2021-07-12 19:01:46,289 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:46,289 [run_pretraining.py:  534]:	loss/total_loss, 7.200383186340332, 1474
[INFO] 2021-07-12 19:01:46,289 [run_pretraining.py:  535]:	loss/mlm_loss, 7.200383186340332, 1474
[INFO] 2021-07-12 19:01:46,290 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4729999747942202e-05, 1474
[INFO] 2021-07-12 19:01:46,290 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1474
[INFO] 2021-07-12 19:01:46,290 [run_pretraining.py:  558]:	worker_index: 2, step: 1474, cost: 7.200383, mlm loss: 7.200383, speed: 1.082969 steps/s, speed: 8.663749 samples/s, speed: 4435.839580 tokens/s, learning rate: 1.473e-05, loss_scalings: 8589.935547, pp_loss: 7.329176
[INFO] 2021-07-12 19:01:46,290 [run_pretraining.py:  512]:	********exe.run_1474******* 
[INFO] 2021-07-12 19:01:47,216 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:47,216 [run_pretraining.py:  534]:	loss/total_loss, 7.308286190032959, 1475
[INFO] 2021-07-12 19:01:47,216 [run_pretraining.py:  535]:	loss/mlm_loss, 7.308286190032959, 1475
[INFO] 2021-07-12 19:01:47,216 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4740000551682897e-05, 1475
[INFO] 2021-07-12 19:01:47,216 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1475
[INFO] 2021-07-12 19:01:47,216 [run_pretraining.py:  558]:	worker_index: 2, step: 1475, cost: 7.308286, mlm loss: 7.308286, speed: 1.079779 steps/s, speed: 8.638231 samples/s, speed: 4422.774420 tokens/s, learning rate: 1.474e-05, loss_scalings: 8589.935547, pp_loss: 7.241620
[INFO] 2021-07-12 19:01:47,216 [run_pretraining.py:  512]:	********exe.run_1475******* 
[INFO] 2021-07-12 19:01:48,135 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:48,135 [run_pretraining.py:  534]:	loss/total_loss, 7.35365629196167, 1476
[INFO] 2021-07-12 19:01:48,135 [run_pretraining.py:  535]:	loss/mlm_loss, 7.35365629196167, 1476
[INFO] 2021-07-12 19:01:48,136 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4749998626939487e-05, 1476
[INFO] 2021-07-12 19:01:48,136 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1476
[INFO] 2021-07-12 19:01:48,136 [run_pretraining.py:  558]:	worker_index: 2, step: 1476, cost: 7.353656, mlm loss: 7.353656, speed: 1.088415 steps/s, speed: 8.707322 samples/s, speed: 4458.148921 tokens/s, learning rate: 1.475e-05, loss_scalings: 8589.935547, pp_loss: 7.318587
[INFO] 2021-07-12 19:01:48,136 [run_pretraining.py:  512]:	********exe.run_1476******* 
[INFO] 2021-07-12 19:01:49,062 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:49,062 [run_pretraining.py:  534]:	loss/total_loss, 7.67620849609375, 1477
[INFO] 2021-07-12 19:01:49,063 [run_pretraining.py:  535]:	loss/mlm_loss, 7.67620849609375, 1477
[INFO] 2021-07-12 19:01:49,063 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4759999430680182e-05, 1477
[INFO] 2021-07-12 19:01:49,063 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1477
[INFO] 2021-07-12 19:01:49,063 [run_pretraining.py:  558]:	worker_index: 2, step: 1477, cost: 7.676208, mlm loss: 7.676208, speed: 1.079411 steps/s, speed: 8.635290 samples/s, speed: 4421.268570 tokens/s, learning rate: 1.476e-05, loss_scalings: 8589.935547, pp_loss: 6.752954
[INFO] 2021-07-12 19:01:49,063 [run_pretraining.py:  512]:	********exe.run_1477******* 
[INFO] 2021-07-12 19:01:49,981 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:49,982 [run_pretraining.py:  534]:	loss/total_loss, 4.213982582092285, 1478
[INFO] 2021-07-12 19:01:49,982 [run_pretraining.py:  535]:	loss/mlm_loss, 4.213982582092285, 1478
[INFO] 2021-07-12 19:01:49,982 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4769999324926175e-05, 1478
[INFO] 2021-07-12 19:01:49,982 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1478
[INFO] 2021-07-12 19:01:49,982 [run_pretraining.py:  558]:	worker_index: 2, step: 1478, cost: 4.213983, mlm loss: 4.213983, speed: 1.088576 steps/s, speed: 8.708606 samples/s, speed: 4458.806127 tokens/s, learning rate: 1.477e-05, loss_scalings: 6871.948730, pp_loss: 6.421680
[INFO] 2021-07-12 19:01:49,982 [run_pretraining.py:  512]:	********exe.run_1478******* 
[INFO] 2021-07-12 19:01:50,907 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:50,907 [run_pretraining.py:  534]:	loss/total_loss, 7.321936130523682, 1479
[INFO] 2021-07-12 19:01:50,907 [run_pretraining.py:  535]:	loss/mlm_loss, 7.321936130523682, 1479
[INFO] 2021-07-12 19:01:50,908 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4779999219172169e-05, 1479
[INFO] 2021-07-12 19:01:50,908 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1479
[INFO] 2021-07-12 19:01:50,908 [run_pretraining.py:  558]:	worker_index: 2, step: 1479, cost: 7.321936, mlm loss: 7.321936, speed: 1.080962 steps/s, speed: 8.647695 samples/s, speed: 4427.619895 tokens/s, learning rate: 1.478e-05, loss_scalings: 6871.948730, pp_loss: 7.419481
[INFO] 2021-07-12 19:01:50,908 [run_pretraining.py:  512]:	********exe.run_1479******* 
[INFO] 2021-07-12 19:01:51,833 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:51,834 [run_pretraining.py:  534]:	loss/total_loss, 8.066341400146484, 1480
[INFO] 2021-07-12 19:01:51,834 [run_pretraining.py:  535]:	loss/mlm_loss, 8.066341400146484, 1480
[INFO] 2021-07-12 19:01:51,834 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4790000022912864e-05, 1480
[INFO] 2021-07-12 19:01:51,834 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1480
[INFO] 2021-07-12 19:01:51,834 [run_pretraining.py:  558]:	worker_index: 2, step: 1480, cost: 8.066341, mlm loss: 8.066341, speed: 1.080159 steps/s, speed: 8.641270 samples/s, speed: 4424.330289 tokens/s, learning rate: 1.479e-05, loss_scalings: 6871.948730, pp_loss: 7.844858
[INFO] 2021-07-12 19:01:51,834 [run_pretraining.py:  512]:	********exe.run_1480******* 
[INFO] 2021-07-12 19:01:52,768 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:52,768 [run_pretraining.py:  534]:	loss/total_loss, 6.844769477844238, 1481
[INFO] 2021-07-12 19:01:52,768 [run_pretraining.py:  535]:	loss/mlm_loss, 6.844769477844238, 1481
[INFO] 2021-07-12 19:01:52,768 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4799999917158857e-05, 1481
[INFO] 2021-07-12 19:01:52,768 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1481
[INFO] 2021-07-12 19:01:52,768 [run_pretraining.py:  558]:	worker_index: 2, step: 1481, cost: 6.844769, mlm loss: 6.844769, speed: 1.070943 steps/s, speed: 8.567548 samples/s, speed: 4386.584401 tokens/s, learning rate: 1.480e-05, loss_scalings: 6871.948730, pp_loss: 7.312535
[INFO] 2021-07-12 19:01:52,769 [run_pretraining.py:  512]:	********exe.run_1481******* 
[INFO] 2021-07-12 19:01:53,693 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:53,694 [run_pretraining.py:  534]:	loss/total_loss, 7.475700855255127, 1482
[INFO] 2021-07-12 19:01:53,694 [run_pretraining.py:  535]:	loss/mlm_loss, 7.475700855255127, 1482
[INFO] 2021-07-12 19:01:53,694 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.480999981140485e-05, 1482
[INFO] 2021-07-12 19:01:53,694 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1482
[INFO] 2021-07-12 19:01:53,694 [run_pretraining.py:  558]:	worker_index: 2, step: 1482, cost: 7.475701, mlm loss: 7.475701, speed: 1.081151 steps/s, speed: 8.649204 samples/s, speed: 4428.392549 tokens/s, learning rate: 1.481e-05, loss_scalings: 6871.948730, pp_loss: 7.643533
[INFO] 2021-07-12 19:01:53,694 [run_pretraining.py:  512]:	********exe.run_1482******* 
[INFO] 2021-07-12 19:01:54,623 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:54,623 [run_pretraining.py:  534]:	loss/total_loss, 3.9249961376190186, 1483
[INFO] 2021-07-12 19:01:54,623 [run_pretraining.py:  535]:	loss/mlm_loss, 3.9249961376190186, 1483
[INFO] 2021-07-12 19:01:54,623 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4819999705650844e-05, 1483
[INFO] 2021-07-12 19:01:54,624 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1483
[INFO] 2021-07-12 19:01:54,624 [run_pretraining.py:  558]:	worker_index: 2, step: 1483, cost: 3.924996, mlm loss: 3.924996, speed: 1.076442 steps/s, speed: 8.611537 samples/s, speed: 4409.106950 tokens/s, learning rate: 1.482e-05, loss_scalings: 6871.948730, pp_loss: 6.532893
[INFO] 2021-07-12 19:01:54,624 [run_pretraining.py:  512]:	********exe.run_1483******* 
[INFO] 2021-07-12 19:01:55,550 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:55,550 [run_pretraining.py:  534]:	loss/total_loss, 7.966386795043945, 1484
[INFO] 2021-07-12 19:01:55,550 [run_pretraining.py:  535]:	loss/mlm_loss, 7.966386795043945, 1484
[INFO] 2021-07-12 19:01:55,550 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4830000509391539e-05, 1484
[INFO] 2021-07-12 19:01:55,550 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1484
[INFO] 2021-07-12 19:01:55,550 [run_pretraining.py:  558]:	worker_index: 2, step: 1484, cost: 7.966387, mlm loss: 7.966387, speed: 1.079577 steps/s, speed: 8.636619 samples/s, speed: 4421.949092 tokens/s, learning rate: 1.483e-05, loss_scalings: 6871.948730, pp_loss: 7.476920
[INFO] 2021-07-12 19:01:55,551 [run_pretraining.py:  512]:	********exe.run_1484******* 
[INFO] 2021-07-12 19:01:56,474 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:56,475 [run_pretraining.py:  534]:	loss/total_loss, 7.833198547363281, 1485
[INFO] 2021-07-12 19:01:56,475 [run_pretraining.py:  535]:	loss/mlm_loss, 7.833198547363281, 1485
[INFO] 2021-07-12 19:01:56,475 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4839998584648129e-05, 1485
[INFO] 2021-07-12 19:01:56,475 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1485
[INFO] 2021-07-12 19:01:56,475 [run_pretraining.py:  558]:	worker_index: 2, step: 1485, cost: 7.833199, mlm loss: 7.833199, speed: 1.082311 steps/s, speed: 8.658491 samples/s, speed: 4433.147392 tokens/s, learning rate: 1.484e-05, loss_scalings: 6871.948730, pp_loss: 7.031699
[INFO] 2021-07-12 19:01:56,475 [run_pretraining.py:  512]:	********exe.run_1485******* 
[INFO] 2021-07-12 19:01:57,404 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:57,405 [run_pretraining.py:  534]:	loss/total_loss, 7.389503479003906, 1486
[INFO] 2021-07-12 19:01:57,405 [run_pretraining.py:  535]:	loss/mlm_loss, 7.389503479003906, 1486
[INFO] 2021-07-12 19:01:57,405 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4849999388388824e-05, 1486
[INFO] 2021-07-12 19:01:57,405 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1486
[INFO] 2021-07-12 19:01:57,405 [run_pretraining.py:  558]:	worker_index: 2, step: 1486, cost: 7.389503, mlm loss: 7.389503, speed: 1.075904 steps/s, speed: 8.607229 samples/s, speed: 4406.901492 tokens/s, learning rate: 1.485e-05, loss_scalings: 6871.948730, pp_loss: 7.380940
[INFO] 2021-07-12 19:01:57,405 [run_pretraining.py:  512]:	********exe.run_1486******* 
[INFO] 2021-07-12 19:01:58,329 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:58,330 [run_pretraining.py:  534]:	loss/total_loss, 7.746126174926758, 1487
[INFO] 2021-07-12 19:01:58,330 [run_pretraining.py:  535]:	loss/mlm_loss, 7.746126174926758, 1487
[INFO] 2021-07-12 19:01:58,330 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4859999282634817e-05, 1487
[INFO] 2021-07-12 19:01:58,330 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1487
[INFO] 2021-07-12 19:01:58,330 [run_pretraining.py:  558]:	worker_index: 2, step: 1487, cost: 7.746126, mlm loss: 7.746126, speed: 1.082053 steps/s, speed: 8.656427 samples/s, speed: 4432.090640 tokens/s, learning rate: 1.486e-05, loss_scalings: 6871.948730, pp_loss: 7.557399
[INFO] 2021-07-12 19:01:58,330 [run_pretraining.py:  512]:	********exe.run_1487******* 
[INFO] 2021-07-12 19:01:59,258 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:59,259 [run_pretraining.py:  534]:	loss/total_loss, 7.230031967163086, 1488
[INFO] 2021-07-12 19:01:59,259 [run_pretraining.py:  535]:	loss/mlm_loss, 7.230031967163086, 1488
[INFO] 2021-07-12 19:01:59,259 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.486999917688081e-05, 1488
[INFO] 2021-07-12 19:01:59,259 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1488
[INFO] 2021-07-12 19:01:59,259 [run_pretraining.py:  558]:	worker_index: 2, step: 1488, cost: 7.230032, mlm loss: 7.230032, speed: 1.076884 steps/s, speed: 8.615072 samples/s, speed: 4410.917073 tokens/s, learning rate: 1.487e-05, loss_scalings: 6871.948730, pp_loss: 7.308247
[INFO] 2021-07-12 19:01:59,259 [run_pretraining.py:  512]:	********exe.run_1488******* 
[INFO] 2021-07-12 19:02:00,196 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:00,196 [run_pretraining.py:  534]:	loss/total_loss, 7.022027015686035, 1489
[INFO] 2021-07-12 19:02:00,196 [run_pretraining.py:  535]:	loss/mlm_loss, 7.022027015686035, 1489
[INFO] 2021-07-12 19:02:00,196 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4879999980621506e-05, 1489
[INFO] 2021-07-12 19:02:00,196 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1489
[INFO] 2021-07-12 19:02:00,196 [run_pretraining.py:  558]:	worker_index: 2, step: 1489, cost: 7.022027, mlm loss: 7.022027, speed: 1.067562 steps/s, speed: 8.540496 samples/s, speed: 4372.734187 tokens/s, learning rate: 1.488e-05, loss_scalings: 6871.948730, pp_loss: 7.103952
[INFO] 2021-07-12 19:02:00,196 [run_pretraining.py:  512]:	********exe.run_1489******* 
[INFO] 2021-07-12 19:02:01,136 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:01,136 [run_pretraining.py:  534]:	loss/total_loss, 7.421377182006836, 1490
[INFO] 2021-07-12 19:02:01,136 [run_pretraining.py:  535]:	loss/mlm_loss, 7.421377182006836, 1490
[INFO] 2021-07-12 19:02:01,137 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4889999874867499e-05, 1490
[INFO] 2021-07-12 19:02:01,137 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1490
[INFO] 2021-07-12 19:02:01,137 [run_pretraining.py:  558]:	worker_index: 2, step: 1490, cost: 7.421377, mlm loss: 7.421377, speed: 1.064165 steps/s, speed: 8.513322 samples/s, speed: 4358.820751 tokens/s, learning rate: 1.489e-05, loss_scalings: 6871.948730, pp_loss: 7.082521
[INFO] 2021-07-12 19:02:01,137 [run_pretraining.py:  512]:	********exe.run_1490******* 
[INFO] 2021-07-12 19:02:02,043 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:02,043 [run_pretraining.py:  534]:	loss/total_loss, 6.6956024169921875, 1491
[INFO] 2021-07-12 19:02:02,044 [run_pretraining.py:  535]:	loss/mlm_loss, 6.6956024169921875, 1491
[INFO] 2021-07-12 19:02:02,044 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4899999769113492e-05, 1491
[INFO] 2021-07-12 19:02:02,044 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1491
[INFO] 2021-07-12 19:02:02,044 [run_pretraining.py:  558]:	worker_index: 2, step: 1491, cost: 6.695602, mlm loss: 6.695602, speed: 1.103101 steps/s, speed: 8.824810 samples/s, speed: 4518.302469 tokens/s, learning rate: 1.490e-05, loss_scalings: 6871.948730, pp_loss: 7.292660
[INFO] 2021-07-12 19:02:02,044 [run_pretraining.py:  512]:	********exe.run_1491******* 
[INFO] 2021-07-12 19:02:02,953 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:02,954 [run_pretraining.py:  534]:	loss/total_loss, 6.684399604797363, 1492
[INFO] 2021-07-12 19:02:02,954 [run_pretraining.py:  535]:	loss/mlm_loss, 6.684399604797363, 1492
[INFO] 2021-07-12 19:02:02,954 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4910000572854187e-05, 1492
[INFO] 2021-07-12 19:02:02,954 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1492
[INFO] 2021-07-12 19:02:02,954 [run_pretraining.py:  558]:	worker_index: 2, step: 1492, cost: 6.684400, mlm loss: 6.684400, speed: 1.099584 steps/s, speed: 8.796672 samples/s, speed: 4503.896289 tokens/s, learning rate: 1.491e-05, loss_scalings: 6871.948730, pp_loss: 6.390445
[INFO] 2021-07-12 19:02:02,954 [run_pretraining.py:  512]:	********exe.run_1492******* 
[INFO] 2021-07-12 19:02:03,861 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:03,861 [run_pretraining.py:  534]:	loss/total_loss, 7.278476715087891, 1493
[INFO] 2021-07-12 19:02:03,861 [run_pretraining.py:  535]:	loss/mlm_loss, 7.278476715087891, 1493
[INFO] 2021-07-12 19:02:03,861 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.492000046710018e-05, 1493
[INFO] 2021-07-12 19:02:03,862 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1493
[INFO] 2021-07-12 19:02:03,862 [run_pretraining.py:  558]:	worker_index: 2, step: 1493, cost: 7.278477, mlm loss: 7.278477, speed: 1.102339 steps/s, speed: 8.818714 samples/s, speed: 4515.181740 tokens/s, learning rate: 1.492e-05, loss_scalings: 6871.948730, pp_loss: 7.654494
[INFO] 2021-07-12 19:02:03,862 [run_pretraining.py:  512]:	********exe.run_1493******* 
[INFO] 2021-07-12 19:02:04,770 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:04,770 [run_pretraining.py:  534]:	loss/total_loss, 6.698218822479248, 1494
[INFO] 2021-07-12 19:02:04,770 [run_pretraining.py:  535]:	loss/mlm_loss, 6.698218822479248, 1494
[INFO] 2021-07-12 19:02:04,770 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4929999451851472e-05, 1494
[INFO] 2021-07-12 19:02:04,770 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1494
[INFO] 2021-07-12 19:02:04,771 [run_pretraining.py:  558]:	worker_index: 2, step: 1494, cost: 6.698219, mlm loss: 6.698219, speed: 1.100932 steps/s, speed: 8.807458 samples/s, speed: 4509.418321 tokens/s, learning rate: 1.493e-05, loss_scalings: 6871.948730, pp_loss: 6.859159
[INFO] 2021-07-12 19:02:04,771 [run_pretraining.py:  512]:	********exe.run_1494******* 
[INFO] 2021-07-12 19:02:05,680 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:05,680 [run_pretraining.py:  534]:	loss/total_loss, 7.185525417327881, 1495
[INFO] 2021-07-12 19:02:05,680 [run_pretraining.py:  535]:	loss/mlm_loss, 7.185525417327881, 1495
[INFO] 2021-07-12 19:02:05,680 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4939999346097466e-05, 1495
[INFO] 2021-07-12 19:02:05,681 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1495
[INFO] 2021-07-12 19:02:05,681 [run_pretraining.py:  558]:	worker_index: 2, step: 1495, cost: 7.185525, mlm loss: 7.185525, speed: 1.099577 steps/s, speed: 8.796619 samples/s, speed: 4503.869132 tokens/s, learning rate: 1.494e-05, loss_scalings: 6871.948730, pp_loss: 7.362289
[INFO] 2021-07-12 19:02:05,681 [run_pretraining.py:  512]:	********exe.run_1495******* 
[INFO] 2021-07-12 19:02:06,584 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:06,585 [run_pretraining.py:  534]:	loss/total_loss, 7.643460750579834, 1496
[INFO] 2021-07-12 19:02:06,585 [run_pretraining.py:  535]:	loss/mlm_loss, 7.643460750579834, 1496
[INFO] 2021-07-12 19:02:06,585 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4949999240343459e-05, 1496
[INFO] 2021-07-12 19:02:06,585 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1496
[INFO] 2021-07-12 19:02:06,585 [run_pretraining.py:  558]:	worker_index: 2, step: 1496, cost: 7.643461, mlm loss: 7.643461, speed: 1.106354 steps/s, speed: 8.850832 samples/s, speed: 4531.625788 tokens/s, learning rate: 1.495e-05, loss_scalings: 6871.948730, pp_loss: 7.522800
[INFO] 2021-07-12 19:02:06,585 [run_pretraining.py:  512]:	********exe.run_1496******* 
[INFO] 2021-07-12 19:02:07,491 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:07,491 [run_pretraining.py:  534]:	loss/total_loss, 6.657794952392578, 1497
[INFO] 2021-07-12 19:02:07,492 [run_pretraining.py:  535]:	loss/mlm_loss, 6.657794952392578, 1497
[INFO] 2021-07-12 19:02:07,492 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4959999134589452e-05, 1497
[INFO] 2021-07-12 19:02:07,492 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1497
[INFO] 2021-07-12 19:02:07,492 [run_pretraining.py:  558]:	worker_index: 2, step: 1497, cost: 6.657795, mlm loss: 6.657795, speed: 1.103614 steps/s, speed: 8.828915 samples/s, speed: 4520.404383 tokens/s, learning rate: 1.496e-05, loss_scalings: 6871.948730, pp_loss: 7.040497
[INFO] 2021-07-12 19:02:07,492 [run_pretraining.py:  512]:	********exe.run_1497******* 
[INFO] 2021-07-12 19:02:08,401 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:08,402 [run_pretraining.py:  534]:	loss/total_loss, 7.4999284744262695, 1498
[INFO] 2021-07-12 19:02:08,402 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4999284744262695, 1498
[INFO] 2021-07-12 19:02:08,402 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4969999938330147e-05, 1498
[INFO] 2021-07-12 19:02:08,402 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1498
[INFO] 2021-07-12 19:02:08,402 [run_pretraining.py:  558]:	worker_index: 2, step: 1498, cost: 7.499928, mlm loss: 7.499928, speed: 1.099292 steps/s, speed: 8.794332 samples/s, speed: 4502.698149 tokens/s, learning rate: 1.497e-05, loss_scalings: 6871.948730, pp_loss: 7.499383
[INFO] 2021-07-12 19:02:08,402 [run_pretraining.py:  512]:	********exe.run_1498******* 
[INFO] 2021-07-12 19:02:09,310 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:09,310 [run_pretraining.py:  534]:	loss/total_loss, 7.428496837615967, 1499
[INFO] 2021-07-12 19:02:09,310 [run_pretraining.py:  535]:	loss/mlm_loss, 7.428496837615967, 1499
[INFO] 2021-07-12 19:02:09,311 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.497999983257614e-05, 1499
[INFO] 2021-07-12 19:02:09,311 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1499
[INFO] 2021-07-12 19:02:09,311 [run_pretraining.py:  558]:	worker_index: 2, step: 1499, cost: 7.428497, mlm loss: 7.428497, speed: 1.101290 steps/s, speed: 8.810321 samples/s, speed: 4510.884149 tokens/s, learning rate: 1.498e-05, loss_scalings: 6871.948730, pp_loss: 7.636228
[INFO] 2021-07-12 19:02:09,311 [run_pretraining.py:  512]:	********exe.run_1499******* 
[INFO] 2021-07-12 19:02:10,223 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:10,224 [run_pretraining.py:  534]:	loss/total_loss, 7.082741737365723, 1500
[INFO] 2021-07-12 19:02:10,224 [run_pretraining.py:  535]:	loss/mlm_loss, 7.082741737365723, 1500
[INFO] 2021-07-12 19:02:10,224 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4989999726822134e-05, 1500
[INFO] 2021-07-12 19:02:10,224 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1500
[INFO] 2021-07-12 19:02:10,224 [run_pretraining.py:  558]:	worker_index: 2, step: 1500, cost: 7.082742, mlm loss: 7.082742, speed: 1.095457 steps/s, speed: 8.763660 samples/s, speed: 4486.993805 tokens/s, learning rate: 1.499e-05, loss_scalings: 6871.948730, pp_loss: 7.043933
[INFO] 2021-07-12 19:02:10,224 [run_pretraining.py:  512]:	********exe.run_1500******* 
[INFO] 2021-07-12 19:02:11,127 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:11,127 [run_pretraining.py:  534]:	loss/total_loss, 7.470137596130371, 1501
[INFO] 2021-07-12 19:02:11,127 [run_pretraining.py:  535]:	loss/mlm_loss, 7.470137596130371, 1501
[INFO] 2021-07-12 19:02:11,127 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.500000053056283e-05, 1501
[INFO] 2021-07-12 19:02:11,127 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1501
[INFO] 2021-07-12 19:02:11,128 [run_pretraining.py:  558]:	worker_index: 2, step: 1501, cost: 7.470138, mlm loss: 7.470138, speed: 1.107757 steps/s, speed: 8.862054 samples/s, speed: 4537.371850 tokens/s, learning rate: 1.500e-05, loss_scalings: 6871.948730, pp_loss: 7.376037
[INFO] 2021-07-12 19:02:11,128 [run_pretraining.py:  512]:	********exe.run_1501******* 
[INFO] 2021-07-12 19:02:12,035 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:12,035 [run_pretraining.py:  534]:	loss/total_loss, 7.767416954040527, 1502
[INFO] 2021-07-12 19:02:12,035 [run_pretraining.py:  535]:	loss/mlm_loss, 7.767416954040527, 1502
[INFO] 2021-07-12 19:02:12,036 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5009998605819419e-05, 1502
[INFO] 2021-07-12 19:02:12,036 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1502
[INFO] 2021-07-12 19:02:12,036 [run_pretraining.py:  558]:	worker_index: 2, step: 1502, cost: 7.767417, mlm loss: 7.767417, speed: 1.101899 steps/s, speed: 8.815193 samples/s, speed: 4513.378719 tokens/s, learning rate: 1.501e-05, loss_scalings: 6871.948730, pp_loss: 7.597490
[INFO] 2021-07-12 19:02:12,036 [run_pretraining.py:  512]:	********exe.run_1502******* 
[INFO] 2021-07-12 19:02:12,942 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:12,942 [run_pretraining.py:  534]:	loss/total_loss, 7.716927528381348, 1503
[INFO] 2021-07-12 19:02:12,942 [run_pretraining.py:  535]:	loss/mlm_loss, 7.716927528381348, 1503
[INFO] 2021-07-12 19:02:12,942 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5019999409560114e-05, 1503
[INFO] 2021-07-12 19:02:12,942 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1503
[INFO] 2021-07-12 19:02:12,943 [run_pretraining.py:  558]:	worker_index: 2, step: 1503, cost: 7.716928, mlm loss: 7.716928, speed: 1.103442 steps/s, speed: 8.827533 samples/s, speed: 4519.696790 tokens/s, learning rate: 1.502e-05, loss_scalings: 6871.948730, pp_loss: 7.505888
[INFO] 2021-07-12 19:02:12,943 [run_pretraining.py:  512]:	********exe.run_1503******* 
[INFO] 2021-07-12 19:02:13,853 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:13,853 [run_pretraining.py:  534]:	loss/total_loss, 7.809107780456543, 1504
[INFO] 2021-07-12 19:02:13,854 [run_pretraining.py:  535]:	loss/mlm_loss, 7.809107780456543, 1504
[INFO] 2021-07-12 19:02:13,854 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5029999303806107e-05, 1504
[INFO] 2021-07-12 19:02:13,854 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1504
[INFO] 2021-07-12 19:02:13,854 [run_pretraining.py:  558]:	worker_index: 2, step: 1504, cost: 7.809108, mlm loss: 7.809108, speed: 1.098083 steps/s, speed: 8.784665 samples/s, speed: 4497.748277 tokens/s, learning rate: 1.503e-05, loss_scalings: 6871.948730, pp_loss: 7.425782
[INFO] 2021-07-12 19:02:13,854 [run_pretraining.py:  512]:	********exe.run_1504******* 
[INFO] 2021-07-12 19:02:14,761 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:14,762 [run_pretraining.py:  534]:	loss/total_loss, 7.047266483306885, 1505
[INFO] 2021-07-12 19:02:14,762 [run_pretraining.py:  535]:	loss/mlm_loss, 7.047266483306885, 1505
[INFO] 2021-07-12 19:02:14,762 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.50399991980521e-05, 1505
[INFO] 2021-07-12 19:02:14,762 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1505
[INFO] 2021-07-12 19:02:14,762 [run_pretraining.py:  558]:	worker_index: 2, step: 1505, cost: 7.047266, mlm loss: 7.047266, speed: 1.101997 steps/s, speed: 8.815978 samples/s, speed: 4513.780715 tokens/s, learning rate: 1.504e-05, loss_scalings: 6871.948730, pp_loss: 7.317053
[INFO] 2021-07-12 19:02:14,762 [run_pretraining.py:  512]:	********exe.run_1505******* 
[INFO] 2021-07-12 19:02:15,672 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:15,672 [run_pretraining.py:  534]:	loss/total_loss, 7.222696781158447, 1506
[INFO] 2021-07-12 19:02:15,672 [run_pretraining.py:  535]:	loss/mlm_loss, 7.222696781158447, 1506
[INFO] 2021-07-12 19:02:15,672 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5050000001792796e-05, 1506
[INFO] 2021-07-12 19:02:15,673 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1506
[INFO] 2021-07-12 19:02:15,673 [run_pretraining.py:  558]:	worker_index: 2, step: 1506, cost: 7.222697, mlm loss: 7.222697, speed: 1.098746 steps/s, speed: 8.789967 samples/s, speed: 4500.462934 tokens/s, learning rate: 1.505e-05, loss_scalings: 6871.948730, pp_loss: 7.188957
[INFO] 2021-07-12 19:02:15,673 [run_pretraining.py:  512]:	********exe.run_1506******* 
[INFO] 2021-07-12 19:02:16,577 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:16,577 [run_pretraining.py:  534]:	loss/total_loss, 7.957406044006348, 1507
[INFO] 2021-07-12 19:02:16,577 [run_pretraining.py:  535]:	loss/mlm_loss, 7.957406044006348, 1507
[INFO] 2021-07-12 19:02:16,577 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.505999989603879e-05, 1507
[INFO] 2021-07-12 19:02:16,577 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1507
[INFO] 2021-07-12 19:02:16,577 [run_pretraining.py:  558]:	worker_index: 2, step: 1507, cost: 7.957406, mlm loss: 7.957406, speed: 1.105837 steps/s, speed: 8.846699 samples/s, speed: 4529.509845 tokens/s, learning rate: 1.506e-05, loss_scalings: 6871.948730, pp_loss: 7.478666
[INFO] 2021-07-12 19:02:16,578 [run_pretraining.py:  512]:	********exe.run_1507******* 
[INFO] 2021-07-12 19:02:17,500 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:17,501 [run_pretraining.py:  534]:	loss/total_loss, 7.39196252822876, 1508
[INFO] 2021-07-12 19:02:17,501 [run_pretraining.py:  535]:	loss/mlm_loss, 7.39196252822876, 1508
[INFO] 2021-07-12 19:02:17,501 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5069999790284783e-05, 1508
[INFO] 2021-07-12 19:02:17,501 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1508
[INFO] 2021-07-12 19:02:17,501 [run_pretraining.py:  558]:	worker_index: 2, step: 1508, cost: 7.391963, mlm loss: 7.391963, speed: 1.083631 steps/s, speed: 8.669047 samples/s, speed: 4438.552242 tokens/s, learning rate: 1.507e-05, loss_scalings: 6871.948730, pp_loss: 7.244270
[INFO] 2021-07-12 19:02:17,501 [run_pretraining.py:  512]:	********exe.run_1508******* 
[INFO] 2021-07-12 19:02:18,425 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:18,425 [run_pretraining.py:  534]:	loss/total_loss, 7.443697929382324, 1509
[INFO] 2021-07-12 19:02:18,425 [run_pretraining.py:  535]:	loss/mlm_loss, 7.443697929382324, 1509
[INFO] 2021-07-12 19:02:18,426 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5079999684530776e-05, 1509
[INFO] 2021-07-12 19:02:18,426 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1509
[INFO] 2021-07-12 19:02:18,426 [run_pretraining.py:  558]:	worker_index: 2, step: 1509, cost: 7.443698, mlm loss: 7.443698, speed: 1.082082 steps/s, speed: 8.656657 samples/s, speed: 4432.208413 tokens/s, learning rate: 1.508e-05, loss_scalings: 6871.948730, pp_loss: 7.390726
[INFO] 2021-07-12 19:02:18,426 [run_pretraining.py:  512]:	********exe.run_1509******* 
[INFO] 2021-07-12 19:02:19,327 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:19,328 [run_pretraining.py:  534]:	loss/total_loss, 4.527008533477783, 1510
[INFO] 2021-07-12 19:02:19,328 [run_pretraining.py:  535]:	loss/mlm_loss, 4.527008533477783, 1510
[INFO] 2021-07-12 19:02:19,328 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5090000488271471e-05, 1510
[INFO] 2021-07-12 19:02:19,328 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1510
[INFO] 2021-07-12 19:02:19,328 [run_pretraining.py:  558]:	worker_index: 2, step: 1510, cost: 4.527009, mlm loss: 4.527009, speed: 1.108930 steps/s, speed: 8.871438 samples/s, speed: 4542.176381 tokens/s, learning rate: 1.509e-05, loss_scalings: 6871.948730, pp_loss: 6.459463
[INFO] 2021-07-12 19:02:19,328 [run_pretraining.py:  512]:	********exe.run_1510******* 
[INFO] 2021-07-12 19:02:20,223 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:20,223 [run_pretraining.py:  534]:	loss/total_loss, 7.037023067474365, 1511
[INFO] 2021-07-12 19:02:20,223 [run_pretraining.py:  535]:	loss/mlm_loss, 7.037023067474365, 1511
[INFO] 2021-07-12 19:02:20,223 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5099998563528061e-05, 1511
[INFO] 2021-07-12 19:02:20,223 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1511
[INFO] 2021-07-12 19:02:20,224 [run_pretraining.py:  558]:	worker_index: 2, step: 1511, cost: 7.037023, mlm loss: 7.037023, speed: 1.117540 steps/s, speed: 8.940317 samples/s, speed: 4577.442412 tokens/s, learning rate: 1.510e-05, loss_scalings: 6871.948730, pp_loss: 6.678322
[INFO] 2021-07-12 19:02:20,224 [run_pretraining.py:  512]:	********exe.run_1511******* 
[INFO] 2021-07-12 19:02:21,138 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:21,139 [run_pretraining.py:  534]:	loss/total_loss, 6.807482719421387, 1512
[INFO] 2021-07-12 19:02:21,139 [run_pretraining.py:  535]:	loss/mlm_loss, 6.807482719421387, 1512
[INFO] 2021-07-12 19:02:21,139 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5109999367268756e-05, 1512
[INFO] 2021-07-12 19:02:21,139 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1512
[INFO] 2021-07-12 19:02:21,139 [run_pretraining.py:  558]:	worker_index: 2, step: 1512, cost: 6.807483, mlm loss: 6.807483, speed: 1.092655 steps/s, speed: 8.741238 samples/s, speed: 4475.514007 tokens/s, learning rate: 1.511e-05, loss_scalings: 6871.948730, pp_loss: 7.358233
[INFO] 2021-07-12 19:02:21,139 [run_pretraining.py:  512]:	********exe.run_1512******* 
[INFO] 2021-07-12 19:02:22,036 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:22,036 [run_pretraining.py:  534]:	loss/total_loss, 6.9200639724731445, 1513
[INFO] 2021-07-12 19:02:22,036 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9200639724731445, 1513
[INFO] 2021-07-12 19:02:22,036 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.511999926151475e-05, 1513
[INFO] 2021-07-12 19:02:22,036 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1513
[INFO] 2021-07-12 19:02:22,036 [run_pretraining.py:  558]:	worker_index: 2, step: 1513, cost: 6.920064, mlm loss: 6.920064, speed: 1.115412 steps/s, speed: 8.923294 samples/s, speed: 4568.726532 tokens/s, learning rate: 1.512e-05, loss_scalings: 6871.948730, pp_loss: 7.501824
[INFO] 2021-07-12 19:02:22,037 [run_pretraining.py:  512]:	********exe.run_1513******* 
[INFO] 2021-07-12 19:02:22,965 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:22,966 [run_pretraining.py:  534]:	loss/total_loss, 7.426780700683594, 1514
[INFO] 2021-07-12 19:02:22,966 [run_pretraining.py:  535]:	loss/mlm_loss, 7.426780700683594, 1514
[INFO] 2021-07-12 19:02:22,966 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5129999155760743e-05, 1514
[INFO] 2021-07-12 19:02:22,966 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1514
[INFO] 2021-07-12 19:02:22,966 [run_pretraining.py:  558]:	worker_index: 2, step: 1514, cost: 7.426781, mlm loss: 7.426781, speed: 1.076225 steps/s, speed: 8.609802 samples/s, speed: 4408.218846 tokens/s, learning rate: 1.513e-05, loss_scalings: 6871.948730, pp_loss: 7.562148
[INFO] 2021-07-12 19:02:22,966 [run_pretraining.py:  512]:	********exe.run_1514******* 
[INFO] 2021-07-12 19:02:23,889 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:23,889 [run_pretraining.py:  534]:	loss/total_loss, 3.1408989429473877, 1515
[INFO] 2021-07-12 19:02:23,889 [run_pretraining.py:  535]:	loss/mlm_loss, 3.1408989429473877, 1515
[INFO] 2021-07-12 19:02:23,889 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5139999959501438e-05, 1515
[INFO] 2021-07-12 19:02:23,889 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1515
[INFO] 2021-07-12 19:02:23,890 [run_pretraining.py:  558]:	worker_index: 2, step: 1515, cost: 3.140899, mlm loss: 3.140899, speed: 1.083768 steps/s, speed: 8.670147 samples/s, speed: 4439.115360 tokens/s, learning rate: 1.514e-05, loss_scalings: 6871.948730, pp_loss: 6.066104
[INFO] 2021-07-12 19:02:23,890 [run_pretraining.py:  512]:	********exe.run_1515******* 
[INFO] 2021-07-12 19:02:24,789 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:24,790 [run_pretraining.py:  534]:	loss/total_loss, 7.667660236358643, 1516
[INFO] 2021-07-12 19:02:24,790 [run_pretraining.py:  535]:	loss/mlm_loss, 7.667660236358643, 1516
[INFO] 2021-07-12 19:02:24,790 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5149999853747431e-05, 1516
[INFO] 2021-07-12 19:02:24,790 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1516
[INFO] 2021-07-12 19:02:24,790 [run_pretraining.py:  558]:	worker_index: 2, step: 1516, cost: 7.667660, mlm loss: 7.667660, speed: 1.110998 steps/s, speed: 8.887984 samples/s, speed: 4550.647713 tokens/s, learning rate: 1.515e-05, loss_scalings: 6871.948730, pp_loss: 7.301527
[INFO] 2021-07-12 19:02:24,790 [run_pretraining.py:  512]:	********exe.run_1516******* 
[INFO] 2021-07-12 19:02:25,687 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:25,688 [run_pretraining.py:  534]:	loss/total_loss, 6.991265296936035, 1517
[INFO] 2021-07-12 19:02:25,688 [run_pretraining.py:  535]:	loss/mlm_loss, 6.991265296936035, 1517
[INFO] 2021-07-12 19:02:25,688 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5159999747993425e-05, 1517
[INFO] 2021-07-12 19:02:25,688 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1517
[INFO] 2021-07-12 19:02:25,688 [run_pretraining.py:  558]:	worker_index: 2, step: 1517, cost: 6.991265, mlm loss: 6.991265, speed: 1.114701 steps/s, speed: 8.917607 samples/s, speed: 4565.814858 tokens/s, learning rate: 1.516e-05, loss_scalings: 6871.948730, pp_loss: 7.353383
[INFO] 2021-07-12 19:02:25,688 [run_pretraining.py:  512]:	********exe.run_1517******* 
[INFO] 2021-07-12 19:02:26,578 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:26,578 [run_pretraining.py:  534]:	loss/total_loss, 7.320560932159424, 1518
[INFO] 2021-07-12 19:02:26,578 [run_pretraining.py:  535]:	loss/mlm_loss, 7.320560932159424, 1518
[INFO] 2021-07-12 19:02:26,578 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.517000055173412e-05, 1518
[INFO] 2021-07-12 19:02:26,579 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1518
[INFO] 2021-07-12 19:02:26,579 [run_pretraining.py:  558]:	worker_index: 2, step: 1518, cost: 7.320561, mlm loss: 7.320561, speed: 1.123520 steps/s, speed: 8.988161 samples/s, speed: 4601.938450 tokens/s, learning rate: 1.517e-05, loss_scalings: 6871.948730, pp_loss: 7.401334
[INFO] 2021-07-12 19:02:26,579 [run_pretraining.py:  512]:	********exe.run_1518******* 
[INFO] 2021-07-12 19:02:27,485 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:27,486 [run_pretraining.py:  534]:	loss/total_loss, 7.707298278808594, 1519
[INFO] 2021-07-12 19:02:27,486 [run_pretraining.py:  535]:	loss/mlm_loss, 7.707298278808594, 1519
[INFO] 2021-07-12 19:02:27,486 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5180000445980113e-05, 1519
[INFO] 2021-07-12 19:02:27,486 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1519
[INFO] 2021-07-12 19:02:27,486 [run_pretraining.py:  558]:	worker_index: 2, step: 1519, cost: 7.707298, mlm loss: 7.707298, speed: 1.102392 steps/s, speed: 8.819136 samples/s, speed: 4515.397724 tokens/s, learning rate: 1.518e-05, loss_scalings: 6871.948730, pp_loss: 7.254012
[INFO] 2021-07-12 19:02:27,486 [run_pretraining.py:  512]:	********exe.run_1519******* 
[INFO] 2021-07-12 19:02:28,396 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:28,397 [run_pretraining.py:  534]:	loss/total_loss, 7.452142715454102, 1520
[INFO] 2021-07-12 19:02:28,397 [run_pretraining.py:  535]:	loss/mlm_loss, 7.452142715454102, 1520
[INFO] 2021-07-12 19:02:28,397 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5189998521236703e-05, 1520
[INFO] 2021-07-12 19:02:28,397 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1520
[INFO] 2021-07-12 19:02:28,397 [run_pretraining.py:  558]:	worker_index: 2, step: 1520, cost: 7.452143, mlm loss: 7.452143, speed: 1.098717 steps/s, speed: 8.789734 samples/s, speed: 4500.343863 tokens/s, learning rate: 1.519e-05, loss_scalings: 6871.948730, pp_loss: 7.363035
[INFO] 2021-07-12 19:02:28,397 [run_pretraining.py:  512]:	********exe.run_1520******* 
[INFO] 2021-07-12 19:02:29,308 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:29,308 [run_pretraining.py:  534]:	loss/total_loss, 7.28590726852417, 1521
[INFO] 2021-07-12 19:02:29,308 [run_pretraining.py:  535]:	loss/mlm_loss, 7.28590726852417, 1521
[INFO] 2021-07-12 19:02:29,308 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5199999324977398e-05, 1521
[INFO] 2021-07-12 19:02:29,308 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1521
[INFO] 2021-07-12 19:02:29,308 [run_pretraining.py:  558]:	worker_index: 2, step: 1521, cost: 7.285907, mlm loss: 7.285907, speed: 1.098108 steps/s, speed: 8.784865 samples/s, speed: 4497.850724 tokens/s, learning rate: 1.520e-05, loss_scalings: 6871.948730, pp_loss: 7.353595
[INFO] 2021-07-12 19:02:29,308 [run_pretraining.py:  512]:	********exe.run_1521******* 
[INFO] 2021-07-12 19:02:30,218 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:30,218 [run_pretraining.py:  534]:	loss/total_loss, 8.048721313476562, 1522
[INFO] 2021-07-12 19:02:30,218 [run_pretraining.py:  535]:	loss/mlm_loss, 8.048721313476562, 1522
[INFO] 2021-07-12 19:02:30,218 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5209999219223391e-05, 1522
[INFO] 2021-07-12 19:02:30,219 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1522
[INFO] 2021-07-12 19:02:30,219 [run_pretraining.py:  558]:	worker_index: 2, step: 1522, cost: 8.048721, mlm loss: 8.048721, speed: 1.099308 steps/s, speed: 8.794461 samples/s, speed: 4502.764237 tokens/s, learning rate: 1.521e-05, loss_scalings: 6871.948730, pp_loss: 7.616461
[INFO] 2021-07-12 19:02:30,219 [run_pretraining.py:  512]:	********exe.run_1522******* 
[INFO] 2021-07-12 19:02:31,120 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:31,121 [run_pretraining.py:  534]:	loss/total_loss, 6.676900863647461, 1523
[INFO] 2021-07-12 19:02:31,121 [run_pretraining.py:  535]:	loss/mlm_loss, 6.676900863647461, 1523
[INFO] 2021-07-12 19:02:31,121 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5219999113469385e-05, 1523
[INFO] 2021-07-12 19:02:31,121 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1523
[INFO] 2021-07-12 19:02:31,121 [run_pretraining.py:  558]:	worker_index: 2, step: 1523, cost: 6.676901, mlm loss: 6.676901, speed: 1.108577 steps/s, speed: 8.868613 samples/s, speed: 4540.729753 tokens/s, learning rate: 1.522e-05, loss_scalings: 6871.948730, pp_loss: 7.242857
[INFO] 2021-07-12 19:02:31,121 [run_pretraining.py:  512]:	********exe.run_1523******* 
[INFO] 2021-07-12 19:02:32,038 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:32,039 [run_pretraining.py:  534]:	loss/total_loss, 7.233527660369873, 1524
[INFO] 2021-07-12 19:02:32,039 [run_pretraining.py:  535]:	loss/mlm_loss, 7.233527660369873, 1524
[INFO] 2021-07-12 19:02:32,039 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.522999991721008e-05, 1524
[INFO] 2021-07-12 19:02:32,039 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1524
[INFO] 2021-07-12 19:02:32,039 [run_pretraining.py:  558]:	worker_index: 2, step: 1524, cost: 7.233528, mlm loss: 7.233528, speed: 1.090385 steps/s, speed: 8.723084 samples/s, speed: 4466.218876 tokens/s, learning rate: 1.523e-05, loss_scalings: 6871.948730, pp_loss: 6.795183
[INFO] 2021-07-12 19:02:32,039 [run_pretraining.py:  512]:	********exe.run_1524******* 
[INFO] 2021-07-12 19:02:32,937 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:32,938 [run_pretraining.py:  534]:	loss/total_loss, 6.783473014831543, 1525
[INFO] 2021-07-12 19:02:32,938 [run_pretraining.py:  535]:	loss/mlm_loss, 6.783473014831543, 1525
[INFO] 2021-07-12 19:02:32,938 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5239999811456073e-05, 1525
[INFO] 2021-07-12 19:02:32,938 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1525
[INFO] 2021-07-12 19:02:32,938 [run_pretraining.py:  558]:	worker_index: 2, step: 1525, cost: 6.783473, mlm loss: 6.783473, speed: 1.112798 steps/s, speed: 8.902387 samples/s, speed: 4558.022149 tokens/s, learning rate: 1.524e-05, loss_scalings: 6871.948730, pp_loss: 6.803992
[INFO] 2021-07-12 19:02:32,938 [run_pretraining.py:  512]:	********exe.run_1525******* 
[INFO] 2021-07-12 19:02:33,846 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:33,847 [run_pretraining.py:  534]:	loss/total_loss, 6.523586273193359, 1526
[INFO] 2021-07-12 19:02:33,847 [run_pretraining.py:  535]:	loss/mlm_loss, 6.523586273193359, 1526
[INFO] 2021-07-12 19:02:33,847 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5249999705702066e-05, 1526
[INFO] 2021-07-12 19:02:33,847 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1526
[INFO] 2021-07-12 19:02:33,847 [run_pretraining.py:  558]:	worker_index: 2, step: 1526, cost: 6.523586, mlm loss: 6.523586, speed: 1.100782 steps/s, speed: 8.806258 samples/s, speed: 4508.804093 tokens/s, learning rate: 1.525e-05, loss_scalings: 6871.948730, pp_loss: 7.202542
[INFO] 2021-07-12 19:02:33,847 [run_pretraining.py:  512]:	********exe.run_1526******* 
[INFO] 2021-07-12 19:02:34,750 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:34,751 [run_pretraining.py:  534]:	loss/total_loss, 7.761372089385986, 1527
[INFO] 2021-07-12 19:02:34,751 [run_pretraining.py:  535]:	loss/mlm_loss, 7.761372089385986, 1527
[INFO] 2021-07-12 19:02:34,751 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.526000050944276e-05, 1527
[INFO] 2021-07-12 19:02:34,751 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1527
[INFO] 2021-07-12 19:02:34,751 [run_pretraining.py:  558]:	worker_index: 2, step: 1527, cost: 7.761372, mlm loss: 7.761372, speed: 1.106948 steps/s, speed: 8.855580 samples/s, speed: 4534.057200 tokens/s, learning rate: 1.526e-05, loss_scalings: 6871.948730, pp_loss: 7.609555
[INFO] 2021-07-12 19:02:34,751 [run_pretraining.py:  512]:	********exe.run_1527******* 
[INFO] 2021-07-12 19:02:35,656 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:35,656 [run_pretraining.py:  534]:	loss/total_loss, 7.695286750793457, 1528
[INFO] 2021-07-12 19:02:35,656 [run_pretraining.py:  535]:	loss/mlm_loss, 7.695286750793457, 1528
[INFO] 2021-07-12 19:02:35,657 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5269999494194053e-05, 1528
[INFO] 2021-07-12 19:02:35,657 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1528
[INFO] 2021-07-12 19:02:35,657 [run_pretraining.py:  558]:	worker_index: 2, step: 1528, cost: 7.695287, mlm loss: 7.695287, speed: 1.105260 steps/s, speed: 8.842078 samples/s, speed: 4527.144147 tokens/s, learning rate: 1.527e-05, loss_scalings: 6871.948730, pp_loss: 7.484040
[INFO] 2021-07-12 19:02:35,657 [run_pretraining.py:  512]:	********exe.run_1528******* 
[INFO] 2021-07-12 19:02:36,558 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:36,558 [run_pretraining.py:  534]:	loss/total_loss, 6.913952350616455, 1529
[INFO] 2021-07-12 19:02:36,558 [run_pretraining.py:  535]:	loss/mlm_loss, 6.913952350616455, 1529
[INFO] 2021-07-12 19:02:36,559 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5279998478945345e-05, 1529
[INFO] 2021-07-12 19:02:36,559 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1529
[INFO] 2021-07-12 19:02:36,559 [run_pretraining.py:  558]:	worker_index: 2, step: 1529, cost: 6.913952, mlm loss: 6.913952, speed: 1.109386 steps/s, speed: 8.875087 samples/s, speed: 4544.044554 tokens/s, learning rate: 1.528e-05, loss_scalings: 6871.948730, pp_loss: 7.514061
[INFO] 2021-07-12 19:02:36,559 [run_pretraining.py:  512]:	********exe.run_1529******* 
[INFO] 2021-07-12 19:02:37,469 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:37,470 [run_pretraining.py:  534]:	loss/total_loss, 7.516141891479492, 1530
[INFO] 2021-07-12 19:02:37,470 [run_pretraining.py:  535]:	loss/mlm_loss, 7.516141891479492, 1530
[INFO] 2021-07-12 19:02:37,470 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.528999928268604e-05, 1530
[INFO] 2021-07-12 19:02:37,470 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1530
[INFO] 2021-07-12 19:02:37,470 [run_pretraining.py:  558]:	worker_index: 2, step: 1530, cost: 7.516142, mlm loss: 7.516142, speed: 1.098043 steps/s, speed: 8.784345 samples/s, speed: 4497.584607 tokens/s, learning rate: 1.529e-05, loss_scalings: 6871.948730, pp_loss: 7.674345
[INFO] 2021-07-12 19:02:37,470 [run_pretraining.py:  512]:	********exe.run_1530******* 
[INFO] 2021-07-12 19:02:38,368 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:38,369 [run_pretraining.py:  534]:	loss/total_loss, 7.7945051193237305, 1531
[INFO] 2021-07-12 19:02:38,369 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7945051193237305, 1531
[INFO] 2021-07-12 19:02:38,369 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5300000086426735e-05, 1531
[INFO] 2021-07-12 19:02:38,369 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1531
[INFO] 2021-07-12 19:02:38,369 [run_pretraining.py:  558]:	worker_index: 2, step: 1531, cost: 7.794505, mlm loss: 7.794505, speed: 1.112757 steps/s, speed: 8.902054 samples/s, speed: 4557.851645 tokens/s, learning rate: 1.530e-05, loss_scalings: 6871.948730, pp_loss: 7.843354
[INFO] 2021-07-12 19:02:38,369 [run_pretraining.py:  512]:	********exe.run_1531******* 
[INFO] 2021-07-12 19:02:39,279 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:39,279 [run_pretraining.py:  534]:	loss/total_loss, 7.601985931396484, 1532
[INFO] 2021-07-12 19:02:39,279 [run_pretraining.py:  535]:	loss/mlm_loss, 7.601985931396484, 1532
[INFO] 2021-07-12 19:02:39,280 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5309999071178026e-05, 1532
[INFO] 2021-07-12 19:02:39,280 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1532
[INFO] 2021-07-12 19:02:39,280 [run_pretraining.py:  558]:	worker_index: 2, step: 1532, cost: 7.601986, mlm loss: 7.601986, speed: 1.099109 steps/s, speed: 8.792874 samples/s, speed: 4501.951258 tokens/s, learning rate: 1.531e-05, loss_scalings: 6871.948730, pp_loss: 7.453472
[INFO] 2021-07-12 19:02:39,280 [run_pretraining.py:  512]:	********exe.run_1532******* 
[INFO] 2021-07-12 19:02:40,186 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:40,187 [run_pretraining.py:  534]:	loss/total_loss, 7.249314785003662, 1533
[INFO] 2021-07-12 19:02:40,187 [run_pretraining.py:  535]:	loss/mlm_loss, 7.249314785003662, 1533
[INFO] 2021-07-12 19:02:40,187 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.531999987491872e-05, 1533
[INFO] 2021-07-12 19:02:40,187 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1533
[INFO] 2021-07-12 19:02:40,187 [run_pretraining.py:  558]:	worker_index: 2, step: 1533, cost: 7.249315, mlm loss: 7.249315, speed: 1.102958 steps/s, speed: 8.823665 samples/s, speed: 4517.716707 tokens/s, learning rate: 1.532e-05, loss_scalings: 6871.948730, pp_loss: 7.273044
[INFO] 2021-07-12 19:02:40,187 [run_pretraining.py:  512]:	********exe.run_1533******* 
[INFO] 2021-07-12 19:02:41,106 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:41,107 [run_pretraining.py:  534]:	loss/total_loss, 6.3806281089782715, 1534
[INFO] 2021-07-12 19:02:41,107 [run_pretraining.py:  535]:	loss/mlm_loss, 6.3806281089782715, 1534
[INFO] 2021-07-12 19:02:41,107 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5330000678659417e-05, 1534
[INFO] 2021-07-12 19:02:41,107 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1534
[INFO] 2021-07-12 19:02:41,107 [run_pretraining.py:  558]:	worker_index: 2, step: 1534, cost: 6.380628, mlm loss: 6.380628, speed: 1.087586 steps/s, speed: 8.700686 samples/s, speed: 4454.751434 tokens/s, learning rate: 1.533e-05, loss_scalings: 6871.948730, pp_loss: 6.877456
[INFO] 2021-07-12 19:02:41,107 [run_pretraining.py:  512]:	********exe.run_1534******* 
[INFO] 2021-07-12 19:02:42,015 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:42,015 [run_pretraining.py:  534]:	loss/total_loss, 7.67280912399292, 1535
[INFO] 2021-07-12 19:02:42,015 [run_pretraining.py:  535]:	loss/mlm_loss, 7.67280912399292, 1535
[INFO] 2021-07-12 19:02:42,016 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.533999966341071e-05, 1535
[INFO] 2021-07-12 19:02:42,016 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1535
[INFO] 2021-07-12 19:02:42,016 [run_pretraining.py:  558]:	worker_index: 2, step: 1535, cost: 7.672809, mlm loss: 7.672809, speed: 1.101375 steps/s, speed: 8.811001 samples/s, speed: 4511.232394 tokens/s, learning rate: 1.534e-05, loss_scalings: 6871.948730, pp_loss: 7.441051
[INFO] 2021-07-12 19:02:42,016 [run_pretraining.py:  512]:	********exe.run_1535******* 
[INFO] 2021-07-12 19:02:42,915 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:42,916 [run_pretraining.py:  534]:	loss/total_loss, 7.942971706390381, 1536
[INFO] 2021-07-12 19:02:42,916 [run_pretraining.py:  535]:	loss/mlm_loss, 7.942971706390381, 1536
[INFO] 2021-07-12 19:02:42,916 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5350000467151403e-05, 1536
[INFO] 2021-07-12 19:02:42,916 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1536
[INFO] 2021-07-12 19:02:42,916 [run_pretraining.py:  558]:	worker_index: 2, step: 1536, cost: 7.942972, mlm loss: 7.942972, speed: 1.111503 steps/s, speed: 8.892023 samples/s, speed: 4552.715892 tokens/s, learning rate: 1.535e-05, loss_scalings: 6871.948730, pp_loss: 7.653509
[INFO] 2021-07-12 19:02:42,916 [run_pretraining.py:  512]:	********exe.run_1536******* 
[INFO] 2021-07-12 19:02:43,818 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:43,819 [run_pretraining.py:  534]:	loss/total_loss, 7.145829677581787, 1537
[INFO] 2021-07-12 19:02:43,819 [run_pretraining.py:  535]:	loss/mlm_loss, 7.145829677581787, 1537
[INFO] 2021-07-12 19:02:43,819 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5359999451902695e-05, 1537
[INFO] 2021-07-12 19:02:43,819 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1537
[INFO] 2021-07-12 19:02:43,819 [run_pretraining.py:  558]:	worker_index: 2, step: 1537, cost: 7.145830, mlm loss: 7.145830, speed: 1.107774 steps/s, speed: 8.862190 samples/s, speed: 4537.441356 tokens/s, learning rate: 1.536e-05, loss_scalings: 6871.948730, pp_loss: 7.456839
[INFO] 2021-07-12 19:02:43,819 [run_pretraining.py:  512]:	********exe.run_1537******* 
[INFO] 2021-07-12 19:02:44,722 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:44,723 [run_pretraining.py:  534]:	loss/total_loss, 6.94959831237793, 1538
[INFO] 2021-07-12 19:02:44,723 [run_pretraining.py:  535]:	loss/mlm_loss, 6.94959831237793, 1538
[INFO] 2021-07-12 19:02:44,723 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5369998436653987e-05, 1538
[INFO] 2021-07-12 19:02:44,723 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1538
[INFO] 2021-07-12 19:02:44,723 [run_pretraining.py:  558]:	worker_index: 2, step: 1538, cost: 6.949598, mlm loss: 6.949598, speed: 1.107388 steps/s, speed: 8.859102 samples/s, speed: 4535.860018 tokens/s, learning rate: 1.537e-05, loss_scalings: 6871.948730, pp_loss: 7.479606
[INFO] 2021-07-12 19:02:44,723 [run_pretraining.py:  512]:	********exe.run_1538******* 
[INFO] 2021-07-12 19:02:45,627 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:45,627 [run_pretraining.py:  534]:	loss/total_loss, 7.5410590171813965, 1539
[INFO] 2021-07-12 19:02:45,627 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5410590171813965, 1539
[INFO] 2021-07-12 19:02:45,628 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.537999924039468e-05, 1539
[INFO] 2021-07-12 19:02:45,628 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1539
[INFO] 2021-07-12 19:02:45,628 [run_pretraining.py:  558]:	worker_index: 2, step: 1539, cost: 7.541059, mlm loss: 7.541059, speed: 1.105916 steps/s, speed: 8.847326 samples/s, speed: 4529.831112 tokens/s, learning rate: 1.538e-05, loss_scalings: 6871.948730, pp_loss: 7.074749
[INFO] 2021-07-12 19:02:45,628 [run_pretraining.py:  512]:	********exe.run_1539******* 
[INFO] 2021-07-12 19:02:46,540 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:46,540 [run_pretraining.py:  534]:	loss/total_loss, 7.609218597412109, 1540
[INFO] 2021-07-12 19:02:46,540 [run_pretraining.py:  535]:	loss/mlm_loss, 7.609218597412109, 1540
[INFO] 2021-07-12 19:02:46,540 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5390000044135377e-05, 1540
[INFO] 2021-07-12 19:02:46,541 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1540
[INFO] 2021-07-12 19:02:46,541 [run_pretraining.py:  558]:	worker_index: 2, step: 1540, cost: 7.609219, mlm loss: 7.609219, speed: 1.096184 steps/s, speed: 8.769468 samples/s, speed: 4489.967716 tokens/s, learning rate: 1.539e-05, loss_scalings: 6871.948730, pp_loss: 7.470973
[INFO] 2021-07-12 19:02:46,541 [run_pretraining.py:  512]:	********exe.run_1540******* 
[INFO] 2021-07-12 19:02:47,448 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:47,448 [run_pretraining.py:  534]:	loss/total_loss, 7.554859161376953, 1541
[INFO] 2021-07-12 19:02:47,448 [run_pretraining.py:  535]:	loss/mlm_loss, 7.554859161376953, 1541
[INFO] 2021-07-12 19:02:47,448 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.539999902888667e-05, 1541
[INFO] 2021-07-12 19:02:47,448 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1541
[INFO] 2021-07-12 19:02:47,448 [run_pretraining.py:  558]:	worker_index: 2, step: 1541, cost: 7.554859, mlm loss: 7.554859, speed: 1.102346 steps/s, speed: 8.818768 samples/s, speed: 4515.209033 tokens/s, learning rate: 1.540e-05, loss_scalings: 6871.948730, pp_loss: 7.408859
[INFO] 2021-07-12 19:02:47,448 [run_pretraining.py:  512]:	********exe.run_1541******* 
[INFO] 2021-07-12 19:02:48,351 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:48,351 [run_pretraining.py:  534]:	loss/total_loss, 7.239167213439941, 1542
[INFO] 2021-07-12 19:02:48,351 [run_pretraining.py:  535]:	loss/mlm_loss, 7.239167213439941, 1542
[INFO] 2021-07-12 19:02:48,351 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5409999832627364e-05, 1542
[INFO] 2021-07-12 19:02:48,351 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1542
[INFO] 2021-07-12 19:02:48,351 [run_pretraining.py:  558]:	worker_index: 2, step: 1542, cost: 7.239167, mlm loss: 7.239167, speed: 1.108040 steps/s, speed: 8.864321 samples/s, speed: 4538.532163 tokens/s, learning rate: 1.541e-05, loss_scalings: 6871.948730, pp_loss: 7.566751
[INFO] 2021-07-12 19:02:48,352 [run_pretraining.py:  512]:	********exe.run_1542******* 
[INFO] 2021-07-12 19:02:49,392 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:49,392 [run_pretraining.py:  534]:	loss/total_loss, 7.690579891204834, 1543
[INFO] 2021-07-12 19:02:49,392 [run_pretraining.py:  535]:	loss/mlm_loss, 7.690579891204834, 1543
[INFO] 2021-07-12 19:02:49,393 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.542000063636806e-05, 1543
[INFO] 2021-07-12 19:02:49,393 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1543
[INFO] 2021-07-12 19:02:49,393 [run_pretraining.py:  558]:	worker_index: 2, step: 1543, cost: 7.690580, mlm loss: 7.690580, speed: 0.960964 steps/s, speed: 7.687712 samples/s, speed: 3936.108361 tokens/s, learning rate: 1.542e-05, loss_scalings: 6871.948730, pp_loss: 7.528134
[INFO] 2021-07-12 19:02:49,393 [run_pretraining.py:  512]:	********exe.run_1543******* 
[INFO] 2021-07-12 19:02:50,446 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:50,447 [run_pretraining.py:  534]:	loss/total_loss, 4.4411187171936035, 1544
[INFO] 2021-07-12 19:02:50,447 [run_pretraining.py:  535]:	loss/mlm_loss, 4.4411187171936035, 1544
[INFO] 2021-07-12 19:02:50,447 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.542999962111935e-05, 1544
[INFO] 2021-07-12 19:02:50,447 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1544
[INFO] 2021-07-12 19:02:50,447 [run_pretraining.py:  558]:	worker_index: 2, step: 1544, cost: 4.441119, mlm loss: 4.441119, speed: 0.949098 steps/s, speed: 7.592784 samples/s, speed: 3887.505238 tokens/s, learning rate: 1.543e-05, loss_scalings: 6871.948730, pp_loss: 6.599190
[INFO] 2021-07-12 19:02:50,447 [run_pretraining.py:  512]:	********exe.run_1544******* 
[INFO] 2021-07-12 19:02:51,500 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:51,501 [run_pretraining.py:  534]:	loss/total_loss, 7.364543914794922, 1545
[INFO] 2021-07-12 19:02:51,501 [run_pretraining.py:  535]:	loss/mlm_loss, 7.364543914794922, 1545
[INFO] 2021-07-12 19:02:51,501 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5440000424860045e-05, 1545
[INFO] 2021-07-12 19:02:51,501 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1545
[INFO] 2021-07-12 19:02:51,501 [run_pretraining.py:  558]:	worker_index: 2, step: 1545, cost: 7.364544, mlm loss: 7.364544, speed: 0.949314 steps/s, speed: 7.594511 samples/s, speed: 3888.389512 tokens/s, learning rate: 1.544e-05, loss_scalings: 6871.948730, pp_loss: 7.450613
[INFO] 2021-07-12 19:02:51,501 [run_pretraining.py:  512]:	********exe.run_1545******* 
[INFO] 2021-07-12 19:02:52,566 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:52,566 [run_pretraining.py:  534]:	loss/total_loss, 7.203881740570068, 1546
[INFO] 2021-07-12 19:02:52,566 [run_pretraining.py:  535]:	loss/mlm_loss, 7.203881740570068, 1546
[INFO] 2021-07-12 19:02:52,566 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5449999409611337e-05, 1546
[INFO] 2021-07-12 19:02:52,566 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1546
[INFO] 2021-07-12 19:02:52,567 [run_pretraining.py:  558]:	worker_index: 2, step: 1546, cost: 7.203882, mlm loss: 7.203882, speed: 0.938949 steps/s, speed: 7.511595 samples/s, speed: 3845.936861 tokens/s, learning rate: 1.545e-05, loss_scalings: 6871.948730, pp_loss: 7.279089
[INFO] 2021-07-12 19:02:52,567 [run_pretraining.py:  512]:	********exe.run_1546******* 
[INFO] 2021-07-12 19:02:53,649 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:53,649 [run_pretraining.py:  534]:	loss/total_loss, 7.766831398010254, 1547
[INFO] 2021-07-12 19:02:53,649 [run_pretraining.py:  535]:	loss/mlm_loss, 7.766831398010254, 1547
[INFO] 2021-07-12 19:02:53,649 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.545999839436263e-05, 1547
[INFO] 2021-07-12 19:02:53,649 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1547
[INFO] 2021-07-12 19:02:53,650 [run_pretraining.py:  558]:	worker_index: 2, step: 1547, cost: 7.766831, mlm loss: 7.766831, speed: 0.923903 steps/s, speed: 7.391225 samples/s, speed: 3784.307205 tokens/s, learning rate: 1.546e-05, loss_scalings: 6871.948730, pp_loss: 7.552786
[INFO] 2021-07-12 19:02:53,650 [run_pretraining.py:  512]:	********exe.run_1547******* 
[INFO] 2021-07-12 19:02:54,709 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:54,710 [run_pretraining.py:  534]:	loss/total_loss, 7.706934928894043, 1548
[INFO] 2021-07-12 19:02:54,710 [run_pretraining.py:  535]:	loss/mlm_loss, 7.706934928894043, 1548
[INFO] 2021-07-12 19:02:54,710 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5469999198103324e-05, 1548
[INFO] 2021-07-12 19:02:54,710 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1548
[INFO] 2021-07-12 19:02:54,710 [run_pretraining.py:  558]:	worker_index: 2, step: 1548, cost: 7.706935, mlm loss: 7.706935, speed: 0.943600 steps/s, speed: 7.548800 samples/s, speed: 3864.985704 tokens/s, learning rate: 1.547e-05, loss_scalings: 6871.948730, pp_loss: 7.613341
[INFO] 2021-07-12 19:02:54,710 [run_pretraining.py:  512]:	********exe.run_1548******* 
[INFO] 2021-07-12 19:02:55,769 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:55,769 [run_pretraining.py:  534]:	loss/total_loss, 7.232456684112549, 1549
[INFO] 2021-07-12 19:02:55,769 [run_pretraining.py:  535]:	loss/mlm_loss, 7.232456684112549, 1549
[INFO] 2021-07-12 19:02:55,769 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.548000000184402e-05, 1549
[INFO] 2021-07-12 19:02:55,769 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1549
[INFO] 2021-07-12 19:02:55,770 [run_pretraining.py:  558]:	worker_index: 2, step: 1549, cost: 7.232457, mlm loss: 7.232457, speed: 0.944248 steps/s, speed: 7.553987 samples/s, speed: 3867.641280 tokens/s, learning rate: 1.548e-05, loss_scalings: 6871.948730, pp_loss: 8.187316
[INFO] 2021-07-12 19:02:55,770 [run_pretraining.py:  512]:	********exe.run_1549******* 
[INFO] 2021-07-12 19:02:56,744 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:56,744 [run_pretraining.py:  534]:	loss/total_loss, 7.703297138214111, 1550
[INFO] 2021-07-12 19:02:56,745 [run_pretraining.py:  535]:	loss/mlm_loss, 7.703297138214111, 1550
[INFO] 2021-07-12 19:02:56,745 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.548999898659531e-05, 1550
[INFO] 2021-07-12 19:02:56,745 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1550
[INFO] 2021-07-12 19:02:56,745 [run_pretraining.py:  558]:	worker_index: 2, step: 1550, cost: 7.703297, mlm loss: 7.703297, speed: 1.025998 steps/s, speed: 8.207987 samples/s, speed: 4202.489415 tokens/s, learning rate: 1.549e-05, loss_scalings: 6871.948730, pp_loss: 7.355490
[INFO] 2021-07-12 19:02:56,745 [run_pretraining.py:  512]:	********exe.run_1550******* 
[INFO] 2021-07-12 19:02:57,709 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:57,710 [run_pretraining.py:  534]:	loss/total_loss, 6.322425365447998, 1551
[INFO] 2021-07-12 19:02:57,710 [run_pretraining.py:  535]:	loss/mlm_loss, 6.322425365447998, 1551
[INFO] 2021-07-12 19:02:57,710 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5499999790336005e-05, 1551
[INFO] 2021-07-12 19:02:57,710 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1551
[INFO] 2021-07-12 19:02:57,710 [run_pretraining.py:  558]:	worker_index: 2, step: 1551, cost: 6.322425, mlm loss: 6.322425, speed: 1.036537 steps/s, speed: 8.292299 samples/s, speed: 4245.657172 tokens/s, learning rate: 1.550e-05, loss_scalings: 6871.948730, pp_loss: 6.987118
[INFO] 2021-07-12 19:02:57,710 [run_pretraining.py:  512]:	********exe.run_1551******* 
[INFO] 2021-07-12 19:02:58,671 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:58,672 [run_pretraining.py:  534]:	loss/total_loss, 7.440946578979492, 1552
[INFO] 2021-07-12 19:02:58,672 [run_pretraining.py:  535]:	loss/mlm_loss, 7.440946578979492, 1552
[INFO] 2021-07-12 19:02:58,672 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.55100005940767e-05, 1552
[INFO] 2021-07-12 19:02:58,672 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1552
[INFO] 2021-07-12 19:02:58,672 [run_pretraining.py:  558]:	worker_index: 2, step: 1552, cost: 7.440947, mlm loss: 7.440947, speed: 1.040338 steps/s, speed: 8.322707 samples/s, speed: 4261.225844 tokens/s, learning rate: 1.551e-05, loss_scalings: 6871.948730, pp_loss: 7.376261
[INFO] 2021-07-12 19:02:58,672 [run_pretraining.py:  512]:	********exe.run_1552******* 
[INFO] 2021-07-12 19:02:59,624 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:59,624 [run_pretraining.py:  534]:	loss/total_loss, 7.5421977043151855, 1553
[INFO] 2021-07-12 19:02:59,624 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5421977043151855, 1553
[INFO] 2021-07-12 19:02:59,625 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5519999578827992e-05, 1553
[INFO] 2021-07-12 19:02:59,625 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1553
[INFO] 2021-07-12 19:02:59,625 [run_pretraining.py:  558]:	worker_index: 2, step: 1553, cost: 7.542198, mlm loss: 7.542198, speed: 1.050305 steps/s, speed: 8.402438 samples/s, speed: 4302.048468 tokens/s, learning rate: 1.552e-05, loss_scalings: 6871.948730, pp_loss: 7.294928
[INFO] 2021-07-12 19:02:59,625 [run_pretraining.py:  512]:	********exe.run_1553******* 
[INFO] 2021-07-12 19:03:00,581 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:00,581 [run_pretraining.py:  534]:	loss/total_loss, 7.658472061157227, 1554
[INFO] 2021-07-12 19:03:00,582 [run_pretraining.py:  535]:	loss/mlm_loss, 7.658472061157227, 1554
[INFO] 2021-07-12 19:03:00,582 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5530000382568687e-05, 1554
[INFO] 2021-07-12 19:03:00,582 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1554
[INFO] 2021-07-12 19:03:00,582 [run_pretraining.py:  558]:	worker_index: 2, step: 1554, cost: 7.658472, mlm loss: 7.658472, speed: 1.045514 steps/s, speed: 8.364114 samples/s, speed: 4282.426211 tokens/s, learning rate: 1.553e-05, loss_scalings: 6871.948730, pp_loss: 6.948598
[INFO] 2021-07-12 19:03:00,582 [run_pretraining.py:  512]:	********exe.run_1554******* 
[INFO] 2021-07-12 19:03:01,495 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:01,496 [run_pretraining.py:  534]:	loss/total_loss, 8.162107467651367, 1555
[INFO] 2021-07-12 19:03:01,496 [run_pretraining.py:  535]:	loss/mlm_loss, 8.162107467651367, 1555
[INFO] 2021-07-12 19:03:01,496 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.553999936731998e-05, 1555
[INFO] 2021-07-12 19:03:01,496 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1555
[INFO] 2021-07-12 19:03:01,496 [run_pretraining.py:  558]:	worker_index: 2, step: 1555, cost: 8.162107, mlm loss: 8.162107, speed: 1.094305 steps/s, speed: 8.754443 samples/s, speed: 4482.274838 tokens/s, learning rate: 1.554e-05, loss_scalings: 6871.948730, pp_loss: 7.573003
[INFO] 2021-07-12 19:03:01,496 [run_pretraining.py:  512]:	********exe.run_1555******* 
[INFO] 2021-07-12 19:03:02,427 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:02,428 [run_pretraining.py:  534]:	loss/total_loss, 6.788100719451904, 1556
[INFO] 2021-07-12 19:03:02,428 [run_pretraining.py:  535]:	loss/mlm_loss, 6.788100719451904, 1556
[INFO] 2021-07-12 19:03:02,428 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.554999835207127e-05, 1556
[INFO] 2021-07-12 19:03:02,428 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1556
[INFO] 2021-07-12 19:03:02,428 [run_pretraining.py:  558]:	worker_index: 2, step: 1556, cost: 6.788101, mlm loss: 6.788101, speed: 1.073628 steps/s, speed: 8.589024 samples/s, speed: 4397.580438 tokens/s, learning rate: 1.555e-05, loss_scalings: 6871.948730, pp_loss: 7.076487
[INFO] 2021-07-12 19:03:02,428 [run_pretraining.py:  512]:	********exe.run_1556******* 
[INFO] 2021-07-12 19:03:03,335 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:03,336 [run_pretraining.py:  534]:	loss/total_loss, 6.9876813888549805, 1557
[INFO] 2021-07-12 19:03:03,336 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9876813888549805, 1557
[INFO] 2021-07-12 19:03:03,336 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5559999155811965e-05, 1557
[INFO] 2021-07-12 19:03:03,336 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1557
[INFO] 2021-07-12 19:03:03,336 [run_pretraining.py:  558]:	worker_index: 2, step: 1557, cost: 6.987681, mlm loss: 6.987681, speed: 1.102249 steps/s, speed: 8.817989 samples/s, speed: 4514.810342 tokens/s, learning rate: 1.556e-05, loss_scalings: 6871.948730, pp_loss: 7.279485
[INFO] 2021-07-12 19:03:03,336 [run_pretraining.py:  512]:	********exe.run_1557******* 
[INFO] 2021-07-12 19:03:04,242 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:04,243 [run_pretraining.py:  534]:	loss/total_loss, 7.031928062438965, 1558
[INFO] 2021-07-12 19:03:04,243 [run_pretraining.py:  535]:	loss/mlm_loss, 7.031928062438965, 1558
[INFO] 2021-07-12 19:03:04,243 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.556999995955266e-05, 1558
[INFO] 2021-07-12 19:03:04,243 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1558
[INFO] 2021-07-12 19:03:04,243 [run_pretraining.py:  558]:	worker_index: 2, step: 1558, cost: 7.031928, mlm loss: 7.031928, speed: 1.103244 steps/s, speed: 8.825949 samples/s, speed: 4518.886006 tokens/s, learning rate: 1.557e-05, loss_scalings: 6871.948730, pp_loss: 7.043004
[INFO] 2021-07-12 19:03:04,243 [run_pretraining.py:  512]:	********exe.run_1558******* 
[INFO] 2021-07-12 19:03:05,153 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:05,153 [run_pretraining.py:  534]:	loss/total_loss, 8.230589866638184, 1559
[INFO] 2021-07-12 19:03:05,153 [run_pretraining.py:  535]:	loss/mlm_loss, 8.230589866638184, 1559
[INFO] 2021-07-12 19:03:05,153 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5579998944303952e-05, 1559
[INFO] 2021-07-12 19:03:05,153 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1559
[INFO] 2021-07-12 19:03:05,153 [run_pretraining.py:  558]:	worker_index: 2, step: 1559, cost: 8.230590, mlm loss: 8.230590, speed: 1.099221 steps/s, speed: 8.793768 samples/s, speed: 4502.409039 tokens/s, learning rate: 1.558e-05, loss_scalings: 6871.948730, pp_loss: 7.606297
[INFO] 2021-07-12 19:03:05,154 [run_pretraining.py:  512]:	********exe.run_1559******* 
[INFO] 2021-07-12 19:03:06,086 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:06,086 [run_pretraining.py:  534]:	loss/total_loss, 7.076785564422607, 1560
[INFO] 2021-07-12 19:03:06,086 [run_pretraining.py:  535]:	loss/mlm_loss, 7.076785564422607, 1560
[INFO] 2021-07-12 19:03:06,086 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5589999748044647e-05, 1560
[INFO] 2021-07-12 19:03:06,087 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1560
[INFO] 2021-07-12 19:03:06,087 [run_pretraining.py:  558]:	worker_index: 2, step: 1560, cost: 7.076786, mlm loss: 7.076786, speed: 1.072324 steps/s, speed: 8.578592 samples/s, speed: 4392.238917 tokens/s, learning rate: 1.559e-05, loss_scalings: 6871.948730, pp_loss: 7.422980
[INFO] 2021-07-12 19:03:06,087 [run_pretraining.py:  512]:	********exe.run_1560******* 
[INFO] 2021-07-12 19:03:07,010 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:07,010 [run_pretraining.py:  534]:	loss/total_loss, 7.085860252380371, 1561
[INFO] 2021-07-12 19:03:07,010 [run_pretraining.py:  535]:	loss/mlm_loss, 7.085860252380371, 1561
[INFO] 2021-07-12 19:03:07,010 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5600000551785342e-05, 1561
[INFO] 2021-07-12 19:03:07,010 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1561
[INFO] 2021-07-12 19:03:07,011 [run_pretraining.py:  558]:	worker_index: 2, step: 1561, cost: 7.085860, mlm loss: 7.085860, speed: 1.083002 steps/s, speed: 8.664018 samples/s, speed: 4435.977025 tokens/s, learning rate: 1.560e-05, loss_scalings: 6871.948730, pp_loss: 7.389461
[INFO] 2021-07-12 19:03:07,011 [run_pretraining.py:  512]:	********exe.run_1561******* 
[INFO] 2021-07-12 19:03:07,919 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:07,919 [run_pretraining.py:  534]:	loss/total_loss, 4.667936325073242, 1562
[INFO] 2021-07-12 19:03:07,920 [run_pretraining.py:  535]:	loss/mlm_loss, 4.667936325073242, 1562
[INFO] 2021-07-12 19:03:07,920 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5609999536536634e-05, 1562
[INFO] 2021-07-12 19:03:07,920 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1562
[INFO] 2021-07-12 19:03:07,920 [run_pretraining.py:  558]:	worker_index: 2, step: 1562, cost: 4.667936, mlm loss: 4.667936, speed: 1.100529 steps/s, speed: 8.804234 samples/s, speed: 4507.767742 tokens/s, learning rate: 1.561e-05, loss_scalings: 6871.948730, pp_loss: 6.724289
[INFO] 2021-07-12 19:03:07,920 [run_pretraining.py:  512]:	********exe.run_1562******* 
[INFO] 2021-07-12 19:03:08,811 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:08,812 [run_pretraining.py:  534]:	loss/total_loss, 7.27854061126709, 1563
[INFO] 2021-07-12 19:03:08,812 [run_pretraining.py:  535]:	loss/mlm_loss, 7.27854061126709, 1563
[INFO] 2021-07-12 19:03:08,812 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.562000034027733e-05, 1563
[INFO] 2021-07-12 19:03:08,812 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1563
[INFO] 2021-07-12 19:03:08,812 [run_pretraining.py:  558]:	worker_index: 2, step: 1563, cost: 7.278541, mlm loss: 7.278541, speed: 1.121660 steps/s, speed: 8.973282 samples/s, speed: 4594.320591 tokens/s, learning rate: 1.562e-05, loss_scalings: 6871.948730, pp_loss: 7.024753
[INFO] 2021-07-12 19:03:08,812 [run_pretraining.py:  512]:	********exe.run_1563******* 
[INFO] 2021-07-12 19:03:09,726 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:09,727 [run_pretraining.py:  534]:	loss/total_loss, 7.595689296722412, 1564
[INFO] 2021-07-12 19:03:09,727 [run_pretraining.py:  535]:	loss/mlm_loss, 7.595689296722412, 1564
[INFO] 2021-07-12 19:03:09,727 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.562999932502862e-05, 1564
[INFO] 2021-07-12 19:03:09,727 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1564
[INFO] 2021-07-12 19:03:09,727 [run_pretraining.py:  558]:	worker_index: 2, step: 1564, cost: 7.595689, mlm loss: 7.595689, speed: 1.093566 steps/s, speed: 8.748531 samples/s, speed: 4479.248040 tokens/s, learning rate: 1.563e-05, loss_scalings: 6871.948730, pp_loss: 7.617979
[INFO] 2021-07-12 19:03:09,727 [run_pretraining.py:  512]:	********exe.run_1564******* 
[INFO] 2021-07-12 19:03:10,631 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:10,632 [run_pretraining.py:  534]:	loss/total_loss, 6.999873638153076, 1565
[INFO] 2021-07-12 19:03:10,632 [run_pretraining.py:  535]:	loss/mlm_loss, 6.999873638153076, 1565
[INFO] 2021-07-12 19:03:10,632 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5639998309779912e-05, 1565
[INFO] 2021-07-12 19:03:10,632 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1565
[INFO] 2021-07-12 19:03:10,632 [run_pretraining.py:  558]:	worker_index: 2, step: 1565, cost: 6.999874, mlm loss: 6.999874, speed: 1.105328 steps/s, speed: 8.842624 samples/s, speed: 4527.423319 tokens/s, learning rate: 1.564e-05, loss_scalings: 6871.948730, pp_loss: 7.228890
[INFO] 2021-07-12 19:03:10,632 [run_pretraining.py:  512]:	********exe.run_1565******* 
[INFO] 2021-07-12 19:03:11,536 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:11,536 [run_pretraining.py:  534]:	loss/total_loss, 7.409750461578369, 1566
[INFO] 2021-07-12 19:03:11,536 [run_pretraining.py:  535]:	loss/mlm_loss, 7.409750461578369, 1566
[INFO] 2021-07-12 19:03:11,536 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5649999113520607e-05, 1566
[INFO] 2021-07-12 19:03:11,536 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1566
[INFO] 2021-07-12 19:03:11,537 [run_pretraining.py:  558]:	worker_index: 2, step: 1566, cost: 7.409750, mlm loss: 7.409750, speed: 1.106661 steps/s, speed: 8.853286 samples/s, speed: 4532.882430 tokens/s, learning rate: 1.565e-05, loss_scalings: 6871.948730, pp_loss: 6.985027
[INFO] 2021-07-12 19:03:11,537 [run_pretraining.py:  512]:	********exe.run_1566******* 
[INFO] 2021-07-12 19:03:12,442 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:12,442 [run_pretraining.py:  534]:	loss/total_loss, 7.673092842102051, 1567
[INFO] 2021-07-12 19:03:12,442 [run_pretraining.py:  535]:	loss/mlm_loss, 7.673092842102051, 1567
[INFO] 2021-07-12 19:03:12,443 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5659999917261302e-05, 1567
[INFO] 2021-07-12 19:03:12,443 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1567
[INFO] 2021-07-12 19:03:12,443 [run_pretraining.py:  558]:	worker_index: 2, step: 1567, cost: 7.673093, mlm loss: 7.673093, speed: 1.104269 steps/s, speed: 8.834152 samples/s, speed: 4523.085733 tokens/s, learning rate: 1.566e-05, loss_scalings: 6871.948730, pp_loss: 7.279229
[INFO] 2021-07-12 19:03:12,443 [run_pretraining.py:  512]:	********exe.run_1567******* 
[INFO] 2021-07-12 19:03:13,352 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:13,352 [run_pretraining.py:  534]:	loss/total_loss, 7.5767412185668945, 1568
[INFO] 2021-07-12 19:03:13,352 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5767412185668945, 1568
[INFO] 2021-07-12 19:03:13,352 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5669998902012594e-05, 1568
[INFO] 2021-07-12 19:03:13,352 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1568
[INFO] 2021-07-12 19:03:13,352 [run_pretraining.py:  558]:	worker_index: 2, step: 1568, cost: 7.576741, mlm loss: 7.576741, speed: 1.100074 steps/s, speed: 8.800595 samples/s, speed: 4505.904454 tokens/s, learning rate: 1.567e-05, loss_scalings: 6871.948730, pp_loss: 7.313910
[INFO] 2021-07-12 19:03:13,352 [run_pretraining.py:  512]:	********exe.run_1568******* 
[INFO] 2021-07-12 19:03:14,263 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:14,263 [run_pretraining.py:  534]:	loss/total_loss, 7.969076156616211, 1569
[INFO] 2021-07-12 19:03:14,263 [run_pretraining.py:  535]:	loss/mlm_loss, 7.969076156616211, 1569
[INFO] 2021-07-12 19:03:14,263 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.567999970575329e-05, 1569
[INFO] 2021-07-12 19:03:14,263 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1569
[INFO] 2021-07-12 19:03:14,263 [run_pretraining.py:  558]:	worker_index: 2, step: 1569, cost: 7.969076, mlm loss: 7.969076, speed: 1.098299 steps/s, speed: 8.786394 samples/s, speed: 4498.633951 tokens/s, learning rate: 1.568e-05, loss_scalings: 6871.948730, pp_loss: 7.881289
[INFO] 2021-07-12 19:03:14,264 [run_pretraining.py:  512]:	********exe.run_1569******* 
[INFO] 2021-07-12 19:03:15,166 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:15,167 [run_pretraining.py:  534]:	loss/total_loss, 7.008373260498047, 1570
[INFO] 2021-07-12 19:03:15,167 [run_pretraining.py:  535]:	loss/mlm_loss, 7.008373260498047, 1570
[INFO] 2021-07-12 19:03:15,167 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5690000509493984e-05, 1570
[INFO] 2021-07-12 19:03:15,167 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1570
[INFO] 2021-07-12 19:03:15,167 [run_pretraining.py:  558]:	worker_index: 2, step: 1570, cost: 7.008373, mlm loss: 7.008373, speed: 1.107516 steps/s, speed: 8.860129 samples/s, speed: 4536.385810 tokens/s, learning rate: 1.569e-05, loss_scalings: 6871.948730, pp_loss: 7.646515
[INFO] 2021-07-12 19:03:15,167 [run_pretraining.py:  512]:	********exe.run_1570******* 
[INFO] 2021-07-12 19:03:16,074 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:16,074 [run_pretraining.py:  534]:	loss/total_loss, 7.728619575500488, 1571
[INFO] 2021-07-12 19:03:16,074 [run_pretraining.py:  535]:	loss/mlm_loss, 7.728619575500488, 1571
[INFO] 2021-07-12 19:03:16,074 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5699999494245276e-05, 1571
[INFO] 2021-07-12 19:03:16,075 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1571
[INFO] 2021-07-12 19:03:16,075 [run_pretraining.py:  558]:	worker_index: 2, step: 1571, cost: 7.728620, mlm loss: 7.728620, speed: 1.102580 steps/s, speed: 8.820641 samples/s, speed: 4516.168079 tokens/s, learning rate: 1.570e-05, loss_scalings: 6871.948730, pp_loss: 7.776474
[INFO] 2021-07-12 19:03:16,075 [run_pretraining.py:  512]:	********exe.run_1571******* 
[INFO] 2021-07-12 19:03:16,981 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:16,981 [run_pretraining.py:  534]:	loss/total_loss, 6.883910179138184, 1572
[INFO] 2021-07-12 19:03:16,981 [run_pretraining.py:  535]:	loss/mlm_loss, 6.883910179138184, 1572
[INFO] 2021-07-12 19:03:16,982 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.571000029798597e-05, 1572
[INFO] 2021-07-12 19:03:16,982 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1572
[INFO] 2021-07-12 19:03:16,982 [run_pretraining.py:  558]:	worker_index: 2, step: 1572, cost: 6.883910, mlm loss: 6.883910, speed: 1.103103 steps/s, speed: 8.824823 samples/s, speed: 4518.309599 tokens/s, learning rate: 1.571e-05, loss_scalings: 6871.948730, pp_loss: 6.883718
[INFO] 2021-07-12 19:03:16,982 [run_pretraining.py:  512]:	********exe.run_1572******* 
[INFO] 2021-07-12 19:03:17,908 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:17,909 [run_pretraining.py:  534]:	loss/total_loss, 7.781059741973877, 1573
[INFO] 2021-07-12 19:03:17,909 [run_pretraining.py:  535]:	loss/mlm_loss, 7.781059741973877, 1573
[INFO] 2021-07-12 19:03:17,909 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5719999282737263e-05, 1573
[INFO] 2021-07-12 19:03:17,909 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1573
[INFO] 2021-07-12 19:03:17,909 [run_pretraining.py:  558]:	worker_index: 2, step: 1573, cost: 7.781060, mlm loss: 7.781060, speed: 1.078963 steps/s, speed: 8.631703 samples/s, speed: 4419.431752 tokens/s, learning rate: 1.572e-05, loss_scalings: 6871.948730, pp_loss: 6.912306
[INFO] 2021-07-12 19:03:17,909 [run_pretraining.py:  512]:	********exe.run_1573******* 
[INFO] 2021-07-12 19:03:18,821 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:18,821 [run_pretraining.py:  534]:	loss/total_loss, 6.9461517333984375, 1574
[INFO] 2021-07-12 19:03:18,821 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9461517333984375, 1574
[INFO] 2021-07-12 19:03:18,822 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5729998267488554e-05, 1574
[INFO] 2021-07-12 19:03:18,822 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1574
[INFO] 2021-07-12 19:03:18,822 [run_pretraining.py:  558]:	worker_index: 2, step: 1574, cost: 6.946152, mlm loss: 6.946152, speed: 1.096619 steps/s, speed: 8.772956 samples/s, speed: 4491.753252 tokens/s, learning rate: 1.573e-05, loss_scalings: 6871.948730, pp_loss: 7.112237
[INFO] 2021-07-12 19:03:18,822 [run_pretraining.py:  512]:	********exe.run_1574******* 
[INFO] 2021-07-12 19:03:19,727 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:19,727 [run_pretraining.py:  534]:	loss/total_loss, 7.315346717834473, 1575
[INFO] 2021-07-12 19:03:19,727 [run_pretraining.py:  535]:	loss/mlm_loss, 7.315346717834473, 1575
[INFO] 2021-07-12 19:03:19,728 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.573999907122925e-05, 1575
[INFO] 2021-07-12 19:03:19,728 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1575
[INFO] 2021-07-12 19:03:19,728 [run_pretraining.py:  558]:	worker_index: 2, step: 1575, cost: 7.315347, mlm loss: 7.315347, speed: 1.104464 steps/s, speed: 8.835708 samples/s, speed: 4523.882538 tokens/s, learning rate: 1.574e-05, loss_scalings: 6871.948730, pp_loss: 6.856041
[INFO] 2021-07-12 19:03:19,728 [run_pretraining.py:  512]:	********exe.run_1575******* 
[INFO] 2021-07-12 19:03:20,643 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:20,644 [run_pretraining.py:  534]:	loss/total_loss, 7.254639625549316, 1576
[INFO] 2021-07-12 19:03:20,644 [run_pretraining.py:  535]:	loss/mlm_loss, 7.254639625549316, 1576
[INFO] 2021-07-12 19:03:20,644 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5749999874969944e-05, 1576
[INFO] 2021-07-12 19:03:20,644 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1576
[INFO] 2021-07-12 19:03:20,644 [run_pretraining.py:  558]:	worker_index: 2, step: 1576, cost: 7.254640, mlm loss: 7.254640, speed: 1.091714 steps/s, speed: 8.733712 samples/s, speed: 4471.660489 tokens/s, learning rate: 1.575e-05, loss_scalings: 6871.948730, pp_loss: 7.826362
[INFO] 2021-07-12 19:03:20,644 [run_pretraining.py:  512]:	********exe.run_1576******* 
[INFO] 2021-07-12 19:03:21,556 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:21,557 [run_pretraining.py:  534]:	loss/total_loss, 7.690176486968994, 1577
[INFO] 2021-07-12 19:03:21,557 [run_pretraining.py:  535]:	loss/mlm_loss, 7.690176486968994, 1577
[INFO] 2021-07-12 19:03:21,557 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5759998859721236e-05, 1577
[INFO] 2021-07-12 19:03:21,557 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1577
[INFO] 2021-07-12 19:03:21,557 [run_pretraining.py:  558]:	worker_index: 2, step: 1577, cost: 7.690176, mlm loss: 7.690176, speed: 1.096273 steps/s, speed: 8.770181 samples/s, speed: 4490.332691 tokens/s, learning rate: 1.576e-05, loss_scalings: 6871.948730, pp_loss: 6.955723
[INFO] 2021-07-12 19:03:21,557 [run_pretraining.py:  512]:	********exe.run_1577******* 
[INFO] 2021-07-12 19:03:22,469 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:22,470 [run_pretraining.py:  534]:	loss/total_loss, 7.368869781494141, 1578
[INFO] 2021-07-12 19:03:22,470 [run_pretraining.py:  535]:	loss/mlm_loss, 7.368869781494141, 1578
[INFO] 2021-07-12 19:03:22,470 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.576999966346193e-05, 1578
[INFO] 2021-07-12 19:03:22,470 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1578
[INFO] 2021-07-12 19:03:22,470 [run_pretraining.py:  558]:	worker_index: 2, step: 1578, cost: 7.368870, mlm loss: 7.368870, speed: 1.096171 steps/s, speed: 8.769365 samples/s, speed: 4489.914912 tokens/s, learning rate: 1.577e-05, loss_scalings: 6871.948730, pp_loss: 7.575920
[INFO] 2021-07-12 19:03:22,470 [run_pretraining.py:  512]:	********exe.run_1578******* 
[INFO] 2021-07-12 19:03:47,812 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:47,812 [run_pretraining.py:  534]:	loss/total_loss, 7.217787742614746, 1579
[INFO] 2021-07-12 19:03:47,812 [run_pretraining.py:  535]:	loss/mlm_loss, 7.217787742614746, 1579
[INFO] 2021-07-12 19:03:47,813 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5780000467202626e-05, 1579
[INFO] 2021-07-12 19:03:47,813 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1579
[INFO] 2021-07-12 19:03:47,813 [run_pretraining.py:  558]:	worker_index: 2, step: 1579, cost: 7.217788, mlm loss: 7.217788, speed: 0.039460 steps/s, speed: 0.315680 samples/s, speed: 161.628053 tokens/s, learning rate: 1.578e-05, loss_scalings: 6871.948730, pp_loss: 6.977278
[INFO] 2021-07-12 19:03:47,813 [run_pretraining.py:  512]:	********exe.run_1579******* 
[INFO] 2021-07-12 19:03:48,755 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:48,756 [run_pretraining.py:  534]:	loss/total_loss, 7.607091903686523, 1580
[INFO] 2021-07-12 19:03:48,756 [run_pretraining.py:  535]:	loss/mlm_loss, 7.607091903686523, 1580
[INFO] 2021-07-12 19:03:48,756 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5789999451953918e-05, 1580
[INFO] 2021-07-12 19:03:48,756 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1580
[INFO] 2021-07-12 19:03:48,756 [run_pretraining.py:  558]:	worker_index: 2, step: 1580, cost: 7.607092, mlm loss: 7.607092, speed: 1.060580 steps/s, speed: 8.484637 samples/s, speed: 4344.134207 tokens/s, learning rate: 1.579e-05, loss_scalings: 6871.948730, pp_loss: 7.763891
[INFO] 2021-07-12 19:03:48,756 [run_pretraining.py:  512]:	********exe.run_1580******* 
[INFO] 2021-07-12 19:03:49,683 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:49,683 [run_pretraining.py:  534]:	loss/total_loss, 7.45604133605957, 1581
[INFO] 2021-07-12 19:03:49,683 [run_pretraining.py:  535]:	loss/mlm_loss, 7.45604133605957, 1581
[INFO] 2021-07-12 19:03:49,683 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5800000255694613e-05, 1581
[INFO] 2021-07-12 19:03:49,684 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1581
[INFO] 2021-07-12 19:03:49,684 [run_pretraining.py:  558]:	worker_index: 2, step: 1581, cost: 7.456041, mlm loss: 7.456041, speed: 1.078889 steps/s, speed: 8.631110 samples/s, speed: 4419.128227 tokens/s, learning rate: 1.580e-05, loss_scalings: 6871.948730, pp_loss: 7.791724
[INFO] 2021-07-12 19:03:49,684 [run_pretraining.py:  512]:	********exe.run_1581******* 
[INFO] 2021-07-12 19:03:50,635 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:50,635 [run_pretraining.py:  534]:	loss/total_loss, 7.080112934112549, 1582
[INFO] 2021-07-12 19:03:50,635 [run_pretraining.py:  535]:	loss/mlm_loss, 7.080112934112549, 1582
[INFO] 2021-07-12 19:03:50,636 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5809999240445904e-05, 1582
[INFO] 2021-07-12 19:03:50,636 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1582
[INFO] 2021-07-12 19:03:50,636 [run_pretraining.py:  558]:	worker_index: 2, step: 1582, cost: 7.080113, mlm loss: 7.080113, speed: 1.051071 steps/s, speed: 8.408568 samples/s, speed: 4305.186733 tokens/s, learning rate: 1.581e-05, loss_scalings: 6871.948730, pp_loss: 6.908361
[INFO] 2021-07-12 19:03:50,636 [run_pretraining.py:  512]:	********exe.run_1582******* 
[INFO] 2021-07-12 19:03:51,570 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:51,570 [run_pretraining.py:  534]:	loss/total_loss, 6.783188819885254, 1583
[INFO] 2021-07-12 19:03:51,570 [run_pretraining.py:  535]:	loss/mlm_loss, 6.783188819885254, 1583
[INFO] 2021-07-12 19:03:51,571 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.58200000441866e-05, 1583
[INFO] 2021-07-12 19:03:51,571 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1583
[INFO] 2021-07-12 19:03:51,571 [run_pretraining.py:  558]:	worker_index: 2, step: 1583, cost: 6.783189, mlm loss: 6.783189, speed: 1.070178 steps/s, speed: 8.561425 samples/s, speed: 4383.449414 tokens/s, learning rate: 1.582e-05, loss_scalings: 6871.948730, pp_loss: 6.917478
[INFO] 2021-07-12 19:03:51,571 [run_pretraining.py:  512]:	********exe.run_1583******* 
[INFO] 2021-07-12 19:03:52,488 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:52,489 [run_pretraining.py:  534]:	loss/total_loss, 7.402817726135254, 1584
[INFO] 2021-07-12 19:03:52,489 [run_pretraining.py:  535]:	loss/mlm_loss, 7.402817726135254, 1584
[INFO] 2021-07-12 19:03:52,489 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.582999902893789e-05, 1584
[INFO] 2021-07-12 19:03:52,489 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1584
[INFO] 2021-07-12 19:03:52,489 [run_pretraining.py:  558]:	worker_index: 2, step: 1584, cost: 7.402818, mlm loss: 7.402818, speed: 1.089575 steps/s, speed: 8.716601 samples/s, speed: 4462.899510 tokens/s, learning rate: 1.583e-05, loss_scalings: 6871.948730, pp_loss: 6.740947
[INFO] 2021-07-12 19:03:52,489 [run_pretraining.py:  512]:	********exe.run_1584******* 
[INFO] 2021-07-12 19:03:53,403 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:53,404 [run_pretraining.py:  534]:	loss/total_loss, 7.525849342346191, 1585
[INFO] 2021-07-12 19:03:53,404 [run_pretraining.py:  535]:	loss/mlm_loss, 7.525849342346191, 1585
[INFO] 2021-07-12 19:03:53,404 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5839999832678586e-05, 1585
[INFO] 2021-07-12 19:03:53,404 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1585
[INFO] 2021-07-12 19:03:53,404 [run_pretraining.py:  558]:	worker_index: 2, step: 1585, cost: 7.525849, mlm loss: 7.525849, speed: 1.093416 steps/s, speed: 8.747329 samples/s, speed: 4478.632663 tokens/s, learning rate: 1.584e-05, loss_scalings: 6871.948730, pp_loss: 7.510801
[INFO] 2021-07-12 19:03:53,404 [run_pretraining.py:  512]:	********exe.run_1585******* 
[INFO] 2021-07-12 19:03:54,374 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:54,375 [run_pretraining.py:  534]:	loss/total_loss, 7.332972526550293, 1586
[INFO] 2021-07-12 19:03:54,375 [run_pretraining.py:  535]:	loss/mlm_loss, 7.332972526550293, 1586
[INFO] 2021-07-12 19:03:54,375 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5849998817429878e-05, 1586
[INFO] 2021-07-12 19:03:54,375 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1586
[INFO] 2021-07-12 19:03:54,375 [run_pretraining.py:  558]:	worker_index: 2, step: 1586, cost: 7.332973, mlm loss: 7.332973, speed: 1.030430 steps/s, speed: 8.243441 samples/s, speed: 4220.641794 tokens/s, learning rate: 1.585e-05, loss_scalings: 6871.948730, pp_loss: 7.211987
[INFO] 2021-07-12 19:03:54,375 [run_pretraining.py:  512]:	********exe.run_1586******* 
[INFO] 2021-07-12 19:03:55,300 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:55,300 [run_pretraining.py:  534]:	loss/total_loss, 7.746335029602051, 1587
[INFO] 2021-07-12 19:03:55,300 [run_pretraining.py:  535]:	loss/mlm_loss, 7.746335029602051, 1587
[INFO] 2021-07-12 19:03:55,301 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5859999621170573e-05, 1587
[INFO] 2021-07-12 19:03:55,301 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1587
[INFO] 2021-07-12 19:03:55,301 [run_pretraining.py:  558]:	worker_index: 2, step: 1587, cost: 7.746335, mlm loss: 7.746335, speed: 1.081338 steps/s, speed: 8.650707 samples/s, speed: 4429.162048 tokens/s, learning rate: 1.586e-05, loss_scalings: 6871.948730, pp_loss: 7.659168
[INFO] 2021-07-12 19:03:55,301 [run_pretraining.py:  512]:	********exe.run_1587******* 
[INFO] 2021-07-12 19:03:56,212 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:56,213 [run_pretraining.py:  534]:	loss/total_loss, 7.328289985656738, 1588
[INFO] 2021-07-12 19:03:56,213 [run_pretraining.py:  535]:	loss/mlm_loss, 7.328289985656738, 1588
[INFO] 2021-07-12 19:03:56,213 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5870000424911268e-05, 1588
[INFO] 2021-07-12 19:03:56,213 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1588
[INFO] 2021-07-12 19:03:56,213 [run_pretraining.py:  558]:	worker_index: 2, step: 1588, cost: 7.328290, mlm loss: 7.328290, speed: 1.096480 steps/s, speed: 8.771843 samples/s, speed: 4491.183745 tokens/s, learning rate: 1.587e-05, loss_scalings: 6871.948730, pp_loss: 7.187533
[INFO] 2021-07-12 19:03:56,213 [run_pretraining.py:  512]:	********exe.run_1588******* 
[INFO] 2021-07-12 19:03:57,160 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:57,160 [run_pretraining.py:  534]:	loss/total_loss, 7.388001441955566, 1589
[INFO] 2021-07-12 19:03:57,160 [run_pretraining.py:  535]:	loss/mlm_loss, 7.388001441955566, 1589
[INFO] 2021-07-12 19:03:57,160 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.587999940966256e-05, 1589
[INFO] 2021-07-12 19:03:57,160 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1589
[INFO] 2021-07-12 19:03:57,160 [run_pretraining.py:  558]:	worker_index: 2, step: 1589, cost: 7.388001, mlm loss: 7.388001, speed: 1.056511 steps/s, speed: 8.452087 samples/s, speed: 4327.468750 tokens/s, learning rate: 1.588e-05, loss_scalings: 6871.948730, pp_loss: 7.358778
[INFO] 2021-07-12 19:03:57,160 [run_pretraining.py:  512]:	********exe.run_1589******* 
[INFO] 2021-07-12 19:03:58,075 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:58,076 [run_pretraining.py:  534]:	loss/total_loss, 7.208340167999268, 1590
[INFO] 2021-07-12 19:03:58,076 [run_pretraining.py:  535]:	loss/mlm_loss, 7.208340167999268, 1590
[INFO] 2021-07-12 19:03:58,076 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.588999839441385e-05, 1590
[INFO] 2021-07-12 19:03:58,076 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1590
[INFO] 2021-07-12 19:03:58,076 [run_pretraining.py:  558]:	worker_index: 2, step: 1590, cost: 7.208340, mlm loss: 7.208340, speed: 1.092594 steps/s, speed: 8.740756 samples/s, speed: 4475.266847 tokens/s, learning rate: 1.589e-05, loss_scalings: 6871.948730, pp_loss: 7.275176
[INFO] 2021-07-12 19:03:58,076 [run_pretraining.py:  512]:	********exe.run_1590******* 
[INFO] 2021-07-12 19:03:58,996 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:58,996 [run_pretraining.py:  534]:	loss/total_loss, 4.548603534698486, 1591
[INFO] 2021-07-12 19:03:58,996 [run_pretraining.py:  535]:	loss/mlm_loss, 4.548603534698486, 1591
[INFO] 2021-07-12 19:03:58,997 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5899999198154546e-05, 1591
[INFO] 2021-07-12 19:03:58,997 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1591
[INFO] 2021-07-12 19:03:58,997 [run_pretraining.py:  558]:	worker_index: 2, step: 1591, cost: 4.548604, mlm loss: 4.548604, speed: 1.087107 steps/s, speed: 8.696853 samples/s, speed: 4452.788595 tokens/s, learning rate: 1.590e-05, loss_scalings: 6871.948730, pp_loss: 6.851861
[INFO] 2021-07-12 19:03:58,997 [run_pretraining.py:  512]:	********exe.run_1591******* 
[INFO] 2021-07-12 19:03:59,908 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:59,908 [run_pretraining.py:  534]:	loss/total_loss, 7.387739181518555, 1592
[INFO] 2021-07-12 19:03:59,908 [run_pretraining.py:  535]:	loss/mlm_loss, 7.387739181518555, 1592
[INFO] 2021-07-12 19:03:59,909 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.591000000189524e-05, 1592
[INFO] 2021-07-12 19:03:59,909 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1592
[INFO] 2021-07-12 19:03:59,909 [run_pretraining.py:  558]:	worker_index: 2, step: 1592, cost: 7.387739, mlm loss: 7.387739, speed: 1.097273 steps/s, speed: 8.778184 samples/s, speed: 4494.430104 tokens/s, learning rate: 1.591e-05, loss_scalings: 6871.948730, pp_loss: 7.589581
[INFO] 2021-07-12 19:03:59,909 [run_pretraining.py:  512]:	********exe.run_1592******* 
[INFO] 2021-07-12 19:04:00,821 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:00,822 [run_pretraining.py:  534]:	loss/total_loss, 7.460658073425293, 1593
[INFO] 2021-07-12 19:04:00,822 [run_pretraining.py:  535]:	loss/mlm_loss, 7.460658073425293, 1593
[INFO] 2021-07-12 19:04:00,822 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5919998986646533e-05, 1593
[INFO] 2021-07-12 19:04:00,822 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1593
[INFO] 2021-07-12 19:04:00,822 [run_pretraining.py:  558]:	worker_index: 2, step: 1593, cost: 7.460658, mlm loss: 7.460658, speed: 1.095724 steps/s, speed: 8.765794 samples/s, speed: 4488.086283 tokens/s, learning rate: 1.592e-05, loss_scalings: 6871.948730, pp_loss: 7.572991
[INFO] 2021-07-12 19:04:00,822 [run_pretraining.py:  512]:	********exe.run_1593******* 
[INFO] 2021-07-12 19:04:01,732 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:01,733 [run_pretraining.py:  534]:	loss/total_loss, 7.6073222160339355, 1594
[INFO] 2021-07-12 19:04:01,733 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6073222160339355, 1594
[INFO] 2021-07-12 19:04:01,733 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5929999790387228e-05, 1594
[INFO] 2021-07-12 19:04:01,733 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1594
[INFO] 2021-07-12 19:04:01,733 [run_pretraining.py:  558]:	worker_index: 2, step: 1594, cost: 7.607322, mlm loss: 7.607322, speed: 1.098228 steps/s, speed: 8.785824 samples/s, speed: 4498.341828 tokens/s, learning rate: 1.593e-05, loss_scalings: 6871.948730, pp_loss: 7.451289
[INFO] 2021-07-12 19:04:01,733 [run_pretraining.py:  512]:	********exe.run_1594******* 
[INFO] 2021-07-12 19:04:02,640 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:02,641 [run_pretraining.py:  534]:	loss/total_loss, 6.899879455566406, 1595
[INFO] 2021-07-12 19:04:02,641 [run_pretraining.py:  535]:	loss/mlm_loss, 6.899879455566406, 1595
[INFO] 2021-07-12 19:04:02,641 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5940000594127923e-05, 1595
[INFO] 2021-07-12 19:04:02,641 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1595
[INFO] 2021-07-12 19:04:02,641 [run_pretraining.py:  558]:	worker_index: 2, step: 1595, cost: 6.899879, mlm loss: 6.899879, speed: 1.102057 steps/s, speed: 8.816460 samples/s, speed: 4514.027403 tokens/s, learning rate: 1.594e-05, loss_scalings: 6871.948730, pp_loss: 7.353522
[INFO] 2021-07-12 19:04:02,641 [run_pretraining.py:  512]:	********exe.run_1595******* 
[INFO] 2021-07-12 19:04:03,544 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:03,545 [run_pretraining.py:  534]:	loss/total_loss, 7.6922078132629395, 1596
[INFO] 2021-07-12 19:04:03,545 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6922078132629395, 1596
[INFO] 2021-07-12 19:04:03,545 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5949999578879215e-05, 1596
[INFO] 2021-07-12 19:04:03,545 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1596
[INFO] 2021-07-12 19:04:03,545 [run_pretraining.py:  558]:	worker_index: 2, step: 1596, cost: 7.692208, mlm loss: 7.692208, speed: 1.106545 steps/s, speed: 8.852356 samples/s, speed: 4532.406474 tokens/s, learning rate: 1.595e-05, loss_scalings: 6871.948730, pp_loss: 7.458453
[INFO] 2021-07-12 19:04:03,545 [run_pretraining.py:  512]:	********exe.run_1596******* 
[INFO] 2021-07-12 19:04:04,454 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:04,455 [run_pretraining.py:  534]:	loss/total_loss, 7.666425704956055, 1597
[INFO] 2021-07-12 19:04:04,455 [run_pretraining.py:  535]:	loss/mlm_loss, 7.666425704956055, 1597
[INFO] 2021-07-12 19:04:04,455 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.596000038261991e-05, 1597
[INFO] 2021-07-12 19:04:04,455 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1597
[INFO] 2021-07-12 19:04:04,455 [run_pretraining.py:  558]:	worker_index: 2, step: 1597, cost: 7.666426, mlm loss: 7.666426, speed: 1.099549 steps/s, speed: 8.796396 samples/s, speed: 4503.754604 tokens/s, learning rate: 1.596e-05, loss_scalings: 6871.948730, pp_loss: 7.362531
[INFO] 2021-07-12 19:04:04,456 [run_pretraining.py:  512]:	********exe.run_1597******* 
[INFO] 2021-07-12 19:04:05,371 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:05,371 [run_pretraining.py:  534]:	loss/total_loss, 7.346338272094727, 1598
[INFO] 2021-07-12 19:04:05,372 [run_pretraining.py:  535]:	loss/mlm_loss, 7.346338272094727, 1598
[INFO] 2021-07-12 19:04:05,372 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.59699993673712e-05, 1598
[INFO] 2021-07-12 19:04:05,372 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1598
[INFO] 2021-07-12 19:04:05,372 [run_pretraining.py:  558]:	worker_index: 2, step: 1598, cost: 7.346338, mlm loss: 7.346338, speed: 1.092056 steps/s, speed: 8.736450 samples/s, speed: 4473.062270 tokens/s, learning rate: 1.597e-05, loss_scalings: 6871.948730, pp_loss: 7.467322
[INFO] 2021-07-12 19:04:05,372 [run_pretraining.py:  512]:	********exe.run_1598******* 
[INFO] 2021-07-12 19:04:06,286 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:06,286 [run_pretraining.py:  534]:	loss/total_loss, 7.600675582885742, 1599
[INFO] 2021-07-12 19:04:06,286 [run_pretraining.py:  535]:	loss/mlm_loss, 7.600675582885742, 1599
[INFO] 2021-07-12 19:04:06,286 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5979998352122493e-05, 1599
[INFO] 2021-07-12 19:04:06,286 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1599
[INFO] 2021-07-12 19:04:06,287 [run_pretraining.py:  558]:	worker_index: 2, step: 1599, cost: 7.600676, mlm loss: 7.600676, speed: 1.093868 steps/s, speed: 8.750943 samples/s, speed: 4480.482807 tokens/s, learning rate: 1.598e-05, loss_scalings: 6871.948730, pp_loss: 7.462225
[INFO] 2021-07-12 19:04:06,287 [run_pretraining.py:  512]:	********exe.run_1599******* 
[INFO] 2021-07-12 19:04:07,196 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:07,196 [run_pretraining.py:  534]:	loss/total_loss, 7.736111640930176, 1600
[INFO] 2021-07-12 19:04:07,197 [run_pretraining.py:  535]:	loss/mlm_loss, 7.736111640930176, 1600
[INFO] 2021-07-12 19:04:07,197 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5989999155863188e-05, 1600
[INFO] 2021-07-12 19:04:07,197 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1600
[INFO] 2021-07-12 19:04:07,197 [run_pretraining.py:  558]:	worker_index: 2, step: 1600, cost: 7.736112, mlm loss: 7.736112, speed: 1.099315 steps/s, speed: 8.794524 samples/s, speed: 4502.796101 tokens/s, learning rate: 1.599e-05, loss_scalings: 6871.948730, pp_loss: 7.582406
[INFO] 2021-07-12 19:04:07,197 [run_pretraining.py:  512]:	********exe.run_1600******* 
[INFO] 2021-07-12 19:04:08,108 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:08,108 [run_pretraining.py:  534]:	loss/total_loss, 7.6518988609313965, 1601
[INFO] 2021-07-12 19:04:08,108 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6518988609313965, 1601
[INFO] 2021-07-12 19:04:08,108 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5999999959603883e-05, 1601
[INFO] 2021-07-12 19:04:08,108 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1601
[INFO] 2021-07-12 19:04:08,108 [run_pretraining.py:  558]:	worker_index: 2, step: 1601, cost: 7.651899, mlm loss: 7.651899, speed: 1.097657 steps/s, speed: 8.781255 samples/s, speed: 4496.002684 tokens/s, learning rate: 1.600e-05, loss_scalings: 6871.948730, pp_loss: 7.544496
[INFO] 2021-07-12 19:04:08,109 [run_pretraining.py:  512]:	********exe.run_1601******* 
[INFO] 2021-07-12 19:04:09,092 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:09,092 [run_pretraining.py:  534]:	loss/total_loss, 7.113161087036133, 1602
[INFO] 2021-07-12 19:04:09,092 [run_pretraining.py:  535]:	loss/mlm_loss, 7.113161087036133, 1602
[INFO] 2021-07-12 19:04:09,092 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6009998944355175e-05, 1602
[INFO] 2021-07-12 19:04:09,092 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1602
[INFO] 2021-07-12 19:04:09,093 [run_pretraining.py:  558]:	worker_index: 2, step: 1602, cost: 7.113161, mlm loss: 7.113161, speed: 1.016794 steps/s, speed: 8.134355 samples/s, speed: 4164.789511 tokens/s, learning rate: 1.601e-05, loss_scalings: 6871.948730, pp_loss: 7.555835
[INFO] 2021-07-12 19:04:09,093 [run_pretraining.py:  512]:	********exe.run_1602******* 
[INFO] 2021-07-12 19:04:10,159 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:10,160 [run_pretraining.py:  534]:	loss/total_loss, 7.818564414978027, 1603
[INFO] 2021-07-12 19:04:10,160 [run_pretraining.py:  535]:	loss/mlm_loss, 7.818564414978027, 1603
[INFO] 2021-07-12 19:04:10,160 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.601999974809587e-05, 1603
[INFO] 2021-07-12 19:04:10,160 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1603
[INFO] 2021-07-12 19:04:10,160 [run_pretraining.py:  558]:	worker_index: 2, step: 1603, cost: 7.818564, mlm loss: 7.818564, speed: 0.937198 steps/s, speed: 7.497582 samples/s, speed: 3838.762091 tokens/s, learning rate: 1.602e-05, loss_scalings: 6871.948730, pp_loss: 7.233904
[INFO] 2021-07-12 19:04:10,160 [run_pretraining.py:  512]:	********exe.run_1603******* 
[INFO] 2021-07-12 19:04:11,233 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:11,233 [run_pretraining.py:  534]:	loss/total_loss, 7.149071216583252, 1604
[INFO] 2021-07-12 19:04:11,234 [run_pretraining.py:  535]:	loss/mlm_loss, 7.149071216583252, 1604
[INFO] 2021-07-12 19:04:11,234 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6030000551836565e-05, 1604
[INFO] 2021-07-12 19:04:11,234 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1604
[INFO] 2021-07-12 19:04:11,234 [run_pretraining.py:  558]:	worker_index: 2, step: 1604, cost: 7.149071, mlm loss: 7.149071, speed: 0.931850 steps/s, speed: 7.454798 samples/s, speed: 3816.856411 tokens/s, learning rate: 1.603e-05, loss_scalings: 6871.948730, pp_loss: 7.066479
[INFO] 2021-07-12 19:04:11,234 [run_pretraining.py:  512]:	********exe.run_1604******* 
[INFO] 2021-07-12 19:04:12,295 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:12,295 [run_pretraining.py:  534]:	loss/total_loss, 7.389259338378906, 1605
[INFO] 2021-07-12 19:04:12,295 [run_pretraining.py:  535]:	loss/mlm_loss, 7.389259338378906, 1605
[INFO] 2021-07-12 19:04:12,295 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6039999536587857e-05, 1605
[INFO] 2021-07-12 19:04:12,295 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1605
[INFO] 2021-07-12 19:04:12,295 [run_pretraining.py:  558]:	worker_index: 2, step: 1605, cost: 7.389259, mlm loss: 7.389259, speed: 0.942578 steps/s, speed: 7.540622 samples/s, speed: 3860.798325 tokens/s, learning rate: 1.604e-05, loss_scalings: 6871.948730, pp_loss: 7.319672
[INFO] 2021-07-12 19:04:12,295 [run_pretraining.py:  512]:	********exe.run_1605******* 
[INFO] 2021-07-12 19:04:13,355 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:13,355 [run_pretraining.py:  534]:	loss/total_loss, 8.328962326049805, 1606
[INFO] 2021-07-12 19:04:13,355 [run_pretraining.py:  535]:	loss/mlm_loss, 8.328962326049805, 1606
[INFO] 2021-07-12 19:04:13,356 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6050000340328552e-05, 1606
[INFO] 2021-07-12 19:04:13,356 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1606
[INFO] 2021-07-12 19:04:13,356 [run_pretraining.py:  558]:	worker_index: 2, step: 1606, cost: 8.328962, mlm loss: 8.328962, speed: 0.943627 steps/s, speed: 7.549019 samples/s, speed: 3865.097874 tokens/s, learning rate: 1.605e-05, loss_scalings: 6871.948730, pp_loss: 7.830522
[INFO] 2021-07-12 19:04:13,356 [run_pretraining.py:  512]:	********exe.run_1606******* 
[INFO] 2021-07-12 19:04:14,419 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:14,419 [run_pretraining.py:  534]:	loss/total_loss, 7.354108810424805, 1607
[INFO] 2021-07-12 19:04:14,419 [run_pretraining.py:  535]:	loss/mlm_loss, 7.354108810424805, 1607
[INFO] 2021-07-12 19:04:14,419 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6060001144069247e-05, 1607
[INFO] 2021-07-12 19:04:14,419 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1607
[INFO] 2021-07-12 19:04:14,419 [run_pretraining.py:  558]:	worker_index: 2, step: 1607, cost: 7.354109, mlm loss: 7.354109, speed: 0.940754 steps/s, speed: 7.526032 samples/s, speed: 3853.328632 tokens/s, learning rate: 1.606e-05, loss_scalings: 6871.948730, pp_loss: 6.597166
[INFO] 2021-07-12 19:04:14,419 [run_pretraining.py:  512]:	********exe.run_1607******* 
[INFO] 2021-07-12 19:04:15,494 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:15,495 [run_pretraining.py:  534]:	loss/total_loss, 6.847592830657959, 1608
[INFO] 2021-07-12 19:04:15,495 [run_pretraining.py:  535]:	loss/mlm_loss, 6.847592830657959, 1608
[INFO] 2021-07-12 19:04:15,495 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6069998309831135e-05, 1608
[INFO] 2021-07-12 19:04:15,495 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1608
[INFO] 2021-07-12 19:04:15,495 [run_pretraining.py:  558]:	worker_index: 2, step: 1608, cost: 6.847593, mlm loss: 6.847593, speed: 0.930188 steps/s, speed: 7.441507 samples/s, speed: 3810.051557 tokens/s, learning rate: 1.607e-05, loss_scalings: 6871.948730, pp_loss: 7.689106
[INFO] 2021-07-12 19:04:15,495 [run_pretraining.py:  512]:	********exe.run_1608******* 
[INFO] 2021-07-12 19:04:16,565 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:16,566 [run_pretraining.py:  534]:	loss/total_loss, 8.83476448059082, 1609
[INFO] 2021-07-12 19:04:16,566 [run_pretraining.py:  535]:	loss/mlm_loss, 8.83476448059082, 1609
[INFO] 2021-07-12 19:04:16,566 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.607999911357183e-05, 1609
[INFO] 2021-07-12 19:04:16,566 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1609
[INFO] 2021-07-12 19:04:16,566 [run_pretraining.py:  558]:	worker_index: 2, step: 1609, cost: 8.834764, mlm loss: 8.834764, speed: 0.933962 steps/s, speed: 7.471698 samples/s, speed: 3825.509391 tokens/s, learning rate: 1.608e-05, loss_scalings: 6871.948730, pp_loss: 7.858194
[INFO] 2021-07-12 19:04:16,566 [run_pretraining.py:  512]:	********exe.run_1609******* 
[INFO] 2021-07-12 19:04:17,714 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:17,714 [run_pretraining.py:  534]:	loss/total_loss, 7.305769443511963, 1610
[INFO] 2021-07-12 19:04:17,714 [run_pretraining.py:  535]:	loss/mlm_loss, 7.305769443511963, 1610
[INFO] 2021-07-12 19:04:17,714 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6089999917312525e-05, 1610
[INFO] 2021-07-12 19:04:17,714 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1610
[INFO] 2021-07-12 19:04:17,714 [run_pretraining.py:  558]:	worker_index: 2, step: 1610, cost: 7.305769, mlm loss: 7.305769, speed: 0.871439 steps/s, speed: 6.971512 samples/s, speed: 3569.414247 tokens/s, learning rate: 1.609e-05, loss_scalings: 6871.948730, pp_loss: 7.361710
[INFO] 2021-07-12 19:04:17,714 [run_pretraining.py:  512]:	********exe.run_1610******* 
[INFO] 2021-07-12 19:04:18,829 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:18,829 [run_pretraining.py:  534]:	loss/total_loss, 7.479517459869385, 1611
[INFO] 2021-07-12 19:04:18,830 [run_pretraining.py:  535]:	loss/mlm_loss, 7.479517459869385, 1611
[INFO] 2021-07-12 19:04:18,830 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6099998902063817e-05, 1611
[INFO] 2021-07-12 19:04:18,830 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1611
[INFO] 2021-07-12 19:04:18,830 [run_pretraining.py:  558]:	worker_index: 2, step: 1611, cost: 7.479517, mlm loss: 7.479517, speed: 0.897012 steps/s, speed: 7.176094 samples/s, speed: 3674.160082 tokens/s, learning rate: 1.610e-05, loss_scalings: 6871.948730, pp_loss: 7.577991
[INFO] 2021-07-12 19:04:18,830 [run_pretraining.py:  512]:	********exe.run_1611******* 
[INFO] 2021-07-12 19:04:19,924 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:19,925 [run_pretraining.py:  534]:	loss/total_loss, 7.419191360473633, 1612
[INFO] 2021-07-12 19:04:19,925 [run_pretraining.py:  535]:	loss/mlm_loss, 7.419191360473633, 1612
[INFO] 2021-07-12 19:04:19,925 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6109999705804512e-05, 1612
[INFO] 2021-07-12 19:04:19,925 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1612
[INFO] 2021-07-12 19:04:19,925 [run_pretraining.py:  558]:	worker_index: 2, step: 1612, cost: 7.419191, mlm loss: 7.419191, speed: 0.913503 steps/s, speed: 7.308020 samples/s, speed: 3741.706424 tokens/s, learning rate: 1.611e-05, loss_scalings: 6871.948730, pp_loss: 7.438045
[INFO] 2021-07-12 19:04:19,925 [run_pretraining.py:  512]:	********exe.run_1612******* 
[INFO] 2021-07-12 19:04:21,020 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:21,020 [run_pretraining.py:  534]:	loss/total_loss, 7.900819778442383, 1613
[INFO] 2021-07-12 19:04:21,020 [run_pretraining.py:  535]:	loss/mlm_loss, 7.900819778442383, 1613
[INFO] 2021-07-12 19:04:21,020 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6120000509545207e-05, 1613
[INFO] 2021-07-12 19:04:21,021 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1613
[INFO] 2021-07-12 19:04:21,021 [run_pretraining.py:  558]:	worker_index: 2, step: 1613, cost: 7.900820, mlm loss: 7.900820, speed: 0.913319 steps/s, speed: 7.306553 samples/s, speed: 3740.955210 tokens/s, learning rate: 1.612e-05, loss_scalings: 6871.948730, pp_loss: 7.417750
[INFO] 2021-07-12 19:04:21,021 [run_pretraining.py:  512]:	********exe.run_1613******* 
[INFO] 2021-07-12 19:04:22,118 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:22,119 [run_pretraining.py:  534]:	loss/total_loss, 7.34218168258667, 1614
[INFO] 2021-07-12 19:04:22,119 [run_pretraining.py:  535]:	loss/mlm_loss, 7.34218168258667, 1614
[INFO] 2021-07-12 19:04:22,119 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.61299994942965e-05, 1614
[INFO] 2021-07-12 19:04:22,119 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1614
[INFO] 2021-07-12 19:04:22,119 [run_pretraining.py:  558]:	worker_index: 2, step: 1614, cost: 7.342182, mlm loss: 7.342182, speed: 0.911033 steps/s, speed: 7.288264 samples/s, speed: 3731.591241 tokens/s, learning rate: 1.613e-05, loss_scalings: 6871.948730, pp_loss: 7.240397
[INFO] 2021-07-12 19:04:22,119 [run_pretraining.py:  512]:	********exe.run_1614******* 
[INFO] 2021-07-12 19:04:23,208 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:23,209 [run_pretraining.py:  534]:	loss/total_loss, 7.0434346199035645, 1615
[INFO] 2021-07-12 19:04:23,209 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0434346199035645, 1615
[INFO] 2021-07-12 19:04:23,209 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6140000298037194e-05, 1615
[INFO] 2021-07-12 19:04:23,209 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1615
[INFO] 2021-07-12 19:04:23,209 [run_pretraining.py:  558]:	worker_index: 2, step: 1615, cost: 7.043435, mlm loss: 7.043435, speed: 0.917646 steps/s, speed: 7.341171 samples/s, speed: 3758.679802 tokens/s, learning rate: 1.614e-05, loss_scalings: 6871.948730, pp_loss: 7.429086
[INFO] 2021-07-12 19:04:23,209 [run_pretraining.py:  512]:	********exe.run_1615******* 
[INFO] 2021-07-12 19:04:24,311 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:24,311 [run_pretraining.py:  534]:	loss/total_loss, 7.010820388793945, 1616
[INFO] 2021-07-12 19:04:24,311 [run_pretraining.py:  535]:	loss/mlm_loss, 7.010820388793945, 1616
[INFO] 2021-07-12 19:04:24,311 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.615000110177789e-05, 1616
[INFO] 2021-07-12 19:04:24,311 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1616
[INFO] 2021-07-12 19:04:24,311 [run_pretraining.py:  558]:	worker_index: 2, step: 1616, cost: 7.010820, mlm loss: 7.010820, speed: 0.907804 steps/s, speed: 7.262435 samples/s, speed: 3718.366682 tokens/s, learning rate: 1.615e-05, loss_scalings: 6871.948730, pp_loss: 7.115058
[INFO] 2021-07-12 19:04:24,311 [run_pretraining.py:  512]:	********exe.run_1616******* 
[INFO] 2021-07-12 19:04:25,402 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:25,403 [run_pretraining.py:  534]:	loss/total_loss, 7.250156402587891, 1617
[INFO] 2021-07-12 19:04:25,403 [run_pretraining.py:  535]:	loss/mlm_loss, 7.250156402587891, 1617
[INFO] 2021-07-12 19:04:25,403 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6159998267539777e-05, 1617
[INFO] 2021-07-12 19:04:25,403 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1617
[INFO] 2021-07-12 19:04:25,403 [run_pretraining.py:  558]:	worker_index: 2, step: 1617, cost: 7.250156, mlm loss: 7.250156, speed: 0.916555 steps/s, speed: 7.332440 samples/s, speed: 3754.209135 tokens/s, learning rate: 1.616e-05, loss_scalings: 6871.948730, pp_loss: 7.179213
[INFO] 2021-07-12 19:04:25,403 [run_pretraining.py:  512]:	********exe.run_1617******* 
[INFO] 2021-07-12 19:04:26,453 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:26,453 [run_pretraining.py:  534]:	loss/total_loss, 7.625779151916504, 1618
[INFO] 2021-07-12 19:04:26,453 [run_pretraining.py:  535]:	loss/mlm_loss, 7.625779151916504, 1618
[INFO] 2021-07-12 19:04:26,453 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6169999071280472e-05, 1618
[INFO] 2021-07-12 19:04:26,453 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1618
[INFO] 2021-07-12 19:04:26,454 [run_pretraining.py:  558]:	worker_index: 2, step: 1618, cost: 7.625779, mlm loss: 7.625779, speed: 0.952466 steps/s, speed: 7.619724 samples/s, speed: 3901.298925 tokens/s, learning rate: 1.617e-05, loss_scalings: 6871.948730, pp_loss: 7.482136
[INFO] 2021-07-12 19:04:26,454 [run_pretraining.py:  512]:	********exe.run_1618******* 
[INFO] 2021-07-12 19:04:27,362 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:27,362 [run_pretraining.py:  534]:	loss/total_loss, 7.394497871398926, 1619
[INFO] 2021-07-12 19:04:27,362 [run_pretraining.py:  535]:	loss/mlm_loss, 7.394497871398926, 1619
[INFO] 2021-07-12 19:04:27,362 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6179999875021167e-05, 1619
[INFO] 2021-07-12 19:04:27,362 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1619
[INFO] 2021-07-12 19:04:27,362 [run_pretraining.py:  558]:	worker_index: 2, step: 1619, cost: 7.394498, mlm loss: 7.394498, speed: 1.100878 steps/s, speed: 8.807021 samples/s, speed: 4509.194623 tokens/s, learning rate: 1.618e-05, loss_scalings: 6871.948730, pp_loss: 6.980145
[INFO] 2021-07-12 19:04:27,363 [run_pretraining.py:  512]:	********exe.run_1619******* 
[INFO] 2021-07-12 19:04:28,291 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:28,292 [run_pretraining.py:  534]:	loss/total_loss, 7.832955360412598, 1620
[INFO] 2021-07-12 19:04:28,292 [run_pretraining.py:  535]:	loss/mlm_loss, 7.832955360412598, 1620
[INFO] 2021-07-12 19:04:28,292 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.618999885977246e-05, 1620
[INFO] 2021-07-12 19:04:28,292 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1620
[INFO] 2021-07-12 19:04:28,292 [run_pretraining.py:  558]:	worker_index: 2, step: 1620, cost: 7.832955, mlm loss: 7.832955, speed: 1.076170 steps/s, speed: 8.609363 samples/s, speed: 4407.993766 tokens/s, learning rate: 1.619e-05, loss_scalings: 6871.948730, pp_loss: 7.352600
[INFO] 2021-07-12 19:04:28,292 [run_pretraining.py:  512]:	********exe.run_1620******* 
[INFO] 2021-07-12 19:04:29,191 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:29,192 [run_pretraining.py:  534]:	loss/total_loss, 7.315254211425781, 1621
[INFO] 2021-07-12 19:04:29,192 [run_pretraining.py:  535]:	loss/mlm_loss, 7.315254211425781, 1621
[INFO] 2021-07-12 19:04:29,192 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6199999663513154e-05, 1621
[INFO] 2021-07-12 19:04:29,192 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1621
[INFO] 2021-07-12 19:04:29,192 [run_pretraining.py:  558]:	worker_index: 2, step: 1621, cost: 7.315254, mlm loss: 7.315254, speed: 1.112024 steps/s, speed: 8.896189 samples/s, speed: 4554.848746 tokens/s, learning rate: 1.620e-05, loss_scalings: 6871.948730, pp_loss: 7.318473
[INFO] 2021-07-12 19:04:29,192 [run_pretraining.py:  512]:	********exe.run_1621******* 
[INFO] 2021-07-12 19:04:30,108 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:30,109 [run_pretraining.py:  534]:	loss/total_loss, 3.350961923599243, 1622
[INFO] 2021-07-12 19:04:30,109 [run_pretraining.py:  535]:	loss/mlm_loss, 3.350961923599243, 1622
[INFO] 2021-07-12 19:04:30,109 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.621000046725385e-05, 1622
[INFO] 2021-07-12 19:04:30,109 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1622
[INFO] 2021-07-12 19:04:30,109 [run_pretraining.py:  558]:	worker_index: 2, step: 1622, cost: 3.350962, mlm loss: 3.350962, speed: 1.091419 steps/s, speed: 8.731355 samples/s, speed: 4470.453844 tokens/s, learning rate: 1.621e-05, loss_scalings: 6871.948730, pp_loss: 6.247441
[INFO] 2021-07-12 19:04:30,109 [run_pretraining.py:  512]:	********exe.run_1622******* 
[INFO] 2021-07-12 19:04:31,017 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:31,018 [run_pretraining.py:  534]:	loss/total_loss, 7.222353935241699, 1623
[INFO] 2021-07-12 19:04:31,018 [run_pretraining.py:  535]:	loss/mlm_loss, 7.222353935241699, 1623
[INFO] 2021-07-12 19:04:31,018 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.621999945200514e-05, 1623
[INFO] 2021-07-12 19:04:31,018 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1623
[INFO] 2021-07-12 19:04:31,018 [run_pretraining.py:  558]:	worker_index: 2, step: 1623, cost: 7.222354, mlm loss: 7.222354, speed: 1.100817 steps/s, speed: 8.806540 samples/s, speed: 4508.948463 tokens/s, learning rate: 1.622e-05, loss_scalings: 6871.948730, pp_loss: 7.428215
[INFO] 2021-07-12 19:04:31,018 [run_pretraining.py:  512]:	********exe.run_1623******* 
[INFO] 2021-07-12 19:04:31,927 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:31,928 [run_pretraining.py:  534]:	loss/total_loss, 6.204294204711914, 1624
[INFO] 2021-07-12 19:04:31,928 [run_pretraining.py:  535]:	loss/mlm_loss, 6.204294204711914, 1624
[INFO] 2021-07-12 19:04:31,928 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6230000255745836e-05, 1624
[INFO] 2021-07-12 19:04:31,928 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1624
[INFO] 2021-07-12 19:04:31,928 [run_pretraining.py:  558]:	worker_index: 2, step: 1624, cost: 6.204294, mlm loss: 6.204294, speed: 1.099734 steps/s, speed: 8.797869 samples/s, speed: 4504.509180 tokens/s, learning rate: 1.623e-05, loss_scalings: 6871.948730, pp_loss: 7.277438
[INFO] 2021-07-12 19:04:31,928 [run_pretraining.py:  512]:	********exe.run_1624******* 
[INFO] 2021-07-12 19:04:32,852 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:32,852 [run_pretraining.py:  534]:	loss/total_loss, 7.33900260925293, 1625
[INFO] 2021-07-12 19:04:32,852 [run_pretraining.py:  535]:	loss/mlm_loss, 7.33900260925293, 1625
[INFO] 2021-07-12 19:04:32,852 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.624000105948653e-05, 1625
[INFO] 2021-07-12 19:04:32,852 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1625
[INFO] 2021-07-12 19:04:32,853 [run_pretraining.py:  558]:	worker_index: 2, step: 1625, cost: 7.339003, mlm loss: 7.339003, speed: 1.082184 steps/s, speed: 8.657475 samples/s, speed: 4432.626959 tokens/s, learning rate: 1.624e-05, loss_scalings: 6871.948730, pp_loss: 7.326045
[INFO] 2021-07-12 19:04:32,853 [run_pretraining.py:  512]:	********exe.run_1625******* 
[INFO] 2021-07-12 19:04:33,764 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:33,764 [run_pretraining.py:  534]:	loss/total_loss, 7.160831451416016, 1626
[INFO] 2021-07-12 19:04:33,764 [run_pretraining.py:  535]:	loss/mlm_loss, 7.160831451416016, 1626
[INFO] 2021-07-12 19:04:33,764 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.624999822524842e-05, 1626
[INFO] 2021-07-12 19:04:33,764 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1626
[INFO] 2021-07-12 19:04:33,765 [run_pretraining.py:  558]:	worker_index: 2, step: 1626, cost: 7.160831, mlm loss: 7.160831, speed: 1.097221 steps/s, speed: 8.777770 samples/s, speed: 4494.218472 tokens/s, learning rate: 1.625e-05, loss_scalings: 6871.948730, pp_loss: 6.384552
[INFO] 2021-07-12 19:04:33,765 [run_pretraining.py:  512]:	********exe.run_1626******* 
[INFO] 2021-07-12 19:04:34,679 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:34,680 [run_pretraining.py:  534]:	loss/total_loss, 7.9204607009887695, 1627
[INFO] 2021-07-12 19:04:34,680 [run_pretraining.py:  535]:	loss/mlm_loss, 7.9204607009887695, 1627
[INFO] 2021-07-12 19:04:34,680 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6259999028989114e-05, 1627
[INFO] 2021-07-12 19:04:34,680 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1627
[INFO] 2021-07-12 19:04:34,680 [run_pretraining.py:  558]:	worker_index: 2, step: 1627, cost: 7.920461, mlm loss: 7.920461, speed: 1.093104 steps/s, speed: 8.744835 samples/s, speed: 4477.355740 tokens/s, learning rate: 1.626e-05, loss_scalings: 6871.948730, pp_loss: 7.858920
[INFO] 2021-07-12 19:04:34,680 [run_pretraining.py:  512]:	********exe.run_1627******* 
[INFO] 2021-07-12 19:04:35,607 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:35,607 [run_pretraining.py:  534]:	loss/total_loss, 7.417224884033203, 1628
[INFO] 2021-07-12 19:04:35,608 [run_pretraining.py:  535]:	loss/mlm_loss, 7.417224884033203, 1628
[INFO] 2021-07-12 19:04:35,608 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.626999983272981e-05, 1628
[INFO] 2021-07-12 19:04:35,608 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1628
[INFO] 2021-07-12 19:04:35,608 [run_pretraining.py:  558]:	worker_index: 2, step: 1628, cost: 7.417225, mlm loss: 7.417225, speed: 1.078533 steps/s, speed: 8.628267 samples/s, speed: 4417.672569 tokens/s, learning rate: 1.627e-05, loss_scalings: 6871.948730, pp_loss: 6.802128
[INFO] 2021-07-12 19:04:35,608 [run_pretraining.py:  512]:	********exe.run_1628******* 
[INFO] 2021-07-12 19:04:36,518 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:36,519 [run_pretraining.py:  534]:	loss/total_loss, 7.044902801513672, 1629
[INFO] 2021-07-12 19:04:36,519 [run_pretraining.py:  535]:	loss/mlm_loss, 7.044902801513672, 1629
[INFO] 2021-07-12 19:04:36,519 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.62799988174811e-05, 1629
[INFO] 2021-07-12 19:04:36,519 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1629
[INFO] 2021-07-12 19:04:36,519 [run_pretraining.py:  558]:	worker_index: 2, step: 1629, cost: 7.044903, mlm loss: 7.044903, speed: 1.097991 steps/s, speed: 8.783924 samples/s, speed: 4497.369146 tokens/s, learning rate: 1.628e-05, loss_scalings: 6871.948730, pp_loss: 6.234339
[INFO] 2021-07-12 19:04:36,519 [run_pretraining.py:  512]:	********exe.run_1629******* 
[INFO] 2021-07-12 19:04:37,435 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:37,436 [run_pretraining.py:  534]:	loss/total_loss, 7.462118625640869, 1630
[INFO] 2021-07-12 19:04:37,436 [run_pretraining.py:  535]:	loss/mlm_loss, 7.462118625640869, 1630
[INFO] 2021-07-12 19:04:37,436 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6289999621221796e-05, 1630
[INFO] 2021-07-12 19:04:37,436 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1630
[INFO] 2021-07-12 19:04:37,436 [run_pretraining.py:  558]:	worker_index: 2, step: 1630, cost: 7.462119, mlm loss: 7.462119, speed: 1.091276 steps/s, speed: 8.730210 samples/s, speed: 4469.867629 tokens/s, learning rate: 1.629e-05, loss_scalings: 6871.948730, pp_loss: 7.374055
[INFO] 2021-07-12 19:04:37,436 [run_pretraining.py:  512]:	********exe.run_1630******* 
[INFO] 2021-07-12 19:04:38,355 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:38,356 [run_pretraining.py:  534]:	loss/total_loss, 7.355530738830566, 1631
[INFO] 2021-07-12 19:04:38,356 [run_pretraining.py:  535]:	loss/mlm_loss, 7.355530738830566, 1631
[INFO] 2021-07-12 19:04:38,356 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.630000042496249e-05, 1631
[INFO] 2021-07-12 19:04:38,356 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1631
[INFO] 2021-07-12 19:04:38,356 [run_pretraining.py:  558]:	worker_index: 2, step: 1631, cost: 7.355531, mlm loss: 7.355531, speed: 1.087789 steps/s, speed: 8.702316 samples/s, speed: 4455.585587 tokens/s, learning rate: 1.630e-05, loss_scalings: 6871.948730, pp_loss: 7.044359
[INFO] 2021-07-12 19:04:38,356 [run_pretraining.py:  512]:	********exe.run_1631******* 
[INFO] 2021-07-12 19:04:39,278 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:39,278 [run_pretraining.py:  534]:	loss/total_loss, 6.870511054992676, 1632
[INFO] 2021-07-12 19:04:39,278 [run_pretraining.py:  535]:	loss/mlm_loss, 6.870511054992676, 1632
[INFO] 2021-07-12 19:04:39,278 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6309999409713782e-05, 1632
[INFO] 2021-07-12 19:04:39,278 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1632
[INFO] 2021-07-12 19:04:39,278 [run_pretraining.py:  558]:	worker_index: 2, step: 1632, cost: 6.870511, mlm loss: 6.870511, speed: 1.084703 steps/s, speed: 8.677623 samples/s, speed: 4442.942839 tokens/s, learning rate: 1.631e-05, loss_scalings: 6871.948730, pp_loss: 7.180052
[INFO] 2021-07-12 19:04:39,279 [run_pretraining.py:  512]:	********exe.run_1632******* 
[INFO] 2021-07-12 19:04:40,190 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:40,190 [run_pretraining.py:  534]:	loss/total_loss, 9.069995880126953, 1633
[INFO] 2021-07-12 19:04:40,190 [run_pretraining.py:  535]:	loss/mlm_loss, 9.069995880126953, 1633
[INFO] 2021-07-12 19:04:40,190 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6320000213454477e-05, 1633
[INFO] 2021-07-12 19:04:40,190 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1633
[INFO] 2021-07-12 19:04:40,190 [run_pretraining.py:  558]:	worker_index: 2, step: 1633, cost: 9.069996, mlm loss: 9.069996, speed: 1.097207 steps/s, speed: 8.777656 samples/s, speed: 4494.159689 tokens/s, learning rate: 1.632e-05, loss_scalings: 6871.948730, pp_loss: 7.550281
[INFO] 2021-07-12 19:04:40,191 [run_pretraining.py:  512]:	********exe.run_1633******* 
[INFO] 2021-07-12 19:04:41,107 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:41,108 [run_pretraining.py:  534]:	loss/total_loss, 7.46937370300293, 1634
[INFO] 2021-07-12 19:04:41,108 [run_pretraining.py:  535]:	loss/mlm_loss, 7.46937370300293, 1634
[INFO] 2021-07-12 19:04:41,108 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.632999919820577e-05, 1634
[INFO] 2021-07-12 19:04:41,108 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1634
[INFO] 2021-07-12 19:04:41,108 [run_pretraining.py:  558]:	worker_index: 2, step: 1634, cost: 7.469374, mlm loss: 7.469374, speed: 1.090773 steps/s, speed: 8.726180 samples/s, speed: 4467.804306 tokens/s, learning rate: 1.633e-05, loss_scalings: 6871.948730, pp_loss: 7.258682
[INFO] 2021-07-12 19:04:41,108 [run_pretraining.py:  512]:	********exe.run_1634******* 
[INFO] 2021-07-12 19:04:42,017 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:42,017 [run_pretraining.py:  534]:	loss/total_loss, 7.2224321365356445, 1635
[INFO] 2021-07-12 19:04:42,017 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2224321365356445, 1635
[INFO] 2021-07-12 19:04:42,018 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.633999818295706e-05, 1635
[INFO] 2021-07-12 19:04:42,018 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1635
[INFO] 2021-07-12 19:04:42,018 [run_pretraining.py:  558]:	worker_index: 2, step: 1635, cost: 7.222432, mlm loss: 7.222432, speed: 1.099830 steps/s, speed: 8.798638 samples/s, speed: 4504.902510 tokens/s, learning rate: 1.634e-05, loss_scalings: 6871.948730, pp_loss: 7.099409
[INFO] 2021-07-12 19:04:42,018 [run_pretraining.py:  512]:	********exe.run_1635******* 
[INFO] 2021-07-12 19:04:42,927 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:42,928 [run_pretraining.py:  534]:	loss/total_loss, 7.069375038146973, 1636
[INFO] 2021-07-12 19:04:42,928 [run_pretraining.py:  535]:	loss/mlm_loss, 7.069375038146973, 1636
[INFO] 2021-07-12 19:04:42,928 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6349998986697756e-05, 1636
[INFO] 2021-07-12 19:04:42,928 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1636
[INFO] 2021-07-12 19:04:42,928 [run_pretraining.py:  558]:	worker_index: 2, step: 1636, cost: 7.069375, mlm loss: 7.069375, speed: 1.099193 steps/s, speed: 8.793544 samples/s, speed: 4502.294585 tokens/s, learning rate: 1.635e-05, loss_scalings: 6871.948730, pp_loss: 7.198361
[INFO] 2021-07-12 19:04:42,928 [run_pretraining.py:  512]:	********exe.run_1636******* 
[INFO] 2021-07-12 19:04:43,849 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:43,849 [run_pretraining.py:  534]:	loss/total_loss, 7.3201494216918945, 1637
[INFO] 2021-07-12 19:04:43,849 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3201494216918945, 1637
[INFO] 2021-07-12 19:04:43,849 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.635999979043845e-05, 1637
[INFO] 2021-07-12 19:04:43,849 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1637
[INFO] 2021-07-12 19:04:43,849 [run_pretraining.py:  558]:	worker_index: 2, step: 1637, cost: 7.320149, mlm loss: 7.320149, speed: 1.086108 steps/s, speed: 8.688863 samples/s, speed: 4448.697603 tokens/s, learning rate: 1.636e-05, loss_scalings: 6871.948730, pp_loss: 7.117929
[INFO] 2021-07-12 19:04:43,849 [run_pretraining.py:  512]:	********exe.run_1637******* 
[INFO] 2021-07-12 19:04:44,767 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:44,768 [run_pretraining.py:  534]:	loss/total_loss, 7.57224702835083, 1638
[INFO] 2021-07-12 19:04:44,768 [run_pretraining.py:  535]:	loss/mlm_loss, 7.57224702835083, 1638
[INFO] 2021-07-12 19:04:44,768 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6369998775189742e-05, 1638
[INFO] 2021-07-12 19:04:44,768 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1638
[INFO] 2021-07-12 19:04:44,768 [run_pretraining.py:  558]:	worker_index: 2, step: 1638, cost: 7.572247, mlm loss: 7.572247, speed: 1.089353 steps/s, speed: 8.714826 samples/s, speed: 4461.990765 tokens/s, learning rate: 1.637e-05, loss_scalings: 6871.948730, pp_loss: 7.431953
[INFO] 2021-07-12 19:04:44,768 [run_pretraining.py:  512]:	********exe.run_1638******* 
[INFO] 2021-07-12 19:04:45,693 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:45,694 [run_pretraining.py:  534]:	loss/total_loss, 7.195247173309326, 1639
[INFO] 2021-07-12 19:04:45,694 [run_pretraining.py:  535]:	loss/mlm_loss, 7.195247173309326, 1639
[INFO] 2021-07-12 19:04:45,694 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6379999578930438e-05, 1639
[INFO] 2021-07-12 19:04:45,694 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1639
[INFO] 2021-07-12 19:04:45,694 [run_pretraining.py:  558]:	worker_index: 2, step: 1639, cost: 7.195247, mlm loss: 7.195247, speed: 1.080528 steps/s, speed: 8.644222 samples/s, speed: 4425.841646 tokens/s, learning rate: 1.638e-05, loss_scalings: 6871.948730, pp_loss: 7.337539
[INFO] 2021-07-12 19:04:45,694 [run_pretraining.py:  512]:	********exe.run_1639******* 
[INFO] 2021-07-12 19:04:46,609 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:46,609 [run_pretraining.py:  534]:	loss/total_loss, 6.86159086227417, 1640
[INFO] 2021-07-12 19:04:46,609 [run_pretraining.py:  535]:	loss/mlm_loss, 6.86159086227417, 1640
[INFO] 2021-07-12 19:04:46,609 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6390000382671133e-05, 1640
[INFO] 2021-07-12 19:04:46,609 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1640
[INFO] 2021-07-12 19:04:46,609 [run_pretraining.py:  558]:	worker_index: 2, step: 1640, cost: 6.861591, mlm loss: 6.861591, speed: 1.093142 steps/s, speed: 8.745139 samples/s, speed: 4477.510939 tokens/s, learning rate: 1.639e-05, loss_scalings: 6871.948730, pp_loss: 7.452565
[INFO] 2021-07-12 19:04:46,609 [run_pretraining.py:  512]:	********exe.run_1640******* 
[INFO] 2021-07-12 19:04:47,514 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:47,514 [run_pretraining.py:  534]:	loss/total_loss, 7.531902313232422, 1641
[INFO] 2021-07-12 19:04:47,514 [run_pretraining.py:  535]:	loss/mlm_loss, 7.531902313232422, 1641
[INFO] 2021-07-12 19:04:47,514 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6399999367422424e-05, 1641
[INFO] 2021-07-12 19:04:47,514 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1641
[INFO] 2021-07-12 19:04:47,515 [run_pretraining.py:  558]:	worker_index: 2, step: 1641, cost: 7.531902, mlm loss: 7.531902, speed: 1.105584 steps/s, speed: 8.844675 samples/s, speed: 4528.473504 tokens/s, learning rate: 1.640e-05, loss_scalings: 6871.948730, pp_loss: 7.467467
[INFO] 2021-07-12 19:04:47,515 [run_pretraining.py:  512]:	********exe.run_1641******* 
[INFO] 2021-07-12 19:04:48,422 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:48,423 [run_pretraining.py:  534]:	loss/total_loss, 7.643027305603027, 1642
[INFO] 2021-07-12 19:04:48,423 [run_pretraining.py:  535]:	loss/mlm_loss, 7.643027305603027, 1642
[INFO] 2021-07-12 19:04:48,423 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.641000017116312e-05, 1642
[INFO] 2021-07-12 19:04:48,423 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1642
[INFO] 2021-07-12 19:04:48,423 [run_pretraining.py:  558]:	worker_index: 2, step: 1642, cost: 7.643027, mlm loss: 7.643027, speed: 1.101477 steps/s, speed: 8.811815 samples/s, speed: 4511.649410 tokens/s, learning rate: 1.641e-05, loss_scalings: 6871.948730, pp_loss: 7.521629
[INFO] 2021-07-12 19:04:48,423 [run_pretraining.py:  512]:	********exe.run_1642******* 
[INFO] 2021-07-12 19:04:49,336 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:49,337 [run_pretraining.py:  534]:	loss/total_loss, 7.1283416748046875, 1643
[INFO] 2021-07-12 19:04:49,337 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1283416748046875, 1643
[INFO] 2021-07-12 19:04:49,337 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.641999915591441e-05, 1643
[INFO] 2021-07-12 19:04:49,337 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1643
[INFO] 2021-07-12 19:04:49,337 [run_pretraining.py:  558]:	worker_index: 2, step: 1643, cost: 7.128342, mlm loss: 7.128342, speed: 1.094607 steps/s, speed: 8.756858 samples/s, speed: 4483.511275 tokens/s, learning rate: 1.642e-05, loss_scalings: 6871.948730, pp_loss: 7.229520
[INFO] 2021-07-12 19:04:49,337 [run_pretraining.py:  512]:	********exe.run_1643******* 
[INFO] 2021-07-12 19:04:50,256 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:50,257 [run_pretraining.py:  534]:	loss/total_loss, 7.657480239868164, 1644
[INFO] 2021-07-12 19:04:50,257 [run_pretraining.py:  535]:	loss/mlm_loss, 7.657480239868164, 1644
[INFO] 2021-07-12 19:04:50,257 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6429999959655106e-05, 1644
[INFO] 2021-07-12 19:04:50,257 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1644
[INFO] 2021-07-12 19:04:50,257 [run_pretraining.py:  558]:	worker_index: 2, step: 1644, cost: 7.657480, mlm loss: 7.657480, speed: 1.087835 steps/s, speed: 8.702683 samples/s, speed: 4455.773950 tokens/s, learning rate: 1.643e-05, loss_scalings: 6871.948730, pp_loss: 7.329128
[INFO] 2021-07-12 19:04:50,257 [run_pretraining.py:  512]:	********exe.run_1644******* 
[INFO] 2021-07-12 19:04:51,318 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:51,319 [run_pretraining.py:  534]:	loss/total_loss, 7.5335893630981445, 1645
[INFO] 2021-07-12 19:04:51,319 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5335893630981445, 1645
[INFO] 2021-07-12 19:04:51,319 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6439998944406398e-05, 1645
[INFO] 2021-07-12 19:04:51,319 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1645
[INFO] 2021-07-12 19:04:51,319 [run_pretraining.py:  558]:	worker_index: 2, step: 1645, cost: 7.533589, mlm loss: 7.533589, speed: 0.941958 steps/s, speed: 7.535662 samples/s, speed: 3858.258709 tokens/s, learning rate: 1.644e-05, loss_scalings: 6871.948730, pp_loss: 7.334191
[INFO] 2021-07-12 19:04:51,319 [run_pretraining.py:  512]:	********exe.run_1645******* 
[INFO] 2021-07-12 19:04:52,227 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:52,227 [run_pretraining.py:  534]:	loss/total_loss, 7.198738098144531, 1646
[INFO] 2021-07-12 19:04:52,227 [run_pretraining.py:  535]:	loss/mlm_loss, 7.198738098144531, 1646
[INFO] 2021-07-12 19:04:52,228 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6449999748147093e-05, 1646
[INFO] 2021-07-12 19:04:52,228 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1646
[INFO] 2021-07-12 19:04:52,228 [run_pretraining.py:  558]:	worker_index: 2, step: 1646, cost: 7.198738, mlm loss: 7.198738, speed: 1.101514 steps/s, speed: 8.812114 samples/s, speed: 4511.802257 tokens/s, learning rate: 1.645e-05, loss_scalings: 6871.948730, pp_loss: 7.259250
[INFO] 2021-07-12 19:04:52,228 [run_pretraining.py:  512]:	********exe.run_1646******* 
[INFO] 2021-07-12 19:04:53,140 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:53,140 [run_pretraining.py:  534]:	loss/total_loss, 7.464053153991699, 1647
[INFO] 2021-07-12 19:04:53,140 [run_pretraining.py:  535]:	loss/mlm_loss, 7.464053153991699, 1647
[INFO] 2021-07-12 19:04:53,140 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6459998732898384e-05, 1647
[INFO] 2021-07-12 19:04:53,140 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1647
[INFO] 2021-07-12 19:04:53,141 [run_pretraining.py:  558]:	worker_index: 2, step: 1647, cost: 7.464053, mlm loss: 7.464053, speed: 1.096182 steps/s, speed: 8.769452 samples/s, speed: 4489.959502 tokens/s, learning rate: 1.646e-05, loss_scalings: 6871.948730, pp_loss: 7.244542
[INFO] 2021-07-12 19:04:53,141 [run_pretraining.py:  512]:	********exe.run_1647******* 
[INFO] 2021-07-12 19:04:54,050 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:54,051 [run_pretraining.py:  534]:	loss/total_loss, 8.303516387939453, 1648
[INFO] 2021-07-12 19:04:54,051 [run_pretraining.py:  535]:	loss/mlm_loss, 8.303516387939453, 1648
[INFO] 2021-07-12 19:04:54,051 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.646999953663908e-05, 1648
[INFO] 2021-07-12 19:04:54,051 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1648
[INFO] 2021-07-12 19:04:54,051 [run_pretraining.py:  558]:	worker_index: 2, step: 1648, cost: 8.303516, mlm loss: 8.303516, speed: 1.099067 steps/s, speed: 8.792533 samples/s, speed: 4501.776665 tokens/s, learning rate: 1.647e-05, loss_scalings: 6871.948730, pp_loss: 7.619128
[INFO] 2021-07-12 19:04:54,051 [run_pretraining.py:  512]:	********exe.run_1648******* 
[INFO] 2021-07-12 19:04:55,118 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:55,120 [run_pretraining.py:  534]:	loss/total_loss, 7.202295303344727, 1649
[INFO] 2021-07-12 19:04:55,122 [run_pretraining.py:  535]:	loss/mlm_loss, 7.202295303344727, 1649
[INFO] 2021-07-12 19:04:55,126 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6480000340379775e-05, 1649
[INFO] 2021-07-12 19:04:55,128 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1649
[INFO] 2021-07-12 19:04:55,130 [run_pretraining.py:  558]:	worker_index: 2, step: 1649, cost: 7.202295, mlm loss: 7.202295, speed: 0.935266 steps/s, speed: 7.482129 samples/s, speed: 3830.850215 tokens/s, learning rate: 1.648e-05, loss_scalings: 6871.948730, pp_loss: 7.360733
[INFO] 2021-07-12 19:04:55,134 [run_pretraining.py:  512]:	********exe.run_1649******* 
[INFO] 2021-07-12 19:04:56,185 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:56,186 [run_pretraining.py:  534]:	loss/total_loss, 6.953866958618164, 1650
[INFO] 2021-07-12 19:04:56,186 [run_pretraining.py:  535]:	loss/mlm_loss, 6.953866958618164, 1650
[INFO] 2021-07-12 19:04:56,186 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6489999325131066e-05, 1650
[INFO] 2021-07-12 19:04:56,186 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1650
[INFO] 2021-07-12 19:04:56,186 [run_pretraining.py:  558]:	worker_index: 2, step: 1650, cost: 6.953867, mlm loss: 6.953867, speed: 0.950708 steps/s, speed: 7.605660 samples/s, speed: 3894.098126 tokens/s, learning rate: 1.649e-05, loss_scalings: 6871.948730, pp_loss: 7.134171
[INFO] 2021-07-12 19:04:56,186 [run_pretraining.py:  512]:	********exe.run_1650******* 
[INFO] 2021-07-12 19:04:57,248 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:57,248 [run_pretraining.py:  534]:	loss/total_loss, 7.81450080871582, 1651
[INFO] 2021-07-12 19:04:57,248 [run_pretraining.py:  535]:	loss/mlm_loss, 7.81450080871582, 1651
[INFO] 2021-07-12 19:04:57,248 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.650000012887176e-05, 1651
[INFO] 2021-07-12 19:04:57,248 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1651
[INFO] 2021-07-12 19:04:57,248 [run_pretraining.py:  558]:	worker_index: 2, step: 1651, cost: 7.814501, mlm loss: 7.814501, speed: 0.941718 steps/s, speed: 7.533741 samples/s, speed: 3857.275495 tokens/s, learning rate: 1.650e-05, loss_scalings: 6871.948730, pp_loss: 7.425622
[INFO] 2021-07-12 19:04:57,248 [run_pretraining.py:  512]:	********exe.run_1651******* 
[INFO] 2021-07-12 19:04:58,316 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:58,316 [run_pretraining.py:  534]:	loss/total_loss, 8.159439086914062, 1652
[INFO] 2021-07-12 19:04:58,316 [run_pretraining.py:  535]:	loss/mlm_loss, 8.159439086914062, 1652
[INFO] 2021-07-12 19:04:58,316 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6509999113623053e-05, 1652
[INFO] 2021-07-12 19:04:58,317 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1652
[INFO] 2021-07-12 19:04:58,317 [run_pretraining.py:  558]:	worker_index: 2, step: 1652, cost: 8.159439, mlm loss: 8.159439, speed: 0.936658 steps/s, speed: 7.493262 samples/s, speed: 3836.550362 tokens/s, learning rate: 1.651e-05, loss_scalings: 6871.948730, pp_loss: 7.465596
[INFO] 2021-07-12 19:04:58,317 [run_pretraining.py:  512]:	********exe.run_1652******* 
[INFO] 2021-07-12 19:04:59,369 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:59,370 [run_pretraining.py:  534]:	loss/total_loss, 7.338229656219482, 1653
[INFO] 2021-07-12 19:04:59,370 [run_pretraining.py:  535]:	loss/mlm_loss, 7.338229656219482, 1653
[INFO] 2021-07-12 19:04:59,370 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6519999917363748e-05, 1653
[INFO] 2021-07-12 19:04:59,370 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1653
[INFO] 2021-07-12 19:04:59,370 [run_pretraining.py:  558]:	worker_index: 2, step: 1653, cost: 7.338230, mlm loss: 7.338230, speed: 0.949637 steps/s, speed: 7.597093 samples/s, speed: 3889.711834 tokens/s, learning rate: 1.652e-05, loss_scalings: 6871.948730, pp_loss: 7.786905
[INFO] 2021-07-12 19:04:59,370 [run_pretraining.py:  512]:	********exe.run_1653******* 
[INFO] 2021-07-12 19:05:00,371 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:00,372 [run_pretraining.py:  534]:	loss/total_loss, 6.8618364334106445, 1654
[INFO] 2021-07-12 19:05:00,372 [run_pretraining.py:  535]:	loss/mlm_loss, 6.8618364334106445, 1654
[INFO] 2021-07-12 19:05:00,372 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.652999890211504e-05, 1654
[INFO] 2021-07-12 19:05:00,372 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1654
[INFO] 2021-07-12 19:05:00,372 [run_pretraining.py:  558]:	worker_index: 2, step: 1654, cost: 6.861836, mlm loss: 6.861836, speed: 0.998828 steps/s, speed: 7.990623 samples/s, speed: 4091.198993 tokens/s, learning rate: 1.653e-05, loss_scalings: 6871.948730, pp_loss: 6.756694
[INFO] 2021-07-12 19:05:00,372 [run_pretraining.py:  512]:	********exe.run_1654******* 
[INFO] 2021-07-12 19:05:01,304 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:01,304 [run_pretraining.py:  534]:	loss/total_loss, 6.622300148010254, 1655
[INFO] 2021-07-12 19:05:01,304 [run_pretraining.py:  535]:	loss/mlm_loss, 6.622300148010254, 1655
[INFO] 2021-07-12 19:05:01,304 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6539999705855735e-05, 1655
[INFO] 2021-07-12 19:05:01,304 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1655
[INFO] 2021-07-12 19:05:01,304 [run_pretraining.py:  558]:	worker_index: 2, step: 1655, cost: 6.622300, mlm loss: 6.622300, speed: 1.073262 steps/s, speed: 8.586097 samples/s, speed: 4396.081568 tokens/s, learning rate: 1.654e-05, loss_scalings: 6871.948730, pp_loss: 6.887388
[INFO] 2021-07-12 19:05:01,304 [run_pretraining.py:  512]:	********exe.run_1655******* 
[INFO] 2021-07-12 19:05:02,211 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:02,211 [run_pretraining.py:  534]:	loss/total_loss, 6.760410785675049, 1656
[INFO] 2021-07-12 19:05:02,211 [run_pretraining.py:  535]:	loss/mlm_loss, 6.760410785675049, 1656
[INFO] 2021-07-12 19:05:02,211 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6549998690607026e-05, 1656
[INFO] 2021-07-12 19:05:02,212 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1656
[INFO] 2021-07-12 19:05:02,212 [run_pretraining.py:  558]:	worker_index: 2, step: 1656, cost: 6.760411, mlm loss: 6.760411, speed: 1.102946 steps/s, speed: 8.823568 samples/s, speed: 4517.666811 tokens/s, learning rate: 1.655e-05, loss_scalings: 6871.948730, pp_loss: 7.094322
[INFO] 2021-07-12 19:05:02,212 [run_pretraining.py:  512]:	********exe.run_1656******* 
[INFO] 2021-07-12 19:05:03,123 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:03,124 [run_pretraining.py:  534]:	loss/total_loss, 7.222085475921631, 1657
[INFO] 2021-07-12 19:05:03,124 [run_pretraining.py:  535]:	loss/mlm_loss, 7.222085475921631, 1657
[INFO] 2021-07-12 19:05:03,124 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.655999949434772e-05, 1657
[INFO] 2021-07-12 19:05:03,124 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1657
[INFO] 2021-07-12 19:05:03,124 [run_pretraining.py:  558]:	worker_index: 2, step: 1657, cost: 7.222085, mlm loss: 7.222085, speed: 1.096384 steps/s, speed: 8.771071 samples/s, speed: 4490.788112 tokens/s, learning rate: 1.656e-05, loss_scalings: 6871.948730, pp_loss: 6.801801
[INFO] 2021-07-12 19:05:03,124 [run_pretraining.py:  512]:	********exe.run_1657******* 
[INFO] 2021-07-12 19:05:04,052 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:04,053 [run_pretraining.py:  534]:	loss/total_loss, 6.878329753875732, 1658
[INFO] 2021-07-12 19:05:04,053 [run_pretraining.py:  535]:	loss/mlm_loss, 6.878329753875732, 1658
[INFO] 2021-07-12 19:05:04,053 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6570000298088416e-05, 1658
[INFO] 2021-07-12 19:05:04,053 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1658
[INFO] 2021-07-12 19:05:04,053 [run_pretraining.py:  558]:	worker_index: 2, step: 1658, cost: 6.878330, mlm loss: 6.878330, speed: 1.077158 steps/s, speed: 8.617265 samples/s, speed: 4412.039666 tokens/s, learning rate: 1.657e-05, loss_scalings: 6871.948730, pp_loss: 6.872435
[INFO] 2021-07-12 19:05:04,053 [run_pretraining.py:  512]:	********exe.run_1658******* 
[INFO] 2021-07-12 19:05:04,964 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:04,964 [run_pretraining.py:  534]:	loss/total_loss, 7.057576656341553, 1659
[INFO] 2021-07-12 19:05:04,964 [run_pretraining.py:  535]:	loss/mlm_loss, 7.057576656341553, 1659
[INFO] 2021-07-12 19:05:04,964 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6579999282839708e-05, 1659
[INFO] 2021-07-12 19:05:04,964 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1659
[INFO] 2021-07-12 19:05:04,964 [run_pretraining.py:  558]:	worker_index: 2, step: 1659, cost: 7.057577, mlm loss: 7.057577, speed: 1.098298 steps/s, speed: 8.786385 samples/s, speed: 4498.629239 tokens/s, learning rate: 1.658e-05, loss_scalings: 6871.948730, pp_loss: 7.330373
[INFO] 2021-07-12 19:05:04,964 [run_pretraining.py:  512]:	********exe.run_1659******* 
[INFO] 2021-07-12 19:05:05,863 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:05,863 [run_pretraining.py:  534]:	loss/total_loss, 7.264618873596191, 1660
[INFO] 2021-07-12 19:05:05,863 [run_pretraining.py:  535]:	loss/mlm_loss, 7.264618873596191, 1660
[INFO] 2021-07-12 19:05:05,864 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6590000086580403e-05, 1660
[INFO] 2021-07-12 19:05:05,864 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1660
[INFO] 2021-07-12 19:05:05,864 [run_pretraining.py:  558]:	worker_index: 2, step: 1660, cost: 7.264619, mlm loss: 7.264619, speed: 1.112782 steps/s, speed: 8.902255 samples/s, speed: 4557.954430 tokens/s, learning rate: 1.659e-05, loss_scalings: 6871.948730, pp_loss: 6.694888
[INFO] 2021-07-12 19:05:05,864 [run_pretraining.py:  512]:	********exe.run_1660******* 
[INFO] 2021-07-12 19:05:06,772 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:06,772 [run_pretraining.py:  534]:	loss/total_loss, 6.880086898803711, 1661
[INFO] 2021-07-12 19:05:06,773 [run_pretraining.py:  535]:	loss/mlm_loss, 6.880086898803711, 1661
[INFO] 2021-07-12 19:05:06,773 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6599999071331695e-05, 1661
[INFO] 2021-07-12 19:05:06,773 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1661
[INFO] 2021-07-12 19:05:06,773 [run_pretraining.py:  558]:	worker_index: 2, step: 1661, cost: 6.880087, mlm loss: 6.880087, speed: 1.100664 steps/s, speed: 8.805315 samples/s, speed: 4508.321350 tokens/s, learning rate: 1.660e-05, loss_scalings: 6871.948730, pp_loss: 7.392639
[INFO] 2021-07-12 19:05:06,773 [run_pretraining.py:  512]:	********exe.run_1661******* 
[INFO] 2021-07-12 19:05:07,800 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:07,801 [run_pretraining.py:  534]:	loss/total_loss, 6.629534721374512, 1662
[INFO] 2021-07-12 19:05:07,801 [run_pretraining.py:  535]:	loss/mlm_loss, 6.629534721374512, 1662
[INFO] 2021-07-12 19:05:07,801 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.660999987507239e-05, 1662
[INFO] 2021-07-12 19:05:07,801 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1662
[INFO] 2021-07-12 19:05:07,801 [run_pretraining.py:  558]:	worker_index: 2, step: 1662, cost: 6.629535, mlm loss: 6.629535, speed: 0.973070 steps/s, speed: 7.784561 samples/s, speed: 3985.695278 tokens/s, learning rate: 1.661e-05, loss_scalings: 6871.948730, pp_loss: 7.144958
[INFO] 2021-07-12 19:05:07,801 [run_pretraining.py:  512]:	********exe.run_1662******* 
[INFO] 2021-07-12 19:05:08,880 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:08,881 [run_pretraining.py:  534]:	loss/total_loss, 7.400430202484131, 1663
[INFO] 2021-07-12 19:05:08,881 [run_pretraining.py:  535]:	loss/mlm_loss, 7.400430202484131, 1663
[INFO] 2021-07-12 19:05:08,881 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.661999885982368e-05, 1663
[INFO] 2021-07-12 19:05:08,881 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1663
[INFO] 2021-07-12 19:05:08,881 [run_pretraining.py:  558]:	worker_index: 2, step: 1663, cost: 7.400430, mlm loss: 7.400430, speed: 0.926539 steps/s, speed: 7.412310 samples/s, speed: 3795.102907 tokens/s, learning rate: 1.662e-05, loss_scalings: 6871.948730, pp_loss: 6.666569
[INFO] 2021-07-12 19:05:08,881 [run_pretraining.py:  512]:	********exe.run_1663******* 
[INFO] 2021-07-12 19:05:09,943 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:09,943 [run_pretraining.py:  534]:	loss/total_loss, 6.563636779785156, 1664
[INFO] 2021-07-12 19:05:09,944 [run_pretraining.py:  535]:	loss/mlm_loss, 6.563636779785156, 1664
[INFO] 2021-07-12 19:05:09,944 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6629999663564377e-05, 1664
[INFO] 2021-07-12 19:05:09,944 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1664
[INFO] 2021-07-12 19:05:09,944 [run_pretraining.py:  558]:	worker_index: 2, step: 1664, cost: 6.563637, mlm loss: 6.563637, speed: 0.941494 steps/s, speed: 7.531954 samples/s, speed: 3856.360301 tokens/s, learning rate: 1.663e-05, loss_scalings: 6871.948730, pp_loss: 7.400432
[INFO] 2021-07-12 19:05:09,944 [run_pretraining.py:  512]:	********exe.run_1664******* 
[INFO] 2021-07-12 19:05:11,004 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:11,004 [run_pretraining.py:  534]:	loss/total_loss, 7.801630973815918, 1665
[INFO] 2021-07-12 19:05:11,004 [run_pretraining.py:  535]:	loss/mlm_loss, 7.801630973815918, 1665
[INFO] 2021-07-12 19:05:11,004 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.664000046730507e-05, 1665
[INFO] 2021-07-12 19:05:11,005 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1665
[INFO] 2021-07-12 19:05:11,005 [run_pretraining.py:  558]:	worker_index: 2, step: 1665, cost: 7.801631, mlm loss: 7.801631, speed: 0.943140 steps/s, speed: 7.545122 samples/s, speed: 3863.102388 tokens/s, learning rate: 1.664e-05, loss_scalings: 6871.948730, pp_loss: 7.497543
[INFO] 2021-07-12 19:05:11,005 [run_pretraining.py:  512]:	********exe.run_1665******* 
[INFO] 2021-07-12 19:05:12,060 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:12,060 [run_pretraining.py:  534]:	loss/total_loss, 7.653234958648682, 1666
[INFO] 2021-07-12 19:05:12,060 [run_pretraining.py:  535]:	loss/mlm_loss, 7.653234958648682, 1666
[INFO] 2021-07-12 19:05:12,060 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6649999452056363e-05, 1666
[INFO] 2021-07-12 19:05:12,060 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1666
[INFO] 2021-07-12 19:05:12,061 [run_pretraining.py:  558]:	worker_index: 2, step: 1666, cost: 7.653235, mlm loss: 7.653235, speed: 0.947603 steps/s, speed: 7.580820 samples/s, speed: 3881.380052 tokens/s, learning rate: 1.665e-05, loss_scalings: 6871.948730, pp_loss: 7.475803
[INFO] 2021-07-12 19:05:12,061 [run_pretraining.py:  512]:	********exe.run_1666******* 
[INFO] 2021-07-12 19:05:13,123 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:13,124 [run_pretraining.py:  534]:	loss/total_loss, 7.568417072296143, 1667
[INFO] 2021-07-12 19:05:13,124 [run_pretraining.py:  535]:	loss/mlm_loss, 7.568417072296143, 1667
[INFO] 2021-07-12 19:05:13,124 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.666000025579706e-05, 1667
[INFO] 2021-07-12 19:05:13,124 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1667
[INFO] 2021-07-12 19:05:13,124 [run_pretraining.py:  558]:	worker_index: 2, step: 1667, cost: 7.568417, mlm loss: 7.568417, speed: 0.940942 steps/s, speed: 7.527535 samples/s, speed: 3854.097990 tokens/s, learning rate: 1.666e-05, loss_scalings: 6871.948730, pp_loss: 7.222471
[INFO] 2021-07-12 19:05:13,124 [run_pretraining.py:  512]:	********exe.run_1667******* 
[INFO] 2021-07-12 19:05:14,182 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:14,183 [run_pretraining.py:  534]:	loss/total_loss, 6.977377414703369, 1668
[INFO] 2021-07-12 19:05:14,183 [run_pretraining.py:  535]:	loss/mlm_loss, 6.977377414703369, 1668
[INFO] 2021-07-12 19:05:14,183 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.666999924054835e-05, 1668
[INFO] 2021-07-12 19:05:14,183 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1668
[INFO] 2021-07-12 19:05:14,183 [run_pretraining.py:  558]:	worker_index: 2, step: 1668, cost: 6.977377, mlm loss: 6.977377, speed: 0.944432 steps/s, speed: 7.555458 samples/s, speed: 3868.394589 tokens/s, learning rate: 1.667e-05, loss_scalings: 6871.948730, pp_loss: 6.787807
[INFO] 2021-07-12 19:05:14,183 [run_pretraining.py:  512]:	********exe.run_1668******* 
[INFO] 2021-07-12 19:05:15,254 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:15,254 [run_pretraining.py:  534]:	loss/total_loss, 6.538971900939941, 1669
[INFO] 2021-07-12 19:05:15,254 [run_pretraining.py:  535]:	loss/mlm_loss, 6.538971900939941, 1669
[INFO] 2021-07-12 19:05:15,254 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6680000044289045e-05, 1669
[INFO] 2021-07-12 19:05:15,254 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1669
[INFO] 2021-07-12 19:05:15,255 [run_pretraining.py:  558]:	worker_index: 2, step: 1669, cost: 6.538972, mlm loss: 6.538972, speed: 0.934105 steps/s, speed: 7.472838 samples/s, speed: 3826.092991 tokens/s, learning rate: 1.668e-05, loss_scalings: 6871.948730, pp_loss: 7.170260
[INFO] 2021-07-12 19:05:15,255 [run_pretraining.py:  512]:	********exe.run_1669******* 
[INFO] 2021-07-12 19:05:40,460 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:40,460 [run_pretraining.py:  534]:	loss/total_loss, 7.348730564117432, 1670
[INFO] 2021-07-12 19:05:40,460 [run_pretraining.py:  535]:	loss/mlm_loss, 7.348730564117432, 1670
[INFO] 2021-07-12 19:05:40,460 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6689999029040337e-05, 1670
[INFO] 2021-07-12 19:05:40,460 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1670
[INFO] 2021-07-12 19:05:40,461 [run_pretraining.py:  558]:	worker_index: 2, step: 1670, cost: 7.348731, mlm loss: 7.348731, speed: 0.039674 steps/s, speed: 0.317392 samples/s, speed: 162.504837 tokens/s, learning rate: 1.669e-05, loss_scalings: 6871.948730, pp_loss: 7.362323
[INFO] 2021-07-12 19:05:40,461 [run_pretraining.py:  512]:	********exe.run_1670******* 
[INFO] 2021-07-12 19:05:41,375 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:41,375 [run_pretraining.py:  534]:	loss/total_loss, 8.049175262451172, 1671
[INFO] 2021-07-12 19:05:41,375 [run_pretraining.py:  535]:	loss/mlm_loss, 8.049175262451172, 1671
[INFO] 2021-07-12 19:05:41,376 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6699999832781032e-05, 1671
[INFO] 2021-07-12 19:05:41,376 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1671
[INFO] 2021-07-12 19:05:41,376 [run_pretraining.py:  558]:	worker_index: 2, step: 1671, cost: 8.049175, mlm loss: 8.049175, speed: 1.093357 steps/s, speed: 8.746855 samples/s, speed: 4478.389828 tokens/s, learning rate: 1.670e-05, loss_scalings: 6871.948730, pp_loss: 7.411161
[INFO] 2021-07-12 19:05:41,376 [run_pretraining.py:  512]:	********exe.run_1671******* 
[INFO] 2021-07-12 19:05:42,278 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:42,278 [run_pretraining.py:  534]:	loss/total_loss, 6.993025302886963, 1672
[INFO] 2021-07-12 19:05:42,279 [run_pretraining.py:  535]:	loss/mlm_loss, 6.993025302886963, 1672
[INFO] 2021-07-12 19:05:42,279 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6709998817532323e-05, 1672
[INFO] 2021-07-12 19:05:42,279 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1672
[INFO] 2021-07-12 19:05:42,279 [run_pretraining.py:  558]:	worker_index: 2, step: 1672, cost: 6.993025, mlm loss: 6.993025, speed: 1.108037 steps/s, speed: 8.864295 samples/s, speed: 4538.518974 tokens/s, learning rate: 1.671e-05, loss_scalings: 6871.948730, pp_loss: 7.260896
[INFO] 2021-07-12 19:05:42,279 [run_pretraining.py:  512]:	********exe.run_1672******* 
[INFO] 2021-07-12 19:05:43,186 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:43,187 [run_pretraining.py:  534]:	loss/total_loss, 7.547133922576904, 1673
[INFO] 2021-07-12 19:05:43,187 [run_pretraining.py:  535]:	loss/mlm_loss, 7.547133922576904, 1673
[INFO] 2021-07-12 19:05:43,187 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.671999962127302e-05, 1673
[INFO] 2021-07-12 19:05:43,187 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1673
[INFO] 2021-07-12 19:05:43,187 [run_pretraining.py:  558]:	worker_index: 2, step: 1673, cost: 7.547134, mlm loss: 7.547134, speed: 1.101994 steps/s, speed: 8.815955 samples/s, speed: 4513.768856 tokens/s, learning rate: 1.672e-05, loss_scalings: 6871.948730, pp_loss: 7.308438
[INFO] 2021-07-12 19:05:43,187 [run_pretraining.py:  512]:	********exe.run_1673******* 
[INFO] 2021-07-12 19:05:44,172 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:44,173 [run_pretraining.py:  534]:	loss/total_loss, 7.153614044189453, 1674
[INFO] 2021-07-12 19:05:44,173 [run_pretraining.py:  535]:	loss/mlm_loss, 7.153614044189453, 1674
[INFO] 2021-07-12 19:05:44,173 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6730000425013714e-05, 1674
[INFO] 2021-07-12 19:05:44,173 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1674
[INFO] 2021-07-12 19:05:44,173 [run_pretraining.py:  558]:	worker_index: 2, step: 1674, cost: 7.153614, mlm loss: 7.153614, speed: 1.014735 steps/s, speed: 8.117883 samples/s, speed: 4156.355943 tokens/s, learning rate: 1.673e-05, loss_scalings: 6871.948730, pp_loss: 7.414977
[INFO] 2021-07-12 19:05:44,173 [run_pretraining.py:  512]:	********exe.run_1674******* 
[INFO] 2021-07-12 19:05:45,082 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:45,083 [run_pretraining.py:  534]:	loss/total_loss, 7.961763381958008, 1675
[INFO] 2021-07-12 19:05:45,083 [run_pretraining.py:  535]:	loss/mlm_loss, 7.961763381958008, 1675
[INFO] 2021-07-12 19:05:45,083 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6739999409765005e-05, 1675
[INFO] 2021-07-12 19:05:45,083 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1675
[INFO] 2021-07-12 19:05:45,083 [run_pretraining.py:  558]:	worker_index: 2, step: 1675, cost: 7.961763, mlm loss: 7.961763, speed: 1.099232 steps/s, speed: 8.793855 samples/s, speed: 4502.453878 tokens/s, learning rate: 1.674e-05, loss_scalings: 6871.948730, pp_loss: 6.531648
[INFO] 2021-07-12 19:05:45,083 [run_pretraining.py:  512]:	********exe.run_1675******* 
[INFO] 2021-07-12 19:05:45,993 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:45,993 [run_pretraining.py:  534]:	loss/total_loss, 7.268376350402832, 1676
[INFO] 2021-07-12 19:05:45,993 [run_pretraining.py:  535]:	loss/mlm_loss, 7.268376350402832, 1676
[INFO] 2021-07-12 19:05:45,993 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.67500002135057e-05, 1676
[INFO] 2021-07-12 19:05:45,993 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1676
[INFO] 2021-07-12 19:05:45,993 [run_pretraining.py:  558]:	worker_index: 2, step: 1676, cost: 7.268376, mlm loss: 7.268376, speed: 1.099450 steps/s, speed: 8.795598 samples/s, speed: 4503.346128 tokens/s, learning rate: 1.675e-05, loss_scalings: 6871.948730, pp_loss: 7.404816
[INFO] 2021-07-12 19:05:45,993 [run_pretraining.py:  512]:	********exe.run_1676******* 
[INFO] 2021-07-12 19:05:46,903 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:46,904 [run_pretraining.py:  534]:	loss/total_loss, 7.143250465393066, 1677
[INFO] 2021-07-12 19:05:46,904 [run_pretraining.py:  535]:	loss/mlm_loss, 7.143250465393066, 1677
[INFO] 2021-07-12 19:05:46,904 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6760001017246395e-05, 1677
[INFO] 2021-07-12 19:05:46,904 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1677
[INFO] 2021-07-12 19:05:46,904 [run_pretraining.py:  558]:	worker_index: 2, step: 1677, cost: 7.143250, mlm loss: 7.143250, speed: 1.099050 steps/s, speed: 8.792401 samples/s, speed: 4501.709427 tokens/s, learning rate: 1.676e-05, loss_scalings: 6871.948730, pp_loss: 7.464157
[INFO] 2021-07-12 19:05:46,904 [run_pretraining.py:  512]:	********exe.run_1677******* 
[INFO] 2021-07-12 19:05:47,807 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:47,807 [run_pretraining.py:  534]:	loss/total_loss, 4.583738803863525, 1678
[INFO] 2021-07-12 19:05:47,808 [run_pretraining.py:  535]:	loss/mlm_loss, 4.583738803863525, 1678
[INFO] 2021-07-12 19:05:47,808 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6769998183008283e-05, 1678
[INFO] 2021-07-12 19:05:47,808 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1678
[INFO] 2021-07-12 19:05:47,808 [run_pretraining.py:  558]:	worker_index: 2, step: 1678, cost: 4.583739, mlm loss: 4.583739, speed: 1.107114 steps/s, speed: 8.856908 samples/s, speed: 4534.736979 tokens/s, learning rate: 1.677e-05, loss_scalings: 6871.948730, pp_loss: 6.765079
[INFO] 2021-07-12 19:05:47,808 [run_pretraining.py:  512]:	********exe.run_1678******* 
[INFO] 2021-07-12 19:05:48,724 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:48,724 [run_pretraining.py:  534]:	loss/total_loss, 7.664846897125244, 1679
[INFO] 2021-07-12 19:05:48,724 [run_pretraining.py:  535]:	loss/mlm_loss, 7.664846897125244, 1679
[INFO] 2021-07-12 19:05:48,725 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.677999898674898e-05, 1679
[INFO] 2021-07-12 19:05:48,725 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1679
[INFO] 2021-07-12 19:05:48,725 [run_pretraining.py:  558]:	worker_index: 2, step: 1679, cost: 7.664847, mlm loss: 7.664847, speed: 1.091306 steps/s, speed: 8.730446 samples/s, speed: 4469.988581 tokens/s, learning rate: 1.678e-05, loss_scalings: 6871.948730, pp_loss: 7.680014
[INFO] 2021-07-12 19:05:48,725 [run_pretraining.py:  512]:	********exe.run_1679******* 
[INFO] 2021-07-12 19:05:49,627 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:49,628 [run_pretraining.py:  534]:	loss/total_loss, 7.045240879058838, 1680
[INFO] 2021-07-12 19:05:49,628 [run_pretraining.py:  535]:	loss/mlm_loss, 7.045240879058838, 1680
[INFO] 2021-07-12 19:05:49,628 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6789999790489674e-05, 1680
[INFO] 2021-07-12 19:05:49,628 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1680
[INFO] 2021-07-12 19:05:49,628 [run_pretraining.py:  558]:	worker_index: 2, step: 1680, cost: 7.045241, mlm loss: 7.045241, speed: 1.107799 steps/s, speed: 8.862391 samples/s, speed: 4537.544421 tokens/s, learning rate: 1.679e-05, loss_scalings: 6871.948730, pp_loss: 7.323950
[INFO] 2021-07-12 19:05:49,628 [run_pretraining.py:  512]:	********exe.run_1680******* 
[INFO] 2021-07-12 19:05:50,549 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:50,549 [run_pretraining.py:  534]:	loss/total_loss, 7.292890548706055, 1681
[INFO] 2021-07-12 19:05:50,549 [run_pretraining.py:  535]:	loss/mlm_loss, 7.292890548706055, 1681
[INFO] 2021-07-12 19:05:50,549 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6799998775240965e-05, 1681
[INFO] 2021-07-12 19:05:50,549 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1681
[INFO] 2021-07-12 19:05:50,549 [run_pretraining.py:  558]:	worker_index: 2, step: 1681, cost: 7.292891, mlm loss: 7.292891, speed: 1.085978 steps/s, speed: 8.687823 samples/s, speed: 4448.165450 tokens/s, learning rate: 1.680e-05, loss_scalings: 6871.948730, pp_loss: 6.589672
[INFO] 2021-07-12 19:05:50,550 [run_pretraining.py:  512]:	********exe.run_1681******* 
[INFO] 2021-07-12 19:05:51,461 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:51,462 [run_pretraining.py:  534]:	loss/total_loss, 7.4126458168029785, 1682
[INFO] 2021-07-12 19:05:51,462 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4126458168029785, 1682
[INFO] 2021-07-12 19:05:51,462 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.680999957898166e-05, 1682
[INFO] 2021-07-12 19:05:51,462 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1682
[INFO] 2021-07-12 19:05:51,462 [run_pretraining.py:  558]:	worker_index: 2, step: 1682, cost: 7.412646, mlm loss: 7.412646, speed: 1.096243 steps/s, speed: 8.769940 samples/s, speed: 4490.209461 tokens/s, learning rate: 1.681e-05, loss_scalings: 6871.948730, pp_loss: 7.219952
[INFO] 2021-07-12 19:05:51,462 [run_pretraining.py:  512]:	********exe.run_1682******* 
[INFO] 2021-07-12 19:05:52,377 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:52,377 [run_pretraining.py:  534]:	loss/total_loss, 7.778357982635498, 1683
[INFO] 2021-07-12 19:05:52,378 [run_pretraining.py:  535]:	loss/mlm_loss, 7.778357982635498, 1683
[INFO] 2021-07-12 19:05:52,378 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6820000382722355e-05, 1683
[INFO] 2021-07-12 19:05:52,378 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1683
[INFO] 2021-07-12 19:05:52,378 [run_pretraining.py:  558]:	worker_index: 2, step: 1683, cost: 7.778358, mlm loss: 7.778358, speed: 1.092965 steps/s, speed: 8.743723 samples/s, speed: 4476.786379 tokens/s, learning rate: 1.682e-05, loss_scalings: 6871.948730, pp_loss: 7.401134
[INFO] 2021-07-12 19:05:52,378 [run_pretraining.py:  512]:	********exe.run_1683******* 
[INFO] 2021-07-12 19:05:53,301 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:53,301 [run_pretraining.py:  534]:	loss/total_loss, 7.65004825592041, 1684
[INFO] 2021-07-12 19:05:53,301 [run_pretraining.py:  535]:	loss/mlm_loss, 7.65004825592041, 1684
[INFO] 2021-07-12 19:05:53,301 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6829999367473647e-05, 1684
[INFO] 2021-07-12 19:05:53,301 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1684
[INFO] 2021-07-12 19:05:53,301 [run_pretraining.py:  558]:	worker_index: 2, step: 1684, cost: 7.650048, mlm loss: 7.650048, speed: 1.083445 steps/s, speed: 8.667560 samples/s, speed: 4437.790941 tokens/s, learning rate: 1.683e-05, loss_scalings: 6871.948730, pp_loss: 7.005915
[INFO] 2021-07-12 19:05:53,301 [run_pretraining.py:  512]:	********exe.run_1684******* 
[INFO] 2021-07-12 19:05:54,218 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:54,221 [run_pretraining.py:  534]:	loss/total_loss, 8.134125709533691, 1685
[INFO] 2021-07-12 19:05:54,221 [run_pretraining.py:  535]:	loss/mlm_loss, 8.134125709533691, 1685
[INFO] 2021-07-12 19:05:54,221 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6840000171214342e-05, 1685
[INFO] 2021-07-12 19:05:54,222 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1685
[INFO] 2021-07-12 19:05:54,222 [run_pretraining.py:  558]:	worker_index: 2, step: 1685, cost: 8.134126, mlm loss: 8.134126, speed: 1.088081 steps/s, speed: 8.704650 samples/s, speed: 4456.780749 tokens/s, learning rate: 1.684e-05, loss_scalings: 6871.948730, pp_loss: 7.438141
[INFO] 2021-07-12 19:05:54,222 [run_pretraining.py:  512]:	********exe.run_1685******* 
[INFO] 2021-07-12 19:05:55,123 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:55,124 [run_pretraining.py:  534]:	loss/total_loss, 7.25552225112915, 1686
[INFO] 2021-07-12 19:05:55,124 [run_pretraining.py:  535]:	loss/mlm_loss, 7.25552225112915, 1686
[INFO] 2021-07-12 19:05:55,124 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6850000974955037e-05, 1686
[INFO] 2021-07-12 19:05:55,124 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1686
[INFO] 2021-07-12 19:05:55,124 [run_pretraining.py:  558]:	worker_index: 2, step: 1686, cost: 7.255522, mlm loss: 7.255522, speed: 1.109439 steps/s, speed: 8.875512 samples/s, speed: 4544.262107 tokens/s, learning rate: 1.685e-05, loss_scalings: 6871.948730, pp_loss: 6.478183
[INFO] 2021-07-12 19:05:55,124 [run_pretraining.py:  512]:	********exe.run_1686******* 
[INFO] 2021-07-12 19:05:56,034 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:56,034 [run_pretraining.py:  534]:	loss/total_loss, 7.164576053619385, 1687
[INFO] 2021-07-12 19:05:56,034 [run_pretraining.py:  535]:	loss/mlm_loss, 7.164576053619385, 1687
[INFO] 2021-07-12 19:05:56,034 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6859998140716925e-05, 1687
[INFO] 2021-07-12 19:05:56,035 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1687
[INFO] 2021-07-12 19:05:56,035 [run_pretraining.py:  558]:	worker_index: 2, step: 1687, cost: 7.164576, mlm loss: 7.164576, speed: 1.098907 steps/s, speed: 8.791254 samples/s, speed: 4501.122062 tokens/s, learning rate: 1.686e-05, loss_scalings: 6871.948730, pp_loss: 7.322692
[INFO] 2021-07-12 19:05:56,035 [run_pretraining.py:  512]:	********exe.run_1687******* 
[INFO] 2021-07-12 19:05:56,945 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:56,946 [run_pretraining.py:  534]:	loss/total_loss, 7.8204145431518555, 1688
[INFO] 2021-07-12 19:05:56,946 [run_pretraining.py:  535]:	loss/mlm_loss, 7.8204145431518555, 1688
[INFO] 2021-07-12 19:05:56,946 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.686999894445762e-05, 1688
[INFO] 2021-07-12 19:05:56,946 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1688
[INFO] 2021-07-12 19:05:56,946 [run_pretraining.py:  558]:	worker_index: 2, step: 1688, cost: 7.820415, mlm loss: 7.820415, speed: 1.097916 steps/s, speed: 8.783326 samples/s, speed: 4497.063061 tokens/s, learning rate: 1.687e-05, loss_scalings: 6871.948730, pp_loss: 7.406286
[INFO] 2021-07-12 19:05:56,946 [run_pretraining.py:  512]:	********exe.run_1688******* 
[INFO] 2021-07-12 19:05:57,905 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:57,905 [run_pretraining.py:  534]:	loss/total_loss, 7.1937713623046875, 1689
[INFO] 2021-07-12 19:05:57,906 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1937713623046875, 1689
[INFO] 2021-07-12 19:05:57,906 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6879999748198316e-05, 1689
[INFO] 2021-07-12 19:05:57,906 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1689
[INFO] 2021-07-12 19:05:57,906 [run_pretraining.py:  558]:	worker_index: 2, step: 1689, cost: 7.193771, mlm loss: 7.193771, speed: 1.042625 steps/s, speed: 8.340998 samples/s, speed: 4270.590764 tokens/s, learning rate: 1.688e-05, loss_scalings: 6871.948730, pp_loss: 7.373236
[INFO] 2021-07-12 19:05:57,906 [run_pretraining.py:  512]:	********exe.run_1689******* 
[INFO] 2021-07-12 19:05:58,816 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:58,817 [run_pretraining.py:  534]:	loss/total_loss, 6.57195520401001, 1690
[INFO] 2021-07-12 19:05:58,817 [run_pretraining.py:  535]:	loss/mlm_loss, 6.57195520401001, 1690
[INFO] 2021-07-12 19:05:58,817 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6889998732949607e-05, 1690
[INFO] 2021-07-12 19:05:58,817 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1690
[INFO] 2021-07-12 19:05:58,817 [run_pretraining.py:  558]:	worker_index: 2, step: 1690, cost: 6.571955, mlm loss: 6.571955, speed: 1.098110 steps/s, speed: 8.784881 samples/s, speed: 4497.858967 tokens/s, learning rate: 1.689e-05, loss_scalings: 6871.948730, pp_loss: 7.354665
[INFO] 2021-07-12 19:05:58,817 [run_pretraining.py:  512]:	********exe.run_1690******* 
[INFO] 2021-07-12 19:05:59,733 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:59,734 [run_pretraining.py:  534]:	loss/total_loss, 7.366428375244141, 1691
[INFO] 2021-07-12 19:05:59,734 [run_pretraining.py:  535]:	loss/mlm_loss, 7.366428375244141, 1691
[INFO] 2021-07-12 19:05:59,734 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6899999536690302e-05, 1691
[INFO] 2021-07-12 19:05:59,734 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1691
[INFO] 2021-07-12 19:05:59,734 [run_pretraining.py:  558]:	worker_index: 2, step: 1691, cost: 7.366428, mlm loss: 7.366428, speed: 1.090979 steps/s, speed: 8.727833 samples/s, speed: 4468.650328 tokens/s, learning rate: 1.690e-05, loss_scalings: 6871.948730, pp_loss: 7.026816
[INFO] 2021-07-12 19:05:59,734 [run_pretraining.py:  512]:	********exe.run_1691******* 
[INFO] 2021-07-12 19:06:00,649 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:00,649 [run_pretraining.py:  534]:	loss/total_loss, 7.402431488037109, 1692
[INFO] 2021-07-12 19:06:00,650 [run_pretraining.py:  535]:	loss/mlm_loss, 7.402431488037109, 1692
[INFO] 2021-07-12 19:06:00,650 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6910000340430997e-05, 1692
[INFO] 2021-07-12 19:06:00,650 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1692
[INFO] 2021-07-12 19:06:00,650 [run_pretraining.py:  558]:	worker_index: 2, step: 1692, cost: 7.402431, mlm loss: 7.402431, speed: 1.092965 steps/s, speed: 8.743719 samples/s, speed: 4476.784046 tokens/s, learning rate: 1.691e-05, loss_scalings: 6871.948730, pp_loss: 7.454513
[INFO] 2021-07-12 19:06:00,650 [run_pretraining.py:  512]:	********exe.run_1692******* 
[INFO] 2021-07-12 19:06:01,573 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:01,573 [run_pretraining.py:  534]:	loss/total_loss, 7.069927215576172, 1693
[INFO] 2021-07-12 19:06:01,573 [run_pretraining.py:  535]:	loss/mlm_loss, 7.069927215576172, 1693
[INFO] 2021-07-12 19:06:01,573 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.691999932518229e-05, 1693
[INFO] 2021-07-12 19:06:01,573 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1693
[INFO] 2021-07-12 19:06:01,573 [run_pretraining.py:  558]:	worker_index: 2, step: 1693, cost: 7.069927, mlm loss: 7.069927, speed: 1.083385 steps/s, speed: 8.667084 samples/s, speed: 4437.546784 tokens/s, learning rate: 1.692e-05, loss_scalings: 6871.948730, pp_loss: 7.520331
[INFO] 2021-07-12 19:06:01,574 [run_pretraining.py:  512]:	********exe.run_1693******* 
[INFO] 2021-07-12 19:06:02,478 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:02,479 [run_pretraining.py:  534]:	loss/total_loss, 7.343721389770508, 1694
[INFO] 2021-07-12 19:06:02,479 [run_pretraining.py:  535]:	loss/mlm_loss, 7.343721389770508, 1694
[INFO] 2021-07-12 19:06:02,479 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6930000128922984e-05, 1694
[INFO] 2021-07-12 19:06:02,479 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1694
[INFO] 2021-07-12 19:06:02,479 [run_pretraining.py:  558]:	worker_index: 2, step: 1694, cost: 7.343721, mlm loss: 7.343721, speed: 1.104678 steps/s, speed: 8.837423 samples/s, speed: 4524.760660 tokens/s, learning rate: 1.693e-05, loss_scalings: 6871.948730, pp_loss: 7.385800
[INFO] 2021-07-12 19:06:02,479 [run_pretraining.py:  512]:	********exe.run_1694******* 
[INFO] 2021-07-12 19:06:03,385 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:03,386 [run_pretraining.py:  534]:	loss/total_loss, 7.779843330383301, 1695
[INFO] 2021-07-12 19:06:03,386 [run_pretraining.py:  535]:	loss/mlm_loss, 7.779843330383301, 1695
[INFO] 2021-07-12 19:06:03,386 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.694000093266368e-05, 1695
[INFO] 2021-07-12 19:06:03,386 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1695
[INFO] 2021-07-12 19:06:03,386 [run_pretraining.py:  558]:	worker_index: 2, step: 1695, cost: 7.779843, mlm loss: 7.779843, speed: 1.103686 steps/s, speed: 8.829489 samples/s, speed: 4520.698188 tokens/s, learning rate: 1.694e-05, loss_scalings: 6871.948730, pp_loss: 6.952978
[INFO] 2021-07-12 19:06:03,386 [run_pretraining.py:  512]:	********exe.run_1695******* 
[INFO] 2021-07-12 19:06:04,304 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:04,305 [run_pretraining.py:  534]:	loss/total_loss, 7.2174787521362305, 1696
[INFO] 2021-07-12 19:06:04,305 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2174787521362305, 1696
[INFO] 2021-07-12 19:06:04,305 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6949998098425567e-05, 1696
[INFO] 2021-07-12 19:06:04,305 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1696
[INFO] 2021-07-12 19:06:04,305 [run_pretraining.py:  558]:	worker_index: 2, step: 1696, cost: 7.217479, mlm loss: 7.217479, speed: 1.088898 steps/s, speed: 8.711185 samples/s, speed: 4460.126911 tokens/s, learning rate: 1.695e-05, loss_scalings: 6871.948730, pp_loss: 7.471783
[INFO] 2021-07-12 19:06:04,305 [run_pretraining.py:  512]:	********exe.run_1696******* 
[INFO] 2021-07-12 19:06:05,226 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:05,227 [run_pretraining.py:  534]:	loss/total_loss, 7.934292793273926, 1697
[INFO] 2021-07-12 19:06:05,227 [run_pretraining.py:  535]:	loss/mlm_loss, 7.934292793273926, 1697
[INFO] 2021-07-12 19:06:05,227 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6959998902166262e-05, 1697
[INFO] 2021-07-12 19:06:05,227 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1697
[INFO] 2021-07-12 19:06:05,227 [run_pretraining.py:  558]:	worker_index: 2, step: 1697, cost: 7.934293, mlm loss: 7.934293, speed: 1.085000 steps/s, speed: 8.679998 samples/s, speed: 4444.158819 tokens/s, learning rate: 1.696e-05, loss_scalings: 6871.948730, pp_loss: 7.507679
[INFO] 2021-07-12 19:06:05,227 [run_pretraining.py:  512]:	********exe.run_1697******* 
[INFO] 2021-07-12 19:06:06,148 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:06,148 [run_pretraining.py:  534]:	loss/total_loss, 7.339438438415527, 1698
[INFO] 2021-07-12 19:06:06,148 [run_pretraining.py:  535]:	loss/mlm_loss, 7.339438438415527, 1698
[INFO] 2021-07-12 19:06:06,148 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6969999705906957e-05, 1698
[INFO] 2021-07-12 19:06:06,148 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1698
[INFO] 2021-07-12 19:06:06,148 [run_pretraining.py:  558]:	worker_index: 2, step: 1698, cost: 7.339438, mlm loss: 7.339438, speed: 1.086270 steps/s, speed: 8.690159 samples/s, speed: 4449.361243 tokens/s, learning rate: 1.697e-05, loss_scalings: 6871.948730, pp_loss: 7.368937
[INFO] 2021-07-12 19:06:06,148 [run_pretraining.py:  512]:	********exe.run_1698******* 
[INFO] 2021-07-12 19:06:07,073 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:07,074 [run_pretraining.py:  534]:	loss/total_loss, 7.056178092956543, 1699
[INFO] 2021-07-12 19:06:07,074 [run_pretraining.py:  535]:	loss/mlm_loss, 7.056178092956543, 1699
[INFO] 2021-07-12 19:06:07,074 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.697999869065825e-05, 1699
[INFO] 2021-07-12 19:06:07,074 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1699
[INFO] 2021-07-12 19:06:07,074 [run_pretraining.py:  558]:	worker_index: 2, step: 1699, cost: 7.056178, mlm loss: 7.056178, speed: 1.080860 steps/s, speed: 8.646884 samples/s, speed: 4427.204576 tokens/s, learning rate: 1.698e-05, loss_scalings: 6871.948730, pp_loss: 6.991181
[INFO] 2021-07-12 19:06:07,074 [run_pretraining.py:  512]:	********exe.run_1699******* 
[INFO] 2021-07-12 19:06:08,005 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:08,006 [run_pretraining.py:  534]:	loss/total_loss, 7.528243541717529, 1700
[INFO] 2021-07-12 19:06:08,006 [run_pretraining.py:  535]:	loss/mlm_loss, 7.528243541717529, 1700
[INFO] 2021-07-12 19:06:08,006 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6989999494398944e-05, 1700
[INFO] 2021-07-12 19:06:08,006 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1700
[INFO] 2021-07-12 19:06:08,006 [run_pretraining.py:  558]:	worker_index: 2, step: 1700, cost: 7.528244, mlm loss: 7.528244, speed: 1.073827 steps/s, speed: 8.590614 samples/s, speed: 4398.394442 tokens/s, learning rate: 1.699e-05, loss_scalings: 6871.948730, pp_loss: 7.304181
[INFO] 2021-07-12 19:06:08,006 [run_pretraining.py:  512]:	********exe.run_1700******* 
[INFO] 2021-07-12 19:06:08,936 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:08,936 [run_pretraining.py:  534]:	loss/total_loss, 7.918540000915527, 1701
[INFO] 2021-07-12 19:06:08,937 [run_pretraining.py:  535]:	loss/mlm_loss, 7.918540000915527, 1701
[INFO] 2021-07-12 19:06:08,937 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.700000029813964e-05, 1701
[INFO] 2021-07-12 19:06:08,937 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1701
[INFO] 2021-07-12 19:06:08,937 [run_pretraining.py:  558]:	worker_index: 2, step: 1701, cost: 7.918540, mlm loss: 7.918540, speed: 1.075082 steps/s, speed: 8.600653 samples/s, speed: 4403.534231 tokens/s, learning rate: 1.700e-05, loss_scalings: 6871.948730, pp_loss: 7.709379
[INFO] 2021-07-12 19:06:08,937 [run_pretraining.py:  512]:	********exe.run_1701******* 
[INFO] 2021-07-12 19:06:09,868 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:09,868 [run_pretraining.py:  534]:	loss/total_loss, 7.808518409729004, 1702
[INFO] 2021-07-12 19:06:09,868 [run_pretraining.py:  535]:	loss/mlm_loss, 7.808518409729004, 1702
[INFO] 2021-07-12 19:06:09,868 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.700999928289093e-05, 1702
[INFO] 2021-07-12 19:06:09,869 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1702
[INFO] 2021-07-12 19:06:09,869 [run_pretraining.py:  558]:	worker_index: 2, step: 1702, cost: 7.808518, mlm loss: 7.808518, speed: 1.073879 steps/s, speed: 8.591034 samples/s, speed: 4398.609533 tokens/s, learning rate: 1.701e-05, loss_scalings: 6871.948730, pp_loss: 7.534040
[INFO] 2021-07-12 19:06:09,869 [run_pretraining.py:  512]:	********exe.run_1702******* 
[INFO] 2021-07-12 19:06:10,797 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:10,798 [run_pretraining.py:  534]:	loss/total_loss, 7.947229862213135, 1703
[INFO] 2021-07-12 19:06:10,798 [run_pretraining.py:  535]:	loss/mlm_loss, 7.947229862213135, 1703
[INFO] 2021-07-12 19:06:10,798 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7020000086631626e-05, 1703
[INFO] 2021-07-12 19:06:10,798 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1703
[INFO] 2021-07-12 19:06:10,798 [run_pretraining.py:  558]:	worker_index: 2, step: 1703, cost: 7.947230, mlm loss: 7.947230, speed: 1.076738 steps/s, speed: 8.613907 samples/s, speed: 4410.320327 tokens/s, learning rate: 1.702e-05, loss_scalings: 6871.948730, pp_loss: 7.119597
[INFO] 2021-07-12 19:06:10,798 [run_pretraining.py:  512]:	********exe.run_1703******* 
[INFO] 2021-07-12 19:06:11,722 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:11,723 [run_pretraining.py:  534]:	loss/total_loss, 7.259764194488525, 1704
[INFO] 2021-07-12 19:06:11,723 [run_pretraining.py:  535]:	loss/mlm_loss, 7.259764194488525, 1704
[INFO] 2021-07-12 19:06:11,723 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.703000089037232e-05, 1704
[INFO] 2021-07-12 19:06:11,723 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1704
[INFO] 2021-07-12 19:06:11,723 [run_pretraining.py:  558]:	worker_index: 2, step: 1704, cost: 7.259764, mlm loss: 7.259764, speed: 1.081621 steps/s, speed: 8.652971 samples/s, speed: 4430.321367 tokens/s, learning rate: 1.703e-05, loss_scalings: 6871.948730, pp_loss: 7.214630
[INFO] 2021-07-12 19:06:11,723 [run_pretraining.py:  512]:	********exe.run_1704******* 
[INFO] 2021-07-12 19:06:12,648 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:12,648 [run_pretraining.py:  534]:	loss/total_loss, 7.3817057609558105, 1705
[INFO] 2021-07-12 19:06:12,648 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3817057609558105, 1705
[INFO] 2021-07-12 19:06:12,648 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.703999805613421e-05, 1705
[INFO] 2021-07-12 19:06:12,648 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1705
[INFO] 2021-07-12 19:06:12,648 [run_pretraining.py:  558]:	worker_index: 2, step: 1705, cost: 7.381706, mlm loss: 7.381706, speed: 1.081311 steps/s, speed: 8.650486 samples/s, speed: 4429.049004 tokens/s, learning rate: 1.704e-05, loss_scalings: 6871.948730, pp_loss: 7.118198
[INFO] 2021-07-12 19:06:12,649 [run_pretraining.py:  512]:	********exe.run_1705******* 
[INFO] 2021-07-12 19:06:13,566 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:13,567 [run_pretraining.py:  534]:	loss/total_loss, 7.220097064971924, 1706
[INFO] 2021-07-12 19:06:13,567 [run_pretraining.py:  535]:	loss/mlm_loss, 7.220097064971924, 1706
[INFO] 2021-07-12 19:06:13,567 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7049998859874904e-05, 1706
[INFO] 2021-07-12 19:06:13,567 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1706
[INFO] 2021-07-12 19:06:13,567 [run_pretraining.py:  558]:	worker_index: 2, step: 1706, cost: 7.220097, mlm loss: 7.220097, speed: 1.089084 steps/s, speed: 8.712669 samples/s, speed: 4460.886628 tokens/s, learning rate: 1.705e-05, loss_scalings: 6871.948730, pp_loss: 7.509976
[INFO] 2021-07-12 19:06:13,567 [run_pretraining.py:  512]:	********exe.run_1706******* 
[INFO] 2021-07-12 19:06:14,487 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:14,488 [run_pretraining.py:  534]:	loss/total_loss, 7.898246765136719, 1707
[INFO] 2021-07-12 19:06:14,488 [run_pretraining.py:  535]:	loss/mlm_loss, 7.898246765136719, 1707
[INFO] 2021-07-12 19:06:14,488 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.70599996636156e-05, 1707
[INFO] 2021-07-12 19:06:14,488 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1707
[INFO] 2021-07-12 19:06:14,488 [run_pretraining.py:  558]:	worker_index: 2, step: 1707, cost: 7.898247, mlm loss: 7.898247, speed: 1.086655 steps/s, speed: 8.693243 samples/s, speed: 4450.940491 tokens/s, learning rate: 1.706e-05, loss_scalings: 6871.948730, pp_loss: 7.856007
[INFO] 2021-07-12 19:06:14,488 [run_pretraining.py:  512]:	********exe.run_1707******* 
[INFO] 2021-07-12 19:06:15,413 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:15,414 [run_pretraining.py:  534]:	loss/total_loss, 7.575402736663818, 1708
[INFO] 2021-07-12 19:06:15,414 [run_pretraining.py:  535]:	loss/mlm_loss, 7.575402736663818, 1708
[INFO] 2021-07-12 19:06:15,414 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.706999864836689e-05, 1708
[INFO] 2021-07-12 19:06:15,414 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1708
[INFO] 2021-07-12 19:06:15,414 [run_pretraining.py:  558]:	worker_index: 2, step: 1708, cost: 7.575403, mlm loss: 7.575403, speed: 1.080785 steps/s, speed: 8.646278 samples/s, speed: 4426.894279 tokens/s, learning rate: 1.707e-05, loss_scalings: 6871.948730, pp_loss: 7.419463
[INFO] 2021-07-12 19:06:15,414 [run_pretraining.py:  512]:	********exe.run_1708******* 
[INFO] 2021-07-12 19:06:16,336 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:16,336 [run_pretraining.py:  534]:	loss/total_loss, 8.178492546081543, 1709
[INFO] 2021-07-12 19:06:16,337 [run_pretraining.py:  535]:	loss/mlm_loss, 8.178492546081543, 1709
[INFO] 2021-07-12 19:06:16,337 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7079999452107586e-05, 1709
[INFO] 2021-07-12 19:06:16,337 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1709
[INFO] 2021-07-12 19:06:16,337 [run_pretraining.py:  558]:	worker_index: 2, step: 1709, cost: 8.178493, mlm loss: 8.178493, speed: 1.084429 steps/s, speed: 8.675431 samples/s, speed: 4441.820546 tokens/s, learning rate: 1.708e-05, loss_scalings: 6871.948730, pp_loss: 7.561177
[INFO] 2021-07-12 19:06:16,337 [run_pretraining.py:  512]:	********exe.run_1709******* 
[INFO] 2021-07-12 19:06:17,262 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:17,263 [run_pretraining.py:  534]:	loss/total_loss, 7.091504096984863, 1710
[INFO] 2021-07-12 19:06:17,263 [run_pretraining.py:  535]:	loss/mlm_loss, 7.091504096984863, 1710
[INFO] 2021-07-12 19:06:17,263 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.709000025584828e-05, 1710
[INFO] 2021-07-12 19:06:17,263 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1710
[INFO] 2021-07-12 19:06:17,263 [run_pretraining.py:  558]:	worker_index: 2, step: 1710, cost: 7.091504, mlm loss: 7.091504, speed: 1.080307 steps/s, speed: 8.642456 samples/s, speed: 4424.937672 tokens/s, learning rate: 1.709e-05, loss_scalings: 6871.948730, pp_loss: 7.011417
[INFO] 2021-07-12 19:06:17,263 [run_pretraining.py:  512]:	********exe.run_1710******* 
[INFO] 2021-07-12 19:06:18,180 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:18,181 [run_pretraining.py:  534]:	loss/total_loss, 6.9259490966796875, 1711
[INFO] 2021-07-12 19:06:18,181 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9259490966796875, 1711
[INFO] 2021-07-12 19:06:18,181 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7099999240599573e-05, 1711
[INFO] 2021-07-12 19:06:18,181 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1711
[INFO] 2021-07-12 19:06:18,181 [run_pretraining.py:  558]:	worker_index: 2, step: 1711, cost: 6.925949, mlm loss: 6.925949, speed: 1.089853 steps/s, speed: 8.718827 samples/s, speed: 4464.039442 tokens/s, learning rate: 1.710e-05, loss_scalings: 6871.948730, pp_loss: 7.387030
[INFO] 2021-07-12 19:06:18,181 [run_pretraining.py:  512]:	********exe.run_1711******* 
[INFO] 2021-07-12 19:06:19,104 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:19,104 [run_pretraining.py:  534]:	loss/total_loss, 7.306068420410156, 1712
[INFO] 2021-07-12 19:06:19,104 [run_pretraining.py:  535]:	loss/mlm_loss, 7.306068420410156, 1712
[INFO] 2021-07-12 19:06:19,104 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7110000044340268e-05, 1712
[INFO] 2021-07-12 19:06:19,104 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1712
[INFO] 2021-07-12 19:06:19,104 [run_pretraining.py:  558]:	worker_index: 2, step: 1712, cost: 7.306068, mlm loss: 7.306068, speed: 1.083905 steps/s, speed: 8.671243 samples/s, speed: 4439.676326 tokens/s, learning rate: 1.711e-05, loss_scalings: 6871.948730, pp_loss: 6.768098
[INFO] 2021-07-12 19:06:19,105 [run_pretraining.py:  512]:	********exe.run_1712******* 
[INFO] 2021-07-12 19:06:20,057 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:20,058 [run_pretraining.py:  534]:	loss/total_loss, 8.117648124694824, 1713
[INFO] 2021-07-12 19:06:20,058 [run_pretraining.py:  535]:	loss/mlm_loss, 8.117648124694824, 1713
[INFO] 2021-07-12 19:06:20,058 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7120000848080963e-05, 1713
[INFO] 2021-07-12 19:06:20,058 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1713
[INFO] 2021-07-12 19:06:20,058 [run_pretraining.py:  558]:	worker_index: 2, step: 1713, cost: 8.117648, mlm loss: 8.117648, speed: 1.049209 steps/s, speed: 8.393674 samples/s, speed: 4297.560874 tokens/s, learning rate: 1.712e-05, loss_scalings: 6871.948730, pp_loss: 7.599909
[INFO] 2021-07-12 19:06:20,058 [run_pretraining.py:  512]:	********exe.run_1713******* 
[INFO] 2021-07-12 19:06:20,989 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:20,989 [run_pretraining.py:  534]:	loss/total_loss, 7.753888130187988, 1714
[INFO] 2021-07-12 19:06:20,989 [run_pretraining.py:  535]:	loss/mlm_loss, 7.753888130187988, 1714
[INFO] 2021-07-12 19:06:20,990 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7129999832832254e-05, 1714
[INFO] 2021-07-12 19:06:20,990 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1714
[INFO] 2021-07-12 19:06:20,990 [run_pretraining.py:  558]:	worker_index: 2, step: 1714, cost: 7.753888, mlm loss: 7.753888, speed: 1.074262 steps/s, speed: 8.594097 samples/s, speed: 4400.177746 tokens/s, learning rate: 1.713e-05, loss_scalings: 6871.948730, pp_loss: 7.305753
[INFO] 2021-07-12 19:06:20,990 [run_pretraining.py:  512]:	********exe.run_1714******* 
[INFO] 2021-07-12 19:06:21,915 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:21,915 [run_pretraining.py:  534]:	loss/total_loss, 7.140275478363037, 1715
[INFO] 2021-07-12 19:06:21,915 [run_pretraining.py:  535]:	loss/mlm_loss, 7.140275478363037, 1715
[INFO] 2021-07-12 19:06:21,916 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7139998817583546e-05, 1715
[INFO] 2021-07-12 19:06:21,916 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1715
[INFO] 2021-07-12 19:06:21,916 [run_pretraining.py:  558]:	worker_index: 2, step: 1715, cost: 7.140275, mlm loss: 7.140275, speed: 1.080537 steps/s, speed: 8.644300 samples/s, speed: 4425.881553 tokens/s, learning rate: 1.714e-05, loss_scalings: 6871.948730, pp_loss: 6.679358
[INFO] 2021-07-12 19:06:21,916 [run_pretraining.py:  512]:	********exe.run_1715******* 
[INFO] 2021-07-12 19:06:22,832 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:22,833 [run_pretraining.py:  534]:	loss/total_loss, 6.736407279968262, 1716
[INFO] 2021-07-12 19:06:22,833 [run_pretraining.py:  535]:	loss/mlm_loss, 6.736407279968262, 1716
[INFO] 2021-07-12 19:06:22,833 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.714999962132424e-05, 1716
[INFO] 2021-07-12 19:06:22,833 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1716
[INFO] 2021-07-12 19:06:22,833 [run_pretraining.py:  558]:	worker_index: 2, step: 1716, cost: 6.736407, mlm loss: 6.736407, speed: 1.090842 steps/s, speed: 8.726736 samples/s, speed: 4468.088989 tokens/s, learning rate: 1.715e-05, loss_scalings: 6871.948730, pp_loss: 6.629919
[INFO] 2021-07-12 19:06:22,833 [run_pretraining.py:  512]:	********exe.run_1716******* 
[INFO] 2021-07-12 19:06:23,883 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:23,883 [run_pretraining.py:  534]:	loss/total_loss, 7.174799919128418, 1717
[INFO] 2021-07-12 19:06:23,883 [run_pretraining.py:  535]:	loss/mlm_loss, 7.174799919128418, 1717
[INFO] 2021-07-12 19:06:23,884 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7159998606075533e-05, 1717
[INFO] 2021-07-12 19:06:23,884 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1717
[INFO] 2021-07-12 19:06:23,884 [run_pretraining.py:  558]:	worker_index: 2, step: 1717, cost: 7.174800, mlm loss: 7.174800, speed: 0.952372 steps/s, speed: 7.618975 samples/s, speed: 3900.915356 tokens/s, learning rate: 1.716e-05, loss_scalings: 6871.948730, pp_loss: 7.168699
[INFO] 2021-07-12 19:06:23,884 [run_pretraining.py:  512]:	********exe.run_1717******* 
[INFO] 2021-07-12 19:06:24,945 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:24,946 [run_pretraining.py:  534]:	loss/total_loss, 7.233666896820068, 1718
[INFO] 2021-07-12 19:06:24,946 [run_pretraining.py:  535]:	loss/mlm_loss, 7.233666896820068, 1718
[INFO] 2021-07-12 19:06:24,946 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7169999409816228e-05, 1718
[INFO] 2021-07-12 19:06:24,946 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1718
[INFO] 2021-07-12 19:06:24,946 [run_pretraining.py:  558]:	worker_index: 2, step: 1718, cost: 7.233667, mlm loss: 7.233667, speed: 0.942006 steps/s, speed: 7.536049 samples/s, speed: 3858.457145 tokens/s, learning rate: 1.717e-05, loss_scalings: 6871.948730, pp_loss: 7.267223
[INFO] 2021-07-12 19:06:24,946 [run_pretraining.py:  512]:	********exe.run_1718******* 
[INFO] 2021-07-12 19:06:26,017 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:26,017 [run_pretraining.py:  534]:	loss/total_loss, 6.8472514152526855, 1719
[INFO] 2021-07-12 19:06:26,018 [run_pretraining.py:  535]:	loss/mlm_loss, 6.8472514152526855, 1719
[INFO] 2021-07-12 19:06:26,018 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7180000213556923e-05, 1719
[INFO] 2021-07-12 19:06:26,018 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1719
[INFO] 2021-07-12 19:06:26,018 [run_pretraining.py:  558]:	worker_index: 2, step: 1719, cost: 6.847251, mlm loss: 6.847251, speed: 0.933489 steps/s, speed: 7.467908 samples/s, speed: 3823.569029 tokens/s, learning rate: 1.718e-05, loss_scalings: 6871.948730, pp_loss: 7.018022
[INFO] 2021-07-12 19:06:26,018 [run_pretraining.py:  512]:	********exe.run_1719******* 
[INFO] 2021-07-12 19:06:27,069 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:27,070 [run_pretraining.py:  534]:	loss/total_loss, 7.259839057922363, 1720
[INFO] 2021-07-12 19:06:27,070 [run_pretraining.py:  535]:	loss/mlm_loss, 7.259839057922363, 1720
[INFO] 2021-07-12 19:06:27,070 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7189999198308215e-05, 1720
[INFO] 2021-07-12 19:06:27,070 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1720
[INFO] 2021-07-12 19:06:27,070 [run_pretraining.py:  558]:	worker_index: 2, step: 1720, cost: 7.259839, mlm loss: 7.259839, speed: 0.950683 steps/s, speed: 7.605467 samples/s, speed: 3893.999271 tokens/s, learning rate: 1.719e-05, loss_scalings: 6871.948730, pp_loss: 7.325378
[INFO] 2021-07-12 19:06:27,070 [run_pretraining.py:  512]:	********exe.run_1720******* 
[INFO] 2021-07-12 19:06:28,138 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:28,138 [run_pretraining.py:  534]:	loss/total_loss, 7.294425010681152, 1721
[INFO] 2021-07-12 19:06:28,138 [run_pretraining.py:  535]:	loss/mlm_loss, 7.294425010681152, 1721
[INFO] 2021-07-12 19:06:28,138 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.720000000204891e-05, 1721
[INFO] 2021-07-12 19:06:28,138 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1721
[INFO] 2021-07-12 19:06:28,139 [run_pretraining.py:  558]:	worker_index: 2, step: 1721, cost: 7.294425, mlm loss: 7.294425, speed: 0.936592 steps/s, speed: 7.492737 samples/s, speed: 3836.281357 tokens/s, learning rate: 1.720e-05, loss_scalings: 6871.948730, pp_loss: 7.534140
[INFO] 2021-07-12 19:06:28,139 [run_pretraining.py:  512]:	********exe.run_1721******* 
[INFO] 2021-07-12 19:06:29,049 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:29,049 [run_pretraining.py:  534]:	loss/total_loss, 7.546633243560791, 1722
[INFO] 2021-07-12 19:06:29,050 [run_pretraining.py:  535]:	loss/mlm_loss, 7.546633243560791, 1722
[INFO] 2021-07-12 19:06:29,050 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.72099989868002e-05, 1722
[INFO] 2021-07-12 19:06:29,050 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1722
[INFO] 2021-07-12 19:06:29,050 [run_pretraining.py:  558]:	worker_index: 2, step: 1722, cost: 7.546633, mlm loss: 7.546633, speed: 1.098162 steps/s, speed: 8.785293 samples/s, speed: 4498.069765 tokens/s, learning rate: 1.721e-05, loss_scalings: 6871.948730, pp_loss: 7.445734
[INFO] 2021-07-12 19:06:29,050 [run_pretraining.py:  512]:	********exe.run_1722******* 
[INFO] 2021-07-12 19:06:29,957 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:29,958 [run_pretraining.py:  534]:	loss/total_loss, 7.369937419891357, 1723
[INFO] 2021-07-12 19:06:29,958 [run_pretraining.py:  535]:	loss/mlm_loss, 7.369937419891357, 1723
[INFO] 2021-07-12 19:06:29,958 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7219999790540896e-05, 1723
[INFO] 2021-07-12 19:06:29,958 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1723
[INFO] 2021-07-12 19:06:29,958 [run_pretraining.py:  558]:	worker_index: 2, step: 1723, cost: 7.369937, mlm loss: 7.369937, speed: 1.101642 steps/s, speed: 8.813137 samples/s, speed: 4512.326041 tokens/s, learning rate: 1.722e-05, loss_scalings: 6871.948730, pp_loss: 7.324806
[INFO] 2021-07-12 19:06:29,958 [run_pretraining.py:  512]:	********exe.run_1723******* 
[INFO] 2021-07-12 19:06:30,875 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:30,875 [run_pretraining.py:  534]:	loss/total_loss, 6.93042516708374, 1724
[INFO] 2021-07-12 19:06:30,875 [run_pretraining.py:  535]:	loss/mlm_loss, 6.93042516708374, 1724
[INFO] 2021-07-12 19:06:30,875 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7229998775292188e-05, 1724
[INFO] 2021-07-12 19:06:30,875 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1724
[INFO] 2021-07-12 19:06:30,875 [run_pretraining.py:  558]:	worker_index: 2, step: 1724, cost: 6.930425, mlm loss: 6.930425, speed: 1.090860 steps/s, speed: 8.726877 samples/s, speed: 4468.161037 tokens/s, learning rate: 1.723e-05, loss_scalings: 6871.948730, pp_loss: 7.082499
[INFO] 2021-07-12 19:06:30,876 [run_pretraining.py:  512]:	********exe.run_1724******* 
[INFO] 2021-07-12 19:06:31,784 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:31,784 [run_pretraining.py:  534]:	loss/total_loss, 5.352090358734131, 1725
[INFO] 2021-07-12 19:06:31,784 [run_pretraining.py:  535]:	loss/mlm_loss, 5.352090358734131, 1725
[INFO] 2021-07-12 19:06:31,785 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7239999579032883e-05, 1725
[INFO] 2021-07-12 19:06:31,785 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1725
[INFO] 2021-07-12 19:06:31,785 [run_pretraining.py:  558]:	worker_index: 2, step: 1725, cost: 5.352090, mlm loss: 5.352090, speed: 1.100582 steps/s, speed: 8.804654 samples/s, speed: 4507.983018 tokens/s, learning rate: 1.724e-05, loss_scalings: 6871.948730, pp_loss: 6.787868
[INFO] 2021-07-12 19:06:31,785 [run_pretraining.py:  512]:	********exe.run_1725******* 
[INFO] 2021-07-12 19:06:32,693 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:32,694 [run_pretraining.py:  534]:	loss/total_loss, 7.2851457595825195, 1726
[INFO] 2021-07-12 19:06:32,694 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2851457595825195, 1726
[INFO] 2021-07-12 19:06:32,694 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7250000382773578e-05, 1726
[INFO] 2021-07-12 19:06:32,694 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1726
[INFO] 2021-07-12 19:06:32,694 [run_pretraining.py:  558]:	worker_index: 2, step: 1726, cost: 7.285146, mlm loss: 7.285146, speed: 1.100328 steps/s, speed: 8.802624 samples/s, speed: 4506.943496 tokens/s, learning rate: 1.725e-05, loss_scalings: 6871.948730, pp_loss: 7.155937
[INFO] 2021-07-12 19:06:32,694 [run_pretraining.py:  512]:	********exe.run_1726******* 
[INFO] 2021-07-12 19:06:33,604 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:33,604 [run_pretraining.py:  534]:	loss/total_loss, 7.424424171447754, 1727
[INFO] 2021-07-12 19:06:33,604 [run_pretraining.py:  535]:	loss/mlm_loss, 7.424424171447754, 1727
[INFO] 2021-07-12 19:06:33,604 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.725999936752487e-05, 1727
[INFO] 2021-07-12 19:06:33,604 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1727
[INFO] 2021-07-12 19:06:33,604 [run_pretraining.py:  558]:	worker_index: 2, step: 1727, cost: 7.424424, mlm loss: 7.424424, speed: 1.099215 steps/s, speed: 8.793719 samples/s, speed: 4502.384260 tokens/s, learning rate: 1.726e-05, loss_scalings: 6871.948730, pp_loss: 7.235675
[INFO] 2021-07-12 19:06:33,604 [run_pretraining.py:  512]:	********exe.run_1727******* 
[INFO] 2021-07-12 19:06:34,557 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:34,558 [run_pretraining.py:  534]:	loss/total_loss, 7.579041481018066, 1728
[INFO] 2021-07-12 19:06:34,558 [run_pretraining.py:  535]:	loss/mlm_loss, 7.579041481018066, 1728
[INFO] 2021-07-12 19:06:34,558 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7270000171265565e-05, 1728
[INFO] 2021-07-12 19:06:34,558 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1728
[INFO] 2021-07-12 19:06:34,558 [run_pretraining.py:  558]:	worker_index: 2, step: 1728, cost: 7.579041, mlm loss: 7.579041, speed: 1.049314 steps/s, speed: 8.394516 samples/s, speed: 4297.992008 tokens/s, learning rate: 1.727e-05, loss_scalings: 6871.948730, pp_loss: 7.378752
[INFO] 2021-07-12 19:06:34,558 [run_pretraining.py:  512]:	********exe.run_1728******* 
[INFO] 2021-07-12 19:06:35,613 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:35,614 [run_pretraining.py:  534]:	loss/total_loss, 7.912590026855469, 1729
[INFO] 2021-07-12 19:06:35,614 [run_pretraining.py:  535]:	loss/mlm_loss, 7.912590026855469, 1729
[INFO] 2021-07-12 19:06:35,614 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7279999156016856e-05, 1729
[INFO] 2021-07-12 19:06:35,614 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1729
[INFO] 2021-07-12 19:06:35,614 [run_pretraining.py:  558]:	worker_index: 2, step: 1729, cost: 7.912590, mlm loss: 7.912590, speed: 0.947521 steps/s, speed: 7.580166 samples/s, speed: 3881.045103 tokens/s, learning rate: 1.728e-05, loss_scalings: 6871.948730, pp_loss: 7.241053
[INFO] 2021-07-12 19:06:35,614 [run_pretraining.py:  512]:	********exe.run_1729******* 
[INFO] 2021-07-12 19:06:36,669 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:36,669 [run_pretraining.py:  534]:	loss/total_loss, 7.395417213439941, 1730
[INFO] 2021-07-12 19:06:36,669 [run_pretraining.py:  535]:	loss/mlm_loss, 7.395417213439941, 1730
[INFO] 2021-07-12 19:06:36,670 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.728999995975755e-05, 1730
[INFO] 2021-07-12 19:06:36,670 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1730
[INFO] 2021-07-12 19:06:36,670 [run_pretraining.py:  558]:	worker_index: 2, step: 1730, cost: 7.395417, mlm loss: 7.395417, speed: 0.947830 steps/s, speed: 7.582641 samples/s, speed: 3882.312426 tokens/s, learning rate: 1.729e-05, loss_scalings: 6871.948730, pp_loss: 7.132128
[INFO] 2021-07-12 19:06:36,670 [run_pretraining.py:  512]:	********exe.run_1730******* 
[INFO] 2021-07-12 19:06:37,730 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:37,731 [run_pretraining.py:  534]:	loss/total_loss, 7.18198823928833, 1731
[INFO] 2021-07-12 19:06:37,731 [run_pretraining.py:  535]:	loss/mlm_loss, 7.18198823928833, 1731
[INFO] 2021-07-12 19:06:37,731 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7299998944508843e-05, 1731
[INFO] 2021-07-12 19:06:37,731 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1731
[INFO] 2021-07-12 19:06:37,731 [run_pretraining.py:  558]:	worker_index: 2, step: 1731, cost: 7.181988, mlm loss: 7.181988, speed: 0.942871 steps/s, speed: 7.542971 samples/s, speed: 3862.001234 tokens/s, learning rate: 1.730e-05, loss_scalings: 6871.948730, pp_loss: 7.489720
[INFO] 2021-07-12 19:06:37,731 [run_pretraining.py:  512]:	********exe.run_1731******* 
[INFO] 2021-07-12 19:06:38,787 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:38,788 [run_pretraining.py:  534]:	loss/total_loss, 7.343233108520508, 1732
[INFO] 2021-07-12 19:06:38,788 [run_pretraining.py:  535]:	loss/mlm_loss, 7.343233108520508, 1732
[INFO] 2021-07-12 19:06:38,788 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7309999748249538e-05, 1732
[INFO] 2021-07-12 19:06:38,788 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1732
[INFO] 2021-07-12 19:06:38,788 [run_pretraining.py:  558]:	worker_index: 2, step: 1732, cost: 7.343233, mlm loss: 7.343233, speed: 0.946372 steps/s, speed: 7.570975 samples/s, speed: 3876.339143 tokens/s, learning rate: 1.731e-05, loss_scalings: 6871.948730, pp_loss: 7.376003
[INFO] 2021-07-12 19:06:38,788 [run_pretraining.py:  512]:	********exe.run_1732******* 
[INFO] 2021-07-12 19:06:39,842 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:39,843 [run_pretraining.py:  534]:	loss/total_loss, 7.474656105041504, 1733
[INFO] 2021-07-12 19:06:39,843 [run_pretraining.py:  535]:	loss/mlm_loss, 7.474656105041504, 1733
[INFO] 2021-07-12 19:06:39,843 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.731999873300083e-05, 1733
[INFO] 2021-07-12 19:06:39,843 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1733
[INFO] 2021-07-12 19:06:39,843 [run_pretraining.py:  558]:	worker_index: 2, step: 1733, cost: 7.474656, mlm loss: 7.474656, speed: 0.948409 steps/s, speed: 7.587271 samples/s, speed: 3884.682653 tokens/s, learning rate: 1.732e-05, loss_scalings: 6871.948730, pp_loss: 7.562190
[INFO] 2021-07-12 19:06:39,843 [run_pretraining.py:  512]:	********exe.run_1733******* 
[INFO] 2021-07-12 19:06:40,905 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:40,906 [run_pretraining.py:  534]:	loss/total_loss, 8.155567169189453, 1734
[INFO] 2021-07-12 19:06:40,906 [run_pretraining.py:  535]:	loss/mlm_loss, 8.155567169189453, 1734
[INFO] 2021-07-12 19:06:40,906 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7329999536741525e-05, 1734
[INFO] 2021-07-12 19:06:40,906 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1734
[INFO] 2021-07-12 19:06:40,906 [run_pretraining.py:  558]:	worker_index: 2, step: 1734, cost: 8.155567, mlm loss: 8.155567, speed: 0.941383 steps/s, speed: 7.531063 samples/s, speed: 3855.904165 tokens/s, learning rate: 1.733e-05, loss_scalings: 6871.948730, pp_loss: 7.280256
[INFO] 2021-07-12 19:06:40,906 [run_pretraining.py:  512]:	********exe.run_1734******* 
[INFO] 2021-07-12 19:06:41,963 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:41,964 [run_pretraining.py:  534]:	loss/total_loss, 6.864428520202637, 1735
[INFO] 2021-07-12 19:06:41,964 [run_pretraining.py:  535]:	loss/mlm_loss, 6.864428520202637, 1735
[INFO] 2021-07-12 19:06:41,964 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.734000034048222e-05, 1735
[INFO] 2021-07-12 19:06:41,964 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1735
[INFO] 2021-07-12 19:06:41,964 [run_pretraining.py:  558]:	worker_index: 2, step: 1735, cost: 6.864429, mlm loss: 6.864429, speed: 0.945839 steps/s, speed: 7.566712 samples/s, speed: 3874.156425 tokens/s, learning rate: 1.734e-05, loss_scalings: 6871.948730, pp_loss: 6.865063
[INFO] 2021-07-12 19:06:41,964 [run_pretraining.py:  512]:	********exe.run_1735******* 
[INFO] 2021-07-12 19:06:43,021 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:43,021 [run_pretraining.py:  534]:	loss/total_loss, 7.0409393310546875, 1736
[INFO] 2021-07-12 19:06:43,021 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0409393310546875, 1736
[INFO] 2021-07-12 19:06:43,021 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.734999932523351e-05, 1736
[INFO] 2021-07-12 19:06:43,021 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1736
[INFO] 2021-07-12 19:06:43,022 [run_pretraining.py:  558]:	worker_index: 2, step: 1736, cost: 7.040939, mlm loss: 7.040939, speed: 0.946025 steps/s, speed: 7.568200 samples/s, speed: 3874.918392 tokens/s, learning rate: 1.735e-05, loss_scalings: 6871.948730, pp_loss: 7.248713
[INFO] 2021-07-12 19:06:43,022 [run_pretraining.py:  512]:	********exe.run_1736******* 
[INFO] 2021-07-12 19:06:44,080 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:44,080 [run_pretraining.py:  534]:	loss/total_loss, 7.210676670074463, 1737
[INFO] 2021-07-12 19:06:44,080 [run_pretraining.py:  535]:	loss/mlm_loss, 7.210676670074463, 1737
[INFO] 2021-07-12 19:06:44,081 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7360000128974207e-05, 1737
[INFO] 2021-07-12 19:06:44,081 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1737
[INFO] 2021-07-12 19:06:44,081 [run_pretraining.py:  558]:	worker_index: 2, step: 1737, cost: 7.210677, mlm loss: 7.210677, speed: 0.944687 steps/s, speed: 7.557499 samples/s, speed: 3869.439257 tokens/s, learning rate: 1.736e-05, loss_scalings: 6871.948730, pp_loss: 7.307945
[INFO] 2021-07-12 19:06:44,081 [run_pretraining.py:  512]:	********exe.run_1737******* 
[INFO] 2021-07-12 19:06:45,141 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:45,142 [run_pretraining.py:  534]:	loss/total_loss, 6.558492660522461, 1738
[INFO] 2021-07-12 19:06:45,142 [run_pretraining.py:  535]:	loss/mlm_loss, 6.558492660522461, 1738
[INFO] 2021-07-12 19:06:45,142 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7370000932714902e-05, 1738
[INFO] 2021-07-12 19:06:45,142 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1738
[INFO] 2021-07-12 19:06:45,142 [run_pretraining.py:  558]:	worker_index: 2, step: 1738, cost: 6.558493, mlm loss: 6.558493, speed: 0.942890 steps/s, speed: 7.543124 samples/s, speed: 3862.079371 tokens/s, learning rate: 1.737e-05, loss_scalings: 6871.948730, pp_loss: 7.383465
[INFO] 2021-07-12 19:06:45,142 [run_pretraining.py:  512]:	********exe.run_1738******* 
[INFO] 2021-07-12 19:06:46,197 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:46,198 [run_pretraining.py:  534]:	loss/total_loss, 6.899391174316406, 1739
[INFO] 2021-07-12 19:06:46,198 [run_pretraining.py:  535]:	loss/mlm_loss, 6.899391174316406, 1739
[INFO] 2021-07-12 19:06:46,198 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7379999917466193e-05, 1739
[INFO] 2021-07-12 19:06:46,198 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1739
[INFO] 2021-07-12 19:06:46,198 [run_pretraining.py:  558]:	worker_index: 2, step: 1739, cost: 6.899391, mlm loss: 6.899391, speed: 0.947379 steps/s, speed: 7.579029 samples/s, speed: 3880.463026 tokens/s, learning rate: 1.738e-05, loss_scalings: 6871.948730, pp_loss: 7.529968
[INFO] 2021-07-12 19:06:46,198 [run_pretraining.py:  512]:	********exe.run_1739******* 
[INFO] 2021-07-12 19:06:47,252 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:47,252 [run_pretraining.py:  534]:	loss/total_loss, 7.110688209533691, 1740
[INFO] 2021-07-12 19:06:47,252 [run_pretraining.py:  535]:	loss/mlm_loss, 7.110688209533691, 1740
[INFO] 2021-07-12 19:06:47,252 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7389998902217485e-05, 1740
[INFO] 2021-07-12 19:06:47,252 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1740
[INFO] 2021-07-12 19:06:47,252 [run_pretraining.py:  558]:	worker_index: 2, step: 1740, cost: 7.110688, mlm loss: 7.110688, speed: 0.948962 steps/s, speed: 7.591700 samples/s, speed: 3886.950242 tokens/s, learning rate: 1.739e-05, loss_scalings: 6871.948730, pp_loss: 7.204769
[INFO] 2021-07-12 19:06:47,252 [run_pretraining.py:  512]:	********exe.run_1740******* 
[INFO] 2021-07-12 19:06:48,309 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:48,309 [run_pretraining.py:  534]:	loss/total_loss, 7.415192127227783, 1741
[INFO] 2021-07-12 19:06:48,309 [run_pretraining.py:  535]:	loss/mlm_loss, 7.415192127227783, 1741
[INFO] 2021-07-12 19:06:48,310 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.739999970595818e-05, 1741
[INFO] 2021-07-12 19:06:48,310 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1741
[INFO] 2021-07-12 19:06:48,310 [run_pretraining.py:  558]:	worker_index: 2, step: 1741, cost: 7.415192, mlm loss: 7.415192, speed: 0.946416 steps/s, speed: 7.571330 samples/s, speed: 3876.521074 tokens/s, learning rate: 1.740e-05, loss_scalings: 6871.948730, pp_loss: 7.385500
[INFO] 2021-07-12 19:06:48,310 [run_pretraining.py:  512]:	********exe.run_1741******* 
[INFO] 2021-07-12 19:07:13,842 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:13,843 [run_pretraining.py:  534]:	loss/total_loss, 7.144017219543457, 1742
[INFO] 2021-07-12 19:07:13,843 [run_pretraining.py:  535]:	loss/mlm_loss, 7.144017219543457, 1742
[INFO] 2021-07-12 19:07:13,843 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7409998690709472e-05, 1742
[INFO] 2021-07-12 19:07:13,843 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1742
[INFO] 2021-07-12 19:07:13,843 [run_pretraining.py:  558]:	worker_index: 2, step: 1742, cost: 7.144017, mlm loss: 7.144017, speed: 0.039165 steps/s, speed: 0.313321 samples/s, speed: 160.420418 tokens/s, learning rate: 1.741e-05, loss_scalings: 6871.948730, pp_loss: 6.957078
[INFO] 2021-07-12 19:07:13,843 [run_pretraining.py:  512]:	********exe.run_1742******* 
[INFO] 2021-07-12 19:07:14,864 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:14,864 [run_pretraining.py:  534]:	loss/total_loss, 6.759099006652832, 1743
[INFO] 2021-07-12 19:07:14,864 [run_pretraining.py:  535]:	loss/mlm_loss, 6.759099006652832, 1743
[INFO] 2021-07-12 19:07:14,864 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7419999494450167e-05, 1743
[INFO] 2021-07-12 19:07:14,864 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1743
[INFO] 2021-07-12 19:07:14,864 [run_pretraining.py:  558]:	worker_index: 2, step: 1743, cost: 6.759099, mlm loss: 6.759099, speed: 0.979768 steps/s, speed: 7.838141 samples/s, speed: 4013.128305 tokens/s, learning rate: 1.742e-05, loss_scalings: 6871.948730, pp_loss: 7.349224
[INFO] 2021-07-12 19:07:14,864 [run_pretraining.py:  512]:	********exe.run_1743******* 
[INFO] 2021-07-12 19:07:15,810 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:15,811 [run_pretraining.py:  534]:	loss/total_loss, 3.7999939918518066, 1744
[INFO] 2021-07-12 19:07:15,811 [run_pretraining.py:  535]:	loss/mlm_loss, 3.7999939918518066, 1744
[INFO] 2021-07-12 19:07:15,811 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7430000298190862e-05, 1744
[INFO] 2021-07-12 19:07:15,811 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1744
[INFO] 2021-07-12 19:07:15,811 [run_pretraining.py:  558]:	worker_index: 2, step: 1744, cost: 3.799994, mlm loss: 3.799994, speed: 1.057062 steps/s, speed: 8.456495 samples/s, speed: 4329.725248 tokens/s, learning rate: 1.743e-05, loss_scalings: 6871.948730, pp_loss: 6.222462
[INFO] 2021-07-12 19:07:15,811 [run_pretraining.py:  512]:	********exe.run_1744******* 
[INFO] 2021-07-12 19:07:16,821 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:16,827 [run_pretraining.py:  534]:	loss/total_loss, 7.684844970703125, 1745
[INFO] 2021-07-12 19:07:16,832 [run_pretraining.py:  535]:	loss/mlm_loss, 7.684844970703125, 1745
[INFO] 2021-07-12 19:07:16,837 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7439999282942154e-05, 1745
[INFO] 2021-07-12 19:07:16,842 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1745
[INFO] 2021-07-12 19:07:16,847 [run_pretraining.py:  558]:	worker_index: 2, step: 1745, cost: 7.684845, mlm loss: 7.684845, speed: 0.984754 steps/s, speed: 7.878031 samples/s, speed: 4033.551796 tokens/s, learning rate: 1.744e-05, loss_scalings: 6871.948730, pp_loss: 7.708487
[INFO] 2021-07-12 19:07:16,853 [run_pretraining.py:  512]:	********exe.run_1745******* 
[INFO] 2021-07-12 19:07:17,803 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:17,803 [run_pretraining.py:  534]:	loss/total_loss, 3.7771999835968018, 1746
[INFO] 2021-07-12 19:07:17,803 [run_pretraining.py:  535]:	loss/mlm_loss, 3.7771999835968018, 1746
[INFO] 2021-07-12 19:07:17,804 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.745000008668285e-05, 1746
[INFO] 2021-07-12 19:07:17,804 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1746
[INFO] 2021-07-12 19:07:17,804 [run_pretraining.py:  558]:	worker_index: 2, step: 1746, cost: 3.777200, mlm loss: 3.777200, speed: 1.051967 steps/s, speed: 8.415734 samples/s, speed: 4308.855816 tokens/s, learning rate: 1.745e-05, loss_scalings: 6871.948730, pp_loss: 6.097369
[INFO] 2021-07-12 19:07:17,804 [run_pretraining.py:  512]:	********exe.run_1746******* 
[INFO] 2021-07-12 19:07:18,745 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:18,746 [run_pretraining.py:  534]:	loss/total_loss, 6.933414459228516, 1747
[INFO] 2021-07-12 19:07:18,746 [run_pretraining.py:  535]:	loss/mlm_loss, 6.933414459228516, 1747
[INFO] 2021-07-12 19:07:18,746 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7460000890423544e-05, 1747
[INFO] 2021-07-12 19:07:18,746 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1747
[INFO] 2021-07-12 19:07:18,746 [run_pretraining.py:  558]:	worker_index: 2, step: 1747, cost: 6.933414, mlm loss: 6.933414, speed: 1.062039 steps/s, speed: 8.496314 samples/s, speed: 4350.112586 tokens/s, learning rate: 1.746e-05, loss_scalings: 6871.948730, pp_loss: 6.866575
[INFO] 2021-07-12 19:07:18,746 [run_pretraining.py:  512]:	********exe.run_1747******* 
[INFO] 2021-07-12 19:07:19,682 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:19,682 [run_pretraining.py:  534]:	loss/total_loss, 7.347430229187012, 1748
[INFO] 2021-07-12 19:07:19,682 [run_pretraining.py:  535]:	loss/mlm_loss, 7.347430229187012, 1748
[INFO] 2021-07-12 19:07:19,683 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7469999875174835e-05, 1748
[INFO] 2021-07-12 19:07:19,683 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1748
[INFO] 2021-07-12 19:07:19,683 [run_pretraining.py:  558]:	worker_index: 2, step: 1748, cost: 7.347430, mlm loss: 7.347430, speed: 1.068218 steps/s, speed: 8.545747 samples/s, speed: 4375.422566 tokens/s, learning rate: 1.747e-05, loss_scalings: 6871.948730, pp_loss: 7.454105
[INFO] 2021-07-12 19:07:19,683 [run_pretraining.py:  512]:	********exe.run_1748******* 
[INFO] 2021-07-12 19:07:20,617 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:20,618 [run_pretraining.py:  534]:	loss/total_loss, 7.241486549377441, 1749
[INFO] 2021-07-12 19:07:20,618 [run_pretraining.py:  535]:	loss/mlm_loss, 7.241486549377441, 1749
[INFO] 2021-07-12 19:07:20,618 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7479998859926127e-05, 1749
[INFO] 2021-07-12 19:07:20,618 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1749
[INFO] 2021-07-12 19:07:20,618 [run_pretraining.py:  558]:	worker_index: 2, step: 1749, cost: 7.241487, mlm loss: 7.241487, speed: 1.069932 steps/s, speed: 8.559453 samples/s, speed: 4382.439697 tokens/s, learning rate: 1.748e-05, loss_scalings: 6871.948730, pp_loss: 7.240640
[INFO] 2021-07-12 19:07:20,618 [run_pretraining.py:  512]:	********exe.run_1749******* 
[INFO] 2021-07-12 19:07:21,547 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:21,547 [run_pretraining.py:  534]:	loss/total_loss, 7.3443121910095215, 1750
[INFO] 2021-07-12 19:07:21,547 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3443121910095215, 1750
[INFO] 2021-07-12 19:07:21,547 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7489999663666822e-05, 1750
[INFO] 2021-07-12 19:07:21,548 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1750
[INFO] 2021-07-12 19:07:21,548 [run_pretraining.py:  558]:	worker_index: 2, step: 1750, cost: 7.344312, mlm loss: 7.344312, speed: 1.076391 steps/s, speed: 8.611126 samples/s, speed: 4408.896488 tokens/s, learning rate: 1.749e-05, loss_scalings: 6871.948730, pp_loss: 7.353393
[INFO] 2021-07-12 19:07:21,548 [run_pretraining.py:  512]:	********exe.run_1750******* 
[INFO] 2021-07-12 19:07:22,471 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:22,471 [run_pretraining.py:  534]:	loss/total_loss, 7.836910247802734, 1751
[INFO] 2021-07-12 19:07:22,472 [run_pretraining.py:  535]:	loss/mlm_loss, 7.836910247802734, 1751
[INFO] 2021-07-12 19:07:22,472 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7499998648418114e-05, 1751
[INFO] 2021-07-12 19:07:22,472 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1751
[INFO] 2021-07-12 19:07:22,472 [run_pretraining.py:  558]:	worker_index: 2, step: 1751, cost: 7.836910, mlm loss: 7.836910, speed: 1.082708 steps/s, speed: 8.661663 samples/s, speed: 4434.771242 tokens/s, learning rate: 1.750e-05, loss_scalings: 6871.948730, pp_loss: 7.557503
[INFO] 2021-07-12 19:07:22,472 [run_pretraining.py:  512]:	********exe.run_1751******* 
[INFO] 2021-07-12 19:07:23,402 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:23,403 [run_pretraining.py:  534]:	loss/total_loss, 6.693353652954102, 1752
[INFO] 2021-07-12 19:07:23,403 [run_pretraining.py:  535]:	loss/mlm_loss, 6.693353652954102, 1752
[INFO] 2021-07-12 19:07:23,403 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.750999945215881e-05, 1752
[INFO] 2021-07-12 19:07:23,403 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1752
[INFO] 2021-07-12 19:07:23,403 [run_pretraining.py:  558]:	worker_index: 2, step: 1752, cost: 6.693354, mlm loss: 6.693354, speed: 1.074674 steps/s, speed: 8.597389 samples/s, speed: 4401.863243 tokens/s, learning rate: 1.751e-05, loss_scalings: 6871.948730, pp_loss: 6.181002
[INFO] 2021-07-12 19:07:23,403 [run_pretraining.py:  512]:	********exe.run_1752******* 
[INFO] 2021-07-12 19:07:24,336 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:24,337 [run_pretraining.py:  534]:	loss/total_loss, 7.175352096557617, 1753
[INFO] 2021-07-12 19:07:24,337 [run_pretraining.py:  535]:	loss/mlm_loss, 7.175352096557617, 1753
[INFO] 2021-07-12 19:07:24,337 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7520000255899504e-05, 1753
[INFO] 2021-07-12 19:07:24,337 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1753
[INFO] 2021-07-12 19:07:24,337 [run_pretraining.py:  558]:	worker_index: 2, step: 1753, cost: 7.175352, mlm loss: 7.175352, speed: 1.071328 steps/s, speed: 8.570624 samples/s, speed: 4388.159741 tokens/s, learning rate: 1.752e-05, loss_scalings: 6871.948730, pp_loss: 7.493169
[INFO] 2021-07-12 19:07:24,337 [run_pretraining.py:  512]:	********exe.run_1753******* 
[INFO] 2021-07-12 19:07:25,277 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:25,278 [run_pretraining.py:  534]:	loss/total_loss, 7.993767738342285, 1754
[INFO] 2021-07-12 19:07:25,278 [run_pretraining.py:  535]:	loss/mlm_loss, 7.993767738342285, 1754
[INFO] 2021-07-12 19:07:25,278 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7529999240650795e-05, 1754
[INFO] 2021-07-12 19:07:25,278 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1754
[INFO] 2021-07-12 19:07:25,278 [run_pretraining.py:  558]:	worker_index: 2, step: 1754, cost: 7.993768, mlm loss: 7.993768, speed: 1.063102 steps/s, speed: 8.504820 samples/s, speed: 4354.467833 tokens/s, learning rate: 1.753e-05, loss_scalings: 6871.948730, pp_loss: 7.635303
[INFO] 2021-07-12 19:07:25,278 [run_pretraining.py:  512]:	********exe.run_1754******* 
[INFO] 2021-07-12 19:07:26,207 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:26,207 [run_pretraining.py:  534]:	loss/total_loss, 8.11687183380127, 1755
[INFO] 2021-07-12 19:07:26,207 [run_pretraining.py:  535]:	loss/mlm_loss, 8.11687183380127, 1755
[INFO] 2021-07-12 19:07:26,207 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.754000004439149e-05, 1755
[INFO] 2021-07-12 19:07:26,207 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1755
[INFO] 2021-07-12 19:07:26,207 [run_pretraining.py:  558]:	worker_index: 2, step: 1755, cost: 8.116872, mlm loss: 8.116872, speed: 1.076977 steps/s, speed: 8.615818 samples/s, speed: 4411.298758 tokens/s, learning rate: 1.754e-05, loss_scalings: 6871.948730, pp_loss: 7.484156
[INFO] 2021-07-12 19:07:26,207 [run_pretraining.py:  512]:	********exe.run_1755******* 
[INFO] 2021-07-12 19:07:27,136 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:27,137 [run_pretraining.py:  534]:	loss/total_loss, 7.574926376342773, 1756
[INFO] 2021-07-12 19:07:27,137 [run_pretraining.py:  535]:	loss/mlm_loss, 7.574926376342773, 1756
[INFO] 2021-07-12 19:07:27,137 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7550000848132186e-05, 1756
[INFO] 2021-07-12 19:07:27,137 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1756
[INFO] 2021-07-12 19:07:27,137 [run_pretraining.py:  558]:	worker_index: 2, step: 1756, cost: 7.574926, mlm loss: 7.574926, speed: 1.076031 steps/s, speed: 8.608245 samples/s, speed: 4407.421555 tokens/s, learning rate: 1.755e-05, loss_scalings: 6871.948730, pp_loss: 7.475961
[INFO] 2021-07-12 19:07:27,137 [run_pretraining.py:  512]:	********exe.run_1756******* 
[INFO] 2021-07-12 19:07:28,073 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:28,073 [run_pretraining.py:  534]:	loss/total_loss, 7.342331886291504, 1757
[INFO] 2021-07-12 19:07:28,073 [run_pretraining.py:  535]:	loss/mlm_loss, 7.342331886291504, 1757
[INFO] 2021-07-12 19:07:28,074 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7559999832883477e-05, 1757
[INFO] 2021-07-12 19:07:28,074 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1757
[INFO] 2021-07-12 19:07:28,074 [run_pretraining.py:  558]:	worker_index: 2, step: 1757, cost: 7.342332, mlm loss: 7.342332, speed: 1.068565 steps/s, speed: 8.548523 samples/s, speed: 4376.843819 tokens/s, learning rate: 1.756e-05, loss_scalings: 6871.948730, pp_loss: 6.923577
[INFO] 2021-07-12 19:07:28,074 [run_pretraining.py:  512]:	********exe.run_1757******* 
[INFO] 2021-07-12 19:07:28,995 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:28,995 [run_pretraining.py:  534]:	loss/total_loss, 6.967430591583252, 1758
[INFO] 2021-07-12 19:07:28,995 [run_pretraining.py:  535]:	loss/mlm_loss, 6.967430591583252, 1758
[INFO] 2021-07-12 19:07:28,995 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.756999881763477e-05, 1758
[INFO] 2021-07-12 19:07:28,995 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1758
[INFO] 2021-07-12 19:07:28,996 [run_pretraining.py:  558]:	worker_index: 2, step: 1758, cost: 6.967431, mlm loss: 6.967431, speed: 1.085510 steps/s, speed: 8.684082 samples/s, speed: 4446.249835 tokens/s, learning rate: 1.757e-05, loss_scalings: 6871.948730, pp_loss: 6.861919
[INFO] 2021-07-12 19:07:28,996 [run_pretraining.py:  512]:	********exe.run_1758******* 
[INFO] 2021-07-12 19:07:29,925 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:29,926 [run_pretraining.py:  534]:	loss/total_loss, 6.324716091156006, 1759
[INFO] 2021-07-12 19:07:29,926 [run_pretraining.py:  535]:	loss/mlm_loss, 6.324716091156006, 1759
[INFO] 2021-07-12 19:07:29,926 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7579999621375464e-05, 1759
[INFO] 2021-07-12 19:07:29,926 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1759
[INFO] 2021-07-12 19:07:29,926 [run_pretraining.py:  558]:	worker_index: 2, step: 1759, cost: 6.324716, mlm loss: 6.324716, speed: 1.075437 steps/s, speed: 8.603495 samples/s, speed: 4404.989621 tokens/s, learning rate: 1.758e-05, loss_scalings: 6871.948730, pp_loss: 6.907604
[INFO] 2021-07-12 19:07:29,926 [run_pretraining.py:  512]:	********exe.run_1759******* 
[INFO] 2021-07-12 19:07:30,842 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:30,842 [run_pretraining.py:  534]:	loss/total_loss, 7.506986618041992, 1760
[INFO] 2021-07-12 19:07:30,842 [run_pretraining.py:  535]:	loss/mlm_loss, 7.506986618041992, 1760
[INFO] 2021-07-12 19:07:30,843 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7589998606126755e-05, 1760
[INFO] 2021-07-12 19:07:30,843 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1760
[INFO] 2021-07-12 19:07:30,843 [run_pretraining.py:  558]:	worker_index: 2, step: 1760, cost: 7.506987, mlm loss: 7.506987, speed: 1.091669 steps/s, speed: 8.733353 samples/s, speed: 4471.476599 tokens/s, learning rate: 1.759e-05, loss_scalings: 6871.948730, pp_loss: 7.254529
[INFO] 2021-07-12 19:07:30,843 [run_pretraining.py:  512]:	********exe.run_1760******* 
[INFO] 2021-07-12 19:07:31,826 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:31,827 [run_pretraining.py:  534]:	loss/total_loss, 7.66334867477417, 1761
[INFO] 2021-07-12 19:07:31,827 [run_pretraining.py:  535]:	loss/mlm_loss, 7.66334867477417, 1761
[INFO] 2021-07-12 19:07:31,827 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.759999940986745e-05, 1761
[INFO] 2021-07-12 19:07:31,827 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1761
[INFO] 2021-07-12 19:07:31,827 [run_pretraining.py:  558]:	worker_index: 2, step: 1761, cost: 7.663349, mlm loss: 7.663349, speed: 1.016568 steps/s, speed: 8.132545 samples/s, speed: 4163.862869 tokens/s, learning rate: 1.760e-05, loss_scalings: 6871.948730, pp_loss: 7.229320
[INFO] 2021-07-12 19:07:31,827 [run_pretraining.py:  512]:	********exe.run_1761******* 
[INFO] 2021-07-12 19:07:32,923 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:32,924 [run_pretraining.py:  534]:	loss/total_loss, 7.370617866516113, 1762
[INFO] 2021-07-12 19:07:32,924 [run_pretraining.py:  535]:	loss/mlm_loss, 7.370617866516113, 1762
[INFO] 2021-07-12 19:07:32,924 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7610000213608146e-05, 1762
[INFO] 2021-07-12 19:07:32,924 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1762
[INFO] 2021-07-12 19:07:32,924 [run_pretraining.py:  558]:	worker_index: 2, step: 1762, cost: 7.370618, mlm loss: 7.370618, speed: 0.911987 steps/s, speed: 7.295893 samples/s, speed: 3735.497210 tokens/s, learning rate: 1.761e-05, loss_scalings: 6871.948730, pp_loss: 7.440749
[INFO] 2021-07-12 19:07:32,924 [run_pretraining.py:  512]:	********exe.run_1762******* 
[INFO] 2021-07-12 19:07:34,011 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:34,012 [run_pretraining.py:  534]:	loss/total_loss, 6.977506637573242, 1763
[INFO] 2021-07-12 19:07:34,012 [run_pretraining.py:  535]:	loss/mlm_loss, 6.977506637573242, 1763
[INFO] 2021-07-12 19:07:34,012 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7619999198359437e-05, 1763
[INFO] 2021-07-12 19:07:34,012 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1763
[INFO] 2021-07-12 19:07:34,012 [run_pretraining.py:  558]:	worker_index: 2, step: 1763, cost: 6.977507, mlm loss: 6.977507, speed: 0.919508 steps/s, speed: 7.356068 samples/s, speed: 3766.306815 tokens/s, learning rate: 1.762e-05, loss_scalings: 6871.948730, pp_loss: 7.432720
[INFO] 2021-07-12 19:07:34,012 [run_pretraining.py:  512]:	********exe.run_1763******* 
[INFO] 2021-07-12 19:07:35,112 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:35,113 [run_pretraining.py:  534]:	loss/total_loss, 7.880742073059082, 1764
[INFO] 2021-07-12 19:07:35,113 [run_pretraining.py:  535]:	loss/mlm_loss, 7.880742073059082, 1764
[INFO] 2021-07-12 19:07:35,113 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7630000002100132e-05, 1764
[INFO] 2021-07-12 19:07:35,113 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1764
[INFO] 2021-07-12 19:07:35,113 [run_pretraining.py:  558]:	worker_index: 2, step: 1764, cost: 7.880742, mlm loss: 7.880742, speed: 0.909004 steps/s, speed: 7.272034 samples/s, speed: 3723.281607 tokens/s, learning rate: 1.763e-05, loss_scalings: 6871.948730, pp_loss: 7.622999
[INFO] 2021-07-12 19:07:35,113 [run_pretraining.py:  512]:	********exe.run_1764******* 
[INFO] 2021-07-12 19:07:36,121 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:36,121 [run_pretraining.py:  534]:	loss/total_loss, 7.222151756286621, 1765
[INFO] 2021-07-12 19:07:36,121 [run_pretraining.py:  535]:	loss/mlm_loss, 7.222151756286621, 1765
[INFO] 2021-07-12 19:07:36,122 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7640000805840828e-05, 1765
[INFO] 2021-07-12 19:07:36,122 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1765
[INFO] 2021-07-12 19:07:36,122 [run_pretraining.py:  558]:	worker_index: 2, step: 1765, cost: 7.222152, mlm loss: 7.222152, speed: 0.991890 steps/s, speed: 7.935124 samples/s, speed: 4062.783294 tokens/s, learning rate: 1.764e-05, loss_scalings: 6871.948730, pp_loss: 7.345882
[INFO] 2021-07-12 19:07:36,122 [run_pretraining.py:  512]:	********exe.run_1765******* 
[INFO] 2021-07-12 19:07:37,033 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:37,033 [run_pretraining.py:  534]:	loss/total_loss, 7.63940954208374, 1766
[INFO] 2021-07-12 19:07:37,033 [run_pretraining.py:  535]:	loss/mlm_loss, 7.63940954208374, 1766
[INFO] 2021-07-12 19:07:37,033 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7649997971602716e-05, 1766
[INFO] 2021-07-12 19:07:37,034 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1766
[INFO] 2021-07-12 19:07:37,034 [run_pretraining.py:  558]:	worker_index: 2, step: 1766, cost: 7.639410, mlm loss: 7.639410, speed: 1.097338 steps/s, speed: 8.778703 samples/s, speed: 4494.695848 tokens/s, learning rate: 1.765e-05, loss_scalings: 6871.948730, pp_loss: 7.163695
[INFO] 2021-07-12 19:07:37,034 [run_pretraining.py:  512]:	********exe.run_1766******* 
[INFO] 2021-07-12 19:08:03,493 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:03,493 [run_pretraining.py:  534]:	loss/total_loss, 6.9580206871032715, 1767
[INFO] 2021-07-12 19:08:03,493 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9580206871032715, 1767
[INFO] 2021-07-12 19:08:03,493 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.765999877534341e-05, 1767
[INFO] 2021-07-12 19:08:03,494 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1767
[INFO] 2021-07-12 19:08:03,494 [run_pretraining.py:  558]:	worker_index: 2, step: 1767, cost: 6.958021, mlm loss: 6.958021, speed: 0.037794 steps/s, speed: 0.302351 samples/s, speed: 154.803546 tokens/s, learning rate: 1.766e-05, loss_scalings: 6871.948730, pp_loss: 7.160917
[INFO] 2021-07-12 19:08:03,494 [run_pretraining.py:  512]:	********exe.run_1767******* 
[INFO] 2021-07-12 19:08:04,449 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:04,450 [run_pretraining.py:  534]:	loss/total_loss, 6.849874496459961, 1768
[INFO] 2021-07-12 19:08:04,450 [run_pretraining.py:  535]:	loss/mlm_loss, 6.849874496459961, 1768
[INFO] 2021-07-12 19:08:04,450 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7669999579084106e-05, 1768
[INFO] 2021-07-12 19:08:04,450 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1768
[INFO] 2021-07-12 19:08:04,450 [run_pretraining.py:  558]:	worker_index: 2, step: 1768, cost: 6.849874, mlm loss: 6.849874, speed: 1.046084 steps/s, speed: 8.368674 samples/s, speed: 4284.760995 tokens/s, learning rate: 1.767e-05, loss_scalings: 6871.948730, pp_loss: 7.172689
[INFO] 2021-07-12 19:08:04,450 [run_pretraining.py:  512]:	********exe.run_1768******* 
[INFO] 2021-07-12 19:08:05,403 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:05,403 [run_pretraining.py:  534]:	loss/total_loss, 7.1153883934021, 1769
[INFO] 2021-07-12 19:08:05,403 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1153883934021, 1769
[INFO] 2021-07-12 19:08:05,404 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7679998563835397e-05, 1769
[INFO] 2021-07-12 19:08:05,404 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1769
[INFO] 2021-07-12 19:08:05,404 [run_pretraining.py:  558]:	worker_index: 2, step: 1769, cost: 7.115388, mlm loss: 7.115388, speed: 1.049416 steps/s, speed: 8.395324 samples/s, speed: 4298.406021 tokens/s, learning rate: 1.768e-05, loss_scalings: 6871.948730, pp_loss: 7.344698
[INFO] 2021-07-12 19:08:05,404 [run_pretraining.py:  512]:	********exe.run_1769******* 
[INFO] 2021-07-12 19:08:06,363 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:06,363 [run_pretraining.py:  534]:	loss/total_loss, 7.156129360198975, 1770
[INFO] 2021-07-12 19:08:06,363 [run_pretraining.py:  535]:	loss/mlm_loss, 7.156129360198975, 1770
[INFO] 2021-07-12 19:08:06,363 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7689999367576092e-05, 1770
[INFO] 2021-07-12 19:08:06,363 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1770
[INFO] 2021-07-12 19:08:06,364 [run_pretraining.py:  558]:	worker_index: 2, step: 1770, cost: 7.156129, mlm loss: 7.156129, speed: 1.042583 steps/s, speed: 8.340662 samples/s, speed: 4270.418794 tokens/s, learning rate: 1.769e-05, loss_scalings: 6871.948730, pp_loss: 7.251975
[INFO] 2021-07-12 19:08:06,364 [run_pretraining.py:  512]:	********exe.run_1770******* 
[INFO] 2021-07-12 19:08:07,318 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:07,319 [run_pretraining.py:  534]:	loss/total_loss, 7.52052640914917, 1771
[INFO] 2021-07-12 19:08:07,319 [run_pretraining.py:  535]:	loss/mlm_loss, 7.52052640914917, 1771
[INFO] 2021-07-12 19:08:07,319 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7700000171316788e-05, 1771
[INFO] 2021-07-12 19:08:07,319 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1771
[INFO] 2021-07-12 19:08:07,319 [run_pretraining.py:  558]:	worker_index: 2, step: 1771, cost: 7.520526, mlm loss: 7.520526, speed: 1.047413 steps/s, speed: 8.379305 samples/s, speed: 4290.204097 tokens/s, learning rate: 1.770e-05, loss_scalings: 6871.948730, pp_loss: 7.165466
[INFO] 2021-07-12 19:08:07,319 [run_pretraining.py:  512]:	********exe.run_1771******* 
[INFO] 2021-07-12 19:08:08,277 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:08,277 [run_pretraining.py:  534]:	loss/total_loss, 7.656396865844727, 1772
[INFO] 2021-07-12 19:08:08,277 [run_pretraining.py:  535]:	loss/mlm_loss, 7.656396865844727, 1772
[INFO] 2021-07-12 19:08:08,277 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.770999915606808e-05, 1772
[INFO] 2021-07-12 19:08:08,277 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1772
[INFO] 2021-07-12 19:08:08,277 [run_pretraining.py:  558]:	worker_index: 2, step: 1772, cost: 7.656397, mlm loss: 7.656397, speed: 1.043885 steps/s, speed: 8.351078 samples/s, speed: 4275.752066 tokens/s, learning rate: 1.771e-05, loss_scalings: 6871.948730, pp_loss: 7.385758
[INFO] 2021-07-12 19:08:08,277 [run_pretraining.py:  512]:	********exe.run_1772******* 
[INFO] 2021-07-12 19:08:09,219 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:09,219 [run_pretraining.py:  534]:	loss/total_loss, 7.185760021209717, 1773
[INFO] 2021-07-12 19:08:09,219 [run_pretraining.py:  535]:	loss/mlm_loss, 7.185760021209717, 1773
[INFO] 2021-07-12 19:08:09,220 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7719999959808774e-05, 1773
[INFO] 2021-07-12 19:08:09,220 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1773
[INFO] 2021-07-12 19:08:09,220 [run_pretraining.py:  558]:	worker_index: 2, step: 1773, cost: 7.185760, mlm loss: 7.185760, speed: 1.061996 steps/s, speed: 8.495965 samples/s, speed: 4349.934151 tokens/s, learning rate: 1.772e-05, loss_scalings: 6871.948730, pp_loss: 7.505266
[INFO] 2021-07-12 19:08:09,220 [run_pretraining.py:  512]:	********exe.run_1773******* 
[INFO] 2021-07-12 19:08:10,157 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:10,158 [run_pretraining.py:  534]:	loss/total_loss, 7.271927833557129, 1774
[INFO] 2021-07-12 19:08:10,158 [run_pretraining.py:  535]:	loss/mlm_loss, 7.271927833557129, 1774
[INFO] 2021-07-12 19:08:10,158 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.773000076354947e-05, 1774
[INFO] 2021-07-12 19:08:10,158 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1774
[INFO] 2021-07-12 19:08:10,158 [run_pretraining.py:  558]:	worker_index: 2, step: 1774, cost: 7.271928, mlm loss: 7.271928, speed: 1.066425 steps/s, speed: 8.531400 samples/s, speed: 4368.076891 tokens/s, learning rate: 1.773e-05, loss_scalings: 6871.948730, pp_loss: 7.292948
[INFO] 2021-07-12 19:08:10,158 [run_pretraining.py:  512]:	********exe.run_1774******* 
[INFO] 2021-07-12 19:08:11,089 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:11,090 [run_pretraining.py:  534]:	loss/total_loss, 7.708488464355469, 1775
[INFO] 2021-07-12 19:08:11,090 [run_pretraining.py:  535]:	loss/mlm_loss, 7.708488464355469, 1775
[INFO] 2021-07-12 19:08:11,090 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.773999974830076e-05, 1775
[INFO] 2021-07-12 19:08:11,090 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1775
[INFO] 2021-07-12 19:08:11,090 [run_pretraining.py:  558]:	worker_index: 2, step: 1775, cost: 7.708488, mlm loss: 7.708488, speed: 1.073418 steps/s, speed: 8.587347 samples/s, speed: 4396.721726 tokens/s, learning rate: 1.774e-05, loss_scalings: 6871.948730, pp_loss: 7.749611
[INFO] 2021-07-12 19:08:11,090 [run_pretraining.py:  512]:	********exe.run_1775******* 
[INFO] 2021-07-12 19:08:12,035 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:12,035 [run_pretraining.py:  534]:	loss/total_loss, 6.742589950561523, 1776
[INFO] 2021-07-12 19:08:12,035 [run_pretraining.py:  535]:	loss/mlm_loss, 6.742589950561523, 1776
[INFO] 2021-07-12 19:08:12,036 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7749998733052053e-05, 1776
[INFO] 2021-07-12 19:08:12,036 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1776
[INFO] 2021-07-12 19:08:12,036 [run_pretraining.py:  558]:	worker_index: 2, step: 1776, cost: 6.742590, mlm loss: 6.742590, speed: 1.058303 steps/s, speed: 8.466425 samples/s, speed: 4334.809615 tokens/s, learning rate: 1.775e-05, loss_scalings: 6871.948730, pp_loss: 7.381687
[INFO] 2021-07-12 19:08:12,036 [run_pretraining.py:  512]:	********exe.run_1776******* 
[INFO] 2021-07-12 19:08:12,971 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:12,972 [run_pretraining.py:  534]:	loss/total_loss, 7.584455490112305, 1777
[INFO] 2021-07-12 19:08:12,972 [run_pretraining.py:  535]:	loss/mlm_loss, 7.584455490112305, 1777
[INFO] 2021-07-12 19:08:12,972 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7759999536792748e-05, 1777
[INFO] 2021-07-12 19:08:12,972 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1777
[INFO] 2021-07-12 19:08:12,972 [run_pretraining.py:  558]:	worker_index: 2, step: 1777, cost: 7.584455, mlm loss: 7.584455, speed: 1.068482 steps/s, speed: 8.547855 samples/s, speed: 4376.501519 tokens/s, learning rate: 1.776e-05, loss_scalings: 6871.948730, pp_loss: 7.342234
[INFO] 2021-07-12 19:08:12,972 [run_pretraining.py:  512]:	********exe.run_1777******* 
[INFO] 2021-07-12 19:08:13,918 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:13,919 [run_pretraining.py:  534]:	loss/total_loss, 7.3227458000183105, 1778
[INFO] 2021-07-12 19:08:13,919 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3227458000183105, 1778
[INFO] 2021-07-12 19:08:13,919 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.776999852154404e-05, 1778
[INFO] 2021-07-12 19:08:13,919 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1778
[INFO] 2021-07-12 19:08:13,919 [run_pretraining.py:  558]:	worker_index: 2, step: 1778, cost: 7.322746, mlm loss: 7.322746, speed: 1.056977 steps/s, speed: 8.455813 samples/s, speed: 4329.376095 tokens/s, learning rate: 1.777e-05, loss_scalings: 6871.948730, pp_loss: 7.359765
[INFO] 2021-07-12 19:08:13,919 [run_pretraining.py:  512]:	********exe.run_1778******* 
[INFO] 2021-07-12 19:08:14,909 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:14,909 [run_pretraining.py:  534]:	loss/total_loss, 4.374995708465576, 1779
[INFO] 2021-07-12 19:08:14,909 [run_pretraining.py:  535]:	loss/mlm_loss, 4.374995708465576, 1779
[INFO] 2021-07-12 19:08:14,909 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7779999325284734e-05, 1779
[INFO] 2021-07-12 19:08:14,909 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1779
[INFO] 2021-07-12 19:08:14,909 [run_pretraining.py:  558]:	worker_index: 2, step: 1779, cost: 4.374996, mlm loss: 4.374996, speed: 1.010315 steps/s, speed: 8.082519 samples/s, speed: 4138.249710 tokens/s, learning rate: 1.778e-05, loss_scalings: 6871.948730, pp_loss: 6.708546
[INFO] 2021-07-12 19:08:14,909 [run_pretraining.py:  512]:	********exe.run_1779******* 
[INFO] 2021-07-12 19:08:15,925 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:15,925 [run_pretraining.py:  534]:	loss/total_loss, 7.125915050506592, 1780
[INFO] 2021-07-12 19:08:15,925 [run_pretraining.py:  535]:	loss/mlm_loss, 7.125915050506592, 1780
[INFO] 2021-07-12 19:08:15,925 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.779000012902543e-05, 1780
[INFO] 2021-07-12 19:08:15,925 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1780
[INFO] 2021-07-12 19:08:15,925 [run_pretraining.py:  558]:	worker_index: 2, step: 1780, cost: 7.125915, mlm loss: 7.125915, speed: 0.984693 steps/s, speed: 7.877541 samples/s, speed: 4033.300853 tokens/s, learning rate: 1.779e-05, loss_scalings: 6871.948730, pp_loss: 7.358622
[INFO] 2021-07-12 19:08:15,926 [run_pretraining.py:  512]:	********exe.run_1780******* 
[INFO] 2021-07-12 19:08:16,999 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:17,000 [run_pretraining.py:  534]:	loss/total_loss, 6.814613342285156, 1781
[INFO] 2021-07-12 19:08:17,000 [run_pretraining.py:  535]:	loss/mlm_loss, 6.814613342285156, 1781
[INFO] 2021-07-12 19:08:17,000 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.779999911377672e-05, 1781
[INFO] 2021-07-12 19:08:17,000 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1781
[INFO] 2021-07-12 19:08:17,000 [run_pretraining.py:  558]:	worker_index: 2, step: 1781, cost: 6.814613, mlm loss: 6.814613, speed: 0.930918 steps/s, speed: 7.447347 samples/s, speed: 3813.041719 tokens/s, learning rate: 1.780e-05, loss_scalings: 6871.948730, pp_loss: 7.070363
[INFO] 2021-07-12 19:08:17,000 [run_pretraining.py:  512]:	********exe.run_1781******* 
[INFO] 2021-07-12 19:08:18,073 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:18,074 [run_pretraining.py:  534]:	loss/total_loss, 7.528219223022461, 1782
[INFO] 2021-07-12 19:08:18,074 [run_pretraining.py:  535]:	loss/mlm_loss, 7.528219223022461, 1782
[INFO] 2021-07-12 19:08:18,074 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7809999917517416e-05, 1782
[INFO] 2021-07-12 19:08:18,074 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1782
[INFO] 2021-07-12 19:08:18,074 [run_pretraining.py:  558]:	worker_index: 2, step: 1782, cost: 7.528219, mlm loss: 7.528219, speed: 0.931782 steps/s, speed: 7.454259 samples/s, speed: 3816.580834 tokens/s, learning rate: 1.781e-05, loss_scalings: 6871.948730, pp_loss: 7.343806
[INFO] 2021-07-12 19:08:18,074 [run_pretraining.py:  512]:	********exe.run_1782******* 
[INFO] 2021-07-12 19:08:19,140 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:19,141 [run_pretraining.py:  534]:	loss/total_loss, 7.7246856689453125, 1783
[INFO] 2021-07-12 19:08:19,141 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7246856689453125, 1783
[INFO] 2021-07-12 19:08:19,141 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.782000072125811e-05, 1783
[INFO] 2021-07-12 19:08:19,141 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1783
[INFO] 2021-07-12 19:08:19,141 [run_pretraining.py:  558]:	worker_index: 2, step: 1783, cost: 7.724686, mlm loss: 7.724686, speed: 0.937567 steps/s, speed: 7.500539 samples/s, speed: 3840.275765 tokens/s, learning rate: 1.782e-05, loss_scalings: 6871.948730, pp_loss: 7.234648
[INFO] 2021-07-12 19:08:19,141 [run_pretraining.py:  512]:	********exe.run_1783******* 
[INFO] 2021-07-12 19:08:20,199 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:20,199 [run_pretraining.py:  534]:	loss/total_loss, 7.5474982261657715, 1784
[INFO] 2021-07-12 19:08:20,199 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5474982261657715, 1784
[INFO] 2021-07-12 19:08:20,200 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7829999706009403e-05, 1784
[INFO] 2021-07-12 19:08:20,200 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1784
[INFO] 2021-07-12 19:08:20,200 [run_pretraining.py:  558]:	worker_index: 2, step: 1784, cost: 7.547498, mlm loss: 7.547498, speed: 0.945478 steps/s, speed: 7.563827 samples/s, speed: 3872.679656 tokens/s, learning rate: 1.783e-05, loss_scalings: 6871.948730, pp_loss: 7.335862
[INFO] 2021-07-12 19:08:20,200 [run_pretraining.py:  512]:	********exe.run_1784******* 
[INFO] 2021-07-12 19:08:21,295 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:21,296 [run_pretraining.py:  534]:	loss/total_loss, 7.354893684387207, 1785
[INFO] 2021-07-12 19:08:21,296 [run_pretraining.py:  535]:	loss/mlm_loss, 7.354893684387207, 1785
[INFO] 2021-07-12 19:08:21,296 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7839998690760694e-05, 1785
[INFO] 2021-07-12 19:08:21,296 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1785
[INFO] 2021-07-12 19:08:21,296 [run_pretraining.py:  558]:	worker_index: 2, step: 1785, cost: 7.354894, mlm loss: 7.354894, speed: 0.912430 steps/s, speed: 7.299442 samples/s, speed: 3737.314231 tokens/s, learning rate: 1.784e-05, loss_scalings: 6871.948730, pp_loss: 7.418790
[INFO] 2021-07-12 19:08:21,296 [run_pretraining.py:  512]:	********exe.run_1785******* 
[INFO] 2021-07-12 19:08:22,400 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:22,400 [run_pretraining.py:  534]:	loss/total_loss, 7.991846084594727, 1786
[INFO] 2021-07-12 19:08:22,400 [run_pretraining.py:  535]:	loss/mlm_loss, 7.991846084594727, 1786
[INFO] 2021-07-12 19:08:22,400 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.784999949450139e-05, 1786
[INFO] 2021-07-12 19:08:22,400 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1786
[INFO] 2021-07-12 19:08:22,401 [run_pretraining.py:  558]:	worker_index: 2, step: 1786, cost: 7.991846, mlm loss: 7.991846, speed: 0.906038 steps/s, speed: 7.248308 samples/s, speed: 3711.133612 tokens/s, learning rate: 1.785e-05, loss_scalings: 6871.948730, pp_loss: 7.161713
[INFO] 2021-07-12 19:08:22,401 [run_pretraining.py:  512]:	********exe.run_1786******* 
[INFO] 2021-07-12 19:08:23,607 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:23,608 [run_pretraining.py:  534]:	loss/total_loss, 7.534541606903076, 1787
[INFO] 2021-07-12 19:08:23,608 [run_pretraining.py:  535]:	loss/mlm_loss, 7.534541606903076, 1787
[INFO] 2021-07-12 19:08:23,608 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.785999847925268e-05, 1787
[INFO] 2021-07-12 19:08:23,608 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1787
[INFO] 2021-07-12 19:08:23,608 [run_pretraining.py:  558]:	worker_index: 2, step: 1787, cost: 7.534542, mlm loss: 7.534542, speed: 0.828613 steps/s, speed: 6.628903 samples/s, speed: 3393.998224 tokens/s, learning rate: 1.786e-05, loss_scalings: 6871.948730, pp_loss: 7.538829
[INFO] 2021-07-12 19:08:23,608 [run_pretraining.py:  512]:	********exe.run_1787******* 
[INFO] 2021-07-12 19:08:24,563 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:24,564 [run_pretraining.py:  534]:	loss/total_loss, 6.646311283111572, 1788
[INFO] 2021-07-12 19:08:24,564 [run_pretraining.py:  535]:	loss/mlm_loss, 6.646311283111572, 1788
[INFO] 2021-07-12 19:08:24,564 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7869999282993376e-05, 1788
[INFO] 2021-07-12 19:08:24,564 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1788
[INFO] 2021-07-12 19:08:24,564 [run_pretraining.py:  558]:	worker_index: 2, step: 1788, cost: 6.646311, mlm loss: 6.646311, speed: 1.046563 steps/s, speed: 8.372503 samples/s, speed: 4286.721787 tokens/s, learning rate: 1.787e-05, loss_scalings: 6871.948730, pp_loss: 6.863043
[INFO] 2021-07-12 19:08:24,564 [run_pretraining.py:  512]:	********exe.run_1788******* 
[INFO] 2021-07-12 19:08:25,519 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:25,519 [run_pretraining.py:  534]:	loss/total_loss, 7.449727535247803, 1789
[INFO] 2021-07-12 19:08:25,519 [run_pretraining.py:  535]:	loss/mlm_loss, 7.449727535247803, 1789
[INFO] 2021-07-12 19:08:25,519 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.788000008673407e-05, 1789
[INFO] 2021-07-12 19:08:25,519 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1789
[INFO] 2021-07-12 19:08:25,520 [run_pretraining.py:  558]:	worker_index: 2, step: 1789, cost: 7.449728, mlm loss: 7.449728, speed: 1.047344 steps/s, speed: 8.378750 samples/s, speed: 4289.920205 tokens/s, learning rate: 1.788e-05, loss_scalings: 6871.948730, pp_loss: 7.119833
[INFO] 2021-07-12 19:08:25,520 [run_pretraining.py:  512]:	********exe.run_1789******* 
[INFO] 2021-07-12 19:08:26,475 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:26,475 [run_pretraining.py:  534]:	loss/total_loss, 6.940296649932861, 1790
[INFO] 2021-07-12 19:08:26,475 [run_pretraining.py:  535]:	loss/mlm_loss, 6.940296649932861, 1790
[INFO] 2021-07-12 19:08:26,476 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7889999071485363e-05, 1790
[INFO] 2021-07-12 19:08:26,476 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1790
[INFO] 2021-07-12 19:08:26,476 [run_pretraining.py:  558]:	worker_index: 2, step: 1790, cost: 6.940297, mlm loss: 6.940297, speed: 1.046523 steps/s, speed: 8.372182 samples/s, speed: 4286.557071 tokens/s, learning rate: 1.789e-05, loss_scalings: 6871.948730, pp_loss: 7.129264
[INFO] 2021-07-12 19:08:26,476 [run_pretraining.py:  512]:	********exe.run_1790******* 
[INFO] 2021-07-12 19:08:27,419 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:27,419 [run_pretraining.py:  534]:	loss/total_loss, 7.468626499176025, 1791
[INFO] 2021-07-12 19:08:27,419 [run_pretraining.py:  535]:	loss/mlm_loss, 7.468626499176025, 1791
[INFO] 2021-07-12 19:08:27,420 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7899999875226058e-05, 1791
[INFO] 2021-07-12 19:08:27,420 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1791
[INFO] 2021-07-12 19:08:27,420 [run_pretraining.py:  558]:	worker_index: 2, step: 1791, cost: 7.468626, mlm loss: 7.468626, speed: 1.060048 steps/s, speed: 8.480381 samples/s, speed: 4341.954846 tokens/s, learning rate: 1.790e-05, loss_scalings: 6871.948730, pp_loss: 7.073997
[INFO] 2021-07-12 19:08:27,420 [run_pretraining.py:  512]:	********exe.run_1791******* 
[INFO] 2021-07-12 19:08:28,359 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:28,360 [run_pretraining.py:  534]:	loss/total_loss, 6.921031951904297, 1792
[INFO] 2021-07-12 19:08:28,360 [run_pretraining.py:  535]:	loss/mlm_loss, 6.921031951904297, 1792
[INFO] 2021-07-12 19:08:28,360 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7910000678966753e-05, 1792
[INFO] 2021-07-12 19:08:28,360 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1792
[INFO] 2021-07-12 19:08:28,360 [run_pretraining.py:  558]:	worker_index: 2, step: 1792, cost: 6.921032, mlm loss: 6.921032, speed: 1.064214 steps/s, speed: 8.513711 samples/s, speed: 4359.019823 tokens/s, learning rate: 1.791e-05, loss_scalings: 6871.948730, pp_loss: 6.352468
[INFO] 2021-07-12 19:08:28,360 [run_pretraining.py:  512]:	********exe.run_1792******* 
[INFO] 2021-07-12 19:08:29,300 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:29,301 [run_pretraining.py:  534]:	loss/total_loss, 7.11201810836792, 1793
[INFO] 2021-07-12 19:08:29,301 [run_pretraining.py:  535]:	loss/mlm_loss, 7.11201810836792, 1793
[INFO] 2021-07-12 19:08:29,301 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7919999663718045e-05, 1793
[INFO] 2021-07-12 19:08:29,301 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1793
[INFO] 2021-07-12 19:08:29,301 [run_pretraining.py:  558]:	worker_index: 2, step: 1793, cost: 7.112018, mlm loss: 7.112018, speed: 1.063176 steps/s, speed: 8.505404 samples/s, speed: 4354.766956 tokens/s, learning rate: 1.792e-05, loss_scalings: 6871.948730, pp_loss: 7.205571
[INFO] 2021-07-12 19:08:29,301 [run_pretraining.py:  512]:	********exe.run_1793******* 
[INFO] 2021-07-12 19:08:30,261 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:30,261 [run_pretraining.py:  534]:	loss/total_loss, 6.901668548583984, 1794
[INFO] 2021-07-12 19:08:30,261 [run_pretraining.py:  535]:	loss/mlm_loss, 6.901668548583984, 1794
[INFO] 2021-07-12 19:08:30,261 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7929998648469336e-05, 1794
[INFO] 2021-07-12 19:08:30,261 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1794
[INFO] 2021-07-12 19:08:30,262 [run_pretraining.py:  558]:	worker_index: 2, step: 1794, cost: 6.901669, mlm loss: 6.901669, speed: 1.041896 steps/s, speed: 8.335165 samples/s, speed: 4267.604483 tokens/s, learning rate: 1.793e-05, loss_scalings: 6871.948730, pp_loss: 7.149393
[INFO] 2021-07-12 19:08:30,262 [run_pretraining.py:  512]:	********exe.run_1794******* 
[INFO] 2021-07-12 19:08:31,219 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:31,219 [run_pretraining.py:  534]:	loss/total_loss, 8.1240873336792, 1795
[INFO] 2021-07-12 19:08:31,219 [run_pretraining.py:  535]:	loss/mlm_loss, 8.1240873336792, 1795
[INFO] 2021-07-12 19:08:31,219 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.793999945221003e-05, 1795
[INFO] 2021-07-12 19:08:31,219 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1795
[INFO] 2021-07-12 19:08:31,220 [run_pretraining.py:  558]:	worker_index: 2, step: 1795, cost: 8.124087, mlm loss: 8.124087, speed: 1.044535 steps/s, speed: 8.356282 samples/s, speed: 4278.416243 tokens/s, learning rate: 1.794e-05, loss_scalings: 6871.948730, pp_loss: 8.097200
[INFO] 2021-07-12 19:08:31,220 [run_pretraining.py:  512]:	********exe.run_1795******* 
[INFO] 2021-07-12 19:08:32,167 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:32,167 [run_pretraining.py:  534]:	loss/total_loss, 7.166947841644287, 1796
[INFO] 2021-07-12 19:08:32,168 [run_pretraining.py:  535]:	loss/mlm_loss, 7.166947841644287, 1796
[INFO] 2021-07-12 19:08:32,168 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7950000255950727e-05, 1796
[INFO] 2021-07-12 19:08:32,168 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1796
[INFO] 2021-07-12 19:08:32,168 [run_pretraining.py:  558]:	worker_index: 2, step: 1796, cost: 7.166948, mlm loss: 7.166948, speed: 1.055254 steps/s, speed: 8.442036 samples/s, speed: 4322.322193 tokens/s, learning rate: 1.795e-05, loss_scalings: 6871.948730, pp_loss: 7.163948
[INFO] 2021-07-12 19:08:32,168 [run_pretraining.py:  512]:	********exe.run_1796******* 
[INFO] 2021-07-12 19:08:33,118 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:33,118 [run_pretraining.py:  534]:	loss/total_loss, 7.252053260803223, 1797
[INFO] 2021-07-12 19:08:33,119 [run_pretraining.py:  535]:	loss/mlm_loss, 7.252053260803223, 1797
[INFO] 2021-07-12 19:08:33,119 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7959999240702018e-05, 1797
[INFO] 2021-07-12 19:08:33,119 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1797
[INFO] 2021-07-12 19:08:33,119 [run_pretraining.py:  558]:	worker_index: 2, step: 1797, cost: 7.252053, mlm loss: 7.252053, speed: 1.052215 steps/s, speed: 8.417719 samples/s, speed: 4309.871911 tokens/s, learning rate: 1.796e-05, loss_scalings: 6871.948730, pp_loss: 7.470872
[INFO] 2021-07-12 19:08:33,119 [run_pretraining.py:  512]:	********exe.run_1797******* 
[INFO] 2021-07-12 19:08:34,060 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:34,060 [run_pretraining.py:  534]:	loss/total_loss, 7.721773624420166, 1798
[INFO] 2021-07-12 19:08:34,061 [run_pretraining.py:  535]:	loss/mlm_loss, 7.721773624420166, 1798
[INFO] 2021-07-12 19:08:34,061 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7970000044442713e-05, 1798
[INFO] 2021-07-12 19:08:34,061 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1798
[INFO] 2021-07-12 19:08:34,061 [run_pretraining.py:  558]:	worker_index: 2, step: 1798, cost: 7.721774, mlm loss: 7.721774, speed: 1.062296 steps/s, speed: 8.498371 samples/s, speed: 4351.165867 tokens/s, learning rate: 1.797e-05, loss_scalings: 6871.948730, pp_loss: 7.388756
[INFO] 2021-07-12 19:08:34,061 [run_pretraining.py:  512]:	********exe.run_1798******* 
[INFO] 2021-07-12 19:08:34,996 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:34,997 [run_pretraining.py:  534]:	loss/total_loss, 8.253923416137695, 1799
[INFO] 2021-07-12 19:08:34,997 [run_pretraining.py:  535]:	loss/mlm_loss, 8.253923416137695, 1799
[INFO] 2021-07-12 19:08:34,997 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7979999029194005e-05, 1799
[INFO] 2021-07-12 19:08:34,997 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1799
[INFO] 2021-07-12 19:08:34,997 [run_pretraining.py:  558]:	worker_index: 2, step: 1799, cost: 8.253923, mlm loss: 8.253923, speed: 1.068713 steps/s, speed: 8.549706 samples/s, speed: 4377.449386 tokens/s, learning rate: 1.798e-05, loss_scalings: 6871.948730, pp_loss: 7.409789
[INFO] 2021-07-12 19:08:34,997 [run_pretraining.py:  512]:	********exe.run_1799******* 
[INFO] 2021-07-12 19:08:35,936 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:35,936 [run_pretraining.py:  534]:	loss/total_loss, 6.916240692138672, 1800
[INFO] 2021-07-12 19:08:35,936 [run_pretraining.py:  535]:	loss/mlm_loss, 6.916240692138672, 1800
[INFO] 2021-07-12 19:08:35,936 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.79899998329347e-05, 1800
[INFO] 2021-07-12 19:08:35,936 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1800
[INFO] 2021-07-12 19:08:35,936 [run_pretraining.py:  558]:	worker_index: 2, step: 1800, cost: 6.916241, mlm loss: 6.916241, speed: 1.065184 steps/s, speed: 8.521473 samples/s, speed: 4362.994008 tokens/s, learning rate: 1.799e-05, loss_scalings: 6871.948730, pp_loss: 6.955646
[INFO] 2021-07-12 19:08:35,937 [run_pretraining.py:  512]:	********exe.run_1800******* 
[INFO] 2021-07-12 19:08:36,881 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:36,882 [run_pretraining.py:  534]:	loss/total_loss, 7.30062198638916, 1801
[INFO] 2021-07-12 19:08:36,882 [run_pretraining.py:  535]:	loss/mlm_loss, 7.30062198638916, 1801
[INFO] 2021-07-12 19:08:36,882 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8000000636675395e-05, 1801
[INFO] 2021-07-12 19:08:36,882 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1801
[INFO] 2021-07-12 19:08:36,882 [run_pretraining.py:  558]:	worker_index: 2, step: 1801, cost: 7.300622, mlm loss: 7.300622, speed: 1.058300 steps/s, speed: 8.466399 samples/s, speed: 4334.796490 tokens/s, learning rate: 1.800e-05, loss_scalings: 6871.948730, pp_loss: 7.063627
[INFO] 2021-07-12 19:08:36,882 [run_pretraining.py:  512]:	********exe.run_1801******* 
[INFO] 2021-07-12 19:08:37,823 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:37,823 [run_pretraining.py:  534]:	loss/total_loss, 7.061615943908691, 1802
[INFO] 2021-07-12 19:08:37,824 [run_pretraining.py:  535]:	loss/mlm_loss, 7.061615943908691, 1802
[INFO] 2021-07-12 19:08:37,824 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8009999621426687e-05, 1802
[INFO] 2021-07-12 19:08:37,824 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1802
[INFO] 2021-07-12 19:08:37,824 [run_pretraining.py:  558]:	worker_index: 2, step: 1802, cost: 7.061616, mlm loss: 7.061616, speed: 1.062425 steps/s, speed: 8.499398 samples/s, speed: 4351.691596 tokens/s, learning rate: 1.801e-05, loss_scalings: 5497.559082, pp_loss: 7.560888
[INFO] 2021-07-12 19:08:37,824 [run_pretraining.py:  512]:	********exe.run_1802******* 
[INFO] 2021-07-12 19:08:38,770 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:38,770 [run_pretraining.py:  534]:	loss/total_loss, 7.338064193725586, 1803
[INFO] 2021-07-12 19:08:38,770 [run_pretraining.py:  535]:	loss/mlm_loss, 7.338064193725586, 1803
[INFO] 2021-07-12 19:08:38,770 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8019998606177978e-05, 1803
[INFO] 2021-07-12 19:08:38,770 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1803
[INFO] 2021-07-12 19:08:38,770 [run_pretraining.py:  558]:	worker_index: 2, step: 1803, cost: 7.338064, mlm loss: 7.338064, speed: 1.057001 steps/s, speed: 8.456011 samples/s, speed: 4329.477562 tokens/s, learning rate: 1.802e-05, loss_scalings: 5497.559082, pp_loss: 7.484008
[INFO] 2021-07-12 19:08:38,771 [run_pretraining.py:  512]:	********exe.run_1803******* 
[INFO] 2021-07-12 19:08:39,713 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:39,714 [run_pretraining.py:  534]:	loss/total_loss, 6.894355773925781, 1804
[INFO] 2021-07-12 19:08:39,714 [run_pretraining.py:  535]:	loss/mlm_loss, 6.894355773925781, 1804
[INFO] 2021-07-12 19:08:39,714 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8029999409918673e-05, 1804
[INFO] 2021-07-12 19:08:39,714 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1804
[INFO] 2021-07-12 19:08:39,714 [run_pretraining.py:  558]:	worker_index: 2, step: 1804, cost: 6.894356, mlm loss: 6.894356, speed: 1.060719 steps/s, speed: 8.485755 samples/s, speed: 4344.706583 tokens/s, learning rate: 1.803e-05, loss_scalings: 5497.559082, pp_loss: 7.224579
[INFO] 2021-07-12 19:08:39,714 [run_pretraining.py:  512]:	********exe.run_1804******* 
[INFO] 2021-07-12 19:08:40,648 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:40,648 [run_pretraining.py:  534]:	loss/total_loss, 6.919055938720703, 1805
[INFO] 2021-07-12 19:08:40,648 [run_pretraining.py:  535]:	loss/mlm_loss, 6.919055938720703, 1805
[INFO] 2021-07-12 19:08:40,648 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.804000021365937e-05, 1805
[INFO] 2021-07-12 19:08:40,648 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1805
[INFO] 2021-07-12 19:08:40,649 [run_pretraining.py:  558]:	worker_index: 2, step: 1805, cost: 6.919056, mlm loss: 6.919056, speed: 1.070596 steps/s, speed: 8.564768 samples/s, speed: 4385.161293 tokens/s, learning rate: 1.804e-05, loss_scalings: 5497.559082, pp_loss: 7.276357
[INFO] 2021-07-12 19:08:40,649 [run_pretraining.py:  512]:	********exe.run_1805******* 
[INFO] 2021-07-12 19:08:41,581 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:41,582 [run_pretraining.py:  534]:	loss/total_loss, 7.3344879150390625, 1806
[INFO] 2021-07-12 19:08:41,582 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3344879150390625, 1806
[INFO] 2021-07-12 19:08:41,582 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.804999919841066e-05, 1806
[INFO] 2021-07-12 19:08:41,582 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1806
[INFO] 2021-07-12 19:08:41,582 [run_pretraining.py:  558]:	worker_index: 2, step: 1806, cost: 7.334488, mlm loss: 7.334488, speed: 1.071992 steps/s, speed: 8.575932 samples/s, speed: 4390.877227 tokens/s, learning rate: 1.805e-05, loss_scalings: 5497.559082, pp_loss: 7.198650
[INFO] 2021-07-12 19:08:41,582 [run_pretraining.py:  512]:	********exe.run_1806******* 
[INFO] 2021-07-12 19:08:42,527 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:42,528 [run_pretraining.py:  534]:	loss/total_loss, 7.0710344314575195, 1807
[INFO] 2021-07-12 19:08:42,528 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0710344314575195, 1807
[INFO] 2021-07-12 19:08:42,528 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8060000002151355e-05, 1807
[INFO] 2021-07-12 19:08:42,528 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1807
[INFO] 2021-07-12 19:08:42,528 [run_pretraining.py:  558]:	worker_index: 2, step: 1807, cost: 7.071034, mlm loss: 7.071034, speed: 1.057845 steps/s, speed: 8.462759 samples/s, speed: 4332.932450 tokens/s, learning rate: 1.806e-05, loss_scalings: 5497.559082, pp_loss: 7.376631
[INFO] 2021-07-12 19:08:42,528 [run_pretraining.py:  512]:	********exe.run_1807******* 
[INFO] 2021-07-12 19:08:43,462 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:43,462 [run_pretraining.py:  534]:	loss/total_loss, 7.485393047332764, 1808
[INFO] 2021-07-12 19:08:43,462 [run_pretraining.py:  535]:	loss/mlm_loss, 7.485393047332764, 1808
[INFO] 2021-07-12 19:08:43,462 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.807000080589205e-05, 1808
[INFO] 2021-07-12 19:08:43,462 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1808
[INFO] 2021-07-12 19:08:43,462 [run_pretraining.py:  558]:	worker_index: 2, step: 1808, cost: 7.485393, mlm loss: 7.485393, speed: 1.070783 steps/s, speed: 8.566262 samples/s, speed: 4385.925917 tokens/s, learning rate: 1.807e-05, loss_scalings: 5497.559082, pp_loss: 7.219073
[INFO] 2021-07-12 19:08:43,462 [run_pretraining.py:  512]:	********exe.run_1808******* 
[INFO] 2021-07-12 19:08:44,365 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:44,366 [run_pretraining.py:  534]:	loss/total_loss, 7.149471759796143, 1809
[INFO] 2021-07-12 19:08:44,366 [run_pretraining.py:  535]:	loss/mlm_loss, 7.149471759796143, 1809
[INFO] 2021-07-12 19:08:44,366 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8079999790643342e-05, 1809
[INFO] 2021-07-12 19:08:44,366 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1809
[INFO] 2021-07-12 19:08:44,366 [run_pretraining.py:  558]:	worker_index: 2, step: 1809, cost: 7.149472, mlm loss: 7.149472, speed: 1.107487 steps/s, speed: 8.859892 samples/s, speed: 4536.264831 tokens/s, learning rate: 1.808e-05, loss_scalings: 5497.559082, pp_loss: 7.002495
[INFO] 2021-07-12 19:08:44,366 [run_pretraining.py:  512]:	********exe.run_1809******* 
[INFO] 2021-07-12 19:08:45,283 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:45,283 [run_pretraining.py:  534]:	loss/total_loss, 7.246161460876465, 1810
[INFO] 2021-07-12 19:08:45,284 [run_pretraining.py:  535]:	loss/mlm_loss, 7.246161460876465, 1810
[INFO] 2021-07-12 19:08:45,284 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8089998775394633e-05, 1810
[INFO] 2021-07-12 19:08:45,284 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1810
[INFO] 2021-07-12 19:08:45,284 [run_pretraining.py:  558]:	worker_index: 2, step: 1810, cost: 7.246161, mlm loss: 7.246161, speed: 1.090250 steps/s, speed: 8.721998 samples/s, speed: 4465.662791 tokens/s, learning rate: 1.809e-05, loss_scalings: 5497.559082, pp_loss: 7.329863
[INFO] 2021-07-12 19:08:45,284 [run_pretraining.py:  512]:	********exe.run_1810******* 
[INFO] 2021-07-12 19:08:46,335 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:46,335 [run_pretraining.py:  534]:	loss/total_loss, 7.8624467849731445, 1811
[INFO] 2021-07-12 19:08:46,335 [run_pretraining.py:  535]:	loss/mlm_loss, 7.8624467849731445, 1811
[INFO] 2021-07-12 19:08:46,335 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.809999957913533e-05, 1811
[INFO] 2021-07-12 19:08:46,335 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1811
[INFO] 2021-07-12 19:08:46,335 [run_pretraining.py:  558]:	worker_index: 2, step: 1811, cost: 7.862447, mlm loss: 7.862447, speed: 0.951379 steps/s, speed: 7.611034 samples/s, speed: 3896.849558 tokens/s, learning rate: 1.810e-05, loss_scalings: 5497.559082, pp_loss: 6.984278
[INFO] 2021-07-12 19:08:46,336 [run_pretraining.py:  512]:	********exe.run_1811******* 
[INFO] 2021-07-12 19:08:47,496 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:47,496 [run_pretraining.py:  534]:	loss/total_loss, 7.991790771484375, 1812
[INFO] 2021-07-12 19:08:47,496 [run_pretraining.py:  535]:	loss/mlm_loss, 7.991790771484375, 1812
[INFO] 2021-07-12 19:08:47,496 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.810999856388662e-05, 1812
[INFO] 2021-07-12 19:08:47,496 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1812
[INFO] 2021-07-12 19:08:47,496 [run_pretraining.py:  558]:	worker_index: 2, step: 1812, cost: 7.991791, mlm loss: 7.991791, speed: 0.861787 steps/s, speed: 6.894294 samples/s, speed: 3529.878488 tokens/s, learning rate: 1.811e-05, loss_scalings: 5497.559082, pp_loss: 7.514064
[INFO] 2021-07-12 19:08:47,497 [run_pretraining.py:  512]:	********exe.run_1812******* 
[INFO] 2021-07-12 19:08:48,740 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:48,741 [run_pretraining.py:  534]:	loss/total_loss, 7.450686454772949, 1813
[INFO] 2021-07-12 19:08:48,741 [run_pretraining.py:  535]:	loss/mlm_loss, 7.450686454772949, 1813
[INFO] 2021-07-12 19:08:48,741 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8119999367627315e-05, 1813
[INFO] 2021-07-12 19:08:48,741 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1813
[INFO] 2021-07-12 19:08:48,741 [run_pretraining.py:  558]:	worker_index: 2, step: 1813, cost: 7.450686, mlm loss: 7.450686, speed: 0.803839 steps/s, speed: 6.430712 samples/s, speed: 3292.524472 tokens/s, learning rate: 1.812e-05, loss_scalings: 5497.559082, pp_loss: 7.231676
[INFO] 2021-07-12 19:08:48,741 [run_pretraining.py:  512]:	********exe.run_1813******* 
[INFO] 2021-07-12 19:08:49,962 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:49,962 [run_pretraining.py:  534]:	loss/total_loss, 7.043074131011963, 1814
[INFO] 2021-07-12 19:08:49,963 [run_pretraining.py:  535]:	loss/mlm_loss, 7.043074131011963, 1814
[INFO] 2021-07-12 19:08:49,963 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.813000017136801e-05, 1814
[INFO] 2021-07-12 19:08:49,963 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1814
[INFO] 2021-07-12 19:08:49,963 [run_pretraining.py:  558]:	worker_index: 2, step: 1814, cost: 7.043074, mlm loss: 7.043074, speed: 0.818963 steps/s, speed: 6.551702 samples/s, speed: 3354.471583 tokens/s, learning rate: 1.813e-05, loss_scalings: 5497.559082, pp_loss: 7.194887
[INFO] 2021-07-12 19:08:49,963 [run_pretraining.py:  512]:	********exe.run_1814******* 
[INFO] 2021-07-12 19:08:51,245 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:51,246 [run_pretraining.py:  534]:	loss/total_loss, 6.807464122772217, 1815
[INFO] 2021-07-12 19:08:51,246 [run_pretraining.py:  535]:	loss/mlm_loss, 6.807464122772217, 1815
[INFO] 2021-07-12 19:08:51,246 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8139999156119302e-05, 1815
[INFO] 2021-07-12 19:08:51,246 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1815
[INFO] 2021-07-12 19:08:51,246 [run_pretraining.py:  558]:	worker_index: 2, step: 1815, cost: 6.807464, mlm loss: 6.807464, speed: 0.779717 steps/s, speed: 6.237737 samples/s, speed: 3193.721145 tokens/s, learning rate: 1.814e-05, loss_scalings: 5497.559082, pp_loss: 7.225644
[INFO] 2021-07-12 19:08:51,246 [run_pretraining.py:  512]:	********exe.run_1815******* 
[INFO] 2021-07-12 19:08:52,517 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:52,518 [run_pretraining.py:  534]:	loss/total_loss, 7.428154945373535, 1816
[INFO] 2021-07-12 19:08:52,518 [run_pretraining.py:  535]:	loss/mlm_loss, 7.428154945373535, 1816
[INFO] 2021-07-12 19:08:52,518 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8149999959859997e-05, 1816
[INFO] 2021-07-12 19:08:52,518 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1816
[INFO] 2021-07-12 19:08:52,518 [run_pretraining.py:  558]:	worker_index: 2, step: 1816, cost: 7.428155, mlm loss: 7.428155, speed: 0.786345 steps/s, speed: 6.290762 samples/s, speed: 3220.869968 tokens/s, learning rate: 1.815e-05, loss_scalings: 5497.559082, pp_loss: 7.279061
[INFO] 2021-07-12 19:08:52,518 [run_pretraining.py:  512]:	********exe.run_1816******* 
[INFO] 2021-07-12 19:08:53,820 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:53,820 [run_pretraining.py:  534]:	loss/total_loss, 7.404105186462402, 1817
[INFO] 2021-07-12 19:08:53,820 [run_pretraining.py:  535]:	loss/mlm_loss, 7.404105186462402, 1817
[INFO] 2021-07-12 19:08:53,820 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8160000763600692e-05, 1817
[INFO] 2021-07-12 19:08:53,820 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1817
[INFO] 2021-07-12 19:08:53,820 [run_pretraining.py:  558]:	worker_index: 2, step: 1817, cost: 7.404105, mlm loss: 7.404105, speed: 0.768244 steps/s, speed: 6.145952 samples/s, speed: 3146.727293 tokens/s, learning rate: 1.816e-05, loss_scalings: 5497.559082, pp_loss: 6.632680
[INFO] 2021-07-12 19:08:53,821 [run_pretraining.py:  512]:	********exe.run_1817******* 
[INFO] 2021-07-12 19:08:55,079 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:55,080 [run_pretraining.py:  534]:	loss/total_loss, 7.197098731994629, 1818
[INFO] 2021-07-12 19:08:55,080 [run_pretraining.py:  535]:	loss/mlm_loss, 7.197098731994629, 1818
[INFO] 2021-07-12 19:08:55,080 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8169999748351984e-05, 1818
[INFO] 2021-07-12 19:08:55,080 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1818
[INFO] 2021-07-12 19:08:55,080 [run_pretraining.py:  558]:	worker_index: 2, step: 1818, cost: 7.197099, mlm loss: 7.197099, speed: 0.794398 steps/s, speed: 6.355181 samples/s, speed: 3253.852461 tokens/s, learning rate: 1.817e-05, loss_scalings: 5497.559082, pp_loss: 7.816890
[INFO] 2021-07-12 19:08:55,080 [run_pretraining.py:  512]:	********exe.run_1818******* 
[INFO] 2021-07-12 19:08:56,160 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:56,161 [run_pretraining.py:  534]:	loss/total_loss, 7.389649868011475, 1819
[INFO] 2021-07-12 19:08:56,161 [run_pretraining.py:  535]:	loss/mlm_loss, 7.389649868011475, 1819
[INFO] 2021-07-12 19:08:56,161 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8179998733103275e-05, 1819
[INFO] 2021-07-12 19:08:56,161 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1819
[INFO] 2021-07-12 19:08:56,161 [run_pretraining.py:  558]:	worker_index: 2, step: 1819, cost: 7.389650, mlm loss: 7.389650, speed: 0.925384 steps/s, speed: 7.403075 samples/s, speed: 3790.374622 tokens/s, learning rate: 1.818e-05, loss_scalings: 5497.559082, pp_loss: 7.388574
[INFO] 2021-07-12 19:08:56,161 [run_pretraining.py:  512]:	********exe.run_1819******* 
[INFO] 2021-07-12 19:08:57,220 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:57,221 [run_pretraining.py:  534]:	loss/total_loss, 6.474215507507324, 1820
[INFO] 2021-07-12 19:08:57,221 [run_pretraining.py:  535]:	loss/mlm_loss, 6.474215507507324, 1820
[INFO] 2021-07-12 19:08:57,221 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.818999953684397e-05, 1820
[INFO] 2021-07-12 19:08:57,221 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1820
[INFO] 2021-07-12 19:08:57,221 [run_pretraining.py:  558]:	worker_index: 2, step: 1820, cost: 6.474216, mlm loss: 6.474216, speed: 0.944134 steps/s, speed: 7.553070 samples/s, speed: 3867.172025 tokens/s, learning rate: 1.819e-05, loss_scalings: 5497.559082, pp_loss: 6.939384
[INFO] 2021-07-12 19:08:57,221 [run_pretraining.py:  512]:	********exe.run_1820******* 
[INFO] 2021-07-12 19:08:58,277 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:58,277 [run_pretraining.py:  534]:	loss/total_loss, 6.968331336975098, 1821
[INFO] 2021-07-12 19:08:58,277 [run_pretraining.py:  535]:	loss/mlm_loss, 6.968331336975098, 1821
[INFO] 2021-07-12 19:08:58,277 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8199998521595262e-05, 1821
[INFO] 2021-07-12 19:08:58,277 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1821
[INFO] 2021-07-12 19:08:58,277 [run_pretraining.py:  558]:	worker_index: 2, step: 1821, cost: 6.968331, mlm loss: 6.968331, speed: 0.947080 steps/s, speed: 7.576644 samples/s, speed: 3879.241583 tokens/s, learning rate: 1.820e-05, loss_scalings: 5497.559082, pp_loss: 7.221161
[INFO] 2021-07-12 19:08:58,277 [run_pretraining.py:  512]:	********exe.run_1821******* 
[INFO] 2021-07-12 19:08:59,341 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:59,342 [run_pretraining.py:  534]:	loss/total_loss, 8.65577507019043, 1822
[INFO] 2021-07-12 19:08:59,342 [run_pretraining.py:  535]:	loss/mlm_loss, 8.65577507019043, 1822
[INFO] 2021-07-12 19:08:59,342 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8209999325335957e-05, 1822
[INFO] 2021-07-12 19:08:59,342 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1822
[INFO] 2021-07-12 19:08:59,342 [run_pretraining.py:  558]:	worker_index: 2, step: 1822, cost: 8.655775, mlm loss: 8.655775, speed: 0.939819 steps/s, speed: 7.518548 samples/s, speed: 3849.496791 tokens/s, learning rate: 1.821e-05, loss_scalings: 5497.559082, pp_loss: 7.485997
[INFO] 2021-07-12 19:08:59,342 [run_pretraining.py:  512]:	********exe.run_1822******* 
[INFO] 2021-07-12 19:09:00,446 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:00,446 [run_pretraining.py:  534]:	loss/total_loss, 6.260463237762451, 1823
[INFO] 2021-07-12 19:09:00,447 [run_pretraining.py:  535]:	loss/mlm_loss, 6.260463237762451, 1823
[INFO] 2021-07-12 19:09:00,447 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8220000129076652e-05, 1823
[INFO] 2021-07-12 19:09:00,447 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1823
[INFO] 2021-07-12 19:09:00,447 [run_pretraining.py:  558]:	worker_index: 2, step: 1823, cost: 6.260463, mlm loss: 6.260463, speed: 0.905683 steps/s, speed: 7.245466 samples/s, speed: 3709.678358 tokens/s, learning rate: 1.822e-05, loss_scalings: 5497.559082, pp_loss: 7.274440
[INFO] 2021-07-12 19:09:00,447 [run_pretraining.py:  512]:	********exe.run_1823******* 
[INFO] 2021-07-12 19:09:01,512 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:01,513 [run_pretraining.py:  534]:	loss/total_loss, 7.450150489807129, 1824
[INFO] 2021-07-12 19:09:01,513 [run_pretraining.py:  535]:	loss/mlm_loss, 7.450150489807129, 1824
[INFO] 2021-07-12 19:09:01,513 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8229999113827944e-05, 1824
[INFO] 2021-07-12 19:09:01,513 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1824
[INFO] 2021-07-12 19:09:01,513 [run_pretraining.py:  558]:	worker_index: 2, step: 1824, cost: 7.450150, mlm loss: 7.450150, speed: 0.938474 steps/s, speed: 7.507790 samples/s, speed: 3843.988628 tokens/s, learning rate: 1.823e-05, loss_scalings: 5497.559082, pp_loss: 7.468203
[INFO] 2021-07-12 19:09:01,513 [run_pretraining.py:  512]:	********exe.run_1824******* 
[INFO] 2021-07-12 19:09:02,571 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:02,571 [run_pretraining.py:  534]:	loss/total_loss, 7.380402565002441, 1825
[INFO] 2021-07-12 19:09:02,572 [run_pretraining.py:  535]:	loss/mlm_loss, 7.380402565002441, 1825
[INFO] 2021-07-12 19:09:02,572 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.823999991756864e-05, 1825
[INFO] 2021-07-12 19:09:02,572 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1825
[INFO] 2021-07-12 19:09:02,572 [run_pretraining.py:  558]:	worker_index: 2, step: 1825, cost: 7.380403, mlm loss: 7.380403, speed: 0.945035 steps/s, speed: 7.560281 samples/s, speed: 3870.863841 tokens/s, learning rate: 1.824e-05, loss_scalings: 5497.559082, pp_loss: 7.474987
[INFO] 2021-07-12 19:09:02,572 [run_pretraining.py:  512]:	********exe.run_1825******* 
[INFO] 2021-07-12 19:09:03,729 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:03,729 [run_pretraining.py:  534]:	loss/total_loss, 6.873380184173584, 1826
[INFO] 2021-07-12 19:09:03,730 [run_pretraining.py:  535]:	loss/mlm_loss, 6.873380184173584, 1826
[INFO] 2021-07-12 19:09:03,730 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8250000721309334e-05, 1826
[INFO] 2021-07-12 19:09:03,730 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1826
[INFO] 2021-07-12 19:09:03,730 [run_pretraining.py:  558]:	worker_index: 2, step: 1826, cost: 6.873380, mlm loss: 6.873380, speed: 0.863954 steps/s, speed: 6.911631 samples/s, speed: 3538.754848 tokens/s, learning rate: 1.825e-05, loss_scalings: 5497.559082, pp_loss: 7.104056
[INFO] 2021-07-12 19:09:03,730 [run_pretraining.py:  512]:	********exe.run_1826******* 
[INFO] 2021-07-12 19:09:04,836 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:04,837 [run_pretraining.py:  534]:	loss/total_loss, 8.173487663269043, 1827
[INFO] 2021-07-12 19:09:04,837 [run_pretraining.py:  535]:	loss/mlm_loss, 8.173487663269043, 1827
[INFO] 2021-07-12 19:09:04,837 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8259999706060626e-05, 1827
[INFO] 2021-07-12 19:09:04,837 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1827
[INFO] 2021-07-12 19:09:04,837 [run_pretraining.py:  558]:	worker_index: 2, step: 1827, cost: 8.173488, mlm loss: 8.173488, speed: 0.903478 steps/s, speed: 7.227822 samples/s, speed: 3700.644685 tokens/s, learning rate: 1.826e-05, loss_scalings: 5497.559082, pp_loss: 7.391116
[INFO] 2021-07-12 19:09:04,837 [run_pretraining.py:  512]:	********exe.run_1827******* 
[INFO] 2021-07-12 19:09:05,933 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:05,934 [run_pretraining.py:  534]:	loss/total_loss, 8.175592422485352, 1828
[INFO] 2021-07-12 19:09:05,934 [run_pretraining.py:  535]:	loss/mlm_loss, 8.175592422485352, 1828
[INFO] 2021-07-12 19:09:05,934 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8269998690811917e-05, 1828
[INFO] 2021-07-12 19:09:05,934 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1828
[INFO] 2021-07-12 19:09:05,934 [run_pretraining.py:  558]:	worker_index: 2, step: 1828, cost: 8.175592, mlm loss: 8.175592, speed: 0.912382 steps/s, speed: 7.299053 samples/s, speed: 3737.115052 tokens/s, learning rate: 1.827e-05, loss_scalings: 5497.559082, pp_loss: 7.546870
[INFO] 2021-07-12 19:09:05,934 [run_pretraining.py:  512]:	********exe.run_1828******* 
[INFO] 2021-07-12 19:09:07,033 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:07,033 [run_pretraining.py:  534]:	loss/total_loss, 7.382885932922363, 1829
[INFO] 2021-07-12 19:09:07,033 [run_pretraining.py:  535]:	loss/mlm_loss, 7.382885932922363, 1829
[INFO] 2021-07-12 19:09:07,033 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8279999494552612e-05, 1829
[INFO] 2021-07-12 19:09:07,034 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1829
[INFO] 2021-07-12 19:09:07,034 [run_pretraining.py:  558]:	worker_index: 2, step: 1829, cost: 7.382886, mlm loss: 7.382886, speed: 0.909887 steps/s, speed: 7.279099 samples/s, speed: 3726.898517 tokens/s, learning rate: 1.828e-05, loss_scalings: 5497.559082, pp_loss: 7.442510
[INFO] 2021-07-12 19:09:07,034 [run_pretraining.py:  512]:	********exe.run_1829******* 
[INFO] 2021-07-12 19:09:08,133 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:08,133 [run_pretraining.py:  534]:	loss/total_loss, 7.433923721313477, 1830
[INFO] 2021-07-12 19:09:08,133 [run_pretraining.py:  535]:	loss/mlm_loss, 7.433923721313477, 1830
[INFO] 2021-07-12 19:09:08,134 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8289998479303904e-05, 1830
[INFO] 2021-07-12 19:09:08,134 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1830
[INFO] 2021-07-12 19:09:08,134 [run_pretraining.py:  558]:	worker_index: 2, step: 1830, cost: 7.433924, mlm loss: 7.433924, speed: 0.909473 steps/s, speed: 7.275787 samples/s, speed: 3725.203074 tokens/s, learning rate: 1.829e-05, loss_scalings: 5497.559082, pp_loss: 7.416199
[INFO] 2021-07-12 19:09:08,134 [run_pretraining.py:  512]:	********exe.run_1830******* 
[INFO] 2021-07-12 19:09:09,232 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:09,232 [run_pretraining.py:  534]:	loss/total_loss, 7.095967769622803, 1831
[INFO] 2021-07-12 19:09:09,233 [run_pretraining.py:  535]:	loss/mlm_loss, 7.095967769622803, 1831
[INFO] 2021-07-12 19:09:09,233 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.82999992830446e-05, 1831
[INFO] 2021-07-12 19:09:09,233 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1831
[INFO] 2021-07-12 19:09:09,233 [run_pretraining.py:  558]:	worker_index: 2, step: 1831, cost: 7.095968, mlm loss: 7.095968, speed: 0.910327 steps/s, speed: 7.282614 samples/s, speed: 3728.698278 tokens/s, learning rate: 1.830e-05, loss_scalings: 5497.559082, pp_loss: 6.896434
[INFO] 2021-07-12 19:09:09,233 [run_pretraining.py:  512]:	********exe.run_1831******* 
[INFO] 2021-07-12 19:09:10,319 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:10,319 [run_pretraining.py:  534]:	loss/total_loss, 7.768481254577637, 1832
[INFO] 2021-07-12 19:09:10,319 [run_pretraining.py:  535]:	loss/mlm_loss, 7.768481254577637, 1832
[INFO] 2021-07-12 19:09:10,319 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8310000086785294e-05, 1832
[INFO] 2021-07-12 19:09:10,319 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1832
[INFO] 2021-07-12 19:09:10,320 [run_pretraining.py:  558]:	worker_index: 2, step: 1832, cost: 7.768481, mlm loss: 7.768481, speed: 0.920758 steps/s, speed: 7.366061 samples/s, speed: 3771.423061 tokens/s, learning rate: 1.831e-05, loss_scalings: 5497.559082, pp_loss: 7.276482
[INFO] 2021-07-12 19:09:10,320 [run_pretraining.py:  512]:	********exe.run_1832******* 
[INFO] 2021-07-12 19:09:11,419 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:11,419 [run_pretraining.py:  534]:	loss/total_loss, 7.557160377502441, 1833
[INFO] 2021-07-12 19:09:11,419 [run_pretraining.py:  535]:	loss/mlm_loss, 7.557160377502441, 1833
[INFO] 2021-07-12 19:09:11,419 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8319999071536586e-05, 1833
[INFO] 2021-07-12 19:09:11,419 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1833
[INFO] 2021-07-12 19:09:11,420 [run_pretraining.py:  558]:	worker_index: 2, step: 1833, cost: 7.557160, mlm loss: 7.557160, speed: 0.909599 steps/s, speed: 7.276789 samples/s, speed: 3725.716069 tokens/s, learning rate: 1.832e-05, loss_scalings: 5497.559082, pp_loss: 8.087691
[INFO] 2021-07-12 19:09:11,420 [run_pretraining.py:  512]:	********exe.run_1833******* 
[INFO] 2021-07-12 19:09:12,515 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:12,516 [run_pretraining.py:  534]:	loss/total_loss, 7.58760929107666, 1834
[INFO] 2021-07-12 19:09:12,516 [run_pretraining.py:  535]:	loss/mlm_loss, 7.58760929107666, 1834
[INFO] 2021-07-12 19:09:12,516 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.832999987527728e-05, 1834
[INFO] 2021-07-12 19:09:12,516 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1834
[INFO] 2021-07-12 19:09:12,516 [run_pretraining.py:  558]:	worker_index: 2, step: 1834, cost: 7.587609, mlm loss: 7.587609, speed: 0.912469 steps/s, speed: 7.299755 samples/s, speed: 3737.474402 tokens/s, learning rate: 1.833e-05, loss_scalings: 5497.559082, pp_loss: 7.407622
[INFO] 2021-07-12 19:09:12,516 [run_pretraining.py:  512]:	********exe.run_1834******* 
[INFO] 2021-07-12 19:09:13,609 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:13,609 [run_pretraining.py:  534]:	loss/total_loss, 7.563594818115234, 1835
[INFO] 2021-07-12 19:09:13,610 [run_pretraining.py:  535]:	loss/mlm_loss, 7.563594818115234, 1835
[INFO] 2021-07-12 19:09:13,610 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8340000679017976e-05, 1835
[INFO] 2021-07-12 19:09:13,610 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1835
[INFO] 2021-07-12 19:09:13,610 [run_pretraining.py:  558]:	worker_index: 2, step: 1835, cost: 7.563595, mlm loss: 7.563595, speed: 0.914754 steps/s, speed: 7.318034 samples/s, speed: 3746.833636 tokens/s, learning rate: 1.834e-05, loss_scalings: 5497.559082, pp_loss: 7.484216
[INFO] 2021-07-12 19:09:13,610 [run_pretraining.py:  512]:	********exe.run_1835******* 
[INFO] 2021-07-12 19:09:14,700 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:14,700 [run_pretraining.py:  534]:	loss/total_loss, 7.278034687042236, 1836
[INFO] 2021-07-12 19:09:14,700 [run_pretraining.py:  535]:	loss/mlm_loss, 7.278034687042236, 1836
[INFO] 2021-07-12 19:09:14,700 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8349999663769267e-05, 1836
[INFO] 2021-07-12 19:09:14,700 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1836
[INFO] 2021-07-12 19:09:14,700 [run_pretraining.py:  558]:	worker_index: 2, step: 1836, cost: 7.278035, mlm loss: 7.278035, speed: 0.917512 steps/s, speed: 7.340099 samples/s, speed: 3758.130559 tokens/s, learning rate: 1.835e-05, loss_scalings: 5497.559082, pp_loss: 7.256018
[INFO] 2021-07-12 19:09:14,700 [run_pretraining.py:  512]:	********exe.run_1836******* 
[INFO] 2021-07-12 19:09:15,794 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:15,794 [run_pretraining.py:  534]:	loss/total_loss, 7.163202285766602, 1837
[INFO] 2021-07-12 19:09:15,795 [run_pretraining.py:  535]:	loss/mlm_loss, 7.163202285766602, 1837
[INFO] 2021-07-12 19:09:15,795 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.835999864852056e-05, 1837
[INFO] 2021-07-12 19:09:15,795 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1837
[INFO] 2021-07-12 19:09:15,795 [run_pretraining.py:  558]:	worker_index: 2, step: 1837, cost: 7.163202, mlm loss: 7.163202, speed: 0.914237 steps/s, speed: 7.313900 samples/s, speed: 3744.716745 tokens/s, learning rate: 1.836e-05, loss_scalings: 5497.559082, pp_loss: 7.300353
[INFO] 2021-07-12 19:09:15,795 [run_pretraining.py:  512]:	********exe.run_1837******* 
[INFO] 2021-07-12 19:09:16,887 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:16,888 [run_pretraining.py:  534]:	loss/total_loss, 7.073678970336914, 1838
[INFO] 2021-07-12 19:09:16,888 [run_pretraining.py:  535]:	loss/mlm_loss, 7.073678970336914, 1838
[INFO] 2021-07-12 19:09:16,888 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8369999452261254e-05, 1838
[INFO] 2021-07-12 19:09:16,888 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1838
[INFO] 2021-07-12 19:09:16,888 [run_pretraining.py:  558]:	worker_index: 2, step: 1838, cost: 7.073679, mlm loss: 7.073679, speed: 0.915088 steps/s, speed: 7.320707 samples/s, speed: 3748.202068 tokens/s, learning rate: 1.837e-05, loss_scalings: 5497.559082, pp_loss: 6.704659
[INFO] 2021-07-12 19:09:16,888 [run_pretraining.py:  512]:	********exe.run_1838******* 
[INFO] 2021-07-12 19:09:17,984 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:17,985 [run_pretraining.py:  534]:	loss/total_loss, 8.057892799377441, 1839
[INFO] 2021-07-12 19:09:17,985 [run_pretraining.py:  535]:	loss/mlm_loss, 8.057892799377441, 1839
[INFO] 2021-07-12 19:09:17,985 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8379998437012546e-05, 1839
[INFO] 2021-07-12 19:09:17,985 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1839
[INFO] 2021-07-12 19:09:17,985 [run_pretraining.py:  558]:	worker_index: 2, step: 1839, cost: 8.057893, mlm loss: 8.057893, speed: 0.912203 steps/s, speed: 7.297623 samples/s, speed: 3736.382746 tokens/s, learning rate: 1.838e-05, loss_scalings: 5497.559082, pp_loss: 7.515264
[INFO] 2021-07-12 19:09:17,985 [run_pretraining.py:  512]:	********exe.run_1839******* 
[INFO] 2021-07-12 19:09:19,072 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:19,072 [run_pretraining.py:  534]:	loss/total_loss, 8.441804885864258, 1840
[INFO] 2021-07-12 19:09:19,072 [run_pretraining.py:  535]:	loss/mlm_loss, 8.441804885864258, 1840
[INFO] 2021-07-12 19:09:19,073 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.838999924075324e-05, 1840
[INFO] 2021-07-12 19:09:19,073 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1840
[INFO] 2021-07-12 19:09:19,073 [run_pretraining.py:  558]:	worker_index: 2, step: 1840, cost: 8.441805, mlm loss: 8.441805, speed: 0.919885 steps/s, speed: 7.359080 samples/s, speed: 3767.848990 tokens/s, learning rate: 1.839e-05, loss_scalings: 5497.559082, pp_loss: 7.686498
[INFO] 2021-07-12 19:09:19,073 [run_pretraining.py:  512]:	********exe.run_1840******* 
[INFO] 2021-07-12 19:09:20,162 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:20,163 [run_pretraining.py:  534]:	loss/total_loss, 7.417303085327148, 1841
[INFO] 2021-07-12 19:09:20,163 [run_pretraining.py:  535]:	loss/mlm_loss, 7.417303085327148, 1841
[INFO] 2021-07-12 19:09:20,163 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8400000044493936e-05, 1841
[INFO] 2021-07-12 19:09:20,163 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1841
[INFO] 2021-07-12 19:09:20,163 [run_pretraining.py:  558]:	worker_index: 2, step: 1841, cost: 7.417303, mlm loss: 7.417303, speed: 0.917539 steps/s, speed: 7.340311 samples/s, speed: 3758.239080 tokens/s, learning rate: 1.840e-05, loss_scalings: 5497.559082, pp_loss: 7.088288
[INFO] 2021-07-12 19:09:20,163 [run_pretraining.py:  512]:	********exe.run_1841******* 
[INFO] 2021-07-12 19:09:21,262 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:21,263 [run_pretraining.py:  534]:	loss/total_loss, 6.898684501647949, 1842
[INFO] 2021-07-12 19:09:21,263 [run_pretraining.py:  535]:	loss/mlm_loss, 6.898684501647949, 1842
[INFO] 2021-07-12 19:09:21,263 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8409999029245228e-05, 1842
[INFO] 2021-07-12 19:09:21,263 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1842
[INFO] 2021-07-12 19:09:21,263 [run_pretraining.py:  558]:	worker_index: 2, step: 1842, cost: 6.898685, mlm loss: 6.898685, speed: 0.909692 steps/s, speed: 7.277539 samples/s, speed: 3726.099898 tokens/s, learning rate: 1.841e-05, loss_scalings: 5497.559082, pp_loss: 7.201051
[INFO] 2021-07-12 19:09:21,263 [run_pretraining.py:  512]:	********exe.run_1842******* 
[INFO] 2021-07-12 19:09:22,411 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:22,412 [run_pretraining.py:  534]:	loss/total_loss, 6.811662673950195, 1843
[INFO] 2021-07-12 19:09:22,412 [run_pretraining.py:  535]:	loss/mlm_loss, 6.811662673950195, 1843
[INFO] 2021-07-12 19:09:22,412 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8419999832985923e-05, 1843
[INFO] 2021-07-12 19:09:22,412 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1843
[INFO] 2021-07-12 19:09:22,412 [run_pretraining.py:  558]:	worker_index: 2, step: 1843, cost: 6.811663, mlm loss: 6.811663, speed: 0.870662 steps/s, speed: 6.965300 samples/s, speed: 3566.233363 tokens/s, learning rate: 1.842e-05, loss_scalings: 5497.559082, pp_loss: 7.411611
[INFO] 2021-07-12 19:09:22,412 [run_pretraining.py:  512]:	********exe.run_1843******* 
[INFO] 2021-07-12 19:09:23,510 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:23,510 [run_pretraining.py:  534]:	loss/total_loss, 8.547008514404297, 1844
[INFO] 2021-07-12 19:09:23,510 [run_pretraining.py:  535]:	loss/mlm_loss, 8.547008514404297, 1844
[INFO] 2021-07-12 19:09:23,510 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8430000636726618e-05, 1844
[INFO] 2021-07-12 19:09:23,511 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1844
[INFO] 2021-07-12 19:09:23,511 [run_pretraining.py:  558]:	worker_index: 2, step: 1844, cost: 8.547009, mlm loss: 8.547009, speed: 0.910889 steps/s, speed: 7.287109 samples/s, speed: 3730.999649 tokens/s, learning rate: 1.843e-05, loss_scalings: 5497.559082, pp_loss: 7.627015
[INFO] 2021-07-12 19:09:23,511 [run_pretraining.py:  512]:	********exe.run_1844******* 
[INFO] 2021-07-12 19:09:24,690 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:24,690 [run_pretraining.py:  534]:	loss/total_loss, 6.840657711029053, 1845
[INFO] 2021-07-12 19:09:24,690 [run_pretraining.py:  535]:	loss/mlm_loss, 6.840657711029053, 1845
[INFO] 2021-07-12 19:09:24,690 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.843999962147791e-05, 1845
[INFO] 2021-07-12 19:09:24,690 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1845
[INFO] 2021-07-12 19:09:24,690 [run_pretraining.py:  558]:	worker_index: 2, step: 1845, cost: 6.840658, mlm loss: 6.840658, speed: 0.848039 steps/s, speed: 6.784316 samples/s, speed: 3473.569671 tokens/s, learning rate: 1.844e-05, loss_scalings: 5497.559082, pp_loss: 7.115693
[INFO] 2021-07-12 19:09:24,691 [run_pretraining.py:  512]:	********exe.run_1845******* 
[INFO] 2021-07-12 19:09:25,760 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:25,760 [run_pretraining.py:  534]:	loss/total_loss, 7.782135009765625, 1846
[INFO] 2021-07-12 19:09:25,761 [run_pretraining.py:  535]:	loss/mlm_loss, 7.782135009765625, 1846
[INFO] 2021-07-12 19:09:25,761 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.84499986062292e-05, 1846
[INFO] 2021-07-12 19:09:25,761 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1846
[INFO] 2021-07-12 19:09:25,761 [run_pretraining.py:  558]:	worker_index: 2, step: 1846, cost: 7.782135, mlm loss: 7.782135, speed: 0.934766 steps/s, speed: 7.478127 samples/s, speed: 3828.801180 tokens/s, learning rate: 1.845e-05, loss_scalings: 5497.559082, pp_loss: 7.340772
[INFO] 2021-07-12 19:09:25,761 [run_pretraining.py:  512]:	********exe.run_1846******* 
[INFO] 2021-07-12 19:09:26,817 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:26,818 [run_pretraining.py:  534]:	loss/total_loss, 7.316178798675537, 1847
[INFO] 2021-07-12 19:09:26,818 [run_pretraining.py:  535]:	loss/mlm_loss, 7.316178798675537, 1847
[INFO] 2021-07-12 19:09:26,818 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8459999409969896e-05, 1847
[INFO] 2021-07-12 19:09:26,818 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1847
[INFO] 2021-07-12 19:09:26,818 [run_pretraining.py:  558]:	worker_index: 2, step: 1847, cost: 7.316179, mlm loss: 7.316179, speed: 0.946533 steps/s, speed: 7.572261 samples/s, speed: 3876.997850 tokens/s, learning rate: 1.846e-05, loss_scalings: 5497.559082, pp_loss: 7.295328
[INFO] 2021-07-12 19:09:26,818 [run_pretraining.py:  512]:	********exe.run_1847******* 
[INFO] 2021-07-12 19:09:27,879 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:27,879 [run_pretraining.py:  534]:	loss/total_loss, 7.220634937286377, 1848
[INFO] 2021-07-12 19:09:27,879 [run_pretraining.py:  535]:	loss/mlm_loss, 7.220634937286377, 1848
[INFO] 2021-07-12 19:09:27,879 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8469998394721188e-05, 1848
[INFO] 2021-07-12 19:09:27,879 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1848
[INFO] 2021-07-12 19:09:27,880 [run_pretraining.py:  558]:	worker_index: 2, step: 1848, cost: 7.220635, mlm loss: 7.220635, speed: 0.942483 steps/s, speed: 7.539861 samples/s, speed: 3860.408798 tokens/s, learning rate: 1.847e-05, loss_scalings: 5497.559082, pp_loss: 6.703133
[INFO] 2021-07-12 19:09:27,880 [run_pretraining.py:  512]:	********exe.run_1848******* 
[INFO] 2021-07-12 19:09:28,938 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:28,939 [run_pretraining.py:  534]:	loss/total_loss, 7.29315185546875, 1849
[INFO] 2021-07-12 19:09:28,939 [run_pretraining.py:  535]:	loss/mlm_loss, 7.29315185546875, 1849
[INFO] 2021-07-12 19:09:28,939 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8479999198461883e-05, 1849
[INFO] 2021-07-12 19:09:28,939 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1849
[INFO] 2021-07-12 19:09:28,939 [run_pretraining.py:  558]:	worker_index: 2, step: 1849, cost: 7.293152, mlm loss: 7.293152, speed: 0.944137 steps/s, speed: 7.553096 samples/s, speed: 3867.185083 tokens/s, learning rate: 1.848e-05, loss_scalings: 5497.559082, pp_loss: 7.063095
[INFO] 2021-07-12 19:09:28,939 [run_pretraining.py:  512]:	********exe.run_1849******* 
[INFO] 2021-07-12 19:09:29,998 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:29,998 [run_pretraining.py:  534]:	loss/total_loss, 7.308585166931152, 1850
[INFO] 2021-07-12 19:09:29,998 [run_pretraining.py:  535]:	loss/mlm_loss, 7.308585166931152, 1850
[INFO] 2021-07-12 19:09:29,998 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8490000002202578e-05, 1850
[INFO] 2021-07-12 19:09:29,998 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1850
[INFO] 2021-07-12 19:09:29,999 [run_pretraining.py:  558]:	worker_index: 2, step: 1850, cost: 7.308585, mlm loss: 7.308585, speed: 0.944690 steps/s, speed: 7.557519 samples/s, speed: 3869.449715 tokens/s, learning rate: 1.849e-05, loss_scalings: 5497.559082, pp_loss: 7.089147
[INFO] 2021-07-12 19:09:29,999 [run_pretraining.py:  512]:	********exe.run_1850******* 
[INFO] 2021-07-12 19:09:31,186 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:31,187 [run_pretraining.py:  534]:	loss/total_loss, 7.162593364715576, 1851
[INFO] 2021-07-12 19:09:31,187 [run_pretraining.py:  535]:	loss/mlm_loss, 7.162593364715576, 1851
[INFO] 2021-07-12 19:09:31,187 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.849999898695387e-05, 1851
[INFO] 2021-07-12 19:09:31,187 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1851
[INFO] 2021-07-12 19:09:31,187 [run_pretraining.py:  558]:	worker_index: 2, step: 1851, cost: 7.162593, mlm loss: 7.162593, speed: 0.841620 steps/s, speed: 6.732960 samples/s, speed: 3447.275384 tokens/s, learning rate: 1.850e-05, loss_scalings: 5497.559082, pp_loss: 7.222184
[INFO] 2021-07-12 19:09:31,187 [run_pretraining.py:  512]:	********exe.run_1851******* 
[INFO] 2021-07-12 19:09:32,345 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:32,346 [run_pretraining.py:  534]:	loss/total_loss, 7.307925224304199, 1852
[INFO] 2021-07-12 19:09:32,346 [run_pretraining.py:  535]:	loss/mlm_loss, 7.307925224304199, 1852
[INFO] 2021-07-12 19:09:32,346 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8509999790694565e-05, 1852
[INFO] 2021-07-12 19:09:32,346 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1852
[INFO] 2021-07-12 19:09:32,346 [run_pretraining.py:  558]:	worker_index: 2, step: 1852, cost: 7.307925, mlm loss: 7.307925, speed: 0.863396 steps/s, speed: 6.907172 samples/s, speed: 3536.471880 tokens/s, learning rate: 1.851e-05, loss_scalings: 5497.559082, pp_loss: 7.331565
[INFO] 2021-07-12 19:09:32,346 [run_pretraining.py:  512]:	********exe.run_1852******* 
[INFO] 2021-07-12 19:09:33,527 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:33,527 [run_pretraining.py:  534]:	loss/total_loss, 6.782212257385254, 1853
[INFO] 2021-07-12 19:09:33,527 [run_pretraining.py:  535]:	loss/mlm_loss, 6.782212257385254, 1853
[INFO] 2021-07-12 19:09:33,527 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.852000059443526e-05, 1853
[INFO] 2021-07-12 19:09:33,527 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1853
[INFO] 2021-07-12 19:09:33,528 [run_pretraining.py:  558]:	worker_index: 2, step: 1853, cost: 6.782212, mlm loss: 6.782212, speed: 0.846898 steps/s, speed: 6.775180 samples/s, speed: 3468.892237 tokens/s, learning rate: 1.852e-05, loss_scalings: 5497.559082, pp_loss: 7.039121
[INFO] 2021-07-12 19:09:33,528 [run_pretraining.py:  512]:	********exe.run_1853******* 
[INFO] 2021-07-12 19:09:34,713 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:34,714 [run_pretraining.py:  534]:	loss/total_loss, 7.858264923095703, 1854
[INFO] 2021-07-12 19:09:34,714 [run_pretraining.py:  535]:	loss/mlm_loss, 7.858264923095703, 1854
[INFO] 2021-07-12 19:09:34,714 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.852999957918655e-05, 1854
[INFO] 2021-07-12 19:09:34,714 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1854
[INFO] 2021-07-12 19:09:34,714 [run_pretraining.py:  558]:	worker_index: 2, step: 1854, cost: 7.858265, mlm loss: 7.858265, speed: 0.843149 steps/s, speed: 6.745188 samples/s, speed: 3453.536451 tokens/s, learning rate: 1.853e-05, loss_scalings: 5497.559082, pp_loss: 7.309239
[INFO] 2021-07-12 19:09:34,714 [run_pretraining.py:  512]:	********exe.run_1854******* 
[INFO] 2021-07-12 19:09:35,994 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:35,995 [run_pretraining.py:  534]:	loss/total_loss, 7.90499210357666, 1855
[INFO] 2021-07-12 19:09:35,995 [run_pretraining.py:  535]:	loss/mlm_loss, 7.90499210357666, 1855
[INFO] 2021-07-12 19:09:35,995 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8539998563937843e-05, 1855
[INFO] 2021-07-12 19:09:35,995 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1855
[INFO] 2021-07-12 19:09:35,995 [run_pretraining.py:  558]:	worker_index: 2, step: 1855, cost: 7.904992, mlm loss: 7.904992, speed: 0.780925 steps/s, speed: 6.247401 samples/s, speed: 3198.669058 tokens/s, learning rate: 1.854e-05, loss_scalings: 5497.559082, pp_loss: 7.876965
[INFO] 2021-07-12 19:09:35,995 [run_pretraining.py:  512]:	********exe.run_1855******* 
[INFO] 2021-07-12 19:09:37,169 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:37,170 [run_pretraining.py:  534]:	loss/total_loss, 7.509567737579346, 1856
[INFO] 2021-07-12 19:09:37,170 [run_pretraining.py:  535]:	loss/mlm_loss, 7.509567737579346, 1856
[INFO] 2021-07-12 19:09:37,170 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8549999367678538e-05, 1856
[INFO] 2021-07-12 19:09:37,170 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1856
[INFO] 2021-07-12 19:09:37,170 [run_pretraining.py:  558]:	worker_index: 2, step: 1856, cost: 7.509568, mlm loss: 7.509568, speed: 0.851820 steps/s, speed: 6.814559 samples/s, speed: 3489.054214 tokens/s, learning rate: 1.855e-05, loss_scalings: 5497.559082, pp_loss: 7.004856
[INFO] 2021-07-12 19:09:37,170 [run_pretraining.py:  512]:	********exe.run_1856******* 
[INFO] 2021-07-12 19:09:38,304 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:38,304 [run_pretraining.py:  534]:	loss/total_loss, 7.305620193481445, 1857
[INFO] 2021-07-12 19:09:38,304 [run_pretraining.py:  535]:	loss/mlm_loss, 7.305620193481445, 1857
[INFO] 2021-07-12 19:09:38,304 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8560000171419233e-05, 1857
[INFO] 2021-07-12 19:09:38,304 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1857
[INFO] 2021-07-12 19:09:38,304 [run_pretraining.py:  558]:	worker_index: 2, step: 1857, cost: 7.305620, mlm loss: 7.305620, speed: 0.881900 steps/s, speed: 7.055203 samples/s, speed: 3612.263873 tokens/s, learning rate: 1.856e-05, loss_scalings: 5497.559082, pp_loss: 7.223370
[INFO] 2021-07-12 19:09:38,305 [run_pretraining.py:  512]:	********exe.run_1857******* 
[INFO] 2021-07-12 19:09:39,459 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:39,459 [run_pretraining.py:  534]:	loss/total_loss, 7.075374603271484, 1858
[INFO] 2021-07-12 19:09:39,460 [run_pretraining.py:  535]:	loss/mlm_loss, 7.075374603271484, 1858
[INFO] 2021-07-12 19:09:39,460 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8569999156170525e-05, 1858
[INFO] 2021-07-12 19:09:39,460 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1858
[INFO] 2021-07-12 19:09:39,460 [run_pretraining.py:  558]:	worker_index: 2, step: 1858, cost: 7.075375, mlm loss: 7.075375, speed: 0.866017 steps/s, speed: 6.928138 samples/s, speed: 3547.206426 tokens/s, learning rate: 1.857e-05, loss_scalings: 5497.559082, pp_loss: 7.164024
[INFO] 2021-07-12 19:09:39,460 [run_pretraining.py:  512]:	********exe.run_1858******* 
[INFO] 2021-07-12 19:09:40,581 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:40,582 [run_pretraining.py:  534]:	loss/total_loss, 7.584924221038818, 1859
[INFO] 2021-07-12 19:09:40,582 [run_pretraining.py:  535]:	loss/mlm_loss, 7.584924221038818, 1859
[INFO] 2021-07-12 19:09:40,582 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.857999995991122e-05, 1859
[INFO] 2021-07-12 19:09:40,582 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1859
[INFO] 2021-07-12 19:09:40,582 [run_pretraining.py:  558]:	worker_index: 2, step: 1859, cost: 7.584924, mlm loss: 7.584924, speed: 0.891425 steps/s, speed: 7.131401 samples/s, speed: 3651.277241 tokens/s, learning rate: 1.858e-05, loss_scalings: 5497.559082, pp_loss: 7.165354
[INFO] 2021-07-12 19:09:40,582 [run_pretraining.py:  512]:	********exe.run_1859******* 
[INFO] 2021-07-12 19:09:41,638 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:41,639 [run_pretraining.py:  534]:	loss/total_loss, 6.818968772888184, 1860
[INFO] 2021-07-12 19:09:41,639 [run_pretraining.py:  535]:	loss/mlm_loss, 6.818968772888184, 1860
[INFO] 2021-07-12 19:09:41,639 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.858999894466251e-05, 1860
[INFO] 2021-07-12 19:09:41,639 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1860
[INFO] 2021-07-12 19:09:41,639 [run_pretraining.py:  558]:	worker_index: 2, step: 1860, cost: 6.818969, mlm loss: 6.818969, speed: 0.946607 steps/s, speed: 7.572860 samples/s, speed: 3877.304099 tokens/s, learning rate: 1.859e-05, loss_scalings: 5497.559082, pp_loss: 6.389243
[INFO] 2021-07-12 19:09:41,639 [run_pretraining.py:  512]:	********exe.run_1860******* 
[INFO] 2021-07-12 19:09:42,557 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:42,557 [run_pretraining.py:  534]:	loss/total_loss, 7.44970178604126, 1861
[INFO] 2021-07-12 19:09:42,557 [run_pretraining.py:  535]:	loss/mlm_loss, 7.44970178604126, 1861
[INFO] 2021-07-12 19:09:42,557 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8599999748403206e-05, 1861
[INFO] 2021-07-12 19:09:42,557 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1861
[INFO] 2021-07-12 19:09:42,558 [run_pretraining.py:  558]:	worker_index: 2, step: 1861, cost: 7.449702, mlm loss: 7.449702, speed: 1.089618 steps/s, speed: 8.716945 samples/s, speed: 4463.075738 tokens/s, learning rate: 1.860e-05, loss_scalings: 5497.559082, pp_loss: 7.392952
[INFO] 2021-07-12 19:09:42,558 [run_pretraining.py:  512]:	********exe.run_1861******* 
[INFO] 2021-07-12 19:09:43,470 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:43,471 [run_pretraining.py:  534]:	loss/total_loss, 8.597604751586914, 1862
[INFO] 2021-07-12 19:09:43,471 [run_pretraining.py:  535]:	loss/mlm_loss, 8.597604751586914, 1862
[INFO] 2021-07-12 19:09:43,471 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.86100005521439e-05, 1862
[INFO] 2021-07-12 19:09:43,471 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1862
[INFO] 2021-07-12 19:09:43,471 [run_pretraining.py:  558]:	worker_index: 2, step: 1862, cost: 8.597605, mlm loss: 8.597605, speed: 1.095477 steps/s, speed: 8.763813 samples/s, speed: 4487.072323 tokens/s, learning rate: 1.861e-05, loss_scalings: 5497.559082, pp_loss: 6.545846
[INFO] 2021-07-12 19:09:43,471 [run_pretraining.py:  512]:	********exe.run_1862******* 
[INFO] 2021-07-12 19:09:44,383 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:44,383 [run_pretraining.py:  534]:	loss/total_loss, 7.3898162841796875, 1863
[INFO] 2021-07-12 19:09:44,383 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3898162841796875, 1863
[INFO] 2021-07-12 19:09:44,383 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8619999536895193e-05, 1863
[INFO] 2021-07-12 19:09:44,383 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1863
[INFO] 2021-07-12 19:09:44,383 [run_pretraining.py:  558]:	worker_index: 2, step: 1863, cost: 7.389816, mlm loss: 7.389816, speed: 1.096681 steps/s, speed: 8.773451 samples/s, speed: 4492.006934 tokens/s, learning rate: 1.862e-05, loss_scalings: 5497.559082, pp_loss: 6.215242
[INFO] 2021-07-12 19:09:44,384 [run_pretraining.py:  512]:	********exe.run_1863******* 
[INFO] 2021-07-12 19:09:45,301 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:45,301 [run_pretraining.py:  534]:	loss/total_loss, 7.169360637664795, 1864
[INFO] 2021-07-12 19:09:45,301 [run_pretraining.py:  535]:	loss/mlm_loss, 7.169360637664795, 1864
[INFO] 2021-07-12 19:09:45,301 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8629998521646485e-05, 1864
[INFO] 2021-07-12 19:09:45,301 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1864
[INFO] 2021-07-12 19:09:45,301 [run_pretraining.py:  558]:	worker_index: 2, step: 1864, cost: 7.169361, mlm loss: 7.169361, speed: 1.090078 steps/s, speed: 8.720624 samples/s, speed: 4464.959465 tokens/s, learning rate: 1.863e-05, loss_scalings: 5497.559082, pp_loss: 7.276766
[INFO] 2021-07-12 19:09:45,301 [run_pretraining.py:  512]:	********exe.run_1864******* 
[INFO] 2021-07-12 19:09:46,229 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:46,230 [run_pretraining.py:  534]:	loss/total_loss, 7.489506721496582, 1865
[INFO] 2021-07-12 19:09:46,230 [run_pretraining.py:  535]:	loss/mlm_loss, 7.489506721496582, 1865
[INFO] 2021-07-12 19:09:46,230 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.863999932538718e-05, 1865
[INFO] 2021-07-12 19:09:46,230 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1865
[INFO] 2021-07-12 19:09:46,230 [run_pretraining.py:  558]:	worker_index: 2, step: 1865, cost: 7.489507, mlm loss: 7.489507, speed: 1.077697 steps/s, speed: 8.621574 samples/s, speed: 4414.245734 tokens/s, learning rate: 1.864e-05, loss_scalings: 5497.559082, pp_loss: 7.707104
[INFO] 2021-07-12 19:09:46,230 [run_pretraining.py:  512]:	********exe.run_1865******* 
[INFO] 2021-07-12 19:09:47,145 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:47,145 [run_pretraining.py:  534]:	loss/total_loss, 7.195798873901367, 1866
[INFO] 2021-07-12 19:09:47,145 [run_pretraining.py:  535]:	loss/mlm_loss, 7.195798873901367, 1866
[INFO] 2021-07-12 19:09:47,145 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8650000129127875e-05, 1866
[INFO] 2021-07-12 19:09:47,145 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1866
[INFO] 2021-07-12 19:09:47,145 [run_pretraining.py:  558]:	worker_index: 2, step: 1866, cost: 7.195799, mlm loss: 7.195799, speed: 1.092969 steps/s, speed: 8.743748 samples/s, speed: 4476.799211 tokens/s, learning rate: 1.865e-05, loss_scalings: 5497.559082, pp_loss: 7.165614
[INFO] 2021-07-12 19:09:47,146 [run_pretraining.py:  512]:	********exe.run_1866******* 
[INFO] 2021-07-12 19:09:48,049 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:48,049 [run_pretraining.py:  534]:	loss/total_loss, 8.011065483093262, 1867
[INFO] 2021-07-12 19:09:48,049 [run_pretraining.py:  535]:	loss/mlm_loss, 8.011065483093262, 1867
[INFO] 2021-07-12 19:09:48,050 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8659999113879167e-05, 1867
[INFO] 2021-07-12 19:09:48,050 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1867
[INFO] 2021-07-12 19:09:48,050 [run_pretraining.py:  558]:	worker_index: 2, step: 1867, cost: 8.011065, mlm loss: 8.011065, speed: 1.106568 steps/s, speed: 8.852546 samples/s, speed: 4532.503331 tokens/s, learning rate: 1.866e-05, loss_scalings: 5497.559082, pp_loss: 7.756344
[INFO] 2021-07-12 19:09:48,050 [run_pretraining.py:  512]:	********exe.run_1867******* 
[INFO] 2021-07-12 19:09:48,962 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:48,962 [run_pretraining.py:  534]:	loss/total_loss, 7.149702072143555, 1868
[INFO] 2021-07-12 19:09:48,962 [run_pretraining.py:  535]:	loss/mlm_loss, 7.149702072143555, 1868
[INFO] 2021-07-12 19:09:48,962 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.866999991761986e-05, 1868
[INFO] 2021-07-12 19:09:48,963 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1868
[INFO] 2021-07-12 19:09:48,963 [run_pretraining.py:  558]:	worker_index: 2, step: 1868, cost: 7.149702, mlm loss: 7.149702, speed: 1.096242 steps/s, speed: 8.769938 samples/s, speed: 4490.208288 tokens/s, learning rate: 1.867e-05, loss_scalings: 5497.559082, pp_loss: 7.055206
[INFO] 2021-07-12 19:09:48,963 [run_pretraining.py:  512]:	********exe.run_1868******* 
[INFO] 2021-07-12 19:09:49,870 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:49,871 [run_pretraining.py:  534]:	loss/total_loss, 7.117026329040527, 1869
[INFO] 2021-07-12 19:09:49,871 [run_pretraining.py:  535]:	loss/mlm_loss, 7.117026329040527, 1869
[INFO] 2021-07-12 19:09:49,871 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8680000721360557e-05, 1869
[INFO] 2021-07-12 19:09:49,871 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1869
[INFO] 2021-07-12 19:09:49,871 [run_pretraining.py:  558]:	worker_index: 2, step: 1869, cost: 7.117026, mlm loss: 7.117026, speed: 1.101281 steps/s, speed: 8.810244 samples/s, speed: 4510.845064 tokens/s, learning rate: 1.868e-05, loss_scalings: 5497.559082, pp_loss: 7.078967
[INFO] 2021-07-12 19:09:49,871 [run_pretraining.py:  512]:	********exe.run_1869******* 
[INFO] 2021-07-12 19:09:50,781 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:50,782 [run_pretraining.py:  534]:	loss/total_loss, 8.299638748168945, 1870
[INFO] 2021-07-12 19:09:50,782 [run_pretraining.py:  535]:	loss/mlm_loss, 8.299638748168945, 1870
[INFO] 2021-07-12 19:09:50,782 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.868999970611185e-05, 1870
[INFO] 2021-07-12 19:09:50,782 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1870
[INFO] 2021-07-12 19:09:50,782 [run_pretraining.py:  558]:	worker_index: 2, step: 1870, cost: 8.299639, mlm loss: 8.299639, speed: 1.098830 steps/s, speed: 8.790637 samples/s, speed: 4500.806034 tokens/s, learning rate: 1.869e-05, loss_scalings: 5497.559082, pp_loss: 7.603850
[INFO] 2021-07-12 19:09:50,782 [run_pretraining.py:  512]:	********exe.run_1870******* 
[INFO] 2021-07-12 19:09:51,690 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:51,691 [run_pretraining.py:  534]:	loss/total_loss, 7.983582973480225, 1871
[INFO] 2021-07-12 19:09:51,691 [run_pretraining.py:  535]:	loss/mlm_loss, 7.983582973480225, 1871
[INFO] 2021-07-12 19:09:51,691 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8700000509852543e-05, 1871
[INFO] 2021-07-12 19:09:51,691 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1871
[INFO] 2021-07-12 19:09:51,691 [run_pretraining.py:  558]:	worker_index: 2, step: 1871, cost: 7.983583, mlm loss: 7.983583, speed: 1.100751 steps/s, speed: 8.806011 samples/s, speed: 4508.677481 tokens/s, learning rate: 1.870e-05, loss_scalings: 5497.559082, pp_loss: 7.465950
[INFO] 2021-07-12 19:09:51,691 [run_pretraining.py:  512]:	********exe.run_1871******* 
[INFO] 2021-07-12 19:09:52,591 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:52,591 [run_pretraining.py:  534]:	loss/total_loss, 7.749682426452637, 1872
[INFO] 2021-07-12 19:09:52,591 [run_pretraining.py:  535]:	loss/mlm_loss, 7.749682426452637, 1872
[INFO] 2021-07-12 19:09:52,591 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8709999494603835e-05, 1872
[INFO] 2021-07-12 19:09:52,592 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1872
[INFO] 2021-07-12 19:09:52,592 [run_pretraining.py:  558]:	worker_index: 2, step: 1872, cost: 7.749682, mlm loss: 7.749682, speed: 1.111118 steps/s, speed: 8.888944 samples/s, speed: 4551.139564 tokens/s, learning rate: 1.871e-05, loss_scalings: 5497.559082, pp_loss: 7.533384
[INFO] 2021-07-12 19:09:52,592 [run_pretraining.py:  512]:	********exe.run_1872******* 
[INFO] 2021-07-12 19:09:53,497 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:53,498 [run_pretraining.py:  534]:	loss/total_loss, 7.045176982879639, 1873
[INFO] 2021-07-12 19:09:53,498 [run_pretraining.py:  535]:	loss/mlm_loss, 7.045176982879639, 1873
[INFO] 2021-07-12 19:09:53,498 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8719998479355127e-05, 1873
[INFO] 2021-07-12 19:09:53,498 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1873
[INFO] 2021-07-12 19:09:53,498 [run_pretraining.py:  558]:	worker_index: 2, step: 1873, cost: 7.045177, mlm loss: 7.045177, speed: 1.103642 steps/s, speed: 8.829136 samples/s, speed: 4520.517381 tokens/s, learning rate: 1.872e-05, loss_scalings: 5497.559082, pp_loss: 7.295141
[INFO] 2021-07-12 19:09:53,498 [run_pretraining.py:  512]:	********exe.run_1873******* 
[INFO] 2021-07-12 19:09:54,401 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:54,401 [run_pretraining.py:  534]:	loss/total_loss, 7.161986351013184, 1874
[INFO] 2021-07-12 19:09:54,401 [run_pretraining.py:  535]:	loss/mlm_loss, 7.161986351013184, 1874
[INFO] 2021-07-12 19:09:54,401 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8729999283095822e-05, 1874
[INFO] 2021-07-12 19:09:54,401 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1874
[INFO] 2021-07-12 19:09:54,402 [run_pretraining.py:  558]:	worker_index: 2, step: 1874, cost: 7.161986, mlm loss: 7.161986, speed: 1.107842 steps/s, speed: 8.862738 samples/s, speed: 4537.721799 tokens/s, learning rate: 1.873e-05, loss_scalings: 5497.559082, pp_loss: 7.239046
[INFO] 2021-07-12 19:09:54,402 [run_pretraining.py:  512]:	********exe.run_1874******* 
[INFO] 2021-07-12 19:09:55,305 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:55,306 [run_pretraining.py:  534]:	loss/total_loss, 7.471670150756836, 1875
[INFO] 2021-07-12 19:09:55,306 [run_pretraining.py:  535]:	loss/mlm_loss, 7.471670150756836, 1875
[INFO] 2021-07-12 19:09:55,306 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8740000086836517e-05, 1875
[INFO] 2021-07-12 19:09:55,306 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1875
[INFO] 2021-07-12 19:09:55,306 [run_pretraining.py:  558]:	worker_index: 2, step: 1875, cost: 7.471670, mlm loss: 7.471670, speed: 1.106524 steps/s, speed: 8.852191 samples/s, speed: 4532.321578 tokens/s, learning rate: 1.874e-05, loss_scalings: 5497.559082, pp_loss: 7.419266
[INFO] 2021-07-12 19:09:55,306 [run_pretraining.py:  512]:	********exe.run_1875******* 
[INFO] 2021-07-12 19:09:56,217 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:56,218 [run_pretraining.py:  534]:	loss/total_loss, 7.212487697601318, 1876
[INFO] 2021-07-12 19:09:56,218 [run_pretraining.py:  535]:	loss/mlm_loss, 7.212487697601318, 1876
[INFO] 2021-07-12 19:09:56,218 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.874999907158781e-05, 1876
[INFO] 2021-07-12 19:09:56,218 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1876
[INFO] 2021-07-12 19:09:56,218 [run_pretraining.py:  558]:	worker_index: 2, step: 1876, cost: 7.212488, mlm loss: 7.212488, speed: 1.096891 steps/s, speed: 8.775128 samples/s, speed: 4492.865674 tokens/s, learning rate: 1.875e-05, loss_scalings: 5497.559082, pp_loss: 7.621448
[INFO] 2021-07-12 19:09:56,218 [run_pretraining.py:  512]:	********exe.run_1876******* 
[INFO] 2021-07-12 19:09:57,154 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:57,154 [run_pretraining.py:  534]:	loss/total_loss, 6.0699663162231445, 1877
[INFO] 2021-07-12 19:09:57,154 [run_pretraining.py:  535]:	loss/mlm_loss, 6.0699663162231445, 1877
[INFO] 2021-07-12 19:09:57,154 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8759999875328504e-05, 1877
[INFO] 2021-07-12 19:09:57,154 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1877
[INFO] 2021-07-12 19:09:57,155 [run_pretraining.py:  558]:	worker_index: 2, step: 1877, cost: 6.069966, mlm loss: 6.069966, speed: 1.068601 steps/s, speed: 8.548804 samples/s, speed: 4376.987668 tokens/s, learning rate: 1.876e-05, loss_scalings: 5497.559082, pp_loss: 6.873005
[INFO] 2021-07-12 19:09:57,155 [run_pretraining.py:  512]:	********exe.run_1877******* 
[INFO] 2021-07-12 19:09:58,060 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:58,061 [run_pretraining.py:  534]:	loss/total_loss, 6.770235061645508, 1878
[INFO] 2021-07-12 19:09:58,061 [run_pretraining.py:  535]:	loss/mlm_loss, 6.770235061645508, 1878
[INFO] 2021-07-12 19:09:58,061 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.87700006790692e-05, 1878
[INFO] 2021-07-12 19:09:58,061 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1878
[INFO] 2021-07-12 19:09:58,061 [run_pretraining.py:  558]:	worker_index: 2, step: 1878, cost: 6.770235, mlm loss: 6.770235, speed: 1.103779 steps/s, speed: 8.830230 samples/s, speed: 4521.077694 tokens/s, learning rate: 1.877e-05, loss_scalings: 5497.559082, pp_loss: 7.129445
[INFO] 2021-07-12 19:09:58,061 [run_pretraining.py:  512]:	********exe.run_1878******* 
[INFO] 2021-07-12 19:09:58,965 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:58,966 [run_pretraining.py:  534]:	loss/total_loss, 7.814661979675293, 1879
[INFO] 2021-07-12 19:09:58,966 [run_pretraining.py:  535]:	loss/mlm_loss, 7.814661979675293, 1879
[INFO] 2021-07-12 19:09:58,966 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.877999966382049e-05, 1879
[INFO] 2021-07-12 19:09:58,966 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1879
[INFO] 2021-07-12 19:09:58,966 [run_pretraining.py:  558]:	worker_index: 2, step: 1879, cost: 7.814662, mlm loss: 7.814662, speed: 1.105843 steps/s, speed: 8.846746 samples/s, speed: 4529.533730 tokens/s, learning rate: 1.878e-05, loss_scalings: 5497.559082, pp_loss: 7.589430
[INFO] 2021-07-12 19:09:58,966 [run_pretraining.py:  512]:	********exe.run_1879******* 
[INFO] 2021-07-12 19:09:59,924 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:59,925 [run_pretraining.py:  534]:	loss/total_loss, 7.421415328979492, 1880
[INFO] 2021-07-12 19:09:59,925 [run_pretraining.py:  535]:	loss/mlm_loss, 7.421415328979492, 1880
[INFO] 2021-07-12 19:09:59,925 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8790000467561185e-05, 1880
[INFO] 2021-07-12 19:09:59,925 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1880
[INFO] 2021-07-12 19:09:59,925 [run_pretraining.py:  558]:	worker_index: 2, step: 1880, cost: 7.421415, mlm loss: 7.421415, speed: 1.043321 steps/s, speed: 8.346570 samples/s, speed: 4273.444095 tokens/s, learning rate: 1.879e-05, loss_scalings: 5497.559082, pp_loss: 7.097643
[INFO] 2021-07-12 19:09:59,925 [run_pretraining.py:  512]:	********exe.run_1880******* 
[INFO] 2021-07-12 19:10:00,980 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:00,981 [run_pretraining.py:  534]:	loss/total_loss, 7.01959228515625, 1881
[INFO] 2021-07-12 19:10:00,981 [run_pretraining.py:  535]:	loss/mlm_loss, 7.01959228515625, 1881
[INFO] 2021-07-12 19:10:00,981 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8799999452312477e-05, 1881
[INFO] 2021-07-12 19:10:00,981 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1881
[INFO] 2021-07-12 19:10:00,981 [run_pretraining.py:  558]:	worker_index: 2, step: 1881, cost: 7.019592, mlm loss: 7.019592, speed: 0.947594 steps/s, speed: 7.580752 samples/s, speed: 3881.344976 tokens/s, learning rate: 1.880e-05, loss_scalings: 5497.559082, pp_loss: 7.323564
[INFO] 2021-07-12 19:10:00,981 [run_pretraining.py:  512]:	********exe.run_1881******* 
[INFO] 2021-07-12 19:10:02,062 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:02,063 [run_pretraining.py:  534]:	loss/total_loss, 7.53313684463501, 1882
[INFO] 2021-07-12 19:10:02,063 [run_pretraining.py:  535]:	loss/mlm_loss, 7.53313684463501, 1882
[INFO] 2021-07-12 19:10:02,063 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.880999843706377e-05, 1882
[INFO] 2021-07-12 19:10:02,063 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1882
[INFO] 2021-07-12 19:10:02,063 [run_pretraining.py:  558]:	worker_index: 2, step: 1882, cost: 7.533137, mlm loss: 7.533137, speed: 0.924604 steps/s, speed: 7.396833 samples/s, speed: 3787.178602 tokens/s, learning rate: 1.881e-05, loss_scalings: 5497.559082, pp_loss: 7.693904
[INFO] 2021-07-12 19:10:02,063 [run_pretraining.py:  512]:	********exe.run_1882******* 
[INFO] 2021-07-12 19:10:03,113 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:03,113 [run_pretraining.py:  534]:	loss/total_loss, 7.830448627471924, 1883
[INFO] 2021-07-12 19:10:03,113 [run_pretraining.py:  535]:	loss/mlm_loss, 7.830448627471924, 1883
[INFO] 2021-07-12 19:10:03,113 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8819999240804464e-05, 1883
[INFO] 2021-07-12 19:10:03,113 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1883
[INFO] 2021-07-12 19:10:03,113 [run_pretraining.py:  558]:	worker_index: 2, step: 1883, cost: 7.830449, mlm loss: 7.830449, speed: 0.952623 steps/s, speed: 7.620981 samples/s, speed: 3901.942215 tokens/s, learning rate: 1.882e-05, loss_scalings: 5497.559082, pp_loss: 7.578107
[INFO] 2021-07-12 19:10:03,114 [run_pretraining.py:  512]:	********exe.run_1883******* 
[INFO] 2021-07-12 19:10:04,176 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:04,176 [run_pretraining.py:  534]:	loss/total_loss, 7.219627380371094, 1884
[INFO] 2021-07-12 19:10:04,176 [run_pretraining.py:  535]:	loss/mlm_loss, 7.219627380371094, 1884
[INFO] 2021-07-12 19:10:04,177 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.883000004454516e-05, 1884
[INFO] 2021-07-12 19:10:04,177 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1884
[INFO] 2021-07-12 19:10:04,177 [run_pretraining.py:  558]:	worker_index: 2, step: 1884, cost: 7.219627, mlm loss: 7.219627, speed: 0.941118 steps/s, speed: 7.528947 samples/s, speed: 3854.820949 tokens/s, learning rate: 1.883e-05, loss_scalings: 5497.559082, pp_loss: 7.279502
[INFO] 2021-07-12 19:10:04,177 [run_pretraining.py:  512]:	********exe.run_1884******* 
[INFO] 2021-07-12 19:10:05,236 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:05,237 [run_pretraining.py:  534]:	loss/total_loss, 7.695638656616211, 1885
[INFO] 2021-07-12 19:10:05,237 [run_pretraining.py:  535]:	loss/mlm_loss, 7.695638656616211, 1885
[INFO] 2021-07-12 19:10:05,237 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.883999902929645e-05, 1885
[INFO] 2021-07-12 19:10:05,237 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1885
[INFO] 2021-07-12 19:10:05,237 [run_pretraining.py:  558]:	worker_index: 2, step: 1885, cost: 7.695639, mlm loss: 7.695639, speed: 0.943384 steps/s, speed: 7.547072 samples/s, speed: 3864.100743 tokens/s, learning rate: 1.884e-05, loss_scalings: 5497.559082, pp_loss: 7.373589
[INFO] 2021-07-12 19:10:05,237 [run_pretraining.py:  512]:	********exe.run_1885******* 
[INFO] 2021-07-12 19:10:06,436 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:06,437 [run_pretraining.py:  534]:	loss/total_loss, 7.382874488830566, 1886
[INFO] 2021-07-12 19:10:06,437 [run_pretraining.py:  535]:	loss/mlm_loss, 7.382874488830566, 1886
[INFO] 2021-07-12 19:10:06,437 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8849999833037145e-05, 1886
[INFO] 2021-07-12 19:10:06,437 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1886
[INFO] 2021-07-12 19:10:06,437 [run_pretraining.py:  558]:	worker_index: 2, step: 1886, cost: 7.382874, mlm loss: 7.382874, speed: 0.833965 steps/s, speed: 6.671723 samples/s, speed: 3415.922372 tokens/s, learning rate: 1.885e-05, loss_scalings: 5497.559082, pp_loss: 7.666704
[INFO] 2021-07-12 19:10:06,437 [run_pretraining.py:  512]:	********exe.run_1886******* 
[INFO] 2021-07-12 19:10:07,668 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:07,669 [run_pretraining.py:  534]:	loss/total_loss, 7.023660659790039, 1887
[INFO] 2021-07-12 19:10:07,669 [run_pretraining.py:  535]:	loss/mlm_loss, 7.023660659790039, 1887
[INFO] 2021-07-12 19:10:07,669 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.886000063677784e-05, 1887
[INFO] 2021-07-12 19:10:07,669 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1887
[INFO] 2021-07-12 19:10:07,669 [run_pretraining.py:  558]:	worker_index: 2, step: 1887, cost: 7.023661, mlm loss: 7.023661, speed: 0.812069 steps/s, speed: 6.496556 samples/s, speed: 3326.236634 tokens/s, learning rate: 1.886e-05, loss_scalings: 5497.559082, pp_loss: 7.135466
[INFO] 2021-07-12 19:10:07,669 [run_pretraining.py:  512]:	********exe.run_1887******* 
[INFO] 2021-07-12 19:10:08,942 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:08,943 [run_pretraining.py:  534]:	loss/total_loss, 7.546857833862305, 1888
[INFO] 2021-07-12 19:10:08,943 [run_pretraining.py:  535]:	loss/mlm_loss, 7.546857833862305, 1888
[INFO] 2021-07-12 19:10:08,943 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8869999621529132e-05, 1888
[INFO] 2021-07-12 19:10:08,943 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1888
[INFO] 2021-07-12 19:10:08,943 [run_pretraining.py:  558]:	worker_index: 2, step: 1888, cost: 7.546858, mlm loss: 7.546858, speed: 0.785224 steps/s, speed: 6.281789 samples/s, speed: 3216.275825 tokens/s, learning rate: 1.887e-05, loss_scalings: 5497.559082, pp_loss: 7.445634
[INFO] 2021-07-12 19:10:08,943 [run_pretraining.py:  512]:	********exe.run_1888******* 
[INFO] 2021-07-12 19:10:09,902 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:09,902 [run_pretraining.py:  534]:	loss/total_loss, 7.819870948791504, 1889
[INFO] 2021-07-12 19:10:09,902 [run_pretraining.py:  535]:	loss/mlm_loss, 7.819870948791504, 1889
[INFO] 2021-07-12 19:10:09,902 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8880000425269827e-05, 1889
[INFO] 2021-07-12 19:10:09,903 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1889
[INFO] 2021-07-12 19:10:09,903 [run_pretraining.py:  558]:	worker_index: 2, step: 1889, cost: 7.819871, mlm loss: 7.819871, speed: 1.042819 steps/s, speed: 8.342551 samples/s, speed: 4271.386042 tokens/s, learning rate: 1.888e-05, loss_scalings: 5497.559082, pp_loss: 7.009157
[INFO] 2021-07-12 19:10:09,903 [run_pretraining.py:  512]:	********exe.run_1889******* 
[INFO] 2021-07-12 19:10:10,813 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:10,813 [run_pretraining.py:  534]:	loss/total_loss, 7.390377044677734, 1890
[INFO] 2021-07-12 19:10:10,813 [run_pretraining.py:  535]:	loss/mlm_loss, 7.390377044677734, 1890
[INFO] 2021-07-12 19:10:10,814 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.888999941002112e-05, 1890
[INFO] 2021-07-12 19:10:10,814 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1890
[INFO] 2021-07-12 19:10:10,814 [run_pretraining.py:  558]:	worker_index: 2, step: 1890, cost: 7.390377, mlm loss: 7.390377, speed: 1.098276 steps/s, speed: 8.786210 samples/s, speed: 4498.539714 tokens/s, learning rate: 1.889e-05, loss_scalings: 5497.559082, pp_loss: 7.298543
[INFO] 2021-07-12 19:10:10,814 [run_pretraining.py:  512]:	********exe.run_1890******* 
[INFO] 2021-07-12 19:10:11,726 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:11,726 [run_pretraining.py:  534]:	loss/total_loss, 6.998069763183594, 1891
[INFO] 2021-07-12 19:10:11,726 [run_pretraining.py:  535]:	loss/mlm_loss, 6.998069763183594, 1891
[INFO] 2021-07-12 19:10:11,726 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.889999839477241e-05, 1891
[INFO] 2021-07-12 19:10:11,727 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1891
[INFO] 2021-07-12 19:10:11,727 [run_pretraining.py:  558]:	worker_index: 2, step: 1891, cost: 6.998070, mlm loss: 6.998070, speed: 1.096141 steps/s, speed: 8.769124 samples/s, speed: 4489.791705 tokens/s, learning rate: 1.890e-05, loss_scalings: 5497.559082, pp_loss: 7.055364
[INFO] 2021-07-12 19:10:11,727 [run_pretraining.py:  512]:	********exe.run_1891******* 
[INFO] 2021-07-12 19:10:12,640 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:12,640 [run_pretraining.py:  534]:	loss/total_loss, 7.191200256347656, 1892
[INFO] 2021-07-12 19:10:12,640 [run_pretraining.py:  535]:	loss/mlm_loss, 7.191200256347656, 1892
[INFO] 2021-07-12 19:10:12,640 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8909999198513106e-05, 1892
[INFO] 2021-07-12 19:10:12,640 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1892
[INFO] 2021-07-12 19:10:12,640 [run_pretraining.py:  558]:	worker_index: 2, step: 1892, cost: 7.191200, mlm loss: 7.191200, speed: 1.095103 steps/s, speed: 8.760827 samples/s, speed: 4485.543460 tokens/s, learning rate: 1.891e-05, loss_scalings: 5497.559082, pp_loss: 7.132404
[INFO] 2021-07-12 19:10:12,640 [run_pretraining.py:  512]:	********exe.run_1892******* 
[INFO] 2021-07-12 19:10:13,559 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:13,559 [run_pretraining.py:  534]:	loss/total_loss, 7.329859733581543, 1893
[INFO] 2021-07-12 19:10:13,559 [run_pretraining.py:  535]:	loss/mlm_loss, 7.329859733581543, 1893
[INFO] 2021-07-12 19:10:13,559 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.89200000022538e-05, 1893
[INFO] 2021-07-12 19:10:13,559 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1893
[INFO] 2021-07-12 19:10:13,559 [run_pretraining.py:  558]:	worker_index: 2, step: 1893, cost: 7.329860, mlm loss: 7.329860, speed: 1.088816 steps/s, speed: 8.710532 samples/s, speed: 4459.792300 tokens/s, learning rate: 1.892e-05, loss_scalings: 5497.559082, pp_loss: 7.269776
[INFO] 2021-07-12 19:10:13,560 [run_pretraining.py:  512]:	********exe.run_1893******* 
[INFO] 2021-07-12 19:10:14,474 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:14,475 [run_pretraining.py:  534]:	loss/total_loss, 6.748366832733154, 1894
[INFO] 2021-07-12 19:10:14,475 [run_pretraining.py:  535]:	loss/mlm_loss, 6.748366832733154, 1894
[INFO] 2021-07-12 19:10:14,475 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8929998987005092e-05, 1894
[INFO] 2021-07-12 19:10:14,475 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1894
[INFO] 2021-07-12 19:10:14,475 [run_pretraining.py:  558]:	worker_index: 2, step: 1894, cost: 6.748367, mlm loss: 6.748367, speed: 1.092724 steps/s, speed: 8.741792 samples/s, speed: 4475.797341 tokens/s, learning rate: 1.893e-05, loss_scalings: 5497.559082, pp_loss: 7.572042
[INFO] 2021-07-12 19:10:14,475 [run_pretraining.py:  512]:	********exe.run_1894******* 
[INFO] 2021-07-12 19:10:15,385 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:15,385 [run_pretraining.py:  534]:	loss/total_loss, 7.213033676147461, 1895
[INFO] 2021-07-12 19:10:15,385 [run_pretraining.py:  535]:	loss/mlm_loss, 7.213033676147461, 1895
[INFO] 2021-07-12 19:10:15,385 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8939999790745787e-05, 1895
[INFO] 2021-07-12 19:10:15,386 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1895
[INFO] 2021-07-12 19:10:15,386 [run_pretraining.py:  558]:	worker_index: 2, step: 1895, cost: 7.213034, mlm loss: 7.213034, speed: 1.099083 steps/s, speed: 8.792662 samples/s, speed: 4501.842726 tokens/s, learning rate: 1.894e-05, loss_scalings: 5497.559082, pp_loss: 7.255150
[INFO] 2021-07-12 19:10:15,386 [run_pretraining.py:  512]:	********exe.run_1895******* 
[INFO] 2021-07-12 19:10:16,291 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:16,292 [run_pretraining.py:  534]:	loss/total_loss, 7.121637344360352, 1896
[INFO] 2021-07-12 19:10:16,292 [run_pretraining.py:  535]:	loss/mlm_loss, 7.121637344360352, 1896
[INFO] 2021-07-12 19:10:16,292 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8950000594486482e-05, 1896
[INFO] 2021-07-12 19:10:16,292 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1896
[INFO] 2021-07-12 19:10:16,292 [run_pretraining.py:  558]:	worker_index: 2, step: 1896, cost: 7.121637, mlm loss: 7.121637, speed: 1.103777 steps/s, speed: 8.830218 samples/s, speed: 4521.071745 tokens/s, learning rate: 1.895e-05, loss_scalings: 5497.559082, pp_loss: 7.355809
[INFO] 2021-07-12 19:10:16,292 [run_pretraining.py:  512]:	********exe.run_1896******* 
[INFO] 2021-07-12 19:10:17,205 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:17,205 [run_pretraining.py:  534]:	loss/total_loss, 7.861649513244629, 1897
[INFO] 2021-07-12 19:10:17,205 [run_pretraining.py:  535]:	loss/mlm_loss, 7.861649513244629, 1897
[INFO] 2021-07-12 19:10:17,205 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8959999579237774e-05, 1897
[INFO] 2021-07-12 19:10:17,206 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1897
[INFO] 2021-07-12 19:10:17,206 [run_pretraining.py:  558]:	worker_index: 2, step: 1897, cost: 7.861650, mlm loss: 7.861650, speed: 1.095530 steps/s, speed: 8.764241 samples/s, speed: 4487.291487 tokens/s, learning rate: 1.896e-05, loss_scalings: 5497.559082, pp_loss: 7.207959
[INFO] 2021-07-12 19:10:17,206 [run_pretraining.py:  512]:	********exe.run_1897******* 
[INFO] 2021-07-12 19:10:18,119 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:18,119 [run_pretraining.py:  534]:	loss/total_loss, 6.659631252288818, 1898
[INFO] 2021-07-12 19:10:18,119 [run_pretraining.py:  535]:	loss/mlm_loss, 6.659631252288818, 1898
[INFO] 2021-07-12 19:10:18,119 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.897000038297847e-05, 1898
[INFO] 2021-07-12 19:10:18,119 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1898
[INFO] 2021-07-12 19:10:18,119 [run_pretraining.py:  558]:	worker_index: 2, step: 1898, cost: 6.659631, mlm loss: 6.659631, speed: 1.095042 steps/s, speed: 8.760338 samples/s, speed: 4485.292849 tokens/s, learning rate: 1.897e-05, loss_scalings: 5497.559082, pp_loss: 7.385441
[INFO] 2021-07-12 19:10:18,120 [run_pretraining.py:  512]:	********exe.run_1898******* 
[INFO] 2021-07-12 19:10:19,042 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:19,042 [run_pretraining.py:  534]:	loss/total_loss, 6.703227996826172, 1899
[INFO] 2021-07-12 19:10:19,042 [run_pretraining.py:  535]:	loss/mlm_loss, 6.703227996826172, 1899
[INFO] 2021-07-12 19:10:19,042 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.897999936772976e-05, 1899
[INFO] 2021-07-12 19:10:19,043 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1899
[INFO] 2021-07-12 19:10:19,043 [run_pretraining.py:  558]:	worker_index: 2, step: 1899, cost: 6.703228, mlm loss: 6.703228, speed: 1.083964 steps/s, speed: 8.671716 samples/s, speed: 4439.918423 tokens/s, learning rate: 1.898e-05, loss_scalings: 5497.559082, pp_loss: 7.160167
[INFO] 2021-07-12 19:10:19,043 [run_pretraining.py:  512]:	********exe.run_1899******* 
[INFO] 2021-07-12 19:10:19,964 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:19,965 [run_pretraining.py:  534]:	loss/total_loss, 7.014269828796387, 1900
[INFO] 2021-07-12 19:10:19,965 [run_pretraining.py:  535]:	loss/mlm_loss, 7.014269828796387, 1900
[INFO] 2021-07-12 19:10:19,965 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8989998352481052e-05, 1900
[INFO] 2021-07-12 19:10:19,965 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1900
[INFO] 2021-07-12 19:10:19,965 [run_pretraining.py:  558]:	worker_index: 2, step: 1900, cost: 7.014270, mlm loss: 7.014270, speed: 1.084431 steps/s, speed: 8.675449 samples/s, speed: 4441.829733 tokens/s, learning rate: 1.899e-05, loss_scalings: 5497.559082, pp_loss: 6.611153
[INFO] 2021-07-12 19:10:19,965 [run_pretraining.py:  512]:	********exe.run_1900******* 
[INFO] 2021-07-12 19:10:20,880 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:20,880 [run_pretraining.py:  534]:	loss/total_loss, 6.840634346008301, 1901
[INFO] 2021-07-12 19:10:20,881 [run_pretraining.py:  535]:	loss/mlm_loss, 6.840634346008301, 1901
[INFO] 2021-07-12 19:10:20,881 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8999999156221747e-05, 1901
[INFO] 2021-07-12 19:10:20,881 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1901
[INFO] 2021-07-12 19:10:20,881 [run_pretraining.py:  558]:	worker_index: 2, step: 1901, cost: 6.840634, mlm loss: 6.840634, speed: 1.092990 steps/s, speed: 8.743919 samples/s, speed: 4476.886707 tokens/s, learning rate: 1.900e-05, loss_scalings: 5497.559082, pp_loss: 7.051704
[INFO] 2021-07-12 19:10:20,881 [run_pretraining.py:  512]:	********exe.run_1901******* 
[INFO] 2021-07-12 19:10:21,814 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:21,814 [run_pretraining.py:  534]:	loss/total_loss, 7.425384521484375, 1902
[INFO] 2021-07-12 19:10:21,814 [run_pretraining.py:  535]:	loss/mlm_loss, 7.425384521484375, 1902
[INFO] 2021-07-12 19:10:21,814 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9009999959962443e-05, 1902
[INFO] 2021-07-12 19:10:21,814 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1902
[INFO] 2021-07-12 19:10:21,814 [run_pretraining.py:  558]:	worker_index: 2, step: 1902, cost: 7.425385, mlm loss: 7.425385, speed: 1.071912 steps/s, speed: 8.575292 samples/s, speed: 4390.549560 tokens/s, learning rate: 1.901e-05, loss_scalings: 5497.559082, pp_loss: 7.506979
[INFO] 2021-07-12 19:10:21,814 [run_pretraining.py:  512]:	********exe.run_1902******* 
[INFO] 2021-07-12 19:10:22,737 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:22,737 [run_pretraining.py:  534]:	loss/total_loss, 7.416287899017334, 1903
[INFO] 2021-07-12 19:10:22,737 [run_pretraining.py:  535]:	loss/mlm_loss, 7.416287899017334, 1903
[INFO] 2021-07-12 19:10:22,737 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9019998944713734e-05, 1903
[INFO] 2021-07-12 19:10:22,737 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1903
[INFO] 2021-07-12 19:10:22,738 [run_pretraining.py:  558]:	worker_index: 2, step: 1903, cost: 7.416288, mlm loss: 7.416288, speed: 1.083969 steps/s, speed: 8.671754 samples/s, speed: 4439.937929 tokens/s, learning rate: 1.902e-05, loss_scalings: 5497.559082, pp_loss: 7.443353
[INFO] 2021-07-12 19:10:22,738 [run_pretraining.py:  512]:	********exe.run_1903******* 
[INFO] 2021-07-12 19:10:23,669 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:23,670 [run_pretraining.py:  534]:	loss/total_loss, 8.082297325134277, 1904
[INFO] 2021-07-12 19:10:23,670 [run_pretraining.py:  535]:	loss/mlm_loss, 8.082297325134277, 1904
[INFO] 2021-07-12 19:10:23,670 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.902999974845443e-05, 1904
[INFO] 2021-07-12 19:10:23,670 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1904
[INFO] 2021-07-12 19:10:23,670 [run_pretraining.py:  558]:	worker_index: 2, step: 1904, cost: 8.082297, mlm loss: 8.082297, speed: 1.072800 steps/s, speed: 8.582396 samples/s, speed: 4394.186939 tokens/s, learning rate: 1.903e-05, loss_scalings: 5497.559082, pp_loss: 7.442510
[INFO] 2021-07-12 19:10:23,670 [run_pretraining.py:  512]:	********exe.run_1904******* 
[INFO] 2021-07-12 19:10:24,593 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:24,594 [run_pretraining.py:  534]:	loss/total_loss, 6.736448287963867, 1905
[INFO] 2021-07-12 19:10:24,594 [run_pretraining.py:  535]:	loss/mlm_loss, 6.736448287963867, 1905
[INFO] 2021-07-12 19:10:24,594 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9040000552195124e-05, 1905
[INFO] 2021-07-12 19:10:24,594 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1905
[INFO] 2021-07-12 19:10:24,594 [run_pretraining.py:  558]:	worker_index: 2, step: 1905, cost: 6.736448, mlm loss: 6.736448, speed: 1.082971 steps/s, speed: 8.663769 samples/s, speed: 4435.849888 tokens/s, learning rate: 1.904e-05, loss_scalings: 5497.559082, pp_loss: 6.975787
[INFO] 2021-07-12 19:10:24,594 [run_pretraining.py:  512]:	********exe.run_1905******* 
[INFO] 2021-07-12 19:10:25,516 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:25,517 [run_pretraining.py:  534]:	loss/total_loss, 6.416726589202881, 1906
[INFO] 2021-07-12 19:10:25,517 [run_pretraining.py:  535]:	loss/mlm_loss, 6.416726589202881, 1906
[INFO] 2021-07-12 19:10:25,517 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9049999536946416e-05, 1906
[INFO] 2021-07-12 19:10:25,517 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1906
[INFO] 2021-07-12 19:10:25,517 [run_pretraining.py:  558]:	worker_index: 2, step: 1906, cost: 6.416727, mlm loss: 6.416727, speed: 1.084505 steps/s, speed: 8.676041 samples/s, speed: 4442.132939 tokens/s, learning rate: 1.905e-05, loss_scalings: 5497.559082, pp_loss: 6.654695
[INFO] 2021-07-12 19:10:25,517 [run_pretraining.py:  512]:	********exe.run_1906******* 
[INFO] 2021-07-12 19:10:26,433 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:26,434 [run_pretraining.py:  534]:	loss/total_loss, 6.832428932189941, 1907
[INFO] 2021-07-12 19:10:26,434 [run_pretraining.py:  535]:	loss/mlm_loss, 6.832428932189941, 1907
[INFO] 2021-07-12 19:10:26,434 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9059998521697707e-05, 1907
[INFO] 2021-07-12 19:10:26,434 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1907
[INFO] 2021-07-12 19:10:26,434 [run_pretraining.py:  558]:	worker_index: 2, step: 1907, cost: 6.832429, mlm loss: 6.832429, speed: 1.090940 steps/s, speed: 8.727519 samples/s, speed: 4468.489931 tokens/s, learning rate: 1.906e-05, loss_scalings: 5497.559082, pp_loss: 6.890507
[INFO] 2021-07-12 19:10:26,434 [run_pretraining.py:  512]:	********exe.run_1907******* 
[INFO] 2021-07-12 19:10:27,395 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:27,395 [run_pretraining.py:  534]:	loss/total_loss, 7.081070899963379, 1908
[INFO] 2021-07-12 19:10:27,396 [run_pretraining.py:  535]:	loss/mlm_loss, 7.081070899963379, 1908
[INFO] 2021-07-12 19:10:27,396 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9069999325438403e-05, 1908
[INFO] 2021-07-12 19:10:27,396 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1908
[INFO] 2021-07-12 19:10:27,396 [run_pretraining.py:  558]:	worker_index: 2, step: 1908, cost: 7.081071, mlm loss: 7.081071, speed: 1.040569 steps/s, speed: 8.324555 samples/s, speed: 4262.172013 tokens/s, learning rate: 1.907e-05, loss_scalings: 5497.559082, pp_loss: 7.419680
[INFO] 2021-07-12 19:10:27,396 [run_pretraining.py:  512]:	********exe.run_1908******* 
[INFO] 2021-07-12 19:10:28,307 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:28,308 [run_pretraining.py:  534]:	loss/total_loss, 7.692667007446289, 1909
[INFO] 2021-07-12 19:10:28,308 [run_pretraining.py:  535]:	loss/mlm_loss, 7.692667007446289, 1909
[INFO] 2021-07-12 19:10:28,308 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9079998310189694e-05, 1909
[INFO] 2021-07-12 19:10:28,308 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1909
[INFO] 2021-07-12 19:10:28,308 [run_pretraining.py:  558]:	worker_index: 2, step: 1909, cost: 7.692667, mlm loss: 7.692667, speed: 1.096845 steps/s, speed: 8.774759 samples/s, speed: 4492.676511 tokens/s, learning rate: 1.908e-05, loss_scalings: 5497.559082, pp_loss: 7.190771
[INFO] 2021-07-12 19:10:28,308 [run_pretraining.py:  512]:	********exe.run_1909******* 
[INFO] 2021-07-12 19:10:29,245 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:29,245 [run_pretraining.py:  534]:	loss/total_loss, 7.2578325271606445, 1910
[INFO] 2021-07-12 19:10:29,245 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2578325271606445, 1910
[INFO] 2021-07-12 19:10:29,246 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.908999911393039e-05, 1910
[INFO] 2021-07-12 19:10:29,246 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1910
[INFO] 2021-07-12 19:10:29,246 [run_pretraining.py:  558]:	worker_index: 2, step: 1910, cost: 7.257833, mlm loss: 7.257833, speed: 1.067262 steps/s, speed: 8.538099 samples/s, speed: 4371.506918 tokens/s, learning rate: 1.909e-05, loss_scalings: 5497.559082, pp_loss: 7.427981
[INFO] 2021-07-12 19:10:29,246 [run_pretraining.py:  512]:	********exe.run_1910******* 
[INFO] 2021-07-12 19:10:30,178 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:30,178 [run_pretraining.py:  534]:	loss/total_loss, 7.453331470489502, 1911
[INFO] 2021-07-12 19:10:30,178 [run_pretraining.py:  535]:	loss/mlm_loss, 7.453331470489502, 1911
[INFO] 2021-07-12 19:10:30,179 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9099999917671084e-05, 1911
[INFO] 2021-07-12 19:10:30,179 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1911
[INFO] 2021-07-12 19:10:30,179 [run_pretraining.py:  558]:	worker_index: 2, step: 1911, cost: 7.453331, mlm loss: 7.453331, speed: 1.072541 steps/s, speed: 8.580329 samples/s, speed: 4393.128457 tokens/s, learning rate: 1.910e-05, loss_scalings: 5497.559082, pp_loss: 6.570932
[INFO] 2021-07-12 19:10:30,179 [run_pretraining.py:  512]:	********exe.run_1911******* 
[INFO] 2021-07-12 19:10:31,098 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:31,098 [run_pretraining.py:  534]:	loss/total_loss, 7.654347896575928, 1912
[INFO] 2021-07-12 19:10:31,099 [run_pretraining.py:  535]:	loss/mlm_loss, 7.654347896575928, 1912
[INFO] 2021-07-12 19:10:31,099 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9109998902422376e-05, 1912
[INFO] 2021-07-12 19:10:31,099 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1912
[INFO] 2021-07-12 19:10:31,099 [run_pretraining.py:  558]:	worker_index: 2, step: 1912, cost: 7.654348, mlm loss: 7.654348, speed: 1.087480 steps/s, speed: 8.699843 samples/s, speed: 4454.319461 tokens/s, learning rate: 1.911e-05, loss_scalings: 5497.559082, pp_loss: 7.340516
[INFO] 2021-07-12 19:10:31,099 [run_pretraining.py:  512]:	********exe.run_1912******* 
[INFO] 2021-07-12 19:10:32,018 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:32,019 [run_pretraining.py:  534]:	loss/total_loss, 7.879995346069336, 1913
[INFO] 2021-07-12 19:10:32,019 [run_pretraining.py:  535]:	loss/mlm_loss, 7.879995346069336, 1913
[INFO] 2021-07-12 19:10:32,019 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.911999970616307e-05, 1913
[INFO] 2021-07-12 19:10:32,019 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1913
[INFO] 2021-07-12 19:10:32,019 [run_pretraining.py:  558]:	worker_index: 2, step: 1913, cost: 7.879995, mlm loss: 7.879995, speed: 1.087585 steps/s, speed: 8.700677 samples/s, speed: 4454.746814 tokens/s, learning rate: 1.912e-05, loss_scalings: 5497.559082, pp_loss: 7.605440
[INFO] 2021-07-12 19:10:32,019 [run_pretraining.py:  512]:	********exe.run_1913******* 
[INFO] 2021-07-12 19:10:32,963 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:32,963 [run_pretraining.py:  534]:	loss/total_loss, 7.638748645782471, 1914
[INFO] 2021-07-12 19:10:32,963 [run_pretraining.py:  535]:	loss/mlm_loss, 7.638748645782471, 1914
[INFO] 2021-07-12 19:10:32,963 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9130000509903766e-05, 1914
[INFO] 2021-07-12 19:10:32,963 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1914
[INFO] 2021-07-12 19:10:32,963 [run_pretraining.py:  558]:	worker_index: 2, step: 1914, cost: 7.638749, mlm loss: 7.638749, speed: 1.059352 steps/s, speed: 8.474816 samples/s, speed: 4339.105765 tokens/s, learning rate: 1.913e-05, loss_scalings: 5497.559082, pp_loss: 7.448634
[INFO] 2021-07-12 19:10:32,964 [run_pretraining.py:  512]:	********exe.run_1914******* 
[INFO] 2021-07-12 19:10:33,907 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:33,908 [run_pretraining.py:  534]:	loss/total_loss, 7.480310440063477, 1915
[INFO] 2021-07-12 19:10:33,908 [run_pretraining.py:  535]:	loss/mlm_loss, 7.480310440063477, 1915
[INFO] 2021-07-12 19:10:33,908 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9139999494655058e-05, 1915
[INFO] 2021-07-12 19:10:33,908 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1915
[INFO] 2021-07-12 19:10:33,908 [run_pretraining.py:  558]:	worker_index: 2, step: 1915, cost: 7.480310, mlm loss: 7.480310, speed: 1.059527 steps/s, speed: 8.476216 samples/s, speed: 4339.822618 tokens/s, learning rate: 1.914e-05, loss_scalings: 5497.559082, pp_loss: 7.449363
[INFO] 2021-07-12 19:10:33,908 [run_pretraining.py:  512]:	********exe.run_1915******* 
[INFO] 2021-07-12 19:10:34,842 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:34,842 [run_pretraining.py:  534]:	loss/total_loss, 7.884824275970459, 1916
[INFO] 2021-07-12 19:10:34,843 [run_pretraining.py:  535]:	loss/mlm_loss, 7.884824275970459, 1916
[INFO] 2021-07-12 19:10:34,843 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.914999847940635e-05, 1916
[INFO] 2021-07-12 19:10:34,843 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1916
[INFO] 2021-07-12 19:10:34,843 [run_pretraining.py:  558]:	worker_index: 2, step: 1916, cost: 7.884824, mlm loss: 7.884824, speed: 1.070368 steps/s, speed: 8.562947 samples/s, speed: 4384.229105 tokens/s, learning rate: 1.915e-05, loss_scalings: 5497.559082, pp_loss: 7.367457
[INFO] 2021-07-12 19:10:34,843 [run_pretraining.py:  512]:	********exe.run_1916******* 
[INFO] 2021-07-12 19:10:35,775 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:35,776 [run_pretraining.py:  534]:	loss/total_loss, 7.248229026794434, 1917
[INFO] 2021-07-12 19:10:35,776 [run_pretraining.py:  535]:	loss/mlm_loss, 7.248229026794434, 1917
[INFO] 2021-07-12 19:10:35,776 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9159999283147044e-05, 1917
[INFO] 2021-07-12 19:10:35,776 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1917
[INFO] 2021-07-12 19:10:35,776 [run_pretraining.py:  558]:	worker_index: 2, step: 1917, cost: 7.248229, mlm loss: 7.248229, speed: 1.072332 steps/s, speed: 8.578657 samples/s, speed: 4392.272605 tokens/s, learning rate: 1.916e-05, loss_scalings: 5497.559082, pp_loss: 7.261628
[INFO] 2021-07-12 19:10:35,776 [run_pretraining.py:  512]:	********exe.run_1917******* 
[INFO] 2021-07-12 19:10:36,711 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:36,712 [run_pretraining.py:  534]:	loss/total_loss, 8.135324478149414, 1918
[INFO] 2021-07-12 19:10:36,712 [run_pretraining.py:  535]:	loss/mlm_loss, 8.135324478149414, 1918
[INFO] 2021-07-12 19:10:36,712 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9169998267898336e-05, 1918
[INFO] 2021-07-12 19:10:36,712 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1918
[INFO] 2021-07-12 19:10:36,712 [run_pretraining.py:  558]:	worker_index: 2, step: 1918, cost: 8.135324, mlm loss: 8.135324, speed: 1.069000 steps/s, speed: 8.551996 samples/s, speed: 4378.621963 tokens/s, learning rate: 1.917e-05, loss_scalings: 5497.559082, pp_loss: 7.355779
[INFO] 2021-07-12 19:10:36,712 [run_pretraining.py:  512]:	********exe.run_1918******* 
[INFO] 2021-07-12 19:10:37,652 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:37,652 [run_pretraining.py:  534]:	loss/total_loss, 7.849930286407471, 1919
[INFO] 2021-07-12 19:10:37,652 [run_pretraining.py:  535]:	loss/mlm_loss, 7.849930286407471, 1919
[INFO] 2021-07-12 19:10:37,653 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.917999907163903e-05, 1919
[INFO] 2021-07-12 19:10:37,653 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1919
[INFO] 2021-07-12 19:10:37,653 [run_pretraining.py:  558]:	worker_index: 2, step: 1919, cost: 7.849930, mlm loss: 7.849930, speed: 1.063686 steps/s, speed: 8.509490 samples/s, speed: 4356.858652 tokens/s, learning rate: 1.918e-05, loss_scalings: 5497.559082, pp_loss: 7.417258
[INFO] 2021-07-12 19:10:37,653 [run_pretraining.py:  512]:	********exe.run_1919******* 
[INFO] 2021-07-12 19:10:38,588 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:38,588 [run_pretraining.py:  534]:	loss/total_loss, 7.302905559539795, 1920
[INFO] 2021-07-12 19:10:38,588 [run_pretraining.py:  535]:	loss/mlm_loss, 7.302905559539795, 1920
[INFO] 2021-07-12 19:10:38,588 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9189999875379726e-05, 1920
[INFO] 2021-07-12 19:10:38,588 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1920
[INFO] 2021-07-12 19:10:38,589 [run_pretraining.py:  558]:	worker_index: 2, step: 1920, cost: 7.302906, mlm loss: 7.302906, speed: 1.069276 steps/s, speed: 8.554207 samples/s, speed: 4379.753856 tokens/s, learning rate: 1.919e-05, loss_scalings: 5497.559082, pp_loss: 7.372581
[INFO] 2021-07-12 19:10:38,589 [run_pretraining.py:  512]:	********exe.run_1920******* 
[INFO] 2021-07-12 19:10:39,498 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:39,498 [run_pretraining.py:  534]:	loss/total_loss, 7.2267937660217285, 1921
[INFO] 2021-07-12 19:10:39,498 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2267937660217285, 1921
[INFO] 2021-07-12 19:10:39,499 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9199998860131018e-05, 1921
[INFO] 2021-07-12 19:10:39,499 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1921
[INFO] 2021-07-12 19:10:39,499 [run_pretraining.py:  558]:	worker_index: 2, step: 1921, cost: 7.226794, mlm loss: 7.226794, speed: 1.099422 steps/s, speed: 8.795377 samples/s, speed: 4503.232807 tokens/s, learning rate: 1.920e-05, loss_scalings: 5497.559082, pp_loss: 7.134217
[INFO] 2021-07-12 19:10:39,499 [run_pretraining.py:  512]:	********exe.run_1921******* 
[INFO] 2021-07-12 19:10:40,412 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:40,412 [run_pretraining.py:  534]:	loss/total_loss, 7.187055587768555, 1922
[INFO] 2021-07-12 19:10:40,412 [run_pretraining.py:  535]:	loss/mlm_loss, 7.187055587768555, 1922
[INFO] 2021-07-12 19:10:40,412 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9209999663871713e-05, 1922
[INFO] 2021-07-12 19:10:40,412 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1922
[INFO] 2021-07-12 19:10:40,412 [run_pretraining.py:  558]:	worker_index: 2, step: 1922, cost: 7.187056, mlm loss: 7.187056, speed: 1.095188 steps/s, speed: 8.761506 samples/s, speed: 4485.891316 tokens/s, learning rate: 1.921e-05, loss_scalings: 5497.559082, pp_loss: 7.377745
[INFO] 2021-07-12 19:10:40,412 [run_pretraining.py:  512]:	********exe.run_1922******* 
[INFO] 2021-07-12 19:10:41,328 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:41,328 [run_pretraining.py:  534]:	loss/total_loss, 7.849231719970703, 1923
[INFO] 2021-07-12 19:10:41,329 [run_pretraining.py:  535]:	loss/mlm_loss, 7.849231719970703, 1923
[INFO] 2021-07-12 19:10:41,329 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9220000467612408e-05, 1923
[INFO] 2021-07-12 19:10:41,329 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1923
[INFO] 2021-07-12 19:10:41,329 [run_pretraining.py:  558]:	worker_index: 2, step: 1923, cost: 7.849232, mlm loss: 7.849232, speed: 1.091908 steps/s, speed: 8.735260 samples/s, speed: 4472.453249 tokens/s, learning rate: 1.922e-05, loss_scalings: 5497.559082, pp_loss: 7.369086
[INFO] 2021-07-12 19:10:41,329 [run_pretraining.py:  512]:	********exe.run_1923******* 
[INFO] 2021-07-12 19:10:42,239 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:42,239 [run_pretraining.py:  534]:	loss/total_loss, 8.02377700805664, 1924
[INFO] 2021-07-12 19:10:42,240 [run_pretraining.py:  535]:	loss/mlm_loss, 8.02377700805664, 1924
[INFO] 2021-07-12 19:10:42,240 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.92299994523637e-05, 1924
[INFO] 2021-07-12 19:10:42,240 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1924
[INFO] 2021-07-12 19:10:42,240 [run_pretraining.py:  558]:	worker_index: 2, step: 1924, cost: 8.023777, mlm loss: 8.023777, speed: 1.098502 steps/s, speed: 8.788019 samples/s, speed: 4499.465765 tokens/s, learning rate: 1.923e-05, loss_scalings: 5497.559082, pp_loss: 7.361133
[INFO] 2021-07-12 19:10:42,240 [run_pretraining.py:  512]:	********exe.run_1924******* 
[INFO] 2021-07-12 19:10:43,178 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:43,178 [run_pretraining.py:  534]:	loss/total_loss, 7.510189056396484, 1925
[INFO] 2021-07-12 19:10:43,178 [run_pretraining.py:  535]:	loss/mlm_loss, 7.510189056396484, 1925
[INFO] 2021-07-12 19:10:43,179 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.923999843711499e-05, 1925
[INFO] 2021-07-12 19:10:43,179 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1925
[INFO] 2021-07-12 19:10:43,179 [run_pretraining.py:  558]:	worker_index: 2, step: 1925, cost: 7.510189, mlm loss: 7.510189, speed: 1.065701 steps/s, speed: 8.525608 samples/s, speed: 4365.111362 tokens/s, learning rate: 1.924e-05, loss_scalings: 5497.559082, pp_loss: 7.237804
[INFO] 2021-07-12 19:10:43,179 [run_pretraining.py:  512]:	********exe.run_1925******* 
[INFO] 2021-07-12 19:10:44,123 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:44,123 [run_pretraining.py:  534]:	loss/total_loss, 7.47885274887085, 1926
[INFO] 2021-07-12 19:10:44,124 [run_pretraining.py:  535]:	loss/mlm_loss, 7.47885274887085, 1926
[INFO] 2021-07-12 19:10:44,124 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9249999240855686e-05, 1926
[INFO] 2021-07-12 19:10:44,124 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1926
[INFO] 2021-07-12 19:10:44,124 [run_pretraining.py:  558]:	worker_index: 2, step: 1926, cost: 7.478853, mlm loss: 7.478853, speed: 1.058740 steps/s, speed: 8.469917 samples/s, speed: 4336.597548 tokens/s, learning rate: 1.925e-05, loss_scalings: 5497.559082, pp_loss: 7.257317
[INFO] 2021-07-12 19:10:44,124 [run_pretraining.py:  512]:	********exe.run_1926******* 
[INFO] 2021-07-12 19:10:45,094 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:45,095 [run_pretraining.py:  534]:	loss/total_loss, 7.108758926391602, 1927
[INFO] 2021-07-12 19:10:45,095 [run_pretraining.py:  535]:	loss/mlm_loss, 7.108758926391602, 1927
[INFO] 2021-07-12 19:10:45,095 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.926000004459638e-05, 1927
[INFO] 2021-07-12 19:10:45,095 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1927
[INFO] 2021-07-12 19:10:45,095 [run_pretraining.py:  558]:	worker_index: 2, step: 1927, cost: 7.108759, mlm loss: 7.108759, speed: 1.030436 steps/s, speed: 8.243486 samples/s, speed: 4220.664606 tokens/s, learning rate: 1.926e-05, loss_scalings: 5497.559082, pp_loss: 7.308960
[INFO] 2021-07-12 19:10:45,095 [run_pretraining.py:  512]:	********exe.run_1927******* 
[INFO] 2021-07-12 19:10:46,074 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:46,074 [run_pretraining.py:  534]:	loss/total_loss, 7.4262495040893555, 1928
[INFO] 2021-07-12 19:10:46,074 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4262495040893555, 1928
[INFO] 2021-07-12 19:10:46,074 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9269999029347673e-05, 1928
[INFO] 2021-07-12 19:10:46,074 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1928
[INFO] 2021-07-12 19:10:46,074 [run_pretraining.py:  558]:	worker_index: 2, step: 1928, cost: 7.426250, mlm loss: 7.426250, speed: 1.021475 steps/s, speed: 8.171798 samples/s, speed: 4183.960547 tokens/s, learning rate: 1.927e-05, loss_scalings: 5497.559082, pp_loss: 7.319519
[INFO] 2021-07-12 19:10:46,075 [run_pretraining.py:  512]:	********exe.run_1928******* 
[INFO] 2021-07-12 19:10:47,034 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:47,034 [run_pretraining.py:  534]:	loss/total_loss, 6.887456893920898, 1929
[INFO] 2021-07-12 19:10:47,035 [run_pretraining.py:  535]:	loss/mlm_loss, 6.887456893920898, 1929
[INFO] 2021-07-12 19:10:47,035 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9279999833088368e-05, 1929
[INFO] 2021-07-12 19:10:47,035 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1929
[INFO] 2021-07-12 19:10:47,035 [run_pretraining.py:  558]:	worker_index: 2, step: 1929, cost: 6.887457, mlm loss: 6.887457, speed: 1.042031 steps/s, speed: 8.336246 samples/s, speed: 4268.157929 tokens/s, learning rate: 1.928e-05, loss_scalings: 5497.559082, pp_loss: 7.297305
[INFO] 2021-07-12 19:10:47,035 [run_pretraining.py:  512]:	********exe.run_1929******* 
[INFO] 2021-07-12 19:10:48,004 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:48,004 [run_pretraining.py:  534]:	loss/total_loss, 7.104328155517578, 1930
[INFO] 2021-07-12 19:10:48,004 [run_pretraining.py:  535]:	loss/mlm_loss, 7.104328155517578, 1930
[INFO] 2021-07-12 19:10:48,005 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.928999881783966e-05, 1930
[INFO] 2021-07-12 19:10:48,005 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1930
[INFO] 2021-07-12 19:10:48,005 [run_pretraining.py:  558]:	worker_index: 2, step: 1930, cost: 7.104328, mlm loss: 7.104328, speed: 1.031693 steps/s, speed: 8.253545 samples/s, speed: 4225.815003 tokens/s, learning rate: 1.929e-05, loss_scalings: 5497.559082, pp_loss: 7.137385
[INFO] 2021-07-12 19:10:48,005 [run_pretraining.py:  512]:	********exe.run_1930******* 
[INFO] 2021-07-12 19:10:48,970 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:48,970 [run_pretraining.py:  534]:	loss/total_loss, 7.526425361633301, 1931
[INFO] 2021-07-12 19:10:48,970 [run_pretraining.py:  535]:	loss/mlm_loss, 7.526425361633301, 1931
[INFO] 2021-07-12 19:10:48,970 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9299999621580355e-05, 1931
[INFO] 2021-07-12 19:10:48,971 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1931
[INFO] 2021-07-12 19:10:48,971 [run_pretraining.py:  558]:	worker_index: 2, step: 1931, cost: 7.526425, mlm loss: 7.526425, speed: 1.035863 steps/s, speed: 8.286903 samples/s, speed: 4242.894255 tokens/s, learning rate: 1.930e-05, loss_scalings: 5497.559082, pp_loss: 7.224885
[INFO] 2021-07-12 19:10:48,971 [run_pretraining.py:  512]:	********exe.run_1931******* 
[INFO] 2021-07-12 19:10:49,934 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:49,934 [run_pretraining.py:  534]:	loss/total_loss, 7.15775203704834, 1932
[INFO] 2021-07-12 19:10:49,935 [run_pretraining.py:  535]:	loss/mlm_loss, 7.15775203704834, 1932
[INFO] 2021-07-12 19:10:49,935 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.931000042532105e-05, 1932
[INFO] 2021-07-12 19:10:49,935 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1932
[INFO] 2021-07-12 19:10:49,935 [run_pretraining.py:  558]:	worker_index: 2, step: 1932, cost: 7.157752, mlm loss: 7.157752, speed: 1.037784 steps/s, speed: 8.302269 samples/s, speed: 4250.761502 tokens/s, learning rate: 1.931e-05, loss_scalings: 5497.559082, pp_loss: 7.472924
[INFO] 2021-07-12 19:10:49,935 [run_pretraining.py:  512]:	********exe.run_1932******* 
[INFO] 2021-07-12 19:10:50,889 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:50,890 [run_pretraining.py:  534]:	loss/total_loss, 7.925515174865723, 1933
[INFO] 2021-07-12 19:10:50,890 [run_pretraining.py:  535]:	loss/mlm_loss, 7.925515174865723, 1933
[INFO] 2021-07-12 19:10:50,890 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.931999941007234e-05, 1933
[INFO] 2021-07-12 19:10:50,890 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1933
[INFO] 2021-07-12 19:10:50,890 [run_pretraining.py:  558]:	worker_index: 2, step: 1933, cost: 7.925515, mlm loss: 7.925515, speed: 1.047734 steps/s, speed: 8.381869 samples/s, speed: 4291.516916 tokens/s, learning rate: 1.932e-05, loss_scalings: 5497.559082, pp_loss: 7.072146
[INFO] 2021-07-12 19:10:50,890 [run_pretraining.py:  512]:	********exe.run_1933******* 
[INFO] 2021-07-12 19:10:51,827 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:51,827 [run_pretraining.py:  534]:	loss/total_loss, 7.837368965148926, 1934
[INFO] 2021-07-12 19:10:51,827 [run_pretraining.py:  535]:	loss/mlm_loss, 7.837368965148926, 1934
[INFO] 2021-07-12 19:10:51,827 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9329998394823633e-05, 1934
[INFO] 2021-07-12 19:10:51,828 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1934
[INFO] 2021-07-12 19:10:51,828 [run_pretraining.py:  558]:	worker_index: 2, step: 1934, cost: 7.837369, mlm loss: 7.837369, speed: 1.067059 steps/s, speed: 8.536470 samples/s, speed: 4370.672812 tokens/s, learning rate: 1.933e-05, loss_scalings: 5497.559082, pp_loss: 7.601039
[INFO] 2021-07-12 19:10:51,828 [run_pretraining.py:  512]:	********exe.run_1934******* 
[INFO] 2021-07-12 19:10:52,776 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:52,777 [run_pretraining.py:  534]:	loss/total_loss, 6.530322074890137, 1935
[INFO] 2021-07-12 19:10:52,777 [run_pretraining.py:  535]:	loss/mlm_loss, 6.530322074890137, 1935
[INFO] 2021-07-12 19:10:52,777 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9339999198564328e-05, 1935
[INFO] 2021-07-12 19:10:52,777 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1935
[INFO] 2021-07-12 19:10:52,777 [run_pretraining.py:  558]:	worker_index: 2, step: 1935, cost: 6.530322, mlm loss: 6.530322, speed: 1.054112 steps/s, speed: 8.432893 samples/s, speed: 4317.641390 tokens/s, learning rate: 1.934e-05, loss_scalings: 5497.559082, pp_loss: 7.326824
[INFO] 2021-07-12 19:10:52,777 [run_pretraining.py:  512]:	********exe.run_1935******* 
[INFO] 2021-07-12 19:10:53,715 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:53,716 [run_pretraining.py:  534]:	loss/total_loss, 6.990232944488525, 1936
[INFO] 2021-07-12 19:10:53,716 [run_pretraining.py:  535]:	loss/mlm_loss, 6.990232944488525, 1936
[INFO] 2021-07-12 19:10:53,716 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9350000002305023e-05, 1936
[INFO] 2021-07-12 19:10:53,716 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1936
[INFO] 2021-07-12 19:10:53,716 [run_pretraining.py:  558]:	worker_index: 2, step: 1936, cost: 6.990233, mlm loss: 6.990233, speed: 1.065385 steps/s, speed: 8.523077 samples/s, speed: 4363.815209 tokens/s, learning rate: 1.935e-05, loss_scalings: 5497.559082, pp_loss: 6.030286
[INFO] 2021-07-12 19:10:53,716 [run_pretraining.py:  512]:	********exe.run_1936******* 
[INFO] 2021-07-12 19:10:54,634 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:54,635 [run_pretraining.py:  534]:	loss/total_loss, 8.377167701721191, 1937
[INFO] 2021-07-12 19:10:54,635 [run_pretraining.py:  535]:	loss/mlm_loss, 8.377167701721191, 1937
[INFO] 2021-07-12 19:10:54,635 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9359998987056315e-05, 1937
[INFO] 2021-07-12 19:10:54,635 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1937
[INFO] 2021-07-12 19:10:54,635 [run_pretraining.py:  558]:	worker_index: 2, step: 1937, cost: 8.377168, mlm loss: 8.377168, speed: 1.089026 steps/s, speed: 8.712208 samples/s, speed: 4460.650347 tokens/s, learning rate: 1.936e-05, loss_scalings: 5497.559082, pp_loss: 7.837423
[INFO] 2021-07-12 19:10:54,635 [run_pretraining.py:  512]:	********exe.run_1937******* 
[INFO] 2021-07-12 19:10:55,572 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:55,572 [run_pretraining.py:  534]:	loss/total_loss, 6.517823219299316, 1938
[INFO] 2021-07-12 19:10:55,572 [run_pretraining.py:  535]:	loss/mlm_loss, 6.517823219299316, 1938
[INFO] 2021-07-12 19:10:55,572 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.936999979079701e-05, 1938
[INFO] 2021-07-12 19:10:55,572 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1938
[INFO] 2021-07-12 19:10:55,572 [run_pretraining.py:  558]:	worker_index: 2, step: 1938, cost: 6.517823, mlm loss: 6.517823, speed: 1.067489 steps/s, speed: 8.539914 samples/s, speed: 4372.435930 tokens/s, learning rate: 1.937e-05, loss_scalings: 5497.559082, pp_loss: 7.557576
[INFO] 2021-07-12 19:10:55,572 [run_pretraining.py:  512]:	********exe.run_1938******* 
[INFO] 2021-07-12 19:10:56,493 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:56,494 [run_pretraining.py:  534]:	loss/total_loss, 7.083611011505127, 1939
[INFO] 2021-07-12 19:10:56,494 [run_pretraining.py:  535]:	loss/mlm_loss, 7.083611011505127, 1939
[INFO] 2021-07-12 19:10:56,494 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9380000594537705e-05, 1939
[INFO] 2021-07-12 19:10:56,494 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1939
[INFO] 2021-07-12 19:10:56,494 [run_pretraining.py:  558]:	worker_index: 2, step: 1939, cost: 7.083611, mlm loss: 7.083611, speed: 1.085638 steps/s, speed: 8.685107 samples/s, speed: 4446.774623 tokens/s, learning rate: 1.938e-05, loss_scalings: 5497.559082, pp_loss: 7.569175
[INFO] 2021-07-12 19:10:56,494 [run_pretraining.py:  512]:	********exe.run_1939******* 
[INFO] 2021-07-12 19:10:57,429 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:57,430 [run_pretraining.py:  534]:	loss/total_loss, 7.127356052398682, 1940
[INFO] 2021-07-12 19:10:57,430 [run_pretraining.py:  535]:	loss/mlm_loss, 7.127356052398682, 1940
[INFO] 2021-07-12 19:10:57,430 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9389999579288997e-05, 1940
[INFO] 2021-07-12 19:10:57,430 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1940
[INFO] 2021-07-12 19:10:57,430 [run_pretraining.py:  558]:	worker_index: 2, step: 1940, cost: 7.127356, mlm loss: 7.127356, speed: 1.068955 steps/s, speed: 8.551636 samples/s, speed: 4378.437835 tokens/s, learning rate: 1.939e-05, loss_scalings: 5497.559082, pp_loss: 7.168766
[INFO] 2021-07-12 19:10:57,430 [run_pretraining.py:  512]:	********exe.run_1940******* 
[INFO] 2021-07-12 19:10:58,357 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:58,358 [run_pretraining.py:  534]:	loss/total_loss, 7.389267921447754, 1941
[INFO] 2021-07-12 19:10:58,358 [run_pretraining.py:  535]:	loss/mlm_loss, 7.389267921447754, 1941
[INFO] 2021-07-12 19:10:58,358 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9400000383029692e-05, 1941
[INFO] 2021-07-12 19:10:58,358 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1941
[INFO] 2021-07-12 19:10:58,358 [run_pretraining.py:  558]:	worker_index: 2, step: 1941, cost: 7.389268, mlm loss: 7.389268, speed: 1.078169 steps/s, speed: 8.625352 samples/s, speed: 4416.180408 tokens/s, learning rate: 1.940e-05, loss_scalings: 5497.559082, pp_loss: 7.283550
[INFO] 2021-07-12 19:10:58,358 [run_pretraining.py:  512]:	********exe.run_1941******* 
[INFO] 2021-07-12 19:10:59,286 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:59,286 [run_pretraining.py:  534]:	loss/total_loss, 7.053418159484863, 1942
[INFO] 2021-07-12 19:10:59,286 [run_pretraining.py:  535]:	loss/mlm_loss, 7.053418159484863, 1942
[INFO] 2021-07-12 19:10:59,287 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9409999367780983e-05, 1942
[INFO] 2021-07-12 19:10:59,287 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1942
[INFO] 2021-07-12 19:10:59,287 [run_pretraining.py:  558]:	worker_index: 2, step: 1942, cost: 7.053418, mlm loss: 7.053418, speed: 1.077718 steps/s, speed: 8.621742 samples/s, speed: 4414.331935 tokens/s, learning rate: 1.941e-05, loss_scalings: 5497.559082, pp_loss: 6.745116
[INFO] 2021-07-12 19:10:59,287 [run_pretraining.py:  512]:	********exe.run_1942******* 
[INFO] 2021-07-12 19:11:00,211 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:00,211 [run_pretraining.py:  534]:	loss/total_loss, 6.36488676071167, 1943
[INFO] 2021-07-12 19:11:00,211 [run_pretraining.py:  535]:	loss/mlm_loss, 6.36488676071167, 1943
[INFO] 2021-07-12 19:11:00,212 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9419998352532275e-05, 1943
[INFO] 2021-07-12 19:11:00,212 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1943
[INFO] 2021-07-12 19:11:00,212 [run_pretraining.py:  558]:	worker_index: 2, step: 1943, cost: 6.364887, mlm loss: 6.364887, speed: 1.081843 steps/s, speed: 8.654744 samples/s, speed: 4431.228686 tokens/s, learning rate: 1.942e-05, loss_scalings: 5497.559082, pp_loss: 7.652113
[INFO] 2021-07-12 19:11:00,212 [run_pretraining.py:  512]:	********exe.run_1943******* 
[INFO] 2021-07-12 19:11:01,134 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:01,135 [run_pretraining.py:  534]:	loss/total_loss, 6.694962024688721, 1944
[INFO] 2021-07-12 19:11:01,135 [run_pretraining.py:  535]:	loss/mlm_loss, 6.694962024688721, 1944
[INFO] 2021-07-12 19:11:01,135 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.942999915627297e-05, 1944
[INFO] 2021-07-12 19:11:01,135 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1944
[INFO] 2021-07-12 19:11:01,135 [run_pretraining.py:  558]:	worker_index: 2, step: 1944, cost: 6.694962, mlm loss: 6.694962, speed: 1.083801 steps/s, speed: 8.670409 samples/s, speed: 4439.249566 tokens/s, learning rate: 1.943e-05, loss_scalings: 5497.559082, pp_loss: 7.186990
[INFO] 2021-07-12 19:11:01,135 [run_pretraining.py:  512]:	********exe.run_1944******* 
[INFO] 2021-07-12 19:11:02,066 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:02,066 [run_pretraining.py:  534]:	loss/total_loss, 7.6390700340271, 1945
[INFO] 2021-07-12 19:11:02,066 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6390700340271, 1945
[INFO] 2021-07-12 19:11:02,066 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9439999960013665e-05, 1945
[INFO] 2021-07-12 19:11:02,066 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1945
[INFO] 2021-07-12 19:11:02,067 [run_pretraining.py:  558]:	worker_index: 2, step: 1945, cost: 7.639070, mlm loss: 7.639070, speed: 1.074150 steps/s, speed: 8.593197 samples/s, speed: 4399.716855 tokens/s, learning rate: 1.944e-05, loss_scalings: 4398.047363, pp_loss: 7.054427
[INFO] 2021-07-12 19:11:02,067 [run_pretraining.py:  512]:	********exe.run_1945******* 
[INFO] 2021-07-12 19:11:02,991 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:02,992 [run_pretraining.py:  534]:	loss/total_loss, 7.642101287841797, 1946
[INFO] 2021-07-12 19:11:02,992 [run_pretraining.py:  535]:	loss/mlm_loss, 7.642101287841797, 1946
[INFO] 2021-07-12 19:11:02,992 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9449998944764957e-05, 1946
[INFO] 2021-07-12 19:11:02,992 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1946
[INFO] 2021-07-12 19:11:02,992 [run_pretraining.py:  558]:	worker_index: 2, step: 1946, cost: 7.642101, mlm loss: 7.642101, speed: 1.081234 steps/s, speed: 8.649875 samples/s, speed: 4428.736165 tokens/s, learning rate: 1.945e-05, loss_scalings: 4398.047363, pp_loss: 7.359725
[INFO] 2021-07-12 19:11:02,992 [run_pretraining.py:  512]:	********exe.run_1946******* 
[INFO] 2021-07-12 19:11:29,620 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:29,620 [run_pretraining.py:  534]:	loss/total_loss, 7.3475565910339355, 1947
[INFO] 2021-07-12 19:11:29,621 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3475565910339355, 1947
[INFO] 2021-07-12 19:11:29,621 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9459999748505652e-05, 1947
[INFO] 2021-07-12 19:11:29,621 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1947
[INFO] 2021-07-12 19:11:29,621 [run_pretraining.py:  558]:	worker_index: 2, step: 1947, cost: 7.347557, mlm loss: 7.347557, speed: 0.037554 steps/s, speed: 0.300434 samples/s, speed: 153.822171 tokens/s, learning rate: 1.946e-05, loss_scalings: 4398.047363, pp_loss: 7.235229
[INFO] 2021-07-12 19:11:29,621 [run_pretraining.py:  512]:	********exe.run_1947******* 
[INFO] 2021-07-12 19:11:30,537 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:30,537 [run_pretraining.py:  534]:	loss/total_loss, 6.930975914001465, 1948
[INFO] 2021-07-12 19:11:30,538 [run_pretraining.py:  535]:	loss/mlm_loss, 6.930975914001465, 1948
[INFO] 2021-07-12 19:11:30,538 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9470000552246347e-05, 1948
[INFO] 2021-07-12 19:11:30,538 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1948
[INFO] 2021-07-12 19:11:30,538 [run_pretraining.py:  558]:	worker_index: 2, step: 1948, cost: 6.930976, mlm loss: 6.930976, speed: 1.091168 steps/s, speed: 8.729347 samples/s, speed: 4469.425743 tokens/s, learning rate: 1.947e-05, loss_scalings: 4398.047363, pp_loss: 7.337432
[INFO] 2021-07-12 19:11:30,538 [run_pretraining.py:  512]:	********exe.run_1948******* 
[INFO] 2021-07-12 19:11:31,455 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:31,456 [run_pretraining.py:  534]:	loss/total_loss, 5.3578901290893555, 1949
[INFO] 2021-07-12 19:11:31,456 [run_pretraining.py:  535]:	loss/mlm_loss, 5.3578901290893555, 1949
[INFO] 2021-07-12 19:11:31,456 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.947999953699764e-05, 1949
[INFO] 2021-07-12 19:11:31,456 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1949
[INFO] 2021-07-12 19:11:31,456 [run_pretraining.py:  558]:	worker_index: 2, step: 1949, cost: 5.357890, mlm loss: 5.357890, speed: 1.089633 steps/s, speed: 8.717065 samples/s, speed: 4463.137190 tokens/s, learning rate: 1.948e-05, loss_scalings: 4398.047363, pp_loss: 6.258314
[INFO] 2021-07-12 19:11:31,456 [run_pretraining.py:  512]:	********exe.run_1949******* 
[INFO] 2021-07-12 19:11:32,373 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:32,374 [run_pretraining.py:  534]:	loss/total_loss, 7.453616142272949, 1950
[INFO] 2021-07-12 19:11:32,374 [run_pretraining.py:  535]:	loss/mlm_loss, 7.453616142272949, 1950
[INFO] 2021-07-12 19:11:32,374 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9490000340738334e-05, 1950
[INFO] 2021-07-12 19:11:32,374 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1950
[INFO] 2021-07-12 19:11:32,374 [run_pretraining.py:  558]:	worker_index: 2, step: 1950, cost: 7.453616, mlm loss: 7.453616, speed: 1.089994 steps/s, speed: 8.719951 samples/s, speed: 4464.614847 tokens/s, learning rate: 1.949e-05, loss_scalings: 4398.047363, pp_loss: 7.281553
[INFO] 2021-07-12 19:11:32,374 [run_pretraining.py:  512]:	********exe.run_1950******* 
[INFO] 2021-07-12 19:11:33,306 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:33,307 [run_pretraining.py:  534]:	loss/total_loss, 5.9427595138549805, 1951
[INFO] 2021-07-12 19:11:33,307 [run_pretraining.py:  535]:	loss/mlm_loss, 5.9427595138549805, 1951
[INFO] 2021-07-12 19:11:33,307 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9499999325489625e-05, 1951
[INFO] 2021-07-12 19:11:33,307 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1951
[INFO] 2021-07-12 19:11:33,307 [run_pretraining.py:  558]:	worker_index: 2, step: 1951, cost: 5.942760, mlm loss: 5.942760, speed: 1.072669 steps/s, speed: 8.581354 samples/s, speed: 4393.653139 tokens/s, learning rate: 1.950e-05, loss_scalings: 4398.047363, pp_loss: 6.784854
[INFO] 2021-07-12 19:11:33,307 [run_pretraining.py:  512]:	********exe.run_1951******* 
[INFO] 2021-07-12 19:11:34,235 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:34,236 [run_pretraining.py:  534]:	loss/total_loss, 7.714078903198242, 1952
[INFO] 2021-07-12 19:11:34,236 [run_pretraining.py:  535]:	loss/mlm_loss, 7.714078903198242, 1952
[INFO] 2021-07-12 19:11:34,236 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9509998310240917e-05, 1952
[INFO] 2021-07-12 19:11:34,236 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1952
[INFO] 2021-07-12 19:11:34,236 [run_pretraining.py:  558]:	worker_index: 2, step: 1952, cost: 7.714079, mlm loss: 7.714079, speed: 1.076926 steps/s, speed: 8.615409 samples/s, speed: 4411.089220 tokens/s, learning rate: 1.951e-05, loss_scalings: 4398.047363, pp_loss: 7.283561
[INFO] 2021-07-12 19:11:34,236 [run_pretraining.py:  512]:	********exe.run_1952******* 
[INFO] 2021-07-12 19:11:35,159 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:35,159 [run_pretraining.py:  534]:	loss/total_loss, 7.274359703063965, 1953
[INFO] 2021-07-12 19:11:35,160 [run_pretraining.py:  535]:	loss/mlm_loss, 7.274359703063965, 1953
[INFO] 2021-07-12 19:11:35,160 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9519999113981612e-05, 1953
[INFO] 2021-07-12 19:11:35,160 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1953
[INFO] 2021-07-12 19:11:35,160 [run_pretraining.py:  558]:	worker_index: 2, step: 1953, cost: 7.274360, mlm loss: 7.274360, speed: 1.083451 steps/s, speed: 8.667607 samples/s, speed: 4437.815014 tokens/s, learning rate: 1.952e-05, loss_scalings: 4398.047363, pp_loss: 7.406134
[INFO] 2021-07-12 19:11:35,160 [run_pretraining.py:  512]:	********exe.run_1953******* 
[INFO] 2021-07-12 19:11:36,095 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:36,095 [run_pretraining.py:  534]:	loss/total_loss, 6.642886638641357, 1954
[INFO] 2021-07-12 19:11:36,096 [run_pretraining.py:  535]:	loss/mlm_loss, 6.642886638641357, 1954
[INFO] 2021-07-12 19:11:36,096 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9529999917722307e-05, 1954
[INFO] 2021-07-12 19:11:36,096 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1954
[INFO] 2021-07-12 19:11:36,096 [run_pretraining.py:  558]:	worker_index: 2, step: 1954, cost: 6.642887, mlm loss: 6.642887, speed: 1.069199 steps/s, speed: 8.553594 samples/s, speed: 4379.440127 tokens/s, learning rate: 1.953e-05, loss_scalings: 4398.047363, pp_loss: 6.530028
[INFO] 2021-07-12 19:11:36,096 [run_pretraining.py:  512]:	********exe.run_1954******* 
[INFO] 2021-07-12 19:11:37,032 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:37,033 [run_pretraining.py:  534]:	loss/total_loss, 7.004312992095947, 1955
[INFO] 2021-07-12 19:11:37,033 [run_pretraining.py:  535]:	loss/mlm_loss, 7.004312992095947, 1955
[INFO] 2021-07-12 19:11:37,033 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.95399989024736e-05, 1955
[INFO] 2021-07-12 19:11:37,033 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1955
[INFO] 2021-07-12 19:11:37,033 [run_pretraining.py:  558]:	worker_index: 2, step: 1955, cost: 7.004313, mlm loss: 7.004313, speed: 1.067579 steps/s, speed: 8.540633 samples/s, speed: 4372.804306 tokens/s, learning rate: 1.954e-05, loss_scalings: 4398.047363, pp_loss: 7.143040
[INFO] 2021-07-12 19:11:37,033 [run_pretraining.py:  512]:	********exe.run_1955******* 
[INFO] 2021-07-12 19:11:37,973 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:37,974 [run_pretraining.py:  534]:	loss/total_loss, 7.341693878173828, 1956
[INFO] 2021-07-12 19:11:37,974 [run_pretraining.py:  535]:	loss/mlm_loss, 7.341693878173828, 1956
[INFO] 2021-07-12 19:11:37,974 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9549999706214294e-05, 1956
[INFO] 2021-07-12 19:11:37,974 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1956
[INFO] 2021-07-12 19:11:37,974 [run_pretraining.py:  558]:	worker_index: 2, step: 1956, cost: 7.341694, mlm loss: 7.341694, speed: 1.063448 steps/s, speed: 8.507584 samples/s, speed: 4355.883234 tokens/s, learning rate: 1.955e-05, loss_scalings: 4398.047363, pp_loss: 7.590472
[INFO] 2021-07-12 19:11:37,974 [run_pretraining.py:  512]:	********exe.run_1956******* 
[INFO] 2021-07-12 19:11:38,907 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:38,908 [run_pretraining.py:  534]:	loss/total_loss, 7.3205976486206055, 1957
[INFO] 2021-07-12 19:11:38,908 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3205976486206055, 1957
[INFO] 2021-07-12 19:11:38,908 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.956000050995499e-05, 1957
[INFO] 2021-07-12 19:11:38,908 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1957
[INFO] 2021-07-12 19:11:38,908 [run_pretraining.py:  558]:	worker_index: 2, step: 1957, cost: 7.320598, mlm loss: 7.320598, speed: 1.071090 steps/s, speed: 8.568718 samples/s, speed: 4387.183704 tokens/s, learning rate: 1.956e-05, loss_scalings: 4398.047363, pp_loss: 7.231076
[INFO] 2021-07-12 19:11:38,908 [run_pretraining.py:  512]:	********exe.run_1957******* 
[INFO] 2021-07-12 19:11:39,825 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:39,826 [run_pretraining.py:  534]:	loss/total_loss, 7.29672384262085, 1958
[INFO] 2021-07-12 19:11:39,826 [run_pretraining.py:  535]:	loss/mlm_loss, 7.29672384262085, 1958
[INFO] 2021-07-12 19:11:39,826 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.956999949470628e-05, 1958
[INFO] 2021-07-12 19:11:39,826 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1958
[INFO] 2021-07-12 19:11:39,826 [run_pretraining.py:  558]:	worker_index: 2, step: 1958, cost: 7.296724, mlm loss: 7.296724, speed: 1.090222 steps/s, speed: 8.721780 samples/s, speed: 4465.551358 tokens/s, learning rate: 1.957e-05, loss_scalings: 4398.047363, pp_loss: 7.362247
[INFO] 2021-07-12 19:11:39,826 [run_pretraining.py:  512]:	********exe.run_1958******* 
[INFO] 2021-07-12 19:11:40,742 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:40,742 [run_pretraining.py:  534]:	loss/total_loss, 7.731409072875977, 1959
[INFO] 2021-07-12 19:11:40,742 [run_pretraining.py:  535]:	loss/mlm_loss, 7.731409072875977, 1959
[INFO] 2021-07-12 19:11:40,743 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9580000298446976e-05, 1959
[INFO] 2021-07-12 19:11:40,743 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1959
[INFO] 2021-07-12 19:11:40,743 [run_pretraining.py:  558]:	worker_index: 2, step: 1959, cost: 7.731409, mlm loss: 7.731409, speed: 1.091657 steps/s, speed: 8.733260 samples/s, speed: 4471.428883 tokens/s, learning rate: 1.958e-05, loss_scalings: 4398.047363, pp_loss: 7.316715
[INFO] 2021-07-12 19:11:40,743 [run_pretraining.py:  512]:	********exe.run_1959******* 
[INFO] 2021-07-12 19:11:41,675 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:41,676 [run_pretraining.py:  534]:	loss/total_loss, 7.210946083068848, 1960
[INFO] 2021-07-12 19:11:41,676 [run_pretraining.py:  535]:	loss/mlm_loss, 7.210946083068848, 1960
[INFO] 2021-07-12 19:11:41,676 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9589999283198267e-05, 1960
[INFO] 2021-07-12 19:11:41,676 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1960
[INFO] 2021-07-12 19:11:41,676 [run_pretraining.py:  558]:	worker_index: 2, step: 1960, cost: 7.210946, mlm loss: 7.210946, speed: 1.071975 steps/s, speed: 8.575796 samples/s, speed: 4390.807650 tokens/s, learning rate: 1.959e-05, loss_scalings: 4398.047363, pp_loss: 7.537320
[INFO] 2021-07-12 19:11:41,676 [run_pretraining.py:  512]:	********exe.run_1960******* 
[INFO] 2021-07-12 19:11:42,586 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:42,587 [run_pretraining.py:  534]:	loss/total_loss, 7.6865386962890625, 1961
[INFO] 2021-07-12 19:11:42,587 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6865386962890625, 1961
[INFO] 2021-07-12 19:11:42,587 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.959999826794956e-05, 1961
[INFO] 2021-07-12 19:11:42,587 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1961
[INFO] 2021-07-12 19:11:42,587 [run_pretraining.py:  558]:	worker_index: 2, step: 1961, cost: 7.686539, mlm loss: 7.686539, speed: 1.098594 steps/s, speed: 8.788756 samples/s, speed: 4499.842893 tokens/s, learning rate: 1.960e-05, loss_scalings: 4398.047363, pp_loss: 7.426368
[INFO] 2021-07-12 19:11:42,587 [run_pretraining.py:  512]:	********exe.run_1961******* 
[INFO] 2021-07-12 19:11:43,520 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:43,520 [run_pretraining.py:  534]:	loss/total_loss, 7.526423454284668, 1962
[INFO] 2021-07-12 19:11:43,520 [run_pretraining.py:  535]:	loss/mlm_loss, 7.526423454284668, 1962
[INFO] 2021-07-12 19:11:43,520 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9609999071690254e-05, 1962
[INFO] 2021-07-12 19:11:43,520 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1962
[INFO] 2021-07-12 19:11:43,520 [run_pretraining.py:  558]:	worker_index: 2, step: 1962, cost: 7.526423, mlm loss: 7.526423, speed: 1.071967 steps/s, speed: 8.575739 samples/s, speed: 4390.778473 tokens/s, learning rate: 1.961e-05, loss_scalings: 4398.047363, pp_loss: 7.322943
[INFO] 2021-07-12 19:11:43,520 [run_pretraining.py:  512]:	********exe.run_1962******* 
[INFO] 2021-07-12 19:11:44,446 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:44,446 [run_pretraining.py:  534]:	loss/total_loss, 7.319181442260742, 1963
[INFO] 2021-07-12 19:11:44,446 [run_pretraining.py:  535]:	loss/mlm_loss, 7.319181442260742, 1963
[INFO] 2021-07-12 19:11:44,446 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.961999987543095e-05, 1963
[INFO] 2021-07-12 19:11:44,447 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1963
[INFO] 2021-07-12 19:11:44,447 [run_pretraining.py:  558]:	worker_index: 2, step: 1963, cost: 7.319181, mlm loss: 7.319181, speed: 1.080441 steps/s, speed: 8.643529 samples/s, speed: 4425.487080 tokens/s, learning rate: 1.962e-05, loss_scalings: 4398.047363, pp_loss: 7.489690
[INFO] 2021-07-12 19:11:44,447 [run_pretraining.py:  512]:	********exe.run_1963******* 
[INFO] 2021-07-12 19:11:45,377 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:45,377 [run_pretraining.py:  534]:	loss/total_loss, 8.122795104980469, 1964
[INFO] 2021-07-12 19:11:45,378 [run_pretraining.py:  535]:	loss/mlm_loss, 8.122795104980469, 1964
[INFO] 2021-07-12 19:11:45,378 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.962999886018224e-05, 1964
[INFO] 2021-07-12 19:11:45,378 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1964
[INFO] 2021-07-12 19:11:45,378 [run_pretraining.py:  558]:	worker_index: 2, step: 1964, cost: 8.122795, mlm loss: 8.122795, speed: 1.074544 steps/s, speed: 8.596354 samples/s, speed: 4401.333215 tokens/s, learning rate: 1.963e-05, loss_scalings: 4398.047363, pp_loss: 7.560937
[INFO] 2021-07-12 19:11:45,378 [run_pretraining.py:  512]:	********exe.run_1964******* 
[INFO] 2021-07-12 19:11:46,298 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:46,299 [run_pretraining.py:  534]:	loss/total_loss, 6.551491737365723, 1965
[INFO] 2021-07-12 19:11:46,299 [run_pretraining.py:  535]:	loss/mlm_loss, 6.551491737365723, 1965
[INFO] 2021-07-12 19:11:46,299 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9639999663922936e-05, 1965
[INFO] 2021-07-12 19:11:46,299 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1965
[INFO] 2021-07-12 19:11:46,299 [run_pretraining.py:  558]:	worker_index: 2, step: 1965, cost: 6.551492, mlm loss: 6.551492, speed: 1.085968 steps/s, speed: 8.687742 samples/s, speed: 4448.123989 tokens/s, learning rate: 1.964e-05, loss_scalings: 4398.047363, pp_loss: 6.996993
[INFO] 2021-07-12 19:11:46,299 [run_pretraining.py:  512]:	********exe.run_1965******* 
[INFO] 2021-07-12 19:11:47,241 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:47,242 [run_pretraining.py:  534]:	loss/total_loss, 7.235228538513184, 1966
[INFO] 2021-07-12 19:11:47,242 [run_pretraining.py:  535]:	loss/mlm_loss, 7.235228538513184, 1966
[INFO] 2021-07-12 19:11:47,242 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.965000046766363e-05, 1966
[INFO] 2021-07-12 19:11:47,242 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1966
[INFO] 2021-07-12 19:11:47,242 [run_pretraining.py:  558]:	worker_index: 2, step: 1966, cost: 7.235229, mlm loss: 7.235229, speed: 1.061549 steps/s, speed: 8.492389 samples/s, speed: 4348.103292 tokens/s, learning rate: 1.965e-05, loss_scalings: 3518.437988, pp_loss: 7.068833
[INFO] 2021-07-12 19:11:47,242 [run_pretraining.py:  512]:	********exe.run_1966******* 
[INFO] 2021-07-12 19:11:48,158 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:48,159 [run_pretraining.py:  534]:	loss/total_loss, 7.757483959197998, 1967
[INFO] 2021-07-12 19:11:48,159 [run_pretraining.py:  535]:	loss/mlm_loss, 7.757483959197998, 1967
[INFO] 2021-07-12 19:11:48,159 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9659999452414922e-05, 1967
[INFO] 2021-07-12 19:11:48,159 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1967
[INFO] 2021-07-12 19:11:48,159 [run_pretraining.py:  558]:	worker_index: 2, step: 1967, cost: 7.757484, mlm loss: 7.757484, speed: 1.091037 steps/s, speed: 8.728298 samples/s, speed: 4468.888621 tokens/s, learning rate: 1.966e-05, loss_scalings: 3518.437988, pp_loss: 6.554460
[INFO] 2021-07-12 19:11:48,159 [run_pretraining.py:  512]:	********exe.run_1967******* 
[INFO] 2021-07-12 19:11:49,088 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:49,088 [run_pretraining.py:  534]:	loss/total_loss, 7.249855041503906, 1968
[INFO] 2021-07-12 19:11:49,088 [run_pretraining.py:  535]:	loss/mlm_loss, 7.249855041503906, 1968
[INFO] 2021-07-12 19:11:49,089 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9670000256155618e-05, 1968
[INFO] 2021-07-12 19:11:49,089 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1968
[INFO] 2021-07-12 19:11:49,089 [run_pretraining.py:  558]:	worker_index: 2, step: 1968, cost: 7.249855, mlm loss: 7.249855, speed: 1.076303 steps/s, speed: 8.610428 samples/s, speed: 4408.538975 tokens/s, learning rate: 1.967e-05, loss_scalings: 3518.437988, pp_loss: 7.201109
[INFO] 2021-07-12 19:11:49,089 [run_pretraining.py:  512]:	********exe.run_1968******* 
[INFO] 2021-07-12 19:11:50,008 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:50,008 [run_pretraining.py:  534]:	loss/total_loss, 7.475221633911133, 1969
[INFO] 2021-07-12 19:11:50,008 [run_pretraining.py:  535]:	loss/mlm_loss, 7.475221633911133, 1969
[INFO] 2021-07-12 19:11:50,009 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.967999924090691e-05, 1969
[INFO] 2021-07-12 19:11:50,009 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1969
[INFO] 2021-07-12 19:11:50,009 [run_pretraining.py:  558]:	worker_index: 2, step: 1969, cost: 7.475222, mlm loss: 7.475222, speed: 1.087649 steps/s, speed: 8.701194 samples/s, speed: 4455.011351 tokens/s, learning rate: 1.968e-05, loss_scalings: 3518.437988, pp_loss: 6.927931
[INFO] 2021-07-12 19:11:50,009 [run_pretraining.py:  512]:	********exe.run_1969******* 
[INFO] 2021-07-12 19:11:50,934 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:50,935 [run_pretraining.py:  534]:	loss/total_loss, 8.27658748626709, 1970
[INFO] 2021-07-12 19:11:50,935 [run_pretraining.py:  535]:	loss/mlm_loss, 8.27658748626709, 1970
[INFO] 2021-07-12 19:11:50,935 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.96899982256582e-05, 1970
[INFO] 2021-07-12 19:11:50,935 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1970
[INFO] 2021-07-12 19:11:50,935 [run_pretraining.py:  558]:	worker_index: 2, step: 1970, cost: 8.276587, mlm loss: 8.276587, speed: 1.080151 steps/s, speed: 8.641208 samples/s, speed: 4424.298386 tokens/s, learning rate: 1.969e-05, loss_scalings: 3518.437988, pp_loss: 7.597231
[INFO] 2021-07-12 19:11:50,935 [run_pretraining.py:  512]:	********exe.run_1970******* 
[INFO] 2021-07-12 19:11:51,857 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:51,858 [run_pretraining.py:  534]:	loss/total_loss, 6.996841907501221, 1971
[INFO] 2021-07-12 19:11:51,858 [run_pretraining.py:  535]:	loss/mlm_loss, 6.996841907501221, 1971
[INFO] 2021-07-12 19:11:51,858 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9699999029398896e-05, 1971
[INFO] 2021-07-12 19:11:51,858 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1971
[INFO] 2021-07-12 19:11:51,858 [run_pretraining.py:  558]:	worker_index: 2, step: 1971, cost: 6.996842, mlm loss: 6.996842, speed: 1.083931 steps/s, speed: 8.671445 samples/s, speed: 4439.779587 tokens/s, learning rate: 1.970e-05, loss_scalings: 3518.437988, pp_loss: 7.485358
[INFO] 2021-07-12 19:11:51,858 [run_pretraining.py:  512]:	********exe.run_1971******* 
[INFO] 2021-07-12 19:11:52,779 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:52,779 [run_pretraining.py:  534]:	loss/total_loss, 7.0953216552734375, 1972
[INFO] 2021-07-12 19:11:52,779 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0953216552734375, 1972
[INFO] 2021-07-12 19:11:52,779 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.970999983313959e-05, 1972
[INFO] 2021-07-12 19:11:52,780 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1972
[INFO] 2021-07-12 19:11:52,780 [run_pretraining.py:  558]:	worker_index: 2, step: 1972, cost: 7.095322, mlm loss: 7.095322, speed: 1.086077 steps/s, speed: 8.688613 samples/s, speed: 4448.569736 tokens/s, learning rate: 1.971e-05, loss_scalings: 3518.437988, pp_loss: 7.485039
[INFO] 2021-07-12 19:11:52,780 [run_pretraining.py:  512]:	********exe.run_1972******* 
[INFO] 2021-07-12 19:11:53,699 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:53,699 [run_pretraining.py:  534]:	loss/total_loss, 7.567855358123779, 1973
[INFO] 2021-07-12 19:11:53,699 [run_pretraining.py:  535]:	loss/mlm_loss, 7.567855358123779, 1973
[INFO] 2021-07-12 19:11:53,699 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9719998817890882e-05, 1973
[INFO] 2021-07-12 19:11:53,699 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1973
[INFO] 2021-07-12 19:11:53,700 [run_pretraining.py:  558]:	worker_index: 2, step: 1973, cost: 7.567855, mlm loss: 7.567855, speed: 1.087776 steps/s, speed: 8.702210 samples/s, speed: 4455.531277 tokens/s, learning rate: 1.972e-05, loss_scalings: 3518.437988, pp_loss: 7.390039
[INFO] 2021-07-12 19:11:53,700 [run_pretraining.py:  512]:	********exe.run_1973******* 
[INFO] 2021-07-12 19:11:54,624 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:54,625 [run_pretraining.py:  534]:	loss/total_loss, 6.940450668334961, 1974
[INFO] 2021-07-12 19:11:54,625 [run_pretraining.py:  535]:	loss/mlm_loss, 6.940450668334961, 1974
[INFO] 2021-07-12 19:11:54,625 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9729999621631578e-05, 1974
[INFO] 2021-07-12 19:11:54,625 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1974
[INFO] 2021-07-12 19:11:54,625 [run_pretraining.py:  558]:	worker_index: 2, step: 1974, cost: 6.940451, mlm loss: 6.940451, speed: 1.081035 steps/s, speed: 8.648281 samples/s, speed: 4427.920023 tokens/s, learning rate: 1.973e-05, loss_scalings: 3518.437988, pp_loss: 7.218064
[INFO] 2021-07-12 19:11:54,625 [run_pretraining.py:  512]:	********exe.run_1974******* 
[INFO] 2021-07-12 19:11:55,574 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:55,574 [run_pretraining.py:  534]:	loss/total_loss, 6.91022253036499, 1975
[INFO] 2021-07-12 19:11:55,574 [run_pretraining.py:  535]:	loss/mlm_loss, 6.91022253036499, 1975
[INFO] 2021-07-12 19:11:55,575 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9740000425372273e-05, 1975
[INFO] 2021-07-12 19:11:55,575 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1975
[INFO] 2021-07-12 19:11:55,575 [run_pretraining.py:  558]:	worker_index: 2, step: 1975, cost: 6.910223, mlm loss: 6.910223, speed: 1.053855 steps/s, speed: 8.430842 samples/s, speed: 4316.591260 tokens/s, learning rate: 1.974e-05, loss_scalings: 3518.437988, pp_loss: 6.951868
[INFO] 2021-07-12 19:11:55,575 [run_pretraining.py:  512]:	********exe.run_1975******* 
[INFO] 2021-07-12 19:11:56,513 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:56,513 [run_pretraining.py:  534]:	loss/total_loss, 7.119366645812988, 1976
[INFO] 2021-07-12 19:11:56,513 [run_pretraining.py:  535]:	loss/mlm_loss, 7.119366645812988, 1976
[INFO] 2021-07-12 19:11:56,514 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9749999410123564e-05, 1976
[INFO] 2021-07-12 19:11:56,514 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1976
[INFO] 2021-07-12 19:11:56,514 [run_pretraining.py:  558]:	worker_index: 2, step: 1976, cost: 7.119367, mlm loss: 7.119367, speed: 1.065609 steps/s, speed: 8.524872 samples/s, speed: 4364.734300 tokens/s, learning rate: 1.975e-05, loss_scalings: 3518.437988, pp_loss: 6.997199
[INFO] 2021-07-12 19:11:56,514 [run_pretraining.py:  512]:	********exe.run_1976******* 
[INFO] 2021-07-12 19:11:57,433 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:57,434 [run_pretraining.py:  534]:	loss/total_loss, 7.744929790496826, 1977
[INFO] 2021-07-12 19:11:57,434 [run_pretraining.py:  535]:	loss/mlm_loss, 7.744929790496826, 1977
[INFO] 2021-07-12 19:11:57,434 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.976000021386426e-05, 1977
[INFO] 2021-07-12 19:11:57,434 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1977
[INFO] 2021-07-12 19:11:57,434 [run_pretraining.py:  558]:	worker_index: 2, step: 1977, cost: 7.744930, mlm loss: 7.744930, speed: 1.087463 steps/s, speed: 8.699701 samples/s, speed: 4454.246704 tokens/s, learning rate: 1.976e-05, loss_scalings: 3518.437988, pp_loss: 7.527722
[INFO] 2021-07-12 19:11:57,434 [run_pretraining.py:  512]:	********exe.run_1977******* 
[INFO] 2021-07-12 19:11:58,354 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:58,354 [run_pretraining.py:  534]:	loss/total_loss, 4.433772563934326, 1978
[INFO] 2021-07-12 19:11:58,354 [run_pretraining.py:  535]:	loss/mlm_loss, 4.433772563934326, 1978
[INFO] 2021-07-12 19:11:58,355 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.976999919861555e-05, 1978
[INFO] 2021-07-12 19:11:58,355 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1978
[INFO] 2021-07-12 19:11:58,355 [run_pretraining.py:  558]:	worker_index: 2, step: 1978, cost: 4.433773, mlm loss: 4.433773, speed: 1.086668 steps/s, speed: 8.693347 samples/s, speed: 4450.993536 tokens/s, learning rate: 1.977e-05, loss_scalings: 3518.437988, pp_loss: 6.694223
[INFO] 2021-07-12 19:11:58,355 [run_pretraining.py:  512]:	********exe.run_1978******* 
[INFO] 2021-07-12 19:11:59,272 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:59,272 [run_pretraining.py:  534]:	loss/total_loss, 7.469146251678467, 1979
[INFO] 2021-07-12 19:11:59,273 [run_pretraining.py:  535]:	loss/mlm_loss, 7.469146251678467, 1979
[INFO] 2021-07-12 19:11:59,273 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9779998183366843e-05, 1979
[INFO] 2021-07-12 19:11:59,273 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1979
[INFO] 2021-07-12 19:11:59,273 [run_pretraining.py:  558]:	worker_index: 2, step: 1979, cost: 7.469146, mlm loss: 7.469146, speed: 1.089925 steps/s, speed: 8.719398 samples/s, speed: 4464.331766 tokens/s, learning rate: 1.978e-05, loss_scalings: 3518.437988, pp_loss: 7.715033
[INFO] 2021-07-12 19:11:59,273 [run_pretraining.py:  512]:	********exe.run_1979******* 
[INFO] 2021-07-12 19:12:00,196 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:00,196 [run_pretraining.py:  534]:	loss/total_loss, 7.34731388092041, 1980
[INFO] 2021-07-12 19:12:00,196 [run_pretraining.py:  535]:	loss/mlm_loss, 7.34731388092041, 1980
[INFO] 2021-07-12 19:12:00,196 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9789998987107538e-05, 1980
[INFO] 2021-07-12 19:12:00,197 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1980
[INFO] 2021-07-12 19:12:00,197 [run_pretraining.py:  558]:	worker_index: 2, step: 1980, cost: 7.347314, mlm loss: 7.347314, speed: 1.083269 steps/s, speed: 8.666152 samples/s, speed: 4437.070009 tokens/s, learning rate: 1.979e-05, loss_scalings: 3518.437988, pp_loss: 7.030849
[INFO] 2021-07-12 19:12:00,197 [run_pretraining.py:  512]:	********exe.run_1980******* 
[INFO] 2021-07-12 19:12:01,123 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:01,123 [run_pretraining.py:  534]:	loss/total_loss, 6.750866413116455, 1981
[INFO] 2021-07-12 19:12:01,123 [run_pretraining.py:  535]:	loss/mlm_loss, 6.750866413116455, 1981
[INFO] 2021-07-12 19:12:01,124 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9799999790848233e-05, 1981
[INFO] 2021-07-12 19:12:01,124 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1981
[INFO] 2021-07-12 19:12:01,124 [run_pretraining.py:  558]:	worker_index: 2, step: 1981, cost: 6.750866, mlm loss: 6.750866, speed: 1.079333 steps/s, speed: 8.634666 samples/s, speed: 4420.948865 tokens/s, learning rate: 1.980e-05, loss_scalings: 3518.437988, pp_loss: 6.830284
[INFO] 2021-07-12 19:12:01,124 [run_pretraining.py:  512]:	********exe.run_1981******* 
[INFO] 2021-07-12 19:12:02,053 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:02,054 [run_pretraining.py:  534]:	loss/total_loss, 7.713080406188965, 1982
[INFO] 2021-07-12 19:12:02,054 [run_pretraining.py:  535]:	loss/mlm_loss, 7.713080406188965, 1982
[INFO] 2021-07-12 19:12:02,054 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9809998775599524e-05, 1982
[INFO] 2021-07-12 19:12:02,054 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1982
[INFO] 2021-07-12 19:12:02,054 [run_pretraining.py:  558]:	worker_index: 2, step: 1982, cost: 7.713080, mlm loss: 7.713080, speed: 1.075389 steps/s, speed: 8.603109 samples/s, speed: 4404.791974 tokens/s, learning rate: 1.981e-05, loss_scalings: 3518.437988, pp_loss: 7.607026
[INFO] 2021-07-12 19:12:02,054 [run_pretraining.py:  512]:	********exe.run_1982******* 
[INFO] 2021-07-12 19:12:02,985 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:02,985 [run_pretraining.py:  534]:	loss/total_loss, 6.984737396240234, 1983
[INFO] 2021-07-12 19:12:02,985 [run_pretraining.py:  535]:	loss/mlm_loss, 6.984737396240234, 1983
[INFO] 2021-07-12 19:12:02,986 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.981999957934022e-05, 1983
[INFO] 2021-07-12 19:12:02,986 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1983
[INFO] 2021-07-12 19:12:02,986 [run_pretraining.py:  558]:	worker_index: 2, step: 1983, cost: 6.984737, mlm loss: 6.984737, speed: 1.074320 steps/s, speed: 8.594559 samples/s, speed: 4400.414427 tokens/s, learning rate: 1.982e-05, loss_scalings: 3518.437988, pp_loss: 7.404234
[INFO] 2021-07-12 19:12:02,986 [run_pretraining.py:  512]:	********exe.run_1983******* 
[INFO] 2021-07-12 19:12:03,912 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:03,912 [run_pretraining.py:  534]:	loss/total_loss, 8.066526412963867, 1984
[INFO] 2021-07-12 19:12:03,912 [run_pretraining.py:  535]:	loss/mlm_loss, 8.066526412963867, 1984
[INFO] 2021-07-12 19:12:03,912 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9830000383080915e-05, 1984
[INFO] 2021-07-12 19:12:03,912 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1984
[INFO] 2021-07-12 19:12:03,913 [run_pretraining.py:  558]:	worker_index: 2, step: 1984, cost: 8.066526, mlm loss: 8.066526, speed: 1.079664 steps/s, speed: 8.637313 samples/s, speed: 4422.304230 tokens/s, learning rate: 1.983e-05, loss_scalings: 3518.437988, pp_loss: 6.726885
[INFO] 2021-07-12 19:12:03,913 [run_pretraining.py:  512]:	********exe.run_1984******* 
[INFO] 2021-07-12 19:12:04,841 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:04,841 [run_pretraining.py:  534]:	loss/total_loss, 6.809967041015625, 1985
[INFO] 2021-07-12 19:12:04,841 [run_pretraining.py:  535]:	loss/mlm_loss, 6.809967041015625, 1985
[INFO] 2021-07-12 19:12:04,842 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9839999367832206e-05, 1985
[INFO] 2021-07-12 19:12:04,842 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1985
[INFO] 2021-07-12 19:12:04,842 [run_pretraining.py:  558]:	worker_index: 2, step: 1985, cost: 6.809967, mlm loss: 6.809967, speed: 1.076964 steps/s, speed: 8.615714 samples/s, speed: 4411.245522 tokens/s, learning rate: 1.984e-05, loss_scalings: 3518.437988, pp_loss: 7.142695
[INFO] 2021-07-12 19:12:04,842 [run_pretraining.py:  512]:	********exe.run_1985******* 
[INFO] 2021-07-12 19:12:05,762 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:05,763 [run_pretraining.py:  534]:	loss/total_loss, 7.663072109222412, 1986
[INFO] 2021-07-12 19:12:05,763 [run_pretraining.py:  535]:	loss/mlm_loss, 7.663072109222412, 1986
[INFO] 2021-07-12 19:12:05,763 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.98500001715729e-05, 1986
[INFO] 2021-07-12 19:12:05,763 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1986
[INFO] 2021-07-12 19:12:05,763 [run_pretraining.py:  558]:	worker_index: 2, step: 1986, cost: 7.663072, mlm loss: 7.663072, speed: 1.086273 steps/s, speed: 8.690181 samples/s, speed: 4449.372767 tokens/s, learning rate: 1.985e-05, loss_scalings: 3518.437988, pp_loss: 7.761658
[INFO] 2021-07-12 19:12:05,763 [run_pretraining.py:  512]:	********exe.run_1986******* 
[INFO] 2021-07-12 19:12:06,709 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:06,710 [run_pretraining.py:  534]:	loss/total_loss, 7.642500877380371, 1987
[INFO] 2021-07-12 19:12:06,710 [run_pretraining.py:  535]:	loss/mlm_loss, 7.642500877380371, 1987
[INFO] 2021-07-12 19:12:06,710 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9859999156324193e-05, 1987
[INFO] 2021-07-12 19:12:06,710 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1987
[INFO] 2021-07-12 19:12:06,710 [run_pretraining.py:  558]:	worker_index: 2, step: 1987, cost: 7.642501, mlm loss: 7.642501, speed: 1.056178 steps/s, speed: 8.449421 samples/s, speed: 4326.103343 tokens/s, learning rate: 1.986e-05, loss_scalings: 3518.437988, pp_loss: 7.649460
[INFO] 2021-07-12 19:12:06,710 [run_pretraining.py:  512]:	********exe.run_1987******* 
[INFO] 2021-07-12 19:12:07,642 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:07,643 [run_pretraining.py:  534]:	loss/total_loss, 7.683063983917236, 1988
[INFO] 2021-07-12 19:12:07,643 [run_pretraining.py:  535]:	loss/mlm_loss, 7.683063983917236, 1988
[INFO] 2021-07-12 19:12:07,643 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9869999960064888e-05, 1988
[INFO] 2021-07-12 19:12:07,643 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1988
[INFO] 2021-07-12 19:12:07,643 [run_pretraining.py:  558]:	worker_index: 2, step: 1988, cost: 7.683064, mlm loss: 7.683064, speed: 1.072711 steps/s, speed: 8.581687 samples/s, speed: 4393.823941 tokens/s, learning rate: 1.987e-05, loss_scalings: 3518.437988, pp_loss: 7.285012
[INFO] 2021-07-12 19:12:07,643 [run_pretraining.py:  512]:	********exe.run_1988******* 
[INFO] 2021-07-12 19:12:08,562 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:08,563 [run_pretraining.py:  534]:	loss/total_loss, 7.380484104156494, 1989
[INFO] 2021-07-12 19:12:08,563 [run_pretraining.py:  535]:	loss/mlm_loss, 7.380484104156494, 1989
[INFO] 2021-07-12 19:12:08,563 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.987999894481618e-05, 1989
[INFO] 2021-07-12 19:12:08,563 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1989
[INFO] 2021-07-12 19:12:08,563 [run_pretraining.py:  558]:	worker_index: 2, step: 1989, cost: 7.380484, mlm loss: 7.380484, speed: 1.087503 steps/s, speed: 8.700023 samples/s, speed: 4454.411855 tokens/s, learning rate: 1.988e-05, loss_scalings: 3518.437988, pp_loss: 7.413239
[INFO] 2021-07-12 19:12:08,563 [run_pretraining.py:  512]:	********exe.run_1989******* 
[INFO] 2021-07-12 19:12:09,510 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:09,511 [run_pretraining.py:  534]:	loss/total_loss, 8.438447952270508, 1990
[INFO] 2021-07-12 19:12:09,511 [run_pretraining.py:  535]:	loss/mlm_loss, 8.438447952270508, 1990
[INFO] 2021-07-12 19:12:09,511 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9889999748556875e-05, 1990
[INFO] 2021-07-12 19:12:09,511 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1990
[INFO] 2021-07-12 19:12:09,511 [run_pretraining.py:  558]:	worker_index: 2, step: 1990, cost: 8.438448, mlm loss: 8.438448, speed: 1.055824 steps/s, speed: 8.446594 samples/s, speed: 4324.656060 tokens/s, learning rate: 1.989e-05, loss_scalings: 3518.437988, pp_loss: 7.690119
[INFO] 2021-07-12 19:12:09,511 [run_pretraining.py:  512]:	********exe.run_1990******* 
[INFO] 2021-07-12 19:12:10,455 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:10,455 [run_pretraining.py:  534]:	loss/total_loss, 7.369860649108887, 1991
[INFO] 2021-07-12 19:12:10,455 [run_pretraining.py:  535]:	loss/mlm_loss, 7.369860649108887, 1991
[INFO] 2021-07-12 19:12:10,456 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9899998733308166e-05, 1991
[INFO] 2021-07-12 19:12:10,456 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1991
[INFO] 2021-07-12 19:12:10,456 [run_pretraining.py:  558]:	worker_index: 2, step: 1991, cost: 7.369861, mlm loss: 7.369861, speed: 1.059261 steps/s, speed: 8.474086 samples/s, speed: 4338.732087 tokens/s, learning rate: 1.990e-05, loss_scalings: 3518.437988, pp_loss: 7.295477
[INFO] 2021-07-12 19:12:10,456 [run_pretraining.py:  512]:	********exe.run_1991******* 
[INFO] 2021-07-12 19:12:11,394 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:11,394 [run_pretraining.py:  534]:	loss/total_loss, 7.921008110046387, 1992
[INFO] 2021-07-12 19:12:11,395 [run_pretraining.py:  535]:	loss/mlm_loss, 7.921008110046387, 1992
[INFO] 2021-07-12 19:12:11,395 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.990999953704886e-05, 1992
[INFO] 2021-07-12 19:12:11,395 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1992
[INFO] 2021-07-12 19:12:11,395 [run_pretraining.py:  558]:	worker_index: 2, step: 1992, cost: 7.921008, mlm loss: 7.921008, speed: 1.065587 steps/s, speed: 8.524698 samples/s, speed: 4364.645589 tokens/s, learning rate: 1.991e-05, loss_scalings: 3518.437988, pp_loss: 7.505773
[INFO] 2021-07-12 19:12:11,395 [run_pretraining.py:  512]:	********exe.run_1992******* 
[INFO] 2021-07-12 19:12:12,326 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:12,327 [run_pretraining.py:  534]:	loss/total_loss, 6.994770050048828, 1993
[INFO] 2021-07-12 19:12:12,327 [run_pretraining.py:  535]:	loss/mlm_loss, 6.994770050048828, 1993
[INFO] 2021-07-12 19:12:12,327 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9920000340789557e-05, 1993
[INFO] 2021-07-12 19:12:12,327 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1993
[INFO] 2021-07-12 19:12:12,327 [run_pretraining.py:  558]:	worker_index: 2, step: 1993, cost: 6.994770, mlm loss: 6.994770, speed: 1.073444 steps/s, speed: 8.587554 samples/s, speed: 4396.827499 tokens/s, learning rate: 1.992e-05, loss_scalings: 3518.437988, pp_loss: 7.116821
[INFO] 2021-07-12 19:12:12,327 [run_pretraining.py:  512]:	********exe.run_1993******* 
[INFO] 2021-07-12 19:12:13,268 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:13,268 [run_pretraining.py:  534]:	loss/total_loss, 4.8097243309021, 1994
[INFO] 2021-07-12 19:12:13,269 [run_pretraining.py:  535]:	loss/mlm_loss, 4.8097243309021, 1994
[INFO] 2021-07-12 19:12:13,269 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9929999325540848e-05, 1994
[INFO] 2021-07-12 19:12:13,269 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1994
[INFO] 2021-07-12 19:12:13,269 [run_pretraining.py:  558]:	worker_index: 2, step: 1994, cost: 4.809724, mlm loss: 4.809724, speed: 1.062510 steps/s, speed: 8.500080 samples/s, speed: 4352.041050 tokens/s, learning rate: 1.993e-05, loss_scalings: 3518.437988, pp_loss: 5.711277
[INFO] 2021-07-12 19:12:13,269 [run_pretraining.py:  512]:	********exe.run_1994******* 
[INFO] 2021-07-12 19:12:14,214 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:14,215 [run_pretraining.py:  534]:	loss/total_loss, 7.174055576324463, 1995
[INFO] 2021-07-12 19:12:14,215 [run_pretraining.py:  535]:	loss/mlm_loss, 7.174055576324463, 1995
[INFO] 2021-07-12 19:12:14,215 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.993999831029214e-05, 1995
[INFO] 2021-07-12 19:12:14,215 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1995
[INFO] 2021-07-12 19:12:14,215 [run_pretraining.py:  558]:	worker_index: 2, step: 1995, cost: 7.174056, mlm loss: 7.174056, speed: 1.057323 steps/s, speed: 8.458584 samples/s, speed: 4330.794879 tokens/s, learning rate: 1.994e-05, loss_scalings: 3518.437988, pp_loss: 7.238946
[INFO] 2021-07-12 19:12:14,215 [run_pretraining.py:  512]:	********exe.run_1995******* 
[INFO] 2021-07-12 19:12:15,132 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:15,132 [run_pretraining.py:  534]:	loss/total_loss, 7.905527591705322, 1996
[INFO] 2021-07-12 19:12:15,132 [run_pretraining.py:  535]:	loss/mlm_loss, 7.905527591705322, 1996
[INFO] 2021-07-12 19:12:15,132 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9949999114032835e-05, 1996
[INFO] 2021-07-12 19:12:15,132 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1996
[INFO] 2021-07-12 19:12:15,132 [run_pretraining.py:  558]:	worker_index: 2, step: 1996, cost: 7.905528, mlm loss: 7.905528, speed: 1.091031 steps/s, speed: 8.728248 samples/s, speed: 4468.863047 tokens/s, learning rate: 1.995e-05, loss_scalings: 3518.437988, pp_loss: 7.745463
[INFO] 2021-07-12 19:12:15,132 [run_pretraining.py:  512]:	********exe.run_1996******* 
[INFO] 2021-07-12 19:12:16,051 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:16,052 [run_pretraining.py:  534]:	loss/total_loss, 7.263027191162109, 1997
[INFO] 2021-07-12 19:12:16,052 [run_pretraining.py:  535]:	loss/mlm_loss, 7.263027191162109, 1997
[INFO] 2021-07-12 19:12:16,052 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.995999991777353e-05, 1997
[INFO] 2021-07-12 19:12:16,052 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1997
[INFO] 2021-07-12 19:12:16,052 [run_pretraining.py:  558]:	worker_index: 2, step: 1997, cost: 7.263027, mlm loss: 7.263027, speed: 1.088006 steps/s, speed: 8.704045 samples/s, speed: 4456.470916 tokens/s, learning rate: 1.996e-05, loss_scalings: 3518.437988, pp_loss: 7.101312
[INFO] 2021-07-12 19:12:16,052 [run_pretraining.py:  512]:	********exe.run_1997******* 
[INFO] 2021-07-12 19:12:17,000 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:17,001 [run_pretraining.py:  534]:	loss/total_loss, 7.296502113342285, 1998
[INFO] 2021-07-12 19:12:17,001 [run_pretraining.py:  535]:	loss/mlm_loss, 7.296502113342285, 1998
[INFO] 2021-07-12 19:12:17,001 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.996999890252482e-05, 1998
[INFO] 2021-07-12 19:12:17,001 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1998
[INFO] 2021-07-12 19:12:17,001 [run_pretraining.py:  558]:	worker_index: 2, step: 1998, cost: 7.296502, mlm loss: 7.296502, speed: 1.054437 steps/s, speed: 8.435495 samples/s, speed: 4318.973229 tokens/s, learning rate: 1.997e-05, loss_scalings: 3518.437988, pp_loss: 7.388417
[INFO] 2021-07-12 19:12:17,001 [run_pretraining.py:  512]:	********exe.run_1998******* 
[INFO] 2021-07-12 19:12:17,915 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:17,916 [run_pretraining.py:  534]:	loss/total_loss, 7.924595355987549, 1999
[INFO] 2021-07-12 19:12:17,916 [run_pretraining.py:  535]:	loss/mlm_loss, 7.924595355987549, 1999
[INFO] 2021-07-12 19:12:17,916 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9979999706265517e-05, 1999
[INFO] 2021-07-12 19:12:17,916 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1999
[INFO] 2021-07-12 19:12:17,916 [run_pretraining.py:  558]:	worker_index: 2, step: 1999, cost: 7.924595, mlm loss: 7.924595, speed: 1.093420 steps/s, speed: 8.747364 samples/s, speed: 4478.650176 tokens/s, learning rate: 1.998e-05, loss_scalings: 3518.437988, pp_loss: 7.659705
[INFO] 2021-07-12 19:12:17,916 [run_pretraining.py:  512]:	********exe.run_1999******* 
[INFO] 2021-07-12 19:12:18,827 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:18,828 [run_pretraining.py:  534]:	loss/total_loss, 6.919096946716309, 2000
[INFO] 2021-07-12 19:12:18,828 [run_pretraining.py:  535]:	loss/mlm_loss, 6.919096946716309, 2000
[INFO] 2021-07-12 19:12:18,828 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9990000510006212e-05, 2000
[INFO] 2021-07-12 19:12:18,828 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2000
[INFO] 2021-07-12 19:12:18,828 [run_pretraining.py:  558]:	worker_index: 2, step: 2000, cost: 6.919097, mlm loss: 6.919097, speed: 1.097682 steps/s, speed: 8.781460 samples/s, speed: 4496.107405 tokens/s, learning rate: 1.999e-05, loss_scalings: 3518.437988, pp_loss: 7.240740
[INFO] 2021-07-12 19:12:18,828 [run_pretraining.py:  512]:	********exe.run_2000******* 
[INFO] 2021-07-12 19:12:19,732 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:19,732 [run_pretraining.py:  534]:	loss/total_loss, 7.74776029586792, 2001
[INFO] 2021-07-12 19:12:19,732 [run_pretraining.py:  535]:	loss/mlm_loss, 7.74776029586792, 2001
[INFO] 2021-07-12 19:12:19,732 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9999999494757503e-05, 2001
[INFO] 2021-07-12 19:12:19,732 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2001
[INFO] 2021-07-12 19:12:19,732 [run_pretraining.py:  558]:	worker_index: 2, step: 2001, cost: 7.747760, mlm loss: 7.747760, speed: 1.106205 steps/s, speed: 8.849643 samples/s, speed: 4531.017446 tokens/s, learning rate: 2.000e-05, loss_scalings: 3518.437988, pp_loss: 7.322771
[INFO] 2021-07-12 19:12:19,733 [run_pretraining.py:  512]:	********exe.run_2001******* 
[INFO] 2021-07-12 19:12:20,651 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:20,652 [run_pretraining.py:  534]:	loss/total_loss, 7.227656364440918, 2002
[INFO] 2021-07-12 19:12:20,652 [run_pretraining.py:  535]:	loss/mlm_loss, 7.227656364440918, 2002
[INFO] 2021-07-12 19:12:20,652 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.00100002984982e-05, 2002
[INFO] 2021-07-12 19:12:20,652 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2002
[INFO] 2021-07-12 19:12:20,652 [run_pretraining.py:  558]:	worker_index: 2, step: 2002, cost: 7.227656, mlm loss: 7.227656, speed: 1.088296 steps/s, speed: 8.706364 samples/s, speed: 4457.658457 tokens/s, learning rate: 2.001e-05, loss_scalings: 3518.437988, pp_loss: 7.136748
[INFO] 2021-07-12 19:12:20,652 [run_pretraining.py:  512]:	********exe.run_2002******* 
[INFO] 2021-07-12 19:12:21,575 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:21,575 [run_pretraining.py:  534]:	loss/total_loss, 6.927847862243652, 2003
[INFO] 2021-07-12 19:12:21,576 [run_pretraining.py:  535]:	loss/mlm_loss, 6.927847862243652, 2003
[INFO] 2021-07-12 19:12:21,576 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.001999928324949e-05, 2003
[INFO] 2021-07-12 19:12:21,576 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2003
[INFO] 2021-07-12 19:12:21,576 [run_pretraining.py:  558]:	worker_index: 2, step: 2003, cost: 6.927848, mlm loss: 6.927848, speed: 1.083195 steps/s, speed: 8.665564 samples/s, speed: 4436.768640 tokens/s, learning rate: 2.002e-05, loss_scalings: 3518.437988, pp_loss: 7.512450
[INFO] 2021-07-12 19:12:21,576 [run_pretraining.py:  512]:	********exe.run_2003******* 
[INFO] 2021-07-12 19:12:22,492 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:22,492 [run_pretraining.py:  534]:	loss/total_loss, 6.9546942710876465, 2004
[INFO] 2021-07-12 19:12:22,492 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9546942710876465, 2004
[INFO] 2021-07-12 19:12:22,492 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.002999826800078e-05, 2004
[INFO] 2021-07-12 19:12:22,492 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2004
[INFO] 2021-07-12 19:12:22,492 [run_pretraining.py:  558]:	worker_index: 2, step: 2004, cost: 6.954694, mlm loss: 6.954694, speed: 1.091597 steps/s, speed: 8.732778 samples/s, speed: 4471.182174 tokens/s, learning rate: 2.003e-05, loss_scalings: 3518.437988, pp_loss: 6.984747
[INFO] 2021-07-12 19:12:22,493 [run_pretraining.py:  512]:	********exe.run_2004******* 
[INFO] 2021-07-12 19:12:23,406 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:23,406 [run_pretraining.py:  534]:	loss/total_loss, 7.359686851501465, 2005
[INFO] 2021-07-12 19:12:23,406 [run_pretraining.py:  535]:	loss/mlm_loss, 7.359686851501465, 2005
[INFO] 2021-07-12 19:12:23,406 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0039999071741477e-05, 2005
[INFO] 2021-07-12 19:12:23,406 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2005
[INFO] 2021-07-12 19:12:23,406 [run_pretraining.py:  558]:	worker_index: 2, step: 2005, cost: 7.359687, mlm loss: 7.359687, speed: 1.094947 steps/s, speed: 8.759578 samples/s, speed: 4484.904106 tokens/s, learning rate: 2.004e-05, loss_scalings: 3518.437988, pp_loss: 7.345965
[INFO] 2021-07-12 19:12:23,406 [run_pretraining.py:  512]:	********exe.run_2005******* 
[INFO] 2021-07-12 19:12:24,324 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:24,325 [run_pretraining.py:  534]:	loss/total_loss, 7.407154083251953, 2006
[INFO] 2021-07-12 19:12:24,325 [run_pretraining.py:  535]:	loss/mlm_loss, 7.407154083251953, 2006
[INFO] 2021-07-12 19:12:24,325 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0049999875482172e-05, 2006
[INFO] 2021-07-12 19:12:24,325 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2006
[INFO] 2021-07-12 19:12:24,325 [run_pretraining.py:  558]:	worker_index: 2, step: 2006, cost: 7.407154, mlm loss: 7.407154, speed: 1.089309 steps/s, speed: 8.714470 samples/s, speed: 4461.808829 tokens/s, learning rate: 2.005e-05, loss_scalings: 3518.437988, pp_loss: 7.192533
[INFO] 2021-07-12 19:12:24,325 [run_pretraining.py:  512]:	********exe.run_2006******* 
[INFO] 2021-07-12 19:12:25,242 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:25,243 [run_pretraining.py:  534]:	loss/total_loss, 6.619771480560303, 2007
[INFO] 2021-07-12 19:12:25,243 [run_pretraining.py:  535]:	loss/mlm_loss, 6.619771480560303, 2007
[INFO] 2021-07-12 19:12:25,243 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0059998860233463e-05, 2007
[INFO] 2021-07-12 19:12:25,243 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2007
[INFO] 2021-07-12 19:12:25,243 [run_pretraining.py:  558]:	worker_index: 2, step: 2007, cost: 6.619771, mlm loss: 6.619771, speed: 1.089658 steps/s, speed: 8.717266 samples/s, speed: 4463.240385 tokens/s, learning rate: 2.006e-05, loss_scalings: 3518.437988, pp_loss: 7.175079
[INFO] 2021-07-12 19:12:25,243 [run_pretraining.py:  512]:	********exe.run_2007******* 
[INFO] 2021-07-12 19:12:26,172 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:26,173 [run_pretraining.py:  534]:	loss/total_loss, 7.266907691955566, 2008
[INFO] 2021-07-12 19:12:26,173 [run_pretraining.py:  535]:	loss/mlm_loss, 7.266907691955566, 2008
[INFO] 2021-07-12 19:12:26,173 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.006999966397416e-05, 2008
[INFO] 2021-07-12 19:12:26,173 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2008
[INFO] 2021-07-12 19:12:26,173 [run_pretraining.py:  558]:	worker_index: 2, step: 2008, cost: 7.266908, mlm loss: 7.266908, speed: 1.076495 steps/s, speed: 8.611964 samples/s, speed: 4409.325354 tokens/s, learning rate: 2.007e-05, loss_scalings: 3518.437988, pp_loss: 7.346910
[INFO] 2021-07-12 19:12:26,173 [run_pretraining.py:  512]:	********exe.run_2008******* 
[INFO] 2021-07-12 19:12:27,113 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:27,113 [run_pretraining.py:  534]:	loss/total_loss, 7.323757171630859, 2009
[INFO] 2021-07-12 19:12:27,113 [run_pretraining.py:  535]:	loss/mlm_loss, 7.323757171630859, 2009
[INFO] 2021-07-12 19:12:27,113 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0080000467714854e-05, 2009
[INFO] 2021-07-12 19:12:27,113 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2009
[INFO] 2021-07-12 19:12:27,113 [run_pretraining.py:  558]:	worker_index: 2, step: 2009, cost: 7.323757, mlm loss: 7.323757, speed: 1.063854 steps/s, speed: 8.510832 samples/s, speed: 4357.546014 tokens/s, learning rate: 2.008e-05, loss_scalings: 3518.437988, pp_loss: 7.450078
[INFO] 2021-07-12 19:12:27,114 [run_pretraining.py:  512]:	********exe.run_2009******* 
[INFO] 2021-07-12 19:12:28,049 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:28,050 [run_pretraining.py:  534]:	loss/total_loss, 7.379794597625732, 2010
[INFO] 2021-07-12 19:12:28,050 [run_pretraining.py:  535]:	loss/mlm_loss, 7.379794597625732, 2010
[INFO] 2021-07-12 19:12:28,050 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0089999452466145e-05, 2010
[INFO] 2021-07-12 19:12:28,050 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2010
[INFO] 2021-07-12 19:12:28,050 [run_pretraining.py:  558]:	worker_index: 2, step: 2010, cost: 7.379795, mlm loss: 7.379795, speed: 1.068162 steps/s, speed: 8.545295 samples/s, speed: 4375.190794 tokens/s, learning rate: 2.009e-05, loss_scalings: 3518.437988, pp_loss: 7.283961
[INFO] 2021-07-12 19:12:28,050 [run_pretraining.py:  512]:	********exe.run_2010******* 
[INFO] 2021-07-12 19:12:29,046 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:29,046 [run_pretraining.py:  534]:	loss/total_loss, 7.744090557098389, 2011
[INFO] 2021-07-12 19:12:29,047 [run_pretraining.py:  535]:	loss/mlm_loss, 7.744090557098389, 2011
[INFO] 2021-07-12 19:12:29,047 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.010000025620684e-05, 2011
[INFO] 2021-07-12 19:12:29,047 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2011
[INFO] 2021-07-12 19:12:29,047 [run_pretraining.py:  558]:	worker_index: 2, step: 2011, cost: 7.744091, mlm loss: 7.744091, speed: 1.004059 steps/s, speed: 8.032470 samples/s, speed: 4112.624821 tokens/s, learning rate: 2.010e-05, loss_scalings: 3518.437988, pp_loss: 7.568533
[INFO] 2021-07-12 19:12:29,047 [run_pretraining.py:  512]:	********exe.run_2011******* 
[INFO] 2021-07-12 19:12:29,986 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:29,986 [run_pretraining.py:  534]:	loss/total_loss, 7.500581741333008, 2012
[INFO] 2021-07-12 19:12:29,986 [run_pretraining.py:  535]:	loss/mlm_loss, 7.500581741333008, 2012
[INFO] 2021-07-12 19:12:29,986 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0110001059947535e-05, 2012
[INFO] 2021-07-12 19:12:29,986 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2012
[INFO] 2021-07-12 19:12:29,986 [run_pretraining.py:  558]:	worker_index: 2, step: 2012, cost: 7.500582, mlm loss: 7.500582, speed: 1.064950 steps/s, speed: 8.519601 samples/s, speed: 4362.035777 tokens/s, learning rate: 2.011e-05, loss_scalings: 3518.437988, pp_loss: 7.521456
[INFO] 2021-07-12 19:12:29,986 [run_pretraining.py:  512]:	********exe.run_2012******* 
[INFO] 2021-07-12 19:12:30,923 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:30,924 [run_pretraining.py:  534]:	loss/total_loss, 7.625067710876465, 2013
[INFO] 2021-07-12 19:12:30,924 [run_pretraining.py:  535]:	loss/mlm_loss, 7.625067710876465, 2013
[INFO] 2021-07-12 19:12:30,924 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0119998225709423e-05, 2013
[INFO] 2021-07-12 19:12:30,924 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2013
[INFO] 2021-07-12 19:12:30,924 [run_pretraining.py:  558]:	worker_index: 2, step: 2013, cost: 7.625068, mlm loss: 7.625068, speed: 1.067017 steps/s, speed: 8.536138 samples/s, speed: 4370.502694 tokens/s, learning rate: 2.012e-05, loss_scalings: 3518.437988, pp_loss: 7.518773
[INFO] 2021-07-12 19:12:30,924 [run_pretraining.py:  512]:	********exe.run_2013******* 
[INFO] 2021-07-12 19:12:31,858 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:31,858 [run_pretraining.py:  534]:	loss/total_loss, 7.196432590484619, 2014
[INFO] 2021-07-12 19:12:31,859 [run_pretraining.py:  535]:	loss/mlm_loss, 7.196432590484619, 2014
[INFO] 2021-07-12 19:12:31,859 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.012999902945012e-05, 2014
[INFO] 2021-07-12 19:12:31,859 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2014
[INFO] 2021-07-12 19:12:31,859 [run_pretraining.py:  558]:	worker_index: 2, step: 2014, cost: 7.196433, mlm loss: 7.196433, speed: 1.070755 steps/s, speed: 8.566041 samples/s, speed: 4385.812830 tokens/s, learning rate: 2.013e-05, loss_scalings: 3518.437988, pp_loss: 7.109139
[INFO] 2021-07-12 19:12:31,859 [run_pretraining.py:  512]:	********exe.run_2014******* 
[INFO] 2021-07-12 19:12:32,798 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:32,798 [run_pretraining.py:  534]:	loss/total_loss, 7.564635276794434, 2015
[INFO] 2021-07-12 19:12:32,798 [run_pretraining.py:  535]:	loss/mlm_loss, 7.564635276794434, 2015
[INFO] 2021-07-12 19:12:32,798 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0139999833190814e-05, 2015
[INFO] 2021-07-12 19:12:32,798 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2015
[INFO] 2021-07-12 19:12:32,799 [run_pretraining.py:  558]:	worker_index: 2, step: 2015, cost: 7.564635, mlm loss: 7.564635, speed: 1.064735 steps/s, speed: 8.517882 samples/s, speed: 4361.155462 tokens/s, learning rate: 2.014e-05, loss_scalings: 3518.437988, pp_loss: 7.490796
[INFO] 2021-07-12 19:12:32,799 [run_pretraining.py:  512]:	********exe.run_2015******* 
[INFO] 2021-07-12 19:12:33,731 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:33,732 [run_pretraining.py:  534]:	loss/total_loss, 7.432682991027832, 2016
[INFO] 2021-07-12 19:12:33,732 [run_pretraining.py:  535]:	loss/mlm_loss, 7.432682991027832, 2016
[INFO] 2021-07-12 19:12:33,732 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0149998817942105e-05, 2016
[INFO] 2021-07-12 19:12:33,732 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2016
[INFO] 2021-07-12 19:12:33,732 [run_pretraining.py:  558]:	worker_index: 2, step: 2016, cost: 7.432683, mlm loss: 7.432683, speed: 1.071784 steps/s, speed: 8.574275 samples/s, speed: 4390.028984 tokens/s, learning rate: 2.015e-05, loss_scalings: 3518.437988, pp_loss: 7.393155
[INFO] 2021-07-12 19:12:33,732 [run_pretraining.py:  512]:	********exe.run_2016******* 
[INFO] 2021-07-12 19:12:34,665 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:34,666 [run_pretraining.py:  534]:	loss/total_loss, 7.1836652755737305, 2017
[INFO] 2021-07-12 19:12:34,666 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1836652755737305, 2017
[INFO] 2021-07-12 19:12:34,666 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.01599996216828e-05, 2017
[INFO] 2021-07-12 19:12:34,666 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2017
[INFO] 2021-07-12 19:12:34,666 [run_pretraining.py:  558]:	worker_index: 2, step: 2017, cost: 7.183665, mlm loss: 7.183665, speed: 1.071512 steps/s, speed: 8.572094 samples/s, speed: 4388.911956 tokens/s, learning rate: 2.016e-05, loss_scalings: 3518.437988, pp_loss: 7.425914
[INFO] 2021-07-12 19:12:34,666 [run_pretraining.py:  512]:	********exe.run_2017******* 
[INFO] 2021-07-12 19:12:35,625 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:35,626 [run_pretraining.py:  534]:	loss/total_loss, 6.277800559997559, 2018
[INFO] 2021-07-12 19:12:35,626 [run_pretraining.py:  535]:	loss/mlm_loss, 6.277800559997559, 2018
[INFO] 2021-07-12 19:12:35,626 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0170000425423495e-05, 2018
[INFO] 2021-07-12 19:12:35,626 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2018
[INFO] 2021-07-12 19:12:35,626 [run_pretraining.py:  558]:	worker_index: 2, step: 2018, cost: 6.277801, mlm loss: 6.277801, speed: 1.042102 steps/s, speed: 8.336820 samples/s, speed: 4268.451674 tokens/s, learning rate: 2.017e-05, loss_scalings: 3518.437988, pp_loss: 7.049459
[INFO] 2021-07-12 19:12:35,626 [run_pretraining.py:  512]:	********exe.run_2018******* 
[INFO] 2021-07-12 19:12:36,591 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:36,591 [run_pretraining.py:  534]:	loss/total_loss, 7.777303695678711, 2019
[INFO] 2021-07-12 19:12:36,591 [run_pretraining.py:  535]:	loss/mlm_loss, 7.777303695678711, 2019
[INFO] 2021-07-12 19:12:36,592 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0179999410174787e-05, 2019
[INFO] 2021-07-12 19:12:36,592 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2019
[INFO] 2021-07-12 19:12:36,592 [run_pretraining.py:  558]:	worker_index: 2, step: 2019, cost: 7.777304, mlm loss: 7.777304, speed: 1.036482 steps/s, speed: 8.291859 samples/s, speed: 4245.431600 tokens/s, learning rate: 2.018e-05, loss_scalings: 3518.437988, pp_loss: 7.920158
[INFO] 2021-07-12 19:12:36,592 [run_pretraining.py:  512]:	********exe.run_2019******* 
[INFO] 2021-07-12 19:12:37,549 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:37,550 [run_pretraining.py:  534]:	loss/total_loss, 6.980395317077637, 2020
[INFO] 2021-07-12 19:12:37,550 [run_pretraining.py:  535]:	loss/mlm_loss, 6.980395317077637, 2020
[INFO] 2021-07-12 19:12:37,550 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0190000213915482e-05, 2020
[INFO] 2021-07-12 19:12:37,550 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2020
[INFO] 2021-07-12 19:12:37,550 [run_pretraining.py:  558]:	worker_index: 2, step: 2020, cost: 6.980395, mlm loss: 6.980395, speed: 1.043843 steps/s, speed: 8.350746 samples/s, speed: 4275.581808 tokens/s, learning rate: 2.019e-05, loss_scalings: 3518.437988, pp_loss: 7.403316
[INFO] 2021-07-12 19:12:37,550 [run_pretraining.py:  512]:	********exe.run_2020******* 
[INFO] 2021-07-12 19:12:38,509 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:38,509 [run_pretraining.py:  534]:	loss/total_loss, 7.347225666046143, 2021
[INFO] 2021-07-12 19:12:38,509 [run_pretraining.py:  535]:	loss/mlm_loss, 7.347225666046143, 2021
[INFO] 2021-07-12 19:12:38,510 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0200001017656177e-05, 2021
[INFO] 2021-07-12 19:12:38,510 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2021
[INFO] 2021-07-12 19:12:38,510 [run_pretraining.py:  558]:	worker_index: 2, step: 2021, cost: 7.347226, mlm loss: 7.347226, speed: 1.042982 steps/s, speed: 8.343858 samples/s, speed: 4272.055196 tokens/s, learning rate: 2.020e-05, loss_scalings: 3518.437988, pp_loss: 7.064342
[INFO] 2021-07-12 19:12:38,510 [run_pretraining.py:  512]:	********exe.run_2021******* 
[INFO] 2021-07-12 19:12:39,469 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:39,470 [run_pretraining.py:  534]:	loss/total_loss, 6.457687854766846, 2022
[INFO] 2021-07-12 19:12:39,470 [run_pretraining.py:  535]:	loss/mlm_loss, 6.457687854766846, 2022
[INFO] 2021-07-12 19:12:39,470 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0209998183418065e-05, 2022
[INFO] 2021-07-12 19:12:39,470 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2022
[INFO] 2021-07-12 19:12:39,470 [run_pretraining.py:  558]:	worker_index: 2, step: 2022, cost: 6.457688, mlm loss: 6.457688, speed: 1.041896 steps/s, speed: 8.335169 samples/s, speed: 4267.606603 tokens/s, learning rate: 2.021e-05, loss_scalings: 3518.437988, pp_loss: 7.292239
[INFO] 2021-07-12 19:12:39,470 [run_pretraining.py:  512]:	********exe.run_2022******* 
[INFO] 2021-07-12 19:12:40,406 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:40,407 [run_pretraining.py:  534]:	loss/total_loss, 7.308912754058838, 2023
[INFO] 2021-07-12 19:12:40,407 [run_pretraining.py:  535]:	loss/mlm_loss, 7.308912754058838, 2023
[INFO] 2021-07-12 19:12:40,407 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.021999898715876e-05, 2023
[INFO] 2021-07-12 19:12:40,407 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2023
[INFO] 2021-07-12 19:12:40,407 [run_pretraining.py:  558]:	worker_index: 2, step: 2023, cost: 7.308913, mlm loss: 7.308913, speed: 1.067859 steps/s, speed: 8.542871 samples/s, speed: 4373.949896 tokens/s, learning rate: 2.022e-05, loss_scalings: 3518.437988, pp_loss: 6.570614
[INFO] 2021-07-12 19:12:40,407 [run_pretraining.py:  512]:	********exe.run_2023******* 
[INFO] 2021-07-12 19:12:41,346 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:41,347 [run_pretraining.py:  534]:	loss/total_loss, 7.443051338195801, 2024
[INFO] 2021-07-12 19:12:41,347 [run_pretraining.py:  535]:	loss/mlm_loss, 7.443051338195801, 2024
[INFO] 2021-07-12 19:12:41,347 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0229999790899456e-05, 2024
[INFO] 2021-07-12 19:12:41,347 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2024
[INFO] 2021-07-12 19:12:41,347 [run_pretraining.py:  558]:	worker_index: 2, step: 2024, cost: 7.443051, mlm loss: 7.443051, speed: 1.064515 steps/s, speed: 8.516120 samples/s, speed: 4360.253370 tokens/s, learning rate: 2.023e-05, loss_scalings: 3518.437988, pp_loss: 7.204116
[INFO] 2021-07-12 19:12:41,347 [run_pretraining.py:  512]:	********exe.run_2024******* 
[INFO] 2021-07-12 19:12:42,284 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:42,285 [run_pretraining.py:  534]:	loss/total_loss, 7.744195938110352, 2025
[INFO] 2021-07-12 19:12:42,285 [run_pretraining.py:  535]:	loss/mlm_loss, 7.744195938110352, 2025
[INFO] 2021-07-12 19:12:42,285 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0239998775650747e-05, 2025
[INFO] 2021-07-12 19:12:42,285 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2025
[INFO] 2021-07-12 19:12:42,285 [run_pretraining.py:  558]:	worker_index: 2, step: 2025, cost: 7.744196, mlm loss: 7.744196, speed: 1.066870 steps/s, speed: 8.534957 samples/s, speed: 4369.897936 tokens/s, learning rate: 2.024e-05, loss_scalings: 3518.437988, pp_loss: 7.564236
[INFO] 2021-07-12 19:12:42,285 [run_pretraining.py:  512]:	********exe.run_2025******* 
[INFO] 2021-07-12 19:12:43,215 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:43,216 [run_pretraining.py:  534]:	loss/total_loss, 6.990476608276367, 2026
[INFO] 2021-07-12 19:12:43,216 [run_pretraining.py:  535]:	loss/mlm_loss, 6.990476608276367, 2026
[INFO] 2021-07-12 19:12:43,216 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0249999579391442e-05, 2026
[INFO] 2021-07-12 19:12:43,216 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2026
[INFO] 2021-07-12 19:12:43,216 [run_pretraining.py:  558]:	worker_index: 2, step: 2026, cost: 6.990477, mlm loss: 6.990477, speed: 1.074519 steps/s, speed: 8.596149 samples/s, speed: 4401.228353 tokens/s, learning rate: 2.025e-05, loss_scalings: 3518.437988, pp_loss: 7.193145
[INFO] 2021-07-12 19:12:43,216 [run_pretraining.py:  512]:	********exe.run_2026******* 
[INFO] 2021-07-12 19:12:44,157 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:44,158 [run_pretraining.py:  534]:	loss/total_loss, 6.304482936859131, 2027
[INFO] 2021-07-12 19:12:44,158 [run_pretraining.py:  535]:	loss/mlm_loss, 6.304482936859131, 2027
[INFO] 2021-07-12 19:12:44,158 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0260000383132137e-05, 2027
[INFO] 2021-07-12 19:12:44,158 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2027
[INFO] 2021-07-12 19:12:44,158 [run_pretraining.py:  558]:	worker_index: 2, step: 2027, cost: 6.304483, mlm loss: 6.304483, speed: 1.062318 steps/s, speed: 8.498545 samples/s, speed: 4351.255132 tokens/s, learning rate: 2.026e-05, loss_scalings: 3518.437988, pp_loss: 7.300508
[INFO] 2021-07-12 19:12:44,158 [run_pretraining.py:  512]:	********exe.run_2027******* 
[INFO] 2021-07-12 19:12:45,106 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:45,106 [run_pretraining.py:  534]:	loss/total_loss, 7.163241386413574, 2028
[INFO] 2021-07-12 19:12:45,107 [run_pretraining.py:  535]:	loss/mlm_loss, 7.163241386413574, 2028
[INFO] 2021-07-12 19:12:45,107 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.026999936788343e-05, 2028
[INFO] 2021-07-12 19:12:45,107 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2028
[INFO] 2021-07-12 19:12:45,107 [run_pretraining.py:  558]:	worker_index: 2, step: 2028, cost: 7.163241, mlm loss: 7.163241, speed: 1.054863 steps/s, speed: 8.438902 samples/s, speed: 4320.717693 tokens/s, learning rate: 2.027e-05, loss_scalings: 3518.437988, pp_loss: 6.927102
[INFO] 2021-07-12 19:12:45,107 [run_pretraining.py:  512]:	********exe.run_2028******* 
[INFO] 2021-07-12 19:12:46,062 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:46,063 [run_pretraining.py:  534]:	loss/total_loss, 7.409252166748047, 2029
[INFO] 2021-07-12 19:12:46,063 [run_pretraining.py:  535]:	loss/mlm_loss, 7.409252166748047, 2029
[INFO] 2021-07-12 19:12:46,063 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0280000171624124e-05, 2029
[INFO] 2021-07-12 19:12:46,063 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2029
[INFO] 2021-07-12 19:12:46,063 [run_pretraining.py:  558]:	worker_index: 2, step: 2029, cost: 7.409252, mlm loss: 7.409252, speed: 1.046271 steps/s, speed: 8.370164 samples/s, speed: 4285.524144 tokens/s, learning rate: 2.028e-05, loss_scalings: 3518.437988, pp_loss: 6.814047
[INFO] 2021-07-12 19:12:46,063 [run_pretraining.py:  512]:	********exe.run_2029******* 
[INFO] 2021-07-12 19:12:47,019 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:47,019 [run_pretraining.py:  534]:	loss/total_loss, 7.187656402587891, 2030
[INFO] 2021-07-12 19:12:47,020 [run_pretraining.py:  535]:	loss/mlm_loss, 7.187656402587891, 2030
[INFO] 2021-07-12 19:12:47,020 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.029000097536482e-05, 2030
[INFO] 2021-07-12 19:12:47,020 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2030
[INFO] 2021-07-12 19:12:47,020 [run_pretraining.py:  558]:	worker_index: 2, step: 2030, cost: 7.187656, mlm loss: 7.187656, speed: 1.046021 steps/s, speed: 8.368171 samples/s, speed: 4284.503467 tokens/s, learning rate: 2.029e-05, loss_scalings: 3518.437988, pp_loss: 7.187787
[INFO] 2021-07-12 19:12:47,020 [run_pretraining.py:  512]:	********exe.run_2030******* 
[INFO] 2021-07-12 19:12:47,967 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:47,967 [run_pretraining.py:  534]:	loss/total_loss, 7.766326427459717, 2031
[INFO] 2021-07-12 19:12:47,967 [run_pretraining.py:  535]:	loss/mlm_loss, 7.766326427459717, 2031
[INFO] 2021-07-12 19:12:47,968 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0299998141126707e-05, 2031
[INFO] 2021-07-12 19:12:47,968 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2031
[INFO] 2021-07-12 19:12:47,968 [run_pretraining.py:  558]:	worker_index: 2, step: 2031, cost: 7.766326, mlm loss: 7.766326, speed: 1.055630 steps/s, speed: 8.445038 samples/s, speed: 4323.859324 tokens/s, learning rate: 2.030e-05, loss_scalings: 3518.437988, pp_loss: 7.259376
[INFO] 2021-07-12 19:12:47,968 [run_pretraining.py:  512]:	********exe.run_2031******* 
[INFO] 2021-07-12 19:12:48,922 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:48,923 [run_pretraining.py:  534]:	loss/total_loss, 7.707559585571289, 2032
[INFO] 2021-07-12 19:12:48,923 [run_pretraining.py:  535]:	loss/mlm_loss, 7.707559585571289, 2032
[INFO] 2021-07-12 19:12:48,923 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0309998944867402e-05, 2032
[INFO] 2021-07-12 19:12:48,923 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2032
[INFO] 2021-07-12 19:12:48,923 [run_pretraining.py:  558]:	worker_index: 2, step: 2032, cost: 7.707560, mlm loss: 7.707560, speed: 1.047543 steps/s, speed: 8.380347 samples/s, speed: 4290.737701 tokens/s, learning rate: 2.031e-05, loss_scalings: 3518.437988, pp_loss: 7.422912
[INFO] 2021-07-12 19:12:48,923 [run_pretraining.py:  512]:	********exe.run_2032******* 
[INFO] 2021-07-12 19:13:15,580 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:15,581 [run_pretraining.py:  534]:	loss/total_loss, 7.020934104919434, 2033
[INFO] 2021-07-12 19:13:15,581 [run_pretraining.py:  535]:	loss/mlm_loss, 7.020934104919434, 2033
[INFO] 2021-07-12 19:13:15,581 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0319999748608097e-05, 2033
[INFO] 2021-07-12 19:13:15,581 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2033
[INFO] 2021-07-12 19:13:15,581 [run_pretraining.py:  558]:	worker_index: 2, step: 2033, cost: 7.020934, mlm loss: 7.020934, speed: 0.037513 steps/s, speed: 0.300105 samples/s, speed: 153.653623 tokens/s, learning rate: 2.032e-05, loss_scalings: 3518.437988, pp_loss: 7.351006
[INFO] 2021-07-12 19:13:15,581 [run_pretraining.py:  512]:	********exe.run_2033******* 
[INFO] 2021-07-12 19:13:41,716 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:41,716 [run_pretraining.py:  534]:	loss/total_loss, 7.9612579345703125, 2034
[INFO] 2021-07-12 19:13:41,716 [run_pretraining.py:  535]:	loss/mlm_loss, 7.9612579345703125, 2034
[INFO] 2021-07-12 19:13:41,716 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.032999873335939e-05, 2034
[INFO] 2021-07-12 19:13:41,716 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2034
[INFO] 2021-07-12 19:13:41,716 [run_pretraining.py:  558]:	worker_index: 2, step: 2034, cost: 7.961258, mlm loss: 7.961258, speed: 0.038263 steps/s, speed: 0.306104 samples/s, speed: 156.725163 tokens/s, learning rate: 2.033e-05, loss_scalings: 3518.437988, pp_loss: 7.592238
[INFO] 2021-07-12 19:13:41,717 [run_pretraining.py:  512]:	********exe.run_2034******* 
[INFO] 2021-07-12 19:13:42,635 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:42,636 [run_pretraining.py:  534]:	loss/total_loss, 6.918231964111328, 2035
[INFO] 2021-07-12 19:13:42,636 [run_pretraining.py:  535]:	loss/mlm_loss, 6.918231964111328, 2035
[INFO] 2021-07-12 19:13:42,636 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0339999537100084e-05, 2035
[INFO] 2021-07-12 19:13:42,636 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2035
[INFO] 2021-07-12 19:13:42,636 [run_pretraining.py:  558]:	worker_index: 2, step: 2035, cost: 6.918232, mlm loss: 6.918232, speed: 1.087860 steps/s, speed: 8.702880 samples/s, speed: 4455.874494 tokens/s, learning rate: 2.034e-05, loss_scalings: 3518.437988, pp_loss: 7.411465
[INFO] 2021-07-12 19:13:42,636 [run_pretraining.py:  512]:	********exe.run_2035******* 
[INFO] 2021-07-12 19:13:43,582 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:43,583 [run_pretraining.py:  534]:	loss/total_loss, 7.2585673332214355, 2036
[INFO] 2021-07-12 19:13:43,583 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2585673332214355, 2036
[INFO] 2021-07-12 19:13:43,583 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.035000034084078e-05, 2036
[INFO] 2021-07-12 19:13:43,583 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2036
[INFO] 2021-07-12 19:13:43,583 [run_pretraining.py:  558]:	worker_index: 2, step: 2036, cost: 7.258567, mlm loss: 7.258567, speed: 1.056659 steps/s, speed: 8.453269 samples/s, speed: 4328.073815 tokens/s, learning rate: 2.035e-05, loss_scalings: 3518.437988, pp_loss: 6.952487
[INFO] 2021-07-12 19:13:43,583 [run_pretraining.py:  512]:	********exe.run_2036******* 
[INFO] 2021-07-12 19:13:44,513 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:44,514 [run_pretraining.py:  534]:	loss/total_loss, 7.182074546813965, 2037
[INFO] 2021-07-12 19:13:44,514 [run_pretraining.py:  535]:	loss/mlm_loss, 7.182074546813965, 2037
[INFO] 2021-07-12 19:13:44,514 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.035999932559207e-05, 2037
[INFO] 2021-07-12 19:13:44,514 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2037
[INFO] 2021-07-12 19:13:44,514 [run_pretraining.py:  558]:	worker_index: 2, step: 2037, cost: 7.182075, mlm loss: 7.182075, speed: 1.074932 steps/s, speed: 8.599454 samples/s, speed: 4402.920297 tokens/s, learning rate: 2.036e-05, loss_scalings: 3518.437988, pp_loss: 7.366718
[INFO] 2021-07-12 19:13:44,514 [run_pretraining.py:  512]:	********exe.run_2037******* 
[INFO] 2021-07-12 19:13:45,461 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:45,461 [run_pretraining.py:  534]:	loss/total_loss, 7.346860885620117, 2038
[INFO] 2021-07-12 19:13:45,461 [run_pretraining.py:  535]:	loss/mlm_loss, 7.346860885620117, 2038
[INFO] 2021-07-12 19:13:45,461 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0370000129332766e-05, 2038
[INFO] 2021-07-12 19:13:45,462 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2038
[INFO] 2021-07-12 19:13:45,462 [run_pretraining.py:  558]:	worker_index: 2, step: 2038, cost: 7.346861, mlm loss: 7.346861, speed: 1.056169 steps/s, speed: 8.449350 samples/s, speed: 4326.067394 tokens/s, learning rate: 2.037e-05, loss_scalings: 3518.437988, pp_loss: 6.503591
[INFO] 2021-07-12 19:13:45,462 [run_pretraining.py:  512]:	********exe.run_2038******* 
[INFO] 2021-07-12 19:13:46,386 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:46,387 [run_pretraining.py:  534]:	loss/total_loss, 7.585577011108398, 2039
[INFO] 2021-07-12 19:13:46,387 [run_pretraining.py:  535]:	loss/mlm_loss, 7.585577011108398, 2039
[INFO] 2021-07-12 19:13:46,387 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0379999114084058e-05, 2039
[INFO] 2021-07-12 19:13:46,387 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2039
[INFO] 2021-07-12 19:13:46,387 [run_pretraining.py:  558]:	worker_index: 2, step: 2039, cost: 7.585577, mlm loss: 7.585577, speed: 1.081237 steps/s, speed: 8.649895 samples/s, speed: 4428.746440 tokens/s, learning rate: 2.038e-05, loss_scalings: 3518.437988, pp_loss: 7.322774
[INFO] 2021-07-12 19:13:46,387 [run_pretraining.py:  512]:	********exe.run_2039******* 
[INFO] 2021-07-12 19:13:47,313 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:47,314 [run_pretraining.py:  534]:	loss/total_loss, 6.809808254241943, 2040
[INFO] 2021-07-12 19:13:47,314 [run_pretraining.py:  535]:	loss/mlm_loss, 6.809808254241943, 2040
[INFO] 2021-07-12 19:13:47,314 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.038999809883535e-05, 2040
[INFO] 2021-07-12 19:13:47,314 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2040
[INFO] 2021-07-12 19:13:47,314 [run_pretraining.py:  558]:	worker_index: 2, step: 2040, cost: 6.809808, mlm loss: 6.809808, speed: 1.079182 steps/s, speed: 8.633457 samples/s, speed: 4420.330067 tokens/s, learning rate: 2.039e-05, loss_scalings: 3518.437988, pp_loss: 7.029509
[INFO] 2021-07-12 19:13:47,314 [run_pretraining.py:  512]:	********exe.run_2040******* 
[INFO] 2021-07-12 19:13:48,221 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:48,221 [run_pretraining.py:  534]:	loss/total_loss, 6.928352355957031, 2041
[INFO] 2021-07-12 19:13:48,221 [run_pretraining.py:  535]:	loss/mlm_loss, 6.928352355957031, 2041
[INFO] 2021-07-12 19:13:48,221 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0399998902576044e-05, 2041
[INFO] 2021-07-12 19:13:48,221 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2041
[INFO] 2021-07-12 19:13:48,222 [run_pretraining.py:  558]:	worker_index: 2, step: 2041, cost: 6.928352, mlm loss: 6.928352, speed: 1.103013 steps/s, speed: 8.824104 samples/s, speed: 4517.941251 tokens/s, learning rate: 2.040e-05, loss_scalings: 3518.437988, pp_loss: 7.192348
[INFO] 2021-07-12 19:13:48,222 [run_pretraining.py:  512]:	********exe.run_2041******* 
[INFO] 2021-07-12 19:13:49,146 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:49,146 [run_pretraining.py:  534]:	loss/total_loss, 6.992714881896973, 2042
[INFO] 2021-07-12 19:13:49,146 [run_pretraining.py:  535]:	loss/mlm_loss, 6.992714881896973, 2042
[INFO] 2021-07-12 19:13:49,146 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.040999970631674e-05, 2042
[INFO] 2021-07-12 19:13:49,147 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2042
[INFO] 2021-07-12 19:13:49,147 [run_pretraining.py:  558]:	worker_index: 2, step: 2042, cost: 6.992715, mlm loss: 6.992715, speed: 1.081652 steps/s, speed: 8.653219 samples/s, speed: 4430.448186 tokens/s, learning rate: 2.041e-05, loss_scalings: 3518.437988, pp_loss: 7.158756
[INFO] 2021-07-12 19:13:49,147 [run_pretraining.py:  512]:	********exe.run_2042******* 
[INFO] 2021-07-12 19:13:50,063 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:50,063 [run_pretraining.py:  534]:	loss/total_loss, 6.80747127532959, 2043
[INFO] 2021-07-12 19:13:50,063 [run_pretraining.py:  535]:	loss/mlm_loss, 6.80747127532959, 2043
[INFO] 2021-07-12 19:13:50,064 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.041999869106803e-05, 2043
[INFO] 2021-07-12 19:13:50,064 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2043
[INFO] 2021-07-12 19:13:50,064 [run_pretraining.py:  558]:	worker_index: 2, step: 2043, cost: 6.807471, mlm loss: 6.807471, speed: 1.091212 steps/s, speed: 8.729695 samples/s, speed: 4469.603650 tokens/s, learning rate: 2.042e-05, loss_scalings: 3518.437988, pp_loss: 6.860119
[INFO] 2021-07-12 19:13:50,064 [run_pretraining.py:  512]:	********exe.run_2043******* 
[INFO] 2021-07-12 19:13:50,983 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:50,983 [run_pretraining.py:  534]:	loss/total_loss, 7.81395959854126, 2044
[INFO] 2021-07-12 19:13:50,984 [run_pretraining.py:  535]:	loss/mlm_loss, 7.81395959854126, 2044
[INFO] 2021-07-12 19:13:50,984 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0429999494808726e-05, 2044
[INFO] 2021-07-12 19:13:50,984 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2044
[INFO] 2021-07-12 19:13:50,984 [run_pretraining.py:  558]:	worker_index: 2, step: 2044, cost: 7.813960, mlm loss: 7.813960, speed: 1.087506 steps/s, speed: 8.700046 samples/s, speed: 4454.423404 tokens/s, learning rate: 2.043e-05, loss_scalings: 3518.437988, pp_loss: 7.449641
[INFO] 2021-07-12 19:13:50,984 [run_pretraining.py:  512]:	********exe.run_2044******* 
[INFO] 2021-07-12 19:13:51,909 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:51,909 [run_pretraining.py:  534]:	loss/total_loss, 7.0485734939575195, 2045
[INFO] 2021-07-12 19:13:51,909 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0485734939575195, 2045
[INFO] 2021-07-12 19:13:51,909 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.044000029854942e-05, 2045
[INFO] 2021-07-12 19:13:51,909 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2045
[INFO] 2021-07-12 19:13:51,910 [run_pretraining.py:  558]:	worker_index: 2, step: 2045, cost: 7.048573, mlm loss: 7.048573, speed: 1.080886 steps/s, speed: 8.647091 samples/s, speed: 4427.310681 tokens/s, learning rate: 2.044e-05, loss_scalings: 3518.437988, pp_loss: 7.298286
[INFO] 2021-07-12 19:13:51,910 [run_pretraining.py:  512]:	********exe.run_2045******* 
[INFO] 2021-07-12 19:13:52,832 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:52,832 [run_pretraining.py:  534]:	loss/total_loss, 6.872218132019043, 2046
[INFO] 2021-07-12 19:13:52,832 [run_pretraining.py:  535]:	loss/mlm_loss, 6.872218132019043, 2046
[INFO] 2021-07-12 19:13:52,832 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0449999283300713e-05, 2046
[INFO] 2021-07-12 19:13:52,832 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2046
[INFO] 2021-07-12 19:13:52,832 [run_pretraining.py:  558]:	worker_index: 2, step: 2046, cost: 6.872218, mlm loss: 6.872218, speed: 1.084315 steps/s, speed: 8.674520 samples/s, speed: 4441.354335 tokens/s, learning rate: 2.045e-05, loss_scalings: 3518.437988, pp_loss: 7.215236
[INFO] 2021-07-12 19:13:52,832 [run_pretraining.py:  512]:	********exe.run_2046******* 
[INFO] 2021-07-12 19:13:53,799 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:53,800 [run_pretraining.py:  534]:	loss/total_loss, 7.312304496765137, 2047
[INFO] 2021-07-12 19:13:53,800 [run_pretraining.py:  535]:	loss/mlm_loss, 7.312304496765137, 2047
[INFO] 2021-07-12 19:13:53,800 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0460000087041408e-05, 2047
[INFO] 2021-07-12 19:13:53,800 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2047
[INFO] 2021-07-12 19:13:53,800 [run_pretraining.py:  558]:	worker_index: 2, step: 2047, cost: 7.312304, mlm loss: 7.312304, speed: 1.034090 steps/s, speed: 8.272724 samples/s, speed: 4235.634528 tokens/s, learning rate: 2.046e-05, loss_scalings: 3518.437988, pp_loss: 7.265944
[INFO] 2021-07-12 19:13:53,800 [run_pretraining.py:  512]:	********exe.run_2047******* 
[INFO] 2021-07-12 19:13:54,720 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:54,721 [run_pretraining.py:  534]:	loss/total_loss, 7.575793743133545, 2048
[INFO] 2021-07-12 19:13:54,721 [run_pretraining.py:  535]:	loss/mlm_loss, 7.575793743133545, 2048
[INFO] 2021-07-12 19:13:54,721 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.04699990717927e-05, 2048
[INFO] 2021-07-12 19:13:54,721 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2048
[INFO] 2021-07-12 19:13:54,721 [run_pretraining.py:  558]:	worker_index: 2, step: 2048, cost: 7.575794, mlm loss: 7.575794, speed: 1.086328 steps/s, speed: 8.690627 samples/s, speed: 4449.600940 tokens/s, learning rate: 2.047e-05, loss_scalings: 3518.437988, pp_loss: 7.652620
[INFO] 2021-07-12 19:13:54,721 [run_pretraining.py:  512]:	********exe.run_2048******* 
[INFO] 2021-07-12 19:13:55,655 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:55,655 [run_pretraining.py:  534]:	loss/total_loss, 6.939764976501465, 2049
[INFO] 2021-07-12 19:13:55,655 [run_pretraining.py:  535]:	loss/mlm_loss, 6.939764976501465, 2049
[INFO] 2021-07-12 19:13:55,655 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.047999805654399e-05, 2049
[INFO] 2021-07-12 19:13:55,655 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2049
[INFO] 2021-07-12 19:13:55,655 [run_pretraining.py:  558]:	worker_index: 2, step: 2049, cost: 6.939765, mlm loss: 6.939765, speed: 1.071022 steps/s, speed: 8.568176 samples/s, speed: 4386.905876 tokens/s, learning rate: 2.048e-05, loss_scalings: 3518.437988, pp_loss: 7.610328
[INFO] 2021-07-12 19:13:55,656 [run_pretraining.py:  512]:	********exe.run_2049******* 
[INFO] 2021-07-12 19:13:56,595 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:56,596 [run_pretraining.py:  534]:	loss/total_loss, 4.894064903259277, 2050
[INFO] 2021-07-12 19:13:56,596 [run_pretraining.py:  535]:	loss/mlm_loss, 4.894064903259277, 2050
[INFO] 2021-07-12 19:13:56,596 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0489998860284686e-05, 2050
[INFO] 2021-07-12 19:13:56,596 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2050
[INFO] 2021-07-12 19:13:56,596 [run_pretraining.py:  558]:	worker_index: 2, step: 2050, cost: 4.894065, mlm loss: 4.894065, speed: 1.064088 steps/s, speed: 8.512706 samples/s, speed: 4358.505590 tokens/s, learning rate: 2.049e-05, loss_scalings: 3518.437988, pp_loss: 6.815253
[INFO] 2021-07-12 19:13:56,596 [run_pretraining.py:  512]:	********exe.run_2050******* 
[INFO] 2021-07-12 19:13:57,552 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:57,553 [run_pretraining.py:  534]:	loss/total_loss, 6.961040496826172, 2051
[INFO] 2021-07-12 19:13:57,553 [run_pretraining.py:  535]:	loss/mlm_loss, 6.961040496826172, 2051
[INFO] 2021-07-12 19:13:57,553 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.049999966402538e-05, 2051
[INFO] 2021-07-12 19:13:57,553 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2051
[INFO] 2021-07-12 19:13:57,553 [run_pretraining.py:  558]:	worker_index: 2, step: 2051, cost: 6.961040, mlm loss: 6.961040, speed: 1.045205 steps/s, speed: 8.361644 samples/s, speed: 4281.161620 tokens/s, learning rate: 2.050e-05, loss_scalings: 3518.437988, pp_loss: 7.472218
[INFO] 2021-07-12 19:13:57,553 [run_pretraining.py:  512]:	********exe.run_2051******* 
[INFO] 2021-07-12 19:13:58,509 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:58,510 [run_pretraining.py:  534]:	loss/total_loss, 7.375946044921875, 2052
[INFO] 2021-07-12 19:13:58,510 [run_pretraining.py:  535]:	loss/mlm_loss, 7.375946044921875, 2052
[INFO] 2021-07-12 19:13:58,510 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0509998648776673e-05, 2052
[INFO] 2021-07-12 19:13:58,510 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2052
[INFO] 2021-07-12 19:13:58,510 [run_pretraining.py:  558]:	worker_index: 2, step: 2052, cost: 7.375946, mlm loss: 7.375946, speed: 1.045888 steps/s, speed: 8.367102 samples/s, speed: 4283.956457 tokens/s, learning rate: 2.051e-05, loss_scalings: 3518.437988, pp_loss: 7.076148
[INFO] 2021-07-12 19:13:58,510 [run_pretraining.py:  512]:	********exe.run_2052******* 
[INFO] 2021-07-12 19:13:59,450 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:59,451 [run_pretraining.py:  534]:	loss/total_loss, 7.165273666381836, 2053
[INFO] 2021-07-12 19:13:59,451 [run_pretraining.py:  535]:	loss/mlm_loss, 7.165273666381836, 2053
[INFO] 2021-07-12 19:13:59,451 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0519999452517368e-05, 2053
[INFO] 2021-07-12 19:13:59,451 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2053
[INFO] 2021-07-12 19:13:59,451 [run_pretraining.py:  558]:	worker_index: 2, step: 2053, cost: 7.165274, mlm loss: 7.165274, speed: 1.063003 steps/s, speed: 8.504022 samples/s, speed: 4354.059503 tokens/s, learning rate: 2.052e-05, loss_scalings: 3518.437988, pp_loss: 6.726679
[INFO] 2021-07-12 19:13:59,451 [run_pretraining.py:  512]:	********exe.run_2053******* 
[INFO] 2021-07-12 19:14:00,405 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:00,405 [run_pretraining.py:  534]:	loss/total_loss, 7.447240352630615, 2054
[INFO] 2021-07-12 19:14:00,405 [run_pretraining.py:  535]:	loss/mlm_loss, 7.447240352630615, 2054
[INFO] 2021-07-12 19:14:00,405 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0530000256258063e-05, 2054
[INFO] 2021-07-12 19:14:00,405 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2054
[INFO] 2021-07-12 19:14:00,405 [run_pretraining.py:  558]:	worker_index: 2, step: 2054, cost: 7.447240, mlm loss: 7.447240, speed: 1.048599 steps/s, speed: 8.388788 samples/s, speed: 4295.059640 tokens/s, learning rate: 2.053e-05, loss_scalings: 3518.437988, pp_loss: 7.684674
[INFO] 2021-07-12 19:14:00,406 [run_pretraining.py:  512]:	********exe.run_2054******* 
[INFO] 2021-07-12 19:14:01,345 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:01,346 [run_pretraining.py:  534]:	loss/total_loss, 6.92736291885376, 2055
[INFO] 2021-07-12 19:14:01,346 [run_pretraining.py:  535]:	loss/mlm_loss, 6.92736291885376, 2055
[INFO] 2021-07-12 19:14:01,346 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0539999241009355e-05, 2055
[INFO] 2021-07-12 19:14:01,346 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2055
[INFO] 2021-07-12 19:14:01,346 [run_pretraining.py:  558]:	worker_index: 2, step: 2055, cost: 6.927363, mlm loss: 6.927363, speed: 1.063882 steps/s, speed: 8.511052 samples/s, speed: 4357.658754 tokens/s, learning rate: 2.054e-05, loss_scalings: 3518.437988, pp_loss: 7.454974
[INFO] 2021-07-12 19:14:01,346 [run_pretraining.py:  512]:	********exe.run_2055******* 
[INFO] 2021-07-12 19:14:02,290 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:02,290 [run_pretraining.py:  534]:	loss/total_loss, 7.479722023010254, 2056
[INFO] 2021-07-12 19:14:02,291 [run_pretraining.py:  535]:	loss/mlm_loss, 7.479722023010254, 2056
[INFO] 2021-07-12 19:14:02,291 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.055000004475005e-05, 2056
[INFO] 2021-07-12 19:14:02,291 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2056
[INFO] 2021-07-12 19:14:02,291 [run_pretraining.py:  558]:	worker_index: 2, step: 2056, cost: 7.479722, mlm loss: 7.479722, speed: 1.059201 steps/s, speed: 8.473609 samples/s, speed: 4338.487751 tokens/s, learning rate: 2.055e-05, loss_scalings: 3518.437988, pp_loss: 7.369904
[INFO] 2021-07-12 19:14:02,291 [run_pretraining.py:  512]:	********exe.run_2056******* 
[INFO] 2021-07-12 19:14:03,231 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:03,232 [run_pretraining.py:  534]:	loss/total_loss, 7.55454683303833, 2057
[INFO] 2021-07-12 19:14:03,232 [run_pretraining.py:  535]:	loss/mlm_loss, 7.55454683303833, 2057
[INFO] 2021-07-12 19:14:03,232 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.055999902950134e-05, 2057
[INFO] 2021-07-12 19:14:03,232 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2057
[INFO] 2021-07-12 19:14:03,232 [run_pretraining.py:  558]:	worker_index: 2, step: 2057, cost: 7.554547, mlm loss: 7.554547, speed: 1.063024 steps/s, speed: 8.504188 samples/s, speed: 4354.144474 tokens/s, learning rate: 2.056e-05, loss_scalings: 3518.437988, pp_loss: 7.234105
[INFO] 2021-07-12 19:14:03,232 [run_pretraining.py:  512]:	********exe.run_2057******* 
[INFO] 2021-07-12 19:14:04,178 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:04,178 [run_pretraining.py:  534]:	loss/total_loss, 7.046139717102051, 2058
[INFO] 2021-07-12 19:14:04,178 [run_pretraining.py:  535]:	loss/mlm_loss, 7.046139717102051, 2058
[INFO] 2021-07-12 19:14:04,179 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0569999833242036e-05, 2058
[INFO] 2021-07-12 19:14:04,179 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2058
[INFO] 2021-07-12 19:14:04,179 [run_pretraining.py:  558]:	worker_index: 2, step: 2058, cost: 7.046140, mlm loss: 7.046140, speed: 1.057005 steps/s, speed: 8.456041 samples/s, speed: 4329.492837 tokens/s, learning rate: 2.057e-05, loss_scalings: 3518.437988, pp_loss: 6.602998
[INFO] 2021-07-12 19:14:04,179 [run_pretraining.py:  512]:	********exe.run_2058******* 
[INFO] 2021-07-12 19:14:05,124 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:05,124 [run_pretraining.py:  534]:	loss/total_loss, 7.085509300231934, 2059
[INFO] 2021-07-12 19:14:05,124 [run_pretraining.py:  535]:	loss/mlm_loss, 7.085509300231934, 2059
[INFO] 2021-07-12 19:14:05,125 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0579998817993328e-05, 2059
[INFO] 2021-07-12 19:14:05,125 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2059
[INFO] 2021-07-12 19:14:05,125 [run_pretraining.py:  558]:	worker_index: 2, step: 2059, cost: 7.085509, mlm loss: 7.085509, speed: 1.057843 steps/s, speed: 8.462746 samples/s, speed: 4332.925893 tokens/s, learning rate: 2.058e-05, loss_scalings: 3518.437988, pp_loss: 7.139951
[INFO] 2021-07-12 19:14:05,125 [run_pretraining.py:  512]:	********exe.run_2059******* 
[INFO] 2021-07-12 19:14:06,064 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:06,065 [run_pretraining.py:  534]:	loss/total_loss, 7.852049827575684, 2060
[INFO] 2021-07-12 19:14:06,065 [run_pretraining.py:  535]:	loss/mlm_loss, 7.852049827575684, 2060
[INFO] 2021-07-12 19:14:06,065 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0589999621734023e-05, 2060
[INFO] 2021-07-12 19:14:06,065 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2060
[INFO] 2021-07-12 19:14:06,065 [run_pretraining.py:  558]:	worker_index: 2, step: 2060, cost: 7.852050, mlm loss: 7.852050, speed: 1.064161 steps/s, speed: 8.513292 samples/s, speed: 4358.805268 tokens/s, learning rate: 2.059e-05, loss_scalings: 3518.437988, pp_loss: 7.399438
[INFO] 2021-07-12 19:14:06,065 [run_pretraining.py:  512]:	********exe.run_2060******* 
[INFO] 2021-07-12 19:14:07,006 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:07,006 [run_pretraining.py:  534]:	loss/total_loss, 7.531360149383545, 2061
[INFO] 2021-07-12 19:14:07,006 [run_pretraining.py:  535]:	loss/mlm_loss, 7.531360149383545, 2061
[INFO] 2021-07-12 19:14:07,007 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0599998606485315e-05, 2061
[INFO] 2021-07-12 19:14:07,007 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2061
[INFO] 2021-07-12 19:14:07,007 [run_pretraining.py:  558]:	worker_index: 2, step: 2061, cost: 7.531360, mlm loss: 7.531360, speed: 1.062501 steps/s, speed: 8.500011 samples/s, speed: 4352.005772 tokens/s, learning rate: 2.060e-05, loss_scalings: 3518.437988, pp_loss: 7.174114
[INFO] 2021-07-12 19:14:07,007 [run_pretraining.py:  512]:	********exe.run_2061******* 
[INFO] 2021-07-12 19:14:07,947 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:07,947 [run_pretraining.py:  534]:	loss/total_loss, 7.740875244140625, 2062
[INFO] 2021-07-12 19:14:07,947 [run_pretraining.py:  535]:	loss/mlm_loss, 7.740875244140625, 2062
[INFO] 2021-07-12 19:14:07,947 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.060999941022601e-05, 2062
[INFO] 2021-07-12 19:14:07,947 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2062
[INFO] 2021-07-12 19:14:07,948 [run_pretraining.py:  558]:	worker_index: 2, step: 2062, cost: 7.740875, mlm loss: 7.740875, speed: 1.063643 steps/s, speed: 8.509146 samples/s, speed: 4356.682978 tokens/s, learning rate: 2.061e-05, loss_scalings: 3518.437988, pp_loss: 7.535598
[INFO] 2021-07-12 19:14:07,948 [run_pretraining.py:  512]:	********exe.run_2062******* 
[INFO] 2021-07-12 19:14:08,886 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:08,887 [run_pretraining.py:  534]:	loss/total_loss, 7.288961410522461, 2063
[INFO] 2021-07-12 19:14:08,887 [run_pretraining.py:  535]:	loss/mlm_loss, 7.288961410522461, 2063
[INFO] 2021-07-12 19:14:08,887 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0620000213966705e-05, 2063
[INFO] 2021-07-12 19:14:08,887 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2063
[INFO] 2021-07-12 19:14:08,887 [run_pretraining.py:  558]:	worker_index: 2, step: 2063, cost: 7.288961, mlm loss: 7.288961, speed: 1.065080 steps/s, speed: 8.520640 samples/s, speed: 4362.567460 tokens/s, learning rate: 2.062e-05, loss_scalings: 3518.437988, pp_loss: 7.190227
[INFO] 2021-07-12 19:14:08,887 [run_pretraining.py:  512]:	********exe.run_2063******* 
[INFO] 2021-07-12 19:14:09,834 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:09,835 [run_pretraining.py:  534]:	loss/total_loss, 5.457738876342773, 2064
[INFO] 2021-07-12 19:14:09,835 [run_pretraining.py:  535]:	loss/mlm_loss, 5.457738876342773, 2064
[INFO] 2021-07-12 19:14:09,835 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0629999198717996e-05, 2064
[INFO] 2021-07-12 19:14:09,835 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2064
[INFO] 2021-07-12 19:14:09,835 [run_pretraining.py:  558]:	worker_index: 2, step: 2064, cost: 5.457739, mlm loss: 5.457739, speed: 1.055155 steps/s, speed: 8.441241 samples/s, speed: 4321.915520 tokens/s, learning rate: 2.063e-05, loss_scalings: 3518.437988, pp_loss: 6.327400
[INFO] 2021-07-12 19:14:09,835 [run_pretraining.py:  512]:	********exe.run_2064******* 
[INFO] 2021-07-12 19:14:10,779 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:10,779 [run_pretraining.py:  534]:	loss/total_loss, 7.409703254699707, 2065
[INFO] 2021-07-12 19:14:10,780 [run_pretraining.py:  535]:	loss/mlm_loss, 7.409703254699707, 2065
[INFO] 2021-07-12 19:14:10,780 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.064000000245869e-05, 2065
[INFO] 2021-07-12 19:14:10,780 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2065
[INFO] 2021-07-12 19:14:10,780 [run_pretraining.py:  558]:	worker_index: 2, step: 2065, cost: 7.409703, mlm loss: 7.409703, speed: 1.059452 steps/s, speed: 8.475619 samples/s, speed: 4339.516775 tokens/s, learning rate: 2.064e-05, loss_scalings: 3518.437988, pp_loss: 7.169890
[INFO] 2021-07-12 19:14:10,780 [run_pretraining.py:  512]:	********exe.run_2065******* 
[INFO] 2021-07-12 19:14:11,717 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:11,717 [run_pretraining.py:  534]:	loss/total_loss, 6.699981689453125, 2066
[INFO] 2021-07-12 19:14:11,717 [run_pretraining.py:  535]:	loss/mlm_loss, 6.699981689453125, 2066
[INFO] 2021-07-12 19:14:11,717 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0649998987209983e-05, 2066
[INFO] 2021-07-12 19:14:11,717 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2066
[INFO] 2021-07-12 19:14:11,717 [run_pretraining.py:  558]:	worker_index: 2, step: 2066, cost: 6.699982, mlm loss: 6.699982, speed: 1.067199 steps/s, speed: 8.537595 samples/s, speed: 4371.248867 tokens/s, learning rate: 2.065e-05, loss_scalings: 3518.437988, pp_loss: 7.092810
[INFO] 2021-07-12 19:14:11,718 [run_pretraining.py:  512]:	********exe.run_2066******* 
[INFO] 2021-07-12 19:14:12,651 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:12,652 [run_pretraining.py:  534]:	loss/total_loss, 7.250091075897217, 2067
[INFO] 2021-07-12 19:14:12,652 [run_pretraining.py:  535]:	loss/mlm_loss, 7.250091075897217, 2067
[INFO] 2021-07-12 19:14:12,652 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0659999790950678e-05, 2067
[INFO] 2021-07-12 19:14:12,652 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2067
[INFO] 2021-07-12 19:14:12,652 [run_pretraining.py:  558]:	worker_index: 2, step: 2067, cost: 7.250091, mlm loss: 7.250091, speed: 1.070624 steps/s, speed: 8.564993 samples/s, speed: 4385.276586 tokens/s, learning rate: 2.066e-05, loss_scalings: 3518.437988, pp_loss: 7.204237
[INFO] 2021-07-12 19:14:12,652 [run_pretraining.py:  512]:	********exe.run_2067******* 
[INFO] 2021-07-12 19:14:13,579 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:13,580 [run_pretraining.py:  534]:	loss/total_loss, 6.771952152252197, 2068
[INFO] 2021-07-12 19:14:13,580 [run_pretraining.py:  535]:	loss/mlm_loss, 6.771952152252197, 2068
[INFO] 2021-07-12 19:14:13,580 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.066999877570197e-05, 2068
[INFO] 2021-07-12 19:14:13,580 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2068
[INFO] 2021-07-12 19:14:13,580 [run_pretraining.py:  558]:	worker_index: 2, step: 2068, cost: 6.771952, mlm loss: 6.771952, speed: 1.078432 steps/s, speed: 8.627457 samples/s, speed: 4417.257979 tokens/s, learning rate: 2.067e-05, loss_scalings: 3518.437988, pp_loss: 6.963415
[INFO] 2021-07-12 19:14:13,580 [run_pretraining.py:  512]:	********exe.run_2068******* 
[INFO] 2021-07-12 19:14:14,518 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:14,518 [run_pretraining.py:  534]:	loss/total_loss, 7.615924835205078, 2069
[INFO] 2021-07-12 19:14:14,518 [run_pretraining.py:  535]:	loss/mlm_loss, 7.615924835205078, 2069
[INFO] 2021-07-12 19:14:14,519 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0679999579442665e-05, 2069
[INFO] 2021-07-12 19:14:14,519 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2069
[INFO] 2021-07-12 19:14:14,519 [run_pretraining.py:  558]:	worker_index: 2, step: 2069, cost: 7.615925, mlm loss: 7.615925, speed: 1.065936 steps/s, speed: 8.527484 samples/s, speed: 4366.072054 tokens/s, learning rate: 2.068e-05, loss_scalings: 3518.437988, pp_loss: 6.447887
[INFO] 2021-07-12 19:14:14,519 [run_pretraining.py:  512]:	********exe.run_2069******* 
[INFO] 2021-07-12 19:14:15,451 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:15,452 [run_pretraining.py:  534]:	loss/total_loss, 7.963428497314453, 2070
[INFO] 2021-07-12 19:14:15,452 [run_pretraining.py:  535]:	loss/mlm_loss, 7.963428497314453, 2070
[INFO] 2021-07-12 19:14:15,452 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.069000038318336e-05, 2070
[INFO] 2021-07-12 19:14:15,452 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2070
[INFO] 2021-07-12 19:14:15,452 [run_pretraining.py:  558]:	worker_index: 2, step: 2070, cost: 7.963428, mlm loss: 7.963428, speed: 1.072107 steps/s, speed: 8.576853 samples/s, speed: 4391.348615 tokens/s, learning rate: 2.069e-05, loss_scalings: 3518.437988, pp_loss: 7.680300
[INFO] 2021-07-12 19:14:15,452 [run_pretraining.py:  512]:	********exe.run_2070******* 
[INFO] 2021-07-12 19:14:16,384 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:16,385 [run_pretraining.py:  534]:	loss/total_loss, 7.324948310852051, 2071
[INFO] 2021-07-12 19:14:16,385 [run_pretraining.py:  535]:	loss/mlm_loss, 7.324948310852051, 2071
[INFO] 2021-07-12 19:14:16,385 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.069999936793465e-05, 2071
[INFO] 2021-07-12 19:14:16,385 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2071
[INFO] 2021-07-12 19:14:16,385 [run_pretraining.py:  558]:	worker_index: 2, step: 2071, cost: 7.324948, mlm loss: 7.324948, speed: 1.072378 steps/s, speed: 8.579024 samples/s, speed: 4392.460145 tokens/s, learning rate: 2.070e-05, loss_scalings: 3518.437988, pp_loss: 7.336486
[INFO] 2021-07-12 19:14:16,385 [run_pretraining.py:  512]:	********exe.run_2071******* 
[INFO] 2021-07-12 19:14:17,316 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:17,317 [run_pretraining.py:  534]:	loss/total_loss, 7.292622089385986, 2072
[INFO] 2021-07-12 19:14:17,317 [run_pretraining.py:  535]:	loss/mlm_loss, 7.292622089385986, 2072
[INFO] 2021-07-12 19:14:17,317 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0710000171675347e-05, 2072
[INFO] 2021-07-12 19:14:17,317 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2072
[INFO] 2021-07-12 19:14:17,317 [run_pretraining.py:  558]:	worker_index: 2, step: 2072, cost: 7.292622, mlm loss: 7.292622, speed: 1.073820 steps/s, speed: 8.590561 samples/s, speed: 4398.367416 tokens/s, learning rate: 2.071e-05, loss_scalings: 3518.437988, pp_loss: 7.464824
[INFO] 2021-07-12 19:14:17,317 [run_pretraining.py:  512]:	********exe.run_2072******* 
[INFO] 2021-07-12 19:14:18,249 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:18,250 [run_pretraining.py:  534]:	loss/total_loss, 7.226905822753906, 2073
[INFO] 2021-07-12 19:14:18,250 [run_pretraining.py:  535]:	loss/mlm_loss, 7.226905822753906, 2073
[INFO] 2021-07-12 19:14:18,250 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.071999915642664e-05, 2073
[INFO] 2021-07-12 19:14:18,250 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2073
[INFO] 2021-07-12 19:14:18,250 [run_pretraining.py:  558]:	worker_index: 2, step: 2073, cost: 7.226906, mlm loss: 7.226906, speed: 1.072353 steps/s, speed: 8.578826 samples/s, speed: 4392.359074 tokens/s, learning rate: 2.072e-05, loss_scalings: 3518.437988, pp_loss: 7.020987
[INFO] 2021-07-12 19:14:18,250 [run_pretraining.py:  512]:	********exe.run_2073******* 
[INFO] 2021-07-12 19:14:19,178 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:19,178 [run_pretraining.py:  534]:	loss/total_loss, 4.519973278045654, 2074
[INFO] 2021-07-12 19:14:19,178 [run_pretraining.py:  535]:	loss/mlm_loss, 4.519973278045654, 2074
[INFO] 2021-07-12 19:14:19,178 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0729999960167333e-05, 2074
[INFO] 2021-07-12 19:14:19,178 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2074
[INFO] 2021-07-12 19:14:19,178 [run_pretraining.py:  558]:	worker_index: 2, step: 2074, cost: 4.519973, mlm loss: 4.519973, speed: 1.077808 steps/s, speed: 8.622462 samples/s, speed: 4414.700598 tokens/s, learning rate: 2.073e-05, loss_scalings: 3518.437988, pp_loss: 6.730990
[INFO] 2021-07-12 19:14:19,179 [run_pretraining.py:  512]:	********exe.run_2074******* 
[INFO] 2021-07-12 19:14:20,107 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:20,108 [run_pretraining.py:  534]:	loss/total_loss, 5.630908012390137, 2075
[INFO] 2021-07-12 19:14:20,108 [run_pretraining.py:  535]:	loss/mlm_loss, 5.630908012390137, 2075
[INFO] 2021-07-12 19:14:20,108 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0739998944918625e-05, 2075
[INFO] 2021-07-12 19:14:20,108 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2075
[INFO] 2021-07-12 19:14:20,108 [run_pretraining.py:  558]:	worker_index: 2, step: 2075, cost: 5.630908, mlm loss: 5.630908, speed: 1.076372 steps/s, speed: 8.610973 samples/s, speed: 4408.818418 tokens/s, learning rate: 2.074e-05, loss_scalings: 3518.437988, pp_loss: 6.942690
[INFO] 2021-07-12 19:14:20,108 [run_pretraining.py:  512]:	********exe.run_2075******* 
[INFO] 2021-07-12 19:14:21,049 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:21,054 [run_pretraining.py:  534]:	loss/total_loss, 7.149030685424805, 2076
[INFO] 2021-07-12 19:14:21,057 [run_pretraining.py:  535]:	loss/mlm_loss, 7.149030685424805, 2076
[INFO] 2021-07-12 19:14:21,057 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.074999974865932e-05, 2076
[INFO] 2021-07-12 19:14:21,057 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2076
[INFO] 2021-07-12 19:14:21,058 [run_pretraining.py:  558]:	worker_index: 2, step: 2076, cost: 7.149031, mlm loss: 7.149031, speed: 1.057047 steps/s, speed: 8.456373 samples/s, speed: 4329.663051 tokens/s, learning rate: 2.075e-05, loss_scalings: 3518.437988, pp_loss: 7.201818
[INFO] 2021-07-12 19:14:21,058 [run_pretraining.py:  512]:	********exe.run_2076******* 
[INFO] 2021-07-12 19:14:22,001 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:22,002 [run_pretraining.py:  534]:	loss/total_loss, 7.573430061340332, 2077
[INFO] 2021-07-12 19:14:22,002 [run_pretraining.py:  535]:	loss/mlm_loss, 7.573430061340332, 2077
[INFO] 2021-07-12 19:14:22,002 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0759998733410612e-05, 2077
[INFO] 2021-07-12 19:14:22,002 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2077
[INFO] 2021-07-12 19:14:22,002 [run_pretraining.py:  558]:	worker_index: 2, step: 2077, cost: 7.573430, mlm loss: 7.573430, speed: 1.059835 steps/s, speed: 8.478679 samples/s, speed: 4341.083714 tokens/s, learning rate: 2.076e-05, loss_scalings: 3518.437988, pp_loss: 7.114386
[INFO] 2021-07-12 19:14:22,002 [run_pretraining.py:  512]:	********exe.run_2077******* 
[INFO] 2021-07-12 19:14:22,944 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:22,945 [run_pretraining.py:  534]:	loss/total_loss, 7.034714221954346, 2078
[INFO] 2021-07-12 19:14:22,945 [run_pretraining.py:  535]:	loss/mlm_loss, 7.034714221954346, 2078
[INFO] 2021-07-12 19:14:22,945 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0769999537151307e-05, 2078
[INFO] 2021-07-12 19:14:22,945 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2078
[INFO] 2021-07-12 19:14:22,945 [run_pretraining.py:  558]:	worker_index: 2, step: 2078, cost: 7.034714, mlm loss: 7.034714, speed: 1.061334 steps/s, speed: 8.490672 samples/s, speed: 4347.224191 tokens/s, learning rate: 2.077e-05, loss_scalings: 3518.437988, pp_loss: 7.384356
[INFO] 2021-07-12 19:14:22,945 [run_pretraining.py:  512]:	********exe.run_2078******* 
[INFO] 2021-07-12 19:14:23,899 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:23,899 [run_pretraining.py:  534]:	loss/total_loss, 7.176119804382324, 2079
[INFO] 2021-07-12 19:14:23,899 [run_pretraining.py:  535]:	loss/mlm_loss, 7.176119804382324, 2079
[INFO] 2021-07-12 19:14:23,899 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0780000340892002e-05, 2079
[INFO] 2021-07-12 19:14:23,899 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2079
[INFO] 2021-07-12 19:14:23,899 [run_pretraining.py:  558]:	worker_index: 2, step: 2079, cost: 7.176120, mlm loss: 7.176120, speed: 1.048322 steps/s, speed: 8.386574 samples/s, speed: 4293.926019 tokens/s, learning rate: 2.078e-05, loss_scalings: 3518.437988, pp_loss: 7.253857
[INFO] 2021-07-12 19:14:23,900 [run_pretraining.py:  512]:	********exe.run_2079******* 
[INFO] 2021-07-12 19:14:24,833 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:24,833 [run_pretraining.py:  534]:	loss/total_loss, 7.22119140625, 2080
[INFO] 2021-07-12 19:14:24,833 [run_pretraining.py:  535]:	loss/mlm_loss, 7.22119140625, 2080
[INFO] 2021-07-12 19:14:24,834 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0789999325643294e-05, 2080
[INFO] 2021-07-12 19:14:24,834 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2080
[INFO] 2021-07-12 19:14:24,834 [run_pretraining.py:  558]:	worker_index: 2, step: 2080, cost: 7.221191, mlm loss: 7.221191, speed: 1.071089 steps/s, speed: 8.568714 samples/s, speed: 4387.181463 tokens/s, learning rate: 2.079e-05, loss_scalings: 3518.437988, pp_loss: 7.008776
[INFO] 2021-07-12 19:14:24,834 [run_pretraining.py:  512]:	********exe.run_2080******* 
[INFO] 2021-07-12 19:14:25,775 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:25,776 [run_pretraining.py:  534]:	loss/total_loss, 7.162406921386719, 2081
[INFO] 2021-07-12 19:14:25,776 [run_pretraining.py:  535]:	loss/mlm_loss, 7.162406921386719, 2081
[INFO] 2021-07-12 19:14:25,776 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.080000012938399e-05, 2081
[INFO] 2021-07-12 19:14:25,776 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2081
[INFO] 2021-07-12 19:14:25,776 [run_pretraining.py:  558]:	worker_index: 2, step: 2081, cost: 7.162407, mlm loss: 7.162407, speed: 1.061759 steps/s, speed: 8.494068 samples/s, speed: 4348.962933 tokens/s, learning rate: 2.080e-05, loss_scalings: 3518.437988, pp_loss: 7.181302
[INFO] 2021-07-12 19:14:25,776 [run_pretraining.py:  512]:	********exe.run_2081******* 
[INFO] 2021-07-12 19:14:26,726 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:26,726 [run_pretraining.py:  534]:	loss/total_loss, 7.2377519607543945, 2082
[INFO] 2021-07-12 19:14:26,727 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2377519607543945, 2082
[INFO] 2021-07-12 19:14:26,727 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0810000933124684e-05, 2082
[INFO] 2021-07-12 19:14:26,727 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2082
[INFO] 2021-07-12 19:14:26,727 [run_pretraining.py:  558]:	worker_index: 2, step: 2082, cost: 7.237752, mlm loss: 7.237752, speed: 1.052458 steps/s, speed: 8.419664 samples/s, speed: 4310.867932 tokens/s, learning rate: 2.081e-05, loss_scalings: 3518.437988, pp_loss: 7.095236
[INFO] 2021-07-12 19:14:26,727 [run_pretraining.py:  512]:	********exe.run_2082******* 
[INFO] 2021-07-12 19:14:27,656 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:27,657 [run_pretraining.py:  534]:	loss/total_loss, 6.425896644592285, 2083
[INFO] 2021-07-12 19:14:27,657 [run_pretraining.py:  535]:	loss/mlm_loss, 6.425896644592285, 2083
[INFO] 2021-07-12 19:14:27,657 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0819998098886572e-05, 2083
[INFO] 2021-07-12 19:14:27,657 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2083
[INFO] 2021-07-12 19:14:27,657 [run_pretraining.py:  558]:	worker_index: 2, step: 2083, cost: 6.425897, mlm loss: 6.425897, speed: 1.075624 steps/s, speed: 8.604989 samples/s, speed: 4405.754396 tokens/s, learning rate: 2.082e-05, loss_scalings: 3518.437988, pp_loss: 6.706403
[INFO] 2021-07-12 19:14:27,657 [run_pretraining.py:  512]:	********exe.run_2083******* 
[INFO] 2021-07-12 19:14:28,588 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:28,589 [run_pretraining.py:  534]:	loss/total_loss, 7.045003890991211, 2084
[INFO] 2021-07-12 19:14:28,589 [run_pretraining.py:  535]:	loss/mlm_loss, 7.045003890991211, 2084
[INFO] 2021-07-12 19:14:28,589 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0829998902627267e-05, 2084
[INFO] 2021-07-12 19:14:28,589 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2084
[INFO] 2021-07-12 19:14:28,589 [run_pretraining.py:  558]:	worker_index: 2, step: 2084, cost: 7.045004, mlm loss: 7.045004, speed: 1.073499 steps/s, speed: 8.587995 samples/s, speed: 4397.053692 tokens/s, learning rate: 2.083e-05, loss_scalings: 3518.437988, pp_loss: 7.058619
[INFO] 2021-07-12 19:14:28,589 [run_pretraining.py:  512]:	********exe.run_2084******* 
[INFO] 2021-07-12 19:14:29,490 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:29,490 [run_pretraining.py:  534]:	loss/total_loss, 7.462852478027344, 2085
[INFO] 2021-07-12 19:14:29,491 [run_pretraining.py:  535]:	loss/mlm_loss, 7.462852478027344, 2085
[INFO] 2021-07-12 19:14:29,491 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0839999706367962e-05, 2085
[INFO] 2021-07-12 19:14:29,491 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2085
[INFO] 2021-07-12 19:14:29,491 [run_pretraining.py:  558]:	worker_index: 2, step: 2085, cost: 7.462852, mlm loss: 7.462852, speed: 1.109919 steps/s, speed: 8.879354 samples/s, speed: 4546.229441 tokens/s, learning rate: 2.084e-05, loss_scalings: 3518.437988, pp_loss: 7.247912
[INFO] 2021-07-12 19:14:29,491 [run_pretraining.py:  512]:	********exe.run_2085******* 
[INFO] 2021-07-12 19:14:30,418 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:30,418 [run_pretraining.py:  534]:	loss/total_loss, 7.533786773681641, 2086
[INFO] 2021-07-12 19:14:30,418 [run_pretraining.py:  535]:	loss/mlm_loss, 7.533786773681641, 2086
[INFO] 2021-07-12 19:14:30,418 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0849998691119254e-05, 2086
[INFO] 2021-07-12 19:14:30,418 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2086
[INFO] 2021-07-12 19:14:30,419 [run_pretraining.py:  558]:	worker_index: 2, step: 2086, cost: 7.533787, mlm loss: 7.533787, speed: 1.078641 steps/s, speed: 8.629125 samples/s, speed: 4418.112234 tokens/s, learning rate: 2.085e-05, loss_scalings: 3518.437988, pp_loss: 7.099038
[INFO] 2021-07-12 19:14:30,419 [run_pretraining.py:  512]:	********exe.run_2086******* 
[INFO] 2021-07-12 19:14:31,345 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:31,346 [run_pretraining.py:  534]:	loss/total_loss, 7.441495895385742, 2087
[INFO] 2021-07-12 19:14:31,346 [run_pretraining.py:  535]:	loss/mlm_loss, 7.441495895385742, 2087
[INFO] 2021-07-12 19:14:31,346 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.085999949485995e-05, 2087
[INFO] 2021-07-12 19:14:31,346 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2087
[INFO] 2021-07-12 19:14:31,346 [run_pretraining.py:  558]:	worker_index: 2, step: 2087, cost: 7.441496, mlm loss: 7.441496, speed: 1.078839 steps/s, speed: 8.630715 samples/s, speed: 4418.925901 tokens/s, learning rate: 2.086e-05, loss_scalings: 3518.437988, pp_loss: 7.524276
[INFO] 2021-07-12 19:14:31,346 [run_pretraining.py:  512]:	********exe.run_2087******* 
[INFO] 2021-07-12 19:14:32,269 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:32,270 [run_pretraining.py:  534]:	loss/total_loss, 8.050629615783691, 2088
[INFO] 2021-07-12 19:14:32,270 [run_pretraining.py:  535]:	loss/mlm_loss, 8.050629615783691, 2088
[INFO] 2021-07-12 19:14:32,270 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0870000298600644e-05, 2088
[INFO] 2021-07-12 19:14:32,270 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2088
[INFO] 2021-07-12 19:14:32,270 [run_pretraining.py:  558]:	worker_index: 2, step: 2088, cost: 8.050630, mlm loss: 8.050630, speed: 1.082935 steps/s, speed: 8.663479 samples/s, speed: 4435.700999 tokens/s, learning rate: 2.087e-05, loss_scalings: 3518.437988, pp_loss: 7.387354
[INFO] 2021-07-12 19:14:32,270 [run_pretraining.py:  512]:	********exe.run_2088******* 
[INFO] 2021-07-12 19:14:33,187 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:33,188 [run_pretraining.py:  534]:	loss/total_loss, 7.163704872131348, 2089
[INFO] 2021-07-12 19:14:33,188 [run_pretraining.py:  535]:	loss/mlm_loss, 7.163704872131348, 2089
[INFO] 2021-07-12 19:14:33,188 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0879999283351935e-05, 2089
[INFO] 2021-07-12 19:14:33,188 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2089
[INFO] 2021-07-12 19:14:33,188 [run_pretraining.py:  558]:	worker_index: 2, step: 2089, cost: 7.163705, mlm loss: 7.163705, speed: 1.090024 steps/s, speed: 8.720196 samples/s, speed: 4464.740157 tokens/s, learning rate: 2.088e-05, loss_scalings: 3518.437988, pp_loss: 7.137834
[INFO] 2021-07-12 19:14:33,188 [run_pretraining.py:  512]:	********exe.run_2089******* 
[INFO] 2021-07-12 19:14:34,102 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:34,102 [run_pretraining.py:  534]:	loss/total_loss, 6.669787406921387, 2090
[INFO] 2021-07-12 19:14:34,103 [run_pretraining.py:  535]:	loss/mlm_loss, 6.669787406921387, 2090
[INFO] 2021-07-12 19:14:34,103 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.089000008709263e-05, 2090
[INFO] 2021-07-12 19:14:34,103 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2090
[INFO] 2021-07-12 19:14:34,103 [run_pretraining.py:  558]:	worker_index: 2, step: 2090, cost: 6.669787, mlm loss: 6.669787, speed: 1.093846 steps/s, speed: 8.750772 samples/s, speed: 4480.395171 tokens/s, learning rate: 2.089e-05, loss_scalings: 3518.437988, pp_loss: 7.017364
[INFO] 2021-07-12 19:14:34,103 [run_pretraining.py:  512]:	********exe.run_2090******* 
[INFO] 2021-07-12 19:14:35,020 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:35,020 [run_pretraining.py:  534]:	loss/total_loss, 8.151809692382812, 2091
[INFO] 2021-07-12 19:14:35,020 [run_pretraining.py:  535]:	loss/mlm_loss, 8.151809692382812, 2091
[INFO] 2021-07-12 19:14:35,021 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0900000890833326e-05, 2091
[INFO] 2021-07-12 19:14:35,021 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2091
[INFO] 2021-07-12 19:14:35,021 [run_pretraining.py:  558]:	worker_index: 2, step: 2091, cost: 8.151810, mlm loss: 8.151810, speed: 1.090241 steps/s, speed: 8.721927 samples/s, speed: 4465.626806 tokens/s, learning rate: 2.090e-05, loss_scalings: 3518.437988, pp_loss: 7.458131
[INFO] 2021-07-12 19:14:35,021 [run_pretraining.py:  512]:	********exe.run_2091******* 
[INFO] 2021-07-12 19:14:35,943 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:35,944 [run_pretraining.py:  534]:	loss/total_loss, 7.398859024047852, 2092
[INFO] 2021-07-12 19:14:35,944 [run_pretraining.py:  535]:	loss/mlm_loss, 7.398859024047852, 2092
[INFO] 2021-07-12 19:14:35,944 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0909998056595214e-05, 2092
[INFO] 2021-07-12 19:14:35,944 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2092
[INFO] 2021-07-12 19:14:35,944 [run_pretraining.py:  558]:	worker_index: 2, step: 2092, cost: 7.398859, mlm loss: 7.398859, speed: 1.083660 steps/s, speed: 8.669278 samples/s, speed: 4438.670359 tokens/s, learning rate: 2.091e-05, loss_scalings: 3518.437988, pp_loss: 7.339376
[INFO] 2021-07-12 19:14:35,944 [run_pretraining.py:  512]:	********exe.run_2092******* 
[INFO] 2021-07-12 19:14:36,869 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:36,869 [run_pretraining.py:  534]:	loss/total_loss, 6.15109395980835, 2093
[INFO] 2021-07-12 19:14:36,869 [run_pretraining.py:  535]:	loss/mlm_loss, 6.15109395980835, 2093
[INFO] 2021-07-12 19:14:36,869 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.091999886033591e-05, 2093
[INFO] 2021-07-12 19:14:36,869 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2093
[INFO] 2021-07-12 19:14:36,869 [run_pretraining.py:  558]:	worker_index: 2, step: 2093, cost: 6.151094, mlm loss: 6.151094, speed: 1.081337 steps/s, speed: 8.650698 samples/s, speed: 4429.157480 tokens/s, learning rate: 2.092e-05, loss_scalings: 3518.437988, pp_loss: 7.029660
[INFO] 2021-07-12 19:14:36,870 [run_pretraining.py:  512]:	********exe.run_2093******* 
[INFO] 2021-07-12 19:14:37,793 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:37,794 [run_pretraining.py:  534]:	loss/total_loss, 7.662964820861816, 2094
[INFO] 2021-07-12 19:14:37,794 [run_pretraining.py:  535]:	loss/mlm_loss, 7.662964820861816, 2094
[INFO] 2021-07-12 19:14:37,794 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0929999664076604e-05, 2094
[INFO] 2021-07-12 19:14:37,794 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2094
[INFO] 2021-07-12 19:14:37,794 [run_pretraining.py:  558]:	worker_index: 2, step: 2094, cost: 7.662965, mlm loss: 7.662965, speed: 1.082245 steps/s, speed: 8.657962 samples/s, speed: 4432.876294 tokens/s, learning rate: 2.093e-05, loss_scalings: 3518.437988, pp_loss: 7.661055
[INFO] 2021-07-12 19:14:37,794 [run_pretraining.py:  512]:	********exe.run_2094******* 
[INFO] 2021-07-12 19:14:38,717 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:38,717 [run_pretraining.py:  534]:	loss/total_loss, 7.306521892547607, 2095
[INFO] 2021-07-12 19:14:38,717 [run_pretraining.py:  535]:	loss/mlm_loss, 7.306521892547607, 2095
[INFO] 2021-07-12 19:14:38,718 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0939998648827896e-05, 2095
[INFO] 2021-07-12 19:14:38,718 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2095
[INFO] 2021-07-12 19:14:38,718 [run_pretraining.py:  558]:	worker_index: 2, step: 2095, cost: 7.306522, mlm loss: 7.306522, speed: 1.083454 steps/s, speed: 8.667634 samples/s, speed: 4437.828770 tokens/s, learning rate: 2.094e-05, loss_scalings: 3518.437988, pp_loss: 7.215159
[INFO] 2021-07-12 19:14:38,718 [run_pretraining.py:  512]:	********exe.run_2095******* 
[INFO] 2021-07-12 19:14:39,639 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:39,640 [run_pretraining.py:  534]:	loss/total_loss, 6.743197441101074, 2096
[INFO] 2021-07-12 19:14:39,640 [run_pretraining.py:  535]:	loss/mlm_loss, 6.743197441101074, 2096
[INFO] 2021-07-12 19:14:39,640 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.094999945256859e-05, 2096
[INFO] 2021-07-12 19:14:39,640 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2096
[INFO] 2021-07-12 19:14:39,640 [run_pretraining.py:  558]:	worker_index: 2, step: 2096, cost: 6.743197, mlm loss: 6.743197, speed: 1.084938 steps/s, speed: 8.679506 samples/s, speed: 4443.907063 tokens/s, learning rate: 2.095e-05, loss_scalings: 3518.437988, pp_loss: 7.225572
[INFO] 2021-07-12 19:14:39,640 [run_pretraining.py:  512]:	********exe.run_2096******* 
[INFO] 2021-07-12 19:14:40,566 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:40,567 [run_pretraining.py:  534]:	loss/total_loss, 7.904274940490723, 2097
[INFO] 2021-07-12 19:14:40,567 [run_pretraining.py:  535]:	loss/mlm_loss, 7.904274940490723, 2097
[INFO] 2021-07-12 19:14:40,567 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0960000256309286e-05, 2097
[INFO] 2021-07-12 19:14:40,567 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2097
[INFO] 2021-07-12 19:14:40,567 [run_pretraining.py:  558]:	worker_index: 2, step: 2097, cost: 7.904275, mlm loss: 7.904275, speed: 1.079380 steps/s, speed: 8.635039 samples/s, speed: 4421.140000 tokens/s, learning rate: 2.096e-05, loss_scalings: 3518.437988, pp_loss: 7.280139
[INFO] 2021-07-12 19:14:40,567 [run_pretraining.py:  512]:	********exe.run_2097******* 
[INFO] 2021-07-12 19:14:41,481 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:41,481 [run_pretraining.py:  534]:	loss/total_loss, 7.629382610321045, 2098
[INFO] 2021-07-12 19:14:41,481 [run_pretraining.py:  535]:	loss/mlm_loss, 7.629382610321045, 2098
[INFO] 2021-07-12 19:14:41,481 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0969999241060577e-05, 2098
[INFO] 2021-07-12 19:14:41,482 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2098
[INFO] 2021-07-12 19:14:41,482 [run_pretraining.py:  558]:	worker_index: 2, step: 2098, cost: 7.629383, mlm loss: 7.629383, speed: 1.094112 steps/s, speed: 8.752899 samples/s, speed: 4481.484438 tokens/s, learning rate: 2.097e-05, loss_scalings: 3518.437988, pp_loss: 7.124333
[INFO] 2021-07-12 19:14:41,482 [run_pretraining.py:  512]:	********exe.run_2098******* 
[INFO] 2021-07-12 19:14:42,399 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:42,399 [run_pretraining.py:  534]:	loss/total_loss, 7.0735883712768555, 2099
[INFO] 2021-07-12 19:14:42,400 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0735883712768555, 2099
[INFO] 2021-07-12 19:14:42,400 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0980000044801272e-05, 2099
[INFO] 2021-07-12 19:14:42,400 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2099
[INFO] 2021-07-12 19:14:42,400 [run_pretraining.py:  558]:	worker_index: 2, step: 2099, cost: 7.073588, mlm loss: 7.073588, speed: 1.089815 steps/s, speed: 8.718523 samples/s, speed: 4463.884015 tokens/s, learning rate: 2.098e-05, loss_scalings: 3518.437988, pp_loss: 6.937042
[INFO] 2021-07-12 19:14:42,400 [run_pretraining.py:  512]:	********exe.run_2099******* 
[INFO] 2021-07-12 19:14:43,318 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:43,318 [run_pretraining.py:  534]:	loss/total_loss, 6.3968505859375, 2100
[INFO] 2021-07-12 19:14:43,318 [run_pretraining.py:  535]:	loss/mlm_loss, 6.3968505859375, 2100
[INFO] 2021-07-12 19:14:43,318 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0990000848541968e-05, 2100
[INFO] 2021-07-12 19:14:43,318 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2100
[INFO] 2021-07-12 19:14:43,318 [run_pretraining.py:  558]:	worker_index: 2, step: 2100, cost: 6.396851, mlm loss: 6.396851, speed: 1.089332 steps/s, speed: 8.714658 samples/s, speed: 4461.905010 tokens/s, learning rate: 2.099e-05, loss_scalings: 3518.437988, pp_loss: 7.255035
[INFO] 2021-07-12 19:14:43,318 [run_pretraining.py:  512]:	********exe.run_2100******* 
[INFO] 2021-07-12 19:14:44,232 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:44,232 [run_pretraining.py:  534]:	loss/total_loss, 7.274410247802734, 2101
[INFO] 2021-07-12 19:14:44,232 [run_pretraining.py:  535]:	loss/mlm_loss, 7.274410247802734, 2101
[INFO] 2021-07-12 19:14:44,232 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0999998014303856e-05, 2101
[INFO] 2021-07-12 19:14:44,233 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2101
[INFO] 2021-07-12 19:14:44,233 [run_pretraining.py:  558]:	worker_index: 2, step: 2101, cost: 7.274410, mlm loss: 7.274410, speed: 1.094499 steps/s, speed: 8.755994 samples/s, speed: 4483.069027 tokens/s, learning rate: 2.100e-05, loss_scalings: 3518.437988, pp_loss: 7.195128
[INFO] 2021-07-12 19:14:44,233 [run_pretraining.py:  512]:	********exe.run_2101******* 
[INFO] 2021-07-12 19:14:45,159 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:45,160 [run_pretraining.py:  534]:	loss/total_loss, 7.725609302520752, 2102
[INFO] 2021-07-12 19:14:45,160 [run_pretraining.py:  535]:	loss/mlm_loss, 7.725609302520752, 2102
[INFO] 2021-07-12 19:14:45,160 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.100999881804455e-05, 2102
[INFO] 2021-07-12 19:14:45,160 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2102
[INFO] 2021-07-12 19:14:45,160 [run_pretraining.py:  558]:	worker_index: 2, step: 2102, cost: 7.725609, mlm loss: 7.725609, speed: 1.079117 steps/s, speed: 8.632940 samples/s, speed: 4420.065083 tokens/s, learning rate: 2.101e-05, loss_scalings: 3518.437988, pp_loss: 7.202038
[INFO] 2021-07-12 19:14:45,160 [run_pretraining.py:  512]:	********exe.run_2102******* 
[INFO] 2021-07-12 19:14:46,081 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:46,081 [run_pretraining.py:  534]:	loss/total_loss, 6.897022247314453, 2103
[INFO] 2021-07-12 19:14:46,082 [run_pretraining.py:  535]:	loss/mlm_loss, 6.897022247314453, 2103
[INFO] 2021-07-12 19:14:46,082 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1019999621785246e-05, 2103
[INFO] 2021-07-12 19:14:46,082 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2103
[INFO] 2021-07-12 19:14:46,082 [run_pretraining.py:  558]:	worker_index: 2, step: 2103, cost: 6.897022, mlm loss: 6.897022, speed: 1.085362 steps/s, speed: 8.682893 samples/s, speed: 4445.641190 tokens/s, learning rate: 2.102e-05, loss_scalings: 3518.437988, pp_loss: 7.165065
[INFO] 2021-07-12 19:14:46,082 [run_pretraining.py:  512]:	********exe.run_2103******* 
[INFO] 2021-07-12 19:14:46,996 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:46,997 [run_pretraining.py:  534]:	loss/total_loss, 7.016423225402832, 2104
[INFO] 2021-07-12 19:14:46,997 [run_pretraining.py:  535]:	loss/mlm_loss, 7.016423225402832, 2104
[INFO] 2021-07-12 19:14:46,997 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1029998606536537e-05, 2104
[INFO] 2021-07-12 19:14:46,997 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2104
[INFO] 2021-07-12 19:14:46,997 [run_pretraining.py:  558]:	worker_index: 2, step: 2104, cost: 7.016423, mlm loss: 7.016423, speed: 1.093400 steps/s, speed: 8.747199 samples/s, speed: 4478.566114 tokens/s, learning rate: 2.103e-05, loss_scalings: 3518.437988, pp_loss: 7.323470
[INFO] 2021-07-12 19:14:46,997 [run_pretraining.py:  512]:	********exe.run_2104******* 
[INFO] 2021-07-12 19:14:47,913 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:47,913 [run_pretraining.py:  534]:	loss/total_loss, 7.493516445159912, 2105
[INFO] 2021-07-12 19:14:47,913 [run_pretraining.py:  535]:	loss/mlm_loss, 7.493516445159912, 2105
[INFO] 2021-07-12 19:14:47,913 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1039999410277233e-05, 2105
[INFO] 2021-07-12 19:14:47,913 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2105
[INFO] 2021-07-12 19:14:47,913 [run_pretraining.py:  558]:	worker_index: 2, step: 2105, cost: 7.493516, mlm loss: 7.493516, speed: 1.091949 steps/s, speed: 8.735592 samples/s, speed: 4472.623246 tokens/s, learning rate: 2.104e-05, loss_scalings: 3518.437988, pp_loss: 7.485770
[INFO] 2021-07-12 19:14:47,913 [run_pretraining.py:  512]:	********exe.run_2105******* 
[INFO] 2021-07-12 19:14:48,829 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:48,830 [run_pretraining.py:  534]:	loss/total_loss, 7.175958633422852, 2106
[INFO] 2021-07-12 19:14:48,830 [run_pretraining.py:  535]:	loss/mlm_loss, 7.175958633422852, 2106
[INFO] 2021-07-12 19:14:48,830 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1050000214017928e-05, 2106
[INFO] 2021-07-12 19:14:48,830 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2106
[INFO] 2021-07-12 19:14:48,830 [run_pretraining.py:  558]:	worker_index: 2, step: 2106, cost: 7.175959, mlm loss: 7.175959, speed: 1.091556 steps/s, speed: 8.732446 samples/s, speed: 4471.012287 tokens/s, learning rate: 2.105e-05, loss_scalings: 3518.437988, pp_loss: 7.545479
[INFO] 2021-07-12 19:14:48,830 [run_pretraining.py:  512]:	********exe.run_2106******* 
[INFO] 2021-07-12 19:14:49,788 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:49,788 [run_pretraining.py:  534]:	loss/total_loss, 7.652278900146484, 2107
[INFO] 2021-07-12 19:14:49,788 [run_pretraining.py:  535]:	loss/mlm_loss, 7.652278900146484, 2107
[INFO] 2021-07-12 19:14:49,788 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.105999919876922e-05, 2107
[INFO] 2021-07-12 19:14:49,788 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2107
[INFO] 2021-07-12 19:14:49,789 [run_pretraining.py:  558]:	worker_index: 2, step: 2107, cost: 7.652279, mlm loss: 7.652279, speed: 1.044076 steps/s, speed: 8.352606 samples/s, speed: 4276.534364 tokens/s, learning rate: 2.106e-05, loss_scalings: 3518.437988, pp_loss: 7.357541
[INFO] 2021-07-12 19:14:49,789 [run_pretraining.py:  512]:	********exe.run_2107******* 
[INFO] 2021-07-12 19:14:50,842 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:50,843 [run_pretraining.py:  534]:	loss/total_loss, 7.37065315246582, 2108
[INFO] 2021-07-12 19:14:50,843 [run_pretraining.py:  535]:	loss/mlm_loss, 7.37065315246582, 2108
[INFO] 2021-07-12 19:14:50,843 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1070000002509914e-05, 2108
[INFO] 2021-07-12 19:14:50,843 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2108
[INFO] 2021-07-12 19:14:50,843 [run_pretraining.py:  558]:	worker_index: 2, step: 2108, cost: 7.370653, mlm loss: 7.370653, speed: 0.948871 steps/s, speed: 7.590965 samples/s, speed: 3886.573885 tokens/s, learning rate: 2.107e-05, loss_scalings: 3518.437988, pp_loss: 7.087161
[INFO] 2021-07-12 19:14:50,843 [run_pretraining.py:  512]:	********exe.run_2108******* 
[INFO] 2021-07-12 19:14:51,900 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:51,901 [run_pretraining.py:  534]:	loss/total_loss, 7.137574672698975, 2109
[INFO] 2021-07-12 19:14:51,901 [run_pretraining.py:  535]:	loss/mlm_loss, 7.137574672698975, 2109
[INFO] 2021-07-12 19:14:51,901 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.108000080625061e-05, 2109
[INFO] 2021-07-12 19:14:51,901 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2109
[INFO] 2021-07-12 19:14:51,901 [run_pretraining.py:  558]:	worker_index: 2, step: 2109, cost: 7.137575, mlm loss: 7.137575, speed: 0.945481 steps/s, speed: 7.563850 samples/s, speed: 3872.691005 tokens/s, learning rate: 2.108e-05, loss_scalings: 3518.437988, pp_loss: 7.374456
[INFO] 2021-07-12 19:14:51,901 [run_pretraining.py:  512]:	********exe.run_2109******* 
[INFO] 2021-07-12 19:14:52,964 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:52,964 [run_pretraining.py:  534]:	loss/total_loss, 7.518315315246582, 2110
[INFO] 2021-07-12 19:14:52,964 [run_pretraining.py:  535]:	loss/mlm_loss, 7.518315315246582, 2110
[INFO] 2021-07-12 19:14:52,964 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1089997972012497e-05, 2110
[INFO] 2021-07-12 19:14:52,964 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2110
[INFO] 2021-07-12 19:14:52,964 [run_pretraining.py:  558]:	worker_index: 2, step: 2110, cost: 7.518315, mlm loss: 7.518315, speed: 0.941143 steps/s, speed: 7.529141 samples/s, speed: 3854.920420 tokens/s, learning rate: 2.109e-05, loss_scalings: 3518.437988, pp_loss: 7.190178
[INFO] 2021-07-12 19:14:52,964 [run_pretraining.py:  512]:	********exe.run_2110******* 
[INFO] 2021-07-12 19:14:54,021 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:54,021 [run_pretraining.py:  534]:	loss/total_loss, 6.42125129699707, 2111
[INFO] 2021-07-12 19:14:54,021 [run_pretraining.py:  535]:	loss/mlm_loss, 6.42125129699707, 2111
[INFO] 2021-07-12 19:14:54,021 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1099998775753193e-05, 2111
[INFO] 2021-07-12 19:14:54,021 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2111
[INFO] 2021-07-12 19:14:54,021 [run_pretraining.py:  558]:	worker_index: 2, step: 2111, cost: 6.421251, mlm loss: 6.421251, speed: 0.946526 steps/s, speed: 7.572212 samples/s, speed: 3876.972478 tokens/s, learning rate: 2.110e-05, loss_scalings: 3518.437988, pp_loss: 6.964666
[INFO] 2021-07-12 19:14:54,022 [run_pretraining.py:  512]:	********exe.run_2111******* 
[INFO] 2021-07-12 19:14:55,076 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:55,077 [run_pretraining.py:  534]:	loss/total_loss, 7.036565780639648, 2112
[INFO] 2021-07-12 19:14:55,077 [run_pretraining.py:  535]:	loss/mlm_loss, 7.036565780639648, 2112
[INFO] 2021-07-12 19:14:55,077 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1109999579493888e-05, 2112
[INFO] 2021-07-12 19:14:55,077 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2112
[INFO] 2021-07-12 19:14:55,077 [run_pretraining.py:  558]:	worker_index: 2, step: 2112, cost: 7.036566, mlm loss: 7.036566, speed: 0.947782 steps/s, speed: 7.582254 samples/s, speed: 3882.114160 tokens/s, learning rate: 2.111e-05, loss_scalings: 3518.437988, pp_loss: 7.224282
[INFO] 2021-07-12 19:14:55,077 [run_pretraining.py:  512]:	********exe.run_2112******* 
[INFO] 2021-07-12 19:14:56,129 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:56,129 [run_pretraining.py:  534]:	loss/total_loss, 7.446960926055908, 2113
[INFO] 2021-07-12 19:14:56,129 [run_pretraining.py:  535]:	loss/mlm_loss, 7.446960926055908, 2113
[INFO] 2021-07-12 19:14:56,129 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.111999856424518e-05, 2113
[INFO] 2021-07-12 19:14:56,129 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2113
[INFO] 2021-07-12 19:14:56,129 [run_pretraining.py:  558]:	worker_index: 2, step: 2113, cost: 7.446961, mlm loss: 7.446961, speed: 0.950827 steps/s, speed: 7.606612 samples/s, speed: 3894.585416 tokens/s, learning rate: 2.112e-05, loss_scalings: 3518.437988, pp_loss: 7.276263
[INFO] 2021-07-12 19:14:56,130 [run_pretraining.py:  512]:	********exe.run_2113******* 
[INFO] 2021-07-12 19:14:57,193 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:57,193 [run_pretraining.py:  534]:	loss/total_loss, 7.078163146972656, 2114
[INFO] 2021-07-12 19:14:57,193 [run_pretraining.py:  535]:	loss/mlm_loss, 7.078163146972656, 2114
[INFO] 2021-07-12 19:14:57,193 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1129999367985874e-05, 2114
[INFO] 2021-07-12 19:14:57,193 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2114
[INFO] 2021-07-12 19:14:57,193 [run_pretraining.py:  558]:	worker_index: 2, step: 2114, cost: 7.078163, mlm loss: 7.078163, speed: 0.940461 steps/s, speed: 7.523690 samples/s, speed: 3852.129390 tokens/s, learning rate: 2.113e-05, loss_scalings: 3518.437988, pp_loss: 7.109563
[INFO] 2021-07-12 19:14:57,193 [run_pretraining.py:  512]:	********exe.run_2114******* 
[INFO] 2021-07-12 19:14:58,256 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:58,256 [run_pretraining.py:  534]:	loss/total_loss, 7.557416915893555, 2115
[INFO] 2021-07-12 19:14:58,256 [run_pretraining.py:  535]:	loss/mlm_loss, 7.557416915893555, 2115
[INFO] 2021-07-12 19:14:58,257 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.114000017172657e-05, 2115
[INFO] 2021-07-12 19:14:58,257 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2115
[INFO] 2021-07-12 19:14:58,257 [run_pretraining.py:  558]:	worker_index: 2, step: 2115, cost: 7.557417, mlm loss: 7.557417, speed: 0.940980 steps/s, speed: 7.527841 samples/s, speed: 3854.254493 tokens/s, learning rate: 2.114e-05, loss_scalings: 3518.437988, pp_loss: 7.596671
[INFO] 2021-07-12 19:14:58,257 [run_pretraining.py:  512]:	********exe.run_2115******* 
[INFO] 2021-07-12 19:14:59,315 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:59,315 [run_pretraining.py:  534]:	loss/total_loss, 6.8436665534973145, 2116
[INFO] 2021-07-12 19:14:59,315 [run_pretraining.py:  535]:	loss/mlm_loss, 6.8436665534973145, 2116
[INFO] 2021-07-12 19:14:59,315 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.114999915647786e-05, 2116
[INFO] 2021-07-12 19:14:59,315 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2116
[INFO] 2021-07-12 19:14:59,315 [run_pretraining.py:  558]:	worker_index: 2, step: 2116, cost: 6.843667, mlm loss: 6.843667, speed: 0.945065 steps/s, speed: 7.560521 samples/s, speed: 3870.986819 tokens/s, learning rate: 2.115e-05, loss_scalings: 3518.437988, pp_loss: 7.085156
[INFO] 2021-07-12 19:14:59,315 [run_pretraining.py:  512]:	********exe.run_2116******* 
[INFO] 2021-07-12 19:15:00,385 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:00,385 [run_pretraining.py:  534]:	loss/total_loss, 7.341242790222168, 2117
[INFO] 2021-07-12 19:15:00,385 [run_pretraining.py:  535]:	loss/mlm_loss, 7.341242790222168, 2117
[INFO] 2021-07-12 19:15:00,385 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1159999960218556e-05, 2117
[INFO] 2021-07-12 19:15:00,385 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2117
[INFO] 2021-07-12 19:15:00,385 [run_pretraining.py:  558]:	worker_index: 2, step: 2117, cost: 7.341243, mlm loss: 7.341243, speed: 0.935174 steps/s, speed: 7.481390 samples/s, speed: 3830.471833 tokens/s, learning rate: 2.116e-05, loss_scalings: 3518.437988, pp_loss: 7.180485
[INFO] 2021-07-12 19:15:00,385 [run_pretraining.py:  512]:	********exe.run_2117******* 
[INFO] 2021-07-12 19:15:01,443 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:01,444 [run_pretraining.py:  534]:	loss/total_loss, 7.147360324859619, 2118
[INFO] 2021-07-12 19:15:01,444 [run_pretraining.py:  535]:	loss/mlm_loss, 7.147360324859619, 2118
[INFO] 2021-07-12 19:15:01,444 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.117000076395925e-05, 2118
[INFO] 2021-07-12 19:15:01,444 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2118
[INFO] 2021-07-12 19:15:01,444 [run_pretraining.py:  558]:	worker_index: 2, step: 2118, cost: 7.147360, mlm loss: 7.147360, speed: 0.944839 steps/s, speed: 7.558709 samples/s, speed: 3870.059005 tokens/s, learning rate: 2.117e-05, loss_scalings: 3518.437988, pp_loss: 7.108887
[INFO] 2021-07-12 19:15:01,444 [run_pretraining.py:  512]:	********exe.run_2118******* 
[INFO] 2021-07-12 19:15:02,504 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:02,504 [run_pretraining.py:  534]:	loss/total_loss, 6.0990142822265625, 2119
[INFO] 2021-07-12 19:15:02,504 [run_pretraining.py:  535]:	loss/mlm_loss, 6.0990142822265625, 2119
[INFO] 2021-07-12 19:15:02,504 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1179999748710543e-05, 2119
[INFO] 2021-07-12 19:15:02,504 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2119
[INFO] 2021-07-12 19:15:02,504 [run_pretraining.py:  558]:	worker_index: 2, step: 2119, cost: 6.099014, mlm loss: 6.099014, speed: 0.943811 steps/s, speed: 7.550490 samples/s, speed: 3865.851063 tokens/s, learning rate: 2.118e-05, loss_scalings: 3518.437988, pp_loss: 7.062577
[INFO] 2021-07-12 19:15:02,505 [run_pretraining.py:  512]:	********exe.run_2119******* 
[INFO] 2021-07-12 19:15:03,568 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:03,569 [run_pretraining.py:  534]:	loss/total_loss, 7.628404140472412, 2120
[INFO] 2021-07-12 19:15:03,569 [run_pretraining.py:  535]:	loss/mlm_loss, 7.628404140472412, 2120
[INFO] 2021-07-12 19:15:03,569 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1189998733461834e-05, 2120
[INFO] 2021-07-12 19:15:03,569 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2120
[INFO] 2021-07-12 19:15:03,569 [run_pretraining.py:  558]:	worker_index: 2, step: 2120, cost: 7.628404, mlm loss: 7.628404, speed: 0.939930 steps/s, speed: 7.519440 samples/s, speed: 3849.953138 tokens/s, learning rate: 2.119e-05, loss_scalings: 3518.437988, pp_loss: 7.322664
[INFO] 2021-07-12 19:15:03,569 [run_pretraining.py:  512]:	********exe.run_2120******* 
[INFO] 2021-07-12 19:15:04,629 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:04,630 [run_pretraining.py:  534]:	loss/total_loss, 7.183998107910156, 2121
[INFO] 2021-07-12 19:15:04,630 [run_pretraining.py:  535]:	loss/mlm_loss, 7.183998107910156, 2121
[INFO] 2021-07-12 19:15:04,630 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.119999953720253e-05, 2121
[INFO] 2021-07-12 19:15:04,630 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2121
[INFO] 2021-07-12 19:15:04,630 [run_pretraining.py:  558]:	worker_index: 2, step: 2121, cost: 7.183998, mlm loss: 7.183998, speed: 0.943046 steps/s, speed: 7.544367 samples/s, speed: 3862.715871 tokens/s, learning rate: 2.120e-05, loss_scalings: 3518.437988, pp_loss: 7.195319
[INFO] 2021-07-12 19:15:04,630 [run_pretraining.py:  512]:	********exe.run_2121******* 
[INFO] 2021-07-12 19:15:05,689 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:05,689 [run_pretraining.py:  534]:	loss/total_loss, 5.423254013061523, 2122
[INFO] 2021-07-12 19:15:05,690 [run_pretraining.py:  535]:	loss/mlm_loss, 5.423254013061523, 2122
[INFO] 2021-07-12 19:15:05,690 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.120999852195382e-05, 2122
[INFO] 2021-07-12 19:15:05,690 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2122
[INFO] 2021-07-12 19:15:05,690 [run_pretraining.py:  558]:	worker_index: 2, step: 2122, cost: 5.423254, mlm loss: 5.423254, speed: 0.944032 steps/s, speed: 7.552259 samples/s, speed: 3866.756843 tokens/s, learning rate: 2.121e-05, loss_scalings: 3518.437988, pp_loss: 6.654977
[INFO] 2021-07-12 19:15:05,690 [run_pretraining.py:  512]:	********exe.run_2122******* 
[INFO] 2021-07-12 19:15:06,758 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:06,759 [run_pretraining.py:  534]:	loss/total_loss, 7.657950401306152, 2123
[INFO] 2021-07-12 19:15:06,759 [run_pretraining.py:  535]:	loss/mlm_loss, 7.657950401306152, 2123
[INFO] 2021-07-12 19:15:06,759 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1219999325694516e-05, 2123
[INFO] 2021-07-12 19:15:06,759 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2123
[INFO] 2021-07-12 19:15:06,759 [run_pretraining.py:  558]:	worker_index: 2, step: 2123, cost: 7.657950, mlm loss: 7.657950, speed: 0.935908 steps/s, speed: 7.487265 samples/s, speed: 3833.479604 tokens/s, learning rate: 2.122e-05, loss_scalings: 3518.437988, pp_loss: 7.492649
[INFO] 2021-07-12 19:15:06,759 [run_pretraining.py:  512]:	********exe.run_2123******* 
[INFO] 2021-07-12 19:15:07,813 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:07,813 [run_pretraining.py:  534]:	loss/total_loss, 7.253037452697754, 2124
[INFO] 2021-07-12 19:15:07,813 [run_pretraining.py:  535]:	loss/mlm_loss, 7.253037452697754, 2124
[INFO] 2021-07-12 19:15:07,813 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.123000012943521e-05, 2124
[INFO] 2021-07-12 19:15:07,813 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2124
[INFO] 2021-07-12 19:15:07,813 [run_pretraining.py:  558]:	worker_index: 2, step: 2124, cost: 7.253037, mlm loss: 7.253037, speed: 0.948855 steps/s, speed: 7.590843 samples/s, speed: 3886.511459 tokens/s, learning rate: 2.123e-05, loss_scalings: 3518.437988, pp_loss: 7.459287
[INFO] 2021-07-12 19:15:07,813 [run_pretraining.py:  512]:	********exe.run_2124******* 
[INFO] 2021-07-12 19:15:08,878 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:08,879 [run_pretraining.py:  534]:	loss/total_loss, 7.989787578582764, 2125
[INFO] 2021-07-12 19:15:08,879 [run_pretraining.py:  535]:	loss/mlm_loss, 7.989787578582764, 2125
[INFO] 2021-07-12 19:15:08,879 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1239999114186503e-05, 2125
[INFO] 2021-07-12 19:15:08,879 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2125
[INFO] 2021-07-12 19:15:08,879 [run_pretraining.py:  558]:	worker_index: 2, step: 2125, cost: 7.989788, mlm loss: 7.989788, speed: 0.938833 steps/s, speed: 7.510661 samples/s, speed: 3845.458225 tokens/s, learning rate: 2.124e-05, loss_scalings: 3518.437988, pp_loss: 7.626104
[INFO] 2021-07-12 19:15:08,879 [run_pretraining.py:  512]:	********exe.run_2125******* 
[INFO] 2021-07-12 19:15:09,959 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:09,960 [run_pretraining.py:  534]:	loss/total_loss, 6.473236083984375, 2126
[INFO] 2021-07-12 19:15:09,960 [run_pretraining.py:  535]:	loss/mlm_loss, 6.473236083984375, 2126
[INFO] 2021-07-12 19:15:09,960 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1249999917927198e-05, 2126
[INFO] 2021-07-12 19:15:09,960 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2126
[INFO] 2021-07-12 19:15:09,960 [run_pretraining.py:  558]:	worker_index: 2, step: 2126, cost: 6.473236, mlm loss: 6.473236, speed: 0.925461 steps/s, speed: 7.403685 samples/s, speed: 3790.686575 tokens/s, learning rate: 2.125e-05, loss_scalings: 3518.437988, pp_loss: 6.616039
[INFO] 2021-07-12 19:15:09,960 [run_pretraining.py:  512]:	********exe.run_2126******* 
[INFO] 2021-07-12 19:15:11,036 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:11,036 [run_pretraining.py:  534]:	loss/total_loss, 7.089265823364258, 2127
[INFO] 2021-07-12 19:15:11,036 [run_pretraining.py:  535]:	loss/mlm_loss, 7.089265823364258, 2127
[INFO] 2021-07-12 19:15:11,036 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.125999890267849e-05, 2127
[INFO] 2021-07-12 19:15:11,036 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2127
[INFO] 2021-07-12 19:15:11,036 [run_pretraining.py:  558]:	worker_index: 2, step: 2127, cost: 7.089266, mlm loss: 7.089266, speed: 0.929690 steps/s, speed: 7.437519 samples/s, speed: 3808.009512 tokens/s, learning rate: 2.126e-05, loss_scalings: 3518.437988, pp_loss: 7.428336
[INFO] 2021-07-12 19:15:11,037 [run_pretraining.py:  512]:	********exe.run_2127******* 
[INFO] 2021-07-12 19:15:12,100 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:12,100 [run_pretraining.py:  534]:	loss/total_loss, 7.704168319702148, 2128
[INFO] 2021-07-12 19:15:12,100 [run_pretraining.py:  535]:	loss/mlm_loss, 7.704168319702148, 2128
[INFO] 2021-07-12 19:15:12,100 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1269999706419185e-05, 2128
[INFO] 2021-07-12 19:15:12,100 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2128
[INFO] 2021-07-12 19:15:12,100 [run_pretraining.py:  558]:	worker_index: 2, step: 2128, cost: 7.704168, mlm loss: 7.704168, speed: 0.940410 steps/s, speed: 7.523277 samples/s, speed: 3851.917786 tokens/s, learning rate: 2.127e-05, loss_scalings: 3518.437988, pp_loss: 7.405631
[INFO] 2021-07-12 19:15:12,101 [run_pretraining.py:  512]:	********exe.run_2128******* 
[INFO] 2021-07-12 19:15:13,160 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:13,160 [run_pretraining.py:  534]:	loss/total_loss, 8.13143539428711, 2129
[INFO] 2021-07-12 19:15:13,160 [run_pretraining.py:  535]:	loss/mlm_loss, 8.13143539428711, 2129
[INFO] 2021-07-12 19:15:13,161 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1279998691170476e-05, 2129
[INFO] 2021-07-12 19:15:13,161 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2129
[INFO] 2021-07-12 19:15:13,161 [run_pretraining.py:  558]:	worker_index: 2, step: 2129, cost: 8.131435, mlm loss: 8.131435, speed: 0.943749 steps/s, speed: 7.549994 samples/s, speed: 3865.597068 tokens/s, learning rate: 2.128e-05, loss_scalings: 3518.437988, pp_loss: 7.389511
[INFO] 2021-07-12 19:15:13,161 [run_pretraining.py:  512]:	********exe.run_2129******* 
[INFO] 2021-07-12 19:15:14,218 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:14,218 [run_pretraining.py:  534]:	loss/total_loss, 7.339330673217773, 2130
[INFO] 2021-07-12 19:15:14,219 [run_pretraining.py:  535]:	loss/mlm_loss, 7.339330673217773, 2130
[INFO] 2021-07-12 19:15:14,219 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.128999949491117e-05, 2130
[INFO] 2021-07-12 19:15:14,219 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2130
[INFO] 2021-07-12 19:15:14,219 [run_pretraining.py:  558]:	worker_index: 2, step: 2130, cost: 7.339331, mlm loss: 7.339331, speed: 0.945602 steps/s, speed: 7.564815 samples/s, speed: 3873.185177 tokens/s, learning rate: 2.129e-05, loss_scalings: 3518.437988, pp_loss: 7.159800
[INFO] 2021-07-12 19:15:14,219 [run_pretraining.py:  512]:	********exe.run_2130******* 
[INFO] 2021-07-12 19:15:15,281 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:15,282 [run_pretraining.py:  534]:	loss/total_loss, 8.335676193237305, 2131
[INFO] 2021-07-12 19:15:15,282 [run_pretraining.py:  535]:	loss/mlm_loss, 8.335676193237305, 2131
[INFO] 2021-07-12 19:15:15,282 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1300000298651867e-05, 2131
[INFO] 2021-07-12 19:15:15,282 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2131
[INFO] 2021-07-12 19:15:15,282 [run_pretraining.py:  558]:	worker_index: 2, step: 2131, cost: 8.335676, mlm loss: 8.335676, speed: 0.940802 steps/s, speed: 7.526412 samples/s, speed: 3853.523103 tokens/s, learning rate: 2.130e-05, loss_scalings: 3518.437988, pp_loss: 7.561980
[INFO] 2021-07-12 19:15:15,282 [run_pretraining.py:  512]:	********exe.run_2131******* 
[INFO] 2021-07-12 19:15:16,344 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:16,344 [run_pretraining.py:  534]:	loss/total_loss, 7.747879505157471, 2132
[INFO] 2021-07-12 19:15:16,344 [run_pretraining.py:  535]:	loss/mlm_loss, 7.747879505157471, 2132
[INFO] 2021-07-12 19:15:16,345 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1309999283403158e-05, 2132
[INFO] 2021-07-12 19:15:16,345 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2132
[INFO] 2021-07-12 19:15:16,345 [run_pretraining.py:  558]:	worker_index: 2, step: 2132, cost: 7.747880, mlm loss: 7.747880, speed: 0.941834 steps/s, speed: 7.534675 samples/s, speed: 3857.753613 tokens/s, learning rate: 2.131e-05, loss_scalings: 3518.437988, pp_loss: 7.601069
[INFO] 2021-07-12 19:15:16,345 [run_pretraining.py:  512]:	********exe.run_2132******* 
[INFO] 2021-07-12 19:15:17,414 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:17,414 [run_pretraining.py:  534]:	loss/total_loss, 7.3961052894592285, 2133
[INFO] 2021-07-12 19:15:17,414 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3961052894592285, 2133
[INFO] 2021-07-12 19:15:17,414 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1320000087143853e-05, 2133
[INFO] 2021-07-12 19:15:17,414 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2133
[INFO] 2021-07-12 19:15:17,414 [run_pretraining.py:  558]:	worker_index: 2, step: 2133, cost: 7.396105, mlm loss: 7.396105, speed: 0.935353 steps/s, speed: 7.482820 samples/s, speed: 3831.203896 tokens/s, learning rate: 2.132e-05, loss_scalings: 3518.437988, pp_loss: 7.125394
[INFO] 2021-07-12 19:15:17,414 [run_pretraining.py:  512]:	********exe.run_2133******* 
[INFO] 2021-07-12 19:15:18,494 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:18,495 [run_pretraining.py:  534]:	loss/total_loss, 7.516366004943848, 2134
[INFO] 2021-07-12 19:15:18,495 [run_pretraining.py:  535]:	loss/mlm_loss, 7.516366004943848, 2134
[INFO] 2021-07-12 19:15:18,495 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1329999071895145e-05, 2134
[INFO] 2021-07-12 19:15:18,495 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2134
[INFO] 2021-07-12 19:15:18,495 [run_pretraining.py:  558]:	worker_index: 2, step: 2134, cost: 7.516366, mlm loss: 7.516366, speed: 0.925783 steps/s, speed: 7.406267 samples/s, speed: 3792.008553 tokens/s, learning rate: 2.133e-05, loss_scalings: 3518.437988, pp_loss: 7.237534
[INFO] 2021-07-12 19:15:18,495 [run_pretraining.py:  512]:	********exe.run_2134******* 
[INFO] 2021-07-12 19:15:19,447 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:19,447 [run_pretraining.py:  534]:	loss/total_loss, 6.373929500579834, 2135
[INFO] 2021-07-12 19:15:19,447 [run_pretraining.py:  535]:	loss/mlm_loss, 6.373929500579834, 2135
[INFO] 2021-07-12 19:15:19,448 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.133999987563584e-05, 2135
[INFO] 2021-07-12 19:15:19,448 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2135
[INFO] 2021-07-12 19:15:19,448 [run_pretraining.py:  558]:	worker_index: 2, step: 2135, cost: 6.373930, mlm loss: 6.373930, speed: 1.050498 steps/s, speed: 8.403987 samples/s, speed: 4302.841496 tokens/s, learning rate: 2.134e-05, loss_scalings: 3518.437988, pp_loss: 7.039559
[INFO] 2021-07-12 19:15:19,448 [run_pretraining.py:  512]:	********exe.run_2135******* 
[INFO] 2021-07-12 19:15:20,355 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:20,355 [run_pretraining.py:  534]:	loss/total_loss, 7.493063449859619, 2136
[INFO] 2021-07-12 19:15:20,356 [run_pretraining.py:  535]:	loss/mlm_loss, 7.493063449859619, 2136
[INFO] 2021-07-12 19:15:20,356 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.134999886038713e-05, 2136
[INFO] 2021-07-12 19:15:20,356 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2136
[INFO] 2021-07-12 19:15:20,356 [run_pretraining.py:  558]:	worker_index: 2, step: 2136, cost: 7.493063, mlm loss: 7.493063, speed: 1.101917 steps/s, speed: 8.815334 samples/s, speed: 4513.451049 tokens/s, learning rate: 2.135e-05, loss_scalings: 3518.437988, pp_loss: 7.133986
[INFO] 2021-07-12 19:15:20,356 [run_pretraining.py:  512]:	********exe.run_2136******* 
[INFO] 2021-07-12 19:15:21,268 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:21,269 [run_pretraining.py:  534]:	loss/total_loss, 7.6453857421875, 2137
[INFO] 2021-07-12 19:15:21,269 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6453857421875, 2137
[INFO] 2021-07-12 19:15:21,269 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1359999664127827e-05, 2137
[INFO] 2021-07-12 19:15:21,269 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2137
[INFO] 2021-07-12 19:15:21,269 [run_pretraining.py:  558]:	worker_index: 2, step: 2137, cost: 7.645386, mlm loss: 7.645386, speed: 1.095631 steps/s, speed: 8.765052 samples/s, speed: 4487.706434 tokens/s, learning rate: 2.136e-05, loss_scalings: 3518.437988, pp_loss: 7.323009
[INFO] 2021-07-12 19:15:21,269 [run_pretraining.py:  512]:	********exe.run_2137******* 
[INFO] 2021-07-12 19:15:22,178 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:22,179 [run_pretraining.py:  534]:	loss/total_loss, 6.612771511077881, 2138
[INFO] 2021-07-12 19:15:22,179 [run_pretraining.py:  535]:	loss/mlm_loss, 6.612771511077881, 2138
[INFO] 2021-07-12 19:15:22,179 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1369998648879118e-05, 2138
[INFO] 2021-07-12 19:15:22,179 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2138
[INFO] 2021-07-12 19:15:22,179 [run_pretraining.py:  558]:	worker_index: 2, step: 2138, cost: 6.612772, mlm loss: 6.612772, speed: 1.099590 steps/s, speed: 8.796723 samples/s, speed: 4503.922266 tokens/s, learning rate: 2.137e-05, loss_scalings: 3518.437988, pp_loss: 6.319644
[INFO] 2021-07-12 19:15:22,179 [run_pretraining.py:  512]:	********exe.run_2138******* 
[INFO] 2021-07-12 19:15:23,089 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:23,090 [run_pretraining.py:  534]:	loss/total_loss, 7.632212162017822, 2139
[INFO] 2021-07-12 19:15:23,090 [run_pretraining.py:  535]:	loss/mlm_loss, 7.632212162017822, 2139
[INFO] 2021-07-12 19:15:23,090 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1379999452619813e-05, 2139
[INFO] 2021-07-12 19:15:23,090 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2139
[INFO] 2021-07-12 19:15:23,090 [run_pretraining.py:  558]:	worker_index: 2, step: 2139, cost: 7.632212, mlm loss: 7.632212, speed: 1.098724 steps/s, speed: 8.789794 samples/s, speed: 4500.374515 tokens/s, learning rate: 2.138e-05, loss_scalings: 3518.437988, pp_loss: 7.648288
[INFO] 2021-07-12 19:15:23,090 [run_pretraining.py:  512]:	********exe.run_2139******* 
[INFO] 2021-07-12 19:15:23,993 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:23,993 [run_pretraining.py:  534]:	loss/total_loss, 7.10065221786499, 2140
[INFO] 2021-07-12 19:15:23,993 [run_pretraining.py:  535]:	loss/mlm_loss, 7.10065221786499, 2140
[INFO] 2021-07-12 19:15:23,994 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.139000025636051e-05, 2140
[INFO] 2021-07-12 19:15:23,994 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2140
[INFO] 2021-07-12 19:15:23,994 [run_pretraining.py:  558]:	worker_index: 2, step: 2140, cost: 7.100652, mlm loss: 7.100652, speed: 1.107221 steps/s, speed: 8.857769 samples/s, speed: 4535.177508 tokens/s, learning rate: 2.139e-05, loss_scalings: 3518.437988, pp_loss: 7.453170
[INFO] 2021-07-12 19:15:23,994 [run_pretraining.py:  512]:	********exe.run_2140******* 
[INFO] 2021-07-12 19:15:24,898 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:24,898 [run_pretraining.py:  534]:	loss/total_loss, 7.0255513191223145, 2141
[INFO] 2021-07-12 19:15:24,899 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0255513191223145, 2141
[INFO] 2021-07-12 19:15:24,899 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.13999992411118e-05, 2141
[INFO] 2021-07-12 19:15:24,899 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2141
[INFO] 2021-07-12 19:15:24,899 [run_pretraining.py:  558]:	worker_index: 2, step: 2141, cost: 7.025551, mlm loss: 7.025551, speed: 1.105599 steps/s, speed: 8.844789 samples/s, speed: 4528.531994 tokens/s, learning rate: 2.140e-05, loss_scalings: 3518.437988, pp_loss: 7.562066
[INFO] 2021-07-12 19:15:24,899 [run_pretraining.py:  512]:	********exe.run_2141******* 
[INFO] 2021-07-12 19:15:25,803 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:25,803 [run_pretraining.py:  534]:	loss/total_loss, 7.185244083404541, 2142
[INFO] 2021-07-12 19:15:25,803 [run_pretraining.py:  535]:	loss/mlm_loss, 7.185244083404541, 2142
[INFO] 2021-07-12 19:15:25,803 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1410000044852495e-05, 2142
[INFO] 2021-07-12 19:15:25,803 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2142
[INFO] 2021-07-12 19:15:25,803 [run_pretraining.py:  558]:	worker_index: 2, step: 2142, cost: 7.185244, mlm loss: 7.185244, speed: 1.106170 steps/s, speed: 8.849361 samples/s, speed: 4530.872855 tokens/s, learning rate: 2.141e-05, loss_scalings: 3518.437988, pp_loss: 7.074426
[INFO] 2021-07-12 19:15:25,803 [run_pretraining.py:  512]:	********exe.run_2142******* 
[INFO] 2021-07-12 19:15:26,712 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:26,712 [run_pretraining.py:  534]:	loss/total_loss, 7.345773696899414, 2143
[INFO] 2021-07-12 19:15:26,712 [run_pretraining.py:  535]:	loss/mlm_loss, 7.345773696899414, 2143
[INFO] 2021-07-12 19:15:26,712 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.142000084859319e-05, 2143
[INFO] 2021-07-12 19:15:26,712 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2143
[INFO] 2021-07-12 19:15:26,713 [run_pretraining.py:  558]:	worker_index: 2, step: 2143, cost: 7.345774, mlm loss: 7.345774, speed: 1.100668 steps/s, speed: 8.805345 samples/s, speed: 4508.336730 tokens/s, learning rate: 2.142e-05, loss_scalings: 3518.437988, pp_loss: 6.758635
[INFO] 2021-07-12 19:15:26,713 [run_pretraining.py:  512]:	********exe.run_2143******* 
[INFO] 2021-07-12 19:15:27,631 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:27,632 [run_pretraining.py:  534]:	loss/total_loss, 7.375975608825684, 2144
[INFO] 2021-07-12 19:15:27,632 [run_pretraining.py:  535]:	loss/mlm_loss, 7.375975608825684, 2144
[INFO] 2021-07-12 19:15:27,632 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1429999833344482e-05, 2144
[INFO] 2021-07-12 19:15:27,632 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2144
[INFO] 2021-07-12 19:15:27,632 [run_pretraining.py:  558]:	worker_index: 2, step: 2144, cost: 7.375976, mlm loss: 7.375976, speed: 1.088487 steps/s, speed: 8.707894 samples/s, speed: 4458.441631 tokens/s, learning rate: 2.143e-05, loss_scalings: 3518.437988, pp_loss: 7.441817
[INFO] 2021-07-12 19:15:27,632 [run_pretraining.py:  512]:	********exe.run_2144******* 
[INFO] 2021-07-12 19:15:28,538 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:28,539 [run_pretraining.py:  534]:	loss/total_loss, 7.341427326202393, 2145
[INFO] 2021-07-12 19:15:28,539 [run_pretraining.py:  535]:	loss/mlm_loss, 7.341427326202393, 2145
[INFO] 2021-07-12 19:15:28,539 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1439998818095773e-05, 2145
[INFO] 2021-07-12 19:15:28,539 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2145
[INFO] 2021-07-12 19:15:28,539 [run_pretraining.py:  558]:	worker_index: 2, step: 2145, cost: 7.341427, mlm loss: 7.341427, speed: 1.103048 steps/s, speed: 8.824380 samples/s, speed: 4518.082642 tokens/s, learning rate: 2.144e-05, loss_scalings: 3518.437988, pp_loss: 6.581654
[INFO] 2021-07-12 19:15:28,539 [run_pretraining.py:  512]:	********exe.run_2145******* 
[INFO] 2021-07-12 19:15:29,481 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:29,482 [run_pretraining.py:  534]:	loss/total_loss, 6.830626487731934, 2146
[INFO] 2021-07-12 19:15:29,482 [run_pretraining.py:  535]:	loss/mlm_loss, 6.830626487731934, 2146
[INFO] 2021-07-12 19:15:29,482 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.144999962183647e-05, 2146
[INFO] 2021-07-12 19:15:29,482 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2146
[INFO] 2021-07-12 19:15:29,482 [run_pretraining.py:  558]:	worker_index: 2, step: 2146, cost: 6.830626, mlm loss: 6.830626, speed: 1.060991 steps/s, speed: 8.487925 samples/s, speed: 4345.817709 tokens/s, learning rate: 2.145e-05, loss_scalings: 3518.437988, pp_loss: 6.965230
[INFO] 2021-07-12 19:15:29,482 [run_pretraining.py:  512]:	********exe.run_2146******* 
[INFO] 2021-07-12 19:15:30,405 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:30,405 [run_pretraining.py:  534]:	loss/total_loss, 6.732464790344238, 2147
[INFO] 2021-07-12 19:15:30,405 [run_pretraining.py:  535]:	loss/mlm_loss, 6.732464790344238, 2147
[INFO] 2021-07-12 19:15:30,405 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.145999860658776e-05, 2147
[INFO] 2021-07-12 19:15:30,405 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2147
[INFO] 2021-07-12 19:15:30,405 [run_pretraining.py:  558]:	worker_index: 2, step: 2147, cost: 6.732465, mlm loss: 6.732465, speed: 1.083714 steps/s, speed: 8.669710 samples/s, speed: 4438.891701 tokens/s, learning rate: 2.146e-05, loss_scalings: 3518.437988, pp_loss: 7.136264
[INFO] 2021-07-12 19:15:30,406 [run_pretraining.py:  512]:	********exe.run_2147******* 
[INFO] 2021-07-12 19:15:31,305 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:31,305 [run_pretraining.py:  534]:	loss/total_loss, 7.157814025878906, 2148
[INFO] 2021-07-12 19:15:31,305 [run_pretraining.py:  535]:	loss/mlm_loss, 7.157814025878906, 2148
[INFO] 2021-07-12 19:15:31,305 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1469999410328455e-05, 2148
[INFO] 2021-07-12 19:15:31,305 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2148
[INFO] 2021-07-12 19:15:31,305 [run_pretraining.py:  558]:	worker_index: 2, step: 2148, cost: 7.157814, mlm loss: 7.157814, speed: 1.111925 steps/s, speed: 8.895399 samples/s, speed: 4554.444231 tokens/s, learning rate: 2.147e-05, loss_scalings: 3518.437988, pp_loss: 7.162777
[INFO] 2021-07-12 19:15:31,306 [run_pretraining.py:  512]:	********exe.run_2148******* 
[INFO] 2021-07-12 19:15:32,206 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:32,207 [run_pretraining.py:  534]:	loss/total_loss, 7.230605125427246, 2149
[INFO] 2021-07-12 19:15:32,207 [run_pretraining.py:  535]:	loss/mlm_loss, 7.230605125427246, 2149
[INFO] 2021-07-12 19:15:32,207 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.148000021406915e-05, 2149
[INFO] 2021-07-12 19:15:32,207 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2149
[INFO] 2021-07-12 19:15:32,207 [run_pretraining.py:  558]:	worker_index: 2, step: 2149, cost: 7.230605, mlm loss: 7.230605, speed: 1.109892 steps/s, speed: 8.879134 samples/s, speed: 4546.116358 tokens/s, learning rate: 2.148e-05, loss_scalings: 3518.437988, pp_loss: 7.409316
[INFO] 2021-07-12 19:15:32,207 [run_pretraining.py:  512]:	********exe.run_2149******* 
[INFO] 2021-07-12 19:15:33,104 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:33,105 [run_pretraining.py:  534]:	loss/total_loss, 6.653968334197998, 2150
[INFO] 2021-07-12 19:15:33,105 [run_pretraining.py:  535]:	loss/mlm_loss, 6.653968334197998, 2150
[INFO] 2021-07-12 19:15:33,105 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1489999198820442e-05, 2150
[INFO] 2021-07-12 19:15:33,105 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2150
[INFO] 2021-07-12 19:15:33,105 [run_pretraining.py:  558]:	worker_index: 2, step: 2150, cost: 6.653968, mlm loss: 6.653968, speed: 1.113973 steps/s, speed: 8.911788 samples/s, speed: 4562.835392 tokens/s, learning rate: 2.149e-05, loss_scalings: 3518.437988, pp_loss: 7.164313
[INFO] 2021-07-12 19:15:33,105 [run_pretraining.py:  512]:	********exe.run_2150******* 
[INFO] 2021-07-12 19:15:34,012 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:34,012 [run_pretraining.py:  534]:	loss/total_loss, 7.721995830535889, 2151
[INFO] 2021-07-12 19:15:34,012 [run_pretraining.py:  535]:	loss/mlm_loss, 7.721995830535889, 2151
[INFO] 2021-07-12 19:15:34,013 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1500000002561137e-05, 2151
[INFO] 2021-07-12 19:15:34,013 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2151
[INFO] 2021-07-12 19:15:34,013 [run_pretraining.py:  558]:	worker_index: 2, step: 2151, cost: 7.721996, mlm loss: 7.721996, speed: 1.102769 steps/s, speed: 8.822155 samples/s, speed: 4516.943448 tokens/s, learning rate: 2.150e-05, loss_scalings: 3518.437988, pp_loss: 7.794155
[INFO] 2021-07-12 19:15:34,013 [run_pretraining.py:  512]:	********exe.run_2151******* 
[INFO] 2021-07-12 19:15:34,913 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:34,913 [run_pretraining.py:  534]:	loss/total_loss, 7.622137069702148, 2152
[INFO] 2021-07-12 19:15:34,913 [run_pretraining.py:  535]:	loss/mlm_loss, 7.622137069702148, 2152
[INFO] 2021-07-12 19:15:34,913 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1510000806301832e-05, 2152
[INFO] 2021-07-12 19:15:34,913 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2152
[INFO] 2021-07-12 19:15:34,914 [run_pretraining.py:  558]:	worker_index: 2, step: 2152, cost: 7.622137, mlm loss: 7.622137, speed: 1.110832 steps/s, speed: 8.886659 samples/s, speed: 4549.969181 tokens/s, learning rate: 2.151e-05, loss_scalings: 3518.437988, pp_loss: 7.479886
[INFO] 2021-07-12 19:15:34,914 [run_pretraining.py:  512]:	********exe.run_2152******* 
[INFO] 2021-07-12 19:15:35,816 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:35,817 [run_pretraining.py:  534]:	loss/total_loss, 7.01681661605835, 2153
[INFO] 2021-07-12 19:15:35,817 [run_pretraining.py:  535]:	loss/mlm_loss, 7.01681661605835, 2153
[INFO] 2021-07-12 19:15:35,817 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1519999791053124e-05, 2153
[INFO] 2021-07-12 19:15:35,817 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2153
[INFO] 2021-07-12 19:15:35,817 [run_pretraining.py:  558]:	worker_index: 2, step: 2153, cost: 7.016817, mlm loss: 7.016817, speed: 1.107468 steps/s, speed: 8.859747 samples/s, speed: 4536.190570 tokens/s, learning rate: 2.152e-05, loss_scalings: 3518.437988, pp_loss: 7.164026
[INFO] 2021-07-12 19:15:35,817 [run_pretraining.py:  512]:	********exe.run_2153******* 
[INFO] 2021-07-12 19:15:36,719 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:36,720 [run_pretraining.py:  534]:	loss/total_loss, 7.11002254486084, 2154
[INFO] 2021-07-12 19:15:36,720 [run_pretraining.py:  535]:	loss/mlm_loss, 7.11002254486084, 2154
[INFO] 2021-07-12 19:15:36,720 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1529998775804415e-05, 2154
[INFO] 2021-07-12 19:15:36,720 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2154
[INFO] 2021-07-12 19:15:36,720 [run_pretraining.py:  558]:	worker_index: 2, step: 2154, cost: 7.110023, mlm loss: 7.110023, speed: 1.108029 steps/s, speed: 8.864232 samples/s, speed: 4538.486602 tokens/s, learning rate: 2.153e-05, loss_scalings: 3518.437988, pp_loss: 7.506015
[INFO] 2021-07-12 19:15:36,720 [run_pretraining.py:  512]:	********exe.run_2154******* 
[INFO] 2021-07-12 19:15:37,631 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:37,631 [run_pretraining.py:  534]:	loss/total_loss, 7.645623683929443, 2155
[INFO] 2021-07-12 19:15:37,631 [run_pretraining.py:  535]:	loss/mlm_loss, 7.645623683929443, 2155
[INFO] 2021-07-12 19:15:37,631 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.153999957954511e-05, 2155
[INFO] 2021-07-12 19:15:37,631 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2155
[INFO] 2021-07-12 19:15:37,631 [run_pretraining.py:  558]:	worker_index: 2, step: 2155, cost: 7.645624, mlm loss: 7.645624, speed: 1.098261 steps/s, speed: 8.786088 samples/s, speed: 4498.477284 tokens/s, learning rate: 2.154e-05, loss_scalings: 3518.437988, pp_loss: 7.293101
[INFO] 2021-07-12 19:15:37,631 [run_pretraining.py:  512]:	********exe.run_2155******* 
[INFO] 2021-07-12 19:15:38,539 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:38,540 [run_pretraining.py:  534]:	loss/total_loss, 7.282853126525879, 2156
[INFO] 2021-07-12 19:15:38,540 [run_pretraining.py:  535]:	loss/mlm_loss, 7.282853126525879, 2156
[INFO] 2021-07-12 19:15:38,540 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1549998564296402e-05, 2156
[INFO] 2021-07-12 19:15:38,540 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2156
[INFO] 2021-07-12 19:15:38,540 [run_pretraining.py:  558]:	worker_index: 2, step: 2156, cost: 7.282853, mlm loss: 7.282853, speed: 1.101124 steps/s, speed: 8.808991 samples/s, speed: 4510.203214 tokens/s, learning rate: 2.155e-05, loss_scalings: 3518.437988, pp_loss: 7.328641
[INFO] 2021-07-12 19:15:38,540 [run_pretraining.py:  512]:	********exe.run_2156******* 
[INFO] 2021-07-12 19:15:39,449 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:39,449 [run_pretraining.py:  534]:	loss/total_loss, 7.870968818664551, 2157
[INFO] 2021-07-12 19:15:39,449 [run_pretraining.py:  535]:	loss/mlm_loss, 7.870968818664551, 2157
[INFO] 2021-07-12 19:15:39,449 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1559999368037097e-05, 2157
[INFO] 2021-07-12 19:15:39,449 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2157
[INFO] 2021-07-12 19:15:39,449 [run_pretraining.py:  558]:	worker_index: 2, step: 2157, cost: 7.870969, mlm loss: 7.870969, speed: 1.100353 steps/s, speed: 8.802825 samples/s, speed: 4507.046363 tokens/s, learning rate: 2.156e-05, loss_scalings: 3518.437988, pp_loss: 7.476256
[INFO] 2021-07-12 19:15:39,450 [run_pretraining.py:  512]:	********exe.run_2157******* 
[INFO] 2021-07-12 19:15:40,359 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:40,360 [run_pretraining.py:  534]:	loss/total_loss, 7.295636177062988, 2158
[INFO] 2021-07-12 19:15:40,360 [run_pretraining.py:  535]:	loss/mlm_loss, 7.295636177062988, 2158
[INFO] 2021-07-12 19:15:40,360 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1570000171777792e-05, 2158
[INFO] 2021-07-12 19:15:40,360 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2158
[INFO] 2021-07-12 19:15:40,360 [run_pretraining.py:  558]:	worker_index: 2, step: 2158, cost: 7.295636, mlm loss: 7.295636, speed: 1.099078 steps/s, speed: 8.792625 samples/s, speed: 4501.823851 tokens/s, learning rate: 2.157e-05, loss_scalings: 3518.437988, pp_loss: 7.187848
[INFO] 2021-07-12 19:15:40,360 [run_pretraining.py:  512]:	********exe.run_2158******* 
[INFO] 2021-07-12 19:15:41,286 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:41,287 [run_pretraining.py:  534]:	loss/total_loss, 7.105114936828613, 2159
[INFO] 2021-07-12 19:15:41,287 [run_pretraining.py:  535]:	loss/mlm_loss, 7.105114936828613, 2159
[INFO] 2021-07-12 19:15:41,287 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1579999156529084e-05, 2159
[INFO] 2021-07-12 19:15:41,287 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2159
[INFO] 2021-07-12 19:15:41,287 [run_pretraining.py:  558]:	worker_index: 2, step: 2159, cost: 7.105115, mlm loss: 7.105115, speed: 1.079287 steps/s, speed: 8.634292 samples/s, speed: 4420.757747 tokens/s, learning rate: 2.158e-05, loss_scalings: 3518.437988, pp_loss: 7.141835
[INFO] 2021-07-12 19:15:41,287 [run_pretraining.py:  512]:	********exe.run_2159******* 
[INFO] 2021-07-12 19:15:42,209 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:42,209 [run_pretraining.py:  534]:	loss/total_loss, 7.246228218078613, 2160
[INFO] 2021-07-12 19:15:42,210 [run_pretraining.py:  535]:	loss/mlm_loss, 7.246228218078613, 2160
[INFO] 2021-07-12 19:15:42,210 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.158999996026978e-05, 2160
[INFO] 2021-07-12 19:15:42,210 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2160
[INFO] 2021-07-12 19:15:42,210 [run_pretraining.py:  558]:	worker_index: 2, step: 2160, cost: 7.246228, mlm loss: 7.246228, speed: 1.084527 steps/s, speed: 8.676216 samples/s, speed: 4442.222531 tokens/s, learning rate: 2.159e-05, loss_scalings: 3518.437988, pp_loss: 7.225476
[INFO] 2021-07-12 19:15:42,210 [run_pretraining.py:  512]:	********exe.run_2160******* 
[INFO] 2021-07-12 19:15:43,125 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:43,126 [run_pretraining.py:  534]:	loss/total_loss, 7.667194843292236, 2161
[INFO] 2021-07-12 19:15:43,126 [run_pretraining.py:  535]:	loss/mlm_loss, 7.667194843292236, 2161
[INFO] 2021-07-12 19:15:43,126 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1600000764010474e-05, 2161
[INFO] 2021-07-12 19:15:43,126 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2161
[INFO] 2021-07-12 19:15:43,126 [run_pretraining.py:  558]:	worker_index: 2, step: 2161, cost: 7.667195, mlm loss: 7.667195, speed: 1.092118 steps/s, speed: 8.736946 samples/s, speed: 4473.316175 tokens/s, learning rate: 2.160e-05, loss_scalings: 3518.437988, pp_loss: 7.048169
[INFO] 2021-07-12 19:15:43,126 [run_pretraining.py:  512]:	********exe.run_2161******* 
[INFO] 2021-07-12 19:15:44,033 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:44,033 [run_pretraining.py:  534]:	loss/total_loss, 7.90244197845459, 2162
[INFO] 2021-07-12 19:15:44,034 [run_pretraining.py:  535]:	loss/mlm_loss, 7.90244197845459, 2162
[INFO] 2021-07-12 19:15:44,034 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1609999748761766e-05, 2162
[INFO] 2021-07-12 19:15:44,034 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2162
[INFO] 2021-07-12 19:15:44,034 [run_pretraining.py:  558]:	worker_index: 2, step: 2162, cost: 7.902442, mlm loss: 7.902442, speed: 1.102254 steps/s, speed: 8.818033 samples/s, speed: 4514.832885 tokens/s, learning rate: 2.161e-05, loss_scalings: 3518.437988, pp_loss: 7.132739
[INFO] 2021-07-12 19:15:44,034 [run_pretraining.py:  512]:	********exe.run_2162******* 
[INFO] 2021-07-12 19:15:44,967 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:44,968 [run_pretraining.py:  534]:	loss/total_loss, 6.928719520568848, 2163
[INFO] 2021-07-12 19:15:44,968 [run_pretraining.py:  535]:	loss/mlm_loss, 6.928719520568848, 2163
[INFO] 2021-07-12 19:15:44,968 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1619998733513057e-05, 2163
[INFO] 2021-07-12 19:15:44,968 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2163
[INFO] 2021-07-12 19:15:44,968 [run_pretraining.py:  558]:	worker_index: 2, step: 2163, cost: 6.928720, mlm loss: 6.928720, speed: 1.071086 steps/s, speed: 8.568692 samples/s, speed: 4387.170260 tokens/s, learning rate: 2.162e-05, loss_scalings: 3518.437988, pp_loss: 6.619814
[INFO] 2021-07-12 19:15:44,968 [run_pretraining.py:  512]:	********exe.run_2163******* 
[INFO] 2021-07-12 19:15:45,971 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:45,972 [run_pretraining.py:  534]:	loss/total_loss, 7.497055530548096, 2164
[INFO] 2021-07-12 19:15:45,972 [run_pretraining.py:  535]:	loss/mlm_loss, 7.497055530548096, 2164
[INFO] 2021-07-12 19:15:45,972 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1629999537253752e-05, 2164
[INFO] 2021-07-12 19:15:45,972 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2164
[INFO] 2021-07-12 19:15:45,972 [run_pretraining.py:  558]:	worker_index: 2, step: 2164, cost: 7.497056, mlm loss: 7.497056, speed: 0.996659 steps/s, speed: 7.973272 samples/s, speed: 4082.315404 tokens/s, learning rate: 2.163e-05, loss_scalings: 3518.437988, pp_loss: 7.247964
[INFO] 2021-07-12 19:15:45,972 [run_pretraining.py:  512]:	********exe.run_2164******* 
[INFO] 2021-07-12 19:15:46,856 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:46,857 [run_pretraining.py:  534]:	loss/total_loss, 7.445224761962891, 2165
[INFO] 2021-07-12 19:15:46,857 [run_pretraining.py:  535]:	loss/mlm_loss, 7.445224761962891, 2165
[INFO] 2021-07-12 19:15:46,857 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1639998522005044e-05, 2165
[INFO] 2021-07-12 19:15:46,857 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2165
[INFO] 2021-07-12 19:15:46,857 [run_pretraining.py:  558]:	worker_index: 2, step: 2165, cost: 7.445225, mlm loss: 7.445225, speed: 1.130859 steps/s, speed: 9.046872 samples/s, speed: 4631.998451 tokens/s, learning rate: 2.164e-05, loss_scalings: 3518.437988, pp_loss: 7.367614
[INFO] 2021-07-12 19:15:46,857 [run_pretraining.py:  512]:	********exe.run_2165******* 
[INFO] 2021-07-12 19:15:47,771 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:47,771 [run_pretraining.py:  534]:	loss/total_loss, 8.105388641357422, 2166
[INFO] 2021-07-12 19:15:47,772 [run_pretraining.py:  535]:	loss/mlm_loss, 8.105388641357422, 2166
[INFO] 2021-07-12 19:15:47,772 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.164999932574574e-05, 2166
[INFO] 2021-07-12 19:15:47,772 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2166
[INFO] 2021-07-12 19:15:47,772 [run_pretraining.py:  558]:	worker_index: 2, step: 2166, cost: 8.105389, mlm loss: 8.105389, speed: 1.093718 steps/s, speed: 8.749745 samples/s, speed: 4479.869427 tokens/s, learning rate: 2.165e-05, loss_scalings: 3518.437988, pp_loss: 7.463161
[INFO] 2021-07-12 19:15:47,772 [run_pretraining.py:  512]:	********exe.run_2166******* 
[INFO] 2021-07-12 19:15:48,681 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:48,682 [run_pretraining.py:  534]:	loss/total_loss, 7.377408504486084, 2167
[INFO] 2021-07-12 19:15:48,682 [run_pretraining.py:  535]:	loss/mlm_loss, 7.377408504486084, 2167
[INFO] 2021-07-12 19:15:48,682 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1660000129486434e-05, 2167
[INFO] 2021-07-12 19:15:48,682 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2167
[INFO] 2021-07-12 19:15:48,682 [run_pretraining.py:  558]:	worker_index: 2, step: 2167, cost: 7.377409, mlm loss: 7.377409, speed: 1.099347 steps/s, speed: 8.794780 samples/s, speed: 4502.927104 tokens/s, learning rate: 2.166e-05, loss_scalings: 3518.437988, pp_loss: 7.274978
[INFO] 2021-07-12 19:15:48,682 [run_pretraining.py:  512]:	********exe.run_2167******* 
[INFO] 2021-07-12 19:15:49,590 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:49,591 [run_pretraining.py:  534]:	loss/total_loss, 7.701601028442383, 2168
[INFO] 2021-07-12 19:15:49,591 [run_pretraining.py:  535]:	loss/mlm_loss, 7.701601028442383, 2168
[INFO] 2021-07-12 19:15:49,591 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1669999114237726e-05, 2168
[INFO] 2021-07-12 19:15:49,591 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2168
[INFO] 2021-07-12 19:15:49,591 [run_pretraining.py:  558]:	worker_index: 2, step: 2168, cost: 7.701601, mlm loss: 7.701601, speed: 1.101049 steps/s, speed: 8.808394 samples/s, speed: 4509.897748 tokens/s, learning rate: 2.167e-05, loss_scalings: 3518.437988, pp_loss: 7.544981
[INFO] 2021-07-12 19:15:49,591 [run_pretraining.py:  512]:	********exe.run_2168******* 
[INFO] 2021-07-12 19:15:50,493 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:50,493 [run_pretraining.py:  534]:	loss/total_loss, 7.717968940734863, 2169
[INFO] 2021-07-12 19:15:50,493 [run_pretraining.py:  535]:	loss/mlm_loss, 7.717968940734863, 2169
[INFO] 2021-07-12 19:15:50,493 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.167999991797842e-05, 2169
[INFO] 2021-07-12 19:15:50,493 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2169
[INFO] 2021-07-12 19:15:50,494 [run_pretraining.py:  558]:	worker_index: 2, step: 2169, cost: 7.717969, mlm loss: 7.717969, speed: 1.108659 steps/s, speed: 8.869274 samples/s, speed: 4541.068218 tokens/s, learning rate: 2.168e-05, loss_scalings: 3518.437988, pp_loss: 7.942953
[INFO] 2021-07-12 19:15:50,494 [run_pretraining.py:  512]:	********exe.run_2169******* 
[INFO] 2021-07-12 19:15:51,403 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:51,404 [run_pretraining.py:  534]:	loss/total_loss, 7.878863334655762, 2170
[INFO] 2021-07-12 19:15:51,404 [run_pretraining.py:  535]:	loss/mlm_loss, 7.878863334655762, 2170
[INFO] 2021-07-12 19:15:51,404 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1690000721719116e-05, 2170
[INFO] 2021-07-12 19:15:51,404 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2170
[INFO] 2021-07-12 19:15:51,404 [run_pretraining.py:  558]:	worker_index: 2, step: 2170, cost: 7.878863, mlm loss: 7.878863, speed: 1.099210 steps/s, speed: 8.793678 samples/s, speed: 4502.363021 tokens/s, learning rate: 2.169e-05, loss_scalings: 3518.437988, pp_loss: 7.516128
[INFO] 2021-07-12 19:15:51,404 [run_pretraining.py:  512]:	********exe.run_2170******* 
[INFO] 2021-07-12 19:15:52,311 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:52,312 [run_pretraining.py:  534]:	loss/total_loss, 7.018998146057129, 2171
[INFO] 2021-07-12 19:15:52,312 [run_pretraining.py:  535]:	loss/mlm_loss, 7.018998146057129, 2171
[INFO] 2021-07-12 19:15:52,312 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1699997887481004e-05, 2171
[INFO] 2021-07-12 19:15:52,312 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2171
[INFO] 2021-07-12 19:15:52,312 [run_pretraining.py:  558]:	worker_index: 2, step: 2171, cost: 7.018998, mlm loss: 7.018998, speed: 1.101760 steps/s, speed: 8.814084 samples/s, speed: 4512.810829 tokens/s, learning rate: 2.170e-05, loss_scalings: 3518.437988, pp_loss: 7.373555
[INFO] 2021-07-12 19:15:52,312 [run_pretraining.py:  512]:	********exe.run_2171******* 
[INFO] 2021-07-12 19:15:53,251 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:53,251 [run_pretraining.py:  534]:	loss/total_loss, 8.202422142028809, 2172
[INFO] 2021-07-12 19:15:53,252 [run_pretraining.py:  535]:	loss/mlm_loss, 8.202422142028809, 2172
[INFO] 2021-07-12 19:15:53,252 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.17099986912217e-05, 2172
[INFO] 2021-07-12 19:15:53,252 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2172
[INFO] 2021-07-12 19:15:53,252 [run_pretraining.py:  558]:	worker_index: 2, step: 2172, cost: 8.202422, mlm loss: 8.202422, speed: 1.064849 steps/s, speed: 8.518794 samples/s, speed: 4361.622705 tokens/s, learning rate: 2.171e-05, loss_scalings: 3518.437988, pp_loss: 7.578498
[INFO] 2021-07-12 19:15:53,252 [run_pretraining.py:  512]:	********exe.run_2172******* 
[INFO] 2021-07-12 19:15:54,164 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:54,164 [run_pretraining.py:  534]:	loss/total_loss, 7.041796684265137, 2173
[INFO] 2021-07-12 19:15:54,164 [run_pretraining.py:  535]:	loss/mlm_loss, 7.041796684265137, 2173
[INFO] 2021-07-12 19:15:54,164 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1719999494962394e-05, 2173
[INFO] 2021-07-12 19:15:54,164 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2173
[INFO] 2021-07-12 19:15:54,165 [run_pretraining.py:  558]:	worker_index: 2, step: 2173, cost: 7.041797, mlm loss: 7.041797, speed: 1.096314 steps/s, speed: 8.770509 samples/s, speed: 4490.500528 tokens/s, learning rate: 2.172e-05, loss_scalings: 3518.437988, pp_loss: 7.223153
[INFO] 2021-07-12 19:15:54,165 [run_pretraining.py:  512]:	********exe.run_2173******* 
[INFO] 2021-07-12 19:15:55,073 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:55,073 [run_pretraining.py:  534]:	loss/total_loss, 7.540760040283203, 2174
[INFO] 2021-07-12 19:15:55,073 [run_pretraining.py:  535]:	loss/mlm_loss, 7.540760040283203, 2174
[INFO] 2021-07-12 19:15:55,074 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1729998479713686e-05, 2174
[INFO] 2021-07-12 19:15:55,074 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2174
[INFO] 2021-07-12 19:15:55,074 [run_pretraining.py:  558]:	worker_index: 2, step: 2174, cost: 7.540760, mlm loss: 7.540760, speed: 1.100566 steps/s, speed: 8.804525 samples/s, speed: 4507.916777 tokens/s, learning rate: 2.173e-05, loss_scalings: 3518.437988, pp_loss: 7.374604
[INFO] 2021-07-12 19:15:55,074 [run_pretraining.py:  512]:	********exe.run_2174******* 
[INFO] 2021-07-12 19:15:55,984 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:55,985 [run_pretraining.py:  534]:	loss/total_loss, 7.526153564453125, 2175
[INFO] 2021-07-12 19:15:55,985 [run_pretraining.py:  535]:	loss/mlm_loss, 7.526153564453125, 2175
[INFO] 2021-07-12 19:15:55,985 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.173999928345438e-05, 2175
[INFO] 2021-07-12 19:15:55,985 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2175
[INFO] 2021-07-12 19:15:55,985 [run_pretraining.py:  558]:	worker_index: 2, step: 2175, cost: 7.526154, mlm loss: 7.526154, speed: 1.097857 steps/s, speed: 8.782857 samples/s, speed: 4496.822932 tokens/s, learning rate: 2.174e-05, loss_scalings: 3518.437988, pp_loss: 7.109540
[INFO] 2021-07-12 19:15:55,985 [run_pretraining.py:  512]:	********exe.run_2175******* 
[INFO] 2021-07-12 19:15:56,888 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:56,888 [run_pretraining.py:  534]:	loss/total_loss, 8.245725631713867, 2176
[INFO] 2021-07-12 19:15:56,888 [run_pretraining.py:  535]:	loss/mlm_loss, 8.245725631713867, 2176
[INFO] 2021-07-12 19:15:56,889 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1750000087195076e-05, 2176
[INFO] 2021-07-12 19:15:56,889 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2176
[INFO] 2021-07-12 19:15:56,889 [run_pretraining.py:  558]:	worker_index: 2, step: 2176, cost: 8.245726, mlm loss: 8.245726, speed: 1.107554 steps/s, speed: 8.860428 samples/s, speed: 4536.539139 tokens/s, learning rate: 2.175e-05, loss_scalings: 3518.437988, pp_loss: 7.591453
[INFO] 2021-07-12 19:15:56,889 [run_pretraining.py:  512]:	********exe.run_2176******* 
[INFO] 2021-07-12 19:15:57,793 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:57,794 [run_pretraining.py:  534]:	loss/total_loss, 8.337281227111816, 2177
[INFO] 2021-07-12 19:15:57,794 [run_pretraining.py:  535]:	loss/mlm_loss, 8.337281227111816, 2177
[INFO] 2021-07-12 19:15:57,794 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1759999071946368e-05, 2177
[INFO] 2021-07-12 19:15:57,794 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2177
[INFO] 2021-07-12 19:15:57,794 [run_pretraining.py:  558]:	worker_index: 2, step: 2177, cost: 8.337281, mlm loss: 8.337281, speed: 1.105451 steps/s, speed: 8.843605 samples/s, speed: 4527.925676 tokens/s, learning rate: 2.176e-05, loss_scalings: 3518.437988, pp_loss: 7.593304
[INFO] 2021-07-12 19:15:57,794 [run_pretraining.py:  512]:	********exe.run_2177******* 
[INFO] 2021-07-12 19:15:58,701 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:58,702 [run_pretraining.py:  534]:	loss/total_loss, 7.6015095710754395, 2178
[INFO] 2021-07-12 19:15:58,702 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6015095710754395, 2178
[INFO] 2021-07-12 19:15:58,702 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1769999875687063e-05, 2178
[INFO] 2021-07-12 19:15:58,702 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2178
[INFO] 2021-07-12 19:15:58,702 [run_pretraining.py:  558]:	worker_index: 2, step: 2178, cost: 7.601510, mlm loss: 7.601510, speed: 1.101806 steps/s, speed: 8.814447 samples/s, speed: 4512.996948 tokens/s, learning rate: 2.177e-05, loss_scalings: 3518.437988, pp_loss: 7.352496
[INFO] 2021-07-12 19:15:58,702 [run_pretraining.py:  512]:	********exe.run_2178******* 
[INFO] 2021-07-12 19:15:59,614 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:59,614 [run_pretraining.py:  534]:	loss/total_loss, 7.287615776062012, 2179
[INFO] 2021-07-12 19:15:59,615 [run_pretraining.py:  535]:	loss/mlm_loss, 7.287615776062012, 2179
[INFO] 2021-07-12 19:15:59,615 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1780000679427758e-05, 2179
[INFO] 2021-07-12 19:15:59,615 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2179
[INFO] 2021-07-12 19:15:59,615 [run_pretraining.py:  558]:	worker_index: 2, step: 2179, cost: 7.287616, mlm loss: 7.287616, speed: 1.096348 steps/s, speed: 8.770784 samples/s, speed: 4490.641381 tokens/s, learning rate: 2.178e-05, loss_scalings: 3518.437988, pp_loss: 7.435179
[INFO] 2021-07-12 19:15:59,615 [run_pretraining.py:  512]:	********exe.run_2179******* 
[INFO] 2021-07-12 19:16:00,529 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:00,530 [run_pretraining.py:  534]:	loss/total_loss, 6.935040473937988, 2180
[INFO] 2021-07-12 19:16:00,530 [run_pretraining.py:  535]:	loss/mlm_loss, 6.935040473937988, 2180
[INFO] 2021-07-12 19:16:00,530 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.178999966417905e-05, 2180
[INFO] 2021-07-12 19:16:00,530 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2180
[INFO] 2021-07-12 19:16:00,530 [run_pretraining.py:  558]:	worker_index: 2, step: 2180, cost: 6.935040, mlm loss: 6.935040, speed: 1.093045 steps/s, speed: 8.744357 samples/s, speed: 4477.110710 tokens/s, learning rate: 2.179e-05, loss_scalings: 3518.437988, pp_loss: 7.292701
[INFO] 2021-07-12 19:16:00,530 [run_pretraining.py:  512]:	********exe.run_2180******* 
[INFO] 2021-07-12 19:16:01,439 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:01,439 [run_pretraining.py:  534]:	loss/total_loss, 7.252790451049805, 2181
[INFO] 2021-07-12 19:16:01,440 [run_pretraining.py:  535]:	loss/mlm_loss, 7.252790451049805, 2181
[INFO] 2021-07-12 19:16:01,440 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.179999864893034e-05, 2181
[INFO] 2021-07-12 19:16:01,440 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2181
[INFO] 2021-07-12 19:16:01,440 [run_pretraining.py:  558]:	worker_index: 2, step: 2181, cost: 7.252790, mlm loss: 7.252790, speed: 1.100217 steps/s, speed: 8.801733 samples/s, speed: 4506.487157 tokens/s, learning rate: 2.180e-05, loss_scalings: 3518.437988, pp_loss: 7.586479
[INFO] 2021-07-12 19:16:01,440 [run_pretraining.py:  512]:	********exe.run_2181******* 
[INFO] 2021-07-12 19:16:02,347 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:02,348 [run_pretraining.py:  534]:	loss/total_loss, 7.940545558929443, 2182
[INFO] 2021-07-12 19:16:02,348 [run_pretraining.py:  535]:	loss/mlm_loss, 7.940545558929443, 2182
[INFO] 2021-07-12 19:16:02,348 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1809999452671036e-05, 2182
[INFO] 2021-07-12 19:16:02,348 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2182
[INFO] 2021-07-12 19:16:02,348 [run_pretraining.py:  558]:	worker_index: 2, step: 2182, cost: 7.940546, mlm loss: 7.940546, speed: 1.101778 steps/s, speed: 8.814223 samples/s, speed: 4512.881955 tokens/s, learning rate: 2.181e-05, loss_scalings: 3518.437988, pp_loss: 7.721097
[INFO] 2021-07-12 19:16:02,348 [run_pretraining.py:  512]:	********exe.run_2182******* 
[INFO] 2021-07-12 19:16:03,256 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:03,257 [run_pretraining.py:  534]:	loss/total_loss, 7.327053070068359, 2183
[INFO] 2021-07-12 19:16:03,257 [run_pretraining.py:  535]:	loss/mlm_loss, 7.327053070068359, 2183
[INFO] 2021-07-12 19:16:03,257 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1819998437422328e-05, 2183
[INFO] 2021-07-12 19:16:03,257 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2183
[INFO] 2021-07-12 19:16:03,257 [run_pretraining.py:  558]:	worker_index: 2, step: 2183, cost: 7.327053, mlm loss: 7.327053, speed: 1.100579 steps/s, speed: 8.804631 samples/s, speed: 4507.971189 tokens/s, learning rate: 2.182e-05, loss_scalings: 3518.437988, pp_loss: 7.474132
[INFO] 2021-07-12 19:16:03,257 [run_pretraining.py:  512]:	********exe.run_2183******* 
[INFO] 2021-07-12 19:16:04,165 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:04,166 [run_pretraining.py:  534]:	loss/total_loss, 7.169193267822266, 2184
[INFO] 2021-07-12 19:16:04,166 [run_pretraining.py:  535]:	loss/mlm_loss, 7.169193267822266, 2184
[INFO] 2021-07-12 19:16:04,166 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1829999241163023e-05, 2184
[INFO] 2021-07-12 19:16:04,166 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2184
[INFO] 2021-07-12 19:16:04,166 [run_pretraining.py:  558]:	worker_index: 2, step: 2184, cost: 7.169193, mlm loss: 7.169193, speed: 1.100906 steps/s, speed: 8.807245 samples/s, speed: 4509.309428 tokens/s, learning rate: 2.183e-05, loss_scalings: 3518.437988, pp_loss: 7.065843
[INFO] 2021-07-12 19:16:04,166 [run_pretraining.py:  512]:	********exe.run_2184******* 
[INFO] 2021-07-12 19:16:05,076 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:05,077 [run_pretraining.py:  534]:	loss/total_loss, 6.162388801574707, 2185
[INFO] 2021-07-12 19:16:05,077 [run_pretraining.py:  535]:	loss/mlm_loss, 6.162388801574707, 2185
[INFO] 2021-07-12 19:16:05,077 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1840000044903718e-05, 2185
[INFO] 2021-07-12 19:16:05,077 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2185
[INFO] 2021-07-12 19:16:05,077 [run_pretraining.py:  558]:	worker_index: 2, step: 2185, cost: 6.162389, mlm loss: 6.162389, speed: 1.098477 steps/s, speed: 8.787819 samples/s, speed: 4499.363245 tokens/s, learning rate: 2.184e-05, loss_scalings: 3518.437988, pp_loss: 6.701998
[INFO] 2021-07-12 19:16:05,077 [run_pretraining.py:  512]:	********exe.run_2185******* 
[INFO] 2021-07-12 19:16:06,024 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:06,024 [run_pretraining.py:  534]:	loss/total_loss, 7.586345195770264, 2186
[INFO] 2021-07-12 19:16:06,025 [run_pretraining.py:  535]:	loss/mlm_loss, 7.586345195770264, 2186
[INFO] 2021-07-12 19:16:06,025 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.184999902965501e-05, 2186
[INFO] 2021-07-12 19:16:06,025 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2186
[INFO] 2021-07-12 19:16:06,025 [run_pretraining.py:  558]:	worker_index: 2, step: 2186, cost: 7.586345, mlm loss: 7.586345, speed: 1.055990 steps/s, speed: 8.447921 samples/s, speed: 4325.335476 tokens/s, learning rate: 2.185e-05, loss_scalings: 3518.437988, pp_loss: 7.304489
[INFO] 2021-07-12 19:16:06,025 [run_pretraining.py:  512]:	********exe.run_2186******* 
[INFO] 2021-07-12 19:16:06,946 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:06,947 [run_pretraining.py:  534]:	loss/total_loss, 7.889291763305664, 2187
[INFO] 2021-07-12 19:16:06,947 [run_pretraining.py:  535]:	loss/mlm_loss, 7.889291763305664, 2187
[INFO] 2021-07-12 19:16:06,947 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1859999833395705e-05, 2187
[INFO] 2021-07-12 19:16:06,947 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2187
[INFO] 2021-07-12 19:16:06,947 [run_pretraining.py:  558]:	worker_index: 2, step: 2187, cost: 7.889292, mlm loss: 7.889292, speed: 1.085038 steps/s, speed: 8.680305 samples/s, speed: 4444.316324 tokens/s, learning rate: 2.186e-05, loss_scalings: 3518.437988, pp_loss: 7.424263
[INFO] 2021-07-12 19:16:06,947 [run_pretraining.py:  512]:	********exe.run_2187******* 
[INFO] 2021-07-12 19:16:07,854 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:07,855 [run_pretraining.py:  534]:	loss/total_loss, 7.749411582946777, 2188
[INFO] 2021-07-12 19:16:07,855 [run_pretraining.py:  535]:	loss/mlm_loss, 7.749411582946777, 2188
[INFO] 2021-07-12 19:16:07,855 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.18700006371364e-05, 2188
[INFO] 2021-07-12 19:16:07,855 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2188
[INFO] 2021-07-12 19:16:07,855 [run_pretraining.py:  558]:	worker_index: 2, step: 2188, cost: 7.749412, mlm loss: 7.749412, speed: 1.102000 steps/s, speed: 8.816003 samples/s, speed: 4513.793761 tokens/s, learning rate: 2.187e-05, loss_scalings: 3518.437988, pp_loss: 7.748462
[INFO] 2021-07-12 19:16:07,855 [run_pretraining.py:  512]:	********exe.run_2188******* 
[INFO] 2021-07-12 19:16:08,767 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:08,767 [run_pretraining.py:  534]:	loss/total_loss, 7.30420446395874, 2189
[INFO] 2021-07-12 19:16:08,767 [run_pretraining.py:  535]:	loss/mlm_loss, 7.30420446395874, 2189
[INFO] 2021-07-12 19:16:08,767 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.187999962188769e-05, 2189
[INFO] 2021-07-12 19:16:08,767 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2189
[INFO] 2021-07-12 19:16:08,767 [run_pretraining.py:  558]:	worker_index: 2, step: 2189, cost: 7.304204, mlm loss: 7.304204, speed: 1.096826 steps/s, speed: 8.774612 samples/s, speed: 4492.601321 tokens/s, learning rate: 2.188e-05, loss_scalings: 3518.437988, pp_loss: 6.610991
[INFO] 2021-07-12 19:16:08,767 [run_pretraining.py:  512]:	********exe.run_2189******* 
[INFO] 2021-07-12 19:16:09,768 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:09,769 [run_pretraining.py:  534]:	loss/total_loss, 7.27235746383667, 2190
[INFO] 2021-07-12 19:16:09,769 [run_pretraining.py:  535]:	loss/mlm_loss, 7.27235746383667, 2190
[INFO] 2021-07-12 19:16:09,769 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1889998606638983e-05, 2190
[INFO] 2021-07-12 19:16:09,769 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2190
[INFO] 2021-07-12 19:16:09,769 [run_pretraining.py:  558]:	worker_index: 2, step: 2190, cost: 7.272357, mlm loss: 7.272357, speed: 0.998922 steps/s, speed: 7.991379 samples/s, speed: 4091.585817 tokens/s, learning rate: 2.189e-05, loss_scalings: 3518.437988, pp_loss: 7.608545
[INFO] 2021-07-12 19:16:09,769 [run_pretraining.py:  512]:	********exe.run_2190******* 
[INFO] 2021-07-12 19:16:10,675 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:10,675 [run_pretraining.py:  534]:	loss/total_loss, 7.305590629577637, 2191
[INFO] 2021-07-12 19:16:10,675 [run_pretraining.py:  535]:	loss/mlm_loss, 7.305590629577637, 2191
[INFO] 2021-07-12 19:16:10,675 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1899999410379678e-05, 2191
[INFO] 2021-07-12 19:16:10,675 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2191
[INFO] 2021-07-12 19:16:10,676 [run_pretraining.py:  558]:	worker_index: 2, step: 2191, cost: 7.305591, mlm loss: 7.305591, speed: 1.103961 steps/s, speed: 8.831685 samples/s, speed: 4521.822615 tokens/s, learning rate: 2.190e-05, loss_scalings: 3518.437988, pp_loss: 7.408945
[INFO] 2021-07-12 19:16:10,676 [run_pretraining.py:  512]:	********exe.run_2191******* 
[INFO] 2021-07-12 19:16:11,584 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:11,585 [run_pretraining.py:  534]:	loss/total_loss, 7.636476516723633, 2192
[INFO] 2021-07-12 19:16:11,585 [run_pretraining.py:  535]:	loss/mlm_loss, 7.636476516723633, 2192
[INFO] 2021-07-12 19:16:11,585 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.190999839513097e-05, 2192
[INFO] 2021-07-12 19:16:11,585 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2192
[INFO] 2021-07-12 19:16:11,585 [run_pretraining.py:  558]:	worker_index: 2, step: 2192, cost: 7.636477, mlm loss: 7.636477, speed: 1.099887 steps/s, speed: 8.799099 samples/s, speed: 4505.138778 tokens/s, learning rate: 2.191e-05, loss_scalings: 3518.437988, pp_loss: 7.743781
[INFO] 2021-07-12 19:16:11,585 [run_pretraining.py:  512]:	********exe.run_2192******* 
[INFO] 2021-07-12 19:16:12,494 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:12,495 [run_pretraining.py:  534]:	loss/total_loss, 7.851544380187988, 2193
[INFO] 2021-07-12 19:16:12,495 [run_pretraining.py:  535]:	loss/mlm_loss, 7.851544380187988, 2193
[INFO] 2021-07-12 19:16:12,495 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1919999198871665e-05, 2193
[INFO] 2021-07-12 19:16:12,495 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2193
[INFO] 2021-07-12 19:16:12,495 [run_pretraining.py:  558]:	worker_index: 2, step: 2193, cost: 7.851544, mlm loss: 7.851544, speed: 1.099692 steps/s, speed: 8.797540 samples/s, speed: 4504.340294 tokens/s, learning rate: 2.192e-05, loss_scalings: 3518.437988, pp_loss: 7.552730
[INFO] 2021-07-12 19:16:12,495 [run_pretraining.py:  512]:	********exe.run_2193******* 
[INFO] 2021-07-12 19:16:13,414 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:13,414 [run_pretraining.py:  534]:	loss/total_loss, 7.667850017547607, 2194
[INFO] 2021-07-12 19:16:13,414 [run_pretraining.py:  535]:	loss/mlm_loss, 7.667850017547607, 2194
[INFO] 2021-07-12 19:16:13,415 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.193000000261236e-05, 2194
[INFO] 2021-07-12 19:16:13,415 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2194
[INFO] 2021-07-12 19:16:13,415 [run_pretraining.py:  558]:	worker_index: 2, step: 2194, cost: 7.667850, mlm loss: 7.667850, speed: 1.088399 steps/s, speed: 8.707189 samples/s, speed: 4458.080666 tokens/s, learning rate: 2.193e-05, loss_scalings: 3518.437988, pp_loss: 6.781683
[INFO] 2021-07-12 19:16:13,415 [run_pretraining.py:  512]:	********exe.run_2194******* 
[INFO] 2021-07-12 19:16:14,327 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:14,327 [run_pretraining.py:  534]:	loss/total_loss, 7.8530378341674805, 2195
[INFO] 2021-07-12 19:16:14,327 [run_pretraining.py:  535]:	loss/mlm_loss, 7.8530378341674805, 2195
[INFO] 2021-07-12 19:16:14,328 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.193999898736365e-05, 2195
[INFO] 2021-07-12 19:16:14,328 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2195
[INFO] 2021-07-12 19:16:14,328 [run_pretraining.py:  558]:	worker_index: 2, step: 2195, cost: 7.853038, mlm loss: 7.853038, speed: 1.096034 steps/s, speed: 8.768270 samples/s, speed: 4489.354083 tokens/s, learning rate: 2.194e-05, loss_scalings: 3518.437988, pp_loss: 7.479033
[INFO] 2021-07-12 19:16:14,328 [run_pretraining.py:  512]:	********exe.run_2195******* 
[INFO] 2021-07-12 19:16:15,237 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:15,237 [run_pretraining.py:  534]:	loss/total_loss, 6.898375988006592, 2196
[INFO] 2021-07-12 19:16:15,237 [run_pretraining.py:  535]:	loss/mlm_loss, 6.898375988006592, 2196
[INFO] 2021-07-12 19:16:15,237 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1949999791104347e-05, 2196
[INFO] 2021-07-12 19:16:15,237 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2196
[INFO] 2021-07-12 19:16:15,237 [run_pretraining.py:  558]:	worker_index: 2, step: 2196, cost: 6.898376, mlm loss: 6.898376, speed: 1.099938 steps/s, speed: 8.799505 samples/s, speed: 4505.346713 tokens/s, learning rate: 2.195e-05, loss_scalings: 3518.437988, pp_loss: 7.310732
[INFO] 2021-07-12 19:16:15,237 [run_pretraining.py:  512]:	********exe.run_2196******* 
[INFO] 2021-07-12 19:16:16,147 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:16,148 [run_pretraining.py:  534]:	loss/total_loss, 7.286013603210449, 2197
[INFO] 2021-07-12 19:16:16,148 [run_pretraining.py:  535]:	loss/mlm_loss, 7.286013603210449, 2197
[INFO] 2021-07-12 19:16:16,148 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.196000059484504e-05, 2197
[INFO] 2021-07-12 19:16:16,148 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2197
[INFO] 2021-07-12 19:16:16,148 [run_pretraining.py:  558]:	worker_index: 2, step: 2197, cost: 7.286014, mlm loss: 7.286014, speed: 1.098934 steps/s, speed: 8.791468 samples/s, speed: 4501.231739 tokens/s, learning rate: 2.196e-05, loss_scalings: 3518.437988, pp_loss: 7.314620
[INFO] 2021-07-12 19:16:16,148 [run_pretraining.py:  512]:	********exe.run_2197******* 
[INFO] 2021-07-12 19:16:17,059 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:17,060 [run_pretraining.py:  534]:	loss/total_loss, 7.907755374908447, 2198
[INFO] 2021-07-12 19:16:17,060 [run_pretraining.py:  535]:	loss/mlm_loss, 7.907755374908447, 2198
[INFO] 2021-07-12 19:16:17,060 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1969999579596333e-05, 2198
[INFO] 2021-07-12 19:16:17,060 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2198
[INFO] 2021-07-12 19:16:17,060 [run_pretraining.py:  558]:	worker_index: 2, step: 2198, cost: 7.907755, mlm loss: 7.907755, speed: 1.096853 steps/s, speed: 8.774828 samples/s, speed: 4492.711758 tokens/s, learning rate: 2.197e-05, loss_scalings: 3518.437988, pp_loss: 7.307392
[INFO] 2021-07-12 19:16:17,060 [run_pretraining.py:  512]:	********exe.run_2198******* 
[INFO] 2021-07-12 19:16:17,967 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:17,968 [run_pretraining.py:  534]:	loss/total_loss, 7.656027793884277, 2199
[INFO] 2021-07-12 19:16:17,968 [run_pretraining.py:  535]:	loss/mlm_loss, 7.656027793884277, 2199
[INFO] 2021-07-12 19:16:17,968 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1979998564347625e-05, 2199
[INFO] 2021-07-12 19:16:17,968 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2199
[INFO] 2021-07-12 19:16:17,968 [run_pretraining.py:  558]:	worker_index: 2, step: 2199, cost: 7.656028, mlm loss: 7.656028, speed: 1.102284 steps/s, speed: 8.818272 samples/s, speed: 4514.955097 tokens/s, learning rate: 2.198e-05, loss_scalings: 3518.437988, pp_loss: 6.932603
[INFO] 2021-07-12 19:16:17,968 [run_pretraining.py:  512]:	********exe.run_2199******* 
[INFO] 2021-07-12 19:16:18,888 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:18,888 [run_pretraining.py:  534]:	loss/total_loss, 6.953275203704834, 2200
[INFO] 2021-07-12 19:16:18,888 [run_pretraining.py:  535]:	loss/mlm_loss, 6.953275203704834, 2200
[INFO] 2021-07-12 19:16:18,888 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.198999936808832e-05, 2200
[INFO] 2021-07-12 19:16:18,888 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2200
[INFO] 2021-07-12 19:16:18,889 [run_pretraining.py:  558]:	worker_index: 2, step: 2200, cost: 6.953275, mlm loss: 6.953275, speed: 1.087161 steps/s, speed: 8.697288 samples/s, speed: 4453.011348 tokens/s, learning rate: 2.199e-05, loss_scalings: 3518.437988, pp_loss: 7.218894
[INFO] 2021-07-12 19:16:18,889 [run_pretraining.py:  512]:	********exe.run_2200******* 
[INFO] 2021-07-12 19:16:19,799 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:19,800 [run_pretraining.py:  534]:	loss/total_loss, 7.492142677307129, 2201
[INFO] 2021-07-12 19:16:19,800 [run_pretraining.py:  535]:	loss/mlm_loss, 7.492142677307129, 2201
[INFO] 2021-07-12 19:16:19,800 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2000000171829015e-05, 2201
[INFO] 2021-07-12 19:16:19,800 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2201
[INFO] 2021-07-12 19:16:19,800 [run_pretraining.py:  558]:	worker_index: 2, step: 2201, cost: 7.492143, mlm loss: 7.492143, speed: 1.097901 steps/s, speed: 8.783209 samples/s, speed: 4497.003027 tokens/s, learning rate: 2.200e-05, loss_scalings: 3518.437988, pp_loss: 7.016722
[INFO] 2021-07-12 19:16:19,800 [run_pretraining.py:  512]:	********exe.run_2201******* 
[INFO] 2021-07-12 19:16:20,739 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:20,739 [run_pretraining.py:  534]:	loss/total_loss, 7.556143760681152, 2202
[INFO] 2021-07-12 19:16:20,739 [run_pretraining.py:  535]:	loss/mlm_loss, 7.556143760681152, 2202
[INFO] 2021-07-12 19:16:20,739 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2009999156580307e-05, 2202
[INFO] 2021-07-12 19:16:20,739 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2202
[INFO] 2021-07-12 19:16:20,739 [run_pretraining.py:  558]:	worker_index: 2, step: 2202, cost: 7.556144, mlm loss: 7.556144, speed: 1.065139 steps/s, speed: 8.521113 samples/s, speed: 4362.810084 tokens/s, learning rate: 2.201e-05, loss_scalings: 3518.437988, pp_loss: 7.368548
[INFO] 2021-07-12 19:16:20,740 [run_pretraining.py:  512]:	********exe.run_2202******* 
[INFO] 2021-07-12 19:16:21,675 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:21,675 [run_pretraining.py:  534]:	loss/total_loss, 7.494428634643555, 2203
[INFO] 2021-07-12 19:16:21,675 [run_pretraining.py:  535]:	loss/mlm_loss, 7.494428634643555, 2203
[INFO] 2021-07-12 19:16:21,675 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2019999960321002e-05, 2203
[INFO] 2021-07-12 19:16:21,675 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2203
[INFO] 2021-07-12 19:16:21,676 [run_pretraining.py:  558]:	worker_index: 2, step: 2203, cost: 7.494429, mlm loss: 7.494429, speed: 1.068977 steps/s, speed: 8.551815 samples/s, speed: 4378.529339 tokens/s, learning rate: 2.202e-05, loss_scalings: 3518.437988, pp_loss: 7.412263
[INFO] 2021-07-12 19:16:21,676 [run_pretraining.py:  512]:	********exe.run_2203******* 
[INFO] 2021-07-12 19:16:22,580 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:22,581 [run_pretraining.py:  534]:	loss/total_loss, 7.215766906738281, 2204
[INFO] 2021-07-12 19:16:22,581 [run_pretraining.py:  535]:	loss/mlm_loss, 7.215766906738281, 2204
[INFO] 2021-07-12 19:16:22,581 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2029998945072293e-05, 2204
[INFO] 2021-07-12 19:16:22,581 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2204
[INFO] 2021-07-12 19:16:22,581 [run_pretraining.py:  558]:	worker_index: 2, step: 2204, cost: 7.215767, mlm loss: 7.215767, speed: 1.105331 steps/s, speed: 8.842647 samples/s, speed: 4527.435250 tokens/s, learning rate: 2.203e-05, loss_scalings: 3518.437988, pp_loss: 7.567794
[INFO] 2021-07-12 19:16:22,581 [run_pretraining.py:  512]:	********exe.run_2204******* 
[INFO] 2021-07-12 19:16:23,491 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:23,491 [run_pretraining.py:  534]:	loss/total_loss, 7.122957229614258, 2205
[INFO] 2021-07-12 19:16:23,492 [run_pretraining.py:  535]:	loss/mlm_loss, 7.122957229614258, 2205
[INFO] 2021-07-12 19:16:23,492 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.203999974881299e-05, 2205
[INFO] 2021-07-12 19:16:23,492 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2205
[INFO] 2021-07-12 19:16:23,492 [run_pretraining.py:  558]:	worker_index: 2, step: 2205, cost: 7.122957, mlm loss: 7.122957, speed: 1.098557 steps/s, speed: 8.788454 samples/s, speed: 4499.688499 tokens/s, learning rate: 2.204e-05, loss_scalings: 3518.437988, pp_loss: 7.346178
[INFO] 2021-07-12 19:16:23,492 [run_pretraining.py:  512]:	********exe.run_2205******* 
[INFO] 2021-07-12 19:16:24,404 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:24,405 [run_pretraining.py:  534]:	loss/total_loss, 6.395229339599609, 2206
[INFO] 2021-07-12 19:16:24,405 [run_pretraining.py:  535]:	loss/mlm_loss, 6.395229339599609, 2206
[INFO] 2021-07-12 19:16:24,405 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2050000552553684e-05, 2206
[INFO] 2021-07-12 19:16:24,405 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2206
[INFO] 2021-07-12 19:16:24,405 [run_pretraining.py:  558]:	worker_index: 2, step: 2206, cost: 6.395229, mlm loss: 6.395229, speed: 1.095885 steps/s, speed: 8.767081 samples/s, speed: 4488.745309 tokens/s, learning rate: 2.205e-05, loss_scalings: 3518.437988, pp_loss: 7.001757
[INFO] 2021-07-12 19:16:24,405 [run_pretraining.py:  512]:	********exe.run_2206******* 
[INFO] 2021-07-12 19:16:25,308 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:25,308 [run_pretraining.py:  534]:	loss/total_loss, 7.604401588439941, 2207
[INFO] 2021-07-12 19:16:25,308 [run_pretraining.py:  535]:	loss/mlm_loss, 7.604401588439941, 2207
[INFO] 2021-07-12 19:16:25,308 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2059999537304975e-05, 2207
[INFO] 2021-07-12 19:16:25,309 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2207
[INFO] 2021-07-12 19:16:25,309 [run_pretraining.py:  558]:	worker_index: 2, step: 2207, cost: 7.604402, mlm loss: 7.604402, speed: 1.107235 steps/s, speed: 8.857876 samples/s, speed: 4535.232580 tokens/s, learning rate: 2.206e-05, loss_scalings: 3518.437988, pp_loss: 7.482738
[INFO] 2021-07-12 19:16:25,309 [run_pretraining.py:  512]:	********exe.run_2207******* 
[INFO] 2021-07-12 19:16:26,207 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:26,208 [run_pretraining.py:  534]:	loss/total_loss, 7.664851188659668, 2208
[INFO] 2021-07-12 19:16:26,208 [run_pretraining.py:  535]:	loss/mlm_loss, 7.664851188659668, 2208
[INFO] 2021-07-12 19:16:26,208 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2069998522056267e-05, 2208
[INFO] 2021-07-12 19:16:26,208 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2208
[INFO] 2021-07-12 19:16:26,208 [run_pretraining.py:  558]:	worker_index: 2, step: 2208, cost: 7.664851, mlm loss: 7.664851, speed: 1.112821 steps/s, speed: 8.902571 samples/s, speed: 4558.116476 tokens/s, learning rate: 2.207e-05, loss_scalings: 3518.437988, pp_loss: 7.122020
[INFO] 2021-07-12 19:16:26,208 [run_pretraining.py:  512]:	********exe.run_2208******* 
[INFO] 2021-07-12 19:16:27,114 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:27,114 [run_pretraining.py:  534]:	loss/total_loss, 7.1394147872924805, 2209
[INFO] 2021-07-12 19:16:27,115 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1394147872924805, 2209
[INFO] 2021-07-12 19:16:27,115 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2079999325796962e-05, 2209
[INFO] 2021-07-12 19:16:27,115 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2209
[INFO] 2021-07-12 19:16:27,115 [run_pretraining.py:  558]:	worker_index: 2, step: 2209, cost: 7.139415, mlm loss: 7.139415, speed: 1.103325 steps/s, speed: 8.826599 samples/s, speed: 4519.218844 tokens/s, learning rate: 2.208e-05, loss_scalings: 3518.437988, pp_loss: 6.976640
[INFO] 2021-07-12 19:16:27,115 [run_pretraining.py:  512]:	********exe.run_2209******* 
[INFO] 2021-07-12 19:16:28,028 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:28,029 [run_pretraining.py:  534]:	loss/total_loss, 7.354154586791992, 2210
[INFO] 2021-07-12 19:16:28,029 [run_pretraining.py:  535]:	loss/mlm_loss, 7.354154586791992, 2210
[INFO] 2021-07-12 19:16:28,029 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2090000129537657e-05, 2210
[INFO] 2021-07-12 19:16:28,029 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2210
[INFO] 2021-07-12 19:16:28,029 [run_pretraining.py:  558]:	worker_index: 2, step: 2210, cost: 7.354155, mlm loss: 7.354155, speed: 1.094599 steps/s, speed: 8.756792 samples/s, speed: 4483.477343 tokens/s, learning rate: 2.209e-05, loss_scalings: 3518.437988, pp_loss: 7.216097
[INFO] 2021-07-12 19:16:28,029 [run_pretraining.py:  512]:	********exe.run_2210******* 
[INFO] 2021-07-12 19:16:29,017 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:29,018 [run_pretraining.py:  534]:	loss/total_loss, 7.085619926452637, 2211
[INFO] 2021-07-12 19:16:29,018 [run_pretraining.py:  535]:	loss/mlm_loss, 7.085619926452637, 2211
[INFO] 2021-07-12 19:16:29,018 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.209999911428895e-05, 2211
[INFO] 2021-07-12 19:16:29,018 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2211
[INFO] 2021-07-12 19:16:29,018 [run_pretraining.py:  558]:	worker_index: 2, step: 2211, cost: 7.085620, mlm loss: 7.085620, speed: 1.011562 steps/s, speed: 8.092499 samples/s, speed: 4143.359693 tokens/s, learning rate: 2.210e-05, loss_scalings: 3518.437988, pp_loss: 7.406190
[INFO] 2021-07-12 19:16:29,018 [run_pretraining.py:  512]:	********exe.run_2211******* 
[INFO] 2021-07-12 19:16:29,923 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:29,924 [run_pretraining.py:  534]:	loss/total_loss, 7.384459972381592, 2212
[INFO] 2021-07-12 19:16:29,924 [run_pretraining.py:  535]:	loss/mlm_loss, 7.384459972381592, 2212
[INFO] 2021-07-12 19:16:29,924 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2109999918029644e-05, 2212
[INFO] 2021-07-12 19:16:29,924 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2212
[INFO] 2021-07-12 19:16:29,924 [run_pretraining.py:  558]:	worker_index: 2, step: 2212, cost: 7.384460, mlm loss: 7.384460, speed: 1.104801 steps/s, speed: 8.838406 samples/s, speed: 4525.263618 tokens/s, learning rate: 2.211e-05, loss_scalings: 3518.437988, pp_loss: 6.951028
[INFO] 2021-07-12 19:16:29,924 [run_pretraining.py:  512]:	********exe.run_2212******* 
[INFO] 2021-07-12 19:16:30,832 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:30,833 [run_pretraining.py:  534]:	loss/total_loss, 6.462481498718262, 2213
[INFO] 2021-07-12 19:16:30,833 [run_pretraining.py:  535]:	loss/mlm_loss, 6.462481498718262, 2213
[INFO] 2021-07-12 19:16:30,833 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.212000072177034e-05, 2213
[INFO] 2021-07-12 19:16:30,833 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2213
[INFO] 2021-07-12 19:16:30,833 [run_pretraining.py:  558]:	worker_index: 2, step: 2213, cost: 6.462481, mlm loss: 6.462481, speed: 1.100866 steps/s, speed: 8.806926 samples/s, speed: 4509.146099 tokens/s, learning rate: 2.212e-05, loss_scalings: 3518.437988, pp_loss: 7.006293
[INFO] 2021-07-12 19:16:30,833 [run_pretraining.py:  512]:	********exe.run_2213******* 
[INFO] 2021-07-12 19:16:31,741 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:31,742 [run_pretraining.py:  534]:	loss/total_loss, 6.882692337036133, 2214
[INFO] 2021-07-12 19:16:31,742 [run_pretraining.py:  535]:	loss/mlm_loss, 6.882692337036133, 2214
[INFO] 2021-07-12 19:16:31,742 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.212999970652163e-05, 2214
[INFO] 2021-07-12 19:16:31,742 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2214
[INFO] 2021-07-12 19:16:31,742 [run_pretraining.py:  558]:	worker_index: 2, step: 2214, cost: 6.882692, mlm loss: 6.882692, speed: 1.100705 steps/s, speed: 8.805639 samples/s, speed: 4508.486985 tokens/s, learning rate: 2.213e-05, loss_scalings: 3518.437988, pp_loss: 6.785816
[INFO] 2021-07-12 19:16:31,742 [run_pretraining.py:  512]:	********exe.run_2214******* 
[INFO] 2021-07-12 19:16:32,649 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:32,650 [run_pretraining.py:  534]:	loss/total_loss, 7.126786708831787, 2215
[INFO] 2021-07-12 19:16:32,650 [run_pretraining.py:  535]:	loss/mlm_loss, 7.126786708831787, 2215
[INFO] 2021-07-12 19:16:32,650 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2139998691272922e-05, 2215
[INFO] 2021-07-12 19:16:32,650 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2215
[INFO] 2021-07-12 19:16:32,650 [run_pretraining.py:  558]:	worker_index: 2, step: 2215, cost: 7.126787, mlm loss: 7.126787, speed: 1.102151 steps/s, speed: 8.817208 samples/s, speed: 4514.410535 tokens/s, learning rate: 2.214e-05, loss_scalings: 2814.750488, pp_loss: 7.460028
[INFO] 2021-07-12 19:16:32,650 [run_pretraining.py:  512]:	********exe.run_2215******* 
[INFO] 2021-07-12 19:16:33,564 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:33,564 [run_pretraining.py:  534]:	loss/total_loss, 7.797093391418457, 2216
[INFO] 2021-07-12 19:16:33,565 [run_pretraining.py:  535]:	loss/mlm_loss, 7.797093391418457, 2216
[INFO] 2021-07-12 19:16:33,565 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2149999495013617e-05, 2216
[INFO] 2021-07-12 19:16:33,565 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2216
[INFO] 2021-07-12 19:16:33,565 [run_pretraining.py:  558]:	worker_index: 2, step: 2216, cost: 7.797093, mlm loss: 7.797093, speed: 1.093794 steps/s, speed: 8.750350 samples/s, speed: 4480.179017 tokens/s, learning rate: 2.215e-05, loss_scalings: 2814.750488, pp_loss: 7.276474
[INFO] 2021-07-12 19:16:33,565 [run_pretraining.py:  512]:	********exe.run_2216******* 
[INFO] 2021-07-12 19:16:34,480 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:34,480 [run_pretraining.py:  534]:	loss/total_loss, 6.909452438354492, 2217
[INFO] 2021-07-12 19:16:34,480 [run_pretraining.py:  535]:	loss/mlm_loss, 6.909452438354492, 2217
[INFO] 2021-07-12 19:16:34,481 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.215999847976491e-05, 2217
[INFO] 2021-07-12 19:16:34,481 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2217
[INFO] 2021-07-12 19:16:34,481 [run_pretraining.py:  558]:	worker_index: 2, step: 2217, cost: 6.909452, mlm loss: 6.909452, speed: 1.092578 steps/s, speed: 8.740626 samples/s, speed: 4475.200398 tokens/s, learning rate: 2.216e-05, loss_scalings: 2814.750488, pp_loss: 7.205776
[INFO] 2021-07-12 19:16:34,481 [run_pretraining.py:  512]:	********exe.run_2217******* 
[INFO] 2021-07-12 19:16:35,396 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:35,397 [run_pretraining.py:  534]:	loss/total_loss, 7.118236541748047, 2218
[INFO] 2021-07-12 19:16:35,397 [run_pretraining.py:  535]:	loss/mlm_loss, 7.118236541748047, 2218
[INFO] 2021-07-12 19:16:35,397 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2169999283505604e-05, 2218
[INFO] 2021-07-12 19:16:35,397 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2218
[INFO] 2021-07-12 19:16:35,397 [run_pretraining.py:  558]:	worker_index: 2, step: 2218, cost: 7.118237, mlm loss: 7.118237, speed: 1.091840 steps/s, speed: 8.734721 samples/s, speed: 4472.177322 tokens/s, learning rate: 2.217e-05, loss_scalings: 2814.750488, pp_loss: 7.271171
[INFO] 2021-07-12 19:16:35,397 [run_pretraining.py:  512]:	********exe.run_2218******* 
[INFO] 2021-07-12 19:16:36,307 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:36,308 [run_pretraining.py:  534]:	loss/total_loss, 7.358245372772217, 2219
[INFO] 2021-07-12 19:16:36,308 [run_pretraining.py:  535]:	loss/mlm_loss, 7.358245372772217, 2219
[INFO] 2021-07-12 19:16:36,308 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.21800000872463e-05, 2219
[INFO] 2021-07-12 19:16:36,308 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2219
[INFO] 2021-07-12 19:16:36,308 [run_pretraining.py:  558]:	worker_index: 2, step: 2219, cost: 7.358245, mlm loss: 7.358245, speed: 1.098419 steps/s, speed: 8.787354 samples/s, speed: 4499.125226 tokens/s, learning rate: 2.218e-05, loss_scalings: 2814.750488, pp_loss: 7.105649
[INFO] 2021-07-12 19:16:36,308 [run_pretraining.py:  512]:	********exe.run_2219******* 
[INFO] 2021-07-12 19:16:37,221 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:37,222 [run_pretraining.py:  534]:	loss/total_loss, 7.152502059936523, 2220
[INFO] 2021-07-12 19:16:37,222 [run_pretraining.py:  535]:	loss/mlm_loss, 7.152502059936523, 2220
[INFO] 2021-07-12 19:16:37,222 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.218999907199759e-05, 2220
[INFO] 2021-07-12 19:16:37,222 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2220
[INFO] 2021-07-12 19:16:37,222 [run_pretraining.py:  558]:	worker_index: 2, step: 2220, cost: 7.152502, mlm loss: 7.152502, speed: 1.095110 steps/s, speed: 8.760880 samples/s, speed: 4485.570396 tokens/s, learning rate: 2.219e-05, loss_scalings: 2814.750488, pp_loss: 7.547122
[INFO] 2021-07-12 19:16:37,222 [run_pretraining.py:  512]:	********exe.run_2220******* 
[INFO] 2021-07-12 19:16:38,139 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:38,139 [run_pretraining.py:  534]:	loss/total_loss, 7.163992404937744, 2221
[INFO] 2021-07-12 19:16:38,139 [run_pretraining.py:  535]:	loss/mlm_loss, 7.163992404937744, 2221
[INFO] 2021-07-12 19:16:38,139 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2199999875738285e-05, 2221
[INFO] 2021-07-12 19:16:38,139 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2221
[INFO] 2021-07-12 19:16:38,140 [run_pretraining.py:  558]:	worker_index: 2, step: 2221, cost: 7.163992, mlm loss: 7.163992, speed: 1.090444 steps/s, speed: 8.723551 samples/s, speed: 4466.458070 tokens/s, learning rate: 2.220e-05, loss_scalings: 2814.750488, pp_loss: 7.339465
[INFO] 2021-07-12 19:16:38,140 [run_pretraining.py:  512]:	********exe.run_2221******* 
[INFO] 2021-07-12 19:16:39,049 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:39,049 [run_pretraining.py:  534]:	loss/total_loss, 7.371127605438232, 2222
[INFO] 2021-07-12 19:16:39,050 [run_pretraining.py:  535]:	loss/mlm_loss, 7.371127605438232, 2222
[INFO] 2021-07-12 19:16:39,050 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.221000067947898e-05, 2222
[INFO] 2021-07-12 19:16:39,050 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2222
[INFO] 2021-07-12 19:16:39,050 [run_pretraining.py:  558]:	worker_index: 2, step: 2222, cost: 7.371128, mlm loss: 7.371128, speed: 1.099287 steps/s, speed: 8.794295 samples/s, speed: 4502.679268 tokens/s, learning rate: 2.221e-05, loss_scalings: 2814.750488, pp_loss: 7.531366
[INFO] 2021-07-12 19:16:39,050 [run_pretraining.py:  512]:	********exe.run_2222******* 
[INFO] 2021-07-12 19:16:39,966 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:39,966 [run_pretraining.py:  534]:	loss/total_loss, 7.419777870178223, 2223
[INFO] 2021-07-12 19:16:39,966 [run_pretraining.py:  535]:	loss/mlm_loss, 7.419777870178223, 2223
[INFO] 2021-07-12 19:16:39,966 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2219999664230272e-05, 2223
[INFO] 2021-07-12 19:16:39,966 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2223
[INFO] 2021-07-12 19:16:39,966 [run_pretraining.py:  558]:	worker_index: 2, step: 2223, cost: 7.419778, mlm loss: 7.419778, speed: 1.091788 steps/s, speed: 8.734303 samples/s, speed: 4471.963125 tokens/s, learning rate: 2.222e-05, loss_scalings: 2814.750488, pp_loss: 7.159073
[INFO] 2021-07-12 19:16:39,966 [run_pretraining.py:  512]:	********exe.run_2223******* 
[INFO] 2021-07-12 19:16:40,878 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:40,878 [run_pretraining.py:  534]:	loss/total_loss, 6.890262603759766, 2224
[INFO] 2021-07-12 19:16:40,878 [run_pretraining.py:  535]:	loss/mlm_loss, 6.890262603759766, 2224
[INFO] 2021-07-12 19:16:40,879 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2229998648981564e-05, 2224
[INFO] 2021-07-12 19:16:40,879 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2224
[INFO] 2021-07-12 19:16:40,879 [run_pretraining.py:  558]:	worker_index: 2, step: 2224, cost: 6.890263, mlm loss: 6.890263, speed: 1.096847 steps/s, speed: 8.774779 samples/s, speed: 4492.687085 tokens/s, learning rate: 2.223e-05, loss_scalings: 2814.750488, pp_loss: 7.494990
[INFO] 2021-07-12 19:16:40,879 [run_pretraining.py:  512]:	********exe.run_2224******* 
[INFO] 2021-07-12 19:16:41,789 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:41,789 [run_pretraining.py:  534]:	loss/total_loss, 6.400445461273193, 2225
[INFO] 2021-07-12 19:16:41,790 [run_pretraining.py:  535]:	loss/mlm_loss, 6.400445461273193, 2225
[INFO] 2021-07-12 19:16:41,790 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.223999945272226e-05, 2225
[INFO] 2021-07-12 19:16:41,790 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2225
[INFO] 2021-07-12 19:16:41,790 [run_pretraining.py:  558]:	worker_index: 2, step: 2225, cost: 6.400445, mlm loss: 6.400445, speed: 1.098319 steps/s, speed: 8.786549 samples/s, speed: 4498.712878 tokens/s, learning rate: 2.224e-05, loss_scalings: 2814.750488, pp_loss: 6.938078
[INFO] 2021-07-12 19:16:41,790 [run_pretraining.py:  512]:	********exe.run_2225******* 
[INFO] 2021-07-12 19:16:42,702 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:42,702 [run_pretraining.py:  534]:	loss/total_loss, 7.344067573547363, 2226
[INFO] 2021-07-12 19:16:42,703 [run_pretraining.py:  535]:	loss/mlm_loss, 7.344067573547363, 2226
[INFO] 2021-07-12 19:16:42,703 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.224999843747355e-05, 2226
[INFO] 2021-07-12 19:16:42,703 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2226
[INFO] 2021-07-12 19:16:42,703 [run_pretraining.py:  558]:	worker_index: 2, step: 2226, cost: 7.344068, mlm loss: 7.344068, speed: 1.095940 steps/s, speed: 8.767521 samples/s, speed: 4488.970501 tokens/s, learning rate: 2.225e-05, loss_scalings: 2814.750488, pp_loss: 7.324985
[INFO] 2021-07-12 19:16:42,703 [run_pretraining.py:  512]:	********exe.run_2226******* 
[INFO] 2021-07-12 19:16:43,627 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:43,628 [run_pretraining.py:  534]:	loss/total_loss, 7.298685073852539, 2227
[INFO] 2021-07-12 19:16:43,628 [run_pretraining.py:  535]:	loss/mlm_loss, 7.298685073852539, 2227
[INFO] 2021-07-12 19:16:43,628 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2259999241214246e-05, 2227
[INFO] 2021-07-12 19:16:43,628 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2227
[INFO] 2021-07-12 19:16:43,628 [run_pretraining.py:  558]:	worker_index: 2, step: 2227, cost: 7.298685, mlm loss: 7.298685, speed: 1.081688 steps/s, speed: 8.653503 samples/s, speed: 4430.593295 tokens/s, learning rate: 2.226e-05, loss_scalings: 2814.750488, pp_loss: 7.306895
[INFO] 2021-07-12 19:16:43,628 [run_pretraining.py:  512]:	********exe.run_2227******* 
[INFO] 2021-07-12 19:16:44,539 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:44,539 [run_pretraining.py:  534]:	loss/total_loss, 7.02146053314209, 2228
[INFO] 2021-07-12 19:16:44,540 [run_pretraining.py:  535]:	loss/mlm_loss, 7.02146053314209, 2228
[INFO] 2021-07-12 19:16:44,540 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.227000004495494e-05, 2228
[INFO] 2021-07-12 19:16:44,540 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2228
[INFO] 2021-07-12 19:16:44,540 [run_pretraining.py:  558]:	worker_index: 2, step: 2228, cost: 7.021461, mlm loss: 7.021461, speed: 1.097358 steps/s, speed: 8.778861 samples/s, speed: 4494.776989 tokens/s, learning rate: 2.227e-05, loss_scalings: 2814.750488, pp_loss: 6.463873
[INFO] 2021-07-12 19:16:44,540 [run_pretraining.py:  512]:	********exe.run_2228******* 
[INFO] 2021-07-12 19:16:45,454 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:45,454 [run_pretraining.py:  534]:	loss/total_loss, 7.5012054443359375, 2229
[INFO] 2021-07-12 19:16:45,454 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5012054443359375, 2229
[INFO] 2021-07-12 19:16:45,454 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2279999029706232e-05, 2229
[INFO] 2021-07-12 19:16:45,454 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2229
[INFO] 2021-07-12 19:16:45,454 [run_pretraining.py:  558]:	worker_index: 2, step: 2229, cost: 7.501205, mlm loss: 7.501205, speed: 1.093955 steps/s, speed: 8.751639 samples/s, speed: 4480.839228 tokens/s, learning rate: 2.228e-05, loss_scalings: 2814.750488, pp_loss: 7.312285
[INFO] 2021-07-12 19:16:45,455 [run_pretraining.py:  512]:	********exe.run_2229******* 
[INFO] 2021-07-12 19:16:46,371 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:46,372 [run_pretraining.py:  534]:	loss/total_loss, 7.469139099121094, 2230
[INFO] 2021-07-12 19:16:46,372 [run_pretraining.py:  535]:	loss/mlm_loss, 7.469139099121094, 2230
[INFO] 2021-07-12 19:16:46,372 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2289999833446927e-05, 2230
[INFO] 2021-07-12 19:16:46,372 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2230
[INFO] 2021-07-12 19:16:46,372 [run_pretraining.py:  558]:	worker_index: 2, step: 2230, cost: 7.469139, mlm loss: 7.469139, speed: 1.090750 steps/s, speed: 8.726003 samples/s, speed: 4467.713679 tokens/s, learning rate: 2.229e-05, loss_scalings: 2814.750488, pp_loss: 7.500864
[INFO] 2021-07-12 19:16:46,372 [run_pretraining.py:  512]:	********exe.run_2230******* 
[INFO] 2021-07-12 19:16:47,288 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:47,289 [run_pretraining.py:  534]:	loss/total_loss, 6.843724727630615, 2231
[INFO] 2021-07-12 19:16:47,289 [run_pretraining.py:  535]:	loss/mlm_loss, 6.843724727630615, 2231
[INFO] 2021-07-12 19:16:47,289 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2300000637187622e-05, 2231
[INFO] 2021-07-12 19:16:47,289 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2231
[INFO] 2021-07-12 19:16:47,289 [run_pretraining.py:  558]:	worker_index: 2, step: 2231, cost: 6.843725, mlm loss: 6.843725, speed: 1.091138 steps/s, speed: 8.729102 samples/s, speed: 4469.300170 tokens/s, learning rate: 2.230e-05, loss_scalings: 2814.750488, pp_loss: 6.966451
[INFO] 2021-07-12 19:16:47,289 [run_pretraining.py:  512]:	********exe.run_2231******* 
[INFO] 2021-07-12 19:16:48,203 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:48,203 [run_pretraining.py:  534]:	loss/total_loss, 7.873746395111084, 2232
[INFO] 2021-07-12 19:16:48,203 [run_pretraining.py:  535]:	loss/mlm_loss, 7.873746395111084, 2232
[INFO] 2021-07-12 19:16:48,203 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2309999621938914e-05, 2232
[INFO] 2021-07-12 19:16:48,203 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2232
[INFO] 2021-07-12 19:16:48,203 [run_pretraining.py:  558]:	worker_index: 2, step: 2232, cost: 7.873746, mlm loss: 7.873746, speed: 1.094301 steps/s, speed: 8.754409 samples/s, speed: 4482.257297 tokens/s, learning rate: 2.231e-05, loss_scalings: 2814.750488, pp_loss: 6.806152
[INFO] 2021-07-12 19:16:48,203 [run_pretraining.py:  512]:	********exe.run_2232******* 
[INFO] 2021-07-12 19:16:49,112 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:49,112 [run_pretraining.py:  534]:	loss/total_loss, 7.286046028137207, 2233
[INFO] 2021-07-12 19:16:49,113 [run_pretraining.py:  535]:	loss/mlm_loss, 7.286046028137207, 2233
[INFO] 2021-07-12 19:16:49,113 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2319998606690206e-05, 2233
[INFO] 2021-07-12 19:16:49,113 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2233
[INFO] 2021-07-12 19:16:49,113 [run_pretraining.py:  558]:	worker_index: 2, step: 2233, cost: 7.286046, mlm loss: 7.286046, speed: 1.100366 steps/s, speed: 8.802924 samples/s, speed: 4507.097206 tokens/s, learning rate: 2.232e-05, loss_scalings: 2814.750488, pp_loss: 6.725354
[INFO] 2021-07-12 19:16:49,113 [run_pretraining.py:  512]:	********exe.run_2233******* 
[INFO] 2021-07-12 19:16:50,029 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:50,029 [run_pretraining.py:  534]:	loss/total_loss, 6.817784309387207, 2234
[INFO] 2021-07-12 19:16:50,029 [run_pretraining.py:  535]:	loss/mlm_loss, 6.817784309387207, 2234
[INFO] 2021-07-12 19:16:50,029 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.23299994104309e-05, 2234
[INFO] 2021-07-12 19:16:50,029 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2234
[INFO] 2021-07-12 19:16:50,029 [run_pretraining.py:  558]:	worker_index: 2, step: 2234, cost: 6.817784, mlm loss: 6.817784, speed: 1.091743 steps/s, speed: 8.733941 samples/s, speed: 4471.778046 tokens/s, learning rate: 2.233e-05, loss_scalings: 2814.750488, pp_loss: 7.354856
[INFO] 2021-07-12 19:16:50,029 [run_pretraining.py:  512]:	********exe.run_2234******* 
[INFO] 2021-07-12 19:16:50,949 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:50,950 [run_pretraining.py:  534]:	loss/total_loss, 7.359265327453613, 2235
[INFO] 2021-07-12 19:16:50,950 [run_pretraining.py:  535]:	loss/mlm_loss, 7.359265327453613, 2235
[INFO] 2021-07-12 19:16:50,950 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2339998395182192e-05, 2235
[INFO] 2021-07-12 19:16:50,950 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2235
[INFO] 2021-07-12 19:16:50,950 [run_pretraining.py:  558]:	worker_index: 2, step: 2235, cost: 7.359265, mlm loss: 7.359265, speed: 1.087117 steps/s, speed: 8.696936 samples/s, speed: 4452.831298 tokens/s, learning rate: 2.234e-05, loss_scalings: 2814.750488, pp_loss: 7.219259
[INFO] 2021-07-12 19:16:50,950 [run_pretraining.py:  512]:	********exe.run_2235******* 
[INFO] 2021-07-12 19:16:51,896 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:51,897 [run_pretraining.py:  534]:	loss/total_loss, 7.391239166259766, 2236
[INFO] 2021-07-12 19:16:51,897 [run_pretraining.py:  535]:	loss/mlm_loss, 7.391239166259766, 2236
[INFO] 2021-07-12 19:16:51,897 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2349999198922887e-05, 2236
[INFO] 2021-07-12 19:16:51,897 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2236
[INFO] 2021-07-12 19:16:51,897 [run_pretraining.py:  558]:	worker_index: 2, step: 2236, cost: 7.391239, mlm loss: 7.391239, speed: 1.056250 steps/s, speed: 8.449997 samples/s, speed: 4326.398582 tokens/s, learning rate: 2.235e-05, loss_scalings: 2814.750488, pp_loss: 5.568245
[INFO] 2021-07-12 19:16:51,897 [run_pretraining.py:  512]:	********exe.run_2236******* 
[INFO] 2021-07-12 19:16:52,841 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:52,842 [run_pretraining.py:  534]:	loss/total_loss, 7.066046714782715, 2237
[INFO] 2021-07-12 19:16:52,842 [run_pretraining.py:  535]:	loss/mlm_loss, 7.066046714782715, 2237
[INFO] 2021-07-12 19:16:52,842 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2360000002663583e-05, 2237
[INFO] 2021-07-12 19:16:52,842 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2237
[INFO] 2021-07-12 19:16:52,842 [run_pretraining.py:  558]:	worker_index: 2, step: 2237, cost: 7.066047, mlm loss: 7.066047, speed: 1.059076 steps/s, speed: 8.472608 samples/s, speed: 4337.975065 tokens/s, learning rate: 2.236e-05, loss_scalings: 2814.750488, pp_loss: 6.587032
[INFO] 2021-07-12 19:16:52,842 [run_pretraining.py:  512]:	********exe.run_2237******* 
[INFO] 2021-07-12 19:16:53,753 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:53,754 [run_pretraining.py:  534]:	loss/total_loss, 7.456421852111816, 2238
[INFO] 2021-07-12 19:16:53,754 [run_pretraining.py:  535]:	loss/mlm_loss, 7.456421852111816, 2238
[INFO] 2021-07-12 19:16:53,754 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2369998987414874e-05, 2238
[INFO] 2021-07-12 19:16:53,754 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2238
[INFO] 2021-07-12 19:16:53,754 [run_pretraining.py:  558]:	worker_index: 2, step: 2238, cost: 7.456422, mlm loss: 7.456422, speed: 1.097223 steps/s, speed: 8.777787 samples/s, speed: 4494.226702 tokens/s, learning rate: 2.237e-05, loss_scalings: 2814.750488, pp_loss: 7.401924
[INFO] 2021-07-12 19:16:53,754 [run_pretraining.py:  512]:	********exe.run_2238******* 
[INFO] 2021-07-12 19:16:54,662 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:54,662 [run_pretraining.py:  534]:	loss/total_loss, 7.158218860626221, 2239
[INFO] 2021-07-12 19:16:54,662 [run_pretraining.py:  535]:	loss/mlm_loss, 7.158218860626221, 2239
[INFO] 2021-07-12 19:16:54,662 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.237999979115557e-05, 2239
[INFO] 2021-07-12 19:16:54,662 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2239
[INFO] 2021-07-12 19:16:54,662 [run_pretraining.py:  558]:	worker_index: 2, step: 2239, cost: 7.158219, mlm loss: 7.158219, speed: 1.101463 steps/s, speed: 8.811706 samples/s, speed: 4511.593724 tokens/s, learning rate: 2.238e-05, loss_scalings: 2814.750488, pp_loss: 7.633739
[INFO] 2021-07-12 19:16:54,663 [run_pretraining.py:  512]:	********exe.run_2239******* 
[INFO] 2021-07-12 19:16:55,572 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:55,572 [run_pretraining.py:  534]:	loss/total_loss, 7.034934043884277, 2240
[INFO] 2021-07-12 19:16:55,572 [run_pretraining.py:  535]:	loss/mlm_loss, 7.034934043884277, 2240
[INFO] 2021-07-12 19:16:55,572 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2390000594896264e-05, 2240
[INFO] 2021-07-12 19:16:55,572 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2240
[INFO] 2021-07-12 19:16:55,572 [run_pretraining.py:  558]:	worker_index: 2, step: 2240, cost: 7.034934, mlm loss: 7.034934, speed: 1.099680 steps/s, speed: 8.797443 samples/s, speed: 4504.290693 tokens/s, learning rate: 2.239e-05, loss_scalings: 2814.750488, pp_loss: 7.350289
[INFO] 2021-07-12 19:16:55,573 [run_pretraining.py:  512]:	********exe.run_2240******* 
[INFO] 2021-07-12 19:16:56,478 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:56,478 [run_pretraining.py:  534]:	loss/total_loss, 7.6540069580078125, 2241
[INFO] 2021-07-12 19:16:56,478 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6540069580078125, 2241
[INFO] 2021-07-12 19:16:56,478 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2399999579647556e-05, 2241
[INFO] 2021-07-12 19:16:56,478 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2241
[INFO] 2021-07-12 19:16:56,479 [run_pretraining.py:  558]:	worker_index: 2, step: 2241, cost: 7.654007, mlm loss: 7.654007, speed: 1.104386 steps/s, speed: 8.835092 samples/s, speed: 4523.566879 tokens/s, learning rate: 2.240e-05, loss_scalings: 2814.750488, pp_loss: 7.469480
[INFO] 2021-07-12 19:16:56,479 [run_pretraining.py:  512]:	********exe.run_2241******* 
[INFO] 2021-07-12 19:16:57,382 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:57,383 [run_pretraining.py:  534]:	loss/total_loss, 7.816723823547363, 2242
[INFO] 2021-07-12 19:16:57,383 [run_pretraining.py:  535]:	loss/mlm_loss, 7.816723823547363, 2242
[INFO] 2021-07-12 19:16:57,383 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2409998564398848e-05, 2242
[INFO] 2021-07-12 19:16:57,383 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2242
[INFO] 2021-07-12 19:16:57,383 [run_pretraining.py:  558]:	worker_index: 2, step: 2242, cost: 7.816724, mlm loss: 7.816724, speed: 1.106517 steps/s, speed: 8.852135 samples/s, speed: 4532.292881 tokens/s, learning rate: 2.241e-05, loss_scalings: 2814.750488, pp_loss: 7.450754
[INFO] 2021-07-12 19:16:57,383 [run_pretraining.py:  512]:	********exe.run_2242******* 
[INFO] 2021-07-12 19:16:58,295 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:58,296 [run_pretraining.py:  534]:	loss/total_loss, 7.788765907287598, 2243
[INFO] 2021-07-12 19:16:58,296 [run_pretraining.py:  535]:	loss/mlm_loss, 7.788765907287598, 2243
[INFO] 2021-07-12 19:16:58,296 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2419999368139543e-05, 2243
[INFO] 2021-07-12 19:16:58,296 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2243
[INFO] 2021-07-12 19:16:58,296 [run_pretraining.py:  558]:	worker_index: 2, step: 2243, cost: 7.788766, mlm loss: 7.788766, speed: 1.095518 steps/s, speed: 8.764143 samples/s, speed: 4487.241089 tokens/s, learning rate: 2.242e-05, loss_scalings: 2814.750488, pp_loss: 7.060149
[INFO] 2021-07-12 19:16:58,296 [run_pretraining.py:  512]:	********exe.run_2243******* 
[INFO] 2021-07-12 19:16:59,211 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:59,211 [run_pretraining.py:  534]:	loss/total_loss, 7.466186046600342, 2244
[INFO] 2021-07-12 19:16:59,211 [run_pretraining.py:  535]:	loss/mlm_loss, 7.466186046600342, 2244
[INFO] 2021-07-12 19:16:59,211 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2429998352890834e-05, 2244
[INFO] 2021-07-12 19:16:59,212 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2244
[INFO] 2021-07-12 19:16:59,212 [run_pretraining.py:  558]:	worker_index: 2, step: 2244, cost: 7.466186, mlm loss: 7.466186, speed: 1.093209 steps/s, speed: 8.745672 samples/s, speed: 4477.784023 tokens/s, learning rate: 2.243e-05, loss_scalings: 2814.750488, pp_loss: 7.400660
[INFO] 2021-07-12 19:16:59,212 [run_pretraining.py:  512]:	********exe.run_2244******* 
[INFO] 2021-07-12 19:17:00,107 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:00,108 [run_pretraining.py:  534]:	loss/total_loss, 7.757266044616699, 2245
[INFO] 2021-07-12 19:17:00,108 [run_pretraining.py:  535]:	loss/mlm_loss, 7.757266044616699, 2245
[INFO] 2021-07-12 19:17:00,108 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.243999915663153e-05, 2245
[INFO] 2021-07-12 19:17:00,108 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2245
[INFO] 2021-07-12 19:17:00,108 [run_pretraining.py:  558]:	worker_index: 2, step: 2245, cost: 7.757266, mlm loss: 7.757266, speed: 1.116491 steps/s, speed: 8.931926 samples/s, speed: 4573.146054 tokens/s, learning rate: 2.244e-05, loss_scalings: 2814.750488, pp_loss: 7.233334
[INFO] 2021-07-12 19:17:00,108 [run_pretraining.py:  512]:	********exe.run_2245******* 
[INFO] 2021-07-12 19:17:01,004 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:01,004 [run_pretraining.py:  534]:	loss/total_loss, 6.522145748138428, 2246
[INFO] 2021-07-12 19:17:01,004 [run_pretraining.py:  535]:	loss/mlm_loss, 6.522145748138428, 2246
[INFO] 2021-07-12 19:17:01,004 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2449999960372224e-05, 2246
[INFO] 2021-07-12 19:17:01,004 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2246
[INFO] 2021-07-12 19:17:01,004 [run_pretraining.py:  558]:	worker_index: 2, step: 2246, cost: 6.522146, mlm loss: 6.522146, speed: 1.116226 steps/s, speed: 8.929808 samples/s, speed: 4572.061665 tokens/s, learning rate: 2.245e-05, loss_scalings: 2814.750488, pp_loss: 6.905978
[INFO] 2021-07-12 19:17:01,004 [run_pretraining.py:  512]:	********exe.run_2246******* 
[INFO] 2021-07-12 19:17:01,913 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:01,913 [run_pretraining.py:  534]:	loss/total_loss, 7.33834171295166, 2247
[INFO] 2021-07-12 19:17:01,913 [run_pretraining.py:  535]:	loss/mlm_loss, 7.33834171295166, 2247
[INFO] 2021-07-12 19:17:01,914 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2459998945123516e-05, 2247
[INFO] 2021-07-12 19:17:01,914 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2247
[INFO] 2021-07-12 19:17:01,914 [run_pretraining.py:  558]:	worker_index: 2, step: 2247, cost: 7.338342, mlm loss: 7.338342, speed: 1.100409 steps/s, speed: 8.803268 samples/s, speed: 4507.273395 tokens/s, learning rate: 2.246e-05, loss_scalings: 2814.750488, pp_loss: 7.477463
[INFO] 2021-07-12 19:17:01,914 [run_pretraining.py:  512]:	********exe.run_2247******* 
[INFO] 2021-07-12 19:17:02,823 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:02,824 [run_pretraining.py:  534]:	loss/total_loss, 7.654463768005371, 2248
[INFO] 2021-07-12 19:17:02,824 [run_pretraining.py:  535]:	loss/mlm_loss, 7.654463768005371, 2248
[INFO] 2021-07-12 19:17:02,824 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.246999974886421e-05, 2248
[INFO] 2021-07-12 19:17:02,824 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2248
[INFO] 2021-07-12 19:17:02,824 [run_pretraining.py:  558]:	worker_index: 2, step: 2248, cost: 7.654464, mlm loss: 7.654464, speed: 1.099204 steps/s, speed: 8.793634 samples/s, speed: 4502.340602 tokens/s, learning rate: 2.247e-05, loss_scalings: 2814.750488, pp_loss: 6.725138
[INFO] 2021-07-12 19:17:02,824 [run_pretraining.py:  512]:	********exe.run_2248******* 
[INFO] 2021-07-12 19:17:03,733 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:03,733 [run_pretraining.py:  534]:	loss/total_loss, 7.250129699707031, 2249
[INFO] 2021-07-12 19:17:03,733 [run_pretraining.py:  535]:	loss/mlm_loss, 7.250129699707031, 2249
[INFO] 2021-07-12 19:17:03,733 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2480000552604906e-05, 2249
[INFO] 2021-07-12 19:17:03,734 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2249
[INFO] 2021-07-12 19:17:03,734 [run_pretraining.py:  558]:	worker_index: 2, step: 2249, cost: 7.250130, mlm loss: 7.250130, speed: 1.100155 steps/s, speed: 8.801241 samples/s, speed: 4506.235383 tokens/s, learning rate: 2.248e-05, loss_scalings: 2814.750488, pp_loss: 7.340120
[INFO] 2021-07-12 19:17:03,734 [run_pretraining.py:  512]:	********exe.run_2249******* 
[INFO] 2021-07-12 19:17:04,642 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:04,643 [run_pretraining.py:  534]:	loss/total_loss, 6.948911190032959, 2250
[INFO] 2021-07-12 19:17:04,643 [run_pretraining.py:  535]:	loss/mlm_loss, 6.948911190032959, 2250
[INFO] 2021-07-12 19:17:04,643 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2489999537356198e-05, 2250
[INFO] 2021-07-12 19:17:04,643 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2250
[INFO] 2021-07-12 19:17:04,643 [run_pretraining.py:  558]:	worker_index: 2, step: 2250, cost: 6.948911, mlm loss: 6.948911, speed: 1.100505 steps/s, speed: 8.804040 samples/s, speed: 4507.668391 tokens/s, learning rate: 2.249e-05, loss_scalings: 2814.750488, pp_loss: 7.413495
[INFO] 2021-07-12 19:17:04,643 [run_pretraining.py:  512]:	********exe.run_2250******* 
[INFO] 2021-07-12 19:17:05,558 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:05,558 [run_pretraining.py:  534]:	loss/total_loss, 7.1850152015686035, 2251
[INFO] 2021-07-12 19:17:05,558 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1850152015686035, 2251
[INFO] 2021-07-12 19:17:05,558 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.249999852210749e-05, 2251
[INFO] 2021-07-12 19:17:05,559 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2251
[INFO] 2021-07-12 19:17:05,559 [run_pretraining.py:  558]:	worker_index: 2, step: 2251, cost: 7.185015, mlm loss: 7.185015, speed: 1.092759 steps/s, speed: 8.742070 samples/s, speed: 4475.939605 tokens/s, learning rate: 2.250e-05, loss_scalings: 2814.750488, pp_loss: 7.105165
[INFO] 2021-07-12 19:17:05,559 [run_pretraining.py:  512]:	********exe.run_2251******* 
[INFO] 2021-07-12 19:17:06,456 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:06,456 [run_pretraining.py:  534]:	loss/total_loss, 7.212608814239502, 2252
[INFO] 2021-07-12 19:17:06,456 [run_pretraining.py:  535]:	loss/mlm_loss, 7.212608814239502, 2252
[INFO] 2021-07-12 19:17:06,456 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2509999325848185e-05, 2252
[INFO] 2021-07-12 19:17:06,456 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2252
[INFO] 2021-07-12 19:17:06,456 [run_pretraining.py:  558]:	worker_index: 2, step: 2252, cost: 7.212609, mlm loss: 7.212609, speed: 1.114636 steps/s, speed: 8.917086 samples/s, speed: 4565.547917 tokens/s, learning rate: 2.251e-05, loss_scalings: 2814.750488, pp_loss: 6.949659
[INFO] 2021-07-12 19:17:06,456 [run_pretraining.py:  512]:	********exe.run_2252******* 
[INFO] 2021-07-12 19:17:07,364 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:07,364 [run_pretraining.py:  534]:	loss/total_loss, 7.652471542358398, 2253
[INFO] 2021-07-12 19:17:07,364 [run_pretraining.py:  535]:	loss/mlm_loss, 7.652471542358398, 2253
[INFO] 2021-07-12 19:17:07,364 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2519998310599476e-05, 2253
[INFO] 2021-07-12 19:17:07,364 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2253
[INFO] 2021-07-12 19:17:07,364 [run_pretraining.py:  558]:	worker_index: 2, step: 2253, cost: 7.652472, mlm loss: 7.652472, speed: 1.101900 steps/s, speed: 8.815202 samples/s, speed: 4513.383462 tokens/s, learning rate: 2.252e-05, loss_scalings: 2814.750488, pp_loss: 7.548403
[INFO] 2021-07-12 19:17:07,365 [run_pretraining.py:  512]:	********exe.run_2253******* 
[INFO] 2021-07-12 19:17:08,277 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:08,277 [run_pretraining.py:  534]:	loss/total_loss, 7.475525856018066, 2254
[INFO] 2021-07-12 19:17:08,277 [run_pretraining.py:  535]:	loss/mlm_loss, 7.475525856018066, 2254
[INFO] 2021-07-12 19:17:08,277 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.252999911434017e-05, 2254
[INFO] 2021-07-12 19:17:08,277 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2254
[INFO] 2021-07-12 19:17:08,277 [run_pretraining.py:  558]:	worker_index: 2, step: 2254, cost: 7.475526, mlm loss: 7.475526, speed: 1.096099 steps/s, speed: 8.768792 samples/s, speed: 4489.621574 tokens/s, learning rate: 2.253e-05, loss_scalings: 2814.750488, pp_loss: 6.905887
[INFO] 2021-07-12 19:17:08,277 [run_pretraining.py:  512]:	********exe.run_2254******* 
[INFO] 2021-07-12 19:17:09,228 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:09,228 [run_pretraining.py:  534]:	loss/total_loss, 7.018454074859619, 2255
[INFO] 2021-07-12 19:17:09,229 [run_pretraining.py:  535]:	loss/mlm_loss, 7.018454074859619, 2255
[INFO] 2021-07-12 19:17:09,229 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2539999918080866e-05, 2255
[INFO] 2021-07-12 19:17:09,229 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2255
[INFO] 2021-07-12 19:17:09,229 [run_pretraining.py:  558]:	worker_index: 2, step: 2255, cost: 7.018454, mlm loss: 7.018454, speed: 1.051750 steps/s, speed: 8.414001 samples/s, speed: 4307.968746 tokens/s, learning rate: 2.254e-05, loss_scalings: 2814.750488, pp_loss: 7.403881
[INFO] 2021-07-12 19:17:09,229 [run_pretraining.py:  512]:	********exe.run_2255******* 
[INFO] 2021-07-12 19:17:10,168 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:10,168 [run_pretraining.py:  534]:	loss/total_loss, 7.409750938415527, 2256
[INFO] 2021-07-12 19:17:10,168 [run_pretraining.py:  535]:	loss/mlm_loss, 7.409750938415527, 2256
[INFO] 2021-07-12 19:17:10,168 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2549998902832158e-05, 2256
[INFO] 2021-07-12 19:17:10,168 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2256
[INFO] 2021-07-12 19:17:10,168 [run_pretraining.py:  558]:	worker_index: 2, step: 2256, cost: 7.409751, mlm loss: 7.409751, speed: 1.064978 steps/s, speed: 8.519822 samples/s, speed: 4362.148749 tokens/s, learning rate: 2.255e-05, loss_scalings: 2814.750488, pp_loss: 7.244120
[INFO] 2021-07-12 19:17:10,168 [run_pretraining.py:  512]:	********exe.run_2256******* 
[INFO] 2021-07-12 19:17:11,086 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:11,086 [run_pretraining.py:  534]:	loss/total_loss, 7.433781623840332, 2257
[INFO] 2021-07-12 19:17:11,086 [run_pretraining.py:  535]:	loss/mlm_loss, 7.433781623840332, 2257
[INFO] 2021-07-12 19:17:11,086 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2559999706572853e-05, 2257
[INFO] 2021-07-12 19:17:11,086 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2257
[INFO] 2021-07-12 19:17:11,087 [run_pretraining.py:  558]:	worker_index: 2, step: 2257, cost: 7.433782, mlm loss: 7.433782, speed: 1.089864 steps/s, speed: 8.718911 samples/s, speed: 4464.082360 tokens/s, learning rate: 2.256e-05, loss_scalings: 2814.750488, pp_loss: 7.381609
[INFO] 2021-07-12 19:17:11,087 [run_pretraining.py:  512]:	********exe.run_2257******* 
[INFO] 2021-07-12 19:17:11,994 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:11,994 [run_pretraining.py:  534]:	loss/total_loss, 7.3769450187683105, 2258
[INFO] 2021-07-12 19:17:11,995 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3769450187683105, 2258
[INFO] 2021-07-12 19:17:11,995 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2570000510313548e-05, 2258
[INFO] 2021-07-12 19:17:11,995 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2258
[INFO] 2021-07-12 19:17:11,995 [run_pretraining.py:  558]:	worker_index: 2, step: 2258, cost: 7.376945, mlm loss: 7.376945, speed: 1.101710 steps/s, speed: 8.813678 samples/s, speed: 4512.603389 tokens/s, learning rate: 2.257e-05, loss_scalings: 2814.750488, pp_loss: 7.128198
[INFO] 2021-07-12 19:17:11,995 [run_pretraining.py:  512]:	********exe.run_2258******* 
[INFO] 2021-07-12 19:17:12,910 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:12,911 [run_pretraining.py:  534]:	loss/total_loss, 7.60268497467041, 2259
[INFO] 2021-07-12 19:17:12,911 [run_pretraining.py:  535]:	loss/mlm_loss, 7.60268497467041, 2259
[INFO] 2021-07-12 19:17:12,911 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.257999949506484e-05, 2259
[INFO] 2021-07-12 19:17:12,911 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2259
[INFO] 2021-07-12 19:17:12,911 [run_pretraining.py:  558]:	worker_index: 2, step: 2259, cost: 7.602685, mlm loss: 7.602685, speed: 1.092198 steps/s, speed: 8.737587 samples/s, speed: 4473.644664 tokens/s, learning rate: 2.258e-05, loss_scalings: 2814.750488, pp_loss: 7.515466
[INFO] 2021-07-12 19:17:12,911 [run_pretraining.py:  512]:	********exe.run_2259******* 
[INFO] 2021-07-12 19:17:13,821 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:13,822 [run_pretraining.py:  534]:	loss/total_loss, 7.417640209197998, 2260
[INFO] 2021-07-12 19:17:13,822 [run_pretraining.py:  535]:	loss/mlm_loss, 7.417640209197998, 2260
[INFO] 2021-07-12 19:17:13,822 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.258999847981613e-05, 2260
[INFO] 2021-07-12 19:17:13,822 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2260
[INFO] 2021-07-12 19:17:13,822 [run_pretraining.py:  558]:	worker_index: 2, step: 2260, cost: 7.417640, mlm loss: 7.417640, speed: 1.098600 steps/s, speed: 8.788804 samples/s, speed: 4499.867644 tokens/s, learning rate: 2.259e-05, loss_scalings: 2814.750488, pp_loss: 7.248640
[INFO] 2021-07-12 19:17:13,822 [run_pretraining.py:  512]:	********exe.run_2260******* 
[INFO] 2021-07-12 19:17:14,732 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:14,732 [run_pretraining.py:  534]:	loss/total_loss, 6.84914493560791, 2261
[INFO] 2021-07-12 19:17:14,732 [run_pretraining.py:  535]:	loss/mlm_loss, 6.84914493560791, 2261
[INFO] 2021-07-12 19:17:14,732 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2599999283556826e-05, 2261
[INFO] 2021-07-12 19:17:14,732 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2261
[INFO] 2021-07-12 19:17:14,733 [run_pretraining.py:  558]:	worker_index: 2, step: 2261, cost: 6.849145, mlm loss: 6.849145, speed: 1.098873 steps/s, speed: 8.790987 samples/s, speed: 4500.985268 tokens/s, learning rate: 2.260e-05, loss_scalings: 2814.750488, pp_loss: 7.354632
[INFO] 2021-07-12 19:17:14,733 [run_pretraining.py:  512]:	********exe.run_2261******* 
[INFO] 2021-07-12 19:17:15,639 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:15,640 [run_pretraining.py:  534]:	loss/total_loss, 7.002292633056641, 2262
[INFO] 2021-07-12 19:17:15,640 [run_pretraining.py:  535]:	loss/mlm_loss, 7.002292633056641, 2262
[INFO] 2021-07-12 19:17:15,640 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.261000008729752e-05, 2262
[INFO] 2021-07-12 19:17:15,640 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2262
[INFO] 2021-07-12 19:17:15,640 [run_pretraining.py:  558]:	worker_index: 2, step: 2262, cost: 7.002293, mlm loss: 7.002293, speed: 1.102773 steps/s, speed: 8.822181 samples/s, speed: 4516.956511 tokens/s, learning rate: 2.261e-05, loss_scalings: 2814.750488, pp_loss: 7.094224
[INFO] 2021-07-12 19:17:15,640 [run_pretraining.py:  512]:	********exe.run_2262******* 
[INFO] 2021-07-12 19:17:16,553 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:16,553 [run_pretraining.py:  534]:	loss/total_loss, 7.210153579711914, 2263
[INFO] 2021-07-12 19:17:16,553 [run_pretraining.py:  535]:	loss/mlm_loss, 7.210153579711914, 2263
[INFO] 2021-07-12 19:17:16,553 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2619999072048813e-05, 2263
[INFO] 2021-07-12 19:17:16,553 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2263
[INFO] 2021-07-12 19:17:16,553 [run_pretraining.py:  558]:	worker_index: 2, step: 2263, cost: 7.210154, mlm loss: 7.210154, speed: 1.095450 steps/s, speed: 8.763598 samples/s, speed: 4486.962163 tokens/s, learning rate: 2.262e-05, loss_scalings: 2814.750488, pp_loss: 7.262295
[INFO] 2021-07-12 19:17:16,553 [run_pretraining.py:  512]:	********exe.run_2263******* 
[INFO] 2021-07-12 19:17:17,468 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:17,468 [run_pretraining.py:  534]:	loss/total_loss, 7.280538558959961, 2264
[INFO] 2021-07-12 19:17:17,468 [run_pretraining.py:  535]:	loss/mlm_loss, 7.280538558959961, 2264
[INFO] 2021-07-12 19:17:17,469 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2629999875789508e-05, 2264
[INFO] 2021-07-12 19:17:17,469 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2264
[INFO] 2021-07-12 19:17:17,469 [run_pretraining.py:  558]:	worker_index: 2, step: 2264, cost: 7.280539, mlm loss: 7.280539, speed: 1.093283 steps/s, speed: 8.746265 samples/s, speed: 4478.087489 tokens/s, learning rate: 2.263e-05, loss_scalings: 2814.750488, pp_loss: 7.183211
[INFO] 2021-07-12 19:17:17,469 [run_pretraining.py:  512]:	********exe.run_2264******* 
[INFO] 2021-07-12 19:17:18,397 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:18,398 [run_pretraining.py:  534]:	loss/total_loss, 7.223074913024902, 2265
[INFO] 2021-07-12 19:17:18,398 [run_pretraining.py:  535]:	loss/mlm_loss, 7.223074913024902, 2265
[INFO] 2021-07-12 19:17:18,398 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.26399988605408e-05, 2265
[INFO] 2021-07-12 19:17:18,398 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2265
[INFO] 2021-07-12 19:17:18,398 [run_pretraining.py:  558]:	worker_index: 2, step: 2265, cost: 7.223075, mlm loss: 7.223075, speed: 1.076429 steps/s, speed: 8.611435 samples/s, speed: 4409.054898 tokens/s, learning rate: 2.264e-05, loss_scalings: 2814.750488, pp_loss: 6.968707
[INFO] 2021-07-12 19:17:18,398 [run_pretraining.py:  512]:	********exe.run_2265******* 
[INFO] 2021-07-12 19:17:19,312 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:19,313 [run_pretraining.py:  534]:	loss/total_loss, 7.9611992835998535, 2266
[INFO] 2021-07-12 19:17:19,313 [run_pretraining.py:  535]:	loss/mlm_loss, 7.9611992835998535, 2266
[INFO] 2021-07-12 19:17:19,313 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2649999664281495e-05, 2266
[INFO] 2021-07-12 19:17:19,313 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2266
[INFO] 2021-07-12 19:17:19,313 [run_pretraining.py:  558]:	worker_index: 2, step: 2266, cost: 7.961199, mlm loss: 7.961199, speed: 1.093965 steps/s, speed: 8.751721 samples/s, speed: 4480.881302 tokens/s, learning rate: 2.265e-05, loss_scalings: 2814.750488, pp_loss: 7.646825
[INFO] 2021-07-12 19:17:19,313 [run_pretraining.py:  512]:	********exe.run_2266******* 
[INFO] 2021-07-12 19:17:20,230 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:20,230 [run_pretraining.py:  534]:	loss/total_loss, 6.98000431060791, 2267
[INFO] 2021-07-12 19:17:20,230 [run_pretraining.py:  535]:	loss/mlm_loss, 6.98000431060791, 2267
[INFO] 2021-07-12 19:17:20,230 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.266000046802219e-05, 2267
[INFO] 2021-07-12 19:17:20,230 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2267
[INFO] 2021-07-12 19:17:20,230 [run_pretraining.py:  558]:	worker_index: 2, step: 2267, cost: 6.980004, mlm loss: 6.980004, speed: 1.090767 steps/s, speed: 8.726137 samples/s, speed: 4467.782230 tokens/s, learning rate: 2.266e-05, loss_scalings: 2814.750488, pp_loss: 7.442266
[INFO] 2021-07-12 19:17:20,230 [run_pretraining.py:  512]:	********exe.run_2267******* 
[INFO] 2021-07-12 19:17:21,135 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:21,136 [run_pretraining.py:  534]:	loss/total_loss, 7.169471740722656, 2268
[INFO] 2021-07-12 19:17:21,136 [run_pretraining.py:  535]:	loss/mlm_loss, 7.169471740722656, 2268
[INFO] 2021-07-12 19:17:21,136 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.266999945277348e-05, 2268
[INFO] 2021-07-12 19:17:21,136 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2268
[INFO] 2021-07-12 19:17:21,136 [run_pretraining.py:  558]:	worker_index: 2, step: 2268, cost: 7.169472, mlm loss: 7.169472, speed: 1.104972 steps/s, speed: 8.839779 samples/s, speed: 4525.966994 tokens/s, learning rate: 2.267e-05, loss_scalings: 2814.750488, pp_loss: 7.229350
[INFO] 2021-07-12 19:17:21,136 [run_pretraining.py:  512]:	********exe.run_2268******* 
[INFO] 2021-07-12 19:17:22,050 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:22,051 [run_pretraining.py:  534]:	loss/total_loss, 7.351015567779541, 2269
[INFO] 2021-07-12 19:17:22,051 [run_pretraining.py:  535]:	loss/mlm_loss, 7.351015567779541, 2269
[INFO] 2021-07-12 19:17:22,051 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2679998437524773e-05, 2269
[INFO] 2021-07-12 19:17:22,051 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2269
[INFO] 2021-07-12 19:17:22,051 [run_pretraining.py:  558]:	worker_index: 2, step: 2269, cost: 7.351016, mlm loss: 7.351016, speed: 1.093701 steps/s, speed: 8.749610 samples/s, speed: 4479.800505 tokens/s, learning rate: 2.268e-05, loss_scalings: 2814.750488, pp_loss: 7.263329
[INFO] 2021-07-12 19:17:22,051 [run_pretraining.py:  512]:	********exe.run_2269******* 
[INFO] 2021-07-12 19:17:22,965 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:22,966 [run_pretraining.py:  534]:	loss/total_loss, 6.982945442199707, 2270
[INFO] 2021-07-12 19:17:22,966 [run_pretraining.py:  535]:	loss/mlm_loss, 6.982945442199707, 2270
[INFO] 2021-07-12 19:17:22,966 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2689999241265468e-05, 2270
[INFO] 2021-07-12 19:17:22,966 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2270
[INFO] 2021-07-12 19:17:22,966 [run_pretraining.py:  558]:	worker_index: 2, step: 2270, cost: 6.982945, mlm loss: 6.982945, speed: 1.093216 steps/s, speed: 8.745724 samples/s, speed: 4477.810867 tokens/s, learning rate: 2.269e-05, loss_scalings: 2814.750488, pp_loss: 7.057521
[INFO] 2021-07-12 19:17:22,966 [run_pretraining.py:  512]:	********exe.run_2270******* 
[INFO] 2021-07-12 19:17:23,902 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:23,903 [run_pretraining.py:  534]:	loss/total_loss, 8.249558448791504, 2271
[INFO] 2021-07-12 19:17:23,903 [run_pretraining.py:  535]:	loss/mlm_loss, 8.249558448791504, 2271
[INFO] 2021-07-12 19:17:23,903 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2700000045006163e-05, 2271
[INFO] 2021-07-12 19:17:23,903 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2271
[INFO] 2021-07-12 19:17:23,903 [run_pretraining.py:  558]:	worker_index: 2, step: 2271, cost: 8.249558, mlm loss: 8.249558, speed: 1.067844 steps/s, speed: 8.542753 samples/s, speed: 4373.889763 tokens/s, learning rate: 2.270e-05, loss_scalings: 2814.750488, pp_loss: 7.551206
[INFO] 2021-07-12 19:17:23,903 [run_pretraining.py:  512]:	********exe.run_2271******* 
[INFO] 2021-07-12 19:17:24,816 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:24,817 [run_pretraining.py:  534]:	loss/total_loss, 7.352060317993164, 2272
[INFO] 2021-07-12 19:17:24,817 [run_pretraining.py:  535]:	loss/mlm_loss, 7.352060317993164, 2272
[INFO] 2021-07-12 19:17:24,817 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2709999029757455e-05, 2272
[INFO] 2021-07-12 19:17:24,817 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2272
[INFO] 2021-07-12 19:17:24,817 [run_pretraining.py:  558]:	worker_index: 2, step: 2272, cost: 7.352060, mlm loss: 7.352060, speed: 1.095230 steps/s, speed: 8.761841 samples/s, speed: 4486.062336 tokens/s, learning rate: 2.271e-05, loss_scalings: 2814.750488, pp_loss: 7.414016
[INFO] 2021-07-12 19:17:24,817 [run_pretraining.py:  512]:	********exe.run_2272******* 
[INFO] 2021-07-12 19:17:25,725 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:25,725 [run_pretraining.py:  534]:	loss/total_loss, 7.4121222496032715, 2273
[INFO] 2021-07-12 19:17:25,726 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4121222496032715, 2273
[INFO] 2021-07-12 19:17:25,726 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.271999983349815e-05, 2273
[INFO] 2021-07-12 19:17:25,726 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2273
[INFO] 2021-07-12 19:17:25,726 [run_pretraining.py:  558]:	worker_index: 2, step: 2273, cost: 7.412122, mlm loss: 7.412122, speed: 1.101058 steps/s, speed: 8.808466 samples/s, speed: 4509.934449 tokens/s, learning rate: 2.272e-05, loss_scalings: 2814.750488, pp_loss: 7.142021
[INFO] 2021-07-12 19:17:25,726 [run_pretraining.py:  512]:	********exe.run_2273******* 
[INFO] 2021-07-12 19:17:26,642 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:26,643 [run_pretraining.py:  534]:	loss/total_loss, 7.454174041748047, 2274
[INFO] 2021-07-12 19:17:26,643 [run_pretraining.py:  535]:	loss/mlm_loss, 7.454174041748047, 2274
[INFO] 2021-07-12 19:17:26,643 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2730000637238845e-05, 2274
[INFO] 2021-07-12 19:17:26,643 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2274
[INFO] 2021-07-12 19:17:26,643 [run_pretraining.py:  558]:	worker_index: 2, step: 2274, cost: 7.454174, mlm loss: 7.454174, speed: 1.090836 steps/s, speed: 8.726686 samples/s, speed: 4468.063424 tokens/s, learning rate: 2.273e-05, loss_scalings: 2814.750488, pp_loss: 7.473970
[INFO] 2021-07-12 19:17:26,643 [run_pretraining.py:  512]:	********exe.run_2274******* 
[INFO] 2021-07-12 19:17:52,510 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:52,510 [run_pretraining.py:  534]:	loss/total_loss, 4.927114963531494, 2275
[INFO] 2021-07-12 19:17:52,510 [run_pretraining.py:  535]:	loss/mlm_loss, 4.927114963531494, 2275
[INFO] 2021-07-12 19:17:52,510 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2739999621990137e-05, 2275
[INFO] 2021-07-12 19:17:52,510 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2275
[INFO] 2021-07-12 19:17:52,510 [run_pretraining.py:  558]:	worker_index: 2, step: 2275, cost: 4.927115, mlm loss: 4.927115, speed: 0.038660 steps/s, speed: 0.309279 samples/s, speed: 158.350726 tokens/s, learning rate: 2.274e-05, loss_scalings: 2814.750488, pp_loss: 6.929406
[INFO] 2021-07-12 19:17:52,510 [run_pretraining.py:  512]:	********exe.run_2275******* 
[INFO] 2021-07-12 19:17:53,423 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:53,423 [run_pretraining.py:  534]:	loss/total_loss, 7.088575839996338, 2276
[INFO] 2021-07-12 19:17:53,423 [run_pretraining.py:  535]:	loss/mlm_loss, 7.088575839996338, 2276
[INFO] 2021-07-12 19:17:53,423 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2750000425730832e-05, 2276
[INFO] 2021-07-12 19:17:53,424 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2276
[INFO] 2021-07-12 19:17:53,424 [run_pretraining.py:  558]:	worker_index: 2, step: 2276, cost: 7.088576, mlm loss: 7.088576, speed: 1.095628 steps/s, speed: 8.765022 samples/s, speed: 4487.691194 tokens/s, learning rate: 2.275e-05, loss_scalings: 2814.750488, pp_loss: 7.073719
[INFO] 2021-07-12 19:17:53,424 [run_pretraining.py:  512]:	********exe.run_2276******* 
[INFO] 2021-07-12 19:17:54,341 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:54,342 [run_pretraining.py:  534]:	loss/total_loss, 7.267551898956299, 2277
[INFO] 2021-07-12 19:17:54,345 [run_pretraining.py:  535]:	loss/mlm_loss, 7.267551898956299, 2277
[INFO] 2021-07-12 19:17:54,346 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2759999410482123e-05, 2277
[INFO] 2021-07-12 19:17:54,347 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2277
[INFO] 2021-07-12 19:17:54,349 [run_pretraining.py:  558]:	worker_index: 2, step: 2277, cost: 7.267552, mlm loss: 7.267552, speed: 1.088587 steps/s, speed: 8.708694 samples/s, speed: 4458.851259 tokens/s, learning rate: 2.276e-05, loss_scalings: 2814.750488, pp_loss: 6.360677
[INFO] 2021-07-12 19:17:54,349 [run_pretraining.py:  512]:	********exe.run_2277******* 
[INFO] 2021-07-12 19:17:55,246 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:55,247 [run_pretraining.py:  534]:	loss/total_loss, 6.647421836853027, 2278
[INFO] 2021-07-12 19:17:55,247 [run_pretraining.py:  535]:	loss/mlm_loss, 6.647421836853027, 2278
[INFO] 2021-07-12 19:17:55,247 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2769998395233415e-05, 2278
[INFO] 2021-07-12 19:17:55,247 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2278
[INFO] 2021-07-12 19:17:55,247 [run_pretraining.py:  558]:	worker_index: 2, step: 2278, cost: 6.647422, mlm loss: 6.647422, speed: 1.114603 steps/s, speed: 8.916823 samples/s, speed: 4565.413246 tokens/s, learning rate: 2.277e-05, loss_scalings: 2814.750488, pp_loss: 7.283994
[INFO] 2021-07-12 19:17:55,247 [run_pretraining.py:  512]:	********exe.run_2278******* 
[INFO] 2021-07-12 19:17:56,155 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:56,156 [run_pretraining.py:  534]:	loss/total_loss, 7.631358623504639, 2279
[INFO] 2021-07-12 19:17:56,156 [run_pretraining.py:  535]:	loss/mlm_loss, 7.631358623504639, 2279
[INFO] 2021-07-12 19:17:56,156 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.277999919897411e-05, 2279
[INFO] 2021-07-12 19:17:56,156 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2279
[INFO] 2021-07-12 19:17:56,156 [run_pretraining.py:  558]:	worker_index: 2, step: 2279, cost: 7.631359, mlm loss: 7.631359, speed: 1.101142 steps/s, speed: 8.809134 samples/s, speed: 4510.276626 tokens/s, learning rate: 2.278e-05, loss_scalings: 2814.750488, pp_loss: 7.143325
[INFO] 2021-07-12 19:17:56,156 [run_pretraining.py:  512]:	********exe.run_2279******* 
[INFO] 2021-07-12 19:17:57,071 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:57,071 [run_pretraining.py:  534]:	loss/total_loss, 6.661724090576172, 2280
[INFO] 2021-07-12 19:17:57,071 [run_pretraining.py:  535]:	loss/mlm_loss, 6.661724090576172, 2280
[INFO] 2021-07-12 19:17:57,072 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2790000002714805e-05, 2280
[INFO] 2021-07-12 19:17:57,072 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2280
[INFO] 2021-07-12 19:17:57,072 [run_pretraining.py:  558]:	worker_index: 2, step: 2280, cost: 6.661724, mlm loss: 6.661724, speed: 1.092746 steps/s, speed: 8.741972 samples/s, speed: 4475.889462 tokens/s, learning rate: 2.279e-05, loss_scalings: 2814.750488, pp_loss: 7.266866
[INFO] 2021-07-12 19:17:57,072 [run_pretraining.py:  512]:	********exe.run_2280******* 
[INFO] 2021-07-12 19:17:57,979 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:57,979 [run_pretraining.py:  534]:	loss/total_loss, 6.901402950286865, 2281
[INFO] 2021-07-12 19:17:57,979 [run_pretraining.py:  535]:	loss/mlm_loss, 6.901402950286865, 2281
[INFO] 2021-07-12 19:17:57,979 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2799998987466097e-05, 2281
[INFO] 2021-07-12 19:17:57,980 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2281
[INFO] 2021-07-12 19:17:57,980 [run_pretraining.py:  558]:	worker_index: 2, step: 2281, cost: 6.901403, mlm loss: 6.901403, speed: 1.102059 steps/s, speed: 8.816469 samples/s, speed: 4514.032148 tokens/s, learning rate: 2.280e-05, loss_scalings: 2814.750488, pp_loss: 7.034728
[INFO] 2021-07-12 19:17:57,980 [run_pretraining.py:  512]:	********exe.run_2281******* 
[INFO] 2021-07-12 19:17:58,917 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:58,918 [run_pretraining.py:  534]:	loss/total_loss, 7.495420455932617, 2282
[INFO] 2021-07-12 19:17:58,918 [run_pretraining.py:  535]:	loss/mlm_loss, 7.495420455932617, 2282
[INFO] 2021-07-12 19:17:58,918 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2809999791206792e-05, 2282
[INFO] 2021-07-12 19:17:58,918 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2282
[INFO] 2021-07-12 19:17:58,918 [run_pretraining.py:  558]:	worker_index: 2, step: 2282, cost: 7.495420, mlm loss: 7.495420, speed: 1.066157 steps/s, speed: 8.529258 samples/s, speed: 4366.979886 tokens/s, learning rate: 2.281e-05, loss_scalings: 2814.750488, pp_loss: 7.084215
[INFO] 2021-07-12 19:17:58,918 [run_pretraining.py:  512]:	********exe.run_2282******* 
[INFO] 2021-07-12 19:17:59,831 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:59,832 [run_pretraining.py:  534]:	loss/total_loss, 7.9647626876831055, 2283
[INFO] 2021-07-12 19:17:59,832 [run_pretraining.py:  535]:	loss/mlm_loss, 7.9647626876831055, 2283
[INFO] 2021-07-12 19:17:59,832 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2820000594947487e-05, 2283
[INFO] 2021-07-12 19:17:59,832 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2283
[INFO] 2021-07-12 19:17:59,832 [run_pretraining.py:  558]:	worker_index: 2, step: 2283, cost: 7.964763, mlm loss: 7.964763, speed: 1.094869 steps/s, speed: 8.758952 samples/s, speed: 4484.583327 tokens/s, learning rate: 2.282e-05, loss_scalings: 2814.750488, pp_loss: 7.290884
[INFO] 2021-07-12 19:17:59,832 [run_pretraining.py:  512]:	********exe.run_2283******* 
[INFO] 2021-07-12 19:18:00,747 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:00,748 [run_pretraining.py:  534]:	loss/total_loss, 7.567522048950195, 2284
[INFO] 2021-07-12 19:18:00,748 [run_pretraining.py:  535]:	loss/mlm_loss, 7.567522048950195, 2284
[INFO] 2021-07-12 19:18:00,748 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.282999957969878e-05, 2284
[INFO] 2021-07-12 19:18:00,748 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2284
[INFO] 2021-07-12 19:18:00,748 [run_pretraining.py:  558]:	worker_index: 2, step: 2284, cost: 7.567522, mlm loss: 7.567522, speed: 1.092505 steps/s, speed: 8.740041 samples/s, speed: 4474.900821 tokens/s, learning rate: 2.283e-05, loss_scalings: 2814.750488, pp_loss: 7.205909
[INFO] 2021-07-12 19:18:00,748 [run_pretraining.py:  512]:	********exe.run_2284******* 
[INFO] 2021-07-12 19:18:01,668 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:01,669 [run_pretraining.py:  534]:	loss/total_loss, 6.923166275024414, 2285
[INFO] 2021-07-12 19:18:01,669 [run_pretraining.py:  535]:	loss/mlm_loss, 6.923166275024414, 2285
[INFO] 2021-07-12 19:18:01,669 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2840000383439474e-05, 2285
[INFO] 2021-07-12 19:18:01,669 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2285
[INFO] 2021-07-12 19:18:01,669 [run_pretraining.py:  558]:	worker_index: 2, step: 2285, cost: 6.923166, mlm loss: 6.923166, speed: 1.086578 steps/s, speed: 8.692622 samples/s, speed: 4450.622246 tokens/s, learning rate: 2.284e-05, loss_scalings: 2814.750488, pp_loss: 7.111734
[INFO] 2021-07-12 19:18:01,669 [run_pretraining.py:  512]:	********exe.run_2285******* 
[INFO] 2021-07-12 19:18:02,580 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:02,580 [run_pretraining.py:  534]:	loss/total_loss, 7.424164295196533, 2286
[INFO] 2021-07-12 19:18:02,580 [run_pretraining.py:  535]:	loss/mlm_loss, 7.424164295196533, 2286
[INFO] 2021-07-12 19:18:02,580 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2849999368190765e-05, 2286
[INFO] 2021-07-12 19:18:02,580 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2286
[INFO] 2021-07-12 19:18:02,580 [run_pretraining.py:  558]:	worker_index: 2, step: 2286, cost: 7.424164, mlm loss: 7.424164, speed: 1.097940 steps/s, speed: 8.783522 samples/s, speed: 4497.163123 tokens/s, learning rate: 2.285e-05, loss_scalings: 2814.750488, pp_loss: 6.811947
[INFO] 2021-07-12 19:18:02,580 [run_pretraining.py:  512]:	********exe.run_2286******* 
[INFO] 2021-07-12 19:18:03,489 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:03,490 [run_pretraining.py:  534]:	loss/total_loss, 7.398893356323242, 2287
[INFO] 2021-07-12 19:18:03,490 [run_pretraining.py:  535]:	loss/mlm_loss, 7.398893356323242, 2287
[INFO] 2021-07-12 19:18:03,490 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2859998352942057e-05, 2287
[INFO] 2021-07-12 19:18:03,490 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2287
[INFO] 2021-07-12 19:18:03,490 [run_pretraining.py:  558]:	worker_index: 2, step: 2287, cost: 7.398893, mlm loss: 7.398893, speed: 1.099895 steps/s, speed: 8.799164 samples/s, speed: 4505.171857 tokens/s, learning rate: 2.286e-05, loss_scalings: 2814.750488, pp_loss: 7.362245
[INFO] 2021-07-12 19:18:03,490 [run_pretraining.py:  512]:	********exe.run_2287******* 
[INFO] 2021-07-12 19:18:04,399 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:04,399 [run_pretraining.py:  534]:	loss/total_loss, 7.268461227416992, 2288
[INFO] 2021-07-12 19:18:04,399 [run_pretraining.py:  535]:	loss/mlm_loss, 7.268461227416992, 2288
[INFO] 2021-07-12 19:18:04,400 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2869999156682752e-05, 2288
[INFO] 2021-07-12 19:18:04,400 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2288
[INFO] 2021-07-12 19:18:04,400 [run_pretraining.py:  558]:	worker_index: 2, step: 2288, cost: 7.268461, mlm loss: 7.268461, speed: 1.100148 steps/s, speed: 8.801181 samples/s, speed: 4506.204651 tokens/s, learning rate: 2.287e-05, loss_scalings: 2814.750488, pp_loss: 7.125575
[INFO] 2021-07-12 19:18:04,400 [run_pretraining.py:  512]:	********exe.run_2288******* 
[INFO] 2021-07-12 19:18:05,315 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:05,315 [run_pretraining.py:  534]:	loss/total_loss, 7.136987686157227, 2289
[INFO] 2021-07-12 19:18:05,315 [run_pretraining.py:  535]:	loss/mlm_loss, 7.136987686157227, 2289
[INFO] 2021-07-12 19:18:05,315 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2879999960423447e-05, 2289
[INFO] 2021-07-12 19:18:05,316 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2289
[INFO] 2021-07-12 19:18:05,316 [run_pretraining.py:  558]:	worker_index: 2, step: 2289, cost: 7.136988, mlm loss: 7.136988, speed: 1.092582 steps/s, speed: 8.740653 samples/s, speed: 4475.214387 tokens/s, learning rate: 2.288e-05, loss_scalings: 2814.750488, pp_loss: 7.181780
[INFO] 2021-07-12 19:18:05,316 [run_pretraining.py:  512]:	********exe.run_2289******* 
[INFO] 2021-07-12 19:18:06,227 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:06,227 [run_pretraining.py:  534]:	loss/total_loss, 7.292673110961914, 2290
[INFO] 2021-07-12 19:18:06,228 [run_pretraining.py:  535]:	loss/mlm_loss, 7.292673110961914, 2290
[INFO] 2021-07-12 19:18:06,228 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.288999894517474e-05, 2290
[INFO] 2021-07-12 19:18:06,228 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2290
[INFO] 2021-07-12 19:18:06,228 [run_pretraining.py:  558]:	worker_index: 2, step: 2290, cost: 7.292673, mlm loss: 7.292673, speed: 1.096970 steps/s, speed: 8.775764 samples/s, speed: 4493.191164 tokens/s, learning rate: 2.289e-05, loss_scalings: 2814.750488, pp_loss: 7.267460
[INFO] 2021-07-12 19:18:06,228 [run_pretraining.py:  512]:	********exe.run_2290******* 
[INFO] 2021-07-12 19:18:07,164 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:07,165 [run_pretraining.py:  534]:	loss/total_loss, 7.401656150817871, 2291
[INFO] 2021-07-12 19:18:07,165 [run_pretraining.py:  535]:	loss/mlm_loss, 7.401656150817871, 2291
[INFO] 2021-07-12 19:18:07,165 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2899999748915434e-05, 2291
[INFO] 2021-07-12 19:18:07,165 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2291
[INFO] 2021-07-12 19:18:07,165 [run_pretraining.py:  558]:	worker_index: 2, step: 2291, cost: 7.401656, mlm loss: 7.401656, speed: 1.067540 steps/s, speed: 8.540318 samples/s, speed: 4372.642925 tokens/s, learning rate: 2.290e-05, loss_scalings: 2814.750488, pp_loss: 7.120898
[INFO] 2021-07-12 19:18:07,165 [run_pretraining.py:  512]:	********exe.run_2291******* 
[INFO] 2021-07-12 19:18:08,082 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:08,083 [run_pretraining.py:  534]:	loss/total_loss, 7.202584266662598, 2292
[INFO] 2021-07-12 19:18:08,083 [run_pretraining.py:  535]:	loss/mlm_loss, 7.202584266662598, 2292
[INFO] 2021-07-12 19:18:08,083 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.291000055265613e-05, 2292
[INFO] 2021-07-12 19:18:08,083 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2292
[INFO] 2021-07-12 19:18:08,083 [run_pretraining.py:  558]:	worker_index: 2, step: 2292, cost: 7.202584, mlm loss: 7.202584, speed: 1.089817 steps/s, speed: 8.718539 samples/s, speed: 4463.892134 tokens/s, learning rate: 2.291e-05, loss_scalings: 2814.750488, pp_loss: 6.610709
[INFO] 2021-07-12 19:18:08,083 [run_pretraining.py:  512]:	********exe.run_2292******* 
[INFO] 2021-07-12 19:18:09,003 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:09,003 [run_pretraining.py:  534]:	loss/total_loss, 6.941924571990967, 2293
[INFO] 2021-07-12 19:18:09,003 [run_pretraining.py:  535]:	loss/mlm_loss, 6.941924571990967, 2293
[INFO] 2021-07-12 19:18:09,003 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.291999953740742e-05, 2293
[INFO] 2021-07-12 19:18:09,003 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2293
[INFO] 2021-07-12 19:18:09,003 [run_pretraining.py:  558]:	worker_index: 2, step: 2293, cost: 6.941925, mlm loss: 6.941925, speed: 1.087620 steps/s, speed: 8.700962 samples/s, speed: 4454.892363 tokens/s, learning rate: 2.292e-05, loss_scalings: 2814.750488, pp_loss: 7.105133
[INFO] 2021-07-12 19:18:09,003 [run_pretraining.py:  512]:	********exe.run_2293******* 
[INFO] 2021-07-12 19:18:09,916 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:09,916 [run_pretraining.py:  534]:	loss/total_loss, 6.7670135498046875, 2294
[INFO] 2021-07-12 19:18:09,916 [run_pretraining.py:  535]:	loss/mlm_loss, 6.7670135498046875, 2294
[INFO] 2021-07-12 19:18:09,916 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2930000341148116e-05, 2294
[INFO] 2021-07-12 19:18:09,916 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2294
[INFO] 2021-07-12 19:18:09,916 [run_pretraining.py:  558]:	worker_index: 2, step: 2294, cost: 6.767014, mlm loss: 6.767014, speed: 1.095921 steps/s, speed: 8.767372 samples/s, speed: 4488.894261 tokens/s, learning rate: 2.293e-05, loss_scalings: 2814.750488, pp_loss: 7.300253
[INFO] 2021-07-12 19:18:09,917 [run_pretraining.py:  512]:	********exe.run_2294******* 
[INFO] 2021-07-12 19:18:10,847 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:10,847 [run_pretraining.py:  534]:	loss/total_loss, 7.181137561798096, 2295
[INFO] 2021-07-12 19:18:10,847 [run_pretraining.py:  535]:	loss/mlm_loss, 7.181137561798096, 2295
[INFO] 2021-07-12 19:18:10,847 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2939999325899407e-05, 2295
[INFO] 2021-07-12 19:18:10,847 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2295
[INFO] 2021-07-12 19:18:10,847 [run_pretraining.py:  558]:	worker_index: 2, step: 2295, cost: 7.181138, mlm loss: 7.181138, speed: 1.074846 steps/s, speed: 8.598771 samples/s, speed: 4402.570522 tokens/s, learning rate: 2.294e-05, loss_scalings: 2814.750488, pp_loss: 7.225667
[INFO] 2021-07-12 19:18:10,847 [run_pretraining.py:  512]:	********exe.run_2295******* 
[INFO] 2021-07-12 19:18:11,907 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:11,908 [run_pretraining.py:  534]:	loss/total_loss, 6.799400329589844, 2296
[INFO] 2021-07-12 19:18:11,908 [run_pretraining.py:  535]:	loss/mlm_loss, 6.799400329589844, 2296
[INFO] 2021-07-12 19:18:11,908 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.29499983106507e-05, 2296
[INFO] 2021-07-12 19:18:11,908 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2296
[INFO] 2021-07-12 19:18:11,908 [run_pretraining.py:  558]:	worker_index: 2, step: 2296, cost: 6.799400, mlm loss: 6.799400, speed: 0.943140 steps/s, speed: 7.545118 samples/s, speed: 3863.100651 tokens/s, learning rate: 2.295e-05, loss_scalings: 2814.750488, pp_loss: 7.311831
[INFO] 2021-07-12 19:18:11,908 [run_pretraining.py:  512]:	********exe.run_2296******* 
[INFO] 2021-07-12 19:18:12,948 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:12,949 [run_pretraining.py:  534]:	loss/total_loss, 7.285226345062256, 2297
[INFO] 2021-07-12 19:18:12,949 [run_pretraining.py:  535]:	loss/mlm_loss, 7.285226345062256, 2297
[INFO] 2021-07-12 19:18:12,949 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2959999114391394e-05, 2297
[INFO] 2021-07-12 19:18:12,949 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2297
[INFO] 2021-07-12 19:18:12,949 [run_pretraining.py:  558]:	worker_index: 2, step: 2297, cost: 7.285226, mlm loss: 7.285226, speed: 0.961498 steps/s, speed: 7.691987 samples/s, speed: 3938.297364 tokens/s, learning rate: 2.296e-05, loss_scalings: 2814.750488, pp_loss: 7.142577
[INFO] 2021-07-12 19:18:12,949 [run_pretraining.py:  512]:	********exe.run_2297******* 
[INFO] 2021-07-12 19:18:14,002 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:14,003 [run_pretraining.py:  534]:	loss/total_loss, 7.2336955070495605, 2298
[INFO] 2021-07-12 19:18:14,003 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2336955070495605, 2298
[INFO] 2021-07-12 19:18:14,003 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.296999991813209e-05, 2298
[INFO] 2021-07-12 19:18:14,003 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2298
[INFO] 2021-07-12 19:18:14,003 [run_pretraining.py:  558]:	worker_index: 2, step: 2298, cost: 7.233696, mlm loss: 7.233696, speed: 0.949154 steps/s, speed: 7.593234 samples/s, speed: 3887.735726 tokens/s, learning rate: 2.297e-05, loss_scalings: 2814.750488, pp_loss: 7.346970
[INFO] 2021-07-12 19:18:14,003 [run_pretraining.py:  512]:	********exe.run_2298******* 
[INFO] 2021-07-12 19:18:15,055 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:15,055 [run_pretraining.py:  534]:	loss/total_loss, 6.668519020080566, 2299
[INFO] 2021-07-12 19:18:15,056 [run_pretraining.py:  535]:	loss/mlm_loss, 6.668519020080566, 2299
[INFO] 2021-07-12 19:18:15,056 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.297999890288338e-05, 2299
[INFO] 2021-07-12 19:18:15,056 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2299
[INFO] 2021-07-12 19:18:15,056 [run_pretraining.py:  558]:	worker_index: 2, step: 2299, cost: 6.668519, mlm loss: 6.668519, speed: 0.950464 steps/s, speed: 7.603713 samples/s, speed: 3893.100975 tokens/s, learning rate: 2.298e-05, loss_scalings: 2814.750488, pp_loss: 6.735917
[INFO] 2021-07-12 19:18:15,056 [run_pretraining.py:  512]:	********exe.run_2299******* 
[INFO] 2021-07-12 19:18:40,219 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:40,219 [run_pretraining.py:  534]:	loss/total_loss, 6.9866766929626465, 2300
[INFO] 2021-07-12 19:18:40,220 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9866766929626465, 2300
[INFO] 2021-07-12 19:18:40,220 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2989999706624076e-05, 2300
[INFO] 2021-07-12 19:18:40,220 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2300
[INFO] 2021-07-12 19:18:40,220 [run_pretraining.py:  558]:	worker_index: 2, step: 2300, cost: 6.986677, mlm loss: 6.986677, speed: 0.039740 steps/s, speed: 0.317923 samples/s, speed: 162.776576 tokens/s, learning rate: 2.299e-05, loss_scalings: 2814.750488, pp_loss: 7.173532
[INFO] 2021-07-12 19:18:40,220 [run_pretraining.py:  512]:	********exe.run_2300******* 
[INFO] 2021-07-12 19:18:41,149 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:41,150 [run_pretraining.py:  534]:	loss/total_loss, 7.078969955444336, 2301
[INFO] 2021-07-12 19:18:41,150 [run_pretraining.py:  535]:	loss/mlm_loss, 7.078969955444336, 2301
[INFO] 2021-07-12 19:18:41,150 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.300000051036477e-05, 2301
[INFO] 2021-07-12 19:18:41,150 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2301
[INFO] 2021-07-12 19:18:41,150 [run_pretraining.py:  558]:	worker_index: 2, step: 2301, cost: 7.078970, mlm loss: 7.078970, speed: 1.075602 steps/s, speed: 8.604819 samples/s, speed: 4405.667399 tokens/s, learning rate: 2.300e-05, loss_scalings: 2814.750488, pp_loss: 7.096449
[INFO] 2021-07-12 19:18:41,150 [run_pretraining.py:  512]:	********exe.run_2301******* 
[INFO] 2021-07-12 19:18:42,066 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:42,066 [run_pretraining.py:  534]:	loss/total_loss, 6.375858306884766, 2302
[INFO] 2021-07-12 19:18:42,067 [run_pretraining.py:  535]:	loss/mlm_loss, 6.375858306884766, 2302
[INFO] 2021-07-12 19:18:42,067 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3009999495116062e-05, 2302
[INFO] 2021-07-12 19:18:42,067 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2302
[INFO] 2021-07-12 19:18:42,067 [run_pretraining.py:  558]:	worker_index: 2, step: 2302, cost: 6.375858, mlm loss: 6.375858, speed: 1.091656 steps/s, speed: 8.733246 samples/s, speed: 4471.421901 tokens/s, learning rate: 2.301e-05, loss_scalings: 2814.750488, pp_loss: 6.127688
[INFO] 2021-07-12 19:18:42,067 [run_pretraining.py:  512]:	********exe.run_2302******* 
[INFO] 2021-07-12 19:18:42,982 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:42,982 [run_pretraining.py:  534]:	loss/total_loss, 7.291952610015869, 2303
[INFO] 2021-07-12 19:18:42,982 [run_pretraining.py:  535]:	loss/mlm_loss, 7.291952610015869, 2303
[INFO] 2021-07-12 19:18:42,983 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3019998479867354e-05, 2303
[INFO] 2021-07-12 19:18:42,983 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2303
[INFO] 2021-07-12 19:18:42,983 [run_pretraining.py:  558]:	worker_index: 2, step: 2303, cost: 7.291953, mlm loss: 7.291953, speed: 1.092527 steps/s, speed: 8.740214 samples/s, speed: 4474.989407 tokens/s, learning rate: 2.302e-05, loss_scalings: 2814.750488, pp_loss: 7.343275
[INFO] 2021-07-12 19:18:42,983 [run_pretraining.py:  512]:	********exe.run_2303******* 
[INFO] 2021-07-12 19:18:43,904 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:43,905 [run_pretraining.py:  534]:	loss/total_loss, 6.973687171936035, 2304
[INFO] 2021-07-12 19:18:43,905 [run_pretraining.py:  535]:	loss/mlm_loss, 6.973687171936035, 2304
[INFO] 2021-07-12 19:18:43,905 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.302999928360805e-05, 2304
[INFO] 2021-07-12 19:18:43,905 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2304
[INFO] 2021-07-12 19:18:43,905 [run_pretraining.py:  558]:	worker_index: 2, step: 2304, cost: 6.973687, mlm loss: 6.973687, speed: 1.084604 steps/s, speed: 8.676835 samples/s, speed: 4442.539576 tokens/s, learning rate: 2.303e-05, loss_scalings: 2814.750488, pp_loss: 7.422019
[INFO] 2021-07-12 19:18:43,905 [run_pretraining.py:  512]:	********exe.run_2304******* 
[INFO] 2021-07-12 19:18:44,835 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:44,836 [run_pretraining.py:  534]:	loss/total_loss, 7.607155799865723, 2305
[INFO] 2021-07-12 19:18:44,836 [run_pretraining.py:  535]:	loss/mlm_loss, 7.607155799865723, 2305
[INFO] 2021-07-12 19:18:44,836 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.303999826835934e-05, 2305
[INFO] 2021-07-12 19:18:44,836 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2305
[INFO] 2021-07-12 19:18:44,836 [run_pretraining.py:  558]:	worker_index: 2, step: 2305, cost: 7.607156, mlm loss: 7.607156, speed: 1.074942 steps/s, speed: 8.599533 samples/s, speed: 4402.960920 tokens/s, learning rate: 2.304e-05, loss_scalings: 2814.750488, pp_loss: 7.023909
[INFO] 2021-07-12 19:18:44,836 [run_pretraining.py:  512]:	********exe.run_2305******* 
[INFO] 2021-07-12 19:18:45,740 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:45,740 [run_pretraining.py:  534]:	loss/total_loss, 7.7049736976623535, 2306
[INFO] 2021-07-12 19:18:45,740 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7049736976623535, 2306
[INFO] 2021-07-12 19:18:45,741 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3049999072100036e-05, 2306
[INFO] 2021-07-12 19:18:45,741 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2306
[INFO] 2021-07-12 19:18:45,741 [run_pretraining.py:  558]:	worker_index: 2, step: 2306, cost: 7.704974, mlm loss: 7.704974, speed: 1.106322 steps/s, speed: 8.850572 samples/s, speed: 4531.493110 tokens/s, learning rate: 2.305e-05, loss_scalings: 2814.750488, pp_loss: 7.388972
[INFO] 2021-07-12 19:18:45,741 [run_pretraining.py:  512]:	********exe.run_2306******* 
[INFO] 2021-07-12 19:18:46,657 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:46,657 [run_pretraining.py:  534]:	loss/total_loss, 7.418706893920898, 2307
[INFO] 2021-07-12 19:18:46,657 [run_pretraining.py:  535]:	loss/mlm_loss, 7.418706893920898, 2307
[INFO] 2021-07-12 19:18:46,657 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.305999987584073e-05, 2307
[INFO] 2021-07-12 19:18:46,658 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2307
[INFO] 2021-07-12 19:18:46,658 [run_pretraining.py:  558]:	worker_index: 2, step: 2307, cost: 7.418707, mlm loss: 7.418707, speed: 1.091319 steps/s, speed: 8.730549 samples/s, speed: 4470.040919 tokens/s, learning rate: 2.306e-05, loss_scalings: 2814.750488, pp_loss: 7.138026
[INFO] 2021-07-12 19:18:46,658 [run_pretraining.py:  512]:	********exe.run_2307******* 
[INFO] 2021-07-12 19:18:47,576 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:47,576 [run_pretraining.py:  534]:	loss/total_loss, 6.968341827392578, 2308
[INFO] 2021-07-12 19:18:47,576 [run_pretraining.py:  535]:	loss/mlm_loss, 6.968341827392578, 2308
[INFO] 2021-07-12 19:18:47,577 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3069998860592023e-05, 2308
[INFO] 2021-07-12 19:18:47,577 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2308
[INFO] 2021-07-12 19:18:47,577 [run_pretraining.py:  558]:	worker_index: 2, step: 2308, cost: 6.968342, mlm loss: 6.968342, speed: 1.088721 steps/s, speed: 8.709765 samples/s, speed: 4459.399862 tokens/s, learning rate: 2.307e-05, loss_scalings: 2814.750488, pp_loss: 7.472337
[INFO] 2021-07-12 19:18:47,577 [run_pretraining.py:  512]:	********exe.run_2308******* 
[INFO] 2021-07-12 19:18:48,508 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:48,508 [run_pretraining.py:  534]:	loss/total_loss, 7.6651506423950195, 2309
[INFO] 2021-07-12 19:18:48,509 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6651506423950195, 2309
[INFO] 2021-07-12 19:18:48,509 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3079999664332718e-05, 2309
[INFO] 2021-07-12 19:18:48,509 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2309
[INFO] 2021-07-12 19:18:48,509 [run_pretraining.py:  558]:	worker_index: 2, step: 2309, cost: 7.665151, mlm loss: 7.665151, speed: 1.073495 steps/s, speed: 8.587960 samples/s, speed: 4397.035685 tokens/s, learning rate: 2.308e-05, loss_scalings: 2814.750488, pp_loss: 7.279627
[INFO] 2021-07-12 19:18:48,509 [run_pretraining.py:  512]:	********exe.run_2309******* 
[INFO] 2021-07-12 19:18:49,421 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:49,421 [run_pretraining.py:  534]:	loss/total_loss, 8.213775634765625, 2310
[INFO] 2021-07-12 19:18:49,421 [run_pretraining.py:  535]:	loss/mlm_loss, 8.213775634765625, 2310
[INFO] 2021-07-12 19:18:49,422 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3090000468073413e-05, 2310
[INFO] 2021-07-12 19:18:49,422 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2310
[INFO] 2021-07-12 19:18:49,422 [run_pretraining.py:  558]:	worker_index: 2, step: 2310, cost: 8.213776, mlm loss: 8.213776, speed: 1.096123 steps/s, speed: 8.768987 samples/s, speed: 4489.721304 tokens/s, learning rate: 2.309e-05, loss_scalings: 2814.750488, pp_loss: 7.446803
[INFO] 2021-07-12 19:18:49,422 [run_pretraining.py:  512]:	********exe.run_2310******* 
[INFO] 2021-07-12 19:18:50,345 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:50,345 [run_pretraining.py:  534]:	loss/total_loss, 6.855927467346191, 2311
[INFO] 2021-07-12 19:18:50,345 [run_pretraining.py:  535]:	loss/mlm_loss, 6.855927467346191, 2311
[INFO] 2021-07-12 19:18:50,345 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3099999452824704e-05, 2311
[INFO] 2021-07-12 19:18:50,346 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2311
[INFO] 2021-07-12 19:18:50,346 [run_pretraining.py:  558]:	worker_index: 2, step: 2311, cost: 6.855927, mlm loss: 6.855927, speed: 1.083149 steps/s, speed: 8.665190 samples/s, speed: 4436.577298 tokens/s, learning rate: 2.310e-05, loss_scalings: 2814.750488, pp_loss: 7.249258
[INFO] 2021-07-12 19:18:50,346 [run_pretraining.py:  512]:	********exe.run_2311******* 
[INFO] 2021-07-12 19:18:51,269 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:51,270 [run_pretraining.py:  534]:	loss/total_loss, 6.488858222961426, 2312
[INFO] 2021-07-12 19:18:51,270 [run_pretraining.py:  535]:	loss/mlm_loss, 6.488858222961426, 2312
[INFO] 2021-07-12 19:18:51,270 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3109998437575996e-05, 2312
[INFO] 2021-07-12 19:18:51,270 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2312
[INFO] 2021-07-12 19:18:51,270 [run_pretraining.py:  558]:	worker_index: 2, step: 2312, cost: 6.488858, mlm loss: 6.488858, speed: 1.082623 steps/s, speed: 8.660981 samples/s, speed: 4434.422111 tokens/s, learning rate: 2.311e-05, loss_scalings: 2814.750488, pp_loss: 6.026212
[INFO] 2021-07-12 19:18:51,270 [run_pretraining.py:  512]:	********exe.run_2312******* 
[INFO] 2021-07-12 19:18:52,186 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:52,186 [run_pretraining.py:  534]:	loss/total_loss, 7.364082336425781, 2313
[INFO] 2021-07-12 19:18:52,186 [run_pretraining.py:  535]:	loss/mlm_loss, 7.364082336425781, 2313
[INFO] 2021-07-12 19:18:52,186 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.311999924131669e-05, 2313
[INFO] 2021-07-12 19:18:52,186 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2313
[INFO] 2021-07-12 19:18:52,186 [run_pretraining.py:  558]:	worker_index: 2, step: 2313, cost: 7.364082, mlm loss: 7.364082, speed: 1.091734 steps/s, speed: 8.733871 samples/s, speed: 4471.741963 tokens/s, learning rate: 2.312e-05, loss_scalings: 2814.750488, pp_loss: 6.953162
[INFO] 2021-07-12 19:18:52,186 [run_pretraining.py:  512]:	********exe.run_2313******* 
[INFO] 2021-07-12 19:18:53,117 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:53,117 [run_pretraining.py:  534]:	loss/total_loss, 6.712516784667969, 2314
[INFO] 2021-07-12 19:18:53,117 [run_pretraining.py:  535]:	loss/mlm_loss, 6.712516784667969, 2314
[INFO] 2021-07-12 19:18:53,117 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3129998226067983e-05, 2314
[INFO] 2021-07-12 19:18:53,117 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2314
[INFO] 2021-07-12 19:18:53,118 [run_pretraining.py:  558]:	worker_index: 2, step: 2314, cost: 6.712517, mlm loss: 6.712517, speed: 1.074628 steps/s, speed: 8.597023 samples/s, speed: 4401.676028 tokens/s, learning rate: 2.313e-05, loss_scalings: 2814.750488, pp_loss: 6.797150
[INFO] 2021-07-12 19:18:53,118 [run_pretraining.py:  512]:	********exe.run_2314******* 
[INFO] 2021-07-12 19:18:54,040 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:54,040 [run_pretraining.py:  534]:	loss/total_loss, 7.246241569519043, 2315
[INFO] 2021-07-12 19:18:54,040 [run_pretraining.py:  535]:	loss/mlm_loss, 7.246241569519043, 2315
[INFO] 2021-07-12 19:18:54,040 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3139999029808678e-05, 2315
[INFO] 2021-07-12 19:18:54,040 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2315
[INFO] 2021-07-12 19:18:54,040 [run_pretraining.py:  558]:	worker_index: 2, step: 2315, cost: 7.246242, mlm loss: 7.246242, speed: 1.084287 steps/s, speed: 8.674298 samples/s, speed: 4441.240668 tokens/s, learning rate: 2.314e-05, loss_scalings: 2814.750488, pp_loss: 7.199534
[INFO] 2021-07-12 19:18:54,040 [run_pretraining.py:  512]:	********exe.run_2315******* 
[INFO] 2021-07-12 19:18:54,958 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:54,959 [run_pretraining.py:  534]:	loss/total_loss, 8.003759384155273, 2316
[INFO] 2021-07-12 19:18:54,959 [run_pretraining.py:  535]:	loss/mlm_loss, 8.003759384155273, 2316
[INFO] 2021-07-12 19:18:54,959 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3149999833549373e-05, 2316
[INFO] 2021-07-12 19:18:54,959 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2316
[INFO] 2021-07-12 19:18:54,959 [run_pretraining.py:  558]:	worker_index: 2, step: 2316, cost: 8.003759, mlm loss: 8.003759, speed: 1.089322 steps/s, speed: 8.714579 samples/s, speed: 4461.864451 tokens/s, learning rate: 2.315e-05, loss_scalings: 2814.750488, pp_loss: 7.185430
[INFO] 2021-07-12 19:18:54,959 [run_pretraining.py:  512]:	********exe.run_2316******* 
[INFO] 2021-07-12 19:18:55,876 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:55,876 [run_pretraining.py:  534]:	loss/total_loss, 7.282458305358887, 2317
[INFO] 2021-07-12 19:18:55,876 [run_pretraining.py:  535]:	loss/mlm_loss, 7.282458305358887, 2317
[INFO] 2021-07-12 19:18:55,877 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3159998818300664e-05, 2317
[INFO] 2021-07-12 19:18:55,877 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2317
[INFO] 2021-07-12 19:18:55,877 [run_pretraining.py:  558]:	worker_index: 2, step: 2317, cost: 7.282458, mlm loss: 7.282458, speed: 1.090367 steps/s, speed: 8.722934 samples/s, speed: 4466.142246 tokens/s, learning rate: 2.316e-05, loss_scalings: 2814.750488, pp_loss: 7.053626
[INFO] 2021-07-12 19:18:55,877 [run_pretraining.py:  512]:	********exe.run_2317******* 
[INFO] 2021-07-12 19:18:56,793 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:56,793 [run_pretraining.py:  534]:	loss/total_loss, 7.233559608459473, 2318
[INFO] 2021-07-12 19:18:56,793 [run_pretraining.py:  535]:	loss/mlm_loss, 7.233559608459473, 2318
[INFO] 2021-07-12 19:18:56,793 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.316999962204136e-05, 2318
[INFO] 2021-07-12 19:18:56,794 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2318
[INFO] 2021-07-12 19:18:56,794 [run_pretraining.py:  558]:	worker_index: 2, step: 2318, cost: 7.233560, mlm loss: 7.233560, speed: 1.091353 steps/s, speed: 8.730821 samples/s, speed: 4470.180491 tokens/s, learning rate: 2.317e-05, loss_scalings: 2814.750488, pp_loss: 7.389763
[INFO] 2021-07-12 19:18:56,794 [run_pretraining.py:  512]:	********exe.run_2318******* 
[INFO] 2021-07-12 19:18:57,709 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:57,709 [run_pretraining.py:  534]:	loss/total_loss, 7.700440883636475, 2319
[INFO] 2021-07-12 19:18:57,709 [run_pretraining.py:  535]:	loss/mlm_loss, 7.700440883636475, 2319
[INFO] 2021-07-12 19:18:57,709 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3180000425782055e-05, 2319
[INFO] 2021-07-12 19:18:57,709 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2319
[INFO] 2021-07-12 19:18:57,709 [run_pretraining.py:  558]:	worker_index: 2, step: 2319, cost: 7.700441, mlm loss: 7.700441, speed: 1.092541 steps/s, speed: 8.740330 samples/s, speed: 4475.048856 tokens/s, learning rate: 2.318e-05, loss_scalings: 2814.750488, pp_loss: 7.450820
[INFO] 2021-07-12 19:18:57,710 [run_pretraining.py:  512]:	********exe.run_2319******* 
[INFO] 2021-07-12 19:18:58,620 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:58,621 [run_pretraining.py:  534]:	loss/total_loss, 6.9126200675964355, 2320
[INFO] 2021-07-12 19:18:58,621 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9126200675964355, 2320
[INFO] 2021-07-12 19:18:58,621 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3189999410533346e-05, 2320
[INFO] 2021-07-12 19:18:58,621 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2320
[INFO] 2021-07-12 19:18:58,621 [run_pretraining.py:  558]:	worker_index: 2, step: 2320, cost: 6.912620, mlm loss: 6.912620, speed: 1.097779 steps/s, speed: 8.782234 samples/s, speed: 4496.503977 tokens/s, learning rate: 2.319e-05, loss_scalings: 2814.750488, pp_loss: 7.465385
[INFO] 2021-07-12 19:18:58,621 [run_pretraining.py:  512]:	********exe.run_2320******* 
[INFO] 2021-07-12 19:18:59,535 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:59,536 [run_pretraining.py:  534]:	loss/total_loss, 7.267584800720215, 2321
[INFO] 2021-07-12 19:18:59,536 [run_pretraining.py:  535]:	loss/mlm_loss, 7.267584800720215, 2321
[INFO] 2021-07-12 19:18:59,536 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3199998395284638e-05, 2321
[INFO] 2021-07-12 19:18:59,536 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2321
[INFO] 2021-07-12 19:18:59,536 [run_pretraining.py:  558]:	worker_index: 2, step: 2321, cost: 7.267585, mlm loss: 7.267585, speed: 1.093769 steps/s, speed: 8.750156 samples/s, speed: 4480.079710 tokens/s, learning rate: 2.320e-05, loss_scalings: 2814.750488, pp_loss: 7.464190
[INFO] 2021-07-12 19:18:59,536 [run_pretraining.py:  512]:	********exe.run_2321******* 
[INFO] 2021-07-12 19:19:00,454 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:00,454 [run_pretraining.py:  534]:	loss/total_loss, 7.005727291107178, 2322
[INFO] 2021-07-12 19:19:00,454 [run_pretraining.py:  535]:	loss/mlm_loss, 7.005727291107178, 2322
[INFO] 2021-07-12 19:19:00,454 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3209999199025333e-05, 2322
[INFO] 2021-07-12 19:19:00,455 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2322
[INFO] 2021-07-12 19:19:00,455 [run_pretraining.py:  558]:	worker_index: 2, step: 2322, cost: 7.005727, mlm loss: 7.005727, speed: 1.089217 steps/s, speed: 8.713737 samples/s, speed: 4461.433415 tokens/s, learning rate: 2.321e-05, loss_scalings: 2814.750488, pp_loss: 6.994272
[INFO] 2021-07-12 19:19:00,455 [run_pretraining.py:  512]:	********exe.run_2322******* 
[INFO] 2021-07-12 19:19:01,378 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:01,379 [run_pretraining.py:  534]:	loss/total_loss, 7.240466117858887, 2323
[INFO] 2021-07-12 19:19:01,379 [run_pretraining.py:  535]:	loss/mlm_loss, 7.240466117858887, 2323
[INFO] 2021-07-12 19:19:01,379 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3219998183776625e-05, 2323
[INFO] 2021-07-12 19:19:01,379 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2323
[INFO] 2021-07-12 19:19:01,379 [run_pretraining.py:  558]:	worker_index: 2, step: 2323, cost: 7.240466, mlm loss: 7.240466, speed: 1.082314 steps/s, speed: 8.658513 samples/s, speed: 4433.158831 tokens/s, learning rate: 2.322e-05, loss_scalings: 2814.750488, pp_loss: 7.363373
[INFO] 2021-07-12 19:19:01,379 [run_pretraining.py:  512]:	********exe.run_2323******* 
[INFO] 2021-07-12 19:19:02,292 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:02,292 [run_pretraining.py:  534]:	loss/total_loss, 6.981026649475098, 2324
[INFO] 2021-07-12 19:19:02,292 [run_pretraining.py:  535]:	loss/mlm_loss, 6.981026649475098, 2324
[INFO] 2021-07-12 19:19:02,292 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.322999898751732e-05, 2324
[INFO] 2021-07-12 19:19:02,292 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2324
[INFO] 2021-07-12 19:19:02,293 [run_pretraining.py:  558]:	worker_index: 2, step: 2324, cost: 6.981027, mlm loss: 6.981027, speed: 1.095528 steps/s, speed: 8.764225 samples/s, speed: 4487.283283 tokens/s, learning rate: 2.323e-05, loss_scalings: 2814.750488, pp_loss: 7.334962
[INFO] 2021-07-12 19:19:02,293 [run_pretraining.py:  512]:	********exe.run_2324******* 
[INFO] 2021-07-12 19:19:03,212 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:03,213 [run_pretraining.py:  534]:	loss/total_loss, 6.680097579956055, 2325
[INFO] 2021-07-12 19:19:03,213 [run_pretraining.py:  535]:	loss/mlm_loss, 6.680097579956055, 2325
[INFO] 2021-07-12 19:19:03,213 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3239999791258015e-05, 2325
[INFO] 2021-07-12 19:19:03,213 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2325
[INFO] 2021-07-12 19:19:03,213 [run_pretraining.py:  558]:	worker_index: 2, step: 2325, cost: 6.680098, mlm loss: 6.680098, speed: 1.087160 steps/s, speed: 8.697277 samples/s, speed: 4453.005577 tokens/s, learning rate: 2.324e-05, loss_scalings: 2814.750488, pp_loss: 6.446035
[INFO] 2021-07-12 19:19:03,213 [run_pretraining.py:  512]:	********exe.run_2325******* 
[INFO] 2021-07-12 19:19:04,129 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:04,129 [run_pretraining.py:  534]:	loss/total_loss, 7.3748297691345215, 2326
[INFO] 2021-07-12 19:19:04,129 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3748297691345215, 2326
[INFO] 2021-07-12 19:19:04,129 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3249998776009306e-05, 2326
[INFO] 2021-07-12 19:19:04,129 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2326
[INFO] 2021-07-12 19:19:04,130 [run_pretraining.py:  558]:	worker_index: 2, step: 2326, cost: 7.374830, mlm loss: 7.374830, speed: 1.091684 steps/s, speed: 8.733475 samples/s, speed: 4471.539446 tokens/s, learning rate: 2.325e-05, loss_scalings: 2814.750488, pp_loss: 7.138567
[INFO] 2021-07-12 19:19:04,130 [run_pretraining.py:  512]:	********exe.run_2326******* 
[INFO] 2021-07-12 19:19:05,039 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:05,039 [run_pretraining.py:  534]:	loss/total_loss, 7.201592445373535, 2327
[INFO] 2021-07-12 19:19:05,039 [run_pretraining.py:  535]:	loss/mlm_loss, 7.201592445373535, 2327
[INFO] 2021-07-12 19:19:05,039 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.325999957975e-05, 2327
[INFO] 2021-07-12 19:19:05,040 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2327
[INFO] 2021-07-12 19:19:05,040 [run_pretraining.py:  558]:	worker_index: 2, step: 2327, cost: 7.201592, mlm loss: 7.201592, speed: 1.099610 steps/s, speed: 8.796878 samples/s, speed: 4504.001378 tokens/s, learning rate: 2.326e-05, loss_scalings: 2814.750488, pp_loss: 7.216256
[INFO] 2021-07-12 19:19:05,040 [run_pretraining.py:  512]:	********exe.run_2327******* 
[INFO] 2021-07-12 19:19:05,955 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:05,955 [run_pretraining.py:  534]:	loss/total_loss, 6.922454833984375, 2328
[INFO] 2021-07-12 19:19:05,956 [run_pretraining.py:  535]:	loss/mlm_loss, 6.922454833984375, 2328
[INFO] 2021-07-12 19:19:05,956 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3270000383490697e-05, 2328
[INFO] 2021-07-12 19:19:05,956 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2328
[INFO] 2021-07-12 19:19:05,956 [run_pretraining.py:  558]:	worker_index: 2, step: 2328, cost: 6.922455, mlm loss: 6.922455, speed: 1.092151 steps/s, speed: 8.737210 samples/s, speed: 4473.451292 tokens/s, learning rate: 2.327e-05, loss_scalings: 2814.750488, pp_loss: 7.190355
[INFO] 2021-07-12 19:19:05,956 [run_pretraining.py:  512]:	********exe.run_2328******* 
[INFO] 2021-07-12 19:19:06,872 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:06,872 [run_pretraining.py:  534]:	loss/total_loss, 7.335866451263428, 2329
[INFO] 2021-07-12 19:19:06,872 [run_pretraining.py:  535]:	loss/mlm_loss, 7.335866451263428, 2329
[INFO] 2021-07-12 19:19:06,872 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3279999368241988e-05, 2329
[INFO] 2021-07-12 19:19:06,872 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2329
[INFO] 2021-07-12 19:19:06,872 [run_pretraining.py:  558]:	worker_index: 2, step: 2329, cost: 7.335866, mlm loss: 7.335866, speed: 1.091624 steps/s, speed: 8.732994 samples/s, speed: 4471.292725 tokens/s, learning rate: 2.328e-05, loss_scalings: 2814.750488, pp_loss: 7.633904
[INFO] 2021-07-12 19:19:06,873 [run_pretraining.py:  512]:	********exe.run_2329******* 
[INFO] 2021-07-12 19:19:07,787 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:07,788 [run_pretraining.py:  534]:	loss/total_loss, 7.101297378540039, 2330
[INFO] 2021-07-12 19:19:07,788 [run_pretraining.py:  535]:	loss/mlm_loss, 7.101297378540039, 2330
[INFO] 2021-07-12 19:19:07,788 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.328999835299328e-05, 2330
[INFO] 2021-07-12 19:19:07,788 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2330
[INFO] 2021-07-12 19:19:07,788 [run_pretraining.py:  558]:	worker_index: 2, step: 2330, cost: 7.101297, mlm loss: 7.101297, speed: 1.092644 steps/s, speed: 8.741154 samples/s, speed: 4475.470868 tokens/s, learning rate: 2.329e-05, loss_scalings: 2814.750488, pp_loss: 7.096080
[INFO] 2021-07-12 19:19:07,788 [run_pretraining.py:  512]:	********exe.run_2330******* 
[INFO] 2021-07-12 19:19:08,702 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:08,702 [run_pretraining.py:  534]:	loss/total_loss, 6.850233554840088, 2331
[INFO] 2021-07-12 19:19:08,702 [run_pretraining.py:  535]:	loss/mlm_loss, 6.850233554840088, 2331
[INFO] 2021-07-12 19:19:08,702 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3299999156733975e-05, 2331
[INFO] 2021-07-12 19:19:08,702 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2331
[INFO] 2021-07-12 19:19:08,702 [run_pretraining.py:  558]:	worker_index: 2, step: 2331, cost: 6.850234, mlm loss: 6.850234, speed: 1.094631 steps/s, speed: 8.757048 samples/s, speed: 4483.608394 tokens/s, learning rate: 2.330e-05, loss_scalings: 2814.750488, pp_loss: 7.301007
[INFO] 2021-07-12 19:19:08,703 [run_pretraining.py:  512]:	********exe.run_2331******* 
[INFO] 2021-07-12 19:19:09,627 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:09,628 [run_pretraining.py:  534]:	loss/total_loss, 7.160916328430176, 2332
[INFO] 2021-07-12 19:19:09,628 [run_pretraining.py:  535]:	loss/mlm_loss, 7.160916328430176, 2332
[INFO] 2021-07-12 19:19:09,628 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.330999996047467e-05, 2332
[INFO] 2021-07-12 19:19:09,628 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2332
[INFO] 2021-07-12 19:19:09,628 [run_pretraining.py:  558]:	worker_index: 2, step: 2332, cost: 7.160916, mlm loss: 7.160916, speed: 1.081035 steps/s, speed: 8.648284 samples/s, speed: 4427.921164 tokens/s, learning rate: 2.331e-05, loss_scalings: 2814.750488, pp_loss: 7.524032
[INFO] 2021-07-12 19:19:09,628 [run_pretraining.py:  512]:	********exe.run_2332******* 
[INFO] 2021-07-12 19:19:10,539 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:10,540 [run_pretraining.py:  534]:	loss/total_loss, 7.201254844665527, 2333
[INFO] 2021-07-12 19:19:10,540 [run_pretraining.py:  535]:	loss/mlm_loss, 7.201254844665527, 2333
[INFO] 2021-07-12 19:19:10,540 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.331999894522596e-05, 2333
[INFO] 2021-07-12 19:19:10,540 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2333
[INFO] 2021-07-12 19:19:10,540 [run_pretraining.py:  558]:	worker_index: 2, step: 2333, cost: 7.201255, mlm loss: 7.201255, speed: 1.096937 steps/s, speed: 8.775498 samples/s, speed: 4493.054852 tokens/s, learning rate: 2.332e-05, loss_scalings: 2814.750488, pp_loss: 7.245278
[INFO] 2021-07-12 19:19:10,540 [run_pretraining.py:  512]:	********exe.run_2333******* 
[INFO] 2021-07-12 19:19:36,253 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:36,254 [run_pretraining.py:  534]:	loss/total_loss, 7.563714981079102, 2334
[INFO] 2021-07-12 19:19:36,254 [run_pretraining.py:  535]:	loss/mlm_loss, 7.563714981079102, 2334
[INFO] 2021-07-12 19:19:36,254 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3329999748966657e-05, 2334
[INFO] 2021-07-12 19:19:36,254 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2334
[INFO] 2021-07-12 19:19:36,254 [run_pretraining.py:  558]:	worker_index: 2, step: 2334, cost: 7.563715, mlm loss: 7.563715, speed: 0.038890 steps/s, speed: 0.311123 samples/s, speed: 159.294827 tokens/s, learning rate: 2.333e-05, loss_scalings: 2814.750488, pp_loss: 7.406827
[INFO] 2021-07-12 19:19:36,254 [run_pretraining.py:  512]:	********exe.run_2334******* 
[INFO] 2021-07-12 19:19:37,169 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:37,170 [run_pretraining.py:  534]:	loss/total_loss, 7.10124397277832, 2335
[INFO] 2021-07-12 19:19:37,170 [run_pretraining.py:  535]:	loss/mlm_loss, 7.10124397277832, 2335
[INFO] 2021-07-12 19:19:37,170 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3339998733717948e-05, 2335
[INFO] 2021-07-12 19:19:37,170 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2335
[INFO] 2021-07-12 19:19:37,170 [run_pretraining.py:  558]:	worker_index: 2, step: 2335, cost: 7.101244, mlm loss: 7.101244, speed: 1.092625 steps/s, speed: 8.741004 samples/s, speed: 4475.393921 tokens/s, learning rate: 2.334e-05, loss_scalings: 2814.750488, pp_loss: 7.138235
[INFO] 2021-07-12 19:19:37,170 [run_pretraining.py:  512]:	********exe.run_2335******* 
[INFO] 2021-07-12 19:19:38,090 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:38,091 [run_pretraining.py:  534]:	loss/total_loss, 7.344322681427002, 2336
[INFO] 2021-07-12 19:19:38,091 [run_pretraining.py:  535]:	loss/mlm_loss, 7.344322681427002, 2336
[INFO] 2021-07-12 19:19:38,091 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3349999537458643e-05, 2336
[INFO] 2021-07-12 19:19:38,091 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2336
[INFO] 2021-07-12 19:19:38,091 [run_pretraining.py:  558]:	worker_index: 2, step: 2336, cost: 7.344323, mlm loss: 7.344323, speed: 1.086738 steps/s, speed: 8.693908 samples/s, speed: 4451.280695 tokens/s, learning rate: 2.335e-05, loss_scalings: 2814.750488, pp_loss: 6.527190
[INFO] 2021-07-12 19:19:38,091 [run_pretraining.py:  512]:	********exe.run_2336******* 
[INFO] 2021-07-12 19:19:39,001 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:39,002 [run_pretraining.py:  534]:	loss/total_loss, 5.163453102111816, 2337
[INFO] 2021-07-12 19:19:39,002 [run_pretraining.py:  535]:	loss/mlm_loss, 5.163453102111816, 2337
[INFO] 2021-07-12 19:19:39,002 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.336000034119934e-05, 2337
[INFO] 2021-07-12 19:19:39,002 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2337
[INFO] 2021-07-12 19:19:39,002 [run_pretraining.py:  558]:	worker_index: 2, step: 2337, cost: 5.163453, mlm loss: 5.163453, speed: 1.098108 steps/s, speed: 8.784860 samples/s, speed: 4497.848369 tokens/s, learning rate: 2.336e-05, loss_scalings: 2814.750488, pp_loss: 5.172410
[INFO] 2021-07-12 19:19:39,002 [run_pretraining.py:  512]:	********exe.run_2337******* 
[INFO] 2021-07-12 19:19:39,915 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:39,915 [run_pretraining.py:  534]:	loss/total_loss, 7.233669757843018, 2338
[INFO] 2021-07-12 19:19:39,915 [run_pretraining.py:  535]:	loss/mlm_loss, 7.233669757843018, 2338
[INFO] 2021-07-12 19:19:39,916 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.336999932595063e-05, 2338
[INFO] 2021-07-12 19:19:39,916 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2338
[INFO] 2021-07-12 19:19:39,916 [run_pretraining.py:  558]:	worker_index: 2, step: 2338, cost: 7.233670, mlm loss: 7.233670, speed: 1.095348 steps/s, speed: 8.762781 samples/s, speed: 4486.543840 tokens/s, learning rate: 2.337e-05, loss_scalings: 2814.750488, pp_loss: 7.198549
[INFO] 2021-07-12 19:19:39,916 [run_pretraining.py:  512]:	********exe.run_2338******* 
[INFO] 2021-07-12 19:19:40,835 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:40,836 [run_pretraining.py:  534]:	loss/total_loss, 6.707391738891602, 2339
[INFO] 2021-07-12 19:19:40,836 [run_pretraining.py:  535]:	loss/mlm_loss, 6.707391738891602, 2339
[INFO] 2021-07-12 19:19:40,836 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.337999831070192e-05, 2339
[INFO] 2021-07-12 19:19:40,836 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2339
[INFO] 2021-07-12 19:19:40,836 [run_pretraining.py:  558]:	worker_index: 2, step: 2339, cost: 6.707392, mlm loss: 6.707392, speed: 1.087074 steps/s, speed: 8.696596 samples/s, speed: 4452.657032 tokens/s, learning rate: 2.338e-05, loss_scalings: 2814.750488, pp_loss: 6.374521
[INFO] 2021-07-12 19:19:40,836 [run_pretraining.py:  512]:	********exe.run_2339******* 
[INFO] 2021-07-12 19:19:41,746 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:41,747 [run_pretraining.py:  534]:	loss/total_loss, 7.280759811401367, 2340
[INFO] 2021-07-12 19:19:41,747 [run_pretraining.py:  535]:	loss/mlm_loss, 7.280759811401367, 2340
[INFO] 2021-07-12 19:19:41,747 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3389999114442617e-05, 2340
[INFO] 2021-07-12 19:19:41,747 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2340
[INFO] 2021-07-12 19:19:41,747 [run_pretraining.py:  558]:	worker_index: 2, step: 2340, cost: 7.280760, mlm loss: 7.280760, speed: 1.098564 steps/s, speed: 8.788512 samples/s, speed: 4499.717962 tokens/s, learning rate: 2.339e-05, loss_scalings: 2814.750488, pp_loss: 7.382607
[INFO] 2021-07-12 19:19:41,747 [run_pretraining.py:  512]:	********exe.run_2340******* 
[INFO] 2021-07-12 19:19:42,662 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:42,662 [run_pretraining.py:  534]:	loss/total_loss, 6.975759506225586, 2341
[INFO] 2021-07-12 19:19:42,662 [run_pretraining.py:  535]:	loss/mlm_loss, 6.975759506225586, 2341
[INFO] 2021-07-12 19:19:42,662 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3399999918183312e-05, 2341
[INFO] 2021-07-12 19:19:42,662 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2341
[INFO] 2021-07-12 19:19:42,662 [run_pretraining.py:  558]:	worker_index: 2, step: 2341, cost: 6.975760, mlm loss: 6.975760, speed: 1.093201 steps/s, speed: 8.745610 samples/s, speed: 4477.752512 tokens/s, learning rate: 2.340e-05, loss_scalings: 2814.750488, pp_loss: 7.029562
[INFO] 2021-07-12 19:19:42,662 [run_pretraining.py:  512]:	********exe.run_2341******* 
[INFO] 2021-07-12 19:19:43,577 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:43,577 [run_pretraining.py:  534]:	loss/total_loss, 7.72536563873291, 2342
[INFO] 2021-07-12 19:19:43,577 [run_pretraining.py:  535]:	loss/mlm_loss, 7.72536563873291, 2342
[INFO] 2021-07-12 19:19:43,577 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3409998902934603e-05, 2342
[INFO] 2021-07-12 19:19:43,577 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2342
[INFO] 2021-07-12 19:19:43,577 [run_pretraining.py:  558]:	worker_index: 2, step: 2342, cost: 7.725366, mlm loss: 7.725366, speed: 1.093586 steps/s, speed: 8.748691 samples/s, speed: 4479.329791 tokens/s, learning rate: 2.341e-05, loss_scalings: 2814.750488, pp_loss: 7.542799
[INFO] 2021-07-12 19:19:43,577 [run_pretraining.py:  512]:	********exe.run_2342******* 
[INFO] 2021-07-12 19:19:44,495 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:44,496 [run_pretraining.py:  534]:	loss/total_loss, 7.071731090545654, 2343
[INFO] 2021-07-12 19:19:44,496 [run_pretraining.py:  535]:	loss/mlm_loss, 7.071731090545654, 2343
[INFO] 2021-07-12 19:19:44,496 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.34199997066753e-05, 2343
[INFO] 2021-07-12 19:19:44,496 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2343
[INFO] 2021-07-12 19:19:44,496 [run_pretraining.py:  558]:	worker_index: 2, step: 2343, cost: 7.071731, mlm loss: 7.071731, speed: 1.089341 steps/s, speed: 8.714731 samples/s, speed: 4461.942093 tokens/s, learning rate: 2.342e-05, loss_scalings: 2814.750488, pp_loss: 6.982101
[INFO] 2021-07-12 19:19:44,496 [run_pretraining.py:  512]:	********exe.run_2343******* 
[INFO] 2021-07-12 19:19:45,416 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:45,417 [run_pretraining.py:  534]:	loss/total_loss, 7.7777581214904785, 2344
[INFO] 2021-07-12 19:19:45,417 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7777581214904785, 2344
[INFO] 2021-07-12 19:19:45,417 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3430000510415994e-05, 2344
[INFO] 2021-07-12 19:19:45,417 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2344
[INFO] 2021-07-12 19:19:45,417 [run_pretraining.py:  558]:	worker_index: 2, step: 2344, cost: 7.777758, mlm loss: 7.777758, speed: 1.086625 steps/s, speed: 8.693000 samples/s, speed: 4450.815955 tokens/s, learning rate: 2.343e-05, loss_scalings: 2814.750488, pp_loss: 7.697129
[INFO] 2021-07-12 19:19:45,417 [run_pretraining.py:  512]:	********exe.run_2344******* 
[INFO] 2021-07-12 19:19:46,332 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:46,333 [run_pretraining.py:  534]:	loss/total_loss, 7.2798614501953125, 2345
[INFO] 2021-07-12 19:19:46,333 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2798614501953125, 2345
[INFO] 2021-07-12 19:19:46,333 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3439999495167285e-05, 2345
[INFO] 2021-07-12 19:19:46,333 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2345
[INFO] 2021-07-12 19:19:46,333 [run_pretraining.py:  558]:	worker_index: 2, step: 2345, cost: 7.279861, mlm loss: 7.279861, speed: 1.092297 steps/s, speed: 8.738375 samples/s, speed: 4474.047769 tokens/s, learning rate: 2.344e-05, loss_scalings: 2814.750488, pp_loss: 7.665275
[INFO] 2021-07-12 19:19:46,333 [run_pretraining.py:  512]:	********exe.run_2345******* 
[INFO] 2021-07-12 19:19:47,269 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:47,270 [run_pretraining.py:  534]:	loss/total_loss, 7.565105438232422, 2346
[INFO] 2021-07-12 19:19:47,270 [run_pretraining.py:  535]:	loss/mlm_loss, 7.565105438232422, 2346
[INFO] 2021-07-12 19:19:47,270 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.345000029890798e-05, 2346
[INFO] 2021-07-12 19:19:47,270 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2346
[INFO] 2021-07-12 19:19:47,270 [run_pretraining.py:  558]:	worker_index: 2, step: 2346, cost: 7.565105, mlm loss: 7.565105, speed: 1.067629 steps/s, speed: 8.541033 samples/s, speed: 4373.009110 tokens/s, learning rate: 2.345e-05, loss_scalings: 2814.750488, pp_loss: 7.331989
[INFO] 2021-07-12 19:19:47,270 [run_pretraining.py:  512]:	********exe.run_2346******* 
[INFO] 2021-07-12 19:19:48,184 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:48,185 [run_pretraining.py:  534]:	loss/total_loss, 6.972480773925781, 2347
[INFO] 2021-07-12 19:19:48,185 [run_pretraining.py:  535]:	loss/mlm_loss, 6.972480773925781, 2347
[INFO] 2021-07-12 19:19:48,185 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3459999283659272e-05, 2347
[INFO] 2021-07-12 19:19:48,185 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2347
[INFO] 2021-07-12 19:19:48,185 [run_pretraining.py:  558]:	worker_index: 2, step: 2347, cost: 6.972481, mlm loss: 6.972481, speed: 1.093630 steps/s, speed: 8.749042 samples/s, speed: 4479.509655 tokens/s, learning rate: 2.346e-05, loss_scalings: 2814.750488, pp_loss: 6.981538
[INFO] 2021-07-12 19:19:48,185 [run_pretraining.py:  512]:	********exe.run_2347******* 
[INFO] 2021-07-12 19:19:49,109 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:49,109 [run_pretraining.py:  534]:	loss/total_loss, 6.404757022857666, 2348
[INFO] 2021-07-12 19:19:49,109 [run_pretraining.py:  535]:	loss/mlm_loss, 6.404757022857666, 2348
[INFO] 2021-07-12 19:19:49,109 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3469998268410563e-05, 2348
[INFO] 2021-07-12 19:19:49,109 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2348
[INFO] 2021-07-12 19:19:49,109 [run_pretraining.py:  558]:	worker_index: 2, step: 2348, cost: 6.404757, mlm loss: 6.404757, speed: 1.082715 steps/s, speed: 8.661721 samples/s, speed: 4434.801007 tokens/s, learning rate: 2.347e-05, loss_scalings: 2814.750488, pp_loss: 6.178812
[INFO] 2021-07-12 19:19:49,109 [run_pretraining.py:  512]:	********exe.run_2348******* 
[INFO] 2021-07-12 19:19:50,017 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:50,018 [run_pretraining.py:  534]:	loss/total_loss, 7.599585056304932, 2349
[INFO] 2021-07-12 19:19:50,018 [run_pretraining.py:  535]:	loss/mlm_loss, 7.599585056304932, 2349
[INFO] 2021-07-12 19:19:50,018 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.347999907215126e-05, 2349
[INFO] 2021-07-12 19:19:50,018 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2349
[INFO] 2021-07-12 19:19:50,018 [run_pretraining.py:  558]:	worker_index: 2, step: 2349, cost: 7.599585, mlm loss: 7.599585, speed: 1.101350 steps/s, speed: 8.810797 samples/s, speed: 4511.128151 tokens/s, learning rate: 2.348e-05, loss_scalings: 2814.750488, pp_loss: 7.326268
[INFO] 2021-07-12 19:19:50,018 [run_pretraining.py:  512]:	********exe.run_2349******* 
[INFO] 2021-07-12 19:19:50,936 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:50,936 [run_pretraining.py:  534]:	loss/total_loss, 7.209222793579102, 2350
[INFO] 2021-07-12 19:19:50,936 [run_pretraining.py:  535]:	loss/mlm_loss, 7.209222793579102, 2350
[INFO] 2021-07-12 19:19:50,936 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3489999875891954e-05, 2350
[INFO] 2021-07-12 19:19:50,937 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2350
[INFO] 2021-07-12 19:19:50,937 [run_pretraining.py:  558]:	worker_index: 2, step: 2350, cost: 7.209223, mlm loss: 7.209223, speed: 1.089310 steps/s, speed: 8.714479 samples/s, speed: 4461.813464 tokens/s, learning rate: 2.349e-05, loss_scalings: 2814.750488, pp_loss: 7.320389
[INFO] 2021-07-12 19:19:50,937 [run_pretraining.py:  512]:	********exe.run_2350******* 
[INFO] 2021-07-12 19:19:51,846 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:51,846 [run_pretraining.py:  534]:	loss/total_loss, 7.000728130340576, 2351
[INFO] 2021-07-12 19:19:51,846 [run_pretraining.py:  535]:	loss/mlm_loss, 7.000728130340576, 2351
[INFO] 2021-07-12 19:19:51,847 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3499998860643245e-05, 2351
[INFO] 2021-07-12 19:19:51,847 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2351
[INFO] 2021-07-12 19:19:51,847 [run_pretraining.py:  558]:	worker_index: 2, step: 2351, cost: 7.000728, mlm loss: 7.000728, speed: 1.099519 steps/s, speed: 8.796156 samples/s, speed: 4503.631817 tokens/s, learning rate: 2.350e-05, loss_scalings: 2814.750488, pp_loss: 7.387672
[INFO] 2021-07-12 19:19:51,847 [run_pretraining.py:  512]:	********exe.run_2351******* 
[INFO] 2021-07-12 19:19:52,762 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:52,762 [run_pretraining.py:  534]:	loss/total_loss, 7.143423557281494, 2352
[INFO] 2021-07-12 19:19:52,763 [run_pretraining.py:  535]:	loss/mlm_loss, 7.143423557281494, 2352
[INFO] 2021-07-12 19:19:52,763 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.350999966438394e-05, 2352
[INFO] 2021-07-12 19:19:52,763 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2352
[INFO] 2021-07-12 19:19:52,763 [run_pretraining.py:  558]:	worker_index: 2, step: 2352, cost: 7.143424, mlm loss: 7.143424, speed: 1.092334 steps/s, speed: 8.738675 samples/s, speed: 4474.201574 tokens/s, learning rate: 2.351e-05, loss_scalings: 2814.750488, pp_loss: 7.471591
[INFO] 2021-07-12 19:19:52,763 [run_pretraining.py:  512]:	********exe.run_2352******* 
[INFO] 2021-07-12 19:19:53,674 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:53,674 [run_pretraining.py:  534]:	loss/total_loss, 7.501047134399414, 2353
[INFO] 2021-07-12 19:19:53,674 [run_pretraining.py:  535]:	loss/mlm_loss, 7.501047134399414, 2353
[INFO] 2021-07-12 19:19:53,674 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3520000468124636e-05, 2353
[INFO] 2021-07-12 19:19:53,675 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2353
[INFO] 2021-07-12 19:19:53,675 [run_pretraining.py:  558]:	worker_index: 2, step: 2353, cost: 7.501047, mlm loss: 7.501047, speed: 1.097416 steps/s, speed: 8.779328 samples/s, speed: 4495.015723 tokens/s, learning rate: 2.352e-05, loss_scalings: 2814.750488, pp_loss: 6.979018
[INFO] 2021-07-12 19:19:53,675 [run_pretraining.py:  512]:	********exe.run_2353******* 
[INFO] 2021-07-12 19:19:54,586 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:54,587 [run_pretraining.py:  534]:	loss/total_loss, 7.618060111999512, 2354
[INFO] 2021-07-12 19:19:54,587 [run_pretraining.py:  535]:	loss/mlm_loss, 7.618060111999512, 2354
[INFO] 2021-07-12 19:19:54,587 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3529999452875927e-05, 2354
[INFO] 2021-07-12 19:19:54,587 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2354
[INFO] 2021-07-12 19:19:54,587 [run_pretraining.py:  558]:	worker_index: 2, step: 2354, cost: 7.618060, mlm loss: 7.618060, speed: 1.096536 steps/s, speed: 8.772286 samples/s, speed: 4491.410356 tokens/s, learning rate: 2.353e-05, loss_scalings: 2814.750488, pp_loss: 7.429084
[INFO] 2021-07-12 19:19:54,587 [run_pretraining.py:  512]:	********exe.run_2354******* 
[INFO] 2021-07-12 19:19:55,502 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:55,503 [run_pretraining.py:  534]:	loss/total_loss, 7.4082465171813965, 2355
[INFO] 2021-07-12 19:19:55,503 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4082465171813965, 2355
[INFO] 2021-07-12 19:19:55,503 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3540000256616622e-05, 2355
[INFO] 2021-07-12 19:19:55,503 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2355
[INFO] 2021-07-12 19:19:55,503 [run_pretraining.py:  558]:	worker_index: 2, step: 2355, cost: 7.408247, mlm loss: 7.408247, speed: 1.092355 steps/s, speed: 8.738837 samples/s, speed: 4474.284307 tokens/s, learning rate: 2.354e-05, loss_scalings: 2814.750488, pp_loss: 7.486097
[INFO] 2021-07-12 19:19:55,503 [run_pretraining.py:  512]:	********exe.run_2355******* 
[INFO] 2021-07-12 19:19:56,418 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:56,419 [run_pretraining.py:  534]:	loss/total_loss, 7.154110431671143, 2356
[INFO] 2021-07-12 19:19:56,419 [run_pretraining.py:  535]:	loss/mlm_loss, 7.154110431671143, 2356
[INFO] 2021-07-12 19:19:56,419 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3549999241367914e-05, 2356
[INFO] 2021-07-12 19:19:56,419 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2356
[INFO] 2021-07-12 19:19:56,419 [run_pretraining.py:  558]:	worker_index: 2, step: 2356, cost: 7.154110, mlm loss: 7.154110, speed: 1.092678 steps/s, speed: 8.741427 samples/s, speed: 4475.610779 tokens/s, learning rate: 2.355e-05, loss_scalings: 2814.750488, pp_loss: 7.345857
[INFO] 2021-07-12 19:19:56,419 [run_pretraining.py:  512]:	********exe.run_2356******* 
[INFO] 2021-07-12 19:19:57,336 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:57,337 [run_pretraining.py:  534]:	loss/total_loss, 7.181190013885498, 2357
[INFO] 2021-07-12 19:19:57,337 [run_pretraining.py:  535]:	loss/mlm_loss, 7.181190013885498, 2357
[INFO] 2021-07-12 19:19:57,337 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3559998226119205e-05, 2357
[INFO] 2021-07-12 19:19:57,337 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2357
[INFO] 2021-07-12 19:19:57,337 [run_pretraining.py:  558]:	worker_index: 2, step: 2357, cost: 7.181190, mlm loss: 7.181190, speed: 1.089742 steps/s, speed: 8.717935 samples/s, speed: 4463.582472 tokens/s, learning rate: 2.356e-05, loss_scalings: 2814.750488, pp_loss: 7.213237
[INFO] 2021-07-12 19:19:57,337 [run_pretraining.py:  512]:	********exe.run_2357******* 
[INFO] 2021-07-12 19:19:58,254 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:58,255 [run_pretraining.py:  534]:	loss/total_loss, 7.350755214691162, 2358
[INFO] 2021-07-12 19:19:58,255 [run_pretraining.py:  535]:	loss/mlm_loss, 7.350755214691162, 2358
[INFO] 2021-07-12 19:19:58,255 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.35699990298599e-05, 2358
[INFO] 2021-07-12 19:19:58,255 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2358
[INFO] 2021-07-12 19:19:58,255 [run_pretraining.py:  558]:	worker_index: 2, step: 2358, cost: 7.350755, mlm loss: 7.350755, speed: 1.090280 steps/s, speed: 8.722238 samples/s, speed: 4465.785837 tokens/s, learning rate: 2.357e-05, loss_scalings: 2814.750488, pp_loss: 7.311733
[INFO] 2021-07-12 19:19:58,255 [run_pretraining.py:  512]:	********exe.run_2358******* 
[INFO] 2021-07-12 19:19:59,214 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:59,215 [run_pretraining.py:  534]:	loss/total_loss, 7.0090532302856445, 2359
[INFO] 2021-07-12 19:19:59,215 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0090532302856445, 2359
[INFO] 2021-07-12 19:19:59,215 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3579999833600596e-05, 2359
[INFO] 2021-07-12 19:19:59,215 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2359
[INFO] 2021-07-12 19:19:59,215 [run_pretraining.py:  558]:	worker_index: 2, step: 2359, cost: 7.009053, mlm loss: 7.009053, speed: 1.042499 steps/s, speed: 8.339994 samples/s, speed: 4270.077017 tokens/s, learning rate: 2.358e-05, loss_scalings: 2814.750488, pp_loss: 7.111416
[INFO] 2021-07-12 19:19:59,215 [run_pretraining.py:  512]:	********exe.run_2359******* 
[INFO] 2021-07-12 19:20:00,230 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:00,231 [run_pretraining.py:  534]:	loss/total_loss, 9.149974822998047, 2360
[INFO] 2021-07-12 19:20:00,231 [run_pretraining.py:  535]:	loss/mlm_loss, 9.149974822998047, 2360
[INFO] 2021-07-12 19:20:00,231 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3589998818351887e-05, 2360
[INFO] 2021-07-12 19:20:00,231 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2360
[INFO] 2021-07-12 19:20:00,231 [run_pretraining.py:  558]:	worker_index: 2, step: 2360, cost: 9.149975, mlm loss: 9.149975, speed: 0.984666 steps/s, speed: 7.877332 samples/s, speed: 4033.193857 tokens/s, learning rate: 2.359e-05, loss_scalings: 2814.750488, pp_loss: 7.849201
[INFO] 2021-07-12 19:20:00,231 [run_pretraining.py:  512]:	********exe.run_2360******* 
[INFO] 2021-07-12 19:20:01,199 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:01,200 [run_pretraining.py:  534]:	loss/total_loss, 7.486599922180176, 2361
[INFO] 2021-07-12 19:20:01,200 [run_pretraining.py:  535]:	loss/mlm_loss, 7.486599922180176, 2361
[INFO] 2021-07-12 19:20:01,200 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3599999622092582e-05, 2361
[INFO] 2021-07-12 19:20:01,200 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2361
[INFO] 2021-07-12 19:20:01,200 [run_pretraining.py:  558]:	worker_index: 2, step: 2361, cost: 7.486600, mlm loss: 7.486600, speed: 1.032412 steps/s, speed: 8.259298 samples/s, speed: 4228.760760 tokens/s, learning rate: 2.360e-05, loss_scalings: 2814.750488, pp_loss: 7.285208
[INFO] 2021-07-12 19:20:01,200 [run_pretraining.py:  512]:	********exe.run_2361******* 
[INFO] 2021-07-12 19:20:02,176 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:02,177 [run_pretraining.py:  534]:	loss/total_loss, 5.410839080810547, 2362
[INFO] 2021-07-12 19:20:02,177 [run_pretraining.py:  535]:	loss/mlm_loss, 5.410839080810547, 2362
[INFO] 2021-07-12 19:20:02,177 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3610000425833277e-05, 2362
[INFO] 2021-07-12 19:20:02,177 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2362
[INFO] 2021-07-12 19:20:02,177 [run_pretraining.py:  558]:	worker_index: 2, step: 2362, cost: 5.410839, mlm loss: 5.410839, speed: 1.024539 steps/s, speed: 8.196312 samples/s, speed: 4196.511882 tokens/s, learning rate: 2.361e-05, loss_scalings: 2814.750488, pp_loss: 7.250873
[INFO] 2021-07-12 19:20:02,177 [run_pretraining.py:  512]:	********exe.run_2362******* 
[INFO] 2021-07-12 19:20:03,156 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:03,157 [run_pretraining.py:  534]:	loss/total_loss, 7.6259050369262695, 2363
[INFO] 2021-07-12 19:20:03,157 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6259050369262695, 2363
[INFO] 2021-07-12 19:20:03,157 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.361999941058457e-05, 2363
[INFO] 2021-07-12 19:20:03,157 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2363
[INFO] 2021-07-12 19:20:03,157 [run_pretraining.py:  558]:	worker_index: 2, step: 2363, cost: 7.625905, mlm loss: 7.625905, speed: 1.020981 steps/s, speed: 8.167845 samples/s, speed: 4181.936861 tokens/s, learning rate: 2.362e-05, loss_scalings: 2814.750488, pp_loss: 7.177055
[INFO] 2021-07-12 19:20:03,157 [run_pretraining.py:  512]:	********exe.run_2363******* 
[INFO] 2021-07-12 19:20:04,132 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:04,133 [run_pretraining.py:  534]:	loss/total_loss, 7.195998668670654, 2364
[INFO] 2021-07-12 19:20:04,133 [run_pretraining.py:  535]:	loss/mlm_loss, 7.195998668670654, 2364
[INFO] 2021-07-12 19:20:04,133 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3630000214325264e-05, 2364
[INFO] 2021-07-12 19:20:04,133 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2364
[INFO] 2021-07-12 19:20:04,133 [run_pretraining.py:  558]:	worker_index: 2, step: 2364, cost: 7.195999, mlm loss: 7.195999, speed: 1.024891 steps/s, speed: 8.199128 samples/s, speed: 4197.953637 tokens/s, learning rate: 2.363e-05, loss_scalings: 2814.750488, pp_loss: 6.880473
[INFO] 2021-07-12 19:20:04,133 [run_pretraining.py:  512]:	********exe.run_2364******* 
[INFO] 2021-07-12 19:20:05,103 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:05,103 [run_pretraining.py:  534]:	loss/total_loss, 7.704024314880371, 2365
[INFO] 2021-07-12 19:20:05,103 [run_pretraining.py:  535]:	loss/mlm_loss, 7.704024314880371, 2365
[INFO] 2021-07-12 19:20:05,103 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3639999199076556e-05, 2365
[INFO] 2021-07-12 19:20:05,103 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2365
[INFO] 2021-07-12 19:20:05,104 [run_pretraining.py:  558]:	worker_index: 2, step: 2365, cost: 7.704024, mlm loss: 7.704024, speed: 1.031298 steps/s, speed: 8.250383 samples/s, speed: 4224.196169 tokens/s, learning rate: 2.364e-05, loss_scalings: 2814.750488, pp_loss: 7.420767
[INFO] 2021-07-12 19:20:05,104 [run_pretraining.py:  512]:	********exe.run_2365******* 
[INFO] 2021-07-12 19:20:06,078 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:06,079 [run_pretraining.py:  534]:	loss/total_loss, 7.669381141662598, 2366
[INFO] 2021-07-12 19:20:06,079 [run_pretraining.py:  535]:	loss/mlm_loss, 7.669381141662598, 2366
[INFO] 2021-07-12 19:20:06,079 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3649998183827847e-05, 2366
[INFO] 2021-07-12 19:20:06,079 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2366
[INFO] 2021-07-12 19:20:06,079 [run_pretraining.py:  558]:	worker_index: 2, step: 2366, cost: 7.669381, mlm loss: 7.669381, speed: 1.025570 steps/s, speed: 8.204559 samples/s, speed: 4200.734323 tokens/s, learning rate: 2.365e-05, loss_scalings: 2814.750488, pp_loss: 7.289071
[INFO] 2021-07-12 19:20:06,079 [run_pretraining.py:  512]:	********exe.run_2366******* 
[INFO] 2021-07-12 19:20:07,053 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:07,053 [run_pretraining.py:  534]:	loss/total_loss, 7.093849182128906, 2367
[INFO] 2021-07-12 19:20:07,054 [run_pretraining.py:  535]:	loss/mlm_loss, 7.093849182128906, 2367
[INFO] 2021-07-12 19:20:07,054 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3659998987568542e-05, 2367
[INFO] 2021-07-12 19:20:07,054 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2367
[INFO] 2021-07-12 19:20:07,054 [run_pretraining.py:  558]:	worker_index: 2, step: 2367, cost: 7.093849, mlm loss: 7.093849, speed: 1.026728 steps/s, speed: 8.213822 samples/s, speed: 4205.476851 tokens/s, learning rate: 2.366e-05, loss_scalings: 2814.750488, pp_loss: 7.001239
[INFO] 2021-07-12 19:20:07,054 [run_pretraining.py:  512]:	********exe.run_2367******* 
[INFO] 2021-07-12 19:20:08,029 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:08,029 [run_pretraining.py:  534]:	loss/total_loss, 7.498693466186523, 2368
[INFO] 2021-07-12 19:20:08,030 [run_pretraining.py:  535]:	loss/mlm_loss, 7.498693466186523, 2368
[INFO] 2021-07-12 19:20:08,030 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3669999791309237e-05, 2368
[INFO] 2021-07-12 19:20:08,030 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2368
[INFO] 2021-07-12 19:20:08,030 [run_pretraining.py:  558]:	worker_index: 2, step: 2368, cost: 7.498693, mlm loss: 7.498693, speed: 1.025219 steps/s, speed: 8.201756 samples/s, speed: 4199.298869 tokens/s, learning rate: 2.367e-05, loss_scalings: 2814.750488, pp_loss: 6.862817
[INFO] 2021-07-12 19:20:08,030 [run_pretraining.py:  512]:	********exe.run_2368******* 
[INFO] 2021-07-12 19:20:09,012 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:09,012 [run_pretraining.py:  534]:	loss/total_loss, 6.505402565002441, 2369
[INFO] 2021-07-12 19:20:09,013 [run_pretraining.py:  535]:	loss/mlm_loss, 6.505402565002441, 2369
[INFO] 2021-07-12 19:20:09,013 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.367999877606053e-05, 2369
[INFO] 2021-07-12 19:20:09,013 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2369
[INFO] 2021-07-12 19:20:09,013 [run_pretraining.py:  558]:	worker_index: 2, step: 2369, cost: 6.505403, mlm loss: 6.505403, speed: 1.017941 steps/s, speed: 8.143525 samples/s, speed: 4169.484573 tokens/s, learning rate: 2.368e-05, loss_scalings: 2814.750488, pp_loss: 7.204999
[INFO] 2021-07-12 19:20:09,013 [run_pretraining.py:  512]:	********exe.run_2369******* 
[INFO] 2021-07-12 19:20:09,988 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:09,989 [run_pretraining.py:  534]:	loss/total_loss, 8.293033599853516, 2370
[INFO] 2021-07-12 19:20:09,989 [run_pretraining.py:  535]:	loss/mlm_loss, 8.293033599853516, 2370
[INFO] 2021-07-12 19:20:09,989 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3689999579801224e-05, 2370
[INFO] 2021-07-12 19:20:09,989 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2370
[INFO] 2021-07-12 19:20:09,989 [run_pretraining.py:  558]:	worker_index: 2, step: 2370, cost: 8.293034, mlm loss: 8.293034, speed: 1.024715 steps/s, speed: 8.197724 samples/s, speed: 4197.234686 tokens/s, learning rate: 2.369e-05, loss_scalings: 2814.750488, pp_loss: 7.411490
[INFO] 2021-07-12 19:20:09,989 [run_pretraining.py:  512]:	********exe.run_2370******* 
[INFO] 2021-07-12 19:20:11,004 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:11,005 [run_pretraining.py:  534]:	loss/total_loss, 6.887799263000488, 2371
[INFO] 2021-07-12 19:20:11,005 [run_pretraining.py:  535]:	loss/mlm_loss, 6.887799263000488, 2371
[INFO] 2021-07-12 19:20:11,005 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.370000038354192e-05, 2371
[INFO] 2021-07-12 19:20:11,005 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2371
[INFO] 2021-07-12 19:20:11,005 [run_pretraining.py:  558]:	worker_index: 2, step: 2371, cost: 6.887799, mlm loss: 6.887799, speed: 0.985139 steps/s, speed: 7.881115 samples/s, speed: 4035.131083 tokens/s, learning rate: 2.370e-05, loss_scalings: 2814.750488, pp_loss: 7.034199
[INFO] 2021-07-12 19:20:11,005 [run_pretraining.py:  512]:	********exe.run_2371******* 
[INFO] 2021-07-12 19:20:11,979 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:11,980 [run_pretraining.py:  534]:	loss/total_loss, 6.9567155838012695, 2372
[INFO] 2021-07-12 19:20:11,980 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9567155838012695, 2372
[INFO] 2021-07-12 19:20:11,980 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.370999936829321e-05, 2372
[INFO] 2021-07-12 19:20:11,980 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2372
[INFO] 2021-07-12 19:20:11,980 [run_pretraining.py:  558]:	worker_index: 2, step: 2372, cost: 6.956716, mlm loss: 6.956716, speed: 1.026070 steps/s, speed: 8.208561 samples/s, speed: 4202.783444 tokens/s, learning rate: 2.371e-05, loss_scalings: 2814.750488, pp_loss: 7.446709
[INFO] 2021-07-12 19:20:11,980 [run_pretraining.py:  512]:	********exe.run_2372******* 
[INFO] 2021-07-12 19:20:12,945 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:12,946 [run_pretraining.py:  534]:	loss/total_loss, 7.70755672454834, 2373
[INFO] 2021-07-12 19:20:12,946 [run_pretraining.py:  535]:	loss/mlm_loss, 7.70755672454834, 2373
[INFO] 2021-07-12 19:20:12,946 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3720000172033906e-05, 2373
[INFO] 2021-07-12 19:20:12,946 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2373
[INFO] 2021-07-12 19:20:12,946 [run_pretraining.py:  558]:	worker_index: 2, step: 2373, cost: 7.707557, mlm loss: 7.707557, speed: 1.035756 steps/s, speed: 8.286052 samples/s, speed: 4242.458389 tokens/s, learning rate: 2.372e-05, loss_scalings: 2814.750488, pp_loss: 7.427064
[INFO] 2021-07-12 19:20:12,946 [run_pretraining.py:  512]:	********exe.run_2373******* 
[INFO] 2021-07-12 19:20:13,920 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:13,921 [run_pretraining.py:  534]:	loss/total_loss, 6.777495384216309, 2374
[INFO] 2021-07-12 19:20:13,921 [run_pretraining.py:  535]:	loss/mlm_loss, 6.777495384216309, 2374
[INFO] 2021-07-12 19:20:13,921 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3729999156785198e-05, 2374
[INFO] 2021-07-12 19:20:13,921 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2374
[INFO] 2021-07-12 19:20:13,921 [run_pretraining.py:  558]:	worker_index: 2, step: 2374, cost: 6.777495, mlm loss: 6.777495, speed: 1.026700 steps/s, speed: 8.213597 samples/s, speed: 4205.361555 tokens/s, learning rate: 2.373e-05, loss_scalings: 2814.750488, pp_loss: 6.997252
[INFO] 2021-07-12 19:20:13,921 [run_pretraining.py:  512]:	********exe.run_2374******* 
[INFO] 2021-07-12 19:20:14,899 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:14,899 [run_pretraining.py:  534]:	loss/total_loss, 6.891136646270752, 2375
[INFO] 2021-07-12 19:20:14,899 [run_pretraining.py:  535]:	loss/mlm_loss, 6.891136646270752, 2375
[INFO] 2021-07-12 19:20:14,899 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.373999814153649e-05, 2375
[INFO] 2021-07-12 19:20:14,900 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2375
[INFO] 2021-07-12 19:20:14,900 [run_pretraining.py:  558]:	worker_index: 2, step: 2375, cost: 6.891137, mlm loss: 6.891137, speed: 1.022326 steps/s, speed: 8.178612 samples/s, speed: 4187.449301 tokens/s, learning rate: 2.374e-05, loss_scalings: 2814.750488, pp_loss: 6.574128
[INFO] 2021-07-12 19:20:14,900 [run_pretraining.py:  512]:	********exe.run_2375******* 
[INFO] 2021-07-12 19:20:15,882 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:15,882 [run_pretraining.py:  534]:	loss/total_loss, 7.728082656860352, 2376
[INFO] 2021-07-12 19:20:15,882 [run_pretraining.py:  535]:	loss/mlm_loss, 7.728082656860352, 2376
[INFO] 2021-07-12 19:20:15,882 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3749998945277184e-05, 2376
[INFO] 2021-07-12 19:20:15,882 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2376
[INFO] 2021-07-12 19:20:15,883 [run_pretraining.py:  558]:	worker_index: 2, step: 2376, cost: 7.728083, mlm loss: 7.728083, speed: 1.017987 steps/s, speed: 8.143894 samples/s, speed: 4169.673810 tokens/s, learning rate: 2.375e-05, loss_scalings: 2814.750488, pp_loss: 7.412047
[INFO] 2021-07-12 19:20:15,883 [run_pretraining.py:  512]:	********exe.run_2376******* 
[INFO] 2021-07-12 19:20:16,849 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:16,849 [run_pretraining.py:  534]:	loss/total_loss, 7.06673526763916, 2377
[INFO] 2021-07-12 19:20:16,849 [run_pretraining.py:  535]:	loss/mlm_loss, 7.06673526763916, 2377
[INFO] 2021-07-12 19:20:16,850 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.375999974901788e-05, 2377
[INFO] 2021-07-12 19:20:16,850 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2377
[INFO] 2021-07-12 19:20:16,850 [run_pretraining.py:  558]:	worker_index: 2, step: 2377, cost: 7.066735, mlm loss: 7.066735, speed: 1.034614 steps/s, speed: 8.276911 samples/s, speed: 4237.778475 tokens/s, learning rate: 2.376e-05, loss_scalings: 2814.750488, pp_loss: 7.223735
[INFO] 2021-07-12 19:20:16,850 [run_pretraining.py:  512]:	********exe.run_2377******* 
[INFO] 2021-07-12 19:20:17,817 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:17,818 [run_pretraining.py:  534]:	loss/total_loss, 7.156429290771484, 2378
[INFO] 2021-07-12 19:20:17,818 [run_pretraining.py:  535]:	loss/mlm_loss, 7.156429290771484, 2378
[INFO] 2021-07-12 19:20:17,818 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.376999873376917e-05, 2378
[INFO] 2021-07-12 19:20:17,818 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2378
[INFO] 2021-07-12 19:20:17,818 [run_pretraining.py:  558]:	worker_index: 2, step: 2378, cost: 7.156429, mlm loss: 7.156429, speed: 1.033362 steps/s, speed: 8.266892 samples/s, speed: 4232.648947 tokens/s, learning rate: 2.377e-05, loss_scalings: 2814.750488, pp_loss: 7.297500
[INFO] 2021-07-12 19:20:17,818 [run_pretraining.py:  512]:	********exe.run_2378******* 
[INFO] 2021-07-12 19:20:18,729 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:18,730 [run_pretraining.py:  534]:	loss/total_loss, 6.573616981506348, 2379
[INFO] 2021-07-12 19:20:18,730 [run_pretraining.py:  535]:	loss/mlm_loss, 6.573616981506348, 2379
[INFO] 2021-07-12 19:20:18,730 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3779999537509866e-05, 2379
[INFO] 2021-07-12 19:20:18,730 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2379
[INFO] 2021-07-12 19:20:18,730 [run_pretraining.py:  558]:	worker_index: 2, step: 2379, cost: 6.573617, mlm loss: 6.573617, speed: 1.096892 steps/s, speed: 8.775135 samples/s, speed: 4492.869198 tokens/s, learning rate: 2.378e-05, loss_scalings: 2814.750488, pp_loss: 7.178942
[INFO] 2021-07-12 19:20:18,730 [run_pretraining.py:  512]:	********exe.run_2379******* 
[INFO] 2021-07-12 19:20:19,677 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:19,677 [run_pretraining.py:  534]:	loss/total_loss, 6.922221660614014, 2380
[INFO] 2021-07-12 19:20:19,678 [run_pretraining.py:  535]:	loss/mlm_loss, 6.922221660614014, 2380
[INFO] 2021-07-12 19:20:19,678 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.379000034125056e-05, 2380
[INFO] 2021-07-12 19:20:19,678 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2380
[INFO] 2021-07-12 19:20:19,678 [run_pretraining.py:  558]:	worker_index: 2, step: 2380, cost: 6.922222, mlm loss: 6.922222, speed: 1.056061 steps/s, speed: 8.448491 samples/s, speed: 4325.627343 tokens/s, learning rate: 2.379e-05, loss_scalings: 2814.750488, pp_loss: 7.395546
[INFO] 2021-07-12 19:20:19,678 [run_pretraining.py:  512]:	********exe.run_2380******* 
[INFO] 2021-07-12 19:20:20,600 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:20,600 [run_pretraining.py:  534]:	loss/total_loss, 7.326704502105713, 2381
[INFO] 2021-07-12 19:20:20,600 [run_pretraining.py:  535]:	loss/mlm_loss, 7.326704502105713, 2381
[INFO] 2021-07-12 19:20:20,600 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3799999326001853e-05, 2381
[INFO] 2021-07-12 19:20:20,600 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2381
[INFO] 2021-07-12 19:20:20,600 [run_pretraining.py:  558]:	worker_index: 2, step: 2381, cost: 7.326705, mlm loss: 7.326705, speed: 1.084688 steps/s, speed: 8.677506 samples/s, speed: 4442.883092 tokens/s, learning rate: 2.380e-05, loss_scalings: 2814.750488, pp_loss: 7.154495
[INFO] 2021-07-12 19:20:20,600 [run_pretraining.py:  512]:	********exe.run_2381******* 
[INFO] 2021-07-12 19:20:21,504 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:21,505 [run_pretraining.py:  534]:	loss/total_loss, 8.08051586151123, 2382
[INFO] 2021-07-12 19:20:21,505 [run_pretraining.py:  535]:	loss/mlm_loss, 8.08051586151123, 2382
[INFO] 2021-07-12 19:20:21,505 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3810000129742548e-05, 2382
[INFO] 2021-07-12 19:20:21,505 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2382
[INFO] 2021-07-12 19:20:21,505 [run_pretraining.py:  558]:	worker_index: 2, step: 2382, cost: 8.080516, mlm loss: 8.080516, speed: 1.105873 steps/s, speed: 8.846981 samples/s, speed: 4529.654350 tokens/s, learning rate: 2.381e-05, loss_scalings: 2814.750488, pp_loss: 7.254006
[INFO] 2021-07-12 19:20:21,505 [run_pretraining.py:  512]:	********exe.run_2382******* 
[INFO] 2021-07-12 19:20:22,414 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:22,415 [run_pretraining.py:  534]:	loss/total_loss, 7.747056007385254, 2383
[INFO] 2021-07-12 19:20:22,415 [run_pretraining.py:  535]:	loss/mlm_loss, 7.747056007385254, 2383
[INFO] 2021-07-12 19:20:22,415 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.381999911449384e-05, 2383
[INFO] 2021-07-12 19:20:22,415 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2383
[INFO] 2021-07-12 19:20:22,415 [run_pretraining.py:  558]:	worker_index: 2, step: 2383, cost: 7.747056, mlm loss: 7.747056, speed: 1.099993 steps/s, speed: 8.799946 samples/s, speed: 4505.572393 tokens/s, learning rate: 2.382e-05, loss_scalings: 2814.750488, pp_loss: 7.038517
[INFO] 2021-07-12 19:20:22,415 [run_pretraining.py:  512]:	********exe.run_2383******* 
[INFO] 2021-07-12 19:20:23,317 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:23,317 [run_pretraining.py:  534]:	loss/total_loss, 7.18135404586792, 2384
[INFO] 2021-07-12 19:20:23,318 [run_pretraining.py:  535]:	loss/mlm_loss, 7.18135404586792, 2384
[INFO] 2021-07-12 19:20:23,318 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.382999809924513e-05, 2384
[INFO] 2021-07-12 19:20:23,318 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2384
[INFO] 2021-07-12 19:20:23,318 [run_pretraining.py:  558]:	worker_index: 2, step: 2384, cost: 7.181354, mlm loss: 7.181354, speed: 1.108337 steps/s, speed: 8.866696 samples/s, speed: 4539.748252 tokens/s, learning rate: 2.383e-05, loss_scalings: 2814.750488, pp_loss: 6.475618
[INFO] 2021-07-12 19:20:23,318 [run_pretraining.py:  512]:	********exe.run_2384******* 
[INFO] 2021-07-12 19:20:24,227 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:24,228 [run_pretraining.py:  534]:	loss/total_loss, 7.207369804382324, 2385
[INFO] 2021-07-12 19:20:24,228 [run_pretraining.py:  535]:	loss/mlm_loss, 7.207369804382324, 2385
[INFO] 2021-07-12 19:20:24,228 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3839998902985826e-05, 2385
[INFO] 2021-07-12 19:20:24,228 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2385
[INFO] 2021-07-12 19:20:24,228 [run_pretraining.py:  558]:	worker_index: 2, step: 2385, cost: 7.207370, mlm loss: 7.207370, speed: 1.099426 steps/s, speed: 8.795407 samples/s, speed: 4503.248152 tokens/s, learning rate: 2.384e-05, loss_scalings: 2814.750488, pp_loss: 7.338633
[INFO] 2021-07-12 19:20:24,228 [run_pretraining.py:  512]:	********exe.run_2385******* 
[INFO] 2021-07-12 19:20:25,131 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:25,131 [run_pretraining.py:  534]:	loss/total_loss, 7.547870635986328, 2386
[INFO] 2021-07-12 19:20:25,132 [run_pretraining.py:  535]:	loss/mlm_loss, 7.547870635986328, 2386
[INFO] 2021-07-12 19:20:25,132 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.384999970672652e-05, 2386
[INFO] 2021-07-12 19:20:25,132 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2386
[INFO] 2021-07-12 19:20:25,132 [run_pretraining.py:  558]:	worker_index: 2, step: 2386, cost: 7.547871, mlm loss: 7.547871, speed: 1.107160 steps/s, speed: 8.857282 samples/s, speed: 4534.928503 tokens/s, learning rate: 2.385e-05, loss_scalings: 2814.750488, pp_loss: 6.482391
[INFO] 2021-07-12 19:20:25,132 [run_pretraining.py:  512]:	********exe.run_2386******* 
[INFO] 2021-07-12 19:20:26,043 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:26,044 [run_pretraining.py:  534]:	loss/total_loss, 7.368864059448242, 2387
[INFO] 2021-07-12 19:20:26,044 [run_pretraining.py:  535]:	loss/mlm_loss, 7.368864059448242, 2387
[INFO] 2021-07-12 19:20:26,044 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3859998691477813e-05, 2387
[INFO] 2021-07-12 19:20:26,044 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2387
[INFO] 2021-07-12 19:20:26,044 [run_pretraining.py:  558]:	worker_index: 2, step: 2387, cost: 7.368864, mlm loss: 7.368864, speed: 1.097055 steps/s, speed: 8.776441 samples/s, speed: 4493.537857 tokens/s, learning rate: 2.386e-05, loss_scalings: 2814.750488, pp_loss: 7.613265
[INFO] 2021-07-12 19:20:26,044 [run_pretraining.py:  512]:	********exe.run_2387******* 
[INFO] 2021-07-12 19:20:26,947 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:26,947 [run_pretraining.py:  534]:	loss/total_loss, 7.621994972229004, 2388
[INFO] 2021-07-12 19:20:26,947 [run_pretraining.py:  535]:	loss/mlm_loss, 7.621994972229004, 2388
[INFO] 2021-07-12 19:20:26,947 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3869999495218508e-05, 2388
[INFO] 2021-07-12 19:20:26,947 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2388
[INFO] 2021-07-12 19:20:26,948 [run_pretraining.py:  558]:	worker_index: 2, step: 2388, cost: 7.621995, mlm loss: 7.621995, speed: 1.107394 steps/s, speed: 8.859155 samples/s, speed: 4535.887562 tokens/s, learning rate: 2.387e-05, loss_scalings: 2814.750488, pp_loss: 7.344117
[INFO] 2021-07-12 19:20:26,948 [run_pretraining.py:  512]:	********exe.run_2388******* 
[INFO] 2021-07-12 19:20:27,850 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:27,850 [run_pretraining.py:  534]:	loss/total_loss, 7.226454734802246, 2389
[INFO] 2021-07-12 19:20:27,850 [run_pretraining.py:  535]:	loss/mlm_loss, 7.226454734802246, 2389
[INFO] 2021-07-12 19:20:27,850 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3880000298959203e-05, 2389
[INFO] 2021-07-12 19:20:27,850 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2389
[INFO] 2021-07-12 19:20:27,850 [run_pretraining.py:  558]:	worker_index: 2, step: 2389, cost: 7.226455, mlm loss: 7.226455, speed: 1.108374 steps/s, speed: 8.866991 samples/s, speed: 4539.899409 tokens/s, learning rate: 2.388e-05, loss_scalings: 2814.750488, pp_loss: 7.102619
[INFO] 2021-07-12 19:20:27,850 [run_pretraining.py:  512]:	********exe.run_2389******* 
[INFO] 2021-07-12 19:20:28,793 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:28,793 [run_pretraining.py:  534]:	loss/total_loss, 8.072564125061035, 2390
[INFO] 2021-07-12 19:20:28,794 [run_pretraining.py:  535]:	loss/mlm_loss, 8.072564125061035, 2390
[INFO] 2021-07-12 19:20:28,794 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3889999283710495e-05, 2390
[INFO] 2021-07-12 19:20:28,794 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2390
[INFO] 2021-07-12 19:20:28,794 [run_pretraining.py:  558]:	worker_index: 2, step: 2390, cost: 8.072564, mlm loss: 8.072564, speed: 1.060611 steps/s, speed: 8.484888 samples/s, speed: 4344.262731 tokens/s, learning rate: 2.389e-05, loss_scalings: 2814.750488, pp_loss: 7.392073
[INFO] 2021-07-12 19:20:28,794 [run_pretraining.py:  512]:	********exe.run_2390******* 
[INFO] 2021-07-12 19:20:29,711 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:29,711 [run_pretraining.py:  534]:	loss/total_loss, 6.796710014343262, 2391
[INFO] 2021-07-12 19:20:29,711 [run_pretraining.py:  535]:	loss/mlm_loss, 6.796710014343262, 2391
[INFO] 2021-07-12 19:20:29,712 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3899998268461786e-05, 2391
[INFO] 2021-07-12 19:20:29,712 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2391
[INFO] 2021-07-12 19:20:29,712 [run_pretraining.py:  558]:	worker_index: 2, step: 2391, cost: 6.796710, mlm loss: 6.796710, speed: 1.090250 steps/s, speed: 8.722002 samples/s, speed: 4465.665112 tokens/s, learning rate: 2.390e-05, loss_scalings: 2814.750488, pp_loss: 6.901455
[INFO] 2021-07-12 19:20:29,712 [run_pretraining.py:  512]:	********exe.run_2391******* 
[INFO] 2021-07-12 19:20:30,621 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:30,622 [run_pretraining.py:  534]:	loss/total_loss, 7.09929895401001, 2392
[INFO] 2021-07-12 19:20:30,622 [run_pretraining.py:  535]:	loss/mlm_loss, 7.09929895401001, 2392
[INFO] 2021-07-12 19:20:30,622 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.390999907220248e-05, 2392
[INFO] 2021-07-12 19:20:30,622 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2392
[INFO] 2021-07-12 19:20:30,622 [run_pretraining.py:  558]:	worker_index: 2, step: 2392, cost: 7.099299, mlm loss: 7.099299, speed: 1.099126 steps/s, speed: 8.793009 samples/s, speed: 4502.020863 tokens/s, learning rate: 2.391e-05, loss_scalings: 2814.750488, pp_loss: 7.204716
[INFO] 2021-07-12 19:20:30,622 [run_pretraining.py:  512]:	********exe.run_2392******* 
[INFO] 2021-07-12 19:20:31,529 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:31,529 [run_pretraining.py:  534]:	loss/total_loss, 6.970235824584961, 2393
[INFO] 2021-07-12 19:20:31,529 [run_pretraining.py:  535]:	loss/mlm_loss, 6.970235824584961, 2393
[INFO] 2021-07-12 19:20:31,530 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3919999875943176e-05, 2393
[INFO] 2021-07-12 19:20:31,530 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2393
[INFO] 2021-07-12 19:20:31,530 [run_pretraining.py:  558]:	worker_index: 2, step: 2393, cost: 6.970236, mlm loss: 6.970236, speed: 1.102538 steps/s, speed: 8.820305 samples/s, speed: 4515.995943 tokens/s, learning rate: 2.392e-05, loss_scalings: 2814.750488, pp_loss: 7.039927
[INFO] 2021-07-12 19:20:31,530 [run_pretraining.py:  512]:	********exe.run_2393******* 
[INFO] 2021-07-12 19:20:32,428 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:32,429 [run_pretraining.py:  534]:	loss/total_loss, 7.676955223083496, 2394
[INFO] 2021-07-12 19:20:32,429 [run_pretraining.py:  535]:	loss/mlm_loss, 7.676955223083496, 2394
[INFO] 2021-07-12 19:20:32,429 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3929998860694468e-05, 2394
[INFO] 2021-07-12 19:20:32,429 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2394
[INFO] 2021-07-12 19:20:32,429 [run_pretraining.py:  558]:	worker_index: 2, step: 2394, cost: 7.676955, mlm loss: 7.676955, speed: 1.112311 steps/s, speed: 8.898492 samples/s, speed: 4556.027682 tokens/s, learning rate: 2.393e-05, loss_scalings: 2814.750488, pp_loss: 6.816047
[INFO] 2021-07-12 19:20:32,429 [run_pretraining.py:  512]:	********exe.run_2394******* 
[INFO] 2021-07-12 19:20:33,343 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:33,343 [run_pretraining.py:  534]:	loss/total_loss, 6.954537868499756, 2395
[INFO] 2021-07-12 19:20:33,343 [run_pretraining.py:  535]:	loss/mlm_loss, 6.954537868499756, 2395
[INFO] 2021-07-12 19:20:33,343 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3939999664435163e-05, 2395
[INFO] 2021-07-12 19:20:33,343 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2395
[INFO] 2021-07-12 19:20:33,343 [run_pretraining.py:  558]:	worker_index: 2, step: 2395, cost: 6.954538, mlm loss: 6.954538, speed: 1.094702 steps/s, speed: 8.757614 samples/s, speed: 4483.898606 tokens/s, learning rate: 2.394e-05, loss_scalings: 2814.750488, pp_loss: 7.635684
[INFO] 2021-07-12 19:20:33,343 [run_pretraining.py:  512]:	********exe.run_2395******* 
[INFO] 2021-07-12 19:20:34,255 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:34,256 [run_pretraining.py:  534]:	loss/total_loss, 7.302677154541016, 2396
[INFO] 2021-07-12 19:20:34,257 [run_pretraining.py:  535]:	loss/mlm_loss, 7.302677154541016, 2396
[INFO] 2021-07-12 19:20:34,258 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3949998649186455e-05, 2396
[INFO] 2021-07-12 19:20:34,259 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2396
[INFO] 2021-07-12 19:20:34,260 [run_pretraining.py:  558]:	worker_index: 2, step: 2396, cost: 7.302677, mlm loss: 7.302677, speed: 1.095838 steps/s, speed: 8.766700 samples/s, speed: 4488.550630 tokens/s, learning rate: 2.395e-05, loss_scalings: 2814.750488, pp_loss: 6.664574
[INFO] 2021-07-12 19:20:34,261 [run_pretraining.py:  512]:	********exe.run_2396******* 
[INFO] 2021-07-12 19:20:35,157 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:35,158 [run_pretraining.py:  534]:	loss/total_loss, 7.675363540649414, 2397
[INFO] 2021-07-12 19:20:35,158 [run_pretraining.py:  535]:	loss/mlm_loss, 7.675363540649414, 2397
[INFO] 2021-07-12 19:20:35,158 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.395999945292715e-05, 2397
[INFO] 2021-07-12 19:20:35,158 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2397
[INFO] 2021-07-12 19:20:35,158 [run_pretraining.py:  558]:	worker_index: 2, step: 2397, cost: 7.675364, mlm loss: 7.675364, speed: 1.115955 steps/s, speed: 8.927639 samples/s, speed: 4570.951035 tokens/s, learning rate: 2.396e-05, loss_scalings: 2814.750488, pp_loss: 6.991677
[INFO] 2021-07-12 19:20:35,158 [run_pretraining.py:  512]:	********exe.run_2397******* 
[INFO] 2021-07-12 19:20:36,065 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:36,066 [run_pretraining.py:  534]:	loss/total_loss, 7.013150215148926, 2398
[INFO] 2021-07-12 19:20:36,066 [run_pretraining.py:  535]:	loss/mlm_loss, 7.013150215148926, 2398
[INFO] 2021-07-12 19:20:36,066 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3970000256667845e-05, 2398
[INFO] 2021-07-12 19:20:36,066 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2398
[INFO] 2021-07-12 19:20:36,066 [run_pretraining.py:  558]:	worker_index: 2, step: 2398, cost: 7.013150, mlm loss: 7.013150, speed: 1.102252 steps/s, speed: 8.818019 samples/s, speed: 4514.825766 tokens/s, learning rate: 2.397e-05, loss_scalings: 2814.750488, pp_loss: 7.105136
[INFO] 2021-07-12 19:20:36,066 [run_pretraining.py:  512]:	********exe.run_2398******* 
[INFO] 2021-07-12 19:20:36,969 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:36,970 [run_pretraining.py:  534]:	loss/total_loss, 7.530752182006836, 2399
[INFO] 2021-07-12 19:20:36,970 [run_pretraining.py:  535]:	loss/mlm_loss, 7.530752182006836, 2399
[INFO] 2021-07-12 19:20:36,970 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3979999241419137e-05, 2399
[INFO] 2021-07-12 19:20:36,970 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2399
[INFO] 2021-07-12 19:20:36,970 [run_pretraining.py:  558]:	worker_index: 2, step: 2399, cost: 7.530752, mlm loss: 7.530752, speed: 1.106696 steps/s, speed: 8.853569 samples/s, speed: 4533.027150 tokens/s, learning rate: 2.398e-05, loss_scalings: 2814.750488, pp_loss: 7.320099
[INFO] 2021-07-12 19:20:36,970 [run_pretraining.py:  512]:	********exe.run_2399******* 
[INFO] 2021-07-12 19:20:37,868 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:37,868 [run_pretraining.py:  534]:	loss/total_loss, 7.382962226867676, 2400
[INFO] 2021-07-12 19:20:37,868 [run_pretraining.py:  535]:	loss/mlm_loss, 7.382962226867676, 2400
[INFO] 2021-07-12 19:20:37,868 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3989998226170428e-05, 2400
[INFO] 2021-07-12 19:20:37,868 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2400
[INFO] 2021-07-12 19:20:37,869 [run_pretraining.py:  558]:	worker_index: 2, step: 2400, cost: 7.382962, mlm loss: 7.382962, speed: 1.113784 steps/s, speed: 8.910271 samples/s, speed: 4562.058727 tokens/s, learning rate: 2.399e-05, loss_scalings: 2814.750488, pp_loss: 7.168526
[INFO] 2021-07-12 19:20:37,869 [run_pretraining.py:  512]:	********exe.run_2400******* 
[INFO] 2021-07-12 19:20:38,775 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:38,776 [run_pretraining.py:  534]:	loss/total_loss, 7.323178291320801, 2401
[INFO] 2021-07-12 19:20:38,776 [run_pretraining.py:  535]:	loss/mlm_loss, 7.323178291320801, 2401
[INFO] 2021-07-12 19:20:38,776 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3999999029911123e-05, 2401
[INFO] 2021-07-12 19:20:38,776 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2401
[INFO] 2021-07-12 19:20:38,776 [run_pretraining.py:  558]:	worker_index: 2, step: 2401, cost: 7.323178, mlm loss: 7.323178, speed: 1.102573 steps/s, speed: 8.820587 samples/s, speed: 4516.140774 tokens/s, learning rate: 2.400e-05, loss_scalings: 2814.750488, pp_loss: 7.212459
[INFO] 2021-07-12 19:20:38,776 [run_pretraining.py:  512]:	********exe.run_2401******* 
[INFO] 2021-07-12 19:20:39,684 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:39,685 [run_pretraining.py:  534]:	loss/total_loss, 7.162559509277344, 2402
[INFO] 2021-07-12 19:20:39,685 [run_pretraining.py:  535]:	loss/mlm_loss, 7.162559509277344, 2402
[INFO] 2021-07-12 19:20:39,685 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.400999983365182e-05, 2402
[INFO] 2021-07-12 19:20:39,685 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2402
[INFO] 2021-07-12 19:20:39,685 [run_pretraining.py:  558]:	worker_index: 2, step: 2402, cost: 7.162560, mlm loss: 7.162560, speed: 1.101066 steps/s, speed: 8.808530 samples/s, speed: 4509.967599 tokens/s, learning rate: 2.401e-05, loss_scalings: 2814.750488, pp_loss: 7.430794
[INFO] 2021-07-12 19:20:39,685 [run_pretraining.py:  512]:	********exe.run_2402******* 
[INFO] 2021-07-12 19:20:40,592 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:40,593 [run_pretraining.py:  534]:	loss/total_loss, 7.5529656410217285, 2403
[INFO] 2021-07-12 19:20:40,593 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5529656410217285, 2403
[INFO] 2021-07-12 19:20:40,593 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.401999881840311e-05, 2403
[INFO] 2021-07-12 19:20:40,593 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2403
[INFO] 2021-07-12 19:20:40,593 [run_pretraining.py:  558]:	worker_index: 2, step: 2403, cost: 7.552966, mlm loss: 7.552966, speed: 1.101912 steps/s, speed: 8.815295 samples/s, speed: 4513.430891 tokens/s, learning rate: 2.402e-05, loss_scalings: 2814.750488, pp_loss: 7.144942
[INFO] 2021-07-12 19:20:40,593 [run_pretraining.py:  512]:	********exe.run_2403******* 
[INFO] 2021-07-12 19:20:41,497 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:41,498 [run_pretraining.py:  534]:	loss/total_loss, 7.247114181518555, 2404
[INFO] 2021-07-12 19:20:41,498 [run_pretraining.py:  535]:	loss/mlm_loss, 7.247114181518555, 2404
[INFO] 2021-07-12 19:20:41,498 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4029999622143805e-05, 2404
[INFO] 2021-07-12 19:20:41,498 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2404
[INFO] 2021-07-12 19:20:41,498 [run_pretraining.py:  558]:	worker_index: 2, step: 2404, cost: 7.247114, mlm loss: 7.247114, speed: 1.105539 steps/s, speed: 8.844316 samples/s, speed: 4528.289686 tokens/s, learning rate: 2.403e-05, loss_scalings: 2814.750488, pp_loss: 7.329929
[INFO] 2021-07-12 19:20:41,498 [run_pretraining.py:  512]:	********exe.run_2404******* 
[INFO] 2021-07-12 19:20:42,406 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:42,407 [run_pretraining.py:  534]:	loss/total_loss, 7.434772968292236, 2405
[INFO] 2021-07-12 19:20:42,407 [run_pretraining.py:  535]:	loss/mlm_loss, 7.434772968292236, 2405
[INFO] 2021-07-12 19:20:42,407 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.40400004258845e-05, 2405
[INFO] 2021-07-12 19:20:42,408 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2405
[INFO] 2021-07-12 19:20:42,408 [run_pretraining.py:  558]:	worker_index: 2, step: 2405, cost: 7.434773, mlm loss: 7.434773, speed: 1.100417 steps/s, speed: 8.803333 samples/s, speed: 4507.306505 tokens/s, learning rate: 2.404e-05, loss_scalings: 2814.750488, pp_loss: 7.384564
[INFO] 2021-07-12 19:20:42,408 [run_pretraining.py:  512]:	********exe.run_2405******* 
[INFO] 2021-07-12 19:20:43,347 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:43,348 [run_pretraining.py:  534]:	loss/total_loss, 7.161011695861816, 2406
[INFO] 2021-07-12 19:20:43,348 [run_pretraining.py:  535]:	loss/mlm_loss, 7.161011695861816, 2406
[INFO] 2021-07-12 19:20:43,348 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4049999410635792e-05, 2406
[INFO] 2021-07-12 19:20:43,348 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2406
[INFO] 2021-07-12 19:20:43,348 [run_pretraining.py:  558]:	worker_index: 2, step: 2406, cost: 7.161012, mlm loss: 7.161012, speed: 1.064162 steps/s, speed: 8.513296 samples/s, speed: 4358.807480 tokens/s, learning rate: 2.405e-05, loss_scalings: 2814.750488, pp_loss: 7.409524
[INFO] 2021-07-12 19:20:43,348 [run_pretraining.py:  512]:	********exe.run_2406******* 
[INFO] 2021-07-12 19:20:44,253 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:44,253 [run_pretraining.py:  534]:	loss/total_loss, 7.481451988220215, 2407
[INFO] 2021-07-12 19:20:44,253 [run_pretraining.py:  535]:	loss/mlm_loss, 7.481451988220215, 2407
[INFO] 2021-07-12 19:20:44,254 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4060000214376487e-05, 2407
[INFO] 2021-07-12 19:20:44,254 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2407
[INFO] 2021-07-12 19:20:44,254 [run_pretraining.py:  558]:	worker_index: 2, step: 2407, cost: 7.481452, mlm loss: 7.481452, speed: 1.104800 steps/s, speed: 8.838399 samples/s, speed: 4525.260042 tokens/s, learning rate: 2.406e-05, loss_scalings: 2814.750488, pp_loss: 7.838862
[INFO] 2021-07-12 19:20:44,254 [run_pretraining.py:  512]:	********exe.run_2407******* 
[INFO] 2021-07-12 19:20:45,163 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:45,164 [run_pretraining.py:  534]:	loss/total_loss, 7.280715465545654, 2408
[INFO] 2021-07-12 19:20:45,164 [run_pretraining.py:  535]:	loss/mlm_loss, 7.280715465545654, 2408
[INFO] 2021-07-12 19:20:45,164 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.406999919912778e-05, 2408
[INFO] 2021-07-12 19:20:45,164 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2408
[INFO] 2021-07-12 19:20:45,164 [run_pretraining.py:  558]:	worker_index: 2, step: 2408, cost: 7.280715, mlm loss: 7.280715, speed: 1.099055 steps/s, speed: 8.792438 samples/s, speed: 4501.728301 tokens/s, learning rate: 2.407e-05, loss_scalings: 2814.750488, pp_loss: 7.308241
[INFO] 2021-07-12 19:20:45,164 [run_pretraining.py:  512]:	********exe.run_2408******* 
[INFO] 2021-07-12 19:20:46,060 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:46,060 [run_pretraining.py:  534]:	loss/total_loss, 7.28162956237793, 2409
[INFO] 2021-07-12 19:20:46,060 [run_pretraining.py:  535]:	loss/mlm_loss, 7.28162956237793, 2409
[INFO] 2021-07-12 19:20:46,060 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.407999818387907e-05, 2409
[INFO] 2021-07-12 19:20:46,060 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2409
[INFO] 2021-07-12 19:20:46,060 [run_pretraining.py:  558]:	worker_index: 2, step: 2409, cost: 7.281630, mlm loss: 7.281630, speed: 1.116376 steps/s, speed: 8.931006 samples/s, speed: 4572.674994 tokens/s, learning rate: 2.408e-05, loss_scalings: 2814.750488, pp_loss: 7.277975
[INFO] 2021-07-12 19:20:46,061 [run_pretraining.py:  512]:	********exe.run_2409******* 
[INFO] 2021-07-12 19:20:46,970 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:46,971 [run_pretraining.py:  534]:	loss/total_loss, 7.1712422370910645, 2410
[INFO] 2021-07-12 19:20:46,971 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1712422370910645, 2410
[INFO] 2021-07-12 19:20:46,971 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4089998987619765e-05, 2410
[INFO] 2021-07-12 19:20:46,971 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2410
[INFO] 2021-07-12 19:20:46,971 [run_pretraining.py:  558]:	worker_index: 2, step: 2410, cost: 7.171242, mlm loss: 7.171242, speed: 1.099095 steps/s, speed: 8.792758 samples/s, speed: 4501.892272 tokens/s, learning rate: 2.409e-05, loss_scalings: 2814.750488, pp_loss: 7.646949
[INFO] 2021-07-12 19:20:46,971 [run_pretraining.py:  512]:	********exe.run_2410******* 
[INFO] 2021-07-12 19:20:47,882 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:47,882 [run_pretraining.py:  534]:	loss/total_loss, 7.133558750152588, 2411
[INFO] 2021-07-12 19:20:47,882 [run_pretraining.py:  535]:	loss/mlm_loss, 7.133558750152588, 2411
[INFO] 2021-07-12 19:20:47,882 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.409999979136046e-05, 2411
[INFO] 2021-07-12 19:20:47,882 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2411
[INFO] 2021-07-12 19:20:47,882 [run_pretraining.py:  558]:	worker_index: 2, step: 2411, cost: 7.133559, mlm loss: 7.133559, speed: 1.097776 steps/s, speed: 8.782211 samples/s, speed: 4496.492208 tokens/s, learning rate: 2.410e-05, loss_scalings: 2814.750488, pp_loss: 7.579333
[INFO] 2021-07-12 19:20:47,883 [run_pretraining.py:  512]:	********exe.run_2411******* 
[INFO] 2021-07-12 19:20:48,784 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:48,785 [run_pretraining.py:  534]:	loss/total_loss, 7.629530906677246, 2412
[INFO] 2021-07-12 19:20:48,785 [run_pretraining.py:  535]:	loss/mlm_loss, 7.629530906677246, 2412
[INFO] 2021-07-12 19:20:48,785 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4109998776111752e-05, 2412
[INFO] 2021-07-12 19:20:48,785 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2412
[INFO] 2021-07-12 19:20:48,785 [run_pretraining.py:  558]:	worker_index: 2, step: 2412, cost: 7.629531, mlm loss: 7.629531, speed: 1.108755 steps/s, speed: 8.870043 samples/s, speed: 4541.461956 tokens/s, learning rate: 2.411e-05, loss_scalings: 2814.750488, pp_loss: 7.401473
[INFO] 2021-07-12 19:20:48,785 [run_pretraining.py:  512]:	********exe.run_2412******* 
[INFO] 2021-07-12 19:20:49,696 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:49,697 [run_pretraining.py:  534]:	loss/total_loss, 7.745065689086914, 2413
[INFO] 2021-07-12 19:20:49,697 [run_pretraining.py:  535]:	loss/mlm_loss, 7.745065689086914, 2413
[INFO] 2021-07-12 19:20:49,697 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4119999579852447e-05, 2413
[INFO] 2021-07-12 19:20:49,697 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2413
[INFO] 2021-07-12 19:20:49,697 [run_pretraining.py:  558]:	worker_index: 2, step: 2413, cost: 7.745066, mlm loss: 7.745066, speed: 1.097118 steps/s, speed: 8.776946 samples/s, speed: 4493.796443 tokens/s, learning rate: 2.412e-05, loss_scalings: 2814.750488, pp_loss: 7.474758
[INFO] 2021-07-12 19:20:49,697 [run_pretraining.py:  512]:	********exe.run_2413******* 
[INFO] 2021-07-12 19:20:50,600 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:50,601 [run_pretraining.py:  534]:	loss/total_loss, 7.46497106552124, 2414
[INFO] 2021-07-12 19:20:50,601 [run_pretraining.py:  535]:	loss/mlm_loss, 7.46497106552124, 2414
[INFO] 2021-07-12 19:20:50,601 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4130000383593142e-05, 2414
[INFO] 2021-07-12 19:20:50,601 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2414
[INFO] 2021-07-12 19:20:50,601 [run_pretraining.py:  558]:	worker_index: 2, step: 2414, cost: 7.464971, mlm loss: 7.464971, speed: 1.106769 steps/s, speed: 8.854155 samples/s, speed: 4533.327383 tokens/s, learning rate: 2.413e-05, loss_scalings: 2814.750488, pp_loss: 7.186718
[INFO] 2021-07-12 19:20:50,601 [run_pretraining.py:  512]:	********exe.run_2414******* 
[INFO] 2021-07-12 19:20:51,506 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:51,506 [run_pretraining.py:  534]:	loss/total_loss, 7.000515937805176, 2415
[INFO] 2021-07-12 19:20:51,507 [run_pretraining.py:  535]:	loss/mlm_loss, 7.000515937805176, 2415
[INFO] 2021-07-12 19:20:51,507 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4139999368344434e-05, 2415
[INFO] 2021-07-12 19:20:51,507 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2415
[INFO] 2021-07-12 19:20:51,507 [run_pretraining.py:  558]:	worker_index: 2, step: 2415, cost: 7.000516, mlm loss: 7.000516, speed: 1.104917 steps/s, speed: 8.839332 samples/s, speed: 4525.738075 tokens/s, learning rate: 2.414e-05, loss_scalings: 2814.750488, pp_loss: 7.096112
[INFO] 2021-07-12 19:20:51,507 [run_pretraining.py:  512]:	********exe.run_2415******* 
[INFO] 2021-07-12 19:20:52,412 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:52,412 [run_pretraining.py:  534]:	loss/total_loss, 7.221182823181152, 2416
[INFO] 2021-07-12 19:20:52,412 [run_pretraining.py:  535]:	loss/mlm_loss, 7.221182823181152, 2416
[INFO] 2021-07-12 19:20:52,412 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.415000017208513e-05, 2416
[INFO] 2021-07-12 19:20:52,412 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2416
[INFO] 2021-07-12 19:20:52,412 [run_pretraining.py:  558]:	worker_index: 2, step: 2416, cost: 7.221183, mlm loss: 7.221183, speed: 1.104930 steps/s, speed: 8.839439 samples/s, speed: 4525.792918 tokens/s, learning rate: 2.415e-05, loss_scalings: 2814.750488, pp_loss: 7.137481
[INFO] 2021-07-12 19:20:52,413 [run_pretraining.py:  512]:	********exe.run_2416******* 
[INFO] 2021-07-12 19:20:53,373 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:53,374 [run_pretraining.py:  534]:	loss/total_loss, 7.727311134338379, 2417
[INFO] 2021-07-12 19:20:53,374 [run_pretraining.py:  535]:	loss/mlm_loss, 7.727311134338379, 2417
[INFO] 2021-07-12 19:20:53,374 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4160000975825824e-05, 2417
[INFO] 2021-07-12 19:20:53,374 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2417
[INFO] 2021-07-12 19:20:53,374 [run_pretraining.py:  558]:	worker_index: 2, step: 2417, cost: 7.727311, mlm loss: 7.727311, speed: 1.040308 steps/s, speed: 8.322463 samples/s, speed: 4261.101129 tokens/s, learning rate: 2.416e-05, loss_scalings: 2814.750488, pp_loss: 7.290181
[INFO] 2021-07-12 19:20:53,374 [run_pretraining.py:  512]:	********exe.run_2417******* 
[INFO] 2021-07-12 19:20:54,300 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:54,301 [run_pretraining.py:  534]:	loss/total_loss, 6.879878520965576, 2418
[INFO] 2021-07-12 19:20:54,301 [run_pretraining.py:  535]:	loss/mlm_loss, 6.879878520965576, 2418
[INFO] 2021-07-12 19:20:54,301 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4169998141587712e-05, 2418
[INFO] 2021-07-12 19:20:54,301 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2418
[INFO] 2021-07-12 19:20:54,301 [run_pretraining.py:  558]:	worker_index: 2, step: 2418, cost: 6.879879, mlm loss: 6.879879, speed: 1.079464 steps/s, speed: 8.635710 samples/s, speed: 4421.483629 tokens/s, learning rate: 2.417e-05, loss_scalings: 2814.750488, pp_loss: 7.378152
[INFO] 2021-07-12 19:20:54,301 [run_pretraining.py:  512]:	********exe.run_2418******* 
[INFO] 2021-07-12 19:20:55,208 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:55,209 [run_pretraining.py:  534]:	loss/total_loss, 7.0451555252075195, 2419
[INFO] 2021-07-12 19:20:55,209 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0451555252075195, 2419
[INFO] 2021-07-12 19:20:55,209 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4179998945328407e-05, 2419
[INFO] 2021-07-12 19:20:55,209 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2419
[INFO] 2021-07-12 19:20:55,209 [run_pretraining.py:  558]:	worker_index: 2, step: 2419, cost: 7.045156, mlm loss: 7.045156, speed: 1.102363 steps/s, speed: 8.818904 samples/s, speed: 4515.279049 tokens/s, learning rate: 2.418e-05, loss_scalings: 2814.750488, pp_loss: 6.449462
[INFO] 2021-07-12 19:20:55,209 [run_pretraining.py:  512]:	********exe.run_2419******* 
[INFO] 2021-07-12 19:20:56,116 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:56,117 [run_pretraining.py:  534]:	loss/total_loss, 6.9378437995910645, 2420
[INFO] 2021-07-12 19:20:56,117 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9378437995910645, 2420
[INFO] 2021-07-12 19:20:56,117 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4189999749069102e-05, 2420
[INFO] 2021-07-12 19:20:56,117 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2420
[INFO] 2021-07-12 19:20:56,117 [run_pretraining.py:  558]:	worker_index: 2, step: 2420, cost: 6.937844, mlm loss: 6.937844, speed: 1.101782 steps/s, speed: 8.814260 samples/s, speed: 4512.900923 tokens/s, learning rate: 2.419e-05, loss_scalings: 2814.750488, pp_loss: 7.117866
[INFO] 2021-07-12 19:20:56,117 [run_pretraining.py:  512]:	********exe.run_2420******* 
[INFO] 2021-07-12 19:20:57,031 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:57,032 [run_pretraining.py:  534]:	loss/total_loss, 7.279620170593262, 2421
[INFO] 2021-07-12 19:20:57,032 [run_pretraining.py:  535]:	loss/mlm_loss, 7.279620170593262, 2421
[INFO] 2021-07-12 19:20:57,032 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4199998733820394e-05, 2421
[INFO] 2021-07-12 19:20:57,032 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2421
[INFO] 2021-07-12 19:20:57,032 [run_pretraining.py:  558]:	worker_index: 2, step: 2421, cost: 7.279620, mlm loss: 7.279620, speed: 1.093741 steps/s, speed: 8.749930 samples/s, speed: 4479.964052 tokens/s, learning rate: 2.420e-05, loss_scalings: 2814.750488, pp_loss: 6.840470
[INFO] 2021-07-12 19:20:57,032 [run_pretraining.py:  512]:	********exe.run_2421******* 
[INFO] 2021-07-12 19:20:57,953 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:57,953 [run_pretraining.py:  534]:	loss/total_loss, 6.671192169189453, 2422
[INFO] 2021-07-12 19:20:57,953 [run_pretraining.py:  535]:	loss/mlm_loss, 6.671192169189453, 2422
[INFO] 2021-07-12 19:20:57,953 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.420999953756109e-05, 2422
[INFO] 2021-07-12 19:20:57,953 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2422
[INFO] 2021-07-12 19:20:57,953 [run_pretraining.py:  558]:	worker_index: 2, step: 2422, cost: 6.671192, mlm loss: 6.671192, speed: 1.086214 steps/s, speed: 8.689709 samples/s, speed: 4449.130790 tokens/s, learning rate: 2.421e-05, loss_scalings: 2814.750488, pp_loss: 6.645597
[INFO] 2021-07-12 19:20:57,953 [run_pretraining.py:  512]:	********exe.run_2422******* 
[INFO] 2021-07-12 19:20:58,874 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:58,874 [run_pretraining.py:  534]:	loss/total_loss, 6.453670501708984, 2423
[INFO] 2021-07-12 19:20:58,874 [run_pretraining.py:  535]:	loss/mlm_loss, 6.453670501708984, 2423
[INFO] 2021-07-12 19:20:58,874 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4220000341301784e-05, 2423
[INFO] 2021-07-12 19:20:58,874 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2423
[INFO] 2021-07-12 19:20:58,874 [run_pretraining.py:  558]:	worker_index: 2, step: 2423, cost: 6.453671, mlm loss: 6.453671, speed: 1.086420 steps/s, speed: 8.691361 samples/s, speed: 4449.976671 tokens/s, learning rate: 2.422e-05, loss_scalings: 2814.750488, pp_loss: 7.055041
[INFO] 2021-07-12 19:20:58,874 [run_pretraining.py:  512]:	********exe.run_2423******* 
[INFO] 2021-07-12 19:20:59,786 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:59,787 [run_pretraining.py:  534]:	loss/total_loss, 7.100717544555664, 2424
[INFO] 2021-07-12 19:20:59,787 [run_pretraining.py:  535]:	loss/mlm_loss, 7.100717544555664, 2424
[INFO] 2021-07-12 19:20:59,787 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4229999326053075e-05, 2424
[INFO] 2021-07-12 19:20:59,787 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2424
[INFO] 2021-07-12 19:20:59,787 [run_pretraining.py:  558]:	worker_index: 2, step: 2424, cost: 7.100718, mlm loss: 7.100718, speed: 1.096574 steps/s, speed: 8.772591 samples/s, speed: 4491.566532 tokens/s, learning rate: 2.423e-05, loss_scalings: 2814.750488, pp_loss: 6.975911
[INFO] 2021-07-12 19:20:59,787 [run_pretraining.py:  512]:	********exe.run_2424******* 
[INFO] 2021-07-12 19:21:00,699 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:00,700 [run_pretraining.py:  534]:	loss/total_loss, 7.998990058898926, 2425
[INFO] 2021-07-12 19:21:00,700 [run_pretraining.py:  535]:	loss/mlm_loss, 7.998990058898926, 2425
[INFO] 2021-07-12 19:21:00,700 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.424000012979377e-05, 2425
[INFO] 2021-07-12 19:21:00,700 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2425
[INFO] 2021-07-12 19:21:00,700 [run_pretraining.py:  558]:	worker_index: 2, step: 2425, cost: 7.998990, mlm loss: 7.998990, speed: 1.096072 steps/s, speed: 8.768579 samples/s, speed: 4489.512462 tokens/s, learning rate: 2.424e-05, loss_scalings: 2814.750488, pp_loss: 7.462593
[INFO] 2021-07-12 19:21:00,700 [run_pretraining.py:  512]:	********exe.run_2425******* 
[INFO] 2021-07-12 19:21:01,613 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:01,613 [run_pretraining.py:  534]:	loss/total_loss, 7.560328483581543, 2426
[INFO] 2021-07-12 19:21:01,613 [run_pretraining.py:  535]:	loss/mlm_loss, 7.560328483581543, 2426
[INFO] 2021-07-12 19:21:01,613 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4250000933534466e-05, 2426
[INFO] 2021-07-12 19:21:01,614 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2426
[INFO] 2021-07-12 19:21:01,614 [run_pretraining.py:  558]:	worker_index: 2, step: 2426, cost: 7.560328, mlm loss: 7.560328, speed: 1.095131 steps/s, speed: 8.761049 samples/s, speed: 4485.657063 tokens/s, learning rate: 2.425e-05, loss_scalings: 2814.750488, pp_loss: 7.436487
[INFO] 2021-07-12 19:21:01,614 [run_pretraining.py:  512]:	********exe.run_2426******* 
[INFO] 2021-07-12 19:21:02,533 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:02,534 [run_pretraining.py:  534]:	loss/total_loss, 7.326930999755859, 2427
[INFO] 2021-07-12 19:21:02,534 [run_pretraining.py:  535]:	loss/mlm_loss, 7.326930999755859, 2427
[INFO] 2021-07-12 19:21:02,534 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4259998099296354e-05, 2427
[INFO] 2021-07-12 19:21:02,534 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2427
[INFO] 2021-07-12 19:21:02,534 [run_pretraining.py:  558]:	worker_index: 2, step: 2427, cost: 7.326931, mlm loss: 7.326931, speed: 1.087082 steps/s, speed: 8.696659 samples/s, speed: 4452.689345 tokens/s, learning rate: 2.426e-05, loss_scalings: 2814.750488, pp_loss: 7.449171
[INFO] 2021-07-12 19:21:02,534 [run_pretraining.py:  512]:	********exe.run_2427******* 
[INFO] 2021-07-12 19:21:03,454 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:03,454 [run_pretraining.py:  534]:	loss/total_loss, 7.316993713378906, 2428
[INFO] 2021-07-12 19:21:03,454 [run_pretraining.py:  535]:	loss/mlm_loss, 7.316993713378906, 2428
[INFO] 2021-07-12 19:21:03,454 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.426999890303705e-05, 2428
[INFO] 2021-07-12 19:21:03,455 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2428
[INFO] 2021-07-12 19:21:03,455 [run_pretraining.py:  558]:	worker_index: 2, step: 2428, cost: 7.316994, mlm loss: 7.316994, speed: 1.087088 steps/s, speed: 8.696704 samples/s, speed: 4452.712426 tokens/s, learning rate: 2.427e-05, loss_scalings: 2814.750488, pp_loss: 7.015043
[INFO] 2021-07-12 19:21:03,455 [run_pretraining.py:  512]:	********exe.run_2428******* 
[INFO] 2021-07-12 19:21:04,367 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:04,368 [run_pretraining.py:  534]:	loss/total_loss, 6.900057792663574, 2429
[INFO] 2021-07-12 19:21:04,368 [run_pretraining.py:  535]:	loss/mlm_loss, 6.900057792663574, 2429
[INFO] 2021-07-12 19:21:04,368 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4279999706777744e-05, 2429
[INFO] 2021-07-12 19:21:04,368 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2429
[INFO] 2021-07-12 19:21:04,368 [run_pretraining.py:  558]:	worker_index: 2, step: 2429, cost: 6.900058, mlm loss: 6.900058, speed: 1.095528 steps/s, speed: 8.764225 samples/s, speed: 4487.283283 tokens/s, learning rate: 2.428e-05, loss_scalings: 2814.750488, pp_loss: 6.833847
[INFO] 2021-07-12 19:21:04,368 [run_pretraining.py:  512]:	********exe.run_2429******* 
[INFO] 2021-07-12 19:21:05,281 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:05,282 [run_pretraining.py:  534]:	loss/total_loss, 7.699961185455322, 2430
[INFO] 2021-07-12 19:21:05,282 [run_pretraining.py:  535]:	loss/mlm_loss, 7.699961185455322, 2430
[INFO] 2021-07-12 19:21:05,282 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4289998691529036e-05, 2430
[INFO] 2021-07-12 19:21:05,282 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2430
[INFO] 2021-07-12 19:21:05,282 [run_pretraining.py:  558]:	worker_index: 2, step: 2430, cost: 7.699961, mlm loss: 7.699961, speed: 1.094805 steps/s, speed: 8.758442 samples/s, speed: 4484.322289 tokens/s, learning rate: 2.429e-05, loss_scalings: 2814.750488, pp_loss: 7.690512
[INFO] 2021-07-12 19:21:05,282 [run_pretraining.py:  512]:	********exe.run_2430******* 
[INFO] 2021-07-12 19:21:06,189 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:06,189 [run_pretraining.py:  534]:	loss/total_loss, 7.4507646560668945, 2431
[INFO] 2021-07-12 19:21:06,189 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4507646560668945, 2431
[INFO] 2021-07-12 19:21:06,190 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.429999949526973e-05, 2431
[INFO] 2021-07-12 19:21:06,190 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2431
[INFO] 2021-07-12 19:21:06,190 [run_pretraining.py:  558]:	worker_index: 2, step: 2431, cost: 7.450765, mlm loss: 7.450765, speed: 1.102434 steps/s, speed: 8.819470 samples/s, speed: 4515.568628 tokens/s, learning rate: 2.430e-05, loss_scalings: 2814.750488, pp_loss: 6.568150
[INFO] 2021-07-12 19:21:06,190 [run_pretraining.py:  512]:	********exe.run_2431******* 
[INFO] 2021-07-12 19:21:07,104 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:07,104 [run_pretraining.py:  534]:	loss/total_loss, 6.964546203613281, 2432
[INFO] 2021-07-12 19:21:07,104 [run_pretraining.py:  535]:	loss/mlm_loss, 6.964546203613281, 2432
[INFO] 2021-07-12 19:21:07,104 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4310000299010426e-05, 2432
[INFO] 2021-07-12 19:21:07,105 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2432
[INFO] 2021-07-12 19:21:07,105 [run_pretraining.py:  558]:	worker_index: 2, step: 2432, cost: 6.964546, mlm loss: 6.964546, speed: 1.093701 steps/s, speed: 8.749610 samples/s, speed: 4479.800505 tokens/s, learning rate: 2.431e-05, loss_scalings: 2814.750488, pp_loss: 7.145863
[INFO] 2021-07-12 19:21:07,105 [run_pretraining.py:  512]:	********exe.run_2432******* 
[INFO] 2021-07-12 19:21:08,012 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:08,013 [run_pretraining.py:  534]:	loss/total_loss, 7.5520806312561035, 2433
[INFO] 2021-07-12 19:21:08,013 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5520806312561035, 2433
[INFO] 2021-07-12 19:21:08,013 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4319999283761717e-05, 2433
[INFO] 2021-07-12 19:21:08,013 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2433
[INFO] 2021-07-12 19:21:08,013 [run_pretraining.py:  558]:	worker_index: 2, step: 2433, cost: 7.552081, mlm loss: 7.552081, speed: 1.101252 steps/s, speed: 8.810018 samples/s, speed: 4510.728996 tokens/s, learning rate: 2.432e-05, loss_scalings: 2814.750488, pp_loss: 7.545293
[INFO] 2021-07-12 19:21:08,013 [run_pretraining.py:  512]:	********exe.run_2433******* 
[INFO] 2021-07-12 19:21:08,923 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:08,923 [run_pretraining.py:  534]:	loss/total_loss, 7.583396911621094, 2434
[INFO] 2021-07-12 19:21:08,923 [run_pretraining.py:  535]:	loss/mlm_loss, 7.583396911621094, 2434
[INFO] 2021-07-12 19:21:08,923 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4330000087502412e-05, 2434
[INFO] 2021-07-12 19:21:08,923 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2434
[INFO] 2021-07-12 19:21:08,923 [run_pretraining.py:  558]:	worker_index: 2, step: 2434, cost: 7.583397, mlm loss: 7.583397, speed: 1.099417 steps/s, speed: 8.795335 samples/s, speed: 4503.211560 tokens/s, learning rate: 2.433e-05, loss_scalings: 2814.750488, pp_loss: 7.570661
[INFO] 2021-07-12 19:21:08,924 [run_pretraining.py:  512]:	********exe.run_2434******* 
[INFO] 2021-07-12 19:21:09,833 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:09,834 [run_pretraining.py:  534]:	loss/total_loss, 7.99592924118042, 2435
[INFO] 2021-07-12 19:21:09,834 [run_pretraining.py:  535]:	loss/mlm_loss, 7.99592924118042, 2435
[INFO] 2021-07-12 19:21:09,834 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4339999072253704e-05, 2435
[INFO] 2021-07-12 19:21:09,834 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2435
[INFO] 2021-07-12 19:21:09,834 [run_pretraining.py:  558]:	worker_index: 2, step: 2435, cost: 7.995929, mlm loss: 7.995929, speed: 1.098614 steps/s, speed: 8.788912 samples/s, speed: 4499.923041 tokens/s, learning rate: 2.434e-05, loss_scalings: 2814.750488, pp_loss: 7.834035
[INFO] 2021-07-12 19:21:09,834 [run_pretraining.py:  512]:	********exe.run_2435******* 
[INFO] 2021-07-12 19:21:10,744 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:10,744 [run_pretraining.py:  534]:	loss/total_loss, 7.157413005828857, 2436
[INFO] 2021-07-12 19:21:10,744 [run_pretraining.py:  535]:	loss/mlm_loss, 7.157413005828857, 2436
[INFO] 2021-07-12 19:21:10,744 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4349998057004996e-05, 2436
[INFO] 2021-07-12 19:21:10,745 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2436
[INFO] 2021-07-12 19:21:10,745 [run_pretraining.py:  558]:	worker_index: 2, step: 2436, cost: 7.157413, mlm loss: 7.157413, speed: 1.099241 steps/s, speed: 8.793929 samples/s, speed: 4502.491638 tokens/s, learning rate: 2.435e-05, loss_scalings: 2814.750488, pp_loss: 6.679549
[INFO] 2021-07-12 19:21:10,745 [run_pretraining.py:  512]:	********exe.run_2436******* 
[INFO] 2021-07-12 19:21:11,654 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:11,654 [run_pretraining.py:  534]:	loss/total_loss, 7.636831760406494, 2437
[INFO] 2021-07-12 19:21:11,654 [run_pretraining.py:  535]:	loss/mlm_loss, 7.636831760406494, 2437
[INFO] 2021-07-12 19:21:11,654 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.435999886074569e-05, 2437
[INFO] 2021-07-12 19:21:11,654 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2437
[INFO] 2021-07-12 19:21:11,654 [run_pretraining.py:  558]:	worker_index: 2, step: 2437, cost: 7.636832, mlm loss: 7.636832, speed: 1.099782 steps/s, speed: 8.798255 samples/s, speed: 4504.706427 tokens/s, learning rate: 2.436e-05, loss_scalings: 2814.750488, pp_loss: 7.432637
[INFO] 2021-07-12 19:21:11,655 [run_pretraining.py:  512]:	********exe.run_2437******* 
[INFO] 2021-07-12 19:21:12,564 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:12,564 [run_pretraining.py:  534]:	loss/total_loss, 6.788237571716309, 2438
[INFO] 2021-07-12 19:21:12,564 [run_pretraining.py:  535]:	loss/mlm_loss, 6.788237571716309, 2438
[INFO] 2021-07-12 19:21:12,564 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4369999664486386e-05, 2438
[INFO] 2021-07-12 19:21:12,564 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2438
[INFO] 2021-07-12 19:21:12,564 [run_pretraining.py:  558]:	worker_index: 2, step: 2438, cost: 6.788238, mlm loss: 6.788238, speed: 1.099669 steps/s, speed: 8.797348 samples/s, speed: 4504.242274 tokens/s, learning rate: 2.437e-05, loss_scalings: 2814.750488, pp_loss: 7.327747
[INFO] 2021-07-12 19:21:12,565 [run_pretraining.py:  512]:	********exe.run_2438******* 
[INFO] 2021-07-12 19:21:13,475 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:13,475 [run_pretraining.py:  534]:	loss/total_loss, 7.287219047546387, 2439
[INFO] 2021-07-12 19:21:13,475 [run_pretraining.py:  535]:	loss/mlm_loss, 7.287219047546387, 2439
[INFO] 2021-07-12 19:21:13,475 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4379998649237677e-05, 2439
[INFO] 2021-07-12 19:21:13,475 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2439
[INFO] 2021-07-12 19:21:13,476 [run_pretraining.py:  558]:	worker_index: 2, step: 2439, cost: 7.287219, mlm loss: 7.287219, speed: 1.098294 steps/s, speed: 8.786355 samples/s, speed: 4498.613925 tokens/s, learning rate: 2.438e-05, loss_scalings: 2814.750488, pp_loss: 7.413907
[INFO] 2021-07-12 19:21:13,476 [run_pretraining.py:  512]:	********exe.run_2439******* 
[INFO] 2021-07-12 19:21:14,382 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:14,383 [run_pretraining.py:  534]:	loss/total_loss, 6.552977561950684, 2440
[INFO] 2021-07-12 19:21:14,383 [run_pretraining.py:  535]:	loss/mlm_loss, 6.552977561950684, 2440
[INFO] 2021-07-12 19:21:14,383 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4389999452978373e-05, 2440
[INFO] 2021-07-12 19:21:14,383 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2440
[INFO] 2021-07-12 19:21:14,383 [run_pretraining.py:  558]:	worker_index: 2, step: 2440, cost: 6.552978, mlm loss: 6.552978, speed: 1.102407 steps/s, speed: 8.819257 samples/s, speed: 4515.459438 tokens/s, learning rate: 2.439e-05, loss_scalings: 2814.750488, pp_loss: 7.219006
[INFO] 2021-07-12 19:21:14,383 [run_pretraining.py:  512]:	********exe.run_2440******* 
[INFO] 2021-07-12 19:21:15,297 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:15,298 [run_pretraining.py:  534]:	loss/total_loss, 7.677860260009766, 2441
[INFO] 2021-07-12 19:21:15,298 [run_pretraining.py:  535]:	loss/mlm_loss, 7.677860260009766, 2441
[INFO] 2021-07-12 19:21:15,298 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4400000256719068e-05, 2441
[INFO] 2021-07-12 19:21:15,298 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2441
[INFO] 2021-07-12 19:21:15,298 [run_pretraining.py:  558]:	worker_index: 2, step: 2441, cost: 7.677860, mlm loss: 7.677860, speed: 1.093837 steps/s, speed: 8.750697 samples/s, speed: 4480.356612 tokens/s, learning rate: 2.440e-05, loss_scalings: 2814.750488, pp_loss: 7.690435
[INFO] 2021-07-12 19:21:15,298 [run_pretraining.py:  512]:	********exe.run_2441******* 
[INFO] 2021-07-12 19:21:16,239 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:16,240 [run_pretraining.py:  534]:	loss/total_loss, 7.624682426452637, 2442
[INFO] 2021-07-12 19:21:16,240 [run_pretraining.py:  535]:	loss/mlm_loss, 7.624682426452637, 2442
[INFO] 2021-07-12 19:21:16,240 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.440999924147036e-05, 2442
[INFO] 2021-07-12 19:21:16,240 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2442
[INFO] 2021-07-12 19:21:16,240 [run_pretraining.py:  558]:	worker_index: 2, step: 2442, cost: 7.624682, mlm loss: 7.624682, speed: 1.062258 steps/s, speed: 8.498067 samples/s, speed: 4351.010487 tokens/s, learning rate: 2.441e-05, loss_scalings: 2814.750488, pp_loss: 7.293534
[INFO] 2021-07-12 19:21:16,240 [run_pretraining.py:  512]:	********exe.run_2442******* 
[INFO] 2021-07-12 19:21:17,160 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:17,160 [run_pretraining.py:  534]:	loss/total_loss, 5.5264716148376465, 2443
[INFO] 2021-07-12 19:21:17,160 [run_pretraining.py:  535]:	loss/mlm_loss, 5.5264716148376465, 2443
[INFO] 2021-07-12 19:21:17,160 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4420000045211054e-05, 2443
[INFO] 2021-07-12 19:21:17,161 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2443
[INFO] 2021-07-12 19:21:17,161 [run_pretraining.py:  558]:	worker_index: 2, step: 2443, cost: 5.526472, mlm loss: 5.526472, speed: 1.087010 steps/s, speed: 8.696080 samples/s, speed: 4452.392773 tokens/s, learning rate: 2.442e-05, loss_scalings: 2814.750488, pp_loss: 6.710030
[INFO] 2021-07-12 19:21:17,161 [run_pretraining.py:  512]:	********exe.run_2443******* 
[INFO] 2021-07-12 19:21:18,071 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:18,071 [run_pretraining.py:  534]:	loss/total_loss, 6.904406547546387, 2444
[INFO] 2021-07-12 19:21:18,071 [run_pretraining.py:  535]:	loss/mlm_loss, 6.904406547546387, 2444
[INFO] 2021-07-12 19:21:18,071 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4429999029962346e-05, 2444
[INFO] 2021-07-12 19:21:18,071 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2444
[INFO] 2021-07-12 19:21:18,071 [run_pretraining.py:  558]:	worker_index: 2, step: 2444, cost: 6.904407, mlm loss: 6.904407, speed: 1.098633 steps/s, speed: 8.789064 samples/s, speed: 4500.000834 tokens/s, learning rate: 2.443e-05, loss_scalings: 2814.750488, pp_loss: 7.253294
[INFO] 2021-07-12 19:21:18,072 [run_pretraining.py:  512]:	********exe.run_2444******* 
[INFO] 2021-07-12 19:21:42,691 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:42,691 [run_pretraining.py:  534]:	loss/total_loss, 7.613579273223877, 2445
[INFO] 2021-07-12 19:21:42,691 [run_pretraining.py:  535]:	loss/mlm_loss, 7.613579273223877, 2445
[INFO] 2021-07-12 19:21:42,692 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4439998014713638e-05, 2445
[INFO] 2021-07-12 19:21:42,692 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2445
[INFO] 2021-07-12 19:21:42,692 [run_pretraining.py:  558]:	worker_index: 2, step: 2445, cost: 7.613579, mlm loss: 7.613579, speed: 0.040618 steps/s, speed: 0.324944 samples/s, speed: 166.371479 tokens/s, learning rate: 2.444e-05, loss_scalings: 2814.750488, pp_loss: 7.049072
[INFO] 2021-07-12 19:21:42,692 [run_pretraining.py:  512]:	********exe.run_2445******* 
[INFO] 2021-07-12 19:21:43,610 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:43,610 [run_pretraining.py:  534]:	loss/total_loss, 7.15717887878418, 2446
[INFO] 2021-07-12 19:21:43,610 [run_pretraining.py:  535]:	loss/mlm_loss, 7.15717887878418, 2446
[INFO] 2021-07-12 19:21:43,610 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4449998818454333e-05, 2446
[INFO] 2021-07-12 19:21:43,610 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2446
[INFO] 2021-07-12 19:21:43,610 [run_pretraining.py:  558]:	worker_index: 2, step: 2446, cost: 7.157179, mlm loss: 7.157179, speed: 1.089148 steps/s, speed: 8.713185 samples/s, speed: 4461.150737 tokens/s, learning rate: 2.445e-05, loss_scalings: 2814.750488, pp_loss: 7.282877
[INFO] 2021-07-12 19:21:43,611 [run_pretraining.py:  512]:	********exe.run_2446******* 
[INFO] 2021-07-12 19:21:44,524 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:44,524 [run_pretraining.py:  534]:	loss/total_loss, 6.842267036437988, 2447
[INFO] 2021-07-12 19:21:44,525 [run_pretraining.py:  535]:	loss/mlm_loss, 6.842267036437988, 2447
[INFO] 2021-07-12 19:21:44,525 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4459999622195028e-05, 2447
[INFO] 2021-07-12 19:21:44,525 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2447
[INFO] 2021-07-12 19:21:44,525 [run_pretraining.py:  558]:	worker_index: 2, step: 2447, cost: 6.842267, mlm loss: 6.842267, speed: 1.094327 steps/s, speed: 8.754614 samples/s, speed: 4482.362548 tokens/s, learning rate: 2.446e-05, loss_scalings: 2814.750488, pp_loss: 6.996671
[INFO] 2021-07-12 19:21:44,525 [run_pretraining.py:  512]:	********exe.run_2447******* 
[INFO] 2021-07-12 19:21:45,445 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:45,445 [run_pretraining.py:  534]:	loss/total_loss, 7.442438125610352, 2448
[INFO] 2021-07-12 19:21:45,445 [run_pretraining.py:  535]:	loss/mlm_loss, 7.442438125610352, 2448
[INFO] 2021-07-12 19:21:45,445 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.446999860694632e-05, 2448
[INFO] 2021-07-12 19:21:45,446 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2448
[INFO] 2021-07-12 19:21:45,446 [run_pretraining.py:  558]:	worker_index: 2, step: 2448, cost: 7.442438, mlm loss: 7.442438, speed: 1.086794 steps/s, speed: 8.694356 samples/s, speed: 4451.510217 tokens/s, learning rate: 2.447e-05, loss_scalings: 2814.750488, pp_loss: 7.394031
[INFO] 2021-07-12 19:21:45,446 [run_pretraining.py:  512]:	********exe.run_2448******* 
[INFO] 2021-07-12 19:21:46,366 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:46,366 [run_pretraining.py:  534]:	loss/total_loss, 6.902067184448242, 2449
[INFO] 2021-07-12 19:21:46,366 [run_pretraining.py:  535]:	loss/mlm_loss, 6.902067184448242, 2449
[INFO] 2021-07-12 19:21:46,367 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4479999410687014e-05, 2449
[INFO] 2021-07-12 19:21:46,367 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2449
[INFO] 2021-07-12 19:21:46,367 [run_pretraining.py:  558]:	worker_index: 2, step: 2449, cost: 6.902067, mlm loss: 6.902067, speed: 1.086315 steps/s, speed: 8.690517 samples/s, speed: 4449.544471 tokens/s, learning rate: 2.448e-05, loss_scalings: 2814.750488, pp_loss: 7.137941
[INFO] 2021-07-12 19:21:46,367 [run_pretraining.py:  512]:	********exe.run_2449******* 
[INFO] 2021-07-12 19:21:47,280 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:47,281 [run_pretraining.py:  534]:	loss/total_loss, 8.163041114807129, 2450
[INFO] 2021-07-12 19:21:47,281 [run_pretraining.py:  535]:	loss/mlm_loss, 8.163041114807129, 2450
[INFO] 2021-07-12 19:21:47,281 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.449000021442771e-05, 2450
[INFO] 2021-07-12 19:21:47,281 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2450
[INFO] 2021-07-12 19:21:47,281 [run_pretraining.py:  558]:	worker_index: 2, step: 2450, cost: 8.163041, mlm loss: 8.163041, speed: 1.094617 steps/s, speed: 8.756936 samples/s, speed: 4483.551058 tokens/s, learning rate: 2.449e-05, loss_scalings: 2814.750488, pp_loss: 7.491374
[INFO] 2021-07-12 19:21:47,281 [run_pretraining.py:  512]:	********exe.run_2450******* 
[INFO] 2021-07-12 19:21:48,201 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:48,202 [run_pretraining.py:  534]:	loss/total_loss, 7.099942207336426, 2451
[INFO] 2021-07-12 19:21:48,202 [run_pretraining.py:  535]:	loss/mlm_loss, 7.099942207336426, 2451
[INFO] 2021-07-12 19:21:48,202 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4499999199179e-05, 2451
[INFO] 2021-07-12 19:21:48,202 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2451
[INFO] 2021-07-12 19:21:48,202 [run_pretraining.py:  558]:	worker_index: 2, step: 2451, cost: 7.099942, mlm loss: 7.099942, speed: 1.086076 steps/s, speed: 8.688606 samples/s, speed: 4448.566280 tokens/s, learning rate: 2.450e-05, loss_scalings: 2814.750488, pp_loss: 7.134361
[INFO] 2021-07-12 19:21:48,202 [run_pretraining.py:  512]:	********exe.run_2451******* 
[INFO] 2021-07-12 19:21:49,130 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:49,130 [run_pretraining.py:  534]:	loss/total_loss, 7.252987861633301, 2452
[INFO] 2021-07-12 19:21:49,130 [run_pretraining.py:  535]:	loss/mlm_loss, 7.252987861633301, 2452
[INFO] 2021-07-12 19:21:49,130 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4510000002919696e-05, 2452
[INFO] 2021-07-12 19:21:49,130 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2452
[INFO] 2021-07-12 19:21:49,130 [run_pretraining.py:  558]:	worker_index: 2, step: 2452, cost: 7.252988, mlm loss: 7.252988, speed: 1.078154 steps/s, speed: 8.625233 samples/s, speed: 4416.119108 tokens/s, learning rate: 2.451e-05, loss_scalings: 2814.750488, pp_loss: 7.196800
[INFO] 2021-07-12 19:21:49,130 [run_pretraining.py:  512]:	********exe.run_2452******* 
[INFO] 2021-07-12 19:21:50,046 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:50,047 [run_pretraining.py:  534]:	loss/total_loss, 7.276754379272461, 2453
[INFO] 2021-07-12 19:21:50,047 [run_pretraining.py:  535]:	loss/mlm_loss, 7.276754379272461, 2453
[INFO] 2021-07-12 19:21:50,047 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4519998987670988e-05, 2453
[INFO] 2021-07-12 19:21:50,047 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2453
[INFO] 2021-07-12 19:21:50,047 [run_pretraining.py:  558]:	worker_index: 2, step: 2453, cost: 7.276754, mlm loss: 7.276754, speed: 1.091788 steps/s, speed: 8.734301 samples/s, speed: 4471.961960 tokens/s, learning rate: 2.452e-05, loss_scalings: 2814.750488, pp_loss: 7.443052
[INFO] 2021-07-12 19:21:50,047 [run_pretraining.py:  512]:	********exe.run_2453******* 
[INFO] 2021-07-12 19:21:50,968 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:50,969 [run_pretraining.py:  534]:	loss/total_loss, 6.860578536987305, 2454
[INFO] 2021-07-12 19:21:50,969 [run_pretraining.py:  535]:	loss/mlm_loss, 6.860578536987305, 2454
[INFO] 2021-07-12 19:21:50,969 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.452999797242228e-05, 2454
[INFO] 2021-07-12 19:21:50,969 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2454
[INFO] 2021-07-12 19:21:50,969 [run_pretraining.py:  558]:	worker_index: 2, step: 2454, cost: 6.860579, mlm loss: 6.860579, speed: 1.085113 steps/s, speed: 8.680903 samples/s, speed: 4444.622169 tokens/s, learning rate: 2.453e-05, loss_scalings: 2814.750488, pp_loss: 5.563424
[INFO] 2021-07-12 19:21:50,969 [run_pretraining.py:  512]:	********exe.run_2454******* 
[INFO] 2021-07-12 19:21:51,890 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:51,890 [run_pretraining.py:  534]:	loss/total_loss, 6.903350353240967, 2455
[INFO] 2021-07-12 19:21:51,890 [run_pretraining.py:  535]:	loss/mlm_loss, 6.903350353240967, 2455
[INFO] 2021-07-12 19:21:51,890 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4539998776162975e-05, 2455
[INFO] 2021-07-12 19:21:51,890 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2455
[INFO] 2021-07-12 19:21:51,890 [run_pretraining.py:  558]:	worker_index: 2, step: 2455, cost: 6.903350, mlm loss: 6.903350, speed: 1.086037 steps/s, speed: 8.688296 samples/s, speed: 4448.407322 tokens/s, learning rate: 2.454e-05, loss_scalings: 2814.750488, pp_loss: 6.965437
[INFO] 2021-07-12 19:21:51,890 [run_pretraining.py:  512]:	********exe.run_2455******* 
[INFO] 2021-07-12 19:21:52,812 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:52,813 [run_pretraining.py:  534]:	loss/total_loss, 6.716196060180664, 2456
[INFO] 2021-07-12 19:21:52,813 [run_pretraining.py:  535]:	loss/mlm_loss, 6.716196060180664, 2456
[INFO] 2021-07-12 19:21:52,813 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.454999957990367e-05, 2456
[INFO] 2021-07-12 19:21:52,813 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2456
[INFO] 2021-07-12 19:21:52,813 [run_pretraining.py:  558]:	worker_index: 2, step: 2456, cost: 6.716196, mlm loss: 6.716196, speed: 1.084300 steps/s, speed: 8.674397 samples/s, speed: 4441.291186 tokens/s, learning rate: 2.455e-05, loss_scalings: 2814.750488, pp_loss: 7.175087
[INFO] 2021-07-12 19:21:52,813 [run_pretraining.py:  512]:	********exe.run_2456******* 
[INFO] 2021-07-12 19:21:53,763 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:53,764 [run_pretraining.py:  534]:	loss/total_loss, 6.778741359710693, 2457
[INFO] 2021-07-12 19:21:53,764 [run_pretraining.py:  535]:	loss/mlm_loss, 6.778741359710693, 2457
[INFO] 2021-07-12 19:21:53,764 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.455999856465496e-05, 2457
[INFO] 2021-07-12 19:21:53,764 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2457
[INFO] 2021-07-12 19:21:53,764 [run_pretraining.py:  558]:	worker_index: 2, step: 2457, cost: 6.778741, mlm loss: 6.778741, speed: 1.052503 steps/s, speed: 8.420025 samples/s, speed: 4311.052912 tokens/s, learning rate: 2.456e-05, loss_scalings: 2814.750488, pp_loss: 7.327869
[INFO] 2021-07-12 19:21:53,764 [run_pretraining.py:  512]:	********exe.run_2457******* 
[INFO] 2021-07-12 19:21:54,684 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:54,685 [run_pretraining.py:  534]:	loss/total_loss, 5.2580108642578125, 2458
[INFO] 2021-07-12 19:21:54,685 [run_pretraining.py:  535]:	loss/mlm_loss, 5.2580108642578125, 2458
[INFO] 2021-07-12 19:21:54,685 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4569999368395656e-05, 2458
[INFO] 2021-07-12 19:21:54,685 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2458
[INFO] 2021-07-12 19:21:54,685 [run_pretraining.py:  558]:	worker_index: 2, step: 2458, cost: 5.258011, mlm loss: 5.258011, speed: 1.086216 steps/s, speed: 8.689724 samples/s, speed: 4449.138856 tokens/s, learning rate: 2.457e-05, loss_scalings: 2814.750488, pp_loss: 6.847542
[INFO] 2021-07-12 19:21:54,685 [run_pretraining.py:  512]:	********exe.run_2458******* 
[INFO] 2021-07-12 19:21:55,612 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:55,613 [run_pretraining.py:  534]:	loss/total_loss, 6.995326519012451, 2459
[INFO] 2021-07-12 19:21:55,613 [run_pretraining.py:  535]:	loss/mlm_loss, 6.995326519012451, 2459
[INFO] 2021-07-12 19:21:55,613 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.458000017213635e-05, 2459
[INFO] 2021-07-12 19:21:55,613 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2459
[INFO] 2021-07-12 19:21:55,613 [run_pretraining.py:  558]:	worker_index: 2, step: 2459, cost: 6.995327, mlm loss: 6.995327, speed: 1.078223 steps/s, speed: 8.625780 samples/s, speed: 4416.399513 tokens/s, learning rate: 2.458e-05, loss_scalings: 2814.750488, pp_loss: 7.454434
[INFO] 2021-07-12 19:21:55,613 [run_pretraining.py:  512]:	********exe.run_2459******* 
[INFO] 2021-07-12 19:21:56,527 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:56,528 [run_pretraining.py:  534]:	loss/total_loss, 6.565340042114258, 2460
[INFO] 2021-07-12 19:21:56,528 [run_pretraining.py:  535]:	loss/mlm_loss, 6.565340042114258, 2460
[INFO] 2021-07-12 19:21:56,528 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4589999156887643e-05, 2460
[INFO] 2021-07-12 19:21:56,528 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2460
[INFO] 2021-07-12 19:21:56,528 [run_pretraining.py:  558]:	worker_index: 2, step: 2460, cost: 6.565340, mlm loss: 6.565340, speed: 1.093538 steps/s, speed: 8.748306 samples/s, speed: 4479.132425 tokens/s, learning rate: 2.459e-05, loss_scalings: 2814.750488, pp_loss: 7.301770
[INFO] 2021-07-12 19:21:56,528 [run_pretraining.py:  512]:	********exe.run_2460******* 
[INFO] 2021-07-12 19:21:57,435 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:57,435 [run_pretraining.py:  534]:	loss/total_loss, 7.373025417327881, 2461
[INFO] 2021-07-12 19:21:57,435 [run_pretraining.py:  535]:	loss/mlm_loss, 7.373025417327881, 2461
[INFO] 2021-07-12 19:21:57,435 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4599999960628338e-05, 2461
[INFO] 2021-07-12 19:21:57,435 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2461
[INFO] 2021-07-12 19:21:57,435 [run_pretraining.py:  558]:	worker_index: 2, step: 2461, cost: 7.373025, mlm loss: 7.373025, speed: 1.103140 steps/s, speed: 8.825123 samples/s, speed: 4518.462897 tokens/s, learning rate: 2.460e-05, loss_scalings: 2814.750488, pp_loss: 7.204806
[INFO] 2021-07-12 19:21:57,435 [run_pretraining.py:  512]:	********exe.run_2461******* 
[INFO] 2021-07-12 19:21:58,349 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:58,350 [run_pretraining.py:  534]:	loss/total_loss, 7.223495960235596, 2462
[INFO] 2021-07-12 19:21:58,350 [run_pretraining.py:  535]:	loss/mlm_loss, 7.223495960235596, 2462
[INFO] 2021-07-12 19:21:58,350 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.460999894537963e-05, 2462
[INFO] 2021-07-12 19:21:58,350 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2462
[INFO] 2021-07-12 19:21:58,350 [run_pretraining.py:  558]:	worker_index: 2, step: 2462, cost: 7.223496, mlm loss: 7.223496, speed: 1.093849 steps/s, speed: 8.750792 samples/s, speed: 4480.405687 tokens/s, learning rate: 2.461e-05, loss_scalings: 2814.750488, pp_loss: 7.020883
[INFO] 2021-07-12 19:21:58,350 [run_pretraining.py:  512]:	********exe.run_2462******* 
[INFO] 2021-07-12 19:21:59,272 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:59,272 [run_pretraining.py:  534]:	loss/total_loss, 4.10074520111084, 2463
[INFO] 2021-07-12 19:21:59,273 [run_pretraining.py:  535]:	loss/mlm_loss, 4.10074520111084, 2463
[INFO] 2021-07-12 19:21:59,273 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4619999749120325e-05, 2463
[INFO] 2021-07-12 19:21:59,273 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2463
[INFO] 2021-07-12 19:21:59,273 [run_pretraining.py:  558]:	worker_index: 2, step: 2463, cost: 4.100745, mlm loss: 4.100745, speed: 1.084597 steps/s, speed: 8.676777 samples/s, speed: 4442.509707 tokens/s, learning rate: 2.462e-05, loss_scalings: 2814.750488, pp_loss: 6.736483
[INFO] 2021-07-12 19:21:59,273 [run_pretraining.py:  512]:	********exe.run_2463******* 
[INFO] 2021-07-12 19:22:00,186 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:00,187 [run_pretraining.py:  534]:	loss/total_loss, 7.114286422729492, 2464
[INFO] 2021-07-12 19:22:00,187 [run_pretraining.py:  535]:	loss/mlm_loss, 7.114286422729492, 2464
[INFO] 2021-07-12 19:22:00,187 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4629998733871616e-05, 2464
[INFO] 2021-07-12 19:22:00,187 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2464
[INFO] 2021-07-12 19:22:00,187 [run_pretraining.py:  558]:	worker_index: 2, step: 2464, cost: 7.114286, mlm loss: 7.114286, speed: 1.094388 steps/s, speed: 8.755103 samples/s, speed: 4482.612831 tokens/s, learning rate: 2.463e-05, loss_scalings: 2814.750488, pp_loss: 7.189587
[INFO] 2021-07-12 19:22:00,187 [run_pretraining.py:  512]:	********exe.run_2464******* 
[INFO] 2021-07-12 19:22:01,102 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:01,102 [run_pretraining.py:  534]:	loss/total_loss, 7.044652938842773, 2465
[INFO] 2021-07-12 19:22:01,102 [run_pretraining.py:  535]:	loss/mlm_loss, 7.044652938842773, 2465
[INFO] 2021-07-12 19:22:01,103 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.463999953761231e-05, 2465
[INFO] 2021-07-12 19:22:01,103 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2465
[INFO] 2021-07-12 19:22:01,103 [run_pretraining.py:  558]:	worker_index: 2, step: 2465, cost: 7.044653, mlm loss: 7.044653, speed: 1.092977 steps/s, speed: 8.743812 samples/s, speed: 4476.831876 tokens/s, learning rate: 2.464e-05, loss_scalings: 2814.750488, pp_loss: 7.090687
[INFO] 2021-07-12 19:22:01,103 [run_pretraining.py:  512]:	********exe.run_2465******* 
[INFO] 2021-07-12 19:22:02,011 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:02,011 [run_pretraining.py:  534]:	loss/total_loss, 6.935186386108398, 2466
[INFO] 2021-07-12 19:22:02,011 [run_pretraining.py:  535]:	loss/mlm_loss, 6.935186386108398, 2466
[INFO] 2021-07-12 19:22:02,011 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4649998522363603e-05, 2466
[INFO] 2021-07-12 19:22:02,011 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2466
[INFO] 2021-07-12 19:22:02,011 [run_pretraining.py:  558]:	worker_index: 2, step: 2466, cost: 6.935186, mlm loss: 6.935186, speed: 1.101183 steps/s, speed: 8.809462 samples/s, speed: 4510.444774 tokens/s, learning rate: 2.465e-05, loss_scalings: 2814.750488, pp_loss: 6.722805
[INFO] 2021-07-12 19:22:02,012 [run_pretraining.py:  512]:	********exe.run_2466******* 
[INFO] 2021-07-12 19:22:02,932 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:02,932 [run_pretraining.py:  534]:	loss/total_loss, 7.151220321655273, 2467
[INFO] 2021-07-12 19:22:02,932 [run_pretraining.py:  535]:	loss/mlm_loss, 7.151220321655273, 2467
[INFO] 2021-07-12 19:22:02,932 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4659999326104298e-05, 2467
[INFO] 2021-07-12 19:22:02,932 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2467
[INFO] 2021-07-12 19:22:02,932 [run_pretraining.py:  558]:	worker_index: 2, step: 2467, cost: 7.151220, mlm loss: 7.151220, speed: 1.086610 steps/s, speed: 8.692876 samples/s, speed: 4450.752536 tokens/s, learning rate: 2.466e-05, loss_scalings: 2814.750488, pp_loss: 7.286805
[INFO] 2021-07-12 19:22:02,932 [run_pretraining.py:  512]:	********exe.run_2467******* 
[INFO] 2021-07-12 19:22:03,855 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:03,855 [run_pretraining.py:  534]:	loss/total_loss, 7.129870891571045, 2468
[INFO] 2021-07-12 19:22:03,855 [run_pretraining.py:  535]:	loss/mlm_loss, 7.129870891571045, 2468
[INFO] 2021-07-12 19:22:03,855 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4670000129844993e-05, 2468
[INFO] 2021-07-12 19:22:03,855 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2468
[INFO] 2021-07-12 19:22:03,855 [run_pretraining.py:  558]:	worker_index: 2, step: 2468, cost: 7.129871, mlm loss: 7.129871, speed: 1.084002 steps/s, speed: 8.672014 samples/s, speed: 4440.071038 tokens/s, learning rate: 2.467e-05, loss_scalings: 2814.750488, pp_loss: 7.053705
[INFO] 2021-07-12 19:22:03,856 [run_pretraining.py:  512]:	********exe.run_2468******* 
[INFO] 2021-07-12 19:22:04,771 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:04,771 [run_pretraining.py:  534]:	loss/total_loss, 6.137217998504639, 2469
[INFO] 2021-07-12 19:22:04,771 [run_pretraining.py:  535]:	loss/mlm_loss, 6.137217998504639, 2469
[INFO] 2021-07-12 19:22:04,771 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4679999114596285e-05, 2469
[INFO] 2021-07-12 19:22:04,772 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2469
[INFO] 2021-07-12 19:22:04,772 [run_pretraining.py:  558]:	worker_index: 2, step: 2469, cost: 6.137218, mlm loss: 6.137218, speed: 1.092256 steps/s, speed: 8.738047 samples/s, speed: 4473.879994 tokens/s, learning rate: 2.468e-05, loss_scalings: 2814.750488, pp_loss: 6.799904
[INFO] 2021-07-12 19:22:04,772 [run_pretraining.py:  512]:	********exe.run_2469******* 
[INFO] 2021-07-12 19:22:05,686 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:05,687 [run_pretraining.py:  534]:	loss/total_loss, 7.0859150886535645, 2470
[INFO] 2021-07-12 19:22:05,687 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0859150886535645, 2470
[INFO] 2021-07-12 19:22:05,687 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.468999991833698e-05, 2470
[INFO] 2021-07-12 19:22:05,687 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2470
[INFO] 2021-07-12 19:22:05,687 [run_pretraining.py:  558]:	worker_index: 2, step: 2470, cost: 7.085915, mlm loss: 7.085915, speed: 1.093186 steps/s, speed: 8.745485 samples/s, speed: 4477.688323 tokens/s, learning rate: 2.469e-05, loss_scalings: 2814.750488, pp_loss: 7.223651
[INFO] 2021-07-12 19:22:05,687 [run_pretraining.py:  512]:	********exe.run_2470******* 
[INFO] 2021-07-12 19:22:06,594 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:06,595 [run_pretraining.py:  534]:	loss/total_loss, 6.2230987548828125, 2471
[INFO] 2021-07-12 19:22:06,595 [run_pretraining.py:  535]:	loss/mlm_loss, 6.2230987548828125, 2471
[INFO] 2021-07-12 19:22:06,595 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.469999890308827e-05, 2471
[INFO] 2021-07-12 19:22:06,595 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2471
[INFO] 2021-07-12 19:22:06,595 [run_pretraining.py:  558]:	worker_index: 2, step: 2471, cost: 6.223099, mlm loss: 6.223099, speed: 1.101716 steps/s, speed: 8.813725 samples/s, speed: 4512.627095 tokens/s, learning rate: 2.470e-05, loss_scalings: 2814.750488, pp_loss: 6.809311
[INFO] 2021-07-12 19:22:06,595 [run_pretraining.py:  512]:	********exe.run_2471******* 
[INFO] 2021-07-12 19:22:07,515 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:07,515 [run_pretraining.py:  534]:	loss/total_loss, 7.500911712646484, 2472
[INFO] 2021-07-12 19:22:07,515 [run_pretraining.py:  535]:	loss/mlm_loss, 7.500911712646484, 2472
[INFO] 2021-07-12 19:22:07,515 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4709999706828967e-05, 2472
[INFO] 2021-07-12 19:22:07,515 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2472
[INFO] 2021-07-12 19:22:07,515 [run_pretraining.py:  558]:	worker_index: 2, step: 2472, cost: 7.500912, mlm loss: 7.500912, speed: 1.087393 steps/s, speed: 8.699141 samples/s, speed: 4453.960317 tokens/s, learning rate: 2.471e-05, loss_scalings: 2814.750488, pp_loss: 7.538896
[INFO] 2021-07-12 19:22:07,516 [run_pretraining.py:  512]:	********exe.run_2472******* 
[INFO] 2021-07-12 19:22:08,428 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:08,429 [run_pretraining.py:  534]:	loss/total_loss, 7.616276264190674, 2473
[INFO] 2021-07-12 19:22:08,429 [run_pretraining.py:  535]:	loss/mlm_loss, 7.616276264190674, 2473
[INFO] 2021-07-12 19:22:08,429 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.471999869158026e-05, 2473
[INFO] 2021-07-12 19:22:08,429 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2473
[INFO] 2021-07-12 19:22:08,429 [run_pretraining.py:  558]:	worker_index: 2, step: 2473, cost: 7.616276, mlm loss: 7.616276, speed: 1.095056 steps/s, speed: 8.760445 samples/s, speed: 4485.347887 tokens/s, learning rate: 2.472e-05, loss_scalings: 2814.750488, pp_loss: 7.274891
[INFO] 2021-07-12 19:22:08,429 [run_pretraining.py:  512]:	********exe.run_2473******* 
[INFO] 2021-07-12 19:22:09,346 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:09,347 [run_pretraining.py:  534]:	loss/total_loss, 7.64177131652832, 2474
[INFO] 2021-07-12 19:22:09,347 [run_pretraining.py:  535]:	loss/mlm_loss, 7.64177131652832, 2474
[INFO] 2021-07-12 19:22:09,347 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4729999495320953e-05, 2474
[INFO] 2021-07-12 19:22:09,347 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2474
[INFO] 2021-07-12 19:22:09,347 [run_pretraining.py:  558]:	worker_index: 2, step: 2474, cost: 7.641771, mlm loss: 7.641771, speed: 1.090025 steps/s, speed: 8.720198 samples/s, speed: 4464.741317 tokens/s, learning rate: 2.473e-05, loss_scalings: 2814.750488, pp_loss: 7.420560
[INFO] 2021-07-12 19:22:09,347 [run_pretraining.py:  512]:	********exe.run_2474******* 
[INFO] 2021-07-12 19:22:10,263 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:10,263 [run_pretraining.py:  534]:	loss/total_loss, 7.160895347595215, 2475
[INFO] 2021-07-12 19:22:10,263 [run_pretraining.py:  535]:	loss/mlm_loss, 7.160895347595215, 2475
[INFO] 2021-07-12 19:22:10,264 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.474000029906165e-05, 2475
[INFO] 2021-07-12 19:22:10,264 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2475
[INFO] 2021-07-12 19:22:10,264 [run_pretraining.py:  558]:	worker_index: 2, step: 2475, cost: 7.160895, mlm loss: 7.160895, speed: 1.091879 steps/s, speed: 8.735031 samples/s, speed: 4472.335656 tokens/s, learning rate: 2.474e-05, loss_scalings: 2814.750488, pp_loss: 6.879292
[INFO] 2021-07-12 19:22:10,264 [run_pretraining.py:  512]:	********exe.run_2475******* 
[INFO] 2021-07-12 19:22:11,179 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:11,180 [run_pretraining.py:  534]:	loss/total_loss, 7.45876932144165, 2476
[INFO] 2021-07-12 19:22:11,180 [run_pretraining.py:  535]:	loss/mlm_loss, 7.45876932144165, 2476
[INFO] 2021-07-12 19:22:11,180 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.474999928381294e-05, 2476
[INFO] 2021-07-12 19:22:11,180 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2476
[INFO] 2021-07-12 19:22:11,180 [run_pretraining.py:  558]:	worker_index: 2, step: 2476, cost: 7.458769, mlm loss: 7.458769, speed: 1.092207 steps/s, speed: 8.737653 samples/s, speed: 4473.678447 tokens/s, learning rate: 2.475e-05, loss_scalings: 2814.750488, pp_loss: 6.532289
[INFO] 2021-07-12 19:22:11,180 [run_pretraining.py:  512]:	********exe.run_2476******* 
[INFO] 2021-07-12 19:22:12,093 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:12,093 [run_pretraining.py:  534]:	loss/total_loss, 7.409951686859131, 2477
[INFO] 2021-07-12 19:22:12,094 [run_pretraining.py:  535]:	loss/mlm_loss, 7.409951686859131, 2477
[INFO] 2021-07-12 19:22:12,094 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4760000087553635e-05, 2477
[INFO] 2021-07-12 19:22:12,094 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2477
[INFO] 2021-07-12 19:22:12,094 [run_pretraining.py:  558]:	worker_index: 2, step: 2477, cost: 7.409952, mlm loss: 7.409952, speed: 1.094953 steps/s, speed: 8.759626 samples/s, speed: 4484.928693 tokens/s, learning rate: 2.476e-05, loss_scalings: 2814.750488, pp_loss: 7.350172
[INFO] 2021-07-12 19:22:12,094 [run_pretraining.py:  512]:	********exe.run_2477******* 
[INFO] 2021-07-12 19:22:13,017 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:13,017 [run_pretraining.py:  534]:	loss/total_loss, 7.304727554321289, 2478
[INFO] 2021-07-12 19:22:13,017 [run_pretraining.py:  535]:	loss/mlm_loss, 7.304727554321289, 2478
[INFO] 2021-07-12 19:22:13,017 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4769999072304927e-05, 2478
[INFO] 2021-07-12 19:22:13,017 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2478
[INFO] 2021-07-12 19:22:13,018 [run_pretraining.py:  558]:	worker_index: 2, step: 2478, cost: 7.304728, mlm loss: 7.304728, speed: 1.083223 steps/s, speed: 8.665781 samples/s, speed: 4436.879787 tokens/s, learning rate: 2.477e-05, loss_scalings: 2814.750488, pp_loss: 7.552348
[INFO] 2021-07-12 19:22:13,018 [run_pretraining.py:  512]:	********exe.run_2478******* 
[INFO] 2021-07-12 19:22:13,933 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:13,934 [run_pretraining.py:  534]:	loss/total_loss, 7.559084892272949, 2479
[INFO] 2021-07-12 19:22:13,934 [run_pretraining.py:  535]:	loss/mlm_loss, 7.559084892272949, 2479
[INFO] 2021-07-12 19:22:13,934 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.477999805705622e-05, 2479
[INFO] 2021-07-12 19:22:13,934 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2479
[INFO] 2021-07-12 19:22:13,934 [run_pretraining.py:  558]:	worker_index: 2, step: 2479, cost: 7.559085, mlm loss: 7.559085, speed: 1.091591 steps/s, speed: 8.732728 samples/s, speed: 4471.156574 tokens/s, learning rate: 2.478e-05, loss_scalings: 2814.750488, pp_loss: 7.161167
[INFO] 2021-07-12 19:22:13,934 [run_pretraining.py:  512]:	********exe.run_2479******* 
[INFO] 2021-07-12 19:22:14,851 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:14,852 [run_pretraining.py:  534]:	loss/total_loss, 6.914287090301514, 2480
[INFO] 2021-07-12 19:22:14,852 [run_pretraining.py:  535]:	loss/mlm_loss, 6.914287090301514, 2480
[INFO] 2021-07-12 19:22:14,852 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4789998860796914e-05, 2480
[INFO] 2021-07-12 19:22:14,852 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2480
[INFO] 2021-07-12 19:22:14,852 [run_pretraining.py:  558]:	worker_index: 2, step: 2480, cost: 6.914287, mlm loss: 6.914287, speed: 1.090058 steps/s, speed: 8.720461 samples/s, speed: 4464.875917 tokens/s, learning rate: 2.479e-05, loss_scalings: 2814.750488, pp_loss: 6.935494
[INFO] 2021-07-12 19:22:14,852 [run_pretraining.py:  512]:	********exe.run_2480******* 
[INFO] 2021-07-12 19:22:15,768 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:15,769 [run_pretraining.py:  534]:	loss/total_loss, 7.460598468780518, 2481
[INFO] 2021-07-12 19:22:15,769 [run_pretraining.py:  535]:	loss/mlm_loss, 7.460598468780518, 2481
[INFO] 2021-07-12 19:22:15,769 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.479999966453761e-05, 2481
[INFO] 2021-07-12 19:22:15,769 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2481
[INFO] 2021-07-12 19:22:15,769 [run_pretraining.py:  558]:	worker_index: 2, step: 2481, cost: 7.460598, mlm loss: 7.460598, speed: 1.091578 steps/s, speed: 8.732621 samples/s, speed: 4471.101884 tokens/s, learning rate: 2.480e-05, loss_scalings: 2814.750488, pp_loss: 7.213773
[INFO] 2021-07-12 19:22:15,769 [run_pretraining.py:  512]:	********exe.run_2481******* 
[INFO] 2021-07-12 19:22:16,687 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:16,687 [run_pretraining.py:  534]:	loss/total_loss, 7.311057090759277, 2482
[INFO] 2021-07-12 19:22:16,687 [run_pretraining.py:  535]:	loss/mlm_loss, 7.311057090759277, 2482
[INFO] 2021-07-12 19:22:16,687 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.48099986492889e-05, 2482
[INFO] 2021-07-12 19:22:16,687 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2482
[INFO] 2021-07-12 19:22:16,688 [run_pretraining.py:  558]:	worker_index: 2, step: 2482, cost: 7.311057, mlm loss: 7.311057, speed: 1.089348 steps/s, speed: 8.714787 samples/s, speed: 4461.971064 tokens/s, learning rate: 2.481e-05, loss_scalings: 2814.750488, pp_loss: 7.437691
[INFO] 2021-07-12 19:22:16,688 [run_pretraining.py:  512]:	********exe.run_2482******* 
[INFO] 2021-07-12 19:22:42,906 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:42,907 [run_pretraining.py:  534]:	loss/total_loss, 7.263592720031738, 2483
[INFO] 2021-07-12 19:22:42,907 [run_pretraining.py:  535]:	loss/mlm_loss, 7.263592720031738, 2483
[INFO] 2021-07-12 19:22:42,907 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4819999453029595e-05, 2483
[INFO] 2021-07-12 19:22:42,907 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2483
[INFO] 2021-07-12 19:22:42,907 [run_pretraining.py:  558]:	worker_index: 2, step: 2483, cost: 7.263593, mlm loss: 7.263593, speed: 0.038140 steps/s, speed: 0.305122 samples/s, speed: 156.222521 tokens/s, learning rate: 2.482e-05, loss_scalings: 2814.750488, pp_loss: 7.534266
[INFO] 2021-07-12 19:22:42,907 [run_pretraining.py:  512]:	********exe.run_2483******* 
[INFO] 2021-07-12 19:22:43,829 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:43,830 [run_pretraining.py:  534]:	loss/total_loss, 7.285463809967041, 2484
[INFO] 2021-07-12 19:22:43,830 [run_pretraining.py:  535]:	loss/mlm_loss, 7.285463809967041, 2484
[INFO] 2021-07-12 19:22:43,830 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.483000025677029e-05, 2484
[INFO] 2021-07-12 19:22:43,830 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2484
[INFO] 2021-07-12 19:22:43,830 [run_pretraining.py:  558]:	worker_index: 2, step: 2484, cost: 7.285464, mlm loss: 7.285464, speed: 1.084049 steps/s, speed: 8.672390 samples/s, speed: 4440.263829 tokens/s, learning rate: 2.483e-05, loss_scalings: 2814.750488, pp_loss: 6.963276
[INFO] 2021-07-12 19:22:43,830 [run_pretraining.py:  512]:	********exe.run_2484******* 
[INFO] 2021-07-12 19:22:44,754 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:44,754 [run_pretraining.py:  534]:	loss/total_loss, 7.669743061065674, 2485
[INFO] 2021-07-12 19:22:44,755 [run_pretraining.py:  535]:	loss/mlm_loss, 7.669743061065674, 2485
[INFO] 2021-07-12 19:22:44,755 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4839999241521582e-05, 2485
[INFO] 2021-07-12 19:22:44,755 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2485
[INFO] 2021-07-12 19:22:44,755 [run_pretraining.py:  558]:	worker_index: 2, step: 2485, cost: 7.669743, mlm loss: 7.669743, speed: 1.082378 steps/s, speed: 8.659025 samples/s, speed: 4433.420811 tokens/s, learning rate: 2.484e-05, loss_scalings: 2814.750488, pp_loss: 7.347845
[INFO] 2021-07-12 19:22:44,755 [run_pretraining.py:  512]:	********exe.run_2485******* 
[INFO] 2021-07-12 19:22:45,671 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:45,672 [run_pretraining.py:  534]:	loss/total_loss, 7.008134841918945, 2486
[INFO] 2021-07-12 19:22:45,672 [run_pretraining.py:  535]:	loss/mlm_loss, 7.008134841918945, 2486
[INFO] 2021-07-12 19:22:45,672 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4850000045262277e-05, 2486
[INFO] 2021-07-12 19:22:45,672 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2486
[INFO] 2021-07-12 19:22:45,672 [run_pretraining.py:  558]:	worker_index: 2, step: 2486, cost: 7.008135, mlm loss: 7.008135, speed: 1.090814 steps/s, speed: 8.726512 samples/s, speed: 4467.973949 tokens/s, learning rate: 2.485e-05, loss_scalings: 2814.750488, pp_loss: 7.268541
[INFO] 2021-07-12 19:22:45,672 [run_pretraining.py:  512]:	********exe.run_2486******* 
[INFO] 2021-07-12 19:22:46,595 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:46,595 [run_pretraining.py:  534]:	loss/total_loss, 5.426040172576904, 2487
[INFO] 2021-07-12 19:22:46,595 [run_pretraining.py:  535]:	loss/mlm_loss, 5.426040172576904, 2487
[INFO] 2021-07-12 19:22:46,595 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4860000849002972e-05, 2487
[INFO] 2021-07-12 19:22:46,595 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2487
[INFO] 2021-07-12 19:22:46,595 [run_pretraining.py:  558]:	worker_index: 2, step: 2487, cost: 5.426040, mlm loss: 5.426040, speed: 1.083700 steps/s, speed: 8.669603 samples/s, speed: 4438.836650 tokens/s, learning rate: 2.486e-05, loss_scalings: 2814.750488, pp_loss: 6.673059
[INFO] 2021-07-12 19:22:46,596 [run_pretraining.py:  512]:	********exe.run_2487******* 
[INFO] 2021-07-12 19:22:47,527 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:47,527 [run_pretraining.py:  534]:	loss/total_loss, 7.08183479309082, 2488
[INFO] 2021-07-12 19:22:47,527 [run_pretraining.py:  535]:	loss/mlm_loss, 7.08183479309082, 2488
[INFO] 2021-07-12 19:22:47,527 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.486999801476486e-05, 2488
[INFO] 2021-07-12 19:22:47,528 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2488
[INFO] 2021-07-12 19:22:47,528 [run_pretraining.py:  558]:	worker_index: 2, step: 2488, cost: 7.081835, mlm loss: 7.081835, speed: 1.073505 steps/s, speed: 8.588039 samples/s, speed: 4397.076200 tokens/s, learning rate: 2.487e-05, loss_scalings: 2814.750488, pp_loss: 7.215113
[INFO] 2021-07-12 19:22:47,528 [run_pretraining.py:  512]:	********exe.run_2488******* 
[INFO] 2021-07-12 19:22:48,464 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:48,464 [run_pretraining.py:  534]:	loss/total_loss, 7.312042713165283, 2489
[INFO] 2021-07-12 19:22:48,464 [run_pretraining.py:  535]:	loss/mlm_loss, 7.312042713165283, 2489
[INFO] 2021-07-12 19:22:48,464 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4879998818505555e-05, 2489
[INFO] 2021-07-12 19:22:48,464 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2489
[INFO] 2021-07-12 19:22:48,465 [run_pretraining.py:  558]:	worker_index: 2, step: 2489, cost: 7.312043, mlm loss: 7.312043, speed: 1.068015 steps/s, speed: 8.544120 samples/s, speed: 4374.589194 tokens/s, learning rate: 2.488e-05, loss_scalings: 2814.750488, pp_loss: 7.184777
[INFO] 2021-07-12 19:22:48,465 [run_pretraining.py:  512]:	********exe.run_2489******* 
[INFO] 2021-07-12 19:22:49,389 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:49,389 [run_pretraining.py:  534]:	loss/total_loss, 7.521799564361572, 2490
[INFO] 2021-07-12 19:22:49,389 [run_pretraining.py:  535]:	loss/mlm_loss, 7.521799564361572, 2490
[INFO] 2021-07-12 19:22:49,389 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.488999962224625e-05, 2490
[INFO] 2021-07-12 19:22:49,390 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2490
[INFO] 2021-07-12 19:22:49,390 [run_pretraining.py:  558]:	worker_index: 2, step: 2490, cost: 7.521800, mlm loss: 7.521800, speed: 1.081671 steps/s, speed: 8.653371 samples/s, speed: 4430.525881 tokens/s, learning rate: 2.489e-05, loss_scalings: 2814.750488, pp_loss: 6.930087
[INFO] 2021-07-12 19:22:49,390 [run_pretraining.py:  512]:	********exe.run_2490******* 
[INFO] 2021-07-12 19:22:50,335 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:50,335 [run_pretraining.py:  534]:	loss/total_loss, 7.36335563659668, 2491
[INFO] 2021-07-12 19:22:50,335 [run_pretraining.py:  535]:	loss/mlm_loss, 7.36335563659668, 2491
[INFO] 2021-07-12 19:22:50,335 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4899998606997542e-05, 2491
[INFO] 2021-07-12 19:22:50,335 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2491
[INFO] 2021-07-12 19:22:50,335 [run_pretraining.py:  558]:	worker_index: 2, step: 2491, cost: 7.363356, mlm loss: 7.363356, speed: 1.057893 steps/s, speed: 8.463141 samples/s, speed: 4333.128072 tokens/s, learning rate: 2.490e-05, loss_scalings: 2814.750488, pp_loss: 6.729325
[INFO] 2021-07-12 19:22:50,336 [run_pretraining.py:  512]:	********exe.run_2491******* 
[INFO] 2021-07-12 19:22:51,250 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:51,250 [run_pretraining.py:  534]:	loss/total_loss, 7.203681468963623, 2492
[INFO] 2021-07-12 19:22:51,250 [run_pretraining.py:  535]:	loss/mlm_loss, 7.203681468963623, 2492
[INFO] 2021-07-12 19:22:51,251 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4909999410738237e-05, 2492
[INFO] 2021-07-12 19:22:51,251 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2492
[INFO] 2021-07-12 19:22:51,251 [run_pretraining.py:  558]:	worker_index: 2, step: 2492, cost: 7.203681, mlm loss: 7.203681, speed: 1.093313 steps/s, speed: 8.746506 samples/s, speed: 4478.211221 tokens/s, learning rate: 2.491e-05, loss_scalings: 2814.750488, pp_loss: 7.268686
[INFO] 2021-07-12 19:22:51,251 [run_pretraining.py:  512]:	********exe.run_2492******* 
[INFO] 2021-07-12 19:22:52,174 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:52,174 [run_pretraining.py:  534]:	loss/total_loss, 7.519461631774902, 2493
[INFO] 2021-07-12 19:22:52,174 [run_pretraining.py:  535]:	loss/mlm_loss, 7.519461631774902, 2493
[INFO] 2021-07-12 19:22:52,174 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4920000214478932e-05, 2493
[INFO] 2021-07-12 19:22:52,175 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2493
[INFO] 2021-07-12 19:22:52,175 [run_pretraining.py:  558]:	worker_index: 2, step: 2493, cost: 7.519462, mlm loss: 7.519462, speed: 1.083065 steps/s, speed: 8.664517 samples/s, speed: 4436.232464 tokens/s, learning rate: 2.492e-05, loss_scalings: 2814.750488, pp_loss: 7.302125
[INFO] 2021-07-12 19:22:52,175 [run_pretraining.py:  512]:	********exe.run_2493******* 
[INFO] 2021-07-12 19:22:53,094 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:53,095 [run_pretraining.py:  534]:	loss/total_loss, 3.9610302448272705, 2494
[INFO] 2021-07-12 19:22:53,095 [run_pretraining.py:  535]:	loss/mlm_loss, 3.9610302448272705, 2494
[INFO] 2021-07-12 19:22:53,095 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4929999199230224e-05, 2494
[INFO] 2021-07-12 19:22:53,095 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2494
[INFO] 2021-07-12 19:22:53,095 [run_pretraining.py:  558]:	worker_index: 2, step: 2494, cost: 3.961030, mlm loss: 3.961030, speed: 1.087010 steps/s, speed: 8.696080 samples/s, speed: 4452.392773 tokens/s, learning rate: 2.493e-05, loss_scalings: 2814.750488, pp_loss: 6.381649
[INFO] 2021-07-12 19:22:53,095 [run_pretraining.py:  512]:	********exe.run_2494******* 
[INFO] 2021-07-12 19:22:54,020 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:54,021 [run_pretraining.py:  534]:	loss/total_loss, 7.192049980163574, 2495
[INFO] 2021-07-12 19:22:54,021 [run_pretraining.py:  535]:	loss/mlm_loss, 7.192049980163574, 2495
[INFO] 2021-07-12 19:22:54,021 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.494000000297092e-05, 2495
[INFO] 2021-07-12 19:22:54,021 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2495
[INFO] 2021-07-12 19:22:54,021 [run_pretraining.py:  558]:	worker_index: 2, step: 2495, cost: 7.192050, mlm loss: 7.192050, speed: 1.080468 steps/s, speed: 8.643743 samples/s, speed: 4425.596522 tokens/s, learning rate: 2.494e-05, loss_scalings: 2814.750488, pp_loss: 7.227405
[INFO] 2021-07-12 19:22:54,021 [run_pretraining.py:  512]:	********exe.run_2495******* 
[INFO] 2021-07-12 19:22:54,942 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:54,942 [run_pretraining.py:  534]:	loss/total_loss, 7.05307149887085, 2496
[INFO] 2021-07-12 19:22:54,942 [run_pretraining.py:  535]:	loss/mlm_loss, 7.05307149887085, 2496
[INFO] 2021-07-12 19:22:54,943 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4950000806711614e-05, 2496
[INFO] 2021-07-12 19:22:54,943 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2496
[INFO] 2021-07-12 19:22:54,943 [run_pretraining.py:  558]:	worker_index: 2, step: 2496, cost: 7.053071, mlm loss: 7.053071, speed: 1.085960 steps/s, speed: 8.687677 samples/s, speed: 4448.090591 tokens/s, learning rate: 2.495e-05, loss_scalings: 2814.750488, pp_loss: 7.133855
[INFO] 2021-07-12 19:22:54,943 [run_pretraining.py:  512]:	********exe.run_2496******* 
[INFO] 2021-07-12 19:22:55,866 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:55,866 [run_pretraining.py:  534]:	loss/total_loss, 7.155842304229736, 2497
[INFO] 2021-07-12 19:22:55,867 [run_pretraining.py:  535]:	loss/mlm_loss, 7.155842304229736, 2497
[INFO] 2021-07-12 19:22:55,867 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4959997972473502e-05, 2497
[INFO] 2021-07-12 19:22:55,867 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2497
[INFO] 2021-07-12 19:22:55,867 [run_pretraining.py:  558]:	worker_index: 2, step: 2497, cost: 7.155842, mlm loss: 7.155842, speed: 1.082897 steps/s, speed: 8.663179 samples/s, speed: 4435.547540 tokens/s, learning rate: 2.496e-05, loss_scalings: 2814.750488, pp_loss: 7.360292
[INFO] 2021-07-12 19:22:55,867 [run_pretraining.py:  512]:	********exe.run_2497******* 
[INFO] 2021-07-12 19:22:56,791 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:56,791 [run_pretraining.py:  534]:	loss/total_loss, 8.005990028381348, 2498
[INFO] 2021-07-12 19:22:56,791 [run_pretraining.py:  535]:	loss/mlm_loss, 8.005990028381348, 2498
[INFO] 2021-07-12 19:22:56,792 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4969998776214197e-05, 2498
[INFO] 2021-07-12 19:22:56,792 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2498
[INFO] 2021-07-12 19:22:56,792 [run_pretraining.py:  558]:	worker_index: 2, step: 2498, cost: 8.005990, mlm loss: 8.005990, speed: 1.081838 steps/s, speed: 8.654701 samples/s, speed: 4431.206970 tokens/s, learning rate: 2.497e-05, loss_scalings: 2814.750488, pp_loss: 6.621728
[INFO] 2021-07-12 19:22:56,792 [run_pretraining.py:  512]:	********exe.run_2498******* 
[INFO] 2021-07-12 19:22:57,716 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:57,717 [run_pretraining.py:  534]:	loss/total_loss, 7.413238525390625, 2499
[INFO] 2021-07-12 19:22:57,717 [run_pretraining.py:  535]:	loss/mlm_loss, 7.413238525390625, 2499
[INFO] 2021-07-12 19:22:57,717 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4979999579954892e-05, 2499
[INFO] 2021-07-12 19:22:57,717 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2499
[INFO] 2021-07-12 19:22:57,717 [run_pretraining.py:  558]:	worker_index: 2, step: 2499, cost: 7.413239, mlm loss: 7.413239, speed: 1.081292 steps/s, speed: 8.650337 samples/s, speed: 4428.972503 tokens/s, learning rate: 2.498e-05, loss_scalings: 2814.750488, pp_loss: 7.558593
[INFO] 2021-07-12 19:22:57,717 [run_pretraining.py:  512]:	********exe.run_2499******* 
[INFO] 2021-07-12 19:22:58,650 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:58,651 [run_pretraining.py:  534]:	loss/total_loss, 7.6138458251953125, 2500
[INFO] 2021-07-12 19:22:58,651 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6138458251953125, 2500
[INFO] 2021-07-12 19:22:58,651 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4989998564706184e-05, 2500
[INFO] 2021-07-12 19:22:58,651 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2500
[INFO] 2021-07-12 19:22:58,651 [run_pretraining.py:  558]:	worker_index: 2, step: 2500, cost: 7.613846, mlm loss: 7.613846, speed: 1.071611 steps/s, speed: 8.572889 samples/s, speed: 4389.319000 tokens/s, learning rate: 2.499e-05, loss_scalings: 2814.750488, pp_loss: 6.958975
[INFO] 2021-07-12 19:22:58,651 [run_pretraining.py:  512]:	********exe.run_2500******* 
[INFO] 2021-07-12 19:22:59,566 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:59,567 [run_pretraining.py:  534]:	loss/total_loss, 7.3287177085876465, 2501
[INFO] 2021-07-12 19:22:59,567 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3287177085876465, 2501
[INFO] 2021-07-12 19:22:59,567 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.499999936844688e-05, 2501
[INFO] 2021-07-12 19:22:59,567 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2501
[INFO] 2021-07-12 19:22:59,567 [run_pretraining.py:  558]:	worker_index: 2, step: 2501, cost: 7.328718, mlm loss: 7.328718, speed: 1.092454 steps/s, speed: 8.739633 samples/s, speed: 4474.692189 tokens/s, learning rate: 2.500e-05, loss_scalings: 2814.750488, pp_loss: 7.399444
[INFO] 2021-07-12 19:22:59,567 [run_pretraining.py:  512]:	********exe.run_2501******* 
[INFO] 2021-07-12 19:23:00,493 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:00,494 [run_pretraining.py:  534]:	loss/total_loss, 7.021270275115967, 2502
[INFO] 2021-07-12 19:23:00,494 [run_pretraining.py:  535]:	loss/mlm_loss, 7.021270275115967, 2502
[INFO] 2021-07-12 19:23:00,494 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.500999835319817e-05, 2502
[INFO] 2021-07-12 19:23:00,494 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2502
[INFO] 2021-07-12 19:23:00,494 [run_pretraining.py:  558]:	worker_index: 2, step: 2502, cost: 7.021270, mlm loss: 7.021270, speed: 1.079162 steps/s, speed: 8.633293 samples/s, speed: 4420.245905 tokens/s, learning rate: 2.501e-05, loss_scalings: 2814.750488, pp_loss: 7.240521
[INFO] 2021-07-12 19:23:00,494 [run_pretraining.py:  512]:	********exe.run_2502******* 
[INFO] 2021-07-12 19:23:01,410 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:01,410 [run_pretraining.py:  534]:	loss/total_loss, 7.824393272399902, 2503
[INFO] 2021-07-12 19:23:01,410 [run_pretraining.py:  535]:	loss/mlm_loss, 7.824393272399902, 2503
[INFO] 2021-07-12 19:23:01,410 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5019999156938866e-05, 2503
[INFO] 2021-07-12 19:23:01,410 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2503
[INFO] 2021-07-12 19:23:01,411 [run_pretraining.py:  558]:	worker_index: 2, step: 2503, cost: 7.824393, mlm loss: 7.824393, speed: 1.091946 steps/s, speed: 8.735572 samples/s, speed: 4472.612766 tokens/s, learning rate: 2.502e-05, loss_scalings: 2814.750488, pp_loss: 7.140788
[INFO] 2021-07-12 19:23:01,411 [run_pretraining.py:  512]:	********exe.run_2503******* 
[INFO] 2021-07-12 19:23:02,331 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:02,331 [run_pretraining.py:  534]:	loss/total_loss, 7.705895900726318, 2504
[INFO] 2021-07-12 19:23:02,331 [run_pretraining.py:  535]:	loss/mlm_loss, 7.705895900726318, 2504
[INFO] 2021-07-12 19:23:02,332 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5029998141690157e-05, 2504
[INFO] 2021-07-12 19:23:02,332 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2504
[INFO] 2021-07-12 19:23:02,332 [run_pretraining.py:  558]:	worker_index: 2, step: 2504, cost: 7.705896, mlm loss: 7.705896, speed: 1.086307 steps/s, speed: 8.690454 samples/s, speed: 4449.512203 tokens/s, learning rate: 2.503e-05, loss_scalings: 2814.750488, pp_loss: 7.235766
[INFO] 2021-07-12 19:23:02,332 [run_pretraining.py:  512]:	********exe.run_2504******* 
[INFO] 2021-07-12 19:23:03,254 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:03,254 [run_pretraining.py:  534]:	loss/total_loss, 4.654656887054443, 2505
[INFO] 2021-07-12 19:23:03,254 [run_pretraining.py:  535]:	loss/mlm_loss, 4.654656887054443, 2505
[INFO] 2021-07-12 19:23:03,255 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5040000764420256e-05, 2505
[INFO] 2021-07-12 19:23:03,255 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2505
[INFO] 2021-07-12 19:23:03,255 [run_pretraining.py:  558]:	worker_index: 2, step: 2505, cost: 4.654657, mlm loss: 4.654657, speed: 1.084068 steps/s, speed: 8.672547 samples/s, speed: 4440.344164 tokens/s, learning rate: 2.504e-05, loss_scalings: 2814.750488, pp_loss: 6.439250
[INFO] 2021-07-12 19:23:03,255 [run_pretraining.py:  512]:	********exe.run_2505******* 
[INFO] 2021-07-12 19:23:04,177 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:04,178 [run_pretraining.py:  534]:	loss/total_loss, 7.3851704597473145, 2506
[INFO] 2021-07-12 19:23:04,178 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3851704597473145, 2506
[INFO] 2021-07-12 19:23:04,178 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5049997930182144e-05, 2506
[INFO] 2021-07-12 19:23:04,178 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2506
[INFO] 2021-07-12 19:23:04,178 [run_pretraining.py:  558]:	worker_index: 2, step: 2506, cost: 7.385170, mlm loss: 7.385170, speed: 1.083768 steps/s, speed: 8.670140 samples/s, speed: 4439.111919 tokens/s, learning rate: 2.505e-05, loss_scalings: 2814.750488, pp_loss: 7.188504
[INFO] 2021-07-12 19:23:04,178 [run_pretraining.py:  512]:	********exe.run_2506******* 
[INFO] 2021-07-12 19:23:05,100 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:05,100 [run_pretraining.py:  534]:	loss/total_loss, 7.020533561706543, 2507
[INFO] 2021-07-12 19:23:05,100 [run_pretraining.py:  535]:	loss/mlm_loss, 7.020533561706543, 2507
[INFO] 2021-07-12 19:23:05,101 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5060000552912243e-05, 2507
[INFO] 2021-07-12 19:23:05,101 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2507
[INFO] 2021-07-12 19:23:05,101 [run_pretraining.py:  558]:	worker_index: 2, step: 2507, cost: 7.020534, mlm loss: 7.020534, speed: 1.084525 steps/s, speed: 8.676202 samples/s, speed: 4442.215639 tokens/s, learning rate: 2.506e-05, loss_scalings: 2814.750488, pp_loss: 7.044669
[INFO] 2021-07-12 19:23:05,101 [run_pretraining.py:  512]:	********exe.run_2507******* 
[INFO] 2021-07-12 19:23:06,017 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:06,017 [run_pretraining.py:  534]:	loss/total_loss, 7.038993835449219, 2508
[INFO] 2021-07-12 19:23:06,017 [run_pretraining.py:  535]:	loss/mlm_loss, 7.038993835449219, 2508
[INFO] 2021-07-12 19:23:06,017 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5069999537663534e-05, 2508
[INFO] 2021-07-12 19:23:06,018 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2508
[INFO] 2021-07-12 19:23:06,018 [run_pretraining.py:  558]:	worker_index: 2, step: 2508, cost: 7.038994, mlm loss: 7.038994, speed: 1.091312 steps/s, speed: 8.730499 samples/s, speed: 4470.015331 tokens/s, learning rate: 2.507e-05, loss_scalings: 2814.750488, pp_loss: 7.127908
[INFO] 2021-07-12 19:23:06,018 [run_pretraining.py:  512]:	********exe.run_2508******* 
[INFO] 2021-07-12 19:23:06,937 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:06,937 [run_pretraining.py:  534]:	loss/total_loss, 7.2771477699279785, 2509
[INFO] 2021-07-12 19:23:06,937 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2771477699279785, 2509
[INFO] 2021-07-12 19:23:06,937 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.508000034140423e-05, 2509
[INFO] 2021-07-12 19:23:06,937 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2509
[INFO] 2021-07-12 19:23:06,938 [run_pretraining.py:  558]:	worker_index: 2, step: 2509, cost: 7.277148, mlm loss: 7.277148, speed: 1.087697 steps/s, speed: 8.701580 samples/s, speed: 4455.208909 tokens/s, learning rate: 2.508e-05, loss_scalings: 2814.750488, pp_loss: 7.006819
[INFO] 2021-07-12 19:23:06,938 [run_pretraining.py:  512]:	********exe.run_2509******* 
[INFO] 2021-07-12 19:23:07,855 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:07,855 [run_pretraining.py:  534]:	loss/total_loss, 7.179098129272461, 2510
[INFO] 2021-07-12 19:23:07,856 [run_pretraining.py:  535]:	loss/mlm_loss, 7.179098129272461, 2510
[INFO] 2021-07-12 19:23:07,856 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.508999932615552e-05, 2510
[INFO] 2021-07-12 19:23:07,856 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2510
[INFO] 2021-07-12 19:23:07,856 [run_pretraining.py:  558]:	worker_index: 2, step: 2510, cost: 7.179098, mlm loss: 7.179098, speed: 1.089777 steps/s, speed: 8.718215 samples/s, speed: 4463.726280 tokens/s, learning rate: 2.509e-05, loss_scalings: 2814.750488, pp_loss: 6.967111
[INFO] 2021-07-12 19:23:07,856 [run_pretraining.py:  512]:	********exe.run_2510******* 
[INFO] 2021-07-12 19:23:08,771 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:08,771 [run_pretraining.py:  534]:	loss/total_loss, 7.233120918273926, 2511
[INFO] 2021-07-12 19:23:08,771 [run_pretraining.py:  535]:	loss/mlm_loss, 7.233120918273926, 2511
[INFO] 2021-07-12 19:23:08,772 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5099998310906813e-05, 2511
[INFO] 2021-07-12 19:23:08,772 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2511
[INFO] 2021-07-12 19:23:08,772 [run_pretraining.py:  558]:	worker_index: 2, step: 2511, cost: 7.233121, mlm loss: 7.233121, speed: 1.092477 steps/s, speed: 8.739815 samples/s, speed: 4474.785430 tokens/s, learning rate: 2.510e-05, loss_scalings: 2814.750488, pp_loss: 7.187589
[INFO] 2021-07-12 19:23:08,772 [run_pretraining.py:  512]:	********exe.run_2511******* 
[INFO] 2021-07-12 19:23:09,696 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:09,697 [run_pretraining.py:  534]:	loss/total_loss, 7.379177570343018, 2512
[INFO] 2021-07-12 19:23:09,697 [run_pretraining.py:  535]:	loss/mlm_loss, 7.379177570343018, 2512
[INFO] 2021-07-12 19:23:09,697 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5109999114647508e-05, 2512
[INFO] 2021-07-12 19:23:09,697 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2512
[INFO] 2021-07-12 19:23:09,697 [run_pretraining.py:  558]:	worker_index: 2, step: 2512, cost: 7.379178, mlm loss: 7.379178, speed: 1.081442 steps/s, speed: 8.651532 samples/s, speed: 4429.584586 tokens/s, learning rate: 2.511e-05, loss_scalings: 2814.750488, pp_loss: 7.052990
[INFO] 2021-07-12 19:23:09,697 [run_pretraining.py:  512]:	********exe.run_2512******* 
[INFO] 2021-07-12 19:23:10,613 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:10,614 [run_pretraining.py:  534]:	loss/total_loss, 6.510652542114258, 2513
[INFO] 2021-07-12 19:23:10,614 [run_pretraining.py:  535]:	loss/mlm_loss, 6.510652542114258, 2513
[INFO] 2021-07-12 19:23:10,614 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.51199980993988e-05, 2513
[INFO] 2021-07-12 19:23:10,614 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2513
[INFO] 2021-07-12 19:23:10,614 [run_pretraining.py:  558]:	worker_index: 2, step: 2513, cost: 6.510653, mlm loss: 6.510653, speed: 1.090967 steps/s, speed: 8.727740 samples/s, speed: 4468.602673 tokens/s, learning rate: 2.512e-05, loss_scalings: 2814.750488, pp_loss: 6.794631
[INFO] 2021-07-12 19:23:10,614 [run_pretraining.py:  512]:	********exe.run_2513******* 
[INFO] 2021-07-12 19:23:11,535 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:11,535 [run_pretraining.py:  534]:	loss/total_loss, 6.572864532470703, 2514
[INFO] 2021-07-12 19:23:11,535 [run_pretraining.py:  535]:	loss/mlm_loss, 6.572864532470703, 2514
[INFO] 2021-07-12 19:23:11,536 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5130000722128898e-05, 2514
[INFO] 2021-07-12 19:23:11,536 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2514
[INFO] 2021-07-12 19:23:11,536 [run_pretraining.py:  558]:	worker_index: 2, step: 2514, cost: 6.572865, mlm loss: 6.572865, speed: 1.086027 steps/s, speed: 8.688217 samples/s, speed: 4448.367008 tokens/s, learning rate: 2.513e-05, loss_scalings: 2814.750488, pp_loss: 7.288972
[INFO] 2021-07-12 19:23:11,536 [run_pretraining.py:  512]:	********exe.run_2514******* 
[INFO] 2021-07-12 19:23:12,452 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:12,452 [run_pretraining.py:  534]:	loss/total_loss, 7.355670928955078, 2515
[INFO] 2021-07-12 19:23:12,452 [run_pretraining.py:  535]:	loss/mlm_loss, 7.355670928955078, 2515
[INFO] 2021-07-12 19:23:12,452 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5139997887890786e-05, 2515
[INFO] 2021-07-12 19:23:12,452 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2515
[INFO] 2021-07-12 19:23:12,452 [run_pretraining.py:  558]:	worker_index: 2, step: 2515, cost: 7.355671, mlm loss: 7.355671, speed: 1.091431 steps/s, speed: 8.731448 samples/s, speed: 4470.501539 tokens/s, learning rate: 2.514e-05, loss_scalings: 2814.750488, pp_loss: 7.294724
[INFO] 2021-07-12 19:23:12,453 [run_pretraining.py:  512]:	********exe.run_2515******* 
[INFO] 2021-07-12 19:23:13,373 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:13,373 [run_pretraining.py:  534]:	loss/total_loss, 6.935468673706055, 2516
[INFO] 2021-07-12 19:23:13,373 [run_pretraining.py:  535]:	loss/mlm_loss, 6.935468673706055, 2516
[INFO] 2021-07-12 19:23:13,373 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5150000510620885e-05, 2516
[INFO] 2021-07-12 19:23:13,373 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2516
[INFO] 2021-07-12 19:23:13,373 [run_pretraining.py:  558]:	worker_index: 2, step: 2516, cost: 6.935469, mlm loss: 6.935469, speed: 1.086588 steps/s, speed: 8.692703 samples/s, speed: 4450.663753 tokens/s, learning rate: 2.515e-05, loss_scalings: 2814.750488, pp_loss: 7.386633
[INFO] 2021-07-12 19:23:13,373 [run_pretraining.py:  512]:	********exe.run_2516******* 
[INFO] 2021-07-12 19:23:14,293 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:14,293 [run_pretraining.py:  534]:	loss/total_loss, 5.665624618530273, 2517
[INFO] 2021-07-12 19:23:14,293 [run_pretraining.py:  535]:	loss/mlm_loss, 5.665624618530273, 2517
[INFO] 2021-07-12 19:23:14,293 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5159999495372176e-05, 2517
[INFO] 2021-07-12 19:23:14,293 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2517
[INFO] 2021-07-12 19:23:14,293 [run_pretraining.py:  558]:	worker_index: 2, step: 2517, cost: 5.665625, mlm loss: 5.665625, speed: 1.087566 steps/s, speed: 8.700528 samples/s, speed: 4454.670577 tokens/s, learning rate: 2.516e-05, loss_scalings: 2814.750488, pp_loss: 6.666901
[INFO] 2021-07-12 19:23:14,294 [run_pretraining.py:  512]:	********exe.run_2517******* 
[INFO] 2021-07-12 19:23:15,239 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:15,239 [run_pretraining.py:  534]:	loss/total_loss, 8.278002738952637, 2518
[INFO] 2021-07-12 19:23:15,239 [run_pretraining.py:  535]:	loss/mlm_loss, 8.278002738952637, 2518
[INFO] 2021-07-12 19:23:15,240 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.517000029911287e-05, 2518
[INFO] 2021-07-12 19:23:15,240 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2518
[INFO] 2021-07-12 19:23:15,240 [run_pretraining.py:  558]:	worker_index: 2, step: 2518, cost: 8.278003, mlm loss: 8.278003, speed: 1.057502 steps/s, speed: 8.460019 samples/s, speed: 4331.529739 tokens/s, learning rate: 2.517e-05, loss_scalings: 2814.750488, pp_loss: 7.215763
[INFO] 2021-07-12 19:23:15,240 [run_pretraining.py:  512]:	********exe.run_2518******* 
[INFO] 2021-07-12 19:23:16,161 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:16,161 [run_pretraining.py:  534]:	loss/total_loss, 6.936657428741455, 2519
[INFO] 2021-07-12 19:23:16,161 [run_pretraining.py:  535]:	loss/mlm_loss, 6.936657428741455, 2519
[INFO] 2021-07-12 19:23:16,161 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5179999283864163e-05, 2519
[INFO] 2021-07-12 19:23:16,161 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2519
[INFO] 2021-07-12 19:23:16,161 [run_pretraining.py:  558]:	worker_index: 2, step: 2519, cost: 6.936657, mlm loss: 6.936657, speed: 1.085681 steps/s, speed: 8.685448 samples/s, speed: 4446.949580 tokens/s, learning rate: 2.518e-05, loss_scalings: 2814.750488, pp_loss: 7.067880
[INFO] 2021-07-12 19:23:16,161 [run_pretraining.py:  512]:	********exe.run_2519******* 
[INFO] 2021-07-12 19:23:17,082 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:17,083 [run_pretraining.py:  534]:	loss/total_loss, 7.764618873596191, 2520
[INFO] 2021-07-12 19:23:17,083 [run_pretraining.py:  535]:	loss/mlm_loss, 7.764618873596191, 2520
[INFO] 2021-07-12 19:23:17,083 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5189998268615454e-05, 2520
[INFO] 2021-07-12 19:23:17,083 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2520
[INFO] 2021-07-12 19:23:17,083 [run_pretraining.py:  558]:	worker_index: 2, step: 2520, cost: 7.764619, mlm loss: 7.764619, speed: 1.085357 steps/s, speed: 8.682855 samples/s, speed: 4445.621633 tokens/s, learning rate: 2.519e-05, loss_scalings: 2814.750488, pp_loss: 7.453455
[INFO] 2021-07-12 19:23:17,083 [run_pretraining.py:  512]:	********exe.run_2520******* 
[INFO] 2021-07-12 19:23:18,007 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:18,007 [run_pretraining.py:  534]:	loss/total_loss, 7.1948323249816895, 2521
[INFO] 2021-07-12 19:23:18,008 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1948323249816895, 2521
[INFO] 2021-07-12 19:23:18,008 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.519999907235615e-05, 2521
[INFO] 2021-07-12 19:23:18,008 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2521
[INFO] 2021-07-12 19:23:18,008 [run_pretraining.py:  558]:	worker_index: 2, step: 2521, cost: 7.194832, mlm loss: 7.194832, speed: 1.082417 steps/s, speed: 8.659338 samples/s, speed: 4433.580989 tokens/s, learning rate: 2.520e-05, loss_scalings: 2814.750488, pp_loss: 7.527367
[INFO] 2021-07-12 19:23:18,008 [run_pretraining.py:  512]:	********exe.run_2521******* 
[INFO] 2021-07-12 19:23:18,927 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:18,927 [run_pretraining.py:  534]:	loss/total_loss, 6.681110858917236, 2522
[INFO] 2021-07-12 19:23:18,927 [run_pretraining.py:  535]:	loss/mlm_loss, 6.681110858917236, 2522
[INFO] 2021-07-12 19:23:18,928 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.520999805710744e-05, 2522
[INFO] 2021-07-12 19:23:18,928 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2522
[INFO] 2021-07-12 19:23:18,928 [run_pretraining.py:  558]:	worker_index: 2, step: 2522, cost: 6.681111, mlm loss: 6.681111, speed: 1.087842 steps/s, speed: 8.702738 samples/s, speed: 4455.801686 tokens/s, learning rate: 2.521e-05, loss_scalings: 2814.750488, pp_loss: 6.991858
[INFO] 2021-07-12 19:23:18,928 [run_pretraining.py:  512]:	********exe.run_2522******* 
[INFO] 2021-07-12 19:23:19,865 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:19,866 [run_pretraining.py:  534]:	loss/total_loss, 7.31608247756958, 2523
[INFO] 2021-07-12 19:23:19,866 [run_pretraining.py:  535]:	loss/mlm_loss, 7.31608247756958, 2523
[INFO] 2021-07-12 19:23:19,866 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.522000067983754e-05, 2523
[INFO] 2021-07-12 19:23:19,866 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2523
[INFO] 2021-07-12 19:23:19,866 [run_pretraining.py:  558]:	worker_index: 2, step: 2523, cost: 7.316082, mlm loss: 7.316082, speed: 1.066514 steps/s, speed: 8.532112 samples/s, speed: 4368.441201 tokens/s, learning rate: 2.522e-05, loss_scalings: 2814.750488, pp_loss: 7.204025
[INFO] 2021-07-12 19:23:19,866 [run_pretraining.py:  512]:	********exe.run_2523******* 
[INFO] 2021-07-12 19:23:20,847 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:20,848 [run_pretraining.py:  534]:	loss/total_loss, 7.361373424530029, 2524
[INFO] 2021-07-12 19:23:20,848 [run_pretraining.py:  535]:	loss/mlm_loss, 7.361373424530029, 2524
[INFO] 2021-07-12 19:23:20,848 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.522999966458883e-05, 2524
[INFO] 2021-07-12 19:23:20,848 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2524
[INFO] 2021-07-12 19:23:20,848 [run_pretraining.py:  558]:	worker_index: 2, step: 2524, cost: 7.361373, mlm loss: 7.361373, speed: 1.018702 steps/s, speed: 8.149612 samples/s, speed: 4172.601582 tokens/s, learning rate: 2.523e-05, loss_scalings: 2814.750488, pp_loss: 7.293647
[INFO] 2021-07-12 19:23:20,848 [run_pretraining.py:  512]:	********exe.run_2524******* 
[INFO] 2021-07-12 19:23:21,774 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:21,775 [run_pretraining.py:  534]:	loss/total_loss, 6.314384937286377, 2525
[INFO] 2021-07-12 19:23:21,775 [run_pretraining.py:  535]:	loss/mlm_loss, 6.314384937286377, 2525
[INFO] 2021-07-12 19:23:21,775 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5240000468329526e-05, 2525
[INFO] 2021-07-12 19:23:21,775 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2525
[INFO] 2021-07-12 19:23:21,775 [run_pretraining.py:  558]:	worker_index: 2, step: 2525, cost: 6.314385, mlm loss: 6.314385, speed: 1.079403 steps/s, speed: 8.635228 samples/s, speed: 4421.236711 tokens/s, learning rate: 2.524e-05, loss_scalings: 2814.750488, pp_loss: 7.245855
[INFO] 2021-07-12 19:23:21,775 [run_pretraining.py:  512]:	********exe.run_2525******* 
[INFO] 2021-07-12 19:23:22,732 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:22,732 [run_pretraining.py:  534]:	loss/total_loss, 2.79006028175354, 2526
[INFO] 2021-07-12 19:23:22,732 [run_pretraining.py:  535]:	loss/mlm_loss, 2.79006028175354, 2526
[INFO] 2021-07-12 19:23:22,732 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5249999453080818e-05, 2526
[INFO] 2021-07-12 19:23:22,732 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2526
[INFO] 2021-07-12 19:23:22,732 [run_pretraining.py:  558]:	worker_index: 2, step: 2526, cost: 2.790060, mlm loss: 2.790060, speed: 1.045300 steps/s, speed: 8.362402 samples/s, speed: 4281.549989 tokens/s, learning rate: 2.525e-05, loss_scalings: 2814.750488, pp_loss: 6.368634
[INFO] 2021-07-12 19:23:22,732 [run_pretraining.py:  512]:	********exe.run_2526******* 
[INFO] 2021-07-12 19:23:23,644 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:23,644 [run_pretraining.py:  534]:	loss/total_loss, 7.537256240844727, 2527
[INFO] 2021-07-12 19:23:23,644 [run_pretraining.py:  535]:	loss/mlm_loss, 7.537256240844727, 2527
[INFO] 2021-07-12 19:23:23,644 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5260000256821513e-05, 2527
[INFO] 2021-07-12 19:23:23,644 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2527
[INFO] 2021-07-12 19:23:23,644 [run_pretraining.py:  558]:	worker_index: 2, step: 2527, cost: 7.537256, mlm loss: 7.537256, speed: 1.097256 steps/s, speed: 8.778046 samples/s, speed: 4494.359558 tokens/s, learning rate: 2.526e-05, loss_scalings: 2814.750488, pp_loss: 7.283250
[INFO] 2021-07-12 19:23:23,644 [run_pretraining.py:  512]:	********exe.run_2527******* 
[INFO] 2021-07-12 19:23:24,557 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:24,558 [run_pretraining.py:  534]:	loss/total_loss, 7.727061748504639, 2528
[INFO] 2021-07-12 19:23:24,558 [run_pretraining.py:  535]:	loss/mlm_loss, 7.727061748504639, 2528
[INFO] 2021-07-12 19:23:24,558 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5269999241572805e-05, 2528
[INFO] 2021-07-12 19:23:24,558 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2528
[INFO] 2021-07-12 19:23:24,558 [run_pretraining.py:  558]:	worker_index: 2, step: 2528, cost: 7.727062, mlm loss: 7.727062, speed: 1.095237 steps/s, speed: 8.761898 samples/s, speed: 4486.091622 tokens/s, learning rate: 2.527e-05, loss_scalings: 2814.750488, pp_loss: 7.091714
[INFO] 2021-07-12 19:23:24,558 [run_pretraining.py:  512]:	********exe.run_2528******* 
[INFO] 2021-07-12 19:23:25,476 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:25,476 [run_pretraining.py:  534]:	loss/total_loss, 6.993246078491211, 2529
[INFO] 2021-07-12 19:23:25,477 [run_pretraining.py:  535]:	loss/mlm_loss, 6.993246078491211, 2529
[INFO] 2021-07-12 19:23:25,477 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5279998226324096e-05, 2529
[INFO] 2021-07-12 19:23:25,477 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2529
[INFO] 2021-07-12 19:23:25,477 [run_pretraining.py:  558]:	worker_index: 2, step: 2529, cost: 6.993246, mlm loss: 6.993246, speed: 1.089170 steps/s, speed: 8.713364 samples/s, speed: 4461.242256 tokens/s, learning rate: 2.528e-05, loss_scalings: 2814.750488, pp_loss: 7.167954
[INFO] 2021-07-12 19:23:25,477 [run_pretraining.py:  512]:	********exe.run_2529******* 
[INFO] 2021-07-12 19:23:26,393 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:26,394 [run_pretraining.py:  534]:	loss/total_loss, 7.137614727020264, 2530
[INFO] 2021-07-12 19:23:26,394 [run_pretraining.py:  535]:	loss/mlm_loss, 7.137614727020264, 2530
[INFO] 2021-07-12 19:23:26,394 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.528999903006479e-05, 2530
[INFO] 2021-07-12 19:23:26,394 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2530
[INFO] 2021-07-12 19:23:26,394 [run_pretraining.py:  558]:	worker_index: 2, step: 2530, cost: 7.137615, mlm loss: 7.137615, speed: 1.090733 steps/s, speed: 8.725860 samples/s, speed: 4467.640484 tokens/s, learning rate: 2.529e-05, loss_scalings: 2814.750488, pp_loss: 7.084911
[INFO] 2021-07-12 19:23:26,394 [run_pretraining.py:  512]:	********exe.run_2530******* 
[INFO] 2021-07-12 19:23:27,309 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:27,309 [run_pretraining.py:  534]:	loss/total_loss, 6.741422653198242, 2531
[INFO] 2021-07-12 19:23:27,309 [run_pretraining.py:  535]:	loss/mlm_loss, 6.741422653198242, 2531
[INFO] 2021-07-12 19:23:27,309 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5299998014816083e-05, 2531
[INFO] 2021-07-12 19:23:27,310 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2531
[INFO] 2021-07-12 19:23:27,310 [run_pretraining.py:  558]:	worker_index: 2, step: 2531, cost: 6.741423, mlm loss: 6.741423, speed: 1.093060 steps/s, speed: 8.744478 samples/s, speed: 4477.172549 tokens/s, learning rate: 2.530e-05, loss_scalings: 2814.750488, pp_loss: 7.272822
[INFO] 2021-07-12 19:23:27,310 [run_pretraining.py:  512]:	********exe.run_2531******* 
[INFO] 2021-07-12 19:23:28,225 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:28,226 [run_pretraining.py:  534]:	loss/total_loss, 7.339198112487793, 2532
[INFO] 2021-07-12 19:23:28,226 [run_pretraining.py:  535]:	loss/mlm_loss, 7.339198112487793, 2532
[INFO] 2021-07-12 19:23:28,226 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.531000063754618e-05, 2532
[INFO] 2021-07-12 19:23:28,226 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2532
[INFO] 2021-07-12 19:23:28,226 [run_pretraining.py:  558]:	worker_index: 2, step: 2532, cost: 7.339198, mlm loss: 7.339198, speed: 1.091901 steps/s, speed: 8.735206 samples/s, speed: 4472.425305 tokens/s, learning rate: 2.531e-05, loss_scalings: 2814.750488, pp_loss: 7.219221
[INFO] 2021-07-12 19:23:28,226 [run_pretraining.py:  512]:	********exe.run_2532******* 
[INFO] 2021-07-12 19:23:29,136 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:29,137 [run_pretraining.py:  534]:	loss/total_loss, 8.286683082580566, 2533
[INFO] 2021-07-12 19:23:29,137 [run_pretraining.py:  535]:	loss/mlm_loss, 8.286683082580566, 2533
[INFO] 2021-07-12 19:23:29,137 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5319999622297473e-05, 2533
[INFO] 2021-07-12 19:23:29,137 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2533
[INFO] 2021-07-12 19:23:29,137 [run_pretraining.py:  558]:	worker_index: 2, step: 2533, cost: 8.286683, mlm loss: 8.286683, speed: 1.098326 steps/s, speed: 8.786611 samples/s, speed: 4498.744685 tokens/s, learning rate: 2.532e-05, loss_scalings: 2814.750488, pp_loss: 7.481059
[INFO] 2021-07-12 19:23:29,137 [run_pretraining.py:  512]:	********exe.run_2533******* 
[INFO] 2021-07-12 19:23:30,046 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:30,047 [run_pretraining.py:  534]:	loss/total_loss, 7.310128211975098, 2534
[INFO] 2021-07-12 19:23:30,047 [run_pretraining.py:  535]:	loss/mlm_loss, 7.310128211975098, 2534
[INFO] 2021-07-12 19:23:30,047 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.533000042603817e-05, 2534
[INFO] 2021-07-12 19:23:30,047 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2534
[INFO] 2021-07-12 19:23:30,047 [run_pretraining.py:  558]:	worker_index: 2, step: 2534, cost: 7.310128, mlm loss: 7.310128, speed: 1.099384 steps/s, speed: 8.795070 samples/s, speed: 4503.075819 tokens/s, learning rate: 2.533e-05, loss_scalings: 2814.750488, pp_loss: 7.375178
[INFO] 2021-07-12 19:23:30,047 [run_pretraining.py:  512]:	********exe.run_2534******* 
[INFO] 2021-07-12 19:23:30,962 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:30,963 [run_pretraining.py:  534]:	loss/total_loss, 7.678459644317627, 2535
[INFO] 2021-07-12 19:23:30,963 [run_pretraining.py:  535]:	loss/mlm_loss, 7.678459644317627, 2535
[INFO] 2021-07-12 19:23:30,963 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.533999941078946e-05, 2535
[INFO] 2021-07-12 19:23:30,963 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2535
[INFO] 2021-07-12 19:23:30,963 [run_pretraining.py:  558]:	worker_index: 2, step: 2535, cost: 7.678460, mlm loss: 7.678460, speed: 1.092418 steps/s, speed: 8.739344 samples/s, speed: 4474.544177 tokens/s, learning rate: 2.534e-05, loss_scalings: 2814.750488, pp_loss: 7.169769
[INFO] 2021-07-12 19:23:30,963 [run_pretraining.py:  512]:	********exe.run_2535******* 
[INFO] 2021-07-12 19:23:31,872 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:31,873 [run_pretraining.py:  534]:	loss/total_loss, 7.630124568939209, 2536
[INFO] 2021-07-12 19:23:31,873 [run_pretraining.py:  535]:	loss/mlm_loss, 7.630124568939209, 2536
[INFO] 2021-07-12 19:23:31,873 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5350000214530155e-05, 2536
[INFO] 2021-07-12 19:23:31,873 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2536
[INFO] 2021-07-12 19:23:31,873 [run_pretraining.py:  558]:	worker_index: 2, step: 2536, cost: 7.630125, mlm loss: 7.630125, speed: 1.099660 steps/s, speed: 8.797284 samples/s, speed: 4504.209209 tokens/s, learning rate: 2.535e-05, loss_scalings: 2814.750488, pp_loss: 7.294681
[INFO] 2021-07-12 19:23:31,873 [run_pretraining.py:  512]:	********exe.run_2536******* 
[INFO] 2021-07-12 19:23:32,791 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:32,791 [run_pretraining.py:  534]:	loss/total_loss, 7.482664108276367, 2537
[INFO] 2021-07-12 19:23:32,791 [run_pretraining.py:  535]:	loss/mlm_loss, 7.482664108276367, 2537
[INFO] 2021-07-12 19:23:32,792 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5359999199281447e-05, 2537
[INFO] 2021-07-12 19:23:32,792 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2537
[INFO] 2021-07-12 19:23:32,792 [run_pretraining.py:  558]:	worker_index: 2, step: 2537, cost: 7.482664, mlm loss: 7.482664, speed: 1.089605 steps/s, speed: 8.716838 samples/s, speed: 4463.021245 tokens/s, learning rate: 2.536e-05, loss_scalings: 2814.750488, pp_loss: 6.961679
[INFO] 2021-07-12 19:23:32,792 [run_pretraining.py:  512]:	********exe.run_2537******* 
[INFO] 2021-07-12 19:23:33,731 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:33,732 [run_pretraining.py:  534]:	loss/total_loss, 6.918597221374512, 2538
[INFO] 2021-07-12 19:23:33,732 [run_pretraining.py:  535]:	loss/mlm_loss, 6.918597221374512, 2538
[INFO] 2021-07-12 19:23:33,732 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5369998184032738e-05, 2538
[INFO] 2021-07-12 19:23:33,732 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2538
[INFO] 2021-07-12 19:23:33,732 [run_pretraining.py:  558]:	worker_index: 2, step: 2538, cost: 6.918597, mlm loss: 6.918597, speed: 1.063846 steps/s, speed: 8.510765 samples/s, speed: 4357.511752 tokens/s, learning rate: 2.537e-05, loss_scalings: 2814.750488, pp_loss: 7.150956
[INFO] 2021-07-12 19:23:33,732 [run_pretraining.py:  512]:	********exe.run_2538******* 
[INFO] 2021-07-12 19:23:34,662 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:34,663 [run_pretraining.py:  534]:	loss/total_loss, 7.786702632904053, 2539
[INFO] 2021-07-12 19:23:34,663 [run_pretraining.py:  535]:	loss/mlm_loss, 7.786702632904053, 2539
[INFO] 2021-07-12 19:23:34,663 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5379998987773433e-05, 2539
[INFO] 2021-07-12 19:23:34,663 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2539
[INFO] 2021-07-12 19:23:34,663 [run_pretraining.py:  558]:	worker_index: 2, step: 2539, cost: 7.786703, mlm loss: 7.786703, speed: 1.075262 steps/s, speed: 8.602095 samples/s, speed: 4404.272532 tokens/s, learning rate: 2.538e-05, loss_scalings: 2814.750488, pp_loss: 7.220363
[INFO] 2021-07-12 19:23:34,663 [run_pretraining.py:  512]:	********exe.run_2539******* 
[INFO] 2021-07-12 19:23:35,721 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:35,722 [run_pretraining.py:  534]:	loss/total_loss, 7.167266368865967, 2540
[INFO] 2021-07-12 19:23:35,722 [run_pretraining.py:  535]:	loss/mlm_loss, 7.167266368865967, 2540
[INFO] 2021-07-12 19:23:35,722 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5389997972524725e-05, 2540
[INFO] 2021-07-12 19:23:35,722 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2540
[INFO] 2021-07-12 19:23:35,722 [run_pretraining.py:  558]:	worker_index: 2, step: 2540, cost: 7.167266, mlm loss: 7.167266, speed: 0.944774 steps/s, speed: 7.558195 samples/s, speed: 3869.795740 tokens/s, learning rate: 2.539e-05, loss_scalings: 2814.750488, pp_loss: 7.162412
[INFO] 2021-07-12 19:23:35,722 [run_pretraining.py:  512]:	********exe.run_2540******* 
[INFO] 2021-07-12 19:23:36,776 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:36,776 [run_pretraining.py:  534]:	loss/total_loss, 7.132089138031006, 2541
[INFO] 2021-07-12 19:23:36,776 [run_pretraining.py:  535]:	loss/mlm_loss, 7.132089138031006, 2541
[INFO] 2021-07-12 19:23:36,777 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5400000595254824e-05, 2541
[INFO] 2021-07-12 19:23:36,777 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2541
[INFO] 2021-07-12 19:23:36,777 [run_pretraining.py:  558]:	worker_index: 2, step: 2541, cost: 7.132089, mlm loss: 7.132089, speed: 0.948603 steps/s, speed: 7.588822 samples/s, speed: 3885.476887 tokens/s, learning rate: 2.540e-05, loss_scalings: 2814.750488, pp_loss: 7.265066
[INFO] 2021-07-12 19:23:36,777 [run_pretraining.py:  512]:	********exe.run_2541******* 
[INFO] 2021-07-12 19:23:37,821 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:37,822 [run_pretraining.py:  534]:	loss/total_loss, 7.596668720245361, 2542
[INFO] 2021-07-12 19:23:37,822 [run_pretraining.py:  535]:	loss/mlm_loss, 7.596668720245361, 2542
[INFO] 2021-07-12 19:23:37,822 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5409999580006115e-05, 2542
[INFO] 2021-07-12 19:23:37,822 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2542
[INFO] 2021-07-12 19:23:37,822 [run_pretraining.py:  558]:	worker_index: 2, step: 2542, cost: 7.596669, mlm loss: 7.596669, speed: 0.957152 steps/s, speed: 7.657212 samples/s, speed: 3920.492622 tokens/s, learning rate: 2.541e-05, loss_scalings: 2814.750488, pp_loss: 7.604827
[INFO] 2021-07-12 19:23:37,822 [run_pretraining.py:  512]:	********exe.run_2542******* 
[INFO] 2021-07-12 19:23:38,868 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:38,868 [run_pretraining.py:  534]:	loss/total_loss, 7.268157005310059, 2543
[INFO] 2021-07-12 19:23:38,868 [run_pretraining.py:  535]:	loss/mlm_loss, 7.268157005310059, 2543
[INFO] 2021-07-12 19:23:38,868 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.542000038374681e-05, 2543
[INFO] 2021-07-12 19:23:38,868 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2543
[INFO] 2021-07-12 19:23:38,868 [run_pretraining.py:  558]:	worker_index: 2, step: 2543, cost: 7.268157, mlm loss: 7.268157, speed: 0.956313 steps/s, speed: 7.650503 samples/s, speed: 3917.057429 tokens/s, learning rate: 2.542e-05, loss_scalings: 2814.750488, pp_loss: 7.232774
[INFO] 2021-07-12 19:23:38,868 [run_pretraining.py:  512]:	********exe.run_2543******* 
[INFO] 2021-07-12 19:23:39,924 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:39,924 [run_pretraining.py:  534]:	loss/total_loss, 7.803890228271484, 2544
[INFO] 2021-07-12 19:23:39,924 [run_pretraining.py:  535]:	loss/mlm_loss, 7.803890228271484, 2544
[INFO] 2021-07-12 19:23:39,924 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5429999368498102e-05, 2544
[INFO] 2021-07-12 19:23:39,924 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2544
[INFO] 2021-07-12 19:23:39,924 [run_pretraining.py:  558]:	worker_index: 2, step: 2544, cost: 7.803890, mlm loss: 7.803890, speed: 0.947351 steps/s, speed: 7.578805 samples/s, speed: 3880.348209 tokens/s, learning rate: 2.543e-05, loss_scalings: 2814.750488, pp_loss: 7.402530
[INFO] 2021-07-12 19:23:39,925 [run_pretraining.py:  512]:	********exe.run_2544******* 
[INFO] 2021-07-12 19:23:40,972 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:40,973 [run_pretraining.py:  534]:	loss/total_loss, 7.441732406616211, 2545
[INFO] 2021-07-12 19:23:40,973 [run_pretraining.py:  535]:	loss/mlm_loss, 7.441732406616211, 2545
[INFO] 2021-07-12 19:23:40,973 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5440000172238797e-05, 2545
[INFO] 2021-07-12 19:23:40,973 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2545
[INFO] 2021-07-12 19:23:40,973 [run_pretraining.py:  558]:	worker_index: 2, step: 2545, cost: 7.441732, mlm loss: 7.441732, speed: 0.954280 steps/s, speed: 7.634238 samples/s, speed: 3908.730045 tokens/s, learning rate: 2.544e-05, loss_scalings: 2814.750488, pp_loss: 6.975865
[INFO] 2021-07-12 19:23:40,973 [run_pretraining.py:  512]:	********exe.run_2545******* 
[INFO] 2021-07-12 19:23:42,027 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:42,028 [run_pretraining.py:  534]:	loss/total_loss, 7.749338150024414, 2546
[INFO] 2021-07-12 19:23:42,028 [run_pretraining.py:  535]:	loss/mlm_loss, 7.749338150024414, 2546
[INFO] 2021-07-12 19:23:42,028 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.544999915699009e-05, 2546
[INFO] 2021-07-12 19:23:42,028 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2546
[INFO] 2021-07-12 19:23:42,028 [run_pretraining.py:  558]:	worker_index: 2, step: 2546, cost: 7.749338, mlm loss: 7.749338, speed: 0.948381 steps/s, speed: 7.587046 samples/s, speed: 3884.567586 tokens/s, learning rate: 2.545e-05, loss_scalings: 2814.750488, pp_loss: 7.339580
[INFO] 2021-07-12 19:23:42,028 [run_pretraining.py:  512]:	********exe.run_2546******* 
[INFO] 2021-07-12 19:23:43,083 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:43,083 [run_pretraining.py:  534]:	loss/total_loss, 7.521943092346191, 2547
[INFO] 2021-07-12 19:23:43,083 [run_pretraining.py:  535]:	loss/mlm_loss, 7.521943092346191, 2547
[INFO] 2021-07-12 19:23:43,083 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.545999814174138e-05, 2547
[INFO] 2021-07-12 19:23:43,084 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2547
[INFO] 2021-07-12 19:23:43,084 [run_pretraining.py:  558]:	worker_index: 2, step: 2547, cost: 7.521943, mlm loss: 7.521943, speed: 0.947913 steps/s, speed: 7.583306 samples/s, speed: 3882.652858 tokens/s, learning rate: 2.546e-05, loss_scalings: 2814.750488, pp_loss: 7.603662
[INFO] 2021-07-12 19:23:43,084 [run_pretraining.py:  512]:	********exe.run_2547******* 
[INFO] 2021-07-12 19:23:44,139 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:44,140 [run_pretraining.py:  534]:	loss/total_loss, 7.719671249389648, 2548
[INFO] 2021-07-12 19:23:44,140 [run_pretraining.py:  535]:	loss/mlm_loss, 7.719671249389648, 2548
[INFO] 2021-07-12 19:23:44,140 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.547000076447148e-05, 2548
[INFO] 2021-07-12 19:23:44,140 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2548
[INFO] 2021-07-12 19:23:44,140 [run_pretraining.py:  558]:	worker_index: 2, step: 2548, cost: 7.719671, mlm loss: 7.719671, speed: 0.946964 steps/s, speed: 7.575708 samples/s, speed: 3878.762504 tokens/s, learning rate: 2.547e-05, loss_scalings: 2814.750488, pp_loss: 7.131019
[INFO] 2021-07-12 19:23:44,140 [run_pretraining.py:  512]:	********exe.run_2548******* 
[INFO] 2021-07-12 19:23:45,206 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:45,206 [run_pretraining.py:  534]:	loss/total_loss, 7.590899467468262, 2549
[INFO] 2021-07-12 19:23:45,206 [run_pretraining.py:  535]:	loss/mlm_loss, 7.590899467468262, 2549
[INFO] 2021-07-12 19:23:45,207 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5479997930233367e-05, 2549
[INFO] 2021-07-12 19:23:45,207 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2549
[INFO] 2021-07-12 19:23:45,207 [run_pretraining.py:  558]:	worker_index: 2, step: 2549, cost: 7.590899, mlm loss: 7.590899, speed: 0.938132 steps/s, speed: 7.505055 samples/s, speed: 3842.588051 tokens/s, learning rate: 2.548e-05, loss_scalings: 2814.750488, pp_loss: 7.511672
[INFO] 2021-07-12 19:23:45,207 [run_pretraining.py:  512]:	********exe.run_2549******* 
[INFO] 2021-07-12 19:23:46,279 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:46,280 [run_pretraining.py:  534]:	loss/total_loss, 7.617246627807617, 2550
[INFO] 2021-07-12 19:23:46,280 [run_pretraining.py:  535]:	loss/mlm_loss, 7.617246627807617, 2550
[INFO] 2021-07-12 19:23:46,280 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5490000552963465e-05, 2550
[INFO] 2021-07-12 19:23:46,280 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2550
[INFO] 2021-07-12 19:23:46,280 [run_pretraining.py:  558]:	worker_index: 2, step: 2550, cost: 7.617247, mlm loss: 7.617247, speed: 0.932005 steps/s, speed: 7.456043 samples/s, speed: 3817.494208 tokens/s, learning rate: 2.549e-05, loss_scalings: 2814.750488, pp_loss: 7.645444
[INFO] 2021-07-12 19:23:46,280 [run_pretraining.py:  512]:	********exe.run_2550******* 
[INFO] 2021-07-12 19:23:47,335 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:47,336 [run_pretraining.py:  534]:	loss/total_loss, 7.520477294921875, 2551
[INFO] 2021-07-12 19:23:47,336 [run_pretraining.py:  535]:	loss/mlm_loss, 7.520477294921875, 2551
[INFO] 2021-07-12 19:23:47,336 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5499999537714757e-05, 2551
[INFO] 2021-07-12 19:23:47,336 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2551
[INFO] 2021-07-12 19:23:47,336 [run_pretraining.py:  558]:	worker_index: 2, step: 2551, cost: 7.520477, mlm loss: 7.520477, speed: 0.947651 steps/s, speed: 7.581204 samples/s, speed: 3881.576489 tokens/s, learning rate: 2.550e-05, loss_scalings: 2814.750488, pp_loss: 7.432946
[INFO] 2021-07-12 19:23:47,336 [run_pretraining.py:  512]:	********exe.run_2551******* 
[INFO] 2021-07-12 19:23:48,398 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:48,398 [run_pretraining.py:  534]:	loss/total_loss, 7.529508590698242, 2552
[INFO] 2021-07-12 19:23:48,399 [run_pretraining.py:  535]:	loss/mlm_loss, 7.529508590698242, 2552
[INFO] 2021-07-12 19:23:48,399 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5510000341455452e-05, 2552
[INFO] 2021-07-12 19:23:48,399 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2552
[INFO] 2021-07-12 19:23:48,399 [run_pretraining.py:  558]:	worker_index: 2, step: 2552, cost: 7.529509, mlm loss: 7.529509, speed: 0.941574 steps/s, speed: 7.532591 samples/s, speed: 3856.686673 tokens/s, learning rate: 2.551e-05, loss_scalings: 2814.750488, pp_loss: 7.336628
[INFO] 2021-07-12 19:23:48,399 [run_pretraining.py:  512]:	********exe.run_2552******* 
[INFO] 2021-07-12 19:23:49,451 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:49,451 [run_pretraining.py:  534]:	loss/total_loss, 7.138335227966309, 2553
[INFO] 2021-07-12 19:23:49,451 [run_pretraining.py:  535]:	loss/mlm_loss, 7.138335227966309, 2553
[INFO] 2021-07-12 19:23:49,452 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5519999326206744e-05, 2553
[INFO] 2021-07-12 19:23:49,452 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2553
[INFO] 2021-07-12 19:23:49,452 [run_pretraining.py:  558]:	worker_index: 2, step: 2553, cost: 7.138335, mlm loss: 7.138335, speed: 0.950337 steps/s, speed: 7.602698 samples/s, speed: 3892.581423 tokens/s, learning rate: 2.552e-05, loss_scalings: 2814.750488, pp_loss: 7.345903
[INFO] 2021-07-12 19:23:49,452 [run_pretraining.py:  512]:	********exe.run_2553******* 
[INFO] 2021-07-12 19:23:50,501 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:50,502 [run_pretraining.py:  534]:	loss/total_loss, 7.407533645629883, 2554
[INFO] 2021-07-12 19:23:50,502 [run_pretraining.py:  535]:	loss/mlm_loss, 7.407533645629883, 2554
[INFO] 2021-07-12 19:23:50,502 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5529998310958035e-05, 2554
[INFO] 2021-07-12 19:23:50,502 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2554
[INFO] 2021-07-12 19:23:50,502 [run_pretraining.py:  558]:	worker_index: 2, step: 2554, cost: 7.407534, mlm loss: 7.407534, speed: 0.952383 steps/s, speed: 7.619062 samples/s, speed: 3900.959644 tokens/s, learning rate: 2.553e-05, loss_scalings: 2814.750488, pp_loss: 7.386509
[INFO] 2021-07-12 19:23:50,502 [run_pretraining.py:  512]:	********exe.run_2554******* 
[INFO] 2021-07-12 19:23:51,554 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:51,554 [run_pretraining.py:  534]:	loss/total_loss, 7.692221641540527, 2555
[INFO] 2021-07-12 19:23:51,554 [run_pretraining.py:  535]:	loss/mlm_loss, 7.692221641540527, 2555
[INFO] 2021-07-12 19:23:51,555 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.553999911469873e-05, 2555
[INFO] 2021-07-12 19:23:51,555 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2555
[INFO] 2021-07-12 19:23:51,555 [run_pretraining.py:  558]:	worker_index: 2, step: 2555, cost: 7.692222, mlm loss: 7.692222, speed: 0.950718 steps/s, speed: 7.605747 samples/s, speed: 3894.142260 tokens/s, learning rate: 2.554e-05, loss_scalings: 2814.750488, pp_loss: 7.653240
[INFO] 2021-07-12 19:23:51,555 [run_pretraining.py:  512]:	********exe.run_2555******* 
[INFO] 2021-07-12 19:23:52,541 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:52,542 [run_pretraining.py:  534]:	loss/total_loss, 6.867879867553711, 2556
[INFO] 2021-07-12 19:23:52,542 [run_pretraining.py:  535]:	loss/mlm_loss, 6.867879867553711, 2556
[INFO] 2021-07-12 19:23:52,542 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5549998099450022e-05, 2556
[INFO] 2021-07-12 19:23:52,542 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2556
[INFO] 2021-07-12 19:23:52,542 [run_pretraining.py:  558]:	worker_index: 2, step: 2556, cost: 6.867880, mlm loss: 6.867880, speed: 1.013280 steps/s, speed: 8.106243 samples/s, speed: 4150.396534 tokens/s, learning rate: 2.555e-05, loss_scalings: 2814.750488, pp_loss: 6.590636
[INFO] 2021-07-12 19:23:52,542 [run_pretraining.py:  512]:	********exe.run_2556******* 
[INFO] 2021-07-12 19:23:53,509 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:53,510 [run_pretraining.py:  534]:	loss/total_loss, 7.478826999664307, 2557
[INFO] 2021-07-12 19:23:53,510 [run_pretraining.py:  535]:	loss/mlm_loss, 7.478826999664307, 2557
[INFO] 2021-07-12 19:23:53,510 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.556000072218012e-05, 2557
[INFO] 2021-07-12 19:23:53,510 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2557
[INFO] 2021-07-12 19:23:53,510 [run_pretraining.py:  558]:	worker_index: 2, step: 2557, cost: 7.478827, mlm loss: 7.478827, speed: 1.033950 steps/s, speed: 8.271600 samples/s, speed: 4235.059207 tokens/s, learning rate: 2.556e-05, loss_scalings: 2814.750488, pp_loss: 7.218324
[INFO] 2021-07-12 19:23:53,510 [run_pretraining.py:  512]:	********exe.run_2557******* 
[INFO] 2021-07-12 19:23:54,484 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:54,484 [run_pretraining.py:  534]:	loss/total_loss, 7.113935947418213, 2558
[INFO] 2021-07-12 19:23:54,484 [run_pretraining.py:  535]:	loss/mlm_loss, 7.113935947418213, 2558
[INFO] 2021-07-12 19:23:54,484 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.556999788794201e-05, 2558
[INFO] 2021-07-12 19:23:54,484 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2558
[INFO] 2021-07-12 19:23:54,484 [run_pretraining.py:  558]:	worker_index: 2, step: 2558, cost: 7.113936, mlm loss: 7.113936, speed: 1.026873 steps/s, speed: 8.214980 samples/s, speed: 4206.069906 tokens/s, learning rate: 2.557e-05, loss_scalings: 2814.750488, pp_loss: 6.380805
[INFO] 2021-07-12 19:23:54,484 [run_pretraining.py:  512]:	********exe.run_2558******* 
[INFO] 2021-07-12 19:23:55,464 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:55,465 [run_pretraining.py:  534]:	loss/total_loss, 7.561121940612793, 2559
[INFO] 2021-07-12 19:23:55,465 [run_pretraining.py:  535]:	loss/mlm_loss, 7.561121940612793, 2559
[INFO] 2021-07-12 19:23:55,465 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5580000510672107e-05, 2559
[INFO] 2021-07-12 19:23:55,465 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2559
[INFO] 2021-07-12 19:23:55,465 [run_pretraining.py:  558]:	worker_index: 2, step: 2559, cost: 7.561122, mlm loss: 7.561122, speed: 1.020060 steps/s, speed: 8.160480 samples/s, speed: 4178.165631 tokens/s, learning rate: 2.558e-05, loss_scalings: 2814.750488, pp_loss: 7.505106
[INFO] 2021-07-12 19:23:55,465 [run_pretraining.py:  512]:	********exe.run_2559******* 
[INFO] 2021-07-12 19:23:56,437 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:56,438 [run_pretraining.py:  534]:	loss/total_loss, 6.078036785125732, 2560
[INFO] 2021-07-12 19:23:56,438 [run_pretraining.py:  535]:	loss/mlm_loss, 6.078036785125732, 2560
[INFO] 2021-07-12 19:23:56,438 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.55899994954234e-05, 2560
[INFO] 2021-07-12 19:23:56,438 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2560
[INFO] 2021-07-12 19:23:56,438 [run_pretraining.py:  558]:	worker_index: 2, step: 2560, cost: 6.078037, mlm loss: 6.078037, speed: 1.028834 steps/s, speed: 8.230674 samples/s, speed: 4214.104943 tokens/s, learning rate: 2.559e-05, loss_scalings: 2814.750488, pp_loss: 6.877701
[INFO] 2021-07-12 19:23:56,438 [run_pretraining.py:  512]:	********exe.run_2560******* 
[INFO] 2021-07-12 19:23:57,410 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:57,411 [run_pretraining.py:  534]:	loss/total_loss, 6.791460037231445, 2561
[INFO] 2021-07-12 19:23:57,411 [run_pretraining.py:  535]:	loss/mlm_loss, 6.791460037231445, 2561
[INFO] 2021-07-12 19:23:57,411 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5600000299164094e-05, 2561
[INFO] 2021-07-12 19:23:57,411 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2561
[INFO] 2021-07-12 19:23:57,411 [run_pretraining.py:  558]:	worker_index: 2, step: 2561, cost: 6.791460, mlm loss: 6.791460, speed: 1.028187 steps/s, speed: 8.225494 samples/s, speed: 4211.453128 tokens/s, learning rate: 2.560e-05, loss_scalings: 2814.750488, pp_loss: 6.989186
[INFO] 2021-07-12 19:23:57,411 [run_pretraining.py:  512]:	********exe.run_2561******* 
[INFO] 2021-07-12 19:23:58,399 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:58,400 [run_pretraining.py:  534]:	loss/total_loss, 6.67010498046875, 2562
[INFO] 2021-07-12 19:23:58,400 [run_pretraining.py:  535]:	loss/mlm_loss, 6.67010498046875, 2562
[INFO] 2021-07-12 19:23:58,400 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5609999283915386e-05, 2562
[INFO] 2021-07-12 19:23:58,400 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2562
[INFO] 2021-07-12 19:23:58,400 [run_pretraining.py:  558]:	worker_index: 2, step: 2562, cost: 6.670105, mlm loss: 6.670105, speed: 1.011778 steps/s, speed: 8.094225 samples/s, speed: 4144.243241 tokens/s, learning rate: 2.561e-05, loss_scalings: 2814.750488, pp_loss: 7.141017
[INFO] 2021-07-12 19:23:58,400 [run_pretraining.py:  512]:	********exe.run_2562******* 
[INFO] 2021-07-12 19:23:59,390 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:59,390 [run_pretraining.py:  534]:	loss/total_loss, 7.017566680908203, 2563
[INFO] 2021-07-12 19:23:59,391 [run_pretraining.py:  535]:	loss/mlm_loss, 7.017566680908203, 2563
[INFO] 2021-07-12 19:23:59,391 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5619998268666677e-05, 2563
[INFO] 2021-07-12 19:23:59,391 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2563
[INFO] 2021-07-12 19:23:59,391 [run_pretraining.py:  558]:	worker_index: 2, step: 2563, cost: 7.017567, mlm loss: 7.017567, speed: 1.009887 steps/s, speed: 8.079096 samples/s, speed: 4136.497060 tokens/s, learning rate: 2.562e-05, loss_scalings: 2814.750488, pp_loss: 7.012636
[INFO] 2021-07-12 19:23:59,391 [run_pretraining.py:  512]:	********exe.run_2563******* 
[INFO] 2021-07-12 19:24:00,367 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:00,368 [run_pretraining.py:  534]:	loss/total_loss, 8.248981475830078, 2564
[INFO] 2021-07-12 19:24:00,368 [run_pretraining.py:  535]:	loss/mlm_loss, 8.248981475830078, 2564
[INFO] 2021-07-12 19:24:00,368 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5629999072407372e-05, 2564
[INFO] 2021-07-12 19:24:00,368 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2564
[INFO] 2021-07-12 19:24:00,368 [run_pretraining.py:  558]:	worker_index: 2, step: 2564, cost: 8.248981, mlm loss: 8.248981, speed: 1.023797 steps/s, speed: 8.190378 samples/s, speed: 4193.473700 tokens/s, learning rate: 2.563e-05, loss_scalings: 2814.750488, pp_loss: 7.440897
[INFO] 2021-07-12 19:24:00,368 [run_pretraining.py:  512]:	********exe.run_2564******* 
[INFO] 2021-07-12 19:24:01,355 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:01,356 [run_pretraining.py:  534]:	loss/total_loss, 7.574039936065674, 2565
[INFO] 2021-07-12 19:24:01,356 [run_pretraining.py:  535]:	loss/mlm_loss, 7.574039936065674, 2565
[INFO] 2021-07-12 19:24:01,356 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5639998057158664e-05, 2565
[INFO] 2021-07-12 19:24:01,356 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2565
[INFO] 2021-07-12 19:24:01,356 [run_pretraining.py:  558]:	worker_index: 2, step: 2565, cost: 7.574040, mlm loss: 7.574040, speed: 1.012903 steps/s, speed: 8.103221 samples/s, speed: 4148.848984 tokens/s, learning rate: 2.564e-05, loss_scalings: 2814.750488, pp_loss: 7.235084
[INFO] 2021-07-12 19:24:01,356 [run_pretraining.py:  512]:	********exe.run_2565******* 
[INFO] 2021-07-12 19:24:02,329 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:02,330 [run_pretraining.py:  534]:	loss/total_loss, 7.218930721282959, 2566
[INFO] 2021-07-12 19:24:02,330 [run_pretraining.py:  535]:	loss/mlm_loss, 7.218930721282959, 2566
[INFO] 2021-07-12 19:24:02,330 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5650000679888763e-05, 2566
[INFO] 2021-07-12 19:24:02,330 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2566
[INFO] 2021-07-12 19:24:02,330 [run_pretraining.py:  558]:	worker_index: 2, step: 2566, cost: 7.218931, mlm loss: 7.218931, speed: 1.027267 steps/s, speed: 8.218135 samples/s, speed: 4207.685178 tokens/s, learning rate: 2.565e-05, loss_scalings: 2814.750488, pp_loss: 7.582809
[INFO] 2021-07-12 19:24:02,330 [run_pretraining.py:  512]:	********exe.run_2566******* 
[INFO] 2021-07-12 19:24:03,301 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:03,301 [run_pretraining.py:  534]:	loss/total_loss, 7.249495029449463, 2567
[INFO] 2021-07-12 19:24:03,302 [run_pretraining.py:  535]:	loss/mlm_loss, 7.249495029449463, 2567
[INFO] 2021-07-12 19:24:03,302 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.565999784565065e-05, 2567
[INFO] 2021-07-12 19:24:03,302 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2567
[INFO] 2021-07-12 19:24:03,302 [run_pretraining.py:  558]:	worker_index: 2, step: 2567, cost: 7.249495, mlm loss: 7.249495, speed: 1.029792 steps/s, speed: 8.238339 samples/s, speed: 4218.029386 tokens/s, learning rate: 2.566e-05, loss_scalings: 2814.750488, pp_loss: 7.376417
[INFO] 2021-07-12 19:24:03,302 [run_pretraining.py:  512]:	********exe.run_2567******* 
[INFO] 2021-07-12 19:24:04,279 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:04,279 [run_pretraining.py:  534]:	loss/total_loss, 7.068078517913818, 2568
[INFO] 2021-07-12 19:24:04,280 [run_pretraining.py:  535]:	loss/mlm_loss, 7.068078517913818, 2568
[INFO] 2021-07-12 19:24:04,280 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.567000046838075e-05, 2568
[INFO] 2021-07-12 19:24:04,280 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2568
[INFO] 2021-07-12 19:24:04,280 [run_pretraining.py:  558]:	worker_index: 2, step: 2568, cost: 7.068079, mlm loss: 7.068079, speed: 1.023134 steps/s, speed: 8.185076 samples/s, speed: 4190.758839 tokens/s, learning rate: 2.567e-05, loss_scalings: 2814.750488, pp_loss: 7.195796
[INFO] 2021-07-12 19:24:04,280 [run_pretraining.py:  512]:	********exe.run_2568******* 
[INFO] 2021-07-12 19:24:05,252 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:05,253 [run_pretraining.py:  534]:	loss/total_loss, 7.339369773864746, 2569
[INFO] 2021-07-12 19:24:05,253 [run_pretraining.py:  535]:	loss/mlm_loss, 7.339369773864746, 2569
[INFO] 2021-07-12 19:24:05,253 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.567999945313204e-05, 2569
[INFO] 2021-07-12 19:24:05,253 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2569
[INFO] 2021-07-12 19:24:05,253 [run_pretraining.py:  558]:	worker_index: 2, step: 2569, cost: 7.339370, mlm loss: 7.339370, speed: 1.028168 steps/s, speed: 8.225347 samples/s, speed: 4211.377764 tokens/s, learning rate: 2.568e-05, loss_scalings: 2814.750488, pp_loss: 7.281007
[INFO] 2021-07-12 19:24:05,253 [run_pretraining.py:  512]:	********exe.run_2569******* 
[INFO] 2021-07-12 19:24:06,237 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:06,238 [run_pretraining.py:  534]:	loss/total_loss, 7.368920803070068, 2570
[INFO] 2021-07-12 19:24:06,238 [run_pretraining.py:  535]:	loss/mlm_loss, 7.368920803070068, 2570
[INFO] 2021-07-12 19:24:06,238 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5690000256872736e-05, 2570
[INFO] 2021-07-12 19:24:06,238 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2570
[INFO] 2021-07-12 19:24:06,238 [run_pretraining.py:  558]:	worker_index: 2, step: 2570, cost: 7.368921, mlm loss: 7.368921, speed: 1.015566 steps/s, speed: 8.124524 samples/s, speed: 4159.756491 tokens/s, learning rate: 2.569e-05, loss_scalings: 2814.750488, pp_loss: 7.649071
[INFO] 2021-07-12 19:24:06,238 [run_pretraining.py:  512]:	********exe.run_2570******* 
[INFO] 2021-07-12 19:24:07,233 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:07,233 [run_pretraining.py:  534]:	loss/total_loss, 6.866690635681152, 2571
[INFO] 2021-07-12 19:24:07,233 [run_pretraining.py:  535]:	loss/mlm_loss, 6.866690635681152, 2571
[INFO] 2021-07-12 19:24:07,233 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5699999241624027e-05, 2571
[INFO] 2021-07-12 19:24:07,233 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2571
[INFO] 2021-07-12 19:24:07,233 [run_pretraining.py:  558]:	worker_index: 2, step: 2571, cost: 6.866691, mlm loss: 6.866691, speed: 1.005527 steps/s, speed: 8.044219 samples/s, speed: 4118.640077 tokens/s, learning rate: 2.570e-05, loss_scalings: 2814.750488, pp_loss: 7.384322
[INFO] 2021-07-12 19:24:07,233 [run_pretraining.py:  512]:	********exe.run_2571******* 
[INFO] 2021-07-12 19:24:08,214 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:08,214 [run_pretraining.py:  534]:	loss/total_loss, 7.370465278625488, 2572
[INFO] 2021-07-12 19:24:08,214 [run_pretraining.py:  535]:	loss/mlm_loss, 7.370465278625488, 2572
[INFO] 2021-07-12 19:24:08,214 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.570999822637532e-05, 2572
[INFO] 2021-07-12 19:24:08,214 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2572
[INFO] 2021-07-12 19:24:08,214 [run_pretraining.py:  558]:	worker_index: 2, step: 2572, cost: 7.370465, mlm loss: 7.370465, speed: 1.019968 steps/s, speed: 8.159747 samples/s, speed: 4177.790711 tokens/s, learning rate: 2.571e-05, loss_scalings: 2814.750488, pp_loss: 7.286270
[INFO] 2021-07-12 19:24:08,214 [run_pretraining.py:  512]:	********exe.run_2572******* 
[INFO] 2021-07-12 19:24:09,190 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:09,190 [run_pretraining.py:  534]:	loss/total_loss, 6.886123180389404, 2573
[INFO] 2021-07-12 19:24:09,190 [run_pretraining.py:  535]:	loss/mlm_loss, 6.886123180389404, 2573
[INFO] 2021-07-12 19:24:09,191 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5719999030116014e-05, 2573
[INFO] 2021-07-12 19:24:09,191 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2573
[INFO] 2021-07-12 19:24:09,191 [run_pretraining.py:  558]:	worker_index: 2, step: 2573, cost: 6.886123, mlm loss: 6.886123, speed: 1.024862 steps/s, speed: 8.198894 samples/s, speed: 4197.833624 tokens/s, learning rate: 2.572e-05, loss_scalings: 2814.750488, pp_loss: 7.439520
[INFO] 2021-07-12 19:24:09,191 [run_pretraining.py:  512]:	********exe.run_2573******* 
[INFO] 2021-07-12 19:24:10,167 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:10,167 [run_pretraining.py:  534]:	loss/total_loss, 7.93880558013916, 2574
[INFO] 2021-07-12 19:24:10,168 [run_pretraining.py:  535]:	loss/mlm_loss, 7.93880558013916, 2574
[INFO] 2021-07-12 19:24:10,168 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5729998014867306e-05, 2574
[INFO] 2021-07-12 19:24:10,168 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2574
[INFO] 2021-07-12 19:24:10,168 [run_pretraining.py:  558]:	worker_index: 2, step: 2574, cost: 7.938806, mlm loss: 7.938806, speed: 1.024103 steps/s, speed: 8.192822 samples/s, speed: 4194.724906 tokens/s, learning rate: 2.573e-05, loss_scalings: 2814.750488, pp_loss: 7.477113
[INFO] 2021-07-12 19:24:10,168 [run_pretraining.py:  512]:	********exe.run_2574******* 
[INFO] 2021-07-12 19:24:11,124 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:11,124 [run_pretraining.py:  534]:	loss/total_loss, 5.583421230316162, 2575
[INFO] 2021-07-12 19:24:11,124 [run_pretraining.py:  535]:	loss/mlm_loss, 5.583421230316162, 2575
[INFO] 2021-07-12 19:24:11,124 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5740000637597404e-05, 2575
[INFO] 2021-07-12 19:24:11,124 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2575
[INFO] 2021-07-12 19:24:11,124 [run_pretraining.py:  558]:	worker_index: 2, step: 2575, cost: 5.583421, mlm loss: 5.583421, speed: 1.046073 steps/s, speed: 8.368584 samples/s, speed: 4284.715044 tokens/s, learning rate: 2.574e-05, loss_scalings: 2814.750488, pp_loss: 6.686875
[INFO] 2021-07-12 19:24:11,124 [run_pretraining.py:  512]:	********exe.run_2575******* 
[INFO] 2021-07-12 19:24:12,031 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:12,032 [run_pretraining.py:  534]:	loss/total_loss, 6.238533020019531, 2576
[INFO] 2021-07-12 19:24:12,032 [run_pretraining.py:  535]:	loss/mlm_loss, 6.238533020019531, 2576
[INFO] 2021-07-12 19:24:12,032 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5749997803359292e-05, 2576
[INFO] 2021-07-12 19:24:12,032 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2576
[INFO] 2021-07-12 19:24:12,032 [run_pretraining.py:  558]:	worker_index: 2, step: 2576, cost: 6.238533, mlm loss: 6.238533, speed: 1.102422 steps/s, speed: 8.819377 samples/s, speed: 4515.521153 tokens/s, learning rate: 2.575e-05, loss_scalings: 2814.750488, pp_loss: 6.226354
[INFO] 2021-07-12 19:24:12,032 [run_pretraining.py:  512]:	********exe.run_2576******* 
[INFO] 2021-07-12 19:24:12,943 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:12,944 [run_pretraining.py:  534]:	loss/total_loss, 7.593616008758545, 2577
[INFO] 2021-07-12 19:24:12,944 [run_pretraining.py:  535]:	loss/mlm_loss, 7.593616008758545, 2577
[INFO] 2021-07-12 19:24:12,944 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.576000042608939e-05, 2577
[INFO] 2021-07-12 19:24:12,944 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2577
[INFO] 2021-07-12 19:24:12,944 [run_pretraining.py:  558]:	worker_index: 2, step: 2577, cost: 7.593616, mlm loss: 7.593616, speed: 1.097386 steps/s, speed: 8.779084 samples/s, speed: 4494.891061 tokens/s, learning rate: 2.576e-05, loss_scalings: 2814.750488, pp_loss: 6.605250
[INFO] 2021-07-12 19:24:12,944 [run_pretraining.py:  512]:	********exe.run_2577******* 
[INFO] 2021-07-12 19:24:13,853 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:13,853 [run_pretraining.py:  534]:	loss/total_loss, 6.179627418518066, 2578
[INFO] 2021-07-12 19:24:13,853 [run_pretraining.py:  535]:	loss/mlm_loss, 6.179627418518066, 2578
[INFO] 2021-07-12 19:24:13,853 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5769999410840683e-05, 2578
[INFO] 2021-07-12 19:24:13,853 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2578
[INFO] 2021-07-12 19:24:13,853 [run_pretraining.py:  558]:	worker_index: 2, step: 2578, cost: 6.179627, mlm loss: 6.179627, speed: 1.100232 steps/s, speed: 8.801860 samples/s, speed: 4506.552174 tokens/s, learning rate: 2.577e-05, loss_scalings: 2814.750488, pp_loss: 7.250036
[INFO] 2021-07-12 19:24:13,853 [run_pretraining.py:  512]:	********exe.run_2578******* 
[INFO] 2021-07-12 19:24:14,765 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:14,765 [run_pretraining.py:  534]:	loss/total_loss, 6.792529582977295, 2579
[INFO] 2021-07-12 19:24:14,765 [run_pretraining.py:  535]:	loss/mlm_loss, 6.792529582977295, 2579
[INFO] 2021-07-12 19:24:14,765 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5780000214581378e-05, 2579
[INFO] 2021-07-12 19:24:14,765 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2579
[INFO] 2021-07-12 19:24:14,765 [run_pretraining.py:  558]:	worker_index: 2, step: 2579, cost: 6.792530, mlm loss: 6.792530, speed: 1.097179 steps/s, speed: 8.777428 samples/s, speed: 4494.043303 tokens/s, learning rate: 2.578e-05, loss_scalings: 2814.750488, pp_loss: 7.057503
[INFO] 2021-07-12 19:24:14,766 [run_pretraining.py:  512]:	********exe.run_2579******* 
[INFO] 2021-07-12 19:24:15,678 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:15,678 [run_pretraining.py:  534]:	loss/total_loss, 7.163118839263916, 2580
[INFO] 2021-07-12 19:24:15,678 [run_pretraining.py:  535]:	loss/mlm_loss, 7.163118839263916, 2580
[INFO] 2021-07-12 19:24:15,679 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.578999919933267e-05, 2580
[INFO] 2021-07-12 19:24:15,679 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2580
[INFO] 2021-07-12 19:24:15,679 [run_pretraining.py:  558]:	worker_index: 2, step: 2580, cost: 7.163119, mlm loss: 7.163119, speed: 1.095666 steps/s, speed: 8.765326 samples/s, speed: 4487.847111 tokens/s, learning rate: 2.579e-05, loss_scalings: 2814.750488, pp_loss: 7.025072
[INFO] 2021-07-12 19:24:15,679 [run_pretraining.py:  512]:	********exe.run_2580******* 
[INFO] 2021-07-12 19:24:16,583 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:16,583 [run_pretraining.py:  534]:	loss/total_loss, 7.445342540740967, 2581
[INFO] 2021-07-12 19:24:16,583 [run_pretraining.py:  535]:	loss/mlm_loss, 7.445342540740967, 2581
[INFO] 2021-07-12 19:24:16,583 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.579999818408396e-05, 2581
[INFO] 2021-07-12 19:24:16,583 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2581
[INFO] 2021-07-12 19:24:16,584 [run_pretraining.py:  558]:	worker_index: 2, step: 2581, cost: 7.445343, mlm loss: 7.445343, speed: 1.105967 steps/s, speed: 8.847739 samples/s, speed: 4530.042528 tokens/s, learning rate: 2.580e-05, loss_scalings: 2814.750488, pp_loss: 7.645788
[INFO] 2021-07-12 19:24:16,584 [run_pretraining.py:  512]:	********exe.run_2581******* 
[INFO] 2021-07-12 19:24:17,499 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:17,499 [run_pretraining.py:  534]:	loss/total_loss, 7.633144378662109, 2582
[INFO] 2021-07-12 19:24:17,499 [run_pretraining.py:  535]:	loss/mlm_loss, 7.633144378662109, 2582
[INFO] 2021-07-12 19:24:17,499 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5809998987824656e-05, 2582
[INFO] 2021-07-12 19:24:17,499 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2582
[INFO] 2021-07-12 19:24:17,499 [run_pretraining.py:  558]:	worker_index: 2, step: 2582, cost: 7.633144, mlm loss: 7.633144, speed: 1.092493 steps/s, speed: 8.739945 samples/s, speed: 4474.851866 tokens/s, learning rate: 2.581e-05, loss_scalings: 2814.750488, pp_loss: 7.736078
[INFO] 2021-07-12 19:24:17,500 [run_pretraining.py:  512]:	********exe.run_2582******* 
[INFO] 2021-07-12 19:24:18,409 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:18,409 [run_pretraining.py:  534]:	loss/total_loss, 6.7357497215271, 2583
[INFO] 2021-07-12 19:24:18,409 [run_pretraining.py:  535]:	loss/mlm_loss, 6.7357497215271, 2583
[INFO] 2021-07-12 19:24:18,409 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5819997972575948e-05, 2583
[INFO] 2021-07-12 19:24:18,409 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2583
[INFO] 2021-07-12 19:24:18,409 [run_pretraining.py:  558]:	worker_index: 2, step: 2583, cost: 6.735750, mlm loss: 6.735750, speed: 1.099703 steps/s, speed: 8.797620 samples/s, speed: 4504.381628 tokens/s, learning rate: 2.582e-05, loss_scalings: 2814.750488, pp_loss: 6.753808
[INFO] 2021-07-12 19:24:18,409 [run_pretraining.py:  512]:	********exe.run_2583******* 
[INFO] 2021-07-12 19:24:19,337 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:19,337 [run_pretraining.py:  534]:	loss/total_loss, 6.93654727935791, 2584
[INFO] 2021-07-12 19:24:19,338 [run_pretraining.py:  535]:	loss/mlm_loss, 6.93654727935791, 2584
[INFO] 2021-07-12 19:24:19,338 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5830000595306046e-05, 2584
[INFO] 2021-07-12 19:24:19,338 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2584
[INFO] 2021-07-12 19:24:19,338 [run_pretraining.py:  558]:	worker_index: 2, step: 2584, cost: 6.936547, mlm loss: 6.936547, speed: 1.077787 steps/s, speed: 8.622298 samples/s, speed: 4414.616651 tokens/s, learning rate: 2.583e-05, loss_scalings: 2814.750488, pp_loss: 7.166719
[INFO] 2021-07-12 19:24:19,338 [run_pretraining.py:  512]:	********exe.run_2584******* 
[INFO] 2021-07-12 19:24:20,246 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:20,247 [run_pretraining.py:  534]:	loss/total_loss, 7.503254413604736, 2585
[INFO] 2021-07-12 19:24:20,247 [run_pretraining.py:  535]:	loss/mlm_loss, 7.503254413604736, 2585
[INFO] 2021-07-12 19:24:20,247 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5839997761067934e-05, 2585
[INFO] 2021-07-12 19:24:20,247 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2585
[INFO] 2021-07-12 19:24:20,247 [run_pretraining.py:  558]:	worker_index: 2, step: 2585, cost: 7.503254, mlm loss: 7.503254, speed: 1.100629 steps/s, speed: 8.805029 samples/s, speed: 4508.174654 tokens/s, learning rate: 2.584e-05, loss_scalings: 2814.750488, pp_loss: 7.465528
[INFO] 2021-07-12 19:24:20,247 [run_pretraining.py:  512]:	********exe.run_2585******* 
[INFO] 2021-07-12 19:24:21,157 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:21,158 [run_pretraining.py:  534]:	loss/total_loss, 7.792247772216797, 2586
[INFO] 2021-07-12 19:24:21,158 [run_pretraining.py:  535]:	loss/mlm_loss, 7.792247772216797, 2586
[INFO] 2021-07-12 19:24:21,158 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5850000383798033e-05, 2586
[INFO] 2021-07-12 19:24:21,158 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2586
[INFO] 2021-07-12 19:24:21,158 [run_pretraining.py:  558]:	worker_index: 2, step: 2586, cost: 7.792248, mlm loss: 7.792248, speed: 1.098449 steps/s, speed: 8.787596 samples/s, speed: 4499.248945 tokens/s, learning rate: 2.585e-05, loss_scalings: 2814.750488, pp_loss: 7.613910
[INFO] 2021-07-12 19:24:21,158 [run_pretraining.py:  512]:	********exe.run_2586******* 
[INFO] 2021-07-12 19:24:22,071 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:22,071 [run_pretraining.py:  534]:	loss/total_loss, 6.908417701721191, 2587
[INFO] 2021-07-12 19:24:22,071 [run_pretraining.py:  535]:	loss/mlm_loss, 6.908417701721191, 2587
[INFO] 2021-07-12 19:24:22,071 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5859999368549325e-05, 2587
[INFO] 2021-07-12 19:24:22,071 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2587
[INFO] 2021-07-12 19:24:22,071 [run_pretraining.py:  558]:	worker_index: 2, step: 2587, cost: 6.908418, mlm loss: 6.908418, speed: 1.095544 steps/s, speed: 8.764349 samples/s, speed: 4487.346575 tokens/s, learning rate: 2.586e-05, loss_scalings: 2814.750488, pp_loss: 7.371738
[INFO] 2021-07-12 19:24:22,071 [run_pretraining.py:  512]:	********exe.run_2587******* 
[INFO] 2021-07-12 19:24:22,982 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:22,983 [run_pretraining.py:  534]:	loss/total_loss, 7.98452091217041, 2588
[INFO] 2021-07-12 19:24:22,983 [run_pretraining.py:  535]:	loss/mlm_loss, 7.98452091217041, 2588
[INFO] 2021-07-12 19:24:22,983 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.587000017229002e-05, 2588
[INFO] 2021-07-12 19:24:22,983 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2588
[INFO] 2021-07-12 19:24:22,983 [run_pretraining.py:  558]:	worker_index: 2, step: 2588, cost: 7.984521, mlm loss: 7.984521, speed: 1.097524 steps/s, speed: 8.780189 samples/s, speed: 4495.456802 tokens/s, learning rate: 2.587e-05, loss_scalings: 2814.750488, pp_loss: 7.438004
[INFO] 2021-07-12 19:24:22,983 [run_pretraining.py:  512]:	********exe.run_2588******* 
[INFO] 2021-07-12 19:24:23,892 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:23,893 [run_pretraining.py:  534]:	loss/total_loss, 7.789778709411621, 2589
[INFO] 2021-07-12 19:24:23,893 [run_pretraining.py:  535]:	loss/mlm_loss, 7.789778709411621, 2589
[INFO] 2021-07-12 19:24:23,893 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.587999915704131e-05, 2589
[INFO] 2021-07-12 19:24:23,893 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2589
[INFO] 2021-07-12 19:24:23,893 [run_pretraining.py:  558]:	worker_index: 2, step: 2589, cost: 7.789779, mlm loss: 7.789779, speed: 1.099570 steps/s, speed: 8.796557 samples/s, speed: 4503.837252 tokens/s, learning rate: 2.588e-05, loss_scalings: 2814.750488, pp_loss: 7.932052
[INFO] 2021-07-12 19:24:23,893 [run_pretraining.py:  512]:	********exe.run_2589******* 
[INFO] 2021-07-12 19:24:24,882 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:24,882 [run_pretraining.py:  534]:	loss/total_loss, 5.977952003479004, 2590
[INFO] 2021-07-12 19:24:24,882 [run_pretraining.py:  535]:	loss/mlm_loss, 5.977952003479004, 2590
[INFO] 2021-07-12 19:24:24,882 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5889998141792603e-05, 2590
[INFO] 2021-07-12 19:24:24,882 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2590
[INFO] 2021-07-12 19:24:24,883 [run_pretraining.py:  558]:	worker_index: 2, step: 2590, cost: 5.977952, mlm loss: 5.977952, speed: 1.011365 steps/s, speed: 8.090917 samples/s, speed: 4142.549439 tokens/s, learning rate: 2.589e-05, loss_scalings: 2814.750488, pp_loss: 6.864058
[INFO] 2021-07-12 19:24:24,883 [run_pretraining.py:  512]:	********exe.run_2590******* 
[INFO] 2021-07-12 19:24:25,942 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:25,942 [run_pretraining.py:  534]:	loss/total_loss, 7.684523582458496, 2591
[INFO] 2021-07-12 19:24:25,943 [run_pretraining.py:  535]:	loss/mlm_loss, 7.684523582458496, 2591
[INFO] 2021-07-12 19:24:25,943 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5899998945533298e-05, 2591
[INFO] 2021-07-12 19:24:25,943 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2591
[INFO] 2021-07-12 19:24:25,943 [run_pretraining.py:  558]:	worker_index: 2, step: 2591, cost: 7.684524, mlm loss: 7.684524, speed: 0.943741 steps/s, speed: 7.549925 samples/s, speed: 3865.561407 tokens/s, learning rate: 2.590e-05, loss_scalings: 2814.750488, pp_loss: 7.725720
[INFO] 2021-07-12 19:24:25,943 [run_pretraining.py:  512]:	********exe.run_2591******* 
[INFO] 2021-07-12 19:24:26,996 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:26,997 [run_pretraining.py:  534]:	loss/total_loss, 7.330000877380371, 2592
[INFO] 2021-07-12 19:24:26,997 [run_pretraining.py:  535]:	loss/mlm_loss, 7.330000877380371, 2592
[INFO] 2021-07-12 19:24:26,997 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.590999793028459e-05, 2592
[INFO] 2021-07-12 19:24:26,997 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2592
[INFO] 2021-07-12 19:24:26,997 [run_pretraining.py:  558]:	worker_index: 2, step: 2592, cost: 7.330001, mlm loss: 7.330001, speed: 0.949055 steps/s, speed: 7.592440 samples/s, speed: 3887.329311 tokens/s, learning rate: 2.591e-05, loss_scalings: 2814.750488, pp_loss: 7.480275
[INFO] 2021-07-12 19:24:26,997 [run_pretraining.py:  512]:	********exe.run_2592******* 
[INFO] 2021-07-12 19:24:28,052 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:28,053 [run_pretraining.py:  534]:	loss/total_loss, 7.104755401611328, 2593
[INFO] 2021-07-12 19:24:28,053 [run_pretraining.py:  535]:	loss/mlm_loss, 7.104755401611328, 2593
[INFO] 2021-07-12 19:24:28,053 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5920000553014688e-05, 2593
[INFO] 2021-07-12 19:24:28,053 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2593
[INFO] 2021-07-12 19:24:28,053 [run_pretraining.py:  558]:	worker_index: 2, step: 2593, cost: 7.104755, mlm loss: 7.104755, speed: 0.947633 steps/s, speed: 7.581064 samples/s, speed: 3881.504577 tokens/s, learning rate: 2.592e-05, loss_scalings: 2814.750488, pp_loss: 7.313141
[INFO] 2021-07-12 19:24:28,053 [run_pretraining.py:  512]:	********exe.run_2593******* 
[INFO] 2021-07-12 19:24:29,114 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:29,114 [run_pretraining.py:  534]:	loss/total_loss, 6.9075164794921875, 2594
[INFO] 2021-07-12 19:24:29,114 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9075164794921875, 2594
[INFO] 2021-07-12 19:24:29,115 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.592999953776598e-05, 2594
[INFO] 2021-07-12 19:24:29,115 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2594
[INFO] 2021-07-12 19:24:29,115 [run_pretraining.py:  558]:	worker_index: 2, step: 2594, cost: 6.907516, mlm loss: 6.907516, speed: 0.942303 steps/s, speed: 7.538426 samples/s, speed: 3859.674204 tokens/s, learning rate: 2.593e-05, loss_scalings: 2814.750488, pp_loss: 7.309689
[INFO] 2021-07-12 19:24:29,115 [run_pretraining.py:  512]:	********exe.run_2594******* 
[INFO] 2021-07-12 19:24:30,174 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:30,175 [run_pretraining.py:  534]:	loss/total_loss, 6.553169250488281, 2595
[INFO] 2021-07-12 19:24:30,175 [run_pretraining.py:  535]:	loss/mlm_loss, 6.553169250488281, 2595
[INFO] 2021-07-12 19:24:30,175 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5940000341506675e-05, 2595
[INFO] 2021-07-12 19:24:30,175 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2595
[INFO] 2021-07-12 19:24:30,175 [run_pretraining.py:  558]:	worker_index: 2, step: 2595, cost: 6.553169, mlm loss: 6.553169, speed: 0.943787 steps/s, speed: 7.550295 samples/s, speed: 3865.751027 tokens/s, learning rate: 2.594e-05, loss_scalings: 2814.750488, pp_loss: 7.116976
[INFO] 2021-07-12 19:24:30,175 [run_pretraining.py:  512]:	********exe.run_2595******* 
[INFO] 2021-07-12 19:24:31,222 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:31,223 [run_pretraining.py:  534]:	loss/total_loss, 7.450396537780762, 2596
[INFO] 2021-07-12 19:24:31,223 [run_pretraining.py:  535]:	loss/mlm_loss, 7.450396537780762, 2596
[INFO] 2021-07-12 19:24:31,223 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5949999326257966e-05, 2596
[INFO] 2021-07-12 19:24:31,223 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2596
[INFO] 2021-07-12 19:24:31,223 [run_pretraining.py:  558]:	worker_index: 2, step: 2596, cost: 7.450397, mlm loss: 7.450397, speed: 0.954640 steps/s, speed: 7.637118 samples/s, speed: 3910.204182 tokens/s, learning rate: 2.595e-05, loss_scalings: 2814.750488, pp_loss: 7.366506
[INFO] 2021-07-12 19:24:31,223 [run_pretraining.py:  512]:	********exe.run_2596******* 
[INFO] 2021-07-12 19:24:32,282 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:32,283 [run_pretraining.py:  534]:	loss/total_loss, 7.008761405944824, 2597
[INFO] 2021-07-12 19:24:32,283 [run_pretraining.py:  535]:	loss/mlm_loss, 7.008761405944824, 2597
[INFO] 2021-07-12 19:24:32,283 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.596000012999866e-05, 2597
[INFO] 2021-07-12 19:24:32,283 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2597
[INFO] 2021-07-12 19:24:32,283 [run_pretraining.py:  558]:	worker_index: 2, step: 2597, cost: 7.008761, mlm loss: 7.008761, speed: 0.943780 steps/s, speed: 7.550239 samples/s, speed: 3865.722322 tokens/s, learning rate: 2.596e-05, loss_scalings: 2814.750488, pp_loss: 6.830401
[INFO] 2021-07-12 19:24:32,283 [run_pretraining.py:  512]:	********exe.run_2597******* 
[INFO] 2021-07-12 19:24:33,347 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:33,348 [run_pretraining.py:  534]:	loss/total_loss, 7.53003454208374, 2598
[INFO] 2021-07-12 19:24:33,348 [run_pretraining.py:  535]:	loss/mlm_loss, 7.53003454208374, 2598
[INFO] 2021-07-12 19:24:33,348 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5969999114749953e-05, 2598
[INFO] 2021-07-12 19:24:33,348 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2598
[INFO] 2021-07-12 19:24:33,348 [run_pretraining.py:  558]:	worker_index: 2, step: 2598, cost: 7.530035, mlm loss: 7.530035, speed: 0.939391 steps/s, speed: 7.515132 samples/s, speed: 3847.747457 tokens/s, learning rate: 2.597e-05, loss_scalings: 2814.750488, pp_loss: 7.337874
[INFO] 2021-07-12 19:24:33,348 [run_pretraining.py:  512]:	********exe.run_2598******* 
[INFO] 2021-07-12 19:24:34,409 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:34,409 [run_pretraining.py:  534]:	loss/total_loss, 6.858447551727295, 2599
[INFO] 2021-07-12 19:24:34,410 [run_pretraining.py:  535]:	loss/mlm_loss, 6.858447551727295, 2599
[INFO] 2021-07-12 19:24:34,410 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5979998099501245e-05, 2599
[INFO] 2021-07-12 19:24:34,410 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2599
[INFO] 2021-07-12 19:24:34,410 [run_pretraining.py:  558]:	worker_index: 2, step: 2599, cost: 6.858448, mlm loss: 6.858448, speed: 0.942565 steps/s, speed: 7.540520 samples/s, speed: 3860.746268 tokens/s, learning rate: 2.598e-05, loss_scalings: 2814.750488, pp_loss: 7.162258
[INFO] 2021-07-12 19:24:34,410 [run_pretraining.py:  512]:	********exe.run_2599******* 
[INFO] 2021-07-12 19:24:59,803 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:59,804 [run_pretraining.py:  534]:	loss/total_loss, 7.486336708068848, 2600
[INFO] 2021-07-12 19:24:59,804 [run_pretraining.py:  535]:	loss/mlm_loss, 7.486336708068848, 2600
[INFO] 2021-07-12 19:24:59,804 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.598999890324194e-05, 2600
[INFO] 2021-07-12 19:24:59,804 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2600
[INFO] 2021-07-12 19:24:59,804 [run_pretraining.py:  558]:	worker_index: 2, step: 2600, cost: 7.486337, mlm loss: 7.486337, speed: 0.039380 steps/s, speed: 0.315041 samples/s, speed: 161.300809 tokens/s, learning rate: 2.599e-05, loss_scalings: 2814.750488, pp_loss: 7.246871
[INFO] 2021-07-12 19:24:59,804 [run_pretraining.py:  512]:	********exe.run_2600******* 
[INFO] 2021-07-12 19:25:00,864 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:00,864 [run_pretraining.py:  534]:	loss/total_loss, 8.133426666259766, 2601
[INFO] 2021-07-12 19:25:00,864 [run_pretraining.py:  535]:	loss/mlm_loss, 8.133426666259766, 2601
[INFO] 2021-07-12 19:25:00,865 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.599999788799323e-05, 2601
[INFO] 2021-07-12 19:25:00,865 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2601
[INFO] 2021-07-12 19:25:00,865 [run_pretraining.py:  558]:	worker_index: 2, step: 2601, cost: 8.133427, mlm loss: 8.133427, speed: 0.943270 steps/s, speed: 7.546162 samples/s, speed: 3863.634953 tokens/s, learning rate: 2.600e-05, loss_scalings: 2814.750488, pp_loss: 7.618830
[INFO] 2021-07-12 19:25:00,865 [run_pretraining.py:  512]:	********exe.run_2601******* 
[INFO] 2021-07-12 19:25:01,928 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:01,928 [run_pretraining.py:  534]:	loss/total_loss, 7.443915843963623, 2602
[INFO] 2021-07-12 19:25:01,929 [run_pretraining.py:  535]:	loss/mlm_loss, 7.443915843963623, 2602
[INFO] 2021-07-12 19:25:01,929 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.601000051072333e-05, 2602
[INFO] 2021-07-12 19:25:01,929 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2602
[INFO] 2021-07-12 19:25:01,929 [run_pretraining.py:  558]:	worker_index: 2, step: 2602, cost: 7.443916, mlm loss: 7.443916, speed: 0.940297 steps/s, speed: 7.522380 samples/s, speed: 3851.458383 tokens/s, learning rate: 2.601e-05, loss_scalings: 2814.750488, pp_loss: 6.334935
[INFO] 2021-07-12 19:25:01,929 [run_pretraining.py:  512]:	********exe.run_2602******* 
[INFO] 2021-07-12 19:25:02,982 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:02,982 [run_pretraining.py:  534]:	loss/total_loss, 6.834940433502197, 2603
[INFO] 2021-07-12 19:25:02,982 [run_pretraining.py:  535]:	loss/mlm_loss, 6.834940433502197, 2603
[INFO] 2021-07-12 19:25:02,983 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.601999949547462e-05, 2603
[INFO] 2021-07-12 19:25:02,983 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2603
[INFO] 2021-07-12 19:25:02,983 [run_pretraining.py:  558]:	worker_index: 2, step: 2603, cost: 6.834940, mlm loss: 6.834940, speed: 0.949476 steps/s, speed: 7.595809 samples/s, speed: 3889.054082 tokens/s, learning rate: 2.602e-05, loss_scalings: 2814.750488, pp_loss: 7.325692
[INFO] 2021-07-12 19:25:02,983 [run_pretraining.py:  512]:	********exe.run_2603******* 
[INFO] 2021-07-12 19:25:04,046 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:04,046 [run_pretraining.py:  534]:	loss/total_loss, 7.159147262573242, 2604
[INFO] 2021-07-12 19:25:04,046 [run_pretraining.py:  535]:	loss/mlm_loss, 7.159147262573242, 2604
[INFO] 2021-07-12 19:25:04,046 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6030000299215317e-05, 2604
[INFO] 2021-07-12 19:25:04,046 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2604
[INFO] 2021-07-12 19:25:04,046 [run_pretraining.py:  558]:	worker_index: 2, step: 2604, cost: 7.159147, mlm loss: 7.159147, speed: 0.940545 steps/s, speed: 7.524363 samples/s, speed: 3852.474053 tokens/s, learning rate: 2.603e-05, loss_scalings: 2814.750488, pp_loss: 7.400219
[INFO] 2021-07-12 19:25:04,047 [run_pretraining.py:  512]:	********exe.run_2604******* 
[INFO] 2021-07-12 19:25:05,102 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:05,102 [run_pretraining.py:  534]:	loss/total_loss, 7.503940105438232, 2605
[INFO] 2021-07-12 19:25:05,102 [run_pretraining.py:  535]:	loss/mlm_loss, 7.503940105438232, 2605
[INFO] 2021-07-12 19:25:05,102 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.603999928396661e-05, 2605
[INFO] 2021-07-12 19:25:05,102 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2605
[INFO] 2021-07-12 19:25:05,102 [run_pretraining.py:  558]:	worker_index: 2, step: 2605, cost: 7.503940, mlm loss: 7.503940, speed: 0.947577 steps/s, speed: 7.580618 samples/s, speed: 3881.276580 tokens/s, learning rate: 2.604e-05, loss_scalings: 2814.750488, pp_loss: 7.353601
[INFO] 2021-07-12 19:25:05,102 [run_pretraining.py:  512]:	********exe.run_2605******* 
[INFO] 2021-07-12 19:25:06,162 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:06,162 [run_pretraining.py:  534]:	loss/total_loss, 6.044050216674805, 2606
[INFO] 2021-07-12 19:25:06,162 [run_pretraining.py:  535]:	loss/mlm_loss, 6.044050216674805, 2606
[INFO] 2021-07-12 19:25:06,162 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6050000087707303e-05, 2606
[INFO] 2021-07-12 19:25:06,162 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2606
[INFO] 2021-07-12 19:25:06,162 [run_pretraining.py:  558]:	worker_index: 2, step: 2606, cost: 6.044050, mlm loss: 6.044050, speed: 0.943958 steps/s, speed: 7.551665 samples/s, speed: 3866.452259 tokens/s, learning rate: 2.605e-05, loss_scalings: 2814.750488, pp_loss: 6.931506
[INFO] 2021-07-12 19:25:06,162 [run_pretraining.py:  512]:	********exe.run_2606******* 
[INFO] 2021-07-12 19:25:07,225 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:07,226 [run_pretraining.py:  534]:	loss/total_loss, 7.323548316955566, 2607
[INFO] 2021-07-12 19:25:07,226 [run_pretraining.py:  535]:	loss/mlm_loss, 7.323548316955566, 2607
[INFO] 2021-07-12 19:25:07,226 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6059999072458595e-05, 2607
[INFO] 2021-07-12 19:25:07,226 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2607
[INFO] 2021-07-12 19:25:07,226 [run_pretraining.py:  558]:	worker_index: 2, step: 2607, cost: 7.323548, mlm loss: 7.323548, speed: 0.940639 steps/s, speed: 7.525113 samples/s, speed: 3852.857659 tokens/s, learning rate: 2.606e-05, loss_scalings: 2814.750488, pp_loss: 7.129204
[INFO] 2021-07-12 19:25:07,226 [run_pretraining.py:  512]:	********exe.run_2607******* 
[INFO] 2021-07-12 19:25:08,281 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:08,281 [run_pretraining.py:  534]:	loss/total_loss, 7.310767650604248, 2608
[INFO] 2021-07-12 19:25:08,281 [run_pretraining.py:  535]:	loss/mlm_loss, 7.310767650604248, 2608
[INFO] 2021-07-12 19:25:08,281 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6069998057209887e-05, 2608
[INFO] 2021-07-12 19:25:08,281 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2608
[INFO] 2021-07-12 19:25:08,282 [run_pretraining.py:  558]:	worker_index: 2, step: 2608, cost: 7.310768, mlm loss: 7.310768, speed: 0.947915 steps/s, speed: 7.583317 samples/s, speed: 3882.658123 tokens/s, learning rate: 2.607e-05, loss_scalings: 2814.750488, pp_loss: 6.947846
[INFO] 2021-07-12 19:25:08,282 [run_pretraining.py:  512]:	********exe.run_2608******* 
[INFO] 2021-07-12 19:25:09,341 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:09,342 [run_pretraining.py:  534]:	loss/total_loss, 7.510031700134277, 2609
[INFO] 2021-07-12 19:25:09,342 [run_pretraining.py:  535]:	loss/mlm_loss, 7.510031700134277, 2609
[INFO] 2021-07-12 19:25:09,342 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6079998860950582e-05, 2609
[INFO] 2021-07-12 19:25:09,342 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2609
[INFO] 2021-07-12 19:25:09,342 [run_pretraining.py:  558]:	worker_index: 2, step: 2609, cost: 7.510032, mlm loss: 7.510032, speed: 0.943566 steps/s, speed: 7.548525 samples/s, speed: 3864.844848 tokens/s, learning rate: 2.608e-05, loss_scalings: 2814.750488, pp_loss: 7.007591
[INFO] 2021-07-12 19:25:09,342 [run_pretraining.py:  512]:	********exe.run_2609******* 
[INFO] 2021-07-12 19:25:10,282 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:10,283 [run_pretraining.py:  534]:	loss/total_loss, 7.73858642578125, 2610
[INFO] 2021-07-12 19:25:10,283 [run_pretraining.py:  535]:	loss/mlm_loss, 7.73858642578125, 2610
[INFO] 2021-07-12 19:25:10,283 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6089997845701873e-05, 2610
[INFO] 2021-07-12 19:25:10,283 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2610
[INFO] 2021-07-12 19:25:10,283 [run_pretraining.py:  558]:	worker_index: 2, step: 2610, cost: 7.738586, mlm loss: 7.738586, speed: 1.063483 steps/s, speed: 8.507863 samples/s, speed: 4356.025708 tokens/s, learning rate: 2.609e-05, loss_scalings: 2814.750488, pp_loss: 7.429034
[INFO] 2021-07-12 19:25:10,283 [run_pretraining.py:  512]:	********exe.run_2610******* 
[INFO] 2021-07-12 19:25:11,199 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:11,199 [run_pretraining.py:  534]:	loss/total_loss, 7.416858673095703, 2611
[INFO] 2021-07-12 19:25:11,199 [run_pretraining.py:  535]:	loss/mlm_loss, 7.416858673095703, 2611
[INFO] 2021-07-12 19:25:11,199 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6100000468431972e-05, 2611
[INFO] 2021-07-12 19:25:11,199 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2611
[INFO] 2021-07-12 19:25:11,199 [run_pretraining.py:  558]:	worker_index: 2, step: 2611, cost: 7.416859, mlm loss: 7.416859, speed: 1.091725 steps/s, speed: 8.733801 samples/s, speed: 4471.705881 tokens/s, learning rate: 2.610e-05, loss_scalings: 2814.750488, pp_loss: 7.261926
[INFO] 2021-07-12 19:25:11,200 [run_pretraining.py:  512]:	********exe.run_2611******* 
[INFO] 2021-07-12 19:25:12,099 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:12,100 [run_pretraining.py:  534]:	loss/total_loss, 7.022402763366699, 2612
[INFO] 2021-07-12 19:25:12,100 [run_pretraining.py:  535]:	loss/mlm_loss, 7.022402763366699, 2612
[INFO] 2021-07-12 19:25:12,100 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6109999453183264e-05, 2612
[INFO] 2021-07-12 19:25:12,100 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2612
[INFO] 2021-07-12 19:25:12,100 [run_pretraining.py:  558]:	worker_index: 2, step: 2612, cost: 7.022403, mlm loss: 7.022403, speed: 1.110934 steps/s, speed: 8.887473 samples/s, speed: 4550.386159 tokens/s, learning rate: 2.611e-05, loss_scalings: 2814.750488, pp_loss: 6.661859
[INFO] 2021-07-12 19:25:12,100 [run_pretraining.py:  512]:	********exe.run_2612******* 
[INFO] 2021-07-12 19:25:13,006 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:13,006 [run_pretraining.py:  534]:	loss/total_loss, 7.524998664855957, 2613
[INFO] 2021-07-12 19:25:13,006 [run_pretraining.py:  535]:	loss/mlm_loss, 7.524998664855957, 2613
[INFO] 2021-07-12 19:25:13,007 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.612000025692396e-05, 2613
[INFO] 2021-07-12 19:25:13,007 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2613
[INFO] 2021-07-12 19:25:13,007 [run_pretraining.py:  558]:	worker_index: 2, step: 2613, cost: 7.524999, mlm loss: 7.524999, speed: 1.103870 steps/s, speed: 8.830962 samples/s, speed: 4521.452504 tokens/s, learning rate: 2.612e-05, loss_scalings: 2814.750488, pp_loss: 7.355099
[INFO] 2021-07-12 19:25:13,007 [run_pretraining.py:  512]:	********exe.run_2613******* 
[INFO] 2021-07-12 19:25:13,918 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:13,919 [run_pretraining.py:  534]:	loss/total_loss, 7.124359130859375, 2614
[INFO] 2021-07-12 19:25:13,919 [run_pretraining.py:  535]:	loss/mlm_loss, 7.124359130859375, 2614
[INFO] 2021-07-12 19:25:13,919 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.612999924167525e-05, 2614
[INFO] 2021-07-12 19:25:13,919 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2614
[INFO] 2021-07-12 19:25:13,919 [run_pretraining.py:  558]:	worker_index: 2, step: 2614, cost: 7.124359, mlm loss: 7.124359, speed: 1.096844 steps/s, speed: 8.774754 samples/s, speed: 4492.674161 tokens/s, learning rate: 2.613e-05, loss_scalings: 2814.750488, pp_loss: 6.984148
[INFO] 2021-07-12 19:25:13,919 [run_pretraining.py:  512]:	********exe.run_2614******* 
[INFO] 2021-07-12 19:25:14,830 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:14,831 [run_pretraining.py:  534]:	loss/total_loss, 7.497252464294434, 2615
[INFO] 2021-07-12 19:25:14,831 [run_pretraining.py:  535]:	loss/mlm_loss, 7.497252464294434, 2615
[INFO] 2021-07-12 19:25:14,831 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6140000045415945e-05, 2615
[INFO] 2021-07-12 19:25:14,831 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2615
[INFO] 2021-07-12 19:25:14,831 [run_pretraining.py:  558]:	worker_index: 2, step: 2615, cost: 7.497252, mlm loss: 7.497252, speed: 1.097387 steps/s, speed: 8.779093 samples/s, speed: 4494.895765 tokens/s, learning rate: 2.614e-05, loss_scalings: 2814.750488, pp_loss: 7.208902
[INFO] 2021-07-12 19:25:14,831 [run_pretraining.py:  512]:	********exe.run_2615******* 
[INFO] 2021-07-12 19:25:15,741 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:15,742 [run_pretraining.py:  534]:	loss/total_loss, 6.808872222900391, 2616
[INFO] 2021-07-12 19:25:15,742 [run_pretraining.py:  535]:	loss/mlm_loss, 6.808872222900391, 2616
[INFO] 2021-07-12 19:25:15,742 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6149999030167237e-05, 2616
[INFO] 2021-07-12 19:25:15,742 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2616
[INFO] 2021-07-12 19:25:15,742 [run_pretraining.py:  558]:	worker_index: 2, step: 2616, cost: 6.808872, mlm loss: 6.808872, speed: 1.098290 steps/s, speed: 8.786316 samples/s, speed: 4498.593900 tokens/s, learning rate: 2.615e-05, loss_scalings: 2814.750488, pp_loss: 6.992820
[INFO] 2021-07-12 19:25:15,742 [run_pretraining.py:  512]:	********exe.run_2616******* 
[INFO] 2021-07-12 19:25:16,653 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:16,654 [run_pretraining.py:  534]:	loss/total_loss, 7.206341743469238, 2617
[INFO] 2021-07-12 19:25:16,654 [run_pretraining.py:  535]:	loss/mlm_loss, 7.206341743469238, 2617
[INFO] 2021-07-12 19:25:16,654 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.615999801491853e-05, 2617
[INFO] 2021-07-12 19:25:16,654 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2617
[INFO] 2021-07-12 19:25:16,654 [run_pretraining.py:  558]:	worker_index: 2, step: 2617, cost: 7.206342, mlm loss: 7.206342, speed: 1.097189 steps/s, speed: 8.777516 samples/s, speed: 4494.087975 tokens/s, learning rate: 2.616e-05, loss_scalings: 2814.750488, pp_loss: 7.376775
[INFO] 2021-07-12 19:25:16,654 [run_pretraining.py:  512]:	********exe.run_2617******* 
[INFO] 2021-07-12 19:25:17,565 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:17,565 [run_pretraining.py:  534]:	loss/total_loss, 7.88066291809082, 2618
[INFO] 2021-07-12 19:25:17,565 [run_pretraining.py:  535]:	loss/mlm_loss, 7.88066291809082, 2618
[INFO] 2021-07-12 19:25:17,565 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6170000637648627e-05, 2618
[INFO] 2021-07-12 19:25:17,565 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2618
[INFO] 2021-07-12 19:25:17,565 [run_pretraining.py:  558]:	worker_index: 2, step: 2618, cost: 7.880663, mlm loss: 7.880663, speed: 1.097867 steps/s, speed: 8.782938 samples/s, speed: 4496.864129 tokens/s, learning rate: 2.617e-05, loss_scalings: 2814.750488, pp_loss: 7.333877
[INFO] 2021-07-12 19:25:17,566 [run_pretraining.py:  512]:	********exe.run_2618******* 
[INFO] 2021-07-12 19:25:18,475 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:18,475 [run_pretraining.py:  534]:	loss/total_loss, 6.591372489929199, 2619
[INFO] 2021-07-12 19:25:18,475 [run_pretraining.py:  535]:	loss/mlm_loss, 6.591372489929199, 2619
[INFO] 2021-07-12 19:25:18,475 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6179997803410515e-05, 2619
[INFO] 2021-07-12 19:25:18,475 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2619
[INFO] 2021-07-12 19:25:18,475 [run_pretraining.py:  558]:	worker_index: 2, step: 2619, cost: 6.591372, mlm loss: 6.591372, speed: 1.099705 steps/s, speed: 8.797643 samples/s, speed: 4504.393438 tokens/s, learning rate: 2.618e-05, loss_scalings: 2814.750488, pp_loss: 6.929130
[INFO] 2021-07-12 19:25:18,475 [run_pretraining.py:  512]:	********exe.run_2619******* 
[INFO] 2021-07-12 19:25:19,386 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:19,386 [run_pretraining.py:  534]:	loss/total_loss, 5.692601680755615, 2620
[INFO] 2021-07-12 19:25:19,386 [run_pretraining.py:  535]:	loss/mlm_loss, 5.692601680755615, 2620
[INFO] 2021-07-12 19:25:19,387 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6190000426140614e-05, 2620
[INFO] 2021-07-12 19:25:19,387 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2620
[INFO] 2021-07-12 19:25:19,387 [run_pretraining.py:  558]:	worker_index: 2, step: 2620, cost: 5.692602, mlm loss: 5.692602, speed: 1.097983 steps/s, speed: 8.783867 samples/s, speed: 4497.339713 tokens/s, learning rate: 2.619e-05, loss_scalings: 2814.750488, pp_loss: 6.883191
[INFO] 2021-07-12 19:25:19,387 [run_pretraining.py:  512]:	********exe.run_2620******* 
[INFO] 2021-07-12 19:25:20,314 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:20,315 [run_pretraining.py:  534]:	loss/total_loss, 7.071833610534668, 2621
[INFO] 2021-07-12 19:25:20,315 [run_pretraining.py:  535]:	loss/mlm_loss, 7.071833610534668, 2621
[INFO] 2021-07-12 19:25:20,315 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6199999410891905e-05, 2621
[INFO] 2021-07-12 19:25:20,315 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2621
[INFO] 2021-07-12 19:25:20,315 [run_pretraining.py:  558]:	worker_index: 2, step: 2621, cost: 7.071834, mlm loss: 7.071834, speed: 1.077770 steps/s, speed: 8.622159 samples/s, speed: 4414.545185 tokens/s, learning rate: 2.620e-05, loss_scalings: 2814.750488, pp_loss: 7.488925
[INFO] 2021-07-12 19:25:20,315 [run_pretraining.py:  512]:	********exe.run_2621******* 
[INFO] 2021-07-12 19:25:21,230 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:21,230 [run_pretraining.py:  534]:	loss/total_loss, 7.2387871742248535, 2622
[INFO] 2021-07-12 19:25:21,230 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2387871742248535, 2622
[INFO] 2021-07-12 19:25:21,230 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.62100002146326e-05, 2622
[INFO] 2021-07-12 19:25:21,230 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2622
[INFO] 2021-07-12 19:25:21,231 [run_pretraining.py:  558]:	worker_index: 2, step: 2622, cost: 7.238787, mlm loss: 7.238787, speed: 1.093142 steps/s, speed: 8.745139 samples/s, speed: 4477.510939 tokens/s, learning rate: 2.621e-05, loss_scalings: 2814.750488, pp_loss: 6.697449
[INFO] 2021-07-12 19:25:21,231 [run_pretraining.py:  512]:	********exe.run_2622******* 
[INFO] 2021-07-12 19:25:22,141 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:22,141 [run_pretraining.py:  534]:	loss/total_loss, 7.499338150024414, 2623
[INFO] 2021-07-12 19:25:22,141 [run_pretraining.py:  535]:	loss/mlm_loss, 7.499338150024414, 2623
[INFO] 2021-07-12 19:25:22,142 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6219999199383892e-05, 2623
[INFO] 2021-07-12 19:25:22,142 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2623
[INFO] 2021-07-12 19:25:22,142 [run_pretraining.py:  558]:	worker_index: 2, step: 2623, cost: 7.499338, mlm loss: 7.499338, speed: 1.098273 steps/s, speed: 8.786180 samples/s, speed: 4498.524400 tokens/s, learning rate: 2.622e-05, loss_scalings: 2814.750488, pp_loss: 7.348273
[INFO] 2021-07-12 19:25:22,142 [run_pretraining.py:  512]:	********exe.run_2623******* 
[INFO] 2021-07-12 19:25:23,061 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:23,061 [run_pretraining.py:  534]:	loss/total_loss, 7.588311672210693, 2624
[INFO] 2021-07-12 19:25:23,061 [run_pretraining.py:  535]:	loss/mlm_loss, 7.588311672210693, 2624
[INFO] 2021-07-12 19:25:23,061 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6230000003124587e-05, 2624
[INFO] 2021-07-12 19:25:23,062 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2624
[INFO] 2021-07-12 19:25:23,062 [run_pretraining.py:  558]:	worker_index: 2, step: 2624, cost: 7.588312, mlm loss: 7.588312, speed: 1.087778 steps/s, speed: 8.702228 samples/s, speed: 4455.540521 tokens/s, learning rate: 2.623e-05, loss_scalings: 2814.750488, pp_loss: 7.820526
[INFO] 2021-07-12 19:25:23,062 [run_pretraining.py:  512]:	********exe.run_2624******* 
[INFO] 2021-07-12 19:25:23,994 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:23,995 [run_pretraining.py:  534]:	loss/total_loss, 7.016802787780762, 2625
[INFO] 2021-07-12 19:25:23,995 [run_pretraining.py:  535]:	loss/mlm_loss, 7.016802787780762, 2625
[INFO] 2021-07-12 19:25:23,995 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.623999898787588e-05, 2625
[INFO] 2021-07-12 19:25:23,995 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2625
[INFO] 2021-07-12 19:25:23,995 [run_pretraining.py:  558]:	worker_index: 2, step: 2625, cost: 7.016803, mlm loss: 7.016803, speed: 1.071984 steps/s, speed: 8.575869 samples/s, speed: 4390.844683 tokens/s, learning rate: 2.624e-05, loss_scalings: 2814.750488, pp_loss: 7.241733
[INFO] 2021-07-12 19:25:23,995 [run_pretraining.py:  512]:	********exe.run_2625******* 
[INFO] 2021-07-12 19:25:24,904 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:24,904 [run_pretraining.py:  534]:	loss/total_loss, 7.559622764587402, 2626
[INFO] 2021-07-12 19:25:24,905 [run_pretraining.py:  535]:	loss/mlm_loss, 7.559622764587402, 2626
[INFO] 2021-07-12 19:25:24,905 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.624999797262717e-05, 2626
[INFO] 2021-07-12 19:25:24,905 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2626
[INFO] 2021-07-12 19:25:24,905 [run_pretraining.py:  558]:	worker_index: 2, step: 2626, cost: 7.559623, mlm loss: 7.559623, speed: 1.099934 steps/s, speed: 8.799475 samples/s, speed: 4505.331354 tokens/s, learning rate: 2.625e-05, loss_scalings: 2814.750488, pp_loss: 7.332597
[INFO] 2021-07-12 19:25:24,905 [run_pretraining.py:  512]:	********exe.run_2626******* 
[INFO] 2021-07-12 19:25:25,822 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:25,823 [run_pretraining.py:  534]:	loss/total_loss, 7.522613525390625, 2627
[INFO] 2021-07-12 19:25:25,823 [run_pretraining.py:  535]:	loss/mlm_loss, 7.522613525390625, 2627
[INFO] 2021-07-12 19:25:25,823 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.626000059535727e-05, 2627
[INFO] 2021-07-12 19:25:25,823 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2627
[INFO] 2021-07-12 19:25:25,823 [run_pretraining.py:  558]:	worker_index: 2, step: 2627, cost: 7.522614, mlm loss: 7.522614, speed: 1.089932 steps/s, speed: 8.719457 samples/s, speed: 4464.361929 tokens/s, learning rate: 2.626e-05, loss_scalings: 2814.750488, pp_loss: 6.978126
[INFO] 2021-07-12 19:25:25,823 [run_pretraining.py:  512]:	********exe.run_2627******* 
[INFO] 2021-07-12 19:25:26,753 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:26,754 [run_pretraining.py:  534]:	loss/total_loss, 7.242764472961426, 2628
[INFO] 2021-07-12 19:25:26,754 [run_pretraining.py:  535]:	loss/mlm_loss, 7.242764472961426, 2628
[INFO] 2021-07-12 19:25:26,754 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6269997761119157e-05, 2628
[INFO] 2021-07-12 19:25:26,754 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2628
[INFO] 2021-07-12 19:25:26,754 [run_pretraining.py:  558]:	worker_index: 2, step: 2628, cost: 7.242764, mlm loss: 7.242764, speed: 1.074405 steps/s, speed: 8.595242 samples/s, speed: 4400.763860 tokens/s, learning rate: 2.627e-05, loss_scalings: 2814.750488, pp_loss: 6.397235
[INFO] 2021-07-12 19:25:26,754 [run_pretraining.py:  512]:	********exe.run_2628******* 
[INFO] 2021-07-12 19:25:27,676 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:27,677 [run_pretraining.py:  534]:	loss/total_loss, 7.113083839416504, 2629
[INFO] 2021-07-12 19:25:27,677 [run_pretraining.py:  535]:	loss/mlm_loss, 7.113083839416504, 2629
[INFO] 2021-07-12 19:25:27,677 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6280000383849256e-05, 2629
[INFO] 2021-07-12 19:25:27,677 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2629
[INFO] 2021-07-12 19:25:27,677 [run_pretraining.py:  558]:	worker_index: 2, step: 2629, cost: 7.113084, mlm loss: 7.113084, speed: 1.084106 steps/s, speed: 8.672850 samples/s, speed: 4440.499103 tokens/s, learning rate: 2.628e-05, loss_scalings: 2814.750488, pp_loss: 7.097358
[INFO] 2021-07-12 19:25:27,677 [run_pretraining.py:  512]:	********exe.run_2629******* 
[INFO] 2021-07-12 19:25:28,591 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:28,592 [run_pretraining.py:  534]:	loss/total_loss, 6.242236614227295, 2630
[INFO] 2021-07-12 19:25:28,592 [run_pretraining.py:  535]:	loss/mlm_loss, 6.242236614227295, 2630
[INFO] 2021-07-12 19:25:28,592 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6289999368600547e-05, 2630
[INFO] 2021-07-12 19:25:28,592 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2630
[INFO] 2021-07-12 19:25:28,592 [run_pretraining.py:  558]:	worker_index: 2, step: 2630, cost: 6.242237, mlm loss: 6.242237, speed: 1.093674 steps/s, speed: 8.749391 samples/s, speed: 4479.688366 tokens/s, learning rate: 2.629e-05, loss_scalings: 2814.750488, pp_loss: 6.982810
[INFO] 2021-07-12 19:25:28,592 [run_pretraining.py:  512]:	********exe.run_2630******* 
[INFO] 2021-07-12 19:25:29,505 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:29,505 [run_pretraining.py:  534]:	loss/total_loss, 6.905094146728516, 2631
[INFO] 2021-07-12 19:25:29,505 [run_pretraining.py:  535]:	loss/mlm_loss, 6.905094146728516, 2631
[INFO] 2021-07-12 19:25:29,505 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6300000172341242e-05, 2631
[INFO] 2021-07-12 19:25:29,505 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2631
[INFO] 2021-07-12 19:25:29,506 [run_pretraining.py:  558]:	worker_index: 2, step: 2631, cost: 6.905094, mlm loss: 6.905094, speed: 1.095558 steps/s, speed: 8.764463 samples/s, speed: 4487.405180 tokens/s, learning rate: 2.630e-05, loss_scalings: 2814.750488, pp_loss: 6.986374
[INFO] 2021-07-12 19:25:29,506 [run_pretraining.py:  512]:	********exe.run_2631******* 
[INFO] 2021-07-12 19:25:30,431 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:30,431 [run_pretraining.py:  534]:	loss/total_loss, 6.820138454437256, 2632
[INFO] 2021-07-12 19:25:30,432 [run_pretraining.py:  535]:	loss/mlm_loss, 6.820138454437256, 2632
[INFO] 2021-07-12 19:25:30,432 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6309999157092534e-05, 2632
[INFO] 2021-07-12 19:25:30,432 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2632
[INFO] 2021-07-12 19:25:30,432 [run_pretraining.py:  558]:	worker_index: 2, step: 2632, cost: 6.820138, mlm loss: 6.820138, speed: 1.080253 steps/s, speed: 8.642020 samples/s, speed: 4424.714300 tokens/s, learning rate: 2.631e-05, loss_scalings: 2814.750488, pp_loss: 6.809048
[INFO] 2021-07-12 19:25:30,432 [run_pretraining.py:  512]:	********exe.run_2632******* 
[INFO] 2021-07-12 19:25:31,353 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:31,354 [run_pretraining.py:  534]:	loss/total_loss, 7.417742729187012, 2633
[INFO] 2021-07-12 19:25:31,354 [run_pretraining.py:  535]:	loss/mlm_loss, 7.417742729187012, 2633
[INFO] 2021-07-12 19:25:31,354 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.631999996083323e-05, 2633
[INFO] 2021-07-12 19:25:31,354 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2633
[INFO] 2021-07-12 19:25:31,354 [run_pretraining.py:  558]:	worker_index: 2, step: 2633, cost: 7.417743, mlm loss: 7.417743, speed: 1.084817 steps/s, speed: 8.678538 samples/s, speed: 4443.411683 tokens/s, learning rate: 2.632e-05, loss_scalings: 2814.750488, pp_loss: 7.344657
[INFO] 2021-07-12 19:25:31,354 [run_pretraining.py:  512]:	********exe.run_2633******* 
[INFO] 2021-07-12 19:25:32,271 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:32,272 [run_pretraining.py:  534]:	loss/total_loss, 8.552560806274414, 2634
[INFO] 2021-07-12 19:25:32,272 [run_pretraining.py:  535]:	loss/mlm_loss, 8.552560806274414, 2634
[INFO] 2021-07-12 19:25:32,272 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.632999894558452e-05, 2634
[INFO] 2021-07-12 19:25:32,272 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2634
[INFO] 2021-07-12 19:25:32,272 [run_pretraining.py:  558]:	worker_index: 2, step: 2634, cost: 8.552561, mlm loss: 8.552561, speed: 1.090072 steps/s, speed: 8.720576 samples/s, speed: 4464.935097 tokens/s, learning rate: 2.633e-05, loss_scalings: 2814.750488, pp_loss: 7.504870
[INFO] 2021-07-12 19:25:32,272 [run_pretraining.py:  512]:	********exe.run_2634******* 
[INFO] 2021-07-12 19:25:33,182 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:33,182 [run_pretraining.py:  534]:	loss/total_loss, 7.441551208496094, 2635
[INFO] 2021-07-12 19:25:33,182 [run_pretraining.py:  535]:	loss/mlm_loss, 7.441551208496094, 2635
[INFO] 2021-07-12 19:25:33,182 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6339997930335812e-05, 2635
[INFO] 2021-07-12 19:25:33,182 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2635
[INFO] 2021-07-12 19:25:33,182 [run_pretraining.py:  558]:	worker_index: 2, step: 2635, cost: 7.441551, mlm loss: 7.441551, speed: 1.099411 steps/s, speed: 8.795284 samples/s, speed: 4503.185591 tokens/s, learning rate: 2.634e-05, loss_scalings: 2814.750488, pp_loss: 7.053272
[INFO] 2021-07-12 19:25:33,182 [run_pretraining.py:  512]:	********exe.run_2635******* 
[INFO] 2021-07-12 19:25:34,105 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:34,105 [run_pretraining.py:  534]:	loss/total_loss, 6.959674835205078, 2636
[INFO] 2021-07-12 19:25:34,105 [run_pretraining.py:  535]:	loss/mlm_loss, 6.959674835205078, 2636
[INFO] 2021-07-12 19:25:34,105 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.635000055306591e-05, 2636
[INFO] 2021-07-12 19:25:34,105 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2636
[INFO] 2021-07-12 19:25:34,105 [run_pretraining.py:  558]:	worker_index: 2, step: 2636, cost: 6.959675, mlm loss: 6.959675, speed: 1.083991 steps/s, speed: 8.671926 samples/s, speed: 4440.026285 tokens/s, learning rate: 2.635e-05, loss_scalings: 2814.750488, pp_loss: 7.188320
[INFO] 2021-07-12 19:25:34,106 [run_pretraining.py:  512]:	********exe.run_2636******* 
[INFO] 2021-07-12 19:25:35,025 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:35,026 [run_pretraining.py:  534]:	loss/total_loss, 7.320446968078613, 2637
[INFO] 2021-07-12 19:25:35,026 [run_pretraining.py:  535]:	loss/mlm_loss, 7.320446968078613, 2637
[INFO] 2021-07-12 19:25:35,026 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.63599977188278e-05, 2637
[INFO] 2021-07-12 19:25:35,026 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2637
[INFO] 2021-07-12 19:25:35,026 [run_pretraining.py:  558]:	worker_index: 2, step: 2637, cost: 7.320447, mlm loss: 7.320447, speed: 1.087005 steps/s, speed: 8.696039 samples/s, speed: 4452.372003 tokens/s, learning rate: 2.636e-05, loss_scalings: 2814.750488, pp_loss: 7.135712
[INFO] 2021-07-12 19:25:35,026 [run_pretraining.py:  512]:	********exe.run_2637******* 
[INFO] 2021-07-12 19:25:35,950 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:35,950 [run_pretraining.py:  534]:	loss/total_loss, 6.574795722961426, 2638
[INFO] 2021-07-12 19:25:35,951 [run_pretraining.py:  535]:	loss/mlm_loss, 6.574795722961426, 2638
[INFO] 2021-07-12 19:25:35,951 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6370000341557898e-05, 2638
[INFO] 2021-07-12 19:25:35,951 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2638
[INFO] 2021-07-12 19:25:35,951 [run_pretraining.py:  558]:	worker_index: 2, step: 2638, cost: 6.574796, mlm loss: 6.574796, speed: 1.082071 steps/s, speed: 8.656570 samples/s, speed: 4432.163819 tokens/s, learning rate: 2.637e-05, loss_scalings: 2814.750488, pp_loss: 6.741986
[INFO] 2021-07-12 19:25:35,951 [run_pretraining.py:  512]:	********exe.run_2638******* 
[INFO] 2021-07-12 19:25:36,866 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:36,866 [run_pretraining.py:  534]:	loss/total_loss, 6.63133430480957, 2639
[INFO] 2021-07-12 19:25:36,866 [run_pretraining.py:  535]:	loss/mlm_loss, 6.63133430480957, 2639
[INFO] 2021-07-12 19:25:36,866 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.637999932630919e-05, 2639
[INFO] 2021-07-12 19:25:36,867 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2639
[INFO] 2021-07-12 19:25:36,867 [run_pretraining.py:  558]:	worker_index: 2, step: 2639, cost: 6.631334, mlm loss: 6.631334, speed: 1.092625 steps/s, speed: 8.741004 samples/s, speed: 4475.393921 tokens/s, learning rate: 2.638e-05, loss_scalings: 2814.750488, pp_loss: 7.282073
[INFO] 2021-07-12 19:25:36,867 [run_pretraining.py:  512]:	********exe.run_2639******* 
[INFO] 2021-07-12 19:25:37,785 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:37,785 [run_pretraining.py:  534]:	loss/total_loss, 6.860341548919678, 2640
[INFO] 2021-07-12 19:25:37,785 [run_pretraining.py:  535]:	loss/mlm_loss, 6.860341548919678, 2640
[INFO] 2021-07-12 19:25:37,785 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6390000130049884e-05, 2640
[INFO] 2021-07-12 19:25:37,786 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2640
[INFO] 2021-07-12 19:25:37,786 [run_pretraining.py:  558]:	worker_index: 2, step: 2640, cost: 6.860342, mlm loss: 6.860342, speed: 1.088832 steps/s, speed: 8.710658 samples/s, speed: 4459.857134 tokens/s, learning rate: 2.639e-05, loss_scalings: 2814.750488, pp_loss: 7.171048
[INFO] 2021-07-12 19:25:37,786 [run_pretraining.py:  512]:	********exe.run_2640******* 
[INFO] 2021-07-12 19:26:03,405 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:03,406 [run_pretraining.py:  534]:	loss/total_loss, 7.445578098297119, 2641
[INFO] 2021-07-12 19:26:03,406 [run_pretraining.py:  535]:	loss/mlm_loss, 7.445578098297119, 2641
[INFO] 2021-07-12 19:26:03,406 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6399999114801176e-05, 2641
[INFO] 2021-07-12 19:26:03,406 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2641
[INFO] 2021-07-12 19:26:03,406 [run_pretraining.py:  558]:	worker_index: 2, step: 2641, cost: 7.445578, mlm loss: 7.445578, speed: 0.039032 steps/s, speed: 0.312254 samples/s, speed: 159.874185 tokens/s, learning rate: 2.640e-05, loss_scalings: 2814.750488, pp_loss: 7.263374
[INFO] 2021-07-12 19:26:03,407 [run_pretraining.py:  512]:	********exe.run_2641******* 
[INFO] 2021-07-12 19:26:04,322 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:04,322 [run_pretraining.py:  534]:	loss/total_loss, 7.3489990234375, 2642
[INFO] 2021-07-12 19:26:04,322 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3489990234375, 2642
[INFO] 2021-07-12 19:26:04,322 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6409998099552467e-05, 2642
[INFO] 2021-07-12 19:26:04,322 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2642
[INFO] 2021-07-12 19:26:04,322 [run_pretraining.py:  558]:	worker_index: 2, step: 2642, cost: 7.348999, mlm loss: 7.348999, speed: 1.092497 steps/s, speed: 8.739977 samples/s, speed: 4474.868184 tokens/s, learning rate: 2.641e-05, loss_scalings: 2814.750488, pp_loss: 7.444348
[INFO] 2021-07-12 19:26:04,322 [run_pretraining.py:  512]:	********exe.run_2642******* 
[INFO] 2021-07-12 19:26:05,240 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:05,241 [run_pretraining.py:  534]:	loss/total_loss, 6.777156829833984, 2643
[INFO] 2021-07-12 19:26:05,241 [run_pretraining.py:  535]:	loss/mlm_loss, 6.777156829833984, 2643
[INFO] 2021-07-12 19:26:05,241 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6419998903293163e-05, 2643
[INFO] 2021-07-12 19:26:05,241 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2643
[INFO] 2021-07-12 19:26:05,241 [run_pretraining.py:  558]:	worker_index: 2, step: 2643, cost: 6.777157, mlm loss: 6.777157, speed: 1.089251 steps/s, speed: 8.714006 samples/s, speed: 4461.571291 tokens/s, learning rate: 2.642e-05, loss_scalings: 2814.750488, pp_loss: 6.974509
[INFO] 2021-07-12 19:26:05,241 [run_pretraining.py:  512]:	********exe.run_2643******* 
[INFO] 2021-07-12 19:26:06,153 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:06,154 [run_pretraining.py:  534]:	loss/total_loss, 7.845546245574951, 2644
[INFO] 2021-07-12 19:26:06,154 [run_pretraining.py:  535]:	loss/mlm_loss, 7.845546245574951, 2644
[INFO] 2021-07-12 19:26:06,154 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6429997888044454e-05, 2644
[INFO] 2021-07-12 19:26:06,154 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2644
[INFO] 2021-07-12 19:26:06,154 [run_pretraining.py:  558]:	worker_index: 2, step: 2644, cost: 7.845546, mlm loss: 7.845546, speed: 1.095757 steps/s, speed: 8.766052 samples/s, speed: 4488.218776 tokens/s, learning rate: 2.643e-05, loss_scalings: 2814.750488, pp_loss: 7.200705
[INFO] 2021-07-12 19:26:06,154 [run_pretraining.py:  512]:	********exe.run_2644******* 
[INFO] 2021-07-12 19:26:07,071 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:07,072 [run_pretraining.py:  534]:	loss/total_loss, 7.09788703918457, 2645
[INFO] 2021-07-12 19:26:07,072 [run_pretraining.py:  535]:	loss/mlm_loss, 7.09788703918457, 2645
[INFO] 2021-07-12 19:26:07,072 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6440000510774553e-05, 2645
[INFO] 2021-07-12 19:26:07,072 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2645
[INFO] 2021-07-12 19:26:07,072 [run_pretraining.py:  558]:	worker_index: 2, step: 2645, cost: 7.097887, mlm loss: 7.097887, speed: 1.090113 steps/s, speed: 8.720907 samples/s, speed: 4465.104522 tokens/s, learning rate: 2.644e-05, loss_scalings: 2814.750488, pp_loss: 7.291870
[INFO] 2021-07-12 19:26:07,072 [run_pretraining.py:  512]:	********exe.run_2645******* 
[INFO] 2021-07-12 19:26:07,987 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:07,987 [run_pretraining.py:  534]:	loss/total_loss, 7.475171089172363, 2646
[INFO] 2021-07-12 19:26:07,987 [run_pretraining.py:  535]:	loss/mlm_loss, 7.475171089172363, 2646
[INFO] 2021-07-12 19:26:07,987 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.644999767653644e-05, 2646
[INFO] 2021-07-12 19:26:07,987 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2646
[INFO] 2021-07-12 19:26:07,988 [run_pretraining.py:  558]:	worker_index: 2, step: 2646, cost: 7.475171, mlm loss: 7.475171, speed: 1.093250 steps/s, speed: 8.746000 samples/s, speed: 4477.952091 tokens/s, learning rate: 2.645e-05, loss_scalings: 2814.750488, pp_loss: 7.143676
[INFO] 2021-07-12 19:26:07,988 [run_pretraining.py:  512]:	********exe.run_2646******* 
[INFO] 2021-07-12 19:26:08,904 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:08,905 [run_pretraining.py:  534]:	loss/total_loss, 7.257590293884277, 2647
[INFO] 2021-07-12 19:26:08,905 [run_pretraining.py:  535]:	loss/mlm_loss, 7.257590293884277, 2647
[INFO] 2021-07-12 19:26:08,905 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.646000029926654e-05, 2647
[INFO] 2021-07-12 19:26:08,905 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2647
[INFO] 2021-07-12 19:26:08,905 [run_pretraining.py:  558]:	worker_index: 2, step: 2647, cost: 7.257590, mlm loss: 7.257590, speed: 1.090313 steps/s, speed: 8.722506 samples/s, speed: 4465.922822 tokens/s, learning rate: 2.646e-05, loss_scalings: 2814.750488, pp_loss: 7.075890
[INFO] 2021-07-12 19:26:08,905 [run_pretraining.py:  512]:	********exe.run_2647******* 
[INFO] 2021-07-12 19:26:09,819 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:09,820 [run_pretraining.py:  534]:	loss/total_loss, 7.18728494644165, 2648
[INFO] 2021-07-12 19:26:09,820 [run_pretraining.py:  535]:	loss/mlm_loss, 7.18728494644165, 2648
[INFO] 2021-07-12 19:26:09,820 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.646999928401783e-05, 2648
[INFO] 2021-07-12 19:26:09,820 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2648
[INFO] 2021-07-12 19:26:09,820 [run_pretraining.py:  558]:	worker_index: 2, step: 2648, cost: 7.187285, mlm loss: 7.187285, speed: 1.094055 steps/s, speed: 8.752438 samples/s, speed: 4481.248307 tokens/s, learning rate: 2.647e-05, loss_scalings: 2814.750488, pp_loss: 7.374634
[INFO] 2021-07-12 19:26:09,820 [run_pretraining.py:  512]:	********exe.run_2648******* 
[INFO] 2021-07-12 19:26:10,738 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:10,739 [run_pretraining.py:  534]:	loss/total_loss, 6.945273399353027, 2649
[INFO] 2021-07-12 19:26:10,739 [run_pretraining.py:  535]:	loss/mlm_loss, 6.945273399353027, 2649
[INFO] 2021-07-12 19:26:10,739 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6480000087758526e-05, 2649
[INFO] 2021-07-12 19:26:10,739 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2649
[INFO] 2021-07-12 19:26:10,739 [run_pretraining.py:  558]:	worker_index: 2, step: 2649, cost: 6.945273, mlm loss: 6.945273, speed: 1.088760 steps/s, speed: 8.710077 samples/s, speed: 4459.559607 tokens/s, learning rate: 2.648e-05, loss_scalings: 2814.750488, pp_loss: 6.469069
[INFO] 2021-07-12 19:26:10,739 [run_pretraining.py:  512]:	********exe.run_2649******* 
[INFO] 2021-07-12 19:26:11,654 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:11,654 [run_pretraining.py:  534]:	loss/total_loss, 7.071669101715088, 2650
[INFO] 2021-07-12 19:26:11,654 [run_pretraining.py:  535]:	loss/mlm_loss, 7.071669101715088, 2650
[INFO] 2021-07-12 19:26:11,655 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6489999072509818e-05, 2650
[INFO] 2021-07-12 19:26:11,655 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2650
[INFO] 2021-07-12 19:26:11,655 [run_pretraining.py:  558]:	worker_index: 2, step: 2650, cost: 7.071669, mlm loss: 7.071669, speed: 1.092704 steps/s, speed: 8.741635 samples/s, speed: 4475.716885 tokens/s, learning rate: 2.649e-05, loss_scalings: 2814.750488, pp_loss: 7.361750
[INFO] 2021-07-12 19:26:11,655 [run_pretraining.py:  512]:	********exe.run_2650******* 
[INFO] 2021-07-12 19:26:12,568 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:12,569 [run_pretraining.py:  534]:	loss/total_loss, 7.378891944885254, 2651
[INFO] 2021-07-12 19:26:12,569 [run_pretraining.py:  535]:	loss/mlm_loss, 7.378891944885254, 2651
[INFO] 2021-07-12 19:26:12,569 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.649999805726111e-05, 2651
[INFO] 2021-07-12 19:26:12,569 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2651
[INFO] 2021-07-12 19:26:12,569 [run_pretraining.py:  558]:	worker_index: 2, step: 2651, cost: 7.378892, mlm loss: 7.378892, speed: 1.094640 steps/s, speed: 8.757121 samples/s, speed: 4483.645838 tokens/s, learning rate: 2.650e-05, loss_scalings: 2814.750488, pp_loss: 7.215672
[INFO] 2021-07-12 19:26:12,569 [run_pretraining.py:  512]:	********exe.run_2651******* 
[INFO] 2021-07-12 19:26:13,479 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:13,479 [run_pretraining.py:  534]:	loss/total_loss, 6.9212799072265625, 2652
[INFO] 2021-07-12 19:26:13,479 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9212799072265625, 2652
[INFO] 2021-07-12 19:26:13,480 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6509998861001804e-05, 2652
[INFO] 2021-07-12 19:26:13,480 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2652
[INFO] 2021-07-12 19:26:13,480 [run_pretraining.py:  558]:	worker_index: 2, step: 2652, cost: 6.921280, mlm loss: 6.921280, speed: 1.098629 steps/s, speed: 8.789032 samples/s, speed: 4499.984332 tokens/s, learning rate: 2.651e-05, loss_scalings: 2814.750488, pp_loss: 7.153110
[INFO] 2021-07-12 19:26:13,480 [run_pretraining.py:  512]:	********exe.run_2652******* 
[INFO] 2021-07-12 19:26:14,388 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:14,389 [run_pretraining.py:  534]:	loss/total_loss, 7.725803852081299, 2653
[INFO] 2021-07-12 19:26:14,389 [run_pretraining.py:  535]:	loss/mlm_loss, 7.725803852081299, 2653
[INFO] 2021-07-12 19:26:14,389 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6519997845753096e-05, 2653
[INFO] 2021-07-12 19:26:14,389 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2653
[INFO] 2021-07-12 19:26:14,389 [run_pretraining.py:  558]:	worker_index: 2, step: 2653, cost: 7.725804, mlm loss: 7.725804, speed: 1.100077 steps/s, speed: 8.800615 samples/s, speed: 4505.915090 tokens/s, learning rate: 2.652e-05, loss_scalings: 2814.750488, pp_loss: 7.439290
[INFO] 2021-07-12 19:26:14,389 [run_pretraining.py:  512]:	********exe.run_2653******* 
[INFO] 2021-07-12 19:26:15,308 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:15,308 [run_pretraining.py:  534]:	loss/total_loss, 6.690999507904053, 2654
[INFO] 2021-07-12 19:26:15,308 [run_pretraining.py:  535]:	loss/mlm_loss, 6.690999507904053, 2654
[INFO] 2021-07-12 19:26:15,308 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6530000468483195e-05, 2654
[INFO] 2021-07-12 19:26:15,308 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2654
[INFO] 2021-07-12 19:26:15,308 [run_pretraining.py:  558]:	worker_index: 2, step: 2654, cost: 6.691000, mlm loss: 6.691000, speed: 1.088854 steps/s, speed: 8.710828 samples/s, speed: 4459.943968 tokens/s, learning rate: 2.653e-05, loss_scalings: 2814.750488, pp_loss: 7.040720
[INFO] 2021-07-12 19:26:15,308 [run_pretraining.py:  512]:	********exe.run_2654******* 
[INFO] 2021-07-12 19:26:16,225 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:16,226 [run_pretraining.py:  534]:	loss/total_loss, 6.996044158935547, 2655
[INFO] 2021-07-12 19:26:16,226 [run_pretraining.py:  535]:	loss/mlm_loss, 6.996044158935547, 2655
[INFO] 2021-07-12 19:26:16,226 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6539999453234486e-05, 2655
[INFO] 2021-07-12 19:26:16,226 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2655
[INFO] 2021-07-12 19:26:16,226 [run_pretraining.py:  558]:	worker_index: 2, step: 2655, cost: 6.996044, mlm loss: 6.996044, speed: 1.090101 steps/s, speed: 8.720810 samples/s, speed: 4465.054622 tokens/s, learning rate: 2.654e-05, loss_scalings: 2814.750488, pp_loss: 7.261146
[INFO] 2021-07-12 19:26:16,226 [run_pretraining.py:  512]:	********exe.run_2655******* 
[INFO] 2021-07-12 19:26:17,143 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:17,143 [run_pretraining.py:  534]:	loss/total_loss, 6.670591831207275, 2656
[INFO] 2021-07-12 19:26:17,143 [run_pretraining.py:  535]:	loss/mlm_loss, 6.670591831207275, 2656
[INFO] 2021-07-12 19:26:17,144 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.655000025697518e-05, 2656
[INFO] 2021-07-12 19:26:17,144 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2656
[INFO] 2021-07-12 19:26:17,144 [run_pretraining.py:  558]:	worker_index: 2, step: 2656, cost: 6.670592, mlm loss: 6.670592, speed: 1.090681 steps/s, speed: 8.725447 samples/s, speed: 4467.429044 tokens/s, learning rate: 2.655e-05, loss_scalings: 2814.750488, pp_loss: 6.952671
[INFO] 2021-07-12 19:26:17,144 [run_pretraining.py:  512]:	********exe.run_2656******* 
[INFO] 2021-07-12 19:26:18,054 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:18,054 [run_pretraining.py:  534]:	loss/total_loss, 7.742403030395508, 2657
[INFO] 2021-07-12 19:26:18,054 [run_pretraining.py:  535]:	loss/mlm_loss, 7.742403030395508, 2657
[INFO] 2021-07-12 19:26:18,054 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6559999241726473e-05, 2657
[INFO] 2021-07-12 19:26:18,054 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2657
[INFO] 2021-07-12 19:26:18,054 [run_pretraining.py:  558]:	worker_index: 2, step: 2657, cost: 7.742403, mlm loss: 7.742403, speed: 1.098878 steps/s, speed: 8.791021 samples/s, speed: 4501.002957 tokens/s, learning rate: 2.656e-05, loss_scalings: 2814.750488, pp_loss: 7.420940
[INFO] 2021-07-12 19:26:18,054 [run_pretraining.py:  512]:	********exe.run_2657******* 
[INFO] 2021-07-12 19:26:18,971 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:18,971 [run_pretraining.py:  534]:	loss/total_loss, 7.20634651184082, 2658
[INFO] 2021-07-12 19:26:18,971 [run_pretraining.py:  535]:	loss/mlm_loss, 7.20634651184082, 2658
[INFO] 2021-07-12 19:26:18,971 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6570000045467168e-05, 2658
[INFO] 2021-07-12 19:26:18,971 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2658
[INFO] 2021-07-12 19:26:18,971 [run_pretraining.py:  558]:	worker_index: 2, step: 2658, cost: 7.206347, mlm loss: 7.206347, speed: 1.091132 steps/s, speed: 8.729054 samples/s, speed: 4469.275754 tokens/s, learning rate: 2.657e-05, loss_scalings: 2814.750488, pp_loss: 7.200475
[INFO] 2021-07-12 19:26:18,972 [run_pretraining.py:  512]:	********exe.run_2658******* 
[INFO] 2021-07-12 19:26:19,887 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:19,887 [run_pretraining.py:  534]:	loss/total_loss, 6.92405891418457, 2659
[INFO] 2021-07-12 19:26:19,887 [run_pretraining.py:  535]:	loss/mlm_loss, 6.92405891418457, 2659
[INFO] 2021-07-12 19:26:19,887 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.657999903021846e-05, 2659
[INFO] 2021-07-12 19:26:19,887 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2659
[INFO] 2021-07-12 19:26:19,887 [run_pretraining.py:  558]:	worker_index: 2, step: 2659, cost: 6.924059, mlm loss: 6.924059, speed: 1.092401 steps/s, speed: 8.739208 samples/s, speed: 4474.474254 tokens/s, learning rate: 2.658e-05, loss_scalings: 2814.750488, pp_loss: 7.477604
[INFO] 2021-07-12 19:26:19,888 [run_pretraining.py:  512]:	********exe.run_2659******* 
[INFO] 2021-07-12 19:26:20,816 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:20,816 [run_pretraining.py:  534]:	loss/total_loss, 7.537458896636963, 2660
[INFO] 2021-07-12 19:26:20,816 [run_pretraining.py:  535]:	loss/mlm_loss, 7.537458896636963, 2660
[INFO] 2021-07-12 19:26:20,816 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.658999801496975e-05, 2660
[INFO] 2021-07-12 19:26:20,816 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2660
[INFO] 2021-07-12 19:26:20,816 [run_pretraining.py:  558]:	worker_index: 2, step: 2660, cost: 7.537459, mlm loss: 7.537459, speed: 1.077143 steps/s, speed: 8.617141 samples/s, speed: 4411.976214 tokens/s, learning rate: 2.659e-05, loss_scalings: 2814.750488, pp_loss: 7.525667
[INFO] 2021-07-12 19:26:20,817 [run_pretraining.py:  512]:	********exe.run_2660******* 
[INFO] 2021-07-12 19:26:21,735 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:21,735 [run_pretraining.py:  534]:	loss/total_loss, 7.302311420440674, 2661
[INFO] 2021-07-12 19:26:21,735 [run_pretraining.py:  535]:	loss/mlm_loss, 7.302311420440674, 2661
[INFO] 2021-07-12 19:26:21,735 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6599998818710446e-05, 2661
[INFO] 2021-07-12 19:26:21,735 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2661
[INFO] 2021-07-12 19:26:21,735 [run_pretraining.py:  558]:	worker_index: 2, step: 2661, cost: 7.302311, mlm loss: 7.302311, speed: 1.088934 steps/s, speed: 8.711475 samples/s, speed: 4460.275128 tokens/s, learning rate: 2.660e-05, loss_scalings: 2814.750488, pp_loss: 7.352231
[INFO] 2021-07-12 19:26:21,735 [run_pretraining.py:  512]:	********exe.run_2661******* 
[INFO] 2021-07-12 19:26:22,657 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:22,658 [run_pretraining.py:  534]:	loss/total_loss, 7.390295505523682, 2662
[INFO] 2021-07-12 19:26:22,658 [run_pretraining.py:  535]:	loss/mlm_loss, 7.390295505523682, 2662
[INFO] 2021-07-12 19:26:22,658 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6609997803461738e-05, 2662
[INFO] 2021-07-12 19:26:22,658 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2662
[INFO] 2021-07-12 19:26:22,658 [run_pretraining.py:  558]:	worker_index: 2, step: 2662, cost: 7.390296, mlm loss: 7.390296, speed: 1.084350 steps/s, speed: 8.674801 samples/s, speed: 4441.497862 tokens/s, learning rate: 2.661e-05, loss_scalings: 2814.750488, pp_loss: 7.206270
[INFO] 2021-07-12 19:26:22,658 [run_pretraining.py:  512]:	********exe.run_2662******* 
[INFO] 2021-07-12 19:26:23,574 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:23,575 [run_pretraining.py:  534]:	loss/total_loss, 7.673919677734375, 2663
[INFO] 2021-07-12 19:26:23,575 [run_pretraining.py:  535]:	loss/mlm_loss, 7.673919677734375, 2663
[INFO] 2021-07-12 19:26:23,575 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6620000426191837e-05, 2663
[INFO] 2021-07-12 19:26:23,575 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2663
[INFO] 2021-07-12 19:26:23,575 [run_pretraining.py:  558]:	worker_index: 2, step: 2663, cost: 7.673920, mlm loss: 7.673920, speed: 1.091476 steps/s, speed: 8.731810 samples/s, speed: 4470.686512 tokens/s, learning rate: 2.662e-05, loss_scalings: 2814.750488, pp_loss: 7.313796
[INFO] 2021-07-12 19:26:23,575 [run_pretraining.py:  512]:	********exe.run_2663******* 
[INFO] 2021-07-12 19:26:24,488 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:24,488 [run_pretraining.py:  534]:	loss/total_loss, 6.8099260330200195, 2664
[INFO] 2021-07-12 19:26:24,488 [run_pretraining.py:  535]:	loss/mlm_loss, 6.8099260330200195, 2664
[INFO] 2021-07-12 19:26:24,488 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6629999410943128e-05, 2664
[INFO] 2021-07-12 19:26:24,488 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2664
[INFO] 2021-07-12 19:26:24,488 [run_pretraining.py:  558]:	worker_index: 2, step: 2664, cost: 6.809926, mlm loss: 6.809926, speed: 1.095385 steps/s, speed: 8.763083 samples/s, speed: 4486.698505 tokens/s, learning rate: 2.663e-05, loss_scalings: 2814.750488, pp_loss: 7.403455
[INFO] 2021-07-12 19:26:24,489 [run_pretraining.py:  512]:	********exe.run_2664******* 
[INFO] 2021-07-12 19:26:25,399 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:25,399 [run_pretraining.py:  534]:	loss/total_loss, 6.7830610275268555, 2665
[INFO] 2021-07-12 19:26:25,400 [run_pretraining.py:  535]:	loss/mlm_loss, 6.7830610275268555, 2665
[INFO] 2021-07-12 19:26:25,400 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6640000214683823e-05, 2665
[INFO] 2021-07-12 19:26:25,400 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2665
[INFO] 2021-07-12 19:26:25,400 [run_pretraining.py:  558]:	worker_index: 2, step: 2665, cost: 6.783061, mlm loss: 6.783061, speed: 1.098110 steps/s, speed: 8.784881 samples/s, speed: 4497.858967 tokens/s, learning rate: 2.664e-05, loss_scalings: 2814.750488, pp_loss: 6.841856
[INFO] 2021-07-12 19:26:25,400 [run_pretraining.py:  512]:	********exe.run_2665******* 
[INFO] 2021-07-12 19:26:26,323 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:26,323 [run_pretraining.py:  534]:	loss/total_loss, 6.541839599609375, 2666
[INFO] 2021-07-12 19:26:26,323 [run_pretraining.py:  535]:	loss/mlm_loss, 6.541839599609375, 2666
[INFO] 2021-07-12 19:26:26,323 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6649999199435115e-05, 2666
[INFO] 2021-07-12 19:26:26,323 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2666
[INFO] 2021-07-12 19:26:26,324 [run_pretraining.py:  558]:	worker_index: 2, step: 2666, cost: 6.541840, mlm loss: 6.541840, speed: 1.083260 steps/s, speed: 8.666079 samples/s, speed: 4437.032193 tokens/s, learning rate: 2.665e-05, loss_scalings: 2814.750488, pp_loss: 6.889101
[INFO] 2021-07-12 19:26:26,324 [run_pretraining.py:  512]:	********exe.run_2666******* 
[INFO] 2021-07-12 19:26:27,243 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:27,244 [run_pretraining.py:  534]:	loss/total_loss, 6.710479736328125, 2667
[INFO] 2021-07-12 19:26:27,244 [run_pretraining.py:  535]:	loss/mlm_loss, 6.710479736328125, 2667
[INFO] 2021-07-12 19:26:27,244 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.666000000317581e-05, 2667
[INFO] 2021-07-12 19:26:27,244 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2667
[INFO] 2021-07-12 19:26:27,244 [run_pretraining.py:  558]:	worker_index: 2, step: 2667, cost: 6.710480, mlm loss: 6.710480, speed: 1.086943 steps/s, speed: 8.695546 samples/s, speed: 4452.119317 tokens/s, learning rate: 2.666e-05, loss_scalings: 2814.750488, pp_loss: 7.442411
[INFO] 2021-07-12 19:26:27,244 [run_pretraining.py:  512]:	********exe.run_2667******* 
[INFO] 2021-07-12 19:26:28,160 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:28,160 [run_pretraining.py:  534]:	loss/total_loss, 7.171541213989258, 2668
[INFO] 2021-07-12 19:26:28,160 [run_pretraining.py:  535]:	loss/mlm_loss, 7.171541213989258, 2668
[INFO] 2021-07-12 19:26:28,160 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.66699989879271e-05, 2668
[INFO] 2021-07-12 19:26:28,160 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2668
[INFO] 2021-07-12 19:26:28,161 [run_pretraining.py:  558]:	worker_index: 2, step: 2668, cost: 7.171541, mlm loss: 7.171541, speed: 1.091913 steps/s, speed: 8.735303 samples/s, speed: 4472.475371 tokens/s, learning rate: 2.667e-05, loss_scalings: 2814.750488, pp_loss: 7.252170
[INFO] 2021-07-12 19:26:28,161 [run_pretraining.py:  512]:	********exe.run_2668******* 
[INFO] 2021-07-12 19:26:29,084 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:29,085 [run_pretraining.py:  534]:	loss/total_loss, 7.385962009429932, 2669
[INFO] 2021-07-12 19:26:29,085 [run_pretraining.py:  535]:	loss/mlm_loss, 7.385962009429932, 2669
[INFO] 2021-07-12 19:26:29,085 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6679997972678393e-05, 2669
[INFO] 2021-07-12 19:26:29,085 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2669
[INFO] 2021-07-12 19:26:29,085 [run_pretraining.py:  558]:	worker_index: 2, step: 2669, cost: 7.385962, mlm loss: 7.385962, speed: 1.082331 steps/s, speed: 8.658645 samples/s, speed: 4433.226325 tokens/s, learning rate: 2.668e-05, loss_scalings: 2814.750488, pp_loss: 6.954315
[INFO] 2021-07-12 19:26:29,085 [run_pretraining.py:  512]:	********exe.run_2669******* 
[INFO] 2021-07-12 19:26:29,996 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:29,997 [run_pretraining.py:  534]:	loss/total_loss, 6.677488803863525, 2670
[INFO] 2021-07-12 19:26:29,997 [run_pretraining.py:  535]:	loss/mlm_loss, 6.677488803863525, 2670
[INFO] 2021-07-12 19:26:29,997 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6689998776419088e-05, 2670
[INFO] 2021-07-12 19:26:29,997 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2670
[INFO] 2021-07-12 19:26:29,997 [run_pretraining.py:  558]:	worker_index: 2, step: 2670, cost: 6.677489, mlm loss: 6.677489, speed: 1.097069 steps/s, speed: 8.776556 samples/s, speed: 4493.596624 tokens/s, learning rate: 2.669e-05, loss_scalings: 2814.750488, pp_loss: 6.831970
[INFO] 2021-07-12 19:26:29,997 [run_pretraining.py:  512]:	********exe.run_2670******* 
[INFO] 2021-07-12 19:26:31,032 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:31,033 [run_pretraining.py:  534]:	loss/total_loss, 7.231522560119629, 2671
[INFO] 2021-07-12 19:26:31,033 [run_pretraining.py:  535]:	loss/mlm_loss, 7.231522560119629, 2671
[INFO] 2021-07-12 19:26:31,033 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.669999776117038e-05, 2671
[INFO] 2021-07-12 19:26:31,033 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2671
[INFO] 2021-07-12 19:26:31,033 [run_pretraining.py:  558]:	worker_index: 2, step: 2671, cost: 7.231523, mlm loss: 7.231523, speed: 0.965783 steps/s, speed: 7.726268 samples/s, speed: 3955.849160 tokens/s, learning rate: 2.670e-05, loss_scalings: 2814.750488, pp_loss: 7.157634
[INFO] 2021-07-12 19:26:31,033 [run_pretraining.py:  512]:	********exe.run_2671******* 
[INFO] 2021-07-12 19:26:32,126 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:32,126 [run_pretraining.py:  534]:	loss/total_loss, 6.877582550048828, 2672
[INFO] 2021-07-12 19:26:32,127 [run_pretraining.py:  535]:	loss/mlm_loss, 6.877582550048828, 2672
[INFO] 2021-07-12 19:26:32,127 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.671000038390048e-05, 2672
[INFO] 2021-07-12 19:26:32,127 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2672
[INFO] 2021-07-12 19:26:32,127 [run_pretraining.py:  558]:	worker_index: 2, step: 2672, cost: 6.877583, mlm loss: 6.877583, speed: 0.914920 steps/s, speed: 7.319359 samples/s, speed: 3747.512005 tokens/s, learning rate: 2.671e-05, loss_scalings: 2814.750488, pp_loss: 6.964309
[INFO] 2021-07-12 19:26:32,127 [run_pretraining.py:  512]:	********exe.run_2672******* 
[INFO] 2021-07-12 19:26:33,229 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:33,229 [run_pretraining.py:  534]:	loss/total_loss, 7.488432884216309, 2673
[INFO] 2021-07-12 19:26:33,229 [run_pretraining.py:  535]:	loss/mlm_loss, 7.488432884216309, 2673
[INFO] 2021-07-12 19:26:33,229 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.671999936865177e-05, 2673
[INFO] 2021-07-12 19:26:33,230 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2673
[INFO] 2021-07-12 19:26:33,230 [run_pretraining.py:  558]:	worker_index: 2, step: 2673, cost: 7.488433, mlm loss: 7.488433, speed: 0.907286 steps/s, speed: 7.258289 samples/s, speed: 3716.244044 tokens/s, learning rate: 2.672e-05, loss_scalings: 2814.750488, pp_loss: 7.466378
[INFO] 2021-07-12 19:26:33,230 [run_pretraining.py:  512]:	********exe.run_2673******* 
[INFO] 2021-07-12 19:26:34,320 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:34,320 [run_pretraining.py:  534]:	loss/total_loss, 7.723202705383301, 2674
[INFO] 2021-07-12 19:26:34,320 [run_pretraining.py:  535]:	loss/mlm_loss, 7.723202705383301, 2674
[INFO] 2021-07-12 19:26:34,320 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6730000172392465e-05, 2674
[INFO] 2021-07-12 19:26:34,320 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2674
[INFO] 2021-07-12 19:26:34,320 [run_pretraining.py:  558]:	worker_index: 2, step: 2674, cost: 7.723203, mlm loss: 7.723203, speed: 0.917279 steps/s, speed: 7.338230 samples/s, speed: 3757.173880 tokens/s, learning rate: 2.673e-05, loss_scalings: 2814.750488, pp_loss: 7.404744
[INFO] 2021-07-12 19:26:34,320 [run_pretraining.py:  512]:	********exe.run_2674******* 
[INFO] 2021-07-12 19:26:35,415 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:35,416 [run_pretraining.py:  534]:	loss/total_loss, 7.09184455871582, 2675
[INFO] 2021-07-12 19:26:35,416 [run_pretraining.py:  535]:	loss/mlm_loss, 7.09184455871582, 2675
[INFO] 2021-07-12 19:26:35,416 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6739999157143757e-05, 2675
[INFO] 2021-07-12 19:26:35,416 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2675
[INFO] 2021-07-12 19:26:35,416 [run_pretraining.py:  558]:	worker_index: 2, step: 2675, cost: 7.091845, mlm loss: 7.091845, speed: 0.913253 steps/s, speed: 7.306025 samples/s, speed: 3740.684782 tokens/s, learning rate: 2.674e-05, loss_scalings: 2814.750488, pp_loss: 7.381603
[INFO] 2021-07-12 19:26:35,416 [run_pretraining.py:  512]:	********exe.run_2675******* 
[INFO] 2021-07-12 19:26:36,513 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:36,514 [run_pretraining.py:  534]:	loss/total_loss, 7.674099922180176, 2676
[INFO] 2021-07-12 19:26:36,514 [run_pretraining.py:  535]:	loss/mlm_loss, 7.674099922180176, 2676
[INFO] 2021-07-12 19:26:36,514 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6749999960884452e-05, 2676
[INFO] 2021-07-12 19:26:36,514 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2676
[INFO] 2021-07-12 19:26:36,514 [run_pretraining.py:  558]:	worker_index: 2, step: 2676, cost: 7.674100, mlm loss: 7.674100, speed: 0.911003 steps/s, speed: 7.288025 samples/s, speed: 3731.468855 tokens/s, learning rate: 2.675e-05, loss_scalings: 2814.750488, pp_loss: 7.424227
[INFO] 2021-07-12 19:26:36,514 [run_pretraining.py:  512]:	********exe.run_2676******* 
[INFO] 2021-07-12 19:26:37,602 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:37,602 [run_pretraining.py:  534]:	loss/total_loss, 7.193118095397949, 2677
[INFO] 2021-07-12 19:26:37,602 [run_pretraining.py:  535]:	loss/mlm_loss, 7.193118095397949, 2677
[INFO] 2021-07-12 19:26:37,602 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6759998945635743e-05, 2677
[INFO] 2021-07-12 19:26:37,602 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2677
[INFO] 2021-07-12 19:26:37,603 [run_pretraining.py:  558]:	worker_index: 2, step: 2677, cost: 7.193118, mlm loss: 7.193118, speed: 0.919390 steps/s, speed: 7.355118 samples/s, speed: 3765.820553 tokens/s, learning rate: 2.676e-05, loss_scalings: 2814.750488, pp_loss: 7.302068
[INFO] 2021-07-12 19:26:37,603 [run_pretraining.py:  512]:	********exe.run_2677******* 
[INFO] 2021-07-12 19:26:38,698 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:38,698 [run_pretraining.py:  534]:	loss/total_loss, 7.08444356918335, 2678
[INFO] 2021-07-12 19:26:38,698 [run_pretraining.py:  535]:	loss/mlm_loss, 7.08444356918335, 2678
[INFO] 2021-07-12 19:26:38,698 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6769997930387035e-05, 2678
[INFO] 2021-07-12 19:26:38,698 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2678
[INFO] 2021-07-12 19:26:38,698 [run_pretraining.py:  558]:	worker_index: 2, step: 2678, cost: 7.084444, mlm loss: 7.084444, speed: 0.913063 steps/s, speed: 7.304508 samples/s, speed: 3739.907926 tokens/s, learning rate: 2.677e-05, loss_scalings: 2814.750488, pp_loss: 7.522727
[INFO] 2021-07-12 19:26:38,698 [run_pretraining.py:  512]:	********exe.run_2678******* 
[INFO] 2021-07-12 19:26:39,798 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:39,798 [run_pretraining.py:  534]:	loss/total_loss, 6.755091667175293, 2679
[INFO] 2021-07-12 19:26:39,799 [run_pretraining.py:  535]:	loss/mlm_loss, 6.755091667175293, 2679
[INFO] 2021-07-12 19:26:39,799 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6780000553117134e-05, 2679
[INFO] 2021-07-12 19:26:39,799 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2679
[INFO] 2021-07-12 19:26:39,799 [run_pretraining.py:  558]:	worker_index: 2, step: 2679, cost: 6.755092, mlm loss: 6.755092, speed: 0.909200 steps/s, speed: 7.273600 samples/s, speed: 3724.083053 tokens/s, learning rate: 2.678e-05, loss_scalings: 2814.750488, pp_loss: 6.889978
[INFO] 2021-07-12 19:26:39,799 [run_pretraining.py:  512]:	********exe.run_2679******* 
[INFO] 2021-07-12 19:26:40,885 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:40,886 [run_pretraining.py:  534]:	loss/total_loss, 7.48652982711792, 2680
[INFO] 2021-07-12 19:26:40,886 [run_pretraining.py:  535]:	loss/mlm_loss, 7.48652982711792, 2680
[INFO] 2021-07-12 19:26:40,886 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6789997718879022e-05, 2680
[INFO] 2021-07-12 19:26:40,886 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2680
[INFO] 2021-07-12 19:26:40,886 [run_pretraining.py:  558]:	worker_index: 2, step: 2680, cost: 7.486530, mlm loss: 7.486530, speed: 0.920307 steps/s, speed: 7.362456 samples/s, speed: 3769.577693 tokens/s, learning rate: 2.679e-05, loss_scalings: 2814.750488, pp_loss: 7.237316
[INFO] 2021-07-12 19:26:40,886 [run_pretraining.py:  512]:	********exe.run_2680******* 
[INFO] 2021-07-12 19:26:41,982 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:41,983 [run_pretraining.py:  534]:	loss/total_loss, 7.48763370513916, 2681
[INFO] 2021-07-12 19:26:41,983 [run_pretraining.py:  535]:	loss/mlm_loss, 7.48763370513916, 2681
[INFO] 2021-07-12 19:26:41,983 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.680000034160912e-05, 2681
[INFO] 2021-07-12 19:26:41,983 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2681
[INFO] 2021-07-12 19:26:41,983 [run_pretraining.py:  558]:	worker_index: 2, step: 2681, cost: 7.487634, mlm loss: 7.487634, speed: 0.911810 steps/s, speed: 7.294478 samples/s, speed: 3734.772844 tokens/s, learning rate: 2.680e-05, loss_scalings: 2814.750488, pp_loss: 7.418378
[INFO] 2021-07-12 19:26:41,983 [run_pretraining.py:  512]:	********exe.run_2681******* 
[INFO] 2021-07-12 19:26:43,082 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:43,082 [run_pretraining.py:  534]:	loss/total_loss, 7.002819538116455, 2682
[INFO] 2021-07-12 19:26:43,082 [run_pretraining.py:  535]:	loss/mlm_loss, 7.002819538116455, 2682
[INFO] 2021-07-12 19:26:43,082 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6809999326360412e-05, 2682
[INFO] 2021-07-12 19:26:43,082 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2682
[INFO] 2021-07-12 19:26:43,082 [run_pretraining.py:  558]:	worker_index: 2, step: 2682, cost: 7.002820, mlm loss: 7.002820, speed: 0.910366 steps/s, speed: 7.282928 samples/s, speed: 3728.859330 tokens/s, learning rate: 2.681e-05, loss_scalings: 2814.750488, pp_loss: 7.459452
[INFO] 2021-07-12 19:26:43,082 [run_pretraining.py:  512]:	********exe.run_2682******* 
[INFO] 2021-07-12 19:26:44,170 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:44,170 [run_pretraining.py:  534]:	loss/total_loss, 7.7279157638549805, 2683
[INFO] 2021-07-12 19:26:44,170 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7279157638549805, 2683
[INFO] 2021-07-12 19:26:44,170 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6820000130101107e-05, 2683
[INFO] 2021-07-12 19:26:44,171 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2683
[INFO] 2021-07-12 19:26:44,171 [run_pretraining.py:  558]:	worker_index: 2, step: 2683, cost: 7.727916, mlm loss: 7.727916, speed: 0.919427 steps/s, speed: 7.355413 samples/s, speed: 3765.971619 tokens/s, learning rate: 2.682e-05, loss_scalings: 2814.750488, pp_loss: 7.526657
[INFO] 2021-07-12 19:26:44,171 [run_pretraining.py:  512]:	********exe.run_2683******* 
[INFO] 2021-07-12 19:26:45,266 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:45,266 [run_pretraining.py:  534]:	loss/total_loss, 7.116103172302246, 2684
[INFO] 2021-07-12 19:26:45,266 [run_pretraining.py:  535]:	loss/mlm_loss, 7.116103172302246, 2684
[INFO] 2021-07-12 19:26:45,266 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.68299991148524e-05, 2684
[INFO] 2021-07-12 19:26:45,266 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2684
[INFO] 2021-07-12 19:26:45,266 [run_pretraining.py:  558]:	worker_index: 2, step: 2684, cost: 7.116103, mlm loss: 7.116103, speed: 0.913073 steps/s, speed: 7.304582 samples/s, speed: 3739.946191 tokens/s, learning rate: 2.683e-05, loss_scalings: 2814.750488, pp_loss: 7.566123
[INFO] 2021-07-12 19:26:45,266 [run_pretraining.py:  512]:	********exe.run_2684******* 
[INFO] 2021-07-12 19:26:46,398 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:46,399 [run_pretraining.py:  534]:	loss/total_loss, 7.2936811447143555, 2685
[INFO] 2021-07-12 19:26:46,399 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2936811447143555, 2685
[INFO] 2021-07-12 19:26:46,399 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6839999918593094e-05, 2685
[INFO] 2021-07-12 19:26:46,399 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2685
[INFO] 2021-07-12 19:26:46,399 [run_pretraining.py:  558]:	worker_index: 2, step: 2685, cost: 7.293681, mlm loss: 7.293681, speed: 0.883383 steps/s, speed: 7.067067 samples/s, speed: 3618.338076 tokens/s, learning rate: 2.684e-05, loss_scalings: 2814.750488, pp_loss: 7.450671
[INFO] 2021-07-12 19:26:46,399 [run_pretraining.py:  512]:	********exe.run_2685******* 
[INFO] 2021-07-12 19:26:47,488 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:47,489 [run_pretraining.py:  534]:	loss/total_loss, 8.008007049560547, 2686
[INFO] 2021-07-12 19:26:47,489 [run_pretraining.py:  535]:	loss/mlm_loss, 8.008007049560547, 2686
[INFO] 2021-07-12 19:26:47,489 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6849998903344385e-05, 2686
[INFO] 2021-07-12 19:26:47,489 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2686
[INFO] 2021-07-12 19:26:47,489 [run_pretraining.py:  558]:	worker_index: 2, step: 2686, cost: 8.008007, mlm loss: 8.008007, speed: 0.917724 steps/s, speed: 7.341792 samples/s, speed: 3758.997251 tokens/s, learning rate: 2.685e-05, loss_scalings: 2814.750488, pp_loss: 7.621063
[INFO] 2021-07-12 19:26:47,489 [run_pretraining.py:  512]:	********exe.run_2686******* 
[INFO] 2021-07-12 19:26:48,582 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:48,583 [run_pretraining.py:  534]:	loss/total_loss, 7.353038787841797, 2687
[INFO] 2021-07-12 19:26:48,583 [run_pretraining.py:  535]:	loss/mlm_loss, 7.353038787841797, 2687
[INFO] 2021-07-12 19:26:48,583 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6859997888095677e-05, 2687
[INFO] 2021-07-12 19:26:48,583 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2687
[INFO] 2021-07-12 19:26:48,583 [run_pretraining.py:  558]:	worker_index: 2, step: 2687, cost: 7.353039, mlm loss: 7.353039, speed: 0.914622 steps/s, speed: 7.316976 samples/s, speed: 3746.291935 tokens/s, learning rate: 2.686e-05, loss_scalings: 2814.750488, pp_loss: 7.477280
[INFO] 2021-07-12 19:26:48,583 [run_pretraining.py:  512]:	********exe.run_2687******* 
[INFO] 2021-07-12 19:26:49,673 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:49,674 [run_pretraining.py:  534]:	loss/total_loss, 7.545592784881592, 2688
[INFO] 2021-07-12 19:26:49,674 [run_pretraining.py:  535]:	loss/mlm_loss, 7.545592784881592, 2688
[INFO] 2021-07-12 19:26:49,674 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6870000510825776e-05, 2688
[INFO] 2021-07-12 19:26:49,674 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2688
[INFO] 2021-07-12 19:26:49,674 [run_pretraining.py:  558]:	worker_index: 2, step: 2688, cost: 7.545593, mlm loss: 7.545593, speed: 0.917343 steps/s, speed: 7.338745 samples/s, speed: 3757.437658 tokens/s, learning rate: 2.687e-05, loss_scalings: 2814.750488, pp_loss: 7.385784
[INFO] 2021-07-12 19:26:49,674 [run_pretraining.py:  512]:	********exe.run_2688******* 
[INFO] 2021-07-12 19:26:50,764 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:50,764 [run_pretraining.py:  534]:	loss/total_loss, 7.011380195617676, 2689
[INFO] 2021-07-12 19:26:50,764 [run_pretraining.py:  535]:	loss/mlm_loss, 7.011380195617676, 2689
[INFO] 2021-07-12 19:26:50,764 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6879997676587664e-05, 2689
[INFO] 2021-07-12 19:26:50,765 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2689
[INFO] 2021-07-12 19:26:50,765 [run_pretraining.py:  558]:	worker_index: 2, step: 2689, cost: 7.011380, mlm loss: 7.011380, speed: 0.917340 steps/s, speed: 7.338720 samples/s, speed: 3757.424510 tokens/s, learning rate: 2.688e-05, loss_scalings: 2814.750488, pp_loss: 7.320940
[INFO] 2021-07-12 19:26:50,765 [run_pretraining.py:  512]:	********exe.run_2689******* 
[INFO] 2021-07-12 19:26:51,867 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:51,867 [run_pretraining.py:  534]:	loss/total_loss, 8.995882987976074, 2690
[INFO] 2021-07-12 19:26:51,867 [run_pretraining.py:  535]:	loss/mlm_loss, 8.995882987976074, 2690
[INFO] 2021-07-12 19:26:51,867 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6890000299317762e-05, 2690
[INFO] 2021-07-12 19:26:51,867 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2690
[INFO] 2021-07-12 19:26:51,868 [run_pretraining.py:  558]:	worker_index: 2, step: 2690, cost: 8.995883, mlm loss: 8.995883, speed: 0.907201 steps/s, speed: 7.257608 samples/s, speed: 3715.895195 tokens/s, learning rate: 2.689e-05, loss_scalings: 2814.750488, pp_loss: 7.558743
[INFO] 2021-07-12 19:26:51,868 [run_pretraining.py:  512]:	********exe.run_2690******* 
[INFO] 2021-07-12 19:26:52,955 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:52,955 [run_pretraining.py:  534]:	loss/total_loss, 7.5268096923828125, 2691
[INFO] 2021-07-12 19:26:52,955 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5268096923828125, 2691
[INFO] 2021-07-12 19:26:52,955 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6899999284069054e-05, 2691
[INFO] 2021-07-12 19:26:52,955 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2691
[INFO] 2021-07-12 19:26:52,956 [run_pretraining.py:  558]:	worker_index: 2, step: 2691, cost: 7.526810, mlm loss: 7.526810, speed: 0.919625 steps/s, speed: 7.356997 samples/s, speed: 3766.782467 tokens/s, learning rate: 2.690e-05, loss_scalings: 2814.750488, pp_loss: 7.281621
[INFO] 2021-07-12 19:26:52,956 [run_pretraining.py:  512]:	********exe.run_2691******* 
[INFO] 2021-07-12 19:26:54,053 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:54,053 [run_pretraining.py:  534]:	loss/total_loss, 7.777550220489502, 2692
[INFO] 2021-07-12 19:26:54,053 [run_pretraining.py:  535]:	loss/mlm_loss, 7.777550220489502, 2692
[INFO] 2021-07-12 19:26:54,053 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.691000008780975e-05, 2692
[INFO] 2021-07-12 19:26:54,054 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2692
[INFO] 2021-07-12 19:26:54,054 [run_pretraining.py:  558]:	worker_index: 2, step: 2692, cost: 7.777550, mlm loss: 7.777550, speed: 0.911191 steps/s, speed: 7.289526 samples/s, speed: 3732.237344 tokens/s, learning rate: 2.691e-05, loss_scalings: 2814.750488, pp_loss: 7.554755
[INFO] 2021-07-12 19:26:54,054 [run_pretraining.py:  512]:	********exe.run_2692******* 
[INFO] 2021-07-12 19:26:55,152 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:55,153 [run_pretraining.py:  534]:	loss/total_loss, 6.204956531524658, 2693
[INFO] 2021-07-12 19:26:55,153 [run_pretraining.py:  535]:	loss/mlm_loss, 6.204956531524658, 2693
[INFO] 2021-07-12 19:26:55,153 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.691999907256104e-05, 2693
[INFO] 2021-07-12 19:26:55,153 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2693
[INFO] 2021-07-12 19:26:55,153 [run_pretraining.py:  558]:	worker_index: 2, step: 2693, cost: 6.204957, mlm loss: 6.204957, speed: 0.909977 steps/s, speed: 7.279814 samples/s, speed: 3727.264799 tokens/s, learning rate: 2.692e-05, loss_scalings: 2814.750488, pp_loss: 6.925791
[INFO] 2021-07-12 19:26:55,153 [run_pretraining.py:  512]:	********exe.run_2693******* 
[INFO] 2021-07-12 19:26:56,247 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:56,247 [run_pretraining.py:  534]:	loss/total_loss, 6.619738578796387, 2694
[INFO] 2021-07-12 19:26:56,248 [run_pretraining.py:  535]:	loss/mlm_loss, 6.619738578796387, 2694
[INFO] 2021-07-12 19:26:56,248 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6929999876301736e-05, 2694
[INFO] 2021-07-12 19:26:56,248 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2694
[INFO] 2021-07-12 19:26:56,248 [run_pretraining.py:  558]:	worker_index: 2, step: 2694, cost: 6.619739, mlm loss: 6.619739, speed: 0.914046 steps/s, speed: 7.312367 samples/s, speed: 3743.931686 tokens/s, learning rate: 2.693e-05, loss_scalings: 2814.750488, pp_loss: 6.918422
[INFO] 2021-07-12 19:26:56,248 [run_pretraining.py:  512]:	********exe.run_2694******* 
[INFO] 2021-07-12 19:26:57,343 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:57,344 [run_pretraining.py:  534]:	loss/total_loss, 7.33999490737915, 2695
[INFO] 2021-07-12 19:26:57,344 [run_pretraining.py:  535]:	loss/mlm_loss, 7.33999490737915, 2695
[INFO] 2021-07-12 19:26:57,344 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6939998861053027e-05, 2695
[INFO] 2021-07-12 19:26:57,344 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2695
[INFO] 2021-07-12 19:26:57,344 [run_pretraining.py:  558]:	worker_index: 2, step: 2695, cost: 7.339995, mlm loss: 7.339995, speed: 0.912473 steps/s, speed: 7.299782 samples/s, speed: 3737.488224 tokens/s, learning rate: 2.694e-05, loss_scalings: 2814.750488, pp_loss: 7.425773
[INFO] 2021-07-12 19:26:57,344 [run_pretraining.py:  512]:	********exe.run_2695******* 
[INFO] 2021-07-12 19:26:58,440 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:58,441 [run_pretraining.py:  534]:	loss/total_loss, 6.9603729248046875, 2696
[INFO] 2021-07-12 19:26:58,441 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9603729248046875, 2696
[INFO] 2021-07-12 19:26:58,441 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.694999784580432e-05, 2696
[INFO] 2021-07-12 19:26:58,441 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2696
[INFO] 2021-07-12 19:26:58,441 [run_pretraining.py:  558]:	worker_index: 2, step: 2696, cost: 6.960373, mlm loss: 6.960373, speed: 0.912342 steps/s, speed: 7.298732 samples/s, speed: 3736.950848 tokens/s, learning rate: 2.695e-05, loss_scalings: 2814.750488, pp_loss: 7.486670
[INFO] 2021-07-12 19:26:58,441 [run_pretraining.py:  512]:	********exe.run_2696******* 
[INFO] 2021-07-12 19:26:59,527 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:59,528 [run_pretraining.py:  534]:	loss/total_loss, 6.4142255783081055, 2697
[INFO] 2021-07-12 19:26:59,528 [run_pretraining.py:  535]:	loss/mlm_loss, 6.4142255783081055, 2697
[INFO] 2021-07-12 19:26:59,528 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6960000468534417e-05, 2697
[INFO] 2021-07-12 19:26:59,528 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2697
[INFO] 2021-07-12 19:26:59,528 [run_pretraining.py:  558]:	worker_index: 2, step: 2697, cost: 6.414226, mlm loss: 6.414226, speed: 0.920570 steps/s, speed: 7.364559 samples/s, speed: 3770.654076 tokens/s, learning rate: 2.696e-05, loss_scalings: 2814.750488, pp_loss: 7.139718
[INFO] 2021-07-12 19:26:59,528 [run_pretraining.py:  512]:	********exe.run_2697******* 
[INFO] 2021-07-12 19:27:00,621 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:00,621 [run_pretraining.py:  534]:	loss/total_loss, 8.064610481262207, 2698
[INFO] 2021-07-12 19:27:00,622 [run_pretraining.py:  535]:	loss/mlm_loss, 8.064610481262207, 2698
[INFO] 2021-07-12 19:27:00,622 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6969997634296305e-05, 2698
[INFO] 2021-07-12 19:27:00,622 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2698
[INFO] 2021-07-12 19:27:00,622 [run_pretraining.py:  558]:	worker_index: 2, step: 2698, cost: 8.064610, mlm loss: 8.064610, speed: 0.914640 steps/s, speed: 7.317122 samples/s, speed: 3746.366277 tokens/s, learning rate: 2.697e-05, loss_scalings: 2814.750488, pp_loss: 7.429597
[INFO] 2021-07-12 19:27:00,622 [run_pretraining.py:  512]:	********exe.run_2698******* 
[INFO] 2021-07-12 19:27:01,714 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:01,714 [run_pretraining.py:  534]:	loss/total_loss, 6.929324150085449, 2699
[INFO] 2021-07-12 19:27:01,714 [run_pretraining.py:  535]:	loss/mlm_loss, 6.929324150085449, 2699
[INFO] 2021-07-12 19:27:01,715 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6980000257026404e-05, 2699
[INFO] 2021-07-12 19:27:01,715 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2699
[INFO] 2021-07-12 19:27:01,715 [run_pretraining.py:  558]:	worker_index: 2, step: 2699, cost: 6.929324, mlm loss: 6.929324, speed: 0.915504 steps/s, speed: 7.324034 samples/s, speed: 3749.905419 tokens/s, learning rate: 2.698e-05, loss_scalings: 2814.750488, pp_loss: 7.296000
[INFO] 2021-07-12 19:27:01,715 [run_pretraining.py:  512]:	********exe.run_2699******* 
[INFO] 2021-07-12 19:27:02,822 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:02,823 [run_pretraining.py:  534]:	loss/total_loss, 7.428593158721924, 2700
[INFO] 2021-07-12 19:27:02,823 [run_pretraining.py:  535]:	loss/mlm_loss, 7.428593158721924, 2700
[INFO] 2021-07-12 19:27:02,823 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6989999241777696e-05, 2700
[INFO] 2021-07-12 19:27:02,823 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2700
[INFO] 2021-07-12 19:27:02,823 [run_pretraining.py:  558]:	worker_index: 2, step: 2700, cost: 7.428593, mlm loss: 7.428593, speed: 0.902514 steps/s, speed: 7.220114 samples/s, speed: 3696.698269 tokens/s, learning rate: 2.699e-05, loss_scalings: 2814.750488, pp_loss: 7.367325
[INFO] 2021-07-12 19:27:02,823 [run_pretraining.py:  512]:	********exe.run_2700******* 
[INFO] 2021-07-12 19:27:03,924 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:03,924 [run_pretraining.py:  534]:	loss/total_loss, 7.223389625549316, 2701
[INFO] 2021-07-12 19:27:03,924 [run_pretraining.py:  535]:	loss/mlm_loss, 7.223389625549316, 2701
[INFO] 2021-07-12 19:27:03,924 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.700000004551839e-05, 2701
[INFO] 2021-07-12 19:27:03,924 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2701
[INFO] 2021-07-12 19:27:03,924 [run_pretraining.py:  558]:	worker_index: 2, step: 2701, cost: 7.223390, mlm loss: 7.223390, speed: 0.908618 steps/s, speed: 7.268944 samples/s, speed: 3721.699097 tokens/s, learning rate: 2.700e-05, loss_scalings: 2814.750488, pp_loss: 7.119966
[INFO] 2021-07-12 19:27:03,925 [run_pretraining.py:  512]:	********exe.run_2701******* 
[INFO] 2021-07-12 19:27:05,020 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:05,021 [run_pretraining.py:  534]:	loss/total_loss, 7.165712833404541, 2702
[INFO] 2021-07-12 19:27:05,021 [run_pretraining.py:  535]:	loss/mlm_loss, 7.165712833404541, 2702
[INFO] 2021-07-12 19:27:05,021 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7009999030269682e-05, 2702
[INFO] 2021-07-12 19:27:05,021 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2702
[INFO] 2021-07-12 19:27:05,021 [run_pretraining.py:  558]:	worker_index: 2, step: 2702, cost: 7.165713, mlm loss: 7.165713, speed: 0.912282 steps/s, speed: 7.298257 samples/s, speed: 3736.707819 tokens/s, learning rate: 2.701e-05, loss_scalings: 2814.750488, pp_loss: 6.723043
[INFO] 2021-07-12 19:27:05,021 [run_pretraining.py:  512]:	********exe.run_2702******* 
[INFO] 2021-07-12 19:27:06,120 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:06,120 [run_pretraining.py:  534]:	loss/total_loss, 7.85331916809082, 2703
[INFO] 2021-07-12 19:27:06,120 [run_pretraining.py:  535]:	loss/mlm_loss, 7.85331916809082, 2703
[INFO] 2021-07-12 19:27:06,121 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7019999834010378e-05, 2703
[INFO] 2021-07-12 19:27:06,121 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2703
[INFO] 2021-07-12 19:27:06,121 [run_pretraining.py:  558]:	worker_index: 2, step: 2703, cost: 7.853319, mlm loss: 7.853319, speed: 0.909983 steps/s, speed: 7.279866 samples/s, speed: 3727.291485 tokens/s, learning rate: 2.702e-05, loss_scalings: 2814.750488, pp_loss: 7.046455
[INFO] 2021-07-12 19:27:06,121 [run_pretraining.py:  512]:	********exe.run_2703******* 
[INFO] 2021-07-12 19:27:07,221 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:07,222 [run_pretraining.py:  534]:	loss/total_loss, 8.745135307312012, 2704
[INFO] 2021-07-12 19:27:07,222 [run_pretraining.py:  535]:	loss/mlm_loss, 8.745135307312012, 2704
[INFO] 2021-07-12 19:27:07,222 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.702999881876167e-05, 2704
[INFO] 2021-07-12 19:27:07,222 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2704
[INFO] 2021-07-12 19:27:07,222 [run_pretraining.py:  558]:	worker_index: 2, step: 2704, cost: 8.745135, mlm loss: 8.745135, speed: 0.908321 steps/s, speed: 7.266568 samples/s, speed: 3720.482883 tokens/s, learning rate: 2.703e-05, loss_scalings: 2814.750488, pp_loss: 7.529714
[INFO] 2021-07-12 19:27:07,222 [run_pretraining.py:  512]:	********exe.run_2704******* 
[INFO] 2021-07-12 19:27:08,317 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:08,318 [run_pretraining.py:  534]:	loss/total_loss, 7.537792205810547, 2705
[INFO] 2021-07-12 19:27:08,318 [run_pretraining.py:  535]:	loss/mlm_loss, 7.537792205810547, 2705
[INFO] 2021-07-12 19:27:08,318 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.703999780351296e-05, 2705
[INFO] 2021-07-12 19:27:08,318 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2705
[INFO] 2021-07-12 19:27:08,318 [run_pretraining.py:  558]:	worker_index: 2, step: 2705, cost: 7.537792, mlm loss: 7.537792, speed: 0.912934 steps/s, speed: 7.303476 samples/s, speed: 3739.379620 tokens/s, learning rate: 2.704e-05, loss_scalings: 2814.750488, pp_loss: 7.181347
[INFO] 2021-07-12 19:27:08,318 [run_pretraining.py:  512]:	********exe.run_2705******* 
[INFO] 2021-07-12 19:27:09,422 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:09,422 [run_pretraining.py:  534]:	loss/total_loss, 7.133524417877197, 2706
[INFO] 2021-07-12 19:27:09,423 [run_pretraining.py:  535]:	loss/mlm_loss, 7.133524417877197, 2706
[INFO] 2021-07-12 19:27:09,423 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.705000042624306e-05, 2706
[INFO] 2021-07-12 19:27:09,423 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2706
[INFO] 2021-07-12 19:27:09,423 [run_pretraining.py:  558]:	worker_index: 2, step: 2706, cost: 7.133524, mlm loss: 7.133524, speed: 0.905847 steps/s, speed: 7.246774 samples/s, speed: 3710.348146 tokens/s, learning rate: 2.705e-05, loss_scalings: 2814.750488, pp_loss: 7.183367
[INFO] 2021-07-12 19:27:09,423 [run_pretraining.py:  512]:	********exe.run_2706******* 
[INFO] 2021-07-12 19:27:10,519 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:10,519 [run_pretraining.py:  534]:	loss/total_loss, 7.504279613494873, 2707
[INFO] 2021-07-12 19:27:10,519 [run_pretraining.py:  535]:	loss/mlm_loss, 7.504279613494873, 2707
[INFO] 2021-07-12 19:27:10,519 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7059997592004947e-05, 2707
[INFO] 2021-07-12 19:27:10,520 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2707
[INFO] 2021-07-12 19:27:10,520 [run_pretraining.py:  558]:	worker_index: 2, step: 2707, cost: 7.504280, mlm loss: 7.504280, speed: 0.912244 steps/s, speed: 7.297950 samples/s, speed: 3736.550151 tokens/s, learning rate: 2.706e-05, loss_scalings: 2814.750488, pp_loss: 7.224686
[INFO] 2021-07-12 19:27:10,520 [run_pretraining.py:  512]:	********exe.run_2707******* 
[INFO] 2021-07-12 19:27:11,610 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:11,611 [run_pretraining.py:  534]:	loss/total_loss, 7.293578147888184, 2708
[INFO] 2021-07-12 19:27:11,611 [run_pretraining.py:  535]:	loss/mlm_loss, 7.293578147888184, 2708
[INFO] 2021-07-12 19:27:11,611 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7070000214735046e-05, 2708
[INFO] 2021-07-12 19:27:11,611 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2708
[INFO] 2021-07-12 19:27:11,611 [run_pretraining.py:  558]:	worker_index: 2, step: 2708, cost: 7.293578, mlm loss: 7.293578, speed: 0.916681 steps/s, speed: 7.333448 samples/s, speed: 3754.725227 tokens/s, learning rate: 2.707e-05, loss_scalings: 2814.750488, pp_loss: 5.927053
[INFO] 2021-07-12 19:27:11,611 [run_pretraining.py:  512]:	********exe.run_2708******* 
[INFO] 2021-07-12 19:27:12,701 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:12,701 [run_pretraining.py:  534]:	loss/total_loss, 7.031242370605469, 2709
[INFO] 2021-07-12 19:27:12,701 [run_pretraining.py:  535]:	loss/mlm_loss, 7.031242370605469, 2709
[INFO] 2021-07-12 19:27:12,702 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7079999199486338e-05, 2709
[INFO] 2021-07-12 19:27:12,702 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2709
[INFO] 2021-07-12 19:27:12,702 [run_pretraining.py:  558]:	worker_index: 2, step: 2709, cost: 7.031242, mlm loss: 7.031242, speed: 0.917410 steps/s, speed: 7.339277 samples/s, speed: 3757.709692 tokens/s, learning rate: 2.708e-05, loss_scalings: 2814.750488, pp_loss: 7.434437
[INFO] 2021-07-12 19:27:12,702 [run_pretraining.py:  512]:	********exe.run_2709******* 
[INFO] 2021-07-12 19:27:13,804 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:13,804 [run_pretraining.py:  534]:	loss/total_loss, 5.630984783172607, 2710
[INFO] 2021-07-12 19:27:13,804 [run_pretraining.py:  535]:	loss/mlm_loss, 5.630984783172607, 2710
[INFO] 2021-07-12 19:27:13,804 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7090000003227033e-05, 2710
[INFO] 2021-07-12 19:27:13,804 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2710
[INFO] 2021-07-12 19:27:13,804 [run_pretraining.py:  558]:	worker_index: 2, step: 2710, cost: 5.630985, mlm loss: 5.630985, speed: 0.907373 steps/s, speed: 7.258980 samples/s, speed: 3716.597782 tokens/s, learning rate: 2.709e-05, loss_scalings: 2814.750488, pp_loss: 6.698476
[INFO] 2021-07-12 19:27:13,804 [run_pretraining.py:  512]:	********exe.run_2710******* 
[INFO] 2021-07-12 19:27:14,768 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:14,769 [run_pretraining.py:  534]:	loss/total_loss, 7.934376239776611, 2711
[INFO] 2021-07-12 19:27:14,769 [run_pretraining.py:  535]:	loss/mlm_loss, 7.934376239776611, 2711
[INFO] 2021-07-12 19:27:14,769 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7099998987978324e-05, 2711
[INFO] 2021-07-12 19:27:14,769 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2711
[INFO] 2021-07-12 19:27:14,769 [run_pretraining.py:  558]:	worker_index: 2, step: 2711, cost: 7.934376, mlm loss: 7.934376, speed: 1.036972 steps/s, speed: 8.295778 samples/s, speed: 4247.438460 tokens/s, learning rate: 2.710e-05, loss_scalings: 2814.750488, pp_loss: 7.426874
[INFO] 2021-07-12 19:27:14,769 [run_pretraining.py:  512]:	********exe.run_2711******* 
[INFO] 2021-07-12 19:27:15,695 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:15,696 [run_pretraining.py:  534]:	loss/total_loss, 7.97857141494751, 2712
[INFO] 2021-07-12 19:27:15,696 [run_pretraining.py:  535]:	loss/mlm_loss, 7.97857141494751, 2712
[INFO] 2021-07-12 19:27:15,696 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7110001610708423e-05, 2712
[INFO] 2021-07-12 19:27:15,696 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2712
[INFO] 2021-07-12 19:27:15,696 [run_pretraining.py:  558]:	worker_index: 2, step: 2712, cost: 7.978571, mlm loss: 7.978571, speed: 1.079600 steps/s, speed: 8.636802 samples/s, speed: 4422.042424 tokens/s, learning rate: 2.711e-05, loss_scalings: 2814.750488, pp_loss: 7.423639
[INFO] 2021-07-12 19:27:15,696 [run_pretraining.py:  512]:	********exe.run_2712******* 
[INFO] 2021-07-12 19:27:16,616 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:16,616 [run_pretraining.py:  534]:	loss/total_loss, 7.427396774291992, 2713
[INFO] 2021-07-12 19:27:16,616 [run_pretraining.py:  535]:	loss/mlm_loss, 7.427396774291992, 2713
[INFO] 2021-07-12 19:27:16,616 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.711999877647031e-05, 2713
[INFO] 2021-07-12 19:27:16,616 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2713
[INFO] 2021-07-12 19:27:16,616 [run_pretraining.py:  558]:	worker_index: 2, step: 2713, cost: 7.427397, mlm loss: 7.427397, speed: 1.087419 steps/s, speed: 8.699353 samples/s, speed: 4454.068863 tokens/s, learning rate: 2.712e-05, loss_scalings: 2814.750488, pp_loss: 7.300456
[INFO] 2021-07-12 19:27:16,617 [run_pretraining.py:  512]:	********exe.run_2713******* 
[INFO] 2021-07-12 19:27:17,536 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:17,536 [run_pretraining.py:  534]:	loss/total_loss, 6.784274101257324, 2714
[INFO] 2021-07-12 19:27:17,536 [run_pretraining.py:  535]:	loss/mlm_loss, 6.784274101257324, 2714
[INFO] 2021-07-12 19:27:17,536 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7129997761221603e-05, 2714
[INFO] 2021-07-12 19:27:17,536 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2714
[INFO] 2021-07-12 19:27:17,536 [run_pretraining.py:  558]:	worker_index: 2, step: 2714, cost: 6.784274, mlm loss: 6.784274, speed: 1.087760 steps/s, speed: 8.702079 samples/s, speed: 4455.464257 tokens/s, learning rate: 2.713e-05, loss_scalings: 2814.750488, pp_loss: 7.150459
[INFO] 2021-07-12 19:27:17,536 [run_pretraining.py:  512]:	********exe.run_2714******* 
[INFO] 2021-07-12 19:27:18,450 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:18,450 [run_pretraining.py:  534]:	loss/total_loss, 7.336612224578857, 2715
[INFO] 2021-07-12 19:27:18,450 [run_pretraining.py:  535]:	loss/mlm_loss, 7.336612224578857, 2715
[INFO] 2021-07-12 19:27:18,450 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.71400003839517e-05, 2715
[INFO] 2021-07-12 19:27:18,450 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2715
[INFO] 2021-07-12 19:27:18,450 [run_pretraining.py:  558]:	worker_index: 2, step: 2715, cost: 7.336612, mlm loss: 7.336612, speed: 1.094701 steps/s, speed: 8.757610 samples/s, speed: 4483.896265 tokens/s, learning rate: 2.714e-05, loss_scalings: 2814.750488, pp_loss: 7.478989
[INFO] 2021-07-12 19:27:18,451 [run_pretraining.py:  512]:	********exe.run_2715******* 
[INFO] 2021-07-12 19:27:19,373 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:19,373 [run_pretraining.py:  534]:	loss/total_loss, 6.538284778594971, 2716
[INFO] 2021-07-12 19:27:19,373 [run_pretraining.py:  535]:	loss/mlm_loss, 6.538284778594971, 2716
[INFO] 2021-07-12 19:27:19,374 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.714999754971359e-05, 2716
[INFO] 2021-07-12 19:27:19,374 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2716
[INFO] 2021-07-12 19:27:19,374 [run_pretraining.py:  558]:	worker_index: 2, step: 2716, cost: 6.538285, mlm loss: 6.538285, speed: 1.083787 steps/s, speed: 8.670297 samples/s, speed: 4439.192212 tokens/s, learning rate: 2.715e-05, loss_scalings: 2814.750488, pp_loss: 6.950648
[INFO] 2021-07-12 19:27:19,374 [run_pretraining.py:  512]:	********exe.run_2716******* 
[INFO] 2021-07-12 19:27:20,294 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:20,295 [run_pretraining.py:  534]:	loss/total_loss, 7.480230331420898, 2717
[INFO] 2021-07-12 19:27:20,295 [run_pretraining.py:  535]:	loss/mlm_loss, 7.480230331420898, 2717
[INFO] 2021-07-12 19:27:20,295 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7160000172443688e-05, 2717
[INFO] 2021-07-12 19:27:20,295 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2717
[INFO] 2021-07-12 19:27:20,295 [run_pretraining.py:  558]:	worker_index: 2, step: 2717, cost: 7.480230, mlm loss: 7.480230, speed: 1.086112 steps/s, speed: 8.688894 samples/s, speed: 4448.713730 tokens/s, learning rate: 2.716e-05, loss_scalings: 2814.750488, pp_loss: 7.505485
[INFO] 2021-07-12 19:27:20,295 [run_pretraining.py:  512]:	********exe.run_2717******* 
[INFO] 2021-07-12 19:27:21,240 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:21,240 [run_pretraining.py:  534]:	loss/total_loss, 7.574961185455322, 2718
[INFO] 2021-07-12 19:27:21,240 [run_pretraining.py:  535]:	loss/mlm_loss, 7.574961185455322, 2718
[INFO] 2021-07-12 19:27:21,240 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.716999915719498e-05, 2718
[INFO] 2021-07-12 19:27:21,240 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2718
[INFO] 2021-07-12 19:27:21,240 [run_pretraining.py:  558]:	worker_index: 2, step: 2718, cost: 7.574961, mlm loss: 7.574961, speed: 1.058492 steps/s, speed: 8.467933 samples/s, speed: 4335.581944 tokens/s, learning rate: 2.717e-05, loss_scalings: 2814.750488, pp_loss: 7.549147
[INFO] 2021-07-12 19:27:21,240 [run_pretraining.py:  512]:	********exe.run_2718******* 
[INFO] 2021-07-12 19:27:22,160 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:22,161 [run_pretraining.py:  534]:	loss/total_loss, 6.369078159332275, 2719
[INFO] 2021-07-12 19:27:22,161 [run_pretraining.py:  535]:	loss/mlm_loss, 6.369078159332275, 2719
[INFO] 2021-07-12 19:27:22,161 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7179999960935675e-05, 2719
[INFO] 2021-07-12 19:27:22,161 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2719
[INFO] 2021-07-12 19:27:22,161 [run_pretraining.py:  558]:	worker_index: 2, step: 2719, cost: 6.369078, mlm loss: 6.369078, speed: 1.086733 steps/s, speed: 8.693865 samples/s, speed: 4451.258782 tokens/s, learning rate: 2.718e-05, loss_scalings: 2814.750488, pp_loss: 7.071878
[INFO] 2021-07-12 19:27:22,161 [run_pretraining.py:  512]:	********exe.run_2719******* 
[INFO] 2021-07-12 19:27:23,087 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:23,088 [run_pretraining.py:  534]:	loss/total_loss, 4.21907901763916, 2720
[INFO] 2021-07-12 19:27:23,088 [run_pretraining.py:  535]:	loss/mlm_loss, 4.21907901763916, 2720
[INFO] 2021-07-12 19:27:23,088 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7189998945686966e-05, 2720
[INFO] 2021-07-12 19:27:23,088 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2720
[INFO] 2021-07-12 19:27:23,088 [run_pretraining.py:  558]:	worker_index: 2, step: 2720, cost: 4.219079, mlm loss: 4.219079, speed: 1.079711 steps/s, speed: 8.637684 samples/s, speed: 4422.494343 tokens/s, learning rate: 2.719e-05, loss_scalings: 2814.750488, pp_loss: 6.989339
[INFO] 2021-07-12 19:27:23,088 [run_pretraining.py:  512]:	********exe.run_2720******* 
[INFO] 2021-07-12 19:27:24,009 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:24,010 [run_pretraining.py:  534]:	loss/total_loss, 6.791141510009766, 2721
[INFO] 2021-07-12 19:27:24,010 [run_pretraining.py:  535]:	loss/mlm_loss, 6.791141510009766, 2721
[INFO] 2021-07-12 19:27:24,010 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7200001568417065e-05, 2721
[INFO] 2021-07-12 19:27:24,010 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2721
[INFO] 2021-07-12 19:27:24,010 [run_pretraining.py:  558]:	worker_index: 2, step: 2721, cost: 6.791142, mlm loss: 6.791142, speed: 1.085063 steps/s, speed: 8.680503 samples/s, speed: 4444.417501 tokens/s, learning rate: 2.720e-05, loss_scalings: 2814.750488, pp_loss: 7.506146
[INFO] 2021-07-12 19:27:24,010 [run_pretraining.py:  512]:	********exe.run_2721******* 
[INFO] 2021-07-12 19:27:24,932 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:24,933 [run_pretraining.py:  534]:	loss/total_loss, 6.884576797485352, 2722
[INFO] 2021-07-12 19:27:24,933 [run_pretraining.py:  535]:	loss/mlm_loss, 6.884576797485352, 2722
[INFO] 2021-07-12 19:27:24,933 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7209998734178953e-05, 2722
[INFO] 2021-07-12 19:27:24,933 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2722
[INFO] 2021-07-12 19:27:24,933 [run_pretraining.py:  558]:	worker_index: 2, step: 2722, cost: 6.884577, mlm loss: 6.884577, speed: 1.083909 steps/s, speed: 8.671270 samples/s, speed: 4439.690094 tokens/s, learning rate: 2.721e-05, loss_scalings: 2814.750488, pp_loss: 6.970256
[INFO] 2021-07-12 19:27:24,933 [run_pretraining.py:  512]:	********exe.run_2722******* 
[INFO] 2021-07-12 19:27:25,863 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:25,863 [run_pretraining.py:  534]:	loss/total_loss, 7.392756462097168, 2723
[INFO] 2021-07-12 19:27:25,864 [run_pretraining.py:  535]:	loss/mlm_loss, 7.392756462097168, 2723
[INFO] 2021-07-12 19:27:25,864 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7219997718930244e-05, 2723
[INFO] 2021-07-12 19:27:25,864 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2723
[INFO] 2021-07-12 19:27:25,864 [run_pretraining.py:  558]:	worker_index: 2, step: 2723, cost: 7.392756, mlm loss: 7.392756, speed: 1.075422 steps/s, speed: 8.603378 samples/s, speed: 4404.929760 tokens/s, learning rate: 2.722e-05, loss_scalings: 2814.750488, pp_loss: 7.326289
[INFO] 2021-07-12 19:27:25,864 [run_pretraining.py:  512]:	********exe.run_2723******* 
[INFO] 2021-07-12 19:27:26,790 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:26,790 [run_pretraining.py:  534]:	loss/total_loss, 7.031156539916992, 2724
[INFO] 2021-07-12 19:27:26,790 [run_pretraining.py:  535]:	loss/mlm_loss, 7.031156539916992, 2724
[INFO] 2021-07-12 19:27:26,790 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7230000341660343e-05, 2724
[INFO] 2021-07-12 19:27:26,790 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2724
[INFO] 2021-07-12 19:27:26,790 [run_pretraining.py:  558]:	worker_index: 2, step: 2724, cost: 7.031157, mlm loss: 7.031157, speed: 1.079931 steps/s, speed: 8.639448 samples/s, speed: 4423.397320 tokens/s, learning rate: 2.723e-05, loss_scalings: 2814.750488, pp_loss: 6.808574
[INFO] 2021-07-12 19:27:26,790 [run_pretraining.py:  512]:	********exe.run_2724******* 
[INFO] 2021-07-12 19:27:27,713 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:27,713 [run_pretraining.py:  534]:	loss/total_loss, 7.709055423736572, 2725
[INFO] 2021-07-12 19:27:27,713 [run_pretraining.py:  535]:	loss/mlm_loss, 7.709055423736572, 2725
[INFO] 2021-07-12 19:27:27,713 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7239999326411635e-05, 2725
[INFO] 2021-07-12 19:27:27,713 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2725
[INFO] 2021-07-12 19:27:27,714 [run_pretraining.py:  558]:	worker_index: 2, step: 2725, cost: 7.709055, mlm loss: 7.709055, speed: 1.083966 steps/s, speed: 8.671725 samples/s, speed: 4439.923012 tokens/s, learning rate: 2.724e-05, loss_scalings: 2814.750488, pp_loss: 7.631410
[INFO] 2021-07-12 19:27:27,714 [run_pretraining.py:  512]:	********exe.run_2725******* 
[INFO] 2021-07-12 19:27:28,651 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:28,651 [run_pretraining.py:  534]:	loss/total_loss, 7.811300277709961, 2726
[INFO] 2021-07-12 19:27:28,651 [run_pretraining.py:  535]:	loss/mlm_loss, 7.811300277709961, 2726
[INFO] 2021-07-12 19:27:28,651 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.725000013015233e-05, 2726
[INFO] 2021-07-12 19:27:28,651 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2726
[INFO] 2021-07-12 19:27:28,651 [run_pretraining.py:  558]:	worker_index: 2, step: 2726, cost: 7.811300, mlm loss: 7.811300, speed: 1.066937 steps/s, speed: 8.535498 samples/s, speed: 4370.174725 tokens/s, learning rate: 2.725e-05, loss_scalings: 2814.750488, pp_loss: 7.533235
[INFO] 2021-07-12 19:27:28,651 [run_pretraining.py:  512]:	********exe.run_2726******* 
[INFO] 2021-07-12 19:27:29,580 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:29,580 [run_pretraining.py:  534]:	loss/total_loss, 6.935794830322266, 2727
[INFO] 2021-07-12 19:27:29,580 [run_pretraining.py:  535]:	loss/mlm_loss, 6.935794830322266, 2727
[INFO] 2021-07-12 19:27:29,580 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.725999911490362e-05, 2727
[INFO] 2021-07-12 19:27:29,580 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2727
[INFO] 2021-07-12 19:27:29,581 [run_pretraining.py:  558]:	worker_index: 2, step: 2727, cost: 6.935795, mlm loss: 6.935795, speed: 1.076928 steps/s, speed: 8.615426 samples/s, speed: 4411.098280 tokens/s, learning rate: 2.726e-05, loss_scalings: 2814.750488, pp_loss: 7.099352
[INFO] 2021-07-12 19:27:29,581 [run_pretraining.py:  512]:	********exe.run_2727******* 
[INFO] 2021-07-12 19:27:30,512 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:30,512 [run_pretraining.py:  534]:	loss/total_loss, 7.340592384338379, 2728
[INFO] 2021-07-12 19:27:30,513 [run_pretraining.py:  535]:	loss/mlm_loss, 7.340592384338379, 2728
[INFO] 2021-07-12 19:27:30,513 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7269999918644316e-05, 2728
[INFO] 2021-07-12 19:27:30,513 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2728
[INFO] 2021-07-12 19:27:30,513 [run_pretraining.py:  558]:	worker_index: 2, step: 2728, cost: 7.340592, mlm loss: 7.340592, speed: 1.073291 steps/s, speed: 8.586328 samples/s, speed: 4396.199685 tokens/s, learning rate: 2.727e-05, loss_scalings: 2814.750488, pp_loss: 7.410835
[INFO] 2021-07-12 19:27:30,513 [run_pretraining.py:  512]:	********exe.run_2728******* 
[INFO] 2021-07-12 19:27:31,442 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:31,443 [run_pretraining.py:  534]:	loss/total_loss, 7.473367214202881, 2729
[INFO] 2021-07-12 19:27:31,443 [run_pretraining.py:  535]:	loss/mlm_loss, 7.473367214202881, 2729
[INFO] 2021-07-12 19:27:31,443 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7279998903395608e-05, 2729
[INFO] 2021-07-12 19:27:31,443 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2729
[INFO] 2021-07-12 19:27:31,443 [run_pretraining.py:  558]:	worker_index: 2, step: 2729, cost: 7.473367, mlm loss: 7.473367, speed: 1.075662 steps/s, speed: 8.605298 samples/s, speed: 4405.912581 tokens/s, learning rate: 2.728e-05, loss_scalings: 2814.750488, pp_loss: 6.903811
[INFO] 2021-07-12 19:27:31,443 [run_pretraining.py:  512]:	********exe.run_2729******* 
[INFO] 2021-07-12 19:27:32,380 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:32,380 [run_pretraining.py:  534]:	loss/total_loss, 6.860339641571045, 2730
[INFO] 2021-07-12 19:27:32,380 [run_pretraining.py:  535]:	loss/mlm_loss, 6.860339641571045, 2730
[INFO] 2021-07-12 19:27:32,380 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.72899978881469e-05, 2730
[INFO] 2021-07-12 19:27:32,381 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2730
[INFO] 2021-07-12 19:27:32,381 [run_pretraining.py:  558]:	worker_index: 2, step: 2730, cost: 6.860340, mlm loss: 6.860340, speed: 1.067300 steps/s, speed: 8.538404 samples/s, speed: 4371.662653 tokens/s, learning rate: 2.729e-05, loss_scalings: 2814.750488, pp_loss: 6.531707
[INFO] 2021-07-12 19:27:32,381 [run_pretraining.py:  512]:	********exe.run_2730******* 
[INFO] 2021-07-12 19:27:33,318 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:33,319 [run_pretraining.py:  534]:	loss/total_loss, 7.098481178283691, 2731
[INFO] 2021-07-12 19:27:33,319 [run_pretraining.py:  535]:	loss/mlm_loss, 7.098481178283691, 2731
[INFO] 2021-07-12 19:27:33,319 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7299998691887595e-05, 2731
[INFO] 2021-07-12 19:27:33,319 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2731
[INFO] 2021-07-12 19:27:33,319 [run_pretraining.py:  558]:	worker_index: 2, step: 2731, cost: 7.098481, mlm loss: 7.098481, speed: 1.065997 steps/s, speed: 8.527976 samples/s, speed: 4366.323945 tokens/s, learning rate: 2.730e-05, loss_scalings: 2814.750488, pp_loss: 7.272186
[INFO] 2021-07-12 19:27:33,319 [run_pretraining.py:  512]:	********exe.run_2731******* 
[INFO] 2021-07-12 19:27:34,264 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:34,264 [run_pretraining.py:  534]:	loss/total_loss, 7.435506820678711, 2732
[INFO] 2021-07-12 19:27:34,264 [run_pretraining.py:  535]:	loss/mlm_loss, 7.435506820678711, 2732
[INFO] 2021-07-12 19:27:34,264 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7309997676638886e-05, 2732
[INFO] 2021-07-12 19:27:34,265 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2732
[INFO] 2021-07-12 19:27:34,265 [run_pretraining.py:  558]:	worker_index: 2, step: 2732, cost: 7.435507, mlm loss: 7.435507, speed: 1.058564 steps/s, speed: 8.468511 samples/s, speed: 4335.877383 tokens/s, learning rate: 2.731e-05, loss_scalings: 2814.750488, pp_loss: 7.575646
[INFO] 2021-07-12 19:27:34,265 [run_pretraining.py:  512]:	********exe.run_2732******* 
[INFO] 2021-07-12 19:27:35,218 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:35,221 [run_pretraining.py:  534]:	loss/total_loss, 7.084964275360107, 2733
[INFO] 2021-07-12 19:27:35,222 [run_pretraining.py:  535]:	loss/mlm_loss, 7.084964275360107, 2733
[INFO] 2021-07-12 19:27:35,223 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7320000299368985e-05, 2733
[INFO] 2021-07-12 19:27:35,224 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2733
[INFO] 2021-07-12 19:27:35,225 [run_pretraining.py:  558]:	worker_index: 2, step: 2733, cost: 7.084964, mlm loss: 7.084964, speed: 1.045832 steps/s, speed: 8.366654 samples/s, speed: 4283.726797 tokens/s, learning rate: 2.732e-05, loss_scalings: 2814.750488, pp_loss: 7.352735
[INFO] 2021-07-12 19:27:35,227 [run_pretraining.py:  512]:	********exe.run_2733******* 
[INFO] 2021-07-12 19:27:36,133 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:36,133 [run_pretraining.py:  534]:	loss/total_loss, 7.642765998840332, 2734
[INFO] 2021-07-12 19:27:36,133 [run_pretraining.py:  535]:	loss/mlm_loss, 7.642765998840332, 2734
[INFO] 2021-07-12 19:27:36,133 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7329999284120277e-05, 2734
[INFO] 2021-07-12 19:27:36,133 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2734
[INFO] 2021-07-12 19:27:36,133 [run_pretraining.py:  558]:	worker_index: 2, step: 2734, cost: 7.642766, mlm loss: 7.642766, speed: 1.103606 steps/s, speed: 8.828850 samples/s, speed: 4520.371080 tokens/s, learning rate: 2.733e-05, loss_scalings: 2814.750488, pp_loss: 6.735911
[INFO] 2021-07-12 19:27:36,133 [run_pretraining.py:  512]:	********exe.run_2734******* 
[INFO] 2021-07-12 19:27:37,061 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:37,061 [run_pretraining.py:  534]:	loss/total_loss, 6.921413421630859, 2735
[INFO] 2021-07-12 19:27:37,061 [run_pretraining.py:  535]:	loss/mlm_loss, 6.921413421630859, 2735
[INFO] 2021-07-12 19:27:37,061 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.734000008786097e-05, 2735
[INFO] 2021-07-12 19:27:37,061 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2735
[INFO] 2021-07-12 19:27:37,062 [run_pretraining.py:  558]:	worker_index: 2, step: 2735, cost: 6.921413, mlm loss: 6.921413, speed: 1.078083 steps/s, speed: 8.624665 samples/s, speed: 4415.828523 tokens/s, learning rate: 2.734e-05, loss_scalings: 2814.750488, pp_loss: 7.380445
[INFO] 2021-07-12 19:27:37,062 [run_pretraining.py:  512]:	********exe.run_2735******* 
[INFO] 2021-07-12 19:27:37,980 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:37,980 [run_pretraining.py:  534]:	loss/total_loss, 7.263985633850098, 2736
[INFO] 2021-07-12 19:27:37,980 [run_pretraining.py:  535]:	loss/mlm_loss, 7.263985633850098, 2736
[INFO] 2021-07-12 19:27:37,981 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7349999072612263e-05, 2736
[INFO] 2021-07-12 19:27:37,981 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2736
[INFO] 2021-07-12 19:27:37,981 [run_pretraining.py:  558]:	worker_index: 2, step: 2736, cost: 7.263986, mlm loss: 7.263986, speed: 1.088642 steps/s, speed: 8.709135 samples/s, speed: 4459.076934 tokens/s, learning rate: 2.735e-05, loss_scalings: 2814.750488, pp_loss: 7.395534
[INFO] 2021-07-12 19:27:37,981 [run_pretraining.py:  512]:	********exe.run_2736******* 
[INFO] 2021-07-12 19:27:38,903 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:38,904 [run_pretraining.py:  534]:	loss/total_loss, 7.195965766906738, 2737
[INFO] 2021-07-12 19:27:38,904 [run_pretraining.py:  535]:	loss/mlm_loss, 7.195965766906738, 2737
[INFO] 2021-07-12 19:27:38,904 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.735999987635296e-05, 2737
[INFO] 2021-07-12 19:27:38,904 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2737
[INFO] 2021-07-12 19:27:38,904 [run_pretraining.py:  558]:	worker_index: 2, step: 2737, cost: 7.195966, mlm loss: 7.195966, speed: 1.083995 steps/s, speed: 8.671958 samples/s, speed: 4440.042350 tokens/s, learning rate: 2.736e-05, loss_scalings: 2814.750488, pp_loss: 6.917846
[INFO] 2021-07-12 19:27:38,904 [run_pretraining.py:  512]:	********exe.run_2737******* 
[INFO] 2021-07-12 19:27:39,829 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:39,830 [run_pretraining.py:  534]:	loss/total_loss, 4.663461685180664, 2738
[INFO] 2021-07-12 19:27:39,830 [run_pretraining.py:  535]:	loss/mlm_loss, 4.663461685180664, 2738
[INFO] 2021-07-12 19:27:39,830 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.736999886110425e-05, 2738
[INFO] 2021-07-12 19:27:39,830 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2738
[INFO] 2021-07-12 19:27:39,830 [run_pretraining.py:  558]:	worker_index: 2, step: 2738, cost: 4.663462, mlm loss: 4.663462, speed: 1.080478 steps/s, speed: 8.643823 samples/s, speed: 4425.637564 tokens/s, learning rate: 2.737e-05, loss_scalings: 2814.750488, pp_loss: 6.431212
[INFO] 2021-07-12 19:27:39,830 [run_pretraining.py:  512]:	********exe.run_2738******* 
[INFO] 2021-07-12 19:27:40,750 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:40,750 [run_pretraining.py:  534]:	loss/total_loss, 4.062075614929199, 2739
[INFO] 2021-07-12 19:27:40,750 [run_pretraining.py:  535]:	loss/mlm_loss, 4.062075614929199, 2739
[INFO] 2021-07-12 19:27:40,750 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.737999784585554e-05, 2739
[INFO] 2021-07-12 19:27:40,750 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2739
[INFO] 2021-07-12 19:27:40,751 [run_pretraining.py:  558]:	worker_index: 2, step: 2739, cost: 4.062076, mlm loss: 4.062076, speed: 1.087052 steps/s, speed: 8.696420 samples/s, speed: 4452.567019 tokens/s, learning rate: 2.738e-05, loss_scalings: 2814.750488, pp_loss: 6.317875
[INFO] 2021-07-12 19:27:40,751 [run_pretraining.py:  512]:	********exe.run_2739******* 
[INFO] 2021-07-12 19:27:41,673 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:41,673 [run_pretraining.py:  534]:	loss/total_loss, 7.434650421142578, 2740
[INFO] 2021-07-12 19:27:41,673 [run_pretraining.py:  535]:	loss/mlm_loss, 7.434650421142578, 2740
[INFO] 2021-07-12 19:27:41,673 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7389998649596237e-05, 2740
[INFO] 2021-07-12 19:27:41,673 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2740
[INFO] 2021-07-12 19:27:41,673 [run_pretraining.py:  558]:	worker_index: 2, step: 2740, cost: 7.434650, mlm loss: 7.434650, speed: 1.084162 steps/s, speed: 8.673294 samples/s, speed: 4440.726368 tokens/s, learning rate: 2.739e-05, loss_scalings: 2814.750488, pp_loss: 7.174001
[INFO] 2021-07-12 19:27:41,674 [run_pretraining.py:  512]:	********exe.run_2740******* 
[INFO] 2021-07-12 19:27:42,599 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:42,600 [run_pretraining.py:  534]:	loss/total_loss, 7.336697101593018, 2741
[INFO] 2021-07-12 19:27:42,600 [run_pretraining.py:  535]:	loss/mlm_loss, 7.336697101593018, 2741
[INFO] 2021-07-12 19:27:42,600 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7399997634347528e-05, 2741
[INFO] 2021-07-12 19:27:42,600 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2741
[INFO] 2021-07-12 19:27:42,600 [run_pretraining.py:  558]:	worker_index: 2, step: 2741, cost: 7.336697, mlm loss: 7.336697, speed: 1.079894 steps/s, speed: 8.639154 samples/s, speed: 4423.246988 tokens/s, learning rate: 2.740e-05, loss_scalings: 2814.750488, pp_loss: 7.444644
[INFO] 2021-07-12 19:27:42,600 [run_pretraining.py:  512]:	********exe.run_2741******* 
[INFO] 2021-07-12 19:27:43,524 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:43,524 [run_pretraining.py:  534]:	loss/total_loss, 7.256542682647705, 2742
[INFO] 2021-07-12 19:27:43,524 [run_pretraining.py:  535]:	loss/mlm_loss, 7.256542682647705, 2742
[INFO] 2021-07-12 19:27:43,524 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7410000257077627e-05, 2742
[INFO] 2021-07-12 19:27:43,525 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2742
[INFO] 2021-07-12 19:27:43,525 [run_pretraining.py:  558]:	worker_index: 2, step: 2742, cost: 7.256543, mlm loss: 7.256543, speed: 1.082342 steps/s, speed: 8.658732 samples/s, speed: 4433.270941 tokens/s, learning rate: 2.741e-05, loss_scalings: 2814.750488, pp_loss: 6.656063
[INFO] 2021-07-12 19:27:43,525 [run_pretraining.py:  512]:	********exe.run_2742******* 
[INFO] 2021-07-12 19:27:44,452 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:44,452 [run_pretraining.py:  534]:	loss/total_loss, 7.023184776306152, 2743
[INFO] 2021-07-12 19:27:44,452 [run_pretraining.py:  535]:	loss/mlm_loss, 7.023184776306152, 2743
[INFO] 2021-07-12 19:27:44,452 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.741999924182892e-05, 2743
[INFO] 2021-07-12 19:27:44,452 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2743
[INFO] 2021-07-12 19:27:44,452 [run_pretraining.py:  558]:	worker_index: 2, step: 2743, cost: 7.023185, mlm loss: 7.023185, speed: 1.078437 steps/s, speed: 8.627497 samples/s, speed: 4417.278423 tokens/s, learning rate: 2.742e-05, loss_scalings: 2814.750488, pp_loss: 7.287669
[INFO] 2021-07-12 19:27:44,453 [run_pretraining.py:  512]:	********exe.run_2743******* 
[INFO] 2021-07-12 19:27:45,372 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:45,373 [run_pretraining.py:  534]:	loss/total_loss, 7.355983734130859, 2744
[INFO] 2021-07-12 19:27:45,373 [run_pretraining.py:  535]:	loss/mlm_loss, 7.355983734130859, 2744
[INFO] 2021-07-12 19:27:45,373 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7430000045569614e-05, 2744
[INFO] 2021-07-12 19:27:45,373 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2744
[INFO] 2021-07-12 19:27:45,373 [run_pretraining.py:  558]:	worker_index: 2, step: 2744, cost: 7.355984, mlm loss: 7.355984, speed: 1.087026 steps/s, speed: 8.696208 samples/s, speed: 4452.458547 tokens/s, learning rate: 2.743e-05, loss_scalings: 2814.750488, pp_loss: 7.387824
[INFO] 2021-07-12 19:27:45,373 [run_pretraining.py:  512]:	********exe.run_2744******* 
[INFO] 2021-07-12 19:27:46,298 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:46,299 [run_pretraining.py:  534]:	loss/total_loss, 8.702539443969727, 2745
[INFO] 2021-07-12 19:27:46,299 [run_pretraining.py:  535]:	loss/mlm_loss, 8.702539443969727, 2745
[INFO] 2021-07-12 19:27:46,299 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7439999030320905e-05, 2745
[INFO] 2021-07-12 19:27:46,299 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2745
[INFO] 2021-07-12 19:27:46,299 [run_pretraining.py:  558]:	worker_index: 2, step: 2745, cost: 8.702539, mlm loss: 8.702539, speed: 1.080735 steps/s, speed: 8.645884 samples/s, speed: 4426.692381 tokens/s, learning rate: 2.744e-05, loss_scalings: 2814.750488, pp_loss: 7.557970
[INFO] 2021-07-12 19:27:46,299 [run_pretraining.py:  512]:	********exe.run_2745******* 
[INFO] 2021-07-12 19:27:47,217 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:47,218 [run_pretraining.py:  534]:	loss/total_loss, 8.460869789123535, 2746
[INFO] 2021-07-12 19:27:47,218 [run_pretraining.py:  535]:	loss/mlm_loss, 8.460869789123535, 2746
[INFO] 2021-07-12 19:27:47,218 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.74499998340616e-05, 2746
[INFO] 2021-07-12 19:27:47,218 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2746
[INFO] 2021-07-12 19:27:47,218 [run_pretraining.py:  558]:	worker_index: 2, step: 2746, cost: 8.460870, mlm loss: 8.460870, speed: 1.088826 steps/s, speed: 8.710606 samples/s, speed: 4459.830505 tokens/s, learning rate: 2.745e-05, loss_scalings: 2814.750488, pp_loss: 7.757548
[INFO] 2021-07-12 19:27:47,218 [run_pretraining.py:  512]:	********exe.run_2746******* 
[INFO] 2021-07-12 19:27:48,145 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:48,147 [run_pretraining.py:  534]:	loss/total_loss, 7.646451950073242, 2747
[INFO] 2021-07-12 19:27:48,150 [run_pretraining.py:  535]:	loss/mlm_loss, 7.646451950073242, 2747
[INFO] 2021-07-12 19:27:48,152 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7459998818812892e-05, 2747
[INFO] 2021-07-12 19:27:48,156 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2747
[INFO] 2021-07-12 19:27:48,166 [run_pretraining.py:  558]:	worker_index: 2, step: 2747, cost: 7.646452, mlm loss: 7.646452, speed: 1.076897 steps/s, speed: 8.615174 samples/s, speed: 4410.969169 tokens/s, learning rate: 2.746e-05, loss_scalings: 2814.750488, pp_loss: 7.274047
[INFO] 2021-07-12 19:27:48,171 [run_pretraining.py:  512]:	********exe.run_2747******* 
[INFO] 2021-07-12 19:27:49,073 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:49,073 [run_pretraining.py:  534]:	loss/total_loss, 7.434780120849609, 2748
[INFO] 2021-07-12 19:27:49,073 [run_pretraining.py:  535]:	loss/mlm_loss, 7.434780120849609, 2748
[INFO] 2021-07-12 19:27:49,074 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7469997803564183e-05, 2748
[INFO] 2021-07-12 19:27:49,074 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2748
[INFO] 2021-07-12 19:27:49,074 [run_pretraining.py:  558]:	worker_index: 2, step: 2748, cost: 7.434780, mlm loss: 7.434780, speed: 1.108507 steps/s, speed: 8.868053 samples/s, speed: 4540.442938 tokens/s, learning rate: 2.747e-05, loss_scalings: 2814.750488, pp_loss: 7.312469
[INFO] 2021-07-12 19:27:49,074 [run_pretraining.py:  512]:	********exe.run_2748******* 
[INFO] 2021-07-12 19:27:49,990 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:49,990 [run_pretraining.py:  534]:	loss/total_loss, 7.199559688568115, 2749
[INFO] 2021-07-12 19:27:49,990 [run_pretraining.py:  535]:	loss/mlm_loss, 7.199559688568115, 2749
[INFO] 2021-07-12 19:27:49,990 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7480000426294282e-05, 2749
[INFO] 2021-07-12 19:27:49,990 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2749
[INFO] 2021-07-12 19:27:49,990 [run_pretraining.py:  558]:	worker_index: 2, step: 2749, cost: 7.199560, mlm loss: 7.199560, speed: 1.091618 steps/s, speed: 8.732946 samples/s, speed: 4471.268287 tokens/s, learning rate: 2.748e-05, loss_scalings: 2814.750488, pp_loss: 7.404912
[INFO] 2021-07-12 19:27:49,990 [run_pretraining.py:  512]:	********exe.run_2749******* 
[INFO] 2021-07-12 19:27:50,922 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:50,922 [run_pretraining.py:  534]:	loss/total_loss, 7.163144111633301, 2750
[INFO] 2021-07-12 19:27:50,922 [run_pretraining.py:  535]:	loss/mlm_loss, 7.163144111633301, 2750
[INFO] 2021-07-12 19:27:50,922 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.748999759205617e-05, 2750
[INFO] 2021-07-12 19:27:50,922 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2750
[INFO] 2021-07-12 19:27:50,923 [run_pretraining.py:  558]:	worker_index: 2, step: 2750, cost: 7.163144, mlm loss: 7.163144, speed: 1.073438 steps/s, speed: 8.587505 samples/s, speed: 4396.802744 tokens/s, learning rate: 2.749e-05, loss_scalings: 2814.750488, pp_loss: 7.397029
[INFO] 2021-07-12 19:27:50,923 [run_pretraining.py:  512]:	********exe.run_2750******* 
[INFO] 2021-07-12 19:27:51,840 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:51,841 [run_pretraining.py:  534]:	loss/total_loss, 7.309017181396484, 2751
[INFO] 2021-07-12 19:27:51,841 [run_pretraining.py:  535]:	loss/mlm_loss, 7.309017181396484, 2751
[INFO] 2021-07-12 19:27:51,841 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.750000021478627e-05, 2751
[INFO] 2021-07-12 19:27:51,841 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2751
[INFO] 2021-07-12 19:27:51,841 [run_pretraining.py:  558]:	worker_index: 2, step: 2751, cost: 7.309017, mlm loss: 7.309017, speed: 1.089413 steps/s, speed: 8.715306 samples/s, speed: 4462.236461 tokens/s, learning rate: 2.750e-05, loss_scalings: 2814.750488, pp_loss: 6.621852
[INFO] 2021-07-12 19:27:51,841 [run_pretraining.py:  512]:	********exe.run_2751******* 
[INFO] 2021-07-12 19:27:52,761 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:52,761 [run_pretraining.py:  534]:	loss/total_loss, 7.687450885772705, 2752
[INFO] 2021-07-12 19:27:52,762 [run_pretraining.py:  535]:	loss/mlm_loss, 7.687450885772705, 2752
[INFO] 2021-07-12 19:27:52,762 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.750999919953756e-05, 2752
[INFO] 2021-07-12 19:27:52,762 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2752
[INFO] 2021-07-12 19:27:52,762 [run_pretraining.py:  558]:	worker_index: 2, step: 2752, cost: 7.687451, mlm loss: 7.687451, speed: 1.086777 steps/s, speed: 8.694216 samples/s, speed: 4451.438705 tokens/s, learning rate: 2.751e-05, loss_scalings: 2814.750488, pp_loss: 7.214416
[INFO] 2021-07-12 19:27:52,762 [run_pretraining.py:  512]:	********exe.run_2752******* 
[INFO] 2021-07-12 19:27:53,680 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:53,680 [run_pretraining.py:  534]:	loss/total_loss, 7.255611419677734, 2753
[INFO] 2021-07-12 19:27:53,680 [run_pretraining.py:  535]:	loss/mlm_loss, 7.255611419677734, 2753
[INFO] 2021-07-12 19:27:53,680 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7520000003278255e-05, 2753
[INFO] 2021-07-12 19:27:53,681 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2753
[INFO] 2021-07-12 19:27:53,681 [run_pretraining.py:  558]:	worker_index: 2, step: 2753, cost: 7.255611, mlm loss: 7.255611, speed: 1.089087 steps/s, speed: 8.712699 samples/s, speed: 4460.901686 tokens/s, learning rate: 2.752e-05, loss_scalings: 2814.750488, pp_loss: 7.285538
[INFO] 2021-07-12 19:27:53,681 [run_pretraining.py:  512]:	********exe.run_2753******* 
[INFO] 2021-07-12 19:27:54,604 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:54,604 [run_pretraining.py:  534]:	loss/total_loss, 7.9509758949279785, 2754
[INFO] 2021-07-12 19:27:54,604 [run_pretraining.py:  535]:	loss/mlm_loss, 7.9509758949279785, 2754
[INFO] 2021-07-12 19:27:54,604 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7529998988029547e-05, 2754
[INFO] 2021-07-12 19:27:54,605 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2754
[INFO] 2021-07-12 19:27:54,605 [run_pretraining.py:  558]:	worker_index: 2, step: 2754, cost: 7.950976, mlm loss: 7.950976, speed: 1.082952 steps/s, speed: 8.663613 samples/s, speed: 4435.769716 tokens/s, learning rate: 2.753e-05, loss_scalings: 2814.750488, pp_loss: 7.404948
[INFO] 2021-07-12 19:27:54,605 [run_pretraining.py:  512]:	********exe.run_2754******* 
[INFO] 2021-07-12 19:27:55,530 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:55,531 [run_pretraining.py:  534]:	loss/total_loss, 7.31388521194458, 2755
[INFO] 2021-07-12 19:27:55,531 [run_pretraining.py:  535]:	loss/mlm_loss, 7.31388521194458, 2755
[INFO] 2021-07-12 19:27:55,531 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7539999791770242e-05, 2755
[INFO] 2021-07-12 19:27:55,531 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2755
[INFO] 2021-07-12 19:27:55,531 [run_pretraining.py:  558]:	worker_index: 2, step: 2755, cost: 7.313885, mlm loss: 7.313885, speed: 1.080051 steps/s, speed: 8.640409 samples/s, speed: 4423.889386 tokens/s, learning rate: 2.754e-05, loss_scalings: 2814.750488, pp_loss: 7.376756
[INFO] 2021-07-12 19:27:55,531 [run_pretraining.py:  512]:	********exe.run_2755******* 
[INFO] 2021-07-12 19:27:56,458 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:56,458 [run_pretraining.py:  534]:	loss/total_loss, 7.3010711669921875, 2756
[INFO] 2021-07-12 19:27:56,458 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3010711669921875, 2756
[INFO] 2021-07-12 19:27:56,458 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7549998776521534e-05, 2756
[INFO] 2021-07-12 19:27:56,459 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2756
[INFO] 2021-07-12 19:27:56,459 [run_pretraining.py:  558]:	worker_index: 2, step: 2756, cost: 7.301071, mlm loss: 7.301071, speed: 1.078812 steps/s, speed: 8.630493 samples/s, speed: 4418.812242 tokens/s, learning rate: 2.755e-05, loss_scalings: 2814.750488, pp_loss: 7.191370
[INFO] 2021-07-12 19:27:56,459 [run_pretraining.py:  512]:	********exe.run_2756******* 
[INFO] 2021-07-12 19:27:57,377 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:57,377 [run_pretraining.py:  534]:	loss/total_loss, 7.35698127746582, 2757
[INFO] 2021-07-12 19:27:57,377 [run_pretraining.py:  535]:	loss/mlm_loss, 7.35698127746582, 2757
[INFO] 2021-07-12 19:27:57,377 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7559997761272825e-05, 2757
[INFO] 2021-07-12 19:27:57,377 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2757
[INFO] 2021-07-12 19:27:57,378 [run_pretraining.py:  558]:	worker_index: 2, step: 2757, cost: 7.356981, mlm loss: 7.356981, speed: 1.089008 steps/s, speed: 8.712067 samples/s, speed: 4460.578541 tokens/s, learning rate: 2.756e-05, loss_scalings: 2814.750488, pp_loss: 7.185584
[INFO] 2021-07-12 19:27:57,378 [run_pretraining.py:  512]:	********exe.run_2757******* 
[INFO] 2021-07-12 19:27:58,393 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:58,393 [run_pretraining.py:  534]:	loss/total_loss, 7.065009593963623, 2758
[INFO] 2021-07-12 19:27:58,393 [run_pretraining.py:  535]:	loss/mlm_loss, 7.065009593963623, 2758
[INFO] 2021-07-12 19:27:58,393 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7570000384002924e-05, 2758
[INFO] 2021-07-12 19:27:58,394 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2758
[INFO] 2021-07-12 19:27:58,394 [run_pretraining.py:  558]:	worker_index: 2, step: 2758, cost: 7.065010, mlm loss: 7.065010, speed: 0.984732 steps/s, speed: 7.877857 samples/s, speed: 4033.462779 tokens/s, learning rate: 2.757e-05, loss_scalings: 2814.750488, pp_loss: 7.578281
[INFO] 2021-07-12 19:27:58,394 [run_pretraining.py:  512]:	********exe.run_2758******* 
[INFO] 2021-07-12 19:27:59,461 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:59,462 [run_pretraining.py:  534]:	loss/total_loss, 7.208739280700684, 2759
[INFO] 2021-07-12 19:27:59,462 [run_pretraining.py:  535]:	loss/mlm_loss, 7.208739280700684, 2759
[INFO] 2021-07-12 19:27:59,462 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7579997549764812e-05, 2759
[INFO] 2021-07-12 19:27:59,462 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2759
[INFO] 2021-07-12 19:27:59,462 [run_pretraining.py:  558]:	worker_index: 2, step: 2759, cost: 7.208739, mlm loss: 7.208739, speed: 0.936653 steps/s, speed: 7.493227 samples/s, speed: 3836.532370 tokens/s, learning rate: 2.758e-05, loss_scalings: 2814.750488, pp_loss: 7.266752
[INFO] 2021-07-12 19:27:59,462 [run_pretraining.py:  512]:	********exe.run_2759******* 
[INFO] 2021-07-12 19:28:00,530 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:00,531 [run_pretraining.py:  534]:	loss/total_loss, 7.935884475708008, 2760
[INFO] 2021-07-12 19:28:00,531 [run_pretraining.py:  535]:	loss/mlm_loss, 7.935884475708008, 2760
[INFO] 2021-07-12 19:28:00,531 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.759000017249491e-05, 2760
[INFO] 2021-07-12 19:28:00,531 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2760
[INFO] 2021-07-12 19:28:00,531 [run_pretraining.py:  558]:	worker_index: 2, step: 2760, cost: 7.935884, mlm loss: 7.935884, speed: 0.935801 steps/s, speed: 7.486406 samples/s, speed: 3833.039982 tokens/s, learning rate: 2.759e-05, loss_scalings: 2814.750488, pp_loss: 7.475672
[INFO] 2021-07-12 19:28:00,531 [run_pretraining.py:  512]:	********exe.run_2760******* 
[INFO] 2021-07-12 19:28:01,589 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:01,589 [run_pretraining.py:  534]:	loss/total_loss, 6.460381031036377, 2761
[INFO] 2021-07-12 19:28:01,589 [run_pretraining.py:  535]:	loss/mlm_loss, 6.460381031036377, 2761
[INFO] 2021-07-12 19:28:01,590 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7599999157246202e-05, 2761
[INFO] 2021-07-12 19:28:01,590 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2761
[INFO] 2021-07-12 19:28:01,590 [run_pretraining.py:  558]:	worker_index: 2, step: 2761, cost: 6.460381, mlm loss: 6.460381, speed: 0.945122 steps/s, speed: 7.560979 samples/s, speed: 3871.221459 tokens/s, learning rate: 2.760e-05, loss_scalings: 2814.750488, pp_loss: 7.086128
[INFO] 2021-07-12 19:28:01,590 [run_pretraining.py:  512]:	********exe.run_2761******* 
[INFO] 2021-07-12 19:28:02,691 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:02,692 [run_pretraining.py:  534]:	loss/total_loss, 7.30277156829834, 2762
[INFO] 2021-07-12 19:28:02,692 [run_pretraining.py:  535]:	loss/mlm_loss, 7.30277156829834, 2762
[INFO] 2021-07-12 19:28:02,692 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7609999960986897e-05, 2762
[INFO] 2021-07-12 19:28:02,692 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2762
[INFO] 2021-07-12 19:28:02,692 [run_pretraining.py:  558]:	worker_index: 2, step: 2762, cost: 7.302772, mlm loss: 7.302772, speed: 0.907503 steps/s, speed: 7.260021 samples/s, speed: 3717.130929 tokens/s, learning rate: 2.761e-05, loss_scalings: 2814.750488, pp_loss: 7.477398
[INFO] 2021-07-12 19:28:02,692 [run_pretraining.py:  512]:	********exe.run_2762******* 
[INFO] 2021-07-12 19:28:03,759 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:03,760 [run_pretraining.py:  534]:	loss/total_loss, 6.856993675231934, 2763
[INFO] 2021-07-12 19:28:03,760 [run_pretraining.py:  535]:	loss/mlm_loss, 6.856993675231934, 2763
[INFO] 2021-07-12 19:28:03,760 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.761999894573819e-05, 2763
[INFO] 2021-07-12 19:28:03,760 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2763
[INFO] 2021-07-12 19:28:03,760 [run_pretraining.py:  558]:	worker_index: 2, step: 2763, cost: 6.856994, mlm loss: 6.856994, speed: 0.937188 steps/s, speed: 7.497505 samples/s, speed: 3838.722635 tokens/s, learning rate: 2.762e-05, loss_scalings: 2814.750488, pp_loss: 7.655499
[INFO] 2021-07-12 19:28:03,760 [run_pretraining.py:  512]:	********exe.run_2763******* 
[INFO] 2021-07-12 19:28:04,836 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:04,837 [run_pretraining.py:  534]:	loss/total_loss, 4.828588962554932, 2764
[INFO] 2021-07-12 19:28:04,837 [run_pretraining.py:  535]:	loss/mlm_loss, 4.828588962554932, 2764
[INFO] 2021-07-12 19:28:04,837 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7629999749478884e-05, 2764
[INFO] 2021-07-12 19:28:04,837 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2764
[INFO] 2021-07-12 19:28:04,837 [run_pretraining.py:  558]:	worker_index: 2, step: 2764, cost: 4.828589, mlm loss: 4.828589, speed: 0.928745 steps/s, speed: 7.429963 samples/s, speed: 3804.140873 tokens/s, learning rate: 2.763e-05, loss_scalings: 2814.750488, pp_loss: 6.725375
[INFO] 2021-07-12 19:28:04,837 [run_pretraining.py:  512]:	********exe.run_2764******* 
[INFO] 2021-07-12 19:28:05,903 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:05,904 [run_pretraining.py:  534]:	loss/total_loss, 7.000336647033691, 2765
[INFO] 2021-07-12 19:28:05,904 [run_pretraining.py:  535]:	loss/mlm_loss, 7.000336647033691, 2765
[INFO] 2021-07-12 19:28:05,904 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7639998734230176e-05, 2765
[INFO] 2021-07-12 19:28:05,904 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2765
[INFO] 2021-07-12 19:28:05,904 [run_pretraining.py:  558]:	worker_index: 2, step: 2765, cost: 7.000337, mlm loss: 7.000337, speed: 0.937880 steps/s, speed: 7.503043 samples/s, speed: 3841.557829 tokens/s, learning rate: 2.764e-05, loss_scalings: 2814.750488, pp_loss: 7.734164
[INFO] 2021-07-12 19:28:05,904 [run_pretraining.py:  512]:	********exe.run_2765******* 
[INFO] 2021-07-12 19:28:06,964 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:06,964 [run_pretraining.py:  534]:	loss/total_loss, 8.118609428405762, 2766
[INFO] 2021-07-12 19:28:06,964 [run_pretraining.py:  535]:	loss/mlm_loss, 8.118609428405762, 2766
[INFO] 2021-07-12 19:28:06,965 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7649997718981467e-05, 2766
[INFO] 2021-07-12 19:28:06,965 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2766
[INFO] 2021-07-12 19:28:06,965 [run_pretraining.py:  558]:	worker_index: 2, step: 2766, cost: 8.118609, mlm loss: 8.118609, speed: 0.943349 steps/s, speed: 7.546795 samples/s, speed: 3863.959082 tokens/s, learning rate: 2.765e-05, loss_scalings: 2814.750488, pp_loss: 7.013672
[INFO] 2021-07-12 19:28:06,965 [run_pretraining.py:  512]:	********exe.run_2766******* 
[INFO] 2021-07-12 19:28:08,020 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:08,021 [run_pretraining.py:  534]:	loss/total_loss, 6.679012775421143, 2767
[INFO] 2021-07-12 19:28:08,021 [run_pretraining.py:  535]:	loss/mlm_loss, 6.679012775421143, 2767
[INFO] 2021-07-12 19:28:08,021 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7660000341711566e-05, 2767
[INFO] 2021-07-12 19:28:08,021 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2767
[INFO] 2021-07-12 19:28:08,021 [run_pretraining.py:  558]:	worker_index: 2, step: 2767, cost: 6.679013, mlm loss: 6.679013, speed: 0.947040 steps/s, speed: 7.576320 samples/s, speed: 3879.076038 tokens/s, learning rate: 2.766e-05, loss_scalings: 2814.750488, pp_loss: 7.128411
[INFO] 2021-07-12 19:28:08,021 [run_pretraining.py:  512]:	********exe.run_2767******* 
[INFO] 2021-07-12 19:28:09,093 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:09,094 [run_pretraining.py:  534]:	loss/total_loss, 6.7424139976501465, 2768
[INFO] 2021-07-12 19:28:09,094 [run_pretraining.py:  535]:	loss/mlm_loss, 6.7424139976501465, 2768
[INFO] 2021-07-12 19:28:09,094 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7669997507473454e-05, 2768
[INFO] 2021-07-12 19:28:09,094 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2768
[INFO] 2021-07-12 19:28:09,094 [run_pretraining.py:  558]:	worker_index: 2, step: 2768, cost: 6.742414, mlm loss: 6.742414, speed: 0.932431 steps/s, speed: 7.459448 samples/s, speed: 3819.237361 tokens/s, learning rate: 2.767e-05, loss_scalings: 2814.750488, pp_loss: 7.057357
[INFO] 2021-07-12 19:28:09,094 [run_pretraining.py:  512]:	********exe.run_2768******* 
[INFO] 2021-07-12 19:28:10,166 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:10,167 [run_pretraining.py:  534]:	loss/total_loss, 6.870585918426514, 2769
[INFO] 2021-07-12 19:28:10,167 [run_pretraining.py:  535]:	loss/mlm_loss, 6.870585918426514, 2769
[INFO] 2021-07-12 19:28:10,167 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7680000130203553e-05, 2769
[INFO] 2021-07-12 19:28:10,167 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2769
[INFO] 2021-07-12 19:28:10,167 [run_pretraining.py:  558]:	worker_index: 2, step: 2769, cost: 6.870586, mlm loss: 6.870586, speed: 0.932630 steps/s, speed: 7.461044 samples/s, speed: 3820.054323 tokens/s, learning rate: 2.768e-05, loss_scalings: 2814.750488, pp_loss: 7.192787
[INFO] 2021-07-12 19:28:10,167 [run_pretraining.py:  512]:	********exe.run_2769******* 
[INFO] 2021-07-12 19:28:11,229 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:11,230 [run_pretraining.py:  534]:	loss/total_loss, 6.61091423034668, 2770
[INFO] 2021-07-12 19:28:11,230 [run_pretraining.py:  535]:	loss/mlm_loss, 6.61091423034668, 2770
[INFO] 2021-07-12 19:28:11,230 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7689999114954844e-05, 2770
[INFO] 2021-07-12 19:28:11,230 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2770
[INFO] 2021-07-12 19:28:11,230 [run_pretraining.py:  558]:	worker_index: 2, step: 2770, cost: 6.610914, mlm loss: 6.610914, speed: 0.941266 steps/s, speed: 7.530128 samples/s, speed: 3855.425640 tokens/s, learning rate: 2.769e-05, loss_scalings: 2814.750488, pp_loss: 6.757017
[INFO] 2021-07-12 19:28:11,230 [run_pretraining.py:  512]:	********exe.run_2770******* 
[INFO] 2021-07-12 19:28:12,294 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:12,294 [run_pretraining.py:  534]:	loss/total_loss, 5.373931407928467, 2771
[INFO] 2021-07-12 19:28:12,294 [run_pretraining.py:  535]:	loss/mlm_loss, 5.373931407928467, 2771
[INFO] 2021-07-12 19:28:12,295 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.769999991869554e-05, 2771
[INFO] 2021-07-12 19:28:12,295 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2771
[INFO] 2021-07-12 19:28:12,295 [run_pretraining.py:  558]:	worker_index: 2, step: 2771, cost: 5.373931, mlm loss: 5.373931, speed: 0.939821 steps/s, speed: 7.518565 samples/s, speed: 3849.505416 tokens/s, learning rate: 2.770e-05, loss_scalings: 2814.750488, pp_loss: 6.840047
[INFO] 2021-07-12 19:28:12,295 [run_pretraining.py:  512]:	********exe.run_2771******* 
[INFO] 2021-07-12 19:28:13,363 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:13,364 [run_pretraining.py:  534]:	loss/total_loss, 7.04384183883667, 2772
[INFO] 2021-07-12 19:28:13,364 [run_pretraining.py:  535]:	loss/mlm_loss, 7.04384183883667, 2772
[INFO] 2021-07-12 19:28:13,364 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.770999890344683e-05, 2772
[INFO] 2021-07-12 19:28:13,364 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2772
[INFO] 2021-07-12 19:28:13,364 [run_pretraining.py:  558]:	worker_index: 2, step: 2772, cost: 7.043842, mlm loss: 7.043842, speed: 0.935854 steps/s, speed: 7.486832 samples/s, speed: 3833.258070 tokens/s, learning rate: 2.771e-05, loss_scalings: 2814.750488, pp_loss: 7.491404
[INFO] 2021-07-12 19:28:13,364 [run_pretraining.py:  512]:	********exe.run_2772******* 
[INFO] 2021-07-12 19:28:14,424 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:14,425 [run_pretraining.py:  534]:	loss/total_loss, 6.950353145599365, 2773
[INFO] 2021-07-12 19:28:14,425 [run_pretraining.py:  535]:	loss/mlm_loss, 6.950353145599365, 2773
[INFO] 2021-07-12 19:28:14,425 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.772000152617693e-05, 2773
[INFO] 2021-07-12 19:28:14,425 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2773
[INFO] 2021-07-12 19:28:14,425 [run_pretraining.py:  558]:	worker_index: 2, step: 2773, cost: 6.950353, mlm loss: 6.950353, speed: 0.942921 steps/s, speed: 7.543365 samples/s, speed: 3862.202660 tokens/s, learning rate: 2.772e-05, loss_scalings: 2814.750488, pp_loss: 7.097917
[INFO] 2021-07-12 19:28:14,425 [run_pretraining.py:  512]:	********exe.run_2773******* 
[INFO] 2021-07-12 19:28:15,479 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:15,480 [run_pretraining.py:  534]:	loss/total_loss, 7.437770843505859, 2774
[INFO] 2021-07-12 19:28:15,480 [run_pretraining.py:  535]:	loss/mlm_loss, 7.437770843505859, 2774
[INFO] 2021-07-12 19:28:15,480 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7729998691938818e-05, 2774
[INFO] 2021-07-12 19:28:15,480 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2774
[INFO] 2021-07-12 19:28:15,480 [run_pretraining.py:  558]:	worker_index: 2, step: 2774, cost: 7.437771, mlm loss: 7.437771, speed: 0.948439 steps/s, speed: 7.587513 samples/s, speed: 3884.806511 tokens/s, learning rate: 2.773e-05, loss_scalings: 2814.750488, pp_loss: 7.308559
[INFO] 2021-07-12 19:28:15,480 [run_pretraining.py:  512]:	********exe.run_2774******* 
[INFO] 2021-07-12 19:28:16,419 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:16,420 [run_pretraining.py:  534]:	loss/total_loss, 6.997435569763184, 2775
[INFO] 2021-07-12 19:28:16,420 [run_pretraining.py:  535]:	loss/mlm_loss, 6.997435569763184, 2775
[INFO] 2021-07-12 19:28:16,420 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.773999767669011e-05, 2775
[INFO] 2021-07-12 19:28:16,420 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2775
[INFO] 2021-07-12 19:28:16,420 [run_pretraining.py:  558]:	worker_index: 2, step: 2775, cost: 6.997436, mlm loss: 6.997436, speed: 1.064342 steps/s, speed: 8.514739 samples/s, speed: 4359.546346 tokens/s, learning rate: 2.774e-05, loss_scalings: 2814.750488, pp_loss: 6.988231
[INFO] 2021-07-12 19:28:16,420 [run_pretraining.py:  512]:	********exe.run_2775******* 
[INFO] 2021-07-12 19:28:17,349 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:17,349 [run_pretraining.py:  534]:	loss/total_loss, 7.573525905609131, 2776
[INFO] 2021-07-12 19:28:17,349 [run_pretraining.py:  535]:	loss/mlm_loss, 7.573525905609131, 2776
[INFO] 2021-07-12 19:28:17,349 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7750000299420208e-05, 2776
[INFO] 2021-07-12 19:28:17,349 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2776
[INFO] 2021-07-12 19:28:17,349 [run_pretraining.py:  558]:	worker_index: 2, step: 2776, cost: 7.573526, mlm loss: 7.573526, speed: 1.076719 steps/s, speed: 8.613750 samples/s, speed: 4410.239942 tokens/s, learning rate: 2.775e-05, loss_scalings: 2814.750488, pp_loss: 6.595217
[INFO] 2021-07-12 19:28:17,350 [run_pretraining.py:  512]:	********exe.run_2776******* 
[INFO] 2021-07-12 19:28:18,269 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:18,269 [run_pretraining.py:  534]:	loss/total_loss, 8.147527694702148, 2777
[INFO] 2021-07-12 19:28:18,269 [run_pretraining.py:  535]:	loss/mlm_loss, 8.147527694702148, 2777
[INFO] 2021-07-12 19:28:18,269 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7759997465182096e-05, 2777
[INFO] 2021-07-12 19:28:18,269 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2777
[INFO] 2021-07-12 19:28:18,269 [run_pretraining.py:  558]:	worker_index: 2, step: 2777, cost: 8.147528, mlm loss: 8.147528, speed: 1.087743 steps/s, speed: 8.701943 samples/s, speed: 4455.394929 tokens/s, learning rate: 2.776e-05, loss_scalings: 2814.750488, pp_loss: 7.707561
[INFO] 2021-07-12 19:28:18,269 [run_pretraining.py:  512]:	********exe.run_2777******* 
[INFO] 2021-07-12 19:28:19,194 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:19,194 [run_pretraining.py:  534]:	loss/total_loss, 7.362597465515137, 2778
[INFO] 2021-07-12 19:28:19,194 [run_pretraining.py:  535]:	loss/mlm_loss, 7.362597465515137, 2778
[INFO] 2021-07-12 19:28:19,194 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7770000087912194e-05, 2778
[INFO] 2021-07-12 19:28:19,195 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2778
[INFO] 2021-07-12 19:28:19,195 [run_pretraining.py:  558]:	worker_index: 2, step: 2778, cost: 7.362597, mlm loss: 7.362597, speed: 1.081505 steps/s, speed: 8.652037 samples/s, speed: 4429.842717 tokens/s, learning rate: 2.777e-05, loss_scalings: 2814.750488, pp_loss: 7.186941
[INFO] 2021-07-12 19:28:19,195 [run_pretraining.py:  512]:	********exe.run_2778******* 
[INFO] 2021-07-12 19:28:20,114 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:20,114 [run_pretraining.py:  534]:	loss/total_loss, 7.46925163269043, 2779
[INFO] 2021-07-12 19:28:20,114 [run_pretraining.py:  535]:	loss/mlm_loss, 7.46925163269043, 2779
[INFO] 2021-07-12 19:28:20,115 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7779999072663486e-05, 2779
[INFO] 2021-07-12 19:28:20,115 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2779
[INFO] 2021-07-12 19:28:20,115 [run_pretraining.py:  558]:	worker_index: 2, step: 2779, cost: 7.469252, mlm loss: 7.469252, speed: 1.087621 steps/s, speed: 8.700971 samples/s, speed: 4454.896984 tokens/s, learning rate: 2.778e-05, loss_scalings: 2814.750488, pp_loss: 6.946321
[INFO] 2021-07-12 19:28:20,115 [run_pretraining.py:  512]:	********exe.run_2779******* 
[INFO] 2021-07-12 19:28:21,040 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:21,040 [run_pretraining.py:  534]:	loss/total_loss, 7.498946189880371, 2780
[INFO] 2021-07-12 19:28:21,040 [run_pretraining.py:  535]:	loss/mlm_loss, 7.498946189880371, 2780
[INFO] 2021-07-12 19:28:21,040 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.778999987640418e-05, 2780
[INFO] 2021-07-12 19:28:21,040 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2780
[INFO] 2021-07-12 19:28:21,041 [run_pretraining.py:  558]:	worker_index: 2, step: 2780, cost: 7.498946, mlm loss: 7.498946, speed: 1.080760 steps/s, speed: 8.646080 samples/s, speed: 4426.792758 tokens/s, learning rate: 2.779e-05, loss_scalings: 2814.750488, pp_loss: 7.297993
[INFO] 2021-07-12 19:28:21,041 [run_pretraining.py:  512]:	********exe.run_2780******* 
[INFO] 2021-07-12 19:28:21,959 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:21,959 [run_pretraining.py:  534]:	loss/total_loss, 7.045057773590088, 2781
[INFO] 2021-07-12 19:28:21,960 [run_pretraining.py:  535]:	loss/mlm_loss, 7.045057773590088, 2781
[INFO] 2021-07-12 19:28:21,960 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7799998861155473e-05, 2781
[INFO] 2021-07-12 19:28:21,960 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2781
[INFO] 2021-07-12 19:28:21,960 [run_pretraining.py:  558]:	worker_index: 2, step: 2781, cost: 7.045058, mlm loss: 7.045058, speed: 1.088484 steps/s, speed: 8.707876 samples/s, speed: 4458.432375 tokens/s, learning rate: 2.780e-05, loss_scalings: 2814.750488, pp_loss: 7.068961
[INFO] 2021-07-12 19:28:21,960 [run_pretraining.py:  512]:	********exe.run_2781******* 
[INFO] 2021-07-12 19:28:22,881 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:22,881 [run_pretraining.py:  534]:	loss/total_loss, 7.44199800491333, 2782
[INFO] 2021-07-12 19:28:22,881 [run_pretraining.py:  535]:	loss/mlm_loss, 7.44199800491333, 2782
[INFO] 2021-07-12 19:28:22,881 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.781000148388557e-05, 2782
[INFO] 2021-07-12 19:28:22,881 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2782
[INFO] 2021-07-12 19:28:22,881 [run_pretraining.py:  558]:	worker_index: 2, step: 2782, cost: 7.441998, mlm loss: 7.441998, speed: 1.085882 steps/s, speed: 8.687054 samples/s, speed: 4447.771601 tokens/s, learning rate: 2.781e-05, loss_scalings: 2814.750488, pp_loss: 6.552359
[INFO] 2021-07-12 19:28:22,881 [run_pretraining.py:  512]:	********exe.run_2782******* 
[INFO] 2021-07-12 19:28:23,801 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:23,801 [run_pretraining.py:  534]:	loss/total_loss, 7.044812202453613, 2783
[INFO] 2021-07-12 19:28:23,801 [run_pretraining.py:  535]:	loss/mlm_loss, 7.044812202453613, 2783
[INFO] 2021-07-12 19:28:23,801 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.781999864964746e-05, 2783
[INFO] 2021-07-12 19:28:23,801 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2783
[INFO] 2021-07-12 19:28:23,802 [run_pretraining.py:  558]:	worker_index: 2, step: 2783, cost: 7.044812, mlm loss: 7.044812, speed: 1.087425 steps/s, speed: 8.699401 samples/s, speed: 4454.093113 tokens/s, learning rate: 2.782e-05, loss_scalings: 2814.750488, pp_loss: 6.962144
[INFO] 2021-07-12 19:28:23,802 [run_pretraining.py:  512]:	********exe.run_2783******* 
[INFO] 2021-07-12 19:28:24,727 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:24,727 [run_pretraining.py:  534]:	loss/total_loss, 7.0862717628479, 2784
[INFO] 2021-07-12 19:28:24,727 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0862717628479, 2784
[INFO] 2021-07-12 19:28:24,727 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.782999763439875e-05, 2784
[INFO] 2021-07-12 19:28:24,727 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2784
[INFO] 2021-07-12 19:28:24,727 [run_pretraining.py:  558]:	worker_index: 2, step: 2784, cost: 7.086272, mlm loss: 7.086272, speed: 1.080749 steps/s, speed: 8.645995 samples/s, speed: 4426.749413 tokens/s, learning rate: 2.783e-05, loss_scalings: 2814.750488, pp_loss: 7.225927
[INFO] 2021-07-12 19:28:24,727 [run_pretraining.py:  512]:	********exe.run_2784******* 
[INFO] 2021-07-12 19:28:25,645 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:25,646 [run_pretraining.py:  534]:	loss/total_loss, 6.898609161376953, 2785
[INFO] 2021-07-12 19:28:25,646 [run_pretraining.py:  535]:	loss/mlm_loss, 6.898609161376953, 2785
[INFO] 2021-07-12 19:28:25,646 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.784000025712885e-05, 2785
[INFO] 2021-07-12 19:28:25,646 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2785
[INFO] 2021-07-12 19:28:25,646 [run_pretraining.py:  558]:	worker_index: 2, step: 2785, cost: 6.898609, mlm loss: 6.898609, speed: 1.089255 steps/s, speed: 8.714040 samples/s, speed: 4461.588671 tokens/s, learning rate: 2.784e-05, loss_scalings: 2814.750488, pp_loss: 7.094118
[INFO] 2021-07-12 19:28:25,646 [run_pretraining.py:  512]:	********exe.run_2785******* 
[INFO] 2021-07-12 19:28:26,572 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:26,572 [run_pretraining.py:  534]:	loss/total_loss, 7.37055778503418, 2786
[INFO] 2021-07-12 19:28:26,572 [run_pretraining.py:  535]:	loss/mlm_loss, 7.37055778503418, 2786
[INFO] 2021-07-12 19:28:26,573 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.784999924188014e-05, 2786
[INFO] 2021-07-12 19:28:26,573 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2786
[INFO] 2021-07-12 19:28:26,573 [run_pretraining.py:  558]:	worker_index: 2, step: 2786, cost: 7.370558, mlm loss: 7.370558, speed: 1.079928 steps/s, speed: 8.639421 samples/s, speed: 4423.383653 tokens/s, learning rate: 2.785e-05, loss_scalings: 2814.750488, pp_loss: 7.397550
[INFO] 2021-07-12 19:28:26,573 [run_pretraining.py:  512]:	********exe.run_2786******* 
[INFO] 2021-07-12 19:28:27,482 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:27,482 [run_pretraining.py:  534]:	loss/total_loss, 7.190176486968994, 2787
[INFO] 2021-07-12 19:28:27,482 [run_pretraining.py:  535]:	loss/mlm_loss, 7.190176486968994, 2787
[INFO] 2021-07-12 19:28:27,482 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7860000045620836e-05, 2787
[INFO] 2021-07-12 19:28:27,482 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2787
[INFO] 2021-07-12 19:28:27,482 [run_pretraining.py:  558]:	worker_index: 2, step: 2787, cost: 7.190176, mlm loss: 7.190176, speed: 1.099840 steps/s, speed: 8.798721 samples/s, speed: 4504.945037 tokens/s, learning rate: 2.786e-05, loss_scalings: 2814.750488, pp_loss: 7.245726
[INFO] 2021-07-12 19:28:27,483 [run_pretraining.py:  512]:	********exe.run_2787******* 
[INFO] 2021-07-12 19:28:28,402 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:28,402 [run_pretraining.py:  534]:	loss/total_loss, 7.272892951965332, 2788
[INFO] 2021-07-12 19:28:28,402 [run_pretraining.py:  535]:	loss/mlm_loss, 7.272892951965332, 2788
[INFO] 2021-07-12 19:28:28,403 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7869999030372128e-05, 2788
[INFO] 2021-07-12 19:28:28,403 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2788
[INFO] 2021-07-12 19:28:28,403 [run_pretraining.py:  558]:	worker_index: 2, step: 2788, cost: 7.272893, mlm loss: 7.272893, speed: 1.087339 steps/s, speed: 8.698711 samples/s, speed: 4453.739779 tokens/s, learning rate: 2.787e-05, loss_scalings: 2814.750488, pp_loss: 6.965434
[INFO] 2021-07-12 19:28:28,403 [run_pretraining.py:  512]:	********exe.run_2788******* 
[INFO] 2021-07-12 19:28:29,315 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:29,315 [run_pretraining.py:  534]:	loss/total_loss, 7.700580596923828, 2789
[INFO] 2021-07-12 19:28:29,315 [run_pretraining.py:  535]:	loss/mlm_loss, 7.700580596923828, 2789
[INFO] 2021-07-12 19:28:29,316 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7879999834112823e-05, 2789
[INFO] 2021-07-12 19:28:29,316 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2789
[INFO] 2021-07-12 19:28:29,316 [run_pretraining.py:  558]:	worker_index: 2, step: 2789, cost: 7.700581, mlm loss: 7.700581, speed: 1.096004 steps/s, speed: 8.768031 samples/s, speed: 4489.232080 tokens/s, learning rate: 2.788e-05, loss_scalings: 2814.750488, pp_loss: 7.466544
[INFO] 2021-07-12 19:28:29,316 [run_pretraining.py:  512]:	********exe.run_2789******* 
[INFO] 2021-07-12 19:28:30,232 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:30,232 [run_pretraining.py:  534]:	loss/total_loss, 7.203985214233398, 2790
[INFO] 2021-07-12 19:28:30,232 [run_pretraining.py:  535]:	loss/mlm_loss, 7.203985214233398, 2790
[INFO] 2021-07-12 19:28:30,232 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7889998818864115e-05, 2790
[INFO] 2021-07-12 19:28:30,232 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2790
[INFO] 2021-07-12 19:28:30,233 [run_pretraining.py:  558]:	worker_index: 2, step: 2790, cost: 7.203985, mlm loss: 7.203985, speed: 1.091462 steps/s, speed: 8.731696 samples/s, speed: 4470.628342 tokens/s, learning rate: 2.789e-05, loss_scalings: 2814.750488, pp_loss: 7.234422
[INFO] 2021-07-12 19:28:30,233 [run_pretraining.py:  512]:	********exe.run_2790******* 
[INFO] 2021-07-12 19:28:31,186 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:31,187 [run_pretraining.py:  534]:	loss/total_loss, 7.634286880493164, 2791
[INFO] 2021-07-12 19:28:31,187 [run_pretraining.py:  535]:	loss/mlm_loss, 7.634286880493164, 2791
[INFO] 2021-07-12 19:28:31,187 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7900001441594213e-05, 2791
[INFO] 2021-07-12 19:28:31,187 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2791
[INFO] 2021-07-12 19:28:31,187 [run_pretraining.py:  558]:	worker_index: 2, step: 2791, cost: 7.634287, mlm loss: 7.634287, speed: 1.048278 steps/s, speed: 8.386226 samples/s, speed: 4293.747872 tokens/s, learning rate: 2.790e-05, loss_scalings: 2814.750488, pp_loss: 7.574076
[INFO] 2021-07-12 19:28:31,187 [run_pretraining.py:  512]:	********exe.run_2791******* 
[INFO] 2021-07-12 19:28:32,150 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:32,150 [run_pretraining.py:  534]:	loss/total_loss, 5.929347515106201, 2792
[INFO] 2021-07-12 19:28:32,150 [run_pretraining.py:  535]:	loss/mlm_loss, 5.929347515106201, 2792
[INFO] 2021-07-12 19:28:32,151 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.79099986073561e-05, 2792
[INFO] 2021-07-12 19:28:32,151 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2792
[INFO] 2021-07-12 19:28:32,151 [run_pretraining.py:  558]:	worker_index: 2, step: 2792, cost: 5.929348, mlm loss: 5.929348, speed: 1.038423 steps/s, speed: 8.307381 samples/s, speed: 4253.378821 tokens/s, learning rate: 2.791e-05, loss_scalings: 2814.750488, pp_loss: 6.902799
[INFO] 2021-07-12 19:28:32,151 [run_pretraining.py:  512]:	********exe.run_2792******* 
[INFO] 2021-07-12 19:28:33,073 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:33,073 [run_pretraining.py:  534]:	loss/total_loss, 6.831462860107422, 2793
[INFO] 2021-07-12 19:28:33,073 [run_pretraining.py:  535]:	loss/mlm_loss, 6.831462860107422, 2793
[INFO] 2021-07-12 19:28:33,074 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7919997592107393e-05, 2793
[INFO] 2021-07-12 19:28:33,074 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2793
[INFO] 2021-07-12 19:28:33,074 [run_pretraining.py:  558]:	worker_index: 2, step: 2793, cost: 6.831463, mlm loss: 6.831463, speed: 1.084130 steps/s, speed: 8.673040 samples/s, speed: 4440.596664 tokens/s, learning rate: 2.792e-05, loss_scalings: 2814.750488, pp_loss: 7.244880
[INFO] 2021-07-12 19:28:33,074 [run_pretraining.py:  512]:	********exe.run_2793******* 
[INFO] 2021-07-12 19:28:33,990 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:33,991 [run_pretraining.py:  534]:	loss/total_loss, 7.790135383605957, 2794
[INFO] 2021-07-12 19:28:33,991 [run_pretraining.py:  535]:	loss/mlm_loss, 7.790135383605957, 2794
[INFO] 2021-07-12 19:28:33,991 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.793000021483749e-05, 2794
[INFO] 2021-07-12 19:28:33,991 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2794
[INFO] 2021-07-12 19:28:33,991 [run_pretraining.py:  558]:	worker_index: 2, step: 2794, cost: 7.790135, mlm loss: 7.790135, speed: 1.090901 steps/s, speed: 8.727206 samples/s, speed: 4468.329546 tokens/s, learning rate: 2.793e-05, loss_scalings: 2814.750488, pp_loss: 7.340825
[INFO] 2021-07-12 19:28:33,991 [run_pretraining.py:  512]:	********exe.run_2794******* 
[INFO] 2021-07-12 19:28:34,906 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:34,907 [run_pretraining.py:  534]:	loss/total_loss, 7.1176981925964355, 2795
[INFO] 2021-07-12 19:28:34,907 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1176981925964355, 2795
[INFO] 2021-07-12 19:28:34,907 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7939999199588783e-05, 2795
[INFO] 2021-07-12 19:28:34,907 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2795
[INFO] 2021-07-12 19:28:34,907 [run_pretraining.py:  558]:	worker_index: 2, step: 2795, cost: 7.117698, mlm loss: 7.117698, speed: 1.092356 steps/s, speed: 8.738848 samples/s, speed: 4474.290133 tokens/s, learning rate: 2.794e-05, loss_scalings: 2814.750488, pp_loss: 7.254763
[INFO] 2021-07-12 19:28:34,907 [run_pretraining.py:  512]:	********exe.run_2795******* 
[INFO] 2021-07-12 19:28:35,838 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:35,839 [run_pretraining.py:  534]:	loss/total_loss, 7.057304859161377, 2796
[INFO] 2021-07-12 19:28:35,839 [run_pretraining.py:  535]:	loss/mlm_loss, 7.057304859161377, 2796
[INFO] 2021-07-12 19:28:35,839 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7950000003329478e-05, 2796
[INFO] 2021-07-12 19:28:35,839 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2796
[INFO] 2021-07-12 19:28:35,839 [run_pretraining.py:  558]:	worker_index: 2, step: 2796, cost: 7.057305, mlm loss: 7.057305, speed: 1.073314 steps/s, speed: 8.586512 samples/s, speed: 4396.294183 tokens/s, learning rate: 2.795e-05, loss_scalings: 2814.750488, pp_loss: 7.085031
[INFO] 2021-07-12 19:28:35,839 [run_pretraining.py:  512]:	********exe.run_2796******* 
[INFO] 2021-07-12 19:28:36,755 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:36,756 [run_pretraining.py:  534]:	loss/total_loss, 6.9540276527404785, 2797
[INFO] 2021-07-12 19:28:36,756 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9540276527404785, 2797
[INFO] 2021-07-12 19:28:36,756 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.795999898808077e-05, 2797
[INFO] 2021-07-12 19:28:36,756 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2797
[INFO] 2021-07-12 19:28:36,756 [run_pretraining.py:  558]:	worker_index: 2, step: 2797, cost: 6.954028, mlm loss: 6.954028, speed: 1.091424 steps/s, speed: 8.731389 samples/s, speed: 4470.471293 tokens/s, learning rate: 2.796e-05, loss_scalings: 2814.750488, pp_loss: 6.884926
[INFO] 2021-07-12 19:28:36,756 [run_pretraining.py:  512]:	********exe.run_2797******* 
[INFO] 2021-07-12 19:28:37,684 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:37,685 [run_pretraining.py:  534]:	loss/total_loss, 6.599924087524414, 2798
[INFO] 2021-07-12 19:28:37,685 [run_pretraining.py:  535]:	loss/mlm_loss, 6.599924087524414, 2798
[INFO] 2021-07-12 19:28:37,685 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7969999791821465e-05, 2798
[INFO] 2021-07-12 19:28:37,685 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2798
[INFO] 2021-07-12 19:28:37,685 [run_pretraining.py:  558]:	worker_index: 2, step: 2798, cost: 6.599924, mlm loss: 6.599924, speed: 1.077221 steps/s, speed: 8.617767 samples/s, speed: 4412.296889 tokens/s, learning rate: 2.797e-05, loss_scalings: 2814.750488, pp_loss: 7.025313
[INFO] 2021-07-12 19:28:37,685 [run_pretraining.py:  512]:	********exe.run_2798******* 
[INFO] 2021-07-12 19:28:38,607 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:38,607 [run_pretraining.py:  534]:	loss/total_loss, 7.185853481292725, 2799
[INFO] 2021-07-12 19:28:38,607 [run_pretraining.py:  535]:	loss/mlm_loss, 7.185853481292725, 2799
[INFO] 2021-07-12 19:28:38,607 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7979998776572756e-05, 2799
[INFO] 2021-07-12 19:28:38,607 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2799
[INFO] 2021-07-12 19:28:38,607 [run_pretraining.py:  558]:	worker_index: 2, step: 2799, cost: 7.185853, mlm loss: 7.185853, speed: 1.084934 steps/s, speed: 8.679472 samples/s, speed: 4443.889821 tokens/s, learning rate: 2.798e-05, loss_scalings: 2814.750488, pp_loss: 7.282939
[INFO] 2021-07-12 19:28:38,607 [run_pretraining.py:  512]:	********exe.run_2799******* 
[INFO] 2021-07-12 19:28:39,540 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:39,541 [run_pretraining.py:  534]:	loss/total_loss, 7.494449138641357, 2800
[INFO] 2021-07-12 19:28:39,541 [run_pretraining.py:  535]:	loss/mlm_loss, 7.494449138641357, 2800
[INFO] 2021-07-12 19:28:39,541 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7990001399302855e-05, 2800
[INFO] 2021-07-12 19:28:39,541 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2800
[INFO] 2021-07-12 19:28:39,541 [run_pretraining.py:  558]:	worker_index: 2, step: 2800, cost: 7.494449, mlm loss: 7.494449, speed: 1.071519 steps/s, speed: 8.572151 samples/s, speed: 4388.941109 tokens/s, learning rate: 2.799e-05, loss_scalings: 2814.750488, pp_loss: 6.301206
[INFO] 2021-07-12 19:28:39,541 [run_pretraining.py:  512]:	********exe.run_2800******* 
[INFO] 2021-07-12 19:28:40,459 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:40,459 [run_pretraining.py:  534]:	loss/total_loss, 6.511153221130371, 2801
[INFO] 2021-07-12 19:28:40,459 [run_pretraining.py:  535]:	loss/mlm_loss, 6.511153221130371, 2801
[INFO] 2021-07-12 19:28:40,460 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7999998565064743e-05, 2801
[INFO] 2021-07-12 19:28:40,460 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2801
[INFO] 2021-07-12 19:28:40,460 [run_pretraining.py:  558]:	worker_index: 2, step: 2801, cost: 6.511153, mlm loss: 6.511153, speed: 1.089537 steps/s, speed: 8.716295 samples/s, speed: 4462.743004 tokens/s, learning rate: 2.800e-05, loss_scalings: 2814.750488, pp_loss: 6.911082
[INFO] 2021-07-12 19:28:40,460 [run_pretraining.py:  512]:	********exe.run_2801******* 
[INFO] 2021-07-12 19:28:41,387 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:41,388 [run_pretraining.py:  534]:	loss/total_loss, 7.836277008056641, 2802
[INFO] 2021-07-12 19:28:41,388 [run_pretraining.py:  535]:	loss/mlm_loss, 7.836277008056641, 2802
[INFO] 2021-07-12 19:28:41,388 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8009997549816035e-05, 2802
[INFO] 2021-07-12 19:28:41,388 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2802
[INFO] 2021-07-12 19:28:41,388 [run_pretraining.py:  558]:	worker_index: 2, step: 2802, cost: 7.836277, mlm loss: 7.836277, speed: 1.077789 steps/s, speed: 8.622311 samples/s, speed: 4414.623458 tokens/s, learning rate: 2.801e-05, loss_scalings: 2814.750488, pp_loss: 7.676440
[INFO] 2021-07-12 19:28:41,388 [run_pretraining.py:  512]:	********exe.run_2802******* 
[INFO] 2021-07-12 19:28:42,303 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:42,304 [run_pretraining.py:  534]:	loss/total_loss, 7.756271839141846, 2803
[INFO] 2021-07-12 19:28:42,304 [run_pretraining.py:  535]:	loss/mlm_loss, 7.756271839141846, 2803
[INFO] 2021-07-12 19:28:42,304 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8020000172546133e-05, 2803
[INFO] 2021-07-12 19:28:42,304 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2803
[INFO] 2021-07-12 19:28:42,304 [run_pretraining.py:  558]:	worker_index: 2, step: 2803, cost: 7.756272, mlm loss: 7.756272, speed: 1.092326 steps/s, speed: 8.738611 samples/s, speed: 4474.168948 tokens/s, learning rate: 2.802e-05, loss_scalings: 2814.750488, pp_loss: 6.347762
[INFO] 2021-07-12 19:28:42,304 [run_pretraining.py:  512]:	********exe.run_2803******* 
[INFO] 2021-07-12 19:28:43,231 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:43,231 [run_pretraining.py:  534]:	loss/total_loss, 7.2625532150268555, 2804
[INFO] 2021-07-12 19:28:43,231 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2625532150268555, 2804
[INFO] 2021-07-12 19:28:43,232 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8029999157297425e-05, 2804
[INFO] 2021-07-12 19:28:43,232 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2804
[INFO] 2021-07-12 19:28:43,232 [run_pretraining.py:  558]:	worker_index: 2, step: 2804, cost: 7.262553, mlm loss: 7.262553, speed: 1.078833 steps/s, speed: 8.630664 samples/s, speed: 4418.899759 tokens/s, learning rate: 2.803e-05, loss_scalings: 2814.750488, pp_loss: 7.209027
[INFO] 2021-07-12 19:28:43,232 [run_pretraining.py:  512]:	********exe.run_2804******* 
[INFO] 2021-07-12 19:28:44,153 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:44,154 [run_pretraining.py:  534]:	loss/total_loss, 7.809365272521973, 2805
[INFO] 2021-07-12 19:28:44,154 [run_pretraining.py:  535]:	loss/mlm_loss, 7.809365272521973, 2805
[INFO] 2021-07-12 19:28:44,154 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.803999996103812e-05, 2805
[INFO] 2021-07-12 19:28:44,154 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2805
[INFO] 2021-07-12 19:28:44,154 [run_pretraining.py:  558]:	worker_index: 2, step: 2805, cost: 7.809365, mlm loss: 7.809365, speed: 1.084922 steps/s, speed: 8.679378 samples/s, speed: 4443.841542 tokens/s, learning rate: 2.804e-05, loss_scalings: 2814.750488, pp_loss: 7.358091
[INFO] 2021-07-12 19:28:44,154 [run_pretraining.py:  512]:	********exe.run_2805******* 
[INFO] 2021-07-12 19:28:45,075 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:45,076 [run_pretraining.py:  534]:	loss/total_loss, 7.315659999847412, 2806
[INFO] 2021-07-12 19:28:45,076 [run_pretraining.py:  535]:	loss/mlm_loss, 7.315659999847412, 2806
[INFO] 2021-07-12 19:28:45,076 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.804999894578941e-05, 2806
[INFO] 2021-07-12 19:28:45,076 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2806
[INFO] 2021-07-12 19:28:45,076 [run_pretraining.py:  558]:	worker_index: 2, step: 2806, cost: 7.315660, mlm loss: 7.315660, speed: 1.085409 steps/s, speed: 8.683270 samples/s, speed: 4445.834466 tokens/s, learning rate: 2.805e-05, loss_scalings: 2814.750488, pp_loss: 7.407355
[INFO] 2021-07-12 19:28:45,076 [run_pretraining.py:  512]:	********exe.run_2806******* 
[INFO] 2021-07-12 19:28:45,989 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:45,990 [run_pretraining.py:  534]:	loss/total_loss, 7.071042060852051, 2807
[INFO] 2021-07-12 19:28:45,990 [run_pretraining.py:  535]:	loss/mlm_loss, 7.071042060852051, 2807
[INFO] 2021-07-12 19:28:45,990 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8059999749530107e-05, 2807
[INFO] 2021-07-12 19:28:45,990 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2807
[INFO] 2021-07-12 19:28:45,990 [run_pretraining.py:  558]:	worker_index: 2, step: 2807, cost: 7.071042, mlm loss: 7.071042, speed: 1.094445 steps/s, speed: 8.755558 samples/s, speed: 4482.845596 tokens/s, learning rate: 2.806e-05, loss_scalings: 2814.750488, pp_loss: 7.354766
[INFO] 2021-07-12 19:28:45,990 [run_pretraining.py:  512]:	********exe.run_2807******* 
[INFO] 2021-07-12 19:28:46,911 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:46,912 [run_pretraining.py:  534]:	loss/total_loss, 7.158706188201904, 2808
[INFO] 2021-07-12 19:28:46,912 [run_pretraining.py:  535]:	loss/mlm_loss, 7.158706188201904, 2808
[INFO] 2021-07-12 19:28:46,912 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.80699987342814e-05, 2808
[INFO] 2021-07-12 19:28:46,912 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2808
[INFO] 2021-07-12 19:28:46,912 [run_pretraining.py:  558]:	worker_index: 2, step: 2808, cost: 7.158706, mlm loss: 7.158706, speed: 1.085585 steps/s, speed: 8.684677 samples/s, speed: 4446.554796 tokens/s, learning rate: 2.807e-05, loss_scalings: 2814.750488, pp_loss: 6.753909
[INFO] 2021-07-12 19:28:46,912 [run_pretraining.py:  512]:	********exe.run_2808******* 
[INFO] 2021-07-12 19:28:47,818 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:47,818 [run_pretraining.py:  534]:	loss/total_loss, 7.524637699127197, 2809
[INFO] 2021-07-12 19:28:47,818 [run_pretraining.py:  535]:	loss/mlm_loss, 7.524637699127197, 2809
[INFO] 2021-07-12 19:28:47,818 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8080001357011497e-05, 2809
[INFO] 2021-07-12 19:28:47,818 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2809
[INFO] 2021-07-12 19:28:47,818 [run_pretraining.py:  558]:	worker_index: 2, step: 2809, cost: 7.524638, mlm loss: 7.524638, speed: 1.103914 steps/s, speed: 8.831311 samples/s, speed: 4521.631006 tokens/s, learning rate: 2.808e-05, loss_scalings: 2814.750488, pp_loss: 7.372530
[INFO] 2021-07-12 19:28:47,819 [run_pretraining.py:  512]:	********exe.run_2809******* 
[INFO] 2021-07-12 19:28:48,736 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:48,737 [run_pretraining.py:  534]:	loss/total_loss, 7.359283447265625, 2810
[INFO] 2021-07-12 19:28:48,737 [run_pretraining.py:  535]:	loss/mlm_loss, 7.359283447265625, 2810
[INFO] 2021-07-12 19:28:48,737 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.809000034176279e-05, 2810
[INFO] 2021-07-12 19:28:48,737 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2810
[INFO] 2021-07-12 19:28:48,737 [run_pretraining.py:  558]:	worker_index: 2, step: 2810, cost: 7.359283, mlm loss: 7.359283, speed: 1.089081 steps/s, speed: 8.712647 samples/s, speed: 4460.875045 tokens/s, learning rate: 2.809e-05, loss_scalings: 2814.750488, pp_loss: 7.566833
[INFO] 2021-07-12 19:28:48,737 [run_pretraining.py:  512]:	********exe.run_2810******* 
[INFO] 2021-07-12 19:28:49,675 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:49,675 [run_pretraining.py:  534]:	loss/total_loss, 7.638635158538818, 2811
[INFO] 2021-07-12 19:28:49,675 [run_pretraining.py:  535]:	loss/mlm_loss, 7.638635158538818, 2811
[INFO] 2021-07-12 19:28:49,676 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8099997507524677e-05, 2811
[INFO] 2021-07-12 19:28:49,676 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2811
[INFO] 2021-07-12 19:28:49,676 [run_pretraining.py:  558]:	worker_index: 2, step: 2811, cost: 7.638635, mlm loss: 7.638635, speed: 1.066283 steps/s, speed: 8.530262 samples/s, speed: 4367.493900 tokens/s, learning rate: 2.810e-05, loss_scalings: 2814.750488, pp_loss: 7.452724
[INFO] 2021-07-12 19:28:49,676 [run_pretraining.py:  512]:	********exe.run_2811******* 
[INFO] 2021-07-12 19:28:50,588 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:50,589 [run_pretraining.py:  534]:	loss/total_loss, 6.876153469085693, 2812
[INFO] 2021-07-12 19:28:50,589 [run_pretraining.py:  535]:	loss/mlm_loss, 6.876153469085693, 2812
[INFO] 2021-07-12 19:28:50,589 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8110000130254775e-05, 2812
[INFO] 2021-07-12 19:28:50,589 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2812
[INFO] 2021-07-12 19:28:50,589 [run_pretraining.py:  558]:	worker_index: 2, step: 2812, cost: 6.876153, mlm loss: 6.876153, speed: 1.095552 steps/s, speed: 8.764413 samples/s, speed: 4487.379393 tokens/s, learning rate: 2.811e-05, loss_scalings: 2814.750488, pp_loss: 6.717067
[INFO] 2021-07-12 19:28:50,589 [run_pretraining.py:  512]:	********exe.run_2812******* 
[INFO] 2021-07-12 19:28:51,503 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:51,503 [run_pretraining.py:  534]:	loss/total_loss, 8.025568008422852, 2813
[INFO] 2021-07-12 19:28:51,503 [run_pretraining.py:  535]:	loss/mlm_loss, 8.025568008422852, 2813
[INFO] 2021-07-12 19:28:51,503 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8119999115006067e-05, 2813
[INFO] 2021-07-12 19:28:51,504 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2813
[INFO] 2021-07-12 19:28:51,504 [run_pretraining.py:  558]:	worker_index: 2, step: 2813, cost: 8.025568, mlm loss: 8.025568, speed: 1.094258 steps/s, speed: 8.754066 samples/s, speed: 4482.081889 tokens/s, learning rate: 2.812e-05, loss_scalings: 2814.750488, pp_loss: 7.424360
[INFO] 2021-07-12 19:28:51,504 [run_pretraining.py:  512]:	********exe.run_2813******* 
[INFO] 2021-07-12 19:28:52,427 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:52,428 [run_pretraining.py:  534]:	loss/total_loss, 6.902873516082764, 2814
[INFO] 2021-07-12 19:28:52,428 [run_pretraining.py:  535]:	loss/mlm_loss, 6.902873516082764, 2814
[INFO] 2021-07-12 19:28:52,428 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8129999918746762e-05, 2814
[INFO] 2021-07-12 19:28:52,428 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2814
[INFO] 2021-07-12 19:28:52,428 [run_pretraining.py:  558]:	worker_index: 2, step: 2814, cost: 6.902874, mlm loss: 6.902874, speed: 1.082294 steps/s, speed: 8.658350 samples/s, speed: 4433.075325 tokens/s, learning rate: 2.813e-05, loss_scalings: 2814.750488, pp_loss: 7.456597
[INFO] 2021-07-12 19:28:52,428 [run_pretraining.py:  512]:	********exe.run_2814******* 
[INFO] 2021-07-12 19:28:53,356 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:53,357 [run_pretraining.py:  534]:	loss/total_loss, 7.3112592697143555, 2815
[INFO] 2021-07-12 19:28:53,357 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3112592697143555, 2815
[INFO] 2021-07-12 19:28:53,357 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8139998903498054e-05, 2815
[INFO] 2021-07-12 19:28:53,357 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2815
[INFO] 2021-07-12 19:28:53,357 [run_pretraining.py:  558]:	worker_index: 2, step: 2815, cost: 7.311259, mlm loss: 7.311259, speed: 1.077220 steps/s, speed: 8.617756 samples/s, speed: 4412.291223 tokens/s, learning rate: 2.814e-05, loss_scalings: 2814.750488, pp_loss: 7.296898
[INFO] 2021-07-12 19:28:53,357 [run_pretraining.py:  512]:	********exe.run_2815******* 
[INFO] 2021-07-12 19:28:54,275 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:54,276 [run_pretraining.py:  534]:	loss/total_loss, 7.1260271072387695, 2816
[INFO] 2021-07-12 19:28:54,276 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1260271072387695, 2816
[INFO] 2021-07-12 19:28:54,276 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.814999970723875e-05, 2816
[INFO] 2021-07-12 19:28:54,276 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2816
[INFO] 2021-07-12 19:28:54,276 [run_pretraining.py:  558]:	worker_index: 2, step: 2816, cost: 7.126027, mlm loss: 7.126027, speed: 1.088974 steps/s, speed: 8.711792 samples/s, speed: 4460.437252 tokens/s, learning rate: 2.815e-05, loss_scalings: 2814.750488, pp_loss: 7.096739
[INFO] 2021-07-12 19:28:54,276 [run_pretraining.py:  512]:	********exe.run_2816******* 
[INFO] 2021-07-12 19:28:55,190 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:55,190 [run_pretraining.py:  534]:	loss/total_loss, 7.57326078414917, 2817
[INFO] 2021-07-12 19:28:55,190 [run_pretraining.py:  535]:	loss/mlm_loss, 7.57326078414917, 2817
[INFO] 2021-07-12 19:28:55,190 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.815999869199004e-05, 2817
[INFO] 2021-07-12 19:28:55,190 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2817
[INFO] 2021-07-12 19:28:55,190 [run_pretraining.py:  558]:	worker_index: 2, step: 2817, cost: 7.573261, mlm loss: 7.573261, speed: 1.094169 steps/s, speed: 8.753356 samples/s, speed: 4481.718255 tokens/s, learning rate: 2.816e-05, loss_scalings: 2814.750488, pp_loss: 7.462143
[INFO] 2021-07-12 19:28:55,191 [run_pretraining.py:  512]:	********exe.run_2817******* 
[INFO] 2021-07-12 19:28:56,099 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:56,099 [run_pretraining.py:  534]:	loss/total_loss, 7.946171760559082, 2818
[INFO] 2021-07-12 19:28:56,099 [run_pretraining.py:  535]:	loss/mlm_loss, 7.946171760559082, 2818
[INFO] 2021-07-12 19:28:56,099 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8169997676741332e-05, 2818
[INFO] 2021-07-12 19:28:56,100 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2818
[INFO] 2021-07-12 19:28:56,100 [run_pretraining.py:  558]:	worker_index: 2, step: 2818, cost: 7.946172, mlm loss: 7.946172, speed: 1.100677 steps/s, speed: 8.805419 samples/s, speed: 4508.374588 tokens/s, learning rate: 2.817e-05, loss_scalings: 2814.750488, pp_loss: 7.504036
[INFO] 2021-07-12 19:28:56,100 [run_pretraining.py:  512]:	********exe.run_2818******* 
[INFO] 2021-07-12 19:28:57,018 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:57,019 [run_pretraining.py:  534]:	loss/total_loss, 7.346819877624512, 2819
[INFO] 2021-07-12 19:28:57,019 [run_pretraining.py:  535]:	loss/mlm_loss, 7.346819877624512, 2819
[INFO] 2021-07-12 19:28:57,019 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.818000029947143e-05, 2819
[INFO] 2021-07-12 19:28:57,019 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2819
[INFO] 2021-07-12 19:28:57,019 [run_pretraining.py:  558]:	worker_index: 2, step: 2819, cost: 7.346820, mlm loss: 7.346820, speed: 1.088131 steps/s, speed: 8.705045 samples/s, speed: 4456.983088 tokens/s, learning rate: 2.818e-05, loss_scalings: 2814.750488, pp_loss: 7.217619
[INFO] 2021-07-12 19:28:57,019 [run_pretraining.py:  512]:	********exe.run_2819******* 
[INFO] 2021-07-12 19:28:57,942 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:57,942 [run_pretraining.py:  534]:	loss/total_loss, 7.047390937805176, 2820
[INFO] 2021-07-12 19:28:57,943 [run_pretraining.py:  535]:	loss/mlm_loss, 7.047390937805176, 2820
[INFO] 2021-07-12 19:28:57,943 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.818999746523332e-05, 2820
[INFO] 2021-07-12 19:28:57,943 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2820
[INFO] 2021-07-12 19:28:57,943 [run_pretraining.py:  558]:	worker_index: 2, step: 2820, cost: 7.047391, mlm loss: 7.047391, speed: 1.083500 steps/s, speed: 8.667997 samples/s, speed: 4438.014488 tokens/s, learning rate: 2.819e-05, loss_scalings: 2814.750488, pp_loss: 7.269431
[INFO] 2021-07-12 19:28:57,943 [run_pretraining.py:  512]:	********exe.run_2820******* 
[INFO] 2021-07-12 19:28:58,862 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:58,863 [run_pretraining.py:  534]:	loss/total_loss, 6.614408493041992, 2821
[INFO] 2021-07-12 19:28:58,863 [run_pretraining.py:  535]:	loss/mlm_loss, 6.614408493041992, 2821
[INFO] 2021-07-12 19:28:58,863 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8200000087963417e-05, 2821
[INFO] 2021-07-12 19:28:58,863 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2821
[INFO] 2021-07-12 19:28:58,863 [run_pretraining.py:  558]:	worker_index: 2, step: 2821, cost: 6.614408, mlm loss: 6.614408, speed: 1.087361 steps/s, speed: 8.698886 samples/s, speed: 4453.829839 tokens/s, learning rate: 2.820e-05, loss_scalings: 2814.750488, pp_loss: 7.290394
[INFO] 2021-07-12 19:28:58,863 [run_pretraining.py:  512]:	********exe.run_2821******* 
[INFO] 2021-07-12 19:28:59,784 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:59,784 [run_pretraining.py:  534]:	loss/total_loss, 7.636336326599121, 2822
[INFO] 2021-07-12 19:28:59,784 [run_pretraining.py:  535]:	loss/mlm_loss, 7.636336326599121, 2822
[INFO] 2021-07-12 19:28:59,784 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.820999907271471e-05, 2822
[INFO] 2021-07-12 19:28:59,784 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2822
[INFO] 2021-07-12 19:28:59,784 [run_pretraining.py:  558]:	worker_index: 2, step: 2822, cost: 7.636336, mlm loss: 7.636336, speed: 1.085921 steps/s, speed: 8.687369 samples/s, speed: 4447.932818 tokens/s, learning rate: 2.821e-05, loss_scalings: 2814.750488, pp_loss: 7.278284
[INFO] 2021-07-12 19:28:59,785 [run_pretraining.py:  512]:	********exe.run_2822******* 
[INFO] 2021-07-12 19:29:00,688 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:00,689 [run_pretraining.py:  534]:	loss/total_loss, 7.573360919952393, 2823
[INFO] 2021-07-12 19:29:00,689 [run_pretraining.py:  535]:	loss/mlm_loss, 7.573360919952393, 2823
[INFO] 2021-07-12 19:29:00,689 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8219999876455404e-05, 2823
[INFO] 2021-07-12 19:29:00,689 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2823
[INFO] 2021-07-12 19:29:00,689 [run_pretraining.py:  558]:	worker_index: 2, step: 2823, cost: 7.573361, mlm loss: 7.573361, speed: 1.105987 steps/s, speed: 8.847898 samples/s, speed: 4530.123755 tokens/s, learning rate: 2.822e-05, loss_scalings: 2814.750488, pp_loss: 7.014003
[INFO] 2021-07-12 19:29:00,689 [run_pretraining.py:  512]:	********exe.run_2823******* 
[INFO] 2021-07-12 19:29:01,596 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:01,596 [run_pretraining.py:  534]:	loss/total_loss, 6.432896614074707, 2824
[INFO] 2021-07-12 19:29:01,596 [run_pretraining.py:  535]:	loss/mlm_loss, 6.432896614074707, 2824
[INFO] 2021-07-12 19:29:01,596 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8229998861206695e-05, 2824
[INFO] 2021-07-12 19:29:01,596 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2824
[INFO] 2021-07-12 19:29:01,596 [run_pretraining.py:  558]:	worker_index: 2, step: 2824, cost: 6.432897, mlm loss: 6.432897, speed: 1.103075 steps/s, speed: 8.824603 samples/s, speed: 4518.196711 tokens/s, learning rate: 2.823e-05, loss_scalings: 2814.750488, pp_loss: 6.906325
[INFO] 2021-07-12 19:29:01,596 [run_pretraining.py:  512]:	********exe.run_2824******* 
[INFO] 2021-07-12 19:29:02,513 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:02,513 [run_pretraining.py:  534]:	loss/total_loss, 7.638916492462158, 2825
[INFO] 2021-07-12 19:29:02,513 [run_pretraining.py:  535]:	loss/mlm_loss, 7.638916492462158, 2825
[INFO] 2021-07-12 19:29:02,514 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.823999966494739e-05, 2825
[INFO] 2021-07-12 19:29:02,514 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2825
[INFO] 2021-07-12 19:29:02,514 [run_pretraining.py:  558]:	worker_index: 2, step: 2825, cost: 7.638916, mlm loss: 7.638916, speed: 1.090853 steps/s, speed: 8.726827 samples/s, speed: 4468.135471 tokens/s, learning rate: 2.824e-05, loss_scalings: 2814.750488, pp_loss: 6.708974
[INFO] 2021-07-12 19:29:02,514 [run_pretraining.py:  512]:	********exe.run_2825******* 
[INFO] 2021-07-12 19:29:03,423 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:03,423 [run_pretraining.py:  534]:	loss/total_loss, 7.87739372253418, 2826
[INFO] 2021-07-12 19:29:03,423 [run_pretraining.py:  535]:	loss/mlm_loss, 7.87739372253418, 2826
[INFO] 2021-07-12 19:29:03,423 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8249998649698682e-05, 2826
[INFO] 2021-07-12 19:29:03,423 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2826
[INFO] 2021-07-12 19:29:03,424 [run_pretraining.py:  558]:	worker_index: 2, step: 2826, cost: 7.877394, mlm loss: 7.877394, speed: 1.099860 steps/s, speed: 8.798882 samples/s, speed: 4505.027729 tokens/s, learning rate: 2.825e-05, loss_scalings: 2814.750488, pp_loss: 7.548574
[INFO] 2021-07-12 19:29:03,424 [run_pretraining.py:  512]:	********exe.run_2826******* 
[INFO] 2021-07-12 19:29:04,330 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:04,330 [run_pretraining.py:  534]:	loss/total_loss, 4.831197738647461, 2827
[INFO] 2021-07-12 19:29:04,330 [run_pretraining.py:  535]:	loss/mlm_loss, 4.831197738647461, 2827
[INFO] 2021-07-12 19:29:04,330 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8259997634449974e-05, 2827
[INFO] 2021-07-12 19:29:04,331 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2827
[INFO] 2021-07-12 19:29:04,331 [run_pretraining.py:  558]:	worker_index: 2, step: 2827, cost: 4.831198, mlm loss: 4.831198, speed: 1.103128 steps/s, speed: 8.825025 samples/s, speed: 4518.412985 tokens/s, learning rate: 2.826e-05, loss_scalings: 2814.750488, pp_loss: 6.514647
[INFO] 2021-07-12 19:29:04,331 [run_pretraining.py:  512]:	********exe.run_2827******* 
[INFO] 2021-07-12 19:29:05,249 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:05,250 [run_pretraining.py:  534]:	loss/total_loss, 7.345110893249512, 2828
[INFO] 2021-07-12 19:29:05,250 [run_pretraining.py:  535]:	loss/mlm_loss, 7.345110893249512, 2828
[INFO] 2021-07-12 19:29:05,250 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8270000257180072e-05, 2828
[INFO] 2021-07-12 19:29:05,250 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2828
[INFO] 2021-07-12 19:29:05,250 [run_pretraining.py:  558]:	worker_index: 2, step: 2828, cost: 7.345111, mlm loss: 7.345111, speed: 1.088206 steps/s, speed: 8.705648 samples/s, speed: 4457.291836 tokens/s, learning rate: 2.827e-05, loss_scalings: 2814.750488, pp_loss: 7.086532
[INFO] 2021-07-12 19:29:05,250 [run_pretraining.py:  512]:	********exe.run_2828******* 
[INFO] 2021-07-12 19:29:06,165 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:06,166 [run_pretraining.py:  534]:	loss/total_loss, 7.219363212585449, 2829
[INFO] 2021-07-12 19:29:06,166 [run_pretraining.py:  535]:	loss/mlm_loss, 7.219363212585449, 2829
[INFO] 2021-07-12 19:29:06,166 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.827999742294196e-05, 2829
[INFO] 2021-07-12 19:29:06,166 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2829
[INFO] 2021-07-12 19:29:06,166 [run_pretraining.py:  558]:	worker_index: 2, step: 2829, cost: 7.219363, mlm loss: 7.219363, speed: 1.092608 steps/s, speed: 8.740867 samples/s, speed: 4475.323971 tokens/s, learning rate: 2.828e-05, loss_scalings: 2814.750488, pp_loss: 6.454474
[INFO] 2021-07-12 19:29:06,166 [run_pretraining.py:  512]:	********exe.run_2829******* 
[INFO] 2021-07-12 19:29:07,085 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:07,085 [run_pretraining.py:  534]:	loss/total_loss, 6.793540954589844, 2830
[INFO] 2021-07-12 19:29:07,085 [run_pretraining.py:  535]:	loss/mlm_loss, 6.793540954589844, 2830
[INFO] 2021-07-12 19:29:07,085 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.829000004567206e-05, 2830
[INFO] 2021-07-12 19:29:07,085 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2830
[INFO] 2021-07-12 19:29:07,085 [run_pretraining.py:  558]:	worker_index: 2, step: 2830, cost: 6.793541, mlm loss: 6.793541, speed: 1.088264 steps/s, speed: 8.706116 samples/s, speed: 4457.531231 tokens/s, learning rate: 2.829e-05, loss_scalings: 2814.750488, pp_loss: 6.959720
[INFO] 2021-07-12 19:29:07,086 [run_pretraining.py:  512]:	********exe.run_2830******* 
[INFO] 2021-07-12 19:29:08,021 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:08,021 [run_pretraining.py:  534]:	loss/total_loss, 6.6188578605651855, 2831
[INFO] 2021-07-12 19:29:08,021 [run_pretraining.py:  535]:	loss/mlm_loss, 6.6188578605651855, 2831
[INFO] 2021-07-12 19:29:08,021 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.829999903042335e-05, 2831
[INFO] 2021-07-12 19:29:08,021 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2831
[INFO] 2021-07-12 19:29:08,021 [run_pretraining.py:  558]:	worker_index: 2, step: 2831, cost: 6.618858, mlm loss: 6.618858, speed: 1.069230 steps/s, speed: 8.553836 samples/s, speed: 4379.564050 tokens/s, learning rate: 2.830e-05, loss_scalings: 2814.750488, pp_loss: 6.854814
[INFO] 2021-07-12 19:29:08,021 [run_pretraining.py:  512]:	********exe.run_2831******* 
[INFO] 2021-07-12 19:29:09,087 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:09,087 [run_pretraining.py:  534]:	loss/total_loss, 6.798242568969727, 2832
[INFO] 2021-07-12 19:29:09,088 [run_pretraining.py:  535]:	loss/mlm_loss, 6.798242568969727, 2832
[INFO] 2021-07-12 19:29:09,088 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8309999834164046e-05, 2832
[INFO] 2021-07-12 19:29:09,088 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2832
[INFO] 2021-07-12 19:29:09,088 [run_pretraining.py:  558]:	worker_index: 2, step: 2832, cost: 6.798243, mlm loss: 6.798243, speed: 0.938159 steps/s, speed: 7.505275 samples/s, speed: 3842.700644 tokens/s, learning rate: 2.831e-05, loss_scalings: 2814.750488, pp_loss: 7.282659
[INFO] 2021-07-12 19:29:09,088 [run_pretraining.py:  512]:	********exe.run_2832******* 
[INFO] 2021-07-12 19:29:10,148 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:10,148 [run_pretraining.py:  534]:	loss/total_loss, 6.9308671951293945, 2833
[INFO] 2021-07-12 19:29:10,148 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9308671951293945, 2833
[INFO] 2021-07-12 19:29:10,148 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8319998818915337e-05, 2833
[INFO] 2021-07-12 19:29:10,149 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2833
[INFO] 2021-07-12 19:29:10,149 [run_pretraining.py:  558]:	worker_index: 2, step: 2833, cost: 6.930867, mlm loss: 6.930867, speed: 0.943264 steps/s, speed: 7.546111 samples/s, speed: 3863.608886 tokens/s, learning rate: 2.832e-05, loss_scalings: 2814.750488, pp_loss: 7.253405
[INFO] 2021-07-12 19:29:10,149 [run_pretraining.py:  512]:	********exe.run_2833******* 
[INFO] 2021-07-12 19:29:11,211 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:11,212 [run_pretraining.py:  534]:	loss/total_loss, 7.092594146728516, 2834
[INFO] 2021-07-12 19:29:11,212 [run_pretraining.py:  535]:	loss/mlm_loss, 7.092594146728516, 2834
[INFO] 2021-07-12 19:29:11,212 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8329999622656032e-05, 2834
[INFO] 2021-07-12 19:29:11,212 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2834
[INFO] 2021-07-12 19:29:11,212 [run_pretraining.py:  558]:	worker_index: 2, step: 2834, cost: 7.092594, mlm loss: 7.092594, speed: 0.940762 steps/s, speed: 7.526095 samples/s, speed: 3853.360610 tokens/s, learning rate: 2.833e-05, loss_scalings: 2814.750488, pp_loss: 7.187354
[INFO] 2021-07-12 19:29:11,212 [run_pretraining.py:  512]:	********exe.run_2834******* 
[INFO] 2021-07-12 19:29:12,270 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:12,271 [run_pretraining.py:  534]:	loss/total_loss, 7.781184196472168, 2835
[INFO] 2021-07-12 19:29:12,271 [run_pretraining.py:  535]:	loss/mlm_loss, 7.781184196472168, 2835
[INFO] 2021-07-12 19:29:12,271 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8339998607407324e-05, 2835
[INFO] 2021-07-12 19:29:12,271 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2835
[INFO] 2021-07-12 19:29:12,271 [run_pretraining.py:  558]:	worker_index: 2, step: 2835, cost: 7.781184, mlm loss: 7.781184, speed: 0.944826 steps/s, speed: 7.558607 samples/s, speed: 3870.006698 tokens/s, learning rate: 2.834e-05, loss_scalings: 2814.750488, pp_loss: 7.356153
[INFO] 2021-07-12 19:29:12,271 [run_pretraining.py:  512]:	********exe.run_2835******* 
[INFO] 2021-07-12 19:29:13,318 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:13,318 [run_pretraining.py:  534]:	loss/total_loss, 7.740699768066406, 2836
[INFO] 2021-07-12 19:29:13,318 [run_pretraining.py:  535]:	loss/mlm_loss, 7.740699768066406, 2836
[INFO] 2021-07-12 19:29:13,319 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8349997592158616e-05, 2836
[INFO] 2021-07-12 19:29:13,319 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2836
[INFO] 2021-07-12 19:29:13,319 [run_pretraining.py:  558]:	worker_index: 2, step: 2836, cost: 7.740700, mlm loss: 7.740700, speed: 0.955180 steps/s, speed: 7.641438 samples/s, speed: 3912.416137 tokens/s, learning rate: 2.835e-05, loss_scalings: 2814.750488, pp_loss: 7.268268
[INFO] 2021-07-12 19:29:13,319 [run_pretraining.py:  512]:	********exe.run_2836******* 
[INFO] 2021-07-12 19:29:14,374 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:14,374 [run_pretraining.py:  534]:	loss/total_loss, 11.313631057739258, 2837
[INFO] 2021-07-12 19:29:14,374 [run_pretraining.py:  535]:	loss/mlm_loss, 11.313631057739258, 2837
[INFO] 2021-07-12 19:29:14,374 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8360000214888714e-05, 2837
[INFO] 2021-07-12 19:29:14,374 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2837
[INFO] 2021-07-12 19:29:14,375 [run_pretraining.py:  558]:	worker_index: 2, step: 2837, cost: 11.313631, mlm loss: 11.313631, speed: 0.947660 steps/s, speed: 7.581279 samples/s, speed: 3881.615077 tokens/s, learning rate: 2.836e-05, loss_scalings: 2814.750488, pp_loss: 8.243334
[INFO] 2021-07-12 19:29:14,375 [run_pretraining.py:  512]:	********exe.run_2837******* 
[INFO] 2021-07-12 19:29:15,439 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:15,439 [run_pretraining.py:  534]:	loss/total_loss, 8.16777229309082, 2838
[INFO] 2021-07-12 19:29:15,439 [run_pretraining.py:  535]:	loss/mlm_loss, 8.16777229309082, 2838
[INFO] 2021-07-12 19:29:15,439 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8369997380650602e-05, 2838
[INFO] 2021-07-12 19:29:15,439 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2838
[INFO] 2021-07-12 19:29:15,440 [run_pretraining.py:  558]:	worker_index: 2, step: 2838, cost: 8.167772, mlm loss: 8.167772, speed: 0.939458 steps/s, speed: 7.515660 samples/s, speed: 3848.018073 tokens/s, learning rate: 2.837e-05, loss_scalings: 2814.750488, pp_loss: 7.734100
[INFO] 2021-07-12 19:29:15,440 [run_pretraining.py:  512]:	********exe.run_2838******* 
[INFO] 2021-07-12 19:29:16,509 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:16,510 [run_pretraining.py:  534]:	loss/total_loss, 7.875458717346191, 2839
[INFO] 2021-07-12 19:29:16,510 [run_pretraining.py:  535]:	loss/mlm_loss, 7.875458717346191, 2839
[INFO] 2021-07-12 19:29:16,510 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.83800000033807e-05, 2839
[INFO] 2021-07-12 19:29:16,510 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2839
[INFO] 2021-07-12 19:29:16,510 [run_pretraining.py:  558]:	worker_index: 2, step: 2839, cost: 7.875459, mlm loss: 7.875459, speed: 0.934696 steps/s, speed: 7.477566 samples/s, speed: 3828.513637 tokens/s, learning rate: 2.838e-05, loss_scalings: 2814.750488, pp_loss: 6.907633
[INFO] 2021-07-12 19:29:16,510 [run_pretraining.py:  512]:	********exe.run_2839******* 
[INFO] 2021-07-12 19:29:17,573 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:17,573 [run_pretraining.py:  534]:	loss/total_loss, 6.9281415939331055, 2840
[INFO] 2021-07-12 19:29:17,573 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9281415939331055, 2840
[INFO] 2021-07-12 19:29:17,574 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8389998988131993e-05, 2840
[INFO] 2021-07-12 19:29:17,574 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2840
[INFO] 2021-07-12 19:29:17,574 [run_pretraining.py:  558]:	worker_index: 2, step: 2840, cost: 6.928142, mlm loss: 6.928142, speed: 0.940681 steps/s, speed: 7.525448 samples/s, speed: 3853.029615 tokens/s, learning rate: 2.839e-05, loss_scalings: 2814.750488, pp_loss: 7.302762
[INFO] 2021-07-12 19:29:17,574 [run_pretraining.py:  512]:	********exe.run_2840******* 
[INFO] 2021-07-12 19:29:18,634 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:18,634 [run_pretraining.py:  534]:	loss/total_loss, 7.167132377624512, 2841
[INFO] 2021-07-12 19:29:18,634 [run_pretraining.py:  535]:	loss/mlm_loss, 7.167132377624512, 2841
[INFO] 2021-07-12 19:29:18,635 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8399999791872688e-05, 2841
[INFO] 2021-07-12 19:29:18,635 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2841
[INFO] 2021-07-12 19:29:18,635 [run_pretraining.py:  558]:	worker_index: 2, step: 2841, cost: 7.167132, mlm loss: 7.167132, speed: 0.942992 steps/s, speed: 7.543933 samples/s, speed: 3862.493549 tokens/s, learning rate: 2.840e-05, loss_scalings: 2814.750488, pp_loss: 7.236348
[INFO] 2021-07-12 19:29:18,635 [run_pretraining.py:  512]:	********exe.run_2841******* 
[INFO] 2021-07-12 19:29:19,714 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:19,714 [run_pretraining.py:  534]:	loss/total_loss, 4.564271926879883, 2842
[INFO] 2021-07-12 19:29:19,714 [run_pretraining.py:  535]:	loss/mlm_loss, 4.564271926879883, 2842
[INFO] 2021-07-12 19:29:19,714 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.840999877662398e-05, 2842
[INFO] 2021-07-12 19:29:19,714 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2842
[INFO] 2021-07-12 19:29:19,715 [run_pretraining.py:  558]:	worker_index: 2, step: 2842, cost: 4.564272, mlm loss: 4.564272, speed: 0.926601 steps/s, speed: 7.412811 samples/s, speed: 3795.359460 tokens/s, learning rate: 2.841e-05, loss_scalings: 2814.750488, pp_loss: 5.478559
[INFO] 2021-07-12 19:29:19,715 [run_pretraining.py:  512]:	********exe.run_2842******* 
[INFO] 2021-07-12 19:29:20,634 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:20,634 [run_pretraining.py:  534]:	loss/total_loss, 6.749283790588379, 2843
[INFO] 2021-07-12 19:29:20,635 [run_pretraining.py:  535]:	loss/mlm_loss, 6.749283790588379, 2843
[INFO] 2021-07-12 19:29:20,635 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8420001399354078e-05, 2843
[INFO] 2021-07-12 19:29:20,635 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2843
[INFO] 2021-07-12 19:29:20,635 [run_pretraining.py:  558]:	worker_index: 2, step: 2843, cost: 6.749284, mlm loss: 6.749284, speed: 1.087324 steps/s, speed: 8.698595 samples/s, speed: 4453.680895 tokens/s, learning rate: 2.842e-05, loss_scalings: 2814.750488, pp_loss: 7.208074
[INFO] 2021-07-12 19:29:20,635 [run_pretraining.py:  512]:	********exe.run_2843******* 
[INFO] 2021-07-12 19:29:21,557 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:21,558 [run_pretraining.py:  534]:	loss/total_loss, 7.5597991943359375, 2844
[INFO] 2021-07-12 19:29:21,558 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5597991943359375, 2844
[INFO] 2021-07-12 19:29:21,558 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8429998565115966e-05, 2844
[INFO] 2021-07-12 19:29:21,558 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2844
[INFO] 2021-07-12 19:29:21,558 [run_pretraining.py:  558]:	worker_index: 2, step: 2844, cost: 7.559799, mlm loss: 7.559799, speed: 1.083837 steps/s, speed: 8.670698 samples/s, speed: 4439.397546 tokens/s, learning rate: 2.843e-05, loss_scalings: 2814.750488, pp_loss: 7.340345
[INFO] 2021-07-12 19:29:21,558 [run_pretraining.py:  512]:	********exe.run_2844******* 
[INFO] 2021-07-12 19:29:22,485 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:22,495 [run_pretraining.py:  534]:	loss/total_loss, 7.456286430358887, 2845
[INFO] 2021-07-12 19:29:22,497 [run_pretraining.py:  535]:	loss/mlm_loss, 7.456286430358887, 2845
[INFO] 2021-07-12 19:29:22,501 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8439997549867257e-05, 2845
[INFO] 2021-07-12 19:29:22,502 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2845
[INFO] 2021-07-12 19:29:22,514 [run_pretraining.py:  558]:	worker_index: 2, step: 2845, cost: 7.456286, mlm loss: 7.456286, speed: 1.067883 steps/s, speed: 8.543064 samples/s, speed: 4374.049009 tokens/s, learning rate: 2.844e-05, loss_scalings: 2814.750488, pp_loss: 7.550748
[INFO] 2021-07-12 19:29:22,520 [run_pretraining.py:  512]:	********exe.run_2845******* 
[INFO] 2021-07-12 19:29:23,411 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:23,412 [run_pretraining.py:  534]:	loss/total_loss, 7.111567497253418, 2846
[INFO] 2021-07-12 19:29:23,412 [run_pretraining.py:  535]:	loss/mlm_loss, 7.111567497253418, 2846
[INFO] 2021-07-12 19:29:23,412 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8450000172597356e-05, 2846
[INFO] 2021-07-12 19:29:23,412 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2846
[INFO] 2021-07-12 19:29:23,412 [run_pretraining.py:  558]:	worker_index: 2, step: 2846, cost: 7.111567, mlm loss: 7.111567, speed: 1.121324 steps/s, speed: 8.970596 samples/s, speed: 4592.944933 tokens/s, learning rate: 2.845e-05, loss_scalings: 2814.750488, pp_loss: 6.940639
[INFO] 2021-07-12 19:29:23,412 [run_pretraining.py:  512]:	********exe.run_2846******* 
[INFO] 2021-07-12 19:29:24,327 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:24,328 [run_pretraining.py:  534]:	loss/total_loss, 7.209410667419434, 2847
[INFO] 2021-07-12 19:29:24,328 [run_pretraining.py:  535]:	loss/mlm_loss, 7.209410667419434, 2847
[INFO] 2021-07-12 19:29:24,328 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8459997338359244e-05, 2847
[INFO] 2021-07-12 19:29:24,328 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2847
[INFO] 2021-07-12 19:29:24,328 [run_pretraining.py:  558]:	worker_index: 2, step: 2847, cost: 7.209411, mlm loss: 7.209411, speed: 1.092327 steps/s, speed: 8.738618 samples/s, speed: 4474.172443 tokens/s, learning rate: 2.846e-05, loss_scalings: 2814.750488, pp_loss: 6.556793
[INFO] 2021-07-12 19:29:24,328 [run_pretraining.py:  512]:	********exe.run_2847******* 
[INFO] 2021-07-12 19:29:25,377 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:25,377 [run_pretraining.py:  534]:	loss/total_loss, 7.272398471832275, 2848
[INFO] 2021-07-12 19:29:25,377 [run_pretraining.py:  535]:	loss/mlm_loss, 7.272398471832275, 2848
[INFO] 2021-07-12 19:29:25,377 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8469999961089343e-05, 2848
[INFO] 2021-07-12 19:29:25,377 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2848
[INFO] 2021-07-12 19:29:25,377 [run_pretraining.py:  558]:	worker_index: 2, step: 2848, cost: 7.272398, mlm loss: 7.272398, speed: 0.953639 steps/s, speed: 7.629113 samples/s, speed: 3906.105686 tokens/s, learning rate: 2.847e-05, loss_scalings: 2814.750488, pp_loss: 6.327618
[INFO] 2021-07-12 19:29:25,378 [run_pretraining.py:  512]:	********exe.run_2848******* 
[INFO] 2021-07-12 19:29:26,292 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:26,292 [run_pretraining.py:  534]:	loss/total_loss, 7.1453094482421875, 2849
[INFO] 2021-07-12 19:29:26,292 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1453094482421875, 2849
[INFO] 2021-07-12 19:29:26,293 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8479998945840634e-05, 2849
[INFO] 2021-07-12 19:29:26,293 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2849
[INFO] 2021-07-12 19:29:26,293 [run_pretraining.py:  558]:	worker_index: 2, step: 2849, cost: 7.145309, mlm loss: 7.145309, speed: 1.093387 steps/s, speed: 8.747097 samples/s, speed: 4478.513577 tokens/s, learning rate: 2.848e-05, loss_scalings: 2814.750488, pp_loss: 7.088332
[INFO] 2021-07-12 19:29:26,293 [run_pretraining.py:  512]:	********exe.run_2849******* 
[INFO] 2021-07-12 19:29:27,212 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:27,212 [run_pretraining.py:  534]:	loss/total_loss, 6.867560863494873, 2850
[INFO] 2021-07-12 19:29:27,212 [run_pretraining.py:  535]:	loss/mlm_loss, 6.867560863494873, 2850
[INFO] 2021-07-12 19:29:27,213 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.848999974958133e-05, 2850
[INFO] 2021-07-12 19:29:27,213 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2850
[INFO] 2021-07-12 19:29:27,213 [run_pretraining.py:  558]:	worker_index: 2, step: 2850, cost: 6.867561, mlm loss: 6.867561, speed: 1.087654 steps/s, speed: 8.701235 samples/s, speed: 4455.032146 tokens/s, learning rate: 2.849e-05, loss_scalings: 2814.750488, pp_loss: 7.176730
[INFO] 2021-07-12 19:29:27,213 [run_pretraining.py:  512]:	********exe.run_2850******* 
[INFO] 2021-07-12 19:29:28,133 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:28,134 [run_pretraining.py:  534]:	loss/total_loss, 7.8517889976501465, 2851
[INFO] 2021-07-12 19:29:28,134 [run_pretraining.py:  535]:	loss/mlm_loss, 7.8517889976501465, 2851
[INFO] 2021-07-12 19:29:28,134 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.849999873433262e-05, 2851
[INFO] 2021-07-12 19:29:28,134 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2851
[INFO] 2021-07-12 19:29:28,134 [run_pretraining.py:  558]:	worker_index: 2, step: 2851, cost: 7.851789, mlm loss: 7.851789, speed: 1.086016 steps/s, speed: 8.688125 samples/s, speed: 4448.319784 tokens/s, learning rate: 2.850e-05, loss_scalings: 2814.750488, pp_loss: 7.609977
[INFO] 2021-07-12 19:29:28,134 [run_pretraining.py:  512]:	********exe.run_2851******* 
[INFO] 2021-07-12 19:29:29,053 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:29,054 [run_pretraining.py:  534]:	loss/total_loss, 7.272567272186279, 2852
[INFO] 2021-07-12 19:29:29,054 [run_pretraining.py:  535]:	loss/mlm_loss, 7.272567272186279, 2852
[INFO] 2021-07-12 19:29:29,054 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.851000135706272e-05, 2852
[INFO] 2021-07-12 19:29:29,054 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2852
[INFO] 2021-07-12 19:29:29,054 [run_pretraining.py:  558]:	worker_index: 2, step: 2852, cost: 7.272567, mlm loss: 7.272567, speed: 1.087723 steps/s, speed: 8.701788 samples/s, speed: 4455.315204 tokens/s, learning rate: 2.851e-05, loss_scalings: 2814.750488, pp_loss: 7.034562
[INFO] 2021-07-12 19:29:29,054 [run_pretraining.py:  512]:	********exe.run_2852******* 
[INFO] 2021-07-12 19:29:30,086 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:30,086 [run_pretraining.py:  534]:	loss/total_loss, 7.937244415283203, 2853
[INFO] 2021-07-12 19:29:30,086 [run_pretraining.py:  535]:	loss/mlm_loss, 7.937244415283203, 2853
[INFO] 2021-07-12 19:29:30,086 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8519998522824608e-05, 2853
[INFO] 2021-07-12 19:29:30,086 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2853
[INFO] 2021-07-12 19:29:30,086 [run_pretraining.py:  558]:	worker_index: 2, step: 2853, cost: 7.937244, mlm loss: 7.937244, speed: 0.969199 steps/s, speed: 7.753591 samples/s, speed: 3969.838514 tokens/s, learning rate: 2.852e-05, loss_scalings: 2814.750488, pp_loss: 7.171909
[INFO] 2021-07-12 19:29:30,086 [run_pretraining.py:  512]:	********exe.run_2853******* 
[INFO] 2021-07-12 19:29:31,139 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:31,140 [run_pretraining.py:  534]:	loss/total_loss, 7.572094917297363, 2854
[INFO] 2021-07-12 19:29:31,140 [run_pretraining.py:  535]:	loss/mlm_loss, 7.572094917297363, 2854
[INFO] 2021-07-12 19:29:31,140 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.85299975075759e-05, 2854
[INFO] 2021-07-12 19:29:31,140 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2854
[INFO] 2021-07-12 19:29:31,140 [run_pretraining.py:  558]:	worker_index: 2, step: 2854, cost: 7.572095, mlm loss: 7.572095, speed: 0.949635 steps/s, speed: 7.597080 samples/s, speed: 3889.704789 tokens/s, learning rate: 2.853e-05, loss_scalings: 2814.750488, pp_loss: 7.403735
[INFO] 2021-07-12 19:29:31,140 [run_pretraining.py:  512]:	********exe.run_2854******* 
[INFO] 2021-07-12 19:29:32,196 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:32,196 [run_pretraining.py:  534]:	loss/total_loss, 6.703688144683838, 2855
[INFO] 2021-07-12 19:29:32,197 [run_pretraining.py:  535]:	loss/mlm_loss, 6.703688144683838, 2855
[INFO] 2021-07-12 19:29:32,197 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8540000130305998e-05, 2855
[INFO] 2021-07-12 19:29:32,197 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2855
[INFO] 2021-07-12 19:29:32,197 [run_pretraining.py:  558]:	worker_index: 2, step: 2855, cost: 6.703688, mlm loss: 6.703688, speed: 0.946842 steps/s, speed: 7.574735 samples/s, speed: 3878.264282 tokens/s, learning rate: 2.854e-05, loss_scalings: 2814.750488, pp_loss: 7.051755
[INFO] 2021-07-12 19:29:32,197 [run_pretraining.py:  512]:	********exe.run_2855******* 
[INFO] 2021-07-12 19:29:33,276 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:33,277 [run_pretraining.py:  534]:	loss/total_loss, 6.644920349121094, 2856
[INFO] 2021-07-12 19:29:33,277 [run_pretraining.py:  535]:	loss/mlm_loss, 6.644920349121094, 2856
[INFO] 2021-07-12 19:29:33,277 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.854999911505729e-05, 2856
[INFO] 2021-07-12 19:29:33,277 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2856
[INFO] 2021-07-12 19:29:33,277 [run_pretraining.py:  558]:	worker_index: 2, step: 2856, cost: 6.644920, mlm loss: 6.644920, speed: 0.926075 steps/s, speed: 7.408603 samples/s, speed: 3793.204985 tokens/s, learning rate: 2.855e-05, loss_scalings: 2814.750488, pp_loss: 7.020381
[INFO] 2021-07-12 19:29:33,277 [run_pretraining.py:  512]:	********exe.run_2856******* 
[INFO] 2021-07-12 19:29:34,343 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:34,343 [run_pretraining.py:  534]:	loss/total_loss, 7.0439605712890625, 2857
[INFO] 2021-07-12 19:29:34,343 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0439605712890625, 2857
[INFO] 2021-07-12 19:29:34,343 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8559999918797985e-05, 2857
[INFO] 2021-07-12 19:29:34,343 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2857
[INFO] 2021-07-12 19:29:34,344 [run_pretraining.py:  558]:	worker_index: 2, step: 2857, cost: 7.043961, mlm loss: 7.043961, speed: 0.938314 steps/s, speed: 7.506512 samples/s, speed: 3843.334210 tokens/s, learning rate: 2.856e-05, loss_scalings: 2814.750488, pp_loss: 7.465710
[INFO] 2021-07-12 19:29:34,344 [run_pretraining.py:  512]:	********exe.run_2857******* 
[INFO] 2021-07-12 19:29:35,410 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:35,411 [run_pretraining.py:  534]:	loss/total_loss, 8.698738098144531, 2858
[INFO] 2021-07-12 19:29:35,411 [run_pretraining.py:  535]:	loss/mlm_loss, 8.698738098144531, 2858
[INFO] 2021-07-12 19:29:35,411 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8569998903549276e-05, 2858
[INFO] 2021-07-12 19:29:35,411 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2858
[INFO] 2021-07-12 19:29:35,411 [run_pretraining.py:  558]:	worker_index: 2, step: 2858, cost: 8.698738, mlm loss: 8.698738, speed: 0.937022 steps/s, speed: 7.496179 samples/s, speed: 3838.043428 tokens/s, learning rate: 2.857e-05, loss_scalings: 2814.750488, pp_loss: 7.787554
[INFO] 2021-07-12 19:29:35,411 [run_pretraining.py:  512]:	********exe.run_2858******* 
[INFO] 2021-07-12 19:29:36,473 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:36,473 [run_pretraining.py:  534]:	loss/total_loss, 7.922182559967041, 2859
[INFO] 2021-07-12 19:29:36,473 [run_pretraining.py:  535]:	loss/mlm_loss, 7.922182559967041, 2859
[INFO] 2021-07-12 19:29:36,473 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.857999970728997e-05, 2859
[INFO] 2021-07-12 19:29:36,473 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2859
[INFO] 2021-07-12 19:29:36,473 [run_pretraining.py:  558]:	worker_index: 2, step: 2859, cost: 7.922183, mlm loss: 7.922183, speed: 0.942173 steps/s, speed: 7.537385 samples/s, speed: 3859.140996 tokens/s, learning rate: 2.858e-05, loss_scalings: 2814.750488, pp_loss: 7.235761
[INFO] 2021-07-12 19:29:36,473 [run_pretraining.py:  512]:	********exe.run_2859******* 
[INFO] 2021-07-12 19:29:37,532 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:37,532 [run_pretraining.py:  534]:	loss/total_loss, 7.5274505615234375, 2860
[INFO] 2021-07-12 19:29:37,532 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5274505615234375, 2860
[INFO] 2021-07-12 19:29:37,532 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8589998692041263e-05, 2860
[INFO] 2021-07-12 19:29:37,532 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2860
[INFO] 2021-07-12 19:29:37,533 [run_pretraining.py:  558]:	worker_index: 2, step: 2860, cost: 7.527451, mlm loss: 7.527451, speed: 0.944640 steps/s, speed: 7.557117 samples/s, speed: 3869.244047 tokens/s, learning rate: 2.859e-05, loss_scalings: 2814.750488, pp_loss: 7.727649
[INFO] 2021-07-12 19:29:37,533 [run_pretraining.py:  512]:	********exe.run_2860******* 
[INFO] 2021-07-12 19:29:38,596 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:38,597 [run_pretraining.py:  534]:	loss/total_loss, 6.972277641296387, 2861
[INFO] 2021-07-12 19:29:38,597 [run_pretraining.py:  535]:	loss/mlm_loss, 6.972277641296387, 2861
[INFO] 2021-07-12 19:29:38,597 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.860000131477136e-05, 2861
[INFO] 2021-07-12 19:29:38,597 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2861
[INFO] 2021-07-12 19:29:38,597 [run_pretraining.py:  558]:	worker_index: 2, step: 2861, cost: 6.972278, mlm loss: 6.972278, speed: 0.939812 steps/s, speed: 7.518498 samples/s, speed: 3849.470914 tokens/s, learning rate: 2.860e-05, loss_scalings: 2814.750488, pp_loss: 6.934080
[INFO] 2021-07-12 19:29:38,597 [run_pretraining.py:  512]:	********exe.run_2861******* 
[INFO] 2021-07-12 19:29:39,522 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:39,523 [run_pretraining.py:  534]:	loss/total_loss, 7.644308567047119, 2862
[INFO] 2021-07-12 19:29:39,523 [run_pretraining.py:  535]:	loss/mlm_loss, 7.644308567047119, 2862
[INFO] 2021-07-12 19:29:39,523 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.860999848053325e-05, 2862
[INFO] 2021-07-12 19:29:39,523 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2862
[INFO] 2021-07-12 19:29:39,523 [run_pretraining.py:  558]:	worker_index: 2, step: 2862, cost: 7.644309, mlm loss: 7.644309, speed: 1.080965 steps/s, speed: 8.647722 samples/s, speed: 4427.633588 tokens/s, learning rate: 2.861e-05, loss_scalings: 2814.750488, pp_loss: 7.393073
[INFO] 2021-07-12 19:29:39,523 [run_pretraining.py:  512]:	********exe.run_2862******* 
[INFO] 2021-07-12 19:29:40,437 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:40,437 [run_pretraining.py:  534]:	loss/total_loss, 6.496039390563965, 2863
[INFO] 2021-07-12 19:29:40,437 [run_pretraining.py:  535]:	loss/mlm_loss, 6.496039390563965, 2863
[INFO] 2021-07-12 19:29:40,437 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.861999746528454e-05, 2863
[INFO] 2021-07-12 19:29:40,437 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2863
[INFO] 2021-07-12 19:29:40,438 [run_pretraining.py:  558]:	worker_index: 2, step: 2863, cost: 6.496039, mlm loss: 6.496039, speed: 1.094023 steps/s, speed: 8.752182 samples/s, speed: 4481.117394 tokens/s, learning rate: 2.862e-05, loss_scalings: 2814.750488, pp_loss: 7.071601
[INFO] 2021-07-12 19:29:40,438 [run_pretraining.py:  512]:	********exe.run_2863******* 
[INFO] 2021-07-12 19:29:41,348 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:41,348 [run_pretraining.py:  534]:	loss/total_loss, 8.160274505615234, 2864
[INFO] 2021-07-12 19:29:41,348 [run_pretraining.py:  535]:	loss/mlm_loss, 8.160274505615234, 2864
[INFO] 2021-07-12 19:29:41,348 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.863000008801464e-05, 2864
[INFO] 2021-07-12 19:29:41,348 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2864
[INFO] 2021-07-12 19:29:41,348 [run_pretraining.py:  558]:	worker_index: 2, step: 2864, cost: 8.160275, mlm loss: 8.160275, speed: 1.098554 steps/s, speed: 8.788436 samples/s, speed: 4499.679070 tokens/s, learning rate: 2.863e-05, loss_scalings: 2814.750488, pp_loss: 7.438919
[INFO] 2021-07-12 19:29:41,348 [run_pretraining.py:  512]:	********exe.run_2864******* 
[INFO] 2021-07-12 19:29:42,276 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:42,276 [run_pretraining.py:  534]:	loss/total_loss, 7.159521102905273, 2865
[INFO] 2021-07-12 19:29:42,276 [run_pretraining.py:  535]:	loss/mlm_loss, 7.159521102905273, 2865
[INFO] 2021-07-12 19:29:42,276 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.863999907276593e-05, 2865
[INFO] 2021-07-12 19:29:42,277 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2865
[INFO] 2021-07-12 19:29:42,277 [run_pretraining.py:  558]:	worker_index: 2, step: 2865, cost: 7.159521, mlm loss: 7.159521, speed: 1.078009 steps/s, speed: 8.624073 samples/s, speed: 4415.525492 tokens/s, learning rate: 2.864e-05, loss_scalings: 2814.750488, pp_loss: 7.325018
[INFO] 2021-07-12 19:29:42,277 [run_pretraining.py:  512]:	********exe.run_2865******* 
[INFO] 2021-07-12 19:29:43,188 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:43,189 [run_pretraining.py:  534]:	loss/total_loss, 7.085168838500977, 2866
[INFO] 2021-07-12 19:29:43,189 [run_pretraining.py:  535]:	loss/mlm_loss, 7.085168838500977, 2866
[INFO] 2021-07-12 19:29:43,189 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8649999876506627e-05, 2866
[INFO] 2021-07-12 19:29:43,189 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2866
[INFO] 2021-07-12 19:29:43,189 [run_pretraining.py:  558]:	worker_index: 2, step: 2866, cost: 7.085169, mlm loss: 7.085169, speed: 1.096681 steps/s, speed: 8.773444 samples/s, speed: 4492.003411 tokens/s, learning rate: 2.865e-05, loss_scalings: 2814.750488, pp_loss: 7.318106
[INFO] 2021-07-12 19:29:43,189 [run_pretraining.py:  512]:	********exe.run_2866******* 
[INFO] 2021-07-12 19:29:44,113 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:44,113 [run_pretraining.py:  534]:	loss/total_loss, 7.377231597900391, 2867
[INFO] 2021-07-12 19:29:44,113 [run_pretraining.py:  535]:	loss/mlm_loss, 7.377231597900391, 2867
[INFO] 2021-07-12 19:29:44,113 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8659998861257918e-05, 2867
[INFO] 2021-07-12 19:29:44,113 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2867
[INFO] 2021-07-12 19:29:44,113 [run_pretraining.py:  558]:	worker_index: 2, step: 2867, cost: 7.377232, mlm loss: 7.377232, speed: 1.082569 steps/s, speed: 8.660551 samples/s, speed: 4434.202359 tokens/s, learning rate: 2.866e-05, loss_scalings: 2814.750488, pp_loss: 7.440752
[INFO] 2021-07-12 19:29:44,113 [run_pretraining.py:  512]:	********exe.run_2867******* 
[INFO] 2021-07-12 19:29:45,032 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:45,033 [run_pretraining.py:  534]:	loss/total_loss, 7.0146331787109375, 2868
[INFO] 2021-07-12 19:29:45,033 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0146331787109375, 2868
[INFO] 2021-07-12 19:29:45,033 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8669999664998613e-05, 2868
[INFO] 2021-07-12 19:29:45,033 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2868
[INFO] 2021-07-12 19:29:45,033 [run_pretraining.py:  558]:	worker_index: 2, step: 2868, cost: 7.014633, mlm loss: 7.014633, speed: 1.087803 steps/s, speed: 8.702422 samples/s, speed: 4455.639899 tokens/s, learning rate: 2.867e-05, loss_scalings: 2814.750488, pp_loss: 7.175284
[INFO] 2021-07-12 19:29:45,033 [run_pretraining.py:  512]:	********exe.run_2868******* 
[INFO] 2021-07-12 19:29:45,945 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:45,945 [run_pretraining.py:  534]:	loss/total_loss, 7.410787105560303, 2869
[INFO] 2021-07-12 19:29:45,946 [run_pretraining.py:  535]:	loss/mlm_loss, 7.410787105560303, 2869
[INFO] 2021-07-12 19:29:45,946 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8679998649749905e-05, 2869
[INFO] 2021-07-12 19:29:45,946 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2869
[INFO] 2021-07-12 19:29:45,946 [run_pretraining.py:  558]:	worker_index: 2, step: 2869, cost: 7.410787, mlm loss: 7.410787, speed: 1.096547 steps/s, speed: 8.772380 samples/s, speed: 4491.458500 tokens/s, learning rate: 2.868e-05, loss_scalings: 2814.750488, pp_loss: 7.599647
[INFO] 2021-07-12 19:29:45,946 [run_pretraining.py:  512]:	********exe.run_2869******* 
[INFO] 2021-07-12 19:29:46,910 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:46,910 [run_pretraining.py:  534]:	loss/total_loss, 6.9940948486328125, 2870
[INFO] 2021-07-12 19:29:46,910 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9940948486328125, 2870
[INFO] 2021-07-12 19:29:46,910 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8690001272480004e-05, 2870
[INFO] 2021-07-12 19:29:46,910 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2870
[INFO] 2021-07-12 19:29:46,910 [run_pretraining.py:  558]:	worker_index: 2, step: 2870, cost: 6.994095, mlm loss: 6.994095, speed: 1.037429 steps/s, speed: 8.299431 samples/s, speed: 4249.308476 tokens/s, learning rate: 2.869e-05, loss_scalings: 2814.750488, pp_loss: 7.183082
[INFO] 2021-07-12 19:29:46,910 [run_pretraining.py:  512]:	********exe.run_2870******* 
[INFO] 2021-07-12 19:29:47,926 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:47,927 [run_pretraining.py:  534]:	loss/total_loss, 7.3116960525512695, 2871
[INFO] 2021-07-12 19:29:47,927 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3116960525512695, 2871
[INFO] 2021-07-12 19:29:47,927 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.869999843824189e-05, 2871
[INFO] 2021-07-12 19:29:47,927 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2871
[INFO] 2021-07-12 19:29:47,927 [run_pretraining.py:  558]:	worker_index: 2, step: 2871, cost: 7.311696, mlm loss: 7.311696, speed: 0.984202 steps/s, speed: 7.873613 samples/s, speed: 4031.289707 tokens/s, learning rate: 2.870e-05, loss_scalings: 2814.750488, pp_loss: 7.238355
[INFO] 2021-07-12 19:29:47,927 [run_pretraining.py:  512]:	********exe.run_2871******* 
[INFO] 2021-07-12 19:29:48,909 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:48,910 [run_pretraining.py:  534]:	loss/total_loss, 7.768695831298828, 2872
[INFO] 2021-07-12 19:29:48,910 [run_pretraining.py:  535]:	loss/mlm_loss, 7.768695831298828, 2872
[INFO] 2021-07-12 19:29:48,910 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8709997422993183e-05, 2872
[INFO] 2021-07-12 19:29:48,910 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2872
[INFO] 2021-07-12 19:29:48,910 [run_pretraining.py:  558]:	worker_index: 2, step: 2872, cost: 7.768696, mlm loss: 7.768696, speed: 1.017811 steps/s, speed: 8.142485 samples/s, speed: 4168.952373 tokens/s, learning rate: 2.871e-05, loss_scalings: 2814.750488, pp_loss: 7.502193
[INFO] 2021-07-12 19:29:48,910 [run_pretraining.py:  512]:	********exe.run_2872******* 
[INFO] 2021-07-12 19:29:49,887 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:49,887 [run_pretraining.py:  534]:	loss/total_loss, 7.2912211418151855, 2873
[INFO] 2021-07-12 19:29:49,887 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2912211418151855, 2873
[INFO] 2021-07-12 19:29:49,887 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8720000045723282e-05, 2873
[INFO] 2021-07-12 19:29:49,888 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2873
[INFO] 2021-07-12 19:29:49,888 [run_pretraining.py:  558]:	worker_index: 2, step: 2873, cost: 7.291221, mlm loss: 7.291221, speed: 1.023641 steps/s, speed: 8.189129 samples/s, speed: 4192.834051 tokens/s, learning rate: 2.872e-05, loss_scalings: 2814.750488, pp_loss: 6.338074
[INFO] 2021-07-12 19:29:49,888 [run_pretraining.py:  512]:	********exe.run_2873******* 
[INFO] 2021-07-12 19:29:50,866 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:50,867 [run_pretraining.py:  534]:	loss/total_loss, 7.2221198081970215, 2874
[INFO] 2021-07-12 19:29:50,867 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2221198081970215, 2874
[INFO] 2021-07-12 19:29:50,867 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8729999030474573e-05, 2874
[INFO] 2021-07-12 19:29:50,867 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2874
[INFO] 2021-07-12 19:29:50,867 [run_pretraining.py:  558]:	worker_index: 2, step: 2874, cost: 7.222120, mlm loss: 7.222120, speed: 1.021568 steps/s, speed: 8.172544 samples/s, speed: 4184.342690 tokens/s, learning rate: 2.873e-05, loss_scalings: 2814.750488, pp_loss: 7.234811
[INFO] 2021-07-12 19:29:50,867 [run_pretraining.py:  512]:	********exe.run_2874******* 
[INFO] 2021-07-12 19:29:51,858 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:51,858 [run_pretraining.py:  534]:	loss/total_loss, 7.0770697593688965, 2875
[INFO] 2021-07-12 19:29:51,858 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0770697593688965, 2875
[INFO] 2021-07-12 19:29:51,858 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.873999983421527e-05, 2875
[INFO] 2021-07-12 19:29:51,858 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2875
[INFO] 2021-07-12 19:29:51,858 [run_pretraining.py:  558]:	worker_index: 2, step: 2875, cost: 7.077070, mlm loss: 7.077070, speed: 1.009368 steps/s, speed: 8.074945 samples/s, speed: 4134.371759 tokens/s, learning rate: 2.874e-05, loss_scalings: 2814.750488, pp_loss: 7.174254
[INFO] 2021-07-12 19:29:51,858 [run_pretraining.py:  512]:	********exe.run_2875******* 
[INFO] 2021-07-12 19:29:52,848 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:52,848 [run_pretraining.py:  534]:	loss/total_loss, 7.065529823303223, 2876
[INFO] 2021-07-12 19:29:52,848 [run_pretraining.py:  535]:	loss/mlm_loss, 7.065529823303223, 2876
[INFO] 2021-07-12 19:29:52,848 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.874999881896656e-05, 2876
[INFO] 2021-07-12 19:29:52,848 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2876
[INFO] 2021-07-12 19:29:52,848 [run_pretraining.py:  558]:	worker_index: 2, step: 2876, cost: 7.065530, mlm loss: 7.065530, speed: 1.010709 steps/s, speed: 8.085674 samples/s, speed: 4139.865177 tokens/s, learning rate: 2.875e-05, loss_scalings: 2814.750488, pp_loss: 7.239344
[INFO] 2021-07-12 19:29:52,848 [run_pretraining.py:  512]:	********exe.run_2876******* 
[INFO] 2021-07-12 19:29:53,854 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:53,855 [run_pretraining.py:  534]:	loss/total_loss, 7.154784202575684, 2877
[INFO] 2021-07-12 19:29:53,855 [run_pretraining.py:  535]:	loss/mlm_loss, 7.154784202575684, 2877
[INFO] 2021-07-12 19:29:53,855 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8759999622707255e-05, 2877
[INFO] 2021-07-12 19:29:53,855 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2877
[INFO] 2021-07-12 19:29:53,855 [run_pretraining.py:  558]:	worker_index: 2, step: 2877, cost: 7.154784, mlm loss: 7.154784, speed: 0.994137 steps/s, speed: 7.953093 samples/s, speed: 4071.983446 tokens/s, learning rate: 2.876e-05, loss_scalings: 2814.750488, pp_loss: 7.065702
[INFO] 2021-07-12 19:29:53,855 [run_pretraining.py:  512]:	********exe.run_2877******* 
[INFO] 2021-07-12 19:29:54,774 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:54,775 [run_pretraining.py:  534]:	loss/total_loss, 7.318210124969482, 2878
[INFO] 2021-07-12 19:29:54,775 [run_pretraining.py:  535]:	loss/mlm_loss, 7.318210124969482, 2878
[INFO] 2021-07-12 19:29:54,775 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8769998607458547e-05, 2878
[INFO] 2021-07-12 19:29:54,775 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2878
[INFO] 2021-07-12 19:29:54,775 [run_pretraining.py:  558]:	worker_index: 2, step: 2878, cost: 7.318210, mlm loss: 7.318210, speed: 1.087538 steps/s, speed: 8.700307 samples/s, speed: 4454.557382 tokens/s, learning rate: 2.877e-05, loss_scalings: 2814.750488, pp_loss: 6.586185
[INFO] 2021-07-12 19:29:54,775 [run_pretraining.py:  512]:	********exe.run_2878******* 
[INFO] 2021-07-12 19:29:55,686 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:55,687 [run_pretraining.py:  534]:	loss/total_loss, 7.1899824142456055, 2879
[INFO] 2021-07-12 19:29:55,687 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1899824142456055, 2879
[INFO] 2021-07-12 19:29:55,687 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8780001230188645e-05, 2879
[INFO] 2021-07-12 19:29:55,687 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2879
[INFO] 2021-07-12 19:29:55,687 [run_pretraining.py:  558]:	worker_index: 2, step: 2879, cost: 7.189982, mlm loss: 7.189982, speed: 1.097295 steps/s, speed: 8.778356 samples/s, speed: 4494.518290 tokens/s, learning rate: 2.878e-05, loss_scalings: 2814.750488, pp_loss: 7.045520
[INFO] 2021-07-12 19:29:55,687 [run_pretraining.py:  512]:	********exe.run_2879******* 
[INFO] 2021-07-12 19:29:56,601 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:56,601 [run_pretraining.py:  534]:	loss/total_loss, 7.19936466217041, 2880
[INFO] 2021-07-12 19:29:56,601 [run_pretraining.py:  535]:	loss/mlm_loss, 7.19936466217041, 2880
[INFO] 2021-07-12 19:29:56,601 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8790000214939937e-05, 2880
[INFO] 2021-07-12 19:29:56,602 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2880
[INFO] 2021-07-12 19:29:56,602 [run_pretraining.py:  558]:	worker_index: 2, step: 2880, cost: 7.199365, mlm loss: 7.199365, speed: 1.094017 steps/s, speed: 8.752132 samples/s, speed: 4481.091679 tokens/s, learning rate: 2.879e-05, loss_scalings: 2814.750488, pp_loss: 7.306981
[INFO] 2021-07-12 19:29:56,602 [run_pretraining.py:  512]:	********exe.run_2880******* 
[INFO] 2021-07-12 19:29:57,513 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:57,514 [run_pretraining.py:  534]:	loss/total_loss, 6.7271952629089355, 2881
[INFO] 2021-07-12 19:29:57,514 [run_pretraining.py:  535]:	loss/mlm_loss, 6.7271952629089355, 2881
[INFO] 2021-07-12 19:29:57,514 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8799997380701825e-05, 2881
[INFO] 2021-07-12 19:29:57,514 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2881
[INFO] 2021-07-12 19:29:57,514 [run_pretraining.py:  558]:	worker_index: 2, step: 2881, cost: 6.727195, mlm loss: 6.727195, speed: 1.096855 steps/s, speed: 8.774839 samples/s, speed: 4492.717632 tokens/s, learning rate: 2.880e-05, loss_scalings: 2814.750488, pp_loss: 7.095259
[INFO] 2021-07-12 19:29:57,514 [run_pretraining.py:  512]:	********exe.run_2881******* 
[INFO] 2021-07-12 19:29:58,426 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:58,427 [run_pretraining.py:  534]:	loss/total_loss, 7.759919166564941, 2882
[INFO] 2021-07-12 19:29:58,427 [run_pretraining.py:  535]:	loss/mlm_loss, 7.759919166564941, 2882
[INFO] 2021-07-12 19:29:58,427 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8810000003431924e-05, 2882
[INFO] 2021-07-12 19:29:58,427 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2882
[INFO] 2021-07-12 19:29:58,427 [run_pretraining.py:  558]:	worker_index: 2, step: 2882, cost: 7.759919, mlm loss: 7.759919, speed: 1.095999 steps/s, speed: 8.767992 samples/s, speed: 4489.212138 tokens/s, learning rate: 2.881e-05, loss_scalings: 2814.750488, pp_loss: 6.853548
[INFO] 2021-07-12 19:29:58,427 [run_pretraining.py:  512]:	********exe.run_2882******* 
[INFO] 2021-07-12 19:29:59,344 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:59,345 [run_pretraining.py:  534]:	loss/total_loss, 4.4926066398620605, 2883
[INFO] 2021-07-12 19:29:59,345 [run_pretraining.py:  535]:	loss/mlm_loss, 4.4926066398620605, 2883
[INFO] 2021-07-12 19:29:59,345 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8819998988183215e-05, 2883
[INFO] 2021-07-12 19:29:59,345 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2883
[INFO] 2021-07-12 19:29:59,345 [run_pretraining.py:  558]:	worker_index: 2, step: 2883, cost: 4.492607, mlm loss: 4.492607, speed: 1.089730 steps/s, speed: 8.717842 samples/s, speed: 4463.534924 tokens/s, learning rate: 2.882e-05, loss_scalings: 2814.750488, pp_loss: 6.752712
[INFO] 2021-07-12 19:29:59,345 [run_pretraining.py:  512]:	********exe.run_2883******* 
[INFO] 2021-07-12 19:30:00,258 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:00,259 [run_pretraining.py:  534]:	loss/total_loss, 6.676962852478027, 2884
[INFO] 2021-07-12 19:30:00,259 [run_pretraining.py:  535]:	loss/mlm_loss, 6.676962852478027, 2884
[INFO] 2021-07-12 19:30:00,259 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.882999979192391e-05, 2884
[INFO] 2021-07-12 19:30:00,259 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2884
[INFO] 2021-07-12 19:30:00,259 [run_pretraining.py:  558]:	worker_index: 2, step: 2884, cost: 6.676963, mlm loss: 6.676963, speed: 1.094843 steps/s, speed: 8.758746 samples/s, speed: 4484.477972 tokens/s, learning rate: 2.883e-05, loss_scalings: 2814.750488, pp_loss: 7.308437
[INFO] 2021-07-12 19:30:00,259 [run_pretraining.py:  512]:	********exe.run_2884******* 
[INFO] 2021-07-12 19:30:01,188 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:01,188 [run_pretraining.py:  534]:	loss/total_loss, 6.784064292907715, 2885
[INFO] 2021-07-12 19:30:01,188 [run_pretraining.py:  535]:	loss/mlm_loss, 6.784064292907715, 2885
[INFO] 2021-07-12 19:30:01,188 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8839998776675202e-05, 2885
[INFO] 2021-07-12 19:30:01,188 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2885
[INFO] 2021-07-12 19:30:01,188 [run_pretraining.py:  558]:	worker_index: 2, step: 2885, cost: 6.784064, mlm loss: 6.784064, speed: 1.076853 steps/s, speed: 8.614825 samples/s, speed: 4410.790237 tokens/s, learning rate: 2.884e-05, loss_scalings: 2814.750488, pp_loss: 7.342870
[INFO] 2021-07-12 19:30:01,188 [run_pretraining.py:  512]:	********exe.run_2885******* 
[INFO] 2021-07-12 19:30:02,101 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:02,101 [run_pretraining.py:  534]:	loss/total_loss, 7.357398509979248, 2886
[INFO] 2021-07-12 19:30:02,102 [run_pretraining.py:  535]:	loss/mlm_loss, 7.357398509979248, 2886
[INFO] 2021-07-12 19:30:02,102 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8849999580415897e-05, 2886
[INFO] 2021-07-12 19:30:02,102 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2886
[INFO] 2021-07-12 19:30:02,102 [run_pretraining.py:  558]:	worker_index: 2, step: 2886, cost: 7.357399, mlm loss: 7.357399, speed: 1.095446 steps/s, speed: 8.763568 samples/s, speed: 4486.946929 tokens/s, learning rate: 2.885e-05, loss_scalings: 2814.750488, pp_loss: 7.167573
[INFO] 2021-07-12 19:30:02,102 [run_pretraining.py:  512]:	********exe.run_2886******* 
[INFO] 2021-07-12 19:30:03,015 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:03,016 [run_pretraining.py:  534]:	loss/total_loss, 7.1825103759765625, 2887
[INFO] 2021-07-12 19:30:03,016 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1825103759765625, 2887
[INFO] 2021-07-12 19:30:03,016 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.885999856516719e-05, 2887
[INFO] 2021-07-12 19:30:03,016 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2887
[INFO] 2021-07-12 19:30:03,016 [run_pretraining.py:  558]:	worker_index: 2, step: 2887, cost: 7.182510, mlm loss: 7.182510, speed: 1.094492 steps/s, speed: 8.755933 samples/s, speed: 4483.037441 tokens/s, learning rate: 2.886e-05, loss_scalings: 2814.750488, pp_loss: 7.427683
[INFO] 2021-07-12 19:30:03,016 [run_pretraining.py:  512]:	********exe.run_2887******* 
[INFO] 2021-07-12 19:30:03,928 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:03,929 [run_pretraining.py:  534]:	loss/total_loss, 7.640800476074219, 2888
[INFO] 2021-07-12 19:30:03,929 [run_pretraining.py:  535]:	loss/mlm_loss, 7.640800476074219, 2888
[INFO] 2021-07-12 19:30:03,929 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8870001187897287e-05, 2888
[INFO] 2021-07-12 19:30:03,929 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2888
[INFO] 2021-07-12 19:30:03,929 [run_pretraining.py:  558]:	worker_index: 2, step: 2888, cost: 7.640800, mlm loss: 7.640800, speed: 1.095772 steps/s, speed: 8.766176 samples/s, speed: 4488.282094 tokens/s, learning rate: 2.887e-05, loss_scalings: 2814.750488, pp_loss: 7.322773
[INFO] 2021-07-12 19:30:03,929 [run_pretraining.py:  512]:	********exe.run_2888******* 
[INFO] 2021-07-12 19:30:04,840 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:04,840 [run_pretraining.py:  534]:	loss/total_loss, 6.729066371917725, 2889
[INFO] 2021-07-12 19:30:04,840 [run_pretraining.py:  535]:	loss/mlm_loss, 6.729066371917725, 2889
[INFO] 2021-07-12 19:30:04,840 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.888000017264858e-05, 2889
[INFO] 2021-07-12 19:30:04,840 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2889
[INFO] 2021-07-12 19:30:04,840 [run_pretraining.py:  558]:	worker_index: 2, step: 2889, cost: 6.729066, mlm loss: 6.729066, speed: 1.098283 steps/s, speed: 8.786266 samples/s, speed: 4498.567984 tokens/s, learning rate: 2.888e-05, loss_scalings: 2814.750488, pp_loss: 7.249215
[INFO] 2021-07-12 19:30:04,841 [run_pretraining.py:  512]:	********exe.run_2889******* 
[INFO] 2021-07-12 19:30:05,759 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:05,759 [run_pretraining.py:  534]:	loss/total_loss, 7.145227432250977, 2890
[INFO] 2021-07-12 19:30:05,759 [run_pretraining.py:  535]:	loss/mlm_loss, 7.145227432250977, 2890
[INFO] 2021-07-12 19:30:05,760 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8889997338410467e-05, 2890
[INFO] 2021-07-12 19:30:05,760 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2890
[INFO] 2021-07-12 19:30:05,760 [run_pretraining.py:  558]:	worker_index: 2, step: 2890, cost: 7.145227, mlm loss: 7.145227, speed: 1.088603 steps/s, speed: 8.708827 samples/s, speed: 4458.919538 tokens/s, learning rate: 2.889e-05, loss_scalings: 2814.750488, pp_loss: 7.473713
[INFO] 2021-07-12 19:30:05,760 [run_pretraining.py:  512]:	********exe.run_2890******* 
[INFO] 2021-07-12 19:30:06,676 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:06,676 [run_pretraining.py:  534]:	loss/total_loss, 6.874365329742432, 2891
[INFO] 2021-07-12 19:30:06,676 [run_pretraining.py:  535]:	loss/mlm_loss, 6.874365329742432, 2891
[INFO] 2021-07-12 19:30:06,676 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8899999961140566e-05, 2891
[INFO] 2021-07-12 19:30:06,676 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2891
[INFO] 2021-07-12 19:30:06,677 [run_pretraining.py:  558]:	worker_index: 2, step: 2891, cost: 6.874365, mlm loss: 6.874365, speed: 1.091363 steps/s, speed: 8.730903 samples/s, speed: 4470.222364 tokens/s, learning rate: 2.890e-05, loss_scalings: 2814.750488, pp_loss: 7.008890
[INFO] 2021-07-12 19:30:06,677 [run_pretraining.py:  512]:	********exe.run_2891******* 
[INFO] 2021-07-12 19:30:07,587 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:07,587 [run_pretraining.py:  534]:	loss/total_loss, 7.630407810211182, 2892
[INFO] 2021-07-12 19:30:07,587 [run_pretraining.py:  535]:	loss/mlm_loss, 7.630407810211182, 2892
[INFO] 2021-07-12 19:30:07,587 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8909998945891857e-05, 2892
[INFO] 2021-07-12 19:30:07,588 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2892
[INFO] 2021-07-12 19:30:07,588 [run_pretraining.py:  558]:	worker_index: 2, step: 2892, cost: 7.630408, mlm loss: 7.630408, speed: 1.098461 steps/s, speed: 8.787688 samples/s, speed: 4499.296078 tokens/s, learning rate: 2.891e-05, loss_scalings: 2814.750488, pp_loss: 7.378307
[INFO] 2021-07-12 19:30:07,588 [run_pretraining.py:  512]:	********exe.run_2892******* 
[INFO] 2021-07-12 19:30:08,501 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:08,501 [run_pretraining.py:  534]:	loss/total_loss, 7.2892680168151855, 2893
[INFO] 2021-07-12 19:30:08,501 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2892680168151855, 2893
[INFO] 2021-07-12 19:30:08,501 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8919999749632552e-05, 2893
[INFO] 2021-07-12 19:30:08,502 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2893
[INFO] 2021-07-12 19:30:08,502 [run_pretraining.py:  558]:	worker_index: 2, step: 2893, cost: 7.289268, mlm loss: 7.289268, speed: 1.094774 steps/s, speed: 8.758195 samples/s, speed: 4484.195878 tokens/s, learning rate: 2.892e-05, loss_scalings: 2814.750488, pp_loss: 7.326422
[INFO] 2021-07-12 19:30:08,502 [run_pretraining.py:  512]:	********exe.run_2893******* 
[INFO] 2021-07-12 19:30:09,418 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:09,418 [run_pretraining.py:  534]:	loss/total_loss, 6.884931564331055, 2894
[INFO] 2021-07-12 19:30:09,419 [run_pretraining.py:  535]:	loss/mlm_loss, 6.884931564331055, 2894
[INFO] 2021-07-12 19:30:09,419 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8929998734383844e-05, 2894
[INFO] 2021-07-12 19:30:09,419 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2894
[INFO] 2021-07-12 19:30:09,419 [run_pretraining.py:  558]:	worker_index: 2, step: 2894, cost: 6.884932, mlm loss: 6.884932, speed: 1.090965 steps/s, speed: 8.727717 samples/s, speed: 4468.591050 tokens/s, learning rate: 2.893e-05, loss_scalings: 2814.750488, pp_loss: 7.387726
[INFO] 2021-07-12 19:30:09,419 [run_pretraining.py:  512]:	********exe.run_2894******* 
[INFO] 2021-07-12 19:30:10,347 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:10,348 [run_pretraining.py:  534]:	loss/total_loss, 7.9858927726745605, 2895
[INFO] 2021-07-12 19:30:10,348 [run_pretraining.py:  535]:	loss/mlm_loss, 7.9858927726745605, 2895
[INFO] 2021-07-12 19:30:10,348 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.893999953812454e-05, 2895
[INFO] 2021-07-12 19:30:10,348 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2895
[INFO] 2021-07-12 19:30:10,348 [run_pretraining.py:  558]:	worker_index: 2, step: 2895, cost: 7.985893, mlm loss: 7.985893, speed: 1.076764 steps/s, speed: 8.614108 samples/s, speed: 4410.423359 tokens/s, learning rate: 2.894e-05, loss_scalings: 2814.750488, pp_loss: 7.665333
[INFO] 2021-07-12 19:30:10,348 [run_pretraining.py:  512]:	********exe.run_2895******* 
[INFO] 2021-07-12 19:30:11,266 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:11,266 [run_pretraining.py:  534]:	loss/total_loss, 7.917941093444824, 2896
[INFO] 2021-07-12 19:30:11,266 [run_pretraining.py:  535]:	loss/mlm_loss, 7.917941093444824, 2896
[INFO] 2021-07-12 19:30:11,267 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.894999852287583e-05, 2896
[INFO] 2021-07-12 19:30:11,267 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2896
[INFO] 2021-07-12 19:30:11,267 [run_pretraining.py:  558]:	worker_index: 2, step: 2896, cost: 7.917941, mlm loss: 7.917941, speed: 1.089398 steps/s, speed: 8.715183 samples/s, speed: 4462.173875 tokens/s, learning rate: 2.895e-05, loss_scalings: 2814.750488, pp_loss: 7.412164
[INFO] 2021-07-12 19:30:11,267 [run_pretraining.py:  512]:	********exe.run_2896******* 
[INFO] 2021-07-12 19:30:12,181 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:12,182 [run_pretraining.py:  534]:	loss/total_loss, 6.788181304931641, 2897
[INFO] 2021-07-12 19:30:12,182 [run_pretraining.py:  535]:	loss/mlm_loss, 6.788181304931641, 2897
[INFO] 2021-07-12 19:30:12,182 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.896000114560593e-05, 2897
[INFO] 2021-07-12 19:30:12,182 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2897
[INFO] 2021-07-12 19:30:12,182 [run_pretraining.py:  558]:	worker_index: 2, step: 2897, cost: 6.788181, mlm loss: 6.788181, speed: 1.093422 steps/s, speed: 8.747380 samples/s, speed: 4478.658348 tokens/s, learning rate: 2.896e-05, loss_scalings: 2814.750488, pp_loss: 6.418781
[INFO] 2021-07-12 19:30:12,182 [run_pretraining.py:  512]:	********exe.run_2897******* 
[INFO] 2021-07-12 19:30:13,092 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:13,092 [run_pretraining.py:  534]:	loss/total_loss, 7.102651119232178, 2898
[INFO] 2021-07-12 19:30:13,093 [run_pretraining.py:  535]:	loss/mlm_loss, 7.102651119232178, 2898
[INFO] 2021-07-12 19:30:13,093 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.897000013035722e-05, 2898
[INFO] 2021-07-12 19:30:13,093 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2898
[INFO] 2021-07-12 19:30:13,093 [run_pretraining.py:  558]:	worker_index: 2, step: 2898, cost: 7.102651, mlm loss: 7.102651, speed: 1.098554 steps/s, speed: 8.788433 samples/s, speed: 4499.677892 tokens/s, learning rate: 2.897e-05, loss_scalings: 2814.750488, pp_loss: 7.246412
[INFO] 2021-07-12 19:30:13,093 [run_pretraining.py:  512]:	********exe.run_2898******* 
[INFO] 2021-07-12 19:30:14,002 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:14,002 [run_pretraining.py:  534]:	loss/total_loss, 6.7999372482299805, 2899
[INFO] 2021-07-12 19:30:14,002 [run_pretraining.py:  535]:	loss/mlm_loss, 6.7999372482299805, 2899
[INFO] 2021-07-12 19:30:14,002 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.897999729611911e-05, 2899
[INFO] 2021-07-12 19:30:14,003 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2899
[INFO] 2021-07-12 19:30:14,003 [run_pretraining.py:  558]:	worker_index: 2, step: 2899, cost: 6.799937, mlm loss: 6.799937, speed: 1.099858 steps/s, speed: 8.798864 samples/s, speed: 4505.018278 tokens/s, learning rate: 2.898e-05, loss_scalings: 2814.750488, pp_loss: 7.230107
[INFO] 2021-07-12 19:30:14,003 [run_pretraining.py:  512]:	********exe.run_2899******* 
[INFO] 2021-07-12 19:30:14,916 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:14,916 [run_pretraining.py:  534]:	loss/total_loss, 7.007687568664551, 2900
[INFO] 2021-07-12 19:30:14,917 [run_pretraining.py:  535]:	loss/mlm_loss, 7.007687568664551, 2900
[INFO] 2021-07-12 19:30:14,917 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8989999918849207e-05, 2900
[INFO] 2021-07-12 19:30:14,917 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2900
[INFO] 2021-07-12 19:30:14,917 [run_pretraining.py:  558]:	worker_index: 2, step: 2900, cost: 7.007688, mlm loss: 7.007688, speed: 1.094602 steps/s, speed: 8.756819 samples/s, speed: 4483.491383 tokens/s, learning rate: 2.899e-05, loss_scalings: 2814.750488, pp_loss: 7.134971
[INFO] 2021-07-12 19:30:14,917 [run_pretraining.py:  512]:	********exe.run_2900******* 
[INFO] 2021-07-12 19:30:15,843 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:15,843 [run_pretraining.py:  534]:	loss/total_loss, 7.26029109954834, 2901
[INFO] 2021-07-12 19:30:15,843 [run_pretraining.py:  535]:	loss/mlm_loss, 7.26029109954834, 2901
[INFO] 2021-07-12 19:30:15,843 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.89999989036005e-05, 2901
[INFO] 2021-07-12 19:30:15,844 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2901
[INFO] 2021-07-12 19:30:15,844 [run_pretraining.py:  558]:	worker_index: 2, step: 2901, cost: 7.260291, mlm loss: 7.260291, speed: 1.079712 steps/s, speed: 8.637695 samples/s, speed: 4422.500035 tokens/s, learning rate: 2.900e-05, loss_scalings: 2814.750488, pp_loss: 7.214646
[INFO] 2021-07-12 19:30:15,844 [run_pretraining.py:  512]:	********exe.run_2901******* 
[INFO] 2021-07-12 19:30:16,751 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:16,751 [run_pretraining.py:  534]:	loss/total_loss, 6.715976238250732, 2902
[INFO] 2021-07-12 19:30:16,751 [run_pretraining.py:  535]:	loss/mlm_loss, 6.715976238250732, 2902
[INFO] 2021-07-12 19:30:16,751 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9009999707341194e-05, 2902
[INFO] 2021-07-12 19:30:16,752 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2902
[INFO] 2021-07-12 19:30:16,752 [run_pretraining.py:  558]:	worker_index: 2, step: 2902, cost: 6.715976, mlm loss: 6.715976, speed: 1.102133 steps/s, speed: 8.817064 samples/s, speed: 4514.336988 tokens/s, learning rate: 2.901e-05, loss_scalings: 2814.750488, pp_loss: 6.962754
[INFO] 2021-07-12 19:30:16,752 [run_pretraining.py:  512]:	********exe.run_2902******* 
[INFO] 2021-07-12 19:30:17,661 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:17,662 [run_pretraining.py:  534]:	loss/total_loss, 7.383957862854004, 2903
[INFO] 2021-07-12 19:30:17,662 [run_pretraining.py:  535]:	loss/mlm_loss, 7.383957862854004, 2903
[INFO] 2021-07-12 19:30:17,662 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9019998692092486e-05, 2903
[INFO] 2021-07-12 19:30:17,662 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2903
[INFO] 2021-07-12 19:30:17,662 [run_pretraining.py:  558]:	worker_index: 2, step: 2903, cost: 7.383958, mlm loss: 7.383958, speed: 1.099348 steps/s, speed: 8.794782 samples/s, speed: 4502.928284 tokens/s, learning rate: 2.902e-05, loss_scalings: 2814.750488, pp_loss: 7.155975
[INFO] 2021-07-12 19:30:17,662 [run_pretraining.py:  512]:	********exe.run_2903******* 
[INFO] 2021-07-12 19:30:18,610 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:18,610 [run_pretraining.py:  534]:	loss/total_loss, 6.494954586029053, 2904
[INFO] 2021-07-12 19:30:18,610 [run_pretraining.py:  535]:	loss/mlm_loss, 6.494954586029053, 2904
[INFO] 2021-07-12 19:30:18,611 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9030001314822584e-05, 2904
[INFO] 2021-07-12 19:30:18,611 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2904
[INFO] 2021-07-12 19:30:18,611 [run_pretraining.py:  558]:	worker_index: 2, step: 2904, cost: 6.494955, mlm loss: 6.494955, speed: 1.054638 steps/s, speed: 8.437100 samples/s, speed: 4319.795320 tokens/s, learning rate: 2.903e-05, loss_scalings: 2814.750488, pp_loss: 7.097043
[INFO] 2021-07-12 19:30:18,611 [run_pretraining.py:  512]:	********exe.run_2904******* 
[INFO] 2021-07-12 19:30:19,528 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:19,528 [run_pretraining.py:  534]:	loss/total_loss, 7.273695945739746, 2905
[INFO] 2021-07-12 19:30:19,528 [run_pretraining.py:  535]:	loss/mlm_loss, 7.273695945739746, 2905
[INFO] 2021-07-12 19:30:19,528 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9039998480584472e-05, 2905
[INFO] 2021-07-12 19:30:19,529 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2905
[INFO] 2021-07-12 19:30:19,529 [run_pretraining.py:  558]:	worker_index: 2, step: 2905, cost: 7.273696, mlm loss: 7.273696, speed: 1.090136 steps/s, speed: 8.721091 samples/s, speed: 4465.198525 tokens/s, learning rate: 2.904e-05, loss_scalings: 2814.750488, pp_loss: 6.901795
[INFO] 2021-07-12 19:30:19,529 [run_pretraining.py:  512]:	********exe.run_2905******* 
[INFO] 2021-07-12 19:30:20,451 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:20,451 [run_pretraining.py:  534]:	loss/total_loss, 8.394580841064453, 2906
[INFO] 2021-07-12 19:30:20,451 [run_pretraining.py:  535]:	loss/mlm_loss, 8.394580841064453, 2906
[INFO] 2021-07-12 19:30:20,451 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9049997465335764e-05, 2906
[INFO] 2021-07-12 19:30:20,452 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2906
[INFO] 2021-07-12 19:30:20,452 [run_pretraining.py:  558]:	worker_index: 2, step: 2906, cost: 8.394581, mlm loss: 8.394581, speed: 1.084206 steps/s, speed: 8.673648 samples/s, speed: 4440.907737 tokens/s, learning rate: 2.905e-05, loss_scalings: 2814.750488, pp_loss: 7.331772
[INFO] 2021-07-12 19:30:20,452 [run_pretraining.py:  512]:	********exe.run_2906******* 
[INFO] 2021-07-12 19:30:21,367 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:21,368 [run_pretraining.py:  534]:	loss/total_loss, 7.474881172180176, 2907
[INFO] 2021-07-12 19:30:21,368 [run_pretraining.py:  535]:	loss/mlm_loss, 7.474881172180176, 2907
[INFO] 2021-07-12 19:30:21,368 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9060000088065863e-05, 2907
[INFO] 2021-07-12 19:30:21,368 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2907
[INFO] 2021-07-12 19:30:21,368 [run_pretraining.py:  558]:	worker_index: 2, step: 2907, cost: 7.474881, mlm loss: 7.474881, speed: 1.091937 steps/s, speed: 8.735499 samples/s, speed: 4472.575506 tokens/s, learning rate: 2.906e-05, loss_scalings: 2814.750488, pp_loss: 7.381707
[INFO] 2021-07-12 19:30:21,368 [run_pretraining.py:  512]:	********exe.run_2907******* 
[INFO] 2021-07-12 19:30:22,276 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:22,277 [run_pretraining.py:  534]:	loss/total_loss, 6.718028545379639, 2908
[INFO] 2021-07-12 19:30:22,277 [run_pretraining.py:  535]:	loss/mlm_loss, 6.718028545379639, 2908
[INFO] 2021-07-12 19:30:22,277 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.906999725382775e-05, 2908
[INFO] 2021-07-12 19:30:22,277 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2908
[INFO] 2021-07-12 19:30:22,277 [run_pretraining.py:  558]:	worker_index: 2, step: 2908, cost: 6.718029, mlm loss: 6.718029, speed: 1.100496 steps/s, speed: 8.803971 samples/s, speed: 4507.632909 tokens/s, learning rate: 2.907e-05, loss_scalings: 2814.750488, pp_loss: 6.715539
[INFO] 2021-07-12 19:30:22,277 [run_pretraining.py:  512]:	********exe.run_2908******* 
[INFO] 2021-07-12 19:30:23,210 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:23,211 [run_pretraining.py:  534]:	loss/total_loss, 7.2038702964782715, 2909
[INFO] 2021-07-12 19:30:23,211 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2038702964782715, 2909
[INFO] 2021-07-12 19:30:23,211 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.907999987655785e-05, 2909
[INFO] 2021-07-12 19:30:23,211 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2909
[INFO] 2021-07-12 19:30:23,211 [run_pretraining.py:  558]:	worker_index: 2, step: 2909, cost: 7.203870, mlm loss: 7.203870, speed: 1.071814 steps/s, speed: 8.574512 samples/s, speed: 4390.150141 tokens/s, learning rate: 2.908e-05, loss_scalings: 2814.750488, pp_loss: 7.503000
[INFO] 2021-07-12 19:30:23,211 [run_pretraining.py:  512]:	********exe.run_2909******* 
[INFO] 2021-07-12 19:30:24,122 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:24,123 [run_pretraining.py:  534]:	loss/total_loss, 7.446384429931641, 2910
[INFO] 2021-07-12 19:30:24,123 [run_pretraining.py:  535]:	loss/mlm_loss, 7.446384429931641, 2910
[INFO] 2021-07-12 19:30:24,123 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.908999886130914e-05, 2910
[INFO] 2021-07-12 19:30:24,123 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2910
[INFO] 2021-07-12 19:30:24,123 [run_pretraining.py:  558]:	worker_index: 2, step: 2910, cost: 7.446384, mlm loss: 7.446384, speed: 1.096963 steps/s, speed: 8.775707 samples/s, speed: 4493.161786 tokens/s, learning rate: 2.909e-05, loss_scalings: 2814.750488, pp_loss: 7.431510
[INFO] 2021-07-12 19:30:24,123 [run_pretraining.py:  512]:	********exe.run_2910******* 
[INFO] 2021-07-12 19:30:25,033 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:25,033 [run_pretraining.py:  534]:	loss/total_loss, 7.367744445800781, 2911
[INFO] 2021-07-12 19:30:25,033 [run_pretraining.py:  535]:	loss/mlm_loss, 7.367744445800781, 2911
[INFO] 2021-07-12 19:30:25,034 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9099999665049836e-05, 2911
[INFO] 2021-07-12 19:30:25,034 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2911
[INFO] 2021-07-12 19:30:25,034 [run_pretraining.py:  558]:	worker_index: 2, step: 2911, cost: 7.367744, mlm loss: 7.367744, speed: 1.098940 steps/s, speed: 8.791521 samples/s, speed: 4501.258864 tokens/s, learning rate: 2.910e-05, loss_scalings: 2814.750488, pp_loss: 6.811154
[INFO] 2021-07-12 19:30:25,034 [run_pretraining.py:  512]:	********exe.run_2911******* 
[INFO] 2021-07-12 19:30:25,944 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:25,944 [run_pretraining.py:  534]:	loss/total_loss, 6.965194225311279, 2912
[INFO] 2021-07-12 19:30:25,944 [run_pretraining.py:  535]:	loss/mlm_loss, 6.965194225311279, 2912
[INFO] 2021-07-12 19:30:25,945 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9109998649801128e-05, 2912
[INFO] 2021-07-12 19:30:25,945 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2912
[INFO] 2021-07-12 19:30:25,945 [run_pretraining.py:  558]:	worker_index: 2, step: 2912, cost: 6.965194, mlm loss: 6.965194, speed: 1.098404 steps/s, speed: 8.787232 samples/s, speed: 4499.062780 tokens/s, learning rate: 2.911e-05, loss_scalings: 2814.750488, pp_loss: 7.353116
[INFO] 2021-07-12 19:30:25,945 [run_pretraining.py:  512]:	********exe.run_2912******* 
[INFO] 2021-07-12 19:30:26,850 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:26,851 [run_pretraining.py:  534]:	loss/total_loss, 7.553600788116455, 2913
[INFO] 2021-07-12 19:30:26,851 [run_pretraining.py:  535]:	loss/mlm_loss, 7.553600788116455, 2913
[INFO] 2021-07-12 19:30:26,851 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9120001272531226e-05, 2913
[INFO] 2021-07-12 19:30:26,851 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2913
[INFO] 2021-07-12 19:30:26,851 [run_pretraining.py:  558]:	worker_index: 2, step: 2913, cost: 7.553601, mlm loss: 7.553601, speed: 1.104013 steps/s, speed: 8.832108 samples/s, speed: 4522.039235 tokens/s, learning rate: 2.912e-05, loss_scalings: 2814.750488, pp_loss: 7.393004
[INFO] 2021-07-12 19:30:26,851 [run_pretraining.py:  512]:	********exe.run_2913******* 
[INFO] 2021-07-12 19:30:27,760 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:27,761 [run_pretraining.py:  534]:	loss/total_loss, 6.57707405090332, 2914
[INFO] 2021-07-12 19:30:27,761 [run_pretraining.py:  535]:	loss/mlm_loss, 6.57707405090332, 2914
[INFO] 2021-07-12 19:30:27,761 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9129998438293114e-05, 2914
[INFO] 2021-07-12 19:30:27,761 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2914
[INFO] 2021-07-12 19:30:27,761 [run_pretraining.py:  558]:	worker_index: 2, step: 2914, cost: 6.577074, mlm loss: 6.577074, speed: 1.099787 steps/s, speed: 8.798294 samples/s, speed: 4504.726507 tokens/s, learning rate: 2.913e-05, loss_scalings: 2814.750488, pp_loss: 7.314078
[INFO] 2021-07-12 19:30:27,761 [run_pretraining.py:  512]:	********exe.run_2914******* 
[INFO] 2021-07-12 19:30:28,668 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:28,669 [run_pretraining.py:  534]:	loss/total_loss, 6.878034591674805, 2915
[INFO] 2021-07-12 19:30:28,669 [run_pretraining.py:  535]:	loss/mlm_loss, 6.878034591674805, 2915
[INFO] 2021-07-12 19:30:28,669 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9139997423044406e-05, 2915
[INFO] 2021-07-12 19:30:28,669 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2915
[INFO] 2021-07-12 19:30:28,669 [run_pretraining.py:  558]:	worker_index: 2, step: 2915, cost: 6.878035, mlm loss: 6.878035, speed: 1.101740 steps/s, speed: 8.813919 samples/s, speed: 4512.726665 tokens/s, learning rate: 2.914e-05, loss_scalings: 2814.750488, pp_loss: 7.351264
[INFO] 2021-07-12 19:30:28,669 [run_pretraining.py:  512]:	********exe.run_2915******* 
[INFO] 2021-07-12 19:30:29,578 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:29,579 [run_pretraining.py:  534]:	loss/total_loss, 7.487945556640625, 2916
[INFO] 2021-07-12 19:30:29,579 [run_pretraining.py:  535]:	loss/mlm_loss, 7.487945556640625, 2916
[INFO] 2021-07-12 19:30:29,579 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9150000045774505e-05, 2916
[INFO] 2021-07-12 19:30:29,579 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2916
[INFO] 2021-07-12 19:30:29,579 [run_pretraining.py:  558]:	worker_index: 2, step: 2916, cost: 7.487946, mlm loss: 7.487946, speed: 1.100110 steps/s, speed: 8.800879 samples/s, speed: 4506.049820 tokens/s, learning rate: 2.915e-05, loss_scalings: 2814.750488, pp_loss: 7.674273
[INFO] 2021-07-12 19:30:29,579 [run_pretraining.py:  512]:	********exe.run_2916******* 
[INFO] 2021-07-12 19:30:30,486 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:30,487 [run_pretraining.py:  534]:	loss/total_loss, 7.098205089569092, 2917
[INFO] 2021-07-12 19:30:30,487 [run_pretraining.py:  535]:	loss/mlm_loss, 7.098205089569092, 2917
[INFO] 2021-07-12 19:30:30,487 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9159999030525796e-05, 2917
[INFO] 2021-07-12 19:30:30,487 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2917
[INFO] 2021-07-12 19:30:30,487 [run_pretraining.py:  558]:	worker_index: 2, step: 2917, cost: 7.098205, mlm loss: 7.098205, speed: 1.101733 steps/s, speed: 8.813866 samples/s, speed: 4512.699401 tokens/s, learning rate: 2.916e-05, loss_scalings: 2814.750488, pp_loss: 6.980783
[INFO] 2021-07-12 19:30:30,487 [run_pretraining.py:  512]:	********exe.run_2917******* 
[INFO] 2021-07-12 19:30:31,389 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:31,389 [run_pretraining.py:  534]:	loss/total_loss, 7.566300868988037, 2918
[INFO] 2021-07-12 19:30:31,390 [run_pretraining.py:  535]:	loss/mlm_loss, 7.566300868988037, 2918
[INFO] 2021-07-12 19:30:31,390 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.916999983426649e-05, 2918
[INFO] 2021-07-12 19:30:31,390 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2918
[INFO] 2021-07-12 19:30:31,390 [run_pretraining.py:  558]:	worker_index: 2, step: 2918, cost: 7.566301, mlm loss: 7.566301, speed: 1.108649 steps/s, speed: 8.869192 samples/s, speed: 4541.026207 tokens/s, learning rate: 2.917e-05, loss_scalings: 2814.750488, pp_loss: 7.420665
[INFO] 2021-07-12 19:30:31,390 [run_pretraining.py:  512]:	********exe.run_2918******* 
[INFO] 2021-07-12 19:30:32,299 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:32,300 [run_pretraining.py:  534]:	loss/total_loss, 7.868322372436523, 2919
[INFO] 2021-07-12 19:30:32,300 [run_pretraining.py:  535]:	loss/mlm_loss, 7.868322372436523, 2919
[INFO] 2021-07-12 19:30:32,300 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9179998819017783e-05, 2919
[INFO] 2021-07-12 19:30:32,300 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2919
[INFO] 2021-07-12 19:30:32,300 [run_pretraining.py:  558]:	worker_index: 2, step: 2919, cost: 7.868322, mlm loss: 7.868322, speed: 1.099273 steps/s, speed: 8.794187 samples/s, speed: 4502.623803 tokens/s, learning rate: 2.918e-05, loss_scalings: 2814.750488, pp_loss: 7.447959
[INFO] 2021-07-12 19:30:32,300 [run_pretraining.py:  512]:	********exe.run_2919******* 
[INFO] 2021-07-12 19:30:33,204 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:33,205 [run_pretraining.py:  534]:	loss/total_loss, 7.40699577331543, 2920
[INFO] 2021-07-12 19:30:33,205 [run_pretraining.py:  535]:	loss/mlm_loss, 7.40699577331543, 2920
[INFO] 2021-07-12 19:30:33,205 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9189999622758478e-05, 2920
[INFO] 2021-07-12 19:30:33,205 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2920
[INFO] 2021-07-12 19:30:33,205 [run_pretraining.py:  558]:	worker_index: 2, step: 2920, cost: 7.406996, mlm loss: 7.406996, speed: 1.105554 steps/s, speed: 8.844430 samples/s, speed: 4528.348172 tokens/s, learning rate: 2.919e-05, loss_scalings: 2814.750488, pp_loss: 7.185089
[INFO] 2021-07-12 19:30:33,205 [run_pretraining.py:  512]:	********exe.run_2920******* 
[INFO] 2021-07-12 19:30:34,113 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:34,113 [run_pretraining.py:  534]:	loss/total_loss, 7.5965256690979, 2921
[INFO] 2021-07-12 19:30:34,113 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5965256690979, 2921
[INFO] 2021-07-12 19:30:34,113 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.919999860750977e-05, 2921
[INFO] 2021-07-12 19:30:34,114 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2921
[INFO] 2021-07-12 19:30:34,114 [run_pretraining.py:  558]:	worker_index: 2, step: 2921, cost: 7.596526, mlm loss: 7.596526, speed: 1.101645 steps/s, speed: 8.813158 samples/s, speed: 4512.336708 tokens/s, learning rate: 2.920e-05, loss_scalings: 2814.750488, pp_loss: 7.422245
[INFO] 2021-07-12 19:30:34,114 [run_pretraining.py:  512]:	********exe.run_2921******* 
[INFO] 2021-07-12 19:30:35,021 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:35,022 [run_pretraining.py:  534]:	loss/total_loss, 6.645881652832031, 2922
[INFO] 2021-07-12 19:30:35,022 [run_pretraining.py:  535]:	loss/mlm_loss, 6.645881652832031, 2922
[INFO] 2021-07-12 19:30:35,022 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9210001230239868e-05, 2922
[INFO] 2021-07-12 19:30:35,022 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2922
[INFO] 2021-07-12 19:30:35,022 [run_pretraining.py:  558]:	worker_index: 2, step: 2922, cost: 6.645882, mlm loss: 6.645882, speed: 1.101432 steps/s, speed: 8.811454 samples/s, speed: 4511.464586 tokens/s, learning rate: 2.921e-05, loss_scalings: 2814.750488, pp_loss: 7.065238
[INFO] 2021-07-12 19:30:35,022 [run_pretraining.py:  512]:	********exe.run_2922******* 
[INFO] 2021-07-12 19:30:35,930 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:35,930 [run_pretraining.py:  534]:	loss/total_loss, 7.3527021408081055, 2923
[INFO] 2021-07-12 19:30:35,930 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3527021408081055, 2923
[INFO] 2021-07-12 19:30:35,930 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9219998396001756e-05, 2923
[INFO] 2021-07-12 19:30:35,931 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2923
[INFO] 2021-07-12 19:30:35,931 [run_pretraining.py:  558]:	worker_index: 2, step: 2923, cost: 7.352702, mlm loss: 7.352702, speed: 1.101473 steps/s, speed: 8.811785 samples/s, speed: 4511.634008 tokens/s, learning rate: 2.922e-05, loss_scalings: 2814.750488, pp_loss: 7.525466
[INFO] 2021-07-12 19:30:35,931 [run_pretraining.py:  512]:	********exe.run_2923******* 
[INFO] 2021-07-12 19:30:36,879 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:36,880 [run_pretraining.py:  534]:	loss/total_loss, 6.002135276794434, 2924
[INFO] 2021-07-12 19:30:36,880 [run_pretraining.py:  535]:	loss/mlm_loss, 6.002135276794434, 2924
[INFO] 2021-07-12 19:30:36,880 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9229997380753048e-05, 2924
[INFO] 2021-07-12 19:30:36,880 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2924
[INFO] 2021-07-12 19:30:36,880 [run_pretraining.py:  558]:	worker_index: 2, step: 2924, cost: 6.002135, mlm loss: 6.002135, speed: 1.053978 steps/s, speed: 8.431823 samples/s, speed: 4317.093479 tokens/s, learning rate: 2.923e-05, loss_scalings: 2814.750488, pp_loss: 6.972767
[INFO] 2021-07-12 19:30:36,880 [run_pretraining.py:  512]:	********exe.run_2924******* 
[INFO] 2021-07-12 19:30:37,790 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:37,790 [run_pretraining.py:  534]:	loss/total_loss, 7.77493143081665, 2925
[INFO] 2021-07-12 19:30:37,790 [run_pretraining.py:  535]:	loss/mlm_loss, 7.77493143081665, 2925
[INFO] 2021-07-12 19:30:37,790 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9240000003483146e-05, 2925
[INFO] 2021-07-12 19:30:37,790 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2925
[INFO] 2021-07-12 19:30:37,791 [run_pretraining.py:  558]:	worker_index: 2, step: 2925, cost: 7.774931, mlm loss: 7.774931, speed: 1.099044 steps/s, speed: 8.792355 samples/s, speed: 4501.685835 tokens/s, learning rate: 2.924e-05, loss_scalings: 2814.750488, pp_loss: 7.424250
[INFO] 2021-07-12 19:30:37,791 [run_pretraining.py:  512]:	********exe.run_2925******* 
[INFO] 2021-07-12 19:30:38,697 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:38,697 [run_pretraining.py:  534]:	loss/total_loss, 7.15000581741333, 2926
[INFO] 2021-07-12 19:30:38,698 [run_pretraining.py:  535]:	loss/mlm_loss, 7.15000581741333, 2926
[INFO] 2021-07-12 19:30:38,698 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9249998988234438e-05, 2926
[INFO] 2021-07-12 19:30:38,698 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2926
[INFO] 2021-07-12 19:30:38,698 [run_pretraining.py:  558]:	worker_index: 2, step: 2926, cost: 7.150006, mlm loss: 7.150006, speed: 1.102865 steps/s, speed: 8.822923 samples/s, speed: 4517.336577 tokens/s, learning rate: 2.925e-05, loss_scalings: 2814.750488, pp_loss: 6.432035
[INFO] 2021-07-12 19:30:38,698 [run_pretraining.py:  512]:	********exe.run_2926******* 
[INFO] 2021-07-12 19:30:39,605 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:39,605 [run_pretraining.py:  534]:	loss/total_loss, 4.621228218078613, 2927
[INFO] 2021-07-12 19:30:39,606 [run_pretraining.py:  535]:	loss/mlm_loss, 4.621228218078613, 2927
[INFO] 2021-07-12 19:30:39,606 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9259999791975133e-05, 2927
[INFO] 2021-07-12 19:30:39,606 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2927
[INFO] 2021-07-12 19:30:39,606 [run_pretraining.py:  558]:	worker_index: 2, step: 2927, cost: 4.621228, mlm loss: 4.621228, speed: 1.102099 steps/s, speed: 8.816791 samples/s, speed: 4514.197017 tokens/s, learning rate: 2.926e-05, loss_scalings: 2814.750488, pp_loss: 6.371711
[INFO] 2021-07-12 19:30:39,606 [run_pretraining.py:  512]:	********exe.run_2927******* 
[INFO] 2021-07-12 19:30:40,513 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:40,513 [run_pretraining.py:  534]:	loss/total_loss, 7.460306644439697, 2928
[INFO] 2021-07-12 19:30:40,513 [run_pretraining.py:  535]:	loss/mlm_loss, 7.460306644439697, 2928
[INFO] 2021-07-12 19:30:40,513 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9269998776726425e-05, 2928
[INFO] 2021-07-12 19:30:40,513 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2928
[INFO] 2021-07-12 19:30:40,513 [run_pretraining.py:  558]:	worker_index: 2, step: 2928, cost: 7.460307, mlm loss: 7.460307, speed: 1.102523 steps/s, speed: 8.820182 samples/s, speed: 4515.933028 tokens/s, learning rate: 2.927e-05, loss_scalings: 2814.750488, pp_loss: 6.502881
[INFO] 2021-07-12 19:30:40,514 [run_pretraining.py:  512]:	********exe.run_2928******* 
[INFO] 2021-07-12 19:30:41,412 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:41,413 [run_pretraining.py:  534]:	loss/total_loss, 7.7831220626831055, 2929
[INFO] 2021-07-12 19:30:41,413 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7831220626831055, 2929
[INFO] 2021-07-12 19:30:41,413 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.927999958046712e-05, 2929
[INFO] 2021-07-12 19:30:41,413 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2929
[INFO] 2021-07-12 19:30:41,413 [run_pretraining.py:  558]:	worker_index: 2, step: 2929, cost: 7.783122, mlm loss: 7.783122, speed: 1.112260 steps/s, speed: 8.898079 samples/s, speed: 4555.816250 tokens/s, learning rate: 2.928e-05, loss_scalings: 2814.750488, pp_loss: 7.410738
[INFO] 2021-07-12 19:30:41,413 [run_pretraining.py:  512]:	********exe.run_2929******* 
[INFO] 2021-07-12 19:30:42,323 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:42,324 [run_pretraining.py:  534]:	loss/total_loss, 6.898225784301758, 2930
[INFO] 2021-07-12 19:30:42,324 [run_pretraining.py:  535]:	loss/mlm_loss, 6.898225784301758, 2930
[INFO] 2021-07-12 19:30:42,324 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.928999856521841e-05, 2930
[INFO] 2021-07-12 19:30:42,324 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2930
[INFO] 2021-07-12 19:30:42,324 [run_pretraining.py:  558]:	worker_index: 2, step: 2930, cost: 6.898226, mlm loss: 6.898226, speed: 1.098408 steps/s, speed: 8.787262 samples/s, speed: 4499.078097 tokens/s, learning rate: 2.929e-05, loss_scalings: 2814.750488, pp_loss: 7.096907
[INFO] 2021-07-12 19:30:42,324 [run_pretraining.py:  512]:	********exe.run_2930******* 
[INFO] 2021-07-12 19:30:43,240 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:43,241 [run_pretraining.py:  534]:	loss/total_loss, 6.794388294219971, 2931
[INFO] 2021-07-12 19:30:43,241 [run_pretraining.py:  535]:	loss/mlm_loss, 6.794388294219971, 2931
[INFO] 2021-07-12 19:30:43,241 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.930000118794851e-05, 2931
[INFO] 2021-07-12 19:30:43,241 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2931
[INFO] 2021-07-12 19:30:43,241 [run_pretraining.py:  558]:	worker_index: 2, step: 2931, cost: 6.794388, mlm loss: 6.794388, speed: 1.091500 steps/s, speed: 8.731998 samples/s, speed: 4470.783076 tokens/s, learning rate: 2.930e-05, loss_scalings: 2814.750488, pp_loss: 6.397512
[INFO] 2021-07-12 19:30:43,241 [run_pretraining.py:  512]:	********exe.run_2931******* 
[INFO] 2021-07-12 19:30:44,145 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:44,146 [run_pretraining.py:  534]:	loss/total_loss, 6.994653701782227, 2932
[INFO] 2021-07-12 19:30:44,146 [run_pretraining.py:  535]:	loss/mlm_loss, 6.994653701782227, 2932
[INFO] 2021-07-12 19:30:44,146 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9309998353710398e-05, 2932
[INFO] 2021-07-12 19:30:44,146 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2932
[INFO] 2021-07-12 19:30:44,146 [run_pretraining.py:  558]:	worker_index: 2, step: 2932, cost: 6.994654, mlm loss: 6.994654, speed: 1.105409 steps/s, speed: 8.843274 samples/s, speed: 4527.756222 tokens/s, learning rate: 2.931e-05, loss_scalings: 2814.750488, pp_loss: 7.207714
[INFO] 2021-07-12 19:30:44,146 [run_pretraining.py:  512]:	********exe.run_2932******* 
[INFO] 2021-07-12 19:30:45,053 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:45,054 [run_pretraining.py:  534]:	loss/total_loss, 7.747941493988037, 2933
[INFO] 2021-07-12 19:30:45,054 [run_pretraining.py:  535]:	loss/mlm_loss, 7.747941493988037, 2933
[INFO] 2021-07-12 19:30:45,054 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.931999733846169e-05, 2933
[INFO] 2021-07-12 19:30:45,054 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2933
[INFO] 2021-07-12 19:30:45,054 [run_pretraining.py:  558]:	worker_index: 2, step: 2933, cost: 7.747941, mlm loss: 7.747941, speed: 1.102404 steps/s, speed: 8.819236 samples/s, speed: 4515.448757 tokens/s, learning rate: 2.932e-05, loss_scalings: 2814.750488, pp_loss: 7.251103
[INFO] 2021-07-12 19:30:45,054 [run_pretraining.py:  512]:	********exe.run_2933******* 
[INFO] 2021-07-12 19:30:45,960 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:45,961 [run_pretraining.py:  534]:	loss/total_loss, 7.334797382354736, 2934
[INFO] 2021-07-12 19:30:45,961 [run_pretraining.py:  535]:	loss/mlm_loss, 7.334797382354736, 2934
[INFO] 2021-07-12 19:30:45,961 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.932999996119179e-05, 2934
[INFO] 2021-07-12 19:30:45,961 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2934
[INFO] 2021-07-12 19:30:45,961 [run_pretraining.py:  558]:	worker_index: 2, step: 2934, cost: 7.334797, mlm loss: 7.334797, speed: 1.103360 steps/s, speed: 8.826880 samples/s, speed: 4519.362692 tokens/s, learning rate: 2.933e-05, loss_scalings: 2814.750488, pp_loss: 7.050550
[INFO] 2021-07-12 19:30:45,961 [run_pretraining.py:  512]:	********exe.run_2934******* 
[INFO] 2021-07-12 19:30:46,857 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:46,858 [run_pretraining.py:  534]:	loss/total_loss, 6.424188613891602, 2935
[INFO] 2021-07-12 19:30:46,858 [run_pretraining.py:  535]:	loss/mlm_loss, 6.424188613891602, 2935
[INFO] 2021-07-12 19:30:46,858 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.933999894594308e-05, 2935
[INFO] 2021-07-12 19:30:46,858 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2935
[INFO] 2021-07-12 19:30:46,858 [run_pretraining.py:  558]:	worker_index: 2, step: 2935, cost: 6.424189, mlm loss: 6.424189, speed: 1.115154 steps/s, speed: 8.921230 samples/s, speed: 4567.669741 tokens/s, learning rate: 2.934e-05, loss_scalings: 2814.750488, pp_loss: 7.302957
[INFO] 2021-07-12 19:30:46,858 [run_pretraining.py:  512]:	********exe.run_2935******* 
[INFO] 2021-07-12 19:30:47,767 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:47,768 [run_pretraining.py:  534]:	loss/total_loss, 7.147702217102051, 2936
[INFO] 2021-07-12 19:30:47,768 [run_pretraining.py:  535]:	loss/mlm_loss, 7.147702217102051, 2936
[INFO] 2021-07-12 19:30:47,768 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9349999749683775e-05, 2936
[INFO] 2021-07-12 19:30:47,768 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2936
[INFO] 2021-07-12 19:30:47,768 [run_pretraining.py:  558]:	worker_index: 2, step: 2936, cost: 7.147702, mlm loss: 7.147702, speed: 1.100061 steps/s, speed: 8.800488 samples/s, speed: 4505.850092 tokens/s, learning rate: 2.935e-05, loss_scalings: 2814.750488, pp_loss: 7.134901
[INFO] 2021-07-12 19:30:47,768 [run_pretraining.py:  512]:	********exe.run_2936******* 
[INFO] 2021-07-12 19:30:48,671 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:48,672 [run_pretraining.py:  534]:	loss/total_loss, 7.157121658325195, 2937
[INFO] 2021-07-12 19:30:48,672 [run_pretraining.py:  535]:	loss/mlm_loss, 7.157121658325195, 2937
[INFO] 2021-07-12 19:30:48,672 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9359998734435067e-05, 2937
[INFO] 2021-07-12 19:30:48,672 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2937
[INFO] 2021-07-12 19:30:48,672 [run_pretraining.py:  558]:	worker_index: 2, step: 2937, cost: 7.157122, mlm loss: 7.157122, speed: 1.106719 steps/s, speed: 8.853756 samples/s, speed: 4533.122837 tokens/s, learning rate: 2.936e-05, loss_scalings: 2814.750488, pp_loss: 7.296015
[INFO] 2021-07-12 19:30:48,672 [run_pretraining.py:  512]:	********exe.run_2937******* 
[INFO] 2021-07-12 19:30:49,576 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:49,576 [run_pretraining.py:  534]:	loss/total_loss, 7.337258815765381, 2938
[INFO] 2021-07-12 19:30:49,576 [run_pretraining.py:  535]:	loss/mlm_loss, 7.337258815765381, 2938
[INFO] 2021-07-12 19:30:49,577 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9369999538175762e-05, 2938
[INFO] 2021-07-12 19:30:49,577 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2938
[INFO] 2021-07-12 19:30:49,577 [run_pretraining.py:  558]:	worker_index: 2, step: 2938, cost: 7.337259, mlm loss: 7.337259, speed: 1.106173 steps/s, speed: 8.849384 samples/s, speed: 4530.884804 tokens/s, learning rate: 2.937e-05, loss_scalings: 2814.750488, pp_loss: 7.544521
[INFO] 2021-07-12 19:30:49,577 [run_pretraining.py:  512]:	********exe.run_2938******* 
[INFO] 2021-07-12 19:30:50,472 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:50,472 [run_pretraining.py:  534]:	loss/total_loss, 6.740754127502441, 2939
[INFO] 2021-07-12 19:30:50,472 [run_pretraining.py:  535]:	loss/mlm_loss, 6.740754127502441, 2939
[INFO] 2021-07-12 19:30:50,473 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9379998522927053e-05, 2939
[INFO] 2021-07-12 19:30:50,473 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2939
[INFO] 2021-07-12 19:30:50,473 [run_pretraining.py:  558]:	worker_index: 2, step: 2939, cost: 6.740754, mlm loss: 6.740754, speed: 1.116861 steps/s, speed: 8.934892 samples/s, speed: 4574.664575 tokens/s, learning rate: 2.938e-05, loss_scalings: 2814.750488, pp_loss: 6.780865
[INFO] 2021-07-12 19:30:50,473 [run_pretraining.py:  512]:	********exe.run_2939******* 
[INFO] 2021-07-12 19:30:51,374 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:51,375 [run_pretraining.py:  534]:	loss/total_loss, 7.648563861846924, 2940
[INFO] 2021-07-12 19:30:51,375 [run_pretraining.py:  535]:	loss/mlm_loss, 7.648563861846924, 2940
[INFO] 2021-07-12 19:30:51,375 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9390001145657152e-05, 2940
[INFO] 2021-07-12 19:30:51,375 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2940
[INFO] 2021-07-12 19:30:51,375 [run_pretraining.py:  558]:	worker_index: 2, step: 2940, cost: 7.648564, mlm loss: 7.648564, speed: 1.108967 steps/s, speed: 8.871734 samples/s, speed: 4542.327700 tokens/s, learning rate: 2.939e-05, loss_scalings: 2814.750488, pp_loss: 7.340612
[INFO] 2021-07-12 19:30:51,375 [run_pretraining.py:  512]:	********exe.run_2940******* 
[INFO] 2021-07-12 19:30:52,282 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:52,283 [run_pretraining.py:  534]:	loss/total_loss, 6.940299034118652, 2941
[INFO] 2021-07-12 19:30:52,283 [run_pretraining.py:  535]:	loss/mlm_loss, 6.940299034118652, 2941
[INFO] 2021-07-12 19:30:52,283 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9400000130408444e-05, 2941
[INFO] 2021-07-12 19:30:52,283 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2941
[INFO] 2021-07-12 19:30:52,283 [run_pretraining.py:  558]:	worker_index: 2, step: 2941, cost: 6.940299, mlm loss: 6.940299, speed: 1.101863 steps/s, speed: 8.814903 samples/s, speed: 4513.230508 tokens/s, learning rate: 2.940e-05, loss_scalings: 2814.750488, pp_loss: 6.556260
[INFO] 2021-07-12 19:30:52,283 [run_pretraining.py:  512]:	********exe.run_2941******* 
[INFO] 2021-07-12 19:30:53,196 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:53,196 [run_pretraining.py:  534]:	loss/total_loss, 6.148682594299316, 2942
[INFO] 2021-07-12 19:30:53,196 [run_pretraining.py:  535]:	loss/mlm_loss, 6.148682594299316, 2942
[INFO] 2021-07-12 19:30:53,196 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.940999729617033e-05, 2942
[INFO] 2021-07-12 19:30:53,197 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2942
[INFO] 2021-07-12 19:30:53,197 [run_pretraining.py:  558]:	worker_index: 2, step: 2942, cost: 6.148683, mlm loss: 6.148683, speed: 1.095579 steps/s, speed: 8.764635 samples/s, speed: 4487.493090 tokens/s, learning rate: 2.941e-05, loss_scalings: 2814.750488, pp_loss: 7.702252
[INFO] 2021-07-12 19:30:53,197 [run_pretraining.py:  512]:	********exe.run_2942******* 
[INFO] 2021-07-12 19:30:54,103 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:54,104 [run_pretraining.py:  534]:	loss/total_loss, 6.682760715484619, 2943
[INFO] 2021-07-12 19:30:54,104 [run_pretraining.py:  535]:	loss/mlm_loss, 6.682760715484619, 2943
[INFO] 2021-07-12 19:30:54,104 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.941999991890043e-05, 2943
[INFO] 2021-07-12 19:30:54,104 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2943
[INFO] 2021-07-12 19:30:54,104 [run_pretraining.py:  558]:	worker_index: 2, step: 2943, cost: 6.682761, mlm loss: 6.682761, speed: 1.102936 steps/s, speed: 8.823484 samples/s, speed: 4517.624044 tokens/s, learning rate: 2.942e-05, loss_scalings: 2814.750488, pp_loss: 6.816152
[INFO] 2021-07-12 19:30:54,104 [run_pretraining.py:  512]:	********exe.run_2943******* 
[INFO] 2021-07-12 19:30:55,005 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:55,005 [run_pretraining.py:  534]:	loss/total_loss, 6.924853801727295, 2944
[INFO] 2021-07-12 19:30:55,006 [run_pretraining.py:  535]:	loss/mlm_loss, 6.924853801727295, 2944
[INFO] 2021-07-12 19:30:55,006 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9429998903651722e-05, 2944
[INFO] 2021-07-12 19:30:55,006 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2944
[INFO] 2021-07-12 19:30:55,006 [run_pretraining.py:  558]:	worker_index: 2, step: 2944, cost: 6.924854, mlm loss: 6.924854, speed: 1.109495 steps/s, speed: 8.875958 samples/s, speed: 4544.490500 tokens/s, learning rate: 2.943e-05, loss_scalings: 2814.750488, pp_loss: 6.990222
[INFO] 2021-07-12 19:30:55,006 [run_pretraining.py:  512]:	********exe.run_2944******* 
[INFO] 2021-07-12 19:30:55,912 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:55,913 [run_pretraining.py:  534]:	loss/total_loss, 6.863148212432861, 2945
[INFO] 2021-07-12 19:30:55,913 [run_pretraining.py:  535]:	loss/mlm_loss, 6.863148212432861, 2945
[INFO] 2021-07-12 19:30:55,913 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9439999707392417e-05, 2945
[INFO] 2021-07-12 19:30:55,913 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2945
[INFO] 2021-07-12 19:30:55,913 [run_pretraining.py:  558]:	worker_index: 2, step: 2945, cost: 6.863148, mlm loss: 6.863148, speed: 1.103074 steps/s, speed: 8.824594 samples/s, speed: 4518.191958 tokens/s, learning rate: 2.944e-05, loss_scalings: 2814.750488, pp_loss: 6.946787
[INFO] 2021-07-12 19:30:55,913 [run_pretraining.py:  512]:	********exe.run_2945******* 
[INFO] 2021-07-12 19:30:56,812 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:56,812 [run_pretraining.py:  534]:	loss/total_loss, 7.705470085144043, 2946
[INFO] 2021-07-12 19:30:56,812 [run_pretraining.py:  535]:	loss/mlm_loss, 7.705470085144043, 2946
[INFO] 2021-07-12 19:30:56,812 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.944999869214371e-05, 2946
[INFO] 2021-07-12 19:30:56,812 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2946
[INFO] 2021-07-12 19:30:56,812 [run_pretraining.py:  558]:	worker_index: 2, step: 2946, cost: 7.705470, mlm loss: 7.705470, speed: 1.112715 steps/s, speed: 8.901721 samples/s, speed: 4557.681153 tokens/s, learning rate: 2.945e-05, loss_scalings: 2814.750488, pp_loss: 7.393868
[INFO] 2021-07-12 19:30:56,812 [run_pretraining.py:  512]:	********exe.run_2946******* 
[INFO] 2021-07-12 19:30:57,719 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:57,719 [run_pretraining.py:  534]:	loss/total_loss, 6.743950843811035, 2947
[INFO] 2021-07-12 19:30:57,719 [run_pretraining.py:  535]:	loss/mlm_loss, 6.743950843811035, 2947
[INFO] 2021-07-12 19:30:57,719 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9459999495884404e-05, 2947
[INFO] 2021-07-12 19:30:57,719 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2947
[INFO] 2021-07-12 19:30:57,719 [run_pretraining.py:  558]:	worker_index: 2, step: 2947, cost: 6.743951, mlm loss: 6.743951, speed: 1.103211 steps/s, speed: 8.825687 samples/s, speed: 4518.751696 tokens/s, learning rate: 2.946e-05, loss_scalings: 2814.750488, pp_loss: 7.353112
[INFO] 2021-07-12 19:30:57,720 [run_pretraining.py:  512]:	********exe.run_2947******* 
[INFO] 2021-07-12 19:30:58,617 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:58,617 [run_pretraining.py:  534]:	loss/total_loss, 7.0726399421691895, 2948
[INFO] 2021-07-12 19:30:58,617 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0726399421691895, 2948
[INFO] 2021-07-12 19:30:58,617 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9469998480635695e-05, 2948
[INFO] 2021-07-12 19:30:58,618 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2948
[INFO] 2021-07-12 19:30:58,618 [run_pretraining.py:  558]:	worker_index: 2, step: 2948, cost: 7.072640, mlm loss: 7.072640, speed: 1.114204 steps/s, speed: 8.913634 samples/s, speed: 4563.780833 tokens/s, learning rate: 2.947e-05, loss_scalings: 2814.750488, pp_loss: 7.378685
[INFO] 2021-07-12 19:30:58,618 [run_pretraining.py:  512]:	********exe.run_2948******* 
[INFO] 2021-07-12 19:30:59,522 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:59,523 [run_pretraining.py:  534]:	loss/total_loss, 7.2058258056640625, 2949
[INFO] 2021-07-12 19:30:59,523 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2058258056640625, 2949
[INFO] 2021-07-12 19:30:59,523 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9480001103365794e-05, 2949
[INFO] 2021-07-12 19:30:59,523 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2949
[INFO] 2021-07-12 19:30:59,523 [run_pretraining.py:  558]:	worker_index: 2, step: 2949, cost: 7.205826, mlm loss: 7.205826, speed: 1.104863 steps/s, speed: 8.838904 samples/s, speed: 4525.518716 tokens/s, learning rate: 2.948e-05, loss_scalings: 2814.750488, pp_loss: 7.430675
[INFO] 2021-07-12 19:30:59,523 [run_pretraining.py:  512]:	********exe.run_2949******* 
[INFO] 2021-07-12 19:31:00,428 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:00,428 [run_pretraining.py:  534]:	loss/total_loss, 6.9996514320373535, 2950
[INFO] 2021-07-12 19:31:00,428 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9996514320373535, 2950
[INFO] 2021-07-12 19:31:00,428 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9490000088117085e-05, 2950
[INFO] 2021-07-12 19:31:00,429 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2950
[INFO] 2021-07-12 19:31:00,429 [run_pretraining.py:  558]:	worker_index: 2, step: 2950, cost: 6.999651, mlm loss: 6.999651, speed: 1.105425 steps/s, speed: 8.843402 samples/s, speed: 4527.821854 tokens/s, learning rate: 2.949e-05, loss_scalings: 2814.750488, pp_loss: 7.846302
[INFO] 2021-07-12 19:31:00,429 [run_pretraining.py:  512]:	********exe.run_2950******* 
[INFO] 2021-07-12 19:31:01,375 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:01,375 [run_pretraining.py:  534]:	loss/total_loss, 7.594268798828125, 2951
[INFO] 2021-07-12 19:31:01,375 [run_pretraining.py:  535]:	loss/mlm_loss, 7.594268798828125, 2951
[INFO] 2021-07-12 19:31:01,375 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9499997253878973e-05, 2951
[INFO] 2021-07-12 19:31:01,376 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2951
[INFO] 2021-07-12 19:31:01,376 [run_pretraining.py:  558]:	worker_index: 2, step: 2951, cost: 7.594269, mlm loss: 7.594269, speed: 1.056630 steps/s, speed: 8.453039 samples/s, speed: 4327.956059 tokens/s, learning rate: 2.950e-05, loss_scalings: 2814.750488, pp_loss: 7.300995
[INFO] 2021-07-12 19:31:01,376 [run_pretraining.py:  512]:	********exe.run_2951******* 
[INFO] 2021-07-12 19:31:02,280 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:02,281 [run_pretraining.py:  534]:	loss/total_loss, 3.856074810028076, 2952
[INFO] 2021-07-12 19:31:02,281 [run_pretraining.py:  535]:	loss/mlm_loss, 3.856074810028076, 2952
[INFO] 2021-07-12 19:31:02,281 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9509999876609072e-05, 2952
[INFO] 2021-07-12 19:31:02,281 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2952
[INFO] 2021-07-12 19:31:02,281 [run_pretraining.py:  558]:	worker_index: 2, step: 2952, cost: 3.856075, mlm loss: 3.856075, speed: 1.105088 steps/s, speed: 8.840702 samples/s, speed: 4526.439213 tokens/s, learning rate: 2.951e-05, loss_scalings: 2814.750488, pp_loss: 6.250599
[INFO] 2021-07-12 19:31:02,281 [run_pretraining.py:  512]:	********exe.run_2952******* 
[INFO] 2021-07-12 19:31:03,186 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:03,186 [run_pretraining.py:  534]:	loss/total_loss, 6.632121562957764, 2953
[INFO] 2021-07-12 19:31:03,186 [run_pretraining.py:  535]:	loss/mlm_loss, 6.632121562957764, 2953
[INFO] 2021-07-12 19:31:03,186 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9519998861360364e-05, 2953
[INFO] 2021-07-12 19:31:03,186 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2953
[INFO] 2021-07-12 19:31:03,187 [run_pretraining.py:  558]:	worker_index: 2, step: 2953, cost: 6.632122, mlm loss: 6.632122, speed: 1.105229 steps/s, speed: 8.841829 samples/s, speed: 4527.016503 tokens/s, learning rate: 2.952e-05, loss_scalings: 2814.750488, pp_loss: 7.324849
[INFO] 2021-07-12 19:31:03,187 [run_pretraining.py:  512]:	********exe.run_2953******* 
[INFO] 2021-07-12 19:31:04,090 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:04,090 [run_pretraining.py:  534]:	loss/total_loss, 4.189950466156006, 2954
[INFO] 2021-07-12 19:31:04,091 [run_pretraining.py:  535]:	loss/mlm_loss, 4.189950466156006, 2954
[INFO] 2021-07-12 19:31:04,091 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.952999966510106e-05, 2954
[INFO] 2021-07-12 19:31:04,091 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2954
[INFO] 2021-07-12 19:31:04,091 [run_pretraining.py:  558]:	worker_index: 2, step: 2954, cost: 4.189950, mlm loss: 4.189950, speed: 1.106698 steps/s, speed: 8.853585 samples/s, speed: 4533.035522 tokens/s, learning rate: 2.953e-05, loss_scalings: 2814.750488, pp_loss: 6.233036
[INFO] 2021-07-12 19:31:04,091 [run_pretraining.py:  512]:	********exe.run_2954******* 
[INFO] 2021-07-12 19:31:04,985 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:04,986 [run_pretraining.py:  534]:	loss/total_loss, 7.993734359741211, 2955
[INFO] 2021-07-12 19:31:04,986 [run_pretraining.py:  535]:	loss/mlm_loss, 7.993734359741211, 2955
[INFO] 2021-07-12 19:31:04,986 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.953999864985235e-05, 2955
[INFO] 2021-07-12 19:31:04,986 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2955
[INFO] 2021-07-12 19:31:04,986 [run_pretraining.py:  558]:	worker_index: 2, step: 2955, cost: 7.993734, mlm loss: 7.993734, speed: 1.117469 steps/s, speed: 8.939753 samples/s, speed: 4577.153379 tokens/s, learning rate: 2.954e-05, loss_scalings: 2814.750488, pp_loss: 7.508517
[INFO] 2021-07-12 19:31:04,986 [run_pretraining.py:  512]:	********exe.run_2955******* 
[INFO] 2021-07-12 19:31:05,894 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:05,894 [run_pretraining.py:  534]:	loss/total_loss, 5.463589191436768, 2956
[INFO] 2021-07-12 19:31:05,894 [run_pretraining.py:  535]:	loss/mlm_loss, 5.463589191436768, 2956
[INFO] 2021-07-12 19:31:05,894 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9549999453593045e-05, 2956
[INFO] 2021-07-12 19:31:05,894 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2956
[INFO] 2021-07-12 19:31:05,894 [run_pretraining.py:  558]:	worker_index: 2, step: 2956, cost: 5.463589, mlm loss: 5.463589, speed: 1.101818 steps/s, speed: 8.814547 samples/s, speed: 4513.047926 tokens/s, learning rate: 2.955e-05, loss_scalings: 2814.750488, pp_loss: 6.863537
[INFO] 2021-07-12 19:31:05,895 [run_pretraining.py:  512]:	********exe.run_2956******* 
[INFO] 2021-07-12 19:31:06,806 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:06,806 [run_pretraining.py:  534]:	loss/total_loss, 7.128133296966553, 2957
[INFO] 2021-07-12 19:31:06,807 [run_pretraining.py:  535]:	loss/mlm_loss, 7.128133296966553, 2957
[INFO] 2021-07-12 19:31:06,807 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9559998438344337e-05, 2957
[INFO] 2021-07-12 19:31:06,807 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2957
[INFO] 2021-07-12 19:31:06,807 [run_pretraining.py:  558]:	worker_index: 2, step: 2957, cost: 7.128133, mlm loss: 7.128133, speed: 1.096804 steps/s, speed: 8.774431 samples/s, speed: 4492.508511 tokens/s, learning rate: 2.956e-05, loss_scalings: 2814.750488, pp_loss: 7.047661
[INFO] 2021-07-12 19:31:06,807 [run_pretraining.py:  512]:	********exe.run_2957******* 
[INFO] 2021-07-12 19:31:07,716 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:07,717 [run_pretraining.py:  534]:	loss/total_loss, 7.199551105499268, 2958
[INFO] 2021-07-12 19:31:07,717 [run_pretraining.py:  535]:	loss/mlm_loss, 7.199551105499268, 2958
[INFO] 2021-07-12 19:31:07,717 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9570001061074436e-05, 2958
[INFO] 2021-07-12 19:31:07,717 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2958
[INFO] 2021-07-12 19:31:07,717 [run_pretraining.py:  558]:	worker_index: 2, step: 2958, cost: 7.199551, mlm loss: 7.199551, speed: 1.099042 steps/s, speed: 8.792332 samples/s, speed: 4501.674039 tokens/s, learning rate: 2.957e-05, loss_scalings: 2814.750488, pp_loss: 7.276133
[INFO] 2021-07-12 19:31:07,717 [run_pretraining.py:  512]:	********exe.run_2958******* 
[INFO] 2021-07-12 19:31:08,624 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:08,625 [run_pretraining.py:  534]:	loss/total_loss, 7.014954090118408, 2959
[INFO] 2021-07-12 19:31:08,625 [run_pretraining.py:  535]:	loss/mlm_loss, 7.014954090118408, 2959
[INFO] 2021-07-12 19:31:08,625 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9580000045825727e-05, 2959
[INFO] 2021-07-12 19:31:08,625 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2959
[INFO] 2021-07-12 19:31:08,625 [run_pretraining.py:  558]:	worker_index: 2, step: 2959, cost: 7.014954, mlm loss: 7.014954, speed: 1.102523 steps/s, speed: 8.820186 samples/s, speed: 4515.935402 tokens/s, learning rate: 2.958e-05, loss_scalings: 2814.750488, pp_loss: 7.290862
[INFO] 2021-07-12 19:31:08,625 [run_pretraining.py:  512]:	********exe.run_2959******* 
[INFO] 2021-07-12 19:31:09,531 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:09,532 [run_pretraining.py:  534]:	loss/total_loss, 6.298308372497559, 2960
[INFO] 2021-07-12 19:31:09,532 [run_pretraining.py:  535]:	loss/mlm_loss, 6.298308372497559, 2960
[INFO] 2021-07-12 19:31:09,532 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9589997211587615e-05, 2960
[INFO] 2021-07-12 19:31:09,532 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2960
[INFO] 2021-07-12 19:31:09,532 [run_pretraining.py:  558]:	worker_index: 2, step: 2960, cost: 6.298308, mlm loss: 6.298308, speed: 1.103335 steps/s, speed: 8.826678 samples/s, speed: 4519.259263 tokens/s, learning rate: 2.959e-05, loss_scalings: 2814.750488, pp_loss: 6.838167
[INFO] 2021-07-12 19:31:09,532 [run_pretraining.py:  512]:	********exe.run_2960******* 
[INFO] 2021-07-12 19:31:10,441 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:10,442 [run_pretraining.py:  534]:	loss/total_loss, 7.161906719207764, 2961
[INFO] 2021-07-12 19:31:10,442 [run_pretraining.py:  535]:	loss/mlm_loss, 7.161906719207764, 2961
[INFO] 2021-07-12 19:31:10,442 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9599999834317714e-05, 2961
[INFO] 2021-07-12 19:31:10,442 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2961
[INFO] 2021-07-12 19:31:10,442 [run_pretraining.py:  558]:	worker_index: 2, step: 2961, cost: 7.161907, mlm loss: 7.161907, speed: 1.099643 steps/s, speed: 8.797141 samples/s, speed: 4504.135993 tokens/s, learning rate: 2.960e-05, loss_scalings: 2814.750488, pp_loss: 7.182327
[INFO] 2021-07-12 19:31:10,442 [run_pretraining.py:  512]:	********exe.run_2961******* 
[INFO] 2021-07-12 19:31:11,354 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:11,354 [run_pretraining.py:  534]:	loss/total_loss, 7.535501003265381, 2962
[INFO] 2021-07-12 19:31:11,354 [run_pretraining.py:  535]:	loss/mlm_loss, 7.535501003265381, 2962
[INFO] 2021-07-12 19:31:11,354 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9609998819069006e-05, 2962
[INFO] 2021-07-12 19:31:11,354 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2962
[INFO] 2021-07-12 19:31:11,354 [run_pretraining.py:  558]:	worker_index: 2, step: 2962, cost: 7.535501, mlm loss: 7.535501, speed: 1.096527 steps/s, speed: 8.772217 samples/s, speed: 4491.375130 tokens/s, learning rate: 2.961e-05, loss_scalings: 2814.750488, pp_loss: 7.417472
[INFO] 2021-07-12 19:31:11,355 [run_pretraining.py:  512]:	********exe.run_2962******* 
[INFO] 2021-07-12 19:31:12,266 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:12,267 [run_pretraining.py:  534]:	loss/total_loss, 7.37955379486084, 2963
[INFO] 2021-07-12 19:31:12,267 [run_pretraining.py:  535]:	loss/mlm_loss, 7.37955379486084, 2963
[INFO] 2021-07-12 19:31:12,267 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.96199996228097e-05, 2963
[INFO] 2021-07-12 19:31:12,267 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2963
[INFO] 2021-07-12 19:31:12,267 [run_pretraining.py:  558]:	worker_index: 2, step: 2963, cost: 7.379554, mlm loss: 7.379554, speed: 1.096196 steps/s, speed: 8.769567 samples/s, speed: 4490.018176 tokens/s, learning rate: 2.962e-05, loss_scalings: 2814.750488, pp_loss: 6.591671
[INFO] 2021-07-12 19:31:12,267 [run_pretraining.py:  512]:	********exe.run_2963******* 
[INFO] 2021-07-12 19:31:13,168 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:13,169 [run_pretraining.py:  534]:	loss/total_loss, 6.676350116729736, 2964
[INFO] 2021-07-12 19:31:13,169 [run_pretraining.py:  535]:	loss/mlm_loss, 6.676350116729736, 2964
[INFO] 2021-07-12 19:31:13,169 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9629998607560992e-05, 2964
[INFO] 2021-07-12 19:31:13,169 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2964
[INFO] 2021-07-12 19:31:13,169 [run_pretraining.py:  558]:	worker_index: 2, step: 2964, cost: 6.676350, mlm loss: 6.676350, speed: 1.109771 steps/s, speed: 8.878166 samples/s, speed: 4545.620781 tokens/s, learning rate: 2.963e-05, loss_scalings: 2814.750488, pp_loss: 7.079867
[INFO] 2021-07-12 19:31:13,169 [run_pretraining.py:  512]:	********exe.run_2964******* 
[INFO] 2021-07-12 19:31:14,072 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:14,072 [run_pretraining.py:  534]:	loss/total_loss, 7.071684837341309, 2965
[INFO] 2021-07-12 19:31:14,073 [run_pretraining.py:  535]:	loss/mlm_loss, 7.071684837341309, 2965
[INFO] 2021-07-12 19:31:14,073 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9639999411301687e-05, 2965
[INFO] 2021-07-12 19:31:14,073 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2965
[INFO] 2021-07-12 19:31:14,073 [run_pretraining.py:  558]:	worker_index: 2, step: 2965, cost: 7.071685, mlm loss: 7.071685, speed: 1.107275 steps/s, speed: 8.858204 samples/s, speed: 4535.400199 tokens/s, learning rate: 2.964e-05, loss_scalings: 2814.750488, pp_loss: 7.089416
[INFO] 2021-07-12 19:31:14,073 [run_pretraining.py:  512]:	********exe.run_2965******* 
[INFO] 2021-07-12 19:31:14,982 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:14,983 [run_pretraining.py:  534]:	loss/total_loss, 7.7547526359558105, 2966
[INFO] 2021-07-12 19:31:14,983 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7547526359558105, 2966
[INFO] 2021-07-12 19:31:14,983 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.964999839605298e-05, 2966
[INFO] 2021-07-12 19:31:14,983 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2966
[INFO] 2021-07-12 19:31:14,983 [run_pretraining.py:  558]:	worker_index: 2, step: 2966, cost: 7.754753, mlm loss: 7.754753, speed: 1.099006 steps/s, speed: 8.792049 samples/s, speed: 4501.528955 tokens/s, learning rate: 2.965e-05, loss_scalings: 2814.750488, pp_loss: 7.430666
[INFO] 2021-07-12 19:31:14,983 [run_pretraining.py:  512]:	********exe.run_2966******* 
[INFO] 2021-07-12 19:31:15,892 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:15,892 [run_pretraining.py:  534]:	loss/total_loss, 7.063148498535156, 2967
[INFO] 2021-07-12 19:31:15,893 [run_pretraining.py:  535]:	loss/mlm_loss, 7.063148498535156, 2967
[INFO] 2021-07-12 19:31:15,893 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9660001018783078e-05, 2967
[INFO] 2021-07-12 19:31:15,893 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2967
[INFO] 2021-07-12 19:31:15,893 [run_pretraining.py:  558]:	worker_index: 2, step: 2967, cost: 7.063148, mlm loss: 7.063148, speed: 1.100264 steps/s, speed: 8.802109 samples/s, speed: 4506.679849 tokens/s, learning rate: 2.966e-05, loss_scalings: 2814.750488, pp_loss: 7.031356
[INFO] 2021-07-12 19:31:15,893 [run_pretraining.py:  512]:	********exe.run_2967******* 
[INFO] 2021-07-12 19:31:16,822 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:16,823 [run_pretraining.py:  534]:	loss/total_loss, 7.3397064208984375, 2968
[INFO] 2021-07-12 19:31:16,823 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3397064208984375, 2968
[INFO] 2021-07-12 19:31:16,823 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.967000000353437e-05, 2968
[INFO] 2021-07-12 19:31:16,823 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2968
[INFO] 2021-07-12 19:31:16,823 [run_pretraining.py:  558]:	worker_index: 2, step: 2968, cost: 7.339706, mlm loss: 7.339706, speed: 1.075907 steps/s, speed: 8.607258 samples/s, speed: 4406.916188 tokens/s, learning rate: 2.967e-05, loss_scalings: 2814.750488, pp_loss: 7.003761
[INFO] 2021-07-12 19:31:16,823 [run_pretraining.py:  512]:	********exe.run_2968******* 
[INFO] 2021-07-12 19:31:17,879 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:17,880 [run_pretraining.py:  534]:	loss/total_loss, 7.278160572052002, 2969
[INFO] 2021-07-12 19:31:17,880 [run_pretraining.py:  535]:	loss/mlm_loss, 7.278160572052002, 2969
[INFO] 2021-07-12 19:31:17,880 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9679997169296257e-05, 2969
[INFO] 2021-07-12 19:31:17,880 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2969
[INFO] 2021-07-12 19:31:17,880 [run_pretraining.py:  558]:	worker_index: 2, step: 2969, cost: 7.278161, mlm loss: 7.278161, speed: 0.946641 steps/s, speed: 7.573131 samples/s, speed: 3877.443239 tokens/s, learning rate: 2.968e-05, loss_scalings: 2814.750488, pp_loss: 6.617876
[INFO] 2021-07-12 19:31:17,880 [run_pretraining.py:  512]:	********exe.run_2969******* 
[INFO] 2021-07-12 19:31:18,943 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:18,943 [run_pretraining.py:  534]:	loss/total_loss, 7.256852149963379, 2970
[INFO] 2021-07-12 19:31:18,943 [run_pretraining.py:  535]:	loss/mlm_loss, 7.256852149963379, 2970
[INFO] 2021-07-12 19:31:18,943 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9689999792026356e-05, 2970
[INFO] 2021-07-12 19:31:18,943 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2970
[INFO] 2021-07-12 19:31:18,943 [run_pretraining.py:  558]:	worker_index: 2, step: 2970, cost: 7.256852, mlm loss: 7.256852, speed: 0.940777 steps/s, speed: 7.526215 samples/s, speed: 3853.421976 tokens/s, learning rate: 2.969e-05, loss_scalings: 2814.750488, pp_loss: 7.195632
[INFO] 2021-07-12 19:31:18,944 [run_pretraining.py:  512]:	********exe.run_2970******* 
[INFO] 2021-07-12 19:31:19,999 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:19,999 [run_pretraining.py:  534]:	loss/total_loss, 7.577020645141602, 2971
[INFO] 2021-07-12 19:31:19,999 [run_pretraining.py:  535]:	loss/mlm_loss, 7.577020645141602, 2971
[INFO] 2021-07-12 19:31:19,999 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9699998776777647e-05, 2971
[INFO] 2021-07-12 19:31:19,999 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2971
[INFO] 2021-07-12 19:31:19,999 [run_pretraining.py:  558]:	worker_index: 2, step: 2971, cost: 7.577021, mlm loss: 7.577021, speed: 0.947515 steps/s, speed: 7.580123 samples/s, speed: 3881.023185 tokens/s, learning rate: 2.970e-05, loss_scalings: 2814.750488, pp_loss: 7.194417
[INFO] 2021-07-12 19:31:20,000 [run_pretraining.py:  512]:	********exe.run_2971******* 
[INFO] 2021-07-12 19:31:21,040 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:21,040 [run_pretraining.py:  534]:	loss/total_loss, 6.870851516723633, 2972
[INFO] 2021-07-12 19:31:21,040 [run_pretraining.py:  535]:	loss/mlm_loss, 6.870851516723633, 2972
[INFO] 2021-07-12 19:31:21,041 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9709999580518343e-05, 2972
[INFO] 2021-07-12 19:31:21,041 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2972
[INFO] 2021-07-12 19:31:21,041 [run_pretraining.py:  558]:	worker_index: 2, step: 2972, cost: 6.870852, mlm loss: 6.870852, speed: 0.961029 steps/s, speed: 7.688233 samples/s, speed: 3936.375314 tokens/s, learning rate: 2.971e-05, loss_scalings: 2814.750488, pp_loss: 7.223557
[INFO] 2021-07-12 19:31:21,041 [run_pretraining.py:  512]:	********exe.run_2972******* 
[INFO] 2021-07-12 19:31:22,095 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:22,095 [run_pretraining.py:  534]:	loss/total_loss, 7.543773651123047, 2973
[INFO] 2021-07-12 19:31:22,095 [run_pretraining.py:  535]:	loss/mlm_loss, 7.543773651123047, 2973
[INFO] 2021-07-12 19:31:22,095 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9719998565269634e-05, 2973
[INFO] 2021-07-12 19:31:22,095 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2973
[INFO] 2021-07-12 19:31:22,096 [run_pretraining.py:  558]:	worker_index: 2, step: 2973, cost: 7.543774, mlm loss: 7.543774, speed: 0.948602 steps/s, speed: 7.588813 samples/s, speed: 3885.472493 tokens/s, learning rate: 2.972e-05, loss_scalings: 2814.750488, pp_loss: 7.520416
[INFO] 2021-07-12 19:31:22,096 [run_pretraining.py:  512]:	********exe.run_2973******* 
[INFO] 2021-07-12 19:31:23,147 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:23,148 [run_pretraining.py:  534]:	loss/total_loss, 7.346946716308594, 2974
[INFO] 2021-07-12 19:31:23,148 [run_pretraining.py:  535]:	loss/mlm_loss, 7.346946716308594, 2974
[INFO] 2021-07-12 19:31:23,148 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9730001187999733e-05, 2974
[INFO] 2021-07-12 19:31:23,148 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2974
[INFO] 2021-07-12 19:31:23,148 [run_pretraining.py:  558]:	worker_index: 2, step: 2974, cost: 7.346947, mlm loss: 7.346947, speed: 0.950704 steps/s, speed: 7.605629 samples/s, speed: 3894.082238 tokens/s, learning rate: 2.973e-05, loss_scalings: 2814.750488, pp_loss: 7.712055
[INFO] 2021-07-12 19:31:23,148 [run_pretraining.py:  512]:	********exe.run_2974******* 
[INFO] 2021-07-12 19:31:24,205 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:24,206 [run_pretraining.py:  534]:	loss/total_loss, 7.654457092285156, 2975
[INFO] 2021-07-12 19:31:24,206 [run_pretraining.py:  535]:	loss/mlm_loss, 7.654457092285156, 2975
[INFO] 2021-07-12 19:31:24,206 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.973999835376162e-05, 2975
[INFO] 2021-07-12 19:31:24,206 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2975
[INFO] 2021-07-12 19:31:24,206 [run_pretraining.py:  558]:	worker_index: 2, step: 2975, cost: 7.654457, mlm loss: 7.654457, speed: 0.945493 steps/s, speed: 7.563947 samples/s, speed: 3872.740766 tokens/s, learning rate: 2.974e-05, loss_scalings: 2814.750488, pp_loss: 7.342093
[INFO] 2021-07-12 19:31:24,206 [run_pretraining.py:  512]:	********exe.run_2975******* 
[INFO] 2021-07-12 19:31:25,265 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:25,266 [run_pretraining.py:  534]:	loss/total_loss, 6.837610244750977, 2976
[INFO] 2021-07-12 19:31:25,266 [run_pretraining.py:  535]:	loss/mlm_loss, 6.837610244750977, 2976
[INFO] 2021-07-12 19:31:25,266 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.975000097649172e-05, 2976
[INFO] 2021-07-12 19:31:25,266 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2976
[INFO] 2021-07-12 19:31:25,266 [run_pretraining.py:  558]:	worker_index: 2, step: 2976, cost: 6.837610, mlm loss: 6.837610, speed: 0.943984 steps/s, speed: 7.551869 samples/s, speed: 3866.556682 tokens/s, learning rate: 2.975e-05, loss_scalings: 2814.750488, pp_loss: 6.865594
[INFO] 2021-07-12 19:31:25,266 [run_pretraining.py:  512]:	********exe.run_2976******* 
[INFO] 2021-07-12 19:31:26,322 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:26,322 [run_pretraining.py:  534]:	loss/total_loss, 7.644163131713867, 2977
[INFO] 2021-07-12 19:31:26,322 [run_pretraining.py:  535]:	loss/mlm_loss, 7.644163131713867, 2977
[INFO] 2021-07-12 19:31:26,322 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.975999996124301e-05, 2977
[INFO] 2021-07-12 19:31:26,323 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2977
[INFO] 2021-07-12 19:31:26,323 [run_pretraining.py:  558]:	worker_index: 2, step: 2977, cost: 7.644163, mlm loss: 7.644163, speed: 0.947247 steps/s, speed: 7.577977 samples/s, speed: 3879.924060 tokens/s, learning rate: 2.976e-05, loss_scalings: 2814.750488, pp_loss: 7.185538
[INFO] 2021-07-12 19:31:26,323 [run_pretraining.py:  512]:	********exe.run_2977******* 
[INFO] 2021-07-12 19:31:27,379 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:27,379 [run_pretraining.py:  534]:	loss/total_loss, 7.4089813232421875, 2978
[INFO] 2021-07-12 19:31:27,380 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4089813232421875, 2978
[INFO] 2021-07-12 19:31:27,380 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9769998945994303e-05, 2978
[INFO] 2021-07-12 19:31:27,380 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2978
[INFO] 2021-07-12 19:31:27,380 [run_pretraining.py:  558]:	worker_index: 2, step: 2978, cost: 7.408981, mlm loss: 7.408981, speed: 0.946476 steps/s, speed: 7.571809 samples/s, speed: 3876.766009 tokens/s, learning rate: 2.977e-05, loss_scalings: 2814.750488, pp_loss: 7.296449
[INFO] 2021-07-12 19:31:27,380 [run_pretraining.py:  512]:	********exe.run_2978******* 
[INFO] 2021-07-12 19:31:28,421 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:28,422 [run_pretraining.py:  534]:	loss/total_loss, 8.16727066040039, 2979
[INFO] 2021-07-12 19:31:28,422 [run_pretraining.py:  535]:	loss/mlm_loss, 8.16727066040039, 2979
[INFO] 2021-07-12 19:31:28,422 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9779999749734998e-05, 2979
[INFO] 2021-07-12 19:31:28,422 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2979
[INFO] 2021-07-12 19:31:28,422 [run_pretraining.py:  558]:	worker_index: 2, step: 2979, cost: 8.167271, mlm loss: 8.167271, speed: 0.960151 steps/s, speed: 7.681211 samples/s, speed: 3932.779898 tokens/s, learning rate: 2.978e-05, loss_scalings: 2814.750488, pp_loss: 7.427944
[INFO] 2021-07-12 19:31:28,422 [run_pretraining.py:  512]:	********exe.run_2979******* 
[INFO] 2021-07-12 19:31:29,478 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:29,479 [run_pretraining.py:  534]:	loss/total_loss, 7.651160717010498, 2980
[INFO] 2021-07-12 19:31:29,479 [run_pretraining.py:  535]:	loss/mlm_loss, 7.651160717010498, 2980
[INFO] 2021-07-12 19:31:29,479 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.978999873448629e-05, 2980
[INFO] 2021-07-12 19:31:29,479 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2980
[INFO] 2021-07-12 19:31:29,479 [run_pretraining.py:  558]:	worker_index: 2, step: 2980, cost: 7.651161, mlm loss: 7.651161, speed: 0.946442 steps/s, speed: 7.571537 samples/s, speed: 3876.626917 tokens/s, learning rate: 2.979e-05, loss_scalings: 2814.750488, pp_loss: 6.925157
[INFO] 2021-07-12 19:31:29,479 [run_pretraining.py:  512]:	********exe.run_2980******* 
[INFO] 2021-07-12 19:31:30,538 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:30,538 [run_pretraining.py:  534]:	loss/total_loss, 7.061223030090332, 2981
[INFO] 2021-07-12 19:31:30,538 [run_pretraining.py:  535]:	loss/mlm_loss, 7.061223030090332, 2981
[INFO] 2021-07-12 19:31:30,538 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9799999538226984e-05, 2981
[INFO] 2021-07-12 19:31:30,539 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2981
[INFO] 2021-07-12 19:31:30,539 [run_pretraining.py:  558]:	worker_index: 2, step: 2981, cost: 7.061223, mlm loss: 7.061223, speed: 0.944379 steps/s, speed: 7.555031 samples/s, speed: 3868.175969 tokens/s, learning rate: 2.980e-05, loss_scalings: 2814.750488, pp_loss: 6.550377
[INFO] 2021-07-12 19:31:30,539 [run_pretraining.py:  512]:	********exe.run_2981******* 
[INFO] 2021-07-12 19:31:31,598 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:31,599 [run_pretraining.py:  534]:	loss/total_loss, 6.5592265129089355, 2982
[INFO] 2021-07-12 19:31:31,599 [run_pretraining.py:  535]:	loss/mlm_loss, 6.5592265129089355, 2982
[INFO] 2021-07-12 19:31:31,599 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9809998522978276e-05, 2982
[INFO] 2021-07-12 19:31:31,599 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2982
[INFO] 2021-07-12 19:31:31,599 [run_pretraining.py:  558]:	worker_index: 2, step: 2982, cost: 6.559227, mlm loss: 6.559227, speed: 0.943637 steps/s, speed: 7.549092 samples/s, speed: 3865.135266 tokens/s, learning rate: 2.981e-05, loss_scalings: 2814.750488, pp_loss: 7.270433
[INFO] 2021-07-12 19:31:31,599 [run_pretraining.py:  512]:	********exe.run_2982******* 
[INFO] 2021-07-12 19:31:32,652 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:32,653 [run_pretraining.py:  534]:	loss/total_loss, 7.399474620819092, 2983
[INFO] 2021-07-12 19:31:32,653 [run_pretraining.py:  535]:	loss/mlm_loss, 7.399474620819092, 2983
[INFO] 2021-07-12 19:31:32,653 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9820001145708375e-05, 2983
[INFO] 2021-07-12 19:31:32,653 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2983
[INFO] 2021-07-12 19:31:32,653 [run_pretraining.py:  558]:	worker_index: 2, step: 2983, cost: 7.399475, mlm loss: 7.399475, speed: 0.949423 steps/s, speed: 7.595382 samples/s, speed: 3888.835761 tokens/s, learning rate: 2.982e-05, loss_scalings: 2814.750488, pp_loss: 5.088313
[INFO] 2021-07-12 19:31:32,653 [run_pretraining.py:  512]:	********exe.run_2983******* 
[INFO] 2021-07-12 19:31:33,713 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:33,713 [run_pretraining.py:  534]:	loss/total_loss, 6.9872612953186035, 2984
[INFO] 2021-07-12 19:31:33,713 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9872612953186035, 2984
[INFO] 2021-07-12 19:31:33,713 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9829998311470263e-05, 2984
[INFO] 2021-07-12 19:31:33,713 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2984
[INFO] 2021-07-12 19:31:33,714 [run_pretraining.py:  558]:	worker_index: 2, step: 2984, cost: 6.987261, mlm loss: 6.987261, speed: 0.943337 steps/s, speed: 7.546698 samples/s, speed: 3863.909547 tokens/s, learning rate: 2.983e-05, loss_scalings: 2814.750488, pp_loss: 7.256603
[INFO] 2021-07-12 19:31:33,714 [run_pretraining.py:  512]:	********exe.run_2984******* 
[INFO] 2021-07-12 19:31:34,772 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:34,772 [run_pretraining.py:  534]:	loss/total_loss, 7.160006523132324, 2985
[INFO] 2021-07-12 19:31:34,772 [run_pretraining.py:  535]:	loss/mlm_loss, 7.160006523132324, 2985
[INFO] 2021-07-12 19:31:34,772 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.984000093420036e-05, 2985
[INFO] 2021-07-12 19:31:34,772 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2985
[INFO] 2021-07-12 19:31:34,772 [run_pretraining.py:  558]:	worker_index: 2, step: 2985, cost: 7.160007, mlm loss: 7.160007, speed: 0.944980 steps/s, speed: 7.559841 samples/s, speed: 3870.638837 tokens/s, learning rate: 2.984e-05, loss_scalings: 2814.750488, pp_loss: 6.738532
[INFO] 2021-07-12 19:31:34,772 [run_pretraining.py:  512]:	********exe.run_2985******* 
[INFO] 2021-07-12 19:31:35,925 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:35,926 [run_pretraining.py:  534]:	loss/total_loss, 7.088181495666504, 2986
[INFO] 2021-07-12 19:31:35,926 [run_pretraining.py:  535]:	loss/mlm_loss, 7.088181495666504, 2986
[INFO] 2021-07-12 19:31:35,926 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9849999918951653e-05, 2986
[INFO] 2021-07-12 19:31:35,926 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2986
[INFO] 2021-07-12 19:31:35,926 [run_pretraining.py:  558]:	worker_index: 2, step: 2986, cost: 7.088181, mlm loss: 7.088181, speed: 0.867053 steps/s, speed: 6.936424 samples/s, speed: 3551.449208 tokens/s, learning rate: 2.985e-05, loss_scalings: 2814.750488, pp_loss: 7.239740
[INFO] 2021-07-12 19:31:35,926 [run_pretraining.py:  512]:	********exe.run_2986******* 
[INFO] 2021-07-12 19:31:37,047 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:37,047 [run_pretraining.py:  534]:	loss/total_loss, 7.281783103942871, 2987
[INFO] 2021-07-12 19:31:37,047 [run_pretraining.py:  535]:	loss/mlm_loss, 7.281783103942871, 2987
[INFO] 2021-07-12 19:31:37,047 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9859998903702945e-05, 2987
[INFO] 2021-07-12 19:31:37,047 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2987
[INFO] 2021-07-12 19:31:37,048 [run_pretraining.py:  558]:	worker_index: 2, step: 2987, cost: 7.281783, mlm loss: 7.281783, speed: 0.892425 steps/s, speed: 7.139399 samples/s, speed: 3655.372201 tokens/s, learning rate: 2.986e-05, loss_scalings: 2814.750488, pp_loss: 7.153840
[INFO] 2021-07-12 19:31:37,048 [run_pretraining.py:  512]:	********exe.run_2987******* 
[INFO] 2021-07-12 19:31:38,138 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:38,139 [run_pretraining.py:  534]:	loss/total_loss, 7.402977466583252, 2988
[INFO] 2021-07-12 19:31:38,139 [run_pretraining.py:  535]:	loss/mlm_loss, 7.402977466583252, 2988
[INFO] 2021-07-12 19:31:38,139 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.986999970744364e-05, 2988
[INFO] 2021-07-12 19:31:38,139 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2988
[INFO] 2021-07-12 19:31:38,139 [run_pretraining.py:  558]:	worker_index: 2, step: 2988, cost: 7.402977, mlm loss: 7.402977, speed: 0.916814 steps/s, speed: 7.334515 samples/s, speed: 3755.271833 tokens/s, learning rate: 2.987e-05, loss_scalings: 2814.750488, pp_loss: 6.941692
[INFO] 2021-07-12 19:31:38,139 [run_pretraining.py:  512]:	********exe.run_2988******* 
[INFO] 2021-07-12 19:31:39,163 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:39,164 [run_pretraining.py:  534]:	loss/total_loss, 6.902076721191406, 2989
[INFO] 2021-07-12 19:31:39,164 [run_pretraining.py:  535]:	loss/mlm_loss, 6.902076721191406, 2989
[INFO] 2021-07-12 19:31:39,164 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.987999869219493e-05, 2989
[INFO] 2021-07-12 19:31:39,164 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2989
[INFO] 2021-07-12 19:31:39,164 [run_pretraining.py:  558]:	worker_index: 2, step: 2989, cost: 6.902077, mlm loss: 6.902077, speed: 0.976109 steps/s, speed: 7.808870 samples/s, speed: 3998.141289 tokens/s, learning rate: 2.988e-05, loss_scalings: 2814.750488, pp_loss: 7.202022
[INFO] 2021-07-12 19:31:39,164 [run_pretraining.py:  512]:	********exe.run_2989******* 
[INFO] 2021-07-12 19:31:40,077 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:40,077 [run_pretraining.py:  534]:	loss/total_loss, 7.202643394470215, 2990
[INFO] 2021-07-12 19:31:40,077 [run_pretraining.py:  535]:	loss/mlm_loss, 7.202643394470215, 2990
[INFO] 2021-07-12 19:31:40,077 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9889999495935626e-05, 2990
[INFO] 2021-07-12 19:31:40,077 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2990
[INFO] 2021-07-12 19:31:40,077 [run_pretraining.py:  558]:	worker_index: 2, step: 2990, cost: 7.202643, mlm loss: 7.202643, speed: 1.095498 steps/s, speed: 8.763987 samples/s, speed: 4487.161393 tokens/s, learning rate: 2.989e-05, loss_scalings: 2814.750488, pp_loss: 7.395832
[INFO] 2021-07-12 19:31:40,077 [run_pretraining.py:  512]:	********exe.run_2990******* 
[INFO] 2021-07-12 19:31:40,980 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:40,980 [run_pretraining.py:  534]:	loss/total_loss, 7.345446586608887, 2991
[INFO] 2021-07-12 19:31:40,980 [run_pretraining.py:  535]:	loss/mlm_loss, 7.345446586608887, 2991
[INFO] 2021-07-12 19:31:40,980 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9899998480686918e-05, 2991
[INFO] 2021-07-12 19:31:40,980 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2991
[INFO] 2021-07-12 19:31:40,980 [run_pretraining.py:  558]:	worker_index: 2, step: 2991, cost: 7.345447, mlm loss: 7.345447, speed: 1.108073 steps/s, speed: 8.864588 samples/s, speed: 4538.668851 tokens/s, learning rate: 2.990e-05, loss_scalings: 2814.750488, pp_loss: 7.110449
[INFO] 2021-07-12 19:31:40,981 [run_pretraining.py:  512]:	********exe.run_2991******* 
[INFO] 2021-07-12 19:31:41,889 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:41,889 [run_pretraining.py:  534]:	loss/total_loss, 7.707916259765625, 2992
[INFO] 2021-07-12 19:31:41,889 [run_pretraining.py:  535]:	loss/mlm_loss, 7.707916259765625, 2992
[INFO] 2021-07-12 19:31:41,889 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9910001103417017e-05, 2992
[INFO] 2021-07-12 19:31:41,890 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2992
[INFO] 2021-07-12 19:31:41,890 [run_pretraining.py:  558]:	worker_index: 2, step: 2992, cost: 7.707916, mlm loss: 7.707916, speed: 1.100692 steps/s, speed: 8.805537 samples/s, speed: 4508.434927 tokens/s, learning rate: 2.991e-05, loss_scalings: 2814.750488, pp_loss: 7.418505
[INFO] 2021-07-12 19:31:41,890 [run_pretraining.py:  512]:	********exe.run_2992******* 
[INFO] 2021-07-12 19:31:42,791 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:42,792 [run_pretraining.py:  534]:	loss/total_loss, 7.130797386169434, 2993
[INFO] 2021-07-12 19:31:42,792 [run_pretraining.py:  535]:	loss/mlm_loss, 7.130797386169434, 2993
[INFO] 2021-07-12 19:31:42,792 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9919998269178905e-05, 2993
[INFO] 2021-07-12 19:31:42,792 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2993
[INFO] 2021-07-12 19:31:42,792 [run_pretraining.py:  558]:	worker_index: 2, step: 2993, cost: 7.130797, mlm loss: 7.130797, speed: 1.108995 steps/s, speed: 8.871964 samples/s, speed: 4542.445399 tokens/s, learning rate: 2.992e-05, loss_scalings: 2814.750488, pp_loss: 7.418957
[INFO] 2021-07-12 19:31:42,792 [run_pretraining.py:  512]:	********exe.run_2993******* 
[INFO] 2021-07-12 19:31:43,701 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:43,701 [run_pretraining.py:  534]:	loss/total_loss, 7.104211807250977, 2994
[INFO] 2021-07-12 19:31:43,701 [run_pretraining.py:  535]:	loss/mlm_loss, 7.104211807250977, 2994
[INFO] 2021-07-12 19:31:43,701 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9929997253930196e-05, 2994
[INFO] 2021-07-12 19:31:43,701 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2994
[INFO] 2021-07-12 19:31:43,701 [run_pretraining.py:  558]:	worker_index: 2, step: 2994, cost: 7.104212, mlm loss: 7.104212, speed: 1.100319 steps/s, speed: 8.802550 samples/s, speed: 4506.905661 tokens/s, learning rate: 2.993e-05, loss_scalings: 2814.750488, pp_loss: 7.444299
[INFO] 2021-07-12 19:31:43,702 [run_pretraining.py:  512]:	********exe.run_2994******* 
[INFO] 2021-07-12 19:31:44,611 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:44,611 [run_pretraining.py:  534]:	loss/total_loss, 8.034778594970703, 2995
[INFO] 2021-07-12 19:31:44,611 [run_pretraining.py:  535]:	loss/mlm_loss, 8.034778594970703, 2995
[INFO] 2021-07-12 19:31:44,612 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9939999876660295e-05, 2995
[INFO] 2021-07-12 19:31:44,612 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2995
[INFO] 2021-07-12 19:31:44,612 [run_pretraining.py:  558]:	worker_index: 2, step: 2995, cost: 8.034779, mlm loss: 8.034779, speed: 1.099352 steps/s, speed: 8.794819 samples/s, speed: 4502.947168 tokens/s, learning rate: 2.994e-05, loss_scalings: 2814.750488, pp_loss: 7.418471
[INFO] 2021-07-12 19:31:44,612 [run_pretraining.py:  512]:	********exe.run_2995******* 
[INFO] 2021-07-12 19:31:45,516 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:45,516 [run_pretraining.py:  534]:	loss/total_loss, 7.0517754554748535, 2996
[INFO] 2021-07-12 19:31:45,516 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0517754554748535, 2996
[INFO] 2021-07-12 19:31:45,516 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9949998861411586e-05, 2996
[INFO] 2021-07-12 19:31:45,516 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2996
[INFO] 2021-07-12 19:31:45,516 [run_pretraining.py:  558]:	worker_index: 2, step: 2996, cost: 7.051775, mlm loss: 7.051775, speed: 1.106024 steps/s, speed: 8.848190 samples/s, speed: 4530.273077 tokens/s, learning rate: 2.995e-05, loss_scalings: 2814.750488, pp_loss: 7.276441
[INFO] 2021-07-12 19:31:45,517 [run_pretraining.py:  512]:	********exe.run_2996******* 
[INFO] 2021-07-12 19:31:46,412 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:46,412 [run_pretraining.py:  534]:	loss/total_loss, 4.183159828186035, 2997
[INFO] 2021-07-12 19:31:46,412 [run_pretraining.py:  535]:	loss/mlm_loss, 4.183159828186035, 2997
[INFO] 2021-07-12 19:31:46,413 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.995999966515228e-05, 2997
[INFO] 2021-07-12 19:31:46,413 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2997
[INFO] 2021-07-12 19:31:46,413 [run_pretraining.py:  558]:	worker_index: 2, step: 2997, cost: 4.183160, mlm loss: 4.183160, speed: 1.116460 steps/s, speed: 8.931676 samples/s, speed: 4573.018237 tokens/s, learning rate: 2.996e-05, loss_scalings: 2814.750488, pp_loss: 6.482794
[INFO] 2021-07-12 19:31:46,413 [run_pretraining.py:  512]:	********exe.run_2997******* 
[INFO] 2021-07-12 19:31:47,315 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:47,316 [run_pretraining.py:  534]:	loss/total_loss, 6.681430816650391, 2998
[INFO] 2021-07-12 19:31:47,316 [run_pretraining.py:  535]:	loss/mlm_loss, 6.681430816650391, 2998
[INFO] 2021-07-12 19:31:47,316 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9969998649903573e-05, 2998
[INFO] 2021-07-12 19:31:47,316 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2998
[INFO] 2021-07-12 19:31:47,316 [run_pretraining.py:  558]:	worker_index: 2, step: 2998, cost: 6.681431, mlm loss: 6.681431, speed: 1.107587 steps/s, speed: 8.860697 samples/s, speed: 4536.676905 tokens/s, learning rate: 2.997e-05, loss_scalings: 2814.750488, pp_loss: 7.029949
[INFO] 2021-07-12 19:31:47,316 [run_pretraining.py:  512]:	********exe.run_2998******* 
[INFO] 2021-07-12 19:31:48,216 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:48,217 [run_pretraining.py:  534]:	loss/total_loss, 8.34471321105957, 2999
[INFO] 2021-07-12 19:31:48,217 [run_pretraining.py:  535]:	loss/mlm_loss, 8.34471321105957, 2999
[INFO] 2021-07-12 19:31:48,217 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9979999453644268e-05, 2999
[INFO] 2021-07-12 19:31:48,217 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2999
[INFO] 2021-07-12 19:31:48,217 [run_pretraining.py:  558]:	worker_index: 2, step: 2999, cost: 8.344713, mlm loss: 8.344713, speed: 1.110825 steps/s, speed: 8.886597 samples/s, speed: 4549.937851 tokens/s, learning rate: 2.998e-05, loss_scalings: 2814.750488, pp_loss: 7.619672
[INFO] 2021-07-12 19:31:48,217 [run_pretraining.py:  512]:	********exe.run_2999******* 
[INFO] 2021-07-12 19:31:49,138 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:49,139 [run_pretraining.py:  534]:	loss/total_loss, 7.612675666809082, 3000
[INFO] 2021-07-12 19:31:49,139 [run_pretraining.py:  535]:	loss/mlm_loss, 7.612675666809082, 3000
[INFO] 2021-07-12 19:31:49,139 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.998999843839556e-05, 3000
[INFO] 2021-07-12 19:31:49,139 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 3000
[INFO] 2021-07-12 19:31:49,139 [run_pretraining.py:  558]:	worker_index: 2, step: 3000, cost: 7.612676, mlm loss: 7.612676, speed: 1.085419 steps/s, speed: 8.683351 samples/s, speed: 4445.875884 tokens/s, learning rate: 2.999e-05, loss_scalings: 2814.750488, pp_loss: 7.512514
[DEBUG] 2021-07-12 19:31:50,183 [run_pretraining.py:  575]:	saving final models to output/step3000-3p-bs8-npu_2/final_step_3000
[DEBUG] 2021-07-12 19:31:50,183 [run_pretraining.py:  576]:	end of training, total steps: 3000
I0712 19:31:50.184041 48391 lod_tensor_blocking_queue.h:59] LoDTensorBlockingQueue close
I0712 19:31:50.184068 48391 blocking_queue.h:132] close queue
I0712 19:31:50.184654 51933 lod_tensor_blocking_queue.h:59] LoDTensorBlockingQueue close
I0712 19:31:50.184703 51933 blocking_queue.h:132] close queue
I0712 19:31:58.043804 48391 reader.h:164] ~ReaderHolder
I0712 19:31:58.043898 48391 buffered_reader.cc:22] ~BufferedReader
I0712 19:31:58.043907 48391 lod_tensor_blocking_queue.h:59] LoDTensorBlockingQueue close
I0712 19:31:58.043918 48391 blocking_queue.h:132] close queue
I0712 19:31:58.044075 48391 reader.cc:76] ~DecoratedReader
I0712 19:31:58.044090 48391 lod_tensor_blocking_queue.h:59] LoDTensorBlockingQueue close
I0712 19:31:58.044098 48391 blocking_queue.h:132] close queue
I0712 19:31:58.044106 48391 lod_tensor_blocking_queue.h:59] LoDTensorBlockingQueue close
I0712 19:31:58.044137 48391 blocking_queue.h:132] close queue
I0712 19:31:58.045619 48391 reader.h:164] ~ReaderHolder
