/home/gongwb/.local/lib/python3.7/site-packages/setuptools/depends.py:2: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0712 16:56:03.115499 48394 init.cc:88] Before Parse: argc is 2, Init commandline: dummy --tryfromenv=check_nan_inf,benchmark,eager_delete_scope,fraction_of_cpu_memory_to_use,initial_cpu_memory_in_mb,init_allocated_mem,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_system_allocator,enable_unused_var_check,free_idle_chunk,free_when_no_cache_hit,call_stack_level,sort_sum_gradient,max_inplace_grad_add,use_pinned_memory,cpu_deterministic,selected_npus,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,gpu_memory_limit_mb 
I0712 16:56:03.115726 48394 init.cc:95] After Parse: argc is 1
-----------  Configuration Arguments -----------
data_dir: ./data
debug: False
do_eval: True
epoch: 100
ernie_config_file: config/ernie_base_config.json
eval_batch_size: 35
eval_data_path: ./data
eval_steps: -1
global_bsz: 8
global_steps: 0
grad_merge: 0
init_checkpoint: 
learning_rate: 0.0001
log_steps: 1
max_seq_len: 512
micro_bsz: 1
num_dp: 2
num_mp: 2
num_pp: 2
num_sharding: 1
num_train_steps: 3000
output_dir: output/step3000-3p-bs8-npu
preln: False
save_steps: 4000
seed: 2021
use_amp: True
use_hybrid_dp: True
use_lamb: False
use_offload: False
use_recompute: True
use_sharding: True
vocab_file: ./config/30k-clean.vocab.albert
warmup_steps: 10000
weight_decay: 0.01
------------------------------------------------
to run startup
[INFO] 2021-07-12 16:56:03,947 [run_pretraining.py:  216]:	pretraining start
[INFO] 2021-07-12 16:56:03,947 [run_pretraining.py:  234]:	using recompute.
[INFO] 2021-07-12 16:56:03,948 [run_pretraining.py:  279]:	using globa_bsz: 8 micro_bsz: 1, acc_steps: 4
[DEBUG] 2021-07-12 16:56:04,011 [run_pretraining.py:  118]:	========= dp_sharding worker: 0 of 2 ==========
[INFO] 2021-07-12 16:56:04,012 [pretraining_ds_mlm.py:  289]:	Apply sharding in distribution env 0/2
[INFO] 2021-07-12 16:56:04,012 [pretraining_ds_mlm.py:  291]:	read from ./data/part-00000.104,./data/part-00000.107,./data/part-00000.10,./data/part-00000.101,./data/part-00000.106,./data/part-00000.108
I0712 16:56:04.012501 48394 reader_py.cc:387] init_lod_tensor_blocking_queue
INFO:root:places would be ommited when DataLoader is not iterable
/home/liupeng51/github/Paddle/build/build_ubuntu_develop_release_ascend_y_none_3.7.5/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /home/liupeng51/github/FleetX/examples/hybrid_parallelism/model/ernie.py:158
The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
/home/liupeng51/github/Paddle/build/build_ubuntu_develop_release_ascend_y_none_3.7.5/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /home/liupeng51/github/FleetX/examples/hybrid_parallelism/model/ernie.py:159
The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
/home/liupeng51/github/Paddle/build/build_ubuntu_develop_release_ascend_y_none_3.7.5/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /home/liupeng51/github/FleetX/examples/hybrid_parallelism/model/transformer_encoder.py:170
The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
/home/liupeng51/github/Paddle/build/build_ubuntu_develop_release_ascend_y_none_3.7.5/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /home/liupeng51/github/FleetX/examples/hybrid_parallelism/model/transformer_encoder.py:280
The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
/home/liupeng51/github/Paddle/build/build_ubuntu_develop_release_ascend_y_none_3.7.5/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /home/liupeng51/github/FleetX/examples/hybrid_parallelism/model/transformer_encoder.py:43
The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
/home/liupeng51/github/Paddle/build/build_ubuntu_develop_release_ascend_y_none_3.7.5/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /home/liupeng51/github/FleetX/examples/hybrid_parallelism/model/transformer_encoder.py:44
The behavior of expression A * B has been unified with elementwise_mul(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_mul(X, Y, axis=0) instead of A * B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
[DEBUG] 2021-07-12 16:56:04,824 [run_pretraining.py:  315]:	base lr: 0.0001
/home/liupeng51/github/Paddle/build/build_ubuntu_develop_release_ascend_y_none_3.7.5/python/paddle/distributed/fleet/base/fleet_base.py:818: UserWarning: It is recommended to use DistributedStrategy in fleet.init(). The strategy here is only for compatibility. If the strategy in fleet.distributed_optimizer() is not None, then it will overwrite the DistributedStrategy in fleet.init(), which will take effect in distributed training.
  "It is recommended to use DistributedStrategy "
2021-07-12 16:56:04 INFO     Gradient merge in [pp_gm], acc step = [4]
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:Gradient merge in [pp_gm], acc step = [4]
Mon Jul 12 16:56:05-INFO: recompute segment[0]
Mon Jul 12 16:56:05-INFO: segment start op: [squeeze2]: [['shard_index_0.tmp_0']]
Mon Jul 12 16:56:05-INFO: segment end op: [layer_norm]: [['encoder_layer_0_post_ffn_layer_norm_bias', 'encoder_layer_0_post_ffn_layer_norm_scale', 'tmp_10']]
Mon Jul 12 16:56:05-INFO: recompute segment[0]
Mon Jul 12 16:56:05-INFO: segment start op: [squeeze2]: [['shard_index_0.tmp_0']]
Mon Jul 12 16:56:05-INFO: segment end op: [layer_norm]: [['encoder_layer_0_post_ffn_layer_norm_bias', 'encoder_layer_0_post_ffn_layer_norm_scale', 'tmp_10']]
Mon Jul 12 16:56:05-INFO: found [0] vars which cross recompute segment: [set()], better checkpoints might be set to reduce those vars
pp_rank: 1
2021-07-12 16:56:10 INFO     Hybrid DP mode turn on !
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:Hybrid DP mode turn on !
2021-07-12 16:56:10 INFO     global word size: 8
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:global word size: 8
2021-07-12 16:56:10 INFO     global rank: 3
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:global rank: 3
2021-07-12 16:56:10 INFO     global endpoints: ['192.168.206.27:6170', '192.168.206.27:6171', '192.168.206.27:6172', '192.168.206.27:6173', '192.168.206.27:6174', '192.168.206.27:6175', '192.168.206.27:6176', '192.168.206.27:6177']
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:global endpoints: ['192.168.206.27:6170', '192.168.206.27:6171', '192.168.206.27:6172', '192.168.206.27:6173', '192.168.206.27:6174', '192.168.206.27:6175', '192.168.206.27:6176', '192.168.206.27:6177']
2021-07-12 16:56:10 INFO     global ring id: 3
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:global ring id: 3
2021-07-12 16:56:10 INFO     ##############################
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:##############################
2021-07-12 16:56:10 INFO     mp group size: 2
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:mp group size: 2
2021-07-12 16:56:10 INFO     mp rank: 1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:mp rank: 1
2021-07-12 16:56:10 INFO     mp group id: 1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:mp group id: 1
2021-07-12 16:56:10 INFO     mp group endpoints: ['192.168.206.27:6172', '192.168.206.27:6173']
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:mp group endpoints: ['192.168.206.27:6172', '192.168.206.27:6173']
2021-07-12 16:56:10 INFO     mp ring id: 0
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:mp ring id: 0
2021-07-12 16:56:10 INFO     ##############################
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:##############################
2021-07-12 16:56:10 INFO     sharding group size: 1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:sharding group size: 1
2021-07-12 16:56:10 INFO     sharding rank: -1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:sharding rank: -1
2021-07-12 16:56:10 INFO     sharding group id: -1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:sharding group id: -1
2021-07-12 16:56:10 INFO     sharding group endpoints: []
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:sharding group endpoints: []
2021-07-12 16:56:10 INFO     sharding ring id: -1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:sharding ring id: -1
2021-07-12 16:56:10 INFO     ##############################
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:##############################
2021-07-12 16:56:10 INFO     pp group size: 2
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pp group size: 2
2021-07-12 16:56:10 INFO     pp rank: 1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pp rank: 1
2021-07-12 16:56:10 INFO     pp group id: 0
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pp group id: 0
2021-07-12 16:56:10 INFO     pp group endpoints: ['192.168.206.27:6171', '192.168.206.27:6173']
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pp group endpoints: ['192.168.206.27:6171', '192.168.206.27:6173']
2021-07-12 16:56:10 INFO     pp ring id: 20
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pp ring id: 20
2021-07-12 16:56:10 INFO     ##############################
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:##############################
2021-07-12 16:56:10 INFO     pure dp group size: 2
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pure dp group size: 2
2021-07-12 16:56:10 INFO     pure dp rank: 0
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pure dp rank: 0
2021-07-12 16:56:10 INFO     pure dp group endpoints: ['192.168.206.27:6173', '192.168.206.27:6177']
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pure dp group endpoints: ['192.168.206.27:6173', '192.168.206.27:6177']
2021-07-12 16:56:10 INFO     pure dp ring id: 2
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pure dp ring id: 2
2021-07-12 16:56:10 INFO     ##############################
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:##############################
pp pair:(0, 1), ring_id: 20
pp pair:(1, 0), ring_id: 21
I0712 16:56:31.284183 48394 gen_hccl_id_op_helper.cc:181] Server listening on: 192.168.206.27:6173 successful.
I0712 16:56:31.352111 48394 collective_helper_npu.cc:83] initialized comm: 0xffffea181950, nranks: 8, hccl_id: 0x1f6e8084, rank: 3
I0712 16:56:34.201675 48394 collective_helper_npu.cc:88] initialized comm: 0xffffea181950, nranks: 8, hccl_id: 0x1f6e8084, rank: 3
I0712 16:56:34.201905 48394 collective_helper_npu.cc:93] hccl communicator of rank 3 in ring 3 has been created on device 3, with comm: 0x1f861c80
I0712 16:56:36.119997 48394 gen_hccl_id_op_helper.cc:181] Server listening on: 192.168.206.27:6173 successful.
I0712 16:56:36.120990 48394 collective_helper_npu.cc:83] initialized comm: 0xffffea181950, nranks: 2, hccl_id: 0x1f7aa034, rank: 1
I0712 16:56:37.340219 48394 collective_helper_npu.cc:88] initialized comm: 0xffffea181950, nranks: 2, hccl_id: 0x1f7aa034, rank: 1
I0712 16:56:37.340397 48394 collective_helper_npu.cc:93] hccl communicator of rank 1 in ring 0 has been created on device 3, with comm: 0x1f5fe190
I0712 16:56:37.670320 48394 gen_hccl_id_op_helper.cc:181] Server listening on: 192.168.206.27:6173 successful.
I0712 16:56:37.671167 48394 collective_helper_npu.cc:83] initialized comm: 0xffffea181950, nranks: 2, hccl_id: 0x1f7b4a24, rank: 1
I0712 16:56:38.886183 48394 collective_helper_npu.cc:88] initialized comm: 0xffffea181950, nranks: 2, hccl_id: 0x1f7b4a24, rank: 1
I0712 16:56:38.886361 48394 collective_helper_npu.cc:93] hccl communicator of rank 1 in ring 20 has been created on device 3, with comm: 0x1f676e50
W0712 16:56:39.227205 48394 gen_hccl_id_op_helper.cc:120] connect addr=192.168.206.27:6171 failed 1 times with reason: Connection refused retry after 0.5 seconds
I0712 16:56:39.727972 48394 collective_helper_npu.cc:83] initialized comm: 0xffffea181950, nranks: 2, hccl_id: 0x1f7b5a54, rank: 0
I0712 16:56:40.943637 48394 collective_helper_npu.cc:88] initialized comm: 0xffffea181950, nranks: 2, hccl_id: 0x1f7b5a54, rank: 0
I0712 16:56:40.943805 48394 collective_helper_npu.cc:93] hccl communicator of rank 0 in ring 21 has been created on device 3, with comm: 0x1f5fb370
I0712 16:56:41.193645 48394 collective_helper_npu.cc:83] initialized comm: 0xffffea181950, nranks: 2, hccl_id: 0x1f7bc404, rank: 0
I0712 16:56:42.608078 48394 collective_helper_npu.cc:88] initialized comm: 0xffffea181950, nranks: 2, hccl_id: 0x1f7bc404, rank: 0
I0712 16:56:42.608237 48394 collective_helper_npu.cc:93] hccl communicator of rank 0 in ring 2 has been created on device 3, with comm: 0x1f84a710
Done broadcast
[INFO] 2021-07-12 16:56:43,034 [run_pretraining.py:  512]:	********exe.run_0******* 
I0712 16:56:45.838193 51983 lod_tensor_blocking_queue.h:104] Init queue with size 1
I0712 16:56:45.838389 51983 buffered_reader.cc:41] BufferedReader
[INFO] 2021-07-12 17:00:09,810 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:00:09,811 [run_pretraining.py:  534]:	loss/total_loss, 10.35910701751709, 1
[INFO] 2021-07-12 17:00:09,811 [run_pretraining.py:  535]:	loss/mlm_loss, 10.35910701751709, 1
[INFO] 2021-07-12 17:00:09,811 [run_pretraining.py:  536]:	lr/scheduled_lr, 0.0, 1
[INFO] 2021-07-12 17:00:09,812 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 1
[INFO] 2021-07-12 17:00:09,812 [run_pretraining.py:  558]:	worker_index: 3, step: 1, cost: 10.359107, mlm loss: 10.359107, speed: 0.004836 steps/s, speed: 0.038689 samples/s, speed: 19.808709 tokens/s, learning rate: 0.000e+00, loss_scalings: 32768.000000, pp_loss: 9.851339
[INFO] 2021-07-12 17:00:09,812 [run_pretraining.py:  512]:	********exe.run_1******* 
[INFO] 2021-07-12 17:01:50,909 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:01:50,911 [run_pretraining.py:  534]:	loss/total_loss, 10.343825340270996, 2
[INFO] 2021-07-12 17:01:50,911 [run_pretraining.py:  535]:	loss/mlm_loss, 10.343825340270996, 2
[INFO] 2021-07-12 17:01:50,911 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.99999905104687e-09, 2
[INFO] 2021-07-12 17:01:50,911 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 2
[INFO] 2021-07-12 17:01:50,911 [run_pretraining.py:  558]:	worker_index: 3, step: 2, cost: 10.343825, mlm loss: 10.343825, speed: 0.009891 steps/s, speed: 0.079130 samples/s, speed: 40.514760 tokens/s, learning rate: 1.000e-08, loss_scalings: 32768.000000, pp_loss: 10.428656
[INFO] 2021-07-12 17:01:50,912 [run_pretraining.py:  512]:	********exe.run_2******* 
[INFO] 2021-07-12 17:03:30,521 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:03:30,522 [run_pretraining.py:  534]:	loss/total_loss, 10.292773246765137, 3
[INFO] 2021-07-12 17:03:30,522 [run_pretraining.py:  535]:	loss/mlm_loss, 10.292773246765137, 3
[INFO] 2021-07-12 17:03:30,522 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.999999810209374e-08, 3
[INFO] 2021-07-12 17:03:30,523 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 3
[INFO] 2021-07-12 17:03:30,523 [run_pretraining.py:  558]:	worker_index: 3, step: 3, cost: 10.292773, mlm loss: 10.292773, speed: 0.010039 steps/s, speed: 0.080313 samples/s, speed: 41.120169 tokens/s, learning rate: 2.000e-08, loss_scalings: 32768.000000, pp_loss: 9.716020
[INFO] 2021-07-12 17:03:30,523 [run_pretraining.py:  512]:	********exe.run_3******* 
[INFO] 2021-07-12 17:05:10,873 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:05:10,874 [run_pretraining.py:  534]:	loss/total_loss, 10.36631965637207, 4
[INFO] 2021-07-12 17:05:10,875 [run_pretraining.py:  535]:	loss/mlm_loss, 10.36631965637207, 4
[INFO] 2021-07-12 17:05:10,875 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.999999892949745e-08, 4
[INFO] 2021-07-12 17:05:10,875 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 4
[INFO] 2021-07-12 17:05:10,875 [run_pretraining.py:  558]:	worker_index: 3, step: 4, cost: 10.366320, mlm loss: 10.366320, speed: 0.009965 steps/s, speed: 0.079720 samples/s, speed: 40.816569 tokens/s, learning rate: 3.000e-08, loss_scalings: 32768.000000, pp_loss: 10.395509
[INFO] 2021-07-12 17:05:10,875 [run_pretraining.py:  512]:	********exe.run_4******* 
[INFO] 2021-07-12 17:06:52,496 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:06:52,497 [run_pretraining.py:  534]:	loss/total_loss, 10.38914680480957, 5
[INFO] 2021-07-12 17:06:52,497 [run_pretraining.py:  535]:	loss/mlm_loss, 10.38914680480957, 5
[INFO] 2021-07-12 17:06:52,497 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.999999620418748e-08, 5
[INFO] 2021-07-12 17:06:52,497 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 5
[INFO] 2021-07-12 17:06:52,498 [run_pretraining.py:  558]:	worker_index: 3, step: 5, cost: 10.389147, mlm loss: 10.389147, speed: 0.009840 steps/s, speed: 0.078723 samples/s, speed: 40.306240 tokens/s, learning rate: 4.000e-08, loss_scalings: 26214.400391, pp_loss: 9.359282
[INFO] 2021-07-12 17:06:52,498 [run_pretraining.py:  512]:	********exe.run_5******* 
[INFO] 2021-07-12 17:08:33,481 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:08:33,482 [run_pretraining.py:  534]:	loss/total_loss, 10.405525207519531, 6
[INFO] 2021-07-12 17:08:33,482 [run_pretraining.py:  535]:	loss/mlm_loss, 10.405525207519531, 6
[INFO] 2021-07-12 17:08:33,482 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.000000058430487e-08, 6
[INFO] 2021-07-12 17:08:33,482 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 6
[INFO] 2021-07-12 17:08:33,483 [run_pretraining.py:  558]:	worker_index: 3, step: 6, cost: 10.405525, mlm loss: 10.405525, speed: 0.009903 steps/s, speed: 0.079220 samples/s, speed: 40.560808 tokens/s, learning rate: 5.000e-08, loss_scalings: 26214.400391, pp_loss: 10.387331
[INFO] 2021-07-12 17:08:33,483 [run_pretraining.py:  512]:	********exe.run_6******* 
[INFO] 2021-07-12 17:10:13,735 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:10:13,735 [run_pretraining.py:  534]:	loss/total_loss, 10.399020195007324, 7
[INFO] 2021-07-12 17:10:13,735 [run_pretraining.py:  535]:	loss/mlm_loss, 10.399020195007324, 7
[INFO] 2021-07-12 17:10:13,736 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.99999978589949e-08, 7
[INFO] 2021-07-12 17:10:13,736 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 7
[INFO] 2021-07-12 17:10:13,736 [run_pretraining.py:  558]:	worker_index: 3, step: 7, cost: 10.399020, mlm loss: 10.399020, speed: 0.009975 steps/s, speed: 0.079799 samples/s, speed: 40.856855 tokens/s, learning rate: 6.000e-08, loss_scalings: 26214.400391, pp_loss: 9.193569
[INFO] 2021-07-12 17:10:13,736 [run_pretraining.py:  512]:	********exe.run_7******* 
[INFO] 2021-07-12 17:11:53,685 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:11:53,686 [run_pretraining.py:  534]:	loss/total_loss, 10.38516902923584, 8
[INFO] 2021-07-12 17:11:53,686 [run_pretraining.py:  535]:	loss/mlm_loss, 10.38516902923584, 8
[INFO] 2021-07-12 17:11:53,686 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.999999868639861e-08, 8
[INFO] 2021-07-12 17:11:53,686 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 8
[INFO] 2021-07-12 17:11:53,686 [run_pretraining.py:  558]:	worker_index: 3, step: 8, cost: 10.385169, mlm loss: 10.385169, speed: 0.010005 steps/s, speed: 0.080040 samples/s, speed: 40.980490 tokens/s, learning rate: 7.000e-08, loss_scalings: 26214.400391, pp_loss: 10.389960
[INFO] 2021-07-12 17:11:53,687 [run_pretraining.py:  512]:	********exe.run_8******* 
[INFO] 2021-07-12 17:13:32,343 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:13:32,343 [run_pretraining.py:  534]:	loss/total_loss, 10.42738151550293, 9
[INFO] 2021-07-12 17:13:32,344 [run_pretraining.py:  535]:	loss/mlm_loss, 10.42738151550293, 9
[INFO] 2021-07-12 17:13:32,344 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.999999240837496e-08, 9
[INFO] 2021-07-12 17:13:32,344 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 9
[INFO] 2021-07-12 17:13:32,344 [run_pretraining.py:  558]:	worker_index: 3, step: 9, cost: 10.427382, mlm loss: 10.427382, speed: 0.010136 steps/s, speed: 0.081089 samples/s, speed: 41.517737 tokens/s, learning rate: 8.000e-08, loss_scalings: 26214.400391, pp_loss: 10.426338
[INFO] 2021-07-12 17:13:32,344 [run_pretraining.py:  512]:	********exe.run_9******* 
[INFO] 2021-07-12 17:15:11,296 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:15:11,296 [run_pretraining.py:  534]:	loss/total_loss, 10.396768569946289, 10
[INFO] 2021-07-12 17:15:11,296 [run_pretraining.py:  535]:	loss/mlm_loss, 10.396768569946289, 10
[INFO] 2021-07-12 17:15:11,297 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.999999323577867e-08, 10
[INFO] 2021-07-12 17:15:11,297 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 10
[INFO] 2021-07-12 17:15:11,297 [run_pretraining.py:  558]:	worker_index: 3, step: 10, cost: 10.396769, mlm loss: 10.396769, speed: 0.010106 steps/s, speed: 0.080847 samples/s, speed: 41.393707 tokens/s, learning rate: 9.000e-08, loss_scalings: 26214.400391, pp_loss: 10.381718
[INFO] 2021-07-12 17:15:11,297 [run_pretraining.py:  512]:	********exe.run_10******* 
[INFO] 2021-07-12 17:16:00,913 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:16:00,914 [run_pretraining.py:  534]:	loss/total_loss, 10.359121322631836, 11
[INFO] 2021-07-12 17:16:00,914 [run_pretraining.py:  535]:	loss/mlm_loss, 10.359121322631836, 11
[INFO] 2021-07-12 17:16:00,914 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0000000116860974e-07, 11
[INFO] 2021-07-12 17:16:00,914 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 11
[INFO] 2021-07-12 17:16:00,914 [run_pretraining.py:  558]:	worker_index: 3, step: 11, cost: 10.359121, mlm loss: 10.359121, speed: 0.020154 steps/s, speed: 0.161235 samples/s, speed: 82.552228 tokens/s, learning rate: 1.000e-07, loss_scalings: 26214.400391, pp_loss: 10.301442
[INFO] 2021-07-12 17:16:00,915 [run_pretraining.py:  512]:	********exe.run_11******* 
[INFO] 2021-07-12 17:17:35,436 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:17:35,437 [run_pretraining.py:  534]:	loss/total_loss, 10.233663558959961, 12
[INFO] 2021-07-12 17:17:35,437 [run_pretraining.py:  535]:	loss/mlm_loss, 10.233663558959961, 12
[INFO] 2021-07-12 17:17:35,437 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.099999948905861e-07, 12
[INFO] 2021-07-12 17:17:35,437 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 12
[INFO] 2021-07-12 17:17:35,437 [run_pretraining.py:  558]:	worker_index: 3, step: 12, cost: 10.233664, mlm loss: 10.233664, speed: 0.010580 steps/s, speed: 0.084636 samples/s, speed: 43.333804 tokens/s, learning rate: 1.100e-07, loss_scalings: 26214.400391, pp_loss: 9.575712
[INFO] 2021-07-12 17:17:35,437 [run_pretraining.py:  512]:	********exe.run_12******* 
[INFO] 2021-07-12 17:18:51,090 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:18:51,090 [run_pretraining.py:  534]:	loss/total_loss, 10.400777816772461, 13
[INFO] 2021-07-12 17:18:51,091 [run_pretraining.py:  535]:	loss/mlm_loss, 10.400777816772461, 13
[INFO] 2021-07-12 17:18:51,091 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.199999957179898e-07, 13
[INFO] 2021-07-12 17:18:51,091 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 13
[INFO] 2021-07-12 17:18:51,091 [run_pretraining.py:  558]:	worker_index: 3, step: 13, cost: 10.400778, mlm loss: 10.400778, speed: 0.013218 steps/s, speed: 0.105746 samples/s, speed: 54.142051 tokens/s, learning rate: 1.200e-07, loss_scalings: 26214.400391, pp_loss: 10.040232
[INFO] 2021-07-12 17:18:51,091 [run_pretraining.py:  512]:	********exe.run_13******* 
[INFO] 2021-07-12 17:20:05,875 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:20:05,875 [run_pretraining.py:  534]:	loss/total_loss, 10.347989082336426, 14
[INFO] 2021-07-12 17:20:05,875 [run_pretraining.py:  535]:	loss/mlm_loss, 10.347989082336426, 14
[INFO] 2021-07-12 17:20:05,876 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3000000365082087e-07, 14
[INFO] 2021-07-12 17:20:05,876 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 14
[INFO] 2021-07-12 17:20:05,876 [run_pretraining.py:  558]:	worker_index: 3, step: 14, cost: 10.347989, mlm loss: 10.347989, speed: 0.013372 steps/s, speed: 0.106974 samples/s, speed: 54.770923 tokens/s, learning rate: 1.300e-07, loss_scalings: 26214.400391, pp_loss: 10.353008
[INFO] 2021-07-12 17:20:05,876 [run_pretraining.py:  512]:	********exe.run_14******* 
[INFO] 2021-07-12 17:21:43,835 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:21:43,835 [run_pretraining.py:  534]:	loss/total_loss, 10.413568496704102, 15
[INFO] 2021-07-12 17:21:43,835 [run_pretraining.py:  535]:	loss/mlm_loss, 10.413568496704102, 15
[INFO] 2021-07-12 17:21:43,836 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3999999737279722e-07, 15
[INFO] 2021-07-12 17:21:43,836 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 15
[INFO] 2021-07-12 17:21:43,836 [run_pretraining.py:  558]:	worker_index: 3, step: 15, cost: 10.413568, mlm loss: 10.413568, speed: 0.010208 steps/s, speed: 0.081667 samples/s, speed: 41.813295 tokens/s, learning rate: 1.400e-07, loss_scalings: 26214.400391, pp_loss: 10.435228
[INFO] 2021-07-12 17:21:43,836 [run_pretraining.py:  512]:	********exe.run_15******* 
[INFO] 2021-07-12 17:22:59,156 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:22:59,157 [run_pretraining.py:  534]:	loss/total_loss, 10.278934478759766, 16
[INFO] 2021-07-12 17:22:59,157 [run_pretraining.py:  535]:	loss/mlm_loss, 10.278934478759766, 16
[INFO] 2021-07-12 17:22:59,157 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4999999109477358e-07, 16
[INFO] 2021-07-12 17:22:59,157 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 16
[INFO] 2021-07-12 17:22:59,157 [run_pretraining.py:  558]:	worker_index: 3, step: 16, cost: 10.278934, mlm loss: 10.278934, speed: 0.013277 steps/s, speed: 0.106213 samples/s, speed: 54.380974 tokens/s, learning rate: 1.500e-07, loss_scalings: 26214.400391, pp_loss: 10.415889
[INFO] 2021-07-12 17:22:59,157 [run_pretraining.py:  512]:	********exe.run_16******* 
[INFO] 2021-07-12 17:23:49,313 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:23:49,313 [run_pretraining.py:  534]:	loss/total_loss, 10.443610191345215, 17
[INFO] 2021-07-12 17:23:49,313 [run_pretraining.py:  535]:	loss/mlm_loss, 10.443610191345215, 17
[INFO] 2021-07-12 17:23:49,313 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5999998481674993e-07, 17
[INFO] 2021-07-12 17:23:49,313 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 17
[INFO] 2021-07-12 17:23:49,314 [run_pretraining.py:  558]:	worker_index: 3, step: 17, cost: 10.443610, mlm loss: 10.443610, speed: 0.019938 steps/s, speed: 0.159502 samples/s, speed: 81.665207 tokens/s, learning rate: 1.600e-07, loss_scalings: 26214.400391, pp_loss: 10.419422
[INFO] 2021-07-12 17:23:49,314 [run_pretraining.py:  512]:	********exe.run_17******* 
[INFO] 2021-07-12 17:25:28,114 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:25:28,115 [run_pretraining.py:  534]:	loss/total_loss, 10.437760353088379, 18
[INFO] 2021-07-12 17:25:28,115 [run_pretraining.py:  535]:	loss/mlm_loss, 10.437760353088379, 18
[INFO] 2021-07-12 17:25:28,115 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.69999992749581e-07, 18
[INFO] 2021-07-12 17:25:28,115 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 18
[INFO] 2021-07-12 17:25:28,115 [run_pretraining.py:  558]:	worker_index: 3, step: 18, cost: 10.437760, mlm loss: 10.437760, speed: 0.010121 steps/s, speed: 0.080971 samples/s, speed: 41.457038 tokens/s, learning rate: 1.700e-07, loss_scalings: 26214.400391, pp_loss: 10.364226
[INFO] 2021-07-12 17:25:28,116 [run_pretraining.py:  512]:	********exe.run_18******* 
[INFO] 2021-07-12 17:27:03,446 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:27:03,447 [run_pretraining.py:  534]:	loss/total_loss, 10.349979400634766, 19
[INFO] 2021-07-12 17:27:03,447 [run_pretraining.py:  535]:	loss/mlm_loss, 10.349979400634766, 19
[INFO] 2021-07-12 17:27:03,447 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7999998647155735e-07, 19
[INFO] 2021-07-12 17:27:03,447 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 19
[INFO] 2021-07-12 17:27:03,447 [run_pretraining.py:  558]:	worker_index: 3, step: 19, cost: 10.349979, mlm loss: 10.349979, speed: 0.010490 steps/s, speed: 0.083918 samples/s, speed: 42.966091 tokens/s, learning rate: 1.800e-07, loss_scalings: 26214.400391, pp_loss: 10.365602
[INFO] 2021-07-12 17:27:03,447 [run_pretraining.py:  512]:	********exe.run_19******* 
[INFO] 2021-07-12 17:28:18,389 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:28:18,390 [run_pretraining.py:  534]:	loss/total_loss, 10.279297828674316, 20
[INFO] 2021-07-12 17:28:18,390 [run_pretraining.py:  535]:	loss/mlm_loss, 10.279297828674316, 20
[INFO] 2021-07-12 17:28:18,390 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8999999440438842e-07, 20
[INFO] 2021-07-12 17:28:18,390 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 20
[INFO] 2021-07-12 17:28:18,390 [run_pretraining.py:  558]:	worker_index: 3, step: 20, cost: 10.279298, mlm loss: 10.279298, speed: 0.013344 steps/s, speed: 0.106749 samples/s, speed: 54.655272 tokens/s, learning rate: 1.900e-07, loss_scalings: 26214.400391, pp_loss: 10.348002
[INFO] 2021-07-12 17:28:18,390 [run_pretraining.py:  512]:	********exe.run_20******* 
[INFO] 2021-07-12 17:29:07,976 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:29:07,977 [run_pretraining.py:  534]:	loss/total_loss, 10.42486572265625, 21
[INFO] 2021-07-12 17:29:07,977 [run_pretraining.py:  535]:	loss/mlm_loss, 10.42486572265625, 21
[INFO] 2021-07-12 17:29:07,977 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0000000233721948e-07, 21
[INFO] 2021-07-12 17:29:07,977 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 21
[INFO] 2021-07-12 17:29:07,977 [run_pretraining.py:  558]:	worker_index: 3, step: 21, cost: 10.424866, mlm loss: 10.424866, speed: 0.020167 steps/s, speed: 0.161335 samples/s, speed: 82.603431 tokens/s, learning rate: 2.000e-07, loss_scalings: 26214.400391, pp_loss: 10.465428
[INFO] 2021-07-12 17:29:07,977 [run_pretraining.py:  512]:	********exe.run_21******* 
[INFO] 2021-07-12 17:30:23,136 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:30:23,137 [run_pretraining.py:  534]:	loss/total_loss, 10.433841705322266, 22
[INFO] 2021-07-12 17:30:23,137 [run_pretraining.py:  535]:	loss/mlm_loss, 10.433841705322266, 22
[INFO] 2021-07-12 17:30:23,137 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0999998184834112e-07, 22
[INFO] 2021-07-12 17:30:23,137 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 22
[INFO] 2021-07-12 17:30:23,137 [run_pretraining.py:  558]:	worker_index: 3, step: 22, cost: 10.433842, mlm loss: 10.433842, speed: 0.013305 steps/s, speed: 0.106441 samples/s, speed: 54.497902 tokens/s, learning rate: 2.100e-07, loss_scalings: 26214.400391, pp_loss: 10.418213
[INFO] 2021-07-12 17:30:23,137 [run_pretraining.py:  512]:	********exe.run_22******* 
[INFO] 2021-07-12 17:32:00,402 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:32:00,402 [run_pretraining.py:  534]:	loss/total_loss, 10.477655410766602, 23
[INFO] 2021-07-12 17:32:00,403 [run_pretraining.py:  535]:	loss/mlm_loss, 10.477655410766602, 23
[INFO] 2021-07-12 17:32:00,403 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.199999897811722e-07, 23
[INFO] 2021-07-12 17:32:00,403 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 23
[INFO] 2021-07-12 17:32:00,403 [run_pretraining.py:  558]:	worker_index: 3, step: 23, cost: 10.477655, mlm loss: 10.477655, speed: 0.010281 steps/s, speed: 0.082249 samples/s, speed: 42.111681 tokens/s, learning rate: 2.200e-07, loss_scalings: 26214.400391, pp_loss: 10.472509
[INFO] 2021-07-12 17:32:00,403 [run_pretraining.py:  512]:	********exe.run_23******* 
[INFO] 2021-07-12 17:33:12,824 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:33:12,825 [run_pretraining.py:  534]:	loss/total_loss, 10.341408729553223, 24
[INFO] 2021-07-12 17:33:12,825 [run_pretraining.py:  535]:	loss/mlm_loss, 10.341408729553223, 24
[INFO] 2021-07-12 17:33:12,825 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2999999771400326e-07, 24
[INFO] 2021-07-12 17:33:12,825 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 24
[INFO] 2021-07-12 17:33:12,825 [run_pretraining.py:  558]:	worker_index: 3, step: 24, cost: 10.341409, mlm loss: 10.341409, speed: 0.013808 steps/s, speed: 0.110464 samples/s, speed: 56.557505 tokens/s, learning rate: 2.300e-07, loss_scalings: 26214.400391, pp_loss: 10.387544
[INFO] 2021-07-12 17:33:12,825 [run_pretraining.py:  512]:	********exe.run_24******* 
[INFO] 2021-07-12 17:34:27,413 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:34:27,414 [run_pretraining.py:  534]:	loss/total_loss, 10.33614730834961, 25
[INFO] 2021-07-12 17:34:27,414 [run_pretraining.py:  535]:	loss/mlm_loss, 10.33614730834961, 25
[INFO] 2021-07-12 17:34:27,414 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.399999914359796e-07, 25
[INFO] 2021-07-12 17:34:27,414 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 25
[INFO] 2021-07-12 17:34:27,414 [run_pretraining.py:  558]:	worker_index: 3, step: 25, cost: 10.336147, mlm loss: 10.336147, speed: 0.013407 steps/s, speed: 0.107256 samples/s, speed: 54.914925 tokens/s, learning rate: 2.400e-07, loss_scalings: 26214.400391, pp_loss: 10.366696
[INFO] 2021-07-12 17:34:27,414 [run_pretraining.py:  512]:	********exe.run_25******* 
[INFO] 2021-07-12 17:36:04,231 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:36:04,231 [run_pretraining.py:  534]:	loss/total_loss, 10.406084060668945, 26
[INFO] 2021-07-12 17:36:04,231 [run_pretraining.py:  535]:	loss/mlm_loss, 10.406084060668945, 26
[INFO] 2021-07-12 17:36:04,231 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.499999993688107e-07, 26
[INFO] 2021-07-12 17:36:04,231 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 26
[INFO] 2021-07-12 17:36:04,232 [run_pretraining.py:  558]:	worker_index: 3, step: 26, cost: 10.406084, mlm loss: 10.406084, speed: 0.010329 steps/s, speed: 0.082630 samples/s, speed: 42.306785 tokens/s, learning rate: 2.500e-07, loss_scalings: 26214.400391, pp_loss: 10.436119
[INFO] 2021-07-12 17:36:04,232 [run_pretraining.py:  512]:	********exe.run_26******* 
[INFO] 2021-07-12 17:37:41,324 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:37:41,324 [run_pretraining.py:  534]:	loss/total_loss, 6.495910167694092, 27
[INFO] 2021-07-12 17:37:41,325 [run_pretraining.py:  535]:	loss/mlm_loss, 6.495910167694092, 27
[INFO] 2021-07-12 17:37:41,325 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6000000730164174e-07, 27
[INFO] 2021-07-12 17:37:41,325 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 27
[INFO] 2021-07-12 17:37:41,325 [run_pretraining.py:  558]:	worker_index: 3, step: 27, cost: 6.495910, mlm loss: 6.495910, speed: 0.010299 steps/s, speed: 0.082396 samples/s, speed: 42.186574 tokens/s, learning rate: 2.600e-07, loss_scalings: 26214.400391, pp_loss: 9.436955
[INFO] 2021-07-12 17:37:41,325 [run_pretraining.py:  512]:	********exe.run_27******* 
[INFO] 2021-07-12 17:38:32,265 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:38:32,266 [run_pretraining.py:  534]:	loss/total_loss, 10.306541442871094, 28
[INFO] 2021-07-12 17:38:32,266 [run_pretraining.py:  535]:	loss/mlm_loss, 10.306541442871094, 28
[INFO] 2021-07-12 17:38:32,266 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.699999868127634e-07, 28
[INFO] 2021-07-12 17:38:32,266 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 28
[INFO] 2021-07-12 17:38:32,266 [run_pretraining.py:  558]:	worker_index: 3, step: 28, cost: 10.306541, mlm loss: 10.306541, speed: 0.019631 steps/s, speed: 0.157045 samples/s, speed: 80.407275 tokens/s, learning rate: 2.700e-07, loss_scalings: 26214.400391, pp_loss: 10.341423
[INFO] 2021-07-12 17:38:32,266 [run_pretraining.py:  512]:	********exe.run_28******* 
[INFO] 2021-07-12 17:39:43,332 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:39:43,333 [run_pretraining.py:  534]:	loss/total_loss, 10.413204193115234, 29
[INFO] 2021-07-12 17:39:43,333 [run_pretraining.py:  535]:	loss/mlm_loss, 10.413204193115234, 29
[INFO] 2021-07-12 17:39:43,333 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7999999474559445e-07, 29
[INFO] 2021-07-12 17:39:43,333 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 29
[INFO] 2021-07-12 17:39:43,333 [run_pretraining.py:  558]:	worker_index: 3, step: 29, cost: 10.413204, mlm loss: 10.413204, speed: 0.014071 steps/s, speed: 0.112571 samples/s, speed: 57.636229 tokens/s, learning rate: 2.800e-07, loss_scalings: 26214.400391, pp_loss: 10.402435
[INFO] 2021-07-12 17:39:43,333 [run_pretraining.py:  512]:	********exe.run_29******* 
[INFO] 2021-07-12 17:40:32,231 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:40:32,232 [run_pretraining.py:  534]:	loss/total_loss, 10.35503101348877, 30
[INFO] 2021-07-12 17:40:32,232 [run_pretraining.py:  535]:	loss/mlm_loss, 10.35503101348877, 30
[INFO] 2021-07-12 17:40:32,232 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.900000026784255e-07, 30
[INFO] 2021-07-12 17:40:32,232 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 30
[INFO] 2021-07-12 17:40:32,232 [run_pretraining.py:  558]:	worker_index: 3, step: 30, cost: 10.355031, mlm loss: 10.355031, speed: 0.020451 steps/s, speed: 0.163605 samples/s, speed: 83.765689 tokens/s, learning rate: 2.900e-07, loss_scalings: 26214.400391, pp_loss: 10.378284
[INFO] 2021-07-12 17:40:32,232 [run_pretraining.py:  512]:	********exe.run_30******* 
[INFO] 2021-07-12 17:41:23,354 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:41:23,354 [run_pretraining.py:  534]:	loss/total_loss, 10.40434455871582, 31
[INFO] 2021-07-12 17:41:23,354 [run_pretraining.py:  535]:	loss/mlm_loss, 10.40434455871582, 31
[INFO] 2021-07-12 17:41:23,354 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9999998218954715e-07, 31
[INFO] 2021-07-12 17:41:23,354 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 31
[INFO] 2021-07-12 17:41:23,355 [run_pretraining.py:  558]:	worker_index: 3, step: 31, cost: 10.404345, mlm loss: 10.404345, speed: 0.019561 steps/s, speed: 0.156490 samples/s, speed: 80.122834 tokens/s, learning rate: 3.000e-07, loss_scalings: 26214.400391, pp_loss: 10.329590
[INFO] 2021-07-12 17:41:23,355 [run_pretraining.py:  512]:	********exe.run_31******* 
[INFO] 2021-07-12 17:42:13,620 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:42:13,620 [run_pretraining.py:  534]:	loss/total_loss, 10.494878768920898, 32
[INFO] 2021-07-12 17:42:13,621 [run_pretraining.py:  535]:	loss/mlm_loss, 10.494878768920898, 32
[INFO] 2021-07-12 17:42:13,621 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.099999901223782e-07, 32
[INFO] 2021-07-12 17:42:13,621 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 32
[INFO] 2021-07-12 17:42:13,621 [run_pretraining.py:  558]:	worker_index: 3, step: 32, cost: 10.494879, mlm loss: 10.494879, speed: 0.019894 steps/s, speed: 0.159155 samples/s, speed: 81.487198 tokens/s, learning rate: 3.100e-07, loss_scalings: 26214.400391, pp_loss: 9.907797
[INFO] 2021-07-12 17:42:13,621 [run_pretraining.py:  512]:	********exe.run_32******* 
[INFO] 2021-07-12 17:43:03,046 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:43:03,047 [run_pretraining.py:  534]:	loss/total_loss, 10.313619613647461, 33
[INFO] 2021-07-12 17:43:03,047 [run_pretraining.py:  535]:	loss/mlm_loss, 10.313619613647461, 33
[INFO] 2021-07-12 17:43:03,047 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.1999996963349986e-07, 33
[INFO] 2021-07-12 17:43:03,047 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 33
[INFO] 2021-07-12 17:43:03,047 [run_pretraining.py:  558]:	worker_index: 3, step: 33, cost: 10.313620, mlm loss: 10.313620, speed: 0.020232 steps/s, speed: 0.161860 samples/s, speed: 82.872269 tokens/s, learning rate: 3.200e-07, loss_scalings: 26214.400391, pp_loss: 10.360453
[INFO] 2021-07-12 17:43:03,047 [run_pretraining.py:  512]:	********exe.run_33******* 
[INFO] 2021-07-12 17:43:29,441 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:43:29,442 [run_pretraining.py:  534]:	loss/total_loss, 10.332452774047852, 34
[INFO] 2021-07-12 17:43:29,442 [run_pretraining.py:  535]:	loss/mlm_loss, 10.332452774047852, 34
[INFO] 2021-07-12 17:43:29,442 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.2999997756633093e-07, 34
[INFO] 2021-07-12 17:43:29,442 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 34
[INFO] 2021-07-12 17:43:29,442 [run_pretraining.py:  558]:	worker_index: 3, step: 34, cost: 10.332453, mlm loss: 10.332453, speed: 0.037887 steps/s, speed: 0.303094 samples/s, speed: 155.184238 tokens/s, learning rate: 3.300e-07, loss_scalings: 26214.400391, pp_loss: 10.423014
[INFO] 2021-07-12 17:43:29,442 [run_pretraining.py:  512]:	********exe.run_34******* 
[INFO] 2021-07-12 17:44:17,429 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:44:17,429 [run_pretraining.py:  534]:	loss/total_loss, 10.418421745300293, 35
[INFO] 2021-07-12 17:44:17,430 [run_pretraining.py:  535]:	loss/mlm_loss, 10.418421745300293, 35
[INFO] 2021-07-12 17:44:17,430 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.39999985499162e-07, 35
[INFO] 2021-07-12 17:44:17,430 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 35
[INFO] 2021-07-12 17:44:17,430 [run_pretraining.py:  558]:	worker_index: 3, step: 35, cost: 10.418422, mlm loss: 10.418422, speed: 0.020839 steps/s, speed: 0.166712 samples/s, speed: 85.356335 tokens/s, learning rate: 3.400e-07, loss_scalings: 26214.400391, pp_loss: 8.488244
[INFO] 2021-07-12 17:44:17,430 [run_pretraining.py:  512]:	********exe.run_35******* 
[INFO] 2021-07-12 17:44:42,788 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:44:42,788 [run_pretraining.py:  534]:	loss/total_loss, 10.474953651428223, 36
[INFO] 2021-07-12 17:44:42,788 [run_pretraining.py:  535]:	loss/mlm_loss, 10.474953651428223, 36
[INFO] 2021-07-12 17:44:42,788 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.4999999343199306e-07, 36
[INFO] 2021-07-12 17:44:42,788 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 36
[INFO] 2021-07-12 17:44:42,789 [run_pretraining.py:  558]:	worker_index: 3, step: 36, cost: 10.474954, mlm loss: 10.474954, speed: 0.039435 steps/s, speed: 0.315481 samples/s, speed: 161.526492 tokens/s, learning rate: 3.500e-07, loss_scalings: 26214.400391, pp_loss: 10.385915
[INFO] 2021-07-12 17:44:42,789 [run_pretraining.py:  512]:	********exe.run_36******* 
[INFO] 2021-07-12 17:45:32,284 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:45:32,285 [run_pretraining.py:  534]:	loss/total_loss, 10.335034370422363, 37
[INFO] 2021-07-12 17:45:32,285 [run_pretraining.py:  535]:	loss/mlm_loss, 10.335034370422363, 37
[INFO] 2021-07-12 17:45:32,285 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.599999729431147e-07, 37
[INFO] 2021-07-12 17:45:32,285 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 37
[INFO] 2021-07-12 17:45:32,285 [run_pretraining.py:  558]:	worker_index: 3, step: 37, cost: 10.335034, mlm loss: 10.335034, speed: 0.020204 steps/s, speed: 0.161630 samples/s, speed: 82.754662 tokens/s, learning rate: 3.600e-07, loss_scalings: 26214.400391, pp_loss: 10.356068
[INFO] 2021-07-12 17:45:32,285 [run_pretraining.py:  512]:	********exe.run_37******* 
[INFO] 2021-07-12 17:45:33,245 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:45:33,246 [run_pretraining.py:  534]:	loss/total_loss, 10.448802947998047, 38
[INFO] 2021-07-12 17:45:33,246 [run_pretraining.py:  535]:	loss/mlm_loss, 10.448802947998047, 38
[INFO] 2021-07-12 17:45:33,246 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.6999998087594577e-07, 38
[INFO] 2021-07-12 17:45:33,246 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 38
[INFO] 2021-07-12 17:45:33,246 [run_pretraining.py:  558]:	worker_index: 3, step: 38, cost: 10.448803, mlm loss: 10.448803, speed: 1.041074 steps/s, speed: 8.328592 samples/s, speed: 4264.239188 tokens/s, learning rate: 3.700e-07, loss_scalings: 26214.400391, pp_loss: 10.404782
[INFO] 2021-07-12 17:45:33,246 [run_pretraining.py:  512]:	********exe.run_38******* 
[INFO] 2021-07-12 17:46:46,191 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:46:46,192 [run_pretraining.py:  534]:	loss/total_loss, 10.400493621826172, 39
[INFO] 2021-07-12 17:46:46,192 [run_pretraining.py:  535]:	loss/mlm_loss, 10.400493621826172, 39
[INFO] 2021-07-12 17:46:46,192 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.7999998880877683e-07, 39
[INFO] 2021-07-12 17:46:46,192 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 39
[INFO] 2021-07-12 17:46:46,192 [run_pretraining.py:  558]:	worker_index: 3, step: 39, cost: 10.400494, mlm loss: 10.400494, speed: 0.013709 steps/s, speed: 0.109671 samples/s, speed: 56.151487 tokens/s, learning rate: 3.800e-07, loss_scalings: 26214.400391, pp_loss: 10.424288
[INFO] 2021-07-12 17:46:46,193 [run_pretraining.py:  512]:	********exe.run_39******* 
[INFO] 2021-07-12 17:47:10,250 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:47:10,251 [run_pretraining.py:  534]:	loss/total_loss, 10.432218551635742, 40
[INFO] 2021-07-12 17:47:10,251 [run_pretraining.py:  535]:	loss/mlm_loss, 10.432218551635742, 40
[INFO] 2021-07-12 17:47:10,251 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.8999996831989847e-07, 40
[INFO] 2021-07-12 17:47:10,251 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 40
[INFO] 2021-07-12 17:47:10,251 [run_pretraining.py:  558]:	worker_index: 3, step: 40, cost: 10.432219, mlm loss: 10.432219, speed: 0.041566 steps/s, speed: 0.332530 samples/s, speed: 170.255373 tokens/s, learning rate: 3.900e-07, loss_scalings: 26214.400391, pp_loss: 10.336128
[INFO] 2021-07-12 17:47:10,251 [run_pretraining.py:  512]:	********exe.run_40******* 
[INFO] 2021-07-12 17:48:26,854 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:48:26,855 [run_pretraining.py:  534]:	loss/total_loss, 10.34521484375, 41
[INFO] 2021-07-12 17:48:26,855 [run_pretraining.py:  535]:	loss/mlm_loss, 10.34521484375, 41
[INFO] 2021-07-12 17:48:26,855 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.0000000467443897e-07, 41
[INFO] 2021-07-12 17:48:26,855 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 41
[INFO] 2021-07-12 17:48:26,855 [run_pretraining.py:  558]:	worker_index: 3, step: 41, cost: 10.345215, mlm loss: 10.345215, speed: 0.013054 steps/s, speed: 0.104434 samples/s, speed: 53.470330 tokens/s, learning rate: 4.000e-07, loss_scalings: 26214.400391, pp_loss: 10.355732
[INFO] 2021-07-12 17:48:26,855 [run_pretraining.py:  512]:	********exe.run_41******* 
[INFO] 2021-07-12 17:49:41,992 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:49:41,992 [run_pretraining.py:  534]:	loss/total_loss, 5.56919527053833, 42
[INFO] 2021-07-12 17:49:41,993 [run_pretraining.py:  535]:	loss/mlm_loss, 5.56919527053833, 42
[INFO] 2021-07-12 17:49:41,993 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.099999841855606e-07, 42
[INFO] 2021-07-12 17:49:41,993 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 42
[INFO] 2021-07-12 17:49:41,993 [run_pretraining.py:  558]:	worker_index: 3, step: 42, cost: 5.569195, mlm loss: 5.569195, speed: 0.013309 steps/s, speed: 0.106472 samples/s, speed: 54.513659 tokens/s, learning rate: 4.100e-07, loss_scalings: 26214.400391, pp_loss: 9.185887
[INFO] 2021-07-12 17:49:41,993 [run_pretraining.py:  512]:	********exe.run_42******* 
[INFO] 2021-07-12 17:50:07,117 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:50:07,118 [run_pretraining.py:  534]:	loss/total_loss, 10.279674530029297, 43
[INFO] 2021-07-12 17:50:07,118 [run_pretraining.py:  535]:	loss/mlm_loss, 10.279674530029297, 43
[INFO] 2021-07-12 17:50:07,118 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.1999996369668224e-07, 43
[INFO] 2021-07-12 17:50:07,118 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 43
[INFO] 2021-07-12 17:50:07,118 [run_pretraining.py:  558]:	worker_index: 3, step: 43, cost: 10.279675, mlm loss: 10.279675, speed: 0.039801 steps/s, speed: 0.318412 samples/s, speed: 163.026905 tokens/s, learning rate: 4.200e-07, loss_scalings: 26214.400391, pp_loss: 10.377583
[INFO] 2021-07-12 17:50:07,118 [run_pretraining.py:  512]:	********exe.run_43******* 
[INFO] 2021-07-12 17:50:31,965 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:50:31,965 [run_pretraining.py:  534]:	loss/total_loss, 10.404609680175781, 44
[INFO] 2021-07-12 17:50:31,965 [run_pretraining.py:  535]:	loss/mlm_loss, 10.404609680175781, 44
[INFO] 2021-07-12 17:50:31,965 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.3000000005122274e-07, 44
[INFO] 2021-07-12 17:50:31,965 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 44
[INFO] 2021-07-12 17:50:31,965 [run_pretraining.py:  558]:	worker_index: 3, step: 44, cost: 10.404610, mlm loss: 10.404610, speed: 0.040247 steps/s, speed: 0.321975 samples/s, speed: 164.850953 tokens/s, learning rate: 4.300e-07, loss_scalings: 26214.400391, pp_loss: 10.417353
[INFO] 2021-07-12 17:50:31,966 [run_pretraining.py:  512]:	********exe.run_44******* 
[INFO] 2021-07-12 17:51:21,603 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:51:21,603 [run_pretraining.py:  534]:	loss/total_loss, 10.356561660766602, 45
[INFO] 2021-07-12 17:51:21,604 [run_pretraining.py:  535]:	loss/mlm_loss, 10.356561660766602, 45
[INFO] 2021-07-12 17:51:21,604 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.399999795623444e-07, 45
[INFO] 2021-07-12 17:51:21,604 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 45
[INFO] 2021-07-12 17:51:21,604 [run_pretraining.py:  558]:	worker_index: 3, step: 45, cost: 10.356562, mlm loss: 10.356562, speed: 0.020146 steps/s, speed: 0.161168 samples/s, speed: 82.518058 tokens/s, learning rate: 4.400e-07, loss_scalings: 26214.400391, pp_loss: 10.304401
[INFO] 2021-07-12 17:51:21,604 [run_pretraining.py:  512]:	********exe.run_45******* 
[INFO] 2021-07-12 17:51:48,539 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:51:48,540 [run_pretraining.py:  534]:	loss/total_loss, 10.23575210571289, 46
[INFO] 2021-07-12 17:51:48,540 [run_pretraining.py:  535]:	loss/mlm_loss, 10.23575210571289, 46
[INFO] 2021-07-12 17:51:48,540 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.49999959073466e-07, 46
[INFO] 2021-07-12 17:51:48,540 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 46
[INFO] 2021-07-12 17:51:48,540 [run_pretraining.py:  558]:	worker_index: 3, step: 46, cost: 10.235752, mlm loss: 10.235752, speed: 0.037125 steps/s, speed: 0.297002 samples/s, speed: 152.065125 tokens/s, learning rate: 4.500e-07, loss_scalings: 26214.400391, pp_loss: 10.314783
[INFO] 2021-07-12 17:51:48,540 [run_pretraining.py:  512]:	********exe.run_46******* 
[INFO] 2021-07-12 17:52:37,780 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:52:37,780 [run_pretraining.py:  534]:	loss/total_loss, 10.275999069213867, 47
[INFO] 2021-07-12 17:52:37,780 [run_pretraining.py:  535]:	loss/mlm_loss, 10.275999069213867, 47
[INFO] 2021-07-12 17:52:37,781 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.599999954280065e-07, 47
[INFO] 2021-07-12 17:52:37,781 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 47
[INFO] 2021-07-12 17:52:37,781 [run_pretraining.py:  558]:	worker_index: 3, step: 47, cost: 10.275999, mlm loss: 10.275999, speed: 0.020309 steps/s, speed: 0.162470 samples/s, speed: 83.184831 tokens/s, learning rate: 4.600e-07, loss_scalings: 26214.400391, pp_loss: 10.291412
[INFO] 2021-07-12 17:52:37,781 [run_pretraining.py:  512]:	********exe.run_47******* 
[INFO] 2021-07-12 17:53:02,006 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:53:02,006 [run_pretraining.py:  534]:	loss/total_loss, 10.350825309753418, 48
[INFO] 2021-07-12 17:53:02,006 [run_pretraining.py:  535]:	loss/mlm_loss, 10.350825309753418, 48
[INFO] 2021-07-12 17:53:02,006 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.6999997493912815e-07, 48
[INFO] 2021-07-12 17:53:02,006 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 48
[INFO] 2021-07-12 17:53:02,007 [run_pretraining.py:  558]:	worker_index: 3, step: 48, cost: 10.350825, mlm loss: 10.350825, speed: 0.041279 steps/s, speed: 0.330234 samples/s, speed: 169.080049 tokens/s, learning rate: 4.700e-07, loss_scalings: 26214.400391, pp_loss: 9.288650
[INFO] 2021-07-12 17:53:02,007 [run_pretraining.py:  512]:	********exe.run_48******* 
[INFO] 2021-07-12 17:54:14,142 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:54:14,143 [run_pretraining.py:  534]:	loss/total_loss, 10.298990249633789, 49
[INFO] 2021-07-12 17:54:14,143 [run_pretraining.py:  535]:	loss/mlm_loss, 10.298990249633789, 49
[INFO] 2021-07-12 17:54:14,143 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.799999828719592e-07, 49
[INFO] 2021-07-12 17:54:14,143 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 49
[INFO] 2021-07-12 17:54:14,144 [run_pretraining.py:  558]:	worker_index: 3, step: 49, cost: 10.298990, mlm loss: 10.298990, speed: 0.013863 steps/s, speed: 0.110901 samples/s, speed: 56.781417 tokens/s, learning rate: 4.800e-07, loss_scalings: 26214.400391, pp_loss: 10.334993
[INFO] 2021-07-12 17:54:14,144 [run_pretraining.py:  512]:	********exe.run_49******* 
[INFO] 2021-07-12 17:54:39,257 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:54:39,258 [run_pretraining.py:  534]:	loss/total_loss, 10.437005043029785, 50
[INFO] 2021-07-12 17:54:39,258 [run_pretraining.py:  535]:	loss/mlm_loss, 10.437005043029785, 50
[INFO] 2021-07-12 17:54:39,258 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.899999908047903e-07, 50
[INFO] 2021-07-12 17:54:39,258 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 50
[INFO] 2021-07-12 17:54:39,258 [run_pretraining.py:  558]:	worker_index: 3, step: 50, cost: 10.437005, mlm loss: 10.437005, speed: 0.039818 steps/s, speed: 0.318547 samples/s, speed: 163.095873 tokens/s, learning rate: 4.900e-07, loss_scalings: 26214.400391, pp_loss: 10.405973
[INFO] 2021-07-12 17:54:39,258 [run_pretraining.py:  512]:	********exe.run_50******* 
[INFO] 2021-07-12 17:55:04,397 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:55:04,398 [run_pretraining.py:  534]:	loss/total_loss, 10.303500175476074, 51
[INFO] 2021-07-12 17:55:04,398 [run_pretraining.py:  535]:	loss/mlm_loss, 10.303500175476074, 51
[INFO] 2021-07-12 17:55:04,398 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.999999987376214e-07, 51
[INFO] 2021-07-12 17:55:04,398 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 51
[INFO] 2021-07-12 17:55:04,398 [run_pretraining.py:  558]:	worker_index: 3, step: 51, cost: 10.303500, mlm loss: 10.303500, speed: 0.039779 steps/s, speed: 0.318231 samples/s, speed: 162.934438 tokens/s, learning rate: 5.000e-07, loss_scalings: 26214.400391, pp_loss: 10.380037
[INFO] 2021-07-12 17:55:04,398 [run_pretraining.py:  512]:	********exe.run_51******* 
[INFO] 2021-07-12 17:56:38,502 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:56:38,503 [run_pretraining.py:  534]:	loss/total_loss, 10.377527236938477, 52
[INFO] 2021-07-12 17:56:38,503 [run_pretraining.py:  535]:	loss/mlm_loss, 10.377527236938477, 52
[INFO] 2021-07-12 17:56:38,503 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.100000066704524e-07, 52
[INFO] 2021-07-12 17:56:38,503 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 52
[INFO] 2021-07-12 17:56:38,503 [run_pretraining.py:  558]:	worker_index: 3, step: 52, cost: 10.377527, mlm loss: 10.377527, speed: 0.010626 steps/s, speed: 0.085012 samples/s, speed: 43.525943 tokens/s, learning rate: 5.100e-07, loss_scalings: 26214.400391, pp_loss: 9.269762
[INFO] 2021-07-12 17:56:38,504 [run_pretraining.py:  512]:	********exe.run_52******* 
[INFO] 2021-07-12 17:57:01,484 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:57:01,485 [run_pretraining.py:  534]:	loss/total_loss, 10.38437557220459, 53
[INFO] 2021-07-12 17:57:01,485 [run_pretraining.py:  535]:	loss/mlm_loss, 10.38437557220459, 53
[INFO] 2021-07-12 17:57:01,485 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.200000146032835e-07, 53
[INFO] 2021-07-12 17:57:01,485 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 53
[INFO] 2021-07-12 17:57:01,485 [run_pretraining.py:  558]:	worker_index: 3, step: 53, cost: 10.384376, mlm loss: 10.384376, speed: 0.043514 steps/s, speed: 0.348112 samples/s, speed: 178.233495 tokens/s, learning rate: 5.200e-07, loss_scalings: 26214.400391, pp_loss: 10.348297
[INFO] 2021-07-12 17:57:01,485 [run_pretraining.py:  512]:	********exe.run_53******* 
[INFO] 2021-07-12 17:57:26,475 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:57:26,476 [run_pretraining.py:  534]:	loss/total_loss, 10.038942337036133, 54
[INFO] 2021-07-12 17:57:26,476 [run_pretraining.py:  535]:	loss/mlm_loss, 10.038942337036133, 54
[INFO] 2021-07-12 17:57:26,476 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.299999656926957e-07, 54
[INFO] 2021-07-12 17:57:26,476 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 54
[INFO] 2021-07-12 17:57:26,476 [run_pretraining.py:  558]:	worker_index: 3, step: 54, cost: 10.038942, mlm loss: 10.038942, speed: 0.040016 steps/s, speed: 0.320124 samples/s, speed: 163.903658 tokens/s, learning rate: 5.300e-07, loss_scalings: 26214.400391, pp_loss: 10.291219
[INFO] 2021-07-12 17:57:26,476 [run_pretraining.py:  512]:	********exe.run_54******* 
[INFO] 2021-07-12 17:57:51,319 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:57:51,319 [run_pretraining.py:  534]:	loss/total_loss, 10.365704536437988, 55
[INFO] 2021-07-12 17:57:51,320 [run_pretraining.py:  535]:	loss/mlm_loss, 10.365704536437988, 55
[INFO] 2021-07-12 17:57:51,320 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.399999736255268e-07, 55
[INFO] 2021-07-12 17:57:51,320 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 55
[INFO] 2021-07-12 17:57:51,320 [run_pretraining.py:  558]:	worker_index: 3, step: 55, cost: 10.365705, mlm loss: 10.365705, speed: 0.040253 steps/s, speed: 0.322023 samples/s, speed: 164.875845 tokens/s, learning rate: 5.400e-07, loss_scalings: 26214.400391, pp_loss: 10.316601
[INFO] 2021-07-12 17:57:51,320 [run_pretraining.py:  512]:	********exe.run_55******* 
[INFO] 2021-07-12 17:57:52,307 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:57:52,307 [run_pretraining.py:  534]:	loss/total_loss, 10.359591484069824, 56
[INFO] 2021-07-12 17:57:52,307 [run_pretraining.py:  535]:	loss/mlm_loss, 10.359591484069824, 56
[INFO] 2021-07-12 17:57:52,308 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.499999815583578e-07, 56
[INFO] 2021-07-12 17:57:52,308 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 56
[INFO] 2021-07-12 17:57:52,308 [run_pretraining.py:  558]:	worker_index: 3, step: 56, cost: 10.359591, mlm loss: 10.359591, speed: 1.012920 steps/s, speed: 8.103362 samples/s, speed: 4148.921124 tokens/s, learning rate: 5.500e-07, loss_scalings: 26214.400391, pp_loss: 10.419241
[INFO] 2021-07-12 17:57:52,308 [run_pretraining.py:  512]:	********exe.run_56******* 
[INFO] 2021-07-12 17:58:15,803 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:58:15,804 [run_pretraining.py:  534]:	loss/total_loss, 10.29825496673584, 57
[INFO] 2021-07-12 17:58:15,804 [run_pretraining.py:  535]:	loss/mlm_loss, 10.29825496673584, 57
[INFO] 2021-07-12 17:58:15,804 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.599999894911889e-07, 57
[INFO] 2021-07-12 17:58:15,804 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 57
[INFO] 2021-07-12 17:58:15,804 [run_pretraining.py:  558]:	worker_index: 3, step: 57, cost: 10.298255, mlm loss: 10.298255, speed: 0.042560 steps/s, speed: 0.340484 samples/s, speed: 174.327805 tokens/s, learning rate: 5.600e-07, loss_scalings: 26214.400391, pp_loss: 10.335046
[INFO] 2021-07-12 17:58:15,804 [run_pretraining.py:  512]:	********exe.run_57******* 
[INFO] 2021-07-12 17:58:42,072 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:58:42,073 [run_pretraining.py:  534]:	loss/total_loss, 10.461124420166016, 58
[INFO] 2021-07-12 17:58:42,073 [run_pretraining.py:  535]:	loss/mlm_loss, 10.461124420166016, 58
[INFO] 2021-07-12 17:58:42,073 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.6999999742402e-07, 58
[INFO] 2021-07-12 17:58:42,073 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 58
[INFO] 2021-07-12 17:58:42,073 [run_pretraining.py:  558]:	worker_index: 3, step: 58, cost: 10.461124, mlm loss: 10.461124, speed: 0.038069 steps/s, speed: 0.304554 samples/s, speed: 155.931401 tokens/s, learning rate: 5.700e-07, loss_scalings: 26214.400391, pp_loss: 10.406540
[INFO] 2021-07-12 17:58:42,073 [run_pretraining.py:  512]:	********exe.run_58******* 
[INFO] 2021-07-12 17:59:06,976 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:59:06,976 [run_pretraining.py:  534]:	loss/total_loss, 10.376348495483398, 59
[INFO] 2021-07-12 17:59:06,977 [run_pretraining.py:  535]:	loss/mlm_loss, 10.376348495483398, 59
[INFO] 2021-07-12 17:59:06,977 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.80000005356851e-07, 59
[INFO] 2021-07-12 17:59:06,977 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 59
[INFO] 2021-07-12 17:59:06,977 [run_pretraining.py:  558]:	worker_index: 3, step: 59, cost: 10.376348, mlm loss: 10.376348, speed: 0.040155 steps/s, speed: 0.321243 samples/s, speed: 164.476657 tokens/s, learning rate: 5.800e-07, loss_scalings: 26214.400391, pp_loss: 10.320272
[INFO] 2021-07-12 17:59:06,977 [run_pretraining.py:  512]:	********exe.run_59******* 
[INFO] 2021-07-12 17:59:07,937 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:59:07,937 [run_pretraining.py:  534]:	loss/total_loss, 10.380717277526855, 60
[INFO] 2021-07-12 17:59:07,937 [run_pretraining.py:  535]:	loss/mlm_loss, 10.380717277526855, 60
[INFO] 2021-07-12 17:59:07,937 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.900000132896821e-07, 60
[INFO] 2021-07-12 17:59:07,937 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 60
[INFO] 2021-07-12 17:59:07,938 [run_pretraining.py:  558]:	worker_index: 3, step: 60, cost: 10.380717, mlm loss: 10.380717, speed: 1.041562 steps/s, speed: 8.332497 samples/s, speed: 4266.238446 tokens/s, learning rate: 5.900e-07, loss_scalings: 26214.400391, pp_loss: 10.315280
[INFO] 2021-07-12 17:59:07,938 [run_pretraining.py:  512]:	********exe.run_60******* 
[INFO] 2021-07-12 17:59:34,484 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:59:34,485 [run_pretraining.py:  534]:	loss/total_loss, 10.309288024902344, 61
[INFO] 2021-07-12 17:59:34,485 [run_pretraining.py:  535]:	loss/mlm_loss, 10.309288024902344, 61
[INFO] 2021-07-12 17:59:34,485 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.999999643790943e-07, 61
[INFO] 2021-07-12 17:59:34,485 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 61
[INFO] 2021-07-12 17:59:34,485 [run_pretraining.py:  558]:	worker_index: 3, step: 61, cost: 10.309288, mlm loss: 10.309288, speed: 0.037670 steps/s, speed: 0.301356 samples/s, speed: 154.294419 tokens/s, learning rate: 6.000e-07, loss_scalings: 26214.400391, pp_loss: 10.312366
[INFO] 2021-07-12 17:59:34,485 [run_pretraining.py:  512]:	********exe.run_61******* 
[INFO] 2021-07-12 17:59:57,532 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:59:57,532 [run_pretraining.py:  534]:	loss/total_loss, 10.29736614227295, 62
[INFO] 2021-07-12 17:59:57,533 [run_pretraining.py:  535]:	loss/mlm_loss, 10.29736614227295, 62
[INFO] 2021-07-12 17:59:57,533 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.099999723119254e-07, 62
[INFO] 2021-07-12 17:59:57,533 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 62
[INFO] 2021-07-12 17:59:57,533 [run_pretraining.py:  558]:	worker_index: 3, step: 62, cost: 10.297366, mlm loss: 10.297366, speed: 0.043389 steps/s, speed: 0.347114 samples/s, speed: 177.722499 tokens/s, learning rate: 6.100e-07, loss_scalings: 26214.400391, pp_loss: 10.066189
[INFO] 2021-07-12 17:59:57,533 [run_pretraining.py:  512]:	********exe.run_62******* 
[INFO] 2021-07-12 18:00:22,667 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:00:22,667 [run_pretraining.py:  534]:	loss/total_loss, 10.401473045349121, 63
[INFO] 2021-07-12 18:00:22,668 [run_pretraining.py:  535]:	loss/mlm_loss, 10.401473045349121, 63
[INFO] 2021-07-12 18:00:22,668 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.199999802447564e-07, 63
[INFO] 2021-07-12 18:00:22,668 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 63
[INFO] 2021-07-12 18:00:22,668 [run_pretraining.py:  558]:	worker_index: 3, step: 63, cost: 10.401473, mlm loss: 10.401473, speed: 0.039786 steps/s, speed: 0.318289 samples/s, speed: 162.964128 tokens/s, learning rate: 6.200e-07, loss_scalings: 26214.400391, pp_loss: 10.360827
[INFO] 2021-07-12 18:00:22,668 [run_pretraining.py:  512]:	********exe.run_63******* 
[INFO] 2021-07-12 18:00:47,675 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:00:47,675 [run_pretraining.py:  534]:	loss/total_loss, 10.442109107971191, 64
[INFO] 2021-07-12 18:00:47,675 [run_pretraining.py:  535]:	loss/mlm_loss, 10.442109107971191, 64
[INFO] 2021-07-12 18:00:47,675 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.299999881775875e-07, 64
[INFO] 2021-07-12 18:00:47,675 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 64
[INFO] 2021-07-12 18:00:47,675 [run_pretraining.py:  558]:	worker_index: 3, step: 64, cost: 10.442109, mlm loss: 10.442109, speed: 0.039989 steps/s, speed: 0.319911 samples/s, speed: 163.794291 tokens/s, learning rate: 6.300e-07, loss_scalings: 26214.400391, pp_loss: 10.338017
[INFO] 2021-07-12 18:00:47,676 [run_pretraining.py:  512]:	********exe.run_64******* 
[INFO] 2021-07-12 18:01:34,936 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:01:34,936 [run_pretraining.py:  534]:	loss/total_loss, 10.264923095703125, 65
[INFO] 2021-07-12 18:01:34,937 [run_pretraining.py:  535]:	loss/mlm_loss, 10.264923095703125, 65
[INFO] 2021-07-12 18:01:34,937 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.399999392669997e-07, 65
[INFO] 2021-07-12 18:01:34,937 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 65
[INFO] 2021-07-12 18:01:34,937 [run_pretraining.py:  558]:	worker_index: 3, step: 65, cost: 10.264923, mlm loss: 10.264923, speed: 0.021159 steps/s, speed: 0.169274 samples/s, speed: 86.668287 tokens/s, learning rate: 6.400e-07, loss_scalings: 26214.400391, pp_loss: 10.327194
[INFO] 2021-07-12 18:01:34,937 [run_pretraining.py:  512]:	********exe.run_65******* 
[INFO] 2021-07-12 18:01:58,674 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:01:58,674 [run_pretraining.py:  534]:	loss/total_loss, 10.47647476196289, 66
[INFO] 2021-07-12 18:01:58,674 [run_pretraining.py:  535]:	loss/mlm_loss, 10.47647476196289, 66
[INFO] 2021-07-12 18:01:58,674 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.500000040432496e-07, 66
[INFO] 2021-07-12 18:01:58,674 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 66
[INFO] 2021-07-12 18:01:58,674 [run_pretraining.py:  558]:	worker_index: 3, step: 66, cost: 10.476475, mlm loss: 10.476475, speed: 0.042128 steps/s, speed: 0.337027 samples/s, speed: 172.557879 tokens/s, learning rate: 6.500e-07, loss_scalings: 26214.400391, pp_loss: 10.339863
[INFO] 2021-07-12 18:01:58,674 [run_pretraining.py:  512]:	********exe.run_66******* 
[INFO] 2021-07-12 18:02:24,255 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:02:24,256 [run_pretraining.py:  534]:	loss/total_loss, 10.355547904968262, 67
[INFO] 2021-07-12 18:02:24,256 [run_pretraining.py:  535]:	loss/mlm_loss, 10.355547904968262, 67
[INFO] 2021-07-12 18:02:24,256 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.599999551326619e-07, 67
[INFO] 2021-07-12 18:02:24,256 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 67
[INFO] 2021-07-12 18:02:24,256 [run_pretraining.py:  558]:	worker_index: 3, step: 67, cost: 10.355548, mlm loss: 10.355548, speed: 0.039092 steps/s, speed: 0.312733 samples/s, speed: 160.119300 tokens/s, learning rate: 6.600e-07, loss_scalings: 26214.400391, pp_loss: 10.371203
[INFO] 2021-07-12 18:02:24,256 [run_pretraining.py:  512]:	********exe.run_67******* 
[INFO] 2021-07-12 18:03:12,747 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:03:12,747 [run_pretraining.py:  534]:	loss/total_loss, 10.31266975402832, 68
[INFO] 2021-07-12 18:03:12,747 [run_pretraining.py:  535]:	loss/mlm_loss, 10.31266975402832, 68
[INFO] 2021-07-12 18:03:12,747 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.699999630654929e-07, 68
[INFO] 2021-07-12 18:03:12,747 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 68
[INFO] 2021-07-12 18:03:12,748 [run_pretraining.py:  558]:	worker_index: 3, step: 68, cost: 10.312670, mlm loss: 10.312670, speed: 0.020622 steps/s, speed: 0.164979 samples/s, speed: 84.469490 tokens/s, learning rate: 6.700e-07, loss_scalings: 26214.400391, pp_loss: 10.311956
[INFO] 2021-07-12 18:03:12,748 [run_pretraining.py:  512]:	********exe.run_68******* 
[INFO] 2021-07-12 18:03:37,911 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:03:37,912 [run_pretraining.py:  534]:	loss/total_loss, 10.38314437866211, 69
[INFO] 2021-07-12 18:03:37,912 [run_pretraining.py:  535]:	loss/mlm_loss, 10.38314437866211, 69
[INFO] 2021-07-12 18:03:37,912 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.79999970998324e-07, 69
[INFO] 2021-07-12 18:03:37,912 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 69
[INFO] 2021-07-12 18:03:37,912 [run_pretraining.py:  558]:	worker_index: 3, step: 69, cost: 10.383144, mlm loss: 10.383144, speed: 0.039740 steps/s, speed: 0.317919 samples/s, speed: 162.774540 tokens/s, learning rate: 6.800e-07, loss_scalings: 26214.400391, pp_loss: 10.319208
[INFO] 2021-07-12 18:03:37,912 [run_pretraining.py:  512]:	********exe.run_69******* 
[INFO] 2021-07-12 18:04:03,926 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:04:03,927 [run_pretraining.py:  534]:	loss/total_loss, 10.339315414428711, 70
[INFO] 2021-07-12 18:04:03,927 [run_pretraining.py:  535]:	loss/mlm_loss, 10.339315414428711, 70
[INFO] 2021-07-12 18:04:03,927 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.899999789311551e-07, 70
[INFO] 2021-07-12 18:04:03,927 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 70
[INFO] 2021-07-12 18:04:03,927 [run_pretraining.py:  558]:	worker_index: 3, step: 70, cost: 10.339315, mlm loss: 10.339315, speed: 0.038440 steps/s, speed: 0.307522 samples/s, speed: 157.451207 tokens/s, learning rate: 6.900e-07, loss_scalings: 26214.400391, pp_loss: 10.274405
[INFO] 2021-07-12 18:04:03,927 [run_pretraining.py:  512]:	********exe.run_70******* 
[INFO] 2021-07-12 18:04:29,002 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:04:29,002 [run_pretraining.py:  534]:	loss/total_loss, 10.11802864074707, 71
[INFO] 2021-07-12 18:04:29,003 [run_pretraining.py:  535]:	loss/mlm_loss, 10.11802864074707, 71
[INFO] 2021-07-12 18:04:29,003 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.999999868639861e-07, 71
[INFO] 2021-07-12 18:04:29,003 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 71
[INFO] 2021-07-12 18:04:29,003 [run_pretraining.py:  558]:	worker_index: 3, step: 71, cost: 10.118029, mlm loss: 10.118029, speed: 0.039880 steps/s, speed: 0.319042 samples/s, speed: 163.349288 tokens/s, learning rate: 7.000e-07, loss_scalings: 26214.400391, pp_loss: 10.243275
[INFO] 2021-07-12 18:04:29,003 [run_pretraining.py:  512]:	********exe.run_71******* 
[INFO] 2021-07-12 18:04:54,345 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:04:54,346 [run_pretraining.py:  534]:	loss/total_loss, 7.697672367095947, 72
[INFO] 2021-07-12 18:04:54,346 [run_pretraining.py:  535]:	loss/mlm_loss, 7.697672367095947, 72
[INFO] 2021-07-12 18:04:54,346 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.099999947968172e-07, 72
[INFO] 2021-07-12 18:04:54,346 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 72
[INFO] 2021-07-12 18:04:54,346 [run_pretraining.py:  558]:	worker_index: 3, step: 72, cost: 7.697672, mlm loss: 7.697672, speed: 0.039459 steps/s, speed: 0.315671 samples/s, speed: 161.623347 tokens/s, learning rate: 7.100e-07, loss_scalings: 26214.400391, pp_loss: 9.701202
[INFO] 2021-07-12 18:04:54,346 [run_pretraining.py:  512]:	********exe.run_72******* 
[INFO] 2021-07-12 18:06:07,142 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:06:07,142 [run_pretraining.py:  534]:	loss/total_loss, 10.267046928405762, 73
[INFO] 2021-07-12 18:06:07,143 [run_pretraining.py:  535]:	loss/mlm_loss, 10.267046928405762, 73
[INFO] 2021-07-12 18:06:07,143 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.199999458862294e-07, 73
[INFO] 2021-07-12 18:06:07,143 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 73
[INFO] 2021-07-12 18:06:07,143 [run_pretraining.py:  558]:	worker_index: 3, step: 73, cost: 10.267047, mlm loss: 10.267047, speed: 0.013737 steps/s, speed: 0.109896 samples/s, speed: 56.266940 tokens/s, learning rate: 7.200e-07, loss_scalings: 26214.400391, pp_loss: 10.332061
[INFO] 2021-07-12 18:06:07,143 [run_pretraining.py:  512]:	********exe.run_73******* 
[INFO] 2021-07-12 18:06:30,303 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:06:30,304 [run_pretraining.py:  534]:	loss/total_loss, 10.248578071594238, 74
[INFO] 2021-07-12 18:06:30,304 [run_pretraining.py:  535]:	loss/mlm_loss, 10.248578071594238, 74
[INFO] 2021-07-12 18:06:30,304 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.300000106624793e-07, 74
[INFO] 2021-07-12 18:06:30,304 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 74
[INFO] 2021-07-12 18:06:30,304 [run_pretraining.py:  558]:	worker_index: 3, step: 74, cost: 10.248578, mlm loss: 10.248578, speed: 0.043176 steps/s, speed: 0.345411 samples/s, speed: 176.850502 tokens/s, learning rate: 7.300e-07, loss_scalings: 26214.400391, pp_loss: 10.232174
[INFO] 2021-07-12 18:06:30,304 [run_pretraining.py:  512]:	********exe.run_74******* 
[INFO] 2021-07-12 18:07:18,880 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:07:18,880 [run_pretraining.py:  534]:	loss/total_loss, 10.258520126342773, 75
[INFO] 2021-07-12 18:07:18,880 [run_pretraining.py:  535]:	loss/mlm_loss, 10.258520126342773, 75
[INFO] 2021-07-12 18:07:18,881 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.399999617518915e-07, 75
[INFO] 2021-07-12 18:07:18,881 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 75
[INFO] 2021-07-12 18:07:18,881 [run_pretraining.py:  558]:	worker_index: 3, step: 75, cost: 10.258520, mlm loss: 10.258520, speed: 0.020586 steps/s, speed: 0.164691 samples/s, speed: 84.321960 tokens/s, learning rate: 7.400e-07, loss_scalings: 26214.400391, pp_loss: 10.216089
[INFO] 2021-07-12 18:07:18,881 [run_pretraining.py:  512]:	********exe.run_75******* 
[INFO] 2021-07-12 18:07:19,860 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:07:19,860 [run_pretraining.py:  534]:	loss/total_loss, 10.295636177062988, 76
[INFO] 2021-07-12 18:07:19,860 [run_pretraining.py:  535]:	loss/mlm_loss, 10.295636177062988, 76
[INFO] 2021-07-12 18:07:19,860 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.499999696847226e-07, 76
[INFO] 2021-07-12 18:07:19,860 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 76
[INFO] 2021-07-12 18:07:19,861 [run_pretraining.py:  558]:	worker_index: 3, step: 76, cost: 10.295636, mlm loss: 10.295636, speed: 1.021236 steps/s, speed: 8.169892 samples/s, speed: 4182.984615 tokens/s, learning rate: 7.500e-07, loss_scalings: 26214.400391, pp_loss: 10.188534
[INFO] 2021-07-12 18:07:19,861 [run_pretraining.py:  512]:	********exe.run_76******* 
[INFO] 2021-07-12 18:07:20,834 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:07:20,835 [run_pretraining.py:  534]:	loss/total_loss, 10.251012802124023, 77
[INFO] 2021-07-12 18:07:20,835 [run_pretraining.py:  535]:	loss/mlm_loss, 10.251012802124023, 77
[INFO] 2021-07-12 18:07:20,835 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.599999776175537e-07, 77
[INFO] 2021-07-12 18:07:20,835 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 77
[INFO] 2021-07-12 18:07:20,835 [run_pretraining.py:  558]:	worker_index: 3, step: 77, cost: 10.251013, mlm loss: 10.251013, speed: 1.026891 steps/s, speed: 8.215131 samples/s, speed: 4206.147138 tokens/s, learning rate: 7.600e-07, loss_scalings: 26214.400391, pp_loss: 10.239229
[INFO] 2021-07-12 18:07:20,835 [run_pretraining.py:  512]:	********exe.run_77******* 
[INFO] 2021-07-12 18:08:10,248 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:08:10,249 [run_pretraining.py:  534]:	loss/total_loss, 10.19645881652832, 78
[INFO] 2021-07-12 18:08:10,249 [run_pretraining.py:  535]:	loss/mlm_loss, 10.19645881652832, 78
[INFO] 2021-07-12 18:08:10,249 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.699999855503847e-07, 78
[INFO] 2021-07-12 18:08:10,249 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 78
[INFO] 2021-07-12 18:08:10,249 [run_pretraining.py:  558]:	worker_index: 3, step: 78, cost: 10.196459, mlm loss: 10.196459, speed: 0.020237 steps/s, speed: 0.161899 samples/s, speed: 82.892304 tokens/s, learning rate: 7.700e-07, loss_scalings: 26214.400391, pp_loss: 10.292828
[INFO] 2021-07-12 18:08:10,249 [run_pretraining.py:  512]:	********exe.run_78******* 
[INFO] 2021-07-12 18:08:34,211 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:08:34,211 [run_pretraining.py:  534]:	loss/total_loss, 10.206884384155273, 79
[INFO] 2021-07-12 18:08:34,212 [run_pretraining.py:  535]:	loss/mlm_loss, 10.206884384155273, 79
[INFO] 2021-07-12 18:08:34,212 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.799999366397969e-07, 79
[INFO] 2021-07-12 18:08:34,212 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 79
[INFO] 2021-07-12 18:08:34,212 [run_pretraining.py:  558]:	worker_index: 3, step: 79, cost: 10.206884, mlm loss: 10.206884, speed: 0.041733 steps/s, speed: 0.333864 samples/s, speed: 170.938116 tokens/s, learning rate: 7.800e-07, loss_scalings: 26214.400391, pp_loss: 10.293682
[INFO] 2021-07-12 18:08:34,212 [run_pretraining.py:  512]:	********exe.run_79******* 
[INFO] 2021-07-12 18:08:35,176 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:08:35,177 [run_pretraining.py:  534]:	loss/total_loss, 10.266959190368652, 80
[INFO] 2021-07-12 18:08:35,177 [run_pretraining.py:  535]:	loss/mlm_loss, 10.266959190368652, 80
[INFO] 2021-07-12 18:08:35,177 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.89999944572628e-07, 80
[INFO] 2021-07-12 18:08:35,177 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 80
[INFO] 2021-07-12 18:08:35,177 [run_pretraining.py:  558]:	worker_index: 3, step: 80, cost: 10.266959, mlm loss: 10.266959, speed: 1.036677 steps/s, speed: 8.293418 samples/s, speed: 4246.230128 tokens/s, learning rate: 7.900e-07, loss_scalings: 26214.400391, pp_loss: 10.227472
[INFO] 2021-07-12 18:08:35,177 [run_pretraining.py:  512]:	********exe.run_80******* 
[INFO] 2021-07-12 18:09:23,459 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:09:23,460 [run_pretraining.py:  534]:	loss/total_loss, 10.321269035339355, 81
[INFO] 2021-07-12 18:09:23,460 [run_pretraining.py:  535]:	loss/mlm_loss, 10.321269035339355, 81
[INFO] 2021-07-12 18:09:23,460 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.000000093488779e-07, 81
[INFO] 2021-07-12 18:09:23,460 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 81
[INFO] 2021-07-12 18:09:23,460 [run_pretraining.py:  558]:	worker_index: 3, step: 81, cost: 10.321269, mlm loss: 10.321269, speed: 0.020711 steps/s, speed: 0.165691 samples/s, speed: 84.833655 tokens/s, learning rate: 8.000e-07, loss_scalings: 26214.400391, pp_loss: 10.254842
[INFO] 2021-07-12 18:09:23,461 [run_pretraining.py:  512]:	********exe.run_81******* 
[INFO] 2021-07-12 18:09:24,419 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:09:24,419 [run_pretraining.py:  534]:	loss/total_loss, 10.353084564208984, 82
[INFO] 2021-07-12 18:09:24,419 [run_pretraining.py:  535]:	loss/mlm_loss, 10.353084564208984, 82
[INFO] 2021-07-12 18:09:24,420 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.10000017281709e-07, 82
[INFO] 2021-07-12 18:09:24,420 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 82
[INFO] 2021-07-12 18:09:24,420 [run_pretraining.py:  558]:	worker_index: 3, step: 82, cost: 10.353085, mlm loss: 10.353085, speed: 1.043248 steps/s, speed: 8.345981 samples/s, speed: 4273.142222 tokens/s, learning rate: 8.100e-07, loss_scalings: 26214.400391, pp_loss: 10.297855
[INFO] 2021-07-12 18:09:24,420 [run_pretraining.py:  512]:	********exe.run_82******* 
[INFO] 2021-07-12 18:09:25,359 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:09:25,360 [run_pretraining.py:  534]:	loss/total_loss, 10.27968978881836, 83
[INFO] 2021-07-12 18:09:25,360 [run_pretraining.py:  535]:	loss/mlm_loss, 10.27968978881836, 83
[INFO] 2021-07-12 18:09:25,360 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.199999683711212e-07, 83
[INFO] 2021-07-12 18:09:25,360 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 83
[INFO] 2021-07-12 18:09:25,360 [run_pretraining.py:  558]:	worker_index: 3, step: 83, cost: 10.279690, mlm loss: 10.279690, speed: 1.064323 steps/s, speed: 8.514583 samples/s, speed: 4359.466696 tokens/s, learning rate: 8.200e-07, loss_scalings: 26214.400391, pp_loss: 10.234154
[INFO] 2021-07-12 18:09:25,360 [run_pretraining.py:  512]:	********exe.run_83******* 
[INFO] 2021-07-12 18:09:26,300 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:09:26,300 [run_pretraining.py:  534]:	loss/total_loss, 10.157079696655273, 84
[INFO] 2021-07-12 18:09:26,300 [run_pretraining.py:  535]:	loss/mlm_loss, 10.157079696655273, 84
[INFO] 2021-07-12 18:09:26,300 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.299999763039523e-07, 84
[INFO] 2021-07-12 18:09:26,300 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 84
[INFO] 2021-07-12 18:09:26,300 [run_pretraining.py:  558]:	worker_index: 3, step: 84, cost: 10.157080, mlm loss: 10.157080, speed: 1.063862 steps/s, speed: 8.510897 samples/s, speed: 4357.579172 tokens/s, learning rate: 8.300e-07, loss_scalings: 26214.400391, pp_loss: 10.171261
[INFO] 2021-07-12 18:09:26,301 [run_pretraining.py:  512]:	********exe.run_84******* 
[INFO] 2021-07-12 18:09:27,233 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:09:27,234 [run_pretraining.py:  534]:	loss/total_loss, 10.226832389831543, 85
[INFO] 2021-07-12 18:09:27,234 [run_pretraining.py:  535]:	loss/mlm_loss, 10.226832389831543, 85
[INFO] 2021-07-12 18:09:27,234 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.399999273933645e-07, 85
[INFO] 2021-07-12 18:09:27,234 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 85
[INFO] 2021-07-12 18:09:27,234 [run_pretraining.py:  558]:	worker_index: 3, step: 85, cost: 10.226832, mlm loss: 10.226832, speed: 1.071856 steps/s, speed: 8.574847 samples/s, speed: 4390.321793 tokens/s, learning rate: 8.400e-07, loss_scalings: 26214.400391, pp_loss: 10.234303
[INFO] 2021-07-12 18:09:27,234 [run_pretraining.py:  512]:	********exe.run_85******* 
[INFO] 2021-07-12 18:09:51,415 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:09:51,415 [run_pretraining.py:  534]:	loss/total_loss, 10.253100395202637, 86
[INFO] 2021-07-12 18:09:51,415 [run_pretraining.py:  535]:	loss/mlm_loss, 10.253100395202637, 86
[INFO] 2021-07-12 18:09:51,415 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.500000490130333e-07, 86
[INFO] 2021-07-12 18:09:51,416 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 86
[INFO] 2021-07-12 18:09:51,416 [run_pretraining.py:  558]:	worker_index: 3, step: 86, cost: 10.253100, mlm loss: 10.253100, speed: 0.041355 steps/s, speed: 0.330841 samples/s, speed: 169.390407 tokens/s, learning rate: 8.500e-07, loss_scalings: 26214.400391, pp_loss: 9.298521
[INFO] 2021-07-12 18:09:51,416 [run_pretraining.py:  512]:	********exe.run_86******* 
[INFO] 2021-07-12 18:10:17,853 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:10:17,853 [run_pretraining.py:  534]:	loss/total_loss, 10.226218223571777, 87
[INFO] 2021-07-12 18:10:17,853 [run_pretraining.py:  535]:	loss/mlm_loss, 10.226218223571777, 87
[INFO] 2021-07-12 18:10:17,853 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.600000001024455e-07, 87
[INFO] 2021-07-12 18:10:17,853 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 87
[INFO] 2021-07-12 18:10:17,853 [run_pretraining.py:  558]:	worker_index: 3, step: 87, cost: 10.226218, mlm loss: 10.226218, speed: 0.037825 steps/s, speed: 0.302603 samples/s, speed: 154.932923 tokens/s, learning rate: 8.600e-07, loss_scalings: 26214.400391, pp_loss: 10.329423
[INFO] 2021-07-12 18:10:17,854 [run_pretraining.py:  512]:	********exe.run_87******* 
[INFO] 2021-07-12 18:10:43,554 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:10:43,555 [run_pretraining.py:  534]:	loss/total_loss, 10.166748046875, 88
[INFO] 2021-07-12 18:10:43,555 [run_pretraining.py:  535]:	loss/mlm_loss, 10.166748046875, 88
[INFO] 2021-07-12 18:10:43,555 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.700000080352766e-07, 88
[INFO] 2021-07-12 18:10:43,555 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 88
[INFO] 2021-07-12 18:10:43,555 [run_pretraining.py:  558]:	worker_index: 3, step: 88, cost: 10.166748, mlm loss: 10.166748, speed: 0.038909 steps/s, speed: 0.311274 samples/s, speed: 159.372094 tokens/s, learning rate: 8.700e-07, loss_scalings: 26214.400391, pp_loss: 10.325144
[INFO] 2021-07-12 18:10:43,555 [run_pretraining.py:  512]:	********exe.run_88******* 
[INFO] 2021-07-12 18:11:07,457 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:11:07,458 [run_pretraining.py:  534]:	loss/total_loss, 10.11239242553711, 89
[INFO] 2021-07-12 18:11:07,458 [run_pretraining.py:  535]:	loss/mlm_loss, 10.11239242553711, 89
[INFO] 2021-07-12 18:11:07,458 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.799999591246888e-07, 89
[INFO] 2021-07-12 18:11:07,458 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 89
[INFO] 2021-07-12 18:11:07,458 [run_pretraining.py:  558]:	worker_index: 3, step: 89, cost: 10.112392, mlm loss: 10.112392, speed: 0.041837 steps/s, speed: 0.334695 samples/s, speed: 171.363632 tokens/s, learning rate: 8.800e-07, loss_scalings: 26214.400391, pp_loss: 10.285501
[INFO] 2021-07-12 18:11:07,458 [run_pretraining.py:  512]:	********exe.run_89******* 
[INFO] 2021-07-12 18:11:57,433 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:11:57,434 [run_pretraining.py:  534]:	loss/total_loss, 10.148052215576172, 90
[INFO] 2021-07-12 18:11:57,434 [run_pretraining.py:  535]:	loss/mlm_loss, 10.148052215576172, 90
[INFO] 2021-07-12 18:11:57,434 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.899999670575198e-07, 90
[INFO] 2021-07-12 18:11:57,434 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 90
[INFO] 2021-07-12 18:11:57,434 [run_pretraining.py:  558]:	worker_index: 3, step: 90, cost: 10.148052, mlm loss: 10.148052, speed: 0.020010 steps/s, speed: 0.160079 samples/s, speed: 81.960368 tokens/s, learning rate: 8.900e-07, loss_scalings: 26214.400391, pp_loss: 9.093809
[INFO] 2021-07-12 18:11:57,434 [run_pretraining.py:  512]:	********exe.run_90******* 
[INFO] 2021-07-12 18:11:58,371 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:11:58,372 [run_pretraining.py:  534]:	loss/total_loss, 10.24084758758545, 91
[INFO] 2021-07-12 18:11:58,372 [run_pretraining.py:  535]:	loss/mlm_loss, 10.24084758758545, 91
[INFO] 2021-07-12 18:11:58,372 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.99999918146932e-07, 91
[INFO] 2021-07-12 18:11:58,372 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 91
[INFO] 2021-07-12 18:11:58,372 [run_pretraining.py:  558]:	worker_index: 3, step: 91, cost: 10.240848, mlm loss: 10.240848, speed: 1.066996 steps/s, speed: 8.535969 samples/s, speed: 4370.415972 tokens/s, learning rate: 9.000e-07, loss_scalings: 26214.400391, pp_loss: 10.272199
[INFO] 2021-07-12 18:11:58,372 [run_pretraining.py:  512]:	********exe.run_91******* 
[INFO] 2021-07-12 18:11:59,310 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:11:59,310 [run_pretraining.py:  534]:	loss/total_loss, 10.289794921875, 92
[INFO] 2021-07-12 18:11:59,310 [run_pretraining.py:  535]:	loss/mlm_loss, 10.289794921875, 92
[INFO] 2021-07-12 18:11:59,311 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.100000397666008e-07, 92
[INFO] 2021-07-12 18:11:59,311 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 92
[INFO] 2021-07-12 18:11:59,311 [run_pretraining.py:  558]:	worker_index: 3, step: 92, cost: 10.289795, mlm loss: 10.289795, speed: 1.066033 steps/s, speed: 8.528265 samples/s, speed: 4366.471542 tokens/s, learning rate: 9.100e-07, loss_scalings: 26214.400391, pp_loss: 10.210969
[INFO] 2021-07-12 18:11:59,311 [run_pretraining.py:  512]:	********exe.run_92******* 
[INFO] 2021-07-12 18:12:00,247 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:12:00,248 [run_pretraining.py:  534]:	loss/total_loss, 10.164324760437012, 93
[INFO] 2021-07-12 18:12:00,248 [run_pretraining.py:  535]:	loss/mlm_loss, 10.164324760437012, 93
[INFO] 2021-07-12 18:12:00,248 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.19999990856013e-07, 93
[INFO] 2021-07-12 18:12:00,248 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 93
[INFO] 2021-07-12 18:12:00,248 [run_pretraining.py:  558]:	worker_index: 3, step: 93, cost: 10.164325, mlm loss: 10.164325, speed: 1.067323 steps/s, speed: 8.538584 samples/s, speed: 4371.754986 tokens/s, learning rate: 9.200e-07, loss_scalings: 26214.400391, pp_loss: 10.171246
[INFO] 2021-07-12 18:12:00,248 [run_pretraining.py:  512]:	********exe.run_93******* 
[INFO] 2021-07-12 18:12:01,192 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:12:01,193 [run_pretraining.py:  534]:	loss/total_loss, 10.173985481262207, 94
[INFO] 2021-07-12 18:12:01,193 [run_pretraining.py:  535]:	loss/mlm_loss, 10.173985481262207, 94
[INFO] 2021-07-12 18:12:01,193 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.299999987888441e-07, 94
[INFO] 2021-07-12 18:12:01,193 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 94
[INFO] 2021-07-12 18:12:01,193 [run_pretraining.py:  558]:	worker_index: 3, step: 94, cost: 10.173985, mlm loss: 10.173985, speed: 1.059214 steps/s, speed: 8.473714 samples/s, speed: 4338.541437 tokens/s, learning rate: 9.300e-07, loss_scalings: 26214.400391, pp_loss: 10.199600
[INFO] 2021-07-12 18:12:01,193 [run_pretraining.py:  512]:	********exe.run_94******* 
[INFO] 2021-07-12 18:12:26,863 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:12:26,864 [run_pretraining.py:  534]:	loss/total_loss, 10.21694564819336, 95
[INFO] 2021-07-12 18:12:26,864 [run_pretraining.py:  535]:	loss/mlm_loss, 10.21694564819336, 95
[INFO] 2021-07-12 18:12:26,864 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.399999498782563e-07, 95
[INFO] 2021-07-12 18:12:26,864 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 95
[INFO] 2021-07-12 18:12:26,864 [run_pretraining.py:  558]:	worker_index: 3, step: 95, cost: 10.216946, mlm loss: 10.216946, speed: 0.038955 steps/s, speed: 0.311640 samples/s, speed: 159.559896 tokens/s, learning rate: 9.400e-07, loss_scalings: 26214.400391, pp_loss: 10.259302
[INFO] 2021-07-12 18:12:26,864 [run_pretraining.py:  512]:	********exe.run_95******* 
[INFO] 2021-07-12 18:12:27,829 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:12:27,830 [run_pretraining.py:  534]:	loss/total_loss, 10.315851211547852, 96
[INFO] 2021-07-12 18:12:27,830 [run_pretraining.py:  535]:	loss/mlm_loss, 10.315851211547852, 96
[INFO] 2021-07-12 18:12:27,830 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.499999578110874e-07, 96
[INFO] 2021-07-12 18:12:27,830 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 96
[INFO] 2021-07-12 18:12:27,830 [run_pretraining.py:  558]:	worker_index: 3, step: 96, cost: 10.315851, mlm loss: 10.315851, speed: 1.036131 steps/s, speed: 8.289048 samples/s, speed: 4243.992700 tokens/s, learning rate: 9.500e-07, loss_scalings: 26214.400391, pp_loss: 9.217318
[INFO] 2021-07-12 18:12:27,830 [run_pretraining.py:  512]:	********exe.run_96******* 
[INFO] 2021-07-12 18:12:51,361 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:12:51,362 [run_pretraining.py:  534]:	loss/total_loss, 7.1630778312683105, 97
[INFO] 2021-07-12 18:12:51,362 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1630778312683105, 97
[INFO] 2021-07-12 18:12:51,362 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.599999657439184e-07, 97
[INFO] 2021-07-12 18:12:51,362 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 97
[INFO] 2021-07-12 18:12:51,362 [run_pretraining.py:  558]:	worker_index: 3, step: 97, cost: 7.163078, mlm loss: 7.163078, speed: 0.042496 steps/s, speed: 0.339969 samples/s, speed: 174.064108 tokens/s, learning rate: 9.600e-07, loss_scalings: 26214.400391, pp_loss: 9.496497
[INFO] 2021-07-12 18:12:51,362 [run_pretraining.py:  512]:	********exe.run_97******* 
[INFO] 2021-07-12 18:12:52,330 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:12:52,331 [run_pretraining.py:  534]:	loss/total_loss, 10.376263618469238, 98
[INFO] 2021-07-12 18:12:52,331 [run_pretraining.py:  535]:	loss/mlm_loss, 10.376263618469238, 98
[INFO] 2021-07-12 18:12:52,331 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.699999736767495e-07, 98
[INFO] 2021-07-12 18:12:52,331 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 98
[INFO] 2021-07-12 18:12:52,331 [run_pretraining.py:  558]:	worker_index: 3, step: 98, cost: 10.376264, mlm loss: 10.376264, speed: 1.032762 steps/s, speed: 8.262099 samples/s, speed: 4230.194557 tokens/s, learning rate: 9.700e-07, loss_scalings: 26214.400391, pp_loss: 10.240817
[INFO] 2021-07-12 18:12:52,331 [run_pretraining.py:  512]:	********exe.run_98******* 
[INFO] 2021-07-12 18:13:17,576 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:13:17,577 [run_pretraining.py:  534]:	loss/total_loss, 10.309171676635742, 99
[INFO] 2021-07-12 18:13:17,577 [run_pretraining.py:  535]:	loss/mlm_loss, 10.309171676635742, 99
[INFO] 2021-07-12 18:13:17,577 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.799999816095806e-07, 99
[INFO] 2021-07-12 18:13:17,577 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 99
[INFO] 2021-07-12 18:13:17,577 [run_pretraining.py:  558]:	worker_index: 3, step: 99, cost: 10.309172, mlm loss: 10.309172, speed: 0.039612 steps/s, speed: 0.316894 samples/s, speed: 162.249677 tokens/s, learning rate: 9.800e-07, loss_scalings: 26214.400391, pp_loss: 10.316687
[INFO] 2021-07-12 18:13:17,577 [run_pretraining.py:  512]:	********exe.run_99******* 
[INFO] 2021-07-12 18:13:18,525 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:13:18,525 [run_pretraining.py:  534]:	loss/total_loss, 10.202824592590332, 100
[INFO] 2021-07-12 18:13:18,525 [run_pretraining.py:  535]:	loss/mlm_loss, 10.202824592590332, 100
[INFO] 2021-07-12 18:13:18,526 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.899999895424116e-07, 100
[INFO] 2021-07-12 18:13:18,526 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 100
[INFO] 2021-07-12 18:13:18,526 [run_pretraining.py:  558]:	worker_index: 3, step: 100, cost: 10.202825, mlm loss: 10.202825, speed: 1.054716 steps/s, speed: 8.437730 samples/s, speed: 4320.117943 tokens/s, learning rate: 9.900e-07, loss_scalings: 26214.400391, pp_loss: 10.239941
[INFO] 2021-07-12 18:13:18,526 [run_pretraining.py:  512]:	********exe.run_100******* 
[INFO] 2021-07-12 18:13:19,466 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:13:19,467 [run_pretraining.py:  534]:	loss/total_loss, 10.30532455444336, 101
[INFO] 2021-07-12 18:13:19,467 [run_pretraining.py:  535]:	loss/mlm_loss, 10.30532455444336, 101
[INFO] 2021-07-12 18:13:19,467 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.999999974752427e-07, 101
[INFO] 2021-07-12 18:13:19,467 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 101
[INFO] 2021-07-12 18:13:19,467 [run_pretraining.py:  558]:	worker_index: 3, step: 101, cost: 10.305325, mlm loss: 10.305325, speed: 1.062986 steps/s, speed: 8.503889 samples/s, speed: 4353.991088 tokens/s, learning rate: 1.000e-06, loss_scalings: 26214.400391, pp_loss: 10.227472
[INFO] 2021-07-12 18:13:19,467 [run_pretraining.py:  512]:	********exe.run_101******* 
[INFO] 2021-07-12 18:13:44,836 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:13:44,837 [run_pretraining.py:  534]:	loss/total_loss, 10.322565078735352, 102
[INFO] 2021-07-12 18:13:44,837 [run_pretraining.py:  535]:	loss/mlm_loss, 10.322565078735352, 102
[INFO] 2021-07-12 18:13:44,837 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.009999891721236e-06, 102
[INFO] 2021-07-12 18:13:44,837 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 102
[INFO] 2021-07-12 18:13:44,837 [run_pretraining.py:  558]:	worker_index: 3, step: 102, cost: 10.322565, mlm loss: 10.322565, speed: 0.039417 steps/s, speed: 0.315338 samples/s, speed: 161.452872 tokens/s, learning rate: 1.010e-06, loss_scalings: 26214.400391, pp_loss: 10.253567
[INFO] 2021-07-12 18:13:44,837 [run_pretraining.py:  512]:	********exe.run_102******* 
[INFO] 2021-07-12 18:13:45,826 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:13:45,826 [run_pretraining.py:  534]:	loss/total_loss, 10.23937702178955, 103
[INFO] 2021-07-12 18:13:45,826 [run_pretraining.py:  535]:	loss/mlm_loss, 10.23937702178955, 103
[INFO] 2021-07-12 18:13:45,826 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0200000133409048e-06, 103
[INFO] 2021-07-12 18:13:45,826 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 103
[INFO] 2021-07-12 18:13:45,826 [run_pretraining.py:  558]:	worker_index: 3, step: 103, cost: 10.239377, mlm loss: 10.239377, speed: 1.011640 steps/s, speed: 8.093116 samples/s, speed: 4143.675488 tokens/s, learning rate: 1.020e-06, loss_scalings: 26214.400391, pp_loss: 8.497156
[INFO] 2021-07-12 18:13:45,827 [run_pretraining.py:  512]:	********exe.run_103******* 
[INFO] 2021-07-12 18:14:11,881 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:14:11,882 [run_pretraining.py:  534]:	loss/total_loss, 9.945012092590332, 104
[INFO] 2021-07-12 18:14:11,882 [run_pretraining.py:  535]:	loss/mlm_loss, 9.945012092590332, 104
[INFO] 2021-07-12 18:14:11,882 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.030000021273736e-06, 104
[INFO] 2021-07-12 18:14:11,882 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 104
[INFO] 2021-07-12 18:14:11,882 [run_pretraining.py:  558]:	worker_index: 3, step: 104, cost: 9.945012, mlm loss: 9.945012, speed: 0.038381 steps/s, speed: 0.307046 samples/s, speed: 157.207365 tokens/s, learning rate: 1.030e-06, loss_scalings: 26214.400391, pp_loss: 10.192413
[INFO] 2021-07-12 18:14:11,882 [run_pretraining.py:  512]:	********exe.run_104******* 
[INFO] 2021-07-12 18:14:37,277 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:14:37,278 [run_pretraining.py:  534]:	loss/total_loss, 10.167985916137695, 105
[INFO] 2021-07-12 18:14:37,278 [run_pretraining.py:  535]:	loss/mlm_loss, 10.167985916137695, 105
[INFO] 2021-07-12 18:14:37,278 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.040000029206567e-06, 105
[INFO] 2021-07-12 18:14:37,278 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 105
[INFO] 2021-07-12 18:14:37,278 [run_pretraining.py:  558]:	worker_index: 3, step: 105, cost: 10.167986, mlm loss: 10.167986, speed: 0.039377 steps/s, speed: 0.315019 samples/s, speed: 161.289867 tokens/s, learning rate: 1.040e-06, loss_scalings: 26214.400391, pp_loss: 10.174706
[INFO] 2021-07-12 18:14:37,278 [run_pretraining.py:  512]:	********exe.run_105******* 
[INFO] 2021-07-12 18:14:38,257 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:14:38,257 [run_pretraining.py:  534]:	loss/total_loss, 10.145124435424805, 106
[INFO] 2021-07-12 18:14:38,257 [run_pretraining.py:  535]:	loss/mlm_loss, 10.145124435424805, 106
[INFO] 2021-07-12 18:14:38,257 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0499999234525603e-06, 106
[INFO] 2021-07-12 18:14:38,257 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 106
[INFO] 2021-07-12 18:14:38,258 [run_pretraining.py:  558]:	worker_index: 3, step: 106, cost: 10.145124, mlm loss: 10.145124, speed: 1.021393 steps/s, speed: 8.171143 samples/s, speed: 4183.625337 tokens/s, learning rate: 1.050e-06, loss_scalings: 26214.400391, pp_loss: 10.214046
[INFO] 2021-07-12 18:14:38,258 [run_pretraining.py:  512]:	********exe.run_106******* 
[INFO] 2021-07-12 18:14:39,227 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:14:39,227 [run_pretraining.py:  534]:	loss/total_loss, 10.31571102142334, 107
[INFO] 2021-07-12 18:14:39,227 [run_pretraining.py:  535]:	loss/mlm_loss, 10.31571102142334, 107
[INFO] 2021-07-12 18:14:39,227 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0599999313853914e-06, 107
[INFO] 2021-07-12 18:14:39,227 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 107
[INFO] 2021-07-12 18:14:39,228 [run_pretraining.py:  558]:	worker_index: 3, step: 107, cost: 10.315711, mlm loss: 10.315711, speed: 1.031651 steps/s, speed: 8.253210 samples/s, speed: 4225.643502 tokens/s, learning rate: 1.060e-06, loss_scalings: 26214.400391, pp_loss: 10.182853
[INFO] 2021-07-12 18:14:39,228 [run_pretraining.py:  512]:	********exe.run_107******* 
[INFO] 2021-07-12 18:14:40,193 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:14:40,194 [run_pretraining.py:  534]:	loss/total_loss, 10.151741027832031, 108
[INFO] 2021-07-12 18:14:40,194 [run_pretraining.py:  535]:	loss/mlm_loss, 10.151741027832031, 108
[INFO] 2021-07-12 18:14:40,194 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0700000530050602e-06, 108
[INFO] 2021-07-12 18:14:40,194 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 108
[INFO] 2021-07-12 18:14:40,194 [run_pretraining.py:  558]:	worker_index: 3, step: 108, cost: 10.151741, mlm loss: 10.151741, speed: 1.035202 steps/s, speed: 8.281618 samples/s, speed: 4240.188303 tokens/s, learning rate: 1.070e-06, loss_scalings: 26214.400391, pp_loss: 10.213983
[INFO] 2021-07-12 18:14:40,194 [run_pretraining.py:  512]:	********exe.run_108******* 
[INFO] 2021-07-12 18:14:41,126 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:14:41,127 [run_pretraining.py:  534]:	loss/total_loss, 10.117618560791016, 109
[INFO] 2021-07-12 18:14:41,127 [run_pretraining.py:  535]:	loss/mlm_loss, 10.117618560791016, 109
[INFO] 2021-07-12 18:14:41,127 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0799999472510535e-06, 109
[INFO] 2021-07-12 18:14:41,127 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 109
[INFO] 2021-07-12 18:14:41,127 [run_pretraining.py:  558]:	worker_index: 3, step: 109, cost: 10.117619, mlm loss: 10.117619, speed: 1.072820 steps/s, speed: 8.582561 samples/s, speed: 4394.271234 tokens/s, learning rate: 1.080e-06, loss_scalings: 26214.400391, pp_loss: 10.145163
[INFO] 2021-07-12 18:14:41,127 [run_pretraining.py:  512]:	********exe.run_109******* 
[INFO] 2021-07-12 18:14:42,061 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:14:42,061 [run_pretraining.py:  534]:	loss/total_loss, 5.571493625640869, 110
[INFO] 2021-07-12 18:14:42,061 [run_pretraining.py:  535]:	loss/mlm_loss, 5.571493625640869, 110
[INFO] 2021-07-12 18:14:42,061 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0899999551838846e-06, 110
[INFO] 2021-07-12 18:14:42,062 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 110
[INFO] 2021-07-12 18:14:42,062 [run_pretraining.py:  558]:	worker_index: 3, step: 110, cost: 5.571494, mlm loss: 5.571494, speed: 1.070631 steps/s, speed: 8.565050 samples/s, speed: 4385.305690 tokens/s, learning rate: 1.090e-06, loss_scalings: 26214.400391, pp_loss: 9.042564
[INFO] 2021-07-12 18:14:42,062 [run_pretraining.py:  512]:	********exe.run_110******* 
[INFO] 2021-07-12 18:14:43,002 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:14:43,003 [run_pretraining.py:  534]:	loss/total_loss, 10.380827903747559, 111
[INFO] 2021-07-12 18:14:43,003 [run_pretraining.py:  535]:	loss/mlm_loss, 10.380827903747559, 111
[INFO] 2021-07-12 18:14:43,003 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0999999631167157e-06, 111
[INFO] 2021-07-12 18:14:43,003 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 111
[INFO] 2021-07-12 18:14:43,003 [run_pretraining.py:  558]:	worker_index: 3, step: 111, cost: 10.380828, mlm loss: 10.380828, speed: 1.062730 steps/s, speed: 8.501840 samples/s, speed: 4352.941953 tokens/s, learning rate: 1.100e-06, loss_scalings: 26214.400391, pp_loss: 10.217559
[INFO] 2021-07-12 18:14:43,003 [run_pretraining.py:  512]:	********exe.run_111******* 
[INFO] 2021-07-12 18:14:43,937 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:14:43,938 [run_pretraining.py:  534]:	loss/total_loss, 10.169508934020996, 112
[INFO] 2021-07-12 18:14:43,938 [run_pretraining.py:  535]:	loss/mlm_loss, 10.169508934020996, 112
[INFO] 2021-07-12 18:14:43,938 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1099999710495467e-06, 112
[INFO] 2021-07-12 18:14:43,938 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 112
[INFO] 2021-07-12 18:14:43,938 [run_pretraining.py:  558]:	worker_index: 3, step: 112, cost: 10.169509, mlm loss: 10.169509, speed: 1.070578 steps/s, speed: 8.564622 samples/s, speed: 4385.086301 tokens/s, learning rate: 1.110e-06, loss_scalings: 26214.400391, pp_loss: 10.160028
[INFO] 2021-07-12 18:14:43,938 [run_pretraining.py:  512]:	********exe.run_112******* 
[INFO] 2021-07-12 18:14:44,866 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:14:44,866 [run_pretraining.py:  534]:	loss/total_loss, 10.100482940673828, 113
[INFO] 2021-07-12 18:14:44,866 [run_pretraining.py:  535]:	loss/mlm_loss, 10.100482940673828, 113
[INFO] 2021-07-12 18:14:44,867 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1199999789823778e-06, 113
[INFO] 2021-07-12 18:14:44,867 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 113
[INFO] 2021-07-12 18:14:44,867 [run_pretraining.py:  558]:	worker_index: 3, step: 113, cost: 10.100483, mlm loss: 10.100483, speed: 1.077490 steps/s, speed: 8.619919 samples/s, speed: 4413.398642 tokens/s, learning rate: 1.120e-06, loss_scalings: 26214.400391, pp_loss: 10.038750
[INFO] 2021-07-12 18:14:44,867 [run_pretraining.py:  512]:	********exe.run_113******* 
[INFO] 2021-07-12 18:15:08,571 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:15:08,571 [run_pretraining.py:  534]:	loss/total_loss, 10.290820121765137, 114
[INFO] 2021-07-12 18:15:08,571 [run_pretraining.py:  535]:	loss/mlm_loss, 10.290820121765137, 114
[INFO] 2021-07-12 18:15:08,571 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1299999869152089e-06, 114
[INFO] 2021-07-12 18:15:08,571 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 114
[INFO] 2021-07-12 18:15:08,572 [run_pretraining.py:  558]:	worker_index: 3, step: 114, cost: 10.290820, mlm loss: 10.290820, speed: 0.042187 steps/s, speed: 0.337494 samples/s, speed: 172.796689 tokens/s, learning rate: 1.130e-06, loss_scalings: 26214.400391, pp_loss: 10.155918
[INFO] 2021-07-12 18:15:08,572 [run_pretraining.py:  512]:	********exe.run_114******* 
[INFO] 2021-07-12 18:15:33,781 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:15:33,782 [run_pretraining.py:  534]:	loss/total_loss, 8.153419494628906, 115
[INFO] 2021-07-12 18:15:33,782 [run_pretraining.py:  535]:	loss/mlm_loss, 8.153419494628906, 115
[INFO] 2021-07-12 18:15:33,782 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.13999999484804e-06, 115
[INFO] 2021-07-12 18:15:33,782 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 115
[INFO] 2021-07-12 18:15:33,782 [run_pretraining.py:  558]:	worker_index: 3, step: 115, cost: 8.153419, mlm loss: 8.153419, speed: 0.039667 steps/s, speed: 0.317336 samples/s, speed: 162.475849 tokens/s, learning rate: 1.140e-06, loss_scalings: 26214.400391, pp_loss: 9.691683
[INFO] 2021-07-12 18:15:33,782 [run_pretraining.py:  512]:	********exe.run_115******* 
[INFO] 2021-07-12 18:15:34,738 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:15:34,738 [run_pretraining.py:  534]:	loss/total_loss, 10.212295532226562, 116
[INFO] 2021-07-12 18:15:34,738 [run_pretraining.py:  535]:	loss/mlm_loss, 10.212295532226562, 116
[INFO] 2021-07-12 18:15:34,738 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.150000002780871e-06, 116
[INFO] 2021-07-12 18:15:34,738 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 116
[INFO] 2021-07-12 18:15:34,738 [run_pretraining.py:  558]:	worker_index: 3, step: 116, cost: 10.212296, mlm loss: 10.212296, speed: 1.046358 steps/s, speed: 8.370862 samples/s, speed: 4285.881228 tokens/s, learning rate: 1.150e-06, loss_scalings: 26214.400391, pp_loss: 10.178225
[INFO] 2021-07-12 18:15:34,738 [run_pretraining.py:  512]:	********exe.run_116******* 
[INFO] 2021-07-12 18:15:35,676 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:15:35,677 [run_pretraining.py:  534]:	loss/total_loss, 10.205862045288086, 117
[INFO] 2021-07-12 18:15:35,677 [run_pretraining.py:  535]:	loss/mlm_loss, 10.205862045288086, 117
[INFO] 2021-07-12 18:15:35,677 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.160000010713702e-06, 117
[INFO] 2021-07-12 18:15:35,677 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 117
[INFO] 2021-07-12 18:15:35,677 [run_pretraining.py:  558]:	worker_index: 3, step: 117, cost: 10.205862, mlm loss: 10.205862, speed: 1.065934 steps/s, speed: 8.527469 samples/s, speed: 4366.064287 tokens/s, learning rate: 1.160e-06, loss_scalings: 26214.400391, pp_loss: 10.188082
[INFO] 2021-07-12 18:15:35,677 [run_pretraining.py:  512]:	********exe.run_117******* 
[INFO] 2021-07-12 18:16:01,604 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:16:01,605 [run_pretraining.py:  534]:	loss/total_loss, 10.179281234741211, 118
[INFO] 2021-07-12 18:16:01,605 [run_pretraining.py:  535]:	loss/mlm_loss, 10.179281234741211, 118
[INFO] 2021-07-12 18:16:01,605 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1699999049596954e-06, 118
[INFO] 2021-07-12 18:16:01,605 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 118
[INFO] 2021-07-12 18:16:01,605 [run_pretraining.py:  558]:	worker_index: 3, step: 118, cost: 10.179281, mlm loss: 10.179281, speed: 0.038570 steps/s, speed: 0.308557 samples/s, speed: 157.981438 tokens/s, learning rate: 1.170e-06, loss_scalings: 26214.400391, pp_loss: 10.222385
[INFO] 2021-07-12 18:16:01,605 [run_pretraining.py:  512]:	********exe.run_118******* 
[INFO] 2021-07-12 18:16:02,560 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:16:02,561 [run_pretraining.py:  534]:	loss/total_loss, 9.987054824829102, 119
[INFO] 2021-07-12 18:16:02,561 [run_pretraining.py:  535]:	loss/mlm_loss, 9.987054824829102, 119
[INFO] 2021-07-12 18:16:02,561 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1800000265793642e-06, 119
[INFO] 2021-07-12 18:16:02,561 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 119
[INFO] 2021-07-12 18:16:02,561 [run_pretraining.py:  558]:	worker_index: 3, step: 119, cost: 9.987055, mlm loss: 9.987055, speed: 1.046461 steps/s, speed: 8.371685 samples/s, speed: 4286.302535 tokens/s, learning rate: 1.180e-06, loss_scalings: 26214.400391, pp_loss: 9.168953
[INFO] 2021-07-12 18:16:02,561 [run_pretraining.py:  512]:	********exe.run_119******* 
[INFO] 2021-07-12 18:16:03,490 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:16:03,490 [run_pretraining.py:  534]:	loss/total_loss, 9.952753067016602, 120
[INFO] 2021-07-12 18:16:03,490 [run_pretraining.py:  535]:	loss/mlm_loss, 9.952753067016602, 120
[INFO] 2021-07-12 18:16:03,490 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1900000345121953e-06, 120
[INFO] 2021-07-12 18:16:03,490 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 120
[INFO] 2021-07-12 18:16:03,491 [run_pretraining.py:  558]:	worker_index: 3, step: 120, cost: 9.952753, mlm loss: 9.952753, speed: 1.076739 steps/s, speed: 8.613916 samples/s, speed: 4410.324856 tokens/s, learning rate: 1.190e-06, loss_scalings: 26214.400391, pp_loss: 10.132454
[INFO] 2021-07-12 18:16:03,491 [run_pretraining.py:  512]:	********exe.run_120******* 
[INFO] 2021-07-12 18:16:04,421 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:16:04,422 [run_pretraining.py:  534]:	loss/total_loss, 10.077974319458008, 121
[INFO] 2021-07-12 18:16:04,422 [run_pretraining.py:  535]:	loss/mlm_loss, 10.077974319458008, 121
[INFO] 2021-07-12 18:16:04,422 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1999999287581886e-06, 121
[INFO] 2021-07-12 18:16:04,422 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 121
[INFO] 2021-07-12 18:16:04,422 [run_pretraining.py:  558]:	worker_index: 3, step: 121, cost: 10.077974, mlm loss: 10.077974, speed: 1.074352 steps/s, speed: 8.594813 samples/s, speed: 4400.544049 tokens/s, learning rate: 1.200e-06, loss_scalings: 26214.400391, pp_loss: 10.110952
[INFO] 2021-07-12 18:16:04,422 [run_pretraining.py:  512]:	********exe.run_121******* 
[INFO] 2021-07-12 18:16:30,652 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:16:30,652 [run_pretraining.py:  534]:	loss/total_loss, 10.260656356811523, 122
[INFO] 2021-07-12 18:16:30,653 [run_pretraining.py:  535]:	loss/mlm_loss, 10.260656356811523, 122
[INFO] 2021-07-12 18:16:30,653 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2099999366910197e-06, 122
[INFO] 2021-07-12 18:16:30,653 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 122
[INFO] 2021-07-12 18:16:30,653 [run_pretraining.py:  558]:	worker_index: 3, step: 122, cost: 10.260656, mlm loss: 10.260656, speed: 0.038124 steps/s, speed: 0.304992 samples/s, speed: 156.155705 tokens/s, learning rate: 1.210e-06, loss_scalings: 26214.400391, pp_loss: 10.167621
[INFO] 2021-07-12 18:16:30,653 [run_pretraining.py:  512]:	********exe.run_122******* 
[INFO] 2021-07-12 18:16:31,610 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:16:31,610 [run_pretraining.py:  534]:	loss/total_loss, 10.109538078308105, 123
[INFO] 2021-07-12 18:16:31,610 [run_pretraining.py:  535]:	loss/mlm_loss, 10.109538078308105, 123
[INFO] 2021-07-12 18:16:31,610 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2199999446238508e-06, 123
[INFO] 2021-07-12 18:16:31,610 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 123
[INFO] 2021-07-12 18:16:31,610 [run_pretraining.py:  558]:	worker_index: 3, step: 123, cost: 10.109538, mlm loss: 10.109538, speed: 1.044946 steps/s, speed: 8.359567 samples/s, speed: 4280.098235 tokens/s, learning rate: 1.220e-06, loss_scalings: 26214.400391, pp_loss: 10.203718
[INFO] 2021-07-12 18:16:31,611 [run_pretraining.py:  512]:	********exe.run_123******* 
[INFO] 2021-07-12 18:16:32,552 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:16:32,552 [run_pretraining.py:  534]:	loss/total_loss, 10.1971435546875, 124
[INFO] 2021-07-12 18:16:32,552 [run_pretraining.py:  535]:	loss/mlm_loss, 10.1971435546875, 124
[INFO] 2021-07-12 18:16:32,553 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2299999525566818e-06, 124
[INFO] 2021-07-12 18:16:32,553 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 124
[INFO] 2021-07-12 18:16:32,553 [run_pretraining.py:  558]:	worker_index: 3, step: 124, cost: 10.197144, mlm loss: 10.197144, speed: 1.062048 steps/s, speed: 8.496387 samples/s, speed: 4350.150037 tokens/s, learning rate: 1.230e-06, loss_scalings: 26214.400391, pp_loss: 10.139542
[INFO] 2021-07-12 18:16:32,553 [run_pretraining.py:  512]:	********exe.run_124******* 
[INFO] 2021-07-12 18:16:33,483 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:16:33,484 [run_pretraining.py:  534]:	loss/total_loss, 9.96345329284668, 125
[INFO] 2021-07-12 18:16:33,484 [run_pretraining.py:  535]:	loss/mlm_loss, 9.96345329284668, 125
[INFO] 2021-07-12 18:16:33,484 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2399999604895129e-06, 125
[INFO] 2021-07-12 18:16:33,484 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 125
[INFO] 2021-07-12 18:16:33,484 [run_pretraining.py:  558]:	worker_index: 3, step: 125, cost: 9.963453, mlm loss: 9.963453, speed: 1.074269 steps/s, speed: 8.594152 samples/s, speed: 4400.205921 tokens/s, learning rate: 1.240e-06, loss_scalings: 26214.400391, pp_loss: 10.103291
[INFO] 2021-07-12 18:16:33,484 [run_pretraining.py:  512]:	********exe.run_125******* 
[INFO] 2021-07-12 18:16:58,778 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:16:58,778 [run_pretraining.py:  534]:	loss/total_loss, 9.927577018737793, 126
[INFO] 2021-07-12 18:16:58,779 [run_pretraining.py:  535]:	loss/mlm_loss, 9.927577018737793, 126
[INFO] 2021-07-12 18:16:58,779 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.249999968422344e-06, 126
[INFO] 2021-07-12 18:16:58,779 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 126
[INFO] 2021-07-12 18:16:58,779 [run_pretraining.py:  558]:	worker_index: 3, step: 126, cost: 9.927577, mlm loss: 9.927577, speed: 0.039535 steps/s, speed: 0.316282 samples/s, speed: 161.936129 tokens/s, learning rate: 1.250e-06, loss_scalings: 26214.400391, pp_loss: 10.095521
[INFO] 2021-07-12 18:16:58,779 [run_pretraining.py:  512]:	********exe.run_126******* 
[INFO] 2021-07-12 18:16:59,715 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:16:59,715 [run_pretraining.py:  534]:	loss/total_loss, 9.899641990661621, 127
[INFO] 2021-07-12 18:16:59,716 [run_pretraining.py:  535]:	loss/mlm_loss, 9.899641990661621, 127
[INFO] 2021-07-12 18:16:59,716 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.259999976355175e-06, 127
[INFO] 2021-07-12 18:16:59,716 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 127
[INFO] 2021-07-12 18:16:59,716 [run_pretraining.py:  558]:	worker_index: 3, step: 127, cost: 9.899642, mlm loss: 9.899642, speed: 1.067995 steps/s, speed: 8.543956 samples/s, speed: 4374.505651 tokens/s, learning rate: 1.260e-06, loss_scalings: 26214.400391, pp_loss: 10.068939
[INFO] 2021-07-12 18:16:59,716 [run_pretraining.py:  512]:	********exe.run_127******* 
[INFO] 2021-07-12 18:17:26,188 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:17:26,189 [run_pretraining.py:  534]:	loss/total_loss, 10.122201919555664, 128
[INFO] 2021-07-12 18:17:26,189 [run_pretraining.py:  535]:	loss/mlm_loss, 10.122201919555664, 128
[INFO] 2021-07-12 18:17:26,189 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.269999984288006e-06, 128
[INFO] 2021-07-12 18:17:26,189 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 128
[INFO] 2021-07-12 18:17:26,189 [run_pretraining.py:  558]:	worker_index: 3, step: 128, cost: 10.122202, mlm loss: 10.122202, speed: 0.037775 steps/s, speed: 0.302199 samples/s, speed: 154.725943 tokens/s, learning rate: 1.270e-06, loss_scalings: 26214.400391, pp_loss: 10.079606
[INFO] 2021-07-12 18:17:26,189 [run_pretraining.py:  512]:	********exe.run_128******* 
[INFO] 2021-07-12 18:18:14,902 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:18:14,903 [run_pretraining.py:  534]:	loss/total_loss, 10.167865753173828, 129
[INFO] 2021-07-12 18:18:14,903 [run_pretraining.py:  535]:	loss/mlm_loss, 10.167865753173828, 129
[INFO] 2021-07-12 18:18:14,903 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2799998785339994e-06, 129
[INFO] 2021-07-12 18:18:14,903 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 129
[INFO] 2021-07-12 18:18:14,903 [run_pretraining.py:  558]:	worker_index: 3, step: 129, cost: 10.167866, mlm loss: 10.167866, speed: 0.020528 steps/s, speed: 0.164226 samples/s, speed: 84.083572 tokens/s, learning rate: 1.280e-06, loss_scalings: 26214.400391, pp_loss: 10.196547
[INFO] 2021-07-12 18:18:14,903 [run_pretraining.py:  512]:	********exe.run_129******* 
[INFO] 2021-07-12 18:18:15,866 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:18:15,867 [run_pretraining.py:  534]:	loss/total_loss, 10.268187522888184, 130
[INFO] 2021-07-12 18:18:15,867 [run_pretraining.py:  535]:	loss/mlm_loss, 10.268187522888184, 130
[INFO] 2021-07-12 18:18:15,867 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2900000001536682e-06, 130
[INFO] 2021-07-12 18:18:15,867 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 130
[INFO] 2021-07-12 18:18:15,867 [run_pretraining.py:  558]:	worker_index: 3, step: 130, cost: 10.268188, mlm loss: 10.268188, speed: 1.037969 steps/s, speed: 8.303754 samples/s, speed: 4251.522055 tokens/s, learning rate: 1.290e-06, loss_scalings: 26214.400391, pp_loss: 10.092810
[INFO] 2021-07-12 18:18:15,867 [run_pretraining.py:  512]:	********exe.run_130******* 
[INFO] 2021-07-12 18:19:03,085 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:19:03,086 [run_pretraining.py:  534]:	loss/total_loss, 5.626866340637207, 131
[INFO] 2021-07-12 18:19:03,086 [run_pretraining.py:  535]:	loss/mlm_loss, 5.626866340637207, 131
[INFO] 2021-07-12 18:19:03,086 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3000000080864993e-06, 131
[INFO] 2021-07-12 18:19:03,086 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 131
[INFO] 2021-07-12 18:19:03,086 [run_pretraining.py:  558]:	worker_index: 3, step: 131, cost: 5.626866, mlm loss: 5.626866, speed: 0.021178 steps/s, speed: 0.169427 samples/s, speed: 86.746549 tokens/s, learning rate: 1.300e-06, loss_scalings: 26214.400391, pp_loss: 9.025798
[INFO] 2021-07-12 18:19:03,086 [run_pretraining.py:  512]:	********exe.run_131******* 
[INFO] 2021-07-12 18:19:04,039 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:19:04,040 [run_pretraining.py:  534]:	loss/total_loss, 10.220345497131348, 132
[INFO] 2021-07-12 18:19:04,040 [run_pretraining.py:  535]:	loss/mlm_loss, 10.220345497131348, 132
[INFO] 2021-07-12 18:19:04,040 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3100000160193304e-06, 132
[INFO] 2021-07-12 18:19:04,040 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 132
[INFO] 2021-07-12 18:19:04,040 [run_pretraining.py:  558]:	worker_index: 3, step: 132, cost: 10.220345, mlm loss: 10.220345, speed: 1.048628 steps/s, speed: 8.389027 samples/s, speed: 4295.182055 tokens/s, learning rate: 1.310e-06, loss_scalings: 26214.400391, pp_loss: 10.123586
[INFO] 2021-07-12 18:19:04,040 [run_pretraining.py:  512]:	********exe.run_132******* 
[INFO] 2021-07-12 18:19:04,978 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:19:04,979 [run_pretraining.py:  534]:	loss/total_loss, 10.177413940429688, 133
[INFO] 2021-07-12 18:19:04,979 [run_pretraining.py:  535]:	loss/mlm_loss, 10.177413940429688, 133
[INFO] 2021-07-12 18:19:04,979 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3199999102653237e-06, 133
[INFO] 2021-07-12 18:19:04,979 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 133
[INFO] 2021-07-12 18:19:04,979 [run_pretraining.py:  558]:	worker_index: 3, step: 133, cost: 10.177414, mlm loss: 10.177414, speed: 1.065650 steps/s, speed: 8.525199 samples/s, speed: 4364.901752 tokens/s, learning rate: 1.320e-06, loss_scalings: 26214.400391, pp_loss: 10.162302
[INFO] 2021-07-12 18:19:04,979 [run_pretraining.py:  512]:	********exe.run_133******* 
[INFO] 2021-07-12 18:19:05,920 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:19:05,921 [run_pretraining.py:  534]:	loss/total_loss, 10.06632137298584, 134
[INFO] 2021-07-12 18:19:05,921 [run_pretraining.py:  535]:	loss/mlm_loss, 10.06632137298584, 134
[INFO] 2021-07-12 18:19:05,921 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3299999181981548e-06, 134
[INFO] 2021-07-12 18:19:05,921 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 134
[INFO] 2021-07-12 18:19:05,921 [run_pretraining.py:  558]:	worker_index: 3, step: 134, cost: 10.066321, mlm loss: 10.066321, speed: 1.062760 steps/s, speed: 8.502079 samples/s, speed: 4353.064382 tokens/s, learning rate: 1.330e-06, loss_scalings: 26214.400391, pp_loss: 10.027201
[INFO] 2021-07-12 18:19:05,921 [run_pretraining.py:  512]:	********exe.run_134******* 
[INFO] 2021-07-12 18:19:52,314 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:19:52,315 [run_pretraining.py:  534]:	loss/total_loss, 10.187592506408691, 135
[INFO] 2021-07-12 18:19:52,315 [run_pretraining.py:  535]:	loss/mlm_loss, 10.187592506408691, 135
[INFO] 2021-07-12 18:19:52,315 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3399999261309858e-06, 135
[INFO] 2021-07-12 18:19:52,315 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 135
[INFO] 2021-07-12 18:19:52,315 [run_pretraining.py:  558]:	worker_index: 3, step: 135, cost: 10.187593, mlm loss: 10.187593, speed: 0.021555 steps/s, speed: 0.172438 samples/s, speed: 88.288027 tokens/s, learning rate: 1.340e-06, loss_scalings: 26214.400391, pp_loss: 10.128328
[INFO] 2021-07-12 18:19:52,315 [run_pretraining.py:  512]:	********exe.run_135******* 
[INFO] 2021-07-12 18:19:53,255 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:19:53,255 [run_pretraining.py:  534]:	loss/total_loss, 10.070968627929688, 136
[INFO] 2021-07-12 18:19:53,255 [run_pretraining.py:  535]:	loss/mlm_loss, 10.070968627929688, 136
[INFO] 2021-07-12 18:19:53,255 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3500000477506546e-06, 136
[INFO] 2021-07-12 18:19:53,256 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 136
[INFO] 2021-07-12 18:19:53,256 [run_pretraining.py:  558]:	worker_index: 3, step: 136, cost: 10.070969, mlm loss: 10.070969, speed: 1.063950 steps/s, speed: 8.511596 samples/s, speed: 4357.937311 tokens/s, learning rate: 1.350e-06, loss_scalings: 26214.400391, pp_loss: 10.122126
[INFO] 2021-07-12 18:19:53,256 [run_pretraining.py:  512]:	********exe.run_136******* 
[INFO] 2021-07-12 18:19:54,182 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:19:54,183 [run_pretraining.py:  534]:	loss/total_loss, 10.29604721069336, 137
[INFO] 2021-07-12 18:19:54,183 [run_pretraining.py:  535]:	loss/mlm_loss, 10.29604721069336, 137
[INFO] 2021-07-12 18:19:54,183 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.359999941996648e-06, 137
[INFO] 2021-07-12 18:19:54,183 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 137
[INFO] 2021-07-12 18:19:54,183 [run_pretraining.py:  558]:	worker_index: 3, step: 137, cost: 10.296047, mlm loss: 10.296047, speed: 1.079152 steps/s, speed: 8.633219 samples/s, speed: 4420.208375 tokens/s, learning rate: 1.360e-06, loss_scalings: 26214.400391, pp_loss: 9.452519
[INFO] 2021-07-12 18:19:54,183 [run_pretraining.py:  512]:	********exe.run_137******* 
[INFO] 2021-07-12 18:19:55,121 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:19:55,122 [run_pretraining.py:  534]:	loss/total_loss, 10.111576080322266, 138
[INFO] 2021-07-12 18:19:55,122 [run_pretraining.py:  535]:	loss/mlm_loss, 10.111576080322266, 138
[INFO] 2021-07-12 18:19:55,122 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.369999949929479e-06, 138
[INFO] 2021-07-12 18:19:55,122 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 138
[INFO] 2021-07-12 18:19:55,122 [run_pretraining.py:  558]:	worker_index: 3, step: 138, cost: 10.111576, mlm loss: 10.111576, speed: 1.065207 steps/s, speed: 8.521652 samples/s, speed: 4363.085976 tokens/s, learning rate: 1.370e-06, loss_scalings: 26214.400391, pp_loss: 9.949494
[INFO] 2021-07-12 18:19:55,122 [run_pretraining.py:  512]:	********exe.run_138******* 
[INFO] 2021-07-12 18:19:56,052 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:19:56,053 [run_pretraining.py:  534]:	loss/total_loss, 10.145769119262695, 139
[INFO] 2021-07-12 18:19:56,053 [run_pretraining.py:  535]:	loss/mlm_loss, 10.145769119262695, 139
[INFO] 2021-07-12 18:19:56,053 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3799999578623101e-06, 139
[INFO] 2021-07-12 18:19:56,053 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 139
[INFO] 2021-07-12 18:19:56,053 [run_pretraining.py:  558]:	worker_index: 3, step: 139, cost: 10.145769, mlm loss: 10.145769, speed: 1.075425 steps/s, speed: 8.603398 samples/s, speed: 4404.939925 tokens/s, learning rate: 1.380e-06, loss_scalings: 26214.400391, pp_loss: 10.072968
[INFO] 2021-07-12 18:19:56,053 [run_pretraining.py:  512]:	********exe.run_139******* 
[INFO] 2021-07-12 18:20:19,894 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:20:19,895 [run_pretraining.py:  534]:	loss/total_loss, 10.20213508605957, 140
[INFO] 2021-07-12 18:20:19,895 [run_pretraining.py:  535]:	loss/mlm_loss, 10.20213508605957, 140
[INFO] 2021-07-12 18:20:19,895 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3899999657951412e-06, 140
[INFO] 2021-07-12 18:20:19,895 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 140
[INFO] 2021-07-12 18:20:19,895 [run_pretraining.py:  558]:	worker_index: 3, step: 140, cost: 10.202135, mlm loss: 10.202135, speed: 0.041944 steps/s, speed: 0.335549 samples/s, speed: 171.801195 tokens/s, learning rate: 1.390e-06, loss_scalings: 26214.400391, pp_loss: 10.084330
[INFO] 2021-07-12 18:20:19,895 [run_pretraining.py:  512]:	********exe.run_140******* 
[INFO] 2021-07-12 18:20:20,824 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:20:20,824 [run_pretraining.py:  534]:	loss/total_loss, 10.042618751525879, 141
[INFO] 2021-07-12 18:20:20,824 [run_pretraining.py:  535]:	loss/mlm_loss, 10.042618751525879, 141
[INFO] 2021-07-12 18:20:20,824 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3999999737279722e-06, 141
[INFO] 2021-07-12 18:20:20,824 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 141
[INFO] 2021-07-12 18:20:20,825 [run_pretraining.py:  558]:	worker_index: 3, step: 141, cost: 10.042619, mlm loss: 10.042619, speed: 1.076633 steps/s, speed: 8.613064 samples/s, speed: 4409.889003 tokens/s, learning rate: 1.400e-06, loss_scalings: 26214.400391, pp_loss: 10.094229
[INFO] 2021-07-12 18:20:20,825 [run_pretraining.py:  512]:	********exe.run_141******* 
[INFO] 2021-07-12 18:20:21,772 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:20:21,773 [run_pretraining.py:  534]:	loss/total_loss, 10.037493705749512, 142
[INFO] 2021-07-12 18:20:21,773 [run_pretraining.py:  535]:	loss/mlm_loss, 10.037493705749512, 142
[INFO] 2021-07-12 18:20:21,773 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4099999816608033e-06, 142
[INFO] 2021-07-12 18:20:21,773 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 142
[INFO] 2021-07-12 18:20:21,773 [run_pretraining.py:  558]:	worker_index: 3, step: 142, cost: 10.037494, mlm loss: 10.037494, speed: 1.054926 steps/s, speed: 8.439409 samples/s, speed: 4320.977420 tokens/s, learning rate: 1.410e-06, loss_scalings: 26214.400391, pp_loss: 10.076116
[INFO] 2021-07-12 18:20:21,773 [run_pretraining.py:  512]:	********exe.run_142******* 
[INFO] 2021-07-12 18:20:45,285 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:20:45,286 [run_pretraining.py:  534]:	loss/total_loss, 10.114069938659668, 143
[INFO] 2021-07-12 18:20:45,286 [run_pretraining.py:  535]:	loss/mlm_loss, 10.114069938659668, 143
[INFO] 2021-07-12 18:20:45,286 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4199999895936344e-06, 143
[INFO] 2021-07-12 18:20:45,286 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 143
[INFO] 2021-07-12 18:20:45,286 [run_pretraining.py:  558]:	worker_index: 3, step: 143, cost: 10.114070, mlm loss: 10.114070, speed: 0.042530 steps/s, speed: 0.340243 samples/s, speed: 174.204602 tokens/s, learning rate: 1.420e-06, loss_scalings: 26214.400391, pp_loss: 10.083281
[INFO] 2021-07-12 18:20:45,286 [run_pretraining.py:  512]:	********exe.run_143******* 
[INFO] 2021-07-12 18:21:08,582 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:21:08,583 [run_pretraining.py:  534]:	loss/total_loss, 10.233183860778809, 144
[INFO] 2021-07-12 18:21:08,583 [run_pretraining.py:  535]:	loss/mlm_loss, 10.233183860778809, 144
[INFO] 2021-07-12 18:21:08,583 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4299999975264654e-06, 144
[INFO] 2021-07-12 18:21:08,583 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 144
[INFO] 2021-07-12 18:21:08,583 [run_pretraining.py:  558]:	worker_index: 3, step: 144, cost: 10.233184, mlm loss: 10.233184, speed: 0.042925 steps/s, speed: 0.343403 samples/s, speed: 175.822481 tokens/s, learning rate: 1.430e-06, loss_scalings: 26214.400391, pp_loss: 10.066886
[INFO] 2021-07-12 18:21:08,583 [run_pretraining.py:  512]:	********exe.run_144******* 
[INFO] 2021-07-12 18:21:09,532 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:21:09,532 [run_pretraining.py:  534]:	loss/total_loss, 10.134969711303711, 145
[INFO] 2021-07-12 18:21:09,532 [run_pretraining.py:  535]:	loss/mlm_loss, 10.134969711303711, 145
[INFO] 2021-07-12 18:21:09,532 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4399998917724588e-06, 145
[INFO] 2021-07-12 18:21:09,533 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 145
[INFO] 2021-07-12 18:21:09,533 [run_pretraining.py:  558]:	worker_index: 3, step: 145, cost: 10.134970, mlm loss: 10.134970, speed: 1.054067 steps/s, speed: 8.432533 samples/s, speed: 4317.456929 tokens/s, learning rate: 1.440e-06, loss_scalings: 26214.400391, pp_loss: 10.118048
[INFO] 2021-07-12 18:21:09,533 [run_pretraining.py:  512]:	********exe.run_145******* 
[INFO] 2021-07-12 18:21:10,475 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:21:10,475 [run_pretraining.py:  534]:	loss/total_loss, 10.073826789855957, 146
[INFO] 2021-07-12 18:21:10,475 [run_pretraining.py:  535]:	loss/mlm_loss, 10.073826789855957, 146
[INFO] 2021-07-12 18:21:10,476 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4499998997052899e-06, 146
[INFO] 2021-07-12 18:21:10,476 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 146
[INFO] 2021-07-12 18:21:10,476 [run_pretraining.py:  558]:	worker_index: 3, step: 146, cost: 10.073827, mlm loss: 10.073827, speed: 1.061098 steps/s, speed: 8.488786 samples/s, speed: 4346.258580 tokens/s, learning rate: 1.450e-06, loss_scalings: 26214.400391, pp_loss: 9.147517
[INFO] 2021-07-12 18:21:10,476 [run_pretraining.py:  512]:	********exe.run_146******* 
[INFO] 2021-07-12 18:21:11,465 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:21:11,465 [run_pretraining.py:  534]:	loss/total_loss, 10.073514938354492, 147
[INFO] 2021-07-12 18:21:11,466 [run_pretraining.py:  535]:	loss/mlm_loss, 10.073514938354492, 147
[INFO] 2021-07-12 18:21:11,466 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4600000213249587e-06, 147
[INFO] 2021-07-12 18:21:11,466 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 147
[INFO] 2021-07-12 18:21:11,466 [run_pretraining.py:  558]:	worker_index: 3, step: 147, cost: 10.073515, mlm loss: 10.073515, speed: 1.010658 steps/s, speed: 8.085267 samples/s, speed: 4139.656691 tokens/s, learning rate: 1.460e-06, loss_scalings: 26214.400391, pp_loss: 9.876911
[INFO] 2021-07-12 18:21:11,466 [run_pretraining.py:  512]:	********exe.run_147******* 
[INFO] 2021-07-12 18:21:12,417 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:21:12,418 [run_pretraining.py:  534]:	loss/total_loss, 10.027942657470703, 148
[INFO] 2021-07-12 18:21:12,418 [run_pretraining.py:  535]:	loss/mlm_loss, 10.027942657470703, 148
[INFO] 2021-07-12 18:21:12,418 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4700000292577897e-06, 148
[INFO] 2021-07-12 18:21:12,418 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 148
[INFO] 2021-07-12 18:21:12,418 [run_pretraining.py:  558]:	worker_index: 3, step: 148, cost: 10.027943, mlm loss: 10.027943, speed: 1.050841 steps/s, speed: 8.406731 samples/s, speed: 4304.246175 tokens/s, learning rate: 1.470e-06, loss_scalings: 26214.400391, pp_loss: 10.057706
[INFO] 2021-07-12 18:21:12,418 [run_pretraining.py:  512]:	********exe.run_148******* 
[INFO] 2021-07-12 18:21:13,356 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:21:13,357 [run_pretraining.py:  534]:	loss/total_loss, 10.11112117767334, 149
[INFO] 2021-07-12 18:21:13,357 [run_pretraining.py:  535]:	loss/mlm_loss, 10.11112117767334, 149
[INFO] 2021-07-12 18:21:13,357 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.479999923503783e-06, 149
[INFO] 2021-07-12 18:21:13,357 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 149
[INFO] 2021-07-12 18:21:13,357 [run_pretraining.py:  558]:	worker_index: 3, step: 149, cost: 10.111121, mlm loss: 10.111121, speed: 1.065871 steps/s, speed: 8.526967 samples/s, speed: 4365.806878 tokens/s, learning rate: 1.480e-06, loss_scalings: 26214.400391, pp_loss: 10.077507
[INFO] 2021-07-12 18:21:13,357 [run_pretraining.py:  512]:	********exe.run_149******* 
[INFO] 2021-07-12 18:21:14,301 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:21:14,302 [run_pretraining.py:  534]:	loss/total_loss, 10.117691040039062, 150
[INFO] 2021-07-12 18:21:14,302 [run_pretraining.py:  535]:	loss/mlm_loss, 10.117691040039062, 150
[INFO] 2021-07-12 18:21:14,302 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4899999314366141e-06, 150
[INFO] 2021-07-12 18:21:14,302 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 150
[INFO] 2021-07-12 18:21:14,302 [run_pretraining.py:  558]:	worker_index: 3, step: 150, cost: 10.117691, mlm loss: 10.117691, speed: 1.058932 steps/s, speed: 8.471452 samples/s, speed: 4337.383655 tokens/s, learning rate: 1.490e-06, loss_scalings: 26214.400391, pp_loss: 9.031904
[INFO] 2021-07-12 18:21:14,302 [run_pretraining.py:  512]:	********exe.run_150******* 
[INFO] 2021-07-12 18:21:15,245 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:21:15,246 [run_pretraining.py:  534]:	loss/total_loss, 10.03128433227539, 151
[INFO] 2021-07-12 18:21:15,246 [run_pretraining.py:  535]:	loss/mlm_loss, 10.03128433227539, 151
[INFO] 2021-07-12 18:21:15,246 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4999999393694452e-06, 151
[INFO] 2021-07-12 18:21:15,246 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 151
[INFO] 2021-07-12 18:21:15,246 [run_pretraining.py:  558]:	worker_index: 3, step: 151, cost: 10.031284, mlm loss: 10.031284, speed: 1.059956 steps/s, speed: 8.479645 samples/s, speed: 4341.578483 tokens/s, learning rate: 1.500e-06, loss_scalings: 26214.400391, pp_loss: 9.948357
[INFO] 2021-07-12 18:21:15,246 [run_pretraining.py:  512]:	********exe.run_151******* 
[INFO] 2021-07-12 18:21:16,190 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:21:16,190 [run_pretraining.py:  534]:	loss/total_loss, 10.168510437011719, 152
[INFO] 2021-07-12 18:21:16,190 [run_pretraining.py:  535]:	loss/mlm_loss, 10.168510437011719, 152
[INFO] 2021-07-12 18:21:16,190 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.510000060989114e-06, 152
[INFO] 2021-07-12 18:21:16,190 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 152
[INFO] 2021-07-12 18:21:16,191 [run_pretraining.py:  558]:	worker_index: 3, step: 152, cost: 10.168510, mlm loss: 10.168510, speed: 1.059330 steps/s, speed: 8.474643 samples/s, speed: 4339.016997 tokens/s, learning rate: 1.510e-06, loss_scalings: 26214.400391, pp_loss: 10.030720
[INFO] 2021-07-12 18:21:16,191 [run_pretraining.py:  512]:	********exe.run_152******* 
[INFO] 2021-07-12 18:21:17,142 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:21:17,143 [run_pretraining.py:  534]:	loss/total_loss, 9.903437614440918, 153
[INFO] 2021-07-12 18:21:17,143 [run_pretraining.py:  535]:	loss/mlm_loss, 9.903437614440918, 153
[INFO] 2021-07-12 18:21:17,143 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5199999552351073e-06, 153
[INFO] 2021-07-12 18:21:17,143 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 153
[INFO] 2021-07-12 18:21:17,143 [run_pretraining.py:  558]:	worker_index: 3, step: 153, cost: 9.903438, mlm loss: 9.903438, speed: 1.050550 steps/s, speed: 8.404398 samples/s, speed: 4303.051654 tokens/s, learning rate: 1.520e-06, loss_scalings: 26214.400391, pp_loss: 10.023513
[INFO] 2021-07-12 18:21:17,143 [run_pretraining.py:  512]:	********exe.run_153******* 
[INFO] 2021-07-12 18:21:42,901 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:21:42,902 [run_pretraining.py:  534]:	loss/total_loss, 9.941068649291992, 154
[INFO] 2021-07-12 18:21:42,902 [run_pretraining.py:  535]:	loss/mlm_loss, 9.941068649291992, 154
[INFO] 2021-07-12 18:21:42,902 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5299999631679384e-06, 154
[INFO] 2021-07-12 18:21:42,902 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 154
[INFO] 2021-07-12 18:21:42,902 [run_pretraining.py:  558]:	worker_index: 3, step: 154, cost: 9.941069, mlm loss: 9.941069, speed: 0.038823 steps/s, speed: 0.310581 samples/s, speed: 159.017257 tokens/s, learning rate: 1.530e-06, loss_scalings: 26214.400391, pp_loss: 9.853827
[INFO] 2021-07-12 18:21:42,902 [run_pretraining.py:  512]:	********exe.run_154******* 
[INFO] 2021-07-12 18:21:43,894 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:21:43,895 [run_pretraining.py:  534]:	loss/total_loss, 9.941892623901367, 155
[INFO] 2021-07-12 18:21:43,895 [run_pretraining.py:  535]:	loss/mlm_loss, 9.941892623901367, 155
[INFO] 2021-07-12 18:21:43,895 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5399999711007695e-06, 155
[INFO] 2021-07-12 18:21:43,895 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 155
[INFO] 2021-07-12 18:21:43,895 [run_pretraining.py:  558]:	worker_index: 3, step: 155, cost: 9.941893, mlm loss: 9.941893, speed: 1.007542 steps/s, speed: 8.060339 samples/s, speed: 4126.893373 tokens/s, learning rate: 1.540e-06, loss_scalings: 26214.400391, pp_loss: 9.920446
[INFO] 2021-07-12 18:21:43,895 [run_pretraining.py:  512]:	********exe.run_155******* 
[INFO] 2021-07-12 18:21:44,861 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:21:44,861 [run_pretraining.py:  534]:	loss/total_loss, 9.962936401367188, 156
[INFO] 2021-07-12 18:21:44,861 [run_pretraining.py:  535]:	loss/mlm_loss, 9.962936401367188, 156
[INFO] 2021-07-12 18:21:44,861 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5499999790336005e-06, 156
[INFO] 2021-07-12 18:21:44,861 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 156
[INFO] 2021-07-12 18:21:44,861 [run_pretraining.py:  558]:	worker_index: 3, step: 156, cost: 9.962936, mlm loss: 9.962936, speed: 1.035509 steps/s, speed: 8.284071 samples/s, speed: 4241.444508 tokens/s, learning rate: 1.550e-06, loss_scalings: 26214.400391, pp_loss: 9.986040
[INFO] 2021-07-12 18:21:44,862 [run_pretraining.py:  512]:	********exe.run_156******* 
[INFO] 2021-07-12 18:21:45,836 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:21:45,837 [run_pretraining.py:  534]:	loss/total_loss, 10.003935813903809, 157
[INFO] 2021-07-12 18:21:45,837 [run_pretraining.py:  535]:	loss/mlm_loss, 10.003935813903809, 157
[INFO] 2021-07-12 18:21:45,837 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5599998732795939e-06, 157
[INFO] 2021-07-12 18:21:45,837 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 157
[INFO] 2021-07-12 18:21:45,837 [run_pretraining.py:  558]:	worker_index: 3, step: 157, cost: 10.003936, mlm loss: 10.003936, speed: 1.025623 steps/s, speed: 8.204981 samples/s, speed: 4200.950034 tokens/s, learning rate: 1.560e-06, loss_scalings: 26214.400391, pp_loss: 9.970556
[INFO] 2021-07-12 18:21:45,837 [run_pretraining.py:  512]:	********exe.run_157******* 
[INFO] 2021-07-12 18:22:11,585 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:11,586 [run_pretraining.py:  534]:	loss/total_loss, 10.033647537231445, 158
[INFO] 2021-07-12 18:22:11,586 [run_pretraining.py:  535]:	loss/mlm_loss, 10.033647537231445, 158
[INFO] 2021-07-12 18:22:11,586 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.569999881212425e-06, 158
[INFO] 2021-07-12 18:22:11,586 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 158
[INFO] 2021-07-12 18:22:11,586 [run_pretraining.py:  558]:	worker_index: 3, step: 158, cost: 10.033648, mlm loss: 10.033648, speed: 0.038837 steps/s, speed: 0.310700 samples/s, speed: 159.078257 tokens/s, learning rate: 1.570e-06, loss_scalings: 26214.400391, pp_loss: 9.988205
[INFO] 2021-07-12 18:22:11,586 [run_pretraining.py:  512]:	********exe.run_158******* 
[INFO] 2021-07-12 18:22:12,584 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:12,584 [run_pretraining.py:  534]:	loss/total_loss, 9.942935943603516, 159
[INFO] 2021-07-12 18:22:12,585 [run_pretraining.py:  535]:	loss/mlm_loss, 9.942935943603516, 159
[INFO] 2021-07-12 18:22:12,585 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.579999889145256e-06, 159
[INFO] 2021-07-12 18:22:12,585 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 159
[INFO] 2021-07-12 18:22:12,585 [run_pretraining.py:  558]:	worker_index: 3, step: 159, cost: 9.942936, mlm loss: 9.942936, speed: 1.002050 steps/s, speed: 8.016397 samples/s, speed: 4104.395101 tokens/s, learning rate: 1.580e-06, loss_scalings: 26214.400391, pp_loss: 9.987609
[INFO] 2021-07-12 18:22:12,585 [run_pretraining.py:  512]:	********exe.run_159******* 
[INFO] 2021-07-12 18:22:13,556 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:13,556 [run_pretraining.py:  534]:	loss/total_loss, 9.63774299621582, 160
[INFO] 2021-07-12 18:22:13,556 [run_pretraining.py:  535]:	loss/mlm_loss, 9.63774299621582, 160
[INFO] 2021-07-12 18:22:13,557 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5900000107649248e-06, 160
[INFO] 2021-07-12 18:22:13,557 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 160
[INFO] 2021-07-12 18:22:13,557 [run_pretraining.py:  558]:	worker_index: 3, step: 160, cost: 9.637743, mlm loss: 9.637743, speed: 1.029551 steps/s, speed: 8.236411 samples/s, speed: 4217.042673 tokens/s, learning rate: 1.590e-06, loss_scalings: 26214.400391, pp_loss: 9.937087
[INFO] 2021-07-12 18:22:13,557 [run_pretraining.py:  512]:	********exe.run_160******* 
[INFO] 2021-07-12 18:22:14,528 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:14,529 [run_pretraining.py:  534]:	loss/total_loss, 9.535017013549805, 161
[INFO] 2021-07-12 18:22:14,529 [run_pretraining.py:  535]:	loss/mlm_loss, 9.535017013549805, 161
[INFO] 2021-07-12 18:22:14,529 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6000000186977559e-06, 161
[INFO] 2021-07-12 18:22:14,529 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 161
[INFO] 2021-07-12 18:22:14,529 [run_pretraining.py:  558]:	worker_index: 3, step: 161, cost: 9.535017, mlm loss: 9.535017, speed: 1.028806 steps/s, speed: 8.230448 samples/s, speed: 4213.989173 tokens/s, learning rate: 1.600e-06, loss_scalings: 26214.400391, pp_loss: 9.755693
[INFO] 2021-07-12 18:22:14,529 [run_pretraining.py:  512]:	********exe.run_161******* 
[INFO] 2021-07-12 18:22:15,494 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:15,495 [run_pretraining.py:  534]:	loss/total_loss, 9.971681594848633, 162
[INFO] 2021-07-12 18:22:15,495 [run_pretraining.py:  535]:	loss/mlm_loss, 9.971681594848633, 162
[INFO] 2021-07-12 18:22:15,495 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.610000026630587e-06, 162
[INFO] 2021-07-12 18:22:15,495 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 162
[INFO] 2021-07-12 18:22:15,495 [run_pretraining.py:  558]:	worker_index: 3, step: 162, cost: 9.971682, mlm loss: 9.971682, speed: 1.036412 steps/s, speed: 8.291297 samples/s, speed: 4245.144162 tokens/s, learning rate: 1.610e-06, loss_scalings: 26214.400391, pp_loss: 8.988298
[INFO] 2021-07-12 18:22:15,495 [run_pretraining.py:  512]:	********exe.run_162******* 
[INFO] 2021-07-12 18:22:16,465 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:16,466 [run_pretraining.py:  534]:	loss/total_loss, 10.176393508911133, 163
[INFO] 2021-07-12 18:22:16,466 [run_pretraining.py:  535]:	loss/mlm_loss, 10.176393508911133, 163
[INFO] 2021-07-12 18:22:16,466 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.620000034563418e-06, 163
[INFO] 2021-07-12 18:22:16,466 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 163
[INFO] 2021-07-12 18:22:16,466 [run_pretraining.py:  558]:	worker_index: 3, step: 163, cost: 10.176394, mlm loss: 10.176394, speed: 1.030192 steps/s, speed: 8.241540 samples/s, speed: 4219.668369 tokens/s, learning rate: 1.620e-06, loss_scalings: 26214.400391, pp_loss: 10.067356
[INFO] 2021-07-12 18:22:16,466 [run_pretraining.py:  512]:	********exe.run_163******* 
[INFO] 2021-07-12 18:22:17,431 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:17,431 [run_pretraining.py:  534]:	loss/total_loss, 10.119139671325684, 164
[INFO] 2021-07-12 18:22:17,432 [run_pretraining.py:  535]:	loss/mlm_loss, 10.119139671325684, 164
[INFO] 2021-07-12 18:22:17,432 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6299999288094114e-06, 164
[INFO] 2021-07-12 18:22:17,432 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 164
[INFO] 2021-07-12 18:22:17,432 [run_pretraining.py:  558]:	worker_index: 3, step: 164, cost: 10.119140, mlm loss: 10.119140, speed: 1.036369 steps/s, speed: 8.290949 samples/s, speed: 4244.965843 tokens/s, learning rate: 1.630e-06, loss_scalings: 26214.400391, pp_loss: 10.106356
[INFO] 2021-07-12 18:22:17,432 [run_pretraining.py:  512]:	********exe.run_164******* 
[INFO] 2021-07-12 18:22:18,406 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:18,407 [run_pretraining.py:  534]:	loss/total_loss, 9.95541763305664, 165
[INFO] 2021-07-12 18:22:18,407 [run_pretraining.py:  535]:	loss/mlm_loss, 9.95541763305664, 165
[INFO] 2021-07-12 18:22:18,407 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6399999367422424e-06, 165
[INFO] 2021-07-12 18:22:18,407 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 165
[INFO] 2021-07-12 18:22:18,407 [run_pretraining.py:  558]:	worker_index: 3, step: 165, cost: 9.955418, mlm loss: 9.955418, speed: 1.026138 steps/s, speed: 8.209106 samples/s, speed: 4203.062090 tokens/s, learning rate: 1.640e-06, loss_scalings: 26214.400391, pp_loss: 9.998781
[INFO] 2021-07-12 18:22:18,407 [run_pretraining.py:  512]:	********exe.run_165******* 
[INFO] 2021-07-12 18:22:19,370 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:19,371 [run_pretraining.py:  534]:	loss/total_loss, 10.238412857055664, 166
[INFO] 2021-07-12 18:22:19,371 [run_pretraining.py:  535]:	loss/mlm_loss, 10.238412857055664, 166
[INFO] 2021-07-12 18:22:19,371 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6499999446750735e-06, 166
[INFO] 2021-07-12 18:22:19,371 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 166
[INFO] 2021-07-12 18:22:19,371 [run_pretraining.py:  558]:	worker_index: 3, step: 166, cost: 10.238413, mlm loss: 10.238413, speed: 1.037874 steps/s, speed: 8.302994 samples/s, speed: 4251.132803 tokens/s, learning rate: 1.650e-06, loss_scalings: 26214.400391, pp_loss: 10.094747
[INFO] 2021-07-12 18:22:19,371 [run_pretraining.py:  512]:	********exe.run_166******* 
[INFO] 2021-07-12 18:22:20,339 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:20,340 [run_pretraining.py:  534]:	loss/total_loss, 10.10689926147461, 167
[INFO] 2021-07-12 18:22:20,340 [run_pretraining.py:  535]:	loss/mlm_loss, 10.10689926147461, 167
[INFO] 2021-07-12 18:22:20,340 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6599999526079046e-06, 167
[INFO] 2021-07-12 18:22:20,340 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 167
[INFO] 2021-07-12 18:22:20,340 [run_pretraining.py:  558]:	worker_index: 3, step: 167, cost: 10.106899, mlm loss: 10.106899, speed: 1.032333 steps/s, speed: 8.258662 samples/s, speed: 4228.434986 tokens/s, learning rate: 1.660e-06, loss_scalings: 26214.400391, pp_loss: 10.097889
[INFO] 2021-07-12 18:22:20,340 [run_pretraining.py:  512]:	********exe.run_167******* 
[INFO] 2021-07-12 18:22:21,313 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:21,314 [run_pretraining.py:  534]:	loss/total_loss, 10.103072166442871, 168
[INFO] 2021-07-12 18:22:21,314 [run_pretraining.py:  535]:	loss/mlm_loss, 10.103072166442871, 168
[INFO] 2021-07-12 18:22:21,314 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6699999605407356e-06, 168
[INFO] 2021-07-12 18:22:21,314 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 168
[INFO] 2021-07-12 18:22:21,314 [run_pretraining.py:  558]:	worker_index: 3, step: 168, cost: 10.103072, mlm loss: 10.103072, speed: 1.027859 steps/s, speed: 8.222872 samples/s, speed: 4210.110416 tokens/s, learning rate: 1.670e-06, loss_scalings: 26214.400391, pp_loss: 10.029770
[INFO] 2021-07-12 18:22:21,314 [run_pretraining.py:  512]:	********exe.run_168******* 
[INFO] 2021-07-12 18:22:22,372 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:22,373 [run_pretraining.py:  534]:	loss/total_loss, 10.130290985107422, 169
[INFO] 2021-07-12 18:22:22,373 [run_pretraining.py:  535]:	loss/mlm_loss, 10.130290985107422, 169
[INFO] 2021-07-12 18:22:22,373 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.679999854786729e-06, 169
[INFO] 2021-07-12 18:22:22,373 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 169
[INFO] 2021-07-12 18:22:22,373 [run_pretraining.py:  558]:	worker_index: 3, step: 169, cost: 10.130291, mlm loss: 10.130291, speed: 0.944519 steps/s, speed: 7.556154 samples/s, speed: 3868.750880 tokens/s, learning rate: 1.680e-06, loss_scalings: 26214.400391, pp_loss: 10.034237
[INFO] 2021-07-12 18:22:22,373 [run_pretraining.py:  512]:	********exe.run_169******* 
[INFO] 2021-07-12 18:22:23,449 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:23,450 [run_pretraining.py:  534]:	loss/total_loss, 10.00837516784668, 170
[INFO] 2021-07-12 18:22:23,450 [run_pretraining.py:  535]:	loss/mlm_loss, 10.00837516784668, 170
[INFO] 2021-07-12 18:22:23,450 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.68999986271956e-06, 170
[INFO] 2021-07-12 18:22:23,450 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 170
[INFO] 2021-07-12 18:22:23,450 [run_pretraining.py:  558]:	worker_index: 3, step: 170, cost: 10.008375, mlm loss: 10.008375, speed: 0.929080 steps/s, speed: 7.432639 samples/s, speed: 3805.511030 tokens/s, learning rate: 1.690e-06, loss_scalings: 26214.400391, pp_loss: 9.016178
[INFO] 2021-07-12 18:22:23,450 [run_pretraining.py:  512]:	********exe.run_170******* 
[INFO] 2021-07-12 18:22:24,492 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:24,493 [run_pretraining.py:  534]:	loss/total_loss, 10.158178329467773, 171
[INFO] 2021-07-12 18:22:24,493 [run_pretraining.py:  535]:	loss/mlm_loss, 10.158178329467773, 171
[INFO] 2021-07-12 18:22:24,493 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7000000980260666e-06, 171
[INFO] 2021-07-12 18:22:24,493 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 171
[INFO] 2021-07-12 18:22:24,493 [run_pretraining.py:  558]:	worker_index: 3, step: 171, cost: 10.158178, mlm loss: 10.158178, speed: 0.959584 steps/s, speed: 7.676668 samples/s, speed: 3930.454040 tokens/s, learning rate: 1.700e-06, loss_scalings: 26214.400391, pp_loss: 10.090833
[INFO] 2021-07-12 18:22:24,493 [run_pretraining.py:  512]:	********exe.run_171******* 
[INFO] 2021-07-12 18:22:25,548 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:25,548 [run_pretraining.py:  534]:	loss/total_loss, 9.826873779296875, 172
[INFO] 2021-07-12 18:22:25,548 [run_pretraining.py:  535]:	loss/mlm_loss, 9.826873779296875, 172
[INFO] 2021-07-12 18:22:25,548 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.70999999227206e-06, 172
[INFO] 2021-07-12 18:22:25,549 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 172
[INFO] 2021-07-12 18:22:25,549 [run_pretraining.py:  558]:	worker_index: 3, step: 172, cost: 9.826874, mlm loss: 9.826874, speed: 0.947896 steps/s, speed: 7.583166 samples/s, speed: 3882.580906 tokens/s, learning rate: 1.710e-06, loss_scalings: 26214.400391, pp_loss: 9.423400
[INFO] 2021-07-12 18:22:25,549 [run_pretraining.py:  512]:	********exe.run_172******* 
[INFO] 2021-07-12 18:22:26,600 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:26,601 [run_pretraining.py:  534]:	loss/total_loss, 10.548051834106445, 173
[INFO] 2021-07-12 18:22:26,601 [run_pretraining.py:  535]:	loss/mlm_loss, 10.548051834106445, 173
[INFO] 2021-07-12 18:22:26,601 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.720000000204891e-06, 173
[INFO] 2021-07-12 18:22:26,601 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 173
[INFO] 2021-07-12 18:22:26,601 [run_pretraining.py:  558]:	worker_index: 3, step: 173, cost: 10.548052, mlm loss: 10.548052, speed: 0.950751 steps/s, speed: 7.606010 samples/s, speed: 3894.277315 tokens/s, learning rate: 1.720e-06, loss_scalings: 26214.400391, pp_loss: 10.080696
[INFO] 2021-07-12 18:22:26,601 [run_pretraining.py:  512]:	********exe.run_173******* 
[INFO] 2021-07-12 18:22:52,565 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:52,566 [run_pretraining.py:  534]:	loss/total_loss, 9.903157234191895, 174
[INFO] 2021-07-12 18:22:52,566 [run_pretraining.py:  535]:	loss/mlm_loss, 9.903157234191895, 174
[INFO] 2021-07-12 18:22:52,566 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.730000008137722e-06, 174
[INFO] 2021-07-12 18:22:52,566 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 174
[INFO] 2021-07-12 18:22:52,566 [run_pretraining.py:  558]:	worker_index: 3, step: 174, cost: 9.903157, mlm loss: 9.903157, speed: 0.038514 steps/s, speed: 0.308114 samples/s, speed: 157.754448 tokens/s, learning rate: 1.730e-06, loss_scalings: 26214.400391, pp_loss: 9.904330
[INFO] 2021-07-12 18:22:52,566 [run_pretraining.py:  512]:	********exe.run_174******* 
[INFO] 2021-07-12 18:23:41,450 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:23:41,450 [run_pretraining.py:  534]:	loss/total_loss, 9.866600036621094, 175
[INFO] 2021-07-12 18:23:41,450 [run_pretraining.py:  535]:	loss/mlm_loss, 9.866600036621094, 175
[INFO] 2021-07-12 18:23:41,451 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.740000016070553e-06, 175
[INFO] 2021-07-12 18:23:41,451 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 175
[INFO] 2021-07-12 18:23:41,451 [run_pretraining.py:  558]:	worker_index: 3, step: 175, cost: 9.866600, mlm loss: 9.866600, speed: 0.020457 steps/s, speed: 0.163653 samples/s, speed: 83.790365 tokens/s, learning rate: 1.740e-06, loss_scalings: 26214.400391, pp_loss: 9.957237
[INFO] 2021-07-12 18:23:41,451 [run_pretraining.py:  512]:	********exe.run_175******* 
[INFO] 2021-07-12 18:23:42,431 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:23:42,432 [run_pretraining.py:  534]:	loss/total_loss, 9.99294376373291, 176
[INFO] 2021-07-12 18:23:42,432 [run_pretraining.py:  535]:	loss/mlm_loss, 9.99294376373291, 176
[INFO] 2021-07-12 18:23:42,432 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7499999103165464e-06, 176
[INFO] 2021-07-12 18:23:42,432 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 176
[INFO] 2021-07-12 18:23:42,432 [run_pretraining.py:  558]:	worker_index: 3, step: 176, cost: 9.992944, mlm loss: 9.992944, speed: 1.019463 steps/s, speed: 8.155707 samples/s, speed: 4175.722240 tokens/s, learning rate: 1.750e-06, loss_scalings: 26214.400391, pp_loss: 9.936285
[INFO] 2021-07-12 18:23:42,432 [run_pretraining.py:  512]:	********exe.run_176******* 
[INFO] 2021-07-12 18:23:43,386 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:23:43,387 [run_pretraining.py:  534]:	loss/total_loss, 9.942171096801758, 177
[INFO] 2021-07-12 18:23:43,387 [run_pretraining.py:  535]:	loss/mlm_loss, 9.942171096801758, 177
[INFO] 2021-07-12 18:23:43,387 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7599999182493775e-06, 177
[INFO] 2021-07-12 18:23:43,387 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 177
[INFO] 2021-07-12 18:23:43,387 [run_pretraining.py:  558]:	worker_index: 3, step: 177, cost: 9.942171, mlm loss: 9.942171, speed: 1.048226 steps/s, speed: 8.385809 samples/s, speed: 4293.534329 tokens/s, learning rate: 1.760e-06, loss_scalings: 26214.400391, pp_loss: 9.878326
[INFO] 2021-07-12 18:23:43,387 [run_pretraining.py:  512]:	********exe.run_177******* 
[INFO] 2021-07-12 18:23:44,369 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:23:44,370 [run_pretraining.py:  534]:	loss/total_loss, 9.956771850585938, 178
[INFO] 2021-07-12 18:23:44,370 [run_pretraining.py:  535]:	loss/mlm_loss, 9.956771850585938, 178
[INFO] 2021-07-12 18:23:44,370 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7699999261822086e-06, 178
[INFO] 2021-07-12 18:23:44,370 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 178
[INFO] 2021-07-12 18:23:44,370 [run_pretraining.py:  558]:	worker_index: 3, step: 178, cost: 9.956772, mlm loss: 9.956772, speed: 1.017946 steps/s, speed: 8.143566 samples/s, speed: 4169.505823 tokens/s, learning rate: 1.770e-06, loss_scalings: 26214.400391, pp_loss: 9.898182
[INFO] 2021-07-12 18:23:44,370 [run_pretraining.py:  512]:	********exe.run_178******* 
[INFO] 2021-07-12 18:23:45,427 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:23:45,427 [run_pretraining.py:  534]:	loss/total_loss, 7.919591426849365, 179
[INFO] 2021-07-12 18:23:45,428 [run_pretraining.py:  535]:	loss/mlm_loss, 7.919591426849365, 179
[INFO] 2021-07-12 18:23:45,428 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7799999341150397e-06, 179
[INFO] 2021-07-12 18:23:45,428 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 179
[INFO] 2021-07-12 18:23:45,428 [run_pretraining.py:  558]:	worker_index: 3, step: 179, cost: 7.919591, mlm loss: 7.919591, speed: 0.945839 steps/s, speed: 7.566715 samples/s, speed: 3874.158172 tokens/s, learning rate: 1.780e-06, loss_scalings: 26214.400391, pp_loss: 9.133593
[INFO] 2021-07-12 18:23:45,428 [run_pretraining.py:  512]:	********exe.run_179******* 
[INFO] 2021-07-12 18:23:46,489 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:23:46,489 [run_pretraining.py:  534]:	loss/total_loss, 9.905025482177734, 180
[INFO] 2021-07-12 18:23:46,489 [run_pretraining.py:  535]:	loss/mlm_loss, 9.905025482177734, 180
[INFO] 2021-07-12 18:23:46,489 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7899999420478707e-06, 180
[INFO] 2021-07-12 18:23:46,490 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 180
[INFO] 2021-07-12 18:23:46,490 [run_pretraining.py:  558]:	worker_index: 3, step: 180, cost: 9.905025, mlm loss: 9.905025, speed: 0.942325 steps/s, speed: 7.538597 samples/s, speed: 3859.761786 tokens/s, learning rate: 1.790e-06, loss_scalings: 26214.400391, pp_loss: 9.968632
[INFO] 2021-07-12 18:23:46,490 [run_pretraining.py:  512]:	********exe.run_180******* 
[INFO] 2021-07-12 18:24:11,805 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:24:11,806 [run_pretraining.py:  534]:	loss/total_loss, 9.860758781433105, 181
[INFO] 2021-07-12 18:24:11,806 [run_pretraining.py:  535]:	loss/mlm_loss, 9.860758781433105, 181
[INFO] 2021-07-12 18:24:11,806 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.799999836293864e-06, 181
[INFO] 2021-07-12 18:24:11,806 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 181
[INFO] 2021-07-12 18:24:11,806 [run_pretraining.py:  558]:	worker_index: 3, step: 181, cost: 9.860759, mlm loss: 9.860759, speed: 0.039501 steps/s, speed: 0.316009 samples/s, speed: 161.796814 tokens/s, learning rate: 1.800e-06, loss_scalings: 26214.400391, pp_loss: 8.841879
[INFO] 2021-07-12 18:24:11,806 [run_pretraining.py:  512]:	********exe.run_181******* 
[INFO] 2021-07-12 18:24:12,842 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:24:12,843 [run_pretraining.py:  534]:	loss/total_loss, 9.909408569335938, 182
[INFO] 2021-07-12 18:24:12,843 [run_pretraining.py:  535]:	loss/mlm_loss, 9.909408569335938, 182
[INFO] 2021-07-12 18:24:12,843 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8100000716003706e-06, 182
[INFO] 2021-07-12 18:24:12,843 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 182
[INFO] 2021-07-12 18:24:12,843 [run_pretraining.py:  558]:	worker_index: 3, step: 182, cost: 9.909409, mlm loss: 9.909409, speed: 0.964529 steps/s, speed: 7.716229 samples/s, speed: 3950.709393 tokens/s, learning rate: 1.810e-06, loss_scalings: 26214.400391, pp_loss: 9.963450
[INFO] 2021-07-12 18:24:12,843 [run_pretraining.py:  512]:	********exe.run_182******* 
[INFO] 2021-07-12 18:24:13,896 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:24:13,897 [run_pretraining.py:  534]:	loss/total_loss, 9.888123512268066, 183
[INFO] 2021-07-12 18:24:13,897 [run_pretraining.py:  535]:	loss/mlm_loss, 9.888123512268066, 183
[INFO] 2021-07-12 18:24:13,897 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8200000795332016e-06, 183
[INFO] 2021-07-12 18:24:13,897 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 183
[INFO] 2021-07-12 18:24:13,897 [run_pretraining.py:  558]:	worker_index: 3, step: 183, cost: 9.888124, mlm loss: 9.888124, speed: 0.949696 steps/s, speed: 7.597565 samples/s, speed: 3889.953154 tokens/s, learning rate: 1.820e-06, loss_scalings: 26214.400391, pp_loss: 9.926990
[INFO] 2021-07-12 18:24:13,897 [run_pretraining.py:  512]:	********exe.run_183******* 
[INFO] 2021-07-12 18:24:39,789 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:24:39,790 [run_pretraining.py:  534]:	loss/total_loss, 10.122504234313965, 184
[INFO] 2021-07-12 18:24:39,790 [run_pretraining.py:  535]:	loss/mlm_loss, 10.122504234313965, 184
[INFO] 2021-07-12 18:24:39,790 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.829999973779195e-06, 184
[INFO] 2021-07-12 18:24:39,790 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 184
[INFO] 2021-07-12 18:24:39,790 [run_pretraining.py:  558]:	worker_index: 3, step: 184, cost: 10.122504, mlm loss: 10.122504, speed: 0.038621 steps/s, speed: 0.308972 samples/s, speed: 158.193659 tokens/s, learning rate: 1.830e-06, loss_scalings: 26214.400391, pp_loss: 9.984968
[INFO] 2021-07-12 18:24:39,790 [run_pretraining.py:  512]:	********exe.run_184******* 
[INFO] 2021-07-12 18:24:40,769 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:24:40,770 [run_pretraining.py:  534]:	loss/total_loss, 9.82607650756836, 185
[INFO] 2021-07-12 18:24:40,770 [run_pretraining.py:  535]:	loss/mlm_loss, 9.82607650756836, 185
[INFO] 2021-07-12 18:24:40,770 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.839999981712026e-06, 185
[INFO] 2021-07-12 18:24:40,770 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 185
[INFO] 2021-07-12 18:24:40,770 [run_pretraining.py:  558]:	worker_index: 3, step: 185, cost: 9.826077, mlm loss: 9.826077, speed: 1.020770 steps/s, speed: 8.166162 samples/s, speed: 4181.074818 tokens/s, learning rate: 1.840e-06, loss_scalings: 26214.400391, pp_loss: 9.993017
[INFO] 2021-07-12 18:24:40,770 [run_pretraining.py:  512]:	********exe.run_185******* 
[INFO] 2021-07-12 18:24:41,725 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:24:41,726 [run_pretraining.py:  534]:	loss/total_loss, 9.687609672546387, 186
[INFO] 2021-07-12 18:24:41,726 [run_pretraining.py:  535]:	loss/mlm_loss, 9.687609672546387, 186
[INFO] 2021-07-12 18:24:41,726 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8499999896448571e-06, 186
[INFO] 2021-07-12 18:24:41,726 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 186
[INFO] 2021-07-12 18:24:41,726 [run_pretraining.py:  558]:	worker_index: 3, step: 186, cost: 9.687610, mlm loss: 9.687610, speed: 1.046956 steps/s, speed: 8.375645 samples/s, speed: 4288.330033 tokens/s, learning rate: 1.850e-06, loss_scalings: 26214.400391, pp_loss: 9.830288
[INFO] 2021-07-12 18:24:41,726 [run_pretraining.py:  512]:	********exe.run_186******* 
[INFO] 2021-07-12 18:24:42,679 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:24:42,679 [run_pretraining.py:  534]:	loss/total_loss, 10.0896577835083, 187
[INFO] 2021-07-12 18:24:42,680 [run_pretraining.py:  535]:	loss/mlm_loss, 10.0896577835083, 187
[INFO] 2021-07-12 18:24:42,680 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8599999975776882e-06, 187
[INFO] 2021-07-12 18:24:42,680 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 187
[INFO] 2021-07-12 18:24:42,680 [run_pretraining.py:  558]:	worker_index: 3, step: 187, cost: 10.089658, mlm loss: 10.089658, speed: 1.049246 steps/s, speed: 8.393970 samples/s, speed: 4297.712460 tokens/s, learning rate: 1.860e-06, loss_scalings: 26214.400391, pp_loss: 9.983945
[INFO] 2021-07-12 18:24:42,680 [run_pretraining.py:  512]:	********exe.run_187******* 
[INFO] 2021-07-12 18:25:06,940 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:25:06,941 [run_pretraining.py:  534]:	loss/total_loss, 9.864259719848633, 188
[INFO] 2021-07-12 18:25:06,941 [run_pretraining.py:  535]:	loss/mlm_loss, 9.864259719848633, 188
[INFO] 2021-07-12 18:25:06,941 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8699998918236815e-06, 188
[INFO] 2021-07-12 18:25:06,941 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 188
[INFO] 2021-07-12 18:25:06,941 [run_pretraining.py:  558]:	worker_index: 3, step: 188, cost: 9.864260, mlm loss: 9.864260, speed: 0.041219 steps/s, speed: 0.329755 samples/s, speed: 168.834669 tokens/s, learning rate: 1.870e-06, loss_scalings: 26214.400391, pp_loss: 9.910070
[INFO] 2021-07-12 18:25:06,941 [run_pretraining.py:  512]:	********exe.run_188******* 
[INFO] 2021-07-12 18:25:07,894 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:25:07,894 [run_pretraining.py:  534]:	loss/total_loss, 9.988500595092773, 189
[INFO] 2021-07-12 18:25:07,894 [run_pretraining.py:  535]:	loss/mlm_loss, 9.988500595092773, 189
[INFO] 2021-07-12 18:25:07,895 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8799998997565126e-06, 189
[INFO] 2021-07-12 18:25:07,895 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 189
[INFO] 2021-07-12 18:25:07,895 [run_pretraining.py:  558]:	worker_index: 3, step: 189, cost: 9.988501, mlm loss: 9.988501, speed: 1.049139 steps/s, speed: 8.393115 samples/s, speed: 4297.274933 tokens/s, learning rate: 1.880e-06, loss_scalings: 26214.400391, pp_loss: 9.914494
[INFO] 2021-07-12 18:25:07,895 [run_pretraining.py:  512]:	********exe.run_189******* 
[INFO] 2021-07-12 18:25:30,890 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:25:30,891 [run_pretraining.py:  534]:	loss/total_loss, 9.736677169799805, 190
[INFO] 2021-07-12 18:25:30,891 [run_pretraining.py:  535]:	loss/mlm_loss, 9.736677169799805, 190
[INFO] 2021-07-12 18:25:30,891 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8899999076893437e-06, 190
[INFO] 2021-07-12 18:25:30,891 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 190
[INFO] 2021-07-12 18:25:30,891 [run_pretraining.py:  558]:	worker_index: 3, step: 190, cost: 9.736677, mlm loss: 9.736677, speed: 0.043487 steps/s, speed: 0.347894 samples/s, speed: 178.121669 tokens/s, learning rate: 1.890e-06, loss_scalings: 26214.400391, pp_loss: 9.872022
[INFO] 2021-07-12 18:25:30,891 [run_pretraining.py:  512]:	********exe.run_190******* 
[INFO] 2021-07-12 18:25:31,869 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:25:31,869 [run_pretraining.py:  534]:	loss/total_loss, 10.119304656982422, 191
[INFO] 2021-07-12 18:25:31,870 [run_pretraining.py:  535]:	loss/mlm_loss, 10.119304656982422, 191
[INFO] 2021-07-12 18:25:31,870 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8999999156221747e-06, 191
[INFO] 2021-07-12 18:25:31,870 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 191
[INFO] 2021-07-12 18:25:31,870 [run_pretraining.py:  558]:	worker_index: 3, step: 191, cost: 10.119305, mlm loss: 10.119305, speed: 1.022247 steps/s, speed: 8.177972 samples/s, speed: 4187.121696 tokens/s, learning rate: 1.900e-06, loss_scalings: 26214.400391, pp_loss: 9.869244
[INFO] 2021-07-12 18:25:31,870 [run_pretraining.py:  512]:	********exe.run_191******* 
[INFO] 2021-07-12 18:25:32,823 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:25:32,824 [run_pretraining.py:  534]:	loss/total_loss, 9.995551109313965, 192
[INFO] 2021-07-12 18:25:32,824 [run_pretraining.py:  535]:	loss/mlm_loss, 9.995551109313965, 192
[INFO] 2021-07-12 18:25:32,824 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.909999809868168e-06, 192
[INFO] 2021-07-12 18:25:32,824 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 192
[INFO] 2021-07-12 18:25:32,824 [run_pretraining.py:  558]:	worker_index: 3, step: 192, cost: 9.995551, mlm loss: 9.995551, speed: 1.048849 steps/s, speed: 8.390796 samples/s, speed: 4296.087501 tokens/s, learning rate: 1.910e-06, loss_scalings: 26214.400391, pp_loss: 9.853308
[INFO] 2021-07-12 18:25:32,824 [run_pretraining.py:  512]:	********exe.run_192******* 
[INFO] 2021-07-12 18:25:58,169 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:25:58,169 [run_pretraining.py:  534]:	loss/total_loss, 9.9162015914917, 193
[INFO] 2021-07-12 18:25:58,169 [run_pretraining.py:  535]:	loss/mlm_loss, 9.9162015914917, 193
[INFO] 2021-07-12 18:25:58,170 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.919999931487837e-06, 193
[INFO] 2021-07-12 18:25:58,170 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 193
[INFO] 2021-07-12 18:25:58,170 [run_pretraining.py:  558]:	worker_index: 3, step: 193, cost: 9.916202, mlm loss: 9.916202, speed: 0.039455 steps/s, speed: 0.315643 samples/s, speed: 161.609134 tokens/s, learning rate: 1.920e-06, loss_scalings: 26214.400391, pp_loss: 9.878983
[INFO] 2021-07-12 18:25:58,170 [run_pretraining.py:  512]:	********exe.run_193******* 
[INFO] 2021-07-12 18:26:21,185 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:26:21,186 [run_pretraining.py:  534]:	loss/total_loss, 9.752551078796387, 194
[INFO] 2021-07-12 18:26:21,186 [run_pretraining.py:  535]:	loss/mlm_loss, 9.752551078796387, 194
[INFO] 2021-07-12 18:26:21,186 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9300000531075057e-06, 194
[INFO] 2021-07-12 18:26:21,186 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 194
[INFO] 2021-07-12 18:26:21,186 [run_pretraining.py:  558]:	worker_index: 3, step: 194, cost: 9.752551, mlm loss: 9.752551, speed: 0.043449 steps/s, speed: 0.347591 samples/s, speed: 177.966627 tokens/s, learning rate: 1.930e-06, loss_scalings: 26214.400391, pp_loss: 9.892275
[INFO] 2021-07-12 18:26:21,186 [run_pretraining.py:  512]:	********exe.run_194******* 
[INFO] 2021-07-12 18:26:22,149 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:26:22,149 [run_pretraining.py:  534]:	loss/total_loss, 9.795321464538574, 195
[INFO] 2021-07-12 18:26:22,149 [run_pretraining.py:  535]:	loss/mlm_loss, 9.795321464538574, 195
[INFO] 2021-07-12 18:26:22,149 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.939999947353499e-06, 195
[INFO] 2021-07-12 18:26:22,149 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 195
[INFO] 2021-07-12 18:26:22,150 [run_pretraining.py:  558]:	worker_index: 3, step: 195, cost: 9.795321, mlm loss: 9.795321, speed: 1.038429 steps/s, speed: 8.307434 samples/s, speed: 4253.406201 tokens/s, learning rate: 1.940e-06, loss_scalings: 26214.400391, pp_loss: 9.894298
[INFO] 2021-07-12 18:26:22,150 [run_pretraining.py:  512]:	********exe.run_195******* 
[INFO] 2021-07-12 18:26:23,099 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:26:23,100 [run_pretraining.py:  534]:	loss/total_loss, 10.00794792175293, 196
[INFO] 2021-07-12 18:26:23,100 [run_pretraining.py:  535]:	loss/mlm_loss, 10.00794792175293, 196
[INFO] 2021-07-12 18:26:23,100 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.950000068973168e-06, 196
[INFO] 2021-07-12 18:26:23,100 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 196
[INFO] 2021-07-12 18:26:23,100 [run_pretraining.py:  558]:	worker_index: 3, step: 196, cost: 10.007948, mlm loss: 10.007948, speed: 1.052918 steps/s, speed: 8.423348 samples/s, speed: 4312.754172 tokens/s, learning rate: 1.950e-06, loss_scalings: 26214.400391, pp_loss: 9.917572
[INFO] 2021-07-12 18:26:23,100 [run_pretraining.py:  512]:	********exe.run_196******* 
[INFO] 2021-07-12 18:26:24,066 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:26:24,066 [run_pretraining.py:  534]:	loss/total_loss, 9.750041961669922, 197
[INFO] 2021-07-12 18:26:24,066 [run_pretraining.py:  535]:	loss/mlm_loss, 9.750041961669922, 197
[INFO] 2021-07-12 18:26:24,066 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.959999963219161e-06, 197
[INFO] 2021-07-12 18:26:24,066 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 197
[INFO] 2021-07-12 18:26:24,067 [run_pretraining.py:  558]:	worker_index: 3, step: 197, cost: 9.750042, mlm loss: 9.750042, speed: 1.035223 steps/s, speed: 8.281787 samples/s, speed: 4240.275167 tokens/s, learning rate: 1.960e-06, loss_scalings: 26214.400391, pp_loss: 9.829541
[INFO] 2021-07-12 18:26:24,067 [run_pretraining.py:  512]:	********exe.run_197******* 
[INFO] 2021-07-12 18:26:25,025 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:26:25,026 [run_pretraining.py:  534]:	loss/total_loss, 9.97291374206543, 198
[INFO] 2021-07-12 18:26:25,026 [run_pretraining.py:  535]:	loss/mlm_loss, 9.97291374206543, 198
[INFO] 2021-07-12 18:26:25,026 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9699998574651545e-06, 198
[INFO] 2021-07-12 18:26:25,026 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 198
[INFO] 2021-07-12 18:26:25,026 [run_pretraining.py:  558]:	worker_index: 3, step: 198, cost: 9.972914, mlm loss: 9.972914, speed: 1.042821 steps/s, speed: 8.342565 samples/s, speed: 4271.393475 tokens/s, learning rate: 1.970e-06, loss_scalings: 26214.400391, pp_loss: 9.836259
[INFO] 2021-07-12 18:26:25,026 [run_pretraining.py:  512]:	********exe.run_198******* 
[INFO] 2021-07-12 18:27:15,714 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:27:15,714 [run_pretraining.py:  534]:	loss/total_loss, 10.070290565490723, 199
[INFO] 2021-07-12 18:27:15,715 [run_pretraining.py:  535]:	loss/mlm_loss, 10.070290565490723, 199
[INFO] 2021-07-12 18:27:15,715 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9799999790848233e-06, 199
[INFO] 2021-07-12 18:27:15,715 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 199
[INFO] 2021-07-12 18:27:15,715 [run_pretraining.py:  558]:	worker_index: 3, step: 199, cost: 10.070291, mlm loss: 10.070291, speed: 0.019729 steps/s, speed: 0.157828 samples/s, speed: 80.808170 tokens/s, learning rate: 1.980e-06, loss_scalings: 26214.400391, pp_loss: 9.904854
[INFO] 2021-07-12 18:27:15,715 [run_pretraining.py:  512]:	********exe.run_199******* 
[INFO] 2021-07-12 18:27:40,973 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:27:40,973 [run_pretraining.py:  534]:	loss/total_loss, 9.765536308288574, 200
[INFO] 2021-07-12 18:27:40,973 [run_pretraining.py:  535]:	loss/mlm_loss, 9.765536308288574, 200
[INFO] 2021-07-12 18:27:40,974 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9899998733308166e-06, 200
[INFO] 2021-07-12 18:27:40,974 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 200
[INFO] 2021-07-12 18:27:40,974 [run_pretraining.py:  558]:	worker_index: 3, step: 200, cost: 9.765536, mlm loss: 9.765536, speed: 0.039591 steps/s, speed: 0.316728 samples/s, speed: 162.164825 tokens/s, learning rate: 1.990e-06, loss_scalings: 26214.400391, pp_loss: 9.854988
[INFO] 2021-07-12 18:27:40,974 [run_pretraining.py:  512]:	********exe.run_200******* 
[INFO] 2021-07-12 18:28:05,996 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:05,997 [run_pretraining.py:  534]:	loss/total_loss, 9.877291679382324, 201
[INFO] 2021-07-12 18:28:05,997 [run_pretraining.py:  535]:	loss/mlm_loss, 9.877291679382324, 201
[INFO] 2021-07-12 18:28:05,997 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9999999949504854e-06, 201
[INFO] 2021-07-12 18:28:05,997 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 201
[INFO] 2021-07-12 18:28:05,997 [run_pretraining.py:  558]:	worker_index: 3, step: 201, cost: 9.877292, mlm loss: 9.877292, speed: 0.039963 steps/s, speed: 0.319707 samples/s, speed: 163.690045 tokens/s, learning rate: 2.000e-06, loss_scalings: 26214.400391, pp_loss: 9.799344
[INFO] 2021-07-12 18:28:05,997 [run_pretraining.py:  512]:	********exe.run_201******* 
[INFO] 2021-07-12 18:28:06,931 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:06,932 [run_pretraining.py:  534]:	loss/total_loss, 9.975675582885742, 202
[INFO] 2021-07-12 18:28:06,932 [run_pretraining.py:  535]:	loss/mlm_loss, 9.975675582885742, 202
[INFO] 2021-07-12 18:28:06,932 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0099998891964788e-06, 202
[INFO] 2021-07-12 18:28:06,932 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 202
[INFO] 2021-07-12 18:28:06,932 [run_pretraining.py:  558]:	worker_index: 3, step: 202, cost: 9.975676, mlm loss: 9.975676, speed: 1.070246 steps/s, speed: 8.561971 samples/s, speed: 4383.729042 tokens/s, learning rate: 2.010e-06, loss_scalings: 26214.400391, pp_loss: 9.968204
[INFO] 2021-07-12 18:28:06,932 [run_pretraining.py:  512]:	********exe.run_202******* 
[INFO] 2021-07-12 18:28:07,943 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:07,943 [run_pretraining.py:  534]:	loss/total_loss, 9.90176010131836, 203
[INFO] 2021-07-12 18:28:07,943 [run_pretraining.py:  535]:	loss/mlm_loss, 9.90176010131836, 203
[INFO] 2021-07-12 18:28:07,944 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.019999783442472e-06, 203
[INFO] 2021-07-12 18:28:07,944 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 203
[INFO] 2021-07-12 18:28:07,944 [run_pretraining.py:  558]:	worker_index: 3, step: 203, cost: 9.901760, mlm loss: 9.901760, speed: 0.989358 steps/s, speed: 7.914862 samples/s, speed: 4052.409323 tokens/s, learning rate: 2.020e-06, loss_scalings: 26214.400391, pp_loss: 9.920001
[INFO] 2021-07-12 18:28:07,944 [run_pretraining.py:  512]:	********exe.run_203******* 
[INFO] 2021-07-12 18:28:08,864 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:08,864 [run_pretraining.py:  534]:	loss/total_loss, 9.858731269836426, 204
[INFO] 2021-07-12 18:28:08,864 [run_pretraining.py:  535]:	loss/mlm_loss, 9.858731269836426, 204
[INFO] 2021-07-12 18:28:08,865 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0300001324358163e-06, 204
[INFO] 2021-07-12 18:28:08,865 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 204
[INFO] 2021-07-12 18:28:08,865 [run_pretraining.py:  558]:	worker_index: 3, step: 204, cost: 9.858731, mlm loss: 9.858731, speed: 1.086584 steps/s, speed: 8.692676 samples/s, speed: 4450.649917 tokens/s, learning rate: 2.030e-06, loss_scalings: 26214.400391, pp_loss: 9.798040
[INFO] 2021-07-12 18:28:08,865 [run_pretraining.py:  512]:	********exe.run_204******* 
[INFO] 2021-07-12 18:28:09,772 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:09,772 [run_pretraining.py:  534]:	loss/total_loss, 9.863329887390137, 205
[INFO] 2021-07-12 18:28:09,772 [run_pretraining.py:  535]:	loss/mlm_loss, 9.863329887390137, 205
[INFO] 2021-07-12 18:28:09,772 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0400000266818097e-06, 205
[INFO] 2021-07-12 18:28:09,772 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 205
[INFO] 2021-07-12 18:28:09,772 [run_pretraining.py:  558]:	worker_index: 3, step: 205, cost: 9.863330, mlm loss: 9.863330, speed: 1.102336 steps/s, speed: 8.818689 samples/s, speed: 4515.168686 tokens/s, learning rate: 2.040e-06, loss_scalings: 26214.400391, pp_loss: 9.161149
[INFO] 2021-07-12 18:28:09,773 [run_pretraining.py:  512]:	********exe.run_205******* 
[INFO] 2021-07-12 18:28:10,688 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:10,689 [run_pretraining.py:  534]:	loss/total_loss, 9.7358980178833, 206
[INFO] 2021-07-12 18:28:10,689 [run_pretraining.py:  535]:	loss/mlm_loss, 9.7358980178833, 206
[INFO] 2021-07-12 18:28:10,689 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.049999920927803e-06, 206
[INFO] 2021-07-12 18:28:10,689 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 206
[INFO] 2021-07-12 18:28:10,689 [run_pretraining.py:  558]:	worker_index: 3, step: 206, cost: 9.735898, mlm loss: 9.735898, speed: 1.091496 steps/s, speed: 8.731964 samples/s, speed: 4470.765624 tokens/s, learning rate: 2.050e-06, loss_scalings: 26214.400391, pp_loss: 9.788119
[INFO] 2021-07-12 18:28:10,689 [run_pretraining.py:  512]:	********exe.run_206******* 
[INFO] 2021-07-12 18:28:11,593 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:11,593 [run_pretraining.py:  534]:	loss/total_loss, 9.78247356414795, 207
[INFO] 2021-07-12 18:28:11,593 [run_pretraining.py:  535]:	loss/mlm_loss, 9.78247356414795, 207
[INFO] 2021-07-12 18:28:11,593 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.060000042547472e-06, 207
[INFO] 2021-07-12 18:28:11,593 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 207
[INFO] 2021-07-12 18:28:11,593 [run_pretraining.py:  558]:	worker_index: 3, step: 207, cost: 9.782474, mlm loss: 9.782474, speed: 1.106842 steps/s, speed: 8.854732 samples/s, speed: 4533.622871 tokens/s, learning rate: 2.060e-06, loss_scalings: 26214.400391, pp_loss: 9.775372
[INFO] 2021-07-12 18:28:11,593 [run_pretraining.py:  512]:	********exe.run_207******* 
[INFO] 2021-07-12 18:28:12,504 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:12,504 [run_pretraining.py:  534]:	loss/total_loss, 10.017156600952148, 208
[INFO] 2021-07-12 18:28:12,504 [run_pretraining.py:  535]:	loss/mlm_loss, 10.017156600952148, 208
[INFO] 2021-07-12 18:28:12,504 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.069999936793465e-06, 208
[INFO] 2021-07-12 18:28:12,504 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 208
[INFO] 2021-07-12 18:28:12,505 [run_pretraining.py:  558]:	worker_index: 3, step: 208, cost: 10.017157, mlm loss: 10.017157, speed: 1.098237 steps/s, speed: 8.785895 samples/s, speed: 4498.378342 tokens/s, learning rate: 2.070e-06, loss_scalings: 26214.400391, pp_loss: 8.941967
[INFO] 2021-07-12 18:28:12,505 [run_pretraining.py:  512]:	********exe.run_208******* 
[INFO] 2021-07-12 18:28:13,451 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:13,452 [run_pretraining.py:  534]:	loss/total_loss, 9.776983261108398, 209
[INFO] 2021-07-12 18:28:13,452 [run_pretraining.py:  535]:	loss/mlm_loss, 9.776983261108398, 209
[INFO] 2021-07-12 18:28:13,452 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.080000058413134e-06, 209
[INFO] 2021-07-12 18:28:13,452 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 209
[INFO] 2021-07-12 18:28:13,452 [run_pretraining.py:  558]:	worker_index: 3, step: 209, cost: 9.776983, mlm loss: 9.776983, speed: 1.056248 steps/s, speed: 8.449980 samples/s, speed: 4326.389866 tokens/s, learning rate: 2.080e-06, loss_scalings: 26214.400391, pp_loss: 9.787113
[INFO] 2021-07-12 18:28:13,452 [run_pretraining.py:  512]:	********exe.run_209******* 
[INFO] 2021-07-12 18:28:14,354 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:14,355 [run_pretraining.py:  534]:	loss/total_loss, 10.272701263427734, 210
[INFO] 2021-07-12 18:28:14,355 [run_pretraining.py:  535]:	loss/mlm_loss, 10.272701263427734, 210
[INFO] 2021-07-12 18:28:14,355 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0899999526591273e-06, 210
[INFO] 2021-07-12 18:28:14,355 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 210
[INFO] 2021-07-12 18:28:14,355 [run_pretraining.py:  558]:	worker_index: 3, step: 210, cost: 10.272701, mlm loss: 10.272701, speed: 1.107998 steps/s, speed: 8.863983 samples/s, speed: 4538.359517 tokens/s, learning rate: 2.090e-06, loss_scalings: 26214.400391, pp_loss: 9.991776
[INFO] 2021-07-12 18:28:14,355 [run_pretraining.py:  512]:	********exe.run_210******* 
[INFO] 2021-07-12 18:28:15,267 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:15,267 [run_pretraining.py:  534]:	loss/total_loss, 9.743244171142578, 211
[INFO] 2021-07-12 18:28:15,267 [run_pretraining.py:  535]:	loss/mlm_loss, 9.743244171142578, 211
[INFO] 2021-07-12 18:28:15,267 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0999998469051206e-06, 211
[INFO] 2021-07-12 18:28:15,267 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 211
[INFO] 2021-07-12 18:28:15,267 [run_pretraining.py:  558]:	worker_index: 3, step: 211, cost: 9.743244, mlm loss: 9.743244, speed: 1.096962 steps/s, speed: 8.775693 samples/s, speed: 4493.154735 tokens/s, learning rate: 2.100e-06, loss_scalings: 26214.400391, pp_loss: 9.802157
[INFO] 2021-07-12 18:28:15,267 [run_pretraining.py:  512]:	********exe.run_211******* 
[INFO] 2021-07-12 18:28:16,174 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:16,175 [run_pretraining.py:  534]:	loss/total_loss, 9.717639923095703, 212
[INFO] 2021-07-12 18:28:16,175 [run_pretraining.py:  535]:	loss/mlm_loss, 9.717639923095703, 212
[INFO] 2021-07-12 18:28:16,175 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1099999685247894e-06, 212
[INFO] 2021-07-12 18:28:16,175 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 212
[INFO] 2021-07-12 18:28:16,175 [run_pretraining.py:  558]:	worker_index: 3, step: 212, cost: 9.717640, mlm loss: 9.717640, speed: 1.102346 steps/s, speed: 8.818770 samples/s, speed: 4515.210220 tokens/s, learning rate: 2.110e-06, loss_scalings: 26214.400391, pp_loss: 9.747342
[INFO] 2021-07-12 18:28:16,175 [run_pretraining.py:  512]:	********exe.run_212******* 
[INFO] 2021-07-12 18:28:17,086 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:17,086 [run_pretraining.py:  534]:	loss/total_loss, 9.781415939331055, 213
[INFO] 2021-07-12 18:28:17,086 [run_pretraining.py:  535]:	loss/mlm_loss, 9.781415939331055, 213
[INFO] 2021-07-12 18:28:17,086 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1199998627707828e-06, 213
[INFO] 2021-07-12 18:28:17,086 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 213
[INFO] 2021-07-12 18:28:17,086 [run_pretraining.py:  558]:	worker_index: 3, step: 213, cost: 9.781416, mlm loss: 9.781416, speed: 1.098188 steps/s, speed: 8.785506 samples/s, speed: 4498.179293 tokens/s, learning rate: 2.120e-06, loss_scalings: 26214.400391, pp_loss: 9.691072
[INFO] 2021-07-12 18:28:17,086 [run_pretraining.py:  512]:	********exe.run_213******* 
[INFO] 2021-07-12 18:28:17,997 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:17,998 [run_pretraining.py:  534]:	loss/total_loss, 10.12874984741211, 214
[INFO] 2021-07-12 18:28:17,998 [run_pretraining.py:  535]:	loss/mlm_loss, 10.12874984741211, 214
[INFO] 2021-07-12 18:28:17,998 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.129999757016776e-06, 214
[INFO] 2021-07-12 18:28:17,998 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 214
[INFO] 2021-07-12 18:28:17,998 [run_pretraining.py:  558]:	worker_index: 3, step: 214, cost: 10.128750, mlm loss: 10.128750, speed: 1.097625 steps/s, speed: 8.781002 samples/s, speed: 4495.873260 tokens/s, learning rate: 2.130e-06, loss_scalings: 26214.400391, pp_loss: 9.854390
[INFO] 2021-07-12 18:28:17,998 [run_pretraining.py:  512]:	********exe.run_214******* 
[INFO] 2021-07-12 18:28:18,908 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:18,909 [run_pretraining.py:  534]:	loss/total_loss, 9.564136505126953, 215
[INFO] 2021-07-12 18:28:18,909 [run_pretraining.py:  535]:	loss/mlm_loss, 9.564136505126953, 215
[INFO] 2021-07-12 18:28:18,909 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1400001060101204e-06, 215
[INFO] 2021-07-12 18:28:18,909 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 215
[INFO] 2021-07-12 18:28:18,909 [run_pretraining.py:  558]:	worker_index: 3, step: 215, cost: 9.564137, mlm loss: 9.564137, speed: 1.098175 steps/s, speed: 8.785401 samples/s, speed: 4498.125117 tokens/s, learning rate: 2.140e-06, loss_scalings: 26214.400391, pp_loss: 9.711335
[INFO] 2021-07-12 18:28:18,909 [run_pretraining.py:  512]:	********exe.run_215******* 
[INFO] 2021-07-12 18:28:19,819 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:19,820 [run_pretraining.py:  534]:	loss/total_loss, 9.706109046936035, 216
[INFO] 2021-07-12 18:28:19,820 [run_pretraining.py:  535]:	loss/mlm_loss, 9.706109046936035, 216
[INFO] 2021-07-12 18:28:19,820 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1500000002561137e-06, 216
[INFO] 2021-07-12 18:28:19,820 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 216
[INFO] 2021-07-12 18:28:19,820 [run_pretraining.py:  558]:	worker_index: 3, step: 216, cost: 9.706109, mlm loss: 9.706109, speed: 1.098952 steps/s, speed: 8.791613 samples/s, speed: 4501.306040 tokens/s, learning rate: 2.150e-06, loss_scalings: 26214.400391, pp_loss: 9.795489
[INFO] 2021-07-12 18:28:19,820 [run_pretraining.py:  512]:	********exe.run_216******* 
[INFO] 2021-07-12 18:28:20,725 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:20,726 [run_pretraining.py:  534]:	loss/total_loss, 9.701624870300293, 217
[INFO] 2021-07-12 18:28:20,726 [run_pretraining.py:  535]:	loss/mlm_loss, 9.701624870300293, 217
[INFO] 2021-07-12 18:28:20,726 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.159999894502107e-06, 217
[INFO] 2021-07-12 18:28:20,726 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 217
[INFO] 2021-07-12 18:28:20,726 [run_pretraining.py:  558]:	worker_index: 3, step: 217, cost: 9.701625, mlm loss: 9.701625, speed: 1.104412 steps/s, speed: 8.835294 samples/s, speed: 4523.670506 tokens/s, learning rate: 2.160e-06, loss_scalings: 26214.400391, pp_loss: 9.744441
[INFO] 2021-07-12 18:28:20,726 [run_pretraining.py:  512]:	********exe.run_217******* 
[INFO] 2021-07-12 18:28:46,555 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:46,555 [run_pretraining.py:  534]:	loss/total_loss, 9.705979347229004, 218
[INFO] 2021-07-12 18:28:46,555 [run_pretraining.py:  535]:	loss/mlm_loss, 9.705979347229004, 218
[INFO] 2021-07-12 18:28:46,555 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.170000016121776e-06, 218
[INFO] 2021-07-12 18:28:46,555 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 218
[INFO] 2021-07-12 18:28:46,555 [run_pretraining.py:  558]:	worker_index: 3, step: 218, cost: 9.705979, mlm loss: 9.705979, speed: 0.038717 steps/s, speed: 0.309732 samples/s, speed: 158.583010 tokens/s, learning rate: 2.170e-06, loss_scalings: 26214.400391, pp_loss: 9.788433
[INFO] 2021-07-12 18:28:46,556 [run_pretraining.py:  512]:	********exe.run_218******* 
[INFO] 2021-07-12 18:28:47,461 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:47,461 [run_pretraining.py:  534]:	loss/total_loss, 9.950185775756836, 219
[INFO] 2021-07-12 18:28:47,461 [run_pretraining.py:  535]:	loss/mlm_loss, 9.950185775756836, 219
[INFO] 2021-07-12 18:28:47,461 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.179999910367769e-06, 219
[INFO] 2021-07-12 18:28:47,462 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 219
[INFO] 2021-07-12 18:28:47,462 [run_pretraining.py:  558]:	worker_index: 3, step: 219, cost: 9.950186, mlm loss: 9.950186, speed: 1.104317 steps/s, speed: 8.834536 samples/s, speed: 4523.282228 tokens/s, learning rate: 2.180e-06, loss_scalings: 26214.400391, pp_loss: 9.746954
[INFO] 2021-07-12 18:28:47,462 [run_pretraining.py:  512]:	********exe.run_219******* 
[INFO] 2021-07-12 18:28:48,368 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:48,369 [run_pretraining.py:  534]:	loss/total_loss, 9.799413681030273, 220
[INFO] 2021-07-12 18:28:48,369 [run_pretraining.py:  535]:	loss/mlm_loss, 9.799413681030273, 220
[INFO] 2021-07-12 18:28:48,369 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.190000031987438e-06, 220
[INFO] 2021-07-12 18:28:48,369 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 220
[INFO] 2021-07-12 18:28:48,369 [run_pretraining.py:  558]:	worker_index: 3, step: 220, cost: 9.799414, mlm loss: 9.799414, speed: 1.102901 steps/s, speed: 8.823206 samples/s, speed: 4517.481494 tokens/s, learning rate: 2.190e-06, loss_scalings: 26214.400391, pp_loss: 9.867182
[INFO] 2021-07-12 18:28:48,369 [run_pretraining.py:  512]:	********exe.run_220******* 
[INFO] 2021-07-12 18:28:49,281 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:49,281 [run_pretraining.py:  534]:	loss/total_loss, 9.735983848571777, 221
[INFO] 2021-07-12 18:28:49,281 [run_pretraining.py:  535]:	loss/mlm_loss, 9.735983848571777, 221
[INFO] 2021-07-12 18:28:49,281 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1999999262334313e-06, 221
[INFO] 2021-07-12 18:28:49,281 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 221
[INFO] 2021-07-12 18:28:49,281 [run_pretraining.py:  558]:	worker_index: 3, step: 221, cost: 9.735984, mlm loss: 9.735984, speed: 1.096681 steps/s, speed: 8.773451 samples/s, speed: 4492.006934 tokens/s, learning rate: 2.200e-06, loss_scalings: 26214.400391, pp_loss: 9.724342
[INFO] 2021-07-12 18:28:49,282 [run_pretraining.py:  512]:	********exe.run_221******* 
[INFO] 2021-07-12 18:28:50,189 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:50,190 [run_pretraining.py:  534]:	loss/total_loss, 9.810633659362793, 222
[INFO] 2021-07-12 18:28:50,190 [run_pretraining.py:  535]:	loss/mlm_loss, 9.810633659362793, 222
[INFO] 2021-07-12 18:28:50,190 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2099998204794247e-06, 222
[INFO] 2021-07-12 18:28:50,190 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 222
[INFO] 2021-07-12 18:28:50,190 [run_pretraining.py:  558]:	worker_index: 3, step: 222, cost: 9.810634, mlm loss: 9.810634, speed: 1.101334 steps/s, speed: 8.810670 samples/s, speed: 4511.063003 tokens/s, learning rate: 2.210e-06, loss_scalings: 26214.400391, pp_loss: 9.744686
[INFO] 2021-07-12 18:28:50,190 [run_pretraining.py:  512]:	********exe.run_222******* 
[INFO] 2021-07-12 18:28:51,107 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:51,107 [run_pretraining.py:  534]:	loss/total_loss, 9.601316452026367, 223
[INFO] 2021-07-12 18:28:51,108 [run_pretraining.py:  535]:	loss/mlm_loss, 9.601316452026367, 223
[INFO] 2021-07-12 18:28:51,108 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2199999420990935e-06, 223
[INFO] 2021-07-12 18:28:51,108 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 223
[INFO] 2021-07-12 18:28:51,108 [run_pretraining.py:  558]:	worker_index: 3, step: 223, cost: 9.601316, mlm loss: 9.601316, speed: 1.090413 steps/s, speed: 8.723304 samples/s, speed: 4466.331503 tokens/s, learning rate: 2.220e-06, loss_scalings: 26214.400391, pp_loss: 9.640651
[INFO] 2021-07-12 18:28:51,108 [run_pretraining.py:  512]:	********exe.run_223******* 
[INFO] 2021-07-12 18:28:52,019 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:52,020 [run_pretraining.py:  534]:	loss/total_loss, 9.865886688232422, 224
[INFO] 2021-07-12 18:28:52,020 [run_pretraining.py:  535]:	loss/mlm_loss, 9.865886688232422, 224
[INFO] 2021-07-12 18:28:52,020 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.229999836345087e-06, 224
[INFO] 2021-07-12 18:28:52,020 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 224
[INFO] 2021-07-12 18:28:52,020 [run_pretraining.py:  558]:	worker_index: 3, step: 224, cost: 9.865887, mlm loss: 9.865887, speed: 1.096572 steps/s, speed: 8.772573 samples/s, speed: 4491.557137 tokens/s, learning rate: 2.230e-06, loss_scalings: 26214.400391, pp_loss: 9.882781
[INFO] 2021-07-12 18:28:52,020 [run_pretraining.py:  512]:	********exe.run_224******* 
[INFO] 2021-07-12 18:28:52,925 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:52,925 [run_pretraining.py:  534]:	loss/total_loss, 9.523883819580078, 225
[INFO] 2021-07-12 18:28:52,925 [run_pretraining.py:  535]:	loss/mlm_loss, 9.523883819580078, 225
[INFO] 2021-07-12 18:28:52,925 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2399999579647556e-06, 225
[INFO] 2021-07-12 18:28:52,925 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 225
[INFO] 2021-07-12 18:28:52,926 [run_pretraining.py:  558]:	worker_index: 3, step: 225, cost: 9.523884, mlm loss: 9.523884, speed: 1.105552 steps/s, speed: 8.844418 samples/s, speed: 4528.342204 tokens/s, learning rate: 2.240e-06, loss_scalings: 26214.400391, pp_loss: 8.551444
[INFO] 2021-07-12 18:28:52,926 [run_pretraining.py:  512]:	********exe.run_225******* 
[INFO] 2021-07-12 18:28:53,843 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:53,843 [run_pretraining.py:  534]:	loss/total_loss, 9.83670711517334, 226
[INFO] 2021-07-12 18:28:53,843 [run_pretraining.py:  535]:	loss/mlm_loss, 9.83670711517334, 226
[INFO] 2021-07-12 18:28:53,844 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2500000795844244e-06, 226
[INFO] 2021-07-12 18:28:53,844 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 226
[INFO] 2021-07-12 18:28:53,844 [run_pretraining.py:  558]:	worker_index: 3, step: 226, cost: 9.836707, mlm loss: 9.836707, speed: 1.089925 steps/s, speed: 8.719400 samples/s, speed: 4464.332926 tokens/s, learning rate: 2.250e-06, loss_scalings: 26214.400391, pp_loss: 9.627021
[INFO] 2021-07-12 18:28:53,844 [run_pretraining.py:  512]:	********exe.run_226******* 
[INFO] 2021-07-12 18:28:54,749 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:54,750 [run_pretraining.py:  534]:	loss/total_loss, 9.670097351074219, 227
[INFO] 2021-07-12 18:28:54,750 [run_pretraining.py:  535]:	loss/mlm_loss, 9.670097351074219, 227
[INFO] 2021-07-12 18:28:54,750 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2599999738304177e-06, 227
[INFO] 2021-07-12 18:28:54,750 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 227
[INFO] 2021-07-12 18:28:54,750 [run_pretraining.py:  558]:	worker_index: 3, step: 227, cost: 9.670097, mlm loss: 9.670097, speed: 1.103776 steps/s, speed: 8.830211 samples/s, speed: 4521.068176 tokens/s, learning rate: 2.260e-06, loss_scalings: 26214.400391, pp_loss: 9.707808
[INFO] 2021-07-12 18:28:54,750 [run_pretraining.py:  512]:	********exe.run_227******* 
[INFO] 2021-07-12 18:28:55,655 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:55,655 [run_pretraining.py:  534]:	loss/total_loss, 9.937007904052734, 228
[INFO] 2021-07-12 18:28:55,655 [run_pretraining.py:  535]:	loss/mlm_loss, 9.937007904052734, 228
[INFO] 2021-07-12 18:28:55,656 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2700000954500865e-06, 228
[INFO] 2021-07-12 18:28:55,656 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 228
[INFO] 2021-07-12 18:28:55,656 [run_pretraining.py:  558]:	worker_index: 3, step: 228, cost: 9.937008, mlm loss: 9.937008, speed: 1.105315 steps/s, speed: 8.842521 samples/s, speed: 4527.370822 tokens/s, learning rate: 2.270e-06, loss_scalings: 26214.400391, pp_loss: 9.797635
[INFO] 2021-07-12 18:28:55,656 [run_pretraining.py:  512]:	********exe.run_228******* 
[INFO] 2021-07-12 18:28:56,567 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:56,568 [run_pretraining.py:  534]:	loss/total_loss, 9.883550643920898, 229
[INFO] 2021-07-12 18:28:56,568 [run_pretraining.py:  535]:	loss/mlm_loss, 9.883550643920898, 229
[INFO] 2021-07-12 18:28:56,568 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.27999998969608e-06, 229
[INFO] 2021-07-12 18:28:56,568 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 229
[INFO] 2021-07-12 18:28:56,568 [run_pretraining.py:  558]:	worker_index: 3, step: 229, cost: 9.883551, mlm loss: 9.883551, speed: 1.096910 steps/s, speed: 8.775277 samples/s, speed: 4492.942048 tokens/s, learning rate: 2.280e-06, loss_scalings: 26214.400391, pp_loss: 9.685892
[INFO] 2021-07-12 18:28:56,568 [run_pretraining.py:  512]:	********exe.run_229******* 
[INFO] 2021-07-12 18:28:57,472 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:57,473 [run_pretraining.py:  534]:	loss/total_loss, 9.971539497375488, 230
[INFO] 2021-07-12 18:28:57,473 [run_pretraining.py:  535]:	loss/mlm_loss, 9.971539497375488, 230
[INFO] 2021-07-12 18:28:57,473 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.289999883942073e-06, 230
[INFO] 2021-07-12 18:28:57,473 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 230
[INFO] 2021-07-12 18:28:57,473 [run_pretraining.py:  558]:	worker_index: 3, step: 230, cost: 9.971539, mlm loss: 9.971539, speed: 1.105376 steps/s, speed: 8.843011 samples/s, speed: 4527.621385 tokens/s, learning rate: 2.290e-06, loss_scalings: 26214.400391, pp_loss: 9.917996
[INFO] 2021-07-12 18:28:57,473 [run_pretraining.py:  512]:	********exe.run_230******* 
[INFO] 2021-07-12 18:28:58,381 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:58,382 [run_pretraining.py:  534]:	loss/total_loss, 9.58787727355957, 231
[INFO] 2021-07-12 18:28:58,382 [run_pretraining.py:  535]:	loss/mlm_loss, 9.58787727355957, 231
[INFO] 2021-07-12 18:28:58,382 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.300000005561742e-06, 231
[INFO] 2021-07-12 18:28:58,382 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 231
[INFO] 2021-07-12 18:28:58,382 [run_pretraining.py:  558]:	worker_index: 3, step: 231, cost: 9.587877, mlm loss: 9.587877, speed: 1.101234 steps/s, speed: 8.809870 samples/s, speed: 4510.653200 tokens/s, learning rate: 2.300e-06, loss_scalings: 26214.400391, pp_loss: 9.666208
[INFO] 2021-07-12 18:28:58,382 [run_pretraining.py:  512]:	********exe.run_231******* 
[INFO] 2021-07-12 18:28:59,300 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:59,301 [run_pretraining.py:  534]:	loss/total_loss, 9.443248748779297, 232
[INFO] 2021-07-12 18:28:59,301 [run_pretraining.py:  535]:	loss/mlm_loss, 9.443248748779297, 232
[INFO] 2021-07-12 18:28:59,301 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3099998998077353e-06, 232
[INFO] 2021-07-12 18:28:59,301 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 232
[INFO] 2021-07-12 18:28:59,301 [run_pretraining.py:  558]:	worker_index: 3, step: 232, cost: 9.443249, mlm loss: 9.443249, speed: 1.088794 steps/s, speed: 8.710353 samples/s, speed: 4459.700841 tokens/s, learning rate: 2.310e-06, loss_scalings: 26214.400391, pp_loss: 9.642384
[INFO] 2021-07-12 18:28:59,301 [run_pretraining.py:  512]:	********exe.run_232******* 
[INFO] 2021-07-12 18:29:00,210 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:00,211 [run_pretraining.py:  534]:	loss/total_loss, 9.735536575317383, 233
[INFO] 2021-07-12 18:29:00,211 [run_pretraining.py:  535]:	loss/mlm_loss, 9.735536575317383, 233
[INFO] 2021-07-12 18:29:00,211 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.320000021427404e-06, 233
[INFO] 2021-07-12 18:29:00,211 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 233
[INFO] 2021-07-12 18:29:00,211 [run_pretraining.py:  558]:	worker_index: 3, step: 233, cost: 9.735537, mlm loss: 9.735537, speed: 1.099735 steps/s, speed: 8.797879 samples/s, speed: 4504.513904 tokens/s, learning rate: 2.320e-06, loss_scalings: 26214.400391, pp_loss: 9.786955
[INFO] 2021-07-12 18:29:00,211 [run_pretraining.py:  512]:	********exe.run_233******* 
[INFO] 2021-07-12 18:29:01,117 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:01,117 [run_pretraining.py:  534]:	loss/total_loss, 9.749173164367676, 234
[INFO] 2021-07-12 18:29:01,117 [run_pretraining.py:  535]:	loss/mlm_loss, 9.749173164367676, 234
[INFO] 2021-07-12 18:29:01,117 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3299999156733975e-06, 234
[INFO] 2021-07-12 18:29:01,117 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 234
[INFO] 2021-07-12 18:29:01,118 [run_pretraining.py:  558]:	worker_index: 3, step: 234, cost: 9.749173, mlm loss: 9.749173, speed: 1.103836 steps/s, speed: 8.830688 samples/s, speed: 4521.312092 tokens/s, learning rate: 2.330e-06, loss_scalings: 26214.400391, pp_loss: 9.664307
[INFO] 2021-07-12 18:29:01,118 [run_pretraining.py:  512]:	********exe.run_234******* 
[INFO] 2021-07-12 18:29:02,025 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:02,026 [run_pretraining.py:  534]:	loss/total_loss, 9.921453475952148, 235
[INFO] 2021-07-12 18:29:02,026 [run_pretraining.py:  535]:	loss/mlm_loss, 9.921453475952148, 235
[INFO] 2021-07-12 18:29:02,026 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.339999809919391e-06, 235
[INFO] 2021-07-12 18:29:02,026 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 235
[INFO] 2021-07-12 18:29:02,026 [run_pretraining.py:  558]:	worker_index: 3, step: 235, cost: 9.921453, mlm loss: 9.921453, speed: 1.101572 steps/s, speed: 8.812577 samples/s, speed: 4512.039248 tokens/s, learning rate: 2.340e-06, loss_scalings: 26214.400391, pp_loss: 9.685102
[INFO] 2021-07-12 18:29:02,026 [run_pretraining.py:  512]:	********exe.run_235******* 
[INFO] 2021-07-12 18:29:02,938 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:02,939 [run_pretraining.py:  534]:	loss/total_loss, 7.571789264678955, 236
[INFO] 2021-07-12 18:29:02,939 [run_pretraining.py:  535]:	loss/mlm_loss, 7.571789264678955, 236
[INFO] 2021-07-12 18:29:02,939 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3499999315390596e-06, 236
[INFO] 2021-07-12 18:29:02,939 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 236
[INFO] 2021-07-12 18:29:02,939 [run_pretraining.py:  558]:	worker_index: 3, step: 236, cost: 7.571789, mlm loss: 7.571789, speed: 1.095607 steps/s, speed: 8.764855 samples/s, speed: 4487.605621 tokens/s, learning rate: 2.350e-06, loss_scalings: 26214.400391, pp_loss: 9.115273
[INFO] 2021-07-12 18:29:02,939 [run_pretraining.py:  512]:	********exe.run_236******* 
[INFO] 2021-07-12 18:29:03,862 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:03,862 [run_pretraining.py:  534]:	loss/total_loss, 9.779314041137695, 237
[INFO] 2021-07-12 18:29:03,863 [run_pretraining.py:  535]:	loss/mlm_loss, 9.779314041137695, 237
[INFO] 2021-07-12 18:29:03,863 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3600000531587284e-06, 237
[INFO] 2021-07-12 18:29:03,863 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 237
[INFO] 2021-07-12 18:29:03,863 [run_pretraining.py:  558]:	worker_index: 3, step: 237, cost: 9.779314, mlm loss: 9.779314, speed: 1.083602 steps/s, speed: 8.668819 samples/s, speed: 4438.435278 tokens/s, learning rate: 2.360e-06, loss_scalings: 26214.400391, pp_loss: 9.682171
[INFO] 2021-07-12 18:29:03,863 [run_pretraining.py:  512]:	********exe.run_237******* 
[INFO] 2021-07-12 18:29:04,773 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:04,774 [run_pretraining.py:  534]:	loss/total_loss, 9.706934928894043, 238
[INFO] 2021-07-12 18:29:04,774 [run_pretraining.py:  535]:	loss/mlm_loss, 9.706934928894043, 238
[INFO] 2021-07-12 18:29:04,774 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3699999474047218e-06, 238
[INFO] 2021-07-12 18:29:04,774 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 238
[INFO] 2021-07-12 18:29:04,774 [run_pretraining.py:  558]:	worker_index: 3, step: 238, cost: 9.706935, mlm loss: 9.706935, speed: 1.097941 steps/s, speed: 8.783524 samples/s, speed: 4497.164300 tokens/s, learning rate: 2.370e-06, loss_scalings: 26214.400391, pp_loss: 9.563673
[INFO] 2021-07-12 18:29:04,774 [run_pretraining.py:  512]:	********exe.run_238******* 
[INFO] 2021-07-12 18:29:27,918 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:27,918 [run_pretraining.py:  534]:	loss/total_loss, 9.670610427856445, 239
[INFO] 2021-07-12 18:29:27,918 [run_pretraining.py:  535]:	loss/mlm_loss, 9.670610427856445, 239
[INFO] 2021-07-12 18:29:27,918 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3800000690243905e-06, 239
[INFO] 2021-07-12 18:29:27,919 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 239
[INFO] 2021-07-12 18:29:27,919 [run_pretraining.py:  558]:	worker_index: 3, step: 239, cost: 9.670610, mlm loss: 9.670610, speed: 0.043208 steps/s, speed: 0.345666 samples/s, speed: 176.980829 tokens/s, learning rate: 2.380e-06, loss_scalings: 26214.400391, pp_loss: 9.587341
[INFO] 2021-07-12 18:29:27,919 [run_pretraining.py:  512]:	********exe.run_239******* 
[INFO] 2021-07-12 18:29:28,825 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:28,825 [run_pretraining.py:  534]:	loss/total_loss, 9.684449195861816, 240
[INFO] 2021-07-12 18:29:28,825 [run_pretraining.py:  535]:	loss/mlm_loss, 9.684449195861816, 240
[INFO] 2021-07-12 18:29:28,826 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.389999963270384e-06, 240
[INFO] 2021-07-12 18:29:28,826 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 240
[INFO] 2021-07-12 18:29:28,826 [run_pretraining.py:  558]:	worker_index: 3, step: 240, cost: 9.684449, mlm loss: 9.684449, speed: 1.103266 steps/s, speed: 8.826128 samples/s, speed: 4518.977531 tokens/s, learning rate: 2.390e-06, loss_scalings: 26214.400391, pp_loss: 9.774014
[INFO] 2021-07-12 18:29:28,826 [run_pretraining.py:  512]:	********exe.run_240******* 
[INFO] 2021-07-12 18:29:29,727 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:29,727 [run_pretraining.py:  534]:	loss/total_loss, 9.542839050292969, 241
[INFO] 2021-07-12 18:29:29,727 [run_pretraining.py:  535]:	loss/mlm_loss, 9.542839050292969, 241
[INFO] 2021-07-12 18:29:29,727 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3999998575163772e-06, 241
[INFO] 2021-07-12 18:29:29,728 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 241
[INFO] 2021-07-12 18:29:29,728 [run_pretraining.py:  558]:	worker_index: 3, step: 241, cost: 9.542839, mlm loss: 9.542839, speed: 1.109553 steps/s, speed: 8.876425 samples/s, speed: 4544.729736 tokens/s, learning rate: 2.400e-06, loss_scalings: 26214.400391, pp_loss: 9.638435
[INFO] 2021-07-12 18:29:29,728 [run_pretraining.py:  512]:	********exe.run_241******* 
[INFO] 2021-07-12 18:29:30,637 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:30,638 [run_pretraining.py:  534]:	loss/total_loss, 9.820953369140625, 242
[INFO] 2021-07-12 18:29:30,638 [run_pretraining.py:  535]:	loss/mlm_loss, 9.820953369140625, 242
[INFO] 2021-07-12 18:29:30,638 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.409999979136046e-06, 242
[INFO] 2021-07-12 18:29:30,638 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 242
[INFO] 2021-07-12 18:29:30,638 [run_pretraining.py:  558]:	worker_index: 3, step: 242, cost: 9.820953, mlm loss: 9.820953, speed: 1.099249 steps/s, speed: 8.793996 samples/s, speed: 4502.525859 tokens/s, learning rate: 2.410e-06, loss_scalings: 26214.400391, pp_loss: 9.711013
[INFO] 2021-07-12 18:29:30,638 [run_pretraining.py:  512]:	********exe.run_242******* 
[INFO] 2021-07-12 18:29:31,540 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:31,541 [run_pretraining.py:  534]:	loss/total_loss, 9.895503997802734, 243
[INFO] 2021-07-12 18:29:31,541 [run_pretraining.py:  535]:	loss/mlm_loss, 9.895503997802734, 243
[INFO] 2021-07-12 18:29:31,541 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4199998733820394e-06, 243
[INFO] 2021-07-12 18:29:31,541 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 243
[INFO] 2021-07-12 18:29:31,541 [run_pretraining.py:  558]:	worker_index: 3, step: 243, cost: 9.895504, mlm loss: 9.895504, speed: 1.108302 steps/s, speed: 8.866417 samples/s, speed: 4539.605502 tokens/s, learning rate: 2.420e-06, loss_scalings: 26214.400391, pp_loss: 9.706514
[INFO] 2021-07-12 18:29:31,541 [run_pretraining.py:  512]:	********exe.run_243******* 
[INFO] 2021-07-12 18:29:32,446 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:32,447 [run_pretraining.py:  534]:	loss/total_loss, 9.669342041015625, 244
[INFO] 2021-07-12 18:29:32,447 [run_pretraining.py:  535]:	loss/mlm_loss, 9.669342041015625, 244
[INFO] 2021-07-12 18:29:32,447 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.429999995001708e-06, 244
[INFO] 2021-07-12 18:29:32,447 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 244
[INFO] 2021-07-12 18:29:32,447 [run_pretraining.py:  558]:	worker_index: 3, step: 244, cost: 9.669342, mlm loss: 9.669342, speed: 1.104565 steps/s, speed: 8.836522 samples/s, speed: 4524.299514 tokens/s, learning rate: 2.430e-06, loss_scalings: 26214.400391, pp_loss: 9.661757
[INFO] 2021-07-12 18:29:32,447 [run_pretraining.py:  512]:	********exe.run_244******* 
[INFO] 2021-07-12 18:29:33,354 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:33,354 [run_pretraining.py:  534]:	loss/total_loss, 9.477906227111816, 245
[INFO] 2021-07-12 18:29:33,355 [run_pretraining.py:  535]:	loss/mlm_loss, 9.477906227111816, 245
[INFO] 2021-07-12 18:29:33,355 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4399998892477015e-06, 245
[INFO] 2021-07-12 18:29:33,355 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 245
[INFO] 2021-07-12 18:29:33,355 [run_pretraining.py:  558]:	worker_index: 3, step: 245, cost: 9.477906, mlm loss: 9.477906, speed: 1.102208 steps/s, speed: 8.817662 samples/s, speed: 4514.643055 tokens/s, learning rate: 2.440e-06, loss_scalings: 26214.400391, pp_loss: 9.640379
[INFO] 2021-07-12 18:29:33,355 [run_pretraining.py:  512]:	********exe.run_245******* 
[INFO] 2021-07-12 18:29:34,260 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:34,260 [run_pretraining.py:  534]:	loss/total_loss, 9.806745529174805, 246
[INFO] 2021-07-12 18:29:34,260 [run_pretraining.py:  535]:	loss/mlm_loss, 9.806745529174805, 246
[INFO] 2021-07-12 18:29:34,260 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.449999783493695e-06, 246
[INFO] 2021-07-12 18:29:34,261 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 246
[INFO] 2021-07-12 18:29:34,261 [run_pretraining.py:  558]:	worker_index: 3, step: 246, cost: 9.806746, mlm loss: 9.806746, speed: 1.104660 steps/s, speed: 8.837281 samples/s, speed: 4524.687966 tokens/s, learning rate: 2.450e-06, loss_scalings: 26214.400391, pp_loss: 8.443617
[INFO] 2021-07-12 18:29:34,261 [run_pretraining.py:  512]:	********exe.run_246******* 
[INFO] 2021-07-12 18:29:35,162 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:35,162 [run_pretraining.py:  534]:	loss/total_loss, 9.706947326660156, 247
[INFO] 2021-07-12 18:29:35,163 [run_pretraining.py:  535]:	loss/mlm_loss, 9.706947326660156, 247
[INFO] 2021-07-12 18:29:35,163 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4599999051133636e-06, 247
[INFO] 2021-07-12 18:29:35,163 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 247
[INFO] 2021-07-12 18:29:35,163 [run_pretraining.py:  558]:	worker_index: 3, step: 247, cost: 9.706947, mlm loss: 9.706947, speed: 1.109217 steps/s, speed: 8.873733 samples/s, speed: 4543.351169 tokens/s, learning rate: 2.460e-06, loss_scalings: 26214.400391, pp_loss: 9.657065
[INFO] 2021-07-12 18:29:35,163 [run_pretraining.py:  512]:	********exe.run_247******* 
[INFO] 2021-07-12 18:29:36,062 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:36,062 [run_pretraining.py:  534]:	loss/total_loss, 5.0600128173828125, 248
[INFO] 2021-07-12 18:29:36,062 [run_pretraining.py:  535]:	loss/mlm_loss, 5.0600128173828125, 248
[INFO] 2021-07-12 18:29:36,062 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4700000267330324e-06, 248
[INFO] 2021-07-12 18:29:36,062 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 248
[INFO] 2021-07-12 18:29:36,062 [run_pretraining.py:  558]:	worker_index: 3, step: 248, cost: 5.060013, mlm loss: 5.060013, speed: 1.112352 steps/s, speed: 8.898813 samples/s, speed: 4556.192009 tokens/s, learning rate: 2.470e-06, loss_scalings: 26214.400391, pp_loss: 8.441918
[INFO] 2021-07-12 18:29:36,063 [run_pretraining.py:  512]:	********exe.run_248******* 
[INFO] 2021-07-12 18:29:36,978 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:36,978 [run_pretraining.py:  534]:	loss/total_loss, 9.800999641418457, 249
[INFO] 2021-07-12 18:29:36,978 [run_pretraining.py:  535]:	loss/mlm_loss, 9.800999641418457, 249
[INFO] 2021-07-12 18:29:36,978 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4799999209790258e-06, 249
[INFO] 2021-07-12 18:29:36,978 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 249
[INFO] 2021-07-12 18:29:36,978 [run_pretraining.py:  558]:	worker_index: 3, step: 249, cost: 9.801000, mlm loss: 9.801000, speed: 1.092529 steps/s, speed: 8.740232 samples/s, speed: 4474.998733 tokens/s, learning rate: 2.480e-06, loss_scalings: 26214.400391, pp_loss: 9.583484
[INFO] 2021-07-12 18:29:36,978 [run_pretraining.py:  512]:	********exe.run_249******* 
[INFO] 2021-07-12 18:30:02,774 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:02,775 [run_pretraining.py:  534]:	loss/total_loss, 9.664438247680664, 250
[INFO] 2021-07-12 18:30:02,775 [run_pretraining.py:  535]:	loss/mlm_loss, 9.664438247680664, 250
[INFO] 2021-07-12 18:30:02,775 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4900000425986946e-06, 250
[INFO] 2021-07-12 18:30:02,775 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 250
[INFO] 2021-07-12 18:30:02,776 [run_pretraining.py:  558]:	worker_index: 3, step: 250, cost: 9.664438, mlm loss: 9.664438, speed: 0.038765 steps/s, speed: 0.310121 samples/s, speed: 158.781717 tokens/s, learning rate: 2.490e-06, loss_scalings: 26214.400391, pp_loss: 9.683914
[INFO] 2021-07-12 18:30:02,776 [run_pretraining.py:  512]:	********exe.run_250******* 
[INFO] 2021-07-12 18:30:03,687 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:03,688 [run_pretraining.py:  534]:	loss/total_loss, 9.357437133789062, 251
[INFO] 2021-07-12 18:30:03,688 [run_pretraining.py:  535]:	loss/mlm_loss, 9.357437133789062, 251
[INFO] 2021-07-12 18:30:03,688 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.499999936844688e-06, 251
[INFO] 2021-07-12 18:30:03,688 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 251
[INFO] 2021-07-12 18:30:03,688 [run_pretraining.py:  558]:	worker_index: 3, step: 251, cost: 9.357437, mlm loss: 9.357437, speed: 1.096430 steps/s, speed: 8.771440 samples/s, speed: 4490.977115 tokens/s, learning rate: 2.500e-06, loss_scalings: 26214.400391, pp_loss: 9.573836
[INFO] 2021-07-12 18:30:03,688 [run_pretraining.py:  512]:	********exe.run_251******* 
[INFO] 2021-07-12 18:30:04,602 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:04,603 [run_pretraining.py:  534]:	loss/total_loss, 9.519758224487305, 252
[INFO] 2021-07-12 18:30:04,603 [run_pretraining.py:  535]:	loss/mlm_loss, 9.519758224487305, 252
[INFO] 2021-07-12 18:30:04,603 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5100000584643567e-06, 252
[INFO] 2021-07-12 18:30:04,603 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 252
[INFO] 2021-07-12 18:30:04,603 [run_pretraining.py:  558]:	worker_index: 3, step: 252, cost: 9.519758, mlm loss: 9.519758, speed: 1.093759 steps/s, speed: 8.750071 samples/s, speed: 4480.036483 tokens/s, learning rate: 2.510e-06, loss_scalings: 26214.400391, pp_loss: 9.558430
[INFO] 2021-07-12 18:30:04,603 [run_pretraining.py:  512]:	********exe.run_252******* 
[INFO] 2021-07-12 18:30:05,520 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:05,520 [run_pretraining.py:  534]:	loss/total_loss, 9.436768531799316, 253
[INFO] 2021-07-12 18:30:05,520 [run_pretraining.py:  535]:	loss/mlm_loss, 9.436768531799316, 253
[INFO] 2021-07-12 18:30:05,520 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.51999995271035e-06, 253
[INFO] 2021-07-12 18:30:05,520 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 253
[INFO] 2021-07-12 18:30:05,521 [run_pretraining.py:  558]:	worker_index: 3, step: 253, cost: 9.436769, mlm loss: 9.436769, speed: 1.090762 steps/s, speed: 8.726099 samples/s, speed: 4467.762478 tokens/s, learning rate: 2.520e-06, loss_scalings: 26214.400391, pp_loss: 9.505033
[INFO] 2021-07-12 18:30:05,521 [run_pretraining.py:  512]:	********exe.run_253******* 
[INFO] 2021-07-12 18:30:06,437 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:06,437 [run_pretraining.py:  534]:	loss/total_loss, 9.831924438476562, 254
[INFO] 2021-07-12 18:30:06,437 [run_pretraining.py:  535]:	loss/mlm_loss, 9.831924438476562, 254
[INFO] 2021-07-12 18:30:06,437 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5299998469563434e-06, 254
[INFO] 2021-07-12 18:30:06,438 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 254
[INFO] 2021-07-12 18:30:06,438 [run_pretraining.py:  558]:	worker_index: 3, step: 254, cost: 9.831924, mlm loss: 9.831924, speed: 1.091201 steps/s, speed: 8.729611 samples/s, speed: 4469.560625 tokens/s, learning rate: 2.530e-06, loss_scalings: 26214.400391, pp_loss: 9.661568
[INFO] 2021-07-12 18:30:06,438 [run_pretraining.py:  512]:	********exe.run_254******* 
[INFO] 2021-07-12 18:30:07,405 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:07,405 [run_pretraining.py:  534]:	loss/total_loss, 9.719491958618164, 255
[INFO] 2021-07-12 18:30:07,405 [run_pretraining.py:  535]:	loss/mlm_loss, 9.719491958618164, 255
[INFO] 2021-07-12 18:30:07,405 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.539999968576012e-06, 255
[INFO] 2021-07-12 18:30:07,405 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 255
[INFO] 2021-07-12 18:30:07,405 [run_pretraining.py:  558]:	worker_index: 3, step: 255, cost: 9.719492, mlm loss: 9.719492, speed: 1.033959 steps/s, speed: 8.271669 samples/s, speed: 4235.094703 tokens/s, learning rate: 2.540e-06, loss_scalings: 26214.400391, pp_loss: 9.607258
[INFO] 2021-07-12 18:30:07,405 [run_pretraining.py:  512]:	********exe.run_255******* 
[INFO] 2021-07-12 18:30:34,004 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:34,005 [run_pretraining.py:  534]:	loss/total_loss, 9.606657981872559, 256
[INFO] 2021-07-12 18:30:34,005 [run_pretraining.py:  535]:	loss/mlm_loss, 9.606657981872559, 256
[INFO] 2021-07-12 18:30:34,005 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5499998628220055e-06, 256
[INFO] 2021-07-12 18:30:34,005 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 256
[INFO] 2021-07-12 18:30:34,006 [run_pretraining.py:  558]:	worker_index: 3, step: 256, cost: 9.606658, mlm loss: 9.606658, speed: 0.037595 steps/s, speed: 0.300758 samples/s, speed: 153.988223 tokens/s, learning rate: 2.550e-06, loss_scalings: 26214.400391, pp_loss: 9.659469
[INFO] 2021-07-12 18:30:34,006 [run_pretraining.py:  512]:	********exe.run_256******* 
[INFO] 2021-07-12 18:30:34,947 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:34,947 [run_pretraining.py:  534]:	loss/total_loss, 9.898005485534668, 257
[INFO] 2021-07-12 18:30:34,947 [run_pretraining.py:  535]:	loss/mlm_loss, 9.898005485534668, 257
[INFO] 2021-07-12 18:30:34,948 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.559999757067999e-06, 257
[INFO] 2021-07-12 18:30:34,948 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 257
[INFO] 2021-07-12 18:30:34,948 [run_pretraining.py:  558]:	worker_index: 3, step: 257, cost: 9.898005, mlm loss: 9.898005, speed: 1.062146 steps/s, speed: 8.497170 samples/s, speed: 4350.551024 tokens/s, learning rate: 2.560e-06, loss_scalings: 26214.400391, pp_loss: 9.786669
[INFO] 2021-07-12 18:30:34,948 [run_pretraining.py:  512]:	********exe.run_257******* 
[INFO] 2021-07-12 18:30:35,866 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:35,867 [run_pretraining.py:  534]:	loss/total_loss, 9.763158798217773, 258
[INFO] 2021-07-12 18:30:35,867 [run_pretraining.py:  535]:	loss/mlm_loss, 9.763158798217773, 258
[INFO] 2021-07-12 18:30:35,867 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5699998786876677e-06, 258
[INFO] 2021-07-12 18:30:35,867 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 258
[INFO] 2021-07-12 18:30:35,867 [run_pretraining.py:  558]:	worker_index: 3, step: 258, cost: 9.763159, mlm loss: 9.763159, speed: 1.088097 steps/s, speed: 8.704774 samples/s, speed: 4456.844339 tokens/s, learning rate: 2.570e-06, loss_scalings: 26214.400391, pp_loss: 9.716918
[INFO] 2021-07-12 18:30:35,867 [run_pretraining.py:  512]:	********exe.run_258******* 
[INFO] 2021-07-12 18:30:36,777 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:36,777 [run_pretraining.py:  534]:	loss/total_loss, 9.511063575744629, 259
[INFO] 2021-07-12 18:30:36,777 [run_pretraining.py:  535]:	loss/mlm_loss, 9.511063575744629, 259
[INFO] 2021-07-12 18:30:36,777 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5800000003073364e-06, 259
[INFO] 2021-07-12 18:30:36,777 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 259
[INFO] 2021-07-12 18:30:36,778 [run_pretraining.py:  558]:	worker_index: 3, step: 259, cost: 9.511064, mlm loss: 9.511064, speed: 1.099410 steps/s, speed: 8.795277 samples/s, speed: 4503.182050 tokens/s, learning rate: 2.580e-06, loss_scalings: 26214.400391, pp_loss: 9.764362
[INFO] 2021-07-12 18:30:36,778 [run_pretraining.py:  512]:	********exe.run_259******* 
[INFO] 2021-07-12 18:30:37,696 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:37,697 [run_pretraining.py:  534]:	loss/total_loss, 9.666276931762695, 260
[INFO] 2021-07-12 18:30:37,697 [run_pretraining.py:  535]:	loss/mlm_loss, 9.666276931762695, 260
[INFO] 2021-07-12 18:30:37,697 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.58999989455333e-06, 260
[INFO] 2021-07-12 18:30:37,697 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 260
[INFO] 2021-07-12 18:30:37,697 [run_pretraining.py:  558]:	worker_index: 3, step: 260, cost: 9.666277, mlm loss: 9.666277, speed: 1.088109 steps/s, speed: 8.704873 samples/s, speed: 4456.895213 tokens/s, learning rate: 2.590e-06, loss_scalings: 26214.400391, pp_loss: 9.768631
[INFO] 2021-07-12 18:30:37,697 [run_pretraining.py:  512]:	********exe.run_260******* 
[INFO] 2021-07-12 18:30:38,603 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:38,604 [run_pretraining.py:  534]:	loss/total_loss, 9.500121116638184, 261
[INFO] 2021-07-12 18:30:38,604 [run_pretraining.py:  535]:	loss/mlm_loss, 9.500121116638184, 261
[INFO] 2021-07-12 18:30:38,604 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6000000161729986e-06, 261
[INFO] 2021-07-12 18:30:38,604 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 261
[INFO] 2021-07-12 18:30:38,604 [run_pretraining.py:  558]:	worker_index: 3, step: 261, cost: 9.500121, mlm loss: 9.500121, speed: 1.103594 steps/s, speed: 8.828750 samples/s, speed: 4520.319936 tokens/s, learning rate: 2.600e-06, loss_scalings: 26214.400391, pp_loss: 9.530219
[INFO] 2021-07-12 18:30:38,604 [run_pretraining.py:  512]:	********exe.run_261******* 
[INFO] 2021-07-12 18:30:39,519 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:39,519 [run_pretraining.py:  534]:	loss/total_loss, 9.963985443115234, 262
[INFO] 2021-07-12 18:30:39,520 [run_pretraining.py:  535]:	loss/mlm_loss, 9.963985443115234, 262
[INFO] 2021-07-12 18:30:39,520 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.609999910418992e-06, 262
[INFO] 2021-07-12 18:30:39,520 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 262
[INFO] 2021-07-12 18:30:39,520 [run_pretraining.py:  558]:	worker_index: 3, step: 262, cost: 9.963985, mlm loss: 9.963985, speed: 1.092772 steps/s, speed: 8.742179 samples/s, speed: 4475.995580 tokens/s, learning rate: 2.610e-06, loss_scalings: 26214.400391, pp_loss: 9.686876
[INFO] 2021-07-12 18:30:39,520 [run_pretraining.py:  512]:	********exe.run_262******* 
[INFO] 2021-07-12 18:30:40,429 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:40,429 [run_pretraining.py:  534]:	loss/total_loss, 9.683881759643555, 263
[INFO] 2021-07-12 18:30:40,429 [run_pretraining.py:  535]:	loss/mlm_loss, 9.683881759643555, 263
[INFO] 2021-07-12 18:30:40,429 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6200000320386607e-06, 263
[INFO] 2021-07-12 18:30:40,429 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 263
[INFO] 2021-07-12 18:30:40,429 [run_pretraining.py:  558]:	worker_index: 3, step: 263, cost: 9.683882, mlm loss: 9.683882, speed: 1.100086 steps/s, speed: 8.800685 samples/s, speed: 4505.950545 tokens/s, learning rate: 2.620e-06, loss_scalings: 26214.400391, pp_loss: 9.094307
[INFO] 2021-07-12 18:30:40,430 [run_pretraining.py:  512]:	********exe.run_263******* 
[INFO] 2021-07-12 18:30:41,334 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:41,335 [run_pretraining.py:  534]:	loss/total_loss, 9.575369834899902, 264
[INFO] 2021-07-12 18:30:41,335 [run_pretraining.py:  535]:	loss/mlm_loss, 9.575369834899902, 264
[INFO] 2021-07-12 18:30:41,335 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.629999926284654e-06, 264
[INFO] 2021-07-12 18:30:41,335 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 264
[INFO] 2021-07-12 18:30:41,335 [run_pretraining.py:  558]:	worker_index: 3, step: 264, cost: 9.575370, mlm loss: 9.575370, speed: 1.104670 steps/s, speed: 8.837360 samples/s, speed: 4524.728484 tokens/s, learning rate: 2.630e-06, loss_scalings: 26214.400391, pp_loss: 9.694628
[INFO] 2021-07-12 18:30:41,335 [run_pretraining.py:  512]:	********exe.run_264******* 
[INFO] 2021-07-12 18:30:42,248 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:42,248 [run_pretraining.py:  534]:	loss/total_loss, 9.5867280960083, 265
[INFO] 2021-07-12 18:30:42,248 [run_pretraining.py:  535]:	loss/mlm_loss, 9.5867280960083, 265
[INFO] 2021-07-12 18:30:42,248 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6399998205306474e-06, 265
[INFO] 2021-07-12 18:30:42,249 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 265
[INFO] 2021-07-12 18:30:42,249 [run_pretraining.py:  558]:	worker_index: 3, step: 265, cost: 9.586728, mlm loss: 9.586728, speed: 1.095720 steps/s, speed: 8.765759 samples/s, speed: 4488.068696 tokens/s, learning rate: 2.640e-06, loss_scalings: 26214.400391, pp_loss: 9.686283
[INFO] 2021-07-12 18:30:42,249 [run_pretraining.py:  512]:	********exe.run_265******* 
[INFO] 2021-07-12 18:30:43,171 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:43,172 [run_pretraining.py:  534]:	loss/total_loss, 9.513392448425293, 266
[INFO] 2021-07-12 18:30:43,172 [run_pretraining.py:  535]:	loss/mlm_loss, 9.513392448425293, 266
[INFO] 2021-07-12 18:30:43,172 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.649999942150316e-06, 266
[INFO] 2021-07-12 18:30:43,172 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 266
[INFO] 2021-07-12 18:30:43,172 [run_pretraining.py:  558]:	worker_index: 3, step: 266, cost: 9.513392, mlm loss: 9.513392, speed: 1.083548 steps/s, speed: 8.668387 samples/s, speed: 4438.213981 tokens/s, learning rate: 2.650e-06, loss_scalings: 26214.400391, pp_loss: 9.541714
[INFO] 2021-07-12 18:30:43,172 [run_pretraining.py:  512]:	********exe.run_266******* 
[INFO] 2021-07-12 18:30:44,247 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:44,247 [run_pretraining.py:  534]:	loss/total_loss, 9.881338119506836, 267
[INFO] 2021-07-12 18:30:44,247 [run_pretraining.py:  535]:	loss/mlm_loss, 9.881338119506836, 267
[INFO] 2021-07-12 18:30:44,247 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6599998363963095e-06, 267
[INFO] 2021-07-12 18:30:44,247 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 267
[INFO] 2021-07-12 18:30:44,247 [run_pretraining.py:  558]:	worker_index: 3, step: 267, cost: 9.881338, mlm loss: 9.881338, speed: 0.930573 steps/s, speed: 7.444584 samples/s, speed: 3811.627234 tokens/s, learning rate: 2.660e-06, loss_scalings: 26214.400391, pp_loss: 9.689148
[INFO] 2021-07-12 18:30:44,247 [run_pretraining.py:  512]:	********exe.run_267******* 
[INFO] 2021-07-12 18:30:45,292 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:45,292 [run_pretraining.py:  534]:	loss/total_loss, 9.37474250793457, 268
[INFO] 2021-07-12 18:30:45,292 [run_pretraining.py:  535]:	loss/mlm_loss, 9.37474250793457, 268
[INFO] 2021-07-12 18:30:45,293 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6699999580159783e-06, 268
[INFO] 2021-07-12 18:30:45,293 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 268
[INFO] 2021-07-12 18:30:45,293 [run_pretraining.py:  558]:	worker_index: 3, step: 268, cost: 9.374743, mlm loss: 9.374743, speed: 0.957211 steps/s, speed: 7.657686 samples/s, speed: 3920.735092 tokens/s, learning rate: 2.670e-06, loss_scalings: 26214.400391, pp_loss: 9.604959
[INFO] 2021-07-12 18:30:45,293 [run_pretraining.py:  512]:	********exe.run_268******* 
[INFO] 2021-07-12 18:30:46,343 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:46,344 [run_pretraining.py:  534]:	loss/total_loss, 9.733192443847656, 269
[INFO] 2021-07-12 18:30:46,344 [run_pretraining.py:  535]:	loss/mlm_loss, 9.733192443847656, 269
[INFO] 2021-07-12 18:30:46,344 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6799998522619717e-06, 269
[INFO] 2021-07-12 18:30:46,344 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 269
[INFO] 2021-07-12 18:30:46,344 [run_pretraining.py:  558]:	worker_index: 3, step: 269, cost: 9.733192, mlm loss: 9.733192, speed: 0.951533 steps/s, speed: 7.612262 samples/s, speed: 3897.478118 tokens/s, learning rate: 2.680e-06, loss_scalings: 26214.400391, pp_loss: 9.589136
[INFO] 2021-07-12 18:30:46,344 [run_pretraining.py:  512]:	********exe.run_269******* 
[INFO] 2021-07-12 18:30:47,405 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:47,405 [run_pretraining.py:  534]:	loss/total_loss, 9.68986701965332, 270
[INFO] 2021-07-12 18:30:47,405 [run_pretraining.py:  535]:	loss/mlm_loss, 9.68986701965332, 270
[INFO] 2021-07-12 18:30:47,405 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6899999738816405e-06, 270
[INFO] 2021-07-12 18:30:47,405 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 270
[INFO] 2021-07-12 18:30:47,405 [run_pretraining.py:  558]:	worker_index: 3, step: 270, cost: 9.689867, mlm loss: 9.689867, speed: 0.942908 steps/s, speed: 7.543261 samples/s, speed: 3862.149697 tokens/s, learning rate: 2.690e-06, loss_scalings: 26214.400391, pp_loss: 9.378496
[INFO] 2021-07-12 18:30:47,406 [run_pretraining.py:  512]:	********exe.run_270******* 
[INFO] 2021-07-12 18:30:48,471 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:48,472 [run_pretraining.py:  534]:	loss/total_loss, 9.533888816833496, 271
[INFO] 2021-07-12 18:30:48,472 [run_pretraining.py:  535]:	loss/mlm_loss, 9.533888816833496, 271
[INFO] 2021-07-12 18:30:48,472 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7000000955013093e-06, 271
[INFO] 2021-07-12 18:30:48,472 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 271
[INFO] 2021-07-12 18:30:48,472 [run_pretraining.py:  558]:	worker_index: 3, step: 271, cost: 9.533889, mlm loss: 9.533889, speed: 0.938260 steps/s, speed: 7.506082 samples/s, speed: 3843.114115 tokens/s, learning rate: 2.700e-06, loss_scalings: 26214.400391, pp_loss: 9.599619
[INFO] 2021-07-12 18:30:48,472 [run_pretraining.py:  512]:	********exe.run_271******* 
[INFO] 2021-07-12 18:30:49,539 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:49,540 [run_pretraining.py:  534]:	loss/total_loss, 9.686107635498047, 272
[INFO] 2021-07-12 18:30:49,540 [run_pretraining.py:  535]:	loss/mlm_loss, 9.686107635498047, 272
[INFO] 2021-07-12 18:30:49,540 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7099999897473026e-06, 272
[INFO] 2021-07-12 18:30:49,540 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 272
[INFO] 2021-07-12 18:30:49,540 [run_pretraining.py:  558]:	worker_index: 3, step: 272, cost: 9.686108, mlm loss: 9.686108, speed: 0.936627 steps/s, speed: 7.493013 samples/s, speed: 3836.422708 tokens/s, learning rate: 2.710e-06, loss_scalings: 26214.400391, pp_loss: 9.552303
[INFO] 2021-07-12 18:30:49,540 [run_pretraining.py:  512]:	********exe.run_272******* 
[INFO] 2021-07-12 18:30:50,603 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:50,604 [run_pretraining.py:  534]:	loss/total_loss, 9.652121543884277, 273
[INFO] 2021-07-12 18:30:50,604 [run_pretraining.py:  535]:	loss/mlm_loss, 9.652121543884277, 273
[INFO] 2021-07-12 18:30:50,604 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.719999883993296e-06, 273
[INFO] 2021-07-12 18:30:50,604 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 273
[INFO] 2021-07-12 18:30:50,604 [run_pretraining.py:  558]:	worker_index: 3, step: 273, cost: 9.652122, mlm loss: 9.652122, speed: 0.940705 steps/s, speed: 7.525641 samples/s, speed: 3853.128130 tokens/s, learning rate: 2.720e-06, loss_scalings: 26214.400391, pp_loss: 9.528418
[INFO] 2021-07-12 18:30:50,604 [run_pretraining.py:  512]:	********exe.run_273******* 
[INFO] 2021-07-12 18:30:51,652 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:51,652 [run_pretraining.py:  534]:	loss/total_loss, 9.45653247833252, 274
[INFO] 2021-07-12 18:30:51,652 [run_pretraining.py:  535]:	loss/mlm_loss, 9.45653247833252, 274
[INFO] 2021-07-12 18:30:51,652 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7300000056129647e-06, 274
[INFO] 2021-07-12 18:30:51,652 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 274
[INFO] 2021-07-12 18:30:51,652 [run_pretraining.py:  558]:	worker_index: 3, step: 274, cost: 9.456532, mlm loss: 9.456532, speed: 0.954246 steps/s, speed: 7.633966 samples/s, speed: 3908.590429 tokens/s, learning rate: 2.730e-06, loss_scalings: 26214.400391, pp_loss: 9.590261
[INFO] 2021-07-12 18:30:51,653 [run_pretraining.py:  512]:	********exe.run_274******* 
[INFO] 2021-07-12 18:30:52,711 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:52,711 [run_pretraining.py:  534]:	loss/total_loss, 9.815311431884766, 275
[INFO] 2021-07-12 18:30:52,711 [run_pretraining.py:  535]:	loss/mlm_loss, 9.815311431884766, 275
[INFO] 2021-07-12 18:30:52,711 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.739999899858958e-06, 275
[INFO] 2021-07-12 18:30:52,711 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 275
[INFO] 2021-07-12 18:30:52,712 [run_pretraining.py:  558]:	worker_index: 3, step: 275, cost: 9.815311, mlm loss: 9.815311, speed: 0.944772 steps/s, speed: 7.558179 samples/s, speed: 3869.787895 tokens/s, learning rate: 2.740e-06, loss_scalings: 26214.400391, pp_loss: 9.665670
[INFO] 2021-07-12 18:30:52,712 [run_pretraining.py:  512]:	********exe.run_275******* 
[INFO] 2021-07-12 18:30:53,846 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:53,847 [run_pretraining.py:  534]:	loss/total_loss, 9.836430549621582, 276
[INFO] 2021-07-12 18:30:53,847 [run_pretraining.py:  535]:	loss/mlm_loss, 9.836430549621582, 276
[INFO] 2021-07-12 18:30:53,847 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.750000021478627e-06, 276
[INFO] 2021-07-12 18:30:53,847 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 276
[INFO] 2021-07-12 18:30:53,847 [run_pretraining.py:  558]:	worker_index: 3, step: 276, cost: 9.836431, mlm loss: 9.836431, speed: 0.881343 steps/s, speed: 7.050745 samples/s, speed: 3609.981440 tokens/s, learning rate: 2.750e-06, loss_scalings: 26214.400391, pp_loss: 9.487554
[INFO] 2021-07-12 18:30:53,847 [run_pretraining.py:  512]:	********exe.run_276******* 
[INFO] 2021-07-12 18:30:54,943 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:54,943 [run_pretraining.py:  534]:	loss/total_loss, 9.541911125183105, 277
[INFO] 2021-07-12 18:30:54,943 [run_pretraining.py:  535]:	loss/mlm_loss, 9.541911125183105, 277
[INFO] 2021-07-12 18:30:54,943 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7599999157246202e-06, 277
[INFO] 2021-07-12 18:30:54,944 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 277
[INFO] 2021-07-12 18:30:54,944 [run_pretraining.py:  558]:	worker_index: 3, step: 277, cost: 9.541911, mlm loss: 9.541911, speed: 0.912268 steps/s, speed: 7.298145 samples/s, speed: 3736.650114 tokens/s, learning rate: 2.760e-06, loss_scalings: 26214.400391, pp_loss: 9.174314
[INFO] 2021-07-12 18:30:54,944 [run_pretraining.py:  512]:	********exe.run_277******* 
[INFO] 2021-07-12 18:30:56,010 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:56,011 [run_pretraining.py:  534]:	loss/total_loss, 9.301776885986328, 278
[INFO] 2021-07-12 18:30:56,011 [run_pretraining.py:  535]:	loss/mlm_loss, 9.301776885986328, 278
[INFO] 2021-07-12 18:30:56,011 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7699998099706136e-06, 278
[INFO] 2021-07-12 18:30:56,011 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 278
[INFO] 2021-07-12 18:30:56,011 [run_pretraining.py:  558]:	worker_index: 3, step: 278, cost: 9.301777, mlm loss: 9.301777, speed: 0.937383 steps/s, speed: 7.499062 samples/s, speed: 3839.519637 tokens/s, learning rate: 2.770e-06, loss_scalings: 26214.400391, pp_loss: 9.382245
[INFO] 2021-07-12 18:30:56,011 [run_pretraining.py:  512]:	********exe.run_278******* 
[INFO] 2021-07-12 18:30:57,097 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:57,097 [run_pretraining.py:  534]:	loss/total_loss, 9.499571800231934, 279
[INFO] 2021-07-12 18:30:57,097 [run_pretraining.py:  535]:	loss/mlm_loss, 9.499571800231934, 279
[INFO] 2021-07-12 18:30:57,097 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7799999315902824e-06, 279
[INFO] 2021-07-12 18:30:57,097 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 279
[INFO] 2021-07-12 18:30:57,097 [run_pretraining.py:  558]:	worker_index: 3, step: 279, cost: 9.499572, mlm loss: 9.499572, speed: 0.921049 steps/s, speed: 7.368395 samples/s, speed: 3772.618134 tokens/s, learning rate: 2.780e-06, loss_scalings: 26214.400391, pp_loss: 9.445834
[INFO] 2021-07-12 18:30:57,098 [run_pretraining.py:  512]:	********exe.run_279******* 
[INFO] 2021-07-12 18:30:58,186 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:58,186 [run_pretraining.py:  534]:	loss/total_loss, 9.30312442779541, 280
[INFO] 2021-07-12 18:30:58,186 [run_pretraining.py:  535]:	loss/mlm_loss, 9.30312442779541, 280
[INFO] 2021-07-12 18:30:58,186 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7899998258362757e-06, 280
[INFO] 2021-07-12 18:30:58,187 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 280
[INFO] 2021-07-12 18:30:58,187 [run_pretraining.py:  558]:	worker_index: 3, step: 280, cost: 9.303124, mlm loss: 9.303124, speed: 0.918648 steps/s, speed: 7.349180 samples/s, speed: 3762.780340 tokens/s, learning rate: 2.790e-06, loss_scalings: 26214.400391, pp_loss: 9.544166
[INFO] 2021-07-12 18:30:58,187 [run_pretraining.py:  512]:	********exe.run_280******* 
[INFO] 2021-07-12 18:30:59,275 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:59,275 [run_pretraining.py:  534]:	loss/total_loss, 9.76034927368164, 281
[INFO] 2021-07-12 18:30:59,275 [run_pretraining.py:  535]:	loss/mlm_loss, 9.76034927368164, 281
[INFO] 2021-07-12 18:30:59,276 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7999999474559445e-06, 281
[INFO] 2021-07-12 18:30:59,276 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 281
[INFO] 2021-07-12 18:30:59,276 [run_pretraining.py:  558]:	worker_index: 3, step: 281, cost: 9.760349, mlm loss: 9.760349, speed: 0.918786 steps/s, speed: 7.350290 samples/s, speed: 3763.348254 tokens/s, learning rate: 2.800e-06, loss_scalings: 26214.400391, pp_loss: 9.735008
[INFO] 2021-07-12 18:30:59,276 [run_pretraining.py:  512]:	********exe.run_281******* 
[INFO] 2021-07-12 18:31:00,364 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:00,364 [run_pretraining.py:  534]:	loss/total_loss, 9.54445743560791, 282
[INFO] 2021-07-12 18:31:00,364 [run_pretraining.py:  535]:	loss/mlm_loss, 9.54445743560791, 282
[INFO] 2021-07-12 18:31:00,364 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8100000690756133e-06, 282
[INFO] 2021-07-12 18:31:00,365 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 282
[INFO] 2021-07-12 18:31:00,365 [run_pretraining.py:  558]:	worker_index: 3, step: 282, cost: 9.544457, mlm loss: 9.544457, speed: 0.918807 steps/s, speed: 7.350459 samples/s, speed: 3763.434816 tokens/s, learning rate: 2.810e-06, loss_scalings: 26214.400391, pp_loss: 9.505751
[INFO] 2021-07-12 18:31:00,365 [run_pretraining.py:  512]:	********exe.run_282******* 
[INFO] 2021-07-12 18:31:01,453 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:01,454 [run_pretraining.py:  534]:	loss/total_loss, 9.728797912597656, 283
[INFO] 2021-07-12 18:31:01,454 [run_pretraining.py:  535]:	loss/mlm_loss, 9.728797912597656, 283
[INFO] 2021-07-12 18:31:01,454 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8199999633216066e-06, 283
[INFO] 2021-07-12 18:31:01,454 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 283
[INFO] 2021-07-12 18:31:01,454 [run_pretraining.py:  558]:	worker_index: 3, step: 283, cost: 9.728798, mlm loss: 9.728798, speed: 0.918516 steps/s, speed: 7.348128 samples/s, speed: 3762.241433 tokens/s, learning rate: 2.820e-06, loss_scalings: 26214.400391, pp_loss: 9.520004
[INFO] 2021-07-12 18:31:01,454 [run_pretraining.py:  512]:	********exe.run_283******* 
[INFO] 2021-07-12 18:31:02,550 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:02,551 [run_pretraining.py:  534]:	loss/total_loss, 9.433197975158691, 284
[INFO] 2021-07-12 18:31:02,551 [run_pretraining.py:  535]:	loss/mlm_loss, 9.433197975158691, 284
[INFO] 2021-07-12 18:31:02,551 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8299998575676e-06, 284
[INFO] 2021-07-12 18:31:02,551 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 284
[INFO] 2021-07-12 18:31:02,551 [run_pretraining.py:  558]:	worker_index: 3, step: 284, cost: 9.433198, mlm loss: 9.433198, speed: 0.912247 steps/s, speed: 7.297980 samples/s, speed: 3736.565592 tokens/s, learning rate: 2.830e-06, loss_scalings: 26214.400391, pp_loss: 9.478410
[INFO] 2021-07-12 18:31:02,551 [run_pretraining.py:  512]:	********exe.run_284******* 
[INFO] 2021-07-12 18:31:03,639 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:03,640 [run_pretraining.py:  534]:	loss/total_loss, 9.8084077835083, 285
[INFO] 2021-07-12 18:31:03,640 [run_pretraining.py:  535]:	loss/mlm_loss, 9.8084077835083, 285
[INFO] 2021-07-12 18:31:03,640 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8399999791872688e-06, 285
[INFO] 2021-07-12 18:31:03,640 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 285
[INFO] 2021-07-12 18:31:03,640 [run_pretraining.py:  558]:	worker_index: 3, step: 285, cost: 9.808408, mlm loss: 9.808408, speed: 0.918575 steps/s, speed: 7.348596 samples/s, speed: 3762.481203 tokens/s, learning rate: 2.840e-06, loss_scalings: 26214.400391, pp_loss: 8.674338
[INFO] 2021-07-12 18:31:03,640 [run_pretraining.py:  512]:	********exe.run_285******* 
[INFO] 2021-07-12 18:31:04,725 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:04,725 [run_pretraining.py:  534]:	loss/total_loss, 10.097395896911621, 286
[INFO] 2021-07-12 18:31:04,725 [run_pretraining.py:  535]:	loss/mlm_loss, 10.097395896911621, 286
[INFO] 2021-07-12 18:31:04,725 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.849999873433262e-06, 286
[INFO] 2021-07-12 18:31:04,726 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 286
[INFO] 2021-07-12 18:31:04,726 [run_pretraining.py:  558]:	worker_index: 3, step: 286, cost: 10.097396, mlm loss: 10.097396, speed: 0.921734 steps/s, speed: 7.373874 samples/s, speed: 3775.423691 tokens/s, learning rate: 2.850e-06, loss_scalings: 26214.400391, pp_loss: 9.722838
[INFO] 2021-07-12 18:31:04,726 [run_pretraining.py:  512]:	********exe.run_286******* 
[INFO] 2021-07-12 18:31:05,815 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:05,815 [run_pretraining.py:  534]:	loss/total_loss, 9.426506996154785, 287
[INFO] 2021-07-12 18:31:05,815 [run_pretraining.py:  535]:	loss/mlm_loss, 9.426506996154785, 287
[INFO] 2021-07-12 18:31:05,815 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.859999995052931e-06, 287
[INFO] 2021-07-12 18:31:05,815 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 287
[INFO] 2021-07-12 18:31:05,815 [run_pretraining.py:  558]:	worker_index: 3, step: 287, cost: 9.426507, mlm loss: 9.426507, speed: 0.918153 steps/s, speed: 7.345221 samples/s, speed: 3760.753239 tokens/s, learning rate: 2.860e-06, loss_scalings: 26214.400391, pp_loss: 9.558489
[INFO] 2021-07-12 18:31:05,815 [run_pretraining.py:  512]:	********exe.run_287******* 
[INFO] 2021-07-12 18:31:06,907 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:06,907 [run_pretraining.py:  534]:	loss/total_loss, 9.466883659362793, 288
[INFO] 2021-07-12 18:31:06,907 [run_pretraining.py:  535]:	loss/mlm_loss, 9.466883659362793, 288
[INFO] 2021-07-12 18:31:06,908 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8699998892989242e-06, 288
[INFO] 2021-07-12 18:31:06,908 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 288
[INFO] 2021-07-12 18:31:06,908 [run_pretraining.py:  558]:	worker_index: 3, step: 288, cost: 9.466884, mlm loss: 9.466884, speed: 0.916043 steps/s, speed: 7.328346 samples/s, speed: 3752.113405 tokens/s, learning rate: 2.870e-06, loss_scalings: 26214.400391, pp_loss: 9.427147
[INFO] 2021-07-12 18:31:06,908 [run_pretraining.py:  512]:	********exe.run_288******* 
[INFO] 2021-07-12 18:31:08,002 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:08,003 [run_pretraining.py:  534]:	loss/total_loss, 8.670976638793945, 289
[INFO] 2021-07-12 18:31:08,003 [run_pretraining.py:  535]:	loss/mlm_loss, 8.670976638793945, 289
[INFO] 2021-07-12 18:31:08,003 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8799997835449176e-06, 289
[INFO] 2021-07-12 18:31:08,003 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 289
[INFO] 2021-07-12 18:31:08,003 [run_pretraining.py:  558]:	worker_index: 3, step: 289, cost: 8.670977, mlm loss: 8.670977, speed: 0.913618 steps/s, speed: 7.308945 samples/s, speed: 3742.179957 tokens/s, learning rate: 2.880e-06, loss_scalings: 26214.400391, pp_loss: 9.218086
[INFO] 2021-07-12 18:31:08,003 [run_pretraining.py:  512]:	********exe.run_289******* 
[INFO] 2021-07-12 18:31:09,093 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:09,094 [run_pretraining.py:  534]:	loss/total_loss, 9.450162887573242, 290
[INFO] 2021-07-12 18:31:09,094 [run_pretraining.py:  535]:	loss/mlm_loss, 9.450162887573242, 290
[INFO] 2021-07-12 18:31:09,094 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8899999051645864e-06, 290
[INFO] 2021-07-12 18:31:09,094 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 290
[INFO] 2021-07-12 18:31:09,094 [run_pretraining.py:  558]:	worker_index: 3, step: 290, cost: 9.450163, mlm loss: 9.450163, speed: 0.916912 steps/s, speed: 7.335298 samples/s, speed: 3755.672450 tokens/s, learning rate: 2.890e-06, loss_scalings: 26214.400391, pp_loss: 9.431639
[INFO] 2021-07-12 18:31:09,094 [run_pretraining.py:  512]:	********exe.run_290******* 
[INFO] 2021-07-12 18:31:10,173 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:10,173 [run_pretraining.py:  534]:	loss/total_loss, 9.708597183227539, 291
[INFO] 2021-07-12 18:31:10,173 [run_pretraining.py:  535]:	loss/mlm_loss, 9.708597183227539, 291
[INFO] 2021-07-12 18:31:10,173 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8999997994105797e-06, 291
[INFO] 2021-07-12 18:31:10,174 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 291
[INFO] 2021-07-12 18:31:10,174 [run_pretraining.py:  558]:	worker_index: 3, step: 291, cost: 9.708597, mlm loss: 9.708597, speed: 0.926887 steps/s, speed: 7.415093 samples/s, speed: 3796.527804 tokens/s, learning rate: 2.900e-06, loss_scalings: 26214.400391, pp_loss: 9.651955
[INFO] 2021-07-12 18:31:10,174 [run_pretraining.py:  512]:	********exe.run_291******* 
[INFO] 2021-07-12 18:31:11,260 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:11,260 [run_pretraining.py:  534]:	loss/total_loss, 9.641613960266113, 292
[INFO] 2021-07-12 18:31:11,260 [run_pretraining.py:  535]:	loss/mlm_loss, 9.641613960266113, 292
[INFO] 2021-07-12 18:31:11,260 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9099999210302485e-06, 292
[INFO] 2021-07-12 18:31:11,260 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 292
[INFO] 2021-07-12 18:31:11,261 [run_pretraining.py:  558]:	worker_index: 3, step: 292, cost: 9.641614, mlm loss: 9.641614, speed: 0.920557 steps/s, speed: 7.364459 samples/s, speed: 3770.602766 tokens/s, learning rate: 2.910e-06, loss_scalings: 26214.400391, pp_loss: 9.560627
[INFO] 2021-07-12 18:31:11,261 [run_pretraining.py:  512]:	********exe.run_292******* 
[INFO] 2021-07-12 18:31:12,357 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:12,358 [run_pretraining.py:  534]:	loss/total_loss, 9.505897521972656, 293
[INFO] 2021-07-12 18:31:12,358 [run_pretraining.py:  535]:	loss/mlm_loss, 9.505897521972656, 293
[INFO] 2021-07-12 18:31:12,358 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9200000426499173e-06, 293
[INFO] 2021-07-12 18:31:12,358 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 293
[INFO] 2021-07-12 18:31:12,358 [run_pretraining.py:  558]:	worker_index: 3, step: 293, cost: 9.505898, mlm loss: 9.505898, speed: 0.911687 steps/s, speed: 7.293498 samples/s, speed: 3734.271151 tokens/s, learning rate: 2.920e-06, loss_scalings: 26214.400391, pp_loss: 9.524435
[INFO] 2021-07-12 18:31:12,358 [run_pretraining.py:  512]:	********exe.run_293******* 
[INFO] 2021-07-12 18:31:13,441 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:13,442 [run_pretraining.py:  534]:	loss/total_loss, 9.437580108642578, 294
[INFO] 2021-07-12 18:31:13,442 [run_pretraining.py:  535]:	loss/mlm_loss, 9.437580108642578, 294
[INFO] 2021-07-12 18:31:13,442 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9299999368959107e-06, 294
[INFO] 2021-07-12 18:31:13,442 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 294
[INFO] 2021-07-12 18:31:13,442 [run_pretraining.py:  558]:	worker_index: 3, step: 294, cost: 9.437580, mlm loss: 9.437580, speed: 0.923115 steps/s, speed: 7.384917 samples/s, speed: 3781.077299 tokens/s, learning rate: 2.930e-06, loss_scalings: 26214.400391, pp_loss: 9.256269
[INFO] 2021-07-12 18:31:13,442 [run_pretraining.py:  512]:	********exe.run_294******* 
[INFO] 2021-07-12 18:31:14,530 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:14,530 [run_pretraining.py:  534]:	loss/total_loss, 9.58518123626709, 295
[INFO] 2021-07-12 18:31:14,530 [run_pretraining.py:  535]:	loss/mlm_loss, 9.58518123626709, 295
[INFO] 2021-07-12 18:31:14,531 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9400000585155794e-06, 295
[INFO] 2021-07-12 18:31:14,531 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 295
[INFO] 2021-07-12 18:31:14,531 [run_pretraining.py:  558]:	worker_index: 3, step: 295, cost: 9.585181, mlm loss: 9.585181, speed: 0.919051 steps/s, speed: 7.352407 samples/s, speed: 3764.432630 tokens/s, learning rate: 2.940e-06, loss_scalings: 26214.400391, pp_loss: 9.514118
[INFO] 2021-07-12 18:31:14,531 [run_pretraining.py:  512]:	********exe.run_295******* 
[INFO] 2021-07-12 18:31:15,614 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:15,615 [run_pretraining.py:  534]:	loss/total_loss, 9.606247901916504, 296
[INFO] 2021-07-12 18:31:15,615 [run_pretraining.py:  535]:	loss/mlm_loss, 9.606247901916504, 296
[INFO] 2021-07-12 18:31:15,615 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9499999527615728e-06, 296
[INFO] 2021-07-12 18:31:15,615 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 296
[INFO] 2021-07-12 18:31:15,615 [run_pretraining.py:  558]:	worker_index: 3, step: 296, cost: 9.606248, mlm loss: 9.606248, speed: 0.922660 steps/s, speed: 7.381276 samples/s, speed: 3779.213329 tokens/s, learning rate: 2.950e-06, loss_scalings: 26214.400391, pp_loss: 9.581590
[INFO] 2021-07-12 18:31:15,615 [run_pretraining.py:  512]:	********exe.run_296******* 
[INFO] 2021-07-12 18:31:16,702 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:16,703 [run_pretraining.py:  534]:	loss/total_loss, 9.686116218566895, 297
[INFO] 2021-07-12 18:31:16,703 [run_pretraining.py:  535]:	loss/mlm_loss, 9.686116218566895, 297
[INFO] 2021-07-12 18:31:16,703 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.959999847007566e-06, 297
[INFO] 2021-07-12 18:31:16,703 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 297
[INFO] 2021-07-12 18:31:16,703 [run_pretraining.py:  558]:	worker_index: 3, step: 297, cost: 9.686116, mlm loss: 9.686116, speed: 0.919532 steps/s, speed: 7.356260 samples/s, speed: 3766.405074 tokens/s, learning rate: 2.960e-06, loss_scalings: 26214.400391, pp_loss: 9.498165
[INFO] 2021-07-12 18:31:16,703 [run_pretraining.py:  512]:	********exe.run_297******* 
[INFO] 2021-07-12 18:31:42,960 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:42,961 [run_pretraining.py:  534]:	loss/total_loss, 9.478558540344238, 298
[INFO] 2021-07-12 18:31:42,961 [run_pretraining.py:  535]:	loss/mlm_loss, 9.478558540344238, 298
[INFO] 2021-07-12 18:31:42,961 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.969999968627235e-06, 298
[INFO] 2021-07-12 18:31:42,961 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 298
[INFO] 2021-07-12 18:31:42,961 [run_pretraining.py:  558]:	worker_index: 3, step: 298, cost: 9.478559, mlm loss: 9.478559, speed: 0.038085 steps/s, speed: 0.304680 samples/s, speed: 155.996406 tokens/s, learning rate: 2.970e-06, loss_scalings: 26214.400391, pp_loss: 9.648595
[INFO] 2021-07-12 18:31:42,961 [run_pretraining.py:  512]:	********exe.run_298******* 
[INFO] 2021-07-12 18:31:43,909 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:43,910 [run_pretraining.py:  534]:	loss/total_loss, 9.36119270324707, 299
[INFO] 2021-07-12 18:31:43,910 [run_pretraining.py:  535]:	loss/mlm_loss, 9.36119270324707, 299
[INFO] 2021-07-12 18:31:43,910 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9799998628732283e-06, 299
[INFO] 2021-07-12 18:31:43,910 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 299
[INFO] 2021-07-12 18:31:43,910 [run_pretraining.py:  558]:	worker_index: 3, step: 299, cost: 9.361193, mlm loss: 9.361193, speed: 1.054447 steps/s, speed: 8.435575 samples/s, speed: 4319.014489 tokens/s, learning rate: 2.980e-06, loss_scalings: 26214.400391, pp_loss: 9.356649
[INFO] 2021-07-12 18:31:43,910 [run_pretraining.py:  512]:	********exe.run_299******* 
[INFO] 2021-07-12 18:31:44,876 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:44,877 [run_pretraining.py:  534]:	loss/total_loss, 9.479205131530762, 300
[INFO] 2021-07-12 18:31:44,877 [run_pretraining.py:  535]:	loss/mlm_loss, 9.479205131530762, 300
[INFO] 2021-07-12 18:31:44,877 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.989999984492897e-06, 300
[INFO] 2021-07-12 18:31:44,877 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 300
[INFO] 2021-07-12 18:31:44,877 [run_pretraining.py:  558]:	worker_index: 3, step: 300, cost: 9.479205, mlm loss: 9.479205, speed: 1.034798 steps/s, speed: 8.278387 samples/s, speed: 4238.534390 tokens/s, learning rate: 2.990e-06, loss_scalings: 26214.400391, pp_loss: 9.407816
[INFO] 2021-07-12 18:31:44,877 [run_pretraining.py:  512]:	********exe.run_300******* 
[INFO] 2021-07-12 18:31:45,778 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:45,778 [run_pretraining.py:  534]:	loss/total_loss, 9.328191757202148, 301
[INFO] 2021-07-12 18:31:45,778 [run_pretraining.py:  535]:	loss/mlm_loss, 9.328191757202148, 301
[INFO] 2021-07-12 18:31:45,779 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9999998787388904e-06, 301
[INFO] 2021-07-12 18:31:45,779 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 301
[INFO] 2021-07-12 18:31:45,779 [run_pretraining.py:  558]:	worker_index: 3, step: 301, cost: 9.328192, mlm loss: 9.328192, speed: 1.109913 steps/s, speed: 8.879303 samples/s, speed: 4546.202974 tokens/s, learning rate: 3.000e-06, loss_scalings: 26214.400391, pp_loss: 9.399340
[INFO] 2021-07-12 18:31:45,779 [run_pretraining.py:  512]:	********exe.run_301******* 
[INFO] 2021-07-12 18:31:46,709 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:46,709 [run_pretraining.py:  534]:	loss/total_loss, 9.516843795776367, 302
[INFO] 2021-07-12 18:31:46,710 [run_pretraining.py:  535]:	loss/mlm_loss, 9.516843795776367, 302
[INFO] 2021-07-12 18:31:46,710 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.0099997729848837e-06, 302
[INFO] 2021-07-12 18:31:46,710 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 302
[INFO] 2021-07-12 18:31:46,710 [run_pretraining.py:  558]:	worker_index: 3, step: 302, cost: 9.516844, mlm loss: 9.516844, speed: 1.074723 steps/s, speed: 8.597788 samples/s, speed: 4402.067395 tokens/s, learning rate: 3.010e-06, loss_scalings: 26214.400391, pp_loss: 9.441715
[INFO] 2021-07-12 18:31:46,710 [run_pretraining.py:  512]:	********exe.run_302******* 
[INFO] 2021-07-12 18:31:47,613 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:47,614 [run_pretraining.py:  534]:	loss/total_loss, 9.374094009399414, 303
[INFO] 2021-07-12 18:31:47,614 [run_pretraining.py:  535]:	loss/mlm_loss, 9.374094009399414, 303
[INFO] 2021-07-12 18:31:47,614 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.020000121978228e-06, 303
[INFO] 2021-07-12 18:31:47,614 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 303
[INFO] 2021-07-12 18:31:47,614 [run_pretraining.py:  558]:	worker_index: 3, step: 303, cost: 9.374094, mlm loss: 9.374094, speed: 1.106620 steps/s, speed: 8.852964 samples/s, speed: 4532.717388 tokens/s, learning rate: 3.020e-06, loss_scalings: 26214.400391, pp_loss: 9.386614
[INFO] 2021-07-12 18:31:47,614 [run_pretraining.py:  512]:	********exe.run_303******* 
[INFO] 2021-07-12 18:31:48,529 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:48,530 [run_pretraining.py:  534]:	loss/total_loss, 9.34347152709961, 304
[INFO] 2021-07-12 18:31:48,530 [run_pretraining.py:  535]:	loss/mlm_loss, 9.34347152709961, 304
[INFO] 2021-07-12 18:31:48,530 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.0300000162242213e-06, 304
[INFO] 2021-07-12 18:31:48,530 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 304
[INFO] 2021-07-12 18:31:48,530 [run_pretraining.py:  558]:	worker_index: 3, step: 304, cost: 9.343472, mlm loss: 9.343472, speed: 1.092343 steps/s, speed: 8.738748 samples/s, speed: 4474.238862 tokens/s, learning rate: 3.030e-06, loss_scalings: 26214.400391, pp_loss: 9.379386
[INFO] 2021-07-12 18:31:48,530 [run_pretraining.py:  512]:	********exe.run_304******* 
[INFO] 2021-07-12 18:31:49,441 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:49,441 [run_pretraining.py:  534]:	loss/total_loss, 9.469715118408203, 305
[INFO] 2021-07-12 18:31:49,441 [run_pretraining.py:  535]:	loss/mlm_loss, 9.469715118408203, 305
[INFO] 2021-07-12 18:31:49,441 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.0399999104702147e-06, 305
[INFO] 2021-07-12 18:31:49,441 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 305
[INFO] 2021-07-12 18:31:49,441 [run_pretraining.py:  558]:	worker_index: 3, step: 305, cost: 9.469715, mlm loss: 9.469715, speed: 1.098125 steps/s, speed: 8.784998 samples/s, speed: 4497.919025 tokens/s, learning rate: 3.040e-06, loss_scalings: 26214.400391, pp_loss: 9.537323
[INFO] 2021-07-12 18:31:49,441 [run_pretraining.py:  512]:	********exe.run_305******* 
[INFO] 2021-07-12 18:31:50,353 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:50,354 [run_pretraining.py:  534]:	loss/total_loss, 9.278923034667969, 306
[INFO] 2021-07-12 18:31:50,354 [run_pretraining.py:  535]:	loss/mlm_loss, 9.278923034667969, 306
[INFO] 2021-07-12 18:31:50,354 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.0500000320898835e-06, 306
[INFO] 2021-07-12 18:31:50,354 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 306
[INFO] 2021-07-12 18:31:50,354 [run_pretraining.py:  558]:	worker_index: 3, step: 306, cost: 9.278923, mlm loss: 9.278923, speed: 1.096345 steps/s, speed: 8.770761 samples/s, speed: 4490.629643 tokens/s, learning rate: 3.050e-06, loss_scalings: 26214.400391, pp_loss: 9.393383
[INFO] 2021-07-12 18:31:50,354 [run_pretraining.py:  512]:	********exe.run_306******* 
[INFO] 2021-07-12 18:31:51,260 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:51,261 [run_pretraining.py:  534]:	loss/total_loss, 9.527641296386719, 307
[INFO] 2021-07-12 18:31:51,261 [run_pretraining.py:  535]:	loss/mlm_loss, 9.527641296386719, 307
[INFO] 2021-07-12 18:31:51,261 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.059999926335877e-06, 307
[INFO] 2021-07-12 18:31:51,261 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 307
[INFO] 2021-07-12 18:31:51,261 [run_pretraining.py:  558]:	worker_index: 3, step: 307, cost: 9.527641, mlm loss: 9.527641, speed: 1.103496 steps/s, speed: 8.827967 samples/s, speed: 4519.919152 tokens/s, learning rate: 3.060e-06, loss_scalings: 26214.400391, pp_loss: 8.680504
[INFO] 2021-07-12 18:31:51,261 [run_pretraining.py:  512]:	********exe.run_307******* 
[INFO] 2021-07-12 18:31:52,176 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:52,176 [run_pretraining.py:  534]:	loss/total_loss, 9.868502616882324, 308
[INFO] 2021-07-12 18:31:52,176 [run_pretraining.py:  535]:	loss/mlm_loss, 9.868502616882324, 308
[INFO] 2021-07-12 18:31:52,176 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.06999982058187e-06, 308
[INFO] 2021-07-12 18:31:52,176 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 308
[INFO] 2021-07-12 18:31:52,177 [run_pretraining.py:  558]:	worker_index: 3, step: 308, cost: 9.868503, mlm loss: 9.868503, speed: 1.093019 steps/s, speed: 8.744149 samples/s, speed: 4477.004539 tokens/s, learning rate: 3.070e-06, loss_scalings: 26214.400391, pp_loss: 9.657037
[INFO] 2021-07-12 18:31:52,177 [run_pretraining.py:  512]:	********exe.run_308******* 
[INFO] 2021-07-12 18:31:53,088 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:53,088 [run_pretraining.py:  534]:	loss/total_loss, 9.25000286102295, 309
[INFO] 2021-07-12 18:31:53,088 [run_pretraining.py:  535]:	loss/mlm_loss, 9.25000286102295, 309
[INFO] 2021-07-12 18:31:53,088 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.079999942201539e-06, 309
[INFO] 2021-07-12 18:31:53,088 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 309
[INFO] 2021-07-12 18:31:53,088 [run_pretraining.py:  558]:	worker_index: 3, step: 309, cost: 9.250003, mlm loss: 9.250003, speed: 1.097408 steps/s, speed: 8.779268 samples/s, speed: 4494.985145 tokens/s, learning rate: 3.080e-06, loss_scalings: 26214.400391, pp_loss: 9.685331
[INFO] 2021-07-12 18:31:53,089 [run_pretraining.py:  512]:	********exe.run_309******* 
[INFO] 2021-07-12 18:32:18,917 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:32:18,918 [run_pretraining.py:  534]:	loss/total_loss, 9.517139434814453, 310
[INFO] 2021-07-12 18:32:18,918 [run_pretraining.py:  535]:	loss/mlm_loss, 9.517139434814453, 310
[INFO] 2021-07-12 18:32:18,918 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.0899998364475323e-06, 310
[INFO] 2021-07-12 18:32:18,918 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 310
[INFO] 2021-07-12 18:32:18,918 [run_pretraining.py:  558]:	worker_index: 3, step: 310, cost: 9.517139, mlm loss: 9.517139, speed: 0.038716 steps/s, speed: 0.309731 samples/s, speed: 158.582518 tokens/s, learning rate: 3.090e-06, loss_scalings: 26214.400391, pp_loss: 9.405947
[INFO] 2021-07-12 18:32:18,918 [run_pretraining.py:  512]:	********exe.run_310******* 
[INFO] 2021-07-12 18:32:19,822 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:32:19,823 [run_pretraining.py:  534]:	loss/total_loss, 9.385425567626953, 311
[INFO] 2021-07-12 18:32:19,823 [run_pretraining.py:  535]:	loss/mlm_loss, 9.385425567626953, 311
[INFO] 2021-07-12 18:32:19,823 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.099999958067201e-06, 311
[INFO] 2021-07-12 18:32:19,823 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 311
[INFO] 2021-07-12 18:32:19,823 [run_pretraining.py:  558]:	worker_index: 3, step: 311, cost: 9.385426, mlm loss: 9.385426, speed: 1.105670 steps/s, speed: 8.845360 samples/s, speed: 4528.824470 tokens/s, learning rate: 3.100e-06, loss_scalings: 26214.400391, pp_loss: 9.248711
[INFO] 2021-07-12 18:32:19,823 [run_pretraining.py:  512]:	********exe.run_311******* 
[INFO] 2021-07-12 18:32:20,738 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:32:20,739 [run_pretraining.py:  534]:	loss/total_loss, 9.157866477966309, 312
[INFO] 2021-07-12 18:32:20,739 [run_pretraining.py:  535]:	loss/mlm_loss, 9.157866477966309, 312
[INFO] 2021-07-12 18:32:20,739 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.1099998523131944e-06, 312
[INFO] 2021-07-12 18:32:20,739 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 312
[INFO] 2021-07-12 18:32:20,739 [run_pretraining.py:  558]:	worker_index: 3, step: 312, cost: 9.157866, mlm loss: 9.157866, speed: 1.092311 steps/s, speed: 8.738491 samples/s, speed: 4474.107192 tokens/s, learning rate: 3.110e-06, loss_scalings: 26214.400391, pp_loss: 9.628202
[INFO] 2021-07-12 18:32:20,739 [run_pretraining.py:  512]:	********exe.run_312******* 
[INFO] 2021-07-12 18:32:21,654 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:32:21,655 [run_pretraining.py:  534]:	loss/total_loss, 9.112051963806152, 313
[INFO] 2021-07-12 18:32:21,655 [run_pretraining.py:  535]:	loss/mlm_loss, 9.112051963806152, 313
[INFO] 2021-07-12 18:32:21,655 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.1199997465591878e-06, 313
[INFO] 2021-07-12 18:32:21,655 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 313
[INFO] 2021-07-12 18:32:21,655 [run_pretraining.py:  558]:	worker_index: 3, step: 313, cost: 9.112052, mlm loss: 9.112052, speed: 1.092462 steps/s, speed: 8.739692 samples/s, speed: 4474.722492 tokens/s, learning rate: 3.120e-06, loss_scalings: 26214.400391, pp_loss: 9.405470
[INFO] 2021-07-12 18:32:21,655 [run_pretraining.py:  512]:	********exe.run_313******* 
[INFO] 2021-07-12 18:32:48,141 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:32:48,141 [run_pretraining.py:  534]:	loss/total_loss, 9.27973461151123, 314
[INFO] 2021-07-12 18:32:48,141 [run_pretraining.py:  535]:	loss/mlm_loss, 9.27973461151123, 314
[INFO] 2021-07-12 18:32:48,142 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.130000095552532e-06, 314
[INFO] 2021-07-12 18:32:48,142 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 314
[INFO] 2021-07-12 18:32:48,142 [run_pretraining.py:  558]:	worker_index: 3, step: 314, cost: 9.279735, mlm loss: 9.279735, speed: 0.037756 steps/s, speed: 0.302048 samples/s, speed: 154.648363 tokens/s, learning rate: 3.130e-06, loss_scalings: 26214.400391, pp_loss: 9.474959
[INFO] 2021-07-12 18:32:48,142 [run_pretraining.py:  512]:	********exe.run_314******* 
[INFO] 2021-07-12 18:33:14,248 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:14,248 [run_pretraining.py:  534]:	loss/total_loss, 9.574243545532227, 315
[INFO] 2021-07-12 18:33:14,248 [run_pretraining.py:  535]:	loss/mlm_loss, 9.574243545532227, 315
[INFO] 2021-07-12 18:33:14,248 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.13999976242485e-06, 315
[INFO] 2021-07-12 18:33:14,248 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 315
[INFO] 2021-07-12 18:33:14,248 [run_pretraining.py:  558]:	worker_index: 3, step: 315, cost: 9.574244, mlm loss: 9.574244, speed: 0.038305 steps/s, speed: 0.306441 samples/s, speed: 156.897591 tokens/s, learning rate: 3.140e-06, loss_scalings: 26214.400391, pp_loss: 9.412746
[INFO] 2021-07-12 18:33:14,249 [run_pretraining.py:  512]:	********exe.run_315******* 
[INFO] 2021-07-12 18:33:15,181 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:15,182 [run_pretraining.py:  534]:	loss/total_loss, 9.859419822692871, 316
[INFO] 2021-07-12 18:33:15,182 [run_pretraining.py:  535]:	loss/mlm_loss, 9.859419822692871, 316
[INFO] 2021-07-12 18:33:15,182 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.1499998840445187e-06, 316
[INFO] 2021-07-12 18:33:15,182 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 316
[INFO] 2021-07-12 18:33:15,182 [run_pretraining.py:  558]:	worker_index: 3, step: 316, cost: 9.859420, mlm loss: 9.859420, speed: 1.071515 steps/s, speed: 8.572122 samples/s, speed: 4388.926532 tokens/s, learning rate: 3.150e-06, loss_scalings: 26214.400391, pp_loss: 8.571457
[INFO] 2021-07-12 18:33:15,182 [run_pretraining.py:  512]:	********exe.run_316******* 
[INFO] 2021-07-12 18:33:16,098 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:16,099 [run_pretraining.py:  534]:	loss/total_loss, 9.485065460205078, 317
[INFO] 2021-07-12 18:33:16,099 [run_pretraining.py:  535]:	loss/mlm_loss, 9.485065460205078, 317
[INFO] 2021-07-12 18:33:16,099 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.159999778290512e-06, 317
[INFO] 2021-07-12 18:33:16,099 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 317
[INFO] 2021-07-12 18:33:16,099 [run_pretraining.py:  558]:	worker_index: 3, step: 317, cost: 9.485065, mlm loss: 9.485065, speed: 1.091662 steps/s, speed: 8.733296 samples/s, speed: 4471.447504 tokens/s, learning rate: 3.160e-06, loss_scalings: 26214.400391, pp_loss: 9.382149
[INFO] 2021-07-12 18:33:16,099 [run_pretraining.py:  512]:	********exe.run_317******* 
[INFO] 2021-07-12 18:33:17,011 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:17,012 [run_pretraining.py:  534]:	loss/total_loss, 7.174595355987549, 318
[INFO] 2021-07-12 18:33:17,012 [run_pretraining.py:  535]:	loss/mlm_loss, 7.174595355987549, 318
[INFO] 2021-07-12 18:33:17,012 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.169999899910181e-06, 318
[INFO] 2021-07-12 18:33:17,012 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 318
[INFO] 2021-07-12 18:33:17,012 [run_pretraining.py:  558]:	worker_index: 3, step: 318, cost: 7.174595, mlm loss: 7.174595, speed: 1.095758 steps/s, speed: 8.766061 samples/s, speed: 4488.223466 tokens/s, learning rate: 3.170e-06, loss_scalings: 26214.400391, pp_loss: 8.876986
[INFO] 2021-07-12 18:33:17,012 [run_pretraining.py:  512]:	********exe.run_318******* 
[INFO] 2021-07-12 18:33:17,918 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:17,919 [run_pretraining.py:  534]:	loss/total_loss, 9.379053115844727, 319
[INFO] 2021-07-12 18:33:17,919 [run_pretraining.py:  535]:	loss/mlm_loss, 9.379053115844727, 319
[INFO] 2021-07-12 18:33:17,919 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.1800000215298496e-06, 319
[INFO] 2021-07-12 18:33:17,919 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 319
[INFO] 2021-07-12 18:33:17,919 [run_pretraining.py:  558]:	worker_index: 3, step: 319, cost: 9.379053, mlm loss: 9.379053, speed: 1.103509 steps/s, speed: 8.828074 samples/s, speed: 4519.973854 tokens/s, learning rate: 3.180e-06, loss_scalings: 26214.400391, pp_loss: 9.365442
[INFO] 2021-07-12 18:33:17,919 [run_pretraining.py:  512]:	********exe.run_319******* 
[INFO] 2021-07-12 18:33:18,831 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:18,831 [run_pretraining.py:  534]:	loss/total_loss, 9.62299919128418, 320
[INFO] 2021-07-12 18:33:18,831 [run_pretraining.py:  535]:	loss/mlm_loss, 9.62299919128418, 320
[INFO] 2021-07-12 18:33:18,831 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.189999915775843e-06, 320
[INFO] 2021-07-12 18:33:18,831 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 320
[INFO] 2021-07-12 18:33:18,831 [run_pretraining.py:  558]:	worker_index: 3, step: 320, cost: 9.622999, mlm loss: 9.622999, speed: 1.096919 steps/s, speed: 8.775353 samples/s, speed: 4492.980824 tokens/s, learning rate: 3.190e-06, loss_scalings: 26214.400391, pp_loss: 9.429033
[INFO] 2021-07-12 18:33:18,831 [run_pretraining.py:  512]:	********exe.run_320******* 
[INFO] 2021-07-12 18:33:19,752 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:19,753 [run_pretraining.py:  534]:	loss/total_loss, 9.193177223205566, 321
[INFO] 2021-07-12 18:33:19,753 [run_pretraining.py:  535]:	loss/mlm_loss, 9.193177223205566, 321
[INFO] 2021-07-12 18:33:19,753 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.2000000373955118e-06, 321
[INFO] 2021-07-12 18:33:19,753 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 321
[INFO] 2021-07-12 18:33:19,753 [run_pretraining.py:  558]:	worker_index: 3, step: 321, cost: 9.193177, mlm loss: 9.193177, speed: 1.085942 steps/s, speed: 8.687535 samples/s, speed: 4448.018037 tokens/s, learning rate: 3.200e-06, loss_scalings: 26214.400391, pp_loss: 8.334732
[INFO] 2021-07-12 18:33:19,753 [run_pretraining.py:  512]:	********exe.run_321******* 
[INFO] 2021-07-12 18:33:20,661 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:20,662 [run_pretraining.py:  534]:	loss/total_loss, 9.636707305908203, 322
[INFO] 2021-07-12 18:33:20,662 [run_pretraining.py:  535]:	loss/mlm_loss, 9.636707305908203, 322
[INFO] 2021-07-12 18:33:20,662 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.209999931641505e-06, 322
[INFO] 2021-07-12 18:33:20,662 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 322
[INFO] 2021-07-12 18:33:20,662 [run_pretraining.py:  558]:	worker_index: 3, step: 322, cost: 9.636707, mlm loss: 9.636707, speed: 1.100769 steps/s, speed: 8.806149 samples/s, speed: 4508.748478 tokens/s, learning rate: 3.210e-06, loss_scalings: 26214.400391, pp_loss: 9.439018
[INFO] 2021-07-12 18:33:20,662 [run_pretraining.py:  512]:	********exe.run_322******* 
[INFO] 2021-07-12 18:33:21,568 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:21,569 [run_pretraining.py:  534]:	loss/total_loss, 9.424423217773438, 323
[INFO] 2021-07-12 18:33:21,569 [run_pretraining.py:  535]:	loss/mlm_loss, 9.424423217773438, 323
[INFO] 2021-07-12 18:33:21,569 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.220000053261174e-06, 323
[INFO] 2021-07-12 18:33:21,569 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 323
[INFO] 2021-07-12 18:33:21,569 [run_pretraining.py:  558]:	worker_index: 3, step: 323, cost: 9.424423, mlm loss: 9.424423, speed: 1.102851 steps/s, speed: 8.822809 samples/s, speed: 4517.278375 tokens/s, learning rate: 3.220e-06, loss_scalings: 26214.400391, pp_loss: 9.395269
[INFO] 2021-07-12 18:33:21,569 [run_pretraining.py:  512]:	********exe.run_323******* 
[INFO] 2021-07-12 18:33:22,480 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:22,481 [run_pretraining.py:  534]:	loss/total_loss, 9.295398712158203, 324
[INFO] 2021-07-12 18:33:22,481 [run_pretraining.py:  535]:	loss/mlm_loss, 9.295398712158203, 324
[INFO] 2021-07-12 18:33:22,481 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.229999720133492e-06, 324
[INFO] 2021-07-12 18:33:22,481 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 324
[INFO] 2021-07-12 18:33:22,481 [run_pretraining.py:  558]:	worker_index: 3, step: 324, cost: 9.295399, mlm loss: 9.295399, speed: 1.097389 steps/s, speed: 8.779114 samples/s, speed: 4494.906349 tokens/s, learning rate: 3.230e-06, loss_scalings: 26214.400391, pp_loss: 9.328144
[INFO] 2021-07-12 18:33:22,481 [run_pretraining.py:  512]:	********exe.run_324******* 
[INFO] 2021-07-12 18:33:23,400 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:23,401 [run_pretraining.py:  534]:	loss/total_loss, 9.519268989562988, 325
[INFO] 2021-07-12 18:33:23,401 [run_pretraining.py:  535]:	loss/mlm_loss, 9.519268989562988, 325
[INFO] 2021-07-12 18:33:23,401 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.240000069126836e-06, 325
[INFO] 2021-07-12 18:33:23,401 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 325
[INFO] 2021-07-12 18:33:23,401 [run_pretraining.py:  558]:	worker_index: 3, step: 325, cost: 9.519269, mlm loss: 9.519269, speed: 1.087831 steps/s, speed: 8.702650 samples/s, speed: 4455.756615 tokens/s, learning rate: 3.240e-06, loss_scalings: 26214.400391, pp_loss: 9.151509
[INFO] 2021-07-12 18:33:23,401 [run_pretraining.py:  512]:	********exe.run_325******* 
[INFO] 2021-07-12 18:33:49,767 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:49,767 [run_pretraining.py:  534]:	loss/total_loss, 9.265142440795898, 326
[INFO] 2021-07-12 18:33:49,767 [run_pretraining.py:  535]:	loss/mlm_loss, 9.265142440795898, 326
[INFO] 2021-07-12 18:33:49,767 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.249999735999154e-06, 326
[INFO] 2021-07-12 18:33:49,767 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 326
[INFO] 2021-07-12 18:33:49,767 [run_pretraining.py:  558]:	worker_index: 3, step: 326, cost: 9.265142, mlm loss: 9.265142, speed: 0.037928 steps/s, speed: 0.303425 samples/s, speed: 155.353499 tokens/s, learning rate: 3.250e-06, loss_scalings: 20971.521484, pp_loss: 9.546122
[INFO] 2021-07-12 18:33:49,768 [run_pretraining.py:  512]:	********exe.run_326******* 
[INFO] 2021-07-12 18:33:50,695 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:50,696 [run_pretraining.py:  534]:	loss/total_loss, 9.437474250793457, 327
[INFO] 2021-07-12 18:33:50,696 [run_pretraining.py:  535]:	loss/mlm_loss, 9.437474250793457, 327
[INFO] 2021-07-12 18:33:50,696 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.2599998576188227e-06, 327
[INFO] 2021-07-12 18:33:50,696 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 327
[INFO] 2021-07-12 18:33:50,696 [run_pretraining.py:  558]:	worker_index: 3, step: 327, cost: 9.437474, mlm loss: 9.437474, speed: 1.077499 steps/s, speed: 8.619995 samples/s, speed: 4413.437191 tokens/s, learning rate: 3.260e-06, loss_scalings: 20971.521484, pp_loss: 9.320409
[INFO] 2021-07-12 18:33:50,696 [run_pretraining.py:  512]:	********exe.run_327******* 
[INFO] 2021-07-12 18:33:51,620 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:51,621 [run_pretraining.py:  534]:	loss/total_loss, 9.5419282913208, 328
[INFO] 2021-07-12 18:33:51,621 [run_pretraining.py:  535]:	loss/mlm_loss, 9.5419282913208, 328
[INFO] 2021-07-12 18:33:51,621 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.269999751864816e-06, 328
[INFO] 2021-07-12 18:33:51,621 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 328
[INFO] 2021-07-12 18:33:51,621 [run_pretraining.py:  558]:	worker_index: 3, step: 328, cost: 9.541928, mlm loss: 9.541928, speed: 1.082055 steps/s, speed: 8.656440 samples/s, speed: 4432.097501 tokens/s, learning rate: 3.270e-06, loss_scalings: 20971.521484, pp_loss: 9.446474
[INFO] 2021-07-12 18:33:51,621 [run_pretraining.py:  512]:	********exe.run_328******* 
[INFO] 2021-07-12 18:33:52,555 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:52,555 [run_pretraining.py:  534]:	loss/total_loss, 9.109193801879883, 329
[INFO] 2021-07-12 18:33:52,555 [run_pretraining.py:  535]:	loss/mlm_loss, 9.109193801879883, 329
[INFO] 2021-07-12 18:33:52,555 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.279999873484485e-06, 329
[INFO] 2021-07-12 18:33:52,555 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 329
[INFO] 2021-07-12 18:33:52,555 [run_pretraining.py:  558]:	worker_index: 3, step: 329, cost: 9.109194, mlm loss: 9.109194, speed: 1.070819 steps/s, speed: 8.566548 samples/s, speed: 4386.072603 tokens/s, learning rate: 3.280e-06, loss_scalings: 20971.521484, pp_loss: 9.291151
[INFO] 2021-07-12 18:33:52,556 [run_pretraining.py:  512]:	********exe.run_329******* 
[INFO] 2021-07-12 18:33:53,485 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:53,486 [run_pretraining.py:  534]:	loss/total_loss, 9.628952026367188, 330
[INFO] 2021-07-12 18:33:53,486 [run_pretraining.py:  535]:	loss/mlm_loss, 9.628952026367188, 330
[INFO] 2021-07-12 18:33:53,486 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.2899999951041536e-06, 330
[INFO] 2021-07-12 18:33:53,486 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 330
[INFO] 2021-07-12 18:33:53,486 [run_pretraining.py:  558]:	worker_index: 3, step: 330, cost: 9.628952, mlm loss: 9.628952, speed: 1.075482 steps/s, speed: 8.603855 samples/s, speed: 4405.173730 tokens/s, learning rate: 3.290e-06, loss_scalings: 20971.521484, pp_loss: 9.473772
[INFO] 2021-07-12 18:33:53,486 [run_pretraining.py:  512]:	********exe.run_330******* 
[INFO] 2021-07-12 18:33:54,416 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:54,416 [run_pretraining.py:  534]:	loss/total_loss, 9.650795936584473, 331
[INFO] 2021-07-12 18:33:54,416 [run_pretraining.py:  535]:	loss/mlm_loss, 9.650795936584473, 331
[INFO] 2021-07-12 18:33:54,416 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.299999889350147e-06, 331
[INFO] 2021-07-12 18:33:54,416 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 331
[INFO] 2021-07-12 18:33:54,416 [run_pretraining.py:  558]:	worker_index: 3, step: 331, cost: 9.650796, mlm loss: 9.650796, speed: 1.075397 steps/s, speed: 8.603178 samples/s, speed: 4404.826985 tokens/s, learning rate: 3.300e-06, loss_scalings: 20971.521484, pp_loss: 9.499023
[INFO] 2021-07-12 18:33:54,417 [run_pretraining.py:  512]:	********exe.run_331******* 
[INFO] 2021-07-12 18:33:55,347 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:55,348 [run_pretraining.py:  534]:	loss/total_loss, 9.595980644226074, 332
[INFO] 2021-07-12 18:33:55,348 [run_pretraining.py:  535]:	loss/mlm_loss, 9.595980644226074, 332
[INFO] 2021-07-12 18:33:55,348 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.3100000109698158e-06, 332
[INFO] 2021-07-12 18:33:55,348 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 332
[INFO] 2021-07-12 18:33:55,348 [run_pretraining.py:  558]:	worker_index: 3, step: 332, cost: 9.595981, mlm loss: 9.595981, speed: 1.073935 steps/s, speed: 8.591481 samples/s, speed: 4398.838161 tokens/s, learning rate: 3.310e-06, loss_scalings: 20971.521484, pp_loss: 9.285246
[INFO] 2021-07-12 18:33:55,348 [run_pretraining.py:  512]:	********exe.run_332******* 
[INFO] 2021-07-12 18:33:56,273 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:56,274 [run_pretraining.py:  534]:	loss/total_loss, 9.541160583496094, 333
[INFO] 2021-07-12 18:33:56,274 [run_pretraining.py:  535]:	loss/mlm_loss, 9.541160583496094, 333
[INFO] 2021-07-12 18:33:56,274 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.319999905215809e-06, 333
[INFO] 2021-07-12 18:33:56,274 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 333
[INFO] 2021-07-12 18:33:56,274 [run_pretraining.py:  558]:	worker_index: 3, step: 333, cost: 9.541161, mlm loss: 9.541161, speed: 1.081059 steps/s, speed: 8.648471 samples/s, speed: 4428.017031 tokens/s, learning rate: 3.320e-06, loss_scalings: 20971.521484, pp_loss: 9.358180
[INFO] 2021-07-12 18:33:56,274 [run_pretraining.py:  512]:	********exe.run_333******* 
[INFO] 2021-07-12 18:33:57,202 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:57,202 [run_pretraining.py:  534]:	loss/total_loss, 9.440187454223633, 334
[INFO] 2021-07-12 18:33:57,202 [run_pretraining.py:  535]:	loss/mlm_loss, 9.440187454223633, 334
[INFO] 2021-07-12 18:33:57,202 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.330000026835478e-06, 334
[INFO] 2021-07-12 18:33:57,202 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 334
[INFO] 2021-07-12 18:33:57,202 [run_pretraining.py:  558]:	worker_index: 3, step: 334, cost: 9.440187, mlm loss: 9.440187, speed: 1.077686 steps/s, speed: 8.621492 samples/s, speed: 4414.203768 tokens/s, learning rate: 3.330e-06, loss_scalings: 20971.521484, pp_loss: 9.460566
[INFO] 2021-07-12 18:33:57,202 [run_pretraining.py:  512]:	********exe.run_334******* 
[INFO] 2021-07-12 18:33:58,134 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:58,134 [run_pretraining.py:  534]:	loss/total_loss, 8.922893524169922, 335
[INFO] 2021-07-12 18:33:58,134 [run_pretraining.py:  535]:	loss/mlm_loss, 8.922893524169922, 335
[INFO] 2021-07-12 18:33:58,134 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.3399999210814713e-06, 335
[INFO] 2021-07-12 18:33:58,134 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 335
[INFO] 2021-07-12 18:33:58,134 [run_pretraining.py:  558]:	worker_index: 3, step: 335, cost: 8.922894, mlm loss: 8.922894, speed: 1.073614 steps/s, speed: 8.588912 samples/s, speed: 4397.523030 tokens/s, learning rate: 3.340e-06, loss_scalings: 20971.521484, pp_loss: 9.347290
[INFO] 2021-07-12 18:33:58,135 [run_pretraining.py:  512]:	********exe.run_335******* 
[INFO] 2021-07-12 18:33:59,057 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:59,058 [run_pretraining.py:  534]:	loss/total_loss, 9.231216430664062, 336
[INFO] 2021-07-12 18:33:59,058 [run_pretraining.py:  535]:	loss/mlm_loss, 9.231216430664062, 336
[INFO] 2021-07-12 18:33:59,058 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.35000004270114e-06, 336
[INFO] 2021-07-12 18:33:59,058 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 336
[INFO] 2021-07-12 18:33:59,058 [run_pretraining.py:  558]:	worker_index: 3, step: 336, cost: 9.231216, mlm loss: 9.231216, speed: 1.083129 steps/s, speed: 8.665029 samples/s, speed: 4436.494808 tokens/s, learning rate: 3.350e-06, loss_scalings: 20971.521484, pp_loss: 9.520772
[INFO] 2021-07-12 18:33:59,058 [run_pretraining.py:  512]:	********exe.run_336******* 
[INFO] 2021-07-12 18:33:59,979 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:59,980 [run_pretraining.py:  534]:	loss/total_loss, 9.42274284362793, 337
[INFO] 2021-07-12 18:33:59,980 [run_pretraining.py:  535]:	loss/mlm_loss, 9.42274284362793, 337
[INFO] 2021-07-12 18:33:59,980 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.359999709573458e-06, 337
[INFO] 2021-07-12 18:33:59,980 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 337
[INFO] 2021-07-12 18:33:59,980 [run_pretraining.py:  558]:	worker_index: 3, step: 337, cost: 9.422743, mlm loss: 9.422743, speed: 1.085844 steps/s, speed: 8.686748 samples/s, speed: 4447.615002 tokens/s, learning rate: 3.360e-06, loss_scalings: 20971.521484, pp_loss: 9.261608
[INFO] 2021-07-12 18:33:59,980 [run_pretraining.py:  512]:	********exe.run_337******* 
[INFO] 2021-07-12 18:34:00,909 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:00,910 [run_pretraining.py:  534]:	loss/total_loss, 9.18364143371582, 338
[INFO] 2021-07-12 18:34:00,910 [run_pretraining.py:  535]:	loss/mlm_loss, 9.18364143371582, 338
[INFO] 2021-07-12 18:34:00,910 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.370000058566802e-06, 338
[INFO] 2021-07-12 18:34:00,910 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 338
[INFO] 2021-07-12 18:34:00,910 [run_pretraining.py:  558]:	worker_index: 3, step: 338, cost: 9.183641, mlm loss: 9.183641, speed: 1.075711 steps/s, speed: 8.605691 samples/s, speed: 4406.113718 tokens/s, learning rate: 3.370e-06, loss_scalings: 20971.521484, pp_loss: 9.243402
[INFO] 2021-07-12 18:34:00,910 [run_pretraining.py:  512]:	********exe.run_338******* 
[INFO] 2021-07-12 18:34:01,834 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:01,834 [run_pretraining.py:  534]:	loss/total_loss, 9.087757110595703, 339
[INFO] 2021-07-12 18:34:01,834 [run_pretraining.py:  535]:	loss/mlm_loss, 9.087757110595703, 339
[INFO] 2021-07-12 18:34:01,834 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.37999972543912e-06, 339
[INFO] 2021-07-12 18:34:01,835 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 339
[INFO] 2021-07-12 18:34:01,835 [run_pretraining.py:  558]:	worker_index: 3, step: 339, cost: 9.087757, mlm loss: 9.087757, speed: 1.082452 steps/s, speed: 8.659613 samples/s, speed: 4433.721726 tokens/s, learning rate: 3.380e-06, loss_scalings: 20971.521484, pp_loss: 9.433753
[INFO] 2021-07-12 18:34:01,835 [run_pretraining.py:  512]:	********exe.run_339******* 
[INFO] 2021-07-12 18:34:02,763 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:02,764 [run_pretraining.py:  534]:	loss/total_loss, 9.35154914855957, 340
[INFO] 2021-07-12 18:34:02,764 [run_pretraining.py:  535]:	loss/mlm_loss, 9.35154914855957, 340
[INFO] 2021-07-12 18:34:02,764 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.389999847058789e-06, 340
[INFO] 2021-07-12 18:34:02,764 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 340
[INFO] 2021-07-12 18:34:02,764 [run_pretraining.py:  558]:	worker_index: 3, step: 340, cost: 9.351549, mlm loss: 9.351549, speed: 1.076612 steps/s, speed: 8.612892 samples/s, speed: 4409.800711 tokens/s, learning rate: 3.390e-06, loss_scalings: 20971.521484, pp_loss: 9.317890
[INFO] 2021-07-12 18:34:02,764 [run_pretraining.py:  512]:	********exe.run_340******* 
[INFO] 2021-07-12 18:34:03,679 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:03,680 [run_pretraining.py:  534]:	loss/total_loss, 9.101921081542969, 341
[INFO] 2021-07-12 18:34:03,680 [run_pretraining.py:  535]:	loss/mlm_loss, 9.101921081542969, 341
[INFO] 2021-07-12 18:34:03,680 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.400000196052133e-06, 341
[INFO] 2021-07-12 18:34:03,680 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 341
[INFO] 2021-07-12 18:34:03,680 [run_pretraining.py:  558]:	worker_index: 3, step: 341, cost: 9.101921, mlm loss: 9.101921, speed: 1.092308 steps/s, speed: 8.738463 samples/s, speed: 4474.093210 tokens/s, learning rate: 3.400e-06, loss_scalings: 20971.521484, pp_loss: 9.303271
[INFO] 2021-07-12 18:34:03,680 [run_pretraining.py:  512]:	********exe.run_341******* 
[INFO] 2021-07-12 18:34:04,601 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:04,601 [run_pretraining.py:  534]:	loss/total_loss, 9.293647766113281, 342
[INFO] 2021-07-12 18:34:04,602 [run_pretraining.py:  535]:	loss/mlm_loss, 9.293647766113281, 342
[INFO] 2021-07-12 18:34:04,602 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.409999862924451e-06, 342
[INFO] 2021-07-12 18:34:04,602 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 342
[INFO] 2021-07-12 18:34:04,602 [run_pretraining.py:  558]:	worker_index: 3, step: 342, cost: 9.293648, mlm loss: 9.293648, speed: 1.085928 steps/s, speed: 8.687425 samples/s, speed: 4447.961607 tokens/s, learning rate: 3.410e-06, loss_scalings: 20971.521484, pp_loss: 9.327806
[INFO] 2021-07-12 18:34:04,602 [run_pretraining.py:  512]:	********exe.run_342******* 
[INFO] 2021-07-12 18:34:30,476 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:30,476 [run_pretraining.py:  534]:	loss/total_loss, 9.647377967834473, 343
[INFO] 2021-07-12 18:34:30,476 [run_pretraining.py:  535]:	loss/mlm_loss, 9.647377967834473, 343
[INFO] 2021-07-12 18:34:30,477 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.41999998454412e-06, 343
[INFO] 2021-07-12 18:34:30,477 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 343
[INFO] 2021-07-12 18:34:30,477 [run_pretraining.py:  558]:	worker_index: 3, step: 343, cost: 9.647378, mlm loss: 9.647378, speed: 0.038648 steps/s, speed: 0.309188 samples/s, speed: 158.304160 tokens/s, learning rate: 3.420e-06, loss_scalings: 20971.521484, pp_loss: 9.287479
[INFO] 2021-07-12 18:34:30,477 [run_pretraining.py:  512]:	********exe.run_343******* 
[INFO] 2021-07-12 18:34:31,394 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:31,395 [run_pretraining.py:  534]:	loss/total_loss, 9.42107105255127, 344
[INFO] 2021-07-12 18:34:31,395 [run_pretraining.py:  535]:	loss/mlm_loss, 9.42107105255127, 344
[INFO] 2021-07-12 18:34:31,395 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.429999878790113e-06, 344
[INFO] 2021-07-12 18:34:31,395 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 344
[INFO] 2021-07-12 18:34:31,395 [run_pretraining.py:  558]:	worker_index: 3, step: 344, cost: 9.421071, mlm loss: 9.421071, speed: 1.089695 steps/s, speed: 8.717556 samples/s, speed: 4463.388809 tokens/s, learning rate: 3.430e-06, loss_scalings: 20971.521484, pp_loss: 9.346498
[INFO] 2021-07-12 18:34:31,395 [run_pretraining.py:  512]:	********exe.run_344******* 
[INFO] 2021-07-12 18:34:32,319 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:32,319 [run_pretraining.py:  534]:	loss/total_loss, 9.39193058013916, 345
[INFO] 2021-07-12 18:34:32,320 [run_pretraining.py:  535]:	loss/mlm_loss, 9.39193058013916, 345
[INFO] 2021-07-12 18:34:32,320 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.440000000409782e-06, 345
[INFO] 2021-07-12 18:34:32,320 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 345
[INFO] 2021-07-12 18:34:32,320 [run_pretraining.py:  558]:	worker_index: 3, step: 345, cost: 9.391931, mlm loss: 9.391931, speed: 1.082168 steps/s, speed: 8.657343 samples/s, speed: 4432.559483 tokens/s, learning rate: 3.440e-06, loss_scalings: 20971.521484, pp_loss: 9.209571
[INFO] 2021-07-12 18:34:32,320 [run_pretraining.py:  512]:	********exe.run_345******* 
[INFO] 2021-07-12 18:34:33,236 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:33,237 [run_pretraining.py:  534]:	loss/total_loss, 9.705924987792969, 346
[INFO] 2021-07-12 18:34:33,237 [run_pretraining.py:  535]:	loss/mlm_loss, 9.705924987792969, 346
[INFO] 2021-07-12 18:34:33,237 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.4499998946557753e-06, 346
[INFO] 2021-07-12 18:34:33,237 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 346
[INFO] 2021-07-12 18:34:33,237 [run_pretraining.py:  558]:	worker_index: 3, step: 346, cost: 9.705925, mlm loss: 9.705925, speed: 1.090936 steps/s, speed: 8.727488 samples/s, speed: 4468.473660 tokens/s, learning rate: 3.450e-06, loss_scalings: 20971.521484, pp_loss: 9.311196
[INFO] 2021-07-12 18:34:33,237 [run_pretraining.py:  512]:	********exe.run_346******* 
[INFO] 2021-07-12 18:34:34,158 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:34,158 [run_pretraining.py:  534]:	loss/total_loss, 8.868271827697754, 347
[INFO] 2021-07-12 18:34:34,158 [run_pretraining.py:  535]:	loss/mlm_loss, 8.868271827697754, 347
[INFO] 2021-07-12 18:34:34,158 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.460000016275444e-06, 347
[INFO] 2021-07-12 18:34:34,158 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 347
[INFO] 2021-07-12 18:34:34,159 [run_pretraining.py:  558]:	worker_index: 3, step: 347, cost: 8.868272, mlm loss: 8.868272, speed: 1.085869 steps/s, speed: 8.686955 samples/s, speed: 4447.720936 tokens/s, learning rate: 3.460e-06, loss_scalings: 20971.521484, pp_loss: 9.222564
[INFO] 2021-07-12 18:34:34,159 [run_pretraining.py:  512]:	********exe.run_347******* 
[INFO] 2021-07-12 18:34:35,085 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:35,086 [run_pretraining.py:  534]:	loss/total_loss, 9.339516639709473, 348
[INFO] 2021-07-12 18:34:35,086 [run_pretraining.py:  535]:	loss/mlm_loss, 9.339516639709473, 348
[INFO] 2021-07-12 18:34:35,086 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.469999683147762e-06, 348
[INFO] 2021-07-12 18:34:35,086 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 348
[INFO] 2021-07-12 18:34:35,086 [run_pretraining.py:  558]:	worker_index: 3, step: 348, cost: 9.339517, mlm loss: 9.339517, speed: 1.078626 steps/s, speed: 8.629008 samples/s, speed: 4418.052016 tokens/s, learning rate: 3.470e-06, loss_scalings: 20971.521484, pp_loss: 9.309242
[INFO] 2021-07-12 18:34:35,086 [run_pretraining.py:  512]:	********exe.run_348******* 
[INFO] 2021-07-12 18:34:36,008 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:36,009 [run_pretraining.py:  534]:	loss/total_loss, 9.739452362060547, 349
[INFO] 2021-07-12 18:34:36,009 [run_pretraining.py:  535]:	loss/mlm_loss, 9.739452362060547, 349
[INFO] 2021-07-12 18:34:36,009 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.480000032141106e-06, 349
[INFO] 2021-07-12 18:34:36,009 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 349
[INFO] 2021-07-12 18:34:36,009 [run_pretraining.py:  558]:	worker_index: 3, step: 349, cost: 9.739452, mlm loss: 9.739452, speed: 1.084450 steps/s, speed: 8.675603 samples/s, speed: 4441.908976 tokens/s, learning rate: 3.480e-06, loss_scalings: 20971.521484, pp_loss: 9.404984
[INFO] 2021-07-12 18:34:36,009 [run_pretraining.py:  512]:	********exe.run_349******* 
[INFO] 2021-07-12 18:34:36,922 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:36,923 [run_pretraining.py:  534]:	loss/total_loss, 8.934528350830078, 350
[INFO] 2021-07-12 18:34:36,923 [run_pretraining.py:  535]:	loss/mlm_loss, 8.934528350830078, 350
[INFO] 2021-07-12 18:34:36,923 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.489999699013424e-06, 350
[INFO] 2021-07-12 18:34:36,923 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 350
[INFO] 2021-07-12 18:34:36,923 [run_pretraining.py:  558]:	worker_index: 3, step: 350, cost: 8.934528, mlm loss: 8.934528, speed: 1.094915 steps/s, speed: 8.759320 samples/s, speed: 4484.771808 tokens/s, learning rate: 3.490e-06, loss_scalings: 20971.521484, pp_loss: 8.029190
[INFO] 2021-07-12 18:34:36,923 [run_pretraining.py:  512]:	********exe.run_350******* 
[INFO] 2021-07-12 18:34:37,844 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:37,845 [run_pretraining.py:  534]:	loss/total_loss, 8.749336242675781, 351
[INFO] 2021-07-12 18:34:37,845 [run_pretraining.py:  535]:	loss/mlm_loss, 8.749336242675781, 351
[INFO] 2021-07-12 18:34:37,845 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.499999820633093e-06, 351
[INFO] 2021-07-12 18:34:37,845 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 351
[INFO] 2021-07-12 18:34:37,845 [run_pretraining.py:  558]:	worker_index: 3, step: 351, cost: 8.749336, mlm loss: 8.749336, speed: 1.085500 steps/s, speed: 8.684003 samples/s, speed: 4446.209560 tokens/s, learning rate: 3.500e-06, loss_scalings: 20971.521484, pp_loss: 9.148823
[INFO] 2021-07-12 18:34:37,845 [run_pretraining.py:  512]:	********exe.run_351******* 
[INFO] 2021-07-12 18:34:38,771 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:38,771 [run_pretraining.py:  534]:	loss/total_loss, 9.538106918334961, 352
[INFO] 2021-07-12 18:34:38,771 [run_pretraining.py:  535]:	loss/mlm_loss, 9.538106918334961, 352
[INFO] 2021-07-12 18:34:38,771 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.510000169626437e-06, 352
[INFO] 2021-07-12 18:34:38,771 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 352
[INFO] 2021-07-12 18:34:38,771 [run_pretraining.py:  558]:	worker_index: 3, step: 352, cost: 9.538107, mlm loss: 9.538107, speed: 1.080023 steps/s, speed: 8.640184 samples/s, speed: 4423.774333 tokens/s, learning rate: 3.510e-06, loss_scalings: 20971.521484, pp_loss: 9.335752
[INFO] 2021-07-12 18:34:38,772 [run_pretraining.py:  512]:	********exe.run_352******* 
[INFO] 2021-07-12 18:34:39,696 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:39,697 [run_pretraining.py:  534]:	loss/total_loss, 9.126181602478027, 353
[INFO] 2021-07-12 18:34:39,697 [run_pretraining.py:  535]:	loss/mlm_loss, 9.126181602478027, 353
[INFO] 2021-07-12 18:34:39,697 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.519999836498755e-06, 353
[INFO] 2021-07-12 18:34:39,697 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 353
[INFO] 2021-07-12 18:34:39,697 [run_pretraining.py:  558]:	worker_index: 3, step: 353, cost: 9.126182, mlm loss: 9.126182, speed: 1.080781 steps/s, speed: 8.646249 samples/s, speed: 4426.879450 tokens/s, learning rate: 3.520e-06, loss_scalings: 20971.521484, pp_loss: 9.329246
[INFO] 2021-07-12 18:34:39,697 [run_pretraining.py:  512]:	********exe.run_353******* 
[INFO] 2021-07-12 18:34:40,629 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:40,629 [run_pretraining.py:  534]:	loss/total_loss, 9.462873458862305, 354
[INFO] 2021-07-12 18:34:40,629 [run_pretraining.py:  535]:	loss/mlm_loss, 9.462873458862305, 354
[INFO] 2021-07-12 18:34:40,630 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.529999958118424e-06, 354
[INFO] 2021-07-12 18:34:40,630 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 354
[INFO] 2021-07-12 18:34:40,630 [run_pretraining.py:  558]:	worker_index: 3, step: 354, cost: 9.462873, mlm loss: 9.462873, speed: 1.073292 steps/s, speed: 8.586338 samples/s, speed: 4396.205310 tokens/s, learning rate: 3.530e-06, loss_scalings: 20971.521484, pp_loss: 9.404612
[INFO] 2021-07-12 18:34:40,630 [run_pretraining.py:  512]:	********exe.run_354******* 
[INFO] 2021-07-12 18:34:41,543 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:41,543 [run_pretraining.py:  534]:	loss/total_loss, 9.070747375488281, 355
[INFO] 2021-07-12 18:34:41,543 [run_pretraining.py:  535]:	loss/mlm_loss, 9.070747375488281, 355
[INFO] 2021-07-12 18:34:41,543 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.539999852364417e-06, 355
[INFO] 2021-07-12 18:34:41,544 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 355
[INFO] 2021-07-12 18:34:41,544 [run_pretraining.py:  558]:	worker_index: 3, step: 355, cost: 9.070747, mlm loss: 9.070747, speed: 1.094954 steps/s, speed: 8.759633 samples/s, speed: 4484.932206 tokens/s, learning rate: 3.540e-06, loss_scalings: 16777.216797, pp_loss: 9.397112
[INFO] 2021-07-12 18:34:41,544 [run_pretraining.py:  512]:	********exe.run_355******* 
[INFO] 2021-07-12 18:34:42,509 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:42,510 [run_pretraining.py:  534]:	loss/total_loss, 9.446968078613281, 356
[INFO] 2021-07-12 18:34:42,510 [run_pretraining.py:  535]:	loss/mlm_loss, 9.446968078613281, 356
[INFO] 2021-07-12 18:34:42,510 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.549999973984086e-06, 356
[INFO] 2021-07-12 18:34:42,510 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 356
[INFO] 2021-07-12 18:34:42,510 [run_pretraining.py:  558]:	worker_index: 3, step: 356, cost: 9.446968, mlm loss: 9.446968, speed: 1.035173 steps/s, speed: 8.281387 samples/s, speed: 4240.070049 tokens/s, learning rate: 3.550e-06, loss_scalings: 16777.216797, pp_loss: 9.373741
[INFO] 2021-07-12 18:34:42,510 [run_pretraining.py:  512]:	********exe.run_356******* 
[INFO] 2021-07-12 18:34:43,441 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:43,442 [run_pretraining.py:  534]:	loss/total_loss, 9.718343734741211, 357
[INFO] 2021-07-12 18:34:43,442 [run_pretraining.py:  535]:	loss/mlm_loss, 9.718343734741211, 357
[INFO] 2021-07-12 18:34:43,442 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.5599998682300793e-06, 357
[INFO] 2021-07-12 18:34:43,442 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 357
[INFO] 2021-07-12 18:34:43,442 [run_pretraining.py:  558]:	worker_index: 3, step: 357, cost: 9.718344, mlm loss: 9.718344, speed: 1.074057 steps/s, speed: 8.592455 samples/s, speed: 4399.337171 tokens/s, learning rate: 3.560e-06, loss_scalings: 16777.216797, pp_loss: 9.587466
[INFO] 2021-07-12 18:34:43,442 [run_pretraining.py:  512]:	********exe.run_357******* 
[INFO] 2021-07-12 18:34:44,364 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:44,365 [run_pretraining.py:  534]:	loss/total_loss, 9.364510536193848, 358
[INFO] 2021-07-12 18:34:44,365 [run_pretraining.py:  535]:	loss/mlm_loss, 9.364510536193848, 358
[INFO] 2021-07-12 18:34:44,365 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.569999989849748e-06, 358
[INFO] 2021-07-12 18:34:44,365 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 358
[INFO] 2021-07-12 18:34:44,365 [run_pretraining.py:  558]:	worker_index: 3, step: 358, cost: 9.364511, mlm loss: 9.364511, speed: 1.083848 steps/s, speed: 8.670781 samples/s, speed: 4439.439992 tokens/s, learning rate: 3.570e-06, loss_scalings: 16777.216797, pp_loss: 9.324725
[INFO] 2021-07-12 18:34:44,365 [run_pretraining.py:  512]:	********exe.run_358******* 
[INFO] 2021-07-12 18:34:45,284 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:45,285 [run_pretraining.py:  534]:	loss/total_loss, 9.495841979980469, 359
[INFO] 2021-07-12 18:34:45,285 [run_pretraining.py:  535]:	loss/mlm_loss, 9.495841979980469, 359
[INFO] 2021-07-12 18:34:45,285 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.5799998840957414e-06, 359
[INFO] 2021-07-12 18:34:45,285 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 359
[INFO] 2021-07-12 18:34:45,285 [run_pretraining.py:  558]:	worker_index: 3, step: 359, cost: 9.495842, mlm loss: 9.495842, speed: 1.087424 steps/s, speed: 8.699392 samples/s, speed: 4454.088494 tokens/s, learning rate: 3.580e-06, loss_scalings: 16777.216797, pp_loss: 9.476871
[INFO] 2021-07-12 18:34:45,285 [run_pretraining.py:  512]:	********exe.run_359******* 
[INFO] 2021-07-12 18:34:46,210 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:46,210 [run_pretraining.py:  534]:	loss/total_loss, 9.306384086608887, 360
[INFO] 2021-07-12 18:34:46,211 [run_pretraining.py:  535]:	loss/mlm_loss, 9.306384086608887, 360
[INFO] 2021-07-12 18:34:46,211 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.5900000057154102e-06, 360
[INFO] 2021-07-12 18:34:46,211 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 360
[INFO] 2021-07-12 18:34:46,211 [run_pretraining.py:  558]:	worker_index: 3, step: 360, cost: 9.306384, mlm loss: 9.306384, speed: 1.081355 steps/s, speed: 8.650841 samples/s, speed: 4429.230562 tokens/s, learning rate: 3.590e-06, loss_scalings: 16777.216797, pp_loss: 9.199986
[INFO] 2021-07-12 18:34:46,211 [run_pretraining.py:  512]:	********exe.run_360******* 
[INFO] 2021-07-12 18:34:47,133 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:47,133 [run_pretraining.py:  534]:	loss/total_loss, 9.137227058410645, 361
[INFO] 2021-07-12 18:34:47,133 [run_pretraining.py:  535]:	loss/mlm_loss, 9.137227058410645, 361
[INFO] 2021-07-12 18:34:47,133 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.599999672587728e-06, 361
[INFO] 2021-07-12 18:34:47,134 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 361
[INFO] 2021-07-12 18:34:47,134 [run_pretraining.py:  558]:	worker_index: 3, step: 361, cost: 9.137227, mlm loss: 9.137227, speed: 1.084444 steps/s, speed: 8.675552 samples/s, speed: 4441.882562 tokens/s, learning rate: 3.600e-06, loss_scalings: 16777.216797, pp_loss: 9.284895
[INFO] 2021-07-12 18:34:47,134 [run_pretraining.py:  512]:	********exe.run_361******* 
[INFO] 2021-07-12 18:34:48,060 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:48,061 [run_pretraining.py:  534]:	loss/total_loss, 8.784149169921875, 362
[INFO] 2021-07-12 18:34:48,061 [run_pretraining.py:  535]:	loss/mlm_loss, 8.784149169921875, 362
[INFO] 2021-07-12 18:34:48,061 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.6100000215810724e-06, 362
[INFO] 2021-07-12 18:34:48,061 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 362
[INFO] 2021-07-12 18:34:48,061 [run_pretraining.py:  558]:	worker_index: 3, step: 362, cost: 8.784149, mlm loss: 8.784149, speed: 1.078894 steps/s, speed: 8.631154 samples/s, speed: 4419.150962 tokens/s, learning rate: 3.610e-06, loss_scalings: 16777.216797, pp_loss: 9.110505
[INFO] 2021-07-12 18:34:48,061 [run_pretraining.py:  512]:	********exe.run_362******* 
[INFO] 2021-07-12 18:34:48,978 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:48,979 [run_pretraining.py:  534]:	loss/total_loss, 9.243022918701172, 363
[INFO] 2021-07-12 18:34:48,979 [run_pretraining.py:  535]:	loss/mlm_loss, 9.243022918701172, 363
[INFO] 2021-07-12 18:34:48,979 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.620000143200741e-06, 363
[INFO] 2021-07-12 18:34:48,979 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 363
[INFO] 2021-07-12 18:34:48,979 [run_pretraining.py:  558]:	worker_index: 3, step: 363, cost: 9.243023, mlm loss: 9.243023, speed: 1.089855 steps/s, speed: 8.718841 samples/s, speed: 4464.046401 tokens/s, learning rate: 3.620e-06, loss_scalings: 16777.216797, pp_loss: 9.390816
[INFO] 2021-07-12 18:34:48,979 [run_pretraining.py:  512]:	********exe.run_363******* 
[INFO] 2021-07-12 18:34:49,899 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:49,900 [run_pretraining.py:  534]:	loss/total_loss, 9.24545669555664, 364
[INFO] 2021-07-12 18:34:49,900 [run_pretraining.py:  535]:	loss/mlm_loss, 9.24545669555664, 364
[INFO] 2021-07-12 18:34:49,900 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.629999810073059e-06, 364
[INFO] 2021-07-12 18:34:49,900 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 364
[INFO] 2021-07-12 18:34:49,900 [run_pretraining.py:  558]:	worker_index: 3, step: 364, cost: 9.245457, mlm loss: 9.245457, speed: 1.086608 steps/s, speed: 8.692860 samples/s, speed: 4450.744465 tokens/s, learning rate: 3.630e-06, loss_scalings: 16777.216797, pp_loss: 9.154711
[INFO] 2021-07-12 18:34:49,900 [run_pretraining.py:  512]:	********exe.run_364******* 
[INFO] 2021-07-12 18:34:50,819 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:50,820 [run_pretraining.py:  534]:	loss/total_loss, 9.03762149810791, 365
[INFO] 2021-07-12 18:34:50,820 [run_pretraining.py:  535]:	loss/mlm_loss, 9.03762149810791, 365
[INFO] 2021-07-12 18:34:50,820 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.6400001590664033e-06, 365
[INFO] 2021-07-12 18:34:50,820 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 365
[INFO] 2021-07-12 18:34:50,820 [run_pretraining.py:  558]:	worker_index: 3, step: 365, cost: 9.037621, mlm loss: 9.037621, speed: 1.087831 steps/s, speed: 8.702645 samples/s, speed: 4455.754304 tokens/s, learning rate: 3.640e-06, loss_scalings: 16777.216797, pp_loss: 9.181446
[INFO] 2021-07-12 18:34:50,820 [run_pretraining.py:  512]:	********exe.run_365******* 
[INFO] 2021-07-12 18:34:51,755 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:51,756 [run_pretraining.py:  534]:	loss/total_loss, 4.929602146148682, 366
[INFO] 2021-07-12 18:34:51,756 [run_pretraining.py:  535]:	loss/mlm_loss, 4.929602146148682, 366
[INFO] 2021-07-12 18:34:51,756 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.649999825938721e-06, 366
[INFO] 2021-07-12 18:34:51,756 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 366
[INFO] 2021-07-12 18:34:51,756 [run_pretraining.py:  558]:	worker_index: 3, step: 366, cost: 4.929602, mlm loss: 4.929602, speed: 1.068889 steps/s, speed: 8.551111 samples/s, speed: 4378.168924 tokens/s, learning rate: 3.650e-06, loss_scalings: 16777.216797, pp_loss: 8.210545
[INFO] 2021-07-12 18:34:51,756 [run_pretraining.py:  512]:	********exe.run_366******* 
[INFO] 2021-07-12 18:34:52,685 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:52,685 [run_pretraining.py:  534]:	loss/total_loss, 8.312959671020508, 367
[INFO] 2021-07-12 18:34:52,685 [run_pretraining.py:  535]:	loss/mlm_loss, 8.312959671020508, 367
[INFO] 2021-07-12 18:34:52,686 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.65999994755839e-06, 367
[INFO] 2021-07-12 18:34:52,686 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 367
[INFO] 2021-07-12 18:34:52,686 [run_pretraining.py:  558]:	worker_index: 3, step: 367, cost: 8.312960, mlm loss: 8.312960, speed: 1.076682 steps/s, speed: 8.613456 samples/s, speed: 4410.089371 tokens/s, learning rate: 3.660e-06, loss_scalings: 16777.216797, pp_loss: 9.079912
[INFO] 2021-07-12 18:34:52,686 [run_pretraining.py:  512]:	********exe.run_367******* 
[INFO] 2021-07-12 18:34:53,616 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:53,616 [run_pretraining.py:  534]:	loss/total_loss, 9.173198699951172, 368
[INFO] 2021-07-12 18:34:53,616 [run_pretraining.py:  535]:	loss/mlm_loss, 9.173198699951172, 368
[INFO] 2021-07-12 18:34:53,616 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.6699998418043833e-06, 368
[INFO] 2021-07-12 18:34:53,616 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 368
[INFO] 2021-07-12 18:34:53,616 [run_pretraining.py:  558]:	worker_index: 3, step: 368, cost: 9.173199, mlm loss: 9.173199, speed: 1.075123 steps/s, speed: 8.600986 samples/s, speed: 4403.704673 tokens/s, learning rate: 3.670e-06, loss_scalings: 16777.216797, pp_loss: 7.514501
[INFO] 2021-07-12 18:34:53,617 [run_pretraining.py:  512]:	********exe.run_368******* 
[INFO] 2021-07-12 18:35:19,236 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:19,236 [run_pretraining.py:  534]:	loss/total_loss, 9.385858535766602, 369
[INFO] 2021-07-12 18:35:19,236 [run_pretraining.py:  535]:	loss/mlm_loss, 9.385858535766602, 369
[INFO] 2021-07-12 18:35:19,236 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.679999963424052e-06, 369
[INFO] 2021-07-12 18:35:19,236 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 369
[INFO] 2021-07-12 18:35:19,237 [run_pretraining.py:  558]:	worker_index: 3, step: 369, cost: 9.385859, mlm loss: 9.385859, speed: 0.039033 steps/s, speed: 0.312263 samples/s, speed: 159.878654 tokens/s, learning rate: 3.680e-06, loss_scalings: 16777.216797, pp_loss: 9.314682
[INFO] 2021-07-12 18:35:19,237 [run_pretraining.py:  512]:	********exe.run_369******* 
[INFO] 2021-07-12 18:35:20,174 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:20,175 [run_pretraining.py:  534]:	loss/total_loss, 9.349954605102539, 370
[INFO] 2021-07-12 18:35:20,175 [run_pretraining.py:  535]:	loss/mlm_loss, 9.349954605102539, 370
[INFO] 2021-07-12 18:35:20,175 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.6899998576700455e-06, 370
[INFO] 2021-07-12 18:35:20,175 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 370
[INFO] 2021-07-12 18:35:20,175 [run_pretraining.py:  558]:	worker_index: 3, step: 370, cost: 9.349955, mlm loss: 9.349955, speed: 1.066155 steps/s, speed: 8.529238 samples/s, speed: 4366.969896 tokens/s, learning rate: 3.690e-06, loss_scalings: 16777.216797, pp_loss: 9.314051
[INFO] 2021-07-12 18:35:20,175 [run_pretraining.py:  512]:	********exe.run_370******* 
[INFO] 2021-07-12 18:35:21,090 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:21,090 [run_pretraining.py:  534]:	loss/total_loss, 9.345220565795898, 371
[INFO] 2021-07-12 18:35:21,090 [run_pretraining.py:  535]:	loss/mlm_loss, 9.345220565795898, 371
[INFO] 2021-07-12 18:35:21,090 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.6999999792897142e-06, 371
[INFO] 2021-07-12 18:35:21,091 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 371
[INFO] 2021-07-12 18:35:21,091 [run_pretraining.py:  558]:	worker_index: 3, step: 371, cost: 9.345221, mlm loss: 9.345221, speed: 1.093027 steps/s, speed: 8.744218 samples/s, speed: 4477.039540 tokens/s, learning rate: 3.700e-06, loss_scalings: 16777.216797, pp_loss: 9.327135
[INFO] 2021-07-12 18:35:21,091 [run_pretraining.py:  512]:	********exe.run_371******* 
[INFO] 2021-07-12 18:35:22,014 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:22,014 [run_pretraining.py:  534]:	loss/total_loss, 9.303037643432617, 372
[INFO] 2021-07-12 18:35:22,014 [run_pretraining.py:  535]:	loss/mlm_loss, 9.303037643432617, 372
[INFO] 2021-07-12 18:35:22,014 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.709999646162032e-06, 372
[INFO] 2021-07-12 18:35:22,014 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 372
[INFO] 2021-07-12 18:35:22,015 [run_pretraining.py:  558]:	worker_index: 3, step: 372, cost: 9.303038, mlm loss: 9.303038, speed: 1.083066 steps/s, speed: 8.664530 samples/s, speed: 4436.239338 tokens/s, learning rate: 3.710e-06, loss_scalings: 16777.216797, pp_loss: 9.296919
[INFO] 2021-07-12 18:35:22,015 [run_pretraining.py:  512]:	********exe.run_372******* 
[INFO] 2021-07-12 18:35:22,933 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:22,933 [run_pretraining.py:  534]:	loss/total_loss, 9.097118377685547, 373
[INFO] 2021-07-12 18:35:22,933 [run_pretraining.py:  535]:	loss/mlm_loss, 9.097118377685547, 373
[INFO] 2021-07-12 18:35:22,933 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.7199999951553764e-06, 373
[INFO] 2021-07-12 18:35:22,933 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 373
[INFO] 2021-07-12 18:35:22,933 [run_pretraining.py:  558]:	worker_index: 3, step: 373, cost: 9.097118, mlm loss: 9.097118, speed: 1.089105 steps/s, speed: 8.712843 samples/s, speed: 4460.975820 tokens/s, learning rate: 3.720e-06, loss_scalings: 16777.216797, pp_loss: 9.307419
[INFO] 2021-07-12 18:35:22,933 [run_pretraining.py:  512]:	********exe.run_373******* 
[INFO] 2021-07-12 18:35:23,854 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:23,854 [run_pretraining.py:  534]:	loss/total_loss, 9.072416305541992, 374
[INFO] 2021-07-12 18:35:23,854 [run_pretraining.py:  535]:	loss/mlm_loss, 9.072416305541992, 374
[INFO] 2021-07-12 18:35:23,855 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.730000116775045e-06, 374
[INFO] 2021-07-12 18:35:23,855 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 374
[INFO] 2021-07-12 18:35:23,855 [run_pretraining.py:  558]:	worker_index: 3, step: 374, cost: 9.072416, mlm loss: 9.072416, speed: 1.086201 steps/s, speed: 8.689607 samples/s, speed: 4449.078941 tokens/s, learning rate: 3.730e-06, loss_scalings: 13421.773438, pp_loss: 9.305068
[INFO] 2021-07-12 18:35:23,855 [run_pretraining.py:  512]:	********exe.run_374******* 
[INFO] 2021-07-12 18:35:24,772 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:24,773 [run_pretraining.py:  534]:	loss/total_loss, 8.534431457519531, 375
[INFO] 2021-07-12 18:35:24,773 [run_pretraining.py:  535]:	loss/mlm_loss, 8.534431457519531, 375
[INFO] 2021-07-12 18:35:24,773 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.739999783647363e-06, 375
[INFO] 2021-07-12 18:35:24,773 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 375
[INFO] 2021-07-12 18:35:24,773 [run_pretraining.py:  558]:	worker_index: 3, step: 375, cost: 8.534431, mlm loss: 8.534431, speed: 1.089886 steps/s, speed: 8.719088 samples/s, speed: 4464.172839 tokens/s, learning rate: 3.740e-06, loss_scalings: 13421.773438, pp_loss: 9.218490
[INFO] 2021-07-12 18:35:24,773 [run_pretraining.py:  512]:	********exe.run_375******* 
[INFO] 2021-07-12 18:35:25,706 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:25,707 [run_pretraining.py:  534]:	loss/total_loss, 9.281150817871094, 376
[INFO] 2021-07-12 18:35:25,707 [run_pretraining.py:  535]:	loss/mlm_loss, 9.281150817871094, 376
[INFO] 2021-07-12 18:35:25,707 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.7500001326407073e-06, 376
[INFO] 2021-07-12 18:35:25,707 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 376
[INFO] 2021-07-12 18:35:25,707 [run_pretraining.py:  558]:	worker_index: 3, step: 376, cost: 9.281151, mlm loss: 9.281151, speed: 1.071348 steps/s, speed: 8.570782 samples/s, speed: 4388.240444 tokens/s, learning rate: 3.750e-06, loss_scalings: 13421.773438, pp_loss: 9.280500
[INFO] 2021-07-12 18:35:25,707 [run_pretraining.py:  512]:	********exe.run_376******* 
[INFO] 2021-07-12 18:35:26,628 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:26,628 [run_pretraining.py:  534]:	loss/total_loss, 9.015142440795898, 377
[INFO] 2021-07-12 18:35:26,628 [run_pretraining.py:  535]:	loss/mlm_loss, 9.015142440795898, 377
[INFO] 2021-07-12 18:35:26,628 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.759999799513025e-06, 377
[INFO] 2021-07-12 18:35:26,628 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 377
[INFO] 2021-07-12 18:35:26,628 [run_pretraining.py:  558]:	worker_index: 3, step: 377, cost: 9.015142, mlm loss: 9.015142, speed: 1.085799 steps/s, speed: 8.686395 samples/s, speed: 4447.434236 tokens/s, learning rate: 3.760e-06, loss_scalings: 13421.773438, pp_loss: 9.440342
[INFO] 2021-07-12 18:35:26,629 [run_pretraining.py:  512]:	********exe.run_377******* 
[INFO] 2021-07-12 18:35:53,339 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:53,340 [run_pretraining.py:  534]:	loss/total_loss, 9.233506202697754, 378
[INFO] 2021-07-12 18:35:53,340 [run_pretraining.py:  535]:	loss/mlm_loss, 9.233506202697754, 378
[INFO] 2021-07-12 18:35:53,340 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.769999921132694e-06, 378
[INFO] 2021-07-12 18:35:53,340 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 378
[INFO] 2021-07-12 18:35:53,340 [run_pretraining.py:  558]:	worker_index: 3, step: 378, cost: 9.233506, mlm loss: 9.233506, speed: 0.037438 steps/s, speed: 0.299503 samples/s, speed: 153.345395 tokens/s, learning rate: 3.770e-06, loss_scalings: 13421.773438, pp_loss: 9.488067
[INFO] 2021-07-12 18:35:53,340 [run_pretraining.py:  512]:	********exe.run_378******* 
[INFO] 2021-07-12 18:35:54,254 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:54,255 [run_pretraining.py:  534]:	loss/total_loss, 9.220295906066895, 379
[INFO] 2021-07-12 18:35:54,255 [run_pretraining.py:  535]:	loss/mlm_loss, 9.220295906066895, 379
[INFO] 2021-07-12 18:35:54,255 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.7799998153786873e-06, 379
[INFO] 2021-07-12 18:35:54,255 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 379
[INFO] 2021-07-12 18:35:54,255 [run_pretraining.py:  558]:	worker_index: 3, step: 379, cost: 9.220296, mlm loss: 9.220296, speed: 1.093546 steps/s, speed: 8.748372 samples/s, speed: 4479.166291 tokens/s, learning rate: 3.780e-06, loss_scalings: 13421.773438, pp_loss: 9.316830
[INFO] 2021-07-12 18:35:54,255 [run_pretraining.py:  512]:	********exe.run_379******* 
[INFO] 2021-07-12 18:35:55,178 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:55,179 [run_pretraining.py:  534]:	loss/total_loss, 9.193535804748535, 380
[INFO] 2021-07-12 18:35:55,179 [run_pretraining.py:  535]:	loss/mlm_loss, 9.193535804748535, 380
[INFO] 2021-07-12 18:35:55,179 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.789999936998356e-06, 380
[INFO] 2021-07-12 18:35:55,179 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 380
[INFO] 2021-07-12 18:35:55,179 [run_pretraining.py:  558]:	worker_index: 3, step: 380, cost: 9.193536, mlm loss: 9.193536, speed: 1.083009 steps/s, speed: 8.664074 samples/s, speed: 4436.005660 tokens/s, learning rate: 3.790e-06, loss_scalings: 13421.773438, pp_loss: 9.190588
[INFO] 2021-07-12 18:35:55,179 [run_pretraining.py:  512]:	********exe.run_380******* 
[INFO] 2021-07-12 18:35:56,093 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:56,093 [run_pretraining.py:  534]:	loss/total_loss, 9.114465713500977, 381
[INFO] 2021-07-12 18:35:56,093 [run_pretraining.py:  535]:	loss/mlm_loss, 9.114465713500977, 381
[INFO] 2021-07-12 18:35:56,093 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.7999998312443495e-06, 381
[INFO] 2021-07-12 18:35:56,093 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 381
[INFO] 2021-07-12 18:35:56,093 [run_pretraining.py:  558]:	worker_index: 3, step: 381, cost: 9.114466, mlm loss: 9.114466, speed: 1.094638 steps/s, speed: 8.757102 samples/s, speed: 4483.636477 tokens/s, learning rate: 3.800e-06, loss_scalings: 13421.773438, pp_loss: 9.120028
[INFO] 2021-07-12 18:35:56,093 [run_pretraining.py:  512]:	********exe.run_381******* 
[INFO] 2021-07-12 18:35:57,155 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:57,155 [run_pretraining.py:  534]:	loss/total_loss, 9.175311088562012, 382
[INFO] 2021-07-12 18:35:57,155 [run_pretraining.py:  535]:	loss/mlm_loss, 9.175311088562012, 382
[INFO] 2021-07-12 18:35:57,155 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.8099999528640183e-06, 382
[INFO] 2021-07-12 18:35:57,156 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 382
[INFO] 2021-07-12 18:35:57,156 [run_pretraining.py:  558]:	worker_index: 3, step: 382, cost: 9.175311, mlm loss: 9.175311, speed: 0.941967 steps/s, speed: 7.535739 samples/s, speed: 3858.298568 tokens/s, learning rate: 3.810e-06, loss_scalings: 13421.773438, pp_loss: 9.165252
[INFO] 2021-07-12 18:35:57,156 [run_pretraining.py:  512]:	********exe.run_382******* 
[INFO] 2021-07-12 18:35:58,063 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:58,063 [run_pretraining.py:  534]:	loss/total_loss, 9.637649536132812, 383
[INFO] 2021-07-12 18:35:58,063 [run_pretraining.py:  535]:	loss/mlm_loss, 9.637649536132812, 383
[INFO] 2021-07-12 18:35:58,063 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.819999619736336e-06, 383
[INFO] 2021-07-12 18:35:58,063 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 383
[INFO] 2021-07-12 18:35:58,064 [run_pretraining.py:  558]:	worker_index: 3, step: 383, cost: 9.637650, mlm loss: 9.637650, speed: 1.102208 steps/s, speed: 8.817667 samples/s, speed: 4514.645428 tokens/s, learning rate: 3.820e-06, loss_scalings: 13421.773438, pp_loss: 9.373297
[INFO] 2021-07-12 18:35:58,064 [run_pretraining.py:  512]:	********exe.run_383******* 
[INFO] 2021-07-12 18:35:58,973 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:58,974 [run_pretraining.py:  534]:	loss/total_loss, 9.433259010314941, 384
[INFO] 2021-07-12 18:35:58,974 [run_pretraining.py:  535]:	loss/mlm_loss, 9.433259010314941, 384
[INFO] 2021-07-12 18:35:58,974 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.82999996872968e-06, 384
[INFO] 2021-07-12 18:35:58,974 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 384
[INFO] 2021-07-12 18:35:58,974 [run_pretraining.py:  558]:	worker_index: 3, step: 384, cost: 9.433259, mlm loss: 9.433259, speed: 1.098913 steps/s, speed: 8.791305 samples/s, speed: 4501.148007 tokens/s, learning rate: 3.830e-06, loss_scalings: 13421.773438, pp_loss: 9.322291
[INFO] 2021-07-12 18:35:58,974 [run_pretraining.py:  512]:	********exe.run_384******* 
[INFO] 2021-07-12 18:35:59,877 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:59,878 [run_pretraining.py:  534]:	loss/total_loss, 9.283292770385742, 385
[INFO] 2021-07-12 18:35:59,878 [run_pretraining.py:  535]:	loss/mlm_loss, 9.283292770385742, 385
[INFO] 2021-07-12 18:35:59,878 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.839999862975674e-06, 385
[INFO] 2021-07-12 18:35:59,878 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 385
[INFO] 2021-07-12 18:35:59,878 [run_pretraining.py:  558]:	worker_index: 3, step: 385, cost: 9.283293, mlm loss: 9.283293, speed: 1.107024 steps/s, speed: 8.856195 samples/s, speed: 4534.371932 tokens/s, learning rate: 3.840e-06, loss_scalings: 13421.773438, pp_loss: 9.350288
[INFO] 2021-07-12 18:35:59,878 [run_pretraining.py:  512]:	********exe.run_385******* 
[INFO] 2021-07-12 18:36:25,757 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:25,757 [run_pretraining.py:  534]:	loss/total_loss, 9.240957260131836, 386
[INFO] 2021-07-12 18:36:25,757 [run_pretraining.py:  535]:	loss/mlm_loss, 9.240957260131836, 386
[INFO] 2021-07-12 18:36:25,757 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.849999757221667e-06, 386
[INFO] 2021-07-12 18:36:25,757 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 386
[INFO] 2021-07-12 18:36:25,757 [run_pretraining.py:  558]:	worker_index: 3, step: 386, cost: 9.240957, mlm loss: 9.240957, speed: 0.038642 steps/s, speed: 0.309135 samples/s, speed: 158.277090 tokens/s, learning rate: 3.850e-06, loss_scalings: 13421.773438, pp_loss: 9.145166
[INFO] 2021-07-12 18:36:25,758 [run_pretraining.py:  512]:	********exe.run_386******* 
[INFO] 2021-07-12 18:36:26,669 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:26,670 [run_pretraining.py:  534]:	loss/total_loss, 9.861526489257812, 387
[INFO] 2021-07-12 18:36:26,670 [run_pretraining.py:  535]:	loss/mlm_loss, 9.861526489257812, 387
[INFO] 2021-07-12 18:36:26,670 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.860000106215011e-06, 387
[INFO] 2021-07-12 18:36:26,670 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 387
[INFO] 2021-07-12 18:36:26,670 [run_pretraining.py:  558]:	worker_index: 3, step: 387, cost: 9.861526, mlm loss: 9.861526, speed: 1.096577 steps/s, speed: 8.772618 samples/s, speed: 4491.580623 tokens/s, learning rate: 3.860e-06, loss_scalings: 13421.773438, pp_loss: 9.517774
[INFO] 2021-07-12 18:36:26,670 [run_pretraining.py:  512]:	********exe.run_387******* 
[INFO] 2021-07-12 18:36:27,582 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:27,582 [run_pretraining.py:  534]:	loss/total_loss, 8.765316009521484, 388
[INFO] 2021-07-12 18:36:27,582 [run_pretraining.py:  535]:	loss/mlm_loss, 8.765316009521484, 388
[INFO] 2021-07-12 18:36:27,582 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.870000000461005e-06, 388
[INFO] 2021-07-12 18:36:27,582 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 388
[INFO] 2021-07-12 18:36:27,583 [run_pretraining.py:  558]:	worker_index: 3, step: 388, cost: 8.765316, mlm loss: 8.765316, speed: 1.096666 steps/s, speed: 8.773327 samples/s, speed: 4491.943511 tokens/s, learning rate: 3.870e-06, loss_scalings: 13421.773438, pp_loss: 9.037020
[INFO] 2021-07-12 18:36:27,583 [run_pretraining.py:  512]:	********exe.run_388******* 
[INFO] 2021-07-12 18:36:28,500 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:28,500 [run_pretraining.py:  534]:	loss/total_loss, 9.303369522094727, 389
[INFO] 2021-07-12 18:36:28,501 [run_pretraining.py:  535]:	loss/mlm_loss, 9.303369522094727, 389
[INFO] 2021-07-12 18:36:28,501 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.879999894706998e-06, 389
[INFO] 2021-07-12 18:36:28,501 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 389
[INFO] 2021-07-12 18:36:28,501 [run_pretraining.py:  558]:	worker_index: 3, step: 389, cost: 9.303370, mlm loss: 9.303370, speed: 1.089722 steps/s, speed: 8.717778 samples/s, speed: 4463.502453 tokens/s, learning rate: 3.880e-06, loss_scalings: 13421.773438, pp_loss: 9.035120
[INFO] 2021-07-12 18:36:28,501 [run_pretraining.py:  512]:	********exe.run_389******* 
[INFO] 2021-07-12 18:36:29,413 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:29,413 [run_pretraining.py:  534]:	loss/total_loss, 9.425748825073242, 390
[INFO] 2021-07-12 18:36:29,413 [run_pretraining.py:  535]:	loss/mlm_loss, 9.425748825073242, 390
[INFO] 2021-07-12 18:36:29,413 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.889999788952991e-06, 390
[INFO] 2021-07-12 18:36:29,413 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 390
[INFO] 2021-07-12 18:36:29,414 [run_pretraining.py:  558]:	worker_index: 3, step: 390, cost: 9.425749, mlm loss: 9.425749, speed: 1.096450 steps/s, speed: 8.771598 samples/s, speed: 4491.058121 tokens/s, learning rate: 3.890e-06, loss_scalings: 13421.773438, pp_loss: 8.665182
[INFO] 2021-07-12 18:36:29,414 [run_pretraining.py:  512]:	********exe.run_390******* 
[INFO] 2021-07-12 18:36:30,321 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:30,322 [run_pretraining.py:  534]:	loss/total_loss, 9.551727294921875, 391
[INFO] 2021-07-12 18:36:30,322 [run_pretraining.py:  535]:	loss/mlm_loss, 9.551727294921875, 391
[INFO] 2021-07-12 18:36:30,322 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.900000137946336e-06, 391
[INFO] 2021-07-12 18:36:30,322 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 391
[INFO] 2021-07-12 18:36:30,322 [run_pretraining.py:  558]:	worker_index: 3, step: 391, cost: 9.551727, mlm loss: 9.551727, speed: 1.101514 steps/s, speed: 8.812114 samples/s, speed: 4511.802257 tokens/s, learning rate: 3.900e-06, loss_scalings: 13421.773438, pp_loss: 9.398725
[INFO] 2021-07-12 18:36:30,322 [run_pretraining.py:  512]:	********exe.run_391******* 
[INFO] 2021-07-12 18:36:31,236 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:31,237 [run_pretraining.py:  534]:	loss/total_loss, 9.012216567993164, 392
[INFO] 2021-07-12 18:36:31,237 [run_pretraining.py:  535]:	loss/mlm_loss, 9.012216567993164, 392
[INFO] 2021-07-12 18:36:31,237 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.909999577444978e-06, 392
[INFO] 2021-07-12 18:36:31,237 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 392
[INFO] 2021-07-12 18:36:31,237 [run_pretraining.py:  558]:	worker_index: 3, step: 392, cost: 9.012217, mlm loss: 9.012217, speed: 1.093319 steps/s, speed: 8.746550 samples/s, speed: 4478.233400 tokens/s, learning rate: 3.910e-06, loss_scalings: 13421.773438, pp_loss: 9.422632
[INFO] 2021-07-12 18:36:31,237 [run_pretraining.py:  512]:	********exe.run_392******* 
[INFO] 2021-07-12 18:36:32,144 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:32,145 [run_pretraining.py:  534]:	loss/total_loss, 9.342072486877441, 393
[INFO] 2021-07-12 18:36:32,145 [run_pretraining.py:  535]:	loss/mlm_loss, 9.342072486877441, 393
[INFO] 2021-07-12 18:36:32,145 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.919999926438322e-06, 393
[INFO] 2021-07-12 18:36:32,145 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 393
[INFO] 2021-07-12 18:36:32,145 [run_pretraining.py:  558]:	worker_index: 3, step: 393, cost: 9.342072, mlm loss: 9.342072, speed: 1.102152 steps/s, speed: 8.817215 samples/s, speed: 4514.414094 tokens/s, learning rate: 3.920e-06, loss_scalings: 13421.773438, pp_loss: 9.269504
[INFO] 2021-07-12 18:36:32,145 [run_pretraining.py:  512]:	********exe.run_393******* 
[INFO] 2021-07-12 18:36:33,053 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:33,053 [run_pretraining.py:  534]:	loss/total_loss, 9.178675651550293, 394
[INFO] 2021-07-12 18:36:33,053 [run_pretraining.py:  535]:	loss/mlm_loss, 9.178675651550293, 394
[INFO] 2021-07-12 18:36:33,054 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.929999820684316e-06, 394
[INFO] 2021-07-12 18:36:33,054 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 394
[INFO] 2021-07-12 18:36:33,054 [run_pretraining.py:  558]:	worker_index: 3, step: 394, cost: 9.178676, mlm loss: 9.178676, speed: 1.101487 steps/s, speed: 8.811899 samples/s, speed: 4511.692064 tokens/s, learning rate: 3.930e-06, loss_scalings: 13421.773438, pp_loss: 9.093992
[INFO] 2021-07-12 18:36:33,054 [run_pretraining.py:  512]:	********exe.run_394******* 
[INFO] 2021-07-12 18:36:33,960 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:33,961 [run_pretraining.py:  534]:	loss/total_loss, 9.512171745300293, 395
[INFO] 2021-07-12 18:36:33,961 [run_pretraining.py:  535]:	loss/mlm_loss, 9.512171745300293, 395
[INFO] 2021-07-12 18:36:33,961 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.939999714930309e-06, 395
[INFO] 2021-07-12 18:36:33,961 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 395
[INFO] 2021-07-12 18:36:33,961 [run_pretraining.py:  558]:	worker_index: 3, step: 395, cost: 9.512172, mlm loss: 9.512172, speed: 1.102986 steps/s, speed: 8.823886 samples/s, speed: 4517.829570 tokens/s, learning rate: 3.940e-06, loss_scalings: 13421.773438, pp_loss: 9.418344
[INFO] 2021-07-12 18:36:33,961 [run_pretraining.py:  512]:	********exe.run_395******* 
[INFO] 2021-07-12 18:36:34,874 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:34,874 [run_pretraining.py:  534]:	loss/total_loss, 9.298527717590332, 396
[INFO] 2021-07-12 18:36:34,874 [run_pretraining.py:  535]:	loss/mlm_loss, 9.298527717590332, 396
[INFO] 2021-07-12 18:36:34,874 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.950000063923653e-06, 396
[INFO] 2021-07-12 18:36:34,874 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 396
[INFO] 2021-07-12 18:36:34,875 [run_pretraining.py:  558]:	worker_index: 3, step: 396, cost: 9.298528, mlm loss: 9.298528, speed: 1.095356 steps/s, speed: 8.762852 samples/s, speed: 4486.580162 tokens/s, learning rate: 3.950e-06, loss_scalings: 13421.773438, pp_loss: 9.346454
[INFO] 2021-07-12 18:36:34,875 [run_pretraining.py:  512]:	********exe.run_396******* 
[INFO] 2021-07-12 18:36:35,779 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:35,780 [run_pretraining.py:  534]:	loss/total_loss, 9.382549285888672, 397
[INFO] 2021-07-12 18:36:35,780 [run_pretraining.py:  535]:	loss/mlm_loss, 9.382549285888672, 397
[INFO] 2021-07-12 18:36:35,780 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.9599999581696466e-06, 397
[INFO] 2021-07-12 18:36:35,780 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 397
[INFO] 2021-07-12 18:36:35,780 [run_pretraining.py:  558]:	worker_index: 3, step: 397, cost: 9.382549, mlm loss: 9.382549, speed: 1.105121 steps/s, speed: 8.840972 samples/s, speed: 4526.577558 tokens/s, learning rate: 3.960e-06, loss_scalings: 13421.773438, pp_loss: 9.234292
[INFO] 2021-07-12 18:36:35,780 [run_pretraining.py:  512]:	********exe.run_397******* 
[INFO] 2021-07-12 18:36:36,685 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:36,685 [run_pretraining.py:  534]:	loss/total_loss, 9.224302291870117, 398
[INFO] 2021-07-12 18:36:36,685 [run_pretraining.py:  535]:	loss/mlm_loss, 9.224302291870117, 398
[INFO] 2021-07-12 18:36:36,685 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.96999985241564e-06, 398
[INFO] 2021-07-12 18:36:36,685 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 398
[INFO] 2021-07-12 18:36:36,686 [run_pretraining.py:  558]:	worker_index: 3, step: 398, cost: 9.224302, mlm loss: 9.224302, speed: 1.105229 steps/s, speed: 8.841831 samples/s, speed: 4527.017696 tokens/s, learning rate: 3.970e-06, loss_scalings: 13421.773438, pp_loss: 8.637595
[INFO] 2021-07-12 18:36:36,686 [run_pretraining.py:  512]:	********exe.run_398******* 
[INFO] 2021-07-12 18:36:37,598 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:37,599 [run_pretraining.py:  534]:	loss/total_loss, 9.244415283203125, 399
[INFO] 2021-07-12 18:36:37,599 [run_pretraining.py:  535]:	loss/mlm_loss, 9.244415283203125, 399
[INFO] 2021-07-12 18:36:37,599 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.979999746661633e-06, 399
[INFO] 2021-07-12 18:36:37,599 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 399
[INFO] 2021-07-12 18:36:37,599 [run_pretraining.py:  558]:	worker_index: 3, step: 399, cost: 9.244415, mlm loss: 9.244415, speed: 1.095446 steps/s, speed: 8.763568 samples/s, speed: 4486.946929 tokens/s, learning rate: 3.980e-06, loss_scalings: 13421.773438, pp_loss: 9.153877
[INFO] 2021-07-12 18:36:37,599 [run_pretraining.py:  512]:	********exe.run_399******* 
[INFO] 2021-07-12 18:36:38,516 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:38,516 [run_pretraining.py:  534]:	loss/total_loss, 9.188730239868164, 400
[INFO] 2021-07-12 18:36:38,516 [run_pretraining.py:  535]:	loss/mlm_loss, 9.188730239868164, 400
[INFO] 2021-07-12 18:36:38,517 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.9900000956549775e-06, 400
[INFO] 2021-07-12 18:36:38,517 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 400
[INFO] 2021-07-12 18:36:38,517 [run_pretraining.py:  558]:	worker_index: 3, step: 400, cost: 9.188730, mlm loss: 9.188730, speed: 1.090588 steps/s, speed: 8.724705 samples/s, speed: 4467.049199 tokens/s, learning rate: 3.990e-06, loss_scalings: 13421.773438, pp_loss: 9.260155
[INFO] 2021-07-12 18:36:38,517 [run_pretraining.py:  512]:	********exe.run_400******* 
[INFO] 2021-07-12 18:36:39,426 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:39,426 [run_pretraining.py:  534]:	loss/total_loss, 9.229293823242188, 401
[INFO] 2021-07-12 18:36:39,426 [run_pretraining.py:  535]:	loss/mlm_loss, 9.229293823242188, 401
[INFO] 2021-07-12 18:36:39,426 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.999999989900971e-06, 401
[INFO] 2021-07-12 18:36:39,426 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 401
[INFO] 2021-07-12 18:36:39,426 [run_pretraining.py:  558]:	worker_index: 3, step: 401, cost: 9.229294, mlm loss: 9.229294, speed: 1.099915 steps/s, speed: 8.799318 samples/s, speed: 4505.251013 tokens/s, learning rate: 4.000e-06, loss_scalings: 13421.773438, pp_loss: 9.265753
[INFO] 2021-07-12 18:36:39,427 [run_pretraining.py:  512]:	********exe.run_401******* 
[INFO] 2021-07-12 18:36:40,335 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:40,335 [run_pretraining.py:  534]:	loss/total_loss, 9.140615463256836, 402
[INFO] 2021-07-12 18:36:40,335 [run_pretraining.py:  535]:	loss/mlm_loss, 9.140615463256836, 402
[INFO] 2021-07-12 18:36:40,335 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.009999884146964e-06, 402
[INFO] 2021-07-12 18:36:40,335 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 402
[INFO] 2021-07-12 18:36:40,335 [run_pretraining.py:  558]:	worker_index: 3, step: 402, cost: 9.140615, mlm loss: 9.140615, speed: 1.100939 steps/s, speed: 8.807511 samples/s, speed: 4509.445545 tokens/s, learning rate: 4.010e-06, loss_scalings: 13421.773438, pp_loss: 9.417381
[INFO] 2021-07-12 18:36:40,335 [run_pretraining.py:  512]:	********exe.run_402******* 
[INFO] 2021-07-12 18:36:41,248 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:41,249 [run_pretraining.py:  534]:	loss/total_loss, 9.285724639892578, 403
[INFO] 2021-07-12 18:36:41,249 [run_pretraining.py:  535]:	loss/mlm_loss, 9.285724639892578, 403
[INFO] 2021-07-12 18:36:41,249 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.0199997783929575e-06, 403
[INFO] 2021-07-12 18:36:41,249 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 403
[INFO] 2021-07-12 18:36:41,249 [run_pretraining.py:  558]:	worker_index: 3, step: 403, cost: 9.285725, mlm loss: 9.285725, speed: 1.095166 steps/s, speed: 8.761326 samples/s, speed: 4485.798783 tokens/s, learning rate: 4.020e-06, loss_scalings: 13421.773438, pp_loss: 9.344299
[INFO] 2021-07-12 18:36:41,249 [run_pretraining.py:  512]:	********exe.run_403******* 
[INFO] 2021-07-12 18:36:42,164 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:42,165 [run_pretraining.py:  534]:	loss/total_loss, 9.290733337402344, 404
[INFO] 2021-07-12 18:36:42,165 [run_pretraining.py:  535]:	loss/mlm_loss, 9.290733337402344, 404
[INFO] 2021-07-12 18:36:42,165 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.030000127386302e-06, 404
[INFO] 2021-07-12 18:36:42,165 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 404
[INFO] 2021-07-12 18:36:42,165 [run_pretraining.py:  558]:	worker_index: 3, step: 404, cost: 9.290733, mlm loss: 9.290733, speed: 1.092454 steps/s, speed: 8.739629 samples/s, speed: 4474.689858 tokens/s, learning rate: 4.030e-06, loss_scalings: 13421.773438, pp_loss: 9.202045
[INFO] 2021-07-12 18:36:42,165 [run_pretraining.py:  512]:	********exe.run_404******* 
[INFO] 2021-07-12 18:36:43,079 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:43,080 [run_pretraining.py:  534]:	loss/total_loss, 9.232603073120117, 405
[INFO] 2021-07-12 18:36:43,080 [run_pretraining.py:  535]:	loss/mlm_loss, 9.232603073120117, 405
[INFO] 2021-07-12 18:36:43,080 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.039999566884944e-06, 405
[INFO] 2021-07-12 18:36:43,080 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 405
[INFO] 2021-07-12 18:36:43,080 [run_pretraining.py:  558]:	worker_index: 3, step: 405, cost: 9.232603, mlm loss: 9.232603, speed: 1.093635 steps/s, speed: 8.749079 samples/s, speed: 4479.528343 tokens/s, learning rate: 4.040e-06, loss_scalings: 13421.773438, pp_loss: 9.086063
[INFO] 2021-07-12 18:36:43,080 [run_pretraining.py:  512]:	********exe.run_405******* 
[INFO] 2021-07-12 18:36:43,989 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:43,989 [run_pretraining.py:  534]:	loss/total_loss, 9.404172897338867, 406
[INFO] 2021-07-12 18:36:43,989 [run_pretraining.py:  535]:	loss/mlm_loss, 9.404172897338867, 406
[INFO] 2021-07-12 18:36:43,989 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.0499999158782884e-06, 406
[INFO] 2021-07-12 18:36:43,989 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 406
[INFO] 2021-07-12 18:36:43,990 [run_pretraining.py:  558]:	worker_index: 3, step: 406, cost: 9.404173, mlm loss: 9.404173, speed: 1.100439 steps/s, speed: 8.803515 samples/s, speed: 4507.399928 tokens/s, learning rate: 4.050e-06, loss_scalings: 13421.773438, pp_loss: 9.262478
[INFO] 2021-07-12 18:36:43,990 [run_pretraining.py:  512]:	********exe.run_406******* 
[INFO] 2021-07-12 18:36:44,894 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:44,894 [run_pretraining.py:  534]:	loss/total_loss, 9.618189811706543, 407
[INFO] 2021-07-12 18:36:44,895 [run_pretraining.py:  535]:	loss/mlm_loss, 9.618189811706543, 407
[INFO] 2021-07-12 18:36:44,895 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.060000264871633e-06, 407
[INFO] 2021-07-12 18:36:44,895 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 407
[INFO] 2021-07-12 18:36:44,895 [run_pretraining.py:  558]:	worker_index: 3, step: 407, cost: 9.618190, mlm loss: 9.618190, speed: 1.105406 steps/s, speed: 8.843248 samples/s, speed: 4527.743096 tokens/s, learning rate: 4.060e-06, loss_scalings: 13421.773438, pp_loss: 8.262330
[INFO] 2021-07-12 18:36:44,895 [run_pretraining.py:  512]:	********exe.run_407******* 
[INFO] 2021-07-12 18:36:45,802 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:45,802 [run_pretraining.py:  534]:	loss/total_loss, 9.454916000366211, 408
[INFO] 2021-07-12 18:36:45,802 [run_pretraining.py:  535]:	loss/mlm_loss, 9.454916000366211, 408
[INFO] 2021-07-12 18:36:45,803 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.069999704370275e-06, 408
[INFO] 2021-07-12 18:36:45,803 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 408
[INFO] 2021-07-12 18:36:45,803 [run_pretraining.py:  558]:	worker_index: 3, step: 408, cost: 9.454916, mlm loss: 9.454916, speed: 1.102301 steps/s, speed: 8.818411 samples/s, speed: 4515.026291 tokens/s, learning rate: 4.070e-06, loss_scalings: 13421.773438, pp_loss: 9.214930
[INFO] 2021-07-12 18:36:45,803 [run_pretraining.py:  512]:	********exe.run_408******* 
[INFO] 2021-07-12 18:36:46,705 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:46,706 [run_pretraining.py:  534]:	loss/total_loss, 9.360748291015625, 409
[INFO] 2021-07-12 18:36:46,706 [run_pretraining.py:  535]:	loss/mlm_loss, 9.360748291015625, 409
[INFO] 2021-07-12 18:36:46,706 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.080000053363619e-06, 409
[INFO] 2021-07-12 18:36:46,706 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 409
[INFO] 2021-07-12 18:36:46,706 [run_pretraining.py:  558]:	worker_index: 3, step: 409, cost: 9.360748, mlm loss: 9.360748, speed: 1.107727 steps/s, speed: 8.861813 samples/s, speed: 4537.248422 tokens/s, learning rate: 4.080e-06, loss_scalings: 13421.773438, pp_loss: 9.225363
[INFO] 2021-07-12 18:36:46,706 [run_pretraining.py:  512]:	********exe.run_409******* 
[INFO] 2021-07-12 18:36:47,663 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:47,664 [run_pretraining.py:  534]:	loss/total_loss, 9.028196334838867, 410
[INFO] 2021-07-12 18:36:47,664 [run_pretraining.py:  535]:	loss/mlm_loss, 9.028196334838867, 410
[INFO] 2021-07-12 18:36:47,664 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.089999947609613e-06, 410
[INFO] 2021-07-12 18:36:47,664 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 410
[INFO] 2021-07-12 18:36:47,664 [run_pretraining.py:  558]:	worker_index: 3, step: 410, cost: 9.028196, mlm loss: 9.028196, speed: 1.044628 steps/s, speed: 8.357021 samples/s, speed: 4278.794522 tokens/s, learning rate: 4.090e-06, loss_scalings: 13421.773438, pp_loss: 9.138062
[INFO] 2021-07-12 18:36:47,664 [run_pretraining.py:  512]:	********exe.run_410******* 
[INFO] 2021-07-12 18:36:48,706 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:48,707 [run_pretraining.py:  534]:	loss/total_loss, 9.805829048156738, 411
[INFO] 2021-07-12 18:36:48,707 [run_pretraining.py:  535]:	loss/mlm_loss, 9.805829048156738, 411
[INFO] 2021-07-12 18:36:48,707 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.099999841855606e-06, 411
[INFO] 2021-07-12 18:36:48,707 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 411
[INFO] 2021-07-12 18:36:48,707 [run_pretraining.py:  558]:	worker_index: 3, step: 411, cost: 9.805829, mlm loss: 9.805829, speed: 0.959324 steps/s, speed: 7.674589 samples/s, speed: 3929.389653 tokens/s, learning rate: 4.100e-06, loss_scalings: 13421.773438, pp_loss: 9.424049
[INFO] 2021-07-12 18:36:48,707 [run_pretraining.py:  512]:	********exe.run_411******* 
[INFO] 2021-07-12 18:36:49,746 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:49,747 [run_pretraining.py:  534]:	loss/total_loss, 9.609339714050293, 412
[INFO] 2021-07-12 18:36:49,747 [run_pretraining.py:  535]:	loss/mlm_loss, 9.609339714050293, 412
[INFO] 2021-07-12 18:36:49,747 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.109999736101599e-06, 412
[INFO] 2021-07-12 18:36:49,747 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 412
[INFO] 2021-07-12 18:36:49,747 [run_pretraining.py:  558]:	worker_index: 3, step: 412, cost: 9.609340, mlm loss: 9.609340, speed: 0.962023 steps/s, speed: 7.696184 samples/s, speed: 3940.446325 tokens/s, learning rate: 4.110e-06, loss_scalings: 13421.773438, pp_loss: 9.482155
[INFO] 2021-07-12 18:36:49,747 [run_pretraining.py:  512]:	********exe.run_412******* 
[INFO] 2021-07-12 18:36:50,809 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:50,809 [run_pretraining.py:  534]:	loss/total_loss, 9.175910949707031, 413
[INFO] 2021-07-12 18:36:50,809 [run_pretraining.py:  535]:	loss/mlm_loss, 9.175910949707031, 413
[INFO] 2021-07-12 18:36:50,809 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.120000085094944e-06, 413
[INFO] 2021-07-12 18:36:50,809 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 413
[INFO] 2021-07-12 18:36:50,810 [run_pretraining.py:  558]:	worker_index: 3, step: 413, cost: 9.175911, mlm loss: 9.175911, speed: 0.941810 steps/s, speed: 7.534477 samples/s, speed: 3857.652263 tokens/s, learning rate: 4.120e-06, loss_scalings: 13421.773438, pp_loss: 9.267552
[INFO] 2021-07-12 18:36:50,810 [run_pretraining.py:  512]:	********exe.run_413******* 
[INFO] 2021-07-12 18:36:51,867 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:51,868 [run_pretraining.py:  534]:	loss/total_loss, 9.19276237487793, 414
[INFO] 2021-07-12 18:36:51,868 [run_pretraining.py:  535]:	loss/mlm_loss, 9.19276237487793, 414
[INFO] 2021-07-12 18:36:51,868 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.129999979340937e-06, 414
[INFO] 2021-07-12 18:36:51,868 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 414
[INFO] 2021-07-12 18:36:51,868 [run_pretraining.py:  558]:	worker_index: 3, step: 414, cost: 9.192762, mlm loss: 9.192762, speed: 0.945263 steps/s, speed: 7.562101 samples/s, speed: 3871.795532 tokens/s, learning rate: 4.130e-06, loss_scalings: 13421.773438, pp_loss: 9.360119
[INFO] 2021-07-12 18:36:51,868 [run_pretraining.py:  512]:	********exe.run_414******* 
[INFO] 2021-07-12 18:36:52,918 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:52,919 [run_pretraining.py:  534]:	loss/total_loss, 9.221433639526367, 415
[INFO] 2021-07-12 18:36:52,919 [run_pretraining.py:  535]:	loss/mlm_loss, 9.221433639526367, 415
[INFO] 2021-07-12 18:36:52,919 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.13999987358693e-06, 415
[INFO] 2021-07-12 18:36:52,919 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 415
[INFO] 2021-07-12 18:36:52,919 [run_pretraining.py:  558]:	worker_index: 3, step: 415, cost: 9.221434, mlm loss: 9.221434, speed: 0.951914 steps/s, speed: 7.615315 samples/s, speed: 3899.041115 tokens/s, learning rate: 4.140e-06, loss_scalings: 13421.773438, pp_loss: 9.209852
[INFO] 2021-07-12 18:36:52,919 [run_pretraining.py:  512]:	********exe.run_415******* 
[INFO] 2021-07-12 18:36:53,967 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:53,967 [run_pretraining.py:  534]:	loss/total_loss, 9.081954956054688, 416
[INFO] 2021-07-12 18:36:53,968 [run_pretraining.py:  535]:	loss/mlm_loss, 9.081954956054688, 416
[INFO] 2021-07-12 18:36:53,968 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.149999767832924e-06, 416
[INFO] 2021-07-12 18:36:53,968 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 416
[INFO] 2021-07-12 18:36:53,968 [run_pretraining.py:  558]:	worker_index: 3, step: 416, cost: 9.081955, mlm loss: 9.081955, speed: 0.954286 steps/s, speed: 7.634285 samples/s, speed: 3908.754057 tokens/s, learning rate: 4.150e-06, loss_scalings: 13421.773438, pp_loss: 9.197205
[INFO] 2021-07-12 18:36:53,968 [run_pretraining.py:  512]:	********exe.run_416******* 
[INFO] 2021-07-12 18:36:55,024 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:55,025 [run_pretraining.py:  534]:	loss/total_loss, 9.582530975341797, 417
[INFO] 2021-07-12 18:36:55,025 [run_pretraining.py:  535]:	loss/mlm_loss, 9.582530975341797, 417
[INFO] 2021-07-12 18:36:55,025 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.160000116826268e-06, 417
[INFO] 2021-07-12 18:36:55,025 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 417
[INFO] 2021-07-12 18:36:55,025 [run_pretraining.py:  558]:	worker_index: 3, step: 417, cost: 9.582531, mlm loss: 9.582531, speed: 0.946534 steps/s, speed: 7.572272 samples/s, speed: 3877.003100 tokens/s, learning rate: 4.160e-06, loss_scalings: 13421.773438, pp_loss: 9.220658
[INFO] 2021-07-12 18:36:55,025 [run_pretraining.py:  512]:	********exe.run_417******* 
[INFO] 2021-07-12 18:36:56,084 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:56,085 [run_pretraining.py:  534]:	loss/total_loss, 9.470796585083008, 418
[INFO] 2021-07-12 18:36:56,085 [run_pretraining.py:  535]:	loss/mlm_loss, 9.470796585083008, 418
[INFO] 2021-07-12 18:36:56,085 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.170000011072261e-06, 418
[INFO] 2021-07-12 18:36:56,085 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 418
[INFO] 2021-07-12 18:36:56,085 [run_pretraining.py:  558]:	worker_index: 3, step: 418, cost: 9.470797, mlm loss: 9.470797, speed: 0.943954 steps/s, speed: 7.551629 samples/s, speed: 3866.433985 tokens/s, learning rate: 4.170e-06, loss_scalings: 13421.773438, pp_loss: 9.299614
[INFO] 2021-07-12 18:36:56,085 [run_pretraining.py:  512]:	********exe.run_418******* 
[INFO] 2021-07-12 18:36:57,133 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:57,134 [run_pretraining.py:  534]:	loss/total_loss, 9.2263822555542, 419
[INFO] 2021-07-12 18:36:57,134 [run_pretraining.py:  535]:	loss/mlm_loss, 9.2263822555542, 419
[INFO] 2021-07-12 18:36:57,134 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.179999905318255e-06, 419
[INFO] 2021-07-12 18:36:57,134 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 419
[INFO] 2021-07-12 18:36:57,134 [run_pretraining.py:  558]:	worker_index: 3, step: 419, cost: 9.226382, mlm loss: 9.226382, speed: 0.953469 steps/s, speed: 7.627753 samples/s, speed: 3905.409530 tokens/s, learning rate: 4.180e-06, loss_scalings: 13421.773438, pp_loss: 9.027123
[INFO] 2021-07-12 18:36:57,134 [run_pretraining.py:  512]:	********exe.run_419******* 
[INFO] 2021-07-12 18:36:58,192 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:58,193 [run_pretraining.py:  534]:	loss/total_loss, 9.38283634185791, 420
[INFO] 2021-07-12 18:36:58,193 [run_pretraining.py:  535]:	loss/mlm_loss, 9.38283634185791, 420
[INFO] 2021-07-12 18:36:58,193 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.190000254311599e-06, 420
[INFO] 2021-07-12 18:36:58,193 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 420
[INFO] 2021-07-12 18:36:58,193 [run_pretraining.py:  558]:	worker_index: 3, step: 420, cost: 9.382836, mlm loss: 9.382836, speed: 0.945203 steps/s, speed: 7.561627 samples/s, speed: 3871.552970 tokens/s, learning rate: 4.190e-06, loss_scalings: 13421.773438, pp_loss: 9.232992
[INFO] 2021-07-12 18:36:58,193 [run_pretraining.py:  512]:	********exe.run_420******* 
[INFO] 2021-07-12 18:36:59,245 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:59,245 [run_pretraining.py:  534]:	loss/total_loss, 9.405403137207031, 421
[INFO] 2021-07-12 18:36:59,245 [run_pretraining.py:  535]:	loss/mlm_loss, 9.405403137207031, 421
[INFO] 2021-07-12 18:36:59,245 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.199999693810241e-06, 421
[INFO] 2021-07-12 18:36:59,245 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 421
[INFO] 2021-07-12 18:36:59,245 [run_pretraining.py:  558]:	worker_index: 3, step: 421, cost: 9.405403, mlm loss: 9.405403, speed: 0.950780 steps/s, speed: 7.606243 samples/s, speed: 3894.396488 tokens/s, learning rate: 4.200e-06, loss_scalings: 13421.773438, pp_loss: 7.687868
[INFO] 2021-07-12 18:36:59,245 [run_pretraining.py:  512]:	********exe.run_421******* 
[INFO] 2021-07-12 18:37:00,303 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:00,303 [run_pretraining.py:  534]:	loss/total_loss, 9.152116775512695, 422
[INFO] 2021-07-12 18:37:00,304 [run_pretraining.py:  535]:	loss/mlm_loss, 9.152116775512695, 422
[INFO] 2021-07-12 18:37:00,304 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.2100000428035855e-06, 422
[INFO] 2021-07-12 18:37:00,304 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 422
[INFO] 2021-07-12 18:37:00,304 [run_pretraining.py:  558]:	worker_index: 3, step: 422, cost: 9.152117, mlm loss: 9.152117, speed: 0.945448 steps/s, speed: 7.563585 samples/s, speed: 3872.555697 tokens/s, learning rate: 4.210e-06, loss_scalings: 13421.773438, pp_loss: 9.152132
[INFO] 2021-07-12 18:37:00,304 [run_pretraining.py:  512]:	********exe.run_422******* 
[INFO] 2021-07-12 18:37:01,353 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:01,354 [run_pretraining.py:  534]:	loss/total_loss, 9.073262214660645, 423
[INFO] 2021-07-12 18:37:01,354 [run_pretraining.py:  535]:	loss/mlm_loss, 9.073262214660645, 423
[INFO] 2021-07-12 18:37:01,354 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.219999937049579e-06, 423
[INFO] 2021-07-12 18:37:01,354 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 423
[INFO] 2021-07-12 18:37:01,354 [run_pretraining.py:  558]:	worker_index: 3, step: 423, cost: 9.073262, mlm loss: 9.073262, speed: 0.952718 steps/s, speed: 7.621746 samples/s, speed: 3902.333964 tokens/s, learning rate: 4.220e-06, loss_scalings: 13421.773438, pp_loss: 9.168361
[INFO] 2021-07-12 18:37:01,354 [run_pretraining.py:  512]:	********exe.run_423******* 
[INFO] 2021-07-12 18:37:02,405 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:02,406 [run_pretraining.py:  534]:	loss/total_loss, 9.44327163696289, 424
[INFO] 2021-07-12 18:37:02,406 [run_pretraining.py:  535]:	loss/mlm_loss, 9.44327163696289, 424
[INFO] 2021-07-12 18:37:02,406 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.229999831295572e-06, 424
[INFO] 2021-07-12 18:37:02,406 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 424
[INFO] 2021-07-12 18:37:02,406 [run_pretraining.py:  558]:	worker_index: 3, step: 424, cost: 9.443272, mlm loss: 9.443272, speed: 0.951251 steps/s, speed: 7.610009 samples/s, speed: 3896.324587 tokens/s, learning rate: 4.230e-06, loss_scalings: 13421.773438, pp_loss: 9.297142
[INFO] 2021-07-12 18:37:02,406 [run_pretraining.py:  512]:	********exe.run_424******* 
[INFO] 2021-07-12 18:37:03,461 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:03,461 [run_pretraining.py:  534]:	loss/total_loss, 9.190603256225586, 425
[INFO] 2021-07-12 18:37:03,461 [run_pretraining.py:  535]:	loss/mlm_loss, 9.190603256225586, 425
[INFO] 2021-07-12 18:37:03,461 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.2399997255415656e-06, 425
[INFO] 2021-07-12 18:37:03,462 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 425
[INFO] 2021-07-12 18:37:03,462 [run_pretraining.py:  558]:	worker_index: 3, step: 425, cost: 9.190603, mlm loss: 9.190603, speed: 0.947825 steps/s, speed: 7.582600 samples/s, speed: 3882.291370 tokens/s, learning rate: 4.240e-06, loss_scalings: 13421.773438, pp_loss: 9.215292
[INFO] 2021-07-12 18:37:03,462 [run_pretraining.py:  512]:	********exe.run_425******* 
[INFO] 2021-07-12 18:37:04,518 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:04,519 [run_pretraining.py:  534]:	loss/total_loss, 9.475677490234375, 426
[INFO] 2021-07-12 18:37:04,519 [run_pretraining.py:  535]:	loss/mlm_loss, 9.475677490234375, 426
[INFO] 2021-07-12 18:37:04,519 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.25000007453491e-06, 426
[INFO] 2021-07-12 18:37:04,519 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 426
[INFO] 2021-07-12 18:37:04,519 [run_pretraining.py:  558]:	worker_index: 3, step: 426, cost: 9.475677, mlm loss: 9.475677, speed: 0.946258 steps/s, speed: 7.570068 samples/s, speed: 3875.874771 tokens/s, learning rate: 4.250e-06, loss_scalings: 13421.773438, pp_loss: 9.344726
[INFO] 2021-07-12 18:37:04,519 [run_pretraining.py:  512]:	********exe.run_426******* 
[INFO] 2021-07-12 18:37:05,646 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:05,646 [run_pretraining.py:  534]:	loss/total_loss, 9.271888732910156, 427
[INFO] 2021-07-12 18:37:05,646 [run_pretraining.py:  535]:	loss/mlm_loss, 9.271888732910156, 427
[INFO] 2021-07-12 18:37:05,646 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.259999514033552e-06, 427
[INFO] 2021-07-12 18:37:05,646 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 427
[INFO] 2021-07-12 18:37:05,646 [run_pretraining.py:  558]:	worker_index: 3, step: 427, cost: 9.271889, mlm loss: 9.271889, speed: 0.887494 steps/s, speed: 7.099949 samples/s, speed: 3635.174108 tokens/s, learning rate: 4.260e-06, loss_scalings: 13421.773438, pp_loss: 9.184246
[INFO] 2021-07-12 18:37:05,646 [run_pretraining.py:  512]:	********exe.run_427******* 
[INFO] 2021-07-12 18:37:06,745 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:06,746 [run_pretraining.py:  534]:	loss/total_loss, 8.961224555969238, 428
[INFO] 2021-07-12 18:37:06,746 [run_pretraining.py:  535]:	loss/mlm_loss, 8.961224555969238, 428
[INFO] 2021-07-12 18:37:06,746 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.2699998630268965e-06, 428
[INFO] 2021-07-12 18:37:06,746 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 428
[INFO] 2021-07-12 18:37:06,746 [run_pretraining.py:  558]:	worker_index: 3, step: 428, cost: 8.961225, mlm loss: 8.961225, speed: 0.909700 steps/s, speed: 7.277600 samples/s, speed: 3726.131416 tokens/s, learning rate: 4.270e-06, loss_scalings: 13421.773438, pp_loss: 9.158501
[INFO] 2021-07-12 18:37:06,746 [run_pretraining.py:  512]:	********exe.run_428******* 
[INFO] 2021-07-12 18:37:07,844 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:07,844 [run_pretraining.py:  534]:	loss/total_loss, 9.190980911254883, 429
[INFO] 2021-07-12 18:37:07,845 [run_pretraining.py:  535]:	loss/mlm_loss, 9.190980911254883, 429
[INFO] 2021-07-12 18:37:07,845 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.280000212020241e-06, 429
[INFO] 2021-07-12 18:37:07,845 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 429
[INFO] 2021-07-12 18:37:07,845 [run_pretraining.py:  558]:	worker_index: 3, step: 429, cost: 9.190981, mlm loss: 9.190981, speed: 0.910933 steps/s, speed: 7.287462 samples/s, speed: 3731.180349 tokens/s, learning rate: 4.280e-06, loss_scalings: 13421.773438, pp_loss: 8.433676
[INFO] 2021-07-12 18:37:07,845 [run_pretraining.py:  512]:	********exe.run_429******* 
[INFO] 2021-07-12 18:37:08,888 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:08,889 [run_pretraining.py:  534]:	loss/total_loss, 6.737278938293457, 430
[INFO] 2021-07-12 18:37:08,889 [run_pretraining.py:  535]:	loss/mlm_loss, 6.737278938293457, 430
[INFO] 2021-07-12 18:37:08,889 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.289999651518883e-06, 430
[INFO] 2021-07-12 18:37:08,889 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 430
[INFO] 2021-07-12 18:37:08,889 [run_pretraining.py:  558]:	worker_index: 3, step: 430, cost: 6.737279, mlm loss: 6.737279, speed: 0.958159 steps/s, speed: 7.665269 samples/s, speed: 3924.617794 tokens/s, learning rate: 4.290e-06, loss_scalings: 13421.773438, pp_loss: 8.521655
[INFO] 2021-07-12 18:37:08,889 [run_pretraining.py:  512]:	********exe.run_430******* 
[INFO] 2021-07-12 18:37:09,960 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:09,961 [run_pretraining.py:  534]:	loss/total_loss, 9.16454029083252, 431
[INFO] 2021-07-12 18:37:09,961 [run_pretraining.py:  535]:	loss/mlm_loss, 9.16454029083252, 431
[INFO] 2021-07-12 18:37:09,961 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.300000000512227e-06, 431
[INFO] 2021-07-12 18:37:09,961 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 431
[INFO] 2021-07-12 18:37:09,961 [run_pretraining.py:  558]:	worker_index: 3, step: 431, cost: 9.164540, mlm loss: 9.164540, speed: 0.933538 steps/s, speed: 7.468307 samples/s, speed: 3823.773275 tokens/s, learning rate: 4.300e-06, loss_scalings: 13421.773438, pp_loss: 9.133185
[INFO] 2021-07-12 18:37:09,961 [run_pretraining.py:  512]:	********exe.run_431******* 
[INFO] 2021-07-12 18:37:11,013 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:11,013 [run_pretraining.py:  534]:	loss/total_loss, 8.81074333190918, 432
[INFO] 2021-07-12 18:37:11,014 [run_pretraining.py:  535]:	loss/mlm_loss, 8.81074333190918, 432
[INFO] 2021-07-12 18:37:11,014 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.309999894758221e-06, 432
[INFO] 2021-07-12 18:37:11,014 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 432
[INFO] 2021-07-12 18:37:11,014 [run_pretraining.py:  558]:	worker_index: 3, step: 432, cost: 8.810743, mlm loss: 8.810743, speed: 0.950308 steps/s, speed: 7.602467 samples/s, speed: 3892.463242 tokens/s, learning rate: 4.310e-06, loss_scalings: 13421.773438, pp_loss: 9.135437
[INFO] 2021-07-12 18:37:11,014 [run_pretraining.py:  512]:	********exe.run_432******* 
[INFO] 2021-07-12 18:37:12,065 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:12,066 [run_pretraining.py:  534]:	loss/total_loss, 8.865949630737305, 433
[INFO] 2021-07-12 18:37:12,066 [run_pretraining.py:  535]:	loss/mlm_loss, 8.865949630737305, 433
[INFO] 2021-07-12 18:37:12,066 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.319999789004214e-06, 433
[INFO] 2021-07-12 18:37:12,066 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 433
[INFO] 2021-07-12 18:37:12,066 [run_pretraining.py:  558]:	worker_index: 3, step: 433, cost: 8.865950, mlm loss: 8.865950, speed: 0.950987 steps/s, speed: 7.607895 samples/s, speed: 3895.242391 tokens/s, learning rate: 4.320e-06, loss_scalings: 13421.773438, pp_loss: 9.144590
[INFO] 2021-07-12 18:37:12,066 [run_pretraining.py:  512]:	********exe.run_433******* 
[INFO] 2021-07-12 18:37:13,107 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:13,108 [run_pretraining.py:  534]:	loss/total_loss, 9.491987228393555, 434
[INFO] 2021-07-12 18:37:13,108 [run_pretraining.py:  535]:	loss/mlm_loss, 9.491987228393555, 434
[INFO] 2021-07-12 18:37:13,108 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.3299996832502075e-06, 434
[INFO] 2021-07-12 18:37:13,108 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 434
[INFO] 2021-07-12 18:37:13,108 [run_pretraining.py:  558]:	worker_index: 3, step: 434, cost: 9.491987, mlm loss: 9.491987, speed: 0.960372 steps/s, speed: 7.682975 samples/s, speed: 3933.683090 tokens/s, learning rate: 4.330e-06, loss_scalings: 13421.773438, pp_loss: 8.235098
[INFO] 2021-07-12 18:37:13,108 [run_pretraining.py:  512]:	********exe.run_434******* 
[INFO] 2021-07-12 18:37:14,162 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:14,163 [run_pretraining.py:  534]:	loss/total_loss, 9.321788787841797, 435
[INFO] 2021-07-12 18:37:14,163 [run_pretraining.py:  535]:	loss/mlm_loss, 9.321788787841797, 435
[INFO] 2021-07-12 18:37:14,163 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.340000032243552e-06, 435
[INFO] 2021-07-12 18:37:14,163 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 435
[INFO] 2021-07-12 18:37:14,163 [run_pretraining.py:  558]:	worker_index: 3, step: 435, cost: 9.321789, mlm loss: 9.321789, speed: 0.948037 steps/s, speed: 7.584297 samples/s, speed: 3883.160108 tokens/s, learning rate: 4.340e-06, loss_scalings: 13421.773438, pp_loss: 9.324637
[INFO] 2021-07-12 18:37:14,163 [run_pretraining.py:  512]:	********exe.run_435******* 
[INFO] 2021-07-12 18:37:15,210 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:15,210 [run_pretraining.py:  534]:	loss/total_loss, 9.144463539123535, 436
[INFO] 2021-07-12 18:37:15,211 [run_pretraining.py:  535]:	loss/mlm_loss, 9.144463539123535, 436
[INFO] 2021-07-12 18:37:15,211 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.349999926489545e-06, 436
[INFO] 2021-07-12 18:37:15,211 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 436
[INFO] 2021-07-12 18:37:15,211 [run_pretraining.py:  558]:	worker_index: 3, step: 436, cost: 9.144464, mlm loss: 9.144464, speed: 0.955298 steps/s, speed: 7.642383 samples/s, speed: 3912.900001 tokens/s, learning rate: 4.350e-06, loss_scalings: 13421.773438, pp_loss: 9.191553
[INFO] 2021-07-12 18:37:15,211 [run_pretraining.py:  512]:	********exe.run_436******* 
[INFO] 2021-07-12 18:37:16,269 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:16,270 [run_pretraining.py:  534]:	loss/total_loss, 9.264245986938477, 437
[INFO] 2021-07-12 18:37:16,270 [run_pretraining.py:  535]:	loss/mlm_loss, 9.264245986938477, 437
[INFO] 2021-07-12 18:37:16,270 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.359999820735538e-06, 437
[INFO] 2021-07-12 18:37:16,270 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 437
[INFO] 2021-07-12 18:37:16,270 [run_pretraining.py:  558]:	worker_index: 3, step: 437, cost: 9.264246, mlm loss: 9.264246, speed: 0.944571 steps/s, speed: 7.556569 samples/s, speed: 3868.963467 tokens/s, learning rate: 4.360e-06, loss_scalings: 13421.773438, pp_loss: 9.087523
[INFO] 2021-07-12 18:37:16,270 [run_pretraining.py:  512]:	********exe.run_437******* 
[INFO] 2021-07-12 18:37:17,323 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:17,323 [run_pretraining.py:  534]:	loss/total_loss, 9.342289924621582, 438
[INFO] 2021-07-12 18:37:17,323 [run_pretraining.py:  535]:	loss/mlm_loss, 9.342289924621582, 438
[INFO] 2021-07-12 18:37:17,324 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.369999714981532e-06, 438
[INFO] 2021-07-12 18:37:17,324 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 438
[INFO] 2021-07-12 18:37:17,324 [run_pretraining.py:  558]:	worker_index: 3, step: 438, cost: 9.342290, mlm loss: 9.342290, speed: 0.949747 steps/s, speed: 7.597979 samples/s, speed: 3890.165434 tokens/s, learning rate: 4.370e-06, loss_scalings: 13421.773438, pp_loss: 9.401615
[INFO] 2021-07-12 18:37:17,324 [run_pretraining.py:  512]:	********exe.run_438******* 
[INFO] 2021-07-12 18:37:18,374 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:18,375 [run_pretraining.py:  534]:	loss/total_loss, 9.204853057861328, 439
[INFO] 2021-07-12 18:37:18,375 [run_pretraining.py:  535]:	loss/mlm_loss, 9.204853057861328, 439
[INFO] 2021-07-12 18:37:18,375 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.380000063974876e-06, 439
[INFO] 2021-07-12 18:37:18,375 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 439
[INFO] 2021-07-12 18:37:18,375 [run_pretraining.py:  558]:	worker_index: 3, step: 439, cost: 9.204853, mlm loss: 9.204853, speed: 0.951843 steps/s, speed: 7.614744 samples/s, speed: 3898.749119 tokens/s, learning rate: 4.380e-06, loss_scalings: 13421.773438, pp_loss: 9.076835
[INFO] 2021-07-12 18:37:18,375 [run_pretraining.py:  512]:	********exe.run_439******* 
[INFO] 2021-07-12 18:37:19,427 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:19,427 [run_pretraining.py:  534]:	loss/total_loss, 9.23170280456543, 440
[INFO] 2021-07-12 18:37:19,427 [run_pretraining.py:  535]:	loss/mlm_loss, 9.23170280456543, 440
[INFO] 2021-07-12 18:37:19,427 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.389999958220869e-06, 440
[INFO] 2021-07-12 18:37:19,428 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 440
[INFO] 2021-07-12 18:37:19,428 [run_pretraining.py:  558]:	worker_index: 3, step: 440, cost: 9.231703, mlm loss: 9.231703, speed: 0.950580 steps/s, speed: 7.604643 samples/s, speed: 3893.577426 tokens/s, learning rate: 4.390e-06, loss_scalings: 13421.773438, pp_loss: 9.185461
[INFO] 2021-07-12 18:37:19,428 [run_pretraining.py:  512]:	********exe.run_440******* 
[INFO] 2021-07-12 18:37:20,488 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:20,488 [run_pretraining.py:  534]:	loss/total_loss, 9.179771423339844, 441
[INFO] 2021-07-12 18:37:20,488 [run_pretraining.py:  535]:	loss/mlm_loss, 9.179771423339844, 441
[INFO] 2021-07-12 18:37:20,489 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.399999852466863e-06, 441
[INFO] 2021-07-12 18:37:20,489 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 441
[INFO] 2021-07-12 18:37:20,489 [run_pretraining.py:  558]:	worker_index: 3, step: 441, cost: 9.179771, mlm loss: 9.179771, speed: 0.943027 steps/s, speed: 7.544216 samples/s, speed: 3862.638576 tokens/s, learning rate: 4.400e-06, loss_scalings: 13421.773438, pp_loss: 9.055443
[INFO] 2021-07-12 18:37:20,489 [run_pretraining.py:  512]:	********exe.run_441******* 
[INFO] 2021-07-12 18:37:21,540 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:21,541 [run_pretraining.py:  534]:	loss/total_loss, 9.091876029968262, 442
[INFO] 2021-07-12 18:37:21,541 [run_pretraining.py:  535]:	loss/mlm_loss, 9.091876029968262, 442
[INFO] 2021-07-12 18:37:21,541 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.410000201460207e-06, 442
[INFO] 2021-07-12 18:37:21,541 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 442
[INFO] 2021-07-12 18:37:21,541 [run_pretraining.py:  558]:	worker_index: 3, step: 442, cost: 9.091876, mlm loss: 9.091876, speed: 0.950903 steps/s, speed: 7.607223 samples/s, speed: 3894.897981 tokens/s, learning rate: 4.410e-06, loss_scalings: 13421.773438, pp_loss: 9.221936
[INFO] 2021-07-12 18:37:21,541 [run_pretraining.py:  512]:	********exe.run_442******* 
[INFO] 2021-07-12 18:37:22,623 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:22,624 [run_pretraining.py:  534]:	loss/total_loss, 9.464722633361816, 443
[INFO] 2021-07-12 18:37:22,624 [run_pretraining.py:  535]:	loss/mlm_loss, 9.464722633361816, 443
[INFO] 2021-07-12 18:37:22,624 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.419999640958849e-06, 443
[INFO] 2021-07-12 18:37:22,624 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 443
[INFO] 2021-07-12 18:37:22,624 [run_pretraining.py:  558]:	worker_index: 3, step: 443, cost: 9.464723, mlm loss: 9.464723, speed: 0.923860 steps/s, speed: 7.390878 samples/s, speed: 3784.129659 tokens/s, learning rate: 4.420e-06, loss_scalings: 13421.773438, pp_loss: 9.133587
[INFO] 2021-07-12 18:37:22,624 [run_pretraining.py:  512]:	********exe.run_443******* 
[INFO] 2021-07-12 18:37:23,684 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:23,684 [run_pretraining.py:  534]:	loss/total_loss, 9.19888687133789, 444
[INFO] 2021-07-12 18:37:23,685 [run_pretraining.py:  535]:	loss/mlm_loss, 9.19888687133789, 444
[INFO] 2021-07-12 18:37:23,685 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.4299999899521936e-06, 444
[INFO] 2021-07-12 18:37:23,685 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 444
[INFO] 2021-07-12 18:37:23,685 [run_pretraining.py:  558]:	worker_index: 3, step: 444, cost: 9.198887, mlm loss: 9.198887, speed: 0.943246 steps/s, speed: 7.545969 samples/s, speed: 3863.535901 tokens/s, learning rate: 4.430e-06, loss_scalings: 13421.773438, pp_loss: 9.299270
[INFO] 2021-07-12 18:37:23,685 [run_pretraining.py:  512]:	********exe.run_444******* 
[INFO] 2021-07-12 18:37:24,741 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:24,742 [run_pretraining.py:  534]:	loss/total_loss, 9.055482864379883, 445
[INFO] 2021-07-12 18:37:24,742 [run_pretraining.py:  535]:	loss/mlm_loss, 9.055482864379883, 445
[INFO] 2021-07-12 18:37:24,742 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.439999884198187e-06, 445
[INFO] 2021-07-12 18:37:24,742 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 445
[INFO] 2021-07-12 18:37:24,742 [run_pretraining.py:  558]:	worker_index: 3, step: 445, cost: 9.055483, mlm loss: 9.055483, speed: 0.946422 steps/s, speed: 7.571376 samples/s, speed: 3876.544692 tokens/s, learning rate: 4.440e-06, loss_scalings: 13421.773438, pp_loss: 9.082401
[INFO] 2021-07-12 18:37:24,742 [run_pretraining.py:  512]:	********exe.run_445******* 
[INFO] 2021-07-12 18:37:25,793 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:25,794 [run_pretraining.py:  534]:	loss/total_loss, 9.125773429870605, 446
[INFO] 2021-07-12 18:37:25,794 [run_pretraining.py:  535]:	loss/mlm_loss, 9.125773429870605, 446
[INFO] 2021-07-12 18:37:25,794 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.44999977844418e-06, 446
[INFO] 2021-07-12 18:37:25,794 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 446
[INFO] 2021-07-12 18:37:25,794 [run_pretraining.py:  558]:	worker_index: 3, step: 446, cost: 9.125773, mlm loss: 9.125773, speed: 0.951178 steps/s, speed: 7.609427 samples/s, speed: 3896.026812 tokens/s, learning rate: 4.450e-06, loss_scalings: 13421.773438, pp_loss: 9.348666
[INFO] 2021-07-12 18:37:25,794 [run_pretraining.py:  512]:	********exe.run_446******* 
[INFO] 2021-07-12 18:37:26,853 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:26,854 [run_pretraining.py:  534]:	loss/total_loss, 8.397443771362305, 447
[INFO] 2021-07-12 18:37:26,854 [run_pretraining.py:  535]:	loss/mlm_loss, 8.397443771362305, 447
[INFO] 2021-07-12 18:37:26,854 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.459999672690174e-06, 447
[INFO] 2021-07-12 18:37:26,854 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 447
[INFO] 2021-07-12 18:37:26,854 [run_pretraining.py:  558]:	worker_index: 3, step: 447, cost: 8.397444, mlm loss: 8.397444, speed: 0.943789 steps/s, speed: 7.550315 samples/s, speed: 3865.761465 tokens/s, learning rate: 4.460e-06, loss_scalings: 13421.773438, pp_loss: 9.096609
[INFO] 2021-07-12 18:37:26,854 [run_pretraining.py:  512]:	********exe.run_447******* 
[INFO] 2021-07-12 18:37:27,900 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:27,900 [run_pretraining.py:  534]:	loss/total_loss, 9.269798278808594, 448
[INFO] 2021-07-12 18:37:27,900 [run_pretraining.py:  535]:	loss/mlm_loss, 9.269798278808594, 448
[INFO] 2021-07-12 18:37:27,900 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.470000021683518e-06, 448
[INFO] 2021-07-12 18:37:27,900 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 448
[INFO] 2021-07-12 18:37:27,901 [run_pretraining.py:  558]:	worker_index: 3, step: 448, cost: 9.269798, mlm loss: 9.269798, speed: 0.956346 steps/s, speed: 7.650770 samples/s, speed: 3917.194078 tokens/s, learning rate: 4.470e-06, loss_scalings: 13421.773438, pp_loss: 9.174770
[INFO] 2021-07-12 18:37:27,901 [run_pretraining.py:  512]:	********exe.run_448******* 
[INFO] 2021-07-12 18:37:28,958 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:28,959 [run_pretraining.py:  534]:	loss/total_loss, 9.341373443603516, 449
[INFO] 2021-07-12 18:37:28,959 [run_pretraining.py:  535]:	loss/mlm_loss, 9.341373443603516, 449
[INFO] 2021-07-12 18:37:28,959 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.479999915929511e-06, 449
[INFO] 2021-07-12 18:37:28,959 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 449
[INFO] 2021-07-12 18:37:28,959 [run_pretraining.py:  558]:	worker_index: 3, step: 449, cost: 9.341373, mlm loss: 9.341373, speed: 0.945341 steps/s, speed: 7.562728 samples/s, speed: 3872.116667 tokens/s, learning rate: 4.480e-06, loss_scalings: 13421.773438, pp_loss: 9.203304
[INFO] 2021-07-12 18:37:28,959 [run_pretraining.py:  512]:	********exe.run_449******* 
[INFO] 2021-07-12 18:37:30,001 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:30,001 [run_pretraining.py:  534]:	loss/total_loss, 9.245660781860352, 450
[INFO] 2021-07-12 18:37:30,001 [run_pretraining.py:  535]:	loss/mlm_loss, 9.245660781860352, 450
[INFO] 2021-07-12 18:37:30,001 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.4899998101755045e-06, 450
[INFO] 2021-07-12 18:37:30,001 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 450
[INFO] 2021-07-12 18:37:30,002 [run_pretraining.py:  558]:	worker_index: 3, step: 450, cost: 9.245661, mlm loss: 9.245661, speed: 0.959819 steps/s, speed: 7.678549 samples/s, speed: 3931.417340 tokens/s, learning rate: 4.490e-06, loss_scalings: 13421.773438, pp_loss: 9.355990
[INFO] 2021-07-12 18:37:30,002 [run_pretraining.py:  512]:	********exe.run_450******* 
[INFO] 2021-07-12 18:37:31,058 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:31,058 [run_pretraining.py:  534]:	loss/total_loss, 9.18254566192627, 451
[INFO] 2021-07-12 18:37:31,058 [run_pretraining.py:  535]:	loss/mlm_loss, 9.18254566192627, 451
[INFO] 2021-07-12 18:37:31,059 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.500000159168849e-06, 451
[INFO] 2021-07-12 18:37:31,059 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 451
[INFO] 2021-07-12 18:37:31,059 [run_pretraining.py:  558]:	worker_index: 3, step: 451, cost: 9.182546, mlm loss: 9.182546, speed: 0.946460 steps/s, speed: 7.571680 samples/s, speed: 3876.700398 tokens/s, learning rate: 4.500e-06, loss_scalings: 13421.773438, pp_loss: 9.103541
[INFO] 2021-07-12 18:37:31,059 [run_pretraining.py:  512]:	********exe.run_451******* 
[INFO] 2021-07-12 18:37:56,813 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:56,813 [run_pretraining.py:  534]:	loss/total_loss, 9.0501070022583, 452
[INFO] 2021-07-12 18:37:56,813 [run_pretraining.py:  535]:	loss/mlm_loss, 9.0501070022583, 452
[INFO] 2021-07-12 18:37:56,813 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.510000053414842e-06, 452
[INFO] 2021-07-12 18:37:56,813 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 452
[INFO] 2021-07-12 18:37:56,813 [run_pretraining.py:  558]:	worker_index: 3, step: 452, cost: 9.050107, mlm loss: 9.050107, speed: 0.038829 steps/s, speed: 0.310631 samples/s, speed: 159.043039 tokens/s, learning rate: 4.510e-06, loss_scalings: 13421.773438, pp_loss: 9.146403
[INFO] 2021-07-12 18:37:56,813 [run_pretraining.py:  512]:	********exe.run_452******* 
[INFO] 2021-07-12 18:37:57,726 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:57,727 [run_pretraining.py:  534]:	loss/total_loss, 9.455084800720215, 453
[INFO] 2021-07-12 18:37:57,727 [run_pretraining.py:  535]:	loss/mlm_loss, 9.455084800720215, 453
[INFO] 2021-07-12 18:37:57,727 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.5199999476608355e-06, 453
[INFO] 2021-07-12 18:37:57,727 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 453
[INFO] 2021-07-12 18:37:57,727 [run_pretraining.py:  558]:	worker_index: 3, step: 453, cost: 9.455085, mlm loss: 9.455085, speed: 1.095535 steps/s, speed: 8.764280 samples/s, speed: 4487.311412 tokens/s, learning rate: 4.520e-06, loss_scalings: 13421.773438, pp_loss: 9.177347
[INFO] 2021-07-12 18:37:57,727 [run_pretraining.py:  512]:	********exe.run_453******* 
[INFO] 2021-07-12 18:37:58,633 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:58,634 [run_pretraining.py:  534]:	loss/total_loss, 9.192644119262695, 454
[INFO] 2021-07-12 18:37:58,634 [run_pretraining.py:  535]:	loss/mlm_loss, 9.192644119262695, 454
[INFO] 2021-07-12 18:37:58,634 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.529999841906829e-06, 454
[INFO] 2021-07-12 18:37:58,634 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 454
[INFO] 2021-07-12 18:37:58,634 [run_pretraining.py:  558]:	worker_index: 3, step: 454, cost: 9.192644, mlm loss: 9.192644, speed: 1.103034 steps/s, speed: 8.824271 samples/s, speed: 4518.026797 tokens/s, learning rate: 4.530e-06, loss_scalings: 13421.773438, pp_loss: 9.235228
[INFO] 2021-07-12 18:37:58,634 [run_pretraining.py:  512]:	********exe.run_454******* 
[INFO] 2021-07-12 18:37:59,538 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:59,538 [run_pretraining.py:  534]:	loss/total_loss, 9.622639656066895, 455
[INFO] 2021-07-12 18:37:59,538 [run_pretraining.py:  535]:	loss/mlm_loss, 9.622639656066895, 455
[INFO] 2021-07-12 18:37:59,538 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.540000190900173e-06, 455
[INFO] 2021-07-12 18:37:59,538 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 455
[INFO] 2021-07-12 18:37:59,538 [run_pretraining.py:  558]:	worker_index: 3, step: 455, cost: 9.622640, mlm loss: 9.622640, speed: 1.106559 steps/s, speed: 8.852473 samples/s, speed: 4532.466262 tokens/s, learning rate: 4.540e-06, loss_scalings: 13421.773438, pp_loss: 9.255691
[INFO] 2021-07-12 18:37:59,538 [run_pretraining.py:  512]:	********exe.run_455******* 
[INFO] 2021-07-12 18:38:00,446 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:00,447 [run_pretraining.py:  534]:	loss/total_loss, 9.063323974609375, 456
[INFO] 2021-07-12 18:38:00,447 [run_pretraining.py:  535]:	loss/mlm_loss, 9.063323974609375, 456
[INFO] 2021-07-12 18:38:00,447 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.5499996303988155e-06, 456
[INFO] 2021-07-12 18:38:00,447 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 456
[INFO] 2021-07-12 18:38:00,447 [run_pretraining.py:  558]:	worker_index: 3, step: 456, cost: 9.063324, mlm loss: 9.063324, speed: 1.101043 steps/s, speed: 8.808343 samples/s, speed: 4509.871702 tokens/s, learning rate: 4.550e-06, loss_scalings: 13421.773438, pp_loss: 9.060595
[INFO] 2021-07-12 18:38:00,447 [run_pretraining.py:  512]:	********exe.run_456******* 
[INFO] 2021-07-12 18:38:01,347 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:01,348 [run_pretraining.py:  534]:	loss/total_loss, 8.79123592376709, 457
[INFO] 2021-07-12 18:38:01,348 [run_pretraining.py:  535]:	loss/mlm_loss, 8.79123592376709, 457
[INFO] 2021-07-12 18:38:01,348 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.55999997939216e-06, 457
[INFO] 2021-07-12 18:38:01,348 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 457
[INFO] 2021-07-12 18:38:01,348 [run_pretraining.py:  558]:	worker_index: 3, step: 457, cost: 8.791236, mlm loss: 8.791236, speed: 1.110626 steps/s, speed: 8.885009 samples/s, speed: 4549.124614 tokens/s, learning rate: 4.560e-06, loss_scalings: 13421.773438, pp_loss: 9.100542
[INFO] 2021-07-12 18:38:01,348 [run_pretraining.py:  512]:	********exe.run_457******* 
[INFO] 2021-07-12 18:38:02,257 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:02,257 [run_pretraining.py:  534]:	loss/total_loss, 9.076990127563477, 458
[INFO] 2021-07-12 18:38:02,257 [run_pretraining.py:  535]:	loss/mlm_loss, 9.076990127563477, 458
[INFO] 2021-07-12 18:38:02,257 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.569999873638153e-06, 458
[INFO] 2021-07-12 18:38:02,258 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 458
[INFO] 2021-07-12 18:38:02,258 [run_pretraining.py:  558]:	worker_index: 3, step: 458, cost: 9.076990, mlm loss: 9.076990, speed: 1.100594 steps/s, speed: 8.804754 samples/s, speed: 4508.033882 tokens/s, learning rate: 4.570e-06, loss_scalings: 13421.773438, pp_loss: 8.134977
[INFO] 2021-07-12 18:38:02,258 [run_pretraining.py:  512]:	********exe.run_458******* 
[INFO] 2021-07-12 18:38:03,173 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:03,174 [run_pretraining.py:  534]:	loss/total_loss, 8.979507446289062, 459
[INFO] 2021-07-12 18:38:03,174 [run_pretraining.py:  535]:	loss/mlm_loss, 8.979507446289062, 459
[INFO] 2021-07-12 18:38:03,174 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.579999767884146e-06, 459
[INFO] 2021-07-12 18:38:03,174 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 459
[INFO] 2021-07-12 18:38:03,174 [run_pretraining.py:  558]:	worker_index: 3, step: 459, cost: 8.979507, mlm loss: 8.979507, speed: 1.091752 steps/s, speed: 8.734014 samples/s, speed: 4471.815293 tokens/s, learning rate: 4.580e-06, loss_scalings: 13421.773438, pp_loss: 8.943666
[INFO] 2021-07-12 18:38:03,174 [run_pretraining.py:  512]:	********exe.run_459******* 
[INFO] 2021-07-12 18:38:04,088 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:04,089 [run_pretraining.py:  534]:	loss/total_loss, 9.361139297485352, 460
[INFO] 2021-07-12 18:38:04,089 [run_pretraining.py:  535]:	loss/mlm_loss, 9.361139297485352, 460
[INFO] 2021-07-12 18:38:04,089 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.58999966213014e-06, 460
[INFO] 2021-07-12 18:38:04,089 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 460
[INFO] 2021-07-12 18:38:04,089 [run_pretraining.py:  558]:	worker_index: 3, step: 460, cost: 9.361139, mlm loss: 9.361139, speed: 1.093863 steps/s, speed: 8.750904 samples/s, speed: 4480.462942 tokens/s, learning rate: 4.590e-06, loss_scalings: 13421.773438, pp_loss: 8.187467
[INFO] 2021-07-12 18:38:04,089 [run_pretraining.py:  512]:	********exe.run_460******* 
[INFO] 2021-07-12 18:38:04,994 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:04,995 [run_pretraining.py:  534]:	loss/total_loss, 9.28564167022705, 461
[INFO] 2021-07-12 18:38:04,995 [run_pretraining.py:  535]:	loss/mlm_loss, 9.28564167022705, 461
[INFO] 2021-07-12 18:38:04,995 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.600000011123484e-06, 461
[INFO] 2021-07-12 18:38:04,995 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 461
[INFO] 2021-07-12 18:38:04,995 [run_pretraining.py:  558]:	worker_index: 3, step: 461, cost: 9.285642, mlm loss: 9.285642, speed: 1.104604 steps/s, speed: 8.836834 samples/s, speed: 4524.459177 tokens/s, learning rate: 4.600e-06, loss_scalings: 13421.773438, pp_loss: 9.075467
[INFO] 2021-07-12 18:38:04,995 [run_pretraining.py:  512]:	********exe.run_461******* 
[INFO] 2021-07-12 18:38:05,900 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:05,900 [run_pretraining.py:  534]:	loss/total_loss, 9.11780071258545, 462
[INFO] 2021-07-12 18:38:05,900 [run_pretraining.py:  535]:	loss/mlm_loss, 9.11780071258545, 462
[INFO] 2021-07-12 18:38:05,901 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.609999905369477e-06, 462
[INFO] 2021-07-12 18:38:05,901 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 462
[INFO] 2021-07-12 18:38:05,901 [run_pretraining.py:  558]:	worker_index: 3, step: 462, cost: 9.117801, mlm loss: 9.117801, speed: 1.104841 steps/s, speed: 8.838724 samples/s, speed: 4525.426925 tokens/s, learning rate: 4.610e-06, loss_scalings: 13421.773438, pp_loss: 9.215981
[INFO] 2021-07-12 18:38:05,901 [run_pretraining.py:  512]:	********exe.run_462******* 
[INFO] 2021-07-12 18:38:06,807 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:06,808 [run_pretraining.py:  534]:	loss/total_loss, 9.070573806762695, 463
[INFO] 2021-07-12 18:38:06,808 [run_pretraining.py:  535]:	loss/mlm_loss, 9.070573806762695, 463
[INFO] 2021-07-12 18:38:06,808 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.619999799615471e-06, 463
[INFO] 2021-07-12 18:38:06,808 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 463
[INFO] 2021-07-12 18:38:06,808 [run_pretraining.py:  558]:	worker_index: 3, step: 463, cost: 9.070574, mlm loss: 9.070574, speed: 1.102879 steps/s, speed: 8.823030 samples/s, speed: 4517.391217 tokens/s, learning rate: 4.620e-06, loss_scalings: 13421.773438, pp_loss: 8.897766
[INFO] 2021-07-12 18:38:06,808 [run_pretraining.py:  512]:	********exe.run_463******* 
[INFO] 2021-07-12 18:38:07,718 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:07,718 [run_pretraining.py:  534]:	loss/total_loss, 8.879201889038086, 464
[INFO] 2021-07-12 18:38:07,718 [run_pretraining.py:  535]:	loss/mlm_loss, 8.879201889038086, 464
[INFO] 2021-07-12 18:38:07,718 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.630000148608815e-06, 464
[INFO] 2021-07-12 18:38:07,719 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 464
[INFO] 2021-07-12 18:38:07,719 [run_pretraining.py:  558]:	worker_index: 3, step: 464, cost: 8.879202, mlm loss: 8.879202, speed: 1.098975 steps/s, speed: 8.791800 samples/s, speed: 4501.401572 tokens/s, learning rate: 4.630e-06, loss_scalings: 13421.773438, pp_loss: 8.987175
[INFO] 2021-07-12 18:38:07,719 [run_pretraining.py:  512]:	********exe.run_464******* 
[INFO] 2021-07-12 18:38:08,631 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:08,631 [run_pretraining.py:  534]:	loss/total_loss, 9.215925216674805, 465
[INFO] 2021-07-12 18:38:08,632 [run_pretraining.py:  535]:	loss/mlm_loss, 9.215925216674805, 465
[INFO] 2021-07-12 18:38:08,632 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.640000042854808e-06, 465
[INFO] 2021-07-12 18:38:08,632 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 465
[INFO] 2021-07-12 18:38:08,632 [run_pretraining.py:  558]:	worker_index: 3, step: 465, cost: 9.215925, mlm loss: 9.215925, speed: 1.095833 steps/s, speed: 8.766664 samples/s, speed: 4488.531866 tokens/s, learning rate: 4.640e-06, loss_scalings: 13421.773438, pp_loss: 8.009297
[INFO] 2021-07-12 18:38:08,632 [run_pretraining.py:  512]:	********exe.run_465******* 
[INFO] 2021-07-12 18:38:09,536 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:09,536 [run_pretraining.py:  534]:	loss/total_loss, 9.217119216918945, 466
[INFO] 2021-07-12 18:38:09,536 [run_pretraining.py:  535]:	loss/mlm_loss, 9.217119216918945, 466
[INFO] 2021-07-12 18:38:09,536 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.649999937100802e-06, 466
[INFO] 2021-07-12 18:38:09,536 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 466
[INFO] 2021-07-12 18:38:09,536 [run_pretraining.py:  558]:	worker_index: 3, step: 466, cost: 9.217119, mlm loss: 9.217119, speed: 1.106110 steps/s, speed: 8.848878 samples/s, speed: 4530.625517 tokens/s, learning rate: 4.650e-06, loss_scalings: 13421.773438, pp_loss: 9.023371
[INFO] 2021-07-12 18:38:09,537 [run_pretraining.py:  512]:	********exe.run_466******* 
[INFO] 2021-07-12 18:38:10,449 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:10,450 [run_pretraining.py:  534]:	loss/total_loss, 9.063060760498047, 467
[INFO] 2021-07-12 18:38:10,450 [run_pretraining.py:  535]:	loss/mlm_loss, 9.063060760498047, 467
[INFO] 2021-07-12 18:38:10,450 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.659999831346795e-06, 467
[INFO] 2021-07-12 18:38:10,450 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 467
[INFO] 2021-07-12 18:38:10,450 [run_pretraining.py:  558]:	worker_index: 3, step: 467, cost: 9.063061, mlm loss: 9.063061, speed: 1.095392 steps/s, speed: 8.763133 samples/s, speed: 4486.724283 tokens/s, learning rate: 4.660e-06, loss_scalings: 13421.773438, pp_loss: 9.167099
[INFO] 2021-07-12 18:38:10,450 [run_pretraining.py:  512]:	********exe.run_467******* 
[INFO] 2021-07-12 18:38:11,363 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:11,363 [run_pretraining.py:  534]:	loss/total_loss, 9.341634750366211, 468
[INFO] 2021-07-12 18:38:11,364 [run_pretraining.py:  535]:	loss/mlm_loss, 9.341634750366211, 468
[INFO] 2021-07-12 18:38:11,364 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.670000180340139e-06, 468
[INFO] 2021-07-12 18:38:11,364 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 468
[INFO] 2021-07-12 18:38:11,364 [run_pretraining.py:  558]:	worker_index: 3, step: 468, cost: 9.341635, mlm loss: 9.341635, speed: 1.095262 steps/s, speed: 8.762094 samples/s, speed: 4486.192367 tokens/s, learning rate: 4.670e-06, loss_scalings: 13421.773438, pp_loss: 9.215553
[INFO] 2021-07-12 18:38:11,364 [run_pretraining.py:  512]:	********exe.run_468******* 
[INFO] 2021-07-12 18:38:12,271 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:12,272 [run_pretraining.py:  534]:	loss/total_loss, 9.090651512145996, 469
[INFO] 2021-07-12 18:38:12,272 [run_pretraining.py:  535]:	loss/mlm_loss, 9.090651512145996, 469
[INFO] 2021-07-12 18:38:12,272 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.679999619838782e-06, 469
[INFO] 2021-07-12 18:38:12,272 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 469
[INFO] 2021-07-12 18:38:12,272 [run_pretraining.py:  558]:	worker_index: 3, step: 469, cost: 9.090652, mlm loss: 9.090652, speed: 1.101696 steps/s, speed: 8.813567 samples/s, speed: 4512.546494 tokens/s, learning rate: 4.680e-06, loss_scalings: 13421.773438, pp_loss: 9.170155
[INFO] 2021-07-12 18:38:12,272 [run_pretraining.py:  512]:	********exe.run_469******* 
[INFO] 2021-07-12 18:38:13,177 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:13,177 [run_pretraining.py:  534]:	loss/total_loss, 9.144477844238281, 470
[INFO] 2021-07-12 18:38:13,177 [run_pretraining.py:  535]:	loss/mlm_loss, 9.144477844238281, 470
[INFO] 2021-07-12 18:38:13,177 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.689999968832126e-06, 470
[INFO] 2021-07-12 18:38:13,177 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 470
[INFO] 2021-07-12 18:38:13,177 [run_pretraining.py:  558]:	worker_index: 3, step: 470, cost: 9.144478, mlm loss: 9.144478, speed: 1.105220 steps/s, speed: 8.841762 samples/s, speed: 4526.981909 tokens/s, learning rate: 4.690e-06, loss_scalings: 13421.773438, pp_loss: 8.979557
[INFO] 2021-07-12 18:38:13,178 [run_pretraining.py:  512]:	********exe.run_470******* 
[INFO] 2021-07-12 18:38:14,090 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:14,091 [run_pretraining.py:  534]:	loss/total_loss, 8.733562469482422, 471
[INFO] 2021-07-12 18:38:14,091 [run_pretraining.py:  535]:	loss/mlm_loss, 8.733562469482422, 471
[INFO] 2021-07-12 18:38:14,091 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.699999863078119e-06, 471
[INFO] 2021-07-12 18:38:14,091 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 471
[INFO] 2021-07-12 18:38:14,091 [run_pretraining.py:  558]:	worker_index: 3, step: 471, cost: 8.733562, mlm loss: 8.733562, speed: 1.095115 steps/s, speed: 8.760916 samples/s, speed: 4485.589135 tokens/s, learning rate: 4.700e-06, loss_scalings: 13421.773438, pp_loss: 8.938213
[INFO] 2021-07-12 18:38:14,091 [run_pretraining.py:  512]:	********exe.run_471******* 
[INFO] 2021-07-12 18:38:15,005 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:15,005 [run_pretraining.py:  534]:	loss/total_loss, 9.452011108398438, 472
[INFO] 2021-07-12 18:38:15,005 [run_pretraining.py:  535]:	loss/mlm_loss, 9.452011108398438, 472
[INFO] 2021-07-12 18:38:15,005 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.709999757324113e-06, 472
[INFO] 2021-07-12 18:38:15,005 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 472
[INFO] 2021-07-12 18:38:15,005 [run_pretraining.py:  558]:	worker_index: 3, step: 472, cost: 9.452011, mlm loss: 9.452011, speed: 1.094748 steps/s, speed: 8.757985 samples/s, speed: 4484.088200 tokens/s, learning rate: 4.710e-06, loss_scalings: 13421.773438, pp_loss: 9.144822
[INFO] 2021-07-12 18:38:15,005 [run_pretraining.py:  512]:	********exe.run_472******* 
[INFO] 2021-07-12 18:38:15,946 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:15,947 [run_pretraining.py:  534]:	loss/total_loss, 8.90230655670166, 473
[INFO] 2021-07-12 18:38:15,947 [run_pretraining.py:  535]:	loss/mlm_loss, 8.90230655670166, 473
[INFO] 2021-07-12 18:38:15,947 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.720000106317457e-06, 473
[INFO] 2021-07-12 18:38:15,947 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 473
[INFO] 2021-07-12 18:38:15,947 [run_pretraining.py:  558]:	worker_index: 3, step: 473, cost: 8.902307, mlm loss: 8.902307, speed: 1.062589 steps/s, speed: 8.500709 samples/s, speed: 4352.362995 tokens/s, learning rate: 4.720e-06, loss_scalings: 13421.773438, pp_loss: 8.897797
[INFO] 2021-07-12 18:38:15,947 [run_pretraining.py:  512]:	********exe.run_473******* 
[INFO] 2021-07-12 18:38:16,851 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:16,851 [run_pretraining.py:  534]:	loss/total_loss, 9.098856925964355, 474
[INFO] 2021-07-12 18:38:16,851 [run_pretraining.py:  535]:	loss/mlm_loss, 9.098856925964355, 474
[INFO] 2021-07-12 18:38:16,851 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.73000000056345e-06, 474
[INFO] 2021-07-12 18:38:16,851 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 474
[INFO] 2021-07-12 18:38:16,851 [run_pretraining.py:  558]:	worker_index: 3, step: 474, cost: 9.098857, mlm loss: 9.098857, speed: 1.106652 steps/s, speed: 8.853214 samples/s, speed: 4532.845354 tokens/s, learning rate: 4.730e-06, loss_scalings: 13421.773438, pp_loss: 8.970028
[INFO] 2021-07-12 18:38:16,851 [run_pretraining.py:  512]:	********exe.run_474******* 
[INFO] 2021-07-12 18:38:17,760 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:17,761 [run_pretraining.py:  534]:	loss/total_loss, 8.79013729095459, 475
[INFO] 2021-07-12 18:38:17,761 [run_pretraining.py:  535]:	loss/mlm_loss, 8.79013729095459, 475
[INFO] 2021-07-12 18:38:17,761 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.7399998948094435e-06, 475
[INFO] 2021-07-12 18:38:17,761 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 475
[INFO] 2021-07-12 18:38:17,761 [run_pretraining.py:  558]:	worker_index: 3, step: 475, cost: 8.790137, mlm loss: 8.790137, speed: 1.100284 steps/s, speed: 8.802268 samples/s, speed: 4506.761422 tokens/s, learning rate: 4.740e-06, loss_scalings: 13421.773438, pp_loss: 8.827560
[INFO] 2021-07-12 18:38:17,761 [run_pretraining.py:  512]:	********exe.run_475******* 
[INFO] 2021-07-12 18:38:18,676 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:18,676 [run_pretraining.py:  534]:	loss/total_loss, 9.139334678649902, 476
[INFO] 2021-07-12 18:38:18,676 [run_pretraining.py:  535]:	loss/mlm_loss, 9.139334678649902, 476
[INFO] 2021-07-12 18:38:18,677 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.749999789055437e-06, 476
[INFO] 2021-07-12 18:38:18,677 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 476
[INFO] 2021-07-12 18:38:18,677 [run_pretraining.py:  558]:	worker_index: 3, step: 476, cost: 9.139335, mlm loss: 9.139335, speed: 1.092680 steps/s, speed: 8.741443 samples/s, speed: 4475.618941 tokens/s, learning rate: 4.750e-06, loss_scalings: 13421.773438, pp_loss: 8.965219
[INFO] 2021-07-12 18:38:18,677 [run_pretraining.py:  512]:	********exe.run_476******* 
[INFO] 2021-07-12 18:38:19,599 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:19,600 [run_pretraining.py:  534]:	loss/total_loss, 9.197513580322266, 477
[INFO] 2021-07-12 18:38:19,600 [run_pretraining.py:  535]:	loss/mlm_loss, 9.197513580322266, 477
[INFO] 2021-07-12 18:38:19,600 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.760000138048781e-06, 477
[INFO] 2021-07-12 18:38:19,600 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 477
[INFO] 2021-07-12 18:38:19,600 [run_pretraining.py:  558]:	worker_index: 3, step: 477, cost: 9.197514, mlm loss: 9.197514, speed: 1.083831 steps/s, speed: 8.670649 samples/s, speed: 4439.372308 tokens/s, learning rate: 4.760e-06, loss_scalings: 13421.773438, pp_loss: 8.782208
[INFO] 2021-07-12 18:38:19,600 [run_pretraining.py:  512]:	********exe.run_477******* 
[INFO] 2021-07-12 18:38:20,505 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:20,505 [run_pretraining.py:  534]:	loss/total_loss, 9.029485702514648, 478
[INFO] 2021-07-12 18:38:20,506 [run_pretraining.py:  535]:	loss/mlm_loss, 9.029485702514648, 478
[INFO] 2021-07-12 18:38:20,506 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.7699995775474235e-06, 478
[INFO] 2021-07-12 18:38:20,506 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 478
[INFO] 2021-07-12 18:38:20,506 [run_pretraining.py:  558]:	worker_index: 3, step: 478, cost: 9.029486, mlm loss: 9.029486, speed: 1.104820 steps/s, speed: 8.838559 samples/s, speed: 4525.342290 tokens/s, learning rate: 4.770e-06, loss_scalings: 13421.773438, pp_loss: 9.051397
[INFO] 2021-07-12 18:38:20,506 [run_pretraining.py:  512]:	********exe.run_478******* 
[INFO] 2021-07-12 18:38:21,424 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:21,424 [run_pretraining.py:  534]:	loss/total_loss, 9.289680480957031, 479
[INFO] 2021-07-12 18:38:21,424 [run_pretraining.py:  535]:	loss/mlm_loss, 9.289680480957031, 479
[INFO] 2021-07-12 18:38:21,424 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.779999926540768e-06, 479
[INFO] 2021-07-12 18:38:21,425 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 479
[INFO] 2021-07-12 18:38:21,425 [run_pretraining.py:  558]:	worker_index: 3, step: 479, cost: 9.289680, mlm loss: 9.289680, speed: 1.089097 steps/s, speed: 8.712773 samples/s, speed: 4460.939911 tokens/s, learning rate: 4.780e-06, loss_scalings: 13421.773438, pp_loss: 9.255054
[INFO] 2021-07-12 18:38:21,425 [run_pretraining.py:  512]:	********exe.run_479******* 
[INFO] 2021-07-12 18:38:22,335 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:22,336 [run_pretraining.py:  534]:	loss/total_loss, 9.197688102722168, 480
[INFO] 2021-07-12 18:38:22,336 [run_pretraining.py:  535]:	loss/mlm_loss, 9.197688102722168, 480
[INFO] 2021-07-12 18:38:22,336 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.789999820786761e-06, 480
[INFO] 2021-07-12 18:38:22,336 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 480
[INFO] 2021-07-12 18:38:22,336 [run_pretraining.py:  558]:	worker_index: 3, step: 480, cost: 9.197688, mlm loss: 9.197688, speed: 1.098195 steps/s, speed: 8.785564 samples/s, speed: 4498.208737 tokens/s, learning rate: 4.790e-06, loss_scalings: 13421.773438, pp_loss: 9.040926
[INFO] 2021-07-12 18:38:22,336 [run_pretraining.py:  512]:	********exe.run_480******* 
[INFO] 2021-07-12 18:38:23,239 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:23,240 [run_pretraining.py:  534]:	loss/total_loss, 8.733330726623535, 481
[INFO] 2021-07-12 18:38:23,240 [run_pretraining.py:  535]:	loss/mlm_loss, 8.733330726623535, 481
[INFO] 2021-07-12 18:38:23,240 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.7999997150327545e-06, 481
[INFO] 2021-07-12 18:38:23,240 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 481
[INFO] 2021-07-12 18:38:23,240 [run_pretraining.py:  558]:	worker_index: 3, step: 481, cost: 8.733331, mlm loss: 8.733331, speed: 1.106963 steps/s, speed: 8.855704 samples/s, speed: 4534.120622 tokens/s, learning rate: 4.800e-06, loss_scalings: 13421.773438, pp_loss: 8.889169
[INFO] 2021-07-12 18:38:23,240 [run_pretraining.py:  512]:	********exe.run_481******* 
[INFO] 2021-07-12 18:38:24,140 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:24,140 [run_pretraining.py:  534]:	loss/total_loss, 8.940753936767578, 482
[INFO] 2021-07-12 18:38:24,140 [run_pretraining.py:  535]:	loss/mlm_loss, 8.940753936767578, 482
[INFO] 2021-07-12 18:38:24,141 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.809999609278748e-06, 482
[INFO] 2021-07-12 18:38:24,141 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 482
[INFO] 2021-07-12 18:38:24,141 [run_pretraining.py:  558]:	worker_index: 3, step: 482, cost: 8.940754, mlm loss: 8.940754, speed: 1.110953 steps/s, speed: 8.887621 samples/s, speed: 4550.462091 tokens/s, learning rate: 4.810e-06, loss_scalings: 13421.773438, pp_loss: 8.904817
[INFO] 2021-07-12 18:38:24,141 [run_pretraining.py:  512]:	********exe.run_482******* 
[INFO] 2021-07-12 18:38:25,049 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:25,050 [run_pretraining.py:  534]:	loss/total_loss, 9.035080909729004, 483
[INFO] 2021-07-12 18:38:25,050 [run_pretraining.py:  535]:	loss/mlm_loss, 9.035080909729004, 483
[INFO] 2021-07-12 18:38:25,050 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.819999958272092e-06, 483
[INFO] 2021-07-12 18:38:25,050 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 483
[INFO] 2021-07-12 18:38:25,050 [run_pretraining.py:  558]:	worker_index: 3, step: 483, cost: 9.035081, mlm loss: 9.035081, speed: 1.100087 steps/s, speed: 8.800696 samples/s, speed: 4505.956454 tokens/s, learning rate: 4.820e-06, loss_scalings: 13421.773438, pp_loss: 8.888165
[INFO] 2021-07-12 18:38:25,050 [run_pretraining.py:  512]:	********exe.run_483******* 
[INFO] 2021-07-12 18:38:25,953 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:25,954 [run_pretraining.py:  534]:	loss/total_loss, 8.706146240234375, 484
[INFO] 2021-07-12 18:38:25,954 [run_pretraining.py:  535]:	loss/mlm_loss, 8.706146240234375, 484
[INFO] 2021-07-12 18:38:25,954 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.829999852518085e-06, 484
[INFO] 2021-07-12 18:38:25,954 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 484
[INFO] 2021-07-12 18:38:25,954 [run_pretraining.py:  558]:	worker_index: 3, step: 484, cost: 8.706146, mlm loss: 8.706146, speed: 1.107128 steps/s, speed: 8.857027 samples/s, speed: 4534.798025 tokens/s, learning rate: 4.830e-06, loss_scalings: 13421.773438, pp_loss: 9.011595
[INFO] 2021-07-12 18:38:25,954 [run_pretraining.py:  512]:	********exe.run_484******* 
[INFO] 2021-07-12 18:38:51,801 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:51,802 [run_pretraining.py:  534]:	loss/total_loss, 8.69976806640625, 485
[INFO] 2021-07-12 18:38:51,802 [run_pretraining.py:  535]:	loss/mlm_loss, 8.69976806640625, 485
[INFO] 2021-07-12 18:38:51,802 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.839999746764079e-06, 485
[INFO] 2021-07-12 18:38:51,802 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 485
[INFO] 2021-07-12 18:38:51,802 [run_pretraining.py:  558]:	worker_index: 3, step: 485, cost: 8.699768, mlm loss: 8.699768, speed: 0.038688 steps/s, speed: 0.309507 samples/s, speed: 158.467647 tokens/s, learning rate: 4.840e-06, loss_scalings: 13421.773438, pp_loss: 9.050794
[INFO] 2021-07-12 18:38:51,803 [run_pretraining.py:  512]:	********exe.run_485******* 
[INFO] 2021-07-12 18:38:52,698 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:52,698 [run_pretraining.py:  534]:	loss/total_loss, 8.842977523803711, 486
[INFO] 2021-07-12 18:38:52,698 [run_pretraining.py:  535]:	loss/mlm_loss, 8.842977523803711, 486
[INFO] 2021-07-12 18:38:52,698 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.850000095757423e-06, 486
[INFO] 2021-07-12 18:38:52,698 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 486
[INFO] 2021-07-12 18:38:52,698 [run_pretraining.py:  558]:	worker_index: 3, step: 486, cost: 8.842978, mlm loss: 8.842978, speed: 1.116864 steps/s, speed: 8.934911 samples/s, speed: 4574.674321 tokens/s, learning rate: 4.850e-06, loss_scalings: 13421.773438, pp_loss: 8.937279
[INFO] 2021-07-12 18:38:52,699 [run_pretraining.py:  512]:	********exe.run_486******* 
[INFO] 2021-07-12 18:39:19,143 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:19,144 [run_pretraining.py:  534]:	loss/total_loss, 9.045114517211914, 487
[INFO] 2021-07-12 18:39:19,144 [run_pretraining.py:  535]:	loss/mlm_loss, 9.045114517211914, 487
[INFO] 2021-07-12 18:39:19,144 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.859999990003416e-06, 487
[INFO] 2021-07-12 18:39:19,144 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 487
[INFO] 2021-07-12 18:39:19,144 [run_pretraining.py:  558]:	worker_index: 3, step: 487, cost: 9.045115, mlm loss: 9.045115, speed: 0.037814 steps/s, speed: 0.302514 samples/s, speed: 154.887201 tokens/s, learning rate: 4.860e-06, loss_scalings: 13421.773438, pp_loss: 9.112036
[INFO] 2021-07-12 18:39:19,144 [run_pretraining.py:  512]:	********exe.run_487******* 
[INFO] 2021-07-12 18:39:44,495 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:44,495 [run_pretraining.py:  534]:	loss/total_loss, 9.171249389648438, 488
[INFO] 2021-07-12 18:39:44,496 [run_pretraining.py:  535]:	loss/mlm_loss, 9.171249389648438, 488
[INFO] 2021-07-12 18:39:44,496 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.86999988424941e-06, 488
[INFO] 2021-07-12 18:39:44,496 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 488
[INFO] 2021-07-12 18:39:44,496 [run_pretraining.py:  558]:	worker_index: 3, step: 488, cost: 9.171249, mlm loss: 9.171249, speed: 0.039446 steps/s, speed: 0.315571 samples/s, speed: 161.572246 tokens/s, learning rate: 4.870e-06, loss_scalings: 13421.773438, pp_loss: 8.551837
[INFO] 2021-07-12 18:39:44,496 [run_pretraining.py:  512]:	********exe.run_488******* 
[INFO] 2021-07-12 18:39:45,406 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:45,406 [run_pretraining.py:  534]:	loss/total_loss, 9.482914924621582, 489
[INFO] 2021-07-12 18:39:45,406 [run_pretraining.py:  535]:	loss/mlm_loss, 9.482914924621582, 489
[INFO] 2021-07-12 18:39:45,406 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.879999778495403e-06, 489
[INFO] 2021-07-12 18:39:45,406 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 489
[INFO] 2021-07-12 18:39:45,406 [run_pretraining.py:  558]:	worker_index: 3, step: 489, cost: 9.482915, mlm loss: 9.482915, speed: 1.098832 steps/s, speed: 8.790658 samples/s, speed: 4500.816646 tokens/s, learning rate: 4.880e-06, loss_scalings: 13421.773438, pp_loss: 9.308496
[INFO] 2021-07-12 18:39:45,407 [run_pretraining.py:  512]:	********exe.run_489******* 
[INFO] 2021-07-12 18:39:46,314 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:46,314 [run_pretraining.py:  534]:	loss/total_loss, 8.977129936218262, 490
[INFO] 2021-07-12 18:39:46,315 [run_pretraining.py:  535]:	loss/mlm_loss, 8.977129936218262, 490
[INFO] 2021-07-12 18:39:46,315 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.890000127488747e-06, 490
[INFO] 2021-07-12 18:39:46,315 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 490
[INFO] 2021-07-12 18:39:46,315 [run_pretraining.py:  558]:	worker_index: 3, step: 490, cost: 8.977130, mlm loss: 8.977130, speed: 1.101694 steps/s, speed: 8.813556 samples/s, speed: 4512.540568 tokens/s, learning rate: 4.890e-06, loss_scalings: 13421.773438, pp_loss: 9.045305
[INFO] 2021-07-12 18:39:46,315 [run_pretraining.py:  512]:	********exe.run_490******* 
[INFO] 2021-07-12 18:39:47,223 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:47,223 [run_pretraining.py:  534]:	loss/total_loss, 9.228371620178223, 491
[INFO] 2021-07-12 18:39:47,223 [run_pretraining.py:  535]:	loss/mlm_loss, 9.228371620178223, 491
[INFO] 2021-07-12 18:39:47,223 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.89999956698739e-06, 491
[INFO] 2021-07-12 18:39:47,224 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 491
[INFO] 2021-07-12 18:39:47,224 [run_pretraining.py:  558]:	worker_index: 3, step: 491, cost: 9.228372, mlm loss: 9.228372, speed: 1.101141 steps/s, speed: 8.809129 samples/s, speed: 4510.274258 tokens/s, learning rate: 4.900e-06, loss_scalings: 13421.773438, pp_loss: 8.973929
[INFO] 2021-07-12 18:39:47,224 [run_pretraining.py:  512]:	********exe.run_491******* 
[INFO] 2021-07-12 18:39:48,133 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:48,133 [run_pretraining.py:  534]:	loss/total_loss, 9.339963912963867, 492
[INFO] 2021-07-12 18:39:48,133 [run_pretraining.py:  535]:	loss/mlm_loss, 9.339963912963867, 492
[INFO] 2021-07-12 18:39:48,133 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.909999915980734e-06, 492
[INFO] 2021-07-12 18:39:48,133 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 492
[INFO] 2021-07-12 18:39:48,133 [run_pretraining.py:  558]:	worker_index: 3, step: 492, cost: 9.339964, mlm loss: 9.339964, speed: 1.099947 steps/s, speed: 8.799577 samples/s, speed: 4505.383340 tokens/s, learning rate: 4.910e-06, loss_scalings: 13421.773438, pp_loss: 9.181166
[INFO] 2021-07-12 18:39:48,133 [run_pretraining.py:  512]:	********exe.run_492******* 
[INFO] 2021-07-12 18:39:49,034 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:49,035 [run_pretraining.py:  534]:	loss/total_loss, 8.547354698181152, 493
[INFO] 2021-07-12 18:39:49,035 [run_pretraining.py:  535]:	loss/mlm_loss, 8.547354698181152, 493
[INFO] 2021-07-12 18:39:49,035 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.919999810226727e-06, 493
[INFO] 2021-07-12 18:39:49,035 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 493
[INFO] 2021-07-12 18:39:49,035 [run_pretraining.py:  558]:	worker_index: 3, step: 493, cost: 8.547355, mlm loss: 8.547355, speed: 1.109465 steps/s, speed: 8.875719 samples/s, speed: 4544.367886 tokens/s, learning rate: 4.920e-06, loss_scalings: 13421.773438, pp_loss: 8.992892
[INFO] 2021-07-12 18:39:49,035 [run_pretraining.py:  512]:	********exe.run_493******* 
[INFO] 2021-07-12 18:39:49,938 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:49,939 [run_pretraining.py:  534]:	loss/total_loss, 8.309792518615723, 494
[INFO] 2021-07-12 18:39:49,939 [run_pretraining.py:  535]:	loss/mlm_loss, 8.309792518615723, 494
[INFO] 2021-07-12 18:39:49,939 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.929999704472721e-06, 494
[INFO] 2021-07-12 18:39:49,939 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 494
[INFO] 2021-07-12 18:39:49,939 [run_pretraining.py:  558]:	worker_index: 3, step: 494, cost: 8.309793, mlm loss: 8.309793, speed: 1.107410 steps/s, speed: 8.859282 samples/s, speed: 4535.952232 tokens/s, learning rate: 4.930e-06, loss_scalings: 13421.773438, pp_loss: 8.921140
[INFO] 2021-07-12 18:39:49,939 [run_pretraining.py:  512]:	********exe.run_494******* 
[INFO] 2021-07-12 18:39:50,842 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:50,843 [run_pretraining.py:  534]:	loss/total_loss, 9.007942199707031, 495
[INFO] 2021-07-12 18:39:50,843 [run_pretraining.py:  535]:	loss/mlm_loss, 9.007942199707031, 495
[INFO] 2021-07-12 18:39:50,843 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.940000053466065e-06, 495
[INFO] 2021-07-12 18:39:50,843 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 495
[INFO] 2021-07-12 18:39:50,843 [run_pretraining.py:  558]:	worker_index: 3, step: 495, cost: 9.007942, mlm loss: 9.007942, speed: 1.107089 steps/s, speed: 8.856712 samples/s, speed: 4534.636436 tokens/s, learning rate: 4.940e-06, loss_scalings: 13421.773438, pp_loss: 8.989538
[INFO] 2021-07-12 18:39:50,843 [run_pretraining.py:  512]:	********exe.run_495******* 
[INFO] 2021-07-12 18:39:51,748 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:51,748 [run_pretraining.py:  534]:	loss/total_loss, 8.928266525268555, 496
[INFO] 2021-07-12 18:39:51,748 [run_pretraining.py:  535]:	loss/mlm_loss, 8.928266525268555, 496
[INFO] 2021-07-12 18:39:51,748 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.949999947712058e-06, 496
[INFO] 2021-07-12 18:39:51,748 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 496
[INFO] 2021-07-12 18:39:51,749 [run_pretraining.py:  558]:	worker_index: 3, step: 496, cost: 8.928267, mlm loss: 8.928267, speed: 1.104999 steps/s, speed: 8.839991 samples/s, speed: 4526.075500 tokens/s, learning rate: 4.950e-06, loss_scalings: 13421.773438, pp_loss: 9.002213
[INFO] 2021-07-12 18:39:51,749 [run_pretraining.py:  512]:	********exe.run_496******* 
[INFO] 2021-07-12 18:39:52,662 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:52,662 [run_pretraining.py:  534]:	loss/total_loss, 8.858447074890137, 497
[INFO] 2021-07-12 18:39:52,662 [run_pretraining.py:  535]:	loss/mlm_loss, 8.858447074890137, 497
[INFO] 2021-07-12 18:39:52,663 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.9599998419580515e-06, 497
[INFO] 2021-07-12 18:39:52,663 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 497
[INFO] 2021-07-12 18:39:52,663 [run_pretraining.py:  558]:	worker_index: 3, step: 497, cost: 8.858447, mlm loss: 8.858447, speed: 1.094689 steps/s, speed: 8.757512 samples/s, speed: 4483.845943 tokens/s, learning rate: 4.960e-06, loss_scalings: 13421.773438, pp_loss: 8.839341
[INFO] 2021-07-12 18:39:52,663 [run_pretraining.py:  512]:	********exe.run_497******* 
[INFO] 2021-07-12 18:39:53,573 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:53,574 [run_pretraining.py:  534]:	loss/total_loss, 9.11506462097168, 498
[INFO] 2021-07-12 18:39:53,574 [run_pretraining.py:  535]:	loss/mlm_loss, 9.11506462097168, 498
[INFO] 2021-07-12 18:39:53,574 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.969999736204045e-06, 498
[INFO] 2021-07-12 18:39:53,574 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 498
[INFO] 2021-07-12 18:39:53,574 [run_pretraining.py:  558]:	worker_index: 3, step: 498, cost: 9.115065, mlm loss: 9.115065, speed: 1.097797 steps/s, speed: 8.782375 samples/s, speed: 4496.575767 tokens/s, learning rate: 4.970e-06, loss_scalings: 13421.773438, pp_loss: 8.960644
[INFO] 2021-07-12 18:39:53,574 [run_pretraining.py:  512]:	********exe.run_498******* 
[INFO] 2021-07-12 18:39:54,485 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:54,486 [run_pretraining.py:  534]:	loss/total_loss, 8.753934860229492, 499
[INFO] 2021-07-12 18:39:54,486 [run_pretraining.py:  535]:	loss/mlm_loss, 8.753934860229492, 499
[INFO] 2021-07-12 18:39:54,486 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.980000085197389e-06, 499
[INFO] 2021-07-12 18:39:54,486 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 499
[INFO] 2021-07-12 18:39:54,486 [run_pretraining.py:  558]:	worker_index: 3, step: 499, cost: 8.753935, mlm loss: 8.753935, speed: 1.097507 steps/s, speed: 8.780058 samples/s, speed: 4495.389753 tokens/s, learning rate: 4.980e-06, loss_scalings: 13421.773438, pp_loss: 8.930556
[INFO] 2021-07-12 18:39:54,486 [run_pretraining.py:  512]:	********exe.run_499******* 
[INFO] 2021-07-12 18:39:55,393 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:55,394 [run_pretraining.py:  534]:	loss/total_loss, 9.297547340393066, 500
[INFO] 2021-07-12 18:39:55,394 [run_pretraining.py:  535]:	loss/mlm_loss, 9.297547340393066, 500
[INFO] 2021-07-12 18:39:55,394 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.9899999794433825e-06, 500
[INFO] 2021-07-12 18:39:55,394 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 500
[INFO] 2021-07-12 18:39:55,394 [run_pretraining.py:  558]:	worker_index: 3, step: 500, cost: 9.297547, mlm loss: 9.297547, speed: 1.101882 steps/s, speed: 8.815058 samples/s, speed: 4513.309948 tokens/s, learning rate: 4.990e-06, loss_scalings: 13421.773438, pp_loss: 9.092836
[INFO] 2021-07-12 18:39:55,394 [run_pretraining.py:  512]:	********exe.run_500******* 
[INFO] 2021-07-12 18:39:56,298 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:56,298 [run_pretraining.py:  534]:	loss/total_loss, 8.762411117553711, 501
[INFO] 2021-07-12 18:39:56,299 [run_pretraining.py:  535]:	loss/mlm_loss, 8.762411117553711, 501
[INFO] 2021-07-12 18:39:56,299 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.999999873689376e-06, 501
[INFO] 2021-07-12 18:39:56,299 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 501
[INFO] 2021-07-12 18:39:56,299 [run_pretraining.py:  558]:	worker_index: 3, step: 501, cost: 8.762411, mlm loss: 8.762411, speed: 1.106339 steps/s, speed: 8.850715 samples/s, speed: 4531.566022 tokens/s, learning rate: 5.000e-06, loss_scalings: 13421.773438, pp_loss: 8.969448
[INFO] 2021-07-12 18:39:56,299 [run_pretraining.py:  512]:	********exe.run_501******* 
[INFO] 2021-07-12 18:39:57,209 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:57,210 [run_pretraining.py:  534]:	loss/total_loss, 9.328725814819336, 502
[INFO] 2021-07-12 18:39:57,210 [run_pretraining.py:  535]:	loss/mlm_loss, 9.328725814819336, 502
[INFO] 2021-07-12 18:39:57,210 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.009999767935369e-06, 502
[INFO] 2021-07-12 18:39:57,210 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 502
[INFO] 2021-07-12 18:39:57,210 [run_pretraining.py:  558]:	worker_index: 3, step: 502, cost: 9.328726, mlm loss: 9.328726, speed: 1.097993 steps/s, speed: 8.783943 samples/s, speed: 4497.378564 tokens/s, learning rate: 5.010e-06, loss_scalings: 13421.773438, pp_loss: 9.017029
[INFO] 2021-07-12 18:39:57,210 [run_pretraining.py:  512]:	********exe.run_502******* 
[INFO] 2021-07-12 18:39:58,117 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:58,118 [run_pretraining.py:  534]:	loss/total_loss, 9.397683143615723, 503
[INFO] 2021-07-12 18:39:58,118 [run_pretraining.py:  535]:	loss/mlm_loss, 9.397683143615723, 503
[INFO] 2021-07-12 18:39:58,118 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.020000116928713e-06, 503
[INFO] 2021-07-12 18:39:58,118 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 503
[INFO] 2021-07-12 18:39:58,118 [run_pretraining.py:  558]:	worker_index: 3, step: 503, cost: 9.397683, mlm loss: 9.397683, speed: 1.102375 steps/s, speed: 8.819002 samples/s, speed: 4515.328892 tokens/s, learning rate: 5.020e-06, loss_scalings: 13421.773438, pp_loss: 9.157175
[INFO] 2021-07-12 18:39:58,118 [run_pretraining.py:  512]:	********exe.run_503******* 
[INFO] 2021-07-12 18:39:59,028 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:59,028 [run_pretraining.py:  534]:	loss/total_loss, 9.203435897827148, 504
[INFO] 2021-07-12 18:39:59,029 [run_pretraining.py:  535]:	loss/mlm_loss, 9.203435897827148, 504
[INFO] 2021-07-12 18:39:59,029 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.029999556427356e-06, 504
[INFO] 2021-07-12 18:39:59,029 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 504
[INFO] 2021-07-12 18:39:59,029 [run_pretraining.py:  558]:	worker_index: 3, step: 504, cost: 9.203436, mlm loss: 9.203436, speed: 1.098571 steps/s, speed: 8.788569 samples/s, speed: 4499.747427 tokens/s, learning rate: 5.030e-06, loss_scalings: 13421.773438, pp_loss: 9.162500
[INFO] 2021-07-12 18:39:59,029 [run_pretraining.py:  512]:	********exe.run_504******* 
[INFO] 2021-07-12 18:39:59,934 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:59,934 [run_pretraining.py:  534]:	loss/total_loss, 8.919478416442871, 505
[INFO] 2021-07-12 18:39:59,934 [run_pretraining.py:  535]:	loss/mlm_loss, 8.919478416442871, 505
[INFO] 2021-07-12 18:39:59,934 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.0399999054207e-06, 505
[INFO] 2021-07-12 18:39:59,935 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 505
[INFO] 2021-07-12 18:39:59,935 [run_pretraining.py:  558]:	worker_index: 3, step: 505, cost: 8.919478, mlm loss: 8.919478, speed: 1.104725 steps/s, speed: 8.837800 samples/s, speed: 4524.953725 tokens/s, learning rate: 5.040e-06, loss_scalings: 13421.773438, pp_loss: 9.052116
[INFO] 2021-07-12 18:39:59,935 [run_pretraining.py:  512]:	********exe.run_505******* 
[INFO] 2021-07-12 18:40:00,846 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:00,847 [run_pretraining.py:  534]:	loss/total_loss, 9.253410339355469, 506
[INFO] 2021-07-12 18:40:00,847 [run_pretraining.py:  535]:	loss/mlm_loss, 9.253410339355469, 506
[INFO] 2021-07-12 18:40:00,847 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.050000254414044e-06, 506
[INFO] 2021-07-12 18:40:00,847 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 506
[INFO] 2021-07-12 18:40:00,847 [run_pretraining.py:  558]:	worker_index: 3, step: 506, cost: 9.253410, mlm loss: 9.253410, speed: 1.096942 steps/s, speed: 8.775532 samples/s, speed: 4493.072478 tokens/s, learning rate: 5.050e-06, loss_scalings: 13421.773438, pp_loss: 8.464735
[INFO] 2021-07-12 18:40:00,847 [run_pretraining.py:  512]:	********exe.run_506******* 
[INFO] 2021-07-12 18:40:01,759 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:01,760 [run_pretraining.py:  534]:	loss/total_loss, 9.170100212097168, 507
[INFO] 2021-07-12 18:40:01,760 [run_pretraining.py:  535]:	loss/mlm_loss, 9.170100212097168, 507
[INFO] 2021-07-12 18:40:01,760 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.059999693912687e-06, 507
[INFO] 2021-07-12 18:40:01,760 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 507
[INFO] 2021-07-12 18:40:01,760 [run_pretraining.py:  558]:	worker_index: 3, step: 507, cost: 9.170100, mlm loss: 9.170100, speed: 1.095900 steps/s, speed: 8.767202 samples/s, speed: 4488.807469 tokens/s, learning rate: 5.060e-06, loss_scalings: 13421.773438, pp_loss: 9.269470
[INFO] 2021-07-12 18:40:01,760 [run_pretraining.py:  512]:	********exe.run_507******* 
[INFO] 2021-07-12 18:40:02,668 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:02,669 [run_pretraining.py:  534]:	loss/total_loss, 8.928937911987305, 508
[INFO] 2021-07-12 18:40:02,669 [run_pretraining.py:  535]:	loss/mlm_loss, 8.928937911987305, 508
[INFO] 2021-07-12 18:40:02,669 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.070000042906031e-06, 508
[INFO] 2021-07-12 18:40:02,669 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 508
[INFO] 2021-07-12 18:40:02,669 [run_pretraining.py:  558]:	worker_index: 3, step: 508, cost: 8.928938, mlm loss: 8.928938, speed: 1.100886 steps/s, speed: 8.807085 samples/s, speed: 4509.227762 tokens/s, learning rate: 5.070e-06, loss_scalings: 13421.773438, pp_loss: 8.847706
[INFO] 2021-07-12 18:40:02,669 [run_pretraining.py:  512]:	********exe.run_508******* 
[INFO] 2021-07-12 18:40:03,579 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:03,579 [run_pretraining.py:  534]:	loss/total_loss, 8.794286727905273, 509
[INFO] 2021-07-12 18:40:03,579 [run_pretraining.py:  535]:	loss/mlm_loss, 8.794286727905273, 509
[INFO] 2021-07-12 18:40:03,579 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.079999937152024e-06, 509
[INFO] 2021-07-12 18:40:03,579 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 509
[INFO] 2021-07-12 18:40:03,579 [run_pretraining.py:  558]:	worker_index: 3, step: 509, cost: 8.794287, mlm loss: 8.794287, speed: 1.099254 steps/s, speed: 8.794033 samples/s, speed: 4502.544739 tokens/s, learning rate: 5.080e-06, loss_scalings: 13421.773438, pp_loss: 9.020055
[INFO] 2021-07-12 18:40:03,579 [run_pretraining.py:  512]:	********exe.run_509******* 
[INFO] 2021-07-12 18:40:04,486 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:04,487 [run_pretraining.py:  534]:	loss/total_loss, 8.708765983581543, 510
[INFO] 2021-07-12 18:40:04,487 [run_pretraining.py:  535]:	loss/mlm_loss, 8.708765983581543, 510
[INFO] 2021-07-12 18:40:04,487 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.089999831398018e-06, 510
[INFO] 2021-07-12 18:40:04,487 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 510
[INFO] 2021-07-12 18:40:04,487 [run_pretraining.py:  558]:	worker_index: 3, step: 510, cost: 8.708766, mlm loss: 8.708766, speed: 1.102220 steps/s, speed: 8.817762 samples/s, speed: 4514.694070 tokens/s, learning rate: 5.090e-06, loss_scalings: 13421.773438, pp_loss: 8.983034
[INFO] 2021-07-12 18:40:04,487 [run_pretraining.py:  512]:	********exe.run_510******* 
[INFO] 2021-07-12 18:40:05,441 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:05,441 [run_pretraining.py:  534]:	loss/total_loss, 8.688377380371094, 511
[INFO] 2021-07-12 18:40:05,441 [run_pretraining.py:  535]:	loss/mlm_loss, 8.688377380371094, 511
[INFO] 2021-07-12 18:40:05,442 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.099999725644011e-06, 511
[INFO] 2021-07-12 18:40:05,442 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 511
[INFO] 2021-07-12 18:40:05,442 [run_pretraining.py:  558]:	worker_index: 3, step: 511, cost: 8.688377, mlm loss: 8.688377, speed: 1.048507 steps/s, speed: 8.388056 samples/s, speed: 4294.684920 tokens/s, learning rate: 5.100e-06, loss_scalings: 13421.773438, pp_loss: 8.720377
[INFO] 2021-07-12 18:40:05,442 [run_pretraining.py:  512]:	********exe.run_511******* 
[INFO] 2021-07-12 18:40:06,347 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:06,348 [run_pretraining.py:  534]:	loss/total_loss, 8.813041687011719, 512
[INFO] 2021-07-12 18:40:06,348 [run_pretraining.py:  535]:	loss/mlm_loss, 8.813041687011719, 512
[INFO] 2021-07-12 18:40:06,348 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.110000074637355e-06, 512
[INFO] 2021-07-12 18:40:06,348 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 512
[INFO] 2021-07-12 18:40:06,348 [run_pretraining.py:  558]:	worker_index: 3, step: 512, cost: 8.813042, mlm loss: 8.813042, speed: 1.103767 steps/s, speed: 8.830135 samples/s, speed: 4521.028914 tokens/s, learning rate: 5.110e-06, loss_scalings: 13421.773438, pp_loss: 9.080194
[INFO] 2021-07-12 18:40:06,348 [run_pretraining.py:  512]:	********exe.run_512******* 
[INFO] 2021-07-12 18:40:07,258 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:07,259 [run_pretraining.py:  534]:	loss/total_loss, 8.199909210205078, 513
[INFO] 2021-07-12 18:40:07,259 [run_pretraining.py:  535]:	loss/mlm_loss, 8.199909210205078, 513
[INFO] 2021-07-12 18:40:07,259 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.119999514135998e-06, 513
[INFO] 2021-07-12 18:40:07,259 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 513
[INFO] 2021-07-12 18:40:07,259 [run_pretraining.py:  558]:	worker_index: 3, step: 513, cost: 8.199909, mlm loss: 8.199909, speed: 1.098915 steps/s, speed: 8.791321 samples/s, speed: 4501.156262 tokens/s, learning rate: 5.120e-06, loss_scalings: 13421.773438, pp_loss: 8.748276
[INFO] 2021-07-12 18:40:07,259 [run_pretraining.py:  512]:	********exe.run_513******* 
[INFO] 2021-07-12 18:40:08,162 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:08,163 [run_pretraining.py:  534]:	loss/total_loss, 8.917004585266113, 514
[INFO] 2021-07-12 18:40:08,163 [run_pretraining.py:  535]:	loss/mlm_loss, 8.917004585266113, 514
[INFO] 2021-07-12 18:40:08,163 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.129999863129342e-06, 514
[INFO] 2021-07-12 18:40:08,163 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 514
[INFO] 2021-07-12 18:40:08,163 [run_pretraining.py:  558]:	worker_index: 3, step: 514, cost: 8.917005, mlm loss: 8.917005, speed: 1.106751 steps/s, speed: 8.854006 samples/s, speed: 4533.250826 tokens/s, learning rate: 5.130e-06, loss_scalings: 13421.773438, pp_loss: 8.971178
[INFO] 2021-07-12 18:40:08,163 [run_pretraining.py:  512]:	********exe.run_514******* 
[INFO] 2021-07-12 18:40:09,077 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:09,078 [run_pretraining.py:  534]:	loss/total_loss, 8.818920135498047, 515
[INFO] 2021-07-12 18:40:09,078 [run_pretraining.py:  535]:	loss/mlm_loss, 8.818920135498047, 515
[INFO] 2021-07-12 18:40:09,078 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.139999757375335e-06, 515
[INFO] 2021-07-12 18:40:09,078 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 515
[INFO] 2021-07-12 18:40:09,078 [run_pretraining.py:  558]:	worker_index: 3, step: 515, cost: 8.818920, mlm loss: 8.818920, speed: 1.093713 steps/s, speed: 8.749704 samples/s, speed: 4479.848400 tokens/s, learning rate: 5.140e-06, loss_scalings: 13421.773438, pp_loss: 8.981589
[INFO] 2021-07-12 18:40:09,078 [run_pretraining.py:  512]:	********exe.run_515******* 
[INFO] 2021-07-12 18:40:09,982 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:09,982 [run_pretraining.py:  534]:	loss/total_loss, 8.706918716430664, 516
[INFO] 2021-07-12 18:40:09,982 [run_pretraining.py:  535]:	loss/mlm_loss, 8.706918716430664, 516
[INFO] 2021-07-12 18:40:09,982 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.149999651621329e-06, 516
[INFO] 2021-07-12 18:40:09,982 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 516
[INFO] 2021-07-12 18:40:09,983 [run_pretraining.py:  558]:	worker_index: 3, step: 516, cost: 8.706919, mlm loss: 8.706919, speed: 1.106360 steps/s, speed: 8.850883 samples/s, speed: 4531.652086 tokens/s, learning rate: 5.150e-06, loss_scalings: 13421.773438, pp_loss: 8.221448
[INFO] 2021-07-12 18:40:09,983 [run_pretraining.py:  512]:	********exe.run_516******* 
[INFO] 2021-07-12 18:40:10,882 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:10,883 [run_pretraining.py:  534]:	loss/total_loss, 9.218019485473633, 517
[INFO] 2021-07-12 18:40:10,883 [run_pretraining.py:  535]:	loss/mlm_loss, 9.218019485473633, 517
[INFO] 2021-07-12 18:40:10,883 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.160000000614673e-06, 517
[INFO] 2021-07-12 18:40:10,883 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 517
[INFO] 2021-07-12 18:40:10,883 [run_pretraining.py:  558]:	worker_index: 3, step: 517, cost: 9.218019, mlm loss: 9.218019, speed: 1.111483 steps/s, speed: 8.891865 samples/s, speed: 4552.635059 tokens/s, learning rate: 5.160e-06, loss_scalings: 13421.773438, pp_loss: 9.246829
[INFO] 2021-07-12 18:40:10,883 [run_pretraining.py:  512]:	********exe.run_517******* 
[INFO] 2021-07-12 18:40:11,782 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:11,783 [run_pretraining.py:  534]:	loss/total_loss, 8.907100677490234, 518
[INFO] 2021-07-12 18:40:11,783 [run_pretraining.py:  535]:	loss/mlm_loss, 8.907100677490234, 518
[INFO] 2021-07-12 18:40:11,783 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.169999894860666e-06, 518
[INFO] 2021-07-12 18:40:11,783 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 518
[INFO] 2021-07-12 18:40:11,783 [run_pretraining.py:  558]:	worker_index: 3, step: 518, cost: 8.907101, mlm loss: 8.907101, speed: 1.111558 steps/s, speed: 8.892462 samples/s, speed: 4552.940309 tokens/s, learning rate: 5.170e-06, loss_scalings: 13421.773438, pp_loss: 8.981716
[INFO] 2021-07-12 18:40:11,783 [run_pretraining.py:  512]:	********exe.run_518******* 
[INFO] 2021-07-12 18:40:12,689 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:12,689 [run_pretraining.py:  534]:	loss/total_loss, 9.0354642868042, 519
[INFO] 2021-07-12 18:40:12,690 [run_pretraining.py:  535]:	loss/mlm_loss, 9.0354642868042, 519
[INFO] 2021-07-12 18:40:12,690 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.17999978910666e-06, 519
[INFO] 2021-07-12 18:40:12,690 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 519
[INFO] 2021-07-12 18:40:12,690 [run_pretraining.py:  558]:	worker_index: 3, step: 519, cost: 9.035464, mlm loss: 9.035464, speed: 1.103851 steps/s, speed: 8.830809 samples/s, speed: 4521.373967 tokens/s, learning rate: 5.180e-06, loss_scalings: 13421.773438, pp_loss: 8.850682
[INFO] 2021-07-12 18:40:12,690 [run_pretraining.py:  512]:	********exe.run_519******* 
[INFO] 2021-07-12 18:40:13,591 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:13,592 [run_pretraining.py:  534]:	loss/total_loss, 9.166189193725586, 520
[INFO] 2021-07-12 18:40:13,592 [run_pretraining.py:  535]:	loss/mlm_loss, 9.166189193725586, 520
[INFO] 2021-07-12 18:40:13,592 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.189999683352653e-06, 520
[INFO] 2021-07-12 18:40:13,592 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 520
[INFO] 2021-07-12 18:40:13,592 [run_pretraining.py:  558]:	worker_index: 3, step: 520, cost: 9.166189, mlm loss: 9.166189, speed: 1.109035 steps/s, speed: 8.872280 samples/s, speed: 4542.607546 tokens/s, learning rate: 5.190e-06, loss_scalings: 13421.773438, pp_loss: 8.866184
[INFO] 2021-07-12 18:40:13,592 [run_pretraining.py:  512]:	********exe.run_520******* 
[INFO] 2021-07-12 18:40:14,505 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:14,506 [run_pretraining.py:  534]:	loss/total_loss, 8.94035530090332, 521
[INFO] 2021-07-12 18:40:14,506 [run_pretraining.py:  535]:	loss/mlm_loss, 8.94035530090332, 521
[INFO] 2021-07-12 18:40:14,506 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.200000032345997e-06, 521
[INFO] 2021-07-12 18:40:14,506 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 521
[INFO] 2021-07-12 18:40:14,506 [run_pretraining.py:  558]:	worker_index: 3, step: 521, cost: 8.940355, mlm loss: 8.940355, speed: 1.095033 steps/s, speed: 8.760264 samples/s, speed: 4485.255377 tokens/s, learning rate: 5.200e-06, loss_scalings: 13421.773438, pp_loss: 9.058690
[INFO] 2021-07-12 18:40:14,506 [run_pretraining.py:  512]:	********exe.run_521******* 
[INFO] 2021-07-12 18:40:15,445 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:15,446 [run_pretraining.py:  534]:	loss/total_loss, 9.005051612854004, 522
[INFO] 2021-07-12 18:40:15,446 [run_pretraining.py:  535]:	loss/mlm_loss, 9.005051612854004, 522
[INFO] 2021-07-12 18:40:15,446 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.2099999265919905e-06, 522
[INFO] 2021-07-12 18:40:15,446 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 522
[INFO] 2021-07-12 18:40:15,446 [run_pretraining.py:  558]:	worker_index: 3, step: 522, cost: 9.005052, mlm loss: 9.005052, speed: 1.064408 steps/s, speed: 8.515266 samples/s, speed: 4359.816294 tokens/s, learning rate: 5.210e-06, loss_scalings: 13421.773438, pp_loss: 8.945153
[INFO] 2021-07-12 18:40:15,446 [run_pretraining.py:  512]:	********exe.run_522******* 
[INFO] 2021-07-12 18:40:16,354 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:16,354 [run_pretraining.py:  534]:	loss/total_loss, 9.175365447998047, 523
[INFO] 2021-07-12 18:40:16,354 [run_pretraining.py:  535]:	loss/mlm_loss, 9.175365447998047, 523
[INFO] 2021-07-12 18:40:16,354 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.219999820837984e-06, 523
[INFO] 2021-07-12 18:40:16,354 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 523
[INFO] 2021-07-12 18:40:16,355 [run_pretraining.py:  558]:	worker_index: 3, step: 523, cost: 9.175365, mlm loss: 9.175365, speed: 1.101501 steps/s, speed: 8.812010 samples/s, speed: 4511.748937 tokens/s, learning rate: 5.220e-06, loss_scalings: 13421.773438, pp_loss: 9.010378
[INFO] 2021-07-12 18:40:16,355 [run_pretraining.py:  512]:	********exe.run_523******* 
[INFO] 2021-07-12 18:40:17,258 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:17,259 [run_pretraining.py:  534]:	loss/total_loss, 9.179020881652832, 524
[INFO] 2021-07-12 18:40:17,259 [run_pretraining.py:  535]:	loss/mlm_loss, 9.179020881652832, 524
[INFO] 2021-07-12 18:40:17,259 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.229999715083977e-06, 524
[INFO] 2021-07-12 18:40:17,259 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 524
[INFO] 2021-07-12 18:40:17,259 [run_pretraining.py:  558]:	worker_index: 3, step: 524, cost: 9.179021, mlm loss: 9.179021, speed: 1.106163 steps/s, speed: 8.849303 samples/s, speed: 4530.842982 tokens/s, learning rate: 5.230e-06, loss_scalings: 13421.773438, pp_loss: 8.986741
[INFO] 2021-07-12 18:40:17,259 [run_pretraining.py:  512]:	********exe.run_524******* 
[INFO] 2021-07-12 18:40:18,167 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:18,168 [run_pretraining.py:  534]:	loss/total_loss, 8.63808536529541, 525
[INFO] 2021-07-12 18:40:18,168 [run_pretraining.py:  535]:	loss/mlm_loss, 8.63808536529541, 525
[INFO] 2021-07-12 18:40:18,168 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.2400000640773214e-06, 525
[INFO] 2021-07-12 18:40:18,168 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 525
[INFO] 2021-07-12 18:40:18,168 [run_pretraining.py:  558]:	worker_index: 3, step: 525, cost: 8.638085, mlm loss: 8.638085, speed: 1.100859 steps/s, speed: 8.806870 samples/s, speed: 4509.117695 tokens/s, learning rate: 5.240e-06, loss_scalings: 13421.773438, pp_loss: 8.824309
[INFO] 2021-07-12 18:40:18,168 [run_pretraining.py:  512]:	********exe.run_525******* 
[INFO] 2021-07-12 18:40:19,070 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:19,071 [run_pretraining.py:  534]:	loss/total_loss, 8.9780855178833, 526
[INFO] 2021-07-12 18:40:19,071 [run_pretraining.py:  535]:	loss/mlm_loss, 8.9780855178833, 526
[INFO] 2021-07-12 18:40:19,071 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.249999503575964e-06, 526
[INFO] 2021-07-12 18:40:19,071 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 526
[INFO] 2021-07-12 18:40:19,071 [run_pretraining.py:  558]:	worker_index: 3, step: 526, cost: 8.978086, mlm loss: 8.978086, speed: 1.108427 steps/s, speed: 8.867415 samples/s, speed: 4540.116565 tokens/s, learning rate: 5.250e-06, loss_scalings: 13421.773438, pp_loss: 8.779615
[INFO] 2021-07-12 18:40:19,071 [run_pretraining.py:  512]:	********exe.run_526******* 
[INFO] 2021-07-12 18:40:19,983 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:19,984 [run_pretraining.py:  534]:	loss/total_loss, 8.73841381072998, 527
[INFO] 2021-07-12 18:40:19,984 [run_pretraining.py:  535]:	loss/mlm_loss, 8.73841381072998, 527
[INFO] 2021-07-12 18:40:19,984 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.259999852569308e-06, 527
[INFO] 2021-07-12 18:40:19,984 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 527
[INFO] 2021-07-12 18:40:19,984 [run_pretraining.py:  558]:	worker_index: 3, step: 527, cost: 8.738414, mlm loss: 8.738414, speed: 1.096243 steps/s, speed: 8.769943 samples/s, speed: 4490.210635 tokens/s, learning rate: 5.260e-06, loss_scalings: 13421.773438, pp_loss: 8.880708
[INFO] 2021-07-12 18:40:19,984 [run_pretraining.py:  512]:	********exe.run_527******* 
[INFO] 2021-07-12 18:40:20,889 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:20,890 [run_pretraining.py:  534]:	loss/total_loss, 8.755961418151855, 528
[INFO] 2021-07-12 18:40:20,890 [run_pretraining.py:  535]:	loss/mlm_loss, 8.755961418151855, 528
[INFO] 2021-07-12 18:40:20,890 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.270000201562652e-06, 528
[INFO] 2021-07-12 18:40:20,890 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 528
[INFO] 2021-07-12 18:40:20,890 [run_pretraining.py:  558]:	worker_index: 3, step: 528, cost: 8.755961, mlm loss: 8.755961, speed: 1.104354 steps/s, speed: 8.834831 samples/s, speed: 4523.433482 tokens/s, learning rate: 5.270e-06, loss_scalings: 13421.773438, pp_loss: 8.802975
[INFO] 2021-07-12 18:40:20,890 [run_pretraining.py:  512]:	********exe.run_528******* 
[INFO] 2021-07-12 18:40:21,796 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:21,797 [run_pretraining.py:  534]:	loss/total_loss, 9.17456340789795, 529
[INFO] 2021-07-12 18:40:21,797 [run_pretraining.py:  535]:	loss/mlm_loss, 9.17456340789795, 529
[INFO] 2021-07-12 18:40:21,797 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.279999641061295e-06, 529
[INFO] 2021-07-12 18:40:21,797 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 529
[INFO] 2021-07-12 18:40:21,797 [run_pretraining.py:  558]:	worker_index: 3, step: 529, cost: 9.174563, mlm loss: 9.174563, speed: 1.102986 steps/s, speed: 8.823891 samples/s, speed: 4517.831946 tokens/s, learning rate: 5.280e-06, loss_scalings: 13421.773438, pp_loss: 9.127271
[INFO] 2021-07-12 18:40:21,797 [run_pretraining.py:  512]:	********exe.run_529******* 
[INFO] 2021-07-12 18:40:22,704 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:22,705 [run_pretraining.py:  534]:	loss/total_loss, 8.763681411743164, 530
[INFO] 2021-07-12 18:40:22,705 [run_pretraining.py:  535]:	loss/mlm_loss, 8.763681411743164, 530
[INFO] 2021-07-12 18:40:22,705 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.289999990054639e-06, 530
[INFO] 2021-07-12 18:40:22,705 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 530
[INFO] 2021-07-12 18:40:22,705 [run_pretraining.py:  558]:	worker_index: 3, step: 530, cost: 8.763681, mlm loss: 8.763681, speed: 1.102229 steps/s, speed: 8.817831 samples/s, speed: 4514.729663 tokens/s, learning rate: 5.290e-06, loss_scalings: 13421.773438, pp_loss: 9.010082
[INFO] 2021-07-12 18:40:22,705 [run_pretraining.py:  512]:	********exe.run_530******* 
[INFO] 2021-07-12 18:40:23,611 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:23,612 [run_pretraining.py:  534]:	loss/total_loss, 9.255523681640625, 531
[INFO] 2021-07-12 18:40:23,612 [run_pretraining.py:  535]:	loss/mlm_loss, 9.255523681640625, 531
[INFO] 2021-07-12 18:40:23,612 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.299999884300632e-06, 531
[INFO] 2021-07-12 18:40:23,612 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 531
[INFO] 2021-07-12 18:40:23,612 [run_pretraining.py:  558]:	worker_index: 3, step: 531, cost: 9.255524, mlm loss: 9.255524, speed: 1.103784 steps/s, speed: 8.830272 samples/s, speed: 4521.099110 tokens/s, learning rate: 5.300e-06, loss_scalings: 13421.773438, pp_loss: 9.001661
[INFO] 2021-07-12 18:40:23,612 [run_pretraining.py:  512]:	********exe.run_531******* 
[INFO] 2021-07-12 18:40:24,519 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:24,519 [run_pretraining.py:  534]:	loss/total_loss, 9.164806365966797, 532
[INFO] 2021-07-12 18:40:24,519 [run_pretraining.py:  535]:	loss/mlm_loss, 9.164806365966797, 532
[INFO] 2021-07-12 18:40:24,520 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.309999778546626e-06, 532
[INFO] 2021-07-12 18:40:24,520 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 532
[INFO] 2021-07-12 18:40:24,520 [run_pretraining.py:  558]:	worker_index: 3, step: 532, cost: 9.164806, mlm loss: 9.164806, speed: 1.102290 steps/s, speed: 8.818318 samples/s, speed: 4514.978828 tokens/s, learning rate: 5.310e-06, loss_scalings: 13421.773438, pp_loss: 8.753073
[INFO] 2021-07-12 18:40:24,520 [run_pretraining.py:  512]:	********exe.run_532******* 
[INFO] 2021-07-12 18:40:25,428 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:25,429 [run_pretraining.py:  534]:	loss/total_loss, 9.201114654541016, 533
[INFO] 2021-07-12 18:40:25,429 [run_pretraining.py:  535]:	loss/mlm_loss, 9.201114654541016, 533
[INFO] 2021-07-12 18:40:25,429 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.319999672792619e-06, 533
[INFO] 2021-07-12 18:40:25,429 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 533
[INFO] 2021-07-12 18:40:25,429 [run_pretraining.py:  558]:	worker_index: 3, step: 533, cost: 9.201115, mlm loss: 9.201115, speed: 1.100187 steps/s, speed: 8.801500 samples/s, speed: 4506.367768 tokens/s, learning rate: 5.320e-06, loss_scalings: 13421.773438, pp_loss: 8.553511
[INFO] 2021-07-12 18:40:25,429 [run_pretraining.py:  512]:	********exe.run_533******* 
[INFO] 2021-07-12 18:40:26,349 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:26,350 [run_pretraining.py:  534]:	loss/total_loss, 8.97531509399414, 534
[INFO] 2021-07-12 18:40:26,350 [run_pretraining.py:  535]:	loss/mlm_loss, 8.97531509399414, 534
[INFO] 2021-07-12 18:40:26,350 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.330000021785963e-06, 534
[INFO] 2021-07-12 18:40:26,350 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 534
[INFO] 2021-07-12 18:40:26,350 [run_pretraining.py:  558]:	worker_index: 3, step: 534, cost: 8.975315, mlm loss: 8.975315, speed: 1.086839 steps/s, speed: 8.694714 samples/s, speed: 4451.693622 tokens/s, learning rate: 5.330e-06, loss_scalings: 13421.773438, pp_loss: 8.472900
[INFO] 2021-07-12 18:40:26,350 [run_pretraining.py:  512]:	********exe.run_534******* 
[INFO] 2021-07-12 18:40:27,253 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:27,254 [run_pretraining.py:  534]:	loss/total_loss, 9.0625, 535
[INFO] 2021-07-12 18:40:27,254 [run_pretraining.py:  535]:	loss/mlm_loss, 9.0625, 535
[INFO] 2021-07-12 18:40:27,254 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.339999916031957e-06, 535
[INFO] 2021-07-12 18:40:27,254 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 535
[INFO] 2021-07-12 18:40:27,254 [run_pretraining.py:  558]:	worker_index: 3, step: 535, cost: 9.062500, mlm loss: 9.062500, speed: 1.106582 steps/s, speed: 8.852653 samples/s, speed: 4532.558338 tokens/s, learning rate: 5.340e-06, loss_scalings: 13421.773438, pp_loss: 9.034857
[INFO] 2021-07-12 18:40:27,254 [run_pretraining.py:  512]:	********exe.run_535******* 
[INFO] 2021-07-12 18:40:28,157 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:28,158 [run_pretraining.py:  534]:	loss/total_loss, 8.933377265930176, 536
[INFO] 2021-07-12 18:40:28,158 [run_pretraining.py:  535]:	loss/mlm_loss, 8.933377265930176, 536
[INFO] 2021-07-12 18:40:28,158 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.34999981027795e-06, 536
[INFO] 2021-07-12 18:40:28,158 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 536
[INFO] 2021-07-12 18:40:28,158 [run_pretraining.py:  558]:	worker_index: 3, step: 536, cost: 8.933377, mlm loss: 8.933377, speed: 1.107332 steps/s, speed: 8.858655 samples/s, speed: 4535.631294 tokens/s, learning rate: 5.350e-06, loss_scalings: 13421.773438, pp_loss: 8.953864
[INFO] 2021-07-12 18:40:28,158 [run_pretraining.py:  512]:	********exe.run_536******* 
[INFO] 2021-07-12 18:40:29,061 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:29,062 [run_pretraining.py:  534]:	loss/total_loss, 8.537302017211914, 537
[INFO] 2021-07-12 18:40:29,062 [run_pretraining.py:  535]:	loss/mlm_loss, 8.537302017211914, 537
[INFO] 2021-07-12 18:40:29,062 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.359999704523943e-06, 537
[INFO] 2021-07-12 18:40:29,062 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 537
[INFO] 2021-07-12 18:40:29,062 [run_pretraining.py:  558]:	worker_index: 3, step: 537, cost: 8.537302, mlm loss: 8.537302, speed: 1.106579 steps/s, speed: 8.852632 samples/s, speed: 4532.547576 tokens/s, learning rate: 5.360e-06, loss_scalings: 13421.773438, pp_loss: 8.703238
[INFO] 2021-07-12 18:40:29,062 [run_pretraining.py:  512]:	********exe.run_537******* 
[INFO] 2021-07-12 18:40:30,020 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:30,021 [run_pretraining.py:  534]:	loss/total_loss, 9.2110595703125, 538
[INFO] 2021-07-12 18:40:30,021 [run_pretraining.py:  535]:	loss/mlm_loss, 9.2110595703125, 538
[INFO] 2021-07-12 18:40:30,021 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.370000053517288e-06, 538
[INFO] 2021-07-12 18:40:30,021 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 538
[INFO] 2021-07-12 18:40:30,021 [run_pretraining.py:  558]:	worker_index: 3, step: 538, cost: 9.211060, mlm loss: 9.211060, speed: 1.043589 steps/s, speed: 8.348712 samples/s, speed: 4274.540336 tokens/s, learning rate: 5.370e-06, loss_scalings: 13421.773438, pp_loss: 9.083548
[INFO] 2021-07-12 18:40:30,021 [run_pretraining.py:  512]:	********exe.run_538******* 
[INFO] 2021-07-12 18:40:30,979 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:30,980 [run_pretraining.py:  534]:	loss/total_loss, 8.792814254760742, 539
[INFO] 2021-07-12 18:40:30,980 [run_pretraining.py:  535]:	loss/mlm_loss, 8.792814254760742, 539
[INFO] 2021-07-12 18:40:30,980 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.379999947763281e-06, 539
[INFO] 2021-07-12 18:40:30,980 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 539
[INFO] 2021-07-12 18:40:30,980 [run_pretraining.py:  558]:	worker_index: 3, step: 539, cost: 8.792814, mlm loss: 8.792814, speed: 1.043476 steps/s, speed: 8.347808 samples/s, speed: 4274.077741 tokens/s, learning rate: 5.380e-06, loss_scalings: 13421.773438, pp_loss: 8.948675
[INFO] 2021-07-12 18:40:30,980 [run_pretraining.py:  512]:	********exe.run_539******* 
[INFO] 2021-07-12 18:40:31,884 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:31,884 [run_pretraining.py:  534]:	loss/total_loss, 8.526507377624512, 540
[INFO] 2021-07-12 18:40:31,884 [run_pretraining.py:  535]:	loss/mlm_loss, 8.526507377624512, 540
[INFO] 2021-07-12 18:40:31,884 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.389999842009274e-06, 540
[INFO] 2021-07-12 18:40:31,884 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 540
[INFO] 2021-07-12 18:40:31,884 [run_pretraining.py:  558]:	worker_index: 3, step: 540, cost: 8.526507, mlm loss: 8.526507, speed: 1.106618 steps/s, speed: 8.852947 samples/s, speed: 4532.709017 tokens/s, learning rate: 5.390e-06, loss_scalings: 13421.773438, pp_loss: 8.904589
[INFO] 2021-07-12 18:40:31,885 [run_pretraining.py:  512]:	********exe.run_540******* 
[INFO] 2021-07-12 18:40:32,790 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:32,791 [run_pretraining.py:  534]:	loss/total_loss, 9.558542251586914, 541
[INFO] 2021-07-12 18:40:32,791 [run_pretraining.py:  535]:	loss/mlm_loss, 9.558542251586914, 541
[INFO] 2021-07-12 18:40:32,791 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.4000001910026185e-06, 541
[INFO] 2021-07-12 18:40:32,791 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 541
[INFO] 2021-07-12 18:40:32,791 [run_pretraining.py:  558]:	worker_index: 3, step: 541, cost: 9.558542, mlm loss: 9.558542, speed: 1.104022 steps/s, speed: 8.832180 samples/s, speed: 4522.076134 tokens/s, learning rate: 5.400e-06, loss_scalings: 13421.773438, pp_loss: 8.999208
[INFO] 2021-07-12 18:40:32,791 [run_pretraining.py:  512]:	********exe.run_541******* 
[INFO] 2021-07-12 18:40:33,694 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:33,694 [run_pretraining.py:  534]:	loss/total_loss, 9.357742309570312, 542
[INFO] 2021-07-12 18:40:33,694 [run_pretraining.py:  535]:	loss/mlm_loss, 9.357742309570312, 542
[INFO] 2021-07-12 18:40:33,694 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.409999630501261e-06, 542
[INFO] 2021-07-12 18:40:33,695 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 542
[INFO] 2021-07-12 18:40:33,695 [run_pretraining.py:  558]:	worker_index: 3, step: 542, cost: 9.357742, mlm loss: 9.357742, speed: 1.107327 steps/s, speed: 8.858620 samples/s, speed: 4535.613333 tokens/s, learning rate: 5.410e-06, loss_scalings: 13421.773438, pp_loss: 8.908558
[INFO] 2021-07-12 18:40:33,695 [run_pretraining.py:  512]:	********exe.run_542******* 
[INFO] 2021-07-12 18:40:34,630 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:34,630 [run_pretraining.py:  534]:	loss/total_loss, 8.85660171508789, 543
[INFO] 2021-07-12 18:40:34,631 [run_pretraining.py:  535]:	loss/mlm_loss, 8.85660171508789, 543
[INFO] 2021-07-12 18:40:34,631 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.419999979494605e-06, 543
[INFO] 2021-07-12 18:40:34,631 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 543
[INFO] 2021-07-12 18:40:34,631 [run_pretraining.py:  558]:	worker_index: 3, step: 543, cost: 8.856602, mlm loss: 8.856602, speed: 1.068849 steps/s, speed: 8.550789 samples/s, speed: 4378.003800 tokens/s, learning rate: 5.420e-06, loss_scalings: 13421.773438, pp_loss: 8.748554
[INFO] 2021-07-12 18:40:34,631 [run_pretraining.py:  512]:	********exe.run_543******* 
[INFO] 2021-07-12 18:40:35,586 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:35,587 [run_pretraining.py:  534]:	loss/total_loss, 8.659114837646484, 544
[INFO] 2021-07-12 18:40:35,587 [run_pretraining.py:  535]:	loss/mlm_loss, 8.659114837646484, 544
[INFO] 2021-07-12 18:40:35,587 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.4299998737405986e-06, 544
[INFO] 2021-07-12 18:40:35,587 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 544
[INFO] 2021-07-12 18:40:35,587 [run_pretraining.py:  558]:	worker_index: 3, step: 544, cost: 8.659115, mlm loss: 8.659115, speed: 1.046238 steps/s, speed: 8.369908 samples/s, speed: 4285.392657 tokens/s, learning rate: 5.430e-06, loss_scalings: 13421.773438, pp_loss: 8.750772
[INFO] 2021-07-12 18:40:35,587 [run_pretraining.py:  512]:	********exe.run_544******* 
[INFO] 2021-07-12 18:40:36,658 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:36,659 [run_pretraining.py:  534]:	loss/total_loss, 9.23226547241211, 545
[INFO] 2021-07-12 18:40:36,659 [run_pretraining.py:  535]:	loss/mlm_loss, 9.23226547241211, 545
[INFO] 2021-07-12 18:40:36,659 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.439999767986592e-06, 545
[INFO] 2021-07-12 18:40:36,659 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 545
[INFO] 2021-07-12 18:40:36,659 [run_pretraining.py:  558]:	worker_index: 3, step: 545, cost: 9.232265, mlm loss: 9.232265, speed: 0.933633 steps/s, speed: 7.469060 samples/s, speed: 3824.158848 tokens/s, learning rate: 5.440e-06, loss_scalings: 13421.773438, pp_loss: 9.052904
[INFO] 2021-07-12 18:40:36,659 [run_pretraining.py:  512]:	********exe.run_545******* 
[INFO] 2021-07-12 18:40:37,716 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:37,716 [run_pretraining.py:  534]:	loss/total_loss, 8.799660682678223, 546
[INFO] 2021-07-12 18:40:37,716 [run_pretraining.py:  535]:	loss/mlm_loss, 8.799660682678223, 546
[INFO] 2021-07-12 18:40:37,716 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.449999662232585e-06, 546
[INFO] 2021-07-12 18:40:37,716 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 546
[INFO] 2021-07-12 18:40:37,716 [run_pretraining.py:  558]:	worker_index: 3, step: 546, cost: 8.799661, mlm loss: 8.799661, speed: 0.946250 steps/s, speed: 7.570000 samples/s, speed: 3875.839794 tokens/s, learning rate: 5.450e-06, loss_scalings: 13421.773438, pp_loss: 9.219302
[INFO] 2021-07-12 18:40:37,717 [run_pretraining.py:  512]:	********exe.run_546******* 
[INFO] 2021-07-12 18:40:38,773 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:38,774 [run_pretraining.py:  534]:	loss/total_loss, 8.451139450073242, 547
[INFO] 2021-07-12 18:40:38,774 [run_pretraining.py:  535]:	loss/mlm_loss, 8.451139450073242, 547
[INFO] 2021-07-12 18:40:38,774 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.4600000112259295e-06, 547
[INFO] 2021-07-12 18:40:38,774 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 547
[INFO] 2021-07-12 18:40:38,774 [run_pretraining.py:  558]:	worker_index: 3, step: 547, cost: 8.451139, mlm loss: 8.451139, speed: 0.946178 steps/s, speed: 7.569422 samples/s, speed: 3875.544269 tokens/s, learning rate: 5.460e-06, loss_scalings: 13421.773438, pp_loss: 8.904491
[INFO] 2021-07-12 18:40:38,774 [run_pretraining.py:  512]:	********exe.run_547******* 
[INFO] 2021-07-12 18:40:39,833 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:39,834 [run_pretraining.py:  534]:	loss/total_loss, 4.903003692626953, 548
[INFO] 2021-07-12 18:40:39,834 [run_pretraining.py:  535]:	loss/mlm_loss, 4.903003692626953, 548
[INFO] 2021-07-12 18:40:39,834 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.469999905471923e-06, 548
[INFO] 2021-07-12 18:40:39,834 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 548
[INFO] 2021-07-12 18:40:39,834 [run_pretraining.py:  558]:	worker_index: 3, step: 548, cost: 4.903004, mlm loss: 4.903004, speed: 0.944064 steps/s, speed: 7.552514 samples/s, speed: 3866.887394 tokens/s, learning rate: 5.470e-06, loss_scalings: 13421.773438, pp_loss: 7.952906
[INFO] 2021-07-12 18:40:39,834 [run_pretraining.py:  512]:	********exe.run_548******* 
[INFO] 2021-07-12 18:40:40,894 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:40,895 [run_pretraining.py:  534]:	loss/total_loss, 9.1773681640625, 549
[INFO] 2021-07-12 18:40:40,895 [run_pretraining.py:  535]:	loss/mlm_loss, 9.1773681640625, 549
[INFO] 2021-07-12 18:40:40,895 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.479999799717916e-06, 549
[INFO] 2021-07-12 18:40:40,895 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 549
[INFO] 2021-07-12 18:40:40,895 [run_pretraining.py:  558]:	worker_index: 3, step: 549, cost: 9.177368, mlm loss: 9.177368, speed: 0.942651 steps/s, speed: 7.541206 samples/s, speed: 3861.097680 tokens/s, learning rate: 5.480e-06, loss_scalings: 13421.773438, pp_loss: 8.948801
[INFO] 2021-07-12 18:40:40,895 [run_pretraining.py:  512]:	********exe.run_549******* 
[INFO] 2021-07-12 18:40:41,944 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:41,945 [run_pretraining.py:  534]:	loss/total_loss, 9.083148956298828, 550
[INFO] 2021-07-12 18:40:41,945 [run_pretraining.py:  535]:	loss/mlm_loss, 9.083148956298828, 550
[INFO] 2021-07-12 18:40:41,945 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.49000014871126e-06, 550
[INFO] 2021-07-12 18:40:41,945 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 550
[INFO] 2021-07-12 18:40:41,945 [run_pretraining.py:  558]:	worker_index: 3, step: 550, cost: 9.083149, mlm loss: 9.083149, speed: 0.953306 steps/s, speed: 7.626448 samples/s, speed: 3904.741134 tokens/s, learning rate: 5.490e-06, loss_scalings: 13421.773438, pp_loss: 9.086099
[INFO] 2021-07-12 18:40:41,945 [run_pretraining.py:  512]:	********exe.run_550******* 
[INFO] 2021-07-12 18:40:43,013 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:43,014 [run_pretraining.py:  534]:	loss/total_loss, 8.701555252075195, 551
[INFO] 2021-07-12 18:40:43,014 [run_pretraining.py:  535]:	loss/mlm_loss, 8.701555252075195, 551
[INFO] 2021-07-12 18:40:43,014 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.500000042957254e-06, 551
[INFO] 2021-07-12 18:40:43,014 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 551
[INFO] 2021-07-12 18:40:43,014 [run_pretraining.py:  558]:	worker_index: 3, step: 551, cost: 8.701555, mlm loss: 8.701555, speed: 0.935786 steps/s, speed: 7.486289 samples/s, speed: 3832.980119 tokens/s, learning rate: 5.500e-06, loss_scalings: 13421.773438, pp_loss: 8.980752
[INFO] 2021-07-12 18:40:43,014 [run_pretraining.py:  512]:	********exe.run_551******* 
[INFO] 2021-07-12 18:40:44,093 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:44,094 [run_pretraining.py:  534]:	loss/total_loss, 9.036049842834473, 552
[INFO] 2021-07-12 18:40:44,094 [run_pretraining.py:  535]:	loss/mlm_loss, 9.036049842834473, 552
[INFO] 2021-07-12 18:40:44,094 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.509999937203247e-06, 552
[INFO] 2021-07-12 18:40:44,094 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 552
[INFO] 2021-07-12 18:40:44,094 [run_pretraining.py:  558]:	worker_index: 3, step: 552, cost: 9.036050, mlm loss: 9.036050, speed: 0.926450 steps/s, speed: 7.411597 samples/s, speed: 3794.737420 tokens/s, learning rate: 5.510e-06, loss_scalings: 13421.773438, pp_loss: 9.072016
[INFO] 2021-07-12 18:40:44,094 [run_pretraining.py:  512]:	********exe.run_552******* 
[INFO] 2021-07-12 18:40:45,143 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:45,143 [run_pretraining.py:  534]:	loss/total_loss, 8.865320205688477, 553
[INFO] 2021-07-12 18:40:45,143 [run_pretraining.py:  535]:	loss/mlm_loss, 8.865320205688477, 553
[INFO] 2021-07-12 18:40:45,143 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.5199998314492404e-06, 553
[INFO] 2021-07-12 18:40:45,143 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 553
[INFO] 2021-07-12 18:40:45,144 [run_pretraining.py:  558]:	worker_index: 3, step: 553, cost: 8.865320, mlm loss: 8.865320, speed: 0.953618 steps/s, speed: 7.628948 samples/s, speed: 3906.021317 tokens/s, learning rate: 5.520e-06, loss_scalings: 13421.773438, pp_loss: 9.041519
[INFO] 2021-07-12 18:40:45,144 [run_pretraining.py:  512]:	********exe.run_553******* 
[INFO] 2021-07-12 18:40:46,201 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:46,202 [run_pretraining.py:  534]:	loss/total_loss, 9.09163761138916, 554
[INFO] 2021-07-12 18:40:46,202 [run_pretraining.py:  535]:	loss/mlm_loss, 9.09163761138916, 554
[INFO] 2021-07-12 18:40:46,202 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.530000180442585e-06, 554
[INFO] 2021-07-12 18:40:46,202 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 554
[INFO] 2021-07-12 18:40:46,202 [run_pretraining.py:  558]:	worker_index: 3, step: 554, cost: 9.091638, mlm loss: 9.091638, speed: 0.945212 steps/s, speed: 7.561693 samples/s, speed: 3871.586996 tokens/s, learning rate: 5.530e-06, loss_scalings: 13421.773438, pp_loss: 8.983057
[INFO] 2021-07-12 18:40:46,202 [run_pretraining.py:  512]:	********exe.run_554******* 
[INFO] 2021-07-12 18:40:47,262 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:47,262 [run_pretraining.py:  534]:	loss/total_loss, 8.860394477844238, 555
[INFO] 2021-07-12 18:40:47,263 [run_pretraining.py:  535]:	loss/mlm_loss, 8.860394477844238, 555
[INFO] 2021-07-12 18:40:47,263 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.539999619941227e-06, 555
[INFO] 2021-07-12 18:40:47,263 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 555
[INFO] 2021-07-12 18:40:47,263 [run_pretraining.py:  558]:	worker_index: 3, step: 555, cost: 8.860394, mlm loss: 8.860394, speed: 0.943455 steps/s, speed: 7.547644 samples/s, speed: 3864.393656 tokens/s, learning rate: 5.540e-06, loss_scalings: 13421.773438, pp_loss: 9.036014
[INFO] 2021-07-12 18:40:47,263 [run_pretraining.py:  512]:	********exe.run_555******* 
[INFO] 2021-07-12 18:40:48,325 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:48,326 [run_pretraining.py:  534]:	loss/total_loss, 8.87324333190918, 556
[INFO] 2021-07-12 18:40:48,326 [run_pretraining.py:  535]:	loss/mlm_loss, 8.87324333190918, 556
[INFO] 2021-07-12 18:40:48,326 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.549999968934571e-06, 556
[INFO] 2021-07-12 18:40:48,326 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 556
[INFO] 2021-07-12 18:40:48,326 [run_pretraining.py:  558]:	worker_index: 3, step: 556, cost: 8.873243, mlm loss: 8.873243, speed: 0.940807 steps/s, speed: 7.526456 samples/s, speed: 3853.545577 tokens/s, learning rate: 5.550e-06, loss_scalings: 13421.773438, pp_loss: 8.749196
[INFO] 2021-07-12 18:40:48,326 [run_pretraining.py:  512]:	********exe.run_556******* 
[INFO] 2021-07-12 18:40:49,396 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:49,397 [run_pretraining.py:  534]:	loss/total_loss, 9.167518615722656, 557
[INFO] 2021-07-12 18:40:49,397 [run_pretraining.py:  535]:	loss/mlm_loss, 9.167518615722656, 557
[INFO] 2021-07-12 18:40:49,397 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.559999863180565e-06, 557
[INFO] 2021-07-12 18:40:49,397 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 557
[INFO] 2021-07-12 18:40:49,397 [run_pretraining.py:  558]:	worker_index: 3, step: 557, cost: 9.167519, mlm loss: 9.167519, speed: 0.934281 steps/s, speed: 7.474248 samples/s, speed: 3826.814857 tokens/s, learning rate: 5.560e-06, loss_scalings: 13421.773438, pp_loss: 8.868626
[INFO] 2021-07-12 18:40:49,397 [run_pretraining.py:  512]:	********exe.run_557******* 
[INFO] 2021-07-12 18:40:50,479 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:50,480 [run_pretraining.py:  534]:	loss/total_loss, 9.014869689941406, 558
[INFO] 2021-07-12 18:40:50,480 [run_pretraining.py:  535]:	loss/mlm_loss, 9.014869689941406, 558
[INFO] 2021-07-12 18:40:50,480 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.569999757426558e-06, 558
[INFO] 2021-07-12 18:40:50,480 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 558
[INFO] 2021-07-12 18:40:50,480 [run_pretraining.py:  558]:	worker_index: 3, step: 558, cost: 9.014870, mlm loss: 9.014870, speed: 0.924041 steps/s, speed: 7.392327 samples/s, speed: 3784.871630 tokens/s, learning rate: 5.570e-06, loss_scalings: 13421.773438, pp_loss: 8.903481
[INFO] 2021-07-12 18:40:50,480 [run_pretraining.py:  512]:	********exe.run_558******* 
[INFO] 2021-07-12 18:40:51,536 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:51,537 [run_pretraining.py:  534]:	loss/total_loss, 8.585471153259277, 559
[INFO] 2021-07-12 18:40:51,537 [run_pretraining.py:  535]:	loss/mlm_loss, 8.585471153259277, 559
[INFO] 2021-07-12 18:40:51,537 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.579999651672551e-06, 559
[INFO] 2021-07-12 18:40:51,537 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 559
[INFO] 2021-07-12 18:40:51,537 [run_pretraining.py:  558]:	worker_index: 3, step: 559, cost: 8.585471, mlm loss: 8.585471, speed: 0.946714 steps/s, speed: 7.573716 samples/s, speed: 3877.742555 tokens/s, learning rate: 5.580e-06, loss_scalings: 13421.773438, pp_loss: 8.921288
[INFO] 2021-07-12 18:40:51,537 [run_pretraining.py:  512]:	********exe.run_559******* 
[INFO] 2021-07-12 18:40:52,596 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:52,597 [run_pretraining.py:  534]:	loss/total_loss, 9.016341209411621, 560
[INFO] 2021-07-12 18:40:52,597 [run_pretraining.py:  535]:	loss/mlm_loss, 9.016341209411621, 560
[INFO] 2021-07-12 18:40:52,597 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.590000000665896e-06, 560
[INFO] 2021-07-12 18:40:52,597 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 560
[INFO] 2021-07-12 18:40:52,597 [run_pretraining.py:  558]:	worker_index: 3, step: 560, cost: 9.016341, mlm loss: 9.016341, speed: 0.944137 steps/s, speed: 7.553094 samples/s, speed: 3867.184212 tokens/s, learning rate: 5.590e-06, loss_scalings: 13421.773438, pp_loss: 8.984982
[INFO] 2021-07-12 18:40:52,597 [run_pretraining.py:  512]:	********exe.run_560******* 
[INFO] 2021-07-12 18:40:53,666 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:53,666 [run_pretraining.py:  534]:	loss/total_loss, 8.742280006408691, 561
[INFO] 2021-07-12 18:40:53,667 [run_pretraining.py:  535]:	loss/mlm_loss, 8.742280006408691, 561
[INFO] 2021-07-12 18:40:53,667 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.599999894911889e-06, 561
[INFO] 2021-07-12 18:40:53,667 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 561
[INFO] 2021-07-12 18:40:53,667 [run_pretraining.py:  558]:	worker_index: 3, step: 561, cost: 8.742280, mlm loss: 8.742280, speed: 0.935187 steps/s, speed: 7.481499 samples/s, speed: 3830.527347 tokens/s, learning rate: 5.600e-06, loss_scalings: 13421.773438, pp_loss: 8.652361
[INFO] 2021-07-12 18:40:53,667 [run_pretraining.py:  512]:	********exe.run_561******* 
[INFO] 2021-07-12 18:40:54,713 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:54,713 [run_pretraining.py:  534]:	loss/total_loss, 8.850154876708984, 562
[INFO] 2021-07-12 18:40:54,713 [run_pretraining.py:  535]:	loss/mlm_loss, 8.850154876708984, 562
[INFO] 2021-07-12 18:40:54,713 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.609999789157882e-06, 562
[INFO] 2021-07-12 18:40:54,714 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 562
[INFO] 2021-07-12 18:40:54,714 [run_pretraining.py:  558]:	worker_index: 3, step: 562, cost: 8.850155, mlm loss: 8.850155, speed: 0.955883 steps/s, speed: 7.647063 samples/s, speed: 3915.296136 tokens/s, learning rate: 5.610e-06, loss_scalings: 13421.773438, pp_loss: 8.884834
[INFO] 2021-07-12 18:40:54,714 [run_pretraining.py:  512]:	********exe.run_562******* 
[INFO] 2021-07-12 18:40:55,778 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:55,778 [run_pretraining.py:  534]:	loss/total_loss, 9.144111633300781, 563
[INFO] 2021-07-12 18:40:55,778 [run_pretraining.py:  535]:	loss/mlm_loss, 9.144111633300781, 563
[INFO] 2021-07-12 18:40:55,778 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.6200001381512266e-06, 563
[INFO] 2021-07-12 18:40:55,778 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 563
[INFO] 2021-07-12 18:40:55,779 [run_pretraining.py:  558]:	worker_index: 3, step: 563, cost: 9.144112, mlm loss: 9.144112, speed: 0.939594 steps/s, speed: 7.516753 samples/s, speed: 3848.577524 tokens/s, learning rate: 5.620e-06, loss_scalings: 13421.773438, pp_loss: 8.990487
[INFO] 2021-07-12 18:40:55,779 [run_pretraining.py:  512]:	********exe.run_563******* 
[INFO] 2021-07-12 18:40:56,828 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:56,829 [run_pretraining.py:  534]:	loss/total_loss, 8.782873153686523, 564
[INFO] 2021-07-12 18:40:56,829 [run_pretraining.py:  535]:	loss/mlm_loss, 8.782873153686523, 564
[INFO] 2021-07-12 18:40:56,829 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.629999577649869e-06, 564
[INFO] 2021-07-12 18:40:56,829 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 564
[INFO] 2021-07-12 18:40:56,829 [run_pretraining.py:  558]:	worker_index: 3, step: 564, cost: 8.782873, mlm loss: 8.782873, speed: 0.952524 steps/s, speed: 7.620192 samples/s, speed: 3901.538141 tokens/s, learning rate: 5.630e-06, loss_scalings: 13421.773438, pp_loss: 8.994944
[INFO] 2021-07-12 18:40:56,829 [run_pretraining.py:  512]:	********exe.run_564******* 
[INFO] 2021-07-12 18:40:57,879 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:57,879 [run_pretraining.py:  534]:	loss/total_loss, 9.224862098693848, 565
[INFO] 2021-07-12 18:40:57,879 [run_pretraining.py:  535]:	loss/mlm_loss, 9.224862098693848, 565
[INFO] 2021-07-12 18:40:57,880 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.639999926643213e-06, 565
[INFO] 2021-07-12 18:40:57,880 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 565
[INFO] 2021-07-12 18:40:57,880 [run_pretraining.py:  558]:	worker_index: 3, step: 565, cost: 9.224862, mlm loss: 9.224862, speed: 0.952380 steps/s, speed: 7.619038 samples/s, speed: 3900.947243 tokens/s, learning rate: 5.640e-06, loss_scalings: 13421.773438, pp_loss: 9.011567
[INFO] 2021-07-12 18:40:57,880 [run_pretraining.py:  512]:	********exe.run_565******* 
[INFO] 2021-07-12 18:40:58,938 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:58,939 [run_pretraining.py:  534]:	loss/total_loss, 9.221166610717773, 566
[INFO] 2021-07-12 18:40:58,939 [run_pretraining.py:  535]:	loss/mlm_loss, 9.221166610717773, 566
[INFO] 2021-07-12 18:40:58,939 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.649999820889207e-06, 566
[INFO] 2021-07-12 18:40:58,939 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 566
[INFO] 2021-07-12 18:40:58,939 [run_pretraining.py:  558]:	worker_index: 3, step: 566, cost: 9.221167, mlm loss: 9.221167, speed: 0.944370 steps/s, speed: 7.554963 samples/s, speed: 3868.141131 tokens/s, learning rate: 5.650e-06, loss_scalings: 13421.773438, pp_loss: 8.969227
[INFO] 2021-07-12 18:40:58,939 [run_pretraining.py:  512]:	********exe.run_566******* 
[INFO] 2021-07-12 18:41:00,002 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:00,002 [run_pretraining.py:  534]:	loss/total_loss, 8.744985580444336, 567
[INFO] 2021-07-12 18:41:00,002 [run_pretraining.py:  535]:	loss/mlm_loss, 8.744985580444336, 567
[INFO] 2021-07-12 18:41:00,002 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.6599997151352e-06, 567
[INFO] 2021-07-12 18:41:00,002 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 567
[INFO] 2021-07-12 18:41:00,003 [run_pretraining.py:  558]:	worker_index: 3, step: 567, cost: 8.744986, mlm loss: 8.744986, speed: 0.940974 steps/s, speed: 7.527794 samples/s, speed: 3854.230282 tokens/s, learning rate: 5.660e-06, loss_scalings: 13421.773438, pp_loss: 8.844973
[INFO] 2021-07-12 18:41:00,003 [run_pretraining.py:  512]:	********exe.run_567******* 
[INFO] 2021-07-12 18:41:01,046 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:01,046 [run_pretraining.py:  534]:	loss/total_loss, 5.452040672302246, 568
[INFO] 2021-07-12 18:41:01,046 [run_pretraining.py:  535]:	loss/mlm_loss, 5.452040672302246, 568
[INFO] 2021-07-12 18:41:01,047 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.669999609381193e-06, 568
[INFO] 2021-07-12 18:41:01,047 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 568
[INFO] 2021-07-12 18:41:01,047 [run_pretraining.py:  558]:	worker_index: 3, step: 568, cost: 5.452041, mlm loss: 5.452041, speed: 0.958350 steps/s, speed: 7.666800 samples/s, speed: 3925.401536 tokens/s, learning rate: 5.670e-06, loss_scalings: 13421.773438, pp_loss: 8.107594
[INFO] 2021-07-12 18:41:01,047 [run_pretraining.py:  512]:	********exe.run_568******* 
[INFO] 2021-07-12 18:41:01,964 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:01,964 [run_pretraining.py:  534]:	loss/total_loss, 8.671343803405762, 569
[INFO] 2021-07-12 18:41:01,965 [run_pretraining.py:  535]:	loss/mlm_loss, 8.671343803405762, 569
[INFO] 2021-07-12 18:41:01,965 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.6799999583745375e-06, 569
[INFO] 2021-07-12 18:41:01,965 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 569
[INFO] 2021-07-12 18:41:01,965 [run_pretraining.py:  558]:	worker_index: 3, step: 569, cost: 8.671344, mlm loss: 8.671344, speed: 1.089872 steps/s, speed: 8.718977 samples/s, speed: 4464.115999 tokens/s, learning rate: 5.680e-06, loss_scalings: 13421.773438, pp_loss: 8.746328
[INFO] 2021-07-12 18:41:01,965 [run_pretraining.py:  512]:	********exe.run_569******* 
[INFO] 2021-07-12 18:41:02,881 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:02,881 [run_pretraining.py:  534]:	loss/total_loss, 9.124656677246094, 570
[INFO] 2021-07-12 18:41:02,881 [run_pretraining.py:  535]:	loss/mlm_loss, 9.124656677246094, 570
[INFO] 2021-07-12 18:41:02,881 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.689999852620531e-06, 570
[INFO] 2021-07-12 18:41:02,881 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 570
[INFO] 2021-07-12 18:41:02,881 [run_pretraining.py:  558]:	worker_index: 3, step: 570, cost: 9.124657, mlm loss: 9.124657, speed: 1.091751 steps/s, speed: 8.734010 samples/s, speed: 4471.812965 tokens/s, learning rate: 5.690e-06, loss_scalings: 13421.773438, pp_loss: 8.992420
[INFO] 2021-07-12 18:41:02,881 [run_pretraining.py:  512]:	********exe.run_570******* 
[INFO] 2021-07-12 18:41:03,797 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:03,797 [run_pretraining.py:  534]:	loss/total_loss, 9.066232681274414, 571
[INFO] 2021-07-12 18:41:03,797 [run_pretraining.py:  535]:	loss/mlm_loss, 9.066232681274414, 571
[INFO] 2021-07-12 18:41:03,797 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.699999746866524e-06, 571
[INFO] 2021-07-12 18:41:03,797 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 571
[INFO] 2021-07-12 18:41:03,798 [run_pretraining.py:  558]:	worker_index: 3, step: 571, cost: 9.066233, mlm loss: 9.066233, speed: 1.092304 steps/s, speed: 8.738429 samples/s, speed: 4474.075733 tokens/s, learning rate: 5.700e-06, loss_scalings: 13421.773438, pp_loss: 8.888859
[INFO] 2021-07-12 18:41:03,798 [run_pretraining.py:  512]:	********exe.run_571******* 
[INFO] 2021-07-12 18:41:04,821 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:04,822 [run_pretraining.py:  534]:	loss/total_loss, 8.708270072937012, 572
[INFO] 2021-07-12 18:41:04,822 [run_pretraining.py:  535]:	loss/mlm_loss, 8.708270072937012, 572
[INFO] 2021-07-12 18:41:04,822 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.7100000958598685e-06, 572
[INFO] 2021-07-12 18:41:04,822 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 572
[INFO] 2021-07-12 18:41:04,822 [run_pretraining.py:  558]:	worker_index: 3, step: 572, cost: 8.708270, mlm loss: 8.708270, speed: 0.976498 steps/s, speed: 7.811980 samples/s, speed: 3999.733935 tokens/s, learning rate: 5.710e-06, loss_scalings: 13421.773438, pp_loss: 7.846102
[INFO] 2021-07-12 18:41:04,822 [run_pretraining.py:  512]:	********exe.run_572******* 
[INFO] 2021-07-12 18:41:05,877 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:05,878 [run_pretraining.py:  534]:	loss/total_loss, 9.010344505310059, 573
[INFO] 2021-07-12 18:41:05,878 [run_pretraining.py:  535]:	loss/mlm_loss, 9.010344505310059, 573
[INFO] 2021-07-12 18:41:05,878 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.719999990105862e-06, 573
[INFO] 2021-07-12 18:41:05,878 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 573
[INFO] 2021-07-12 18:41:05,878 [run_pretraining.py:  558]:	worker_index: 3, step: 573, cost: 9.010345, mlm loss: 9.010345, speed: 0.947648 steps/s, speed: 7.581184 samples/s, speed: 3881.565965 tokens/s, learning rate: 5.720e-06, loss_scalings: 13421.773438, pp_loss: 8.943206
[INFO] 2021-07-12 18:41:05,878 [run_pretraining.py:  512]:	********exe.run_573******* 
[INFO] 2021-07-12 18:41:06,933 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:06,933 [run_pretraining.py:  534]:	loss/total_loss, 9.085955619812012, 574
[INFO] 2021-07-12 18:41:06,934 [run_pretraining.py:  535]:	loss/mlm_loss, 9.085955619812012, 574
[INFO] 2021-07-12 18:41:06,934 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.729999884351855e-06, 574
[INFO] 2021-07-12 18:41:06,934 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 574
[INFO] 2021-07-12 18:41:06,934 [run_pretraining.py:  558]:	worker_index: 3, step: 574, cost: 9.085956, mlm loss: 9.085956, speed: 0.947837 steps/s, speed: 7.582700 samples/s, speed: 3882.342255 tokens/s, learning rate: 5.730e-06, loss_scalings: 13421.773438, pp_loss: 8.934790
[INFO] 2021-07-12 18:41:06,934 [run_pretraining.py:  512]:	********exe.run_574******* 
[INFO] 2021-07-12 18:41:07,915 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:07,915 [run_pretraining.py:  534]:	loss/total_loss, 8.767244338989258, 575
[INFO] 2021-07-12 18:41:07,915 [run_pretraining.py:  535]:	loss/mlm_loss, 8.767244338989258, 575
[INFO] 2021-07-12 18:41:07,915 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.7399997785978485e-06, 575
[INFO] 2021-07-12 18:41:07,915 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 575
[INFO] 2021-07-12 18:41:07,915 [run_pretraining.py:  558]:	worker_index: 3, step: 575, cost: 8.767244, mlm loss: 8.767244, speed: 1.019335 steps/s, speed: 8.154683 samples/s, speed: 4175.197578 tokens/s, learning rate: 5.740e-06, loss_scalings: 13421.773438, pp_loss: 8.910534
[INFO] 2021-07-12 18:41:07,916 [run_pretraining.py:  512]:	********exe.run_575******* 
[INFO] 2021-07-12 18:41:08,828 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:08,829 [run_pretraining.py:  534]:	loss/total_loss, 8.660222053527832, 576
[INFO] 2021-07-12 18:41:08,829 [run_pretraining.py:  535]:	loss/mlm_loss, 8.660222053527832, 576
[INFO] 2021-07-12 18:41:08,829 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.750000127591193e-06, 576
[INFO] 2021-07-12 18:41:08,829 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 576
[INFO] 2021-07-12 18:41:08,829 [run_pretraining.py:  558]:	worker_index: 3, step: 576, cost: 8.660222, mlm loss: 8.660222, speed: 1.095240 steps/s, speed: 8.761918 samples/s, speed: 4486.102165 tokens/s, learning rate: 5.750e-06, loss_scalings: 13421.773438, pp_loss: 8.223611
[INFO] 2021-07-12 18:41:08,829 [run_pretraining.py:  512]:	********exe.run_576******* 
[INFO] 2021-07-12 18:41:09,739 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:09,740 [run_pretraining.py:  534]:	loss/total_loss, 9.038433074951172, 577
[INFO] 2021-07-12 18:41:09,740 [run_pretraining.py:  535]:	loss/mlm_loss, 9.038433074951172, 577
[INFO] 2021-07-12 18:41:09,740 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.759999567089835e-06, 577
[INFO] 2021-07-12 18:41:09,740 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 577
[INFO] 2021-07-12 18:41:09,740 [run_pretraining.py:  558]:	worker_index: 3, step: 577, cost: 9.038433, mlm loss: 9.038433, speed: 1.098528 steps/s, speed: 8.788226 samples/s, speed: 4499.571826 tokens/s, learning rate: 5.760e-06, loss_scalings: 13421.773438, pp_loss: 8.730877
[INFO] 2021-07-12 18:41:09,740 [run_pretraining.py:  512]:	********exe.run_577******* 
[INFO] 2021-07-12 18:41:10,665 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:10,665 [run_pretraining.py:  534]:	loss/total_loss, 8.925286293029785, 578
[INFO] 2021-07-12 18:41:10,665 [run_pretraining.py:  535]:	loss/mlm_loss, 8.925286293029785, 578
[INFO] 2021-07-12 18:41:10,666 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.769999916083179e-06, 578
[INFO] 2021-07-12 18:41:10,666 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 578
[INFO] 2021-07-12 18:41:10,666 [run_pretraining.py:  558]:	worker_index: 3, step: 578, cost: 8.925286, mlm loss: 8.925286, speed: 1.081125 steps/s, speed: 8.649004 samples/s, speed: 4428.289818 tokens/s, learning rate: 5.770e-06, loss_scalings: 13421.773438, pp_loss: 9.301219
[INFO] 2021-07-12 18:41:10,666 [run_pretraining.py:  512]:	********exe.run_578******* 
[INFO] 2021-07-12 18:41:11,581 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:11,582 [run_pretraining.py:  534]:	loss/total_loss, 8.542264938354492, 579
[INFO] 2021-07-12 18:41:11,582 [run_pretraining.py:  535]:	loss/mlm_loss, 8.542264938354492, 579
[INFO] 2021-07-12 18:41:11,582 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.779999810329173e-06, 579
[INFO] 2021-07-12 18:41:11,582 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 579
[INFO] 2021-07-12 18:41:11,582 [run_pretraining.py:  558]:	worker_index: 3, step: 579, cost: 8.542265, mlm loss: 8.542265, speed: 1.091657 steps/s, speed: 8.733257 samples/s, speed: 4471.427720 tokens/s, learning rate: 5.780e-06, loss_scalings: 13421.773438, pp_loss: 8.758810
[INFO] 2021-07-12 18:41:11,582 [run_pretraining.py:  512]:	********exe.run_579******* 
[INFO] 2021-07-12 18:41:12,500 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:12,500 [run_pretraining.py:  534]:	loss/total_loss, 8.825915336608887, 580
[INFO] 2021-07-12 18:41:12,500 [run_pretraining.py:  535]:	loss/mlm_loss, 8.825915336608887, 580
[INFO] 2021-07-12 18:41:12,500 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.789999704575166e-06, 580
[INFO] 2021-07-12 18:41:12,500 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 580
[INFO] 2021-07-12 18:41:12,500 [run_pretraining.py:  558]:	worker_index: 3, step: 580, cost: 8.825915, mlm loss: 8.825915, speed: 1.089968 steps/s, speed: 8.719740 samples/s, speed: 4464.506947 tokens/s, learning rate: 5.790e-06, loss_scalings: 13421.773438, pp_loss: 8.620414
[INFO] 2021-07-12 18:41:12,501 [run_pretraining.py:  512]:	********exe.run_580******* 
[INFO] 2021-07-12 18:41:13,420 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:13,421 [run_pretraining.py:  534]:	loss/total_loss, 8.988861083984375, 581
[INFO] 2021-07-12 18:41:13,421 [run_pretraining.py:  535]:	loss/mlm_loss, 8.988861083984375, 581
[INFO] 2021-07-12 18:41:13,421 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.7999995988211595e-06, 581
[INFO] 2021-07-12 18:41:13,421 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 581
[INFO] 2021-07-12 18:41:13,421 [run_pretraining.py:  558]:	worker_index: 3, step: 581, cost: 8.988861, mlm loss: 8.988861, speed: 1.086794 steps/s, speed: 8.694354 samples/s, speed: 4451.509064 tokens/s, learning rate: 5.800e-06, loss_scalings: 13421.773438, pp_loss: 8.946268
[INFO] 2021-07-12 18:41:13,421 [run_pretraining.py:  512]:	********exe.run_581******* 
[INFO] 2021-07-12 18:41:14,341 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:14,341 [run_pretraining.py:  534]:	loss/total_loss, 8.301308631896973, 582
[INFO] 2021-07-12 18:41:14,341 [run_pretraining.py:  535]:	loss/mlm_loss, 8.301308631896973, 582
[INFO] 2021-07-12 18:41:14,341 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.809999947814504e-06, 582
[INFO] 2021-07-12 18:41:14,341 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 582
[INFO] 2021-07-12 18:41:14,342 [run_pretraining.py:  558]:	worker_index: 3, step: 582, cost: 8.301309, mlm loss: 8.301309, speed: 1.087375 steps/s, speed: 8.698997 samples/s, speed: 4453.886417 tokens/s, learning rate: 5.810e-06, loss_scalings: 13421.773438, pp_loss: 8.696109
[INFO] 2021-07-12 18:41:14,342 [run_pretraining.py:  512]:	********exe.run_582******* 
[INFO] 2021-07-12 18:41:15,255 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:15,255 [run_pretraining.py:  534]:	loss/total_loss, 9.29149341583252, 583
[INFO] 2021-07-12 18:41:15,255 [run_pretraining.py:  535]:	loss/mlm_loss, 9.29149341583252, 583
[INFO] 2021-07-12 18:41:15,255 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.819999842060497e-06, 583
[INFO] 2021-07-12 18:41:15,255 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 583
[INFO] 2021-07-12 18:41:15,256 [run_pretraining.py:  558]:	worker_index: 3, step: 583, cost: 9.291493, mlm loss: 9.291493, speed: 1.094943 steps/s, speed: 8.759542 samples/s, speed: 4484.885373 tokens/s, learning rate: 5.820e-06, loss_scalings: 13421.773438, pp_loss: 8.940815
[INFO] 2021-07-12 18:41:15,256 [run_pretraining.py:  512]:	********exe.run_583******* 
[INFO] 2021-07-12 18:41:16,175 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:16,175 [run_pretraining.py:  534]:	loss/total_loss, 8.664307594299316, 584
[INFO] 2021-07-12 18:41:16,175 [run_pretraining.py:  535]:	loss/mlm_loss, 8.664307594299316, 584
[INFO] 2021-07-12 18:41:16,175 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.82999973630649e-06, 584
[INFO] 2021-07-12 18:41:16,176 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 584
[INFO] 2021-07-12 18:41:16,176 [run_pretraining.py:  558]:	worker_index: 3, step: 584, cost: 8.664308, mlm loss: 8.664308, speed: 1.087586 steps/s, speed: 8.700686 samples/s, speed: 4454.751434 tokens/s, learning rate: 5.830e-06, loss_scalings: 13421.773438, pp_loss: 8.607558
[INFO] 2021-07-12 18:41:16,176 [run_pretraining.py:  512]:	********exe.run_584******* 
[INFO] 2021-07-12 18:41:17,085 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:17,085 [run_pretraining.py:  534]:	loss/total_loss, 8.7455415725708, 585
[INFO] 2021-07-12 18:41:17,085 [run_pretraining.py:  535]:	loss/mlm_loss, 8.7455415725708, 585
[INFO] 2021-07-12 18:41:17,085 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.840000085299835e-06, 585
[INFO] 2021-07-12 18:41:17,085 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 585
[INFO] 2021-07-12 18:41:17,085 [run_pretraining.py:  558]:	worker_index: 3, step: 585, cost: 8.745542, mlm loss: 8.745542, speed: 1.099884 steps/s, speed: 8.799071 samples/s, speed: 4505.124601 tokens/s, learning rate: 5.840e-06, loss_scalings: 13421.773438, pp_loss: 8.674650
[INFO] 2021-07-12 18:41:17,086 [run_pretraining.py:  512]:	********exe.run_585******* 
[INFO] 2021-07-12 18:41:17,993 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:17,993 [run_pretraining.py:  534]:	loss/total_loss, 8.830968856811523, 586
[INFO] 2021-07-12 18:41:17,993 [run_pretraining.py:  535]:	loss/mlm_loss, 8.830968856811523, 586
[INFO] 2021-07-12 18:41:17,993 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.849999979545828e-06, 586
[INFO] 2021-07-12 18:41:17,994 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 586
[INFO] 2021-07-12 18:41:17,994 [run_pretraining.py:  558]:	worker_index: 3, step: 586, cost: 8.830969, mlm loss: 8.830969, speed: 1.101886 steps/s, speed: 8.815091 samples/s, speed: 4513.326548 tokens/s, learning rate: 5.850e-06, loss_scalings: 13421.773438, pp_loss: 8.491730
[INFO] 2021-07-12 18:41:17,994 [run_pretraining.py:  512]:	********exe.run_586******* 
[INFO] 2021-07-12 18:41:18,902 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:18,903 [run_pretraining.py:  534]:	loss/total_loss, 8.481851577758789, 587
[INFO] 2021-07-12 18:41:18,903 [run_pretraining.py:  535]:	loss/mlm_loss, 8.481851577758789, 587
[INFO] 2021-07-12 18:41:18,903 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.859999873791821e-06, 587
[INFO] 2021-07-12 18:41:18,903 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 587
[INFO] 2021-07-12 18:41:18,903 [run_pretraining.py:  558]:	worker_index: 3, step: 587, cost: 8.481852, mlm loss: 8.481852, speed: 1.100138 steps/s, speed: 8.801105 samples/s, speed: 4506.165647 tokens/s, learning rate: 5.860e-06, loss_scalings: 13421.773438, pp_loss: 8.553760
[INFO] 2021-07-12 18:41:18,903 [run_pretraining.py:  512]:	********exe.run_587******* 
[INFO] 2021-07-12 18:41:19,806 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:19,807 [run_pretraining.py:  534]:	loss/total_loss, 8.590946197509766, 588
[INFO] 2021-07-12 18:41:19,807 [run_pretraining.py:  535]:	loss/mlm_loss, 8.590946197509766, 588
[INFO] 2021-07-12 18:41:19,807 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.869999768037815e-06, 588
[INFO] 2021-07-12 18:41:19,807 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 588
[INFO] 2021-07-12 18:41:19,807 [run_pretraining.py:  558]:	worker_index: 3, step: 588, cost: 8.590946, mlm loss: 8.590946, speed: 1.106760 steps/s, speed: 8.854078 samples/s, speed: 4533.287908 tokens/s, learning rate: 5.870e-06, loss_scalings: 13421.773438, pp_loss: 8.034040
[INFO] 2021-07-12 18:41:19,808 [run_pretraining.py:  512]:	********exe.run_588******* 
[INFO] 2021-07-12 18:41:20,711 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:20,712 [run_pretraining.py:  534]:	loss/total_loss, 8.87218952178955, 589
[INFO] 2021-07-12 18:41:20,712 [run_pretraining.py:  535]:	loss/mlm_loss, 8.87218952178955, 589
[INFO] 2021-07-12 18:41:20,712 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.880000117031159e-06, 589
[INFO] 2021-07-12 18:41:20,712 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 589
[INFO] 2021-07-12 18:41:20,712 [run_pretraining.py:  558]:	worker_index: 3, step: 589, cost: 8.872190, mlm loss: 8.872190, speed: 1.106149 steps/s, speed: 8.849195 samples/s, speed: 4530.788016 tokens/s, learning rate: 5.880e-06, loss_scalings: 13421.773438, pp_loss: 8.071320
[INFO] 2021-07-12 18:41:20,712 [run_pretraining.py:  512]:	********exe.run_589******* 
[INFO] 2021-07-12 18:41:21,676 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:21,676 [run_pretraining.py:  534]:	loss/total_loss, 8.83054256439209, 590
[INFO] 2021-07-12 18:41:21,676 [run_pretraining.py:  535]:	loss/mlm_loss, 8.83054256439209, 590
[INFO] 2021-07-12 18:41:21,676 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.889999556529801e-06, 590
[INFO] 2021-07-12 18:41:21,677 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 590
[INFO] 2021-07-12 18:41:21,677 [run_pretraining.py:  558]:	worker_index: 3, step: 590, cost: 8.830543, mlm loss: 8.830543, speed: 1.037540 steps/s, speed: 8.300324 samples/s, speed: 4249.765725 tokens/s, learning rate: 5.890e-06, loss_scalings: 13421.773438, pp_loss: 8.773376
[INFO] 2021-07-12 18:41:21,677 [run_pretraining.py:  512]:	********exe.run_590******* 
[INFO] 2021-07-12 18:41:22,588 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:22,588 [run_pretraining.py:  534]:	loss/total_loss, 8.632305145263672, 591
[INFO] 2021-07-12 18:41:22,589 [run_pretraining.py:  535]:	loss/mlm_loss, 8.632305145263672, 591
[INFO] 2021-07-12 18:41:22,589 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.8999999055231456e-06, 591
[INFO] 2021-07-12 18:41:22,589 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 591
[INFO] 2021-07-12 18:41:22,589 [run_pretraining.py:  558]:	worker_index: 3, step: 591, cost: 8.632305, mlm loss: 8.632305, speed: 1.097074 steps/s, speed: 8.776593 samples/s, speed: 4493.615430 tokens/s, learning rate: 5.900e-06, loss_scalings: 13421.773438, pp_loss: 9.197605
[INFO] 2021-07-12 18:41:22,589 [run_pretraining.py:  512]:	********exe.run_591******* 
[INFO] 2021-07-12 18:41:23,495 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:23,495 [run_pretraining.py:  534]:	loss/total_loss, 8.807243347167969, 592
[INFO] 2021-07-12 18:41:23,495 [run_pretraining.py:  535]:	loss/mlm_loss, 8.807243347167969, 592
[INFO] 2021-07-12 18:41:23,495 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.909999799769139e-06, 592
[INFO] 2021-07-12 18:41:23,495 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 592
[INFO] 2021-07-12 18:41:23,496 [run_pretraining.py:  558]:	worker_index: 3, step: 592, cost: 8.807243, mlm loss: 8.807243, speed: 1.103568 steps/s, speed: 8.828545 samples/s, speed: 4520.215273 tokens/s, learning rate: 5.910e-06, loss_scalings: 13421.773438, pp_loss: 8.816983
[INFO] 2021-07-12 18:41:23,496 [run_pretraining.py:  512]:	********exe.run_592******* 
[INFO] 2021-07-12 18:41:24,416 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:24,417 [run_pretraining.py:  534]:	loss/total_loss, 8.72999095916748, 593
[INFO] 2021-07-12 18:41:24,417 [run_pretraining.py:  535]:	loss/mlm_loss, 8.72999095916748, 593
[INFO] 2021-07-12 18:41:24,417 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.919999694015132e-06, 593
[INFO] 2021-07-12 18:41:24,417 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 593
[INFO] 2021-07-12 18:41:24,417 [run_pretraining.py:  558]:	worker_index: 3, step: 593, cost: 8.729991, mlm loss: 8.729991, speed: 1.086072 steps/s, speed: 8.688572 samples/s, speed: 4448.549002 tokens/s, learning rate: 5.920e-06, loss_scalings: 13421.773438, pp_loss: 8.787122
[INFO] 2021-07-12 18:41:24,417 [run_pretraining.py:  512]:	********exe.run_593******* 
[INFO] 2021-07-12 18:41:25,392 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:25,393 [run_pretraining.py:  534]:	loss/total_loss, 6.459301471710205, 594
[INFO] 2021-07-12 18:41:25,393 [run_pretraining.py:  535]:	loss/mlm_loss, 6.459301471710205, 594
[INFO] 2021-07-12 18:41:25,393 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.9300000430084765e-06, 594
[INFO] 2021-07-12 18:41:25,393 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 594
[INFO] 2021-07-12 18:41:25,393 [run_pretraining.py:  558]:	worker_index: 3, step: 594, cost: 6.459301, mlm loss: 6.459301, speed: 1.024937 steps/s, speed: 8.199499 samples/s, speed: 4198.143415 tokens/s, learning rate: 5.930e-06, loss_scalings: 13421.773438, pp_loss: 7.989747
[INFO] 2021-07-12 18:41:25,393 [run_pretraining.py:  512]:	********exe.run_594******* 
[INFO] 2021-07-12 18:41:26,305 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:26,306 [run_pretraining.py:  534]:	loss/total_loss, 8.688005447387695, 595
[INFO] 2021-07-12 18:41:26,306 [run_pretraining.py:  535]:	loss/mlm_loss, 8.688005447387695, 595
[INFO] 2021-07-12 18:41:26,306 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.93999993725447e-06, 595
[INFO] 2021-07-12 18:41:26,306 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 595
[INFO] 2021-07-12 18:41:26,306 [run_pretraining.py:  558]:	worker_index: 3, step: 595, cost: 8.688005, mlm loss: 8.688005, speed: 1.095966 steps/s, speed: 8.767731 samples/s, speed: 4489.078413 tokens/s, learning rate: 5.940e-06, loss_scalings: 13421.773438, pp_loss: 8.880136
[INFO] 2021-07-12 18:41:26,306 [run_pretraining.py:  512]:	********exe.run_595******* 
[INFO] 2021-07-12 18:41:27,239 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:27,240 [run_pretraining.py:  534]:	loss/total_loss, 8.449583053588867, 596
[INFO] 2021-07-12 18:41:27,240 [run_pretraining.py:  535]:	loss/mlm_loss, 8.449583053588867, 596
[INFO] 2021-07-12 18:41:27,240 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.949999831500463e-06, 596
[INFO] 2021-07-12 18:41:27,240 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 596
[INFO] 2021-07-12 18:41:27,240 [run_pretraining.py:  558]:	worker_index: 3, step: 596, cost: 8.449583, mlm loss: 8.449583, speed: 1.071575 steps/s, speed: 8.572597 samples/s, speed: 4389.169854 tokens/s, learning rate: 5.950e-06, loss_scalings: 13421.773438, pp_loss: 8.894106
[INFO] 2021-07-12 18:41:27,240 [run_pretraining.py:  512]:	********exe.run_596******* 
[INFO] 2021-07-12 18:41:28,149 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:28,150 [run_pretraining.py:  534]:	loss/total_loss, 8.517719268798828, 597
[INFO] 2021-07-12 18:41:28,150 [run_pretraining.py:  535]:	loss/mlm_loss, 8.517719268798828, 597
[INFO] 2021-07-12 18:41:28,150 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.9599997257464565e-06, 597
[INFO] 2021-07-12 18:41:28,150 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 597
[INFO] 2021-07-12 18:41:28,150 [run_pretraining.py:  558]:	worker_index: 3, step: 597, cost: 8.517719, mlm loss: 8.517719, speed: 1.099539 steps/s, speed: 8.796313 samples/s, speed: 4503.712100 tokens/s, learning rate: 5.960e-06, loss_scalings: 13421.773438, pp_loss: 8.717130
[INFO] 2021-07-12 18:41:28,150 [run_pretraining.py:  512]:	********exe.run_597******* 
[INFO] 2021-07-12 18:41:29,057 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:29,058 [run_pretraining.py:  534]:	loss/total_loss, 8.484621047973633, 598
[INFO] 2021-07-12 18:41:29,058 [run_pretraining.py:  535]:	loss/mlm_loss, 8.484621047973633, 598
[INFO] 2021-07-12 18:41:29,058 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.970000074739801e-06, 598
[INFO] 2021-07-12 18:41:29,058 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 598
[INFO] 2021-07-12 18:41:29,058 [run_pretraining.py:  558]:	worker_index: 3, step: 598, cost: 8.484621, mlm loss: 8.484621, speed: 1.102100 steps/s, speed: 8.816798 samples/s, speed: 4514.200575 tokens/s, learning rate: 5.970e-06, loss_scalings: 13421.773438, pp_loss: 8.758173
[INFO] 2021-07-12 18:41:29,058 [run_pretraining.py:  512]:	********exe.run_598******* 
[INFO] 2021-07-12 18:41:29,979 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:29,979 [run_pretraining.py:  534]:	loss/total_loss, 8.135784149169922, 599
[INFO] 2021-07-12 18:41:29,980 [run_pretraining.py:  535]:	loss/mlm_loss, 8.135784149169922, 599
[INFO] 2021-07-12 18:41:29,980 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.979999968985794e-06, 599
[INFO] 2021-07-12 18:41:29,980 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 599
[INFO] 2021-07-12 18:41:29,980 [run_pretraining.py:  558]:	worker_index: 3, step: 599, cost: 8.135784, mlm loss: 8.135784, speed: 1.085885 steps/s, speed: 8.687079 samples/s, speed: 4447.784268 tokens/s, learning rate: 5.980e-06, loss_scalings: 13421.773438, pp_loss: 8.494075
[INFO] 2021-07-12 18:41:29,980 [run_pretraining.py:  512]:	********exe.run_599******* 
[INFO] 2021-07-12 18:41:30,891 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:30,891 [run_pretraining.py:  534]:	loss/total_loss, 8.598016738891602, 600
[INFO] 2021-07-12 18:41:30,891 [run_pretraining.py:  535]:	loss/mlm_loss, 8.598016738891602, 600
[INFO] 2021-07-12 18:41:30,891 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.9899998632317875e-06, 600
[INFO] 2021-07-12 18:41:30,891 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 600
[INFO] 2021-07-12 18:41:30,892 [run_pretraining.py:  558]:	worker_index: 3, step: 600, cost: 8.598017, mlm loss: 8.598017, speed: 1.097556 steps/s, speed: 8.780451 samples/s, speed: 4495.590908 tokens/s, learning rate: 5.990e-06, loss_scalings: 13421.773438, pp_loss: 8.674969
[INFO] 2021-07-12 18:41:30,892 [run_pretraining.py:  512]:	********exe.run_600******* 
[INFO] 2021-07-12 18:41:31,805 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:31,806 [run_pretraining.py:  534]:	loss/total_loss, 8.595044136047363, 601
[INFO] 2021-07-12 18:41:31,806 [run_pretraining.py:  535]:	loss/mlm_loss, 8.595044136047363, 601
[INFO] 2021-07-12 18:41:31,806 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.999999757477781e-06, 601
[INFO] 2021-07-12 18:41:31,806 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 601
[INFO] 2021-07-12 18:41:31,806 [run_pretraining.py:  558]:	worker_index: 3, step: 601, cost: 8.595044, mlm loss: 8.595044, speed: 1.093938 steps/s, speed: 8.751502 samples/s, speed: 4480.769108 tokens/s, learning rate: 6.000e-06, loss_scalings: 13421.773438, pp_loss: 8.799360
[INFO] 2021-07-12 18:41:31,806 [run_pretraining.py:  512]:	********exe.run_601******* 
[INFO] 2021-07-12 18:41:32,717 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:32,718 [run_pretraining.py:  534]:	loss/total_loss, 8.468842506408691, 602
[INFO] 2021-07-12 18:41:32,718 [run_pretraining.py:  535]:	loss/mlm_loss, 8.468842506408691, 602
[INFO] 2021-07-12 18:41:32,718 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.010000106471125e-06, 602
[INFO] 2021-07-12 18:41:32,718 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 602
[INFO] 2021-07-12 18:41:32,718 [run_pretraining.py:  558]:	worker_index: 3, step: 602, cost: 8.468843, mlm loss: 8.468843, speed: 1.097348 steps/s, speed: 8.778786 samples/s, speed: 4494.738182 tokens/s, learning rate: 6.010e-06, loss_scalings: 13421.773438, pp_loss: 8.839305
[INFO] 2021-07-12 18:41:32,718 [run_pretraining.py:  512]:	********exe.run_602******* 
[INFO] 2021-07-12 18:41:33,634 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:33,635 [run_pretraining.py:  534]:	loss/total_loss, 8.680256843566895, 603
[INFO] 2021-07-12 18:41:33,635 [run_pretraining.py:  535]:	loss/mlm_loss, 8.680256843566895, 603
[INFO] 2021-07-12 18:41:33,635 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.0199995459697675e-06, 603
[INFO] 2021-07-12 18:41:33,635 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 603
[INFO] 2021-07-12 18:41:33,635 [run_pretraining.py:  558]:	worker_index: 3, step: 603, cost: 8.680257, mlm loss: 8.680257, speed: 1.091439 steps/s, speed: 8.731514 samples/s, speed: 4470.535275 tokens/s, learning rate: 6.020e-06, loss_scalings: 13421.773438, pp_loss: 8.608394
[INFO] 2021-07-12 18:41:33,635 [run_pretraining.py:  512]:	********exe.run_603******* 
[INFO] 2021-07-12 18:41:34,550 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:34,551 [run_pretraining.py:  534]:	loss/total_loss, 8.352411270141602, 604
[INFO] 2021-07-12 18:41:34,551 [run_pretraining.py:  535]:	loss/mlm_loss, 8.352411270141602, 604
[INFO] 2021-07-12 18:41:34,551 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.029999894963112e-06, 604
[INFO] 2021-07-12 18:41:34,551 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 604
[INFO] 2021-07-12 18:41:34,551 [run_pretraining.py:  558]:	worker_index: 3, step: 604, cost: 8.352411, mlm loss: 8.352411, speed: 1.092472 steps/s, speed: 8.739779 samples/s, speed: 4474.766781 tokens/s, learning rate: 6.030e-06, loss_scalings: 13421.773438, pp_loss: 8.692263
[INFO] 2021-07-12 18:41:34,551 [run_pretraining.py:  512]:	********exe.run_604******* 
[INFO] 2021-07-12 18:41:35,459 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:35,459 [run_pretraining.py:  534]:	loss/total_loss, 7.875276565551758, 605
[INFO] 2021-07-12 18:41:35,460 [run_pretraining.py:  535]:	loss/mlm_loss, 7.875276565551758, 605
[INFO] 2021-07-12 18:41:35,460 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.040000243956456e-06, 605
[INFO] 2021-07-12 18:41:35,460 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 605
[INFO] 2021-07-12 18:41:35,460 [run_pretraining.py:  558]:	worker_index: 3, step: 605, cost: 7.875277, mlm loss: 7.875277, speed: 1.101198 steps/s, speed: 8.809587 samples/s, speed: 4510.508721 tokens/s, learning rate: 6.040e-06, loss_scalings: 13421.773438, pp_loss: 8.365986
[INFO] 2021-07-12 18:41:35,460 [run_pretraining.py:  512]:	********exe.run_605******* 
[INFO] 2021-07-12 18:41:36,374 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:36,375 [run_pretraining.py:  534]:	loss/total_loss, 8.773065567016602, 606
[INFO] 2021-07-12 18:41:36,375 [run_pretraining.py:  535]:	loss/mlm_loss, 8.773065567016602, 606
[INFO] 2021-07-12 18:41:36,375 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.049999683455098e-06, 606
[INFO] 2021-07-12 18:41:36,375 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 606
[INFO] 2021-07-12 18:41:36,375 [run_pretraining.py:  558]:	worker_index: 3, step: 606, cost: 8.773066, mlm loss: 8.773066, speed: 1.093517 steps/s, speed: 8.748139 samples/s, speed: 4479.047177 tokens/s, learning rate: 6.050e-06, loss_scalings: 13421.773438, pp_loss: 7.986588
[INFO] 2021-07-12 18:41:36,375 [run_pretraining.py:  512]:	********exe.run_606******* 
[INFO] 2021-07-12 18:41:37,290 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:37,290 [run_pretraining.py:  534]:	loss/total_loss, 8.715971946716309, 607
[INFO] 2021-07-12 18:41:37,291 [run_pretraining.py:  535]:	loss/mlm_loss, 8.715971946716309, 607
[INFO] 2021-07-12 18:41:37,291 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.060000032448443e-06, 607
[INFO] 2021-07-12 18:41:37,291 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 607
[INFO] 2021-07-12 18:41:37,291 [run_pretraining.py:  558]:	worker_index: 3, step: 607, cost: 8.715972, mlm loss: 8.715972, speed: 1.092624 steps/s, speed: 8.740992 samples/s, speed: 4475.388092 tokens/s, learning rate: 6.060e-06, loss_scalings: 13421.773438, pp_loss: 8.442733
[INFO] 2021-07-12 18:41:37,291 [run_pretraining.py:  512]:	********exe.run_607******* 
[INFO] 2021-07-12 18:41:38,201 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:38,201 [run_pretraining.py:  534]:	loss/total_loss, 8.933465957641602, 608
[INFO] 2021-07-12 18:41:38,201 [run_pretraining.py:  535]:	loss/mlm_loss, 8.933465957641602, 608
[INFO] 2021-07-12 18:41:38,201 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.069999926694436e-06, 608
[INFO] 2021-07-12 18:41:38,201 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 608
[INFO] 2021-07-12 18:41:38,202 [run_pretraining.py:  558]:	worker_index: 3, step: 608, cost: 8.933466, mlm loss: 8.933466, speed: 1.098746 steps/s, speed: 8.789971 samples/s, speed: 4500.465292 tokens/s, learning rate: 6.070e-06, loss_scalings: 13421.773438, pp_loss: 8.854832
[INFO] 2021-07-12 18:41:38,202 [run_pretraining.py:  512]:	********exe.run_608******* 
[INFO] 2021-07-12 18:41:39,120 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:39,120 [run_pretraining.py:  534]:	loss/total_loss, 8.505834579467773, 609
[INFO] 2021-07-12 18:41:39,120 [run_pretraining.py:  535]:	loss/mlm_loss, 8.505834579467773, 609
[INFO] 2021-07-12 18:41:39,120 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.079999820940429e-06, 609
[INFO] 2021-07-12 18:41:39,121 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 609
[INFO] 2021-07-12 18:41:39,121 [run_pretraining.py:  558]:	worker_index: 3, step: 609, cost: 8.505835, mlm loss: 8.505835, speed: 1.088767 steps/s, speed: 8.710134 samples/s, speed: 4459.588548 tokens/s, learning rate: 6.080e-06, loss_scalings: 13421.773438, pp_loss: 8.608580
[INFO] 2021-07-12 18:41:39,121 [run_pretraining.py:  512]:	********exe.run_609******* 
[INFO] 2021-07-12 18:41:40,047 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:40,047 [run_pretraining.py:  534]:	loss/total_loss, 8.768412590026855, 610
[INFO] 2021-07-12 18:41:40,047 [run_pretraining.py:  535]:	loss/mlm_loss, 8.768412590026855, 610
[INFO] 2021-07-12 18:41:40,047 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.089999715186423e-06, 610
[INFO] 2021-07-12 18:41:40,047 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 610
[INFO] 2021-07-12 18:41:40,048 [run_pretraining.py:  558]:	worker_index: 3, step: 610, cost: 8.768413, mlm loss: 8.768413, speed: 1.079608 steps/s, speed: 8.636864 samples/s, speed: 4422.074294 tokens/s, learning rate: 6.090e-06, loss_scalings: 13421.773438, pp_loss: 8.480329
[INFO] 2021-07-12 18:41:40,048 [run_pretraining.py:  512]:	********exe.run_610******* 
[INFO] 2021-07-12 18:41:40,962 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:40,962 [run_pretraining.py:  534]:	loss/total_loss, 8.562307357788086, 611
[INFO] 2021-07-12 18:41:40,962 [run_pretraining.py:  535]:	loss/mlm_loss, 8.562307357788086, 611
[INFO] 2021-07-12 18:41:40,962 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.100000064179767e-06, 611
[INFO] 2021-07-12 18:41:40,963 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 611
[INFO] 2021-07-12 18:41:40,963 [run_pretraining.py:  558]:	worker_index: 3, step: 611, cost: 8.562307, mlm loss: 8.562307, speed: 1.093537 steps/s, speed: 8.748299 samples/s, speed: 4479.128921 tokens/s, learning rate: 6.100e-06, loss_scalings: 13421.773438, pp_loss: 8.697838
[INFO] 2021-07-12 18:41:40,963 [run_pretraining.py:  512]:	********exe.run_611******* 
[INFO] 2021-07-12 18:41:41,878 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:41,879 [run_pretraining.py:  534]:	loss/total_loss, 8.820895195007324, 612
[INFO] 2021-07-12 18:41:41,879 [run_pretraining.py:  535]:	loss/mlm_loss, 8.820895195007324, 612
[INFO] 2021-07-12 18:41:41,879 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.109999503678409e-06, 612
[INFO] 2021-07-12 18:41:41,879 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 612
[INFO] 2021-07-12 18:41:41,879 [run_pretraining.py:  558]:	worker_index: 3, step: 612, cost: 8.820895, mlm loss: 8.820895, speed: 1.091811 steps/s, speed: 8.734489 samples/s, speed: 4472.058580 tokens/s, learning rate: 6.110e-06, loss_scalings: 13421.773438, pp_loss: 8.588318
[INFO] 2021-07-12 18:41:41,879 [run_pretraining.py:  512]:	********exe.run_612******* 
[INFO] 2021-07-12 18:41:42,794 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:42,795 [run_pretraining.py:  534]:	loss/total_loss, 8.600994110107422, 613
[INFO] 2021-07-12 18:41:42,795 [run_pretraining.py:  535]:	loss/mlm_loss, 8.600994110107422, 613
[INFO] 2021-07-12 18:41:42,795 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.119999852671754e-06, 613
[INFO] 2021-07-12 18:41:42,795 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 613
[INFO] 2021-07-12 18:41:42,795 [run_pretraining.py:  558]:	worker_index: 3, step: 613, cost: 8.600994, mlm loss: 8.600994, speed: 1.092871 steps/s, speed: 8.742967 samples/s, speed: 4476.399109 tokens/s, learning rate: 6.120e-06, loss_scalings: 13421.773438, pp_loss: 8.600842
[INFO] 2021-07-12 18:41:42,795 [run_pretraining.py:  512]:	********exe.run_613******* 
[INFO] 2021-07-12 18:41:43,714 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:43,714 [run_pretraining.py:  534]:	loss/total_loss, 8.666439056396484, 614
[INFO] 2021-07-12 18:41:43,714 [run_pretraining.py:  535]:	loss/mlm_loss, 8.666439056396484, 614
[INFO] 2021-07-12 18:41:43,715 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.129999746917747e-06, 614
[INFO] 2021-07-12 18:41:43,715 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 614
[INFO] 2021-07-12 18:41:43,715 [run_pretraining.py:  558]:	worker_index: 3, step: 614, cost: 8.666439, mlm loss: 8.666439, speed: 1.087967 steps/s, speed: 8.703733 samples/s, speed: 4456.311392 tokens/s, learning rate: 6.130e-06, loss_scalings: 13421.773438, pp_loss: 8.690616
[INFO] 2021-07-12 18:41:43,715 [run_pretraining.py:  512]:	********exe.run_614******* 
[INFO] 2021-07-12 18:41:44,630 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:44,630 [run_pretraining.py:  534]:	loss/total_loss, 8.888434410095215, 615
[INFO] 2021-07-12 18:41:44,630 [run_pretraining.py:  535]:	loss/mlm_loss, 8.888434410095215, 615
[INFO] 2021-07-12 18:41:44,631 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.13999964116374e-06, 615
[INFO] 2021-07-12 18:41:44,631 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 615
[INFO] 2021-07-12 18:41:44,631 [run_pretraining.py:  558]:	worker_index: 3, step: 615, cost: 8.888434, mlm loss: 8.888434, speed: 1.092400 steps/s, speed: 8.739201 samples/s, speed: 4474.470758 tokens/s, learning rate: 6.140e-06, loss_scalings: 13421.773438, pp_loss: 8.772351
[INFO] 2021-07-12 18:41:44,631 [run_pretraining.py:  512]:	********exe.run_615******* 
[INFO] 2021-07-12 18:42:10,740 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:10,740 [run_pretraining.py:  534]:	loss/total_loss, 8.236599922180176, 616
[INFO] 2021-07-12 18:42:10,740 [run_pretraining.py:  535]:	loss/mlm_loss, 8.236599922180176, 616
[INFO] 2021-07-12 18:42:10,740 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.1499999901570845e-06, 616
[INFO] 2021-07-12 18:42:10,740 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 616
[INFO] 2021-07-12 18:42:10,740 [run_pretraining.py:  558]:	worker_index: 3, step: 616, cost: 8.236600, mlm loss: 8.236600, speed: 0.038301 steps/s, speed: 0.306406 samples/s, speed: 156.879885 tokens/s, learning rate: 6.150e-06, loss_scalings: 13421.773438, pp_loss: 8.651062
[INFO] 2021-07-12 18:42:10,741 [run_pretraining.py:  512]:	********exe.run_616******* 
[INFO] 2021-07-12 18:42:11,651 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:11,652 [run_pretraining.py:  534]:	loss/total_loss, 10.682297706604004, 617
[INFO] 2021-07-12 18:42:11,652 [run_pretraining.py:  535]:	loss/mlm_loss, 10.682297706604004, 617
[INFO] 2021-07-12 18:42:11,652 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.159999884403078e-06, 617
[INFO] 2021-07-12 18:42:11,652 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 617
[INFO] 2021-07-12 18:42:11,652 [run_pretraining.py:  558]:	worker_index: 3, step: 617, cost: 10.682298, mlm loss: 10.682298, speed: 1.098000 steps/s, speed: 8.783998 samples/s, speed: 4497.406821 tokens/s, learning rate: 6.160e-06, loss_scalings: 13421.773438, pp_loss: 8.230145
[INFO] 2021-07-12 18:42:11,652 [run_pretraining.py:  512]:	********exe.run_617******* 
[INFO] 2021-07-12 18:42:12,569 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:12,569 [run_pretraining.py:  534]:	loss/total_loss, 8.822623252868652, 618
[INFO] 2021-07-12 18:42:12,569 [run_pretraining.py:  535]:	loss/mlm_loss, 8.822623252868652, 618
[INFO] 2021-07-12 18:42:12,569 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.169999778649071e-06, 618
[INFO] 2021-07-12 18:42:12,569 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 618
[INFO] 2021-07-12 18:42:12,569 [run_pretraining.py:  558]:	worker_index: 3, step: 618, cost: 8.822623, mlm loss: 8.822623, speed: 1.090628 steps/s, speed: 8.725028 samples/s, speed: 4467.214139 tokens/s, learning rate: 6.170e-06, loss_scalings: 13421.773438, pp_loss: 8.705073
[INFO] 2021-07-12 18:42:12,570 [run_pretraining.py:  512]:	********exe.run_618******* 
[INFO] 2021-07-12 18:42:13,478 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:13,478 [run_pretraining.py:  534]:	loss/total_loss, 8.847317695617676, 619
[INFO] 2021-07-12 18:42:13,478 [run_pretraining.py:  535]:	loss/mlm_loss, 8.847317695617676, 619
[INFO] 2021-07-12 18:42:13,478 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.179999672895065e-06, 619
[INFO] 2021-07-12 18:42:13,478 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 619
[INFO] 2021-07-12 18:42:13,478 [run_pretraining.py:  558]:	worker_index: 3, step: 619, cost: 8.847318, mlm loss: 8.847318, speed: 1.100934 steps/s, speed: 8.807469 samples/s, speed: 4509.424239 tokens/s, learning rate: 6.180e-06, loss_scalings: 13421.773438, pp_loss: 8.657828
[INFO] 2021-07-12 18:42:13,479 [run_pretraining.py:  512]:	********exe.run_619******* 
[INFO] 2021-07-12 18:42:14,392 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:14,392 [run_pretraining.py:  534]:	loss/total_loss, 8.353362083435059, 620
[INFO] 2021-07-12 18:42:14,392 [run_pretraining.py:  535]:	loss/mlm_loss, 8.353362083435059, 620
[INFO] 2021-07-12 18:42:14,392 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.190000021888409e-06, 620
[INFO] 2021-07-12 18:42:14,392 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 620
[INFO] 2021-07-12 18:42:14,393 [run_pretraining.py:  558]:	worker_index: 3, step: 620, cost: 8.353362, mlm loss: 8.353362, speed: 1.094766 steps/s, speed: 8.758131 samples/s, speed: 4484.163106 tokens/s, learning rate: 6.190e-06, loss_scalings: 13421.773438, pp_loss: 8.738473
[INFO] 2021-07-12 18:42:14,393 [run_pretraining.py:  512]:	********exe.run_620******* 
[INFO] 2021-07-12 18:42:15,300 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:15,301 [run_pretraining.py:  534]:	loss/total_loss, 9.064474105834961, 621
[INFO] 2021-07-12 18:42:15,301 [run_pretraining.py:  535]:	loss/mlm_loss, 9.064474105834961, 621
[INFO] 2021-07-12 18:42:15,301 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.199999916134402e-06, 621
[INFO] 2021-07-12 18:42:15,301 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 621
[INFO] 2021-07-12 18:42:15,301 [run_pretraining.py:  558]:	worker_index: 3, step: 621, cost: 9.064474, mlm loss: 9.064474, speed: 1.101612 steps/s, speed: 8.812894 samples/s, speed: 4512.201602 tokens/s, learning rate: 6.200e-06, loss_scalings: 13421.773438, pp_loss: 8.760723
[INFO] 2021-07-12 18:42:15,301 [run_pretraining.py:  512]:	********exe.run_621******* 
[INFO] 2021-07-12 18:42:16,215 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:16,216 [run_pretraining.py:  534]:	loss/total_loss, 8.608933448791504, 622
[INFO] 2021-07-12 18:42:16,216 [run_pretraining.py:  535]:	loss/mlm_loss, 8.608933448791504, 622
[INFO] 2021-07-12 18:42:16,216 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.2099998103803955e-06, 622
[INFO] 2021-07-12 18:42:16,216 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 622
[INFO] 2021-07-12 18:42:16,216 [run_pretraining.py:  558]:	worker_index: 3, step: 622, cost: 8.608933, mlm loss: 8.608933, speed: 1.093676 steps/s, speed: 8.749412 samples/s, speed: 4479.698879 tokens/s, learning rate: 6.210e-06, loss_scalings: 13421.773438, pp_loss: 8.555640
[INFO] 2021-07-12 18:42:16,216 [run_pretraining.py:  512]:	********exe.run_622******* 
[INFO] 2021-07-12 18:42:17,136 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:17,136 [run_pretraining.py:  534]:	loss/total_loss, 8.843411445617676, 623
[INFO] 2021-07-12 18:42:17,136 [run_pretraining.py:  535]:	loss/mlm_loss, 8.843411445617676, 623
[INFO] 2021-07-12 18:42:17,136 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.219999704626389e-06, 623
[INFO] 2021-07-12 18:42:17,136 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 623
[INFO] 2021-07-12 18:42:17,137 [run_pretraining.py:  558]:	worker_index: 3, step: 623, cost: 8.843411, mlm loss: 8.843411, speed: 1.086969 steps/s, speed: 8.695751 samples/s, speed: 4452.224311 tokens/s, learning rate: 6.220e-06, loss_scalings: 13421.773438, pp_loss: 8.747183
[INFO] 2021-07-12 18:42:17,137 [run_pretraining.py:  512]:	********exe.run_623******* 
[INFO] 2021-07-12 18:42:18,054 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:18,054 [run_pretraining.py:  534]:	loss/total_loss, 8.521697998046875, 624
[INFO] 2021-07-12 18:42:18,055 [run_pretraining.py:  535]:	loss/mlm_loss, 8.521697998046875, 624
[INFO] 2021-07-12 18:42:18,055 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.230000053619733e-06, 624
[INFO] 2021-07-12 18:42:18,055 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 624
[INFO] 2021-07-12 18:42:18,055 [run_pretraining.py:  558]:	worker_index: 3, step: 624, cost: 8.521698, mlm loss: 8.521698, speed: 1.089775 steps/s, speed: 8.718200 samples/s, speed: 4463.718161 tokens/s, learning rate: 6.230e-06, loss_scalings: 13421.773438, pp_loss: 8.525933
[INFO] 2021-07-12 18:42:18,055 [run_pretraining.py:  512]:	********exe.run_624******* 
[INFO] 2021-07-12 18:42:18,964 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:18,964 [run_pretraining.py:  534]:	loss/total_loss, 8.911147117614746, 625
[INFO] 2021-07-12 18:42:18,965 [run_pretraining.py:  535]:	loss/mlm_loss, 8.911147117614746, 625
[INFO] 2021-07-12 18:42:18,965 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.2399994931183755e-06, 625
[INFO] 2021-07-12 18:42:18,965 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 625
[INFO] 2021-07-12 18:42:18,965 [run_pretraining.py:  558]:	worker_index: 3, step: 625, cost: 8.911147, mlm loss: 8.911147, speed: 1.099773 steps/s, speed: 8.798186 samples/s, speed: 4504.670992 tokens/s, learning rate: 6.240e-06, loss_scalings: 13421.773438, pp_loss: 8.703641
[INFO] 2021-07-12 18:42:18,965 [run_pretraining.py:  512]:	********exe.run_625******* 
[INFO] 2021-07-12 18:42:19,878 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:19,878 [run_pretraining.py:  534]:	loss/total_loss, 8.463780403137207, 626
[INFO] 2021-07-12 18:42:19,878 [run_pretraining.py:  535]:	loss/mlm_loss, 8.463780403137207, 626
[INFO] 2021-07-12 18:42:19,878 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.24999984211172e-06, 626
[INFO] 2021-07-12 18:42:19,878 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 626
[INFO] 2021-07-12 18:42:19,879 [run_pretraining.py:  558]:	worker_index: 3, step: 626, cost: 8.463780, mlm loss: 8.463780, speed: 1.095137 steps/s, speed: 8.761095 samples/s, speed: 4485.680488 tokens/s, learning rate: 6.250e-06, loss_scalings: 13421.773438, pp_loss: 8.605795
[INFO] 2021-07-12 18:42:19,879 [run_pretraining.py:  512]:	********exe.run_626******* 
[INFO] 2021-07-12 18:42:20,790 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:20,790 [run_pretraining.py:  534]:	loss/total_loss, 8.687102317810059, 627
[INFO] 2021-07-12 18:42:20,790 [run_pretraining.py:  535]:	loss/mlm_loss, 8.687102317810059, 627
[INFO] 2021-07-12 18:42:20,791 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.260000191105064e-06, 627
[INFO] 2021-07-12 18:42:20,791 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 627
[INFO] 2021-07-12 18:42:20,791 [run_pretraining.py:  558]:	worker_index: 3, step: 627, cost: 8.687102, mlm loss: 8.687102, speed: 1.097089 steps/s, speed: 8.776712 samples/s, speed: 4493.676550 tokens/s, learning rate: 6.260e-06, loss_scalings: 13421.773438, pp_loss: 8.446830
[INFO] 2021-07-12 18:42:20,791 [run_pretraining.py:  512]:	********exe.run_627******* 
[INFO] 2021-07-12 18:42:21,702 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:21,702 [run_pretraining.py:  534]:	loss/total_loss, 8.431005477905273, 628
[INFO] 2021-07-12 18:42:21,703 [run_pretraining.py:  535]:	loss/mlm_loss, 8.431005477905273, 628
[INFO] 2021-07-12 18:42:21,703 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.270000085351057e-06, 628
[INFO] 2021-07-12 18:42:21,703 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 628
[INFO] 2021-07-12 18:42:21,703 [run_pretraining.py:  558]:	worker_index: 3, step: 628, cost: 8.431005, mlm loss: 8.431005, speed: 1.097116 steps/s, speed: 8.776928 samples/s, speed: 4493.787039 tokens/s, learning rate: 6.270e-06, loss_scalings: 13421.773438, pp_loss: 8.726614
[INFO] 2021-07-12 18:42:21,703 [run_pretraining.py:  512]:	********exe.run_628******* 
[INFO] 2021-07-12 18:42:22,623 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:22,623 [run_pretraining.py:  534]:	loss/total_loss, 7.850265979766846, 629
[INFO] 2021-07-12 18:42:22,623 [run_pretraining.py:  535]:	loss/mlm_loss, 7.850265979766846, 629
[INFO] 2021-07-12 18:42:22,623 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.2799995248497e-06, 629
[INFO] 2021-07-12 18:42:22,624 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 629
[INFO] 2021-07-12 18:42:22,624 [run_pretraining.py:  558]:	worker_index: 3, step: 629, cost: 7.850266, mlm loss: 7.850266, speed: 1.086703 steps/s, speed: 8.693622 samples/s, speed: 4451.134228 tokens/s, learning rate: 6.280e-06, loss_scalings: 13421.773438, pp_loss: 8.395812
[INFO] 2021-07-12 18:42:22,624 [run_pretraining.py:  512]:	********exe.run_629******* 
[INFO] 2021-07-12 18:42:23,536 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:23,537 [run_pretraining.py:  534]:	loss/total_loss, 8.556440353393555, 630
[INFO] 2021-07-12 18:42:23,537 [run_pretraining.py:  535]:	loss/mlm_loss, 8.556440353393555, 630
[INFO] 2021-07-12 18:42:23,537 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.289999873843044e-06, 630
[INFO] 2021-07-12 18:42:23,537 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 630
[INFO] 2021-07-12 18:42:23,537 [run_pretraining.py:  558]:	worker_index: 3, step: 630, cost: 8.556440, mlm loss: 8.556440, speed: 1.095504 steps/s, speed: 8.764035 samples/s, speed: 4487.186005 tokens/s, learning rate: 6.290e-06, loss_scalings: 13421.773438, pp_loss: 8.586809
[INFO] 2021-07-12 18:42:23,537 [run_pretraining.py:  512]:	********exe.run_630******* 
[INFO] 2021-07-12 18:42:24,457 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:24,457 [run_pretraining.py:  534]:	loss/total_loss, 8.47807788848877, 631
[INFO] 2021-07-12 18:42:24,457 [run_pretraining.py:  535]:	loss/mlm_loss, 8.47807788848877, 631
[INFO] 2021-07-12 18:42:24,457 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.299999768089037e-06, 631
[INFO] 2021-07-12 18:42:24,457 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 631
[INFO] 2021-07-12 18:42:24,457 [run_pretraining.py:  558]:	worker_index: 3, step: 631, cost: 8.478078, mlm loss: 8.478078, speed: 1.087196 steps/s, speed: 8.697570 samples/s, speed: 4453.155630 tokens/s, learning rate: 6.300e-06, loss_scalings: 13421.773438, pp_loss: 7.933859
[INFO] 2021-07-12 18:42:24,458 [run_pretraining.py:  512]:	********exe.run_631******* 
[INFO] 2021-07-12 18:42:25,378 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:25,379 [run_pretraining.py:  534]:	loss/total_loss, 8.926162719726562, 632
[INFO] 2021-07-12 18:42:25,379 [run_pretraining.py:  535]:	loss/mlm_loss, 8.926162719726562, 632
[INFO] 2021-07-12 18:42:25,379 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.310000117082382e-06, 632
[INFO] 2021-07-12 18:42:25,379 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 632
[INFO] 2021-07-12 18:42:25,379 [run_pretraining.py:  558]:	worker_index: 3, step: 632, cost: 8.926163, mlm loss: 8.926163, speed: 1.085969 steps/s, speed: 8.687751 samples/s, speed: 4448.128596 tokens/s, learning rate: 6.310e-06, loss_scalings: 13421.773438, pp_loss: 8.750499
[INFO] 2021-07-12 18:42:25,379 [run_pretraining.py:  512]:	********exe.run_632******* 
[INFO] 2021-07-12 18:42:26,299 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:26,300 [run_pretraining.py:  534]:	loss/total_loss, 5.392142295837402, 633
[INFO] 2021-07-12 18:42:26,300 [run_pretraining.py:  535]:	loss/mlm_loss, 5.392142295837402, 633
[INFO] 2021-07-12 18:42:26,300 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.319999556581024e-06, 633
[INFO] 2021-07-12 18:42:26,300 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 633
[INFO] 2021-07-12 18:42:26,300 [run_pretraining.py:  558]:	worker_index: 3, step: 633, cost: 5.392142, mlm loss: 5.392142, speed: 1.086680 steps/s, speed: 8.693441 samples/s, speed: 4451.041970 tokens/s, learning rate: 6.320e-06, loss_scalings: 13421.773438, pp_loss: 7.870919
[INFO] 2021-07-12 18:42:26,300 [run_pretraining.py:  512]:	********exe.run_633******* 
[INFO] 2021-07-12 18:42:27,220 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:27,220 [run_pretraining.py:  534]:	loss/total_loss, 4.516101837158203, 634
[INFO] 2021-07-12 18:42:27,220 [run_pretraining.py:  535]:	loss/mlm_loss, 4.516101837158203, 634
[INFO] 2021-07-12 18:42:27,220 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.329999905574368e-06, 634
[INFO] 2021-07-12 18:42:27,221 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 634
[INFO] 2021-07-12 18:42:27,221 [run_pretraining.py:  558]:	worker_index: 3, step: 634, cost: 4.516102, mlm loss: 4.516102, speed: 1.086785 steps/s, speed: 8.694277 samples/s, speed: 4451.469847 tokens/s, learning rate: 6.330e-06, loss_scalings: 13421.773438, pp_loss: 7.694064
[INFO] 2021-07-12 18:42:27,221 [run_pretraining.py:  512]:	********exe.run_634******* 
[INFO] 2021-07-12 18:42:28,139 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:28,139 [run_pretraining.py:  534]:	loss/total_loss, 8.923437118530273, 635
[INFO] 2021-07-12 18:42:28,140 [run_pretraining.py:  535]:	loss/mlm_loss, 8.923437118530273, 635
[INFO] 2021-07-12 18:42:28,140 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.339999799820362e-06, 635
[INFO] 2021-07-12 18:42:28,140 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 635
[INFO] 2021-07-12 18:42:28,140 [run_pretraining.py:  558]:	worker_index: 3, step: 635, cost: 8.923437, mlm loss: 8.923437, speed: 1.088722 steps/s, speed: 8.709777 samples/s, speed: 4459.405650 tokens/s, learning rate: 6.340e-06, loss_scalings: 13421.773438, pp_loss: 7.806270
[INFO] 2021-07-12 18:42:28,140 [run_pretraining.py:  512]:	********exe.run_635******* 
[INFO] 2021-07-12 18:42:29,093 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:29,094 [run_pretraining.py:  534]:	loss/total_loss, 8.281621932983398, 636
[INFO] 2021-07-12 18:42:29,094 [run_pretraining.py:  535]:	loss/mlm_loss, 8.281621932983398, 636
[INFO] 2021-07-12 18:42:29,094 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.350000148813706e-06, 636
[INFO] 2021-07-12 18:42:29,094 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 636
[INFO] 2021-07-12 18:42:29,094 [run_pretraining.py:  558]:	worker_index: 3, step: 636, cost: 8.281622, mlm loss: 8.281622, speed: 1.048803 steps/s, speed: 8.390422 samples/s, speed: 4295.896284 tokens/s, learning rate: 6.350e-06, loss_scalings: 13421.773438, pp_loss: 7.906318
[INFO] 2021-07-12 18:42:29,094 [run_pretraining.py:  512]:	********exe.run_636******* 
[INFO] 2021-07-12 18:42:30,006 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:30,007 [run_pretraining.py:  534]:	loss/total_loss, 8.783665657043457, 637
[INFO] 2021-07-12 18:42:30,009 [run_pretraining.py:  535]:	loss/mlm_loss, 8.783665657043457, 637
[INFO] 2021-07-12 18:42:30,010 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.360000043059699e-06, 637
[INFO] 2021-07-12 18:42:30,011 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 637
[INFO] 2021-07-12 18:42:30,011 [run_pretraining.py:  558]:	worker_index: 3, step: 637, cost: 8.783666, mlm loss: 8.783666, speed: 1.095254 steps/s, speed: 8.762035 samples/s, speed: 4486.161909 tokens/s, learning rate: 6.360e-06, loss_scalings: 13421.773438, pp_loss: 8.877426
[INFO] 2021-07-12 18:42:30,011 [run_pretraining.py:  512]:	********exe.run_637******* 
[INFO] 2021-07-12 18:42:30,937 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:30,938 [run_pretraining.py:  534]:	loss/total_loss, 8.944732666015625, 638
[INFO] 2021-07-12 18:42:30,938 [run_pretraining.py:  535]:	loss/mlm_loss, 8.944732666015625, 638
[INFO] 2021-07-12 18:42:30,938 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.369999482558342e-06, 638
[INFO] 2021-07-12 18:42:30,938 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 638
[INFO] 2021-07-12 18:42:30,938 [run_pretraining.py:  558]:	worker_index: 3, step: 638, cost: 8.944733, mlm loss: 8.944733, speed: 1.078802 steps/s, speed: 8.630415 samples/s, speed: 4418.772463 tokens/s, learning rate: 6.370e-06, loss_scalings: 13421.773438, pp_loss: 8.704867
[INFO] 2021-07-12 18:42:30,938 [run_pretraining.py:  512]:	********exe.run_638******* 
[INFO] 2021-07-12 18:42:31,845 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:31,845 [run_pretraining.py:  534]:	loss/total_loss, 8.758200645446777, 639
[INFO] 2021-07-12 18:42:31,845 [run_pretraining.py:  535]:	loss/mlm_loss, 8.758200645446777, 639
[INFO] 2021-07-12 18:42:31,846 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.379999831551686e-06, 639
[INFO] 2021-07-12 18:42:31,846 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 639
[INFO] 2021-07-12 18:42:31,846 [run_pretraining.py:  558]:	worker_index: 3, step: 639, cost: 8.758201, mlm loss: 8.758201, speed: 1.102815 steps/s, speed: 8.822524 samples/s, speed: 4517.132284 tokens/s, learning rate: 6.380e-06, loss_scalings: 13421.773438, pp_loss: 8.753252
[INFO] 2021-07-12 18:42:31,846 [run_pretraining.py:  512]:	********exe.run_639******* 
[INFO] 2021-07-12 18:42:32,832 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:32,833 [run_pretraining.py:  534]:	loss/total_loss, 8.938770294189453, 640
[INFO] 2021-07-12 18:42:32,833 [run_pretraining.py:  535]:	loss/mlm_loss, 8.938770294189453, 640
[INFO] 2021-07-12 18:42:32,833 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.39000018054503e-06, 640
[INFO] 2021-07-12 18:42:32,833 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 640
[INFO] 2021-07-12 18:42:32,833 [run_pretraining.py:  558]:	worker_index: 3, step: 640, cost: 8.938770, mlm loss: 8.938770, speed: 1.013532 steps/s, speed: 8.108253 samples/s, speed: 4151.425531 tokens/s, learning rate: 6.390e-06, loss_scalings: 13421.773438, pp_loss: 8.779005
[INFO] 2021-07-12 18:42:32,833 [run_pretraining.py:  512]:	********exe.run_640******* 
[INFO] 2021-07-12 18:42:33,739 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:33,740 [run_pretraining.py:  534]:	loss/total_loss, 9.144659996032715, 641
[INFO] 2021-07-12 18:42:33,740 [run_pretraining.py:  535]:	loss/mlm_loss, 9.144659996032715, 641
[INFO] 2021-07-12 18:42:33,740 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.4000000747910235e-06, 641
[INFO] 2021-07-12 18:42:33,740 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 641
[INFO] 2021-07-12 18:42:33,740 [run_pretraining.py:  558]:	worker_index: 3, step: 641, cost: 9.144660, mlm loss: 9.144660, speed: 1.103397 steps/s, speed: 8.827180 samples/s, speed: 4519.516062 tokens/s, learning rate: 6.400e-06, loss_scalings: 13421.773438, pp_loss: 8.664278
[INFO] 2021-07-12 18:42:33,740 [run_pretraining.py:  512]:	********exe.run_641******* 
[INFO] 2021-07-12 18:42:34,648 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:34,649 [run_pretraining.py:  534]:	loss/total_loss, 8.679619789123535, 642
[INFO] 2021-07-12 18:42:34,649 [run_pretraining.py:  535]:	loss/mlm_loss, 8.679619789123535, 642
[INFO] 2021-07-12 18:42:34,649 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.409999514289666e-06, 642
[INFO] 2021-07-12 18:42:34,649 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 642
[INFO] 2021-07-12 18:42:34,649 [run_pretraining.py:  558]:	worker_index: 3, step: 642, cost: 8.679620, mlm loss: 8.679620, speed: 1.100555 steps/s, speed: 8.804437 samples/s, speed: 4507.871829 tokens/s, learning rate: 6.410e-06, loss_scalings: 13421.773438, pp_loss: 8.607861
[INFO] 2021-07-12 18:42:34,649 [run_pretraining.py:  512]:	********exe.run_642******* 
[INFO] 2021-07-12 18:42:35,555 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:35,556 [run_pretraining.py:  534]:	loss/total_loss, 9.007216453552246, 643
[INFO] 2021-07-12 18:42:35,556 [run_pretraining.py:  535]:	loss/mlm_loss, 9.007216453552246, 643
[INFO] 2021-07-12 18:42:35,556 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.41999986328301e-06, 643
[INFO] 2021-07-12 18:42:35,556 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 643
[INFO] 2021-07-12 18:42:35,556 [run_pretraining.py:  558]:	worker_index: 3, step: 643, cost: 9.007216, mlm loss: 9.007216, speed: 1.103416 steps/s, speed: 8.827328 samples/s, speed: 4519.592156 tokens/s, learning rate: 6.420e-06, loss_scalings: 13421.773438, pp_loss: 8.503173
[INFO] 2021-07-12 18:42:35,556 [run_pretraining.py:  512]:	********exe.run_643******* 
[INFO] 2021-07-12 18:42:36,468 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:36,468 [run_pretraining.py:  534]:	loss/total_loss, 8.514321327209473, 644
[INFO] 2021-07-12 18:42:36,468 [run_pretraining.py:  535]:	loss/mlm_loss, 8.514321327209473, 644
[INFO] 2021-07-12 18:42:36,469 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.4299997575290035e-06, 644
[INFO] 2021-07-12 18:42:36,469 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 644
[INFO] 2021-07-12 18:42:36,469 [run_pretraining.py:  558]:	worker_index: 3, step: 644, cost: 8.514321, mlm loss: 8.514321, speed: 1.096535 steps/s, speed: 8.772281 samples/s, speed: 4491.408008 tokens/s, learning rate: 6.430e-06, loss_scalings: 13421.773438, pp_loss: 8.596381
[INFO] 2021-07-12 18:42:36,469 [run_pretraining.py:  512]:	********exe.run_644******* 
[INFO] 2021-07-12 18:42:37,526 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:37,526 [run_pretraining.py:  534]:	loss/total_loss, 8.613433837890625, 645
[INFO] 2021-07-12 18:42:37,526 [run_pretraining.py:  535]:	loss/mlm_loss, 8.613433837890625, 645
[INFO] 2021-07-12 18:42:37,526 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.440000106522348e-06, 645
[INFO] 2021-07-12 18:42:37,526 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 645
[INFO] 2021-07-12 18:42:37,526 [run_pretraining.py:  558]:	worker_index: 3, step: 645, cost: 8.613434, mlm loss: 8.613434, speed: 0.945882 steps/s, speed: 7.567060 samples/s, speed: 3874.334657 tokens/s, learning rate: 6.440e-06, loss_scalings: 13421.773438, pp_loss: 8.802325
[INFO] 2021-07-12 18:42:37,527 [run_pretraining.py:  512]:	********exe.run_645******* 
[INFO] 2021-07-12 18:42:38,606 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:38,607 [run_pretraining.py:  534]:	loss/total_loss, 8.809319496154785, 646
[INFO] 2021-07-12 18:42:38,607 [run_pretraining.py:  535]:	loss/mlm_loss, 8.809319496154785, 646
[INFO] 2021-07-12 18:42:38,607 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.44999954602099e-06, 646
[INFO] 2021-07-12 18:42:38,607 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 646
[INFO] 2021-07-12 18:42:38,607 [run_pretraining.py:  558]:	worker_index: 3, step: 646, cost: 8.809319, mlm loss: 8.809319, speed: 0.926075 steps/s, speed: 7.408599 samples/s, speed: 3793.202473 tokens/s, learning rate: 6.450e-06, loss_scalings: 13421.773438, pp_loss: 8.743988
[INFO] 2021-07-12 18:42:38,607 [run_pretraining.py:  512]:	********exe.run_646******* 
[INFO] 2021-07-12 18:42:39,731 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:39,731 [run_pretraining.py:  534]:	loss/total_loss, 8.700352668762207, 647
[INFO] 2021-07-12 18:42:39,732 [run_pretraining.py:  535]:	loss/mlm_loss, 8.700352668762207, 647
[INFO] 2021-07-12 18:42:39,732 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.459999440266984e-06, 647
[INFO] 2021-07-12 18:42:39,732 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 647
[INFO] 2021-07-12 18:42:39,732 [run_pretraining.py:  558]:	worker_index: 3, step: 647, cost: 8.700353, mlm loss: 8.700353, speed: 0.889540 steps/s, speed: 7.116322 samples/s, speed: 3643.556737 tokens/s, learning rate: 6.460e-06, loss_scalings: 13421.773438, pp_loss: 8.867625
[INFO] 2021-07-12 18:42:39,732 [run_pretraining.py:  512]:	********exe.run_647******* 
[INFO] 2021-07-12 18:42:40,779 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:40,779 [run_pretraining.py:  534]:	loss/total_loss, 8.636343955993652, 648
[INFO] 2021-07-12 18:42:40,779 [run_pretraining.py:  535]:	loss/mlm_loss, 8.636343955993652, 648
[INFO] 2021-07-12 18:42:40,780 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.469999789260328e-06, 648
[INFO] 2021-07-12 18:42:40,780 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 648
[INFO] 2021-07-12 18:42:40,780 [run_pretraining.py:  558]:	worker_index: 3, step: 648, cost: 8.636344, mlm loss: 8.636344, speed: 0.954872 steps/s, speed: 7.638976 samples/s, speed: 3911.155800 tokens/s, learning rate: 6.470e-06, loss_scalings: 13421.773438, pp_loss: 8.732524
[INFO] 2021-07-12 18:42:40,780 [run_pretraining.py:  512]:	********exe.run_648******* 
[INFO] 2021-07-12 18:42:41,835 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:41,835 [run_pretraining.py:  534]:	loss/total_loss, 8.623685836791992, 649
[INFO] 2021-07-12 18:42:41,836 [run_pretraining.py:  535]:	loss/mlm_loss, 8.623685836791992, 649
[INFO] 2021-07-12 18:42:41,836 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.480000138253672e-06, 649
[INFO] 2021-07-12 18:42:41,836 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 649
[INFO] 2021-07-12 18:42:41,836 [run_pretraining.py:  558]:	worker_index: 3, step: 649, cost: 8.623686, mlm loss: 8.623686, speed: 0.947446 steps/s, speed: 7.579570 samples/s, speed: 3880.740017 tokens/s, learning rate: 6.480e-06, loss_scalings: 13421.773438, pp_loss: 8.697994
[INFO] 2021-07-12 18:42:41,836 [run_pretraining.py:  512]:	********exe.run_649******* 
[INFO] 2021-07-12 18:42:42,762 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:42,763 [run_pretraining.py:  534]:	loss/total_loss, 8.481512069702148, 650
[INFO] 2021-07-12 18:42:42,763 [run_pretraining.py:  535]:	loss/mlm_loss, 8.481512069702148, 650
[INFO] 2021-07-12 18:42:42,763 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.490000032499665e-06, 650
[INFO] 2021-07-12 18:42:42,763 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 650
[INFO] 2021-07-12 18:42:42,763 [run_pretraining.py:  558]:	worker_index: 3, step: 650, cost: 8.481512, mlm loss: 8.481512, speed: 1.078981 steps/s, speed: 8.631849 samples/s, speed: 4419.506788 tokens/s, learning rate: 6.490e-06, loss_scalings: 13421.773438, pp_loss: 8.594921
[INFO] 2021-07-12 18:42:42,763 [run_pretraining.py:  512]:	********exe.run_650******* 
[INFO] 2021-07-12 18:42:43,670 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:43,670 [run_pretraining.py:  534]:	loss/total_loss, 8.807061195373535, 651
[INFO] 2021-07-12 18:42:43,670 [run_pretraining.py:  535]:	loss/mlm_loss, 8.807061195373535, 651
[INFO] 2021-07-12 18:42:43,670 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.499999471998308e-06, 651
[INFO] 2021-07-12 18:42:43,671 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 651
[INFO] 2021-07-12 18:42:43,671 [run_pretraining.py:  558]:	worker_index: 3, step: 651, cost: 8.807061, mlm loss: 8.807061, speed: 1.102940 steps/s, speed: 8.823522 samples/s, speed: 4517.643051 tokens/s, learning rate: 6.500e-06, loss_scalings: 13421.773438, pp_loss: 8.957858
[INFO] 2021-07-12 18:42:43,671 [run_pretraining.py:  512]:	********exe.run_651******* 
[INFO] 2021-07-12 18:42:44,583 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:44,583 [run_pretraining.py:  534]:	loss/total_loss, 8.831259727478027, 652
[INFO] 2021-07-12 18:42:44,583 [run_pretraining.py:  535]:	loss/mlm_loss, 8.831259727478027, 652
[INFO] 2021-07-12 18:42:44,583 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.509999820991652e-06, 652
[INFO] 2021-07-12 18:42:44,583 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 652
[INFO] 2021-07-12 18:42:44,584 [run_pretraining.py:  558]:	worker_index: 3, step: 652, cost: 8.831260, mlm loss: 8.831260, speed: 1.096208 steps/s, speed: 8.769668 samples/s, speed: 4490.069809 tokens/s, learning rate: 6.510e-06, loss_scalings: 13421.773438, pp_loss: 8.648765
[INFO] 2021-07-12 18:42:44,584 [run_pretraining.py:  512]:	********exe.run_652******* 
[INFO] 2021-07-12 18:42:45,492 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:45,493 [run_pretraining.py:  534]:	loss/total_loss, 8.601181030273438, 653
[INFO] 2021-07-12 18:42:45,493 [run_pretraining.py:  535]:	loss/mlm_loss, 8.601181030273438, 653
[INFO] 2021-07-12 18:42:45,493 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.5199997152376454e-06, 653
[INFO] 2021-07-12 18:42:45,493 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 653
[INFO] 2021-07-12 18:42:45,493 [run_pretraining.py:  558]:	worker_index: 3, step: 653, cost: 8.601181, mlm loss: 8.601181, speed: 1.100500 steps/s, speed: 8.804001 samples/s, speed: 4507.648284 tokens/s, learning rate: 6.520e-06, loss_scalings: 13421.773438, pp_loss: 8.534393
[INFO] 2021-07-12 18:42:45,493 [run_pretraining.py:  512]:	********exe.run_653******* 
[INFO] 2021-07-12 18:42:46,399 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:46,399 [run_pretraining.py:  534]:	loss/total_loss, 8.633727073669434, 654
[INFO] 2021-07-12 18:42:46,399 [run_pretraining.py:  535]:	loss/mlm_loss, 8.633727073669434, 654
[INFO] 2021-07-12 18:42:46,400 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.53000006423099e-06, 654
[INFO] 2021-07-12 18:42:46,400 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 654
[INFO] 2021-07-12 18:42:46,400 [run_pretraining.py:  558]:	worker_index: 3, step: 654, cost: 8.633727, mlm loss: 8.633727, speed: 1.103466 steps/s, speed: 8.827730 samples/s, speed: 4519.797861 tokens/s, learning rate: 6.530e-06, loss_scalings: 13421.773438, pp_loss: 8.567569
[INFO] 2021-07-12 18:42:46,400 [run_pretraining.py:  512]:	********exe.run_654******* 
[INFO] 2021-07-12 18:42:47,304 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:47,305 [run_pretraining.py:  534]:	loss/total_loss, 8.671175003051758, 655
[INFO] 2021-07-12 18:42:47,305 [run_pretraining.py:  535]:	loss/mlm_loss, 8.671175003051758, 655
[INFO] 2021-07-12 18:42:47,305 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.539999503729632e-06, 655
[INFO] 2021-07-12 18:42:47,305 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 655
[INFO] 2021-07-12 18:42:47,305 [run_pretraining.py:  558]:	worker_index: 3, step: 655, cost: 8.671175, mlm loss: 8.671175, speed: 1.105427 steps/s, speed: 8.843414 samples/s, speed: 4527.827821 tokens/s, learning rate: 6.540e-06, loss_scalings: 13421.773438, pp_loss: 8.660690
[INFO] 2021-07-12 18:42:47,305 [run_pretraining.py:  512]:	********exe.run_655******* 
[INFO] 2021-07-12 18:42:48,205 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:48,205 [run_pretraining.py:  534]:	loss/total_loss, 8.812638282775879, 656
[INFO] 2021-07-12 18:42:48,205 [run_pretraining.py:  535]:	loss/mlm_loss, 8.812638282775879, 656
[INFO] 2021-07-12 18:42:48,205 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.549999852722976e-06, 656
[INFO] 2021-07-12 18:42:48,205 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 656
[INFO] 2021-07-12 18:42:48,205 [run_pretraining.py:  558]:	worker_index: 3, step: 656, cost: 8.812638, mlm loss: 8.812638, speed: 1.111338 steps/s, speed: 8.890704 samples/s, speed: 4552.040361 tokens/s, learning rate: 6.550e-06, loss_scalings: 13421.773438, pp_loss: 8.459888
[INFO] 2021-07-12 18:42:48,206 [run_pretraining.py:  512]:	********exe.run_656******* 
[INFO] 2021-07-12 18:42:49,107 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:49,108 [run_pretraining.py:  534]:	loss/total_loss, 8.632049560546875, 657
[INFO] 2021-07-12 18:42:49,108 [run_pretraining.py:  535]:	loss/mlm_loss, 8.632049560546875, 657
[INFO] 2021-07-12 18:42:49,108 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.55999974696897e-06, 657
[INFO] 2021-07-12 18:42:49,108 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 657
[INFO] 2021-07-12 18:42:49,108 [run_pretraining.py:  558]:	worker_index: 3, step: 657, cost: 8.632050, mlm loss: 8.632050, speed: 1.108850 steps/s, speed: 8.870798 samples/s, speed: 4541.848558 tokens/s, learning rate: 6.560e-06, loss_scalings: 13421.773438, pp_loss: 8.604013
[INFO] 2021-07-12 18:42:49,108 [run_pretraining.py:  512]:	********exe.run_657******* 
[INFO] 2021-07-12 18:42:50,016 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:50,017 [run_pretraining.py:  534]:	loss/total_loss, 8.712736129760742, 658
[INFO] 2021-07-12 18:42:50,017 [run_pretraining.py:  535]:	loss/mlm_loss, 8.712736129760742, 658
[INFO] 2021-07-12 18:42:50,017 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.570000095962314e-06, 658
[INFO] 2021-07-12 18:42:50,017 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 658
[INFO] 2021-07-12 18:42:50,017 [run_pretraining.py:  558]:	worker_index: 3, step: 658, cost: 8.712736, mlm loss: 8.712736, speed: 1.100472 steps/s, speed: 8.803779 samples/s, speed: 4507.534746 tokens/s, learning rate: 6.570e-06, loss_scalings: 13421.773438, pp_loss: 7.981627
[INFO] 2021-07-12 18:42:50,017 [run_pretraining.py:  512]:	********exe.run_658******* 
[INFO] 2021-07-12 18:42:50,926 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:50,926 [run_pretraining.py:  534]:	loss/total_loss, 9.045454025268555, 659
[INFO] 2021-07-12 18:42:50,926 [run_pretraining.py:  535]:	loss/mlm_loss, 9.045454025268555, 659
[INFO] 2021-07-12 18:42:50,926 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.579999990208307e-06, 659
[INFO] 2021-07-12 18:42:50,926 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 659
[INFO] 2021-07-12 18:42:50,926 [run_pretraining.py:  558]:	worker_index: 3, step: 659, cost: 9.045454, mlm loss: 9.045454, speed: 1.100644 steps/s, speed: 8.805149 samples/s, speed: 4508.236170 tokens/s, learning rate: 6.580e-06, loss_scalings: 13421.773438, pp_loss: 8.597174
[INFO] 2021-07-12 18:42:50,927 [run_pretraining.py:  512]:	********exe.run_659******* 
[INFO] 2021-07-12 18:42:51,831 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:51,832 [run_pretraining.py:  534]:	loss/total_loss, 8.691458702087402, 660
[INFO] 2021-07-12 18:42:51,832 [run_pretraining.py:  535]:	loss/mlm_loss, 8.691458702087402, 660
[INFO] 2021-07-12 18:42:51,832 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.58999942970695e-06, 660
[INFO] 2021-07-12 18:42:51,832 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 660
[INFO] 2021-07-12 18:42:51,832 [run_pretraining.py:  558]:	worker_index: 3, step: 660, cost: 8.691459, mlm loss: 8.691459, speed: 1.104767 steps/s, speed: 8.838135 samples/s, speed: 4525.125353 tokens/s, learning rate: 6.590e-06, loss_scalings: 13421.773438, pp_loss: 8.540180
[INFO] 2021-07-12 18:42:51,832 [run_pretraining.py:  512]:	********exe.run_660******* 
[INFO] 2021-07-12 18:42:52,739 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:52,740 [run_pretraining.py:  534]:	loss/total_loss, 9.233084678649902, 661
[INFO] 2021-07-12 18:42:52,740 [run_pretraining.py:  535]:	loss/mlm_loss, 9.233084678649902, 661
[INFO] 2021-07-12 18:42:52,740 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.599999778700294e-06, 661
[INFO] 2021-07-12 18:42:52,740 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 661
[INFO] 2021-07-12 18:42:52,740 [run_pretraining.py:  558]:	worker_index: 3, step: 661, cost: 9.233085, mlm loss: 9.233085, speed: 1.102581 steps/s, speed: 8.820648 samples/s, speed: 4516.171641 tokens/s, learning rate: 6.600e-06, loss_scalings: 13421.773438, pp_loss: 8.730850
[INFO] 2021-07-12 18:42:52,740 [run_pretraining.py:  512]:	********exe.run_661******* 
[INFO] 2021-07-12 18:42:53,640 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:53,640 [run_pretraining.py:  534]:	loss/total_loss, 8.403961181640625, 662
[INFO] 2021-07-12 18:42:53,640 [run_pretraining.py:  535]:	loss/mlm_loss, 8.403961181640625, 662
[INFO] 2021-07-12 18:42:53,640 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.610000127693638e-06, 662
[INFO] 2021-07-12 18:42:53,640 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 662
[INFO] 2021-07-12 18:42:53,640 [run_pretraining.py:  558]:	worker_index: 3, step: 662, cost: 8.403961, mlm loss: 8.403961, speed: 1.111216 steps/s, speed: 8.889726 samples/s, speed: 4551.539874 tokens/s, learning rate: 6.610e-06, loss_scalings: 13421.773438, pp_loss: 8.424124
[INFO] 2021-07-12 18:42:53,641 [run_pretraining.py:  512]:	********exe.run_662******* 
[INFO] 2021-07-12 18:42:54,546 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:54,546 [run_pretraining.py:  534]:	loss/total_loss, 9.209857940673828, 663
[INFO] 2021-07-12 18:42:54,546 [run_pretraining.py:  535]:	loss/mlm_loss, 9.209857940673828, 663
[INFO] 2021-07-12 18:42:54,546 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.6200000219396316e-06, 663
[INFO] 2021-07-12 18:42:54,546 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 663
[INFO] 2021-07-12 18:42:54,546 [run_pretraining.py:  558]:	worker_index: 3, step: 663, cost: 9.209858, mlm loss: 9.209858, speed: 1.104649 steps/s, speed: 8.837190 samples/s, speed: 4524.641492 tokens/s, learning rate: 6.620e-06, loss_scalings: 13421.773438, pp_loss: 8.722250
[INFO] 2021-07-12 18:42:54,546 [run_pretraining.py:  512]:	********exe.run_663******* 
[INFO] 2021-07-12 18:42:55,449 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:55,449 [run_pretraining.py:  534]:	loss/total_loss, 8.943745613098145, 664
[INFO] 2021-07-12 18:42:55,450 [run_pretraining.py:  535]:	loss/mlm_loss, 8.943745613098145, 664
[INFO] 2021-07-12 18:42:55,450 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.629999461438274e-06, 664
[INFO] 2021-07-12 18:42:55,450 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 664
[INFO] 2021-07-12 18:42:55,450 [run_pretraining.py:  558]:	worker_index: 3, step: 664, cost: 8.943746, mlm loss: 8.943746, speed: 1.107748 steps/s, speed: 8.861982 samples/s, speed: 4537.334701 tokens/s, learning rate: 6.630e-06, loss_scalings: 13421.773438, pp_loss: 8.560087
[INFO] 2021-07-12 18:42:55,450 [run_pretraining.py:  512]:	********exe.run_664******* 
[INFO] 2021-07-12 18:42:56,365 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:56,366 [run_pretraining.py:  534]:	loss/total_loss, 8.528614044189453, 665
[INFO] 2021-07-12 18:42:56,366 [run_pretraining.py:  535]:	loss/mlm_loss, 8.528614044189453, 665
[INFO] 2021-07-12 18:42:56,366 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.639999810431618e-06, 665
[INFO] 2021-07-12 18:42:56,366 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 665
[INFO] 2021-07-12 18:42:56,366 [run_pretraining.py:  558]:	worker_index: 3, step: 665, cost: 8.528614, mlm loss: 8.528614, speed: 1.092196 steps/s, speed: 8.737567 samples/s, speed: 4473.634179 tokens/s, learning rate: 6.640e-06, loss_scalings: 13421.773438, pp_loss: 8.539328
[INFO] 2021-07-12 18:42:56,366 [run_pretraining.py:  512]:	********exe.run_665******* 
[INFO] 2021-07-12 18:43:19,354 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:19,354 [run_pretraining.py:  534]:	loss/total_loss, 7.8115034103393555, 666
[INFO] 2021-07-12 18:43:19,354 [run_pretraining.py:  535]:	loss/mlm_loss, 7.8115034103393555, 666
[INFO] 2021-07-12 18:43:19,354 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.649999704677612e-06, 666
[INFO] 2021-07-12 18:43:19,354 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 666
[INFO] 2021-07-12 18:43:19,355 [run_pretraining.py:  558]:	worker_index: 3, step: 666, cost: 7.811503, mlm loss: 7.811503, speed: 0.043501 steps/s, speed: 0.348009 samples/s, speed: 178.180608 tokens/s, learning rate: 6.650e-06, loss_scalings: 13421.773438, pp_loss: 8.346255
[INFO] 2021-07-12 18:43:19,355 [run_pretraining.py:  512]:	********exe.run_666******* 
[INFO] 2021-07-12 18:43:20,330 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:20,331 [run_pretraining.py:  534]:	loss/total_loss, 8.61996078491211, 667
[INFO] 2021-07-12 18:43:20,331 [run_pretraining.py:  535]:	loss/mlm_loss, 8.61996078491211, 667
[INFO] 2021-07-12 18:43:20,331 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.660000053670956e-06, 667
[INFO] 2021-07-12 18:43:20,331 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 667
[INFO] 2021-07-12 18:43:20,331 [run_pretraining.py:  558]:	worker_index: 3, step: 667, cost: 8.619961, mlm loss: 8.619961, speed: 1.024392 steps/s, speed: 8.195135 samples/s, speed: 4195.909222 tokens/s, learning rate: 6.660e-06, loss_scalings: 13421.773438, pp_loss: 8.431585
[INFO] 2021-07-12 18:43:20,331 [run_pretraining.py:  512]:	********exe.run_667******* 
[INFO] 2021-07-12 18:43:21,254 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:21,255 [run_pretraining.py:  534]:	loss/total_loss, 8.724479675292969, 668
[INFO] 2021-07-12 18:43:21,255 [run_pretraining.py:  535]:	loss/mlm_loss, 8.724479675292969, 668
[INFO] 2021-07-12 18:43:21,255 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.669999493169598e-06, 668
[INFO] 2021-07-12 18:43:21,255 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 668
[INFO] 2021-07-12 18:43:21,255 [run_pretraining.py:  558]:	worker_index: 3, step: 668, cost: 8.724480, mlm loss: 8.724480, speed: 1.083293 steps/s, speed: 8.666345 samples/s, speed: 4437.168565 tokens/s, learning rate: 6.670e-06, loss_scalings: 13421.773438, pp_loss: 8.615513
[INFO] 2021-07-12 18:43:21,255 [run_pretraining.py:  512]:	********exe.run_668******* 
[INFO] 2021-07-12 18:43:22,194 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:22,195 [run_pretraining.py:  534]:	loss/total_loss, 8.810970306396484, 669
[INFO] 2021-07-12 18:43:22,195 [run_pretraining.py:  535]:	loss/mlm_loss, 8.810970306396484, 669
[INFO] 2021-07-12 18:43:22,195 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.6799998421629425e-06, 669
[INFO] 2021-07-12 18:43:22,195 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 669
[INFO] 2021-07-12 18:43:22,195 [run_pretraining.py:  558]:	worker_index: 3, step: 669, cost: 8.810970, mlm loss: 8.810970, speed: 1.064806 steps/s, speed: 8.518446 samples/s, speed: 4361.444432 tokens/s, learning rate: 6.680e-06, loss_scalings: 13421.773438, pp_loss: 8.686114
[INFO] 2021-07-12 18:43:22,195 [run_pretraining.py:  512]:	********exe.run_669******* 
[INFO] 2021-07-12 18:43:23,254 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:23,254 [run_pretraining.py:  534]:	loss/total_loss, 8.732461929321289, 670
[INFO] 2021-07-12 18:43:23,254 [run_pretraining.py:  535]:	loss/mlm_loss, 8.732461929321289, 670
[INFO] 2021-07-12 18:43:23,255 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.689999736408936e-06, 670
[INFO] 2021-07-12 18:43:23,255 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 670
[INFO] 2021-07-12 18:43:23,255 [run_pretraining.py:  558]:	worker_index: 3, step: 670, cost: 8.732462, mlm loss: 8.732462, speed: 0.944177 steps/s, speed: 7.553417 samples/s, speed: 3867.349615 tokens/s, learning rate: 6.690e-06, loss_scalings: 13421.773438, pp_loss: 8.603666
[INFO] 2021-07-12 18:43:23,255 [run_pretraining.py:  512]:	********exe.run_670******* 
[INFO] 2021-07-12 18:43:49,160 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:49,161 [run_pretraining.py:  534]:	loss/total_loss, 8.742406845092773, 671
[INFO] 2021-07-12 18:43:49,161 [run_pretraining.py:  535]:	loss/mlm_loss, 8.742406845092773, 671
[INFO] 2021-07-12 18:43:49,161 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.70000008540228e-06, 671
[INFO] 2021-07-12 18:43:49,161 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 671
[INFO] 2021-07-12 18:43:49,161 [run_pretraining.py:  558]:	worker_index: 3, step: 671, cost: 8.742407, mlm loss: 8.742407, speed: 0.038602 steps/s, speed: 0.308813 samples/s, speed: 158.112295 tokens/s, learning rate: 6.700e-06, loss_scalings: 13421.773438, pp_loss: 8.592884
[INFO] 2021-07-12 18:43:49,161 [run_pretraining.py:  512]:	********exe.run_671******* 
[INFO] 2021-07-12 18:43:50,202 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:50,202 [run_pretraining.py:  534]:	loss/total_loss, 8.792513847351074, 672
[INFO] 2021-07-12 18:43:50,203 [run_pretraining.py:  535]:	loss/mlm_loss, 8.792513847351074, 672
[INFO] 2021-07-12 18:43:50,203 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.7099999796482734e-06, 672
[INFO] 2021-07-12 18:43:50,203 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 672
[INFO] 2021-07-12 18:43:50,203 [run_pretraining.py:  558]:	worker_index: 3, step: 672, cost: 8.792514, mlm loss: 8.792514, speed: 0.960479 steps/s, speed: 7.683828 samples/s, speed: 3934.119976 tokens/s, learning rate: 6.710e-06, loss_scalings: 13421.773438, pp_loss: 8.512556
[INFO] 2021-07-12 18:43:50,203 [run_pretraining.py:  512]:	********exe.run_672******* 
[INFO] 2021-07-12 18:43:51,243 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:51,244 [run_pretraining.py:  534]:	loss/total_loss, 8.763649940490723, 673
[INFO] 2021-07-12 18:43:51,244 [run_pretraining.py:  535]:	loss/mlm_loss, 8.763649940490723, 673
[INFO] 2021-07-12 18:43:51,244 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.719999419146916e-06, 673
[INFO] 2021-07-12 18:43:51,244 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 673
[INFO] 2021-07-12 18:43:51,244 [run_pretraining.py:  558]:	worker_index: 3, step: 673, cost: 8.763650, mlm loss: 8.763650, speed: 0.960852 steps/s, speed: 7.686817 samples/s, speed: 3935.650295 tokens/s, learning rate: 6.720e-06, loss_scalings: 13421.773438, pp_loss: 8.404271
[INFO] 2021-07-12 18:43:51,244 [run_pretraining.py:  512]:	********exe.run_673******* 
[INFO] 2021-07-12 18:43:52,336 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:52,336 [run_pretraining.py:  534]:	loss/total_loss, 8.416505813598633, 674
[INFO] 2021-07-12 18:43:52,336 [run_pretraining.py:  535]:	loss/mlm_loss, 8.416505813598633, 674
[INFO] 2021-07-12 18:43:52,336 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.72999976814026e-06, 674
[INFO] 2021-07-12 18:43:52,336 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 674
[INFO] 2021-07-12 18:43:52,336 [run_pretraining.py:  558]:	worker_index: 3, step: 674, cost: 8.416506, mlm loss: 8.416506, speed: 0.916072 steps/s, speed: 7.328572 samples/s, speed: 3752.228953 tokens/s, learning rate: 6.730e-06, loss_scalings: 13421.773438, pp_loss: 8.589149
[INFO] 2021-07-12 18:43:52,337 [run_pretraining.py:  512]:	********exe.run_674******* 
[INFO] 2021-07-12 18:43:53,381 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:53,381 [run_pretraining.py:  534]:	loss/total_loss, 8.493622779846191, 675
[INFO] 2021-07-12 18:43:53,381 [run_pretraining.py:  535]:	loss/mlm_loss, 8.493622779846191, 675
[INFO] 2021-07-12 18:43:53,381 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.740000117133604e-06, 675
[INFO] 2021-07-12 18:43:53,381 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 675
[INFO] 2021-07-12 18:43:53,381 [run_pretraining.py:  558]:	worker_index: 3, step: 675, cost: 8.493623, mlm loss: 8.493623, speed: 0.957518 steps/s, speed: 7.660140 samples/s, speed: 3921.991762 tokens/s, learning rate: 6.740e-06, loss_scalings: 13421.773438, pp_loss: 8.530636
[INFO] 2021-07-12 18:43:53,382 [run_pretraining.py:  512]:	********exe.run_675******* 
[INFO] 2021-07-12 18:43:54,429 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:54,429 [run_pretraining.py:  534]:	loss/total_loss, 8.983278274536133, 676
[INFO] 2021-07-12 18:43:54,429 [run_pretraining.py:  535]:	loss/mlm_loss, 8.983278274536133, 676
[INFO] 2021-07-12 18:43:54,430 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.750000011379598e-06, 676
[INFO] 2021-07-12 18:43:54,430 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 676
[INFO] 2021-07-12 18:43:54,430 [run_pretraining.py:  558]:	worker_index: 3, step: 676, cost: 8.983278, mlm loss: 8.983278, speed: 0.954590 steps/s, speed: 7.636716 samples/s, speed: 3909.998608 tokens/s, learning rate: 6.750e-06, loss_scalings: 13421.773438, pp_loss: 8.561131
[INFO] 2021-07-12 18:43:54,430 [run_pretraining.py:  512]:	********exe.run_676******* 
[INFO] 2021-07-12 18:43:55,358 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:55,358 [run_pretraining.py:  534]:	loss/total_loss, 8.724929809570312, 677
[INFO] 2021-07-12 18:43:55,358 [run_pretraining.py:  535]:	loss/mlm_loss, 8.724929809570312, 677
[INFO] 2021-07-12 18:43:55,358 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.75999945087824e-06, 677
[INFO] 2021-07-12 18:43:55,358 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 677
[INFO] 2021-07-12 18:43:55,359 [run_pretraining.py:  558]:	worker_index: 3, step: 677, cost: 8.724930, mlm loss: 8.724930, speed: 1.077365 steps/s, speed: 8.618918 samples/s, speed: 4412.886236 tokens/s, learning rate: 6.760e-06, loss_scalings: 13421.773438, pp_loss: 8.462935
[INFO] 2021-07-12 18:43:55,359 [run_pretraining.py:  512]:	********exe.run_677******* 
[INFO] 2021-07-12 18:43:56,276 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:56,277 [run_pretraining.py:  534]:	loss/total_loss, 8.58753490447998, 678
[INFO] 2021-07-12 18:43:56,277 [run_pretraining.py:  535]:	loss/mlm_loss, 8.58753490447998, 678
[INFO] 2021-07-12 18:43:56,277 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.769999799871584e-06, 678
[INFO] 2021-07-12 18:43:56,277 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 678
[INFO] 2021-07-12 18:43:56,277 [run_pretraining.py:  558]:	worker_index: 3, step: 678, cost: 8.587535, mlm loss: 8.587535, speed: 1.089514 steps/s, speed: 8.716114 samples/s, speed: 4462.650264 tokens/s, learning rate: 6.770e-06, loss_scalings: 13421.773438, pp_loss: 7.364081
[INFO] 2021-07-12 18:43:56,277 [run_pretraining.py:  512]:	********exe.run_678******* 
[INFO] 2021-07-12 18:43:57,208 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:57,209 [run_pretraining.py:  534]:	loss/total_loss, 8.611197471618652, 679
[INFO] 2021-07-12 18:43:57,209 [run_pretraining.py:  535]:	loss/mlm_loss, 8.611197471618652, 679
[INFO] 2021-07-12 18:43:57,209 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.779999694117578e-06, 679
[INFO] 2021-07-12 18:43:57,209 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 679
[INFO] 2021-07-12 18:43:57,209 [run_pretraining.py:  558]:	worker_index: 3, step: 679, cost: 8.611197, mlm loss: 8.611197, speed: 1.073376 steps/s, speed: 8.587011 samples/s, speed: 4396.549574 tokens/s, learning rate: 6.780e-06, loss_scalings: 13421.773438, pp_loss: 8.392593
[INFO] 2021-07-12 18:43:57,209 [run_pretraining.py:  512]:	********exe.run_679******* 
[INFO] 2021-07-12 18:43:58,125 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:58,125 [run_pretraining.py:  534]:	loss/total_loss, 8.235103607177734, 680
[INFO] 2021-07-12 18:43:58,126 [run_pretraining.py:  535]:	loss/mlm_loss, 8.235103607177734, 680
[INFO] 2021-07-12 18:43:58,126 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.790000043110922e-06, 680
[INFO] 2021-07-12 18:43:58,126 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 680
[INFO] 2021-07-12 18:43:58,126 [run_pretraining.py:  558]:	worker_index: 3, step: 680, cost: 8.235104, mlm loss: 8.235104, speed: 1.091760 steps/s, speed: 8.734082 samples/s, speed: 4471.850213 tokens/s, learning rate: 6.790e-06, loss_scalings: 13421.773438, pp_loss: 8.415311
[INFO] 2021-07-12 18:43:58,126 [run_pretraining.py:  512]:	********exe.run_680******* 
[INFO] 2021-07-12 18:43:59,046 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:59,047 [run_pretraining.py:  534]:	loss/total_loss, 8.074112892150879, 681
[INFO] 2021-07-12 18:43:59,047 [run_pretraining.py:  535]:	loss/mlm_loss, 8.074112892150879, 681
[INFO] 2021-07-12 18:43:59,047 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.800000392104266e-06, 681
[INFO] 2021-07-12 18:43:59,047 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 681
[INFO] 2021-07-12 18:43:59,047 [run_pretraining.py:  558]:	worker_index: 3, step: 681, cost: 8.074113, mlm loss: 8.074113, speed: 1.086137 steps/s, speed: 8.689097 samples/s, speed: 4448.817412 tokens/s, learning rate: 6.800e-06, loss_scalings: 13421.773438, pp_loss: 8.524834
[INFO] 2021-07-12 18:43:59,047 [run_pretraining.py:  512]:	********exe.run_681******* 
[INFO] 2021-07-12 18:43:59,964 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:59,964 [run_pretraining.py:  534]:	loss/total_loss, 8.449505805969238, 682
[INFO] 2021-07-12 18:43:59,965 [run_pretraining.py:  535]:	loss/mlm_loss, 8.449505805969238, 682
[INFO] 2021-07-12 18:43:59,965 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.809999831602909e-06, 682
[INFO] 2021-07-12 18:43:59,965 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 682
[INFO] 2021-07-12 18:43:59,965 [run_pretraining.py:  558]:	worker_index: 3, step: 682, cost: 8.449506, mlm loss: 8.449506, speed: 1.090510 steps/s, speed: 8.724082 samples/s, speed: 4466.729807 tokens/s, learning rate: 6.810e-06, loss_scalings: 13421.773438, pp_loss: 8.271914
[INFO] 2021-07-12 18:43:59,965 [run_pretraining.py:  512]:	********exe.run_682******* 
[INFO] 2021-07-12 18:44:00,891 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:00,891 [run_pretraining.py:  534]:	loss/total_loss, 8.61557388305664, 683
[INFO] 2021-07-12 18:44:00,891 [run_pretraining.py:  535]:	loss/mlm_loss, 8.61557388305664, 683
[INFO] 2021-07-12 18:44:00,891 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.819999725848902e-06, 683
[INFO] 2021-07-12 18:44:00,891 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 683
[INFO] 2021-07-12 18:44:00,891 [run_pretraining.py:  558]:	worker_index: 3, step: 683, cost: 8.615574, mlm loss: 8.615574, speed: 1.079857 steps/s, speed: 8.638858 samples/s, speed: 4423.095527 tokens/s, learning rate: 6.820e-06, loss_scalings: 13421.773438, pp_loss: 8.624244
[INFO] 2021-07-12 18:44:00,892 [run_pretraining.py:  512]:	********exe.run_683******* 
[INFO] 2021-07-12 18:44:01,817 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:01,817 [run_pretraining.py:  534]:	loss/total_loss, 8.090985298156738, 684
[INFO] 2021-07-12 18:44:01,818 [run_pretraining.py:  535]:	loss/mlm_loss, 8.090985298156738, 684
[INFO] 2021-07-12 18:44:01,818 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.830000074842246e-06, 684
[INFO] 2021-07-12 18:44:01,818 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 684
[INFO] 2021-07-12 18:44:01,818 [run_pretraining.py:  558]:	worker_index: 3, step: 684, cost: 8.090985, mlm loss: 8.090985, speed: 1.080360 steps/s, speed: 8.642884 samples/s, speed: 4425.156507 tokens/s, learning rate: 6.830e-06, loss_scalings: 13421.773438, pp_loss: 8.280807
[INFO] 2021-07-12 18:44:01,818 [run_pretraining.py:  512]:	********exe.run_684******* 
[INFO] 2021-07-12 18:44:02,746 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:02,747 [run_pretraining.py:  534]:	loss/total_loss, 8.217206954956055, 685
[INFO] 2021-07-12 18:44:02,747 [run_pretraining.py:  535]:	loss/mlm_loss, 8.217206954956055, 685
[INFO] 2021-07-12 18:44:02,747 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.83999996908824e-06, 685
[INFO] 2021-07-12 18:44:02,747 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 685
[INFO] 2021-07-12 18:44:02,747 [run_pretraining.py:  558]:	worker_index: 3, step: 685, cost: 8.217207, mlm loss: 8.217207, speed: 1.076856 steps/s, speed: 8.614847 samples/s, speed: 4410.801561 tokens/s, learning rate: 6.840e-06, loss_scalings: 13421.773438, pp_loss: 8.087423
[INFO] 2021-07-12 18:44:02,747 [run_pretraining.py:  512]:	********exe.run_685******* 
[INFO] 2021-07-12 18:44:03,675 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:03,676 [run_pretraining.py:  534]:	loss/total_loss, 8.517717361450195, 686
[INFO] 2021-07-12 18:44:03,676 [run_pretraining.py:  535]:	loss/mlm_loss, 8.517717361450195, 686
[INFO] 2021-07-12 18:44:03,676 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.849999408586882e-06, 686
[INFO] 2021-07-12 18:44:03,676 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 686
[INFO] 2021-07-12 18:44:03,676 [run_pretraining.py:  558]:	worker_index: 3, step: 686, cost: 8.517717, mlm loss: 8.517717, speed: 1.077156 steps/s, speed: 8.617252 samples/s, speed: 4412.032867 tokens/s, learning rate: 6.850e-06, loss_scalings: 13421.773438, pp_loss: 8.289631
[INFO] 2021-07-12 18:44:03,676 [run_pretraining.py:  512]:	********exe.run_686******* 
[INFO] 2021-07-12 18:44:04,598 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:04,599 [run_pretraining.py:  534]:	loss/total_loss, 8.605683326721191, 687
[INFO] 2021-07-12 18:44:04,599 [run_pretraining.py:  535]:	loss/mlm_loss, 8.605683326721191, 687
[INFO] 2021-07-12 18:44:04,599 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.859999757580226e-06, 687
[INFO] 2021-07-12 18:44:04,599 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 687
[INFO] 2021-07-12 18:44:04,599 [run_pretraining.py:  558]:	worker_index: 3, step: 687, cost: 8.605683, mlm loss: 8.605683, speed: 1.084214 steps/s, speed: 8.673713 samples/s, speed: 4440.941028 tokens/s, learning rate: 6.860e-06, loss_scalings: 13421.773438, pp_loss: 8.560234
[INFO] 2021-07-12 18:44:04,599 [run_pretraining.py:  512]:	********exe.run_687******* 
[INFO] 2021-07-12 18:44:05,513 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:05,513 [run_pretraining.py:  534]:	loss/total_loss, 4.525353908538818, 688
[INFO] 2021-07-12 18:44:05,514 [run_pretraining.py:  535]:	loss/mlm_loss, 4.525353908538818, 688
[INFO] 2021-07-12 18:44:05,514 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.8700001065735705e-06, 688
[INFO] 2021-07-12 18:44:05,514 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 688
[INFO] 2021-07-12 18:44:05,514 [run_pretraining.py:  558]:	worker_index: 3, step: 688, cost: 4.525354, mlm loss: 4.525354, speed: 1.093833 steps/s, speed: 8.750667 samples/s, speed: 4480.341422 tokens/s, learning rate: 6.870e-06, loss_scalings: 13421.773438, pp_loss: 7.449255
[INFO] 2021-07-12 18:44:05,514 [run_pretraining.py:  512]:	********exe.run_688******* 
[INFO] 2021-07-12 18:44:06,435 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:06,436 [run_pretraining.py:  534]:	loss/total_loss, 8.47364616394043, 689
[INFO] 2021-07-12 18:44:06,436 [run_pretraining.py:  535]:	loss/mlm_loss, 8.47364616394043, 689
[INFO] 2021-07-12 18:44:06,436 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.880000000819564e-06, 689
[INFO] 2021-07-12 18:44:06,436 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 689
[INFO] 2021-07-12 18:44:06,436 [run_pretraining.py:  558]:	worker_index: 3, step: 689, cost: 8.473646, mlm loss: 8.473646, speed: 1.084893 steps/s, speed: 8.679142 samples/s, speed: 4443.720852 tokens/s, learning rate: 6.880e-06, loss_scalings: 13421.773438, pp_loss: 8.594938
[INFO] 2021-07-12 18:44:06,436 [run_pretraining.py:  512]:	********exe.run_689******* 
[INFO] 2021-07-12 18:44:07,357 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:07,358 [run_pretraining.py:  534]:	loss/total_loss, 8.236991882324219, 690
[INFO] 2021-07-12 18:44:07,358 [run_pretraining.py:  535]:	loss/mlm_loss, 8.236991882324219, 690
[INFO] 2021-07-12 18:44:07,358 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.889999440318206e-06, 690
[INFO] 2021-07-12 18:44:07,358 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 690
[INFO] 2021-07-12 18:44:07,358 [run_pretraining.py:  558]:	worker_index: 3, step: 690, cost: 8.236992, mlm loss: 8.236992, speed: 1.085311 steps/s, speed: 8.682489 samples/s, speed: 4445.434128 tokens/s, learning rate: 6.890e-06, loss_scalings: 13421.773438, pp_loss: 8.569317
[INFO] 2021-07-12 18:44:07,358 [run_pretraining.py:  512]:	********exe.run_690******* 
[INFO] 2021-07-12 18:44:08,281 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:08,282 [run_pretraining.py:  534]:	loss/total_loss, 8.627099990844727, 691
[INFO] 2021-07-12 18:44:08,282 [run_pretraining.py:  535]:	loss/mlm_loss, 8.627099990844727, 691
[INFO] 2021-07-12 18:44:08,282 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.8999997893115506e-06, 691
[INFO] 2021-07-12 18:44:08,282 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 691
[INFO] 2021-07-12 18:44:08,282 [run_pretraining.py:  558]:	worker_index: 3, step: 691, cost: 8.627100, mlm loss: 8.627100, speed: 1.083086 steps/s, speed: 8.664687 samples/s, speed: 4436.319527 tokens/s, learning rate: 6.900e-06, loss_scalings: 13421.773438, pp_loss: 8.575232
[INFO] 2021-07-12 18:44:08,282 [run_pretraining.py:  512]:	********exe.run_691******* 
[INFO] 2021-07-12 18:44:09,218 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:09,219 [run_pretraining.py:  534]:	loss/total_loss, 8.243329048156738, 692
[INFO] 2021-07-12 18:44:09,219 [run_pretraining.py:  535]:	loss/mlm_loss, 8.243329048156738, 692
[INFO] 2021-07-12 18:44:09,219 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.909999683557544e-06, 692
[INFO] 2021-07-12 18:44:09,219 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 692
[INFO] 2021-07-12 18:44:09,219 [run_pretraining.py:  558]:	worker_index: 3, step: 692, cost: 8.243329, mlm loss: 8.243329, speed: 1.068208 steps/s, speed: 8.545667 samples/s, speed: 4375.381336 tokens/s, learning rate: 6.910e-06, loss_scalings: 13421.773438, pp_loss: 8.512862
[INFO] 2021-07-12 18:44:09,219 [run_pretraining.py:  512]:	********exe.run_692******* 
[INFO] 2021-07-12 18:44:10,140 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:10,140 [run_pretraining.py:  534]:	loss/total_loss, 8.067021369934082, 693
[INFO] 2021-07-12 18:44:10,140 [run_pretraining.py:  535]:	loss/mlm_loss, 8.067021369934082, 693
[INFO] 2021-07-12 18:44:10,140 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.920000032550888e-06, 693
[INFO] 2021-07-12 18:44:10,140 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 693
[INFO] 2021-07-12 18:44:10,140 [run_pretraining.py:  558]:	worker_index: 3, step: 693, cost: 8.067021, mlm loss: 8.067021, speed: 1.085983 steps/s, speed: 8.687864 samples/s, speed: 4448.186181 tokens/s, learning rate: 6.920e-06, loss_scalings: 13421.773438, pp_loss: 8.278464
[INFO] 2021-07-12 18:44:10,140 [run_pretraining.py:  512]:	********exe.run_693******* 
[INFO] 2021-07-12 18:44:11,050 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:11,051 [run_pretraining.py:  534]:	loss/total_loss, 8.640032768249512, 694
[INFO] 2021-07-12 18:44:11,051 [run_pretraining.py:  535]:	loss/mlm_loss, 8.640032768249512, 694
[INFO] 2021-07-12 18:44:11,051 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.930000381544232e-06, 694
[INFO] 2021-07-12 18:44:11,051 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 694
[INFO] 2021-07-12 18:44:11,051 [run_pretraining.py:  558]:	worker_index: 3, step: 694, cost: 8.640033, mlm loss: 8.640033, speed: 1.098627 steps/s, speed: 8.789016 samples/s, speed: 4499.976081 tokens/s, learning rate: 6.930e-06, loss_scalings: 13421.773438, pp_loss: 8.667170
[INFO] 2021-07-12 18:44:11,051 [run_pretraining.py:  512]:	********exe.run_694******* 
[INFO] 2021-07-12 18:44:11,965 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:11,965 [run_pretraining.py:  534]:	loss/total_loss, 8.417283058166504, 695
[INFO] 2021-07-12 18:44:11,966 [run_pretraining.py:  535]:	loss/mlm_loss, 8.417283058166504, 695
[INFO] 2021-07-12 18:44:11,966 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.939999366295524e-06, 695
[INFO] 2021-07-12 18:44:11,966 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 695
[INFO] 2021-07-12 18:44:11,966 [run_pretraining.py:  558]:	worker_index: 3, step: 695, cost: 8.417283, mlm loss: 8.417283, speed: 1.094212 steps/s, speed: 8.753696 samples/s, speed: 4481.892465 tokens/s, learning rate: 6.940e-06, loss_scalings: 13421.773438, pp_loss: 8.289852
[INFO] 2021-07-12 18:44:11,966 [run_pretraining.py:  512]:	********exe.run_695******* 
[INFO] 2021-07-12 18:44:12,884 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:12,884 [run_pretraining.py:  534]:	loss/total_loss, 8.565624237060547, 696
[INFO] 2021-07-12 18:44:12,885 [run_pretraining.py:  535]:	loss/mlm_loss, 8.565624237060547, 696
[INFO] 2021-07-12 18:44:12,885 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.949999715288868e-06, 696
[INFO] 2021-07-12 18:44:12,885 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 696
[INFO] 2021-07-12 18:44:12,885 [run_pretraining.py:  558]:	worker_index: 3, step: 696, cost: 8.565624, mlm loss: 8.565624, speed: 1.088966 steps/s, speed: 8.711726 samples/s, speed: 4460.403668 tokens/s, learning rate: 6.950e-06, loss_scalings: 13421.773438, pp_loss: 8.518421
[INFO] 2021-07-12 18:44:12,885 [run_pretraining.py:  512]:	********exe.run_696******* 
[INFO] 2021-07-12 18:44:13,793 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:13,794 [run_pretraining.py:  534]:	loss/total_loss, 5.256777286529541, 697
[INFO] 2021-07-12 18:44:13,794 [run_pretraining.py:  535]:	loss/mlm_loss, 5.256777286529541, 697
[INFO] 2021-07-12 18:44:13,794 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.960000064282212e-06, 697
[INFO] 2021-07-12 18:44:13,794 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 697
[INFO] 2021-07-12 18:44:13,794 [run_pretraining.py:  558]:	worker_index: 3, step: 697, cost: 5.256777, mlm loss: 5.256777, speed: 1.100705 steps/s, speed: 8.805641 samples/s, speed: 4508.488169 tokens/s, learning rate: 6.960e-06, loss_scalings: 13421.773438, pp_loss: 7.746574
[INFO] 2021-07-12 18:44:13,794 [run_pretraining.py:  512]:	********exe.run_697******* 
[INFO] 2021-07-12 18:44:14,707 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:14,708 [run_pretraining.py:  534]:	loss/total_loss, 8.435086250305176, 698
[INFO] 2021-07-12 18:44:14,708 [run_pretraining.py:  535]:	loss/mlm_loss, 8.435086250305176, 698
[INFO] 2021-07-12 18:44:14,708 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.969999958528206e-06, 698
[INFO] 2021-07-12 18:44:14,708 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 698
[INFO] 2021-07-12 18:44:14,708 [run_pretraining.py:  558]:	worker_index: 3, step: 698, cost: 8.435086, mlm loss: 8.435086, speed: 1.094554 steps/s, speed: 8.756433 samples/s, speed: 4483.293650 tokens/s, learning rate: 6.970e-06, loss_scalings: 13421.773438, pp_loss: 8.704152
[INFO] 2021-07-12 18:44:14,708 [run_pretraining.py:  512]:	********exe.run_698******* 
[INFO] 2021-07-12 18:44:15,619 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:15,620 [run_pretraining.py:  534]:	loss/total_loss, 8.738795280456543, 699
[INFO] 2021-07-12 18:44:15,620 [run_pretraining.py:  535]:	loss/mlm_loss, 8.738795280456543, 699
[INFO] 2021-07-12 18:44:15,620 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.979999398026848e-06, 699
[INFO] 2021-07-12 18:44:15,620 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 699
[INFO] 2021-07-12 18:44:15,620 [run_pretraining.py:  558]:	worker_index: 3, step: 699, cost: 8.738795, mlm loss: 8.738795, speed: 1.097084 steps/s, speed: 8.776673 samples/s, speed: 4493.656568 tokens/s, learning rate: 6.980e-06, loss_scalings: 13421.773438, pp_loss: 8.620082
[INFO] 2021-07-12 18:44:15,620 [run_pretraining.py:  512]:	********exe.run_699******* 
[INFO] 2021-07-12 18:44:16,562 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:16,562 [run_pretraining.py:  534]:	loss/total_loss, 8.871182441711426, 700
[INFO] 2021-07-12 18:44:16,562 [run_pretraining.py:  535]:	loss/mlm_loss, 8.871182441711426, 700
[INFO] 2021-07-12 18:44:16,563 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.9899997470201924e-06, 700
[INFO] 2021-07-12 18:44:16,563 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 700
[INFO] 2021-07-12 18:44:16,563 [run_pretraining.py:  558]:	worker_index: 3, step: 700, cost: 8.871182, mlm loss: 8.871182, speed: 1.061898 steps/s, speed: 8.495180 samples/s, speed: 4349.532177 tokens/s, learning rate: 6.990e-06, loss_scalings: 13421.773438, pp_loss: 8.888358
[INFO] 2021-07-12 18:44:16,563 [run_pretraining.py:  512]:	********exe.run_700******* 
[INFO] 2021-07-12 18:44:17,471 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:17,472 [run_pretraining.py:  534]:	loss/total_loss, 7.9832658767700195, 701
[INFO] 2021-07-12 18:44:17,472 [run_pretraining.py:  535]:	loss/mlm_loss, 7.9832658767700195, 701
[INFO] 2021-07-12 18:44:17,472 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.999999641266186e-06, 701
[INFO] 2021-07-12 18:44:17,472 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 701
[INFO] 2021-07-12 18:44:17,472 [run_pretraining.py:  558]:	worker_index: 3, step: 701, cost: 7.983266, mlm loss: 7.983266, speed: 1.100388 steps/s, speed: 8.803107 samples/s, speed: 4507.190620 tokens/s, learning rate: 7.000e-06, loss_scalings: 13421.773438, pp_loss: 7.479003
[INFO] 2021-07-12 18:44:17,472 [run_pretraining.py:  512]:	********exe.run_701******* 
[INFO] 2021-07-12 18:44:18,382 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:18,383 [run_pretraining.py:  534]:	loss/total_loss, 8.483062744140625, 702
[INFO] 2021-07-12 18:44:18,383 [run_pretraining.py:  535]:	loss/mlm_loss, 8.483062744140625, 702
[INFO] 2021-07-12 18:44:18,383 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.00999999025953e-06, 702
[INFO] 2021-07-12 18:44:18,383 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 702
[INFO] 2021-07-12 18:44:18,383 [run_pretraining.py:  558]:	worker_index: 3, step: 702, cost: 8.483063, mlm loss: 8.483063, speed: 1.098672 steps/s, speed: 8.789373 samples/s, speed: 4500.158786 tokens/s, learning rate: 7.010e-06, loss_scalings: 13421.773438, pp_loss: 8.572938
[INFO] 2021-07-12 18:44:18,383 [run_pretraining.py:  512]:	********exe.run_702******* 
[INFO] 2021-07-12 18:44:19,300 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:19,301 [run_pretraining.py:  534]:	loss/total_loss, 8.82484245300293, 703
[INFO] 2021-07-12 18:44:19,301 [run_pretraining.py:  535]:	loss/mlm_loss, 8.82484245300293, 703
[INFO] 2021-07-12 18:44:19,301 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.020000339252874e-06, 703
[INFO] 2021-07-12 18:44:19,301 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 703
[INFO] 2021-07-12 18:44:19,301 [run_pretraining.py:  558]:	worker_index: 3, step: 703, cost: 8.824842, mlm loss: 8.824842, speed: 1.090072 steps/s, speed: 8.720574 samples/s, speed: 4464.933936 tokens/s, learning rate: 7.020e-06, loss_scalings: 13421.773438, pp_loss: 8.653528
[INFO] 2021-07-12 18:44:19,301 [run_pretraining.py:  512]:	********exe.run_703******* 
[INFO] 2021-07-12 18:44:20,218 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:20,219 [run_pretraining.py:  534]:	loss/total_loss, 8.390603065490723, 704
[INFO] 2021-07-12 18:44:20,219 [run_pretraining.py:  535]:	loss/mlm_loss, 8.390603065490723, 704
[INFO] 2021-07-12 18:44:20,219 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.029999778751517e-06, 704
[INFO] 2021-07-12 18:44:20,219 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 704
[INFO] 2021-07-12 18:44:20,219 [run_pretraining.py:  558]:	worker_index: 3, step: 704, cost: 8.390603, mlm loss: 8.390603, speed: 1.089947 steps/s, speed: 8.719577 samples/s, speed: 4464.423416 tokens/s, learning rate: 7.030e-06, loss_scalings: 13421.773438, pp_loss: 8.532532
[INFO] 2021-07-12 18:44:20,219 [run_pretraining.py:  512]:	********exe.run_704******* 
[INFO] 2021-07-12 18:44:21,139 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:21,140 [run_pretraining.py:  534]:	loss/total_loss, 8.491410255432129, 705
[INFO] 2021-07-12 18:44:21,140 [run_pretraining.py:  535]:	loss/mlm_loss, 8.491410255432129, 705
[INFO] 2021-07-12 18:44:21,140 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.03999967299751e-06, 705
[INFO] 2021-07-12 18:44:21,140 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 705
[INFO] 2021-07-12 18:44:21,140 [run_pretraining.py:  558]:	worker_index: 3, step: 705, cost: 8.491410, mlm loss: 8.491410, speed: 1.086203 steps/s, speed: 8.689623 samples/s, speed: 4449.087007 tokens/s, learning rate: 7.040e-06, loss_scalings: 13421.773438, pp_loss: 8.517077
[INFO] 2021-07-12 18:44:21,140 [run_pretraining.py:  512]:	********exe.run_705******* 
[INFO] 2021-07-12 18:44:22,057 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:22,057 [run_pretraining.py:  534]:	loss/total_loss, 8.30228042602539, 706
[INFO] 2021-07-12 18:44:22,057 [run_pretraining.py:  535]:	loss/mlm_loss, 8.30228042602539, 706
[INFO] 2021-07-12 18:44:22,057 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.050000021990854e-06, 706
[INFO] 2021-07-12 18:44:22,057 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 706
[INFO] 2021-07-12 18:44:22,058 [run_pretraining.py:  558]:	worker_index: 3, step: 706, cost: 8.302280, mlm loss: 8.302280, speed: 1.091030 steps/s, speed: 8.728237 samples/s, speed: 4468.857234 tokens/s, learning rate: 7.050e-06, loss_scalings: 13421.773438, pp_loss: 8.541582
[INFO] 2021-07-12 18:44:22,058 [run_pretraining.py:  512]:	********exe.run_706******* 
[INFO] 2021-07-12 18:44:23,009 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:23,009 [run_pretraining.py:  534]:	loss/total_loss, 8.185237884521484, 707
[INFO] 2021-07-12 18:44:23,009 [run_pretraining.py:  535]:	loss/mlm_loss, 8.185237884521484, 707
[INFO] 2021-07-12 18:44:23,009 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.059999916236848e-06, 707
[INFO] 2021-07-12 18:44:23,010 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 707
[INFO] 2021-07-12 18:44:23,010 [run_pretraining.py:  558]:	worker_index: 3, step: 707, cost: 8.185238, mlm loss: 8.185238, speed: 1.051041 steps/s, speed: 8.408326 samples/s, speed: 4305.062668 tokens/s, learning rate: 7.060e-06, loss_scalings: 13421.773438, pp_loss: 8.218197
[INFO] 2021-07-12 18:44:23,010 [run_pretraining.py:  512]:	********exe.run_707******* 
[INFO] 2021-07-12 18:44:23,943 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:23,944 [run_pretraining.py:  534]:	loss/total_loss, 8.264936447143555, 708
[INFO] 2021-07-12 18:44:23,944 [run_pretraining.py:  535]:	loss/mlm_loss, 8.264936447143555, 708
[INFO] 2021-07-12 18:44:23,944 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.06999935573549e-06, 708
[INFO] 2021-07-12 18:44:23,944 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 708
[INFO] 2021-07-12 18:44:23,944 [run_pretraining.py:  558]:	worker_index: 3, step: 708, cost: 8.264936, mlm loss: 8.264936, speed: 1.071039 steps/s, speed: 8.568313 samples/s, speed: 4386.976450 tokens/s, learning rate: 7.070e-06, loss_scalings: 13421.773438, pp_loss: 8.390972
[INFO] 2021-07-12 18:44:23,944 [run_pretraining.py:  512]:	********exe.run_708******* 
[INFO] 2021-07-12 18:44:24,857 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:24,858 [run_pretraining.py:  534]:	loss/total_loss, 8.28219223022461, 709
[INFO] 2021-07-12 18:44:24,858 [run_pretraining.py:  535]:	loss/mlm_loss, 8.28219223022461, 709
[INFO] 2021-07-12 18:44:24,858 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.079999704728834e-06, 709
[INFO] 2021-07-12 18:44:24,858 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 709
[INFO] 2021-07-12 18:44:24,858 [run_pretraining.py:  558]:	worker_index: 3, step: 709, cost: 8.282192, mlm loss: 8.282192, speed: 1.094514 steps/s, speed: 8.756108 samples/s, speed: 4483.127520 tokens/s, learning rate: 7.080e-06, loss_scalings: 13421.773438, pp_loss: 8.233378
[INFO] 2021-07-12 18:44:24,858 [run_pretraining.py:  512]:	********exe.run_709******* 
[INFO] 2021-07-12 18:44:25,774 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:25,775 [run_pretraining.py:  534]:	loss/total_loss, 8.278797149658203, 710
[INFO] 2021-07-12 18:44:25,775 [run_pretraining.py:  535]:	loss/mlm_loss, 8.278797149658203, 710
[INFO] 2021-07-12 18:44:25,775 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.0900000537221786e-06, 710
[INFO] 2021-07-12 18:44:25,775 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 710
[INFO] 2021-07-12 18:44:25,775 [run_pretraining.py:  558]:	worker_index: 3, step: 710, cost: 8.278797, mlm loss: 8.278797, speed: 1.091707 steps/s, speed: 8.733655 samples/s, speed: 4471.631391 tokens/s, learning rate: 7.090e-06, loss_scalings: 13421.773438, pp_loss: 8.193234
[INFO] 2021-07-12 18:44:25,775 [run_pretraining.py:  512]:	********exe.run_710******* 
[INFO] 2021-07-12 18:44:26,694 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:26,695 [run_pretraining.py:  534]:	loss/total_loss, 8.203619956970215, 711
[INFO] 2021-07-12 18:44:26,695 [run_pretraining.py:  535]:	loss/mlm_loss, 8.203619956970215, 711
[INFO] 2021-07-12 18:44:26,695 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.099999947968172e-06, 711
[INFO] 2021-07-12 18:44:26,695 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 711
[INFO] 2021-07-12 18:44:26,695 [run_pretraining.py:  558]:	worker_index: 3, step: 711, cost: 8.203620, mlm loss: 8.203620, speed: 1.087602 steps/s, speed: 8.700813 samples/s, speed: 4454.816122 tokens/s, learning rate: 7.100e-06, loss_scalings: 13421.773438, pp_loss: 8.230228
[INFO] 2021-07-12 18:44:26,695 [run_pretraining.py:  512]:	********exe.run_711******* 
[INFO] 2021-07-12 18:44:27,615 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:27,616 [run_pretraining.py:  534]:	loss/total_loss, 7.96194314956665, 712
[INFO] 2021-07-12 18:44:27,616 [run_pretraining.py:  535]:	loss/mlm_loss, 7.96194314956665, 712
[INFO] 2021-07-12 18:44:27,616 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.109999387466814e-06, 712
[INFO] 2021-07-12 18:44:27,616 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 712
[INFO] 2021-07-12 18:44:27,616 [run_pretraining.py:  558]:	worker_index: 3, step: 712, cost: 7.961943, mlm loss: 7.961943, speed: 1.086319 steps/s, speed: 8.690548 samples/s, speed: 4449.560605 tokens/s, learning rate: 7.110e-06, loss_scalings: 13421.773438, pp_loss: 8.006080
[INFO] 2021-07-12 18:44:27,616 [run_pretraining.py:  512]:	********exe.run_712******* 
[INFO] 2021-07-12 18:44:28,572 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:28,572 [run_pretraining.py:  534]:	loss/total_loss, 8.51569652557373, 713
[INFO] 2021-07-12 18:44:28,572 [run_pretraining.py:  535]:	loss/mlm_loss, 8.51569652557373, 713
[INFO] 2021-07-12 18:44:28,572 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.119999736460159e-06, 713
[INFO] 2021-07-12 18:44:28,572 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 713
[INFO] 2021-07-12 18:44:28,573 [run_pretraining.py:  558]:	worker_index: 3, step: 713, cost: 8.515697, mlm loss: 8.515697, speed: 1.046258 steps/s, speed: 8.370066 samples/s, speed: 4285.473900 tokens/s, learning rate: 7.120e-06, loss_scalings: 13421.773438, pp_loss: 8.415462
[INFO] 2021-07-12 18:44:28,573 [run_pretraining.py:  512]:	********exe.run_713******* 
[INFO] 2021-07-12 18:44:29,646 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:29,646 [run_pretraining.py:  534]:	loss/total_loss, 8.151028633117676, 714
[INFO] 2021-07-12 18:44:29,646 [run_pretraining.py:  535]:	loss/mlm_loss, 8.151028633117676, 714
[INFO] 2021-07-12 18:44:29,646 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.129999630706152e-06, 714
[INFO] 2021-07-12 18:44:29,646 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 714
[INFO] 2021-07-12 18:44:29,646 [run_pretraining.py:  558]:	worker_index: 3, step: 714, cost: 8.151029, mlm loss: 8.151029, speed: 0.931806 steps/s, speed: 7.454445 samples/s, speed: 3816.675798 tokens/s, learning rate: 7.130e-06, loss_scalings: 13421.773438, pp_loss: 7.525271
[INFO] 2021-07-12 18:44:29,646 [run_pretraining.py:  512]:	********exe.run_714******* 
[INFO] 2021-07-12 18:44:30,725 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:30,726 [run_pretraining.py:  534]:	loss/total_loss, 8.325387001037598, 715
[INFO] 2021-07-12 18:44:30,726 [run_pretraining.py:  535]:	loss/mlm_loss, 8.325387001037598, 715
[INFO] 2021-07-12 18:44:30,726 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.139999979699496e-06, 715
[INFO] 2021-07-12 18:44:30,726 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 715
[INFO] 2021-07-12 18:44:30,726 [run_pretraining.py:  558]:	worker_index: 3, step: 715, cost: 8.325387, mlm loss: 8.325387, speed: 0.926568 steps/s, speed: 7.412548 samples/s, speed: 3795.224472 tokens/s, learning rate: 7.140e-06, loss_scalings: 13421.773438, pp_loss: 8.296254
[INFO] 2021-07-12 18:44:30,726 [run_pretraining.py:  512]:	********exe.run_715******* 
[INFO] 2021-07-12 18:44:31,787 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:31,787 [run_pretraining.py:  534]:	loss/total_loss, 8.50537395477295, 716
[INFO] 2021-07-12 18:44:31,788 [run_pretraining.py:  535]:	loss/mlm_loss, 8.50537395477295, 716
[INFO] 2021-07-12 18:44:31,788 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.15000032869284e-06, 716
[INFO] 2021-07-12 18:44:31,788 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 716
[INFO] 2021-07-12 18:44:31,788 [run_pretraining.py:  558]:	worker_index: 3, step: 716, cost: 8.505374, mlm loss: 8.505374, speed: 0.942679 steps/s, speed: 7.541432 samples/s, speed: 3861.213096 tokens/s, learning rate: 7.150e-06, loss_scalings: 13421.773438, pp_loss: 8.549185
[INFO] 2021-07-12 18:44:31,788 [run_pretraining.py:  512]:	********exe.run_716******* 
[INFO] 2021-07-12 18:44:32,854 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:32,855 [run_pretraining.py:  534]:	loss/total_loss, 8.688036918640137, 717
[INFO] 2021-07-12 18:44:32,855 [run_pretraining.py:  535]:	loss/mlm_loss, 8.688036918640137, 717
[INFO] 2021-07-12 18:44:32,855 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.159999768191483e-06, 717
[INFO] 2021-07-12 18:44:32,855 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 717
[INFO] 2021-07-12 18:44:32,855 [run_pretraining.py:  558]:	worker_index: 3, step: 717, cost: 8.688037, mlm loss: 8.688037, speed: 0.937584 steps/s, speed: 7.500673 samples/s, speed: 3840.344441 tokens/s, learning rate: 7.160e-06, loss_scalings: 13421.773438, pp_loss: 8.700576
[INFO] 2021-07-12 18:44:32,855 [run_pretraining.py:  512]:	********exe.run_717******* 
[INFO] 2021-07-12 18:44:33,920 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:33,920 [run_pretraining.py:  534]:	loss/total_loss, 8.458982467651367, 718
[INFO] 2021-07-12 18:44:33,920 [run_pretraining.py:  535]:	loss/mlm_loss, 8.458982467651367, 718
[INFO] 2021-07-12 18:44:33,921 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.169999662437476e-06, 718
[INFO] 2021-07-12 18:44:33,921 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 718
[INFO] 2021-07-12 18:44:33,921 [run_pretraining.py:  558]:	worker_index: 3, step: 718, cost: 8.458982, mlm loss: 8.458982, speed: 0.938888 steps/s, speed: 7.511108 samples/s, speed: 3845.687198 tokens/s, learning rate: 7.170e-06, loss_scalings: 13421.773438, pp_loss: 8.153636
[INFO] 2021-07-12 18:44:33,921 [run_pretraining.py:  512]:	********exe.run_718******* 
[INFO] 2021-07-12 18:44:34,989 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:34,990 [run_pretraining.py:  534]:	loss/total_loss, 8.335527420043945, 719
[INFO] 2021-07-12 18:44:34,990 [run_pretraining.py:  535]:	loss/mlm_loss, 8.335527420043945, 719
[INFO] 2021-07-12 18:44:34,990 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.1800000114308205e-06, 719
[INFO] 2021-07-12 18:44:34,990 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 719
[INFO] 2021-07-12 18:44:34,990 [run_pretraining.py:  558]:	worker_index: 3, step: 719, cost: 8.335527, mlm loss: 8.335527, speed: 0.935604 steps/s, speed: 7.484830 samples/s, speed: 3832.232844 tokens/s, learning rate: 7.180e-06, loss_scalings: 13421.773438, pp_loss: 8.182215
[INFO] 2021-07-12 18:44:34,990 [run_pretraining.py:  512]:	********exe.run_719******* 
[INFO] 2021-07-12 18:44:36,060 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:36,061 [run_pretraining.py:  534]:	loss/total_loss, 8.134156227111816, 720
[INFO] 2021-07-12 18:44:36,061 [run_pretraining.py:  535]:	loss/mlm_loss, 8.134156227111816, 720
[INFO] 2021-07-12 18:44:36,061 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.189999905676814e-06, 720
[INFO] 2021-07-12 18:44:36,061 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 720
[INFO] 2021-07-12 18:44:36,061 [run_pretraining.py:  558]:	worker_index: 3, step: 720, cost: 8.134156, mlm loss: 8.134156, speed: 0.934163 steps/s, speed: 7.473307 samples/s, speed: 3826.333299 tokens/s, learning rate: 7.190e-06, loss_scalings: 13421.773438, pp_loss: 8.520658
[INFO] 2021-07-12 18:44:36,061 [run_pretraining.py:  512]:	********exe.run_720******* 
[INFO] 2021-07-12 18:44:37,130 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:37,131 [run_pretraining.py:  534]:	loss/total_loss, 8.292119979858398, 721
[INFO] 2021-07-12 18:44:37,131 [run_pretraining.py:  535]:	loss/mlm_loss, 8.292119979858398, 721
[INFO] 2021-07-12 18:44:37,131 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.199999345175456e-06, 721
[INFO] 2021-07-12 18:44:37,131 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 721
[INFO] 2021-07-12 18:44:37,131 [run_pretraining.py:  558]:	worker_index: 3, step: 721, cost: 8.292120, mlm loss: 8.292120, speed: 0.935185 steps/s, speed: 7.481479 samples/s, speed: 3830.517098 tokens/s, learning rate: 7.200e-06, loss_scalings: 13421.773438, pp_loss: 8.290182
[INFO] 2021-07-12 18:44:37,131 [run_pretraining.py:  512]:	********exe.run_721******* 
[INFO] 2021-07-12 18:44:38,212 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:38,212 [run_pretraining.py:  534]:	loss/total_loss, 8.056924819946289, 722
[INFO] 2021-07-12 18:44:38,212 [run_pretraining.py:  535]:	loss/mlm_loss, 8.056924819946289, 722
[INFO] 2021-07-12 18:44:38,212 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.2099996941688005e-06, 722
[INFO] 2021-07-12 18:44:38,212 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 722
[INFO] 2021-07-12 18:44:38,212 [run_pretraining.py:  558]:	worker_index: 3, step: 722, cost: 8.056925, mlm loss: 8.056925, speed: 0.925430 steps/s, speed: 7.403438 samples/s, speed: 3790.560282 tokens/s, learning rate: 7.210e-06, loss_scalings: 13421.773438, pp_loss: 8.088321
[INFO] 2021-07-12 18:44:38,213 [run_pretraining.py:  512]:	********exe.run_722******* 
[INFO] 2021-07-12 18:44:39,330 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:39,331 [run_pretraining.py:  534]:	loss/total_loss, 8.655313491821289, 723
[INFO] 2021-07-12 18:44:39,331 [run_pretraining.py:  535]:	loss/mlm_loss, 8.655313491821289, 723
[INFO] 2021-07-12 18:44:39,331 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.220000043162145e-06, 723
[INFO] 2021-07-12 18:44:39,331 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 723
[INFO] 2021-07-12 18:44:39,331 [run_pretraining.py:  558]:	worker_index: 3, step: 723, cost: 8.655313, mlm loss: 8.655313, speed: 0.894400 steps/s, speed: 7.155202 samples/s, speed: 3663.463177 tokens/s, learning rate: 7.220e-06, loss_scalings: 13421.773438, pp_loss: 8.781473
[INFO] 2021-07-12 18:44:39,331 [run_pretraining.py:  512]:	********exe.run_723******* 
[INFO] 2021-07-12 18:44:40,392 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:40,393 [run_pretraining.py:  534]:	loss/total_loss, 8.68522834777832, 724
[INFO] 2021-07-12 18:44:40,393 [run_pretraining.py:  535]:	loss/mlm_loss, 8.68522834777832, 724
[INFO] 2021-07-12 18:44:40,393 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.229999937408138e-06, 724
[INFO] 2021-07-12 18:44:40,393 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 724
[INFO] 2021-07-12 18:44:40,393 [run_pretraining.py:  558]:	worker_index: 3, step: 724, cost: 8.685228, mlm loss: 8.685228, speed: 0.942246 steps/s, speed: 7.537969 samples/s, speed: 3859.440095 tokens/s, learning rate: 7.230e-06, loss_scalings: 13421.773438, pp_loss: 8.494658
[INFO] 2021-07-12 18:44:40,393 [run_pretraining.py:  512]:	********exe.run_724******* 
[INFO] 2021-07-12 18:44:41,465 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:41,466 [run_pretraining.py:  534]:	loss/total_loss, 8.446449279785156, 725
[INFO] 2021-07-12 18:44:41,466 [run_pretraining.py:  535]:	loss/mlm_loss, 8.446449279785156, 725
[INFO] 2021-07-12 18:44:41,466 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.240000286401482e-06, 725
[INFO] 2021-07-12 18:44:41,466 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 725
[INFO] 2021-07-12 18:44:41,466 [run_pretraining.py:  558]:	worker_index: 3, step: 725, cost: 8.446449, mlm loss: 8.446449, speed: 0.932663 steps/s, speed: 7.461304 samples/s, speed: 3820.187685 tokens/s, learning rate: 7.240e-06, loss_scalings: 13421.773438, pp_loss: 7.692076
[INFO] 2021-07-12 18:44:41,466 [run_pretraining.py:  512]:	********exe.run_725******* 
[INFO] 2021-07-12 18:44:42,525 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:42,525 [run_pretraining.py:  534]:	loss/total_loss, 7.929094314575195, 726
[INFO] 2021-07-12 18:44:42,525 [run_pretraining.py:  535]:	loss/mlm_loss, 7.929094314575195, 726
[INFO] 2021-07-12 18:44:42,526 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.249999725900125e-06, 726
[INFO] 2021-07-12 18:44:42,526 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 726
[INFO] 2021-07-12 18:44:42,526 [run_pretraining.py:  558]:	worker_index: 3, step: 726, cost: 7.929094, mlm loss: 7.929094, speed: 0.944231 steps/s, speed: 7.553849 samples/s, speed: 3867.570754 tokens/s, learning rate: 7.250e-06, loss_scalings: 13421.773438, pp_loss: 8.327452
[INFO] 2021-07-12 18:44:42,526 [run_pretraining.py:  512]:	********exe.run_726******* 
[INFO] 2021-07-12 18:44:43,584 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:43,585 [run_pretraining.py:  534]:	loss/total_loss, 8.465362548828125, 727
[INFO] 2021-07-12 18:44:43,585 [run_pretraining.py:  535]:	loss/mlm_loss, 8.465362548828125, 727
[INFO] 2021-07-12 18:44:43,585 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.259999620146118e-06, 727
[INFO] 2021-07-12 18:44:43,585 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 727
[INFO] 2021-07-12 18:44:43,585 [run_pretraining.py:  558]:	worker_index: 3, step: 727, cost: 8.465363, mlm loss: 8.465363, speed: 0.944445 steps/s, speed: 7.555564 samples/s, speed: 3868.448595 tokens/s, learning rate: 7.260e-06, loss_scalings: 13421.773438, pp_loss: 8.278623
[INFO] 2021-07-12 18:44:43,585 [run_pretraining.py:  512]:	********exe.run_727******* 
[INFO] 2021-07-12 18:44:44,631 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:44,632 [run_pretraining.py:  534]:	loss/total_loss, 8.61751937866211, 728
[INFO] 2021-07-12 18:44:44,632 [run_pretraining.py:  535]:	loss/mlm_loss, 8.61751937866211, 728
[INFO] 2021-07-12 18:44:44,632 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.269999969139462e-06, 728
[INFO] 2021-07-12 18:44:44,632 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 728
[INFO] 2021-07-12 18:44:44,632 [run_pretraining.py:  558]:	worker_index: 3, step: 728, cost: 8.617519, mlm loss: 8.617519, speed: 0.955569 steps/s, speed: 7.644551 samples/s, speed: 3914.009866 tokens/s, learning rate: 7.270e-06, loss_scalings: 13421.773438, pp_loss: 8.292290
[INFO] 2021-07-12 18:44:44,632 [run_pretraining.py:  512]:	********exe.run_728******* 
[INFO] 2021-07-12 18:44:45,692 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:45,692 [run_pretraining.py:  534]:	loss/total_loss, 8.715890884399414, 729
[INFO] 2021-07-12 18:44:45,692 [run_pretraining.py:  535]:	loss/mlm_loss, 8.715890884399414, 729
[INFO] 2021-07-12 18:44:45,692 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.2800003181328066e-06, 729
[INFO] 2021-07-12 18:44:45,692 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 729
[INFO] 2021-07-12 18:44:45,692 [run_pretraining.py:  558]:	worker_index: 3, step: 729, cost: 8.715891, mlm loss: 8.715891, speed: 0.943845 steps/s, speed: 7.550764 samples/s, speed: 3865.991122 tokens/s, learning rate: 7.280e-06, loss_scalings: 13421.773438, pp_loss: 8.445391
[INFO] 2021-07-12 18:44:45,692 [run_pretraining.py:  512]:	********exe.run_729******* 
[INFO] 2021-07-12 18:44:46,761 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:46,761 [run_pretraining.py:  534]:	loss/total_loss, 8.75214958190918, 730
[INFO] 2021-07-12 18:44:46,762 [run_pretraining.py:  535]:	loss/mlm_loss, 8.75214958190918, 730
[INFO] 2021-07-12 18:44:46,762 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.289999757631449e-06, 730
[INFO] 2021-07-12 18:44:46,762 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 730
[INFO] 2021-07-12 18:44:46,762 [run_pretraining.py:  558]:	worker_index: 3, step: 730, cost: 8.752150, mlm loss: 8.752150, speed: 0.935612 steps/s, speed: 7.484898 samples/s, speed: 3832.267893 tokens/s, learning rate: 7.290e-06, loss_scalings: 13421.773438, pp_loss: 8.343536
[INFO] 2021-07-12 18:44:46,762 [run_pretraining.py:  512]:	********exe.run_730******* 
[INFO] 2021-07-12 18:44:47,825 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:47,826 [run_pretraining.py:  534]:	loss/total_loss, 5.167237758636475, 731
[INFO] 2021-07-12 18:44:47,826 [run_pretraining.py:  535]:	loss/mlm_loss, 5.167237758636475, 731
[INFO] 2021-07-12 18:44:47,826 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.299999651877442e-06, 731
[INFO] 2021-07-12 18:44:47,826 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 731
[INFO] 2021-07-12 18:44:47,826 [run_pretraining.py:  558]:	worker_index: 3, step: 731, cost: 5.167238, mlm loss: 5.167238, speed: 0.940285 steps/s, speed: 7.522282 samples/s, speed: 3851.408304 tokens/s, learning rate: 7.300e-06, loss_scalings: 13421.773438, pp_loss: 7.678653
[INFO] 2021-07-12 18:44:47,826 [run_pretraining.py:  512]:	********exe.run_731******* 
[INFO] 2021-07-12 18:44:48,888 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:48,888 [run_pretraining.py:  534]:	loss/total_loss, 8.177672386169434, 732
[INFO] 2021-07-12 18:44:48,888 [run_pretraining.py:  535]:	loss/mlm_loss, 8.177672386169434, 732
[INFO] 2021-07-12 18:44:48,888 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.310000000870787e-06, 732
[INFO] 2021-07-12 18:44:48,889 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 732
[INFO] 2021-07-12 18:44:48,889 [run_pretraining.py:  558]:	worker_index: 3, step: 732, cost: 8.177672, mlm loss: 8.177672, speed: 0.941615 steps/s, speed: 7.532919 samples/s, speed: 3856.854642 tokens/s, learning rate: 7.310e-06, loss_scalings: 13421.773438, pp_loss: 8.131447
[INFO] 2021-07-12 18:44:48,889 [run_pretraining.py:  512]:	********exe.run_732******* 
[INFO] 2021-07-12 18:44:49,962 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:49,963 [run_pretraining.py:  534]:	loss/total_loss, 8.583760261535645, 733
[INFO] 2021-07-12 18:44:49,963 [run_pretraining.py:  535]:	loss/mlm_loss, 8.583760261535645, 733
[INFO] 2021-07-12 18:44:49,963 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.31999989511678e-06, 733
[INFO] 2021-07-12 18:44:49,963 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 733
[INFO] 2021-07-12 18:44:49,963 [run_pretraining.py:  558]:	worker_index: 3, step: 733, cost: 8.583760, mlm loss: 8.583760, speed: 0.931350 steps/s, speed: 7.450798 samples/s, speed: 3814.808762 tokens/s, learning rate: 7.320e-06, loss_scalings: 13421.773438, pp_loss: 7.862323
[INFO] 2021-07-12 18:44:49,963 [run_pretraining.py:  512]:	********exe.run_733******* 
[INFO] 2021-07-12 18:44:51,036 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:51,036 [run_pretraining.py:  534]:	loss/total_loss, 7.763113975524902, 734
[INFO] 2021-07-12 18:44:51,036 [run_pretraining.py:  535]:	loss/mlm_loss, 7.763113975524902, 734
[INFO] 2021-07-12 18:44:51,036 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.329999334615422e-06, 734
[INFO] 2021-07-12 18:44:51,036 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 734
[INFO] 2021-07-12 18:44:51,036 [run_pretraining.py:  558]:	worker_index: 3, step: 734, cost: 7.763114, mlm loss: 7.763114, speed: 0.932170 steps/s, speed: 7.457361 samples/s, speed: 3818.168706 tokens/s, learning rate: 7.330e-06, loss_scalings: 13421.773438, pp_loss: 8.172038
[INFO] 2021-07-12 18:44:51,036 [run_pretraining.py:  512]:	********exe.run_734******* 
[INFO] 2021-07-12 18:44:52,076 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:52,076 [run_pretraining.py:  534]:	loss/total_loss, 8.06992244720459, 735
[INFO] 2021-07-12 18:44:52,076 [run_pretraining.py:  535]:	loss/mlm_loss, 8.06992244720459, 735
[INFO] 2021-07-12 18:44:52,076 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.339999683608767e-06, 735
[INFO] 2021-07-12 18:44:52,076 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 735
[INFO] 2021-07-12 18:44:52,077 [run_pretraining.py:  558]:	worker_index: 3, step: 735, cost: 8.069922, mlm loss: 8.069922, speed: 0.961926 steps/s, speed: 7.695409 samples/s, speed: 3940.049598 tokens/s, learning rate: 7.340e-06, loss_scalings: 13421.773438, pp_loss: 8.440287
[INFO] 2021-07-12 18:44:52,077 [run_pretraining.py:  512]:	********exe.run_735******* 
[INFO] 2021-07-12 18:44:52,990 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:52,990 [run_pretraining.py:  534]:	loss/total_loss, 8.300775527954102, 736
[INFO] 2021-07-12 18:44:52,990 [run_pretraining.py:  535]:	loss/mlm_loss, 8.300775527954102, 736
[INFO] 2021-07-12 18:44:52,991 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.350000032602111e-06, 736
[INFO] 2021-07-12 18:44:52,991 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 736
[INFO] 2021-07-12 18:44:52,991 [run_pretraining.py:  558]:	worker_index: 3, step: 736, cost: 8.300776, mlm loss: 8.300776, speed: 1.094738 steps/s, speed: 8.757905 samples/s, speed: 4484.047237 tokens/s, learning rate: 7.350e-06, loss_scalings: 13421.773438, pp_loss: 8.547704
[INFO] 2021-07-12 18:44:52,991 [run_pretraining.py:  512]:	********exe.run_736******* 
[INFO] 2021-07-12 18:44:53,908 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:53,908 [run_pretraining.py:  534]:	loss/total_loss, 8.206430435180664, 737
[INFO] 2021-07-12 18:44:53,908 [run_pretraining.py:  535]:	loss/mlm_loss, 8.206430435180664, 737
[INFO] 2021-07-12 18:44:53,908 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.359999926848104e-06, 737
[INFO] 2021-07-12 18:44:53,908 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 737
[INFO] 2021-07-12 18:44:53,908 [run_pretraining.py:  558]:	worker_index: 3, step: 737, cost: 8.206430, mlm loss: 8.206430, speed: 1.090297 steps/s, speed: 8.722374 samples/s, speed: 4465.855489 tokens/s, learning rate: 7.360e-06, loss_scalings: 13421.773438, pp_loss: 8.258562
[INFO] 2021-07-12 18:44:53,909 [run_pretraining.py:  512]:	********exe.run_737******* 
[INFO] 2021-07-12 18:44:54,818 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:54,818 [run_pretraining.py:  534]:	loss/total_loss, 8.419509887695312, 738
[INFO] 2021-07-12 18:44:54,818 [run_pretraining.py:  535]:	loss/mlm_loss, 8.419509887695312, 738
[INFO] 2021-07-12 18:44:54,818 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.3700002758414485e-06, 738
[INFO] 2021-07-12 18:44:54,819 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 738
[INFO] 2021-07-12 18:44:54,819 [run_pretraining.py:  558]:	worker_index: 3, step: 738, cost: 8.419510, mlm loss: 8.419510, speed: 1.099481 steps/s, speed: 8.795847 samples/s, speed: 4503.473621 tokens/s, learning rate: 7.370e-06, loss_scalings: 13421.773438, pp_loss: 8.311418
[INFO] 2021-07-12 18:44:54,819 [run_pretraining.py:  512]:	********exe.run_738******* 
[INFO] 2021-07-12 18:44:55,732 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:55,732 [run_pretraining.py:  534]:	loss/total_loss, 8.586886405944824, 739
[INFO] 2021-07-12 18:44:55,732 [run_pretraining.py:  535]:	loss/mlm_loss, 8.586886405944824, 739
[INFO] 2021-07-12 18:44:55,732 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.379999715340091e-06, 739
[INFO] 2021-07-12 18:44:55,732 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 739
[INFO] 2021-07-12 18:44:55,733 [run_pretraining.py:  558]:	worker_index: 3, step: 739, cost: 8.586886, mlm loss: 8.586886, speed: 1.094957 steps/s, speed: 8.759658 samples/s, speed: 4484.945085 tokens/s, learning rate: 7.380e-06, loss_scalings: 13421.773438, pp_loss: 8.253563
[INFO] 2021-07-12 18:44:55,733 [run_pretraining.py:  512]:	********exe.run_739******* 
[INFO] 2021-07-12 18:44:56,647 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:56,647 [run_pretraining.py:  534]:	loss/total_loss, 8.711982727050781, 740
[INFO] 2021-07-12 18:44:56,647 [run_pretraining.py:  535]:	loss/mlm_loss, 8.711982727050781, 740
[INFO] 2021-07-12 18:44:56,647 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.389999609586084e-06, 740
[INFO] 2021-07-12 18:44:56,647 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 740
[INFO] 2021-07-12 18:44:56,648 [run_pretraining.py:  558]:	worker_index: 3, step: 740, cost: 8.711983, mlm loss: 8.711983, speed: 1.093715 steps/s, speed: 8.749722 samples/s, speed: 4479.857745 tokens/s, learning rate: 7.390e-06, loss_scalings: 13421.773438, pp_loss: 8.825869
[INFO] 2021-07-12 18:44:56,648 [run_pretraining.py:  512]:	********exe.run_740******* 
[INFO] 2021-07-12 18:44:57,562 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:57,563 [run_pretraining.py:  534]:	loss/total_loss, 8.49376106262207, 741
[INFO] 2021-07-12 18:44:57,563 [run_pretraining.py:  535]:	loss/mlm_loss, 8.49376106262207, 741
[INFO] 2021-07-12 18:44:57,563 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.3999999585794285e-06, 741
[INFO] 2021-07-12 18:44:57,563 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 741
[INFO] 2021-07-12 18:44:57,563 [run_pretraining.py:  558]:	worker_index: 3, step: 741, cost: 8.493761, mlm loss: 8.493761, speed: 1.093043 steps/s, speed: 8.744341 samples/s, speed: 4477.102543 tokens/s, learning rate: 7.400e-06, loss_scalings: 13421.773438, pp_loss: 8.262030
[INFO] 2021-07-12 18:44:57,563 [run_pretraining.py:  512]:	********exe.run_741******* 
[INFO] 2021-07-12 18:44:58,475 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:58,476 [run_pretraining.py:  534]:	loss/total_loss, 8.552803039550781, 742
[INFO] 2021-07-12 18:44:58,476 [run_pretraining.py:  535]:	loss/mlm_loss, 8.552803039550781, 742
[INFO] 2021-07-12 18:44:58,476 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.409999852825422e-06, 742
[INFO] 2021-07-12 18:44:58,476 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 742
[INFO] 2021-07-12 18:44:58,476 [run_pretraining.py:  558]:	worker_index: 3, step: 742, cost: 8.552803, mlm loss: 8.552803, speed: 1.095629 steps/s, speed: 8.765036 samples/s, speed: 4487.698228 tokens/s, learning rate: 7.410e-06, loss_scalings: 13421.773438, pp_loss: 8.436582
[INFO] 2021-07-12 18:44:58,476 [run_pretraining.py:  512]:	********exe.run_742******* 
[INFO] 2021-07-12 18:44:59,387 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:59,387 [run_pretraining.py:  534]:	loss/total_loss, 8.300050735473633, 743
[INFO] 2021-07-12 18:44:59,387 [run_pretraining.py:  535]:	loss/mlm_loss, 8.300050735473633, 743
[INFO] 2021-07-12 18:44:59,387 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.419999292324064e-06, 743
[INFO] 2021-07-12 18:44:59,388 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 743
[INFO] 2021-07-12 18:44:59,388 [run_pretraining.py:  558]:	worker_index: 3, step: 743, cost: 8.300051, mlm loss: 8.300051, speed: 1.098206 steps/s, speed: 8.785649 samples/s, speed: 4498.252315 tokens/s, learning rate: 7.420e-06, loss_scalings: 13421.773438, pp_loss: 8.647664
[INFO] 2021-07-12 18:44:59,388 [run_pretraining.py:  512]:	********exe.run_743******* 
[INFO] 2021-07-12 18:45:00,299 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:00,299 [run_pretraining.py:  534]:	loss/total_loss, 7.994228363037109, 744
[INFO] 2021-07-12 18:45:00,299 [run_pretraining.py:  535]:	loss/mlm_loss, 7.994228363037109, 744
[INFO] 2021-07-12 18:45:00,300 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.4299996413174085e-06, 744
[INFO] 2021-07-12 18:45:00,300 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 744
[INFO] 2021-07-12 18:45:00,300 [run_pretraining.py:  558]:	worker_index: 3, step: 744, cost: 7.994228, mlm loss: 7.994228, speed: 1.097256 steps/s, speed: 8.778046 samples/s, speed: 4494.359558 tokens/s, learning rate: 7.430e-06, loss_scalings: 13421.773438, pp_loss: 8.038741
[INFO] 2021-07-12 18:45:00,300 [run_pretraining.py:  512]:	********exe.run_744******* 
[INFO] 2021-07-12 18:45:01,219 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:01,220 [run_pretraining.py:  534]:	loss/total_loss, 8.396430969238281, 745
[INFO] 2021-07-12 18:45:01,220 [run_pretraining.py:  535]:	loss/mlm_loss, 8.396430969238281, 745
[INFO] 2021-07-12 18:45:01,220 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.439999990310753e-06, 745
[INFO] 2021-07-12 18:45:01,220 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 745
[INFO] 2021-07-12 18:45:01,220 [run_pretraining.py:  558]:	worker_index: 3, step: 745, cost: 8.396431, mlm loss: 8.396431, speed: 1.087055 steps/s, speed: 8.696440 samples/s, speed: 4452.577405 tokens/s, learning rate: 7.440e-06, loss_scalings: 13421.773438, pp_loss: 8.512888
[INFO] 2021-07-12 18:45:01,220 [run_pretraining.py:  512]:	********exe.run_745******* 
[INFO] 2021-07-12 18:45:02,134 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:02,135 [run_pretraining.py:  534]:	loss/total_loss, 8.252371788024902, 746
[INFO] 2021-07-12 18:45:02,135 [run_pretraining.py:  535]:	loss/mlm_loss, 8.252371788024902, 746
[INFO] 2021-07-12 18:45:02,135 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.449999884556746e-06, 746
[INFO] 2021-07-12 18:45:02,135 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 746
[INFO] 2021-07-12 18:45:02,135 [run_pretraining.py:  558]:	worker_index: 3, step: 746, cost: 8.252372, mlm loss: 8.252372, speed: 1.093854 steps/s, speed: 8.750829 samples/s, speed: 4480.424382 tokens/s, learning rate: 7.450e-06, loss_scalings: 13421.773438, pp_loss: 8.406931
[INFO] 2021-07-12 18:45:02,135 [run_pretraining.py:  512]:	********exe.run_746******* 
[INFO] 2021-07-12 18:45:03,046 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:03,047 [run_pretraining.py:  534]:	loss/total_loss, 8.351953506469727, 747
[INFO] 2021-07-12 18:45:03,047 [run_pretraining.py:  535]:	loss/mlm_loss, 8.351953506469727, 747
[INFO] 2021-07-12 18:45:03,047 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.46000023355009e-06, 747
[INFO] 2021-07-12 18:45:03,047 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 747
[INFO] 2021-07-12 18:45:03,047 [run_pretraining.py:  558]:	worker_index: 3, step: 747, cost: 8.351954, mlm loss: 8.351954, speed: 1.097266 steps/s, speed: 8.778129 samples/s, speed: 4494.401885 tokens/s, learning rate: 7.460e-06, loss_scalings: 13421.773438, pp_loss: 8.247567
[INFO] 2021-07-12 18:45:03,047 [run_pretraining.py:  512]:	********exe.run_747******* 
[INFO] 2021-07-12 18:45:03,971 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:03,971 [run_pretraining.py:  534]:	loss/total_loss, 8.651815414428711, 748
[INFO] 2021-07-12 18:45:03,971 [run_pretraining.py:  535]:	loss/mlm_loss, 8.651815414428711, 748
[INFO] 2021-07-12 18:45:03,971 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.469999673048733e-06, 748
[INFO] 2021-07-12 18:45:03,972 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 748
[INFO] 2021-07-12 18:45:03,972 [run_pretraining.py:  558]:	worker_index: 3, step: 748, cost: 8.651815, mlm loss: 8.651815, speed: 1.082293 steps/s, speed: 8.658344 samples/s, speed: 4433.071893 tokens/s, learning rate: 7.470e-06, loss_scalings: 13421.773438, pp_loss: 8.804480
[INFO] 2021-07-12 18:45:03,972 [run_pretraining.py:  512]:	********exe.run_748******* 
[INFO] 2021-07-12 18:45:04,886 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:04,887 [run_pretraining.py:  534]:	loss/total_loss, 8.257484436035156, 749
[INFO] 2021-07-12 18:45:04,887 [run_pretraining.py:  535]:	loss/mlm_loss, 8.257484436035156, 749
[INFO] 2021-07-12 18:45:04,887 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.479999567294726e-06, 749
[INFO] 2021-07-12 18:45:04,887 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 749
[INFO] 2021-07-12 18:45:04,887 [run_pretraining.py:  558]:	worker_index: 3, step: 749, cost: 8.257484, mlm loss: 8.257484, speed: 1.093415 steps/s, speed: 8.747320 samples/s, speed: 4478.627992 tokens/s, learning rate: 7.480e-06, loss_scalings: 13421.773438, pp_loss: 8.298895
[INFO] 2021-07-12 18:45:04,887 [run_pretraining.py:  512]:	********exe.run_749******* 
[INFO] 2021-07-12 18:45:05,796 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:05,796 [run_pretraining.py:  534]:	loss/total_loss, 8.284189224243164, 750
[INFO] 2021-07-12 18:45:05,796 [run_pretraining.py:  535]:	loss/mlm_loss, 8.284189224243164, 750
[INFO] 2021-07-12 18:45:05,796 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.48999991628807e-06, 750
[INFO] 2021-07-12 18:45:05,796 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 750
[INFO] 2021-07-12 18:45:05,796 [run_pretraining.py:  558]:	worker_index: 3, step: 750, cost: 8.284189, mlm loss: 8.284189, speed: 1.100223 steps/s, speed: 8.801781 samples/s, speed: 4506.511981 tokens/s, learning rate: 7.490e-06, loss_scalings: 13421.773438, pp_loss: 8.746531
[INFO] 2021-07-12 18:45:05,796 [run_pretraining.py:  512]:	********exe.run_750******* 
[INFO] 2021-07-12 18:45:06,706 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:06,707 [run_pretraining.py:  534]:	loss/total_loss, 8.52949047088623, 751
[INFO] 2021-07-12 18:45:06,707 [run_pretraining.py:  535]:	loss/mlm_loss, 8.52949047088623, 751
[INFO] 2021-07-12 18:45:06,707 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.500000265281415e-06, 751
[INFO] 2021-07-12 18:45:06,707 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 751
[INFO] 2021-07-12 18:45:06,707 [run_pretraining.py:  558]:	worker_index: 3, step: 751, cost: 8.529490, mlm loss: 8.529490, speed: 1.098934 steps/s, speed: 8.791468 samples/s, speed: 4501.231739 tokens/s, learning rate: 7.500e-06, loss_scalings: 13421.773438, pp_loss: 8.629330
[INFO] 2021-07-12 18:45:06,707 [run_pretraining.py:  512]:	********exe.run_751******* 
[INFO] 2021-07-12 18:45:07,618 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:07,618 [run_pretraining.py:  534]:	loss/total_loss, 8.574166297912598, 752
[INFO] 2021-07-12 18:45:07,618 [run_pretraining.py:  535]:	loss/mlm_loss, 8.574166297912598, 752
[INFO] 2021-07-12 18:45:07,619 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.509999704780057e-06, 752
[INFO] 2021-07-12 18:45:07,619 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 752
[INFO] 2021-07-12 18:45:07,619 [run_pretraining.py:  558]:	worker_index: 3, step: 752, cost: 8.574166, mlm loss: 8.574166, speed: 1.097618 steps/s, speed: 8.780943 samples/s, speed: 4495.842670 tokens/s, learning rate: 7.510e-06, loss_scalings: 13421.773438, pp_loss: 8.376013
[INFO] 2021-07-12 18:45:07,619 [run_pretraining.py:  512]:	********exe.run_752******* 
[INFO] 2021-07-12 18:45:08,523 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:08,523 [run_pretraining.py:  534]:	loss/total_loss, 8.449946403503418, 753
[INFO] 2021-07-12 18:45:08,524 [run_pretraining.py:  535]:	loss/mlm_loss, 8.449946403503418, 753
[INFO] 2021-07-12 18:45:08,524 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.51999959902605e-06, 753
[INFO] 2021-07-12 18:45:08,524 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 753
[INFO] 2021-07-12 18:45:08,524 [run_pretraining.py:  558]:	worker_index: 3, step: 753, cost: 8.449946, mlm loss: 8.449946, speed: 1.105702 steps/s, speed: 8.845617 samples/s, speed: 4528.955797 tokens/s, learning rate: 7.520e-06, loss_scalings: 13421.773438, pp_loss: 8.276595
[INFO] 2021-07-12 18:45:08,524 [run_pretraining.py:  512]:	********exe.run_753******* 
[INFO] 2021-07-12 18:45:09,425 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:09,426 [run_pretraining.py:  534]:	loss/total_loss, 7.723334312438965, 754
[INFO] 2021-07-12 18:45:09,426 [run_pretraining.py:  535]:	loss/mlm_loss, 7.723334312438965, 754
[INFO] 2021-07-12 18:45:09,426 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.529999948019395e-06, 754
[INFO] 2021-07-12 18:45:09,426 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 754
[INFO] 2021-07-12 18:45:09,426 [run_pretraining.py:  558]:	worker_index: 3, step: 754, cost: 7.723334, mlm loss: 7.723334, speed: 1.109101 steps/s, speed: 8.872808 samples/s, speed: 4542.877817 tokens/s, learning rate: 7.530e-06, loss_scalings: 13421.773438, pp_loss: 7.844252
[INFO] 2021-07-12 18:45:09,426 [run_pretraining.py:  512]:	********exe.run_754******* 
[INFO] 2021-07-12 18:45:10,328 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:10,329 [run_pretraining.py:  534]:	loss/total_loss, 8.001852035522461, 755
[INFO] 2021-07-12 18:45:10,329 [run_pretraining.py:  535]:	loss/mlm_loss, 8.001852035522461, 755
[INFO] 2021-07-12 18:45:10,329 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.539999842265388e-06, 755
[INFO] 2021-07-12 18:45:10,329 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 755
[INFO] 2021-07-12 18:45:10,329 [run_pretraining.py:  558]:	worker_index: 3, step: 755, cost: 8.001852, mlm loss: 8.001852, speed: 1.108162 steps/s, speed: 8.865293 samples/s, speed: 4539.029793 tokens/s, learning rate: 7.540e-06, loss_scalings: 13421.773438, pp_loss: 8.091619
[INFO] 2021-07-12 18:45:10,329 [run_pretraining.py:  512]:	********exe.run_755******* 
[INFO] 2021-07-12 18:45:11,225 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:11,226 [run_pretraining.py:  534]:	loss/total_loss, 8.164655685424805, 756
[INFO] 2021-07-12 18:45:11,226 [run_pretraining.py:  535]:	loss/mlm_loss, 8.164655685424805, 756
[INFO] 2021-07-12 18:45:11,226 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.5499992817640305e-06, 756
[INFO] 2021-07-12 18:45:11,226 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 756
[INFO] 2021-07-12 18:45:11,226 [run_pretraining.py:  558]:	worker_index: 3, step: 756, cost: 8.164656, mlm loss: 8.164656, speed: 1.115313 steps/s, speed: 8.922501 samples/s, speed: 4568.320763 tokens/s, learning rate: 7.550e-06, loss_scalings: 13421.773438, pp_loss: 8.402250
[INFO] 2021-07-12 18:45:11,226 [run_pretraining.py:  512]:	********exe.run_756******* 
[INFO] 2021-07-12 18:45:12,129 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:12,130 [run_pretraining.py:  534]:	loss/total_loss, 8.372289657592773, 757
[INFO] 2021-07-12 18:45:12,130 [run_pretraining.py:  535]:	loss/mlm_loss, 8.372289657592773, 757
[INFO] 2021-07-12 18:45:12,130 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.559999630757375e-06, 757
[INFO] 2021-07-12 18:45:12,130 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 757
[INFO] 2021-07-12 18:45:12,130 [run_pretraining.py:  558]:	worker_index: 3, step: 757, cost: 8.372290, mlm loss: 8.372290, speed: 1.106974 steps/s, speed: 8.855795 samples/s, speed: 4534.167291 tokens/s, learning rate: 7.560e-06, loss_scalings: 13421.773438, pp_loss: 8.380795
[INFO] 2021-07-12 18:45:12,130 [run_pretraining.py:  512]:	********exe.run_757******* 
[INFO] 2021-07-12 18:45:13,042 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:13,043 [run_pretraining.py:  534]:	loss/total_loss, 3.6875059604644775, 758
[INFO] 2021-07-12 18:45:13,043 [run_pretraining.py:  535]:	loss/mlm_loss, 3.6875059604644775, 758
[INFO] 2021-07-12 18:45:13,043 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.569999979750719e-06, 758
[INFO] 2021-07-12 18:45:13,043 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 758
[INFO] 2021-07-12 18:45:13,043 [run_pretraining.py:  558]:	worker_index: 3, step: 758, cost: 3.687506, mlm loss: 3.687506, speed: 1.096236 steps/s, speed: 8.769885 samples/s, speed: 4490.181295 tokens/s, learning rate: 7.570e-06, loss_scalings: 13421.773438, pp_loss: 7.027174
[INFO] 2021-07-12 18:45:13,043 [run_pretraining.py:  512]:	********exe.run_758******* 
[INFO] 2021-07-12 18:45:13,947 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:13,948 [run_pretraining.py:  534]:	loss/total_loss, 4.744151592254639, 759
[INFO] 2021-07-12 18:45:13,948 [run_pretraining.py:  535]:	loss/mlm_loss, 4.744151592254639, 759
[INFO] 2021-07-12 18:45:13,948 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.579999873996712e-06, 759
[INFO] 2021-07-12 18:45:13,948 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 759
[INFO] 2021-07-12 18:45:13,948 [run_pretraining.py:  558]:	worker_index: 3, step: 759, cost: 4.744152, mlm loss: 4.744152, speed: 1.105833 steps/s, speed: 8.846666 samples/s, speed: 4529.493126 tokens/s, learning rate: 7.580e-06, loss_scalings: 13421.773438, pp_loss: 7.272416
[INFO] 2021-07-12 18:45:13,948 [run_pretraining.py:  512]:	********exe.run_759******* 
[INFO] 2021-07-12 18:45:14,849 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:14,850 [run_pretraining.py:  534]:	loss/total_loss, 8.384010314941406, 760
[INFO] 2021-07-12 18:45:14,850 [run_pretraining.py:  535]:	loss/mlm_loss, 8.384010314941406, 760
[INFO] 2021-07-12 18:45:14,850 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.5900002229900565e-06, 760
[INFO] 2021-07-12 18:45:14,850 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 760
[INFO] 2021-07-12 18:45:14,850 [run_pretraining.py:  558]:	worker_index: 3, step: 760, cost: 8.384010, mlm loss: 8.384010, speed: 1.109338 steps/s, speed: 8.874704 samples/s, speed: 4543.848654 tokens/s, learning rate: 7.590e-06, loss_scalings: 13421.773438, pp_loss: 8.244984
[INFO] 2021-07-12 18:45:14,850 [run_pretraining.py:  512]:	********exe.run_760******* 
[INFO] 2021-07-12 18:45:15,754 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:15,754 [run_pretraining.py:  534]:	loss/total_loss, 8.534878730773926, 761
[INFO] 2021-07-12 18:45:15,754 [run_pretraining.py:  535]:	loss/mlm_loss, 8.534878730773926, 761
[INFO] 2021-07-12 18:45:15,754 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.599999662488699e-06, 761
[INFO] 2021-07-12 18:45:15,754 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 761
[INFO] 2021-07-12 18:45:15,755 [run_pretraining.py:  558]:	worker_index: 3, step: 761, cost: 8.534879, mlm loss: 8.534879, speed: 1.106459 steps/s, speed: 8.851672 samples/s, speed: 4532.056148 tokens/s, learning rate: 7.600e-06, loss_scalings: 13421.773438, pp_loss: 8.302453
[INFO] 2021-07-12 18:45:15,755 [run_pretraining.py:  512]:	********exe.run_761******* 
[INFO] 2021-07-12 18:45:16,658 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:16,659 [run_pretraining.py:  534]:	loss/total_loss, 8.549088478088379, 762
[INFO] 2021-07-12 18:45:16,659 [run_pretraining.py:  535]:	loss/mlm_loss, 8.549088478088379, 762
[INFO] 2021-07-12 18:45:16,659 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.609999556734692e-06, 762
[INFO] 2021-07-12 18:45:16,659 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 762
[INFO] 2021-07-12 18:45:16,659 [run_pretraining.py:  558]:	worker_index: 3, step: 762, cost: 8.549088, mlm loss: 8.549088, speed: 1.106076 steps/s, speed: 8.848605 samples/s, speed: 4530.485729 tokens/s, learning rate: 7.610e-06, loss_scalings: 13421.773438, pp_loss: 8.515503
[INFO] 2021-07-12 18:45:16,659 [run_pretraining.py:  512]:	********exe.run_762******* 
[INFO] 2021-07-12 18:45:17,567 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:17,567 [run_pretraining.py:  534]:	loss/total_loss, 7.902194023132324, 763
[INFO] 2021-07-12 18:45:17,567 [run_pretraining.py:  535]:	loss/mlm_loss, 7.902194023132324, 763
[INFO] 2021-07-12 18:45:17,567 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.6199999057280365e-06, 763
[INFO] 2021-07-12 18:45:17,567 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 763
[INFO] 2021-07-12 18:45:17,567 [run_pretraining.py:  558]:	worker_index: 3, step: 763, cost: 7.902194, mlm loss: 7.902194, speed: 1.101920 steps/s, speed: 8.815360 samples/s, speed: 4513.464093 tokens/s, learning rate: 7.620e-06, loss_scalings: 13421.773438, pp_loss: 8.359111
[INFO] 2021-07-12 18:45:17,568 [run_pretraining.py:  512]:	********exe.run_763******* 
[INFO] 2021-07-12 18:45:18,471 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:18,471 [run_pretraining.py:  534]:	loss/total_loss, 8.272500038146973, 764
[INFO] 2021-07-12 18:45:18,472 [run_pretraining.py:  535]:	loss/mlm_loss, 8.272500038146973, 764
[INFO] 2021-07-12 18:45:18,472 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.63000025472138e-06, 764
[INFO] 2021-07-12 18:45:18,472 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 764
[INFO] 2021-07-12 18:45:18,472 [run_pretraining.py:  558]:	worker_index: 3, step: 764, cost: 8.272500, mlm loss: 8.272500, speed: 1.106591 steps/s, speed: 8.852725 samples/s, speed: 4532.595409 tokens/s, learning rate: 7.630e-06, loss_scalings: 13421.773438, pp_loss: 7.606348
[INFO] 2021-07-12 18:45:18,472 [run_pretraining.py:  512]:	********exe.run_764******* 
[INFO] 2021-07-12 18:45:19,383 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:19,383 [run_pretraining.py:  534]:	loss/total_loss, 8.385063171386719, 765
[INFO] 2021-07-12 18:45:19,383 [run_pretraining.py:  535]:	loss/mlm_loss, 8.385063171386719, 765
[INFO] 2021-07-12 18:45:19,383 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.639999239472672e-06, 765
[INFO] 2021-07-12 18:45:19,383 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 765
[INFO] 2021-07-12 18:45:19,383 [run_pretraining.py:  558]:	worker_index: 3, step: 765, cost: 8.385063, mlm loss: 8.385063, speed: 1.097670 steps/s, speed: 8.781363 samples/s, speed: 4496.057985 tokens/s, learning rate: 7.640e-06, loss_scalings: 13421.773438, pp_loss: 8.397676
[INFO] 2021-07-12 18:45:19,384 [run_pretraining.py:  512]:	********exe.run_765******* 
[INFO] 2021-07-12 18:45:20,298 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:20,298 [run_pretraining.py:  534]:	loss/total_loss, 8.320137977600098, 766
[INFO] 2021-07-12 18:45:20,298 [run_pretraining.py:  535]:	loss/mlm_loss, 8.320137977600098, 766
[INFO] 2021-07-12 18:45:20,298 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.650000043213367e-06, 766
[INFO] 2021-07-12 18:45:20,298 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 766
[INFO] 2021-07-12 18:45:20,299 [run_pretraining.py:  558]:	worker_index: 3, step: 766, cost: 8.320138, mlm loss: 8.320138, speed: 1.093612 steps/s, speed: 8.748899 samples/s, speed: 4479.436073 tokens/s, learning rate: 7.650e-06, loss_scalings: 13421.773438, pp_loss: 8.363359
[INFO] 2021-07-12 18:45:20,299 [run_pretraining.py:  512]:	********exe.run_766******* 
[INFO] 2021-07-12 18:45:21,215 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:21,215 [run_pretraining.py:  534]:	loss/total_loss, 8.447746276855469, 767
[INFO] 2021-07-12 18:45:21,215 [run_pretraining.py:  535]:	loss/mlm_loss, 8.447746276855469, 767
[INFO] 2021-07-12 18:45:21,216 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.65999993745936e-06, 767
[INFO] 2021-07-12 18:45:21,216 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 767
[INFO] 2021-07-12 18:45:21,216 [run_pretraining.py:  558]:	worker_index: 3, step: 767, cost: 8.447746, mlm loss: 8.447746, speed: 1.091126 steps/s, speed: 8.729007 samples/s, speed: 4469.251339 tokens/s, learning rate: 7.660e-06, loss_scalings: 13421.773438, pp_loss: 7.237810
[INFO] 2021-07-12 18:45:21,216 [run_pretraining.py:  512]:	********exe.run_767******* 
[INFO] 2021-07-12 18:45:22,122 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:22,122 [run_pretraining.py:  534]:	loss/total_loss, 4.670951843261719, 768
[INFO] 2021-07-12 18:45:22,123 [run_pretraining.py:  535]:	loss/mlm_loss, 4.670951843261719, 768
[INFO] 2021-07-12 18:45:22,123 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.669999831705354e-06, 768
[INFO] 2021-07-12 18:45:22,123 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 768
[INFO] 2021-07-12 18:45:22,123 [run_pretraining.py:  558]:	worker_index: 3, step: 768, cost: 4.670952, mlm loss: 4.670952, speed: 1.103175 steps/s, speed: 8.825399 samples/s, speed: 4518.604320 tokens/s, learning rate: 7.670e-06, loss_scalings: 13421.773438, pp_loss: 7.367535
[INFO] 2021-07-12 18:45:22,123 [run_pretraining.py:  512]:	********exe.run_768******* 
[INFO] 2021-07-12 18:45:23,036 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:23,036 [run_pretraining.py:  534]:	loss/total_loss, 8.37286376953125, 769
[INFO] 2021-07-12 18:45:23,036 [run_pretraining.py:  535]:	loss/mlm_loss, 8.37286376953125, 769
[INFO] 2021-07-12 18:45:23,036 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.679999725951348e-06, 769
[INFO] 2021-07-12 18:45:23,036 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 769
[INFO] 2021-07-12 18:45:23,036 [run_pretraining.py:  558]:	worker_index: 3, step: 769, cost: 8.372864, mlm loss: 8.372864, speed: 1.095230 steps/s, speed: 8.761838 samples/s, speed: 4486.061165 tokens/s, learning rate: 7.680e-06, loss_scalings: 13421.773438, pp_loss: 8.315762
[INFO] 2021-07-12 18:45:23,037 [run_pretraining.py:  512]:	********exe.run_769******* 
[INFO] 2021-07-12 18:45:23,948 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:23,948 [run_pretraining.py:  534]:	loss/total_loss, 7.860045909881592, 770
[INFO] 2021-07-12 18:45:23,948 [run_pretraining.py:  535]:	loss/mlm_loss, 7.860045909881592, 770
[INFO] 2021-07-12 18:45:23,949 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.68999962019734e-06, 770
[INFO] 2021-07-12 18:45:23,949 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 770
[INFO] 2021-07-12 18:45:23,949 [run_pretraining.py:  558]:	worker_index: 3, step: 770, cost: 7.860046, mlm loss: 7.860046, speed: 1.097064 steps/s, speed: 8.776512 samples/s, speed: 4493.574293 tokens/s, learning rate: 7.690e-06, loss_scalings: 13421.773438, pp_loss: 8.440024
[INFO] 2021-07-12 18:45:23,949 [run_pretraining.py:  512]:	********exe.run_770******* 
[INFO] 2021-07-12 18:45:24,865 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:24,866 [run_pretraining.py:  534]:	loss/total_loss, 8.045567512512207, 771
[INFO] 2021-07-12 18:45:24,866 [run_pretraining.py:  535]:	loss/mlm_loss, 8.045567512512207, 771
[INFO] 2021-07-12 18:45:24,866 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.699999514443334e-06, 771
[INFO] 2021-07-12 18:45:24,866 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 771
[INFO] 2021-07-12 18:45:24,866 [run_pretraining.py:  558]:	worker_index: 3, step: 771, cost: 8.045568, mlm loss: 8.045568, speed: 1.090925 steps/s, speed: 8.727401 samples/s, speed: 4468.429495 tokens/s, learning rate: 7.700e-06, loss_scalings: 13421.773438, pp_loss: 8.188665
[INFO] 2021-07-12 18:45:24,866 [run_pretraining.py:  512]:	********exe.run_771******* 
[INFO] 2021-07-12 18:45:25,790 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:25,791 [run_pretraining.py:  534]:	loss/total_loss, 9.019465446472168, 772
[INFO] 2021-07-12 18:45:25,791 [run_pretraining.py:  535]:	loss/mlm_loss, 9.019465446472168, 772
[INFO] 2021-07-12 18:45:25,791 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.71000031818403e-06, 772
[INFO] 2021-07-12 18:45:25,791 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 772
[INFO] 2021-07-12 18:45:25,791 [run_pretraining.py:  558]:	worker_index: 3, step: 772, cost: 9.019465, mlm loss: 9.019465, speed: 1.081557 steps/s, speed: 8.652454 samples/s, speed: 4430.056326 tokens/s, learning rate: 7.710e-06, loss_scalings: 13421.773438, pp_loss: 8.322652
[INFO] 2021-07-12 18:45:25,791 [run_pretraining.py:  512]:	********exe.run_772******* 
[INFO] 2021-07-12 18:45:26,852 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:26,853 [run_pretraining.py:  534]:	loss/total_loss, 8.111623764038086, 773
[INFO] 2021-07-12 18:45:26,853 [run_pretraining.py:  535]:	loss/mlm_loss, 8.111623764038086, 773
[INFO] 2021-07-12 18:45:26,853 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.720000212430023e-06, 773
[INFO] 2021-07-12 18:45:26,853 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 773
[INFO] 2021-07-12 18:45:26,853 [run_pretraining.py:  558]:	worker_index: 3, step: 773, cost: 8.111624, mlm loss: 8.111624, speed: 0.942151 steps/s, speed: 7.537207 samples/s, speed: 3859.049976 tokens/s, learning rate: 7.720e-06, loss_scalings: 13421.773438, pp_loss: 8.308054
[INFO] 2021-07-12 18:45:26,853 [run_pretraining.py:  512]:	********exe.run_773******* 
[INFO] 2021-07-12 18:45:27,908 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:27,909 [run_pretraining.py:  534]:	loss/total_loss, 8.205041885375977, 774
[INFO] 2021-07-12 18:45:27,909 [run_pretraining.py:  535]:	loss/mlm_loss, 8.205041885375977, 774
[INFO] 2021-07-12 18:45:27,909 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.729999197181314e-06, 774
[INFO] 2021-07-12 18:45:27,909 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 774
[INFO] 2021-07-12 18:45:27,909 [run_pretraining.py:  558]:	worker_index: 3, step: 774, cost: 8.205042, mlm loss: 8.205042, speed: 0.947852 steps/s, speed: 7.582816 samples/s, speed: 3882.401915 tokens/s, learning rate: 7.730e-06, loss_scalings: 13421.773438, pp_loss: 8.441786
[INFO] 2021-07-12 18:45:27,909 [run_pretraining.py:  512]:	********exe.run_774******* 
[INFO] 2021-07-12 18:45:28,973 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:28,973 [run_pretraining.py:  534]:	loss/total_loss, 8.362520217895508, 775
[INFO] 2021-07-12 18:45:28,974 [run_pretraining.py:  535]:	loss/mlm_loss, 8.362520217895508, 775
[INFO] 2021-07-12 18:45:28,974 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.74000000092201e-06, 775
[INFO] 2021-07-12 18:45:28,974 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 775
[INFO] 2021-07-12 18:45:28,974 [run_pretraining.py:  558]:	worker_index: 3, step: 775, cost: 8.362520, mlm loss: 8.362520, speed: 0.939660 steps/s, speed: 7.517280 samples/s, speed: 3848.847395 tokens/s, learning rate: 7.740e-06, loss_scalings: 13421.773438, pp_loss: 8.520710
[INFO] 2021-07-12 18:45:28,974 [run_pretraining.py:  512]:	********exe.run_775******* 
[INFO] 2021-07-12 18:45:30,041 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:30,042 [run_pretraining.py:  534]:	loss/total_loss, 8.200411796569824, 776
[INFO] 2021-07-12 18:45:30,042 [run_pretraining.py:  535]:	loss/mlm_loss, 8.200411796569824, 776
[INFO] 2021-07-12 18:45:30,042 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.749999895168003e-06, 776
[INFO] 2021-07-12 18:45:30,042 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 776
[INFO] 2021-07-12 18:45:30,042 [run_pretraining.py:  558]:	worker_index: 3, step: 776, cost: 8.200412, mlm loss: 8.200412, speed: 0.936439 steps/s, speed: 7.491511 samples/s, speed: 3835.653538 tokens/s, learning rate: 7.750e-06, loss_scalings: 13421.773438, pp_loss: 8.549037
[INFO] 2021-07-12 18:45:30,042 [run_pretraining.py:  512]:	********exe.run_776******* 
[INFO] 2021-07-12 18:45:31,124 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:31,124 [run_pretraining.py:  534]:	loss/total_loss, 8.272933959960938, 777
[INFO] 2021-07-12 18:45:31,125 [run_pretraining.py:  535]:	loss/mlm_loss, 8.272933959960938, 777
[INFO] 2021-07-12 18:45:31,125 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.759999789413996e-06, 777
[INFO] 2021-07-12 18:45:31,125 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 777
[INFO] 2021-07-12 18:45:31,125 [run_pretraining.py:  558]:	worker_index: 3, step: 777, cost: 8.272934, mlm loss: 8.272934, speed: 0.924366 steps/s, speed: 7.394926 samples/s, speed: 3786.202072 tokens/s, learning rate: 7.760e-06, loss_scalings: 13421.773438, pp_loss: 8.488506
[INFO] 2021-07-12 18:45:31,125 [run_pretraining.py:  512]:	********exe.run_777******* 
[INFO] 2021-07-12 18:45:32,183 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:32,184 [run_pretraining.py:  534]:	loss/total_loss, 8.621946334838867, 778
[INFO] 2021-07-12 18:45:32,184 [run_pretraining.py:  535]:	loss/mlm_loss, 8.621946334838867, 778
[INFO] 2021-07-12 18:45:32,184 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.76999968365999e-06, 778
[INFO] 2021-07-12 18:45:32,184 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 778
[INFO] 2021-07-12 18:45:32,184 [run_pretraining.py:  558]:	worker_index: 3, step: 778, cost: 8.621946, mlm loss: 8.621946, speed: 0.944522 steps/s, speed: 7.556180 samples/s, speed: 3868.763948 tokens/s, learning rate: 7.770e-06, loss_scalings: 13421.773438, pp_loss: 8.406256
[INFO] 2021-07-12 18:45:32,184 [run_pretraining.py:  512]:	********exe.run_778******* 
[INFO] 2021-07-12 18:45:33,245 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:33,246 [run_pretraining.py:  534]:	loss/total_loss, 8.276103973388672, 779
[INFO] 2021-07-12 18:45:33,246 [run_pretraining.py:  535]:	loss/mlm_loss, 8.276103973388672, 779
[INFO] 2021-07-12 18:45:33,246 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.779999577905983e-06, 779
[INFO] 2021-07-12 18:45:33,246 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 779
[INFO] 2021-07-12 18:45:33,246 [run_pretraining.py:  558]:	worker_index: 3, step: 779, cost: 8.276104, mlm loss: 8.276104, speed: 0.941948 steps/s, speed: 7.535582 samples/s, speed: 3858.217985 tokens/s, learning rate: 7.780e-06, loss_scalings: 13421.773438, pp_loss: 7.811530
[INFO] 2021-07-12 18:45:33,246 [run_pretraining.py:  512]:	********exe.run_779******* 
[INFO] 2021-07-12 18:45:34,311 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:34,312 [run_pretraining.py:  534]:	loss/total_loss, 8.264739036560059, 780
[INFO] 2021-07-12 18:45:34,312 [run_pretraining.py:  535]:	loss/mlm_loss, 8.264739036560059, 780
[INFO] 2021-07-12 18:45:34,312 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.789999472151976e-06, 780
[INFO] 2021-07-12 18:45:34,312 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 780
[INFO] 2021-07-12 18:45:34,312 [run_pretraining.py:  558]:	worker_index: 3, step: 780, cost: 8.264739, mlm loss: 8.264739, speed: 0.938880 steps/s, speed: 7.511044 samples/s, speed: 3845.654486 tokens/s, learning rate: 7.790e-06, loss_scalings: 13421.773438, pp_loss: 8.287916
[INFO] 2021-07-12 18:45:34,312 [run_pretraining.py:  512]:	********exe.run_780******* 
[INFO] 2021-07-12 18:45:35,382 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:35,382 [run_pretraining.py:  534]:	loss/total_loss, 8.387384414672852, 781
[INFO] 2021-07-12 18:45:35,382 [run_pretraining.py:  535]:	loss/mlm_loss, 8.387384414672852, 781
[INFO] 2021-07-12 18:45:35,382 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.800000275892671e-06, 781
[INFO] 2021-07-12 18:45:35,382 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 781
[INFO] 2021-07-12 18:45:35,382 [run_pretraining.py:  558]:	worker_index: 3, step: 781, cost: 8.387384, mlm loss: 8.387384, speed: 0.934908 steps/s, speed: 7.479261 samples/s, speed: 3829.381518 tokens/s, learning rate: 7.800e-06, loss_scalings: 13421.773438, pp_loss: 8.551380
[INFO] 2021-07-12 18:45:35,382 [run_pretraining.py:  512]:	********exe.run_781******* 
[INFO] 2021-07-12 18:45:36,439 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:36,440 [run_pretraining.py:  534]:	loss/total_loss, 8.172016143798828, 782
[INFO] 2021-07-12 18:45:36,440 [run_pretraining.py:  535]:	loss/mlm_loss, 8.172016143798828, 782
[INFO] 2021-07-12 18:45:36,440 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.810000170138665e-06, 782
[INFO] 2021-07-12 18:45:36,440 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 782
[INFO] 2021-07-12 18:45:36,440 [run_pretraining.py:  558]:	worker_index: 3, step: 782, cost: 8.172016, mlm loss: 8.172016, speed: 0.946236 steps/s, speed: 7.569889 samples/s, speed: 3875.782959 tokens/s, learning rate: 7.810e-06, loss_scalings: 13421.773438, pp_loss: 8.261469
[INFO] 2021-07-12 18:45:36,440 [run_pretraining.py:  512]:	********exe.run_782******* 
[INFO] 2021-07-12 18:45:37,505 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:37,505 [run_pretraining.py:  534]:	loss/total_loss, 8.021641731262207, 783
[INFO] 2021-07-12 18:45:37,506 [run_pretraining.py:  535]:	loss/mlm_loss, 8.021641731262207, 783
[INFO] 2021-07-12 18:45:37,506 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.819999154889956e-06, 783
[INFO] 2021-07-12 18:45:37,506 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 783
[INFO] 2021-07-12 18:45:37,506 [run_pretraining.py:  558]:	worker_index: 3, step: 783, cost: 8.021642, mlm loss: 8.021642, speed: 0.938790 steps/s, speed: 7.510321 samples/s, speed: 3845.284362 tokens/s, learning rate: 7.820e-06, loss_scalings: 13421.773438, pp_loss: 8.304293
[INFO] 2021-07-12 18:45:37,506 [run_pretraining.py:  512]:	********exe.run_783******* 
[INFO] 2021-07-12 18:45:38,562 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:38,563 [run_pretraining.py:  534]:	loss/total_loss, 8.110302925109863, 784
[INFO] 2021-07-12 18:45:38,563 [run_pretraining.py:  535]:	loss/mlm_loss, 8.110302925109863, 784
[INFO] 2021-07-12 18:45:38,563 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.829999958630651e-06, 784
[INFO] 2021-07-12 18:45:38,563 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 784
[INFO] 2021-07-12 18:45:38,563 [run_pretraining.py:  558]:	worker_index: 3, step: 784, cost: 8.110303, mlm loss: 8.110303, speed: 0.946404 steps/s, speed: 7.571231 samples/s, speed: 3876.470342 tokens/s, learning rate: 7.830e-06, loss_scalings: 13421.773438, pp_loss: 7.508575
[INFO] 2021-07-12 18:45:38,563 [run_pretraining.py:  512]:	********exe.run_784******* 
[INFO] 2021-07-12 18:45:39,626 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:39,626 [run_pretraining.py:  534]:	loss/total_loss, 8.073638916015625, 785
[INFO] 2021-07-12 18:45:39,626 [run_pretraining.py:  535]:	loss/mlm_loss, 8.073638916015625, 785
[INFO] 2021-07-12 18:45:39,626 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.839999852876645e-06, 785
[INFO] 2021-07-12 18:45:39,626 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 785
[INFO] 2021-07-12 18:45:39,626 [run_pretraining.py:  558]:	worker_index: 3, step: 785, cost: 8.073639, mlm loss: 8.073639, speed: 0.940865 steps/s, speed: 7.526919 samples/s, speed: 3853.782430 tokens/s, learning rate: 7.840e-06, loss_scalings: 13421.773438, pp_loss: 8.230844
[INFO] 2021-07-12 18:45:39,627 [run_pretraining.py:  512]:	********exe.run_785******* 
[INFO] 2021-07-12 18:45:40,644 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:40,645 [run_pretraining.py:  534]:	loss/total_loss, 8.551990509033203, 786
[INFO] 2021-07-12 18:45:40,645 [run_pretraining.py:  535]:	loss/mlm_loss, 8.551990509033203, 786
[INFO] 2021-07-12 18:45:40,645 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.849999747122638e-06, 786
[INFO] 2021-07-12 18:45:40,645 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 786
[INFO] 2021-07-12 18:45:40,645 [run_pretraining.py:  558]:	worker_index: 3, step: 786, cost: 8.551991, mlm loss: 8.551991, speed: 0.982412 steps/s, speed: 7.859294 samples/s, speed: 4023.958707 tokens/s, learning rate: 7.850e-06, loss_scalings: 13421.773438, pp_loss: 8.520676
[INFO] 2021-07-12 18:45:40,645 [run_pretraining.py:  512]:	********exe.run_786******* 
[INFO] 2021-07-12 18:45:41,565 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:41,565 [run_pretraining.py:  534]:	loss/total_loss, 8.376344680786133, 787
[INFO] 2021-07-12 18:45:41,565 [run_pretraining.py:  535]:	loss/mlm_loss, 8.376344680786133, 787
[INFO] 2021-07-12 18:45:41,565 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.859999641368631e-06, 787
[INFO] 2021-07-12 18:45:41,565 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 787
[INFO] 2021-07-12 18:45:41,565 [run_pretraining.py:  558]:	worker_index: 3, step: 787, cost: 8.376345, mlm loss: 8.376345, speed: 1.087172 steps/s, speed: 8.697373 samples/s, speed: 4453.055209 tokens/s, learning rate: 7.860e-06, loss_scalings: 13421.773438, pp_loss: 7.607769
[INFO] 2021-07-12 18:45:41,566 [run_pretraining.py:  512]:	********exe.run_787******* 
[INFO] 2021-07-12 18:45:42,482 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:42,483 [run_pretraining.py:  534]:	loss/total_loss, 7.0655598640441895, 788
[INFO] 2021-07-12 18:45:42,483 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0655598640441895, 788
[INFO] 2021-07-12 18:45:42,483 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.869999535614625e-06, 788
[INFO] 2021-07-12 18:45:42,483 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 788
[INFO] 2021-07-12 18:45:42,483 [run_pretraining.py:  558]:	worker_index: 3, step: 788, cost: 7.065560, mlm loss: 7.065560, speed: 1.090647 steps/s, speed: 8.725177 samples/s, speed: 4467.290805 tokens/s, learning rate: 7.870e-06, loss_scalings: 13421.773438, pp_loss: 7.921506
[INFO] 2021-07-12 18:45:42,483 [run_pretraining.py:  512]:	********exe.run_788******* 
[INFO] 2021-07-12 18:45:43,400 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:43,401 [run_pretraining.py:  534]:	loss/total_loss, 8.494036674499512, 789
[INFO] 2021-07-12 18:45:43,401 [run_pretraining.py:  535]:	loss/mlm_loss, 8.494036674499512, 789
[INFO] 2021-07-12 18:45:43,401 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.879999429860618e-06, 789
[INFO] 2021-07-12 18:45:43,401 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 789
[INFO] 2021-07-12 18:45:43,401 [run_pretraining.py:  558]:	worker_index: 3, step: 789, cost: 8.494037, mlm loss: 8.494037, speed: 1.089836 steps/s, speed: 8.718687 samples/s, speed: 4463.967527 tokens/s, learning rate: 7.880e-06, loss_scalings: 13421.773438, pp_loss: 8.649343
[INFO] 2021-07-12 18:45:43,401 [run_pretraining.py:  512]:	********exe.run_789******* 
[INFO] 2021-07-12 18:46:08,298 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:08,298 [run_pretraining.py:  534]:	loss/total_loss, 8.608455657958984, 790
[INFO] 2021-07-12 18:46:08,299 [run_pretraining.py:  535]:	loss/mlm_loss, 8.608455657958984, 790
[INFO] 2021-07-12 18:46:08,299 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.890000233601313e-06, 790
[INFO] 2021-07-12 18:46:08,299 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 790
[INFO] 2021-07-12 18:46:08,299 [run_pretraining.py:  558]:	worker_index: 3, step: 790, cost: 8.608456, mlm loss: 8.608456, speed: 0.040166 steps/s, speed: 0.321324 samples/s, speed: 164.518108 tokens/s, learning rate: 7.890e-06, loss_scalings: 13421.773438, pp_loss: 8.485892
[INFO] 2021-07-12 18:46:08,299 [run_pretraining.py:  512]:	********exe.run_790******* 
[INFO] 2021-07-12 18:46:09,215 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:09,215 [run_pretraining.py:  534]:	loss/total_loss, 8.68648910522461, 791
[INFO] 2021-07-12 18:46:09,215 [run_pretraining.py:  535]:	loss/mlm_loss, 8.68648910522461, 791
[INFO] 2021-07-12 18:46:09,216 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.900000127847306e-06, 791
[INFO] 2021-07-12 18:46:09,216 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 791
[INFO] 2021-07-12 18:46:09,216 [run_pretraining.py:  558]:	worker_index: 3, step: 791, cost: 8.686489, mlm loss: 8.686489, speed: 1.091426 steps/s, speed: 8.731407 samples/s, speed: 4470.480600 tokens/s, learning rate: 7.900e-06, loss_scalings: 13421.773438, pp_loss: 8.507437
[INFO] 2021-07-12 18:46:09,216 [run_pretraining.py:  512]:	********exe.run_791******* 
[INFO] 2021-07-12 18:46:10,141 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:10,141 [run_pretraining.py:  534]:	loss/total_loss, 8.676399230957031, 792
[INFO] 2021-07-12 18:46:10,141 [run_pretraining.py:  535]:	loss/mlm_loss, 8.676399230957031, 792
[INFO] 2021-07-12 18:46:10,141 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.9100000220933e-06, 792
[INFO] 2021-07-12 18:46:10,141 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 792
[INFO] 2021-07-12 18:46:10,142 [run_pretraining.py:  558]:	worker_index: 3, step: 792, cost: 8.676399, mlm loss: 8.676399, speed: 1.080804 steps/s, speed: 8.646432 samples/s, speed: 4426.972990 tokens/s, learning rate: 7.910e-06, loss_scalings: 13421.773438, pp_loss: 7.585235
[INFO] 2021-07-12 18:46:10,142 [run_pretraining.py:  512]:	********exe.run_792******* 
[INFO] 2021-07-12 18:46:11,058 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:11,058 [run_pretraining.py:  534]:	loss/total_loss, 8.501426696777344, 793
[INFO] 2021-07-12 18:46:11,058 [run_pretraining.py:  535]:	loss/mlm_loss, 8.501426696777344, 793
[INFO] 2021-07-12 18:46:11,058 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.919999916339293e-06, 793
[INFO] 2021-07-12 18:46:11,058 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 793
[INFO] 2021-07-12 18:46:11,059 [run_pretraining.py:  558]:	worker_index: 3, step: 793, cost: 8.501427, mlm loss: 8.501427, speed: 1.091287 steps/s, speed: 8.730294 samples/s, speed: 4469.910659 tokens/s, learning rate: 7.920e-06, loss_scalings: 13421.773438, pp_loss: 8.417216
[INFO] 2021-07-12 18:46:11,059 [run_pretraining.py:  512]:	********exe.run_793******* 
[INFO] 2021-07-12 18:46:36,804 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:36,804 [run_pretraining.py:  534]:	loss/total_loss, 8.488964080810547, 794
[INFO] 2021-07-12 18:46:36,804 [run_pretraining.py:  535]:	loss/mlm_loss, 8.488964080810547, 794
[INFO] 2021-07-12 18:46:36,804 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.929999810585286e-06, 794
[INFO] 2021-07-12 18:46:36,804 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 794
[INFO] 2021-07-12 18:46:36,804 [run_pretraining.py:  558]:	worker_index: 3, step: 794, cost: 8.488964, mlm loss: 8.488964, speed: 0.038842 steps/s, speed: 0.310736 samples/s, speed: 159.097044 tokens/s, learning rate: 7.930e-06, loss_scalings: 13421.773438, pp_loss: 8.479473
[INFO] 2021-07-12 18:46:36,805 [run_pretraining.py:  512]:	********exe.run_794******* 
[INFO] 2021-07-12 18:46:37,722 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:37,723 [run_pretraining.py:  534]:	loss/total_loss, 8.223197937011719, 795
[INFO] 2021-07-12 18:46:37,723 [run_pretraining.py:  535]:	loss/mlm_loss, 8.223197937011719, 795
[INFO] 2021-07-12 18:46:37,723 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.93999970483128e-06, 795
[INFO] 2021-07-12 18:46:37,723 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 795
[INFO] 2021-07-12 18:46:37,723 [run_pretraining.py:  558]:	worker_index: 3, step: 795, cost: 8.223198, mlm loss: 8.223198, speed: 1.089301 steps/s, speed: 8.714412 samples/s, speed: 4461.778701 tokens/s, learning rate: 7.940e-06, loss_scalings: 13421.773438, pp_loss: 8.277711
[INFO] 2021-07-12 18:46:37,723 [run_pretraining.py:  512]:	********exe.run_795******* 
[INFO] 2021-07-12 18:46:38,671 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:38,672 [run_pretraining.py:  534]:	loss/total_loss, 8.353797912597656, 796
[INFO] 2021-07-12 18:46:38,672 [run_pretraining.py:  535]:	loss/mlm_loss, 8.353797912597656, 796
[INFO] 2021-07-12 18:46:38,672 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.949999599077273e-06, 796
[INFO] 2021-07-12 18:46:38,672 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 796
[INFO] 2021-07-12 18:46:38,672 [run_pretraining.py:  558]:	worker_index: 3, step: 796, cost: 8.353798, mlm loss: 8.353798, speed: 1.054585 steps/s, speed: 8.436678 samples/s, speed: 4319.579178 tokens/s, learning rate: 7.950e-06, loss_scalings: 13421.773438, pp_loss: 8.520851
[INFO] 2021-07-12 18:46:38,672 [run_pretraining.py:  512]:	********exe.run_796******* 
[INFO] 2021-07-12 18:46:39,752 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:39,753 [run_pretraining.py:  534]:	loss/total_loss, 8.256074905395508, 797
[INFO] 2021-07-12 18:46:39,753 [run_pretraining.py:  535]:	loss/mlm_loss, 8.256074905395508, 797
[INFO] 2021-07-12 18:46:39,753 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.959999493323267e-06, 797
[INFO] 2021-07-12 18:46:39,753 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 797
[INFO] 2021-07-12 18:46:39,753 [run_pretraining.py:  558]:	worker_index: 3, step: 797, cost: 8.256075, mlm loss: 8.256075, speed: 0.925567 steps/s, speed: 7.404539 samples/s, speed: 3791.124064 tokens/s, learning rate: 7.960e-06, loss_scalings: 13421.773438, pp_loss: 8.488297
[INFO] 2021-07-12 18:46:39,753 [run_pretraining.py:  512]:	********exe.run_797******* 
[INFO] 2021-07-12 18:46:40,812 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:40,813 [run_pretraining.py:  534]:	loss/total_loss, 7.085986137390137, 798
[INFO] 2021-07-12 18:46:40,813 [run_pretraining.py:  535]:	loss/mlm_loss, 7.085986137390137, 798
[INFO] 2021-07-12 18:46:40,813 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.970000297063962e-06, 798
[INFO] 2021-07-12 18:46:40,813 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 798
[INFO] 2021-07-12 18:46:40,813 [run_pretraining.py:  558]:	worker_index: 3, step: 798, cost: 7.085986, mlm loss: 7.085986, speed: 0.944159 steps/s, speed: 7.553271 samples/s, speed: 3867.274747 tokens/s, learning rate: 7.970e-06, loss_scalings: 13421.773438, pp_loss: 7.902658
[INFO] 2021-07-12 18:46:40,813 [run_pretraining.py:  512]:	********exe.run_798******* 
[INFO] 2021-07-12 18:46:41,884 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:41,885 [run_pretraining.py:  534]:	loss/total_loss, 8.567744255065918, 799
[INFO] 2021-07-12 18:46:41,885 [run_pretraining.py:  535]:	loss/mlm_loss, 8.567744255065918, 799
[INFO] 2021-07-12 18:46:41,885 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.980000191309955e-06, 799
[INFO] 2021-07-12 18:46:41,885 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 799
[INFO] 2021-07-12 18:46:41,885 [run_pretraining.py:  558]:	worker_index: 3, step: 799, cost: 8.567744, mlm loss: 8.567744, speed: 0.933273 steps/s, speed: 7.466183 samples/s, speed: 3822.685919 tokens/s, learning rate: 7.980e-06, loss_scalings: 13421.773438, pp_loss: 7.766829
[INFO] 2021-07-12 18:46:41,885 [run_pretraining.py:  512]:	********exe.run_799******* 
[INFO] 2021-07-12 18:46:42,811 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:42,812 [run_pretraining.py:  534]:	loss/total_loss, 8.812034606933594, 800
[INFO] 2021-07-12 18:46:42,812 [run_pretraining.py:  535]:	loss/mlm_loss, 8.812034606933594, 800
[INFO] 2021-07-12 18:46:42,812 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.989999176061247e-06, 800
[INFO] 2021-07-12 18:46:42,812 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 800
[INFO] 2021-07-12 18:46:42,812 [run_pretraining.py:  558]:	worker_index: 3, step: 800, cost: 8.812035, mlm loss: 8.812035, speed: 1.079195 steps/s, speed: 8.633557 samples/s, speed: 4420.381248 tokens/s, learning rate: 7.990e-06, loss_scalings: 13421.773438, pp_loss: 8.361367
[INFO] 2021-07-12 18:46:42,812 [run_pretraining.py:  512]:	********exe.run_800******* 
[INFO] 2021-07-12 18:46:43,733 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:43,734 [run_pretraining.py:  534]:	loss/total_loss, 8.394363403320312, 801
[INFO] 2021-07-12 18:46:43,734 [run_pretraining.py:  535]:	loss/mlm_loss, 8.394363403320312, 801
[INFO] 2021-07-12 18:46:43,734 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.999999979801942e-06, 801
[INFO] 2021-07-12 18:46:43,734 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 801
[INFO] 2021-07-12 18:46:43,734 [run_pretraining.py:  558]:	worker_index: 3, step: 801, cost: 8.394363, mlm loss: 8.394363, speed: 1.085387 steps/s, speed: 8.683097 samples/s, speed: 4445.745879 tokens/s, learning rate: 8.000e-06, loss_scalings: 13421.773438, pp_loss: 8.370687
[INFO] 2021-07-12 18:46:43,734 [run_pretraining.py:  512]:	********exe.run_801******* 
[INFO] 2021-07-12 18:46:44,653 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:44,654 [run_pretraining.py:  534]:	loss/total_loss, 8.805792808532715, 802
[INFO] 2021-07-12 18:46:44,654 [run_pretraining.py:  535]:	loss/mlm_loss, 8.805792808532715, 802
[INFO] 2021-07-12 18:46:44,654 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.009999874047935e-06, 802
[INFO] 2021-07-12 18:46:44,654 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 802
[INFO] 2021-07-12 18:46:44,654 [run_pretraining.py:  558]:	worker_index: 3, step: 802, cost: 8.805793, mlm loss: 8.805793, speed: 1.087607 steps/s, speed: 8.700853 samples/s, speed: 4454.836915 tokens/s, learning rate: 8.010e-06, loss_scalings: 13421.773438, pp_loss: 8.468975
[INFO] 2021-07-12 18:46:44,654 [run_pretraining.py:  512]:	********exe.run_802******* 
[INFO] 2021-07-12 18:46:45,577 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:45,577 [run_pretraining.py:  534]:	loss/total_loss, 8.38569450378418, 803
[INFO] 2021-07-12 18:46:45,577 [run_pretraining.py:  535]:	loss/mlm_loss, 8.38569450378418, 803
[INFO] 2021-07-12 18:46:45,577 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.019999768293928e-06, 803
[INFO] 2021-07-12 18:46:45,577 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 803
[INFO] 2021-07-12 18:46:45,577 [run_pretraining.py:  558]:	worker_index: 3, step: 803, cost: 8.385695, mlm loss: 8.385695, speed: 1.084035 steps/s, speed: 8.672283 samples/s, speed: 4440.208744 tokens/s, learning rate: 8.020e-06, loss_scalings: 13421.773438, pp_loss: 8.615148
[INFO] 2021-07-12 18:46:45,577 [run_pretraining.py:  512]:	********exe.run_803******* 
[INFO] 2021-07-12 18:46:46,490 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:46,491 [run_pretraining.py:  534]:	loss/total_loss, 8.228645324707031, 804
[INFO] 2021-07-12 18:46:46,491 [run_pretraining.py:  535]:	loss/mlm_loss, 8.228645324707031, 804
[INFO] 2021-07-12 18:46:46,491 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.030000572034623e-06, 804
[INFO] 2021-07-12 18:46:46,491 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 804
[INFO] 2021-07-12 18:46:46,491 [run_pretraining.py:  558]:	worker_index: 3, step: 804, cost: 8.228645, mlm loss: 8.228645, speed: 1.095081 steps/s, speed: 8.760646 samples/s, speed: 4485.450941 tokens/s, learning rate: 8.030e-06, loss_scalings: 13421.773438, pp_loss: 8.293063
[INFO] 2021-07-12 18:46:46,491 [run_pretraining.py:  512]:	********exe.run_804******* 
[INFO] 2021-07-12 18:46:47,412 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:47,413 [run_pretraining.py:  534]:	loss/total_loss, 8.537327766418457, 805
[INFO] 2021-07-12 18:46:47,413 [run_pretraining.py:  535]:	loss/mlm_loss, 8.537327766418457, 805
[INFO] 2021-07-12 18:46:47,413 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.039999556785915e-06, 805
[INFO] 2021-07-12 18:46:47,413 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 805
[INFO] 2021-07-12 18:46:47,413 [run_pretraining.py:  558]:	worker_index: 3, step: 805, cost: 8.537328, mlm loss: 8.537328, speed: 1.085412 steps/s, speed: 8.683297 samples/s, speed: 4445.848272 tokens/s, learning rate: 8.040e-06, loss_scalings: 13421.773438, pp_loss: 7.741309
[INFO] 2021-07-12 18:46:47,413 [run_pretraining.py:  512]:	********exe.run_805******* 
[INFO] 2021-07-12 18:46:48,407 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:48,408 [run_pretraining.py:  534]:	loss/total_loss, 8.56107234954834, 806
[INFO] 2021-07-12 18:46:48,408 [run_pretraining.py:  535]:	loss/mlm_loss, 8.56107234954834, 806
[INFO] 2021-07-12 18:46:48,408 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.049999451031908e-06, 806
[INFO] 2021-07-12 18:46:48,408 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 806
[INFO] 2021-07-12 18:46:48,408 [run_pretraining.py:  558]:	worker_index: 3, step: 806, cost: 8.561072, mlm loss: 8.561072, speed: 1.005456 steps/s, speed: 8.043644 samples/s, speed: 4118.345856 tokens/s, learning rate: 8.050e-06, loss_scalings: 13421.773438, pp_loss: 8.454143
[INFO] 2021-07-12 18:46:48,408 [run_pretraining.py:  512]:	********exe.run_806******* 
[INFO] 2021-07-12 18:46:49,466 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:49,467 [run_pretraining.py:  534]:	loss/total_loss, 8.205466270446777, 807
[INFO] 2021-07-12 18:46:49,468 [run_pretraining.py:  535]:	loss/mlm_loss, 8.205466270446777, 807
[INFO] 2021-07-12 18:46:49,469 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.060000254772604e-06, 807
[INFO] 2021-07-12 18:46:49,470 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 807
[INFO] 2021-07-12 18:46:49,471 [run_pretraining.py:  558]:	worker_index: 3, step: 807, cost: 8.205466, mlm loss: 8.205466, speed: 0.945074 steps/s, speed: 7.560591 samples/s, speed: 3871.022581 tokens/s, learning rate: 8.060e-06, loss_scalings: 13421.773438, pp_loss: 8.457420
[INFO] 2021-07-12 18:46:49,471 [run_pretraining.py:  512]:	********exe.run_807******* 
[INFO] 2021-07-12 18:46:50,528 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:50,529 [run_pretraining.py:  534]:	loss/total_loss, 8.32127571105957, 808
[INFO] 2021-07-12 18:46:50,529 [run_pretraining.py:  535]:	loss/mlm_loss, 8.32127571105957, 808
[INFO] 2021-07-12 18:46:50,529 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.070000149018597e-06, 808
[INFO] 2021-07-12 18:46:50,529 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 808
[INFO] 2021-07-12 18:46:50,529 [run_pretraining.py:  558]:	worker_index: 3, step: 808, cost: 8.321276, mlm loss: 8.321276, speed: 0.945371 steps/s, speed: 7.562970 samples/s, speed: 3872.240598 tokens/s, learning rate: 8.070e-06, loss_scalings: 13421.773438, pp_loss: 7.367660
[INFO] 2021-07-12 18:46:50,529 [run_pretraining.py:  512]:	********exe.run_808******* 
[INFO] 2021-07-12 18:47:16,738 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:16,739 [run_pretraining.py:  534]:	loss/total_loss, 8.45649528503418, 809
[INFO] 2021-07-12 18:47:16,739 [run_pretraining.py:  535]:	loss/mlm_loss, 8.45649528503418, 809
[INFO] 2021-07-12 18:47:16,739 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.079999133769888e-06, 809
[INFO] 2021-07-12 18:47:16,739 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 809
[INFO] 2021-07-12 18:47:16,739 [run_pretraining.py:  558]:	worker_index: 3, step: 809, cost: 8.456495, mlm loss: 8.456495, speed: 0.038154 steps/s, speed: 0.305230 samples/s, speed: 156.277655 tokens/s, learning rate: 8.080e-06, loss_scalings: 13421.773438, pp_loss: 8.523214
[INFO] 2021-07-12 18:47:16,740 [run_pretraining.py:  512]:	********exe.run_809******* 
[INFO] 2021-07-12 18:47:17,835 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:17,835 [run_pretraining.py:  534]:	loss/total_loss, 8.375929832458496, 810
[INFO] 2021-07-12 18:47:17,835 [run_pretraining.py:  535]:	loss/mlm_loss, 8.375929832458496, 810
[INFO] 2021-07-12 18:47:17,836 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.089999937510584e-06, 810
[INFO] 2021-07-12 18:47:17,836 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 810
[INFO] 2021-07-12 18:47:17,836 [run_pretraining.py:  558]:	worker_index: 3, step: 810, cost: 8.375930, mlm loss: 8.375930, speed: 0.912740 steps/s, speed: 7.301918 samples/s, speed: 3738.582153 tokens/s, learning rate: 8.090e-06, loss_scalings: 13421.773438, pp_loss: 8.333302
[INFO] 2021-07-12 18:47:17,836 [run_pretraining.py:  512]:	********exe.run_810******* 
[INFO] 2021-07-12 18:47:18,757 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:18,757 [run_pretraining.py:  534]:	loss/total_loss, 8.247608184814453, 811
[INFO] 2021-07-12 18:47:18,758 [run_pretraining.py:  535]:	loss/mlm_loss, 8.247608184814453, 811
[INFO] 2021-07-12 18:47:18,758 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.099999831756577e-06, 811
[INFO] 2021-07-12 18:47:18,758 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 811
[INFO] 2021-07-12 18:47:18,758 [run_pretraining.py:  558]:	worker_index: 3, step: 811, cost: 8.247608, mlm loss: 8.247608, speed: 1.085199 steps/s, speed: 8.681592 samples/s, speed: 4444.975208 tokens/s, learning rate: 8.100e-06, loss_scalings: 13421.773438, pp_loss: 8.508057
[INFO] 2021-07-12 18:47:18,758 [run_pretraining.py:  512]:	********exe.run_811******* 
[INFO] 2021-07-12 18:47:19,683 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:19,683 [run_pretraining.py:  534]:	loss/total_loss, 8.725409507751465, 812
[INFO] 2021-07-12 18:47:19,684 [run_pretraining.py:  535]:	loss/mlm_loss, 8.725409507751465, 812
[INFO] 2021-07-12 18:47:19,684 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.10999972600257e-06, 812
[INFO] 2021-07-12 18:47:19,684 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 812
[INFO] 2021-07-12 18:47:19,684 [run_pretraining.py:  558]:	worker_index: 3, step: 812, cost: 8.725410, mlm loss: 8.725410, speed: 1.080796 steps/s, speed: 8.646369 samples/s, speed: 4426.941049 tokens/s, learning rate: 8.110e-06, loss_scalings: 13421.773438, pp_loss: 7.848930
[INFO] 2021-07-12 18:47:19,684 [run_pretraining.py:  512]:	********exe.run_812******* 
[INFO] 2021-07-12 18:47:20,605 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:20,605 [run_pretraining.py:  534]:	loss/total_loss, 8.473402976989746, 813
[INFO] 2021-07-12 18:47:20,605 [run_pretraining.py:  535]:	loss/mlm_loss, 8.473402976989746, 813
[INFO] 2021-07-12 18:47:20,606 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.120000529743265e-06, 813
[INFO] 2021-07-12 18:47:20,606 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 813
[INFO] 2021-07-12 18:47:20,606 [run_pretraining.py:  558]:	worker_index: 3, step: 813, cost: 8.473403, mlm loss: 8.473403, speed: 1.085451 steps/s, speed: 8.683610 samples/s, speed: 4446.008198 tokens/s, learning rate: 8.120e-06, loss_scalings: 13421.773438, pp_loss: 8.480081
[INFO] 2021-07-12 18:47:20,606 [run_pretraining.py:  512]:	********exe.run_813******* 
[INFO] 2021-07-12 18:47:21,530 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:21,530 [run_pretraining.py:  534]:	loss/total_loss, 8.288103103637695, 814
[INFO] 2021-07-12 18:47:21,530 [run_pretraining.py:  535]:	loss/mlm_loss, 8.288103103637695, 814
[INFO] 2021-07-12 18:47:21,530 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.129999514494557e-06, 814
[INFO] 2021-07-12 18:47:21,530 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 814
[INFO] 2021-07-12 18:47:21,531 [run_pretraining.py:  558]:	worker_index: 3, step: 814, cost: 8.288103, mlm loss: 8.288103, speed: 1.081991 steps/s, speed: 8.655927 samples/s, speed: 4431.834534 tokens/s, learning rate: 8.130e-06, loss_scalings: 13421.773438, pp_loss: 8.285658
[INFO] 2021-07-12 18:47:21,531 [run_pretraining.py:  512]:	********exe.run_814******* 
[INFO] 2021-07-12 18:47:22,452 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:22,452 [run_pretraining.py:  534]:	loss/total_loss, 8.498648643493652, 815
[INFO] 2021-07-12 18:47:22,452 [run_pretraining.py:  535]:	loss/mlm_loss, 8.498648643493652, 815
[INFO] 2021-07-12 18:47:22,452 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.13999940874055e-06, 815
[INFO] 2021-07-12 18:47:22,452 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 815
[INFO] 2021-07-12 18:47:22,453 [run_pretraining.py:  558]:	worker_index: 3, step: 815, cost: 8.498649, mlm loss: 8.498649, speed: 1.085331 steps/s, speed: 8.682650 samples/s, speed: 4445.516950 tokens/s, learning rate: 8.140e-06, loss_scalings: 13421.773438, pp_loss: 8.495510
[INFO] 2021-07-12 18:47:22,453 [run_pretraining.py:  512]:	********exe.run_815******* 
[INFO] 2021-07-12 18:47:23,393 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:23,393 [run_pretraining.py:  534]:	loss/total_loss, 8.635846138000488, 816
[INFO] 2021-07-12 18:47:23,394 [run_pretraining.py:  535]:	loss/mlm_loss, 8.635846138000488, 816
[INFO] 2021-07-12 18:47:23,394 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.150000212481245e-06, 816
[INFO] 2021-07-12 18:47:23,394 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 816
[INFO] 2021-07-12 18:47:23,394 [run_pretraining.py:  558]:	worker_index: 3, step: 816, cost: 8.635846, mlm loss: 8.635846, speed: 1.063080 steps/s, speed: 8.504637 samples/s, speed: 4354.374021 tokens/s, learning rate: 8.150e-06, loss_scalings: 13421.773438, pp_loss: 8.522730
[INFO] 2021-07-12 18:47:23,394 [run_pretraining.py:  512]:	********exe.run_816******* 
[INFO] 2021-07-12 18:47:24,313 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:24,313 [run_pretraining.py:  534]:	loss/total_loss, 8.285841941833496, 817
[INFO] 2021-07-12 18:47:24,313 [run_pretraining.py:  535]:	loss/mlm_loss, 8.285841941833496, 817
[INFO] 2021-07-12 18:47:24,313 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.160000106727239e-06, 817
[INFO] 2021-07-12 18:47:24,314 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 817
[INFO] 2021-07-12 18:47:24,314 [run_pretraining.py:  558]:	worker_index: 3, step: 817, cost: 8.285842, mlm loss: 8.285842, speed: 1.087949 steps/s, speed: 8.703595 samples/s, speed: 4456.240882 tokens/s, learning rate: 8.160e-06, loss_scalings: 13421.773438, pp_loss: 8.573644
[INFO] 2021-07-12 18:47:24,314 [run_pretraining.py:  512]:	********exe.run_817******* 
[INFO] 2021-07-12 18:47:25,233 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:25,233 [run_pretraining.py:  534]:	loss/total_loss, 8.689156532287598, 818
[INFO] 2021-07-12 18:47:25,234 [run_pretraining.py:  535]:	loss/mlm_loss, 8.689156532287598, 818
[INFO] 2021-07-12 18:47:25,234 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.16999909147853e-06, 818
[INFO] 2021-07-12 18:47:25,234 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 818
[INFO] 2021-07-12 18:47:25,234 [run_pretraining.py:  558]:	worker_index: 3, step: 818, cost: 8.689157, mlm loss: 8.689157, speed: 1.087508 steps/s, speed: 8.700066 samples/s, speed: 4454.433799 tokens/s, learning rate: 8.170e-06, loss_scalings: 13421.773438, pp_loss: 8.564082
[INFO] 2021-07-12 18:47:25,234 [run_pretraining.py:  512]:	********exe.run_818******* 
[INFO] 2021-07-12 18:47:26,151 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:26,152 [run_pretraining.py:  534]:	loss/total_loss, 8.777074813842773, 819
[INFO] 2021-07-12 18:47:26,152 [run_pretraining.py:  535]:	loss/mlm_loss, 8.777074813842773, 819
[INFO] 2021-07-12 18:47:26,152 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.179999895219225e-06, 819
[INFO] 2021-07-12 18:47:26,152 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 819
[INFO] 2021-07-12 18:47:26,152 [run_pretraining.py:  558]:	worker_index: 3, step: 819, cost: 8.777075, mlm loss: 8.777075, speed: 1.089992 steps/s, speed: 8.719935 samples/s, speed: 4464.606725 tokens/s, learning rate: 8.180e-06, loss_scalings: 13421.773438, pp_loss: 8.604706
[INFO] 2021-07-12 18:47:26,152 [run_pretraining.py:  512]:	********exe.run_819******* 
[INFO] 2021-07-12 18:47:27,070 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:27,071 [run_pretraining.py:  534]:	loss/total_loss, 8.949237823486328, 820
[INFO] 2021-07-12 18:47:27,071 [run_pretraining.py:  535]:	loss/mlm_loss, 8.949237823486328, 820
[INFO] 2021-07-12 18:47:27,071 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.189999789465219e-06, 820
[INFO] 2021-07-12 18:47:27,071 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 820
[INFO] 2021-07-12 18:47:27,071 [run_pretraining.py:  558]:	worker_index: 3, step: 820, cost: 8.949238, mlm loss: 8.949238, speed: 1.088667 steps/s, speed: 8.709338 samples/s, speed: 4459.181099 tokens/s, learning rate: 8.190e-06, loss_scalings: 13421.773438, pp_loss: 8.684333
[INFO] 2021-07-12 18:47:27,071 [run_pretraining.py:  512]:	********exe.run_820******* 
[INFO] 2021-07-12 18:47:28,021 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:28,021 [run_pretraining.py:  534]:	loss/total_loss, 8.92717170715332, 821
[INFO] 2021-07-12 18:47:28,021 [run_pretraining.py:  535]:	loss/mlm_loss, 8.92717170715332, 821
[INFO] 2021-07-12 18:47:28,022 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.199999683711212e-06, 821
[INFO] 2021-07-12 18:47:28,022 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 821
[INFO] 2021-07-12 18:47:28,022 [run_pretraining.py:  558]:	worker_index: 3, step: 821, cost: 8.927172, mlm loss: 8.927172, speed: 1.052655 steps/s, speed: 8.421236 samples/s, speed: 4311.672873 tokens/s, learning rate: 8.200e-06, loss_scalings: 13421.773438, pp_loss: 7.776606
[INFO] 2021-07-12 18:47:28,022 [run_pretraining.py:  512]:	********exe.run_821******* 
[INFO] 2021-07-12 18:47:29,036 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:29,036 [run_pretraining.py:  534]:	loss/total_loss, 8.945560455322266, 822
[INFO] 2021-07-12 18:47:29,037 [run_pretraining.py:  535]:	loss/mlm_loss, 8.945560455322266, 822
[INFO] 2021-07-12 18:47:29,037 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.209999577957205e-06, 822
[INFO] 2021-07-12 18:47:29,037 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 822
[INFO] 2021-07-12 18:47:29,037 [run_pretraining.py:  558]:	worker_index: 3, step: 822, cost: 8.945560, mlm loss: 8.945560, speed: 0.985778 steps/s, speed: 7.886226 samples/s, speed: 4037.747630 tokens/s, learning rate: 8.210e-06, loss_scalings: 13421.773438, pp_loss: 8.679089
[INFO] 2021-07-12 18:47:29,037 [run_pretraining.py:  512]:	********exe.run_822******* 
[INFO] 2021-07-12 18:47:30,099 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:30,100 [run_pretraining.py:  534]:	loss/total_loss, 8.771245002746582, 823
[INFO] 2021-07-12 18:47:30,100 [run_pretraining.py:  535]:	loss/mlm_loss, 8.771245002746582, 823
[INFO] 2021-07-12 18:47:30,100 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.219999472203199e-06, 823
[INFO] 2021-07-12 18:47:30,100 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 823
[INFO] 2021-07-12 18:47:30,100 [run_pretraining.py:  558]:	worker_index: 3, step: 823, cost: 8.771245, mlm loss: 8.771245, speed: 0.941070 steps/s, speed: 7.528559 samples/s, speed: 3854.622022 tokens/s, learning rate: 8.220e-06, loss_scalings: 13421.773438, pp_loss: 8.857292
[INFO] 2021-07-12 18:47:30,100 [run_pretraining.py:  512]:	********exe.run_823******* 
[INFO] 2021-07-12 18:47:31,140 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:31,140 [run_pretraining.py:  534]:	loss/total_loss, 8.672372817993164, 824
[INFO] 2021-07-12 18:47:31,141 [run_pretraining.py:  535]:	loss/mlm_loss, 8.672372817993164, 824
[INFO] 2021-07-12 18:47:31,141 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.229999366449192e-06, 824
[INFO] 2021-07-12 18:47:31,141 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 824
[INFO] 2021-07-12 18:47:31,141 [run_pretraining.py:  558]:	worker_index: 3, step: 824, cost: 8.672373, mlm loss: 8.672373, speed: 0.961492 steps/s, speed: 7.691938 samples/s, speed: 3938.272086 tokens/s, learning rate: 8.230e-06, loss_scalings: 13421.773438, pp_loss: 8.637300
[INFO] 2021-07-12 18:47:31,141 [run_pretraining.py:  512]:	********exe.run_824******* 
[INFO] 2021-07-12 18:47:32,207 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:32,208 [run_pretraining.py:  534]:	loss/total_loss, 8.84101676940918, 825
[INFO] 2021-07-12 18:47:32,208 [run_pretraining.py:  535]:	loss/mlm_loss, 8.84101676940918, 825
[INFO] 2021-07-12 18:47:32,208 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.240000170189887e-06, 825
[INFO] 2021-07-12 18:47:32,208 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 825
[INFO] 2021-07-12 18:47:32,208 [run_pretraining.py:  558]:	worker_index: 3, step: 825, cost: 8.841017, mlm loss: 8.841017, speed: 0.937291 steps/s, speed: 7.498329 samples/s, speed: 3839.144687 tokens/s, learning rate: 8.240e-06, loss_scalings: 13421.773438, pp_loss: 8.540272
[INFO] 2021-07-12 18:47:32,208 [run_pretraining.py:  512]:	********exe.run_825******* 
[INFO] 2021-07-12 18:47:33,274 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:33,275 [run_pretraining.py:  534]:	loss/total_loss, 8.700984954833984, 826
[INFO] 2021-07-12 18:47:33,275 [run_pretraining.py:  535]:	loss/mlm_loss, 8.700984954833984, 826
[INFO] 2021-07-12 18:47:33,275 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.25000006443588e-06, 826
[INFO] 2021-07-12 18:47:33,275 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 826
[INFO] 2021-07-12 18:47:33,275 [run_pretraining.py:  558]:	worker_index: 3, step: 826, cost: 8.700985, mlm loss: 8.700985, speed: 0.937978 steps/s, speed: 7.503828 samples/s, speed: 3841.959885 tokens/s, learning rate: 8.250e-06, loss_scalings: 13421.773438, pp_loss: 8.629699
[INFO] 2021-07-12 18:47:33,275 [run_pretraining.py:  512]:	********exe.run_826******* 
[INFO] 2021-07-12 18:47:34,347 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:34,348 [run_pretraining.py:  534]:	loss/total_loss, 8.597757339477539, 827
[INFO] 2021-07-12 18:47:34,348 [run_pretraining.py:  535]:	loss/mlm_loss, 8.597757339477539, 827
[INFO] 2021-07-12 18:47:34,348 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.259999958681874e-06, 827
[INFO] 2021-07-12 18:47:34,348 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 827
[INFO] 2021-07-12 18:47:34,348 [run_pretraining.py:  558]:	worker_index: 3, step: 827, cost: 8.597757, mlm loss: 8.597757, speed: 0.932567 steps/s, speed: 7.460534 samples/s, speed: 3819.793570 tokens/s, learning rate: 8.260e-06, loss_scalings: 13421.773438, pp_loss: 8.817108
[INFO] 2021-07-12 18:47:34,348 [run_pretraining.py:  512]:	********exe.run_827******* 
[INFO] 2021-07-12 18:47:35,405 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:35,406 [run_pretraining.py:  534]:	loss/total_loss, 8.64716911315918, 828
[INFO] 2021-07-12 18:47:35,406 [run_pretraining.py:  535]:	loss/mlm_loss, 8.64716911315918, 828
[INFO] 2021-07-12 18:47:35,406 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.269999852927867e-06, 828
[INFO] 2021-07-12 18:47:35,406 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 828
[INFO] 2021-07-12 18:47:35,406 [run_pretraining.py:  558]:	worker_index: 3, step: 828, cost: 8.647169, mlm loss: 8.647169, speed: 0.945666 steps/s, speed: 7.565326 samples/s, speed: 3873.447156 tokens/s, learning rate: 8.270e-06, loss_scalings: 13421.773438, pp_loss: 8.877989
[INFO] 2021-07-12 18:47:35,406 [run_pretraining.py:  512]:	********exe.run_828******* 
[INFO] 2021-07-12 18:47:36,472 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:36,473 [run_pretraining.py:  534]:	loss/total_loss, 8.427983283996582, 829
[INFO] 2021-07-12 18:47:36,473 [run_pretraining.py:  535]:	loss/mlm_loss, 8.427983283996582, 829
[INFO] 2021-07-12 18:47:36,473 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.27999974717386e-06, 829
[INFO] 2021-07-12 18:47:36,473 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 829
[INFO] 2021-07-12 18:47:36,473 [run_pretraining.py:  558]:	worker_index: 3, step: 829, cost: 8.427983, mlm loss: 8.427983, speed: 0.937912 steps/s, speed: 7.503298 samples/s, speed: 3841.688402 tokens/s, learning rate: 8.280e-06, loss_scalings: 13421.773438, pp_loss: 8.473135
[INFO] 2021-07-12 18:47:36,473 [run_pretraining.py:  512]:	********exe.run_829******* 
[INFO] 2021-07-12 18:47:37,546 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:37,547 [run_pretraining.py:  534]:	loss/total_loss, 8.890128135681152, 830
[INFO] 2021-07-12 18:47:37,547 [run_pretraining.py:  535]:	loss/mlm_loss, 8.890128135681152, 830
[INFO] 2021-07-12 18:47:37,547 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.289999641419854e-06, 830
[INFO] 2021-07-12 18:47:37,547 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 830
[INFO] 2021-07-12 18:47:37,547 [run_pretraining.py:  558]:	worker_index: 3, step: 830, cost: 8.890128, mlm loss: 8.890128, speed: 0.931488 steps/s, speed: 7.451902 samples/s, speed: 3815.373849 tokens/s, learning rate: 8.290e-06, loss_scalings: 13421.773438, pp_loss: 8.633401
[INFO] 2021-07-12 18:47:37,547 [run_pretraining.py:  512]:	********exe.run_830******* 
[INFO] 2021-07-12 18:47:38,610 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:38,610 [run_pretraining.py:  534]:	loss/total_loss, 8.583097457885742, 831
[INFO] 2021-07-12 18:47:38,610 [run_pretraining.py:  535]:	loss/mlm_loss, 8.583097457885742, 831
[INFO] 2021-07-12 18:47:38,611 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.299999535665847e-06, 831
[INFO] 2021-07-12 18:47:38,611 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 831
[INFO] 2021-07-12 18:47:38,611 [run_pretraining.py:  558]:	worker_index: 3, step: 831, cost: 8.583097, mlm loss: 8.583097, speed: 0.940858 steps/s, speed: 7.526863 samples/s, speed: 3853.753902 tokens/s, learning rate: 8.300e-06, loss_scalings: 13421.773438, pp_loss: 8.608572
[INFO] 2021-07-12 18:47:38,611 [run_pretraining.py:  512]:	********exe.run_831******* 
[INFO] 2021-07-12 18:47:39,678 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:39,679 [run_pretraining.py:  534]:	loss/total_loss, 8.541807174682617, 832
[INFO] 2021-07-12 18:47:39,679 [run_pretraining.py:  535]:	loss/mlm_loss, 8.541807174682617, 832
[INFO] 2021-07-12 18:47:39,679 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.30999942991184e-06, 832
[INFO] 2021-07-12 18:47:39,679 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 832
[INFO] 2021-07-12 18:47:39,679 [run_pretraining.py:  558]:	worker_index: 3, step: 832, cost: 8.541807, mlm loss: 8.541807, speed: 0.936252 steps/s, speed: 7.490012 samples/s, speed: 3834.886389 tokens/s, learning rate: 8.310e-06, loss_scalings: 13421.773438, pp_loss: 8.398300
[INFO] 2021-07-12 18:47:39,679 [run_pretraining.py:  512]:	********exe.run_832******* 
[INFO] 2021-07-12 18:47:40,742 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:40,743 [run_pretraining.py:  534]:	loss/total_loss, 8.479166030883789, 833
[INFO] 2021-07-12 18:47:40,743 [run_pretraining.py:  535]:	loss/mlm_loss, 8.479166030883789, 833
[INFO] 2021-07-12 18:47:40,743 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.320000233652536e-06, 833
[INFO] 2021-07-12 18:47:40,743 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 833
[INFO] 2021-07-12 18:47:40,743 [run_pretraining.py:  558]:	worker_index: 3, step: 833, cost: 8.479166, mlm loss: 8.479166, speed: 0.940622 steps/s, speed: 7.524973 samples/s, speed: 3852.785943 tokens/s, learning rate: 8.320e-06, loss_scalings: 13421.773438, pp_loss: 8.550858
[INFO] 2021-07-12 18:47:40,743 [run_pretraining.py:  512]:	********exe.run_833******* 
[INFO] 2021-07-12 18:47:41,737 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:41,738 [run_pretraining.py:  534]:	loss/total_loss, 8.252416610717773, 834
[INFO] 2021-07-12 18:47:41,738 [run_pretraining.py:  535]:	loss/mlm_loss, 8.252416610717773, 834
[INFO] 2021-07-12 18:47:41,738 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.33000012789853e-06, 834
[INFO] 2021-07-12 18:47:41,738 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 834
[INFO] 2021-07-12 18:47:41,738 [run_pretraining.py:  558]:	worker_index: 3, step: 834, cost: 8.252417, mlm loss: 8.252417, speed: 1.005982 steps/s, speed: 8.047854 samples/s, speed: 4120.501157 tokens/s, learning rate: 8.330e-06, loss_scalings: 13421.773438, pp_loss: 8.376612
[INFO] 2021-07-12 18:47:41,738 [run_pretraining.py:  512]:	********exe.run_834******* 
[INFO] 2021-07-12 18:47:42,655 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:42,656 [run_pretraining.py:  534]:	loss/total_loss, 8.425185203552246, 835
[INFO] 2021-07-12 18:47:42,656 [run_pretraining.py:  535]:	loss/mlm_loss, 8.425185203552246, 835
[INFO] 2021-07-12 18:47:42,656 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.340000022144523e-06, 835
[INFO] 2021-07-12 18:47:42,656 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 835
[INFO] 2021-07-12 18:47:42,656 [run_pretraining.py:  558]:	worker_index: 3, step: 835, cost: 8.425185, mlm loss: 8.425185, speed: 1.090091 steps/s, speed: 8.720728 samples/s, speed: 4465.012845 tokens/s, learning rate: 8.340e-06, loss_scalings: 13421.773438, pp_loss: 8.370110
[INFO] 2021-07-12 18:47:42,656 [run_pretraining.py:  512]:	********exe.run_835******* 
[INFO] 2021-07-12 18:47:43,573 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:43,574 [run_pretraining.py:  534]:	loss/total_loss, 8.065982818603516, 836
[INFO] 2021-07-12 18:47:43,574 [run_pretraining.py:  535]:	loss/mlm_loss, 8.065982818603516, 836
[INFO] 2021-07-12 18:47:43,574 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.349999916390516e-06, 836
[INFO] 2021-07-12 18:47:43,574 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 836
[INFO] 2021-07-12 18:47:43,574 [run_pretraining.py:  558]:	worker_index: 3, step: 836, cost: 8.065983, mlm loss: 8.065983, speed: 1.089521 steps/s, speed: 8.716166 samples/s, speed: 4462.676926 tokens/s, learning rate: 8.350e-06, loss_scalings: 13421.773438, pp_loss: 8.148310
[INFO] 2021-07-12 18:47:43,574 [run_pretraining.py:  512]:	********exe.run_836******* 
[INFO] 2021-07-12 18:47:44,487 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:44,488 [run_pretraining.py:  534]:	loss/total_loss, 7.794465065002441, 837
[INFO] 2021-07-12 18:47:44,488 [run_pretraining.py:  535]:	loss/mlm_loss, 7.794465065002441, 837
[INFO] 2021-07-12 18:47:44,488 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.35999981063651e-06, 837
[INFO] 2021-07-12 18:47:44,488 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 837
[INFO] 2021-07-12 18:47:44,488 [run_pretraining.py:  558]:	worker_index: 3, step: 837, cost: 7.794465, mlm loss: 7.794465, speed: 1.094969 steps/s, speed: 8.759754 samples/s, speed: 4484.994260 tokens/s, learning rate: 8.360e-06, loss_scalings: 13421.773438, pp_loss: 7.854100
[INFO] 2021-07-12 18:47:44,488 [run_pretraining.py:  512]:	********exe.run_837******* 
[INFO] 2021-07-12 18:47:45,404 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:45,405 [run_pretraining.py:  534]:	loss/total_loss, 8.668675422668457, 838
[INFO] 2021-07-12 18:47:45,405 [run_pretraining.py:  535]:	loss/mlm_loss, 8.668675422668457, 838
[INFO] 2021-07-12 18:47:45,405 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.369999704882503e-06, 838
[INFO] 2021-07-12 18:47:45,405 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 838
[INFO] 2021-07-12 18:47:45,405 [run_pretraining.py:  558]:	worker_index: 3, step: 838, cost: 8.668675, mlm loss: 8.668675, speed: 1.091654 steps/s, speed: 8.733230 samples/s, speed: 4471.413754 tokens/s, learning rate: 8.370e-06, loss_scalings: 13421.773438, pp_loss: 7.533228
[INFO] 2021-07-12 18:47:45,405 [run_pretraining.py:  512]:	********exe.run_838******* 
[INFO] 2021-07-12 18:47:46,314 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:46,315 [run_pretraining.py:  534]:	loss/total_loss, 8.729116439819336, 839
[INFO] 2021-07-12 18:47:46,315 [run_pretraining.py:  535]:	loss/mlm_loss, 8.729116439819336, 839
[INFO] 2021-07-12 18:47:46,315 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.380000508623198e-06, 839
[INFO] 2021-07-12 18:47:46,315 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 839
[INFO] 2021-07-12 18:47:46,315 [run_pretraining.py:  558]:	worker_index: 3, step: 839, cost: 8.729116, mlm loss: 8.729116, speed: 1.099220 steps/s, speed: 8.793758 samples/s, speed: 4502.404319 tokens/s, learning rate: 8.380e-06, loss_scalings: 13421.773438, pp_loss: 8.413383
[INFO] 2021-07-12 18:47:46,315 [run_pretraining.py:  512]:	********exe.run_839******* 
[INFO] 2021-07-12 18:47:47,260 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:47,260 [run_pretraining.py:  534]:	loss/total_loss, 8.401698112487793, 840
[INFO] 2021-07-12 18:47:47,260 [run_pretraining.py:  535]:	loss/mlm_loss, 8.401698112487793, 840
[INFO] 2021-07-12 18:47:47,260 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.38999949337449e-06, 840
[INFO] 2021-07-12 18:47:47,261 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 840
[INFO] 2021-07-12 18:47:47,261 [run_pretraining.py:  558]:	worker_index: 3, step: 840, cost: 8.401698, mlm loss: 8.401698, speed: 1.058524 steps/s, speed: 8.468194 samples/s, speed: 4335.715434 tokens/s, learning rate: 8.390e-06, loss_scalings: 13421.773438, pp_loss: 8.189794
[INFO] 2021-07-12 18:47:47,261 [run_pretraining.py:  512]:	********exe.run_840******* 
[INFO] 2021-07-12 18:47:48,315 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:48,315 [run_pretraining.py:  534]:	loss/total_loss, 8.315900802612305, 841
[INFO] 2021-07-12 18:47:48,315 [run_pretraining.py:  535]:	loss/mlm_loss, 8.315900802612305, 841
[INFO] 2021-07-12 18:47:48,316 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.399999387620483e-06, 841
[INFO] 2021-07-12 18:47:48,316 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 841
[INFO] 2021-07-12 18:47:48,316 [run_pretraining.py:  558]:	worker_index: 3, step: 841, cost: 8.315901, mlm loss: 8.315901, speed: 0.948403 steps/s, speed: 7.587221 samples/s, speed: 3884.657180 tokens/s, learning rate: 8.400e-06, loss_scalings: 13421.773438, pp_loss: 7.841884
[INFO] 2021-07-12 18:47:48,316 [run_pretraining.py:  512]:	********exe.run_841******* 
[INFO] 2021-07-12 18:47:49,376 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:49,377 [run_pretraining.py:  534]:	loss/total_loss, 8.203348159790039, 842
[INFO] 2021-07-12 18:47:49,377 [run_pretraining.py:  535]:	loss/mlm_loss, 8.203348159790039, 842
[INFO] 2021-07-12 18:47:49,377 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.410000191361178e-06, 842
[INFO] 2021-07-12 18:47:49,377 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 842
[INFO] 2021-07-12 18:47:49,377 [run_pretraining.py:  558]:	worker_index: 3, step: 842, cost: 8.203348, mlm loss: 8.203348, speed: 0.942863 steps/s, speed: 7.542907 samples/s, speed: 3861.968244 tokens/s, learning rate: 8.410e-06, loss_scalings: 13421.773438, pp_loss: 8.288940
[INFO] 2021-07-12 18:47:49,377 [run_pretraining.py:  512]:	********exe.run_842******* 
[INFO] 2021-07-12 18:47:50,446 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:50,447 [run_pretraining.py:  534]:	loss/total_loss, 8.325775146484375, 843
[INFO] 2021-07-12 18:47:50,447 [run_pretraining.py:  535]:	loss/mlm_loss, 8.325775146484375, 843
[INFO] 2021-07-12 18:47:50,447 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.420000085607171e-06, 843
[INFO] 2021-07-12 18:47:50,447 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 843
[INFO] 2021-07-12 18:47:50,447 [run_pretraining.py:  558]:	worker_index: 3, step: 843, cost: 8.325775, mlm loss: 8.325775, speed: 0.935224 steps/s, speed: 7.481796 samples/s, speed: 3830.679379 tokens/s, learning rate: 8.420e-06, loss_scalings: 13421.773438, pp_loss: 8.221512
[INFO] 2021-07-12 18:47:50,447 [run_pretraining.py:  512]:	********exe.run_843******* 
[INFO] 2021-07-12 18:47:51,507 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:51,507 [run_pretraining.py:  534]:	loss/total_loss, 8.710443496704102, 844
[INFO] 2021-07-12 18:47:51,507 [run_pretraining.py:  535]:	loss/mlm_loss, 8.710443496704102, 844
[INFO] 2021-07-12 18:47:51,507 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.429999070358463e-06, 844
[INFO] 2021-07-12 18:47:51,507 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 844
[INFO] 2021-07-12 18:47:51,507 [run_pretraining.py:  558]:	worker_index: 3, step: 844, cost: 8.710443, mlm loss: 8.710443, speed: 0.943375 steps/s, speed: 7.547002 samples/s, speed: 3864.065109 tokens/s, learning rate: 8.430e-06, loss_scalings: 13421.773438, pp_loss: 8.391492
[INFO] 2021-07-12 18:47:51,508 [run_pretraining.py:  512]:	********exe.run_844******* 
[INFO] 2021-07-12 18:47:52,564 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:52,565 [run_pretraining.py:  534]:	loss/total_loss, 8.043429374694824, 845
[INFO] 2021-07-12 18:47:52,565 [run_pretraining.py:  535]:	loss/mlm_loss, 8.043429374694824, 845
[INFO] 2021-07-12 18:47:52,565 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.439999874099158e-06, 845
[INFO] 2021-07-12 18:47:52,565 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 845
[INFO] 2021-07-12 18:47:52,565 [run_pretraining.py:  558]:	worker_index: 3, step: 845, cost: 8.043429, mlm loss: 8.043429, speed: 0.945911 steps/s, speed: 7.567292 samples/s, speed: 3874.453487 tokens/s, learning rate: 8.440e-06, loss_scalings: 13421.773438, pp_loss: 8.111009
[INFO] 2021-07-12 18:47:52,565 [run_pretraining.py:  512]:	********exe.run_845******* 
[INFO] 2021-07-12 18:47:53,628 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:53,628 [run_pretraining.py:  534]:	loss/total_loss, 8.204422950744629, 846
[INFO] 2021-07-12 18:47:53,628 [run_pretraining.py:  535]:	loss/mlm_loss, 8.204422950744629, 846
[INFO] 2021-07-12 18:47:53,628 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.449999768345151e-06, 846
[INFO] 2021-07-12 18:47:53,628 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 846
[INFO] 2021-07-12 18:47:53,628 [run_pretraining.py:  558]:	worker_index: 3, step: 846, cost: 8.204423, mlm loss: 8.204423, speed: 0.941164 steps/s, speed: 7.529312 samples/s, speed: 3855.007786 tokens/s, learning rate: 8.450e-06, loss_scalings: 13421.773438, pp_loss: 8.112721
[INFO] 2021-07-12 18:47:53,629 [run_pretraining.py:  512]:	********exe.run_846******* 
[INFO] 2021-07-12 18:47:54,688 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:54,689 [run_pretraining.py:  534]:	loss/total_loss, 8.28342056274414, 847
[INFO] 2021-07-12 18:47:54,689 [run_pretraining.py:  535]:	loss/mlm_loss, 8.28342056274414, 847
[INFO] 2021-07-12 18:47:54,689 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.459999662591144e-06, 847
[INFO] 2021-07-12 18:47:54,689 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 847
[INFO] 2021-07-12 18:47:54,689 [run_pretraining.py:  558]:	worker_index: 3, step: 847, cost: 8.283421, mlm loss: 8.283421, speed: 0.943519 steps/s, speed: 7.548150 samples/s, speed: 3864.652709 tokens/s, learning rate: 8.460e-06, loss_scalings: 13421.773438, pp_loss: 8.245147
[INFO] 2021-07-12 18:47:54,689 [run_pretraining.py:  512]:	********exe.run_847******* 
[INFO] 2021-07-12 18:47:55,759 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:55,760 [run_pretraining.py:  534]:	loss/total_loss, 8.304651260375977, 848
[INFO] 2021-07-12 18:47:55,760 [run_pretraining.py:  535]:	loss/mlm_loss, 8.304651260375977, 848
[INFO] 2021-07-12 18:47:55,760 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.47000046633184e-06, 848
[INFO] 2021-07-12 18:47:55,760 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 848
[INFO] 2021-07-12 18:47:55,760 [run_pretraining.py:  558]:	worker_index: 3, step: 848, cost: 8.304651, mlm loss: 8.304651, speed: 0.933971 steps/s, speed: 7.471770 samples/s, speed: 3825.546020 tokens/s, learning rate: 8.470e-06, loss_scalings: 13421.773438, pp_loss: 8.146038
[INFO] 2021-07-12 18:47:55,760 [run_pretraining.py:  512]:	********exe.run_848******* 
[INFO] 2021-07-12 18:47:56,826 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:56,826 [run_pretraining.py:  534]:	loss/total_loss, 8.211605072021484, 849
[INFO] 2021-07-12 18:47:56,826 [run_pretraining.py:  535]:	loss/mlm_loss, 8.211605072021484, 849
[INFO] 2021-07-12 18:47:56,826 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.479999451083131e-06, 849
[INFO] 2021-07-12 18:47:56,826 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 849
[INFO] 2021-07-12 18:47:56,827 [run_pretraining.py:  558]:	worker_index: 3, step: 849, cost: 8.211605, mlm loss: 8.211605, speed: 0.938488 steps/s, speed: 7.507906 samples/s, speed: 3844.047975 tokens/s, learning rate: 8.480e-06, loss_scalings: 13421.773438, pp_loss: 8.134130
[INFO] 2021-07-12 18:47:56,827 [run_pretraining.py:  512]:	********exe.run_849******* 
[INFO] 2021-07-12 18:47:57,891 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:57,892 [run_pretraining.py:  534]:	loss/total_loss, 8.234885215759277, 850
[INFO] 2021-07-12 18:47:57,892 [run_pretraining.py:  535]:	loss/mlm_loss, 8.234885215759277, 850
[INFO] 2021-07-12 18:47:57,892 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.489999345329124e-06, 850
[INFO] 2021-07-12 18:47:57,892 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 850
[INFO] 2021-07-12 18:47:57,892 [run_pretraining.py:  558]:	worker_index: 3, step: 850, cost: 8.234885, mlm loss: 8.234885, speed: 0.939093 steps/s, speed: 7.512747 samples/s, speed: 3846.526711 tokens/s, learning rate: 8.490e-06, loss_scalings: 13421.773438, pp_loss: 8.018332
[INFO] 2021-07-12 18:47:57,892 [run_pretraining.py:  512]:	********exe.run_850******* 
[INFO] 2021-07-12 18:47:59,131 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:59,131 [run_pretraining.py:  534]:	loss/total_loss, 5.032166481018066, 851
[INFO] 2021-07-12 18:47:59,131 [run_pretraining.py:  535]:	loss/mlm_loss, 5.032166481018066, 851
[INFO] 2021-07-12 18:47:59,131 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.50000014906982e-06, 851
[INFO] 2021-07-12 18:47:59,132 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 851
[INFO] 2021-07-12 18:47:59,132 [run_pretraining.py:  558]:	worker_index: 3, step: 851, cost: 5.032166, mlm loss: 5.032166, speed: 0.807146 steps/s, speed: 6.457171 samples/s, speed: 3306.071669 tokens/s, learning rate: 8.500e-06, loss_scalings: 13421.773438, pp_loss: 7.443363
[INFO] 2021-07-12 18:47:59,132 [run_pretraining.py:  512]:	********exe.run_851******* 
[INFO] 2021-07-12 18:48:00,210 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:00,215 [run_pretraining.py:  534]:	loss/total_loss, 8.137045860290527, 852
[INFO] 2021-07-12 18:48:00,221 [run_pretraining.py:  535]:	loss/mlm_loss, 8.137045860290527, 852
[INFO] 2021-07-12 18:48:00,226 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.510000043315813e-06, 852
[INFO] 2021-07-12 18:48:00,231 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 852
[INFO] 2021-07-12 18:48:00,236 [run_pretraining.py:  558]:	worker_index: 3, step: 852, cost: 8.137046, mlm loss: 8.137046, speed: 0.922927 steps/s, speed: 7.383413 samples/s, speed: 3780.307700 tokens/s, learning rate: 8.510e-06, loss_scalings: 13421.773438, pp_loss: 8.004441
[INFO] 2021-07-12 18:48:00,241 [run_pretraining.py:  512]:	********exe.run_852******* 
[INFO] 2021-07-12 18:48:01,259 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:01,260 [run_pretraining.py:  534]:	loss/total_loss, 8.104037284851074, 853
[INFO] 2021-07-12 18:48:01,260 [run_pretraining.py:  535]:	loss/mlm_loss, 8.104037284851074, 853
[INFO] 2021-07-12 18:48:01,260 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.519999028067105e-06, 853
[INFO] 2021-07-12 18:48:01,260 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 853
[INFO] 2021-07-12 18:48:01,260 [run_pretraining.py:  558]:	worker_index: 3, step: 853, cost: 8.104037, mlm loss: 8.104037, speed: 0.982015 steps/s, speed: 7.856118 samples/s, speed: 4022.332588 tokens/s, learning rate: 8.520e-06, loss_scalings: 13421.773438, pp_loss: 8.132969
[INFO] 2021-07-12 18:48:01,260 [run_pretraining.py:  512]:	********exe.run_853******* 
[INFO] 2021-07-12 18:48:02,379 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:02,379 [run_pretraining.py:  534]:	loss/total_loss, 8.076332092285156, 854
[INFO] 2021-07-12 18:48:02,379 [run_pretraining.py:  535]:	loss/mlm_loss, 8.076332092285156, 854
[INFO] 2021-07-12 18:48:02,379 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.5299998318078e-06, 854
[INFO] 2021-07-12 18:48:02,379 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 854
[INFO] 2021-07-12 18:48:02,379 [run_pretraining.py:  558]:	worker_index: 3, step: 854, cost: 8.076332, mlm loss: 8.076332, speed: 0.893944 steps/s, speed: 7.151554 samples/s, speed: 3661.595492 tokens/s, learning rate: 8.530e-06, loss_scalings: 13421.773438, pp_loss: 8.190444
[INFO] 2021-07-12 18:48:02,380 [run_pretraining.py:  512]:	********exe.run_854******* 
[INFO] 2021-07-12 18:48:03,449 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:03,450 [run_pretraining.py:  534]:	loss/total_loss, 7.935659885406494, 855
[INFO] 2021-07-12 18:48:03,450 [run_pretraining.py:  535]:	loss/mlm_loss, 7.935659885406494, 855
[INFO] 2021-07-12 18:48:03,450 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.539999726053793e-06, 855
[INFO] 2021-07-12 18:48:03,450 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 855
[INFO] 2021-07-12 18:48:03,450 [run_pretraining.py:  558]:	worker_index: 3, step: 855, cost: 7.935660, mlm loss: 7.935660, speed: 0.934611 steps/s, speed: 7.476889 samples/s, speed: 3828.167277 tokens/s, learning rate: 8.540e-06, loss_scalings: 13421.773438, pp_loss: 8.269532
[INFO] 2021-07-12 18:48:03,450 [run_pretraining.py:  512]:	********exe.run_855******* 
[INFO] 2021-07-12 18:48:04,510 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:04,510 [run_pretraining.py:  534]:	loss/total_loss, 8.161352157592773, 856
[INFO] 2021-07-12 18:48:04,510 [run_pretraining.py:  535]:	loss/mlm_loss, 8.161352157592773, 856
[INFO] 2021-07-12 18:48:04,510 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.549999620299786e-06, 856
[INFO] 2021-07-12 18:48:04,511 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 856
[INFO] 2021-07-12 18:48:04,511 [run_pretraining.py:  558]:	worker_index: 3, step: 856, cost: 8.161352, mlm loss: 8.161352, speed: 0.943469 steps/s, speed: 7.547756 samples/s, speed: 3864.451028 tokens/s, learning rate: 8.550e-06, loss_scalings: 13421.773438, pp_loss: 8.264675
[INFO] 2021-07-12 18:48:04,511 [run_pretraining.py:  512]:	********exe.run_856******* 
[INFO] 2021-07-12 18:48:05,540 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:05,540 [run_pretraining.py:  534]:	loss/total_loss, 8.068115234375, 857
[INFO] 2021-07-12 18:48:05,540 [run_pretraining.py:  535]:	loss/mlm_loss, 8.068115234375, 857
[INFO] 2021-07-12 18:48:05,540 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.560000424040481e-06, 857
[INFO] 2021-07-12 18:48:05,541 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 857
[INFO] 2021-07-12 18:48:05,541 [run_pretraining.py:  558]:	worker_index: 3, step: 857, cost: 8.068115, mlm loss: 8.068115, speed: 0.971467 steps/s, speed: 7.771736 samples/s, speed: 3979.128912 tokens/s, learning rate: 8.560e-06, loss_scalings: 13421.773438, pp_loss: 8.007278
[INFO] 2021-07-12 18:48:05,541 [run_pretraining.py:  512]:	********exe.run_857******* 
[INFO] 2021-07-12 18:48:06,462 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:06,462 [run_pretraining.py:  534]:	loss/total_loss, 8.06096076965332, 858
[INFO] 2021-07-12 18:48:06,463 [run_pretraining.py:  535]:	loss/mlm_loss, 8.06096076965332, 858
[INFO] 2021-07-12 18:48:06,463 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.569999408791773e-06, 858
[INFO] 2021-07-12 18:48:06,463 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 858
[INFO] 2021-07-12 18:48:06,463 [run_pretraining.py:  558]:	worker_index: 3, step: 858, cost: 8.060961, mlm loss: 8.060961, speed: 1.085138 steps/s, speed: 8.681107 samples/s, speed: 4444.726810 tokens/s, learning rate: 8.570e-06, loss_scalings: 13421.773438, pp_loss: 8.367613
[INFO] 2021-07-12 18:48:06,463 [run_pretraining.py:  512]:	********exe.run_858******* 
[INFO] 2021-07-12 18:48:07,379 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:07,379 [run_pretraining.py:  534]:	loss/total_loss, 8.555049896240234, 859
[INFO] 2021-07-12 18:48:07,379 [run_pretraining.py:  535]:	loss/mlm_loss, 8.555049896240234, 859
[INFO] 2021-07-12 18:48:07,379 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.579999303037766e-06, 859
[INFO] 2021-07-12 18:48:07,379 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 859
[INFO] 2021-07-12 18:48:07,379 [run_pretraining.py:  558]:	worker_index: 3, step: 859, cost: 8.555050, mlm loss: 8.555050, speed: 1.091712 steps/s, speed: 8.733694 samples/s, speed: 4471.651177 tokens/s, learning rate: 8.580e-06, loss_scalings: 13421.773438, pp_loss: 8.471570
[INFO] 2021-07-12 18:48:07,380 [run_pretraining.py:  512]:	********exe.run_859******* 
[INFO] 2021-07-12 18:48:08,331 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:08,331 [run_pretraining.py:  534]:	loss/total_loss, 8.297796249389648, 860
[INFO] 2021-07-12 18:48:08,331 [run_pretraining.py:  535]:	loss/mlm_loss, 8.297796249389648, 860
[INFO] 2021-07-12 18:48:08,331 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.590000106778461e-06, 860
[INFO] 2021-07-12 18:48:08,331 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 860
[INFO] 2021-07-12 18:48:08,331 [run_pretraining.py:  558]:	worker_index: 3, step: 860, cost: 8.297796, mlm loss: 8.297796, speed: 1.051129 steps/s, speed: 8.409036 samples/s, speed: 4305.426253 tokens/s, learning rate: 8.590e-06, loss_scalings: 13421.773438, pp_loss: 8.226673
[INFO] 2021-07-12 18:48:08,332 [run_pretraining.py:  512]:	********exe.run_860******* 
[INFO] 2021-07-12 18:48:09,242 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:09,242 [run_pretraining.py:  534]:	loss/total_loss, 8.277420997619629, 861
[INFO] 2021-07-12 18:48:09,242 [run_pretraining.py:  535]:	loss/mlm_loss, 8.277420997619629, 861
[INFO] 2021-07-12 18:48:09,242 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.600000001024455e-06, 861
[INFO] 2021-07-12 18:48:09,243 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 861
[INFO] 2021-07-12 18:48:09,243 [run_pretraining.py:  558]:	worker_index: 3, step: 861, cost: 8.277421, mlm loss: 8.277421, speed: 1.098254 steps/s, speed: 8.786029 samples/s, speed: 4498.446658 tokens/s, learning rate: 8.600e-06, loss_scalings: 13421.773438, pp_loss: 8.321661
[INFO] 2021-07-12 18:48:09,243 [run_pretraining.py:  512]:	********exe.run_861******* 
[INFO] 2021-07-12 18:48:10,170 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:10,171 [run_pretraining.py:  534]:	loss/total_loss, 8.070999145507812, 862
[INFO] 2021-07-12 18:48:10,171 [run_pretraining.py:  535]:	loss/mlm_loss, 8.070999145507812, 862
[INFO] 2021-07-12 18:48:10,171 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.609999895270448e-06, 862
[INFO] 2021-07-12 18:48:10,171 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 862
[INFO] 2021-07-12 18:48:10,171 [run_pretraining.py:  558]:	worker_index: 3, step: 862, cost: 8.070999, mlm loss: 8.070999, speed: 1.077639 steps/s, speed: 8.621109 samples/s, speed: 4414.007562 tokens/s, learning rate: 8.610e-06, loss_scalings: 13421.773438, pp_loss: 8.239181
[INFO] 2021-07-12 18:48:10,171 [run_pretraining.py:  512]:	********exe.run_862******* 
[INFO] 2021-07-12 18:48:11,090 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:11,091 [run_pretraining.py:  534]:	loss/total_loss, 8.246370315551758, 863
[INFO] 2021-07-12 18:48:11,091 [run_pretraining.py:  535]:	loss/mlm_loss, 8.246370315551758, 863
[INFO] 2021-07-12 18:48:11,091 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.619999789516442e-06, 863
[INFO] 2021-07-12 18:48:11,091 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 863
[INFO] 2021-07-12 18:48:11,091 [run_pretraining.py:  558]:	worker_index: 3, step: 863, cost: 8.246370, mlm loss: 8.246370, speed: 1.087584 steps/s, speed: 8.700668 samples/s, speed: 4454.742193 tokens/s, learning rate: 8.620e-06, loss_scalings: 13421.773438, pp_loss: 8.240294
[INFO] 2021-07-12 18:48:11,091 [run_pretraining.py:  512]:	********exe.run_863******* 
[INFO] 2021-07-12 18:48:12,012 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:12,012 [run_pretraining.py:  534]:	loss/total_loss, 8.321544647216797, 864
[INFO] 2021-07-12 18:48:12,012 [run_pretraining.py:  535]:	loss/mlm_loss, 8.321544647216797, 864
[INFO] 2021-07-12 18:48:12,012 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.629999683762435e-06, 864
[INFO] 2021-07-12 18:48:12,012 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 864
[INFO] 2021-07-12 18:48:12,012 [run_pretraining.py:  558]:	worker_index: 3, step: 864, cost: 8.321545, mlm loss: 8.321545, speed: 1.086445 steps/s, speed: 8.691561 samples/s, speed: 4450.079259 tokens/s, learning rate: 8.630e-06, loss_scalings: 13421.773438, pp_loss: 8.094328
[INFO] 2021-07-12 18:48:12,013 [run_pretraining.py:  512]:	********exe.run_864******* 
[INFO] 2021-07-12 18:48:12,923 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:12,924 [run_pretraining.py:  534]:	loss/total_loss, 8.509586334228516, 865
[INFO] 2021-07-12 18:48:12,924 [run_pretraining.py:  535]:	loss/mlm_loss, 8.509586334228516, 865
[INFO] 2021-07-12 18:48:12,924 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.639999578008428e-06, 865
[INFO] 2021-07-12 18:48:12,924 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 865
[INFO] 2021-07-12 18:48:12,924 [run_pretraining.py:  558]:	worker_index: 3, step: 865, cost: 8.509586, mlm loss: 8.509586, speed: 1.097504 steps/s, speed: 8.780033 samples/s, speed: 4495.376814 tokens/s, learning rate: 8.640e-06, loss_scalings: 13421.773438, pp_loss: 8.054037
[INFO] 2021-07-12 18:48:12,924 [run_pretraining.py:  512]:	********exe.run_865******* 
[INFO] 2021-07-12 18:48:13,844 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:13,845 [run_pretraining.py:  534]:	loss/total_loss, 8.291513442993164, 866
[INFO] 2021-07-12 18:48:13,845 [run_pretraining.py:  535]:	loss/mlm_loss, 8.291513442993164, 866
[INFO] 2021-07-12 18:48:13,845 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.649999472254422e-06, 866
[INFO] 2021-07-12 18:48:13,845 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 866
[INFO] 2021-07-12 18:48:13,845 [run_pretraining.py:  558]:	worker_index: 3, step: 866, cost: 8.291513, mlm loss: 8.291513, speed: 1.086457 steps/s, speed: 8.691658 samples/s, speed: 4450.128825 tokens/s, learning rate: 8.650e-06, loss_scalings: 13421.773438, pp_loss: 8.237488
[INFO] 2021-07-12 18:48:13,845 [run_pretraining.py:  512]:	********exe.run_866******* 
[INFO] 2021-07-12 18:48:14,763 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:14,764 [run_pretraining.py:  534]:	loss/total_loss, 8.456892013549805, 867
[INFO] 2021-07-12 18:48:14,764 [run_pretraining.py:  535]:	loss/mlm_loss, 8.456892013549805, 867
[INFO] 2021-07-12 18:48:14,764 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.659999366500415e-06, 867
[INFO] 2021-07-12 18:48:14,764 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 867
[INFO] 2021-07-12 18:48:14,764 [run_pretraining.py:  558]:	worker_index: 3, step: 867, cost: 8.456892, mlm loss: 8.456892, speed: 1.088922 steps/s, speed: 8.711373 samples/s, speed: 4460.223019 tokens/s, learning rate: 8.660e-06, loss_scalings: 13421.773438, pp_loss: 8.444906
[INFO] 2021-07-12 18:48:14,764 [run_pretraining.py:  512]:	********exe.run_867******* 
[INFO] 2021-07-12 18:48:15,672 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:15,673 [run_pretraining.py:  534]:	loss/total_loss, 8.209098815917969, 868
[INFO] 2021-07-12 18:48:15,673 [run_pretraining.py:  535]:	loss/mlm_loss, 8.209098815917969, 868
[INFO] 2021-07-12 18:48:15,673 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.67000017024111e-06, 868
[INFO] 2021-07-12 18:48:15,673 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 868
[INFO] 2021-07-12 18:48:15,673 [run_pretraining.py:  558]:	worker_index: 3, step: 868, cost: 8.209099, mlm loss: 8.209099, speed: 1.101360 steps/s, speed: 8.810878 samples/s, speed: 4511.169611 tokens/s, learning rate: 8.670e-06, loss_scalings: 13421.773438, pp_loss: 8.366664
[INFO] 2021-07-12 18:48:15,673 [run_pretraining.py:  512]:	********exe.run_868******* 
[INFO] 2021-07-12 18:48:16,580 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:16,580 [run_pretraining.py:  534]:	loss/total_loss, 8.475172996520996, 869
[INFO] 2021-07-12 18:48:16,580 [run_pretraining.py:  535]:	loss/mlm_loss, 8.475172996520996, 869
[INFO] 2021-07-12 18:48:16,581 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.680000064487103e-06, 869
[INFO] 2021-07-12 18:48:16,581 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 869
[INFO] 2021-07-12 18:48:16,581 [run_pretraining.py:  558]:	worker_index: 3, step: 869, cost: 8.475173, mlm loss: 8.475173, speed: 1.102413 steps/s, speed: 8.819301 samples/s, speed: 4515.481988 tokens/s, learning rate: 8.680e-06, loss_scalings: 13421.773438, pp_loss: 8.221029
[INFO] 2021-07-12 18:48:16,581 [run_pretraining.py:  512]:	********exe.run_869******* 
[INFO] 2021-07-12 18:48:17,507 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:17,508 [run_pretraining.py:  534]:	loss/total_loss, 8.038557052612305, 870
[INFO] 2021-07-12 18:48:17,508 [run_pretraining.py:  535]:	loss/mlm_loss, 8.038557052612305, 870
[INFO] 2021-07-12 18:48:17,508 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.689999958733097e-06, 870
[INFO] 2021-07-12 18:48:17,508 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 870
[INFO] 2021-07-12 18:48:17,508 [run_pretraining.py:  558]:	worker_index: 3, step: 870, cost: 8.038557, mlm loss: 8.038557, speed: 1.079158 steps/s, speed: 8.633264 samples/s, speed: 4420.231121 tokens/s, learning rate: 8.690e-06, loss_scalings: 13421.773438, pp_loss: 7.806686
[INFO] 2021-07-12 18:48:17,508 [run_pretraining.py:  512]:	********exe.run_870******* 
[INFO] 2021-07-12 18:48:44,188 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:44,189 [run_pretraining.py:  534]:	loss/total_loss, 8.297378540039062, 871
[INFO] 2021-07-12 18:48:44,189 [run_pretraining.py:  535]:	loss/mlm_loss, 8.297378540039062, 871
[INFO] 2021-07-12 18:48:44,189 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.69999985297909e-06, 871
[INFO] 2021-07-12 18:48:44,189 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 871
[INFO] 2021-07-12 18:48:44,189 [run_pretraining.py:  558]:	worker_index: 3, step: 871, cost: 8.297379, mlm loss: 8.297379, speed: 0.037481 steps/s, speed: 0.299845 samples/s, speed: 153.520583 tokens/s, learning rate: 8.700e-06, loss_scalings: 13421.773438, pp_loss: 8.412715
[INFO] 2021-07-12 18:48:44,189 [run_pretraining.py:  512]:	********exe.run_871******* 
[INFO] 2021-07-12 18:48:45,094 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:45,095 [run_pretraining.py:  534]:	loss/total_loss, 8.398977279663086, 872
[INFO] 2021-07-12 18:48:45,095 [run_pretraining.py:  535]:	loss/mlm_loss, 8.398977279663086, 872
[INFO] 2021-07-12 18:48:45,095 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.709999747225083e-06, 872
[INFO] 2021-07-12 18:48:45,095 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 872
[INFO] 2021-07-12 18:48:45,095 [run_pretraining.py:  558]:	worker_index: 3, step: 872, cost: 8.398977, mlm loss: 8.398977, speed: 1.104569 steps/s, speed: 8.836548 samples/s, speed: 4524.312620 tokens/s, learning rate: 8.710e-06, loss_scalings: 13421.773438, pp_loss: 8.385584
[INFO] 2021-07-12 18:48:45,095 [run_pretraining.py:  512]:	********exe.run_872******* 
[INFO] 2021-07-12 18:49:12,316 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:12,317 [run_pretraining.py:  534]:	loss/total_loss, 8.005517959594727, 873
[INFO] 2021-07-12 18:49:12,317 [run_pretraining.py:  535]:	loss/mlm_loss, 8.005517959594727, 873
[INFO] 2021-07-12 18:49:12,317 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.719999641471077e-06, 873
[INFO] 2021-07-12 18:49:12,317 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 873
[INFO] 2021-07-12 18:49:12,317 [run_pretraining.py:  558]:	worker_index: 3, step: 873, cost: 8.005518, mlm loss: 8.005518, speed: 0.036736 steps/s, speed: 0.293889 samples/s, speed: 150.471003 tokens/s, learning rate: 8.720e-06, loss_scalings: 13421.773438, pp_loss: 8.273130
[INFO] 2021-07-12 18:49:12,317 [run_pretraining.py:  512]:	********exe.run_873******* 
[INFO] 2021-07-12 18:49:13,258 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:13,259 [run_pretraining.py:  534]:	loss/total_loss, 8.176877975463867, 874
[INFO] 2021-07-12 18:49:13,259 [run_pretraining.py:  535]:	loss/mlm_loss, 8.176877975463867, 874
[INFO] 2021-07-12 18:49:13,259 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.730000445211772e-06, 874
[INFO] 2021-07-12 18:49:13,259 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 874
[INFO] 2021-07-12 18:49:13,259 [run_pretraining.py:  558]:	worker_index: 3, step: 874, cost: 8.176878, mlm loss: 8.176878, speed: 1.062325 steps/s, speed: 8.498603 samples/s, speed: 4351.284888 tokens/s, learning rate: 8.730e-06, loss_scalings: 13421.773438, pp_loss: 7.970487
[INFO] 2021-07-12 18:49:13,259 [run_pretraining.py:  512]:	********exe.run_874******* 
[INFO] 2021-07-12 18:49:14,159 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:14,159 [run_pretraining.py:  534]:	loss/total_loss, 8.543224334716797, 875
[INFO] 2021-07-12 18:49:14,160 [run_pretraining.py:  535]:	loss/mlm_loss, 8.543224334716797, 875
[INFO] 2021-07-12 18:49:14,160 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.739999429963063e-06, 875
[INFO] 2021-07-12 18:49:14,160 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 875
[INFO] 2021-07-12 18:49:14,160 [run_pretraining.py:  558]:	worker_index: 3, step: 875, cost: 8.543224, mlm loss: 8.543224, speed: 1.110892 steps/s, speed: 8.887134 samples/s, speed: 4550.212610 tokens/s, learning rate: 8.740e-06, loss_scalings: 13421.773438, pp_loss: 7.687574
[INFO] 2021-07-12 18:49:14,160 [run_pretraining.py:  512]:	********exe.run_875******* 
[INFO] 2021-07-12 18:49:40,922 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:40,923 [run_pretraining.py:  534]:	loss/total_loss, 8.488626480102539, 876
[INFO] 2021-07-12 18:49:40,923 [run_pretraining.py:  535]:	loss/mlm_loss, 8.488626480102539, 876
[INFO] 2021-07-12 18:49:40,923 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.749999324209057e-06, 876
[INFO] 2021-07-12 18:49:40,923 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 876
[INFO] 2021-07-12 18:49:40,923 [run_pretraining.py:  558]:	worker_index: 3, step: 876, cost: 8.488626, mlm loss: 8.488626, speed: 0.037365 steps/s, speed: 0.298921 samples/s, speed: 153.047541 tokens/s, learning rate: 8.750e-06, loss_scalings: 13421.773438, pp_loss: 8.092188
[INFO] 2021-07-12 18:49:40,923 [run_pretraining.py:  512]:	********exe.run_876******* 
[INFO] 2021-07-12 18:49:41,850 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:41,850 [run_pretraining.py:  534]:	loss/total_loss, 7.4964776039123535, 877
[INFO] 2021-07-12 18:49:41,850 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4964776039123535, 877
[INFO] 2021-07-12 18:49:41,850 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.760000127949752e-06, 877
[INFO] 2021-07-12 18:49:41,850 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 877
[INFO] 2021-07-12 18:49:41,850 [run_pretraining.py:  558]:	worker_index: 3, step: 877, cost: 7.496478, mlm loss: 7.496478, speed: 1.079403 steps/s, speed: 8.635226 samples/s, speed: 4421.235573 tokens/s, learning rate: 8.760e-06, loss_scalings: 13421.773438, pp_loss: 8.054371
[INFO] 2021-07-12 18:49:41,851 [run_pretraining.py:  512]:	********exe.run_877******* 
[INFO] 2021-07-12 18:49:42,789 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:42,789 [run_pretraining.py:  534]:	loss/total_loss, 8.332442283630371, 878
[INFO] 2021-07-12 18:49:42,789 [run_pretraining.py:  535]:	loss/mlm_loss, 8.332442283630371, 878
[INFO] 2021-07-12 18:49:42,789 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.770000022195745e-06, 878
[INFO] 2021-07-12 18:49:42,790 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 878
[INFO] 2021-07-12 18:49:42,790 [run_pretraining.py:  558]:	worker_index: 3, step: 878, cost: 8.332442, mlm loss: 8.332442, speed: 1.065529 steps/s, speed: 8.524231 samples/s, speed: 4364.406088 tokens/s, learning rate: 8.770e-06, loss_scalings: 13421.773438, pp_loss: 8.264471
[INFO] 2021-07-12 18:49:42,790 [run_pretraining.py:  512]:	********exe.run_878******* 
[INFO] 2021-07-12 18:49:43,814 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:43,815 [run_pretraining.py:  534]:	loss/total_loss, 8.797845840454102, 879
[INFO] 2021-07-12 18:49:43,815 [run_pretraining.py:  535]:	loss/mlm_loss, 8.797845840454102, 879
[INFO] 2021-07-12 18:49:43,815 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.779999916441739e-06, 879
[INFO] 2021-07-12 18:49:43,815 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 879
[INFO] 2021-07-12 18:49:43,815 [run_pretraining.py:  558]:	worker_index: 3, step: 879, cost: 8.797846, mlm loss: 8.797846, speed: 0.975849 steps/s, speed: 7.806795 samples/s, speed: 3997.078989 tokens/s, learning rate: 8.780e-06, loss_scalings: 13421.773438, pp_loss: 8.165137
[INFO] 2021-07-12 18:49:43,815 [run_pretraining.py:  512]:	********exe.run_879******* 
[INFO] 2021-07-12 18:49:44,735 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:44,735 [run_pretraining.py:  534]:	loss/total_loss, 8.553256034851074, 880
[INFO] 2021-07-12 18:49:44,736 [run_pretraining.py:  535]:	loss/mlm_loss, 8.553256034851074, 880
[INFO] 2021-07-12 18:49:44,736 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.789999810687732e-06, 880
[INFO] 2021-07-12 18:49:44,736 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 880
[INFO] 2021-07-12 18:49:44,736 [run_pretraining.py:  558]:	worker_index: 3, step: 880, cost: 8.553256, mlm loss: 8.553256, speed: 1.086743 steps/s, speed: 8.693944 samples/s, speed: 4451.299148 tokens/s, learning rate: 8.790e-06, loss_scalings: 13421.773438, pp_loss: 8.449926
[INFO] 2021-07-12 18:49:44,736 [run_pretraining.py:  512]:	********exe.run_880******* 
[INFO] 2021-07-12 18:49:45,728 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:45,728 [run_pretraining.py:  534]:	loss/total_loss, 7.7651166915893555, 881
[INFO] 2021-07-12 18:49:45,729 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7651166915893555, 881
[INFO] 2021-07-12 18:49:45,729 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.799999704933725e-06, 881
[INFO] 2021-07-12 18:49:45,729 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 881
[INFO] 2021-07-12 18:49:45,729 [run_pretraining.py:  558]:	worker_index: 3, step: 881, cost: 7.765117, mlm loss: 7.765117, speed: 1.007750 steps/s, speed: 8.061996 samples/s, speed: 4127.742142 tokens/s, learning rate: 8.800e-06, loss_scalings: 13421.773438, pp_loss: 8.123017
[INFO] 2021-07-12 18:49:45,729 [run_pretraining.py:  512]:	********exe.run_881******* 
[INFO] 2021-07-12 18:49:46,792 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:46,793 [run_pretraining.py:  534]:	loss/total_loss, 8.616238594055176, 882
[INFO] 2021-07-12 18:49:46,793 [run_pretraining.py:  535]:	loss/mlm_loss, 8.616238594055176, 882
[INFO] 2021-07-12 18:49:46,793 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.809999599179719e-06, 882
[INFO] 2021-07-12 18:49:46,793 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 882
[INFO] 2021-07-12 18:49:46,793 [run_pretraining.py:  558]:	worker_index: 3, step: 882, cost: 8.616239, mlm loss: 8.616239, speed: 0.940194 steps/s, speed: 7.521552 samples/s, speed: 3851.034482 tokens/s, learning rate: 8.810e-06, loss_scalings: 13421.773438, pp_loss: 8.419415
[INFO] 2021-07-12 18:49:46,793 [run_pretraining.py:  512]:	********exe.run_882******* 
[INFO] 2021-07-12 18:49:47,854 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:47,855 [run_pretraining.py:  534]:	loss/total_loss, 7.920618057250977, 883
[INFO] 2021-07-12 18:49:47,855 [run_pretraining.py:  535]:	loss/mlm_loss, 7.920618057250977, 883
[INFO] 2021-07-12 18:49:47,855 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.820000402920414e-06, 883
[INFO] 2021-07-12 18:49:47,855 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 883
[INFO] 2021-07-12 18:49:47,855 [run_pretraining.py:  558]:	worker_index: 3, step: 883, cost: 7.920618, mlm loss: 7.920618, speed: 0.942303 steps/s, speed: 7.538428 samples/s, speed: 3859.675071 tokens/s, learning rate: 8.820e-06, loss_scalings: 13421.773438, pp_loss: 8.336618
[INFO] 2021-07-12 18:49:47,855 [run_pretraining.py:  512]:	********exe.run_883******* 
[INFO] 2021-07-12 18:49:48,909 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:48,910 [run_pretraining.py:  534]:	loss/total_loss, 8.526347160339355, 884
[INFO] 2021-07-12 18:49:48,910 [run_pretraining.py:  535]:	loss/mlm_loss, 8.526347160339355, 884
[INFO] 2021-07-12 18:49:48,910 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.829999387671705e-06, 884
[INFO] 2021-07-12 18:49:48,910 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 884
[INFO] 2021-07-12 18:49:48,910 [run_pretraining.py:  558]:	worker_index: 3, step: 884, cost: 8.526347, mlm loss: 8.526347, speed: 0.947980 steps/s, speed: 7.583839 samples/s, speed: 3882.925774 tokens/s, learning rate: 8.830e-06, loss_scalings: 13421.773438, pp_loss: 8.531198
[INFO] 2021-07-12 18:49:48,910 [run_pretraining.py:  512]:	********exe.run_884******* 
[INFO] 2021-07-12 18:49:49,996 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:49,996 [run_pretraining.py:  534]:	loss/total_loss, 8.243072509765625, 885
[INFO] 2021-07-12 18:49:49,997 [run_pretraining.py:  535]:	loss/mlm_loss, 8.243072509765625, 885
[INFO] 2021-07-12 18:49:49,997 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.839999281917699e-06, 885
[INFO] 2021-07-12 18:49:49,997 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 885
[INFO] 2021-07-12 18:49:49,997 [run_pretraining.py:  558]:	worker_index: 3, step: 885, cost: 8.243073, mlm loss: 8.243073, speed: 0.921043 steps/s, speed: 7.368345 samples/s, speed: 3772.592453 tokens/s, learning rate: 8.840e-06, loss_scalings: 13421.773438, pp_loss: 8.117290
[INFO] 2021-07-12 18:49:49,997 [run_pretraining.py:  512]:	********exe.run_885******* 
[INFO] 2021-07-12 18:49:51,080 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:51,081 [run_pretraining.py:  534]:	loss/total_loss, 7.982657432556152, 886
[INFO] 2021-07-12 18:49:51,081 [run_pretraining.py:  535]:	loss/mlm_loss, 7.982657432556152, 886
[INFO] 2021-07-12 18:49:51,081 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.850000085658394e-06, 886
[INFO] 2021-07-12 18:49:51,081 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 886
[INFO] 2021-07-12 18:49:51,081 [run_pretraining.py:  558]:	worker_index: 3, step: 886, cost: 7.982657, mlm loss: 7.982657, speed: 0.922968 steps/s, speed: 7.383745 samples/s, speed: 3780.477401 tokens/s, learning rate: 8.850e-06, loss_scalings: 13421.773438, pp_loss: 8.298555
[INFO] 2021-07-12 18:49:51,081 [run_pretraining.py:  512]:	********exe.run_886******* 
[INFO] 2021-07-12 18:49:52,154 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:52,155 [run_pretraining.py:  534]:	loss/total_loss, 8.296760559082031, 887
[INFO] 2021-07-12 18:49:52,155 [run_pretraining.py:  535]:	loss/mlm_loss, 8.296760559082031, 887
[INFO] 2021-07-12 18:49:52,155 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.859999979904387e-06, 887
[INFO] 2021-07-12 18:49:52,155 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 887
[INFO] 2021-07-12 18:49:52,155 [run_pretraining.py:  558]:	worker_index: 3, step: 887, cost: 8.296761, mlm loss: 8.296761, speed: 0.931241 steps/s, speed: 7.449925 samples/s, speed: 3814.361554 tokens/s, learning rate: 8.860e-06, loss_scalings: 13421.773438, pp_loss: 8.260153
[INFO] 2021-07-12 18:49:52,155 [run_pretraining.py:  512]:	********exe.run_887******* 
[INFO] 2021-07-12 18:49:53,219 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:53,220 [run_pretraining.py:  534]:	loss/total_loss, 6.882622718811035, 888
[INFO] 2021-07-12 18:49:53,220 [run_pretraining.py:  535]:	loss/mlm_loss, 6.882622718811035, 888
[INFO] 2021-07-12 18:49:53,220 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.86999987415038e-06, 888
[INFO] 2021-07-12 18:49:53,220 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 888
[INFO] 2021-07-12 18:49:53,220 [run_pretraining.py:  558]:	worker_index: 3, step: 888, cost: 6.882623, mlm loss: 6.882623, speed: 0.939702 steps/s, speed: 7.517617 samples/s, speed: 3849.019856 tokens/s, learning rate: 8.870e-06, loss_scalings: 13421.773438, pp_loss: 8.010242
[INFO] 2021-07-12 18:49:53,220 [run_pretraining.py:  512]:	********exe.run_888******* 
[INFO] 2021-07-12 18:49:54,297 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:54,298 [run_pretraining.py:  534]:	loss/total_loss, 8.784835815429688, 889
[INFO] 2021-07-12 18:49:54,298 [run_pretraining.py:  535]:	loss/mlm_loss, 8.784835815429688, 889
[INFO] 2021-07-12 18:49:54,298 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.879999768396374e-06, 889
[INFO] 2021-07-12 18:49:54,298 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 889
[INFO] 2021-07-12 18:49:54,298 [run_pretraining.py:  558]:	worker_index: 3, step: 889, cost: 8.784836, mlm loss: 8.784836, speed: 0.928190 steps/s, speed: 7.425520 samples/s, speed: 3801.866200 tokens/s, learning rate: 8.880e-06, loss_scalings: 13421.773438, pp_loss: 8.465124
[INFO] 2021-07-12 18:49:54,298 [run_pretraining.py:  512]:	********exe.run_889******* 
[INFO] 2021-07-12 18:49:55,203 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:55,203 [run_pretraining.py:  534]:	loss/total_loss, 8.380412101745605, 890
[INFO] 2021-07-12 18:49:55,203 [run_pretraining.py:  535]:	loss/mlm_loss, 8.380412101745605, 890
[INFO] 2021-07-12 18:49:55,203 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.889999662642367e-06, 890
[INFO] 2021-07-12 18:49:55,203 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 890
[INFO] 2021-07-12 18:49:55,203 [run_pretraining.py:  558]:	worker_index: 3, step: 890, cost: 8.380412, mlm loss: 8.380412, speed: 1.105426 steps/s, speed: 8.843411 samples/s, speed: 4527.826628 tokens/s, learning rate: 8.890e-06, loss_scalings: 13421.773438, pp_loss: 8.442005
[INFO] 2021-07-12 18:49:55,203 [run_pretraining.py:  512]:	********exe.run_890******* 
[INFO] 2021-07-12 18:49:56,117 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:56,118 [run_pretraining.py:  534]:	loss/total_loss, 8.516889572143555, 891
[INFO] 2021-07-12 18:49:56,118 [run_pretraining.py:  535]:	loss/mlm_loss, 8.516889572143555, 891
[INFO] 2021-07-12 18:49:56,118 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.89999955688836e-06, 891
[INFO] 2021-07-12 18:49:56,118 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 891
[INFO] 2021-07-12 18:49:56,118 [run_pretraining.py:  558]:	worker_index: 3, step: 891, cost: 8.516890, mlm loss: 8.516890, speed: 1.093997 steps/s, speed: 8.751979 samples/s, speed: 4481.013370 tokens/s, learning rate: 8.900e-06, loss_scalings: 13421.773438, pp_loss: 8.380808
[INFO] 2021-07-12 18:49:56,118 [run_pretraining.py:  512]:	********exe.run_891******* 
[INFO] 2021-07-12 18:49:57,026 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:57,027 [run_pretraining.py:  534]:	loss/total_loss, 8.1722412109375, 892
[INFO] 2021-07-12 18:49:57,027 [run_pretraining.py:  535]:	loss/mlm_loss, 8.1722412109375, 892
[INFO] 2021-07-12 18:49:57,027 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.910000360629056e-06, 892
[INFO] 2021-07-12 18:49:57,027 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 892
[INFO] 2021-07-12 18:49:57,027 [run_pretraining.py:  558]:	worker_index: 3, step: 892, cost: 8.172241, mlm loss: 8.172241, speed: 1.100579 steps/s, speed: 8.804631 samples/s, speed: 4507.971189 tokens/s, learning rate: 8.910e-06, loss_scalings: 13421.773438, pp_loss: 8.288813
[INFO] 2021-07-12 18:49:57,027 [run_pretraining.py:  512]:	********exe.run_892******* 
[INFO] 2021-07-12 18:49:57,935 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:57,935 [run_pretraining.py:  534]:	loss/total_loss, 7.99671745300293, 893
[INFO] 2021-07-12 18:49:57,936 [run_pretraining.py:  535]:	loss/mlm_loss, 7.99671745300293, 893
[INFO] 2021-07-12 18:49:57,936 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.919999345380347e-06, 893
[INFO] 2021-07-12 18:49:57,936 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 893
[INFO] 2021-07-12 18:49:57,936 [run_pretraining.py:  558]:	worker_index: 3, step: 893, cost: 7.996717, mlm loss: 7.996717, speed: 1.101613 steps/s, speed: 8.812905 samples/s, speed: 4512.207527 tokens/s, learning rate: 8.920e-06, loss_scalings: 13421.773438, pp_loss: 8.137369
[INFO] 2021-07-12 18:49:57,936 [run_pretraining.py:  512]:	********exe.run_893******* 
[INFO] 2021-07-12 18:49:58,843 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:58,844 [run_pretraining.py:  534]:	loss/total_loss, 8.66344928741455, 894
[INFO] 2021-07-12 18:49:58,844 [run_pretraining.py:  535]:	loss/mlm_loss, 8.66344928741455, 894
[INFO] 2021-07-12 18:49:58,844 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.92999923962634e-06, 894
[INFO] 2021-07-12 18:49:58,844 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 894
[INFO] 2021-07-12 18:49:58,844 [run_pretraining.py:  558]:	worker_index: 3, step: 894, cost: 8.663449, mlm loss: 8.663449, speed: 1.101592 steps/s, speed: 8.812739 samples/s, speed: 4512.122201 tokens/s, learning rate: 8.930e-06, loss_scalings: 13421.773438, pp_loss: 8.212646
[INFO] 2021-07-12 18:49:58,844 [run_pretraining.py:  512]:	********exe.run_894******* 
[INFO] 2021-07-12 18:49:59,753 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:59,753 [run_pretraining.py:  534]:	loss/total_loss, 8.580916404724121, 895
[INFO] 2021-07-12 18:49:59,753 [run_pretraining.py:  535]:	loss/mlm_loss, 8.580916404724121, 895
[INFO] 2021-07-12 18:49:59,753 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.940000043367036e-06, 895
[INFO] 2021-07-12 18:49:59,753 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 895
[INFO] 2021-07-12 18:49:59,753 [run_pretraining.py:  558]:	worker_index: 3, step: 895, cost: 8.580916, mlm loss: 8.580916, speed: 1.100695 steps/s, speed: 8.805558 samples/s, speed: 4508.445575 tokens/s, learning rate: 8.940e-06, loss_scalings: 13421.773438, pp_loss: 8.309083
[INFO] 2021-07-12 18:49:59,753 [run_pretraining.py:  512]:	********exe.run_895******* 
[INFO] 2021-07-12 18:50:00,688 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:00,688 [run_pretraining.py:  534]:	loss/total_loss, 8.415828704833984, 896
[INFO] 2021-07-12 18:50:00,689 [run_pretraining.py:  535]:	loss/mlm_loss, 8.415828704833984, 896
[INFO] 2021-07-12 18:50:00,689 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.949999937613029e-06, 896
[INFO] 2021-07-12 18:50:00,689 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 896
[INFO] 2021-07-12 18:50:00,689 [run_pretraining.py:  558]:	worker_index: 3, step: 896, cost: 8.415829, mlm loss: 8.415829, speed: 1.069742 steps/s, speed: 8.557937 samples/s, speed: 4381.663995 tokens/s, learning rate: 8.950e-06, loss_scalings: 13421.773438, pp_loss: 8.395712
[INFO] 2021-07-12 18:50:00,689 [run_pretraining.py:  512]:	********exe.run_896******* 
[INFO] 2021-07-12 18:50:01,614 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:01,615 [run_pretraining.py:  534]:	loss/total_loss, 8.051151275634766, 897
[INFO] 2021-07-12 18:50:01,615 [run_pretraining.py:  535]:	loss/mlm_loss, 8.051151275634766, 897
[INFO] 2021-07-12 18:50:01,615 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.959999831859022e-06, 897
[INFO] 2021-07-12 18:50:01,615 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 897
[INFO] 2021-07-12 18:50:01,615 [run_pretraining.py:  558]:	worker_index: 3, step: 897, cost: 8.051151, mlm loss: 8.051151, speed: 1.080268 steps/s, speed: 8.642147 samples/s, speed: 4424.779257 tokens/s, learning rate: 8.960e-06, loss_scalings: 13421.773438, pp_loss: 8.067715
[INFO] 2021-07-12 18:50:01,615 [run_pretraining.py:  512]:	********exe.run_897******* 
[INFO] 2021-07-12 18:50:02,530 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:02,531 [run_pretraining.py:  534]:	loss/total_loss, 9.5943021774292, 898
[INFO] 2021-07-12 18:50:02,531 [run_pretraining.py:  535]:	loss/mlm_loss, 9.5943021774292, 898
[INFO] 2021-07-12 18:50:02,531 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.969999726105016e-06, 898
[INFO] 2021-07-12 18:50:02,531 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 898
[INFO] 2021-07-12 18:50:02,531 [run_pretraining.py:  558]:	worker_index: 3, step: 898, cost: 9.594302, mlm loss: 9.594302, speed: 1.092535 steps/s, speed: 8.740277 samples/s, speed: 4475.022046 tokens/s, learning rate: 8.970e-06, loss_scalings: 13421.773438, pp_loss: 8.638475
[INFO] 2021-07-12 18:50:02,531 [run_pretraining.py:  512]:	********exe.run_898******* 
[INFO] 2021-07-12 18:50:03,447 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:03,447 [run_pretraining.py:  534]:	loss/total_loss, 8.278666496276855, 899
[INFO] 2021-07-12 18:50:03,447 [run_pretraining.py:  535]:	loss/mlm_loss, 8.278666496276855, 899
[INFO] 2021-07-12 18:50:03,447 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.979999620351009e-06, 899
[INFO] 2021-07-12 18:50:03,447 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 899
[INFO] 2021-07-12 18:50:03,448 [run_pretraining.py:  558]:	worker_index: 3, step: 899, cost: 8.278666, mlm loss: 8.278666, speed: 1.091944 steps/s, speed: 8.735549 samples/s, speed: 4472.601122 tokens/s, learning rate: 8.980e-06, loss_scalings: 13421.773438, pp_loss: 8.321473
[INFO] 2021-07-12 18:50:03,448 [run_pretraining.py:  512]:	********exe.run_899******* 
[INFO] 2021-07-12 18:50:04,371 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:04,371 [run_pretraining.py:  534]:	loss/total_loss, 8.308435440063477, 900
[INFO] 2021-07-12 18:50:04,371 [run_pretraining.py:  535]:	loss/mlm_loss, 8.308435440063477, 900
[INFO] 2021-07-12 18:50:04,371 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.989999514597002e-06, 900
[INFO] 2021-07-12 18:50:04,371 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 900
[INFO] 2021-07-12 18:50:04,372 [run_pretraining.py:  558]:	worker_index: 3, step: 900, cost: 8.308435, mlm loss: 8.308435, speed: 1.083079 steps/s, speed: 8.664635 samples/s, speed: 4436.293179 tokens/s, learning rate: 8.990e-06, loss_scalings: 13421.773438, pp_loss: 8.271229
[INFO] 2021-07-12 18:50:04,372 [run_pretraining.py:  512]:	********exe.run_900******* 
[INFO] 2021-07-12 18:50:05,431 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:05,431 [run_pretraining.py:  534]:	loss/total_loss, 8.304582595825195, 901
[INFO] 2021-07-12 18:50:05,431 [run_pretraining.py:  535]:	loss/mlm_loss, 8.304582595825195, 901
[INFO] 2021-07-12 18:50:05,432 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.000000318337698e-06, 901
[INFO] 2021-07-12 18:50:05,432 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 901
[INFO] 2021-07-12 18:50:05,432 [run_pretraining.py:  558]:	worker_index: 3, step: 901, cost: 8.304583, mlm loss: 8.304583, speed: 0.943805 steps/s, speed: 7.550439 samples/s, speed: 3865.824966 tokens/s, learning rate: 9.000e-06, loss_scalings: 13421.773438, pp_loss: 8.267702
[INFO] 2021-07-12 18:50:05,432 [run_pretraining.py:  512]:	********exe.run_901******* 
[INFO] 2021-07-12 18:50:06,489 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:06,490 [run_pretraining.py:  534]:	loss/total_loss, 8.320332527160645, 902
[INFO] 2021-07-12 18:50:06,490 [run_pretraining.py:  535]:	loss/mlm_loss, 8.320332527160645, 902
[INFO] 2021-07-12 18:50:06,490 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.009999303088989e-06, 902
[INFO] 2021-07-12 18:50:06,490 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 902
[INFO] 2021-07-12 18:50:06,490 [run_pretraining.py:  558]:	worker_index: 3, step: 902, cost: 8.320333, mlm loss: 8.320333, speed: 0.945438 steps/s, speed: 7.563507 samples/s, speed: 3872.515543 tokens/s, learning rate: 9.010e-06, loss_scalings: 13421.773438, pp_loss: 8.314023
[INFO] 2021-07-12 18:50:06,490 [run_pretraining.py:  512]:	********exe.run_902******* 
[INFO] 2021-07-12 18:50:07,567 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:07,567 [run_pretraining.py:  534]:	loss/total_loss, 8.361376762390137, 903
[INFO] 2021-07-12 18:50:07,567 [run_pretraining.py:  535]:	loss/mlm_loss, 8.361376762390137, 903
[INFO] 2021-07-12 18:50:07,567 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.020000106829684e-06, 903
[INFO] 2021-07-12 18:50:07,568 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 903
[INFO] 2021-07-12 18:50:07,568 [run_pretraining.py:  558]:	worker_index: 3, step: 903, cost: 8.361377, mlm loss: 8.361377, speed: 0.928621 steps/s, speed: 7.428971 samples/s, speed: 3803.633003 tokens/s, learning rate: 9.020e-06, loss_scalings: 13421.773438, pp_loss: 8.330209
[INFO] 2021-07-12 18:50:07,568 [run_pretraining.py:  512]:	********exe.run_903******* 
[INFO] 2021-07-12 18:50:08,630 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:08,631 [run_pretraining.py:  534]:	loss/total_loss, 8.608308792114258, 904
[INFO] 2021-07-12 18:50:08,631 [run_pretraining.py:  535]:	loss/mlm_loss, 8.608308792114258, 904
[INFO] 2021-07-12 18:50:08,631 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.030000001075678e-06, 904
[INFO] 2021-07-12 18:50:08,631 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 904
[INFO] 2021-07-12 18:50:08,631 [run_pretraining.py:  558]:	worker_index: 3, step: 904, cost: 8.608309, mlm loss: 8.608309, speed: 0.940626 steps/s, speed: 7.525006 samples/s, speed: 3852.803224 tokens/s, learning rate: 9.030e-06, loss_scalings: 13421.773438, pp_loss: 8.236444
[INFO] 2021-07-12 18:50:08,632 [run_pretraining.py:  512]:	********exe.run_904******* 
[INFO] 2021-07-12 18:50:09,698 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:09,698 [run_pretraining.py:  534]:	loss/total_loss, 8.22806167602539, 905
[INFO] 2021-07-12 18:50:09,698 [run_pretraining.py:  535]:	loss/mlm_loss, 8.22806167602539, 905
[INFO] 2021-07-12 18:50:09,698 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.039999895321671e-06, 905
[INFO] 2021-07-12 18:50:09,698 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 905
[INFO] 2021-07-12 18:50:09,698 [run_pretraining.py:  558]:	worker_index: 3, step: 905, cost: 8.228062, mlm loss: 8.228062, speed: 0.937723 steps/s, speed: 7.501785 samples/s, speed: 3840.913685 tokens/s, learning rate: 9.040e-06, loss_scalings: 13421.773438, pp_loss: 8.161671
[INFO] 2021-07-12 18:50:09,699 [run_pretraining.py:  512]:	********exe.run_905******* 
[INFO] 2021-07-12 18:50:10,784 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:10,785 [run_pretraining.py:  534]:	loss/total_loss, 8.282106399536133, 906
[INFO] 2021-07-12 18:50:10,785 [run_pretraining.py:  535]:	loss/mlm_loss, 8.282106399536133, 906
[INFO] 2021-07-12 18:50:10,785 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.049999789567664e-06, 906
[INFO] 2021-07-12 18:50:10,785 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 906
[INFO] 2021-07-12 18:50:10,785 [run_pretraining.py:  558]:	worker_index: 3, step: 906, cost: 8.282106, mlm loss: 8.282106, speed: 0.920936 steps/s, speed: 7.367489 samples/s, speed: 3772.154260 tokens/s, learning rate: 9.050e-06, loss_scalings: 13421.773438, pp_loss: 8.387995
[INFO] 2021-07-12 18:50:10,785 [run_pretraining.py:  512]:	********exe.run_906******* 
[INFO] 2021-07-12 18:50:11,849 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:11,850 [run_pretraining.py:  534]:	loss/total_loss, 8.255919456481934, 907
[INFO] 2021-07-12 18:50:11,850 [run_pretraining.py:  535]:	loss/mlm_loss, 8.255919456481934, 907
[INFO] 2021-07-12 18:50:11,850 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.059999683813658e-06, 907
[INFO] 2021-07-12 18:50:11,850 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 907
[INFO] 2021-07-12 18:50:11,850 [run_pretraining.py:  558]:	worker_index: 3, step: 907, cost: 8.255919, mlm loss: 8.255919, speed: 0.939496 steps/s, speed: 7.515968 samples/s, speed: 3848.175806 tokens/s, learning rate: 9.060e-06, loss_scalings: 13421.773438, pp_loss: 8.189675
[INFO] 2021-07-12 18:50:11,850 [run_pretraining.py:  512]:	********exe.run_907******* 
[INFO] 2021-07-12 18:50:12,920 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:12,920 [run_pretraining.py:  534]:	loss/total_loss, 8.146302223205566, 908
[INFO] 2021-07-12 18:50:12,920 [run_pretraining.py:  535]:	loss/mlm_loss, 8.146302223205566, 908
[INFO] 2021-07-12 18:50:12,920 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.069999578059651e-06, 908
[INFO] 2021-07-12 18:50:12,920 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 908
[INFO] 2021-07-12 18:50:12,920 [run_pretraining.py:  558]:	worker_index: 3, step: 908, cost: 8.146302, mlm loss: 8.146302, speed: 0.934765 steps/s, speed: 7.478117 samples/s, speed: 3828.796060 tokens/s, learning rate: 9.070e-06, loss_scalings: 13421.773438, pp_loss: 8.304475
[INFO] 2021-07-12 18:50:12,921 [run_pretraining.py:  512]:	********exe.run_908******* 
[INFO] 2021-07-12 18:50:13,987 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:13,988 [run_pretraining.py:  534]:	loss/total_loss, 8.070030212402344, 909
[INFO] 2021-07-12 18:50:13,988 [run_pretraining.py:  535]:	loss/mlm_loss, 8.070030212402344, 909
[INFO] 2021-07-12 18:50:13,988 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.080000381800346e-06, 909
[INFO] 2021-07-12 18:50:13,988 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 909
[INFO] 2021-07-12 18:50:13,988 [run_pretraining.py:  558]:	worker_index: 3, step: 909, cost: 8.070030, mlm loss: 8.070030, speed: 0.937430 steps/s, speed: 7.499444 samples/s, speed: 3839.715292 tokens/s, learning rate: 9.080e-06, loss_scalings: 13421.773438, pp_loss: 8.071775
[INFO] 2021-07-12 18:50:13,988 [run_pretraining.py:  512]:	********exe.run_909******* 
[INFO] 2021-07-12 18:50:15,049 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:15,050 [run_pretraining.py:  534]:	loss/total_loss, 8.352570533752441, 910
[INFO] 2021-07-12 18:50:15,050 [run_pretraining.py:  535]:	loss/mlm_loss, 8.352570533752441, 910
[INFO] 2021-07-12 18:50:15,050 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.089999366551638e-06, 910
[INFO] 2021-07-12 18:50:15,050 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 910
[INFO] 2021-07-12 18:50:15,050 [run_pretraining.py:  558]:	worker_index: 3, step: 910, cost: 8.352571, mlm loss: 8.352571, speed: 0.941758 steps/s, speed: 7.534063 samples/s, speed: 3857.440051 tokens/s, learning rate: 9.090e-06, loss_scalings: 13421.773438, pp_loss: 8.085728
[INFO] 2021-07-12 18:50:15,050 [run_pretraining.py:  512]:	********exe.run_910******* 
[INFO] 2021-07-12 18:50:16,123 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:16,124 [run_pretraining.py:  534]:	loss/total_loss, 8.062763214111328, 911
[INFO] 2021-07-12 18:50:16,124 [run_pretraining.py:  535]:	loss/mlm_loss, 8.062763214111328, 911
[INFO] 2021-07-12 18:50:16,124 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.099999260797631e-06, 911
[INFO] 2021-07-12 18:50:16,124 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 911
[INFO] 2021-07-12 18:50:16,124 [run_pretraining.py:  558]:	worker_index: 3, step: 911, cost: 8.062763, mlm loss: 8.062763, speed: 0.931976 steps/s, speed: 7.455808 samples/s, speed: 3817.373757 tokens/s, learning rate: 9.100e-06, loss_scalings: 13421.773438, pp_loss: 8.184818
[INFO] 2021-07-12 18:50:16,124 [run_pretraining.py:  512]:	********exe.run_911******* 
[INFO] 2021-07-12 18:50:17,165 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:17,166 [run_pretraining.py:  534]:	loss/total_loss, 8.153663635253906, 912
[INFO] 2021-07-12 18:50:17,166 [run_pretraining.py:  535]:	loss/mlm_loss, 8.153663635253906, 912
[INFO] 2021-07-12 18:50:17,166 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.110000064538326e-06, 912
[INFO] 2021-07-12 18:50:17,166 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 912
[INFO] 2021-07-12 18:50:17,166 [run_pretraining.py:  558]:	worker_index: 3, step: 912, cost: 8.153664, mlm loss: 8.153664, speed: 0.959996 steps/s, speed: 7.679964 samples/s, speed: 3932.141700 tokens/s, learning rate: 9.110e-06, loss_scalings: 13421.773438, pp_loss: 7.493248
[INFO] 2021-07-12 18:50:17,166 [run_pretraining.py:  512]:	********exe.run_912******* 
[INFO] 2021-07-12 18:50:18,224 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:18,224 [run_pretraining.py:  534]:	loss/total_loss, 8.086103439331055, 913
[INFO] 2021-07-12 18:50:18,224 [run_pretraining.py:  535]:	loss/mlm_loss, 8.086103439331055, 913
[INFO] 2021-07-12 18:50:18,224 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.11999995878432e-06, 913
[INFO] 2021-07-12 18:50:18,224 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 913
[INFO] 2021-07-12 18:50:18,225 [run_pretraining.py:  558]:	worker_index: 3, step: 913, cost: 8.086103, mlm loss: 8.086103, speed: 0.945553 steps/s, speed: 7.564426 samples/s, speed: 3872.986096 tokens/s, learning rate: 9.120e-06, loss_scalings: 13421.773438, pp_loss: 8.158553
[INFO] 2021-07-12 18:50:18,225 [run_pretraining.py:  512]:	********exe.run_913******* 
[INFO] 2021-07-12 18:50:19,289 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:19,290 [run_pretraining.py:  534]:	loss/total_loss, 8.425806999206543, 914
[INFO] 2021-07-12 18:50:19,290 [run_pretraining.py:  535]:	loss/mlm_loss, 8.425806999206543, 914
[INFO] 2021-07-12 18:50:19,290 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.129999853030313e-06, 914
[INFO] 2021-07-12 18:50:19,290 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 914
[INFO] 2021-07-12 18:50:19,290 [run_pretraining.py:  558]:	worker_index: 3, step: 914, cost: 8.425807, mlm loss: 8.425807, speed: 0.939166 steps/s, speed: 7.513330 samples/s, speed: 3846.824718 tokens/s, learning rate: 9.130e-06, loss_scalings: 13421.773438, pp_loss: 8.122750
[INFO] 2021-07-12 18:50:19,290 [run_pretraining.py:  512]:	********exe.run_914******* 
[INFO] 2021-07-12 18:50:20,351 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:20,352 [run_pretraining.py:  534]:	loss/total_loss, 8.100895881652832, 915
[INFO] 2021-07-12 18:50:20,352 [run_pretraining.py:  535]:	loss/mlm_loss, 8.100895881652832, 915
[INFO] 2021-07-12 18:50:20,352 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.139999747276306e-06, 915
[INFO] 2021-07-12 18:50:20,352 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 915
[INFO] 2021-07-12 18:50:20,352 [run_pretraining.py:  558]:	worker_index: 3, step: 915, cost: 8.100896, mlm loss: 8.100896, speed: 0.942010 steps/s, speed: 7.536078 samples/s, speed: 3858.471877 tokens/s, learning rate: 9.140e-06, loss_scalings: 13421.773438, pp_loss: 8.005411
[INFO] 2021-07-12 18:50:20,352 [run_pretraining.py:  512]:	********exe.run_915******* 
[INFO] 2021-07-12 18:50:21,296 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:21,297 [run_pretraining.py:  534]:	loss/total_loss, 8.394789695739746, 916
[INFO] 2021-07-12 18:50:21,297 [run_pretraining.py:  535]:	loss/mlm_loss, 8.394789695739746, 916
[INFO] 2021-07-12 18:50:21,297 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.1499996415223e-06, 916
[INFO] 2021-07-12 18:50:21,297 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 916
[INFO] 2021-07-12 18:50:21,297 [run_pretraining.py:  558]:	worker_index: 3, step: 916, cost: 8.394790, mlm loss: 8.394790, speed: 1.058890 steps/s, speed: 8.471123 samples/s, speed: 4337.215023 tokens/s, learning rate: 9.150e-06, loss_scalings: 13421.773438, pp_loss: 8.139286
[INFO] 2021-07-12 18:50:21,297 [run_pretraining.py:  512]:	********exe.run_916******* 
[INFO] 2021-07-12 18:50:22,209 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:22,210 [run_pretraining.py:  534]:	loss/total_loss, 7.985299110412598, 917
[INFO] 2021-07-12 18:50:22,210 [run_pretraining.py:  535]:	loss/mlm_loss, 7.985299110412598, 917
[INFO] 2021-07-12 18:50:22,210 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.159999535768293e-06, 917
[INFO] 2021-07-12 18:50:22,210 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 917
[INFO] 2021-07-12 18:50:22,210 [run_pretraining.py:  558]:	worker_index: 3, step: 917, cost: 7.985299, mlm loss: 7.985299, speed: 1.096076 steps/s, speed: 8.768604 samples/s, speed: 4489.525367 tokens/s, learning rate: 9.160e-06, loss_scalings: 13421.773438, pp_loss: 8.081591
[INFO] 2021-07-12 18:50:22,210 [run_pretraining.py:  512]:	********exe.run_917******* 
[INFO] 2021-07-12 18:50:23,129 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:23,129 [run_pretraining.py:  534]:	loss/total_loss, 8.306131362915039, 918
[INFO] 2021-07-12 18:50:23,129 [run_pretraining.py:  535]:	loss/mlm_loss, 8.306131362915039, 918
[INFO] 2021-07-12 18:50:23,130 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.170000339508988e-06, 918
[INFO] 2021-07-12 18:50:23,130 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 918
[INFO] 2021-07-12 18:50:23,130 [run_pretraining.py:  558]:	worker_index: 3, step: 918, cost: 8.306131, mlm loss: 8.306131, speed: 1.088238 steps/s, speed: 8.705908 samples/s, speed: 4457.424830 tokens/s, learning rate: 9.170e-06, loss_scalings: 13421.773438, pp_loss: 7.988924
[INFO] 2021-07-12 18:50:23,130 [run_pretraining.py:  512]:	********exe.run_918******* 
[INFO] 2021-07-12 18:50:24,041 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:24,041 [run_pretraining.py:  534]:	loss/total_loss, 7.411236763000488, 919
[INFO] 2021-07-12 18:50:24,041 [run_pretraining.py:  535]:	loss/mlm_loss, 7.411236763000488, 919
[INFO] 2021-07-12 18:50:24,041 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.17999932426028e-06, 919
[INFO] 2021-07-12 18:50:24,041 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 919
[INFO] 2021-07-12 18:50:24,042 [run_pretraining.py:  558]:	worker_index: 3, step: 919, cost: 7.411237, mlm loss: 7.411237, speed: 1.097510 steps/s, speed: 8.780083 samples/s, speed: 4495.402692 tokens/s, learning rate: 9.180e-06, loss_scalings: 13421.773438, pp_loss: 7.993967
[INFO] 2021-07-12 18:50:24,042 [run_pretraining.py:  512]:	********exe.run_919******* 
[INFO] 2021-07-12 18:50:24,961 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:24,961 [run_pretraining.py:  534]:	loss/total_loss, 8.438575744628906, 920
[INFO] 2021-07-12 18:50:24,961 [run_pretraining.py:  535]:	loss/mlm_loss, 8.438575744628906, 920
[INFO] 2021-07-12 18:50:24,962 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.189999218506273e-06, 920
[INFO] 2021-07-12 18:50:24,962 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 920
[INFO] 2021-07-12 18:50:24,962 [run_pretraining.py:  558]:	worker_index: 3, step: 920, cost: 8.438576, mlm loss: 8.438576, speed: 1.087479 steps/s, speed: 8.699834 samples/s, speed: 4454.314842 tokens/s, learning rate: 9.190e-06, loss_scalings: 13421.773438, pp_loss: 7.866434
[INFO] 2021-07-12 18:50:24,962 [run_pretraining.py:  512]:	********exe.run_920******* 
[INFO] 2021-07-12 18:50:25,874 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:25,874 [run_pretraining.py:  534]:	loss/total_loss, 8.647602081298828, 921
[INFO] 2021-07-12 18:50:25,874 [run_pretraining.py:  535]:	loss/mlm_loss, 8.647602081298828, 921
[INFO] 2021-07-12 18:50:25,874 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.200000022246968e-06, 921
[INFO] 2021-07-12 18:50:25,874 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 921
[INFO] 2021-07-12 18:50:25,875 [run_pretraining.py:  558]:	worker_index: 3, step: 921, cost: 8.647602, mlm loss: 8.647602, speed: 1.096286 steps/s, speed: 8.770286 samples/s, speed: 4490.386679 tokens/s, learning rate: 9.200e-06, loss_scalings: 13421.773438, pp_loss: 8.220274
[INFO] 2021-07-12 18:50:25,875 [run_pretraining.py:  512]:	********exe.run_921******* 
[INFO] 2021-07-12 18:50:26,794 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:26,795 [run_pretraining.py:  534]:	loss/total_loss, 7.366106033325195, 922
[INFO] 2021-07-12 18:50:26,795 [run_pretraining.py:  535]:	loss/mlm_loss, 7.366106033325195, 922
[INFO] 2021-07-12 18:50:26,795 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.209999916492961e-06, 922
[INFO] 2021-07-12 18:50:26,795 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 922
[INFO] 2021-07-12 18:50:26,795 [run_pretraining.py:  558]:	worker_index: 3, step: 922, cost: 7.366106, mlm loss: 7.366106, speed: 1.087082 steps/s, speed: 8.696659 samples/s, speed: 4452.689345 tokens/s, learning rate: 9.210e-06, loss_scalings: 13421.773438, pp_loss: 7.948259
[INFO] 2021-07-12 18:50:26,795 [run_pretraining.py:  512]:	********exe.run_922******* 
[INFO] 2021-07-12 18:50:27,710 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:27,711 [run_pretraining.py:  534]:	loss/total_loss, 7.964636325836182, 923
[INFO] 2021-07-12 18:50:27,711 [run_pretraining.py:  535]:	loss/mlm_loss, 7.964636325836182, 923
[INFO] 2021-07-12 18:50:27,711 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.219999810738955e-06, 923
[INFO] 2021-07-12 18:50:27,711 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 923
[INFO] 2021-07-12 18:50:27,711 [run_pretraining.py:  558]:	worker_index: 3, step: 923, cost: 7.964636, mlm loss: 7.964636, speed: 1.092559 steps/s, speed: 8.740476 samples/s, speed: 4475.123460 tokens/s, learning rate: 9.220e-06, loss_scalings: 13421.773438, pp_loss: 8.269306
[INFO] 2021-07-12 18:50:27,711 [run_pretraining.py:  512]:	********exe.run_923******* 
[INFO] 2021-07-12 18:50:28,632 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:28,633 [run_pretraining.py:  534]:	loss/total_loss, 7.8981852531433105, 924
[INFO] 2021-07-12 18:50:28,633 [run_pretraining.py:  535]:	loss/mlm_loss, 7.8981852531433105, 924
[INFO] 2021-07-12 18:50:28,633 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.229999704984948e-06, 924
[INFO] 2021-07-12 18:50:28,633 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 924
[INFO] 2021-07-12 18:50:28,633 [run_pretraining.py:  558]:	worker_index: 3, step: 924, cost: 7.898185, mlm loss: 7.898185, speed: 1.085274 steps/s, speed: 8.682192 samples/s, speed: 4445.282294 tokens/s, learning rate: 9.230e-06, loss_scalings: 13421.773438, pp_loss: 7.345035
[INFO] 2021-07-12 18:50:28,633 [run_pretraining.py:  512]:	********exe.run_924******* 
[INFO] 2021-07-12 18:50:29,552 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:29,552 [run_pretraining.py:  534]:	loss/total_loss, 8.232237815856934, 925
[INFO] 2021-07-12 18:50:29,553 [run_pretraining.py:  535]:	loss/mlm_loss, 8.232237815856934, 925
[INFO] 2021-07-12 18:50:29,553 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.239999599230941e-06, 925
[INFO] 2021-07-12 18:50:29,553 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 925
[INFO] 2021-07-12 18:50:29,553 [run_pretraining.py:  558]:	worker_index: 3, step: 925, cost: 8.232238, mlm loss: 8.232238, speed: 1.087973 steps/s, speed: 8.703783 samples/s, speed: 4456.336823 tokens/s, learning rate: 9.240e-06, loss_scalings: 13421.773438, pp_loss: 8.005008
[INFO] 2021-07-12 18:50:29,553 [run_pretraining.py:  512]:	********exe.run_925******* 
[INFO] 2021-07-12 18:50:30,479 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:30,480 [run_pretraining.py:  534]:	loss/total_loss, 8.131403923034668, 926
[INFO] 2021-07-12 18:50:30,480 [run_pretraining.py:  535]:	loss/mlm_loss, 8.131403923034668, 926
[INFO] 2021-07-12 18:50:30,480 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.249999493476935e-06, 926
[INFO] 2021-07-12 18:50:30,480 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 926
[INFO] 2021-07-12 18:50:30,480 [run_pretraining.py:  558]:	worker_index: 3, step: 926, cost: 8.131404, mlm loss: 8.131404, speed: 1.078995 steps/s, speed: 8.631962 samples/s, speed: 4419.564771 tokens/s, learning rate: 9.250e-06, loss_scalings: 13421.773438, pp_loss: 8.064137
[INFO] 2021-07-12 18:50:30,480 [run_pretraining.py:  512]:	********exe.run_926******* 
[INFO] 2021-07-12 18:50:31,403 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:31,404 [run_pretraining.py:  534]:	loss/total_loss, 7.988409996032715, 927
[INFO] 2021-07-12 18:50:31,404 [run_pretraining.py:  535]:	loss/mlm_loss, 7.988409996032715, 927
[INFO] 2021-07-12 18:50:31,404 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.26000029721763e-06, 927
[INFO] 2021-07-12 18:50:31,404 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 927
[INFO] 2021-07-12 18:50:31,404 [run_pretraining.py:  558]:	worker_index: 3, step: 927, cost: 7.988410, mlm loss: 7.988410, speed: 1.083210 steps/s, speed: 8.665680 samples/s, speed: 4436.828223 tokens/s, learning rate: 9.260e-06, loss_scalings: 13421.773438, pp_loss: 8.175382
[INFO] 2021-07-12 18:50:31,404 [run_pretraining.py:  512]:	********exe.run_927******* 
[INFO] 2021-07-12 18:50:32,325 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:32,325 [run_pretraining.py:  534]:	loss/total_loss, 8.292098045349121, 928
[INFO] 2021-07-12 18:50:32,325 [run_pretraining.py:  535]:	loss/mlm_loss, 8.292098045349121, 928
[INFO] 2021-07-12 18:50:32,325 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.269999281968921e-06, 928
[INFO] 2021-07-12 18:50:32,325 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 928
[INFO] 2021-07-12 18:50:32,325 [run_pretraining.py:  558]:	worker_index: 3, step: 928, cost: 8.292098, mlm loss: 8.292098, speed: 1.086146 steps/s, speed: 8.689171 samples/s, speed: 4448.855430 tokens/s, learning rate: 9.270e-06, loss_scalings: 13421.773438, pp_loss: 8.194669
[INFO] 2021-07-12 18:50:32,325 [run_pretraining.py:  512]:	********exe.run_928******* 
[INFO] 2021-07-12 18:50:33,240 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:33,241 [run_pretraining.py:  534]:	loss/total_loss, 8.430353164672852, 929
[INFO] 2021-07-12 18:50:33,241 [run_pretraining.py:  535]:	loss/mlm_loss, 8.430353164672852, 929
[INFO] 2021-07-12 18:50:33,241 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.280000085709617e-06, 929
[INFO] 2021-07-12 18:50:33,241 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 929
[INFO] 2021-07-12 18:50:33,241 [run_pretraining.py:  558]:	worker_index: 3, step: 929, cost: 8.430353, mlm loss: 8.430353, speed: 1.092644 steps/s, speed: 8.741149 samples/s, speed: 4475.468536 tokens/s, learning rate: 9.280e-06, loss_scalings: 13421.773438, pp_loss: 7.006870
[INFO] 2021-07-12 18:50:33,241 [run_pretraining.py:  512]:	********exe.run_929******* 
[INFO] 2021-07-12 18:50:34,158 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:34,158 [run_pretraining.py:  534]:	loss/total_loss, 7.838033199310303, 930
[INFO] 2021-07-12 18:50:34,158 [run_pretraining.py:  535]:	loss/mlm_loss, 7.838033199310303, 930
[INFO] 2021-07-12 18:50:34,158 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.28999997995561e-06, 930
[INFO] 2021-07-12 18:50:34,158 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 930
[INFO] 2021-07-12 18:50:34,158 [run_pretraining.py:  558]:	worker_index: 3, step: 930, cost: 7.838033, mlm loss: 7.838033, speed: 1.091084 steps/s, speed: 8.728670 samples/s, speed: 4469.079273 tokens/s, learning rate: 9.290e-06, loss_scalings: 13421.773438, pp_loss: 8.052506
[INFO] 2021-07-12 18:50:34,158 [run_pretraining.py:  512]:	********exe.run_930******* 
[INFO] 2021-07-12 18:50:35,074 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:35,075 [run_pretraining.py:  534]:	loss/total_loss, 7.709812641143799, 931
[INFO] 2021-07-12 18:50:35,075 [run_pretraining.py:  535]:	loss/mlm_loss, 7.709812641143799, 931
[INFO] 2021-07-12 18:50:35,075 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.299999874201603e-06, 931
[INFO] 2021-07-12 18:50:35,075 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 931
[INFO] 2021-07-12 18:50:35,075 [run_pretraining.py:  558]:	worker_index: 3, step: 931, cost: 7.709813, mlm loss: 7.709813, speed: 1.091321 steps/s, speed: 8.730571 samples/s, speed: 4470.052549 tokens/s, learning rate: 9.300e-06, loss_scalings: 13421.773438, pp_loss: 7.774065
[INFO] 2021-07-12 18:50:35,075 [run_pretraining.py:  512]:	********exe.run_931******* 
[INFO] 2021-07-12 18:50:35,987 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:35,987 [run_pretraining.py:  534]:	loss/total_loss, 8.472541809082031, 932
[INFO] 2021-07-12 18:50:35,987 [run_pretraining.py:  535]:	loss/mlm_loss, 8.472541809082031, 932
[INFO] 2021-07-12 18:50:35,988 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.309999768447597e-06, 932
[INFO] 2021-07-12 18:50:35,988 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 932
[INFO] 2021-07-12 18:50:35,988 [run_pretraining.py:  558]:	worker_index: 3, step: 932, cost: 8.472542, mlm loss: 8.472542, speed: 1.096901 steps/s, speed: 8.775206 samples/s, speed: 4492.905623 tokens/s, learning rate: 9.310e-06, loss_scalings: 13421.773438, pp_loss: 8.165627
[INFO] 2021-07-12 18:50:35,988 [run_pretraining.py:  512]:	********exe.run_932******* 
[INFO] 2021-07-12 18:50:36,901 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:36,902 [run_pretraining.py:  534]:	loss/total_loss, 7.78271484375, 933
[INFO] 2021-07-12 18:50:36,902 [run_pretraining.py:  535]:	loss/mlm_loss, 7.78271484375, 933
[INFO] 2021-07-12 18:50:36,902 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.31999966269359e-06, 933
[INFO] 2021-07-12 18:50:36,902 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 933
[INFO] 2021-07-12 18:50:36,902 [run_pretraining.py:  558]:	worker_index: 3, step: 933, cost: 7.782715, mlm loss: 7.782715, speed: 1.094567 steps/s, speed: 8.756536 samples/s, speed: 4483.346299 tokens/s, learning rate: 9.320e-06, loss_scalings: 13421.773438, pp_loss: 8.144479
[INFO] 2021-07-12 18:50:36,902 [run_pretraining.py:  512]:	********exe.run_933******* 
[INFO] 2021-07-12 18:50:37,826 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:37,826 [run_pretraining.py:  534]:	loss/total_loss, 8.228246688842773, 934
[INFO] 2021-07-12 18:50:37,826 [run_pretraining.py:  535]:	loss/mlm_loss, 8.228246688842773, 934
[INFO] 2021-07-12 18:50:37,827 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.329999556939583e-06, 934
[INFO] 2021-07-12 18:50:37,827 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 934
[INFO] 2021-07-12 18:50:37,827 [run_pretraining.py:  558]:	worker_index: 3, step: 934, cost: 8.228247, mlm loss: 8.228247, speed: 1.082149 steps/s, speed: 8.657193 samples/s, speed: 4432.482861 tokens/s, learning rate: 9.330e-06, loss_scalings: 13421.773438, pp_loss: 8.147848
[INFO] 2021-07-12 18:50:37,827 [run_pretraining.py:  512]:	********exe.run_934******* 
[INFO] 2021-07-12 18:50:38,760 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:38,957 [run_pretraining.py:  534]:	loss/total_loss, 8.076997756958008, 935
[INFO] 2021-07-12 18:50:38,962 [run_pretraining.py:  535]:	loss/mlm_loss, 8.076997756958008, 935
[INFO] 2021-07-12 18:50:38,968 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.340000360680278e-06, 935
[INFO] 2021-07-12 18:50:38,973 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 935
[INFO] 2021-07-12 18:50:38,978 [run_pretraining.py:  558]:	worker_index: 3, step: 935, cost: 8.076998, mlm loss: 8.076998, speed: 0.884889 steps/s, speed: 7.079114 samples/s, speed: 3624.506149 tokens/s, learning rate: 9.340e-06, loss_scalings: 13421.773438, pp_loss: 8.241951
[INFO] 2021-07-12 18:50:38,983 [run_pretraining.py:  512]:	********exe.run_935******* 
[INFO] 2021-07-12 18:50:39,885 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:39,886 [run_pretraining.py:  534]:	loss/total_loss, 8.104591369628906, 936
[INFO] 2021-07-12 18:50:39,886 [run_pretraining.py:  535]:	loss/mlm_loss, 8.104591369628906, 936
[INFO] 2021-07-12 18:50:39,886 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.350000254926272e-06, 936
[INFO] 2021-07-12 18:50:39,886 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 936
[INFO] 2021-07-12 18:50:39,886 [run_pretraining.py:  558]:	worker_index: 3, step: 936, cost: 8.104591, mlm loss: 8.104591, speed: 1.108150 steps/s, speed: 8.865197 samples/s, speed: 4538.980625 tokens/s, learning rate: 9.350e-06, loss_scalings: 13421.773438, pp_loss: 8.012613
[INFO] 2021-07-12 18:50:39,886 [run_pretraining.py:  512]:	********exe.run_936******* 
[INFO] 2021-07-12 18:50:40,814 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:40,815 [run_pretraining.py:  534]:	loss/total_loss, 8.279985427856445, 937
[INFO] 2021-07-12 18:50:40,815 [run_pretraining.py:  535]:	loss/mlm_loss, 8.279985427856445, 937
[INFO] 2021-07-12 18:50:40,815 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.359999239677563e-06, 937
[INFO] 2021-07-12 18:50:40,815 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 937
[INFO] 2021-07-12 18:50:40,815 [run_pretraining.py:  558]:	worker_index: 3, step: 937, cost: 8.279985, mlm loss: 8.279985, speed: 1.077109 steps/s, speed: 8.616875 samples/s, speed: 4411.840253 tokens/s, learning rate: 9.360e-06, loss_scalings: 13421.773438, pp_loss: 8.081753
[INFO] 2021-07-12 18:50:40,815 [run_pretraining.py:  512]:	********exe.run_937******* 
[INFO] 2021-07-12 18:50:41,772 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:41,773 [run_pretraining.py:  534]:	loss/total_loss, 8.077203750610352, 938
[INFO] 2021-07-12 18:50:41,773 [run_pretraining.py:  535]:	loss/mlm_loss, 8.077203750610352, 938
[INFO] 2021-07-12 18:50:41,773 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.370000043418258e-06, 938
[INFO] 2021-07-12 18:50:41,773 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 938
[INFO] 2021-07-12 18:50:41,773 [run_pretraining.py:  558]:	worker_index: 3, step: 938, cost: 8.077204, mlm loss: 8.077204, speed: 1.044549 steps/s, speed: 8.356394 samples/s, speed: 4278.473780 tokens/s, learning rate: 9.370e-06, loss_scalings: 13421.773438, pp_loss: 8.249431
[INFO] 2021-07-12 18:50:41,773 [run_pretraining.py:  512]:	********exe.run_938******* 
[INFO] 2021-07-12 18:50:42,680 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:42,680 [run_pretraining.py:  534]:	loss/total_loss, 8.01948356628418, 939
[INFO] 2021-07-12 18:50:42,681 [run_pretraining.py:  535]:	loss/mlm_loss, 8.01948356628418, 939
[INFO] 2021-07-12 18:50:42,681 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.379999937664252e-06, 939
[INFO] 2021-07-12 18:50:42,681 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 939
[INFO] 2021-07-12 18:50:42,681 [run_pretraining.py:  558]:	worker_index: 3, step: 939, cost: 8.019484, mlm loss: 8.019484, speed: 1.102701 steps/s, speed: 8.821610 samples/s, speed: 4516.664380 tokens/s, learning rate: 9.380e-06, loss_scalings: 13421.773438, pp_loss: 8.199787
[INFO] 2021-07-12 18:50:42,681 [run_pretraining.py:  512]:	********exe.run_939******* 
[INFO] 2021-07-12 18:50:43,591 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:43,592 [run_pretraining.py:  534]:	loss/total_loss, 8.12181568145752, 940
[INFO] 2021-07-12 18:50:43,592 [run_pretraining.py:  535]:	loss/mlm_loss, 8.12181568145752, 940
[INFO] 2021-07-12 18:50:43,592 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.389999831910245e-06, 940
[INFO] 2021-07-12 18:50:43,592 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 940
[INFO] 2021-07-12 18:50:43,592 [run_pretraining.py:  558]:	worker_index: 3, step: 940, cost: 8.121816, mlm loss: 8.121816, speed: 1.098050 steps/s, speed: 8.784402 samples/s, speed: 4497.614043 tokens/s, learning rate: 9.390e-06, loss_scalings: 13421.773438, pp_loss: 8.007559
[INFO] 2021-07-12 18:50:43,592 [run_pretraining.py:  512]:	********exe.run_940******* 
[INFO] 2021-07-12 18:50:44,511 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:44,512 [run_pretraining.py:  534]:	loss/total_loss, 8.001100540161133, 941
[INFO] 2021-07-12 18:50:44,512 [run_pretraining.py:  535]:	loss/mlm_loss, 8.001100540161133, 941
[INFO] 2021-07-12 18:50:44,512 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.399999726156238e-06, 941
[INFO] 2021-07-12 18:50:44,512 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 941
[INFO] 2021-07-12 18:50:44,512 [run_pretraining.py:  558]:	worker_index: 3, step: 941, cost: 8.001101, mlm loss: 8.001101, speed: 1.087573 steps/s, speed: 8.700587 samples/s, speed: 4454.700609 tokens/s, learning rate: 9.400e-06, loss_scalings: 13421.773438, pp_loss: 8.220842
[INFO] 2021-07-12 18:50:44,512 [run_pretraining.py:  512]:	********exe.run_941******* 
[INFO] 2021-07-12 18:50:45,424 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:45,425 [run_pretraining.py:  534]:	loss/total_loss, 7.800611972808838, 942
[INFO] 2021-07-12 18:50:45,425 [run_pretraining.py:  535]:	loss/mlm_loss, 7.800611972808838, 942
[INFO] 2021-07-12 18:50:45,425 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.409999620402232e-06, 942
[INFO] 2021-07-12 18:50:45,425 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 942
[INFO] 2021-07-12 18:50:45,425 [run_pretraining.py:  558]:	worker_index: 3, step: 942, cost: 7.800612, mlm loss: 7.800612, speed: 1.096152 steps/s, speed: 8.769218 samples/s, speed: 4489.839813 tokens/s, learning rate: 9.410e-06, loss_scalings: 13421.773438, pp_loss: 8.255057
[INFO] 2021-07-12 18:50:45,425 [run_pretraining.py:  512]:	********exe.run_942******* 
[INFO] 2021-07-12 18:50:46,344 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:46,344 [run_pretraining.py:  534]:	loss/total_loss, 7.271557807922363, 943
[INFO] 2021-07-12 18:50:46,344 [run_pretraining.py:  535]:	loss/mlm_loss, 7.271557807922363, 943
[INFO] 2021-07-12 18:50:46,344 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.419999514648225e-06, 943
[INFO] 2021-07-12 18:50:46,345 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 943
[INFO] 2021-07-12 18:50:46,345 [run_pretraining.py:  558]:	worker_index: 3, step: 943, cost: 7.271558, mlm loss: 7.271558, speed: 1.088417 steps/s, speed: 8.707333 samples/s, speed: 4458.154705 tokens/s, learning rate: 9.420e-06, loss_scalings: 13421.773438, pp_loss: 8.060466
[INFO] 2021-07-12 18:50:46,345 [run_pretraining.py:  512]:	********exe.run_943******* 
[INFO] 2021-07-12 18:50:47,254 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:47,255 [run_pretraining.py:  534]:	loss/total_loss, 8.17376708984375, 944
[INFO] 2021-07-12 18:50:47,255 [run_pretraining.py:  535]:	loss/mlm_loss, 8.17376708984375, 944
[INFO] 2021-07-12 18:50:47,255 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.43000031838892e-06, 944
[INFO] 2021-07-12 18:50:47,255 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 944
[INFO] 2021-07-12 18:50:47,255 [run_pretraining.py:  558]:	worker_index: 3, step: 944, cost: 8.173767, mlm loss: 8.173767, speed: 1.099194 steps/s, speed: 8.793556 samples/s, speed: 4502.300484 tokens/s, learning rate: 9.430e-06, loss_scalings: 13421.773438, pp_loss: 7.962975
[INFO] 2021-07-12 18:50:47,255 [run_pretraining.py:  512]:	********exe.run_944******* 
[INFO] 2021-07-12 18:50:48,171 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:48,171 [run_pretraining.py:  534]:	loss/total_loss, 8.25960922241211, 945
[INFO] 2021-07-12 18:50:48,171 [run_pretraining.py:  535]:	loss/mlm_loss, 8.25960922241211, 945
[INFO] 2021-07-12 18:50:48,171 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.440000212634914e-06, 945
[INFO] 2021-07-12 18:50:48,172 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 945
[INFO] 2021-07-12 18:50:48,172 [run_pretraining.py:  558]:	worker_index: 3, step: 945, cost: 8.259609, mlm loss: 8.259609, speed: 1.091751 steps/s, speed: 8.734010 samples/s, speed: 4471.812965 tokens/s, learning rate: 9.440e-06, loss_scalings: 13421.773438, pp_loss: 8.144338
[INFO] 2021-07-12 18:50:48,172 [run_pretraining.py:  512]:	********exe.run_945******* 
[INFO] 2021-07-12 18:50:49,080 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:49,081 [run_pretraining.py:  534]:	loss/total_loss, 8.24402904510498, 946
[INFO] 2021-07-12 18:50:49,081 [run_pretraining.py:  535]:	loss/mlm_loss, 8.24402904510498, 946
[INFO] 2021-07-12 18:50:49,081 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.449999197386205e-06, 946
[INFO] 2021-07-12 18:50:49,081 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 946
[INFO] 2021-07-12 18:50:49,081 [run_pretraining.py:  558]:	worker_index: 3, step: 946, cost: 8.244029, mlm loss: 8.244029, speed: 1.100019 steps/s, speed: 8.800149 samples/s, speed: 4505.676378 tokens/s, learning rate: 9.450e-06, loss_scalings: 13421.773438, pp_loss: 7.899858
[INFO] 2021-07-12 18:50:49,081 [run_pretraining.py:  512]:	********exe.run_946******* 
[INFO] 2021-07-12 18:50:50,071 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:50,072 [run_pretraining.py:  534]:	loss/total_loss, 8.54959487915039, 947
[INFO] 2021-07-12 18:50:50,072 [run_pretraining.py:  535]:	loss/mlm_loss, 8.54959487915039, 947
[INFO] 2021-07-12 18:50:50,072 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.4600000011269e-06, 947
[INFO] 2021-07-12 18:50:50,072 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 947
[INFO] 2021-07-12 18:50:50,072 [run_pretraining.py:  558]:	worker_index: 3, step: 947, cost: 8.549595, mlm loss: 8.549595, speed: 1.009712 steps/s, speed: 8.077697 samples/s, speed: 4135.781082 tokens/s, learning rate: 9.460e-06, loss_scalings: 13421.773438, pp_loss: 8.439549
[INFO] 2021-07-12 18:50:50,072 [run_pretraining.py:  512]:	********exe.run_947******* 
[INFO] 2021-07-12 18:50:51,135 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:51,136 [run_pretraining.py:  534]:	loss/total_loss, 8.499592781066895, 948
[INFO] 2021-07-12 18:50:51,136 [run_pretraining.py:  535]:	loss/mlm_loss, 8.499592781066895, 948
[INFO] 2021-07-12 18:50:51,136 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.469999895372894e-06, 948
[INFO] 2021-07-12 18:50:51,136 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 948
[INFO] 2021-07-12 18:50:51,136 [run_pretraining.py:  558]:	worker_index: 3, step: 948, cost: 8.499593, mlm loss: 8.499593, speed: 0.940720 steps/s, speed: 7.525761 samples/s, speed: 3853.189488 tokens/s, learning rate: 9.470e-06, loss_scalings: 13421.773438, pp_loss: 8.061522
[INFO] 2021-07-12 18:50:51,136 [run_pretraining.py:  512]:	********exe.run_948******* 
[INFO] 2021-07-12 18:50:52,199 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:52,199 [run_pretraining.py:  534]:	loss/total_loss, 8.147205352783203, 949
[INFO] 2021-07-12 18:50:52,199 [run_pretraining.py:  535]:	loss/mlm_loss, 8.147205352783203, 949
[INFO] 2021-07-12 18:50:52,199 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.479999789618887e-06, 949
[INFO] 2021-07-12 18:50:52,200 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 949
[INFO] 2021-07-12 18:50:52,200 [run_pretraining.py:  558]:	worker_index: 3, step: 949, cost: 8.147205, mlm loss: 8.147205, speed: 0.940768 steps/s, speed: 7.526144 samples/s, speed: 3853.385675 tokens/s, learning rate: 9.480e-06, loss_scalings: 13421.773438, pp_loss: 8.029500
[INFO] 2021-07-12 18:50:52,200 [run_pretraining.py:  512]:	********exe.run_949******* 
[INFO] 2021-07-12 18:50:53,257 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:53,258 [run_pretraining.py:  534]:	loss/total_loss, 8.147889137268066, 950
[INFO] 2021-07-12 18:50:53,258 [run_pretraining.py:  535]:	loss/mlm_loss, 8.147889137268066, 950
[INFO] 2021-07-12 18:50:53,258 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.48999968386488e-06, 950
[INFO] 2021-07-12 18:50:53,258 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 950
[INFO] 2021-07-12 18:50:53,258 [run_pretraining.py:  558]:	worker_index: 3, step: 950, cost: 8.147889, mlm loss: 8.147889, speed: 0.945350 steps/s, speed: 7.562801 samples/s, speed: 3872.154195 tokens/s, learning rate: 9.490e-06, loss_scalings: 13421.773438, pp_loss: 8.026581
[INFO] 2021-07-12 18:50:53,258 [run_pretraining.py:  512]:	********exe.run_950******* 
[INFO] 2021-07-12 18:50:54,321 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:54,322 [run_pretraining.py:  534]:	loss/total_loss, 8.20810317993164, 951
[INFO] 2021-07-12 18:50:54,322 [run_pretraining.py:  535]:	loss/mlm_loss, 8.20810317993164, 951
[INFO] 2021-07-12 18:50:54,322 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.499999578110874e-06, 951
[INFO] 2021-07-12 18:50:54,322 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 951
[INFO] 2021-07-12 18:50:54,322 [run_pretraining.py:  558]:	worker_index: 3, step: 951, cost: 8.208103, mlm loss: 8.208103, speed: 0.940301 steps/s, speed: 7.522407 samples/s, speed: 3851.472198 tokens/s, learning rate: 9.500e-06, loss_scalings: 13421.773438, pp_loss: 7.999881
[INFO] 2021-07-12 18:50:54,322 [run_pretraining.py:  512]:	********exe.run_951******* 
[INFO] 2021-07-12 18:50:55,385 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:55,386 [run_pretraining.py:  534]:	loss/total_loss, 8.302783966064453, 952
[INFO] 2021-07-12 18:50:55,386 [run_pretraining.py:  535]:	loss/mlm_loss, 8.302783966064453, 952
[INFO] 2021-07-12 18:50:55,386 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.509999472356867e-06, 952
[INFO] 2021-07-12 18:50:55,386 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 952
[INFO] 2021-07-12 18:50:55,386 [run_pretraining.py:  558]:	worker_index: 3, step: 952, cost: 8.302784, mlm loss: 8.302784, speed: 0.940348 steps/s, speed: 7.522781 samples/s, speed: 3851.663892 tokens/s, learning rate: 9.510e-06, loss_scalings: 13421.773438, pp_loss: 7.990532
[INFO] 2021-07-12 18:50:55,386 [run_pretraining.py:  512]:	********exe.run_952******* 
[INFO] 2021-07-12 18:50:56,460 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:56,460 [run_pretraining.py:  534]:	loss/total_loss, 8.156842231750488, 953
[INFO] 2021-07-12 18:50:56,460 [run_pretraining.py:  535]:	loss/mlm_loss, 8.156842231750488, 953
[INFO] 2021-07-12 18:50:56,460 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.520000276097562e-06, 953
[INFO] 2021-07-12 18:50:56,461 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 953
[INFO] 2021-07-12 18:50:56,461 [run_pretraining.py:  558]:	worker_index: 3, step: 953, cost: 8.156842, mlm loss: 8.156842, speed: 0.931359 steps/s, speed: 7.450873 samples/s, speed: 3814.846881 tokens/s, learning rate: 9.520e-06, loss_scalings: 13421.773438, pp_loss: 7.943772
[INFO] 2021-07-12 18:50:56,461 [run_pretraining.py:  512]:	********exe.run_953******* 
[INFO] 2021-07-12 18:50:57,551 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:57,552 [run_pretraining.py:  534]:	loss/total_loss, 8.008722305297852, 954
[INFO] 2021-07-12 18:50:57,552 [run_pretraining.py:  535]:	loss/mlm_loss, 8.008722305297852, 954
[INFO] 2021-07-12 18:50:57,552 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.529999260848854e-06, 954
[INFO] 2021-07-12 18:50:57,552 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 954
[INFO] 2021-07-12 18:50:57,552 [run_pretraining.py:  558]:	worker_index: 3, step: 954, cost: 8.008722, mlm loss: 8.008722, speed: 0.916635 steps/s, speed: 7.333079 samples/s, speed: 3754.536497 tokens/s, learning rate: 9.530e-06, loss_scalings: 13421.773438, pp_loss: 8.121483
[INFO] 2021-07-12 18:50:57,552 [run_pretraining.py:  512]:	********exe.run_954******* 
[INFO] 2021-07-12 18:50:58,617 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:58,618 [run_pretraining.py:  534]:	loss/total_loss, 8.242116928100586, 955
[INFO] 2021-07-12 18:50:58,618 [run_pretraining.py:  535]:	loss/mlm_loss, 8.242116928100586, 955
[INFO] 2021-07-12 18:50:58,618 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.539999155094847e-06, 955
[INFO] 2021-07-12 18:50:58,618 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 955
[INFO] 2021-07-12 18:50:58,618 [run_pretraining.py:  558]:	worker_index: 3, step: 955, cost: 8.242117, mlm loss: 8.242117, speed: 0.938791 steps/s, speed: 7.510328 samples/s, speed: 3845.287804 tokens/s, learning rate: 9.540e-06, loss_scalings: 13421.773438, pp_loss: 7.747726
[INFO] 2021-07-12 18:50:58,618 [run_pretraining.py:  512]:	********exe.run_955******* 
[INFO] 2021-07-12 18:50:59,683 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:59,683 [run_pretraining.py:  534]:	loss/total_loss, 7.70784330368042, 956
[INFO] 2021-07-12 18:50:59,683 [run_pretraining.py:  535]:	loss/mlm_loss, 7.70784330368042, 956
[INFO] 2021-07-12 18:50:59,683 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.549999958835542e-06, 956
[INFO] 2021-07-12 18:50:59,683 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 956
[INFO] 2021-07-12 18:50:59,683 [run_pretraining.py:  558]:	worker_index: 3, step: 956, cost: 7.707843, mlm loss: 7.707843, speed: 0.939222 steps/s, speed: 7.513779 samples/s, speed: 3847.054715 tokens/s, learning rate: 9.550e-06, loss_scalings: 13421.773438, pp_loss: 8.147042
[INFO] 2021-07-12 18:50:59,683 [run_pretraining.py:  512]:	********exe.run_956******* 
[INFO] 2021-07-12 18:51:00,751 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:00,752 [run_pretraining.py:  534]:	loss/total_loss, 6.226755142211914, 957
[INFO] 2021-07-12 18:51:00,752 [run_pretraining.py:  535]:	loss/mlm_loss, 6.226755142211914, 957
[INFO] 2021-07-12 18:51:00,752 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.559999853081536e-06, 957
[INFO] 2021-07-12 18:51:00,752 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 957
[INFO] 2021-07-12 18:51:00,752 [run_pretraining.py:  558]:	worker_index: 3, step: 957, cost: 6.226755, mlm loss: 6.226755, speed: 0.936499 steps/s, speed: 7.491991 samples/s, speed: 3835.899331 tokens/s, learning rate: 9.560e-06, loss_scalings: 13421.773438, pp_loss: 7.368081
[INFO] 2021-07-12 18:51:00,752 [run_pretraining.py:  512]:	********exe.run_957******* 
[INFO] 2021-07-12 18:51:01,834 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:01,834 [run_pretraining.py:  534]:	loss/total_loss, 7.731338977813721, 958
[INFO] 2021-07-12 18:51:01,834 [run_pretraining.py:  535]:	loss/mlm_loss, 7.731338977813721, 958
[INFO] 2021-07-12 18:51:01,834 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.569999747327529e-06, 958
[INFO] 2021-07-12 18:51:01,834 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 958
[INFO] 2021-07-12 18:51:01,834 [run_pretraining.py:  558]:	worker_index: 3, step: 958, cost: 7.731339, mlm loss: 7.731339, speed: 0.924259 steps/s, speed: 7.394069 samples/s, speed: 3785.763215 tokens/s, learning rate: 9.570e-06, loss_scalings: 13421.773438, pp_loss: 8.104126
[INFO] 2021-07-12 18:51:01,835 [run_pretraining.py:  512]:	********exe.run_958******* 
[INFO] 2021-07-12 18:51:02,898 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:02,898 [run_pretraining.py:  534]:	loss/total_loss, 8.308948516845703, 959
[INFO] 2021-07-12 18:51:02,899 [run_pretraining.py:  535]:	loss/mlm_loss, 8.308948516845703, 959
[INFO] 2021-07-12 18:51:02,899 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.579999641573522e-06, 959
[INFO] 2021-07-12 18:51:02,899 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 959
[INFO] 2021-07-12 18:51:02,899 [run_pretraining.py:  558]:	worker_index: 3, step: 959, cost: 8.308949, mlm loss: 8.308949, speed: 0.940119 steps/s, speed: 7.520950 samples/s, speed: 3850.726328 tokens/s, learning rate: 9.580e-06, loss_scalings: 13421.773438, pp_loss: 8.157475
[INFO] 2021-07-12 18:51:02,899 [run_pretraining.py:  512]:	********exe.run_959******* 
[INFO] 2021-07-12 18:51:03,963 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:03,963 [run_pretraining.py:  534]:	loss/total_loss, 8.650287628173828, 960
[INFO] 2021-07-12 18:51:03,964 [run_pretraining.py:  535]:	loss/mlm_loss, 8.650287628173828, 960
[INFO] 2021-07-12 18:51:03,964 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.589999535819516e-06, 960
[INFO] 2021-07-12 18:51:03,964 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 960
[INFO] 2021-07-12 18:51:03,964 [run_pretraining.py:  558]:	worker_index: 3, step: 960, cost: 8.650288, mlm loss: 8.650288, speed: 0.939556 steps/s, speed: 7.516452 samples/s, speed: 3848.423206 tokens/s, learning rate: 9.590e-06, loss_scalings: 13421.773438, pp_loss: 8.361479
[INFO] 2021-07-12 18:51:03,964 [run_pretraining.py:  512]:	********exe.run_960******* 
[INFO] 2021-07-12 18:51:05,025 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:05,026 [run_pretraining.py:  534]:	loss/total_loss, 7.923579692840576, 961
[INFO] 2021-07-12 18:51:05,026 [run_pretraining.py:  535]:	loss/mlm_loss, 7.923579692840576, 961
[INFO] 2021-07-12 18:51:05,026 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.599999430065509e-06, 961
[INFO] 2021-07-12 18:51:05,026 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 961
[INFO] 2021-07-12 18:51:05,026 [run_pretraining.py:  558]:	worker_index: 3, step: 961, cost: 7.923580, mlm loss: 7.923580, speed: 0.941942 steps/s, speed: 7.535533 samples/s, speed: 3858.192857 tokens/s, learning rate: 9.600e-06, loss_scalings: 13421.773438, pp_loss: 7.687534
[INFO] 2021-07-12 18:51:05,026 [run_pretraining.py:  512]:	********exe.run_961******* 
[INFO] 2021-07-12 18:51:05,970 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:05,971 [run_pretraining.py:  534]:	loss/total_loss, 8.216917037963867, 962
[INFO] 2021-07-12 18:51:05,971 [run_pretraining.py:  535]:	loss/mlm_loss, 8.216917037963867, 962
[INFO] 2021-07-12 18:51:05,971 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.610000233806204e-06, 962
[INFO] 2021-07-12 18:51:05,971 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 962
[INFO] 2021-07-12 18:51:05,971 [run_pretraining.py:  558]:	worker_index: 3, step: 962, cost: 8.216917, mlm loss: 8.216917, speed: 1.058749 steps/s, speed: 8.469990 samples/s, speed: 4336.634767 tokens/s, learning rate: 9.610e-06, loss_scalings: 13421.773438, pp_loss: 8.000488
[INFO] 2021-07-12 18:51:05,971 [run_pretraining.py:  512]:	********exe.run_962******* 
[INFO] 2021-07-12 18:51:06,885 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:06,885 [run_pretraining.py:  534]:	loss/total_loss, 7.5814528465271, 963
[INFO] 2021-07-12 18:51:06,885 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5814528465271, 963
[INFO] 2021-07-12 18:51:06,885 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.619999218557496e-06, 963
[INFO] 2021-07-12 18:51:06,886 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 963
[INFO] 2021-07-12 18:51:06,886 [run_pretraining.py:  558]:	worker_index: 3, step: 963, cost: 7.581453, mlm loss: 7.581453, speed: 1.094394 steps/s, speed: 8.755156 samples/s, speed: 4482.639732 tokens/s, learning rate: 9.620e-06, loss_scalings: 13421.773438, pp_loss: 6.914459
[INFO] 2021-07-12 18:51:06,886 [run_pretraining.py:  512]:	********exe.run_963******* 
[INFO] 2021-07-12 18:51:07,803 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:07,804 [run_pretraining.py:  534]:	loss/total_loss, 8.329741477966309, 964
[INFO] 2021-07-12 18:51:07,804 [run_pretraining.py:  535]:	loss/mlm_loss, 8.329741477966309, 964
[INFO] 2021-07-12 18:51:07,804 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.63000002229819e-06, 964
[INFO] 2021-07-12 18:51:07,804 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 964
[INFO] 2021-07-12 18:51:07,804 [run_pretraining.py:  558]:	worker_index: 3, step: 964, cost: 8.329741, mlm loss: 8.329741, speed: 1.089236 steps/s, speed: 8.713886 samples/s, speed: 4461.509883 tokens/s, learning rate: 9.630e-06, loss_scalings: 13421.773438, pp_loss: 8.050955
[INFO] 2021-07-12 18:51:07,804 [run_pretraining.py:  512]:	********exe.run_964******* 
[INFO] 2021-07-12 18:51:08,720 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:08,720 [run_pretraining.py:  534]:	loss/total_loss, 8.00408935546875, 965
[INFO] 2021-07-12 18:51:08,720 [run_pretraining.py:  535]:	loss/mlm_loss, 8.00408935546875, 965
[INFO] 2021-07-12 18:51:08,720 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.639999916544184e-06, 965
[INFO] 2021-07-12 18:51:08,721 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 965
[INFO] 2021-07-12 18:51:08,721 [run_pretraining.py:  558]:	worker_index: 3, step: 965, cost: 8.004089, mlm loss: 8.004089, speed: 1.092060 steps/s, speed: 8.736477 samples/s, speed: 4473.076246 tokens/s, learning rate: 9.640e-06, loss_scalings: 13421.773438, pp_loss: 8.069441
[INFO] 2021-07-12 18:51:08,721 [run_pretraining.py:  512]:	********exe.run_965******* 
[INFO] 2021-07-12 18:51:09,630 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:09,630 [run_pretraining.py:  534]:	loss/total_loss, 7.776100158691406, 966
[INFO] 2021-07-12 18:51:09,630 [run_pretraining.py:  535]:	loss/mlm_loss, 7.776100158691406, 966
[INFO] 2021-07-12 18:51:09,630 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.649999810790177e-06, 966
[INFO] 2021-07-12 18:51:09,630 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 966
[INFO] 2021-07-12 18:51:09,631 [run_pretraining.py:  558]:	worker_index: 3, step: 966, cost: 7.776100, mlm loss: 7.776100, speed: 1.099793 steps/s, speed: 8.798342 samples/s, speed: 4504.751312 tokens/s, learning rate: 9.650e-06, loss_scalings: 13421.773438, pp_loss: 8.144812
[INFO] 2021-07-12 18:51:09,631 [run_pretraining.py:  512]:	********exe.run_966******* 
[INFO] 2021-07-12 18:51:10,539 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:10,540 [run_pretraining.py:  534]:	loss/total_loss, 7.963642597198486, 967
[INFO] 2021-07-12 18:51:10,540 [run_pretraining.py:  535]:	loss/mlm_loss, 7.963642597198486, 967
[INFO] 2021-07-12 18:51:10,540 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.65999970503617e-06, 967
[INFO] 2021-07-12 18:51:10,540 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 967
[INFO] 2021-07-12 18:51:10,540 [run_pretraining.py:  558]:	worker_index: 3, step: 967, cost: 7.963643, mlm loss: 7.963643, speed: 1.100366 steps/s, speed: 8.802924 samples/s, speed: 4507.097206 tokens/s, learning rate: 9.660e-06, loss_scalings: 13421.773438, pp_loss: 7.975940
[INFO] 2021-07-12 18:51:10,540 [run_pretraining.py:  512]:	********exe.run_967******* 
[INFO] 2021-07-12 18:51:11,468 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:11,468 [run_pretraining.py:  534]:	loss/total_loss, 7.931584358215332, 968
[INFO] 2021-07-12 18:51:11,469 [run_pretraining.py:  535]:	loss/mlm_loss, 7.931584358215332, 968
[INFO] 2021-07-12 18:51:11,469 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.669999599282164e-06, 968
[INFO] 2021-07-12 18:51:11,469 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 968
[INFO] 2021-07-12 18:51:11,469 [run_pretraining.py:  558]:	worker_index: 3, step: 968, cost: 7.931584, mlm loss: 7.931584, speed: 1.077389 steps/s, speed: 8.619115 samples/s, speed: 4412.987120 tokens/s, learning rate: 9.670e-06, loss_scalings: 13421.773438, pp_loss: 7.740170
[INFO] 2021-07-12 18:51:11,469 [run_pretraining.py:  512]:	********exe.run_968******* 
[INFO] 2021-07-12 18:51:12,375 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:12,376 [run_pretraining.py:  534]:	loss/total_loss, 8.722965240478516, 969
[INFO] 2021-07-12 18:51:12,376 [run_pretraining.py:  535]:	loss/mlm_loss, 8.722965240478516, 969
[INFO] 2021-07-12 18:51:12,376 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.679999493528157e-06, 969
[INFO] 2021-07-12 18:51:12,376 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 969
[INFO] 2021-07-12 18:51:12,376 [run_pretraining.py:  558]:	worker_index: 3, step: 969, cost: 8.722965, mlm loss: 8.722965, speed: 1.102983 steps/s, speed: 8.823860 samples/s, speed: 4517.816501 tokens/s, learning rate: 9.680e-06, loss_scalings: 13421.773438, pp_loss: 8.129341
[INFO] 2021-07-12 18:51:12,376 [run_pretraining.py:  512]:	********exe.run_969******* 
[INFO] 2021-07-12 18:51:13,280 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:13,281 [run_pretraining.py:  534]:	loss/total_loss, 8.269132614135742, 970
[INFO] 2021-07-12 18:51:13,281 [run_pretraining.py:  535]:	loss/mlm_loss, 8.269132614135742, 970
[INFO] 2021-07-12 18:51:13,281 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.690000297268853e-06, 970
[INFO] 2021-07-12 18:51:13,281 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 970
[INFO] 2021-07-12 18:51:13,281 [run_pretraining.py:  558]:	worker_index: 3, step: 970, cost: 8.269133, mlm loss: 8.269133, speed: 1.105403 steps/s, speed: 8.843223 samples/s, speed: 4527.729970 tokens/s, learning rate: 9.690e-06, loss_scalings: 13421.773438, pp_loss: 7.773521
[INFO] 2021-07-12 18:51:13,281 [run_pretraining.py:  512]:	********exe.run_970******* 
[INFO] 2021-07-12 18:51:14,192 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:14,193 [run_pretraining.py:  534]:	loss/total_loss, 8.022467613220215, 971
[INFO] 2021-07-12 18:51:14,193 [run_pretraining.py:  535]:	loss/mlm_loss, 8.022467613220215, 971
[INFO] 2021-07-12 18:51:14,193 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.700000191514846e-06, 971
[INFO] 2021-07-12 18:51:14,193 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 971
[INFO] 2021-07-12 18:51:14,193 [run_pretraining.py:  558]:	worker_index: 3, step: 971, cost: 8.022468, mlm loss: 8.022468, speed: 1.097463 steps/s, speed: 8.779707 samples/s, speed: 4495.209787 tokens/s, learning rate: 9.700e-06, loss_scalings: 13421.773438, pp_loss: 8.280041
[INFO] 2021-07-12 18:51:14,193 [run_pretraining.py:  512]:	********exe.run_971******* 
[INFO] 2021-07-12 18:51:15,103 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:15,103 [run_pretraining.py:  534]:	loss/total_loss, 8.805627822875977, 972
[INFO] 2021-07-12 18:51:15,103 [run_pretraining.py:  535]:	loss/mlm_loss, 8.805627822875977, 972
[INFO] 2021-07-12 18:51:15,103 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.709999176266138e-06, 972
[INFO] 2021-07-12 18:51:15,104 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 972
[INFO] 2021-07-12 18:51:15,104 [run_pretraining.py:  558]:	worker_index: 3, step: 972, cost: 8.805628, mlm loss: 8.805628, speed: 1.099117 steps/s, speed: 8.792938 samples/s, speed: 4501.984291 tokens/s, learning rate: 9.710e-06, loss_scalings: 13421.773438, pp_loss: 8.302067
[INFO] 2021-07-12 18:51:15,104 [run_pretraining.py:  512]:	********exe.run_972******* 
[INFO] 2021-07-12 18:51:16,010 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:16,011 [run_pretraining.py:  534]:	loss/total_loss, 7.5714030265808105, 973
[INFO] 2021-07-12 18:51:16,011 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5714030265808105, 973
[INFO] 2021-07-12 18:51:16,011 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.719999980006833e-06, 973
[INFO] 2021-07-12 18:51:16,011 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 973
[INFO] 2021-07-12 18:51:16,011 [run_pretraining.py:  558]:	worker_index: 3, step: 973, cost: 7.571403, mlm loss: 7.571403, speed: 1.102538 steps/s, speed: 8.820305 samples/s, speed: 4515.995943 tokens/s, learning rate: 9.720e-06, loss_scalings: 13421.773438, pp_loss: 8.049736
[INFO] 2021-07-12 18:51:16,011 [run_pretraining.py:  512]:	********exe.run_973******* 
[INFO] 2021-07-12 18:51:16,938 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:16,939 [run_pretraining.py:  534]:	loss/total_loss, 8.018267631530762, 974
[INFO] 2021-07-12 18:51:16,939 [run_pretraining.py:  535]:	loss/mlm_loss, 8.018267631530762, 974
[INFO] 2021-07-12 18:51:16,939 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.729999874252826e-06, 974
[INFO] 2021-07-12 18:51:16,939 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 974
[INFO] 2021-07-12 18:51:16,939 [run_pretraining.py:  558]:	worker_index: 3, step: 974, cost: 8.018268, mlm loss: 8.018268, speed: 1.078451 steps/s, speed: 8.627608 samples/s, speed: 4417.335212 tokens/s, learning rate: 9.730e-06, loss_scalings: 13421.773438, pp_loss: 8.080841
[INFO] 2021-07-12 18:51:16,939 [run_pretraining.py:  512]:	********exe.run_974******* 
[INFO] 2021-07-12 18:51:17,846 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:17,847 [run_pretraining.py:  534]:	loss/total_loss, 8.034117698669434, 975
[INFO] 2021-07-12 18:51:17,847 [run_pretraining.py:  535]:	loss/mlm_loss, 8.034117698669434, 975
[INFO] 2021-07-12 18:51:17,847 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.73999976849882e-06, 975
[INFO] 2021-07-12 18:51:17,847 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 975
[INFO] 2021-07-12 18:51:17,847 [run_pretraining.py:  558]:	worker_index: 3, step: 975, cost: 8.034118, mlm loss: 8.034118, speed: 1.102103 steps/s, speed: 8.816823 samples/s, speed: 4514.213623 tokens/s, learning rate: 9.740e-06, loss_scalings: 13421.773438, pp_loss: 7.937453
[INFO] 2021-07-12 18:51:17,847 [run_pretraining.py:  512]:	********exe.run_975******* 
[INFO] 2021-07-12 18:51:18,758 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:18,759 [run_pretraining.py:  534]:	loss/total_loss, 8.837669372558594, 976
[INFO] 2021-07-12 18:51:18,759 [run_pretraining.py:  535]:	loss/mlm_loss, 8.837669372558594, 976
[INFO] 2021-07-12 18:51:18,759 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.749999662744813e-06, 976
[INFO] 2021-07-12 18:51:18,759 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 976
[INFO] 2021-07-12 18:51:18,759 [run_pretraining.py:  558]:	worker_index: 3, step: 976, cost: 8.837669, mlm loss: 8.837669, speed: 1.097587 steps/s, speed: 8.780699 samples/s, speed: 4495.717962 tokens/s, learning rate: 9.750e-06, loss_scalings: 13421.773438, pp_loss: 8.392401
[INFO] 2021-07-12 18:51:18,759 [run_pretraining.py:  512]:	********exe.run_976******* 
[INFO] 2021-07-12 18:51:19,658 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:19,658 [run_pretraining.py:  534]:	loss/total_loss, 8.18552017211914, 977
[INFO] 2021-07-12 18:51:19,658 [run_pretraining.py:  535]:	loss/mlm_loss, 8.18552017211914, 977
[INFO] 2021-07-12 18:51:19,659 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.759999556990806e-06, 977
[INFO] 2021-07-12 18:51:19,659 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 977
[INFO] 2021-07-12 18:51:19,659 [run_pretraining.py:  558]:	worker_index: 3, step: 977, cost: 8.185520, mlm loss: 8.185520, speed: 1.112224 steps/s, speed: 8.897788 samples/s, speed: 4555.667655 tokens/s, learning rate: 9.760e-06, loss_scalings: 13421.773438, pp_loss: 8.006580
[INFO] 2021-07-12 18:51:19,659 [run_pretraining.py:  512]:	********exe.run_977******* 
[INFO] 2021-07-12 18:51:20,567 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:20,567 [run_pretraining.py:  534]:	loss/total_loss, 8.219894409179688, 978
[INFO] 2021-07-12 18:51:20,567 [run_pretraining.py:  535]:	loss/mlm_loss, 8.219894409179688, 978
[INFO] 2021-07-12 18:51:20,567 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.7699994512368e-06, 978
[INFO] 2021-07-12 18:51:20,567 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 978
[INFO] 2021-07-12 18:51:20,568 [run_pretraining.py:  558]:	worker_index: 3, step: 978, cost: 8.219894, mlm loss: 8.219894, speed: 1.101055 steps/s, speed: 8.808443 samples/s, speed: 4509.922610 tokens/s, learning rate: 9.770e-06, loss_scalings: 13421.773438, pp_loss: 8.153506
[INFO] 2021-07-12 18:51:20,568 [run_pretraining.py:  512]:	********exe.run_978******* 
[INFO] 2021-07-12 18:51:21,470 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:21,471 [run_pretraining.py:  534]:	loss/total_loss, 7.8619866371154785, 979
[INFO] 2021-07-12 18:51:21,471 [run_pretraining.py:  535]:	loss/mlm_loss, 7.8619866371154785, 979
[INFO] 2021-07-12 18:51:21,471 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.780000254977494e-06, 979
[INFO] 2021-07-12 18:51:21,471 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 979
[INFO] 2021-07-12 18:51:21,471 [run_pretraining.py:  558]:	worker_index: 3, step: 979, cost: 7.861987, mlm loss: 7.861987, speed: 1.107812 steps/s, speed: 8.862492 samples/s, speed: 4537.595955 tokens/s, learning rate: 9.780e-06, loss_scalings: 13421.773438, pp_loss: 7.859087
[INFO] 2021-07-12 18:51:21,471 [run_pretraining.py:  512]:	********exe.run_979******* 
[INFO] 2021-07-12 18:51:22,384 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:22,385 [run_pretraining.py:  534]:	loss/total_loss, 7.533053874969482, 980
[INFO] 2021-07-12 18:51:22,385 [run_pretraining.py:  535]:	loss/mlm_loss, 7.533053874969482, 980
[INFO] 2021-07-12 18:51:22,385 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.790000149223488e-06, 980
[INFO] 2021-07-12 18:51:22,385 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 980
[INFO] 2021-07-12 18:51:22,385 [run_pretraining.py:  558]:	worker_index: 3, step: 980, cost: 7.533054, mlm loss: 7.533054, speed: 1.094486 steps/s, speed: 8.755885 samples/s, speed: 4483.012875 tokens/s, learning rate: 9.790e-06, loss_scalings: 13421.773438, pp_loss: 7.746009
[INFO] 2021-07-12 18:51:22,385 [run_pretraining.py:  512]:	********exe.run_980******* 
[INFO] 2021-07-12 18:51:23,298 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:23,298 [run_pretraining.py:  534]:	loss/total_loss, 7.788930416107178, 981
[INFO] 2021-07-12 18:51:23,299 [run_pretraining.py:  535]:	loss/mlm_loss, 7.788930416107178, 981
[INFO] 2021-07-12 18:51:23,299 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.79999913397478e-06, 981
[INFO] 2021-07-12 18:51:23,299 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 981
[INFO] 2021-07-12 18:51:23,299 [run_pretraining.py:  558]:	worker_index: 3, step: 981, cost: 7.788930, mlm loss: 7.788930, speed: 1.095307 steps/s, speed: 8.762458 samples/s, speed: 4486.378641 tokens/s, learning rate: 9.800e-06, loss_scalings: 13421.773438, pp_loss: 8.189065
[INFO] 2021-07-12 18:51:23,299 [run_pretraining.py:  512]:	********exe.run_981******* 
[INFO] 2021-07-12 18:51:24,208 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:24,208 [run_pretraining.py:  534]:	loss/total_loss, 7.843298435211182, 982
[INFO] 2021-07-12 18:51:24,208 [run_pretraining.py:  535]:	loss/mlm_loss, 7.843298435211182, 982
[INFO] 2021-07-12 18:51:24,208 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.809999937715475e-06, 982
[INFO] 2021-07-12 18:51:24,208 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 982
[INFO] 2021-07-12 18:51:24,209 [run_pretraining.py:  558]:	worker_index: 3, step: 982, cost: 7.843298, mlm loss: 7.843298, speed: 1.100025 steps/s, speed: 8.800198 samples/s, speed: 4505.701194 tokens/s, learning rate: 9.810e-06, loss_scalings: 13421.773438, pp_loss: 7.745374
[INFO] 2021-07-12 18:51:24,209 [run_pretraining.py:  512]:	********exe.run_982******* 
[INFO] 2021-07-12 18:51:25,117 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:25,117 [run_pretraining.py:  534]:	loss/total_loss, 7.840972900390625, 983
[INFO] 2021-07-12 18:51:25,117 [run_pretraining.py:  535]:	loss/mlm_loss, 7.840972900390625, 983
[INFO] 2021-07-12 18:51:25,117 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.819999831961468e-06, 983
[INFO] 2021-07-12 18:51:25,117 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 983
[INFO] 2021-07-12 18:51:25,118 [run_pretraining.py:  558]:	worker_index: 3, step: 983, cost: 7.840973, mlm loss: 7.840973, speed: 1.100854 steps/s, speed: 8.806834 samples/s, speed: 4509.098760 tokens/s, learning rate: 9.820e-06, loss_scalings: 13421.773438, pp_loss: 7.901639
[INFO] 2021-07-12 18:51:25,118 [run_pretraining.py:  512]:	********exe.run_983******* 
[INFO] 2021-07-12 18:51:26,050 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:26,050 [run_pretraining.py:  534]:	loss/total_loss, 7.448553085327148, 984
[INFO] 2021-07-12 18:51:26,050 [run_pretraining.py:  535]:	loss/mlm_loss, 7.448553085327148, 984
[INFO] 2021-07-12 18:51:26,050 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.829999726207461e-06, 984
[INFO] 2021-07-12 18:51:26,050 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 984
[INFO] 2021-07-12 18:51:26,050 [run_pretraining.py:  558]:	worker_index: 3, step: 984, cost: 7.448553, mlm loss: 7.448553, speed: 1.072651 steps/s, speed: 8.581207 samples/s, speed: 4393.577856 tokens/s, learning rate: 9.830e-06, loss_scalings: 13421.773438, pp_loss: 8.143415
[INFO] 2021-07-12 18:51:26,051 [run_pretraining.py:  512]:	********exe.run_984******* 
[INFO] 2021-07-12 18:51:26,950 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:26,951 [run_pretraining.py:  534]:	loss/total_loss, 8.442854881286621, 985
[INFO] 2021-07-12 18:51:26,951 [run_pretraining.py:  535]:	loss/mlm_loss, 8.442854881286621, 985
[INFO] 2021-07-12 18:51:26,951 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.839999620453455e-06, 985
[INFO] 2021-07-12 18:51:26,951 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 985
[INFO] 2021-07-12 18:51:26,951 [run_pretraining.py:  558]:	worker_index: 3, step: 985, cost: 8.442855, mlm loss: 8.442855, speed: 1.110910 steps/s, speed: 8.887282 samples/s, speed: 4550.288536 tokens/s, learning rate: 9.840e-06, loss_scalings: 13421.773438, pp_loss: 8.263568
[INFO] 2021-07-12 18:51:26,951 [run_pretraining.py:  512]:	********exe.run_985******* 
[INFO] 2021-07-12 18:51:27,915 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:27,916 [run_pretraining.py:  534]:	loss/total_loss, 7.962608814239502, 986
[INFO] 2021-07-12 18:51:27,916 [run_pretraining.py:  535]:	loss/mlm_loss, 7.962608814239502, 986
[INFO] 2021-07-12 18:51:27,916 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.849999514699448e-06, 986
[INFO] 2021-07-12 18:51:27,916 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 986
[INFO] 2021-07-12 18:51:27,916 [run_pretraining.py:  558]:	worker_index: 3, step: 986, cost: 7.962609, mlm loss: 7.962609, speed: 1.037112 steps/s, speed: 8.296896 samples/s, speed: 4248.010846 tokens/s, learning rate: 9.850e-06, loss_scalings: 13421.773438, pp_loss: 8.061084
[INFO] 2021-07-12 18:51:27,916 [run_pretraining.py:  512]:	********exe.run_986******* 
[INFO] 2021-07-12 18:51:28,818 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:28,818 [run_pretraining.py:  534]:	loss/total_loss, 8.218916893005371, 987
[INFO] 2021-07-12 18:51:28,818 [run_pretraining.py:  535]:	loss/mlm_loss, 8.218916893005371, 987
[INFO] 2021-07-12 18:51:28,818 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.859999408945441e-06, 987
[INFO] 2021-07-12 18:51:28,818 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 987
[INFO] 2021-07-12 18:51:28,818 [run_pretraining.py:  558]:	worker_index: 3, step: 987, cost: 8.218917, mlm loss: 8.218917, speed: 1.109028 steps/s, speed: 8.872224 samples/s, speed: 4542.578719 tokens/s, learning rate: 9.860e-06, loss_scalings: 13421.773438, pp_loss: 7.000745
[INFO] 2021-07-12 18:51:28,819 [run_pretraining.py:  512]:	********exe.run_987******* 
[INFO] 2021-07-12 18:51:29,725 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:29,725 [run_pretraining.py:  534]:	loss/total_loss, 7.839631080627441, 988
[INFO] 2021-07-12 18:51:29,725 [run_pretraining.py:  535]:	loss/mlm_loss, 7.839631080627441, 988
[INFO] 2021-07-12 18:51:29,725 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.870000212686136e-06, 988
[INFO] 2021-07-12 18:51:29,725 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 988
[INFO] 2021-07-12 18:51:29,726 [run_pretraining.py:  558]:	worker_index: 3, step: 988, cost: 7.839631, mlm loss: 7.839631, speed: 1.103207 steps/s, speed: 8.825657 samples/s, speed: 4518.736245 tokens/s, learning rate: 9.870e-06, loss_scalings: 13421.773438, pp_loss: 8.089136
[INFO] 2021-07-12 18:51:29,726 [run_pretraining.py:  512]:	********exe.run_988******* 
[INFO] 2021-07-12 18:51:30,634 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:30,634 [run_pretraining.py:  534]:	loss/total_loss, 8.15593433380127, 989
[INFO] 2021-07-12 18:51:30,634 [run_pretraining.py:  535]:	loss/mlm_loss, 8.15593433380127, 989
[INFO] 2021-07-12 18:51:30,635 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.88000010693213e-06, 989
[INFO] 2021-07-12 18:51:30,635 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 989
[INFO] 2021-07-12 18:51:30,635 [run_pretraining.py:  558]:	worker_index: 3, step: 989, cost: 8.155934, mlm loss: 8.155934, speed: 1.100726 steps/s, speed: 8.805810 samples/s, speed: 4508.574541 tokens/s, learning rate: 9.880e-06, loss_scalings: 13421.773438, pp_loss: 7.709995
[INFO] 2021-07-12 18:51:30,635 [run_pretraining.py:  512]:	********exe.run_989******* 
[INFO] 2021-07-12 18:51:31,539 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:31,540 [run_pretraining.py:  534]:	loss/total_loss, 6.261713981628418, 990
[INFO] 2021-07-12 18:51:31,540 [run_pretraining.py:  535]:	loss/mlm_loss, 6.261713981628418, 990
[INFO] 2021-07-12 18:51:31,540 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.889999091683421e-06, 990
[INFO] 2021-07-12 18:51:31,540 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 990
[INFO] 2021-07-12 18:51:31,540 [run_pretraining.py:  558]:	worker_index: 3, step: 990, cost: 6.261714, mlm loss: 6.261714, speed: 1.105424 steps/s, speed: 8.843395 samples/s, speed: 4527.818274 tokens/s, learning rate: 9.890e-06, loss_scalings: 13421.773438, pp_loss: 7.465281
[INFO] 2021-07-12 18:51:31,540 [run_pretraining.py:  512]:	********exe.run_990******* 
[INFO] 2021-07-12 18:51:32,455 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:32,455 [run_pretraining.py:  534]:	loss/total_loss, 8.199466705322266, 991
[INFO] 2021-07-12 18:51:32,455 [run_pretraining.py:  535]:	loss/mlm_loss, 8.199466705322266, 991
[INFO] 2021-07-12 18:51:32,455 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.899999895424116e-06, 991
[INFO] 2021-07-12 18:51:32,456 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 991
[INFO] 2021-07-12 18:51:32,456 [run_pretraining.py:  558]:	worker_index: 3, step: 991, cost: 8.199467, mlm loss: 8.199467, speed: 1.092856 steps/s, speed: 8.742849 samples/s, speed: 4476.338459 tokens/s, learning rate: 9.900e-06, loss_scalings: 13421.773438, pp_loss: 8.209538
[INFO] 2021-07-12 18:51:32,456 [run_pretraining.py:  512]:	********exe.run_991******* 
[INFO] 2021-07-12 18:51:33,364 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:33,365 [run_pretraining.py:  534]:	loss/total_loss, 8.364856719970703, 992
[INFO] 2021-07-12 18:51:33,365 [run_pretraining.py:  535]:	loss/mlm_loss, 8.364856719970703, 992
[INFO] 2021-07-12 18:51:33,365 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.90999978967011e-06, 992
[INFO] 2021-07-12 18:51:33,365 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 992
[INFO] 2021-07-12 18:51:33,365 [run_pretraining.py:  558]:	worker_index: 3, step: 992, cost: 8.364857, mlm loss: 8.364857, speed: 1.100606 steps/s, speed: 8.804848 samples/s, speed: 4508.082383 tokens/s, learning rate: 9.910e-06, loss_scalings: 13421.773438, pp_loss: 8.192753
[INFO] 2021-07-12 18:51:33,365 [run_pretraining.py:  512]:	********exe.run_992******* 
[INFO] 2021-07-12 18:51:34,274 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:34,275 [run_pretraining.py:  534]:	loss/total_loss, 8.404523849487305, 993
[INFO] 2021-07-12 18:51:34,275 [run_pretraining.py:  535]:	loss/mlm_loss, 8.404523849487305, 993
[INFO] 2021-07-12 18:51:34,275 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.919999683916103e-06, 993
[INFO] 2021-07-12 18:51:34,275 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 993
[INFO] 2021-07-12 18:51:34,275 [run_pretraining.py:  558]:	worker_index: 3, step: 993, cost: 8.404524, mlm loss: 8.404524, speed: 1.099206 steps/s, speed: 8.793648 samples/s, speed: 4502.347681 tokens/s, learning rate: 9.920e-06, loss_scalings: 13421.773438, pp_loss: 8.130106
[INFO] 2021-07-12 18:51:34,275 [run_pretraining.py:  512]:	********exe.run_993******* 
[INFO] 2021-07-12 18:51:35,184 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:35,184 [run_pretraining.py:  534]:	loss/total_loss, 8.290366172790527, 994
[INFO] 2021-07-12 18:51:35,184 [run_pretraining.py:  535]:	loss/mlm_loss, 8.290366172790527, 994
[INFO] 2021-07-12 18:51:35,185 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.929999578162096e-06, 994
[INFO] 2021-07-12 18:51:35,185 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 994
[INFO] 2021-07-12 18:51:35,185 [run_pretraining.py:  558]:	worker_index: 3, step: 994, cost: 8.290366, mlm loss: 8.290366, speed: 1.100312 steps/s, speed: 8.802492 samples/s, speed: 4506.876104 tokens/s, learning rate: 9.930e-06, loss_scalings: 13421.773438, pp_loss: 7.614281
[INFO] 2021-07-12 18:51:35,185 [run_pretraining.py:  512]:	********exe.run_994******* 
[INFO] 2021-07-12 18:51:36,123 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:36,124 [run_pretraining.py:  534]:	loss/total_loss, 8.084916114807129, 995
[INFO] 2021-07-12 18:51:36,124 [run_pretraining.py:  535]:	loss/mlm_loss, 8.084916114807129, 995
[INFO] 2021-07-12 18:51:36,124 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.93999947240809e-06, 995
[INFO] 2021-07-12 18:51:36,124 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 995
[INFO] 2021-07-12 18:51:36,124 [run_pretraining.py:  558]:	worker_index: 3, step: 995, cost: 8.084916, mlm loss: 8.084916, speed: 1.065072 steps/s, speed: 8.520579 samples/s, speed: 4362.536442 tokens/s, learning rate: 9.940e-06, loss_scalings: 13421.773438, pp_loss: 7.989489
[INFO] 2021-07-12 18:51:36,124 [run_pretraining.py:  512]:	********exe.run_995******* 
[INFO] 2021-07-12 18:51:37,034 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:37,034 [run_pretraining.py:  534]:	loss/total_loss, 7.884356498718262, 996
[INFO] 2021-07-12 18:51:37,034 [run_pretraining.py:  535]:	loss/mlm_loss, 7.884356498718262, 996
[INFO] 2021-07-12 18:51:37,035 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.949999366654083e-06, 996
[INFO] 2021-07-12 18:51:37,035 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 996
[INFO] 2021-07-12 18:51:37,035 [run_pretraining.py:  558]:	worker_index: 3, step: 996, cost: 7.884356, mlm loss: 7.884356, speed: 1.099248 steps/s, speed: 8.793987 samples/s, speed: 4502.521139 tokens/s, learning rate: 9.950e-06, loss_scalings: 13421.773438, pp_loss: 7.054670
[INFO] 2021-07-12 18:51:37,035 [run_pretraining.py:  512]:	********exe.run_996******* 
[INFO] 2021-07-12 18:51:37,951 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:37,951 [run_pretraining.py:  534]:	loss/total_loss, 8.101451873779297, 997
[INFO] 2021-07-12 18:51:37,951 [run_pretraining.py:  535]:	loss/mlm_loss, 8.101451873779297, 997
[INFO] 2021-07-12 18:51:37,951 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.960000170394778e-06, 997
[INFO] 2021-07-12 18:51:37,951 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 997
[INFO] 2021-07-12 18:51:37,952 [run_pretraining.py:  558]:	worker_index: 3, step: 997, cost: 8.101452, mlm loss: 8.101452, speed: 1.091492 steps/s, speed: 8.731939 samples/s, speed: 4470.752826 tokens/s, learning rate: 9.960e-06, loss_scalings: 13421.773438, pp_loss: 8.172239
[INFO] 2021-07-12 18:51:37,952 [run_pretraining.py:  512]:	********exe.run_997******* 
[INFO] 2021-07-12 18:51:38,863 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:38,863 [run_pretraining.py:  534]:	loss/total_loss, 8.329804420471191, 998
[INFO] 2021-07-12 18:51:38,863 [run_pretraining.py:  535]:	loss/mlm_loss, 8.329804420471191, 998
[INFO] 2021-07-12 18:51:38,863 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.96999915514607e-06, 998
[INFO] 2021-07-12 18:51:38,863 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 998
[INFO] 2021-07-12 18:51:38,864 [run_pretraining.py:  558]:	worker_index: 3, step: 998, cost: 8.329804, mlm loss: 8.329804, speed: 1.097269 steps/s, speed: 8.778154 samples/s, speed: 4494.414819 tokens/s, learning rate: 9.970e-06, loss_scalings: 13421.773438, pp_loss: 7.756433
[INFO] 2021-07-12 18:51:38,864 [run_pretraining.py:  512]:	********exe.run_998******* 
[INFO] 2021-07-12 18:51:39,855 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:39,856 [run_pretraining.py:  534]:	loss/total_loss, 7.857612609863281, 999
[INFO] 2021-07-12 18:51:39,856 [run_pretraining.py:  535]:	loss/mlm_loss, 7.857612609863281, 999
[INFO] 2021-07-12 18:51:39,856 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.979999958886765e-06, 999
[INFO] 2021-07-12 18:51:39,856 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 999
[INFO] 2021-07-12 18:51:39,856 [run_pretraining.py:  558]:	worker_index: 3, step: 999, cost: 7.857613, mlm loss: 7.857613, speed: 1.008289 steps/s, speed: 8.066314 samples/s, speed: 4129.952960 tokens/s, learning rate: 9.980e-06, loss_scalings: 13421.773438, pp_loss: 8.092513
[INFO] 2021-07-12 18:51:39,856 [run_pretraining.py:  512]:	********exe.run_999******* 
[INFO] 2021-07-12 18:51:40,770 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:40,771 [run_pretraining.py:  534]:	loss/total_loss, 8.021349906921387, 1000
[INFO] 2021-07-12 18:51:40,771 [run_pretraining.py:  535]:	loss/mlm_loss, 8.021349906921387, 1000
[INFO] 2021-07-12 18:51:40,771 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.989999853132758e-06, 1000
[INFO] 2021-07-12 18:51:40,771 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1000
[INFO] 2021-07-12 18:51:40,771 [run_pretraining.py:  558]:	worker_index: 3, step: 1000, cost: 8.021350, mlm loss: 8.021350, speed: 1.093728 steps/s, speed: 8.749820 samples/s, speed: 4479.907977 tokens/s, learning rate: 9.990e-06, loss_scalings: 13421.773438, pp_loss: 8.071103
[INFO] 2021-07-12 18:51:40,771 [run_pretraining.py:  512]:	********exe.run_1000******* 
[INFO] 2021-07-12 18:51:41,681 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:41,682 [run_pretraining.py:  534]:	loss/total_loss, 8.079839706420898, 1001
[INFO] 2021-07-12 18:51:41,682 [run_pretraining.py:  535]:	loss/mlm_loss, 8.079839706420898, 1001
[INFO] 2021-07-12 18:51:41,682 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.999999747378752e-06, 1001
[INFO] 2021-07-12 18:51:41,682 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1001
[INFO] 2021-07-12 18:51:41,682 [run_pretraining.py:  558]:	worker_index: 3, step: 1001, cost: 8.079840, mlm loss: 8.079840, speed: 1.098161 steps/s, speed: 8.785288 samples/s, speed: 4498.067409 tokens/s, learning rate: 1.000e-05, loss_scalings: 13421.773438, pp_loss: 8.091990
[INFO] 2021-07-12 18:51:41,682 [run_pretraining.py:  512]:	********exe.run_1001******* 
[INFO] 2021-07-12 18:51:42,596 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:42,597 [run_pretraining.py:  534]:	loss/total_loss, 8.057435035705566, 1002
[INFO] 2021-07-12 18:51:42,597 [run_pretraining.py:  535]:	loss/mlm_loss, 8.057435035705566, 1002
[INFO] 2021-07-12 18:51:42,597 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0009999641624745e-05, 1002
[INFO] 2021-07-12 18:51:42,597 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1002
[INFO] 2021-07-12 18:51:42,597 [run_pretraining.py:  558]:	worker_index: 3, step: 1002, cost: 8.057435, mlm loss: 8.057435, speed: 1.093673 steps/s, speed: 8.749387 samples/s, speed: 4479.686030 tokens/s, learning rate: 1.001e-05, loss_scalings: 13421.773438, pp_loss: 7.168078
[INFO] 2021-07-12 18:51:42,597 [run_pretraining.py:  512]:	********exe.run_1002******* 
[INFO] 2021-07-12 18:51:43,508 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:43,509 [run_pretraining.py:  534]:	loss/total_loss, 7.875461101531982, 1003
[INFO] 2021-07-12 18:51:43,509 [run_pretraining.py:  535]:	loss/mlm_loss, 7.875461101531982, 1003
[INFO] 2021-07-12 18:51:43,509 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0019999535870738e-05, 1003
[INFO] 2021-07-12 18:51:43,509 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1003
[INFO] 2021-07-12 18:51:43,509 [run_pretraining.py:  558]:	worker_index: 3, step: 1003, cost: 7.875461, mlm loss: 7.875461, speed: 1.097373 steps/s, speed: 8.778988 samples/s, speed: 4494.841668 tokens/s, learning rate: 1.002e-05, loss_scalings: 13421.773438, pp_loss: 8.070312
[INFO] 2021-07-12 18:51:43,509 [run_pretraining.py:  512]:	********exe.run_1003******* 
[INFO] 2021-07-12 18:52:09,833 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:09,833 [run_pretraining.py:  534]:	loss/total_loss, 8.076984405517578, 1004
[INFO] 2021-07-12 18:52:09,833 [run_pretraining.py:  535]:	loss/mlm_loss, 8.076984405517578, 1004
[INFO] 2021-07-12 18:52:09,833 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0029999430116732e-05, 1004
[INFO] 2021-07-12 18:52:09,833 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1004
[INFO] 2021-07-12 18:52:09,833 [run_pretraining.py:  558]:	worker_index: 3, step: 1004, cost: 8.076984, mlm loss: 8.076984, speed: 0.037988 steps/s, speed: 0.303908 samples/s, speed: 155.600831 tokens/s, learning rate: 1.003e-05, loss_scalings: 13421.773438, pp_loss: 8.222060
[INFO] 2021-07-12 18:52:09,834 [run_pretraining.py:  512]:	********exe.run_1004******* 
[INFO] 2021-07-12 18:52:10,758 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:10,758 [run_pretraining.py:  534]:	loss/total_loss, 8.19359016418457, 1005
[INFO] 2021-07-12 18:52:10,758 [run_pretraining.py:  535]:	loss/mlm_loss, 8.19359016418457, 1005
[INFO] 2021-07-12 18:52:10,758 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0040000233857427e-05, 1005
[INFO] 2021-07-12 18:52:10,759 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1005
[INFO] 2021-07-12 18:52:10,759 [run_pretraining.py:  558]:	worker_index: 3, step: 1005, cost: 8.193590, mlm loss: 8.193590, speed: 1.081641 steps/s, speed: 8.653128 samples/s, speed: 4430.401342 tokens/s, learning rate: 1.004e-05, loss_scalings: 13421.773438, pp_loss: 8.049911
[INFO] 2021-07-12 18:52:10,759 [run_pretraining.py:  512]:	********exe.run_1005******* 
[INFO] 2021-07-12 18:52:11,678 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:11,679 [run_pretraining.py:  534]:	loss/total_loss, 8.234115600585938, 1006
[INFO] 2021-07-12 18:52:11,679 [run_pretraining.py:  535]:	loss/mlm_loss, 8.234115600585938, 1006
[INFO] 2021-07-12 18:52:11,679 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.005000012810342e-05, 1006
[INFO] 2021-07-12 18:52:11,679 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1006
[INFO] 2021-07-12 18:52:11,679 [run_pretraining.py:  558]:	worker_index: 3, step: 1006, cost: 8.234116, mlm loss: 8.234116, speed: 1.086874 steps/s, speed: 8.694996 samples/s, speed: 4451.837818 tokens/s, learning rate: 1.005e-05, loss_scalings: 13421.773438, pp_loss: 7.950714
[INFO] 2021-07-12 18:52:11,679 [run_pretraining.py:  512]:	********exe.run_1006******* 
[INFO] 2021-07-12 18:52:12,589 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:12,590 [run_pretraining.py:  534]:	loss/total_loss, 7.836617946624756, 1007
[INFO] 2021-07-12 18:52:12,590 [run_pretraining.py:  535]:	loss/mlm_loss, 7.836617946624756, 1007
[INFO] 2021-07-12 18:52:12,590 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0059999112854712e-05, 1007
[INFO] 2021-07-12 18:52:12,590 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1007
[INFO] 2021-07-12 18:52:12,590 [run_pretraining.py:  558]:	worker_index: 3, step: 1007, cost: 7.836618, mlm loss: 7.836618, speed: 1.098898 steps/s, speed: 8.791180 samples/s, speed: 4501.084325 tokens/s, learning rate: 1.006e-05, loss_scalings: 13421.773438, pp_loss: 8.025015
[INFO] 2021-07-12 18:52:12,590 [run_pretraining.py:  512]:	********exe.run_1007******* 
[INFO] 2021-07-12 18:52:13,513 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:13,514 [run_pretraining.py:  534]:	loss/total_loss, 7.394390106201172, 1008
[INFO] 2021-07-12 18:52:13,514 [run_pretraining.py:  535]:	loss/mlm_loss, 7.394390106201172, 1008
[INFO] 2021-07-12 18:52:13,514 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0069999916595407e-05, 1008
[INFO] 2021-07-12 18:52:13,514 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1008
[INFO] 2021-07-12 18:52:13,514 [run_pretraining.py:  558]:	worker_index: 3, step: 1008, cost: 7.394390, mlm loss: 7.394390, speed: 1.083061 steps/s, speed: 8.664490 samples/s, speed: 4436.218718 tokens/s, learning rate: 1.007e-05, loss_scalings: 13421.773438, pp_loss: 7.828578
[INFO] 2021-07-12 18:52:13,514 [run_pretraining.py:  512]:	********exe.run_1008******* 
[INFO] 2021-07-12 18:52:14,442 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:14,442 [run_pretraining.py:  534]:	loss/total_loss, 8.182046890258789, 1009
[INFO] 2021-07-12 18:52:14,442 [run_pretraining.py:  535]:	loss/mlm_loss, 8.182046890258789, 1009
[INFO] 2021-07-12 18:52:14,442 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.00799998108414e-05, 1009
[INFO] 2021-07-12 18:52:14,442 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1009
[INFO] 2021-07-12 18:52:14,442 [run_pretraining.py:  558]:	worker_index: 3, step: 1009, cost: 8.182047, mlm loss: 8.182047, speed: 1.077714 steps/s, speed: 8.621715 samples/s, speed: 4414.318324 tokens/s, learning rate: 1.008e-05, loss_scalings: 13421.773438, pp_loss: 7.868115
[INFO] 2021-07-12 18:52:14,443 [run_pretraining.py:  512]:	********exe.run_1009******* 
[INFO] 2021-07-12 18:52:15,357 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:15,357 [run_pretraining.py:  534]:	loss/total_loss, 8.15047550201416, 1010
[INFO] 2021-07-12 18:52:15,357 [run_pretraining.py:  535]:	loss/mlm_loss, 8.15047550201416, 1010
[INFO] 2021-07-12 18:52:15,357 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0089999705087394e-05, 1010
[INFO] 2021-07-12 18:52:15,358 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1010
[INFO] 2021-07-12 18:52:15,358 [run_pretraining.py:  558]:	worker_index: 3, step: 1010, cost: 8.150476, mlm loss: 8.150476, speed: 1.093510 steps/s, speed: 8.748082 samples/s, speed: 4479.017983 tokens/s, learning rate: 1.009e-05, loss_scalings: 13421.773438, pp_loss: 7.882705
[INFO] 2021-07-12 18:52:15,358 [run_pretraining.py:  512]:	********exe.run_1010******* 
[INFO] 2021-07-12 18:52:16,260 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:16,260 [run_pretraining.py:  534]:	loss/total_loss, 8.077637672424316, 1011
[INFO] 2021-07-12 18:52:16,260 [run_pretraining.py:  535]:	loss/mlm_loss, 8.077637672424316, 1011
[INFO] 2021-07-12 18:52:16,260 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0100000508828089e-05, 1011
[INFO] 2021-07-12 18:52:16,260 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1011
[INFO] 2021-07-12 18:52:16,260 [run_pretraining.py:  558]:	worker_index: 3, step: 1011, cost: 8.077638, mlm loss: 8.077638, speed: 1.108466 steps/s, speed: 8.867725 samples/s, speed: 4540.274946 tokens/s, learning rate: 1.010e-05, loss_scalings: 13421.773438, pp_loss: 8.090038
[INFO] 2021-07-12 18:52:16,260 [run_pretraining.py:  512]:	********exe.run_1011******* 
[INFO] 2021-07-12 18:52:17,171 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:17,172 [run_pretraining.py:  534]:	loss/total_loss, 8.090977668762207, 1012
[INFO] 2021-07-12 18:52:17,172 [run_pretraining.py:  535]:	loss/mlm_loss, 8.090977668762207, 1012
[INFO] 2021-07-12 18:52:17,172 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.010999949357938e-05, 1012
[INFO] 2021-07-12 18:52:17,172 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1012
[INFO] 2021-07-12 18:52:17,172 [run_pretraining.py:  558]:	worker_index: 3, step: 1012, cost: 8.090978, mlm loss: 8.090978, speed: 1.097425 steps/s, speed: 8.779401 samples/s, speed: 4495.053359 tokens/s, learning rate: 1.011e-05, loss_scalings: 13421.773438, pp_loss: 7.931207
[INFO] 2021-07-12 18:52:17,172 [run_pretraining.py:  512]:	********exe.run_1012******* 
[INFO] 2021-07-12 18:52:18,090 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:18,090 [run_pretraining.py:  534]:	loss/total_loss, 7.651112079620361, 1013
[INFO] 2021-07-12 18:52:18,090 [run_pretraining.py:  535]:	loss/mlm_loss, 7.651112079620361, 1013
[INFO] 2021-07-12 18:52:18,090 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0119999387825374e-05, 1013
[INFO] 2021-07-12 18:52:18,091 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1013
[INFO] 2021-07-12 18:52:18,091 [run_pretraining.py:  558]:	worker_index: 3, step: 1013, cost: 7.651112, mlm loss: 7.651112, speed: 1.089660 steps/s, speed: 8.717282 samples/s, speed: 4463.248502 tokens/s, learning rate: 1.012e-05, loss_scalings: 13421.773438, pp_loss: 7.992520
[INFO] 2021-07-12 18:52:18,091 [run_pretraining.py:  512]:	********exe.run_1013******* 
[INFO] 2021-07-12 18:52:18,994 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:18,995 [run_pretraining.py:  534]:	loss/total_loss, 8.163837432861328, 1014
[INFO] 2021-07-12 18:52:18,995 [run_pretraining.py:  535]:	loss/mlm_loss, 8.163837432861328, 1014
[INFO] 2021-07-12 18:52:18,995 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0130000191566069e-05, 1014
[INFO] 2021-07-12 18:52:18,995 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1014
[INFO] 2021-07-12 18:52:18,995 [run_pretraining.py:  558]:	worker_index: 3, step: 1014, cost: 8.163837, mlm loss: 8.163837, speed: 1.106680 steps/s, speed: 8.853440 samples/s, speed: 4532.961367 tokens/s, learning rate: 1.013e-05, loss_scalings: 13421.773438, pp_loss: 8.190800
[INFO] 2021-07-12 18:52:18,995 [run_pretraining.py:  512]:	********exe.run_1014******* 
[INFO] 2021-07-12 18:52:19,905 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:19,906 [run_pretraining.py:  534]:	loss/total_loss, 6.331262111663818, 1015
[INFO] 2021-07-12 18:52:19,906 [run_pretraining.py:  535]:	loss/mlm_loss, 6.331262111663818, 1015
[INFO] 2021-07-12 18:52:19,906 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0140000085812062e-05, 1015
[INFO] 2021-07-12 18:52:19,906 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1015
[INFO] 2021-07-12 18:52:19,906 [run_pretraining.py:  558]:	worker_index: 3, step: 1015, cost: 6.331262, mlm loss: 6.331262, speed: 1.097837 steps/s, speed: 8.782694 samples/s, speed: 4496.739364 tokens/s, learning rate: 1.014e-05, loss_scalings: 13421.773438, pp_loss: 7.715772
[INFO] 2021-07-12 18:52:19,906 [run_pretraining.py:  512]:	********exe.run_1015******* 
[INFO] 2021-07-12 18:52:20,819 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:20,819 [run_pretraining.py:  534]:	loss/total_loss, 8.627429962158203, 1016
[INFO] 2021-07-12 18:52:20,819 [run_pretraining.py:  535]:	loss/mlm_loss, 8.627429962158203, 1016
[INFO] 2021-07-12 18:52:20,819 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0149999070563354e-05, 1016
[INFO] 2021-07-12 18:52:20,819 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1016
[INFO] 2021-07-12 18:52:20,820 [run_pretraining.py:  558]:	worker_index: 3, step: 1016, cost: 8.627430, mlm loss: 8.627430, speed: 1.095844 steps/s, speed: 8.766751 samples/s, speed: 4488.576430 tokens/s, learning rate: 1.015e-05, loss_scalings: 13421.773438, pp_loss: 8.228363
[INFO] 2021-07-12 18:52:20,820 [run_pretraining.py:  512]:	********exe.run_1016******* 
[INFO] 2021-07-12 18:52:21,722 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:21,722 [run_pretraining.py:  534]:	loss/total_loss, 8.614230155944824, 1017
[INFO] 2021-07-12 18:52:21,722 [run_pretraining.py:  535]:	loss/mlm_loss, 8.614230155944824, 1017
[INFO] 2021-07-12 18:52:21,723 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0159999874304049e-05, 1017
[INFO] 2021-07-12 18:52:21,723 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1017
[INFO] 2021-07-12 18:52:21,723 [run_pretraining.py:  558]:	worker_index: 3, step: 1017, cost: 8.614230, mlm loss: 8.614230, speed: 1.108011 steps/s, speed: 8.864089 samples/s, speed: 4538.413467 tokens/s, learning rate: 1.016e-05, loss_scalings: 13421.773438, pp_loss: 8.136952
[INFO] 2021-07-12 18:52:21,723 [run_pretraining.py:  512]:	********exe.run_1017******* 
[INFO] 2021-07-12 18:52:22,629 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:22,629 [run_pretraining.py:  534]:	loss/total_loss, 8.372941017150879, 1018
[INFO] 2021-07-12 18:52:22,629 [run_pretraining.py:  535]:	loss/mlm_loss, 8.372941017150879, 1018
[INFO] 2021-07-12 18:52:22,629 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0169999768550042e-05, 1018
[INFO] 2021-07-12 18:52:22,629 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1018
[INFO] 2021-07-12 18:52:22,630 [run_pretraining.py:  558]:	worker_index: 3, step: 1018, cost: 8.372941, mlm loss: 8.372941, speed: 1.103514 steps/s, speed: 8.828116 samples/s, speed: 4519.995260 tokens/s, learning rate: 1.017e-05, loss_scalings: 13421.773438, pp_loss: 8.314227
[INFO] 2021-07-12 18:52:22,630 [run_pretraining.py:  512]:	********exe.run_1018******* 
[INFO] 2021-07-12 18:52:23,532 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:23,533 [run_pretraining.py:  534]:	loss/total_loss, 8.310675621032715, 1019
[INFO] 2021-07-12 18:52:23,533 [run_pretraining.py:  535]:	loss/mlm_loss, 8.310675621032715, 1019
[INFO] 2021-07-12 18:52:23,533 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0179999662796035e-05, 1019
[INFO] 2021-07-12 18:52:23,533 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1019
[INFO] 2021-07-12 18:52:23,533 [run_pretraining.py:  558]:	worker_index: 3, step: 1019, cost: 8.310676, mlm loss: 8.310676, speed: 1.107595 steps/s, speed: 8.860760 samples/s, speed: 4536.709251 tokens/s, learning rate: 1.018e-05, loss_scalings: 13421.773438, pp_loss: 8.342465
[INFO] 2021-07-12 18:52:23,533 [run_pretraining.py:  512]:	********exe.run_1019******* 
[INFO] 2021-07-12 18:52:24,442 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:24,443 [run_pretraining.py:  534]:	loss/total_loss, 7.809328079223633, 1020
[INFO] 2021-07-12 18:52:24,443 [run_pretraining.py:  535]:	loss/mlm_loss, 7.809328079223633, 1020
[INFO] 2021-07-12 18:52:24,443 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0189999557042029e-05, 1020
[INFO] 2021-07-12 18:52:24,443 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1020
[INFO] 2021-07-12 18:52:24,443 [run_pretraining.py:  558]:	worker_index: 3, step: 1020, cost: 7.809328, mlm loss: 7.809328, speed: 1.099756 steps/s, speed: 8.798049 samples/s, speed: 4504.601305 tokens/s, learning rate: 1.019e-05, loss_scalings: 13421.773438, pp_loss: 7.359284
[INFO] 2021-07-12 18:52:24,443 [run_pretraining.py:  512]:	********exe.run_1020******* 
[INFO] 2021-07-12 18:52:25,420 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:25,420 [run_pretraining.py:  534]:	loss/total_loss, 7.808078765869141, 1021
[INFO] 2021-07-12 18:52:25,420 [run_pretraining.py:  535]:	loss/mlm_loss, 7.808078765869141, 1021
[INFO] 2021-07-12 18:52:25,420 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0199999451288022e-05, 1021
[INFO] 2021-07-12 18:52:25,420 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1021
[INFO] 2021-07-12 18:52:25,421 [run_pretraining.py:  558]:	worker_index: 3, step: 1021, cost: 7.808079, mlm loss: 7.808079, speed: 1.023626 steps/s, speed: 8.189009 samples/s, speed: 4192.772655 tokens/s, learning rate: 1.020e-05, loss_scalings: 13421.773438, pp_loss: 7.023520
[INFO] 2021-07-12 18:52:25,421 [run_pretraining.py:  512]:	********exe.run_1021******* 
[INFO] 2021-07-12 18:52:26,473 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:26,474 [run_pretraining.py:  534]:	loss/total_loss, 7.655822277069092, 1022
[INFO] 2021-07-12 18:52:26,474 [run_pretraining.py:  535]:	loss/mlm_loss, 7.655822277069092, 1022
[INFO] 2021-07-12 18:52:26,474 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0209999345534015e-05, 1022
[INFO] 2021-07-12 18:52:26,474 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1022
[INFO] 2021-07-12 18:52:26,474 [run_pretraining.py:  558]:	worker_index: 3, step: 1022, cost: 7.655822, mlm loss: 7.655822, speed: 0.949544 steps/s, speed: 7.596354 samples/s, speed: 3889.333181 tokens/s, learning rate: 1.021e-05, loss_scalings: 13421.773438, pp_loss: 7.748549
[INFO] 2021-07-12 18:52:26,474 [run_pretraining.py:  512]:	********exe.run_1022******* 
[INFO] 2021-07-12 18:52:27,537 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:27,537 [run_pretraining.py:  534]:	loss/total_loss, 7.796314239501953, 1023
[INFO] 2021-07-12 18:52:27,538 [run_pretraining.py:  535]:	loss/mlm_loss, 7.796314239501953, 1023
[INFO] 2021-07-12 18:52:27,538 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.022000014927471e-05, 1023
[INFO] 2021-07-12 18:52:27,538 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1023
[INFO] 2021-07-12 18:52:27,538 [run_pretraining.py:  558]:	worker_index: 3, step: 1023, cost: 7.796314, mlm loss: 7.796314, speed: 0.940886 steps/s, speed: 7.527089 samples/s, speed: 3853.869744 tokens/s, learning rate: 1.022e-05, loss_scalings: 13421.773438, pp_loss: 7.906696
[INFO] 2021-07-12 18:52:27,538 [run_pretraining.py:  512]:	********exe.run_1023******* 
[INFO] 2021-07-12 18:52:28,601 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:28,602 [run_pretraining.py:  534]:	loss/total_loss, 8.240432739257812, 1024
[INFO] 2021-07-12 18:52:28,602 [run_pretraining.py:  535]:	loss/mlm_loss, 8.240432739257812, 1024
[INFO] 2021-07-12 18:52:28,602 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0230000043520704e-05, 1024
[INFO] 2021-07-12 18:52:28,602 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1024
[INFO] 2021-07-12 18:52:28,602 [run_pretraining.py:  558]:	worker_index: 3, step: 1024, cost: 8.240433, mlm loss: 8.240433, speed: 0.940247 steps/s, speed: 7.521975 samples/s, speed: 3851.251169 tokens/s, learning rate: 1.023e-05, loss_scalings: 13421.773438, pp_loss: 7.823989
[INFO] 2021-07-12 18:52:28,602 [run_pretraining.py:  512]:	********exe.run_1024******* 
[INFO] 2021-07-12 18:52:29,659 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:29,660 [run_pretraining.py:  534]:	loss/total_loss, 7.9209465980529785, 1025
[INFO] 2021-07-12 18:52:29,660 [run_pretraining.py:  535]:	loss/mlm_loss, 7.9209465980529785, 1025
[INFO] 2021-07-12 18:52:29,660 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0239999028271995e-05, 1025
[INFO] 2021-07-12 18:52:29,660 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1025
[INFO] 2021-07-12 18:52:29,660 [run_pretraining.py:  558]:	worker_index: 3, step: 1025, cost: 7.920947, mlm loss: 7.920947, speed: 0.945714 steps/s, speed: 7.565715 samples/s, speed: 3873.646284 tokens/s, learning rate: 1.024e-05, loss_scalings: 13421.773438, pp_loss: 7.919927
[INFO] 2021-07-12 18:52:29,660 [run_pretraining.py:  512]:	********exe.run_1025******* 
[INFO] 2021-07-12 18:52:30,742 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:30,742 [run_pretraining.py:  534]:	loss/total_loss, 7.821748733520508, 1026
[INFO] 2021-07-12 18:52:30,742 [run_pretraining.py:  535]:	loss/mlm_loss, 7.821748733520508, 1026
[INFO] 2021-07-12 18:52:30,742 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.024999983201269e-05, 1026
[INFO] 2021-07-12 18:52:30,742 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1026
[INFO] 2021-07-12 18:52:30,742 [run_pretraining.py:  558]:	worker_index: 3, step: 1026, cost: 7.821749, mlm loss: 7.821749, speed: 0.924356 steps/s, speed: 7.394849 samples/s, speed: 3786.162854 tokens/s, learning rate: 1.025e-05, loss_scalings: 13421.773438, pp_loss: 7.899399
[INFO] 2021-07-12 18:52:30,743 [run_pretraining.py:  512]:	********exe.run_1026******* 
[INFO] 2021-07-12 18:52:31,895 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:31,896 [run_pretraining.py:  534]:	loss/total_loss, 8.096631050109863, 1027
[INFO] 2021-07-12 18:52:31,896 [run_pretraining.py:  535]:	loss/mlm_loss, 8.096631050109863, 1027
[INFO] 2021-07-12 18:52:31,896 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0259999726258684e-05, 1027
[INFO] 2021-07-12 18:52:31,896 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1027
[INFO] 2021-07-12 18:52:31,896 [run_pretraining.py:  558]:	worker_index: 3, step: 1027, cost: 8.096631, mlm loss: 8.096631, speed: 0.867397 steps/s, speed: 6.939180 samples/s, speed: 3552.860092 tokens/s, learning rate: 1.026e-05, loss_scalings: 13421.773438, pp_loss: 8.201867
[INFO] 2021-07-12 18:52:31,896 [run_pretraining.py:  512]:	********exe.run_1027******* 
[INFO] 2021-07-12 18:52:32,931 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:32,932 [run_pretraining.py:  534]:	loss/total_loss, 8.283349990844727, 1028
[INFO] 2021-07-12 18:52:32,932 [run_pretraining.py:  535]:	loss/mlm_loss, 8.283349990844727, 1028
[INFO] 2021-07-12 18:52:32,932 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0269999620504677e-05, 1028
[INFO] 2021-07-12 18:52:32,932 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1028
[INFO] 2021-07-12 18:52:32,932 [run_pretraining.py:  558]:	worker_index: 3, step: 1028, cost: 8.283350, mlm loss: 8.283350, speed: 0.965505 steps/s, speed: 7.724043 samples/s, speed: 3954.709981 tokens/s, learning rate: 1.027e-05, loss_scalings: 13421.773438, pp_loss: 8.775347
[INFO] 2021-07-12 18:52:32,932 [run_pretraining.py:  512]:	********exe.run_1028******* 
[INFO] 2021-07-12 18:52:33,984 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:33,985 [run_pretraining.py:  534]:	loss/total_loss, 7.105031967163086, 1029
[INFO] 2021-07-12 18:52:33,985 [run_pretraining.py:  535]:	loss/mlm_loss, 7.105031967163086, 1029
[INFO] 2021-07-12 18:52:33,985 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.027999951475067e-05, 1029
[INFO] 2021-07-12 18:52:33,985 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1029
[INFO] 2021-07-12 18:52:33,985 [run_pretraining.py:  558]:	worker_index: 3, step: 1029, cost: 7.105032, mlm loss: 7.105032, speed: 0.950476 steps/s, speed: 7.603809 samples/s, speed: 3893.150379 tokens/s, learning rate: 1.028e-05, loss_scalings: 13421.773438, pp_loss: 7.972657
[INFO] 2021-07-12 18:52:33,985 [run_pretraining.py:  512]:	********exe.run_1029******* 
[INFO] 2021-07-12 18:52:35,045 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:35,046 [run_pretraining.py:  534]:	loss/total_loss, 8.47434139251709, 1030
[INFO] 2021-07-12 18:52:35,046 [run_pretraining.py:  535]:	loss/mlm_loss, 8.47434139251709, 1030
[INFO] 2021-07-12 18:52:35,046 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0289999408996664e-05, 1030
[INFO] 2021-07-12 18:52:35,046 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1030
[INFO] 2021-07-12 18:52:35,046 [run_pretraining.py:  558]:	worker_index: 3, step: 1030, cost: 8.474341, mlm loss: 8.474341, speed: 0.943245 steps/s, speed: 7.545957 samples/s, speed: 3863.529819 tokens/s, learning rate: 1.029e-05, loss_scalings: 13421.773438, pp_loss: 8.090408
[INFO] 2021-07-12 18:52:35,046 [run_pretraining.py:  512]:	********exe.run_1030******* 
[INFO] 2021-07-12 18:52:36,097 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:36,097 [run_pretraining.py:  534]:	loss/total_loss, 8.165003776550293, 1031
[INFO] 2021-07-12 18:52:36,097 [run_pretraining.py:  535]:	loss/mlm_loss, 8.165003776550293, 1031
[INFO] 2021-07-12 18:52:36,097 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0299999303242657e-05, 1031
[INFO] 2021-07-12 18:52:36,098 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1031
[INFO] 2021-07-12 18:52:36,098 [run_pretraining.py:  558]:	worker_index: 3, step: 1031, cost: 8.165004, mlm loss: 8.165004, speed: 0.951372 steps/s, speed: 7.610976 samples/s, speed: 3896.819505 tokens/s, learning rate: 1.030e-05, loss_scalings: 13421.773438, pp_loss: 8.136692
[INFO] 2021-07-12 18:52:36,098 [run_pretraining.py:  512]:	********exe.run_1031******* 
[INFO] 2021-07-12 18:52:37,162 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:37,162 [run_pretraining.py:  534]:	loss/total_loss, 7.713407516479492, 1032
[INFO] 2021-07-12 18:52:37,162 [run_pretraining.py:  535]:	loss/mlm_loss, 7.713407516479492, 1032
[INFO] 2021-07-12 18:52:37,162 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0310000106983352e-05, 1032
[INFO] 2021-07-12 18:52:37,162 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1032
[INFO] 2021-07-12 18:52:37,163 [run_pretraining.py:  558]:	worker_index: 3, step: 1032, cost: 7.713408, mlm loss: 7.713408, speed: 0.939625 steps/s, speed: 7.517002 samples/s, speed: 3848.705126 tokens/s, learning rate: 1.031e-05, loss_scalings: 13421.773438, pp_loss: 7.756052
[INFO] 2021-07-12 18:52:37,163 [run_pretraining.py:  512]:	********exe.run_1032******* 
[INFO] 2021-07-12 18:52:38,221 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:38,222 [run_pretraining.py:  534]:	loss/total_loss, 8.535046577453613, 1033
[INFO] 2021-07-12 18:52:38,222 [run_pretraining.py:  535]:	loss/mlm_loss, 8.535046577453613, 1033
[INFO] 2021-07-12 18:52:38,222 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0320000001229346e-05, 1033
[INFO] 2021-07-12 18:52:38,222 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1033
[INFO] 2021-07-12 18:52:38,222 [run_pretraining.py:  558]:	worker_index: 3, step: 1033, cost: 8.535047, mlm loss: 8.535047, speed: 0.944484 steps/s, speed: 7.555872 samples/s, speed: 3868.606265 tokens/s, learning rate: 1.032e-05, loss_scalings: 13421.773438, pp_loss: 7.210761
[INFO] 2021-07-12 18:52:38,222 [run_pretraining.py:  512]:	********exe.run_1033******* 
[INFO] 2021-07-12 18:52:39,339 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:39,340 [run_pretraining.py:  534]:	loss/total_loss, 7.716883659362793, 1034
[INFO] 2021-07-12 18:52:39,340 [run_pretraining.py:  535]:	loss/mlm_loss, 7.716883659362793, 1034
[INFO] 2021-07-12 18:52:39,340 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0329999895475339e-05, 1034
[INFO] 2021-07-12 18:52:39,340 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1034
[INFO] 2021-07-12 18:52:39,340 [run_pretraining.py:  558]:	worker_index: 3, step: 1034, cost: 7.716884, mlm loss: 7.716884, speed: 0.895035 steps/s, speed: 7.160278 samples/s, speed: 3666.062519 tokens/s, learning rate: 1.033e-05, loss_scalings: 13421.773438, pp_loss: 7.853865
[INFO] 2021-07-12 18:52:39,340 [run_pretraining.py:  512]:	********exe.run_1034******* 
[INFO] 2021-07-12 18:52:40,376 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:40,377 [run_pretraining.py:  534]:	loss/total_loss, 8.157676696777344, 1035
[INFO] 2021-07-12 18:52:40,377 [run_pretraining.py:  535]:	loss/mlm_loss, 8.157676696777344, 1035
[INFO] 2021-07-12 18:52:40,377 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0339999789721332e-05, 1035
[INFO] 2021-07-12 18:52:40,377 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1035
[INFO] 2021-07-12 18:52:40,377 [run_pretraining.py:  558]:	worker_index: 3, step: 1035, cost: 8.157677, mlm loss: 8.157677, speed: 0.964500 steps/s, speed: 7.715997 samples/s, speed: 3950.590382 tokens/s, learning rate: 1.034e-05, loss_scalings: 13421.773438, pp_loss: 8.181908
[INFO] 2021-07-12 18:52:40,377 [run_pretraining.py:  512]:	********exe.run_1035******* 
[INFO] 2021-07-12 18:52:41,436 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:41,436 [run_pretraining.py:  534]:	loss/total_loss, 8.126561164855957, 1036
[INFO] 2021-07-12 18:52:41,436 [run_pretraining.py:  535]:	loss/mlm_loss, 8.126561164855957, 1036
[INFO] 2021-07-12 18:52:41,436 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0349999683967326e-05, 1036
[INFO] 2021-07-12 18:52:41,436 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1036
[INFO] 2021-07-12 18:52:41,437 [run_pretraining.py:  558]:	worker_index: 3, step: 1036, cost: 8.126561, mlm loss: 8.126561, speed: 0.944648 steps/s, speed: 7.557184 samples/s, speed: 3869.278033 tokens/s, learning rate: 1.035e-05, loss_scalings: 13421.773438, pp_loss: 7.974311
[INFO] 2021-07-12 18:52:41,437 [run_pretraining.py:  512]:	********exe.run_1036******* 
[INFO] 2021-07-12 18:52:42,500 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:42,501 [run_pretraining.py:  534]:	loss/total_loss, 7.765589714050293, 1037
[INFO] 2021-07-12 18:52:42,501 [run_pretraining.py:  535]:	loss/mlm_loss, 7.765589714050293, 1037
[INFO] 2021-07-12 18:52:42,501 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.035999957821332e-05, 1037
[INFO] 2021-07-12 18:52:42,501 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1037
[INFO] 2021-07-12 18:52:42,501 [run_pretraining.py:  558]:	worker_index: 3, step: 1037, cost: 7.765590, mlm loss: 7.765590, speed: 0.939699 steps/s, speed: 7.517590 samples/s, speed: 3849.006058 tokens/s, learning rate: 1.036e-05, loss_scalings: 13421.773438, pp_loss: 7.978268
[INFO] 2021-07-12 18:52:42,501 [run_pretraining.py:  512]:	********exe.run_1037******* 
[INFO] 2021-07-12 18:52:43,553 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:43,554 [run_pretraining.py:  534]:	loss/total_loss, 7.829302787780762, 1038
[INFO] 2021-07-12 18:52:43,554 [run_pretraining.py:  535]:	loss/mlm_loss, 7.829302787780762, 1038
[INFO] 2021-07-12 18:52:43,554 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0369999472459313e-05, 1038
[INFO] 2021-07-12 18:52:43,554 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1038
[INFO] 2021-07-12 18:52:43,554 [run_pretraining.py:  558]:	worker_index: 3, step: 1038, cost: 7.829303, mlm loss: 7.829303, speed: 0.950519 steps/s, speed: 7.604154 samples/s, speed: 3893.326833 tokens/s, learning rate: 1.037e-05, loss_scalings: 13421.773438, pp_loss: 7.440733
[INFO] 2021-07-12 18:52:43,554 [run_pretraining.py:  512]:	********exe.run_1038******* 
[INFO] 2021-07-12 18:52:44,524 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:44,525 [run_pretraining.py:  534]:	loss/total_loss, 7.091411590576172, 1039
[INFO] 2021-07-12 18:52:44,525 [run_pretraining.py:  535]:	loss/mlm_loss, 7.091411590576172, 1039
[INFO] 2021-07-12 18:52:44,525 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0379999366705306e-05, 1039
[INFO] 2021-07-12 18:52:44,525 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1039
[INFO] 2021-07-12 18:52:44,525 [run_pretraining.py:  558]:	worker_index: 3, step: 1039, cost: 7.091412, mlm loss: 7.091412, speed: 1.030662 steps/s, speed: 8.245294 samples/s, speed: 4221.590771 tokens/s, learning rate: 1.038e-05, loss_scalings: 13421.773438, pp_loss: 7.026503
[INFO] 2021-07-12 18:52:44,525 [run_pretraining.py:  512]:	********exe.run_1039******* 
[INFO] 2021-07-12 18:52:45,491 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:45,492 [run_pretraining.py:  534]:	loss/total_loss, 8.069844245910645, 1040
[INFO] 2021-07-12 18:52:45,492 [run_pretraining.py:  535]:	loss/mlm_loss, 8.069844245910645, 1040
[INFO] 2021-07-12 18:52:45,492 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0390000170446001e-05, 1040
[INFO] 2021-07-12 18:52:45,492 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1040
[INFO] 2021-07-12 18:52:45,492 [run_pretraining.py:  558]:	worker_index: 3, step: 1040, cost: 8.069844, mlm loss: 8.069844, speed: 1.034492 steps/s, speed: 8.275937 samples/s, speed: 4237.279908 tokens/s, learning rate: 1.039e-05, loss_scalings: 13421.773438, pp_loss: 7.772893
[INFO] 2021-07-12 18:52:45,492 [run_pretraining.py:  512]:	********exe.run_1040******* 
[INFO] 2021-07-12 18:52:46,450 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:46,450 [run_pretraining.py:  534]:	loss/total_loss, 7.838117599487305, 1041
[INFO] 2021-07-12 18:52:46,450 [run_pretraining.py:  535]:	loss/mlm_loss, 7.838117599487305, 1041
[INFO] 2021-07-12 18:52:46,450 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0400000064691994e-05, 1041
[INFO] 2021-07-12 18:52:46,450 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1041
[INFO] 2021-07-12 18:52:46,451 [run_pretraining.py:  558]:	worker_index: 3, step: 1041, cost: 7.838118, mlm loss: 7.838118, speed: 1.044162 steps/s, speed: 8.353297 samples/s, speed: 4276.887822 tokens/s, learning rate: 1.040e-05, loss_scalings: 13421.773438, pp_loss: 7.477614
[INFO] 2021-07-12 18:52:46,451 [run_pretraining.py:  512]:	********exe.run_1041******* 
[INFO] 2021-07-12 18:52:47,396 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:47,397 [run_pretraining.py:  534]:	loss/total_loss, 8.09349250793457, 1042
[INFO] 2021-07-12 18:52:47,397 [run_pretraining.py:  535]:	loss/mlm_loss, 8.09349250793457, 1042
[INFO] 2021-07-12 18:52:47,397 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0409999049443286e-05, 1042
[INFO] 2021-07-12 18:52:47,397 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1042
[INFO] 2021-07-12 18:52:47,397 [run_pretraining.py:  558]:	worker_index: 3, step: 1042, cost: 8.093493, mlm loss: 8.093493, speed: 1.057242 steps/s, speed: 8.457938 samples/s, speed: 4330.464110 tokens/s, learning rate: 1.041e-05, loss_scalings: 13421.773438, pp_loss: 8.114580
[INFO] 2021-07-12 18:52:47,397 [run_pretraining.py:  512]:	********exe.run_1042******* 
[INFO] 2021-07-12 18:52:48,360 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:48,361 [run_pretraining.py:  534]:	loss/total_loss, 8.178868293762207, 1043
[INFO] 2021-07-12 18:52:48,361 [run_pretraining.py:  535]:	loss/mlm_loss, 8.178868293762207, 1043
[INFO] 2021-07-12 18:52:48,361 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0419999853183981e-05, 1043
[INFO] 2021-07-12 18:52:48,361 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1043
[INFO] 2021-07-12 18:52:48,361 [run_pretraining.py:  558]:	worker_index: 3, step: 1043, cost: 8.178868, mlm loss: 8.178868, speed: 1.037827 steps/s, speed: 8.302616 samples/s, speed: 4250.939255 tokens/s, learning rate: 1.042e-05, loss_scalings: 13421.773438, pp_loss: 7.976534
[INFO] 2021-07-12 18:52:48,361 [run_pretraining.py:  512]:	********exe.run_1043******* 
[INFO] 2021-07-12 18:52:49,324 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:49,324 [run_pretraining.py:  534]:	loss/total_loss, 8.361552238464355, 1044
[INFO] 2021-07-12 18:52:49,324 [run_pretraining.py:  535]:	loss/mlm_loss, 8.361552238464355, 1044
[INFO] 2021-07-12 18:52:49,324 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0429999747429974e-05, 1044
[INFO] 2021-07-12 18:52:49,324 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1044
[INFO] 2021-07-12 18:52:49,324 [run_pretraining.py:  558]:	worker_index: 3, step: 1044, cost: 8.361552, mlm loss: 8.361552, speed: 1.038971 steps/s, speed: 8.311770 samples/s, speed: 4255.626160 tokens/s, learning rate: 1.043e-05, loss_scalings: 13421.773438, pp_loss: 8.293317
[INFO] 2021-07-12 18:52:49,324 [run_pretraining.py:  512]:	********exe.run_1044******* 
[INFO] 2021-07-12 18:52:50,275 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:50,276 [run_pretraining.py:  534]:	loss/total_loss, 7.750631332397461, 1045
[INFO] 2021-07-12 18:52:50,276 [run_pretraining.py:  535]:	loss/mlm_loss, 7.750631332397461, 1045
[INFO] 2021-07-12 18:52:50,276 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0439999641675968e-05, 1045
[INFO] 2021-07-12 18:52:50,276 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1045
[INFO] 2021-07-12 18:52:50,276 [run_pretraining.py:  558]:	worker_index: 3, step: 1045, cost: 7.750631, mlm loss: 7.750631, speed: 1.051482 steps/s, speed: 8.411854 samples/s, speed: 4306.869329 tokens/s, learning rate: 1.044e-05, loss_scalings: 13421.773438, pp_loss: 7.756178
[INFO] 2021-07-12 18:52:50,276 [run_pretraining.py:  512]:	********exe.run_1045******* 
[INFO] 2021-07-12 18:52:51,184 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:51,184 [run_pretraining.py:  534]:	loss/total_loss, 8.33482551574707, 1046
[INFO] 2021-07-12 18:52:51,185 [run_pretraining.py:  535]:	loss/mlm_loss, 8.33482551574707, 1046
[INFO] 2021-07-12 18:52:51,185 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0450000445416663e-05, 1046
[INFO] 2021-07-12 18:52:51,185 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1046
[INFO] 2021-07-12 18:52:51,185 [run_pretraining.py:  558]:	worker_index: 3, step: 1046, cost: 8.334826, mlm loss: 8.334826, speed: 1.101196 steps/s, speed: 8.809567 samples/s, speed: 4510.498063 tokens/s, learning rate: 1.045e-05, loss_scalings: 13421.773438, pp_loss: 8.200052
[INFO] 2021-07-12 18:52:51,185 [run_pretraining.py:  512]:	********exe.run_1046******* 
[INFO] 2021-07-12 18:52:52,089 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:52,090 [run_pretraining.py:  534]:	loss/total_loss, 8.059926986694336, 1047
[INFO] 2021-07-12 18:52:52,090 [run_pretraining.py:  535]:	loss/mlm_loss, 8.059926986694336, 1047
[INFO] 2021-07-12 18:52:52,090 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0459999430167954e-05, 1047
[INFO] 2021-07-12 18:52:52,090 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1047
[INFO] 2021-07-12 18:52:52,090 [run_pretraining.py:  558]:	worker_index: 3, step: 1047, cost: 8.059927, mlm loss: 8.059927, speed: 1.105311 steps/s, speed: 8.842486 samples/s, speed: 4527.352926 tokens/s, learning rate: 1.046e-05, loss_scalings: 13421.773438, pp_loss: 7.839972
[INFO] 2021-07-12 18:52:52,090 [run_pretraining.py:  512]:	********exe.run_1047******* 
[INFO] 2021-07-12 18:52:52,993 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:52,994 [run_pretraining.py:  534]:	loss/total_loss, 7.808493614196777, 1048
[INFO] 2021-07-12 18:52:52,994 [run_pretraining.py:  535]:	loss/mlm_loss, 7.808493614196777, 1048
[INFO] 2021-07-12 18:52:52,994 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0469999324413948e-05, 1048
[INFO] 2021-07-12 18:52:52,994 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1048
[INFO] 2021-07-12 18:52:52,994 [run_pretraining.py:  558]:	worker_index: 3, step: 1048, cost: 7.808494, mlm loss: 7.808494, speed: 1.107096 steps/s, speed: 8.856766 samples/s, speed: 4534.663965 tokens/s, learning rate: 1.047e-05, loss_scalings: 13421.773438, pp_loss: 6.856308
[INFO] 2021-07-12 18:52:52,994 [run_pretraining.py:  512]:	********exe.run_1048******* 
[INFO] 2021-07-12 18:52:53,901 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:53,902 [run_pretraining.py:  534]:	loss/total_loss, 8.203033447265625, 1049
[INFO] 2021-07-12 18:52:53,902 [run_pretraining.py:  535]:	loss/mlm_loss, 8.203033447265625, 1049
[INFO] 2021-07-12 18:52:53,902 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0480000128154643e-05, 1049
[INFO] 2021-07-12 18:52:53,902 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1049
[INFO] 2021-07-12 18:52:53,902 [run_pretraining.py:  558]:	worker_index: 3, step: 1049, cost: 8.203033, mlm loss: 8.203033, speed: 1.102065 steps/s, speed: 8.816518 samples/s, speed: 4514.057055 tokens/s, learning rate: 1.048e-05, loss_scalings: 13421.773438, pp_loss: 8.262134
[INFO] 2021-07-12 18:52:53,902 [run_pretraining.py:  512]:	********exe.run_1049******* 
[INFO] 2021-07-12 18:52:54,807 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:54,807 [run_pretraining.py:  534]:	loss/total_loss, 8.005025863647461, 1050
[INFO] 2021-07-12 18:52:54,808 [run_pretraining.py:  535]:	loss/mlm_loss, 8.005025863647461, 1050
[INFO] 2021-07-12 18:52:54,808 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0490000022400636e-05, 1050
[INFO] 2021-07-12 18:52:54,808 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1050
[INFO] 2021-07-12 18:52:54,808 [run_pretraining.py:  558]:	worker_index: 3, step: 1050, cost: 8.005026, mlm loss: 8.005026, speed: 1.105022 steps/s, speed: 8.840178 samples/s, speed: 4526.170895 tokens/s, learning rate: 1.049e-05, loss_scalings: 13421.773438, pp_loss: 7.977083
[INFO] 2021-07-12 18:52:54,808 [run_pretraining.py:  512]:	********exe.run_1050******* 
[INFO] 2021-07-12 18:52:55,717 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:55,718 [run_pretraining.py:  534]:	loss/total_loss, 7.495959758758545, 1051
[INFO] 2021-07-12 18:52:55,718 [run_pretraining.py:  535]:	loss/mlm_loss, 7.495959758758545, 1051
[INFO] 2021-07-12 18:52:55,718 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0499999007151928e-05, 1051
[INFO] 2021-07-12 18:52:55,718 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1051
[INFO] 2021-07-12 18:52:55,718 [run_pretraining.py:  558]:	worker_index: 3, step: 1051, cost: 7.495960, mlm loss: 7.495960, speed: 1.099555 steps/s, speed: 8.796442 samples/s, speed: 4503.778217 tokens/s, learning rate: 1.050e-05, loss_scalings: 13421.773438, pp_loss: 7.854325
[INFO] 2021-07-12 18:52:55,718 [run_pretraining.py:  512]:	********exe.run_1051******* 
[INFO] 2021-07-12 18:52:56,621 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:56,621 [run_pretraining.py:  534]:	loss/total_loss, 7.8173723220825195, 1052
[INFO] 2021-07-12 18:52:56,621 [run_pretraining.py:  535]:	loss/mlm_loss, 7.8173723220825195, 1052
[INFO] 2021-07-12 18:52:56,621 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0509999810892623e-05, 1052
[INFO] 2021-07-12 18:52:56,622 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1052
[INFO] 2021-07-12 18:52:56,622 [run_pretraining.py:  558]:	worker_index: 3, step: 1052, cost: 7.817372, mlm loss: 7.817372, speed: 1.107281 steps/s, speed: 8.858250 samples/s, speed: 4535.424146 tokens/s, learning rate: 1.051e-05, loss_scalings: 13421.773438, pp_loss: 7.733315
[INFO] 2021-07-12 18:52:56,622 [run_pretraining.py:  512]:	********exe.run_1052******* 
[INFO] 2021-07-12 18:52:57,533 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:57,533 [run_pretraining.py:  534]:	loss/total_loss, 7.6581010818481445, 1053
[INFO] 2021-07-12 18:52:57,533 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6581010818481445, 1053
[INFO] 2021-07-12 18:52:57,533 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0519999705138616e-05, 1053
[INFO] 2021-07-12 18:52:57,534 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1053
[INFO] 2021-07-12 18:52:57,534 [run_pretraining.py:  558]:	worker_index: 3, step: 1053, cost: 7.658101, mlm loss: 7.658101, speed: 1.097241 steps/s, speed: 8.777924 samples/s, speed: 4494.297244 tokens/s, learning rate: 1.052e-05, loss_scalings: 13421.773438, pp_loss: 8.111205
[INFO] 2021-07-12 18:52:57,534 [run_pretraining.py:  512]:	********exe.run_1053******* 
[INFO] 2021-07-12 18:52:58,485 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:58,486 [run_pretraining.py:  534]:	loss/total_loss, 8.088814735412598, 1054
[INFO] 2021-07-12 18:52:58,486 [run_pretraining.py:  535]:	loss/mlm_loss, 8.088814735412598, 1054
[INFO] 2021-07-12 18:52:58,486 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.052999959938461e-05, 1054
[INFO] 2021-07-12 18:52:58,486 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1054
[INFO] 2021-07-12 18:52:58,486 [run_pretraining.py:  558]:	worker_index: 3, step: 1054, cost: 8.088815, mlm loss: 8.088815, speed: 1.050852 steps/s, speed: 8.406817 samples/s, speed: 4304.290389 tokens/s, learning rate: 1.053e-05, loss_scalings: 13421.773438, pp_loss: 7.993912
[INFO] 2021-07-12 18:52:58,486 [run_pretraining.py:  512]:	********exe.run_1054******* 
[INFO] 2021-07-12 18:52:59,541 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:59,542 [run_pretraining.py:  534]:	loss/total_loss, 7.638158798217773, 1055
[INFO] 2021-07-12 18:52:59,542 [run_pretraining.py:  535]:	loss/mlm_loss, 7.638158798217773, 1055
[INFO] 2021-07-12 18:52:59,542 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0540000403125305e-05, 1055
[INFO] 2021-07-12 18:52:59,542 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1055
[INFO] 2021-07-12 18:52:59,542 [run_pretraining.py:  558]:	worker_index: 3, step: 1055, cost: 7.638159, mlm loss: 7.638159, speed: 0.947183 steps/s, speed: 7.577465 samples/s, speed: 3879.662079 tokens/s, learning rate: 1.054e-05, loss_scalings: 13421.773438, pp_loss: 7.863052
[INFO] 2021-07-12 18:52:59,542 [run_pretraining.py:  512]:	********exe.run_1055******* 
[INFO] 2021-07-12 18:53:00,607 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:00,608 [run_pretraining.py:  534]:	loss/total_loss, 7.961794853210449, 1056
[INFO] 2021-07-12 18:53:00,608 [run_pretraining.py:  535]:	loss/mlm_loss, 7.961794853210449, 1056
[INFO] 2021-07-12 18:53:00,608 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0549999387876596e-05, 1056
[INFO] 2021-07-12 18:53:00,608 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1056
[INFO] 2021-07-12 18:53:00,608 [run_pretraining.py:  558]:	worker_index: 3, step: 1056, cost: 7.961795, mlm loss: 7.961795, speed: 0.938937 steps/s, speed: 7.511496 samples/s, speed: 3845.886065 tokens/s, learning rate: 1.055e-05, loss_scalings: 13421.773438, pp_loss: 7.825400
[INFO] 2021-07-12 18:53:00,608 [run_pretraining.py:  512]:	********exe.run_1056******* 
[INFO] 2021-07-12 18:53:01,692 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:01,692 [run_pretraining.py:  534]:	loss/total_loss, 8.270606994628906, 1057
[INFO] 2021-07-12 18:53:01,692 [run_pretraining.py:  535]:	loss/mlm_loss, 8.270606994628906, 1057
[INFO] 2021-07-12 18:53:01,693 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.055999928212259e-05, 1057
[INFO] 2021-07-12 18:53:01,693 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1057
[INFO] 2021-07-12 18:53:01,693 [run_pretraining.py:  558]:	worker_index: 3, step: 1057, cost: 8.270607, mlm loss: 8.270607, speed: 0.922421 steps/s, speed: 7.379369 samples/s, speed: 3778.236747 tokens/s, learning rate: 1.056e-05, loss_scalings: 13421.773438, pp_loss: 7.898290
[INFO] 2021-07-12 18:53:01,693 [run_pretraining.py:  512]:	********exe.run_1057******* 
[INFO] 2021-07-12 18:53:02,807 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:02,807 [run_pretraining.py:  534]:	loss/total_loss, 8.441123962402344, 1058
[INFO] 2021-07-12 18:53:02,807 [run_pretraining.py:  535]:	loss/mlm_loss, 8.441123962402344, 1058
[INFO] 2021-07-12 18:53:02,808 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0570000085863285e-05, 1058
[INFO] 2021-07-12 18:53:02,808 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1058
[INFO] 2021-07-12 18:53:02,808 [run_pretraining.py:  558]:	worker_index: 3, step: 1058, cost: 8.441124, mlm loss: 8.441124, speed: 0.897388 steps/s, speed: 7.179103 samples/s, speed: 3675.700840 tokens/s, learning rate: 1.057e-05, loss_scalings: 13421.773438, pp_loss: 8.055912
[INFO] 2021-07-12 18:53:02,808 [run_pretraining.py:  512]:	********exe.run_1058******* 
[INFO] 2021-07-12 18:53:03,898 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:03,899 [run_pretraining.py:  534]:	loss/total_loss, 7.582756996154785, 1059
[INFO] 2021-07-12 18:53:03,899 [run_pretraining.py:  535]:	loss/mlm_loss, 7.582756996154785, 1059
[INFO] 2021-07-12 18:53:03,899 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0579999980109278e-05, 1059
[INFO] 2021-07-12 18:53:03,899 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1059
[INFO] 2021-07-12 18:53:03,899 [run_pretraining.py:  558]:	worker_index: 3, step: 1059, cost: 7.582757, mlm loss: 7.582757, speed: 0.916864 steps/s, speed: 7.334911 samples/s, speed: 3755.474593 tokens/s, learning rate: 1.058e-05, loss_scalings: 13421.773438, pp_loss: 7.926245
[INFO] 2021-07-12 18:53:03,899 [run_pretraining.py:  512]:	********exe.run_1059******* 
[INFO] 2021-07-12 18:53:04,998 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:04,998 [run_pretraining.py:  534]:	loss/total_loss, 7.560510635375977, 1060
[INFO] 2021-07-12 18:53:04,998 [run_pretraining.py:  535]:	loss/mlm_loss, 7.560510635375977, 1060
[INFO] 2021-07-12 18:53:04,998 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0589999874355271e-05, 1060
[INFO] 2021-07-12 18:53:04,998 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1060
[INFO] 2021-07-12 18:53:04,998 [run_pretraining.py:  558]:	worker_index: 3, step: 1060, cost: 7.560511, mlm loss: 7.560511, speed: 0.910122 steps/s, speed: 7.280975 samples/s, speed: 3727.859252 tokens/s, learning rate: 1.059e-05, loss_scalings: 13421.773438, pp_loss: 7.881925
[INFO] 2021-07-12 18:53:04,998 [run_pretraining.py:  512]:	********exe.run_1060******* 
[INFO] 2021-07-12 18:53:06,077 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:06,077 [run_pretraining.py:  534]:	loss/total_loss, 7.827692985534668, 1061
[INFO] 2021-07-12 18:53:06,077 [run_pretraining.py:  535]:	loss/mlm_loss, 7.827692985534668, 1061
[INFO] 2021-07-12 18:53:06,077 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0599999768601265e-05, 1061
[INFO] 2021-07-12 18:53:06,078 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1061
[INFO] 2021-07-12 18:53:06,078 [run_pretraining.py:  558]:	worker_index: 3, step: 1061, cost: 7.827693, mlm loss: 7.827693, speed: 0.927124 steps/s, speed: 7.416988 samples/s, speed: 3797.497917 tokens/s, learning rate: 1.060e-05, loss_scalings: 13421.773438, pp_loss: 7.862836
[INFO] 2021-07-12 18:53:06,078 [run_pretraining.py:  512]:	********exe.run_1061******* 
[INFO] 2021-07-12 18:53:07,174 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:07,175 [run_pretraining.py:  534]:	loss/total_loss, 7.971232891082764, 1062
[INFO] 2021-07-12 18:53:07,175 [run_pretraining.py:  535]:	loss/mlm_loss, 7.971232891082764, 1062
[INFO] 2021-07-12 18:53:07,175 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0609999662847258e-05, 1062
[INFO] 2021-07-12 18:53:07,175 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1062
[INFO] 2021-07-12 18:53:07,175 [run_pretraining.py:  558]:	worker_index: 3, step: 1062, cost: 7.971233, mlm loss: 7.971233, speed: 0.911923 steps/s, speed: 7.295385 samples/s, speed: 3735.237315 tokens/s, learning rate: 1.061e-05, loss_scalings: 13421.773438, pp_loss: 7.843756
[INFO] 2021-07-12 18:53:07,175 [run_pretraining.py:  512]:	********exe.run_1062******* 
[INFO] 2021-07-12 18:53:08,273 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:08,273 [run_pretraining.py:  534]:	loss/total_loss, 8.048676490783691, 1063
[INFO] 2021-07-12 18:53:08,273 [run_pretraining.py:  535]:	loss/mlm_loss, 8.048676490783691, 1063
[INFO] 2021-07-12 18:53:08,273 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0619999557093251e-05, 1063
[INFO] 2021-07-12 18:53:08,274 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1063
[INFO] 2021-07-12 18:53:08,274 [run_pretraining.py:  558]:	worker_index: 3, step: 1063, cost: 8.048676, mlm loss: 8.048676, speed: 0.910700 steps/s, speed: 7.285601 samples/s, speed: 3730.227620 tokens/s, learning rate: 1.062e-05, loss_scalings: 13421.773438, pp_loss: 7.680229
[INFO] 2021-07-12 18:53:08,274 [run_pretraining.py:  512]:	********exe.run_1063******* 
[INFO] 2021-07-12 18:53:09,372 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:09,372 [run_pretraining.py:  534]:	loss/total_loss, 7.850347518920898, 1064
[INFO] 2021-07-12 18:53:09,372 [run_pretraining.py:  535]:	loss/mlm_loss, 7.850347518920898, 1064
[INFO] 2021-07-12 18:53:09,373 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0629999451339245e-05, 1064
[INFO] 2021-07-12 18:53:09,373 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1064
[INFO] 2021-07-12 18:53:09,373 [run_pretraining.py:  558]:	worker_index: 3, step: 1064, cost: 7.850348, mlm loss: 7.850348, speed: 0.910358 steps/s, speed: 7.282867 samples/s, speed: 3728.827766 tokens/s, learning rate: 1.063e-05, loss_scalings: 13421.773438, pp_loss: 7.827059
[INFO] 2021-07-12 18:53:09,373 [run_pretraining.py:  512]:	********exe.run_1064******* 
[INFO] 2021-07-12 18:53:10,311 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:10,312 [run_pretraining.py:  534]:	loss/total_loss, 7.570068359375, 1065
[INFO] 2021-07-12 18:53:10,312 [run_pretraining.py:  535]:	loss/mlm_loss, 7.570068359375, 1065
[INFO] 2021-07-12 18:53:10,312 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0639999345585238e-05, 1065
[INFO] 2021-07-12 18:53:10,312 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1065
[INFO] 2021-07-12 18:53:10,312 [run_pretraining.py:  558]:	worker_index: 3, step: 1065, cost: 7.570068, mlm loss: 7.570068, speed: 1.065383 steps/s, speed: 8.523068 samples/s, speed: 4363.810775 tokens/s, learning rate: 1.064e-05, loss_scalings: 13421.773438, pp_loss: 7.793118
[INFO] 2021-07-12 18:53:10,312 [run_pretraining.py:  512]:	********exe.run_1065******* 
[INFO] 2021-07-12 18:53:11,229 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:11,229 [run_pretraining.py:  534]:	loss/total_loss, 8.303116798400879, 1066
[INFO] 2021-07-12 18:53:11,230 [run_pretraining.py:  535]:	loss/mlm_loss, 8.303116798400879, 1066
[INFO] 2021-07-12 18:53:11,230 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0650000149325933e-05, 1066
[INFO] 2021-07-12 18:53:11,230 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1066
[INFO] 2021-07-12 18:53:11,230 [run_pretraining.py:  558]:	worker_index: 3, step: 1066, cost: 8.303117, mlm loss: 8.303117, speed: 1.090317 steps/s, speed: 8.722537 samples/s, speed: 4465.939075 tokens/s, learning rate: 1.065e-05, loss_scalings: 13421.773438, pp_loss: 7.863897
[INFO] 2021-07-12 18:53:11,230 [run_pretraining.py:  512]:	********exe.run_1066******* 
[INFO] 2021-07-12 18:53:12,138 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:12,139 [run_pretraining.py:  534]:	loss/total_loss, 8.0057954788208, 1067
[INFO] 2021-07-12 18:53:12,139 [run_pretraining.py:  535]:	loss/mlm_loss, 8.0057954788208, 1067
[INFO] 2021-07-12 18:53:12,139 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0660000043571927e-05, 1067
[INFO] 2021-07-12 18:53:12,139 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1067
[INFO] 2021-07-12 18:53:12,139 [run_pretraining.py:  558]:	worker_index: 3, step: 1067, cost: 8.005795, mlm loss: 8.005795, speed: 1.100574 steps/s, speed: 8.804594 samples/s, speed: 4507.952263 tokens/s, learning rate: 1.066e-05, loss_scalings: 13421.773438, pp_loss: 7.703563
[INFO] 2021-07-12 18:53:12,139 [run_pretraining.py:  512]:	********exe.run_1067******* 
[INFO] 2021-07-12 18:53:13,047 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:13,047 [run_pretraining.py:  534]:	loss/total_loss, 8.070866584777832, 1068
[INFO] 2021-07-12 18:53:13,047 [run_pretraining.py:  535]:	loss/mlm_loss, 8.070866584777832, 1068
[INFO] 2021-07-12 18:53:13,047 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.066999993781792e-05, 1068
[INFO] 2021-07-12 18:53:13,047 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1068
[INFO] 2021-07-12 18:53:13,048 [run_pretraining.py:  558]:	worker_index: 3, step: 1068, cost: 8.070867, mlm loss: 8.070867, speed: 1.101505 steps/s, speed: 8.812037 samples/s, speed: 4511.763155 tokens/s, learning rate: 1.067e-05, loss_scalings: 13421.773438, pp_loss: 7.974288
[INFO] 2021-07-12 18:53:13,048 [run_pretraining.py:  512]:	********exe.run_1068******* 
[INFO] 2021-07-12 18:53:13,954 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:13,954 [run_pretraining.py:  534]:	loss/total_loss, 7.79944372177124, 1069
[INFO] 2021-07-12 18:53:13,954 [run_pretraining.py:  535]:	loss/mlm_loss, 7.79944372177124, 1069
[INFO] 2021-07-12 18:53:13,955 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0679999832063913e-05, 1069
[INFO] 2021-07-12 18:53:13,955 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1069
[INFO] 2021-07-12 18:53:13,955 [run_pretraining.py:  558]:	worker_index: 3, step: 1069, cost: 7.799444, mlm loss: 7.799444, speed: 1.103148 steps/s, speed: 8.825181 samples/s, speed: 4518.492607 tokens/s, learning rate: 1.068e-05, loss_scalings: 13421.773438, pp_loss: 6.968105
[INFO] 2021-07-12 18:53:13,955 [run_pretraining.py:  512]:	********exe.run_1069******* 
[INFO] 2021-07-12 18:53:14,868 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:14,868 [run_pretraining.py:  534]:	loss/total_loss, 8.175488471984863, 1070
[INFO] 2021-07-12 18:53:14,869 [run_pretraining.py:  535]:	loss/mlm_loss, 8.175488471984863, 1070
[INFO] 2021-07-12 18:53:14,869 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0689999726309907e-05, 1070
[INFO] 2021-07-12 18:53:14,869 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1070
[INFO] 2021-07-12 18:53:14,869 [run_pretraining.py:  558]:	worker_index: 3, step: 1070, cost: 8.175488, mlm loss: 8.175488, speed: 1.094719 steps/s, speed: 8.757754 samples/s, speed: 4483.969994 tokens/s, learning rate: 1.069e-05, loss_scalings: 13421.773438, pp_loss: 7.707521
[INFO] 2021-07-12 18:53:14,869 [run_pretraining.py:  512]:	********exe.run_1070******* 
[INFO] 2021-07-12 18:53:15,771 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:15,772 [run_pretraining.py:  534]:	loss/total_loss, 7.802905082702637, 1071
[INFO] 2021-07-12 18:53:15,772 [run_pretraining.py:  535]:	loss/mlm_loss, 7.802905082702637, 1071
[INFO] 2021-07-12 18:53:15,772 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.06999996205559e-05, 1071
[INFO] 2021-07-12 18:53:15,772 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1071
[INFO] 2021-07-12 18:53:15,772 [run_pretraining.py:  558]:	worker_index: 3, step: 1071, cost: 7.802905, mlm loss: 7.802905, speed: 1.108152 steps/s, speed: 8.865220 samples/s, speed: 4538.992617 tokens/s, learning rate: 1.070e-05, loss_scalings: 13421.773438, pp_loss: 7.959266
[INFO] 2021-07-12 18:53:15,772 [run_pretraining.py:  512]:	********exe.run_1071******* 
[INFO] 2021-07-12 18:53:16,685 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:16,685 [run_pretraining.py:  534]:	loss/total_loss, 7.713513374328613, 1072
[INFO] 2021-07-12 18:53:16,686 [run_pretraining.py:  535]:	loss/mlm_loss, 7.713513374328613, 1072
[INFO] 2021-07-12 18:53:16,686 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0710000424296595e-05, 1072
[INFO] 2021-07-12 18:53:16,686 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1072
[INFO] 2021-07-12 18:53:16,686 [run_pretraining.py:  558]:	worker_index: 3, step: 1072, cost: 7.713513, mlm loss: 7.713513, speed: 1.094943 steps/s, speed: 8.759544 samples/s, speed: 4484.886544 tokens/s, learning rate: 1.071e-05, loss_scalings: 13421.773438, pp_loss: 6.852765
[INFO] 2021-07-12 18:53:16,686 [run_pretraining.py:  512]:	********exe.run_1072******* 
[INFO] 2021-07-12 18:53:17,592 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:17,592 [run_pretraining.py:  534]:	loss/total_loss, 8.019306182861328, 1073
[INFO] 2021-07-12 18:53:17,593 [run_pretraining.py:  535]:	loss/mlm_loss, 8.019306182861328, 1073
[INFO] 2021-07-12 18:53:17,593 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0719999409047887e-05, 1073
[INFO] 2021-07-12 18:53:17,593 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1073
[INFO] 2021-07-12 18:53:17,593 [run_pretraining.py:  558]:	worker_index: 3, step: 1073, cost: 8.019306, mlm loss: 8.019306, speed: 1.103284 steps/s, speed: 8.826274 samples/s, speed: 4519.052419 tokens/s, learning rate: 1.072e-05, loss_scalings: 13421.773438, pp_loss: 8.281416
[INFO] 2021-07-12 18:53:17,593 [run_pretraining.py:  512]:	********exe.run_1073******* 
[INFO] 2021-07-12 18:53:18,503 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:18,504 [run_pretraining.py:  534]:	loss/total_loss, 8.306106567382812, 1074
[INFO] 2021-07-12 18:53:18,504 [run_pretraining.py:  535]:	loss/mlm_loss, 8.306106567382812, 1074
[INFO] 2021-07-12 18:53:18,504 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.072999930329388e-05, 1074
[INFO] 2021-07-12 18:53:18,504 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1074
[INFO] 2021-07-12 18:53:18,504 [run_pretraining.py:  558]:	worker_index: 3, step: 1074, cost: 8.306107, mlm loss: 8.306107, speed: 1.098294 steps/s, speed: 8.786351 samples/s, speed: 4498.611569 tokens/s, learning rate: 1.073e-05, loss_scalings: 13421.773438, pp_loss: 8.147044
[INFO] 2021-07-12 18:53:18,504 [run_pretraining.py:  512]:	********exe.run_1074******* 
[INFO] 2021-07-12 18:53:19,412 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:19,413 [run_pretraining.py:  534]:	loss/total_loss, 8.016733169555664, 1075
[INFO] 2021-07-12 18:53:19,413 [run_pretraining.py:  535]:	loss/mlm_loss, 8.016733169555664, 1075
[INFO] 2021-07-12 18:53:19,413 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0740000107034575e-05, 1075
[INFO] 2021-07-12 18:53:19,413 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1075
[INFO] 2021-07-12 18:53:19,413 [run_pretraining.py:  558]:	worker_index: 3, step: 1075, cost: 8.016733, mlm loss: 8.016733, speed: 1.100461 steps/s, speed: 8.803686 samples/s, speed: 4507.487441 tokens/s, learning rate: 1.074e-05, loss_scalings: 13421.773438, pp_loss: 7.931246
[INFO] 2021-07-12 18:53:19,413 [run_pretraining.py:  512]:	********exe.run_1075******* 
[INFO] 2021-07-12 18:53:20,319 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:20,320 [run_pretraining.py:  534]:	loss/total_loss, 7.7211761474609375, 1076
[INFO] 2021-07-12 18:53:20,320 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7211761474609375, 1076
[INFO] 2021-07-12 18:53:20,320 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0750000001280569e-05, 1076
[INFO] 2021-07-12 18:53:20,320 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1076
[INFO] 2021-07-12 18:53:20,320 [run_pretraining.py:  558]:	worker_index: 3, step: 1076, cost: 7.721176, mlm loss: 7.721176, speed: 1.103679 steps/s, speed: 8.829433 samples/s, speed: 4520.669639 tokens/s, learning rate: 1.075e-05, loss_scalings: 13421.773438, pp_loss: 7.919337
[INFO] 2021-07-12 18:53:20,320 [run_pretraining.py:  512]:	********exe.run_1076******* 
[INFO] 2021-07-12 18:53:21,219 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:21,219 [run_pretraining.py:  534]:	loss/total_loss, 7.72913932800293, 1077
[INFO] 2021-07-12 18:53:21,219 [run_pretraining.py:  535]:	loss/mlm_loss, 7.72913932800293, 1077
[INFO] 2021-07-12 18:53:21,219 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0759999895526562e-05, 1077
[INFO] 2021-07-12 18:53:21,219 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1077
[INFO] 2021-07-12 18:53:21,220 [run_pretraining.py:  558]:	worker_index: 3, step: 1077, cost: 7.729139, mlm loss: 7.729139, speed: 1.112593 steps/s, speed: 8.900743 samples/s, speed: 4557.180634 tokens/s, learning rate: 1.076e-05, loss_scalings: 13421.773438, pp_loss: 7.919105
[INFO] 2021-07-12 18:53:21,220 [run_pretraining.py:  512]:	********exe.run_1077******* 
[INFO] 2021-07-12 18:53:22,126 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:22,126 [run_pretraining.py:  534]:	loss/total_loss, 8.375617980957031, 1078
[INFO] 2021-07-12 18:53:22,126 [run_pretraining.py:  535]:	loss/mlm_loss, 8.375617980957031, 1078
[INFO] 2021-07-12 18:53:22,126 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0769999789772555e-05, 1078
[INFO] 2021-07-12 18:53:22,126 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1078
[INFO] 2021-07-12 18:53:22,127 [run_pretraining.py:  558]:	worker_index: 3, step: 1078, cost: 8.375618, mlm loss: 8.375618, speed: 1.103245 steps/s, speed: 8.825961 samples/s, speed: 4518.891949 tokens/s, learning rate: 1.077e-05, loss_scalings: 13421.773438, pp_loss: 8.172056
[INFO] 2021-07-12 18:53:22,127 [run_pretraining.py:  512]:	********exe.run_1078******* 
[INFO] 2021-07-12 18:53:23,036 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:23,037 [run_pretraining.py:  534]:	loss/total_loss, 8.155143737792969, 1079
[INFO] 2021-07-12 18:53:23,037 [run_pretraining.py:  535]:	loss/mlm_loss, 8.155143737792969, 1079
[INFO] 2021-07-12 18:53:23,037 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0779999684018549e-05, 1079
[INFO] 2021-07-12 18:53:23,037 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1079
[INFO] 2021-07-12 18:53:23,037 [run_pretraining.py:  558]:	worker_index: 3, step: 1079, cost: 8.155144, mlm loss: 8.155144, speed: 1.098671 steps/s, speed: 8.789366 samples/s, speed: 4500.155250 tokens/s, learning rate: 1.078e-05, loss_scalings: 13421.773438, pp_loss: 8.019322
[INFO] 2021-07-12 18:53:23,037 [run_pretraining.py:  512]:	********exe.run_1079******* 
[INFO] 2021-07-12 18:53:23,936 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:23,936 [run_pretraining.py:  534]:	loss/total_loss, 7.832406997680664, 1080
[INFO] 2021-07-12 18:53:23,937 [run_pretraining.py:  535]:	loss/mlm_loss, 7.832406997680664, 1080
[INFO] 2021-07-12 18:53:23,937 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0789999578264542e-05, 1080
[INFO] 2021-07-12 18:53:23,937 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1080
[INFO] 2021-07-12 18:53:23,937 [run_pretraining.py:  558]:	worker_index: 3, step: 1080, cost: 7.832407, mlm loss: 7.832407, speed: 1.112712 steps/s, speed: 8.901695 samples/s, speed: 4557.667853 tokens/s, learning rate: 1.079e-05, loss_scalings: 13421.773438, pp_loss: 7.909079
[INFO] 2021-07-12 18:53:23,937 [run_pretraining.py:  512]:	********exe.run_1080******* 
[INFO] 2021-07-12 18:53:24,839 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:24,839 [run_pretraining.py:  534]:	loss/total_loss, 7.762977600097656, 1081
[INFO] 2021-07-12 18:53:24,839 [run_pretraining.py:  535]:	loss/mlm_loss, 7.762977600097656, 1081
[INFO] 2021-07-12 18:53:24,839 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0800000382005237e-05, 1081
[INFO] 2021-07-12 18:53:24,840 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1081
[INFO] 2021-07-12 18:53:24,840 [run_pretraining.py:  558]:	worker_index: 3, step: 1081, cost: 7.762978, mlm loss: 7.762978, speed: 1.108390 steps/s, speed: 8.867122 samples/s, speed: 4539.966593 tokens/s, learning rate: 1.080e-05, loss_scalings: 13421.773438, pp_loss: 8.073468
[INFO] 2021-07-12 18:53:24,840 [run_pretraining.py:  512]:	********exe.run_1081******* 
[INFO] 2021-07-12 18:53:25,767 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:25,773 [run_pretraining.py:  534]:	loss/total_loss, 8.137386322021484, 1082
[INFO] 2021-07-12 18:53:25,779 [run_pretraining.py:  535]:	loss/mlm_loss, 8.137386322021484, 1082
[INFO] 2021-07-12 18:53:25,784 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0809999366756529e-05, 1082
[INFO] 2021-07-12 18:53:25,789 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1082
[INFO] 2021-07-12 18:53:25,794 [run_pretraining.py:  558]:	worker_index: 3, step: 1082, cost: 8.137386, mlm loss: 8.137386, speed: 1.071319 steps/s, speed: 8.570550 samples/s, speed: 4388.121633 tokens/s, learning rate: 1.081e-05, loss_scalings: 13421.773438, pp_loss: 7.935950
[INFO] 2021-07-12 18:53:25,799 [run_pretraining.py:  512]:	********exe.run_1082******* 
[INFO] 2021-07-12 18:53:26,711 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:26,711 [run_pretraining.py:  534]:	loss/total_loss, 7.905149936676025, 1083
[INFO] 2021-07-12 18:53:26,711 [run_pretraining.py:  535]:	loss/mlm_loss, 7.905149936676025, 1083
[INFO] 2021-07-12 18:53:26,711 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0819999261002522e-05, 1083
[INFO] 2021-07-12 18:53:26,712 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1083
[INFO] 2021-07-12 18:53:26,712 [run_pretraining.py:  558]:	worker_index: 3, step: 1083, cost: 7.905150, mlm loss: 7.905150, speed: 1.096789 steps/s, speed: 8.774309 samples/s, speed: 4492.446248 tokens/s, learning rate: 1.082e-05, loss_scalings: 13421.773438, pp_loss: 8.002996
[INFO] 2021-07-12 18:53:26,712 [run_pretraining.py:  512]:	********exe.run_1083******* 
[INFO] 2021-07-12 18:53:27,618 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:27,618 [run_pretraining.py:  534]:	loss/total_loss, 7.798478603363037, 1084
[INFO] 2021-07-12 18:53:27,618 [run_pretraining.py:  535]:	loss/mlm_loss, 7.798478603363037, 1084
[INFO] 2021-07-12 18:53:27,619 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0830000064743217e-05, 1084
[INFO] 2021-07-12 18:53:27,619 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1084
[INFO] 2021-07-12 18:53:27,619 [run_pretraining.py:  558]:	worker_index: 3, step: 1084, cost: 7.798479, mlm loss: 7.798479, speed: 1.103226 steps/s, speed: 8.825808 samples/s, speed: 4518.813501 tokens/s, learning rate: 1.083e-05, loss_scalings: 13421.773438, pp_loss: 7.831417
[INFO] 2021-07-12 18:53:27,619 [run_pretraining.py:  512]:	********exe.run_1084******* 
[INFO] 2021-07-12 18:53:28,532 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:28,533 [run_pretraining.py:  534]:	loss/total_loss, 8.04153823852539, 1085
[INFO] 2021-07-12 18:53:28,533 [run_pretraining.py:  535]:	loss/mlm_loss, 8.04153823852539, 1085
[INFO] 2021-07-12 18:53:28,533 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.083999995898921e-05, 1085
[INFO] 2021-07-12 18:53:28,533 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1085
[INFO] 2021-07-12 18:53:28,533 [run_pretraining.py:  558]:	worker_index: 3, step: 1085, cost: 8.041538, mlm loss: 8.041538, speed: 1.094197 steps/s, speed: 8.753575 samples/s, speed: 4481.830496 tokens/s, learning rate: 1.084e-05, loss_scalings: 13421.773438, pp_loss: 7.957433
[INFO] 2021-07-12 18:53:28,533 [run_pretraining.py:  512]:	********exe.run_1085******* 
[INFO] 2021-07-12 18:53:29,435 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:29,436 [run_pretraining.py:  534]:	loss/total_loss, 8.521797180175781, 1086
[INFO] 2021-07-12 18:53:29,436 [run_pretraining.py:  535]:	loss/mlm_loss, 8.521797180175781, 1086
[INFO] 2021-07-12 18:53:29,436 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0849998943740502e-05, 1086
[INFO] 2021-07-12 18:53:29,436 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1086
[INFO] 2021-07-12 18:53:29,436 [run_pretraining.py:  558]:	worker_index: 3, step: 1086, cost: 8.521797, mlm loss: 8.521797, speed: 1.108423 steps/s, speed: 8.867380 samples/s, speed: 4540.098568 tokens/s, learning rate: 1.085e-05, loss_scalings: 13421.773438, pp_loss: 8.027654
[INFO] 2021-07-12 18:53:29,436 [run_pretraining.py:  512]:	********exe.run_1086******* 
[INFO] 2021-07-12 18:53:30,345 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:30,346 [run_pretraining.py:  534]:	loss/total_loss, 8.392749786376953, 1087
[INFO] 2021-07-12 18:53:30,346 [run_pretraining.py:  535]:	loss/mlm_loss, 8.392749786376953, 1087
[INFO] 2021-07-12 18:53:30,346 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0859999747481197e-05, 1087
[INFO] 2021-07-12 18:53:30,346 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1087
[INFO] 2021-07-12 18:53:30,346 [run_pretraining.py:  558]:	worker_index: 3, step: 1087, cost: 8.392750, mlm loss: 8.392750, speed: 1.099528 steps/s, speed: 8.796225 samples/s, speed: 4503.667236 tokens/s, learning rate: 1.086e-05, loss_scalings: 13421.773438, pp_loss: 8.326514
[INFO] 2021-07-12 18:53:30,346 [run_pretraining.py:  512]:	********exe.run_1087******* 
[INFO] 2021-07-12 18:53:31,242 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:31,243 [run_pretraining.py:  534]:	loss/total_loss, 8.276982307434082, 1088
[INFO] 2021-07-12 18:53:31,243 [run_pretraining.py:  535]:	loss/mlm_loss, 8.276982307434082, 1088
[INFO] 2021-07-12 18:53:31,243 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.086999964172719e-05, 1088
[INFO] 2021-07-12 18:53:31,243 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1088
[INFO] 2021-07-12 18:53:31,243 [run_pretraining.py:  558]:	worker_index: 3, step: 1088, cost: 8.276982, mlm loss: 8.276982, speed: 1.115609 steps/s, speed: 8.924875 samples/s, speed: 4569.535855 tokens/s, learning rate: 1.087e-05, loss_scalings: 13421.773438, pp_loss: 8.410332
[INFO] 2021-07-12 18:53:31,243 [run_pretraining.py:  512]:	********exe.run_1088******* 
[INFO] 2021-07-12 18:53:32,150 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:32,151 [run_pretraining.py:  534]:	loss/total_loss, 7.7812724113464355, 1089
[INFO] 2021-07-12 18:53:32,151 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7812724113464355, 1089
[INFO] 2021-07-12 18:53:32,151 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0879999535973184e-05, 1089
[INFO] 2021-07-12 18:53:32,151 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1089
[INFO] 2021-07-12 18:53:32,151 [run_pretraining.py:  558]:	worker_index: 3, step: 1089, cost: 7.781272, mlm loss: 7.781272, speed: 1.101882 steps/s, speed: 8.815058 samples/s, speed: 4513.309948 tokens/s, learning rate: 1.088e-05, loss_scalings: 13421.773438, pp_loss: 8.090981
[INFO] 2021-07-12 18:53:32,151 [run_pretraining.py:  512]:	********exe.run_1089******* 
[INFO] 2021-07-12 18:53:33,092 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:33,093 [run_pretraining.py:  534]:	loss/total_loss, 8.288461685180664, 1090
[INFO] 2021-07-12 18:53:33,093 [run_pretraining.py:  535]:	loss/mlm_loss, 8.288461685180664, 1090
[INFO] 2021-07-12 18:53:33,093 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0890000339713879e-05, 1090
[INFO] 2021-07-12 18:53:33,093 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1090
[INFO] 2021-07-12 18:53:33,093 [run_pretraining.py:  558]:	worker_index: 3, step: 1090, cost: 8.288462, mlm loss: 8.288462, speed: 1.062600 steps/s, speed: 8.500802 samples/s, speed: 4352.410409 tokens/s, learning rate: 1.089e-05, loss_scalings: 13421.773438, pp_loss: 8.231741
[INFO] 2021-07-12 18:53:33,093 [run_pretraining.py:  512]:	********exe.run_1090******* 
[INFO] 2021-07-12 18:53:33,994 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:33,995 [run_pretraining.py:  534]:	loss/total_loss, 7.824250221252441, 1091
[INFO] 2021-07-12 18:53:33,995 [run_pretraining.py:  535]:	loss/mlm_loss, 7.824250221252441, 1091
[INFO] 2021-07-12 18:53:33,995 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.089999932446517e-05, 1091
[INFO] 2021-07-12 18:53:33,995 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1091
[INFO] 2021-07-12 18:53:33,995 [run_pretraining.py:  558]:	worker_index: 3, step: 1091, cost: 7.824250, mlm loss: 7.824250, speed: 1.109700 steps/s, speed: 8.877599 samples/s, speed: 4545.330942 tokens/s, learning rate: 1.090e-05, loss_scalings: 13421.773438, pp_loss: 7.822377
[INFO] 2021-07-12 18:53:33,995 [run_pretraining.py:  512]:	********exe.run_1091******* 
[INFO] 2021-07-12 18:53:34,901 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:34,901 [run_pretraining.py:  534]:	loss/total_loss, 8.462051391601562, 1092
[INFO] 2021-07-12 18:53:34,902 [run_pretraining.py:  535]:	loss/mlm_loss, 8.462051391601562, 1092
[INFO] 2021-07-12 18:53:34,902 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0909999218711164e-05, 1092
[INFO] 2021-07-12 18:53:34,902 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1092
[INFO] 2021-07-12 18:53:34,902 [run_pretraining.py:  558]:	worker_index: 3, step: 1092, cost: 8.462051, mlm loss: 8.462051, speed: 1.103466 steps/s, speed: 8.827726 samples/s, speed: 4519.795483 tokens/s, learning rate: 1.091e-05, loss_scalings: 13421.773438, pp_loss: 8.106943
[INFO] 2021-07-12 18:53:34,902 [run_pretraining.py:  512]:	********exe.run_1092******* 
[INFO] 2021-07-12 18:53:35,926 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:35,927 [run_pretraining.py:  534]:	loss/total_loss, 7.903772354125977, 1093
[INFO] 2021-07-12 18:53:35,927 [run_pretraining.py:  535]:	loss/mlm_loss, 7.903772354125977, 1093
[INFO] 2021-07-12 18:53:35,927 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0920000022451859e-05, 1093
[INFO] 2021-07-12 18:53:35,927 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1093
[INFO] 2021-07-12 18:53:35,927 [run_pretraining.py:  558]:	worker_index: 3, step: 1093, cost: 7.903772, mlm loss: 7.903772, speed: 0.975783 steps/s, speed: 7.806266 samples/s, speed: 3996.808388 tokens/s, learning rate: 1.092e-05, loss_scalings: 13421.773438, pp_loss: 8.000198
[INFO] 2021-07-12 18:53:35,927 [run_pretraining.py:  512]:	********exe.run_1093******* 
[INFO] 2021-07-12 18:53:36,836 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:36,836 [run_pretraining.py:  534]:	loss/total_loss, 7.844751358032227, 1094
[INFO] 2021-07-12 18:53:36,836 [run_pretraining.py:  535]:	loss/mlm_loss, 7.844751358032227, 1094
[INFO] 2021-07-12 18:53:36,837 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0929999916697852e-05, 1094
[INFO] 2021-07-12 18:53:36,837 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1094
[INFO] 2021-07-12 18:53:36,837 [run_pretraining.py:  558]:	worker_index: 3, step: 1094, cost: 7.844751, mlm loss: 7.844751, speed: 1.100265 steps/s, speed: 8.802118 samples/s, speed: 4506.684577 tokens/s, learning rate: 1.093e-05, loss_scalings: 13421.773438, pp_loss: 8.158752
[INFO] 2021-07-12 18:53:36,837 [run_pretraining.py:  512]:	********exe.run_1094******* 
[INFO] 2021-07-12 18:53:37,737 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:37,738 [run_pretraining.py:  534]:	loss/total_loss, 8.35223388671875, 1095
[INFO] 2021-07-12 18:53:37,738 [run_pretraining.py:  535]:	loss/mlm_loss, 8.35223388671875, 1095
[INFO] 2021-07-12 18:53:37,738 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0939999810943846e-05, 1095
[INFO] 2021-07-12 18:53:37,738 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1095
[INFO] 2021-07-12 18:53:37,738 [run_pretraining.py:  558]:	worker_index: 3, step: 1095, cost: 8.352234, mlm loss: 8.352234, speed: 1.110219 steps/s, speed: 8.881754 samples/s, speed: 4547.458085 tokens/s, learning rate: 1.094e-05, loss_scalings: 13421.773438, pp_loss: 7.999019
[INFO] 2021-07-12 18:53:37,738 [run_pretraining.py:  512]:	********exe.run_1095******* 
[INFO] 2021-07-12 18:53:38,645 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:38,645 [run_pretraining.py:  534]:	loss/total_loss, 7.8304948806762695, 1096
[INFO] 2021-07-12 18:53:38,645 [run_pretraining.py:  535]:	loss/mlm_loss, 7.8304948806762695, 1096
[INFO] 2021-07-12 18:53:38,645 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0949999705189839e-05, 1096
[INFO] 2021-07-12 18:53:38,646 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1096
[INFO] 2021-07-12 18:53:38,646 [run_pretraining.py:  558]:	worker_index: 3, step: 1096, cost: 7.830495, mlm loss: 7.830495, speed: 1.102619 steps/s, speed: 8.820952 samples/s, speed: 4516.327169 tokens/s, learning rate: 1.095e-05, loss_scalings: 13421.773438, pp_loss: 7.889604
[INFO] 2021-07-12 18:53:38,646 [run_pretraining.py:  512]:	********exe.run_1096******* 
[INFO] 2021-07-12 18:53:39,551 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:39,552 [run_pretraining.py:  534]:	loss/total_loss, 8.740764617919922, 1097
[INFO] 2021-07-12 18:53:39,552 [run_pretraining.py:  535]:	loss/mlm_loss, 8.740764617919922, 1097
[INFO] 2021-07-12 18:53:39,552 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0959999599435832e-05, 1097
[INFO] 2021-07-12 18:53:39,552 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1097
[INFO] 2021-07-12 18:53:39,552 [run_pretraining.py:  558]:	worker_index: 3, step: 1097, cost: 8.740765, mlm loss: 8.740765, speed: 1.104263 steps/s, speed: 8.834108 samples/s, speed: 4523.063107 tokens/s, learning rate: 1.096e-05, loss_scalings: 13421.773438, pp_loss: 7.892866
[INFO] 2021-07-12 18:53:39,552 [run_pretraining.py:  512]:	********exe.run_1097******* 
[INFO] 2021-07-12 18:53:40,460 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:40,460 [run_pretraining.py:  534]:	loss/total_loss, 7.744759559631348, 1098
[INFO] 2021-07-12 18:53:40,460 [run_pretraining.py:  535]:	loss/mlm_loss, 7.744759559631348, 1098
[INFO] 2021-07-12 18:53:40,460 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0969999493681826e-05, 1098
[INFO] 2021-07-12 18:53:40,461 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1098
[INFO] 2021-07-12 18:53:40,461 [run_pretraining.py:  558]:	worker_index: 3, step: 1098, cost: 7.744760, mlm loss: 7.744760, speed: 1.101219 steps/s, speed: 8.809749 samples/s, speed: 4510.591618 tokens/s, learning rate: 1.097e-05, loss_scalings: 13421.773438, pp_loss: 8.196401
[INFO] 2021-07-12 18:53:40,461 [run_pretraining.py:  512]:	********exe.run_1098******* 
[INFO] 2021-07-12 18:53:41,364 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:41,364 [run_pretraining.py:  534]:	loss/total_loss, 7.8326568603515625, 1099
[INFO] 2021-07-12 18:53:41,364 [run_pretraining.py:  535]:	loss/mlm_loss, 7.8326568603515625, 1099
[INFO] 2021-07-12 18:53:41,365 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.098000029742252e-05, 1099
[INFO] 2021-07-12 18:53:41,365 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1099
[INFO] 2021-07-12 18:53:41,365 [run_pretraining.py:  558]:	worker_index: 3, step: 1099, cost: 7.832657, mlm loss: 7.832657, speed: 1.106827 steps/s, speed: 8.854613 samples/s, speed: 4533.561856 tokens/s, learning rate: 1.098e-05, loss_scalings: 13421.773438, pp_loss: 7.668075
[INFO] 2021-07-12 18:53:41,365 [run_pretraining.py:  512]:	********exe.run_1099******* 
[INFO] 2021-07-12 18:53:42,276 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:42,277 [run_pretraining.py:  534]:	loss/total_loss, 8.229883193969727, 1100
[INFO] 2021-07-12 18:53:42,277 [run_pretraining.py:  535]:	loss/mlm_loss, 8.229883193969727, 1100
[INFO] 2021-07-12 18:53:42,277 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0989999282173812e-05, 1100
[INFO] 2021-07-12 18:53:42,277 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1100
[INFO] 2021-07-12 18:53:42,277 [run_pretraining.py:  558]:	worker_index: 3, step: 1100, cost: 8.229883, mlm loss: 8.229883, speed: 1.096852 steps/s, speed: 8.774814 samples/s, speed: 4492.704708 tokens/s, learning rate: 1.099e-05, loss_scalings: 13421.773438, pp_loss: 7.768938
[INFO] 2021-07-12 18:53:42,277 [run_pretraining.py:  512]:	********exe.run_1100******* 
[INFO] 2021-07-12 18:53:43,246 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:43,246 [run_pretraining.py:  534]:	loss/total_loss, 8.188406944274902, 1101
[INFO] 2021-07-12 18:53:43,246 [run_pretraining.py:  535]:	loss/mlm_loss, 8.188406944274902, 1101
[INFO] 2021-07-12 18:53:43,246 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1000000085914508e-05, 1101
[INFO] 2021-07-12 18:53:43,246 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1101
[INFO] 2021-07-12 18:53:43,247 [run_pretraining.py:  558]:	worker_index: 3, step: 1101, cost: 8.188407, mlm loss: 8.188407, speed: 1.032153 steps/s, speed: 8.257223 samples/s, speed: 4227.698275 tokens/s, learning rate: 1.100e-05, loss_scalings: 13421.773438, pp_loss: 7.670312
[INFO] 2021-07-12 18:53:43,247 [run_pretraining.py:  512]:	********exe.run_1101******* 
[INFO] 2021-07-12 18:53:44,304 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:44,304 [run_pretraining.py:  534]:	loss/total_loss, 7.807538032531738, 1102
[INFO] 2021-07-12 18:53:44,304 [run_pretraining.py:  535]:	loss/mlm_loss, 7.807538032531738, 1102
[INFO] 2021-07-12 18:53:44,304 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1009999980160501e-05, 1102
[INFO] 2021-07-12 18:53:44,305 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1102
[INFO] 2021-07-12 18:53:44,305 [run_pretraining.py:  558]:	worker_index: 3, step: 1102, cost: 7.807538, mlm loss: 7.807538, speed: 0.945690 steps/s, speed: 7.565518 samples/s, speed: 3873.544971 tokens/s, learning rate: 1.101e-05, loss_scalings: 13421.773438, pp_loss: 7.770809
[INFO] 2021-07-12 18:53:44,305 [run_pretraining.py:  512]:	********exe.run_1102******* 
[INFO] 2021-07-12 18:53:45,386 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:45,386 [run_pretraining.py:  534]:	loss/total_loss, 7.806910514831543, 1103
[INFO] 2021-07-12 18:53:45,386 [run_pretraining.py:  535]:	loss/mlm_loss, 7.806910514831543, 1103
[INFO] 2021-07-12 18:53:45,386 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1019999874406494e-05, 1103
[INFO] 2021-07-12 18:53:45,386 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1103
[INFO] 2021-07-12 18:53:45,386 [run_pretraining.py:  558]:	worker_index: 3, step: 1103, cost: 7.806911, mlm loss: 7.806911, speed: 0.924869 steps/s, speed: 7.398949 samples/s, speed: 3788.261720 tokens/s, learning rate: 1.102e-05, loss_scalings: 13421.773438, pp_loss: 7.923738
[INFO] 2021-07-12 18:53:45,387 [run_pretraining.py:  512]:	********exe.run_1103******* 
[INFO] 2021-07-12 18:53:46,497 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:46,498 [run_pretraining.py:  534]:	loss/total_loss, 7.659786701202393, 1104
[INFO] 2021-07-12 18:53:46,498 [run_pretraining.py:  535]:	loss/mlm_loss, 7.659786701202393, 1104
[INFO] 2021-07-12 18:53:46,498 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1029999768652488e-05, 1104
[INFO] 2021-07-12 18:53:46,498 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1104
[INFO] 2021-07-12 18:53:46,498 [run_pretraining.py:  558]:	worker_index: 3, step: 1104, cost: 7.659787, mlm loss: 7.659787, speed: 0.900093 steps/s, speed: 7.200743 samples/s, speed: 3686.780342 tokens/s, learning rate: 1.103e-05, loss_scalings: 13421.773438, pp_loss: 7.760015
[INFO] 2021-07-12 18:53:46,498 [run_pretraining.py:  512]:	********exe.run_1104******* 
[INFO] 2021-07-12 18:53:47,592 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:47,592 [run_pretraining.py:  534]:	loss/total_loss, 7.836540699005127, 1105
[INFO] 2021-07-12 18:53:47,592 [run_pretraining.py:  535]:	loss/mlm_loss, 7.836540699005127, 1105
[INFO] 2021-07-12 18:53:47,593 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1039999662898481e-05, 1105
[INFO] 2021-07-12 18:53:47,593 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1105
[INFO] 2021-07-12 18:53:47,593 [run_pretraining.py:  558]:	worker_index: 3, step: 1105, cost: 7.836541, mlm loss: 7.836541, speed: 0.914117 steps/s, speed: 7.312936 samples/s, speed: 3744.222985 tokens/s, learning rate: 1.104e-05, loss_scalings: 13421.773438, pp_loss: 7.732355
[INFO] 2021-07-12 18:53:47,593 [run_pretraining.py:  512]:	********exe.run_1105******* 
[INFO] 2021-07-12 18:53:48,546 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:48,547 [run_pretraining.py:  534]:	loss/total_loss, 8.174982070922852, 1106
[INFO] 2021-07-12 18:53:48,547 [run_pretraining.py:  535]:	loss/mlm_loss, 8.174982070922852, 1106
[INFO] 2021-07-12 18:53:48,547 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1049999557144474e-05, 1106
[INFO] 2021-07-12 18:53:48,547 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1106
[INFO] 2021-07-12 18:53:48,547 [run_pretraining.py:  558]:	worker_index: 3, step: 1106, cost: 8.174982, mlm loss: 8.174982, speed: 1.048541 steps/s, speed: 8.388325 samples/s, speed: 4294.822346 tokens/s, learning rate: 1.105e-05, loss_scalings: 13421.773438, pp_loss: 8.098346
[INFO] 2021-07-12 18:53:48,547 [run_pretraining.py:  512]:	********exe.run_1106******* 
[INFO] 2021-07-12 18:53:49,454 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:49,454 [run_pretraining.py:  534]:	loss/total_loss, 8.015604019165039, 1107
[INFO] 2021-07-12 18:53:49,455 [run_pretraining.py:  535]:	loss/mlm_loss, 8.015604019165039, 1107
[INFO] 2021-07-12 18:53:49,455 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.106000036088517e-05, 1107
[INFO] 2021-07-12 18:53:49,455 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1107
[INFO] 2021-07-12 18:53:49,455 [run_pretraining.py:  558]:	worker_index: 3, step: 1107, cost: 8.015604, mlm loss: 8.015604, speed: 1.102415 steps/s, speed: 8.819319 samples/s, speed: 4515.491482 tokens/s, learning rate: 1.106e-05, loss_scalings: 13421.773438, pp_loss: 8.027989
[INFO] 2021-07-12 18:53:49,455 [run_pretraining.py:  512]:	********exe.run_1107******* 
[INFO] 2021-07-12 18:53:50,359 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:50,360 [run_pretraining.py:  534]:	loss/total_loss, 8.08447265625, 1108
[INFO] 2021-07-12 18:53:50,360 [run_pretraining.py:  535]:	loss/mlm_loss, 8.08447265625, 1108
[INFO] 2021-07-12 18:53:50,360 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1069999345636461e-05, 1108
[INFO] 2021-07-12 18:53:50,360 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1108
[INFO] 2021-07-12 18:53:50,360 [run_pretraining.py:  558]:	worker_index: 3, step: 1108, cost: 8.084473, mlm loss: 8.084473, speed: 1.105513 steps/s, speed: 8.844106 samples/s, speed: 4528.182267 tokens/s, learning rate: 1.107e-05, loss_scalings: 13421.773438, pp_loss: 7.723467
[INFO] 2021-07-12 18:53:50,360 [run_pretraining.py:  512]:	********exe.run_1108******* 
[INFO] 2021-07-12 18:53:51,294 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:51,295 [run_pretraining.py:  534]:	loss/total_loss, 8.186136245727539, 1109
[INFO] 2021-07-12 18:53:51,295 [run_pretraining.py:  535]:	loss/mlm_loss, 8.186136245727539, 1109
[INFO] 2021-07-12 18:53:51,295 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1079999239882454e-05, 1109
[INFO] 2021-07-12 18:53:51,295 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1109
[INFO] 2021-07-12 18:53:51,295 [run_pretraining.py:  558]:	worker_index: 3, step: 1109, cost: 8.186136, mlm loss: 8.186136, speed: 1.069822 steps/s, speed: 8.558575 samples/s, speed: 4381.990338 tokens/s, learning rate: 1.108e-05, loss_scalings: 13421.773438, pp_loss: 8.003092
[INFO] 2021-07-12 18:53:51,295 [run_pretraining.py:  512]:	********exe.run_1109******* 
[INFO] 2021-07-12 18:53:52,200 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:52,200 [run_pretraining.py:  534]:	loss/total_loss, 7.322681427001953, 1110
[INFO] 2021-07-12 18:53:52,200 [run_pretraining.py:  535]:	loss/mlm_loss, 7.322681427001953, 1110
[INFO] 2021-07-12 18:53:52,201 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.109000004362315e-05, 1110
[INFO] 2021-07-12 18:53:52,201 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1110
[INFO] 2021-07-12 18:53:52,201 [run_pretraining.py:  558]:	worker_index: 3, step: 1110, cost: 7.322681, mlm loss: 7.322681, speed: 1.105420 steps/s, speed: 8.843360 samples/s, speed: 4527.800375 tokens/s, learning rate: 1.109e-05, loss_scalings: 13421.773438, pp_loss: 7.565859
[INFO] 2021-07-12 18:53:52,201 [run_pretraining.py:  512]:	********exe.run_1110******* 
[INFO] 2021-07-12 18:53:53,104 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:53,105 [run_pretraining.py:  534]:	loss/total_loss, 8.147316932678223, 1111
[INFO] 2021-07-12 18:53:53,105 [run_pretraining.py:  535]:	loss/mlm_loss, 8.147316932678223, 1111
[INFO] 2021-07-12 18:53:53,105 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1099999937869143e-05, 1111
[INFO] 2021-07-12 18:53:53,105 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1111
[INFO] 2021-07-12 18:53:53,105 [run_pretraining.py:  558]:	worker_index: 3, step: 1111, cost: 8.147317, mlm loss: 8.147317, speed: 1.106689 steps/s, speed: 8.853510 samples/s, speed: 4532.997248 tokens/s, learning rate: 1.110e-05, loss_scalings: 13421.773438, pp_loss: 7.841761
[INFO] 2021-07-12 18:53:53,105 [run_pretraining.py:  512]:	********exe.run_1111******* 
[INFO] 2021-07-12 18:53:54,008 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:54,009 [run_pretraining.py:  534]:	loss/total_loss, 7.5713582038879395, 1112
[INFO] 2021-07-12 18:53:54,009 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5713582038879395, 1112
[INFO] 2021-07-12 18:53:54,009 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1109999832115136e-05, 1112
[INFO] 2021-07-12 18:53:54,009 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1112
[INFO] 2021-07-12 18:53:54,009 [run_pretraining.py:  558]:	worker_index: 3, step: 1112, cost: 7.571358, mlm loss: 7.571358, speed: 1.106960 steps/s, speed: 8.855676 samples/s, speed: 4534.106262 tokens/s, learning rate: 1.111e-05, loss_scalings: 13421.773438, pp_loss: 6.819185
[INFO] 2021-07-12 18:53:54,009 [run_pretraining.py:  512]:	********exe.run_1112******* 
[INFO] 2021-07-12 18:53:54,911 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:54,911 [run_pretraining.py:  534]:	loss/total_loss, 7.70842981338501, 1113
[INFO] 2021-07-12 18:53:54,912 [run_pretraining.py:  535]:	loss/mlm_loss, 7.70842981338501, 1113
[INFO] 2021-07-12 18:53:54,912 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.111999972636113e-05, 1113
[INFO] 2021-07-12 18:53:54,912 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1113
[INFO] 2021-07-12 18:53:54,912 [run_pretraining.py:  558]:	worker_index: 3, step: 1113, cost: 7.708430, mlm loss: 7.708430, speed: 1.108311 steps/s, speed: 8.866487 samples/s, speed: 4539.641488 tokens/s, learning rate: 1.112e-05, loss_scalings: 13421.773438, pp_loss: 7.672214
[INFO] 2021-07-12 18:53:54,912 [run_pretraining.py:  512]:	********exe.run_1113******* 
[INFO] 2021-07-12 18:53:55,873 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:55,874 [run_pretraining.py:  534]:	loss/total_loss, 7.549136638641357, 1114
[INFO] 2021-07-12 18:53:55,874 [run_pretraining.py:  535]:	loss/mlm_loss, 7.549136638641357, 1114
[INFO] 2021-07-12 18:53:55,874 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1129999620607123e-05, 1114
[INFO] 2021-07-12 18:53:55,874 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1114
[INFO] 2021-07-12 18:53:55,874 [run_pretraining.py:  558]:	worker_index: 3, step: 1114, cost: 7.549137, mlm loss: 7.549137, speed: 1.039989 steps/s, speed: 8.319915 samples/s, speed: 4259.796288 tokens/s, learning rate: 1.113e-05, loss_scalings: 13421.773438, pp_loss: 7.670854
[INFO] 2021-07-12 18:53:55,874 [run_pretraining.py:  512]:	********exe.run_1114******* 
[INFO] 2021-07-12 18:53:56,939 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:56,939 [run_pretraining.py:  534]:	loss/total_loss, 4.358268737792969, 1115
[INFO] 2021-07-12 18:53:56,940 [run_pretraining.py:  535]:	loss/mlm_loss, 4.358268737792969, 1115
[INFO] 2021-07-12 18:53:56,940 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1139999514853116e-05, 1115
[INFO] 2021-07-12 18:53:56,940 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1115
[INFO] 2021-07-12 18:53:56,940 [run_pretraining.py:  558]:	worker_index: 3, step: 1115, cost: 4.358269, mlm loss: 4.358269, speed: 0.938871 steps/s, speed: 7.510968 samples/s, speed: 3845.615748 tokens/s, learning rate: 1.114e-05, loss_scalings: 13421.773438, pp_loss: 6.906695
[INFO] 2021-07-12 18:53:56,940 [run_pretraining.py:  512]:	********exe.run_1115******* 
[INFO] 2021-07-12 18:53:58,003 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:58,004 [run_pretraining.py:  534]:	loss/total_loss, 8.055620193481445, 1116
[INFO] 2021-07-12 18:53:58,004 [run_pretraining.py:  535]:	loss/mlm_loss, 8.055620193481445, 1116
[INFO] 2021-07-12 18:53:58,004 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1150000318593811e-05, 1116
[INFO] 2021-07-12 18:53:58,004 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1116
[INFO] 2021-07-12 18:53:58,004 [run_pretraining.py:  558]:	worker_index: 3, step: 1116, cost: 8.055620, mlm loss: 8.055620, speed: 0.940023 steps/s, speed: 7.520188 samples/s, speed: 3850.336242 tokens/s, learning rate: 1.115e-05, loss_scalings: 13421.773438, pp_loss: 7.605980
[INFO] 2021-07-12 18:53:58,004 [run_pretraining.py:  512]:	********exe.run_1116******* 
[INFO] 2021-07-12 18:53:59,085 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:59,085 [run_pretraining.py:  534]:	loss/total_loss, 7.666940689086914, 1117
[INFO] 2021-07-12 18:53:59,085 [run_pretraining.py:  535]:	loss/mlm_loss, 7.666940689086914, 1117
[INFO] 2021-07-12 18:53:59,085 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1159999303345103e-05, 1117
[INFO] 2021-07-12 18:53:59,085 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1117
[INFO] 2021-07-12 18:53:59,085 [run_pretraining.py:  558]:	worker_index: 3, step: 1117, cost: 7.666941, mlm loss: 7.666941, speed: 0.925428 steps/s, speed: 7.403423 samples/s, speed: 3790.552755 tokens/s, learning rate: 1.116e-05, loss_scalings: 13421.773438, pp_loss: 7.767443
[INFO] 2021-07-12 18:53:59,085 [run_pretraining.py:  512]:	********exe.run_1117******* 
[INFO] 2021-07-12 18:54:00,164 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:00,164 [run_pretraining.py:  534]:	loss/total_loss, 7.764979362487793, 1118
[INFO] 2021-07-12 18:54:00,164 [run_pretraining.py:  535]:	loss/mlm_loss, 7.764979362487793, 1118
[INFO] 2021-07-12 18:54:00,164 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1169999197591096e-05, 1118
[INFO] 2021-07-12 18:54:00,164 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1118
[INFO] 2021-07-12 18:54:00,164 [run_pretraining.py:  558]:	worker_index: 3, step: 1118, cost: 7.764979, mlm loss: 7.764979, speed: 0.927264 steps/s, speed: 7.418110 samples/s, speed: 3798.072162 tokens/s, learning rate: 1.117e-05, loss_scalings: 13421.773438, pp_loss: 7.845812
[INFO] 2021-07-12 18:54:00,165 [run_pretraining.py:  512]:	********exe.run_1118******* 
[INFO] 2021-07-12 18:54:01,229 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:01,229 [run_pretraining.py:  534]:	loss/total_loss, 7.600794792175293, 1119
[INFO] 2021-07-12 18:54:01,229 [run_pretraining.py:  535]:	loss/mlm_loss, 7.600794792175293, 1119
[INFO] 2021-07-12 18:54:01,229 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1180000001331791e-05, 1119
[INFO] 2021-07-12 18:54:01,229 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1119
[INFO] 2021-07-12 18:54:01,229 [run_pretraining.py:  558]:	worker_index: 3, step: 1119, cost: 7.600795, mlm loss: 7.600795, speed: 0.939542 steps/s, speed: 7.516337 samples/s, speed: 3848.364586 tokens/s, learning rate: 1.118e-05, loss_scalings: 13421.773438, pp_loss: 7.777225
[INFO] 2021-07-12 18:54:01,230 [run_pretraining.py:  512]:	********exe.run_1119******* 
[INFO] 2021-07-12 18:54:02,320 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:02,326 [run_pretraining.py:  534]:	loss/total_loss, 7.76599645614624, 1120
[INFO] 2021-07-12 18:54:02,331 [run_pretraining.py:  535]:	loss/mlm_loss, 7.76599645614624, 1120
[INFO] 2021-07-12 18:54:02,340 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1189999895577785e-05, 1120
[INFO] 2021-07-12 18:54:02,343 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1120
[INFO] 2021-07-12 18:54:02,344 [run_pretraining.py:  558]:	worker_index: 3, step: 1120, cost: 7.765996, mlm loss: 7.765996, speed: 0.912354 steps/s, speed: 7.298835 samples/s, speed: 3737.003684 tokens/s, learning rate: 1.119e-05, loss_scalings: 13421.773438, pp_loss: 7.912384
[INFO] 2021-07-12 18:54:02,353 [run_pretraining.py:  512]:	********exe.run_1120******* 
[INFO] 2021-07-12 18:54:03,358 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:03,359 [run_pretraining.py:  534]:	loss/total_loss, 7.902620792388916, 1121
[INFO] 2021-07-12 18:54:03,359 [run_pretraining.py:  535]:	loss/mlm_loss, 7.902620792388916, 1121
[INFO] 2021-07-12 18:54:03,359 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1199999789823778e-05, 1121
[INFO] 2021-07-12 18:54:03,359 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1121
[INFO] 2021-07-12 18:54:03,359 [run_pretraining.py:  558]:	worker_index: 3, step: 1121, cost: 7.902621, mlm loss: 7.902621, speed: 0.994332 steps/s, speed: 7.954656 samples/s, speed: 4072.783708 tokens/s, learning rate: 1.120e-05, loss_scalings: 13421.773438, pp_loss: 7.936585
[INFO] 2021-07-12 18:54:03,359 [run_pretraining.py:  512]:	********exe.run_1121******* 
[INFO] 2021-07-12 18:54:04,418 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:04,419 [run_pretraining.py:  534]:	loss/total_loss, 8.80389404296875, 1122
[INFO] 2021-07-12 18:54:04,419 [run_pretraining.py:  535]:	loss/mlm_loss, 8.80389404296875, 1122
[INFO] 2021-07-12 18:54:04,419 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1209999684069771e-05, 1122
[INFO] 2021-07-12 18:54:04,419 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1122
[INFO] 2021-07-12 18:54:04,419 [run_pretraining.py:  558]:	worker_index: 3, step: 1122, cost: 8.803894, mlm loss: 8.803894, speed: 0.943808 steps/s, speed: 7.550465 samples/s, speed: 3865.838014 tokens/s, learning rate: 1.121e-05, loss_scalings: 13421.773438, pp_loss: 8.182571
[INFO] 2021-07-12 18:54:04,419 [run_pretraining.py:  512]:	********exe.run_1122******* 
[INFO] 2021-07-12 18:54:05,472 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:05,472 [run_pretraining.py:  534]:	loss/total_loss, 7.645534038543701, 1123
[INFO] 2021-07-12 18:54:05,473 [run_pretraining.py:  535]:	loss/mlm_loss, 7.645534038543701, 1123
[INFO] 2021-07-12 18:54:05,473 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1219999578315765e-05, 1123
[INFO] 2021-07-12 18:54:05,473 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1123
[INFO] 2021-07-12 18:54:05,473 [run_pretraining.py:  558]:	worker_index: 3, step: 1123, cost: 7.645534, mlm loss: 7.645534, speed: 0.949622 steps/s, speed: 7.596980 samples/s, speed: 3889.653710 tokens/s, learning rate: 1.122e-05, loss_scalings: 13421.773438, pp_loss: 7.603691
[INFO] 2021-07-12 18:54:05,473 [run_pretraining.py:  512]:	********exe.run_1123******* 
[INFO] 2021-07-12 18:54:06,553 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:06,554 [run_pretraining.py:  534]:	loss/total_loss, 7.72336483001709, 1124
[INFO] 2021-07-12 18:54:06,554 [run_pretraining.py:  535]:	loss/mlm_loss, 7.72336483001709, 1124
[INFO] 2021-07-12 18:54:06,554 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1229999472561758e-05, 1124
[INFO] 2021-07-12 18:54:06,554 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1124
[INFO] 2021-07-12 18:54:06,554 [run_pretraining.py:  558]:	worker_index: 3, step: 1124, cost: 7.723365, mlm loss: 7.723365, speed: 0.925170 steps/s, speed: 7.401359 samples/s, speed: 3789.495910 tokens/s, learning rate: 1.123e-05, loss_scalings: 13421.773438, pp_loss: 7.591861
[INFO] 2021-07-12 18:54:06,554 [run_pretraining.py:  512]:	********exe.run_1124******* 
[INFO] 2021-07-12 18:54:07,506 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:07,507 [run_pretraining.py:  534]:	loss/total_loss, 8.05135726928711, 1125
[INFO] 2021-07-12 18:54:07,507 [run_pretraining.py:  535]:	loss/mlm_loss, 8.05135726928711, 1125
[INFO] 2021-07-12 18:54:07,507 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1240000276302453e-05, 1125
[INFO] 2021-07-12 18:54:07,507 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1125
[INFO] 2021-07-12 18:54:07,507 [run_pretraining.py:  558]:	worker_index: 3, step: 1125, cost: 8.051357, mlm loss: 8.051357, speed: 1.050110 steps/s, speed: 8.400884 samples/s, speed: 4301.252501 tokens/s, learning rate: 1.124e-05, loss_scalings: 13421.773438, pp_loss: 7.285702
[INFO] 2021-07-12 18:54:07,507 [run_pretraining.py:  512]:	********exe.run_1125******* 
[INFO] 2021-07-12 18:54:08,429 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:08,429 [run_pretraining.py:  534]:	loss/total_loss, 7.878252029418945, 1126
[INFO] 2021-07-12 18:54:08,429 [run_pretraining.py:  535]:	loss/mlm_loss, 7.878252029418945, 1126
[INFO] 2021-07-12 18:54:08,430 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1249999261053745e-05, 1126
[INFO] 2021-07-12 18:54:08,430 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1126
[INFO] 2021-07-12 18:54:08,430 [run_pretraining.py:  558]:	worker_index: 3, step: 1126, cost: 7.878252, mlm loss: 7.878252, speed: 1.084755 steps/s, speed: 8.678040 samples/s, speed: 4443.156565 tokens/s, learning rate: 1.125e-05, loss_scalings: 13421.773438, pp_loss: 7.262429
[INFO] 2021-07-12 18:54:08,430 [run_pretraining.py:  512]:	********exe.run_1126******* 
[INFO] 2021-07-12 18:54:09,349 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:09,350 [run_pretraining.py:  534]:	loss/total_loss, 7.748449325561523, 1127
[INFO] 2021-07-12 18:54:09,350 [run_pretraining.py:  535]:	loss/mlm_loss, 7.748449325561523, 1127
[INFO] 2021-07-12 18:54:09,350 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1259999155299738e-05, 1127
[INFO] 2021-07-12 18:54:09,350 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1127
[INFO] 2021-07-12 18:54:09,350 [run_pretraining.py:  558]:	worker_index: 3, step: 1127, cost: 7.748449, mlm loss: 7.748449, speed: 1.087069 steps/s, speed: 8.696551 samples/s, speed: 4452.633951 tokens/s, learning rate: 1.126e-05, loss_scalings: 13421.773438, pp_loss: 7.768005
[INFO] 2021-07-12 18:54:09,350 [run_pretraining.py:  512]:	********exe.run_1127******* 
[INFO] 2021-07-12 18:54:10,272 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:10,273 [run_pretraining.py:  534]:	loss/total_loss, 7.380956649780273, 1128
[INFO] 2021-07-12 18:54:10,273 [run_pretraining.py:  535]:	loss/mlm_loss, 7.380956649780273, 1128
[INFO] 2021-07-12 18:54:10,273 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1269999959040433e-05, 1128
[INFO] 2021-07-12 18:54:10,273 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1128
[INFO] 2021-07-12 18:54:10,273 [run_pretraining.py:  558]:	worker_index: 3, step: 1128, cost: 7.380957, mlm loss: 7.380957, speed: 1.084273 steps/s, speed: 8.674182 samples/s, speed: 4441.180966 tokens/s, learning rate: 1.127e-05, loss_scalings: 13421.773438, pp_loss: 7.824662
[INFO] 2021-07-12 18:54:10,273 [run_pretraining.py:  512]:	********exe.run_1128******* 
[INFO] 2021-07-12 18:54:11,188 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:11,188 [run_pretraining.py:  534]:	loss/total_loss, 7.515562534332275, 1129
[INFO] 2021-07-12 18:54:11,188 [run_pretraining.py:  535]:	loss/mlm_loss, 7.515562534332275, 1129
[INFO] 2021-07-12 18:54:11,188 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1279999853286427e-05, 1129
[INFO] 2021-07-12 18:54:11,188 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1129
[INFO] 2021-07-12 18:54:11,188 [run_pretraining.py:  558]:	worker_index: 3, step: 1129, cost: 7.515563, mlm loss: 7.515563, speed: 1.093266 steps/s, speed: 8.746130 samples/s, speed: 4478.018622 tokens/s, learning rate: 1.128e-05, loss_scalings: 13421.773438, pp_loss: 7.865080
[INFO] 2021-07-12 18:54:11,189 [run_pretraining.py:  512]:	********exe.run_1129******* 
[INFO] 2021-07-12 18:54:12,109 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:12,109 [run_pretraining.py:  534]:	loss/total_loss, 8.040271759033203, 1130
[INFO] 2021-07-12 18:54:12,110 [run_pretraining.py:  535]:	loss/mlm_loss, 8.040271759033203, 1130
[INFO] 2021-07-12 18:54:12,110 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.128999974753242e-05, 1130
[INFO] 2021-07-12 18:54:12,110 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1130
[INFO] 2021-07-12 18:54:12,110 [run_pretraining.py:  558]:	worker_index: 3, step: 1130, cost: 8.040272, mlm loss: 8.040272, speed: 1.086203 steps/s, speed: 8.689623 samples/s, speed: 4449.087007 tokens/s, learning rate: 1.129e-05, loss_scalings: 13421.773438, pp_loss: 8.108348
[INFO] 2021-07-12 18:54:12,110 [run_pretraining.py:  512]:	********exe.run_1130******* 
[INFO] 2021-07-12 18:54:13,031 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:13,031 [run_pretraining.py:  534]:	loss/total_loss, 7.821025371551514, 1131
[INFO] 2021-07-12 18:54:13,031 [run_pretraining.py:  535]:	loss/mlm_loss, 7.821025371551514, 1131
[INFO] 2021-07-12 18:54:13,032 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1299999641778413e-05, 1131
[INFO] 2021-07-12 18:54:13,032 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1131
[INFO] 2021-07-12 18:54:13,032 [run_pretraining.py:  558]:	worker_index: 3, step: 1131, cost: 7.821025, mlm loss: 7.821025, speed: 1.085469 steps/s, speed: 8.683756 samples/s, speed: 4446.082988 tokens/s, learning rate: 1.130e-05, loss_scalings: 13421.773438, pp_loss: 7.945491
[INFO] 2021-07-12 18:54:13,032 [run_pretraining.py:  512]:	********exe.run_1131******* 
[INFO] 2021-07-12 18:54:13,946 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:13,947 [run_pretraining.py:  534]:	loss/total_loss, 7.136569976806641, 1132
[INFO] 2021-07-12 18:54:13,947 [run_pretraining.py:  535]:	loss/mlm_loss, 7.136569976806641, 1132
[INFO] 2021-07-12 18:54:13,947 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1309999536024407e-05, 1132
[INFO] 2021-07-12 18:54:13,947 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1132
[INFO] 2021-07-12 18:54:13,947 [run_pretraining.py:  558]:	worker_index: 3, step: 1132, cost: 7.136570, mlm loss: 7.136570, speed: 1.093372 steps/s, speed: 8.746978 samples/s, speed: 4478.452869 tokens/s, learning rate: 1.131e-05, loss_scalings: 13421.773438, pp_loss: 7.882414
[INFO] 2021-07-12 18:54:13,947 [run_pretraining.py:  512]:	********exe.run_1132******* 
[INFO] 2021-07-12 18:54:14,859 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:14,860 [run_pretraining.py:  534]:	loss/total_loss, 5.008694171905518, 1133
[INFO] 2021-07-12 18:54:14,860 [run_pretraining.py:  535]:	loss/mlm_loss, 5.008694171905518, 1133
[INFO] 2021-07-12 18:54:14,860 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.13199994302704e-05, 1133
[INFO] 2021-07-12 18:54:14,860 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1133
[INFO] 2021-07-12 18:54:14,860 [run_pretraining.py:  558]:	worker_index: 3, step: 1133, cost: 5.008694, mlm loss: 5.008694, speed: 1.096012 steps/s, speed: 8.768093 samples/s, speed: 4489.263754 tokens/s, learning rate: 1.132e-05, loss_scalings: 13421.773438, pp_loss: 7.088989
[INFO] 2021-07-12 18:54:14,860 [run_pretraining.py:  512]:	********exe.run_1133******* 
[INFO] 2021-07-12 18:54:15,776 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:15,776 [run_pretraining.py:  534]:	loss/total_loss, 7.678869247436523, 1134
[INFO] 2021-07-12 18:54:15,777 [run_pretraining.py:  535]:	loss/mlm_loss, 7.678869247436523, 1134
[INFO] 2021-07-12 18:54:15,777 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1330000234011095e-05, 1134
[INFO] 2021-07-12 18:54:15,777 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1134
[INFO] 2021-07-12 18:54:15,777 [run_pretraining.py:  558]:	worker_index: 3, step: 1134, cost: 7.678869, mlm loss: 7.678869, speed: 1.091426 steps/s, speed: 8.731407 samples/s, speed: 4470.480600 tokens/s, learning rate: 1.133e-05, loss_scalings: 13421.773438, pp_loss: 7.968185
[INFO] 2021-07-12 18:54:15,777 [run_pretraining.py:  512]:	********exe.run_1134******* 
[INFO] 2021-07-12 18:54:16,716 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:16,717 [run_pretraining.py:  534]:	loss/total_loss, 7.91119384765625, 1135
[INFO] 2021-07-12 18:54:16,717 [run_pretraining.py:  535]:	loss/mlm_loss, 7.91119384765625, 1135
[INFO] 2021-07-12 18:54:16,717 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1339999218762387e-05, 1135
[INFO] 2021-07-12 18:54:16,717 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1135
[INFO] 2021-07-12 18:54:16,717 [run_pretraining.py:  558]:	worker_index: 3, step: 1135, cost: 7.911194, mlm loss: 7.911194, speed: 1.064424 steps/s, speed: 8.515396 samples/s, speed: 4359.882679 tokens/s, learning rate: 1.134e-05, loss_scalings: 13421.773438, pp_loss: 7.982793
[INFO] 2021-07-12 18:54:16,717 [run_pretraining.py:  512]:	********exe.run_1135******* 
[INFO] 2021-07-12 18:54:17,634 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:17,635 [run_pretraining.py:  534]:	loss/total_loss, 7.721220970153809, 1136
[INFO] 2021-07-12 18:54:17,635 [run_pretraining.py:  535]:	loss/mlm_loss, 7.721220970153809, 1136
[INFO] 2021-07-12 18:54:17,635 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1350000022503082e-05, 1136
[INFO] 2021-07-12 18:54:17,635 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1136
[INFO] 2021-07-12 18:54:17,635 [run_pretraining.py:  558]:	worker_index: 3, step: 1136, cost: 7.721221, mlm loss: 7.721221, speed: 1.089592 steps/s, speed: 8.716739 samples/s, speed: 4462.970232 tokens/s, learning rate: 1.135e-05, loss_scalings: 13421.773438, pp_loss: 6.548764
[INFO] 2021-07-12 18:54:17,635 [run_pretraining.py:  512]:	********exe.run_1136******* 
[INFO] 2021-07-12 18:54:18,555 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:18,556 [run_pretraining.py:  534]:	loss/total_loss, 8.176216125488281, 1137
[INFO] 2021-07-12 18:54:18,556 [run_pretraining.py:  535]:	loss/mlm_loss, 8.176216125488281, 1137
[INFO] 2021-07-12 18:54:18,556 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1359999916749075e-05, 1137
[INFO] 2021-07-12 18:54:18,556 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1137
[INFO] 2021-07-12 18:54:18,556 [run_pretraining.py:  558]:	worker_index: 3, step: 1137, cost: 8.176216, mlm loss: 8.176216, speed: 1.087010 steps/s, speed: 8.696080 samples/s, speed: 4452.392773 tokens/s, learning rate: 1.136e-05, loss_scalings: 13421.773438, pp_loss: 7.742061
[INFO] 2021-07-12 18:54:18,556 [run_pretraining.py:  512]:	********exe.run_1137******* 
[INFO] 2021-07-12 18:54:19,480 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:19,481 [run_pretraining.py:  534]:	loss/total_loss, 8.114330291748047, 1138
[INFO] 2021-07-12 18:54:19,481 [run_pretraining.py:  535]:	loss/mlm_loss, 8.114330291748047, 1138
[INFO] 2021-07-12 18:54:19,481 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1369999810995068e-05, 1138
[INFO] 2021-07-12 18:54:19,481 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1138
[INFO] 2021-07-12 18:54:19,481 [run_pretraining.py:  558]:	worker_index: 3, step: 1138, cost: 8.114330, mlm loss: 8.114330, speed: 1.081893 steps/s, speed: 8.655143 samples/s, speed: 4431.433284 tokens/s, learning rate: 1.137e-05, loss_scalings: 13421.773438, pp_loss: 8.011718
[INFO] 2021-07-12 18:54:19,481 [run_pretraining.py:  512]:	********exe.run_1138******* 
[INFO] 2021-07-12 18:54:20,397 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:20,397 [run_pretraining.py:  534]:	loss/total_loss, 7.560293197631836, 1139
[INFO] 2021-07-12 18:54:20,397 [run_pretraining.py:  535]:	loss/mlm_loss, 7.560293197631836, 1139
[INFO] 2021-07-12 18:54:20,397 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1379999705241062e-05, 1139
[INFO] 2021-07-12 18:54:20,397 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1139
[INFO] 2021-07-12 18:54:20,397 [run_pretraining.py:  558]:	worker_index: 3, step: 1139, cost: 7.560293, mlm loss: 7.560293, speed: 1.091775 steps/s, speed: 8.734203 samples/s, speed: 4471.911906 tokens/s, learning rate: 1.138e-05, loss_scalings: 13421.773438, pp_loss: 7.793581
[INFO] 2021-07-12 18:54:20,398 [run_pretraining.py:  512]:	********exe.run_1139******* 
[INFO] 2021-07-12 18:54:21,315 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:21,316 [run_pretraining.py:  534]:	loss/total_loss, 7.516027450561523, 1140
[INFO] 2021-07-12 18:54:21,316 [run_pretraining.py:  535]:	loss/mlm_loss, 7.516027450561523, 1140
[INFO] 2021-07-12 18:54:21,316 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1389999599487055e-05, 1140
[INFO] 2021-07-12 18:54:21,316 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1140
[INFO] 2021-07-12 18:54:21,316 [run_pretraining.py:  558]:	worker_index: 3, step: 1140, cost: 7.516027, mlm loss: 7.516027, speed: 1.089204 steps/s, speed: 8.713631 samples/s, speed: 4461.378962 tokens/s, learning rate: 1.139e-05, loss_scalings: 13421.773438, pp_loss: 7.504736
[INFO] 2021-07-12 18:54:21,316 [run_pretraining.py:  512]:	********exe.run_1140******* 
[INFO] 2021-07-12 18:54:22,234 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:22,234 [run_pretraining.py:  534]:	loss/total_loss, 7.8228960037231445, 1141
[INFO] 2021-07-12 18:54:22,234 [run_pretraining.py:  535]:	loss/mlm_loss, 7.8228960037231445, 1141
[INFO] 2021-07-12 18:54:22,235 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1399999493733048e-05, 1141
[INFO] 2021-07-12 18:54:22,235 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1141
[INFO] 2021-07-12 18:54:22,235 [run_pretraining.py:  558]:	worker_index: 3, step: 1141, cost: 7.822896, mlm loss: 7.822896, speed: 1.089495 steps/s, speed: 8.715958 samples/s, speed: 4462.570279 tokens/s, learning rate: 1.140e-05, loss_scalings: 13421.773438, pp_loss: 7.807679
[INFO] 2021-07-12 18:54:22,235 [run_pretraining.py:  512]:	********exe.run_1141******* 
[INFO] 2021-07-12 18:54:23,155 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:23,155 [run_pretraining.py:  534]:	loss/total_loss, 8.127376556396484, 1142
[INFO] 2021-07-12 18:54:23,155 [run_pretraining.py:  535]:	loss/mlm_loss, 8.127376556396484, 1142
[INFO] 2021-07-12 18:54:23,155 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1410000297473744e-05, 1142
[INFO] 2021-07-12 18:54:23,155 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1142
[INFO] 2021-07-12 18:54:23,156 [run_pretraining.py:  558]:	worker_index: 3, step: 1142, cost: 8.127377, mlm loss: 8.127377, speed: 1.086747 steps/s, speed: 8.693977 samples/s, speed: 4451.316448 tokens/s, learning rate: 1.141e-05, loss_scalings: 13421.773438, pp_loss: 7.824467
[INFO] 2021-07-12 18:54:23,156 [run_pretraining.py:  512]:	********exe.run_1142******* 
[INFO] 2021-07-12 18:54:24,096 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:24,096 [run_pretraining.py:  534]:	loss/total_loss, 8.141006469726562, 1143
[INFO] 2021-07-12 18:54:24,096 [run_pretraining.py:  535]:	loss/mlm_loss, 8.141006469726562, 1143
[INFO] 2021-07-12 18:54:24,096 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1420000191719737e-05, 1143
[INFO] 2021-07-12 18:54:24,096 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1143
[INFO] 2021-07-12 18:54:24,096 [run_pretraining.py:  558]:	worker_index: 3, step: 1143, cost: 8.141006, mlm loss: 8.141006, speed: 1.063567 steps/s, speed: 8.508538 samples/s, speed: 4356.371441 tokens/s, learning rate: 1.142e-05, loss_scalings: 13421.773438, pp_loss: 7.853782
[INFO] 2021-07-12 18:54:24,096 [run_pretraining.py:  512]:	********exe.run_1143******* 
[INFO] 2021-07-12 18:54:25,017 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:25,018 [run_pretraining.py:  534]:	loss/total_loss, 7.6442036628723145, 1144
[INFO] 2021-07-12 18:54:25,018 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6442036628723145, 1144
[INFO] 2021-07-12 18:54:25,018 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1429999176471028e-05, 1144
[INFO] 2021-07-12 18:54:25,018 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1144
[INFO] 2021-07-12 18:54:25,018 [run_pretraining.py:  558]:	worker_index: 3, step: 1144, cost: 7.644204, mlm loss: 7.644204, speed: 1.085932 steps/s, speed: 8.687452 samples/s, speed: 4447.975427 tokens/s, learning rate: 1.143e-05, loss_scalings: 13421.773438, pp_loss: 7.749680
[INFO] 2021-07-12 18:54:25,018 [run_pretraining.py:  512]:	********exe.run_1144******* 
[INFO] 2021-07-12 18:54:25,933 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:25,934 [run_pretraining.py:  534]:	loss/total_loss, 7.2064619064331055, 1145
[INFO] 2021-07-12 18:54:25,934 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2064619064331055, 1145
[INFO] 2021-07-12 18:54:25,934 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1439999980211724e-05, 1145
[INFO] 2021-07-12 18:54:25,934 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1145
[INFO] 2021-07-12 18:54:25,934 [run_pretraining.py:  558]:	worker_index: 3, step: 1145, cost: 7.206462, mlm loss: 7.206462, speed: 1.092173 steps/s, speed: 8.737380 samples/s, speed: 4473.538657 tokens/s, learning rate: 1.144e-05, loss_scalings: 13421.773438, pp_loss: 7.546348
[INFO] 2021-07-12 18:54:25,934 [run_pretraining.py:  512]:	********exe.run_1145******* 
[INFO] 2021-07-12 18:54:26,846 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:26,846 [run_pretraining.py:  534]:	loss/total_loss, 8.13841438293457, 1146
[INFO] 2021-07-12 18:54:26,846 [run_pretraining.py:  535]:	loss/mlm_loss, 8.13841438293457, 1146
[INFO] 2021-07-12 18:54:26,846 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1449999874457717e-05, 1146
[INFO] 2021-07-12 18:54:26,846 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1146
[INFO] 2021-07-12 18:54:26,847 [run_pretraining.py:  558]:	worker_index: 3, step: 1146, cost: 8.138414, mlm loss: 8.138414, speed: 1.096750 steps/s, speed: 8.774004 samples/s, speed: 4492.290012 tokens/s, learning rate: 1.145e-05, loss_scalings: 13421.773438, pp_loss: 7.873281
[INFO] 2021-07-12 18:54:26,847 [run_pretraining.py:  512]:	********exe.run_1146******* 
[INFO] 2021-07-12 18:54:27,768 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:27,769 [run_pretraining.py:  534]:	loss/total_loss, 7.896050453186035, 1147
[INFO] 2021-07-12 18:54:27,769 [run_pretraining.py:  535]:	loss/mlm_loss, 7.896050453186035, 1147
[INFO] 2021-07-12 18:54:27,769 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.145999976870371e-05, 1147
[INFO] 2021-07-12 18:54:27,769 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1147
[INFO] 2021-07-12 18:54:27,769 [run_pretraining.py:  558]:	worker_index: 3, step: 1147, cost: 7.896050, mlm loss: 7.896050, speed: 1.084584 steps/s, speed: 8.676676 samples/s, speed: 4442.458013 tokens/s, learning rate: 1.146e-05, loss_scalings: 13421.773438, pp_loss: 7.845560
[INFO] 2021-07-12 18:54:27,769 [run_pretraining.py:  512]:	********exe.run_1147******* 
[INFO] 2021-07-12 18:54:28,680 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:28,680 [run_pretraining.py:  534]:	loss/total_loss, 7.759554862976074, 1148
[INFO] 2021-07-12 18:54:28,680 [run_pretraining.py:  535]:	loss/mlm_loss, 7.759554862976074, 1148
[INFO] 2021-07-12 18:54:28,680 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1469999662949704e-05, 1148
[INFO] 2021-07-12 18:54:28,680 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1148
[INFO] 2021-07-12 18:54:28,680 [run_pretraining.py:  558]:	worker_index: 3, step: 1148, cost: 7.759555, mlm loss: 7.759555, speed: 1.098209 steps/s, speed: 8.785672 samples/s, speed: 4498.264093 tokens/s, learning rate: 1.147e-05, loss_scalings: 13421.773438, pp_loss: 7.645175
[INFO] 2021-07-12 18:54:28,680 [run_pretraining.py:  512]:	********exe.run_1148******* 
[INFO] 2021-07-12 18:54:29,590 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:29,590 [run_pretraining.py:  534]:	loss/total_loss, 7.859375, 1149
[INFO] 2021-07-12 18:54:29,590 [run_pretraining.py:  535]:	loss/mlm_loss, 7.859375, 1149
[INFO] 2021-07-12 18:54:29,590 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1479999557195697e-05, 1149
[INFO] 2021-07-12 18:54:29,590 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1149
[INFO] 2021-07-12 18:54:29,590 [run_pretraining.py:  558]:	worker_index: 3, step: 1149, cost: 7.859375, mlm loss: 7.859375, speed: 1.099595 steps/s, speed: 8.796760 samples/s, speed: 4503.941158 tokens/s, learning rate: 1.148e-05, loss_scalings: 13421.773438, pp_loss: 7.766315
[INFO] 2021-07-12 18:54:29,591 [run_pretraining.py:  512]:	********exe.run_1149******* 
[INFO] 2021-07-12 18:54:30,506 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:30,507 [run_pretraining.py:  534]:	loss/total_loss, 7.633089542388916, 1150
[INFO] 2021-07-12 18:54:30,507 [run_pretraining.py:  535]:	loss/mlm_loss, 7.633089542388916, 1150
[INFO] 2021-07-12 18:54:30,507 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.148999945144169e-05, 1150
[INFO] 2021-07-12 18:54:30,507 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1150
[INFO] 2021-07-12 18:54:30,507 [run_pretraining.py:  558]:	worker_index: 3, step: 1150, cost: 7.633090, mlm loss: 7.633090, speed: 1.091887 steps/s, speed: 8.735099 samples/s, speed: 4472.370584 tokens/s, learning rate: 1.149e-05, loss_scalings: 13421.773438, pp_loss: 7.887088
[INFO] 2021-07-12 18:54:30,507 [run_pretraining.py:  512]:	********exe.run_1150******* 
[INFO] 2021-07-12 18:54:31,422 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:31,423 [run_pretraining.py:  534]:	loss/total_loss, 6.931173324584961, 1151
[INFO] 2021-07-12 18:54:31,423 [run_pretraining.py:  535]:	loss/mlm_loss, 6.931173324584961, 1151
[INFO] 2021-07-12 18:54:31,423 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1500000255182385e-05, 1151
[INFO] 2021-07-12 18:54:31,423 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1151
[INFO] 2021-07-12 18:54:31,423 [run_pretraining.py:  558]:	worker_index: 3, step: 1151, cost: 6.931173, mlm loss: 6.931173, speed: 1.092358 steps/s, speed: 8.738866 samples/s, speed: 4474.299455 tokens/s, learning rate: 1.150e-05, loss_scalings: 13421.773438, pp_loss: 7.689507
[INFO] 2021-07-12 18:54:31,423 [run_pretraining.py:  512]:	********exe.run_1151******* 
[INFO] 2021-07-12 18:54:32,333 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:32,334 [run_pretraining.py:  534]:	loss/total_loss, 7.6486711502075195, 1152
[INFO] 2021-07-12 18:54:32,334 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6486711502075195, 1152
[INFO] 2021-07-12 18:54:32,334 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1509999239933677e-05, 1152
[INFO] 2021-07-12 18:54:32,334 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1152
[INFO] 2021-07-12 18:54:32,334 [run_pretraining.py:  558]:	worker_index: 3, step: 1152, cost: 7.648671, mlm loss: 7.648671, speed: 1.098031 steps/s, speed: 8.784251 samples/s, speed: 4497.536332 tokens/s, learning rate: 1.151e-05, loss_scalings: 13421.773438, pp_loss: 7.869108
[INFO] 2021-07-12 18:54:32,334 [run_pretraining.py:  512]:	********exe.run_1152******* 
[INFO] 2021-07-12 18:54:33,248 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:33,249 [run_pretraining.py:  534]:	loss/total_loss, 7.598639488220215, 1153
[INFO] 2021-07-12 18:54:33,249 [run_pretraining.py:  535]:	loss/mlm_loss, 7.598639488220215, 1153
[INFO] 2021-07-12 18:54:33,249 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.151999913417967e-05, 1153
[INFO] 2021-07-12 18:54:33,249 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1153
[INFO] 2021-07-12 18:54:33,249 [run_pretraining.py:  558]:	worker_index: 3, step: 1153, cost: 7.598639, mlm loss: 7.598639, speed: 1.094218 steps/s, speed: 8.753742 samples/s, speed: 4481.915849 tokens/s, learning rate: 1.152e-05, loss_scalings: 13421.773438, pp_loss: 7.653251
[INFO] 2021-07-12 18:54:33,249 [run_pretraining.py:  512]:	********exe.run_1153******* 
[INFO] 2021-07-12 18:54:34,161 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:34,162 [run_pretraining.py:  534]:	loss/total_loss, 8.548934936523438, 1154
[INFO] 2021-07-12 18:54:34,162 [run_pretraining.py:  535]:	loss/mlm_loss, 8.548934936523438, 1154
[INFO] 2021-07-12 18:54:34,162 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1529999937920365e-05, 1154
[INFO] 2021-07-12 18:54:34,162 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1154
[INFO] 2021-07-12 18:54:34,162 [run_pretraining.py:  558]:	worker_index: 3, step: 1154, cost: 8.548935, mlm loss: 8.548935, speed: 1.096057 steps/s, speed: 8.768460 samples/s, speed: 4489.451455 tokens/s, learning rate: 1.153e-05, loss_scalings: 13421.773438, pp_loss: 8.004894
[INFO] 2021-07-12 18:54:34,162 [run_pretraining.py:  512]:	********exe.run_1154******* 
[INFO] 2021-07-12 18:54:35,085 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:35,085 [run_pretraining.py:  534]:	loss/total_loss, 8.238231658935547, 1155
[INFO] 2021-07-12 18:54:35,086 [run_pretraining.py:  535]:	loss/mlm_loss, 8.238231658935547, 1155
[INFO] 2021-07-12 18:54:35,086 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1539999832166359e-05, 1155
[INFO] 2021-07-12 18:54:35,086 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1155
[INFO] 2021-07-12 18:54:35,086 [run_pretraining.py:  558]:	worker_index: 3, step: 1155, cost: 8.238232, mlm loss: 8.238232, speed: 1.083232 steps/s, speed: 8.665857 samples/s, speed: 4436.918747 tokens/s, learning rate: 1.154e-05, loss_scalings: 13421.773438, pp_loss: 7.457946
[INFO] 2021-07-12 18:54:35,086 [run_pretraining.py:  512]:	********exe.run_1155******* 
[INFO] 2021-07-12 18:54:35,995 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:35,995 [run_pretraining.py:  534]:	loss/total_loss, 5.33493185043335, 1156
[INFO] 2021-07-12 18:54:35,995 [run_pretraining.py:  535]:	loss/mlm_loss, 5.33493185043335, 1156
[INFO] 2021-07-12 18:54:35,995 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1549999726412352e-05, 1156
[INFO] 2021-07-12 18:54:35,995 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1156
[INFO] 2021-07-12 18:54:35,995 [run_pretraining.py:  558]:	worker_index: 3, step: 1156, cost: 5.334932, mlm loss: 5.334932, speed: 1.100067 steps/s, speed: 8.800535 samples/s, speed: 4505.873728 tokens/s, learning rate: 1.155e-05, loss_scalings: 13421.773438, pp_loss: 7.450156
[INFO] 2021-07-12 18:54:35,996 [run_pretraining.py:  512]:	********exe.run_1156******* 
[INFO] 2021-07-12 18:54:36,902 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:36,903 [run_pretraining.py:  534]:	loss/total_loss, 8.0003662109375, 1157
[INFO] 2021-07-12 18:54:36,903 [run_pretraining.py:  535]:	loss/mlm_loss, 8.0003662109375, 1157
[INFO] 2021-07-12 18:54:36,903 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1559999620658346e-05, 1157
[INFO] 2021-07-12 18:54:36,903 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1157
[INFO] 2021-07-12 18:54:36,903 [run_pretraining.py:  558]:	worker_index: 3, step: 1157, cost: 8.000366, mlm loss: 8.000366, speed: 1.102202 steps/s, speed: 8.817616 samples/s, speed: 4514.619327 tokens/s, learning rate: 1.156e-05, loss_scalings: 13421.773438, pp_loss: 7.832963
[INFO] 2021-07-12 18:54:36,903 [run_pretraining.py:  512]:	********exe.run_1157******* 
[INFO] 2021-07-12 18:54:37,817 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:37,817 [run_pretraining.py:  534]:	loss/total_loss, 7.842677116394043, 1158
[INFO] 2021-07-12 18:54:37,818 [run_pretraining.py:  535]:	loss/mlm_loss, 7.842677116394043, 1158
[INFO] 2021-07-12 18:54:37,818 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1569999514904339e-05, 1158
[INFO] 2021-07-12 18:54:37,818 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1158
[INFO] 2021-07-12 18:54:37,818 [run_pretraining.py:  558]:	worker_index: 3, step: 1158, cost: 7.842677, mlm loss: 7.842677, speed: 1.094299 steps/s, speed: 8.754393 samples/s, speed: 4482.249111 tokens/s, learning rate: 1.157e-05, loss_scalings: 13421.773438, pp_loss: 7.757809
[INFO] 2021-07-12 18:54:37,818 [run_pretraining.py:  512]:	********exe.run_1158******* 
[INFO] 2021-07-12 18:54:38,732 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:38,733 [run_pretraining.py:  534]:	loss/total_loss, 7.883044242858887, 1159
[INFO] 2021-07-12 18:54:38,733 [run_pretraining.py:  535]:	loss/mlm_loss, 7.883044242858887, 1159
[INFO] 2021-07-12 18:54:38,733 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1579999409150332e-05, 1159
[INFO] 2021-07-12 18:54:38,733 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1159
[INFO] 2021-07-12 18:54:38,733 [run_pretraining.py:  558]:	worker_index: 3, step: 1159, cost: 7.883044, mlm loss: 7.883044, speed: 1.093124 steps/s, speed: 8.744993 samples/s, speed: 4477.436256 tokens/s, learning rate: 1.158e-05, loss_scalings: 13421.773438, pp_loss: 7.793128
[INFO] 2021-07-12 18:54:38,733 [run_pretraining.py:  512]:	********exe.run_1159******* 
[INFO] 2021-07-12 18:54:39,647 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:39,647 [run_pretraining.py:  534]:	loss/total_loss, 7.5696611404418945, 1160
[INFO] 2021-07-12 18:54:39,647 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5696611404418945, 1160
[INFO] 2021-07-12 18:54:39,648 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1590000212891027e-05, 1160
[INFO] 2021-07-12 18:54:39,648 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1160
[INFO] 2021-07-12 18:54:39,648 [run_pretraining.py:  558]:	worker_index: 3, step: 1160, cost: 7.569661, mlm loss: 7.569661, speed: 1.094380 steps/s, speed: 8.755039 samples/s, speed: 4482.580082 tokens/s, learning rate: 1.159e-05, loss_scalings: 13421.773438, pp_loss: 7.571293
[INFO] 2021-07-12 18:54:39,648 [run_pretraining.py:  512]:	********exe.run_1160******* 
[INFO] 2021-07-12 18:54:40,555 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:40,556 [run_pretraining.py:  534]:	loss/total_loss, 7.673999786376953, 1161
[INFO] 2021-07-12 18:54:40,556 [run_pretraining.py:  535]:	loss/mlm_loss, 7.673999786376953, 1161
[INFO] 2021-07-12 18:54:40,556 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1599999197642319e-05, 1161
[INFO] 2021-07-12 18:54:40,556 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1161
[INFO] 2021-07-12 18:54:40,556 [run_pretraining.py:  558]:	worker_index: 3, step: 1161, cost: 7.674000, mlm loss: 7.674000, speed: 1.101408 steps/s, speed: 8.811265 samples/s, speed: 4511.367442 tokens/s, learning rate: 1.160e-05, loss_scalings: 13421.773438, pp_loss: 7.826467
[INFO] 2021-07-12 18:54:40,556 [run_pretraining.py:  512]:	********exe.run_1161******* 
[INFO] 2021-07-12 18:54:41,471 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:41,472 [run_pretraining.py:  534]:	loss/total_loss, 7.912295341491699, 1162
[INFO] 2021-07-12 18:54:41,472 [run_pretraining.py:  535]:	loss/mlm_loss, 7.912295341491699, 1162
[INFO] 2021-07-12 18:54:41,472 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1609999091888312e-05, 1162
[INFO] 2021-07-12 18:54:41,472 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1162
[INFO] 2021-07-12 18:54:41,472 [run_pretraining.py:  558]:	worker_index: 3, step: 1162, cost: 7.912295, mlm loss: 7.912295, speed: 1.092786 steps/s, speed: 8.742286 samples/s, speed: 4476.050391 tokens/s, learning rate: 1.161e-05, loss_scalings: 13421.773438, pp_loss: 7.923228
[INFO] 2021-07-12 18:54:41,472 [run_pretraining.py:  512]:	********exe.run_1162******* 
[INFO] 2021-07-12 18:54:42,385 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:42,385 [run_pretraining.py:  534]:	loss/total_loss, 7.94400691986084, 1163
[INFO] 2021-07-12 18:54:42,385 [run_pretraining.py:  535]:	loss/mlm_loss, 7.94400691986084, 1163
[INFO] 2021-07-12 18:54:42,385 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1619999895629007e-05, 1163
[INFO] 2021-07-12 18:54:42,385 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1163
[INFO] 2021-07-12 18:54:42,385 [run_pretraining.py:  558]:	worker_index: 3, step: 1163, cost: 7.944007, mlm loss: 7.944007, speed: 1.095428 steps/s, speed: 8.763424 samples/s, speed: 4486.873102 tokens/s, learning rate: 1.162e-05, loss_scalings: 13421.773438, pp_loss: 7.598234
[INFO] 2021-07-12 18:54:42,386 [run_pretraining.py:  512]:	********exe.run_1163******* 
[INFO] 2021-07-12 18:54:43,297 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:43,298 [run_pretraining.py:  534]:	loss/total_loss, 7.056307792663574, 1164
[INFO] 2021-07-12 18:54:43,298 [run_pretraining.py:  535]:	loss/mlm_loss, 7.056307792663574, 1164
[INFO] 2021-07-12 18:54:43,298 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1629999789875e-05, 1164
[INFO] 2021-07-12 18:54:43,298 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1164
[INFO] 2021-07-12 18:54:43,298 [run_pretraining.py:  558]:	worker_index: 3, step: 1164, cost: 7.056308, mlm loss: 7.056308, speed: 1.096211 steps/s, speed: 8.769688 samples/s, speed: 4490.080371 tokens/s, learning rate: 1.163e-05, loss_scalings: 13421.773438, pp_loss: 7.503102
[INFO] 2021-07-12 18:54:43,298 [run_pretraining.py:  512]:	********exe.run_1164******* 
[INFO] 2021-07-12 18:54:44,214 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:44,215 [run_pretraining.py:  534]:	loss/total_loss, 7.447046279907227, 1165
[INFO] 2021-07-12 18:54:44,215 [run_pretraining.py:  535]:	loss/mlm_loss, 7.447046279907227, 1165
[INFO] 2021-07-12 18:54:44,215 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1639999684120994e-05, 1165
[INFO] 2021-07-12 18:54:44,215 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1165
[INFO] 2021-07-12 18:54:44,215 [run_pretraining.py:  558]:	worker_index: 3, step: 1165, cost: 7.447046, mlm loss: 7.447046, speed: 1.091507 steps/s, speed: 8.732055 samples/s, speed: 4470.812162 tokens/s, learning rate: 1.164e-05, loss_scalings: 13421.773438, pp_loss: 7.726823
[INFO] 2021-07-12 18:54:44,215 [run_pretraining.py:  512]:	********exe.run_1165******* 
[INFO] 2021-07-12 18:54:45,131 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:45,132 [run_pretraining.py:  534]:	loss/total_loss, 8.0975923538208, 1166
[INFO] 2021-07-12 18:54:45,132 [run_pretraining.py:  535]:	loss/mlm_loss, 8.0975923538208, 1166
[INFO] 2021-07-12 18:54:45,132 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1649999578366987e-05, 1166
[INFO] 2021-07-12 18:54:45,132 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1166
[INFO] 2021-07-12 18:54:45,132 [run_pretraining.py:  558]:	worker_index: 3, step: 1166, cost: 8.097592, mlm loss: 8.097592, speed: 1.091217 steps/s, speed: 8.729738 samples/s, speed: 4469.625744 tokens/s, learning rate: 1.165e-05, loss_scalings: 13421.773438, pp_loss: 7.768756
[INFO] 2021-07-12 18:54:45,132 [run_pretraining.py:  512]:	********exe.run_1166******* 
[INFO] 2021-07-12 18:54:46,039 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:46,039 [run_pretraining.py:  534]:	loss/total_loss, 5.636335849761963, 1167
[INFO] 2021-07-12 18:54:46,039 [run_pretraining.py:  535]:	loss/mlm_loss, 5.636335849761963, 1167
[INFO] 2021-07-12 18:54:46,040 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.165999947261298e-05, 1167
[INFO] 2021-07-12 18:54:46,040 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1167
[INFO] 2021-07-12 18:54:46,040 [run_pretraining.py:  558]:	worker_index: 3, step: 1167, cost: 5.636336, mlm loss: 5.636336, speed: 1.102684 steps/s, speed: 8.821469 samples/s, speed: 4516.591946 tokens/s, learning rate: 1.166e-05, loss_scalings: 13421.773438, pp_loss: 7.220157
[INFO] 2021-07-12 18:54:46,040 [run_pretraining.py:  512]:	********exe.run_1167******* 
[INFO] 2021-07-12 18:54:46,952 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:46,952 [run_pretraining.py:  534]:	loss/total_loss, 8.290822982788086, 1168
[INFO] 2021-07-12 18:54:46,952 [run_pretraining.py:  535]:	loss/mlm_loss, 8.290822982788086, 1168
[INFO] 2021-07-12 18:54:46,953 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1669999366858974e-05, 1168
[INFO] 2021-07-12 18:54:46,953 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1168
[INFO] 2021-07-12 18:54:46,953 [run_pretraining.py:  558]:	worker_index: 3, step: 1168, cost: 8.290823, mlm loss: 8.290823, speed: 1.096043 steps/s, speed: 8.768343 samples/s, speed: 4489.391624 tokens/s, learning rate: 1.167e-05, loss_scalings: 13421.773438, pp_loss: 7.885715
[INFO] 2021-07-12 18:54:46,953 [run_pretraining.py:  512]:	********exe.run_1168******* 
[INFO] 2021-07-12 18:54:47,873 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:47,873 [run_pretraining.py:  534]:	loss/total_loss, 7.8175506591796875, 1169
[INFO] 2021-07-12 18:54:47,873 [run_pretraining.py:  535]:	loss/mlm_loss, 7.8175506591796875, 1169
[INFO] 2021-07-12 18:54:47,873 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.168000017059967e-05, 1169
[INFO] 2021-07-12 18:54:47,873 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1169
[INFO] 2021-07-12 18:54:47,873 [run_pretraining.py:  558]:	worker_index: 3, step: 1169, cost: 7.817551, mlm loss: 7.817551, speed: 1.086843 steps/s, speed: 8.694748 samples/s, speed: 4451.710925 tokens/s, learning rate: 1.168e-05, loss_scalings: 13421.773438, pp_loss: 7.887420
[INFO] 2021-07-12 18:54:47,874 [run_pretraining.py:  512]:	********exe.run_1169******* 
[INFO] 2021-07-12 18:54:48,784 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:48,785 [run_pretraining.py:  534]:	loss/total_loss, 8.371814727783203, 1170
[INFO] 2021-07-12 18:54:48,785 [run_pretraining.py:  535]:	loss/mlm_loss, 8.371814727783203, 1170
[INFO] 2021-07-12 18:54:48,785 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.168999915535096e-05, 1170
[INFO] 2021-07-12 18:54:48,785 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1170
[INFO] 2021-07-12 18:54:48,785 [run_pretraining.py:  558]:	worker_index: 3, step: 1170, cost: 8.371815, mlm loss: 8.371815, speed: 1.097852 steps/s, speed: 8.782818 samples/s, speed: 4496.802923 tokens/s, learning rate: 1.169e-05, loss_scalings: 13421.773438, pp_loss: 8.035973
[INFO] 2021-07-12 18:54:48,785 [run_pretraining.py:  512]:	********exe.run_1170******* 
[INFO] 2021-07-12 18:54:49,698 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:49,698 [run_pretraining.py:  534]:	loss/total_loss, 8.691229820251465, 1171
[INFO] 2021-07-12 18:54:49,699 [run_pretraining.py:  535]:	loss/mlm_loss, 8.691229820251465, 1171
[INFO] 2021-07-12 18:54:49,699 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1699999959091656e-05, 1171
[INFO] 2021-07-12 18:54:49,699 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1171
[INFO] 2021-07-12 18:54:49,699 [run_pretraining.py:  558]:	worker_index: 3, step: 1171, cost: 8.691230, mlm loss: 8.691230, speed: 1.095052 steps/s, speed: 8.760415 samples/s, speed: 4485.332664 tokens/s, learning rate: 1.170e-05, loss_scalings: 13421.773438, pp_loss: 8.116351
[INFO] 2021-07-12 18:54:49,699 [run_pretraining.py:  512]:	********exe.run_1171******* 
[INFO] 2021-07-12 18:54:50,615 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:50,616 [run_pretraining.py:  534]:	loss/total_loss, 4.086514949798584, 1172
[INFO] 2021-07-12 18:54:50,616 [run_pretraining.py:  535]:	loss/mlm_loss, 4.086514949798584, 1172
[INFO] 2021-07-12 18:54:50,616 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.170999985333765e-05, 1172
[INFO] 2021-07-12 18:54:50,616 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1172
[INFO] 2021-07-12 18:54:50,616 [run_pretraining.py:  558]:	worker_index: 3, step: 1172, cost: 4.086515, mlm loss: 4.086515, speed: 1.091205 steps/s, speed: 8.729640 samples/s, speed: 4469.575742 tokens/s, learning rate: 1.171e-05, loss_scalings: 13421.773438, pp_loss: 6.941601
[INFO] 2021-07-12 18:54:50,616 [run_pretraining.py:  512]:	********exe.run_1172******* 
[INFO] 2021-07-12 18:54:51,527 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:51,528 [run_pretraining.py:  534]:	loss/total_loss, 7.55381965637207, 1173
[INFO] 2021-07-12 18:54:51,528 [run_pretraining.py:  535]:	loss/mlm_loss, 7.55381965637207, 1173
[INFO] 2021-07-12 18:54:51,528 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1719999747583643e-05, 1173
[INFO] 2021-07-12 18:54:51,528 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1173
[INFO] 2021-07-12 18:54:51,528 [run_pretraining.py:  558]:	worker_index: 3, step: 1173, cost: 7.553820, mlm loss: 7.553820, speed: 1.097059 steps/s, speed: 8.776473 samples/s, speed: 4493.554312 tokens/s, learning rate: 1.172e-05, loss_scalings: 13421.773438, pp_loss: 7.760106
[INFO] 2021-07-12 18:54:51,528 [run_pretraining.py:  512]:	********exe.run_1173******* 
[INFO] 2021-07-12 18:54:52,438 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:52,438 [run_pretraining.py:  534]:	loss/total_loss, 7.547410011291504, 1174
[INFO] 2021-07-12 18:54:52,439 [run_pretraining.py:  535]:	loss/mlm_loss, 7.547410011291504, 1174
[INFO] 2021-07-12 18:54:52,439 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1729999641829636e-05, 1174
[INFO] 2021-07-12 18:54:52,439 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1174
[INFO] 2021-07-12 18:54:52,439 [run_pretraining.py:  558]:	worker_index: 3, step: 1174, cost: 7.547410, mlm loss: 7.547410, speed: 1.098790 steps/s, speed: 8.790317 samples/s, speed: 4500.642141 tokens/s, learning rate: 1.173e-05, loss_scalings: 13421.773438, pp_loss: 7.628731
[INFO] 2021-07-12 18:54:52,439 [run_pretraining.py:  512]:	********exe.run_1174******* 
[INFO] 2021-07-12 18:54:53,351 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:53,351 [run_pretraining.py:  534]:	loss/total_loss, 8.039447784423828, 1175
[INFO] 2021-07-12 18:54:53,351 [run_pretraining.py:  535]:	loss/mlm_loss, 8.039447784423828, 1175
[INFO] 2021-07-12 18:54:53,352 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.173999953607563e-05, 1175
[INFO] 2021-07-12 18:54:53,352 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1175
[INFO] 2021-07-12 18:54:53,352 [run_pretraining.py:  558]:	worker_index: 3, step: 1175, cost: 8.039448, mlm loss: 8.039448, speed: 1.096079 steps/s, speed: 8.768634 samples/s, speed: 4489.540619 tokens/s, learning rate: 1.174e-05, loss_scalings: 13421.773438, pp_loss: 7.631814
[INFO] 2021-07-12 18:54:53,352 [run_pretraining.py:  512]:	********exe.run_1175******* 
[INFO] 2021-07-12 18:54:54,274 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:54,275 [run_pretraining.py:  534]:	loss/total_loss, 6.748668193817139, 1176
[INFO] 2021-07-12 18:54:54,275 [run_pretraining.py:  535]:	loss/mlm_loss, 6.748668193817139, 1176
[INFO] 2021-07-12 18:54:54,275 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1749999430321623e-05, 1176
[INFO] 2021-07-12 18:54:54,275 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1176
[INFO] 2021-07-12 18:54:54,275 [run_pretraining.py:  558]:	worker_index: 3, step: 1176, cost: 6.748668, mlm loss: 6.748668, speed: 1.083944 steps/s, speed: 8.671552 samples/s, speed: 4439.834661 tokens/s, learning rate: 1.175e-05, loss_scalings: 13421.773438, pp_loss: 7.394239
[INFO] 2021-07-12 18:54:54,275 [run_pretraining.py:  512]:	********exe.run_1176******* 
[INFO] 2021-07-12 18:54:55,185 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:55,186 [run_pretraining.py:  534]:	loss/total_loss, 7.633376121520996, 1177
[INFO] 2021-07-12 18:54:55,186 [run_pretraining.py:  535]:	loss/mlm_loss, 7.633376121520996, 1177
[INFO] 2021-07-12 18:54:55,186 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1760000234062318e-05, 1177
[INFO] 2021-07-12 18:54:55,186 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1177
[INFO] 2021-07-12 18:54:55,186 [run_pretraining.py:  558]:	worker_index: 3, step: 1177, cost: 7.633376, mlm loss: 7.633376, speed: 1.098449 steps/s, speed: 8.787589 samples/s, speed: 4499.245411 tokens/s, learning rate: 1.176e-05, loss_scalings: 13421.773438, pp_loss: 7.727973
[INFO] 2021-07-12 18:54:55,186 [run_pretraining.py:  512]:	********exe.run_1177******* 
[INFO] 2021-07-12 18:54:56,103 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:56,103 [run_pretraining.py:  534]:	loss/total_loss, 8.20850944519043, 1178
[INFO] 2021-07-12 18:54:56,104 [run_pretraining.py:  535]:	loss/mlm_loss, 8.20850944519043, 1178
[INFO] 2021-07-12 18:54:56,104 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1770000128308311e-05, 1178
[INFO] 2021-07-12 18:54:56,104 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1178
[INFO] 2021-07-12 18:54:56,104 [run_pretraining.py:  558]:	worker_index: 3, step: 1178, cost: 8.208509, mlm loss: 8.208509, speed: 1.090284 steps/s, speed: 8.722274 samples/s, speed: 4465.804411 tokens/s, learning rate: 1.177e-05, loss_scalings: 13421.773438, pp_loss: 7.698370
[INFO] 2021-07-12 18:54:56,104 [run_pretraining.py:  512]:	********exe.run_1178******* 
[INFO] 2021-07-12 18:54:57,016 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:57,016 [run_pretraining.py:  534]:	loss/total_loss, 7.125442028045654, 1179
[INFO] 2021-07-12 18:54:57,017 [run_pretraining.py:  535]:	loss/mlm_loss, 7.125442028045654, 1179
[INFO] 2021-07-12 18:54:57,017 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1779999113059603e-05, 1179
[INFO] 2021-07-12 18:54:57,017 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1179
[INFO] 2021-07-12 18:54:57,017 [run_pretraining.py:  558]:	worker_index: 3, step: 1179, cost: 7.125442, mlm loss: 7.125442, speed: 1.096015 steps/s, speed: 8.768118 samples/s, speed: 4489.276658 tokens/s, learning rate: 1.178e-05, loss_scalings: 13421.773438, pp_loss: 7.547508
[INFO] 2021-07-12 18:54:57,017 [run_pretraining.py:  512]:	********exe.run_1179******* 
[INFO] 2021-07-12 18:54:57,948 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:57,949 [run_pretraining.py:  534]:	loss/total_loss, 7.459232330322266, 1180
[INFO] 2021-07-12 18:54:57,949 [run_pretraining.py:  535]:	loss/mlm_loss, 7.459232330322266, 1180
[INFO] 2021-07-12 18:54:57,949 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1789999916800298e-05, 1180
[INFO] 2021-07-12 18:54:57,949 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1180
[INFO] 2021-07-12 18:54:57,949 [run_pretraining.py:  558]:	worker_index: 3, step: 1180, cost: 7.459232, mlm loss: 7.459232, speed: 1.073563 steps/s, speed: 8.588501 samples/s, speed: 4397.312547 tokens/s, learning rate: 1.179e-05, loss_scalings: 13421.773438, pp_loss: 7.663208
[INFO] 2021-07-12 18:54:57,949 [run_pretraining.py:  512]:	********exe.run_1180******* 
[INFO] 2021-07-12 18:54:58,875 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:58,876 [run_pretraining.py:  534]:	loss/total_loss, 7.867038249969482, 1181
[INFO] 2021-07-12 18:54:58,876 [run_pretraining.py:  535]:	loss/mlm_loss, 7.867038249969482, 1181
[INFO] 2021-07-12 18:54:58,876 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1799999811046291e-05, 1181
[INFO] 2021-07-12 18:54:58,876 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1181
[INFO] 2021-07-12 18:54:58,876 [run_pretraining.py:  558]:	worker_index: 3, step: 1181, cost: 7.867038, mlm loss: 7.867038, speed: 1.079332 steps/s, speed: 8.634657 samples/s, speed: 4420.944315 tokens/s, learning rate: 1.180e-05, loss_scalings: 13421.773438, pp_loss: 7.759648
[INFO] 2021-07-12 18:54:58,876 [run_pretraining.py:  512]:	********exe.run_1181******* 
[INFO] 2021-07-12 18:54:59,809 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:59,809 [run_pretraining.py:  534]:	loss/total_loss, 7.526504039764404, 1182
[INFO] 2021-07-12 18:54:59,809 [run_pretraining.py:  535]:	loss/mlm_loss, 7.526504039764404, 1182
[INFO] 2021-07-12 18:54:59,809 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1809999705292284e-05, 1182
[INFO] 2021-07-12 18:54:59,809 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1182
[INFO] 2021-07-12 18:54:59,809 [run_pretraining.py:  558]:	worker_index: 3, step: 1182, cost: 7.526504, mlm loss: 7.526504, speed: 1.072058 steps/s, speed: 8.576460 samples/s, speed: 4391.147702 tokens/s, learning rate: 1.181e-05, loss_scalings: 13421.773438, pp_loss: 7.515135
[INFO] 2021-07-12 18:54:59,810 [run_pretraining.py:  512]:	********exe.run_1182******* 
[INFO] 2021-07-12 18:55:00,733 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:00,734 [run_pretraining.py:  534]:	loss/total_loss, 7.209615707397461, 1183
[INFO] 2021-07-12 18:55:00,734 [run_pretraining.py:  535]:	loss/mlm_loss, 7.209615707397461, 1183
[INFO] 2021-07-12 18:55:00,734 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1819999599538278e-05, 1183
[INFO] 2021-07-12 18:55:00,734 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1183
[INFO] 2021-07-12 18:55:00,734 [run_pretraining.py:  558]:	worker_index: 3, step: 1183, cost: 7.209616, mlm loss: 7.209616, speed: 1.082505 steps/s, speed: 8.660042 samples/s, speed: 4433.941431 tokens/s, learning rate: 1.182e-05, loss_scalings: 13421.773438, pp_loss: 7.562462
[INFO] 2021-07-12 18:55:00,734 [run_pretraining.py:  512]:	********exe.run_1183******* 
[INFO] 2021-07-12 18:55:01,656 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:01,656 [run_pretraining.py:  534]:	loss/total_loss, 7.777228355407715, 1184
[INFO] 2021-07-12 18:55:01,656 [run_pretraining.py:  535]:	loss/mlm_loss, 7.777228355407715, 1184
[INFO] 2021-07-12 18:55:01,657 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1829999493784271e-05, 1184
[INFO] 2021-07-12 18:55:01,657 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1184
[INFO] 2021-07-12 18:55:01,657 [run_pretraining.py:  558]:	worker_index: 3, step: 1184, cost: 7.777228, mlm loss: 7.777228, speed: 1.084413 steps/s, speed: 8.675301 samples/s, speed: 4441.753938 tokens/s, learning rate: 1.183e-05, loss_scalings: 13421.773438, pp_loss: 7.706731
[INFO] 2021-07-12 18:55:01,657 [run_pretraining.py:  512]:	********exe.run_1184******* 
[INFO] 2021-07-12 18:55:02,580 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:02,580 [run_pretraining.py:  534]:	loss/total_loss, 8.176931381225586, 1185
[INFO] 2021-07-12 18:55:02,580 [run_pretraining.py:  535]:	loss/mlm_loss, 8.176931381225586, 1185
[INFO] 2021-07-12 18:55:02,580 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1839999388030265e-05, 1185
[INFO] 2021-07-12 18:55:02,580 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1185
[INFO] 2021-07-12 18:55:02,580 [run_pretraining.py:  558]:	worker_index: 3, step: 1185, cost: 8.176931, mlm loss: 8.176931, speed: 1.083344 steps/s, speed: 8.666752 samples/s, speed: 4437.377150 tokens/s, learning rate: 1.184e-05, loss_scalings: 13421.773438, pp_loss: 7.938314
[INFO] 2021-07-12 18:55:02,580 [run_pretraining.py:  512]:	********exe.run_1185******* 
[INFO] 2021-07-12 18:55:03,501 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:03,502 [run_pretraining.py:  534]:	loss/total_loss, 8.408458709716797, 1186
[INFO] 2021-07-12 18:55:03,502 [run_pretraining.py:  535]:	loss/mlm_loss, 8.408458709716797, 1186
[INFO] 2021-07-12 18:55:03,502 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.185000019177096e-05, 1186
[INFO] 2021-07-12 18:55:03,502 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1186
[INFO] 2021-07-12 18:55:03,502 [run_pretraining.py:  558]:	worker_index: 3, step: 1186, cost: 8.408459, mlm loss: 8.408459, speed: 1.085686 steps/s, speed: 8.685489 samples/s, speed: 4446.970300 tokens/s, learning rate: 1.185e-05, loss_scalings: 13421.773438, pp_loss: 7.889829
[INFO] 2021-07-12 18:55:03,502 [run_pretraining.py:  512]:	********exe.run_1186******* 
[INFO] 2021-07-12 18:55:04,421 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:04,421 [run_pretraining.py:  534]:	loss/total_loss, 5.0015788078308105, 1187
[INFO] 2021-07-12 18:55:04,421 [run_pretraining.py:  535]:	loss/mlm_loss, 5.0015788078308105, 1187
[INFO] 2021-07-12 18:55:04,421 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1860000086016953e-05, 1187
[INFO] 2021-07-12 18:55:04,421 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1187
[INFO] 2021-07-12 18:55:04,421 [run_pretraining.py:  558]:	worker_index: 3, step: 1187, cost: 5.001579, mlm loss: 5.001579, speed: 1.088467 steps/s, speed: 8.707736 samples/s, speed: 4458.360641 tokens/s, learning rate: 1.186e-05, loss_scalings: 13421.773438, pp_loss: 7.161874
[INFO] 2021-07-12 18:55:04,421 [run_pretraining.py:  512]:	********exe.run_1187******* 
[INFO] 2021-07-12 18:55:05,344 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:05,345 [run_pretraining.py:  534]:	loss/total_loss, 7.801253795623779, 1188
[INFO] 2021-07-12 18:55:05,345 [run_pretraining.py:  535]:	loss/mlm_loss, 7.801253795623779, 1188
[INFO] 2021-07-12 18:55:05,345 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1869999070768245e-05, 1188
[INFO] 2021-07-12 18:55:05,345 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1188
[INFO] 2021-07-12 18:55:05,345 [run_pretraining.py:  558]:	worker_index: 3, step: 1188, cost: 7.801254, mlm loss: 7.801254, speed: 1.083527 steps/s, speed: 8.668214 samples/s, speed: 4438.125698 tokens/s, learning rate: 1.187e-05, loss_scalings: 13421.773438, pp_loss: 7.688762
[INFO] 2021-07-12 18:55:05,345 [run_pretraining.py:  512]:	********exe.run_1188******* 
[INFO] 2021-07-12 18:55:06,276 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:06,276 [run_pretraining.py:  534]:	loss/total_loss, 7.578779220581055, 1189
[INFO] 2021-07-12 18:55:06,276 [run_pretraining.py:  535]:	loss/mlm_loss, 7.578779220581055, 1189
[INFO] 2021-07-12 18:55:06,276 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.187999987450894e-05, 1189
[INFO] 2021-07-12 18:55:06,276 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1189
[INFO] 2021-07-12 18:55:06,276 [run_pretraining.py:  558]:	worker_index: 3, step: 1189, cost: 7.578779, mlm loss: 7.578779, speed: 1.074279 steps/s, speed: 8.594229 samples/s, speed: 4400.245367 tokens/s, learning rate: 1.188e-05, loss_scalings: 13421.773438, pp_loss: 7.425869
[INFO] 2021-07-12 18:55:06,277 [run_pretraining.py:  512]:	********exe.run_1189******* 
[INFO] 2021-07-12 18:55:07,193 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:07,193 [run_pretraining.py:  534]:	loss/total_loss, 7.765279769897461, 1190
[INFO] 2021-07-12 18:55:07,194 [run_pretraining.py:  535]:	loss/mlm_loss, 7.765279769897461, 1190
[INFO] 2021-07-12 18:55:07,194 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1889999768754933e-05, 1190
[INFO] 2021-07-12 18:55:07,194 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1190
[INFO] 2021-07-12 18:55:07,194 [run_pretraining.py:  558]:	worker_index: 3, step: 1190, cost: 7.765280, mlm loss: 7.765280, speed: 1.090831 steps/s, speed: 8.726648 samples/s, speed: 4468.043670 tokens/s, learning rate: 1.189e-05, loss_scalings: 13421.773438, pp_loss: 7.980339
[INFO] 2021-07-12 18:55:07,194 [run_pretraining.py:  512]:	********exe.run_1190******* 
[INFO] 2021-07-12 18:55:08,108 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:08,109 [run_pretraining.py:  534]:	loss/total_loss, 6.839599132537842, 1191
[INFO] 2021-07-12 18:55:08,109 [run_pretraining.py:  535]:	loss/mlm_loss, 6.839599132537842, 1191
[INFO] 2021-07-12 18:55:08,109 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1899999663000926e-05, 1191
[INFO] 2021-07-12 18:55:08,109 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1191
[INFO] 2021-07-12 18:55:08,109 [run_pretraining.py:  558]:	worker_index: 3, step: 1191, cost: 6.839599, mlm loss: 6.839599, speed: 1.093490 steps/s, speed: 8.747918 samples/s, speed: 4478.933908 tokens/s, learning rate: 1.190e-05, loss_scalings: 13421.773438, pp_loss: 7.403458
[INFO] 2021-07-12 18:55:08,109 [run_pretraining.py:  512]:	********exe.run_1191******* 
[INFO] 2021-07-12 18:55:09,028 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:09,029 [run_pretraining.py:  534]:	loss/total_loss, 7.578002452850342, 1192
[INFO] 2021-07-12 18:55:09,029 [run_pretraining.py:  535]:	loss/mlm_loss, 7.578002452850342, 1192
[INFO] 2021-07-12 18:55:09,029 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.190999955724692e-05, 1192
[INFO] 2021-07-12 18:55:09,029 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1192
[INFO] 2021-07-12 18:55:09,029 [run_pretraining.py:  558]:	worker_index: 3, step: 1192, cost: 7.578002, mlm loss: 7.578002, speed: 1.087395 steps/s, speed: 8.699162 samples/s, speed: 4453.970710 tokens/s, learning rate: 1.191e-05, loss_scalings: 13421.773438, pp_loss: 7.763677
[INFO] 2021-07-12 18:55:09,029 [run_pretraining.py:  512]:	********exe.run_1192******* 
[INFO] 2021-07-12 18:55:09,957 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:09,958 [run_pretraining.py:  534]:	loss/total_loss, 7.881204605102539, 1193
[INFO] 2021-07-12 18:55:09,958 [run_pretraining.py:  535]:	loss/mlm_loss, 7.881204605102539, 1193
[INFO] 2021-07-12 18:55:09,958 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1919999451492913e-05, 1193
[INFO] 2021-07-12 18:55:09,958 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1193
[INFO] 2021-07-12 18:55:09,958 [run_pretraining.py:  558]:	worker_index: 3, step: 1193, cost: 7.881205, mlm loss: 7.881205, speed: 1.077537 steps/s, speed: 8.620298 samples/s, speed: 4413.592526 tokens/s, learning rate: 1.192e-05, loss_scalings: 13421.773438, pp_loss: 7.579537
[INFO] 2021-07-12 18:55:09,958 [run_pretraining.py:  512]:	********exe.run_1193******* 
[INFO] 2021-07-12 18:55:10,874 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:10,875 [run_pretraining.py:  534]:	loss/total_loss, 8.419572830200195, 1194
[INFO] 2021-07-12 18:55:10,875 [run_pretraining.py:  535]:	loss/mlm_loss, 8.419572830200195, 1194
[INFO] 2021-07-12 18:55:10,875 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1929999345738906e-05, 1194
[INFO] 2021-07-12 18:55:10,875 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1194
[INFO] 2021-07-12 18:55:10,875 [run_pretraining.py:  558]:	worker_index: 3, step: 1194, cost: 8.419573, mlm loss: 8.419573, speed: 1.090732 steps/s, speed: 8.725858 samples/s, speed: 4467.639322 tokens/s, learning rate: 1.193e-05, loss_scalings: 13421.773438, pp_loss: 8.019344
[INFO] 2021-07-12 18:55:10,875 [run_pretraining.py:  512]:	********exe.run_1194******* 
[INFO] 2021-07-12 18:55:11,793 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:11,793 [run_pretraining.py:  534]:	loss/total_loss, 7.9333391189575195, 1195
[INFO] 2021-07-12 18:55:11,794 [run_pretraining.py:  535]:	loss/mlm_loss, 7.9333391189575195, 1195
[INFO] 2021-07-12 18:55:11,794 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1940000149479602e-05, 1195
[INFO] 2021-07-12 18:55:11,794 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1195
[INFO] 2021-07-12 18:55:11,794 [run_pretraining.py:  558]:	worker_index: 3, step: 1195, cost: 7.933339, mlm loss: 7.933339, speed: 1.089471 steps/s, speed: 8.715772 samples/s, speed: 4462.475229 tokens/s, learning rate: 1.194e-05, loss_scalings: 13421.773438, pp_loss: 7.644952
[INFO] 2021-07-12 18:55:11,794 [run_pretraining.py:  512]:	********exe.run_1195******* 
[INFO] 2021-07-12 18:55:12,708 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:12,709 [run_pretraining.py:  534]:	loss/total_loss, 7.243587493896484, 1196
[INFO] 2021-07-12 18:55:12,709 [run_pretraining.py:  535]:	loss/mlm_loss, 7.243587493896484, 1196
[INFO] 2021-07-12 18:55:12,709 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1949999134230893e-05, 1196
[INFO] 2021-07-12 18:55:12,709 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1196
[INFO] 2021-07-12 18:55:12,709 [run_pretraining.py:  558]:	worker_index: 3, step: 1196, cost: 7.243587, mlm loss: 7.243587, speed: 1.093520 steps/s, speed: 8.748160 samples/s, speed: 4479.057687 tokens/s, learning rate: 1.195e-05, loss_scalings: 13421.773438, pp_loss: 7.643297
[INFO] 2021-07-12 18:55:12,709 [run_pretraining.py:  512]:	********exe.run_1196******* 
[INFO] 2021-07-12 18:55:13,624 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:13,625 [run_pretraining.py:  534]:	loss/total_loss, 7.829778671264648, 1197
[INFO] 2021-07-12 18:55:13,625 [run_pretraining.py:  535]:	loss/mlm_loss, 7.829778671264648, 1197
[INFO] 2021-07-12 18:55:13,625 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1959999937971588e-05, 1197
[INFO] 2021-07-12 18:55:13,625 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1197
[INFO] 2021-07-12 18:55:13,625 [run_pretraining.py:  558]:	worker_index: 3, step: 1197, cost: 7.829779, mlm loss: 7.829779, speed: 1.091971 steps/s, speed: 8.735767 samples/s, speed: 4472.712907 tokens/s, learning rate: 1.196e-05, loss_scalings: 13421.773438, pp_loss: 7.515757
[INFO] 2021-07-12 18:55:13,625 [run_pretraining.py:  512]:	********exe.run_1197******* 
[INFO] 2021-07-12 18:55:14,536 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:14,537 [run_pretraining.py:  534]:	loss/total_loss, 7.541121482849121, 1198
[INFO] 2021-07-12 18:55:14,537 [run_pretraining.py:  535]:	loss/mlm_loss, 7.541121482849121, 1198
[INFO] 2021-07-12 18:55:14,537 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1969999832217582e-05, 1198
[INFO] 2021-07-12 18:55:14,537 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1198
[INFO] 2021-07-12 18:55:14,537 [run_pretraining.py:  558]:	worker_index: 3, step: 1198, cost: 7.541121, mlm loss: 7.541121, speed: 1.097655 steps/s, speed: 8.781239 samples/s, speed: 4495.994448 tokens/s, learning rate: 1.197e-05, loss_scalings: 13421.773438, pp_loss: 7.601630
[INFO] 2021-07-12 18:55:14,537 [run_pretraining.py:  512]:	********exe.run_1198******* 
[INFO] 2021-07-12 18:55:15,505 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:15,506 [run_pretraining.py:  534]:	loss/total_loss, 8.020541191101074, 1199
[INFO] 2021-07-12 18:55:15,506 [run_pretraining.py:  535]:	loss/mlm_loss, 8.020541191101074, 1199
[INFO] 2021-07-12 18:55:15,506 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1979999726463575e-05, 1199
[INFO] 2021-07-12 18:55:15,506 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1199
[INFO] 2021-07-12 18:55:15,506 [run_pretraining.py:  558]:	worker_index: 3, step: 1199, cost: 8.020541, mlm loss: 8.020541, speed: 1.032596 steps/s, speed: 8.260766 samples/s, speed: 4229.512419 tokens/s, learning rate: 1.198e-05, loss_scalings: 13421.773438, pp_loss: 7.880858
[INFO] 2021-07-12 18:55:15,506 [run_pretraining.py:  512]:	********exe.run_1199******* 
[INFO] 2021-07-12 18:55:16,418 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:16,419 [run_pretraining.py:  534]:	loss/total_loss, 8.059603691101074, 1200
[INFO] 2021-07-12 18:55:16,419 [run_pretraining.py:  535]:	loss/mlm_loss, 8.059603691101074, 1200
[INFO] 2021-07-12 18:55:16,419 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1989999620709568e-05, 1200
[INFO] 2021-07-12 18:55:16,419 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1200
[INFO] 2021-07-12 18:55:16,419 [run_pretraining.py:  558]:	worker_index: 3, step: 1200, cost: 8.059604, mlm loss: 8.059604, speed: 1.096137 steps/s, speed: 8.769092 samples/s, speed: 4489.775278 tokens/s, learning rate: 1.199e-05, loss_scalings: 13421.773438, pp_loss: 7.038842
[INFO] 2021-07-12 18:55:16,419 [run_pretraining.py:  512]:	********exe.run_1200******* 
[INFO] 2021-07-12 18:55:17,326 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:17,327 [run_pretraining.py:  534]:	loss/total_loss, 7.285632133483887, 1201
[INFO] 2021-07-12 18:55:17,327 [run_pretraining.py:  535]:	loss/mlm_loss, 7.285632133483887, 1201
[INFO] 2021-07-12 18:55:17,327 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1999999514955562e-05, 1201
[INFO] 2021-07-12 18:55:17,327 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1201
[INFO] 2021-07-12 18:55:17,327 [run_pretraining.py:  558]:	worker_index: 3, step: 1201, cost: 7.285632, mlm loss: 7.285632, speed: 1.101725 steps/s, speed: 8.813797 samples/s, speed: 4512.663840 tokens/s, learning rate: 1.200e-05, loss_scalings: 13421.773438, pp_loss: 7.687799
[INFO] 2021-07-12 18:55:17,327 [run_pretraining.py:  512]:	********exe.run_1201******* 
[INFO] 2021-07-12 18:55:18,234 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:18,235 [run_pretraining.py:  534]:	loss/total_loss, 8.186426162719727, 1202
[INFO] 2021-07-12 18:55:18,235 [run_pretraining.py:  535]:	loss/mlm_loss, 8.186426162719727, 1202
[INFO] 2021-07-12 18:55:18,235 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2009999409201555e-05, 1202
[INFO] 2021-07-12 18:55:18,235 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1202
[INFO] 2021-07-12 18:55:18,235 [run_pretraining.py:  558]:	worker_index: 3, step: 1202, cost: 8.186426, mlm loss: 8.186426, speed: 1.102123 steps/s, speed: 8.816983 samples/s, speed: 4514.295470 tokens/s, learning rate: 1.201e-05, loss_scalings: 13421.773438, pp_loss: 8.015386
[INFO] 2021-07-12 18:55:18,235 [run_pretraining.py:  512]:	********exe.run_1202******* 
[INFO] 2021-07-12 18:55:19,151 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:19,151 [run_pretraining.py:  534]:	loss/total_loss, 8.021276473999023, 1203
[INFO] 2021-07-12 18:55:19,152 [run_pretraining.py:  535]:	loss/mlm_loss, 8.021276473999023, 1203
[INFO] 2021-07-12 18:55:19,152 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.202000021294225e-05, 1203
[INFO] 2021-07-12 18:55:19,152 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1203
[INFO] 2021-07-12 18:55:19,152 [run_pretraining.py:  558]:	worker_index: 3, step: 1203, cost: 8.021276, mlm loss: 8.021276, speed: 1.092030 steps/s, speed: 8.736238 samples/s, speed: 4472.953962 tokens/s, learning rate: 1.202e-05, loss_scalings: 13421.773438, pp_loss: 7.752107
[INFO] 2021-07-12 18:55:19,152 [run_pretraining.py:  512]:	********exe.run_1203******* 
[INFO] 2021-07-12 18:55:20,063 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:20,064 [run_pretraining.py:  534]:	loss/total_loss, 7.920966148376465, 1204
[INFO] 2021-07-12 18:55:20,064 [run_pretraining.py:  535]:	loss/mlm_loss, 7.920966148376465, 1204
[INFO] 2021-07-12 18:55:20,064 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2030000107188243e-05, 1204
[INFO] 2021-07-12 18:55:20,064 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1204
[INFO] 2021-07-12 18:55:20,064 [run_pretraining.py:  558]:	worker_index: 3, step: 1204, cost: 7.920966, mlm loss: 7.920966, speed: 1.096619 steps/s, speed: 8.772951 samples/s, speed: 4491.750903 tokens/s, learning rate: 1.203e-05, loss_scalings: 13421.773438, pp_loss: 7.868871
[INFO] 2021-07-12 18:55:20,064 [run_pretraining.py:  512]:	********exe.run_1204******* 
[INFO] 2021-07-12 18:55:20,973 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:20,973 [run_pretraining.py:  534]:	loss/total_loss, 7.146812438964844, 1205
[INFO] 2021-07-12 18:55:20,974 [run_pretraining.py:  535]:	loss/mlm_loss, 7.146812438964844, 1205
[INFO] 2021-07-12 18:55:20,974 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2039999091939535e-05, 1205
[INFO] 2021-07-12 18:55:20,974 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1205
[INFO] 2021-07-12 18:55:20,974 [run_pretraining.py:  558]:	worker_index: 3, step: 1205, cost: 7.146812, mlm loss: 7.146812, speed: 1.100221 steps/s, speed: 8.801767 samples/s, speed: 4506.504889 tokens/s, learning rate: 1.204e-05, loss_scalings: 13421.773438, pp_loss: 7.782623
[INFO] 2021-07-12 18:55:20,974 [run_pretraining.py:  512]:	********exe.run_1205******* 
[INFO] 2021-07-12 18:55:21,882 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:21,883 [run_pretraining.py:  534]:	loss/total_loss, 7.95024299621582, 1206
[INFO] 2021-07-12 18:55:21,883 [run_pretraining.py:  535]:	loss/mlm_loss, 7.95024299621582, 1206
[INFO] 2021-07-12 18:55:21,883 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.204999989568023e-05, 1206
[INFO] 2021-07-12 18:55:21,883 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1206
[INFO] 2021-07-12 18:55:21,883 [run_pretraining.py:  558]:	worker_index: 3, step: 1206, cost: 7.950243, mlm loss: 7.950243, speed: 1.100435 steps/s, speed: 8.803483 samples/s, speed: 4507.383372 tokens/s, learning rate: 1.205e-05, loss_scalings: 13421.773438, pp_loss: 6.838496
[INFO] 2021-07-12 18:55:21,883 [run_pretraining.py:  512]:	********exe.run_1206******* 
[INFO] 2021-07-12 18:55:22,794 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:22,794 [run_pretraining.py:  534]:	loss/total_loss, 7.252764701843262, 1207
[INFO] 2021-07-12 18:55:22,794 [run_pretraining.py:  535]:	loss/mlm_loss, 7.252764701843262, 1207
[INFO] 2021-07-12 18:55:22,794 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2059999789926223e-05, 1207
[INFO] 2021-07-12 18:55:22,795 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1207
[INFO] 2021-07-12 18:55:22,795 [run_pretraining.py:  558]:	worker_index: 3, step: 1207, cost: 7.252765, mlm loss: 7.252765, speed: 1.097928 steps/s, speed: 8.783423 samples/s, speed: 4497.112503 tokens/s, learning rate: 1.206e-05, loss_scalings: 13421.773438, pp_loss: 7.308190
[INFO] 2021-07-12 18:55:22,795 [run_pretraining.py:  512]:	********exe.run_1207******* 
[INFO] 2021-07-12 18:55:23,704 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:23,704 [run_pretraining.py:  534]:	loss/total_loss, 7.678924560546875, 1208
[INFO] 2021-07-12 18:55:23,704 [run_pretraining.py:  535]:	loss/mlm_loss, 7.678924560546875, 1208
[INFO] 2021-07-12 18:55:23,704 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2069999684172217e-05, 1208
[INFO] 2021-07-12 18:55:23,704 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1208
[INFO] 2021-07-12 18:55:23,704 [run_pretraining.py:  558]:	worker_index: 3, step: 1208, cost: 7.678925, mlm loss: 7.678925, speed: 1.099960 steps/s, speed: 8.799676 samples/s, speed: 4505.434147 tokens/s, learning rate: 1.207e-05, loss_scalings: 13421.773438, pp_loss: 7.903524
[INFO] 2021-07-12 18:55:23,704 [run_pretraining.py:  512]:	********exe.run_1208******* 
[INFO] 2021-07-12 18:55:24,612 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:24,612 [run_pretraining.py:  534]:	loss/total_loss, 7.883152008056641, 1209
[INFO] 2021-07-12 18:55:24,612 [run_pretraining.py:  535]:	loss/mlm_loss, 7.883152008056641, 1209
[INFO] 2021-07-12 18:55:24,612 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2080000487912912e-05, 1209
[INFO] 2021-07-12 18:55:24,612 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1209
[INFO] 2021-07-12 18:55:24,613 [run_pretraining.py:  558]:	worker_index: 3, step: 1209, cost: 7.883152, mlm loss: 7.883152, speed: 1.101912 steps/s, speed: 8.815299 samples/s, speed: 4513.433263 tokens/s, learning rate: 1.208e-05, loss_scalings: 13421.773438, pp_loss: 7.586528
[INFO] 2021-07-12 18:55:24,613 [run_pretraining.py:  512]:	********exe.run_1209******* 
[INFO] 2021-07-12 18:55:25,516 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:25,517 [run_pretraining.py:  534]:	loss/total_loss, 8.296381950378418, 1210
[INFO] 2021-07-12 18:55:25,517 [run_pretraining.py:  535]:	loss/mlm_loss, 8.296381950378418, 1210
[INFO] 2021-07-12 18:55:25,517 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2089999472664203e-05, 1210
[INFO] 2021-07-12 18:55:25,517 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1210
[INFO] 2021-07-12 18:55:25,517 [run_pretraining.py:  558]:	worker_index: 3, step: 1210, cost: 8.296382, mlm loss: 8.296382, speed: 1.106491 steps/s, speed: 8.851924 samples/s, speed: 4532.185272 tokens/s, learning rate: 1.209e-05, loss_scalings: 13421.773438, pp_loss: 7.911206
[INFO] 2021-07-12 18:55:25,517 [run_pretraining.py:  512]:	********exe.run_1210******* 
[INFO] 2021-07-12 18:55:26,458 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:26,459 [run_pretraining.py:  534]:	loss/total_loss, 6.835147857666016, 1211
[INFO] 2021-07-12 18:55:26,459 [run_pretraining.py:  535]:	loss/mlm_loss, 6.835147857666016, 1211
[INFO] 2021-07-12 18:55:26,459 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2099999366910197e-05, 1211
[INFO] 2021-07-12 18:55:26,459 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1211
[INFO] 2021-07-12 18:55:26,459 [run_pretraining.py:  558]:	worker_index: 3, step: 1211, cost: 6.835148, mlm loss: 6.835148, speed: 1.062198 steps/s, speed: 8.497583 samples/s, speed: 4350.762563 tokens/s, learning rate: 1.210e-05, loss_scalings: 13421.773438, pp_loss: 7.338248
[INFO] 2021-07-12 18:55:26,459 [run_pretraining.py:  512]:	********exe.run_1211******* 
[INFO] 2021-07-12 18:55:27,369 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:27,369 [run_pretraining.py:  534]:	loss/total_loss, 7.233014106750488, 1212
[INFO] 2021-07-12 18:55:27,369 [run_pretraining.py:  535]:	loss/mlm_loss, 7.233014106750488, 1212
[INFO] 2021-07-12 18:55:27,369 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2110000170650892e-05, 1212
[INFO] 2021-07-12 18:55:27,369 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1212
[INFO] 2021-07-12 18:55:27,369 [run_pretraining.py:  558]:	worker_index: 3, step: 1212, cost: 7.233014, mlm loss: 7.233014, speed: 1.099071 steps/s, speed: 8.792565 samples/s, speed: 4501.793180 tokens/s, learning rate: 1.211e-05, loss_scalings: 13421.773438, pp_loss: 7.547060
[INFO] 2021-07-12 18:55:27,370 [run_pretraining.py:  512]:	********exe.run_1212******* 
[INFO] 2021-07-12 18:55:28,279 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:28,280 [run_pretraining.py:  534]:	loss/total_loss, 8.134634017944336, 1213
[INFO] 2021-07-12 18:55:28,280 [run_pretraining.py:  535]:	loss/mlm_loss, 8.134634017944336, 1213
[INFO] 2021-07-12 18:55:28,280 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2120000064896885e-05, 1213
[INFO] 2021-07-12 18:55:28,280 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1213
[INFO] 2021-07-12 18:55:28,280 [run_pretraining.py:  558]:	worker_index: 3, step: 1213, cost: 8.134634, mlm loss: 8.134634, speed: 1.098769 steps/s, speed: 8.790151 samples/s, speed: 4500.557252 tokens/s, learning rate: 1.212e-05, loss_scalings: 13421.773438, pp_loss: 7.933914
[INFO] 2021-07-12 18:55:28,280 [run_pretraining.py:  512]:	********exe.run_1213******* 
[INFO] 2021-07-12 18:55:29,193 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:29,194 [run_pretraining.py:  534]:	loss/total_loss, 7.606550216674805, 1214
[INFO] 2021-07-12 18:55:29,194 [run_pretraining.py:  535]:	loss/mlm_loss, 7.606550216674805, 1214
[INFO] 2021-07-12 18:55:29,194 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2129999049648177e-05, 1214
[INFO] 2021-07-12 18:55:29,194 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1214
[INFO] 2021-07-12 18:55:29,194 [run_pretraining.py:  558]:	worker_index: 3, step: 1214, cost: 7.606550, mlm loss: 7.606550, speed: 1.095318 steps/s, speed: 8.762541 samples/s, speed: 4486.420818 tokens/s, learning rate: 1.213e-05, loss_scalings: 13421.773438, pp_loss: 7.166455
[INFO] 2021-07-12 18:55:29,194 [run_pretraining.py:  512]:	********exe.run_1214******* 
[INFO] 2021-07-12 18:55:30,101 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:30,101 [run_pretraining.py:  534]:	loss/total_loss, 7.415373802185059, 1215
[INFO] 2021-07-12 18:55:30,101 [run_pretraining.py:  535]:	loss/mlm_loss, 7.415373802185059, 1215
[INFO] 2021-07-12 18:55:30,101 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2139999853388872e-05, 1215
[INFO] 2021-07-12 18:55:30,101 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1215
[INFO] 2021-07-12 18:55:30,102 [run_pretraining.py:  558]:	worker_index: 3, step: 1215, cost: 7.415374, mlm loss: 7.415374, speed: 1.102403 steps/s, speed: 8.819222 samples/s, speed: 4515.441636 tokens/s, learning rate: 1.214e-05, loss_scalings: 13421.773438, pp_loss: 7.674908
[INFO] 2021-07-12 18:55:30,102 [run_pretraining.py:  512]:	********exe.run_1215******* 
[INFO] 2021-07-12 18:55:31,017 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:31,017 [run_pretraining.py:  534]:	loss/total_loss, 7.327322483062744, 1216
[INFO] 2021-07-12 18:55:31,017 [run_pretraining.py:  535]:	loss/mlm_loss, 7.327322483062744, 1216
[INFO] 2021-07-12 18:55:31,017 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2149999747634865e-05, 1216
[INFO] 2021-07-12 18:55:31,017 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1216
[INFO] 2021-07-12 18:55:31,018 [run_pretraining.py:  558]:	worker_index: 3, step: 1216, cost: 7.327322, mlm loss: 7.327322, speed: 1.092521 steps/s, speed: 8.740170 samples/s, speed: 4474.967260 tokens/s, learning rate: 1.215e-05, loss_scalings: 13421.773438, pp_loss: 7.743996
[INFO] 2021-07-12 18:55:31,018 [run_pretraining.py:  512]:	********exe.run_1216******* 
[INFO] 2021-07-12 18:55:31,922 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:31,923 [run_pretraining.py:  534]:	loss/total_loss, 7.544635772705078, 1217
[INFO] 2021-07-12 18:55:31,923 [run_pretraining.py:  535]:	loss/mlm_loss, 7.544635772705078, 1217
[INFO] 2021-07-12 18:55:31,923 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2159999641880859e-05, 1217
[INFO] 2021-07-12 18:55:31,923 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1217
[INFO] 2021-07-12 18:55:31,923 [run_pretraining.py:  558]:	worker_index: 3, step: 1217, cost: 7.544636, mlm loss: 7.544636, speed: 1.104765 steps/s, speed: 8.838121 samples/s, speed: 4525.118202 tokens/s, learning rate: 1.216e-05, loss_scalings: 13421.773438, pp_loss: 7.781946
[INFO] 2021-07-12 18:55:31,923 [run_pretraining.py:  512]:	********exe.run_1217******* 
[INFO] 2021-07-12 18:55:32,828 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:32,828 [run_pretraining.py:  534]:	loss/total_loss, 7.844715118408203, 1218
[INFO] 2021-07-12 18:55:32,828 [run_pretraining.py:  535]:	loss/mlm_loss, 7.844715118408203, 1218
[INFO] 2021-07-12 18:55:32,828 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2169999536126852e-05, 1218
[INFO] 2021-07-12 18:55:32,828 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1218
[INFO] 2021-07-12 18:55:32,828 [run_pretraining.py:  558]:	worker_index: 3, step: 1218, cost: 7.844715, mlm loss: 7.844715, speed: 1.105646 steps/s, speed: 8.845164 samples/s, speed: 4528.724188 tokens/s, learning rate: 1.217e-05, loss_scalings: 13421.773438, pp_loss: 7.878228
[INFO] 2021-07-12 18:55:32,828 [run_pretraining.py:  512]:	********exe.run_1218******* 
[INFO] 2021-07-12 18:55:33,741 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:33,741 [run_pretraining.py:  534]:	loss/total_loss, 7.802168369293213, 1219
[INFO] 2021-07-12 18:55:33,741 [run_pretraining.py:  535]:	loss/mlm_loss, 7.802168369293213, 1219
[INFO] 2021-07-12 18:55:33,741 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2179999430372845e-05, 1219
[INFO] 2021-07-12 18:55:33,742 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1219
[INFO] 2021-07-12 18:55:33,742 [run_pretraining.py:  558]:	worker_index: 3, step: 1219, cost: 7.802168, mlm loss: 7.802168, speed: 1.095786 steps/s, speed: 8.766290 samples/s, speed: 4488.340724 tokens/s, learning rate: 1.218e-05, loss_scalings: 13421.773438, pp_loss: 7.652222
[INFO] 2021-07-12 18:55:33,742 [run_pretraining.py:  512]:	********exe.run_1219******* 
[INFO] 2021-07-12 18:55:34,686 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:34,687 [run_pretraining.py:  534]:	loss/total_loss, 7.775115489959717, 1220
[INFO] 2021-07-12 18:55:34,687 [run_pretraining.py:  535]:	loss/mlm_loss, 7.775115489959717, 1220
[INFO] 2021-07-12 18:55:34,687 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2189999324618839e-05, 1220
[INFO] 2021-07-12 18:55:34,687 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1220
[INFO] 2021-07-12 18:55:34,687 [run_pretraining.py:  558]:	worker_index: 3, step: 1220, cost: 7.775115, mlm loss: 7.775115, speed: 1.058527 steps/s, speed: 8.468216 samples/s, speed: 4335.726376 tokens/s, learning rate: 1.219e-05, loss_scalings: 13421.773438, pp_loss: 7.525542
[INFO] 2021-07-12 18:55:34,687 [run_pretraining.py:  512]:	********exe.run_1220******* 
[INFO] 2021-07-12 18:55:35,593 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:35,593 [run_pretraining.py:  534]:	loss/total_loss, 7.514007091522217, 1221
[INFO] 2021-07-12 18:55:35,593 [run_pretraining.py:  535]:	loss/mlm_loss, 7.514007091522217, 1221
[INFO] 2021-07-12 18:55:35,593 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2200000128359534e-05, 1221
[INFO] 2021-07-12 18:55:35,593 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1221
[INFO] 2021-07-12 18:55:35,593 [run_pretraining.py:  558]:	worker_index: 3, step: 1221, cost: 7.514007, mlm loss: 7.514007, speed: 1.103953 steps/s, speed: 8.831622 samples/s, speed: 4521.790481 tokens/s, learning rate: 1.220e-05, loss_scalings: 13421.773438, pp_loss: 7.558758
[INFO] 2021-07-12 18:55:35,594 [run_pretraining.py:  512]:	********exe.run_1221******* 
[INFO] 2021-07-12 18:55:36,490 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:36,491 [run_pretraining.py:  534]:	loss/total_loss, 7.570261478424072, 1222
[INFO] 2021-07-12 18:55:36,491 [run_pretraining.py:  535]:	loss/mlm_loss, 7.570261478424072, 1222
[INFO] 2021-07-12 18:55:36,491 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2210000022605527e-05, 1222
[INFO] 2021-07-12 18:55:36,491 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1222
[INFO] 2021-07-12 18:55:36,491 [run_pretraining.py:  558]:	worker_index: 3, step: 1222, cost: 7.570261, mlm loss: 7.570261, speed: 1.114731 steps/s, speed: 8.917851 samples/s, speed: 4565.939845 tokens/s, learning rate: 1.221e-05, loss_scalings: 13421.773438, pp_loss: 6.815129
[INFO] 2021-07-12 18:55:36,491 [run_pretraining.py:  512]:	********exe.run_1222******* 
[INFO] 2021-07-12 18:55:37,395 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:37,395 [run_pretraining.py:  534]:	loss/total_loss, 7.999072551727295, 1223
[INFO] 2021-07-12 18:55:37,395 [run_pretraining.py:  535]:	loss/mlm_loss, 7.999072551727295, 1223
[INFO] 2021-07-12 18:55:37,395 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2219999007356819e-05, 1223
[INFO] 2021-07-12 18:55:37,395 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1223
[INFO] 2021-07-12 18:55:37,395 [run_pretraining.py:  558]:	worker_index: 3, step: 1223, cost: 7.999073, mlm loss: 7.999073, speed: 1.106708 steps/s, speed: 8.853667 samples/s, speed: 4533.077385 tokens/s, learning rate: 1.222e-05, loss_scalings: 13421.773438, pp_loss: 7.538353
[INFO] 2021-07-12 18:55:37,395 [run_pretraining.py:  512]:	********exe.run_1223******* 
[INFO] 2021-07-12 18:55:38,406 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:38,406 [run_pretraining.py:  534]:	loss/total_loss, 7.696601390838623, 1224
[INFO] 2021-07-12 18:55:38,406 [run_pretraining.py:  535]:	loss/mlm_loss, 7.696601390838623, 1224
[INFO] 2021-07-12 18:55:38,406 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2229999811097514e-05, 1224
[INFO] 2021-07-12 18:55:38,406 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1224
[INFO] 2021-07-12 18:55:38,406 [run_pretraining.py:  558]:	worker_index: 3, step: 1224, cost: 7.696601, mlm loss: 7.696601, speed: 0.989697 steps/s, speed: 7.917576 samples/s, speed: 4053.798704 tokens/s, learning rate: 1.223e-05, loss_scalings: 13421.773438, pp_loss: 7.715209
[INFO] 2021-07-12 18:55:38,406 [run_pretraining.py:  512]:	********exe.run_1224******* 
[INFO] 2021-07-12 18:55:39,468 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:39,469 [run_pretraining.py:  534]:	loss/total_loss, 8.106592178344727, 1225
[INFO] 2021-07-12 18:55:39,469 [run_pretraining.py:  535]:	loss/mlm_loss, 8.106592178344727, 1225
[INFO] 2021-07-12 18:55:39,469 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2239999705343507e-05, 1225
[INFO] 2021-07-12 18:55:39,469 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1225
[INFO] 2021-07-12 18:55:39,469 [run_pretraining.py:  558]:	worker_index: 3, step: 1225, cost: 8.106592, mlm loss: 8.106592, speed: 0.941586 steps/s, speed: 7.532686 samples/s, speed: 3856.735158 tokens/s, learning rate: 1.224e-05, loss_scalings: 13421.773438, pp_loss: 7.595672
[INFO] 2021-07-12 18:55:39,469 [run_pretraining.py:  512]:	********exe.run_1225******* 
[INFO] 2021-07-12 18:55:40,492 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:40,492 [run_pretraining.py:  534]:	loss/total_loss, 7.279594421386719, 1226
[INFO] 2021-07-12 18:55:40,492 [run_pretraining.py:  535]:	loss/mlm_loss, 7.279594421386719, 1226
[INFO] 2021-07-12 18:55:40,492 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.22499995995895e-05, 1226
[INFO] 2021-07-12 18:55:40,492 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1226
[INFO] 2021-07-12 18:55:40,492 [run_pretraining.py:  558]:	worker_index: 3, step: 1226, cost: 7.279594, mlm loss: 7.279594, speed: 0.977732 steps/s, speed: 7.821856 samples/s, speed: 4004.790209 tokens/s, learning rate: 1.225e-05, loss_scalings: 13421.773438, pp_loss: 7.654540
[INFO] 2021-07-12 18:55:40,493 [run_pretraining.py:  512]:	********exe.run_1226******* 
[INFO] 2021-07-12 18:55:41,543 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:41,544 [run_pretraining.py:  534]:	loss/total_loss, 7.233002662658691, 1227
[INFO] 2021-07-12 18:55:41,544 [run_pretraining.py:  535]:	loss/mlm_loss, 7.233002662658691, 1227
[INFO] 2021-07-12 18:55:41,544 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2259999493835494e-05, 1227
[INFO] 2021-07-12 18:55:41,544 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1227
[INFO] 2021-07-12 18:55:41,544 [run_pretraining.py:  558]:	worker_index: 3, step: 1227, cost: 7.233003, mlm loss: 7.233003, speed: 0.951436 steps/s, speed: 7.611492 samples/s, speed: 3897.083808 tokens/s, learning rate: 1.226e-05, loss_scalings: 13421.773438, pp_loss: 7.504057
[INFO] 2021-07-12 18:55:41,544 [run_pretraining.py:  512]:	********exe.run_1227******* 
[INFO] 2021-07-12 18:55:42,606 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:42,607 [run_pretraining.py:  534]:	loss/total_loss, 7.752376556396484, 1228
[INFO] 2021-07-12 18:55:42,607 [run_pretraining.py:  535]:	loss/mlm_loss, 7.752376556396484, 1228
[INFO] 2021-07-12 18:55:42,607 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2269999388081487e-05, 1228
[INFO] 2021-07-12 18:55:42,607 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1228
[INFO] 2021-07-12 18:55:42,607 [run_pretraining.py:  558]:	worker_index: 3, step: 1228, cost: 7.752377, mlm loss: 7.752377, speed: 0.941571 steps/s, speed: 7.532567 samples/s, speed: 3856.674552 tokens/s, learning rate: 1.227e-05, loss_scalings: 13421.773438, pp_loss: 7.020837
[INFO] 2021-07-12 18:55:42,607 [run_pretraining.py:  512]:	********exe.run_1228******* 
[INFO] 2021-07-12 18:55:43,667 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:43,667 [run_pretraining.py:  534]:	loss/total_loss, 6.954990386962891, 1229
[INFO] 2021-07-12 18:55:43,667 [run_pretraining.py:  535]:	loss/mlm_loss, 6.954990386962891, 1229
[INFO] 2021-07-12 18:55:43,668 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.227999928232748e-05, 1229
[INFO] 2021-07-12 18:55:43,668 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1229
[INFO] 2021-07-12 18:55:43,668 [run_pretraining.py:  558]:	worker_index: 3, step: 1229, cost: 6.954990, mlm loss: 6.954990, speed: 0.943261 steps/s, speed: 7.546086 samples/s, speed: 3863.595853 tokens/s, learning rate: 1.228e-05, loss_scalings: 10737.418945, pp_loss: 7.619894
[INFO] 2021-07-12 18:55:43,668 [run_pretraining.py:  512]:	********exe.run_1229******* 
[INFO] 2021-07-12 18:55:44,720 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:44,721 [run_pretraining.py:  534]:	loss/total_loss, 7.924148082733154, 1230
[INFO] 2021-07-12 18:55:44,721 [run_pretraining.py:  535]:	loss/mlm_loss, 7.924148082733154, 1230
[INFO] 2021-07-12 18:55:44,721 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2290000086068176e-05, 1230
[INFO] 2021-07-12 18:55:44,721 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1230
[INFO] 2021-07-12 18:55:44,721 [run_pretraining.py:  558]:	worker_index: 3, step: 1230, cost: 7.924148, mlm loss: 7.924148, speed: 0.950064 steps/s, speed: 7.600514 samples/s, speed: 3891.463402 tokens/s, learning rate: 1.229e-05, loss_scalings: 10737.418945, pp_loss: 7.798526
[INFO] 2021-07-12 18:55:44,721 [run_pretraining.py:  512]:	********exe.run_1230******* 
[INFO] 2021-07-12 18:55:45,787 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:45,787 [run_pretraining.py:  534]:	loss/total_loss, 7.947453022003174, 1231
[INFO] 2021-07-12 18:55:45,787 [run_pretraining.py:  535]:	loss/mlm_loss, 7.947453022003174, 1231
[INFO] 2021-07-12 18:55:45,787 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2299999980314169e-05, 1231
[INFO] 2021-07-12 18:55:45,788 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1231
[INFO] 2021-07-12 18:55:45,788 [run_pretraining.py:  558]:	worker_index: 3, step: 1231, cost: 7.947453, mlm loss: 7.947453, speed: 0.937996 steps/s, speed: 7.503967 samples/s, speed: 3842.031199 tokens/s, learning rate: 1.230e-05, loss_scalings: 10737.418945, pp_loss: 7.710236
[INFO] 2021-07-12 18:55:45,788 [run_pretraining.py:  512]:	********exe.run_1231******* 
[INFO] 2021-07-12 18:55:46,839 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:46,839 [run_pretraining.py:  534]:	loss/total_loss, 7.5596923828125, 1232
[INFO] 2021-07-12 18:55:46,839 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5596923828125, 1232
[INFO] 2021-07-12 18:55:46,839 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2309999874560162e-05, 1232
[INFO] 2021-07-12 18:55:46,839 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1232
[INFO] 2021-07-12 18:55:46,839 [run_pretraining.py:  558]:	worker_index: 3, step: 1232, cost: 7.559692, mlm loss: 7.559692, speed: 0.951324 steps/s, speed: 7.610592 samples/s, speed: 3896.623290 tokens/s, learning rate: 1.231e-05, loss_scalings: 10737.418945, pp_loss: 7.671647
[INFO] 2021-07-12 18:55:46,839 [run_pretraining.py:  512]:	********exe.run_1232******* 
[INFO] 2021-07-12 18:55:47,856 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:47,856 [run_pretraining.py:  534]:	loss/total_loss, 7.74156379699707, 1233
[INFO] 2021-07-12 18:55:47,857 [run_pretraining.py:  535]:	loss/mlm_loss, 7.74156379699707, 1233
[INFO] 2021-07-12 18:55:47,857 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2319999768806156e-05, 1233
[INFO] 2021-07-12 18:55:47,857 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1233
[INFO] 2021-07-12 18:55:47,857 [run_pretraining.py:  558]:	worker_index: 3, step: 1233, cost: 7.741564, mlm loss: 7.741564, speed: 0.983571 steps/s, speed: 7.868565 samples/s, speed: 4028.705138 tokens/s, learning rate: 1.232e-05, loss_scalings: 10737.418945, pp_loss: 7.614610
[INFO] 2021-07-12 18:55:47,857 [run_pretraining.py:  512]:	********exe.run_1233******* 
[INFO] 2021-07-12 18:55:48,914 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:48,915 [run_pretraining.py:  534]:	loss/total_loss, 8.272729873657227, 1234
[INFO] 2021-07-12 18:55:48,915 [run_pretraining.py:  535]:	loss/mlm_loss, 8.272729873657227, 1234
[INFO] 2021-07-12 18:55:48,915 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2329999663052149e-05, 1234
[INFO] 2021-07-12 18:55:48,915 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1234
[INFO] 2021-07-12 18:55:48,915 [run_pretraining.py:  558]:	worker_index: 3, step: 1234, cost: 8.272730, mlm loss: 8.272730, speed: 0.945679 steps/s, speed: 7.565432 samples/s, speed: 3873.501303 tokens/s, learning rate: 1.233e-05, loss_scalings: 10737.418945, pp_loss: 7.861528
[INFO] 2021-07-12 18:55:48,915 [run_pretraining.py:  512]:	********exe.run_1234******* 
[INFO] 2021-07-12 18:55:49,982 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:49,982 [run_pretraining.py:  534]:	loss/total_loss, 7.7922234535217285, 1235
[INFO] 2021-07-12 18:55:49,983 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7922234535217285, 1235
[INFO] 2021-07-12 18:55:49,983 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2339999557298142e-05, 1235
[INFO] 2021-07-12 18:55:49,983 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1235
[INFO] 2021-07-12 18:55:49,983 [run_pretraining.py:  558]:	worker_index: 3, step: 1235, cost: 7.792223, mlm loss: 7.792223, speed: 0.936957 steps/s, speed: 7.495659 samples/s, speed: 3837.777643 tokens/s, learning rate: 1.234e-05, loss_scalings: 10737.418945, pp_loss: 7.772570
[INFO] 2021-07-12 18:55:49,983 [run_pretraining.py:  512]:	********exe.run_1235******* 
[INFO] 2021-07-12 18:55:50,902 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:50,903 [run_pretraining.py:  534]:	loss/total_loss, 7.8289361000061035, 1236
[INFO] 2021-07-12 18:55:50,903 [run_pretraining.py:  535]:	loss/mlm_loss, 7.8289361000061035, 1236
[INFO] 2021-07-12 18:55:50,903 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2349999451544136e-05, 1236
[INFO] 2021-07-12 18:55:50,903 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1236
[INFO] 2021-07-12 18:55:50,903 [run_pretraining.py:  558]:	worker_index: 3, step: 1236, cost: 7.828936, mlm loss: 7.828936, speed: 1.087036 steps/s, speed: 8.696291 samples/s, speed: 4452.501242 tokens/s, learning rate: 1.235e-05, loss_scalings: 10737.418945, pp_loss: 7.566764
[INFO] 2021-07-12 18:55:50,903 [run_pretraining.py:  512]:	********exe.run_1236******* 
[INFO] 2021-07-12 18:55:51,873 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:51,874 [run_pretraining.py:  534]:	loss/total_loss, 8.247000694274902, 1237
[INFO] 2021-07-12 18:55:51,874 [run_pretraining.py:  535]:	loss/mlm_loss, 8.247000694274902, 1237
[INFO] 2021-07-12 18:55:51,874 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.235999934579013e-05, 1237
[INFO] 2021-07-12 18:55:51,874 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1237
[INFO] 2021-07-12 18:55:51,874 [run_pretraining.py:  558]:	worker_index: 3, step: 1237, cost: 8.247001, mlm loss: 8.247001, speed: 1.030951 steps/s, speed: 8.247611 samples/s, speed: 4222.776815 tokens/s, learning rate: 1.236e-05, loss_scalings: 10737.418945, pp_loss: 7.724519
[INFO] 2021-07-12 18:55:51,874 [run_pretraining.py:  512]:	********exe.run_1237******* 
[INFO] 2021-07-12 18:55:52,822 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:52,823 [run_pretraining.py:  534]:	loss/total_loss, 7.920793056488037, 1238
[INFO] 2021-07-12 18:55:52,823 [run_pretraining.py:  535]:	loss/mlm_loss, 7.920793056488037, 1238
[INFO] 2021-07-12 18:55:52,823 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2370000149530824e-05, 1238
[INFO] 2021-07-12 18:55:52,823 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1238
[INFO] 2021-07-12 18:55:52,823 [run_pretraining.py:  558]:	worker_index: 3, step: 1238, cost: 7.920793, mlm loss: 7.920793, speed: 1.054194 steps/s, speed: 8.433550 samples/s, speed: 4317.977800 tokens/s, learning rate: 1.237e-05, loss_scalings: 10737.418945, pp_loss: 7.794652
[INFO] 2021-07-12 18:55:52,823 [run_pretraining.py:  512]:	********exe.run_1238******* 
[INFO] 2021-07-12 18:55:53,732 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:53,732 [run_pretraining.py:  534]:	loss/total_loss, 7.374110698699951, 1239
[INFO] 2021-07-12 18:55:53,732 [run_pretraining.py:  535]:	loss/mlm_loss, 7.374110698699951, 1239
[INFO] 2021-07-12 18:55:53,732 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2380000043776818e-05, 1239
[INFO] 2021-07-12 18:55:53,732 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1239
[INFO] 2021-07-12 18:55:53,732 [run_pretraining.py:  558]:	worker_index: 3, step: 1239, cost: 7.374111, mlm loss: 7.374111, speed: 1.100519 steps/s, speed: 8.804153 samples/s, speed: 4507.726345 tokens/s, learning rate: 1.238e-05, loss_scalings: 10737.418945, pp_loss: 7.754606
[INFO] 2021-07-12 18:55:53,733 [run_pretraining.py:  512]:	********exe.run_1239******* 
[INFO] 2021-07-12 18:55:54,645 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:54,645 [run_pretraining.py:  534]:	loss/total_loss, 7.196305751800537, 1240
[INFO] 2021-07-12 18:55:54,645 [run_pretraining.py:  535]:	loss/mlm_loss, 7.196305751800537, 1240
[INFO] 2021-07-12 18:55:54,645 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.238999902852811e-05, 1240
[INFO] 2021-07-12 18:55:54,646 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1240
[INFO] 2021-07-12 18:55:54,646 [run_pretraining.py:  558]:	worker_index: 3, step: 1240, cost: 7.196306, mlm loss: 7.196306, speed: 1.095887 steps/s, speed: 8.767099 samples/s, speed: 4488.754691 tokens/s, learning rate: 1.239e-05, loss_scalings: 10737.418945, pp_loss: 7.454704
[INFO] 2021-07-12 18:55:54,646 [run_pretraining.py:  512]:	********exe.run_1240******* 
[INFO] 2021-07-12 18:55:55,550 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:55,551 [run_pretraining.py:  534]:	loss/total_loss, 7.929656028747559, 1241
[INFO] 2021-07-12 18:55:55,551 [run_pretraining.py:  535]:	loss/mlm_loss, 7.929656028747559, 1241
[INFO] 2021-07-12 18:55:55,551 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2399999832268804e-05, 1241
[INFO] 2021-07-12 18:55:55,551 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1241
[INFO] 2021-07-12 18:55:55,551 [run_pretraining.py:  558]:	worker_index: 3, step: 1241, cost: 7.929656, mlm loss: 7.929656, speed: 1.105280 steps/s, speed: 8.842237 samples/s, speed: 4527.225270 tokens/s, learning rate: 1.240e-05, loss_scalings: 10737.418945, pp_loss: 7.701309
[INFO] 2021-07-12 18:55:55,551 [run_pretraining.py:  512]:	********exe.run_1241******* 
[INFO] 2021-07-12 18:55:56,463 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:56,463 [run_pretraining.py:  534]:	loss/total_loss, 7.900506019592285, 1242
[INFO] 2021-07-12 18:55:56,464 [run_pretraining.py:  535]:	loss/mlm_loss, 7.900506019592285, 1242
[INFO] 2021-07-12 18:55:56,464 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2409999726514798e-05, 1242
[INFO] 2021-07-12 18:55:56,464 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1242
[INFO] 2021-07-12 18:55:56,464 [run_pretraining.py:  558]:	worker_index: 3, step: 1242, cost: 7.900506, mlm loss: 7.900506, speed: 1.096367 steps/s, speed: 8.770935 samples/s, speed: 4490.718854 tokens/s, learning rate: 1.241e-05, loss_scalings: 10737.418945, pp_loss: 7.480591
[INFO] 2021-07-12 18:55:56,464 [run_pretraining.py:  512]:	********exe.run_1242******* 
[INFO] 2021-07-12 18:55:57,370 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:57,371 [run_pretraining.py:  534]:	loss/total_loss, 7.549668788909912, 1243
[INFO] 2021-07-12 18:55:57,371 [run_pretraining.py:  535]:	loss/mlm_loss, 7.549668788909912, 1243
[INFO] 2021-07-12 18:55:57,371 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2419999620760791e-05, 1243
[INFO] 2021-07-12 18:55:57,371 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1243
[INFO] 2021-07-12 18:55:57,371 [run_pretraining.py:  558]:	worker_index: 3, step: 1243, cost: 7.549669, mlm loss: 7.549669, speed: 1.102580 steps/s, speed: 8.820643 samples/s, speed: 4516.169267 tokens/s, learning rate: 1.242e-05, loss_scalings: 10737.418945, pp_loss: 7.550714
[INFO] 2021-07-12 18:55:57,371 [run_pretraining.py:  512]:	********exe.run_1243******* 
[INFO] 2021-07-12 18:55:58,295 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:58,296 [run_pretraining.py:  534]:	loss/total_loss, 8.080587387084961, 1244
[INFO] 2021-07-12 18:55:58,296 [run_pretraining.py:  535]:	loss/mlm_loss, 8.080587387084961, 1244
[INFO] 2021-07-12 18:55:58,296 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2430000424501486e-05, 1244
[INFO] 2021-07-12 18:55:58,296 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1244
[INFO] 2021-07-12 18:55:58,296 [run_pretraining.py:  558]:	worker_index: 3, step: 1244, cost: 8.080587, mlm loss: 8.080587, speed: 1.082281 steps/s, speed: 8.658245 samples/s, speed: 4433.021562 tokens/s, learning rate: 1.243e-05, loss_scalings: 10737.418945, pp_loss: 7.989279
[INFO] 2021-07-12 18:55:58,296 [run_pretraining.py:  512]:	********exe.run_1244******* 
[INFO] 2021-07-12 18:55:59,201 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:59,201 [run_pretraining.py:  534]:	loss/total_loss, 7.954022407531738, 1245
[INFO] 2021-07-12 18:55:59,202 [run_pretraining.py:  535]:	loss/mlm_loss, 7.954022407531738, 1245
[INFO] 2021-07-12 18:55:59,202 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2439999409252778e-05, 1245
[INFO] 2021-07-12 18:55:59,202 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1245
[INFO] 2021-07-12 18:55:59,202 [run_pretraining.py:  558]:	worker_index: 3, step: 1245, cost: 7.954022, mlm loss: 7.954022, speed: 1.104772 steps/s, speed: 8.838180 samples/s, speed: 4525.147999 tokens/s, learning rate: 1.244e-05, loss_scalings: 10737.418945, pp_loss: 7.632509
[INFO] 2021-07-12 18:55:59,202 [run_pretraining.py:  512]:	********exe.run_1245******* 
[INFO] 2021-07-12 18:56:00,109 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:00,110 [run_pretraining.py:  534]:	loss/total_loss, 7.844672203063965, 1246
[INFO] 2021-07-12 18:56:00,110 [run_pretraining.py:  535]:	loss/mlm_loss, 7.844672203063965, 1246
[INFO] 2021-07-12 18:56:00,110 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2449999303498771e-05, 1246
[INFO] 2021-07-12 18:56:00,110 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1246
[INFO] 2021-07-12 18:56:00,110 [run_pretraining.py:  558]:	worker_index: 3, step: 1246, cost: 7.844672, mlm loss: 7.844672, speed: 1.101931 steps/s, speed: 8.815448 samples/s, speed: 4513.509152 tokens/s, learning rate: 1.245e-05, loss_scalings: 10737.418945, pp_loss: 7.097980
[INFO] 2021-07-12 18:56:00,110 [run_pretraining.py:  512]:	********exe.run_1246******* 
[INFO] 2021-07-12 18:56:01,035 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:01,036 [run_pretraining.py:  534]:	loss/total_loss, 8.027854919433594, 1247
[INFO] 2021-07-12 18:56:01,036 [run_pretraining.py:  535]:	loss/mlm_loss, 8.027854919433594, 1247
[INFO] 2021-07-12 18:56:01,036 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2460000107239466e-05, 1247
[INFO] 2021-07-12 18:56:01,036 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1247
[INFO] 2021-07-12 18:56:01,036 [run_pretraining.py:  558]:	worker_index: 3, step: 1247, cost: 8.027855, mlm loss: 8.027855, speed: 1.080190 steps/s, speed: 8.641517 samples/s, speed: 4424.456766 tokens/s, learning rate: 1.246e-05, loss_scalings: 10737.418945, pp_loss: 7.976939
[INFO] 2021-07-12 18:56:01,036 [run_pretraining.py:  512]:	********exe.run_1247******* 
[INFO] 2021-07-12 18:56:01,944 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:01,944 [run_pretraining.py:  534]:	loss/total_loss, 7.598063945770264, 1248
[INFO] 2021-07-12 18:56:01,944 [run_pretraining.py:  535]:	loss/mlm_loss, 7.598063945770264, 1248
[INFO] 2021-07-12 18:56:01,945 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.247000000148546e-05, 1248
[INFO] 2021-07-12 18:56:01,945 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1248
[INFO] 2021-07-12 18:56:01,945 [run_pretraining.py:  558]:	worker_index: 3, step: 1248, cost: 7.598064, mlm loss: 7.598064, speed: 1.101629 steps/s, speed: 8.813033 samples/s, speed: 4512.272709 tokens/s, learning rate: 1.247e-05, loss_scalings: 10737.418945, pp_loss: 7.810837
[INFO] 2021-07-12 18:56:01,945 [run_pretraining.py:  512]:	********exe.run_1248******* 
[INFO] 2021-07-12 18:56:02,860 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:02,860 [run_pretraining.py:  534]:	loss/total_loss, 7.714656352996826, 1249
[INFO] 2021-07-12 18:56:02,860 [run_pretraining.py:  535]:	loss/mlm_loss, 7.714656352996826, 1249
[INFO] 2021-07-12 18:56:02,860 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2479998986236751e-05, 1249
[INFO] 2021-07-12 18:56:02,860 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1249
[INFO] 2021-07-12 18:56:02,861 [run_pretraining.py:  558]:	worker_index: 3, step: 1249, cost: 7.714656, mlm loss: 7.714656, speed: 1.092586 steps/s, speed: 8.740685 samples/s, speed: 4475.230708 tokens/s, learning rate: 1.248e-05, loss_scalings: 10737.418945, pp_loss: 7.857694
[INFO] 2021-07-12 18:56:02,861 [run_pretraining.py:  512]:	********exe.run_1249******* 
[INFO] 2021-07-12 18:56:03,772 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:03,773 [run_pretraining.py:  534]:	loss/total_loss, 7.877912521362305, 1250
[INFO] 2021-07-12 18:56:03,773 [run_pretraining.py:  535]:	loss/mlm_loss, 7.877912521362305, 1250
[INFO] 2021-07-12 18:56:03,773 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2489999789977446e-05, 1250
[INFO] 2021-07-12 18:56:03,773 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1250
[INFO] 2021-07-12 18:56:03,773 [run_pretraining.py:  558]:	worker_index: 3, step: 1250, cost: 7.877913, mlm loss: 7.877913, speed: 1.096455 steps/s, speed: 8.771639 samples/s, speed: 4491.079254 tokens/s, learning rate: 1.249e-05, loss_scalings: 10737.418945, pp_loss: 7.744958
[INFO] 2021-07-12 18:56:03,773 [run_pretraining.py:  512]:	********exe.run_1250******* 
[INFO] 2021-07-12 18:56:04,683 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:04,684 [run_pretraining.py:  534]:	loss/total_loss, 7.318451404571533, 1251
[INFO] 2021-07-12 18:56:04,684 [run_pretraining.py:  535]:	loss/mlm_loss, 7.318451404571533, 1251
[INFO] 2021-07-12 18:56:04,684 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.249999968422344e-05, 1251
[INFO] 2021-07-12 18:56:04,684 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1251
[INFO] 2021-07-12 18:56:04,684 [run_pretraining.py:  558]:	worker_index: 3, step: 1251, cost: 7.318451, mlm loss: 7.318451, speed: 1.098629 steps/s, speed: 8.789030 samples/s, speed: 4499.983153 tokens/s, learning rate: 1.250e-05, loss_scalings: 10737.418945, pp_loss: 7.647209
[INFO] 2021-07-12 18:56:04,684 [run_pretraining.py:  512]:	********exe.run_1251******* 
[INFO] 2021-07-12 18:56:05,618 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:05,619 [run_pretraining.py:  534]:	loss/total_loss, 7.9018049240112305, 1252
[INFO] 2021-07-12 18:56:05,619 [run_pretraining.py:  535]:	loss/mlm_loss, 7.9018049240112305, 1252
[INFO] 2021-07-12 18:56:05,619 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2509999578469433e-05, 1252
[INFO] 2021-07-12 18:56:05,619 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1252
[INFO] 2021-07-12 18:56:05,619 [run_pretraining.py:  558]:	worker_index: 3, step: 1252, cost: 7.901805, mlm loss: 7.901805, speed: 1.070294 steps/s, speed: 8.562355 samples/s, speed: 4383.925921 tokens/s, learning rate: 1.251e-05, loss_scalings: 10737.418945, pp_loss: 7.091974
[INFO] 2021-07-12 18:56:05,619 [run_pretraining.py:  512]:	********exe.run_1252******* 
[INFO] 2021-07-12 18:56:06,533 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:06,534 [run_pretraining.py:  534]:	loss/total_loss, 7.777193069458008, 1253
[INFO] 2021-07-12 18:56:06,534 [run_pretraining.py:  535]:	loss/mlm_loss, 7.777193069458008, 1253
[INFO] 2021-07-12 18:56:06,534 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2520000382210128e-05, 1253
[INFO] 2021-07-12 18:56:06,534 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1253
[INFO] 2021-07-12 18:56:06,534 [run_pretraining.py:  558]:	worker_index: 3, step: 1253, cost: 7.777193, mlm loss: 7.777193, speed: 1.093626 steps/s, speed: 8.749006 samples/s, speed: 4479.490967 tokens/s, learning rate: 1.252e-05, loss_scalings: 10737.418945, pp_loss: 7.509286
[INFO] 2021-07-12 18:56:06,534 [run_pretraining.py:  512]:	********exe.run_1253******* 
[INFO] 2021-07-12 18:56:07,468 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:07,469 [run_pretraining.py:  534]:	loss/total_loss, 7.417418479919434, 1254
[INFO] 2021-07-12 18:56:07,469 [run_pretraining.py:  535]:	loss/mlm_loss, 7.417418479919434, 1254
[INFO] 2021-07-12 18:56:07,469 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2530000276456121e-05, 1254
[INFO] 2021-07-12 18:56:07,469 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1254
[INFO] 2021-07-12 18:56:07,469 [run_pretraining.py:  558]:	worker_index: 3, step: 1254, cost: 7.417418, mlm loss: 7.417418, speed: 1.070347 steps/s, speed: 8.562775 samples/s, speed: 4384.140718 tokens/s, learning rate: 1.253e-05, loss_scalings: 10737.418945, pp_loss: 7.643093
[INFO] 2021-07-12 18:56:07,469 [run_pretraining.py:  512]:	********exe.run_1254******* 
[INFO] 2021-07-12 18:56:08,410 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:08,410 [run_pretraining.py:  534]:	loss/total_loss, 7.92868709564209, 1255
[INFO] 2021-07-12 18:56:08,411 [run_pretraining.py:  535]:	loss/mlm_loss, 7.92868709564209, 1255
[INFO] 2021-07-12 18:56:08,411 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2540000170702115e-05, 1255
[INFO] 2021-07-12 18:56:08,411 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1255
[INFO] 2021-07-12 18:56:08,411 [run_pretraining.py:  558]:	worker_index: 3, step: 1255, cost: 7.928687, mlm loss: 7.928687, speed: 1.062508 steps/s, speed: 8.500067 samples/s, speed: 4352.034436 tokens/s, learning rate: 1.254e-05, loss_scalings: 10737.418945, pp_loss: 7.967000
[INFO] 2021-07-12 18:56:08,411 [run_pretraining.py:  512]:	********exe.run_1255******* 
[INFO] 2021-07-12 18:56:09,347 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:09,348 [run_pretraining.py:  534]:	loss/total_loss, 7.374781608581543, 1256
[INFO] 2021-07-12 18:56:09,348 [run_pretraining.py:  535]:	loss/mlm_loss, 7.374781608581543, 1256
[INFO] 2021-07-12 18:56:09,348 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2549999155453406e-05, 1256
[INFO] 2021-07-12 18:56:09,348 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1256
[INFO] 2021-07-12 18:56:09,348 [run_pretraining.py:  558]:	worker_index: 3, step: 1256, cost: 7.374782, mlm loss: 7.374782, speed: 1.067525 steps/s, speed: 8.540203 samples/s, speed: 4372.583940 tokens/s, learning rate: 1.255e-05, loss_scalings: 10737.418945, pp_loss: 7.887579
[INFO] 2021-07-12 18:56:09,348 [run_pretraining.py:  512]:	********exe.run_1256******* 
[INFO] 2021-07-12 18:56:10,413 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:10,414 [run_pretraining.py:  534]:	loss/total_loss, 7.877130031585693, 1257
[INFO] 2021-07-12 18:56:10,414 [run_pretraining.py:  535]:	loss/mlm_loss, 7.877130031585693, 1257
[INFO] 2021-07-12 18:56:10,414 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.25599990496994e-05, 1257
[INFO] 2021-07-12 18:56:10,414 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1257
[INFO] 2021-07-12 18:56:10,414 [run_pretraining.py:  558]:	worker_index: 3, step: 1257, cost: 7.877130, mlm loss: 7.877130, speed: 0.938617 steps/s, speed: 7.508934 samples/s, speed: 3844.574439 tokens/s, learning rate: 1.256e-05, loss_scalings: 10737.418945, pp_loss: 7.672589
[INFO] 2021-07-12 18:56:10,414 [run_pretraining.py:  512]:	********exe.run_1257******* 
[INFO] 2021-07-12 18:56:11,482 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:11,488 [run_pretraining.py:  534]:	loss/total_loss, 7.799108028411865, 1258
[INFO] 2021-07-12 18:56:11,493 [run_pretraining.py:  535]:	loss/mlm_loss, 7.799108028411865, 1258
[INFO] 2021-07-12 18:56:11,499 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2569998943945393e-05, 1258
[INFO] 2021-07-12 18:56:11,504 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1258
[INFO] 2021-07-12 18:56:11,509 [run_pretraining.py:  558]:	worker_index: 3, step: 1258, cost: 7.799108, mlm loss: 7.799108, speed: 0.931472 steps/s, speed: 7.451778 samples/s, speed: 3815.310300 tokens/s, learning rate: 1.257e-05, loss_scalings: 10737.418945, pp_loss: 7.672154
[INFO] 2021-07-12 18:56:11,514 [run_pretraining.py:  512]:	********exe.run_1258******* 
[INFO] 2021-07-12 18:56:12,524 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:12,525 [run_pretraining.py:  534]:	loss/total_loss, 7.651950836181641, 1259
[INFO] 2021-07-12 18:56:12,525 [run_pretraining.py:  535]:	loss/mlm_loss, 7.651950836181641, 1259
[INFO] 2021-07-12 18:56:12,525 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2579999747686088e-05, 1259
[INFO] 2021-07-12 18:56:12,525 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1259
[INFO] 2021-07-12 18:56:12,525 [run_pretraining.py:  558]:	worker_index: 3, step: 1259, cost: 7.651951, mlm loss: 7.651951, speed: 0.989369 steps/s, speed: 7.914953 samples/s, speed: 4052.456162 tokens/s, learning rate: 1.258e-05, loss_scalings: 10737.418945, pp_loss: 7.703137
[INFO] 2021-07-12 18:56:12,525 [run_pretraining.py:  512]:	********exe.run_1259******* 
[INFO] 2021-07-12 18:56:13,456 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:13,456 [run_pretraining.py:  534]:	loss/total_loss, 7.458488464355469, 1260
[INFO] 2021-07-12 18:56:13,457 [run_pretraining.py:  535]:	loss/mlm_loss, 7.458488464355469, 1260
[INFO] 2021-07-12 18:56:13,457 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2589999641932081e-05, 1260
[INFO] 2021-07-12 18:56:13,457 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1260
[INFO] 2021-07-12 18:56:13,457 [run_pretraining.py:  558]:	worker_index: 3, step: 1260, cost: 7.458488, mlm loss: 7.458488, speed: 1.074320 steps/s, speed: 8.594559 samples/s, speed: 4400.414427 tokens/s, learning rate: 1.259e-05, loss_scalings: 10737.418945, pp_loss: 7.453823
[INFO] 2021-07-12 18:56:13,457 [run_pretraining.py:  512]:	********exe.run_1260******* 
[INFO] 2021-07-12 18:56:14,374 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:14,375 [run_pretraining.py:  534]:	loss/total_loss, 7.922539710998535, 1261
[INFO] 2021-07-12 18:56:14,375 [run_pretraining.py:  535]:	loss/mlm_loss, 7.922539710998535, 1261
[INFO] 2021-07-12 18:56:14,375 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2599999536178075e-05, 1261
[INFO] 2021-07-12 18:56:14,375 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1261
[INFO] 2021-07-12 18:56:14,375 [run_pretraining.py:  558]:	worker_index: 3, step: 1261, cost: 7.922540, mlm loss: 7.922540, speed: 1.089474 steps/s, speed: 8.715790 samples/s, speed: 4462.484502 tokens/s, learning rate: 1.260e-05, loss_scalings: 10737.418945, pp_loss: 7.882422
[INFO] 2021-07-12 18:56:14,375 [run_pretraining.py:  512]:	********exe.run_1261******* 
[INFO] 2021-07-12 18:56:15,296 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:15,297 [run_pretraining.py:  534]:	loss/total_loss, 8.188894271850586, 1262
[INFO] 2021-07-12 18:56:15,300 [run_pretraining.py:  535]:	loss/mlm_loss, 8.188894271850586, 1262
[INFO] 2021-07-12 18:56:15,301 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.261000033991877e-05, 1262
[INFO] 2021-07-12 18:56:15,301 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1262
[INFO] 2021-07-12 18:56:15,303 [run_pretraining.py:  558]:	worker_index: 3, step: 1262, cost: 8.188894, mlm loss: 8.188894, speed: 1.085086 steps/s, speed: 8.680689 samples/s, speed: 4444.512934 tokens/s, learning rate: 1.261e-05, loss_scalings: 10737.418945, pp_loss: 7.962314
[INFO] 2021-07-12 18:56:15,307 [run_pretraining.py:  512]:	********exe.run_1262******* 
[INFO] 2021-07-12 18:56:16,211 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:16,211 [run_pretraining.py:  534]:	loss/total_loss, 8.013460159301758, 1263
[INFO] 2021-07-12 18:56:16,211 [run_pretraining.py:  535]:	loss/mlm_loss, 8.013460159301758, 1263
[INFO] 2021-07-12 18:56:16,212 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2620000234164763e-05, 1263
[INFO] 2021-07-12 18:56:16,212 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1263
[INFO] 2021-07-12 18:56:16,212 [run_pretraining.py:  558]:	worker_index: 3, step: 1263, cost: 8.013460, mlm loss: 8.013460, speed: 1.105748 steps/s, speed: 8.845983 samples/s, speed: 4529.143251 tokens/s, learning rate: 1.262e-05, loss_scalings: 10737.418945, pp_loss: 7.634620
[INFO] 2021-07-12 18:56:16,212 [run_pretraining.py:  512]:	********exe.run_1263******* 
[INFO] 2021-07-12 18:56:17,113 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:17,114 [run_pretraining.py:  534]:	loss/total_loss, 7.246432781219482, 1264
[INFO] 2021-07-12 18:56:17,114 [run_pretraining.py:  535]:	loss/mlm_loss, 7.246432781219482, 1264
[INFO] 2021-07-12 18:56:17,114 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2630000128410757e-05, 1264
[INFO] 2021-07-12 18:56:17,114 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1264
[INFO] 2021-07-12 18:56:17,114 [run_pretraining.py:  558]:	worker_index: 3, step: 1264, cost: 7.246433, mlm loss: 7.246433, speed: 1.108911 steps/s, speed: 8.871288 samples/s, speed: 4542.099525 tokens/s, learning rate: 1.263e-05, loss_scalings: 10737.418945, pp_loss: 7.641695
[INFO] 2021-07-12 18:56:17,114 [run_pretraining.py:  512]:	********exe.run_1264******* 
[INFO] 2021-07-12 18:56:18,013 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:18,014 [run_pretraining.py:  534]:	loss/total_loss, 7.833538055419922, 1265
[INFO] 2021-07-12 18:56:18,014 [run_pretraining.py:  535]:	loss/mlm_loss, 7.833538055419922, 1265
[INFO] 2021-07-12 18:56:18,014 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2639999113162048e-05, 1265
[INFO] 2021-07-12 18:56:18,014 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1265
[INFO] 2021-07-12 18:56:18,014 [run_pretraining.py:  558]:	worker_index: 3, step: 1265, cost: 7.833538, mlm loss: 7.833538, speed: 1.111775 steps/s, speed: 8.894196 samples/s, speed: 4553.828541 tokens/s, learning rate: 1.264e-05, loss_scalings: 10737.418945, pp_loss: 7.790903
[INFO] 2021-07-12 18:56:18,014 [run_pretraining.py:  512]:	********exe.run_1265******* 
[INFO] 2021-07-12 18:56:18,939 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:18,939 [run_pretraining.py:  534]:	loss/total_loss, 7.8770976066589355, 1266
[INFO] 2021-07-12 18:56:18,939 [run_pretraining.py:  535]:	loss/mlm_loss, 7.8770976066589355, 1266
[INFO] 2021-07-12 18:56:18,939 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2649999007408042e-05, 1266
[INFO] 2021-07-12 18:56:18,940 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1266
[INFO] 2021-07-12 18:56:18,940 [run_pretraining.py:  558]:	worker_index: 3, step: 1266, cost: 7.877098, mlm loss: 7.877098, speed: 1.081362 steps/s, speed: 8.650894 samples/s, speed: 4429.257968 tokens/s, learning rate: 1.265e-05, loss_scalings: 10737.418945, pp_loss: 7.603180
[INFO] 2021-07-12 18:56:18,940 [run_pretraining.py:  512]:	********exe.run_1266******* 
[INFO] 2021-07-12 18:56:19,866 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:19,867 [run_pretraining.py:  534]:	loss/total_loss, 7.993962287902832, 1267
[INFO] 2021-07-12 18:56:19,867 [run_pretraining.py:  535]:	loss/mlm_loss, 7.993962287902832, 1267
[INFO] 2021-07-12 18:56:19,867 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2659999811148737e-05, 1267
[INFO] 2021-07-12 18:56:19,867 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1267
[INFO] 2021-07-12 18:56:19,867 [run_pretraining.py:  558]:	worker_index: 3, step: 1267, cost: 7.993962, mlm loss: 7.993962, speed: 1.079145 steps/s, speed: 8.633160 samples/s, speed: 4420.177669 tokens/s, learning rate: 1.266e-05, loss_scalings: 10737.418945, pp_loss: 7.927224
[INFO] 2021-07-12 18:56:19,867 [run_pretraining.py:  512]:	********exe.run_1267******* 
[INFO] 2021-07-12 18:56:20,788 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:20,788 [run_pretraining.py:  534]:	loss/total_loss, 7.658478736877441, 1268
[INFO] 2021-07-12 18:56:20,788 [run_pretraining.py:  535]:	loss/mlm_loss, 7.658478736877441, 1268
[INFO] 2021-07-12 18:56:20,789 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.266999970539473e-05, 1268
[INFO] 2021-07-12 18:56:20,789 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1268
[INFO] 2021-07-12 18:56:20,789 [run_pretraining.py:  558]:	worker_index: 3, step: 1268, cost: 7.658479, mlm loss: 7.658479, speed: 1.085615 steps/s, speed: 8.684920 samples/s, speed: 4446.679093 tokens/s, learning rate: 1.267e-05, loss_scalings: 10737.418945, pp_loss: 7.780291
[INFO] 2021-07-12 18:56:20,789 [run_pretraining.py:  512]:	********exe.run_1268******* 
[INFO] 2021-07-12 18:56:21,711 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:21,711 [run_pretraining.py:  534]:	loss/total_loss, 7.562175273895264, 1269
[INFO] 2021-07-12 18:56:21,711 [run_pretraining.py:  535]:	loss/mlm_loss, 7.562175273895264, 1269
[INFO] 2021-07-12 18:56:21,712 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2679999599640723e-05, 1269
[INFO] 2021-07-12 18:56:21,712 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1269
[INFO] 2021-07-12 18:56:21,712 [run_pretraining.py:  558]:	worker_index: 3, step: 1269, cost: 7.562175, mlm loss: 7.562175, speed: 1.084240 steps/s, speed: 8.673921 samples/s, speed: 4441.047791 tokens/s, learning rate: 1.268e-05, loss_scalings: 10737.418945, pp_loss: 7.785291
[INFO] 2021-07-12 18:56:21,712 [run_pretraining.py:  512]:	********exe.run_1269******* 
[INFO] 2021-07-12 18:56:22,622 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:22,622 [run_pretraining.py:  534]:	loss/total_loss, 7.5686116218566895, 1270
[INFO] 2021-07-12 18:56:22,622 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5686116218566895, 1270
[INFO] 2021-07-12 18:56:22,622 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2689999493886717e-05, 1270
[INFO] 2021-07-12 18:56:22,622 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1270
[INFO] 2021-07-12 18:56:22,622 [run_pretraining.py:  558]:	worker_index: 3, step: 1270, cost: 7.568612, mlm loss: 7.568612, speed: 1.098743 steps/s, speed: 8.789946 samples/s, speed: 4500.452324 tokens/s, learning rate: 1.269e-05, loss_scalings: 10737.418945, pp_loss: 6.922439
[INFO] 2021-07-12 18:56:22,623 [run_pretraining.py:  512]:	********exe.run_1270******* 
[INFO] 2021-07-12 18:56:23,545 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:23,546 [run_pretraining.py:  534]:	loss/total_loss, 7.391515731811523, 1271
[INFO] 2021-07-12 18:56:23,546 [run_pretraining.py:  535]:	loss/mlm_loss, 7.391515731811523, 1271
[INFO] 2021-07-12 18:56:23,546 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2700000297627412e-05, 1271
[INFO] 2021-07-12 18:56:23,546 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1271
[INFO] 2021-07-12 18:56:23,546 [run_pretraining.py:  558]:	worker_index: 3, step: 1271, cost: 7.391516, mlm loss: 7.391516, speed: 1.083428 steps/s, speed: 8.667422 samples/s, speed: 4437.719869 tokens/s, learning rate: 1.270e-05, loss_scalings: 10737.418945, pp_loss: 7.469208
[INFO] 2021-07-12 18:56:23,546 [run_pretraining.py:  512]:	********exe.run_1271******* 
[INFO] 2021-07-12 18:56:24,464 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:24,464 [run_pretraining.py:  534]:	loss/total_loss, 7.600622177124023, 1272
[INFO] 2021-07-12 18:56:24,465 [run_pretraining.py:  535]:	loss/mlm_loss, 7.600622177124023, 1272
[INFO] 2021-07-12 18:56:24,465 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2710000191873405e-05, 1272
[INFO] 2021-07-12 18:56:24,465 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1272
[INFO] 2021-07-12 18:56:24,465 [run_pretraining.py:  558]:	worker_index: 3, step: 1272, cost: 7.600622, mlm loss: 7.600622, speed: 1.089189 steps/s, speed: 8.713509 samples/s, speed: 4461.316401 tokens/s, learning rate: 1.271e-05, loss_scalings: 10737.418945, pp_loss: 7.447223
[INFO] 2021-07-12 18:56:24,465 [run_pretraining.py:  512]:	********exe.run_1272******* 
[INFO] 2021-07-12 18:56:25,384 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:25,385 [run_pretraining.py:  534]:	loss/total_loss, 7.622254371643066, 1273
[INFO] 2021-07-12 18:56:25,385 [run_pretraining.py:  535]:	loss/mlm_loss, 7.622254371643066, 1273
[INFO] 2021-07-12 18:56:25,385 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2720000086119398e-05, 1273
[INFO] 2021-07-12 18:56:25,385 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1273
[INFO] 2021-07-12 18:56:25,385 [run_pretraining.py:  558]:	worker_index: 3, step: 1273, cost: 7.622254, mlm loss: 7.622254, speed: 1.087391 steps/s, speed: 8.699130 samples/s, speed: 4453.954544 tokens/s, learning rate: 1.272e-05, loss_scalings: 10737.418945, pp_loss: 7.637938
[INFO] 2021-07-12 18:56:25,385 [run_pretraining.py:  512]:	********exe.run_1273******* 
[INFO] 2021-07-12 18:56:26,302 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:26,302 [run_pretraining.py:  534]:	loss/total_loss, 7.715197563171387, 1274
[INFO] 2021-07-12 18:56:26,303 [run_pretraining.py:  535]:	loss/mlm_loss, 7.715197563171387, 1274
[INFO] 2021-07-12 18:56:26,303 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.272999907087069e-05, 1274
[INFO] 2021-07-12 18:56:26,303 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1274
[INFO] 2021-07-12 18:56:26,303 [run_pretraining.py:  558]:	worker_index: 3, step: 1274, cost: 7.715198, mlm loss: 7.715198, speed: 1.090402 steps/s, speed: 8.723218 samples/s, speed: 4466.287380 tokens/s, learning rate: 1.273e-05, loss_scalings: 10737.418945, pp_loss: 7.755620
[INFO] 2021-07-12 18:56:26,303 [run_pretraining.py:  512]:	********exe.run_1274******* 
[INFO] 2021-07-12 18:56:27,205 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:27,206 [run_pretraining.py:  534]:	loss/total_loss, 6.9597487449646, 1275
[INFO] 2021-07-12 18:56:27,206 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9597487449646, 1275
[INFO] 2021-07-12 18:56:27,206 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2739998965116683e-05, 1275
[INFO] 2021-07-12 18:56:27,206 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1275
[INFO] 2021-07-12 18:56:27,206 [run_pretraining.py:  558]:	worker_index: 3, step: 1275, cost: 6.959749, mlm loss: 6.959749, speed: 1.107982 steps/s, speed: 8.863852 samples/s, speed: 4538.292380 tokens/s, learning rate: 1.274e-05, loss_scalings: 10737.418945, pp_loss: 7.596381
[INFO] 2021-07-12 18:56:27,206 [run_pretraining.py:  512]:	********exe.run_1275******* 
[INFO] 2021-07-12 18:56:28,118 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:28,118 [run_pretraining.py:  534]:	loss/total_loss, 7.657405376434326, 1276
[INFO] 2021-07-12 18:56:28,118 [run_pretraining.py:  535]:	loss/mlm_loss, 7.657405376434326, 1276
[INFO] 2021-07-12 18:56:28,118 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2749999768857379e-05, 1276
[INFO] 2021-07-12 18:56:28,118 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1276
[INFO] 2021-07-12 18:56:28,118 [run_pretraining.py:  558]:	worker_index: 3, step: 1276, cost: 7.657405, mlm loss: 7.657405, speed: 1.096814 steps/s, speed: 8.774509 samples/s, speed: 4492.548454 tokens/s, learning rate: 1.275e-05, loss_scalings: 10737.418945, pp_loss: 7.741500
[INFO] 2021-07-12 18:56:28,118 [run_pretraining.py:  512]:	********exe.run_1276******* 
[INFO] 2021-07-12 18:56:29,018 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:29,019 [run_pretraining.py:  534]:	loss/total_loss, 7.609105587005615, 1277
[INFO] 2021-07-12 18:56:29,019 [run_pretraining.py:  535]:	loss/mlm_loss, 7.609105587005615, 1277
[INFO] 2021-07-12 18:56:29,019 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2759999663103372e-05, 1277
[INFO] 2021-07-12 18:56:29,019 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1277
[INFO] 2021-07-12 18:56:29,019 [run_pretraining.py:  558]:	worker_index: 3, step: 1277, cost: 7.609106, mlm loss: 7.609106, speed: 1.111275 steps/s, speed: 8.890200 samples/s, speed: 4551.782265 tokens/s, learning rate: 1.276e-05, loss_scalings: 10737.418945, pp_loss: 7.591612
[INFO] 2021-07-12 18:56:29,019 [run_pretraining.py:  512]:	********exe.run_1277******* 
[INFO] 2021-07-12 18:56:29,917 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:29,917 [run_pretraining.py:  534]:	loss/total_loss, 4.4855451583862305, 1278
[INFO] 2021-07-12 18:56:29,918 [run_pretraining.py:  535]:	loss/mlm_loss, 4.4855451583862305, 1278
[INFO] 2021-07-12 18:56:29,918 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2769999557349365e-05, 1278
[INFO] 2021-07-12 18:56:29,918 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1278
[INFO] 2021-07-12 18:56:29,918 [run_pretraining.py:  558]:	worker_index: 3, step: 1278, cost: 4.485545, mlm loss: 4.485545, speed: 1.113237 steps/s, speed: 8.905893 samples/s, speed: 4559.817453 tokens/s, learning rate: 1.277e-05, loss_scalings: 10737.418945, pp_loss: 7.412948
[INFO] 2021-07-12 18:56:29,918 [run_pretraining.py:  512]:	********exe.run_1278******* 
[INFO] 2021-07-12 18:56:30,823 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:30,823 [run_pretraining.py:  534]:	loss/total_loss, 7.206504821777344, 1279
[INFO] 2021-07-12 18:56:30,823 [run_pretraining.py:  535]:	loss/mlm_loss, 7.206504821777344, 1279
[INFO] 2021-07-12 18:56:30,823 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.278000036109006e-05, 1279
[INFO] 2021-07-12 18:56:30,823 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1279
[INFO] 2021-07-12 18:56:30,824 [run_pretraining.py:  558]:	worker_index: 3, step: 1279, cost: 7.206505, mlm loss: 7.206505, speed: 1.104911 steps/s, speed: 8.839288 samples/s, speed: 4525.715423 tokens/s, learning rate: 1.278e-05, loss_scalings: 10737.418945, pp_loss: 7.506222
[INFO] 2021-07-12 18:56:30,824 [run_pretraining.py:  512]:	********exe.run_1279******* 
[INFO] 2021-07-12 18:56:31,735 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:31,735 [run_pretraining.py:  534]:	loss/total_loss, 7.528008937835693, 1280
[INFO] 2021-07-12 18:56:31,735 [run_pretraining.py:  535]:	loss/mlm_loss, 7.528008937835693, 1280
[INFO] 2021-07-12 18:56:31,736 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2790000255336054e-05, 1280
[INFO] 2021-07-12 18:56:31,736 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1280
[INFO] 2021-07-12 18:56:31,736 [run_pretraining.py:  558]:	worker_index: 3, step: 1280, cost: 7.528009, mlm loss: 7.528009, speed: 1.097125 steps/s, speed: 8.776997 samples/s, speed: 4493.822303 tokens/s, learning rate: 1.279e-05, loss_scalings: 10737.418945, pp_loss: 8.084667
[INFO] 2021-07-12 18:56:31,736 [run_pretraining.py:  512]:	********exe.run_1280******* 
[INFO] 2021-07-12 18:56:32,716 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:32,717 [run_pretraining.py:  534]:	loss/total_loss, 6.699603080749512, 1281
[INFO] 2021-07-12 18:56:32,717 [run_pretraining.py:  535]:	loss/mlm_loss, 6.699603080749512, 1281
[INFO] 2021-07-12 18:56:32,717 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2800000149582047e-05, 1281
[INFO] 2021-07-12 18:56:32,717 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1281
[INFO] 2021-07-12 18:56:32,717 [run_pretraining.py:  558]:	worker_index: 3, step: 1281, cost: 6.699603, mlm loss: 6.699603, speed: 1.019774 steps/s, speed: 8.158190 samples/s, speed: 4176.993340 tokens/s, learning rate: 1.280e-05, loss_scalings: 10737.418945, pp_loss: 7.389757
[INFO] 2021-07-12 18:56:32,717 [run_pretraining.py:  512]:	********exe.run_1281******* 
[INFO] 2021-07-12 18:56:33,777 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:33,778 [run_pretraining.py:  534]:	loss/total_loss, 8.050069808959961, 1282
[INFO] 2021-07-12 18:56:33,778 [run_pretraining.py:  535]:	loss/mlm_loss, 8.050069808959961, 1282
[INFO] 2021-07-12 18:56:33,778 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2809999134333339e-05, 1282
[INFO] 2021-07-12 18:56:33,778 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1282
[INFO] 2021-07-12 18:56:33,778 [run_pretraining.py:  558]:	worker_index: 3, step: 1282, cost: 8.050070, mlm loss: 8.050070, speed: 0.942845 steps/s, speed: 7.542763 samples/s, speed: 3861.894452 tokens/s, learning rate: 1.281e-05, loss_scalings: 10737.418945, pp_loss: 7.745290
[INFO] 2021-07-12 18:56:33,778 [run_pretraining.py:  512]:	********exe.run_1282******* 
[INFO] 2021-07-12 18:56:34,831 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:34,832 [run_pretraining.py:  534]:	loss/total_loss, 7.455096244812012, 1283
[INFO] 2021-07-12 18:56:34,832 [run_pretraining.py:  535]:	loss/mlm_loss, 7.455096244812012, 1283
[INFO] 2021-07-12 18:56:34,832 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2819999028579332e-05, 1283
[INFO] 2021-07-12 18:56:34,832 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1283
[INFO] 2021-07-12 18:56:34,832 [run_pretraining.py:  558]:	worker_index: 3, step: 1283, cost: 7.455096, mlm loss: 7.455096, speed: 0.949549 steps/s, speed: 7.596392 samples/s, speed: 3889.352552 tokens/s, learning rate: 1.282e-05, loss_scalings: 10737.418945, pp_loss: 7.361376
[INFO] 2021-07-12 18:56:34,832 [run_pretraining.py:  512]:	********exe.run_1283******* 
[INFO] 2021-07-12 18:56:35,893 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:35,893 [run_pretraining.py:  534]:	loss/total_loss, 7.725425720214844, 1284
[INFO] 2021-07-12 18:56:35,893 [run_pretraining.py:  535]:	loss/mlm_loss, 7.725425720214844, 1284
[INFO] 2021-07-12 18:56:35,893 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2829998922825325e-05, 1284
[INFO] 2021-07-12 18:56:35,894 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1284
[INFO] 2021-07-12 18:56:35,894 [run_pretraining.py:  558]:	worker_index: 3, step: 1284, cost: 7.725426, mlm loss: 7.725426, speed: 0.942528 steps/s, speed: 7.540220 samples/s, speed: 3860.592708 tokens/s, learning rate: 1.283e-05, loss_scalings: 10737.418945, pp_loss: 7.695407
[INFO] 2021-07-12 18:56:35,894 [run_pretraining.py:  512]:	********exe.run_1284******* 
[INFO] 2021-07-12 18:56:36,936 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:36,936 [run_pretraining.py:  534]:	loss/total_loss, 7.286792755126953, 1285
[INFO] 2021-07-12 18:56:36,936 [run_pretraining.py:  535]:	loss/mlm_loss, 7.286792755126953, 1285
[INFO] 2021-07-12 18:56:36,936 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.283999972656602e-05, 1285
[INFO] 2021-07-12 18:56:36,937 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1285
[INFO] 2021-07-12 18:56:36,937 [run_pretraining.py:  558]:	worker_index: 3, step: 1285, cost: 7.286793, mlm loss: 7.286793, speed: 0.959332 steps/s, speed: 7.674656 samples/s, speed: 3929.423805 tokens/s, learning rate: 1.284e-05, loss_scalings: 10737.418945, pp_loss: 7.543732
[INFO] 2021-07-12 18:56:36,937 [run_pretraining.py:  512]:	********exe.run_1285******* 
[INFO] 2021-07-12 18:56:37,996 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:37,996 [run_pretraining.py:  534]:	loss/total_loss, 7.45761775970459, 1286
[INFO] 2021-07-12 18:56:37,996 [run_pretraining.py:  535]:	loss/mlm_loss, 7.45761775970459, 1286
[INFO] 2021-07-12 18:56:37,996 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2849999620812014e-05, 1286
[INFO] 2021-07-12 18:56:37,996 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1286
[INFO] 2021-07-12 18:56:37,996 [run_pretraining.py:  558]:	worker_index: 3, step: 1286, cost: 7.457618, mlm loss: 7.457618, speed: 0.944120 steps/s, speed: 7.552958 samples/s, speed: 3867.114573 tokens/s, learning rate: 1.285e-05, loss_scalings: 10737.418945, pp_loss: 7.621367
[INFO] 2021-07-12 18:56:37,997 [run_pretraining.py:  512]:	********exe.run_1286******* 
[INFO] 2021-07-12 18:56:39,053 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:39,053 [run_pretraining.py:  534]:	loss/total_loss, 8.056690216064453, 1287
[INFO] 2021-07-12 18:56:39,053 [run_pretraining.py:  535]:	loss/mlm_loss, 8.056690216064453, 1287
[INFO] 2021-07-12 18:56:39,053 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2859999515058007e-05, 1287
[INFO] 2021-07-12 18:56:39,053 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1287
[INFO] 2021-07-12 18:56:39,053 [run_pretraining.py:  558]:	worker_index: 3, step: 1287, cost: 8.056690, mlm loss: 8.056690, speed: 0.946683 steps/s, speed: 7.573465 samples/s, speed: 3877.613896 tokens/s, learning rate: 1.286e-05, loss_scalings: 10737.418945, pp_loss: 7.661630
[INFO] 2021-07-12 18:56:39,053 [run_pretraining.py:  512]:	********exe.run_1287******* 
[INFO] 2021-07-12 18:56:40,097 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:40,097 [run_pretraining.py:  534]:	loss/total_loss, 7.62949275970459, 1288
[INFO] 2021-07-12 18:56:40,098 [run_pretraining.py:  535]:	loss/mlm_loss, 7.62949275970459, 1288
[INFO] 2021-07-12 18:56:40,098 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2870000318798702e-05, 1288
[INFO] 2021-07-12 18:56:40,098 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1288
[INFO] 2021-07-12 18:56:40,098 [run_pretraining.py:  558]:	worker_index: 3, step: 1288, cost: 7.629493, mlm loss: 7.629493, speed: 0.958125 steps/s, speed: 7.665003 samples/s, speed: 3924.481523 tokens/s, learning rate: 1.287e-05, loss_scalings: 10737.418945, pp_loss: 7.519506
[INFO] 2021-07-12 18:56:40,098 [run_pretraining.py:  512]:	********exe.run_1288******* 
[INFO] 2021-07-12 18:56:41,215 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:41,216 [run_pretraining.py:  534]:	loss/total_loss, 7.25753116607666, 1289
[INFO] 2021-07-12 18:56:41,216 [run_pretraining.py:  535]:	loss/mlm_loss, 7.25753116607666, 1289
[INFO] 2021-07-12 18:56:41,216 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2880000213044696e-05, 1289
[INFO] 2021-07-12 18:56:41,216 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1289
[INFO] 2021-07-12 18:56:41,216 [run_pretraining.py:  558]:	worker_index: 3, step: 1289, cost: 7.257531, mlm loss: 7.257531, speed: 0.894522 steps/s, speed: 7.156172 samples/s, speed: 3663.960089 tokens/s, learning rate: 1.288e-05, loss_scalings: 10737.418945, pp_loss: 7.623812
[INFO] 2021-07-12 18:56:41,216 [run_pretraining.py:  512]:	********exe.run_1289******* 
[INFO] 2021-07-12 18:56:42,117 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:42,118 [run_pretraining.py:  534]:	loss/total_loss, 7.77641487121582, 1290
[INFO] 2021-07-12 18:56:42,118 [run_pretraining.py:  535]:	loss/mlm_loss, 7.77641487121582, 1290
[INFO] 2021-07-12 18:56:42,118 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2890000107290689e-05, 1290
[INFO] 2021-07-12 18:56:42,118 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1290
[INFO] 2021-07-12 18:56:42,118 [run_pretraining.py:  558]:	worker_index: 3, step: 1290, cost: 7.776415, mlm loss: 7.776415, speed: 1.109987 steps/s, speed: 8.879897 samples/s, speed: 4546.507362 tokens/s, learning rate: 1.289e-05, loss_scalings: 10737.418945, pp_loss: 7.834675
[INFO] 2021-07-12 18:56:42,118 [run_pretraining.py:  512]:	********exe.run_1290******* 
[INFO] 2021-07-12 18:56:43,024 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:43,024 [run_pretraining.py:  534]:	loss/total_loss, 7.90836238861084, 1291
[INFO] 2021-07-12 18:56:43,024 [run_pretraining.py:  535]:	loss/mlm_loss, 7.90836238861084, 1291
[INFO] 2021-07-12 18:56:43,025 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.289999909204198e-05, 1291
[INFO] 2021-07-12 18:56:43,025 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1291
[INFO] 2021-07-12 18:56:43,025 [run_pretraining.py:  558]:	worker_index: 3, step: 1291, cost: 7.908362, mlm loss: 7.908362, speed: 1.103513 steps/s, speed: 8.828104 samples/s, speed: 4519.989314 tokens/s, learning rate: 1.290e-05, loss_scalings: 10737.418945, pp_loss: 7.645835
[INFO] 2021-07-12 18:56:43,025 [run_pretraining.py:  512]:	********exe.run_1291******* 
[INFO] 2021-07-12 18:56:43,924 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:43,925 [run_pretraining.py:  534]:	loss/total_loss, 7.451249122619629, 1292
[INFO] 2021-07-12 18:56:43,925 [run_pretraining.py:  535]:	loss/mlm_loss, 7.451249122619629, 1292
[INFO] 2021-07-12 18:56:43,925 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2909998986287974e-05, 1292
[INFO] 2021-07-12 18:56:43,925 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1292
[INFO] 2021-07-12 18:56:43,925 [run_pretraining.py:  558]:	worker_index: 3, step: 1292, cost: 7.451249, mlm loss: 7.451249, speed: 1.111148 steps/s, speed: 8.889182 samples/s, speed: 4551.261338 tokens/s, learning rate: 1.291e-05, loss_scalings: 10737.418945, pp_loss: 7.923459
[INFO] 2021-07-12 18:56:43,925 [run_pretraining.py:  512]:	********exe.run_1292******* 
[INFO] 2021-07-12 18:56:44,833 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:44,833 [run_pretraining.py:  534]:	loss/total_loss, 7.654837608337402, 1293
[INFO] 2021-07-12 18:56:44,833 [run_pretraining.py:  535]:	loss/mlm_loss, 7.654837608337402, 1293
[INFO] 2021-07-12 18:56:44,833 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2919998880533967e-05, 1293
[INFO] 2021-07-12 18:56:44,834 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1293
[INFO] 2021-07-12 18:56:44,834 [run_pretraining.py:  558]:	worker_index: 3, step: 1293, cost: 7.654838, mlm loss: 7.654838, speed: 1.101651 steps/s, speed: 8.813206 samples/s, speed: 4512.361597 tokens/s, learning rate: 1.292e-05, loss_scalings: 10737.418945, pp_loss: 7.706162
[INFO] 2021-07-12 18:56:44,834 [run_pretraining.py:  512]:	********exe.run_1293******* 
[INFO] 2021-07-12 18:56:45,736 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:45,737 [run_pretraining.py:  534]:	loss/total_loss, 7.4886627197265625, 1294
[INFO] 2021-07-12 18:56:45,737 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4886627197265625, 1294
[INFO] 2021-07-12 18:56:45,737 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2929999684274662e-05, 1294
[INFO] 2021-07-12 18:56:45,737 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1294
[INFO] 2021-07-12 18:56:45,737 [run_pretraining.py:  558]:	worker_index: 3, step: 1294, cost: 7.488663, mlm loss: 7.488663, speed: 1.107901 steps/s, speed: 8.863208 samples/s, speed: 4537.962720 tokens/s, learning rate: 1.293e-05, loss_scalings: 10737.418945, pp_loss: 7.546250
[INFO] 2021-07-12 18:56:45,737 [run_pretraining.py:  512]:	********exe.run_1294******* 
[INFO] 2021-07-12 18:56:46,636 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:46,637 [run_pretraining.py:  534]:	loss/total_loss, 8.101312637329102, 1295
[INFO] 2021-07-12 18:56:46,637 [run_pretraining.py:  535]:	loss/mlm_loss, 8.101312637329102, 1295
[INFO] 2021-07-12 18:56:46,637 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2939999578520656e-05, 1295
[INFO] 2021-07-12 18:56:46,637 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1295
[INFO] 2021-07-12 18:56:46,637 [run_pretraining.py:  558]:	worker_index: 3, step: 1295, cost: 8.101313, mlm loss: 8.101313, speed: 1.111595 steps/s, speed: 8.892758 samples/s, speed: 4553.092346 tokens/s, learning rate: 1.294e-05, loss_scalings: 10737.418945, pp_loss: 7.552433
[INFO] 2021-07-12 18:56:46,637 [run_pretraining.py:  512]:	********exe.run_1295******* 
[INFO] 2021-07-12 18:56:47,535 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:47,536 [run_pretraining.py:  534]:	loss/total_loss, 7.7479352951049805, 1296
[INFO] 2021-07-12 18:56:47,536 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7479352951049805, 1296
[INFO] 2021-07-12 18:56:47,536 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2949999472766649e-05, 1296
[INFO] 2021-07-12 18:56:47,536 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1296
[INFO] 2021-07-12 18:56:47,536 [run_pretraining.py:  558]:	worker_index: 3, step: 1296, cost: 7.747935, mlm loss: 7.747935, speed: 1.113010 steps/s, speed: 8.904078 samples/s, speed: 4558.888171 tokens/s, learning rate: 1.295e-05, loss_scalings: 10737.418945, pp_loss: 7.696843
[INFO] 2021-07-12 18:56:47,536 [run_pretraining.py:  512]:	********exe.run_1296******* 
[INFO] 2021-07-12 18:56:48,444 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:48,444 [run_pretraining.py:  534]:	loss/total_loss, 7.795858383178711, 1297
[INFO] 2021-07-12 18:56:48,444 [run_pretraining.py:  535]:	loss/mlm_loss, 7.795858383178711, 1297
[INFO] 2021-07-12 18:56:48,444 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2960000276507344e-05, 1297
[INFO] 2021-07-12 18:56:48,444 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1297
[INFO] 2021-07-12 18:56:48,444 [run_pretraining.py:  558]:	worker_index: 3, step: 1297, cost: 7.795858, mlm loss: 7.795858, speed: 1.101776 steps/s, speed: 8.814204 samples/s, speed: 4512.872472 tokens/s, learning rate: 1.296e-05, loss_scalings: 10737.418945, pp_loss: 7.714251
[INFO] 2021-07-12 18:56:48,445 [run_pretraining.py:  512]:	********exe.run_1297******* 
[INFO] 2021-07-12 18:56:49,343 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:49,344 [run_pretraining.py:  534]:	loss/total_loss, 7.027615070343018, 1298
[INFO] 2021-07-12 18:56:49,344 [run_pretraining.py:  535]:	loss/mlm_loss, 7.027615070343018, 1298
[INFO] 2021-07-12 18:56:49,344 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2970000170753337e-05, 1298
[INFO] 2021-07-12 18:56:49,344 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1298
[INFO] 2021-07-12 18:56:49,344 [run_pretraining.py:  558]:	worker_index: 3, step: 1298, cost: 7.027615, mlm loss: 7.027615, speed: 1.112117 steps/s, speed: 8.896937 samples/s, speed: 4555.231592 tokens/s, learning rate: 1.297e-05, loss_scalings: 10737.418945, pp_loss: 7.452927
[INFO] 2021-07-12 18:56:49,344 [run_pretraining.py:  512]:	********exe.run_1298******* 
[INFO] 2021-07-12 18:56:50,245 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:50,245 [run_pretraining.py:  534]:	loss/total_loss, 7.823489189147949, 1299
[INFO] 2021-07-12 18:56:50,245 [run_pretraining.py:  535]:	loss/mlm_loss, 7.823489189147949, 1299
[INFO] 2021-07-12 18:56:50,245 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.298000006499933e-05, 1299
[INFO] 2021-07-12 18:56:50,245 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1299
[INFO] 2021-07-12 18:56:50,245 [run_pretraining.py:  558]:	worker_index: 3, step: 1299, cost: 7.823489, mlm loss: 7.823489, speed: 1.110458 steps/s, speed: 8.883666 samples/s, speed: 4548.436902 tokens/s, learning rate: 1.298e-05, loss_scalings: 10737.418945, pp_loss: 7.875832
[INFO] 2021-07-12 18:56:50,246 [run_pretraining.py:  512]:	********exe.run_1299******* 
[INFO] 2021-07-12 18:56:51,229 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:51,230 [run_pretraining.py:  534]:	loss/total_loss, 7.657885551452637, 1300
[INFO] 2021-07-12 18:56:51,230 [run_pretraining.py:  535]:	loss/mlm_loss, 7.657885551452637, 1300
[INFO] 2021-07-12 18:56:51,230 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2989999049750622e-05, 1300
[INFO] 2021-07-12 18:56:51,230 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1300
[INFO] 2021-07-12 18:56:51,230 [run_pretraining.py:  558]:	worker_index: 3, step: 1300, cost: 7.657886, mlm loss: 7.657886, speed: 1.016293 steps/s, speed: 8.130346 samples/s, speed: 4162.736917 tokens/s, learning rate: 1.299e-05, loss_scalings: 10737.418945, pp_loss: 7.680567
[INFO] 2021-07-12 18:56:51,230 [run_pretraining.py:  512]:	********exe.run_1300******* 
[INFO] 2021-07-12 18:56:52,162 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:52,163 [run_pretraining.py:  534]:	loss/total_loss, 7.221062183380127, 1301
[INFO] 2021-07-12 18:56:52,163 [run_pretraining.py:  535]:	loss/mlm_loss, 7.221062183380127, 1301
[INFO] 2021-07-12 18:56:52,163 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2999998943996616e-05, 1301
[INFO] 2021-07-12 18:56:52,163 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1301
[INFO] 2021-07-12 18:56:52,163 [run_pretraining.py:  558]:	worker_index: 3, step: 1301, cost: 7.221062, mlm loss: 7.221062, speed: 1.072391 steps/s, speed: 8.579125 samples/s, speed: 4392.511806 tokens/s, learning rate: 1.300e-05, loss_scalings: 10737.418945, pp_loss: 6.847973
[INFO] 2021-07-12 18:56:52,163 [run_pretraining.py:  512]:	********exe.run_1301******* 
[INFO] 2021-07-12 18:56:53,062 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:53,063 [run_pretraining.py:  534]:	loss/total_loss, 8.103677749633789, 1302
[INFO] 2021-07-12 18:56:53,063 [run_pretraining.py:  535]:	loss/mlm_loss, 8.103677749633789, 1302
[INFO] 2021-07-12 18:56:53,063 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.300999974773731e-05, 1302
[INFO] 2021-07-12 18:56:53,063 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1302
[INFO] 2021-07-12 18:56:53,063 [run_pretraining.py:  558]:	worker_index: 3, step: 1302, cost: 8.103678, mlm loss: 8.103678, speed: 1.112199 steps/s, speed: 8.897593 samples/s, speed: 4555.567390 tokens/s, learning rate: 1.301e-05, loss_scalings: 10737.418945, pp_loss: 7.624667
[INFO] 2021-07-12 18:56:53,063 [run_pretraining.py:  512]:	********exe.run_1302******* 
[INFO] 2021-07-12 18:56:53,967 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:53,968 [run_pretraining.py:  534]:	loss/total_loss, 7.443652629852295, 1303
[INFO] 2021-07-12 18:56:53,968 [run_pretraining.py:  535]:	loss/mlm_loss, 7.443652629852295, 1303
[INFO] 2021-07-12 18:56:53,968 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3019999641983304e-05, 1303
[INFO] 2021-07-12 18:56:53,968 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1303
[INFO] 2021-07-12 18:56:53,968 [run_pretraining.py:  558]:	worker_index: 3, step: 1303, cost: 7.443653, mlm loss: 7.443653, speed: 1.105519 steps/s, speed: 8.844150 samples/s, speed: 4528.204944 tokens/s, learning rate: 1.302e-05, loss_scalings: 10737.418945, pp_loss: 7.498263
[INFO] 2021-07-12 18:56:53,968 [run_pretraining.py:  512]:	********exe.run_1303******* 
[INFO] 2021-07-12 18:56:54,871 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:54,871 [run_pretraining.py:  534]:	loss/total_loss, 7.195956707000732, 1304
[INFO] 2021-07-12 18:56:54,871 [run_pretraining.py:  535]:	loss/mlm_loss, 7.195956707000732, 1304
[INFO] 2021-07-12 18:56:54,871 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3029999536229298e-05, 1304
[INFO] 2021-07-12 18:56:54,871 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1304
[INFO] 2021-07-12 18:56:54,871 [run_pretraining.py:  558]:	worker_index: 3, step: 1304, cost: 7.195957, mlm loss: 7.195957, speed: 1.107977 steps/s, speed: 8.863812 samples/s, speed: 4538.272000 tokens/s, learning rate: 1.303e-05, loss_scalings: 10737.418945, pp_loss: 7.332545
[INFO] 2021-07-12 18:56:54,871 [run_pretraining.py:  512]:	********exe.run_1304******* 
[INFO] 2021-07-12 18:56:55,781 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:55,781 [run_pretraining.py:  534]:	loss/total_loss, 7.480530738830566, 1305
[INFO] 2021-07-12 18:56:55,781 [run_pretraining.py:  535]:	loss/mlm_loss, 7.480530738830566, 1305
[INFO] 2021-07-12 18:56:55,781 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3039999430475291e-05, 1305
[INFO] 2021-07-12 18:56:55,781 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1305
[INFO] 2021-07-12 18:56:55,782 [run_pretraining.py:  558]:	worker_index: 3, step: 1305, cost: 7.480531, mlm loss: 7.480531, speed: 1.099546 steps/s, speed: 8.796368 samples/s, speed: 4503.740436 tokens/s, learning rate: 1.304e-05, loss_scalings: 10737.418945, pp_loss: 7.828969
[INFO] 2021-07-12 18:56:55,782 [run_pretraining.py:  512]:	********exe.run_1305******* 
[INFO] 2021-07-12 18:56:56,675 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:56,676 [run_pretraining.py:  534]:	loss/total_loss, 3.2040772438049316, 1306
[INFO] 2021-07-12 18:56:56,676 [run_pretraining.py:  535]:	loss/mlm_loss, 3.2040772438049316, 1306
[INFO] 2021-07-12 18:56:56,676 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3050000234215986e-05, 1306
[INFO] 2021-07-12 18:56:56,676 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1306
[INFO] 2021-07-12 18:56:56,676 [run_pretraining.py:  558]:	worker_index: 3, step: 1306, cost: 3.204077, mlm loss: 3.204077, speed: 1.118836 steps/s, speed: 8.950684 samples/s, speed: 4582.750264 tokens/s, learning rate: 1.305e-05, loss_scalings: 10737.418945, pp_loss: 6.539974
[INFO] 2021-07-12 18:56:56,676 [run_pretraining.py:  512]:	********exe.run_1306******* 
[INFO] 2021-07-12 18:56:57,601 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:57,602 [run_pretraining.py:  534]:	loss/total_loss, 8.272571563720703, 1307
[INFO] 2021-07-12 18:56:57,602 [run_pretraining.py:  535]:	loss/mlm_loss, 8.272571563720703, 1307
[INFO] 2021-07-12 18:56:57,602 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.306000012846198e-05, 1307
[INFO] 2021-07-12 18:56:57,602 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1307
[INFO] 2021-07-12 18:56:57,602 [run_pretraining.py:  558]:	worker_index: 3, step: 1307, cost: 8.272572, mlm loss: 8.272572, speed: 1.080484 steps/s, speed: 8.643875 samples/s, speed: 4425.663786 tokens/s, learning rate: 1.306e-05, loss_scalings: 10737.418945, pp_loss: 7.775953
[INFO] 2021-07-12 18:56:57,602 [run_pretraining.py:  512]:	********exe.run_1307******* 
[INFO] 2021-07-12 18:56:58,522 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:58,523 [run_pretraining.py:  534]:	loss/total_loss, 7.365189075469971, 1308
[INFO] 2021-07-12 18:56:58,523 [run_pretraining.py:  535]:	loss/mlm_loss, 7.365189075469971, 1308
[INFO] 2021-07-12 18:56:58,523 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3070000022707973e-05, 1308
[INFO] 2021-07-12 18:56:58,523 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1308
[INFO] 2021-07-12 18:56:58,523 [run_pretraining.py:  558]:	worker_index: 3, step: 1308, cost: 7.365189, mlm loss: 7.365189, speed: 1.086366 steps/s, speed: 8.690931 samples/s, speed: 4449.756527 tokens/s, learning rate: 1.307e-05, loss_scalings: 10737.418945, pp_loss: 7.698905
[INFO] 2021-07-12 18:56:58,523 [run_pretraining.py:  512]:	********exe.run_1308******* 
[INFO] 2021-07-12 18:56:59,502 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:59,503 [run_pretraining.py:  534]:	loss/total_loss, 7.019944667816162, 1309
[INFO] 2021-07-12 18:56:59,503 [run_pretraining.py:  535]:	loss/mlm_loss, 7.019944667816162, 1309
[INFO] 2021-07-12 18:56:59,503 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3079999007459264e-05, 1309
[INFO] 2021-07-12 18:56:59,503 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1309
[INFO] 2021-07-12 18:56:59,503 [run_pretraining.py:  558]:	worker_index: 3, step: 1309, cost: 7.019945, mlm loss: 7.019945, speed: 1.021032 steps/s, speed: 8.168255 samples/s, speed: 4182.146573 tokens/s, learning rate: 1.308e-05, loss_scalings: 10737.418945, pp_loss: 7.524177
[INFO] 2021-07-12 18:56:59,503 [run_pretraining.py:  512]:	********exe.run_1309******* 
[INFO] 2021-07-12 18:57:00,560 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:57:00,560 [run_pretraining.py:  534]:	loss/total_loss, 7.35674524307251, 1310
[INFO] 2021-07-12 18:57:00,560 [run_pretraining.py:  535]:	loss/mlm_loss, 7.35674524307251, 1310
[INFO] 2021-07-12 18:57:00,560 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3089998901705258e-05, 1310
[INFO] 2021-07-12 18:57:00,560 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1310
[INFO] 2021-07-12 18:57:00,561 [run_pretraining.py:  558]:	worker_index: 3, step: 1310, cost: 7.356745, mlm loss: 7.356745, speed: 0.946485 steps/s, speed: 7.571879 samples/s, speed: 3876.801877 tokens/s, learning rate: 1.309e-05, loss_scalings: 10737.418945, pp_loss: 7.191792
[INFO] 2021-07-12 18:57:00,561 [run_pretraining.py:  512]:	********exe.run_1310******* 
[INFO] 2021-07-12 18:57:28,154 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:57:28,155 [run_pretraining.py:  534]:	loss/total_loss, 7.827094554901123, 1311
[INFO] 2021-07-12 18:57:28,155 [run_pretraining.py:  535]:	loss/mlm_loss, 7.827094554901123, 1311
[INFO] 2021-07-12 18:57:28,155 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3099999705445953e-05, 1311
[INFO] 2021-07-12 18:57:28,155 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1311
[INFO] 2021-07-12 18:57:28,155 [run_pretraining.py:  558]:	worker_index: 3, step: 1311, cost: 7.827095, mlm loss: 7.827095, speed: 0.036240 steps/s, speed: 0.289921 samples/s, speed: 148.439456 tokens/s, learning rate: 1.310e-05, loss_scalings: 10737.418945, pp_loss: 7.603846
[INFO] 2021-07-12 18:57:28,155 [run_pretraining.py:  512]:	********exe.run_1311******* 
[INFO] 2021-07-12 18:57:56,328 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:57:56,329 [run_pretraining.py:  534]:	loss/total_loss, 7.412562847137451, 1312
[INFO] 2021-07-12 18:57:56,329 [run_pretraining.py:  535]:	loss/mlm_loss, 7.412562847137451, 1312
[INFO] 2021-07-12 18:57:56,329 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3109999599691946e-05, 1312
[INFO] 2021-07-12 18:57:56,329 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1312
[INFO] 2021-07-12 18:57:56,329 [run_pretraining.py:  558]:	worker_index: 3, step: 1312, cost: 7.412563, mlm loss: 7.412563, speed: 0.035494 steps/s, speed: 0.283955 samples/s, speed: 145.384811 tokens/s, learning rate: 1.311e-05, loss_scalings: 10737.418945, pp_loss: 6.995015
[INFO] 2021-07-12 18:57:56,329 [run_pretraining.py:  512]:	********exe.run_1312******* 
[INFO] 2021-07-12 18:57:57,266 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:57:57,266 [run_pretraining.py:  534]:	loss/total_loss, 6.981437683105469, 1313
[INFO] 2021-07-12 18:57:57,266 [run_pretraining.py:  535]:	loss/mlm_loss, 6.981437683105469, 1313
[INFO] 2021-07-12 18:57:57,266 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.311999949393794e-05, 1313
[INFO] 2021-07-12 18:57:57,266 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1313
[INFO] 2021-07-12 18:57:57,267 [run_pretraining.py:  558]:	worker_index: 3, step: 1313, cost: 6.981438, mlm loss: 6.981438, speed: 1.067509 steps/s, speed: 8.540073 samples/s, speed: 4372.517167 tokens/s, learning rate: 1.312e-05, loss_scalings: 10737.418945, pp_loss: 7.721044
[INFO] 2021-07-12 18:57:57,267 [run_pretraining.py:  512]:	********exe.run_1313******* 
[INFO] 2021-07-12 18:57:58,182 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:57:58,182 [run_pretraining.py:  534]:	loss/total_loss, 6.892237663269043, 1314
[INFO] 2021-07-12 18:57:58,183 [run_pretraining.py:  535]:	loss/mlm_loss, 6.892237663269043, 1314
[INFO] 2021-07-12 18:57:58,183 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3130000297678635e-05, 1314
[INFO] 2021-07-12 18:57:58,183 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1314
[INFO] 2021-07-12 18:57:58,183 [run_pretraining.py:  558]:	worker_index: 3, step: 1314, cost: 6.892238, mlm loss: 6.892238, speed: 1.092105 steps/s, speed: 8.736843 samples/s, speed: 4473.263761 tokens/s, learning rate: 1.313e-05, loss_scalings: 10737.418945, pp_loss: 7.383418
[INFO] 2021-07-12 18:57:58,183 [run_pretraining.py:  512]:	********exe.run_1314******* 
[INFO] 2021-07-12 18:57:59,138 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:57:59,138 [run_pretraining.py:  534]:	loss/total_loss, 7.484925746917725, 1315
[INFO] 2021-07-12 18:57:59,139 [run_pretraining.py:  535]:	loss/mlm_loss, 7.484925746917725, 1315
[INFO] 2021-07-12 18:57:59,139 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3140000191924628e-05, 1315
[INFO] 2021-07-12 18:57:59,139 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1315
[INFO] 2021-07-12 18:57:59,139 [run_pretraining.py:  558]:	worker_index: 3, step: 1315, cost: 7.484926, mlm loss: 7.484926, speed: 1.046778 steps/s, speed: 8.374225 samples/s, speed: 4287.603337 tokens/s, learning rate: 1.314e-05, loss_scalings: 10737.418945, pp_loss: 6.765176
[INFO] 2021-07-12 18:57:59,139 [run_pretraining.py:  512]:	********exe.run_1315******* 
[INFO] 2021-07-12 18:58:00,204 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:00,204 [run_pretraining.py:  534]:	loss/total_loss, 7.698503017425537, 1316
[INFO] 2021-07-12 18:58:00,204 [run_pretraining.py:  535]:	loss/mlm_loss, 7.698503017425537, 1316
[INFO] 2021-07-12 18:58:00,205 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3150000086170621e-05, 1316
[INFO] 2021-07-12 18:58:00,205 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1316
[INFO] 2021-07-12 18:58:00,205 [run_pretraining.py:  558]:	worker_index: 3, step: 1316, cost: 7.698503, mlm loss: 7.698503, speed: 0.938695 steps/s, speed: 7.509561 samples/s, speed: 3844.895378 tokens/s, learning rate: 1.315e-05, loss_scalings: 10737.418945, pp_loss: 7.457134
[INFO] 2021-07-12 18:58:00,205 [run_pretraining.py:  512]:	********exe.run_1316******* 
[INFO] 2021-07-12 18:58:01,270 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:01,270 [run_pretraining.py:  534]:	loss/total_loss, 7.2793779373168945, 1317
[INFO] 2021-07-12 18:58:01,270 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2793779373168945, 1317
[INFO] 2021-07-12 18:58:01,270 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3159999980416615e-05, 1317
[INFO] 2021-07-12 18:58:01,270 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1317
[INFO] 2021-07-12 18:58:01,271 [run_pretraining.py:  558]:	worker_index: 3, step: 1317, cost: 7.279378, mlm loss: 7.279378, speed: 0.938755 steps/s, speed: 7.510042 samples/s, speed: 3845.141496 tokens/s, learning rate: 1.316e-05, loss_scalings: 10737.418945, pp_loss: 7.478936
[INFO] 2021-07-12 18:58:01,271 [run_pretraining.py:  512]:	********exe.run_1317******* 
[INFO] 2021-07-12 18:58:02,354 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:02,355 [run_pretraining.py:  534]:	loss/total_loss, 8.590404510498047, 1318
[INFO] 2021-07-12 18:58:02,355 [run_pretraining.py:  535]:	loss/mlm_loss, 8.590404510498047, 1318
[INFO] 2021-07-12 18:58:02,355 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3169998965167906e-05, 1318
[INFO] 2021-07-12 18:58:02,355 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1318
[INFO] 2021-07-12 18:58:02,355 [run_pretraining.py:  558]:	worker_index: 3, step: 1318, cost: 8.590405, mlm loss: 8.590405, speed: 0.922797 steps/s, speed: 7.382375 samples/s, speed: 3779.776236 tokens/s, learning rate: 1.317e-05, loss_scalings: 10737.418945, pp_loss: 7.818919
[INFO] 2021-07-12 18:58:02,355 [run_pretraining.py:  512]:	********exe.run_1318******* 
[INFO] 2021-07-12 18:58:03,419 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:03,420 [run_pretraining.py:  534]:	loss/total_loss, 7.0580949783325195, 1319
[INFO] 2021-07-12 18:58:03,420 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0580949783325195, 1319
[INFO] 2021-07-12 18:58:03,420 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.31799988594139e-05, 1319
[INFO] 2021-07-12 18:58:03,420 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1319
[INFO] 2021-07-12 18:58:03,420 [run_pretraining.py:  558]:	worker_index: 3, step: 1319, cost: 7.058095, mlm loss: 7.058095, speed: 0.939568 steps/s, speed: 7.516548 samples/s, speed: 3848.472345 tokens/s, learning rate: 1.318e-05, loss_scalings: 10737.418945, pp_loss: 7.340004
[INFO] 2021-07-12 18:58:03,420 [run_pretraining.py:  512]:	********exe.run_1319******* 
[INFO] 2021-07-12 18:58:04,487 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:04,488 [run_pretraining.py:  534]:	loss/total_loss, 7.1497721672058105, 1320
[INFO] 2021-07-12 18:58:04,488 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1497721672058105, 1320
[INFO] 2021-07-12 18:58:04,488 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3189999663154595e-05, 1320
[INFO] 2021-07-12 18:58:04,488 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1320
[INFO] 2021-07-12 18:58:04,488 [run_pretraining.py:  558]:	worker_index: 3, step: 1320, cost: 7.149772, mlm loss: 7.149772, speed: 0.936826 steps/s, speed: 7.494610 samples/s, speed: 3837.240182 tokens/s, learning rate: 1.319e-05, loss_scalings: 10737.418945, pp_loss: 7.368301
[INFO] 2021-07-12 18:58:04,488 [run_pretraining.py:  512]:	********exe.run_1320******* 
[INFO] 2021-07-12 18:58:05,540 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:05,541 [run_pretraining.py:  534]:	loss/total_loss, 7.159087181091309, 1321
[INFO] 2021-07-12 18:58:05,541 [run_pretraining.py:  535]:	loss/mlm_loss, 7.159087181091309, 1321
[INFO] 2021-07-12 18:58:05,541 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3199999557400588e-05, 1321
[INFO] 2021-07-12 18:58:05,541 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1321
[INFO] 2021-07-12 18:58:05,541 [run_pretraining.py:  558]:	worker_index: 3, step: 1321, cost: 7.159087, mlm loss: 7.159087, speed: 0.950026 steps/s, speed: 7.600210 samples/s, speed: 3891.307388 tokens/s, learning rate: 1.320e-05, loss_scalings: 10737.418945, pp_loss: 6.652329
[INFO] 2021-07-12 18:58:05,541 [run_pretraining.py:  512]:	********exe.run_1321******* 
[INFO] 2021-07-12 18:58:06,597 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:06,597 [run_pretraining.py:  534]:	loss/total_loss, 7.444087505340576, 1322
[INFO] 2021-07-12 18:58:06,598 [run_pretraining.py:  535]:	loss/mlm_loss, 7.444087505340576, 1322
[INFO] 2021-07-12 18:58:06,598 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3209999451646581e-05, 1322
[INFO] 2021-07-12 18:58:06,598 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1322
[INFO] 2021-07-12 18:58:06,598 [run_pretraining.py:  558]:	worker_index: 3, step: 1322, cost: 7.444088, mlm loss: 7.444088, speed: 0.946943 steps/s, speed: 7.575544 samples/s, speed: 3878.678436 tokens/s, learning rate: 1.321e-05, loss_scalings: 10737.418945, pp_loss: 7.121844
[INFO] 2021-07-12 18:58:06,598 [run_pretraining.py:  512]:	********exe.run_1322******* 
[INFO] 2021-07-12 18:58:07,658 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:07,659 [run_pretraining.py:  534]:	loss/total_loss, 7.805006980895996, 1323
[INFO] 2021-07-12 18:58:07,659 [run_pretraining.py:  535]:	loss/mlm_loss, 7.805006980895996, 1323
[INFO] 2021-07-12 18:58:07,659 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3220000255387276e-05, 1323
[INFO] 2021-07-12 18:58:07,659 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1323
[INFO] 2021-07-12 18:58:07,659 [run_pretraining.py:  558]:	worker_index: 3, step: 1323, cost: 7.805007, mlm loss: 7.805007, speed: 0.942633 steps/s, speed: 7.541062 samples/s, speed: 3861.023922 tokens/s, learning rate: 1.322e-05, loss_scalings: 10737.418945, pp_loss: 7.441134
[INFO] 2021-07-12 18:58:07,659 [run_pretraining.py:  512]:	********exe.run_1323******* 
[INFO] 2021-07-12 18:58:08,719 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:08,720 [run_pretraining.py:  534]:	loss/total_loss, 7.252870082855225, 1324
[INFO] 2021-07-12 18:58:08,720 [run_pretraining.py:  535]:	loss/mlm_loss, 7.252870082855225, 1324
[INFO] 2021-07-12 18:58:08,720 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.323000014963327e-05, 1324
[INFO] 2021-07-12 18:58:08,720 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1324
[INFO] 2021-07-12 18:58:08,720 [run_pretraining.py:  558]:	worker_index: 3, step: 1324, cost: 7.252870, mlm loss: 7.252870, speed: 0.943216 steps/s, speed: 7.545728 samples/s, speed: 3863.412527 tokens/s, learning rate: 1.323e-05, loss_scalings: 10737.418945, pp_loss: 7.480993
[INFO] 2021-07-12 18:58:08,720 [run_pretraining.py:  512]:	********exe.run_1324******* 
[INFO] 2021-07-12 18:58:09,776 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:09,776 [run_pretraining.py:  534]:	loss/total_loss, 7.343317985534668, 1325
[INFO] 2021-07-12 18:58:09,776 [run_pretraining.py:  535]:	loss/mlm_loss, 7.343317985534668, 1325
[INFO] 2021-07-12 18:58:09,776 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3240000043879263e-05, 1325
[INFO] 2021-07-12 18:58:09,777 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1325
[INFO] 2021-07-12 18:58:09,777 [run_pretraining.py:  558]:	worker_index: 3, step: 1325, cost: 7.343318, mlm loss: 7.343318, speed: 0.947114 steps/s, speed: 7.576912 samples/s, speed: 3879.379110 tokens/s, learning rate: 1.324e-05, loss_scalings: 10737.418945, pp_loss: 6.887210
[INFO] 2021-07-12 18:58:09,777 [run_pretraining.py:  512]:	********exe.run_1325******* 
[INFO] 2021-07-12 18:58:10,840 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:10,840 [run_pretraining.py:  534]:	loss/total_loss, 7.162677764892578, 1326
[INFO] 2021-07-12 18:58:10,840 [run_pretraining.py:  535]:	loss/mlm_loss, 7.162677764892578, 1326
[INFO] 2021-07-12 18:58:10,840 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3249999028630555e-05, 1326
[INFO] 2021-07-12 18:58:10,840 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1326
[INFO] 2021-07-12 18:58:10,841 [run_pretraining.py:  558]:	worker_index: 3, step: 1326, cost: 7.162678, mlm loss: 7.162678, speed: 0.940521 steps/s, speed: 7.524168 samples/s, speed: 3852.373844 tokens/s, learning rate: 1.325e-05, loss_scalings: 10737.418945, pp_loss: 7.742733
[INFO] 2021-07-12 18:58:10,841 [run_pretraining.py:  512]:	********exe.run_1326******* 
[INFO] 2021-07-12 18:58:11,902 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:11,903 [run_pretraining.py:  534]:	loss/total_loss, 7.68889045715332, 1327
[INFO] 2021-07-12 18:58:11,903 [run_pretraining.py:  535]:	loss/mlm_loss, 7.68889045715332, 1327
[INFO] 2021-07-12 18:58:11,903 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3259998922876548e-05, 1327
[INFO] 2021-07-12 18:58:11,903 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1327
[INFO] 2021-07-12 18:58:11,903 [run_pretraining.py:  558]:	worker_index: 3, step: 1327, cost: 7.688890, mlm loss: 7.688890, speed: 0.941734 steps/s, speed: 7.533868 samples/s, speed: 3857.340450 tokens/s, learning rate: 1.326e-05, loss_scalings: 10737.418945, pp_loss: 7.685221
[INFO] 2021-07-12 18:58:11,903 [run_pretraining.py:  512]:	********exe.run_1327******* 
[INFO] 2021-07-12 18:58:12,981 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:12,982 [run_pretraining.py:  534]:	loss/total_loss, 7.055217742919922, 1328
[INFO] 2021-07-12 18:58:12,982 [run_pretraining.py:  535]:	loss/mlm_loss, 7.055217742919922, 1328
[INFO] 2021-07-12 18:58:12,982 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3269999726617243e-05, 1328
[INFO] 2021-07-12 18:58:12,982 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1328
[INFO] 2021-07-12 18:58:12,982 [run_pretraining.py:  558]:	worker_index: 3, step: 1328, cost: 7.055218, mlm loss: 7.055218, speed: 0.927422 steps/s, speed: 7.419376 samples/s, speed: 3798.720495 tokens/s, learning rate: 1.327e-05, loss_scalings: 10737.418945, pp_loss: 7.436710
[INFO] 2021-07-12 18:58:12,982 [run_pretraining.py:  512]:	********exe.run_1328******* 
[INFO] 2021-07-12 18:58:14,058 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:14,059 [run_pretraining.py:  534]:	loss/total_loss, 7.424709320068359, 1329
[INFO] 2021-07-12 18:58:14,059 [run_pretraining.py:  535]:	loss/mlm_loss, 7.424709320068359, 1329
[INFO] 2021-07-12 18:58:14,059 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3279999620863236e-05, 1329
[INFO] 2021-07-12 18:58:14,059 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1329
[INFO] 2021-07-12 18:58:14,059 [run_pretraining.py:  558]:	worker_index: 3, step: 1329, cost: 7.424709, mlm loss: 7.424709, speed: 0.928882 steps/s, speed: 7.431059 samples/s, speed: 3804.701962 tokens/s, learning rate: 1.328e-05, loss_scalings: 10737.418945, pp_loss: 7.524065
[INFO] 2021-07-12 18:58:14,059 [run_pretraining.py:  512]:	********exe.run_1329******* 
[INFO] 2021-07-12 18:58:15,124 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:15,125 [run_pretraining.py:  534]:	loss/total_loss, 7.647080898284912, 1330
[INFO] 2021-07-12 18:58:15,125 [run_pretraining.py:  535]:	loss/mlm_loss, 7.647080898284912, 1330
[INFO] 2021-07-12 18:58:15,125 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.328999951510923e-05, 1330
[INFO] 2021-07-12 18:58:15,125 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1330
[INFO] 2021-07-12 18:58:15,125 [run_pretraining.py:  558]:	worker_index: 3, step: 1330, cost: 7.647081, mlm loss: 7.647081, speed: 0.938661 steps/s, speed: 7.509291 samples/s, speed: 3844.756843 tokens/s, learning rate: 1.329e-05, loss_scalings: 10737.418945, pp_loss: 7.586863
[INFO] 2021-07-12 18:58:15,125 [run_pretraining.py:  512]:	********exe.run_1330******* 
[INFO] 2021-07-12 18:58:16,183 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:16,183 [run_pretraining.py:  534]:	loss/total_loss, 7.9279632568359375, 1331
[INFO] 2021-07-12 18:58:16,183 [run_pretraining.py:  535]:	loss/mlm_loss, 7.9279632568359375, 1331
[INFO] 2021-07-12 18:58:16,183 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3299999409355223e-05, 1331
[INFO] 2021-07-12 18:58:16,183 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1331
[INFO] 2021-07-12 18:58:16,184 [run_pretraining.py:  558]:	worker_index: 3, step: 1331, cost: 7.927963, mlm loss: 7.927963, speed: 0.945404 steps/s, speed: 7.563232 samples/s, speed: 3872.375011 tokens/s, learning rate: 1.330e-05, loss_scalings: 10737.418945, pp_loss: 7.790585
[INFO] 2021-07-12 18:58:16,184 [run_pretraining.py:  512]:	********exe.run_1331******* 
[INFO] 2021-07-12 18:58:17,246 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:17,247 [run_pretraining.py:  534]:	loss/total_loss, 7.169353485107422, 1332
[INFO] 2021-07-12 18:58:17,247 [run_pretraining.py:  535]:	loss/mlm_loss, 7.169353485107422, 1332
[INFO] 2021-07-12 18:58:17,247 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3310000213095918e-05, 1332
[INFO] 2021-07-12 18:58:17,247 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1332
[INFO] 2021-07-12 18:58:17,247 [run_pretraining.py:  558]:	worker_index: 3, step: 1332, cost: 7.169353, mlm loss: 7.169353, speed: 0.940978 steps/s, speed: 7.527824 samples/s, speed: 3854.245846 tokens/s, learning rate: 1.331e-05, loss_scalings: 10737.418945, pp_loss: 7.410379
[INFO] 2021-07-12 18:58:17,247 [run_pretraining.py:  512]:	********exe.run_1332******* 
[INFO] 2021-07-12 18:58:18,301 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:18,302 [run_pretraining.py:  534]:	loss/total_loss, 7.431958198547363, 1333
[INFO] 2021-07-12 18:58:18,302 [run_pretraining.py:  535]:	loss/mlm_loss, 7.431958198547363, 1333
[INFO] 2021-07-12 18:58:18,302 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3320000107341912e-05, 1333
[INFO] 2021-07-12 18:58:18,302 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1333
[INFO] 2021-07-12 18:58:18,302 [run_pretraining.py:  558]:	worker_index: 3, step: 1333, cost: 7.431958, mlm loss: 7.431958, speed: 0.948348 steps/s, speed: 7.586780 samples/s, speed: 3884.431447 tokens/s, learning rate: 1.332e-05, loss_scalings: 10737.418945, pp_loss: 7.468307
[INFO] 2021-07-12 18:58:18,302 [run_pretraining.py:  512]:	********exe.run_1333******* 
[INFO] 2021-07-12 18:58:47,367 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:47,367 [run_pretraining.py:  534]:	loss/total_loss, 7.2175750732421875, 1334
[INFO] 2021-07-12 18:58:47,367 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2175750732421875, 1334
[INFO] 2021-07-12 18:58:47,368 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3330000001587905e-05, 1334
[INFO] 2021-07-12 18:58:47,368 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1334
[INFO] 2021-07-12 18:58:47,368 [run_pretraining.py:  558]:	worker_index: 3, step: 1334, cost: 7.217575, mlm loss: 7.217575, speed: 0.034406 steps/s, speed: 0.275245 samples/s, speed: 140.925250 tokens/s, learning rate: 1.333e-05, loss_scalings: 10737.418945, pp_loss: 7.335649
[INFO] 2021-07-12 18:58:47,368 [run_pretraining.py:  512]:	********exe.run_1334******* 
[INFO] 2021-07-12 18:58:48,259 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:48,260 [run_pretraining.py:  534]:	loss/total_loss, 7.05643367767334, 1335
[INFO] 2021-07-12 18:58:48,260 [run_pretraining.py:  535]:	loss/mlm_loss, 7.05643367767334, 1335
[INFO] 2021-07-12 18:58:48,260 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3339998986339197e-05, 1335
[INFO] 2021-07-12 18:58:48,260 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1335
[INFO] 2021-07-12 18:58:48,260 [run_pretraining.py:  558]:	worker_index: 3, step: 1335, cost: 7.056434, mlm loss: 7.056434, speed: 1.121212 steps/s, speed: 8.969694 samples/s, speed: 4592.483289 tokens/s, learning rate: 1.334e-05, loss_scalings: 10737.418945, pp_loss: 7.414815
[INFO] 2021-07-12 18:58:48,260 [run_pretraining.py:  512]:	********exe.run_1335******* 
[INFO] 2021-07-12 18:58:49,161 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:49,161 [run_pretraining.py:  534]:	loss/total_loss, 7.217437267303467, 1336
[INFO] 2021-07-12 18:58:49,161 [run_pretraining.py:  535]:	loss/mlm_loss, 7.217437267303467, 1336
[INFO] 2021-07-12 18:58:49,161 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.334999888058519e-05, 1336
[INFO] 2021-07-12 18:58:49,161 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1336
[INFO] 2021-07-12 18:58:49,161 [run_pretraining.py:  558]:	worker_index: 3, step: 1336, cost: 7.217437, mlm loss: 7.217437, speed: 1.110362 steps/s, speed: 8.882894 samples/s, speed: 4548.041953 tokens/s, learning rate: 1.335e-05, loss_scalings: 10737.418945, pp_loss: 7.645009
[INFO] 2021-07-12 18:58:49,162 [run_pretraining.py:  512]:	********exe.run_1336******* 
[INFO] 2021-07-12 18:58:50,062 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:50,063 [run_pretraining.py:  534]:	loss/total_loss, 7.614705562591553, 1337
[INFO] 2021-07-12 18:58:50,063 [run_pretraining.py:  535]:	loss/mlm_loss, 7.614705562591553, 1337
[INFO] 2021-07-12 18:58:50,063 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3359999684325885e-05, 1337
[INFO] 2021-07-12 18:58:50,063 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1337
[INFO] 2021-07-12 18:58:50,063 [run_pretraining.py:  558]:	worker_index: 3, step: 1337, cost: 7.614706, mlm loss: 7.614706, speed: 1.109693 steps/s, speed: 8.877543 samples/s, speed: 4545.302081 tokens/s, learning rate: 1.336e-05, loss_scalings: 10737.418945, pp_loss: 7.582701
[INFO] 2021-07-12 18:58:50,063 [run_pretraining.py:  512]:	********exe.run_1337******* 
[INFO] 2021-07-12 18:58:50,965 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:50,965 [run_pretraining.py:  534]:	loss/total_loss, 6.855395317077637, 1338
[INFO] 2021-07-12 18:58:50,965 [run_pretraining.py:  535]:	loss/mlm_loss, 6.855395317077637, 1338
[INFO] 2021-07-12 18:58:50,965 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3369999578571878e-05, 1338
[INFO] 2021-07-12 18:58:50,965 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1338
[INFO] 2021-07-12 18:58:50,965 [run_pretraining.py:  558]:	worker_index: 3, step: 1338, cost: 6.855395, mlm loss: 6.855395, speed: 1.109359 steps/s, speed: 8.874876 samples/s, speed: 4543.936387 tokens/s, learning rate: 1.337e-05, loss_scalings: 10737.418945, pp_loss: 7.453498
[INFO] 2021-07-12 18:58:50,965 [run_pretraining.py:  512]:	********exe.run_1338******* 
[INFO] 2021-07-12 18:58:51,864 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:51,864 [run_pretraining.py:  534]:	loss/total_loss, 8.059033393859863, 1339
[INFO] 2021-07-12 18:58:51,864 [run_pretraining.py:  535]:	loss/mlm_loss, 8.059033393859863, 1339
[INFO] 2021-07-12 18:58:51,864 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3379999472817872e-05, 1339
[INFO] 2021-07-12 18:58:51,864 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1339
[INFO] 2021-07-12 18:58:51,864 [run_pretraining.py:  558]:	worker_index: 3, step: 1339, cost: 8.059033, mlm loss: 8.059033, speed: 1.113132 steps/s, speed: 8.905059 samples/s, speed: 4559.390275 tokens/s, learning rate: 1.338e-05, loss_scalings: 10737.418945, pp_loss: 7.407078
[INFO] 2021-07-12 18:58:51,864 [run_pretraining.py:  512]:	********exe.run_1339******* 
[INFO] 2021-07-12 18:58:52,769 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:52,769 [run_pretraining.py:  534]:	loss/total_loss, 6.797906398773193, 1340
[INFO] 2021-07-12 18:58:52,770 [run_pretraining.py:  535]:	loss/mlm_loss, 6.797906398773193, 1340
[INFO] 2021-07-12 18:58:52,770 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3390000276558567e-05, 1340
[INFO] 2021-07-12 18:58:52,770 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1340
[INFO] 2021-07-12 18:58:52,770 [run_pretraining.py:  558]:	worker_index: 3, step: 1340, cost: 6.797906, mlm loss: 6.797906, speed: 1.105259 steps/s, speed: 8.842071 samples/s, speed: 4527.140568 tokens/s, learning rate: 1.339e-05, loss_scalings: 10737.418945, pp_loss: 7.646804
[INFO] 2021-07-12 18:58:52,770 [run_pretraining.py:  512]:	********exe.run_1340******* 
[INFO] 2021-07-12 18:58:53,669 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:53,670 [run_pretraining.py:  534]:	loss/total_loss, 7.549489974975586, 1341
[INFO] 2021-07-12 18:58:53,670 [run_pretraining.py:  535]:	loss/mlm_loss, 7.549489974975586, 1341
[INFO] 2021-07-12 18:58:53,670 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.340000017080456e-05, 1341
[INFO] 2021-07-12 18:58:53,670 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1341
[INFO] 2021-07-12 18:58:53,670 [run_pretraining.py:  558]:	worker_index: 3, step: 1341, cost: 7.549490, mlm loss: 7.549490, speed: 1.111694 steps/s, speed: 8.893548 samples/s, speed: 4553.496620 tokens/s, learning rate: 1.340e-05, loss_scalings: 10737.418945, pp_loss: 7.768385
[INFO] 2021-07-12 18:58:53,670 [run_pretraining.py:  512]:	********exe.run_1341******* 
[INFO] 2021-07-12 18:58:54,573 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:54,574 [run_pretraining.py:  534]:	loss/total_loss, 7.570449352264404, 1342
[INFO] 2021-07-12 18:58:54,574 [run_pretraining.py:  535]:	loss/mlm_loss, 7.570449352264404, 1342
[INFO] 2021-07-12 18:58:54,574 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3410000065050554e-05, 1342
[INFO] 2021-07-12 18:58:54,574 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1342
[INFO] 2021-07-12 18:58:54,574 [run_pretraining.py:  558]:	worker_index: 3, step: 1342, cost: 7.570449, mlm loss: 7.570449, speed: 1.106580 steps/s, speed: 8.852637 samples/s, speed: 4532.549968 tokens/s, learning rate: 1.341e-05, loss_scalings: 10737.418945, pp_loss: 7.626626
[INFO] 2021-07-12 18:58:54,574 [run_pretraining.py:  512]:	********exe.run_1342******* 
[INFO] 2021-07-12 18:58:55,481 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:55,481 [run_pretraining.py:  534]:	loss/total_loss, 7.6233062744140625, 1343
[INFO] 2021-07-12 18:58:55,481 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6233062744140625, 1343
[INFO] 2021-07-12 18:58:55,481 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3419999959296547e-05, 1343
[INFO] 2021-07-12 18:58:55,482 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1343
[INFO] 2021-07-12 18:58:55,482 [run_pretraining.py:  558]:	worker_index: 3, step: 1343, cost: 7.623306, mlm loss: 7.623306, speed: 1.102848 steps/s, speed: 8.822786 samples/s, speed: 4517.266498 tokens/s, learning rate: 1.342e-05, loss_scalings: 10737.418945, pp_loss: 7.617694
[INFO] 2021-07-12 18:58:55,482 [run_pretraining.py:  512]:	********exe.run_1343******* 
[INFO] 2021-07-12 18:58:56,383 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:56,383 [run_pretraining.py:  534]:	loss/total_loss, 7.4079813957214355, 1344
[INFO] 2021-07-12 18:58:56,383 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4079813957214355, 1344
[INFO] 2021-07-12 18:58:56,383 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3429998944047838e-05, 1344
[INFO] 2021-07-12 18:58:56,384 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1344
[INFO] 2021-07-12 18:58:56,384 [run_pretraining.py:  558]:	worker_index: 3, step: 1344, cost: 7.407981, mlm loss: 7.407981, speed: 1.109447 steps/s, speed: 8.875573 samples/s, speed: 4544.293359 tokens/s, learning rate: 1.343e-05, loss_scalings: 10737.418945, pp_loss: 7.668020
[INFO] 2021-07-12 18:58:56,384 [run_pretraining.py:  512]:	********exe.run_1344******* 
[INFO] 2021-07-12 18:58:57,286 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:57,286 [run_pretraining.py:  534]:	loss/total_loss, 7.764402389526367, 1345
[INFO] 2021-07-12 18:58:57,286 [run_pretraining.py:  535]:	loss/mlm_loss, 7.764402389526367, 1345
[INFO] 2021-07-12 18:58:57,287 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3439998838293832e-05, 1345
[INFO] 2021-07-12 18:58:57,287 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1345
[INFO] 2021-07-12 18:58:57,287 [run_pretraining.py:  558]:	worker_index: 3, step: 1345, cost: 7.764402, mlm loss: 7.764402, speed: 1.108115 steps/s, speed: 8.864920 samples/s, speed: 4538.839122 tokens/s, learning rate: 1.344e-05, loss_scalings: 10737.418945, pp_loss: 7.316930
[INFO] 2021-07-12 18:58:57,287 [run_pretraining.py:  512]:	********exe.run_1345******* 
[INFO] 2021-07-12 18:58:58,247 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:58,247 [run_pretraining.py:  534]:	loss/total_loss, 7.315300464630127, 1346
[INFO] 2021-07-12 18:58:58,247 [run_pretraining.py:  535]:	loss/mlm_loss, 7.315300464630127, 1346
[INFO] 2021-07-12 18:58:58,248 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3449999642034527e-05, 1346
[INFO] 2021-07-12 18:58:58,248 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1346
[INFO] 2021-07-12 18:58:58,248 [run_pretraining.py:  558]:	worker_index: 3, step: 1346, cost: 7.315300, mlm loss: 7.315300, speed: 1.041326 steps/s, speed: 8.330606 samples/s, speed: 4265.270351 tokens/s, learning rate: 1.345e-05, loss_scalings: 10737.418945, pp_loss: 7.323305
[INFO] 2021-07-12 18:58:58,248 [run_pretraining.py:  512]:	********exe.run_1346******* 
[INFO] 2021-07-12 18:58:59,305 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:59,305 [run_pretraining.py:  534]:	loss/total_loss, 3.6996469497680664, 1347
[INFO] 2021-07-12 18:58:59,306 [run_pretraining.py:  535]:	loss/mlm_loss, 3.6996469497680664, 1347
[INFO] 2021-07-12 18:58:59,306 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.345999953628052e-05, 1347
[INFO] 2021-07-12 18:58:59,306 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1347
[INFO] 2021-07-12 18:58:59,306 [run_pretraining.py:  558]:	worker_index: 3, step: 1347, cost: 3.699647, mlm loss: 3.699647, speed: 0.945656 steps/s, speed: 7.565248 samples/s, speed: 3873.406984 tokens/s, learning rate: 1.346e-05, loss_scalings: 10737.418945, pp_loss: 6.608501
[INFO] 2021-07-12 18:58:59,306 [run_pretraining.py:  512]:	********exe.run_1347******* 
[INFO] 2021-07-12 18:59:00,358 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:00,359 [run_pretraining.py:  534]:	loss/total_loss, 7.597387313842773, 1348
[INFO] 2021-07-12 18:59:00,359 [run_pretraining.py:  535]:	loss/mlm_loss, 7.597387313842773, 1348
[INFO] 2021-07-12 18:59:00,359 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3469999430526514e-05, 1348
[INFO] 2021-07-12 18:59:00,359 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1348
[INFO] 2021-07-12 18:59:00,359 [run_pretraining.py:  558]:	worker_index: 3, step: 1348, cost: 7.597387, mlm loss: 7.597387, speed: 0.950154 steps/s, speed: 7.601231 samples/s, speed: 3891.830126 tokens/s, learning rate: 1.347e-05, loss_scalings: 10737.418945, pp_loss: 7.522909
[INFO] 2021-07-12 18:59:00,359 [run_pretraining.py:  512]:	********exe.run_1348******* 
[INFO] 2021-07-12 18:59:01,353 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:01,353 [run_pretraining.py:  534]:	loss/total_loss, 7.044940948486328, 1349
[INFO] 2021-07-12 18:59:01,353 [run_pretraining.py:  535]:	loss/mlm_loss, 7.044940948486328, 1349
[INFO] 2021-07-12 18:59:01,353 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3480000234267209e-05, 1349
[INFO] 2021-07-12 18:59:01,353 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1349
[INFO] 2021-07-12 18:59:01,353 [run_pretraining.py:  558]:	worker_index: 3, step: 1349, cost: 7.044941, mlm loss: 7.044941, speed: 1.006187 steps/s, speed: 8.049499 samples/s, speed: 4121.343344 tokens/s, learning rate: 1.348e-05, loss_scalings: 10737.418945, pp_loss: 7.306136
[INFO] 2021-07-12 18:59:01,353 [run_pretraining.py:  512]:	********exe.run_1349******* 
[INFO] 2021-07-12 18:59:02,258 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:02,259 [run_pretraining.py:  534]:	loss/total_loss, 4.191041469573975, 1350
[INFO] 2021-07-12 18:59:02,259 [run_pretraining.py:  535]:	loss/mlm_loss, 4.191041469573975, 1350
[INFO] 2021-07-12 18:59:02,259 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3490000128513202e-05, 1350
[INFO] 2021-07-12 18:59:02,259 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1350
[INFO] 2021-07-12 18:59:02,259 [run_pretraining.py:  558]:	worker_index: 3, step: 1350, cost: 4.191041, mlm loss: 4.191041, speed: 1.105036 steps/s, speed: 8.840292 samples/s, speed: 4526.229326 tokens/s, learning rate: 1.349e-05, loss_scalings: 10737.418945, pp_loss: 6.638904
[INFO] 2021-07-12 18:59:02,259 [run_pretraining.py:  512]:	********exe.run_1350******* 
[INFO] 2021-07-12 18:59:03,161 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:03,162 [run_pretraining.py:  534]:	loss/total_loss, 8.223109245300293, 1351
[INFO] 2021-07-12 18:59:03,162 [run_pretraining.py:  535]:	loss/mlm_loss, 8.223109245300293, 1351
[INFO] 2021-07-12 18:59:03,162 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3500000022759195e-05, 1351
[INFO] 2021-07-12 18:59:03,162 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1351
[INFO] 2021-07-12 18:59:03,162 [run_pretraining.py:  558]:	worker_index: 3, step: 1351, cost: 8.223109, mlm loss: 8.223109, speed: 1.108224 steps/s, speed: 8.865789 samples/s, speed: 4539.284046 tokens/s, learning rate: 1.350e-05, loss_scalings: 10737.418945, pp_loss: 7.689238
[INFO] 2021-07-12 18:59:03,162 [run_pretraining.py:  512]:	********exe.run_1351******* 
[INFO] 2021-07-12 18:59:04,051 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:04,052 [run_pretraining.py:  534]:	loss/total_loss, 7.341071605682373, 1352
[INFO] 2021-07-12 18:59:04,052 [run_pretraining.py:  535]:	loss/mlm_loss, 7.341071605682373, 1352
[INFO] 2021-07-12 18:59:04,052 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3509999917005189e-05, 1352
[INFO] 2021-07-12 18:59:04,052 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1352
[INFO] 2021-07-12 18:59:04,052 [run_pretraining.py:  558]:	worker_index: 3, step: 1352, cost: 7.341072, mlm loss: 7.341072, speed: 1.124061 steps/s, speed: 8.992485 samples/s, speed: 4604.152233 tokens/s, learning rate: 1.351e-05, loss_scalings: 10737.418945, pp_loss: 6.708846
[INFO] 2021-07-12 18:59:04,052 [run_pretraining.py:  512]:	********exe.run_1352******* 
[INFO] 2021-07-12 18:59:04,952 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:04,952 [run_pretraining.py:  534]:	loss/total_loss, 8.271760940551758, 1353
[INFO] 2021-07-12 18:59:04,952 [run_pretraining.py:  535]:	loss/mlm_loss, 8.271760940551758, 1353
[INFO] 2021-07-12 18:59:04,953 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.351999890175648e-05, 1353
[INFO] 2021-07-12 18:59:04,953 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1353
[INFO] 2021-07-12 18:59:04,953 [run_pretraining.py:  558]:	worker_index: 3, step: 1353, cost: 8.271761, mlm loss: 8.271761, speed: 1.111219 steps/s, speed: 8.889755 samples/s, speed: 4551.554345 tokens/s, learning rate: 1.352e-05, loss_scalings: 10737.418945, pp_loss: 7.810720
[INFO] 2021-07-12 18:59:04,953 [run_pretraining.py:  512]:	********exe.run_1353******* 
[INFO] 2021-07-12 18:59:05,853 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:05,853 [run_pretraining.py:  534]:	loss/total_loss, 8.32359790802002, 1354
[INFO] 2021-07-12 18:59:05,853 [run_pretraining.py:  535]:	loss/mlm_loss, 8.32359790802002, 1354
[INFO] 2021-07-12 18:59:05,853 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3529998796002474e-05, 1354
[INFO] 2021-07-12 18:59:05,854 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1354
[INFO] 2021-07-12 18:59:05,854 [run_pretraining.py:  558]:	worker_index: 3, step: 1354, cost: 8.323598, mlm loss: 8.323598, speed: 1.110818 steps/s, speed: 8.886543 samples/s, speed: 4549.910136 tokens/s, learning rate: 1.353e-05, loss_scalings: 10737.418945, pp_loss: 7.974887
[INFO] 2021-07-12 18:59:05,854 [run_pretraining.py:  512]:	********exe.run_1354******* 
[INFO] 2021-07-12 18:59:06,750 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:06,751 [run_pretraining.py:  534]:	loss/total_loss, 7.639617443084717, 1355
[INFO] 2021-07-12 18:59:06,751 [run_pretraining.py:  535]:	loss/mlm_loss, 7.639617443084717, 1355
[INFO] 2021-07-12 18:59:06,751 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3539999599743169e-05, 1355
[INFO] 2021-07-12 18:59:06,751 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1355
[INFO] 2021-07-12 18:59:06,751 [run_pretraining.py:  558]:	worker_index: 3, step: 1355, cost: 7.639617, mlm loss: 7.639617, speed: 1.114777 steps/s, speed: 8.918214 samples/s, speed: 4566.125518 tokens/s, learning rate: 1.354e-05, loss_scalings: 10737.418945, pp_loss: 7.285824
[INFO] 2021-07-12 18:59:06,751 [run_pretraining.py:  512]:	********exe.run_1355******* 
[INFO] 2021-07-12 18:59:07,646 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:07,647 [run_pretraining.py:  534]:	loss/total_loss, 7.723689079284668, 1356
[INFO] 2021-07-12 18:59:07,647 [run_pretraining.py:  535]:	loss/mlm_loss, 7.723689079284668, 1356
[INFO] 2021-07-12 18:59:07,647 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3549999493989162e-05, 1356
[INFO] 2021-07-12 18:59:07,647 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1356
[INFO] 2021-07-12 18:59:07,647 [run_pretraining.py:  558]:	worker_index: 3, step: 1356, cost: 7.723689, mlm loss: 7.723689, speed: 1.116782 steps/s, speed: 8.934259 samples/s, speed: 4574.340572 tokens/s, learning rate: 1.355e-05, loss_scalings: 10737.418945, pp_loss: 7.584887
[INFO] 2021-07-12 18:59:07,647 [run_pretraining.py:  512]:	********exe.run_1356******* 
[INFO] 2021-07-12 18:59:08,550 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:08,550 [run_pretraining.py:  534]:	loss/total_loss, 8.083941459655762, 1357
[INFO] 2021-07-12 18:59:08,550 [run_pretraining.py:  535]:	loss/mlm_loss, 8.083941459655762, 1357
[INFO] 2021-07-12 18:59:08,550 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3559999388235155e-05, 1357
[INFO] 2021-07-12 18:59:08,551 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1357
[INFO] 2021-07-12 18:59:08,551 [run_pretraining.py:  558]:	worker_index: 3, step: 1357, cost: 8.083941, mlm loss: 8.083941, speed: 1.107914 steps/s, speed: 8.863309 samples/s, speed: 4538.014264 tokens/s, learning rate: 1.356e-05, loss_scalings: 10737.418945, pp_loss: 7.759813
[INFO] 2021-07-12 18:59:08,551 [run_pretraining.py:  512]:	********exe.run_1357******* 
[INFO] 2021-07-12 18:59:09,442 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:09,443 [run_pretraining.py:  534]:	loss/total_loss, 7.756369590759277, 1358
[INFO] 2021-07-12 18:59:09,443 [run_pretraining.py:  535]:	loss/mlm_loss, 7.756369590759277, 1358
[INFO] 2021-07-12 18:59:09,443 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.357000019197585e-05, 1358
[INFO] 2021-07-12 18:59:09,443 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1358
[INFO] 2021-07-12 18:59:09,443 [run_pretraining.py:  558]:	worker_index: 3, step: 1358, cost: 7.756370, mlm loss: 7.756370, speed: 1.121217 steps/s, speed: 8.969732 samples/s, speed: 4592.502932 tokens/s, learning rate: 1.357e-05, loss_scalings: 10737.418945, pp_loss: 7.789751
[INFO] 2021-07-12 18:59:09,443 [run_pretraining.py:  512]:	********exe.run_1358******* 
[INFO] 2021-07-12 18:59:10,352 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:10,352 [run_pretraining.py:  534]:	loss/total_loss, 7.698032855987549, 1359
[INFO] 2021-07-12 18:59:10,352 [run_pretraining.py:  535]:	loss/mlm_loss, 7.698032855987549, 1359
[INFO] 2021-07-12 18:59:10,352 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3580000086221844e-05, 1359
[INFO] 2021-07-12 18:59:10,352 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1359
[INFO] 2021-07-12 18:59:10,352 [run_pretraining.py:  558]:	worker_index: 3, step: 1359, cost: 7.698033, mlm loss: 7.698033, speed: 1.100564 steps/s, speed: 8.804516 samples/s, speed: 4507.912045 tokens/s, learning rate: 1.358e-05, loss_scalings: 10737.418945, pp_loss: 7.554284
[INFO] 2021-07-12 18:59:10,352 [run_pretraining.py:  512]:	********exe.run_1359******* 
[INFO] 2021-07-12 18:59:11,278 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:11,279 [run_pretraining.py:  534]:	loss/total_loss, 7.760512828826904, 1360
[INFO] 2021-07-12 18:59:11,279 [run_pretraining.py:  535]:	loss/mlm_loss, 7.760512828826904, 1360
[INFO] 2021-07-12 18:59:11,279 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3589999980467837e-05, 1360
[INFO] 2021-07-12 18:59:11,279 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1360
[INFO] 2021-07-12 18:59:11,279 [run_pretraining.py:  558]:	worker_index: 3, step: 1360, cost: 7.760513, mlm loss: 7.760513, speed: 1.080064 steps/s, speed: 8.640509 samples/s, speed: 4423.940650 tokens/s, learning rate: 1.359e-05, loss_scalings: 10737.418945, pp_loss: 7.763439
[INFO] 2021-07-12 18:59:11,279 [run_pretraining.py:  512]:	********exe.run_1360******* 
[INFO] 2021-07-12 18:59:12,179 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:12,180 [run_pretraining.py:  534]:	loss/total_loss, 7.245764255523682, 1361
[INFO] 2021-07-12 18:59:12,180 [run_pretraining.py:  535]:	loss/mlm_loss, 7.245764255523682, 1361
[INFO] 2021-07-12 18:59:12,180 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3600000784208532e-05, 1361
[INFO] 2021-07-12 18:59:12,180 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1361
[INFO] 2021-07-12 18:59:12,180 [run_pretraining.py:  558]:	worker_index: 3, step: 1361, cost: 7.245764, mlm loss: 7.245764, speed: 1.110080 steps/s, speed: 8.880638 samples/s, speed: 4546.886400 tokens/s, learning rate: 1.360e-05, loss_scalings: 10737.418945, pp_loss: 7.600696
[INFO] 2021-07-12 18:59:12,180 [run_pretraining.py:  512]:	********exe.run_1361******* 
[INFO] 2021-07-12 18:59:13,076 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:13,076 [run_pretraining.py:  534]:	loss/total_loss, 7.3735198974609375, 1362
[INFO] 2021-07-12 18:59:13,076 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3735198974609375, 1362
[INFO] 2021-07-12 18:59:13,077 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3609998859465122e-05, 1362
[INFO] 2021-07-12 18:59:13,077 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1362
[INFO] 2021-07-12 18:59:13,077 [run_pretraining.py:  558]:	worker_index: 3, step: 1362, cost: 7.373520, mlm loss: 7.373520, speed: 1.116423 steps/s, speed: 8.931384 samples/s, speed: 4572.868518 tokens/s, learning rate: 1.361e-05, loss_scalings: 10737.418945, pp_loss: 7.596025
[INFO] 2021-07-12 18:59:13,077 [run_pretraining.py:  512]:	********exe.run_1362******* 
[INFO] 2021-07-12 18:59:13,976 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:13,977 [run_pretraining.py:  534]:	loss/total_loss, 7.67099142074585, 1363
[INFO] 2021-07-12 18:59:13,977 [run_pretraining.py:  535]:	loss/mlm_loss, 7.67099142074585, 1363
[INFO] 2021-07-12 18:59:13,977 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3619999663205817e-05, 1363
[INFO] 2021-07-12 18:59:13,977 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1363
[INFO] 2021-07-12 18:59:13,977 [run_pretraining.py:  558]:	worker_index: 3, step: 1363, cost: 7.670991, mlm loss: 7.670991, speed: 1.111240 steps/s, speed: 8.889922 samples/s, speed: 4551.639963 tokens/s, learning rate: 1.362e-05, loss_scalings: 10737.418945, pp_loss: 7.541121
[INFO] 2021-07-12 18:59:13,977 [run_pretraining.py:  512]:	********exe.run_1363******* 
[INFO] 2021-07-12 18:59:14,878 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:14,879 [run_pretraining.py:  534]:	loss/total_loss, 7.384027481079102, 1364
[INFO] 2021-07-12 18:59:14,879 [run_pretraining.py:  535]:	loss/mlm_loss, 7.384027481079102, 1364
[INFO] 2021-07-12 18:59:14,879 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.362999955745181e-05, 1364
[INFO] 2021-07-12 18:59:14,879 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1364
[INFO] 2021-07-12 18:59:14,879 [run_pretraining.py:  558]:	worker_index: 3, step: 1364, cost: 7.384027, mlm loss: 7.384027, speed: 1.109581 steps/s, speed: 8.876646 samples/s, speed: 4544.842750 tokens/s, learning rate: 1.363e-05, loss_scalings: 10737.418945, pp_loss: 7.517816
[INFO] 2021-07-12 18:59:14,879 [run_pretraining.py:  512]:	********exe.run_1364******* 
[INFO] 2021-07-12 18:59:15,853 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:15,853 [run_pretraining.py:  534]:	loss/total_loss, 7.642791748046875, 1365
[INFO] 2021-07-12 18:59:15,853 [run_pretraining.py:  535]:	loss/mlm_loss, 7.642791748046875, 1365
[INFO] 2021-07-12 18:59:15,854 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3639999451697804e-05, 1365
[INFO] 2021-07-12 18:59:15,854 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1365
[INFO] 2021-07-12 18:59:15,854 [run_pretraining.py:  558]:	worker_index: 3, step: 1365, cost: 7.642792, mlm loss: 7.642792, speed: 1.026726 steps/s, speed: 8.213810 samples/s, speed: 4205.470675 tokens/s, learning rate: 1.364e-05, loss_scalings: 10737.418945, pp_loss: 6.600633
[INFO] 2021-07-12 18:59:15,854 [run_pretraining.py:  512]:	********exe.run_1365******* 
[INFO] 2021-07-12 18:59:16,754 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:16,755 [run_pretraining.py:  534]:	loss/total_loss, 7.575729846954346, 1366
[INFO] 2021-07-12 18:59:16,755 [run_pretraining.py:  535]:	loss/mlm_loss, 7.575729846954346, 1366
[INFO] 2021-07-12 18:59:16,755 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3649999345943797e-05, 1366
[INFO] 2021-07-12 18:59:16,755 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1366
[INFO] 2021-07-12 18:59:16,755 [run_pretraining.py:  558]:	worker_index: 3, step: 1366, cost: 7.575730, mlm loss: 7.575730, speed: 1.110479 steps/s, speed: 8.883830 samples/s, speed: 4548.521199 tokens/s, learning rate: 1.365e-05, loss_scalings: 10737.418945, pp_loss: 7.166671
[INFO] 2021-07-12 18:59:16,755 [run_pretraining.py:  512]:	********exe.run_1366******* 
[INFO] 2021-07-12 18:59:17,651 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:17,652 [run_pretraining.py:  534]:	loss/total_loss, 8.165742874145508, 1367
[INFO] 2021-07-12 18:59:17,652 [run_pretraining.py:  535]:	loss/mlm_loss, 8.165742874145508, 1367
[INFO] 2021-07-12 18:59:17,652 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3660000149684492e-05, 1367
[INFO] 2021-07-12 18:59:17,652 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1367
[INFO] 2021-07-12 18:59:17,652 [run_pretraining.py:  558]:	worker_index: 3, step: 1367, cost: 8.165743, mlm loss: 8.165743, speed: 1.114999 steps/s, speed: 8.919994 samples/s, speed: 4567.037115 tokens/s, learning rate: 1.366e-05, loss_scalings: 10737.418945, pp_loss: 7.685062
[INFO] 2021-07-12 18:59:17,652 [run_pretraining.py:  512]:	********exe.run_1367******* 
[INFO] 2021-07-12 18:59:18,554 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:18,555 [run_pretraining.py:  534]:	loss/total_loss, 7.761199951171875, 1368
[INFO] 2021-07-12 18:59:18,555 [run_pretraining.py:  535]:	loss/mlm_loss, 7.761199951171875, 1368
[INFO] 2021-07-12 18:59:18,555 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3670000043930486e-05, 1368
[INFO] 2021-07-12 18:59:18,555 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1368
[INFO] 2021-07-12 18:59:18,555 [run_pretraining.py:  558]:	worker_index: 3, step: 1368, cost: 7.761200, mlm loss: 7.761200, speed: 1.108617 steps/s, speed: 8.868936 samples/s, speed: 4540.895378 tokens/s, learning rate: 1.367e-05, loss_scalings: 10737.418945, pp_loss: 7.493817
[INFO] 2021-07-12 18:59:18,555 [run_pretraining.py:  512]:	********exe.run_1368******* 
[INFO] 2021-07-12 18:59:19,454 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:19,454 [run_pretraining.py:  534]:	loss/total_loss, 8.100213050842285, 1369
[INFO] 2021-07-12 18:59:19,455 [run_pretraining.py:  535]:	loss/mlm_loss, 8.100213050842285, 1369
[INFO] 2021-07-12 18:59:19,455 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.367999993817648e-05, 1369
[INFO] 2021-07-12 18:59:19,455 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1369
[INFO] 2021-07-12 18:59:19,455 [run_pretraining.py:  558]:	worker_index: 3, step: 1369, cost: 8.100213, mlm loss: 8.100213, speed: 1.112174 steps/s, speed: 8.897394 samples/s, speed: 4555.465920 tokens/s, learning rate: 1.368e-05, loss_scalings: 10737.418945, pp_loss: 7.780552
[INFO] 2021-07-12 18:59:19,455 [run_pretraining.py:  512]:	********exe.run_1369******* 
[INFO] 2021-07-12 18:59:20,349 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:20,350 [run_pretraining.py:  534]:	loss/total_loss, 7.997001647949219, 1370
[INFO] 2021-07-12 18:59:20,350 [run_pretraining.py:  535]:	loss/mlm_loss, 7.997001647949219, 1370
[INFO] 2021-07-12 18:59:20,350 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.368999892292777e-05, 1370
[INFO] 2021-07-12 18:59:20,350 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1370
[INFO] 2021-07-12 18:59:20,350 [run_pretraining.py:  558]:	worker_index: 3, step: 1370, cost: 7.997002, mlm loss: 7.997002, speed: 1.117634 steps/s, speed: 8.941075 samples/s, speed: 4577.830285 tokens/s, learning rate: 1.369e-05, loss_scalings: 10737.418945, pp_loss: 7.776850
[INFO] 2021-07-12 18:59:20,350 [run_pretraining.py:  512]:	********exe.run_1370******* 
[INFO] 2021-07-12 18:59:21,250 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:21,250 [run_pretraining.py:  534]:	loss/total_loss, 8.153404235839844, 1371
[INFO] 2021-07-12 18:59:21,251 [run_pretraining.py:  535]:	loss/mlm_loss, 8.153404235839844, 1371
[INFO] 2021-07-12 18:59:21,251 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3699998817173764e-05, 1371
[INFO] 2021-07-12 18:59:21,251 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1371
[INFO] 2021-07-12 18:59:21,251 [run_pretraining.py:  558]:	worker_index: 3, step: 1371, cost: 8.153404, mlm loss: 8.153404, speed: 1.111177 steps/s, speed: 8.889418 samples/s, speed: 4551.381912 tokens/s, learning rate: 1.370e-05, loss_scalings: 10737.418945, pp_loss: 7.844620
[INFO] 2021-07-12 18:59:21,251 [run_pretraining.py:  512]:	********exe.run_1371******* 
[INFO] 2021-07-12 18:59:22,154 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:22,154 [run_pretraining.py:  534]:	loss/total_loss, 7.359464168548584, 1372
[INFO] 2021-07-12 18:59:22,154 [run_pretraining.py:  535]:	loss/mlm_loss, 7.359464168548584, 1372
[INFO] 2021-07-12 18:59:22,154 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.370999962091446e-05, 1372
[INFO] 2021-07-12 18:59:22,154 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1372
[INFO] 2021-07-12 18:59:22,154 [run_pretraining.py:  558]:	worker_index: 3, step: 1372, cost: 7.359464, mlm loss: 7.359464, speed: 1.107381 steps/s, speed: 8.859048 samples/s, speed: 4535.832474 tokens/s, learning rate: 1.371e-05, loss_scalings: 10737.418945, pp_loss: 7.317539
[INFO] 2021-07-12 18:59:22,155 [run_pretraining.py:  512]:	********exe.run_1372******* 
[INFO] 2021-07-12 18:59:23,070 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:23,071 [run_pretraining.py:  534]:	loss/total_loss, 7.946598529815674, 1373
[INFO] 2021-07-12 18:59:23,071 [run_pretraining.py:  535]:	loss/mlm_loss, 7.946598529815674, 1373
[INFO] 2021-07-12 18:59:23,071 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3719999515160453e-05, 1373
[INFO] 2021-07-12 18:59:23,071 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1373
[INFO] 2021-07-12 18:59:23,071 [run_pretraining.py:  558]:	worker_index: 3, step: 1373, cost: 7.946599, mlm loss: 7.946599, speed: 1.091827 steps/s, speed: 8.734617 samples/s, speed: 4472.123771 tokens/s, learning rate: 1.372e-05, loss_scalings: 10737.418945, pp_loss: 7.277423
[INFO] 2021-07-12 18:59:23,071 [run_pretraining.py:  512]:	********exe.run_1373******* 
[INFO] 2021-07-12 18:59:23,982 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:23,983 [run_pretraining.py:  534]:	loss/total_loss, 7.8538594245910645, 1374
[INFO] 2021-07-12 18:59:23,983 [run_pretraining.py:  535]:	loss/mlm_loss, 7.8538594245910645, 1374
[INFO] 2021-07-12 18:59:23,983 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3729999409406446e-05, 1374
[INFO] 2021-07-12 18:59:23,983 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1374
[INFO] 2021-07-12 18:59:23,983 [run_pretraining.py:  558]:	worker_index: 3, step: 1374, cost: 7.853859, mlm loss: 7.853859, speed: 1.097341 steps/s, speed: 8.778728 samples/s, speed: 4494.708783 tokens/s, learning rate: 1.373e-05, loss_scalings: 10737.418945, pp_loss: 7.616677
[INFO] 2021-07-12 18:59:23,983 [run_pretraining.py:  512]:	********exe.run_1374******* 
[INFO] 2021-07-12 18:59:24,917 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:24,923 [run_pretraining.py:  534]:	loss/total_loss, 8.161110877990723, 1375
[INFO] 2021-07-12 18:59:24,928 [run_pretraining.py:  535]:	loss/mlm_loss, 8.161110877990723, 1375
[INFO] 2021-07-12 18:59:24,933 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3740000213147141e-05, 1375
[INFO] 2021-07-12 18:59:24,938 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1375
[INFO] 2021-07-12 18:59:24,945 [run_pretraining.py:  558]:	worker_index: 3, step: 1375, cost: 8.161111, mlm loss: 8.161111, speed: 1.064330 steps/s, speed: 8.514642 samples/s, speed: 4359.496564 tokens/s, learning rate: 1.374e-05, loss_scalings: 10737.418945, pp_loss: 7.567681
[INFO] 2021-07-12 18:59:24,945 [run_pretraining.py:  512]:	********exe.run_1375******* 
[INFO] 2021-07-12 18:59:25,845 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:25,846 [run_pretraining.py:  534]:	loss/total_loss, 7.6807050704956055, 1376
[INFO] 2021-07-12 18:59:25,846 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6807050704956055, 1376
[INFO] 2021-07-12 18:59:25,846 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3750000107393134e-05, 1376
[INFO] 2021-07-12 18:59:25,846 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1376
[INFO] 2021-07-12 18:59:25,846 [run_pretraining.py:  558]:	worker_index: 3, step: 1376, cost: 7.680705, mlm loss: 7.680705, speed: 1.110030 steps/s, speed: 8.880240 samples/s, speed: 4546.683036 tokens/s, learning rate: 1.375e-05, loss_scalings: 8589.935547, pp_loss: 7.353578
[INFO] 2021-07-12 18:59:25,846 [run_pretraining.py:  512]:	********exe.run_1376******* 
[INFO] 2021-07-12 18:59:26,741 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:26,742 [run_pretraining.py:  534]:	loss/total_loss, 7.7147674560546875, 1377
[INFO] 2021-07-12 18:59:26,742 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7147674560546875, 1377
[INFO] 2021-07-12 18:59:26,742 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3760000001639128e-05, 1377
[INFO] 2021-07-12 18:59:26,742 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1377
[INFO] 2021-07-12 18:59:26,742 [run_pretraining.py:  558]:	worker_index: 3, step: 1377, cost: 7.714767, mlm loss: 7.714767, speed: 1.116887 steps/s, speed: 8.935099 samples/s, speed: 4574.770556 tokens/s, learning rate: 1.376e-05, loss_scalings: 8589.935547, pp_loss: 7.688685
[INFO] 2021-07-12 18:59:26,742 [run_pretraining.py:  512]:	********exe.run_1377******* 
[INFO] 2021-07-12 18:59:27,637 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:27,638 [run_pretraining.py:  534]:	loss/total_loss, 7.719060897827148, 1378
[INFO] 2021-07-12 18:59:27,638 [run_pretraining.py:  535]:	loss/mlm_loss, 7.719060897827148, 1378
[INFO] 2021-07-12 18:59:27,638 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3769999895885121e-05, 1378
[INFO] 2021-07-12 18:59:27,638 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1378
[INFO] 2021-07-12 18:59:27,638 [run_pretraining.py:  558]:	worker_index: 3, step: 1378, cost: 7.719061, mlm loss: 7.719061, speed: 1.117075 steps/s, speed: 8.936603 samples/s, speed: 4575.540589 tokens/s, learning rate: 1.377e-05, loss_scalings: 8589.935547, pp_loss: 7.914097
[INFO] 2021-07-12 18:59:27,638 [run_pretraining.py:  512]:	********exe.run_1378******* 
[INFO] 2021-07-12 18:59:28,535 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:28,536 [run_pretraining.py:  534]:	loss/total_loss, 7.047550201416016, 1379
[INFO] 2021-07-12 18:59:28,536 [run_pretraining.py:  535]:	loss/mlm_loss, 7.047550201416016, 1379
[INFO] 2021-07-12 18:59:28,536 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3779998880636413e-05, 1379
[INFO] 2021-07-12 18:59:28,536 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1379
[INFO] 2021-07-12 18:59:28,536 [run_pretraining.py:  558]:	worker_index: 3, step: 1379, cost: 7.047550, mlm loss: 7.047550, speed: 1.114107 steps/s, speed: 8.912855 samples/s, speed: 4563.382003 tokens/s, learning rate: 1.378e-05, loss_scalings: 8589.935547, pp_loss: 7.440429
[INFO] 2021-07-12 18:59:28,536 [run_pretraining.py:  512]:	********exe.run_1379******* 
[INFO] 2021-07-12 18:59:29,435 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:29,435 [run_pretraining.py:  534]:	loss/total_loss, 7.640141487121582, 1380
[INFO] 2021-07-12 18:59:29,435 [run_pretraining.py:  535]:	loss/mlm_loss, 7.640141487121582, 1380
[INFO] 2021-07-12 18:59:29,436 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3789998774882406e-05, 1380
[INFO] 2021-07-12 18:59:29,436 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1380
[INFO] 2021-07-12 18:59:29,436 [run_pretraining.py:  558]:	worker_index: 3, step: 1380, cost: 7.640141, mlm loss: 7.640141, speed: 1.112625 steps/s, speed: 8.901001 samples/s, speed: 4557.312402 tokens/s, learning rate: 1.379e-05, loss_scalings: 8589.935547, pp_loss: 7.310550
[INFO] 2021-07-12 18:59:29,436 [run_pretraining.py:  512]:	********exe.run_1380******* 
[INFO] 2021-07-12 18:59:30,349 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:30,350 [run_pretraining.py:  534]:	loss/total_loss, 8.042025566101074, 1381
[INFO] 2021-07-12 18:59:30,350 [run_pretraining.py:  535]:	loss/mlm_loss, 8.042025566101074, 1381
[INFO] 2021-07-12 18:59:30,350 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3799999578623101e-05, 1381
[INFO] 2021-07-12 18:59:30,350 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1381
[INFO] 2021-07-12 18:59:30,350 [run_pretraining.py:  558]:	worker_index: 3, step: 1381, cost: 8.042026, mlm loss: 8.042026, speed: 1.094246 steps/s, speed: 8.753970 samples/s, speed: 4482.032778 tokens/s, learning rate: 1.380e-05, loss_scalings: 8589.935547, pp_loss: 7.539055
[INFO] 2021-07-12 18:59:30,350 [run_pretraining.py:  512]:	********exe.run_1381******* 
[INFO] 2021-07-12 18:59:31,249 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:31,250 [run_pretraining.py:  534]:	loss/total_loss, 7.116018772125244, 1382
[INFO] 2021-07-12 18:59:31,250 [run_pretraining.py:  535]:	loss/mlm_loss, 7.116018772125244, 1382
[INFO] 2021-07-12 18:59:31,250 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3809999472869094e-05, 1382
[INFO] 2021-07-12 18:59:31,250 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1382
[INFO] 2021-07-12 18:59:31,250 [run_pretraining.py:  558]:	worker_index: 3, step: 1382, cost: 7.116019, mlm loss: 7.116019, speed: 1.111864 steps/s, speed: 8.894913 samples/s, speed: 4554.195521 tokens/s, learning rate: 1.381e-05, loss_scalings: 8589.935547, pp_loss: 6.531412
[INFO] 2021-07-12 18:59:31,250 [run_pretraining.py:  512]:	********exe.run_1382******* 
[INFO] 2021-07-12 18:59:32,186 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:32,187 [run_pretraining.py:  534]:	loss/total_loss, 7.5065083503723145, 1383
[INFO] 2021-07-12 18:59:32,187 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5065083503723145, 1383
[INFO] 2021-07-12 18:59:32,187 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3819999367115088e-05, 1383
[INFO] 2021-07-12 18:59:32,187 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1383
[INFO] 2021-07-12 18:59:32,187 [run_pretraining.py:  558]:	worker_index: 3, step: 1383, cost: 7.506508, mlm loss: 7.506508, speed: 1.067883 steps/s, speed: 8.543064 samples/s, speed: 4374.049009 tokens/s, learning rate: 1.382e-05, loss_scalings: 8589.935547, pp_loss: 7.462018
[INFO] 2021-07-12 18:59:32,187 [run_pretraining.py:  512]:	********exe.run_1383******* 
[INFO] 2021-07-12 18:59:33,085 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:33,085 [run_pretraining.py:  534]:	loss/total_loss, 7.67920446395874, 1384
[INFO] 2021-07-12 18:59:33,085 [run_pretraining.py:  535]:	loss/mlm_loss, 7.67920446395874, 1384
[INFO] 2021-07-12 18:59:33,085 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3830000170855783e-05, 1384
[INFO] 2021-07-12 18:59:33,085 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1384
[INFO] 2021-07-12 18:59:33,085 [run_pretraining.py:  558]:	worker_index: 3, step: 1384, cost: 7.679204, mlm loss: 7.679204, speed: 1.114139 steps/s, speed: 8.913116 samples/s, speed: 4563.515342 tokens/s, learning rate: 1.383e-05, loss_scalings: 8589.935547, pp_loss: 7.674234
[INFO] 2021-07-12 18:59:33,086 [run_pretraining.py:  512]:	********exe.run_1384******* 
[INFO] 2021-07-12 18:59:33,988 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:33,988 [run_pretraining.py:  534]:	loss/total_loss, 8.081547737121582, 1385
[INFO] 2021-07-12 18:59:33,988 [run_pretraining.py:  535]:	loss/mlm_loss, 8.081547737121582, 1385
[INFO] 2021-07-12 18:59:33,989 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3840000065101776e-05, 1385
[INFO] 2021-07-12 18:59:33,989 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1385
[INFO] 2021-07-12 18:59:33,989 [run_pretraining.py:  558]:	worker_index: 3, step: 1385, cost: 8.081548, mlm loss: 8.081548, speed: 1.107970 steps/s, speed: 8.863763 samples/s, speed: 4538.246824 tokens/s, learning rate: 1.384e-05, loss_scalings: 8589.935547, pp_loss: 8.089295
[INFO] 2021-07-12 18:59:33,989 [run_pretraining.py:  512]:	********exe.run_1385******* 
[INFO] 2021-07-12 18:59:34,889 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:34,890 [run_pretraining.py:  534]:	loss/total_loss, 8.145243644714355, 1386
[INFO] 2021-07-12 18:59:34,890 [run_pretraining.py:  535]:	loss/mlm_loss, 8.145243644714355, 1386
[INFO] 2021-07-12 18:59:34,890 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.384999995934777e-05, 1386
[INFO] 2021-07-12 18:59:34,890 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1386
[INFO] 2021-07-12 18:59:34,890 [run_pretraining.py:  558]:	worker_index: 3, step: 1386, cost: 8.145244, mlm loss: 8.145244, speed: 1.109836 steps/s, speed: 8.878687 samples/s, speed: 4545.887801 tokens/s, learning rate: 1.385e-05, loss_scalings: 8589.935547, pp_loss: 8.007964
[INFO] 2021-07-12 18:59:34,890 [run_pretraining.py:  512]:	********exe.run_1386******* 
[INFO] 2021-07-12 18:59:35,797 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:35,797 [run_pretraining.py:  534]:	loss/total_loss, 7.542971611022949, 1387
[INFO] 2021-07-12 18:59:35,797 [run_pretraining.py:  535]:	loss/mlm_loss, 7.542971611022949, 1387
[INFO] 2021-07-12 18:59:35,797 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3860000763088465e-05, 1387
[INFO] 2021-07-12 18:59:35,798 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1387
[INFO] 2021-07-12 18:59:35,798 [run_pretraining.py:  558]:	worker_index: 3, step: 1387, cost: 7.542972, mlm loss: 7.542972, speed: 1.102919 steps/s, speed: 8.823355 samples/s, speed: 4517.557519 tokens/s, learning rate: 1.386e-05, loss_scalings: 8589.935547, pp_loss: 7.591160
[INFO] 2021-07-12 18:59:35,798 [run_pretraining.py:  512]:	********exe.run_1387******* 
[INFO] 2021-07-12 18:59:36,694 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:36,694 [run_pretraining.py:  534]:	loss/total_loss, 5.028230667114258, 1388
[INFO] 2021-07-12 18:59:36,694 [run_pretraining.py:  535]:	loss/mlm_loss, 5.028230667114258, 1388
[INFO] 2021-07-12 18:59:36,694 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3869998838345055e-05, 1388
[INFO] 2021-07-12 18:59:36,694 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1388
[INFO] 2021-07-12 18:59:36,694 [run_pretraining.py:  558]:	worker_index: 3, step: 1388, cost: 5.028231, mlm loss: 5.028231, speed: 1.115861 steps/s, speed: 8.926886 samples/s, speed: 4570.565542 tokens/s, learning rate: 1.387e-05, loss_scalings: 8589.935547, pp_loss: 6.966221
[INFO] 2021-07-12 18:59:36,695 [run_pretraining.py:  512]:	********exe.run_1388******* 
[INFO] 2021-07-12 18:59:37,652 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:37,652 [run_pretraining.py:  534]:	loss/total_loss, 7.847400188446045, 1389
[INFO] 2021-07-12 18:59:37,653 [run_pretraining.py:  535]:	loss/mlm_loss, 7.847400188446045, 1389
[INFO] 2021-07-12 18:59:37,653 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3879998732591048e-05, 1389
[INFO] 2021-07-12 18:59:37,653 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1389
[INFO] 2021-07-12 18:59:37,653 [run_pretraining.py:  558]:	worker_index: 3, step: 1389, cost: 7.847400, mlm loss: 7.847400, speed: 1.044131 steps/s, speed: 8.353049 samples/s, speed: 4276.761124 tokens/s, learning rate: 1.388e-05, loss_scalings: 8589.935547, pp_loss: 7.647966
[INFO] 2021-07-12 18:59:37,653 [run_pretraining.py:  512]:	********exe.run_1389******* 
[INFO] 2021-07-12 18:59:38,550 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:38,550 [run_pretraining.py:  534]:	loss/total_loss, 7.796030044555664, 1390
[INFO] 2021-07-12 18:59:38,550 [run_pretraining.py:  535]:	loss/mlm_loss, 7.796030044555664, 1390
[INFO] 2021-07-12 18:59:38,550 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3889999536331743e-05, 1390
[INFO] 2021-07-12 18:59:38,551 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1390
[INFO] 2021-07-12 18:59:38,551 [run_pretraining.py:  558]:	worker_index: 3, step: 1390, cost: 7.796030, mlm loss: 7.796030, speed: 1.114586 steps/s, speed: 8.916688 samples/s, speed: 4565.344093 tokens/s, learning rate: 1.389e-05, loss_scalings: 8589.935547, pp_loss: 7.945659
[INFO] 2021-07-12 18:59:38,551 [run_pretraining.py:  512]:	********exe.run_1390******* 
[INFO] 2021-07-12 18:59:39,448 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:39,449 [run_pretraining.py:  534]:	loss/total_loss, 7.786325454711914, 1391
[INFO] 2021-07-12 18:59:39,449 [run_pretraining.py:  535]:	loss/mlm_loss, 7.786325454711914, 1391
[INFO] 2021-07-12 18:59:39,449 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3899999430577736e-05, 1391
[INFO] 2021-07-12 18:59:39,449 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1391
[INFO] 2021-07-12 18:59:39,449 [run_pretraining.py:  558]:	worker_index: 3, step: 1391, cost: 7.786325, mlm loss: 7.786325, speed: 1.113947 steps/s, speed: 8.911575 samples/s, speed: 4562.726328 tokens/s, learning rate: 1.390e-05, loss_scalings: 8589.935547, pp_loss: 6.956186
[INFO] 2021-07-12 18:59:39,449 [run_pretraining.py:  512]:	********exe.run_1391******* 
[INFO] 2021-07-12 18:59:40,352 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:40,353 [run_pretraining.py:  534]:	loss/total_loss, 6.914888858795166, 1392
[INFO] 2021-07-12 18:59:40,353 [run_pretraining.py:  535]:	loss/mlm_loss, 6.914888858795166, 1392
[INFO] 2021-07-12 18:59:40,353 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.390999932482373e-05, 1392
[INFO] 2021-07-12 18:59:40,353 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1392
[INFO] 2021-07-12 18:59:40,353 [run_pretraining.py:  558]:	worker_index: 3, step: 1392, cost: 6.914889, mlm loss: 6.914889, speed: 1.106730 steps/s, speed: 8.853837 samples/s, speed: 4533.164702 tokens/s, learning rate: 1.391e-05, loss_scalings: 8589.935547, pp_loss: 7.339060
[INFO] 2021-07-12 18:59:40,353 [run_pretraining.py:  512]:	********exe.run_1392******* 
[INFO] 2021-07-12 18:59:41,247 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:41,247 [run_pretraining.py:  534]:	loss/total_loss, 7.662351608276367, 1393
[INFO] 2021-07-12 18:59:41,247 [run_pretraining.py:  535]:	loss/mlm_loss, 7.662351608276367, 1393
[INFO] 2021-07-12 18:59:41,248 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3920000128564425e-05, 1393
[INFO] 2021-07-12 18:59:41,248 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1393
[INFO] 2021-07-12 18:59:41,248 [run_pretraining.py:  558]:	worker_index: 3, step: 1393, cost: 7.662352, mlm loss: 7.662352, speed: 1.118745 steps/s, speed: 8.949961 samples/s, speed: 4582.379891 tokens/s, learning rate: 1.392e-05, loss_scalings: 8589.935547, pp_loss: 7.496305
[INFO] 2021-07-12 18:59:41,248 [run_pretraining.py:  512]:	********exe.run_1393******* 
[INFO] 2021-07-12 18:59:42,151 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:42,152 [run_pretraining.py:  534]:	loss/total_loss, 7.543982982635498, 1394
[INFO] 2021-07-12 18:59:42,152 [run_pretraining.py:  535]:	loss/mlm_loss, 7.543982982635498, 1394
[INFO] 2021-07-12 18:59:42,152 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3930000022810418e-05, 1394
[INFO] 2021-07-12 18:59:42,152 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1394
[INFO] 2021-07-12 18:59:42,152 [run_pretraining.py:  558]:	worker_index: 3, step: 1394, cost: 7.543983, mlm loss: 7.543983, speed: 1.106724 steps/s, speed: 8.853795 samples/s, speed: 4533.143171 tokens/s, learning rate: 1.393e-05, loss_scalings: 8589.935547, pp_loss: 7.433633
[INFO] 2021-07-12 18:59:42,152 [run_pretraining.py:  512]:	********exe.run_1394******* 
[INFO] 2021-07-12 18:59:43,055 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:43,055 [run_pretraining.py:  534]:	loss/total_loss, 7.802834510803223, 1395
[INFO] 2021-07-12 18:59:43,056 [run_pretraining.py:  535]:	loss/mlm_loss, 7.802834510803223, 1395
[INFO] 2021-07-12 18:59:43,056 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3939999917056412e-05, 1395
[INFO] 2021-07-12 18:59:43,056 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1395
[INFO] 2021-07-12 18:59:43,056 [run_pretraining.py:  558]:	worker_index: 3, step: 1395, cost: 7.802835, mlm loss: 7.802835, speed: 1.107154 steps/s, speed: 8.857233 samples/s, speed: 4534.903364 tokens/s, learning rate: 1.394e-05, loss_scalings: 8589.935547, pp_loss: 7.687154
[INFO] 2021-07-12 18:59:43,056 [run_pretraining.py:  512]:	********exe.run_1395******* 
[INFO] 2021-07-12 18:59:43,958 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:43,958 [run_pretraining.py:  534]:	loss/total_loss, 8.193031311035156, 1396
[INFO] 2021-07-12 18:59:43,958 [run_pretraining.py:  535]:	loss/mlm_loss, 8.193031311035156, 1396
[INFO] 2021-07-12 18:59:43,958 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3950000720797107e-05, 1396
[INFO] 2021-07-12 18:59:43,958 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1396
[INFO] 2021-07-12 18:59:43,959 [run_pretraining.py:  558]:	worker_index: 3, step: 1396, cost: 8.193031, mlm loss: 8.193031, speed: 1.108529 steps/s, speed: 8.868228 samples/s, speed: 4540.532939 tokens/s, learning rate: 1.395e-05, loss_scalings: 8589.935547, pp_loss: 7.470763
[INFO] 2021-07-12 18:59:43,959 [run_pretraining.py:  512]:	********exe.run_1396******* 
[INFO] 2021-07-12 18:59:44,855 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:44,856 [run_pretraining.py:  534]:	loss/total_loss, 7.366972923278809, 1397
[INFO] 2021-07-12 18:59:44,856 [run_pretraining.py:  535]:	loss/mlm_loss, 7.366972923278809, 1397
[INFO] 2021-07-12 18:59:44,856 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3959998796053696e-05, 1397
[INFO] 2021-07-12 18:59:44,856 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1397
[INFO] 2021-07-12 18:59:44,856 [run_pretraining.py:  558]:	worker_index: 3, step: 1397, cost: 7.366973, mlm loss: 7.366973, speed: 1.114700 steps/s, speed: 8.917598 samples/s, speed: 4565.810004 tokens/s, learning rate: 1.396e-05, loss_scalings: 8589.935547, pp_loss: 7.549841
[INFO] 2021-07-12 18:59:44,856 [run_pretraining.py:  512]:	********exe.run_1397******* 
[INFO] 2021-07-12 18:59:45,756 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:45,757 [run_pretraining.py:  534]:	loss/total_loss, 7.793806076049805, 1398
[INFO] 2021-07-12 18:59:45,757 [run_pretraining.py:  535]:	loss/mlm_loss, 7.793806076049805, 1398
[INFO] 2021-07-12 18:59:45,757 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3969999599794392e-05, 1398
[INFO] 2021-07-12 18:59:45,757 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1398
[INFO] 2021-07-12 18:59:45,757 [run_pretraining.py:  558]:	worker_index: 3, step: 1398, cost: 7.793806, mlm loss: 7.793806, speed: 1.110953 steps/s, speed: 8.887624 samples/s, speed: 4550.463296 tokens/s, learning rate: 1.397e-05, loss_scalings: 8589.935547, pp_loss: 7.590974
[INFO] 2021-07-12 18:59:45,757 [run_pretraining.py:  512]:	********exe.run_1398******* 
[INFO] 2021-07-12 18:59:46,650 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:46,651 [run_pretraining.py:  534]:	loss/total_loss, 7.976768970489502, 1399
[INFO] 2021-07-12 18:59:46,651 [run_pretraining.py:  535]:	loss/mlm_loss, 7.976768970489502, 1399
[INFO] 2021-07-12 18:59:46,651 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3979999494040385e-05, 1399
[INFO] 2021-07-12 18:59:46,651 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1399
[INFO] 2021-07-12 18:59:46,651 [run_pretraining.py:  558]:	worker_index: 3, step: 1399, cost: 7.976769, mlm loss: 7.976769, speed: 1.118924 steps/s, speed: 8.951389 samples/s, speed: 4583.110917 tokens/s, learning rate: 1.398e-05, loss_scalings: 8589.935547, pp_loss: 7.788703
[INFO] 2021-07-12 18:59:46,651 [run_pretraining.py:  512]:	********exe.run_1399******* 
[INFO] 2021-07-12 18:59:47,559 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:47,560 [run_pretraining.py:  534]:	loss/total_loss, 7.819199085235596, 1400
[INFO] 2021-07-12 18:59:47,560 [run_pretraining.py:  535]:	loss/mlm_loss, 7.819199085235596, 1400
[INFO] 2021-07-12 18:59:47,560 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3989999388286378e-05, 1400
[INFO] 2021-07-12 18:59:47,560 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1400
[INFO] 2021-07-12 18:59:47,560 [run_pretraining.py:  558]:	worker_index: 3, step: 1400, cost: 7.819199, mlm loss: 7.819199, speed: 1.101205 steps/s, speed: 8.809643 samples/s, speed: 4510.537142 tokens/s, learning rate: 1.399e-05, loss_scalings: 8589.935547, pp_loss: 7.538436
[INFO] 2021-07-12 18:59:47,560 [run_pretraining.py:  512]:	********exe.run_1400******* 
[INFO] 2021-07-12 18:59:48,456 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:48,457 [run_pretraining.py:  534]:	loss/total_loss, 7.3820037841796875, 1401
[INFO] 2021-07-12 18:59:48,457 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3820037841796875, 1401
[INFO] 2021-07-12 18:59:48,457 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3999999282532372e-05, 1401
[INFO] 2021-07-12 18:59:48,457 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1401
[INFO] 2021-07-12 18:59:48,457 [run_pretraining.py:  558]:	worker_index: 3, step: 1401, cost: 7.382004, mlm loss: 7.382004, speed: 1.115408 steps/s, speed: 8.923261 samples/s, speed: 4568.709522 tokens/s, learning rate: 1.400e-05, loss_scalings: 8589.935547, pp_loss: 7.612672
[INFO] 2021-07-12 18:59:48,457 [run_pretraining.py:  512]:	********exe.run_1401******* 
[INFO] 2021-07-12 18:59:49,358 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:49,358 [run_pretraining.py:  534]:	loss/total_loss, 7.633042812347412, 1402
[INFO] 2021-07-12 18:59:49,358 [run_pretraining.py:  535]:	loss/mlm_loss, 7.633042812347412, 1402
[INFO] 2021-07-12 18:59:49,358 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4010000086273067e-05, 1402
[INFO] 2021-07-12 18:59:49,358 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1402
[INFO] 2021-07-12 18:59:49,358 [run_pretraining.py:  558]:	worker_index: 3, step: 1402, cost: 7.633043, mlm loss: 7.633043, speed: 1.110467 steps/s, speed: 8.883736 samples/s, speed: 4548.473029 tokens/s, learning rate: 1.401e-05, loss_scalings: 8589.935547, pp_loss: 7.640039
[INFO] 2021-07-12 18:59:49,359 [run_pretraining.py:  512]:	********exe.run_1402******* 
[INFO] 2021-07-12 18:59:50,258 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:50,258 [run_pretraining.py:  534]:	loss/total_loss, 6.735032558441162, 1403
[INFO] 2021-07-12 18:59:50,258 [run_pretraining.py:  535]:	loss/mlm_loss, 6.735032558441162, 1403
[INFO] 2021-07-12 18:59:50,259 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.401999998051906e-05, 1403
[INFO] 2021-07-12 18:59:50,259 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1403
[INFO] 2021-07-12 18:59:50,259 [run_pretraining.py:  558]:	worker_index: 3, step: 1403, cost: 6.735033, mlm loss: 6.735033, speed: 1.111633 steps/s, speed: 8.893060 samples/s, speed: 4553.246806 tokens/s, learning rate: 1.402e-05, loss_scalings: 8589.935547, pp_loss: 6.894725
[INFO] 2021-07-12 18:59:50,259 [run_pretraining.py:  512]:	********exe.run_1403******* 
[INFO] 2021-07-12 18:59:51,153 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:51,154 [run_pretraining.py:  534]:	loss/total_loss, 7.616610527038574, 1404
[INFO] 2021-07-12 18:59:51,154 [run_pretraining.py:  535]:	loss/mlm_loss, 7.616610527038574, 1404
[INFO] 2021-07-12 18:59:51,154 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4029999874765053e-05, 1404
[INFO] 2021-07-12 18:59:51,154 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1404
[INFO] 2021-07-12 18:59:51,154 [run_pretraining.py:  558]:	worker_index: 3, step: 1404, cost: 7.616611, mlm loss: 7.616611, speed: 1.117272 steps/s, speed: 8.938174 samples/s, speed: 4576.345013 tokens/s, learning rate: 1.403e-05, loss_scalings: 8589.935547, pp_loss: 7.480403
[INFO] 2021-07-12 18:59:51,154 [run_pretraining.py:  512]:	********exe.run_1404******* 
[INFO] 2021-07-12 18:59:52,045 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:52,045 [run_pretraining.py:  534]:	loss/total_loss, 7.458614349365234, 1405
[INFO] 2021-07-12 18:59:52,045 [run_pretraining.py:  535]:	loss/mlm_loss, 7.458614349365234, 1405
[INFO] 2021-07-12 18:59:52,045 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4040000678505749e-05, 1405
[INFO] 2021-07-12 18:59:52,045 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1405
[INFO] 2021-07-12 18:59:52,046 [run_pretraining.py:  558]:	worker_index: 3, step: 1405, cost: 7.458614, mlm loss: 7.458614, speed: 1.122942 steps/s, speed: 8.983538 samples/s, speed: 4599.571627 tokens/s, learning rate: 1.404e-05, loss_scalings: 8589.935547, pp_loss: 7.626327
[INFO] 2021-07-12 18:59:52,046 [run_pretraining.py:  512]:	********exe.run_1405******* 
[INFO] 2021-07-12 18:59:52,940 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:52,941 [run_pretraining.py:  534]:	loss/total_loss, 7.621591091156006, 1406
[INFO] 2021-07-12 18:59:52,941 [run_pretraining.py:  535]:	loss/mlm_loss, 7.621591091156006, 1406
[INFO] 2021-07-12 18:59:52,941 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4049998753762338e-05, 1406
[INFO] 2021-07-12 18:59:52,941 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1406
[INFO] 2021-07-12 18:59:52,941 [run_pretraining.py:  558]:	worker_index: 3, step: 1406, cost: 7.621591, mlm loss: 7.621591, speed: 1.117289 steps/s, speed: 8.938312 samples/s, speed: 4576.415719 tokens/s, learning rate: 1.405e-05, loss_scalings: 8589.935547, pp_loss: 7.294797
[INFO] 2021-07-12 18:59:52,941 [run_pretraining.py:  512]:	********exe.run_1406******* 
[INFO] 2021-07-12 18:59:53,840 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:53,841 [run_pretraining.py:  534]:	loss/total_loss, 7.274411678314209, 1407
[INFO] 2021-07-12 18:59:53,841 [run_pretraining.py:  535]:	loss/mlm_loss, 7.274411678314209, 1407
[INFO] 2021-07-12 18:59:53,841 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4059999557503033e-05, 1407
[INFO] 2021-07-12 18:59:53,841 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1407
[INFO] 2021-07-12 18:59:53,841 [run_pretraining.py:  558]:	worker_index: 3, step: 1407, cost: 7.274412, mlm loss: 7.274412, speed: 1.112235 steps/s, speed: 8.897880 samples/s, speed: 4555.714770 tokens/s, learning rate: 1.406e-05, loss_scalings: 8589.935547, pp_loss: 7.518981
[INFO] 2021-07-12 18:59:53,841 [run_pretraining.py:  512]:	********exe.run_1407******* 
[INFO] 2021-07-12 18:59:54,738 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:54,738 [run_pretraining.py:  534]:	loss/total_loss, 7.45461893081665, 1408
[INFO] 2021-07-12 18:59:54,739 [run_pretraining.py:  535]:	loss/mlm_loss, 7.45461893081665, 1408
[INFO] 2021-07-12 18:59:54,739 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4069999451749027e-05, 1408
[INFO] 2021-07-12 18:59:54,739 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1408
[INFO] 2021-07-12 18:59:54,739 [run_pretraining.py:  558]:	worker_index: 3, step: 1408, cost: 7.454619, mlm loss: 7.454619, speed: 1.114527 steps/s, speed: 8.916219 samples/s, speed: 4565.103895 tokens/s, learning rate: 1.407e-05, loss_scalings: 8589.935547, pp_loss: 7.428834
[INFO] 2021-07-12 18:59:54,739 [run_pretraining.py:  512]:	********exe.run_1408******* 
[INFO] 2021-07-12 18:59:55,633 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:55,633 [run_pretraining.py:  534]:	loss/total_loss, 6.887011528015137, 1409
[INFO] 2021-07-12 18:59:55,633 [run_pretraining.py:  535]:	loss/mlm_loss, 6.887011528015137, 1409
[INFO] 2021-07-12 18:59:55,633 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.407999934599502e-05, 1409
[INFO] 2021-07-12 18:59:55,634 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1409
[INFO] 2021-07-12 18:59:55,634 [run_pretraining.py:  558]:	worker_index: 3, step: 1409, cost: 6.887012, mlm loss: 6.887012, speed: 1.118318 steps/s, speed: 8.946544 samples/s, speed: 4580.630288 tokens/s, learning rate: 1.408e-05, loss_scalings: 8589.935547, pp_loss: 7.261857
[INFO] 2021-07-12 18:59:55,634 [run_pretraining.py:  512]:	********exe.run_1409******* 
[INFO] 2021-07-12 18:59:56,542 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:56,542 [run_pretraining.py:  534]:	loss/total_loss, 6.4918999671936035, 1410
[INFO] 2021-07-12 18:59:56,542 [run_pretraining.py:  535]:	loss/mlm_loss, 6.4918999671936035, 1410
[INFO] 2021-07-12 18:59:56,542 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4090000149735715e-05, 1410
[INFO] 2021-07-12 18:59:56,543 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1410
[INFO] 2021-07-12 18:59:56,543 [run_pretraining.py:  558]:	worker_index: 3, step: 1410, cost: 6.491900, mlm loss: 6.491900, speed: 1.100935 steps/s, speed: 8.807476 samples/s, speed: 4509.427790 tokens/s, learning rate: 1.409e-05, loss_scalings: 8589.935547, pp_loss: 7.367609
[INFO] 2021-07-12 18:59:56,543 [run_pretraining.py:  512]:	********exe.run_1410******* 
[INFO] 2021-07-12 18:59:57,523 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:57,524 [run_pretraining.py:  534]:	loss/total_loss, 7.937566757202148, 1411
[INFO] 2021-07-12 18:59:57,524 [run_pretraining.py:  535]:	loss/mlm_loss, 7.937566757202148, 1411
[INFO] 2021-07-12 18:59:57,524 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4100000043981709e-05, 1411
[INFO] 2021-07-12 18:59:57,524 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1411
[INFO] 2021-07-12 18:59:57,524 [run_pretraining.py:  558]:	worker_index: 3, step: 1411, cost: 7.937567, mlm loss: 7.937567, speed: 1.019422 steps/s, speed: 8.155376 samples/s, speed: 4175.552751 tokens/s, learning rate: 1.410e-05, loss_scalings: 8589.935547, pp_loss: 7.897212
[INFO] 2021-07-12 18:59:57,524 [run_pretraining.py:  512]:	********exe.run_1411******* 
[INFO] 2021-07-12 18:59:58,471 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:58,471 [run_pretraining.py:  534]:	loss/total_loss, 7.665523529052734, 1412
[INFO] 2021-07-12 18:59:58,471 [run_pretraining.py:  535]:	loss/mlm_loss, 7.665523529052734, 1412
[INFO] 2021-07-12 18:59:58,471 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4109999938227702e-05, 1412
[INFO] 2021-07-12 18:59:58,472 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1412
[INFO] 2021-07-12 18:59:58,472 [run_pretraining.py:  558]:	worker_index: 3, step: 1412, cost: 7.665524, mlm loss: 7.665524, speed: 1.056158 steps/s, speed: 8.449265 samples/s, speed: 4326.023821 tokens/s, learning rate: 1.411e-05, loss_scalings: 8589.935547, pp_loss: 7.291184
[INFO] 2021-07-12 18:59:58,472 [run_pretraining.py:  512]:	********exe.run_1412******* 
[INFO] 2021-07-12 19:00:23,925 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:23,925 [run_pretraining.py:  534]:	loss/total_loss, 7.359317779541016, 1413
[INFO] 2021-07-12 19:00:23,926 [run_pretraining.py:  535]:	loss/mlm_loss, 7.359317779541016, 1413
[INFO] 2021-07-12 19:00:23,926 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4119999832473695e-05, 1413
[INFO] 2021-07-12 19:00:23,926 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1413
[INFO] 2021-07-12 19:00:23,926 [run_pretraining.py:  558]:	worker_index: 3, step: 1413, cost: 7.359318, mlm loss: 7.359318, speed: 0.039287 steps/s, speed: 0.314300 samples/s, speed: 160.921525 tokens/s, learning rate: 1.412e-05, loss_scalings: 8589.935547, pp_loss: 6.927845
[INFO] 2021-07-12 19:00:23,926 [run_pretraining.py:  512]:	********exe.run_1413******* 
[INFO] 2021-07-12 19:00:24,828 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:24,828 [run_pretraining.py:  534]:	loss/total_loss, 8.115523338317871, 1414
[INFO] 2021-07-12 19:00:24,828 [run_pretraining.py:  535]:	loss/mlm_loss, 8.115523338317871, 1414
[INFO] 2021-07-12 19:00:24,828 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4129998817224987e-05, 1414
[INFO] 2021-07-12 19:00:24,828 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1414
[INFO] 2021-07-12 19:00:24,829 [run_pretraining.py:  558]:	worker_index: 3, step: 1414, cost: 8.115523, mlm loss: 8.115523, speed: 1.108473 steps/s, speed: 8.867783 samples/s, speed: 4540.304944 tokens/s, learning rate: 1.413e-05, loss_scalings: 8589.935547, pp_loss: 7.880880
[INFO] 2021-07-12 19:00:24,829 [run_pretraining.py:  512]:	********exe.run_1414******* 
[INFO] 2021-07-12 19:00:25,729 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:25,730 [run_pretraining.py:  534]:	loss/total_loss, 7.531741142272949, 1415
[INFO] 2021-07-12 19:00:25,730 [run_pretraining.py:  535]:	loss/mlm_loss, 7.531741142272949, 1415
[INFO] 2021-07-12 19:00:25,730 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.413999871147098e-05, 1415
[INFO] 2021-07-12 19:00:25,730 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1415
[INFO] 2021-07-12 19:00:25,730 [run_pretraining.py:  558]:	worker_index: 3, step: 1415, cost: 7.531741, mlm loss: 7.531741, speed: 1.109738 steps/s, speed: 8.877907 samples/s, speed: 4545.488485 tokens/s, learning rate: 1.414e-05, loss_scalings: 8589.935547, pp_loss: 7.352310
[INFO] 2021-07-12 19:00:25,730 [run_pretraining.py:  512]:	********exe.run_1415******* 
[INFO] 2021-07-12 19:00:26,726 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:26,727 [run_pretraining.py:  534]:	loss/total_loss, 7.390385627746582, 1416
[INFO] 2021-07-12 19:00:26,727 [run_pretraining.py:  535]:	loss/mlm_loss, 7.390385627746582, 1416
[INFO] 2021-07-12 19:00:26,727 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4149999515211675e-05, 1416
[INFO] 2021-07-12 19:00:26,727 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1416
[INFO] 2021-07-12 19:00:26,727 [run_pretraining.py:  558]:	worker_index: 3, step: 1416, cost: 7.390386, mlm loss: 7.390386, speed: 1.003897 steps/s, speed: 8.031178 samples/s, speed: 4111.963340 tokens/s, learning rate: 1.415e-05, loss_scalings: 8589.935547, pp_loss: 7.509650
[INFO] 2021-07-12 19:00:26,727 [run_pretraining.py:  512]:	********exe.run_1416******* 
[INFO] 2021-07-12 19:00:27,773 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:27,774 [run_pretraining.py:  534]:	loss/total_loss, 7.338878631591797, 1417
[INFO] 2021-07-12 19:00:27,774 [run_pretraining.py:  535]:	loss/mlm_loss, 7.338878631591797, 1417
[INFO] 2021-07-12 19:00:27,774 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4159999409457669e-05, 1417
[INFO] 2021-07-12 19:00:27,774 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1417
[INFO] 2021-07-12 19:00:27,774 [run_pretraining.py:  558]:	worker_index: 3, step: 1417, cost: 7.338879, mlm loss: 7.338879, speed: 0.955578 steps/s, speed: 7.644620 samples/s, speed: 3914.045535 tokens/s, learning rate: 1.416e-05, loss_scalings: 8589.935547, pp_loss: 7.486681
[INFO] 2021-07-12 19:00:27,774 [run_pretraining.py:  512]:	********exe.run_1417******* 
[INFO] 2021-07-12 19:00:28,830 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:28,830 [run_pretraining.py:  534]:	loss/total_loss, 7.8268818855285645, 1418
[INFO] 2021-07-12 19:00:28,831 [run_pretraining.py:  535]:	loss/mlm_loss, 7.8268818855285645, 1418
[INFO] 2021-07-12 19:00:28,831 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4169999303703662e-05, 1418
[INFO] 2021-07-12 19:00:28,831 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1418
[INFO] 2021-07-12 19:00:28,831 [run_pretraining.py:  558]:	worker_index: 3, step: 1418, cost: 7.826882, mlm loss: 7.826882, speed: 0.946944 steps/s, speed: 7.575551 samples/s, speed: 3878.681939 tokens/s, learning rate: 1.417e-05, loss_scalings: 8589.935547, pp_loss: 7.300696
[INFO] 2021-07-12 19:00:28,831 [run_pretraining.py:  512]:	********exe.run_1418******* 
[INFO] 2021-07-12 19:00:29,890 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:29,890 [run_pretraining.py:  534]:	loss/total_loss, 7.757402420043945, 1419
[INFO] 2021-07-12 19:00:29,890 [run_pretraining.py:  535]:	loss/mlm_loss, 7.757402420043945, 1419
[INFO] 2021-07-12 19:00:29,891 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4180000107444357e-05, 1419
[INFO] 2021-07-12 19:00:29,891 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1419
[INFO] 2021-07-12 19:00:29,891 [run_pretraining.py:  558]:	worker_index: 3, step: 1419, cost: 7.757402, mlm loss: 7.757402, speed: 0.944101 steps/s, speed: 7.552812 samples/s, speed: 3867.039714 tokens/s, learning rate: 1.418e-05, loss_scalings: 8589.935547, pp_loss: 6.708100
[INFO] 2021-07-12 19:00:29,891 [run_pretraining.py:  512]:	********exe.run_1419******* 
[INFO] 2021-07-12 19:00:30,946 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:30,946 [run_pretraining.py:  534]:	loss/total_loss, 7.740967273712158, 1420
[INFO] 2021-07-12 19:00:30,946 [run_pretraining.py:  535]:	loss/mlm_loss, 7.740967273712158, 1420
[INFO] 2021-07-12 19:00:30,946 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.419000000169035e-05, 1420
[INFO] 2021-07-12 19:00:30,946 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1420
[INFO] 2021-07-12 19:00:30,947 [run_pretraining.py:  558]:	worker_index: 3, step: 1420, cost: 7.740967, mlm loss: 7.740967, speed: 0.947671 steps/s, speed: 7.581369 samples/s, speed: 3881.660682 tokens/s, learning rate: 1.419e-05, loss_scalings: 8589.935547, pp_loss: 7.647008
[INFO] 2021-07-12 19:00:30,947 [run_pretraining.py:  512]:	********exe.run_1420******* 
[INFO] 2021-07-12 19:00:31,994 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:31,995 [run_pretraining.py:  534]:	loss/total_loss, 5.830025672912598, 1421
[INFO] 2021-07-12 19:00:31,995 [run_pretraining.py:  535]:	loss/mlm_loss, 5.830025672912598, 1421
[INFO] 2021-07-12 19:00:31,995 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4199999895936344e-05, 1421
[INFO] 2021-07-12 19:00:31,995 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1421
[INFO] 2021-07-12 19:00:31,995 [run_pretraining.py:  558]:	worker_index: 3, step: 1421, cost: 5.830026, mlm loss: 5.830026, speed: 0.954280 steps/s, speed: 7.634242 samples/s, speed: 3908.731824 tokens/s, learning rate: 1.420e-05, loss_scalings: 8589.935547, pp_loss: 7.291155
[INFO] 2021-07-12 19:00:31,995 [run_pretraining.py:  512]:	********exe.run_1421******* 
[INFO] 2021-07-12 19:00:33,049 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:33,049 [run_pretraining.py:  534]:	loss/total_loss, 7.725104331970215, 1422
[INFO] 2021-07-12 19:00:33,049 [run_pretraining.py:  535]:	loss/mlm_loss, 7.725104331970215, 1422
[INFO] 2021-07-12 19:00:33,049 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4210000699677039e-05, 1422
[INFO] 2021-07-12 19:00:33,050 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1422
[INFO] 2021-07-12 19:00:33,050 [run_pretraining.py:  558]:	worker_index: 3, step: 1422, cost: 7.725104, mlm loss: 7.725104, speed: 0.948879 steps/s, speed: 7.591033 samples/s, speed: 3886.609056 tokens/s, learning rate: 1.421e-05, loss_scalings: 8589.935547, pp_loss: 7.615830
[INFO] 2021-07-12 19:00:33,050 [run_pretraining.py:  512]:	********exe.run_1422******* 
[INFO] 2021-07-12 19:00:34,103 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:34,104 [run_pretraining.py:  534]:	loss/total_loss, 7.709533214569092, 1423
[INFO] 2021-07-12 19:00:34,104 [run_pretraining.py:  535]:	loss/mlm_loss, 7.709533214569092, 1423
[INFO] 2021-07-12 19:00:34,104 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4219998774933629e-05, 1423
[INFO] 2021-07-12 19:00:34,104 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1423
[INFO] 2021-07-12 19:00:34,104 [run_pretraining.py:  558]:	worker_index: 3, step: 1423, cost: 7.709533, mlm loss: 7.709533, speed: 0.948881 steps/s, speed: 7.591045 samples/s, speed: 3886.615211 tokens/s, learning rate: 1.422e-05, loss_scalings: 8589.935547, pp_loss: 7.646244
[INFO] 2021-07-12 19:00:34,104 [run_pretraining.py:  512]:	********exe.run_1423******* 
[INFO] 2021-07-12 19:00:35,172 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:35,173 [run_pretraining.py:  534]:	loss/total_loss, 7.6848297119140625, 1424
[INFO] 2021-07-12 19:00:35,173 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6848297119140625, 1424
[INFO] 2021-07-12 19:00:35,173 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4229998669179622e-05, 1424
[INFO] 2021-07-12 19:00:35,173 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1424
[INFO] 2021-07-12 19:00:35,173 [run_pretraining.py:  558]:	worker_index: 3, step: 1424, cost: 7.684830, mlm loss: 7.684830, speed: 0.935944 steps/s, speed: 7.487551 samples/s, speed: 3833.625882 tokens/s, learning rate: 1.423e-05, loss_scalings: 8589.935547, pp_loss: 7.535836
[INFO] 2021-07-12 19:00:35,173 [run_pretraining.py:  512]:	********exe.run_1424******* 
[INFO] 2021-07-12 19:00:36,238 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:36,239 [run_pretraining.py:  534]:	loss/total_loss, 7.438037872314453, 1425
[INFO] 2021-07-12 19:00:36,239 [run_pretraining.py:  535]:	loss/mlm_loss, 7.438037872314453, 1425
[INFO] 2021-07-12 19:00:36,239 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4239999472920317e-05, 1425
[INFO] 2021-07-12 19:00:36,239 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1425
[INFO] 2021-07-12 19:00:36,239 [run_pretraining.py:  558]:	worker_index: 3, step: 1425, cost: 7.438038, mlm loss: 7.438038, speed: 0.938783 steps/s, speed: 7.510266 samples/s, speed: 3845.255960 tokens/s, learning rate: 1.424e-05, loss_scalings: 8589.935547, pp_loss: 7.391636
[INFO] 2021-07-12 19:00:36,239 [run_pretraining.py:  512]:	********exe.run_1425******* 
[INFO] 2021-07-12 19:00:37,355 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:37,356 [run_pretraining.py:  534]:	loss/total_loss, 7.651823997497559, 1426
[INFO] 2021-07-12 19:00:37,356 [run_pretraining.py:  535]:	loss/mlm_loss, 7.651823997497559, 1426
[INFO] 2021-07-12 19:00:37,356 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.424999936716631e-05, 1426
[INFO] 2021-07-12 19:00:37,356 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1426
[INFO] 2021-07-12 19:00:37,356 [run_pretraining.py:  558]:	worker_index: 3, step: 1426, cost: 7.651824, mlm loss: 7.651824, speed: 0.895824 steps/s, speed: 7.166590 samples/s, speed: 3669.293966 tokens/s, learning rate: 1.425e-05, loss_scalings: 8589.935547, pp_loss: 7.427567
[INFO] 2021-07-12 19:00:37,356 [run_pretraining.py:  512]:	********exe.run_1426******* 
[INFO] 2021-07-12 19:00:38,331 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:38,331 [run_pretraining.py:  534]:	loss/total_loss, 7.363054275512695, 1427
[INFO] 2021-07-12 19:00:38,332 [run_pretraining.py:  535]:	loss/mlm_loss, 7.363054275512695, 1427
[INFO] 2021-07-12 19:00:38,332 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4259999261412304e-05, 1427
[INFO] 2021-07-12 19:00:38,332 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1427
[INFO] 2021-07-12 19:00:38,332 [run_pretraining.py:  558]:	worker_index: 3, step: 1427, cost: 7.363054, mlm loss: 7.363054, speed: 1.025440 steps/s, speed: 8.203520 samples/s, speed: 4200.202331 tokens/s, learning rate: 1.426e-05, loss_scalings: 8589.935547, pp_loss: 7.615222
[INFO] 2021-07-12 19:00:38,332 [run_pretraining.py:  512]:	********exe.run_1427******* 
[INFO] 2021-07-12 19:00:39,238 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:39,238 [run_pretraining.py:  534]:	loss/total_loss, 7.441141128540039, 1428
[INFO] 2021-07-12 19:00:39,238 [run_pretraining.py:  535]:	loss/mlm_loss, 7.441141128540039, 1428
[INFO] 2021-07-12 19:00:39,238 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4270000065152999e-05, 1428
[INFO] 2021-07-12 19:00:39,238 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1428
[INFO] 2021-07-12 19:00:39,238 [run_pretraining.py:  558]:	worker_index: 3, step: 1428, cost: 7.441141, mlm loss: 7.441141, speed: 1.103822 steps/s, speed: 8.830578 samples/s, speed: 4521.256167 tokens/s, learning rate: 1.427e-05, loss_scalings: 8589.935547, pp_loss: 7.164463
[INFO] 2021-07-12 19:00:39,238 [run_pretraining.py:  512]:	********exe.run_1428******* 
[INFO] 2021-07-12 19:00:40,135 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:40,135 [run_pretraining.py:  534]:	loss/total_loss, 4.431686878204346, 1429
[INFO] 2021-07-12 19:00:40,136 [run_pretraining.py:  535]:	loss/mlm_loss, 4.431686878204346, 1429
[INFO] 2021-07-12 19:00:40,136 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4279999959398992e-05, 1429
[INFO] 2021-07-12 19:00:40,136 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1429
[INFO] 2021-07-12 19:00:40,136 [run_pretraining.py:  558]:	worker_index: 3, step: 1429, cost: 4.431687, mlm loss: 4.431687, speed: 1.115149 steps/s, speed: 8.921190 samples/s, speed: 4567.649096 tokens/s, learning rate: 1.428e-05, loss_scalings: 8589.935547, pp_loss: 6.824368
[INFO] 2021-07-12 19:00:40,136 [run_pretraining.py:  512]:	********exe.run_1429******* 
[INFO] 2021-07-12 19:00:41,030 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:41,030 [run_pretraining.py:  534]:	loss/total_loss, 7.189690113067627, 1430
[INFO] 2021-07-12 19:00:41,031 [run_pretraining.py:  535]:	loss/mlm_loss, 7.189690113067627, 1430
[INFO] 2021-07-12 19:00:41,031 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4289999853644986e-05, 1430
[INFO] 2021-07-12 19:00:41,031 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1430
[INFO] 2021-07-12 19:00:41,031 [run_pretraining.py:  558]:	worker_index: 3, step: 1430, cost: 7.189690, mlm loss: 7.189690, speed: 1.118142 steps/s, speed: 8.945134 samples/s, speed: 4579.908599 tokens/s, learning rate: 1.429e-05, loss_scalings: 8589.935547, pp_loss: 7.265931
[INFO] 2021-07-12 19:00:41,031 [run_pretraining.py:  512]:	********exe.run_1430******* 
[INFO] 2021-07-12 19:00:41,933 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:41,933 [run_pretraining.py:  534]:	loss/total_loss, 7.417728900909424, 1431
[INFO] 2021-07-12 19:00:41,934 [run_pretraining.py:  535]:	loss/mlm_loss, 7.417728900909424, 1431
[INFO] 2021-07-12 19:00:41,934 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.430000065738568e-05, 1431
[INFO] 2021-07-12 19:00:41,934 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1431
[INFO] 2021-07-12 19:00:41,934 [run_pretraining.py:  558]:	worker_index: 3, step: 1431, cost: 7.417729, mlm loss: 7.417729, speed: 1.108161 steps/s, speed: 8.865286 samples/s, speed: 4539.026196 tokens/s, learning rate: 1.430e-05, loss_scalings: 8589.935547, pp_loss: 7.262419
[INFO] 2021-07-12 19:00:41,934 [run_pretraining.py:  512]:	********exe.run_1431******* 
[INFO] 2021-07-12 19:00:42,835 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:42,836 [run_pretraining.py:  534]:	loss/total_loss, 7.3615403175354, 1432
[INFO] 2021-07-12 19:00:42,836 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3615403175354, 1432
[INFO] 2021-07-12 19:00:42,836 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.430999873264227e-05, 1432
[INFO] 2021-07-12 19:00:42,836 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1432
[INFO] 2021-07-12 19:00:42,836 [run_pretraining.py:  558]:	worker_index: 3, step: 1432, cost: 7.361540, mlm loss: 7.361540, speed: 1.109088 steps/s, speed: 8.872705 samples/s, speed: 4542.824962 tokens/s, learning rate: 1.431e-05, loss_scalings: 8589.935547, pp_loss: 7.384785
[INFO] 2021-07-12 19:00:42,836 [run_pretraining.py:  512]:	********exe.run_1432******* 
[INFO] 2021-07-12 19:00:43,729 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:43,730 [run_pretraining.py:  534]:	loss/total_loss, 7.573835372924805, 1433
[INFO] 2021-07-12 19:00:43,730 [run_pretraining.py:  535]:	loss/mlm_loss, 7.573835372924805, 1433
[INFO] 2021-07-12 19:00:43,730 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4319999536382966e-05, 1433
[INFO] 2021-07-12 19:00:43,730 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1433
[INFO] 2021-07-12 19:00:43,730 [run_pretraining.py:  558]:	worker_index: 3, step: 1433, cost: 7.573835, mlm loss: 7.573835, speed: 1.119413 steps/s, speed: 8.955307 samples/s, speed: 4585.116934 tokens/s, learning rate: 1.432e-05, loss_scalings: 8589.935547, pp_loss: 6.533983
[INFO] 2021-07-12 19:00:43,730 [run_pretraining.py:  512]:	********exe.run_1433******* 
[INFO] 2021-07-12 19:00:44,616 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:44,616 [run_pretraining.py:  534]:	loss/total_loss, 7.1041789054870605, 1434
[INFO] 2021-07-12 19:00:44,616 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1041789054870605, 1434
[INFO] 2021-07-12 19:00:44,616 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4329999430628959e-05, 1434
[INFO] 2021-07-12 19:00:44,616 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1434
[INFO] 2021-07-12 19:00:44,616 [run_pretraining.py:  558]:	worker_index: 3, step: 1434, cost: 7.104179, mlm loss: 7.104179, speed: 1.129005 steps/s, speed: 9.032037 samples/s, speed: 4624.402816 tokens/s, learning rate: 1.433e-05, loss_scalings: 8589.935547, pp_loss: 7.324756
[INFO] 2021-07-12 19:00:44,616 [run_pretraining.py:  512]:	********exe.run_1434******* 
[INFO] 2021-07-12 19:00:45,515 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:45,516 [run_pretraining.py:  534]:	loss/total_loss, 7.714278221130371, 1435
[INFO] 2021-07-12 19:00:45,516 [run_pretraining.py:  535]:	loss/mlm_loss, 7.714278221130371, 1435
[INFO] 2021-07-12 19:00:45,516 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4339999324874952e-05, 1435
[INFO] 2021-07-12 19:00:45,516 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1435
[INFO] 2021-07-12 19:00:45,516 [run_pretraining.py:  558]:	worker_index: 3, step: 1435, cost: 7.714278, mlm loss: 7.714278, speed: 1.111921 steps/s, speed: 8.895368 samples/s, speed: 4554.428535 tokens/s, learning rate: 1.434e-05, loss_scalings: 8589.935547, pp_loss: 7.088561
[INFO] 2021-07-12 19:00:45,516 [run_pretraining.py:  512]:	********exe.run_1435******* 
[INFO] 2021-07-12 19:00:46,410 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:46,410 [run_pretraining.py:  534]:	loss/total_loss, 7.306758880615234, 1436
[INFO] 2021-07-12 19:00:46,410 [run_pretraining.py:  535]:	loss/mlm_loss, 7.306758880615234, 1436
[INFO] 2021-07-12 19:00:46,410 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4349999219120946e-05, 1436
[INFO] 2021-07-12 19:00:46,410 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1436
[INFO] 2021-07-12 19:00:46,410 [run_pretraining.py:  558]:	worker_index: 3, step: 1436, cost: 7.306759, mlm loss: 7.306759, speed: 1.119199 steps/s, speed: 8.953588 samples/s, speed: 4584.237251 tokens/s, learning rate: 1.435e-05, loss_scalings: 8589.935547, pp_loss: 7.354752
[INFO] 2021-07-12 19:00:46,411 [run_pretraining.py:  512]:	********exe.run_1436******* 
[INFO] 2021-07-12 19:00:47,310 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:47,311 [run_pretraining.py:  534]:	loss/total_loss, 7.958250522613525, 1437
[INFO] 2021-07-12 19:00:47,311 [run_pretraining.py:  535]:	loss/mlm_loss, 7.958250522613525, 1437
[INFO] 2021-07-12 19:00:47,311 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4360000022861641e-05, 1437
[INFO] 2021-07-12 19:00:47,311 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1437
[INFO] 2021-07-12 19:00:47,311 [run_pretraining.py:  558]:	worker_index: 3, step: 1437, cost: 7.958251, mlm loss: 7.958251, speed: 1.111402 steps/s, speed: 8.891215 samples/s, speed: 4552.302106 tokens/s, learning rate: 1.436e-05, loss_scalings: 8589.935547, pp_loss: 7.685863
[INFO] 2021-07-12 19:00:47,311 [run_pretraining.py:  512]:	********exe.run_1437******* 
[INFO] 2021-07-12 19:00:48,206 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:48,207 [run_pretraining.py:  534]:	loss/total_loss, 7.571739673614502, 1438
[INFO] 2021-07-12 19:00:48,207 [run_pretraining.py:  535]:	loss/mlm_loss, 7.571739673614502, 1438
[INFO] 2021-07-12 19:00:48,207 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4369999917107634e-05, 1438
[INFO] 2021-07-12 19:00:48,207 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1438
[INFO] 2021-07-12 19:00:48,207 [run_pretraining.py:  558]:	worker_index: 3, step: 1438, cost: 7.571740, mlm loss: 7.571740, speed: 1.116673 steps/s, speed: 8.933386 samples/s, speed: 4573.893620 tokens/s, learning rate: 1.437e-05, loss_scalings: 8589.935547, pp_loss: 7.646926
[INFO] 2021-07-12 19:00:48,207 [run_pretraining.py:  512]:	********exe.run_1438******* 
[INFO] 2021-07-12 19:00:49,103 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:49,104 [run_pretraining.py:  534]:	loss/total_loss, 7.691415309906006, 1439
[INFO] 2021-07-12 19:00:49,104 [run_pretraining.py:  535]:	loss/mlm_loss, 7.691415309906006, 1439
[INFO] 2021-07-12 19:00:49,104 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4379999811353628e-05, 1439
[INFO] 2021-07-12 19:00:49,104 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1439
[INFO] 2021-07-12 19:00:49,104 [run_pretraining.py:  558]:	worker_index: 3, step: 1439, cost: 7.691415, mlm loss: 7.691415, speed: 1.115249 steps/s, speed: 8.921991 samples/s, speed: 4568.059603 tokens/s, learning rate: 1.438e-05, loss_scalings: 8589.935547, pp_loss: 7.204862
[INFO] 2021-07-12 19:00:49,104 [run_pretraining.py:  512]:	********exe.run_1439******* 
[INFO] 2021-07-12 19:00:50,002 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:50,003 [run_pretraining.py:  534]:	loss/total_loss, 7.275595664978027, 1440
[INFO] 2021-07-12 19:00:50,003 [run_pretraining.py:  535]:	loss/mlm_loss, 7.275595664978027, 1440
[INFO] 2021-07-12 19:00:50,003 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4390000615094323e-05, 1440
[INFO] 2021-07-12 19:00:50,003 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1440
[INFO] 2021-07-12 19:00:50,003 [run_pretraining.py:  558]:	worker_index: 3, step: 1440, cost: 7.275596, mlm loss: 7.275596, speed: 1.113736 steps/s, speed: 8.909888 samples/s, speed: 4561.862482 tokens/s, learning rate: 1.439e-05, loss_scalings: 8589.935547, pp_loss: 7.180591
[INFO] 2021-07-12 19:00:50,003 [run_pretraining.py:  512]:	********exe.run_1440******* 
[INFO] 2021-07-12 19:00:50,904 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:50,905 [run_pretraining.py:  534]:	loss/total_loss, 5.515780925750732, 1441
[INFO] 2021-07-12 19:00:50,905 [run_pretraining.py:  535]:	loss/mlm_loss, 5.515780925750732, 1441
[INFO] 2021-07-12 19:00:50,905 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4399998690350913e-05, 1441
[INFO] 2021-07-12 19:00:50,905 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1441
[INFO] 2021-07-12 19:00:50,905 [run_pretraining.py:  558]:	worker_index: 3, step: 1441, cost: 5.515781, mlm loss: 5.515781, speed: 1.108893 steps/s, speed: 8.871140 samples/s, speed: 4542.023871 tokens/s, learning rate: 1.440e-05, loss_scalings: 8589.935547, pp_loss: 6.796002
[INFO] 2021-07-12 19:00:50,905 [run_pretraining.py:  512]:	********exe.run_1441******* 
[INFO] 2021-07-12 19:00:51,806 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:51,807 [run_pretraining.py:  534]:	loss/total_loss, 7.359611511230469, 1442
[INFO] 2021-07-12 19:00:51,807 [run_pretraining.py:  535]:	loss/mlm_loss, 7.359611511230469, 1442
[INFO] 2021-07-12 19:00:51,807 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4409999494091608e-05, 1442
[INFO] 2021-07-12 19:00:51,807 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1442
[INFO] 2021-07-12 19:00:51,807 [run_pretraining.py:  558]:	worker_index: 3, step: 1442, cost: 7.359612, mlm loss: 7.359612, speed: 1.109476 steps/s, speed: 8.875808 samples/s, speed: 4544.413565 tokens/s, learning rate: 1.441e-05, loss_scalings: 8589.935547, pp_loss: 7.095431
[INFO] 2021-07-12 19:00:51,807 [run_pretraining.py:  512]:	********exe.run_1442******* 
[INFO] 2021-07-12 19:00:52,726 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:52,726 [run_pretraining.py:  534]:	loss/total_loss, 6.904922962188721, 1443
[INFO] 2021-07-12 19:00:52,727 [run_pretraining.py:  535]:	loss/mlm_loss, 6.904922962188721, 1443
[INFO] 2021-07-12 19:00:52,727 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4419999388337601e-05, 1443
[INFO] 2021-07-12 19:00:52,727 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1443
[INFO] 2021-07-12 19:00:52,727 [run_pretraining.py:  558]:	worker_index: 3, step: 1443, cost: 6.904923, mlm loss: 6.904923, speed: 1.088281 steps/s, speed: 8.706247 samples/s, speed: 4457.598313 tokens/s, learning rate: 1.442e-05, loss_scalings: 8589.935547, pp_loss: 7.468140
[INFO] 2021-07-12 19:00:52,727 [run_pretraining.py:  512]:	********exe.run_1443******* 
[INFO] 2021-07-12 19:00:53,628 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:53,628 [run_pretraining.py:  534]:	loss/total_loss, 8.225000381469727, 1444
[INFO] 2021-07-12 19:00:53,628 [run_pretraining.py:  535]:	loss/mlm_loss, 8.225000381469727, 1444
[INFO] 2021-07-12 19:00:53,628 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4429999282583594e-05, 1444
[INFO] 2021-07-12 19:00:53,629 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1444
[INFO] 2021-07-12 19:00:53,629 [run_pretraining.py:  558]:	worker_index: 3, step: 1444, cost: 8.225000, mlm loss: 8.225000, speed: 1.109696 steps/s, speed: 8.877569 samples/s, speed: 4545.315309 tokens/s, learning rate: 1.443e-05, loss_scalings: 8589.935547, pp_loss: 7.776168
[INFO] 2021-07-12 19:00:53,629 [run_pretraining.py:  512]:	********exe.run_1444******* 
[INFO] 2021-07-12 19:00:54,547 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:54,548 [run_pretraining.py:  534]:	loss/total_loss, 7.300612449645996, 1445
[INFO] 2021-07-12 19:00:54,548 [run_pretraining.py:  535]:	loss/mlm_loss, 7.300612449645996, 1445
[INFO] 2021-07-12 19:00:54,548 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.444000008632429e-05, 1445
[INFO] 2021-07-12 19:00:54,548 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1445
[INFO] 2021-07-12 19:00:54,548 [run_pretraining.py:  558]:	worker_index: 3, step: 1445, cost: 7.300612, mlm loss: 7.300612, speed: 1.088371 steps/s, speed: 8.706970 samples/s, speed: 4457.968455 tokens/s, learning rate: 1.444e-05, loss_scalings: 8589.935547, pp_loss: 7.425870
[INFO] 2021-07-12 19:00:54,548 [run_pretraining.py:  512]:	********exe.run_1445******* 
[INFO] 2021-07-12 19:00:55,451 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:55,451 [run_pretraining.py:  534]:	loss/total_loss, 6.931588172912598, 1446
[INFO] 2021-07-12 19:00:55,451 [run_pretraining.py:  535]:	loss/mlm_loss, 6.931588172912598, 1446
[INFO] 2021-07-12 19:00:55,451 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4449999980570283e-05, 1446
[INFO] 2021-07-12 19:00:55,452 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1446
[INFO] 2021-07-12 19:00:55,452 [run_pretraining.py:  558]:	worker_index: 3, step: 1446, cost: 6.931588, mlm loss: 6.931588, speed: 1.107475 steps/s, speed: 8.859799 samples/s, speed: 4536.216920 tokens/s, learning rate: 1.445e-05, loss_scalings: 8589.935547, pp_loss: 6.527995
[INFO] 2021-07-12 19:00:55,452 [run_pretraining.py:  512]:	********exe.run_1446******* 
[INFO] 2021-07-12 19:00:56,349 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:56,350 [run_pretraining.py:  534]:	loss/total_loss, 7.270766735076904, 1447
[INFO] 2021-07-12 19:00:56,350 [run_pretraining.py:  535]:	loss/mlm_loss, 7.270766735076904, 1447
[INFO] 2021-07-12 19:00:56,350 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4459999874816276e-05, 1447
[INFO] 2021-07-12 19:00:56,350 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1447
[INFO] 2021-07-12 19:00:56,350 [run_pretraining.py:  558]:	worker_index: 3, step: 1447, cost: 7.270767, mlm loss: 7.270767, speed: 1.113563 steps/s, speed: 8.908506 samples/s, speed: 4561.155172 tokens/s, learning rate: 1.446e-05, loss_scalings: 8589.935547, pp_loss: 7.426964
[INFO] 2021-07-12 19:00:56,350 [run_pretraining.py:  512]:	********exe.run_1447******* 
[INFO] 2021-07-12 19:00:57,328 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:57,328 [run_pretraining.py:  534]:	loss/total_loss, 7.718786239624023, 1448
[INFO] 2021-07-12 19:00:57,328 [run_pretraining.py:  535]:	loss/mlm_loss, 7.718786239624023, 1448
[INFO] 2021-07-12 19:00:57,328 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.446999976906227e-05, 1448
[INFO] 2021-07-12 19:00:57,328 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1448
[INFO] 2021-07-12 19:00:57,329 [run_pretraining.py:  558]:	worker_index: 3, step: 1448, cost: 7.718786, mlm loss: 7.718786, speed: 1.022922 steps/s, speed: 8.183379 samples/s, speed: 4189.890090 tokens/s, learning rate: 1.447e-05, loss_scalings: 8589.935547, pp_loss: 7.792745
[INFO] 2021-07-12 19:00:57,329 [run_pretraining.py:  512]:	********exe.run_1448******* 
[INFO] 2021-07-12 19:00:58,262 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:58,262 [run_pretraining.py:  534]:	loss/total_loss, 7.615895748138428, 1449
[INFO] 2021-07-12 19:00:58,262 [run_pretraining.py:  535]:	loss/mlm_loss, 7.615895748138428, 1449
[INFO] 2021-07-12 19:00:58,263 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4480000572802965e-05, 1449
[INFO] 2021-07-12 19:00:58,263 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1449
[INFO] 2021-07-12 19:00:58,263 [run_pretraining.py:  558]:	worker_index: 3, step: 1449, cost: 7.615896, mlm loss: 7.615896, speed: 1.071247 steps/s, speed: 8.569974 samples/s, speed: 4387.826876 tokens/s, learning rate: 1.448e-05, loss_scalings: 8589.935547, pp_loss: 7.287569
[INFO] 2021-07-12 19:00:58,263 [run_pretraining.py:  512]:	********exe.run_1449******* 
[INFO] 2021-07-12 19:00:59,164 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:59,165 [run_pretraining.py:  534]:	loss/total_loss, 7.48958683013916, 1450
[INFO] 2021-07-12 19:00:59,165 [run_pretraining.py:  535]:	loss/mlm_loss, 7.48958683013916, 1450
[INFO] 2021-07-12 19:00:59,165 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4489998648059554e-05, 1450
[INFO] 2021-07-12 19:00:59,165 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1450
[INFO] 2021-07-12 19:00:59,165 [run_pretraining.py:  558]:	worker_index: 3, step: 1450, cost: 7.489587, mlm loss: 7.489587, speed: 1.108920 steps/s, speed: 8.871361 samples/s, speed: 4542.136752 tokens/s, learning rate: 1.449e-05, loss_scalings: 8589.935547, pp_loss: 7.303304
[INFO] 2021-07-12 19:00:59,165 [run_pretraining.py:  512]:	********exe.run_1450******* 
[INFO] 2021-07-12 19:01:00,068 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:00,068 [run_pretraining.py:  534]:	loss/total_loss, 7.696974277496338, 1451
[INFO] 2021-07-12 19:01:00,068 [run_pretraining.py:  535]:	loss/mlm_loss, 7.696974277496338, 1451
[INFO] 2021-07-12 19:01:00,068 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.449999945180025e-05, 1451
[INFO] 2021-07-12 19:01:00,068 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1451
[INFO] 2021-07-12 19:01:00,068 [run_pretraining.py:  558]:	worker_index: 3, step: 1451, cost: 7.696974, mlm loss: 7.696974, speed: 1.107791 steps/s, speed: 8.862328 samples/s, speed: 4537.512063 tokens/s, learning rate: 1.450e-05, loss_scalings: 8589.935547, pp_loss: 7.276448
[INFO] 2021-07-12 19:01:00,068 [run_pretraining.py:  512]:	********exe.run_1451******* 
[INFO] 2021-07-12 19:01:00,966 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:00,966 [run_pretraining.py:  534]:	loss/total_loss, 7.520925998687744, 1452
[INFO] 2021-07-12 19:01:00,966 [run_pretraining.py:  535]:	loss/mlm_loss, 7.520925998687744, 1452
[INFO] 2021-07-12 19:01:00,966 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4509999346046243e-05, 1452
[INFO] 2021-07-12 19:01:00,966 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1452
[INFO] 2021-07-12 19:01:00,967 [run_pretraining.py:  558]:	worker_index: 3, step: 1452, cost: 7.520926, mlm loss: 7.520926, speed: 1.114247 steps/s, speed: 8.913975 samples/s, speed: 4563.955418 tokens/s, learning rate: 1.451e-05, loss_scalings: 8589.935547, pp_loss: 7.588932
[INFO] 2021-07-12 19:01:00,967 [run_pretraining.py:  512]:	********exe.run_1452******* 
[INFO] 2021-07-12 19:01:01,872 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:01,872 [run_pretraining.py:  534]:	loss/total_loss, 7.251031398773193, 1453
[INFO] 2021-07-12 19:01:01,872 [run_pretraining.py:  535]:	loss/mlm_loss, 7.251031398773193, 1453
[INFO] 2021-07-12 19:01:01,872 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4519999240292236e-05, 1453
[INFO] 2021-07-12 19:01:01,872 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1453
[INFO] 2021-07-12 19:01:01,872 [run_pretraining.py:  558]:	worker_index: 3, step: 1453, cost: 7.251031, mlm loss: 7.251031, speed: 1.104638 steps/s, speed: 8.837107 samples/s, speed: 4524.598593 tokens/s, learning rate: 1.452e-05, loss_scalings: 8589.935547, pp_loss: 7.282272
[INFO] 2021-07-12 19:01:01,872 [run_pretraining.py:  512]:	********exe.run_1453******* 
[INFO] 2021-07-12 19:01:02,768 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:02,768 [run_pretraining.py:  534]:	loss/total_loss, 7.807234287261963, 1454
[INFO] 2021-07-12 19:01:02,768 [run_pretraining.py:  535]:	loss/mlm_loss, 7.807234287261963, 1454
[INFO] 2021-07-12 19:01:02,769 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4530000044032931e-05, 1454
[INFO] 2021-07-12 19:01:02,769 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1454
[INFO] 2021-07-12 19:01:02,769 [run_pretraining.py:  558]:	worker_index: 3, step: 1454, cost: 7.807234, mlm loss: 7.807234, speed: 1.116497 steps/s, speed: 8.931978 samples/s, speed: 4573.172836 tokens/s, learning rate: 1.453e-05, loss_scalings: 8589.935547, pp_loss: 7.447779
[INFO] 2021-07-12 19:01:02,769 [run_pretraining.py:  512]:	********exe.run_1454******* 
[INFO] 2021-07-12 19:01:03,673 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:03,673 [run_pretraining.py:  534]:	loss/total_loss, 4.950728893280029, 1455
[INFO] 2021-07-12 19:01:03,673 [run_pretraining.py:  535]:	loss/mlm_loss, 4.950728893280029, 1455
[INFO] 2021-07-12 19:01:03,674 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4539999938278925e-05, 1455
[INFO] 2021-07-12 19:01:03,674 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1455
[INFO] 2021-07-12 19:01:03,674 [run_pretraining.py:  558]:	worker_index: 3, step: 1455, cost: 4.950729, mlm loss: 4.950729, speed: 1.105799 steps/s, speed: 8.846391 samples/s, speed: 4529.352214 tokens/s, learning rate: 1.454e-05, loss_scalings: 8589.935547, pp_loss: 6.783319
[INFO] 2021-07-12 19:01:03,674 [run_pretraining.py:  512]:	********exe.run_1455******* 
[INFO] 2021-07-12 19:01:04,570 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:04,571 [run_pretraining.py:  534]:	loss/total_loss, 7.487642288208008, 1456
[INFO] 2021-07-12 19:01:04,571 [run_pretraining.py:  535]:	loss/mlm_loss, 7.487642288208008, 1456
[INFO] 2021-07-12 19:01:04,571 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4549999832524918e-05, 1456
[INFO] 2021-07-12 19:01:04,571 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1456
[INFO] 2021-07-12 19:01:04,571 [run_pretraining.py:  558]:	worker_index: 3, step: 1456, cost: 7.487642, mlm loss: 7.487642, speed: 1.115138 steps/s, speed: 8.921102 samples/s, speed: 4567.604163 tokens/s, learning rate: 1.455e-05, loss_scalings: 8589.935547, pp_loss: 7.320062
[INFO] 2021-07-12 19:01:04,571 [run_pretraining.py:  512]:	********exe.run_1456******* 
[INFO] 2021-07-12 19:01:05,471 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:05,472 [run_pretraining.py:  534]:	loss/total_loss, 7.730263710021973, 1457
[INFO] 2021-07-12 19:01:05,472 [run_pretraining.py:  535]:	loss/mlm_loss, 7.730263710021973, 1457
[INFO] 2021-07-12 19:01:05,472 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4560000636265613e-05, 1457
[INFO] 2021-07-12 19:01:05,472 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1457
[INFO] 2021-07-12 19:01:05,472 [run_pretraining.py:  558]:	worker_index: 3, step: 1457, cost: 7.730264, mlm loss: 7.730264, speed: 1.110568 steps/s, speed: 8.884541 samples/s, speed: 4548.884915 tokens/s, learning rate: 1.456e-05, loss_scalings: 8589.935547, pp_loss: 7.580346
[INFO] 2021-07-12 19:01:05,472 [run_pretraining.py:  512]:	********exe.run_1457******* 
[INFO] 2021-07-12 19:01:31,551 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:31,551 [run_pretraining.py:  534]:	loss/total_loss, 7.631159782409668, 1458
[INFO] 2021-07-12 19:01:31,551 [run_pretraining.py:  535]:	loss/mlm_loss, 7.631159782409668, 1458
[INFO] 2021-07-12 19:01:31,551 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4569998711522203e-05, 1458
[INFO] 2021-07-12 19:01:31,551 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1458
[INFO] 2021-07-12 19:01:31,551 [run_pretraining.py:  558]:	worker_index: 3, step: 1458, cost: 7.631160, mlm loss: 7.631160, speed: 0.038346 steps/s, speed: 0.306764 samples/s, speed: 157.063190 tokens/s, learning rate: 1.457e-05, loss_scalings: 8589.935547, pp_loss: 6.731078
[INFO] 2021-07-12 19:01:31,552 [run_pretraining.py:  512]:	********exe.run_1458******* 
[INFO] 2021-07-12 19:01:32,474 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:32,474 [run_pretraining.py:  534]:	loss/total_loss, 8.016019821166992, 1459
[INFO] 2021-07-12 19:01:32,474 [run_pretraining.py:  535]:	loss/mlm_loss, 8.016019821166992, 1459
[INFO] 2021-07-12 19:01:32,474 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4579999515262898e-05, 1459
[INFO] 2021-07-12 19:01:32,474 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1459
[INFO] 2021-07-12 19:01:32,474 [run_pretraining.py:  558]:	worker_index: 3, step: 1459, cost: 8.016020, mlm loss: 8.016020, speed: 1.084221 steps/s, speed: 8.673767 samples/s, speed: 4440.968579 tokens/s, learning rate: 1.458e-05, loss_scalings: 8589.935547, pp_loss: 8.021681
[INFO] 2021-07-12 19:01:32,474 [run_pretraining.py:  512]:	********exe.run_1459******* 
[INFO] 2021-07-12 19:01:33,392 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:33,392 [run_pretraining.py:  534]:	loss/total_loss, 7.492066860198975, 1460
[INFO] 2021-07-12 19:01:33,392 [run_pretraining.py:  535]:	loss/mlm_loss, 7.492066860198975, 1460
[INFO] 2021-07-12 19:01:33,392 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4589999409508891e-05, 1460
[INFO] 2021-07-12 19:01:33,392 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1460
[INFO] 2021-07-12 19:01:33,392 [run_pretraining.py:  558]:	worker_index: 3, step: 1460, cost: 7.492067, mlm loss: 7.492067, speed: 1.090079 steps/s, speed: 8.720631 samples/s, speed: 4464.962947 tokens/s, learning rate: 1.459e-05, loss_scalings: 8589.935547, pp_loss: 7.881567
[INFO] 2021-07-12 19:01:33,392 [run_pretraining.py:  512]:	********exe.run_1460******* 
[INFO] 2021-07-12 19:01:34,298 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:34,299 [run_pretraining.py:  534]:	loss/total_loss, 7.722812175750732, 1461
[INFO] 2021-07-12 19:01:34,299 [run_pretraining.py:  535]:	loss/mlm_loss, 7.722812175750732, 1461
[INFO] 2021-07-12 19:01:34,299 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4599999303754885e-05, 1461
[INFO] 2021-07-12 19:01:34,299 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1461
[INFO] 2021-07-12 19:01:34,299 [run_pretraining.py:  558]:	worker_index: 3, step: 1461, cost: 7.722812, mlm loss: 7.722812, speed: 1.103523 steps/s, speed: 8.828181 samples/s, speed: 4520.028558 tokens/s, learning rate: 1.460e-05, loss_scalings: 8589.935547, pp_loss: 7.430495
[INFO] 2021-07-12 19:01:34,299 [run_pretraining.py:  512]:	********exe.run_1461******* 
[INFO] 2021-07-12 19:01:35,206 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:35,206 [run_pretraining.py:  534]:	loss/total_loss, 6.991020202636719, 1462
[INFO] 2021-07-12 19:01:35,206 [run_pretraining.py:  535]:	loss/mlm_loss, 6.991020202636719, 1462
[INFO] 2021-07-12 19:01:35,206 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4609999198000878e-05, 1462
[INFO] 2021-07-12 19:01:35,207 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1462
[INFO] 2021-07-12 19:01:35,207 [run_pretraining.py:  558]:	worker_index: 3, step: 1462, cost: 6.991020, mlm loss: 6.991020, speed: 1.102839 steps/s, speed: 8.822712 samples/s, speed: 4517.228489 tokens/s, learning rate: 1.461e-05, loss_scalings: 8589.935547, pp_loss: 7.476635
[INFO] 2021-07-12 19:01:35,207 [run_pretraining.py:  512]:	********exe.run_1462******* 
[INFO] 2021-07-12 19:01:36,130 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:36,130 [run_pretraining.py:  534]:	loss/total_loss, 7.600548267364502, 1463
[INFO] 2021-07-12 19:01:36,130 [run_pretraining.py:  535]:	loss/mlm_loss, 7.600548267364502, 1463
[INFO] 2021-07-12 19:01:36,131 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4620000001741573e-05, 1463
[INFO] 2021-07-12 19:01:36,131 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1463
[INFO] 2021-07-12 19:01:36,131 [run_pretraining.py:  558]:	worker_index: 3, step: 1463, cost: 7.600548, mlm loss: 7.600548, speed: 1.082912 steps/s, speed: 8.663295 samples/s, speed: 4435.607090 tokens/s, learning rate: 1.462e-05, loss_scalings: 8589.935547, pp_loss: 7.808287
[INFO] 2021-07-12 19:01:36,131 [run_pretraining.py:  512]:	********exe.run_1463******* 
[INFO] 2021-07-12 19:01:37,048 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:37,049 [run_pretraining.py:  534]:	loss/total_loss, 7.468233108520508, 1464
[INFO] 2021-07-12 19:01:37,049 [run_pretraining.py:  535]:	loss/mlm_loss, 7.468233108520508, 1464
[INFO] 2021-07-12 19:01:37,049 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4629999895987567e-05, 1464
[INFO] 2021-07-12 19:01:37,049 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1464
[INFO] 2021-07-12 19:01:37,049 [run_pretraining.py:  558]:	worker_index: 3, step: 1464, cost: 7.468233, mlm loss: 7.468233, speed: 1.089870 steps/s, speed: 8.718961 samples/s, speed: 4464.107879 tokens/s, learning rate: 1.463e-05, loss_scalings: 8589.935547, pp_loss: 7.510108
[INFO] 2021-07-12 19:01:37,049 [run_pretraining.py:  512]:	********exe.run_1464******* 
[INFO] 2021-07-12 19:01:37,963 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:37,963 [run_pretraining.py:  534]:	loss/total_loss, 7.410564422607422, 1465
[INFO] 2021-07-12 19:01:37,964 [run_pretraining.py:  535]:	loss/mlm_loss, 7.410564422607422, 1465
[INFO] 2021-07-12 19:01:37,964 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.463999979023356e-05, 1465
[INFO] 2021-07-12 19:01:37,964 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1465
[INFO] 2021-07-12 19:01:37,964 [run_pretraining.py:  558]:	worker_index: 3, step: 1465, cost: 7.410564, mlm loss: 7.410564, speed: 1.093787 steps/s, speed: 8.750299 samples/s, speed: 4480.153313 tokens/s, learning rate: 1.464e-05, loss_scalings: 8589.935547, pp_loss: 7.507093
[INFO] 2021-07-12 19:01:37,964 [run_pretraining.py:  512]:	********exe.run_1465******* 
[INFO] 2021-07-12 19:01:38,894 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:38,895 [run_pretraining.py:  534]:	loss/total_loss, 7.6719865798950195, 1466
[INFO] 2021-07-12 19:01:38,895 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6719865798950195, 1466
[INFO] 2021-07-12 19:01:38,895 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4650000593974255e-05, 1466
[INFO] 2021-07-12 19:01:38,895 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1466
[INFO] 2021-07-12 19:01:38,895 [run_pretraining.py:  558]:	worker_index: 3, step: 1466, cost: 7.671987, mlm loss: 7.671987, speed: 1.074564 steps/s, speed: 8.596508 samples/s, speed: 4401.412148 tokens/s, learning rate: 1.465e-05, loss_scalings: 8589.935547, pp_loss: 7.749171
[INFO] 2021-07-12 19:01:38,895 [run_pretraining.py:  512]:	********exe.run_1466******* 
[INFO] 2021-07-12 19:01:39,819 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:39,819 [run_pretraining.py:  534]:	loss/total_loss, 7.945581912994385, 1467
[INFO] 2021-07-12 19:01:39,820 [run_pretraining.py:  535]:	loss/mlm_loss, 7.945581912994385, 1467
[INFO] 2021-07-12 19:01:39,820 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4659998669230845e-05, 1467
[INFO] 2021-07-12 19:01:39,820 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1467
[INFO] 2021-07-12 19:01:39,820 [run_pretraining.py:  558]:	worker_index: 3, step: 1467, cost: 7.945582, mlm loss: 7.945582, speed: 1.082027 steps/s, speed: 8.656215 samples/s, speed: 4431.982020 tokens/s, learning rate: 1.466e-05, loss_scalings: 8589.935547, pp_loss: 7.845730
[INFO] 2021-07-12 19:01:39,820 [run_pretraining.py:  512]:	********exe.run_1467******* 
[INFO] 2021-07-12 19:01:40,750 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:40,751 [run_pretraining.py:  534]:	loss/total_loss, 7.662953853607178, 1468
[INFO] 2021-07-12 19:01:40,751 [run_pretraining.py:  535]:	loss/mlm_loss, 7.662953853607178, 1468
[INFO] 2021-07-12 19:01:40,751 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.466999947297154e-05, 1468
[INFO] 2021-07-12 19:01:40,751 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1468
[INFO] 2021-07-12 19:01:40,751 [run_pretraining.py:  558]:	worker_index: 3, step: 1468, cost: 7.662954, mlm loss: 7.662954, speed: 1.074434 steps/s, speed: 8.595469 samples/s, speed: 4400.879974 tokens/s, learning rate: 1.467e-05, loss_scalings: 8589.935547, pp_loss: 7.235113
[INFO] 2021-07-12 19:01:40,751 [run_pretraining.py:  512]:	********exe.run_1468******* 
[INFO] 2021-07-12 19:01:41,673 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:41,674 [run_pretraining.py:  534]:	loss/total_loss, 7.04621696472168, 1469
[INFO] 2021-07-12 19:01:41,674 [run_pretraining.py:  535]:	loss/mlm_loss, 7.04621696472168, 1469
[INFO] 2021-07-12 19:01:41,674 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4679999367217533e-05, 1469
[INFO] 2021-07-12 19:01:41,674 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1469
[INFO] 2021-07-12 19:01:41,674 [run_pretraining.py:  558]:	worker_index: 3, step: 1469, cost: 7.046217, mlm loss: 7.046217, speed: 1.084279 steps/s, speed: 8.674235 samples/s, speed: 4441.208520 tokens/s, learning rate: 1.468e-05, loss_scalings: 8589.935547, pp_loss: 7.404188
[INFO] 2021-07-12 19:01:41,674 [run_pretraining.py:  512]:	********exe.run_1469******* 
[INFO] 2021-07-12 19:01:42,596 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:42,597 [run_pretraining.py:  534]:	loss/total_loss, 7.580898761749268, 1470
[INFO] 2021-07-12 19:01:42,597 [run_pretraining.py:  535]:	loss/mlm_loss, 7.580898761749268, 1470
[INFO] 2021-07-12 19:01:42,597 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4689999261463527e-05, 1470
[INFO] 2021-07-12 19:01:42,597 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1470
[INFO] 2021-07-12 19:01:42,597 [run_pretraining.py:  558]:	worker_index: 3, step: 1470, cost: 7.580899, mlm loss: 7.580899, speed: 1.084112 steps/s, speed: 8.672899 samples/s, speed: 4440.524354 tokens/s, learning rate: 1.469e-05, loss_scalings: 8589.935547, pp_loss: 7.352210
[INFO] 2021-07-12 19:01:42,597 [run_pretraining.py:  512]:	********exe.run_1470******* 
[INFO] 2021-07-12 19:01:43,520 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:43,521 [run_pretraining.py:  534]:	loss/total_loss, 7.256785869598389, 1471
[INFO] 2021-07-12 19:01:43,521 [run_pretraining.py:  535]:	loss/mlm_loss, 7.256785869598389, 1471
[INFO] 2021-07-12 19:01:43,521 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4700000065204222e-05, 1471
[INFO] 2021-07-12 19:01:43,521 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1471
[INFO] 2021-07-12 19:01:43,521 [run_pretraining.py:  558]:	worker_index: 3, step: 1471, cost: 7.256786, mlm loss: 7.256786, speed: 1.083148 steps/s, speed: 8.665181 samples/s, speed: 4436.572715 tokens/s, learning rate: 1.470e-05, loss_scalings: 8589.935547, pp_loss: 7.590104
[INFO] 2021-07-12 19:01:43,521 [run_pretraining.py:  512]:	********exe.run_1471******* 
[INFO] 2021-07-12 19:01:44,445 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:44,446 [run_pretraining.py:  534]:	loss/total_loss, 7.537835597991943, 1472
[INFO] 2021-07-12 19:01:44,446 [run_pretraining.py:  535]:	loss/mlm_loss, 7.537835597991943, 1472
[INFO] 2021-07-12 19:01:44,446 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4709999959450215e-05, 1472
[INFO] 2021-07-12 19:01:44,446 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1472
[INFO] 2021-07-12 19:01:44,446 [run_pretraining.py:  558]:	worker_index: 3, step: 1472, cost: 7.537836, mlm loss: 7.537836, speed: 1.081752 steps/s, speed: 8.654014 samples/s, speed: 4430.854972 tokens/s, learning rate: 1.471e-05, loss_scalings: 8589.935547, pp_loss: 7.624154
[INFO] 2021-07-12 19:01:44,446 [run_pretraining.py:  512]:	********exe.run_1472******* 
[INFO] 2021-07-12 19:01:45,368 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:45,369 [run_pretraining.py:  534]:	loss/total_loss, 7.1788458824157715, 1473
[INFO] 2021-07-12 19:01:45,369 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1788458824157715, 1473
[INFO] 2021-07-12 19:01:45,369 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4719999853696208e-05, 1473
[INFO] 2021-07-12 19:01:45,369 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1473
[INFO] 2021-07-12 19:01:45,369 [run_pretraining.py:  558]:	worker_index: 3, step: 1473, cost: 7.178846, mlm loss: 7.178846, speed: 1.083953 steps/s, speed: 8.671622 samples/s, speed: 4439.870231 tokens/s, learning rate: 1.472e-05, loss_scalings: 8589.935547, pp_loss: 7.024120
[INFO] 2021-07-12 19:01:45,369 [run_pretraining.py:  512]:	********exe.run_1473******* 
[INFO] 2021-07-12 19:01:46,296 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:46,297 [run_pretraining.py:  534]:	loss/total_loss, 6.752228260040283, 1474
[INFO] 2021-07-12 19:01:46,297 [run_pretraining.py:  535]:	loss/mlm_loss, 6.752228260040283, 1474
[INFO] 2021-07-12 19:01:46,297 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4729999747942202e-05, 1474
[INFO] 2021-07-12 19:01:46,297 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1474
[INFO] 2021-07-12 19:01:46,297 [run_pretraining.py:  558]:	worker_index: 3, step: 1474, cost: 6.752228, mlm loss: 6.752228, speed: 1.078759 steps/s, speed: 8.630069 samples/s, speed: 4418.595170 tokens/s, learning rate: 1.473e-05, loss_scalings: 8589.935547, pp_loss: 7.187616
[INFO] 2021-07-12 19:01:46,297 [run_pretraining.py:  512]:	********exe.run_1474******* 
[INFO] 2021-07-12 19:01:47,218 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:47,219 [run_pretraining.py:  534]:	loss/total_loss, 7.629788398742676, 1475
[INFO] 2021-07-12 19:01:47,219 [run_pretraining.py:  535]:	loss/mlm_loss, 7.629788398742676, 1475
[INFO] 2021-07-12 19:01:47,219 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4740000551682897e-05, 1475
[INFO] 2021-07-12 19:01:47,219 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1475
[INFO] 2021-07-12 19:01:47,219 [run_pretraining.py:  558]:	worker_index: 3, step: 1475, cost: 7.629788, mlm loss: 7.629788, speed: 1.084942 steps/s, speed: 8.679540 samples/s, speed: 4443.924306 tokens/s, learning rate: 1.474e-05, loss_scalings: 8589.935547, pp_loss: 6.264384
[INFO] 2021-07-12 19:01:47,219 [run_pretraining.py:  512]:	********exe.run_1475******* 
[INFO] 2021-07-12 19:01:48,140 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:48,141 [run_pretraining.py:  534]:	loss/total_loss, 7.013585090637207, 1476
[INFO] 2021-07-12 19:01:48,141 [run_pretraining.py:  535]:	loss/mlm_loss, 7.013585090637207, 1476
[INFO] 2021-07-12 19:01:48,141 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4749998626939487e-05, 1476
[INFO] 2021-07-12 19:01:48,141 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1476
[INFO] 2021-07-12 19:01:48,141 [run_pretraining.py:  558]:	worker_index: 3, step: 1476, cost: 7.013585, mlm loss: 7.013585, speed: 1.085206 steps/s, speed: 8.681648 samples/s, speed: 4445.003960 tokens/s, learning rate: 1.475e-05, loss_scalings: 8589.935547, pp_loss: 7.766792
[INFO] 2021-07-12 19:01:48,141 [run_pretraining.py:  512]:	********exe.run_1476******* 
[INFO] 2021-07-12 19:01:49,069 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:49,069 [run_pretraining.py:  534]:	loss/total_loss, 7.257309913635254, 1477
[INFO] 2021-07-12 19:01:49,069 [run_pretraining.py:  535]:	loss/mlm_loss, 7.257309913635254, 1477
[INFO] 2021-07-12 19:01:49,070 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4759999430680182e-05, 1477
[INFO] 2021-07-12 19:01:49,070 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1477
[INFO] 2021-07-12 19:01:49,070 [run_pretraining.py:  558]:	worker_index: 3, step: 1477, cost: 7.257310, mlm loss: 7.257310, speed: 1.077901 steps/s, speed: 8.623209 samples/s, speed: 4415.082939 tokens/s, learning rate: 1.476e-05, loss_scalings: 8589.935547, pp_loss: 7.304409
[INFO] 2021-07-12 19:01:49,070 [run_pretraining.py:  512]:	********exe.run_1477******* 
[INFO] 2021-07-12 19:01:49,989 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:49,989 [run_pretraining.py:  534]:	loss/total_loss, 7.218803405761719, 1478
[INFO] 2021-07-12 19:01:49,990 [run_pretraining.py:  535]:	loss/mlm_loss, 7.218803405761719, 1478
[INFO] 2021-07-12 19:01:49,990 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4769999324926175e-05, 1478
[INFO] 2021-07-12 19:01:49,990 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1478
[INFO] 2021-07-12 19:01:49,990 [run_pretraining.py:  558]:	worker_index: 3, step: 1478, cost: 7.218803, mlm loss: 7.218803, speed: 1.087611 steps/s, speed: 8.700885 samples/s, speed: 4454.853087 tokens/s, learning rate: 1.477e-05, loss_scalings: 6871.948730, pp_loss: 7.149717
[INFO] 2021-07-12 19:01:49,990 [run_pretraining.py:  512]:	********exe.run_1478******* 
[INFO] 2021-07-12 19:01:50,915 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:50,915 [run_pretraining.py:  534]:	loss/total_loss, 7.653019905090332, 1479
[INFO] 2021-07-12 19:01:50,915 [run_pretraining.py:  535]:	loss/mlm_loss, 7.653019905090332, 1479
[INFO] 2021-07-12 19:01:50,916 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4779999219172169e-05, 1479
[INFO] 2021-07-12 19:01:50,916 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1479
[INFO] 2021-07-12 19:01:50,916 [run_pretraining.py:  558]:	worker_index: 3, step: 1479, cost: 7.653020, mlm loss: 7.653020, speed: 1.080806 steps/s, speed: 8.646452 samples/s, speed: 4426.983257 tokens/s, learning rate: 1.478e-05, loss_scalings: 6871.948730, pp_loss: 7.397263
[INFO] 2021-07-12 19:01:50,916 [run_pretraining.py:  512]:	********exe.run_1479******* 
[INFO] 2021-07-12 19:01:51,843 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:51,843 [run_pretraining.py:  534]:	loss/total_loss, 7.440098762512207, 1480
[INFO] 2021-07-12 19:01:51,843 [run_pretraining.py:  535]:	loss/mlm_loss, 7.440098762512207, 1480
[INFO] 2021-07-12 19:01:51,843 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4790000022912864e-05, 1480
[INFO] 2021-07-12 19:01:51,843 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1480
[INFO] 2021-07-12 19:01:51,843 [run_pretraining.py:  558]:	worker_index: 3, step: 1480, cost: 7.440099, mlm loss: 7.440099, speed: 1.078718 steps/s, speed: 8.629740 samples/s, speed: 4418.426983 tokens/s, learning rate: 1.479e-05, loss_scalings: 6871.948730, pp_loss: 7.629869
[INFO] 2021-07-12 19:01:51,843 [run_pretraining.py:  512]:	********exe.run_1480******* 
[INFO] 2021-07-12 19:01:52,771 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:52,772 [run_pretraining.py:  534]:	loss/total_loss, 7.599684715270996, 1481
[INFO] 2021-07-12 19:01:52,772 [run_pretraining.py:  535]:	loss/mlm_loss, 7.599684715270996, 1481
[INFO] 2021-07-12 19:01:52,772 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4799999917158857e-05, 1481
[INFO] 2021-07-12 19:01:52,772 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1481
[INFO] 2021-07-12 19:01:52,772 [run_pretraining.py:  558]:	worker_index: 3, step: 1481, cost: 7.599685, mlm loss: 7.599685, speed: 1.077419 steps/s, speed: 8.619355 samples/s, speed: 4413.109548 tokens/s, learning rate: 1.480e-05, loss_scalings: 6871.948730, pp_loss: 7.504244
[INFO] 2021-07-12 19:01:52,772 [run_pretraining.py:  512]:	********exe.run_1481******* 
[INFO] 2021-07-12 19:01:53,705 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:53,705 [run_pretraining.py:  534]:	loss/total_loss, 7.606895446777344, 1482
[INFO] 2021-07-12 19:01:53,705 [run_pretraining.py:  535]:	loss/mlm_loss, 7.606895446777344, 1482
[INFO] 2021-07-12 19:01:53,705 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.480999981140485e-05, 1482
[INFO] 2021-07-12 19:01:53,705 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1482
[INFO] 2021-07-12 19:01:53,705 [run_pretraining.py:  558]:	worker_index: 3, step: 1482, cost: 7.606895, mlm loss: 7.606895, speed: 1.072214 steps/s, speed: 8.577712 samples/s, speed: 4391.788669 tokens/s, learning rate: 1.481e-05, loss_scalings: 6871.948730, pp_loss: 7.676690
[INFO] 2021-07-12 19:01:53,706 [run_pretraining.py:  512]:	********exe.run_1482******* 
[INFO] 2021-07-12 19:01:54,629 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:54,629 [run_pretraining.py:  534]:	loss/total_loss, 7.606712341308594, 1483
[INFO] 2021-07-12 19:01:54,629 [run_pretraining.py:  535]:	loss/mlm_loss, 7.606712341308594, 1483
[INFO] 2021-07-12 19:01:54,629 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4819999705650844e-05, 1483
[INFO] 2021-07-12 19:01:54,630 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1483
[INFO] 2021-07-12 19:01:54,630 [run_pretraining.py:  558]:	worker_index: 3, step: 1483, cost: 7.606712, mlm loss: 7.606712, speed: 1.082779 steps/s, speed: 8.662235 samples/s, speed: 4435.064325 tokens/s, learning rate: 1.482e-05, loss_scalings: 6871.948730, pp_loss: 7.626391
[INFO] 2021-07-12 19:01:54,630 [run_pretraining.py:  512]:	********exe.run_1483******* 
[INFO] 2021-07-12 19:01:55,553 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:55,553 [run_pretraining.py:  534]:	loss/total_loss, 7.864983081817627, 1484
[INFO] 2021-07-12 19:01:55,553 [run_pretraining.py:  535]:	loss/mlm_loss, 7.864983081817627, 1484
[INFO] 2021-07-12 19:01:55,554 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4830000509391539e-05, 1484
[INFO] 2021-07-12 19:01:55,554 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1484
[INFO] 2021-07-12 19:01:55,554 [run_pretraining.py:  558]:	worker_index: 3, step: 1484, cost: 7.864983, mlm loss: 7.864983, speed: 1.082867 steps/s, speed: 8.662935 samples/s, speed: 4435.422718 tokens/s, learning rate: 1.483e-05, loss_scalings: 6871.948730, pp_loss: 7.452880
[INFO] 2021-07-12 19:01:55,554 [run_pretraining.py:  512]:	********exe.run_1484******* 
[INFO] 2021-07-12 19:01:56,484 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:56,485 [run_pretraining.py:  534]:	loss/total_loss, 6.946906089782715, 1485
[INFO] 2021-07-12 19:01:56,485 [run_pretraining.py:  535]:	loss/mlm_loss, 6.946906089782715, 1485
[INFO] 2021-07-12 19:01:56,485 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4839998584648129e-05, 1485
[INFO] 2021-07-12 19:01:56,485 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1485
[INFO] 2021-07-12 19:01:56,485 [run_pretraining.py:  558]:	worker_index: 3, step: 1485, cost: 6.946906, mlm loss: 6.946906, speed: 1.074591 steps/s, speed: 8.596731 samples/s, speed: 4401.526041 tokens/s, learning rate: 1.484e-05, loss_scalings: 6871.948730, pp_loss: 7.180782
[INFO] 2021-07-12 19:01:56,485 [run_pretraining.py:  512]:	********exe.run_1485******* 
[INFO] 2021-07-12 19:01:57,411 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:57,412 [run_pretraining.py:  534]:	loss/total_loss, 7.772969722747803, 1486
[INFO] 2021-07-12 19:01:57,412 [run_pretraining.py:  535]:	loss/mlm_loss, 7.772969722747803, 1486
[INFO] 2021-07-12 19:01:57,412 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4849999388388824e-05, 1486
[INFO] 2021-07-12 19:01:57,412 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1486
[INFO] 2021-07-12 19:01:57,412 [run_pretraining.py:  558]:	worker_index: 3, step: 1486, cost: 7.772970, mlm loss: 7.772970, speed: 1.079138 steps/s, speed: 8.633102 samples/s, speed: 4420.148100 tokens/s, learning rate: 1.485e-05, loss_scalings: 6871.948730, pp_loss: 7.423201
[INFO] 2021-07-12 19:01:57,412 [run_pretraining.py:  512]:	********exe.run_1486******* 
[INFO] 2021-07-12 19:01:58,335 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:58,336 [run_pretraining.py:  534]:	loss/total_loss, 7.853519916534424, 1487
[INFO] 2021-07-12 19:01:58,336 [run_pretraining.py:  535]:	loss/mlm_loss, 7.853519916534424, 1487
[INFO] 2021-07-12 19:01:58,336 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4859999282634817e-05, 1487
[INFO] 2021-07-12 19:01:58,336 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1487
[INFO] 2021-07-12 19:01:58,336 [run_pretraining.py:  558]:	worker_index: 3, step: 1487, cost: 7.853520, mlm loss: 7.853520, speed: 1.083213 steps/s, speed: 8.665705 samples/s, speed: 4436.840828 tokens/s, learning rate: 1.486e-05, loss_scalings: 6871.948730, pp_loss: 7.509041
[INFO] 2021-07-12 19:01:58,336 [run_pretraining.py:  512]:	********exe.run_1487******* 
[INFO] 2021-07-12 19:01:59,265 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:59,265 [run_pretraining.py:  534]:	loss/total_loss, 8.148067474365234, 1488
[INFO] 2021-07-12 19:01:59,265 [run_pretraining.py:  535]:	loss/mlm_loss, 8.148067474365234, 1488
[INFO] 2021-07-12 19:01:59,265 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.486999917688081e-05, 1488
[INFO] 2021-07-12 19:01:59,265 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1488
[INFO] 2021-07-12 19:01:59,265 [run_pretraining.py:  558]:	worker_index: 3, step: 1488, cost: 8.148067, mlm loss: 8.148067, speed: 1.076761 steps/s, speed: 8.614088 samples/s, speed: 4410.413168 tokens/s, learning rate: 1.487e-05, loss_scalings: 6871.948730, pp_loss: 7.515747
[INFO] 2021-07-12 19:01:59,265 [run_pretraining.py:  512]:	********exe.run_1488******* 
[INFO] 2021-07-12 19:02:00,219 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:00,219 [run_pretraining.py:  534]:	loss/total_loss, 7.535279273986816, 1489
[INFO] 2021-07-12 19:02:00,219 [run_pretraining.py:  535]:	loss/mlm_loss, 7.535279273986816, 1489
[INFO] 2021-07-12 19:02:00,219 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4879999980621506e-05, 1489
[INFO] 2021-07-12 19:02:00,219 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1489
[INFO] 2021-07-12 19:02:00,220 [run_pretraining.py:  558]:	worker_index: 3, step: 1489, cost: 7.535279, mlm loss: 7.535279, speed: 1.048832 steps/s, speed: 8.390653 samples/s, speed: 4296.014450 tokens/s, learning rate: 1.488e-05, loss_scalings: 6871.948730, pp_loss: 6.765724
[INFO] 2021-07-12 19:02:00,220 [run_pretraining.py:  512]:	********exe.run_1489******* 
[INFO] 2021-07-12 19:02:01,142 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:01,142 [run_pretraining.py:  534]:	loss/total_loss, 7.571221828460693, 1490
[INFO] 2021-07-12 19:02:01,142 [run_pretraining.py:  535]:	loss/mlm_loss, 7.571221828460693, 1490
[INFO] 2021-07-12 19:02:01,142 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4889999874867499e-05, 1490
[INFO] 2021-07-12 19:02:01,142 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1490
[INFO] 2021-07-12 19:02:01,142 [run_pretraining.py:  558]:	worker_index: 3, step: 1490, cost: 7.571222, mlm loss: 7.571222, speed: 1.084281 steps/s, speed: 8.674249 samples/s, speed: 4441.215409 tokens/s, learning rate: 1.489e-05, loss_scalings: 6871.948730, pp_loss: 7.446712
[INFO] 2021-07-12 19:02:01,143 [run_pretraining.py:  512]:	********exe.run_1490******* 
[INFO] 2021-07-12 19:02:02,050 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:02,050 [run_pretraining.py:  534]:	loss/total_loss, 7.579020977020264, 1491
[INFO] 2021-07-12 19:02:02,051 [run_pretraining.py:  535]:	loss/mlm_loss, 7.579020977020264, 1491
[INFO] 2021-07-12 19:02:02,051 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4899999769113492e-05, 1491
[INFO] 2021-07-12 19:02:02,051 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1491
[INFO] 2021-07-12 19:02:02,051 [run_pretraining.py:  558]:	worker_index: 3, step: 1491, cost: 7.579021, mlm loss: 7.579021, speed: 1.101737 steps/s, speed: 8.813896 samples/s, speed: 4512.714811 tokens/s, learning rate: 1.490e-05, loss_scalings: 6871.948730, pp_loss: 7.390339
[INFO] 2021-07-12 19:02:02,051 [run_pretraining.py:  512]:	********exe.run_1491******* 
[INFO] 2021-07-12 19:02:02,959 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:02,960 [run_pretraining.py:  534]:	loss/total_loss, 7.7113165855407715, 1492
[INFO] 2021-07-12 19:02:02,960 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7113165855407715, 1492
[INFO] 2021-07-12 19:02:02,960 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4910000572854187e-05, 1492
[INFO] 2021-07-12 19:02:02,960 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1492
[INFO] 2021-07-12 19:02:02,960 [run_pretraining.py:  558]:	worker_index: 3, step: 1492, cost: 7.711317, mlm loss: 7.711317, speed: 1.100384 steps/s, speed: 8.803070 samples/s, speed: 4507.171700 tokens/s, learning rate: 1.491e-05, loss_scalings: 6871.948730, pp_loss: 6.492181
[INFO] 2021-07-12 19:02:02,960 [run_pretraining.py:  512]:	********exe.run_1492******* 
[INFO] 2021-07-12 19:02:03,869 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:03,869 [run_pretraining.py:  534]:	loss/total_loss, 7.092717170715332, 1493
[INFO] 2021-07-12 19:02:03,869 [run_pretraining.py:  535]:	loss/mlm_loss, 7.092717170715332, 1493
[INFO] 2021-07-12 19:02:03,869 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.492000046710018e-05, 1493
[INFO] 2021-07-12 19:02:03,869 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1493
[INFO] 2021-07-12 19:02:03,869 [run_pretraining.py:  558]:	worker_index: 3, step: 1493, cost: 7.092717, mlm loss: 7.092717, speed: 1.100478 steps/s, speed: 8.803823 samples/s, speed: 4507.557217 tokens/s, learning rate: 1.492e-05, loss_scalings: 6871.948730, pp_loss: 7.066326
[INFO] 2021-07-12 19:02:03,870 [run_pretraining.py:  512]:	********exe.run_1493******* 
[INFO] 2021-07-12 19:02:04,776 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:04,777 [run_pretraining.py:  534]:	loss/total_loss, 7.079775810241699, 1494
[INFO] 2021-07-12 19:02:04,777 [run_pretraining.py:  535]:	loss/mlm_loss, 7.079775810241699, 1494
[INFO] 2021-07-12 19:02:04,777 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4929999451851472e-05, 1494
[INFO] 2021-07-12 19:02:04,777 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1494
[INFO] 2021-07-12 19:02:04,777 [run_pretraining.py:  558]:	worker_index: 3, step: 1494, cost: 7.079776, mlm loss: 7.079776, speed: 1.102624 steps/s, speed: 8.820991 samples/s, speed: 4516.347352 tokens/s, learning rate: 1.493e-05, loss_scalings: 6871.948730, pp_loss: 7.392236
[INFO] 2021-07-12 19:02:04,777 [run_pretraining.py:  512]:	********exe.run_1494******* 
[INFO] 2021-07-12 19:02:05,684 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:05,684 [run_pretraining.py:  534]:	loss/total_loss, 7.6681694984436035, 1495
[INFO] 2021-07-12 19:02:05,684 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6681694984436035, 1495
[INFO] 2021-07-12 19:02:05,684 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4939999346097466e-05, 1495
[INFO] 2021-07-12 19:02:05,684 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1495
[INFO] 2021-07-12 19:02:05,685 [run_pretraining.py:  558]:	worker_index: 3, step: 1495, cost: 7.668169, mlm loss: 7.668169, speed: 1.102742 steps/s, speed: 8.821935 samples/s, speed: 4516.830629 tokens/s, learning rate: 1.494e-05, loss_scalings: 6871.948730, pp_loss: 7.096826
[INFO] 2021-07-12 19:02:05,685 [run_pretraining.py:  512]:	********exe.run_1495******* 
[INFO] 2021-07-12 19:02:06,589 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:06,589 [run_pretraining.py:  534]:	loss/total_loss, 7.458890914916992, 1496
[INFO] 2021-07-12 19:02:06,589 [run_pretraining.py:  535]:	loss/mlm_loss, 7.458890914916992, 1496
[INFO] 2021-07-12 19:02:06,589 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4949999240343459e-05, 1496
[INFO] 2021-07-12 19:02:06,589 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1496
[INFO] 2021-07-12 19:02:06,589 [run_pretraining.py:  558]:	worker_index: 3, step: 1496, cost: 7.458891, mlm loss: 7.458891, speed: 1.105747 steps/s, speed: 8.845978 samples/s, speed: 4529.140863 tokens/s, learning rate: 1.495e-05, loss_scalings: 6871.948730, pp_loss: 7.290915
[INFO] 2021-07-12 19:02:06,590 [run_pretraining.py:  512]:	********exe.run_1496******* 
[INFO] 2021-07-12 19:02:07,500 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:07,501 [run_pretraining.py:  534]:	loss/total_loss, 7.131728172302246, 1497
[INFO] 2021-07-12 19:02:07,501 [run_pretraining.py:  535]:	loss/mlm_loss, 7.131728172302246, 1497
[INFO] 2021-07-12 19:02:07,501 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4959999134589452e-05, 1497
[INFO] 2021-07-12 19:02:07,501 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1497
[INFO] 2021-07-12 19:02:07,501 [run_pretraining.py:  558]:	worker_index: 3, step: 1497, cost: 7.131728, mlm loss: 7.131728, speed: 1.097934 steps/s, speed: 8.783471 samples/s, speed: 4497.137224 tokens/s, learning rate: 1.496e-05, loss_scalings: 6871.948730, pp_loss: 7.329428
[INFO] 2021-07-12 19:02:07,501 [run_pretraining.py:  512]:	********exe.run_1497******* 
[INFO] 2021-07-12 19:02:08,405 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:08,405 [run_pretraining.py:  534]:	loss/total_loss, 4.979532718658447, 1498
[INFO] 2021-07-12 19:02:08,405 [run_pretraining.py:  535]:	loss/mlm_loss, 4.979532718658447, 1498
[INFO] 2021-07-12 19:02:08,405 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4969999938330147e-05, 1498
[INFO] 2021-07-12 19:02:08,405 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1498
[INFO] 2021-07-12 19:02:08,406 [run_pretraining.py:  558]:	worker_index: 3, step: 1498, cost: 4.979533, mlm loss: 4.979533, speed: 1.106217 steps/s, speed: 8.849737 samples/s, speed: 4531.065247 tokens/s, learning rate: 1.497e-05, loss_scalings: 6871.948730, pp_loss: 6.805873
[INFO] 2021-07-12 19:02:08,406 [run_pretraining.py:  512]:	********exe.run_1498******* 
[INFO] 2021-07-12 19:02:09,321 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:09,322 [run_pretraining.py:  534]:	loss/total_loss, 7.721435546875, 1499
[INFO] 2021-07-12 19:02:09,322 [run_pretraining.py:  535]:	loss/mlm_loss, 7.721435546875, 1499
[INFO] 2021-07-12 19:02:09,322 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.497999983257614e-05, 1499
[INFO] 2021-07-12 19:02:09,322 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1499
[INFO] 2021-07-12 19:02:09,322 [run_pretraining.py:  558]:	worker_index: 3, step: 1499, cost: 7.721436, mlm loss: 7.721436, speed: 1.092051 steps/s, speed: 8.736404 samples/s, speed: 4473.038978 tokens/s, learning rate: 1.498e-05, loss_scalings: 6871.948730, pp_loss: 7.246469
[INFO] 2021-07-12 19:02:09,322 [run_pretraining.py:  512]:	********exe.run_1499******* 
[INFO] 2021-07-12 19:02:10,225 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:10,226 [run_pretraining.py:  534]:	loss/total_loss, 7.152568817138672, 1500
[INFO] 2021-07-12 19:02:10,226 [run_pretraining.py:  535]:	loss/mlm_loss, 7.152568817138672, 1500
[INFO] 2021-07-12 19:02:10,226 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4989999726822134e-05, 1500
[INFO] 2021-07-12 19:02:10,226 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1500
[INFO] 2021-07-12 19:02:10,226 [run_pretraining.py:  558]:	worker_index: 3, step: 1500, cost: 7.152569, mlm loss: 7.152569, speed: 1.106794 steps/s, speed: 8.854356 samples/s, speed: 4533.430261 tokens/s, learning rate: 1.499e-05, loss_scalings: 6871.948730, pp_loss: 7.476170
[INFO] 2021-07-12 19:02:10,226 [run_pretraining.py:  512]:	********exe.run_1500******* 
[INFO] 2021-07-12 19:02:11,127 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:11,127 [run_pretraining.py:  534]:	loss/total_loss, 7.04420280456543, 1501
[INFO] 2021-07-12 19:02:11,128 [run_pretraining.py:  535]:	loss/mlm_loss, 7.04420280456543, 1501
[INFO] 2021-07-12 19:02:11,128 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.500000053056283e-05, 1501
[INFO] 2021-07-12 19:02:11,128 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1501
[INFO] 2021-07-12 19:02:11,128 [run_pretraining.py:  558]:	worker_index: 3, step: 1501, cost: 7.044203, mlm loss: 7.044203, speed: 1.109775 steps/s, speed: 8.878196 samples/s, speed: 4545.636416 tokens/s, learning rate: 1.500e-05, loss_scalings: 6871.948730, pp_loss: 7.484988
[INFO] 2021-07-12 19:02:11,128 [run_pretraining.py:  512]:	********exe.run_1501******* 
[INFO] 2021-07-12 19:02:12,042 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:12,042 [run_pretraining.py:  534]:	loss/total_loss, 7.421980857849121, 1502
[INFO] 2021-07-12 19:02:12,042 [run_pretraining.py:  535]:	loss/mlm_loss, 7.421980857849121, 1502
[INFO] 2021-07-12 19:02:12,042 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5009998605819419e-05, 1502
[INFO] 2021-07-12 19:02:12,042 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1502
[INFO] 2021-07-12 19:02:12,042 [run_pretraining.py:  558]:	worker_index: 3, step: 1502, cost: 7.421981, mlm loss: 7.421981, speed: 1.094146 steps/s, speed: 8.753169 samples/s, speed: 4481.622387 tokens/s, learning rate: 1.501e-05, loss_scalings: 6871.948730, pp_loss: 7.382785
[INFO] 2021-07-12 19:02:12,042 [run_pretraining.py:  512]:	********exe.run_1502******* 
[INFO] 2021-07-12 19:02:12,948 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:12,949 [run_pretraining.py:  534]:	loss/total_loss, 7.680248737335205, 1503
[INFO] 2021-07-12 19:02:12,949 [run_pretraining.py:  535]:	loss/mlm_loss, 7.680248737335205, 1503
[INFO] 2021-07-12 19:02:12,949 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5019999409560114e-05, 1503
[INFO] 2021-07-12 19:02:12,949 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1503
[INFO] 2021-07-12 19:02:12,949 [run_pretraining.py:  558]:	worker_index: 3, step: 1503, cost: 7.680249, mlm loss: 7.680249, speed: 1.103914 steps/s, speed: 8.831315 samples/s, speed: 4521.633386 tokens/s, learning rate: 1.502e-05, loss_scalings: 6871.948730, pp_loss: 7.463342
[INFO] 2021-07-12 19:02:12,949 [run_pretraining.py:  512]:	********exe.run_1503******* 
[INFO] 2021-07-12 19:02:13,857 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:13,857 [run_pretraining.py:  534]:	loss/total_loss, 7.391190528869629, 1504
[INFO] 2021-07-12 19:02:13,857 [run_pretraining.py:  535]:	loss/mlm_loss, 7.391190528869629, 1504
[INFO] 2021-07-12 19:02:13,857 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5029999303806107e-05, 1504
[INFO] 2021-07-12 19:02:13,857 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1504
[INFO] 2021-07-12 19:02:13,857 [run_pretraining.py:  558]:	worker_index: 3, step: 1504, cost: 7.391191, mlm loss: 7.391191, speed: 1.101396 steps/s, speed: 8.811165 samples/s, speed: 4511.316501 tokens/s, learning rate: 1.503e-05, loss_scalings: 6871.948730, pp_loss: 7.453086
[INFO] 2021-07-12 19:02:13,858 [run_pretraining.py:  512]:	********exe.run_1504******* 
[INFO] 2021-07-12 19:02:14,766 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:14,767 [run_pretraining.py:  534]:	loss/total_loss, 6.698390960693359, 1505
[INFO] 2021-07-12 19:02:14,767 [run_pretraining.py:  535]:	loss/mlm_loss, 6.698390960693359, 1505
[INFO] 2021-07-12 19:02:14,767 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.50399991980521e-05, 1505
[INFO] 2021-07-12 19:02:14,767 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1505
[INFO] 2021-07-12 19:02:14,767 [run_pretraining.py:  558]:	worker_index: 3, step: 1505, cost: 6.698391, mlm loss: 6.698391, speed: 1.100401 steps/s, speed: 8.803206 samples/s, speed: 4507.241467 tokens/s, learning rate: 1.504e-05, loss_scalings: 6871.948730, pp_loss: 7.171839
[INFO] 2021-07-12 19:02:14,767 [run_pretraining.py:  512]:	********exe.run_1505******* 
[INFO] 2021-07-12 19:02:15,673 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:15,674 [run_pretraining.py:  534]:	loss/total_loss, 7.929546356201172, 1506
[INFO] 2021-07-12 19:02:15,674 [run_pretraining.py:  535]:	loss/mlm_loss, 7.929546356201172, 1506
[INFO] 2021-07-12 19:02:15,674 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5050000001792796e-05, 1506
[INFO] 2021-07-12 19:02:15,674 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1506
[INFO] 2021-07-12 19:02:15,674 [run_pretraining.py:  558]:	worker_index: 3, step: 1506, cost: 7.929546, mlm loss: 7.929546, speed: 1.103296 steps/s, speed: 8.826369 samples/s, speed: 4519.101156 tokens/s, learning rate: 1.505e-05, loss_scalings: 6871.948730, pp_loss: 7.511899
[INFO] 2021-07-12 19:02:15,674 [run_pretraining.py:  512]:	********exe.run_1506******* 
[INFO] 2021-07-12 19:02:16,580 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:16,581 [run_pretraining.py:  534]:	loss/total_loss, 7.7383317947387695, 1507
[INFO] 2021-07-12 19:02:16,581 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7383317947387695, 1507
[INFO] 2021-07-12 19:02:16,581 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.505999989603879e-05, 1507
[INFO] 2021-07-12 19:02:16,581 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1507
[INFO] 2021-07-12 19:02:16,581 [run_pretraining.py:  558]:	worker_index: 3, step: 1507, cost: 7.738332, mlm loss: 7.738332, speed: 1.102898 steps/s, speed: 8.823183 samples/s, speed: 4517.469615 tokens/s, learning rate: 1.506e-05, loss_scalings: 6871.948730, pp_loss: 7.732027
[INFO] 2021-07-12 19:02:16,581 [run_pretraining.py:  512]:	********exe.run_1507******* 
[INFO] 2021-07-12 19:02:17,523 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:17,524 [run_pretraining.py:  534]:	loss/total_loss, 4.319190979003906, 1508
[INFO] 2021-07-12 19:02:17,524 [run_pretraining.py:  535]:	loss/mlm_loss, 4.319190979003906, 1508
[INFO] 2021-07-12 19:02:17,524 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5069999790284783e-05, 1508
[INFO] 2021-07-12 19:02:17,524 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1508
[INFO] 2021-07-12 19:02:17,524 [run_pretraining.py:  558]:	worker_index: 3, step: 1508, cost: 4.319191, mlm loss: 4.319191, speed: 1.061061 steps/s, speed: 8.488488 samples/s, speed: 4346.105749 tokens/s, learning rate: 1.507e-05, loss_scalings: 6871.948730, pp_loss: 6.610137
[INFO] 2021-07-12 19:02:17,524 [run_pretraining.py:  512]:	********exe.run_1508******* 
[INFO] 2021-07-12 19:02:18,424 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:18,425 [run_pretraining.py:  534]:	loss/total_loss, 7.04892110824585, 1509
[INFO] 2021-07-12 19:02:18,425 [run_pretraining.py:  535]:	loss/mlm_loss, 7.04892110824585, 1509
[INFO] 2021-07-12 19:02:18,425 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5079999684530776e-05, 1509
[INFO] 2021-07-12 19:02:18,425 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1509
[INFO] 2021-07-12 19:02:18,425 [run_pretraining.py:  558]:	worker_index: 3, step: 1509, cost: 7.048921, mlm loss: 7.048921, speed: 1.110614 steps/s, speed: 8.884915 samples/s, speed: 4549.076431 tokens/s, learning rate: 1.508e-05, loss_scalings: 6871.948730, pp_loss: 7.028514
[INFO] 2021-07-12 19:02:18,425 [run_pretraining.py:  512]:	********exe.run_1509******* 
[INFO] 2021-07-12 19:02:19,326 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:19,326 [run_pretraining.py:  534]:	loss/total_loss, 7.597518444061279, 1510
[INFO] 2021-07-12 19:02:19,326 [run_pretraining.py:  535]:	loss/mlm_loss, 7.597518444061279, 1510
[INFO] 2021-07-12 19:02:19,326 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5090000488271471e-05, 1510
[INFO] 2021-07-12 19:02:19,326 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1510
[INFO] 2021-07-12 19:02:19,326 [run_pretraining.py:  558]:	worker_index: 3, step: 1510, cost: 7.597518, mlm loss: 7.597518, speed: 1.110598 steps/s, speed: 8.884786 samples/s, speed: 4549.010181 tokens/s, learning rate: 1.509e-05, loss_scalings: 6871.948730, pp_loss: 7.445521
[INFO] 2021-07-12 19:02:19,326 [run_pretraining.py:  512]:	********exe.run_1510******* 
[INFO] 2021-07-12 19:02:20,234 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:20,234 [run_pretraining.py:  534]:	loss/total_loss, 7.224614143371582, 1511
[INFO] 2021-07-12 19:02:20,235 [run_pretraining.py:  535]:	loss/mlm_loss, 7.224614143371582, 1511
[INFO] 2021-07-12 19:02:20,235 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5099998563528061e-05, 1511
[INFO] 2021-07-12 19:02:20,235 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1511
[INFO] 2021-07-12 19:02:20,235 [run_pretraining.py:  558]:	worker_index: 3, step: 1511, cost: 7.224614, mlm loss: 7.224614, speed: 1.101585 steps/s, speed: 8.812676 samples/s, speed: 4512.090205 tokens/s, learning rate: 1.510e-05, loss_scalings: 6871.948730, pp_loss: 6.423345
[INFO] 2021-07-12 19:02:20,235 [run_pretraining.py:  512]:	********exe.run_1511******* 
[INFO] 2021-07-12 19:02:21,144 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:21,145 [run_pretraining.py:  534]:	loss/total_loss, 6.957989692687988, 1512
[INFO] 2021-07-12 19:02:21,145 [run_pretraining.py:  535]:	loss/mlm_loss, 6.957989692687988, 1512
[INFO] 2021-07-12 19:02:21,145 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5109999367268756e-05, 1512
[INFO] 2021-07-12 19:02:21,145 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1512
[INFO] 2021-07-12 19:02:21,145 [run_pretraining.py:  558]:	worker_index: 3, step: 1512, cost: 6.957990, mlm loss: 6.957990, speed: 1.099207 steps/s, speed: 8.793652 samples/s, speed: 4502.350041 tokens/s, learning rate: 1.511e-05, loss_scalings: 6871.948730, pp_loss: 7.420865
[INFO] 2021-07-12 19:02:21,145 [run_pretraining.py:  512]:	********exe.run_1512******* 
[INFO] 2021-07-12 19:02:22,040 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:22,040 [run_pretraining.py:  534]:	loss/total_loss, 7.261471748352051, 1513
[INFO] 2021-07-12 19:02:22,041 [run_pretraining.py:  535]:	loss/mlm_loss, 7.261471748352051, 1513
[INFO] 2021-07-12 19:02:22,041 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.511999926151475e-05, 1513
[INFO] 2021-07-12 19:02:22,041 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1513
[INFO] 2021-07-12 19:02:22,041 [run_pretraining.py:  558]:	worker_index: 3, step: 1513, cost: 7.261472, mlm loss: 7.261472, speed: 1.117387 steps/s, speed: 8.939095 samples/s, speed: 4576.816830 tokens/s, learning rate: 1.512e-05, loss_scalings: 6871.948730, pp_loss: 7.495358
[INFO] 2021-07-12 19:02:22,041 [run_pretraining.py:  512]:	********exe.run_1513******* 
[INFO] 2021-07-12 19:02:22,980 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:22,986 [run_pretraining.py:  534]:	loss/total_loss, 7.8216328620910645, 1514
[INFO] 2021-07-12 19:02:22,992 [run_pretraining.py:  535]:	loss/mlm_loss, 7.8216328620910645, 1514
[INFO] 2021-07-12 19:02:22,993 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5129999155760743e-05, 1514
[INFO] 2021-07-12 19:02:22,996 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1514
[INFO] 2021-07-12 19:02:22,997 [run_pretraining.py:  558]:	worker_index: 3, step: 1514, cost: 7.821633, mlm loss: 7.821633, speed: 1.058212 steps/s, speed: 8.465694 samples/s, speed: 4334.435583 tokens/s, learning rate: 1.513e-05, loss_scalings: 6871.948730, pp_loss: 6.806353
[INFO] 2021-07-12 19:02:23,001 [run_pretraining.py:  512]:	********exe.run_1514******* 
[INFO] 2021-07-12 19:02:23,899 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:23,899 [run_pretraining.py:  534]:	loss/total_loss, 7.089029788970947, 1515
[INFO] 2021-07-12 19:02:23,899 [run_pretraining.py:  535]:	loss/mlm_loss, 7.089029788970947, 1515
[INFO] 2021-07-12 19:02:23,899 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5139999959501438e-05, 1515
[INFO] 2021-07-12 19:02:23,899 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1515
[INFO] 2021-07-12 19:02:23,900 [run_pretraining.py:  558]:	worker_index: 3, step: 1515, cost: 7.089030, mlm loss: 7.089030, speed: 1.113604 steps/s, speed: 8.908830 samples/s, speed: 4561.321079 tokens/s, learning rate: 1.514e-05, loss_scalings: 6871.948730, pp_loss: 7.187380
[INFO] 2021-07-12 19:02:23,900 [run_pretraining.py:  512]:	********exe.run_1515******* 
[INFO] 2021-07-12 19:02:24,794 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:24,794 [run_pretraining.py:  534]:	loss/total_loss, 7.455512046813965, 1516
[INFO] 2021-07-12 19:02:24,794 [run_pretraining.py:  535]:	loss/mlm_loss, 7.455512046813965, 1516
[INFO] 2021-07-12 19:02:24,794 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5149999853747431e-05, 1516
[INFO] 2021-07-12 19:02:24,794 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1516
[INFO] 2021-07-12 19:02:24,794 [run_pretraining.py:  558]:	worker_index: 3, step: 1516, cost: 7.455512, mlm loss: 7.455512, speed: 1.118320 steps/s, speed: 8.946563 samples/s, speed: 4580.640058 tokens/s, learning rate: 1.515e-05, loss_scalings: 6871.948730, pp_loss: 7.414715
[INFO] 2021-07-12 19:02:24,794 [run_pretraining.py:  512]:	********exe.run_1516******* 
[INFO] 2021-07-12 19:02:25,686 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:25,687 [run_pretraining.py:  534]:	loss/total_loss, 7.203956127166748, 1517
[INFO] 2021-07-12 19:02:25,687 [run_pretraining.py:  535]:	loss/mlm_loss, 7.203956127166748, 1517
[INFO] 2021-07-12 19:02:25,687 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5159999747993425e-05, 1517
[INFO] 2021-07-12 19:02:25,687 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1517
[INFO] 2021-07-12 19:02:25,687 [run_pretraining.py:  558]:	worker_index: 3, step: 1517, cost: 7.203956, mlm loss: 7.203956, speed: 1.121303 steps/s, speed: 8.970425 samples/s, speed: 4592.857753 tokens/s, learning rate: 1.516e-05, loss_scalings: 6871.948730, pp_loss: 7.169850
[INFO] 2021-07-12 19:02:25,687 [run_pretraining.py:  512]:	********exe.run_1517******* 
[INFO] 2021-07-12 19:02:26,587 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:26,588 [run_pretraining.py:  534]:	loss/total_loss, 7.963773727416992, 1518
[INFO] 2021-07-12 19:02:26,588 [run_pretraining.py:  535]:	loss/mlm_loss, 7.963773727416992, 1518
[INFO] 2021-07-12 19:02:26,588 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.517000055173412e-05, 1518
[INFO] 2021-07-12 19:02:26,588 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1518
[INFO] 2021-07-12 19:02:26,588 [run_pretraining.py:  558]:	worker_index: 3, step: 1518, cost: 7.963774, mlm loss: 7.963774, speed: 1.110257 steps/s, speed: 8.882060 samples/s, speed: 4547.614571 tokens/s, learning rate: 1.517e-05, loss_scalings: 6871.948730, pp_loss: 6.958555
[INFO] 2021-07-12 19:02:26,588 [run_pretraining.py:  512]:	********exe.run_1518******* 
[INFO] 2021-07-12 19:02:27,493 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:27,494 [run_pretraining.py:  534]:	loss/total_loss, 7.533297538757324, 1519
[INFO] 2021-07-12 19:02:27,494 [run_pretraining.py:  535]:	loss/mlm_loss, 7.533297538757324, 1519
[INFO] 2021-07-12 19:02:27,494 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5180000445980113e-05, 1519
[INFO] 2021-07-12 19:02:27,494 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1519
[INFO] 2021-07-12 19:02:27,494 [run_pretraining.py:  558]:	worker_index: 3, step: 1519, cost: 7.533298, mlm loss: 7.533298, speed: 1.104887 steps/s, speed: 8.839097 samples/s, speed: 4525.617663 tokens/s, learning rate: 1.518e-05, loss_scalings: 6871.948730, pp_loss: 7.749991
[INFO] 2021-07-12 19:02:27,494 [run_pretraining.py:  512]:	********exe.run_1519******* 
[INFO] 2021-07-12 19:02:28,403 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:28,404 [run_pretraining.py:  534]:	loss/total_loss, 7.288755416870117, 1520
[INFO] 2021-07-12 19:02:28,404 [run_pretraining.py:  535]:	loss/mlm_loss, 7.288755416870117, 1520
[INFO] 2021-07-12 19:02:28,404 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5189998521236703e-05, 1520
[INFO] 2021-07-12 19:02:28,404 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1520
[INFO] 2021-07-12 19:02:28,404 [run_pretraining.py:  558]:	worker_index: 3, step: 1520, cost: 7.288755, mlm loss: 7.288755, speed: 1.099658 steps/s, speed: 8.797265 samples/s, speed: 4504.199761 tokens/s, learning rate: 1.519e-05, loss_scalings: 6871.948730, pp_loss: 7.165740
[INFO] 2021-07-12 19:02:28,404 [run_pretraining.py:  512]:	********exe.run_1520******* 
[INFO] 2021-07-12 19:02:29,314 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:29,314 [run_pretraining.py:  534]:	loss/total_loss, 6.275938510894775, 1521
[INFO] 2021-07-12 19:02:29,314 [run_pretraining.py:  535]:	loss/mlm_loss, 6.275938510894775, 1521
[INFO] 2021-07-12 19:02:29,314 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5199999324977398e-05, 1521
[INFO] 2021-07-12 19:02:29,314 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1521
[INFO] 2021-07-12 19:02:29,315 [run_pretraining.py:  558]:	worker_index: 3, step: 1521, cost: 6.275939, mlm loss: 6.275939, speed: 1.098948 steps/s, speed: 8.791581 samples/s, speed: 4501.289528 tokens/s, learning rate: 1.520e-05, loss_scalings: 6871.948730, pp_loss: 7.323433
[INFO] 2021-07-12 19:02:29,315 [run_pretraining.py:  512]:	********exe.run_1521******* 
[INFO] 2021-07-12 19:02:30,218 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:30,219 [run_pretraining.py:  534]:	loss/total_loss, 7.260838031768799, 1522
[INFO] 2021-07-12 19:02:30,219 [run_pretraining.py:  535]:	loss/mlm_loss, 7.260838031768799, 1522
[INFO] 2021-07-12 19:02:30,219 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5209999219223391e-05, 1522
[INFO] 2021-07-12 19:02:30,219 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1522
[INFO] 2021-07-12 19:02:30,219 [run_pretraining.py:  558]:	worker_index: 3, step: 1522, cost: 7.260838, mlm loss: 7.260838, speed: 1.106211 steps/s, speed: 8.849685 samples/s, speed: 4531.038957 tokens/s, learning rate: 1.521e-05, loss_scalings: 6871.948730, pp_loss: 7.327523
[INFO] 2021-07-12 19:02:30,219 [run_pretraining.py:  512]:	********exe.run_1522******* 
[INFO] 2021-07-12 19:02:31,131 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:31,132 [run_pretraining.py:  534]:	loss/total_loss, 6.557555675506592, 1523
[INFO] 2021-07-12 19:02:31,132 [run_pretraining.py:  535]:	loss/mlm_loss, 6.557555675506592, 1523
[INFO] 2021-07-12 19:02:31,132 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5219999113469385e-05, 1523
[INFO] 2021-07-12 19:02:31,132 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1523
[INFO] 2021-07-12 19:02:31,132 [run_pretraining.py:  558]:	worker_index: 3, step: 1523, cost: 6.557556, mlm loss: 6.557556, speed: 1.096302 steps/s, speed: 8.770417 samples/s, speed: 4490.453580 tokens/s, learning rate: 1.522e-05, loss_scalings: 6871.948730, pp_loss: 7.426296
[INFO] 2021-07-12 19:02:31,132 [run_pretraining.py:  512]:	********exe.run_1523******* 
[INFO] 2021-07-12 19:02:32,041 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:32,041 [run_pretraining.py:  534]:	loss/total_loss, 7.473910331726074, 1524
[INFO] 2021-07-12 19:02:32,041 [run_pretraining.py:  535]:	loss/mlm_loss, 7.473910331726074, 1524
[INFO] 2021-07-12 19:02:32,042 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.522999991721008e-05, 1524
[INFO] 2021-07-12 19:02:32,042 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1524
[INFO] 2021-07-12 19:02:32,042 [run_pretraining.py:  558]:	worker_index: 3, step: 1524, cost: 7.473910, mlm loss: 7.473910, speed: 1.100011 steps/s, speed: 8.800091 samples/s, speed: 4505.646836 tokens/s, learning rate: 1.523e-05, loss_scalings: 6871.948730, pp_loss: 7.634762
[INFO] 2021-07-12 19:02:32,042 [run_pretraining.py:  512]:	********exe.run_1524******* 
[INFO] 2021-07-12 19:02:32,944 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:32,944 [run_pretraining.py:  534]:	loss/total_loss, 7.068208694458008, 1525
[INFO] 2021-07-12 19:02:32,944 [run_pretraining.py:  535]:	loss/mlm_loss, 7.068208694458008, 1525
[INFO] 2021-07-12 19:02:32,944 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5239999811456073e-05, 1525
[INFO] 2021-07-12 19:02:32,944 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1525
[INFO] 2021-07-12 19:02:32,945 [run_pretraining.py:  558]:	worker_index: 3, step: 1525, cost: 7.068209, mlm loss: 7.068209, speed: 1.108389 steps/s, speed: 8.867111 samples/s, speed: 4539.960595 tokens/s, learning rate: 1.524e-05, loss_scalings: 6871.948730, pp_loss: 7.141017
[INFO] 2021-07-12 19:02:32,945 [run_pretraining.py:  512]:	********exe.run_1525******* 
[INFO] 2021-07-12 19:02:33,851 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:33,851 [run_pretraining.py:  534]:	loss/total_loss, 7.692235946655273, 1526
[INFO] 2021-07-12 19:02:33,852 [run_pretraining.py:  535]:	loss/mlm_loss, 7.692235946655273, 1526
[INFO] 2021-07-12 19:02:33,852 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5249999705702066e-05, 1526
[INFO] 2021-07-12 19:02:33,852 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1526
[INFO] 2021-07-12 19:02:33,852 [run_pretraining.py:  558]:	worker_index: 3, step: 1526, cost: 7.692236, mlm loss: 7.692236, speed: 1.103085 steps/s, speed: 8.824682 samples/s, speed: 4518.237112 tokens/s, learning rate: 1.525e-05, loss_scalings: 6871.948730, pp_loss: 6.900661
[INFO] 2021-07-12 19:02:33,852 [run_pretraining.py:  512]:	********exe.run_1526******* 
[INFO] 2021-07-12 19:02:34,762 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:34,762 [run_pretraining.py:  534]:	loss/total_loss, 7.4231109619140625, 1527
[INFO] 2021-07-12 19:02:34,762 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4231109619140625, 1527
[INFO] 2021-07-12 19:02:34,762 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.526000050944276e-05, 1527
[INFO] 2021-07-12 19:02:34,762 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1527
[INFO] 2021-07-12 19:02:34,762 [run_pretraining.py:  558]:	worker_index: 3, step: 1527, cost: 7.423111, mlm loss: 7.423111, speed: 1.098848 steps/s, speed: 8.790784 samples/s, speed: 4500.881499 tokens/s, learning rate: 1.526e-05, loss_scalings: 6871.948730, pp_loss: 7.435764
[INFO] 2021-07-12 19:02:34,763 [run_pretraining.py:  512]:	********exe.run_1527******* 
[INFO] 2021-07-12 19:02:35,657 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:35,657 [run_pretraining.py:  534]:	loss/total_loss, 6.826042175292969, 1528
[INFO] 2021-07-12 19:02:35,657 [run_pretraining.py:  535]:	loss/mlm_loss, 6.826042175292969, 1528
[INFO] 2021-07-12 19:02:35,657 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5269999494194053e-05, 1528
[INFO] 2021-07-12 19:02:35,657 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1528
[INFO] 2021-07-12 19:02:35,658 [run_pretraining.py:  558]:	worker_index: 3, step: 1528, cost: 6.826042, mlm loss: 6.826042, speed: 1.117956 steps/s, speed: 8.943646 samples/s, speed: 4579.146861 tokens/s, learning rate: 1.527e-05, loss_scalings: 6871.948730, pp_loss: 7.209267
[INFO] 2021-07-12 19:02:35,658 [run_pretraining.py:  512]:	********exe.run_1528******* 
[INFO] 2021-07-12 19:02:36,565 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:36,565 [run_pretraining.py:  534]:	loss/total_loss, 7.073193550109863, 1529
[INFO] 2021-07-12 19:02:36,566 [run_pretraining.py:  535]:	loss/mlm_loss, 7.073193550109863, 1529
[INFO] 2021-07-12 19:02:36,566 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5279998478945345e-05, 1529
[INFO] 2021-07-12 19:02:36,566 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1529
[INFO] 2021-07-12 19:02:36,566 [run_pretraining.py:  558]:	worker_index: 3, step: 1529, cost: 7.073194, mlm loss: 7.073194, speed: 1.101799 steps/s, speed: 8.814389 samples/s, speed: 4512.967310 tokens/s, learning rate: 1.528e-05, loss_scalings: 6871.948730, pp_loss: 7.315098
[INFO] 2021-07-12 19:02:36,566 [run_pretraining.py:  512]:	********exe.run_1529******* 
[INFO] 2021-07-12 19:02:37,477 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:37,478 [run_pretraining.py:  534]:	loss/total_loss, 8.214798927307129, 1530
[INFO] 2021-07-12 19:02:37,478 [run_pretraining.py:  535]:	loss/mlm_loss, 8.214798927307129, 1530
[INFO] 2021-07-12 19:02:37,478 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.528999928268604e-05, 1530
[INFO] 2021-07-12 19:02:37,478 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1530
[INFO] 2021-07-12 19:02:37,478 [run_pretraining.py:  558]:	worker_index: 3, step: 1530, cost: 8.214799, mlm loss: 8.214799, speed: 1.096596 steps/s, speed: 8.772767 samples/s, speed: 4491.656954 tokens/s, learning rate: 1.529e-05, loss_scalings: 6871.948730, pp_loss: 7.860037
[INFO] 2021-07-12 19:02:37,478 [run_pretraining.py:  512]:	********exe.run_1530******* 
[INFO] 2021-07-12 19:02:38,379 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:38,380 [run_pretraining.py:  534]:	loss/total_loss, 7.835669040679932, 1531
[INFO] 2021-07-12 19:02:38,380 [run_pretraining.py:  535]:	loss/mlm_loss, 7.835669040679932, 1531
[INFO] 2021-07-12 19:02:38,380 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5300000086426735e-05, 1531
[INFO] 2021-07-12 19:02:38,380 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1531
[INFO] 2021-07-12 19:02:38,380 [run_pretraining.py:  558]:	worker_index: 3, step: 1531, cost: 7.835669, mlm loss: 7.835669, speed: 1.109934 steps/s, speed: 8.879472 samples/s, speed: 4546.289595 tokens/s, learning rate: 1.530e-05, loss_scalings: 6871.948730, pp_loss: 6.838187
[INFO] 2021-07-12 19:02:38,380 [run_pretraining.py:  512]:	********exe.run_1531******* 
[INFO] 2021-07-12 19:02:39,281 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:39,282 [run_pretraining.py:  534]:	loss/total_loss, 7.080060958862305, 1532
[INFO] 2021-07-12 19:02:39,282 [run_pretraining.py:  535]:	loss/mlm_loss, 7.080060958862305, 1532
[INFO] 2021-07-12 19:02:39,282 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5309999071178026e-05, 1532
[INFO] 2021-07-12 19:02:39,282 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1532
[INFO] 2021-07-12 19:02:39,282 [run_pretraining.py:  558]:	worker_index: 3, step: 1532, cost: 7.080061, mlm loss: 7.080061, speed: 1.109193 steps/s, speed: 8.873545 samples/s, speed: 4543.255049 tokens/s, learning rate: 1.531e-05, loss_scalings: 6871.948730, pp_loss: 7.537703
[INFO] 2021-07-12 19:02:39,282 [run_pretraining.py:  512]:	********exe.run_1532******* 
[INFO] 2021-07-12 19:02:40,206 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:40,207 [run_pretraining.py:  534]:	loss/total_loss, 7.584202766418457, 1533
[INFO] 2021-07-12 19:02:40,207 [run_pretraining.py:  535]:	loss/mlm_loss, 7.584202766418457, 1533
[INFO] 2021-07-12 19:02:40,207 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.531999987491872e-05, 1533
[INFO] 2021-07-12 19:02:40,207 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1533
[INFO] 2021-07-12 19:02:40,207 [run_pretraining.py:  558]:	worker_index: 3, step: 1533, cost: 7.584203, mlm loss: 7.584203, speed: 1.082136 steps/s, speed: 8.657090 samples/s, speed: 4432.430256 tokens/s, learning rate: 1.532e-05, loss_scalings: 6871.948730, pp_loss: 7.535914
[INFO] 2021-07-12 19:02:40,207 [run_pretraining.py:  512]:	********exe.run_1533******* 
[INFO] 2021-07-12 19:02:41,118 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:41,118 [run_pretraining.py:  534]:	loss/total_loss, 7.182915687561035, 1534
[INFO] 2021-07-12 19:02:41,118 [run_pretraining.py:  535]:	loss/mlm_loss, 7.182915687561035, 1534
[INFO] 2021-07-12 19:02:41,118 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5330000678659417e-05, 1534
[INFO] 2021-07-12 19:02:41,118 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1534
[INFO] 2021-07-12 19:02:41,118 [run_pretraining.py:  558]:	worker_index: 3, step: 1534, cost: 7.182916, mlm loss: 7.182916, speed: 1.097775 steps/s, speed: 8.782202 samples/s, speed: 4496.487500 tokens/s, learning rate: 1.533e-05, loss_scalings: 6871.948730, pp_loss: 7.297132
[INFO] 2021-07-12 19:02:41,119 [run_pretraining.py:  512]:	********exe.run_1534******* 
[INFO] 2021-07-12 19:02:42,019 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:42,019 [run_pretraining.py:  534]:	loss/total_loss, 7.617510795593262, 1535
[INFO] 2021-07-12 19:02:42,020 [run_pretraining.py:  535]:	loss/mlm_loss, 7.617510795593262, 1535
[INFO] 2021-07-12 19:02:42,020 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.533999966341071e-05, 1535
[INFO] 2021-07-12 19:02:42,020 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1535
[INFO] 2021-07-12 19:02:42,020 [run_pretraining.py:  558]:	worker_index: 3, step: 1535, cost: 7.617511, mlm loss: 7.617511, speed: 1.110284 steps/s, speed: 8.882269 samples/s, speed: 4547.721710 tokens/s, learning rate: 1.534e-05, loss_scalings: 6871.948730, pp_loss: 7.428165
[INFO] 2021-07-12 19:02:42,020 [run_pretraining.py:  512]:	********exe.run_1535******* 
[INFO] 2021-07-12 19:02:42,920 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:42,920 [run_pretraining.py:  534]:	loss/total_loss, 6.739881992340088, 1536
[INFO] 2021-07-12 19:02:42,921 [run_pretraining.py:  535]:	loss/mlm_loss, 6.739881992340088, 1536
[INFO] 2021-07-12 19:02:42,921 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5350000467151403e-05, 1536
[INFO] 2021-07-12 19:02:42,921 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1536
[INFO] 2021-07-12 19:02:42,921 [run_pretraining.py:  558]:	worker_index: 3, step: 1536, cost: 6.739882, mlm loss: 6.739882, speed: 1.110591 steps/s, speed: 8.884729 samples/s, speed: 4548.981273 tokens/s, learning rate: 1.535e-05, loss_scalings: 6871.948730, pp_loss: 7.148390
[INFO] 2021-07-12 19:02:42,921 [run_pretraining.py:  512]:	********exe.run_1536******* 
[INFO] 2021-07-12 19:02:43,825 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:43,826 [run_pretraining.py:  534]:	loss/total_loss, 7.516325950622559, 1537
[INFO] 2021-07-12 19:02:43,826 [run_pretraining.py:  535]:	loss/mlm_loss, 7.516325950622559, 1537
[INFO] 2021-07-12 19:02:43,826 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5359999451902695e-05, 1537
[INFO] 2021-07-12 19:02:43,826 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1537
[INFO] 2021-07-12 19:02:43,826 [run_pretraining.py:  558]:	worker_index: 3, step: 1537, cost: 7.516326, mlm loss: 7.516326, speed: 1.105152 steps/s, speed: 8.841216 samples/s, speed: 4526.702792 tokens/s, learning rate: 1.536e-05, loss_scalings: 6871.948730, pp_loss: 7.294251
[INFO] 2021-07-12 19:02:43,826 [run_pretraining.py:  512]:	********exe.run_1537******* 
[INFO] 2021-07-12 19:02:44,731 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:44,732 [run_pretraining.py:  534]:	loss/total_loss, 7.378949165344238, 1538
[INFO] 2021-07-12 19:02:44,732 [run_pretraining.py:  535]:	loss/mlm_loss, 7.378949165344238, 1538
[INFO] 2021-07-12 19:02:44,732 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5369998436653987e-05, 1538
[INFO] 2021-07-12 19:02:44,732 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1538
[INFO] 2021-07-12 19:02:44,732 [run_pretraining.py:  558]:	worker_index: 3, step: 1538, cost: 7.378949, mlm loss: 7.378949, speed: 1.104933 steps/s, speed: 8.839460 samples/s, speed: 4525.803648 tokens/s, learning rate: 1.537e-05, loss_scalings: 6871.948730, pp_loss: 7.613653
[INFO] 2021-07-12 19:02:44,732 [run_pretraining.py:  512]:	********exe.run_1538******* 
[INFO] 2021-07-12 19:02:45,637 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:45,637 [run_pretraining.py:  534]:	loss/total_loss, 7.234857082366943, 1539
[INFO] 2021-07-12 19:02:45,637 [run_pretraining.py:  535]:	loss/mlm_loss, 7.234857082366943, 1539
[INFO] 2021-07-12 19:02:45,637 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.537999924039468e-05, 1539
[INFO] 2021-07-12 19:02:45,637 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1539
[INFO] 2021-07-12 19:02:45,637 [run_pretraining.py:  558]:	worker_index: 3, step: 1539, cost: 7.234857, mlm loss: 7.234857, speed: 1.105191 steps/s, speed: 8.841526 samples/s, speed: 4526.861431 tokens/s, learning rate: 1.538e-05, loss_scalings: 6871.948730, pp_loss: 7.169691
[INFO] 2021-07-12 19:02:45,638 [run_pretraining.py:  512]:	********exe.run_1539******* 
[INFO] 2021-07-12 19:02:46,547 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:46,548 [run_pretraining.py:  534]:	loss/total_loss, 7.715664863586426, 1540
[INFO] 2021-07-12 19:02:46,548 [run_pretraining.py:  535]:	loss/mlm_loss, 7.715664863586426, 1540
[INFO] 2021-07-12 19:02:46,548 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5390000044135377e-05, 1540
[INFO] 2021-07-12 19:02:46,548 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1540
[INFO] 2021-07-12 19:02:46,548 [run_pretraining.py:  558]:	worker_index: 3, step: 1540, cost: 7.715665, mlm loss: 7.715665, speed: 1.098681 steps/s, speed: 8.789446 samples/s, speed: 4500.196508 tokens/s, learning rate: 1.539e-05, loss_scalings: 6871.948730, pp_loss: 7.242061
[INFO] 2021-07-12 19:02:46,548 [run_pretraining.py:  512]:	********exe.run_1540******* 
[INFO] 2021-07-12 19:02:47,454 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:47,455 [run_pretraining.py:  534]:	loss/total_loss, 7.380170822143555, 1541
[INFO] 2021-07-12 19:02:47,455 [run_pretraining.py:  535]:	loss/mlm_loss, 7.380170822143555, 1541
[INFO] 2021-07-12 19:02:47,455 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.539999902888667e-05, 1541
[INFO] 2021-07-12 19:02:47,455 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1541
[INFO] 2021-07-12 19:02:47,455 [run_pretraining.py:  558]:	worker_index: 3, step: 1541, cost: 7.380171, mlm loss: 7.380171, speed: 1.103392 steps/s, speed: 8.827138 samples/s, speed: 4519.494661 tokens/s, learning rate: 1.540e-05, loss_scalings: 6871.948730, pp_loss: 6.897234
[INFO] 2021-07-12 19:02:47,455 [run_pretraining.py:  512]:	********exe.run_1541******* 
[INFO] 2021-07-12 19:02:48,361 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:48,361 [run_pretraining.py:  534]:	loss/total_loss, 7.639116287231445, 1542
[INFO] 2021-07-12 19:02:48,362 [run_pretraining.py:  535]:	loss/mlm_loss, 7.639116287231445, 1542
[INFO] 2021-07-12 19:02:48,362 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5409999832627364e-05, 1542
[INFO] 2021-07-12 19:02:48,362 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1542
[INFO] 2021-07-12 19:02:48,362 [run_pretraining.py:  558]:	worker_index: 3, step: 1542, cost: 7.639116, mlm loss: 7.639116, speed: 1.103746 steps/s, speed: 8.829970 samples/s, speed: 4520.944444 tokens/s, learning rate: 1.541e-05, loss_scalings: 6871.948730, pp_loss: 7.539439
[INFO] 2021-07-12 19:02:48,362 [run_pretraining.py:  512]:	********exe.run_1542******* 
[INFO] 2021-07-12 19:02:49,400 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:49,400 [run_pretraining.py:  534]:	loss/total_loss, 7.112550735473633, 1543
[INFO] 2021-07-12 19:02:49,400 [run_pretraining.py:  535]:	loss/mlm_loss, 7.112550735473633, 1543
[INFO] 2021-07-12 19:02:49,400 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.542000063636806e-05, 1543
[INFO] 2021-07-12 19:02:49,400 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1543
[INFO] 2021-07-12 19:02:49,401 [run_pretraining.py:  558]:	worker_index: 3, step: 1543, cost: 7.112551, mlm loss: 7.112551, speed: 0.963297 steps/s, speed: 7.706380 samples/s, speed: 3945.666333 tokens/s, learning rate: 1.542e-05, loss_scalings: 6871.948730, pp_loss: 7.391519
[INFO] 2021-07-12 19:02:49,401 [run_pretraining.py:  512]:	********exe.run_1543******* 
[INFO] 2021-07-12 19:02:50,458 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:50,458 [run_pretraining.py:  534]:	loss/total_loss, 5.199542045593262, 1544
[INFO] 2021-07-12 19:02:50,458 [run_pretraining.py:  535]:	loss/mlm_loss, 5.199542045593262, 1544
[INFO] 2021-07-12 19:02:50,458 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.542999962111935e-05, 1544
[INFO] 2021-07-12 19:02:50,458 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1544
[INFO] 2021-07-12 19:02:50,458 [run_pretraining.py:  558]:	worker_index: 3, step: 1544, cost: 5.199542, mlm loss: 5.199542, speed: 0.945833 steps/s, speed: 7.566661 samples/s, speed: 3874.130216 tokens/s, learning rate: 1.543e-05, loss_scalings: 6871.948730, pp_loss: 6.575251
[INFO] 2021-07-12 19:02:50,459 [run_pretraining.py:  512]:	********exe.run_1544******* 
[INFO] 2021-07-12 19:02:51,513 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:51,513 [run_pretraining.py:  534]:	loss/total_loss, 7.274811744689941, 1545
[INFO] 2021-07-12 19:02:51,513 [run_pretraining.py:  535]:	loss/mlm_loss, 7.274811744689941, 1545
[INFO] 2021-07-12 19:02:51,513 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5440000424860045e-05, 1545
[INFO] 2021-07-12 19:02:51,513 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1545
[INFO] 2021-07-12 19:02:51,513 [run_pretraining.py:  558]:	worker_index: 3, step: 1545, cost: 7.274812, mlm loss: 7.274812, speed: 0.948476 steps/s, speed: 7.587806 samples/s, speed: 3884.956732 tokens/s, learning rate: 1.544e-05, loss_scalings: 6871.948730, pp_loss: 7.392505
[INFO] 2021-07-12 19:02:51,513 [run_pretraining.py:  512]:	********exe.run_1545******* 
[INFO] 2021-07-12 19:02:52,569 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:52,569 [run_pretraining.py:  534]:	loss/total_loss, 7.0422282218933105, 1546
[INFO] 2021-07-12 19:02:52,569 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0422282218933105, 1546
[INFO] 2021-07-12 19:02:52,569 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5449999409611337e-05, 1546
[INFO] 2021-07-12 19:02:52,569 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1546
[INFO] 2021-07-12 19:02:52,570 [run_pretraining.py:  558]:	worker_index: 3, step: 1546, cost: 7.042228, mlm loss: 7.042228, speed: 0.947414 steps/s, speed: 7.579310 samples/s, speed: 3880.606776 tokens/s, learning rate: 1.545e-05, loss_scalings: 6871.948730, pp_loss: 7.621788
[INFO] 2021-07-12 19:02:52,570 [run_pretraining.py:  512]:	********exe.run_1546******* 
[INFO] 2021-07-12 19:02:53,653 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:53,654 [run_pretraining.py:  534]:	loss/total_loss, 6.578853607177734, 1547
[INFO] 2021-07-12 19:02:53,654 [run_pretraining.py:  535]:	loss/mlm_loss, 6.578853607177734, 1547
[INFO] 2021-07-12 19:02:53,654 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.545999839436263e-05, 1547
[INFO] 2021-07-12 19:02:53,654 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1547
[INFO] 2021-07-12 19:02:53,654 [run_pretraining.py:  558]:	worker_index: 3, step: 1547, cost: 6.578854, mlm loss: 6.578854, speed: 0.922654 steps/s, speed: 7.381235 samples/s, speed: 3779.192545 tokens/s, learning rate: 1.546e-05, loss_scalings: 6871.948730, pp_loss: 6.976161
[INFO] 2021-07-12 19:02:53,654 [run_pretraining.py:  512]:	********exe.run_1547******* 
[INFO] 2021-07-12 19:02:54,714 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:54,715 [run_pretraining.py:  534]:	loss/total_loss, 6.088226318359375, 1548
[INFO] 2021-07-12 19:02:54,715 [run_pretraining.py:  535]:	loss/mlm_loss, 6.088226318359375, 1548
[INFO] 2021-07-12 19:02:54,715 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5469999198103324e-05, 1548
[INFO] 2021-07-12 19:02:54,715 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1548
[INFO] 2021-07-12 19:02:54,715 [run_pretraining.py:  558]:	worker_index: 3, step: 1548, cost: 6.088226, mlm loss: 6.088226, speed: 0.942880 steps/s, speed: 7.543039 samples/s, speed: 3862.035961 tokens/s, learning rate: 1.547e-05, loss_scalings: 6871.948730, pp_loss: 6.901040
[INFO] 2021-07-12 19:02:54,715 [run_pretraining.py:  512]:	********exe.run_1548******* 
[INFO] 2021-07-12 19:02:55,777 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:55,778 [run_pretraining.py:  534]:	loss/total_loss, 7.99459171295166, 1549
[INFO] 2021-07-12 19:02:55,778 [run_pretraining.py:  535]:	loss/mlm_loss, 7.99459171295166, 1549
[INFO] 2021-07-12 19:02:55,778 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.548000000184402e-05, 1549
[INFO] 2021-07-12 19:02:55,778 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1549
[INFO] 2021-07-12 19:02:55,778 [run_pretraining.py:  558]:	worker_index: 3, step: 1549, cost: 7.994592, mlm loss: 7.994592, speed: 0.941497 steps/s, speed: 7.531974 samples/s, speed: 3856.370688 tokens/s, learning rate: 1.548e-05, loss_scalings: 6871.948730, pp_loss: 7.515805
[INFO] 2021-07-12 19:02:55,778 [run_pretraining.py:  512]:	********exe.run_1549******* 
[INFO] 2021-07-12 19:02:56,754 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:56,755 [run_pretraining.py:  534]:	loss/total_loss, 7.375293254852295, 1550
[INFO] 2021-07-12 19:02:56,755 [run_pretraining.py:  535]:	loss/mlm_loss, 7.375293254852295, 1550
[INFO] 2021-07-12 19:02:56,755 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.548999898659531e-05, 1550
[INFO] 2021-07-12 19:02:56,755 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1550
[INFO] 2021-07-12 19:02:56,755 [run_pretraining.py:  558]:	worker_index: 3, step: 1550, cost: 7.375293, mlm loss: 7.375293, speed: 1.023979 steps/s, speed: 8.191832 samples/s, speed: 4194.217986 tokens/s, learning rate: 1.549e-05, loss_scalings: 6871.948730, pp_loss: 7.562371
[INFO] 2021-07-12 19:02:56,755 [run_pretraining.py:  512]:	********exe.run_1550******* 
[INFO] 2021-07-12 19:02:57,716 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:57,716 [run_pretraining.py:  534]:	loss/total_loss, 7.611745834350586, 1551
[INFO] 2021-07-12 19:02:57,716 [run_pretraining.py:  535]:	loss/mlm_loss, 7.611745834350586, 1551
[INFO] 2021-07-12 19:02:57,717 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5499999790336005e-05, 1551
[INFO] 2021-07-12 19:02:57,717 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1551
[INFO] 2021-07-12 19:02:57,717 [run_pretraining.py:  558]:	worker_index: 3, step: 1551, cost: 7.611746, mlm loss: 7.611746, speed: 1.040830 steps/s, speed: 8.326639 samples/s, speed: 4263.239204 tokens/s, learning rate: 1.550e-05, loss_scalings: 6871.948730, pp_loss: 7.454369
[INFO] 2021-07-12 19:02:57,717 [run_pretraining.py:  512]:	********exe.run_1551******* 
[INFO] 2021-07-12 19:02:58,671 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:58,671 [run_pretraining.py:  534]:	loss/total_loss, 7.935825824737549, 1552
[INFO] 2021-07-12 19:02:58,672 [run_pretraining.py:  535]:	loss/mlm_loss, 7.935825824737549, 1552
[INFO] 2021-07-12 19:02:58,672 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.55100005940767e-05, 1552
[INFO] 2021-07-12 19:02:58,672 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1552
[INFO] 2021-07-12 19:02:58,672 [run_pretraining.py:  558]:	worker_index: 3, step: 1552, cost: 7.935826, mlm loss: 7.935826, speed: 1.047763 steps/s, speed: 8.382103 samples/s, speed: 4291.636986 tokens/s, learning rate: 1.551e-05, loss_scalings: 6871.948730, pp_loss: 7.384686
[INFO] 2021-07-12 19:02:58,672 [run_pretraining.py:  512]:	********exe.run_1552******* 
[INFO] 2021-07-12 19:02:59,631 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:59,632 [run_pretraining.py:  534]:	loss/total_loss, 3.274552583694458, 1553
[INFO] 2021-07-12 19:02:59,632 [run_pretraining.py:  535]:	loss/mlm_loss, 3.274552583694458, 1553
[INFO] 2021-07-12 19:02:59,632 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5519999578827992e-05, 1553
[INFO] 2021-07-12 19:02:59,632 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1553
[INFO] 2021-07-12 19:02:59,632 [run_pretraining.py:  558]:	worker_index: 3, step: 1553, cost: 3.274553, mlm loss: 3.274553, speed: 1.042001 steps/s, speed: 8.336012 samples/s, speed: 4268.038110 tokens/s, learning rate: 1.552e-05, loss_scalings: 6871.948730, pp_loss: 5.742775
[INFO] 2021-07-12 19:02:59,632 [run_pretraining.py:  512]:	********exe.run_1553******* 
[INFO] 2021-07-12 19:03:00,589 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:00,589 [run_pretraining.py:  534]:	loss/total_loss, 7.38375186920166, 1554
[INFO] 2021-07-12 19:03:00,589 [run_pretraining.py:  535]:	loss/mlm_loss, 7.38375186920166, 1554
[INFO] 2021-07-12 19:03:00,589 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5530000382568687e-05, 1554
[INFO] 2021-07-12 19:03:00,589 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1554
[INFO] 2021-07-12 19:03:00,589 [run_pretraining.py:  558]:	worker_index: 3, step: 1554, cost: 7.383752, mlm loss: 7.383752, speed: 1.045206 steps/s, speed: 8.361648 samples/s, speed: 4281.163754 tokens/s, learning rate: 1.553e-05, loss_scalings: 6871.948730, pp_loss: 7.390882
[INFO] 2021-07-12 19:03:00,590 [run_pretraining.py:  512]:	********exe.run_1554******* 
[INFO] 2021-07-12 19:03:01,499 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:01,499 [run_pretraining.py:  534]:	loss/total_loss, 7.505446434020996, 1555
[INFO] 2021-07-12 19:03:01,499 [run_pretraining.py:  535]:	loss/mlm_loss, 7.505446434020996, 1555
[INFO] 2021-07-12 19:03:01,500 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.553999936731998e-05, 1555
[INFO] 2021-07-12 19:03:01,500 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1555
[INFO] 2021-07-12 19:03:01,500 [run_pretraining.py:  558]:	worker_index: 3, step: 1555, cost: 7.505446, mlm loss: 7.505446, speed: 1.099432 steps/s, speed: 8.795457 samples/s, speed: 4503.274121 tokens/s, learning rate: 1.554e-05, loss_scalings: 6871.948730, pp_loss: 7.260728
[INFO] 2021-07-12 19:03:01,500 [run_pretraining.py:  512]:	********exe.run_1555******* 
[INFO] 2021-07-12 19:03:02,436 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:02,436 [run_pretraining.py:  534]:	loss/total_loss, 7.588671684265137, 1556
[INFO] 2021-07-12 19:03:02,437 [run_pretraining.py:  535]:	loss/mlm_loss, 7.588671684265137, 1556
[INFO] 2021-07-12 19:03:02,437 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.554999835207127e-05, 1556
[INFO] 2021-07-12 19:03:02,437 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1556
[INFO] 2021-07-12 19:03:02,437 [run_pretraining.py:  558]:	worker_index: 3, step: 1556, cost: 7.588672, mlm loss: 7.588672, speed: 1.067932 steps/s, speed: 8.543454 samples/s, speed: 4374.248360 tokens/s, learning rate: 1.555e-05, loss_scalings: 6871.948730, pp_loss: 6.012617
[INFO] 2021-07-12 19:03:02,437 [run_pretraining.py:  512]:	********exe.run_1556******* 
[INFO] 2021-07-12 19:03:03,347 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:03,348 [run_pretraining.py:  534]:	loss/total_loss, 7.696080684661865, 1557
[INFO] 2021-07-12 19:03:03,348 [run_pretraining.py:  535]:	loss/mlm_loss, 7.696080684661865, 1557
[INFO] 2021-07-12 19:03:03,348 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5559999155811965e-05, 1557
[INFO] 2021-07-12 19:03:03,348 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1557
[INFO] 2021-07-12 19:03:03,348 [run_pretraining.py:  558]:	worker_index: 3, step: 1557, cost: 7.696081, mlm loss: 7.696081, speed: 1.097876 steps/s, speed: 8.783009 samples/s, speed: 4496.900618 tokens/s, learning rate: 1.556e-05, loss_scalings: 6871.948730, pp_loss: 7.535079
[INFO] 2021-07-12 19:03:03,348 [run_pretraining.py:  512]:	********exe.run_1557******* 
[INFO] 2021-07-12 19:03:04,250 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:04,251 [run_pretraining.py:  534]:	loss/total_loss, 7.5681610107421875, 1558
[INFO] 2021-07-12 19:03:04,251 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5681610107421875, 1558
[INFO] 2021-07-12 19:03:04,251 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.556999995955266e-05, 1558
[INFO] 2021-07-12 19:03:04,251 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1558
[INFO] 2021-07-12 19:03:04,251 [run_pretraining.py:  558]:	worker_index: 3, step: 1558, cost: 7.568161, mlm loss: 7.568161, speed: 1.108689 steps/s, speed: 8.869513 samples/s, speed: 4541.190653 tokens/s, learning rate: 1.557e-05, loss_scalings: 6871.948730, pp_loss: 7.313177
[INFO] 2021-07-12 19:03:04,251 [run_pretraining.py:  512]:	********exe.run_1558******* 
[INFO] 2021-07-12 19:03:05,163 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:05,163 [run_pretraining.py:  534]:	loss/total_loss, 7.586784362792969, 1559
[INFO] 2021-07-12 19:03:05,163 [run_pretraining.py:  535]:	loss/mlm_loss, 7.586784362792969, 1559
[INFO] 2021-07-12 19:03:05,163 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5579998944303952e-05, 1559
[INFO] 2021-07-12 19:03:05,164 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1559
[INFO] 2021-07-12 19:03:05,164 [run_pretraining.py:  558]:	worker_index: 3, step: 1559, cost: 7.586784, mlm loss: 7.586784, speed: 1.096389 steps/s, speed: 8.771114 samples/s, speed: 4490.810416 tokens/s, learning rate: 1.558e-05, loss_scalings: 6871.948730, pp_loss: 7.751586
[INFO] 2021-07-12 19:03:05,164 [run_pretraining.py:  512]:	********exe.run_1559******* 
[INFO] 2021-07-12 19:03:06,112 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:06,113 [run_pretraining.py:  534]:	loss/total_loss, 7.465387344360352, 1560
[INFO] 2021-07-12 19:03:06,113 [run_pretraining.py:  535]:	loss/mlm_loss, 7.465387344360352, 1560
[INFO] 2021-07-12 19:03:06,113 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5589999748044647e-05, 1560
[INFO] 2021-07-12 19:03:06,113 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1560
[INFO] 2021-07-12 19:03:06,113 [run_pretraining.py:  558]:	worker_index: 3, step: 1560, cost: 7.465387, mlm loss: 7.465387, speed: 1.053852 steps/s, speed: 8.430817 samples/s, speed: 4316.578245 tokens/s, learning rate: 1.559e-05, loss_scalings: 6871.948730, pp_loss: 7.657238
[INFO] 2021-07-12 19:03:06,113 [run_pretraining.py:  512]:	********exe.run_1560******* 
[INFO] 2021-07-12 19:03:07,014 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:07,014 [run_pretraining.py:  534]:	loss/total_loss, 7.608846664428711, 1561
[INFO] 2021-07-12 19:03:07,014 [run_pretraining.py:  535]:	loss/mlm_loss, 7.608846664428711, 1561
[INFO] 2021-07-12 19:03:07,015 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5600000551785342e-05, 1561
[INFO] 2021-07-12 19:03:07,015 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1561
[INFO] 2021-07-12 19:03:07,015 [run_pretraining.py:  558]:	worker_index: 3, step: 1561, cost: 7.608847, mlm loss: 7.608847, speed: 1.110065 steps/s, speed: 8.880522 samples/s, speed: 4546.827435 tokens/s, learning rate: 1.560e-05, loss_scalings: 6871.948730, pp_loss: 7.268246
[INFO] 2021-07-12 19:03:07,015 [run_pretraining.py:  512]:	********exe.run_1561******* 
[INFO] 2021-07-12 19:03:07,917 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:07,917 [run_pretraining.py:  534]:	loss/total_loss, 4.735064506530762, 1562
[INFO] 2021-07-12 19:03:07,917 [run_pretraining.py:  535]:	loss/mlm_loss, 4.735064506530762, 1562
[INFO] 2021-07-12 19:03:07,917 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5609999536536634e-05, 1562
[INFO] 2021-07-12 19:03:07,917 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1562
[INFO] 2021-07-12 19:03:07,917 [run_pretraining.py:  558]:	worker_index: 3, step: 1562, cost: 4.735065, mlm loss: 4.735065, speed: 1.108425 steps/s, speed: 8.867403 samples/s, speed: 4540.110566 tokens/s, learning rate: 1.561e-05, loss_scalings: 6871.948730, pp_loss: 6.714155
[INFO] 2021-07-12 19:03:07,918 [run_pretraining.py:  512]:	********exe.run_1562******* 
[INFO] 2021-07-12 19:03:08,824 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:08,824 [run_pretraining.py:  534]:	loss/total_loss, 6.968767166137695, 1563
[INFO] 2021-07-12 19:03:08,825 [run_pretraining.py:  535]:	loss/mlm_loss, 6.968767166137695, 1563
[INFO] 2021-07-12 19:03:08,825 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.562000034027733e-05, 1563
[INFO] 2021-07-12 19:03:08,825 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1563
[INFO] 2021-07-12 19:03:08,825 [run_pretraining.py:  558]:	worker_index: 3, step: 1563, cost: 6.968767, mlm loss: 6.968767, speed: 1.102916 steps/s, speed: 8.823329 samples/s, speed: 4517.544452 tokens/s, learning rate: 1.562e-05, loss_scalings: 6871.948730, pp_loss: 7.063643
[INFO] 2021-07-12 19:03:08,825 [run_pretraining.py:  512]:	********exe.run_1563******* 
[INFO] 2021-07-12 19:03:09,730 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:09,730 [run_pretraining.py:  534]:	loss/total_loss, 7.085908889770508, 1564
[INFO] 2021-07-12 19:03:09,730 [run_pretraining.py:  535]:	loss/mlm_loss, 7.085908889770508, 1564
[INFO] 2021-07-12 19:03:09,730 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.562999932502862e-05, 1564
[INFO] 2021-07-12 19:03:09,730 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1564
[INFO] 2021-07-12 19:03:09,730 [run_pretraining.py:  558]:	worker_index: 3, step: 1564, cost: 7.085909, mlm loss: 7.085909, speed: 1.104918 steps/s, speed: 8.839346 samples/s, speed: 4525.745228 tokens/s, learning rate: 1.563e-05, loss_scalings: 6871.948730, pp_loss: 7.100545
[INFO] 2021-07-12 19:03:09,731 [run_pretraining.py:  512]:	********exe.run_1564******* 
[INFO] 2021-07-12 19:03:10,638 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:10,639 [run_pretraining.py:  534]:	loss/total_loss, 7.353474140167236, 1565
[INFO] 2021-07-12 19:03:10,639 [run_pretraining.py:  535]:	loss/mlm_loss, 7.353474140167236, 1565
[INFO] 2021-07-12 19:03:10,639 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5639998309779912e-05, 1565
[INFO] 2021-07-12 19:03:10,639 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1565
[INFO] 2021-07-12 19:03:10,639 [run_pretraining.py:  558]:	worker_index: 3, step: 1565, cost: 7.353474, mlm loss: 7.353474, speed: 1.101306 steps/s, speed: 8.810450 samples/s, speed: 4510.950477 tokens/s, learning rate: 1.564e-05, loss_scalings: 6871.948730, pp_loss: 7.706776
[INFO] 2021-07-12 19:03:10,639 [run_pretraining.py:  512]:	********exe.run_1565******* 
[INFO] 2021-07-12 19:03:11,543 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:11,544 [run_pretraining.py:  534]:	loss/total_loss, 7.566082000732422, 1566
[INFO] 2021-07-12 19:03:11,544 [run_pretraining.py:  535]:	loss/mlm_loss, 7.566082000732422, 1566
[INFO] 2021-07-12 19:03:11,544 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5649999113520607e-05, 1566
[INFO] 2021-07-12 19:03:11,544 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1566
[INFO] 2021-07-12 19:03:11,544 [run_pretraining.py:  558]:	worker_index: 3, step: 1566, cost: 7.566082, mlm loss: 7.566082, speed: 1.105662 steps/s, speed: 8.845293 samples/s, speed: 4528.789848 tokens/s, learning rate: 1.565e-05, loss_scalings: 6871.948730, pp_loss: 7.576217
[INFO] 2021-07-12 19:03:11,544 [run_pretraining.py:  512]:	********exe.run_1566******* 
[INFO] 2021-07-12 19:03:12,451 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:12,451 [run_pretraining.py:  534]:	loss/total_loss, 7.146820068359375, 1567
[INFO] 2021-07-12 19:03:12,452 [run_pretraining.py:  535]:	loss/mlm_loss, 7.146820068359375, 1567
[INFO] 2021-07-12 19:03:12,452 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5659999917261302e-05, 1567
[INFO] 2021-07-12 19:03:12,452 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1567
[INFO] 2021-07-12 19:03:12,452 [run_pretraining.py:  558]:	worker_index: 3, step: 1567, cost: 7.146820, mlm loss: 7.146820, speed: 1.102527 steps/s, speed: 8.820214 samples/s, speed: 4515.949647 tokens/s, learning rate: 1.566e-05, loss_scalings: 6871.948730, pp_loss: 7.271896
[INFO] 2021-07-12 19:03:12,452 [run_pretraining.py:  512]:	********exe.run_1567******* 
[INFO] 2021-07-12 19:03:13,362 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:13,362 [run_pretraining.py:  534]:	loss/total_loss, 7.803762435913086, 1568
[INFO] 2021-07-12 19:03:13,362 [run_pretraining.py:  535]:	loss/mlm_loss, 7.803762435913086, 1568
[INFO] 2021-07-12 19:03:13,363 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5669998902012594e-05, 1568
[INFO] 2021-07-12 19:03:13,363 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1568
[INFO] 2021-07-12 19:03:13,363 [run_pretraining.py:  558]:	worker_index: 3, step: 1568, cost: 7.803762, mlm loss: 7.803762, speed: 1.098641 steps/s, speed: 8.789126 samples/s, speed: 4500.032659 tokens/s, learning rate: 1.567e-05, loss_scalings: 6871.948730, pp_loss: 7.289882
[INFO] 2021-07-12 19:03:13,363 [run_pretraining.py:  512]:	********exe.run_1568******* 
[INFO] 2021-07-12 19:03:14,264 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:14,264 [run_pretraining.py:  534]:	loss/total_loss, 7.467939376831055, 1569
[INFO] 2021-07-12 19:03:14,265 [run_pretraining.py:  535]:	loss/mlm_loss, 7.467939376831055, 1569
[INFO] 2021-07-12 19:03:14,265 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.567999970575329e-05, 1569
[INFO] 2021-07-12 19:03:14,265 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1569
[INFO] 2021-07-12 19:03:14,265 [run_pretraining.py:  558]:	worker_index: 3, step: 1569, cost: 7.467939, mlm loss: 7.467939, speed: 1.109382 steps/s, speed: 8.875054 samples/s, speed: 4544.027728 tokens/s, learning rate: 1.568e-05, loss_scalings: 6871.948730, pp_loss: 7.289916
[INFO] 2021-07-12 19:03:14,265 [run_pretraining.py:  512]:	********exe.run_1569******* 
[INFO] 2021-07-12 19:03:15,171 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:15,172 [run_pretraining.py:  534]:	loss/total_loss, 7.1173529624938965, 1570
[INFO] 2021-07-12 19:03:15,172 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1173529624938965, 1570
[INFO] 2021-07-12 19:03:15,172 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5690000509493984e-05, 1570
[INFO] 2021-07-12 19:03:15,172 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1570
[INFO] 2021-07-12 19:03:15,172 [run_pretraining.py:  558]:	worker_index: 3, step: 1570, cost: 7.117353, mlm loss: 7.117353, speed: 1.102697 steps/s, speed: 8.821578 samples/s, speed: 4516.647755 tokens/s, learning rate: 1.569e-05, loss_scalings: 6871.948730, pp_loss: 7.340775
[INFO] 2021-07-12 19:03:15,172 [run_pretraining.py:  512]:	********exe.run_1570******* 
[INFO] 2021-07-12 19:03:16,077 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:16,077 [run_pretraining.py:  534]:	loss/total_loss, 8.241722106933594, 1571
[INFO] 2021-07-12 19:03:16,077 [run_pretraining.py:  535]:	loss/mlm_loss, 8.241722106933594, 1571
[INFO] 2021-07-12 19:03:16,078 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5699999494245276e-05, 1571
[INFO] 2021-07-12 19:03:16,078 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1571
[INFO] 2021-07-12 19:03:16,078 [run_pretraining.py:  558]:	worker_index: 3, step: 1571, cost: 8.241722, mlm loss: 8.241722, speed: 1.105204 steps/s, speed: 8.841633 samples/s, speed: 4526.916302 tokens/s, learning rate: 1.570e-05, loss_scalings: 6871.948730, pp_loss: 7.414798
[INFO] 2021-07-12 19:03:16,078 [run_pretraining.py:  512]:	********exe.run_1571******* 
[INFO] 2021-07-12 19:03:16,988 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:16,988 [run_pretraining.py:  534]:	loss/total_loss, 7.606781482696533, 1572
[INFO] 2021-07-12 19:03:16,988 [run_pretraining.py:  535]:	loss/mlm_loss, 7.606781482696533, 1572
[INFO] 2021-07-12 19:03:16,988 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.571000029798597e-05, 1572
[INFO] 2021-07-12 19:03:16,988 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1572
[INFO] 2021-07-12 19:03:16,988 [run_pretraining.py:  558]:	worker_index: 3, step: 1572, cost: 7.606781, mlm loss: 7.606781, speed: 1.098767 steps/s, speed: 8.790132 samples/s, speed: 4500.547820 tokens/s, learning rate: 1.571e-05, loss_scalings: 6871.948730, pp_loss: 7.397435
[INFO] 2021-07-12 19:03:16,989 [run_pretraining.py:  512]:	********exe.run_1572******* 
[INFO] 2021-07-12 19:03:17,920 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:17,920 [run_pretraining.py:  534]:	loss/total_loss, 7.211640357971191, 1573
[INFO] 2021-07-12 19:03:17,920 [run_pretraining.py:  535]:	loss/mlm_loss, 7.211640357971191, 1573
[INFO] 2021-07-12 19:03:17,920 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5719999282737263e-05, 1573
[INFO] 2021-07-12 19:03:17,921 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1573
[INFO] 2021-07-12 19:03:17,921 [run_pretraining.py:  558]:	worker_index: 3, step: 1573, cost: 7.211640, mlm loss: 7.211640, speed: 1.073512 steps/s, speed: 8.588097 samples/s, speed: 4397.105460 tokens/s, learning rate: 1.572e-05, loss_scalings: 6871.948730, pp_loss: 7.965775
[INFO] 2021-07-12 19:03:17,921 [run_pretraining.py:  512]:	********exe.run_1573******* 
[INFO] 2021-07-12 19:03:18,827 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:18,828 [run_pretraining.py:  534]:	loss/total_loss, 7.446908950805664, 1574
[INFO] 2021-07-12 19:03:18,828 [run_pretraining.py:  535]:	loss/mlm_loss, 7.446908950805664, 1574
[INFO] 2021-07-12 19:03:18,828 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5729998267488554e-05, 1574
[INFO] 2021-07-12 19:03:18,828 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1574
[INFO] 2021-07-12 19:03:18,828 [run_pretraining.py:  558]:	worker_index: 3, step: 1574, cost: 7.446909, mlm loss: 7.446909, speed: 1.102466 steps/s, speed: 8.819725 samples/s, speed: 4515.699188 tokens/s, learning rate: 1.573e-05, loss_scalings: 6871.948730, pp_loss: 7.265102
[INFO] 2021-07-12 19:03:18,828 [run_pretraining.py:  512]:	********exe.run_1574******* 
[INFO] 2021-07-12 19:03:19,732 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:19,732 [run_pretraining.py:  534]:	loss/total_loss, 7.245140552520752, 1575
[INFO] 2021-07-12 19:03:19,732 [run_pretraining.py:  535]:	loss/mlm_loss, 7.245140552520752, 1575
[INFO] 2021-07-12 19:03:19,732 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.573999907122925e-05, 1575
[INFO] 2021-07-12 19:03:19,732 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1575
[INFO] 2021-07-12 19:03:19,733 [run_pretraining.py:  558]:	worker_index: 3, step: 1575, cost: 7.245141, mlm loss: 7.245141, speed: 1.106655 steps/s, speed: 8.853244 samples/s, speed: 4532.860902 tokens/s, learning rate: 1.574e-05, loss_scalings: 6871.948730, pp_loss: 7.072955
[INFO] 2021-07-12 19:03:19,733 [run_pretraining.py:  512]:	********exe.run_1575******* 
[INFO] 2021-07-12 19:03:20,648 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:20,648 [run_pretraining.py:  534]:	loss/total_loss, 8.25535774230957, 1576
[INFO] 2021-07-12 19:03:20,648 [run_pretraining.py:  535]:	loss/mlm_loss, 8.25535774230957, 1576
[INFO] 2021-07-12 19:03:20,648 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5749999874969944e-05, 1576
[INFO] 2021-07-12 19:03:20,648 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1576
[INFO] 2021-07-12 19:03:20,648 [run_pretraining.py:  558]:	worker_index: 3, step: 1576, cost: 8.255358, mlm loss: 8.255358, speed: 1.092616 steps/s, speed: 8.740924 samples/s, speed: 4475.353116 tokens/s, learning rate: 1.575e-05, loss_scalings: 6871.948730, pp_loss: 7.718525
[INFO] 2021-07-12 19:03:20,648 [run_pretraining.py:  512]:	********exe.run_1576******* 
[INFO] 2021-07-12 19:03:21,560 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:21,560 [run_pretraining.py:  534]:	loss/total_loss, 7.018786430358887, 1577
[INFO] 2021-07-12 19:03:21,561 [run_pretraining.py:  535]:	loss/mlm_loss, 7.018786430358887, 1577
[INFO] 2021-07-12 19:03:21,561 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5759998859721236e-05, 1577
[INFO] 2021-07-12 19:03:21,561 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1577
[INFO] 2021-07-12 19:03:21,561 [run_pretraining.py:  558]:	worker_index: 3, step: 1577, cost: 7.018786, mlm loss: 7.018786, speed: 1.096764 steps/s, speed: 8.774109 samples/s, speed: 4492.344047 tokens/s, learning rate: 1.576e-05, loss_scalings: 6871.948730, pp_loss: 7.268128
[INFO] 2021-07-12 19:03:21,561 [run_pretraining.py:  512]:	********exe.run_1577******* 
[INFO] 2021-07-12 19:03:22,472 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:22,472 [run_pretraining.py:  534]:	loss/total_loss, 7.548604965209961, 1578
[INFO] 2021-07-12 19:03:22,472 [run_pretraining.py:  535]:	loss/mlm_loss, 7.548604965209961, 1578
[INFO] 2021-07-12 19:03:22,472 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.576999966346193e-05, 1578
[INFO] 2021-07-12 19:03:22,472 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1578
[INFO] 2021-07-12 19:03:22,473 [run_pretraining.py:  558]:	worker_index: 3, step: 1578, cost: 7.548605, mlm loss: 7.548605, speed: 1.097531 steps/s, speed: 8.780249 samples/s, speed: 4495.487387 tokens/s, learning rate: 1.577e-05, loss_scalings: 6871.948730, pp_loss: 7.039162
[INFO] 2021-07-12 19:03:22,473 [run_pretraining.py:  512]:	********exe.run_1578******* 
[INFO] 2021-07-12 19:03:47,837 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:47,838 [run_pretraining.py:  534]:	loss/total_loss, 7.714801788330078, 1579
[INFO] 2021-07-12 19:03:47,838 [run_pretraining.py:  535]:	loss/mlm_loss, 7.714801788330078, 1579
[INFO] 2021-07-12 19:03:47,838 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5780000467202626e-05, 1579
[INFO] 2021-07-12 19:03:47,838 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1579
[INFO] 2021-07-12 19:03:47,838 [run_pretraining.py:  558]:	worker_index: 3, step: 1579, cost: 7.714802, mlm loss: 7.714802, speed: 0.039424 steps/s, speed: 0.315394 samples/s, speed: 161.481949 tokens/s, learning rate: 1.578e-05, loss_scalings: 6871.948730, pp_loss: 6.999663
[INFO] 2021-07-12 19:03:47,838 [run_pretraining.py:  512]:	********exe.run_1579******* 
[INFO] 2021-07-12 19:03:48,766 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:48,767 [run_pretraining.py:  534]:	loss/total_loss, 7.688450336456299, 1580
[INFO] 2021-07-12 19:03:48,767 [run_pretraining.py:  535]:	loss/mlm_loss, 7.688450336456299, 1580
[INFO] 2021-07-12 19:03:48,767 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5789999451953918e-05, 1580
[INFO] 2021-07-12 19:03:48,767 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1580
[INFO] 2021-07-12 19:03:48,767 [run_pretraining.py:  558]:	worker_index: 3, step: 1580, cost: 7.688450, mlm loss: 7.688450, speed: 1.077596 steps/s, speed: 8.620765 samples/s, speed: 4413.831786 tokens/s, learning rate: 1.579e-05, loss_scalings: 6871.948730, pp_loss: 7.107636
[INFO] 2021-07-12 19:03:48,767 [run_pretraining.py:  512]:	********exe.run_1580******* 
[INFO] 2021-07-12 19:03:49,691 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:49,692 [run_pretraining.py:  534]:	loss/total_loss, 7.154930114746094, 1581
[INFO] 2021-07-12 19:03:49,692 [run_pretraining.py:  535]:	loss/mlm_loss, 7.154930114746094, 1581
[INFO] 2021-07-12 19:03:49,692 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5800000255694613e-05, 1581
[INFO] 2021-07-12 19:03:49,692 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1581
[INFO] 2021-07-12 19:03:49,692 [run_pretraining.py:  558]:	worker_index: 3, step: 1581, cost: 7.154930, mlm loss: 7.154930, speed: 1.081583 steps/s, speed: 8.652668 samples/s, speed: 4430.165994 tokens/s, learning rate: 1.580e-05, loss_scalings: 6871.948730, pp_loss: 7.292420
[INFO] 2021-07-12 19:03:49,692 [run_pretraining.py:  512]:	********exe.run_1581******* 
[INFO] 2021-07-12 19:03:50,660 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:50,660 [run_pretraining.py:  534]:	loss/total_loss, 7.141698837280273, 1582
[INFO] 2021-07-12 19:03:50,660 [run_pretraining.py:  535]:	loss/mlm_loss, 7.141698837280273, 1582
[INFO] 2021-07-12 19:03:50,660 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5809999240445904e-05, 1582
[INFO] 2021-07-12 19:03:50,661 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1582
[INFO] 2021-07-12 19:03:50,661 [run_pretraining.py:  558]:	worker_index: 3, step: 1582, cost: 7.141699, mlm loss: 7.141699, speed: 1.033225 steps/s, speed: 8.265799 samples/s, speed: 4232.089033 tokens/s, learning rate: 1.581e-05, loss_scalings: 6871.948730, pp_loss: 7.093626
[INFO] 2021-07-12 19:03:50,661 [run_pretraining.py:  512]:	********exe.run_1582******* 
[INFO] 2021-07-12 19:03:51,579 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:51,580 [run_pretraining.py:  534]:	loss/total_loss, 8.040035247802734, 1583
[INFO] 2021-07-12 19:03:51,580 [run_pretraining.py:  535]:	loss/mlm_loss, 8.040035247802734, 1583
[INFO] 2021-07-12 19:03:51,580 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.58200000441866e-05, 1583
[INFO] 2021-07-12 19:03:51,580 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1583
[INFO] 2021-07-12 19:03:51,580 [run_pretraining.py:  558]:	worker_index: 3, step: 1583, cost: 8.040035, mlm loss: 8.040035, speed: 1.088329 steps/s, speed: 8.706631 samples/s, speed: 4457.794943 tokens/s, learning rate: 1.582e-05, loss_scalings: 6871.948730, pp_loss: 7.571428
[INFO] 2021-07-12 19:03:51,580 [run_pretraining.py:  512]:	********exe.run_1583******* 
[INFO] 2021-07-12 19:03:52,498 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:52,499 [run_pretraining.py:  534]:	loss/total_loss, 7.240086555480957, 1584
[INFO] 2021-07-12 19:03:52,499 [run_pretraining.py:  535]:	loss/mlm_loss, 7.240086555480957, 1584
[INFO] 2021-07-12 19:03:52,499 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.582999902893789e-05, 1584
[INFO] 2021-07-12 19:03:52,499 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1584
[INFO] 2021-07-12 19:03:52,499 [run_pretraining.py:  558]:	worker_index: 3, step: 1584, cost: 7.240087, mlm loss: 7.240087, speed: 1.089145 steps/s, speed: 8.713160 samples/s, speed: 4461.137995 tokens/s, learning rate: 1.583e-05, loss_scalings: 6871.948730, pp_loss: 7.446240
[INFO] 2021-07-12 19:03:52,499 [run_pretraining.py:  512]:	********exe.run_1584******* 
[INFO] 2021-07-12 19:03:53,417 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:53,417 [run_pretraining.py:  534]:	loss/total_loss, 7.438270092010498, 1585
[INFO] 2021-07-12 19:03:53,418 [run_pretraining.py:  535]:	loss/mlm_loss, 7.438270092010498, 1585
[INFO] 2021-07-12 19:03:53,418 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5839999832678586e-05, 1585
[INFO] 2021-07-12 19:03:53,418 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1585
[INFO] 2021-07-12 19:03:53,418 [run_pretraining.py:  558]:	worker_index: 3, step: 1585, cost: 7.438270, mlm loss: 7.438270, speed: 1.088977 steps/s, speed: 8.711816 samples/s, speed: 4460.449991 tokens/s, learning rate: 1.584e-05, loss_scalings: 6871.948730, pp_loss: 7.817051
[INFO] 2021-07-12 19:03:53,418 [run_pretraining.py:  512]:	********exe.run_1585******* 
[INFO] 2021-07-12 19:03:54,399 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:54,400 [run_pretraining.py:  534]:	loss/total_loss, 7.720065116882324, 1586
[INFO] 2021-07-12 19:03:54,400 [run_pretraining.py:  535]:	loss/mlm_loss, 7.720065116882324, 1586
[INFO] 2021-07-12 19:03:54,400 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5849998817429878e-05, 1586
[INFO] 2021-07-12 19:03:54,400 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1586
[INFO] 2021-07-12 19:03:54,400 [run_pretraining.py:  558]:	worker_index: 3, step: 1586, cost: 7.720065, mlm loss: 7.720065, speed: 1.018426 steps/s, speed: 8.147408 samples/s, speed: 4171.472926 tokens/s, learning rate: 1.585e-05, loss_scalings: 6871.948730, pp_loss: 7.439881
[INFO] 2021-07-12 19:03:54,400 [run_pretraining.py:  512]:	********exe.run_1586******* 
[INFO] 2021-07-12 19:03:55,311 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:55,312 [run_pretraining.py:  534]:	loss/total_loss, 7.479106903076172, 1587
[INFO] 2021-07-12 19:03:55,312 [run_pretraining.py:  535]:	loss/mlm_loss, 7.479106903076172, 1587
[INFO] 2021-07-12 19:03:55,312 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5859999621170573e-05, 1587
[INFO] 2021-07-12 19:03:55,312 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1587
[INFO] 2021-07-12 19:03:55,312 [run_pretraining.py:  558]:	worker_index: 3, step: 1587, cost: 7.479107, mlm loss: 7.479107, speed: 1.097659 steps/s, speed: 8.781276 samples/s, speed: 4496.013274 tokens/s, learning rate: 1.586e-05, loss_scalings: 6871.948730, pp_loss: 7.713065
[INFO] 2021-07-12 19:03:55,312 [run_pretraining.py:  512]:	********exe.run_1587******* 
[INFO] 2021-07-12 19:03:56,216 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:56,217 [run_pretraining.py:  534]:	loss/total_loss, 7.703899383544922, 1588
[INFO] 2021-07-12 19:03:56,217 [run_pretraining.py:  535]:	loss/mlm_loss, 7.703899383544922, 1588
[INFO] 2021-07-12 19:03:56,217 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5870000424911268e-05, 1588
[INFO] 2021-07-12 19:03:56,217 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1588
[INFO] 2021-07-12 19:03:56,217 [run_pretraining.py:  558]:	worker_index: 3, step: 1588, cost: 7.703899, mlm loss: 7.703899, speed: 1.105442 steps/s, speed: 8.843535 samples/s, speed: 4527.889875 tokens/s, learning rate: 1.587e-05, loss_scalings: 6871.948730, pp_loss: 7.836390
[INFO] 2021-07-12 19:03:56,217 [run_pretraining.py:  512]:	********exe.run_1588******* 
[INFO] 2021-07-12 19:03:57,164 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:57,164 [run_pretraining.py:  534]:	loss/total_loss, 7.036746978759766, 1589
[INFO] 2021-07-12 19:03:57,165 [run_pretraining.py:  535]:	loss/mlm_loss, 7.036746978759766, 1589
[INFO] 2021-07-12 19:03:57,165 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.587999940966256e-05, 1589
[INFO] 2021-07-12 19:03:57,165 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1589
[INFO] 2021-07-12 19:03:57,165 [run_pretraining.py:  558]:	worker_index: 3, step: 1589, cost: 7.036747, mlm loss: 7.036747, speed: 1.056036 steps/s, speed: 8.448287 samples/s, speed: 4325.522789 tokens/s, learning rate: 1.588e-05, loss_scalings: 6871.948730, pp_loss: 7.124207
[INFO] 2021-07-12 19:03:57,165 [run_pretraining.py:  512]:	********exe.run_1589******* 
[INFO] 2021-07-12 19:03:58,081 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:58,081 [run_pretraining.py:  534]:	loss/total_loss, 7.597347259521484, 1590
[INFO] 2021-07-12 19:03:58,081 [run_pretraining.py:  535]:	loss/mlm_loss, 7.597347259521484, 1590
[INFO] 2021-07-12 19:03:58,081 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.588999839441385e-05, 1590
[INFO] 2021-07-12 19:03:58,082 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1590
[INFO] 2021-07-12 19:03:58,082 [run_pretraining.py:  558]:	worker_index: 3, step: 1590, cost: 7.597347, mlm loss: 7.597347, speed: 1.091509 steps/s, speed: 8.732075 samples/s, speed: 4470.822633 tokens/s, learning rate: 1.589e-05, loss_scalings: 6871.948730, pp_loss: 7.356231
[INFO] 2021-07-12 19:03:58,082 [run_pretraining.py:  512]:	********exe.run_1590******* 
[INFO] 2021-07-12 19:03:58,998 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:58,999 [run_pretraining.py:  534]:	loss/total_loss, 7.119080543518066, 1591
[INFO] 2021-07-12 19:03:58,999 [run_pretraining.py:  535]:	loss/mlm_loss, 7.119080543518066, 1591
[INFO] 2021-07-12 19:03:58,999 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5899999198154546e-05, 1591
[INFO] 2021-07-12 19:03:58,999 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1591
[INFO] 2021-07-12 19:03:58,999 [run_pretraining.py:  558]:	worker_index: 3, step: 1591, cost: 7.119081, mlm loss: 7.119081, speed: 1.090871 steps/s, speed: 8.726968 samples/s, speed: 4468.207521 tokens/s, learning rate: 1.590e-05, loss_scalings: 6871.948730, pp_loss: 7.382098
[INFO] 2021-07-12 19:03:58,999 [run_pretraining.py:  512]:	********exe.run_1591******* 
[INFO] 2021-07-12 19:03:59,908 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:59,908 [run_pretraining.py:  534]:	loss/total_loss, 6.800490379333496, 1592
[INFO] 2021-07-12 19:03:59,908 [run_pretraining.py:  535]:	loss/mlm_loss, 6.800490379333496, 1592
[INFO] 2021-07-12 19:03:59,908 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.591000000189524e-05, 1592
[INFO] 2021-07-12 19:03:59,908 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1592
[INFO] 2021-07-12 19:03:59,908 [run_pretraining.py:  558]:	worker_index: 3, step: 1592, cost: 6.800490, mlm loss: 6.800490, speed: 1.100337 steps/s, speed: 8.802693 samples/s, speed: 4506.978967 tokens/s, learning rate: 1.591e-05, loss_scalings: 6871.948730, pp_loss: 7.111746
[INFO] 2021-07-12 19:03:59,908 [run_pretraining.py:  512]:	********exe.run_1592******* 
[INFO] 2021-07-12 19:04:00,828 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:00,828 [run_pretraining.py:  534]:	loss/total_loss, 7.247868537902832, 1593
[INFO] 2021-07-12 19:04:00,828 [run_pretraining.py:  535]:	loss/mlm_loss, 7.247868537902832, 1593
[INFO] 2021-07-12 19:04:00,828 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5919998986646533e-05, 1593
[INFO] 2021-07-12 19:04:00,829 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1593
[INFO] 2021-07-12 19:04:00,829 [run_pretraining.py:  558]:	worker_index: 3, step: 1593, cost: 7.247869, mlm loss: 7.247869, speed: 1.087519 steps/s, speed: 8.700152 samples/s, speed: 4454.477688 tokens/s, learning rate: 1.592e-05, loss_scalings: 6871.948730, pp_loss: 7.371488
[INFO] 2021-07-12 19:04:00,829 [run_pretraining.py:  512]:	********exe.run_1593******* 
[INFO] 2021-07-12 19:04:01,738 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:01,738 [run_pretraining.py:  534]:	loss/total_loss, 7.673174858093262, 1594
[INFO] 2021-07-12 19:04:01,738 [run_pretraining.py:  535]:	loss/mlm_loss, 7.673174858093262, 1594
[INFO] 2021-07-12 19:04:01,739 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5929999790387228e-05, 1594
[INFO] 2021-07-12 19:04:01,739 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1594
[INFO] 2021-07-12 19:04:01,739 [run_pretraining.py:  558]:	worker_index: 3, step: 1594, cost: 7.673175, mlm loss: 7.673175, speed: 1.099573 steps/s, speed: 8.796583 samples/s, speed: 4503.850240 tokens/s, learning rate: 1.593e-05, loss_scalings: 6871.948730, pp_loss: 7.657073
[INFO] 2021-07-12 19:04:01,739 [run_pretraining.py:  512]:	********exe.run_1594******* 
[INFO] 2021-07-12 19:04:02,639 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:02,640 [run_pretraining.py:  534]:	loss/total_loss, 7.019227027893066, 1595
[INFO] 2021-07-12 19:04:02,640 [run_pretraining.py:  535]:	loss/mlm_loss, 7.019227027893066, 1595
[INFO] 2021-07-12 19:04:02,640 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5940000594127923e-05, 1595
[INFO] 2021-07-12 19:04:02,640 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1595
[INFO] 2021-07-12 19:04:02,640 [run_pretraining.py:  558]:	worker_index: 3, step: 1595, cost: 7.019227, mlm loss: 7.019227, speed: 1.110411 steps/s, speed: 8.883285 samples/s, speed: 4548.241827 tokens/s, learning rate: 1.594e-05, loss_scalings: 6871.948730, pp_loss: 7.128386
[INFO] 2021-07-12 19:04:02,640 [run_pretraining.py:  512]:	********exe.run_1595******* 
[INFO] 2021-07-12 19:04:03,549 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:03,549 [run_pretraining.py:  534]:	loss/total_loss, 7.130159378051758, 1596
[INFO] 2021-07-12 19:04:03,550 [run_pretraining.py:  535]:	loss/mlm_loss, 7.130159378051758, 1596
[INFO] 2021-07-12 19:04:03,550 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5949999578879215e-05, 1596
[INFO] 2021-07-12 19:04:03,550 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1596
[INFO] 2021-07-12 19:04:03,550 [run_pretraining.py:  558]:	worker_index: 3, step: 1596, cost: 7.130159, mlm loss: 7.130159, speed: 1.099762 steps/s, speed: 8.798098 samples/s, speed: 4504.626109 tokens/s, learning rate: 1.595e-05, loss_scalings: 6871.948730, pp_loss: 7.429959
[INFO] 2021-07-12 19:04:03,550 [run_pretraining.py:  512]:	********exe.run_1596******* 
[INFO] 2021-07-12 19:04:04,460 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:04,460 [run_pretraining.py:  534]:	loss/total_loss, 7.963774681091309, 1597
[INFO] 2021-07-12 19:04:04,460 [run_pretraining.py:  535]:	loss/mlm_loss, 7.963774681091309, 1597
[INFO] 2021-07-12 19:04:04,460 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.596000038261991e-05, 1597
[INFO] 2021-07-12 19:04:04,460 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1597
[INFO] 2021-07-12 19:04:04,460 [run_pretraining.py:  558]:	worker_index: 3, step: 1597, cost: 7.963775, mlm loss: 7.963775, speed: 1.098988 steps/s, speed: 8.791906 samples/s, speed: 4501.455827 tokens/s, learning rate: 1.596e-05, loss_scalings: 6871.948730, pp_loss: 7.245427
[INFO] 2021-07-12 19:04:04,460 [run_pretraining.py:  512]:	********exe.run_1597******* 
[INFO] 2021-07-12 19:04:05,375 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:05,375 [run_pretraining.py:  534]:	loss/total_loss, 7.606093883514404, 1598
[INFO] 2021-07-12 19:04:05,375 [run_pretraining.py:  535]:	loss/mlm_loss, 7.606093883514404, 1598
[INFO] 2021-07-12 19:04:05,376 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.59699993673712e-05, 1598
[INFO] 2021-07-12 19:04:05,376 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1598
[INFO] 2021-07-12 19:04:05,376 [run_pretraining.py:  558]:	worker_index: 3, step: 1598, cost: 7.606094, mlm loss: 7.606094, speed: 1.093310 steps/s, speed: 8.746479 samples/s, speed: 4478.197213 tokens/s, learning rate: 1.597e-05, loss_scalings: 6871.948730, pp_loss: 7.311729
[INFO] 2021-07-12 19:04:05,376 [run_pretraining.py:  512]:	********exe.run_1598******* 
[INFO] 2021-07-12 19:04:06,286 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:06,287 [run_pretraining.py:  534]:	loss/total_loss, 6.886906147003174, 1599
[INFO] 2021-07-12 19:04:06,287 [run_pretraining.py:  535]:	loss/mlm_loss, 6.886906147003174, 1599
[INFO] 2021-07-12 19:04:06,287 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5979998352122493e-05, 1599
[INFO] 2021-07-12 19:04:06,287 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1599
[INFO] 2021-07-12 19:04:06,287 [run_pretraining.py:  558]:	worker_index: 3, step: 1599, cost: 6.886906, mlm loss: 6.886906, speed: 1.097832 steps/s, speed: 8.782653 samples/s, speed: 4496.718178 tokens/s, learning rate: 1.598e-05, loss_scalings: 6871.948730, pp_loss: 7.046361
[INFO] 2021-07-12 19:04:06,287 [run_pretraining.py:  512]:	********exe.run_1599******* 
[INFO] 2021-07-12 19:04:07,204 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:07,205 [run_pretraining.py:  534]:	loss/total_loss, 7.186740875244141, 1600
[INFO] 2021-07-12 19:04:07,205 [run_pretraining.py:  535]:	loss/mlm_loss, 7.186740875244141, 1600
[INFO] 2021-07-12 19:04:07,205 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5989999155863188e-05, 1600
[INFO] 2021-07-12 19:04:07,205 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1600
[INFO] 2021-07-12 19:04:07,205 [run_pretraining.py:  558]:	worker_index: 3, step: 1600, cost: 7.186741, mlm loss: 7.186741, speed: 1.090170 steps/s, speed: 8.721358 samples/s, speed: 4465.335473 tokens/s, learning rate: 1.599e-05, loss_scalings: 6871.948730, pp_loss: 7.306010
[INFO] 2021-07-12 19:04:07,205 [run_pretraining.py:  512]:	********exe.run_1600******* 
[INFO] 2021-07-12 19:04:08,116 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:08,117 [run_pretraining.py:  534]:	loss/total_loss, 7.1077165603637695, 1601
[INFO] 2021-07-12 19:04:08,117 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1077165603637695, 1601
[INFO] 2021-07-12 19:04:08,117 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5999999959603883e-05, 1601
[INFO] 2021-07-12 19:04:08,117 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1601
[INFO] 2021-07-12 19:04:08,117 [run_pretraining.py:  558]:	worker_index: 3, step: 1601, cost: 7.107717, mlm loss: 7.107717, speed: 1.097172 steps/s, speed: 8.777376 samples/s, speed: 4494.016264 tokens/s, learning rate: 1.600e-05, loss_scalings: 6871.948730, pp_loss: 6.728708
[INFO] 2021-07-12 19:04:08,117 [run_pretraining.py:  512]:	********exe.run_1601******* 
[INFO] 2021-07-12 19:04:09,099 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:09,100 [run_pretraining.py:  534]:	loss/total_loss, 7.2597336769104, 1602
[INFO] 2021-07-12 19:04:09,100 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2597336769104, 1602
[INFO] 2021-07-12 19:04:09,100 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6009998944355175e-05, 1602
[INFO] 2021-07-12 19:04:09,100 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1602
[INFO] 2021-07-12 19:04:09,100 [run_pretraining.py:  558]:	worker_index: 3, step: 1602, cost: 7.259734, mlm loss: 7.259734, speed: 1.017841 steps/s, speed: 8.142730 samples/s, speed: 4169.077822 tokens/s, learning rate: 1.601e-05, loss_scalings: 6871.948730, pp_loss: 6.430605
[INFO] 2021-07-12 19:04:09,100 [run_pretraining.py:  512]:	********exe.run_1602******* 
[INFO] 2021-07-12 19:04:10,166 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:10,167 [run_pretraining.py:  534]:	loss/total_loss, 7.3210368156433105, 1603
[INFO] 2021-07-12 19:04:10,167 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3210368156433105, 1603
[INFO] 2021-07-12 19:04:10,167 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.601999974809587e-05, 1603
[INFO] 2021-07-12 19:04:10,167 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1603
[INFO] 2021-07-12 19:04:10,167 [run_pretraining.py:  558]:	worker_index: 3, step: 1603, cost: 7.321037, mlm loss: 7.321037, speed: 0.937735 steps/s, speed: 7.501883 samples/s, speed: 3840.964350 tokens/s, learning rate: 1.602e-05, loss_scalings: 6871.948730, pp_loss: 7.268647
[INFO] 2021-07-12 19:04:10,167 [run_pretraining.py:  512]:	********exe.run_1603******* 
[INFO] 2021-07-12 19:04:11,241 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:11,241 [run_pretraining.py:  534]:	loss/total_loss, 8.351553916931152, 1604
[INFO] 2021-07-12 19:04:11,241 [run_pretraining.py:  535]:	loss/mlm_loss, 8.351553916931152, 1604
[INFO] 2021-07-12 19:04:11,242 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6030000551836565e-05, 1604
[INFO] 2021-07-12 19:04:11,242 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1604
[INFO] 2021-07-12 19:04:11,242 [run_pretraining.py:  558]:	worker_index: 3, step: 1604, cost: 8.351554, mlm loss: 8.351554, speed: 0.931353 steps/s, speed: 7.450825 samples/s, speed: 3814.822315 tokens/s, learning rate: 1.603e-05, loss_scalings: 6871.948730, pp_loss: 7.464624
[INFO] 2021-07-12 19:04:11,242 [run_pretraining.py:  512]:	********exe.run_1604******* 
[INFO] 2021-07-12 19:04:12,296 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:12,297 [run_pretraining.py:  534]:	loss/total_loss, 7.2856597900390625, 1605
[INFO] 2021-07-12 19:04:12,297 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2856597900390625, 1605
[INFO] 2021-07-12 19:04:12,297 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6039999536587857e-05, 1605
[INFO] 2021-07-12 19:04:12,297 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1605
[INFO] 2021-07-12 19:04:12,297 [run_pretraining.py:  558]:	worker_index: 3, step: 1605, cost: 7.285660, mlm loss: 7.285660, speed: 0.948165 steps/s, speed: 7.585322 samples/s, speed: 3883.685049 tokens/s, learning rate: 1.604e-05, loss_scalings: 6871.948730, pp_loss: 6.992867
[INFO] 2021-07-12 19:04:12,297 [run_pretraining.py:  512]:	********exe.run_1605******* 
[INFO] 2021-07-12 19:04:13,362 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:13,363 [run_pretraining.py:  534]:	loss/total_loss, 6.394476413726807, 1606
[INFO] 2021-07-12 19:04:13,363 [run_pretraining.py:  535]:	loss/mlm_loss, 6.394476413726807, 1606
[INFO] 2021-07-12 19:04:13,363 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6050000340328552e-05, 1606
[INFO] 2021-07-12 19:04:13,363 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1606
[INFO] 2021-07-12 19:04:13,363 [run_pretraining.py:  558]:	worker_index: 3, step: 1606, cost: 6.394476, mlm loss: 6.394476, speed: 0.938419 steps/s, speed: 7.507354 samples/s, speed: 3843.765018 tokens/s, learning rate: 1.605e-05, loss_scalings: 6871.948730, pp_loss: 6.909251
[INFO] 2021-07-12 19:04:13,363 [run_pretraining.py:  512]:	********exe.run_1606******* 
[INFO] 2021-07-12 19:04:14,426 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:14,427 [run_pretraining.py:  534]:	loss/total_loss, 6.9599609375, 1607
[INFO] 2021-07-12 19:04:14,427 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9599609375, 1607
[INFO] 2021-07-12 19:04:14,427 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6060001144069247e-05, 1607
[INFO] 2021-07-12 19:04:14,427 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1607
[INFO] 2021-07-12 19:04:14,427 [run_pretraining.py:  558]:	worker_index: 3, step: 1607, cost: 6.959961, mlm loss: 6.959961, speed: 0.940779 steps/s, speed: 7.526228 samples/s, speed: 3853.428890 tokens/s, learning rate: 1.606e-05, loss_scalings: 6871.948730, pp_loss: 7.281647
[INFO] 2021-07-12 19:04:14,427 [run_pretraining.py:  512]:	********exe.run_1607******* 
[INFO] 2021-07-12 19:04:15,493 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:15,494 [run_pretraining.py:  534]:	loss/total_loss, 7.180366516113281, 1608
[INFO] 2021-07-12 19:04:15,494 [run_pretraining.py:  535]:	loss/mlm_loss, 7.180366516113281, 1608
[INFO] 2021-07-12 19:04:15,494 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6069998309831135e-05, 1608
[INFO] 2021-07-12 19:04:15,494 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1608
[INFO] 2021-07-12 19:04:15,494 [run_pretraining.py:  558]:	worker_index: 3, step: 1608, cost: 7.180367, mlm loss: 7.180367, speed: 0.937379 steps/s, speed: 7.499032 samples/s, speed: 3839.504192 tokens/s, learning rate: 1.607e-05, loss_scalings: 6871.948730, pp_loss: 7.246692
[INFO] 2021-07-12 19:04:15,494 [run_pretraining.py:  512]:	********exe.run_1608******* 
[INFO] 2021-07-12 19:04:16,573 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:16,574 [run_pretraining.py:  534]:	loss/total_loss, 8.032344818115234, 1609
[INFO] 2021-07-12 19:04:16,574 [run_pretraining.py:  535]:	loss/mlm_loss, 8.032344818115234, 1609
[INFO] 2021-07-12 19:04:16,574 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.607999911357183e-05, 1609
[INFO] 2021-07-12 19:04:16,574 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1609
[INFO] 2021-07-12 19:04:16,574 [run_pretraining.py:  558]:	worker_index: 3, step: 1609, cost: 8.032345, mlm loss: 8.032345, speed: 0.926844 steps/s, speed: 7.414753 samples/s, speed: 3796.353304 tokens/s, learning rate: 1.608e-05, loss_scalings: 6871.948730, pp_loss: 7.592842
[INFO] 2021-07-12 19:04:16,574 [run_pretraining.py:  512]:	********exe.run_1609******* 
[INFO] 2021-07-12 19:04:17,719 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:17,720 [run_pretraining.py:  534]:	loss/total_loss, 6.783585548400879, 1610
[INFO] 2021-07-12 19:04:17,720 [run_pretraining.py:  535]:	loss/mlm_loss, 6.783585548400879, 1610
[INFO] 2021-07-12 19:04:17,720 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6089999917312525e-05, 1610
[INFO] 2021-07-12 19:04:17,720 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1610
[INFO] 2021-07-12 19:04:17,720 [run_pretraining.py:  558]:	worker_index: 3, step: 1610, cost: 6.783586, mlm loss: 6.783586, speed: 0.872785 steps/s, speed: 6.982276 samples/s, speed: 3574.925470 tokens/s, learning rate: 1.609e-05, loss_scalings: 6871.948730, pp_loss: 6.382155
[INFO] 2021-07-12 19:04:17,720 [run_pretraining.py:  512]:	********exe.run_1610******* 
[INFO] 2021-07-12 19:04:18,831 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:18,832 [run_pretraining.py:  534]:	loss/total_loss, 7.600910186767578, 1611
[INFO] 2021-07-12 19:04:18,832 [run_pretraining.py:  535]:	loss/mlm_loss, 7.600910186767578, 1611
[INFO] 2021-07-12 19:04:18,832 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6099998902063817e-05, 1611
[INFO] 2021-07-12 19:04:18,832 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1611
[INFO] 2021-07-12 19:04:18,832 [run_pretraining.py:  558]:	worker_index: 3, step: 1611, cost: 7.600910, mlm loss: 7.600910, speed: 0.899759 steps/s, speed: 7.198075 samples/s, speed: 3685.414482 tokens/s, learning rate: 1.610e-05, loss_scalings: 6871.948730, pp_loss: 7.036445
[INFO] 2021-07-12 19:04:18,832 [run_pretraining.py:  512]:	********exe.run_1611******* 
[INFO] 2021-07-12 19:04:19,929 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:19,930 [run_pretraining.py:  534]:	loss/total_loss, 7.334684371948242, 1612
[INFO] 2021-07-12 19:04:19,930 [run_pretraining.py:  535]:	loss/mlm_loss, 7.334684371948242, 1612
[INFO] 2021-07-12 19:04:19,930 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6109999705804512e-05, 1612
[INFO] 2021-07-12 19:04:19,930 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1612
[INFO] 2021-07-12 19:04:19,930 [run_pretraining.py:  558]:	worker_index: 3, step: 1612, cost: 7.334684, mlm loss: 7.334684, speed: 0.911273 steps/s, speed: 7.290183 samples/s, speed: 3732.573860 tokens/s, learning rate: 1.611e-05, loss_scalings: 6871.948730, pp_loss: 7.410599
[INFO] 2021-07-12 19:04:19,930 [run_pretraining.py:  512]:	********exe.run_1612******* 
[INFO] 2021-07-12 19:04:21,027 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:21,027 [run_pretraining.py:  534]:	loss/total_loss, 7.786602973937988, 1613
[INFO] 2021-07-12 19:04:21,027 [run_pretraining.py:  535]:	loss/mlm_loss, 7.786602973937988, 1613
[INFO] 2021-07-12 19:04:21,027 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6120000509545207e-05, 1613
[INFO] 2021-07-12 19:04:21,027 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1613
[INFO] 2021-07-12 19:04:21,027 [run_pretraining.py:  558]:	worker_index: 3, step: 1613, cost: 7.786603, mlm loss: 7.786603, speed: 0.912041 steps/s, speed: 7.296329 samples/s, speed: 3735.720585 tokens/s, learning rate: 1.612e-05, loss_scalings: 6871.948730, pp_loss: 7.524179
[INFO] 2021-07-12 19:04:21,027 [run_pretraining.py:  512]:	********exe.run_1613******* 
[INFO] 2021-07-12 19:04:22,123 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:22,123 [run_pretraining.py:  534]:	loss/total_loss, 7.497687339782715, 1614
[INFO] 2021-07-12 19:04:22,123 [run_pretraining.py:  535]:	loss/mlm_loss, 7.497687339782715, 1614
[INFO] 2021-07-12 19:04:22,124 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.61299994942965e-05, 1614
[INFO] 2021-07-12 19:04:22,124 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1614
[INFO] 2021-07-12 19:04:22,124 [run_pretraining.py:  558]:	worker_index: 3, step: 1614, cost: 7.497687, mlm loss: 7.497687, speed: 0.912735 steps/s, speed: 7.301880 samples/s, speed: 3738.562628 tokens/s, learning rate: 1.613e-05, loss_scalings: 6871.948730, pp_loss: 6.772799
[INFO] 2021-07-12 19:04:22,124 [run_pretraining.py:  512]:	********exe.run_1614******* 
[INFO] 2021-07-12 19:04:23,216 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:23,216 [run_pretraining.py:  534]:	loss/total_loss, 7.940396308898926, 1615
[INFO] 2021-07-12 19:04:23,216 [run_pretraining.py:  535]:	loss/mlm_loss, 7.940396308898926, 1615
[INFO] 2021-07-12 19:04:23,217 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6140000298037194e-05, 1615
[INFO] 2021-07-12 19:04:23,217 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1615
[INFO] 2021-07-12 19:04:23,217 [run_pretraining.py:  558]:	worker_index: 3, step: 1615, cost: 7.940396, mlm loss: 7.940396, speed: 0.915414 steps/s, speed: 7.323310 samples/s, speed: 3749.534673 tokens/s, learning rate: 1.614e-05, loss_scalings: 6871.948730, pp_loss: 7.567861
[INFO] 2021-07-12 19:04:23,217 [run_pretraining.py:  512]:	********exe.run_1615******* 
[INFO] 2021-07-12 19:04:24,318 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:24,318 [run_pretraining.py:  534]:	loss/total_loss, 7.471269130706787, 1616
[INFO] 2021-07-12 19:04:24,318 [run_pretraining.py:  535]:	loss/mlm_loss, 7.471269130706787, 1616
[INFO] 2021-07-12 19:04:24,318 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.615000110177789e-05, 1616
[INFO] 2021-07-12 19:04:24,318 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1616
[INFO] 2021-07-12 19:04:24,319 [run_pretraining.py:  558]:	worker_index: 3, step: 1616, cost: 7.471269, mlm loss: 7.471269, speed: 0.908100 steps/s, speed: 7.264797 samples/s, speed: 3719.575875 tokens/s, learning rate: 1.615e-05, loss_scalings: 6871.948730, pp_loss: 7.371815
[INFO] 2021-07-12 19:04:24,319 [run_pretraining.py:  512]:	********exe.run_1616******* 
[INFO] 2021-07-12 19:04:25,408 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:25,408 [run_pretraining.py:  534]:	loss/total_loss, 4.04274320602417, 1617
[INFO] 2021-07-12 19:04:25,408 [run_pretraining.py:  535]:	loss/mlm_loss, 4.04274320602417, 1617
[INFO] 2021-07-12 19:04:25,409 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6159998267539777e-05, 1617
[INFO] 2021-07-12 19:04:25,409 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1617
[INFO] 2021-07-12 19:04:25,409 [run_pretraining.py:  558]:	worker_index: 3, step: 1617, cost: 4.042743, mlm loss: 4.042743, speed: 0.917903 steps/s, speed: 7.343223 samples/s, speed: 3759.730222 tokens/s, learning rate: 1.616e-05, loss_scalings: 6871.948730, pp_loss: 6.568223
[INFO] 2021-07-12 19:04:25,409 [run_pretraining.py:  512]:	********exe.run_1617******* 
[INFO] 2021-07-12 19:04:26,454 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:26,454 [run_pretraining.py:  534]:	loss/total_loss, 7.79503870010376, 1618
[INFO] 2021-07-12 19:04:26,454 [run_pretraining.py:  535]:	loss/mlm_loss, 7.79503870010376, 1618
[INFO] 2021-07-12 19:04:26,454 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6169999071280472e-05, 1618
[INFO] 2021-07-12 19:04:26,454 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1618
[INFO] 2021-07-12 19:04:26,454 [run_pretraining.py:  558]:	worker_index: 3, step: 1618, cost: 7.795039, mlm loss: 7.795039, speed: 0.956845 steps/s, speed: 7.654760 samples/s, speed: 3919.236912 tokens/s, learning rate: 1.617e-05, loss_scalings: 6871.948730, pp_loss: 7.855663
[INFO] 2021-07-12 19:04:26,454 [run_pretraining.py:  512]:	********exe.run_1618******* 
[INFO] 2021-07-12 19:04:27,364 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:27,365 [run_pretraining.py:  534]:	loss/total_loss, 7.680190086364746, 1619
[INFO] 2021-07-12 19:04:27,365 [run_pretraining.py:  535]:	loss/mlm_loss, 7.680190086364746, 1619
[INFO] 2021-07-12 19:04:27,365 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6179999875021167e-05, 1619
[INFO] 2021-07-12 19:04:27,365 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1619
[INFO] 2021-07-12 19:04:27,365 [run_pretraining.py:  558]:	worker_index: 3, step: 1619, cost: 7.680190, mlm loss: 7.680190, speed: 1.098684 steps/s, speed: 8.789474 samples/s, speed: 4500.210653 tokens/s, learning rate: 1.618e-05, loss_scalings: 6871.948730, pp_loss: 7.503756
[INFO] 2021-07-12 19:04:27,365 [run_pretraining.py:  512]:	********exe.run_1619******* 
[INFO] 2021-07-12 19:04:28,281 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:28,282 [run_pretraining.py:  534]:	loss/total_loss, 7.6574835777282715, 1620
[INFO] 2021-07-12 19:04:28,282 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6574835777282715, 1620
[INFO] 2021-07-12 19:04:28,282 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.618999885977246e-05, 1620
[INFO] 2021-07-12 19:04:28,282 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1620
[INFO] 2021-07-12 19:04:28,282 [run_pretraining.py:  558]:	worker_index: 3, step: 1620, cost: 7.657484, mlm loss: 7.657484, speed: 1.091285 steps/s, speed: 8.730278 samples/s, speed: 4469.902518 tokens/s, learning rate: 1.619e-05, loss_scalings: 6871.948730, pp_loss: 7.543793
[INFO] 2021-07-12 19:04:28,282 [run_pretraining.py:  512]:	********exe.run_1620******* 
[INFO] 2021-07-12 19:04:29,197 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:29,198 [run_pretraining.py:  534]:	loss/total_loss, 7.789528846740723, 1621
[INFO] 2021-07-12 19:04:29,198 [run_pretraining.py:  535]:	loss/mlm_loss, 7.789528846740723, 1621
[INFO] 2021-07-12 19:04:29,198 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6199999663513154e-05, 1621
[INFO] 2021-07-12 19:04:29,198 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1621
[INFO] 2021-07-12 19:04:29,198 [run_pretraining.py:  558]:	worker_index: 3, step: 1621, cost: 7.789529, mlm loss: 7.789529, speed: 1.092725 steps/s, speed: 8.741801 samples/s, speed: 4475.802005 tokens/s, learning rate: 1.620e-05, loss_scalings: 6871.948730, pp_loss: 7.681013
[INFO] 2021-07-12 19:04:29,198 [run_pretraining.py:  512]:	********exe.run_1621******* 
[INFO] 2021-07-12 19:04:30,112 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:30,112 [run_pretraining.py:  534]:	loss/total_loss, 6.841512203216553, 1622
[INFO] 2021-07-12 19:04:30,113 [run_pretraining.py:  535]:	loss/mlm_loss, 6.841512203216553, 1622
[INFO] 2021-07-12 19:04:30,113 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.621000046725385e-05, 1622
[INFO] 2021-07-12 19:04:30,113 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1622
[INFO] 2021-07-12 19:04:30,113 [run_pretraining.py:  558]:	worker_index: 3, step: 1622, cost: 6.841512, mlm loss: 6.841512, speed: 1.093876 steps/s, speed: 8.751007 samples/s, speed: 4480.515525 tokens/s, learning rate: 1.621e-05, loss_scalings: 6871.948730, pp_loss: 7.114138
[INFO] 2021-07-12 19:04:30,113 [run_pretraining.py:  512]:	********exe.run_1622******* 
[INFO] 2021-07-12 19:04:31,021 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:31,022 [run_pretraining.py:  534]:	loss/total_loss, 7.207690715789795, 1623
[INFO] 2021-07-12 19:04:31,022 [run_pretraining.py:  535]:	loss/mlm_loss, 7.207690715789795, 1623
[INFO] 2021-07-12 19:04:31,022 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.621999945200514e-05, 1623
[INFO] 2021-07-12 19:04:31,022 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1623
[INFO] 2021-07-12 19:04:31,022 [run_pretraining.py:  558]:	worker_index: 3, step: 1623, cost: 7.207691, mlm loss: 7.207691, speed: 1.100549 steps/s, speed: 8.804391 samples/s, speed: 4507.848172 tokens/s, learning rate: 1.622e-05, loss_scalings: 6871.948730, pp_loss: 6.915168
[INFO] 2021-07-12 19:04:31,022 [run_pretraining.py:  512]:	********exe.run_1623******* 
[INFO] 2021-07-12 19:04:31,932 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:31,933 [run_pretraining.py:  534]:	loss/total_loss, 7.149183750152588, 1624
[INFO] 2021-07-12 19:04:31,933 [run_pretraining.py:  535]:	loss/mlm_loss, 7.149183750152588, 1624
[INFO] 2021-07-12 19:04:31,933 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6230000255745836e-05, 1624
[INFO] 2021-07-12 19:04:31,933 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1624
[INFO] 2021-07-12 19:04:31,933 [run_pretraining.py:  558]:	worker_index: 3, step: 1624, cost: 7.149184, mlm loss: 7.149184, speed: 1.098374 steps/s, speed: 8.786995 samples/s, speed: 4498.941427 tokens/s, learning rate: 1.623e-05, loss_scalings: 6871.948730, pp_loss: 7.330369
[INFO] 2021-07-12 19:04:31,933 [run_pretraining.py:  512]:	********exe.run_1624******* 
[INFO] 2021-07-12 19:04:32,849 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:32,849 [run_pretraining.py:  534]:	loss/total_loss, 6.906213283538818, 1625
[INFO] 2021-07-12 19:04:32,849 [run_pretraining.py:  535]:	loss/mlm_loss, 6.906213283538818, 1625
[INFO] 2021-07-12 19:04:32,849 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.624000105948653e-05, 1625
[INFO] 2021-07-12 19:04:32,849 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1625
[INFO] 2021-07-12 19:04:32,849 [run_pretraining.py:  558]:	worker_index: 3, step: 1625, cost: 6.906213, mlm loss: 6.906213, speed: 1.092129 steps/s, speed: 8.737032 samples/s, speed: 4473.360437 tokens/s, learning rate: 1.624e-05, loss_scalings: 6871.948730, pp_loss: 6.693932
[INFO] 2021-07-12 19:04:32,849 [run_pretraining.py:  512]:	********exe.run_1625******* 
[INFO] 2021-07-12 19:04:33,769 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:33,769 [run_pretraining.py:  534]:	loss/total_loss, 7.789615631103516, 1626
[INFO] 2021-07-12 19:04:33,769 [run_pretraining.py:  535]:	loss/mlm_loss, 7.789615631103516, 1626
[INFO] 2021-07-12 19:04:33,770 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.624999822524842e-05, 1626
[INFO] 2021-07-12 19:04:33,770 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1626
[INFO] 2021-07-12 19:04:33,770 [run_pretraining.py:  558]:	worker_index: 3, step: 1626, cost: 7.789616, mlm loss: 7.789616, speed: 1.087340 steps/s, speed: 8.698720 samples/s, speed: 4453.744397 tokens/s, learning rate: 1.625e-05, loss_scalings: 6871.948730, pp_loss: 7.379053
[INFO] 2021-07-12 19:04:33,770 [run_pretraining.py:  512]:	********exe.run_1626******* 
[INFO] 2021-07-12 19:04:34,683 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:34,684 [run_pretraining.py:  534]:	loss/total_loss, 8.222538948059082, 1627
[INFO] 2021-07-12 19:04:34,684 [run_pretraining.py:  535]:	loss/mlm_loss, 8.222538948059082, 1627
[INFO] 2021-07-12 19:04:34,684 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6259999028989114e-05, 1627
[INFO] 2021-07-12 19:04:34,684 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1627
[INFO] 2021-07-12 19:04:34,684 [run_pretraining.py:  558]:	worker_index: 3, step: 1627, cost: 8.222539, mlm loss: 8.222539, speed: 1.094154 steps/s, speed: 8.753235 samples/s, speed: 4481.656291 tokens/s, learning rate: 1.626e-05, loss_scalings: 6871.948730, pp_loss: 7.758709
[INFO] 2021-07-12 19:04:34,684 [run_pretraining.py:  512]:	********exe.run_1627******* 
[INFO] 2021-07-12 19:04:35,606 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:35,607 [run_pretraining.py:  534]:	loss/total_loss, 8.755349159240723, 1628
[INFO] 2021-07-12 19:04:35,607 [run_pretraining.py:  535]:	loss/mlm_loss, 8.755349159240723, 1628
[INFO] 2021-07-12 19:04:35,607 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.626999983272981e-05, 1628
[INFO] 2021-07-12 19:04:35,607 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1628
[INFO] 2021-07-12 19:04:35,607 [run_pretraining.py:  558]:	worker_index: 3, step: 1628, cost: 8.755349, mlm loss: 8.755349, speed: 1.084042 steps/s, speed: 8.672336 samples/s, speed: 4440.236286 tokens/s, learning rate: 1.627e-05, loss_scalings: 6871.948730, pp_loss: 8.086800
[INFO] 2021-07-12 19:04:35,608 [run_pretraining.py:  512]:	********exe.run_1628******* 
[INFO] 2021-07-12 19:04:36,523 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:36,524 [run_pretraining.py:  534]:	loss/total_loss, 7.252047061920166, 1629
[INFO] 2021-07-12 19:04:36,524 [run_pretraining.py:  535]:	loss/mlm_loss, 7.252047061920166, 1629
[INFO] 2021-07-12 19:04:36,524 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.62799988174811e-05, 1629
[INFO] 2021-07-12 19:04:36,524 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1629
[INFO] 2021-07-12 19:04:36,524 [run_pretraining.py:  558]:	worker_index: 3, step: 1629, cost: 7.252047, mlm loss: 7.252047, speed: 1.091366 steps/s, speed: 8.730928 samples/s, speed: 4470.235159 tokens/s, learning rate: 1.628e-05, loss_scalings: 6871.948730, pp_loss: 7.323957
[INFO] 2021-07-12 19:04:36,524 [run_pretraining.py:  512]:	********exe.run_1629******* 
[INFO] 2021-07-12 19:04:37,440 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:37,441 [run_pretraining.py:  534]:	loss/total_loss, 7.563776969909668, 1630
[INFO] 2021-07-12 19:04:37,441 [run_pretraining.py:  535]:	loss/mlm_loss, 7.563776969909668, 1630
[INFO] 2021-07-12 19:04:37,441 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6289999621221796e-05, 1630
[INFO] 2021-07-12 19:04:37,441 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1630
[INFO] 2021-07-12 19:04:37,441 [run_pretraining.py:  558]:	worker_index: 3, step: 1630, cost: 7.563777, mlm loss: 7.563777, speed: 1.091647 steps/s, speed: 8.733173 samples/s, speed: 4471.384660 tokens/s, learning rate: 1.629e-05, loss_scalings: 6871.948730, pp_loss: 7.189198
[INFO] 2021-07-12 19:04:37,441 [run_pretraining.py:  512]:	********exe.run_1630******* 
[INFO] 2021-07-12 19:04:38,360 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:38,361 [run_pretraining.py:  534]:	loss/total_loss, 6.49973201751709, 1631
[INFO] 2021-07-12 19:04:38,361 [run_pretraining.py:  535]:	loss/mlm_loss, 6.49973201751709, 1631
[INFO] 2021-07-12 19:04:38,361 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.630000042496249e-05, 1631
[INFO] 2021-07-12 19:04:38,361 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1631
[INFO] 2021-07-12 19:04:38,361 [run_pretraining.py:  558]:	worker_index: 3, step: 1631, cost: 6.499732, mlm loss: 6.499732, speed: 1.087801 steps/s, speed: 8.702410 samples/s, speed: 4455.634121 tokens/s, learning rate: 1.630e-05, loss_scalings: 6871.948730, pp_loss: 7.309613
[INFO] 2021-07-12 19:04:38,361 [run_pretraining.py:  512]:	********exe.run_1631******* 
[INFO] 2021-07-12 19:04:39,282 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:39,282 [run_pretraining.py:  534]:	loss/total_loss, 7.491824150085449, 1632
[INFO] 2021-07-12 19:04:39,282 [run_pretraining.py:  535]:	loss/mlm_loss, 7.491824150085449, 1632
[INFO] 2021-07-12 19:04:39,282 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6309999409713782e-05, 1632
[INFO] 2021-07-12 19:04:39,282 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1632
[INFO] 2021-07-12 19:04:39,283 [run_pretraining.py:  558]:	worker_index: 3, step: 1632, cost: 7.491824, mlm loss: 7.491824, speed: 1.085882 steps/s, speed: 8.687054 samples/s, speed: 4447.771601 tokens/s, learning rate: 1.631e-05, loss_scalings: 6871.948730, pp_loss: 7.504338
[INFO] 2021-07-12 19:04:39,283 [run_pretraining.py:  512]:	********exe.run_1632******* 
[INFO] 2021-07-12 19:04:40,201 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:40,202 [run_pretraining.py:  534]:	loss/total_loss, 7.622469902038574, 1633
[INFO] 2021-07-12 19:04:40,202 [run_pretraining.py:  535]:	loss/mlm_loss, 7.622469902038574, 1633
[INFO] 2021-07-12 19:04:40,202 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6320000213454477e-05, 1633
[INFO] 2021-07-12 19:04:40,202 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1633
[INFO] 2021-07-12 19:04:40,202 [run_pretraining.py:  558]:	worker_index: 3, step: 1633, cost: 7.622470, mlm loss: 7.622470, speed: 1.088228 steps/s, speed: 8.705824 samples/s, speed: 4457.382040 tokens/s, learning rate: 1.632e-05, loss_scalings: 6871.948730, pp_loss: 7.032347
[INFO] 2021-07-12 19:04:40,202 [run_pretraining.py:  512]:	********exe.run_1633******* 
[INFO] 2021-07-12 19:04:41,108 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:41,108 [run_pretraining.py:  534]:	loss/total_loss, 7.208932399749756, 1634
[INFO] 2021-07-12 19:04:41,108 [run_pretraining.py:  535]:	loss/mlm_loss, 7.208932399749756, 1634
[INFO] 2021-07-12 19:04:41,108 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.632999919820577e-05, 1634
[INFO] 2021-07-12 19:04:41,108 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1634
[INFO] 2021-07-12 19:04:41,109 [run_pretraining.py:  558]:	worker_index: 3, step: 1634, cost: 7.208932, mlm loss: 7.208932, speed: 1.103977 steps/s, speed: 8.831820 samples/s, speed: 4521.891645 tokens/s, learning rate: 1.633e-05, loss_scalings: 6871.948730, pp_loss: 7.030125
[INFO] 2021-07-12 19:04:41,109 [run_pretraining.py:  512]:	********exe.run_1634******* 
[INFO] 2021-07-12 19:04:42,015 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:42,015 [run_pretraining.py:  534]:	loss/total_loss, 7.682763576507568, 1635
[INFO] 2021-07-12 19:04:42,015 [run_pretraining.py:  535]:	loss/mlm_loss, 7.682763576507568, 1635
[INFO] 2021-07-12 19:04:42,015 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.633999818295706e-05, 1635
[INFO] 2021-07-12 19:04:42,015 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1635
[INFO] 2021-07-12 19:04:42,016 [run_pretraining.py:  558]:	worker_index: 3, step: 1635, cost: 7.682764, mlm loss: 7.682764, speed: 1.103333 steps/s, speed: 8.826664 samples/s, speed: 4519.252130 tokens/s, learning rate: 1.634e-05, loss_scalings: 6871.948730, pp_loss: 7.429431
[INFO] 2021-07-12 19:04:42,016 [run_pretraining.py:  512]:	********exe.run_1635******* 
[INFO] 2021-07-12 19:04:42,935 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:42,935 [run_pretraining.py:  534]:	loss/total_loss, 6.7422075271606445, 1636
[INFO] 2021-07-12 19:04:42,935 [run_pretraining.py:  535]:	loss/mlm_loss, 6.7422075271606445, 1636
[INFO] 2021-07-12 19:04:42,935 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6349998986697756e-05, 1636
[INFO] 2021-07-12 19:04:42,935 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1636
[INFO] 2021-07-12 19:04:42,936 [run_pretraining.py:  558]:	worker_index: 3, step: 1636, cost: 6.742208, mlm loss: 6.742208, speed: 1.087741 steps/s, speed: 8.701927 samples/s, speed: 4455.386841 tokens/s, learning rate: 1.635e-05, loss_scalings: 6871.948730, pp_loss: 7.516181
[INFO] 2021-07-12 19:04:42,936 [run_pretraining.py:  512]:	********exe.run_1636******* 
[INFO] 2021-07-12 19:04:43,850 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:43,851 [run_pretraining.py:  534]:	loss/total_loss, 6.668143272399902, 1637
[INFO] 2021-07-12 19:04:43,851 [run_pretraining.py:  535]:	loss/mlm_loss, 6.668143272399902, 1637
[INFO] 2021-07-12 19:04:43,851 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.635999979043845e-05, 1637
[INFO] 2021-07-12 19:04:43,851 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1637
[INFO] 2021-07-12 19:04:43,851 [run_pretraining.py:  558]:	worker_index: 3, step: 1637, cost: 6.668143, mlm loss: 6.668143, speed: 1.092697 steps/s, speed: 8.741575 samples/s, speed: 4475.686568 tokens/s, learning rate: 1.636e-05, loss_scalings: 6871.948730, pp_loss: 7.452382
[INFO] 2021-07-12 19:04:43,851 [run_pretraining.py:  512]:	********exe.run_1637******* 
[INFO] 2021-07-12 19:04:44,772 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:44,772 [run_pretraining.py:  534]:	loss/total_loss, 7.227394104003906, 1638
[INFO] 2021-07-12 19:04:44,772 [run_pretraining.py:  535]:	loss/mlm_loss, 7.227394104003906, 1638
[INFO] 2021-07-12 19:04:44,772 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6369998775189742e-05, 1638
[INFO] 2021-07-12 19:04:44,773 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1638
[INFO] 2021-07-12 19:04:44,773 [run_pretraining.py:  558]:	worker_index: 3, step: 1638, cost: 7.227394, mlm loss: 7.227394, speed: 1.086247 steps/s, speed: 8.689979 samples/s, speed: 4449.269059 tokens/s, learning rate: 1.637e-05, loss_scalings: 6871.948730, pp_loss: 7.235712
[INFO] 2021-07-12 19:04:44,773 [run_pretraining.py:  512]:	********exe.run_1638******* 
[INFO] 2021-07-12 19:04:45,700 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:45,700 [run_pretraining.py:  534]:	loss/total_loss, 7.882263660430908, 1639
[INFO] 2021-07-12 19:04:45,701 [run_pretraining.py:  535]:	loss/mlm_loss, 7.882263660430908, 1639
[INFO] 2021-07-12 19:04:45,701 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6379999578930438e-05, 1639
[INFO] 2021-07-12 19:04:45,701 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1639
[INFO] 2021-07-12 19:04:45,701 [run_pretraining.py:  558]:	worker_index: 3, step: 1639, cost: 7.882264, mlm loss: 7.882264, speed: 1.078052 steps/s, speed: 8.624415 samples/s, speed: 4415.700269 tokens/s, learning rate: 1.638e-05, loss_scalings: 6871.948730, pp_loss: 7.359622
[INFO] 2021-07-12 19:04:45,701 [run_pretraining.py:  512]:	********exe.run_1639******* 
[INFO] 2021-07-12 19:04:46,604 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:46,604 [run_pretraining.py:  534]:	loss/total_loss, 7.1750383377075195, 1640
[INFO] 2021-07-12 19:04:46,604 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1750383377075195, 1640
[INFO] 2021-07-12 19:04:46,604 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6390000382671133e-05, 1640
[INFO] 2021-07-12 19:04:46,604 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1640
[INFO] 2021-07-12 19:04:46,604 [run_pretraining.py:  558]:	worker_index: 3, step: 1640, cost: 7.175038, mlm loss: 7.175038, speed: 1.107499 steps/s, speed: 8.859993 samples/s, speed: 4536.316336 tokens/s, learning rate: 1.639e-05, loss_scalings: 6871.948730, pp_loss: 6.867458
[INFO] 2021-07-12 19:04:46,605 [run_pretraining.py:  512]:	********exe.run_1640******* 
[INFO] 2021-07-12 19:04:47,519 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:47,520 [run_pretraining.py:  534]:	loss/total_loss, 6.9289140701293945, 1641
[INFO] 2021-07-12 19:04:47,520 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9289140701293945, 1641
[INFO] 2021-07-12 19:04:47,520 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6399999367422424e-05, 1641
[INFO] 2021-07-12 19:04:47,520 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1641
[INFO] 2021-07-12 19:04:47,520 [run_pretraining.py:  558]:	worker_index: 3, step: 1641, cost: 6.928914, mlm loss: 6.928914, speed: 1.093037 steps/s, speed: 8.744298 samples/s, speed: 4477.080375 tokens/s, learning rate: 1.640e-05, loss_scalings: 6871.948730, pp_loss: 7.114841
[INFO] 2021-07-12 19:04:47,520 [run_pretraining.py:  512]:	********exe.run_1641******* 
[INFO] 2021-07-12 19:04:48,429 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:48,429 [run_pretraining.py:  534]:	loss/total_loss, 7.325936794281006, 1642
[INFO] 2021-07-12 19:04:48,430 [run_pretraining.py:  535]:	loss/mlm_loss, 7.325936794281006, 1642
[INFO] 2021-07-12 19:04:48,430 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.641000017116312e-05, 1642
[INFO] 2021-07-12 19:04:48,430 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1642
[INFO] 2021-07-12 19:04:48,430 [run_pretraining.py:  558]:	worker_index: 3, step: 1642, cost: 7.325937, mlm loss: 7.325937, speed: 1.099821 steps/s, speed: 8.798571 samples/s, speed: 4504.868254 tokens/s, learning rate: 1.641e-05, loss_scalings: 6871.948730, pp_loss: 7.546538
[INFO] 2021-07-12 19:04:48,430 [run_pretraining.py:  512]:	********exe.run_1642******* 
[INFO] 2021-07-12 19:04:49,343 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:49,344 [run_pretraining.py:  534]:	loss/total_loss, 7.183933258056641, 1643
[INFO] 2021-07-12 19:04:49,344 [run_pretraining.py:  535]:	loss/mlm_loss, 7.183933258056641, 1643
[INFO] 2021-07-12 19:04:49,344 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.641999915591441e-05, 1643
[INFO] 2021-07-12 19:04:49,344 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1643
[INFO] 2021-07-12 19:04:49,344 [run_pretraining.py:  558]:	worker_index: 3, step: 1643, cost: 7.183933, mlm loss: 7.183933, speed: 1.094246 steps/s, speed: 8.753966 samples/s, speed: 4482.030439 tokens/s, learning rate: 1.642e-05, loss_scalings: 6871.948730, pp_loss: 7.228437
[INFO] 2021-07-12 19:04:49,344 [run_pretraining.py:  512]:	********exe.run_1643******* 
[INFO] 2021-07-12 19:04:50,386 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:50,391 [run_pretraining.py:  534]:	loss/total_loss, 7.042535781860352, 1644
[INFO] 2021-07-12 19:04:50,397 [run_pretraining.py:  535]:	loss/mlm_loss, 7.042535781860352, 1644
[INFO] 2021-07-12 19:04:50,402 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6429999959655106e-05, 1644
[INFO] 2021-07-12 19:04:50,407 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1644
[INFO] 2021-07-12 19:04:50,412 [run_pretraining.py:  558]:	worker_index: 3, step: 1644, cost: 7.042536, mlm loss: 7.042536, speed: 0.955288 steps/s, speed: 7.642304 samples/s, speed: 3912.859897 tokens/s, learning rate: 1.643e-05, loss_scalings: 6871.948730, pp_loss: 7.351872
[INFO] 2021-07-12 19:04:50,417 [run_pretraining.py:  512]:	********exe.run_1644******* 
[INFO] 2021-07-12 19:04:51,323 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:51,323 [run_pretraining.py:  534]:	loss/total_loss, 7.679291725158691, 1645
[INFO] 2021-07-12 19:04:51,324 [run_pretraining.py:  535]:	loss/mlm_loss, 7.679291725158691, 1645
[INFO] 2021-07-12 19:04:51,324 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6439998944406398e-05, 1645
[INFO] 2021-07-12 19:04:51,324 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1645
[INFO] 2021-07-12 19:04:51,324 [run_pretraining.py:  558]:	worker_index: 3, step: 1645, cost: 7.679292, mlm loss: 7.679292, speed: 1.103926 steps/s, speed: 8.831408 samples/s, speed: 4521.680990 tokens/s, learning rate: 1.644e-05, loss_scalings: 6871.948730, pp_loss: 7.294071
[INFO] 2021-07-12 19:04:51,324 [run_pretraining.py:  512]:	********exe.run_1645******* 
[INFO] 2021-07-12 19:04:52,231 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:52,232 [run_pretraining.py:  534]:	loss/total_loss, 7.463542938232422, 1646
[INFO] 2021-07-12 19:04:52,232 [run_pretraining.py:  535]:	loss/mlm_loss, 7.463542938232422, 1646
[INFO] 2021-07-12 19:04:52,232 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6449999748147093e-05, 1646
[INFO] 2021-07-12 19:04:52,232 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1646
[INFO] 2021-07-12 19:04:52,232 [run_pretraining.py:  558]:	worker_index: 3, step: 1646, cost: 7.463543, mlm loss: 7.463543, speed: 1.101879 steps/s, speed: 8.815033 samples/s, speed: 4513.296905 tokens/s, learning rate: 1.645e-05, loss_scalings: 6871.948730, pp_loss: 6.420790
[INFO] 2021-07-12 19:04:52,232 [run_pretraining.py:  512]:	********exe.run_1646******* 
[INFO] 2021-07-12 19:04:53,139 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:53,139 [run_pretraining.py:  534]:	loss/total_loss, 8.093618392944336, 1647
[INFO] 2021-07-12 19:04:53,139 [run_pretraining.py:  535]:	loss/mlm_loss, 8.093618392944336, 1647
[INFO] 2021-07-12 19:04:53,139 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6459998732898384e-05, 1647
[INFO] 2021-07-12 19:04:53,139 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1647
[INFO] 2021-07-12 19:04:53,139 [run_pretraining.py:  558]:	worker_index: 3, step: 1647, cost: 8.093618, mlm loss: 8.093618, speed: 1.102715 steps/s, speed: 8.821717 samples/s, speed: 4516.719003 tokens/s, learning rate: 1.646e-05, loss_scalings: 6871.948730, pp_loss: 7.685482
[INFO] 2021-07-12 19:04:53,140 [run_pretraining.py:  512]:	********exe.run_1647******* 
[INFO] 2021-07-12 19:04:54,048 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:54,049 [run_pretraining.py:  534]:	loss/total_loss, 7.556087493896484, 1648
[INFO] 2021-07-12 19:04:54,049 [run_pretraining.py:  535]:	loss/mlm_loss, 7.556087493896484, 1648
[INFO] 2021-07-12 19:04:54,049 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.646999953663908e-05, 1648
[INFO] 2021-07-12 19:04:54,049 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1648
[INFO] 2021-07-12 19:04:54,049 [run_pretraining.py:  558]:	worker_index: 3, step: 1648, cost: 7.556087, mlm loss: 7.556087, speed: 1.099934 steps/s, speed: 8.799471 samples/s, speed: 4505.328991 tokens/s, learning rate: 1.647e-05, loss_scalings: 6871.948730, pp_loss: 7.302677
[INFO] 2021-07-12 19:04:54,049 [run_pretraining.py:  512]:	********exe.run_1648******* 
[INFO] 2021-07-12 19:04:55,112 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:55,113 [run_pretraining.py:  534]:	loss/total_loss, 7.038464069366455, 1649
[INFO] 2021-07-12 19:04:55,113 [run_pretraining.py:  535]:	loss/mlm_loss, 7.038464069366455, 1649
[INFO] 2021-07-12 19:04:55,113 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6480000340379775e-05, 1649
[INFO] 2021-07-12 19:04:55,113 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1649
[INFO] 2021-07-12 19:04:55,113 [run_pretraining.py:  558]:	worker_index: 3, step: 1649, cost: 7.038464, mlm loss: 7.038464, speed: 0.940500 steps/s, speed: 7.523999 samples/s, speed: 3852.287461 tokens/s, learning rate: 1.648e-05, loss_scalings: 6871.948730, pp_loss: 7.333924
[INFO] 2021-07-12 19:04:55,113 [run_pretraining.py:  512]:	********exe.run_1649******* 
[INFO] 2021-07-12 19:04:56,192 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:56,193 [run_pretraining.py:  534]:	loss/total_loss, 7.252007484436035, 1650
[INFO] 2021-07-12 19:04:56,193 [run_pretraining.py:  535]:	loss/mlm_loss, 7.252007484436035, 1650
[INFO] 2021-07-12 19:04:56,193 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6489999325131066e-05, 1650
[INFO] 2021-07-12 19:04:56,193 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1650
[INFO] 2021-07-12 19:04:56,193 [run_pretraining.py:  558]:	worker_index: 3, step: 1650, cost: 7.252007, mlm loss: 7.252007, speed: 0.926447 steps/s, speed: 7.411575 samples/s, speed: 3794.726523 tokens/s, learning rate: 1.649e-05, loss_scalings: 6871.948730, pp_loss: 7.107029
[INFO] 2021-07-12 19:04:56,193 [run_pretraining.py:  512]:	********exe.run_1650******* 
[INFO] 2021-07-12 19:04:57,248 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:57,249 [run_pretraining.py:  534]:	loss/total_loss, 6.815842628479004, 1651
[INFO] 2021-07-12 19:04:57,249 [run_pretraining.py:  535]:	loss/mlm_loss, 6.815842628479004, 1651
[INFO] 2021-07-12 19:04:57,249 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.650000012887176e-05, 1651
[INFO] 2021-07-12 19:04:57,249 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1651
[INFO] 2021-07-12 19:04:57,249 [run_pretraining.py:  558]:	worker_index: 3, step: 1651, cost: 6.815843, mlm loss: 6.815843, speed: 0.947546 steps/s, speed: 7.580370 samples/s, speed: 3881.149440 tokens/s, learning rate: 1.650e-05, loss_scalings: 6871.948730, pp_loss: 5.355595
[INFO] 2021-07-12 19:04:57,249 [run_pretraining.py:  512]:	********exe.run_1651******* 
[INFO] 2021-07-12 19:04:58,317 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:58,317 [run_pretraining.py:  534]:	loss/total_loss, 7.672508239746094, 1652
[INFO] 2021-07-12 19:04:58,317 [run_pretraining.py:  535]:	loss/mlm_loss, 7.672508239746094, 1652
[INFO] 2021-07-12 19:04:58,317 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6509999113623053e-05, 1652
[INFO] 2021-07-12 19:04:58,317 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1652
[INFO] 2021-07-12 19:04:58,317 [run_pretraining.py:  558]:	worker_index: 3, step: 1652, cost: 7.672508, mlm loss: 7.672508, speed: 0.936620 steps/s, speed: 7.492963 samples/s, speed: 3836.397007 tokens/s, learning rate: 1.651e-05, loss_scalings: 6871.948730, pp_loss: 7.456289
[INFO] 2021-07-12 19:04:58,318 [run_pretraining.py:  512]:	********exe.run_1652******* 
[INFO] 2021-07-12 19:04:59,378 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:59,379 [run_pretraining.py:  534]:	loss/total_loss, 7.300168991088867, 1653
[INFO] 2021-07-12 19:04:59,379 [run_pretraining.py:  535]:	loss/mlm_loss, 7.300168991088867, 1653
[INFO] 2021-07-12 19:04:59,379 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6519999917363748e-05, 1653
[INFO] 2021-07-12 19:04:59,379 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1653
[INFO] 2021-07-12 19:04:59,379 [run_pretraining.py:  558]:	worker_index: 3, step: 1653, cost: 7.300169, mlm loss: 7.300169, speed: 0.942319 steps/s, speed: 7.538555 samples/s, speed: 3859.740107 tokens/s, learning rate: 1.652e-05, loss_scalings: 6871.948730, pp_loss: 7.181162
[INFO] 2021-07-12 19:04:59,379 [run_pretraining.py:  512]:	********exe.run_1653******* 
[INFO] 2021-07-12 19:05:00,378 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:00,379 [run_pretraining.py:  534]:	loss/total_loss, 6.802958011627197, 1654
[INFO] 2021-07-12 19:05:00,379 [run_pretraining.py:  535]:	loss/mlm_loss, 6.802958011627197, 1654
[INFO] 2021-07-12 19:05:00,379 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.652999890211504e-05, 1654
[INFO] 2021-07-12 19:05:00,379 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1654
[INFO] 2021-07-12 19:05:00,379 [run_pretraining.py:  558]:	worker_index: 3, step: 1654, cost: 6.802958, mlm loss: 6.802958, speed: 1.000844 steps/s, speed: 8.006756 samples/s, speed: 4099.458973 tokens/s, learning rate: 1.653e-05, loss_scalings: 6871.948730, pp_loss: 7.469326
[INFO] 2021-07-12 19:05:00,379 [run_pretraining.py:  512]:	********exe.run_1654******* 
[INFO] 2021-07-12 19:05:01,303 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:01,304 [run_pretraining.py:  534]:	loss/total_loss, 7.443753242492676, 1655
[INFO] 2021-07-12 19:05:01,304 [run_pretraining.py:  535]:	loss/mlm_loss, 7.443753242492676, 1655
[INFO] 2021-07-12 19:05:01,304 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6539999705855735e-05, 1655
[INFO] 2021-07-12 19:05:01,304 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1655
[INFO] 2021-07-12 19:05:01,304 [run_pretraining.py:  558]:	worker_index: 3, step: 1655, cost: 7.443753, mlm loss: 7.443753, speed: 1.081622 steps/s, speed: 8.652974 samples/s, speed: 4430.322509 tokens/s, learning rate: 1.654e-05, loss_scalings: 6871.948730, pp_loss: 7.627967
[INFO] 2021-07-12 19:05:01,304 [run_pretraining.py:  512]:	********exe.run_1655******* 
[INFO] 2021-07-12 19:05:02,220 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:02,220 [run_pretraining.py:  534]:	loss/total_loss, 8.17967414855957, 1656
[INFO] 2021-07-12 19:05:02,220 [run_pretraining.py:  535]:	loss/mlm_loss, 8.17967414855957, 1656
[INFO] 2021-07-12 19:05:02,221 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6549998690607026e-05, 1656
[INFO] 2021-07-12 19:05:02,221 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1656
[INFO] 2021-07-12 19:05:02,221 [run_pretraining.py:  558]:	worker_index: 3, step: 1656, cost: 8.179674, mlm loss: 8.179674, speed: 1.091994 steps/s, speed: 8.735954 samples/s, speed: 4472.808394 tokens/s, learning rate: 1.655e-05, loss_scalings: 6871.948730, pp_loss: 7.662032
[INFO] 2021-07-12 19:05:02,221 [run_pretraining.py:  512]:	********exe.run_1656******* 
[INFO] 2021-07-12 19:05:03,130 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:03,131 [run_pretraining.py:  534]:	loss/total_loss, 7.520757675170898, 1657
[INFO] 2021-07-12 19:05:03,131 [run_pretraining.py:  535]:	loss/mlm_loss, 7.520757675170898, 1657
[INFO] 2021-07-12 19:05:03,131 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.655999949434772e-05, 1657
[INFO] 2021-07-12 19:05:03,131 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1657
[INFO] 2021-07-12 19:05:03,131 [run_pretraining.py:  558]:	worker_index: 3, step: 1657, cost: 7.520758, mlm loss: 7.520758, speed: 1.099252 steps/s, speed: 8.794019 samples/s, speed: 4502.537659 tokens/s, learning rate: 1.656e-05, loss_scalings: 6871.948730, pp_loss: 6.908983
[INFO] 2021-07-12 19:05:03,131 [run_pretraining.py:  512]:	********exe.run_1657******* 
[INFO] 2021-07-12 19:05:04,057 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:04,057 [run_pretraining.py:  534]:	loss/total_loss, 5.847927093505859, 1658
[INFO] 2021-07-12 19:05:04,057 [run_pretraining.py:  535]:	loss/mlm_loss, 5.847927093505859, 1658
[INFO] 2021-07-12 19:05:04,057 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6570000298088416e-05, 1658
[INFO] 2021-07-12 19:05:04,057 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1658
[INFO] 2021-07-12 19:05:04,057 [run_pretraining.py:  558]:	worker_index: 3, step: 1658, cost: 5.847927, mlm loss: 5.847927, speed: 1.080212 steps/s, speed: 8.641693 samples/s, speed: 4424.546785 tokens/s, learning rate: 1.657e-05, loss_scalings: 6871.948730, pp_loss: 7.191267
[INFO] 2021-07-12 19:05:04,058 [run_pretraining.py:  512]:	********exe.run_1658******* 
[INFO] 2021-07-12 19:05:04,960 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:04,960 [run_pretraining.py:  534]:	loss/total_loss, 7.540968418121338, 1659
[INFO] 2021-07-12 19:05:04,960 [run_pretraining.py:  535]:	loss/mlm_loss, 7.540968418121338, 1659
[INFO] 2021-07-12 19:05:04,960 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6579999282839708e-05, 1659
[INFO] 2021-07-12 19:05:04,960 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1659
[INFO] 2021-07-12 19:05:04,960 [run_pretraining.py:  558]:	worker_index: 3, step: 1659, cost: 7.540968, mlm loss: 7.540968, speed: 1.108168 steps/s, speed: 8.865342 samples/s, speed: 4539.054977 tokens/s, learning rate: 1.658e-05, loss_scalings: 6871.948730, pp_loss: 7.480466
[INFO] 2021-07-12 19:05:04,961 [run_pretraining.py:  512]:	********exe.run_1659******* 
[INFO] 2021-07-12 19:05:05,866 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:05,867 [run_pretraining.py:  534]:	loss/total_loss, 7.092055320739746, 1660
[INFO] 2021-07-12 19:05:05,867 [run_pretraining.py:  535]:	loss/mlm_loss, 7.092055320739746, 1660
[INFO] 2021-07-12 19:05:05,867 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6590000086580403e-05, 1660
[INFO] 2021-07-12 19:05:05,867 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1660
[INFO] 2021-07-12 19:05:05,867 [run_pretraining.py:  558]:	worker_index: 3, step: 1660, cost: 7.092055, mlm loss: 7.092055, speed: 1.103692 steps/s, speed: 8.829533 samples/s, speed: 4520.720790 tokens/s, learning rate: 1.659e-05, loss_scalings: 6871.948730, pp_loss: 7.377602
[INFO] 2021-07-12 19:05:05,867 [run_pretraining.py:  512]:	********exe.run_1660******* 
[INFO] 2021-07-12 19:05:06,780 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:06,781 [run_pretraining.py:  534]:	loss/total_loss, 7.432246208190918, 1661
[INFO] 2021-07-12 19:05:06,781 [run_pretraining.py:  535]:	loss/mlm_loss, 7.432246208190918, 1661
[INFO] 2021-07-12 19:05:06,781 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6599999071331695e-05, 1661
[INFO] 2021-07-12 19:05:06,781 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1661
[INFO] 2021-07-12 19:05:06,781 [run_pretraining.py:  558]:	worker_index: 3, step: 1661, cost: 7.432246, mlm loss: 7.432246, speed: 1.094745 steps/s, speed: 8.757960 samples/s, speed: 4484.075326 tokens/s, learning rate: 1.660e-05, loss_scalings: 6871.948730, pp_loss: 7.471843
[INFO] 2021-07-12 19:05:06,781 [run_pretraining.py:  512]:	********exe.run_1661******* 
[INFO] 2021-07-12 19:05:07,808 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:07,808 [run_pretraining.py:  534]:	loss/total_loss, 7.00209903717041, 1662
[INFO] 2021-07-12 19:05:07,808 [run_pretraining.py:  535]:	loss/mlm_loss, 7.00209903717041, 1662
[INFO] 2021-07-12 19:05:07,808 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.660999987507239e-05, 1662
[INFO] 2021-07-12 19:05:07,808 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1662
[INFO] 2021-07-12 19:05:07,808 [run_pretraining.py:  558]:	worker_index: 3, step: 1662, cost: 7.002099, mlm loss: 7.002099, speed: 0.974058 steps/s, speed: 7.792463 samples/s, speed: 3989.741128 tokens/s, learning rate: 1.661e-05, loss_scalings: 6871.948730, pp_loss: 7.431287
[INFO] 2021-07-12 19:05:07,809 [run_pretraining.py:  512]:	********exe.run_1662******* 
[INFO] 2021-07-12 19:05:08,885 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:08,886 [run_pretraining.py:  534]:	loss/total_loss, 7.244575023651123, 1663
[INFO] 2021-07-12 19:05:08,886 [run_pretraining.py:  535]:	loss/mlm_loss, 7.244575023651123, 1663
[INFO] 2021-07-12 19:05:08,886 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.661999885982368e-05, 1663
[INFO] 2021-07-12 19:05:08,886 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1663
[INFO] 2021-07-12 19:05:08,886 [run_pretraining.py:  558]:	worker_index: 3, step: 1663, cost: 7.244575, mlm loss: 7.244575, speed: 0.928306 steps/s, speed: 7.426447 samples/s, speed: 3802.340778 tokens/s, learning rate: 1.662e-05, loss_scalings: 6871.948730, pp_loss: 7.231137
[INFO] 2021-07-12 19:05:08,886 [run_pretraining.py:  512]:	********exe.run_1663******* 
[INFO] 2021-07-12 19:05:09,945 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:09,946 [run_pretraining.py:  534]:	loss/total_loss, 8.607940673828125, 1664
[INFO] 2021-07-12 19:05:09,946 [run_pretraining.py:  535]:	loss/mlm_loss, 8.607940673828125, 1664
[INFO] 2021-07-12 19:05:09,946 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6629999663564377e-05, 1664
[INFO] 2021-07-12 19:05:09,946 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1664
[INFO] 2021-07-12 19:05:09,946 [run_pretraining.py:  558]:	worker_index: 3, step: 1664, cost: 8.607941, mlm loss: 8.607941, speed: 0.944434 steps/s, speed: 7.555472 samples/s, speed: 3868.401558 tokens/s, learning rate: 1.663e-05, loss_scalings: 6871.948730, pp_loss: 7.571846
[INFO] 2021-07-12 19:05:09,946 [run_pretraining.py:  512]:	********exe.run_1664******* 
[INFO] 2021-07-12 19:05:11,010 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:11,011 [run_pretraining.py:  534]:	loss/total_loss, 7.111158847808838, 1665
[INFO] 2021-07-12 19:05:11,012 [run_pretraining.py:  535]:	loss/mlm_loss, 7.111158847808838, 1665
[INFO] 2021-07-12 19:05:11,014 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.664000046730507e-05, 1665
[INFO] 2021-07-12 19:05:11,014 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1665
[INFO] 2021-07-12 19:05:11,016 [run_pretraining.py:  558]:	worker_index: 3, step: 1665, cost: 7.111159, mlm loss: 7.111159, speed: 0.939154 steps/s, speed: 7.513234 samples/s, speed: 3846.775622 tokens/s, learning rate: 1.664e-05, loss_scalings: 6871.948730, pp_loss: 7.428805
[INFO] 2021-07-12 19:05:11,016 [run_pretraining.py:  512]:	********exe.run_1665******* 
[INFO] 2021-07-12 19:05:12,065 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:12,066 [run_pretraining.py:  534]:	loss/total_loss, 7.640201568603516, 1666
[INFO] 2021-07-12 19:05:12,066 [run_pretraining.py:  535]:	loss/mlm_loss, 7.640201568603516, 1666
[INFO] 2021-07-12 19:05:12,066 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6649999452056363e-05, 1666
[INFO] 2021-07-12 19:05:12,066 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1666
[INFO] 2021-07-12 19:05:12,066 [run_pretraining.py:  558]:	worker_index: 3, step: 1666, cost: 7.640202, mlm loss: 7.640202, speed: 0.953211 steps/s, speed: 7.625690 samples/s, speed: 3904.353338 tokens/s, learning rate: 1.665e-05, loss_scalings: 6871.948730, pp_loss: 7.436653
[INFO] 2021-07-12 19:05:12,066 [run_pretraining.py:  512]:	********exe.run_1666******* 
[INFO] 2021-07-12 19:05:13,126 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:13,127 [run_pretraining.py:  534]:	loss/total_loss, 7.2099714279174805, 1667
[INFO] 2021-07-12 19:05:13,127 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2099714279174805, 1667
[INFO] 2021-07-12 19:05:13,127 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.666000025579706e-05, 1667
[INFO] 2021-07-12 19:05:13,127 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1667
[INFO] 2021-07-12 19:05:13,127 [run_pretraining.py:  558]:	worker_index: 3, step: 1667, cost: 7.209971, mlm loss: 7.209971, speed: 0.943071 steps/s, speed: 7.544570 samples/s, speed: 3862.820092 tokens/s, learning rate: 1.666e-05, loss_scalings: 6871.948730, pp_loss: 6.823497
[INFO] 2021-07-12 19:05:13,127 [run_pretraining.py:  512]:	********exe.run_1667******* 
[INFO] 2021-07-12 19:05:14,187 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:14,187 [run_pretraining.py:  534]:	loss/total_loss, 6.900871276855469, 1668
[INFO] 2021-07-12 19:05:14,188 [run_pretraining.py:  535]:	loss/mlm_loss, 6.900871276855469, 1668
[INFO] 2021-07-12 19:05:14,188 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.666999924054835e-05, 1668
[INFO] 2021-07-12 19:05:14,188 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1668
[INFO] 2021-07-12 19:05:14,188 [run_pretraining.py:  558]:	worker_index: 3, step: 1668, cost: 6.900871, mlm loss: 6.900871, speed: 0.943199 steps/s, speed: 7.545588 samples/s, speed: 3863.341286 tokens/s, learning rate: 1.667e-05, loss_scalings: 6871.948730, pp_loss: 7.426494
[INFO] 2021-07-12 19:05:14,188 [run_pretraining.py:  512]:	********exe.run_1668******* 
[INFO] 2021-07-12 19:05:15,258 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:15,259 [run_pretraining.py:  534]:	loss/total_loss, 7.511867523193359, 1669
[INFO] 2021-07-12 19:05:15,259 [run_pretraining.py:  535]:	loss/mlm_loss, 7.511867523193359, 1669
[INFO] 2021-07-12 19:05:15,259 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6680000044289045e-05, 1669
[INFO] 2021-07-12 19:05:15,259 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1669
[INFO] 2021-07-12 19:05:15,259 [run_pretraining.py:  558]:	worker_index: 3, step: 1669, cost: 7.511868, mlm loss: 7.511868, speed: 0.933976 steps/s, speed: 7.471805 samples/s, speed: 3825.563910 tokens/s, learning rate: 1.668e-05, loss_scalings: 6871.948730, pp_loss: 7.402066
[INFO] 2021-07-12 19:05:15,259 [run_pretraining.py:  512]:	********exe.run_1669******* 
[INFO] 2021-07-12 19:05:40,460 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:40,460 [run_pretraining.py:  534]:	loss/total_loss, 6.854939937591553, 1670
[INFO] 2021-07-12 19:05:40,460 [run_pretraining.py:  535]:	loss/mlm_loss, 6.854939937591553, 1670
[INFO] 2021-07-12 19:05:40,461 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6689999029040337e-05, 1670
[INFO] 2021-07-12 19:05:40,461 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1670
[INFO] 2021-07-12 19:05:40,461 [run_pretraining.py:  558]:	worker_index: 3, step: 1670, cost: 6.854940, mlm loss: 6.854940, speed: 0.039681 steps/s, speed: 0.317449 samples/s, speed: 162.533816 tokens/s, learning rate: 1.669e-05, loss_scalings: 6871.948730, pp_loss: 7.673163
[INFO] 2021-07-12 19:05:40,461 [run_pretraining.py:  512]:	********exe.run_1670******* 
[INFO] 2021-07-12 19:05:41,374 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:41,374 [run_pretraining.py:  534]:	loss/total_loss, 7.860404968261719, 1671
[INFO] 2021-07-12 19:05:41,374 [run_pretraining.py:  535]:	loss/mlm_loss, 7.860404968261719, 1671
[INFO] 2021-07-12 19:05:41,374 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6699999832781032e-05, 1671
[INFO] 2021-07-12 19:05:41,374 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1671
[INFO] 2021-07-12 19:05:41,375 [run_pretraining.py:  558]:	worker_index: 3, step: 1671, cost: 7.860405, mlm loss: 7.860405, speed: 1.095094 steps/s, speed: 8.760752 samples/s, speed: 4485.504812 tokens/s, learning rate: 1.670e-05, loss_scalings: 6871.948730, pp_loss: 7.589247
[INFO] 2021-07-12 19:05:41,375 [run_pretraining.py:  512]:	********exe.run_1671******* 
[INFO] 2021-07-12 19:05:42,282 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:42,283 [run_pretraining.py:  534]:	loss/total_loss, 6.740163326263428, 1672
[INFO] 2021-07-12 19:05:42,283 [run_pretraining.py:  535]:	loss/mlm_loss, 6.740163326263428, 1672
[INFO] 2021-07-12 19:05:42,283 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6709998817532323e-05, 1672
[INFO] 2021-07-12 19:05:42,283 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1672
[INFO] 2021-07-12 19:05:42,283 [run_pretraining.py:  558]:	worker_index: 3, step: 1672, cost: 6.740163, mlm loss: 6.740163, speed: 1.101308 steps/s, speed: 8.810462 samples/s, speed: 4510.956399 tokens/s, learning rate: 1.671e-05, loss_scalings: 6871.948730, pp_loss: 7.354897
[INFO] 2021-07-12 19:05:42,283 [run_pretraining.py:  512]:	********exe.run_1672******* 
[INFO] 2021-07-12 19:05:43,191 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:43,192 [run_pretraining.py:  534]:	loss/total_loss, 6.937963485717773, 1673
[INFO] 2021-07-12 19:05:43,192 [run_pretraining.py:  535]:	loss/mlm_loss, 6.937963485717773, 1673
[INFO] 2021-07-12 19:05:43,192 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.671999962127302e-05, 1673
[INFO] 2021-07-12 19:05:43,192 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1673
[INFO] 2021-07-12 19:05:43,192 [run_pretraining.py:  558]:	worker_index: 3, step: 1673, cost: 6.937963, mlm loss: 6.937963, speed: 1.100660 steps/s, speed: 8.805278 samples/s, speed: 4508.302421 tokens/s, learning rate: 1.672e-05, loss_scalings: 6871.948730, pp_loss: 7.304234
[INFO] 2021-07-12 19:05:43,192 [run_pretraining.py:  512]:	********exe.run_1673******* 
[INFO] 2021-07-12 19:05:44,180 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:44,180 [run_pretraining.py:  534]:	loss/total_loss, 7.587765693664551, 1674
[INFO] 2021-07-12 19:05:44,180 [run_pretraining.py:  535]:	loss/mlm_loss, 7.587765693664551, 1674
[INFO] 2021-07-12 19:05:44,180 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6730000425013714e-05, 1674
[INFO] 2021-07-12 19:05:44,180 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1674
[INFO] 2021-07-12 19:05:44,181 [run_pretraining.py:  558]:	worker_index: 3, step: 1674, cost: 7.587766, mlm loss: 7.587766, speed: 1.012567 steps/s, speed: 8.100533 samples/s, speed: 4147.472795 tokens/s, learning rate: 1.673e-05, loss_scalings: 6871.948730, pp_loss: 7.631766
[INFO] 2021-07-12 19:05:44,181 [run_pretraining.py:  512]:	********exe.run_1674******* 
[INFO] 2021-07-12 19:05:45,087 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:45,087 [run_pretraining.py:  534]:	loss/total_loss, 7.34600830078125, 1675
[INFO] 2021-07-12 19:05:45,087 [run_pretraining.py:  535]:	loss/mlm_loss, 7.34600830078125, 1675
[INFO] 2021-07-12 19:05:45,087 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6739999409765005e-05, 1675
[INFO] 2021-07-12 19:05:45,088 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1675
[INFO] 2021-07-12 19:05:45,088 [run_pretraining.py:  558]:	worker_index: 3, step: 1675, cost: 7.346008, mlm loss: 7.346008, speed: 1.103230 steps/s, speed: 8.825842 samples/s, speed: 4518.831330 tokens/s, learning rate: 1.674e-05, loss_scalings: 6871.948730, pp_loss: 7.546117
[INFO] 2021-07-12 19:05:45,088 [run_pretraining.py:  512]:	********exe.run_1675******* 
[INFO] 2021-07-12 19:05:45,993 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:45,994 [run_pretraining.py:  534]:	loss/total_loss, 6.627350807189941, 1676
[INFO] 2021-07-12 19:05:45,994 [run_pretraining.py:  535]:	loss/mlm_loss, 6.627350807189941, 1676
[INFO] 2021-07-12 19:05:45,994 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.67500002135057e-05, 1676
[INFO] 2021-07-12 19:05:45,994 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1676
[INFO] 2021-07-12 19:05:45,994 [run_pretraining.py:  558]:	worker_index: 3, step: 1676, cost: 6.627351, mlm loss: 6.627351, speed: 1.103907 steps/s, speed: 8.831252 samples/s, speed: 4521.601255 tokens/s, learning rate: 1.675e-05, loss_scalings: 6871.948730, pp_loss: 7.299145
[INFO] 2021-07-12 19:05:45,994 [run_pretraining.py:  512]:	********exe.run_1676******* 
[INFO] 2021-07-12 19:05:46,900 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:46,900 [run_pretraining.py:  534]:	loss/total_loss, 7.707470893859863, 1677
[INFO] 2021-07-12 19:05:46,900 [run_pretraining.py:  535]:	loss/mlm_loss, 7.707470893859863, 1677
[INFO] 2021-07-12 19:05:46,900 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6760001017246395e-05, 1677
[INFO] 2021-07-12 19:05:46,900 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1677
[INFO] 2021-07-12 19:05:46,901 [run_pretraining.py:  558]:	worker_index: 3, step: 1677, cost: 7.707471, mlm loss: 7.707471, speed: 1.104031 steps/s, speed: 8.832247 samples/s, speed: 4522.110653 tokens/s, learning rate: 1.676e-05, loss_scalings: 6871.948730, pp_loss: 7.508857
[INFO] 2021-07-12 19:05:46,901 [run_pretraining.py:  512]:	********exe.run_1677******* 
[INFO] 2021-07-12 19:05:47,814 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:47,814 [run_pretraining.py:  534]:	loss/total_loss, 7.155920505523682, 1678
[INFO] 2021-07-12 19:05:47,814 [run_pretraining.py:  535]:	loss/mlm_loss, 7.155920505523682, 1678
[INFO] 2021-07-12 19:05:47,814 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6769998183008283e-05, 1678
[INFO] 2021-07-12 19:05:47,814 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1678
[INFO] 2021-07-12 19:05:47,815 [run_pretraining.py:  558]:	worker_index: 3, step: 1678, cost: 7.155921, mlm loss: 7.155921, speed: 1.094896 steps/s, speed: 8.759167 samples/s, speed: 4484.693370 tokens/s, learning rate: 1.677e-05, loss_scalings: 6871.948730, pp_loss: 7.425886
[INFO] 2021-07-12 19:05:47,815 [run_pretraining.py:  512]:	********exe.run_1678******* 
[INFO] 2021-07-12 19:05:48,728 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:48,728 [run_pretraining.py:  534]:	loss/total_loss, 7.039172172546387, 1679
[INFO] 2021-07-12 19:05:48,729 [run_pretraining.py:  535]:	loss/mlm_loss, 7.039172172546387, 1679
[INFO] 2021-07-12 19:05:48,729 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.677999898674898e-05, 1679
[INFO] 2021-07-12 19:05:48,729 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1679
[INFO] 2021-07-12 19:05:48,729 [run_pretraining.py:  558]:	worker_index: 3, step: 1679, cost: 7.039172, mlm loss: 7.039172, speed: 1.094484 steps/s, speed: 8.755873 samples/s, speed: 4483.007026 tokens/s, learning rate: 1.678e-05, loss_scalings: 6871.948730, pp_loss: 7.439024
[INFO] 2021-07-12 19:05:48,729 [run_pretraining.py:  512]:	********exe.run_1679******* 
[INFO] 2021-07-12 19:05:49,637 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:49,637 [run_pretraining.py:  534]:	loss/total_loss, 7.712169170379639, 1680
[INFO] 2021-07-12 19:05:49,637 [run_pretraining.py:  535]:	loss/mlm_loss, 7.712169170379639, 1680
[INFO] 2021-07-12 19:05:49,638 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6789999790489674e-05, 1680
[INFO] 2021-07-12 19:05:49,638 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1680
[INFO] 2021-07-12 19:05:49,638 [run_pretraining.py:  558]:	worker_index: 3, step: 1680, cost: 7.712169, mlm loss: 7.712169, speed: 1.100980 steps/s, speed: 8.807839 samples/s, speed: 4509.613631 tokens/s, learning rate: 1.679e-05, loss_scalings: 6871.948730, pp_loss: 6.715928
[INFO] 2021-07-12 19:05:49,638 [run_pretraining.py:  512]:	********exe.run_1680******* 
[INFO] 2021-07-12 19:05:50,555 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:50,555 [run_pretraining.py:  534]:	loss/total_loss, 7.224399089813232, 1681
[INFO] 2021-07-12 19:05:50,556 [run_pretraining.py:  535]:	loss/mlm_loss, 7.224399089813232, 1681
[INFO] 2021-07-12 19:05:50,556 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6799998775240965e-05, 1681
[INFO] 2021-07-12 19:05:50,556 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1681
[INFO] 2021-07-12 19:05:50,556 [run_pretraining.py:  558]:	worker_index: 3, step: 1681, cost: 7.224399, mlm loss: 7.224399, speed: 1.090069 steps/s, speed: 8.720556 samples/s, speed: 4464.924653 tokens/s, learning rate: 1.680e-05, loss_scalings: 6871.948730, pp_loss: 7.581742
[INFO] 2021-07-12 19:05:50,556 [run_pretraining.py:  512]:	********exe.run_1681******* 
[INFO] 2021-07-12 19:05:51,468 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:51,469 [run_pretraining.py:  534]:	loss/total_loss, 7.254704475402832, 1682
[INFO] 2021-07-12 19:05:51,469 [run_pretraining.py:  535]:	loss/mlm_loss, 7.254704475402832, 1682
[INFO] 2021-07-12 19:05:51,469 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.680999957898166e-05, 1682
[INFO] 2021-07-12 19:05:51,469 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1682
[INFO] 2021-07-12 19:05:51,469 [run_pretraining.py:  558]:	worker_index: 3, step: 1682, cost: 7.254704, mlm loss: 7.254704, speed: 1.095708 steps/s, speed: 8.765661 samples/s, speed: 4488.018280 tokens/s, learning rate: 1.681e-05, loss_scalings: 6871.948730, pp_loss: 7.442969
[INFO] 2021-07-12 19:05:51,469 [run_pretraining.py:  512]:	********exe.run_1682******* 
[INFO] 2021-07-12 19:05:52,383 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:52,384 [run_pretraining.py:  534]:	loss/total_loss, 6.681100368499756, 1683
[INFO] 2021-07-12 19:05:52,384 [run_pretraining.py:  535]:	loss/mlm_loss, 6.681100368499756, 1683
[INFO] 2021-07-12 19:05:52,384 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6820000382722355e-05, 1683
[INFO] 2021-07-12 19:05:52,384 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1683
[INFO] 2021-07-12 19:05:52,384 [run_pretraining.py:  558]:	worker_index: 3, step: 1683, cost: 6.681100, mlm loss: 6.681100, speed: 1.093700 steps/s, speed: 8.749597 samples/s, speed: 4479.793496 tokens/s, learning rate: 1.682e-05, loss_scalings: 6871.948730, pp_loss: 6.939814
[INFO] 2021-07-12 19:05:52,384 [run_pretraining.py:  512]:	********exe.run_1683******* 
[INFO] 2021-07-12 19:05:53,306 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:53,307 [run_pretraining.py:  534]:	loss/total_loss, 6.787540912628174, 1684
[INFO] 2021-07-12 19:05:53,307 [run_pretraining.py:  535]:	loss/mlm_loss, 6.787540912628174, 1684
[INFO] 2021-07-12 19:05:53,307 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6829999367473647e-05, 1684
[INFO] 2021-07-12 19:05:53,307 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1684
[INFO] 2021-07-12 19:05:53,307 [run_pretraining.py:  558]:	worker_index: 3, step: 1684, cost: 6.787541, mlm loss: 6.787541, speed: 1.084150 steps/s, speed: 8.673200 samples/s, speed: 4440.678158 tokens/s, learning rate: 1.683e-05, loss_scalings: 6871.948730, pp_loss: 7.232858
[INFO] 2021-07-12 19:05:53,307 [run_pretraining.py:  512]:	********exe.run_1684******* 
[INFO] 2021-07-12 19:05:54,213 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:54,213 [run_pretraining.py:  534]:	loss/total_loss, 6.718725204467773, 1685
[INFO] 2021-07-12 19:05:54,214 [run_pretraining.py:  535]:	loss/mlm_loss, 6.718725204467773, 1685
[INFO] 2021-07-12 19:05:54,214 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6840000171214342e-05, 1685
[INFO] 2021-07-12 19:05:54,214 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1685
[INFO] 2021-07-12 19:05:54,214 [run_pretraining.py:  558]:	worker_index: 3, step: 1685, cost: 6.718725, mlm loss: 6.718725, speed: 1.103592 steps/s, speed: 8.828736 samples/s, speed: 4520.312800 tokens/s, learning rate: 1.684e-05, loss_scalings: 6871.948730, pp_loss: 7.203595
[INFO] 2021-07-12 19:05:54,214 [run_pretraining.py:  512]:	********exe.run_1685******* 
[INFO] 2021-07-12 19:05:55,124 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:55,125 [run_pretraining.py:  534]:	loss/total_loss, 6.941205024719238, 1686
[INFO] 2021-07-12 19:05:55,125 [run_pretraining.py:  535]:	loss/mlm_loss, 6.941205024719238, 1686
[INFO] 2021-07-12 19:05:55,125 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6850000974955037e-05, 1686
[INFO] 2021-07-12 19:05:55,125 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1686
[INFO] 2021-07-12 19:05:55,125 [run_pretraining.py:  558]:	worker_index: 3, step: 1686, cost: 6.941205, mlm loss: 6.941205, speed: 1.097963 steps/s, speed: 8.783703 samples/s, speed: 4497.256125 tokens/s, learning rate: 1.685e-05, loss_scalings: 6871.948730, pp_loss: 7.240993
[INFO] 2021-07-12 19:05:55,125 [run_pretraining.py:  512]:	********exe.run_1686******* 
[INFO] 2021-07-12 19:05:56,042 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:56,042 [run_pretraining.py:  534]:	loss/total_loss, 7.832828521728516, 1687
[INFO] 2021-07-12 19:05:56,043 [run_pretraining.py:  535]:	loss/mlm_loss, 7.832828521728516, 1687
[INFO] 2021-07-12 19:05:56,043 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6859998140716925e-05, 1687
[INFO] 2021-07-12 19:05:56,043 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1687
[INFO] 2021-07-12 19:05:56,043 [run_pretraining.py:  558]:	worker_index: 3, step: 1687, cost: 7.832829, mlm loss: 7.832829, speed: 1.090580 steps/s, speed: 8.724637 samples/s, speed: 4467.014354 tokens/s, learning rate: 1.686e-05, loss_scalings: 6871.948730, pp_loss: 7.875100
[INFO] 2021-07-12 19:05:56,043 [run_pretraining.py:  512]:	********exe.run_1687******* 
[INFO] 2021-07-12 19:05:56,955 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:56,956 [run_pretraining.py:  534]:	loss/total_loss, 7.093118190765381, 1688
[INFO] 2021-07-12 19:05:56,956 [run_pretraining.py:  535]:	loss/mlm_loss, 7.093118190765381, 1688
[INFO] 2021-07-12 19:05:56,956 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.686999894445762e-05, 1688
[INFO] 2021-07-12 19:05:56,956 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1688
[INFO] 2021-07-12 19:05:56,956 [run_pretraining.py:  558]:	worker_index: 3, step: 1688, cost: 7.093118, mlm loss: 7.093118, speed: 1.095422 steps/s, speed: 8.763374 samples/s, speed: 4486.847322 tokens/s, learning rate: 1.687e-05, loss_scalings: 6871.948730, pp_loss: 7.391500
[INFO] 2021-07-12 19:05:56,956 [run_pretraining.py:  512]:	********exe.run_1688******* 
[INFO] 2021-07-12 19:05:57,906 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:57,907 [run_pretraining.py:  534]:	loss/total_loss, 6.732145309448242, 1689
[INFO] 2021-07-12 19:05:57,907 [run_pretraining.py:  535]:	loss/mlm_loss, 6.732145309448242, 1689
[INFO] 2021-07-12 19:05:57,907 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6879999748198316e-05, 1689
[INFO] 2021-07-12 19:05:57,907 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1689
[INFO] 2021-07-12 19:05:57,907 [run_pretraining.py:  558]:	worker_index: 3, step: 1689, cost: 6.732145, mlm loss: 6.732145, speed: 1.052413 steps/s, speed: 8.419305 samples/s, speed: 4310.684050 tokens/s, learning rate: 1.688e-05, loss_scalings: 6871.948730, pp_loss: 7.006419
[INFO] 2021-07-12 19:05:57,907 [run_pretraining.py:  512]:	********exe.run_1689******* 
[INFO] 2021-07-12 19:05:58,820 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:58,821 [run_pretraining.py:  534]:	loss/total_loss, 8.093171119689941, 1690
[INFO] 2021-07-12 19:05:58,821 [run_pretraining.py:  535]:	loss/mlm_loss, 8.093171119689941, 1690
[INFO] 2021-07-12 19:05:58,821 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6889998732949607e-05, 1690
[INFO] 2021-07-12 19:05:58,821 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1690
[INFO] 2021-07-12 19:05:58,821 [run_pretraining.py:  558]:	worker_index: 3, step: 1690, cost: 8.093171, mlm loss: 8.093171, speed: 1.095013 steps/s, speed: 8.760107 samples/s, speed: 4485.174580 tokens/s, learning rate: 1.689e-05, loss_scalings: 6871.948730, pp_loss: 7.463912
[INFO] 2021-07-12 19:05:58,821 [run_pretraining.py:  512]:	********exe.run_1690******* 
[INFO] 2021-07-12 19:05:59,737 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:59,737 [run_pretraining.py:  534]:	loss/total_loss, 8.00303840637207, 1691
[INFO] 2021-07-12 19:05:59,737 [run_pretraining.py:  535]:	loss/mlm_loss, 8.00303840637207, 1691
[INFO] 2021-07-12 19:05:59,738 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6899999536690302e-05, 1691
[INFO] 2021-07-12 19:05:59,738 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1691
[INFO] 2021-07-12 19:05:59,738 [run_pretraining.py:  558]:	worker_index: 3, step: 1691, cost: 8.003038, mlm loss: 8.003038, speed: 1.091599 steps/s, speed: 8.732794 samples/s, speed: 4471.190320 tokens/s, learning rate: 1.690e-05, loss_scalings: 6871.948730, pp_loss: 7.420419
[INFO] 2021-07-12 19:05:59,738 [run_pretraining.py:  512]:	********exe.run_1691******* 
[INFO] 2021-07-12 19:06:00,660 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:00,660 [run_pretraining.py:  534]:	loss/total_loss, 7.426486015319824, 1692
[INFO] 2021-07-12 19:06:00,660 [run_pretraining.py:  535]:	loss/mlm_loss, 7.426486015319824, 1692
[INFO] 2021-07-12 19:06:00,660 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6910000340430997e-05, 1692
[INFO] 2021-07-12 19:06:00,661 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1692
[INFO] 2021-07-12 19:06:00,661 [run_pretraining.py:  558]:	worker_index: 3, step: 1692, cost: 7.426486, mlm loss: 7.426486, speed: 1.084327 steps/s, speed: 8.674614 samples/s, speed: 4441.402559 tokens/s, learning rate: 1.691e-05, loss_scalings: 6871.948730, pp_loss: 6.716624
[INFO] 2021-07-12 19:06:00,661 [run_pretraining.py:  512]:	********exe.run_1692******* 
[INFO] 2021-07-12 19:06:01,573 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:01,573 [run_pretraining.py:  534]:	loss/total_loss, 7.204883575439453, 1693
[INFO] 2021-07-12 19:06:01,573 [run_pretraining.py:  535]:	loss/mlm_loss, 7.204883575439453, 1693
[INFO] 2021-07-12 19:06:01,573 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.691999932518229e-05, 1693
[INFO] 2021-07-12 19:06:01,573 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1693
[INFO] 2021-07-12 19:06:01,574 [run_pretraining.py:  558]:	worker_index: 3, step: 1693, cost: 7.204884, mlm loss: 7.204884, speed: 1.096124 steps/s, speed: 8.768994 samples/s, speed: 4489.724824 tokens/s, learning rate: 1.692e-05, loss_scalings: 6871.948730, pp_loss: 7.107248
[INFO] 2021-07-12 19:06:01,574 [run_pretraining.py:  512]:	********exe.run_1693******* 
[INFO] 2021-07-12 19:06:02,483 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:02,484 [run_pretraining.py:  534]:	loss/total_loss, 7.477883815765381, 1694
[INFO] 2021-07-12 19:06:02,484 [run_pretraining.py:  535]:	loss/mlm_loss, 7.477883815765381, 1694
[INFO] 2021-07-12 19:06:02,484 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6930000128922984e-05, 1694
[INFO] 2021-07-12 19:06:02,484 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1694
[INFO] 2021-07-12 19:06:02,484 [run_pretraining.py:  558]:	worker_index: 3, step: 1694, cost: 7.477884, mlm loss: 7.477884, speed: 1.099164 steps/s, speed: 8.793316 samples/s, speed: 4502.177777 tokens/s, learning rate: 1.693e-05, loss_scalings: 6871.948730, pp_loss: 7.401144
[INFO] 2021-07-12 19:06:02,484 [run_pretraining.py:  512]:	********exe.run_1694******* 
[INFO] 2021-07-12 19:06:03,399 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:03,399 [run_pretraining.py:  534]:	loss/total_loss, 7.163527011871338, 1695
[INFO] 2021-07-12 19:06:03,399 [run_pretraining.py:  535]:	loss/mlm_loss, 7.163527011871338, 1695
[INFO] 2021-07-12 19:06:03,399 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.694000093266368e-05, 1695
[INFO] 2021-07-12 19:06:03,399 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1695
[INFO] 2021-07-12 19:06:03,400 [run_pretraining.py:  558]:	worker_index: 3, step: 1695, cost: 7.163527, mlm loss: 7.163527, speed: 1.093002 steps/s, speed: 8.744015 samples/s, speed: 4476.935705 tokens/s, learning rate: 1.694e-05, loss_scalings: 6871.948730, pp_loss: 6.356829
[INFO] 2021-07-12 19:06:03,400 [run_pretraining.py:  512]:	********exe.run_1695******* 
[INFO] 2021-07-12 19:06:04,312 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:04,312 [run_pretraining.py:  534]:	loss/total_loss, 7.266448020935059, 1696
[INFO] 2021-07-12 19:06:04,312 [run_pretraining.py:  535]:	loss/mlm_loss, 7.266448020935059, 1696
[INFO] 2021-07-12 19:06:04,312 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6949998098425567e-05, 1696
[INFO] 2021-07-12 19:06:04,312 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1696
[INFO] 2021-07-12 19:06:04,312 [run_pretraining.py:  558]:	worker_index: 3, step: 1696, cost: 7.266448, mlm loss: 7.266448, speed: 1.096112 steps/s, speed: 8.768900 samples/s, speed: 4489.676718 tokens/s, learning rate: 1.695e-05, loss_scalings: 6871.948730, pp_loss: 7.549717
[INFO] 2021-07-12 19:06:04,313 [run_pretraining.py:  512]:	********exe.run_1696******* 
[INFO] 2021-07-12 19:06:05,227 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:05,228 [run_pretraining.py:  534]:	loss/total_loss, 7.693347930908203, 1697
[INFO] 2021-07-12 19:06:05,228 [run_pretraining.py:  535]:	loss/mlm_loss, 7.693347930908203, 1697
[INFO] 2021-07-12 19:06:05,228 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6959998902166262e-05, 1697
[INFO] 2021-07-12 19:06:05,228 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1697
[INFO] 2021-07-12 19:06:05,228 [run_pretraining.py:  558]:	worker_index: 3, step: 1697, cost: 7.693348, mlm loss: 7.693348, speed: 1.092862 steps/s, speed: 8.742896 samples/s, speed: 4476.362952 tokens/s, learning rate: 1.696e-05, loss_scalings: 6871.948730, pp_loss: 7.380980
[INFO] 2021-07-12 19:06:05,228 [run_pretraining.py:  512]:	********exe.run_1697******* 
[INFO] 2021-07-12 19:06:06,158 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:06,159 [run_pretraining.py:  534]:	loss/total_loss, 7.215180397033691, 1698
[INFO] 2021-07-12 19:06:06,159 [run_pretraining.py:  535]:	loss/mlm_loss, 7.215180397033691, 1698
[INFO] 2021-07-12 19:06:06,159 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6969999705906957e-05, 1698
[INFO] 2021-07-12 19:06:06,159 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1698
[INFO] 2021-07-12 19:06:06,159 [run_pretraining.py:  558]:	worker_index: 3, step: 1698, cost: 7.215180, mlm loss: 7.215180, speed: 1.075060 steps/s, speed: 8.600481 samples/s, speed: 4403.446193 tokens/s, learning rate: 1.697e-05, loss_scalings: 6871.948730, pp_loss: 7.235221
[INFO] 2021-07-12 19:06:06,159 [run_pretraining.py:  512]:	********exe.run_1698******* 
[INFO] 2021-07-12 19:06:07,088 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:07,089 [run_pretraining.py:  534]:	loss/total_loss, 7.035700798034668, 1699
[INFO] 2021-07-12 19:06:07,089 [run_pretraining.py:  535]:	loss/mlm_loss, 7.035700798034668, 1699
[INFO] 2021-07-12 19:06:07,089 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.697999869065825e-05, 1699
[INFO] 2021-07-12 19:06:07,089 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1699
[INFO] 2021-07-12 19:06:07,089 [run_pretraining.py:  558]:	worker_index: 3, step: 1699, cost: 7.035701, mlm loss: 7.035701, speed: 1.075913 steps/s, speed: 8.607300 samples/s, speed: 4406.937666 tokens/s, learning rate: 1.698e-05, loss_scalings: 6871.948730, pp_loss: 7.168172
[INFO] 2021-07-12 19:06:07,089 [run_pretraining.py:  512]:	********exe.run_1699******* 
[INFO] 2021-07-12 19:06:08,020 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:08,021 [run_pretraining.py:  534]:	loss/total_loss, 6.8661298751831055, 1700
[INFO] 2021-07-12 19:06:08,021 [run_pretraining.py:  535]:	loss/mlm_loss, 6.8661298751831055, 1700
[INFO] 2021-07-12 19:06:08,021 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6989999494398944e-05, 1700
[INFO] 2021-07-12 19:06:08,021 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1700
[INFO] 2021-07-12 19:06:08,021 [run_pretraining.py:  558]:	worker_index: 3, step: 1700, cost: 6.866130, mlm loss: 6.866130, speed: 1.073394 steps/s, speed: 8.587152 samples/s, speed: 4396.621584 tokens/s, learning rate: 1.699e-05, loss_scalings: 6871.948730, pp_loss: 7.154105
[INFO] 2021-07-12 19:06:08,021 [run_pretraining.py:  512]:	********exe.run_1700******* 
[INFO] 2021-07-12 19:06:08,950 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:08,950 [run_pretraining.py:  534]:	loss/total_loss, 7.844624042510986, 1701
[INFO] 2021-07-12 19:06:08,950 [run_pretraining.py:  535]:	loss/mlm_loss, 7.844624042510986, 1701
[INFO] 2021-07-12 19:06:08,951 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.700000029813964e-05, 1701
[INFO] 2021-07-12 19:06:08,951 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1701
[INFO] 2021-07-12 19:06:08,951 [run_pretraining.py:  558]:	worker_index: 3, step: 1701, cost: 7.844624, mlm loss: 7.844624, speed: 1.076684 steps/s, speed: 8.613469 samples/s, speed: 4410.096164 tokens/s, learning rate: 1.700e-05, loss_scalings: 6871.948730, pp_loss: 7.180034
[INFO] 2021-07-12 19:06:08,951 [run_pretraining.py:  512]:	********exe.run_1701******* 
[INFO] 2021-07-12 19:06:09,880 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:09,881 [run_pretraining.py:  534]:	loss/total_loss, 7.9113969802856445, 1702
[INFO] 2021-07-12 19:06:09,881 [run_pretraining.py:  535]:	loss/mlm_loss, 7.9113969802856445, 1702
[INFO] 2021-07-12 19:06:09,881 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.700999928289093e-05, 1702
[INFO] 2021-07-12 19:06:09,881 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1702
[INFO] 2021-07-12 19:06:09,881 [run_pretraining.py:  558]:	worker_index: 3, step: 1702, cost: 7.911397, mlm loss: 7.911397, speed: 1.075831 steps/s, speed: 8.606649 samples/s, speed: 4406.604207 tokens/s, learning rate: 1.701e-05, loss_scalings: 6871.948730, pp_loss: 7.384564
[INFO] 2021-07-12 19:06:09,881 [run_pretraining.py:  512]:	********exe.run_1702******* 
[INFO] 2021-07-12 19:06:10,805 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:10,805 [run_pretraining.py:  534]:	loss/total_loss, 7.774470806121826, 1703
[INFO] 2021-07-12 19:06:10,805 [run_pretraining.py:  535]:	loss/mlm_loss, 7.774470806121826, 1703
[INFO] 2021-07-12 19:06:10,805 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7020000086631626e-05, 1703
[INFO] 2021-07-12 19:06:10,806 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1703
[INFO] 2021-07-12 19:06:10,806 [run_pretraining.py:  558]:	worker_index: 3, step: 1703, cost: 7.774471, mlm loss: 7.774471, speed: 1.082115 steps/s, speed: 8.656918 samples/s, speed: 4432.342202 tokens/s, learning rate: 1.702e-05, loss_scalings: 6871.948730, pp_loss: 7.367990
[INFO] 2021-07-12 19:06:10,806 [run_pretraining.py:  512]:	********exe.run_1703******* 
[INFO] 2021-07-12 19:06:11,729 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:11,729 [run_pretraining.py:  534]:	loss/total_loss, 6.5804266929626465, 1704
[INFO] 2021-07-12 19:06:11,730 [run_pretraining.py:  535]:	loss/mlm_loss, 6.5804266929626465, 1704
[INFO] 2021-07-12 19:06:11,730 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.703000089037232e-05, 1704
[INFO] 2021-07-12 19:06:11,730 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1704
[INFO] 2021-07-12 19:06:11,730 [run_pretraining.py:  558]:	worker_index: 3, step: 1704, cost: 6.580427, mlm loss: 6.580427, speed: 1.082918 steps/s, speed: 8.663342 samples/s, speed: 4435.631140 tokens/s, learning rate: 1.703e-05, loss_scalings: 6871.948730, pp_loss: 7.455423
[INFO] 2021-07-12 19:06:11,730 [run_pretraining.py:  512]:	********exe.run_1704******* 
[INFO] 2021-07-12 19:06:12,653 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:12,653 [run_pretraining.py:  534]:	loss/total_loss, 6.785275459289551, 1705
[INFO] 2021-07-12 19:06:12,653 [run_pretraining.py:  535]:	loss/mlm_loss, 6.785275459289551, 1705
[INFO] 2021-07-12 19:06:12,653 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.703999805613421e-05, 1705
[INFO] 2021-07-12 19:06:12,654 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1705
[INFO] 2021-07-12 19:06:12,654 [run_pretraining.py:  558]:	worker_index: 3, step: 1705, cost: 6.785275, mlm loss: 6.785275, speed: 1.083173 steps/s, speed: 8.665387 samples/s, speed: 4436.678123 tokens/s, learning rate: 1.704e-05, loss_scalings: 6871.948730, pp_loss: 7.343136
[INFO] 2021-07-12 19:06:12,654 [run_pretraining.py:  512]:	********exe.run_1705******* 
[INFO] 2021-07-12 19:06:13,574 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:13,575 [run_pretraining.py:  534]:	loss/total_loss, 7.386397838592529, 1706
[INFO] 2021-07-12 19:06:13,575 [run_pretraining.py:  535]:	loss/mlm_loss, 7.386397838592529, 1706
[INFO] 2021-07-12 19:06:13,575 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7049998859874904e-05, 1706
[INFO] 2021-07-12 19:06:13,575 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1706
[INFO] 2021-07-12 19:06:13,575 [run_pretraining.py:  558]:	worker_index: 3, step: 1706, cost: 7.386398, mlm loss: 7.386398, speed: 1.085891 steps/s, speed: 8.687128 samples/s, speed: 4447.809601 tokens/s, learning rate: 1.705e-05, loss_scalings: 6871.948730, pp_loss: 7.287804
[INFO] 2021-07-12 19:06:13,575 [run_pretraining.py:  512]:	********exe.run_1706******* 
[INFO] 2021-07-12 19:06:14,494 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:14,494 [run_pretraining.py:  534]:	loss/total_loss, 7.1683454513549805, 1707
[INFO] 2021-07-12 19:06:14,494 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1683454513549805, 1707
[INFO] 2021-07-12 19:06:14,495 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.70599996636156e-05, 1707
[INFO] 2021-07-12 19:06:14,495 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1707
[INFO] 2021-07-12 19:06:14,495 [run_pretraining.py:  558]:	worker_index: 3, step: 1707, cost: 7.168345, mlm loss: 7.168345, speed: 1.088274 steps/s, speed: 8.706190 samples/s, speed: 4457.569398 tokens/s, learning rate: 1.706e-05, loss_scalings: 6871.948730, pp_loss: 7.241343
[INFO] 2021-07-12 19:06:14,495 [run_pretraining.py:  512]:	********exe.run_1707******* 
[INFO] 2021-07-12 19:06:15,419 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:15,420 [run_pretraining.py:  534]:	loss/total_loss, 6.990086555480957, 1708
[INFO] 2021-07-12 19:06:15,420 [run_pretraining.py:  535]:	loss/mlm_loss, 6.990086555480957, 1708
[INFO] 2021-07-12 19:06:15,420 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.706999864836689e-05, 1708
[INFO] 2021-07-12 19:06:15,420 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1708
[INFO] 2021-07-12 19:06:15,420 [run_pretraining.py:  558]:	worker_index: 3, step: 1708, cost: 6.990087, mlm loss: 6.990087, speed: 1.081054 steps/s, speed: 8.648428 samples/s, speed: 4427.995346 tokens/s, learning rate: 1.707e-05, loss_scalings: 6871.948730, pp_loss: 7.267562
[INFO] 2021-07-12 19:06:15,420 [run_pretraining.py:  512]:	********exe.run_1708******* 
[INFO] 2021-07-12 19:06:16,346 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:16,346 [run_pretraining.py:  534]:	loss/total_loss, 7.413073539733887, 1709
[INFO] 2021-07-12 19:06:16,346 [run_pretraining.py:  535]:	loss/mlm_loss, 7.413073539733887, 1709
[INFO] 2021-07-12 19:06:16,347 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7079999452107586e-05, 1709
[INFO] 2021-07-12 19:06:16,347 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1709
[INFO] 2021-07-12 19:06:16,347 [run_pretraining.py:  558]:	worker_index: 3, step: 1709, cost: 7.413074, mlm loss: 7.413074, speed: 1.080197 steps/s, speed: 8.641573 samples/s, speed: 4424.485253 tokens/s, learning rate: 1.708e-05, loss_scalings: 6871.948730, pp_loss: 7.318719
[INFO] 2021-07-12 19:06:16,347 [run_pretraining.py:  512]:	********exe.run_1709******* 
[INFO] 2021-07-12 19:06:17,265 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:17,266 [run_pretraining.py:  534]:	loss/total_loss, 7.975496292114258, 1710
[INFO] 2021-07-12 19:06:17,266 [run_pretraining.py:  535]:	loss/mlm_loss, 7.975496292114258, 1710
[INFO] 2021-07-12 19:06:17,266 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.709000025584828e-05, 1710
[INFO] 2021-07-12 19:06:17,266 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1710
[INFO] 2021-07-12 19:06:17,266 [run_pretraining.py:  558]:	worker_index: 3, step: 1710, cost: 7.975496, mlm loss: 7.975496, speed: 1.088253 steps/s, speed: 8.706025 samples/s, speed: 4457.484969 tokens/s, learning rate: 1.709e-05, loss_scalings: 6871.948730, pp_loss: 7.503948
[INFO] 2021-07-12 19:06:17,266 [run_pretraining.py:  512]:	********exe.run_1710******* 
[INFO] 2021-07-12 19:06:18,189 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:18,190 [run_pretraining.py:  534]:	loss/total_loss, 7.773214340209961, 1711
[INFO] 2021-07-12 19:06:18,190 [run_pretraining.py:  535]:	loss/mlm_loss, 7.773214340209961, 1711
[INFO] 2021-07-12 19:06:18,190 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7099999240599573e-05, 1711
[INFO] 2021-07-12 19:06:18,190 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1711
[INFO] 2021-07-12 19:06:18,190 [run_pretraining.py:  558]:	worker_index: 3, step: 1711, cost: 7.773214, mlm loss: 7.773214, speed: 1.083272 steps/s, speed: 8.666175 samples/s, speed: 4437.081469 tokens/s, learning rate: 1.710e-05, loss_scalings: 6871.948730, pp_loss: 7.384305
[INFO] 2021-07-12 19:06:18,190 [run_pretraining.py:  512]:	********exe.run_1711******* 
[INFO] 2021-07-12 19:06:19,123 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:19,129 [run_pretraining.py:  534]:	loss/total_loss, 7.169107437133789, 1712
[INFO] 2021-07-12 19:06:19,134 [run_pretraining.py:  535]:	loss/mlm_loss, 7.169107437133789, 1712
[INFO] 2021-07-12 19:06:19,136 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7110000044340268e-05, 1712
[INFO] 2021-07-12 19:06:19,140 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1712
[INFO] 2021-07-12 19:06:19,144 [run_pretraining.py:  558]:	worker_index: 3, step: 1712, cost: 7.169107, mlm loss: 7.169107, speed: 1.065722 steps/s, speed: 8.525773 samples/s, speed: 4365.195655 tokens/s, learning rate: 1.711e-05, loss_scalings: 6871.948730, pp_loss: 7.558300
[INFO] 2021-07-12 19:06:19,146 [run_pretraining.py:  512]:	********exe.run_1712******* 
[INFO] 2021-07-12 19:06:20,064 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:20,065 [run_pretraining.py:  534]:	loss/total_loss, 7.207408905029297, 1713
[INFO] 2021-07-12 19:06:20,065 [run_pretraining.py:  535]:	loss/mlm_loss, 7.207408905029297, 1713
[INFO] 2021-07-12 19:06:20,065 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7120000848080963e-05, 1713
[INFO] 2021-07-12 19:06:20,065 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1713
[INFO] 2021-07-12 19:06:20,065 [run_pretraining.py:  558]:	worker_index: 3, step: 1713, cost: 7.207409, mlm loss: 7.207409, speed: 1.088436 steps/s, speed: 8.707489 samples/s, speed: 4458.234532 tokens/s, learning rate: 1.712e-05, loss_scalings: 6871.948730, pp_loss: 7.481834
[INFO] 2021-07-12 19:06:20,065 [run_pretraining.py:  512]:	********exe.run_1713******* 
[INFO] 2021-07-12 19:06:20,999 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:21,000 [run_pretraining.py:  534]:	loss/total_loss, 6.9922332763671875, 1714
[INFO] 2021-07-12 19:06:21,000 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9922332763671875, 1714
[INFO] 2021-07-12 19:06:21,000 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7129999832832254e-05, 1714
[INFO] 2021-07-12 19:06:21,000 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1714
[INFO] 2021-07-12 19:06:21,000 [run_pretraining.py:  558]:	worker_index: 3, step: 1714, cost: 6.992233, mlm loss: 6.992233, speed: 1.070170 steps/s, speed: 8.561363 samples/s, speed: 4383.418098 tokens/s, learning rate: 1.713e-05, loss_scalings: 6871.948730, pp_loss: 7.314898
[INFO] 2021-07-12 19:06:21,000 [run_pretraining.py:  512]:	********exe.run_1714******* 
[INFO] 2021-07-12 19:06:21,917 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:21,917 [run_pretraining.py:  534]:	loss/total_loss, 7.19782829284668, 1715
[INFO] 2021-07-12 19:06:21,918 [run_pretraining.py:  535]:	loss/mlm_loss, 7.19782829284668, 1715
[INFO] 2021-07-12 19:06:21,918 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7139998817583546e-05, 1715
[INFO] 2021-07-12 19:06:21,918 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1715
[INFO] 2021-07-12 19:06:21,918 [run_pretraining.py:  558]:	worker_index: 3, step: 1715, cost: 7.197828, mlm loss: 7.197828, speed: 1.090637 steps/s, speed: 8.725096 samples/s, speed: 4467.248987 tokens/s, learning rate: 1.714e-05, loss_scalings: 6871.948730, pp_loss: 7.126019
[INFO] 2021-07-12 19:06:21,918 [run_pretraining.py:  512]:	********exe.run_1715******* 
[INFO] 2021-07-12 19:06:22,840 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:22,841 [run_pretraining.py:  534]:	loss/total_loss, 7.438504219055176, 1716
[INFO] 2021-07-12 19:06:22,841 [run_pretraining.py:  535]:	loss/mlm_loss, 7.438504219055176, 1716
[INFO] 2021-07-12 19:06:22,841 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.714999962132424e-05, 1716
[INFO] 2021-07-12 19:06:22,841 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1716
[INFO] 2021-07-12 19:06:22,841 [run_pretraining.py:  558]:	worker_index: 3, step: 1716, cost: 7.438504, mlm loss: 7.438504, speed: 1.083736 steps/s, speed: 8.669890 samples/s, speed: 4438.983456 tokens/s, learning rate: 1.715e-05, loss_scalings: 6871.948730, pp_loss: 7.264868
[INFO] 2021-07-12 19:06:22,841 [run_pretraining.py:  512]:	********exe.run_1716******* 
[INFO] 2021-07-12 19:06:23,885 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:23,885 [run_pretraining.py:  534]:	loss/total_loss, 6.897912502288818, 1717
[INFO] 2021-07-12 19:06:23,885 [run_pretraining.py:  535]:	loss/mlm_loss, 6.897912502288818, 1717
[INFO] 2021-07-12 19:06:23,885 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7159998606075533e-05, 1717
[INFO] 2021-07-12 19:06:23,885 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1717
[INFO] 2021-07-12 19:06:23,885 [run_pretraining.py:  558]:	worker_index: 3, step: 1717, cost: 6.897913, mlm loss: 6.897913, speed: 0.958191 steps/s, speed: 7.665530 samples/s, speed: 3924.751385 tokens/s, learning rate: 1.716e-05, loss_scalings: 6871.948730, pp_loss: 7.134949
[INFO] 2021-07-12 19:06:23,886 [run_pretraining.py:  512]:	********exe.run_1717******* 
[INFO] 2021-07-12 19:06:24,955 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:24,955 [run_pretraining.py:  534]:	loss/total_loss, 7.3245530128479, 1718
[INFO] 2021-07-12 19:06:24,955 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3245530128479, 1718
[INFO] 2021-07-12 19:06:24,955 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7169999409816228e-05, 1718
[INFO] 2021-07-12 19:06:24,955 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1718
[INFO] 2021-07-12 19:06:24,955 [run_pretraining.py:  558]:	worker_index: 3, step: 1718, cost: 7.324553, mlm loss: 7.324553, speed: 0.935141 steps/s, speed: 7.481130 samples/s, speed: 3830.338605 tokens/s, learning rate: 1.717e-05, loss_scalings: 6871.948730, pp_loss: 7.155902
[INFO] 2021-07-12 19:06:24,956 [run_pretraining.py:  512]:	********exe.run_1718******* 
[INFO] 2021-07-12 19:06:26,018 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:26,019 [run_pretraining.py:  534]:	loss/total_loss, 7.092846870422363, 1719
[INFO] 2021-07-12 19:06:26,019 [run_pretraining.py:  535]:	loss/mlm_loss, 7.092846870422363, 1719
[INFO] 2021-07-12 19:06:26,019 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7180000213556923e-05, 1719
[INFO] 2021-07-12 19:06:26,019 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1719
[INFO] 2021-07-12 19:06:26,019 [run_pretraining.py:  558]:	worker_index: 3, step: 1719, cost: 7.092847, mlm loss: 7.092847, speed: 0.940532 steps/s, speed: 7.524252 samples/s, speed: 3852.417037 tokens/s, learning rate: 1.718e-05, loss_scalings: 6871.948730, pp_loss: 7.076922
[INFO] 2021-07-12 19:06:26,019 [run_pretraining.py:  512]:	********exe.run_1719******* 
[INFO] 2021-07-12 19:06:27,082 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:27,082 [run_pretraining.py:  534]:	loss/total_loss, 7.363461971282959, 1720
[INFO] 2021-07-12 19:06:27,082 [run_pretraining.py:  535]:	loss/mlm_loss, 7.363461971282959, 1720
[INFO] 2021-07-12 19:06:27,082 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7189999198308215e-05, 1720
[INFO] 2021-07-12 19:06:27,082 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1720
[INFO] 2021-07-12 19:06:27,082 [run_pretraining.py:  558]:	worker_index: 3, step: 1720, cost: 7.363462, mlm loss: 7.363462, speed: 0.941152 steps/s, speed: 7.529216 samples/s, speed: 3854.958480 tokens/s, learning rate: 1.719e-05, loss_scalings: 6871.948730, pp_loss: 7.301747
[INFO] 2021-07-12 19:06:27,083 [run_pretraining.py:  512]:	********exe.run_1720******* 
[INFO] 2021-07-12 19:06:28,148 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:28,148 [run_pretraining.py:  534]:	loss/total_loss, 6.630708694458008, 1721
[INFO] 2021-07-12 19:06:28,148 [run_pretraining.py:  535]:	loss/mlm_loss, 6.630708694458008, 1721
[INFO] 2021-07-12 19:06:28,148 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.720000000204891e-05, 1721
[INFO] 2021-07-12 19:06:28,149 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1721
[INFO] 2021-07-12 19:06:28,149 [run_pretraining.py:  558]:	worker_index: 3, step: 1721, cost: 6.630709, mlm loss: 6.630709, speed: 0.938525 steps/s, speed: 7.508197 samples/s, speed: 3844.196781 tokens/s, learning rate: 1.720e-05, loss_scalings: 6871.948730, pp_loss: 7.118567
[INFO] 2021-07-12 19:06:28,149 [run_pretraining.py:  512]:	********exe.run_1721******* 
[INFO] 2021-07-12 19:06:29,063 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:29,063 [run_pretraining.py:  534]:	loss/total_loss, 7.13043212890625, 1722
[INFO] 2021-07-12 19:06:29,064 [run_pretraining.py:  535]:	loss/mlm_loss, 7.13043212890625, 1722
[INFO] 2021-07-12 19:06:29,064 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.72099989868002e-05, 1722
[INFO] 2021-07-12 19:06:29,064 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1722
[INFO] 2021-07-12 19:06:29,064 [run_pretraining.py:  558]:	worker_index: 3, step: 1722, cost: 7.130432, mlm loss: 7.130432, speed: 1.093421 steps/s, speed: 8.747368 samples/s, speed: 4478.652511 tokens/s, learning rate: 1.721e-05, loss_scalings: 6871.948730, pp_loss: 7.501968
[INFO] 2021-07-12 19:06:29,064 [run_pretraining.py:  512]:	********exe.run_1722******* 
[INFO] 2021-07-12 19:06:29,976 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:29,976 [run_pretraining.py:  534]:	loss/total_loss, 7.121582984924316, 1723
[INFO] 2021-07-12 19:06:29,976 [run_pretraining.py:  535]:	loss/mlm_loss, 7.121582984924316, 1723
[INFO] 2021-07-12 19:06:29,976 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7219999790540896e-05, 1723
[INFO] 2021-07-12 19:06:29,976 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1723
[INFO] 2021-07-12 19:06:29,977 [run_pretraining.py:  558]:	worker_index: 3, step: 1723, cost: 7.121583, mlm loss: 7.121583, speed: 1.096333 steps/s, speed: 8.770662 samples/s, speed: 4490.579170 tokens/s, learning rate: 1.722e-05, loss_scalings: 6871.948730, pp_loss: 6.976692
[INFO] 2021-07-12 19:06:29,977 [run_pretraining.py:  512]:	********exe.run_1723******* 
[INFO] 2021-07-12 19:06:30,885 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:30,885 [run_pretraining.py:  534]:	loss/total_loss, 7.507888317108154, 1724
[INFO] 2021-07-12 19:06:30,885 [run_pretraining.py:  535]:	loss/mlm_loss, 7.507888317108154, 1724
[INFO] 2021-07-12 19:06:30,885 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7229998775292188e-05, 1724
[INFO] 2021-07-12 19:06:30,885 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1724
[INFO] 2021-07-12 19:06:30,885 [run_pretraining.py:  558]:	worker_index: 3, step: 1724, cost: 7.507888, mlm loss: 7.507888, speed: 1.101077 steps/s, speed: 8.808614 samples/s, speed: 4510.010221 tokens/s, learning rate: 1.723e-05, loss_scalings: 6871.948730, pp_loss: 7.311917
[INFO] 2021-07-12 19:06:30,885 [run_pretraining.py:  512]:	********exe.run_1724******* 
[INFO] 2021-07-12 19:06:31,797 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:31,798 [run_pretraining.py:  534]:	loss/total_loss, 6.747041702270508, 1725
[INFO] 2021-07-12 19:06:31,798 [run_pretraining.py:  535]:	loss/mlm_loss, 6.747041702270508, 1725
[INFO] 2021-07-12 19:06:31,798 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7239999579032883e-05, 1725
[INFO] 2021-07-12 19:06:31,798 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1725
[INFO] 2021-07-12 19:06:31,798 [run_pretraining.py:  558]:	worker_index: 3, step: 1725, cost: 6.747042, mlm loss: 6.747042, speed: 1.096454 steps/s, speed: 8.771635 samples/s, speed: 4491.076906 tokens/s, learning rate: 1.724e-05, loss_scalings: 6871.948730, pp_loss: 6.900973
[INFO] 2021-07-12 19:06:31,798 [run_pretraining.py:  512]:	********exe.run_1725******* 
[INFO] 2021-07-12 19:06:32,706 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:32,706 [run_pretraining.py:  534]:	loss/total_loss, 7.624631881713867, 1726
[INFO] 2021-07-12 19:06:32,706 [run_pretraining.py:  535]:	loss/mlm_loss, 7.624631881713867, 1726
[INFO] 2021-07-12 19:06:32,707 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7250000382773578e-05, 1726
[INFO] 2021-07-12 19:06:32,707 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1726
[INFO] 2021-07-12 19:06:32,707 [run_pretraining.py:  558]:	worker_index: 3, step: 1726, cost: 7.624632, mlm loss: 7.624632, speed: 1.101352 steps/s, speed: 8.810816 samples/s, speed: 4511.137628 tokens/s, learning rate: 1.725e-05, loss_scalings: 6871.948730, pp_loss: 7.162379
[INFO] 2021-07-12 19:06:32,707 [run_pretraining.py:  512]:	********exe.run_1726******* 
[INFO] 2021-07-12 19:06:33,617 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:33,617 [run_pretraining.py:  534]:	loss/total_loss, 6.340315818786621, 1727
[INFO] 2021-07-12 19:06:33,617 [run_pretraining.py:  535]:	loss/mlm_loss, 6.340315818786621, 1727
[INFO] 2021-07-12 19:06:33,617 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.725999936752487e-05, 1727
[INFO] 2021-07-12 19:06:33,617 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1727
[INFO] 2021-07-12 19:06:33,617 [run_pretraining.py:  558]:	worker_index: 3, step: 1727, cost: 6.340316, mlm loss: 6.340316, speed: 1.098657 steps/s, speed: 8.789260 samples/s, speed: 4500.101026 tokens/s, learning rate: 1.726e-05, loss_scalings: 6871.948730, pp_loss: 7.260711
[INFO] 2021-07-12 19:06:33,618 [run_pretraining.py:  512]:	********exe.run_1727******* 
[INFO] 2021-07-12 19:06:34,587 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:34,587 [run_pretraining.py:  534]:	loss/total_loss, 7.408441066741943, 1728
[INFO] 2021-07-12 19:06:34,587 [run_pretraining.py:  535]:	loss/mlm_loss, 7.408441066741943, 1728
[INFO] 2021-07-12 19:06:34,587 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7270000171265565e-05, 1728
[INFO] 2021-07-12 19:06:34,588 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1728
[INFO] 2021-07-12 19:06:34,588 [run_pretraining.py:  558]:	worker_index: 3, step: 1728, cost: 7.408441, mlm loss: 7.408441, speed: 1.031505 steps/s, speed: 8.252039 samples/s, speed: 4225.043876 tokens/s, learning rate: 1.727e-05, loss_scalings: 6871.948730, pp_loss: 7.319772
[INFO] 2021-07-12 19:06:34,588 [run_pretraining.py:  512]:	********exe.run_1728******* 
[INFO] 2021-07-12 19:06:35,622 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:35,623 [run_pretraining.py:  534]:	loss/total_loss, 7.314052581787109, 1729
[INFO] 2021-07-12 19:06:35,623 [run_pretraining.py:  535]:	loss/mlm_loss, 7.314052581787109, 1729
[INFO] 2021-07-12 19:06:35,623 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7279999156016856e-05, 1729
[INFO] 2021-07-12 19:06:35,623 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1729
[INFO] 2021-07-12 19:06:35,623 [run_pretraining.py:  558]:	worker_index: 3, step: 1729, cost: 7.314053, mlm loss: 7.314053, speed: 0.966206 steps/s, speed: 7.729644 samples/s, speed: 3957.577848 tokens/s, learning rate: 1.728e-05, loss_scalings: 6871.948730, pp_loss: 7.190831
[INFO] 2021-07-12 19:06:35,623 [run_pretraining.py:  512]:	********exe.run_1729******* 
[INFO] 2021-07-12 19:06:36,672 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:36,673 [run_pretraining.py:  534]:	loss/total_loss, 6.85947847366333, 1730
[INFO] 2021-07-12 19:06:36,673 [run_pretraining.py:  535]:	loss/mlm_loss, 6.85947847366333, 1730
[INFO] 2021-07-12 19:06:36,673 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.728999995975755e-05, 1730
[INFO] 2021-07-12 19:06:36,673 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1730
[INFO] 2021-07-12 19:06:36,673 [run_pretraining.py:  558]:	worker_index: 3, step: 1730, cost: 6.859478, mlm loss: 6.859478, speed: 0.953087 steps/s, speed: 7.624699 samples/s, speed: 3903.845859 tokens/s, learning rate: 1.729e-05, loss_scalings: 6871.948730, pp_loss: 6.955029
[INFO] 2021-07-12 19:06:36,673 [run_pretraining.py:  512]:	********exe.run_1730******* 
[INFO] 2021-07-12 19:06:37,740 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:37,740 [run_pretraining.py:  534]:	loss/total_loss, 7.313472747802734, 1731
[INFO] 2021-07-12 19:06:37,740 [run_pretraining.py:  535]:	loss/mlm_loss, 7.313472747802734, 1731
[INFO] 2021-07-12 19:06:37,741 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7299998944508843e-05, 1731
[INFO] 2021-07-12 19:06:37,741 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1731
[INFO] 2021-07-12 19:06:37,741 [run_pretraining.py:  558]:	worker_index: 3, step: 1731, cost: 7.313473, mlm loss: 7.313473, speed: 0.937192 steps/s, speed: 7.497534 samples/s, speed: 3838.737217 tokens/s, learning rate: 1.730e-05, loss_scalings: 6871.948730, pp_loss: 7.570655
[INFO] 2021-07-12 19:06:37,741 [run_pretraining.py:  512]:	********exe.run_1731******* 
[INFO] 2021-07-12 19:06:38,792 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:38,792 [run_pretraining.py:  534]:	loss/total_loss, 7.586142539978027, 1732
[INFO] 2021-07-12 19:06:38,792 [run_pretraining.py:  535]:	loss/mlm_loss, 7.586142539978027, 1732
[INFO] 2021-07-12 19:06:38,793 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7309999748249538e-05, 1732
[INFO] 2021-07-12 19:06:38,793 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1732
[INFO] 2021-07-12 19:06:38,793 [run_pretraining.py:  558]:	worker_index: 3, step: 1732, cost: 7.586143, mlm loss: 7.586143, speed: 0.951186 steps/s, speed: 7.609489 samples/s, speed: 3896.058620 tokens/s, learning rate: 1.731e-05, loss_scalings: 6871.948730, pp_loss: 7.244100
[INFO] 2021-07-12 19:06:38,793 [run_pretraining.py:  512]:	********exe.run_1732******* 
[INFO] 2021-07-12 19:06:39,852 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:39,852 [run_pretraining.py:  534]:	loss/total_loss, 7.700138092041016, 1733
[INFO] 2021-07-12 19:06:39,852 [run_pretraining.py:  535]:	loss/mlm_loss, 7.700138092041016, 1733
[INFO] 2021-07-12 19:06:39,852 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.731999873300083e-05, 1733
[INFO] 2021-07-12 19:06:39,852 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1733
[INFO] 2021-07-12 19:06:39,852 [run_pretraining.py:  558]:	worker_index: 3, step: 1733, cost: 7.700138, mlm loss: 7.700138, speed: 0.944170 steps/s, speed: 7.553361 samples/s, speed: 3867.320886 tokens/s, learning rate: 1.732e-05, loss_scalings: 6871.948730, pp_loss: 7.759677
[INFO] 2021-07-12 19:06:39,853 [run_pretraining.py:  512]:	********exe.run_1733******* 
[INFO] 2021-07-12 19:06:40,914 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:40,915 [run_pretraining.py:  534]:	loss/total_loss, 6.470446586608887, 1734
[INFO] 2021-07-12 19:06:40,915 [run_pretraining.py:  535]:	loss/mlm_loss, 6.470446586608887, 1734
[INFO] 2021-07-12 19:06:40,915 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7329999536741525e-05, 1734
[INFO] 2021-07-12 19:06:40,915 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1734
[INFO] 2021-07-12 19:06:40,915 [run_pretraining.py:  558]:	worker_index: 3, step: 1734, cost: 6.470447, mlm loss: 6.470447, speed: 0.941443 steps/s, speed: 7.531548 samples/s, speed: 3856.152559 tokens/s, learning rate: 1.733e-05, loss_scalings: 6871.948730, pp_loss: 7.209410
[INFO] 2021-07-12 19:06:40,915 [run_pretraining.py:  512]:	********exe.run_1734******* 
[INFO] 2021-07-12 19:06:41,971 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:41,971 [run_pretraining.py:  534]:	loss/total_loss, 7.534473419189453, 1735
[INFO] 2021-07-12 19:06:41,971 [run_pretraining.py:  535]:	loss/mlm_loss, 7.534473419189453, 1735
[INFO] 2021-07-12 19:06:41,972 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.734000034048222e-05, 1735
[INFO] 2021-07-12 19:06:41,972 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1735
[INFO] 2021-07-12 19:06:41,972 [run_pretraining.py:  558]:	worker_index: 3, step: 1735, cost: 7.534473, mlm loss: 7.534473, speed: 0.947231 steps/s, speed: 7.577852 samples/s, speed: 3879.860095 tokens/s, learning rate: 1.734e-05, loss_scalings: 6871.948730, pp_loss: 7.398877
[INFO] 2021-07-12 19:06:41,972 [run_pretraining.py:  512]:	********exe.run_1735******* 
[INFO] 2021-07-12 19:06:43,030 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:43,031 [run_pretraining.py:  534]:	loss/total_loss, 8.13001823425293, 1736
[INFO] 2021-07-12 19:06:43,031 [run_pretraining.py:  535]:	loss/mlm_loss, 8.13001823425293, 1736
[INFO] 2021-07-12 19:06:43,031 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.734999932523351e-05, 1736
[INFO] 2021-07-12 19:06:43,031 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1736
[INFO] 2021-07-12 19:06:43,031 [run_pretraining.py:  558]:	worker_index: 3, step: 1736, cost: 8.130018, mlm loss: 8.130018, speed: 0.944545 steps/s, speed: 7.556357 samples/s, speed: 3868.854557 tokens/s, learning rate: 1.735e-05, loss_scalings: 6871.948730, pp_loss: 7.426227
[INFO] 2021-07-12 19:06:43,031 [run_pretraining.py:  512]:	********exe.run_1736******* 
[INFO] 2021-07-12 19:06:44,093 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:44,093 [run_pretraining.py:  534]:	loss/total_loss, 7.2499918937683105, 1737
[INFO] 2021-07-12 19:06:44,094 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2499918937683105, 1737
[INFO] 2021-07-12 19:06:44,094 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7360000128974207e-05, 1737
[INFO] 2021-07-12 19:06:44,094 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1737
[INFO] 2021-07-12 19:06:44,094 [run_pretraining.py:  558]:	worker_index: 3, step: 1737, cost: 7.249992, mlm loss: 7.249992, speed: 0.941474 steps/s, speed: 7.531793 samples/s, speed: 3856.278067 tokens/s, learning rate: 1.736e-05, loss_scalings: 6871.948730, pp_loss: 7.304004
[INFO] 2021-07-12 19:06:44,094 [run_pretraining.py:  512]:	********exe.run_1737******* 
[INFO] 2021-07-12 19:06:45,154 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:45,155 [run_pretraining.py:  534]:	loss/total_loss, 7.112990379333496, 1738
[INFO] 2021-07-12 19:06:45,155 [run_pretraining.py:  535]:	loss/mlm_loss, 7.112990379333496, 1738
[INFO] 2021-07-12 19:06:45,155 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7370000932714902e-05, 1738
[INFO] 2021-07-12 19:06:45,155 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1738
[INFO] 2021-07-12 19:06:45,155 [run_pretraining.py:  558]:	worker_index: 3, step: 1738, cost: 7.112990, mlm loss: 7.112990, speed: 0.942897 steps/s, speed: 7.543180 samples/s, speed: 3862.108022 tokens/s, learning rate: 1.737e-05, loss_scalings: 6871.948730, pp_loss: 7.151170
[INFO] 2021-07-12 19:06:45,155 [run_pretraining.py:  512]:	********exe.run_1738******* 
[INFO] 2021-07-12 19:06:46,207 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:46,207 [run_pretraining.py:  534]:	loss/total_loss, 7.356592178344727, 1739
[INFO] 2021-07-12 19:06:46,207 [run_pretraining.py:  535]:	loss/mlm_loss, 7.356592178344727, 1739
[INFO] 2021-07-12 19:06:46,207 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7379999917466193e-05, 1739
[INFO] 2021-07-12 19:06:46,207 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1739
[INFO] 2021-07-12 19:06:46,208 [run_pretraining.py:  558]:	worker_index: 3, step: 1739, cost: 7.356592, mlm loss: 7.356592, speed: 0.950675 steps/s, speed: 7.605400 samples/s, speed: 3893.964849 tokens/s, learning rate: 1.738e-05, loss_scalings: 6871.948730, pp_loss: 6.430080
[INFO] 2021-07-12 19:06:46,208 [run_pretraining.py:  512]:	********exe.run_1739******* 
[INFO] 2021-07-12 19:06:47,265 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:47,265 [run_pretraining.py:  534]:	loss/total_loss, 7.0804972648620605, 1740
[INFO] 2021-07-12 19:06:47,265 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0804972648620605, 1740
[INFO] 2021-07-12 19:06:47,265 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7389998902217485e-05, 1740
[INFO] 2021-07-12 19:06:47,265 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1740
[INFO] 2021-07-12 19:06:47,265 [run_pretraining.py:  558]:	worker_index: 3, step: 1740, cost: 7.080497, mlm loss: 7.080497, speed: 0.945851 steps/s, speed: 7.566811 samples/s, speed: 3874.207097 tokens/s, learning rate: 1.739e-05, loss_scalings: 6871.948730, pp_loss: 7.136248
[INFO] 2021-07-12 19:06:47,265 [run_pretraining.py:  512]:	********exe.run_1740******* 
[INFO] 2021-07-12 19:06:48,322 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:48,322 [run_pretraining.py:  534]:	loss/total_loss, 6.827690124511719, 1741
[INFO] 2021-07-12 19:06:48,322 [run_pretraining.py:  535]:	loss/mlm_loss, 6.827690124511719, 1741
[INFO] 2021-07-12 19:06:48,322 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.739999970595818e-05, 1741
[INFO] 2021-07-12 19:06:48,322 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1741
[INFO] 2021-07-12 19:06:48,322 [run_pretraining.py:  558]:	worker_index: 3, step: 1741, cost: 6.827690, mlm loss: 6.827690, speed: 0.946562 steps/s, speed: 7.572492 samples/s, speed: 3877.115969 tokens/s, learning rate: 1.740e-05, loss_scalings: 6871.948730, pp_loss: 6.992755
[INFO] 2021-07-12 19:06:48,323 [run_pretraining.py:  512]:	********exe.run_1741******* 
[INFO] 2021-07-12 19:07:13,849 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:13,850 [run_pretraining.py:  534]:	loss/total_loss, 7.234308242797852, 1742
[INFO] 2021-07-12 19:07:13,850 [run_pretraining.py:  535]:	loss/mlm_loss, 7.234308242797852, 1742
[INFO] 2021-07-12 19:07:13,850 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7409998690709472e-05, 1742
[INFO] 2021-07-12 19:07:13,850 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1742
[INFO] 2021-07-12 19:07:13,850 [run_pretraining.py:  558]:	worker_index: 3, step: 1742, cost: 7.234308, mlm loss: 7.234308, speed: 0.039175 steps/s, speed: 0.313397 samples/s, speed: 160.459343 tokens/s, learning rate: 1.741e-05, loss_scalings: 6871.948730, pp_loss: 7.135238
[INFO] 2021-07-12 19:07:13,850 [run_pretraining.py:  512]:	********exe.run_1742******* 
[INFO] 2021-07-12 19:07:14,854 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:14,855 [run_pretraining.py:  534]:	loss/total_loss, 7.8261308670043945, 1743
[INFO] 2021-07-12 19:07:14,855 [run_pretraining.py:  535]:	loss/mlm_loss, 7.8261308670043945, 1743
[INFO] 2021-07-12 19:07:14,855 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7419999494450167e-05, 1743
[INFO] 2021-07-12 19:07:14,855 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1743
[INFO] 2021-07-12 19:07:14,855 [run_pretraining.py:  558]:	worker_index: 3, step: 1743, cost: 7.826131, mlm loss: 7.826131, speed: 0.995353 steps/s, speed: 7.962822 samples/s, speed: 4076.964851 tokens/s, learning rate: 1.742e-05, loss_scalings: 6871.948730, pp_loss: 7.422401
[INFO] 2021-07-12 19:07:14,855 [run_pretraining.py:  512]:	********exe.run_1743******* 
[INFO] 2021-07-12 19:07:15,808 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:15,809 [run_pretraining.py:  534]:	loss/total_loss, 6.797547340393066, 1744
[INFO] 2021-07-12 19:07:15,809 [run_pretraining.py:  535]:	loss/mlm_loss, 6.797547340393066, 1744
[INFO] 2021-07-12 19:07:15,809 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7430000298190862e-05, 1744
[INFO] 2021-07-12 19:07:15,809 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1744
[INFO] 2021-07-12 19:07:15,809 [run_pretraining.py:  558]:	worker_index: 3, step: 1744, cost: 6.797547, mlm loss: 6.797547, speed: 1.048933 steps/s, speed: 8.391463 samples/s, speed: 4296.429156 tokens/s, learning rate: 1.743e-05, loss_scalings: 6871.948730, pp_loss: 7.061727
[INFO] 2021-07-12 19:07:15,809 [run_pretraining.py:  512]:	********exe.run_1744******* 
[INFO] 2021-07-12 19:07:16,776 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:16,776 [run_pretraining.py:  534]:	loss/total_loss, 7.472072601318359, 1745
[INFO] 2021-07-12 19:07:16,776 [run_pretraining.py:  535]:	loss/mlm_loss, 7.472072601318359, 1745
[INFO] 2021-07-12 19:07:16,776 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7439999282942154e-05, 1745
[INFO] 2021-07-12 19:07:16,777 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1745
[INFO] 2021-07-12 19:07:16,777 [run_pretraining.py:  558]:	worker_index: 3, step: 1745, cost: 7.472073, mlm loss: 7.472073, speed: 1.034402 steps/s, speed: 8.275217 samples/s, speed: 4236.911023 tokens/s, learning rate: 1.744e-05, loss_scalings: 6871.948730, pp_loss: 6.715703
[INFO] 2021-07-12 19:07:16,777 [run_pretraining.py:  512]:	********exe.run_1745******* 
[INFO] 2021-07-12 19:07:17,807 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:17,808 [run_pretraining.py:  534]:	loss/total_loss, 6.383594036102295, 1746
[INFO] 2021-07-12 19:07:17,808 [run_pretraining.py:  535]:	loss/mlm_loss, 6.383594036102295, 1746
[INFO] 2021-07-12 19:07:17,808 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.745000008668285e-05, 1746
[INFO] 2021-07-12 19:07:17,808 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1746
[INFO] 2021-07-12 19:07:17,808 [run_pretraining.py:  558]:	worker_index: 3, step: 1746, cost: 6.383594, mlm loss: 6.383594, speed: 0.970023 steps/s, speed: 7.760183 samples/s, speed: 3973.213488 tokens/s, learning rate: 1.745e-05, loss_scalings: 6871.948730, pp_loss: 7.416284
[INFO] 2021-07-12 19:07:17,808 [run_pretraining.py:  512]:	********exe.run_1746******* 
[INFO] 2021-07-12 19:07:18,747 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:18,748 [run_pretraining.py:  534]:	loss/total_loss, 6.735299587249756, 1747
[INFO] 2021-07-12 19:07:18,748 [run_pretraining.py:  535]:	loss/mlm_loss, 6.735299587249756, 1747
[INFO] 2021-07-12 19:07:18,748 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7460000890423544e-05, 1747
[INFO] 2021-07-12 19:07:18,748 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1747
[INFO] 2021-07-12 19:07:18,748 [run_pretraining.py:  558]:	worker_index: 3, step: 1747, cost: 6.735300, mlm loss: 6.735300, speed: 1.064423 steps/s, speed: 8.515385 samples/s, speed: 4359.877147 tokens/s, learning rate: 1.746e-05, loss_scalings: 6871.948730, pp_loss: 7.207221
[INFO] 2021-07-12 19:07:18,748 [run_pretraining.py:  512]:	********exe.run_1747******* 
[INFO] 2021-07-12 19:07:19,684 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:19,685 [run_pretraining.py:  534]:	loss/total_loss, 7.394211292266846, 1748
[INFO] 2021-07-12 19:07:19,685 [run_pretraining.py:  535]:	loss/mlm_loss, 7.394211292266846, 1748
[INFO] 2021-07-12 19:07:19,685 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7469999875174835e-05, 1748
[INFO] 2021-07-12 19:07:19,685 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1748
[INFO] 2021-07-12 19:07:19,685 [run_pretraining.py:  558]:	worker_index: 3, step: 1748, cost: 7.394211, mlm loss: 7.394211, speed: 1.068200 steps/s, speed: 8.545601 samples/s, speed: 4375.347906 tokens/s, learning rate: 1.747e-05, loss_scalings: 6871.948730, pp_loss: 7.177110
[INFO] 2021-07-12 19:07:19,685 [run_pretraining.py:  512]:	********exe.run_1748******* 
[INFO] 2021-07-12 19:07:20,611 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:20,612 [run_pretraining.py:  534]:	loss/total_loss, 7.139127254486084, 1749
[INFO] 2021-07-12 19:07:20,612 [run_pretraining.py:  535]:	loss/mlm_loss, 7.139127254486084, 1749
[INFO] 2021-07-12 19:07:20,612 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7479998859926127e-05, 1749
[INFO] 2021-07-12 19:07:20,612 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1749
[INFO] 2021-07-12 19:07:20,612 [run_pretraining.py:  558]:	worker_index: 3, step: 1749, cost: 7.139127, mlm loss: 7.139127, speed: 1.079706 steps/s, speed: 8.637649 samples/s, speed: 4422.476128 tokens/s, learning rate: 1.748e-05, loss_scalings: 6871.948730, pp_loss: 7.156825
[INFO] 2021-07-12 19:07:20,612 [run_pretraining.py:  512]:	********exe.run_1749******* 
[INFO] 2021-07-12 19:07:21,551 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:21,551 [run_pretraining.py:  534]:	loss/total_loss, 7.046199798583984, 1750
[INFO] 2021-07-12 19:07:21,551 [run_pretraining.py:  535]:	loss/mlm_loss, 7.046199798583984, 1750
[INFO] 2021-07-12 19:07:21,552 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7489999663666822e-05, 1750
[INFO] 2021-07-12 19:07:21,552 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1750
[INFO] 2021-07-12 19:07:21,552 [run_pretraining.py:  558]:	worker_index: 3, step: 1750, cost: 7.046200, mlm loss: 7.046200, speed: 1.064769 steps/s, speed: 8.518154 samples/s, speed: 4361.294960 tokens/s, learning rate: 1.749e-05, loss_scalings: 6871.948730, pp_loss: 7.291958
[INFO] 2021-07-12 19:07:21,552 [run_pretraining.py:  512]:	********exe.run_1750******* 
[INFO] 2021-07-12 19:07:22,474 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:22,475 [run_pretraining.py:  534]:	loss/total_loss, 7.285622596740723, 1751
[INFO] 2021-07-12 19:07:22,475 [run_pretraining.py:  535]:	loss/mlm_loss, 7.285622596740723, 1751
[INFO] 2021-07-12 19:07:22,475 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7499998648418114e-05, 1751
[INFO] 2021-07-12 19:07:22,475 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1751
[INFO] 2021-07-12 19:07:22,475 [run_pretraining.py:  558]:	worker_index: 3, step: 1751, cost: 7.285623, mlm loss: 7.285623, speed: 1.083886 steps/s, speed: 8.671090 samples/s, speed: 4439.598310 tokens/s, learning rate: 1.750e-05, loss_scalings: 6871.948730, pp_loss: 7.375864
[INFO] 2021-07-12 19:07:22,475 [run_pretraining.py:  512]:	********exe.run_1751******* 
[INFO] 2021-07-12 19:07:23,401 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:23,402 [run_pretraining.py:  534]:	loss/total_loss, 7.973804950714111, 1752
[INFO] 2021-07-12 19:07:23,402 [run_pretraining.py:  535]:	loss/mlm_loss, 7.973804950714111, 1752
[INFO] 2021-07-12 19:07:23,402 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.750999945215881e-05, 1752
[INFO] 2021-07-12 19:07:23,402 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1752
[INFO] 2021-07-12 19:07:23,402 [run_pretraining.py:  558]:	worker_index: 3, step: 1752, cost: 7.973805, mlm loss: 7.973805, speed: 1.079264 steps/s, speed: 8.634113 samples/s, speed: 4420.665607 tokens/s, learning rate: 1.751e-05, loss_scalings: 6871.948730, pp_loss: 7.568124
[INFO] 2021-07-12 19:07:23,402 [run_pretraining.py:  512]:	********exe.run_1752******* 
[INFO] 2021-07-12 19:07:24,341 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:24,342 [run_pretraining.py:  534]:	loss/total_loss, 7.173580169677734, 1753
[INFO] 2021-07-12 19:07:24,342 [run_pretraining.py:  535]:	loss/mlm_loss, 7.173580169677734, 1753
[INFO] 2021-07-12 19:07:24,342 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7520000255899504e-05, 1753
[INFO] 2021-07-12 19:07:24,342 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1753
[INFO] 2021-07-12 19:07:24,342 [run_pretraining.py:  558]:	worker_index: 3, step: 1753, cost: 7.173580, mlm loss: 7.173580, speed: 1.064573 steps/s, speed: 8.516580 samples/s, speed: 4360.489095 tokens/s, learning rate: 1.752e-05, loss_scalings: 6871.948730, pp_loss: 7.258728
[INFO] 2021-07-12 19:07:24,342 [run_pretraining.py:  512]:	********exe.run_1753******* 
[INFO] 2021-07-12 19:07:25,276 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:25,277 [run_pretraining.py:  534]:	loss/total_loss, 7.750280857086182, 1754
[INFO] 2021-07-12 19:07:25,277 [run_pretraining.py:  535]:	loss/mlm_loss, 7.750280857086182, 1754
[INFO] 2021-07-12 19:07:25,277 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7529999240650795e-05, 1754
[INFO] 2021-07-12 19:07:25,277 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1754
[INFO] 2021-07-12 19:07:25,277 [run_pretraining.py:  558]:	worker_index: 3, step: 1754, cost: 7.750281, mlm loss: 7.750281, speed: 1.070161 steps/s, speed: 8.561289 samples/s, speed: 4383.380072 tokens/s, learning rate: 1.753e-05, loss_scalings: 6871.948730, pp_loss: 6.565172
[INFO] 2021-07-12 19:07:25,277 [run_pretraining.py:  512]:	********exe.run_1754******* 
[INFO] 2021-07-12 19:07:26,211 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:26,212 [run_pretraining.py:  534]:	loss/total_loss, 8.321512222290039, 1755
[INFO] 2021-07-12 19:07:26,212 [run_pretraining.py:  535]:	loss/mlm_loss, 8.321512222290039, 1755
[INFO] 2021-07-12 19:07:26,212 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.754000004439149e-05, 1755
[INFO] 2021-07-12 19:07:26,212 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1755
[INFO] 2021-07-12 19:07:26,212 [run_pretraining.py:  558]:	worker_index: 3, step: 1755, cost: 8.321512, mlm loss: 8.321512, speed: 1.070481 steps/s, speed: 8.563848 samples/s, speed: 4384.690114 tokens/s, learning rate: 1.754e-05, loss_scalings: 6871.948730, pp_loss: 7.496861
[INFO] 2021-07-12 19:07:26,212 [run_pretraining.py:  512]:	********exe.run_1755******* 
[INFO] 2021-07-12 19:07:27,133 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:27,133 [run_pretraining.py:  534]:	loss/total_loss, 7.042386054992676, 1756
[INFO] 2021-07-12 19:07:27,133 [run_pretraining.py:  535]:	loss/mlm_loss, 7.042386054992676, 1756
[INFO] 2021-07-12 19:07:27,133 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7550000848132186e-05, 1756
[INFO] 2021-07-12 19:07:27,133 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1756
[INFO] 2021-07-12 19:07:27,133 [run_pretraining.py:  558]:	worker_index: 3, step: 1756, cost: 7.042386, mlm loss: 7.042386, speed: 1.085974 steps/s, speed: 8.687789 samples/s, speed: 4448.148175 tokens/s, learning rate: 1.755e-05, loss_scalings: 6871.948730, pp_loss: 7.487352
[INFO] 2021-07-12 19:07:27,133 [run_pretraining.py:  512]:	********exe.run_1756******* 
[INFO] 2021-07-12 19:07:28,068 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:28,068 [run_pretraining.py:  534]:	loss/total_loss, 7.135972023010254, 1757
[INFO] 2021-07-12 19:07:28,068 [run_pretraining.py:  535]:	loss/mlm_loss, 7.135972023010254, 1757
[INFO] 2021-07-12 19:07:28,068 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7559999832883477e-05, 1757
[INFO] 2021-07-12 19:07:28,068 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1757
[INFO] 2021-07-12 19:07:28,068 [run_pretraining.py:  558]:	worker_index: 3, step: 1757, cost: 7.135972, mlm loss: 7.135972, speed: 1.070269 steps/s, speed: 8.562154 samples/s, speed: 4383.823004 tokens/s, learning rate: 1.756e-05, loss_scalings: 6871.948730, pp_loss: 7.284061
[INFO] 2021-07-12 19:07:28,068 [run_pretraining.py:  512]:	********exe.run_1757******* 
[INFO] 2021-07-12 19:07:29,000 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:29,001 [run_pretraining.py:  534]:	loss/total_loss, 7.579136848449707, 1758
[INFO] 2021-07-12 19:07:29,001 [run_pretraining.py:  535]:	loss/mlm_loss, 7.579136848449707, 1758
[INFO] 2021-07-12 19:07:29,001 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.756999881763477e-05, 1758
[INFO] 2021-07-12 19:07:29,001 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1758
[INFO] 2021-07-12 19:07:29,001 [run_pretraining.py:  558]:	worker_index: 3, step: 1758, cost: 7.579137, mlm loss: 7.579137, speed: 1.072831 steps/s, speed: 8.582651 samples/s, speed: 4394.317318 tokens/s, learning rate: 1.757e-05, loss_scalings: 6871.948730, pp_loss: 7.271032
[INFO] 2021-07-12 19:07:29,001 [run_pretraining.py:  512]:	********exe.run_1758******* 
[INFO] 2021-07-12 19:07:29,926 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:29,927 [run_pretraining.py:  534]:	loss/total_loss, 7.603569984436035, 1759
[INFO] 2021-07-12 19:07:29,927 [run_pretraining.py:  535]:	loss/mlm_loss, 7.603569984436035, 1759
[INFO] 2021-07-12 19:07:29,927 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7579999621375464e-05, 1759
[INFO] 2021-07-12 19:07:29,927 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1759
[INFO] 2021-07-12 19:07:29,927 [run_pretraining.py:  558]:	worker_index: 3, step: 1759, cost: 7.603570, mlm loss: 7.603570, speed: 1.080787 steps/s, speed: 8.646293 samples/s, speed: 4426.902264 tokens/s, learning rate: 1.758e-05, loss_scalings: 6871.948730, pp_loss: 7.430636
[INFO] 2021-07-12 19:07:29,927 [run_pretraining.py:  512]:	********exe.run_1759******* 
[INFO] 2021-07-12 19:07:30,846 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:30,847 [run_pretraining.py:  534]:	loss/total_loss, 7.591550827026367, 1760
[INFO] 2021-07-12 19:07:30,847 [run_pretraining.py:  535]:	loss/mlm_loss, 7.591550827026367, 1760
[INFO] 2021-07-12 19:07:30,847 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7589998606126755e-05, 1760
[INFO] 2021-07-12 19:07:30,847 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1760
[INFO] 2021-07-12 19:07:30,847 [run_pretraining.py:  558]:	worker_index: 3, step: 1760, cost: 7.591551, mlm loss: 7.591551, speed: 1.087283 steps/s, speed: 8.698264 samples/s, speed: 4453.511181 tokens/s, learning rate: 1.759e-05, loss_scalings: 6871.948730, pp_loss: 7.356662
[INFO] 2021-07-12 19:07:30,847 [run_pretraining.py:  512]:	********exe.run_1760******* 
[INFO] 2021-07-12 19:07:31,829 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:31,830 [run_pretraining.py:  534]:	loss/total_loss, 7.832575798034668, 1761
[INFO] 2021-07-12 19:07:31,830 [run_pretraining.py:  535]:	loss/mlm_loss, 7.832575798034668, 1761
[INFO] 2021-07-12 19:07:31,830 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.759999940986745e-05, 1761
[INFO] 2021-07-12 19:07:31,830 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1761
[INFO] 2021-07-12 19:07:31,830 [run_pretraining.py:  558]:	worker_index: 3, step: 1761, cost: 7.832576, mlm loss: 7.832576, speed: 1.018049 steps/s, speed: 8.144392 samples/s, speed: 4169.928852 tokens/s, learning rate: 1.760e-05, loss_scalings: 6871.948730, pp_loss: 7.443201
[INFO] 2021-07-12 19:07:31,830 [run_pretraining.py:  512]:	********exe.run_1761******* 
[INFO] 2021-07-12 19:07:32,927 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:32,928 [run_pretraining.py:  534]:	loss/total_loss, 7.01970100402832, 1762
[INFO] 2021-07-12 19:07:32,928 [run_pretraining.py:  535]:	loss/mlm_loss, 7.01970100402832, 1762
[INFO] 2021-07-12 19:07:32,928 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7610000213608146e-05, 1762
[INFO] 2021-07-12 19:07:32,928 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1762
[INFO] 2021-07-12 19:07:32,928 [run_pretraining.py:  558]:	worker_index: 3, step: 1762, cost: 7.019701, mlm loss: 7.019701, speed: 0.911426 steps/s, speed: 7.291409 samples/s, speed: 3733.201645 tokens/s, learning rate: 1.761e-05, loss_scalings: 6871.948730, pp_loss: 7.224170
[INFO] 2021-07-12 19:07:32,928 [run_pretraining.py:  512]:	********exe.run_1762******* 
[INFO] 2021-07-12 19:07:34,018 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:34,019 [run_pretraining.py:  534]:	loss/total_loss, 6.976315975189209, 1763
[INFO] 2021-07-12 19:07:34,019 [run_pretraining.py:  535]:	loss/mlm_loss, 6.976315975189209, 1763
[INFO] 2021-07-12 19:07:34,019 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7619999198359437e-05, 1763
[INFO] 2021-07-12 19:07:34,019 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1763
[INFO] 2021-07-12 19:07:34,019 [run_pretraining.py:  558]:	worker_index: 3, step: 1763, cost: 6.976316, mlm loss: 6.976316, speed: 0.917245 steps/s, speed: 7.337959 samples/s, speed: 3757.035022 tokens/s, learning rate: 1.762e-05, loss_scalings: 6871.948730, pp_loss: 6.661971
[INFO] 2021-07-12 19:07:34,019 [run_pretraining.py:  512]:	********exe.run_1763******* 
[INFO] 2021-07-12 19:07:35,116 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:35,117 [run_pretraining.py:  534]:	loss/total_loss, 7.280220031738281, 1764
[INFO] 2021-07-12 19:07:35,117 [run_pretraining.py:  535]:	loss/mlm_loss, 7.280220031738281, 1764
[INFO] 2021-07-12 19:07:35,117 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7630000002100132e-05, 1764
[INFO] 2021-07-12 19:07:35,117 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1764
[INFO] 2021-07-12 19:07:35,117 [run_pretraining.py:  558]:	worker_index: 3, step: 1764, cost: 7.280220, mlm loss: 7.280220, speed: 0.911213 steps/s, speed: 7.289707 samples/s, speed: 3732.329779 tokens/s, learning rate: 1.763e-05, loss_scalings: 6871.948730, pp_loss: 7.116410
[INFO] 2021-07-12 19:07:35,117 [run_pretraining.py:  512]:	********exe.run_1764******* 
[INFO] 2021-07-12 19:07:36,129 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:36,130 [run_pretraining.py:  534]:	loss/total_loss, 7.242776393890381, 1765
[INFO] 2021-07-12 19:07:36,130 [run_pretraining.py:  535]:	loss/mlm_loss, 7.242776393890381, 1765
[INFO] 2021-07-12 19:07:36,130 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7640000805840828e-05, 1765
[INFO] 2021-07-12 19:07:36,130 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1765
[INFO] 2021-07-12 19:07:36,130 [run_pretraining.py:  558]:	worker_index: 3, step: 1765, cost: 7.242776, mlm loss: 7.242776, speed: 0.987881 steps/s, speed: 7.903051 samples/s, speed: 4046.361858 tokens/s, learning rate: 1.764e-05, loss_scalings: 6871.948730, pp_loss: 7.109808
[INFO] 2021-07-12 19:07:36,130 [run_pretraining.py:  512]:	********exe.run_1765******* 
[INFO] 2021-07-12 19:07:37,045 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:37,046 [run_pretraining.py:  534]:	loss/total_loss, 7.804970741271973, 1766
[INFO] 2021-07-12 19:07:37,046 [run_pretraining.py:  535]:	loss/mlm_loss, 7.804970741271973, 1766
[INFO] 2021-07-12 19:07:37,046 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7649997971602716e-05, 1766
[INFO] 2021-07-12 19:07:37,046 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1766
[INFO] 2021-07-12 19:07:37,046 [run_pretraining.py:  558]:	worker_index: 3, step: 1766, cost: 7.804971, mlm loss: 7.804971, speed: 1.092119 steps/s, speed: 8.736952 samples/s, speed: 4473.319670 tokens/s, learning rate: 1.765e-05, loss_scalings: 6871.948730, pp_loss: 7.213474
[INFO] 2021-07-12 19:07:37,046 [run_pretraining.py:  512]:	********exe.run_1766******* 
[INFO] 2021-07-12 19:08:03,479 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:03,479 [run_pretraining.py:  534]:	loss/total_loss, 8.594664573669434, 1767
[INFO] 2021-07-12 19:08:03,480 [run_pretraining.py:  535]:	loss/mlm_loss, 8.594664573669434, 1767
[INFO] 2021-07-12 19:08:03,480 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.765999877534341e-05, 1767
[INFO] 2021-07-12 19:08:03,480 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1767
[INFO] 2021-07-12 19:08:03,480 [run_pretraining.py:  558]:	worker_index: 3, step: 1767, cost: 8.594665, mlm loss: 8.594665, speed: 0.037832 steps/s, speed: 0.302652 samples/s, speed: 154.957868 tokens/s, learning rate: 1.766e-05, loss_scalings: 6871.948730, pp_loss: 7.548715
[INFO] 2021-07-12 19:08:03,480 [run_pretraining.py:  512]:	********exe.run_1767******* 
[INFO] 2021-07-12 19:08:04,435 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:04,435 [run_pretraining.py:  534]:	loss/total_loss, 8.60951042175293, 1768
[INFO] 2021-07-12 19:08:04,435 [run_pretraining.py:  535]:	loss/mlm_loss, 8.60951042175293, 1768
[INFO] 2021-07-12 19:08:04,436 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7669999579084106e-05, 1768
[INFO] 2021-07-12 19:08:04,436 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1768
[INFO] 2021-07-12 19:08:04,436 [run_pretraining.py:  558]:	worker_index: 3, step: 1768, cost: 8.609510, mlm loss: 8.609510, speed: 1.046847 steps/s, speed: 8.374773 samples/s, speed: 4287.883712 tokens/s, learning rate: 1.767e-05, loss_scalings: 6871.948730, pp_loss: 7.561178
[INFO] 2021-07-12 19:08:04,436 [run_pretraining.py:  512]:	********exe.run_1768******* 
[INFO] 2021-07-12 19:08:05,392 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:05,392 [run_pretraining.py:  534]:	loss/total_loss, 4.593883991241455, 1769
[INFO] 2021-07-12 19:08:05,392 [run_pretraining.py:  535]:	loss/mlm_loss, 4.593883991241455, 1769
[INFO] 2021-07-12 19:08:05,392 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7679998563835397e-05, 1769
[INFO] 2021-07-12 19:08:05,393 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1769
[INFO] 2021-07-12 19:08:05,393 [run_pretraining.py:  558]:	worker_index: 3, step: 1769, cost: 4.593884, mlm loss: 4.593884, speed: 1.045756 steps/s, speed: 8.366047 samples/s, speed: 4283.415994 tokens/s, learning rate: 1.768e-05, loss_scalings: 6871.948730, pp_loss: 6.657411
[INFO] 2021-07-12 19:08:05,393 [run_pretraining.py:  512]:	********exe.run_1769******* 
[INFO] 2021-07-12 19:08:06,348 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:06,348 [run_pretraining.py:  534]:	loss/total_loss, 6.824341297149658, 1770
[INFO] 2021-07-12 19:08:06,349 [run_pretraining.py:  535]:	loss/mlm_loss, 6.824341297149658, 1770
[INFO] 2021-07-12 19:08:06,349 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7689999367576092e-05, 1770
[INFO] 2021-07-12 19:08:06,349 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1770
[INFO] 2021-07-12 19:08:06,349 [run_pretraining.py:  558]:	worker_index: 3, step: 1770, cost: 6.824341, mlm loss: 6.824341, speed: 1.046607 steps/s, speed: 8.372854 samples/s, speed: 4286.901491 tokens/s, learning rate: 1.769e-05, loss_scalings: 6871.948730, pp_loss: 7.212861
[INFO] 2021-07-12 19:08:06,349 [run_pretraining.py:  512]:	********exe.run_1770******* 
[INFO] 2021-07-12 19:08:07,307 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:07,307 [run_pretraining.py:  534]:	loss/total_loss, 6.817460536956787, 1771
[INFO] 2021-07-12 19:08:07,307 [run_pretraining.py:  535]:	loss/mlm_loss, 6.817460536956787, 1771
[INFO] 2021-07-12 19:08:07,308 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7700000171316788e-05, 1771
[INFO] 2021-07-12 19:08:07,308 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1771
[INFO] 2021-07-12 19:08:07,308 [run_pretraining.py:  558]:	worker_index: 3, step: 1771, cost: 6.817461, mlm loss: 6.817461, speed: 1.043568 steps/s, speed: 8.348543 samples/s, speed: 4274.454190 tokens/s, learning rate: 1.770e-05, loss_scalings: 6871.948730, pp_loss: 6.960914
[INFO] 2021-07-12 19:08:07,308 [run_pretraining.py:  512]:	********exe.run_1771******* 
[INFO] 2021-07-12 19:08:08,267 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:08,268 [run_pretraining.py:  534]:	loss/total_loss, 7.039779186248779, 1772
[INFO] 2021-07-12 19:08:08,268 [run_pretraining.py:  535]:	loss/mlm_loss, 7.039779186248779, 1772
[INFO] 2021-07-12 19:08:08,268 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.770999915606808e-05, 1772
[INFO] 2021-07-12 19:08:08,268 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1772
[INFO] 2021-07-12 19:08:08,268 [run_pretraining.py:  558]:	worker_index: 3, step: 1772, cost: 7.039779, mlm loss: 7.039779, speed: 1.042141 steps/s, speed: 8.337126 samples/s, speed: 4268.608638 tokens/s, learning rate: 1.771e-05, loss_scalings: 6871.948730, pp_loss: 7.407210
[INFO] 2021-07-12 19:08:08,268 [run_pretraining.py:  512]:	********exe.run_1772******* 
[INFO] 2021-07-12 19:08:09,212 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:09,213 [run_pretraining.py:  534]:	loss/total_loss, 7.624338150024414, 1773
[INFO] 2021-07-12 19:08:09,213 [run_pretraining.py:  535]:	loss/mlm_loss, 7.624338150024414, 1773
[INFO] 2021-07-12 19:08:09,213 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7719999959808774e-05, 1773
[INFO] 2021-07-12 19:08:09,213 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1773
[INFO] 2021-07-12 19:08:09,213 [run_pretraining.py:  558]:	worker_index: 3, step: 1773, cost: 7.624338, mlm loss: 7.624338, speed: 1.058639 steps/s, speed: 8.469109 samples/s, speed: 4336.183807 tokens/s, learning rate: 1.772e-05, loss_scalings: 6871.948730, pp_loss: 7.426006
[INFO] 2021-07-12 19:08:09,213 [run_pretraining.py:  512]:	********exe.run_1773******* 
[INFO] 2021-07-12 19:08:10,144 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:10,144 [run_pretraining.py:  534]:	loss/total_loss, 7.464659214019775, 1774
[INFO] 2021-07-12 19:08:10,144 [run_pretraining.py:  535]:	loss/mlm_loss, 7.464659214019775, 1774
[INFO] 2021-07-12 19:08:10,144 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.773000076354947e-05, 1774
[INFO] 2021-07-12 19:08:10,144 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1774
[INFO] 2021-07-12 19:08:10,145 [run_pretraining.py:  558]:	worker_index: 3, step: 1774, cost: 7.464659, mlm loss: 7.464659, speed: 1.074452 steps/s, speed: 8.595616 samples/s, speed: 4400.955507 tokens/s, learning rate: 1.773e-05, loss_scalings: 6871.948730, pp_loss: 7.480917
[INFO] 2021-07-12 19:08:10,145 [run_pretraining.py:  512]:	********exe.run_1774******* 
[INFO] 2021-07-12 19:08:11,082 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:11,082 [run_pretraining.py:  534]:	loss/total_loss, 7.177616119384766, 1775
[INFO] 2021-07-12 19:08:11,082 [run_pretraining.py:  535]:	loss/mlm_loss, 7.177616119384766, 1775
[INFO] 2021-07-12 19:08:11,082 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.773999974830076e-05, 1775
[INFO] 2021-07-12 19:08:11,082 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1775
[INFO] 2021-07-12 19:08:11,083 [run_pretraining.py:  558]:	worker_index: 3, step: 1775, cost: 7.177616, mlm loss: 7.177616, speed: 1.066774 steps/s, speed: 8.534188 samples/s, speed: 4369.504488 tokens/s, learning rate: 1.774e-05, loss_scalings: 6871.948730, pp_loss: 7.103539
[INFO] 2021-07-12 19:08:11,083 [run_pretraining.py:  512]:	********exe.run_1775******* 
[INFO] 2021-07-12 19:08:12,031 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:12,031 [run_pretraining.py:  534]:	loss/total_loss, 8.105015754699707, 1776
[INFO] 2021-07-12 19:08:12,031 [run_pretraining.py:  535]:	loss/mlm_loss, 8.105015754699707, 1776
[INFO] 2021-07-12 19:08:12,031 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7749998733052053e-05, 1776
[INFO] 2021-07-12 19:08:12,031 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1776
[INFO] 2021-07-12 19:08:12,031 [run_pretraining.py:  558]:	worker_index: 3, step: 1776, cost: 8.105016, mlm loss: 8.105016, speed: 1.054645 steps/s, speed: 8.437162 samples/s, speed: 4319.826819 tokens/s, learning rate: 1.775e-05, loss_scalings: 6871.948730, pp_loss: 7.493347
[INFO] 2021-07-12 19:08:12,031 [run_pretraining.py:  512]:	********exe.run_1776******* 
[INFO] 2021-07-12 19:08:12,968 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:12,969 [run_pretraining.py:  534]:	loss/total_loss, 6.3872246742248535, 1777
[INFO] 2021-07-12 19:08:12,969 [run_pretraining.py:  535]:	loss/mlm_loss, 6.3872246742248535, 1777
[INFO] 2021-07-12 19:08:12,969 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7759999536792748e-05, 1777
[INFO] 2021-07-12 19:08:12,969 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1777
[INFO] 2021-07-12 19:08:12,969 [run_pretraining.py:  558]:	worker_index: 3, step: 1777, cost: 6.387225, mlm loss: 6.387225, speed: 1.066859 steps/s, speed: 8.534870 samples/s, speed: 4369.853475 tokens/s, learning rate: 1.776e-05, loss_scalings: 6871.948730, pp_loss: 7.041745
[INFO] 2021-07-12 19:08:12,969 [run_pretraining.py:  512]:	********exe.run_1777******* 
[INFO] 2021-07-12 19:08:13,942 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:13,948 [run_pretraining.py:  534]:	loss/total_loss, 7.200762748718262, 1778
[INFO] 2021-07-12 19:08:13,953 [run_pretraining.py:  535]:	loss/mlm_loss, 7.200762748718262, 1778
[INFO] 2021-07-12 19:08:13,958 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.776999852154404e-05, 1778
[INFO] 2021-07-12 19:08:13,963 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1778
[INFO] 2021-07-12 19:08:13,968 [run_pretraining.py:  558]:	worker_index: 3, step: 1778, cost: 7.200763, mlm loss: 7.200763, speed: 1.022498 steps/s, speed: 8.179982 samples/s, speed: 4188.150609 tokens/s, learning rate: 1.777e-05, loss_scalings: 6871.948730, pp_loss: 7.409738
[INFO] 2021-07-12 19:08:13,975 [run_pretraining.py:  512]:	********exe.run_1778******* 
[INFO] 2021-07-12 19:08:14,902 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:14,903 [run_pretraining.py:  534]:	loss/total_loss, 7.194390773773193, 1779
[INFO] 2021-07-12 19:08:14,903 [run_pretraining.py:  535]:	loss/mlm_loss, 7.194390773773193, 1779
[INFO] 2021-07-12 19:08:14,903 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7779999325284734e-05, 1779
[INFO] 2021-07-12 19:08:14,903 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1779
[INFO] 2021-07-12 19:08:14,903 [run_pretraining.py:  558]:	worker_index: 3, step: 1779, cost: 7.194391, mlm loss: 7.194391, speed: 1.078268 steps/s, speed: 8.626144 samples/s, speed: 4416.585713 tokens/s, learning rate: 1.778e-05, loss_scalings: 6871.948730, pp_loss: 7.360394
[INFO] 2021-07-12 19:08:14,903 [run_pretraining.py:  512]:	********exe.run_1779******* 
[INFO] 2021-07-12 19:08:15,915 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:15,916 [run_pretraining.py:  534]:	loss/total_loss, 8.039932250976562, 1780
[INFO] 2021-07-12 19:08:15,916 [run_pretraining.py:  535]:	loss/mlm_loss, 8.039932250976562, 1780
[INFO] 2021-07-12 19:08:15,916 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.779000012902543e-05, 1780
[INFO] 2021-07-12 19:08:15,916 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1780
[INFO] 2021-07-12 19:08:15,916 [run_pretraining.py:  558]:	worker_index: 3, step: 1780, cost: 8.039932, mlm loss: 8.039932, speed: 0.987973 steps/s, speed: 7.903784 samples/s, speed: 4046.737389 tokens/s, learning rate: 1.779e-05, loss_scalings: 6871.948730, pp_loss: 7.496918
[INFO] 2021-07-12 19:08:15,916 [run_pretraining.py:  512]:	********exe.run_1780******* 
[INFO] 2021-07-12 19:08:16,990 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:16,990 [run_pretraining.py:  534]:	loss/total_loss, 6.903691291809082, 1781
[INFO] 2021-07-12 19:08:16,990 [run_pretraining.py:  535]:	loss/mlm_loss, 6.903691291809082, 1781
[INFO] 2021-07-12 19:08:16,990 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.779999911377672e-05, 1781
[INFO] 2021-07-12 19:08:16,990 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1781
[INFO] 2021-07-12 19:08:16,990 [run_pretraining.py:  558]:	worker_index: 3, step: 1781, cost: 6.903691, mlm loss: 6.903691, speed: 0.931137 steps/s, speed: 7.449095 samples/s, speed: 3813.936466 tokens/s, learning rate: 1.780e-05, loss_scalings: 6871.948730, pp_loss: 7.332294
[INFO] 2021-07-12 19:08:16,991 [run_pretraining.py:  512]:	********exe.run_1781******* 
[INFO] 2021-07-12 19:08:18,060 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:18,060 [run_pretraining.py:  534]:	loss/total_loss, 6.89966344833374, 1782
[INFO] 2021-07-12 19:08:18,060 [run_pretraining.py:  535]:	loss/mlm_loss, 6.89966344833374, 1782
[INFO] 2021-07-12 19:08:18,061 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7809999917517416e-05, 1782
[INFO] 2021-07-12 19:08:18,061 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1782
[INFO] 2021-07-12 19:08:18,061 [run_pretraining.py:  558]:	worker_index: 3, step: 1782, cost: 6.899663, mlm loss: 6.899663, speed: 0.934931 steps/s, speed: 7.479449 samples/s, speed: 3829.477973 tokens/s, learning rate: 1.781e-05, loss_scalings: 6871.948730, pp_loss: 6.520819
[INFO] 2021-07-12 19:08:18,061 [run_pretraining.py:  512]:	********exe.run_1782******* 
[INFO] 2021-07-12 19:08:19,132 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:19,133 [run_pretraining.py:  534]:	loss/total_loss, 7.4882426261901855, 1783
[INFO] 2021-07-12 19:08:19,133 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4882426261901855, 1783
[INFO] 2021-07-12 19:08:19,133 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.782000072125811e-05, 1783
[INFO] 2021-07-12 19:08:19,133 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1783
[INFO] 2021-07-12 19:08:19,133 [run_pretraining.py:  558]:	worker_index: 3, step: 1783, cost: 7.488243, mlm loss: 7.488243, speed: 0.933091 steps/s, speed: 7.464732 samples/s, speed: 3821.942653 tokens/s, learning rate: 1.782e-05, loss_scalings: 6871.948730, pp_loss: 7.086134
[INFO] 2021-07-12 19:08:19,133 [run_pretraining.py:  512]:	********exe.run_1783******* 
[INFO] 2021-07-12 19:08:20,198 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:20,198 [run_pretraining.py:  534]:	loss/total_loss, 7.539222717285156, 1784
[INFO] 2021-07-12 19:08:20,199 [run_pretraining.py:  535]:	loss/mlm_loss, 7.539222717285156, 1784
[INFO] 2021-07-12 19:08:20,199 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7829999706009403e-05, 1784
[INFO] 2021-07-12 19:08:20,199 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1784
[INFO] 2021-07-12 19:08:20,199 [run_pretraining.py:  558]:	worker_index: 3, step: 1784, cost: 7.539223, mlm loss: 7.539223, speed: 0.938902 steps/s, speed: 7.511217 samples/s, speed: 3845.743154 tokens/s, learning rate: 1.783e-05, loss_scalings: 6871.948730, pp_loss: 7.310082
[INFO] 2021-07-12 19:08:20,199 [run_pretraining.py:  512]:	********exe.run_1784******* 
[INFO] 2021-07-12 19:08:21,279 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:21,280 [run_pretraining.py:  534]:	loss/total_loss, 6.693772315979004, 1785
[INFO] 2021-07-12 19:08:21,280 [run_pretraining.py:  535]:	loss/mlm_loss, 6.693772315979004, 1785
[INFO] 2021-07-12 19:08:21,280 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7839998690760694e-05, 1785
[INFO] 2021-07-12 19:08:21,280 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1785
[INFO] 2021-07-12 19:08:21,280 [run_pretraining.py:  558]:	worker_index: 3, step: 1785, cost: 6.693772, mlm loss: 6.693772, speed: 0.925317 steps/s, speed: 7.402535 samples/s, speed: 3790.097838 tokens/s, learning rate: 1.784e-05, loss_scalings: 6871.948730, pp_loss: 7.107281
[INFO] 2021-07-12 19:08:21,280 [run_pretraining.py:  512]:	********exe.run_1785******* 
[INFO] 2021-07-12 19:08:22,386 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:22,387 [run_pretraining.py:  534]:	loss/total_loss, 7.710304260253906, 1786
[INFO] 2021-07-12 19:08:22,387 [run_pretraining.py:  535]:	loss/mlm_loss, 7.710304260253906, 1786
[INFO] 2021-07-12 19:08:22,387 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.784999949450139e-05, 1786
[INFO] 2021-07-12 19:08:22,387 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1786
[INFO] 2021-07-12 19:08:22,387 [run_pretraining.py:  558]:	worker_index: 3, step: 1786, cost: 7.710304, mlm loss: 7.710304, speed: 0.903796 steps/s, speed: 7.230370 samples/s, speed: 3701.949267 tokens/s, learning rate: 1.785e-05, loss_scalings: 6871.948730, pp_loss: 7.401123
[INFO] 2021-07-12 19:08:22,387 [run_pretraining.py:  512]:	********exe.run_1786******* 
[INFO] 2021-07-12 19:08:23,598 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:23,598 [run_pretraining.py:  534]:	loss/total_loss, 6.930819034576416, 1787
[INFO] 2021-07-12 19:08:23,598 [run_pretraining.py:  535]:	loss/mlm_loss, 6.930819034576416, 1787
[INFO] 2021-07-12 19:08:23,598 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.785999847925268e-05, 1787
[INFO] 2021-07-12 19:08:23,599 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1787
[INFO] 2021-07-12 19:08:23,599 [run_pretraining.py:  558]:	worker_index: 3, step: 1787, cost: 6.930819, mlm loss: 6.930819, speed: 0.825927 steps/s, speed: 6.607417 samples/s, speed: 3382.997450 tokens/s, learning rate: 1.786e-05, loss_scalings: 6871.948730, pp_loss: 7.168111
[INFO] 2021-07-12 19:08:23,599 [run_pretraining.py:  512]:	********exe.run_1787******* 
[INFO] 2021-07-12 19:08:24,553 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:24,553 [run_pretraining.py:  534]:	loss/total_loss, 7.161385536193848, 1788
[INFO] 2021-07-12 19:08:24,553 [run_pretraining.py:  535]:	loss/mlm_loss, 7.161385536193848, 1788
[INFO] 2021-07-12 19:08:24,553 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7869999282993376e-05, 1788
[INFO] 2021-07-12 19:08:24,553 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1788
[INFO] 2021-07-12 19:08:24,553 [run_pretraining.py:  558]:	worker_index: 3, step: 1788, cost: 7.161386, mlm loss: 7.161386, speed: 1.047985 steps/s, speed: 8.383882 samples/s, speed: 4292.547372 tokens/s, learning rate: 1.787e-05, loss_scalings: 6871.948730, pp_loss: 7.475592
[INFO] 2021-07-12 19:08:24,554 [run_pretraining.py:  512]:	********exe.run_1788******* 
[INFO] 2021-07-12 19:08:25,542 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:25,543 [run_pretraining.py:  534]:	loss/total_loss, 7.222963333129883, 1789
[INFO] 2021-07-12 19:08:25,543 [run_pretraining.py:  535]:	loss/mlm_loss, 7.222963333129883, 1789
[INFO] 2021-07-12 19:08:25,543 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.788000008673407e-05, 1789
[INFO] 2021-07-12 19:08:25,543 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1789
[INFO] 2021-07-12 19:08:25,543 [run_pretraining.py:  558]:	worker_index: 3, step: 1789, cost: 7.222963, mlm loss: 7.222963, speed: 1.011409 steps/s, speed: 8.091274 samples/s, speed: 4142.732243 tokens/s, learning rate: 1.788e-05, loss_scalings: 6871.948730, pp_loss: 7.209699
[INFO] 2021-07-12 19:08:25,543 [run_pretraining.py:  512]:	********exe.run_1789******* 
[INFO] 2021-07-12 19:08:26,466 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:26,467 [run_pretraining.py:  534]:	loss/total_loss, 6.941083908081055, 1790
[INFO] 2021-07-12 19:08:26,467 [run_pretraining.py:  535]:	loss/mlm_loss, 6.941083908081055, 1790
[INFO] 2021-07-12 19:08:26,467 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7889999071485363e-05, 1790
[INFO] 2021-07-12 19:08:26,467 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1790
[INFO] 2021-07-12 19:08:26,467 [run_pretraining.py:  558]:	worker_index: 3, step: 1790, cost: 6.941084, mlm loss: 6.941084, speed: 1.082567 steps/s, speed: 8.660536 samples/s, speed: 4434.194347 tokens/s, learning rate: 1.789e-05, loss_scalings: 6871.948730, pp_loss: 6.972397
[INFO] 2021-07-12 19:08:26,467 [run_pretraining.py:  512]:	********exe.run_1790******* 
[INFO] 2021-07-12 19:08:27,414 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:27,414 [run_pretraining.py:  534]:	loss/total_loss, 7.446632385253906, 1791
[INFO] 2021-07-12 19:08:27,414 [run_pretraining.py:  535]:	loss/mlm_loss, 7.446632385253906, 1791
[INFO] 2021-07-12 19:08:27,414 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7899999875226058e-05, 1791
[INFO] 2021-07-12 19:08:27,414 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1791
[INFO] 2021-07-12 19:08:27,415 [run_pretraining.py:  558]:	worker_index: 3, step: 1791, cost: 7.446632, mlm loss: 7.446632, speed: 1.056333 steps/s, speed: 8.450668 samples/s, speed: 4326.741806 tokens/s, learning rate: 1.790e-05, loss_scalings: 6871.948730, pp_loss: 7.112908
[INFO] 2021-07-12 19:08:27,415 [run_pretraining.py:  512]:	********exe.run_1791******* 
[INFO] 2021-07-12 19:08:28,352 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:28,352 [run_pretraining.py:  534]:	loss/total_loss, 6.7671074867248535, 1792
[INFO] 2021-07-12 19:08:28,352 [run_pretraining.py:  535]:	loss/mlm_loss, 6.7671074867248535, 1792
[INFO] 2021-07-12 19:08:28,352 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7910000678966753e-05, 1792
[INFO] 2021-07-12 19:08:28,352 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1792
[INFO] 2021-07-12 19:08:28,352 [run_pretraining.py:  558]:	worker_index: 3, step: 1792, cost: 6.767107, mlm loss: 6.767107, speed: 1.066919 steps/s, speed: 8.535352 samples/s, speed: 4370.100244 tokens/s, learning rate: 1.791e-05, loss_scalings: 6871.948730, pp_loss: 7.340908
[INFO] 2021-07-12 19:08:28,353 [run_pretraining.py:  512]:	********exe.run_1792******* 
[INFO] 2021-07-12 19:08:29,293 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:29,293 [run_pretraining.py:  534]:	loss/total_loss, 7.104660987854004, 1793
[INFO] 2021-07-12 19:08:29,293 [run_pretraining.py:  535]:	loss/mlm_loss, 7.104660987854004, 1793
[INFO] 2021-07-12 19:08:29,293 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7919999663718045e-05, 1793
[INFO] 2021-07-12 19:08:29,293 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1793
[INFO] 2021-07-12 19:08:29,293 [run_pretraining.py:  558]:	worker_index: 3, step: 1793, cost: 7.104661, mlm loss: 7.104661, speed: 1.063566 steps/s, speed: 8.508529 samples/s, speed: 4356.367022 tokens/s, learning rate: 1.792e-05, loss_scalings: 6871.948730, pp_loss: 7.704300
[INFO] 2021-07-12 19:08:29,293 [run_pretraining.py:  512]:	********exe.run_1793******* 
[INFO] 2021-07-12 19:08:30,245 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:30,246 [run_pretraining.py:  534]:	loss/total_loss, 8.010354995727539, 1794
[INFO] 2021-07-12 19:08:30,246 [run_pretraining.py:  535]:	loss/mlm_loss, 8.010354995727539, 1794
[INFO] 2021-07-12 19:08:30,246 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7929998648469336e-05, 1794
[INFO] 2021-07-12 19:08:30,246 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1794
[INFO] 2021-07-12 19:08:30,246 [run_pretraining.py:  558]:	worker_index: 3, step: 1794, cost: 8.010355, mlm loss: 8.010355, speed: 1.050365 steps/s, speed: 8.402918 samples/s, speed: 4302.294103 tokens/s, learning rate: 1.793e-05, loss_scalings: 6871.948730, pp_loss: 7.619518
[INFO] 2021-07-12 19:08:30,246 [run_pretraining.py:  512]:	********exe.run_1794******* 
[INFO] 2021-07-12 19:08:31,206 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:31,207 [run_pretraining.py:  534]:	loss/total_loss, 7.056392669677734, 1795
[INFO] 2021-07-12 19:08:31,207 [run_pretraining.py:  535]:	loss/mlm_loss, 7.056392669677734, 1795
[INFO] 2021-07-12 19:08:31,207 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.793999945221003e-05, 1795
[INFO] 2021-07-12 19:08:31,207 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1795
[INFO] 2021-07-12 19:08:31,207 [run_pretraining.py:  558]:	worker_index: 3, step: 1795, cost: 7.056393, mlm loss: 7.056393, speed: 1.041107 steps/s, speed: 8.328857 samples/s, speed: 4264.374672 tokens/s, learning rate: 1.794e-05, loss_scalings: 6871.948730, pp_loss: 7.190647
[INFO] 2021-07-12 19:08:31,207 [run_pretraining.py:  512]:	********exe.run_1795******* 
[INFO] 2021-07-12 19:08:32,156 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:32,156 [run_pretraining.py:  534]:	loss/total_loss, 7.604228973388672, 1796
[INFO] 2021-07-12 19:08:32,156 [run_pretraining.py:  535]:	loss/mlm_loss, 7.604228973388672, 1796
[INFO] 2021-07-12 19:08:32,156 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7950000255950727e-05, 1796
[INFO] 2021-07-12 19:08:32,157 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1796
[INFO] 2021-07-12 19:08:32,157 [run_pretraining.py:  558]:	worker_index: 3, step: 1796, cost: 7.604229, mlm loss: 7.604229, speed: 1.054035 steps/s, speed: 8.432283 samples/s, speed: 4317.328901 tokens/s, learning rate: 1.795e-05, loss_scalings: 6871.948730, pp_loss: 7.490405
[INFO] 2021-07-12 19:08:32,157 [run_pretraining.py:  512]:	********exe.run_1796******* 
[INFO] 2021-07-12 19:08:33,104 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:33,105 [run_pretraining.py:  534]:	loss/total_loss, 7.745943069458008, 1797
[INFO] 2021-07-12 19:08:33,105 [run_pretraining.py:  535]:	loss/mlm_loss, 7.745943069458008, 1797
[INFO] 2021-07-12 19:08:33,105 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7959999240702018e-05, 1797
[INFO] 2021-07-12 19:08:33,105 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1797
[INFO] 2021-07-12 19:08:33,105 [run_pretraining.py:  558]:	worker_index: 3, step: 1797, cost: 7.745943, mlm loss: 7.745943, speed: 1.054920 steps/s, speed: 8.439360 samples/s, speed: 4320.952424 tokens/s, learning rate: 1.796e-05, loss_scalings: 6871.948730, pp_loss: 7.766918
[INFO] 2021-07-12 19:08:33,105 [run_pretraining.py:  512]:	********exe.run_1797******* 
[INFO] 2021-07-12 19:08:34,048 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:34,049 [run_pretraining.py:  534]:	loss/total_loss, 7.441075325012207, 1798
[INFO] 2021-07-12 19:08:34,049 [run_pretraining.py:  535]:	loss/mlm_loss, 7.441075325012207, 1798
[INFO] 2021-07-12 19:08:34,049 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7970000044442713e-05, 1798
[INFO] 2021-07-12 19:08:34,049 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1798
[INFO] 2021-07-12 19:08:34,049 [run_pretraining.py:  558]:	worker_index: 3, step: 1798, cost: 7.441075, mlm loss: 7.441075, speed: 1.060333 steps/s, speed: 8.482662 samples/s, speed: 4343.122755 tokens/s, learning rate: 1.797e-05, loss_scalings: 6871.948730, pp_loss: 7.160560
[INFO] 2021-07-12 19:08:34,049 [run_pretraining.py:  512]:	********exe.run_1798******* 
[INFO] 2021-07-12 19:08:34,986 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:34,986 [run_pretraining.py:  534]:	loss/total_loss, 7.829213619232178, 1799
[INFO] 2021-07-12 19:08:34,986 [run_pretraining.py:  535]:	loss/mlm_loss, 7.829213619232178, 1799
[INFO] 2021-07-12 19:08:34,986 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7979999029194005e-05, 1799
[INFO] 2021-07-12 19:08:34,986 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1799
[INFO] 2021-07-12 19:08:34,986 [run_pretraining.py:  558]:	worker_index: 3, step: 1799, cost: 7.829214, mlm loss: 7.829214, speed: 1.067346 steps/s, speed: 8.538769 samples/s, speed: 4371.849549 tokens/s, learning rate: 1.798e-05, loss_scalings: 6871.948730, pp_loss: 7.623685
[INFO] 2021-07-12 19:08:34,987 [run_pretraining.py:  512]:	********exe.run_1799******* 
[INFO] 2021-07-12 19:08:35,926 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:35,926 [run_pretraining.py:  534]:	loss/total_loss, 7.1954264640808105, 1800
[INFO] 2021-07-12 19:08:35,926 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1954264640808105, 1800
[INFO] 2021-07-12 19:08:35,926 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.79899998329347e-05, 1800
[INFO] 2021-07-12 19:08:35,926 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1800
[INFO] 2021-07-12 19:08:35,927 [run_pretraining.py:  558]:	worker_index: 3, step: 1800, cost: 7.195426, mlm loss: 7.195426, speed: 1.064493 steps/s, speed: 8.515947 samples/s, speed: 4360.164841 tokens/s, learning rate: 1.799e-05, loss_scalings: 6871.948730, pp_loss: 7.624218
[INFO] 2021-07-12 19:08:35,927 [run_pretraining.py:  512]:	********exe.run_1800******* 
[INFO] 2021-07-12 19:08:36,865 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:36,865 [run_pretraining.py:  534]:	loss/total_loss, 7.294346809387207, 1801
[INFO] 2021-07-12 19:08:36,865 [run_pretraining.py:  535]:	loss/mlm_loss, 7.294346809387207, 1801
[INFO] 2021-07-12 19:08:36,865 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8000000636675395e-05, 1801
[INFO] 2021-07-12 19:08:36,865 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1801
[INFO] 2021-07-12 19:08:36,865 [run_pretraining.py:  558]:	worker_index: 3, step: 1801, cost: 7.294347, mlm loss: 7.294347, speed: 1.065732 steps/s, speed: 8.525853 samples/s, speed: 4365.236694 tokens/s, learning rate: 1.800e-05, loss_scalings: 6871.948730, pp_loss: 7.329344
[INFO] 2021-07-12 19:08:36,866 [run_pretraining.py:  512]:	********exe.run_1801******* 
[INFO] 2021-07-12 19:08:37,808 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:37,808 [run_pretraining.py:  534]:	loss/total_loss, 7.264866828918457, 1802
[INFO] 2021-07-12 19:08:37,808 [run_pretraining.py:  535]:	loss/mlm_loss, 7.264866828918457, 1802
[INFO] 2021-07-12 19:08:37,809 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8009999621426687e-05, 1802
[INFO] 2021-07-12 19:08:37,809 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1802
[INFO] 2021-07-12 19:08:37,809 [run_pretraining.py:  558]:	worker_index: 3, step: 1802, cost: 7.264867, mlm loss: 7.264867, speed: 1.060872 steps/s, speed: 8.486976 samples/s, speed: 4345.331865 tokens/s, learning rate: 1.801e-05, loss_scalings: 5497.559082, pp_loss: 7.232295
[INFO] 2021-07-12 19:08:37,809 [run_pretraining.py:  512]:	********exe.run_1802******* 
[INFO] 2021-07-12 19:08:38,758 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:38,759 [run_pretraining.py:  534]:	loss/total_loss, 7.362423896789551, 1803
[INFO] 2021-07-12 19:08:38,759 [run_pretraining.py:  535]:	loss/mlm_loss, 7.362423896789551, 1803
[INFO] 2021-07-12 19:08:38,759 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8019998606177978e-05, 1803
[INFO] 2021-07-12 19:08:38,759 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1803
[INFO] 2021-07-12 19:08:38,759 [run_pretraining.py:  558]:	worker_index: 3, step: 1803, cost: 7.362424, mlm loss: 7.362424, speed: 1.052678 steps/s, speed: 8.421426 samples/s, speed: 4311.770265 tokens/s, learning rate: 1.802e-05, loss_scalings: 5497.559082, pp_loss: 7.359658
[INFO] 2021-07-12 19:08:38,759 [run_pretraining.py:  512]:	********exe.run_1803******* 
[INFO] 2021-07-12 19:08:39,700 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:39,701 [run_pretraining.py:  534]:	loss/total_loss, 7.522912979125977, 1804
[INFO] 2021-07-12 19:08:39,701 [run_pretraining.py:  535]:	loss/mlm_loss, 7.522912979125977, 1804
[INFO] 2021-07-12 19:08:39,701 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8029999409918673e-05, 1804
[INFO] 2021-07-12 19:08:39,701 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1804
[INFO] 2021-07-12 19:08:39,701 [run_pretraining.py:  558]:	worker_index: 3, step: 1804, cost: 7.522913, mlm loss: 7.522913, speed: 1.062632 steps/s, speed: 8.501056 samples/s, speed: 4352.540526 tokens/s, learning rate: 1.803e-05, loss_scalings: 5497.559082, pp_loss: 7.373069
[INFO] 2021-07-12 19:08:39,701 [run_pretraining.py:  512]:	********exe.run_1804******* 
[INFO] 2021-07-12 19:08:40,644 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:40,644 [run_pretraining.py:  534]:	loss/total_loss, 7.6749491691589355, 1805
[INFO] 2021-07-12 19:08:40,644 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6749491691589355, 1805
[INFO] 2021-07-12 19:08:40,645 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.804000021365937e-05, 1805
[INFO] 2021-07-12 19:08:40,645 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1805
[INFO] 2021-07-12 19:08:40,645 [run_pretraining.py:  558]:	worker_index: 3, step: 1805, cost: 7.674949, mlm loss: 7.674949, speed: 1.060461 steps/s, speed: 8.483691 samples/s, speed: 4343.649837 tokens/s, learning rate: 1.804e-05, loss_scalings: 5497.559082, pp_loss: 7.470930
[INFO] 2021-07-12 19:08:40,645 [run_pretraining.py:  512]:	********exe.run_1805******* 
[INFO] 2021-07-12 19:08:41,575 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:41,575 [run_pretraining.py:  534]:	loss/total_loss, 8.1386137008667, 1806
[INFO] 2021-07-12 19:08:41,576 [run_pretraining.py:  535]:	loss/mlm_loss, 8.1386137008667, 1806
[INFO] 2021-07-12 19:08:41,576 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.804999919841066e-05, 1806
[INFO] 2021-07-12 19:08:41,576 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1806
[INFO] 2021-07-12 19:08:41,576 [run_pretraining.py:  558]:	worker_index: 3, step: 1806, cost: 8.138614, mlm loss: 8.138614, speed: 1.074796 steps/s, speed: 8.598372 samples/s, speed: 4402.366324 tokens/s, learning rate: 1.805e-05, loss_scalings: 5497.559082, pp_loss: 7.501697
[INFO] 2021-07-12 19:08:41,576 [run_pretraining.py:  512]:	********exe.run_1806******* 
[INFO] 2021-07-12 19:08:42,516 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:42,516 [run_pretraining.py:  534]:	loss/total_loss, 7.405920028686523, 1807
[INFO] 2021-07-12 19:08:42,516 [run_pretraining.py:  535]:	loss/mlm_loss, 7.405920028686523, 1807
[INFO] 2021-07-12 19:08:42,517 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8060000002151355e-05, 1807
[INFO] 2021-07-12 19:08:42,517 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1807
[INFO] 2021-07-12 19:08:42,517 [run_pretraining.py:  558]:	worker_index: 3, step: 1807, cost: 7.405920, mlm loss: 7.405920, speed: 1.063479 steps/s, speed: 8.507833 samples/s, speed: 4356.010246 tokens/s, learning rate: 1.806e-05, loss_scalings: 5497.559082, pp_loss: 7.489084
[INFO] 2021-07-12 19:08:42,517 [run_pretraining.py:  512]:	********exe.run_1807******* 
[INFO] 2021-07-12 19:08:43,460 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:43,460 [run_pretraining.py:  534]:	loss/total_loss, 7.270617961883545, 1808
[INFO] 2021-07-12 19:08:43,461 [run_pretraining.py:  535]:	loss/mlm_loss, 7.270617961883545, 1808
[INFO] 2021-07-12 19:08:43,461 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.807000080589205e-05, 1808
[INFO] 2021-07-12 19:08:43,461 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1808
[INFO] 2021-07-12 19:08:43,461 [run_pretraining.py:  558]:	worker_index: 3, step: 1808, cost: 7.270618, mlm loss: 7.270618, speed: 1.059929 steps/s, speed: 8.479429 samples/s, speed: 4341.467671 tokens/s, learning rate: 1.807e-05, loss_scalings: 5497.559082, pp_loss: 7.432751
[INFO] 2021-07-12 19:08:43,461 [run_pretraining.py:  512]:	********exe.run_1808******* 
[INFO] 2021-07-12 19:08:44,369 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:44,369 [run_pretraining.py:  534]:	loss/total_loss, 7.226899147033691, 1809
[INFO] 2021-07-12 19:08:44,369 [run_pretraining.py:  535]:	loss/mlm_loss, 7.226899147033691, 1809
[INFO] 2021-07-12 19:08:44,370 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8079999790643342e-05, 1809
[INFO] 2021-07-12 19:08:44,370 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1809
[INFO] 2021-07-12 19:08:44,370 [run_pretraining.py:  558]:	worker_index: 3, step: 1809, cost: 7.226899, mlm loss: 7.226899, speed: 1.100946 steps/s, speed: 8.807564 samples/s, speed: 4509.472769 tokens/s, learning rate: 1.808e-05, loss_scalings: 5497.559082, pp_loss: 7.316133
[INFO] 2021-07-12 19:08:44,370 [run_pretraining.py:  512]:	********exe.run_1809******* 
[INFO] 2021-07-12 19:08:45,278 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:45,278 [run_pretraining.py:  534]:	loss/total_loss, 7.282546043395996, 1810
[INFO] 2021-07-12 19:08:45,278 [run_pretraining.py:  535]:	loss/mlm_loss, 7.282546043395996, 1810
[INFO] 2021-07-12 19:08:45,278 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8089998775394633e-05, 1810
[INFO] 2021-07-12 19:08:45,278 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1810
[INFO] 2021-07-12 19:08:45,278 [run_pretraining.py:  558]:	worker_index: 3, step: 1810, cost: 7.282546, mlm loss: 7.282546, speed: 1.101251 steps/s, speed: 8.810008 samples/s, speed: 4510.724259 tokens/s, learning rate: 1.809e-05, loss_scalings: 5497.559082, pp_loss: 6.561682
[INFO] 2021-07-12 19:08:45,278 [run_pretraining.py:  512]:	********exe.run_1810******* 
[INFO] 2021-07-12 19:08:46,331 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:46,331 [run_pretraining.py:  534]:	loss/total_loss, 7.551275253295898, 1811
[INFO] 2021-07-12 19:08:46,331 [run_pretraining.py:  535]:	loss/mlm_loss, 7.551275253295898, 1811
[INFO] 2021-07-12 19:08:46,331 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.809999957913533e-05, 1811
[INFO] 2021-07-12 19:08:46,332 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1811
[INFO] 2021-07-12 19:08:46,332 [run_pretraining.py:  558]:	worker_index: 3, step: 1811, cost: 7.551275, mlm loss: 7.551275, speed: 0.950080 steps/s, speed: 7.600638 samples/s, speed: 3891.526868 tokens/s, learning rate: 1.810e-05, loss_scalings: 5497.559082, pp_loss: 7.516537
[INFO] 2021-07-12 19:08:46,332 [run_pretraining.py:  512]:	********exe.run_1811******* 
[INFO] 2021-07-12 19:08:47,481 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:47,481 [run_pretraining.py:  534]:	loss/total_loss, 6.73195743560791, 1812
[INFO] 2021-07-12 19:08:47,481 [run_pretraining.py:  535]:	loss/mlm_loss, 6.73195743560791, 1812
[INFO] 2021-07-12 19:08:47,481 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.810999856388662e-05, 1812
[INFO] 2021-07-12 19:08:47,481 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1812
[INFO] 2021-07-12 19:08:47,481 [run_pretraining.py:  558]:	worker_index: 3, step: 1812, cost: 6.731957, mlm loss: 6.731957, speed: 0.870167 steps/s, speed: 6.961333 samples/s, speed: 3564.202435 tokens/s, learning rate: 1.811e-05, loss_scalings: 5497.559082, pp_loss: 7.617358
[INFO] 2021-07-12 19:08:47,482 [run_pretraining.py:  512]:	********exe.run_1812******* 
[INFO] 2021-07-12 19:08:48,722 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:48,723 [run_pretraining.py:  534]:	loss/total_loss, 7.269095420837402, 1813
[INFO] 2021-07-12 19:08:48,723 [run_pretraining.py:  535]:	loss/mlm_loss, 7.269095420837402, 1813
[INFO] 2021-07-12 19:08:48,723 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8119999367627315e-05, 1813
[INFO] 2021-07-12 19:08:48,723 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1813
[INFO] 2021-07-12 19:08:48,723 [run_pretraining.py:  558]:	worker_index: 3, step: 1813, cost: 7.269095, mlm loss: 7.269095, speed: 0.805714 steps/s, speed: 6.445715 samples/s, speed: 3300.206002 tokens/s, learning rate: 1.812e-05, loss_scalings: 5497.559082, pp_loss: 7.468903
[INFO] 2021-07-12 19:08:48,723 [run_pretraining.py:  512]:	********exe.run_1813******* 
[INFO] 2021-07-12 19:08:49,941 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:49,942 [run_pretraining.py:  534]:	loss/total_loss, 7.180793762207031, 1814
[INFO] 2021-07-12 19:08:49,942 [run_pretraining.py:  535]:	loss/mlm_loss, 7.180793762207031, 1814
[INFO] 2021-07-12 19:08:49,942 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.813000017136801e-05, 1814
[INFO] 2021-07-12 19:08:49,942 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1814
[INFO] 2021-07-12 19:08:49,942 [run_pretraining.py:  558]:	worker_index: 3, step: 1814, cost: 7.180794, mlm loss: 7.180794, speed: 0.820820 steps/s, speed: 6.566561 samples/s, speed: 3362.079367 tokens/s, learning rate: 1.813e-05, loss_scalings: 5497.559082, pp_loss: 7.008798
[INFO] 2021-07-12 19:08:49,942 [run_pretraining.py:  512]:	********exe.run_1814******* 
[INFO] 2021-07-12 19:08:51,226 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:51,227 [run_pretraining.py:  534]:	loss/total_loss, 7.2438201904296875, 1815
[INFO] 2021-07-12 19:08:51,227 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2438201904296875, 1815
[INFO] 2021-07-12 19:08:51,227 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8139999156119302e-05, 1815
[INFO] 2021-07-12 19:08:51,227 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1815
[INFO] 2021-07-12 19:08:51,227 [run_pretraining.py:  558]:	worker_index: 3, step: 1815, cost: 7.243820, mlm loss: 7.243820, speed: 0.778530 steps/s, speed: 6.228238 samples/s, speed: 3188.857768 tokens/s, learning rate: 1.814e-05, loss_scalings: 5497.559082, pp_loss: 7.473609
[INFO] 2021-07-12 19:08:51,227 [run_pretraining.py:  512]:	********exe.run_1815******* 
[INFO] 2021-07-12 19:08:52,506 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:52,506 [run_pretraining.py:  534]:	loss/total_loss, 7.081925392150879, 1816
[INFO] 2021-07-12 19:08:52,506 [run_pretraining.py:  535]:	loss/mlm_loss, 7.081925392150879, 1816
[INFO] 2021-07-12 19:08:52,506 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8149999959859997e-05, 1816
[INFO] 2021-07-12 19:08:52,506 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1816
[INFO] 2021-07-12 19:08:52,507 [run_pretraining.py:  558]:	worker_index: 3, step: 1816, cost: 7.081925, mlm loss: 7.081925, speed: 0.782053 steps/s, speed: 6.256424 samples/s, speed: 3203.288856 tokens/s, learning rate: 1.815e-05, loss_scalings: 5497.559082, pp_loss: 7.110937
[INFO] 2021-07-12 19:08:52,507 [run_pretraining.py:  512]:	********exe.run_1816******* 
[INFO] 2021-07-12 19:08:53,804 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:53,805 [run_pretraining.py:  534]:	loss/total_loss, 7.8520121574401855, 1817
[INFO] 2021-07-12 19:08:53,805 [run_pretraining.py:  535]:	loss/mlm_loss, 7.8520121574401855, 1817
[INFO] 2021-07-12 19:08:53,805 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8160000763600692e-05, 1817
[INFO] 2021-07-12 19:08:53,805 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1817
[INFO] 2021-07-12 19:08:53,805 [run_pretraining.py:  558]:	worker_index: 3, step: 1817, cost: 7.852012, mlm loss: 7.852012, speed: 0.770377 steps/s, speed: 6.163014 samples/s, speed: 3155.463251 tokens/s, learning rate: 1.816e-05, loss_scalings: 5497.559082, pp_loss: 7.536582
[INFO] 2021-07-12 19:08:53,805 [run_pretraining.py:  512]:	********exe.run_1817******* 
[INFO] 2021-07-12 19:08:55,080 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:55,080 [run_pretraining.py:  534]:	loss/total_loss, 7.458890914916992, 1818
[INFO] 2021-07-12 19:08:55,080 [run_pretraining.py:  535]:	loss/mlm_loss, 7.458890914916992, 1818
[INFO] 2021-07-12 19:08:55,080 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8169999748351984e-05, 1818
[INFO] 2021-07-12 19:08:55,080 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1818
[INFO] 2021-07-12 19:08:55,081 [run_pretraining.py:  558]:	worker_index: 3, step: 1818, cost: 7.458891, mlm loss: 7.458891, speed: 0.784546 steps/s, speed: 6.276370 samples/s, speed: 3213.501219 tokens/s, learning rate: 1.817e-05, loss_scalings: 5497.559082, pp_loss: 6.627621
[INFO] 2021-07-12 19:08:55,081 [run_pretraining.py:  512]:	********exe.run_1818******* 
[INFO] 2021-07-12 19:08:56,162 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:56,162 [run_pretraining.py:  534]:	loss/total_loss, 7.20775032043457, 1819
[INFO] 2021-07-12 19:08:56,162 [run_pretraining.py:  535]:	loss/mlm_loss, 7.20775032043457, 1819
[INFO] 2021-07-12 19:08:56,162 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8179998733103275e-05, 1819
[INFO] 2021-07-12 19:08:56,162 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1819
[INFO] 2021-07-12 19:08:56,162 [run_pretraining.py:  558]:	worker_index: 3, step: 1819, cost: 7.207750, mlm loss: 7.207750, speed: 0.924779 steps/s, speed: 7.398234 samples/s, speed: 3787.895879 tokens/s, learning rate: 1.818e-05, loss_scalings: 5497.559082, pp_loss: 6.690726
[INFO] 2021-07-12 19:08:56,163 [run_pretraining.py:  512]:	********exe.run_1819******* 
[INFO] 2021-07-12 19:08:57,223 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:57,223 [run_pretraining.py:  534]:	loss/total_loss, 7.272824764251709, 1820
[INFO] 2021-07-12 19:08:57,223 [run_pretraining.py:  535]:	loss/mlm_loss, 7.272824764251709, 1820
[INFO] 2021-07-12 19:08:57,223 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.818999953684397e-05, 1820
[INFO] 2021-07-12 19:08:57,223 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1820
[INFO] 2021-07-12 19:08:57,224 [run_pretraining.py:  558]:	worker_index: 3, step: 1820, cost: 7.272825, mlm loss: 7.272825, speed: 0.943056 steps/s, speed: 7.544452 samples/s, speed: 3862.759296 tokens/s, learning rate: 1.819e-05, loss_scalings: 5497.559082, pp_loss: 7.097352
[INFO] 2021-07-12 19:08:57,224 [run_pretraining.py:  512]:	********exe.run_1820******* 
[INFO] 2021-07-12 19:08:58,280 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:58,281 [run_pretraining.py:  534]:	loss/total_loss, 6.881153106689453, 1821
[INFO] 2021-07-12 19:08:58,281 [run_pretraining.py:  535]:	loss/mlm_loss, 6.881153106689453, 1821
[INFO] 2021-07-12 19:08:58,281 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8199998521595262e-05, 1821
[INFO] 2021-07-12 19:08:58,281 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1821
[INFO] 2021-07-12 19:08:58,281 [run_pretraining.py:  558]:	worker_index: 3, step: 1821, cost: 6.881153, mlm loss: 6.881153, speed: 0.946139 steps/s, speed: 7.569113 samples/s, speed: 3875.386032 tokens/s, learning rate: 1.820e-05, loss_scalings: 5497.559082, pp_loss: 7.317370
[INFO] 2021-07-12 19:08:58,281 [run_pretraining.py:  512]:	********exe.run_1821******* 
[INFO] 2021-07-12 19:08:59,343 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:59,344 [run_pretraining.py:  534]:	loss/total_loss, 7.708686828613281, 1822
[INFO] 2021-07-12 19:08:59,344 [run_pretraining.py:  535]:	loss/mlm_loss, 7.708686828613281, 1822
[INFO] 2021-07-12 19:08:59,344 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8209999325335957e-05, 1822
[INFO] 2021-07-12 19:08:59,344 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1822
[INFO] 2021-07-12 19:08:59,344 [run_pretraining.py:  558]:	worker_index: 3, step: 1822, cost: 7.708687, mlm loss: 7.708687, speed: 0.941429 steps/s, speed: 7.531435 samples/s, speed: 3856.094569 tokens/s, learning rate: 1.821e-05, loss_scalings: 5497.559082, pp_loss: 7.540801
[INFO] 2021-07-12 19:08:59,344 [run_pretraining.py:  512]:	********exe.run_1822******* 
[INFO] 2021-07-12 19:09:00,424 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:00,425 [run_pretraining.py:  534]:	loss/total_loss, 6.7964677810668945, 1823
[INFO] 2021-07-12 19:09:00,425 [run_pretraining.py:  535]:	loss/mlm_loss, 6.7964677810668945, 1823
[INFO] 2021-07-12 19:09:00,425 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8220000129076652e-05, 1823
[INFO] 2021-07-12 19:09:00,425 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1823
[INFO] 2021-07-12 19:09:00,425 [run_pretraining.py:  558]:	worker_index: 3, step: 1823, cost: 6.796468, mlm loss: 6.796468, speed: 0.925359 steps/s, speed: 7.402873 samples/s, speed: 3790.270928 tokens/s, learning rate: 1.822e-05, loss_scalings: 5497.559082, pp_loss: 7.099504
[INFO] 2021-07-12 19:09:00,425 [run_pretraining.py:  512]:	********exe.run_1823******* 
[INFO] 2021-07-12 19:09:01,501 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:01,502 [run_pretraining.py:  534]:	loss/total_loss, 7.450150489807129, 1824
[INFO] 2021-07-12 19:09:01,502 [run_pretraining.py:  535]:	loss/mlm_loss, 7.450150489807129, 1824
[INFO] 2021-07-12 19:09:01,502 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8229999113827944e-05, 1824
[INFO] 2021-07-12 19:09:01,502 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1824
[INFO] 2021-07-12 19:09:01,502 [run_pretraining.py:  558]:	worker_index: 3, step: 1824, cost: 7.450150, mlm loss: 7.450150, speed: 0.929295 steps/s, speed: 7.434361 samples/s, speed: 3806.392969 tokens/s, learning rate: 1.823e-05, loss_scalings: 5497.559082, pp_loss: 6.758618
[INFO] 2021-07-12 19:09:01,502 [run_pretraining.py:  512]:	********exe.run_1824******* 
[INFO] 2021-07-12 19:09:02,578 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:02,578 [run_pretraining.py:  534]:	loss/total_loss, 7.2954607009887695, 1825
[INFO] 2021-07-12 19:09:02,578 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2954607009887695, 1825
[INFO] 2021-07-12 19:09:02,578 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.823999991756864e-05, 1825
[INFO] 2021-07-12 19:09:02,578 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1825
[INFO] 2021-07-12 19:09:02,578 [run_pretraining.py:  558]:	worker_index: 3, step: 1825, cost: 7.295461, mlm loss: 7.295461, speed: 0.929548 steps/s, speed: 7.436381 samples/s, speed: 3807.427195 tokens/s, learning rate: 1.824e-05, loss_scalings: 5497.559082, pp_loss: 7.350167
[INFO] 2021-07-12 19:09:02,578 [run_pretraining.py:  512]:	********exe.run_1825******* 
[INFO] 2021-07-12 19:09:03,732 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:03,733 [run_pretraining.py:  534]:	loss/total_loss, 6.984494209289551, 1826
[INFO] 2021-07-12 19:09:03,733 [run_pretraining.py:  535]:	loss/mlm_loss, 6.984494209289551, 1826
[INFO] 2021-07-12 19:09:03,733 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8250000721309334e-05, 1826
[INFO] 2021-07-12 19:09:03,733 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1826
[INFO] 2021-07-12 19:09:03,733 [run_pretraining.py:  558]:	worker_index: 3, step: 1826, cost: 6.984494, mlm loss: 6.984494, speed: 0.866313 steps/s, speed: 6.930506 samples/s, speed: 3548.418976 tokens/s, learning rate: 1.825e-05, loss_scalings: 5497.559082, pp_loss: 7.123259
[INFO] 2021-07-12 19:09:03,733 [run_pretraining.py:  512]:	********exe.run_1826******* 
[INFO] 2021-07-12 19:09:04,835 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:04,836 [run_pretraining.py:  534]:	loss/total_loss, 7.219316482543945, 1827
[INFO] 2021-07-12 19:09:04,836 [run_pretraining.py:  535]:	loss/mlm_loss, 7.219316482543945, 1827
[INFO] 2021-07-12 19:09:04,836 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8259999706060626e-05, 1827
[INFO] 2021-07-12 19:09:04,836 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1827
[INFO] 2021-07-12 19:09:04,836 [run_pretraining.py:  558]:	worker_index: 3, step: 1827, cost: 7.219316, mlm loss: 7.219316, speed: 0.907265 steps/s, speed: 7.258118 samples/s, speed: 3716.156423 tokens/s, learning rate: 1.826e-05, loss_scalings: 5497.559082, pp_loss: 7.107207
[INFO] 2021-07-12 19:09:04,836 [run_pretraining.py:  512]:	********exe.run_1827******* 
[INFO] 2021-07-12 19:09:05,930 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:05,931 [run_pretraining.py:  534]:	loss/total_loss, 7.580844402313232, 1828
[INFO] 2021-07-12 19:09:05,931 [run_pretraining.py:  535]:	loss/mlm_loss, 7.580844402313232, 1828
[INFO] 2021-07-12 19:09:05,931 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8269998690811917e-05, 1828
[INFO] 2021-07-12 19:09:05,931 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1828
[INFO] 2021-07-12 19:09:05,931 [run_pretraining.py:  558]:	worker_index: 3, step: 1828, cost: 7.580844, mlm loss: 7.580844, speed: 0.914045 steps/s, speed: 7.312362 samples/s, speed: 3743.929239 tokens/s, learning rate: 1.827e-05, loss_scalings: 5497.559082, pp_loss: 7.423597
[INFO] 2021-07-12 19:09:05,931 [run_pretraining.py:  512]:	********exe.run_1828******* 
[INFO] 2021-07-12 19:09:07,033 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:07,033 [run_pretraining.py:  534]:	loss/total_loss, 7.496770858764648, 1829
[INFO] 2021-07-12 19:09:07,033 [run_pretraining.py:  535]:	loss/mlm_loss, 7.496770858764648, 1829
[INFO] 2021-07-12 19:09:07,033 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8279999494552612e-05, 1829
[INFO] 2021-07-12 19:09:07,033 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1829
[INFO] 2021-07-12 19:09:07,033 [run_pretraining.py:  558]:	worker_index: 3, step: 1829, cost: 7.496771, mlm loss: 7.496771, speed: 0.907453 steps/s, speed: 7.259624 samples/s, speed: 3716.927463 tokens/s, learning rate: 1.828e-05, loss_scalings: 5497.559082, pp_loss: 7.006213
[INFO] 2021-07-12 19:09:07,034 [run_pretraining.py:  512]:	********exe.run_1829******* 
[INFO] 2021-07-12 19:09:08,126 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:08,126 [run_pretraining.py:  534]:	loss/total_loss, 5.952482223510742, 1830
[INFO] 2021-07-12 19:09:08,127 [run_pretraining.py:  535]:	loss/mlm_loss, 5.952482223510742, 1830
[INFO] 2021-07-12 19:09:08,127 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8289998479303904e-05, 1830
[INFO] 2021-07-12 19:09:08,127 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1830
[INFO] 2021-07-12 19:09:08,127 [run_pretraining.py:  558]:	worker_index: 3, step: 1830, cost: 5.952482, mlm loss: 5.952482, speed: 0.915191 steps/s, speed: 7.321525 samples/s, speed: 3748.620808 tokens/s, learning rate: 1.829e-05, loss_scalings: 5497.559082, pp_loss: 7.159586
[INFO] 2021-07-12 19:09:08,127 [run_pretraining.py:  512]:	********exe.run_1830******* 
[INFO] 2021-07-12 19:09:09,231 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:09,231 [run_pretraining.py:  534]:	loss/total_loss, 7.2483367919921875, 1831
[INFO] 2021-07-12 19:09:09,231 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2483367919921875, 1831
[INFO] 2021-07-12 19:09:09,231 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.82999992830446e-05, 1831
[INFO] 2021-07-12 19:09:09,231 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1831
[INFO] 2021-07-12 19:09:09,232 [run_pretraining.py:  558]:	worker_index: 3, step: 1831, cost: 7.248337, mlm loss: 7.248337, speed: 0.905751 steps/s, speed: 7.246007 samples/s, speed: 3709.955537 tokens/s, learning rate: 1.830e-05, loss_scalings: 5497.559082, pp_loss: 7.354254
[INFO] 2021-07-12 19:09:09,232 [run_pretraining.py:  512]:	********exe.run_1831******* 
[INFO] 2021-07-12 19:09:10,329 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:10,330 [run_pretraining.py:  534]:	loss/total_loss, 7.10175085067749, 1832
[INFO] 2021-07-12 19:09:10,330 [run_pretraining.py:  535]:	loss/mlm_loss, 7.10175085067749, 1832
[INFO] 2021-07-12 19:09:10,330 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8310000086785294e-05, 1832
[INFO] 2021-07-12 19:09:10,330 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1832
[INFO] 2021-07-12 19:09:10,330 [run_pretraining.py:  558]:	worker_index: 3, step: 1832, cost: 7.101751, mlm loss: 7.101751, speed: 0.910647 steps/s, speed: 7.285177 samples/s, speed: 3730.010570 tokens/s, learning rate: 1.831e-05, loss_scalings: 5497.559082, pp_loss: 7.253236
[INFO] 2021-07-12 19:09:10,330 [run_pretraining.py:  512]:	********exe.run_1832******* 
[INFO] 2021-07-12 19:09:11,426 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:11,427 [run_pretraining.py:  534]:	loss/total_loss, 7.686163902282715, 1833
[INFO] 2021-07-12 19:09:11,427 [run_pretraining.py:  535]:	loss/mlm_loss, 7.686163902282715, 1833
[INFO] 2021-07-12 19:09:11,427 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8319999071536586e-05, 1833
[INFO] 2021-07-12 19:09:11,427 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1833
[INFO] 2021-07-12 19:09:11,427 [run_pretraining.py:  558]:	worker_index: 3, step: 1833, cost: 7.686164, mlm loss: 7.686164, speed: 0.912081 steps/s, speed: 7.296650 samples/s, speed: 3735.884682 tokens/s, learning rate: 1.832e-05, loss_scalings: 5497.559082, pp_loss: 7.441794
[INFO] 2021-07-12 19:09:11,427 [run_pretraining.py:  512]:	********exe.run_1833******* 
[INFO] 2021-07-12 19:09:12,517 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:12,518 [run_pretraining.py:  534]:	loss/total_loss, 7.846986293792725, 1834
[INFO] 2021-07-12 19:09:12,518 [run_pretraining.py:  535]:	loss/mlm_loss, 7.846986293792725, 1834
[INFO] 2021-07-12 19:09:12,518 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.832999987527728e-05, 1834
[INFO] 2021-07-12 19:09:12,518 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1834
[INFO] 2021-07-12 19:09:12,518 [run_pretraining.py:  558]:	worker_index: 3, step: 1834, cost: 7.846986, mlm loss: 7.846986, speed: 0.917445 steps/s, speed: 7.339558 samples/s, speed: 3757.853533 tokens/s, learning rate: 1.833e-05, loss_scalings: 5497.559082, pp_loss: 7.382650
[INFO] 2021-07-12 19:09:12,518 [run_pretraining.py:  512]:	********exe.run_1834******* 
[INFO] 2021-07-12 19:09:13,613 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:13,613 [run_pretraining.py:  534]:	loss/total_loss, 7.719701290130615, 1835
[INFO] 2021-07-12 19:09:13,613 [run_pretraining.py:  535]:	loss/mlm_loss, 7.719701290130615, 1835
[INFO] 2021-07-12 19:09:13,613 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8340000679017976e-05, 1835
[INFO] 2021-07-12 19:09:13,613 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1835
[INFO] 2021-07-12 19:09:13,614 [run_pretraining.py:  558]:	worker_index: 3, step: 1835, cost: 7.719701, mlm loss: 7.719701, speed: 0.913213 steps/s, speed: 7.305702 samples/s, speed: 3740.519449 tokens/s, learning rate: 1.834e-05, loss_scalings: 5497.559082, pp_loss: 6.440587
[INFO] 2021-07-12 19:09:13,614 [run_pretraining.py:  512]:	********exe.run_1835******* 
[INFO] 2021-07-12 19:09:14,705 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:14,706 [run_pretraining.py:  534]:	loss/total_loss, 7.16889762878418, 1836
[INFO] 2021-07-12 19:09:14,706 [run_pretraining.py:  535]:	loss/mlm_loss, 7.16889762878418, 1836
[INFO] 2021-07-12 19:09:14,706 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8349999663769267e-05, 1836
[INFO] 2021-07-12 19:09:14,706 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1836
[INFO] 2021-07-12 19:09:14,706 [run_pretraining.py:  558]:	worker_index: 3, step: 1836, cost: 7.168898, mlm loss: 7.168898, speed: 0.915914 steps/s, speed: 7.327316 samples/s, speed: 3751.585741 tokens/s, learning rate: 1.835e-05, loss_scalings: 5497.559082, pp_loss: 7.422920
[INFO] 2021-07-12 19:09:14,706 [run_pretraining.py:  512]:	********exe.run_1836******* 
[INFO] 2021-07-12 19:09:15,792 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:15,792 [run_pretraining.py:  534]:	loss/total_loss, 7.429558753967285, 1837
[INFO] 2021-07-12 19:09:15,793 [run_pretraining.py:  535]:	loss/mlm_loss, 7.429558753967285, 1837
[INFO] 2021-07-12 19:09:15,793 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.835999864852056e-05, 1837
[INFO] 2021-07-12 19:09:15,793 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1837
[INFO] 2021-07-12 19:09:15,793 [run_pretraining.py:  558]:	worker_index: 3, step: 1837, cost: 7.429559, mlm loss: 7.429559, speed: 0.920679 steps/s, speed: 7.365428 samples/s, speed: 3771.099370 tokens/s, learning rate: 1.836e-05, loss_scalings: 5497.559082, pp_loss: 7.368634
[INFO] 2021-07-12 19:09:15,793 [run_pretraining.py:  512]:	********exe.run_1837******* 
[INFO] 2021-07-12 19:09:16,887 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:16,888 [run_pretraining.py:  534]:	loss/total_loss, 6.8659868240356445, 1838
[INFO] 2021-07-12 19:09:16,888 [run_pretraining.py:  535]:	loss/mlm_loss, 6.8659868240356445, 1838
[INFO] 2021-07-12 19:09:16,888 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8369999452261254e-05, 1838
[INFO] 2021-07-12 19:09:16,888 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1838
[INFO] 2021-07-12 19:09:16,888 [run_pretraining.py:  558]:	worker_index: 3, step: 1838, cost: 6.865987, mlm loss: 6.865987, speed: 0.913527 steps/s, speed: 7.308219 samples/s, speed: 3741.808293 tokens/s, learning rate: 1.837e-05, loss_scalings: 5497.559082, pp_loss: 6.953657
[INFO] 2021-07-12 19:09:16,888 [run_pretraining.py:  512]:	********exe.run_1838******* 
[INFO] 2021-07-12 19:09:17,983 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:17,984 [run_pretraining.py:  534]:	loss/total_loss, 3.9838414192199707, 1839
[INFO] 2021-07-12 19:09:17,984 [run_pretraining.py:  535]:	loss/mlm_loss, 3.9838414192199707, 1839
[INFO] 2021-07-12 19:09:17,984 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8379998437012546e-05, 1839
[INFO] 2021-07-12 19:09:17,984 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1839
[INFO] 2021-07-12 19:09:17,984 [run_pretraining.py:  558]:	worker_index: 3, step: 1839, cost: 3.983841, mlm loss: 3.983841, speed: 0.912740 steps/s, speed: 7.301920 samples/s, speed: 3738.582967 tokens/s, learning rate: 1.838e-05, loss_scalings: 5497.559082, pp_loss: 6.396317
[INFO] 2021-07-12 19:09:17,984 [run_pretraining.py:  512]:	********exe.run_1839******* 
[INFO] 2021-07-12 19:09:19,077 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:19,078 [run_pretraining.py:  534]:	loss/total_loss, 6.979391098022461, 1840
[INFO] 2021-07-12 19:09:19,078 [run_pretraining.py:  535]:	loss/mlm_loss, 6.979391098022461, 1840
[INFO] 2021-07-12 19:09:19,078 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.838999924075324e-05, 1840
[INFO] 2021-07-12 19:09:19,078 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1840
[INFO] 2021-07-12 19:09:19,078 [run_pretraining.py:  558]:	worker_index: 3, step: 1840, cost: 6.979391, mlm loss: 6.979391, speed: 0.914646 steps/s, speed: 7.317170 samples/s, speed: 3746.390786 tokens/s, learning rate: 1.839e-05, loss_scalings: 5497.559082, pp_loss: 6.270361
[INFO] 2021-07-12 19:09:19,078 [run_pretraining.py:  512]:	********exe.run_1840******* 
[INFO] 2021-07-12 19:09:20,171 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:20,171 [run_pretraining.py:  534]:	loss/total_loss, 7.044834136962891, 1841
[INFO] 2021-07-12 19:09:20,171 [run_pretraining.py:  535]:	loss/mlm_loss, 7.044834136962891, 1841
[INFO] 2021-07-12 19:09:20,171 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8400000044493936e-05, 1841
[INFO] 2021-07-12 19:09:20,171 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1841
[INFO] 2021-07-12 19:09:20,171 [run_pretraining.py:  558]:	worker_index: 3, step: 1841, cost: 7.044834, mlm loss: 7.044834, speed: 0.915366 steps/s, speed: 7.322925 samples/s, speed: 3749.337463 tokens/s, learning rate: 1.840e-05, loss_scalings: 5497.559082, pp_loss: 7.128225
[INFO] 2021-07-12 19:09:20,171 [run_pretraining.py:  512]:	********exe.run_1841******* 
[INFO] 2021-07-12 19:09:21,270 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:21,270 [run_pretraining.py:  534]:	loss/total_loss, 6.987220287322998, 1842
[INFO] 2021-07-12 19:09:21,270 [run_pretraining.py:  535]:	loss/mlm_loss, 6.987220287322998, 1842
[INFO] 2021-07-12 19:09:21,270 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8409999029245228e-05, 1842
[INFO] 2021-07-12 19:09:21,271 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1842
[INFO] 2021-07-12 19:09:21,271 [run_pretraining.py:  558]:	worker_index: 3, step: 1842, cost: 6.987220, mlm loss: 6.987220, speed: 0.910293 steps/s, speed: 7.282344 samples/s, speed: 3728.559898 tokens/s, learning rate: 1.841e-05, loss_scalings: 5497.559082, pp_loss: 7.210888
[INFO] 2021-07-12 19:09:21,271 [run_pretraining.py:  512]:	********exe.run_1842******* 
[INFO] 2021-07-12 19:09:22,412 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:22,412 [run_pretraining.py:  534]:	loss/total_loss, 4.780177116394043, 1843
[INFO] 2021-07-12 19:09:22,412 [run_pretraining.py:  535]:	loss/mlm_loss, 4.780177116394043, 1843
[INFO] 2021-07-12 19:09:22,413 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8419999832985923e-05, 1843
[INFO] 2021-07-12 19:09:22,413 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1843
[INFO] 2021-07-12 19:09:22,413 [run_pretraining.py:  558]:	worker_index: 3, step: 1843, cost: 4.780177, mlm loss: 4.780177, speed: 0.876038 steps/s, speed: 7.008302 samples/s, speed: 3588.250580 tokens/s, learning rate: 1.842e-05, loss_scalings: 5497.559082, pp_loss: 6.806059
[INFO] 2021-07-12 19:09:22,413 [run_pretraining.py:  512]:	********exe.run_1843******* 
[INFO] 2021-07-12 19:09:23,510 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:23,510 [run_pretraining.py:  534]:	loss/total_loss, 7.021137237548828, 1844
[INFO] 2021-07-12 19:09:23,510 [run_pretraining.py:  535]:	loss/mlm_loss, 7.021137237548828, 1844
[INFO] 2021-07-12 19:09:23,510 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8430000636726618e-05, 1844
[INFO] 2021-07-12 19:09:23,511 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1844
[INFO] 2021-07-12 19:09:23,511 [run_pretraining.py:  558]:	worker_index: 3, step: 1844, cost: 7.021137, mlm loss: 7.021137, speed: 0.911360 steps/s, speed: 7.290882 samples/s, speed: 3732.931526 tokens/s, learning rate: 1.843e-05, loss_scalings: 5497.559082, pp_loss: 6.843381
[INFO] 2021-07-12 19:09:23,511 [run_pretraining.py:  512]:	********exe.run_1844******* 
[INFO] 2021-07-12 19:09:24,688 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:24,688 [run_pretraining.py:  534]:	loss/total_loss, 7.311407566070557, 1845
[INFO] 2021-07-12 19:09:24,688 [run_pretraining.py:  535]:	loss/mlm_loss, 7.311407566070557, 1845
[INFO] 2021-07-12 19:09:24,689 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.843999962147791e-05, 1845
[INFO] 2021-07-12 19:09:24,689 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1845
[INFO] 2021-07-12 19:09:24,689 [run_pretraining.py:  558]:	worker_index: 3, step: 1845, cost: 7.311408, mlm loss: 7.311408, speed: 0.849312 steps/s, speed: 6.794495 samples/s, speed: 3478.781636 tokens/s, learning rate: 1.844e-05, loss_scalings: 5497.559082, pp_loss: 7.230316
[INFO] 2021-07-12 19:09:24,689 [run_pretraining.py:  512]:	********exe.run_1845******* 
[INFO] 2021-07-12 19:09:25,758 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:25,759 [run_pretraining.py:  534]:	loss/total_loss, 6.855630874633789, 1846
[INFO] 2021-07-12 19:09:25,759 [run_pretraining.py:  535]:	loss/mlm_loss, 6.855630874633789, 1846
[INFO] 2021-07-12 19:09:25,759 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.84499986062292e-05, 1846
[INFO] 2021-07-12 19:09:25,759 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1846
[INFO] 2021-07-12 19:09:25,759 [run_pretraining.py:  558]:	worker_index: 3, step: 1846, cost: 6.855631, mlm loss: 6.855631, speed: 0.934630 steps/s, speed: 7.477042 samples/s, speed: 3828.245757 tokens/s, learning rate: 1.845e-05, loss_scalings: 5497.559082, pp_loss: 7.006642
[INFO] 2021-07-12 19:09:25,759 [run_pretraining.py:  512]:	********exe.run_1846******* 
[INFO] 2021-07-12 19:09:26,817 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:26,818 [run_pretraining.py:  534]:	loss/total_loss, 4.32074499130249, 1847
[INFO] 2021-07-12 19:09:26,818 [run_pretraining.py:  535]:	loss/mlm_loss, 4.32074499130249, 1847
[INFO] 2021-07-12 19:09:26,818 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8459999409969896e-05, 1847
[INFO] 2021-07-12 19:09:26,818 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1847
[INFO] 2021-07-12 19:09:26,818 [run_pretraining.py:  558]:	worker_index: 3, step: 1847, cost: 4.320745, mlm loss: 4.320745, speed: 0.945037 steps/s, speed: 7.560295 samples/s, speed: 3870.870818 tokens/s, learning rate: 1.846e-05, loss_scalings: 5497.559082, pp_loss: 6.220063
[INFO] 2021-07-12 19:09:26,818 [run_pretraining.py:  512]:	********exe.run_1847******* 
[INFO] 2021-07-12 19:09:27,878 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:27,879 [run_pretraining.py:  534]:	loss/total_loss, 7.6453938484191895, 1848
[INFO] 2021-07-12 19:09:27,879 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6453938484191895, 1848
[INFO] 2021-07-12 19:09:27,879 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8469998394721188e-05, 1848
[INFO] 2021-07-12 19:09:27,879 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1848
[INFO] 2021-07-12 19:09:27,879 [run_pretraining.py:  558]:	worker_index: 3, step: 1848, cost: 7.645394, mlm loss: 7.645394, speed: 0.943251 steps/s, speed: 7.546006 samples/s, speed: 3863.555016 tokens/s, learning rate: 1.847e-05, loss_scalings: 5497.559082, pp_loss: 7.356521
[INFO] 2021-07-12 19:09:27,879 [run_pretraining.py:  512]:	********exe.run_1848******* 
[INFO] 2021-07-12 19:09:28,937 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:28,937 [run_pretraining.py:  534]:	loss/total_loss, 8.112678527832031, 1849
[INFO] 2021-07-12 19:09:28,937 [run_pretraining.py:  535]:	loss/mlm_loss, 8.112678527832031, 1849
[INFO] 2021-07-12 19:09:28,937 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8479999198461883e-05, 1849
[INFO] 2021-07-12 19:09:28,938 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1849
[INFO] 2021-07-12 19:09:28,938 [run_pretraining.py:  558]:	worker_index: 3, step: 1849, cost: 8.112679, mlm loss: 8.112679, speed: 0.945076 steps/s, speed: 7.560610 samples/s, speed: 3871.032175 tokens/s, learning rate: 1.848e-05, loss_scalings: 5497.559082, pp_loss: 7.502945
[INFO] 2021-07-12 19:09:28,938 [run_pretraining.py:  512]:	********exe.run_1849******* 
[INFO] 2021-07-12 19:09:29,998 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:29,998 [run_pretraining.py:  534]:	loss/total_loss, 7.3976359367370605, 1850
[INFO] 2021-07-12 19:09:29,998 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3976359367370605, 1850
[INFO] 2021-07-12 19:09:29,999 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8490000002202578e-05, 1850
[INFO] 2021-07-12 19:09:29,999 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1850
[INFO] 2021-07-12 19:09:29,999 [run_pretraining.py:  558]:	worker_index: 3, step: 1850, cost: 7.397636, mlm loss: 7.397636, speed: 0.942988 steps/s, speed: 7.543900 samples/s, speed: 3862.477050 tokens/s, learning rate: 1.849e-05, loss_scalings: 5497.559082, pp_loss: 7.397432
[INFO] 2021-07-12 19:09:29,999 [run_pretraining.py:  512]:	********exe.run_1850******* 
[INFO] 2021-07-12 19:09:31,191 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:31,191 [run_pretraining.py:  534]:	loss/total_loss, 7.212969779968262, 1851
[INFO] 2021-07-12 19:09:31,191 [run_pretraining.py:  535]:	loss/mlm_loss, 7.212969779968262, 1851
[INFO] 2021-07-12 19:09:31,191 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.849999898695387e-05, 1851
[INFO] 2021-07-12 19:09:31,191 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1851
[INFO] 2021-07-12 19:09:31,192 [run_pretraining.py:  558]:	worker_index: 3, step: 1851, cost: 7.212970, mlm loss: 7.212970, speed: 0.838827 steps/s, speed: 6.710617 samples/s, speed: 3435.835716 tokens/s, learning rate: 1.850e-05, loss_scalings: 5497.559082, pp_loss: 7.548081
[INFO] 2021-07-12 19:09:31,192 [run_pretraining.py:  512]:	********exe.run_1851******* 
[INFO] 2021-07-12 19:09:32,347 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:32,347 [run_pretraining.py:  534]:	loss/total_loss, 8.297457695007324, 1852
[INFO] 2021-07-12 19:09:32,347 [run_pretraining.py:  535]:	loss/mlm_loss, 8.297457695007324, 1852
[INFO] 2021-07-12 19:09:32,348 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8509999790694565e-05, 1852
[INFO] 2021-07-12 19:09:32,348 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1852
[INFO] 2021-07-12 19:09:32,348 [run_pretraining.py:  558]:	worker_index: 3, step: 1852, cost: 8.297458, mlm loss: 8.297458, speed: 0.865425 steps/s, speed: 6.923400 samples/s, speed: 3544.780886 tokens/s, learning rate: 1.851e-05, loss_scalings: 5497.559082, pp_loss: 7.950684
[INFO] 2021-07-12 19:09:32,348 [run_pretraining.py:  512]:	********exe.run_1852******* 
[INFO] 2021-07-12 19:09:33,528 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:33,528 [run_pretraining.py:  534]:	loss/total_loss, 7.768872261047363, 1853
[INFO] 2021-07-12 19:09:33,528 [run_pretraining.py:  535]:	loss/mlm_loss, 7.768872261047363, 1853
[INFO] 2021-07-12 19:09:33,528 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.852000059443526e-05, 1853
[INFO] 2021-07-12 19:09:33,528 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1853
[INFO] 2021-07-12 19:09:33,528 [run_pretraining.py:  558]:	worker_index: 3, step: 1853, cost: 7.768872, mlm loss: 7.768872, speed: 0.847378 steps/s, speed: 6.779026 samples/s, speed: 3470.861549 tokens/s, learning rate: 1.852e-05, loss_scalings: 5497.559082, pp_loss: 7.486721
[INFO] 2021-07-12 19:09:33,528 [run_pretraining.py:  512]:	********exe.run_1853******* 
[INFO] 2021-07-12 19:09:34,713 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:34,713 [run_pretraining.py:  534]:	loss/total_loss, 6.9514007568359375, 1854
[INFO] 2021-07-12 19:09:34,713 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9514007568359375, 1854
[INFO] 2021-07-12 19:09:34,714 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.852999957918655e-05, 1854
[INFO] 2021-07-12 19:09:34,714 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1854
[INFO] 2021-07-12 19:09:34,714 [run_pretraining.py:  558]:	worker_index: 3, step: 1854, cost: 6.951401, mlm loss: 6.951401, speed: 0.844129 steps/s, speed: 6.753029 samples/s, speed: 3457.551030 tokens/s, learning rate: 1.853e-05, loss_scalings: 5497.559082, pp_loss: 6.405672
[INFO] 2021-07-12 19:09:34,714 [run_pretraining.py:  512]:	********exe.run_1854******* 
[INFO] 2021-07-12 19:09:35,987 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:35,987 [run_pretraining.py:  534]:	loss/total_loss, 7.138505935668945, 1855
[INFO] 2021-07-12 19:09:35,987 [run_pretraining.py:  535]:	loss/mlm_loss, 7.138505935668945, 1855
[INFO] 2021-07-12 19:09:35,988 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8539998563937843e-05, 1855
[INFO] 2021-07-12 19:09:35,988 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1855
[INFO] 2021-07-12 19:09:35,988 [run_pretraining.py:  558]:	worker_index: 3, step: 1855, cost: 7.138506, mlm loss: 7.138506, speed: 0.785328 steps/s, speed: 6.282621 samples/s, speed: 3216.702186 tokens/s, learning rate: 1.854e-05, loss_scalings: 5497.559082, pp_loss: 7.506006
[INFO] 2021-07-12 19:09:35,988 [run_pretraining.py:  512]:	********exe.run_1855******* 
[INFO] 2021-07-12 19:09:37,171 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:37,172 [run_pretraining.py:  534]:	loss/total_loss, 7.27792501449585, 1856
[INFO] 2021-07-12 19:09:37,172 [run_pretraining.py:  535]:	loss/mlm_loss, 7.27792501449585, 1856
[INFO] 2021-07-12 19:09:37,172 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8549999367678538e-05, 1856
[INFO] 2021-07-12 19:09:37,172 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1856
[INFO] 2021-07-12 19:09:37,172 [run_pretraining.py:  558]:	worker_index: 3, step: 1856, cost: 7.277925, mlm loss: 7.277925, speed: 0.844593 steps/s, speed: 6.756744 samples/s, speed: 3459.453145 tokens/s, learning rate: 1.855e-05, loss_scalings: 5497.559082, pp_loss: 7.309104
[INFO] 2021-07-12 19:09:37,172 [run_pretraining.py:  512]:	********exe.run_1856******* 
[INFO] 2021-07-12 19:09:38,306 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:38,306 [run_pretraining.py:  534]:	loss/total_loss, 7.191627502441406, 1857
[INFO] 2021-07-12 19:09:38,306 [run_pretraining.py:  535]:	loss/mlm_loss, 7.191627502441406, 1857
[INFO] 2021-07-12 19:09:38,307 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8560000171419233e-05, 1857
[INFO] 2021-07-12 19:09:38,307 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1857
[INFO] 2021-07-12 19:09:38,307 [run_pretraining.py:  558]:	worker_index: 3, step: 1857, cost: 7.191628, mlm loss: 7.191628, speed: 0.882057 steps/s, speed: 7.056457 samples/s, speed: 3612.905781 tokens/s, learning rate: 1.856e-05, loss_scalings: 5497.559082, pp_loss: 7.189091
[INFO] 2021-07-12 19:09:38,307 [run_pretraining.py:  512]:	********exe.run_1857******* 
[INFO] 2021-07-12 19:09:39,508 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:39,514 [run_pretraining.py:  534]:	loss/total_loss, 7.105398654937744, 1858
[INFO] 2021-07-12 19:09:39,519 [run_pretraining.py:  535]:	loss/mlm_loss, 7.105398654937744, 1858
[INFO] 2021-07-12 19:09:39,523 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8569999156170525e-05, 1858
[INFO] 2021-07-12 19:09:39,523 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1858
[INFO] 2021-07-12 19:09:39,525 [run_pretraining.py:  558]:	worker_index: 3, step: 1858, cost: 7.105399, mlm loss: 7.105399, speed: 0.828616 steps/s, speed: 6.628925 samples/s, speed: 3394.009623 tokens/s, learning rate: 1.857e-05, loss_scalings: 5497.559082, pp_loss: 7.228557
[INFO] 2021-07-12 19:09:39,527 [run_pretraining.py:  512]:	********exe.run_1858******* 
[INFO] 2021-07-12 19:09:40,586 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:40,587 [run_pretraining.py:  534]:	loss/total_loss, 7.577515602111816, 1859
[INFO] 2021-07-12 19:09:40,587 [run_pretraining.py:  535]:	loss/mlm_loss, 7.577515602111816, 1859
[INFO] 2021-07-12 19:09:40,587 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.857999995991122e-05, 1859
[INFO] 2021-07-12 19:09:40,587 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1859
[INFO] 2021-07-12 19:09:40,587 [run_pretraining.py:  558]:	worker_index: 3, step: 1859, cost: 7.577516, mlm loss: 7.577516, speed: 0.943514 steps/s, speed: 7.548114 samples/s, speed: 3864.634453 tokens/s, learning rate: 1.858e-05, loss_scalings: 5497.559082, pp_loss: 7.299081
[INFO] 2021-07-12 19:09:40,587 [run_pretraining.py:  512]:	********exe.run_1859******* 
[INFO] 2021-07-12 19:09:41,644 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:41,645 [run_pretraining.py:  534]:	loss/total_loss, 7.294284343719482, 1860
[INFO] 2021-07-12 19:09:41,645 [run_pretraining.py:  535]:	loss/mlm_loss, 7.294284343719482, 1860
[INFO] 2021-07-12 19:09:41,645 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.858999894466251e-05, 1860
[INFO] 2021-07-12 19:09:41,645 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1860
[INFO] 2021-07-12 19:09:41,645 [run_pretraining.py:  558]:	worker_index: 3, step: 1860, cost: 7.294284, mlm loss: 7.294284, speed: 0.945653 steps/s, speed: 7.565222 samples/s, speed: 3873.393884 tokens/s, learning rate: 1.859e-05, loss_scalings: 5497.559082, pp_loss: 7.621275
[INFO] 2021-07-12 19:09:41,645 [run_pretraining.py:  512]:	********exe.run_1860******* 
[INFO] 2021-07-12 19:09:42,560 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:42,560 [run_pretraining.py:  534]:	loss/total_loss, 7.479842185974121, 1861
[INFO] 2021-07-12 19:09:42,560 [run_pretraining.py:  535]:	loss/mlm_loss, 7.479842185974121, 1861
[INFO] 2021-07-12 19:09:42,560 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8599999748403206e-05, 1861
[INFO] 2021-07-12 19:09:42,560 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1861
[INFO] 2021-07-12 19:09:42,561 [run_pretraining.py:  558]:	worker_index: 3, step: 1861, cost: 7.479842, mlm loss: 7.479842, speed: 1.092971 steps/s, speed: 8.743769 samples/s, speed: 4476.809710 tokens/s, learning rate: 1.860e-05, loss_scalings: 5497.559082, pp_loss: 6.243603
[INFO] 2021-07-12 19:09:42,561 [run_pretraining.py:  512]:	********exe.run_1861******* 
[INFO] 2021-07-12 19:09:43,472 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:43,473 [run_pretraining.py:  534]:	loss/total_loss, 6.85323429107666, 1862
[INFO] 2021-07-12 19:09:43,473 [run_pretraining.py:  535]:	loss/mlm_loss, 6.85323429107666, 1862
[INFO] 2021-07-12 19:09:43,473 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.86100005521439e-05, 1862
[INFO] 2021-07-12 19:09:43,473 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1862
[INFO] 2021-07-12 19:09:43,473 [run_pretraining.py:  558]:	worker_index: 3, step: 1862, cost: 6.853234, mlm loss: 6.853234, speed: 1.096758 steps/s, speed: 8.774064 samples/s, speed: 4492.320553 tokens/s, learning rate: 1.861e-05, loss_scalings: 5497.559082, pp_loss: 7.423204
[INFO] 2021-07-12 19:09:43,473 [run_pretraining.py:  512]:	********exe.run_1862******* 
[INFO] 2021-07-12 19:09:44,391 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:44,391 [run_pretraining.py:  534]:	loss/total_loss, 7.6881256103515625, 1863
[INFO] 2021-07-12 19:09:44,391 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6881256103515625, 1863
[INFO] 2021-07-12 19:09:44,392 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8619999536895193e-05, 1863
[INFO] 2021-07-12 19:09:44,392 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1863
[INFO] 2021-07-12 19:09:44,392 [run_pretraining.py:  558]:	worker_index: 3, step: 1863, cost: 7.688126, mlm loss: 7.688126, speed: 1.089254 steps/s, speed: 8.714036 samples/s, speed: 4461.586354 tokens/s, learning rate: 1.862e-05, loss_scalings: 5497.559082, pp_loss: 7.413347
[INFO] 2021-07-12 19:09:44,392 [run_pretraining.py:  512]:	********exe.run_1863******* 
[INFO] 2021-07-12 19:09:45,303 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:45,303 [run_pretraining.py:  534]:	loss/total_loss, 7.075131416320801, 1864
[INFO] 2021-07-12 19:09:45,303 [run_pretraining.py:  535]:	loss/mlm_loss, 7.075131416320801, 1864
[INFO] 2021-07-12 19:09:45,304 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8629998521646485e-05, 1864
[INFO] 2021-07-12 19:09:45,304 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1864
[INFO] 2021-07-12 19:09:45,304 [run_pretraining.py:  558]:	worker_index: 3, step: 1864, cost: 7.075131, mlm loss: 7.075131, speed: 1.097236 steps/s, speed: 8.777890 samples/s, speed: 4494.279608 tokens/s, learning rate: 1.863e-05, loss_scalings: 5497.559082, pp_loss: 6.936529
[INFO] 2021-07-12 19:09:45,304 [run_pretraining.py:  512]:	********exe.run_1864******* 
[INFO] 2021-07-12 19:09:46,238 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:46,238 [run_pretraining.py:  534]:	loss/total_loss, 7.350066661834717, 1865
[INFO] 2021-07-12 19:09:46,238 [run_pretraining.py:  535]:	loss/mlm_loss, 7.350066661834717, 1865
[INFO] 2021-07-12 19:09:46,238 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.863999932538718e-05, 1865
[INFO] 2021-07-12 19:09:46,238 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1865
[INFO] 2021-07-12 19:09:46,239 [run_pretraining.py:  558]:	worker_index: 3, step: 1865, cost: 7.350067, mlm loss: 7.350067, speed: 1.070461 steps/s, speed: 8.563688 samples/s, speed: 4384.608423 tokens/s, learning rate: 1.864e-05, loss_scalings: 5497.559082, pp_loss: 7.403918
[INFO] 2021-07-12 19:09:46,239 [run_pretraining.py:  512]:	********exe.run_1865******* 
[INFO] 2021-07-12 19:09:47,150 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:47,150 [run_pretraining.py:  534]:	loss/total_loss, 7.945283889770508, 1866
[INFO] 2021-07-12 19:09:47,150 [run_pretraining.py:  535]:	loss/mlm_loss, 7.945283889770508, 1866
[INFO] 2021-07-12 19:09:47,150 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8650000129127875e-05, 1866
[INFO] 2021-07-12 19:09:47,150 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1866
[INFO] 2021-07-12 19:09:47,150 [run_pretraining.py:  558]:	worker_index: 3, step: 1866, cost: 7.945284, mlm loss: 7.945284, speed: 1.097445 steps/s, speed: 8.779557 samples/s, speed: 4495.133336 tokens/s, learning rate: 1.865e-05, loss_scalings: 5497.559082, pp_loss: 7.602061
[INFO] 2021-07-12 19:09:47,150 [run_pretraining.py:  512]:	********exe.run_1866******* 
[INFO] 2021-07-12 19:09:48,058 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:48,058 [run_pretraining.py:  534]:	loss/total_loss, 7.826001167297363, 1867
[INFO] 2021-07-12 19:09:48,058 [run_pretraining.py:  535]:	loss/mlm_loss, 7.826001167297363, 1867
[INFO] 2021-07-12 19:09:48,058 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8659999113879167e-05, 1867
[INFO] 2021-07-12 19:09:48,058 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1867
[INFO] 2021-07-12 19:09:48,058 [run_pretraining.py:  558]:	worker_index: 3, step: 1867, cost: 7.826001, mlm loss: 7.826001, speed: 1.102043 steps/s, speed: 8.816346 samples/s, speed: 4513.969287 tokens/s, learning rate: 1.866e-05, loss_scalings: 5497.559082, pp_loss: 7.362658
[INFO] 2021-07-12 19:09:48,058 [run_pretraining.py:  512]:	********exe.run_1867******* 
[INFO] 2021-07-12 19:09:48,971 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:48,972 [run_pretraining.py:  534]:	loss/total_loss, 6.972713947296143, 1868
[INFO] 2021-07-12 19:09:48,972 [run_pretraining.py:  535]:	loss/mlm_loss, 6.972713947296143, 1868
[INFO] 2021-07-12 19:09:48,972 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.866999991761986e-05, 1868
[INFO] 2021-07-12 19:09:48,972 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1868
[INFO] 2021-07-12 19:09:48,972 [run_pretraining.py:  558]:	worker_index: 3, step: 1868, cost: 6.972714, mlm loss: 6.972714, speed: 1.095311 steps/s, speed: 8.762486 samples/s, speed: 4486.392700 tokens/s, learning rate: 1.867e-05, loss_scalings: 5497.559082, pp_loss: 7.397001
[INFO] 2021-07-12 19:09:48,972 [run_pretraining.py:  512]:	********exe.run_1868******* 
[INFO] 2021-07-12 19:09:49,875 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:49,876 [run_pretraining.py:  534]:	loss/total_loss, 8.107717514038086, 1869
[INFO] 2021-07-12 19:09:49,876 [run_pretraining.py:  535]:	loss/mlm_loss, 8.107717514038086, 1869
[INFO] 2021-07-12 19:09:49,876 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8680000721360557e-05, 1869
[INFO] 2021-07-12 19:09:49,876 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1869
[INFO] 2021-07-12 19:09:49,876 [run_pretraining.py:  558]:	worker_index: 3, step: 1869, cost: 8.107718, mlm loss: 8.107718, speed: 1.107050 steps/s, speed: 8.856399 samples/s, speed: 4534.476054 tokens/s, learning rate: 1.868e-05, loss_scalings: 5497.559082, pp_loss: 7.398661
[INFO] 2021-07-12 19:09:49,876 [run_pretraining.py:  512]:	********exe.run_1869******* 
[INFO] 2021-07-12 19:09:50,789 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:50,789 [run_pretraining.py:  534]:	loss/total_loss, 7.557125568389893, 1870
[INFO] 2021-07-12 19:09:50,789 [run_pretraining.py:  535]:	loss/mlm_loss, 7.557125568389893, 1870
[INFO] 2021-07-12 19:09:50,789 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.868999970611185e-05, 1870
[INFO] 2021-07-12 19:09:50,789 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1870
[INFO] 2021-07-12 19:09:50,790 [run_pretraining.py:  558]:	worker_index: 3, step: 1870, cost: 7.557126, mlm loss: 7.557126, speed: 1.095320 steps/s, speed: 8.762557 samples/s, speed: 4486.429019 tokens/s, learning rate: 1.869e-05, loss_scalings: 5497.559082, pp_loss: 7.459659
[INFO] 2021-07-12 19:09:50,790 [run_pretraining.py:  512]:	********exe.run_1870******* 
[INFO] 2021-07-12 19:09:51,692 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:51,692 [run_pretraining.py:  534]:	loss/total_loss, 7.525012969970703, 1871
[INFO] 2021-07-12 19:09:51,693 [run_pretraining.py:  535]:	loss/mlm_loss, 7.525012969970703, 1871
[INFO] 2021-07-12 19:09:51,693 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8700000509852543e-05, 1871
[INFO] 2021-07-12 19:09:51,693 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1871
[INFO] 2021-07-12 19:09:51,693 [run_pretraining.py:  558]:	worker_index: 3, step: 1871, cost: 7.525013, mlm loss: 7.525013, speed: 1.107937 steps/s, speed: 8.863499 samples/s, speed: 4538.111361 tokens/s, learning rate: 1.870e-05, loss_scalings: 5497.559082, pp_loss: 7.640654
[INFO] 2021-07-12 19:09:51,693 [run_pretraining.py:  512]:	********exe.run_1871******* 
[INFO] 2021-07-12 19:09:52,596 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:52,597 [run_pretraining.py:  534]:	loss/total_loss, 6.500975131988525, 1872
[INFO] 2021-07-12 19:09:52,597 [run_pretraining.py:  535]:	loss/mlm_loss, 6.500975131988525, 1872
[INFO] 2021-07-12 19:09:52,597 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8709999494603835e-05, 1872
[INFO] 2021-07-12 19:09:52,597 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1872
[INFO] 2021-07-12 19:09:52,597 [run_pretraining.py:  558]:	worker_index: 3, step: 1872, cost: 6.500975, mlm loss: 6.500975, speed: 1.106343 steps/s, speed: 8.850745 samples/s, speed: 4531.581561 tokens/s, learning rate: 1.871e-05, loss_scalings: 5497.559082, pp_loss: 6.482991
[INFO] 2021-07-12 19:09:52,597 [run_pretraining.py:  512]:	********exe.run_1872******* 
[INFO] 2021-07-12 19:09:53,508 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:53,508 [run_pretraining.py:  534]:	loss/total_loss, 7.433506965637207, 1873
[INFO] 2021-07-12 19:09:53,508 [run_pretraining.py:  535]:	loss/mlm_loss, 7.433506965637207, 1873
[INFO] 2021-07-12 19:09:53,508 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8719998479355127e-05, 1873
[INFO] 2021-07-12 19:09:53,508 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1873
[INFO] 2021-07-12 19:09:53,508 [run_pretraining.py:  558]:	worker_index: 3, step: 1873, cost: 7.433507, mlm loss: 7.433507, speed: 1.098276 steps/s, speed: 8.786206 samples/s, speed: 4498.537358 tokens/s, learning rate: 1.872e-05, loss_scalings: 5497.559082, pp_loss: 6.887258
[INFO] 2021-07-12 19:09:53,508 [run_pretraining.py:  512]:	********exe.run_1873******* 
[INFO] 2021-07-12 19:09:54,404 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:54,404 [run_pretraining.py:  534]:	loss/total_loss, 7.827429294586182, 1874
[INFO] 2021-07-12 19:09:54,405 [run_pretraining.py:  535]:	loss/mlm_loss, 7.827429294586182, 1874
[INFO] 2021-07-12 19:09:54,405 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8729999283095822e-05, 1874
[INFO] 2021-07-12 19:09:54,405 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1874
[INFO] 2021-07-12 19:09:54,405 [run_pretraining.py:  558]:	worker_index: 3, step: 1874, cost: 7.827429, mlm loss: 7.827429, speed: 1.116359 steps/s, speed: 8.930870 samples/s, speed: 4572.605621 tokens/s, learning rate: 1.873e-05, loss_scalings: 5497.559082, pp_loss: 7.482687
[INFO] 2021-07-12 19:09:54,405 [run_pretraining.py:  512]:	********exe.run_1874******* 
[INFO] 2021-07-12 19:09:55,316 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:55,317 [run_pretraining.py:  534]:	loss/total_loss, 7.529664516448975, 1875
[INFO] 2021-07-12 19:09:55,317 [run_pretraining.py:  535]:	loss/mlm_loss, 7.529664516448975, 1875
[INFO] 2021-07-12 19:09:55,317 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8740000086836517e-05, 1875
[INFO] 2021-07-12 19:09:55,317 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1875
[INFO] 2021-07-12 19:09:55,317 [run_pretraining.py:  558]:	worker_index: 3, step: 1875, cost: 7.529665, mlm loss: 7.529665, speed: 1.096713 steps/s, speed: 8.773706 samples/s, speed: 4492.137310 tokens/s, learning rate: 1.874e-05, loss_scalings: 5497.559082, pp_loss: 7.240467
[INFO] 2021-07-12 19:09:55,317 [run_pretraining.py:  512]:	********exe.run_1875******* 
[INFO] 2021-07-12 19:09:56,230 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:56,230 [run_pretraining.py:  534]:	loss/total_loss, 7.325550079345703, 1876
[INFO] 2021-07-12 19:09:56,230 [run_pretraining.py:  535]:	loss/mlm_loss, 7.325550079345703, 1876
[INFO] 2021-07-12 19:09:56,231 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.874999907158781e-05, 1876
[INFO] 2021-07-12 19:09:56,231 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1876
[INFO] 2021-07-12 19:09:56,231 [run_pretraining.py:  558]:	worker_index: 3, step: 1876, cost: 7.325550, mlm loss: 7.325550, speed: 1.095494 steps/s, speed: 8.763948 samples/s, speed: 4487.141469 tokens/s, learning rate: 1.875e-05, loss_scalings: 5497.559082, pp_loss: 7.089000
[INFO] 2021-07-12 19:09:56,231 [run_pretraining.py:  512]:	********exe.run_1876******* 
[INFO] 2021-07-12 19:09:57,159 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:57,159 [run_pretraining.py:  534]:	loss/total_loss, 7.991715431213379, 1877
[INFO] 2021-07-12 19:09:57,159 [run_pretraining.py:  535]:	loss/mlm_loss, 7.991715431213379, 1877
[INFO] 2021-07-12 19:09:57,160 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8759999875328504e-05, 1877
[INFO] 2021-07-12 19:09:57,160 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1877
[INFO] 2021-07-12 19:09:57,160 [run_pretraining.py:  558]:	worker_index: 3, step: 1877, cost: 7.991715, mlm loss: 7.991715, speed: 1.077204 steps/s, speed: 8.617635 samples/s, speed: 4412.228897 tokens/s, learning rate: 1.876e-05, loss_scalings: 5497.559082, pp_loss: 7.296628
[INFO] 2021-07-12 19:09:57,160 [run_pretraining.py:  512]:	********exe.run_1877******* 
[INFO] 2021-07-12 19:09:58,066 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:58,066 [run_pretraining.py:  534]:	loss/total_loss, 7.357975482940674, 1878
[INFO] 2021-07-12 19:09:58,066 [run_pretraining.py:  535]:	loss/mlm_loss, 7.357975482940674, 1878
[INFO] 2021-07-12 19:09:58,066 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.87700006790692e-05, 1878
[INFO] 2021-07-12 19:09:58,066 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1878
[INFO] 2021-07-12 19:09:58,067 [run_pretraining.py:  558]:	worker_index: 3, step: 1878, cost: 7.357975, mlm loss: 7.357975, speed: 1.103478 steps/s, speed: 8.827828 samples/s, speed: 4519.847804 tokens/s, learning rate: 1.877e-05, loss_scalings: 5497.559082, pp_loss: 7.338926
[INFO] 2021-07-12 19:09:58,067 [run_pretraining.py:  512]:	********exe.run_1878******* 
[INFO] 2021-07-12 19:09:58,977 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:58,977 [run_pretraining.py:  534]:	loss/total_loss, 7.083338260650635, 1879
[INFO] 2021-07-12 19:09:58,977 [run_pretraining.py:  535]:	loss/mlm_loss, 7.083338260650635, 1879
[INFO] 2021-07-12 19:09:58,977 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.877999966382049e-05, 1879
[INFO] 2021-07-12 19:09:58,977 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1879
[INFO] 2021-07-12 19:09:58,978 [run_pretraining.py:  558]:	worker_index: 3, step: 1879, cost: 7.083338, mlm loss: 7.083338, speed: 1.098467 steps/s, speed: 8.787734 samples/s, speed: 4499.319645 tokens/s, learning rate: 1.878e-05, loss_scalings: 5497.559082, pp_loss: 7.139790
[INFO] 2021-07-12 19:09:58,978 [run_pretraining.py:  512]:	********exe.run_1879******* 
[INFO] 2021-07-12 19:09:59,936 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:59,936 [run_pretraining.py:  534]:	loss/total_loss, 7.30690860748291, 1880
[INFO] 2021-07-12 19:09:59,936 [run_pretraining.py:  535]:	loss/mlm_loss, 7.30690860748291, 1880
[INFO] 2021-07-12 19:09:59,937 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8790000467561185e-05, 1880
[INFO] 2021-07-12 19:09:59,937 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1880
[INFO] 2021-07-12 19:09:59,937 [run_pretraining.py:  558]:	worker_index: 3, step: 1880, cost: 7.306909, mlm loss: 7.306909, speed: 1.043286 steps/s, speed: 8.346290 samples/s, speed: 4273.300594 tokens/s, learning rate: 1.879e-05, loss_scalings: 5497.559082, pp_loss: 7.205173
[INFO] 2021-07-12 19:09:59,937 [run_pretraining.py:  512]:	********exe.run_1880******* 
[INFO] 2021-07-12 19:10:00,997 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:00,997 [run_pretraining.py:  534]:	loss/total_loss, 7.565817832946777, 1881
[INFO] 2021-07-12 19:10:00,997 [run_pretraining.py:  535]:	loss/mlm_loss, 7.565817832946777, 1881
[INFO] 2021-07-12 19:10:00,997 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8799999452312477e-05, 1881
[INFO] 2021-07-12 19:10:00,997 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1881
[INFO] 2021-07-12 19:10:00,997 [run_pretraining.py:  558]:	worker_index: 3, step: 1881, cost: 7.565818, mlm loss: 7.565818, speed: 0.943236 steps/s, speed: 7.545885 samples/s, speed: 3863.493327 tokens/s, learning rate: 1.880e-05, loss_scalings: 5497.559082, pp_loss: 7.267622
[INFO] 2021-07-12 19:10:00,998 [run_pretraining.py:  512]:	********exe.run_1881******* 
[INFO] 2021-07-12 19:10:02,067 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:02,068 [run_pretraining.py:  534]:	loss/total_loss, 7.785269737243652, 1882
[INFO] 2021-07-12 19:10:02,068 [run_pretraining.py:  535]:	loss/mlm_loss, 7.785269737243652, 1882
[INFO] 2021-07-12 19:10:02,068 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.880999843706377e-05, 1882
[INFO] 2021-07-12 19:10:02,068 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1882
[INFO] 2021-07-12 19:10:02,068 [run_pretraining.py:  558]:	worker_index: 3, step: 1882, cost: 7.785270, mlm loss: 7.785270, speed: 0.934595 steps/s, speed: 7.476758 samples/s, speed: 3828.099890 tokens/s, learning rate: 1.881e-05, loss_scalings: 5497.559082, pp_loss: 7.344925
[INFO] 2021-07-12 19:10:02,068 [run_pretraining.py:  512]:	********exe.run_1882******* 
[INFO] 2021-07-12 19:10:03,119 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:03,120 [run_pretraining.py:  534]:	loss/total_loss, 7.090683937072754, 1883
[INFO] 2021-07-12 19:10:03,120 [run_pretraining.py:  535]:	loss/mlm_loss, 7.090683937072754, 1883
[INFO] 2021-07-12 19:10:03,120 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8819999240804464e-05, 1883
[INFO] 2021-07-12 19:10:03,120 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1883
[INFO] 2021-07-12 19:10:03,120 [run_pretraining.py:  558]:	worker_index: 3, step: 1883, cost: 7.090684, mlm loss: 7.090684, speed: 0.951132 steps/s, speed: 7.609053 samples/s, speed: 3895.835095 tokens/s, learning rate: 1.882e-05, loss_scalings: 5497.559082, pp_loss: 7.250571
[INFO] 2021-07-12 19:10:03,120 [run_pretraining.py:  512]:	********exe.run_1883******* 
[INFO] 2021-07-12 19:10:04,185 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:04,185 [run_pretraining.py:  534]:	loss/total_loss, 7.657280445098877, 1884
[INFO] 2021-07-12 19:10:04,185 [run_pretraining.py:  535]:	loss/mlm_loss, 7.657280445098877, 1884
[INFO] 2021-07-12 19:10:04,186 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.883000004454516e-05, 1884
[INFO] 2021-07-12 19:10:04,186 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1884
[INFO] 2021-07-12 19:10:04,186 [run_pretraining.py:  558]:	worker_index: 3, step: 1884, cost: 7.657280, mlm loss: 7.657280, speed: 0.939039 steps/s, speed: 7.512315 samples/s, speed: 3846.305388 tokens/s, learning rate: 1.883e-05, loss_scalings: 5497.559082, pp_loss: 7.287162
[INFO] 2021-07-12 19:10:04,186 [run_pretraining.py:  512]:	********exe.run_1884******* 
[INFO] 2021-07-12 19:10:05,240 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:05,240 [run_pretraining.py:  534]:	loss/total_loss, 6.794315814971924, 1885
[INFO] 2021-07-12 19:10:05,241 [run_pretraining.py:  535]:	loss/mlm_loss, 6.794315814971924, 1885
[INFO] 2021-07-12 19:10:05,241 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.883999902929645e-05, 1885
[INFO] 2021-07-12 19:10:05,241 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1885
[INFO] 2021-07-12 19:10:05,241 [run_pretraining.py:  558]:	worker_index: 3, step: 1885, cost: 6.794316, mlm loss: 6.794316, speed: 0.948319 steps/s, speed: 7.586552 samples/s, speed: 3884.314639 tokens/s, learning rate: 1.884e-05, loss_scalings: 5497.559082, pp_loss: 7.012482
[INFO] 2021-07-12 19:10:05,241 [run_pretraining.py:  512]:	********exe.run_1885******* 
[INFO] 2021-07-12 19:10:06,447 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:06,447 [run_pretraining.py:  534]:	loss/total_loss, 7.688121795654297, 1886
[INFO] 2021-07-12 19:10:06,448 [run_pretraining.py:  535]:	loss/mlm_loss, 7.688121795654297, 1886
[INFO] 2021-07-12 19:10:06,448 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8849999833037145e-05, 1886
[INFO] 2021-07-12 19:10:06,448 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1886
[INFO] 2021-07-12 19:10:06,448 [run_pretraining.py:  558]:	worker_index: 3, step: 1886, cost: 7.688122, mlm loss: 7.688122, speed: 0.828974 steps/s, speed: 6.631789 samples/s, speed: 3395.475995 tokens/s, learning rate: 1.885e-05, loss_scalings: 5497.559082, pp_loss: 7.393363
[INFO] 2021-07-12 19:10:06,448 [run_pretraining.py:  512]:	********exe.run_1886******* 
[INFO] 2021-07-12 19:10:07,675 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:07,675 [run_pretraining.py:  534]:	loss/total_loss, 6.984453201293945, 1887
[INFO] 2021-07-12 19:10:07,675 [run_pretraining.py:  535]:	loss/mlm_loss, 6.984453201293945, 1887
[INFO] 2021-07-12 19:10:07,675 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.886000063677784e-05, 1887
[INFO] 2021-07-12 19:10:07,675 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1887
[INFO] 2021-07-12 19:10:07,675 [run_pretraining.py:  558]:	worker_index: 3, step: 1887, cost: 6.984453, mlm loss: 6.984453, speed: 0.814969 steps/s, speed: 6.519756 samples/s, speed: 3338.114993 tokens/s, learning rate: 1.886e-05, loss_scalings: 5497.559082, pp_loss: 6.495536
[INFO] 2021-07-12 19:10:07,675 [run_pretraining.py:  512]:	********exe.run_1887******* 
[INFO] 2021-07-12 19:10:08,949 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:08,949 [run_pretraining.py:  534]:	loss/total_loss, 7.765504360198975, 1888
[INFO] 2021-07-12 19:10:08,950 [run_pretraining.py:  535]:	loss/mlm_loss, 7.765504360198975, 1888
[INFO] 2021-07-12 19:10:08,950 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8869999621529132e-05, 1888
[INFO] 2021-07-12 19:10:08,950 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1888
[INFO] 2021-07-12 19:10:08,950 [run_pretraining.py:  558]:	worker_index: 3, step: 1888, cost: 7.765504, mlm loss: 7.765504, speed: 0.785118 steps/s, speed: 6.280947 samples/s, speed: 3215.844761 tokens/s, learning rate: 1.887e-05, loss_scalings: 5497.559082, pp_loss: 7.429844
[INFO] 2021-07-12 19:10:08,950 [run_pretraining.py:  512]:	********exe.run_1888******* 
[INFO] 2021-07-12 19:10:09,907 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:09,907 [run_pretraining.py:  534]:	loss/total_loss, 7.260897636413574, 1889
[INFO] 2021-07-12 19:10:09,907 [run_pretraining.py:  535]:	loss/mlm_loss, 7.260897636413574, 1889
[INFO] 2021-07-12 19:10:09,907 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8880000425269827e-05, 1889
[INFO] 2021-07-12 19:10:09,908 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1889
[INFO] 2021-07-12 19:10:09,908 [run_pretraining.py:  558]:	worker_index: 3, step: 1889, cost: 7.260898, mlm loss: 7.260898, speed: 1.044692 steps/s, speed: 8.357537 samples/s, speed: 4279.058825 tokens/s, learning rate: 1.888e-05, loss_scalings: 5497.559082, pp_loss: 7.493790
[INFO] 2021-07-12 19:10:09,908 [run_pretraining.py:  512]:	********exe.run_1889******* 
[INFO] 2021-07-12 19:10:10,822 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:10,823 [run_pretraining.py:  534]:	loss/total_loss, 7.351011276245117, 1890
[INFO] 2021-07-12 19:10:10,823 [run_pretraining.py:  535]:	loss/mlm_loss, 7.351011276245117, 1890
[INFO] 2021-07-12 19:10:10,823 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.888999941002112e-05, 1890
[INFO] 2021-07-12 19:10:10,823 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1890
[INFO] 2021-07-12 19:10:10,823 [run_pretraining.py:  558]:	worker_index: 3, step: 1890, cost: 7.351011, mlm loss: 7.351011, speed: 1.093085 steps/s, speed: 8.744680 samples/s, speed: 4477.276394 tokens/s, learning rate: 1.889e-05, loss_scalings: 5497.559082, pp_loss: 7.478436
[INFO] 2021-07-12 19:10:10,823 [run_pretraining.py:  512]:	********exe.run_1890******* 
[INFO] 2021-07-12 19:10:11,732 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:11,733 [run_pretraining.py:  534]:	loss/total_loss, 6.960668087005615, 1891
[INFO] 2021-07-12 19:10:11,733 [run_pretraining.py:  535]:	loss/mlm_loss, 6.960668087005615, 1891
[INFO] 2021-07-12 19:10:11,733 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.889999839477241e-05, 1891
[INFO] 2021-07-12 19:10:11,733 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1891
[INFO] 2021-07-12 19:10:11,733 [run_pretraining.py:  558]:	worker_index: 3, step: 1891, cost: 6.960668, mlm loss: 6.960668, speed: 1.099635 steps/s, speed: 8.797081 samples/s, speed: 4504.105291 tokens/s, learning rate: 1.890e-05, loss_scalings: 5497.559082, pp_loss: 7.256903
[INFO] 2021-07-12 19:10:11,733 [run_pretraining.py:  512]:	********exe.run_1891******* 
[INFO] 2021-07-12 19:10:12,653 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:12,654 [run_pretraining.py:  534]:	loss/total_loss, 6.695037841796875, 1892
[INFO] 2021-07-12 19:10:12,654 [run_pretraining.py:  535]:	loss/mlm_loss, 6.695037841796875, 1892
[INFO] 2021-07-12 19:10:12,654 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8909999198513106e-05, 1892
[INFO] 2021-07-12 19:10:12,654 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1892
[INFO] 2021-07-12 19:10:12,654 [run_pretraining.py:  558]:	worker_index: 3, step: 1892, cost: 6.695038, mlm loss: 6.695038, speed: 1.086564 steps/s, speed: 8.692513 samples/s, speed: 4450.566903 tokens/s, learning rate: 1.891e-05, loss_scalings: 5497.559082, pp_loss: 7.250118
[INFO] 2021-07-12 19:10:12,654 [run_pretraining.py:  512]:	********exe.run_1892******* 
[INFO] 2021-07-12 19:10:13,562 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:13,562 [run_pretraining.py:  534]:	loss/total_loss, 8.019554138183594, 1893
[INFO] 2021-07-12 19:10:13,562 [run_pretraining.py:  535]:	loss/mlm_loss, 8.019554138183594, 1893
[INFO] 2021-07-12 19:10:13,563 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.89200000022538e-05, 1893
[INFO] 2021-07-12 19:10:13,563 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1893
[INFO] 2021-07-12 19:10:13,563 [run_pretraining.py:  558]:	worker_index: 3, step: 1893, cost: 8.019554, mlm loss: 8.019554, speed: 1.101368 steps/s, speed: 8.810941 samples/s, speed: 4511.201594 tokens/s, learning rate: 1.892e-05, loss_scalings: 5497.559082, pp_loss: 7.840879
[INFO] 2021-07-12 19:10:13,563 [run_pretraining.py:  512]:	********exe.run_1893******* 
[INFO] 2021-07-12 19:10:14,477 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:14,478 [run_pretraining.py:  534]:	loss/total_loss, 7.548704147338867, 1894
[INFO] 2021-07-12 19:10:14,478 [run_pretraining.py:  535]:	loss/mlm_loss, 7.548704147338867, 1894
[INFO] 2021-07-12 19:10:14,478 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8929998987005092e-05, 1894
[INFO] 2021-07-12 19:10:14,478 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1894
[INFO] 2021-07-12 19:10:14,478 [run_pretraining.py:  558]:	worker_index: 3, step: 1894, cost: 7.548704, mlm loss: 7.548704, speed: 1.093098 steps/s, speed: 8.744785 samples/s, speed: 4477.330069 tokens/s, learning rate: 1.893e-05, loss_scalings: 5497.559082, pp_loss: 7.661209
[INFO] 2021-07-12 19:10:14,478 [run_pretraining.py:  512]:	********exe.run_1894******* 
[INFO] 2021-07-12 19:10:15,385 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:15,385 [run_pretraining.py:  534]:	loss/total_loss, 7.618277549743652, 1895
[INFO] 2021-07-12 19:10:15,385 [run_pretraining.py:  535]:	loss/mlm_loss, 7.618277549743652, 1895
[INFO] 2021-07-12 19:10:15,385 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8939999790745787e-05, 1895
[INFO] 2021-07-12 19:10:15,385 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1895
[INFO] 2021-07-12 19:10:15,385 [run_pretraining.py:  558]:	worker_index: 3, step: 1895, cost: 7.618278, mlm loss: 7.618278, speed: 1.103061 steps/s, speed: 8.824485 samples/s, speed: 4518.136111 tokens/s, learning rate: 1.894e-05, loss_scalings: 5497.559082, pp_loss: 6.727855
[INFO] 2021-07-12 19:10:15,385 [run_pretraining.py:  512]:	********exe.run_1895******* 
[INFO] 2021-07-12 19:10:16,297 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:16,298 [run_pretraining.py:  534]:	loss/total_loss, 7.4922380447387695, 1896
[INFO] 2021-07-12 19:10:16,298 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4922380447387695, 1896
[INFO] 2021-07-12 19:10:16,298 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8950000594486482e-05, 1896
[INFO] 2021-07-12 19:10:16,298 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1896
[INFO] 2021-07-12 19:10:16,298 [run_pretraining.py:  558]:	worker_index: 3, step: 1896, cost: 7.492238, mlm loss: 7.492238, speed: 1.096584 steps/s, speed: 8.772671 samples/s, speed: 4491.607632 tokens/s, learning rate: 1.895e-05, loss_scalings: 5497.559082, pp_loss: 7.237741
[INFO] 2021-07-12 19:10:16,298 [run_pretraining.py:  512]:	********exe.run_1896******* 
[INFO] 2021-07-12 19:10:17,205 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:17,206 [run_pretraining.py:  534]:	loss/total_loss, 7.310800552368164, 1897
[INFO] 2021-07-12 19:10:17,206 [run_pretraining.py:  535]:	loss/mlm_loss, 7.310800552368164, 1897
[INFO] 2021-07-12 19:10:17,206 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8959999579237774e-05, 1897
[INFO] 2021-07-12 19:10:17,206 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1897
[INFO] 2021-07-12 19:10:17,206 [run_pretraining.py:  558]:	worker_index: 3, step: 1897, cost: 7.310801, mlm loss: 7.310801, speed: 1.102087 steps/s, speed: 8.816696 samples/s, speed: 4514.148385 tokens/s, learning rate: 1.896e-05, loss_scalings: 5497.559082, pp_loss: 7.221374
[INFO] 2021-07-12 19:10:17,206 [run_pretraining.py:  512]:	********exe.run_1897******* 
[INFO] 2021-07-12 19:10:18,119 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:18,120 [run_pretraining.py:  534]:	loss/total_loss, 7.281943321228027, 1898
[INFO] 2021-07-12 19:10:18,120 [run_pretraining.py:  535]:	loss/mlm_loss, 7.281943321228027, 1898
[INFO] 2021-07-12 19:10:18,120 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.897000038297847e-05, 1898
[INFO] 2021-07-12 19:10:18,120 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1898
[INFO] 2021-07-12 19:10:18,120 [run_pretraining.py:  558]:	worker_index: 3, step: 1898, cost: 7.281943, mlm loss: 7.281943, speed: 1.094962 steps/s, speed: 8.759700 samples/s, speed: 4484.966160 tokens/s, learning rate: 1.897e-05, loss_scalings: 5497.559082, pp_loss: 7.324540
[INFO] 2021-07-12 19:10:18,120 [run_pretraining.py:  512]:	********exe.run_1898******* 
[INFO] 2021-07-12 19:10:19,038 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:19,039 [run_pretraining.py:  534]:	loss/total_loss, 7.256925582885742, 1899
[INFO] 2021-07-12 19:10:19,039 [run_pretraining.py:  535]:	loss/mlm_loss, 7.256925582885742, 1899
[INFO] 2021-07-12 19:10:19,039 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.897999936772976e-05, 1899
[INFO] 2021-07-12 19:10:19,039 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1899
[INFO] 2021-07-12 19:10:19,039 [run_pretraining.py:  558]:	worker_index: 3, step: 1899, cost: 7.256926, mlm loss: 7.256926, speed: 1.088395 steps/s, speed: 8.707157 samples/s, speed: 4458.064470 tokens/s, learning rate: 1.898e-05, loss_scalings: 5497.559082, pp_loss: 7.352046
[INFO] 2021-07-12 19:10:19,039 [run_pretraining.py:  512]:	********exe.run_1899******* 
[INFO] 2021-07-12 19:10:19,965 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:19,966 [run_pretraining.py:  534]:	loss/total_loss, 8.094537734985352, 1900
[INFO] 2021-07-12 19:10:19,966 [run_pretraining.py:  535]:	loss/mlm_loss, 8.094537734985352, 1900
[INFO] 2021-07-12 19:10:19,966 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8989998352481052e-05, 1900
[INFO] 2021-07-12 19:10:19,966 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1900
[INFO] 2021-07-12 19:10:19,966 [run_pretraining.py:  558]:	worker_index: 3, step: 1900, cost: 8.094538, mlm loss: 8.094538, speed: 1.079716 steps/s, speed: 8.637724 samples/s, speed: 4422.514835 tokens/s, learning rate: 1.899e-05, loss_scalings: 5497.559082, pp_loss: 7.740828
[INFO] 2021-07-12 19:10:19,966 [run_pretraining.py:  512]:	********exe.run_1900******* 
[INFO] 2021-07-12 19:10:20,883 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:20,883 [run_pretraining.py:  534]:	loss/total_loss, 7.972919464111328, 1901
[INFO] 2021-07-12 19:10:20,883 [run_pretraining.py:  535]:	loss/mlm_loss, 7.972919464111328, 1901
[INFO] 2021-07-12 19:10:20,883 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8999999156221747e-05, 1901
[INFO] 2021-07-12 19:10:20,883 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1901
[INFO] 2021-07-12 19:10:20,884 [run_pretraining.py:  558]:	worker_index: 3, step: 1901, cost: 7.972919, mlm loss: 7.972919, speed: 1.090847 steps/s, speed: 8.726779 samples/s, speed: 4468.111068 tokens/s, learning rate: 1.900e-05, loss_scalings: 5497.559082, pp_loss: 7.999428
[INFO] 2021-07-12 19:10:20,884 [run_pretraining.py:  512]:	********exe.run_1901******* 
[INFO] 2021-07-12 19:10:21,810 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:21,810 [run_pretraining.py:  534]:	loss/total_loss, 7.040939807891846, 1902
[INFO] 2021-07-12 19:10:21,811 [run_pretraining.py:  535]:	loss/mlm_loss, 7.040939807891846, 1902
[INFO] 2021-07-12 19:10:21,811 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9009999959962443e-05, 1902
[INFO] 2021-07-12 19:10:21,811 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1902
[INFO] 2021-07-12 19:10:21,811 [run_pretraining.py:  558]:	worker_index: 3, step: 1902, cost: 7.040940, mlm loss: 7.040940, speed: 1.079240 steps/s, speed: 8.633917 samples/s, speed: 4420.565508 tokens/s, learning rate: 1.901e-05, loss_scalings: 5497.559082, pp_loss: 7.249269
[INFO] 2021-07-12 19:10:21,811 [run_pretraining.py:  512]:	********exe.run_1902******* 
[INFO] 2021-07-12 19:10:22,740 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:22,741 [run_pretraining.py:  534]:	loss/total_loss, 7.7140398025512695, 1903
[INFO] 2021-07-12 19:10:22,741 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7140398025512695, 1903
[INFO] 2021-07-12 19:10:22,741 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9019998944713734e-05, 1903
[INFO] 2021-07-12 19:10:22,741 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1903
[INFO] 2021-07-12 19:10:22,741 [run_pretraining.py:  558]:	worker_index: 3, step: 1903, cost: 7.714040, mlm loss: 7.714040, speed: 1.075884 steps/s, speed: 8.607068 samples/s, speed: 4406.818972 tokens/s, learning rate: 1.902e-05, loss_scalings: 5497.559082, pp_loss: 7.857882
[INFO] 2021-07-12 19:10:22,741 [run_pretraining.py:  512]:	********exe.run_1903******* 
[INFO] 2021-07-12 19:10:23,669 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:23,670 [run_pretraining.py:  534]:	loss/total_loss, 7.261636734008789, 1904
[INFO] 2021-07-12 19:10:23,670 [run_pretraining.py:  535]:	loss/mlm_loss, 7.261636734008789, 1904
[INFO] 2021-07-12 19:10:23,670 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.902999974845443e-05, 1904
[INFO] 2021-07-12 19:10:23,670 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1904
[INFO] 2021-07-12 19:10:23,670 [run_pretraining.py:  558]:	worker_index: 3, step: 1904, cost: 7.261637, mlm loss: 7.261637, speed: 1.076680 steps/s, speed: 8.613438 samples/s, speed: 4410.080315 tokens/s, learning rate: 1.903e-05, loss_scalings: 5497.559082, pp_loss: 7.252282
[INFO] 2021-07-12 19:10:23,670 [run_pretraining.py:  512]:	********exe.run_1904******* 
[INFO] 2021-07-12 19:10:24,591 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:24,591 [run_pretraining.py:  534]:	loss/total_loss, 7.64611291885376, 1905
[INFO] 2021-07-12 19:10:24,592 [run_pretraining.py:  535]:	loss/mlm_loss, 7.64611291885376, 1905
[INFO] 2021-07-12 19:10:24,592 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9040000552195124e-05, 1905
[INFO] 2021-07-12 19:10:24,592 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1905
[INFO] 2021-07-12 19:10:24,592 [run_pretraining.py:  558]:	worker_index: 3, step: 1905, cost: 7.646113, mlm loss: 7.646113, speed: 1.086051 steps/s, speed: 8.688408 samples/s, speed: 4448.464914 tokens/s, learning rate: 1.904e-05, loss_scalings: 5497.559082, pp_loss: 6.877281
[INFO] 2021-07-12 19:10:24,592 [run_pretraining.py:  512]:	********exe.run_1905******* 
[INFO] 2021-07-12 19:10:25,518 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:25,518 [run_pretraining.py:  534]:	loss/total_loss, 7.500795364379883, 1906
[INFO] 2021-07-12 19:10:25,518 [run_pretraining.py:  535]:	loss/mlm_loss, 7.500795364379883, 1906
[INFO] 2021-07-12 19:10:25,519 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9049999536946416e-05, 1906
[INFO] 2021-07-12 19:10:25,519 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1906
[INFO] 2021-07-12 19:10:25,519 [run_pretraining.py:  558]:	worker_index: 3, step: 1906, cost: 7.500795, mlm loss: 7.500795, speed: 1.079631 steps/s, speed: 8.637048 samples/s, speed: 4422.168770 tokens/s, learning rate: 1.905e-05, loss_scalings: 5497.559082, pp_loss: 7.354255
[INFO] 2021-07-12 19:10:25,519 [run_pretraining.py:  512]:	********exe.run_1906******* 
[INFO] 2021-07-12 19:10:26,441 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:26,442 [run_pretraining.py:  534]:	loss/total_loss, 7.294433116912842, 1907
[INFO] 2021-07-12 19:10:26,442 [run_pretraining.py:  535]:	loss/mlm_loss, 7.294433116912842, 1907
[INFO] 2021-07-12 19:10:26,442 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9059998521697707e-05, 1907
[INFO] 2021-07-12 19:10:26,442 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1907
[INFO] 2021-07-12 19:10:26,442 [run_pretraining.py:  558]:	worker_index: 3, step: 1907, cost: 7.294433, mlm loss: 7.294433, speed: 1.083623 steps/s, speed: 8.668985 samples/s, speed: 4438.520133 tokens/s, learning rate: 1.906e-05, loss_scalings: 5497.559082, pp_loss: 7.212857
[INFO] 2021-07-12 19:10:26,442 [run_pretraining.py:  512]:	********exe.run_1907******* 
[INFO] 2021-07-12 19:10:27,408 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:27,409 [run_pretraining.py:  534]:	loss/total_loss, 7.3790693283081055, 1908
[INFO] 2021-07-12 19:10:27,409 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3790693283081055, 1908
[INFO] 2021-07-12 19:10:27,409 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9069999325438403e-05, 1908
[INFO] 2021-07-12 19:10:27,409 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1908
[INFO] 2021-07-12 19:10:27,409 [run_pretraining.py:  558]:	worker_index: 3, step: 1908, cost: 7.379069, mlm loss: 7.379069, speed: 1.034996 steps/s, speed: 8.279967 samples/s, speed: 4239.342878 tokens/s, learning rate: 1.907e-05, loss_scalings: 5497.559082, pp_loss: 7.205043
[INFO] 2021-07-12 19:10:27,409 [run_pretraining.py:  512]:	********exe.run_1908******* 
[INFO] 2021-07-12 19:10:28,309 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:28,309 [run_pretraining.py:  534]:	loss/total_loss, 3.6253063678741455, 1909
[INFO] 2021-07-12 19:10:28,310 [run_pretraining.py:  535]:	loss/mlm_loss, 3.6253063678741455, 1909
[INFO] 2021-07-12 19:10:28,310 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9079998310189694e-05, 1909
[INFO] 2021-07-12 19:10:28,310 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1909
[INFO] 2021-07-12 19:10:28,310 [run_pretraining.py:  558]:	worker_index: 3, step: 1909, cost: 3.625306, mlm loss: 3.625306, speed: 1.110915 steps/s, speed: 8.887320 samples/s, speed: 4550.307819 tokens/s, learning rate: 1.908e-05, loss_scalings: 5497.559082, pp_loss: 6.395991
[INFO] 2021-07-12 19:10:28,310 [run_pretraining.py:  512]:	********exe.run_1909******* 
[INFO] 2021-07-12 19:10:29,241 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:29,242 [run_pretraining.py:  534]:	loss/total_loss, 7.641155242919922, 1910
[INFO] 2021-07-12 19:10:29,242 [run_pretraining.py:  535]:	loss/mlm_loss, 7.641155242919922, 1910
[INFO] 2021-07-12 19:10:29,242 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.908999911393039e-05, 1910
[INFO] 2021-07-12 19:10:29,242 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1910
[INFO] 2021-07-12 19:10:29,242 [run_pretraining.py:  558]:	worker_index: 3, step: 1910, cost: 7.641155, mlm loss: 7.641155, speed: 1.073229 steps/s, speed: 8.585833 samples/s, speed: 4395.946585 tokens/s, learning rate: 1.909e-05, loss_scalings: 5497.559082, pp_loss: 7.509939
[INFO] 2021-07-12 19:10:29,242 [run_pretraining.py:  512]:	********exe.run_1910******* 
[INFO] 2021-07-12 19:10:30,174 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:30,174 [run_pretraining.py:  534]:	loss/total_loss, 7.579232215881348, 1911
[INFO] 2021-07-12 19:10:30,174 [run_pretraining.py:  535]:	loss/mlm_loss, 7.579232215881348, 1911
[INFO] 2021-07-12 19:10:30,174 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9099999917671084e-05, 1911
[INFO] 2021-07-12 19:10:30,174 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1911
[INFO] 2021-07-12 19:10:30,175 [run_pretraining.py:  558]:	worker_index: 3, step: 1911, cost: 7.579232, mlm loss: 7.579232, speed: 1.073274 steps/s, speed: 8.586189 samples/s, speed: 4396.128814 tokens/s, learning rate: 1.910e-05, loss_scalings: 5497.559082, pp_loss: 7.269908
[INFO] 2021-07-12 19:10:30,175 [run_pretraining.py:  512]:	********exe.run_1911******* 
[INFO] 2021-07-12 19:10:31,092 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:31,093 [run_pretraining.py:  534]:	loss/total_loss, 7.628985404968262, 1912
[INFO] 2021-07-12 19:10:31,093 [run_pretraining.py:  535]:	loss/mlm_loss, 7.628985404968262, 1912
[INFO] 2021-07-12 19:10:31,093 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9109998902422376e-05, 1912
[INFO] 2021-07-12 19:10:31,093 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1912
[INFO] 2021-07-12 19:10:31,093 [run_pretraining.py:  558]:	worker_index: 3, step: 1912, cost: 7.628985, mlm loss: 7.628985, speed: 1.089096 steps/s, speed: 8.712771 samples/s, speed: 4460.938753 tokens/s, learning rate: 1.911e-05, loss_scalings: 5497.559082, pp_loss: 7.366977
[INFO] 2021-07-12 19:10:31,093 [run_pretraining.py:  512]:	********exe.run_1912******* 
[INFO] 2021-07-12 19:10:32,011 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:32,011 [run_pretraining.py:  534]:	loss/total_loss, 7.101518630981445, 1913
[INFO] 2021-07-12 19:10:32,011 [run_pretraining.py:  535]:	loss/mlm_loss, 7.101518630981445, 1913
[INFO] 2021-07-12 19:10:32,011 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.911999970616307e-05, 1913
[INFO] 2021-07-12 19:10:32,011 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1913
[INFO] 2021-07-12 19:10:32,011 [run_pretraining.py:  558]:	worker_index: 3, step: 1913, cost: 7.101519, mlm loss: 7.101519, speed: 1.089968 steps/s, speed: 8.719740 samples/s, speed: 4464.506947 tokens/s, learning rate: 1.912e-05, loss_scalings: 5497.559082, pp_loss: 7.310933
[INFO] 2021-07-12 19:10:32,012 [run_pretraining.py:  512]:	********exe.run_1913******* 
[INFO] 2021-07-12 19:10:32,957 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:32,958 [run_pretraining.py:  534]:	loss/total_loss, 7.595338344573975, 1914
[INFO] 2021-07-12 19:10:32,958 [run_pretraining.py:  535]:	loss/mlm_loss, 7.595338344573975, 1914
[INFO] 2021-07-12 19:10:32,958 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9130000509903766e-05, 1914
[INFO] 2021-07-12 19:10:32,958 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1914
[INFO] 2021-07-12 19:10:32,958 [run_pretraining.py:  558]:	worker_index: 3, step: 1914, cost: 7.595338, mlm loss: 7.595338, speed: 1.057395 steps/s, speed: 8.459157 samples/s, speed: 4331.088575 tokens/s, learning rate: 1.913e-05, loss_scalings: 5497.559082, pp_loss: 7.690199
[INFO] 2021-07-12 19:10:32,958 [run_pretraining.py:  512]:	********exe.run_1914******* 
[INFO] 2021-07-12 19:10:33,900 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:33,901 [run_pretraining.py:  534]:	loss/total_loss, 7.28678035736084, 1915
[INFO] 2021-07-12 19:10:33,901 [run_pretraining.py:  535]:	loss/mlm_loss, 7.28678035736084, 1915
[INFO] 2021-07-12 19:10:33,901 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9139999494655058e-05, 1915
[INFO] 2021-07-12 19:10:33,901 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1915
[INFO] 2021-07-12 19:10:33,901 [run_pretraining.py:  558]:	worker_index: 3, step: 1915, cost: 7.286780, mlm loss: 7.286780, speed: 1.061128 steps/s, speed: 8.489023 samples/s, speed: 4346.379533 tokens/s, learning rate: 1.914e-05, loss_scalings: 5497.559082, pp_loss: 7.531021
[INFO] 2021-07-12 19:10:33,901 [run_pretraining.py:  512]:	********exe.run_1915******* 
[INFO] 2021-07-12 19:10:34,835 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:34,836 [run_pretraining.py:  534]:	loss/total_loss, 7.454133033752441, 1916
[INFO] 2021-07-12 19:10:34,836 [run_pretraining.py:  535]:	loss/mlm_loss, 7.454133033752441, 1916
[INFO] 2021-07-12 19:10:34,836 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.914999847940635e-05, 1916
[INFO] 2021-07-12 19:10:34,836 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1916
[INFO] 2021-07-12 19:10:34,836 [run_pretraining.py:  558]:	worker_index: 3, step: 1916, cost: 7.454133, mlm loss: 7.454133, speed: 1.070009 steps/s, speed: 8.560073 samples/s, speed: 4382.757210 tokens/s, learning rate: 1.915e-05, loss_scalings: 5497.559082, pp_loss: 7.458605
[INFO] 2021-07-12 19:10:34,836 [run_pretraining.py:  512]:	********exe.run_1916******* 
[INFO] 2021-07-12 19:10:35,777 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:35,778 [run_pretraining.py:  534]:	loss/total_loss, 7.872296333312988, 1917
[INFO] 2021-07-12 19:10:35,778 [run_pretraining.py:  535]:	loss/mlm_loss, 7.872296333312988, 1917
[INFO] 2021-07-12 19:10:35,778 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9159999283147044e-05, 1917
[INFO] 2021-07-12 19:10:35,778 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1917
[INFO] 2021-07-12 19:10:35,778 [run_pretraining.py:  558]:	worker_index: 3, step: 1917, cost: 7.872296, mlm loss: 7.872296, speed: 1.062358 steps/s, speed: 8.498866 samples/s, speed: 4351.419347 tokens/s, learning rate: 1.916e-05, loss_scalings: 5497.559082, pp_loss: 7.837090
[INFO] 2021-07-12 19:10:35,778 [run_pretraining.py:  512]:	********exe.run_1917******* 
[INFO] 2021-07-12 19:10:36,703 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:36,704 [run_pretraining.py:  534]:	loss/total_loss, 6.621257781982422, 1918
[INFO] 2021-07-12 19:10:36,704 [run_pretraining.py:  535]:	loss/mlm_loss, 6.621257781982422, 1918
[INFO] 2021-07-12 19:10:36,704 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9169998267898336e-05, 1918
[INFO] 2021-07-12 19:10:36,704 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1918
[INFO] 2021-07-12 19:10:36,704 [run_pretraining.py:  558]:	worker_index: 3, step: 1918, cost: 6.621258, mlm loss: 6.621258, speed: 1.080778 steps/s, speed: 8.646227 samples/s, speed: 4426.868043 tokens/s, learning rate: 1.917e-05, loss_scalings: 5497.559082, pp_loss: 7.383962
[INFO] 2021-07-12 19:10:36,704 [run_pretraining.py:  512]:	********exe.run_1918******* 
[INFO] 2021-07-12 19:10:37,637 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:37,638 [run_pretraining.py:  534]:	loss/total_loss, 6.142390251159668, 1919
[INFO] 2021-07-12 19:10:37,638 [run_pretraining.py:  535]:	loss/mlm_loss, 6.142390251159668, 1919
[INFO] 2021-07-12 19:10:37,638 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.917999907163903e-05, 1919
[INFO] 2021-07-12 19:10:37,638 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1919
[INFO] 2021-07-12 19:10:37,638 [run_pretraining.py:  558]:	worker_index: 3, step: 1919, cost: 6.142390, mlm loss: 6.142390, speed: 1.071168 steps/s, speed: 8.569344 samples/s, speed: 4387.504146 tokens/s, learning rate: 1.918e-05, loss_scalings: 5497.559082, pp_loss: 6.908892
[INFO] 2021-07-12 19:10:37,638 [run_pretraining.py:  512]:	********exe.run_1919******* 
[INFO] 2021-07-12 19:10:38,587 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:38,587 [run_pretraining.py:  534]:	loss/total_loss, 7.1901140213012695, 1920
[INFO] 2021-07-12 19:10:38,588 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1901140213012695, 1920
[INFO] 2021-07-12 19:10:38,588 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9189999875379726e-05, 1920
[INFO] 2021-07-12 19:10:38,588 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1920
[INFO] 2021-07-12 19:10:38,588 [run_pretraining.py:  558]:	worker_index: 3, step: 1920, cost: 7.190114, mlm loss: 7.190114, speed: 1.053782 steps/s, speed: 8.430256 samples/s, speed: 4316.290852 tokens/s, learning rate: 1.919e-05, loss_scalings: 5497.559082, pp_loss: 7.330287
[INFO] 2021-07-12 19:10:38,588 [run_pretraining.py:  512]:	********exe.run_1920******* 
[INFO] 2021-07-12 19:10:39,499 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:39,500 [run_pretraining.py:  534]:	loss/total_loss, 6.68723201751709, 1921
[INFO] 2021-07-12 19:10:39,500 [run_pretraining.py:  535]:	loss/mlm_loss, 6.68723201751709, 1921
[INFO] 2021-07-12 19:10:39,500 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9199998860131018e-05, 1921
[INFO] 2021-07-12 19:10:39,500 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1921
[INFO] 2021-07-12 19:10:39,500 [run_pretraining.py:  558]:	worker_index: 3, step: 1921, cost: 6.687232, mlm loss: 6.687232, speed: 1.096888 steps/s, speed: 8.775105 samples/s, speed: 4492.853924 tokens/s, learning rate: 1.920e-05, loss_scalings: 5497.559082, pp_loss: 7.204350
[INFO] 2021-07-12 19:10:39,500 [run_pretraining.py:  512]:	********exe.run_1921******* 
[INFO] 2021-07-12 19:10:40,407 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:40,407 [run_pretraining.py:  534]:	loss/total_loss, 7.1265740394592285, 1922
[INFO] 2021-07-12 19:10:40,408 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1265740394592285, 1922
[INFO] 2021-07-12 19:10:40,408 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9209999663871713e-05, 1922
[INFO] 2021-07-12 19:10:40,408 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1922
[INFO] 2021-07-12 19:10:40,408 [run_pretraining.py:  558]:	worker_index: 3, step: 1922, cost: 7.126574, mlm loss: 7.126574, speed: 1.102442 steps/s, speed: 8.819535 samples/s, speed: 4515.601861 tokens/s, learning rate: 1.921e-05, loss_scalings: 5497.559082, pp_loss: 7.499998
[INFO] 2021-07-12 19:10:40,408 [run_pretraining.py:  512]:	********exe.run_1922******* 
[INFO] 2021-07-12 19:10:41,326 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:41,326 [run_pretraining.py:  534]:	loss/total_loss, 6.289830684661865, 1923
[INFO] 2021-07-12 19:10:41,326 [run_pretraining.py:  535]:	loss/mlm_loss, 6.289830684661865, 1923
[INFO] 2021-07-12 19:10:41,327 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9220000467612408e-05, 1923
[INFO] 2021-07-12 19:10:41,327 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1923
[INFO] 2021-07-12 19:10:41,327 [run_pretraining.py:  558]:	worker_index: 3, step: 1923, cost: 6.289831, mlm loss: 6.289831, speed: 1.089081 steps/s, speed: 8.712649 samples/s, speed: 4460.876204 tokens/s, learning rate: 1.922e-05, loss_scalings: 5497.559082, pp_loss: 6.987902
[INFO] 2021-07-12 19:10:41,327 [run_pretraining.py:  512]:	********exe.run_1923******* 
[INFO] 2021-07-12 19:10:42,234 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:42,235 [run_pretraining.py:  534]:	loss/total_loss, 7.09421443939209, 1924
[INFO] 2021-07-12 19:10:42,235 [run_pretraining.py:  535]:	loss/mlm_loss, 7.09421443939209, 1924
[INFO] 2021-07-12 19:10:42,235 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.92299994523637e-05, 1924
[INFO] 2021-07-12 19:10:42,235 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1924
[INFO] 2021-07-12 19:10:42,235 [run_pretraining.py:  558]:	worker_index: 3, step: 1924, cost: 7.094214, mlm loss: 7.094214, speed: 1.101861 steps/s, speed: 8.814889 samples/s, speed: 4513.223394 tokens/s, learning rate: 1.923e-05, loss_scalings: 5497.559082, pp_loss: 7.398768
[INFO] 2021-07-12 19:10:42,235 [run_pretraining.py:  512]:	********exe.run_1924******* 
[INFO] 2021-07-12 19:10:43,175 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:43,175 [run_pretraining.py:  534]:	loss/total_loss, 7.573342800140381, 1925
[INFO] 2021-07-12 19:10:43,176 [run_pretraining.py:  535]:	loss/mlm_loss, 7.573342800140381, 1925
[INFO] 2021-07-12 19:10:43,176 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.923999843711499e-05, 1925
[INFO] 2021-07-12 19:10:43,176 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1925
[INFO] 2021-07-12 19:10:43,176 [run_pretraining.py:  558]:	worker_index: 3, step: 1925, cost: 7.573343, mlm loss: 7.573343, speed: 1.063524 steps/s, speed: 8.508193 samples/s, speed: 4356.194702 tokens/s, learning rate: 1.924e-05, loss_scalings: 5497.559082, pp_loss: 6.896515
[INFO] 2021-07-12 19:10:43,176 [run_pretraining.py:  512]:	********exe.run_1925******* 
[INFO] 2021-07-12 19:10:44,116 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:44,116 [run_pretraining.py:  534]:	loss/total_loss, 8.08581829071045, 1926
[INFO] 2021-07-12 19:10:44,116 [run_pretraining.py:  535]:	loss/mlm_loss, 8.08581829071045, 1926
[INFO] 2021-07-12 19:10:44,116 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9249999240855686e-05, 1926
[INFO] 2021-07-12 19:10:44,116 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1926
[INFO] 2021-07-12 19:10:44,117 [run_pretraining.py:  558]:	worker_index: 3, step: 1926, cost: 8.085818, mlm loss: 8.085818, speed: 1.063673 steps/s, speed: 8.509386 samples/s, speed: 4356.805617 tokens/s, learning rate: 1.925e-05, loss_scalings: 5497.559082, pp_loss: 7.749693
[INFO] 2021-07-12 19:10:44,117 [run_pretraining.py:  512]:	********exe.run_1926******* 
[INFO] 2021-07-12 19:10:45,076 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:45,076 [run_pretraining.py:  534]:	loss/total_loss, 7.333727836608887, 1927
[INFO] 2021-07-12 19:10:45,076 [run_pretraining.py:  535]:	loss/mlm_loss, 7.333727836608887, 1927
[INFO] 2021-07-12 19:10:45,076 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.926000004459638e-05, 1927
[INFO] 2021-07-12 19:10:45,076 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1927
[INFO] 2021-07-12 19:10:45,076 [run_pretraining.py:  558]:	worker_index: 3, step: 1927, cost: 7.333728, mlm loss: 7.333728, speed: 1.042515 steps/s, speed: 8.340119 samples/s, speed: 4270.140698 tokens/s, learning rate: 1.926e-05, loss_scalings: 5497.559082, pp_loss: 7.631910
[INFO] 2021-07-12 19:10:45,077 [run_pretraining.py:  512]:	********exe.run_1927******* 
[INFO] 2021-07-12 19:10:46,061 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:46,062 [run_pretraining.py:  534]:	loss/total_loss, 7.034617900848389, 1928
[INFO] 2021-07-12 19:10:46,062 [run_pretraining.py:  535]:	loss/mlm_loss, 7.034617900848389, 1928
[INFO] 2021-07-12 19:10:46,062 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9269999029347673e-05, 1928
[INFO] 2021-07-12 19:10:46,062 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1928
[INFO] 2021-07-12 19:10:46,062 [run_pretraining.py:  558]:	worker_index: 3, step: 1928, cost: 7.034618, mlm loss: 7.034618, speed: 1.015032 steps/s, speed: 8.120256 samples/s, speed: 4157.571008 tokens/s, learning rate: 1.927e-05, loss_scalings: 5497.559082, pp_loss: 7.282016
[INFO] 2021-07-12 19:10:46,062 [run_pretraining.py:  512]:	********exe.run_1928******* 
[INFO] 2021-07-12 19:10:47,030 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:47,030 [run_pretraining.py:  534]:	loss/total_loss, 7.387570381164551, 1929
[INFO] 2021-07-12 19:10:47,030 [run_pretraining.py:  535]:	loss/mlm_loss, 7.387570381164551, 1929
[INFO] 2021-07-12 19:10:47,030 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9279999833088368e-05, 1929
[INFO] 2021-07-12 19:10:47,030 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1929
[INFO] 2021-07-12 19:10:47,030 [run_pretraining.py:  558]:	worker_index: 3, step: 1929, cost: 7.387570, mlm loss: 7.387570, speed: 1.033592 steps/s, speed: 8.268734 samples/s, speed: 4233.591856 tokens/s, learning rate: 1.928e-05, loss_scalings: 5497.559082, pp_loss: 7.417089
[INFO] 2021-07-12 19:10:47,030 [run_pretraining.py:  512]:	********exe.run_1929******* 
[INFO] 2021-07-12 19:10:47,994 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:47,994 [run_pretraining.py:  534]:	loss/total_loss, 7.008607864379883, 1930
[INFO] 2021-07-12 19:10:47,994 [run_pretraining.py:  535]:	loss/mlm_loss, 7.008607864379883, 1930
[INFO] 2021-07-12 19:10:47,995 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.928999881783966e-05, 1930
[INFO] 2021-07-12 19:10:47,995 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1930
[INFO] 2021-07-12 19:10:47,995 [run_pretraining.py:  558]:	worker_index: 3, step: 1930, cost: 7.008608, mlm loss: 7.008608, speed: 1.037725 steps/s, speed: 8.301802 samples/s, speed: 4250.522767 tokens/s, learning rate: 1.929e-05, loss_scalings: 5497.559082, pp_loss: 7.250685
[INFO] 2021-07-12 19:10:47,995 [run_pretraining.py:  512]:	********exe.run_1930******* 
[INFO] 2021-07-12 19:10:48,964 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:48,964 [run_pretraining.py:  534]:	loss/total_loss, 6.8287739753723145, 1931
[INFO] 2021-07-12 19:10:48,964 [run_pretraining.py:  535]:	loss/mlm_loss, 6.8287739753723145, 1931
[INFO] 2021-07-12 19:10:48,964 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9299999621580355e-05, 1931
[INFO] 2021-07-12 19:10:48,964 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1931
[INFO] 2021-07-12 19:10:48,964 [run_pretraining.py:  558]:	worker_index: 3, step: 1931, cost: 6.828774, mlm loss: 6.828774, speed: 1.031782 steps/s, speed: 8.254256 samples/s, speed: 4226.178840 tokens/s, learning rate: 1.930e-05, loss_scalings: 5497.559082, pp_loss: 7.152523
[INFO] 2021-07-12 19:10:48,965 [run_pretraining.py:  512]:	********exe.run_1931******* 
[INFO] 2021-07-12 19:10:49,930 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:49,931 [run_pretraining.py:  534]:	loss/total_loss, 6.63092041015625, 1932
[INFO] 2021-07-12 19:10:49,931 [run_pretraining.py:  535]:	loss/mlm_loss, 6.63092041015625, 1932
[INFO] 2021-07-12 19:10:49,931 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.931000042532105e-05, 1932
[INFO] 2021-07-12 19:10:49,931 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1932
[INFO] 2021-07-12 19:10:49,931 [run_pretraining.py:  558]:	worker_index: 3, step: 1932, cost: 6.630920, mlm loss: 6.630920, speed: 1.035278 steps/s, speed: 8.282225 samples/s, speed: 4240.499145 tokens/s, learning rate: 1.931e-05, loss_scalings: 5497.559082, pp_loss: 7.132848
[INFO] 2021-07-12 19:10:49,931 [run_pretraining.py:  512]:	********exe.run_1932******* 
[INFO] 2021-07-12 19:10:50,879 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:50,879 [run_pretraining.py:  534]:	loss/total_loss, 6.972857475280762, 1933
[INFO] 2021-07-12 19:10:50,879 [run_pretraining.py:  535]:	loss/mlm_loss, 6.972857475280762, 1933
[INFO] 2021-07-12 19:10:50,879 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.931999941007234e-05, 1933
[INFO] 2021-07-12 19:10:50,879 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1933
[INFO] 2021-07-12 19:10:50,879 [run_pretraining.py:  558]:	worker_index: 3, step: 1933, cost: 6.972857, mlm loss: 6.972857, speed: 1.055150 steps/s, speed: 8.441201 samples/s, speed: 4321.894862 tokens/s, learning rate: 1.932e-05, loss_scalings: 5497.559082, pp_loss: 7.404519
[INFO] 2021-07-12 19:10:50,880 [run_pretraining.py:  512]:	********exe.run_1933******* 
[INFO] 2021-07-12 19:10:51,828 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:51,829 [run_pretraining.py:  534]:	loss/total_loss, 6.961036682128906, 1934
[INFO] 2021-07-12 19:10:51,829 [run_pretraining.py:  535]:	loss/mlm_loss, 6.961036682128906, 1934
[INFO] 2021-07-12 19:10:51,829 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9329998394823633e-05, 1934
[INFO] 2021-07-12 19:10:51,829 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1934
[INFO] 2021-07-12 19:10:51,829 [run_pretraining.py:  558]:	worker_index: 3, step: 1934, cost: 6.961037, mlm loss: 6.961037, speed: 1.053874 steps/s, speed: 8.430993 samples/s, speed: 4316.668267 tokens/s, learning rate: 1.933e-05, loss_scalings: 5497.559082, pp_loss: 7.458928
[INFO] 2021-07-12 19:10:51,829 [run_pretraining.py:  512]:	********exe.run_1934******* 
[INFO] 2021-07-12 19:10:52,770 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:52,771 [run_pretraining.py:  534]:	loss/total_loss, 7.860978126525879, 1935
[INFO] 2021-07-12 19:10:52,771 [run_pretraining.py:  535]:	loss/mlm_loss, 7.860978126525879, 1935
[INFO] 2021-07-12 19:10:52,771 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9339999198564328e-05, 1935
[INFO] 2021-07-12 19:10:52,771 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1935
[INFO] 2021-07-12 19:10:52,771 [run_pretraining.py:  558]:	worker_index: 3, step: 1935, cost: 7.860978, mlm loss: 7.860978, speed: 1.062137 steps/s, speed: 8.497097 samples/s, speed: 4350.513566 tokens/s, learning rate: 1.934e-05, loss_scalings: 5497.559082, pp_loss: 7.125539
[INFO] 2021-07-12 19:10:52,771 [run_pretraining.py:  512]:	********exe.run_1935******* 
[INFO] 2021-07-12 19:10:53,715 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:53,715 [run_pretraining.py:  534]:	loss/total_loss, 6.975200653076172, 1936
[INFO] 2021-07-12 19:10:53,715 [run_pretraining.py:  535]:	loss/mlm_loss, 6.975200653076172, 1936
[INFO] 2021-07-12 19:10:53,716 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9350000002305023e-05, 1936
[INFO] 2021-07-12 19:10:53,716 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1936
[INFO] 2021-07-12 19:10:53,716 [run_pretraining.py:  558]:	worker_index: 3, step: 1936, cost: 6.975201, mlm loss: 6.975201, speed: 1.059413 steps/s, speed: 8.475306 samples/s, speed: 4339.356746 tokens/s, learning rate: 1.935e-05, loss_scalings: 5497.559082, pp_loss: 6.918437
[INFO] 2021-07-12 19:10:53,716 [run_pretraining.py:  512]:	********exe.run_1936******* 
[INFO] 2021-07-12 19:10:54,646 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:54,646 [run_pretraining.py:  534]:	loss/total_loss, 7.632158279418945, 1937
[INFO] 2021-07-12 19:10:54,646 [run_pretraining.py:  535]:	loss/mlm_loss, 7.632158279418945, 1937
[INFO] 2021-07-12 19:10:54,646 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9359998987056315e-05, 1937
[INFO] 2021-07-12 19:10:54,646 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1937
[INFO] 2021-07-12 19:10:54,647 [run_pretraining.py:  558]:	worker_index: 3, step: 1937, cost: 7.632158, mlm loss: 7.632158, speed: 1.075033 steps/s, speed: 8.600265 samples/s, speed: 4403.335586 tokens/s, learning rate: 1.936e-05, loss_scalings: 5497.559082, pp_loss: 7.236451
[INFO] 2021-07-12 19:10:54,647 [run_pretraining.py:  512]:	********exe.run_1937******* 
[INFO] 2021-07-12 19:10:55,565 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:55,565 [run_pretraining.py:  534]:	loss/total_loss, 7.377388000488281, 1938
[INFO] 2021-07-12 19:10:55,565 [run_pretraining.py:  535]:	loss/mlm_loss, 7.377388000488281, 1938
[INFO] 2021-07-12 19:10:55,565 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.936999979079701e-05, 1938
[INFO] 2021-07-12 19:10:55,565 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1938
[INFO] 2021-07-12 19:10:55,565 [run_pretraining.py:  558]:	worker_index: 3, step: 1938, cost: 7.377388, mlm loss: 7.377388, speed: 1.089021 steps/s, speed: 8.712167 samples/s, speed: 4460.629500 tokens/s, learning rate: 1.937e-05, loss_scalings: 5497.559082, pp_loss: 7.428716
[INFO] 2021-07-12 19:10:55,565 [run_pretraining.py:  512]:	********exe.run_1938******* 
[INFO] 2021-07-12 19:10:56,495 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:56,496 [run_pretraining.py:  534]:	loss/total_loss, 7.234392166137695, 1939
[INFO] 2021-07-12 19:10:56,496 [run_pretraining.py:  535]:	loss/mlm_loss, 7.234392166137695, 1939
[INFO] 2021-07-12 19:10:56,496 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9380000594537705e-05, 1939
[INFO] 2021-07-12 19:10:56,496 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1939
[INFO] 2021-07-12 19:10:56,496 [run_pretraining.py:  558]:	worker_index: 3, step: 1939, cost: 7.234392, mlm loss: 7.234392, speed: 1.075465 steps/s, speed: 8.603718 samples/s, speed: 4405.103699 tokens/s, learning rate: 1.938e-05, loss_scalings: 5497.559082, pp_loss: 7.034322
[INFO] 2021-07-12 19:10:56,496 [run_pretraining.py:  512]:	********exe.run_1939******* 
[INFO] 2021-07-12 19:10:57,428 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:57,429 [run_pretraining.py:  534]:	loss/total_loss, 7.404456615447998, 1940
[INFO] 2021-07-12 19:10:57,429 [run_pretraining.py:  535]:	loss/mlm_loss, 7.404456615447998, 1940
[INFO] 2021-07-12 19:10:57,429 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9389999579288997e-05, 1940
[INFO] 2021-07-12 19:10:57,429 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1940
[INFO] 2021-07-12 19:10:57,429 [run_pretraining.py:  558]:	worker_index: 3, step: 1940, cost: 7.404457, mlm loss: 7.404457, speed: 1.072546 steps/s, speed: 8.580371 samples/s, speed: 4393.149801 tokens/s, learning rate: 1.939e-05, loss_scalings: 5497.559082, pp_loss: 7.538546
[INFO] 2021-07-12 19:10:57,429 [run_pretraining.py:  512]:	********exe.run_1940******* 
[INFO] 2021-07-12 19:10:58,345 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:58,346 [run_pretraining.py:  534]:	loss/total_loss, 6.827324390411377, 1941
[INFO] 2021-07-12 19:10:58,346 [run_pretraining.py:  535]:	loss/mlm_loss, 6.827324390411377, 1941
[INFO] 2021-07-12 19:10:58,346 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9400000383029692e-05, 1941
[INFO] 2021-07-12 19:10:58,346 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1941
[INFO] 2021-07-12 19:10:58,346 [run_pretraining.py:  558]:	worker_index: 3, step: 1941, cost: 6.827324, mlm loss: 6.827324, speed: 1.091013 steps/s, speed: 8.728103 samples/s, speed: 4468.788651 tokens/s, learning rate: 1.940e-05, loss_scalings: 5497.559082, pp_loss: 6.851647
[INFO] 2021-07-12 19:10:58,346 [run_pretraining.py:  512]:	********exe.run_1941******* 
[INFO] 2021-07-12 19:10:59,283 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:59,283 [run_pretraining.py:  534]:	loss/total_loss, 8.049379348754883, 1942
[INFO] 2021-07-12 19:10:59,283 [run_pretraining.py:  535]:	loss/mlm_loss, 8.049379348754883, 1942
[INFO] 2021-07-12 19:10:59,283 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9409999367780983e-05, 1942
[INFO] 2021-07-12 19:10:59,283 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1942
[INFO] 2021-07-12 19:10:59,283 [run_pretraining.py:  558]:	worker_index: 3, step: 1942, cost: 8.049379, mlm loss: 8.049379, speed: 1.067544 steps/s, speed: 8.540355 samples/s, speed: 4372.661845 tokens/s, learning rate: 1.941e-05, loss_scalings: 5497.559082, pp_loss: 7.668745
[INFO] 2021-07-12 19:10:59,284 [run_pretraining.py:  512]:	********exe.run_1942******* 
[INFO] 2021-07-12 19:11:00,208 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:00,208 [run_pretraining.py:  534]:	loss/total_loss, 7.049497127532959, 1943
[INFO] 2021-07-12 19:11:00,208 [run_pretraining.py:  535]:	loss/mlm_loss, 7.049497127532959, 1943
[INFO] 2021-07-12 19:11:00,208 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9419998352532275e-05, 1943
[INFO] 2021-07-12 19:11:00,208 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1943
[INFO] 2021-07-12 19:11:00,209 [run_pretraining.py:  558]:	worker_index: 3, step: 1943, cost: 7.049497, mlm loss: 7.049497, speed: 1.081760 steps/s, speed: 8.654081 samples/s, speed: 4430.889255 tokens/s, learning rate: 1.942e-05, loss_scalings: 5497.559082, pp_loss: 7.228031
[INFO] 2021-07-12 19:11:00,209 [run_pretraining.py:  512]:	********exe.run_1943******* 
[INFO] 2021-07-12 19:11:01,136 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:01,137 [run_pretraining.py:  534]:	loss/total_loss, 7.403316497802734, 1944
[INFO] 2021-07-12 19:11:01,137 [run_pretraining.py:  535]:	loss/mlm_loss, 7.403316497802734, 1944
[INFO] 2021-07-12 19:11:01,137 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.942999915627297e-05, 1944
[INFO] 2021-07-12 19:11:01,137 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1944
[INFO] 2021-07-12 19:11:01,137 [run_pretraining.py:  558]:	worker_index: 3, step: 1944, cost: 7.403316, mlm loss: 7.403316, speed: 1.077589 steps/s, speed: 8.620710 samples/s, speed: 4413.803436 tokens/s, learning rate: 1.943e-05, loss_scalings: 5497.559082, pp_loss: 6.250417
[INFO] 2021-07-12 19:11:01,137 [run_pretraining.py:  512]:	********exe.run_1944******* 
[INFO] 2021-07-12 19:11:02,064 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:02,064 [run_pretraining.py:  534]:	loss/total_loss, 7.087691783905029, 1945
[INFO] 2021-07-12 19:11:02,064 [run_pretraining.py:  535]:	loss/mlm_loss, 7.087691783905029, 1945
[INFO] 2021-07-12 19:11:02,064 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9439999960013665e-05, 1945
[INFO] 2021-07-12 19:11:02,064 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1945
[INFO] 2021-07-12 19:11:02,065 [run_pretraining.py:  558]:	worker_index: 3, step: 1945, cost: 7.087692, mlm loss: 7.087692, speed: 1.078993 steps/s, speed: 8.631940 samples/s, speed: 4419.553401 tokens/s, learning rate: 1.944e-05, loss_scalings: 4398.047363, pp_loss: 7.000155
[INFO] 2021-07-12 19:11:02,065 [run_pretraining.py:  512]:	********exe.run_1945******* 
[INFO] 2021-07-12 19:11:02,997 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:02,998 [run_pretraining.py:  534]:	loss/total_loss, 7.817437648773193, 1946
[INFO] 2021-07-12 19:11:02,998 [run_pretraining.py:  535]:	loss/mlm_loss, 7.817437648773193, 1946
[INFO] 2021-07-12 19:11:02,998 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9449998944764957e-05, 1946
[INFO] 2021-07-12 19:11:02,998 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1946
[INFO] 2021-07-12 19:11:02,998 [run_pretraining.py:  558]:	worker_index: 3, step: 1946, cost: 7.817438, mlm loss: 7.817438, speed: 1.072001 steps/s, speed: 8.576009 samples/s, speed: 4390.916506 tokens/s, learning rate: 1.945e-05, loss_scalings: 4398.047363, pp_loss: 7.665646
[INFO] 2021-07-12 19:11:02,998 [run_pretraining.py:  512]:	********exe.run_1946******* 
[INFO] 2021-07-12 19:11:29,618 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:29,619 [run_pretraining.py:  534]:	loss/total_loss, 7.02689266204834, 1947
[INFO] 2021-07-12 19:11:29,619 [run_pretraining.py:  535]:	loss/mlm_loss, 7.02689266204834, 1947
[INFO] 2021-07-12 19:11:29,619 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9459999748505652e-05, 1947
[INFO] 2021-07-12 19:11:29,619 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1947
[INFO] 2021-07-12 19:11:29,619 [run_pretraining.py:  558]:	worker_index: 3, step: 1947, cost: 7.026893, mlm loss: 7.026893, speed: 0.037565 steps/s, speed: 0.300522 samples/s, speed: 153.867126 tokens/s, learning rate: 1.946e-05, loss_scalings: 4398.047363, pp_loss: 7.120728
[INFO] 2021-07-12 19:11:29,619 [run_pretraining.py:  512]:	********exe.run_1947******* 
[INFO] 2021-07-12 19:11:30,532 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:30,532 [run_pretraining.py:  534]:	loss/total_loss, 7.419818878173828, 1948
[INFO] 2021-07-12 19:11:30,533 [run_pretraining.py:  535]:	loss/mlm_loss, 7.419818878173828, 1948
[INFO] 2021-07-12 19:11:30,533 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9470000552246347e-05, 1948
[INFO] 2021-07-12 19:11:30,533 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1948
[INFO] 2021-07-12 19:11:30,533 [run_pretraining.py:  558]:	worker_index: 3, step: 1948, cost: 7.419819, mlm loss: 7.419819, speed: 1.095193 steps/s, speed: 8.761548 samples/s, speed: 4485.912400 tokens/s, learning rate: 1.947e-05, loss_scalings: 4398.047363, pp_loss: 7.531290
[INFO] 2021-07-12 19:11:30,533 [run_pretraining.py:  512]:	********exe.run_1948******* 
[INFO] 2021-07-12 19:11:31,460 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:31,461 [run_pretraining.py:  534]:	loss/total_loss, 7.821188926696777, 1949
[INFO] 2021-07-12 19:11:31,461 [run_pretraining.py:  535]:	loss/mlm_loss, 7.821188926696777, 1949
[INFO] 2021-07-12 19:11:31,461 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.947999953699764e-05, 1949
[INFO] 2021-07-12 19:11:31,461 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1949
[INFO] 2021-07-12 19:11:31,461 [run_pretraining.py:  558]:	worker_index: 3, step: 1949, cost: 7.821189, mlm loss: 7.821189, speed: 1.077664 steps/s, speed: 8.621315 samples/s, speed: 4414.113035 tokens/s, learning rate: 1.948e-05, loss_scalings: 4398.047363, pp_loss: 7.356305
[INFO] 2021-07-12 19:11:31,461 [run_pretraining.py:  512]:	********exe.run_1949******* 
[INFO] 2021-07-12 19:11:32,380 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:32,380 [run_pretraining.py:  534]:	loss/total_loss, 7.451747417449951, 1950
[INFO] 2021-07-12 19:11:32,380 [run_pretraining.py:  535]:	loss/mlm_loss, 7.451747417449951, 1950
[INFO] 2021-07-12 19:11:32,380 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9490000340738334e-05, 1950
[INFO] 2021-07-12 19:11:32,380 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1950
[INFO] 2021-07-12 19:11:32,381 [run_pretraining.py:  558]:	worker_index: 3, step: 1950, cost: 7.451747, mlm loss: 7.451747, speed: 1.088653 steps/s, speed: 8.709225 samples/s, speed: 4459.123229 tokens/s, learning rate: 1.949e-05, loss_scalings: 4398.047363, pp_loss: 7.122116
[INFO] 2021-07-12 19:11:32,381 [run_pretraining.py:  512]:	********exe.run_1950******* 
[INFO] 2021-07-12 19:11:33,304 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:33,304 [run_pretraining.py:  534]:	loss/total_loss, 7.505865097045898, 1951
[INFO] 2021-07-12 19:11:33,305 [run_pretraining.py:  535]:	loss/mlm_loss, 7.505865097045898, 1951
[INFO] 2021-07-12 19:11:33,305 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9499999325489625e-05, 1951
[INFO] 2021-07-12 19:11:33,305 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1951
[INFO] 2021-07-12 19:11:33,305 [run_pretraining.py:  558]:	worker_index: 3, step: 1951, cost: 7.505865, mlm loss: 7.505865, speed: 1.082609 steps/s, speed: 8.660869 samples/s, speed: 4434.364882 tokens/s, learning rate: 1.950e-05, loss_scalings: 4398.047363, pp_loss: 7.274226
[INFO] 2021-07-12 19:11:33,305 [run_pretraining.py:  512]:	********exe.run_1951******* 
[INFO] 2021-07-12 19:11:34,233 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:34,233 [run_pretraining.py:  534]:	loss/total_loss, 7.879731178283691, 1952
[INFO] 2021-07-12 19:11:34,234 [run_pretraining.py:  535]:	loss/mlm_loss, 7.879731178283691, 1952
[INFO] 2021-07-12 19:11:34,234 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9509998310240917e-05, 1952
[INFO] 2021-07-12 19:11:34,234 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1952
[INFO] 2021-07-12 19:11:34,234 [run_pretraining.py:  558]:	worker_index: 3, step: 1952, cost: 7.879731, mlm loss: 7.879731, speed: 1.077259 steps/s, speed: 8.618075 samples/s, speed: 4412.454410 tokens/s, learning rate: 1.951e-05, loss_scalings: 4398.047363, pp_loss: 7.575530
[INFO] 2021-07-12 19:11:34,234 [run_pretraining.py:  512]:	********exe.run_1952******* 
[INFO] 2021-07-12 19:11:35,158 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:35,159 [run_pretraining.py:  534]:	loss/total_loss, 6.38696813583374, 1953
[INFO] 2021-07-12 19:11:35,159 [run_pretraining.py:  535]:	loss/mlm_loss, 6.38696813583374, 1953
[INFO] 2021-07-12 19:11:35,159 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9519999113981612e-05, 1953
[INFO] 2021-07-12 19:11:35,159 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1953
[INFO] 2021-07-12 19:11:35,159 [run_pretraining.py:  558]:	worker_index: 3, step: 1953, cost: 6.386968, mlm loss: 6.386968, speed: 1.081313 steps/s, speed: 8.650502 samples/s, speed: 4429.056997 tokens/s, learning rate: 1.952e-05, loss_scalings: 4398.047363, pp_loss: 6.725839
[INFO] 2021-07-12 19:11:35,159 [run_pretraining.py:  512]:	********exe.run_1953******* 
[INFO] 2021-07-12 19:11:36,087 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:36,088 [run_pretraining.py:  534]:	loss/total_loss, 7.717412948608398, 1954
[INFO] 2021-07-12 19:11:36,088 [run_pretraining.py:  535]:	loss/mlm_loss, 7.717412948608398, 1954
[INFO] 2021-07-12 19:11:36,088 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9529999917722307e-05, 1954
[INFO] 2021-07-12 19:11:36,088 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1954
[INFO] 2021-07-12 19:11:36,088 [run_pretraining.py:  558]:	worker_index: 3, step: 1954, cost: 7.717413, mlm loss: 7.717413, speed: 1.077049 steps/s, speed: 8.616395 samples/s, speed: 4411.594412 tokens/s, learning rate: 1.953e-05, loss_scalings: 4398.047363, pp_loss: 7.383812
[INFO] 2021-07-12 19:11:36,088 [run_pretraining.py:  512]:	********exe.run_1954******* 
[INFO] 2021-07-12 19:11:37,034 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:37,034 [run_pretraining.py:  534]:	loss/total_loss, 6.836041450500488, 1955
[INFO] 2021-07-12 19:11:37,034 [run_pretraining.py:  535]:	loss/mlm_loss, 6.836041450500488, 1955
[INFO] 2021-07-12 19:11:37,034 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.95399989024736e-05, 1955
[INFO] 2021-07-12 19:11:37,035 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1955
[INFO] 2021-07-12 19:11:37,035 [run_pretraining.py:  558]:	worker_index: 3, step: 1955, cost: 6.836041, mlm loss: 6.836041, speed: 1.057449 steps/s, speed: 8.459590 samples/s, speed: 4331.310237 tokens/s, learning rate: 1.954e-05, loss_scalings: 4398.047363, pp_loss: 7.289812
[INFO] 2021-07-12 19:11:37,035 [run_pretraining.py:  512]:	********exe.run_1955******* 
[INFO] 2021-07-12 19:11:37,973 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:37,973 [run_pretraining.py:  534]:	loss/total_loss, 6.994363784790039, 1956
[INFO] 2021-07-12 19:11:37,973 [run_pretraining.py:  535]:	loss/mlm_loss, 6.994363784790039, 1956
[INFO] 2021-07-12 19:11:37,974 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9549999706214294e-05, 1956
[INFO] 2021-07-12 19:11:37,974 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1956
[INFO] 2021-07-12 19:11:37,974 [run_pretraining.py:  558]:	worker_index: 3, step: 1956, cost: 6.994364, mlm loss: 6.994364, speed: 1.065546 steps/s, speed: 8.524367 samples/s, speed: 4364.475940 tokens/s, learning rate: 1.955e-05, loss_scalings: 4398.047363, pp_loss: 7.161964
[INFO] 2021-07-12 19:11:37,974 [run_pretraining.py:  512]:	********exe.run_1956******* 
[INFO] 2021-07-12 19:11:38,903 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:38,903 [run_pretraining.py:  534]:	loss/total_loss, 7.233831405639648, 1957
[INFO] 2021-07-12 19:11:38,903 [run_pretraining.py:  535]:	loss/mlm_loss, 7.233831405639648, 1957
[INFO] 2021-07-12 19:11:38,903 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.956000050995499e-05, 1957
[INFO] 2021-07-12 19:11:38,903 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1957
[INFO] 2021-07-12 19:11:38,903 [run_pretraining.py:  558]:	worker_index: 3, step: 1957, cost: 7.233831, mlm loss: 7.233831, speed: 1.076361 steps/s, speed: 8.610885 samples/s, speed: 4408.773162 tokens/s, learning rate: 1.956e-05, loss_scalings: 4398.047363, pp_loss: 7.327349
[INFO] 2021-07-12 19:11:38,903 [run_pretraining.py:  512]:	********exe.run_1957******* 
[INFO] 2021-07-12 19:11:39,823 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:39,824 [run_pretraining.py:  534]:	loss/total_loss, 7.663879871368408, 1958
[INFO] 2021-07-12 19:11:39,824 [run_pretraining.py:  535]:	loss/mlm_loss, 7.663879871368408, 1958
[INFO] 2021-07-12 19:11:39,824 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.956999949470628e-05, 1958
[INFO] 2021-07-12 19:11:39,824 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1958
[INFO] 2021-07-12 19:11:39,824 [run_pretraining.py:  558]:	worker_index: 3, step: 1958, cost: 7.663880, mlm loss: 7.663880, speed: 1.086989 steps/s, speed: 8.695911 samples/s, speed: 4452.306233 tokens/s, learning rate: 1.957e-05, loss_scalings: 4398.047363, pp_loss: 7.372289
[INFO] 2021-07-12 19:11:39,824 [run_pretraining.py:  512]:	********exe.run_1958******* 
[INFO] 2021-07-12 19:11:40,746 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:40,746 [run_pretraining.py:  534]:	loss/total_loss, 6.722010612487793, 1959
[INFO] 2021-07-12 19:11:40,746 [run_pretraining.py:  535]:	loss/mlm_loss, 6.722010612487793, 1959
[INFO] 2021-07-12 19:11:40,746 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9580000298446976e-05, 1959
[INFO] 2021-07-12 19:11:40,746 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1959
[INFO] 2021-07-12 19:11:40,746 [run_pretraining.py:  558]:	worker_index: 3, step: 1959, cost: 6.722011, mlm loss: 6.722011, speed: 1.084857 steps/s, speed: 8.678857 samples/s, speed: 4443.574882 tokens/s, learning rate: 1.958e-05, loss_scalings: 4398.047363, pp_loss: 7.144860
[INFO] 2021-07-12 19:11:40,747 [run_pretraining.py:  512]:	********exe.run_1959******* 
[INFO] 2021-07-12 19:11:41,679 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:41,679 [run_pretraining.py:  534]:	loss/total_loss, 7.437681198120117, 1960
[INFO] 2021-07-12 19:11:41,679 [run_pretraining.py:  535]:	loss/mlm_loss, 7.437681198120117, 1960
[INFO] 2021-07-12 19:11:41,679 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9589999283198267e-05, 1960
[INFO] 2021-07-12 19:11:41,680 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1960
[INFO] 2021-07-12 19:11:41,680 [run_pretraining.py:  558]:	worker_index: 3, step: 1960, cost: 7.437681, mlm loss: 7.437681, speed: 1.072346 steps/s, speed: 8.578767 samples/s, speed: 4392.328753 tokens/s, learning rate: 1.959e-05, loss_scalings: 4398.047363, pp_loss: 7.024994
[INFO] 2021-07-12 19:11:41,680 [run_pretraining.py:  512]:	********exe.run_1960******* 
[INFO] 2021-07-12 19:11:42,593 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:42,593 [run_pretraining.py:  534]:	loss/total_loss, 7.280470371246338, 1961
[INFO] 2021-07-12 19:11:42,593 [run_pretraining.py:  535]:	loss/mlm_loss, 7.280470371246338, 1961
[INFO] 2021-07-12 19:11:42,593 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.959999826794956e-05, 1961
[INFO] 2021-07-12 19:11:42,593 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1961
[INFO] 2021-07-12 19:11:42,594 [run_pretraining.py:  558]:	worker_index: 3, step: 1961, cost: 7.280470, mlm loss: 7.280470, speed: 1.094978 steps/s, speed: 8.759828 samples/s, speed: 4485.031728 tokens/s, learning rate: 1.960e-05, loss_scalings: 4398.047363, pp_loss: 7.056875
[INFO] 2021-07-12 19:11:42,594 [run_pretraining.py:  512]:	********exe.run_1961******* 
[INFO] 2021-07-12 19:11:43,521 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:43,521 [run_pretraining.py:  534]:	loss/total_loss, 7.696839332580566, 1962
[INFO] 2021-07-12 19:11:43,522 [run_pretraining.py:  535]:	loss/mlm_loss, 7.696839332580566, 1962
[INFO] 2021-07-12 19:11:43,522 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9609999071690254e-05, 1962
[INFO] 2021-07-12 19:11:43,522 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1962
[INFO] 2021-07-12 19:11:43,522 [run_pretraining.py:  558]:	worker_index: 3, step: 1962, cost: 7.696839, mlm loss: 7.696839, speed: 1.078003 steps/s, speed: 8.624027 samples/s, speed: 4415.501660 tokens/s, learning rate: 1.961e-05, loss_scalings: 4398.047363, pp_loss: 7.585419
[INFO] 2021-07-12 19:11:43,522 [run_pretraining.py:  512]:	********exe.run_1962******* 
[INFO] 2021-07-12 19:11:44,444 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:44,444 [run_pretraining.py:  534]:	loss/total_loss, 7.687038421630859, 1963
[INFO] 2021-07-12 19:11:44,445 [run_pretraining.py:  535]:	loss/mlm_loss, 7.687038421630859, 1963
[INFO] 2021-07-12 19:11:44,445 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.961999987543095e-05, 1963
[INFO] 2021-07-12 19:11:44,445 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1963
[INFO] 2021-07-12 19:11:44,445 [run_pretraining.py:  558]:	worker_index: 3, step: 1963, cost: 7.687038, mlm loss: 7.687038, speed: 1.084197 steps/s, speed: 8.673576 samples/s, speed: 4440.871003 tokens/s, learning rate: 1.962e-05, loss_scalings: 4398.047363, pp_loss: 6.603971
[INFO] 2021-07-12 19:11:44,445 [run_pretraining.py:  512]:	********exe.run_1963******* 
[INFO] 2021-07-12 19:11:45,377 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:45,378 [run_pretraining.py:  534]:	loss/total_loss, 7.202116012573242, 1964
[INFO] 2021-07-12 19:11:45,378 [run_pretraining.py:  535]:	loss/mlm_loss, 7.202116012573242, 1964
[INFO] 2021-07-12 19:11:45,378 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.962999886018224e-05, 1964
[INFO] 2021-07-12 19:11:45,378 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1964
[INFO] 2021-07-12 19:11:45,378 [run_pretraining.py:  558]:	worker_index: 3, step: 1964, cost: 7.202116, mlm loss: 7.202116, speed: 1.072323 steps/s, speed: 8.578585 samples/s, speed: 4392.235548 tokens/s, learning rate: 1.963e-05, loss_scalings: 4398.047363, pp_loss: 7.066648
[INFO] 2021-07-12 19:11:45,378 [run_pretraining.py:  512]:	********exe.run_1964******* 
[INFO] 2021-07-12 19:11:46,303 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:46,304 [run_pretraining.py:  534]:	loss/total_loss, 8.193748474121094, 1965
[INFO] 2021-07-12 19:11:46,304 [run_pretraining.py:  535]:	loss/mlm_loss, 8.193748474121094, 1965
[INFO] 2021-07-12 19:11:46,306 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9639999663922936e-05, 1965
[INFO] 2021-07-12 19:11:46,309 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1965
[INFO] 2021-07-12 19:11:46,310 [run_pretraining.py:  558]:	worker_index: 3, step: 1965, cost: 8.193748, mlm loss: 8.193748, speed: 1.080575 steps/s, speed: 8.644596 samples/s, speed: 4426.033204 tokens/s, learning rate: 1.964e-05, loss_scalings: 4398.047363, pp_loss: 7.619065
[INFO] 2021-07-12 19:11:46,311 [run_pretraining.py:  512]:	********exe.run_1965******* 
[INFO] 2021-07-12 19:11:47,241 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:47,242 [run_pretraining.py:  534]:	loss/total_loss, 7.983399391174316, 1966
[INFO] 2021-07-12 19:11:47,242 [run_pretraining.py:  535]:	loss/mlm_loss, 7.983399391174316, 1966
[INFO] 2021-07-12 19:11:47,242 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.965000046766363e-05, 1966
[INFO] 2021-07-12 19:11:47,242 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1966
[INFO] 2021-07-12 19:11:47,242 [run_pretraining.py:  558]:	worker_index: 3, step: 1966, cost: 7.983399, mlm loss: 7.983399, speed: 1.074127 steps/s, speed: 8.593014 samples/s, speed: 4399.623336 tokens/s, learning rate: 1.965e-05, loss_scalings: 3518.437988, pp_loss: 7.463923
[INFO] 2021-07-12 19:11:47,242 [run_pretraining.py:  512]:	********exe.run_1966******* 
[INFO] 2021-07-12 19:11:48,163 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:48,164 [run_pretraining.py:  534]:	loss/total_loss, 7.5575270652771, 1967
[INFO] 2021-07-12 19:11:48,164 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5575270652771, 1967
[INFO] 2021-07-12 19:11:48,164 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9659999452414922e-05, 1967
[INFO] 2021-07-12 19:11:48,164 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1967
[INFO] 2021-07-12 19:11:48,164 [run_pretraining.py:  558]:	worker_index: 3, step: 1967, cost: 7.557527, mlm loss: 7.557527, speed: 1.085133 steps/s, speed: 8.681062 samples/s, speed: 4444.703812 tokens/s, learning rate: 1.966e-05, loss_scalings: 3518.437988, pp_loss: 7.351945
[INFO] 2021-07-12 19:11:48,164 [run_pretraining.py:  512]:	********exe.run_1967******* 
[INFO] 2021-07-12 19:11:49,084 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:49,085 [run_pretraining.py:  534]:	loss/total_loss, 7.802416801452637, 1968
[INFO] 2021-07-12 19:11:49,085 [run_pretraining.py:  535]:	loss/mlm_loss, 7.802416801452637, 1968
[INFO] 2021-07-12 19:11:49,085 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9670000256155618e-05, 1968
[INFO] 2021-07-12 19:11:49,085 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1968
[INFO] 2021-07-12 19:11:49,085 [run_pretraining.py:  558]:	worker_index: 3, step: 1968, cost: 7.802417, mlm loss: 7.802417, speed: 1.087040 steps/s, speed: 8.696319 samples/s, speed: 4452.515090 tokens/s, learning rate: 1.967e-05, loss_scalings: 3518.437988, pp_loss: 7.324015
[INFO] 2021-07-12 19:11:49,085 [run_pretraining.py:  512]:	********exe.run_1968******* 
[INFO] 2021-07-12 19:11:50,000 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:50,000 [run_pretraining.py:  534]:	loss/total_loss, 8.000192642211914, 1969
[INFO] 2021-07-12 19:11:50,000 [run_pretraining.py:  535]:	loss/mlm_loss, 8.000192642211914, 1969
[INFO] 2021-07-12 19:11:50,001 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.967999924090691e-05, 1969
[INFO] 2021-07-12 19:11:50,001 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1969
[INFO] 2021-07-12 19:11:50,001 [run_pretraining.py:  558]:	worker_index: 3, step: 1969, cost: 8.000193, mlm loss: 8.000193, speed: 1.092716 steps/s, speed: 8.741726 samples/s, speed: 4475.763526 tokens/s, learning rate: 1.968e-05, loss_scalings: 3518.437988, pp_loss: 7.680758
[INFO] 2021-07-12 19:11:50,001 [run_pretraining.py:  512]:	********exe.run_1969******* 
[INFO] 2021-07-12 19:11:50,929 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:50,929 [run_pretraining.py:  534]:	loss/total_loss, 7.8664937019348145, 1970
[INFO] 2021-07-12 19:11:50,929 [run_pretraining.py:  535]:	loss/mlm_loss, 7.8664937019348145, 1970
[INFO] 2021-07-12 19:11:50,929 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.96899982256582e-05, 1970
[INFO] 2021-07-12 19:11:50,929 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1970
[INFO] 2021-07-12 19:11:50,930 [run_pretraining.py:  558]:	worker_index: 3, step: 1970, cost: 7.866494, mlm loss: 7.866494, speed: 1.077394 steps/s, speed: 8.619153 samples/s, speed: 4413.006391 tokens/s, learning rate: 1.969e-05, loss_scalings: 3518.437988, pp_loss: 7.386890
[INFO] 2021-07-12 19:11:50,930 [run_pretraining.py:  512]:	********exe.run_1970******* 
[INFO] 2021-07-12 19:11:51,865 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:51,866 [run_pretraining.py:  534]:	loss/total_loss, 7.465869903564453, 1971
[INFO] 2021-07-12 19:11:51,866 [run_pretraining.py:  535]:	loss/mlm_loss, 7.465869903564453, 1971
[INFO] 2021-07-12 19:11:51,866 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9699999029398896e-05, 1971
[INFO] 2021-07-12 19:11:51,866 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1971
[INFO] 2021-07-12 19:11:51,866 [run_pretraining.py:  558]:	worker_index: 3, step: 1971, cost: 7.465870, mlm loss: 7.465870, speed: 1.068318 steps/s, speed: 8.546542 samples/s, speed: 4375.829340 tokens/s, learning rate: 1.970e-05, loss_scalings: 3518.437988, pp_loss: 7.128434
[INFO] 2021-07-12 19:11:51,866 [run_pretraining.py:  512]:	********exe.run_1971******* 
[INFO] 2021-07-12 19:11:52,783 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:52,784 [run_pretraining.py:  534]:	loss/total_loss, 5.391624927520752, 1972
[INFO] 2021-07-12 19:11:52,784 [run_pretraining.py:  535]:	loss/mlm_loss, 5.391624927520752, 1972
[INFO] 2021-07-12 19:11:52,784 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.970999983313959e-05, 1972
[INFO] 2021-07-12 19:11:52,784 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1972
[INFO] 2021-07-12 19:11:52,784 [run_pretraining.py:  558]:	worker_index: 3, step: 1972, cost: 5.391625, mlm loss: 5.391625, speed: 1.090491 steps/s, speed: 8.723925 samples/s, speed: 4466.649676 tokens/s, learning rate: 1.971e-05, loss_scalings: 3518.437988, pp_loss: 7.053992
[INFO] 2021-07-12 19:11:52,784 [run_pretraining.py:  512]:	********exe.run_1972******* 
[INFO] 2021-07-12 19:11:53,703 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:53,704 [run_pretraining.py:  534]:	loss/total_loss, 7.041338920593262, 1973
[INFO] 2021-07-12 19:11:53,704 [run_pretraining.py:  535]:	loss/mlm_loss, 7.041338920593262, 1973
[INFO] 2021-07-12 19:11:53,704 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9719998817890882e-05, 1973
[INFO] 2021-07-12 19:11:53,704 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1973
[INFO] 2021-07-12 19:11:53,704 [run_pretraining.py:  558]:	worker_index: 3, step: 1973, cost: 7.041339, mlm loss: 7.041339, speed: 1.087442 steps/s, speed: 8.699538 samples/s, speed: 4454.163556 tokens/s, learning rate: 1.972e-05, loss_scalings: 3518.437988, pp_loss: 6.615024
[INFO] 2021-07-12 19:11:53,704 [run_pretraining.py:  512]:	********exe.run_1973******* 
[INFO] 2021-07-12 19:11:54,621 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:54,622 [run_pretraining.py:  534]:	loss/total_loss, 7.273303508758545, 1974
[INFO] 2021-07-12 19:11:54,622 [run_pretraining.py:  535]:	loss/mlm_loss, 7.273303508758545, 1974
[INFO] 2021-07-12 19:11:54,622 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9729999621631578e-05, 1974
[INFO] 2021-07-12 19:11:54,622 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1974
[INFO] 2021-07-12 19:11:54,622 [run_pretraining.py:  558]:	worker_index: 3, step: 1974, cost: 7.273304, mlm loss: 7.273304, speed: 1.090131 steps/s, speed: 8.721048 samples/s, speed: 4465.176474 tokens/s, learning rate: 1.973e-05, loss_scalings: 3518.437988, pp_loss: 7.026128
[INFO] 2021-07-12 19:11:54,622 [run_pretraining.py:  512]:	********exe.run_1974******* 
[INFO] 2021-07-12 19:11:55,575 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:55,576 [run_pretraining.py:  534]:	loss/total_loss, 6.926000595092773, 1975
[INFO] 2021-07-12 19:11:55,576 [run_pretraining.py:  535]:	loss/mlm_loss, 6.926000595092773, 1975
[INFO] 2021-07-12 19:11:55,576 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9740000425372273e-05, 1975
[INFO] 2021-07-12 19:11:55,576 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1975
[INFO] 2021-07-12 19:11:55,576 [run_pretraining.py:  558]:	worker_index: 3, step: 1975, cost: 6.926001, mlm loss: 6.926001, speed: 1.048806 steps/s, speed: 8.390446 samples/s, speed: 4295.908100 tokens/s, learning rate: 1.974e-05, loss_scalings: 3518.437988, pp_loss: 7.527716
[INFO] 2021-07-12 19:11:55,576 [run_pretraining.py:  512]:	********exe.run_1975******* 
[INFO] 2021-07-12 19:11:56,507 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:56,507 [run_pretraining.py:  534]:	loss/total_loss, 7.20784330368042, 1976
[INFO] 2021-07-12 19:11:56,507 [run_pretraining.py:  535]:	loss/mlm_loss, 7.20784330368042, 1976
[INFO] 2021-07-12 19:11:56,507 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9749999410123564e-05, 1976
[INFO] 2021-07-12 19:11:56,507 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1976
[INFO] 2021-07-12 19:11:56,507 [run_pretraining.py:  558]:	worker_index: 3, step: 1976, cost: 7.207843, mlm loss: 7.207843, speed: 1.074540 steps/s, speed: 8.596321 samples/s, speed: 4401.316302 tokens/s, learning rate: 1.975e-05, loss_scalings: 3518.437988, pp_loss: 7.230104
[INFO] 2021-07-12 19:11:56,507 [run_pretraining.py:  512]:	********exe.run_1976******* 
[INFO] 2021-07-12 19:11:57,435 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:57,435 [run_pretraining.py:  534]:	loss/total_loss, 7.587421894073486, 1977
[INFO] 2021-07-12 19:11:57,436 [run_pretraining.py:  535]:	loss/mlm_loss, 7.587421894073486, 1977
[INFO] 2021-07-12 19:11:57,436 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.976000021386426e-05, 1977
[INFO] 2021-07-12 19:11:57,436 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1977
[INFO] 2021-07-12 19:11:57,436 [run_pretraining.py:  558]:	worker_index: 3, step: 1977, cost: 7.587422, mlm loss: 7.587422, speed: 1.077941 steps/s, speed: 8.623526 samples/s, speed: 4415.245198 tokens/s, learning rate: 1.976e-05, loss_scalings: 3518.437988, pp_loss: 7.176888
[INFO] 2021-07-12 19:11:57,436 [run_pretraining.py:  512]:	********exe.run_1977******* 
[INFO] 2021-07-12 19:11:58,355 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:58,356 [run_pretraining.py:  534]:	loss/total_loss, 7.5155229568481445, 1978
[INFO] 2021-07-12 19:11:58,356 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5155229568481445, 1978
[INFO] 2021-07-12 19:11:58,356 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.976999919861555e-05, 1978
[INFO] 2021-07-12 19:11:58,356 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1978
[INFO] 2021-07-12 19:11:58,356 [run_pretraining.py:  558]:	worker_index: 3, step: 1978, cost: 7.515523, mlm loss: 7.515523, speed: 1.087432 steps/s, speed: 8.699459 samples/s, speed: 4454.123137 tokens/s, learning rate: 1.977e-05, loss_scalings: 3518.437988, pp_loss: 7.406574
[INFO] 2021-07-12 19:11:58,356 [run_pretraining.py:  512]:	********exe.run_1978******* 
[INFO] 2021-07-12 19:11:59,267 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:59,268 [run_pretraining.py:  534]:	loss/total_loss, 7.661982536315918, 1979
[INFO] 2021-07-12 19:11:59,268 [run_pretraining.py:  535]:	loss/mlm_loss, 7.661982536315918, 1979
[INFO] 2021-07-12 19:11:59,268 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9779998183366843e-05, 1979
[INFO] 2021-07-12 19:11:59,268 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1979
[INFO] 2021-07-12 19:11:59,268 [run_pretraining.py:  558]:	worker_index: 3, step: 1979, cost: 7.661983, mlm loss: 7.661983, speed: 1.096921 steps/s, speed: 8.775367 samples/s, speed: 4492.987874 tokens/s, learning rate: 1.978e-05, loss_scalings: 3518.437988, pp_loss: 6.565063
[INFO] 2021-07-12 19:11:59,268 [run_pretraining.py:  512]:	********exe.run_1979******* 
[INFO] 2021-07-12 19:12:00,195 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:00,195 [run_pretraining.py:  534]:	loss/total_loss, 7.771069526672363, 1980
[INFO] 2021-07-12 19:12:00,195 [run_pretraining.py:  535]:	loss/mlm_loss, 7.771069526672363, 1980
[INFO] 2021-07-12 19:12:00,196 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9789998987107538e-05, 1980
[INFO] 2021-07-12 19:12:00,196 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1980
[INFO] 2021-07-12 19:12:00,196 [run_pretraining.py:  558]:	worker_index: 3, step: 1980, cost: 7.771070, mlm loss: 7.771070, speed: 1.079016 steps/s, speed: 8.632127 samples/s, speed: 4419.648906 tokens/s, learning rate: 1.979e-05, loss_scalings: 3518.437988, pp_loss: 7.677963
[INFO] 2021-07-12 19:12:00,196 [run_pretraining.py:  512]:	********exe.run_1980******* 
[INFO] 2021-07-12 19:12:01,118 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:01,119 [run_pretraining.py:  534]:	loss/total_loss, 6.730233192443848, 1981
[INFO] 2021-07-12 19:12:01,119 [run_pretraining.py:  535]:	loss/mlm_loss, 6.730233192443848, 1981
[INFO] 2021-07-12 19:12:01,119 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9799999790848233e-05, 1981
[INFO] 2021-07-12 19:12:01,119 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1981
[INFO] 2021-07-12 19:12:01,119 [run_pretraining.py:  558]:	worker_index: 3, step: 1981, cost: 6.730233, mlm loss: 6.730233, speed: 1.083356 steps/s, speed: 8.666851 samples/s, speed: 4437.427580 tokens/s, learning rate: 1.980e-05, loss_scalings: 3518.437988, pp_loss: 7.995811
[INFO] 2021-07-12 19:12:01,119 [run_pretraining.py:  512]:	********exe.run_1981******* 
[INFO] 2021-07-12 19:12:02,042 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:02,042 [run_pretraining.py:  534]:	loss/total_loss, 7.375450134277344, 1982
[INFO] 2021-07-12 19:12:02,042 [run_pretraining.py:  535]:	loss/mlm_loss, 7.375450134277344, 1982
[INFO] 2021-07-12 19:12:02,042 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9809998775599524e-05, 1982
[INFO] 2021-07-12 19:12:02,042 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1982
[INFO] 2021-07-12 19:12:02,042 [run_pretraining.py:  558]:	worker_index: 3, step: 1982, cost: 7.375450, mlm loss: 7.375450, speed: 1.084173 steps/s, speed: 8.673388 samples/s, speed: 4440.774578 tokens/s, learning rate: 1.981e-05, loss_scalings: 3518.437988, pp_loss: 7.552697
[INFO] 2021-07-12 19:12:02,042 [run_pretraining.py:  512]:	********exe.run_1982******* 
[INFO] 2021-07-12 19:12:02,976 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:02,977 [run_pretraining.py:  534]:	loss/total_loss, 6.96651029586792, 1983
[INFO] 2021-07-12 19:12:02,977 [run_pretraining.py:  535]:	loss/mlm_loss, 6.96651029586792, 1983
[INFO] 2021-07-12 19:12:02,977 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.981999957934022e-05, 1983
[INFO] 2021-07-12 19:12:02,977 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1983
[INFO] 2021-07-12 19:12:02,977 [run_pretraining.py:  558]:	worker_index: 3, step: 1983, cost: 6.966510, mlm loss: 6.966510, speed: 1.070284 steps/s, speed: 8.562272 samples/s, speed: 4383.883411 tokens/s, learning rate: 1.982e-05, loss_scalings: 3518.437988, pp_loss: 7.127507
[INFO] 2021-07-12 19:12:02,977 [run_pretraining.py:  512]:	********exe.run_1983******* 
[INFO] 2021-07-12 19:12:03,909 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:03,910 [run_pretraining.py:  534]:	loss/total_loss, 7.316891670227051, 1984
[INFO] 2021-07-12 19:12:03,910 [run_pretraining.py:  535]:	loss/mlm_loss, 7.316891670227051, 1984
[INFO] 2021-07-12 19:12:03,910 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9830000383080915e-05, 1984
[INFO] 2021-07-12 19:12:03,910 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1984
[INFO] 2021-07-12 19:12:03,910 [run_pretraining.py:  558]:	worker_index: 3, step: 1984, cost: 7.316892, mlm loss: 7.316892, speed: 1.072665 steps/s, speed: 8.581321 samples/s, speed: 4393.636284 tokens/s, learning rate: 1.983e-05, loss_scalings: 3518.437988, pp_loss: 7.690789
[INFO] 2021-07-12 19:12:03,910 [run_pretraining.py:  512]:	********exe.run_1984******* 
[INFO] 2021-07-12 19:12:04,828 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:04,828 [run_pretraining.py:  534]:	loss/total_loss, 7.371531963348389, 1985
[INFO] 2021-07-12 19:12:04,828 [run_pretraining.py:  535]:	loss/mlm_loss, 7.371531963348389, 1985
[INFO] 2021-07-12 19:12:04,828 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9839999367832206e-05, 1985
[INFO] 2021-07-12 19:12:04,829 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1985
[INFO] 2021-07-12 19:12:04,829 [run_pretraining.py:  558]:	worker_index: 3, step: 1985, cost: 7.371532, mlm loss: 7.371532, speed: 1.089711 steps/s, speed: 8.717688 samples/s, speed: 4463.456067 tokens/s, learning rate: 1.984e-05, loss_scalings: 3518.437988, pp_loss: 7.351418
[INFO] 2021-07-12 19:12:04,829 [run_pretraining.py:  512]:	********exe.run_1985******* 
[INFO] 2021-07-12 19:12:05,761 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:05,761 [run_pretraining.py:  534]:	loss/total_loss, 6.214868068695068, 1986
[INFO] 2021-07-12 19:12:05,761 [run_pretraining.py:  535]:	loss/mlm_loss, 6.214868068695068, 1986
[INFO] 2021-07-12 19:12:05,761 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.98500001715729e-05, 1986
[INFO] 2021-07-12 19:12:05,761 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1986
[INFO] 2021-07-12 19:12:05,762 [run_pretraining.py:  558]:	worker_index: 3, step: 1986, cost: 6.214868, mlm loss: 6.214868, speed: 1.072634 steps/s, speed: 8.581073 samples/s, speed: 4393.509316 tokens/s, learning rate: 1.985e-05, loss_scalings: 3518.437988, pp_loss: 6.851437
[INFO] 2021-07-12 19:12:05,762 [run_pretraining.py:  512]:	********exe.run_1986******* 
[INFO] 2021-07-12 19:12:06,700 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:06,701 [run_pretraining.py:  534]:	loss/total_loss, 7.3438401222229, 1987
[INFO] 2021-07-12 19:12:06,701 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3438401222229, 1987
[INFO] 2021-07-12 19:12:06,701 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9859999156324193e-05, 1987
[INFO] 2021-07-12 19:12:06,701 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1987
[INFO] 2021-07-12 19:12:06,701 [run_pretraining.py:  558]:	worker_index: 3, step: 1987, cost: 7.343840, mlm loss: 7.343840, speed: 1.065260 steps/s, speed: 8.522079 samples/s, speed: 4363.304277 tokens/s, learning rate: 1.986e-05, loss_scalings: 3518.437988, pp_loss: 6.989194
[INFO] 2021-07-12 19:12:06,701 [run_pretraining.py:  512]:	********exe.run_1987******* 
[INFO] 2021-07-12 19:12:07,630 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:07,631 [run_pretraining.py:  534]:	loss/total_loss, 6.894784927368164, 1988
[INFO] 2021-07-12 19:12:07,631 [run_pretraining.py:  535]:	loss/mlm_loss, 6.894784927368164, 1988
[INFO] 2021-07-12 19:12:07,631 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9869999960064888e-05, 1988
[INFO] 2021-07-12 19:12:07,631 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1988
[INFO] 2021-07-12 19:12:07,631 [run_pretraining.py:  558]:	worker_index: 3, step: 1988, cost: 6.894785, mlm loss: 6.894785, speed: 1.075609 steps/s, speed: 8.604872 samples/s, speed: 4405.694515 tokens/s, learning rate: 1.987e-05, loss_scalings: 3518.437988, pp_loss: 6.929929
[INFO] 2021-07-12 19:12:07,631 [run_pretraining.py:  512]:	********exe.run_1988******* 
[INFO] 2021-07-12 19:12:08,562 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:08,563 [run_pretraining.py:  534]:	loss/total_loss, 7.485688209533691, 1989
[INFO] 2021-07-12 19:12:08,563 [run_pretraining.py:  535]:	loss/mlm_loss, 7.485688209533691, 1989
[INFO] 2021-07-12 19:12:08,563 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.987999894481618e-05, 1989
[INFO] 2021-07-12 19:12:08,563 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1989
[INFO] 2021-07-12 19:12:08,563 [run_pretraining.py:  558]:	worker_index: 3, step: 1989, cost: 7.485688, mlm loss: 7.485688, speed: 1.073596 steps/s, speed: 8.588767 samples/s, speed: 4397.448740 tokens/s, learning rate: 1.988e-05, loss_scalings: 3518.437988, pp_loss: 7.413126
[INFO] 2021-07-12 19:12:08,563 [run_pretraining.py:  512]:	********exe.run_1989******* 
[INFO] 2021-07-12 19:12:09,505 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:09,505 [run_pretraining.py:  534]:	loss/total_loss, 7.153339385986328, 1990
[INFO] 2021-07-12 19:12:09,505 [run_pretraining.py:  535]:	loss/mlm_loss, 7.153339385986328, 1990
[INFO] 2021-07-12 19:12:09,506 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9889999748556875e-05, 1990
[INFO] 2021-07-12 19:12:09,506 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1990
[INFO] 2021-07-12 19:12:09,506 [run_pretraining.py:  558]:	worker_index: 3, step: 1990, cost: 7.153339, mlm loss: 7.153339, speed: 1.062012 steps/s, speed: 8.496094 samples/s, speed: 4350.000236 tokens/s, learning rate: 1.989e-05, loss_scalings: 3518.437988, pp_loss: 7.300375
[INFO] 2021-07-12 19:12:09,506 [run_pretraining.py:  512]:	********exe.run_1990******* 
[INFO] 2021-07-12 19:12:10,449 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:10,449 [run_pretraining.py:  534]:	loss/total_loss, 7.267664432525635, 1991
[INFO] 2021-07-12 19:12:10,450 [run_pretraining.py:  535]:	loss/mlm_loss, 7.267664432525635, 1991
[INFO] 2021-07-12 19:12:10,450 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9899998733308166e-05, 1991
[INFO] 2021-07-12 19:12:10,450 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1991
[INFO] 2021-07-12 19:12:10,450 [run_pretraining.py:  558]:	worker_index: 3, step: 1991, cost: 7.267664, mlm loss: 7.267664, speed: 1.059871 steps/s, speed: 8.478964 samples/s, speed: 4341.229609 tokens/s, learning rate: 1.990e-05, loss_scalings: 3518.437988, pp_loss: 7.302480
[INFO] 2021-07-12 19:12:10,450 [run_pretraining.py:  512]:	********exe.run_1991******* 
[INFO] 2021-07-12 19:12:11,384 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:11,385 [run_pretraining.py:  534]:	loss/total_loss, 7.608062744140625, 1992
[INFO] 2021-07-12 19:12:11,385 [run_pretraining.py:  535]:	loss/mlm_loss, 7.608062744140625, 1992
[INFO] 2021-07-12 19:12:11,385 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.990999953704886e-05, 1992
[INFO] 2021-07-12 19:12:11,385 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1992
[INFO] 2021-07-12 19:12:11,385 [run_pretraining.py:  558]:	worker_index: 3, step: 1992, cost: 7.608063, mlm loss: 7.608063, speed: 1.069918 steps/s, speed: 8.559343 samples/s, speed: 4382.383801 tokens/s, learning rate: 1.991e-05, loss_scalings: 3518.437988, pp_loss: 7.286532
[INFO] 2021-07-12 19:12:11,385 [run_pretraining.py:  512]:	********exe.run_1992******* 
[INFO] 2021-07-12 19:12:12,326 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:12,326 [run_pretraining.py:  534]:	loss/total_loss, 7.020271301269531, 1993
[INFO] 2021-07-12 19:12:12,326 [run_pretraining.py:  535]:	loss/mlm_loss, 7.020271301269531, 1993
[INFO] 2021-07-12 19:12:12,326 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9920000340789557e-05, 1993
[INFO] 2021-07-12 19:12:12,326 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1993
[INFO] 2021-07-12 19:12:12,326 [run_pretraining.py:  558]:	worker_index: 3, step: 1993, cost: 7.020271, mlm loss: 7.020271, speed: 1.063026 steps/s, speed: 8.504210 samples/s, speed: 4354.155509 tokens/s, learning rate: 1.992e-05, loss_scalings: 3518.437988, pp_loss: 7.232646
[INFO] 2021-07-12 19:12:12,327 [run_pretraining.py:  512]:	********exe.run_1993******* 
[INFO] 2021-07-12 19:12:13,260 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:13,261 [run_pretraining.py:  534]:	loss/total_loss, 7.841432571411133, 1994
[INFO] 2021-07-12 19:12:13,261 [run_pretraining.py:  535]:	loss/mlm_loss, 7.841432571411133, 1994
[INFO] 2021-07-12 19:12:13,261 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9929999325540848e-05, 1994
[INFO] 2021-07-12 19:12:13,261 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1994
[INFO] 2021-07-12 19:12:13,261 [run_pretraining.py:  558]:	worker_index: 3, step: 1994, cost: 7.841433, mlm loss: 7.841433, speed: 1.070339 steps/s, speed: 8.562709 samples/s, speed: 4384.107155 tokens/s, learning rate: 1.993e-05, loss_scalings: 3518.437988, pp_loss: 7.288890
[INFO] 2021-07-12 19:12:13,261 [run_pretraining.py:  512]:	********exe.run_1994******* 
[INFO] 2021-07-12 19:12:14,211 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:14,211 [run_pretraining.py:  534]:	loss/total_loss, 6.823999404907227, 1995
[INFO] 2021-07-12 19:12:14,212 [run_pretraining.py:  535]:	loss/mlm_loss, 6.823999404907227, 1995
[INFO] 2021-07-12 19:12:14,212 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.993999831029214e-05, 1995
[INFO] 2021-07-12 19:12:14,212 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1995
[INFO] 2021-07-12 19:12:14,212 [run_pretraining.py:  558]:	worker_index: 3, step: 1995, cost: 6.823999, mlm loss: 6.823999, speed: 1.052882 steps/s, speed: 8.423054 samples/s, speed: 4312.603689 tokens/s, learning rate: 1.994e-05, loss_scalings: 3518.437988, pp_loss: 6.900408
[INFO] 2021-07-12 19:12:14,212 [run_pretraining.py:  512]:	********exe.run_1995******* 
[INFO] 2021-07-12 19:12:15,140 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:15,140 [run_pretraining.py:  534]:	loss/total_loss, 7.041787147521973, 1996
[INFO] 2021-07-12 19:12:15,140 [run_pretraining.py:  535]:	loss/mlm_loss, 7.041787147521973, 1996
[INFO] 2021-07-12 19:12:15,140 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9949999114032835e-05, 1996
[INFO] 2021-07-12 19:12:15,141 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1996
[INFO] 2021-07-12 19:12:15,141 [run_pretraining.py:  558]:	worker_index: 3, step: 1996, cost: 7.041787, mlm loss: 7.041787, speed: 1.077391 steps/s, speed: 8.619131 samples/s, speed: 4412.995055 tokens/s, learning rate: 1.995e-05, loss_scalings: 3518.437988, pp_loss: 7.406665
[INFO] 2021-07-12 19:12:15,141 [run_pretraining.py:  512]:	********exe.run_1996******* 
[INFO] 2021-07-12 19:12:16,051 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:16,051 [run_pretraining.py:  534]:	loss/total_loss, 7.693005561828613, 1997
[INFO] 2021-07-12 19:12:16,051 [run_pretraining.py:  535]:	loss/mlm_loss, 7.693005561828613, 1997
[INFO] 2021-07-12 19:12:16,052 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.995999991777353e-05, 1997
[INFO] 2021-07-12 19:12:16,052 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1997
[INFO] 2021-07-12 19:12:16,052 [run_pretraining.py:  558]:	worker_index: 3, step: 1997, cost: 7.693006, mlm loss: 7.693006, speed: 1.098378 steps/s, speed: 8.787025 samples/s, speed: 4498.956743 tokens/s, learning rate: 1.996e-05, loss_scalings: 3518.437988, pp_loss: 7.585436
[INFO] 2021-07-12 19:12:16,052 [run_pretraining.py:  512]:	********exe.run_1997******* 
[INFO] 2021-07-12 19:12:17,015 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:17,016 [run_pretraining.py:  534]:	loss/total_loss, 7.197444438934326, 1998
[INFO] 2021-07-12 19:12:17,016 [run_pretraining.py:  535]:	loss/mlm_loss, 7.197444438934326, 1998
[INFO] 2021-07-12 19:12:17,016 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.996999890252482e-05, 1998
[INFO] 2021-07-12 19:12:17,016 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1998
[INFO] 2021-07-12 19:12:17,016 [run_pretraining.py:  558]:	worker_index: 3, step: 1998, cost: 7.197444, mlm loss: 7.197444, speed: 1.037530 steps/s, speed: 8.300237 samples/s, speed: 4249.721573 tokens/s, learning rate: 1.997e-05, loss_scalings: 3518.437988, pp_loss: 7.222682
[INFO] 2021-07-12 19:12:17,016 [run_pretraining.py:  512]:	********exe.run_1998******* 
[INFO] 2021-07-12 19:12:17,914 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:17,914 [run_pretraining.py:  534]:	loss/total_loss, 7.966427326202393, 1999
[INFO] 2021-07-12 19:12:17,914 [run_pretraining.py:  535]:	loss/mlm_loss, 7.966427326202393, 1999
[INFO] 2021-07-12 19:12:17,915 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9979999706265517e-05, 1999
[INFO] 2021-07-12 19:12:17,915 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1999
[INFO] 2021-07-12 19:12:17,915 [run_pretraining.py:  558]:	worker_index: 3, step: 1999, cost: 7.966427, mlm loss: 7.966427, speed: 1.113785 steps/s, speed: 8.910283 samples/s, speed: 4562.064784 tokens/s, learning rate: 1.998e-05, loss_scalings: 3518.437988, pp_loss: 7.480137
[INFO] 2021-07-12 19:12:17,915 [run_pretraining.py:  512]:	********exe.run_1999******* 
[INFO] 2021-07-12 19:12:18,828 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:18,829 [run_pretraining.py:  534]:	loss/total_loss, 7.059478282928467, 2000
[INFO] 2021-07-12 19:12:18,829 [run_pretraining.py:  535]:	loss/mlm_loss, 7.059478282928467, 2000
[INFO] 2021-07-12 19:12:18,829 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9990000510006212e-05, 2000
[INFO] 2021-07-12 19:12:18,829 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2000
[INFO] 2021-07-12 19:12:18,829 [run_pretraining.py:  558]:	worker_index: 3, step: 2000, cost: 7.059478, mlm loss: 7.059478, speed: 1.094439 steps/s, speed: 8.755510 samples/s, speed: 4482.821032 tokens/s, learning rate: 1.999e-05, loss_scalings: 3518.437988, pp_loss: 7.233285
[INFO] 2021-07-12 19:12:18,829 [run_pretraining.py:  512]:	********exe.run_2000******* 
[INFO] 2021-07-12 19:12:19,737 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:19,738 [run_pretraining.py:  534]:	loss/total_loss, 7.50877046585083, 2001
[INFO] 2021-07-12 19:12:19,738 [run_pretraining.py:  535]:	loss/mlm_loss, 7.50877046585083, 2001
[INFO] 2021-07-12 19:12:19,738 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9999999494757503e-05, 2001
[INFO] 2021-07-12 19:12:19,738 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2001
[INFO] 2021-07-12 19:12:19,738 [run_pretraining.py:  558]:	worker_index: 3, step: 2001, cost: 7.508770, mlm loss: 7.508770, speed: 1.100650 steps/s, speed: 8.805200 samples/s, speed: 4508.262197 tokens/s, learning rate: 2.000e-05, loss_scalings: 3518.437988, pp_loss: 7.350972
[INFO] 2021-07-12 19:12:19,738 [run_pretraining.py:  512]:	********exe.run_2001******* 
[INFO] 2021-07-12 19:12:20,651 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:20,652 [run_pretraining.py:  534]:	loss/total_loss, 7.3439178466796875, 2002
[INFO] 2021-07-12 19:12:20,652 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3439178466796875, 2002
[INFO] 2021-07-12 19:12:20,652 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.00100002984982e-05, 2002
[INFO] 2021-07-12 19:12:20,652 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2002
[INFO] 2021-07-12 19:12:20,652 [run_pretraining.py:  558]:	worker_index: 3, step: 2002, cost: 7.343918, mlm loss: 7.343918, speed: 1.095216 steps/s, speed: 8.761726 samples/s, speed: 4486.003766 tokens/s, learning rate: 2.001e-05, loss_scalings: 3518.437988, pp_loss: 7.371721
[INFO] 2021-07-12 19:12:20,652 [run_pretraining.py:  512]:	********exe.run_2002******* 
[INFO] 2021-07-12 19:12:21,572 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:21,572 [run_pretraining.py:  534]:	loss/total_loss, 7.666000843048096, 2003
[INFO] 2021-07-12 19:12:21,572 [run_pretraining.py:  535]:	loss/mlm_loss, 7.666000843048096, 2003
[INFO] 2021-07-12 19:12:21,572 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.001999928324949e-05, 2003
[INFO] 2021-07-12 19:12:21,572 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2003
[INFO] 2021-07-12 19:12:21,572 [run_pretraining.py:  558]:	worker_index: 3, step: 2003, cost: 7.666001, mlm loss: 7.666001, speed: 1.087069 steps/s, speed: 8.696548 samples/s, speed: 4452.632797 tokens/s, learning rate: 2.002e-05, loss_scalings: 3518.437988, pp_loss: 7.672823
[INFO] 2021-07-12 19:12:21,573 [run_pretraining.py:  512]:	********exe.run_2003******* 
[INFO] 2021-07-12 19:12:22,485 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:22,485 [run_pretraining.py:  534]:	loss/total_loss, 7.013387203216553, 2004
[INFO] 2021-07-12 19:12:22,485 [run_pretraining.py:  535]:	loss/mlm_loss, 7.013387203216553, 2004
[INFO] 2021-07-12 19:12:22,485 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.002999826800078e-05, 2004
[INFO] 2021-07-12 19:12:22,486 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2004
[INFO] 2021-07-12 19:12:22,486 [run_pretraining.py:  558]:	worker_index: 3, step: 2004, cost: 7.013387, mlm loss: 7.013387, speed: 1.095826 steps/s, speed: 8.766611 samples/s, speed: 4488.504894 tokens/s, learning rate: 2.003e-05, loss_scalings: 3518.437988, pp_loss: 7.424028
[INFO] 2021-07-12 19:12:22,486 [run_pretraining.py:  512]:	********exe.run_2004******* 
[INFO] 2021-07-12 19:12:23,402 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:23,402 [run_pretraining.py:  534]:	loss/total_loss, 7.49350118637085, 2005
[INFO] 2021-07-12 19:12:23,402 [run_pretraining.py:  535]:	loss/mlm_loss, 7.49350118637085, 2005
[INFO] 2021-07-12 19:12:23,402 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0039999071741477e-05, 2005
[INFO] 2021-07-12 19:12:23,402 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2005
[INFO] 2021-07-12 19:12:23,403 [run_pretraining.py:  558]:	worker_index: 3, step: 2005, cost: 7.493501, mlm loss: 7.493501, speed: 1.091335 steps/s, speed: 8.730678 samples/s, speed: 4470.107214 tokens/s, learning rate: 2.004e-05, loss_scalings: 3518.437988, pp_loss: 6.725544
[INFO] 2021-07-12 19:12:23,403 [run_pretraining.py:  512]:	********exe.run_2005******* 
[INFO] 2021-07-12 19:12:24,319 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:24,320 [run_pretraining.py:  534]:	loss/total_loss, 7.15444278717041, 2006
[INFO] 2021-07-12 19:12:24,320 [run_pretraining.py:  535]:	loss/mlm_loss, 7.15444278717041, 2006
[INFO] 2021-07-12 19:12:24,320 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0049999875482172e-05, 2006
[INFO] 2021-07-12 19:12:24,320 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2006
[INFO] 2021-07-12 19:12:24,320 [run_pretraining.py:  558]:	worker_index: 3, step: 2006, cost: 7.154443, mlm loss: 7.154443, speed: 1.090721 steps/s, speed: 8.725765 samples/s, speed: 4467.591688 tokens/s, learning rate: 2.005e-05, loss_scalings: 3518.437988, pp_loss: 7.495962
[INFO] 2021-07-12 19:12:24,320 [run_pretraining.py:  512]:	********exe.run_2006******* 
[INFO] 2021-07-12 19:12:25,237 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:25,238 [run_pretraining.py:  534]:	loss/total_loss, 7.474437236785889, 2007
[INFO] 2021-07-12 19:12:25,238 [run_pretraining.py:  535]:	loss/mlm_loss, 7.474437236785889, 2007
[INFO] 2021-07-12 19:12:25,238 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0059998860233463e-05, 2007
[INFO] 2021-07-12 19:12:25,238 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2007
[INFO] 2021-07-12 19:12:25,238 [run_pretraining.py:  558]:	worker_index: 3, step: 2007, cost: 7.474437, mlm loss: 7.474437, speed: 1.089824 steps/s, speed: 8.718594 samples/s, speed: 4463.919971 tokens/s, learning rate: 2.006e-05, loss_scalings: 3518.437988, pp_loss: 7.176481
[INFO] 2021-07-12 19:12:25,238 [run_pretraining.py:  512]:	********exe.run_2007******* 
[INFO] 2021-07-12 19:12:26,161 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:26,162 [run_pretraining.py:  534]:	loss/total_loss, 7.843919277191162, 2008
[INFO] 2021-07-12 19:12:26,162 [run_pretraining.py:  535]:	loss/mlm_loss, 7.843919277191162, 2008
[INFO] 2021-07-12 19:12:26,162 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.006999966397416e-05, 2008
[INFO] 2021-07-12 19:12:26,162 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2008
[INFO] 2021-07-12 19:12:26,162 [run_pretraining.py:  558]:	worker_index: 3, step: 2008, cost: 7.843919, mlm loss: 7.843919, speed: 1.083108 steps/s, speed: 8.664861 samples/s, speed: 4436.408884 tokens/s, learning rate: 2.007e-05, loss_scalings: 3518.437988, pp_loss: 7.474456
[INFO] 2021-07-12 19:12:26,162 [run_pretraining.py:  512]:	********exe.run_2008******* 
[INFO] 2021-07-12 19:12:27,095 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:27,095 [run_pretraining.py:  534]:	loss/total_loss, 7.203068733215332, 2009
[INFO] 2021-07-12 19:12:27,095 [run_pretraining.py:  535]:	loss/mlm_loss, 7.203068733215332, 2009
[INFO] 2021-07-12 19:12:27,095 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0080000467714854e-05, 2009
[INFO] 2021-07-12 19:12:27,096 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2009
[INFO] 2021-07-12 19:12:27,096 [run_pretraining.py:  558]:	worker_index: 3, step: 2009, cost: 7.203069, mlm loss: 7.203069, speed: 1.072020 steps/s, speed: 8.576158 samples/s, speed: 4390.992820 tokens/s, learning rate: 2.008e-05, loss_scalings: 3518.437988, pp_loss: 7.479514
[INFO] 2021-07-12 19:12:27,096 [run_pretraining.py:  512]:	********exe.run_2009******* 
[INFO] 2021-07-12 19:12:28,041 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:28,042 [run_pretraining.py:  534]:	loss/total_loss, 7.2488226890563965, 2010
[INFO] 2021-07-12 19:12:28,042 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2488226890563965, 2010
[INFO] 2021-07-12 19:12:28,042 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0089999452466145e-05, 2010
[INFO] 2021-07-12 19:12:28,042 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2010
[INFO] 2021-07-12 19:12:28,042 [run_pretraining.py:  558]:	worker_index: 3, step: 2010, cost: 7.248823, mlm loss: 7.248823, speed: 1.057160 steps/s, speed: 8.457279 samples/s, speed: 4330.126843 tokens/s, learning rate: 2.009e-05, loss_scalings: 3518.437988, pp_loss: 7.406407
[INFO] 2021-07-12 19:12:28,042 [run_pretraining.py:  512]:	********exe.run_2010******* 
[INFO] 2021-07-12 19:12:29,032 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:29,032 [run_pretraining.py:  534]:	loss/total_loss, 6.832210063934326, 2011
[INFO] 2021-07-12 19:12:29,032 [run_pretraining.py:  535]:	loss/mlm_loss, 6.832210063934326, 2011
[INFO] 2021-07-12 19:12:29,032 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.010000025620684e-05, 2011
[INFO] 2021-07-12 19:12:29,032 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2011
[INFO] 2021-07-12 19:12:29,032 [run_pretraining.py:  558]:	worker_index: 3, step: 2011, cost: 6.832210, mlm loss: 6.832210, speed: 1.010489 steps/s, speed: 8.083911 samples/s, speed: 4138.962554 tokens/s, learning rate: 2.010e-05, loss_scalings: 3518.437988, pp_loss: 7.069765
[INFO] 2021-07-12 19:12:29,033 [run_pretraining.py:  512]:	********exe.run_2011******* 
[INFO] 2021-07-12 19:12:29,981 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:29,982 [run_pretraining.py:  534]:	loss/total_loss, 7.33504581451416, 2012
[INFO] 2021-07-12 19:12:29,982 [run_pretraining.py:  535]:	loss/mlm_loss, 7.33504581451416, 2012
[INFO] 2021-07-12 19:12:29,982 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0110001059947535e-05, 2012
[INFO] 2021-07-12 19:12:29,982 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2012
[INFO] 2021-07-12 19:12:29,982 [run_pretraining.py:  558]:	worker_index: 3, step: 2012, cost: 7.335046, mlm loss: 7.335046, speed: 1.053581 steps/s, speed: 8.428646 samples/s, speed: 4315.466842 tokens/s, learning rate: 2.011e-05, loss_scalings: 3518.437988, pp_loss: 7.157844
[INFO] 2021-07-12 19:12:29,982 [run_pretraining.py:  512]:	********exe.run_2012******* 
[INFO] 2021-07-12 19:12:30,916 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:30,916 [run_pretraining.py:  534]:	loss/total_loss, 7.0947699546813965, 2013
[INFO] 2021-07-12 19:12:30,916 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0947699546813965, 2013
[INFO] 2021-07-12 19:12:30,917 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0119998225709423e-05, 2013
[INFO] 2021-07-12 19:12:30,917 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2013
[INFO] 2021-07-12 19:12:30,917 [run_pretraining.py:  558]:	worker_index: 3, step: 2013, cost: 7.094770, mlm loss: 7.094770, speed: 1.070847 steps/s, speed: 8.566773 samples/s, speed: 4386.187943 tokens/s, learning rate: 2.012e-05, loss_scalings: 3518.437988, pp_loss: 7.228881
[INFO] 2021-07-12 19:12:30,917 [run_pretraining.py:  512]:	********exe.run_2013******* 
[INFO] 2021-07-12 19:12:31,859 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:31,860 [run_pretraining.py:  534]:	loss/total_loss, 7.326305389404297, 2014
[INFO] 2021-07-12 19:12:31,860 [run_pretraining.py:  535]:	loss/mlm_loss, 7.326305389404297, 2014
[INFO] 2021-07-12 19:12:31,860 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.012999902945012e-05, 2014
[INFO] 2021-07-12 19:12:31,860 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2014
[INFO] 2021-07-12 19:12:31,860 [run_pretraining.py:  558]:	worker_index: 3, step: 2014, cost: 7.326305, mlm loss: 7.326305, speed: 1.060721 steps/s, speed: 8.485766 samples/s, speed: 4344.712077 tokens/s, learning rate: 2.013e-05, loss_scalings: 3518.437988, pp_loss: 7.022163
[INFO] 2021-07-12 19:12:31,860 [run_pretraining.py:  512]:	********exe.run_2014******* 
[INFO] 2021-07-12 19:12:32,792 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:32,792 [run_pretraining.py:  534]:	loss/total_loss, 6.95617151260376, 2015
[INFO] 2021-07-12 19:12:32,792 [run_pretraining.py:  535]:	loss/mlm_loss, 6.95617151260376, 2015
[INFO] 2021-07-12 19:12:32,792 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0139999833190814e-05, 2015
[INFO] 2021-07-12 19:12:32,792 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2015
[INFO] 2021-07-12 19:12:32,792 [run_pretraining.py:  558]:	worker_index: 3, step: 2015, cost: 6.956172, mlm loss: 6.956172, speed: 1.073252 steps/s, speed: 8.586013 samples/s, speed: 4396.038823 tokens/s, learning rate: 2.014e-05, loss_scalings: 3518.437988, pp_loss: 7.248868
[INFO] 2021-07-12 19:12:32,793 [run_pretraining.py:  512]:	********exe.run_2015******* 
[INFO] 2021-07-12 19:12:33,722 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:33,723 [run_pretraining.py:  534]:	loss/total_loss, 6.650472640991211, 2016
[INFO] 2021-07-12 19:12:33,723 [run_pretraining.py:  535]:	loss/mlm_loss, 6.650472640991211, 2016
[INFO] 2021-07-12 19:12:33,723 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0149998817942105e-05, 2016
[INFO] 2021-07-12 19:12:33,723 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2016
[INFO] 2021-07-12 19:12:33,723 [run_pretraining.py:  558]:	worker_index: 3, step: 2016, cost: 6.650473, mlm loss: 6.650473, speed: 1.074992 steps/s, speed: 8.599934 samples/s, speed: 4403.166302 tokens/s, learning rate: 2.015e-05, loss_scalings: 3518.437988, pp_loss: 6.988100
[INFO] 2021-07-12 19:12:33,723 [run_pretraining.py:  512]:	********exe.run_2016******* 
[INFO] 2021-07-12 19:12:34,664 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:34,665 [run_pretraining.py:  534]:	loss/total_loss, 7.422764778137207, 2017
[INFO] 2021-07-12 19:12:34,665 [run_pretraining.py:  535]:	loss/mlm_loss, 7.422764778137207, 2017
[INFO] 2021-07-12 19:12:34,665 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.01599996216828e-05, 2017
[INFO] 2021-07-12 19:12:34,665 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2017
[INFO] 2021-07-12 19:12:34,665 [run_pretraining.py:  558]:	worker_index: 3, step: 2017, cost: 7.422765, mlm loss: 7.422765, speed: 1.062459 steps/s, speed: 8.499671 samples/s, speed: 4351.831591 tokens/s, learning rate: 2.016e-05, loss_scalings: 3518.437988, pp_loss: 7.282279
[INFO] 2021-07-12 19:12:34,665 [run_pretraining.py:  512]:	********exe.run_2017******* 
[INFO] 2021-07-12 19:12:35,625 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:35,626 [run_pretraining.py:  534]:	loss/total_loss, 7.621490001678467, 2018
[INFO] 2021-07-12 19:12:35,626 [run_pretraining.py:  535]:	loss/mlm_loss, 7.621490001678467, 2018
[INFO] 2021-07-12 19:12:35,626 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0170000425423495e-05, 2018
[INFO] 2021-07-12 19:12:35,626 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2018
[INFO] 2021-07-12 19:12:35,626 [run_pretraining.py:  558]:	worker_index: 3, step: 2018, cost: 7.621490, mlm loss: 7.621490, speed: 1.041584 steps/s, speed: 8.332675 samples/s, speed: 4266.329559 tokens/s, learning rate: 2.017e-05, loss_scalings: 3518.437988, pp_loss: 7.492669
[INFO] 2021-07-12 19:12:35,626 [run_pretraining.py:  512]:	********exe.run_2018******* 
[INFO] 2021-07-12 19:12:36,586 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:36,587 [run_pretraining.py:  534]:	loss/total_loss, 7.3052473068237305, 2019
[INFO] 2021-07-12 19:12:36,587 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3052473068237305, 2019
[INFO] 2021-07-12 19:12:36,587 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0179999410174787e-05, 2019
[INFO] 2021-07-12 19:12:36,587 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2019
[INFO] 2021-07-12 19:12:36,587 [run_pretraining.py:  558]:	worker_index: 3, step: 2019, cost: 7.305247, mlm loss: 7.305247, speed: 1.041319 steps/s, speed: 8.330548 samples/s, speed: 4265.240701 tokens/s, learning rate: 2.018e-05, loss_scalings: 3518.437988, pp_loss: 7.300053
[INFO] 2021-07-12 19:12:36,587 [run_pretraining.py:  512]:	********exe.run_2019******* 
[INFO] 2021-07-12 19:12:37,546 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:37,547 [run_pretraining.py:  534]:	loss/total_loss, 6.8383378982543945, 2020
[INFO] 2021-07-12 19:12:37,547 [run_pretraining.py:  535]:	loss/mlm_loss, 6.8383378982543945, 2020
[INFO] 2021-07-12 19:12:37,547 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0190000213915482e-05, 2020
[INFO] 2021-07-12 19:12:37,547 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2020
[INFO] 2021-07-12 19:12:37,547 [run_pretraining.py:  558]:	worker_index: 3, step: 2020, cost: 6.838338, mlm loss: 6.838338, speed: 1.042082 steps/s, speed: 8.336656 samples/s, speed: 4268.367894 tokens/s, learning rate: 2.019e-05, loss_scalings: 3518.437988, pp_loss: 7.186370
[INFO] 2021-07-12 19:12:37,547 [run_pretraining.py:  512]:	********exe.run_2020******* 
[INFO] 2021-07-12 19:12:38,505 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:38,505 [run_pretraining.py:  534]:	loss/total_loss, 7.202884197235107, 2021
[INFO] 2021-07-12 19:12:38,505 [run_pretraining.py:  535]:	loss/mlm_loss, 7.202884197235107, 2021
[INFO] 2021-07-12 19:12:38,506 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0200001017656177e-05, 2021
[INFO] 2021-07-12 19:12:38,506 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2021
[INFO] 2021-07-12 19:12:38,506 [run_pretraining.py:  558]:	worker_index: 3, step: 2021, cost: 7.202884, mlm loss: 7.202884, speed: 1.043895 steps/s, speed: 8.351159 samples/s, speed: 4275.793569 tokens/s, learning rate: 2.020e-05, loss_scalings: 3518.437988, pp_loss: 7.183548
[INFO] 2021-07-12 19:12:38,506 [run_pretraining.py:  512]:	********exe.run_2021******* 
[INFO] 2021-07-12 19:12:39,458 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:39,458 [run_pretraining.py:  534]:	loss/total_loss, 7.427619934082031, 2022
[INFO] 2021-07-12 19:12:39,458 [run_pretraining.py:  535]:	loss/mlm_loss, 7.427619934082031, 2022
[INFO] 2021-07-12 19:12:39,458 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0209998183418065e-05, 2022
[INFO] 2021-07-12 19:12:39,458 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2022
[INFO] 2021-07-12 19:12:39,458 [run_pretraining.py:  558]:	worker_index: 3, step: 2022, cost: 7.427620, mlm loss: 7.427620, speed: 1.050302 steps/s, speed: 8.402419 samples/s, speed: 4302.038772 tokens/s, learning rate: 2.021e-05, loss_scalings: 3518.437988, pp_loss: 7.271941
[INFO] 2021-07-12 19:12:39,458 [run_pretraining.py:  512]:	********exe.run_2022******* 
[INFO] 2021-07-12 19:12:40,395 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:40,396 [run_pretraining.py:  534]:	loss/total_loss, 7.608062744140625, 2023
[INFO] 2021-07-12 19:12:40,396 [run_pretraining.py:  535]:	loss/mlm_loss, 7.608062744140625, 2023
[INFO] 2021-07-12 19:12:40,396 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.021999898715876e-05, 2023
[INFO] 2021-07-12 19:12:40,396 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2023
[INFO] 2021-07-12 19:12:40,396 [run_pretraining.py:  558]:	worker_index: 3, step: 2023, cost: 7.608063, mlm loss: 7.608063, speed: 1.066961 steps/s, speed: 8.535689 samples/s, speed: 4370.272555 tokens/s, learning rate: 2.022e-05, loss_scalings: 3518.437988, pp_loss: 7.391947
[INFO] 2021-07-12 19:12:40,396 [run_pretraining.py:  512]:	********exe.run_2023******* 
[INFO] 2021-07-12 19:12:41,343 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:41,344 [run_pretraining.py:  534]:	loss/total_loss, 7.008206844329834, 2024
[INFO] 2021-07-12 19:12:41,344 [run_pretraining.py:  535]:	loss/mlm_loss, 7.008206844329834, 2024
[INFO] 2021-07-12 19:12:41,344 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0229999790899456e-05, 2024
[INFO] 2021-07-12 19:12:41,344 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2024
[INFO] 2021-07-12 19:12:41,344 [run_pretraining.py:  558]:	worker_index: 3, step: 2024, cost: 7.008207, mlm loss: 7.008207, speed: 1.055718 steps/s, speed: 8.445746 samples/s, speed: 4324.221737 tokens/s, learning rate: 2.023e-05, loss_scalings: 3518.437988, pp_loss: 7.288068
[INFO] 2021-07-12 19:12:41,344 [run_pretraining.py:  512]:	********exe.run_2024******* 
[INFO] 2021-07-12 19:12:42,282 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:42,282 [run_pretraining.py:  534]:	loss/total_loss, 7.16064453125, 2025
[INFO] 2021-07-12 19:12:42,282 [run_pretraining.py:  535]:	loss/mlm_loss, 7.16064453125, 2025
[INFO] 2021-07-12 19:12:42,282 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0239998775650747e-05, 2025
[INFO] 2021-07-12 19:12:42,282 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2025
[INFO] 2021-07-12 19:12:42,282 [run_pretraining.py:  558]:	worker_index: 3, step: 2025, cost: 7.160645, mlm loss: 7.160645, speed: 1.066544 steps/s, speed: 8.532353 samples/s, speed: 4368.564502 tokens/s, learning rate: 2.024e-05, loss_scalings: 3518.437988, pp_loss: 7.341047
[INFO] 2021-07-12 19:12:42,282 [run_pretraining.py:  512]:	********exe.run_2025******* 
[INFO] 2021-07-12 19:12:43,209 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:43,210 [run_pretraining.py:  534]:	loss/total_loss, 7.423206806182861, 2026
[INFO] 2021-07-12 19:12:43,210 [run_pretraining.py:  535]:	loss/mlm_loss, 7.423206806182861, 2026
[INFO] 2021-07-12 19:12:43,210 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0249999579391442e-05, 2026
[INFO] 2021-07-12 19:12:43,210 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2026
[INFO] 2021-07-12 19:12:43,210 [run_pretraining.py:  558]:	worker_index: 3, step: 2026, cost: 7.423207, mlm loss: 7.423207, speed: 1.078813 steps/s, speed: 8.630506 samples/s, speed: 4418.819061 tokens/s, learning rate: 2.025e-05, loss_scalings: 3518.437988, pp_loss: 6.336198
[INFO] 2021-07-12 19:12:43,210 [run_pretraining.py:  512]:	********exe.run_2026******* 
[INFO] 2021-07-12 19:12:44,158 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:44,159 [run_pretraining.py:  534]:	loss/total_loss, 6.942266464233398, 2027
[INFO] 2021-07-12 19:12:44,159 [run_pretraining.py:  535]:	loss/mlm_loss, 6.942266464233398, 2027
[INFO] 2021-07-12 19:12:44,159 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0260000383132137e-05, 2027
[INFO] 2021-07-12 19:12:44,159 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2027
[INFO] 2021-07-12 19:12:44,159 [run_pretraining.py:  558]:	worker_index: 3, step: 2027, cost: 6.942266, mlm loss: 6.942266, speed: 1.054397 steps/s, speed: 8.435174 samples/s, speed: 4318.809283 tokens/s, learning rate: 2.026e-05, loss_scalings: 3518.437988, pp_loss: 7.229859
[INFO] 2021-07-12 19:12:44,159 [run_pretraining.py:  512]:	********exe.run_2027******* 
[INFO] 2021-07-12 19:12:45,106 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:45,107 [run_pretraining.py:  534]:	loss/total_loss, 7.039450645446777, 2028
[INFO] 2021-07-12 19:12:45,107 [run_pretraining.py:  535]:	loss/mlm_loss, 7.039450645446777, 2028
[INFO] 2021-07-12 19:12:45,107 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.026999936788343e-05, 2028
[INFO] 2021-07-12 19:12:45,107 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2028
[INFO] 2021-07-12 19:12:45,107 [run_pretraining.py:  558]:	worker_index: 3, step: 2028, cost: 7.039451, mlm loss: 7.039451, speed: 1.055471 steps/s, speed: 8.443769 samples/s, speed: 4323.209744 tokens/s, learning rate: 2.027e-05, loss_scalings: 3518.437988, pp_loss: 7.300015
[INFO] 2021-07-12 19:12:45,107 [run_pretraining.py:  512]:	********exe.run_2028******* 
[INFO] 2021-07-12 19:12:46,061 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:46,061 [run_pretraining.py:  534]:	loss/total_loss, 6.420507431030273, 2029
[INFO] 2021-07-12 19:12:46,061 [run_pretraining.py:  535]:	loss/mlm_loss, 6.420507431030273, 2029
[INFO] 2021-07-12 19:12:46,061 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0280000171624124e-05, 2029
[INFO] 2021-07-12 19:12:46,061 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2029
[INFO] 2021-07-12 19:12:46,061 [run_pretraining.py:  558]:	worker_index: 3, step: 2029, cost: 6.420507, mlm loss: 6.420507, speed: 1.048477 steps/s, speed: 8.387820 samples/s, speed: 4294.563607 tokens/s, learning rate: 2.028e-05, loss_scalings: 3518.437988, pp_loss: 6.834456
[INFO] 2021-07-12 19:12:46,062 [run_pretraining.py:  512]:	********exe.run_2029******* 
[INFO] 2021-07-12 19:12:47,015 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:47,015 [run_pretraining.py:  534]:	loss/total_loss, 6.031396389007568, 2030
[INFO] 2021-07-12 19:12:47,015 [run_pretraining.py:  535]:	loss/mlm_loss, 6.031396389007568, 2030
[INFO] 2021-07-12 19:12:47,015 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.029000097536482e-05, 2030
[INFO] 2021-07-12 19:12:47,015 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2030
[INFO] 2021-07-12 19:12:47,015 [run_pretraining.py:  558]:	worker_index: 3, step: 2030, cost: 6.031396, mlm loss: 6.031396, speed: 1.048937 steps/s, speed: 8.391497 samples/s, speed: 4296.446348 tokens/s, learning rate: 2.029e-05, loss_scalings: 3518.437988, pp_loss: 6.645259
[INFO] 2021-07-12 19:12:47,016 [run_pretraining.py:  512]:	********exe.run_2030******* 
[INFO] 2021-07-12 19:12:47,959 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:47,960 [run_pretraining.py:  534]:	loss/total_loss, 7.4045586585998535, 2031
[INFO] 2021-07-12 19:12:47,960 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4045586585998535, 2031
[INFO] 2021-07-12 19:12:47,960 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0299998141126707e-05, 2031
[INFO] 2021-07-12 19:12:47,960 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2031
[INFO] 2021-07-12 19:12:47,960 [run_pretraining.py:  558]:	worker_index: 3, step: 2031, cost: 7.404559, mlm loss: 7.404559, speed: 1.059284 steps/s, speed: 8.474270 samples/s, speed: 4338.826322 tokens/s, learning rate: 2.030e-05, loss_scalings: 3518.437988, pp_loss: 7.304174
[INFO] 2021-07-12 19:12:47,960 [run_pretraining.py:  512]:	********exe.run_2031******* 
[INFO] 2021-07-12 19:12:48,921 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:48,922 [run_pretraining.py:  534]:	loss/total_loss, 7.964761734008789, 2032
[INFO] 2021-07-12 19:12:48,922 [run_pretraining.py:  535]:	loss/mlm_loss, 7.964761734008789, 2032
[INFO] 2021-07-12 19:12:48,922 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0309998944867402e-05, 2032
[INFO] 2021-07-12 19:12:48,922 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2032
[INFO] 2021-07-12 19:12:48,922 [run_pretraining.py:  558]:	worker_index: 3, step: 2032, cost: 7.964762, mlm loss: 7.964762, speed: 1.040466 steps/s, speed: 8.323729 samples/s, speed: 4261.749093 tokens/s, learning rate: 2.031e-05, loss_scalings: 3518.437988, pp_loss: 7.742568
[INFO] 2021-07-12 19:12:48,922 [run_pretraining.py:  512]:	********exe.run_2032******* 
[INFO] 2021-07-12 19:13:15,584 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:15,585 [run_pretraining.py:  534]:	loss/total_loss, 7.539840221405029, 2033
[INFO] 2021-07-12 19:13:15,585 [run_pretraining.py:  535]:	loss/mlm_loss, 7.539840221405029, 2033
[INFO] 2021-07-12 19:13:15,585 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0319999748608097e-05, 2033
[INFO] 2021-07-12 19:13:15,585 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2033
[INFO] 2021-07-12 19:13:15,585 [run_pretraining.py:  558]:	worker_index: 3, step: 2033, cost: 7.539840, mlm loss: 7.539840, speed: 0.037506 steps/s, speed: 0.300044 samples/s, speed: 153.622764 tokens/s, learning rate: 2.032e-05, loss_scalings: 3518.437988, pp_loss: 6.436804
[INFO] 2021-07-12 19:13:15,585 [run_pretraining.py:  512]:	********exe.run_2033******* 
[INFO] 2021-07-12 19:13:41,715 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:41,716 [run_pretraining.py:  534]:	loss/total_loss, 7.348398208618164, 2034
[INFO] 2021-07-12 19:13:41,716 [run_pretraining.py:  535]:	loss/mlm_loss, 7.348398208618164, 2034
[INFO] 2021-07-12 19:13:41,716 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.032999873335939e-05, 2034
[INFO] 2021-07-12 19:13:41,716 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2034
[INFO] 2021-07-12 19:13:41,716 [run_pretraining.py:  558]:	worker_index: 3, step: 2034, cost: 7.348398, mlm loss: 7.348398, speed: 0.038270 steps/s, speed: 0.306159 samples/s, speed: 156.753515 tokens/s, learning rate: 2.033e-05, loss_scalings: 3518.437988, pp_loss: 7.691220
[INFO] 2021-07-12 19:13:41,716 [run_pretraining.py:  512]:	********exe.run_2034******* 
[INFO] 2021-07-12 19:13:42,639 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:42,640 [run_pretraining.py:  534]:	loss/total_loss, 6.7140583992004395, 2035
[INFO] 2021-07-12 19:13:42,640 [run_pretraining.py:  535]:	loss/mlm_loss, 6.7140583992004395, 2035
[INFO] 2021-07-12 19:13:42,640 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0339999537100084e-05, 2035
[INFO] 2021-07-12 19:13:42,640 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2035
[INFO] 2021-07-12 19:13:42,640 [run_pretraining.py:  558]:	worker_index: 3, step: 2035, cost: 6.714058, mlm loss: 6.714058, speed: 1.083045 steps/s, speed: 8.664360 samples/s, speed: 4436.152278 tokens/s, learning rate: 2.034e-05, loss_scalings: 3518.437988, pp_loss: 6.537840
[INFO] 2021-07-12 19:13:42,640 [run_pretraining.py:  512]:	********exe.run_2035******* 
[INFO] 2021-07-12 19:13:43,583 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:43,584 [run_pretraining.py:  534]:	loss/total_loss, 7.4403791427612305, 2036
[INFO] 2021-07-12 19:13:43,584 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4403791427612305, 2036
[INFO] 2021-07-12 19:13:43,584 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.035000034084078e-05, 2036
[INFO] 2021-07-12 19:13:43,584 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2036
[INFO] 2021-07-12 19:13:43,584 [run_pretraining.py:  558]:	worker_index: 3, step: 2036, cost: 7.440379, mlm loss: 7.440379, speed: 1.059860 steps/s, speed: 8.478878 samples/s, speed: 4341.185730 tokens/s, learning rate: 2.035e-05, loss_scalings: 3518.437988, pp_loss: 7.018054
[INFO] 2021-07-12 19:13:43,584 [run_pretraining.py:  512]:	********exe.run_2036******* 
[INFO] 2021-07-12 19:13:44,507 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:44,508 [run_pretraining.py:  534]:	loss/total_loss, 7.077553749084473, 2037
[INFO] 2021-07-12 19:13:44,508 [run_pretraining.py:  535]:	loss/mlm_loss, 7.077553749084473, 2037
[INFO] 2021-07-12 19:13:44,508 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.035999932559207e-05, 2037
[INFO] 2021-07-12 19:13:44,508 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2037
[INFO] 2021-07-12 19:13:44,508 [run_pretraining.py:  558]:	worker_index: 3, step: 2037, cost: 7.077554, mlm loss: 7.077554, speed: 1.083026 steps/s, speed: 8.664206 samples/s, speed: 4436.073241 tokens/s, learning rate: 2.036e-05, loss_scalings: 3518.437988, pp_loss: 7.484011
[INFO] 2021-07-12 19:13:44,508 [run_pretraining.py:  512]:	********exe.run_2037******* 
[INFO] 2021-07-12 19:13:45,444 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:45,445 [run_pretraining.py:  534]:	loss/total_loss, 7.503002166748047, 2038
[INFO] 2021-07-12 19:13:45,445 [run_pretraining.py:  535]:	loss/mlm_loss, 7.503002166748047, 2038
[INFO] 2021-07-12 19:13:45,445 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0370000129332766e-05, 2038
[INFO] 2021-07-12 19:13:45,445 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2038
[INFO] 2021-07-12 19:13:45,445 [run_pretraining.py:  558]:	worker_index: 3, step: 2038, cost: 7.503002, mlm loss: 7.503002, speed: 1.068368 steps/s, speed: 8.546947 samples/s, speed: 4376.036657 tokens/s, learning rate: 2.037e-05, loss_scalings: 3518.437988, pp_loss: 7.383383
[INFO] 2021-07-12 19:13:45,445 [run_pretraining.py:  512]:	********exe.run_2038******* 
[INFO] 2021-07-12 19:13:46,389 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:46,389 [run_pretraining.py:  534]:	loss/total_loss, 7.5275797843933105, 2039
[INFO] 2021-07-12 19:13:46,389 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5275797843933105, 2039
[INFO] 2021-07-12 19:13:46,389 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0379999114084058e-05, 2039
[INFO] 2021-07-12 19:13:46,389 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2039
[INFO] 2021-07-12 19:13:46,389 [run_pretraining.py:  558]:	worker_index: 3, step: 2039, cost: 7.527580, mlm loss: 7.527580, speed: 1.059344 steps/s, speed: 8.474752 samples/s, speed: 4339.072887 tokens/s, learning rate: 2.038e-05, loss_scalings: 3518.437988, pp_loss: 7.341655
[INFO] 2021-07-12 19:13:46,390 [run_pretraining.py:  512]:	********exe.run_2039******* 
[INFO] 2021-07-12 19:13:47,310 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:47,310 [run_pretraining.py:  534]:	loss/total_loss, 7.1951446533203125, 2040
[INFO] 2021-07-12 19:13:47,310 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1951446533203125, 2040
[INFO] 2021-07-12 19:13:47,310 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.038999809883535e-05, 2040
[INFO] 2021-07-12 19:13:47,310 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2040
[INFO] 2021-07-12 19:13:47,310 [run_pretraining.py:  558]:	worker_index: 3, step: 2040, cost: 7.195145, mlm loss: 7.195145, speed: 1.086490 steps/s, speed: 8.691917 samples/s, speed: 4450.261392 tokens/s, learning rate: 2.039e-05, loss_scalings: 3518.437988, pp_loss: 7.439047
[INFO] 2021-07-12 19:13:47,311 [run_pretraining.py:  512]:	********exe.run_2040******* 
[INFO] 2021-07-12 19:13:48,227 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:48,228 [run_pretraining.py:  534]:	loss/total_loss, 6.925298690795898, 2041
[INFO] 2021-07-12 19:13:48,228 [run_pretraining.py:  535]:	loss/mlm_loss, 6.925298690795898, 2041
[INFO] 2021-07-12 19:13:48,228 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0399998902576044e-05, 2041
[INFO] 2021-07-12 19:13:48,228 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2041
[INFO] 2021-07-12 19:13:48,228 [run_pretraining.py:  558]:	worker_index: 3, step: 2041, cost: 6.925299, mlm loss: 6.925299, speed: 1.090550 steps/s, speed: 8.724399 samples/s, speed: 4466.892401 tokens/s, learning rate: 2.040e-05, loss_scalings: 3518.437988, pp_loss: 7.007871
[INFO] 2021-07-12 19:13:48,228 [run_pretraining.py:  512]:	********exe.run_2041******* 
[INFO] 2021-07-12 19:13:49,145 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:49,145 [run_pretraining.py:  534]:	loss/total_loss, 7.570474147796631, 2042
[INFO] 2021-07-12 19:13:49,146 [run_pretraining.py:  535]:	loss/mlm_loss, 7.570474147796631, 2042
[INFO] 2021-07-12 19:13:49,146 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.040999970631674e-05, 2042
[INFO] 2021-07-12 19:13:49,146 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2042
[INFO] 2021-07-12 19:13:49,146 [run_pretraining.py:  558]:	worker_index: 3, step: 2042, cost: 7.570474, mlm loss: 7.570474, speed: 1.090418 steps/s, speed: 8.723340 samples/s, speed: 4466.350081 tokens/s, learning rate: 2.041e-05, loss_scalings: 3518.437988, pp_loss: 6.723206
[INFO] 2021-07-12 19:13:49,146 [run_pretraining.py:  512]:	********exe.run_2042******* 
[INFO] 2021-07-12 19:13:50,066 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:50,067 [run_pretraining.py:  534]:	loss/total_loss, 7.558277130126953, 2043
[INFO] 2021-07-12 19:13:50,067 [run_pretraining.py:  535]:	loss/mlm_loss, 7.558277130126953, 2043
[INFO] 2021-07-12 19:13:50,067 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.041999869106803e-05, 2043
[INFO] 2021-07-12 19:13:50,067 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2043
[INFO] 2021-07-12 19:13:50,067 [run_pretraining.py:  558]:	worker_index: 3, step: 2043, cost: 7.558277, mlm loss: 7.558277, speed: 1.086381 steps/s, speed: 8.691046 samples/s, speed: 4449.815306 tokens/s, learning rate: 2.042e-05, loss_scalings: 3518.437988, pp_loss: 6.621469
[INFO] 2021-07-12 19:13:50,067 [run_pretraining.py:  512]:	********exe.run_2043******* 
[INFO] 2021-07-12 19:13:50,991 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:50,992 [run_pretraining.py:  534]:	loss/total_loss, 6.775932788848877, 2044
[INFO] 2021-07-12 19:13:50,992 [run_pretraining.py:  535]:	loss/mlm_loss, 6.775932788848877, 2044
[INFO] 2021-07-12 19:13:50,992 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0429999494808726e-05, 2044
[INFO] 2021-07-12 19:13:50,992 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2044
[INFO] 2021-07-12 19:13:50,992 [run_pretraining.py:  558]:	worker_index: 3, step: 2044, cost: 6.775933, mlm loss: 6.775933, speed: 1.081632 steps/s, speed: 8.653058 samples/s, speed: 4430.365924 tokens/s, learning rate: 2.043e-05, loss_scalings: 3518.437988, pp_loss: 7.046080
[INFO] 2021-07-12 19:13:50,992 [run_pretraining.py:  512]:	********exe.run_2044******* 
[INFO] 2021-07-12 19:13:51,915 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:51,916 [run_pretraining.py:  534]:	loss/total_loss, 7.501489639282227, 2045
[INFO] 2021-07-12 19:13:51,916 [run_pretraining.py:  535]:	loss/mlm_loss, 7.501489639282227, 2045
[INFO] 2021-07-12 19:13:51,916 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.044000029854942e-05, 2045
[INFO] 2021-07-12 19:13:51,916 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2045
[INFO] 2021-07-12 19:13:51,916 [run_pretraining.py:  558]:	worker_index: 3, step: 2045, cost: 7.501490, mlm loss: 7.501490, speed: 1.083093 steps/s, speed: 8.664740 samples/s, speed: 4436.347021 tokens/s, learning rate: 2.044e-05, loss_scalings: 3518.437988, pp_loss: 7.309734
[INFO] 2021-07-12 19:13:51,916 [run_pretraining.py:  512]:	********exe.run_2045******* 
[INFO] 2021-07-12 19:13:52,841 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:52,841 [run_pretraining.py:  534]:	loss/total_loss, 7.652187824249268, 2046
[INFO] 2021-07-12 19:13:52,841 [run_pretraining.py:  535]:	loss/mlm_loss, 7.652187824249268, 2046
[INFO] 2021-07-12 19:13:52,842 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0449999283300713e-05, 2046
[INFO] 2021-07-12 19:13:52,842 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2046
[INFO] 2021-07-12 19:13:52,842 [run_pretraining.py:  558]:	worker_index: 3, step: 2046, cost: 7.652188, mlm loss: 7.652188, speed: 1.080979 steps/s, speed: 8.647829 samples/s, speed: 4427.688362 tokens/s, learning rate: 2.045e-05, loss_scalings: 3518.437988, pp_loss: 7.549567
[INFO] 2021-07-12 19:13:52,842 [run_pretraining.py:  512]:	********exe.run_2046******* 
[INFO] 2021-07-12 19:13:53,797 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:53,797 [run_pretraining.py:  534]:	loss/total_loss, 6.753566741943359, 2047
[INFO] 2021-07-12 19:13:53,797 [run_pretraining.py:  535]:	loss/mlm_loss, 6.753566741943359, 2047
[INFO] 2021-07-12 19:13:53,797 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0460000087041408e-05, 2047
[INFO] 2021-07-12 19:13:53,797 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2047
[INFO] 2021-07-12 19:13:53,797 [run_pretraining.py:  558]:	worker_index: 3, step: 2047, cost: 6.753567, mlm loss: 6.753567, speed: 1.047078 steps/s, speed: 8.376625 samples/s, speed: 4288.832122 tokens/s, learning rate: 2.046e-05, loss_scalings: 3518.437988, pp_loss: 7.076340
[INFO] 2021-07-12 19:13:53,798 [run_pretraining.py:  512]:	********exe.run_2047******* 
[INFO] 2021-07-12 19:13:54,720 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:54,720 [run_pretraining.py:  534]:	loss/total_loss, 6.747061252593994, 2048
[INFO] 2021-07-12 19:13:54,721 [run_pretraining.py:  535]:	loss/mlm_loss, 6.747061252593994, 2048
[INFO] 2021-07-12 19:13:54,721 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.04699990717927e-05, 2048
[INFO] 2021-07-12 19:13:54,721 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2048
[INFO] 2021-07-12 19:13:54,721 [run_pretraining.py:  558]:	worker_index: 3, step: 2048, cost: 6.747061, mlm loss: 6.747061, speed: 1.083767 steps/s, speed: 8.670134 samples/s, speed: 4439.108478 tokens/s, learning rate: 2.047e-05, loss_scalings: 3518.437988, pp_loss: 6.364918
[INFO] 2021-07-12 19:13:54,721 [run_pretraining.py:  512]:	********exe.run_2048******* 
[INFO] 2021-07-12 19:13:55,656 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:55,657 [run_pretraining.py:  534]:	loss/total_loss, 7.337531089782715, 2049
[INFO] 2021-07-12 19:13:55,657 [run_pretraining.py:  535]:	loss/mlm_loss, 7.337531089782715, 2049
[INFO] 2021-07-12 19:13:55,657 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.047999805654399e-05, 2049
[INFO] 2021-07-12 19:13:55,657 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2049
[INFO] 2021-07-12 19:13:55,657 [run_pretraining.py:  558]:	worker_index: 3, step: 2049, cost: 7.337531, mlm loss: 7.337531, speed: 1.068700 steps/s, speed: 8.549599 samples/s, speed: 4377.394733 tokens/s, learning rate: 2.048e-05, loss_scalings: 3518.437988, pp_loss: 6.828498
[INFO] 2021-07-12 19:13:55,657 [run_pretraining.py:  512]:	********exe.run_2049******* 
[INFO] 2021-07-12 19:13:56,595 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:56,596 [run_pretraining.py:  534]:	loss/total_loss, 7.2172651290893555, 2050
[INFO] 2021-07-12 19:13:56,596 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2172651290893555, 2050
[INFO] 2021-07-12 19:13:56,596 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0489998860284686e-05, 2050
[INFO] 2021-07-12 19:13:56,596 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2050
[INFO] 2021-07-12 19:13:56,596 [run_pretraining.py:  558]:	worker_index: 3, step: 2050, cost: 7.217265, mlm loss: 7.217265, speed: 1.065815 steps/s, speed: 8.526518 samples/s, speed: 4365.577234 tokens/s, learning rate: 2.049e-05, loss_scalings: 3518.437988, pp_loss: 6.394291
[INFO] 2021-07-12 19:13:56,596 [run_pretraining.py:  512]:	********exe.run_2050******* 
[INFO] 2021-07-12 19:13:57,548 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:57,549 [run_pretraining.py:  534]:	loss/total_loss, 7.3313212394714355, 2051
[INFO] 2021-07-12 19:13:57,549 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3313212394714355, 2051
[INFO] 2021-07-12 19:13:57,549 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.049999966402538e-05, 2051
[INFO] 2021-07-12 19:13:57,549 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2051
[INFO] 2021-07-12 19:13:57,549 [run_pretraining.py:  558]:	worker_index: 3, step: 2051, cost: 7.331321, mlm loss: 7.331321, speed: 1.049685 steps/s, speed: 8.397478 samples/s, speed: 4299.508652 tokens/s, learning rate: 2.050e-05, loss_scalings: 3518.437988, pp_loss: 7.309128
[INFO] 2021-07-12 19:13:57,549 [run_pretraining.py:  512]:	********exe.run_2051******* 
[INFO] 2021-07-12 19:13:58,509 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:58,510 [run_pretraining.py:  534]:	loss/total_loss, 7.087861061096191, 2052
[INFO] 2021-07-12 19:13:58,510 [run_pretraining.py:  535]:	loss/mlm_loss, 7.087861061096191, 2052
[INFO] 2021-07-12 19:13:58,510 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0509998648776673e-05, 2052
[INFO] 2021-07-12 19:13:58,510 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2052
[INFO] 2021-07-12 19:13:58,510 [run_pretraining.py:  558]:	worker_index: 3, step: 2052, cost: 7.087861, mlm loss: 7.087861, speed: 1.041643 steps/s, speed: 8.333145 samples/s, speed: 4266.570072 tokens/s, learning rate: 2.051e-05, loss_scalings: 3518.437988, pp_loss: 7.048075
[INFO] 2021-07-12 19:13:58,510 [run_pretraining.py:  512]:	********exe.run_2052******* 
[INFO] 2021-07-12 19:13:59,444 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:59,444 [run_pretraining.py:  534]:	loss/total_loss, 7.515806674957275, 2053
[INFO] 2021-07-12 19:13:59,444 [run_pretraining.py:  535]:	loss/mlm_loss, 7.515806674957275, 2053
[INFO] 2021-07-12 19:13:59,444 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0519999452517368e-05, 2053
[INFO] 2021-07-12 19:13:59,445 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2053
[INFO] 2021-07-12 19:13:59,445 [run_pretraining.py:  558]:	worker_index: 3, step: 2053, cost: 7.515807, mlm loss: 7.515807, speed: 1.070601 steps/s, speed: 8.564805 samples/s, speed: 4385.180322 tokens/s, learning rate: 2.052e-05, loss_scalings: 3518.437988, pp_loss: 7.563168
[INFO] 2021-07-12 19:13:59,445 [run_pretraining.py:  512]:	********exe.run_2053******* 
[INFO] 2021-07-12 19:14:00,396 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:00,397 [run_pretraining.py:  534]:	loss/total_loss, 7.346235275268555, 2054
[INFO] 2021-07-12 19:14:00,397 [run_pretraining.py:  535]:	loss/mlm_loss, 7.346235275268555, 2054
[INFO] 2021-07-12 19:14:00,397 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0530000256258063e-05, 2054
[INFO] 2021-07-12 19:14:00,397 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2054
[INFO] 2021-07-12 19:14:00,397 [run_pretraining.py:  558]:	worker_index: 3, step: 2054, cost: 7.346235, mlm loss: 7.346235, speed: 1.050558 steps/s, speed: 8.404463 samples/s, speed: 4303.085066 tokens/s, learning rate: 2.053e-05, loss_scalings: 3518.437988, pp_loss: 7.416458
[INFO] 2021-07-12 19:14:00,397 [run_pretraining.py:  512]:	********exe.run_2054******* 
[INFO] 2021-07-12 19:14:01,345 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:01,346 [run_pretraining.py:  534]:	loss/total_loss, 7.423345565795898, 2055
[INFO] 2021-07-12 19:14:01,346 [run_pretraining.py:  535]:	loss/mlm_loss, 7.423345565795898, 2055
[INFO] 2021-07-12 19:14:01,346 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0539999241009355e-05, 2055
[INFO] 2021-07-12 19:14:01,346 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2055
[INFO] 2021-07-12 19:14:01,346 [run_pretraining.py:  558]:	worker_index: 3, step: 2055, cost: 7.423346, mlm loss: 7.423346, speed: 1.054345 steps/s, speed: 8.434761 samples/s, speed: 4318.597582 tokens/s, learning rate: 2.054e-05, loss_scalings: 3518.437988, pp_loss: 7.469660
[INFO] 2021-07-12 19:14:01,346 [run_pretraining.py:  512]:	********exe.run_2055******* 
[INFO] 2021-07-12 19:14:02,288 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:02,289 [run_pretraining.py:  534]:	loss/total_loss, 7.393990516662598, 2056
[INFO] 2021-07-12 19:14:02,289 [run_pretraining.py:  535]:	loss/mlm_loss, 7.393990516662598, 2056
[INFO] 2021-07-12 19:14:02,289 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.055000004475005e-05, 2056
[INFO] 2021-07-12 19:14:02,289 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2056
[INFO] 2021-07-12 19:14:02,289 [run_pretraining.py:  558]:	worker_index: 3, step: 2056, cost: 7.393991, mlm loss: 7.393991, speed: 1.061060 steps/s, speed: 8.488479 samples/s, speed: 4346.101351 tokens/s, learning rate: 2.055e-05, loss_scalings: 3518.437988, pp_loss: 7.673568
[INFO] 2021-07-12 19:14:02,289 [run_pretraining.py:  512]:	********exe.run_2056******* 
[INFO] 2021-07-12 19:14:03,234 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:03,235 [run_pretraining.py:  534]:	loss/total_loss, 7.301192283630371, 2057
[INFO] 2021-07-12 19:14:03,235 [run_pretraining.py:  535]:	loss/mlm_loss, 7.301192283630371, 2057
[INFO] 2021-07-12 19:14:03,235 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.055999902950134e-05, 2057
[INFO] 2021-07-12 19:14:03,235 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2057
[INFO] 2021-07-12 19:14:03,235 [run_pretraining.py:  558]:	worker_index: 3, step: 2057, cost: 7.301192, mlm loss: 7.301192, speed: 1.057967 steps/s, speed: 8.463734 samples/s, speed: 4333.431921 tokens/s, learning rate: 2.056e-05, loss_scalings: 3518.437988, pp_loss: 7.083323
[INFO] 2021-07-12 19:14:03,235 [run_pretraining.py:  512]:	********exe.run_2057******* 
[INFO] 2021-07-12 19:14:04,175 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:04,175 [run_pretraining.py:  534]:	loss/total_loss, 7.266024589538574, 2058
[INFO] 2021-07-12 19:14:04,175 [run_pretraining.py:  535]:	loss/mlm_loss, 7.266024589538574, 2058
[INFO] 2021-07-12 19:14:04,176 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0569999833242036e-05, 2058
[INFO] 2021-07-12 19:14:04,176 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2058
[INFO] 2021-07-12 19:14:04,176 [run_pretraining.py:  558]:	worker_index: 3, step: 2058, cost: 7.266025, mlm loss: 7.266025, speed: 1.063961 steps/s, speed: 8.511685 samples/s, speed: 4357.982635 tokens/s, learning rate: 2.057e-05, loss_scalings: 3518.437988, pp_loss: 7.209878
[INFO] 2021-07-12 19:14:04,176 [run_pretraining.py:  512]:	********exe.run_2058******* 
[INFO] 2021-07-12 19:14:05,121 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:05,122 [run_pretraining.py:  534]:	loss/total_loss, 6.679039001464844, 2059
[INFO] 2021-07-12 19:14:05,122 [run_pretraining.py:  535]:	loss/mlm_loss, 6.679039001464844, 2059
[INFO] 2021-07-12 19:14:05,122 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0579998817993328e-05, 2059
[INFO] 2021-07-12 19:14:05,122 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2059
[INFO] 2021-07-12 19:14:05,122 [run_pretraining.py:  558]:	worker_index: 3, step: 2059, cost: 6.679039, mlm loss: 6.679039, speed: 1.057595 steps/s, speed: 8.460759 samples/s, speed: 4331.908731 tokens/s, learning rate: 2.058e-05, loss_scalings: 3518.437988, pp_loss: 7.041645
[INFO] 2021-07-12 19:14:05,122 [run_pretraining.py:  512]:	********exe.run_2059******* 
[INFO] 2021-07-12 19:14:06,062 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:06,062 [run_pretraining.py:  534]:	loss/total_loss, 6.331184387207031, 2060
[INFO] 2021-07-12 19:14:06,062 [run_pretraining.py:  535]:	loss/mlm_loss, 6.331184387207031, 2060
[INFO] 2021-07-12 19:14:06,062 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0589999621734023e-05, 2060
[INFO] 2021-07-12 19:14:06,062 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2060
[INFO] 2021-07-12 19:14:06,062 [run_pretraining.py:  558]:	worker_index: 3, step: 2060, cost: 6.331184, mlm loss: 6.331184, speed: 1.063871 steps/s, speed: 8.510966 samples/s, speed: 4357.614541 tokens/s, learning rate: 2.059e-05, loss_scalings: 3518.437988, pp_loss: 7.097121
[INFO] 2021-07-12 19:14:06,063 [run_pretraining.py:  512]:	********exe.run_2060******* 
[INFO] 2021-07-12 19:14:07,004 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:07,005 [run_pretraining.py:  534]:	loss/total_loss, 7.461283206939697, 2061
[INFO] 2021-07-12 19:14:07,005 [run_pretraining.py:  535]:	loss/mlm_loss, 7.461283206939697, 2061
[INFO] 2021-07-12 19:14:07,005 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0599998606485315e-05, 2061
[INFO] 2021-07-12 19:14:07,005 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2061
[INFO] 2021-07-12 19:14:07,005 [run_pretraining.py:  558]:	worker_index: 3, step: 2061, cost: 7.461283, mlm loss: 7.461283, speed: 1.061521 steps/s, speed: 8.492166 samples/s, speed: 4347.988846 tokens/s, learning rate: 2.060e-05, loss_scalings: 3518.437988, pp_loss: 6.857580
[INFO] 2021-07-12 19:14:07,005 [run_pretraining.py:  512]:	********exe.run_2061******* 
[INFO] 2021-07-12 19:14:07,949 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:07,949 [run_pretraining.py:  534]:	loss/total_loss, 7.32579231262207, 2062
[INFO] 2021-07-12 19:14:07,950 [run_pretraining.py:  535]:	loss/mlm_loss, 7.32579231262207, 2062
[INFO] 2021-07-12 19:14:07,950 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.060999941022601e-05, 2062
[INFO] 2021-07-12 19:14:07,950 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2062
[INFO] 2021-07-12 19:14:07,950 [run_pretraining.py:  558]:	worker_index: 3, step: 2062, cost: 7.325792, mlm loss: 7.325792, speed: 1.059394 steps/s, speed: 8.475152 samples/s, speed: 4339.277832 tokens/s, learning rate: 2.061e-05, loss_scalings: 3518.437988, pp_loss: 7.395802
[INFO] 2021-07-12 19:14:07,950 [run_pretraining.py:  512]:	********exe.run_2062******* 
[INFO] 2021-07-12 19:14:08,885 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:08,885 [run_pretraining.py:  534]:	loss/total_loss, 7.807711124420166, 2063
[INFO] 2021-07-12 19:14:08,886 [run_pretraining.py:  535]:	loss/mlm_loss, 7.807711124420166, 2063
[INFO] 2021-07-12 19:14:08,886 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0620000213966705e-05, 2063
[INFO] 2021-07-12 19:14:08,886 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2063
[INFO] 2021-07-12 19:14:08,886 [run_pretraining.py:  558]:	worker_index: 3, step: 2063, cost: 7.807711, mlm loss: 7.807711, speed: 1.069079 steps/s, speed: 8.552633 samples/s, speed: 4378.947853 tokens/s, learning rate: 2.062e-05, loss_scalings: 3518.437988, pp_loss: 7.685639
[INFO] 2021-07-12 19:14:08,886 [run_pretraining.py:  512]:	********exe.run_2063******* 
[INFO] 2021-07-12 19:14:09,837 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:09,837 [run_pretraining.py:  534]:	loss/total_loss, 7.589748382568359, 2064
[INFO] 2021-07-12 19:14:09,837 [run_pretraining.py:  535]:	loss/mlm_loss, 7.589748382568359, 2064
[INFO] 2021-07-12 19:14:09,838 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0629999198717996e-05, 2064
[INFO] 2021-07-12 19:14:09,838 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2064
[INFO] 2021-07-12 19:14:09,838 [run_pretraining.py:  558]:	worker_index: 3, step: 2064, cost: 7.589748, mlm loss: 7.589748, speed: 1.051187 steps/s, speed: 8.409495 samples/s, speed: 4305.661483 tokens/s, learning rate: 2.063e-05, loss_scalings: 3518.437988, pp_loss: 7.526808
[INFO] 2021-07-12 19:14:09,838 [run_pretraining.py:  512]:	********exe.run_2064******* 
[INFO] 2021-07-12 19:14:10,779 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:10,779 [run_pretraining.py:  534]:	loss/total_loss, 6.673748970031738, 2065
[INFO] 2021-07-12 19:14:10,779 [run_pretraining.py:  535]:	loss/mlm_loss, 6.673748970031738, 2065
[INFO] 2021-07-12 19:14:10,779 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.064000000245869e-05, 2065
[INFO] 2021-07-12 19:14:10,779 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2065
[INFO] 2021-07-12 19:14:10,780 [run_pretraining.py:  558]:	worker_index: 3, step: 2065, cost: 6.673749, mlm loss: 6.673749, speed: 1.062429 steps/s, speed: 8.499430 samples/s, speed: 4351.708130 tokens/s, learning rate: 2.064e-05, loss_scalings: 3518.437988, pp_loss: 7.309886
[INFO] 2021-07-12 19:14:10,780 [run_pretraining.py:  512]:	********exe.run_2065******* 
[INFO] 2021-07-12 19:14:11,717 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:11,717 [run_pretraining.py:  534]:	loss/total_loss, 6.642459869384766, 2066
[INFO] 2021-07-12 19:14:11,717 [run_pretraining.py:  535]:	loss/mlm_loss, 6.642459869384766, 2066
[INFO] 2021-07-12 19:14:11,718 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0649998987209983e-05, 2066
[INFO] 2021-07-12 19:14:11,718 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2066
[INFO] 2021-07-12 19:14:11,718 [run_pretraining.py:  558]:	worker_index: 3, step: 2066, cost: 6.642460, mlm loss: 6.642460, speed: 1.066679 steps/s, speed: 8.533431 samples/s, speed: 4369.116667 tokens/s, learning rate: 2.065e-05, loss_scalings: 3518.437988, pp_loss: 7.488841
[INFO] 2021-07-12 19:14:11,718 [run_pretraining.py:  512]:	********exe.run_2066******* 
[INFO] 2021-07-12 19:14:12,654 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:12,655 [run_pretraining.py:  534]:	loss/total_loss, 7.471928596496582, 2067
[INFO] 2021-07-12 19:14:12,655 [run_pretraining.py:  535]:	loss/mlm_loss, 7.471928596496582, 2067
[INFO] 2021-07-12 19:14:12,655 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0659999790950678e-05, 2067
[INFO] 2021-07-12 19:14:12,655 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2067
[INFO] 2021-07-12 19:14:12,655 [run_pretraining.py:  558]:	worker_index: 3, step: 2067, cost: 7.471929, mlm loss: 7.471929, speed: 1.067257 steps/s, speed: 8.538058 samples/s, speed: 4371.485783 tokens/s, learning rate: 2.066e-05, loss_scalings: 3518.437988, pp_loss: 7.157990
[INFO] 2021-07-12 19:14:12,655 [run_pretraining.py:  512]:	********exe.run_2067******* 
[INFO] 2021-07-12 19:14:13,586 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:13,586 [run_pretraining.py:  534]:	loss/total_loss, 6.97098445892334, 2068
[INFO] 2021-07-12 19:14:13,586 [run_pretraining.py:  535]:	loss/mlm_loss, 6.97098445892334, 2068
[INFO] 2021-07-12 19:14:13,586 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.066999877570197e-05, 2068
[INFO] 2021-07-12 19:14:13,587 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2068
[INFO] 2021-07-12 19:14:13,587 [run_pretraining.py:  558]:	worker_index: 3, step: 2068, cost: 6.970984, mlm loss: 6.970984, speed: 1.074494 steps/s, speed: 8.595949 samples/s, speed: 4401.125750 tokens/s, learning rate: 2.067e-05, loss_scalings: 3518.437988, pp_loss: 7.135112
[INFO] 2021-07-12 19:14:13,587 [run_pretraining.py:  512]:	********exe.run_2068******* 
[INFO] 2021-07-12 19:14:14,512 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:14,512 [run_pretraining.py:  534]:	loss/total_loss, 7.030996799468994, 2069
[INFO] 2021-07-12 19:14:14,512 [run_pretraining.py:  535]:	loss/mlm_loss, 7.030996799468994, 2069
[INFO] 2021-07-12 19:14:14,512 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0679999579442665e-05, 2069
[INFO] 2021-07-12 19:14:14,512 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2069
[INFO] 2021-07-12 19:14:14,513 [run_pretraining.py:  558]:	worker_index: 3, step: 2069, cost: 7.030997, mlm loss: 7.030997, speed: 1.080742 steps/s, speed: 8.645939 samples/s, speed: 4426.720897 tokens/s, learning rate: 2.068e-05, loss_scalings: 3518.437988, pp_loss: 7.195940
[INFO] 2021-07-12 19:14:14,513 [run_pretraining.py:  512]:	********exe.run_2069******* 
[INFO] 2021-07-12 19:14:15,453 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:15,453 [run_pretraining.py:  534]:	loss/total_loss, 6.966035842895508, 2070
[INFO] 2021-07-12 19:14:15,453 [run_pretraining.py:  535]:	loss/mlm_loss, 6.966035842895508, 2070
[INFO] 2021-07-12 19:14:15,453 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.069000038318336e-05, 2070
[INFO] 2021-07-12 19:14:15,454 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2070
[INFO] 2021-07-12 19:14:15,454 [run_pretraining.py:  558]:	worker_index: 3, step: 2070, cost: 6.966036, mlm loss: 6.966036, speed: 1.063379 steps/s, speed: 8.507032 samples/s, speed: 4355.600522 tokens/s, learning rate: 2.069e-05, loss_scalings: 3518.437988, pp_loss: 7.234772
[INFO] 2021-07-12 19:14:15,454 [run_pretraining.py:  512]:	********exe.run_2070******* 
[INFO] 2021-07-12 19:14:16,390 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:16,390 [run_pretraining.py:  534]:	loss/total_loss, 7.793307304382324, 2071
[INFO] 2021-07-12 19:14:16,390 [run_pretraining.py:  535]:	loss/mlm_loss, 7.793307304382324, 2071
[INFO] 2021-07-12 19:14:16,390 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.069999936793465e-05, 2071
[INFO] 2021-07-12 19:14:16,390 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2071
[INFO] 2021-07-12 19:14:16,390 [run_pretraining.py:  558]:	worker_index: 3, step: 2071, cost: 7.793307, mlm loss: 7.793307, speed: 1.068132 steps/s, speed: 8.545053 samples/s, speed: 4375.067119 tokens/s, learning rate: 2.070e-05, loss_scalings: 3518.437988, pp_loss: 7.438015
[INFO] 2021-07-12 19:14:16,391 [run_pretraining.py:  512]:	********exe.run_2071******* 
[INFO] 2021-07-12 19:14:17,317 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:17,318 [run_pretraining.py:  534]:	loss/total_loss, 7.2116618156433105, 2072
[INFO] 2021-07-12 19:14:17,318 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2116618156433105, 2072
[INFO] 2021-07-12 19:14:17,318 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0710000171675347e-05, 2072
[INFO] 2021-07-12 19:14:17,318 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2072
[INFO] 2021-07-12 19:14:17,318 [run_pretraining.py:  558]:	worker_index: 3, step: 2072, cost: 7.211662, mlm loss: 7.211662, speed: 1.078611 steps/s, speed: 8.628886 samples/s, speed: 4417.989528 tokens/s, learning rate: 2.071e-05, loss_scalings: 3518.437988, pp_loss: 7.254355
[INFO] 2021-07-12 19:14:17,318 [run_pretraining.py:  512]:	********exe.run_2072******* 
[INFO] 2021-07-12 19:14:18,245 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:18,246 [run_pretraining.py:  534]:	loss/total_loss, 6.438763618469238, 2073
[INFO] 2021-07-12 19:14:18,246 [run_pretraining.py:  535]:	loss/mlm_loss, 6.438763618469238, 2073
[INFO] 2021-07-12 19:14:18,246 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.071999915642664e-05, 2073
[INFO] 2021-07-12 19:14:18,246 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2073
[INFO] 2021-07-12 19:14:18,246 [run_pretraining.py:  558]:	worker_index: 3, step: 2073, cost: 6.438764, mlm loss: 6.438764, speed: 1.078340 steps/s, speed: 8.626716 samples/s, speed: 4416.878668 tokens/s, learning rate: 2.072e-05, loss_scalings: 3518.437988, pp_loss: 6.900693
[INFO] 2021-07-12 19:14:18,246 [run_pretraining.py:  512]:	********exe.run_2073******* 
[INFO] 2021-07-12 19:14:19,178 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:19,178 [run_pretraining.py:  534]:	loss/total_loss, 7.301634788513184, 2074
[INFO] 2021-07-12 19:14:19,178 [run_pretraining.py:  535]:	loss/mlm_loss, 7.301634788513184, 2074
[INFO] 2021-07-12 19:14:19,178 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0729999960167333e-05, 2074
[INFO] 2021-07-12 19:14:19,178 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2074
[INFO] 2021-07-12 19:14:19,178 [run_pretraining.py:  558]:	worker_index: 3, step: 2074, cost: 7.301635, mlm loss: 7.301635, speed: 1.073455 steps/s, speed: 8.587644 samples/s, speed: 4396.873636 tokens/s, learning rate: 2.073e-05, loss_scalings: 3518.437988, pp_loss: 7.312864
[INFO] 2021-07-12 19:14:19,178 [run_pretraining.py:  512]:	********exe.run_2074******* 
[INFO] 2021-07-12 19:14:20,104 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:20,105 [run_pretraining.py:  534]:	loss/total_loss, 7.245232582092285, 2075
[INFO] 2021-07-12 19:14:20,105 [run_pretraining.py:  535]:	loss/mlm_loss, 7.245232582092285, 2075
[INFO] 2021-07-12 19:14:20,105 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0739998944918625e-05, 2075
[INFO] 2021-07-12 19:14:20,105 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2075
[INFO] 2021-07-12 19:14:20,105 [run_pretraining.py:  558]:	worker_index: 3, step: 2075, cost: 7.245233, mlm loss: 7.245233, speed: 1.079561 steps/s, speed: 8.636486 samples/s, speed: 4421.880802 tokens/s, learning rate: 2.074e-05, loss_scalings: 3518.437988, pp_loss: 7.227441
[INFO] 2021-07-12 19:14:20,105 [run_pretraining.py:  512]:	********exe.run_2075******* 
[INFO] 2021-07-12 19:14:21,041 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:21,042 [run_pretraining.py:  534]:	loss/total_loss, 4.50923490524292, 2076
[INFO] 2021-07-12 19:14:21,042 [run_pretraining.py:  535]:	loss/mlm_loss, 4.50923490524292, 2076
[INFO] 2021-07-12 19:14:21,042 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.074999974865932e-05, 2076
[INFO] 2021-07-12 19:14:21,042 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2076
[INFO] 2021-07-12 19:14:21,042 [run_pretraining.py:  558]:	worker_index: 3, step: 2076, cost: 4.509235, mlm loss: 4.509235, speed: 1.068133 steps/s, speed: 8.545062 samples/s, speed: 4375.071575 tokens/s, learning rate: 2.075e-05, loss_scalings: 3518.437988, pp_loss: 6.502767
[INFO] 2021-07-12 19:14:21,042 [run_pretraining.py:  512]:	********exe.run_2076******* 
[INFO] 2021-07-12 19:14:21,993 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:21,994 [run_pretraining.py:  534]:	loss/total_loss, 7.3057451248168945, 2077
[INFO] 2021-07-12 19:14:21,994 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3057451248168945, 2077
[INFO] 2021-07-12 19:14:21,994 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0759998733410612e-05, 2077
[INFO] 2021-07-12 19:14:21,994 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2077
[INFO] 2021-07-12 19:14:21,994 [run_pretraining.py:  558]:	worker_index: 3, step: 2077, cost: 7.305745, mlm loss: 7.305745, speed: 1.051382 steps/s, speed: 8.411055 samples/s, speed: 4306.460162 tokens/s, learning rate: 2.076e-05, loss_scalings: 3518.437988, pp_loss: 7.523787
[INFO] 2021-07-12 19:14:21,994 [run_pretraining.py:  512]:	********exe.run_2077******* 
[INFO] 2021-07-12 19:14:22,949 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:22,950 [run_pretraining.py:  534]:	loss/total_loss, 3.933424472808838, 2078
[INFO] 2021-07-12 19:14:22,950 [run_pretraining.py:  535]:	loss/mlm_loss, 3.933424472808838, 2078
[INFO] 2021-07-12 19:14:22,950 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0769999537151307e-05, 2078
[INFO] 2021-07-12 19:14:22,950 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2078
[INFO] 2021-07-12 19:14:22,950 [run_pretraining.py:  558]:	worker_index: 3, step: 2078, cost: 3.933424, mlm loss: 3.933424, speed: 1.046267 steps/s, speed: 8.370139 samples/s, speed: 4285.511315 tokens/s, learning rate: 2.077e-05, loss_scalings: 3518.437988, pp_loss: 6.338497
[INFO] 2021-07-12 19:14:22,950 [run_pretraining.py:  512]:	********exe.run_2078******* 
[INFO] 2021-07-12 19:14:23,895 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:23,895 [run_pretraining.py:  534]:	loss/total_loss, 7.676018238067627, 2079
[INFO] 2021-07-12 19:14:23,895 [run_pretraining.py:  535]:	loss/mlm_loss, 7.676018238067627, 2079
[INFO] 2021-07-12 19:14:23,895 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0780000340892002e-05, 2079
[INFO] 2021-07-12 19:14:23,895 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2079
[INFO] 2021-07-12 19:14:23,895 [run_pretraining.py:  558]:	worker_index: 3, step: 2079, cost: 7.676018, mlm loss: 7.676018, speed: 1.058809 steps/s, speed: 8.470475 samples/s, speed: 4336.883273 tokens/s, learning rate: 2.078e-05, loss_scalings: 3518.437988, pp_loss: 7.503982
[INFO] 2021-07-12 19:14:23,895 [run_pretraining.py:  512]:	********exe.run_2079******* 
[INFO] 2021-07-12 19:14:24,831 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:24,832 [run_pretraining.py:  534]:	loss/total_loss, 7.409337997436523, 2080
[INFO] 2021-07-12 19:14:24,832 [run_pretraining.py:  535]:	loss/mlm_loss, 7.409337997436523, 2080
[INFO] 2021-07-12 19:14:24,832 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0789999325643294e-05, 2080
[INFO] 2021-07-12 19:14:24,832 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2080
[INFO] 2021-07-12 19:14:24,832 [run_pretraining.py:  558]:	worker_index: 3, step: 2080, cost: 7.409338, mlm loss: 7.409338, speed: 1.068295 steps/s, speed: 8.546363 samples/s, speed: 4375.737949 tokens/s, learning rate: 2.079e-05, loss_scalings: 3518.437988, pp_loss: 7.215129
[INFO] 2021-07-12 19:14:24,832 [run_pretraining.py:  512]:	********exe.run_2080******* 
[INFO] 2021-07-12 19:14:25,778 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:25,779 [run_pretraining.py:  534]:	loss/total_loss, 7.387146949768066, 2081
[INFO] 2021-07-12 19:14:25,779 [run_pretraining.py:  535]:	loss/mlm_loss, 7.387146949768066, 2081
[INFO] 2021-07-12 19:14:25,779 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.080000012938399e-05, 2081
[INFO] 2021-07-12 19:14:25,779 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2081
[INFO] 2021-07-12 19:14:25,779 [run_pretraining.py:  558]:	worker_index: 3, step: 2081, cost: 7.387147, mlm loss: 7.387147, speed: 1.056494 steps/s, speed: 8.451951 samples/s, speed: 4327.398988 tokens/s, learning rate: 2.080e-05, loss_scalings: 3518.437988, pp_loss: 7.486539
[INFO] 2021-07-12 19:14:25,779 [run_pretraining.py:  512]:	********exe.run_2081******* 
[INFO] 2021-07-12 19:14:26,727 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:26,728 [run_pretraining.py:  534]:	loss/total_loss, 6.82942533493042, 2082
[INFO] 2021-07-12 19:14:26,728 [run_pretraining.py:  535]:	loss/mlm_loss, 6.82942533493042, 2082
[INFO] 2021-07-12 19:14:26,728 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0810000933124684e-05, 2082
[INFO] 2021-07-12 19:14:26,728 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2082
[INFO] 2021-07-12 19:14:26,728 [run_pretraining.py:  558]:	worker_index: 3, step: 2082, cost: 6.829425, mlm loss: 6.829425, speed: 1.054628 steps/s, speed: 8.437026 samples/s, speed: 4319.757303 tokens/s, learning rate: 2.081e-05, loss_scalings: 3518.437988, pp_loss: 7.237434
[INFO] 2021-07-12 19:14:26,728 [run_pretraining.py:  512]:	********exe.run_2082******* 
[INFO] 2021-07-12 19:14:27,657 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:27,658 [run_pretraining.py:  534]:	loss/total_loss, 7.370784759521484, 2083
[INFO] 2021-07-12 19:14:27,658 [run_pretraining.py:  535]:	loss/mlm_loss, 7.370784759521484, 2083
[INFO] 2021-07-12 19:14:27,658 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0819998098886572e-05, 2083
[INFO] 2021-07-12 19:14:27,658 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2083
[INFO] 2021-07-12 19:14:27,658 [run_pretraining.py:  558]:	worker_index: 3, step: 2083, cost: 7.370785, mlm loss: 7.370785, speed: 1.075766 steps/s, speed: 8.606128 samples/s, speed: 4406.337476 tokens/s, learning rate: 2.082e-05, loss_scalings: 3518.437988, pp_loss: 6.780583
[INFO] 2021-07-12 19:14:27,658 [run_pretraining.py:  512]:	********exe.run_2083******* 
[INFO] 2021-07-12 19:14:28,587 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:28,588 [run_pretraining.py:  534]:	loss/total_loss, 7.013359069824219, 2084
[INFO] 2021-07-12 19:14:28,588 [run_pretraining.py:  535]:	loss/mlm_loss, 7.013359069824219, 2084
[INFO] 2021-07-12 19:14:28,588 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0829998902627267e-05, 2084
[INFO] 2021-07-12 19:14:28,588 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2084
[INFO] 2021-07-12 19:14:28,588 [run_pretraining.py:  558]:	worker_index: 3, step: 2084, cost: 7.013359, mlm loss: 7.013359, speed: 1.076321 steps/s, speed: 8.610567 samples/s, speed: 4408.610247 tokens/s, learning rate: 2.083e-05, loss_scalings: 3518.437988, pp_loss: 7.424676
[INFO] 2021-07-12 19:14:28,588 [run_pretraining.py:  512]:	********exe.run_2084******* 
[INFO] 2021-07-12 19:14:29,498 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:29,498 [run_pretraining.py:  534]:	loss/total_loss, 6.995316505432129, 2085
[INFO] 2021-07-12 19:14:29,499 [run_pretraining.py:  535]:	loss/mlm_loss, 6.995316505432129, 2085
[INFO] 2021-07-12 19:14:29,499 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0839999706367962e-05, 2085
[INFO] 2021-07-12 19:14:29,499 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2085
[INFO] 2021-07-12 19:14:29,499 [run_pretraining.py:  558]:	worker_index: 3, step: 2085, cost: 6.995317, mlm loss: 6.995317, speed: 1.098723 steps/s, speed: 8.789780 samples/s, speed: 4500.367441 tokens/s, learning rate: 2.084e-05, loss_scalings: 3518.437988, pp_loss: 7.372944
[INFO] 2021-07-12 19:14:29,499 [run_pretraining.py:  512]:	********exe.run_2085******* 
[INFO] 2021-07-12 19:14:30,417 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:30,417 [run_pretraining.py:  534]:	loss/total_loss, 7.225222587585449, 2086
[INFO] 2021-07-12 19:14:30,417 [run_pretraining.py:  535]:	loss/mlm_loss, 7.225222587585449, 2086
[INFO] 2021-07-12 19:14:30,417 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0849998691119254e-05, 2086
[INFO] 2021-07-12 19:14:30,417 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2086
[INFO] 2021-07-12 19:14:30,418 [run_pretraining.py:  558]:	worker_index: 3, step: 2086, cost: 7.225223, mlm loss: 7.225223, speed: 1.089260 steps/s, speed: 8.714077 samples/s, speed: 4461.607210 tokens/s, learning rate: 2.085e-05, loss_scalings: 3518.437988, pp_loss: 7.420350
[INFO] 2021-07-12 19:14:30,418 [run_pretraining.py:  512]:	********exe.run_2086******* 
[INFO] 2021-07-12 19:14:31,350 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:31,350 [run_pretraining.py:  534]:	loss/total_loss, 7.346623420715332, 2087
[INFO] 2021-07-12 19:14:31,351 [run_pretraining.py:  535]:	loss/mlm_loss, 7.346623420715332, 2087
[INFO] 2021-07-12 19:14:31,351 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.085999949485995e-05, 2087
[INFO] 2021-07-12 19:14:31,351 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2087
[INFO] 2021-07-12 19:14:31,351 [run_pretraining.py:  558]:	worker_index: 3, step: 2087, cost: 7.346623, mlm loss: 7.346623, speed: 1.072270 steps/s, speed: 8.578160 samples/s, speed: 4392.017711 tokens/s, learning rate: 2.086e-05, loss_scalings: 3518.437988, pp_loss: 7.308867
[INFO] 2021-07-12 19:14:31,351 [run_pretraining.py:  512]:	********exe.run_2087******* 
[INFO] 2021-07-12 19:14:32,273 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:32,273 [run_pretraining.py:  534]:	loss/total_loss, 6.843686580657959, 2088
[INFO] 2021-07-12 19:14:32,273 [run_pretraining.py:  535]:	loss/mlm_loss, 6.843686580657959, 2088
[INFO] 2021-07-12 19:14:32,273 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0870000298600644e-05, 2088
[INFO] 2021-07-12 19:14:32,273 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2088
[INFO] 2021-07-12 19:14:32,273 [run_pretraining.py:  558]:	worker_index: 3, step: 2088, cost: 6.843687, mlm loss: 6.843687, speed: 1.084535 steps/s, speed: 8.676281 samples/s, speed: 4442.255841 tokens/s, learning rate: 2.087e-05, loss_scalings: 3518.437988, pp_loss: 7.309443
[INFO] 2021-07-12 19:14:32,274 [run_pretraining.py:  512]:	********exe.run_2088******* 
[INFO] 2021-07-12 19:14:33,189 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:33,190 [run_pretraining.py:  534]:	loss/total_loss, 7.290162563323975, 2089
[INFO] 2021-07-12 19:14:33,190 [run_pretraining.py:  535]:	loss/mlm_loss, 7.290162563323975, 2089
[INFO] 2021-07-12 19:14:33,190 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0879999283351935e-05, 2089
[INFO] 2021-07-12 19:14:33,190 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2089
[INFO] 2021-07-12 19:14:33,190 [run_pretraining.py:  558]:	worker_index: 3, step: 2089, cost: 7.290163, mlm loss: 7.290163, speed: 1.091786 steps/s, speed: 8.734287 samples/s, speed: 4471.954976 tokens/s, learning rate: 2.088e-05, loss_scalings: 3518.437988, pp_loss: 7.461793
[INFO] 2021-07-12 19:14:33,190 [run_pretraining.py:  512]:	********exe.run_2089******* 
[INFO] 2021-07-12 19:14:34,103 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:34,104 [run_pretraining.py:  534]:	loss/total_loss, 7.66497802734375, 2090
[INFO] 2021-07-12 19:14:34,104 [run_pretraining.py:  535]:	loss/mlm_loss, 7.66497802734375, 2090
[INFO] 2021-07-12 19:14:34,104 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.089000008709263e-05, 2090
[INFO] 2021-07-12 19:14:34,104 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2090
[INFO] 2021-07-12 19:14:34,104 [run_pretraining.py:  558]:	worker_index: 3, step: 2090, cost: 7.664978, mlm loss: 7.664978, speed: 1.094912 steps/s, speed: 8.759292 samples/s, speed: 4484.757760 tokens/s, learning rate: 2.089e-05, loss_scalings: 3518.437988, pp_loss: 7.590524
[INFO] 2021-07-12 19:14:34,104 [run_pretraining.py:  512]:	********exe.run_2090******* 
[INFO] 2021-07-12 19:14:35,027 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:35,028 [run_pretraining.py:  534]:	loss/total_loss, 7.532982349395752, 2091
[INFO] 2021-07-12 19:14:35,028 [run_pretraining.py:  535]:	loss/mlm_loss, 7.532982349395752, 2091
[INFO] 2021-07-12 19:14:35,028 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0900000890833326e-05, 2091
[INFO] 2021-07-12 19:14:35,028 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2091
[INFO] 2021-07-12 19:14:35,028 [run_pretraining.py:  558]:	worker_index: 3, step: 2091, cost: 7.532982, mlm loss: 7.532982, speed: 1.083075 steps/s, speed: 8.664604 samples/s, speed: 4436.277141 tokens/s, learning rate: 2.090e-05, loss_scalings: 3518.437988, pp_loss: 7.499075
[INFO] 2021-07-12 19:14:35,028 [run_pretraining.py:  512]:	********exe.run_2091******* 
[INFO] 2021-07-12 19:14:35,949 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:35,949 [run_pretraining.py:  534]:	loss/total_loss, 7.235812187194824, 2092
[INFO] 2021-07-12 19:14:35,950 [run_pretraining.py:  535]:	loss/mlm_loss, 7.235812187194824, 2092
[INFO] 2021-07-12 19:14:35,950 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0909998056595214e-05, 2092
[INFO] 2021-07-12 19:14:35,950 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2092
[INFO] 2021-07-12 19:14:35,950 [run_pretraining.py:  558]:	worker_index: 3, step: 2092, cost: 7.235812, mlm loss: 7.235812, speed: 1.085532 steps/s, speed: 8.684255 samples/s, speed: 4446.338442 tokens/s, learning rate: 2.091e-05, loss_scalings: 3518.437988, pp_loss: 7.267909
[INFO] 2021-07-12 19:14:35,950 [run_pretraining.py:  512]:	********exe.run_2092******* 
[INFO] 2021-07-12 19:14:36,873 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:36,874 [run_pretraining.py:  534]:	loss/total_loss, 7.591622829437256, 2093
[INFO] 2021-07-12 19:14:36,874 [run_pretraining.py:  535]:	loss/mlm_loss, 7.591622829437256, 2093
[INFO] 2021-07-12 19:14:36,874 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.091999886033591e-05, 2093
[INFO] 2021-07-12 19:14:36,874 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2093
[INFO] 2021-07-12 19:14:36,874 [run_pretraining.py:  558]:	worker_index: 3, step: 2093, cost: 7.591623, mlm loss: 7.591623, speed: 1.082736 steps/s, speed: 8.661886 samples/s, speed: 4434.885723 tokens/s, learning rate: 2.092e-05, loss_scalings: 3518.437988, pp_loss: 7.386115
[INFO] 2021-07-12 19:14:36,874 [run_pretraining.py:  512]:	********exe.run_2093******* 
[INFO] 2021-07-12 19:14:37,798 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:37,798 [run_pretraining.py:  534]:	loss/total_loss, 7.339961528778076, 2094
[INFO] 2021-07-12 19:14:37,798 [run_pretraining.py:  535]:	loss/mlm_loss, 7.339961528778076, 2094
[INFO] 2021-07-12 19:14:37,798 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0929999664076604e-05, 2094
[INFO] 2021-07-12 19:14:37,798 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2094
[INFO] 2021-07-12 19:14:37,799 [run_pretraining.py:  558]:	worker_index: 3, step: 2094, cost: 7.339962, mlm loss: 7.339962, speed: 1.082289 steps/s, speed: 8.658314 samples/s, speed: 4433.057022 tokens/s, learning rate: 2.093e-05, loss_scalings: 3518.437988, pp_loss: 7.159972
[INFO] 2021-07-12 19:14:37,799 [run_pretraining.py:  512]:	********exe.run_2094******* 
[INFO] 2021-07-12 19:14:38,722 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:38,723 [run_pretraining.py:  534]:	loss/total_loss, 7.486093997955322, 2095
[INFO] 2021-07-12 19:14:38,723 [run_pretraining.py:  535]:	loss/mlm_loss, 7.486093997955322, 2095
[INFO] 2021-07-12 19:14:38,723 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0939998648827896e-05, 2095
[INFO] 2021-07-12 19:14:38,723 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2095
[INFO] 2021-07-12 19:14:38,723 [run_pretraining.py:  558]:	worker_index: 3, step: 2095, cost: 7.486094, mlm loss: 7.486094, speed: 1.082211 steps/s, speed: 8.657685 samples/s, speed: 4432.734467 tokens/s, learning rate: 2.094e-05, loss_scalings: 3518.437988, pp_loss: 7.138533
[INFO] 2021-07-12 19:14:38,723 [run_pretraining.py:  512]:	********exe.run_2095******* 
[INFO] 2021-07-12 19:14:39,642 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:39,643 [run_pretraining.py:  534]:	loss/total_loss, 7.9766459465026855, 2096
[INFO] 2021-07-12 19:14:39,643 [run_pretraining.py:  535]:	loss/mlm_loss, 7.9766459465026855, 2096
[INFO] 2021-07-12 19:14:39,643 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.094999945256859e-05, 2096
[INFO] 2021-07-12 19:14:39,643 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2096
[INFO] 2021-07-12 19:14:39,643 [run_pretraining.py:  558]:	worker_index: 3, step: 2096, cost: 7.976646, mlm loss: 7.976646, speed: 1.087690 steps/s, speed: 8.701523 samples/s, speed: 4455.180025 tokens/s, learning rate: 2.095e-05, loss_scalings: 3518.437988, pp_loss: 7.485809
[INFO] 2021-07-12 19:14:39,643 [run_pretraining.py:  512]:	********exe.run_2096******* 
[INFO] 2021-07-12 19:14:40,573 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:40,574 [run_pretraining.py:  534]:	loss/total_loss, 6.908431529998779, 2097
[INFO] 2021-07-12 19:14:40,574 [run_pretraining.py:  535]:	loss/mlm_loss, 6.908431529998779, 2097
[INFO] 2021-07-12 19:14:40,574 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0960000256309286e-05, 2097
[INFO] 2021-07-12 19:14:40,574 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2097
[INFO] 2021-07-12 19:14:40,574 [run_pretraining.py:  558]:	worker_index: 3, step: 2097, cost: 6.908432, mlm loss: 6.908432, speed: 1.074711 steps/s, speed: 8.597687 samples/s, speed: 4402.015509 tokens/s, learning rate: 2.096e-05, loss_scalings: 3518.437988, pp_loss: 7.442653
[INFO] 2021-07-12 19:14:40,574 [run_pretraining.py:  512]:	********exe.run_2097******* 
[INFO] 2021-07-12 19:14:41,490 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:41,490 [run_pretraining.py:  534]:	loss/total_loss, 7.229925632476807, 2098
[INFO] 2021-07-12 19:14:41,490 [run_pretraining.py:  535]:	loss/mlm_loss, 7.229925632476807, 2098
[INFO] 2021-07-12 19:14:41,490 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0969999241060577e-05, 2098
[INFO] 2021-07-12 19:14:41,490 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2098
[INFO] 2021-07-12 19:14:41,490 [run_pretraining.py:  558]:	worker_index: 3, step: 2098, cost: 7.229926, mlm loss: 7.229926, speed: 1.092332 steps/s, speed: 8.738659 samples/s, speed: 4474.193417 tokens/s, learning rate: 2.097e-05, loss_scalings: 3518.437988, pp_loss: 7.227277
[INFO] 2021-07-12 19:14:41,491 [run_pretraining.py:  512]:	********exe.run_2098******* 
[INFO] 2021-07-12 19:14:42,409 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:42,409 [run_pretraining.py:  534]:	loss/total_loss, 7.308022975921631, 2099
[INFO] 2021-07-12 19:14:42,410 [run_pretraining.py:  535]:	loss/mlm_loss, 7.308022975921631, 2099
[INFO] 2021-07-12 19:14:42,410 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0980000044801272e-05, 2099
[INFO] 2021-07-12 19:14:42,410 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2099
[INFO] 2021-07-12 19:14:42,410 [run_pretraining.py:  558]:	worker_index: 3, step: 2099, cost: 7.308023, mlm loss: 7.308023, speed: 1.088458 steps/s, speed: 8.707661 samples/s, speed: 4458.322460 tokens/s, learning rate: 2.098e-05, loss_scalings: 3518.437988, pp_loss: 7.389944
[INFO] 2021-07-12 19:14:42,410 [run_pretraining.py:  512]:	********exe.run_2099******* 
[INFO] 2021-07-12 19:14:43,320 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:43,321 [run_pretraining.py:  534]:	loss/total_loss, 6.617305755615234, 2100
[INFO] 2021-07-12 19:14:43,321 [run_pretraining.py:  535]:	loss/mlm_loss, 6.617305755615234, 2100
[INFO] 2021-07-12 19:14:43,321 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0990000848541968e-05, 2100
[INFO] 2021-07-12 19:14:43,321 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2100
[INFO] 2021-07-12 19:14:43,321 [run_pretraining.py:  558]:	worker_index: 3, step: 2100, cost: 6.617306, mlm loss: 6.617306, speed: 1.098149 steps/s, speed: 8.785191 samples/s, speed: 4498.017947 tokens/s, learning rate: 2.099e-05, loss_scalings: 3518.437988, pp_loss: 7.378667
[INFO] 2021-07-12 19:14:43,321 [run_pretraining.py:  512]:	********exe.run_2100******* 
[INFO] 2021-07-12 19:14:44,237 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:44,238 [run_pretraining.py:  534]:	loss/total_loss, 7.174901485443115, 2101
[INFO] 2021-07-12 19:14:44,238 [run_pretraining.py:  535]:	loss/mlm_loss, 7.174901485443115, 2101
[INFO] 2021-07-12 19:14:44,238 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0999998014303856e-05, 2101
[INFO] 2021-07-12 19:14:44,238 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2101
[INFO] 2021-07-12 19:14:44,238 [run_pretraining.py:  558]:	worker_index: 3, step: 2101, cost: 7.174901, mlm loss: 7.174901, speed: 1.090962 steps/s, speed: 8.727694 samples/s, speed: 4468.579427 tokens/s, learning rate: 2.100e-05, loss_scalings: 3518.437988, pp_loss: 7.033756
[INFO] 2021-07-12 19:14:44,238 [run_pretraining.py:  512]:	********exe.run_2101******* 
[INFO] 2021-07-12 19:14:45,166 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:45,167 [run_pretraining.py:  534]:	loss/total_loss, 7.722596645355225, 2102
[INFO] 2021-07-12 19:14:45,167 [run_pretraining.py:  535]:	loss/mlm_loss, 7.722596645355225, 2102
[INFO] 2021-07-12 19:14:45,167 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.100999881804455e-05, 2102
[INFO] 2021-07-12 19:14:45,167 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2102
[INFO] 2021-07-12 19:14:45,167 [run_pretraining.py:  558]:	worker_index: 3, step: 2102, cost: 7.722597, mlm loss: 7.722597, speed: 1.077163 steps/s, speed: 8.617303 samples/s, speed: 4412.058928 tokens/s, learning rate: 2.101e-05, loss_scalings: 3518.437988, pp_loss: 7.417011
[INFO] 2021-07-12 19:14:45,167 [run_pretraining.py:  512]:	********exe.run_2102******* 
[INFO] 2021-07-12 19:14:46,084 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:46,084 [run_pretraining.py:  534]:	loss/total_loss, 7.056102275848389, 2103
[INFO] 2021-07-12 19:14:46,085 [run_pretraining.py:  535]:	loss/mlm_loss, 7.056102275848389, 2103
[INFO] 2021-07-12 19:14:46,085 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1019999621785246e-05, 2103
[INFO] 2021-07-12 19:14:46,085 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2103
[INFO] 2021-07-12 19:14:46,085 [run_pretraining.py:  558]:	worker_index: 3, step: 2103, cost: 7.056102, mlm loss: 7.056102, speed: 1.090691 steps/s, speed: 8.725529 samples/s, speed: 4467.470865 tokens/s, learning rate: 2.102e-05, loss_scalings: 3518.437988, pp_loss: 7.068884
[INFO] 2021-07-12 19:14:46,085 [run_pretraining.py:  512]:	********exe.run_2103******* 
[INFO] 2021-07-12 19:14:46,999 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:47,000 [run_pretraining.py:  534]:	loss/total_loss, 6.915026664733887, 2104
[INFO] 2021-07-12 19:14:47,000 [run_pretraining.py:  535]:	loss/mlm_loss, 6.915026664733887, 2104
[INFO] 2021-07-12 19:14:47,000 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1029998606536537e-05, 2104
[INFO] 2021-07-12 19:14:47,000 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2104
[INFO] 2021-07-12 19:14:47,000 [run_pretraining.py:  558]:	worker_index: 3, step: 2104, cost: 6.915027, mlm loss: 6.915027, speed: 1.093583 steps/s, speed: 8.748661 samples/s, speed: 4479.314609 tokens/s, learning rate: 2.103e-05, loss_scalings: 3518.437988, pp_loss: 7.251274
[INFO] 2021-07-12 19:14:47,000 [run_pretraining.py:  512]:	********exe.run_2104******* 
[INFO] 2021-07-12 19:14:47,915 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:47,916 [run_pretraining.py:  534]:	loss/total_loss, 7.337270736694336, 2105
[INFO] 2021-07-12 19:14:47,916 [run_pretraining.py:  535]:	loss/mlm_loss, 7.337270736694336, 2105
[INFO] 2021-07-12 19:14:47,916 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1039999410277233e-05, 2105
[INFO] 2021-07-12 19:14:47,916 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2105
[INFO] 2021-07-12 19:14:47,916 [run_pretraining.py:  558]:	worker_index: 3, step: 2105, cost: 7.337271, mlm loss: 7.337271, speed: 1.092118 steps/s, speed: 8.736941 samples/s, speed: 4473.313846 tokens/s, learning rate: 2.104e-05, loss_scalings: 3518.437988, pp_loss: 6.975193
[INFO] 2021-07-12 19:14:47,916 [run_pretraining.py:  512]:	********exe.run_2105******* 
[INFO] 2021-07-12 19:14:48,831 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:48,832 [run_pretraining.py:  534]:	loss/total_loss, 7.5720977783203125, 2106
[INFO] 2021-07-12 19:14:48,832 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5720977783203125, 2106
[INFO] 2021-07-12 19:14:48,832 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1050000214017928e-05, 2106
[INFO] 2021-07-12 19:14:48,832 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2106
[INFO] 2021-07-12 19:14:48,832 [run_pretraining.py:  558]:	worker_index: 3, step: 2106, cost: 7.572098, mlm loss: 7.572098, speed: 1.092251 steps/s, speed: 8.738010 samples/s, speed: 4473.861353 tokens/s, learning rate: 2.105e-05, loss_scalings: 3518.437988, pp_loss: 7.042120
[INFO] 2021-07-12 19:14:48,832 [run_pretraining.py:  512]:	********exe.run_2106******* 
[INFO] 2021-07-12 19:14:49,794 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:49,794 [run_pretraining.py:  534]:	loss/total_loss, 6.853707790374756, 2107
[INFO] 2021-07-12 19:14:49,794 [run_pretraining.py:  535]:	loss/mlm_loss, 6.853707790374756, 2107
[INFO] 2021-07-12 19:14:49,794 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.105999919876922e-05, 2107
[INFO] 2021-07-12 19:14:49,794 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2107
[INFO] 2021-07-12 19:14:49,794 [run_pretraining.py:  558]:	worker_index: 3, step: 2107, cost: 6.853708, mlm loss: 6.853708, speed: 1.040044 steps/s, speed: 8.320350 samples/s, speed: 4260.019164 tokens/s, learning rate: 2.106e-05, loss_scalings: 3518.437988, pp_loss: 7.270409
[INFO] 2021-07-12 19:14:49,795 [run_pretraining.py:  512]:	********exe.run_2107******* 
[INFO] 2021-07-12 19:14:50,854 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:50,854 [run_pretraining.py:  534]:	loss/total_loss, 5.872128963470459, 2108
[INFO] 2021-07-12 19:14:50,854 [run_pretraining.py:  535]:	loss/mlm_loss, 5.872128963470459, 2108
[INFO] 2021-07-12 19:14:50,854 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1070000002509914e-05, 2108
[INFO] 2021-07-12 19:14:50,854 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2108
[INFO] 2021-07-12 19:14:50,855 [run_pretraining.py:  558]:	worker_index: 3, step: 2108, cost: 5.872129, mlm loss: 5.872129, speed: 0.943849 steps/s, speed: 7.550791 samples/s, speed: 3866.005042 tokens/s, learning rate: 2.107e-05, loss_scalings: 3518.437988, pp_loss: 6.721138
[INFO] 2021-07-12 19:14:50,855 [run_pretraining.py:  512]:	********exe.run_2108******* 
[INFO] 2021-07-12 19:14:51,912 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:51,913 [run_pretraining.py:  534]:	loss/total_loss, 7.272452354431152, 2109
[INFO] 2021-07-12 19:14:51,913 [run_pretraining.py:  535]:	loss/mlm_loss, 7.272452354431152, 2109
[INFO] 2021-07-12 19:14:51,913 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.108000080625061e-05, 2109
[INFO] 2021-07-12 19:14:51,913 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2109
[INFO] 2021-07-12 19:14:51,913 [run_pretraining.py:  558]:	worker_index: 3, step: 2109, cost: 7.272452, mlm loss: 7.272452, speed: 0.945394 steps/s, speed: 7.563152 samples/s, speed: 3872.333988 tokens/s, learning rate: 2.108e-05, loss_scalings: 3518.437988, pp_loss: 7.397157
[INFO] 2021-07-12 19:14:51,913 [run_pretraining.py:  512]:	********exe.run_2109******* 
[INFO] 2021-07-12 19:14:52,964 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:52,964 [run_pretraining.py:  534]:	loss/total_loss, 6.792657375335693, 2110
[INFO] 2021-07-12 19:14:52,964 [run_pretraining.py:  535]:	loss/mlm_loss, 6.792657375335693, 2110
[INFO] 2021-07-12 19:14:52,964 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1089997972012497e-05, 2110
[INFO] 2021-07-12 19:14:52,964 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2110
[INFO] 2021-07-12 19:14:52,964 [run_pretraining.py:  558]:	worker_index: 3, step: 2110, cost: 6.792657, mlm loss: 6.792657, speed: 0.951687 steps/s, speed: 7.613497 samples/s, speed: 3898.110419 tokens/s, learning rate: 2.109e-05, loss_scalings: 3518.437988, pp_loss: 7.329120
[INFO] 2021-07-12 19:14:52,964 [run_pretraining.py:  512]:	********exe.run_2110******* 
[INFO] 2021-07-12 19:14:54,028 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:54,029 [run_pretraining.py:  534]:	loss/total_loss, 6.786458492279053, 2111
[INFO] 2021-07-12 19:14:54,029 [run_pretraining.py:  535]:	loss/mlm_loss, 6.786458492279053, 2111
[INFO] 2021-07-12 19:14:54,029 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1099998775753193e-05, 2111
[INFO] 2021-07-12 19:14:54,029 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2111
[INFO] 2021-07-12 19:14:54,029 [run_pretraining.py:  558]:	worker_index: 3, step: 2111, cost: 6.786458, mlm loss: 6.786458, speed: 0.939890 steps/s, speed: 7.519118 samples/s, speed: 3849.788357 tokens/s, learning rate: 2.110e-05, loss_scalings: 3518.437988, pp_loss: 7.246902
[INFO] 2021-07-12 19:14:54,029 [run_pretraining.py:  512]:	********exe.run_2111******* 
[INFO] 2021-07-12 19:14:55,086 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:55,087 [run_pretraining.py:  534]:	loss/total_loss, 8.259973526000977, 2112
[INFO] 2021-07-12 19:14:55,087 [run_pretraining.py:  535]:	loss/mlm_loss, 8.259973526000977, 2112
[INFO] 2021-07-12 19:14:55,087 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1109999579493888e-05, 2112
[INFO] 2021-07-12 19:14:55,087 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2112
[INFO] 2021-07-12 19:14:55,087 [run_pretraining.py:  558]:	worker_index: 3, step: 2112, cost: 8.259974, mlm loss: 8.259974, speed: 0.945776 steps/s, speed: 7.566212 samples/s, speed: 3873.900464 tokens/s, learning rate: 2.111e-05, loss_scalings: 3518.437988, pp_loss: 7.709311
[INFO] 2021-07-12 19:14:55,087 [run_pretraining.py:  512]:	********exe.run_2112******* 
[INFO] 2021-07-12 19:14:56,135 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:56,135 [run_pretraining.py:  534]:	loss/total_loss, 8.17396068572998, 2113
[INFO] 2021-07-12 19:14:56,135 [run_pretraining.py:  535]:	loss/mlm_loss, 8.17396068572998, 2113
[INFO] 2021-07-12 19:14:56,136 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.111999856424518e-05, 2113
[INFO] 2021-07-12 19:14:56,136 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2113
[INFO] 2021-07-12 19:14:56,136 [run_pretraining.py:  558]:	worker_index: 3, step: 2113, cost: 8.173961, mlm loss: 8.173961, speed: 0.954080 steps/s, speed: 7.632641 samples/s, speed: 3907.912054 tokens/s, learning rate: 2.112e-05, loss_scalings: 3518.437988, pp_loss: 7.449052
[INFO] 2021-07-12 19:14:56,136 [run_pretraining.py:  512]:	********exe.run_2113******* 
[INFO] 2021-07-12 19:14:57,194 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:57,195 [run_pretraining.py:  534]:	loss/total_loss, 6.68355655670166, 2114
[INFO] 2021-07-12 19:14:57,195 [run_pretraining.py:  535]:	loss/mlm_loss, 6.68355655670166, 2114
[INFO] 2021-07-12 19:14:57,195 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1129999367985874e-05, 2114
[INFO] 2021-07-12 19:14:57,195 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2114
[INFO] 2021-07-12 19:14:57,195 [run_pretraining.py:  558]:	worker_index: 3, step: 2114, cost: 6.683557, mlm loss: 6.683557, speed: 0.944583 steps/s, speed: 7.556666 samples/s, speed: 3869.013132 tokens/s, learning rate: 2.113e-05, loss_scalings: 3518.437988, pp_loss: 7.159053
[INFO] 2021-07-12 19:14:57,195 [run_pretraining.py:  512]:	********exe.run_2114******* 
[INFO] 2021-07-12 19:14:58,261 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:58,262 [run_pretraining.py:  534]:	loss/total_loss, 6.858143329620361, 2115
[INFO] 2021-07-12 19:14:58,262 [run_pretraining.py:  535]:	loss/mlm_loss, 6.858143329620361, 2115
[INFO] 2021-07-12 19:14:58,262 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.114000017172657e-05, 2115
[INFO] 2021-07-12 19:14:58,262 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2115
[INFO] 2021-07-12 19:14:58,262 [run_pretraining.py:  558]:	worker_index: 3, step: 2115, cost: 6.858143, mlm loss: 6.858143, speed: 0.937776 steps/s, speed: 7.502209 samples/s, speed: 3841.130952 tokens/s, learning rate: 2.114e-05, loss_scalings: 3518.437988, pp_loss: 7.258095
[INFO] 2021-07-12 19:14:58,262 [run_pretraining.py:  512]:	********exe.run_2115******* 
[INFO] 2021-07-12 19:14:59,321 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:59,321 [run_pretraining.py:  534]:	loss/total_loss, 7.648645401000977, 2116
[INFO] 2021-07-12 19:14:59,321 [run_pretraining.py:  535]:	loss/mlm_loss, 7.648645401000977, 2116
[INFO] 2021-07-12 19:14:59,321 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.114999915647786e-05, 2116
[INFO] 2021-07-12 19:14:59,322 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2116
[INFO] 2021-07-12 19:14:59,322 [run_pretraining.py:  558]:	worker_index: 3, step: 2116, cost: 7.648645, mlm loss: 7.648645, speed: 0.944357 steps/s, speed: 7.554858 samples/s, speed: 3868.087134 tokens/s, learning rate: 2.115e-05, loss_scalings: 3518.437988, pp_loss: 7.621691
[INFO] 2021-07-12 19:14:59,322 [run_pretraining.py:  512]:	********exe.run_2116******* 
[INFO] 2021-07-12 19:15:00,392 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:00,392 [run_pretraining.py:  534]:	loss/total_loss, 6.533963203430176, 2117
[INFO] 2021-07-12 19:15:00,392 [run_pretraining.py:  535]:	loss/mlm_loss, 6.533963203430176, 2117
[INFO] 2021-07-12 19:15:00,392 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1159999960218556e-05, 2117
[INFO] 2021-07-12 19:15:00,392 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2117
[INFO] 2021-07-12 19:15:00,393 [run_pretraining.py:  558]:	worker_index: 3, step: 2117, cost: 6.533963, mlm loss: 6.533963, speed: 0.934328 steps/s, speed: 7.474622 samples/s, speed: 3827.006662 tokens/s, learning rate: 2.116e-05, loss_scalings: 3518.437988, pp_loss: 7.125269
[INFO] 2021-07-12 19:15:00,393 [run_pretraining.py:  512]:	********exe.run_2117******* 
[INFO] 2021-07-12 19:15:01,450 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:01,450 [run_pretraining.py:  534]:	loss/total_loss, 4.642119407653809, 2118
[INFO] 2021-07-12 19:15:01,450 [run_pretraining.py:  535]:	loss/mlm_loss, 4.642119407653809, 2118
[INFO] 2021-07-12 19:15:01,450 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.117000076395925e-05, 2118
[INFO] 2021-07-12 19:15:01,450 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2118
[INFO] 2021-07-12 19:15:01,450 [run_pretraining.py:  558]:	worker_index: 3, step: 2118, cost: 4.642119, mlm loss: 4.642119, speed: 0.945840 steps/s, speed: 7.566722 samples/s, speed: 3874.161667 tokens/s, learning rate: 2.117e-05, loss_scalings: 3518.437988, pp_loss: 6.702008
[INFO] 2021-07-12 19:15:01,450 [run_pretraining.py:  512]:	********exe.run_2118******* 
[INFO] 2021-07-12 19:15:02,509 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:02,510 [run_pretraining.py:  534]:	loss/total_loss, 7.163280010223389, 2119
[INFO] 2021-07-12 19:15:02,510 [run_pretraining.py:  535]:	loss/mlm_loss, 7.163280010223389, 2119
[INFO] 2021-07-12 19:15:02,510 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1179999748710543e-05, 2119
[INFO] 2021-07-12 19:15:02,510 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2119
[INFO] 2021-07-12 19:15:02,510 [run_pretraining.py:  558]:	worker_index: 3, step: 2119, cost: 7.163280, mlm loss: 7.163280, speed: 0.944307 steps/s, speed: 7.554458 samples/s, speed: 3867.882481 tokens/s, learning rate: 2.118e-05, loss_scalings: 3518.437988, pp_loss: 7.043636
[INFO] 2021-07-12 19:15:02,510 [run_pretraining.py:  512]:	********exe.run_2119******* 
[INFO] 2021-07-12 19:15:03,571 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:03,571 [run_pretraining.py:  534]:	loss/total_loss, 6.479310035705566, 2120
[INFO] 2021-07-12 19:15:03,571 [run_pretraining.py:  535]:	loss/mlm_loss, 6.479310035705566, 2120
[INFO] 2021-07-12 19:15:03,571 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1189998733461834e-05, 2120
[INFO] 2021-07-12 19:15:03,571 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2120
[INFO] 2021-07-12 19:15:03,572 [run_pretraining.py:  558]:	worker_index: 3, step: 2120, cost: 6.479310, mlm loss: 6.479310, speed: 0.942667 steps/s, speed: 7.541339 samples/s, speed: 3861.165367 tokens/s, learning rate: 2.119e-05, loss_scalings: 3518.437988, pp_loss: 7.114786
[INFO] 2021-07-12 19:15:03,572 [run_pretraining.py:  512]:	********exe.run_2120******* 
[INFO] 2021-07-12 19:15:04,634 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:04,635 [run_pretraining.py:  534]:	loss/total_loss, 7.52689790725708, 2121
[INFO] 2021-07-12 19:15:04,635 [run_pretraining.py:  535]:	loss/mlm_loss, 7.52689790725708, 2121
[INFO] 2021-07-12 19:15:04,635 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.119999953720253e-05, 2121
[INFO] 2021-07-12 19:15:04,635 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2121
[INFO] 2021-07-12 19:15:04,635 [run_pretraining.py:  558]:	worker_index: 3, step: 2121, cost: 7.526898, mlm loss: 7.526898, speed: 0.940938 steps/s, speed: 7.527503 samples/s, speed: 3854.081563 tokens/s, learning rate: 2.120e-05, loss_scalings: 3518.437988, pp_loss: 6.714956
[INFO] 2021-07-12 19:15:04,635 [run_pretraining.py:  512]:	********exe.run_2121******* 
[INFO] 2021-07-12 19:15:05,698 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:05,698 [run_pretraining.py:  534]:	loss/total_loss, 7.363391399383545, 2122
[INFO] 2021-07-12 19:15:05,698 [run_pretraining.py:  535]:	loss/mlm_loss, 7.363391399383545, 2122
[INFO] 2021-07-12 19:15:05,698 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.120999852195382e-05, 2122
[INFO] 2021-07-12 19:15:05,698 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2122
[INFO] 2021-07-12 19:15:05,698 [run_pretraining.py:  558]:	worker_index: 3, step: 2122, cost: 7.363391, mlm loss: 7.363391, speed: 0.940848 steps/s, speed: 7.526785 samples/s, speed: 3853.714137 tokens/s, learning rate: 2.121e-05, loss_scalings: 3518.437988, pp_loss: 7.194409
[INFO] 2021-07-12 19:15:05,698 [run_pretraining.py:  512]:	********exe.run_2122******* 
[INFO] 2021-07-12 19:15:06,761 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:06,761 [run_pretraining.py:  534]:	loss/total_loss, 7.025659561157227, 2123
[INFO] 2021-07-12 19:15:06,761 [run_pretraining.py:  535]:	loss/mlm_loss, 7.025659561157227, 2123
[INFO] 2021-07-12 19:15:06,761 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1219999325694516e-05, 2123
[INFO] 2021-07-12 19:15:06,762 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2123
[INFO] 2021-07-12 19:15:06,762 [run_pretraining.py:  558]:	worker_index: 3, step: 2123, cost: 7.025660, mlm loss: 7.025660, speed: 0.941127 steps/s, speed: 7.529013 samples/s, speed: 3854.854682 tokens/s, learning rate: 2.122e-05, loss_scalings: 3518.437988, pp_loss: 7.126325
[INFO] 2021-07-12 19:15:06,762 [run_pretraining.py:  512]:	********exe.run_2123******* 
[INFO] 2021-07-12 19:15:07,819 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:07,819 [run_pretraining.py:  534]:	loss/total_loss, 7.166779041290283, 2124
[INFO] 2021-07-12 19:15:07,819 [run_pretraining.py:  535]:	loss/mlm_loss, 7.166779041290283, 2124
[INFO] 2021-07-12 19:15:07,819 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.123000012943521e-05, 2124
[INFO] 2021-07-12 19:15:07,819 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2124
[INFO] 2021-07-12 19:15:07,820 [run_pretraining.py:  558]:	worker_index: 3, step: 2124, cost: 7.166779, mlm loss: 7.166779, speed: 0.945819 steps/s, speed: 7.566550 samples/s, speed: 3874.073431 tokens/s, learning rate: 2.123e-05, loss_scalings: 3518.437988, pp_loss: 7.252249
[INFO] 2021-07-12 19:15:07,820 [run_pretraining.py:  512]:	********exe.run_2124******* 
[INFO] 2021-07-12 19:15:08,883 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:08,884 [run_pretraining.py:  534]:	loss/total_loss, 5.226253032684326, 2125
[INFO] 2021-07-12 19:15:08,884 [run_pretraining.py:  535]:	loss/mlm_loss, 5.226253032684326, 2125
[INFO] 2021-07-12 19:15:08,884 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1239999114186503e-05, 2125
[INFO] 2021-07-12 19:15:08,884 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2125
[INFO] 2021-07-12 19:15:08,884 [run_pretraining.py:  558]:	worker_index: 3, step: 2125, cost: 5.226253, mlm loss: 5.226253, speed: 0.939979 steps/s, speed: 7.519834 samples/s, speed: 3850.155035 tokens/s, learning rate: 2.124e-05, loss_scalings: 3518.437988, pp_loss: 6.723151
[INFO] 2021-07-12 19:15:08,884 [run_pretraining.py:  512]:	********exe.run_2125******* 
[INFO] 2021-07-12 19:15:09,968 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:09,968 [run_pretraining.py:  534]:	loss/total_loss, 6.771649360656738, 2126
[INFO] 2021-07-12 19:15:09,968 [run_pretraining.py:  535]:	loss/mlm_loss, 6.771649360656738, 2126
[INFO] 2021-07-12 19:15:09,968 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1249999917927198e-05, 2126
[INFO] 2021-07-12 19:15:09,969 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2126
[INFO] 2021-07-12 19:15:09,969 [run_pretraining.py:  558]:	worker_index: 3, step: 2126, cost: 6.771649, mlm loss: 6.771649, speed: 0.922519 steps/s, speed: 7.380149 samples/s, speed: 3778.636461 tokens/s, learning rate: 2.125e-05, loss_scalings: 3518.437988, pp_loss: 7.162409
[INFO] 2021-07-12 19:15:09,969 [run_pretraining.py:  512]:	********exe.run_2126******* 
[INFO] 2021-07-12 19:15:11,040 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:11,041 [run_pretraining.py:  534]:	loss/total_loss, 7.121015548706055, 2127
[INFO] 2021-07-12 19:15:11,041 [run_pretraining.py:  535]:	loss/mlm_loss, 7.121015548706055, 2127
[INFO] 2021-07-12 19:15:11,041 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.125999890267849e-05, 2127
[INFO] 2021-07-12 19:15:11,041 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2127
[INFO] 2021-07-12 19:15:11,041 [run_pretraining.py:  558]:	worker_index: 3, step: 2127, cost: 7.121016, mlm loss: 7.121016, speed: 0.932864 steps/s, speed: 7.462915 samples/s, speed: 3821.012702 tokens/s, learning rate: 2.126e-05, loss_scalings: 3518.437988, pp_loss: 6.977888
[INFO] 2021-07-12 19:15:11,041 [run_pretraining.py:  512]:	********exe.run_2127******* 
[INFO] 2021-07-12 19:15:12,096 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:12,097 [run_pretraining.py:  534]:	loss/total_loss, 7.108607292175293, 2128
[INFO] 2021-07-12 19:15:12,097 [run_pretraining.py:  535]:	loss/mlm_loss, 7.108607292175293, 2128
[INFO] 2021-07-12 19:15:12,097 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1269999706419185e-05, 2128
[INFO] 2021-07-12 19:15:12,097 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2128
[INFO] 2021-07-12 19:15:12,097 [run_pretraining.py:  558]:	worker_index: 3, step: 2128, cost: 7.108607, mlm loss: 7.108607, speed: 0.947744 steps/s, speed: 7.581953 samples/s, speed: 3881.959773 tokens/s, learning rate: 2.127e-05, loss_scalings: 3518.437988, pp_loss: 6.633683
[INFO] 2021-07-12 19:15:12,097 [run_pretraining.py:  512]:	********exe.run_2128******* 
[INFO] 2021-07-12 19:15:13,165 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:13,166 [run_pretraining.py:  534]:	loss/total_loss, 7.051372528076172, 2129
[INFO] 2021-07-12 19:15:13,166 [run_pretraining.py:  535]:	loss/mlm_loss, 7.051372528076172, 2129
[INFO] 2021-07-12 19:15:13,166 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1279998691170476e-05, 2129
[INFO] 2021-07-12 19:15:13,166 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2129
[INFO] 2021-07-12 19:15:13,166 [run_pretraining.py:  558]:	worker_index: 3, step: 2129, cost: 7.051373, mlm loss: 7.051373, speed: 0.936089 steps/s, speed: 7.488710 samples/s, speed: 3834.219663 tokens/s, learning rate: 2.128e-05, loss_scalings: 3518.437988, pp_loss: 7.473916
[INFO] 2021-07-12 19:15:13,166 [run_pretraining.py:  512]:	********exe.run_2129******* 
[INFO] 2021-07-12 19:15:14,221 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:14,221 [run_pretraining.py:  534]:	loss/total_loss, 7.328536033630371, 2130
[INFO] 2021-07-12 19:15:14,222 [run_pretraining.py:  535]:	loss/mlm_loss, 7.328536033630371, 2130
[INFO] 2021-07-12 19:15:14,222 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.128999949491117e-05, 2130
[INFO] 2021-07-12 19:15:14,222 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2130
[INFO] 2021-07-12 19:15:14,222 [run_pretraining.py:  558]:	worker_index: 3, step: 2130, cost: 7.328536, mlm loss: 7.328536, speed: 0.947643 steps/s, speed: 7.581148 samples/s, speed: 3881.547548 tokens/s, learning rate: 2.129e-05, loss_scalings: 3518.437988, pp_loss: 7.115932
[INFO] 2021-07-12 19:15:14,222 [run_pretraining.py:  512]:	********exe.run_2130******* 
[INFO] 2021-07-12 19:15:15,289 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:15,290 [run_pretraining.py:  534]:	loss/total_loss, 3.5288188457489014, 2131
[INFO] 2021-07-12 19:15:15,290 [run_pretraining.py:  535]:	loss/mlm_loss, 3.5288188457489014, 2131
[INFO] 2021-07-12 19:15:15,290 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1300000298651867e-05, 2131
[INFO] 2021-07-12 19:15:15,290 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2131
[INFO] 2021-07-12 19:15:15,290 [run_pretraining.py:  558]:	worker_index: 3, step: 2131, cost: 3.528819, mlm loss: 3.528819, speed: 0.936703 steps/s, speed: 7.493627 samples/s, speed: 3836.737146 tokens/s, learning rate: 2.130e-05, loss_scalings: 3518.437988, pp_loss: 6.436110
[INFO] 2021-07-12 19:15:15,290 [run_pretraining.py:  512]:	********exe.run_2131******* 
[INFO] 2021-07-12 19:15:16,357 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:16,357 [run_pretraining.py:  534]:	loss/total_loss, 8.043255805969238, 2132
[INFO] 2021-07-12 19:15:16,358 [run_pretraining.py:  535]:	loss/mlm_loss, 8.043255805969238, 2132
[INFO] 2021-07-12 19:15:16,358 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1309999283403158e-05, 2132
[INFO] 2021-07-12 19:15:16,358 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2132
[INFO] 2021-07-12 19:15:16,358 [run_pretraining.py:  558]:	worker_index: 3, step: 2132, cost: 8.043256, mlm loss: 8.043256, speed: 0.937082 steps/s, speed: 7.496659 samples/s, speed: 3838.289527 tokens/s, learning rate: 2.131e-05, loss_scalings: 3518.437988, pp_loss: 7.411336
[INFO] 2021-07-12 19:15:16,358 [run_pretraining.py:  512]:	********exe.run_2132******* 
[INFO] 2021-07-12 19:15:17,416 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:17,417 [run_pretraining.py:  534]:	loss/total_loss, 7.555328369140625, 2133
[INFO] 2021-07-12 19:15:17,417 [run_pretraining.py:  535]:	loss/mlm_loss, 7.555328369140625, 2133
[INFO] 2021-07-12 19:15:17,417 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1320000087143853e-05, 2133
[INFO] 2021-07-12 19:15:17,417 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2133
[INFO] 2021-07-12 19:15:17,417 [run_pretraining.py:  558]:	worker_index: 3, step: 2133, cost: 7.555328, mlm loss: 7.555328, speed: 0.944640 steps/s, speed: 7.557119 samples/s, speed: 3869.244918 tokens/s, learning rate: 2.132e-05, loss_scalings: 3518.437988, pp_loss: 7.362659
[INFO] 2021-07-12 19:15:17,417 [run_pretraining.py:  512]:	********exe.run_2133******* 
[INFO] 2021-07-12 19:15:18,504 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:18,505 [run_pretraining.py:  534]:	loss/total_loss, 7.385821342468262, 2134
[INFO] 2021-07-12 19:15:18,505 [run_pretraining.py:  535]:	loss/mlm_loss, 7.385821342468262, 2134
[INFO] 2021-07-12 19:15:18,505 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1329999071895145e-05, 2134
[INFO] 2021-07-12 19:15:18,505 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2134
[INFO] 2021-07-12 19:15:18,505 [run_pretraining.py:  558]:	worker_index: 3, step: 2134, cost: 7.385821, mlm loss: 7.385821, speed: 0.919423 steps/s, speed: 7.355386 samples/s, speed: 3765.957585 tokens/s, learning rate: 2.133e-05, loss_scalings: 3518.437988, pp_loss: 7.440715
[INFO] 2021-07-12 19:15:18,505 [run_pretraining.py:  512]:	********exe.run_2134******* 
[INFO] 2021-07-12 19:15:19,449 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:19,450 [run_pretraining.py:  534]:	loss/total_loss, 7.281319618225098, 2135
[INFO] 2021-07-12 19:15:19,450 [run_pretraining.py:  535]:	loss/mlm_loss, 7.281319618225098, 2135
[INFO] 2021-07-12 19:15:19,450 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.133999987563584e-05, 2135
[INFO] 2021-07-12 19:15:19,450 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2135
[INFO] 2021-07-12 19:15:19,450 [run_pretraining.py:  558]:	worker_index: 3, step: 2135, cost: 7.281320, mlm loss: 7.281320, speed: 1.059364 steps/s, speed: 8.474910 samples/s, speed: 4339.153986 tokens/s, learning rate: 2.134e-05, loss_scalings: 3518.437988, pp_loss: 7.460670
[INFO] 2021-07-12 19:15:19,450 [run_pretraining.py:  512]:	********exe.run_2135******* 
[INFO] 2021-07-12 19:15:20,361 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:20,362 [run_pretraining.py:  534]:	loss/total_loss, 7.760289669036865, 2136
[INFO] 2021-07-12 19:15:20,362 [run_pretraining.py:  535]:	loss/mlm_loss, 7.760289669036865, 2136
[INFO] 2021-07-12 19:15:20,362 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.134999886038713e-05, 2136
[INFO] 2021-07-12 19:15:20,362 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2136
[INFO] 2021-07-12 19:15:20,362 [run_pretraining.py:  558]:	worker_index: 3, step: 2136, cost: 7.760290, mlm loss: 7.760290, speed: 1.096834 steps/s, speed: 8.774674 samples/s, speed: 4492.633041 tokens/s, learning rate: 2.135e-05, loss_scalings: 3518.437988, pp_loss: 7.588776
[INFO] 2021-07-12 19:15:20,362 [run_pretraining.py:  512]:	********exe.run_2136******* 
[INFO] 2021-07-12 19:15:21,272 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:21,273 [run_pretraining.py:  534]:	loss/total_loss, 6.643477439880371, 2137
[INFO] 2021-07-12 19:15:21,273 [run_pretraining.py:  535]:	loss/mlm_loss, 6.643477439880371, 2137
[INFO] 2021-07-12 19:15:21,273 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1359999664127827e-05, 2137
[INFO] 2021-07-12 19:15:21,273 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2137
[INFO] 2021-07-12 19:15:21,273 [run_pretraining.py:  558]:	worker_index: 3, step: 2137, cost: 6.643477, mlm loss: 6.643477, speed: 1.098503 steps/s, speed: 8.788024 samples/s, speed: 4499.468122 tokens/s, learning rate: 2.136e-05, loss_scalings: 3518.437988, pp_loss: 7.279332
[INFO] 2021-07-12 19:15:21,273 [run_pretraining.py:  512]:	********exe.run_2137******* 
[INFO] 2021-07-12 19:15:22,180 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:22,181 [run_pretraining.py:  534]:	loss/total_loss, 7.102969169616699, 2138
[INFO] 2021-07-12 19:15:22,181 [run_pretraining.py:  535]:	loss/mlm_loss, 7.102969169616699, 2138
[INFO] 2021-07-12 19:15:22,181 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1369998648879118e-05, 2138
[INFO] 2021-07-12 19:15:22,181 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2138
[INFO] 2021-07-12 19:15:22,181 [run_pretraining.py:  558]:	worker_index: 3, step: 2138, cost: 7.102969, mlm loss: 7.102969, speed: 1.102462 steps/s, speed: 8.819699 samples/s, speed: 4515.686132 tokens/s, learning rate: 2.137e-05, loss_scalings: 3518.437988, pp_loss: 6.946467
[INFO] 2021-07-12 19:15:22,181 [run_pretraining.py:  512]:	********exe.run_2138******* 
[INFO] 2021-07-12 19:15:23,085 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:23,086 [run_pretraining.py:  534]:	loss/total_loss, 8.151165962219238, 2139
[INFO] 2021-07-12 19:15:23,086 [run_pretraining.py:  535]:	loss/mlm_loss, 8.151165962219238, 2139
[INFO] 2021-07-12 19:15:23,086 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1379999452619813e-05, 2139
[INFO] 2021-07-12 19:15:23,086 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2139
[INFO] 2021-07-12 19:15:23,086 [run_pretraining.py:  558]:	worker_index: 3, step: 2139, cost: 8.151166, mlm loss: 8.151166, speed: 1.105595 steps/s, speed: 8.844756 samples/s, speed: 4528.515283 tokens/s, learning rate: 2.138e-05, loss_scalings: 3518.437988, pp_loss: 7.554424
[INFO] 2021-07-12 19:15:23,086 [run_pretraining.py:  512]:	********exe.run_2139******* 
[INFO] 2021-07-12 19:15:23,994 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:23,995 [run_pretraining.py:  534]:	loss/total_loss, 7.571385860443115, 2140
[INFO] 2021-07-12 19:15:23,995 [run_pretraining.py:  535]:	loss/mlm_loss, 7.571385860443115, 2140
[INFO] 2021-07-12 19:15:23,995 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.139000025636051e-05, 2140
[INFO] 2021-07-12 19:15:23,995 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2140
[INFO] 2021-07-12 19:15:23,995 [run_pretraining.py:  558]:	worker_index: 3, step: 2140, cost: 7.571386, mlm loss: 7.571386, speed: 1.100671 steps/s, speed: 8.805368 samples/s, speed: 4508.348560 tokens/s, learning rate: 2.139e-05, loss_scalings: 3518.437988, pp_loss: 7.564746
[INFO] 2021-07-12 19:15:23,995 [run_pretraining.py:  512]:	********exe.run_2140******* 
[INFO] 2021-07-12 19:15:24,898 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:24,899 [run_pretraining.py:  534]:	loss/total_loss, 6.943481922149658, 2141
[INFO] 2021-07-12 19:15:24,899 [run_pretraining.py:  535]:	loss/mlm_loss, 6.943481922149658, 2141
[INFO] 2021-07-12 19:15:24,899 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.13999992411118e-05, 2141
[INFO] 2021-07-12 19:15:24,899 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2141
[INFO] 2021-07-12 19:15:24,899 [run_pretraining.py:  558]:	worker_index: 3, step: 2141, cost: 6.943482, mlm loss: 6.943482, speed: 1.107249 steps/s, speed: 8.857991 samples/s, speed: 4535.291245 tokens/s, learning rate: 2.140e-05, loss_scalings: 3518.437988, pp_loss: 7.278633
[INFO] 2021-07-12 19:15:24,899 [run_pretraining.py:  512]:	********exe.run_2141******* 
[INFO] 2021-07-12 19:15:25,802 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:25,803 [run_pretraining.py:  534]:	loss/total_loss, 7.3276824951171875, 2142
[INFO] 2021-07-12 19:15:25,803 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3276824951171875, 2142
[INFO] 2021-07-12 19:15:25,803 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1410000044852495e-05, 2142
[INFO] 2021-07-12 19:15:25,803 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2142
[INFO] 2021-07-12 19:15:25,803 [run_pretraining.py:  558]:	worker_index: 3, step: 2142, cost: 7.327682, mlm loss: 7.327682, speed: 1.106699 steps/s, speed: 8.853594 samples/s, speed: 4533.040306 tokens/s, learning rate: 2.141e-05, loss_scalings: 3518.437988, pp_loss: 7.354388
[INFO] 2021-07-12 19:15:25,803 [run_pretraining.py:  512]:	********exe.run_2142******* 
[INFO] 2021-07-12 19:15:26,711 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:26,712 [run_pretraining.py:  534]:	loss/total_loss, 7.177359104156494, 2143
[INFO] 2021-07-12 19:15:26,712 [run_pretraining.py:  535]:	loss/mlm_loss, 7.177359104156494, 2143
[INFO] 2021-07-12 19:15:26,712 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.142000084859319e-05, 2143
[INFO] 2021-07-12 19:15:26,712 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2143
[INFO] 2021-07-12 19:15:26,712 [run_pretraining.py:  558]:	worker_index: 3, step: 2143, cost: 7.177359, mlm loss: 7.177359, speed: 1.100954 steps/s, speed: 8.807633 samples/s, speed: 4509.508280 tokens/s, learning rate: 2.142e-05, loss_scalings: 3518.437988, pp_loss: 6.994540
[INFO] 2021-07-12 19:15:26,712 [run_pretraining.py:  512]:	********exe.run_2143******* 
[INFO] 2021-07-12 19:15:27,633 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:27,634 [run_pretraining.py:  534]:	loss/total_loss, 6.591423511505127, 2144
[INFO] 2021-07-12 19:15:27,634 [run_pretraining.py:  535]:	loss/mlm_loss, 6.591423511505127, 2144
[INFO] 2021-07-12 19:15:27,634 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1429999833344482e-05, 2144
[INFO] 2021-07-12 19:15:27,634 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2144
[INFO] 2021-07-12 19:15:27,634 [run_pretraining.py:  558]:	worker_index: 3, step: 2144, cost: 6.591424, mlm loss: 6.591424, speed: 1.085131 steps/s, speed: 8.681051 samples/s, speed: 4444.698062 tokens/s, learning rate: 2.143e-05, loss_scalings: 3518.437988, pp_loss: 6.484985
[INFO] 2021-07-12 19:15:27,634 [run_pretraining.py:  512]:	********exe.run_2144******* 
[INFO] 2021-07-12 19:15:28,540 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:28,541 [run_pretraining.py:  534]:	loss/total_loss, 7.293404579162598, 2145
[INFO] 2021-07-12 19:15:28,541 [run_pretraining.py:  535]:	loss/mlm_loss, 7.293404579162598, 2145
[INFO] 2021-07-12 19:15:28,541 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1439998818095773e-05, 2145
[INFO] 2021-07-12 19:15:28,541 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2145
[INFO] 2021-07-12 19:15:28,541 [run_pretraining.py:  558]:	worker_index: 3, step: 2145, cost: 7.293405, mlm loss: 7.293405, speed: 1.103562 steps/s, speed: 8.828494 samples/s, speed: 4520.189108 tokens/s, learning rate: 2.144e-05, loss_scalings: 3518.437988, pp_loss: 7.201827
[INFO] 2021-07-12 19:15:28,541 [run_pretraining.py:  512]:	********exe.run_2145******* 
[INFO] 2021-07-12 19:15:29,503 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:29,504 [run_pretraining.py:  534]:	loss/total_loss, 7.941685676574707, 2146
[INFO] 2021-07-12 19:15:29,504 [run_pretraining.py:  535]:	loss/mlm_loss, 7.941685676574707, 2146
[INFO] 2021-07-12 19:15:29,504 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.144999962183647e-05, 2146
[INFO] 2021-07-12 19:15:29,504 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2146
[INFO] 2021-07-12 19:15:29,504 [run_pretraining.py:  558]:	worker_index: 3, step: 2146, cost: 7.941686, mlm loss: 7.941686, speed: 1.039227 steps/s, speed: 8.313813 samples/s, speed: 4256.672145 tokens/s, learning rate: 2.145e-05, loss_scalings: 3518.437988, pp_loss: 7.519771
[INFO] 2021-07-12 19:15:29,504 [run_pretraining.py:  512]:	********exe.run_2146******* 
[INFO] 2021-07-12 19:15:30,405 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:30,405 [run_pretraining.py:  534]:	loss/total_loss, 7.110871315002441, 2147
[INFO] 2021-07-12 19:15:30,405 [run_pretraining.py:  535]:	loss/mlm_loss, 7.110871315002441, 2147
[INFO] 2021-07-12 19:15:30,405 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.145999860658776e-05, 2147
[INFO] 2021-07-12 19:15:30,405 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2147
[INFO] 2021-07-12 19:15:30,405 [run_pretraining.py:  558]:	worker_index: 3, step: 2147, cost: 7.110871, mlm loss: 7.110871, speed: 1.110103 steps/s, speed: 8.880823 samples/s, speed: 4546.981471 tokens/s, learning rate: 2.146e-05, loss_scalings: 3518.437988, pp_loss: 7.035322
[INFO] 2021-07-12 19:15:30,406 [run_pretraining.py:  512]:	********exe.run_2147******* 
[INFO] 2021-07-12 19:15:31,300 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:31,300 [run_pretraining.py:  534]:	loss/total_loss, 7.159263610839844, 2148
[INFO] 2021-07-12 19:15:31,300 [run_pretraining.py:  535]:	loss/mlm_loss, 7.159263610839844, 2148
[INFO] 2021-07-12 19:15:31,301 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1469999410328455e-05, 2148
[INFO] 2021-07-12 19:15:31,301 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2148
[INFO] 2021-07-12 19:15:31,301 [run_pretraining.py:  558]:	worker_index: 3, step: 2148, cost: 7.159264, mlm loss: 7.159264, speed: 1.117843 steps/s, speed: 8.942740 samples/s, speed: 4578.683105 tokens/s, learning rate: 2.147e-05, loss_scalings: 3518.437988, pp_loss: 7.393909
[INFO] 2021-07-12 19:15:31,301 [run_pretraining.py:  512]:	********exe.run_2148******* 
[INFO] 2021-07-12 19:15:32,205 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:32,205 [run_pretraining.py:  534]:	loss/total_loss, 7.511378288269043, 2149
[INFO] 2021-07-12 19:15:32,206 [run_pretraining.py:  535]:	loss/mlm_loss, 7.511378288269043, 2149
[INFO] 2021-07-12 19:15:32,206 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.148000021406915e-05, 2149
[INFO] 2021-07-12 19:15:32,206 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2149
[INFO] 2021-07-12 19:15:32,206 [run_pretraining.py:  558]:	worker_index: 3, step: 2149, cost: 7.511378, mlm loss: 7.511378, speed: 1.105624 steps/s, speed: 8.844990 samples/s, speed: 4528.634655 tokens/s, learning rate: 2.148e-05, loss_scalings: 3518.437988, pp_loss: 7.372266
[INFO] 2021-07-12 19:15:32,206 [run_pretraining.py:  512]:	********exe.run_2149******* 
[INFO] 2021-07-12 19:15:33,109 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:33,109 [run_pretraining.py:  534]:	loss/total_loss, 6.997175216674805, 2150
[INFO] 2021-07-12 19:15:33,109 [run_pretraining.py:  535]:	loss/mlm_loss, 6.997175216674805, 2150
[INFO] 2021-07-12 19:15:33,109 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1489999198820442e-05, 2150
[INFO] 2021-07-12 19:15:33,109 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2150
[INFO] 2021-07-12 19:15:33,109 [run_pretraining.py:  558]:	worker_index: 3, step: 2150, cost: 6.997175, mlm loss: 6.997175, speed: 1.107359 steps/s, speed: 8.858872 samples/s, speed: 4535.742659 tokens/s, learning rate: 2.149e-05, loss_scalings: 3518.437988, pp_loss: 7.302186
[INFO] 2021-07-12 19:15:33,109 [run_pretraining.py:  512]:	********exe.run_2150******* 
[INFO] 2021-07-12 19:15:34,013 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:34,014 [run_pretraining.py:  534]:	loss/total_loss, 7.536511421203613, 2151
[INFO] 2021-07-12 19:15:34,014 [run_pretraining.py:  535]:	loss/mlm_loss, 7.536511421203613, 2151
[INFO] 2021-07-12 19:15:34,014 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1500000002561137e-05, 2151
[INFO] 2021-07-12 19:15:34,014 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2151
[INFO] 2021-07-12 19:15:34,014 [run_pretraining.py:  558]:	worker_index: 3, step: 2151, cost: 7.536511, mlm loss: 7.536511, speed: 1.106381 steps/s, speed: 8.851049 samples/s, speed: 4531.736957 tokens/s, learning rate: 2.150e-05, loss_scalings: 3518.437988, pp_loss: 7.327354
[INFO] 2021-07-12 19:15:34,014 [run_pretraining.py:  512]:	********exe.run_2151******* 
[INFO] 2021-07-12 19:15:34,917 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:34,918 [run_pretraining.py:  534]:	loss/total_loss, 6.116804122924805, 2152
[INFO] 2021-07-12 19:15:34,918 [run_pretraining.py:  535]:	loss/mlm_loss, 6.116804122924805, 2152
[INFO] 2021-07-12 19:15:34,918 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1510000806301832e-05, 2152
[INFO] 2021-07-12 19:15:34,918 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2152
[INFO] 2021-07-12 19:15:34,918 [run_pretraining.py:  558]:	worker_index: 3, step: 2152, cost: 6.116804, mlm loss: 6.116804, speed: 1.106741 steps/s, speed: 8.853926 samples/s, speed: 4533.210156 tokens/s, learning rate: 2.151e-05, loss_scalings: 3518.437988, pp_loss: 7.021581
[INFO] 2021-07-12 19:15:34,918 [run_pretraining.py:  512]:	********exe.run_2152******* 
[INFO] 2021-07-12 19:15:35,816 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:35,816 [run_pretraining.py:  534]:	loss/total_loss, 6.865065574645996, 2153
[INFO] 2021-07-12 19:15:35,816 [run_pretraining.py:  535]:	loss/mlm_loss, 6.865065574645996, 2153
[INFO] 2021-07-12 19:15:35,817 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1519999791053124e-05, 2153
[INFO] 2021-07-12 19:15:35,817 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2153
[INFO] 2021-07-12 19:15:35,817 [run_pretraining.py:  558]:	worker_index: 3, step: 2153, cost: 6.865066, mlm loss: 6.865066, speed: 1.113646 steps/s, speed: 8.909168 samples/s, speed: 4561.494266 tokens/s, learning rate: 2.152e-05, loss_scalings: 3518.437988, pp_loss: 7.194536
[INFO] 2021-07-12 19:15:35,817 [run_pretraining.py:  512]:	********exe.run_2153******* 
[INFO] 2021-07-12 19:15:36,720 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:36,720 [run_pretraining.py:  534]:	loss/total_loss, 6.976048469543457, 2154
[INFO] 2021-07-12 19:15:36,721 [run_pretraining.py:  535]:	loss/mlm_loss, 6.976048469543457, 2154
[INFO] 2021-07-12 19:15:36,721 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1529998775804415e-05, 2154
[INFO] 2021-07-12 19:15:36,721 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2154
[INFO] 2021-07-12 19:15:36,721 [run_pretraining.py:  558]:	worker_index: 3, step: 2154, cost: 6.976048, mlm loss: 6.976048, speed: 1.106815 steps/s, speed: 8.854520 samples/s, speed: 4533.514003 tokens/s, learning rate: 2.153e-05, loss_scalings: 3518.437988, pp_loss: 7.200733
[INFO] 2021-07-12 19:15:36,721 [run_pretraining.py:  512]:	********exe.run_2154******* 
[INFO] 2021-07-12 19:15:37,628 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:37,629 [run_pretraining.py:  534]:	loss/total_loss, 7.389693737030029, 2155
[INFO] 2021-07-12 19:15:37,629 [run_pretraining.py:  535]:	loss/mlm_loss, 7.389693737030029, 2155
[INFO] 2021-07-12 19:15:37,629 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.153999957954511e-05, 2155
[INFO] 2021-07-12 19:15:37,629 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2155
[INFO] 2021-07-12 19:15:37,629 [run_pretraining.py:  558]:	worker_index: 3, step: 2155, cost: 7.389694, mlm loss: 7.389694, speed: 1.101541 steps/s, speed: 8.812331 samples/s, speed: 4511.913640 tokens/s, learning rate: 2.154e-05, loss_scalings: 3518.437988, pp_loss: 7.365016
[INFO] 2021-07-12 19:15:37,629 [run_pretraining.py:  512]:	********exe.run_2155******* 
[INFO] 2021-07-12 19:15:38,537 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:38,537 [run_pretraining.py:  534]:	loss/total_loss, 8.112079620361328, 2156
[INFO] 2021-07-12 19:15:38,537 [run_pretraining.py:  535]:	loss/mlm_loss, 8.112079620361328, 2156
[INFO] 2021-07-12 19:15:38,537 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1549998564296402e-05, 2156
[INFO] 2021-07-12 19:15:38,537 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2156
[INFO] 2021-07-12 19:15:38,538 [run_pretraining.py:  558]:	worker_index: 3, step: 2156, cost: 8.112080, mlm loss: 8.112080, speed: 1.101754 steps/s, speed: 8.814035 samples/s, speed: 4512.785935 tokens/s, learning rate: 2.155e-05, loss_scalings: 3518.437988, pp_loss: 7.767505
[INFO] 2021-07-12 19:15:38,538 [run_pretraining.py:  512]:	********exe.run_2156******* 
[INFO] 2021-07-12 19:15:39,453 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:39,453 [run_pretraining.py:  534]:	loss/total_loss, 7.366216659545898, 2157
[INFO] 2021-07-12 19:15:39,453 [run_pretraining.py:  535]:	loss/mlm_loss, 7.366216659545898, 2157
[INFO] 2021-07-12 19:15:39,454 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1559999368037097e-05, 2157
[INFO] 2021-07-12 19:15:39,454 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2157
[INFO] 2021-07-12 19:15:39,454 [run_pretraining.py:  558]:	worker_index: 3, step: 2157, cost: 7.366217, mlm loss: 7.366217, speed: 1.092291 steps/s, speed: 8.738331 samples/s, speed: 4474.025631 tokens/s, learning rate: 2.156e-05, loss_scalings: 3518.437988, pp_loss: 7.077364
[INFO] 2021-07-12 19:15:39,454 [run_pretraining.py:  512]:	********exe.run_2157******* 
[INFO] 2021-07-12 19:15:40,361 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:40,362 [run_pretraining.py:  534]:	loss/total_loss, 7.3989152908325195, 2158
[INFO] 2021-07-12 19:15:40,362 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3989152908325195, 2158
[INFO] 2021-07-12 19:15:40,362 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1570000171777792e-05, 2158
[INFO] 2021-07-12 19:15:40,362 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2158
[INFO] 2021-07-12 19:15:40,362 [run_pretraining.py:  558]:	worker_index: 3, step: 2158, cost: 7.398915, mlm loss: 7.398915, speed: 1.101979 steps/s, speed: 8.815834 samples/s, speed: 4513.707188 tokens/s, learning rate: 2.157e-05, loss_scalings: 3518.437988, pp_loss: 6.580310
[INFO] 2021-07-12 19:15:40,362 [run_pretraining.py:  512]:	********exe.run_2158******* 
[INFO] 2021-07-12 19:15:41,305 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:41,306 [run_pretraining.py:  534]:	loss/total_loss, 6.271360874176025, 2159
[INFO] 2021-07-12 19:15:41,306 [run_pretraining.py:  535]:	loss/mlm_loss, 6.271360874176025, 2159
[INFO] 2021-07-12 19:15:41,306 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1579999156529084e-05, 2159
[INFO] 2021-07-12 19:15:41,306 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2159
[INFO] 2021-07-12 19:15:41,306 [run_pretraining.py:  558]:	worker_index: 3, step: 2159, cost: 6.271361, mlm loss: 6.271361, speed: 1.059507 steps/s, speed: 8.476058 samples/s, speed: 4339.741494 tokens/s, learning rate: 2.158e-05, loss_scalings: 3518.437988, pp_loss: 6.967136
[INFO] 2021-07-12 19:15:41,306 [run_pretraining.py:  512]:	********exe.run_2159******* 
[INFO] 2021-07-12 19:15:42,211 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:42,212 [run_pretraining.py:  534]:	loss/total_loss, 7.195228576660156, 2160
[INFO] 2021-07-12 19:15:42,212 [run_pretraining.py:  535]:	loss/mlm_loss, 7.195228576660156, 2160
[INFO] 2021-07-12 19:15:42,212 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.158999996026978e-05, 2160
[INFO] 2021-07-12 19:15:42,212 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2160
[INFO] 2021-07-12 19:15:42,212 [run_pretraining.py:  558]:	worker_index: 3, step: 2160, cost: 7.195229, mlm loss: 7.195229, speed: 1.104571 steps/s, speed: 8.836569 samples/s, speed: 4524.323344 tokens/s, learning rate: 2.159e-05, loss_scalings: 3518.437988, pp_loss: 7.243877
[INFO] 2021-07-12 19:15:42,212 [run_pretraining.py:  512]:	********exe.run_2160******* 
[INFO] 2021-07-12 19:15:43,122 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:43,123 [run_pretraining.py:  534]:	loss/total_loss, 7.422331809997559, 2161
[INFO] 2021-07-12 19:15:43,123 [run_pretraining.py:  535]:	loss/mlm_loss, 7.422331809997559, 2161
[INFO] 2021-07-12 19:15:43,123 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1600000764010474e-05, 2161
[INFO] 2021-07-12 19:15:43,123 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2161
[INFO] 2021-07-12 19:15:43,123 [run_pretraining.py:  558]:	worker_index: 3, step: 2161, cost: 7.422332, mlm loss: 7.422332, speed: 1.098501 steps/s, speed: 8.788005 samples/s, speed: 4499.458695 tokens/s, learning rate: 2.160e-05, loss_scalings: 3518.437988, pp_loss: 7.530869
[INFO] 2021-07-12 19:15:43,123 [run_pretraining.py:  512]:	********exe.run_2161******* 
[INFO] 2021-07-12 19:15:44,029 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:44,030 [run_pretraining.py:  534]:	loss/total_loss, 6.56906795501709, 2162
[INFO] 2021-07-12 19:15:44,030 [run_pretraining.py:  535]:	loss/mlm_loss, 6.56906795501709, 2162
[INFO] 2021-07-12 19:15:44,030 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1609999748761766e-05, 2162
[INFO] 2021-07-12 19:15:44,030 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2162
[INFO] 2021-07-12 19:15:44,030 [run_pretraining.py:  558]:	worker_index: 3, step: 2162, cost: 6.569068, mlm loss: 6.569068, speed: 1.103740 steps/s, speed: 8.829916 samples/s, speed: 4520.917081 tokens/s, learning rate: 2.161e-05, loss_scalings: 3518.437988, pp_loss: 7.072126
[INFO] 2021-07-12 19:15:44,030 [run_pretraining.py:  512]:	********exe.run_2162******* 
[INFO] 2021-07-12 19:15:44,994 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:44,995 [run_pretraining.py:  534]:	loss/total_loss, 7.509523391723633, 2163
[INFO] 2021-07-12 19:15:44,995 [run_pretraining.py:  535]:	loss/mlm_loss, 7.509523391723633, 2163
[INFO] 2021-07-12 19:15:44,995 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1619998733513057e-05, 2163
[INFO] 2021-07-12 19:15:44,995 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2163
[INFO] 2021-07-12 19:15:44,995 [run_pretraining.py:  558]:	worker_index: 3, step: 2163, cost: 7.509523, mlm loss: 7.509523, speed: 1.036982 steps/s, speed: 8.295854 samples/s, speed: 4247.477314 tokens/s, learning rate: 2.162e-05, loss_scalings: 3518.437988, pp_loss: 7.149117
[INFO] 2021-07-12 19:15:44,995 [run_pretraining.py:  512]:	********exe.run_2163******* 
[INFO] 2021-07-12 19:15:45,945 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:45,945 [run_pretraining.py:  534]:	loss/total_loss, 7.7370476722717285, 2164
[INFO] 2021-07-12 19:15:45,945 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7370476722717285, 2164
[INFO] 2021-07-12 19:15:45,945 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1629999537253752e-05, 2164
[INFO] 2021-07-12 19:15:45,945 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2164
[INFO] 2021-07-12 19:15:45,945 [run_pretraining.py:  558]:	worker_index: 3, step: 2164, cost: 7.737048, mlm loss: 7.737048, speed: 1.052647 steps/s, speed: 8.421179 samples/s, speed: 4311.643656 tokens/s, learning rate: 2.163e-05, loss_scalings: 3518.437988, pp_loss: 7.693124
[INFO] 2021-07-12 19:15:45,946 [run_pretraining.py:  512]:	********exe.run_2164******* 
[INFO] 2021-07-12 19:15:46,865 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:46,866 [run_pretraining.py:  534]:	loss/total_loss, 7.624042510986328, 2165
[INFO] 2021-07-12 19:15:46,866 [run_pretraining.py:  535]:	loss/mlm_loss, 7.624042510986328, 2165
[INFO] 2021-07-12 19:15:46,866 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1639998522005044e-05, 2165
[INFO] 2021-07-12 19:15:46,866 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2165
[INFO] 2021-07-12 19:15:46,866 [run_pretraining.py:  558]:	worker_index: 3, step: 2165, cost: 7.624043, mlm loss: 7.624043, speed: 1.086715 steps/s, speed: 8.693716 samples/s, speed: 4451.182664 tokens/s, learning rate: 2.164e-05, loss_scalings: 3518.437988, pp_loss: 7.425880
[INFO] 2021-07-12 19:15:46,866 [run_pretraining.py:  512]:	********exe.run_2165******* 
[INFO] 2021-07-12 19:15:47,777 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:47,777 [run_pretraining.py:  534]:	loss/total_loss, 7.054302215576172, 2166
[INFO] 2021-07-12 19:15:47,777 [run_pretraining.py:  535]:	loss/mlm_loss, 7.054302215576172, 2166
[INFO] 2021-07-12 19:15:47,777 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.164999932574574e-05, 2166
[INFO] 2021-07-12 19:15:47,778 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2166
[INFO] 2021-07-12 19:15:47,778 [run_pretraining.py:  558]:	worker_index: 3, step: 2166, cost: 7.054302, mlm loss: 7.054302, speed: 1.098125 steps/s, speed: 8.785000 samples/s, speed: 4497.920202 tokens/s, learning rate: 2.165e-05, loss_scalings: 3518.437988, pp_loss: 7.260393
[INFO] 2021-07-12 19:15:47,778 [run_pretraining.py:  512]:	********exe.run_2166******* 
[INFO] 2021-07-12 19:15:48,685 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:48,685 [run_pretraining.py:  534]:	loss/total_loss, 7.363153457641602, 2167
[INFO] 2021-07-12 19:15:48,686 [run_pretraining.py:  535]:	loss/mlm_loss, 7.363153457641602, 2167
[INFO] 2021-07-12 19:15:48,686 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1660000129486434e-05, 2167
[INFO] 2021-07-12 19:15:48,686 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2167
[INFO] 2021-07-12 19:15:48,686 [run_pretraining.py:  558]:	worker_index: 3, step: 2167, cost: 7.363153, mlm loss: 7.363153, speed: 1.101921 steps/s, speed: 8.815371 samples/s, speed: 4513.470022 tokens/s, learning rate: 2.166e-05, loss_scalings: 3518.437988, pp_loss: 7.374988
[INFO] 2021-07-12 19:15:48,686 [run_pretraining.py:  512]:	********exe.run_2167******* 
[INFO] 2021-07-12 19:15:49,590 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:49,591 [run_pretraining.py:  534]:	loss/total_loss, 7.94293737411499, 2168
[INFO] 2021-07-12 19:15:49,591 [run_pretraining.py:  535]:	loss/mlm_loss, 7.94293737411499, 2168
[INFO] 2021-07-12 19:15:49,591 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1669999114237726e-05, 2168
[INFO] 2021-07-12 19:15:49,591 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2168
[INFO] 2021-07-12 19:15:49,591 [run_pretraining.py:  558]:	worker_index: 3, step: 2168, cost: 7.942937, mlm loss: 7.942937, speed: 1.105032 steps/s, speed: 8.840259 samples/s, speed: 4526.212631 tokens/s, learning rate: 2.167e-05, loss_scalings: 3518.437988, pp_loss: 7.644218
[INFO] 2021-07-12 19:15:49,591 [run_pretraining.py:  512]:	********exe.run_2168******* 
[INFO] 2021-07-12 19:15:50,500 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:50,501 [run_pretraining.py:  534]:	loss/total_loss, 6.98733377456665, 2169
[INFO] 2021-07-12 19:15:50,501 [run_pretraining.py:  535]:	loss/mlm_loss, 6.98733377456665, 2169
[INFO] 2021-07-12 19:15:50,501 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.167999991797842e-05, 2169
[INFO] 2021-07-12 19:15:50,501 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2169
[INFO] 2021-07-12 19:15:50,501 [run_pretraining.py:  558]:	worker_index: 3, step: 2169, cost: 6.987334, mlm loss: 6.987334, speed: 1.099923 steps/s, speed: 8.799388 samples/s, speed: 4505.286457 tokens/s, learning rate: 2.168e-05, loss_scalings: 3518.437988, pp_loss: 7.260571
[INFO] 2021-07-12 19:15:50,501 [run_pretraining.py:  512]:	********exe.run_2169******* 
[INFO] 2021-07-12 19:15:51,408 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:51,408 [run_pretraining.py:  534]:	loss/total_loss, 7.209275722503662, 2170
[INFO] 2021-07-12 19:15:51,409 [run_pretraining.py:  535]:	loss/mlm_loss, 7.209275722503662, 2170
[INFO] 2021-07-12 19:15:51,409 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1690000721719116e-05, 2170
[INFO] 2021-07-12 19:15:51,409 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2170
[INFO] 2021-07-12 19:15:51,409 [run_pretraining.py:  558]:	worker_index: 3, step: 2170, cost: 7.209276, mlm loss: 7.209276, speed: 1.102560 steps/s, speed: 8.820483 samples/s, speed: 4516.087352 tokens/s, learning rate: 2.169e-05, loss_scalings: 3518.437988, pp_loss: 7.120102
[INFO] 2021-07-12 19:15:51,409 [run_pretraining.py:  512]:	********exe.run_2170******* 
[INFO] 2021-07-12 19:15:52,315 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:52,315 [run_pretraining.py:  534]:	loss/total_loss, 6.8561320304870605, 2171
[INFO] 2021-07-12 19:15:52,315 [run_pretraining.py:  535]:	loss/mlm_loss, 6.8561320304870605, 2171
[INFO] 2021-07-12 19:15:52,315 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1699997887481004e-05, 2171
[INFO] 2021-07-12 19:15:52,316 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2171
[INFO] 2021-07-12 19:15:52,316 [run_pretraining.py:  558]:	worker_index: 3, step: 2171, cost: 6.856132, mlm loss: 6.856132, speed: 1.103531 steps/s, speed: 8.828250 samples/s, speed: 4520.064235 tokens/s, learning rate: 2.170e-05, loss_scalings: 3518.437988, pp_loss: 7.131478
[INFO] 2021-07-12 19:15:52,316 [run_pretraining.py:  512]:	********exe.run_2171******* 
[INFO] 2021-07-12 19:15:53,262 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:53,263 [run_pretraining.py:  534]:	loss/total_loss, 8.659795761108398, 2172
[INFO] 2021-07-12 19:15:53,263 [run_pretraining.py:  535]:	loss/mlm_loss, 8.659795761108398, 2172
[INFO] 2021-07-12 19:15:53,263 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.17099986912217e-05, 2172
[INFO] 2021-07-12 19:15:53,263 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2172
[INFO] 2021-07-12 19:15:53,263 [run_pretraining.py:  558]:	worker_index: 3, step: 2172, cost: 8.659796, mlm loss: 8.659796, speed: 1.056299 steps/s, speed: 8.450393 samples/s, speed: 4326.601241 tokens/s, learning rate: 2.171e-05, loss_scalings: 3518.437988, pp_loss: 7.737206
[INFO] 2021-07-12 19:15:53,263 [run_pretraining.py:  512]:	********exe.run_2172******* 
[INFO] 2021-07-12 19:15:54,171 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:54,171 [run_pretraining.py:  534]:	loss/total_loss, 5.262951850891113, 2173
[INFO] 2021-07-12 19:15:54,171 [run_pretraining.py:  535]:	loss/mlm_loss, 5.262951850891113, 2173
[INFO] 2021-07-12 19:15:54,172 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1719999494962394e-05, 2173
[INFO] 2021-07-12 19:15:54,172 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2173
[INFO] 2021-07-12 19:15:54,172 [run_pretraining.py:  558]:	worker_index: 3, step: 2173, cost: 5.262952, mlm loss: 5.262952, speed: 1.101170 steps/s, speed: 8.809363 samples/s, speed: 4510.393855 tokens/s, learning rate: 2.172e-05, loss_scalings: 3518.437988, pp_loss: 6.706125
[INFO] 2021-07-12 19:15:54,172 [run_pretraining.py:  512]:	********exe.run_2173******* 
[INFO] 2021-07-12 19:15:55,079 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:55,080 [run_pretraining.py:  534]:	loss/total_loss, 7.036811828613281, 2174
[INFO] 2021-07-12 19:15:55,080 [run_pretraining.py:  535]:	loss/mlm_loss, 7.036811828613281, 2174
[INFO] 2021-07-12 19:15:55,080 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1729998479713686e-05, 2174
[INFO] 2021-07-12 19:15:55,080 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2174
[INFO] 2021-07-12 19:15:55,080 [run_pretraining.py:  558]:	worker_index: 3, step: 2174, cost: 7.036812, mlm loss: 7.036812, speed: 1.101704 steps/s, speed: 8.813632 samples/s, speed: 4512.579682 tokens/s, learning rate: 2.173e-05, loss_scalings: 3518.437988, pp_loss: 6.936470
[INFO] 2021-07-12 19:15:55,080 [run_pretraining.py:  512]:	********exe.run_2174******* 
[INFO] 2021-07-12 19:15:55,985 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:55,985 [run_pretraining.py:  534]:	loss/total_loss, 4.585015296936035, 2175
[INFO] 2021-07-12 19:15:55,985 [run_pretraining.py:  535]:	loss/mlm_loss, 4.585015296936035, 2175
[INFO] 2021-07-12 19:15:55,985 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.173999928345438e-05, 2175
[INFO] 2021-07-12 19:15:55,985 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2175
[INFO] 2021-07-12 19:15:55,985 [run_pretraining.py:  558]:	worker_index: 3, step: 2175, cost: 4.585015, mlm loss: 4.585015, speed: 1.105320 steps/s, speed: 8.842563 samples/s, speed: 4527.392298 tokens/s, learning rate: 2.174e-05, loss_scalings: 3518.437988, pp_loss: 6.441500
[INFO] 2021-07-12 19:15:55,985 [run_pretraining.py:  512]:	********exe.run_2175******* 
[INFO] 2021-07-12 19:15:56,895 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:56,895 [run_pretraining.py:  534]:	loss/total_loss, 8.060708999633789, 2176
[INFO] 2021-07-12 19:15:56,896 [run_pretraining.py:  535]:	loss/mlm_loss, 8.060708999633789, 2176
[INFO] 2021-07-12 19:15:56,896 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1750000087195076e-05, 2176
[INFO] 2021-07-12 19:15:56,896 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2176
[INFO] 2021-07-12 19:15:56,896 [run_pretraining.py:  558]:	worker_index: 3, step: 2176, cost: 8.060709, mlm loss: 8.060709, speed: 1.099133 steps/s, speed: 8.793060 samples/s, speed: 4502.046818 tokens/s, learning rate: 2.175e-05, loss_scalings: 3518.437988, pp_loss: 7.751291
[INFO] 2021-07-12 19:15:56,896 [run_pretraining.py:  512]:	********exe.run_2176******* 
[INFO] 2021-07-12 19:15:57,798 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:57,799 [run_pretraining.py:  534]:	loss/total_loss, 7.595180988311768, 2177
[INFO] 2021-07-12 19:15:57,799 [run_pretraining.py:  535]:	loss/mlm_loss, 7.595180988311768, 2177
[INFO] 2021-07-12 19:15:57,799 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1759999071946368e-05, 2177
[INFO] 2021-07-12 19:15:57,799 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2177
[INFO] 2021-07-12 19:15:57,799 [run_pretraining.py:  558]:	worker_index: 3, step: 2177, cost: 7.595181, mlm loss: 7.595181, speed: 1.107618 steps/s, speed: 8.860947 samples/s, speed: 4536.805094 tokens/s, learning rate: 2.176e-05, loss_scalings: 3518.437988, pp_loss: 7.399154
[INFO] 2021-07-12 19:15:57,799 [run_pretraining.py:  512]:	********exe.run_2177******* 
[INFO] 2021-07-12 19:15:58,710 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:58,711 [run_pretraining.py:  534]:	loss/total_loss, 6.721991539001465, 2178
[INFO] 2021-07-12 19:15:58,711 [run_pretraining.py:  535]:	loss/mlm_loss, 6.721991539001465, 2178
[INFO] 2021-07-12 19:15:58,711 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1769999875687063e-05, 2178
[INFO] 2021-07-12 19:15:58,711 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2178
[INFO] 2021-07-12 19:15:58,711 [run_pretraining.py:  558]:	worker_index: 3, step: 2178, cost: 6.721992, mlm loss: 6.721992, speed: 1.097634 steps/s, speed: 8.781076 samples/s, speed: 4495.910910 tokens/s, learning rate: 2.177e-05, loss_scalings: 3518.437988, pp_loss: 7.576546
[INFO] 2021-07-12 19:15:58,711 [run_pretraining.py:  512]:	********exe.run_2178******* 
[INFO] 2021-07-12 19:15:59,613 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:59,614 [run_pretraining.py:  534]:	loss/total_loss, 7.319479942321777, 2179
[INFO] 2021-07-12 19:15:59,614 [run_pretraining.py:  535]:	loss/mlm_loss, 7.319479942321777, 2179
[INFO] 2021-07-12 19:15:59,614 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1780000679427758e-05, 2179
[INFO] 2021-07-12 19:15:59,614 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2179
[INFO] 2021-07-12 19:15:59,614 [run_pretraining.py:  558]:	worker_index: 3, step: 2179, cost: 7.319480, mlm loss: 7.319480, speed: 1.108035 steps/s, speed: 8.864283 samples/s, speed: 4538.512980 tokens/s, learning rate: 2.178e-05, loss_scalings: 3518.437988, pp_loss: 7.700356
[INFO] 2021-07-12 19:15:59,614 [run_pretraining.py:  512]:	********exe.run_2179******* 
[INFO] 2021-07-12 19:16:00,533 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:00,533 [run_pretraining.py:  534]:	loss/total_loss, 7.117029190063477, 2180
[INFO] 2021-07-12 19:16:00,534 [run_pretraining.py:  535]:	loss/mlm_loss, 7.117029190063477, 2180
[INFO] 2021-07-12 19:16:00,534 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.178999966417905e-05, 2180
[INFO] 2021-07-12 19:16:00,534 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2180
[INFO] 2021-07-12 19:16:00,534 [run_pretraining.py:  558]:	worker_index: 3, step: 2180, cost: 7.117029, mlm loss: 7.117029, speed: 1.088134 steps/s, speed: 8.705074 samples/s, speed: 4456.998120 tokens/s, learning rate: 2.179e-05, loss_scalings: 3518.437988, pp_loss: 7.379887
[INFO] 2021-07-12 19:16:00,534 [run_pretraining.py:  512]:	********exe.run_2180******* 
[INFO] 2021-07-12 19:16:01,446 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:01,447 [run_pretraining.py:  534]:	loss/total_loss, 7.0944414138793945, 2181
[INFO] 2021-07-12 19:16:01,447 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0944414138793945, 2181
[INFO] 2021-07-12 19:16:01,447 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.179999864893034e-05, 2181
[INFO] 2021-07-12 19:16:01,447 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2181
[INFO] 2021-07-12 19:16:01,447 [run_pretraining.py:  558]:	worker_index: 3, step: 2181, cost: 7.094441, mlm loss: 7.094441, speed: 1.095923 steps/s, speed: 8.767385 samples/s, speed: 4488.901299 tokens/s, learning rate: 2.180e-05, loss_scalings: 3518.437988, pp_loss: 7.617107
[INFO] 2021-07-12 19:16:01,447 [run_pretraining.py:  512]:	********exe.run_2181******* 
[INFO] 2021-07-12 19:16:02,353 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:02,353 [run_pretraining.py:  534]:	loss/total_loss, 7.764271259307861, 2182
[INFO] 2021-07-12 19:16:02,353 [run_pretraining.py:  535]:	loss/mlm_loss, 7.764271259307861, 2182
[INFO] 2021-07-12 19:16:02,353 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1809999452671036e-05, 2182
[INFO] 2021-07-12 19:16:02,353 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2182
[INFO] 2021-07-12 19:16:02,354 [run_pretraining.py:  558]:	worker_index: 3, step: 2182, cost: 7.764271, mlm loss: 7.764271, speed: 1.103757 steps/s, speed: 8.830058 samples/s, speed: 4520.989653 tokens/s, learning rate: 2.181e-05, loss_scalings: 3518.437988, pp_loss: 7.555638
[INFO] 2021-07-12 19:16:02,354 [run_pretraining.py:  512]:	********exe.run_2182******* 
[INFO] 2021-07-12 19:16:03,263 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:03,263 [run_pretraining.py:  534]:	loss/total_loss, 7.96669340133667, 2183
[INFO] 2021-07-12 19:16:03,264 [run_pretraining.py:  535]:	loss/mlm_loss, 7.96669340133667, 2183
[INFO] 2021-07-12 19:16:03,264 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1819998437422328e-05, 2183
[INFO] 2021-07-12 19:16:03,264 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2183
[INFO] 2021-07-12 19:16:03,264 [run_pretraining.py:  558]:	worker_index: 3, step: 2183, cost: 7.966693, mlm loss: 7.966693, speed: 1.099359 steps/s, speed: 8.794872 samples/s, speed: 4502.974314 tokens/s, learning rate: 2.182e-05, loss_scalings: 3518.437988, pp_loss: 7.736415
[INFO] 2021-07-12 19:16:03,264 [run_pretraining.py:  512]:	********exe.run_2183******* 
[INFO] 2021-07-12 19:16:04,172 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:04,172 [run_pretraining.py:  534]:	loss/total_loss, 7.57279634475708, 2184
[INFO] 2021-07-12 19:16:04,172 [run_pretraining.py:  535]:	loss/mlm_loss, 7.57279634475708, 2184
[INFO] 2021-07-12 19:16:04,173 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1829999241163023e-05, 2184
[INFO] 2021-07-12 19:16:04,173 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2184
[INFO] 2021-07-12 19:16:04,173 [run_pretraining.py:  558]:	worker_index: 3, step: 2184, cost: 7.572796, mlm loss: 7.572796, speed: 1.100984 steps/s, speed: 8.807871 samples/s, speed: 4509.630203 tokens/s, learning rate: 2.183e-05, loss_scalings: 3518.437988, pp_loss: 7.337689
[INFO] 2021-07-12 19:16:04,173 [run_pretraining.py:  512]:	********exe.run_2184******* 
[INFO] 2021-07-12 19:16:05,084 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:05,084 [run_pretraining.py:  534]:	loss/total_loss, 6.817090034484863, 2185
[INFO] 2021-07-12 19:16:05,084 [run_pretraining.py:  535]:	loss/mlm_loss, 6.817090034484863, 2185
[INFO] 2021-07-12 19:16:05,084 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1840000044903718e-05, 2185
[INFO] 2021-07-12 19:16:05,085 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2185
[INFO] 2021-07-12 19:16:05,085 [run_pretraining.py:  558]:	worker_index: 3, step: 2185, cost: 6.817090, mlm loss: 6.817090, speed: 1.097339 steps/s, speed: 8.778714 samples/s, speed: 4494.701728 tokens/s, learning rate: 2.184e-05, loss_scalings: 3518.437988, pp_loss: 7.216501
[INFO] 2021-07-12 19:16:05,085 [run_pretraining.py:  512]:	********exe.run_2185******* 
[INFO] 2021-07-12 19:16:06,026 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:06,027 [run_pretraining.py:  534]:	loss/total_loss, 7.524632453918457, 2186
[INFO] 2021-07-12 19:16:06,027 [run_pretraining.py:  535]:	loss/mlm_loss, 7.524632453918457, 2186
[INFO] 2021-07-12 19:16:06,027 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.184999902965501e-05, 2186
[INFO] 2021-07-12 19:16:06,027 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2186
[INFO] 2021-07-12 19:16:06,027 [run_pretraining.py:  558]:	worker_index: 3, step: 2186, cost: 7.524632, mlm loss: 7.524632, speed: 1.061858 steps/s, speed: 8.494866 samples/s, speed: 4349.371408 tokens/s, learning rate: 2.185e-05, loss_scalings: 3518.437988, pp_loss: 7.656125
[INFO] 2021-07-12 19:16:06,027 [run_pretraining.py:  512]:	********exe.run_2186******* 
[INFO] 2021-07-12 19:16:06,952 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:06,952 [run_pretraining.py:  534]:	loss/total_loss, 7.044179439544678, 2187
[INFO] 2021-07-12 19:16:06,952 [run_pretraining.py:  535]:	loss/mlm_loss, 7.044179439544678, 2187
[INFO] 2021-07-12 19:16:06,952 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1859999833395705e-05, 2187
[INFO] 2021-07-12 19:16:06,953 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2187
[INFO] 2021-07-12 19:16:06,953 [run_pretraining.py:  558]:	worker_index: 3, step: 2187, cost: 7.044179, mlm loss: 7.044179, speed: 1.081115 steps/s, speed: 8.648917 samples/s, speed: 4428.245302 tokens/s, learning rate: 2.186e-05, loss_scalings: 3518.437988, pp_loss: 7.688000
[INFO] 2021-07-12 19:16:06,953 [run_pretraining.py:  512]:	********exe.run_2187******* 
[INFO] 2021-07-12 19:16:07,862 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:07,862 [run_pretraining.py:  534]:	loss/total_loss, 6.564542293548584, 2188
[INFO] 2021-07-12 19:16:07,863 [run_pretraining.py:  535]:	loss/mlm_loss, 6.564542293548584, 2188
[INFO] 2021-07-12 19:16:07,863 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.18700006371364e-05, 2188
[INFO] 2021-07-12 19:16:07,863 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2188
[INFO] 2021-07-12 19:16:07,863 [run_pretraining.py:  558]:	worker_index: 3, step: 2188, cost: 6.564542, mlm loss: 6.564542, speed: 1.099497 steps/s, speed: 8.795974 samples/s, speed: 4503.538551 tokens/s, learning rate: 2.187e-05, loss_scalings: 3518.437988, pp_loss: 6.726014
[INFO] 2021-07-12 19:16:07,863 [run_pretraining.py:  512]:	********exe.run_2188******* 
[INFO] 2021-07-12 19:16:08,773 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:08,774 [run_pretraining.py:  534]:	loss/total_loss, 7.253180503845215, 2189
[INFO] 2021-07-12 19:16:08,774 [run_pretraining.py:  535]:	loss/mlm_loss, 7.253180503845215, 2189
[INFO] 2021-07-12 19:16:08,774 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.187999962188769e-05, 2189
[INFO] 2021-07-12 19:16:08,774 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2189
[INFO] 2021-07-12 19:16:08,774 [run_pretraining.py:  558]:	worker_index: 3, step: 2189, cost: 7.253181, mlm loss: 7.253181, speed: 1.097777 steps/s, speed: 8.782214 samples/s, speed: 4496.493385 tokens/s, learning rate: 2.188e-05, loss_scalings: 3518.437988, pp_loss: 7.154546
[INFO] 2021-07-12 19:16:08,774 [run_pretraining.py:  512]:	********exe.run_2189******* 
[INFO] 2021-07-12 19:16:09,773 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:09,774 [run_pretraining.py:  534]:	loss/total_loss, 7.0934038162231445, 2190
[INFO] 2021-07-12 19:16:09,774 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0934038162231445, 2190
[INFO] 2021-07-12 19:16:09,774 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1889998606638983e-05, 2190
[INFO] 2021-07-12 19:16:09,774 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2190
[INFO] 2021-07-12 19:16:09,774 [run_pretraining.py:  558]:	worker_index: 3, step: 2190, cost: 7.093404, mlm loss: 7.093404, speed: 1.001012 steps/s, speed: 8.008093 samples/s, speed: 4100.143836 tokens/s, learning rate: 2.189e-05, loss_scalings: 3518.437988, pp_loss: 7.446203
[INFO] 2021-07-12 19:16:09,774 [run_pretraining.py:  512]:	********exe.run_2190******* 
[INFO] 2021-07-12 19:16:10,680 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:10,680 [run_pretraining.py:  534]:	loss/total_loss, 6.8700127601623535, 2191
[INFO] 2021-07-12 19:16:10,680 [run_pretraining.py:  535]:	loss/mlm_loss, 6.8700127601623535, 2191
[INFO] 2021-07-12 19:16:10,680 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1899999410379678e-05, 2191
[INFO] 2021-07-12 19:16:10,680 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2191
[INFO] 2021-07-12 19:16:10,681 [run_pretraining.py:  558]:	worker_index: 3, step: 2191, cost: 6.870013, mlm loss: 6.870013, speed: 1.103857 steps/s, speed: 8.830855 samples/s, speed: 4521.397766 tokens/s, learning rate: 2.190e-05, loss_scalings: 3518.437988, pp_loss: 7.283166
[INFO] 2021-07-12 19:16:10,681 [run_pretraining.py:  512]:	********exe.run_2191******* 
[INFO] 2021-07-12 19:16:11,593 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:11,593 [run_pretraining.py:  534]:	loss/total_loss, 7.433892250061035, 2192
[INFO] 2021-07-12 19:16:11,594 [run_pretraining.py:  535]:	loss/mlm_loss, 7.433892250061035, 2192
[INFO] 2021-07-12 19:16:11,594 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.190999839513097e-05, 2192
[INFO] 2021-07-12 19:16:11,594 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2192
[INFO] 2021-07-12 19:16:11,594 [run_pretraining.py:  558]:	worker_index: 3, step: 2192, cost: 7.433892, mlm loss: 7.433892, speed: 1.095746 steps/s, speed: 8.765965 samples/s, speed: 4488.174220 tokens/s, learning rate: 2.191e-05, loss_scalings: 3518.437988, pp_loss: 7.434126
[INFO] 2021-07-12 19:16:11,594 [run_pretraining.py:  512]:	********exe.run_2192******* 
[INFO] 2021-07-12 19:16:12,508 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:12,508 [run_pretraining.py:  534]:	loss/total_loss, 7.156777381896973, 2193
[INFO] 2021-07-12 19:16:12,508 [run_pretraining.py:  535]:	loss/mlm_loss, 7.156777381896973, 2193
[INFO] 2021-07-12 19:16:12,509 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1919999198871665e-05, 2193
[INFO] 2021-07-12 19:16:12,509 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2193
[INFO] 2021-07-12 19:16:12,509 [run_pretraining.py:  558]:	worker_index: 3, step: 2193, cost: 7.156777, mlm loss: 7.156777, speed: 1.093733 steps/s, speed: 8.749864 samples/s, speed: 4479.930173 tokens/s, learning rate: 2.192e-05, loss_scalings: 3518.437988, pp_loss: 7.093827
[INFO] 2021-07-12 19:16:12,509 [run_pretraining.py:  512]:	********exe.run_2193******* 
[INFO] 2021-07-12 19:16:13,420 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:13,420 [run_pretraining.py:  534]:	loss/total_loss, 7.509522438049316, 2194
[INFO] 2021-07-12 19:16:13,420 [run_pretraining.py:  535]:	loss/mlm_loss, 7.509522438049316, 2194
[INFO] 2021-07-12 19:16:13,421 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.193000000261236e-05, 2194
[INFO] 2021-07-12 19:16:13,421 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2194
[INFO] 2021-07-12 19:16:13,421 [run_pretraining.py:  558]:	worker_index: 3, step: 2194, cost: 7.509522, mlm loss: 7.509522, speed: 1.097185 steps/s, speed: 8.777477 samples/s, speed: 4494.067990 tokens/s, learning rate: 2.193e-05, loss_scalings: 3518.437988, pp_loss: 7.147973
[INFO] 2021-07-12 19:16:13,421 [run_pretraining.py:  512]:	********exe.run_2194******* 
[INFO] 2021-07-12 19:16:14,332 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:14,333 [run_pretraining.py:  534]:	loss/total_loss, 7.199831962585449, 2195
[INFO] 2021-07-12 19:16:14,333 [run_pretraining.py:  535]:	loss/mlm_loss, 7.199831962585449, 2195
[INFO] 2021-07-12 19:16:14,333 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.193999898736365e-05, 2195
[INFO] 2021-07-12 19:16:14,333 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2195
[INFO] 2021-07-12 19:16:14,333 [run_pretraining.py:  558]:	worker_index: 3, step: 2195, cost: 7.199832, mlm loss: 7.199832, speed: 1.097057 steps/s, speed: 8.776455 samples/s, speed: 4493.544909 tokens/s, learning rate: 2.194e-05, loss_scalings: 3518.437988, pp_loss: 7.033236
[INFO] 2021-07-12 19:16:14,333 [run_pretraining.py:  512]:	********exe.run_2195******* 
[INFO] 2021-07-12 19:16:15,241 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:15,241 [run_pretraining.py:  534]:	loss/total_loss, 7.296047210693359, 2196
[INFO] 2021-07-12 19:16:15,241 [run_pretraining.py:  535]:	loss/mlm_loss, 7.296047210693359, 2196
[INFO] 2021-07-12 19:16:15,241 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1949999791104347e-05, 2196
[INFO] 2021-07-12 19:16:15,241 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2196
[INFO] 2021-07-12 19:16:15,241 [run_pretraining.py:  558]:	worker_index: 3, step: 2196, cost: 7.296047, mlm loss: 7.296047, speed: 1.101397 steps/s, speed: 8.811177 samples/s, speed: 4511.322425 tokens/s, learning rate: 2.195e-05, loss_scalings: 3518.437988, pp_loss: 7.332113
[INFO] 2021-07-12 19:16:15,241 [run_pretraining.py:  512]:	********exe.run_2196******* 
[INFO] 2021-07-12 19:16:16,153 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:16,154 [run_pretraining.py:  534]:	loss/total_loss, 7.508815765380859, 2197
[INFO] 2021-07-12 19:16:16,154 [run_pretraining.py:  535]:	loss/mlm_loss, 7.508815765380859, 2197
[INFO] 2021-07-12 19:16:16,154 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.196000059484504e-05, 2197
[INFO] 2021-07-12 19:16:16,154 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2197
[INFO] 2021-07-12 19:16:16,154 [run_pretraining.py:  558]:	worker_index: 3, step: 2197, cost: 7.508816, mlm loss: 7.508816, speed: 1.096236 steps/s, speed: 8.769890 samples/s, speed: 4490.183643 tokens/s, learning rate: 2.196e-05, loss_scalings: 3518.437988, pp_loss: 7.329606
[INFO] 2021-07-12 19:16:16,154 [run_pretraining.py:  512]:	********exe.run_2197******* 
[INFO] 2021-07-12 19:16:17,067 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:17,067 [run_pretraining.py:  534]:	loss/total_loss, 6.967274188995361, 2198
[INFO] 2021-07-12 19:16:17,067 [run_pretraining.py:  535]:	loss/mlm_loss, 6.967274188995361, 2198
[INFO] 2021-07-12 19:16:17,067 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1969999579596333e-05, 2198
[INFO] 2021-07-12 19:16:17,067 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2198
[INFO] 2021-07-12 19:16:17,067 [run_pretraining.py:  558]:	worker_index: 3, step: 2198, cost: 6.967274, mlm loss: 6.967274, speed: 1.095865 steps/s, speed: 8.766918 samples/s, speed: 4488.662040 tokens/s, learning rate: 2.197e-05, loss_scalings: 3518.437988, pp_loss: 7.359070
[INFO] 2021-07-12 19:16:17,067 [run_pretraining.py:  512]:	********exe.run_2198******* 
[INFO] 2021-07-12 19:16:17,974 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:17,974 [run_pretraining.py:  534]:	loss/total_loss, 7.459149360656738, 2199
[INFO] 2021-07-12 19:16:17,974 [run_pretraining.py:  535]:	loss/mlm_loss, 7.459149360656738, 2199
[INFO] 2021-07-12 19:16:17,975 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1979998564347625e-05, 2199
[INFO] 2021-07-12 19:16:17,975 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2199
[INFO] 2021-07-12 19:16:17,975 [run_pretraining.py:  558]:	worker_index: 3, step: 2199, cost: 7.459149, mlm loss: 7.459149, speed: 1.103007 steps/s, speed: 8.824058 samples/s, speed: 4517.917488 tokens/s, learning rate: 2.198e-05, loss_scalings: 3518.437988, pp_loss: 7.254708
[INFO] 2021-07-12 19:16:17,975 [run_pretraining.py:  512]:	********exe.run_2199******* 
[INFO] 2021-07-12 19:16:18,894 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:18,894 [run_pretraining.py:  534]:	loss/total_loss, 6.932956695556641, 2200
[INFO] 2021-07-12 19:16:18,895 [run_pretraining.py:  535]:	loss/mlm_loss, 6.932956695556641, 2200
[INFO] 2021-07-12 19:16:18,895 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.198999936808832e-05, 2200
[INFO] 2021-07-12 19:16:18,895 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2200
[INFO] 2021-07-12 19:16:18,895 [run_pretraining.py:  558]:	worker_index: 3, step: 2200, cost: 6.932957, mlm loss: 6.932957, speed: 1.087502 steps/s, speed: 8.700019 samples/s, speed: 4454.409545 tokens/s, learning rate: 2.199e-05, loss_scalings: 3518.437988, pp_loss: 6.989428
[INFO] 2021-07-12 19:16:18,895 [run_pretraining.py:  512]:	********exe.run_2200******* 
[INFO] 2021-07-12 19:16:19,802 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:19,802 [run_pretraining.py:  534]:	loss/total_loss, 6.528135299682617, 2201
[INFO] 2021-07-12 19:16:19,802 [run_pretraining.py:  535]:	loss/mlm_loss, 6.528135299682617, 2201
[INFO] 2021-07-12 19:16:19,802 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2000000171829015e-05, 2201
[INFO] 2021-07-12 19:16:19,802 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2201
[INFO] 2021-07-12 19:16:19,802 [run_pretraining.py:  558]:	worker_index: 3, step: 2201, cost: 6.528135, mlm loss: 6.528135, speed: 1.102615 steps/s, speed: 8.820917 samples/s, speed: 4516.309360 tokens/s, learning rate: 2.200e-05, loss_scalings: 3518.437988, pp_loss: 6.725073
[INFO] 2021-07-12 19:16:19,803 [run_pretraining.py:  512]:	********exe.run_2201******* 
[INFO] 2021-07-12 19:16:20,769 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:20,769 [run_pretraining.py:  534]:	loss/total_loss, 7.148349761962891, 2202
[INFO] 2021-07-12 19:16:20,769 [run_pretraining.py:  535]:	loss/mlm_loss, 7.148349761962891, 2202
[INFO] 2021-07-12 19:16:20,769 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2009999156580307e-05, 2202
[INFO] 2021-07-12 19:16:20,769 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2202
[INFO] 2021-07-12 19:16:20,770 [run_pretraining.py:  558]:	worker_index: 3, step: 2202, cost: 7.148350, mlm loss: 7.148350, speed: 1.034721 steps/s, speed: 8.277769 samples/s, speed: 4238.217563 tokens/s, learning rate: 2.201e-05, loss_scalings: 3518.437988, pp_loss: 7.303899
[INFO] 2021-07-12 19:16:20,770 [run_pretraining.py:  512]:	********exe.run_2202******* 
[INFO] 2021-07-12 19:16:21,676 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:21,677 [run_pretraining.py:  534]:	loss/total_loss, 6.9495697021484375, 2203
[INFO] 2021-07-12 19:16:21,677 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9495697021484375, 2203
[INFO] 2021-07-12 19:16:21,677 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2019999960321002e-05, 2203
[INFO] 2021-07-12 19:16:21,677 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2203
[INFO] 2021-07-12 19:16:21,677 [run_pretraining.py:  558]:	worker_index: 3, step: 2203, cost: 6.949570, mlm loss: 6.949570, speed: 1.102453 steps/s, speed: 8.819628 samples/s, speed: 4515.649337 tokens/s, learning rate: 2.202e-05, loss_scalings: 3518.437988, pp_loss: 7.104819
[INFO] 2021-07-12 19:16:21,677 [run_pretraining.py:  512]:	********exe.run_2203******* 
[INFO] 2021-07-12 19:16:22,587 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:22,587 [run_pretraining.py:  534]:	loss/total_loss, 7.334853172302246, 2204
[INFO] 2021-07-12 19:16:22,587 [run_pretraining.py:  535]:	loss/mlm_loss, 7.334853172302246, 2204
[INFO] 2021-07-12 19:16:22,587 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2029998945072293e-05, 2204
[INFO] 2021-07-12 19:16:22,587 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2204
[INFO] 2021-07-12 19:16:22,587 [run_pretraining.py:  558]:	worker_index: 3, step: 2204, cost: 7.334853, mlm loss: 7.334853, speed: 1.099353 steps/s, speed: 8.794826 samples/s, speed: 4502.950709 tokens/s, learning rate: 2.203e-05, loss_scalings: 3518.437988, pp_loss: 7.129148
[INFO] 2021-07-12 19:16:22,588 [run_pretraining.py:  512]:	********exe.run_2204******* 
[INFO] 2021-07-12 19:16:23,499 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:23,500 [run_pretraining.py:  534]:	loss/total_loss, 7.302420616149902, 2205
[INFO] 2021-07-12 19:16:23,500 [run_pretraining.py:  535]:	loss/mlm_loss, 7.302420616149902, 2205
[INFO] 2021-07-12 19:16:23,500 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.203999974881299e-05, 2205
[INFO] 2021-07-12 19:16:23,500 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2205
[INFO] 2021-07-12 19:16:23,500 [run_pretraining.py:  558]:	worker_index: 3, step: 2205, cost: 7.302421, mlm loss: 7.302421, speed: 1.096406 steps/s, speed: 8.771252 samples/s, speed: 4490.880850 tokens/s, learning rate: 2.204e-05, loss_scalings: 3518.437988, pp_loss: 7.014432
[INFO] 2021-07-12 19:16:23,500 [run_pretraining.py:  512]:	********exe.run_2205******* 
[INFO] 2021-07-12 19:16:24,404 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:24,405 [run_pretraining.py:  534]:	loss/total_loss, 8.24578857421875, 2206
[INFO] 2021-07-12 19:16:24,405 [run_pretraining.py:  535]:	loss/mlm_loss, 8.24578857421875, 2206
[INFO] 2021-07-12 19:16:24,405 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2050000552553684e-05, 2206
[INFO] 2021-07-12 19:16:24,405 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2206
[INFO] 2021-07-12 19:16:24,405 [run_pretraining.py:  558]:	worker_index: 3, step: 2206, cost: 8.245789, mlm loss: 8.245789, speed: 1.106156 steps/s, speed: 8.849249 samples/s, speed: 4530.815499 tokens/s, learning rate: 2.205e-05, loss_scalings: 3518.437988, pp_loss: 7.226028
[INFO] 2021-07-12 19:16:24,405 [run_pretraining.py:  512]:	********exe.run_2206******* 
[INFO] 2021-07-12 19:16:25,308 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:25,308 [run_pretraining.py:  534]:	loss/total_loss, 7.59658145904541, 2207
[INFO] 2021-07-12 19:16:25,308 [run_pretraining.py:  535]:	loss/mlm_loss, 7.59658145904541, 2207
[INFO] 2021-07-12 19:16:25,309 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2059999537304975e-05, 2207
[INFO] 2021-07-12 19:16:25,309 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2207
[INFO] 2021-07-12 19:16:25,309 [run_pretraining.py:  558]:	worker_index: 3, step: 2207, cost: 7.596581, mlm loss: 7.596581, speed: 1.107195 steps/s, speed: 8.857563 samples/s, speed: 4535.072156 tokens/s, learning rate: 2.206e-05, loss_scalings: 3518.437988, pp_loss: 7.657530
[INFO] 2021-07-12 19:16:25,309 [run_pretraining.py:  512]:	********exe.run_2207******* 
[INFO] 2021-07-12 19:16:26,220 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:26,221 [run_pretraining.py:  534]:	loss/total_loss, 7.027403354644775, 2208
[INFO] 2021-07-12 19:16:26,221 [run_pretraining.py:  535]:	loss/mlm_loss, 7.027403354644775, 2208
[INFO] 2021-07-12 19:16:26,221 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2069998522056267e-05, 2208
[INFO] 2021-07-12 19:16:26,221 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2208
[INFO] 2021-07-12 19:16:26,221 [run_pretraining.py:  558]:	worker_index: 3, step: 2208, cost: 7.027403, mlm loss: 7.027403, speed: 1.096910 steps/s, speed: 8.775280 samples/s, speed: 4492.943223 tokens/s, learning rate: 2.207e-05, loss_scalings: 3518.437988, pp_loss: 7.666913
[INFO] 2021-07-12 19:16:26,221 [run_pretraining.py:  512]:	********exe.run_2208******* 
[INFO] 2021-07-12 19:16:27,122 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:27,123 [run_pretraining.py:  534]:	loss/total_loss, 5.055359363555908, 2209
[INFO] 2021-07-12 19:16:27,123 [run_pretraining.py:  535]:	loss/mlm_loss, 5.055359363555908, 2209
[INFO] 2021-07-12 19:16:27,123 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2079999325796962e-05, 2209
[INFO] 2021-07-12 19:16:27,123 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2209
[INFO] 2021-07-12 19:16:27,123 [run_pretraining.py:  558]:	worker_index: 3, step: 2209, cost: 5.055359, mlm loss: 5.055359, speed: 1.109340 steps/s, speed: 8.874718 samples/s, speed: 4543.855865 tokens/s, learning rate: 2.208e-05, loss_scalings: 3518.437988, pp_loss: 6.656210
[INFO] 2021-07-12 19:16:27,123 [run_pretraining.py:  512]:	********exe.run_2209******* 
[INFO] 2021-07-12 19:16:28,035 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:28,035 [run_pretraining.py:  534]:	loss/total_loss, 7.230274200439453, 2210
[INFO] 2021-07-12 19:16:28,036 [run_pretraining.py:  535]:	loss/mlm_loss, 7.230274200439453, 2210
[INFO] 2021-07-12 19:16:28,036 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2090000129537657e-05, 2210
[INFO] 2021-07-12 19:16:28,036 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2210
[INFO] 2021-07-12 19:16:28,036 [run_pretraining.py:  558]:	worker_index: 3, step: 2210, cost: 7.230274, mlm loss: 7.230274, speed: 1.096522 steps/s, speed: 8.772178 samples/s, speed: 4491.355169 tokens/s, learning rate: 2.209e-05, loss_scalings: 3518.437988, pp_loss: 7.146829
[INFO] 2021-07-12 19:16:28,036 [run_pretraining.py:  512]:	********exe.run_2210******* 
[INFO] 2021-07-12 19:16:29,022 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:29,023 [run_pretraining.py:  534]:	loss/total_loss, 6.7620391845703125, 2211
[INFO] 2021-07-12 19:16:29,023 [run_pretraining.py:  535]:	loss/mlm_loss, 6.7620391845703125, 2211
[INFO] 2021-07-12 19:16:29,023 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.209999911428895e-05, 2211
[INFO] 2021-07-12 19:16:29,023 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2211
[INFO] 2021-07-12 19:16:29,023 [run_pretraining.py:  558]:	worker_index: 3, step: 2211, cost: 6.762039, mlm loss: 6.762039, speed: 1.013392 steps/s, speed: 8.107136 samples/s, speed: 4150.853803 tokens/s, learning rate: 2.210e-05, loss_scalings: 3518.437988, pp_loss: 7.041005
[INFO] 2021-07-12 19:16:29,023 [run_pretraining.py:  512]:	********exe.run_2211******* 
[INFO] 2021-07-12 19:16:29,927 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:29,927 [run_pretraining.py:  534]:	loss/total_loss, 7.279050827026367, 2212
[INFO] 2021-07-12 19:16:29,927 [run_pretraining.py:  535]:	loss/mlm_loss, 7.279050827026367, 2212
[INFO] 2021-07-12 19:16:29,927 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2109999918029644e-05, 2212
[INFO] 2021-07-12 19:16:29,928 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2212
[INFO] 2021-07-12 19:16:29,928 [run_pretraining.py:  558]:	worker_index: 3, step: 2212, cost: 7.279051, mlm loss: 7.279051, speed: 1.106463 steps/s, speed: 8.851707 samples/s, speed: 4532.074082 tokens/s, learning rate: 2.211e-05, loss_scalings: 3518.437988, pp_loss: 7.451930
[INFO] 2021-07-12 19:16:29,928 [run_pretraining.py:  512]:	********exe.run_2212******* 
[INFO] 2021-07-12 19:16:30,837 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:30,838 [run_pretraining.py:  534]:	loss/total_loss, 7.861484527587891, 2213
[INFO] 2021-07-12 19:16:30,838 [run_pretraining.py:  535]:	loss/mlm_loss, 7.861484527587891, 2213
[INFO] 2021-07-12 19:16:30,838 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.212000072177034e-05, 2213
[INFO] 2021-07-12 19:16:30,838 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2213
[INFO] 2021-07-12 19:16:30,838 [run_pretraining.py:  558]:	worker_index: 3, step: 2213, cost: 7.861485, mlm loss: 7.861485, speed: 1.099310 steps/s, speed: 8.794478 samples/s, speed: 4502.772498 tokens/s, learning rate: 2.212e-05, loss_scalings: 3518.437988, pp_loss: 7.514652
[INFO] 2021-07-12 19:16:30,838 [run_pretraining.py:  512]:	********exe.run_2213******* 
[INFO] 2021-07-12 19:16:31,746 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:31,747 [run_pretraining.py:  534]:	loss/total_loss, 7.06714391708374, 2214
[INFO] 2021-07-12 19:16:31,747 [run_pretraining.py:  535]:	loss/mlm_loss, 7.06714391708374, 2214
[INFO] 2021-07-12 19:16:31,747 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.212999970652163e-05, 2214
[INFO] 2021-07-12 19:16:31,747 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2214
[INFO] 2021-07-12 19:16:31,747 [run_pretraining.py:  558]:	worker_index: 3, step: 2214, cost: 7.067144, mlm loss: 7.067144, speed: 1.100872 steps/s, speed: 8.806979 samples/s, speed: 4509.173320 tokens/s, learning rate: 2.213e-05, loss_scalings: 3518.437988, pp_loss: 7.193763
[INFO] 2021-07-12 19:16:31,747 [run_pretraining.py:  512]:	********exe.run_2214******* 
[INFO] 2021-07-12 19:16:32,654 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:32,655 [run_pretraining.py:  534]:	loss/total_loss, 7.041164398193359, 2215
[INFO] 2021-07-12 19:16:32,655 [run_pretraining.py:  535]:	loss/mlm_loss, 7.041164398193359, 2215
[INFO] 2021-07-12 19:16:32,655 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2139998691272922e-05, 2215
[INFO] 2021-07-12 19:16:32,655 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2215
[INFO] 2021-07-12 19:16:32,655 [run_pretraining.py:  558]:	worker_index: 3, step: 2215, cost: 7.041164, mlm loss: 7.041164, speed: 1.101614 steps/s, speed: 8.812912 samples/s, speed: 4512.211083 tokens/s, learning rate: 2.214e-05, loss_scalings: 2814.750488, pp_loss: 7.369795
[INFO] 2021-07-12 19:16:32,655 [run_pretraining.py:  512]:	********exe.run_2215******* 
[INFO] 2021-07-12 19:16:33,572 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:33,573 [run_pretraining.py:  534]:	loss/total_loss, 7.78355598449707, 2216
[INFO] 2021-07-12 19:16:33,573 [run_pretraining.py:  535]:	loss/mlm_loss, 7.78355598449707, 2216
[INFO] 2021-07-12 19:16:33,573 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2149999495013617e-05, 2216
[INFO] 2021-07-12 19:16:33,573 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2216
[INFO] 2021-07-12 19:16:33,573 [run_pretraining.py:  558]:	worker_index: 3, step: 2216, cost: 7.783556, mlm loss: 7.783556, speed: 1.090661 steps/s, speed: 8.725291 samples/s, speed: 4467.348888 tokens/s, learning rate: 2.215e-05, loss_scalings: 2814.750488, pp_loss: 7.628170
[INFO] 2021-07-12 19:16:33,573 [run_pretraining.py:  512]:	********exe.run_2216******* 
[INFO] 2021-07-12 19:16:34,488 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:34,489 [run_pretraining.py:  534]:	loss/total_loss, 7.32572078704834, 2217
[INFO] 2021-07-12 19:16:34,489 [run_pretraining.py:  535]:	loss/mlm_loss, 7.32572078704834, 2217
[INFO] 2021-07-12 19:16:34,489 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.215999847976491e-05, 2217
[INFO] 2021-07-12 19:16:34,489 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2217
[INFO] 2021-07-12 19:16:34,489 [run_pretraining.py:  558]:	worker_index: 3, step: 2217, cost: 7.325721, mlm loss: 7.325721, speed: 1.092278 steps/s, speed: 8.738227 samples/s, speed: 4473.972036 tokens/s, learning rate: 2.216e-05, loss_scalings: 2814.750488, pp_loss: 7.718163
[INFO] 2021-07-12 19:16:34,489 [run_pretraining.py:  512]:	********exe.run_2217******* 
[INFO] 2021-07-12 19:16:35,403 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:35,403 [run_pretraining.py:  534]:	loss/total_loss, 7.384538650512695, 2218
[INFO] 2021-07-12 19:16:35,404 [run_pretraining.py:  535]:	loss/mlm_loss, 7.384538650512695, 2218
[INFO] 2021-07-12 19:16:35,404 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2169999283505604e-05, 2218
[INFO] 2021-07-12 19:16:35,404 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2218
[INFO] 2021-07-12 19:16:35,404 [run_pretraining.py:  558]:	worker_index: 3, step: 2218, cost: 7.384539, mlm loss: 7.384539, speed: 1.093922 steps/s, speed: 8.751372 samples/s, speed: 4480.702496 tokens/s, learning rate: 2.217e-05, loss_scalings: 2814.750488, pp_loss: 7.198796
[INFO] 2021-07-12 19:16:35,404 [run_pretraining.py:  512]:	********exe.run_2218******* 
[INFO] 2021-07-12 19:16:36,311 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:36,312 [run_pretraining.py:  534]:	loss/total_loss, 7.371778964996338, 2219
[INFO] 2021-07-12 19:16:36,312 [run_pretraining.py:  535]:	loss/mlm_loss, 7.371778964996338, 2219
[INFO] 2021-07-12 19:16:36,312 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.21800000872463e-05, 2219
[INFO] 2021-07-12 19:16:36,312 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2219
[INFO] 2021-07-12 19:16:36,312 [run_pretraining.py:  558]:	worker_index: 3, step: 2219, cost: 7.371779, mlm loss: 7.371779, speed: 1.101771 steps/s, speed: 8.814167 samples/s, speed: 4512.853504 tokens/s, learning rate: 2.218e-05, loss_scalings: 2814.750488, pp_loss: 7.099911
[INFO] 2021-07-12 19:16:36,312 [run_pretraining.py:  512]:	********exe.run_2219******* 
[INFO] 2021-07-12 19:16:37,229 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:37,229 [run_pretraining.py:  534]:	loss/total_loss, 7.285255432128906, 2220
[INFO] 2021-07-12 19:16:37,229 [run_pretraining.py:  535]:	loss/mlm_loss, 7.285255432128906, 2220
[INFO] 2021-07-12 19:16:37,229 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.218999907199759e-05, 2220
[INFO] 2021-07-12 19:16:37,229 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2220
[INFO] 2021-07-12 19:16:37,229 [run_pretraining.py:  558]:	worker_index: 3, step: 2220, cost: 7.285255, mlm loss: 7.285255, speed: 1.090890 steps/s, speed: 8.727120 samples/s, speed: 4468.285384 tokens/s, learning rate: 2.219e-05, loss_scalings: 2814.750488, pp_loss: 7.266222
[INFO] 2021-07-12 19:16:37,229 [run_pretraining.py:  512]:	********exe.run_2220******* 
[INFO] 2021-07-12 19:16:38,143 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:38,143 [run_pretraining.py:  534]:	loss/total_loss, 7.032042026519775, 2221
[INFO] 2021-07-12 19:16:38,143 [run_pretraining.py:  535]:	loss/mlm_loss, 7.032042026519775, 2221
[INFO] 2021-07-12 19:16:38,144 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2199999875738285e-05, 2221
[INFO] 2021-07-12 19:16:38,144 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2221
[INFO] 2021-07-12 19:16:38,144 [run_pretraining.py:  558]:	worker_index: 3, step: 2221, cost: 7.032042, mlm loss: 7.032042, speed: 1.094464 steps/s, speed: 8.755709 samples/s, speed: 4482.922800 tokens/s, learning rate: 2.220e-05, loss_scalings: 2814.750488, pp_loss: 7.087525
[INFO] 2021-07-12 19:16:38,144 [run_pretraining.py:  512]:	********exe.run_2221******* 
[INFO] 2021-07-12 19:16:39,057 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:39,058 [run_pretraining.py:  534]:	loss/total_loss, 7.225586414337158, 2222
[INFO] 2021-07-12 19:16:39,058 [run_pretraining.py:  535]:	loss/mlm_loss, 7.225586414337158, 2222
[INFO] 2021-07-12 19:16:39,058 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.221000067947898e-05, 2222
[INFO] 2021-07-12 19:16:39,058 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2222
[INFO] 2021-07-12 19:16:39,058 [run_pretraining.py:  558]:	worker_index: 3, step: 2222, cost: 7.225586, mlm loss: 7.225586, speed: 1.094377 steps/s, speed: 8.755019 samples/s, speed: 4482.569556 tokens/s, learning rate: 2.221e-05, loss_scalings: 2814.750488, pp_loss: 7.358311
[INFO] 2021-07-12 19:16:39,058 [run_pretraining.py:  512]:	********exe.run_2222******* 
[INFO] 2021-07-12 19:16:39,972 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:39,972 [run_pretraining.py:  534]:	loss/total_loss, 7.026725769042969, 2223
[INFO] 2021-07-12 19:16:39,972 [run_pretraining.py:  535]:	loss/mlm_loss, 7.026725769042969, 2223
[INFO] 2021-07-12 19:16:39,972 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2219999664230272e-05, 2223
[INFO] 2021-07-12 19:16:39,972 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2223
[INFO] 2021-07-12 19:16:39,973 [run_pretraining.py:  558]:	worker_index: 3, step: 2223, cost: 7.026726, mlm loss: 7.026726, speed: 1.094390 steps/s, speed: 8.755119 samples/s, speed: 4482.621018 tokens/s, learning rate: 2.222e-05, loss_scalings: 2814.750488, pp_loss: 7.188758
[INFO] 2021-07-12 19:16:39,973 [run_pretraining.py:  512]:	********exe.run_2223******* 
[INFO] 2021-07-12 19:16:40,884 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:40,885 [run_pretraining.py:  534]:	loss/total_loss, 7.727176666259766, 2224
[INFO] 2021-07-12 19:16:40,885 [run_pretraining.py:  535]:	loss/mlm_loss, 7.727176666259766, 2224
[INFO] 2021-07-12 19:16:40,885 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2229998648981564e-05, 2224
[INFO] 2021-07-12 19:16:40,885 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2224
[INFO] 2021-07-12 19:16:40,885 [run_pretraining.py:  558]:	worker_index: 3, step: 2224, cost: 7.727177, mlm loss: 7.727177, speed: 1.096802 steps/s, speed: 8.774419 samples/s, speed: 4492.502637 tokens/s, learning rate: 2.223e-05, loss_scalings: 2814.750488, pp_loss: 7.583242
[INFO] 2021-07-12 19:16:40,885 [run_pretraining.py:  512]:	********exe.run_2224******* 
[INFO] 2021-07-12 19:16:41,793 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:41,793 [run_pretraining.py:  534]:	loss/total_loss, 5.9247517585754395, 2225
[INFO] 2021-07-12 19:16:41,794 [run_pretraining.py:  535]:	loss/mlm_loss, 5.9247517585754395, 2225
[INFO] 2021-07-12 19:16:41,794 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.223999945272226e-05, 2225
[INFO] 2021-07-12 19:16:41,794 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2225
[INFO] 2021-07-12 19:16:41,794 [run_pretraining.py:  558]:	worker_index: 3, step: 2225, cost: 5.924752, mlm loss: 5.924752, speed: 1.101077 steps/s, speed: 8.808614 samples/s, speed: 4510.010221 tokens/s, learning rate: 2.224e-05, loss_scalings: 2814.750488, pp_loss: 7.120514
[INFO] 2021-07-12 19:16:41,794 [run_pretraining.py:  512]:	********exe.run_2225******* 
[INFO] 2021-07-12 19:16:42,709 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:42,709 [run_pretraining.py:  534]:	loss/total_loss, 6.419506549835205, 2226
[INFO] 2021-07-12 19:16:42,709 [run_pretraining.py:  535]:	loss/mlm_loss, 6.419506549835205, 2226
[INFO] 2021-07-12 19:16:42,709 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.224999843747355e-05, 2226
[INFO] 2021-07-12 19:16:42,710 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2226
[INFO] 2021-07-12 19:16:42,710 [run_pretraining.py:  558]:	worker_index: 3, step: 2226, cost: 6.419507, mlm loss: 6.419507, speed: 1.092684 steps/s, speed: 8.741471 samples/s, speed: 4475.632933 tokens/s, learning rate: 2.225e-05, loss_scalings: 2814.750488, pp_loss: 6.832622
[INFO] 2021-07-12 19:16:42,710 [run_pretraining.py:  512]:	********exe.run_2226******* 
[INFO] 2021-07-12 19:16:43,628 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:43,628 [run_pretraining.py:  534]:	loss/total_loss, 6.887897968292236, 2227
[INFO] 2021-07-12 19:16:43,628 [run_pretraining.py:  535]:	loss/mlm_loss, 6.887897968292236, 2227
[INFO] 2021-07-12 19:16:43,628 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2259999241214246e-05, 2227
[INFO] 2021-07-12 19:16:43,629 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2227
[INFO] 2021-07-12 19:16:43,629 [run_pretraining.py:  558]:	worker_index: 3, step: 2227, cost: 6.887898, mlm loss: 6.887898, speed: 1.088911 steps/s, speed: 8.711289 samples/s, speed: 4460.180175 tokens/s, learning rate: 2.226e-05, loss_scalings: 2814.750488, pp_loss: 7.027679
[INFO] 2021-07-12 19:16:43,629 [run_pretraining.py:  512]:	********exe.run_2227******* 
[INFO] 2021-07-12 19:16:44,546 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:44,547 [run_pretraining.py:  534]:	loss/total_loss, 7.254761695861816, 2228
[INFO] 2021-07-12 19:16:44,547 [run_pretraining.py:  535]:	loss/mlm_loss, 7.254761695861816, 2228
[INFO] 2021-07-12 19:16:44,547 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.227000004495494e-05, 2228
[INFO] 2021-07-12 19:16:44,547 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2228
[INFO] 2021-07-12 19:16:44,547 [run_pretraining.py:  558]:	worker_index: 3, step: 2228, cost: 7.254762, mlm loss: 7.254762, speed: 1.089543 steps/s, speed: 8.716340 samples/s, speed: 4462.766189 tokens/s, learning rate: 2.227e-05, loss_scalings: 2814.750488, pp_loss: 7.599565
[INFO] 2021-07-12 19:16:44,547 [run_pretraining.py:  512]:	********exe.run_2228******* 
[INFO] 2021-07-12 19:16:45,463 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:45,463 [run_pretraining.py:  534]:	loss/total_loss, 6.517641544342041, 2229
[INFO] 2021-07-12 19:16:45,463 [run_pretraining.py:  535]:	loss/mlm_loss, 6.517641544342041, 2229
[INFO] 2021-07-12 19:16:45,463 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2279999029706232e-05, 2229
[INFO] 2021-07-12 19:16:45,464 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2229
[INFO] 2021-07-12 19:16:45,464 [run_pretraining.py:  558]:	worker_index: 3, step: 2229, cost: 6.517642, mlm loss: 6.517642, speed: 1.091882 steps/s, speed: 8.735056 samples/s, speed: 4472.348463 tokens/s, learning rate: 2.228e-05, loss_scalings: 2814.750488, pp_loss: 7.018113
[INFO] 2021-07-12 19:16:45,464 [run_pretraining.py:  512]:	********exe.run_2229******* 
[INFO] 2021-07-12 19:16:46,378 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:46,378 [run_pretraining.py:  534]:	loss/total_loss, 7.813490867614746, 2230
[INFO] 2021-07-12 19:16:46,378 [run_pretraining.py:  535]:	loss/mlm_loss, 7.813490867614746, 2230
[INFO] 2021-07-12 19:16:46,378 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2289999833446927e-05, 2230
[INFO] 2021-07-12 19:16:46,378 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2230
[INFO] 2021-07-12 19:16:46,378 [run_pretraining.py:  558]:	worker_index: 3, step: 2230, cost: 7.813491, mlm loss: 7.813491, speed: 1.093834 steps/s, speed: 8.750669 samples/s, speed: 4480.342591 tokens/s, learning rate: 2.229e-05, loss_scalings: 2814.750488, pp_loss: 7.690467
[INFO] 2021-07-12 19:16:46,379 [run_pretraining.py:  512]:	********exe.run_2230******* 
[INFO] 2021-07-12 19:16:47,289 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:47,290 [run_pretraining.py:  534]:	loss/total_loss, 7.601124286651611, 2231
[INFO] 2021-07-12 19:16:47,290 [run_pretraining.py:  535]:	loss/mlm_loss, 7.601124286651611, 2231
[INFO] 2021-07-12 19:16:47,290 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2300000637187622e-05, 2231
[INFO] 2021-07-12 19:16:47,290 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2231
[INFO] 2021-07-12 19:16:47,290 [run_pretraining.py:  558]:	worker_index: 3, step: 2231, cost: 7.601124, mlm loss: 7.601124, speed: 1.097464 steps/s, speed: 8.779709 samples/s, speed: 4495.210964 tokens/s, learning rate: 2.230e-05, loss_scalings: 2814.750488, pp_loss: 7.428148
[INFO] 2021-07-12 19:16:47,290 [run_pretraining.py:  512]:	********exe.run_2231******* 
[INFO] 2021-07-12 19:16:48,207 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:48,207 [run_pretraining.py:  534]:	loss/total_loss, 7.052846431732178, 2232
[INFO] 2021-07-12 19:16:48,208 [run_pretraining.py:  535]:	loss/mlm_loss, 7.052846431732178, 2232
[INFO] 2021-07-12 19:16:48,208 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2309999621938914e-05, 2232
[INFO] 2021-07-12 19:16:48,208 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2232
[INFO] 2021-07-12 19:16:48,208 [run_pretraining.py:  558]:	worker_index: 3, step: 2232, cost: 7.052846, mlm loss: 7.052846, speed: 1.090767 steps/s, speed: 8.726137 samples/s, speed: 4467.782230 tokens/s, learning rate: 2.231e-05, loss_scalings: 2814.750488, pp_loss: 6.864408
[INFO] 2021-07-12 19:16:48,208 [run_pretraining.py:  512]:	********exe.run_2232******* 
[INFO] 2021-07-12 19:16:49,115 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:49,116 [run_pretraining.py:  534]:	loss/total_loss, 7.044814109802246, 2233
[INFO] 2021-07-12 19:16:49,116 [run_pretraining.py:  535]:	loss/mlm_loss, 7.044814109802246, 2233
[INFO] 2021-07-12 19:16:49,116 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2319998606690206e-05, 2233
[INFO] 2021-07-12 19:16:49,116 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2233
[INFO] 2021-07-12 19:16:49,116 [run_pretraining.py:  558]:	worker_index: 3, step: 2233, cost: 7.044814, mlm loss: 7.044814, speed: 1.101460 steps/s, speed: 8.811683 samples/s, speed: 4511.581877 tokens/s, learning rate: 2.232e-05, loss_scalings: 2814.750488, pp_loss: 7.465311
[INFO] 2021-07-12 19:16:49,116 [run_pretraining.py:  512]:	********exe.run_2233******* 
[INFO] 2021-07-12 19:16:50,034 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:50,034 [run_pretraining.py:  534]:	loss/total_loss, 6.947784900665283, 2234
[INFO] 2021-07-12 19:16:50,034 [run_pretraining.py:  535]:	loss/mlm_loss, 6.947784900665283, 2234
[INFO] 2021-07-12 19:16:50,034 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.23299994104309e-05, 2234
[INFO] 2021-07-12 19:16:50,034 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2234
[INFO] 2021-07-12 19:16:50,034 [run_pretraining.py:  558]:	worker_index: 3, step: 2234, cost: 6.947785, mlm loss: 6.947785, speed: 1.089948 steps/s, speed: 8.719584 samples/s, speed: 4464.426896 tokens/s, learning rate: 2.233e-05, loss_scalings: 2814.750488, pp_loss: 7.310357
[INFO] 2021-07-12 19:16:50,035 [run_pretraining.py:  512]:	********exe.run_2234******* 
[INFO] 2021-07-12 19:16:50,957 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:50,958 [run_pretraining.py:  534]:	loss/total_loss, 7.110365867614746, 2235
[INFO] 2021-07-12 19:16:50,958 [run_pretraining.py:  535]:	loss/mlm_loss, 7.110365867614746, 2235
[INFO] 2021-07-12 19:16:50,958 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2339998395182192e-05, 2235
[INFO] 2021-07-12 19:16:50,958 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2235
[INFO] 2021-07-12 19:16:50,958 [run_pretraining.py:  558]:	worker_index: 3, step: 2235, cost: 7.110366, mlm loss: 7.110366, speed: 1.083204 steps/s, speed: 8.665635 samples/s, speed: 4436.805306 tokens/s, learning rate: 2.234e-05, loss_scalings: 2814.750488, pp_loss: 7.385577
[INFO] 2021-07-12 19:16:50,958 [run_pretraining.py:  512]:	********exe.run_2235******* 
[INFO] 2021-07-12 19:16:51,900 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:51,901 [run_pretraining.py:  534]:	loss/total_loss, 6.774722099304199, 2236
[INFO] 2021-07-12 19:16:51,901 [run_pretraining.py:  535]:	loss/mlm_loss, 6.774722099304199, 2236
[INFO] 2021-07-12 19:16:51,901 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2349999198922887e-05, 2236
[INFO] 2021-07-12 19:16:51,901 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2236
[INFO] 2021-07-12 19:16:51,901 [run_pretraining.py:  558]:	worker_index: 3, step: 2236, cost: 6.774722, mlm loss: 6.774722, speed: 1.061562 steps/s, speed: 8.492495 samples/s, speed: 4348.157216 tokens/s, learning rate: 2.235e-05, loss_scalings: 2814.750488, pp_loss: 6.989898
[INFO] 2021-07-12 19:16:51,901 [run_pretraining.py:  512]:	********exe.run_2236******* 
[INFO] 2021-07-12 19:16:52,838 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:52,838 [run_pretraining.py:  534]:	loss/total_loss, 7.111971855163574, 2237
[INFO] 2021-07-12 19:16:52,838 [run_pretraining.py:  535]:	loss/mlm_loss, 7.111971855163574, 2237
[INFO] 2021-07-12 19:16:52,838 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2360000002663583e-05, 2237
[INFO] 2021-07-12 19:16:52,839 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2237
[INFO] 2021-07-12 19:16:52,839 [run_pretraining.py:  558]:	worker_index: 3, step: 2237, cost: 7.111972, mlm loss: 7.111972, speed: 1.067207 steps/s, speed: 8.537654 samples/s, speed: 4371.278897 tokens/s, learning rate: 2.236e-05, loss_scalings: 2814.750488, pp_loss: 6.453744
[INFO] 2021-07-12 19:16:52,839 [run_pretraining.py:  512]:	********exe.run_2237******* 
[INFO] 2021-07-12 19:16:53,760 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:53,761 [run_pretraining.py:  534]:	loss/total_loss, 8.284911155700684, 2238
[INFO] 2021-07-12 19:16:53,761 [run_pretraining.py:  535]:	loss/mlm_loss, 8.284911155700684, 2238
[INFO] 2021-07-12 19:16:53,761 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2369998987414874e-05, 2238
[INFO] 2021-07-12 19:16:53,761 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2238
[INFO] 2021-07-12 19:16:53,761 [run_pretraining.py:  558]:	worker_index: 3, step: 2238, cost: 8.284911, mlm loss: 8.284911, speed: 1.084703 steps/s, speed: 8.677623 samples/s, speed: 4442.942839 tokens/s, learning rate: 2.237e-05, loss_scalings: 2814.750488, pp_loss: 7.491270
[INFO] 2021-07-12 19:16:53,761 [run_pretraining.py:  512]:	********exe.run_2238******* 
[INFO] 2021-07-12 19:16:54,665 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:54,665 [run_pretraining.py:  534]:	loss/total_loss, 6.690613746643066, 2239
[INFO] 2021-07-12 19:16:54,665 [run_pretraining.py:  535]:	loss/mlm_loss, 6.690613746643066, 2239
[INFO] 2021-07-12 19:16:54,665 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.237999979115557e-05, 2239
[INFO] 2021-07-12 19:16:54,665 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2239
[INFO] 2021-07-12 19:16:54,665 [run_pretraining.py:  558]:	worker_index: 3, step: 2239, cost: 6.690614, mlm loss: 6.690614, speed: 1.106616 steps/s, speed: 8.852926 samples/s, speed: 4532.698254 tokens/s, learning rate: 2.238e-05, loss_scalings: 2814.750488, pp_loss: 7.096217
[INFO] 2021-07-12 19:16:54,665 [run_pretraining.py:  512]:	********exe.run_2239******* 
[INFO] 2021-07-12 19:16:55,577 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:55,578 [run_pretraining.py:  534]:	loss/total_loss, 7.128284454345703, 2240
[INFO] 2021-07-12 19:16:55,578 [run_pretraining.py:  535]:	loss/mlm_loss, 7.128284454345703, 2240
[INFO] 2021-07-12 19:16:55,578 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2390000594896264e-05, 2240
[INFO] 2021-07-12 19:16:55,578 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2240
[INFO] 2021-07-12 19:16:55,578 [run_pretraining.py:  558]:	worker_index: 3, step: 2240, cost: 7.128284, mlm loss: 7.128284, speed: 1.096560 steps/s, speed: 8.772481 samples/s, speed: 4491.510166 tokens/s, learning rate: 2.239e-05, loss_scalings: 2814.750488, pp_loss: 7.367630
[INFO] 2021-07-12 19:16:55,578 [run_pretraining.py:  512]:	********exe.run_2240******* 
[INFO] 2021-07-12 19:16:56,486 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:56,487 [run_pretraining.py:  534]:	loss/total_loss, 6.546682357788086, 2241
[INFO] 2021-07-12 19:16:56,487 [run_pretraining.py:  535]:	loss/mlm_loss, 6.546682357788086, 2241
[INFO] 2021-07-12 19:16:56,487 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2399999579647556e-05, 2241
[INFO] 2021-07-12 19:16:56,487 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2241
[INFO] 2021-07-12 19:16:56,487 [run_pretraining.py:  558]:	worker_index: 3, step: 2241, cost: 6.546682, mlm loss: 6.546682, speed: 1.100510 steps/s, speed: 8.804081 samples/s, speed: 4507.689680 tokens/s, learning rate: 2.240e-05, loss_scalings: 2814.750488, pp_loss: 7.353026
[INFO] 2021-07-12 19:16:56,487 [run_pretraining.py:  512]:	********exe.run_2241******* 
[INFO] 2021-07-12 19:16:57,390 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:57,391 [run_pretraining.py:  534]:	loss/total_loss, 7.058640480041504, 2242
[INFO] 2021-07-12 19:16:57,391 [run_pretraining.py:  535]:	loss/mlm_loss, 7.058640480041504, 2242
[INFO] 2021-07-12 19:16:57,391 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2409998564398848e-05, 2242
[INFO] 2021-07-12 19:16:57,391 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2242
[INFO] 2021-07-12 19:16:57,391 [run_pretraining.py:  558]:	worker_index: 3, step: 2242, cost: 7.058640, mlm loss: 7.058640, speed: 1.107333 steps/s, speed: 8.858662 samples/s, speed: 4535.634887 tokens/s, learning rate: 2.241e-05, loss_scalings: 2814.750488, pp_loss: 7.344313
[INFO] 2021-07-12 19:16:57,391 [run_pretraining.py:  512]:	********exe.run_2242******* 
[INFO] 2021-07-12 19:16:58,304 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:58,304 [run_pretraining.py:  534]:	loss/total_loss, 7.158290863037109, 2243
[INFO] 2021-07-12 19:16:58,305 [run_pretraining.py:  535]:	loss/mlm_loss, 7.158290863037109, 2243
[INFO] 2021-07-12 19:16:58,305 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2419999368139543e-05, 2243
[INFO] 2021-07-12 19:16:58,305 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2243
[INFO] 2021-07-12 19:16:58,305 [run_pretraining.py:  558]:	worker_index: 3, step: 2243, cost: 7.158291, mlm loss: 7.158291, speed: 1.095165 steps/s, speed: 8.761321 samples/s, speed: 4485.796441 tokens/s, learning rate: 2.242e-05, loss_scalings: 2814.750488, pp_loss: 7.231682
[INFO] 2021-07-12 19:16:58,305 [run_pretraining.py:  512]:	********exe.run_2243******* 
[INFO] 2021-07-12 19:16:59,211 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:59,211 [run_pretraining.py:  534]:	loss/total_loss, 4.440779685974121, 2244
[INFO] 2021-07-12 19:16:59,211 [run_pretraining.py:  535]:	loss/mlm_loss, 4.440779685974121, 2244
[INFO] 2021-07-12 19:16:59,211 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2429998352890834e-05, 2244
[INFO] 2021-07-12 19:16:59,212 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2244
[INFO] 2021-07-12 19:16:59,212 [run_pretraining.py:  558]:	worker_index: 3, step: 2244, cost: 4.440780, mlm loss: 4.440780, speed: 1.103512 steps/s, speed: 8.828093 samples/s, speed: 4519.983368 tokens/s, learning rate: 2.243e-05, loss_scalings: 2814.750488, pp_loss: 6.597161
[INFO] 2021-07-12 19:16:59,212 [run_pretraining.py:  512]:	********exe.run_2244******* 
[INFO] 2021-07-12 19:17:00,109 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:00,109 [run_pretraining.py:  534]:	loss/total_loss, 7.618928909301758, 2245
[INFO] 2021-07-12 19:17:00,109 [run_pretraining.py:  535]:	loss/mlm_loss, 7.618928909301758, 2245
[INFO] 2021-07-12 19:17:00,109 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.243999915663153e-05, 2245
[INFO] 2021-07-12 19:17:00,109 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2245
[INFO] 2021-07-12 19:17:00,110 [run_pretraining.py:  558]:	worker_index: 3, step: 2245, cost: 7.618929, mlm loss: 7.618929, speed: 1.114470 steps/s, speed: 8.915759 samples/s, speed: 4564.868574 tokens/s, learning rate: 2.244e-05, loss_scalings: 2814.750488, pp_loss: 7.268975
[INFO] 2021-07-12 19:17:00,110 [run_pretraining.py:  512]:	********exe.run_2245******* 
[INFO] 2021-07-12 19:17:01,013 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:01,013 [run_pretraining.py:  534]:	loss/total_loss, 7.432612419128418, 2246
[INFO] 2021-07-12 19:17:01,013 [run_pretraining.py:  535]:	loss/mlm_loss, 7.432612419128418, 2246
[INFO] 2021-07-12 19:17:01,013 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2449999960372224e-05, 2246
[INFO] 2021-07-12 19:17:01,014 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2246
[INFO] 2021-07-12 19:17:01,014 [run_pretraining.py:  558]:	worker_index: 3, step: 2246, cost: 7.432612, mlm loss: 7.432612, speed: 1.106835 steps/s, speed: 8.854676 samples/s, speed: 4533.594158 tokens/s, learning rate: 2.245e-05, loss_scalings: 2814.750488, pp_loss: 7.602066
[INFO] 2021-07-12 19:17:01,014 [run_pretraining.py:  512]:	********exe.run_2246******* 
[INFO] 2021-07-12 19:17:01,923 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:01,924 [run_pretraining.py:  534]:	loss/total_loss, 3.246854782104492, 2247
[INFO] 2021-07-12 19:17:01,924 [run_pretraining.py:  535]:	loss/mlm_loss, 3.246854782104492, 2247
[INFO] 2021-07-12 19:17:01,924 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2459998945123516e-05, 2247
[INFO] 2021-07-12 19:17:01,924 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2247
[INFO] 2021-07-12 19:17:01,924 [run_pretraining.py:  558]:	worker_index: 3, step: 2247, cost: 3.246855, mlm loss: 3.246855, speed: 1.098975 steps/s, speed: 8.791802 samples/s, speed: 4501.402752 tokens/s, learning rate: 2.246e-05, loss_scalings: 2814.750488, pp_loss: 6.060962
[INFO] 2021-07-12 19:17:01,924 [run_pretraining.py:  512]:	********exe.run_2247******* 
[INFO] 2021-07-12 19:17:02,833 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:02,834 [run_pretraining.py:  534]:	loss/total_loss, 6.907902717590332, 2248
[INFO] 2021-07-12 19:17:02,834 [run_pretraining.py:  535]:	loss/mlm_loss, 6.907902717590332, 2248
[INFO] 2021-07-12 19:17:02,834 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.246999974886421e-05, 2248
[INFO] 2021-07-12 19:17:02,834 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2248
[INFO] 2021-07-12 19:17:02,834 [run_pretraining.py:  558]:	worker_index: 3, step: 2248, cost: 6.907903, mlm loss: 6.907903, speed: 1.099940 steps/s, speed: 8.799524 samples/s, speed: 4505.356166 tokens/s, learning rate: 2.247e-05, loss_scalings: 2814.750488, pp_loss: 7.066469
[INFO] 2021-07-12 19:17:02,834 [run_pretraining.py:  512]:	********exe.run_2248******* 
[INFO] 2021-07-12 19:17:03,743 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:03,743 [run_pretraining.py:  534]:	loss/total_loss, 8.173344612121582, 2249
[INFO] 2021-07-12 19:17:03,743 [run_pretraining.py:  535]:	loss/mlm_loss, 8.173344612121582, 2249
[INFO] 2021-07-12 19:17:03,743 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2480000552604906e-05, 2249
[INFO] 2021-07-12 19:17:03,744 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2249
[INFO] 2021-07-12 19:17:03,744 [run_pretraining.py:  558]:	worker_index: 3, step: 2249, cost: 8.173345, mlm loss: 8.173345, speed: 1.100094 steps/s, speed: 8.800749 samples/s, speed: 4505.983636 tokens/s, learning rate: 2.248e-05, loss_scalings: 2814.750488, pp_loss: 7.406497
[INFO] 2021-07-12 19:17:03,744 [run_pretraining.py:  512]:	********exe.run_2249******* 
[INFO] 2021-07-12 19:17:04,648 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:04,648 [run_pretraining.py:  534]:	loss/total_loss, 7.178468227386475, 2250
[INFO] 2021-07-12 19:17:04,648 [run_pretraining.py:  535]:	loss/mlm_loss, 7.178468227386475, 2250
[INFO] 2021-07-12 19:17:04,648 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2489999537356198e-05, 2250
[INFO] 2021-07-12 19:17:04,648 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2250
[INFO] 2021-07-12 19:17:04,649 [run_pretraining.py:  558]:	worker_index: 3, step: 2250, cost: 7.178468, mlm loss: 7.178468, speed: 1.105842 steps/s, speed: 8.846739 samples/s, speed: 4529.530147 tokens/s, learning rate: 2.249e-05, loss_scalings: 2814.750488, pp_loss: 7.437427
[INFO] 2021-07-12 19:17:04,649 [run_pretraining.py:  512]:	********exe.run_2250******* 
[INFO] 2021-07-12 19:17:05,559 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:05,559 [run_pretraining.py:  534]:	loss/total_loss, 7.867164134979248, 2251
[INFO] 2021-07-12 19:17:05,559 [run_pretraining.py:  535]:	loss/mlm_loss, 7.867164134979248, 2251
[INFO] 2021-07-12 19:17:05,560 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.249999852210749e-05, 2251
[INFO] 2021-07-12 19:17:05,560 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2251
[INFO] 2021-07-12 19:17:05,560 [run_pretraining.py:  558]:	worker_index: 3, step: 2251, cost: 7.867164, mlm loss: 7.867164, speed: 1.098279 steps/s, speed: 8.786229 samples/s, speed: 4498.549137 tokens/s, learning rate: 2.250e-05, loss_scalings: 2814.750488, pp_loss: 7.506067
[INFO] 2021-07-12 19:17:05,560 [run_pretraining.py:  512]:	********exe.run_2251******* 
[INFO] 2021-07-12 19:17:06,465 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:06,466 [run_pretraining.py:  534]:	loss/total_loss, 7.313969135284424, 2252
[INFO] 2021-07-12 19:17:06,466 [run_pretraining.py:  535]:	loss/mlm_loss, 7.313969135284424, 2252
[INFO] 2021-07-12 19:17:06,466 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2509999325848185e-05, 2252
[INFO] 2021-07-12 19:17:06,466 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2252
[INFO] 2021-07-12 19:17:06,466 [run_pretraining.py:  558]:	worker_index: 3, step: 2252, cost: 7.313969, mlm loss: 7.313969, speed: 1.104173 steps/s, speed: 8.833384 samples/s, speed: 4522.692793 tokens/s, learning rate: 2.251e-05, loss_scalings: 2814.750488, pp_loss: 7.327120
[INFO] 2021-07-12 19:17:06,466 [run_pretraining.py:  512]:	********exe.run_2252******* 
[INFO] 2021-07-12 19:17:07,365 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:07,366 [run_pretraining.py:  534]:	loss/total_loss, 7.451521873474121, 2253
[INFO] 2021-07-12 19:17:07,366 [run_pretraining.py:  535]:	loss/mlm_loss, 7.451521873474121, 2253
[INFO] 2021-07-12 19:17:07,366 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2519998310599476e-05, 2253
[INFO] 2021-07-12 19:17:07,366 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2253
[INFO] 2021-07-12 19:17:07,366 [run_pretraining.py:  558]:	worker_index: 3, step: 2253, cost: 7.451522, mlm loss: 7.451522, speed: 1.111644 steps/s, speed: 8.893154 samples/s, speed: 4553.295077 tokens/s, learning rate: 2.252e-05, loss_scalings: 2814.750488, pp_loss: 7.305263
[INFO] 2021-07-12 19:17:07,366 [run_pretraining.py:  512]:	********exe.run_2253******* 
[INFO] 2021-07-12 19:17:08,282 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:08,283 [run_pretraining.py:  534]:	loss/total_loss, 7.016737461090088, 2254
[INFO] 2021-07-12 19:17:08,283 [run_pretraining.py:  535]:	loss/mlm_loss, 7.016737461090088, 2254
[INFO] 2021-07-12 19:17:08,283 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.252999911434017e-05, 2254
[INFO] 2021-07-12 19:17:08,283 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2254
[INFO] 2021-07-12 19:17:08,283 [run_pretraining.py:  558]:	worker_index: 3, step: 2254, cost: 7.016737, mlm loss: 7.016737, speed: 1.091314 steps/s, speed: 8.730515 samples/s, speed: 4470.023473 tokens/s, learning rate: 2.253e-05, loss_scalings: 2814.750488, pp_loss: 6.336683
[INFO] 2021-07-12 19:17:08,283 [run_pretraining.py:  512]:	********exe.run_2254******* 
[INFO] 2021-07-12 19:17:09,234 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:09,235 [run_pretraining.py:  534]:	loss/total_loss, 7.489348888397217, 2255
[INFO] 2021-07-12 19:17:09,235 [run_pretraining.py:  535]:	loss/mlm_loss, 7.489348888397217, 2255
[INFO] 2021-07-12 19:17:09,235 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2539999918080866e-05, 2255
[INFO] 2021-07-12 19:17:09,235 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2255
[INFO] 2021-07-12 19:17:09,235 [run_pretraining.py:  558]:	worker_index: 3, step: 2255, cost: 7.489349, mlm loss: 7.489349, speed: 1.051389 steps/s, speed: 8.411112 samples/s, speed: 4306.489308 tokens/s, learning rate: 2.254e-05, loss_scalings: 2814.750488, pp_loss: 7.266555
[INFO] 2021-07-12 19:17:09,235 [run_pretraining.py:  512]:	********exe.run_2255******* 
[INFO] 2021-07-12 19:17:10,176 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:10,177 [run_pretraining.py:  534]:	loss/total_loss, 8.017498016357422, 2256
[INFO] 2021-07-12 19:17:10,177 [run_pretraining.py:  535]:	loss/mlm_loss, 8.017498016357422, 2256
[INFO] 2021-07-12 19:17:10,177 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2549998902832158e-05, 2256
[INFO] 2021-07-12 19:17:10,177 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2256
[INFO] 2021-07-12 19:17:10,177 [run_pretraining.py:  558]:	worker_index: 3, step: 2256, cost: 8.017498, mlm loss: 8.017498, speed: 1.061932 steps/s, speed: 8.495460 samples/s, speed: 4349.675338 tokens/s, learning rate: 2.255e-05, loss_scalings: 2814.750488, pp_loss: 7.501425
[INFO] 2021-07-12 19:17:10,177 [run_pretraining.py:  512]:	********exe.run_2256******* 
[INFO] 2021-07-12 19:17:11,089 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:11,089 [run_pretraining.py:  534]:	loss/total_loss, 7.880787372589111, 2257
[INFO] 2021-07-12 19:17:11,089 [run_pretraining.py:  535]:	loss/mlm_loss, 7.880787372589111, 2257
[INFO] 2021-07-12 19:17:11,090 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2559999706572853e-05, 2257
[INFO] 2021-07-12 19:17:11,090 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2257
[INFO] 2021-07-12 19:17:11,090 [run_pretraining.py:  558]:	worker_index: 3, step: 2257, cost: 7.880787, mlm loss: 7.880787, speed: 1.096687 steps/s, speed: 8.773495 samples/s, speed: 4492.029250 tokens/s, learning rate: 2.256e-05, loss_scalings: 2814.750488, pp_loss: 7.553327
[INFO] 2021-07-12 19:17:11,090 [run_pretraining.py:  512]:	********exe.run_2257******* 
[INFO] 2021-07-12 19:17:12,001 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:12,002 [run_pretraining.py:  534]:	loss/total_loss, 7.076686382293701, 2258
[INFO] 2021-07-12 19:17:12,002 [run_pretraining.py:  535]:	loss/mlm_loss, 7.076686382293701, 2258
[INFO] 2021-07-12 19:17:12,002 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2570000510313548e-05, 2258
[INFO] 2021-07-12 19:17:12,002 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2258
[INFO] 2021-07-12 19:17:12,002 [run_pretraining.py:  558]:	worker_index: 3, step: 2258, cost: 7.076686, mlm loss: 7.076686, speed: 1.096461 steps/s, speed: 8.771690 samples/s, speed: 4491.105083 tokens/s, learning rate: 2.257e-05, loss_scalings: 2814.750488, pp_loss: 7.356743
[INFO] 2021-07-12 19:17:12,002 [run_pretraining.py:  512]:	********exe.run_2258******* 
[INFO] 2021-07-12 19:17:12,913 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:12,913 [run_pretraining.py:  534]:	loss/total_loss, 7.099220275878906, 2259
[INFO] 2021-07-12 19:17:12,913 [run_pretraining.py:  535]:	loss/mlm_loss, 7.099220275878906, 2259
[INFO] 2021-07-12 19:17:12,913 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.257999949506484e-05, 2259
[INFO] 2021-07-12 19:17:12,914 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2259
[INFO] 2021-07-12 19:17:12,914 [run_pretraining.py:  558]:	worker_index: 3, step: 2259, cost: 7.099220, mlm loss: 7.099220, speed: 1.098175 steps/s, speed: 8.785396 samples/s, speed: 4498.122761 tokens/s, learning rate: 2.258e-05, loss_scalings: 2814.750488, pp_loss: 7.301051
[INFO] 2021-07-12 19:17:12,914 [run_pretraining.py:  512]:	********exe.run_2259******* 
[INFO] 2021-07-12 19:17:13,826 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:13,826 [run_pretraining.py:  534]:	loss/total_loss, 6.933773040771484, 2260
[INFO] 2021-07-12 19:17:13,826 [run_pretraining.py:  535]:	loss/mlm_loss, 6.933773040771484, 2260
[INFO] 2021-07-12 19:17:13,827 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.258999847981613e-05, 2260
[INFO] 2021-07-12 19:17:13,827 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2260
[INFO] 2021-07-12 19:17:13,827 [run_pretraining.py:  558]:	worker_index: 3, step: 2260, cost: 6.933773, mlm loss: 6.933773, speed: 1.095928 steps/s, speed: 8.767422 samples/s, speed: 4488.920065 tokens/s, learning rate: 2.259e-05, loss_scalings: 2814.750488, pp_loss: 7.419636
[INFO] 2021-07-12 19:17:13,827 [run_pretraining.py:  512]:	********exe.run_2260******* 
[INFO] 2021-07-12 19:17:14,732 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:14,733 [run_pretraining.py:  534]:	loss/total_loss, 7.337950229644775, 2261
[INFO] 2021-07-12 19:17:14,733 [run_pretraining.py:  535]:	loss/mlm_loss, 7.337950229644775, 2261
[INFO] 2021-07-12 19:17:14,733 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2599999283556826e-05, 2261
[INFO] 2021-07-12 19:17:14,733 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2261
[INFO] 2021-07-12 19:17:14,733 [run_pretraining.py:  558]:	worker_index: 3, step: 2261, cost: 7.337950, mlm loss: 7.337950, speed: 1.104066 steps/s, speed: 8.832529 samples/s, speed: 4522.254686 tokens/s, learning rate: 2.260e-05, loss_scalings: 2814.750488, pp_loss: 7.310796
[INFO] 2021-07-12 19:17:14,733 [run_pretraining.py:  512]:	********exe.run_2261******* 
[INFO] 2021-07-12 19:17:15,645 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:15,646 [run_pretraining.py:  534]:	loss/total_loss, 7.047226905822754, 2262
[INFO] 2021-07-12 19:17:15,646 [run_pretraining.py:  535]:	loss/mlm_loss, 7.047226905822754, 2262
[INFO] 2021-07-12 19:17:15,646 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.261000008729752e-05, 2262
[INFO] 2021-07-12 19:17:15,646 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2262
[INFO] 2021-07-12 19:17:15,646 [run_pretraining.py:  558]:	worker_index: 3, step: 2262, cost: 7.047227, mlm loss: 7.047227, speed: 1.096014 steps/s, speed: 8.768109 samples/s, speed: 4489.271965 tokens/s, learning rate: 2.261e-05, loss_scalings: 2814.750488, pp_loss: 7.055331
[INFO] 2021-07-12 19:17:15,646 [run_pretraining.py:  512]:	********exe.run_2262******* 
[INFO] 2021-07-12 19:17:16,562 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:16,563 [run_pretraining.py:  534]:	loss/total_loss, 7.0755510330200195, 2263
[INFO] 2021-07-12 19:17:16,563 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0755510330200195, 2263
[INFO] 2021-07-12 19:17:16,563 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2619999072048813e-05, 2263
[INFO] 2021-07-12 19:17:16,563 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2263
[INFO] 2021-07-12 19:17:16,563 [run_pretraining.py:  558]:	worker_index: 3, step: 2263, cost: 7.075551, mlm loss: 7.075551, speed: 1.091149 steps/s, speed: 8.729193 samples/s, speed: 4469.346678 tokens/s, learning rate: 2.262e-05, loss_scalings: 2814.750488, pp_loss: 6.284343
[INFO] 2021-07-12 19:17:16,563 [run_pretraining.py:  512]:	********exe.run_2263******* 
[INFO] 2021-07-12 19:17:17,484 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:17,485 [run_pretraining.py:  534]:	loss/total_loss, 7.74564790725708, 2264
[INFO] 2021-07-12 19:17:17,486 [run_pretraining.py:  535]:	loss/mlm_loss, 7.74564790725708, 2264
[INFO] 2021-07-12 19:17:17,487 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2629999875789508e-05, 2264
[INFO] 2021-07-12 19:17:17,491 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2264
[INFO] 2021-07-12 19:17:17,492 [run_pretraining.py:  558]:	worker_index: 3, step: 2264, cost: 7.745648, mlm loss: 7.745648, speed: 1.084804 steps/s, speed: 8.678428 samples/s, speed: 4443.355370 tokens/s, learning rate: 2.263e-05, loss_scalings: 2814.750488, pp_loss: 7.577470
[INFO] 2021-07-12 19:17:17,493 [run_pretraining.py:  512]:	********exe.run_2264******* 
[INFO] 2021-07-12 19:17:18,408 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:18,408 [run_pretraining.py:  534]:	loss/total_loss, 7.709127902984619, 2265
[INFO] 2021-07-12 19:17:18,408 [run_pretraining.py:  535]:	loss/mlm_loss, 7.709127902984619, 2265
[INFO] 2021-07-12 19:17:18,408 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.26399988605408e-05, 2265
[INFO] 2021-07-12 19:17:18,409 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2265
[INFO] 2021-07-12 19:17:18,409 [run_pretraining.py:  558]:	worker_index: 3, step: 2265, cost: 7.709128, mlm loss: 7.709128, speed: 1.093228 steps/s, speed: 8.745827 samples/s, speed: 4477.863387 tokens/s, learning rate: 2.264e-05, loss_scalings: 2814.750488, pp_loss: 7.915173
[INFO] 2021-07-12 19:17:18,409 [run_pretraining.py:  512]:	********exe.run_2265******* 
[INFO] 2021-07-12 19:17:19,316 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:19,316 [run_pretraining.py:  534]:	loss/total_loss, 7.353111267089844, 2266
[INFO] 2021-07-12 19:17:19,316 [run_pretraining.py:  535]:	loss/mlm_loss, 7.353111267089844, 2266
[INFO] 2021-07-12 19:17:19,316 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2649999664281495e-05, 2266
[INFO] 2021-07-12 19:17:19,316 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2266
[INFO] 2021-07-12 19:17:19,317 [run_pretraining.py:  558]:	worker_index: 3, step: 2266, cost: 7.353111, mlm loss: 7.353111, speed: 1.102142 steps/s, speed: 8.817134 samples/s, speed: 4514.372575 tokens/s, learning rate: 2.265e-05, loss_scalings: 2814.750488, pp_loss: 6.250320
[INFO] 2021-07-12 19:17:19,317 [run_pretraining.py:  512]:	********exe.run_2266******* 
[INFO] 2021-07-12 19:17:20,228 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:20,228 [run_pretraining.py:  534]:	loss/total_loss, 7.400104522705078, 2267
[INFO] 2021-07-12 19:17:20,228 [run_pretraining.py:  535]:	loss/mlm_loss, 7.400104522705078, 2267
[INFO] 2021-07-12 19:17:20,228 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.266000046802219e-05, 2267
[INFO] 2021-07-12 19:17:20,228 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2267
[INFO] 2021-07-12 19:17:20,229 [run_pretraining.py:  558]:	worker_index: 3, step: 2267, cost: 7.400105, mlm loss: 7.400105, speed: 1.097323 steps/s, speed: 8.778588 samples/s, speed: 4494.637052 tokens/s, learning rate: 2.266e-05, loss_scalings: 2814.750488, pp_loss: 7.336996
[INFO] 2021-07-12 19:17:20,229 [run_pretraining.py:  512]:	********exe.run_2267******* 
[INFO] 2021-07-12 19:17:21,144 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:21,144 [run_pretraining.py:  534]:	loss/total_loss, 6.965939998626709, 2268
[INFO] 2021-07-12 19:17:21,144 [run_pretraining.py:  535]:	loss/mlm_loss, 6.965939998626709, 2268
[INFO] 2021-07-12 19:17:21,144 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.266999945277348e-05, 2268
[INFO] 2021-07-12 19:17:21,144 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2268
[INFO] 2021-07-12 19:17:21,144 [run_pretraining.py:  558]:	worker_index: 3, step: 2268, cost: 6.965940, mlm loss: 6.965940, speed: 1.092610 steps/s, speed: 8.740881 samples/s, speed: 4475.330966 tokens/s, learning rate: 2.267e-05, loss_scalings: 2814.750488, pp_loss: 7.014814
[INFO] 2021-07-12 19:17:21,144 [run_pretraining.py:  512]:	********exe.run_2268******* 
[INFO] 2021-07-12 19:17:22,057 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:22,058 [run_pretraining.py:  534]:	loss/total_loss, 7.6564130783081055, 2269
[INFO] 2021-07-12 19:17:22,058 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6564130783081055, 2269
[INFO] 2021-07-12 19:17:22,058 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2679998437524773e-05, 2269
[INFO] 2021-07-12 19:17:22,058 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2269
[INFO] 2021-07-12 19:17:22,058 [run_pretraining.py:  558]:	worker_index: 3, step: 2269, cost: 7.656413, mlm loss: 7.656413, speed: 1.095425 steps/s, speed: 8.763403 samples/s, speed: 4486.862555 tokens/s, learning rate: 2.268e-05, loss_scalings: 2814.750488, pp_loss: 7.720785
[INFO] 2021-07-12 19:17:22,058 [run_pretraining.py:  512]:	********exe.run_2269******* 
[INFO] 2021-07-12 19:17:22,968 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:22,969 [run_pretraining.py:  534]:	loss/total_loss, 7.201047420501709, 2270
[INFO] 2021-07-12 19:17:22,969 [run_pretraining.py:  535]:	loss/mlm_loss, 7.201047420501709, 2270
[INFO] 2021-07-12 19:17:22,969 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2689999241265468e-05, 2270
[INFO] 2021-07-12 19:17:22,969 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2270
[INFO] 2021-07-12 19:17:22,969 [run_pretraining.py:  558]:	worker_index: 3, step: 2270, cost: 7.201047, mlm loss: 7.201047, speed: 1.098246 steps/s, speed: 8.785967 samples/s, speed: 4498.414855 tokens/s, learning rate: 2.269e-05, loss_scalings: 2814.750488, pp_loss: 7.069856
[INFO] 2021-07-12 19:17:22,969 [run_pretraining.py:  512]:	********exe.run_2270******* 
[INFO] 2021-07-12 19:17:23,902 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:23,903 [run_pretraining.py:  534]:	loss/total_loss, 7.31724739074707, 2271
[INFO] 2021-07-12 19:17:23,903 [run_pretraining.py:  535]:	loss/mlm_loss, 7.31724739074707, 2271
[INFO] 2021-07-12 19:17:23,903 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2700000045006163e-05, 2271
[INFO] 2021-07-12 19:17:23,903 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2271
[INFO] 2021-07-12 19:17:23,903 [run_pretraining.py:  558]:	worker_index: 3, step: 2271, cost: 7.317247, mlm loss: 7.317247, speed: 1.071280 steps/s, speed: 8.570241 samples/s, speed: 4387.963603 tokens/s, learning rate: 2.270e-05, loss_scalings: 2814.750488, pp_loss: 7.307161
[INFO] 2021-07-12 19:17:23,903 [run_pretraining.py:  512]:	********exe.run_2271******* 
[INFO] 2021-07-12 19:17:24,815 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:24,816 [run_pretraining.py:  534]:	loss/total_loss, 7.402466773986816, 2272
[INFO] 2021-07-12 19:17:24,816 [run_pretraining.py:  535]:	loss/mlm_loss, 7.402466773986816, 2272
[INFO] 2021-07-12 19:17:24,816 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2709999029757455e-05, 2272
[INFO] 2021-07-12 19:17:24,816 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2272
[INFO] 2021-07-12 19:17:24,816 [run_pretraining.py:  558]:	worker_index: 3, step: 2272, cost: 7.402467, mlm loss: 7.402467, speed: 1.096081 steps/s, speed: 8.768650 samples/s, speed: 4489.548832 tokens/s, learning rate: 2.271e-05, loss_scalings: 2814.750488, pp_loss: 7.655830
[INFO] 2021-07-12 19:17:24,816 [run_pretraining.py:  512]:	********exe.run_2272******* 
[INFO] 2021-07-12 19:17:25,734 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:25,734 [run_pretraining.py:  534]:	loss/total_loss, 7.567447662353516, 2273
[INFO] 2021-07-12 19:17:25,734 [run_pretraining.py:  535]:	loss/mlm_loss, 7.567447662353516, 2273
[INFO] 2021-07-12 19:17:25,734 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.271999983349815e-05, 2273
[INFO] 2021-07-12 19:17:25,735 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2273
[INFO] 2021-07-12 19:17:25,735 [run_pretraining.py:  558]:	worker_index: 3, step: 2273, cost: 7.567448, mlm loss: 7.567448, speed: 1.089586 steps/s, speed: 8.716684 samples/s, speed: 4462.942407 tokens/s, learning rate: 2.272e-05, loss_scalings: 2814.750488, pp_loss: 7.355986
[INFO] 2021-07-12 19:17:25,735 [run_pretraining.py:  512]:	********exe.run_2273******* 
[INFO] 2021-07-12 19:17:26,648 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:26,648 [run_pretraining.py:  534]:	loss/total_loss, 8.083621978759766, 2274
[INFO] 2021-07-12 19:17:26,648 [run_pretraining.py:  535]:	loss/mlm_loss, 8.083621978759766, 2274
[INFO] 2021-07-12 19:17:26,648 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2730000637238845e-05, 2274
[INFO] 2021-07-12 19:17:26,648 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2274
[INFO] 2021-07-12 19:17:26,649 [run_pretraining.py:  558]:	worker_index: 3, step: 2274, cost: 8.083622, mlm loss: 8.083622, speed: 1.094891 steps/s, speed: 8.759130 samples/s, speed: 4484.674639 tokens/s, learning rate: 2.273e-05, loss_scalings: 2814.750488, pp_loss: 7.552787
[INFO] 2021-07-12 19:17:26,649 [run_pretraining.py:  512]:	********exe.run_2274******* 
[INFO] 2021-07-12 19:17:52,519 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:52,520 [run_pretraining.py:  534]:	loss/total_loss, 7.1763529777526855, 2275
[INFO] 2021-07-12 19:17:52,520 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1763529777526855, 2275
[INFO] 2021-07-12 19:17:52,520 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2739999621990137e-05, 2275
[INFO] 2021-07-12 19:17:52,520 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2275
[INFO] 2021-07-12 19:17:52,520 [run_pretraining.py:  558]:	worker_index: 3, step: 2275, cost: 7.176353, mlm loss: 7.176353, speed: 0.038654 steps/s, speed: 0.309229 samples/s, speed: 158.325174 tokens/s, learning rate: 2.274e-05, loss_scalings: 2814.750488, pp_loss: 7.220781
[INFO] 2021-07-12 19:17:52,520 [run_pretraining.py:  512]:	********exe.run_2275******* 
[INFO] 2021-07-12 19:17:53,427 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:53,427 [run_pretraining.py:  534]:	loss/total_loss, 7.127723693847656, 2276
[INFO] 2021-07-12 19:17:53,428 [run_pretraining.py:  535]:	loss/mlm_loss, 7.127723693847656, 2276
[INFO] 2021-07-12 19:17:53,428 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2750000425730832e-05, 2276
[INFO] 2021-07-12 19:17:53,428 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2276
[INFO] 2021-07-12 19:17:53,428 [run_pretraining.py:  558]:	worker_index: 3, step: 2276, cost: 7.127724, mlm loss: 7.127724, speed: 1.102492 steps/s, speed: 8.819938 samples/s, speed: 4515.808389 tokens/s, learning rate: 2.275e-05, loss_scalings: 2814.750488, pp_loss: 7.003560
[INFO] 2021-07-12 19:17:53,428 [run_pretraining.py:  512]:	********exe.run_2276******* 
[INFO] 2021-07-12 19:17:54,339 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:54,339 [run_pretraining.py:  534]:	loss/total_loss, 7.315710544586182, 2277
[INFO] 2021-07-12 19:17:54,339 [run_pretraining.py:  535]:	loss/mlm_loss, 7.315710544586182, 2277
[INFO] 2021-07-12 19:17:54,339 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2759999410482123e-05, 2277
[INFO] 2021-07-12 19:17:54,339 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2277
[INFO] 2021-07-12 19:17:54,340 [run_pretraining.py:  558]:	worker_index: 3, step: 2277, cost: 7.315711, mlm loss: 7.315711, speed: 1.097490 steps/s, speed: 8.779918 samples/s, speed: 4495.318000 tokens/s, learning rate: 2.276e-05, loss_scalings: 2814.750488, pp_loss: 7.220719
[INFO] 2021-07-12 19:17:54,340 [run_pretraining.py:  512]:	********exe.run_2277******* 
[INFO] 2021-07-12 19:17:55,252 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:55,253 [run_pretraining.py:  534]:	loss/total_loss, 7.428974628448486, 2278
[INFO] 2021-07-12 19:17:55,253 [run_pretraining.py:  535]:	loss/mlm_loss, 7.428974628448486, 2278
[INFO] 2021-07-12 19:17:55,253 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2769998395233415e-05, 2278
[INFO] 2021-07-12 19:17:55,253 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2278
[INFO] 2021-07-12 19:17:55,253 [run_pretraining.py:  558]:	worker_index: 3, step: 2278, cost: 7.428975, mlm loss: 7.428975, speed: 1.095225 steps/s, speed: 8.761802 samples/s, speed: 4486.042422 tokens/s, learning rate: 2.277e-05, loss_scalings: 2814.750488, pp_loss: 7.449723
[INFO] 2021-07-12 19:17:55,253 [run_pretraining.py:  512]:	********exe.run_2278******* 
[INFO] 2021-07-12 19:17:56,165 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:56,166 [run_pretraining.py:  534]:	loss/total_loss, 7.498569488525391, 2279
[INFO] 2021-07-12 19:17:56,166 [run_pretraining.py:  535]:	loss/mlm_loss, 7.498569488525391, 2279
[INFO] 2021-07-12 19:17:56,166 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.277999919897411e-05, 2279
[INFO] 2021-07-12 19:17:56,166 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2279
[INFO] 2021-07-12 19:17:56,166 [run_pretraining.py:  558]:	worker_index: 3, step: 2279, cost: 7.498569, mlm loss: 7.498569, speed: 1.096248 steps/s, speed: 8.769982 samples/s, speed: 4490.230586 tokens/s, learning rate: 2.278e-05, loss_scalings: 2814.750488, pp_loss: 6.814221
[INFO] 2021-07-12 19:17:56,166 [run_pretraining.py:  512]:	********exe.run_2279******* 
[INFO] 2021-07-12 19:17:57,071 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:57,072 [run_pretraining.py:  534]:	loss/total_loss, 7.209322929382324, 2280
[INFO] 2021-07-12 19:17:57,072 [run_pretraining.py:  535]:	loss/mlm_loss, 7.209322929382324, 2280
[INFO] 2021-07-12 19:17:57,072 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2790000002714805e-05, 2280
[INFO] 2021-07-12 19:17:57,072 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2280
[INFO] 2021-07-12 19:17:57,072 [run_pretraining.py:  558]:	worker_index: 3, step: 2280, cost: 7.209323, mlm loss: 7.209323, speed: 1.104526 steps/s, speed: 8.836208 samples/s, speed: 4524.138671 tokens/s, learning rate: 2.279e-05, loss_scalings: 2814.750488, pp_loss: 7.106668
[INFO] 2021-07-12 19:17:57,072 [run_pretraining.py:  512]:	********exe.run_2280******* 
[INFO] 2021-07-12 19:17:57,983 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:57,983 [run_pretraining.py:  534]:	loss/total_loss, 6.919663429260254, 2281
[INFO] 2021-07-12 19:17:57,983 [run_pretraining.py:  535]:	loss/mlm_loss, 6.919663429260254, 2281
[INFO] 2021-07-12 19:17:57,983 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2799998987466097e-05, 2281
[INFO] 2021-07-12 19:17:57,984 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2281
[INFO] 2021-07-12 19:17:57,984 [run_pretraining.py:  558]:	worker_index: 3, step: 2281, cost: 6.919663, mlm loss: 6.919663, speed: 1.097858 steps/s, speed: 8.782862 samples/s, speed: 4496.825286 tokens/s, learning rate: 2.280e-05, loss_scalings: 2814.750488, pp_loss: 7.296069
[INFO] 2021-07-12 19:17:57,984 [run_pretraining.py:  512]:	********exe.run_2281******* 
[INFO] 2021-07-12 19:17:58,924 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:58,925 [run_pretraining.py:  534]:	loss/total_loss, 7.257516860961914, 2282
[INFO] 2021-07-12 19:17:58,925 [run_pretraining.py:  535]:	loss/mlm_loss, 7.257516860961914, 2282
[INFO] 2021-07-12 19:17:58,925 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2809999791206792e-05, 2282
[INFO] 2021-07-12 19:17:58,925 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2282
[INFO] 2021-07-12 19:17:58,925 [run_pretraining.py:  558]:	worker_index: 3, step: 2282, cost: 7.257517, mlm loss: 7.257517, speed: 1.063108 steps/s, speed: 8.504861 samples/s, speed: 4354.488803 tokens/s, learning rate: 2.281e-05, loss_scalings: 2814.750488, pp_loss: 6.981224
[INFO] 2021-07-12 19:17:58,925 [run_pretraining.py:  512]:	********exe.run_2282******* 
[INFO] 2021-07-12 19:17:59,842 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:59,842 [run_pretraining.py:  534]:	loss/total_loss, 7.6669793128967285, 2283
[INFO] 2021-07-12 19:17:59,842 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6669793128967285, 2283
[INFO] 2021-07-12 19:17:59,843 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2820000594947487e-05, 2283
[INFO] 2021-07-12 19:17:59,843 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2283
[INFO] 2021-07-12 19:17:59,843 [run_pretraining.py:  558]:	worker_index: 3, step: 2283, cost: 7.666979, mlm loss: 7.666979, speed: 1.090337 steps/s, speed: 8.722696 samples/s, speed: 4466.020341 tokens/s, learning rate: 2.282e-05, loss_scalings: 2814.750488, pp_loss: 7.340396
[INFO] 2021-07-12 19:17:59,843 [run_pretraining.py:  512]:	********exe.run_2283******* 
[INFO] 2021-07-12 19:18:00,757 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:00,758 [run_pretraining.py:  534]:	loss/total_loss, 6.680011749267578, 2284
[INFO] 2021-07-12 19:18:00,758 [run_pretraining.py:  535]:	loss/mlm_loss, 6.680011749267578, 2284
[INFO] 2021-07-12 19:18:00,758 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.282999957969878e-05, 2284
[INFO] 2021-07-12 19:18:00,758 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2284
[INFO] 2021-07-12 19:18:00,758 [run_pretraining.py:  558]:	worker_index: 3, step: 2284, cost: 6.680012, mlm loss: 6.680012, speed: 1.093071 steps/s, speed: 8.744564 samples/s, speed: 4477.216887 tokens/s, learning rate: 2.283e-05, loss_scalings: 2814.750488, pp_loss: 6.979255
[INFO] 2021-07-12 19:18:00,758 [run_pretraining.py:  512]:	********exe.run_2284******* 
[INFO] 2021-07-12 19:18:01,675 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:01,675 [run_pretraining.py:  534]:	loss/total_loss, 3.4367918968200684, 2285
[INFO] 2021-07-12 19:18:01,676 [run_pretraining.py:  535]:	loss/mlm_loss, 3.4367918968200684, 2285
[INFO] 2021-07-12 19:18:01,676 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2840000383439474e-05, 2285
[INFO] 2021-07-12 19:18:01,676 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2285
[INFO] 2021-07-12 19:18:01,676 [run_pretraining.py:  558]:	worker_index: 3, step: 2285, cost: 3.436792, mlm loss: 3.436792, speed: 1.090610 steps/s, speed: 8.724882 samples/s, speed: 4467.139798 tokens/s, learning rate: 2.284e-05, loss_scalings: 2814.750488, pp_loss: 6.445285
[INFO] 2021-07-12 19:18:01,676 [run_pretraining.py:  512]:	********exe.run_2285******* 
[INFO] 2021-07-12 19:18:02,579 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:02,580 [run_pretraining.py:  534]:	loss/total_loss, 7.734245777130127, 2286
[INFO] 2021-07-12 19:18:02,580 [run_pretraining.py:  535]:	loss/mlm_loss, 7.734245777130127, 2286
[INFO] 2021-07-12 19:18:02,580 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2849999368190765e-05, 2286
[INFO] 2021-07-12 19:18:02,580 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2286
[INFO] 2021-07-12 19:18:02,580 [run_pretraining.py:  558]:	worker_index: 3, step: 2286, cost: 7.734246, mlm loss: 7.734246, speed: 1.106550 steps/s, speed: 8.852398 samples/s, speed: 4532.427997 tokens/s, learning rate: 2.285e-05, loss_scalings: 2814.750488, pp_loss: 7.633157
[INFO] 2021-07-12 19:18:02,580 [run_pretraining.py:  512]:	********exe.run_2286******* 
[INFO] 2021-07-12 19:18:03,491 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:03,491 [run_pretraining.py:  534]:	loss/total_loss, 7.596803665161133, 2287
[INFO] 2021-07-12 19:18:03,491 [run_pretraining.py:  535]:	loss/mlm_loss, 7.596803665161133, 2287
[INFO] 2021-07-12 19:18:03,491 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2859998352942057e-05, 2287
[INFO] 2021-07-12 19:18:03,491 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2287
[INFO] 2021-07-12 19:18:03,492 [run_pretraining.py:  558]:	worker_index: 3, step: 2287, cost: 7.596804, mlm loss: 7.596804, speed: 1.097984 steps/s, speed: 8.783876 samples/s, speed: 4497.344422 tokens/s, learning rate: 2.286e-05, loss_scalings: 2814.750488, pp_loss: 7.472301
[INFO] 2021-07-12 19:18:03,492 [run_pretraining.py:  512]:	********exe.run_2287******* 
[INFO] 2021-07-12 19:18:04,409 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:04,410 [run_pretraining.py:  534]:	loss/total_loss, 7.17195987701416, 2288
[INFO] 2021-07-12 19:18:04,410 [run_pretraining.py:  535]:	loss/mlm_loss, 7.17195987701416, 2288
[INFO] 2021-07-12 19:18:04,410 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2869999156682752e-05, 2288
[INFO] 2021-07-12 19:18:04,410 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2288
[INFO] 2021-07-12 19:18:04,410 [run_pretraining.py:  558]:	worker_index: 3, step: 2288, cost: 7.171960, mlm loss: 7.171960, speed: 1.089383 steps/s, speed: 8.715061 samples/s, speed: 4462.111292 tokens/s, learning rate: 2.287e-05, loss_scalings: 2814.750488, pp_loss: 7.209603
[INFO] 2021-07-12 19:18:04,410 [run_pretraining.py:  512]:	********exe.run_2288******* 
[INFO] 2021-07-12 19:18:05,320 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:05,320 [run_pretraining.py:  534]:	loss/total_loss, 7.751926422119141, 2289
[INFO] 2021-07-12 19:18:05,320 [run_pretraining.py:  535]:	loss/mlm_loss, 7.751926422119141, 2289
[INFO] 2021-07-12 19:18:05,320 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2879999960423447e-05, 2289
[INFO] 2021-07-12 19:18:05,320 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2289
[INFO] 2021-07-12 19:18:05,321 [run_pretraining.py:  558]:	worker_index: 3, step: 2289, cost: 7.751926, mlm loss: 7.751926, speed: 1.099190 steps/s, speed: 8.793523 samples/s, speed: 4502.283966 tokens/s, learning rate: 2.288e-05, loss_scalings: 2814.750488, pp_loss: 7.153494
[INFO] 2021-07-12 19:18:05,321 [run_pretraining.py:  512]:	********exe.run_2289******* 
[INFO] 2021-07-12 19:18:06,236 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:06,236 [run_pretraining.py:  534]:	loss/total_loss, 5.776446342468262, 2290
[INFO] 2021-07-12 19:18:06,237 [run_pretraining.py:  535]:	loss/mlm_loss, 5.776446342468262, 2290
[INFO] 2021-07-12 19:18:06,237 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.288999894517474e-05, 2290
[INFO] 2021-07-12 19:18:06,237 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2290
[INFO] 2021-07-12 19:18:06,237 [run_pretraining.py:  558]:	worker_index: 3, step: 2290, cost: 5.776446, mlm loss: 5.776446, speed: 1.092162 steps/s, speed: 8.737298 samples/s, speed: 4473.496722 tokens/s, learning rate: 2.289e-05, loss_scalings: 2814.750488, pp_loss: 7.182959
[INFO] 2021-07-12 19:18:06,237 [run_pretraining.py:  512]:	********exe.run_2290******* 
[INFO] 2021-07-12 19:18:07,175 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:07,175 [run_pretraining.py:  534]:	loss/total_loss, 6.349493980407715, 2291
[INFO] 2021-07-12 19:18:07,176 [run_pretraining.py:  535]:	loss/mlm_loss, 6.349493980407715, 2291
[INFO] 2021-07-12 19:18:07,176 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2899999748915434e-05, 2291
[INFO] 2021-07-12 19:18:07,176 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2291
[INFO] 2021-07-12 19:18:07,176 [run_pretraining.py:  558]:	worker_index: 3, step: 2291, cost: 6.349494, mlm loss: 6.349494, speed: 1.065734 steps/s, speed: 8.525868 samples/s, speed: 4365.244458 tokens/s, learning rate: 2.290e-05, loss_scalings: 2814.750488, pp_loss: 7.014428
[INFO] 2021-07-12 19:18:07,176 [run_pretraining.py:  512]:	********exe.run_2291******* 
[INFO] 2021-07-12 19:18:08,088 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:08,089 [run_pretraining.py:  534]:	loss/total_loss, 7.093787670135498, 2292
[INFO] 2021-07-12 19:18:08,089 [run_pretraining.py:  535]:	loss/mlm_loss, 7.093787670135498, 2292
[INFO] 2021-07-12 19:18:08,089 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.291000055265613e-05, 2292
[INFO] 2021-07-12 19:18:08,089 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2292
[INFO] 2021-07-12 19:18:08,089 [run_pretraining.py:  558]:	worker_index: 3, step: 2292, cost: 7.093788, mlm loss: 7.093788, speed: 1.095523 steps/s, speed: 8.764186 samples/s, speed: 4487.263358 tokens/s, learning rate: 2.291e-05, loss_scalings: 2814.750488, pp_loss: 7.215578
[INFO] 2021-07-12 19:18:08,089 [run_pretraining.py:  512]:	********exe.run_2292******* 
[INFO] 2021-07-12 19:18:09,009 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:09,010 [run_pretraining.py:  534]:	loss/total_loss, 7.3552470207214355, 2293
[INFO] 2021-07-12 19:18:09,010 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3552470207214355, 2293
[INFO] 2021-07-12 19:18:09,010 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.291999953740742e-05, 2293
[INFO] 2021-07-12 19:18:09,010 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2293
[INFO] 2021-07-12 19:18:09,010 [run_pretraining.py:  558]:	worker_index: 3, step: 2293, cost: 7.355247, mlm loss: 7.355247, speed: 1.086423 steps/s, speed: 8.691385 samples/s, speed: 4449.989350 tokens/s, learning rate: 2.292e-05, loss_scalings: 2814.750488, pp_loss: 7.329986
[INFO] 2021-07-12 19:18:09,010 [run_pretraining.py:  512]:	********exe.run_2293******* 
[INFO] 2021-07-12 19:18:09,918 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:09,919 [run_pretraining.py:  534]:	loss/total_loss, 6.926061153411865, 2294
[INFO] 2021-07-12 19:18:09,919 [run_pretraining.py:  535]:	loss/mlm_loss, 6.926061153411865, 2294
[INFO] 2021-07-12 19:18:09,919 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2930000341148116e-05, 2294
[INFO] 2021-07-12 19:18:09,919 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2294
[INFO] 2021-07-12 19:18:09,919 [run_pretraining.py:  558]:	worker_index: 3, step: 2294, cost: 6.926061, mlm loss: 6.926061, speed: 1.100808 steps/s, speed: 8.806461 samples/s, speed: 4508.908228 tokens/s, learning rate: 2.293e-05, loss_scalings: 2814.750488, pp_loss: 7.339711
[INFO] 2021-07-12 19:18:09,919 [run_pretraining.py:  512]:	********exe.run_2294******* 
[INFO] 2021-07-12 19:18:10,854 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:10,854 [run_pretraining.py:  534]:	loss/total_loss, 7.5136871337890625, 2295
[INFO] 2021-07-12 19:18:10,854 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5136871337890625, 2295
[INFO] 2021-07-12 19:18:10,854 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2939999325899407e-05, 2295
[INFO] 2021-07-12 19:18:10,854 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2295
[INFO] 2021-07-12 19:18:10,854 [run_pretraining.py:  558]:	worker_index: 3, step: 2295, cost: 7.513687, mlm loss: 7.513687, speed: 1.070093 steps/s, speed: 8.560748 samples/s, speed: 4383.102726 tokens/s, learning rate: 2.294e-05, loss_scalings: 2814.750488, pp_loss: 7.654820
[INFO] 2021-07-12 19:18:10,855 [run_pretraining.py:  512]:	********exe.run_2295******* 
[INFO] 2021-07-12 19:18:11,913 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:11,914 [run_pretraining.py:  534]:	loss/total_loss, 8.194385528564453, 2296
[INFO] 2021-07-12 19:18:11,914 [run_pretraining.py:  535]:	loss/mlm_loss, 8.194385528564453, 2296
[INFO] 2021-07-12 19:18:11,914 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.29499983106507e-05, 2296
[INFO] 2021-07-12 19:18:11,914 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2296
[INFO] 2021-07-12 19:18:11,914 [run_pretraining.py:  558]:	worker_index: 3, step: 2296, cost: 8.194386, mlm loss: 8.194386, speed: 0.944201 steps/s, speed: 7.553604 samples/s, speed: 3867.445381 tokens/s, learning rate: 2.295e-05, loss_scalings: 2814.750488, pp_loss: 7.294075
[INFO] 2021-07-12 19:18:11,914 [run_pretraining.py:  512]:	********exe.run_2296******* 
[INFO] 2021-07-12 19:18:12,955 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:12,955 [run_pretraining.py:  534]:	loss/total_loss, 7.373581886291504, 2297
[INFO] 2021-07-12 19:18:12,955 [run_pretraining.py:  535]:	loss/mlm_loss, 7.373581886291504, 2297
[INFO] 2021-07-12 19:18:12,956 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2959999114391394e-05, 2297
[INFO] 2021-07-12 19:18:12,956 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2297
[INFO] 2021-07-12 19:18:12,956 [run_pretraining.py:  558]:	worker_index: 3, step: 2297, cost: 7.373582, mlm loss: 7.373582, speed: 0.960768 steps/s, speed: 7.686144 samples/s, speed: 3935.305915 tokens/s, learning rate: 2.296e-05, loss_scalings: 2814.750488, pp_loss: 7.325914
[INFO] 2021-07-12 19:18:12,956 [run_pretraining.py:  512]:	********exe.run_2297******* 
[INFO] 2021-07-12 19:18:14,009 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:14,010 [run_pretraining.py:  534]:	loss/total_loss, 7.8276238441467285, 2298
[INFO] 2021-07-12 19:18:14,010 [run_pretraining.py:  535]:	loss/mlm_loss, 7.8276238441467285, 2298
[INFO] 2021-07-12 19:18:14,010 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.296999991813209e-05, 2298
[INFO] 2021-07-12 19:18:14,010 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2298
[INFO] 2021-07-12 19:18:14,010 [run_pretraining.py:  558]:	worker_index: 3, step: 2298, cost: 7.827624, mlm loss: 7.827624, speed: 0.948973 steps/s, speed: 7.591780 samples/s, speed: 3886.991575 tokens/s, learning rate: 2.297e-05, loss_scalings: 2814.750488, pp_loss: 7.403801
[INFO] 2021-07-12 19:18:14,010 [run_pretraining.py:  512]:	********exe.run_2298******* 
[INFO] 2021-07-12 19:18:15,063 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:15,063 [run_pretraining.py:  534]:	loss/total_loss, 6.919832229614258, 2299
[INFO] 2021-07-12 19:18:15,063 [run_pretraining.py:  535]:	loss/mlm_loss, 6.919832229614258, 2299
[INFO] 2021-07-12 19:18:15,063 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.297999890288338e-05, 2299
[INFO] 2021-07-12 19:18:15,063 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2299
[INFO] 2021-07-12 19:18:15,063 [run_pretraining.py:  558]:	worker_index: 3, step: 2299, cost: 6.919832, mlm loss: 6.919832, speed: 0.949884 steps/s, speed: 7.599074 samples/s, speed: 3890.725754 tokens/s, learning rate: 2.298e-05, loss_scalings: 2814.750488, pp_loss: 7.127975
[INFO] 2021-07-12 19:18:15,064 [run_pretraining.py:  512]:	********exe.run_2299******* 
[INFO] 2021-07-12 19:18:40,224 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:40,225 [run_pretraining.py:  534]:	loss/total_loss, 7.580039024353027, 2300
[INFO] 2021-07-12 19:18:40,225 [run_pretraining.py:  535]:	loss/mlm_loss, 7.580039024353027, 2300
[INFO] 2021-07-12 19:18:40,225 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2989999706624076e-05, 2300
[INFO] 2021-07-12 19:18:40,225 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2300
[INFO] 2021-07-12 19:18:40,225 [run_pretraining.py:  558]:	worker_index: 3, step: 2300, cost: 7.580039, mlm loss: 7.580039, speed: 0.039744 steps/s, speed: 0.317952 samples/s, speed: 162.791261 tokens/s, learning rate: 2.299e-05, loss_scalings: 2814.750488, pp_loss: 6.541864
[INFO] 2021-07-12 19:18:40,225 [run_pretraining.py:  512]:	********exe.run_2300******* 
[INFO] 2021-07-12 19:18:41,157 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:41,157 [run_pretraining.py:  534]:	loss/total_loss, 7.278873920440674, 2301
[INFO] 2021-07-12 19:18:41,157 [run_pretraining.py:  535]:	loss/mlm_loss, 7.278873920440674, 2301
[INFO] 2021-07-12 19:18:41,158 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.300000051036477e-05, 2301
[INFO] 2021-07-12 19:18:41,158 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2301
[INFO] 2021-07-12 19:18:41,158 [run_pretraining.py:  558]:	worker_index: 3, step: 2301, cost: 7.278874, mlm loss: 7.278874, speed: 1.073016 steps/s, speed: 8.584127 samples/s, speed: 4395.072770 tokens/s, learning rate: 2.300e-05, loss_scalings: 2814.750488, pp_loss: 7.355604
[INFO] 2021-07-12 19:18:41,158 [run_pretraining.py:  512]:	********exe.run_2301******* 
[INFO] 2021-07-12 19:18:42,072 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:42,072 [run_pretraining.py:  534]:	loss/total_loss, 7.104448318481445, 2302
[INFO] 2021-07-12 19:18:42,072 [run_pretraining.py:  535]:	loss/mlm_loss, 7.104448318481445, 2302
[INFO] 2021-07-12 19:18:42,072 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3009999495116062e-05, 2302
[INFO] 2021-07-12 19:18:42,072 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2302
[INFO] 2021-07-12 19:18:42,072 [run_pretraining.py:  558]:	worker_index: 3, step: 2302, cost: 7.104448, mlm loss: 7.104448, speed: 1.094096 steps/s, speed: 8.752765 samples/s, speed: 4481.415466 tokens/s, learning rate: 2.301e-05, loss_scalings: 2814.750488, pp_loss: 7.011154
[INFO] 2021-07-12 19:18:42,072 [run_pretraining.py:  512]:	********exe.run_2302******* 
[INFO] 2021-07-12 19:18:42,990 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:42,991 [run_pretraining.py:  534]:	loss/total_loss, 7.084015369415283, 2303
[INFO] 2021-07-12 19:18:42,991 [run_pretraining.py:  535]:	loss/mlm_loss, 7.084015369415283, 2303
[INFO] 2021-07-12 19:18:42,991 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3019998479867354e-05, 2303
[INFO] 2021-07-12 19:18:42,991 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2303
[INFO] 2021-07-12 19:18:42,991 [run_pretraining.py:  558]:	worker_index: 3, step: 2303, cost: 7.084015, mlm loss: 7.084015, speed: 1.089057 steps/s, speed: 8.712457 samples/s, speed: 4460.777751 tokens/s, learning rate: 2.302e-05, loss_scalings: 2814.750488, pp_loss: 7.073730
[INFO] 2021-07-12 19:18:42,991 [run_pretraining.py:  512]:	********exe.run_2303******* 
[INFO] 2021-07-12 19:18:43,913 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:43,914 [run_pretraining.py:  534]:	loss/total_loss, 7.57966947555542, 2304
[INFO] 2021-07-12 19:18:43,914 [run_pretraining.py:  535]:	loss/mlm_loss, 7.57966947555542, 2304
[INFO] 2021-07-12 19:18:43,914 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.302999928360805e-05, 2304
[INFO] 2021-07-12 19:18:43,914 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2304
[INFO] 2021-07-12 19:18:43,914 [run_pretraining.py:  558]:	worker_index: 3, step: 2304, cost: 7.579669, mlm loss: 7.579669, speed: 1.083993 steps/s, speed: 8.671942 samples/s, speed: 4440.034317 tokens/s, learning rate: 2.303e-05, loss_scalings: 2814.750488, pp_loss: 7.251637
[INFO] 2021-07-12 19:18:43,914 [run_pretraining.py:  512]:	********exe.run_2304******* 
[INFO] 2021-07-12 19:18:44,830 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:44,831 [run_pretraining.py:  534]:	loss/total_loss, 7.316882133483887, 2305
[INFO] 2021-07-12 19:18:44,831 [run_pretraining.py:  535]:	loss/mlm_loss, 7.316882133483887, 2305
[INFO] 2021-07-12 19:18:44,831 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.303999826835934e-05, 2305
[INFO] 2021-07-12 19:18:44,831 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2305
[INFO] 2021-07-12 19:18:44,831 [run_pretraining.py:  558]:	worker_index: 3, step: 2305, cost: 7.316882, mlm loss: 7.316882, speed: 1.091449 steps/s, speed: 8.731591 samples/s, speed: 4470.574828 tokens/s, learning rate: 2.304e-05, loss_scalings: 2814.750488, pp_loss: 7.346539
[INFO] 2021-07-12 19:18:44,831 [run_pretraining.py:  512]:	********exe.run_2305******* 
[INFO] 2021-07-12 19:18:45,746 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:45,746 [run_pretraining.py:  534]:	loss/total_loss, 6.86725378036499, 2306
[INFO] 2021-07-12 19:18:45,746 [run_pretraining.py:  535]:	loss/mlm_loss, 6.86725378036499, 2306
[INFO] 2021-07-12 19:18:45,747 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3049999072100036e-05, 2306
[INFO] 2021-07-12 19:18:45,747 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2306
[INFO] 2021-07-12 19:18:45,747 [run_pretraining.py:  558]:	worker_index: 3, step: 2306, cost: 6.867254, mlm loss: 6.867254, speed: 1.093076 steps/s, speed: 8.744605 samples/s, speed: 4477.237889 tokens/s, learning rate: 2.305e-05, loss_scalings: 2814.750488, pp_loss: 7.002544
[INFO] 2021-07-12 19:18:45,747 [run_pretraining.py:  512]:	********exe.run_2306******* 
[INFO] 2021-07-12 19:18:46,666 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:46,666 [run_pretraining.py:  534]:	loss/total_loss, 7.22100830078125, 2307
[INFO] 2021-07-12 19:18:46,666 [run_pretraining.py:  535]:	loss/mlm_loss, 7.22100830078125, 2307
[INFO] 2021-07-12 19:18:46,666 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.305999987584073e-05, 2307
[INFO] 2021-07-12 19:18:46,667 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2307
[INFO] 2021-07-12 19:18:46,667 [run_pretraining.py:  558]:	worker_index: 3, step: 2307, cost: 7.221008, mlm loss: 7.221008, speed: 1.087800 steps/s, speed: 8.702401 samples/s, speed: 4455.629498 tokens/s, learning rate: 2.306e-05, loss_scalings: 2814.750488, pp_loss: 7.378709
[INFO] 2021-07-12 19:18:46,667 [run_pretraining.py:  512]:	********exe.run_2307******* 
[INFO] 2021-07-12 19:18:47,588 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:47,589 [run_pretraining.py:  534]:	loss/total_loss, 7.569029331207275, 2308
[INFO] 2021-07-12 19:18:47,589 [run_pretraining.py:  535]:	loss/mlm_loss, 7.569029331207275, 2308
[INFO] 2021-07-12 19:18:47,589 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3069998860592023e-05, 2308
[INFO] 2021-07-12 19:18:47,589 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2308
[INFO] 2021-07-12 19:18:47,589 [run_pretraining.py:  558]:	worker_index: 3, step: 2308, cost: 7.569029, mlm loss: 7.569029, speed: 1.084545 steps/s, speed: 8.676357 samples/s, speed: 4442.294896 tokens/s, learning rate: 2.307e-05, loss_scalings: 2814.750488, pp_loss: 7.460236
[INFO] 2021-07-12 19:18:47,589 [run_pretraining.py:  512]:	********exe.run_2308******* 
[INFO] 2021-07-12 19:18:48,514 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:48,514 [run_pretraining.py:  534]:	loss/total_loss, 6.809276580810547, 2309
[INFO] 2021-07-12 19:18:48,514 [run_pretraining.py:  535]:	loss/mlm_loss, 6.809276580810547, 2309
[INFO] 2021-07-12 19:18:48,514 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3079999664332718e-05, 2309
[INFO] 2021-07-12 19:18:48,514 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2309
[INFO] 2021-07-12 19:18:48,514 [run_pretraining.py:  558]:	worker_index: 3, step: 2309, cost: 6.809277, mlm loss: 6.809277, speed: 1.081676 steps/s, speed: 8.653407 samples/s, speed: 4430.544163 tokens/s, learning rate: 2.308e-05, loss_scalings: 2814.750488, pp_loss: 7.111861
[INFO] 2021-07-12 19:18:48,514 [run_pretraining.py:  512]:	********exe.run_2309******* 
[INFO] 2021-07-12 19:18:49,435 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:49,435 [run_pretraining.py:  534]:	loss/total_loss, 6.880199909210205, 2310
[INFO] 2021-07-12 19:18:49,436 [run_pretraining.py:  535]:	loss/mlm_loss, 6.880199909210205, 2310
[INFO] 2021-07-12 19:18:49,436 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3090000468073413e-05, 2310
[INFO] 2021-07-12 19:18:49,436 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2310
[INFO] 2021-07-12 19:18:49,436 [run_pretraining.py:  558]:	worker_index: 3, step: 2310, cost: 6.880200, mlm loss: 6.880200, speed: 1.086060 steps/s, speed: 8.688478 samples/s, speed: 4448.500622 tokens/s, learning rate: 2.309e-05, loss_scalings: 2814.750488, pp_loss: 7.050982
[INFO] 2021-07-12 19:18:49,436 [run_pretraining.py:  512]:	********exe.run_2310******* 
[INFO] 2021-07-12 19:18:50,356 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:50,357 [run_pretraining.py:  534]:	loss/total_loss, 7.791542053222656, 2311
[INFO] 2021-07-12 19:18:50,357 [run_pretraining.py:  535]:	loss/mlm_loss, 7.791542053222656, 2311
[INFO] 2021-07-12 19:18:50,357 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3099999452824704e-05, 2311
[INFO] 2021-07-12 19:18:50,357 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2311
[INFO] 2021-07-12 19:18:50,357 [run_pretraining.py:  558]:	worker_index: 3, step: 2311, cost: 7.791542, mlm loss: 7.791542, speed: 1.085968 steps/s, speed: 8.687744 samples/s, speed: 4448.125141 tokens/s, learning rate: 2.310e-05, loss_scalings: 2814.750488, pp_loss: 7.012978
[INFO] 2021-07-12 19:18:50,357 [run_pretraining.py:  512]:	********exe.run_2311******* 
[INFO] 2021-07-12 19:18:51,274 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:51,275 [run_pretraining.py:  534]:	loss/total_loss, 7.2070159912109375, 2312
[INFO] 2021-07-12 19:18:51,275 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2070159912109375, 2312
[INFO] 2021-07-12 19:18:51,275 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3109998437575996e-05, 2312
[INFO] 2021-07-12 19:18:51,275 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2312
[INFO] 2021-07-12 19:18:51,275 [run_pretraining.py:  558]:	worker_index: 3, step: 2312, cost: 7.207016, mlm loss: 7.207016, speed: 1.090319 steps/s, speed: 8.722553 samples/s, speed: 4465.947201 tokens/s, learning rate: 2.311e-05, loss_scalings: 2814.750488, pp_loss: 6.976549
[INFO] 2021-07-12 19:18:51,275 [run_pretraining.py:  512]:	********exe.run_2312******* 
[INFO] 2021-07-12 19:18:52,199 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:52,199 [run_pretraining.py:  534]:	loss/total_loss, 7.218953609466553, 2313
[INFO] 2021-07-12 19:18:52,199 [run_pretraining.py:  535]:	loss/mlm_loss, 7.218953609466553, 2313
[INFO] 2021-07-12 19:18:52,199 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.311999924131669e-05, 2313
[INFO] 2021-07-12 19:18:52,199 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2313
[INFO] 2021-07-12 19:18:52,200 [run_pretraining.py:  558]:	worker_index: 3, step: 2313, cost: 7.218954, mlm loss: 7.218954, speed: 1.082392 steps/s, speed: 8.659139 samples/s, speed: 4433.479160 tokens/s, learning rate: 2.312e-05, loss_scalings: 2814.750488, pp_loss: 6.823287
[INFO] 2021-07-12 19:18:52,200 [run_pretraining.py:  512]:	********exe.run_2313******* 
[INFO] 2021-07-12 19:18:53,130 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:53,131 [run_pretraining.py:  534]:	loss/total_loss, 6.271015167236328, 2314
[INFO] 2021-07-12 19:18:53,131 [run_pretraining.py:  535]:	loss/mlm_loss, 6.271015167236328, 2314
[INFO] 2021-07-12 19:18:53,131 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3129998226067983e-05, 2314
[INFO] 2021-07-12 19:18:53,131 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2314
[INFO] 2021-07-12 19:18:53,131 [run_pretraining.py:  558]:	worker_index: 3, step: 2314, cost: 6.271015, mlm loss: 6.271015, speed: 1.074276 steps/s, speed: 8.594209 samples/s, speed: 4400.235223 tokens/s, learning rate: 2.313e-05, loss_scalings: 2814.750488, pp_loss: 6.841515
[INFO] 2021-07-12 19:18:53,131 [run_pretraining.py:  512]:	********exe.run_2314******* 
[INFO] 2021-07-12 19:18:54,050 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:54,051 [run_pretraining.py:  534]:	loss/total_loss, 6.907862663269043, 2315
[INFO] 2021-07-12 19:18:54,051 [run_pretraining.py:  535]:	loss/mlm_loss, 6.907862663269043, 2315
[INFO] 2021-07-12 19:18:54,051 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3139999029808678e-05, 2315
[INFO] 2021-07-12 19:18:54,051 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2315
[INFO] 2021-07-12 19:18:54,051 [run_pretraining.py:  558]:	worker_index: 3, step: 2315, cost: 6.907863, mlm loss: 6.907863, speed: 1.087384 steps/s, speed: 8.699076 samples/s, speed: 4453.926831 tokens/s, learning rate: 2.314e-05, loss_scalings: 2814.750488, pp_loss: 7.239390
[INFO] 2021-07-12 19:18:54,051 [run_pretraining.py:  512]:	********exe.run_2315******* 
[INFO] 2021-07-12 19:18:54,969 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:54,970 [run_pretraining.py:  534]:	loss/total_loss, 6.784023284912109, 2316
[INFO] 2021-07-12 19:18:54,970 [run_pretraining.py:  535]:	loss/mlm_loss, 6.784023284912109, 2316
[INFO] 2021-07-12 19:18:54,970 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3149999833549373e-05, 2316
[INFO] 2021-07-12 19:18:54,970 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2316
[INFO] 2021-07-12 19:18:54,970 [run_pretraining.py:  558]:	worker_index: 3, step: 2316, cost: 6.784023, mlm loss: 6.784023, speed: 1.088968 steps/s, speed: 8.711742 samples/s, speed: 4460.411774 tokens/s, learning rate: 2.315e-05, loss_scalings: 2814.750488, pp_loss: 6.969653
[INFO] 2021-07-12 19:18:54,970 [run_pretraining.py:  512]:	********exe.run_2316******* 
[INFO] 2021-07-12 19:18:55,885 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:55,886 [run_pretraining.py:  534]:	loss/total_loss, 7.471665382385254, 2317
[INFO] 2021-07-12 19:18:55,886 [run_pretraining.py:  535]:	loss/mlm_loss, 7.471665382385254, 2317
[INFO] 2021-07-12 19:18:55,886 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3159998818300664e-05, 2317
[INFO] 2021-07-12 19:18:55,886 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2317
[INFO] 2021-07-12 19:18:55,886 [run_pretraining.py:  558]:	worker_index: 3, step: 2317, cost: 7.471665, mlm loss: 7.471665, speed: 1.092686 steps/s, speed: 8.741487 samples/s, speed: 4475.641095 tokens/s, learning rate: 2.316e-05, loss_scalings: 2814.750488, pp_loss: 7.513208
[INFO] 2021-07-12 19:18:55,886 [run_pretraining.py:  512]:	********exe.run_2317******* 
[INFO] 2021-07-12 19:18:56,805 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:56,806 [run_pretraining.py:  534]:	loss/total_loss, 6.880120277404785, 2318
[INFO] 2021-07-12 19:18:56,806 [run_pretraining.py:  535]:	loss/mlm_loss, 6.880120277404785, 2318
[INFO] 2021-07-12 19:18:56,806 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.316999962204136e-05, 2318
[INFO] 2021-07-12 19:18:56,806 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2318
[INFO] 2021-07-12 19:18:56,806 [run_pretraining.py:  558]:	worker_index: 3, step: 2318, cost: 6.880120, mlm loss: 6.880120, speed: 1.087852 steps/s, speed: 8.702812 samples/s, speed: 4455.839823 tokens/s, learning rate: 2.317e-05, loss_scalings: 2814.750488, pp_loss: 6.931655
[INFO] 2021-07-12 19:18:56,806 [run_pretraining.py:  512]:	********exe.run_2318******* 
[INFO] 2021-07-12 19:18:57,716 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:57,717 [run_pretraining.py:  534]:	loss/total_loss, 7.258878707885742, 2319
[INFO] 2021-07-12 19:18:57,717 [run_pretraining.py:  535]:	loss/mlm_loss, 7.258878707885742, 2319
[INFO] 2021-07-12 19:18:57,717 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3180000425782055e-05, 2319
[INFO] 2021-07-12 19:18:57,717 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2319
[INFO] 2021-07-12 19:18:57,717 [run_pretraining.py:  558]:	worker_index: 3, step: 2319, cost: 7.258879, mlm loss: 7.258879, speed: 1.098078 steps/s, speed: 8.784628 samples/s, speed: 4497.729437 tokens/s, learning rate: 2.318e-05, loss_scalings: 2814.750488, pp_loss: 7.268281
[INFO] 2021-07-12 19:18:57,717 [run_pretraining.py:  512]:	********exe.run_2319******* 
[INFO] 2021-07-12 19:18:58,632 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:58,633 [run_pretraining.py:  534]:	loss/total_loss, 6.618537425994873, 2320
[INFO] 2021-07-12 19:18:58,633 [run_pretraining.py:  535]:	loss/mlm_loss, 6.618537425994873, 2320
[INFO] 2021-07-12 19:18:58,633 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3189999410533346e-05, 2320
[INFO] 2021-07-12 19:18:58,633 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2320
[INFO] 2021-07-12 19:18:58,633 [run_pretraining.py:  558]:	worker_index: 3, step: 2320, cost: 6.618537, mlm loss: 6.618537, speed: 1.092488 steps/s, speed: 8.739906 samples/s, speed: 4474.832052 tokens/s, learning rate: 2.319e-05, loss_scalings: 2814.750488, pp_loss: 6.877612
[INFO] 2021-07-12 19:18:58,633 [run_pretraining.py:  512]:	********exe.run_2320******* 
[INFO] 2021-07-12 19:18:59,549 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:59,550 [run_pretraining.py:  534]:	loss/total_loss, 7.301833152770996, 2321
[INFO] 2021-07-12 19:18:59,550 [run_pretraining.py:  535]:	loss/mlm_loss, 7.301833152770996, 2321
[INFO] 2021-07-12 19:18:59,550 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3199998395284638e-05, 2321
[INFO] 2021-07-12 19:18:59,550 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2321
[INFO] 2021-07-12 19:18:59,550 [run_pretraining.py:  558]:	worker_index: 3, step: 2321, cost: 7.301833, mlm loss: 7.301833, speed: 1.091193 steps/s, speed: 8.729547 samples/s, speed: 4469.528067 tokens/s, learning rate: 2.320e-05, loss_scalings: 2814.750488, pp_loss: 6.952003
[INFO] 2021-07-12 19:18:59,550 [run_pretraining.py:  512]:	********exe.run_2321******* 
[INFO] 2021-07-12 19:19:00,468 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:00,469 [run_pretraining.py:  534]:	loss/total_loss, 7.05813455581665, 2322
[INFO] 2021-07-12 19:19:00,469 [run_pretraining.py:  535]:	loss/mlm_loss, 7.05813455581665, 2322
[INFO] 2021-07-12 19:19:00,469 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3209999199025333e-05, 2322
[INFO] 2021-07-12 19:19:00,469 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2322
[INFO] 2021-07-12 19:19:00,469 [run_pretraining.py:  558]:	worker_index: 3, step: 2322, cost: 7.058135, mlm loss: 7.058135, speed: 1.088959 steps/s, speed: 8.711669 samples/s, speed: 4460.374717 tokens/s, learning rate: 2.321e-05, loss_scalings: 2814.750488, pp_loss: 7.140148
[INFO] 2021-07-12 19:19:00,469 [run_pretraining.py:  512]:	********exe.run_2322******* 
[INFO] 2021-07-12 19:19:01,388 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:01,389 [run_pretraining.py:  534]:	loss/total_loss, 8.197346687316895, 2323
[INFO] 2021-07-12 19:19:01,389 [run_pretraining.py:  535]:	loss/mlm_loss, 8.197346687316895, 2323
[INFO] 2021-07-12 19:19:01,389 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3219998183776625e-05, 2323
[INFO] 2021-07-12 19:19:01,389 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2323
[INFO] 2021-07-12 19:19:01,389 [run_pretraining.py:  558]:	worker_index: 3, step: 2323, cost: 8.197347, mlm loss: 8.197347, speed: 1.088052 steps/s, speed: 8.704420 samples/s, speed: 4456.662822 tokens/s, learning rate: 2.322e-05, loss_scalings: 2814.750488, pp_loss: 7.315158
[INFO] 2021-07-12 19:19:01,389 [run_pretraining.py:  512]:	********exe.run_2323******* 
[INFO] 2021-07-12 19:19:02,303 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:02,304 [run_pretraining.py:  534]:	loss/total_loss, 7.207519054412842, 2324
[INFO] 2021-07-12 19:19:02,304 [run_pretraining.py:  535]:	loss/mlm_loss, 7.207519054412842, 2324
[INFO] 2021-07-12 19:19:02,304 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.322999898751732e-05, 2324
[INFO] 2021-07-12 19:19:02,304 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2324
[INFO] 2021-07-12 19:19:02,304 [run_pretraining.py:  558]:	worker_index: 3, step: 2324, cost: 7.207519, mlm loss: 7.207519, speed: 1.093269 steps/s, speed: 8.746148 samples/s, speed: 4478.027959 tokens/s, learning rate: 2.323e-05, loss_scalings: 2814.750488, pp_loss: 6.796181
[INFO] 2021-07-12 19:19:02,304 [run_pretraining.py:  512]:	********exe.run_2324******* 
[INFO] 2021-07-12 19:19:03,224 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:03,224 [run_pretraining.py:  534]:	loss/total_loss, 6.722973823547363, 2325
[INFO] 2021-07-12 19:19:03,224 [run_pretraining.py:  535]:	loss/mlm_loss, 6.722973823547363, 2325
[INFO] 2021-07-12 19:19:03,224 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3239999791258015e-05, 2325
[INFO] 2021-07-12 19:19:03,225 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2325
[INFO] 2021-07-12 19:19:03,225 [run_pretraining.py:  558]:	worker_index: 3, step: 2325, cost: 6.722974, mlm loss: 6.722974, speed: 1.087220 steps/s, speed: 8.697761 samples/s, speed: 4453.253747 tokens/s, learning rate: 2.324e-05, loss_scalings: 2814.750488, pp_loss: 6.763844
[INFO] 2021-07-12 19:19:03,225 [run_pretraining.py:  512]:	********exe.run_2325******* 
[INFO] 2021-07-12 19:19:04,137 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:04,138 [run_pretraining.py:  534]:	loss/total_loss, 4.860665798187256, 2326
[INFO] 2021-07-12 19:19:04,138 [run_pretraining.py:  535]:	loss/mlm_loss, 4.860665798187256, 2326
[INFO] 2021-07-12 19:19:04,138 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3249998776009306e-05, 2326
[INFO] 2021-07-12 19:19:04,138 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2326
[INFO] 2021-07-12 19:19:04,138 [run_pretraining.py:  558]:	worker_index: 3, step: 2326, cost: 4.860666, mlm loss: 4.860666, speed: 1.095489 steps/s, speed: 8.763909 samples/s, speed: 4487.121546 tokens/s, learning rate: 2.325e-05, loss_scalings: 2814.750488, pp_loss: 6.958889
[INFO] 2021-07-12 19:19:04,138 [run_pretraining.py:  512]:	********exe.run_2326******* 
[INFO] 2021-07-12 19:19:05,050 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:05,050 [run_pretraining.py:  534]:	loss/total_loss, 7.954806327819824, 2327
[INFO] 2021-07-12 19:19:05,051 [run_pretraining.py:  535]:	loss/mlm_loss, 7.954806327819824, 2327
[INFO] 2021-07-12 19:19:05,051 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.325999957975e-05, 2327
[INFO] 2021-07-12 19:19:05,051 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2327
[INFO] 2021-07-12 19:19:05,051 [run_pretraining.py:  558]:	worker_index: 3, step: 2327, cost: 7.954806, mlm loss: 7.954806, speed: 1.096451 steps/s, speed: 8.771605 samples/s, speed: 4491.061643 tokens/s, learning rate: 2.326e-05, loss_scalings: 2814.750488, pp_loss: 7.297026
[INFO] 2021-07-12 19:19:05,051 [run_pretraining.py:  512]:	********exe.run_2327******* 
[INFO] 2021-07-12 19:19:05,965 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:05,965 [run_pretraining.py:  534]:	loss/total_loss, 7.152028560638428, 2328
[INFO] 2021-07-12 19:19:05,965 [run_pretraining.py:  535]:	loss/mlm_loss, 7.152028560638428, 2328
[INFO] 2021-07-12 19:19:05,965 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3270000383490697e-05, 2328
[INFO] 2021-07-12 19:19:05,965 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2328
[INFO] 2021-07-12 19:19:05,965 [run_pretraining.py:  558]:	worker_index: 3, step: 2328, cost: 7.152029, mlm loss: 7.152029, speed: 1.093954 steps/s, speed: 8.751635 samples/s, speed: 4480.836891 tokens/s, learning rate: 2.327e-05, loss_scalings: 2814.750488, pp_loss: 7.332771
[INFO] 2021-07-12 19:19:05,966 [run_pretraining.py:  512]:	********exe.run_2328******* 
[INFO] 2021-07-12 19:19:06,877 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:06,878 [run_pretraining.py:  534]:	loss/total_loss, 6.7315521240234375, 2329
[INFO] 2021-07-12 19:19:06,878 [run_pretraining.py:  535]:	loss/mlm_loss, 6.7315521240234375, 2329
[INFO] 2021-07-12 19:19:06,878 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3279999368241988e-05, 2329
[INFO] 2021-07-12 19:19:06,878 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2329
[INFO] 2021-07-12 19:19:06,878 [run_pretraining.py:  558]:	worker_index: 3, step: 2329, cost: 6.731552, mlm loss: 6.731552, speed: 1.096314 steps/s, speed: 8.770511 samples/s, speed: 4490.501702 tokens/s, learning rate: 2.328e-05, loss_scalings: 2814.750488, pp_loss: 7.336175
[INFO] 2021-07-12 19:19:06,878 [run_pretraining.py:  512]:	********exe.run_2329******* 
[INFO] 2021-07-12 19:19:07,796 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:07,797 [run_pretraining.py:  534]:	loss/total_loss, 7.680538177490234, 2330
[INFO] 2021-07-12 19:19:07,797 [run_pretraining.py:  535]:	loss/mlm_loss, 7.680538177490234, 2330
[INFO] 2021-07-12 19:19:07,797 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.328999835299328e-05, 2330
[INFO] 2021-07-12 19:19:07,797 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2330
[INFO] 2021-07-12 19:19:07,797 [run_pretraining.py:  558]:	worker_index: 3, step: 2330, cost: 7.680538, mlm loss: 7.680538, speed: 1.089046 steps/s, speed: 8.712366 samples/s, speed: 4460.731421 tokens/s, learning rate: 2.329e-05, loss_scalings: 2814.750488, pp_loss: 7.449094
[INFO] 2021-07-12 19:19:07,797 [run_pretraining.py:  512]:	********exe.run_2330******* 
[INFO] 2021-07-12 19:19:08,715 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:08,716 [run_pretraining.py:  534]:	loss/total_loss, 6.836791038513184, 2331
[INFO] 2021-07-12 19:19:08,716 [run_pretraining.py:  535]:	loss/mlm_loss, 6.836791038513184, 2331
[INFO] 2021-07-12 19:19:08,716 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3299999156733975e-05, 2331
[INFO] 2021-07-12 19:19:08,716 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2331
[INFO] 2021-07-12 19:19:08,716 [run_pretraining.py:  558]:	worker_index: 3, step: 2331, cost: 6.836791, mlm loss: 6.836791, speed: 1.088665 steps/s, speed: 8.709320 samples/s, speed: 4459.171840 tokens/s, learning rate: 2.330e-05, loss_scalings: 2814.750488, pp_loss: 7.165770
[INFO] 2021-07-12 19:19:08,716 [run_pretraining.py:  512]:	********exe.run_2331******* 
[INFO] 2021-07-12 19:19:09,633 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:09,633 [run_pretraining.py:  534]:	loss/total_loss, 7.473832130432129, 2332
[INFO] 2021-07-12 19:19:09,633 [run_pretraining.py:  535]:	loss/mlm_loss, 7.473832130432129, 2332
[INFO] 2021-07-12 19:19:09,634 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.330999996047467e-05, 2332
[INFO] 2021-07-12 19:19:09,634 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2332
[INFO] 2021-07-12 19:19:09,634 [run_pretraining.py:  558]:	worker_index: 3, step: 2332, cost: 7.473832, mlm loss: 7.473832, speed: 1.090761 steps/s, speed: 8.726085 samples/s, speed: 4467.755506 tokens/s, learning rate: 2.331e-05, loss_scalings: 2814.750488, pp_loss: 7.260783
[INFO] 2021-07-12 19:19:09,634 [run_pretraining.py:  512]:	********exe.run_2332******* 
[INFO] 2021-07-12 19:19:10,551 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:10,552 [run_pretraining.py:  534]:	loss/total_loss, 6.364130973815918, 2333
[INFO] 2021-07-12 19:19:10,552 [run_pretraining.py:  535]:	loss/mlm_loss, 6.364130973815918, 2333
[INFO] 2021-07-12 19:19:10,552 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.331999894522596e-05, 2333
[INFO] 2021-07-12 19:19:10,552 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2333
[INFO] 2021-07-12 19:19:10,552 [run_pretraining.py:  558]:	worker_index: 3, step: 2333, cost: 6.364131, mlm loss: 6.364131, speed: 1.089718 steps/s, speed: 8.717744 samples/s, speed: 4463.485059 tokens/s, learning rate: 2.332e-05, loss_scalings: 2814.750488, pp_loss: 6.773816
[INFO] 2021-07-12 19:19:10,552 [run_pretraining.py:  512]:	********exe.run_2333******* 
[INFO] 2021-07-12 19:19:36,263 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:36,263 [run_pretraining.py:  534]:	loss/total_loss, 7.247808933258057, 2334
[INFO] 2021-07-12 19:19:36,264 [run_pretraining.py:  535]:	loss/mlm_loss, 7.247808933258057, 2334
[INFO] 2021-07-12 19:19:36,264 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3329999748966657e-05, 2334
[INFO] 2021-07-12 19:19:36,264 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2334
[INFO] 2021-07-12 19:19:36,264 [run_pretraining.py:  558]:	worker_index: 3, step: 2334, cost: 7.247809, mlm loss: 7.247809, speed: 0.038894 steps/s, speed: 0.311149 samples/s, speed: 159.308526 tokens/s, learning rate: 2.333e-05, loss_scalings: 2814.750488, pp_loss: 7.436587
[INFO] 2021-07-12 19:19:36,264 [run_pretraining.py:  512]:	********exe.run_2334******* 
[INFO] 2021-07-12 19:19:37,176 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:37,177 [run_pretraining.py:  534]:	loss/total_loss, 4.220634937286377, 2335
[INFO] 2021-07-12 19:19:37,177 [run_pretraining.py:  535]:	loss/mlm_loss, 4.220634937286377, 2335
[INFO] 2021-07-12 19:19:37,177 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3339998733717948e-05, 2335
[INFO] 2021-07-12 19:19:37,177 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2335
[INFO] 2021-07-12 19:19:37,177 [run_pretraining.py:  558]:	worker_index: 3, step: 2335, cost: 4.220635, mlm loss: 4.220635, speed: 1.095815 steps/s, speed: 8.766522 samples/s, speed: 4488.459160 tokens/s, learning rate: 2.334e-05, loss_scalings: 2814.750488, pp_loss: 6.285721
[INFO] 2021-07-12 19:19:37,177 [run_pretraining.py:  512]:	********exe.run_2335******* 
[INFO] 2021-07-12 19:19:38,097 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:38,097 [run_pretraining.py:  534]:	loss/total_loss, 7.75239372253418, 2336
[INFO] 2021-07-12 19:19:38,098 [run_pretraining.py:  535]:	loss/mlm_loss, 7.75239372253418, 2336
[INFO] 2021-07-12 19:19:38,098 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3349999537458643e-05, 2336
[INFO] 2021-07-12 19:19:38,098 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2336
[INFO] 2021-07-12 19:19:38,098 [run_pretraining.py:  558]:	worker_index: 3, step: 2336, cost: 7.752394, mlm loss: 7.752394, speed: 1.086807 steps/s, speed: 8.694460 samples/s, speed: 4451.563276 tokens/s, learning rate: 2.335e-05, loss_scalings: 2814.750488, pp_loss: 7.548601
[INFO] 2021-07-12 19:19:38,098 [run_pretraining.py:  512]:	********exe.run_2336******* 
[INFO] 2021-07-12 19:19:39,007 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:39,007 [run_pretraining.py:  534]:	loss/total_loss, 6.917902946472168, 2337
[INFO] 2021-07-12 19:19:39,008 [run_pretraining.py:  535]:	loss/mlm_loss, 6.917902946472168, 2337
[INFO] 2021-07-12 19:19:39,008 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.336000034119934e-05, 2337
[INFO] 2021-07-12 19:19:39,008 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2337
[INFO] 2021-07-12 19:19:39,008 [run_pretraining.py:  558]:	worker_index: 3, step: 2337, cost: 6.917903, mlm loss: 6.917903, speed: 1.099668 steps/s, speed: 8.797341 samples/s, speed: 4504.238732 tokens/s, learning rate: 2.336e-05, loss_scalings: 2814.750488, pp_loss: 7.019701
[INFO] 2021-07-12 19:19:39,008 [run_pretraining.py:  512]:	********exe.run_2337******* 
[INFO] 2021-07-12 19:19:39,926 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:39,926 [run_pretraining.py:  534]:	loss/total_loss, 6.727783679962158, 2338
[INFO] 2021-07-12 19:19:39,926 [run_pretraining.py:  535]:	loss/mlm_loss, 6.727783679962158, 2338
[INFO] 2021-07-12 19:19:39,926 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.336999932595063e-05, 2338
[INFO] 2021-07-12 19:19:39,926 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2338
[INFO] 2021-07-12 19:19:39,926 [run_pretraining.py:  558]:	worker_index: 3, step: 2338, cost: 6.727784, mlm loss: 6.727784, speed: 1.089331 steps/s, speed: 8.714645 samples/s, speed: 4461.898057 tokens/s, learning rate: 2.337e-05, loss_scalings: 2814.750488, pp_loss: 7.352048
[INFO] 2021-07-12 19:19:39,926 [run_pretraining.py:  512]:	********exe.run_2338******* 
[INFO] 2021-07-12 19:19:40,838 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:40,838 [run_pretraining.py:  534]:	loss/total_loss, 7.439398288726807, 2339
[INFO] 2021-07-12 19:19:40,838 [run_pretraining.py:  535]:	loss/mlm_loss, 7.439398288726807, 2339
[INFO] 2021-07-12 19:19:40,838 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.337999831070192e-05, 2339
[INFO] 2021-07-12 19:19:40,839 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2339
[INFO] 2021-07-12 19:19:40,839 [run_pretraining.py:  558]:	worker_index: 3, step: 2339, cost: 7.439398, mlm loss: 7.439398, speed: 1.096975 steps/s, speed: 8.775801 samples/s, speed: 4493.209966 tokens/s, learning rate: 2.338e-05, loss_scalings: 2814.750488, pp_loss: 7.371206
[INFO] 2021-07-12 19:19:40,839 [run_pretraining.py:  512]:	********exe.run_2339******* 
[INFO] 2021-07-12 19:19:41,754 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:41,754 [run_pretraining.py:  534]:	loss/total_loss, 7.1060028076171875, 2340
[INFO] 2021-07-12 19:19:41,754 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1060028076171875, 2340
[INFO] 2021-07-12 19:19:41,754 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3389999114442617e-05, 2340
[INFO] 2021-07-12 19:19:41,754 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2340
[INFO] 2021-07-12 19:19:41,755 [run_pretraining.py:  558]:	worker_index: 3, step: 2340, cost: 7.106003, mlm loss: 7.106003, speed: 1.092519 steps/s, speed: 8.740150 samples/s, speed: 4474.956770 tokens/s, learning rate: 2.339e-05, loss_scalings: 2814.750488, pp_loss: 7.215560
[INFO] 2021-07-12 19:19:41,755 [run_pretraining.py:  512]:	********exe.run_2340******* 
[INFO] 2021-07-12 19:19:42,671 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:42,672 [run_pretraining.py:  534]:	loss/total_loss, 7.043129920959473, 2341
[INFO] 2021-07-12 19:19:42,672 [run_pretraining.py:  535]:	loss/mlm_loss, 7.043129920959473, 2341
[INFO] 2021-07-12 19:19:42,672 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3399999918183312e-05, 2341
[INFO] 2021-07-12 19:19:42,672 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2341
[INFO] 2021-07-12 19:19:42,672 [run_pretraining.py:  558]:	worker_index: 3, step: 2341, cost: 7.043130, mlm loss: 7.043130, speed: 1.090474 steps/s, speed: 8.723794 samples/s, speed: 4466.582322 tokens/s, learning rate: 2.340e-05, loss_scalings: 2814.750488, pp_loss: 7.274718
[INFO] 2021-07-12 19:19:42,672 [run_pretraining.py:  512]:	********exe.run_2341******* 
[INFO] 2021-07-12 19:19:43,586 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:43,586 [run_pretraining.py:  534]:	loss/total_loss, 7.020454406738281, 2342
[INFO] 2021-07-12 19:19:43,587 [run_pretraining.py:  535]:	loss/mlm_loss, 7.020454406738281, 2342
[INFO] 2021-07-12 19:19:43,587 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3409998902934603e-05, 2342
[INFO] 2021-07-12 19:19:43,587 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2342
[INFO] 2021-07-12 19:19:43,587 [run_pretraining.py:  558]:	worker_index: 3, step: 2342, cost: 7.020454, mlm loss: 7.020454, speed: 1.094173 steps/s, speed: 8.753388 samples/s, speed: 4481.734623 tokens/s, learning rate: 2.341e-05, loss_scalings: 2814.750488, pp_loss: 7.258852
[INFO] 2021-07-12 19:19:43,587 [run_pretraining.py:  512]:	********exe.run_2342******* 
[INFO] 2021-07-12 19:19:44,504 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:44,504 [run_pretraining.py:  534]:	loss/total_loss, 6.336724281311035, 2343
[INFO] 2021-07-12 19:19:44,504 [run_pretraining.py:  535]:	loss/mlm_loss, 6.336724281311035, 2343
[INFO] 2021-07-12 19:19:44,504 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.34199997066753e-05, 2343
[INFO] 2021-07-12 19:19:44,505 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2343
[INFO] 2021-07-12 19:19:44,505 [run_pretraining.py:  558]:	worker_index: 3, step: 2343, cost: 6.336724, mlm loss: 6.336724, speed: 1.090235 steps/s, speed: 8.721880 samples/s, speed: 4465.602430 tokens/s, learning rate: 2.342e-05, loss_scalings: 2814.750488, pp_loss: 7.078240
[INFO] 2021-07-12 19:19:44,505 [run_pretraining.py:  512]:	********exe.run_2343******* 
[INFO] 2021-07-12 19:19:45,420 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:45,420 [run_pretraining.py:  534]:	loss/total_loss, 6.97512674331665, 2344
[INFO] 2021-07-12 19:19:45,421 [run_pretraining.py:  535]:	loss/mlm_loss, 6.97512674331665, 2344
[INFO] 2021-07-12 19:19:45,421 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3430000510415994e-05, 2344
[INFO] 2021-07-12 19:19:45,421 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2344
[INFO] 2021-07-12 19:19:45,421 [run_pretraining.py:  558]:	worker_index: 3, step: 2344, cost: 6.975127, mlm loss: 6.975127, speed: 1.092250 steps/s, speed: 8.738001 samples/s, speed: 4473.856693 tokens/s, learning rate: 2.343e-05, loss_scalings: 2814.750488, pp_loss: 6.986877
[INFO] 2021-07-12 19:19:45,421 [run_pretraining.py:  512]:	********exe.run_2344******* 
[INFO] 2021-07-12 19:19:46,340 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:46,341 [run_pretraining.py:  534]:	loss/total_loss, 7.255443096160889, 2345
[INFO] 2021-07-12 19:19:46,341 [run_pretraining.py:  535]:	loss/mlm_loss, 7.255443096160889, 2345
[INFO] 2021-07-12 19:19:46,341 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3439999495167285e-05, 2345
[INFO] 2021-07-12 19:19:46,341 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2345
[INFO] 2021-07-12 19:19:46,341 [run_pretraining.py:  558]:	worker_index: 3, step: 2345, cost: 7.255443, mlm loss: 7.255443, speed: 1.087206 steps/s, speed: 8.697646 samples/s, speed: 4453.194876 tokens/s, learning rate: 2.344e-05, loss_scalings: 2814.750488, pp_loss: 7.354764
[INFO] 2021-07-12 19:19:46,341 [run_pretraining.py:  512]:	********exe.run_2345******* 
[INFO] 2021-07-12 19:19:47,278 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:47,278 [run_pretraining.py:  534]:	loss/total_loss, 7.327386379241943, 2346
[INFO] 2021-07-12 19:19:47,279 [run_pretraining.py:  535]:	loss/mlm_loss, 7.327386379241943, 2346
[INFO] 2021-07-12 19:19:47,279 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.345000029890798e-05, 2346
[INFO] 2021-07-12 19:19:47,279 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2346
[INFO] 2021-07-12 19:19:47,279 [run_pretraining.py:  558]:	worker_index: 3, step: 2346, cost: 7.327386, mlm loss: 7.327386, speed: 1.067341 steps/s, speed: 8.538732 samples/s, speed: 4371.830636 tokens/s, learning rate: 2.345e-05, loss_scalings: 2814.750488, pp_loss: 7.115834
[INFO] 2021-07-12 19:19:47,279 [run_pretraining.py:  512]:	********exe.run_2346******* 
[INFO] 2021-07-12 19:19:48,196 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:48,196 [run_pretraining.py:  534]:	loss/total_loss, 7.439755439758301, 2347
[INFO] 2021-07-12 19:19:48,197 [run_pretraining.py:  535]:	loss/mlm_loss, 7.439755439758301, 2347
[INFO] 2021-07-12 19:19:48,197 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3459999283659272e-05, 2347
[INFO] 2021-07-12 19:19:48,197 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2347
[INFO] 2021-07-12 19:19:48,197 [run_pretraining.py:  558]:	worker_index: 3, step: 2347, cost: 7.439755, mlm loss: 7.439755, speed: 1.090004 steps/s, speed: 8.720030 samples/s, speed: 4464.655456 tokens/s, learning rate: 2.346e-05, loss_scalings: 2814.750488, pp_loss: 7.498377
[INFO] 2021-07-12 19:19:48,197 [run_pretraining.py:  512]:	********exe.run_2347******* 
[INFO] 2021-07-12 19:19:49,111 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:49,112 [run_pretraining.py:  534]:	loss/total_loss, 7.258366584777832, 2348
[INFO] 2021-07-12 19:19:49,112 [run_pretraining.py:  535]:	loss/mlm_loss, 7.258366584777832, 2348
[INFO] 2021-07-12 19:19:49,112 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3469998268410563e-05, 2348
[INFO] 2021-07-12 19:19:49,112 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2348
[INFO] 2021-07-12 19:19:49,112 [run_pretraining.py:  558]:	worker_index: 3, step: 2348, cost: 7.258367, mlm loss: 7.258367, speed: 1.093493 steps/s, speed: 8.747947 samples/s, speed: 4478.949088 tokens/s, learning rate: 2.347e-05, loss_scalings: 2814.750488, pp_loss: 7.417480
[INFO] 2021-07-12 19:19:49,112 [run_pretraining.py:  512]:	********exe.run_2348******* 
[INFO] 2021-07-12 19:19:50,028 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:50,028 [run_pretraining.py:  534]:	loss/total_loss, 7.357470512390137, 2349
[INFO] 2021-07-12 19:19:50,029 [run_pretraining.py:  535]:	loss/mlm_loss, 7.357470512390137, 2349
[INFO] 2021-07-12 19:19:50,029 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.347999907215126e-05, 2349
[INFO] 2021-07-12 19:19:50,029 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2349
[INFO] 2021-07-12 19:19:50,029 [run_pretraining.py:  558]:	worker_index: 3, step: 2349, cost: 7.357471, mlm loss: 7.357471, speed: 1.091400 steps/s, speed: 8.731201 samples/s, speed: 4470.374743 tokens/s, learning rate: 2.348e-05, loss_scalings: 2814.750488, pp_loss: 7.430222
[INFO] 2021-07-12 19:19:50,029 [run_pretraining.py:  512]:	********exe.run_2349******* 
[INFO] 2021-07-12 19:19:50,942 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:50,942 [run_pretraining.py:  534]:	loss/total_loss, 6.8403472900390625, 2350
[INFO] 2021-07-12 19:19:50,942 [run_pretraining.py:  535]:	loss/mlm_loss, 6.8403472900390625, 2350
[INFO] 2021-07-12 19:19:50,942 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3489999875891954e-05, 2350
[INFO] 2021-07-12 19:19:50,942 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2350
[INFO] 2021-07-12 19:19:50,942 [run_pretraining.py:  558]:	worker_index: 3, step: 2350, cost: 6.840347, mlm loss: 6.840347, speed: 1.095281 steps/s, speed: 8.762248 samples/s, speed: 4486.270858 tokens/s, learning rate: 2.349e-05, loss_scalings: 2814.750488, pp_loss: 7.294175
[INFO] 2021-07-12 19:19:50,943 [run_pretraining.py:  512]:	********exe.run_2350******* 
[INFO] 2021-07-12 19:19:51,853 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:51,853 [run_pretraining.py:  534]:	loss/total_loss, 7.391369819641113, 2351
[INFO] 2021-07-12 19:19:51,853 [run_pretraining.py:  535]:	loss/mlm_loss, 7.391369819641113, 2351
[INFO] 2021-07-12 19:19:51,853 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3499998860643245e-05, 2351
[INFO] 2021-07-12 19:19:51,853 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2351
[INFO] 2021-07-12 19:19:51,853 [run_pretraining.py:  558]:	worker_index: 3, step: 2351, cost: 7.391370, mlm loss: 7.391370, speed: 1.098401 steps/s, speed: 8.787204 samples/s, speed: 4499.048641 tokens/s, learning rate: 2.350e-05, loss_scalings: 2814.750488, pp_loss: 7.187413
[INFO] 2021-07-12 19:19:51,854 [run_pretraining.py:  512]:	********exe.run_2351******* 
[INFO] 2021-07-12 19:19:52,765 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:52,766 [run_pretraining.py:  534]:	loss/total_loss, 6.992147922515869, 2352
[INFO] 2021-07-12 19:19:52,766 [run_pretraining.py:  535]:	loss/mlm_loss, 6.992147922515869, 2352
[INFO] 2021-07-12 19:19:52,766 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.350999966438394e-05, 2352
[INFO] 2021-07-12 19:19:52,766 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2352
[INFO] 2021-07-12 19:19:52,766 [run_pretraining.py:  558]:	worker_index: 3, step: 2352, cost: 6.992148, mlm loss: 6.992148, speed: 1.096785 steps/s, speed: 8.774277 samples/s, speed: 4492.429802 tokens/s, learning rate: 2.351e-05, loss_scalings: 2814.750488, pp_loss: 7.216821
[INFO] 2021-07-12 19:19:52,766 [run_pretraining.py:  512]:	********exe.run_2352******* 
[INFO] 2021-07-12 19:19:53,678 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:53,679 [run_pretraining.py:  534]:	loss/total_loss, 7.2171220779418945, 2353
[INFO] 2021-07-12 19:19:53,679 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2171220779418945, 2353
[INFO] 2021-07-12 19:19:53,679 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3520000468124636e-05, 2353
[INFO] 2021-07-12 19:19:53,679 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2353
[INFO] 2021-07-12 19:19:53,679 [run_pretraining.py:  558]:	worker_index: 3, step: 2353, cost: 7.217122, mlm loss: 7.217122, speed: 1.095709 steps/s, speed: 8.765672 samples/s, speed: 4488.024143 tokens/s, learning rate: 2.352e-05, loss_scalings: 2814.750488, pp_loss: 7.360414
[INFO] 2021-07-12 19:19:53,679 [run_pretraining.py:  512]:	********exe.run_2353******* 
[INFO] 2021-07-12 19:19:54,588 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:54,588 [run_pretraining.py:  534]:	loss/total_loss, 7.0460333824157715, 2354
[INFO] 2021-07-12 19:19:54,589 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0460333824157715, 2354
[INFO] 2021-07-12 19:19:54,589 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3529999452875927e-05, 2354
[INFO] 2021-07-12 19:19:54,589 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2354
[INFO] 2021-07-12 19:19:54,589 [run_pretraining.py:  558]:	worker_index: 3, step: 2354, cost: 7.046033, mlm loss: 7.046033, speed: 1.100203 steps/s, speed: 8.801627 samples/s, speed: 4506.432781 tokens/s, learning rate: 2.353e-05, loss_scalings: 2814.750488, pp_loss: 7.119562
[INFO] 2021-07-12 19:19:54,589 [run_pretraining.py:  512]:	********exe.run_2354******* 
[INFO] 2021-07-12 19:19:55,509 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:55,510 [run_pretraining.py:  534]:	loss/total_loss, 6.984902381896973, 2355
[INFO] 2021-07-12 19:19:55,510 [run_pretraining.py:  535]:	loss/mlm_loss, 6.984902381896973, 2355
[INFO] 2021-07-12 19:19:55,510 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3540000256616622e-05, 2355
[INFO] 2021-07-12 19:19:55,510 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2355
[INFO] 2021-07-12 19:19:55,510 [run_pretraining.py:  558]:	worker_index: 3, step: 2355, cost: 6.984902, mlm loss: 6.984902, speed: 1.085983 steps/s, speed: 8.687866 samples/s, speed: 4448.187333 tokens/s, learning rate: 2.354e-05, loss_scalings: 2814.750488, pp_loss: 6.767970
[INFO] 2021-07-12 19:19:55,510 [run_pretraining.py:  512]:	********exe.run_2355******* 
[INFO] 2021-07-12 19:19:56,427 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:56,428 [run_pretraining.py:  534]:	loss/total_loss, 6.952617645263672, 2356
[INFO] 2021-07-12 19:19:56,428 [run_pretraining.py:  535]:	loss/mlm_loss, 6.952617645263672, 2356
[INFO] 2021-07-12 19:19:56,428 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3549999241367914e-05, 2356
[INFO] 2021-07-12 19:19:56,428 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2356
[INFO] 2021-07-12 19:19:56,428 [run_pretraining.py:  558]:	worker_index: 3, step: 2356, cost: 6.952618, mlm loss: 6.952618, speed: 1.090249 steps/s, speed: 8.721989 samples/s, speed: 4465.658147 tokens/s, learning rate: 2.355e-05, loss_scalings: 2814.750488, pp_loss: 7.350541
[INFO] 2021-07-12 19:19:56,428 [run_pretraining.py:  512]:	********exe.run_2356******* 
[INFO] 2021-07-12 19:19:57,346 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:57,346 [run_pretraining.py:  534]:	loss/total_loss, 7.0145063400268555, 2357
[INFO] 2021-07-12 19:19:57,346 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0145063400268555, 2357
[INFO] 2021-07-12 19:19:57,346 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3559998226119205e-05, 2357
[INFO] 2021-07-12 19:19:57,346 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2357
[INFO] 2021-07-12 19:19:57,346 [run_pretraining.py:  558]:	worker_index: 3, step: 2357, cost: 7.014506, mlm loss: 7.014506, speed: 1.089591 steps/s, speed: 8.716730 samples/s, speed: 4462.965594 tokens/s, learning rate: 2.356e-05, loss_scalings: 2814.750488, pp_loss: 7.353006
[INFO] 2021-07-12 19:19:57,347 [run_pretraining.py:  512]:	********exe.run_2357******* 
[INFO] 2021-07-12 19:19:58,262 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:58,262 [run_pretraining.py:  534]:	loss/total_loss, 6.811944007873535, 2358
[INFO] 2021-07-12 19:19:58,262 [run_pretraining.py:  535]:	loss/mlm_loss, 6.811944007873535, 2358
[INFO] 2021-07-12 19:19:58,262 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.35699990298599e-05, 2358
[INFO] 2021-07-12 19:19:58,262 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2358
[INFO] 2021-07-12 19:19:58,263 [run_pretraining.py:  558]:	worker_index: 3, step: 2358, cost: 6.811944, mlm loss: 6.811944, speed: 1.092366 steps/s, speed: 8.738930 samples/s, speed: 4474.332083 tokens/s, learning rate: 2.357e-05, loss_scalings: 2814.750488, pp_loss: 7.271547
[INFO] 2021-07-12 19:19:58,263 [run_pretraining.py:  512]:	********exe.run_2358******* 
[INFO] 2021-07-12 19:19:59,219 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:59,220 [run_pretraining.py:  534]:	loss/total_loss, 6.874763011932373, 2359
[INFO] 2021-07-12 19:19:59,220 [run_pretraining.py:  535]:	loss/mlm_loss, 6.874763011932373, 2359
[INFO] 2021-07-12 19:19:59,220 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3579999833600596e-05, 2359
[INFO] 2021-07-12 19:19:59,220 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2359
[INFO] 2021-07-12 19:19:59,220 [run_pretraining.py:  558]:	worker_index: 3, step: 2359, cost: 6.874763, mlm loss: 6.874763, speed: 1.045134 steps/s, speed: 8.361069 samples/s, speed: 4280.867190 tokens/s, learning rate: 2.358e-05, loss_scalings: 2814.750488, pp_loss: 7.228920
[INFO] 2021-07-12 19:19:59,220 [run_pretraining.py:  512]:	********exe.run_2359******* 
[INFO] 2021-07-12 19:20:00,232 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:00,232 [run_pretraining.py:  534]:	loss/total_loss, 7.559050559997559, 2360
[INFO] 2021-07-12 19:20:00,232 [run_pretraining.py:  535]:	loss/mlm_loss, 7.559050559997559, 2360
[INFO] 2021-07-12 19:20:00,232 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3589998818351887e-05, 2360
[INFO] 2021-07-12 19:20:00,232 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2360
[INFO] 2021-07-12 19:20:00,233 [run_pretraining.py:  558]:	worker_index: 3, step: 2360, cost: 7.559051, mlm loss: 7.559051, speed: 0.988252 steps/s, speed: 7.906019 samples/s, speed: 4047.881569 tokens/s, learning rate: 2.359e-05, loss_scalings: 2814.750488, pp_loss: 7.234096
[INFO] 2021-07-12 19:20:00,233 [run_pretraining.py:  512]:	********exe.run_2360******* 
[INFO] 2021-07-12 19:20:01,196 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:01,196 [run_pretraining.py:  534]:	loss/total_loss, 7.87736701965332, 2361
[INFO] 2021-07-12 19:20:01,197 [run_pretraining.py:  535]:	loss/mlm_loss, 7.87736701965332, 2361
[INFO] 2021-07-12 19:20:01,197 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3599999622092582e-05, 2361
[INFO] 2021-07-12 19:20:01,197 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2361
[INFO] 2021-07-12 19:20:01,197 [run_pretraining.py:  558]:	worker_index: 3, step: 2361, cost: 7.877367, mlm loss: 7.877367, speed: 1.037748 steps/s, speed: 8.301983 samples/s, speed: 4250.615313 tokens/s, learning rate: 2.360e-05, loss_scalings: 2814.750488, pp_loss: 7.332284
[INFO] 2021-07-12 19:20:01,197 [run_pretraining.py:  512]:	********exe.run_2361******* 
[INFO] 2021-07-12 19:20:02,184 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:02,184 [run_pretraining.py:  534]:	loss/total_loss, 7.544464111328125, 2362
[INFO] 2021-07-12 19:20:02,184 [run_pretraining.py:  535]:	loss/mlm_loss, 7.544464111328125, 2362
[INFO] 2021-07-12 19:20:02,184 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3610000425833277e-05, 2362
[INFO] 2021-07-12 19:20:02,184 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2362
[INFO] 2021-07-12 19:20:02,184 [run_pretraining.py:  558]:	worker_index: 3, step: 2362, cost: 7.544464, mlm loss: 7.544464, speed: 1.013085 steps/s, speed: 8.104681 samples/s, speed: 4149.596555 tokens/s, learning rate: 2.361e-05, loss_scalings: 2814.750488, pp_loss: 7.402336
[INFO] 2021-07-12 19:20:02,185 [run_pretraining.py:  512]:	********exe.run_2362******* 
[INFO] 2021-07-12 19:20:03,152 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:03,152 [run_pretraining.py:  534]:	loss/total_loss, 7.183696269989014, 2363
[INFO] 2021-07-12 19:20:03,152 [run_pretraining.py:  535]:	loss/mlm_loss, 7.183696269989014, 2363
[INFO] 2021-07-12 19:20:03,152 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.361999941058457e-05, 2363
[INFO] 2021-07-12 19:20:03,152 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2363
[INFO] 2021-07-12 19:20:03,153 [run_pretraining.py:  558]:	worker_index: 3, step: 2363, cost: 7.183696, mlm loss: 7.183696, speed: 1.033652 steps/s, speed: 8.269217 samples/s, speed: 4233.839127 tokens/s, learning rate: 2.362e-05, loss_scalings: 2814.750488, pp_loss: 7.725266
[INFO] 2021-07-12 19:20:03,153 [run_pretraining.py:  512]:	********exe.run_2363******* 
[INFO] 2021-07-12 19:20:04,138 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:04,138 [run_pretraining.py:  534]:	loss/total_loss, 7.728641510009766, 2364
[INFO] 2021-07-12 19:20:04,138 [run_pretraining.py:  535]:	loss/mlm_loss, 7.728641510009766, 2364
[INFO] 2021-07-12 19:20:04,138 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3630000214325264e-05, 2364
[INFO] 2021-07-12 19:20:04,139 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2364
[INFO] 2021-07-12 19:20:04,139 [run_pretraining.py:  558]:	worker_index: 3, step: 2364, cost: 7.728642, mlm loss: 7.728642, speed: 1.014801 steps/s, speed: 8.118407 samples/s, speed: 4156.624443 tokens/s, learning rate: 2.363e-05, loss_scalings: 2814.750488, pp_loss: 7.598318
[INFO] 2021-07-12 19:20:04,139 [run_pretraining.py:  512]:	********exe.run_2364******* 
[INFO] 2021-07-12 19:20:05,108 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:05,108 [run_pretraining.py:  534]:	loss/total_loss, 6.657977104187012, 2365
[INFO] 2021-07-12 19:20:05,108 [run_pretraining.py:  535]:	loss/mlm_loss, 6.657977104187012, 2365
[INFO] 2021-07-12 19:20:05,108 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3639999199076556e-05, 2365
[INFO] 2021-07-12 19:20:05,108 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2365
[INFO] 2021-07-12 19:20:05,108 [run_pretraining.py:  558]:	worker_index: 3, step: 2365, cost: 6.657977, mlm loss: 6.657977, speed: 1.031740 steps/s, speed: 8.253923 samples/s, speed: 4226.008348 tokens/s, learning rate: 2.364e-05, loss_scalings: 2814.750488, pp_loss: 7.379182
[INFO] 2021-07-12 19:20:05,109 [run_pretraining.py:  512]:	********exe.run_2365******* 
[INFO] 2021-07-12 19:20:06,086 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:06,087 [run_pretraining.py:  534]:	loss/total_loss, 7.340071201324463, 2366
[INFO] 2021-07-12 19:20:06,087 [run_pretraining.py:  535]:	loss/mlm_loss, 7.340071201324463, 2366
[INFO] 2021-07-12 19:20:06,087 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3649998183827847e-05, 2366
[INFO] 2021-07-12 19:20:06,087 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2366
[INFO] 2021-07-12 19:20:06,087 [run_pretraining.py:  558]:	worker_index: 3, step: 2366, cost: 7.340071, mlm loss: 7.340071, speed: 1.022255 steps/s, speed: 8.178040 samples/s, speed: 4187.156393 tokens/s, learning rate: 2.365e-05, loss_scalings: 2814.750488, pp_loss: 7.262188
[INFO] 2021-07-12 19:20:06,087 [run_pretraining.py:  512]:	********exe.run_2366******* 
[INFO] 2021-07-12 19:20:07,068 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:07,068 [run_pretraining.py:  534]:	loss/total_loss, 7.199798583984375, 2367
[INFO] 2021-07-12 19:20:07,068 [run_pretraining.py:  535]:	loss/mlm_loss, 7.199798583984375, 2367
[INFO] 2021-07-12 19:20:07,069 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3659998987568542e-05, 2367
[INFO] 2021-07-12 19:20:07,069 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2367
[INFO] 2021-07-12 19:20:07,069 [run_pretraining.py:  558]:	worker_index: 3, step: 2367, cost: 7.199799, mlm loss: 7.199799, speed: 1.019682 steps/s, speed: 8.157454 samples/s, speed: 4176.616600 tokens/s, learning rate: 2.366e-05, loss_scalings: 2814.750488, pp_loss: 7.094831
[INFO] 2021-07-12 19:20:07,069 [run_pretraining.py:  512]:	********exe.run_2367******* 
[INFO] 2021-07-12 19:20:08,038 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:08,039 [run_pretraining.py:  534]:	loss/total_loss, 7.005397319793701, 2368
[INFO] 2021-07-12 19:20:08,039 [run_pretraining.py:  535]:	loss/mlm_loss, 7.005397319793701, 2368
[INFO] 2021-07-12 19:20:08,039 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3669999791309237e-05, 2368
[INFO] 2021-07-12 19:20:08,039 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2368
[INFO] 2021-07-12 19:20:08,039 [run_pretraining.py:  558]:	worker_index: 3, step: 2368, cost: 7.005397, mlm loss: 7.005397, speed: 1.031417 steps/s, speed: 8.251333 samples/s, speed: 4224.682313 tokens/s, learning rate: 2.367e-05, loss_scalings: 2814.750488, pp_loss: 7.379609
[INFO] 2021-07-12 19:20:08,039 [run_pretraining.py:  512]:	********exe.run_2368******* 
[INFO] 2021-07-12 19:20:09,018 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:09,018 [run_pretraining.py:  534]:	loss/total_loss, 7.6954240798950195, 2369
[INFO] 2021-07-12 19:20:09,018 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6954240798950195, 2369
[INFO] 2021-07-12 19:20:09,019 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.367999877606053e-05, 2369
[INFO] 2021-07-12 19:20:09,019 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2369
[INFO] 2021-07-12 19:20:09,019 [run_pretraining.py:  558]:	worker_index: 3, step: 2369, cost: 7.695424, mlm loss: 7.695424, speed: 1.021259 steps/s, speed: 8.170075 samples/s, speed: 4183.078317 tokens/s, learning rate: 2.368e-05, loss_scalings: 2814.750488, pp_loss: 7.137900
[INFO] 2021-07-12 19:20:09,019 [run_pretraining.py:  512]:	********exe.run_2369******* 
[INFO] 2021-07-12 19:20:10,008 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:10,009 [run_pretraining.py:  534]:	loss/total_loss, 7.378684043884277, 2370
[INFO] 2021-07-12 19:20:10,009 [run_pretraining.py:  535]:	loss/mlm_loss, 7.378684043884277, 2370
[INFO] 2021-07-12 19:20:10,009 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3689999579801224e-05, 2370
[INFO] 2021-07-12 19:20:10,009 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2370
[INFO] 2021-07-12 19:20:10,009 [run_pretraining.py:  558]:	worker_index: 3, step: 2370, cost: 7.378684, mlm loss: 7.378684, speed: 1.010131 steps/s, speed: 8.081045 samples/s, speed: 4137.495261 tokens/s, learning rate: 2.369e-05, loss_scalings: 2814.750488, pp_loss: 7.229681
[INFO] 2021-07-12 19:20:10,009 [run_pretraining.py:  512]:	********exe.run_2370******* 
[INFO] 2021-07-12 19:20:11,007 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:11,008 [run_pretraining.py:  534]:	loss/total_loss, 6.795519828796387, 2371
[INFO] 2021-07-12 19:20:11,008 [run_pretraining.py:  535]:	loss/mlm_loss, 6.795519828796387, 2371
[INFO] 2021-07-12 19:20:11,008 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.370000038354192e-05, 2371
[INFO] 2021-07-12 19:20:11,008 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2371
[INFO] 2021-07-12 19:20:11,008 [run_pretraining.py:  558]:	worker_index: 3, step: 2371, cost: 6.795520, mlm loss: 6.795520, speed: 1.002085 steps/s, speed: 8.016684 samples/s, speed: 4104.542192 tokens/s, learning rate: 2.370e-05, loss_scalings: 2814.750488, pp_loss: 7.222163
[INFO] 2021-07-12 19:20:11,008 [run_pretraining.py:  512]:	********exe.run_2371******* 
[INFO] 2021-07-12 19:20:11,981 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:11,982 [run_pretraining.py:  534]:	loss/total_loss, 7.80009126663208, 2372
[INFO] 2021-07-12 19:20:11,982 [run_pretraining.py:  535]:	loss/mlm_loss, 7.80009126663208, 2372
[INFO] 2021-07-12 19:20:11,982 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.370999936829321e-05, 2372
[INFO] 2021-07-12 19:20:11,982 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2372
[INFO] 2021-07-12 19:20:11,982 [run_pretraining.py:  558]:	worker_index: 3, step: 2372, cost: 7.800091, mlm loss: 7.800091, speed: 1.027121 steps/s, speed: 8.216966 samples/s, speed: 4207.086518 tokens/s, learning rate: 2.371e-05, loss_scalings: 2814.750488, pp_loss: 7.276999
[INFO] 2021-07-12 19:20:11,982 [run_pretraining.py:  512]:	********exe.run_2372******* 
[INFO] 2021-07-12 19:20:12,954 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:12,955 [run_pretraining.py:  534]:	loss/total_loss, 7.433624744415283, 2373
[INFO] 2021-07-12 19:20:12,955 [run_pretraining.py:  535]:	loss/mlm_loss, 7.433624744415283, 2373
[INFO] 2021-07-12 19:20:12,955 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3720000172033906e-05, 2373
[INFO] 2021-07-12 19:20:12,955 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2373
[INFO] 2021-07-12 19:20:12,955 [run_pretraining.py:  558]:	worker_index: 3, step: 2373, cost: 7.433625, mlm loss: 7.433625, speed: 1.028740 steps/s, speed: 8.229917 samples/s, speed: 4213.717345 tokens/s, learning rate: 2.372e-05, loss_scalings: 2814.750488, pp_loss: 7.293140
[INFO] 2021-07-12 19:20:12,955 [run_pretraining.py:  512]:	********exe.run_2373******* 
[INFO] 2021-07-12 19:20:13,927 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:13,928 [run_pretraining.py:  534]:	loss/total_loss, 7.167758941650391, 2374
[INFO] 2021-07-12 19:20:13,928 [run_pretraining.py:  535]:	loss/mlm_loss, 7.167758941650391, 2374
[INFO] 2021-07-12 19:20:13,928 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3729999156785198e-05, 2374
[INFO] 2021-07-12 19:20:13,928 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2374
[INFO] 2021-07-12 19:20:13,928 [run_pretraining.py:  558]:	worker_index: 3, step: 2374, cost: 7.167759, mlm loss: 7.167759, speed: 1.027965 steps/s, speed: 8.223720 samples/s, speed: 4210.544820 tokens/s, learning rate: 2.373e-05, loss_scalings: 2814.750488, pp_loss: 6.943415
[INFO] 2021-07-12 19:20:13,928 [run_pretraining.py:  512]:	********exe.run_2374******* 
[INFO] 2021-07-12 19:20:14,905 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:14,906 [run_pretraining.py:  534]:	loss/total_loss, 7.075473308563232, 2375
[INFO] 2021-07-12 19:20:14,906 [run_pretraining.py:  535]:	loss/mlm_loss, 7.075473308563232, 2375
[INFO] 2021-07-12 19:20:14,906 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.373999814153649e-05, 2375
[INFO] 2021-07-12 19:20:14,906 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2375
[INFO] 2021-07-12 19:20:14,906 [run_pretraining.py:  558]:	worker_index: 3, step: 2375, cost: 7.075473, mlm loss: 7.075473, speed: 1.023130 steps/s, speed: 8.185038 samples/s, speed: 4190.739416 tokens/s, learning rate: 2.374e-05, loss_scalings: 2814.750488, pp_loss: 6.915583
[INFO] 2021-07-12 19:20:14,906 [run_pretraining.py:  512]:	********exe.run_2375******* 
[INFO] 2021-07-12 19:20:15,891 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:15,892 [run_pretraining.py:  534]:	loss/total_loss, 6.830922603607178, 2376
[INFO] 2021-07-12 19:20:15,892 [run_pretraining.py:  535]:	loss/mlm_loss, 6.830922603607178, 2376
[INFO] 2021-07-12 19:20:15,892 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3749998945277184e-05, 2376
[INFO] 2021-07-12 19:20:15,892 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2376
[INFO] 2021-07-12 19:20:15,892 [run_pretraining.py:  558]:	worker_index: 3, step: 2376, cost: 6.830923, mlm loss: 6.830923, speed: 1.015277 steps/s, speed: 8.122216 samples/s, speed: 4158.574374 tokens/s, learning rate: 2.375e-05, loss_scalings: 2814.750488, pp_loss: 7.073260
[INFO] 2021-07-12 19:20:15,892 [run_pretraining.py:  512]:	********exe.run_2376******* 
[INFO] 2021-07-12 19:20:16,861 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:16,862 [run_pretraining.py:  534]:	loss/total_loss, 6.854010581970215, 2377
[INFO] 2021-07-12 19:20:16,862 [run_pretraining.py:  535]:	loss/mlm_loss, 6.854010581970215, 2377
[INFO] 2021-07-12 19:20:16,862 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.375999974901788e-05, 2377
[INFO] 2021-07-12 19:20:16,862 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2377
[INFO] 2021-07-12 19:20:16,862 [run_pretraining.py:  558]:	worker_index: 3, step: 2377, cost: 6.854011, mlm loss: 6.854011, speed: 1.031336 steps/s, speed: 8.250685 samples/s, speed: 4224.350934 tokens/s, learning rate: 2.376e-05, loss_scalings: 2814.750488, pp_loss: 6.996982
[INFO] 2021-07-12 19:20:16,862 [run_pretraining.py:  512]:	********exe.run_2377******* 
[INFO] 2021-07-12 19:20:17,829 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:17,830 [run_pretraining.py:  534]:	loss/total_loss, 7.014038562774658, 2378
[INFO] 2021-07-12 19:20:17,830 [run_pretraining.py:  535]:	loss/mlm_loss, 7.014038562774658, 2378
[INFO] 2021-07-12 19:20:17,830 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.376999873376917e-05, 2378
[INFO] 2021-07-12 19:20:17,830 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2378
[INFO] 2021-07-12 19:20:17,830 [run_pretraining.py:  558]:	worker_index: 3, step: 2378, cost: 7.014039, mlm loss: 7.014039, speed: 1.033765 steps/s, speed: 8.270122 samples/s, speed: 4234.302445 tokens/s, learning rate: 2.377e-05, loss_scalings: 2814.750488, pp_loss: 6.712152
[INFO] 2021-07-12 19:20:17,830 [run_pretraining.py:  512]:	********exe.run_2378******* 
[INFO] 2021-07-12 19:20:18,739 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:18,739 [run_pretraining.py:  534]:	loss/total_loss, 7.708805561065674, 2379
[INFO] 2021-07-12 19:20:18,739 [run_pretraining.py:  535]:	loss/mlm_loss, 7.708805561065674, 2379
[INFO] 2021-07-12 19:20:18,739 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3779999537509866e-05, 2379
[INFO] 2021-07-12 19:20:18,739 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2379
[INFO] 2021-07-12 19:20:18,739 [run_pretraining.py:  558]:	worker_index: 3, step: 2379, cost: 7.708806, mlm loss: 7.708806, speed: 1.100537 steps/s, speed: 8.804294 samples/s, speed: 4507.798494 tokens/s, learning rate: 2.378e-05, loss_scalings: 2814.750488, pp_loss: 7.437503
[INFO] 2021-07-12 19:20:18,740 [run_pretraining.py:  512]:	********exe.run_2379******* 
[INFO] 2021-07-12 19:20:19,704 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:19,705 [run_pretraining.py:  534]:	loss/total_loss, 7.452230453491211, 2380
[INFO] 2021-07-12 19:20:19,705 [run_pretraining.py:  535]:	loss/mlm_loss, 7.452230453491211, 2380
[INFO] 2021-07-12 19:20:19,705 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.379000034125056e-05, 2380
[INFO] 2021-07-12 19:20:19,705 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2380
[INFO] 2021-07-12 19:20:19,705 [run_pretraining.py:  558]:	worker_index: 3, step: 2380, cost: 7.452230, mlm loss: 7.452230, speed: 1.036194 steps/s, speed: 8.289554 samples/s, speed: 4244.251672 tokens/s, learning rate: 2.379e-05, loss_scalings: 2814.750488, pp_loss: 7.160740
[INFO] 2021-07-12 19:20:19,705 [run_pretraining.py:  512]:	********exe.run_2380******* 
[INFO] 2021-07-12 19:20:20,609 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:20,609 [run_pretraining.py:  534]:	loss/total_loss, 7.417934417724609, 2381
[INFO] 2021-07-12 19:20:20,609 [run_pretraining.py:  535]:	loss/mlm_loss, 7.417934417724609, 2381
[INFO] 2021-07-12 19:20:20,609 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3799999326001853e-05, 2381
[INFO] 2021-07-12 19:20:20,609 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2381
[INFO] 2021-07-12 19:20:20,610 [run_pretraining.py:  558]:	worker_index: 3, step: 2381, cost: 7.417934, mlm loss: 7.417934, speed: 1.106468 steps/s, speed: 8.851742 samples/s, speed: 4532.092015 tokens/s, learning rate: 2.380e-05, loss_scalings: 2814.750488, pp_loss: 7.113161
[INFO] 2021-07-12 19:20:20,610 [run_pretraining.py:  512]:	********exe.run_2381******* 
[INFO] 2021-07-12 19:20:21,514 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:21,514 [run_pretraining.py:  534]:	loss/total_loss, 6.686092376708984, 2382
[INFO] 2021-07-12 19:20:21,515 [run_pretraining.py:  535]:	loss/mlm_loss, 6.686092376708984, 2382
[INFO] 2021-07-12 19:20:21,515 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3810000129742548e-05, 2382
[INFO] 2021-07-12 19:20:21,515 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2382
[INFO] 2021-07-12 19:20:21,515 [run_pretraining.py:  558]:	worker_index: 3, step: 2382, cost: 6.686092, mlm loss: 6.686092, speed: 1.105429 steps/s, speed: 8.843435 samples/s, speed: 4527.838561 tokens/s, learning rate: 2.381e-05, loss_scalings: 2814.750488, pp_loss: 7.174328
[INFO] 2021-07-12 19:20:21,515 [run_pretraining.py:  512]:	********exe.run_2382******* 
[INFO] 2021-07-12 19:20:22,423 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:22,423 [run_pretraining.py:  534]:	loss/total_loss, 7.2354021072387695, 2383
[INFO] 2021-07-12 19:20:22,423 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2354021072387695, 2383
[INFO] 2021-07-12 19:20:22,423 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.381999911449384e-05, 2383
[INFO] 2021-07-12 19:20:22,423 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2383
[INFO] 2021-07-12 19:20:22,424 [run_pretraining.py:  558]:	worker_index: 3, step: 2383, cost: 7.235402, mlm loss: 7.235402, speed: 1.101230 steps/s, speed: 8.809837 samples/s, speed: 4510.636620 tokens/s, learning rate: 2.382e-05, loss_scalings: 2814.750488, pp_loss: 7.203155
[INFO] 2021-07-12 19:20:22,424 [run_pretraining.py:  512]:	********exe.run_2383******* 
[INFO] 2021-07-12 19:20:23,329 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:23,329 [run_pretraining.py:  534]:	loss/total_loss, 6.816225528717041, 2384
[INFO] 2021-07-12 19:20:23,329 [run_pretraining.py:  535]:	loss/mlm_loss, 6.816225528717041, 2384
[INFO] 2021-07-12 19:20:23,329 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.382999809924513e-05, 2384
[INFO] 2021-07-12 19:20:23,329 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2384
[INFO] 2021-07-12 19:20:23,330 [run_pretraining.py:  558]:	worker_index: 3, step: 2384, cost: 6.816226, mlm loss: 6.816226, speed: 1.104520 steps/s, speed: 8.836162 samples/s, speed: 4524.114844 tokens/s, learning rate: 2.383e-05, loss_scalings: 2814.750488, pp_loss: 7.360724
[INFO] 2021-07-12 19:20:23,330 [run_pretraining.py:  512]:	********exe.run_2384******* 
[INFO] 2021-07-12 19:20:24,229 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:24,230 [run_pretraining.py:  534]:	loss/total_loss, 6.403934001922607, 2385
[INFO] 2021-07-12 19:20:24,230 [run_pretraining.py:  535]:	loss/mlm_loss, 6.403934001922607, 2385
[INFO] 2021-07-12 19:20:24,230 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3839998902985826e-05, 2385
[INFO] 2021-07-12 19:20:24,230 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2385
[INFO] 2021-07-12 19:20:24,230 [run_pretraining.py:  558]:	worker_index: 3, step: 2385, cost: 6.403934, mlm loss: 6.403934, speed: 1.111433 steps/s, speed: 8.891465 samples/s, speed: 4552.429973 tokens/s, learning rate: 2.384e-05, loss_scalings: 2814.750488, pp_loss: 6.808725
[INFO] 2021-07-12 19:20:24,230 [run_pretraining.py:  512]:	********exe.run_2385******* 
[INFO] 2021-07-12 19:20:25,139 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:25,140 [run_pretraining.py:  534]:	loss/total_loss, 6.833255767822266, 2386
[INFO] 2021-07-12 19:20:25,140 [run_pretraining.py:  535]:	loss/mlm_loss, 6.833255767822266, 2386
[INFO] 2021-07-12 19:20:25,140 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.384999970672652e-05, 2386
[INFO] 2021-07-12 19:20:25,140 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2386
[INFO] 2021-07-12 19:20:25,140 [run_pretraining.py:  558]:	worker_index: 3, step: 2386, cost: 6.833256, mlm loss: 6.833256, speed: 1.099268 steps/s, speed: 8.794143 samples/s, speed: 4502.601382 tokens/s, learning rate: 2.385e-05, loss_scalings: 2814.750488, pp_loss: 7.284089
[INFO] 2021-07-12 19:20:25,140 [run_pretraining.py:  512]:	********exe.run_2386******* 
[INFO] 2021-07-12 19:20:26,046 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:26,047 [run_pretraining.py:  534]:	loss/total_loss, 7.684384822845459, 2387
[INFO] 2021-07-12 19:20:26,047 [run_pretraining.py:  535]:	loss/mlm_loss, 7.684384822845459, 2387
[INFO] 2021-07-12 19:20:26,047 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3859998691477813e-05, 2387
[INFO] 2021-07-12 19:20:26,047 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2387
[INFO] 2021-07-12 19:20:26,047 [run_pretraining.py:  558]:	worker_index: 3, step: 2387, cost: 7.684385, mlm loss: 7.684385, speed: 1.103364 steps/s, speed: 8.826915 samples/s, speed: 4519.380526 tokens/s, learning rate: 2.386e-05, loss_scalings: 2814.750488, pp_loss: 7.505136
[INFO] 2021-07-12 19:20:26,047 [run_pretraining.py:  512]:	********exe.run_2387******* 
[INFO] 2021-07-12 19:20:26,951 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:26,952 [run_pretraining.py:  534]:	loss/total_loss, 8.19703197479248, 2388
[INFO] 2021-07-12 19:20:26,952 [run_pretraining.py:  535]:	loss/mlm_loss, 8.19703197479248, 2388
[INFO] 2021-07-12 19:20:26,952 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3869999495218508e-05, 2388
[INFO] 2021-07-12 19:20:26,952 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2388
[INFO] 2021-07-12 19:20:26,952 [run_pretraining.py:  558]:	worker_index: 3, step: 2388, cost: 8.197032, mlm loss: 8.197032, speed: 1.105820 steps/s, speed: 8.846557 samples/s, speed: 4529.436999 tokens/s, learning rate: 2.387e-05, loss_scalings: 2814.750488, pp_loss: 7.590879
[INFO] 2021-07-12 19:20:26,952 [run_pretraining.py:  512]:	********exe.run_2388******* 
[INFO] 2021-07-12 19:20:27,861 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:27,862 [run_pretraining.py:  534]:	loss/total_loss, 7.198398590087891, 2389
[INFO] 2021-07-12 19:20:27,862 [run_pretraining.py:  535]:	loss/mlm_loss, 7.198398590087891, 2389
[INFO] 2021-07-12 19:20:27,862 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3880000298959203e-05, 2389
[INFO] 2021-07-12 19:20:27,862 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2389
[INFO] 2021-07-12 19:20:27,862 [run_pretraining.py:  558]:	worker_index: 3, step: 2389, cost: 7.198399, mlm loss: 7.198399, speed: 1.100084 steps/s, speed: 8.800673 samples/s, speed: 4505.944636 tokens/s, learning rate: 2.388e-05, loss_scalings: 2814.750488, pp_loss: 7.529847
[INFO] 2021-07-12 19:20:27,862 [run_pretraining.py:  512]:	********exe.run_2389******* 
[INFO] 2021-07-12 19:20:28,816 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:28,816 [run_pretraining.py:  534]:	loss/total_loss, 6.785216331481934, 2390
[INFO] 2021-07-12 19:20:28,817 [run_pretraining.py:  535]:	loss/mlm_loss, 6.785216331481934, 2390
[INFO] 2021-07-12 19:20:28,817 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3889999283710495e-05, 2390
[INFO] 2021-07-12 19:20:28,817 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2390
[INFO] 2021-07-12 19:20:28,817 [run_pretraining.py:  558]:	worker_index: 3, step: 2390, cost: 6.785216, mlm loss: 6.785216, speed: 1.047907 steps/s, speed: 8.383255 samples/s, speed: 4292.226709 tokens/s, learning rate: 2.389e-05, loss_scalings: 2814.750488, pp_loss: 7.412220
[INFO] 2021-07-12 19:20:28,817 [run_pretraining.py:  512]:	********exe.run_2390******* 
[INFO] 2021-07-12 19:20:29,721 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:29,721 [run_pretraining.py:  534]:	loss/total_loss, 6.9726996421813965, 2391
[INFO] 2021-07-12 19:20:29,721 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9726996421813965, 2391
[INFO] 2021-07-12 19:20:29,721 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3899998268461786e-05, 2391
[INFO] 2021-07-12 19:20:29,721 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2391
[INFO] 2021-07-12 19:20:29,721 [run_pretraining.py:  558]:	worker_index: 3, step: 2391, cost: 6.972700, mlm loss: 6.972700, speed: 1.106103 steps/s, speed: 8.848824 samples/s, speed: 4530.598037 tokens/s, learning rate: 2.390e-05, loss_scalings: 2814.750488, pp_loss: 7.697951
[INFO] 2021-07-12 19:20:29,722 [run_pretraining.py:  512]:	********exe.run_2391******* 
[INFO] 2021-07-12 19:20:30,627 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:30,628 [run_pretraining.py:  534]:	loss/total_loss, 7.108878135681152, 2392
[INFO] 2021-07-12 19:20:30,628 [run_pretraining.py:  535]:	loss/mlm_loss, 7.108878135681152, 2392
[INFO] 2021-07-12 19:20:30,628 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.390999907220248e-05, 2392
[INFO] 2021-07-12 19:20:30,628 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2392
[INFO] 2021-07-12 19:20:30,628 [run_pretraining.py:  558]:	worker_index: 3, step: 2392, cost: 7.108878, mlm loss: 7.108878, speed: 1.103937 steps/s, speed: 8.831497 samples/s, speed: 4521.726213 tokens/s, learning rate: 2.391e-05, loss_scalings: 2814.750488, pp_loss: 7.519079
[INFO] 2021-07-12 19:20:30,628 [run_pretraining.py:  512]:	********exe.run_2392******* 
[INFO] 2021-07-12 19:20:31,533 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:31,534 [run_pretraining.py:  534]:	loss/total_loss, 7.586991310119629, 2393
[INFO] 2021-07-12 19:20:31,534 [run_pretraining.py:  535]:	loss/mlm_loss, 7.586991310119629, 2393
[INFO] 2021-07-12 19:20:31,534 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3919999875943176e-05, 2393
[INFO] 2021-07-12 19:20:31,534 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2393
[INFO] 2021-07-12 19:20:31,534 [run_pretraining.py:  558]:	worker_index: 3, step: 2393, cost: 7.586991, mlm loss: 7.586991, speed: 1.104092 steps/s, speed: 8.832738 samples/s, speed: 4522.361824 tokens/s, learning rate: 2.392e-05, loss_scalings: 2814.750488, pp_loss: 7.463372
[INFO] 2021-07-12 19:20:31,534 [run_pretraining.py:  512]:	********exe.run_2393******* 
[INFO] 2021-07-12 19:20:32,444 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:32,444 [run_pretraining.py:  534]:	loss/total_loss, 7.28587532043457, 2394
[INFO] 2021-07-12 19:20:32,445 [run_pretraining.py:  535]:	loss/mlm_loss, 7.28587532043457, 2394
[INFO] 2021-07-12 19:20:32,445 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3929998860694468e-05, 2394
[INFO] 2021-07-12 19:20:32,445 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2394
[INFO] 2021-07-12 19:20:32,445 [run_pretraining.py:  558]:	worker_index: 3, step: 2394, cost: 7.285875, mlm loss: 7.285875, speed: 1.099141 steps/s, speed: 8.793127 samples/s, speed: 4502.081032 tokens/s, learning rate: 2.393e-05, loss_scalings: 2814.750488, pp_loss: 6.981492
[INFO] 2021-07-12 19:20:32,445 [run_pretraining.py:  512]:	********exe.run_2394******* 
[INFO] 2021-07-12 19:20:33,354 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:33,354 [run_pretraining.py:  534]:	loss/total_loss, 7.336318016052246, 2395
[INFO] 2021-07-12 19:20:33,354 [run_pretraining.py:  535]:	loss/mlm_loss, 7.336318016052246, 2395
[INFO] 2021-07-12 19:20:33,354 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3939999664435163e-05, 2395
[INFO] 2021-07-12 19:20:33,354 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2395
[INFO] 2021-07-12 19:20:33,354 [run_pretraining.py:  558]:	worker_index: 3, step: 2395, cost: 7.336318, mlm loss: 7.336318, speed: 1.100005 steps/s, speed: 8.800036 samples/s, speed: 4505.618477 tokens/s, learning rate: 2.394e-05, loss_scalings: 2814.750488, pp_loss: 7.559279
[INFO] 2021-07-12 19:20:33,355 [run_pretraining.py:  512]:	********exe.run_2395******* 
[INFO] 2021-07-12 19:20:34,262 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:34,262 [run_pretraining.py:  534]:	loss/total_loss, 7.037685871124268, 2396
[INFO] 2021-07-12 19:20:34,262 [run_pretraining.py:  535]:	loss/mlm_loss, 7.037685871124268, 2396
[INFO] 2021-07-12 19:20:34,262 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3949998649186455e-05, 2396
[INFO] 2021-07-12 19:20:34,262 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2396
[INFO] 2021-07-12 19:20:34,263 [run_pretraining.py:  558]:	worker_index: 3, step: 2396, cost: 7.037686, mlm loss: 7.037686, speed: 1.101976 steps/s, speed: 8.815811 samples/s, speed: 4513.695330 tokens/s, learning rate: 2.395e-05, loss_scalings: 2814.750488, pp_loss: 7.251240
[INFO] 2021-07-12 19:20:34,263 [run_pretraining.py:  512]:	********exe.run_2396******* 
[INFO] 2021-07-12 19:20:35,169 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:35,170 [run_pretraining.py:  534]:	loss/total_loss, 7.744688510894775, 2397
[INFO] 2021-07-12 19:20:35,170 [run_pretraining.py:  535]:	loss/mlm_loss, 7.744688510894775, 2397
[INFO] 2021-07-12 19:20:35,170 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.395999945292715e-05, 2397
[INFO] 2021-07-12 19:20:35,170 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2397
[INFO] 2021-07-12 19:20:35,170 [run_pretraining.py:  558]:	worker_index: 3, step: 2397, cost: 7.744689, mlm loss: 7.744689, speed: 1.102657 steps/s, speed: 8.821253 samples/s, speed: 4516.481519 tokens/s, learning rate: 2.396e-05, loss_scalings: 2814.750488, pp_loss: 7.448514
[INFO] 2021-07-12 19:20:35,170 [run_pretraining.py:  512]:	********exe.run_2397******* 
[INFO] 2021-07-12 19:20:36,074 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:36,075 [run_pretraining.py:  534]:	loss/total_loss, 7.074772834777832, 2398
[INFO] 2021-07-12 19:20:36,075 [run_pretraining.py:  535]:	loss/mlm_loss, 7.074772834777832, 2398
[INFO] 2021-07-12 19:20:36,075 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3970000256667845e-05, 2398
[INFO] 2021-07-12 19:20:36,075 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2398
[INFO] 2021-07-12 19:20:36,075 [run_pretraining.py:  558]:	worker_index: 3, step: 2398, cost: 7.074773, mlm loss: 7.074773, speed: 1.105570 steps/s, speed: 8.844563 samples/s, speed: 4528.416208 tokens/s, learning rate: 2.397e-05, loss_scalings: 2814.750488, pp_loss: 7.364142
[INFO] 2021-07-12 19:20:36,075 [run_pretraining.py:  512]:	********exe.run_2398******* 
[INFO] 2021-07-12 19:20:36,976 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:36,976 [run_pretraining.py:  534]:	loss/total_loss, 7.37327241897583, 2399
[INFO] 2021-07-12 19:20:36,977 [run_pretraining.py:  535]:	loss/mlm_loss, 7.37327241897583, 2399
[INFO] 2021-07-12 19:20:36,977 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3979999241419137e-05, 2399
[INFO] 2021-07-12 19:20:36,977 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2399
[INFO] 2021-07-12 19:20:36,977 [run_pretraining.py:  558]:	worker_index: 3, step: 2399, cost: 7.373272, mlm loss: 7.373272, speed: 1.110024 steps/s, speed: 8.880189 samples/s, speed: 4546.656563 tokens/s, learning rate: 2.398e-05, loss_scalings: 2814.750488, pp_loss: 7.273800
[INFO] 2021-07-12 19:20:36,977 [run_pretraining.py:  512]:	********exe.run_2399******* 
[INFO] 2021-07-12 19:20:37,879 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:37,879 [run_pretraining.py:  534]:	loss/total_loss, 7.387930393218994, 2400
[INFO] 2021-07-12 19:20:37,879 [run_pretraining.py:  535]:	loss/mlm_loss, 7.387930393218994, 2400
[INFO] 2021-07-12 19:20:37,879 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3989998226170428e-05, 2400
[INFO] 2021-07-12 19:20:37,879 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2400
[INFO] 2021-07-12 19:20:37,880 [run_pretraining.py:  558]:	worker_index: 3, step: 2400, cost: 7.387930, mlm loss: 7.387930, speed: 1.108483 steps/s, speed: 8.867863 samples/s, speed: 4540.345741 tokens/s, learning rate: 2.399e-05, loss_scalings: 2814.750488, pp_loss: 7.107685
[INFO] 2021-07-12 19:20:37,880 [run_pretraining.py:  512]:	********exe.run_2400******* 
[INFO] 2021-07-12 19:20:38,786 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:38,787 [run_pretraining.py:  534]:	loss/total_loss, 6.7935943603515625, 2401
[INFO] 2021-07-12 19:20:38,787 [run_pretraining.py:  535]:	loss/mlm_loss, 6.7935943603515625, 2401
[INFO] 2021-07-12 19:20:38,787 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3999999029911123e-05, 2401
[INFO] 2021-07-12 19:20:38,787 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2401
[INFO] 2021-07-12 19:20:38,787 [run_pretraining.py:  558]:	worker_index: 3, step: 2401, cost: 6.793594, mlm loss: 6.793594, speed: 1.102570 steps/s, speed: 8.820562 samples/s, speed: 4516.127715 tokens/s, learning rate: 2.400e-05, loss_scalings: 2814.750488, pp_loss: 6.837657
[INFO] 2021-07-12 19:20:38,787 [run_pretraining.py:  512]:	********exe.run_2401******* 
[INFO] 2021-07-12 19:20:39,695 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:39,696 [run_pretraining.py:  534]:	loss/total_loss, 7.791197299957275, 2402
[INFO] 2021-07-12 19:20:39,696 [run_pretraining.py:  535]:	loss/mlm_loss, 7.791197299957275, 2402
[INFO] 2021-07-12 19:20:39,696 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.400999983365182e-05, 2402
[INFO] 2021-07-12 19:20:39,696 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2402
[INFO] 2021-07-12 19:20:39,696 [run_pretraining.py:  558]:	worker_index: 3, step: 2402, cost: 7.791197, mlm loss: 7.791197, speed: 1.100816 steps/s, speed: 8.806531 samples/s, speed: 4508.943730 tokens/s, learning rate: 2.401e-05, loss_scalings: 2814.750488, pp_loss: 6.530946
[INFO] 2021-07-12 19:20:39,696 [run_pretraining.py:  512]:	********exe.run_2402******* 
[INFO] 2021-07-12 19:20:40,598 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:40,599 [run_pretraining.py:  534]:	loss/total_loss, 7.015230178833008, 2403
[INFO] 2021-07-12 19:20:40,599 [run_pretraining.py:  535]:	loss/mlm_loss, 7.015230178833008, 2403
[INFO] 2021-07-12 19:20:40,599 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.401999881840311e-05, 2403
[INFO] 2021-07-12 19:20:40,599 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2403
[INFO] 2021-07-12 19:20:40,599 [run_pretraining.py:  558]:	worker_index: 3, step: 2403, cost: 7.015230, mlm loss: 7.015230, speed: 1.108479 steps/s, speed: 8.867835 samples/s, speed: 4540.331342 tokens/s, learning rate: 2.402e-05, loss_scalings: 2814.750488, pp_loss: 7.319709
[INFO] 2021-07-12 19:20:40,599 [run_pretraining.py:  512]:	********exe.run_2403******* 
[INFO] 2021-07-12 19:20:41,507 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:41,507 [run_pretraining.py:  534]:	loss/total_loss, 6.933507919311523, 2404
[INFO] 2021-07-12 19:20:41,507 [run_pretraining.py:  535]:	loss/mlm_loss, 6.933507919311523, 2404
[INFO] 2021-07-12 19:20:41,507 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4029999622143805e-05, 2404
[INFO] 2021-07-12 19:20:41,507 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2404
[INFO] 2021-07-12 19:20:41,507 [run_pretraining.py:  558]:	worker_index: 3, step: 2404, cost: 6.933508, mlm loss: 6.933508, speed: 1.101589 steps/s, speed: 8.812709 samples/s, speed: 4512.106795 tokens/s, learning rate: 2.403e-05, loss_scalings: 2814.750488, pp_loss: 7.182168
[INFO] 2021-07-12 19:20:41,508 [run_pretraining.py:  512]:	********exe.run_2404******* 
[INFO] 2021-07-12 19:20:42,415 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:42,416 [run_pretraining.py:  534]:	loss/total_loss, 7.71467399597168, 2405
[INFO] 2021-07-12 19:20:42,416 [run_pretraining.py:  535]:	loss/mlm_loss, 7.71467399597168, 2405
[INFO] 2021-07-12 19:20:42,416 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.40400004258845e-05, 2405
[INFO] 2021-07-12 19:20:42,416 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2405
[INFO] 2021-07-12 19:20:42,416 [run_pretraining.py:  558]:	worker_index: 3, step: 2405, cost: 7.714674, mlm loss: 7.714674, speed: 1.101099 steps/s, speed: 8.808792 samples/s, speed: 4510.101387 tokens/s, learning rate: 2.404e-05, loss_scalings: 2814.750488, pp_loss: 7.163567
[INFO] 2021-07-12 19:20:42,416 [run_pretraining.py:  512]:	********exe.run_2405******* 
[INFO] 2021-07-12 19:20:43,356 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:43,356 [run_pretraining.py:  534]:	loss/total_loss, 7.985588550567627, 2406
[INFO] 2021-07-12 19:20:43,357 [run_pretraining.py:  535]:	loss/mlm_loss, 7.985588550567627, 2406
[INFO] 2021-07-12 19:20:43,357 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4049999410635792e-05, 2406
[INFO] 2021-07-12 19:20:43,357 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2406
[INFO] 2021-07-12 19:20:43,357 [run_pretraining.py:  558]:	worker_index: 3, step: 2406, cost: 7.985589, mlm loss: 7.985589, speed: 1.063931 steps/s, speed: 8.511449 samples/s, speed: 4357.862141 tokens/s, learning rate: 2.405e-05, loss_scalings: 2814.750488, pp_loss: 7.753934
[INFO] 2021-07-12 19:20:43,357 [run_pretraining.py:  512]:	********exe.run_2406******* 
[INFO] 2021-07-12 19:20:44,263 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:44,264 [run_pretraining.py:  534]:	loss/total_loss, 6.881838321685791, 2407
[INFO] 2021-07-12 19:20:44,264 [run_pretraining.py:  535]:	loss/mlm_loss, 6.881838321685791, 2407
[INFO] 2021-07-12 19:20:44,264 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4060000214376487e-05, 2407
[INFO] 2021-07-12 19:20:44,264 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2407
[INFO] 2021-07-12 19:20:44,264 [run_pretraining.py:  558]:	worker_index: 3, step: 2407, cost: 6.881838, mlm loss: 6.881838, speed: 1.102654 steps/s, speed: 8.821232 samples/s, speed: 4516.470833 tokens/s, learning rate: 2.406e-05, loss_scalings: 2814.750488, pp_loss: 7.102640
[INFO] 2021-07-12 19:20:44,264 [run_pretraining.py:  512]:	********exe.run_2407******* 
[INFO] 2021-07-12 19:20:45,168 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:45,168 [run_pretraining.py:  534]:	loss/total_loss, 7.033699035644531, 2408
[INFO] 2021-07-12 19:20:45,168 [run_pretraining.py:  535]:	loss/mlm_loss, 7.033699035644531, 2408
[INFO] 2021-07-12 19:20:45,168 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.406999919912778e-05, 2408
[INFO] 2021-07-12 19:20:45,168 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2408
[INFO] 2021-07-12 19:20:45,169 [run_pretraining.py:  558]:	worker_index: 3, step: 2408, cost: 7.033699, mlm loss: 7.033699, speed: 1.106647 steps/s, speed: 8.853176 samples/s, speed: 4532.826219 tokens/s, learning rate: 2.407e-05, loss_scalings: 2814.750488, pp_loss: 7.454868
[INFO] 2021-07-12 19:20:45,169 [run_pretraining.py:  512]:	********exe.run_2408******* 
[INFO] 2021-07-12 19:20:46,067 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:46,067 [run_pretraining.py:  534]:	loss/total_loss, 6.881697177886963, 2409
[INFO] 2021-07-12 19:20:46,067 [run_pretraining.py:  535]:	loss/mlm_loss, 6.881697177886963, 2409
[INFO] 2021-07-12 19:20:46,067 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.407999818387907e-05, 2409
[INFO] 2021-07-12 19:20:46,068 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2409
[INFO] 2021-07-12 19:20:46,068 [run_pretraining.py:  558]:	worker_index: 3, step: 2409, cost: 6.881697, mlm loss: 6.881697, speed: 1.113120 steps/s, speed: 8.904960 samples/s, speed: 4559.339454 tokens/s, learning rate: 2.408e-05, loss_scalings: 2814.750488, pp_loss: 7.063983
[INFO] 2021-07-12 19:20:46,068 [run_pretraining.py:  512]:	********exe.run_2409******* 
[INFO] 2021-07-12 19:20:46,980 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:46,981 [run_pretraining.py:  534]:	loss/total_loss, 8.736495971679688, 2410
[INFO] 2021-07-12 19:20:46,981 [run_pretraining.py:  535]:	loss/mlm_loss, 8.736495971679688, 2410
[INFO] 2021-07-12 19:20:46,981 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4089998987619765e-05, 2410
[INFO] 2021-07-12 19:20:46,981 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2410
[INFO] 2021-07-12 19:20:46,981 [run_pretraining.py:  558]:	worker_index: 3, step: 2410, cost: 8.736496, mlm loss: 8.736496, speed: 1.095469 steps/s, speed: 8.763749 samples/s, speed: 4487.039509 tokens/s, learning rate: 2.409e-05, loss_scalings: 2814.750488, pp_loss: 7.675169
[INFO] 2021-07-12 19:20:46,981 [run_pretraining.py:  512]:	********exe.run_2410******* 
[INFO] 2021-07-12 19:20:47,889 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:47,889 [run_pretraining.py:  534]:	loss/total_loss, 7.170576095581055, 2411
[INFO] 2021-07-12 19:20:47,889 [run_pretraining.py:  535]:	loss/mlm_loss, 7.170576095581055, 2411
[INFO] 2021-07-12 19:20:47,889 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.409999979136046e-05, 2411
[INFO] 2021-07-12 19:20:47,889 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2411
[INFO] 2021-07-12 19:20:47,889 [run_pretraining.py:  558]:	worker_index: 3, step: 2411, cost: 7.170576, mlm loss: 7.170576, speed: 1.101662 steps/s, speed: 8.813294 samples/s, speed: 4512.406634 tokens/s, learning rate: 2.410e-05, loss_scalings: 2814.750488, pp_loss: 7.104770
[INFO] 2021-07-12 19:20:47,890 [run_pretraining.py:  512]:	********exe.run_2411******* 
[INFO] 2021-07-12 19:20:48,798 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:48,798 [run_pretraining.py:  534]:	loss/total_loss, 6.954013824462891, 2412
[INFO] 2021-07-12 19:20:48,798 [run_pretraining.py:  535]:	loss/mlm_loss, 6.954013824462891, 2412
[INFO] 2021-07-12 19:20:48,799 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4109998776111752e-05, 2412
[INFO] 2021-07-12 19:20:48,799 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2412
[INFO] 2021-07-12 19:20:48,799 [run_pretraining.py:  558]:	worker_index: 3, step: 2412, cost: 6.954014, mlm loss: 6.954014, speed: 1.100618 steps/s, speed: 8.804945 samples/s, speed: 4508.132067 tokens/s, learning rate: 2.411e-05, loss_scalings: 2814.750488, pp_loss: 7.047374
[INFO] 2021-07-12 19:20:48,799 [run_pretraining.py:  512]:	********exe.run_2412******* 
[INFO] 2021-07-12 19:20:49,700 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:49,701 [run_pretraining.py:  534]:	loss/total_loss, 7.645444869995117, 2413
[INFO] 2021-07-12 19:20:49,701 [run_pretraining.py:  535]:	loss/mlm_loss, 7.645444869995117, 2413
[INFO] 2021-07-12 19:20:49,701 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4119999579852447e-05, 2413
[INFO] 2021-07-12 19:20:49,701 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2413
[INFO] 2021-07-12 19:20:49,701 [run_pretraining.py:  558]:	worker_index: 3, step: 2413, cost: 7.645445, mlm loss: 7.645445, speed: 1.109023 steps/s, speed: 8.872187 samples/s, speed: 4542.559502 tokens/s, learning rate: 2.412e-05, loss_scalings: 2814.750488, pp_loss: 7.298924
[INFO] 2021-07-12 19:20:49,701 [run_pretraining.py:  512]:	********exe.run_2413******* 
[INFO] 2021-07-12 19:20:50,609 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:50,610 [run_pretraining.py:  534]:	loss/total_loss, 6.466783046722412, 2414
[INFO] 2021-07-12 19:20:50,610 [run_pretraining.py:  535]:	loss/mlm_loss, 6.466783046722412, 2414
[INFO] 2021-07-12 19:20:50,610 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4130000383593142e-05, 2414
[INFO] 2021-07-12 19:20:50,610 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2414
[INFO] 2021-07-12 19:20:50,610 [run_pretraining.py:  558]:	worker_index: 3, step: 2414, cost: 6.466783, mlm loss: 6.466783, speed: 1.100543 steps/s, speed: 8.804347 samples/s, speed: 4507.825699 tokens/s, learning rate: 2.413e-05, loss_scalings: 2814.750488, pp_loss: 7.114339
[INFO] 2021-07-12 19:20:50,610 [run_pretraining.py:  512]:	********exe.run_2414******* 
[INFO] 2021-07-12 19:20:51,511 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:51,512 [run_pretraining.py:  534]:	loss/total_loss, 7.253663063049316, 2415
[INFO] 2021-07-12 19:20:51,512 [run_pretraining.py:  535]:	loss/mlm_loss, 7.253663063049316, 2415
[INFO] 2021-07-12 19:20:51,512 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4139999368344434e-05, 2415
[INFO] 2021-07-12 19:20:51,512 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2415
[INFO] 2021-07-12 19:20:51,512 [run_pretraining.py:  558]:	worker_index: 3, step: 2415, cost: 7.253663, mlm loss: 7.253663, speed: 1.109667 steps/s, speed: 8.877336 samples/s, speed: 4545.196258 tokens/s, learning rate: 2.414e-05, loss_scalings: 2814.750488, pp_loss: 7.041513
[INFO] 2021-07-12 19:20:51,512 [run_pretraining.py:  512]:	********exe.run_2415******* 
[INFO] 2021-07-12 19:20:52,416 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:52,417 [run_pretraining.py:  534]:	loss/total_loss, 7.6487884521484375, 2416
[INFO] 2021-07-12 19:20:52,417 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6487884521484375, 2416
[INFO] 2021-07-12 19:20:52,417 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.415000017208513e-05, 2416
[INFO] 2021-07-12 19:20:52,417 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2416
[INFO] 2021-07-12 19:20:52,417 [run_pretraining.py:  558]:	worker_index: 3, step: 2416, cost: 7.648788, mlm loss: 7.648788, speed: 1.105756 steps/s, speed: 8.846046 samples/s, speed: 4529.175490 tokens/s, learning rate: 2.415e-05, loss_scalings: 2814.750488, pp_loss: 7.652151
[INFO] 2021-07-12 19:20:52,417 [run_pretraining.py:  512]:	********exe.run_2416******* 
[INFO] 2021-07-12 19:20:53,401 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:53,402 [run_pretraining.py:  534]:	loss/total_loss, 7.448886871337891, 2417
[INFO] 2021-07-12 19:20:53,402 [run_pretraining.py:  535]:	loss/mlm_loss, 7.448886871337891, 2417
[INFO] 2021-07-12 19:20:53,402 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4160000975825824e-05, 2417
[INFO] 2021-07-12 19:20:53,402 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2417
[INFO] 2021-07-12 19:20:53,402 [run_pretraining.py:  558]:	worker_index: 3, step: 2417, cost: 7.448887, mlm loss: 7.448887, speed: 1.016154 steps/s, speed: 8.129233 samples/s, speed: 4162.167111 tokens/s, learning rate: 2.416e-05, loss_scalings: 2814.750488, pp_loss: 6.626573
[INFO] 2021-07-12 19:20:53,402 [run_pretraining.py:  512]:	********exe.run_2417******* 
[INFO] 2021-07-12 19:20:54,308 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:54,308 [run_pretraining.py:  534]:	loss/total_loss, 7.220857620239258, 2418
[INFO] 2021-07-12 19:20:54,309 [run_pretraining.py:  535]:	loss/mlm_loss, 7.220857620239258, 2418
[INFO] 2021-07-12 19:20:54,309 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4169998141587712e-05, 2418
[INFO] 2021-07-12 19:20:54,309 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2418
[INFO] 2021-07-12 19:20:54,309 [run_pretraining.py:  558]:	worker_index: 3, step: 2418, cost: 7.220858, mlm loss: 7.220858, speed: 1.103313 steps/s, speed: 8.826504 samples/s, speed: 4519.170104 tokens/s, learning rate: 2.417e-05, loss_scalings: 2814.750488, pp_loss: 7.324219
[INFO] 2021-07-12 19:20:54,309 [run_pretraining.py:  512]:	********exe.run_2418******* 
[INFO] 2021-07-12 19:20:55,218 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:55,219 [run_pretraining.py:  534]:	loss/total_loss, 7.253320217132568, 2419
[INFO] 2021-07-12 19:20:55,219 [run_pretraining.py:  535]:	loss/mlm_loss, 7.253320217132568, 2419
[INFO] 2021-07-12 19:20:55,219 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4179998945328407e-05, 2419
[INFO] 2021-07-12 19:20:55,219 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2419
[INFO] 2021-07-12 19:20:55,219 [run_pretraining.py:  558]:	worker_index: 3, step: 2419, cost: 7.253320, mlm loss: 7.253320, speed: 1.099261 steps/s, speed: 8.794086 samples/s, speed: 4502.571880 tokens/s, learning rate: 2.418e-05, loss_scalings: 2814.750488, pp_loss: 7.588333
[INFO] 2021-07-12 19:20:55,219 [run_pretraining.py:  512]:	********exe.run_2419******* 
[INFO] 2021-07-12 19:20:56,128 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:56,128 [run_pretraining.py:  534]:	loss/total_loss, 7.4713873863220215, 2420
[INFO] 2021-07-12 19:20:56,128 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4713873863220215, 2420
[INFO] 2021-07-12 19:20:56,128 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4189999749069102e-05, 2420
[INFO] 2021-07-12 19:20:56,128 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2420
[INFO] 2021-07-12 19:20:56,128 [run_pretraining.py:  558]:	worker_index: 3, step: 2420, cost: 7.471387, mlm loss: 7.471387, speed: 1.100568 steps/s, speed: 8.804543 samples/s, speed: 4507.926239 tokens/s, learning rate: 2.419e-05, loss_scalings: 2814.750488, pp_loss: 6.927562
[INFO] 2021-07-12 19:20:56,128 [run_pretraining.py:  512]:	********exe.run_2420******* 
[INFO] 2021-07-12 19:20:57,042 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:57,042 [run_pretraining.py:  534]:	loss/total_loss, 7.1603169441223145, 2421
[INFO] 2021-07-12 19:20:57,042 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1603169441223145, 2421
[INFO] 2021-07-12 19:20:57,042 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4199998733820394e-05, 2421
[INFO] 2021-07-12 19:20:57,042 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2421
[INFO] 2021-07-12 19:20:57,043 [run_pretraining.py:  558]:	worker_index: 3, step: 2421, cost: 7.160317, mlm loss: 7.160317, speed: 1.094743 steps/s, speed: 8.757944 samples/s, speed: 4484.067133 tokens/s, learning rate: 2.420e-05, loss_scalings: 2814.750488, pp_loss: 6.625954
[INFO] 2021-07-12 19:20:57,043 [run_pretraining.py:  512]:	********exe.run_2421******* 
[INFO] 2021-07-12 19:20:57,962 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:57,963 [run_pretraining.py:  534]:	loss/total_loss, 7.85610818862915, 2422
[INFO] 2021-07-12 19:20:57,963 [run_pretraining.py:  535]:	loss/mlm_loss, 7.85610818862915, 2422
[INFO] 2021-07-12 19:20:57,963 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.420999953756109e-05, 2422
[INFO] 2021-07-12 19:20:57,963 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2422
[INFO] 2021-07-12 19:20:57,963 [run_pretraining.py:  558]:	worker_index: 3, step: 2422, cost: 7.856108, mlm loss: 7.856108, speed: 1.086890 steps/s, speed: 8.695120 samples/s, speed: 4451.901268 tokens/s, learning rate: 2.421e-05, loss_scalings: 2814.750488, pp_loss: 7.330760
[INFO] 2021-07-12 19:20:57,963 [run_pretraining.py:  512]:	********exe.run_2422******* 
[INFO] 2021-07-12 19:20:58,880 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:58,881 [run_pretraining.py:  534]:	loss/total_loss, 7.538486957550049, 2423
[INFO] 2021-07-12 19:20:58,881 [run_pretraining.py:  535]:	loss/mlm_loss, 7.538486957550049, 2423
[INFO] 2021-07-12 19:20:58,881 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4220000341301784e-05, 2423
[INFO] 2021-07-12 19:20:58,881 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2423
[INFO] 2021-07-12 19:20:58,881 [run_pretraining.py:  558]:	worker_index: 3, step: 2423, cost: 7.538487, mlm loss: 7.538487, speed: 1.090226 steps/s, speed: 8.721805 samples/s, speed: 4465.564126 tokens/s, learning rate: 2.422e-05, loss_scalings: 2814.750488, pp_loss: 7.236440
[INFO] 2021-07-12 19:20:58,881 [run_pretraining.py:  512]:	********exe.run_2423******* 
[INFO] 2021-07-12 19:20:59,791 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:59,791 [run_pretraining.py:  534]:	loss/total_loss, 7.129497528076172, 2424
[INFO] 2021-07-12 19:20:59,792 [run_pretraining.py:  535]:	loss/mlm_loss, 7.129497528076172, 2424
[INFO] 2021-07-12 19:20:59,792 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4229999326053075e-05, 2424
[INFO] 2021-07-12 19:20:59,792 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2424
[INFO] 2021-07-12 19:20:59,792 [run_pretraining.py:  558]:	worker_index: 3, step: 2424, cost: 7.129498, mlm loss: 7.129498, speed: 1.098908 steps/s, speed: 8.791261 samples/s, speed: 4501.125600 tokens/s, learning rate: 2.423e-05, loss_scalings: 2814.750488, pp_loss: 6.502913
[INFO] 2021-07-12 19:20:59,792 [run_pretraining.py:  512]:	********exe.run_2424******* 
[INFO] 2021-07-12 19:21:00,707 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:00,707 [run_pretraining.py:  534]:	loss/total_loss, 7.905716419219971, 2425
[INFO] 2021-07-12 19:21:00,707 [run_pretraining.py:  535]:	loss/mlm_loss, 7.905716419219971, 2425
[INFO] 2021-07-12 19:21:00,707 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.424000012979377e-05, 2425
[INFO] 2021-07-12 19:21:00,707 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2425
[INFO] 2021-07-12 19:21:00,708 [run_pretraining.py:  558]:	worker_index: 3, step: 2425, cost: 7.905716, mlm loss: 7.905716, speed: 1.092710 steps/s, speed: 8.741682 samples/s, speed: 4475.741371 tokens/s, learning rate: 2.424e-05, loss_scalings: 2814.750488, pp_loss: 7.785905
[INFO] 2021-07-12 19:21:00,708 [run_pretraining.py:  512]:	********exe.run_2425******* 
[INFO] 2021-07-12 19:21:01,621 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:01,621 [run_pretraining.py:  534]:	loss/total_loss, 7.335413932800293, 2426
[INFO] 2021-07-12 19:21:01,621 [run_pretraining.py:  535]:	loss/mlm_loss, 7.335413932800293, 2426
[INFO] 2021-07-12 19:21:01,621 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4250000933534466e-05, 2426
[INFO] 2021-07-12 19:21:01,621 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2426
[INFO] 2021-07-12 19:21:01,621 [run_pretraining.py:  558]:	worker_index: 3, step: 2426, cost: 7.335414, mlm loss: 7.335414, speed: 1.094953 steps/s, speed: 8.759622 samples/s, speed: 4484.926352 tokens/s, learning rate: 2.425e-05, loss_scalings: 2814.750488, pp_loss: 7.534702
[INFO] 2021-07-12 19:21:01,622 [run_pretraining.py:  512]:	********exe.run_2426******* 
[INFO] 2021-07-12 19:21:02,541 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:02,541 [run_pretraining.py:  534]:	loss/total_loss, 7.249489784240723, 2427
[INFO] 2021-07-12 19:21:02,541 [run_pretraining.py:  535]:	loss/mlm_loss, 7.249489784240723, 2427
[INFO] 2021-07-12 19:21:02,541 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4259998099296354e-05, 2427
[INFO] 2021-07-12 19:21:02,541 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2427
[INFO] 2021-07-12 19:21:02,542 [run_pretraining.py:  558]:	worker_index: 3, step: 2427, cost: 7.249490, mlm loss: 7.249490, speed: 1.087587 steps/s, speed: 8.700698 samples/s, speed: 4454.757210 tokens/s, learning rate: 2.426e-05, loss_scalings: 2814.750488, pp_loss: 7.429297
[INFO] 2021-07-12 19:21:02,542 [run_pretraining.py:  512]:	********exe.run_2427******* 
[INFO] 2021-07-12 19:21:03,454 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:03,455 [run_pretraining.py:  534]:	loss/total_loss, 7.236067295074463, 2428
[INFO] 2021-07-12 19:21:03,455 [run_pretraining.py:  535]:	loss/mlm_loss, 7.236067295074463, 2428
[INFO] 2021-07-12 19:21:03,455 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.426999890303705e-05, 2428
[INFO] 2021-07-12 19:21:03,455 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2428
[INFO] 2021-07-12 19:21:03,455 [run_pretraining.py:  558]:	worker_index: 3, step: 2428, cost: 7.236067, mlm loss: 7.236067, speed: 1.095081 steps/s, speed: 8.760644 samples/s, speed: 4485.449770 tokens/s, learning rate: 2.427e-05, loss_scalings: 2814.750488, pp_loss: 7.164295
[INFO] 2021-07-12 19:21:03,455 [run_pretraining.py:  512]:	********exe.run_2428******* 
[INFO] 2021-07-12 19:21:04,372 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:04,373 [run_pretraining.py:  534]:	loss/total_loss, 7.455798149108887, 2429
[INFO] 2021-07-12 19:21:04,373 [run_pretraining.py:  535]:	loss/mlm_loss, 7.455798149108887, 2429
[INFO] 2021-07-12 19:21:04,373 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4279999706777744e-05, 2429
[INFO] 2021-07-12 19:21:04,373 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2429
[INFO] 2021-07-12 19:21:04,373 [run_pretraining.py:  558]:	worker_index: 3, step: 2429, cost: 7.455798, mlm loss: 7.455798, speed: 1.090237 steps/s, speed: 8.721896 samples/s, speed: 4465.610556 tokens/s, learning rate: 2.428e-05, loss_scalings: 2814.750488, pp_loss: 7.345037
[INFO] 2021-07-12 19:21:04,373 [run_pretraining.py:  512]:	********exe.run_2429******* 
[INFO] 2021-07-12 19:21:05,284 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:05,285 [run_pretraining.py:  534]:	loss/total_loss, 7.338100433349609, 2430
[INFO] 2021-07-12 19:21:05,285 [run_pretraining.py:  535]:	loss/mlm_loss, 7.338100433349609, 2430
[INFO] 2021-07-12 19:21:05,285 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4289998691529036e-05, 2430
[INFO] 2021-07-12 19:21:05,285 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2430
[INFO] 2021-07-12 19:21:05,285 [run_pretraining.py:  558]:	worker_index: 3, step: 2430, cost: 7.338100, mlm loss: 7.338100, speed: 1.097485 steps/s, speed: 8.779881 samples/s, speed: 4495.299180 tokens/s, learning rate: 2.429e-05, loss_scalings: 2814.750488, pp_loss: 6.496696
[INFO] 2021-07-12 19:21:05,285 [run_pretraining.py:  512]:	********exe.run_2430******* 
[INFO] 2021-07-12 19:21:06,197 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:06,197 [run_pretraining.py:  534]:	loss/total_loss, 6.890288352966309, 2431
[INFO] 2021-07-12 19:21:06,197 [run_pretraining.py:  535]:	loss/mlm_loss, 6.890288352966309, 2431
[INFO] 2021-07-12 19:21:06,197 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.429999949526973e-05, 2431
[INFO] 2021-07-12 19:21:06,198 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2431
[INFO] 2021-07-12 19:21:06,198 [run_pretraining.py:  558]:	worker_index: 3, step: 2431, cost: 6.890288, mlm loss: 6.890288, speed: 1.096672 steps/s, speed: 8.773378 samples/s, speed: 4491.969350 tokens/s, learning rate: 2.430e-05, loss_scalings: 2814.750488, pp_loss: 7.276142
[INFO] 2021-07-12 19:21:06,198 [run_pretraining.py:  512]:	********exe.run_2431******* 
[INFO] 2021-07-12 19:21:07,105 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:07,106 [run_pretraining.py:  534]:	loss/total_loss, 5.262716293334961, 2432
[INFO] 2021-07-12 19:21:07,106 [run_pretraining.py:  535]:	loss/mlm_loss, 5.262716293334961, 2432
[INFO] 2021-07-12 19:21:07,106 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4310000299010426e-05, 2432
[INFO] 2021-07-12 19:21:07,106 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2432
[INFO] 2021-07-12 19:21:07,106 [run_pretraining.py:  558]:	worker_index: 3, step: 2432, cost: 5.262716, mlm loss: 5.262716, speed: 1.101529 steps/s, speed: 8.812229 samples/s, speed: 4511.861502 tokens/s, learning rate: 2.431e-05, loss_scalings: 2814.750488, pp_loss: 6.526241
[INFO] 2021-07-12 19:21:07,106 [run_pretraining.py:  512]:	********exe.run_2432******* 
[INFO] 2021-07-12 19:21:08,018 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:08,018 [run_pretraining.py:  534]:	loss/total_loss, 6.570075988769531, 2433
[INFO] 2021-07-12 19:21:08,018 [run_pretraining.py:  535]:	loss/mlm_loss, 6.570075988769531, 2433
[INFO] 2021-07-12 19:21:08,018 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4319999283761717e-05, 2433
[INFO] 2021-07-12 19:21:08,018 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2433
[INFO] 2021-07-12 19:21:08,019 [run_pretraining.py:  558]:	worker_index: 3, step: 2433, cost: 6.570076, mlm loss: 6.570076, speed: 1.096680 steps/s, speed: 8.773437 samples/s, speed: 4491.999887 tokens/s, learning rate: 2.432e-05, loss_scalings: 2814.750488, pp_loss: 6.576512
[INFO] 2021-07-12 19:21:08,019 [run_pretraining.py:  512]:	********exe.run_2433******* 
[INFO] 2021-07-12 19:21:08,928 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:08,928 [run_pretraining.py:  534]:	loss/total_loss, 6.809063911437988, 2434
[INFO] 2021-07-12 19:21:08,929 [run_pretraining.py:  535]:	loss/mlm_loss, 6.809063911437988, 2434
[INFO] 2021-07-12 19:21:08,929 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4330000087502412e-05, 2434
[INFO] 2021-07-12 19:21:08,929 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2434
[INFO] 2021-07-12 19:21:08,929 [run_pretraining.py:  558]:	worker_index: 3, step: 2434, cost: 6.809064, mlm loss: 6.809064, speed: 1.099438 steps/s, speed: 8.795506 samples/s, speed: 4503.298910 tokens/s, learning rate: 2.433e-05, loss_scalings: 2814.750488, pp_loss: 7.097943
[INFO] 2021-07-12 19:21:08,929 [run_pretraining.py:  512]:	********exe.run_2434******* 
[INFO] 2021-07-12 19:21:09,836 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:09,837 [run_pretraining.py:  534]:	loss/total_loss, 7.244147300720215, 2435
[INFO] 2021-07-12 19:21:09,837 [run_pretraining.py:  535]:	loss/mlm_loss, 7.244147300720215, 2435
[INFO] 2021-07-12 19:21:09,837 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4339999072253704e-05, 2435
[INFO] 2021-07-12 19:21:09,837 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2435
[INFO] 2021-07-12 19:21:09,837 [run_pretraining.py:  558]:	worker_index: 3, step: 2435, cost: 7.244147, mlm loss: 7.244147, speed: 1.101848 steps/s, speed: 8.814783 samples/s, speed: 4513.168856 tokens/s, learning rate: 2.434e-05, loss_scalings: 2814.750488, pp_loss: 7.277294
[INFO] 2021-07-12 19:21:09,837 [run_pretraining.py:  512]:	********exe.run_2435******* 
[INFO] 2021-07-12 19:21:10,749 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:10,750 [run_pretraining.py:  534]:	loss/total_loss, 7.459436416625977, 2436
[INFO] 2021-07-12 19:21:10,750 [run_pretraining.py:  535]:	loss/mlm_loss, 7.459436416625977, 2436
[INFO] 2021-07-12 19:21:10,750 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4349998057004996e-05, 2436
[INFO] 2021-07-12 19:21:10,750 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2436
[INFO] 2021-07-12 19:21:10,750 [run_pretraining.py:  558]:	worker_index: 3, step: 2436, cost: 7.459436, mlm loss: 7.459436, speed: 1.095782 steps/s, speed: 8.766258 samples/s, speed: 4488.324307 tokens/s, learning rate: 2.435e-05, loss_scalings: 2814.750488, pp_loss: 7.297547
[INFO] 2021-07-12 19:21:10,750 [run_pretraining.py:  512]:	********exe.run_2436******* 
[INFO] 2021-07-12 19:21:11,658 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:11,659 [run_pretraining.py:  534]:	loss/total_loss, 7.591569900512695, 2437
[INFO] 2021-07-12 19:21:11,659 [run_pretraining.py:  535]:	loss/mlm_loss, 7.591569900512695, 2437
[INFO] 2021-07-12 19:21:11,659 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.435999886074569e-05, 2437
[INFO] 2021-07-12 19:21:11,659 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2437
[INFO] 2021-07-12 19:21:11,659 [run_pretraining.py:  558]:	worker_index: 3, step: 2437, cost: 7.591570, mlm loss: 7.591570, speed: 1.100882 steps/s, speed: 8.807055 samples/s, speed: 4509.212376 tokens/s, learning rate: 2.436e-05, loss_scalings: 2814.750488, pp_loss: 7.368966
[INFO] 2021-07-12 19:21:11,659 [run_pretraining.py:  512]:	********exe.run_2437******* 
[INFO] 2021-07-12 19:21:12,567 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:12,567 [run_pretraining.py:  534]:	loss/total_loss, 7.563716411590576, 2438
[INFO] 2021-07-12 19:21:12,567 [run_pretraining.py:  535]:	loss/mlm_loss, 7.563716411590576, 2438
[INFO] 2021-07-12 19:21:12,568 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4369999664486386e-05, 2438
[INFO] 2021-07-12 19:21:12,568 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2438
[INFO] 2021-07-12 19:21:12,568 [run_pretraining.py:  558]:	worker_index: 3, step: 2438, cost: 7.563716, mlm loss: 7.563716, speed: 1.101509 steps/s, speed: 8.812070 samples/s, speed: 4511.779744 tokens/s, learning rate: 2.437e-05, loss_scalings: 2814.750488, pp_loss: 7.592488
[INFO] 2021-07-12 19:21:12,568 [run_pretraining.py:  512]:	********exe.run_2438******* 
[INFO] 2021-07-12 19:21:13,481 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:13,482 [run_pretraining.py:  534]:	loss/total_loss, 6.665107727050781, 2439
[INFO] 2021-07-12 19:21:13,482 [run_pretraining.py:  535]:	loss/mlm_loss, 6.665107727050781, 2439
[INFO] 2021-07-12 19:21:13,482 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4379998649237677e-05, 2439
[INFO] 2021-07-12 19:21:13,482 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2439
[INFO] 2021-07-12 19:21:13,482 [run_pretraining.py:  558]:	worker_index: 3, step: 2439, cost: 6.665108, mlm loss: 6.665108, speed: 1.094634 steps/s, speed: 8.757073 samples/s, speed: 4483.621265 tokens/s, learning rate: 2.438e-05, loss_scalings: 2814.750488, pp_loss: 7.194473
[INFO] 2021-07-12 19:21:13,482 [run_pretraining.py:  512]:	********exe.run_2439******* 
[INFO] 2021-07-12 19:21:14,392 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:14,393 [run_pretraining.py:  534]:	loss/total_loss, 7.600580215454102, 2440
[INFO] 2021-07-12 19:21:14,393 [run_pretraining.py:  535]:	loss/mlm_loss, 7.600580215454102, 2440
[INFO] 2021-07-12 19:21:14,393 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4389999452978373e-05, 2440
[INFO] 2021-07-12 19:21:14,393 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2440
[INFO] 2021-07-12 19:21:14,393 [run_pretraining.py:  558]:	worker_index: 3, step: 2440, cost: 7.600580, mlm loss: 7.600580, speed: 1.098239 steps/s, speed: 8.785916 samples/s, speed: 4498.388942 tokens/s, learning rate: 2.439e-05, loss_scalings: 2814.750488, pp_loss: 7.272285
[INFO] 2021-07-12 19:21:14,393 [run_pretraining.py:  512]:	********exe.run_2440******* 
[INFO] 2021-07-12 19:21:15,299 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:15,300 [run_pretraining.py:  534]:	loss/total_loss, 7.743047714233398, 2441
[INFO] 2021-07-12 19:21:15,300 [run_pretraining.py:  535]:	loss/mlm_loss, 7.743047714233398, 2441
[INFO] 2021-07-12 19:21:15,300 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4400000256719068e-05, 2441
[INFO] 2021-07-12 19:21:15,300 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2441
[INFO] 2021-07-12 19:21:15,300 [run_pretraining.py:  558]:	worker_index: 3, step: 2441, cost: 7.743048, mlm loss: 7.743048, speed: 1.103579 steps/s, speed: 8.828629 samples/s, speed: 4520.258089 tokens/s, learning rate: 2.440e-05, loss_scalings: 2814.750488, pp_loss: 7.526257
[INFO] 2021-07-12 19:21:15,300 [run_pretraining.py:  512]:	********exe.run_2441******* 
[INFO] 2021-07-12 19:21:16,244 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:16,245 [run_pretraining.py:  534]:	loss/total_loss, 7.788601875305176, 2442
[INFO] 2021-07-12 19:21:16,245 [run_pretraining.py:  535]:	loss/mlm_loss, 7.788601875305176, 2442
[INFO] 2021-07-12 19:21:16,245 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.440999924147036e-05, 2442
[INFO] 2021-07-12 19:21:16,245 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2442
[INFO] 2021-07-12 19:21:16,245 [run_pretraining.py:  558]:	worker_index: 3, step: 2442, cost: 7.788602, mlm loss: 7.788602, speed: 1.058821 steps/s, speed: 8.470567 samples/s, speed: 4336.930350 tokens/s, learning rate: 2.441e-05, loss_scalings: 2814.750488, pp_loss: 7.214132
[INFO] 2021-07-12 19:21:16,245 [run_pretraining.py:  512]:	********exe.run_2442******* 
[INFO] 2021-07-12 19:21:17,162 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:17,162 [run_pretraining.py:  534]:	loss/total_loss, 6.923554420471191, 2443
[INFO] 2021-07-12 19:21:17,162 [run_pretraining.py:  535]:	loss/mlm_loss, 6.923554420471191, 2443
[INFO] 2021-07-12 19:21:17,163 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4420000045211054e-05, 2443
[INFO] 2021-07-12 19:21:17,163 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2443
[INFO] 2021-07-12 19:21:17,163 [run_pretraining.py:  558]:	worker_index: 3, step: 2443, cost: 6.923554, mlm loss: 6.923554, speed: 1.090441 steps/s, speed: 8.723528 samples/s, speed: 4466.446458 tokens/s, learning rate: 2.442e-05, loss_scalings: 2814.750488, pp_loss: 7.465909
[INFO] 2021-07-12 19:21:17,163 [run_pretraining.py:  512]:	********exe.run_2443******* 
[INFO] 2021-07-12 19:21:18,077 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:18,078 [run_pretraining.py:  534]:	loss/total_loss, 6.980781078338623, 2444
[INFO] 2021-07-12 19:21:18,078 [run_pretraining.py:  535]:	loss/mlm_loss, 6.980781078338623, 2444
[INFO] 2021-07-12 19:21:18,078 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4429999029962346e-05, 2444
[INFO] 2021-07-12 19:21:18,078 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2444
[INFO] 2021-07-12 19:21:18,078 [run_pretraining.py:  558]:	worker_index: 3, step: 2444, cost: 6.980781, mlm loss: 6.980781, speed: 1.093253 steps/s, speed: 8.746025 samples/s, speed: 4477.964930 tokens/s, learning rate: 2.443e-05, loss_scalings: 2814.750488, pp_loss: 7.413902
[INFO] 2021-07-12 19:21:18,078 [run_pretraining.py:  512]:	********exe.run_2444******* 
[INFO] 2021-07-12 19:21:42,696 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:42,697 [run_pretraining.py:  534]:	loss/total_loss, 6.85141658782959, 2445
[INFO] 2021-07-12 19:21:42,697 [run_pretraining.py:  535]:	loss/mlm_loss, 6.85141658782959, 2445
[INFO] 2021-07-12 19:21:42,697 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4439998014713638e-05, 2445
[INFO] 2021-07-12 19:21:42,697 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2445
[INFO] 2021-07-12 19:21:42,697 [run_pretraining.py:  558]:	worker_index: 3, step: 2445, cost: 6.851417, mlm loss: 6.851417, speed: 0.040620 steps/s, speed: 0.324960 samples/s, speed: 166.379677 tokens/s, learning rate: 2.444e-05, loss_scalings: 2814.750488, pp_loss: 7.004214
[INFO] 2021-07-12 19:21:42,697 [run_pretraining.py:  512]:	********exe.run_2445******* 
[INFO] 2021-07-12 19:21:43,615 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:43,616 [run_pretraining.py:  534]:	loss/total_loss, 7.352171421051025, 2446
[INFO] 2021-07-12 19:21:43,616 [run_pretraining.py:  535]:	loss/mlm_loss, 7.352171421051025, 2446
[INFO] 2021-07-12 19:21:43,616 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4449998818454333e-05, 2446
[INFO] 2021-07-12 19:21:43,616 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2446
[INFO] 2021-07-12 19:21:43,616 [run_pretraining.py:  558]:	worker_index: 3, step: 2446, cost: 7.352171, mlm loss: 7.352171, speed: 1.088641 steps/s, speed: 8.709130 samples/s, speed: 4459.074619 tokens/s, learning rate: 2.445e-05, loss_scalings: 2814.750488, pp_loss: 7.625051
[INFO] 2021-07-12 19:21:43,616 [run_pretraining.py:  512]:	********exe.run_2446******* 
[INFO] 2021-07-12 19:21:44,535 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:44,536 [run_pretraining.py:  534]:	loss/total_loss, 6.751896858215332, 2447
[INFO] 2021-07-12 19:21:44,536 [run_pretraining.py:  535]:	loss/mlm_loss, 6.751896858215332, 2447
[INFO] 2021-07-12 19:21:44,536 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4459999622195028e-05, 2447
[INFO] 2021-07-12 19:21:44,536 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2447
[INFO] 2021-07-12 19:21:44,536 [run_pretraining.py:  558]:	worker_index: 3, step: 2447, cost: 6.751897, mlm loss: 6.751897, speed: 1.088018 steps/s, speed: 8.704142 samples/s, speed: 4456.520625 tokens/s, learning rate: 2.446e-05, loss_scalings: 2814.750488, pp_loss: 6.955330
[INFO] 2021-07-12 19:21:44,536 [run_pretraining.py:  512]:	********exe.run_2447******* 
[INFO] 2021-07-12 19:21:45,455 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:45,456 [run_pretraining.py:  534]:	loss/total_loss, 7.145652770996094, 2448
[INFO] 2021-07-12 19:21:45,456 [run_pretraining.py:  535]:	loss/mlm_loss, 7.145652770996094, 2448
[INFO] 2021-07-12 19:21:45,456 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.446999860694632e-05, 2448
[INFO] 2021-07-12 19:21:45,456 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2448
[INFO] 2021-07-12 19:21:45,456 [run_pretraining.py:  558]:	worker_index: 3, step: 2448, cost: 7.145653, mlm loss: 7.145653, speed: 1.087476 steps/s, speed: 8.699809 samples/s, speed: 4454.302138 tokens/s, learning rate: 2.447e-05, loss_scalings: 2814.750488, pp_loss: 6.686428
[INFO] 2021-07-12 19:21:45,456 [run_pretraining.py:  512]:	********exe.run_2448******* 
[INFO] 2021-07-12 19:21:46,371 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:46,372 [run_pretraining.py:  534]:	loss/total_loss, 6.895403861999512, 2449
[INFO] 2021-07-12 19:21:46,372 [run_pretraining.py:  535]:	loss/mlm_loss, 6.895403861999512, 2449
[INFO] 2021-07-12 19:21:46,372 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4479999410687014e-05, 2449
[INFO] 2021-07-12 19:21:46,372 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2449
[INFO] 2021-07-12 19:21:46,372 [run_pretraining.py:  558]:	worker_index: 3, step: 2449, cost: 6.895404, mlm loss: 6.895404, speed: 1.092838 steps/s, speed: 8.742707 samples/s, speed: 4476.266147 tokens/s, learning rate: 2.448e-05, loss_scalings: 2814.750488, pp_loss: 7.022861
[INFO] 2021-07-12 19:21:46,372 [run_pretraining.py:  512]:	********exe.run_2449******* 
[INFO] 2021-07-12 19:21:47,292 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:47,292 [run_pretraining.py:  534]:	loss/total_loss, 6.666145324707031, 2450
[INFO] 2021-07-12 19:21:47,292 [run_pretraining.py:  535]:	loss/mlm_loss, 6.666145324707031, 2450
[INFO] 2021-07-12 19:21:47,292 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.449000021442771e-05, 2450
[INFO] 2021-07-12 19:21:47,293 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2450
[INFO] 2021-07-12 19:21:47,293 [run_pretraining.py:  558]:	worker_index: 3, step: 2450, cost: 6.666145, mlm loss: 6.666145, speed: 1.086944 steps/s, speed: 8.695555 samples/s, speed: 4452.123932 tokens/s, learning rate: 2.449e-05, loss_scalings: 2814.750488, pp_loss: 6.980287
[INFO] 2021-07-12 19:21:47,293 [run_pretraining.py:  512]:	********exe.run_2450******* 
[INFO] 2021-07-12 19:21:48,204 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:48,204 [run_pretraining.py:  534]:	loss/total_loss, 7.993965148925781, 2451
[INFO] 2021-07-12 19:21:48,205 [run_pretraining.py:  535]:	loss/mlm_loss, 7.993965148925781, 2451
[INFO] 2021-07-12 19:21:48,205 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4499999199179e-05, 2451
[INFO] 2021-07-12 19:21:48,205 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2451
[INFO] 2021-07-12 19:21:48,205 [run_pretraining.py:  558]:	worker_index: 3, step: 2451, cost: 7.993965, mlm loss: 7.993965, speed: 1.097061 steps/s, speed: 8.776487 samples/s, speed: 4493.561364 tokens/s, learning rate: 2.450e-05, loss_scalings: 2814.750488, pp_loss: 7.412391
[INFO] 2021-07-12 19:21:48,205 [run_pretraining.py:  512]:	********exe.run_2451******* 
[INFO] 2021-07-12 19:21:49,136 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:49,136 [run_pretraining.py:  534]:	loss/total_loss, 7.26725435256958, 2452
[INFO] 2021-07-12 19:21:49,136 [run_pretraining.py:  535]:	loss/mlm_loss, 7.26725435256958, 2452
[INFO] 2021-07-12 19:21:49,136 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4510000002919696e-05, 2452
[INFO] 2021-07-12 19:21:49,137 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2452
[INFO] 2021-07-12 19:21:49,137 [run_pretraining.py:  558]:	worker_index: 3, step: 2452, cost: 7.267254, mlm loss: 7.267254, speed: 1.073866 steps/s, speed: 8.590926 samples/s, speed: 4398.554351 tokens/s, learning rate: 2.451e-05, loss_scalings: 2814.750488, pp_loss: 6.920460
[INFO] 2021-07-12 19:21:49,137 [run_pretraining.py:  512]:	********exe.run_2452******* 
[INFO] 2021-07-12 19:21:50,051 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:50,052 [run_pretraining.py:  534]:	loss/total_loss, 6.820376396179199, 2453
[INFO] 2021-07-12 19:21:50,052 [run_pretraining.py:  535]:	loss/mlm_loss, 6.820376396179199, 2453
[INFO] 2021-07-12 19:21:50,052 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4519998987670988e-05, 2453
[INFO] 2021-07-12 19:21:50,052 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2453
[INFO] 2021-07-12 19:21:50,052 [run_pretraining.py:  558]:	worker_index: 3, step: 2453, cost: 6.820376, mlm loss: 6.820376, speed: 1.093329 steps/s, speed: 8.746632 samples/s, speed: 4478.275424 tokens/s, learning rate: 2.452e-05, loss_scalings: 2814.750488, pp_loss: 7.176045
[INFO] 2021-07-12 19:21:50,052 [run_pretraining.py:  512]:	********exe.run_2453******* 
[INFO] 2021-07-12 19:21:50,975 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:50,975 [run_pretraining.py:  534]:	loss/total_loss, 6.8230485916137695, 2454
[INFO] 2021-07-12 19:21:50,975 [run_pretraining.py:  535]:	loss/mlm_loss, 6.8230485916137695, 2454
[INFO] 2021-07-12 19:21:50,975 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.452999797242228e-05, 2454
[INFO] 2021-07-12 19:21:50,976 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2454
[INFO] 2021-07-12 19:21:50,976 [run_pretraining.py:  558]:	worker_index: 3, step: 2454, cost: 6.823049, mlm loss: 6.823049, speed: 1.083342 steps/s, speed: 8.666732 samples/s, speed: 4437.366835 tokens/s, learning rate: 2.453e-05, loss_scalings: 2814.750488, pp_loss: 6.990508
[INFO] 2021-07-12 19:21:50,976 [run_pretraining.py:  512]:	********exe.run_2454******* 
[INFO] 2021-07-12 19:21:51,895 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:51,895 [run_pretraining.py:  534]:	loss/total_loss, 7.498281478881836, 2455
[INFO] 2021-07-12 19:21:51,895 [run_pretraining.py:  535]:	loss/mlm_loss, 7.498281478881836, 2455
[INFO] 2021-07-12 19:21:51,895 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4539998776162975e-05, 2455
[INFO] 2021-07-12 19:21:51,895 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2455
[INFO] 2021-07-12 19:21:51,896 [run_pretraining.py:  558]:	worker_index: 3, step: 2455, cost: 7.498281, mlm loss: 7.498281, speed: 1.087833 steps/s, speed: 8.702668 samples/s, speed: 4455.765860 tokens/s, learning rate: 2.454e-05, loss_scalings: 2814.750488, pp_loss: 7.224319
[INFO] 2021-07-12 19:21:51,896 [run_pretraining.py:  512]:	********exe.run_2455******* 
[INFO] 2021-07-12 19:21:52,816 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:52,816 [run_pretraining.py:  534]:	loss/total_loss, 7.399160385131836, 2456
[INFO] 2021-07-12 19:21:52,816 [run_pretraining.py:  535]:	loss/mlm_loss, 7.399160385131836, 2456
[INFO] 2021-07-12 19:21:52,817 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.454999957990367e-05, 2456
[INFO] 2021-07-12 19:21:52,817 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2456
[INFO] 2021-07-12 19:21:52,817 [run_pretraining.py:  558]:	worker_index: 3, step: 2456, cost: 7.399160, mlm loss: 7.399160, speed: 1.086360 steps/s, speed: 8.690879 samples/s, speed: 4449.730018 tokens/s, learning rate: 2.455e-05, loss_scalings: 2814.750488, pp_loss: 7.585936
[INFO] 2021-07-12 19:21:52,817 [run_pretraining.py:  512]:	********exe.run_2456******* 
[INFO] 2021-07-12 19:21:53,770 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:53,770 [run_pretraining.py:  534]:	loss/total_loss, 7.405783176422119, 2457
[INFO] 2021-07-12 19:21:53,771 [run_pretraining.py:  535]:	loss/mlm_loss, 7.405783176422119, 2457
[INFO] 2021-07-12 19:21:53,771 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.455999856465496e-05, 2457
[INFO] 2021-07-12 19:21:53,771 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2457
[INFO] 2021-07-12 19:21:53,771 [run_pretraining.py:  558]:	worker_index: 3, step: 2457, cost: 7.405783, mlm loss: 7.405783, speed: 1.048821 steps/s, speed: 8.390569 samples/s, speed: 4295.971479 tokens/s, learning rate: 2.456e-05, loss_scalings: 2814.750488, pp_loss: 7.520854
[INFO] 2021-07-12 19:21:53,771 [run_pretraining.py:  512]:	********exe.run_2457******* 
[INFO] 2021-07-12 19:21:54,691 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:54,692 [run_pretraining.py:  534]:	loss/total_loss, 6.690706253051758, 2458
[INFO] 2021-07-12 19:21:54,692 [run_pretraining.py:  535]:	loss/mlm_loss, 6.690706253051758, 2458
[INFO] 2021-07-12 19:21:54,692 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4569999368395656e-05, 2458
[INFO] 2021-07-12 19:21:54,692 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2458
[INFO] 2021-07-12 19:21:54,692 [run_pretraining.py:  558]:	worker_index: 3, step: 2458, cost: 6.690706, mlm loss: 6.690706, speed: 1.086009 steps/s, speed: 8.688071 samples/s, speed: 4448.292142 tokens/s, learning rate: 2.457e-05, loss_scalings: 2814.750488, pp_loss: 7.232353
[INFO] 2021-07-12 19:21:54,692 [run_pretraining.py:  512]:	********exe.run_2458******* 
[INFO] 2021-07-12 19:21:55,614 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:55,614 [run_pretraining.py:  534]:	loss/total_loss, 7.121858596801758, 2459
[INFO] 2021-07-12 19:21:55,615 [run_pretraining.py:  535]:	loss/mlm_loss, 7.121858596801758, 2459
[INFO] 2021-07-12 19:21:55,615 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.458000017213635e-05, 2459
[INFO] 2021-07-12 19:21:55,615 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2459
[INFO] 2021-07-12 19:21:55,615 [run_pretraining.py:  558]:	worker_index: 3, step: 2459, cost: 7.121859, mlm loss: 7.121859, speed: 1.084604 steps/s, speed: 8.676833 samples/s, speed: 4442.538427 tokens/s, learning rate: 2.458e-05, loss_scalings: 2814.750488, pp_loss: 7.436900
[INFO] 2021-07-12 19:21:55,615 [run_pretraining.py:  512]:	********exe.run_2459******* 
[INFO] 2021-07-12 19:21:56,527 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:56,528 [run_pretraining.py:  534]:	loss/total_loss, 6.984211444854736, 2460
[INFO] 2021-07-12 19:21:56,528 [run_pretraining.py:  535]:	loss/mlm_loss, 6.984211444854736, 2460
[INFO] 2021-07-12 19:21:56,528 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4589999156887643e-05, 2460
[INFO] 2021-07-12 19:21:56,528 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2460
[INFO] 2021-07-12 19:21:56,528 [run_pretraining.py:  558]:	worker_index: 3, step: 2460, cost: 6.984211, mlm loss: 6.984211, speed: 1.095488 steps/s, speed: 8.763907 samples/s, speed: 4487.120374 tokens/s, learning rate: 2.459e-05, loss_scalings: 2814.750488, pp_loss: 7.457453
[INFO] 2021-07-12 19:21:56,528 [run_pretraining.py:  512]:	********exe.run_2460******* 
[INFO] 2021-07-12 19:21:57,438 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:57,439 [run_pretraining.py:  534]:	loss/total_loss, 7.201751708984375, 2461
[INFO] 2021-07-12 19:21:57,439 [run_pretraining.py:  535]:	loss/mlm_loss, 7.201751708984375, 2461
[INFO] 2021-07-12 19:21:57,439 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4599999960628338e-05, 2461
[INFO] 2021-07-12 19:21:57,439 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2461
[INFO] 2021-07-12 19:21:57,439 [run_pretraining.py:  558]:	worker_index: 3, step: 2461, cost: 7.201752, mlm loss: 7.201752, speed: 1.098507 steps/s, speed: 8.788058 samples/s, speed: 4499.485799 tokens/s, learning rate: 2.460e-05, loss_scalings: 2814.750488, pp_loss: 7.151149
[INFO] 2021-07-12 19:21:57,439 [run_pretraining.py:  512]:	********exe.run_2461******* 
[INFO] 2021-07-12 19:21:58,357 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:58,357 [run_pretraining.py:  534]:	loss/total_loss, 7.385235786437988, 2462
[INFO] 2021-07-12 19:21:58,358 [run_pretraining.py:  535]:	loss/mlm_loss, 7.385235786437988, 2462
[INFO] 2021-07-12 19:21:58,358 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.460999894537963e-05, 2462
[INFO] 2021-07-12 19:21:58,358 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2462
[INFO] 2021-07-12 19:21:58,358 [run_pretraining.py:  558]:	worker_index: 3, step: 2462, cost: 7.385236, mlm loss: 7.385236, speed: 1.089484 steps/s, speed: 8.715869 samples/s, speed: 4462.525072 tokens/s, learning rate: 2.461e-05, loss_scalings: 2814.750488, pp_loss: 7.315677
[INFO] 2021-07-12 19:21:58,358 [run_pretraining.py:  512]:	********exe.run_2462******* 
[INFO] 2021-07-12 19:21:59,277 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:59,277 [run_pretraining.py:  534]:	loss/total_loss, 7.646789073944092, 2463
[INFO] 2021-07-12 19:21:59,277 [run_pretraining.py:  535]:	loss/mlm_loss, 7.646789073944092, 2463
[INFO] 2021-07-12 19:21:59,277 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4619999749120325e-05, 2463
[INFO] 2021-07-12 19:21:59,277 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2463
[INFO] 2021-07-12 19:21:59,278 [run_pretraining.py:  558]:	worker_index: 3, step: 2463, cost: 7.646789, mlm loss: 7.646789, speed: 1.087979 steps/s, speed: 8.703830 samples/s, speed: 4456.361098 tokens/s, learning rate: 2.462e-05, loss_scalings: 2814.750488, pp_loss: 7.304785
[INFO] 2021-07-12 19:21:59,278 [run_pretraining.py:  512]:	********exe.run_2463******* 
[INFO] 2021-07-12 19:22:00,192 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:00,193 [run_pretraining.py:  534]:	loss/total_loss, 7.065044403076172, 2464
[INFO] 2021-07-12 19:22:00,193 [run_pretraining.py:  535]:	loss/mlm_loss, 7.065044403076172, 2464
[INFO] 2021-07-12 19:22:00,193 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4629998733871616e-05, 2464
[INFO] 2021-07-12 19:22:00,193 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2464
[INFO] 2021-07-12 19:22:00,193 [run_pretraining.py:  558]:	worker_index: 3, step: 2464, cost: 7.065044, mlm loss: 7.065044, speed: 1.092963 steps/s, speed: 8.743701 samples/s, speed: 4476.774713 tokens/s, learning rate: 2.463e-05, loss_scalings: 2814.750488, pp_loss: 7.593854
[INFO] 2021-07-12 19:22:00,193 [run_pretraining.py:  512]:	********exe.run_2464******* 
[INFO] 2021-07-12 19:22:01,102 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:01,102 [run_pretraining.py:  534]:	loss/total_loss, 6.963025093078613, 2465
[INFO] 2021-07-12 19:22:01,103 [run_pretraining.py:  535]:	loss/mlm_loss, 6.963025093078613, 2465
[INFO] 2021-07-12 19:22:01,103 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.463999953761231e-05, 2465
[INFO] 2021-07-12 19:22:01,103 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2465
[INFO] 2021-07-12 19:22:01,103 [run_pretraining.py:  558]:	worker_index: 3, step: 2465, cost: 6.963025, mlm loss: 6.963025, speed: 1.100116 steps/s, speed: 8.800932 samples/s, speed: 4506.077004 tokens/s, learning rate: 2.464e-05, loss_scalings: 2814.750488, pp_loss: 6.901796
[INFO] 2021-07-12 19:22:01,103 [run_pretraining.py:  512]:	********exe.run_2465******* 
[INFO] 2021-07-12 19:22:02,019 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:02,020 [run_pretraining.py:  534]:	loss/total_loss, 7.318045616149902, 2466
[INFO] 2021-07-12 19:22:02,020 [run_pretraining.py:  535]:	loss/mlm_loss, 7.318045616149902, 2466
[INFO] 2021-07-12 19:22:02,020 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4649998522363603e-05, 2466
[INFO] 2021-07-12 19:22:02,020 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2466
[INFO] 2021-07-12 19:22:02,020 [run_pretraining.py:  558]:	worker_index: 3, step: 2466, cost: 7.318046, mlm loss: 7.318046, speed: 1.090679 steps/s, speed: 8.725429 samples/s, speed: 4467.419750 tokens/s, learning rate: 2.465e-05, loss_scalings: 2814.750488, pp_loss: 7.363001
[INFO] 2021-07-12 19:22:02,020 [run_pretraining.py:  512]:	********exe.run_2466******* 
[INFO] 2021-07-12 19:22:02,938 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:02,939 [run_pretraining.py:  534]:	loss/total_loss, 7.371746063232422, 2467
[INFO] 2021-07-12 19:22:02,939 [run_pretraining.py:  535]:	loss/mlm_loss, 7.371746063232422, 2467
[INFO] 2021-07-12 19:22:02,939 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4659999326104298e-05, 2467
[INFO] 2021-07-12 19:22:02,939 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2467
[INFO] 2021-07-12 19:22:02,939 [run_pretraining.py:  558]:	worker_index: 3, step: 2467, cost: 7.371746, mlm loss: 7.371746, speed: 1.088805 steps/s, speed: 8.710439 samples/s, speed: 4459.744833 tokens/s, learning rate: 2.466e-05, loss_scalings: 2814.750488, pp_loss: 7.354932
[INFO] 2021-07-12 19:22:02,939 [run_pretraining.py:  512]:	********exe.run_2467******* 
[INFO] 2021-07-12 19:22:03,860 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:03,861 [run_pretraining.py:  534]:	loss/total_loss, 6.986045837402344, 2468
[INFO] 2021-07-12 19:22:03,861 [run_pretraining.py:  535]:	loss/mlm_loss, 6.986045837402344, 2468
[INFO] 2021-07-12 19:22:03,861 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4670000129844993e-05, 2468
[INFO] 2021-07-12 19:22:03,861 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2468
[INFO] 2021-07-12 19:22:03,861 [run_pretraining.py:  558]:	worker_index: 3, step: 2468, cost: 6.986046, mlm loss: 6.986046, speed: 1.085462 steps/s, speed: 8.683695 samples/s, speed: 4446.051921 tokens/s, learning rate: 2.467e-05, loss_scalings: 2814.750488, pp_loss: 7.392536
[INFO] 2021-07-12 19:22:03,861 [run_pretraining.py:  512]:	********exe.run_2468******* 
[INFO] 2021-07-12 19:22:04,776 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:04,777 [run_pretraining.py:  534]:	loss/total_loss, 6.94469690322876, 2469
[INFO] 2021-07-12 19:22:04,777 [run_pretraining.py:  535]:	loss/mlm_loss, 6.94469690322876, 2469
[INFO] 2021-07-12 19:22:04,777 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4679999114596285e-05, 2469
[INFO] 2021-07-12 19:22:04,777 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2469
[INFO] 2021-07-12 19:22:04,777 [run_pretraining.py:  558]:	worker_index: 3, step: 2469, cost: 6.944697, mlm loss: 6.944697, speed: 1.092623 steps/s, speed: 8.740988 samples/s, speed: 4475.385760 tokens/s, learning rate: 2.468e-05, loss_scalings: 2814.750488, pp_loss: 7.579140
[INFO] 2021-07-12 19:22:04,777 [run_pretraining.py:  512]:	********exe.run_2469******* 
[INFO] 2021-07-12 19:22:05,688 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:05,688 [run_pretraining.py:  534]:	loss/total_loss, 6.790597915649414, 2470
[INFO] 2021-07-12 19:22:05,689 [run_pretraining.py:  535]:	loss/mlm_loss, 6.790597915649414, 2470
[INFO] 2021-07-12 19:22:05,689 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.468999991833698e-05, 2470
[INFO] 2021-07-12 19:22:05,689 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2470
[INFO] 2021-07-12 19:22:05,689 [run_pretraining.py:  558]:	worker_index: 3, step: 2470, cost: 6.790598, mlm loss: 6.790598, speed: 1.097719 steps/s, speed: 8.781749 samples/s, speed: 4496.255670 tokens/s, learning rate: 2.469e-05, loss_scalings: 2814.750488, pp_loss: 6.877620
[INFO] 2021-07-12 19:22:05,689 [run_pretraining.py:  512]:	********exe.run_2470******* 
[INFO] 2021-07-12 19:22:06,603 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:06,603 [run_pretraining.py:  534]:	loss/total_loss, 7.0385260581970215, 2471
[INFO] 2021-07-12 19:22:06,603 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0385260581970215, 2471
[INFO] 2021-07-12 19:22:06,603 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.469999890308827e-05, 2471
[INFO] 2021-07-12 19:22:06,603 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2471
[INFO] 2021-07-12 19:22:06,604 [run_pretraining.py:  558]:	worker_index: 3, step: 2471, cost: 7.038526, mlm loss: 7.038526, speed: 1.093915 steps/s, speed: 8.751317 samples/s, speed: 4480.674449 tokens/s, learning rate: 2.470e-05, loss_scalings: 2814.750488, pp_loss: 7.278993
[INFO] 2021-07-12 19:22:06,604 [run_pretraining.py:  512]:	********exe.run_2471******* 
[INFO] 2021-07-12 19:22:07,517 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:07,517 [run_pretraining.py:  534]:	loss/total_loss, 7.113835334777832, 2472
[INFO] 2021-07-12 19:22:07,517 [run_pretraining.py:  535]:	loss/mlm_loss, 7.113835334777832, 2472
[INFO] 2021-07-12 19:22:07,517 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4709999706828967e-05, 2472
[INFO] 2021-07-12 19:22:07,518 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2472
[INFO] 2021-07-12 19:22:07,518 [run_pretraining.py:  558]:	worker_index: 3, step: 2472, cost: 7.113835, mlm loss: 7.113835, speed: 1.094734 steps/s, speed: 8.757868 samples/s, speed: 4484.028511 tokens/s, learning rate: 2.471e-05, loss_scalings: 2814.750488, pp_loss: 7.238313
[INFO] 2021-07-12 19:22:07,518 [run_pretraining.py:  512]:	********exe.run_2472******* 
[INFO] 2021-07-12 19:22:08,435 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:08,436 [run_pretraining.py:  534]:	loss/total_loss, 7.711517810821533, 2473
[INFO] 2021-07-12 19:22:08,436 [run_pretraining.py:  535]:	loss/mlm_loss, 7.711517810821533, 2473
[INFO] 2021-07-12 19:22:08,436 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.471999869158026e-05, 2473
[INFO] 2021-07-12 19:22:08,436 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2473
[INFO] 2021-07-12 19:22:08,436 [run_pretraining.py:  558]:	worker_index: 3, step: 2473, cost: 7.711518, mlm loss: 7.711518, speed: 1.089737 steps/s, speed: 8.717894 samples/s, speed: 4463.561597 tokens/s, learning rate: 2.472e-05, loss_scalings: 2814.750488, pp_loss: 7.269908
[INFO] 2021-07-12 19:22:08,436 [run_pretraining.py:  512]:	********exe.run_2473******* 
[INFO] 2021-07-12 19:22:09,350 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:09,350 [run_pretraining.py:  534]:	loss/total_loss, 7.282188415527344, 2474
[INFO] 2021-07-12 19:22:09,350 [run_pretraining.py:  535]:	loss/mlm_loss, 7.282188415527344, 2474
[INFO] 2021-07-12 19:22:09,351 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4729999495320953e-05, 2474
[INFO] 2021-07-12 19:22:09,351 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2474
[INFO] 2021-07-12 19:22:09,351 [run_pretraining.py:  558]:	worker_index: 3, step: 2474, cost: 7.282188, mlm loss: 7.282188, speed: 1.093964 steps/s, speed: 8.751710 samples/s, speed: 4480.875458 tokens/s, learning rate: 2.473e-05, loss_scalings: 2814.750488, pp_loss: 7.175213
[INFO] 2021-07-12 19:22:09,351 [run_pretraining.py:  512]:	********exe.run_2474******* 
[INFO] 2021-07-12 19:22:10,267 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:10,268 [run_pretraining.py:  534]:	loss/total_loss, 7.234857559204102, 2475
[INFO] 2021-07-12 19:22:10,268 [run_pretraining.py:  535]:	loss/mlm_loss, 7.234857559204102, 2475
[INFO] 2021-07-12 19:22:10,268 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.474000029906165e-05, 2475
[INFO] 2021-07-12 19:22:10,268 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2475
[INFO] 2021-07-12 19:22:10,268 [run_pretraining.py:  558]:	worker_index: 3, step: 2475, cost: 7.234858, mlm loss: 7.234858, speed: 1.091021 steps/s, speed: 8.728164 samples/s, speed: 4468.820036 tokens/s, learning rate: 2.474e-05, loss_scalings: 2814.750488, pp_loss: 7.336258
[INFO] 2021-07-12 19:22:10,268 [run_pretraining.py:  512]:	********exe.run_2475******* 
[INFO] 2021-07-12 19:22:11,185 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:11,185 [run_pretraining.py:  534]:	loss/total_loss, 7.0950727462768555, 2476
[INFO] 2021-07-12 19:22:11,186 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0950727462768555, 2476
[INFO] 2021-07-12 19:22:11,186 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.474999928381294e-05, 2476
[INFO] 2021-07-12 19:22:11,186 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2476
[INFO] 2021-07-12 19:22:11,186 [run_pretraining.py:  558]:	worker_index: 3, step: 2476, cost: 7.095073, mlm loss: 7.095073, speed: 1.090273 steps/s, speed: 8.722186 samples/s, speed: 4465.759138 tokens/s, learning rate: 2.475e-05, loss_scalings: 2814.750488, pp_loss: 7.278133
[INFO] 2021-07-12 19:22:11,186 [run_pretraining.py:  512]:	********exe.run_2476******* 
[INFO] 2021-07-12 19:22:12,103 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:12,103 [run_pretraining.py:  534]:	loss/total_loss, 5.427587509155273, 2477
[INFO] 2021-07-12 19:22:12,103 [run_pretraining.py:  535]:	loss/mlm_loss, 5.427587509155273, 2477
[INFO] 2021-07-12 19:22:12,104 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4760000087553635e-05, 2477
[INFO] 2021-07-12 19:22:12,104 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2477
[INFO] 2021-07-12 19:22:12,104 [run_pretraining.py:  558]:	worker_index: 3, step: 2477, cost: 5.427588, mlm loss: 5.427588, speed: 1.090212 steps/s, speed: 8.721698 samples/s, speed: 4465.509572 tokens/s, learning rate: 2.476e-05, loss_scalings: 2814.750488, pp_loss: 6.837984
[INFO] 2021-07-12 19:22:12,104 [run_pretraining.py:  512]:	********exe.run_2477******* 
[INFO] 2021-07-12 19:22:13,023 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:13,024 [run_pretraining.py:  534]:	loss/total_loss, 7.82086181640625, 2478
[INFO] 2021-07-12 19:22:13,024 [run_pretraining.py:  535]:	loss/mlm_loss, 7.82086181640625, 2478
[INFO] 2021-07-12 19:22:13,024 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4769999072304927e-05, 2478
[INFO] 2021-07-12 19:22:13,024 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2478
[INFO] 2021-07-12 19:22:13,024 [run_pretraining.py:  558]:	worker_index: 3, step: 2478, cost: 7.820862, mlm loss: 7.820862, speed: 1.086947 steps/s, speed: 8.695577 samples/s, speed: 4452.135469 tokens/s, learning rate: 2.477e-05, loss_scalings: 2814.750488, pp_loss: 7.604603
[INFO] 2021-07-12 19:22:13,024 [run_pretraining.py:  512]:	********exe.run_2478******* 
[INFO] 2021-07-12 19:22:13,943 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:13,943 [run_pretraining.py:  534]:	loss/total_loss, 7.0586957931518555, 2479
[INFO] 2021-07-12 19:22:13,943 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0586957931518555, 2479
[INFO] 2021-07-12 19:22:13,943 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.477999805705622e-05, 2479
[INFO] 2021-07-12 19:22:13,944 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2479
[INFO] 2021-07-12 19:22:13,944 [run_pretraining.py:  558]:	worker_index: 3, step: 2479, cost: 7.058696, mlm loss: 7.058696, speed: 1.088524 steps/s, speed: 8.708190 samples/s, speed: 4458.593208 tokens/s, learning rate: 2.478e-05, loss_scalings: 2814.750488, pp_loss: 7.204115
[INFO] 2021-07-12 19:22:13,944 [run_pretraining.py:  512]:	********exe.run_2479******* 
[INFO] 2021-07-12 19:22:14,859 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:14,859 [run_pretraining.py:  534]:	loss/total_loss, 8.182558059692383, 2480
[INFO] 2021-07-12 19:22:14,859 [run_pretraining.py:  535]:	loss/mlm_loss, 8.182558059692383, 2480
[INFO] 2021-07-12 19:22:14,859 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4789998860796914e-05, 2480
[INFO] 2021-07-12 19:22:14,859 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2480
[INFO] 2021-07-12 19:22:14,860 [run_pretraining.py:  558]:	worker_index: 3, step: 2480, cost: 8.182558, mlm loss: 8.182558, speed: 1.092504 steps/s, speed: 8.740034 samples/s, speed: 4474.897324 tokens/s, learning rate: 2.479e-05, loss_scalings: 2814.750488, pp_loss: 7.555172
[INFO] 2021-07-12 19:22:14,860 [run_pretraining.py:  512]:	********exe.run_2480******* 
[INFO] 2021-07-12 19:22:15,776 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:15,777 [run_pretraining.py:  534]:	loss/total_loss, 6.753001689910889, 2481
[INFO] 2021-07-12 19:22:15,777 [run_pretraining.py:  535]:	loss/mlm_loss, 6.753001689910889, 2481
[INFO] 2021-07-12 19:22:15,777 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.479999966453761e-05, 2481
[INFO] 2021-07-12 19:22:15,777 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2481
[INFO] 2021-07-12 19:22:15,777 [run_pretraining.py:  558]:	worker_index: 3, step: 2481, cost: 6.753002, mlm loss: 6.753002, speed: 1.090681 steps/s, speed: 8.725452 samples/s, speed: 4467.431367 tokens/s, learning rate: 2.480e-05, loss_scalings: 2814.750488, pp_loss: 6.943486
[INFO] 2021-07-12 19:22:15,777 [run_pretraining.py:  512]:	********exe.run_2481******* 
[INFO] 2021-07-12 19:22:16,696 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:16,696 [run_pretraining.py:  534]:	loss/total_loss, 7.5757317543029785, 2482
[INFO] 2021-07-12 19:22:16,696 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5757317543029785, 2482
[INFO] 2021-07-12 19:22:16,696 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.48099986492889e-05, 2482
[INFO] 2021-07-12 19:22:16,696 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2482
[INFO] 2021-07-12 19:22:16,696 [run_pretraining.py:  558]:	worker_index: 3, step: 2482, cost: 7.575732, mlm loss: 7.575732, speed: 1.088437 steps/s, speed: 8.707498 samples/s, speed: 4458.239160 tokens/s, learning rate: 2.481e-05, loss_scalings: 2814.750488, pp_loss: 7.292470
[INFO] 2021-07-12 19:22:16,697 [run_pretraining.py:  512]:	********exe.run_2482******* 
[INFO] 2021-07-12 19:22:42,920 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:42,921 [run_pretraining.py:  534]:	loss/total_loss, 6.951423168182373, 2483
[INFO] 2021-07-12 19:22:42,921 [run_pretraining.py:  535]:	loss/mlm_loss, 6.951423168182373, 2483
[INFO] 2021-07-12 19:22:42,921 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4819999453029595e-05, 2483
[INFO] 2021-07-12 19:22:42,921 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2483
[INFO] 2021-07-12 19:22:42,921 [run_pretraining.py:  558]:	worker_index: 3, step: 2483, cost: 6.951423, mlm loss: 6.951423, speed: 0.038133 steps/s, speed: 0.305065 samples/s, speed: 156.193298 tokens/s, learning rate: 2.482e-05, loss_scalings: 2814.750488, pp_loss: 7.393332
[INFO] 2021-07-12 19:22:42,921 [run_pretraining.py:  512]:	********exe.run_2483******* 
[INFO] 2021-07-12 19:22:43,838 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:43,838 [run_pretraining.py:  534]:	loss/total_loss, 8.166762351989746, 2484
[INFO] 2021-07-12 19:22:43,838 [run_pretraining.py:  535]:	loss/mlm_loss, 8.166762351989746, 2484
[INFO] 2021-07-12 19:22:43,838 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.483000025677029e-05, 2484
[INFO] 2021-07-12 19:22:43,838 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2484
[INFO] 2021-07-12 19:22:43,839 [run_pretraining.py:  558]:	worker_index: 3, step: 2484, cost: 8.166762, mlm loss: 8.166762, speed: 1.090735 steps/s, speed: 8.725881 samples/s, speed: 4467.650940 tokens/s, learning rate: 2.483e-05, loss_scalings: 2814.750488, pp_loss: 7.754498
[INFO] 2021-07-12 19:22:43,839 [run_pretraining.py:  512]:	********exe.run_2484******* 
[INFO] 2021-07-12 19:22:44,760 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:44,760 [run_pretraining.py:  534]:	loss/total_loss, 7.102756500244141, 2485
[INFO] 2021-07-12 19:22:44,760 [run_pretraining.py:  535]:	loss/mlm_loss, 7.102756500244141, 2485
[INFO] 2021-07-12 19:22:44,761 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4839999241521582e-05, 2485
[INFO] 2021-07-12 19:22:44,761 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2485
[INFO] 2021-07-12 19:22:44,761 [run_pretraining.py:  558]:	worker_index: 3, step: 2485, cost: 7.102757, mlm loss: 7.102757, speed: 1.085108 steps/s, speed: 8.680862 samples/s, speed: 4444.601471 tokens/s, learning rate: 2.484e-05, loss_scalings: 2814.750488, pp_loss: 7.074284
[INFO] 2021-07-12 19:22:44,761 [run_pretraining.py:  512]:	********exe.run_2485******* 
[INFO] 2021-07-12 19:22:45,682 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:45,682 [run_pretraining.py:  534]:	loss/total_loss, 6.455033302307129, 2486
[INFO] 2021-07-12 19:22:45,682 [run_pretraining.py:  535]:	loss/mlm_loss, 6.455033302307129, 2486
[INFO] 2021-07-12 19:22:45,682 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4850000045262277e-05, 2486
[INFO] 2021-07-12 19:22:45,682 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2486
[INFO] 2021-07-12 19:22:45,682 [run_pretraining.py:  558]:	worker_index: 3, step: 2486, cost: 6.455033, mlm loss: 6.455033, speed: 1.085723 steps/s, speed: 8.685781 samples/s, speed: 4447.119946 tokens/s, learning rate: 2.485e-05, loss_scalings: 2814.750488, pp_loss: 7.098594
[INFO] 2021-07-12 19:22:45,682 [run_pretraining.py:  512]:	********exe.run_2486******* 
[INFO] 2021-07-12 19:22:46,604 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:46,605 [run_pretraining.py:  534]:	loss/total_loss, 6.929508209228516, 2487
[INFO] 2021-07-12 19:22:46,605 [run_pretraining.py:  535]:	loss/mlm_loss, 6.929508209228516, 2487
[INFO] 2021-07-12 19:22:46,605 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4860000849002972e-05, 2487
[INFO] 2021-07-12 19:22:46,605 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2487
[INFO] 2021-07-12 19:22:46,605 [run_pretraining.py:  558]:	worker_index: 3, step: 2487, cost: 6.929508, mlm loss: 6.929508, speed: 1.084773 steps/s, speed: 8.678184 samples/s, speed: 4443.230109 tokens/s, learning rate: 2.486e-05, loss_scalings: 2814.750488, pp_loss: 7.176502
[INFO] 2021-07-12 19:22:46,605 [run_pretraining.py:  512]:	********exe.run_2487******* 
[INFO] 2021-07-12 19:22:47,541 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:47,542 [run_pretraining.py:  534]:	loss/total_loss, 7.158343315124512, 2488
[INFO] 2021-07-12 19:22:47,542 [run_pretraining.py:  535]:	loss/mlm_loss, 7.158343315124512, 2488
[INFO] 2021-07-12 19:22:47,542 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.486999801476486e-05, 2488
[INFO] 2021-07-12 19:22:47,542 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2488
[INFO] 2021-07-12 19:22:47,542 [run_pretraining.py:  558]:	worker_index: 3, step: 2488, cost: 7.158343, mlm loss: 7.158343, speed: 1.067805 steps/s, speed: 8.542440 samples/s, speed: 4373.729415 tokens/s, learning rate: 2.487e-05, loss_scalings: 2814.750488, pp_loss: 7.010446
[INFO] 2021-07-12 19:22:47,542 [run_pretraining.py:  512]:	********exe.run_2488******* 
[INFO] 2021-07-12 19:22:48,473 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:48,474 [run_pretraining.py:  534]:	loss/total_loss, 6.903315544128418, 2489
[INFO] 2021-07-12 19:22:48,474 [run_pretraining.py:  535]:	loss/mlm_loss, 6.903315544128418, 2489
[INFO] 2021-07-12 19:22:48,474 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4879998818505555e-05, 2489
[INFO] 2021-07-12 19:22:48,474 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2489
[INFO] 2021-07-12 19:22:48,474 [run_pretraining.py:  558]:	worker_index: 3, step: 2489, cost: 6.903316, mlm loss: 6.903316, speed: 1.073810 steps/s, speed: 8.590478 samples/s, speed: 4398.324626 tokens/s, learning rate: 2.488e-05, loss_scalings: 2814.750488, pp_loss: 6.730951
[INFO] 2021-07-12 19:22:48,474 [run_pretraining.py:  512]:	********exe.run_2489******* 
[INFO] 2021-07-12 19:22:49,402 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:49,403 [run_pretraining.py:  534]:	loss/total_loss, 6.85743522644043, 2490
[INFO] 2021-07-12 19:22:49,403 [run_pretraining.py:  535]:	loss/mlm_loss, 6.85743522644043, 2490
[INFO] 2021-07-12 19:22:49,403 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.488999962224625e-05, 2490
[INFO] 2021-07-12 19:22:49,403 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2490
[INFO] 2021-07-12 19:22:49,403 [run_pretraining.py:  558]:	worker_index: 3, step: 2490, cost: 6.857435, mlm loss: 6.857435, speed: 1.076916 steps/s, speed: 8.615331 samples/s, speed: 4411.049579 tokens/s, learning rate: 2.489e-05, loss_scalings: 2814.750488, pp_loss: 7.130352
[INFO] 2021-07-12 19:22:49,403 [run_pretraining.py:  512]:	********exe.run_2490******* 
[INFO] 2021-07-12 19:22:50,339 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:50,340 [run_pretraining.py:  534]:	loss/total_loss, 6.888315200805664, 2491
[INFO] 2021-07-12 19:22:50,340 [run_pretraining.py:  535]:	loss/mlm_loss, 6.888315200805664, 2491
[INFO] 2021-07-12 19:22:50,340 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4899998606997542e-05, 2491
[INFO] 2021-07-12 19:22:50,340 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2491
[INFO] 2021-07-12 19:22:50,340 [run_pretraining.py:  558]:	worker_index: 3, step: 2491, cost: 6.888315, mlm loss: 6.888315, speed: 1.068256 steps/s, speed: 8.546052 samples/s, speed: 4375.578580 tokens/s, learning rate: 2.490e-05, loss_scalings: 2814.750488, pp_loss: 7.262628
[INFO] 2021-07-12 19:22:50,340 [run_pretraining.py:  512]:	********exe.run_2491******* 
[INFO] 2021-07-12 19:22:51,258 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:51,259 [run_pretraining.py:  534]:	loss/total_loss, 7.696685314178467, 2492
[INFO] 2021-07-12 19:22:51,259 [run_pretraining.py:  535]:	loss/mlm_loss, 7.696685314178467, 2492
[INFO] 2021-07-12 19:22:51,259 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4909999410738237e-05, 2492
[INFO] 2021-07-12 19:22:51,259 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2492
[INFO] 2021-07-12 19:22:51,259 [run_pretraining.py:  558]:	worker_index: 3, step: 2492, cost: 7.696685, mlm loss: 7.696685, speed: 1.088607 steps/s, speed: 8.708857 samples/s, speed: 4458.934583 tokens/s, learning rate: 2.491e-05, loss_scalings: 2814.750488, pp_loss: 6.786718
[INFO] 2021-07-12 19:22:51,259 [run_pretraining.py:  512]:	********exe.run_2492******* 
[INFO] 2021-07-12 19:22:52,179 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:52,180 [run_pretraining.py:  534]:	loss/total_loss, 7.239121437072754, 2493
[INFO] 2021-07-12 19:22:52,180 [run_pretraining.py:  535]:	loss/mlm_loss, 7.239121437072754, 2493
[INFO] 2021-07-12 19:22:52,180 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4920000214478932e-05, 2493
[INFO] 2021-07-12 19:22:52,180 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2493
[INFO] 2021-07-12 19:22:52,180 [run_pretraining.py:  558]:	worker_index: 3, step: 2493, cost: 7.239121, mlm loss: 7.239121, speed: 1.086761 steps/s, speed: 8.694086 samples/s, speed: 4451.371809 tokens/s, learning rate: 2.492e-05, loss_scalings: 2814.750488, pp_loss: 7.171138
[INFO] 2021-07-12 19:22:52,180 [run_pretraining.py:  512]:	********exe.run_2493******* 
[INFO] 2021-07-12 19:22:53,106 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:53,107 [run_pretraining.py:  534]:	loss/total_loss, 7.012549877166748, 2494
[INFO] 2021-07-12 19:22:53,107 [run_pretraining.py:  535]:	loss/mlm_loss, 7.012549877166748, 2494
[INFO] 2021-07-12 19:22:53,107 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4929999199230224e-05, 2494
[INFO] 2021-07-12 19:22:53,107 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2494
[INFO] 2021-07-12 19:22:53,107 [run_pretraining.py:  558]:	worker_index: 3, step: 2494, cost: 7.012550, mlm loss: 7.012550, speed: 1.079170 steps/s, speed: 8.633359 samples/s, speed: 4420.280025 tokens/s, learning rate: 2.493e-05, loss_scalings: 2814.750488, pp_loss: 7.023439
[INFO] 2021-07-12 19:22:53,107 [run_pretraining.py:  512]:	********exe.run_2494******* 
[INFO] 2021-07-12 19:22:54,030 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:54,030 [run_pretraining.py:  534]:	loss/total_loss, 7.756769180297852, 2495
[INFO] 2021-07-12 19:22:54,030 [run_pretraining.py:  535]:	loss/mlm_loss, 7.756769180297852, 2495
[INFO] 2021-07-12 19:22:54,030 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.494000000297092e-05, 2495
[INFO] 2021-07-12 19:22:54,030 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2495
[INFO] 2021-07-12 19:22:54,031 [run_pretraining.py:  558]:	worker_index: 3, step: 2495, cost: 7.756769, mlm loss: 7.756769, speed: 1.083763 steps/s, speed: 8.670107 samples/s, speed: 4439.094713 tokens/s, learning rate: 2.494e-05, loss_scalings: 2814.750488, pp_loss: 7.500090
[INFO] 2021-07-12 19:22:54,031 [run_pretraining.py:  512]:	********exe.run_2495******* 
[INFO] 2021-07-12 19:22:54,948 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:54,949 [run_pretraining.py:  534]:	loss/total_loss, 7.357548236846924, 2496
[INFO] 2021-07-12 19:22:54,949 [run_pretraining.py:  535]:	loss/mlm_loss, 7.357548236846924, 2496
[INFO] 2021-07-12 19:22:54,949 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4950000806711614e-05, 2496
[INFO] 2021-07-12 19:22:54,949 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2496
[INFO] 2021-07-12 19:22:54,949 [run_pretraining.py:  558]:	worker_index: 3, step: 2496, cost: 7.357548, mlm loss: 7.357548, speed: 1.089243 steps/s, speed: 8.713943 samples/s, speed: 4461.538849 tokens/s, learning rate: 2.495e-05, loss_scalings: 2814.750488, pp_loss: 7.015381
[INFO] 2021-07-12 19:22:54,949 [run_pretraining.py:  512]:	********exe.run_2496******* 
[INFO] 2021-07-12 19:22:55,872 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:55,873 [run_pretraining.py:  534]:	loss/total_loss, 7.428186416625977, 2497
[INFO] 2021-07-12 19:22:55,873 [run_pretraining.py:  535]:	loss/mlm_loss, 7.428186416625977, 2497
[INFO] 2021-07-12 19:22:55,873 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4959997972473502e-05, 2497
[INFO] 2021-07-12 19:22:55,873 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2497
[INFO] 2021-07-12 19:22:55,873 [run_pretraining.py:  558]:	worker_index: 3, step: 2497, cost: 7.428186, mlm loss: 7.428186, speed: 1.082846 steps/s, speed: 8.662765 samples/s, speed: 4435.335691 tokens/s, learning rate: 2.496e-05, loss_scalings: 2814.750488, pp_loss: 7.365335
[INFO] 2021-07-12 19:22:55,873 [run_pretraining.py:  512]:	********exe.run_2497******* 
[INFO] 2021-07-12 19:22:56,798 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:56,799 [run_pretraining.py:  534]:	loss/total_loss, 7.160544395446777, 2498
[INFO] 2021-07-12 19:22:56,799 [run_pretraining.py:  535]:	loss/mlm_loss, 7.160544395446777, 2498
[INFO] 2021-07-12 19:22:56,799 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4969998776214197e-05, 2498
[INFO] 2021-07-12 19:22:56,799 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2498
[INFO] 2021-07-12 19:22:56,799 [run_pretraining.py:  558]:	worker_index: 3, step: 2498, cost: 7.160544, mlm loss: 7.160544, speed: 1.081163 steps/s, speed: 8.649302 samples/s, speed: 4428.442775 tokens/s, learning rate: 2.497e-05, loss_scalings: 2814.750488, pp_loss: 6.985176
[INFO] 2021-07-12 19:22:56,799 [run_pretraining.py:  512]:	********exe.run_2498******* 
[INFO] 2021-07-12 19:22:57,724 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:57,724 [run_pretraining.py:  534]:	loss/total_loss, 7.274609088897705, 2499
[INFO] 2021-07-12 19:22:57,724 [run_pretraining.py:  535]:	loss/mlm_loss, 7.274609088897705, 2499
[INFO] 2021-07-12 19:22:57,724 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4979999579954892e-05, 2499
[INFO] 2021-07-12 19:22:57,724 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2499
[INFO] 2021-07-12 19:22:57,725 [run_pretraining.py:  558]:	worker_index: 3, step: 2499, cost: 7.274609, mlm loss: 7.274609, speed: 1.081079 steps/s, speed: 8.648631 samples/s, speed: 4428.099206 tokens/s, learning rate: 2.498e-05, loss_scalings: 2814.750488, pp_loss: 7.437760
[INFO] 2021-07-12 19:22:57,725 [run_pretraining.py:  512]:	********exe.run_2499******* 
[INFO] 2021-07-12 19:22:58,653 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:58,653 [run_pretraining.py:  534]:	loss/total_loss, 6.808367729187012, 2500
[INFO] 2021-07-12 19:22:58,653 [run_pretraining.py:  535]:	loss/mlm_loss, 6.808367729187012, 2500
[INFO] 2021-07-12 19:22:58,653 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4989998564706184e-05, 2500
[INFO] 2021-07-12 19:22:58,653 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2500
[INFO] 2021-07-12 19:22:58,654 [run_pretraining.py:  558]:	worker_index: 3, step: 2500, cost: 6.808368, mlm loss: 6.808368, speed: 1.077204 steps/s, speed: 8.617635 samples/s, speed: 4412.228897 tokens/s, learning rate: 2.499e-05, loss_scalings: 2814.750488, pp_loss: 6.945626
[INFO] 2021-07-12 19:22:58,654 [run_pretraining.py:  512]:	********exe.run_2500******* 
[INFO] 2021-07-12 19:22:59,578 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:59,578 [run_pretraining.py:  534]:	loss/total_loss, 7.013596534729004, 2501
[INFO] 2021-07-12 19:22:59,578 [run_pretraining.py:  535]:	loss/mlm_loss, 7.013596534729004, 2501
[INFO] 2021-07-12 19:22:59,578 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.499999936844688e-05, 2501
[INFO] 2021-07-12 19:22:59,578 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2501
[INFO] 2021-07-12 19:22:59,578 [run_pretraining.py:  558]:	worker_index: 3, step: 2501, cost: 7.013597, mlm loss: 7.013597, speed: 1.081845 steps/s, speed: 8.654759 samples/s, speed: 4431.236687 tokens/s, learning rate: 2.500e-05, loss_scalings: 2814.750488, pp_loss: 7.100591
[INFO] 2021-07-12 19:22:59,579 [run_pretraining.py:  512]:	********exe.run_2501******* 
[INFO] 2021-07-12 19:23:00,498 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:00,498 [run_pretraining.py:  534]:	loss/total_loss, 7.689347743988037, 2502
[INFO] 2021-07-12 19:23:00,498 [run_pretraining.py:  535]:	loss/mlm_loss, 7.689347743988037, 2502
[INFO] 2021-07-12 19:23:00,498 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.500999835319817e-05, 2502
[INFO] 2021-07-12 19:23:00,498 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2502
[INFO] 2021-07-12 19:23:00,499 [run_pretraining.py:  558]:	worker_index: 3, step: 2502, cost: 7.689348, mlm loss: 7.689348, speed: 1.087638 steps/s, speed: 8.701104 samples/s, speed: 4454.965142 tokens/s, learning rate: 2.501e-05, loss_scalings: 2814.750488, pp_loss: 6.687022
[INFO] 2021-07-12 19:23:00,499 [run_pretraining.py:  512]:	********exe.run_2502******* 
[INFO] 2021-07-12 19:23:01,416 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:01,416 [run_pretraining.py:  534]:	loss/total_loss, 7.488112926483154, 2503
[INFO] 2021-07-12 19:23:01,416 [run_pretraining.py:  535]:	loss/mlm_loss, 7.488112926483154, 2503
[INFO] 2021-07-12 19:23:01,416 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5019999156938866e-05, 2503
[INFO] 2021-07-12 19:23:01,417 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2503
[INFO] 2021-07-12 19:23:01,417 [run_pretraining.py:  558]:	worker_index: 3, step: 2503, cost: 7.488113, mlm loss: 7.488113, speed: 1.089938 steps/s, speed: 8.719507 samples/s, speed: 4464.387451 tokens/s, learning rate: 2.502e-05, loss_scalings: 2814.750488, pp_loss: 7.328391
[INFO] 2021-07-12 19:23:01,417 [run_pretraining.py:  512]:	********exe.run_2503******* 
[INFO] 2021-07-12 19:23:02,337 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:02,337 [run_pretraining.py:  534]:	loss/total_loss, 7.237560272216797, 2504
[INFO] 2021-07-12 19:23:02,337 [run_pretraining.py:  535]:	loss/mlm_loss, 7.237560272216797, 2504
[INFO] 2021-07-12 19:23:02,338 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5029998141690157e-05, 2504
[INFO] 2021-07-12 19:23:02,338 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2504
[INFO] 2021-07-12 19:23:02,338 [run_pretraining.py:  558]:	worker_index: 3, step: 2504, cost: 7.237560, mlm loss: 7.237560, speed: 1.086440 steps/s, speed: 8.691518 samples/s, speed: 4450.057357 tokens/s, learning rate: 2.503e-05, loss_scalings: 2814.750488, pp_loss: 7.342310
[INFO] 2021-07-12 19:23:02,338 [run_pretraining.py:  512]:	********exe.run_2504******* 
[INFO] 2021-07-12 19:23:03,264 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:03,265 [run_pretraining.py:  534]:	loss/total_loss, 7.972361087799072, 2505
[INFO] 2021-07-12 19:23:03,265 [run_pretraining.py:  535]:	loss/mlm_loss, 7.972361087799072, 2505
[INFO] 2021-07-12 19:23:03,265 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5040000764420256e-05, 2505
[INFO] 2021-07-12 19:23:03,265 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2505
[INFO] 2021-07-12 19:23:03,265 [run_pretraining.py:  558]:	worker_index: 3, step: 2505, cost: 7.972361, mlm loss: 7.972361, speed: 1.079084 steps/s, speed: 8.632669 samples/s, speed: 4419.926349 tokens/s, learning rate: 2.504e-05, loss_scalings: 2814.750488, pp_loss: 7.530450
[INFO] 2021-07-12 19:23:03,265 [run_pretraining.py:  512]:	********exe.run_2505******* 
[INFO] 2021-07-12 19:23:04,185 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:04,186 [run_pretraining.py:  534]:	loss/total_loss, 7.160608291625977, 2506
[INFO] 2021-07-12 19:23:04,186 [run_pretraining.py:  535]:	loss/mlm_loss, 7.160608291625977, 2506
[INFO] 2021-07-12 19:23:04,186 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5049997930182144e-05, 2506
[INFO] 2021-07-12 19:23:04,186 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2506
[INFO] 2021-07-12 19:23:04,186 [run_pretraining.py:  558]:	worker_index: 3, step: 2506, cost: 7.160608, mlm loss: 7.160608, speed: 1.086214 steps/s, speed: 8.689713 samples/s, speed: 4449.133095 tokens/s, learning rate: 2.505e-05, loss_scalings: 2814.750488, pp_loss: 7.319882
[INFO] 2021-07-12 19:23:04,186 [run_pretraining.py:  512]:	********exe.run_2506******* 
[INFO] 2021-07-12 19:23:05,106 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:05,106 [run_pretraining.py:  534]:	loss/total_loss, 7.019710540771484, 2507
[INFO] 2021-07-12 19:23:05,106 [run_pretraining.py:  535]:	loss/mlm_loss, 7.019710540771484, 2507
[INFO] 2021-07-12 19:23:05,107 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5060000552912243e-05, 2507
[INFO] 2021-07-12 19:23:05,107 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2507
[INFO] 2021-07-12 19:23:05,107 [run_pretraining.py:  558]:	worker_index: 3, step: 2507, cost: 7.019711, mlm loss: 7.019711, speed: 1.087271 steps/s, speed: 8.698169 samples/s, speed: 4453.462693 tokens/s, learning rate: 2.506e-05, loss_scalings: 2814.750488, pp_loss: 7.201690
[INFO] 2021-07-12 19:23:05,107 [run_pretraining.py:  512]:	********exe.run_2507******* 
[INFO] 2021-07-12 19:23:06,022 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:06,023 [run_pretraining.py:  534]:	loss/total_loss, 7.746241569519043, 2508
[INFO] 2021-07-12 19:23:06,023 [run_pretraining.py:  535]:	loss/mlm_loss, 7.746241569519043, 2508
[INFO] 2021-07-12 19:23:06,023 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5069999537663534e-05, 2508
[INFO] 2021-07-12 19:23:06,023 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2508
[INFO] 2021-07-12 19:23:06,023 [run_pretraining.py:  558]:	worker_index: 3, step: 2508, cost: 7.746242, mlm loss: 7.746242, speed: 1.091800 steps/s, speed: 8.734401 samples/s, speed: 4472.013180 tokens/s, learning rate: 2.507e-05, loss_scalings: 2814.750488, pp_loss: 7.223722
[INFO] 2021-07-12 19:23:06,023 [run_pretraining.py:  512]:	********exe.run_2508******* 
[INFO] 2021-07-12 19:23:06,947 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:06,947 [run_pretraining.py:  534]:	loss/total_loss, 7.19618034362793, 2509
[INFO] 2021-07-12 19:23:06,947 [run_pretraining.py:  535]:	loss/mlm_loss, 7.19618034362793, 2509
[INFO] 2021-07-12 19:23:06,948 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.508000034140423e-05, 2509
[INFO] 2021-07-12 19:23:06,948 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2509
[INFO] 2021-07-12 19:23:06,948 [run_pretraining.py:  558]:	worker_index: 3, step: 2509, cost: 7.196180, mlm loss: 7.196180, speed: 1.082449 steps/s, speed: 8.659593 samples/s, speed: 4433.711428 tokens/s, learning rate: 2.508e-05, loss_scalings: 2814.750488, pp_loss: 8.317776
[INFO] 2021-07-12 19:23:06,948 [run_pretraining.py:  512]:	********exe.run_2509******* 
[INFO] 2021-07-12 19:23:07,864 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:07,865 [run_pretraining.py:  534]:	loss/total_loss, 6.701133728027344, 2510
[INFO] 2021-07-12 19:23:07,865 [run_pretraining.py:  535]:	loss/mlm_loss, 6.701133728027344, 2510
[INFO] 2021-07-12 19:23:07,865 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.508999932615552e-05, 2510
[INFO] 2021-07-12 19:23:07,865 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2510
[INFO] 2021-07-12 19:23:07,865 [run_pretraining.py:  558]:	worker_index: 3, step: 2510, cost: 6.701134, mlm loss: 6.701134, speed: 1.090703 steps/s, speed: 8.725624 samples/s, speed: 4467.519658 tokens/s, learning rate: 2.509e-05, loss_scalings: 2814.750488, pp_loss: 6.975114
[INFO] 2021-07-12 19:23:07,865 [run_pretraining.py:  512]:	********exe.run_2510******* 
[INFO] 2021-07-12 19:23:08,783 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:08,783 [run_pretraining.py:  534]:	loss/total_loss, 7.525896072387695, 2511
[INFO] 2021-07-12 19:23:08,783 [run_pretraining.py:  535]:	loss/mlm_loss, 7.525896072387695, 2511
[INFO] 2021-07-12 19:23:08,783 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5099998310906813e-05, 2511
[INFO] 2021-07-12 19:23:08,783 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2511
[INFO] 2021-07-12 19:23:08,783 [run_pretraining.py:  558]:	worker_index: 3, step: 2511, cost: 7.525896, mlm loss: 7.525896, speed: 1.089822 steps/s, speed: 8.718573 samples/s, speed: 4463.909532 tokens/s, learning rate: 2.510e-05, loss_scalings: 2814.750488, pp_loss: 7.035021
[INFO] 2021-07-12 19:23:08,783 [run_pretraining.py:  512]:	********exe.run_2511******* 
[INFO] 2021-07-12 19:23:09,703 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:09,704 [run_pretraining.py:  534]:	loss/total_loss, 7.158907413482666, 2512
[INFO] 2021-07-12 19:23:09,704 [run_pretraining.py:  535]:	loss/mlm_loss, 7.158907413482666, 2512
[INFO] 2021-07-12 19:23:09,704 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5109999114647508e-05, 2512
[INFO] 2021-07-12 19:23:09,704 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2512
[INFO] 2021-07-12 19:23:09,704 [run_pretraining.py:  558]:	worker_index: 3, step: 2512, cost: 7.158907, mlm loss: 7.158907, speed: 1.086977 steps/s, speed: 8.695816 samples/s, speed: 4452.257772 tokens/s, learning rate: 2.511e-05, loss_scalings: 2814.750488, pp_loss: 7.261030
[INFO] 2021-07-12 19:23:09,704 [run_pretraining.py:  512]:	********exe.run_2512******* 
[INFO] 2021-07-12 19:23:10,620 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:10,621 [run_pretraining.py:  534]:	loss/total_loss, 6.788823127746582, 2513
[INFO] 2021-07-12 19:23:10,621 [run_pretraining.py:  535]:	loss/mlm_loss, 6.788823127746582, 2513
[INFO] 2021-07-12 19:23:10,621 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.51199980993988e-05, 2513
[INFO] 2021-07-12 19:23:10,621 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2513
[INFO] 2021-07-12 19:23:10,621 [run_pretraining.py:  558]:	worker_index: 3, step: 2513, cost: 6.788823, mlm loss: 6.788823, speed: 1.091290 steps/s, speed: 8.730319 samples/s, speed: 4469.923452 tokens/s, learning rate: 2.512e-05, loss_scalings: 2814.750488, pp_loss: 7.208804
[INFO] 2021-07-12 19:23:10,621 [run_pretraining.py:  512]:	********exe.run_2513******* 
[INFO] 2021-07-12 19:23:11,538 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:11,538 [run_pretraining.py:  534]:	loss/total_loss, 8.2793550491333, 2514
[INFO] 2021-07-12 19:23:11,538 [run_pretraining.py:  535]:	loss/mlm_loss, 8.2793550491333, 2514
[INFO] 2021-07-12 19:23:11,538 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5130000722128898e-05, 2514
[INFO] 2021-07-12 19:23:11,538 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2514
[INFO] 2021-07-12 19:23:11,539 [run_pretraining.py:  558]:	worker_index: 3, step: 2514, cost: 8.279355, mlm loss: 8.279355, speed: 1.090697 steps/s, speed: 8.725572 samples/s, speed: 4467.492938 tokens/s, learning rate: 2.513e-05, loss_scalings: 2814.750488, pp_loss: 7.472252
[INFO] 2021-07-12 19:23:11,539 [run_pretraining.py:  512]:	********exe.run_2514******* 
[INFO] 2021-07-12 19:23:12,459 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:12,460 [run_pretraining.py:  534]:	loss/total_loss, 7.3944597244262695, 2515
[INFO] 2021-07-12 19:23:12,460 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3944597244262695, 2515
[INFO] 2021-07-12 19:23:12,460 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5139997887890786e-05, 2515
[INFO] 2021-07-12 19:23:12,460 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2515
[INFO] 2021-07-12 19:23:12,460 [run_pretraining.py:  558]:	worker_index: 3, step: 2515, cost: 7.394460, mlm loss: 7.394460, speed: 1.086155 steps/s, speed: 8.689236 samples/s, speed: 4448.888840 tokens/s, learning rate: 2.514e-05, loss_scalings: 2814.750488, pp_loss: 7.454202
[INFO] 2021-07-12 19:23:12,460 [run_pretraining.py:  512]:	********exe.run_2515******* 
[INFO] 2021-07-12 19:23:13,381 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:13,381 [run_pretraining.py:  534]:	loss/total_loss, 6.829336166381836, 2516
[INFO] 2021-07-12 19:23:13,381 [run_pretraining.py:  535]:	loss/mlm_loss, 6.829336166381836, 2516
[INFO] 2021-07-12 19:23:13,381 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5150000510620885e-05, 2516
[INFO] 2021-07-12 19:23:13,381 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2516
[INFO] 2021-07-12 19:23:13,382 [run_pretraining.py:  558]:	worker_index: 3, step: 2516, cost: 6.829336, mlm loss: 6.829336, speed: 1.085751 steps/s, speed: 8.686010 samples/s, speed: 4447.237368 tokens/s, learning rate: 2.515e-05, loss_scalings: 2814.750488, pp_loss: 7.119775
[INFO] 2021-07-12 19:23:13,382 [run_pretraining.py:  512]:	********exe.run_2516******* 
[INFO] 2021-07-12 19:23:14,301 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:14,301 [run_pretraining.py:  534]:	loss/total_loss, 6.864136695861816, 2517
[INFO] 2021-07-12 19:23:14,301 [run_pretraining.py:  535]:	loss/mlm_loss, 6.864136695861816, 2517
[INFO] 2021-07-12 19:23:14,302 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5159999495372176e-05, 2517
[INFO] 2021-07-12 19:23:14,302 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2517
[INFO] 2021-07-12 19:23:14,302 [run_pretraining.py:  558]:	worker_index: 3, step: 2517, cost: 6.864137, mlm loss: 6.864137, speed: 1.087542 steps/s, speed: 8.700339 samples/s, speed: 4454.573553 tokens/s, learning rate: 2.516e-05, loss_scalings: 2814.750488, pp_loss: 7.277322
[INFO] 2021-07-12 19:23:14,302 [run_pretraining.py:  512]:	********exe.run_2517******* 
[INFO] 2021-07-12 19:23:15,247 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:15,248 [run_pretraining.py:  534]:	loss/total_loss, 7.2867255210876465, 2518
[INFO] 2021-07-12 19:23:15,248 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2867255210876465, 2518
[INFO] 2021-07-12 19:23:15,248 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.517000029911287e-05, 2518
[INFO] 2021-07-12 19:23:15,248 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2518
[INFO] 2021-07-12 19:23:15,248 [run_pretraining.py:  558]:	worker_index: 3, step: 2518, cost: 7.286726, mlm loss: 7.286726, speed: 1.057587 steps/s, speed: 8.460697 samples/s, speed: 4331.877054 tokens/s, learning rate: 2.517e-05, loss_scalings: 2814.750488, pp_loss: 6.984731
[INFO] 2021-07-12 19:23:15,248 [run_pretraining.py:  512]:	********exe.run_2518******* 
[INFO] 2021-07-12 19:23:16,158 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:16,158 [run_pretraining.py:  534]:	loss/total_loss, 7.25784969329834, 2519
[INFO] 2021-07-12 19:23:16,158 [run_pretraining.py:  535]:	loss/mlm_loss, 7.25784969329834, 2519
[INFO] 2021-07-12 19:23:16,158 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5179999283864163e-05, 2519
[INFO] 2021-07-12 19:23:16,159 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2519
[INFO] 2021-07-12 19:23:16,159 [run_pretraining.py:  558]:	worker_index: 3, step: 2519, cost: 7.257850, mlm loss: 7.257850, speed: 1.098860 steps/s, speed: 8.790876 samples/s, speed: 4500.928667 tokens/s, learning rate: 2.518e-05, loss_scalings: 2814.750488, pp_loss: 7.504761
[INFO] 2021-07-12 19:23:16,159 [run_pretraining.py:  512]:	********exe.run_2519******* 
[INFO] 2021-07-12 19:23:17,093 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:17,093 [run_pretraining.py:  534]:	loss/total_loss, 5.639420032501221, 2520
[INFO] 2021-07-12 19:23:17,094 [run_pretraining.py:  535]:	loss/mlm_loss, 5.639420032501221, 2520
[INFO] 2021-07-12 19:23:17,094 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5189998268615454e-05, 2520
[INFO] 2021-07-12 19:23:17,094 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2520
[INFO] 2021-07-12 19:23:17,094 [run_pretraining.py:  558]:	worker_index: 3, step: 2520, cost: 5.639420, mlm loss: 5.639420, speed: 1.070046 steps/s, speed: 8.560370 samples/s, speed: 4382.909275 tokens/s, learning rate: 2.519e-05, loss_scalings: 2814.750488, pp_loss: 6.832985
[INFO] 2021-07-12 19:23:17,094 [run_pretraining.py:  512]:	********exe.run_2520******* 
[INFO] 2021-07-12 19:23:18,014 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:18,015 [run_pretraining.py:  534]:	loss/total_loss, 6.984166145324707, 2521
[INFO] 2021-07-12 19:23:18,015 [run_pretraining.py:  535]:	loss/mlm_loss, 6.984166145324707, 2521
[INFO] 2021-07-12 19:23:18,015 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.519999907235615e-05, 2521
[INFO] 2021-07-12 19:23:18,015 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2521
[INFO] 2021-07-12 19:23:18,015 [run_pretraining.py:  558]:	worker_index: 3, step: 2521, cost: 6.984166, mlm loss: 6.984166, speed: 1.085906 steps/s, speed: 8.687247 samples/s, speed: 4447.870633 tokens/s, learning rate: 2.520e-05, loss_scalings: 2814.750488, pp_loss: 7.203043
[INFO] 2021-07-12 19:23:18,015 [run_pretraining.py:  512]:	********exe.run_2521******* 
[INFO] 2021-07-12 19:23:18,942 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:18,943 [run_pretraining.py:  534]:	loss/total_loss, 8.482081413269043, 2522
[INFO] 2021-07-12 19:23:18,943 [run_pretraining.py:  535]:	loss/mlm_loss, 8.482081413269043, 2522
[INFO] 2021-07-12 19:23:18,943 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.520999805710744e-05, 2522
[INFO] 2021-07-12 19:23:18,943 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2522
[INFO] 2021-07-12 19:23:18,943 [run_pretraining.py:  558]:	worker_index: 3, step: 2522, cost: 8.482081, mlm loss: 8.482081, speed: 1.078320 steps/s, speed: 8.626556 samples/s, speed: 4416.796909 tokens/s, learning rate: 2.521e-05, loss_scalings: 2814.750488, pp_loss: 7.371716
[INFO] 2021-07-12 19:23:18,943 [run_pretraining.py:  512]:	********exe.run_2522******* 
[INFO] 2021-07-12 19:23:19,873 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:19,874 [run_pretraining.py:  534]:	loss/total_loss, 7.9802632331848145, 2523
[INFO] 2021-07-12 19:23:19,874 [run_pretraining.py:  535]:	loss/mlm_loss, 7.9802632331848145, 2523
[INFO] 2021-07-12 19:23:19,874 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.522000067983754e-05, 2523
[INFO] 2021-07-12 19:23:19,874 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2523
[INFO] 2021-07-12 19:23:19,874 [run_pretraining.py:  558]:	worker_index: 3, step: 2523, cost: 7.980263, mlm loss: 7.980263, speed: 1.074954 steps/s, speed: 8.599630 samples/s, speed: 4403.010571 tokens/s, learning rate: 2.522e-05, loss_scalings: 2814.750488, pp_loss: 7.396377
[INFO] 2021-07-12 19:23:19,874 [run_pretraining.py:  512]:	********exe.run_2523******* 
[INFO] 2021-07-12 19:23:20,861 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:20,862 [run_pretraining.py:  534]:	loss/total_loss, 7.379140377044678, 2524
[INFO] 2021-07-12 19:23:20,862 [run_pretraining.py:  535]:	loss/mlm_loss, 7.379140377044678, 2524
[INFO] 2021-07-12 19:23:20,862 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.522999966458883e-05, 2524
[INFO] 2021-07-12 19:23:20,862 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2524
[INFO] 2021-07-12 19:23:20,862 [run_pretraining.py:  558]:	worker_index: 3, step: 2524, cost: 7.379140, mlm loss: 7.379140, speed: 1.013032 steps/s, speed: 8.104256 samples/s, speed: 4149.379070 tokens/s, learning rate: 2.523e-05, loss_scalings: 2814.750488, pp_loss: 6.880461
[INFO] 2021-07-12 19:23:20,862 [run_pretraining.py:  512]:	********exe.run_2524******* 
[INFO] 2021-07-12 19:23:21,784 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:21,785 [run_pretraining.py:  534]:	loss/total_loss, 7.191091060638428, 2525
[INFO] 2021-07-12 19:23:21,785 [run_pretraining.py:  535]:	loss/mlm_loss, 7.191091060638428, 2525
[INFO] 2021-07-12 19:23:21,785 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5240000468329526e-05, 2525
[INFO] 2021-07-12 19:23:21,785 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2525
[INFO] 2021-07-12 19:23:21,785 [run_pretraining.py:  558]:	worker_index: 3, step: 2525, cost: 7.191091, mlm loss: 7.191091, speed: 1.084251 steps/s, speed: 8.674004 samples/s, speed: 4441.090269 tokens/s, learning rate: 2.524e-05, loss_scalings: 2814.750488, pp_loss: 7.147391
[INFO] 2021-07-12 19:23:21,785 [run_pretraining.py:  512]:	********exe.run_2525******* 
[INFO] 2021-07-12 19:23:22,731 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:22,732 [run_pretraining.py:  534]:	loss/total_loss, 7.382584095001221, 2526
[INFO] 2021-07-12 19:23:22,732 [run_pretraining.py:  535]:	loss/mlm_loss, 7.382584095001221, 2526
[INFO] 2021-07-12 19:23:22,732 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5249999453080818e-05, 2526
[INFO] 2021-07-12 19:23:22,732 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2526
[INFO] 2021-07-12 19:23:22,732 [run_pretraining.py:  558]:	worker_index: 3, step: 2526, cost: 7.382584, mlm loss: 7.382584, speed: 1.056517 steps/s, speed: 8.452136 samples/s, speed: 4327.493821 tokens/s, learning rate: 2.525e-05, loss_scalings: 2814.750488, pp_loss: 6.713892
[INFO] 2021-07-12 19:23:22,732 [run_pretraining.py:  512]:	********exe.run_2526******* 
[INFO] 2021-07-12 19:23:23,651 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:23,651 [run_pretraining.py:  534]:	loss/total_loss, 7.132789134979248, 2527
[INFO] 2021-07-12 19:23:23,652 [run_pretraining.py:  535]:	loss/mlm_loss, 7.132789134979248, 2527
[INFO] 2021-07-12 19:23:23,652 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5260000256821513e-05, 2527
[INFO] 2021-07-12 19:23:23,652 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2527
[INFO] 2021-07-12 19:23:23,652 [run_pretraining.py:  558]:	worker_index: 3, step: 2527, cost: 7.132789, mlm loss: 7.132789, speed: 1.088103 steps/s, speed: 8.704822 samples/s, speed: 4456.868620 tokens/s, learning rate: 2.526e-05, loss_scalings: 2814.750488, pp_loss: 7.398628
[INFO] 2021-07-12 19:23:23,652 [run_pretraining.py:  512]:	********exe.run_2527******* 
[INFO] 2021-07-12 19:23:24,561 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:24,561 [run_pretraining.py:  534]:	loss/total_loss, 7.176100254058838, 2528
[INFO] 2021-07-12 19:23:24,562 [run_pretraining.py:  535]:	loss/mlm_loss, 7.176100254058838, 2528
[INFO] 2021-07-12 19:23:24,562 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5269999241572805e-05, 2528
[INFO] 2021-07-12 19:23:24,562 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2528
[INFO] 2021-07-12 19:23:24,562 [run_pretraining.py:  558]:	worker_index: 3, step: 2528, cost: 7.176100, mlm loss: 7.176100, speed: 1.099620 steps/s, speed: 8.796963 samples/s, speed: 4504.045068 tokens/s, learning rate: 2.527e-05, loss_scalings: 2814.750488, pp_loss: 7.308627
[INFO] 2021-07-12 19:23:24,562 [run_pretraining.py:  512]:	********exe.run_2528******* 
[INFO] 2021-07-12 19:23:25,481 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:25,481 [run_pretraining.py:  534]:	loss/total_loss, 7.956033229827881, 2529
[INFO] 2021-07-12 19:23:25,481 [run_pretraining.py:  535]:	loss/mlm_loss, 7.956033229827881, 2529
[INFO] 2021-07-12 19:23:25,481 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5279998226324096e-05, 2529
[INFO] 2021-07-12 19:23:25,481 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2529
[INFO] 2021-07-12 19:23:25,481 [run_pretraining.py:  558]:	worker_index: 3, step: 2529, cost: 7.956033, mlm loss: 7.956033, speed: 1.088131 steps/s, speed: 8.705047 samples/s, speed: 4456.984245 tokens/s, learning rate: 2.528e-05, loss_scalings: 2814.750488, pp_loss: 7.262174
[INFO] 2021-07-12 19:23:25,481 [run_pretraining.py:  512]:	********exe.run_2529******* 
[INFO] 2021-07-12 19:23:26,396 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:26,396 [run_pretraining.py:  534]:	loss/total_loss, 7.324699401855469, 2530
[INFO] 2021-07-12 19:23:26,397 [run_pretraining.py:  535]:	loss/mlm_loss, 7.324699401855469, 2530
[INFO] 2021-07-12 19:23:26,397 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.528999903006479e-05, 2530
[INFO] 2021-07-12 19:23:26,397 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2530
[INFO] 2021-07-12 19:23:26,397 [run_pretraining.py:  558]:	worker_index: 3, step: 2530, cost: 7.324699, mlm loss: 7.324699, speed: 1.093218 steps/s, speed: 8.745740 samples/s, speed: 4477.819036 tokens/s, learning rate: 2.529e-05, loss_scalings: 2814.750488, pp_loss: 7.218727
[INFO] 2021-07-12 19:23:26,397 [run_pretraining.py:  512]:	********exe.run_2530******* 
[INFO] 2021-07-12 19:23:27,314 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:27,314 [run_pretraining.py:  534]:	loss/total_loss, 7.440382957458496, 2531
[INFO] 2021-07-12 19:23:27,315 [run_pretraining.py:  535]:	loss/mlm_loss, 7.440382957458496, 2531
[INFO] 2021-07-12 19:23:27,315 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5299998014816083e-05, 2531
[INFO] 2021-07-12 19:23:27,315 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2531
[INFO] 2021-07-12 19:23:27,315 [run_pretraining.py:  558]:	worker_index: 3, step: 2531, cost: 7.440383, mlm loss: 7.440383, speed: 1.090039 steps/s, speed: 8.720316 samples/s, speed: 4464.801654 tokens/s, learning rate: 2.530e-05, loss_scalings: 2814.750488, pp_loss: 7.105727
[INFO] 2021-07-12 19:23:27,315 [run_pretraining.py:  512]:	********exe.run_2531******* 
[INFO] 2021-07-12 19:23:28,228 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:28,229 [run_pretraining.py:  534]:	loss/total_loss, 6.866837024688721, 2532
[INFO] 2021-07-12 19:23:28,229 [run_pretraining.py:  535]:	loss/mlm_loss, 6.866837024688721, 2532
[INFO] 2021-07-12 19:23:28,229 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.531000063754618e-05, 2532
[INFO] 2021-07-12 19:23:28,229 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2532
[INFO] 2021-07-12 19:23:28,229 [run_pretraining.py:  558]:	worker_index: 3, step: 2532, cost: 6.866837, mlm loss: 6.866837, speed: 1.094602 steps/s, speed: 8.756817 samples/s, speed: 4483.490213 tokens/s, learning rate: 2.531e-05, loss_scalings: 2814.750488, pp_loss: 7.004512
[INFO] 2021-07-12 19:23:28,229 [run_pretraining.py:  512]:	********exe.run_2532******* 
[INFO] 2021-07-12 19:23:29,136 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:29,137 [run_pretraining.py:  534]:	loss/total_loss, 8.155437469482422, 2533
[INFO] 2021-07-12 19:23:29,137 [run_pretraining.py:  535]:	loss/mlm_loss, 8.155437469482422, 2533
[INFO] 2021-07-12 19:23:29,137 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5319999622297473e-05, 2533
[INFO] 2021-07-12 19:23:29,137 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2533
[INFO] 2021-07-12 19:23:29,137 [run_pretraining.py:  558]:	worker_index: 3, step: 2533, cost: 8.155437, mlm loss: 8.155437, speed: 1.101828 steps/s, speed: 8.814628 samples/s, speed: 4513.089421 tokens/s, learning rate: 2.532e-05, loss_scalings: 2814.750488, pp_loss: 6.816126
[INFO] 2021-07-12 19:23:29,137 [run_pretraining.py:  512]:	********exe.run_2533******* 
[INFO] 2021-07-12 19:23:30,055 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:30,056 [run_pretraining.py:  534]:	loss/total_loss, 7.247997760772705, 2534
[INFO] 2021-07-12 19:23:30,056 [run_pretraining.py:  535]:	loss/mlm_loss, 7.247997760772705, 2534
[INFO] 2021-07-12 19:23:30,056 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.533000042603817e-05, 2534
[INFO] 2021-07-12 19:23:30,056 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2534
[INFO] 2021-07-12 19:23:30,056 [run_pretraining.py:  558]:	worker_index: 3, step: 2534, cost: 7.247998, mlm loss: 7.247998, speed: 1.088918 steps/s, speed: 8.711346 samples/s, speed: 4460.209124 tokens/s, learning rate: 2.533e-05, loss_scalings: 2814.750488, pp_loss: 6.915642
[INFO] 2021-07-12 19:23:30,056 [run_pretraining.py:  512]:	********exe.run_2534******* 
[INFO] 2021-07-12 19:23:30,968 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:30,968 [run_pretraining.py:  534]:	loss/total_loss, 8.013374328613281, 2535
[INFO] 2021-07-12 19:23:30,968 [run_pretraining.py:  535]:	loss/mlm_loss, 8.013374328613281, 2535
[INFO] 2021-07-12 19:23:30,968 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.533999941078946e-05, 2535
[INFO] 2021-07-12 19:23:30,968 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2535
[INFO] 2021-07-12 19:23:30,968 [run_pretraining.py:  558]:	worker_index: 3, step: 2535, cost: 8.013374, mlm loss: 8.013374, speed: 1.097074 steps/s, speed: 8.776593 samples/s, speed: 4493.615430 tokens/s, learning rate: 2.534e-05, loss_scalings: 2814.750488, pp_loss: 7.831951
[INFO] 2021-07-12 19:23:30,968 [run_pretraining.py:  512]:	********exe.run_2535******* 
[INFO] 2021-07-12 19:23:31,880 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:31,880 [run_pretraining.py:  534]:	loss/total_loss, 7.106511116027832, 2536
[INFO] 2021-07-12 19:23:31,880 [run_pretraining.py:  535]:	loss/mlm_loss, 7.106511116027832, 2536
[INFO] 2021-07-12 19:23:31,880 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5350000214530155e-05, 2536
[INFO] 2021-07-12 19:23:31,881 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2536
[INFO] 2021-07-12 19:23:31,881 [run_pretraining.py:  558]:	worker_index: 3, step: 2536, cost: 7.106511, mlm loss: 7.106511, speed: 1.096998 steps/s, speed: 8.775984 samples/s, speed: 4493.303980 tokens/s, learning rate: 2.535e-05, loss_scalings: 2814.750488, pp_loss: 7.235863
[INFO] 2021-07-12 19:23:31,881 [run_pretraining.py:  512]:	********exe.run_2536******* 
[INFO] 2021-07-12 19:23:32,793 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:32,793 [run_pretraining.py:  534]:	loss/total_loss, 7.049474716186523, 2537
[INFO] 2021-07-12 19:23:32,794 [run_pretraining.py:  535]:	loss/mlm_loss, 7.049474716186523, 2537
[INFO] 2021-07-12 19:23:32,794 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5359999199281447e-05, 2537
[INFO] 2021-07-12 19:23:32,794 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2537
[INFO] 2021-07-12 19:23:32,794 [run_pretraining.py:  558]:	worker_index: 3, step: 2537, cost: 7.049475, mlm loss: 7.049475, speed: 1.095866 steps/s, speed: 8.766932 samples/s, speed: 4488.669077 tokens/s, learning rate: 2.536e-05, loss_scalings: 2814.750488, pp_loss: 7.335288
[INFO] 2021-07-12 19:23:32,794 [run_pretraining.py:  512]:	********exe.run_2537******* 
[INFO] 2021-07-12 19:23:33,736 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:33,737 [run_pretraining.py:  534]:	loss/total_loss, 6.674355506896973, 2538
[INFO] 2021-07-12 19:23:33,737 [run_pretraining.py:  535]:	loss/mlm_loss, 6.674355506896973, 2538
[INFO] 2021-07-12 19:23:33,737 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5369998184032738e-05, 2538
[INFO] 2021-07-12 19:23:33,737 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2538
[INFO] 2021-07-12 19:23:33,737 [run_pretraining.py:  558]:	worker_index: 3, step: 2538, cost: 6.674356, mlm loss: 6.674356, speed: 1.060636 steps/s, speed: 8.485090 samples/s, speed: 4344.365996 tokens/s, learning rate: 2.537e-05, loss_scalings: 2814.750488, pp_loss: 7.177126
[INFO] 2021-07-12 19:23:33,737 [run_pretraining.py:  512]:	********exe.run_2538******* 
[INFO] 2021-07-12 19:23:34,668 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:34,669 [run_pretraining.py:  534]:	loss/total_loss, 7.461709022521973, 2539
[INFO] 2021-07-12 19:23:34,669 [run_pretraining.py:  535]:	loss/mlm_loss, 7.461709022521973, 2539
[INFO] 2021-07-12 19:23:34,669 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5379998987773433e-05, 2539
[INFO] 2021-07-12 19:23:34,669 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2539
[INFO] 2021-07-12 19:23:34,669 [run_pretraining.py:  558]:	worker_index: 3, step: 2539, cost: 7.461709, mlm loss: 7.461709, speed: 1.073809 steps/s, speed: 8.590476 samples/s, speed: 4398.323500 tokens/s, learning rate: 2.538e-05, loss_scalings: 2814.750488, pp_loss: 7.491916
[INFO] 2021-07-12 19:23:34,669 [run_pretraining.py:  512]:	********exe.run_2539******* 
[INFO] 2021-07-12 19:23:35,718 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:35,718 [run_pretraining.py:  534]:	loss/total_loss, 7.113554954528809, 2540
[INFO] 2021-07-12 19:23:35,718 [run_pretraining.py:  535]:	loss/mlm_loss, 7.113554954528809, 2540
[INFO] 2021-07-12 19:23:35,719 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5389997972524725e-05, 2540
[INFO] 2021-07-12 19:23:35,719 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2540
[INFO] 2021-07-12 19:23:35,719 [run_pretraining.py:  558]:	worker_index: 3, step: 2540, cost: 7.113555, mlm loss: 7.113555, speed: 0.953418 steps/s, speed: 7.627344 samples/s, speed: 3905.200021 tokens/s, learning rate: 2.539e-05, loss_scalings: 2814.750488, pp_loss: 6.717875
[INFO] 2021-07-12 19:23:35,719 [run_pretraining.py:  512]:	********exe.run_2540******* 
[INFO] 2021-07-12 19:23:36,782 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:36,783 [run_pretraining.py:  534]:	loss/total_loss, 7.509528636932373, 2541
[INFO] 2021-07-12 19:23:36,783 [run_pretraining.py:  535]:	loss/mlm_loss, 7.509528636932373, 2541
[INFO] 2021-07-12 19:23:36,783 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5400000595254824e-05, 2541
[INFO] 2021-07-12 19:23:36,783 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2541
[INFO] 2021-07-12 19:23:36,783 [run_pretraining.py:  558]:	worker_index: 3, step: 2541, cost: 7.509529, mlm loss: 7.509529, speed: 0.940023 steps/s, speed: 7.520181 samples/s, speed: 3850.332791 tokens/s, learning rate: 2.540e-05, loss_scalings: 2814.750488, pp_loss: 7.308289
[INFO] 2021-07-12 19:23:36,783 [run_pretraining.py:  512]:	********exe.run_2541******* 
[INFO] 2021-07-12 19:23:37,822 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:37,823 [run_pretraining.py:  534]:	loss/total_loss, 7.209285259246826, 2542
[INFO] 2021-07-12 19:23:37,823 [run_pretraining.py:  535]:	loss/mlm_loss, 7.209285259246826, 2542
[INFO] 2021-07-12 19:23:37,823 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5409999580006115e-05, 2542
[INFO] 2021-07-12 19:23:37,823 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2542
[INFO] 2021-07-12 19:23:37,823 [run_pretraining.py:  558]:	worker_index: 3, step: 2542, cost: 7.209285, mlm loss: 7.209285, speed: 0.962070 steps/s, speed: 7.696560 samples/s, speed: 3940.638843 tokens/s, learning rate: 2.541e-05, loss_scalings: 2814.750488, pp_loss: 7.216782
[INFO] 2021-07-12 19:23:37,823 [run_pretraining.py:  512]:	********exe.run_2542******* 
[INFO] 2021-07-12 19:23:38,872 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:38,873 [run_pretraining.py:  534]:	loss/total_loss, 6.90309476852417, 2543
[INFO] 2021-07-12 19:23:38,873 [run_pretraining.py:  535]:	loss/mlm_loss, 6.90309476852417, 2543
[INFO] 2021-07-12 19:23:38,873 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.542000038374681e-05, 2543
[INFO] 2021-07-12 19:23:38,873 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2543
[INFO] 2021-07-12 19:23:38,873 [run_pretraining.py:  558]:	worker_index: 3, step: 2543, cost: 6.903095, mlm loss: 6.903095, speed: 0.953205 steps/s, speed: 7.625638 samples/s, speed: 3904.326719 tokens/s, learning rate: 2.542e-05, loss_scalings: 2814.750488, pp_loss: 7.397909
[INFO] 2021-07-12 19:23:38,873 [run_pretraining.py:  512]:	********exe.run_2543******* 
[INFO] 2021-07-12 19:23:39,928 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:39,929 [run_pretraining.py:  534]:	loss/total_loss, 7.187659740447998, 2544
[INFO] 2021-07-12 19:23:39,929 [run_pretraining.py:  535]:	loss/mlm_loss, 7.187659740447998, 2544
[INFO] 2021-07-12 19:23:39,929 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5429999368498102e-05, 2544
[INFO] 2021-07-12 19:23:39,929 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2544
[INFO] 2021-07-12 19:23:39,929 [run_pretraining.py:  558]:	worker_index: 3, step: 2544, cost: 7.187660, mlm loss: 7.187660, speed: 0.947410 steps/s, speed: 7.579281 samples/s, speed: 3880.591875 tokens/s, learning rate: 2.543e-05, loss_scalings: 2814.750488, pp_loss: 7.483752
[INFO] 2021-07-12 19:23:39,929 [run_pretraining.py:  512]:	********exe.run_2544******* 
[INFO] 2021-07-12 19:23:40,977 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:40,978 [run_pretraining.py:  534]:	loss/total_loss, 6.996424198150635, 2545
[INFO] 2021-07-12 19:23:40,978 [run_pretraining.py:  535]:	loss/mlm_loss, 6.996424198150635, 2545
[INFO] 2021-07-12 19:23:40,978 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5440000172238797e-05, 2545
[INFO] 2021-07-12 19:23:40,978 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2545
[INFO] 2021-07-12 19:23:40,978 [run_pretraining.py:  558]:	worker_index: 3, step: 2545, cost: 6.996424, mlm loss: 6.996424, speed: 0.954008 steps/s, speed: 7.632064 samples/s, speed: 3907.616951 tokens/s, learning rate: 2.544e-05, loss_scalings: 2814.750488, pp_loss: 7.353480
[INFO] 2021-07-12 19:23:40,978 [run_pretraining.py:  512]:	********exe.run_2545******* 
[INFO] 2021-07-12 19:23:42,029 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:42,029 [run_pretraining.py:  534]:	loss/total_loss, 7.735781669616699, 2546
[INFO] 2021-07-12 19:23:42,029 [run_pretraining.py:  535]:	loss/mlm_loss, 7.735781669616699, 2546
[INFO] 2021-07-12 19:23:42,030 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.544999915699009e-05, 2546
[INFO] 2021-07-12 19:23:42,030 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2546
[INFO] 2021-07-12 19:23:42,030 [run_pretraining.py:  558]:	worker_index: 3, step: 2546, cost: 7.735782, mlm loss: 7.735782, speed: 0.951294 steps/s, speed: 7.610356 samples/s, speed: 3896.502213 tokens/s, learning rate: 2.545e-05, loss_scalings: 2814.750488, pp_loss: 7.207406
[INFO] 2021-07-12 19:23:42,030 [run_pretraining.py:  512]:	********exe.run_2546******* 
[INFO] 2021-07-12 19:23:43,086 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:43,087 [run_pretraining.py:  534]:	loss/total_loss, 7.009076118469238, 2547
[INFO] 2021-07-12 19:23:43,087 [run_pretraining.py:  535]:	loss/mlm_loss, 7.009076118469238, 2547
[INFO] 2021-07-12 19:23:43,087 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.545999814174138e-05, 2547
[INFO] 2021-07-12 19:23:43,087 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2547
[INFO] 2021-07-12 19:23:43,087 [run_pretraining.py:  558]:	worker_index: 3, step: 2547, cost: 7.009076, mlm loss: 7.009076, speed: 0.946191 steps/s, speed: 7.569532 samples/s, speed: 3875.600223 tokens/s, learning rate: 2.546e-05, loss_scalings: 2814.750488, pp_loss: 7.065571
[INFO] 2021-07-12 19:23:43,087 [run_pretraining.py:  512]:	********exe.run_2547******* 
[INFO] 2021-07-12 19:23:44,149 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:44,149 [run_pretraining.py:  534]:	loss/total_loss, 6.434661865234375, 2548
[INFO] 2021-07-12 19:23:44,150 [run_pretraining.py:  535]:	loss/mlm_loss, 6.434661865234375, 2548
[INFO] 2021-07-12 19:23:44,150 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.547000076447148e-05, 2548
[INFO] 2021-07-12 19:23:44,150 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2548
[INFO] 2021-07-12 19:23:44,150 [run_pretraining.py:  558]:	worker_index: 3, step: 2548, cost: 6.434662, mlm loss: 6.434662, speed: 0.941708 steps/s, speed: 7.533660 samples/s, speed: 3857.233926 tokens/s, learning rate: 2.547e-05, loss_scalings: 2814.750488, pp_loss: 7.065060
[INFO] 2021-07-12 19:23:44,150 [run_pretraining.py:  512]:	********exe.run_2548******* 
[INFO] 2021-07-12 19:23:45,214 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:45,215 [run_pretraining.py:  534]:	loss/total_loss, 7.526189804077148, 2549
[INFO] 2021-07-12 19:23:45,215 [run_pretraining.py:  535]:	loss/mlm_loss, 7.526189804077148, 2549
[INFO] 2021-07-12 19:23:45,215 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5479997930233367e-05, 2549
[INFO] 2021-07-12 19:23:45,215 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2549
[INFO] 2021-07-12 19:23:45,215 [run_pretraining.py:  558]:	worker_index: 3, step: 2549, cost: 7.526190, mlm loss: 7.526190, speed: 0.939231 steps/s, speed: 7.513849 samples/s, speed: 3847.090897 tokens/s, learning rate: 2.548e-05, loss_scalings: 2814.750488, pp_loss: 7.479182
[INFO] 2021-07-12 19:23:45,215 [run_pretraining.py:  512]:	********exe.run_2549******* 
[INFO] 2021-07-12 19:23:46,283 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:46,283 [run_pretraining.py:  534]:	loss/total_loss, 6.97586727142334, 2550
[INFO] 2021-07-12 19:23:46,283 [run_pretraining.py:  535]:	loss/mlm_loss, 6.97586727142334, 2550
[INFO] 2021-07-12 19:23:46,283 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5490000552963465e-05, 2550
[INFO] 2021-07-12 19:23:46,283 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2550
[INFO] 2021-07-12 19:23:46,284 [run_pretraining.py:  558]:	worker_index: 3, step: 2550, cost: 6.975867, mlm loss: 6.975867, speed: 0.936531 steps/s, speed: 7.492247 samples/s, speed: 3836.030376 tokens/s, learning rate: 2.549e-05, loss_scalings: 2814.750488, pp_loss: 6.974467
[INFO] 2021-07-12 19:23:46,284 [run_pretraining.py:  512]:	********exe.run_2550******* 
[INFO] 2021-07-12 19:23:47,387 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:47,393 [run_pretraining.py:  534]:	loss/total_loss, 7.542668342590332, 2551
[INFO] 2021-07-12 19:23:47,398 [run_pretraining.py:  535]:	loss/mlm_loss, 7.542668342590332, 2551
[INFO] 2021-07-12 19:23:47,403 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5499999537714757e-05, 2551
[INFO] 2021-07-12 19:23:47,405 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2551
[INFO] 2021-07-12 19:23:47,411 [run_pretraining.py:  558]:	worker_index: 3, step: 2551, cost: 7.542668, mlm loss: 7.542668, speed: 0.901630 steps/s, speed: 7.213038 samples/s, speed: 3693.075406 tokens/s, learning rate: 2.550e-05, loss_scalings: 2814.750488, pp_loss: 7.226989
[INFO] 2021-07-12 19:23:47,414 [run_pretraining.py:  512]:	********exe.run_2551******* 
[INFO] 2021-07-12 19:23:48,400 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:48,401 [run_pretraining.py:  534]:	loss/total_loss, 7.705214977264404, 2552
[INFO] 2021-07-12 19:23:48,401 [run_pretraining.py:  535]:	loss/mlm_loss, 7.705214977264404, 2552
[INFO] 2021-07-12 19:23:48,401 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5510000341455452e-05, 2552
[INFO] 2021-07-12 19:23:48,401 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2552
[INFO] 2021-07-12 19:23:48,401 [run_pretraining.py:  558]:	worker_index: 3, step: 2552, cost: 7.705215, mlm loss: 7.705215, speed: 1.013619 steps/s, speed: 8.108951 samples/s, speed: 4151.782690 tokens/s, learning rate: 2.551e-05, loss_scalings: 2814.750488, pp_loss: 7.353006
[INFO] 2021-07-12 19:23:48,401 [run_pretraining.py:  512]:	********exe.run_2552******* 
[INFO] 2021-07-12 19:23:49,461 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:49,461 [run_pretraining.py:  534]:	loss/total_loss, 7.099410533905029, 2553
[INFO] 2021-07-12 19:23:49,462 [run_pretraining.py:  535]:	loss/mlm_loss, 7.099410533905029, 2553
[INFO] 2021-07-12 19:23:49,462 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5519999326206744e-05, 2553
[INFO] 2021-07-12 19:23:49,462 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2553
[INFO] 2021-07-12 19:23:49,462 [run_pretraining.py:  558]:	worker_index: 3, step: 2553, cost: 7.099411, mlm loss: 7.099411, speed: 0.943628 steps/s, speed: 7.549026 samples/s, speed: 3865.101353 tokens/s, learning rate: 2.552e-05, loss_scalings: 2814.750488, pp_loss: 7.095949
[INFO] 2021-07-12 19:23:49,462 [run_pretraining.py:  512]:	********exe.run_2553******* 
[INFO] 2021-07-12 19:23:50,509 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:50,509 [run_pretraining.py:  534]:	loss/total_loss, 7.420843124389648, 2554
[INFO] 2021-07-12 19:23:50,509 [run_pretraining.py:  535]:	loss/mlm_loss, 7.420843124389648, 2554
[INFO] 2021-07-12 19:23:50,509 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5529998310958035e-05, 2554
[INFO] 2021-07-12 19:23:50,509 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2554
[INFO] 2021-07-12 19:23:50,509 [run_pretraining.py:  558]:	worker_index: 3, step: 2554, cost: 7.420843, mlm loss: 7.420843, speed: 0.954997 steps/s, speed: 7.639978 samples/s, speed: 3911.668743 tokens/s, learning rate: 2.553e-05, loss_scalings: 2814.750488, pp_loss: 7.400773
[INFO] 2021-07-12 19:23:50,510 [run_pretraining.py:  512]:	********exe.run_2554******* 
[INFO] 2021-07-12 19:23:51,555 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:51,556 [run_pretraining.py:  534]:	loss/total_loss, 7.738973617553711, 2555
[INFO] 2021-07-12 19:23:51,556 [run_pretraining.py:  535]:	loss/mlm_loss, 7.738973617553711, 2555
[INFO] 2021-07-12 19:23:51,556 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.553999911469873e-05, 2555
[INFO] 2021-07-12 19:23:51,556 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2555
[INFO] 2021-07-12 19:23:51,556 [run_pretraining.py:  558]:	worker_index: 3, step: 2555, cost: 7.738974, mlm loss: 7.738974, speed: 0.955802 steps/s, speed: 7.646413 samples/s, speed: 3914.963337 tokens/s, learning rate: 2.554e-05, loss_scalings: 2814.750488, pp_loss: 7.570861
[INFO] 2021-07-12 19:23:51,556 [run_pretraining.py:  512]:	********exe.run_2555******* 
[INFO] 2021-07-12 19:23:52,543 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:52,544 [run_pretraining.py:  534]:	loss/total_loss, 6.90938138961792, 2556
[INFO] 2021-07-12 19:23:52,544 [run_pretraining.py:  535]:	loss/mlm_loss, 6.90938138961792, 2556
[INFO] 2021-07-12 19:23:52,544 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5549998099450022e-05, 2556
[INFO] 2021-07-12 19:23:52,544 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2556
[INFO] 2021-07-12 19:23:52,544 [run_pretraining.py:  558]:	worker_index: 3, step: 2556, cost: 6.909381, mlm loss: 6.909381, speed: 1.013331 steps/s, speed: 8.106645 samples/s, speed: 4150.602092 tokens/s, learning rate: 2.555e-05, loss_scalings: 2814.750488, pp_loss: 7.244849
[INFO] 2021-07-12 19:23:52,544 [run_pretraining.py:  512]:	********exe.run_2556******* 
[INFO] 2021-07-12 19:23:53,506 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:53,507 [run_pretraining.py:  534]:	loss/total_loss, 7.239091873168945, 2557
[INFO] 2021-07-12 19:23:53,507 [run_pretraining.py:  535]:	loss/mlm_loss, 7.239091873168945, 2557
[INFO] 2021-07-12 19:23:53,507 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.556000072218012e-05, 2557
[INFO] 2021-07-12 19:23:53,507 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2557
[INFO] 2021-07-12 19:23:53,507 [run_pretraining.py:  558]:	worker_index: 3, step: 2557, cost: 7.239092, mlm loss: 7.239092, speed: 1.038891 steps/s, speed: 8.311132 samples/s, speed: 4255.299395 tokens/s, learning rate: 2.556e-05, loss_scalings: 2814.750488, pp_loss: 7.309927
[INFO] 2021-07-12 19:23:53,507 [run_pretraining.py:  512]:	********exe.run_2557******* 
[INFO] 2021-07-12 19:23:54,485 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:54,485 [run_pretraining.py:  534]:	loss/total_loss, 8.37332534790039, 2558
[INFO] 2021-07-12 19:23:54,486 [run_pretraining.py:  535]:	loss/mlm_loss, 8.37332534790039, 2558
[INFO] 2021-07-12 19:23:54,486 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.556999788794201e-05, 2558
[INFO] 2021-07-12 19:23:54,486 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2558
[INFO] 2021-07-12 19:23:54,486 [run_pretraining.py:  558]:	worker_index: 3, step: 2558, cost: 8.373325, mlm loss: 8.373325, speed: 1.022368 steps/s, speed: 8.178941 samples/s, speed: 4187.617716 tokens/s, learning rate: 2.557e-05, loss_scalings: 2814.750488, pp_loss: 7.112267
[INFO] 2021-07-12 19:23:54,486 [run_pretraining.py:  512]:	********exe.run_2558******* 
[INFO] 2021-07-12 19:23:55,468 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:55,469 [run_pretraining.py:  534]:	loss/total_loss, 7.071814060211182, 2559
[INFO] 2021-07-12 19:23:55,469 [run_pretraining.py:  535]:	loss/mlm_loss, 7.071814060211182, 2559
[INFO] 2021-07-12 19:23:55,469 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5580000510672107e-05, 2559
[INFO] 2021-07-12 19:23:55,469 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2559
[INFO] 2021-07-12 19:23:55,469 [run_pretraining.py:  558]:	worker_index: 3, step: 2559, cost: 7.071814, mlm loss: 7.071814, speed: 1.017667 steps/s, speed: 8.141333 samples/s, speed: 4168.362659 tokens/s, learning rate: 2.558e-05, loss_scalings: 2814.750488, pp_loss: 6.591745
[INFO] 2021-07-12 19:23:55,469 [run_pretraining.py:  512]:	********exe.run_2559******* 
[INFO] 2021-07-12 19:23:56,440 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:56,440 [run_pretraining.py:  534]:	loss/total_loss, 7.436689376831055, 2560
[INFO] 2021-07-12 19:23:56,440 [run_pretraining.py:  535]:	loss/mlm_loss, 7.436689376831055, 2560
[INFO] 2021-07-12 19:23:56,440 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.55899994954234e-05, 2560
[INFO] 2021-07-12 19:23:56,441 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2560
[INFO] 2021-07-12 19:23:56,441 [run_pretraining.py:  558]:	worker_index: 3, step: 2560, cost: 7.436689, mlm loss: 7.436689, speed: 1.030013 steps/s, speed: 8.240103 samples/s, speed: 4218.932637 tokens/s, learning rate: 2.559e-05, loss_scalings: 2814.750488, pp_loss: 7.706356
[INFO] 2021-07-12 19:23:56,441 [run_pretraining.py:  512]:	********exe.run_2560******* 
[INFO] 2021-07-12 19:23:57,413 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:57,413 [run_pretraining.py:  534]:	loss/total_loss, 7.301161766052246, 2561
[INFO] 2021-07-12 19:23:57,413 [run_pretraining.py:  535]:	loss/mlm_loss, 7.301161766052246, 2561
[INFO] 2021-07-12 19:23:57,414 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5600000299164094e-05, 2561
[INFO] 2021-07-12 19:23:57,414 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2561
[INFO] 2021-07-12 19:23:57,414 [run_pretraining.py:  558]:	worker_index: 3, step: 2561, cost: 7.301162, mlm loss: 7.301162, speed: 1.028328 steps/s, speed: 8.226622 samples/s, speed: 4212.030313 tokens/s, learning rate: 2.560e-05, loss_scalings: 2814.750488, pp_loss: 6.408467
[INFO] 2021-07-12 19:23:57,414 [run_pretraining.py:  512]:	********exe.run_2561******* 
[INFO] 2021-07-12 19:23:58,401 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:58,402 [run_pretraining.py:  534]:	loss/total_loss, 7.9736328125, 2562
[INFO] 2021-07-12 19:23:58,402 [run_pretraining.py:  535]:	loss/mlm_loss, 7.9736328125, 2562
[INFO] 2021-07-12 19:23:58,402 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5609999283915386e-05, 2562
[INFO] 2021-07-12 19:23:58,402 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2562
[INFO] 2021-07-12 19:23:58,402 [run_pretraining.py:  558]:	worker_index: 3, step: 2562, cost: 7.973633, mlm loss: 7.973633, speed: 1.012518 steps/s, speed: 8.100148 samples/s, speed: 4147.275556 tokens/s, learning rate: 2.561e-05, loss_scalings: 2814.750488, pp_loss: 6.883287
[INFO] 2021-07-12 19:23:58,402 [run_pretraining.py:  512]:	********exe.run_2562******* 
[INFO] 2021-07-12 19:23:59,387 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:59,387 [run_pretraining.py:  534]:	loss/total_loss, 6.379395008087158, 2563
[INFO] 2021-07-12 19:23:59,388 [run_pretraining.py:  535]:	loss/mlm_loss, 6.379395008087158, 2563
[INFO] 2021-07-12 19:23:59,388 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5619998268666677e-05, 2563
[INFO] 2021-07-12 19:23:59,388 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2563
[INFO] 2021-07-12 19:23:59,388 [run_pretraining.py:  558]:	worker_index: 3, step: 2563, cost: 6.379395, mlm loss: 6.379395, speed: 1.015093 steps/s, speed: 8.120741 samples/s, speed: 4157.819540 tokens/s, learning rate: 2.562e-05, loss_scalings: 2814.750488, pp_loss: 7.273318
[INFO] 2021-07-12 19:23:59,388 [run_pretraining.py:  512]:	********exe.run_2563******* 
[INFO] 2021-07-12 19:24:00,367 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:00,367 [run_pretraining.py:  534]:	loss/total_loss, 6.767611503601074, 2564
[INFO] 2021-07-12 19:24:00,367 [run_pretraining.py:  535]:	loss/mlm_loss, 6.767611503601074, 2564
[INFO] 2021-07-12 19:24:00,367 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5629999072407372e-05, 2564
[INFO] 2021-07-12 19:24:00,367 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2564
[INFO] 2021-07-12 19:24:00,368 [run_pretraining.py:  558]:	worker_index: 3, step: 2564, cost: 6.767612, mlm loss: 6.767612, speed: 1.021301 steps/s, speed: 8.170405 samples/s, speed: 4183.247399 tokens/s, learning rate: 2.563e-05, loss_scalings: 2814.750488, pp_loss: 6.994197
[INFO] 2021-07-12 19:24:00,368 [run_pretraining.py:  512]:	********exe.run_2564******* 
[INFO] 2021-07-12 19:24:01,354 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:01,354 [run_pretraining.py:  534]:	loss/total_loss, 7.121382713317871, 2565
[INFO] 2021-07-12 19:24:01,354 [run_pretraining.py:  535]:	loss/mlm_loss, 7.121382713317871, 2565
[INFO] 2021-07-12 19:24:01,354 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5639998057158664e-05, 2565
[INFO] 2021-07-12 19:24:01,355 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2565
[INFO] 2021-07-12 19:24:01,355 [run_pretraining.py:  558]:	worker_index: 3, step: 2565, cost: 7.121383, mlm loss: 7.121383, speed: 1.013773 steps/s, speed: 8.110187 samples/s, speed: 4152.415896 tokens/s, learning rate: 2.564e-05, loss_scalings: 2814.750488, pp_loss: 7.169333
[INFO] 2021-07-12 19:24:01,355 [run_pretraining.py:  512]:	********exe.run_2565******* 
[INFO] 2021-07-12 19:24:02,334 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:02,335 [run_pretraining.py:  534]:	loss/total_loss, 6.999493598937988, 2566
[INFO] 2021-07-12 19:24:02,335 [run_pretraining.py:  535]:	loss/mlm_loss, 6.999493598937988, 2566
[INFO] 2021-07-12 19:24:02,335 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5650000679888763e-05, 2566
[INFO] 2021-07-12 19:24:02,335 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2566
[INFO] 2021-07-12 19:24:02,335 [run_pretraining.py:  558]:	worker_index: 3, step: 2566, cost: 6.999494, mlm loss: 6.999494, speed: 1.020346 steps/s, speed: 8.162769 samples/s, speed: 4179.337564 tokens/s, learning rate: 2.565e-05, loss_scalings: 2814.750488, pp_loss: 7.426520
[INFO] 2021-07-12 19:24:02,335 [run_pretraining.py:  512]:	********exe.run_2566******* 
[INFO] 2021-07-12 19:24:03,306 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:03,307 [run_pretraining.py:  534]:	loss/total_loss, 8.090909004211426, 2567
[INFO] 2021-07-12 19:24:03,307 [run_pretraining.py:  535]:	loss/mlm_loss, 8.090909004211426, 2567
[INFO] 2021-07-12 19:24:03,307 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.565999784565065e-05, 2567
[INFO] 2021-07-12 19:24:03,307 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2567
[INFO] 2021-07-12 19:24:03,307 [run_pretraining.py:  558]:	worker_index: 3, step: 2567, cost: 8.090909, mlm loss: 8.090909, speed: 1.029730 steps/s, speed: 8.237843 samples/s, speed: 4217.775674 tokens/s, learning rate: 2.566e-05, loss_scalings: 2814.750488, pp_loss: 7.454389
[INFO] 2021-07-12 19:24:03,307 [run_pretraining.py:  512]:	********exe.run_2567******* 
[INFO] 2021-07-12 19:24:04,281 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:04,281 [run_pretraining.py:  534]:	loss/total_loss, 6.741249084472656, 2568
[INFO] 2021-07-12 19:24:04,281 [run_pretraining.py:  535]:	loss/mlm_loss, 6.741249084472656, 2568
[INFO] 2021-07-12 19:24:04,281 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.567000046838075e-05, 2568
[INFO] 2021-07-12 19:24:04,281 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2568
[INFO] 2021-07-12 19:24:04,281 [run_pretraining.py:  558]:	worker_index: 3, step: 2568, cost: 6.741249, mlm loss: 6.741249, speed: 1.027073 steps/s, speed: 8.216582 samples/s, speed: 4206.889749 tokens/s, learning rate: 2.567e-05, loss_scalings: 2814.750488, pp_loss: 7.301412
[INFO] 2021-07-12 19:24:04,281 [run_pretraining.py:  512]:	********exe.run_2568******* 
[INFO] 2021-07-12 19:24:05,253 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:05,253 [run_pretraining.py:  534]:	loss/total_loss, 7.122496604919434, 2569
[INFO] 2021-07-12 19:24:05,254 [run_pretraining.py:  535]:	loss/mlm_loss, 7.122496604919434, 2569
[INFO] 2021-07-12 19:24:05,254 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.567999945313204e-05, 2569
[INFO] 2021-07-12 19:24:05,254 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2569
[INFO] 2021-07-12 19:24:05,254 [run_pretraining.py:  558]:	worker_index: 3, step: 2569, cost: 7.122497, mlm loss: 7.122497, speed: 1.029129 steps/s, speed: 8.233033 samples/s, speed: 4215.312641 tokens/s, learning rate: 2.568e-05, loss_scalings: 2814.750488, pp_loss: 7.404642
[INFO] 2021-07-12 19:24:05,254 [run_pretraining.py:  512]:	********exe.run_2569******* 
[INFO] 2021-07-12 19:24:06,243 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:06,243 [run_pretraining.py:  534]:	loss/total_loss, 7.69356632232666, 2570
[INFO] 2021-07-12 19:24:06,244 [run_pretraining.py:  535]:	loss/mlm_loss, 7.69356632232666, 2570
[INFO] 2021-07-12 19:24:06,244 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5690000256872736e-05, 2570
[INFO] 2021-07-12 19:24:06,244 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2570
[INFO] 2021-07-12 19:24:06,244 [run_pretraining.py:  558]:	worker_index: 3, step: 2570, cost: 7.693566, mlm loss: 7.693566, speed: 1.010774 steps/s, speed: 8.086191 samples/s, speed: 4140.129556 tokens/s, learning rate: 2.569e-05, loss_scalings: 2814.750488, pp_loss: 7.402144
[INFO] 2021-07-12 19:24:06,244 [run_pretraining.py:  512]:	********exe.run_2570******* 
[INFO] 2021-07-12 19:24:07,232 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:07,232 [run_pretraining.py:  534]:	loss/total_loss, 7.139096736907959, 2571
[INFO] 2021-07-12 19:24:07,232 [run_pretraining.py:  535]:	loss/mlm_loss, 7.139096736907959, 2571
[INFO] 2021-07-12 19:24:07,232 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5699999241624027e-05, 2571
[INFO] 2021-07-12 19:24:07,232 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2571
[INFO] 2021-07-12 19:24:07,232 [run_pretraining.py:  558]:	worker_index: 3, step: 2571, cost: 7.139097, mlm loss: 7.139097, speed: 1.012074 steps/s, speed: 8.096594 samples/s, speed: 4145.456235 tokens/s, learning rate: 2.570e-05, loss_scalings: 2814.750488, pp_loss: 7.422104
[INFO] 2021-07-12 19:24:07,233 [run_pretraining.py:  512]:	********exe.run_2571******* 
[INFO] 2021-07-12 19:24:08,215 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:08,216 [run_pretraining.py:  534]:	loss/total_loss, 7.957052230834961, 2572
[INFO] 2021-07-12 19:24:08,216 [run_pretraining.py:  535]:	loss/mlm_loss, 7.957052230834961, 2572
[INFO] 2021-07-12 19:24:08,216 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.570999822637532e-05, 2572
[INFO] 2021-07-12 19:24:08,216 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2572
[INFO] 2021-07-12 19:24:08,216 [run_pretraining.py:  558]:	worker_index: 3, step: 2572, cost: 7.957052, mlm loss: 7.957052, speed: 1.017386 steps/s, speed: 8.139088 samples/s, speed: 4167.213046 tokens/s, learning rate: 2.571e-05, loss_scalings: 2814.750488, pp_loss: 7.747475
[INFO] 2021-07-12 19:24:08,216 [run_pretraining.py:  512]:	********exe.run_2572******* 
[INFO] 2021-07-12 19:24:09,197 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:09,198 [run_pretraining.py:  534]:	loss/total_loss, 7.311169624328613, 2573
[INFO] 2021-07-12 19:24:09,198 [run_pretraining.py:  535]:	loss/mlm_loss, 7.311169624328613, 2573
[INFO] 2021-07-12 19:24:09,198 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5719999030116014e-05, 2573
[INFO] 2021-07-12 19:24:09,198 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2573
[INFO] 2021-07-12 19:24:09,198 [run_pretraining.py:  558]:	worker_index: 3, step: 2573, cost: 7.311170, mlm loss: 7.311170, speed: 1.019055 steps/s, speed: 8.152438 samples/s, speed: 4174.048249 tokens/s, learning rate: 2.572e-05, loss_scalings: 2814.750488, pp_loss: 7.166728
[INFO] 2021-07-12 19:24:09,198 [run_pretraining.py:  512]:	********exe.run_2573******* 
[INFO] 2021-07-12 19:24:10,166 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:10,167 [run_pretraining.py:  534]:	loss/total_loss, 7.442131519317627, 2574
[INFO] 2021-07-12 19:24:10,167 [run_pretraining.py:  535]:	loss/mlm_loss, 7.442131519317627, 2574
[INFO] 2021-07-12 19:24:10,167 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5729998014867306e-05, 2574
[INFO] 2021-07-12 19:24:10,167 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2574
[INFO] 2021-07-12 19:24:10,167 [run_pretraining.py:  558]:	worker_index: 3, step: 2574, cost: 7.442132, mlm loss: 7.442132, speed: 1.032543 steps/s, speed: 8.260341 samples/s, speed: 4229.294806 tokens/s, learning rate: 2.573e-05, loss_scalings: 2814.750488, pp_loss: 7.546531
[INFO] 2021-07-12 19:24:10,167 [run_pretraining.py:  512]:	********exe.run_2574******* 
[INFO] 2021-07-12 19:24:11,125 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:11,125 [run_pretraining.py:  534]:	loss/total_loss, 7.120685577392578, 2575
[INFO] 2021-07-12 19:24:11,126 [run_pretraining.py:  535]:	loss/mlm_loss, 7.120685577392578, 2575
[INFO] 2021-07-12 19:24:11,126 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5740000637597404e-05, 2575
[INFO] 2021-07-12 19:24:11,126 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2575
[INFO] 2021-07-12 19:24:11,126 [run_pretraining.py:  558]:	worker_index: 3, step: 2575, cost: 7.120686, mlm loss: 7.120686, speed: 1.043770 steps/s, speed: 8.350160 samples/s, speed: 4275.281761 tokens/s, learning rate: 2.574e-05, loss_scalings: 2814.750488, pp_loss: 7.178452
[INFO] 2021-07-12 19:24:11,126 [run_pretraining.py:  512]:	********exe.run_2575******* 
[INFO] 2021-07-12 19:24:12,034 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:12,034 [run_pretraining.py:  534]:	loss/total_loss, 7.832725524902344, 2576
[INFO] 2021-07-12 19:24:12,034 [run_pretraining.py:  535]:	loss/mlm_loss, 7.832725524902344, 2576
[INFO] 2021-07-12 19:24:12,035 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5749997803359292e-05, 2576
[INFO] 2021-07-12 19:24:12,035 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2576
[INFO] 2021-07-12 19:24:12,035 [run_pretraining.py:  558]:	worker_index: 3, step: 2576, cost: 7.832726, mlm loss: 7.832726, speed: 1.100992 steps/s, speed: 8.807936 samples/s, speed: 4509.663349 tokens/s, learning rate: 2.575e-05, loss_scalings: 2814.750488, pp_loss: 7.292033
[INFO] 2021-07-12 19:24:12,035 [run_pretraining.py:  512]:	********exe.run_2576******* 
[INFO] 2021-07-12 19:24:12,943 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:12,943 [run_pretraining.py:  534]:	loss/total_loss, 6.93696403503418, 2577
[INFO] 2021-07-12 19:24:12,943 [run_pretraining.py:  535]:	loss/mlm_loss, 6.93696403503418, 2577
[INFO] 2021-07-12 19:24:12,943 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.576000042608939e-05, 2577
[INFO] 2021-07-12 19:24:12,943 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2577
[INFO] 2021-07-12 19:24:12,943 [run_pretraining.py:  558]:	worker_index: 3, step: 2577, cost: 6.936964, mlm loss: 6.936964, speed: 1.101233 steps/s, speed: 8.809863 samples/s, speed: 4510.649647 tokens/s, learning rate: 2.576e-05, loss_scalings: 2814.750488, pp_loss: 6.403628
[INFO] 2021-07-12 19:24:12,943 [run_pretraining.py:  512]:	********exe.run_2577******* 
[INFO] 2021-07-12 19:24:13,857 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:13,857 [run_pretraining.py:  534]:	loss/total_loss, 7.240026473999023, 2578
[INFO] 2021-07-12 19:24:13,857 [run_pretraining.py:  535]:	loss/mlm_loss, 7.240026473999023, 2578
[INFO] 2021-07-12 19:24:13,857 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5769999410840683e-05, 2578
[INFO] 2021-07-12 19:24:13,857 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2578
[INFO] 2021-07-12 19:24:13,857 [run_pretraining.py:  558]:	worker_index: 3, step: 2578, cost: 7.240026, mlm loss: 7.240026, speed: 1.094802 steps/s, speed: 8.758419 samples/s, speed: 4484.310584 tokens/s, learning rate: 2.577e-05, loss_scalings: 2814.750488, pp_loss: 7.171892
[INFO] 2021-07-12 19:24:13,858 [run_pretraining.py:  512]:	********exe.run_2578******* 
[INFO] 2021-07-12 19:24:14,768 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:14,769 [run_pretraining.py:  534]:	loss/total_loss, 6.242003440856934, 2579
[INFO] 2021-07-12 19:24:14,769 [run_pretraining.py:  535]:	loss/mlm_loss, 6.242003440856934, 2579
[INFO] 2021-07-12 19:24:14,769 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5780000214581378e-05, 2579
[INFO] 2021-07-12 19:24:14,769 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2579
[INFO] 2021-07-12 19:24:14,769 [run_pretraining.py:  558]:	worker_index: 3, step: 2579, cost: 6.242003, mlm loss: 6.242003, speed: 1.097341 steps/s, speed: 8.778728 samples/s, speed: 4494.708783 tokens/s, learning rate: 2.578e-05, loss_scalings: 2814.750488, pp_loss: 7.092299
[INFO] 2021-07-12 19:24:14,770 [run_pretraining.py:  512]:	********exe.run_2579******* 
[INFO] 2021-07-12 19:24:15,676 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:15,676 [run_pretraining.py:  534]:	loss/total_loss, 7.605429649353027, 2580
[INFO] 2021-07-12 19:24:15,676 [run_pretraining.py:  535]:	loss/mlm_loss, 7.605429649353027, 2580
[INFO] 2021-07-12 19:24:15,676 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.578999919933267e-05, 2580
[INFO] 2021-07-12 19:24:15,677 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2580
[INFO] 2021-07-12 19:24:15,677 [run_pretraining.py:  558]:	worker_index: 3, step: 2580, cost: 7.605430, mlm loss: 7.605430, speed: 1.103129 steps/s, speed: 8.825032 samples/s, speed: 4518.416550 tokens/s, learning rate: 2.579e-05, loss_scalings: 2814.750488, pp_loss: 7.326444
[INFO] 2021-07-12 19:24:15,677 [run_pretraining.py:  512]:	********exe.run_2580******* 
[INFO] 2021-07-12 19:24:16,588 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:16,589 [run_pretraining.py:  534]:	loss/total_loss, 7.288267135620117, 2581
[INFO] 2021-07-12 19:24:16,589 [run_pretraining.py:  535]:	loss/mlm_loss, 7.288267135620117, 2581
[INFO] 2021-07-12 19:24:16,589 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.579999818408396e-05, 2581
[INFO] 2021-07-12 19:24:16,589 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2581
[INFO] 2021-07-12 19:24:16,589 [run_pretraining.py:  558]:	worker_index: 3, step: 2581, cost: 7.288267, mlm loss: 7.288267, speed: 1.096460 steps/s, speed: 8.771680 samples/s, speed: 4491.100387 tokens/s, learning rate: 2.580e-05, loss_scalings: 2814.750488, pp_loss: 6.402212
[INFO] 2021-07-12 19:24:16,589 [run_pretraining.py:  512]:	********exe.run_2581******* 
[INFO] 2021-07-12 19:24:17,503 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:17,503 [run_pretraining.py:  534]:	loss/total_loss, 7.43081521987915, 2582
[INFO] 2021-07-12 19:24:17,503 [run_pretraining.py:  535]:	loss/mlm_loss, 7.43081521987915, 2582
[INFO] 2021-07-12 19:24:17,503 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5809998987824656e-05, 2582
[INFO] 2021-07-12 19:24:17,503 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2582
[INFO] 2021-07-12 19:24:17,503 [run_pretraining.py:  558]:	worker_index: 3, step: 2582, cost: 7.430815, mlm loss: 7.430815, speed: 1.094688 steps/s, speed: 8.757502 samples/s, speed: 4483.841262 tokens/s, learning rate: 2.581e-05, loss_scalings: 2814.750488, pp_loss: 7.148879
[INFO] 2021-07-12 19:24:17,503 [run_pretraining.py:  512]:	********exe.run_2582******* 
[INFO] 2021-07-12 19:24:18,416 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:18,416 [run_pretraining.py:  534]:	loss/total_loss, 7.406080722808838, 2583
[INFO] 2021-07-12 19:24:18,416 [run_pretraining.py:  535]:	loss/mlm_loss, 7.406080722808838, 2583
[INFO] 2021-07-12 19:24:18,416 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5819997972575948e-05, 2583
[INFO] 2021-07-12 19:24:18,416 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2583
[INFO] 2021-07-12 19:24:18,416 [run_pretraining.py:  558]:	worker_index: 3, step: 2583, cost: 7.406081, mlm loss: 7.406081, speed: 1.095974 steps/s, speed: 8.767795 samples/s, speed: 4489.111257 tokens/s, learning rate: 2.582e-05, loss_scalings: 2814.750488, pp_loss: 7.018710
[INFO] 2021-07-12 19:24:18,417 [run_pretraining.py:  512]:	********exe.run_2583******* 
[INFO] 2021-07-12 19:24:19,340 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:19,341 [run_pretraining.py:  534]:	loss/total_loss, 7.411397457122803, 2584
[INFO] 2021-07-12 19:24:19,341 [run_pretraining.py:  535]:	loss/mlm_loss, 7.411397457122803, 2584
[INFO] 2021-07-12 19:24:19,341 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5830000595306046e-05, 2584
[INFO] 2021-07-12 19:24:19,341 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2584
[INFO] 2021-07-12 19:24:19,341 [run_pretraining.py:  558]:	worker_index: 3, step: 2584, cost: 7.411397, mlm loss: 7.411397, speed: 1.082218 steps/s, speed: 8.657745 samples/s, speed: 4432.765348 tokens/s, learning rate: 2.583e-05, loss_scalings: 2814.750488, pp_loss: 7.129637
[INFO] 2021-07-12 19:24:19,341 [run_pretraining.py:  512]:	********exe.run_2584******* 
[INFO] 2021-07-12 19:24:20,249 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:20,249 [run_pretraining.py:  534]:	loss/total_loss, 7.363780498504639, 2585
[INFO] 2021-07-12 19:24:20,249 [run_pretraining.py:  535]:	loss/mlm_loss, 7.363780498504639, 2585
[INFO] 2021-07-12 19:24:20,249 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5839997761067934e-05, 2585
[INFO] 2021-07-12 19:24:20,249 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2585
[INFO] 2021-07-12 19:24:20,249 [run_pretraining.py:  558]:	worker_index: 3, step: 2585, cost: 7.363780, mlm loss: 7.363780, speed: 1.101729 steps/s, speed: 8.813834 samples/s, speed: 4512.682806 tokens/s, learning rate: 2.584e-05, loss_scalings: 2814.750488, pp_loss: 7.405803
[INFO] 2021-07-12 19:24:20,250 [run_pretraining.py:  512]:	********exe.run_2585******* 
[INFO] 2021-07-12 19:24:21,160 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:21,160 [run_pretraining.py:  534]:	loss/total_loss, 8.037864685058594, 2586
[INFO] 2021-07-12 19:24:21,161 [run_pretraining.py:  535]:	loss/mlm_loss, 8.037864685058594, 2586
[INFO] 2021-07-12 19:24:21,161 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5850000383798033e-05, 2586
[INFO] 2021-07-12 19:24:21,161 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2586
[INFO] 2021-07-12 19:24:21,161 [run_pretraining.py:  558]:	worker_index: 3, step: 2586, cost: 8.037865, mlm loss: 8.037865, speed: 1.098085 steps/s, speed: 8.784683 samples/s, speed: 4497.757697 tokens/s, learning rate: 2.585e-05, loss_scalings: 2814.750488, pp_loss: 7.654556
[INFO] 2021-07-12 19:24:21,161 [run_pretraining.py:  512]:	********exe.run_2586******* 
[INFO] 2021-07-12 19:24:22,075 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:22,075 [run_pretraining.py:  534]:	loss/total_loss, 7.072756767272949, 2587
[INFO] 2021-07-12 19:24:22,075 [run_pretraining.py:  535]:	loss/mlm_loss, 7.072756767272949, 2587
[INFO] 2021-07-12 19:24:22,075 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5859999368549325e-05, 2587
[INFO] 2021-07-12 19:24:22,075 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2587
[INFO] 2021-07-12 19:24:22,076 [run_pretraining.py:  558]:	worker_index: 3, step: 2587, cost: 7.072757, mlm loss: 7.072757, speed: 1.093975 steps/s, speed: 8.751797 samples/s, speed: 4480.919869 tokens/s, learning rate: 2.586e-05, loss_scalings: 2814.750488, pp_loss: 7.717910
[INFO] 2021-07-12 19:24:22,076 [run_pretraining.py:  512]:	********exe.run_2587******* 
[INFO] 2021-07-12 19:24:22,980 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:22,980 [run_pretraining.py:  534]:	loss/total_loss, 7.151627540588379, 2588
[INFO] 2021-07-12 19:24:22,980 [run_pretraining.py:  535]:	loss/mlm_loss, 7.151627540588379, 2588
[INFO] 2021-07-12 19:24:22,980 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.587000017229002e-05, 2588
[INFO] 2021-07-12 19:24:22,980 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2588
[INFO] 2021-07-12 19:24:22,980 [run_pretraining.py:  558]:	worker_index: 3, step: 2588, cost: 7.151628, mlm loss: 7.151628, speed: 1.105807 steps/s, speed: 8.846454 samples/s, speed: 4529.384456 tokens/s, learning rate: 2.587e-05, loss_scalings: 2814.750488, pp_loss: 7.383501
[INFO] 2021-07-12 19:24:22,981 [run_pretraining.py:  512]:	********exe.run_2588******* 
[INFO] 2021-07-12 19:24:23,888 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:23,888 [run_pretraining.py:  534]:	loss/total_loss, 7.161489486694336, 2589
[INFO] 2021-07-12 19:24:23,889 [run_pretraining.py:  535]:	loss/mlm_loss, 7.161489486694336, 2589
[INFO] 2021-07-12 19:24:23,889 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.587999915704131e-05, 2589
[INFO] 2021-07-12 19:24:23,889 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2589
[INFO] 2021-07-12 19:24:23,889 [run_pretraining.py:  558]:	worker_index: 3, step: 2589, cost: 7.161489, mlm loss: 7.161489, speed: 1.101682 steps/s, speed: 8.813454 samples/s, speed: 4512.488416 tokens/s, learning rate: 2.588e-05, loss_scalings: 2814.750488, pp_loss: 7.178663
[INFO] 2021-07-12 19:24:23,889 [run_pretraining.py:  512]:	********exe.run_2589******* 
[INFO] 2021-07-12 19:24:24,882 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:24,882 [run_pretraining.py:  534]:	loss/total_loss, 5.100480556488037, 2590
[INFO] 2021-07-12 19:24:24,883 [run_pretraining.py:  535]:	loss/mlm_loss, 5.100480556488037, 2590
[INFO] 2021-07-12 19:24:24,883 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5889998141792603e-05, 2590
[INFO] 2021-07-12 19:24:24,883 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2590
[INFO] 2021-07-12 19:24:24,883 [run_pretraining.py:  558]:	worker_index: 3, step: 2590, cost: 5.100481, mlm loss: 5.100481, speed: 1.006667 steps/s, speed: 8.053337 samples/s, speed: 4123.308797 tokens/s, learning rate: 2.589e-05, loss_scalings: 2814.750488, pp_loss: 6.844536
[INFO] 2021-07-12 19:24:24,883 [run_pretraining.py:  512]:	********exe.run_2590******* 
[INFO] 2021-07-12 19:24:25,942 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:25,943 [run_pretraining.py:  534]:	loss/total_loss, 7.120645999908447, 2591
[INFO] 2021-07-12 19:24:25,943 [run_pretraining.py:  535]:	loss/mlm_loss, 7.120645999908447, 2591
[INFO] 2021-07-12 19:24:25,943 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5899998945533298e-05, 2591
[INFO] 2021-07-12 19:24:25,943 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2591
[INFO] 2021-07-12 19:24:25,943 [run_pretraining.py:  558]:	worker_index: 3, step: 2591, cost: 7.120646, mlm loss: 7.120646, speed: 0.943901 steps/s, speed: 7.551207 samples/s, speed: 3866.218196 tokens/s, learning rate: 2.590e-05, loss_scalings: 2814.750488, pp_loss: 7.354122
[INFO] 2021-07-12 19:24:25,943 [run_pretraining.py:  512]:	********exe.run_2591******* 
[INFO] 2021-07-12 19:24:27,002 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:27,002 [run_pretraining.py:  534]:	loss/total_loss, 7.278243541717529, 2592
[INFO] 2021-07-12 19:24:27,002 [run_pretraining.py:  535]:	loss/mlm_loss, 7.278243541717529, 2592
[INFO] 2021-07-12 19:24:27,002 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.590999793028459e-05, 2592
[INFO] 2021-07-12 19:24:27,003 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2592
[INFO] 2021-07-12 19:24:27,003 [run_pretraining.py:  558]:	worker_index: 3, step: 2592, cost: 7.278244, mlm loss: 7.278244, speed: 0.944191 steps/s, speed: 7.553529 samples/s, speed: 3867.407074 tokens/s, learning rate: 2.591e-05, loss_scalings: 2814.750488, pp_loss: 7.151267
[INFO] 2021-07-12 19:24:27,003 [run_pretraining.py:  512]:	********exe.run_2592******* 
[INFO] 2021-07-12 19:24:28,045 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:28,046 [run_pretraining.py:  534]:	loss/total_loss, 7.308862686157227, 2593
[INFO] 2021-07-12 19:24:28,046 [run_pretraining.py:  535]:	loss/mlm_loss, 7.308862686157227, 2593
[INFO] 2021-07-12 19:24:28,046 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5920000553014688e-05, 2593
[INFO] 2021-07-12 19:24:28,046 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2593
[INFO] 2021-07-12 19:24:28,046 [run_pretraining.py:  558]:	worker_index: 3, step: 2593, cost: 7.308863, mlm loss: 7.308863, speed: 0.958989 steps/s, speed: 7.671913 samples/s, speed: 3928.019564 tokens/s, learning rate: 2.592e-05, loss_scalings: 2814.750488, pp_loss: 7.056799
[INFO] 2021-07-12 19:24:28,046 [run_pretraining.py:  512]:	********exe.run_2593******* 
[INFO] 2021-07-12 19:24:29,117 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:29,118 [run_pretraining.py:  534]:	loss/total_loss, 7.447566032409668, 2594
[INFO] 2021-07-12 19:24:29,118 [run_pretraining.py:  535]:	loss/mlm_loss, 7.447566032409668, 2594
[INFO] 2021-07-12 19:24:29,118 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.592999953776598e-05, 2594
[INFO] 2021-07-12 19:24:29,118 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2594
[INFO] 2021-07-12 19:24:29,118 [run_pretraining.py:  558]:	worker_index: 3, step: 2594, cost: 7.447566, mlm loss: 7.447566, speed: 0.933415 steps/s, speed: 7.467323 samples/s, speed: 3823.269509 tokens/s, learning rate: 2.593e-05, loss_scalings: 2814.750488, pp_loss: 7.299936
[INFO] 2021-07-12 19:24:29,118 [run_pretraining.py:  512]:	********exe.run_2594******* 
[INFO] 2021-07-12 19:24:30,172 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:30,173 [run_pretraining.py:  534]:	loss/total_loss, 4.674338340759277, 2595
[INFO] 2021-07-12 19:24:30,173 [run_pretraining.py:  535]:	loss/mlm_loss, 4.674338340759277, 2595
[INFO] 2021-07-12 19:24:30,173 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5940000341506675e-05, 2595
[INFO] 2021-07-12 19:24:30,173 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2595
[INFO] 2021-07-12 19:24:30,173 [run_pretraining.py:  558]:	worker_index: 3, step: 2595, cost: 4.674338, mlm loss: 4.674338, speed: 0.948515 steps/s, speed: 7.588118 samples/s, speed: 3885.116630 tokens/s, learning rate: 2.594e-05, loss_scalings: 2814.750488, pp_loss: 6.760691
[INFO] 2021-07-12 19:24:30,173 [run_pretraining.py:  512]:	********exe.run_2595******* 
[INFO] 2021-07-12 19:24:31,224 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:31,224 [run_pretraining.py:  534]:	loss/total_loss, 7.44234561920166, 2596
[INFO] 2021-07-12 19:24:31,224 [run_pretraining.py:  535]:	loss/mlm_loss, 7.44234561920166, 2596
[INFO] 2021-07-12 19:24:31,225 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5949999326257966e-05, 2596
[INFO] 2021-07-12 19:24:31,225 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2596
[INFO] 2021-07-12 19:24:31,225 [run_pretraining.py:  558]:	worker_index: 3, step: 2596, cost: 7.442346, mlm loss: 7.442346, speed: 0.951358 steps/s, speed: 7.610863 samples/s, speed: 3896.762053 tokens/s, learning rate: 2.595e-05, loss_scalings: 2814.750488, pp_loss: 7.287054
[INFO] 2021-07-12 19:24:31,225 [run_pretraining.py:  512]:	********exe.run_2596******* 
[INFO] 2021-07-12 19:24:32,286 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:32,287 [run_pretraining.py:  534]:	loss/total_loss, 6.896871089935303, 2597
[INFO] 2021-07-12 19:24:32,287 [run_pretraining.py:  535]:	loss/mlm_loss, 6.896871089935303, 2597
[INFO] 2021-07-12 19:24:32,287 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.596000012999866e-05, 2597
[INFO] 2021-07-12 19:24:32,287 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2597
[INFO] 2021-07-12 19:24:32,287 [run_pretraining.py:  558]:	worker_index: 3, step: 2597, cost: 6.896871, mlm loss: 6.896871, speed: 0.941872 steps/s, speed: 7.534980 samples/s, speed: 3857.909546 tokens/s, learning rate: 2.596e-05, loss_scalings: 2814.750488, pp_loss: 6.806679
[INFO] 2021-07-12 19:24:32,287 [run_pretraining.py:  512]:	********exe.run_2597******* 
[INFO] 2021-07-12 19:24:33,348 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:33,348 [run_pretraining.py:  534]:	loss/total_loss, 7.590951919555664, 2598
[INFO] 2021-07-12 19:24:33,349 [run_pretraining.py:  535]:	loss/mlm_loss, 7.590951919555664, 2598
[INFO] 2021-07-12 19:24:33,349 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5969999114749953e-05, 2598
[INFO] 2021-07-12 19:24:33,349 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2598
[INFO] 2021-07-12 19:24:33,349 [run_pretraining.py:  558]:	worker_index: 3, step: 2598, cost: 7.590952, mlm loss: 7.590952, speed: 0.942395 steps/s, speed: 7.539161 samples/s, speed: 3860.050573 tokens/s, learning rate: 2.597e-05, loss_scalings: 2814.750488, pp_loss: 7.173805
[INFO] 2021-07-12 19:24:33,349 [run_pretraining.py:  512]:	********exe.run_2598******* 
[INFO] 2021-07-12 19:24:34,413 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:34,414 [run_pretraining.py:  534]:	loss/total_loss, 7.777449131011963, 2599
[INFO] 2021-07-12 19:24:34,414 [run_pretraining.py:  535]:	loss/mlm_loss, 7.777449131011963, 2599
[INFO] 2021-07-12 19:24:34,414 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5979998099501245e-05, 2599
[INFO] 2021-07-12 19:24:34,414 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2599
[INFO] 2021-07-12 19:24:34,414 [run_pretraining.py:  558]:	worker_index: 3, step: 2599, cost: 7.777449, mlm loss: 7.777449, speed: 0.939476 steps/s, speed: 7.515812 samples/s, speed: 3848.095645 tokens/s, learning rate: 2.598e-05, loss_scalings: 2814.750488, pp_loss: 7.318425
[INFO] 2021-07-12 19:24:34,414 [run_pretraining.py:  512]:	********exe.run_2599******* 
[INFO] 2021-07-12 19:24:59,803 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:59,803 [run_pretraining.py:  534]:	loss/total_loss, 7.464670181274414, 2600
[INFO] 2021-07-12 19:24:59,804 [run_pretraining.py:  535]:	loss/mlm_loss, 7.464670181274414, 2600
[INFO] 2021-07-12 19:24:59,804 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.598999890324194e-05, 2600
[INFO] 2021-07-12 19:24:59,804 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2600
[INFO] 2021-07-12 19:24:59,804 [run_pretraining.py:  558]:	worker_index: 3, step: 2600, cost: 7.464670, mlm loss: 7.464670, speed: 0.039387 steps/s, speed: 0.315093 samples/s, speed: 161.327838 tokens/s, learning rate: 2.599e-05, loss_scalings: 2814.750488, pp_loss: 7.263998
[INFO] 2021-07-12 19:24:59,804 [run_pretraining.py:  512]:	********exe.run_2600******* 
[INFO] 2021-07-12 19:25:00,862 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:00,862 [run_pretraining.py:  534]:	loss/total_loss, 6.706048965454102, 2601
[INFO] 2021-07-12 19:25:00,863 [run_pretraining.py:  535]:	loss/mlm_loss, 6.706048965454102, 2601
[INFO] 2021-07-12 19:25:00,863 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.599999788799323e-05, 2601
[INFO] 2021-07-12 19:25:00,863 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2601
[INFO] 2021-07-12 19:25:00,863 [run_pretraining.py:  558]:	worker_index: 3, step: 2601, cost: 6.706049, mlm loss: 6.706049, speed: 0.944937 steps/s, speed: 7.559494 samples/s, speed: 3870.460945 tokens/s, learning rate: 2.600e-05, loss_scalings: 2814.750488, pp_loss: 7.291300
[INFO] 2021-07-12 19:25:00,863 [run_pretraining.py:  512]:	********exe.run_2601******* 
[INFO] 2021-07-12 19:25:01,925 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:01,926 [run_pretraining.py:  534]:	loss/total_loss, 6.872710227966309, 2602
[INFO] 2021-07-12 19:25:01,926 [run_pretraining.py:  535]:	loss/mlm_loss, 6.872710227966309, 2602
[INFO] 2021-07-12 19:25:01,926 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.601000051072333e-05, 2602
[INFO] 2021-07-12 19:25:01,926 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2602
[INFO] 2021-07-12 19:25:01,926 [run_pretraining.py:  558]:	worker_index: 3, step: 2602, cost: 6.872710, mlm loss: 6.872710, speed: 0.940801 steps/s, speed: 7.526407 samples/s, speed: 3853.520510 tokens/s, learning rate: 2.601e-05, loss_scalings: 2814.750488, pp_loss: 6.810283
[INFO] 2021-07-12 19:25:01,926 [run_pretraining.py:  512]:	********exe.run_2602******* 
[INFO] 2021-07-12 19:25:02,985 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:02,986 [run_pretraining.py:  534]:	loss/total_loss, 6.834334850311279, 2603
[INFO] 2021-07-12 19:25:02,986 [run_pretraining.py:  535]:	loss/mlm_loss, 6.834334850311279, 2603
[INFO] 2021-07-12 19:25:02,986 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.601999949547462e-05, 2603
[INFO] 2021-07-12 19:25:02,986 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2603
[INFO] 2021-07-12 19:25:02,986 [run_pretraining.py:  558]:	worker_index: 3, step: 2603, cost: 6.834335, mlm loss: 6.834335, speed: 0.944273 steps/s, speed: 7.554186 samples/s, speed: 3867.743156 tokens/s, learning rate: 2.602e-05, loss_scalings: 2814.750488, pp_loss: 7.156917
[INFO] 2021-07-12 19:25:02,986 [run_pretraining.py:  512]:	********exe.run_2603******* 
[INFO] 2021-07-12 19:25:04,043 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:04,044 [run_pretraining.py:  534]:	loss/total_loss, 6.8337931632995605, 2604
[INFO] 2021-07-12 19:25:04,044 [run_pretraining.py:  535]:	loss/mlm_loss, 6.8337931632995605, 2604
[INFO] 2021-07-12 19:25:04,044 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6030000299215317e-05, 2604
[INFO] 2021-07-12 19:25:04,044 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2604
[INFO] 2021-07-12 19:25:04,044 [run_pretraining.py:  558]:	worker_index: 3, step: 2604, cost: 6.833793, mlm loss: 6.833793, speed: 0.945644 steps/s, speed: 7.565154 samples/s, speed: 3873.358952 tokens/s, learning rate: 2.603e-05, loss_scalings: 2814.750488, pp_loss: 7.161708
[INFO] 2021-07-12 19:25:04,044 [run_pretraining.py:  512]:	********exe.run_2604******* 
[INFO] 2021-07-12 19:25:05,097 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:05,098 [run_pretraining.py:  534]:	loss/total_loss, 7.621432304382324, 2605
[INFO] 2021-07-12 19:25:05,098 [run_pretraining.py:  535]:	loss/mlm_loss, 7.621432304382324, 2605
[INFO] 2021-07-12 19:25:05,098 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.603999928396661e-05, 2605
[INFO] 2021-07-12 19:25:05,098 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2605
[INFO] 2021-07-12 19:25:05,098 [run_pretraining.py:  558]:	worker_index: 3, step: 2605, cost: 7.621432, mlm loss: 7.621432, speed: 0.949274 steps/s, speed: 7.594189 samples/s, speed: 3888.224945 tokens/s, learning rate: 2.604e-05, loss_scalings: 2814.750488, pp_loss: 7.372931
[INFO] 2021-07-12 19:25:05,098 [run_pretraining.py:  512]:	********exe.run_2605******* 
[INFO] 2021-07-12 19:25:06,162 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:06,163 [run_pretraining.py:  534]:	loss/total_loss, 7.01145601272583, 2606
[INFO] 2021-07-12 19:25:06,163 [run_pretraining.py:  535]:	loss/mlm_loss, 7.01145601272583, 2606
[INFO] 2021-07-12 19:25:06,163 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6050000087707303e-05, 2606
[INFO] 2021-07-12 19:25:06,163 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2606
[INFO] 2021-07-12 19:25:06,163 [run_pretraining.py:  558]:	worker_index: 3, step: 2606, cost: 7.011456, mlm loss: 7.011456, speed: 0.939343 steps/s, speed: 7.514741 samples/s, speed: 3847.547536 tokens/s, learning rate: 2.605e-05, loss_scalings: 2814.750488, pp_loss: 7.145979
[INFO] 2021-07-12 19:25:06,163 [run_pretraining.py:  512]:	********exe.run_2606******* 
[INFO] 2021-07-12 19:25:07,228 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:07,228 [run_pretraining.py:  534]:	loss/total_loss, 6.55728006362915, 2607
[INFO] 2021-07-12 19:25:07,228 [run_pretraining.py:  535]:	loss/mlm_loss, 6.55728006362915, 2607
[INFO] 2021-07-12 19:25:07,228 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6059999072458595e-05, 2607
[INFO] 2021-07-12 19:25:07,228 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2607
[INFO] 2021-07-12 19:25:07,229 [run_pretraining.py:  558]:	worker_index: 3, step: 2607, cost: 6.557280, mlm loss: 6.557280, speed: 0.939407 steps/s, speed: 7.515253 samples/s, speed: 3847.809506 tokens/s, learning rate: 2.606e-05, loss_scalings: 2814.750488, pp_loss: 7.599908
[INFO] 2021-07-12 19:25:07,229 [run_pretraining.py:  512]:	********exe.run_2607******* 
[INFO] 2021-07-12 19:25:08,277 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:08,278 [run_pretraining.py:  534]:	loss/total_loss, 7.390275001525879, 2608
[INFO] 2021-07-12 19:25:08,278 [run_pretraining.py:  535]:	loss/mlm_loss, 7.390275001525879, 2608
[INFO] 2021-07-12 19:25:08,278 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6069998057209887e-05, 2608
[INFO] 2021-07-12 19:25:08,278 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2608
[INFO] 2021-07-12 19:25:08,278 [run_pretraining.py:  558]:	worker_index: 3, step: 2608, cost: 7.390275, mlm loss: 7.390275, speed: 0.953160 steps/s, speed: 7.625279 samples/s, speed: 3904.143055 tokens/s, learning rate: 2.607e-05, loss_scalings: 2814.750488, pp_loss: 7.487066
[INFO] 2021-07-12 19:25:08,278 [run_pretraining.py:  512]:	********exe.run_2608******* 
[INFO] 2021-07-12 19:25:09,342 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:09,342 [run_pretraining.py:  534]:	loss/total_loss, 9.575428009033203, 2609
[INFO] 2021-07-12 19:25:09,343 [run_pretraining.py:  535]:	loss/mlm_loss, 9.575428009033203, 2609
[INFO] 2021-07-12 19:25:09,343 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6079998860950582e-05, 2609
[INFO] 2021-07-12 19:25:09,343 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2609
[INFO] 2021-07-12 19:25:09,343 [run_pretraining.py:  558]:	worker_index: 3, step: 2609, cost: 9.575428, mlm loss: 9.575428, speed: 0.940030 steps/s, speed: 7.520240 samples/s, speed: 3850.362993 tokens/s, learning rate: 2.608e-05, loss_scalings: 2814.750488, pp_loss: 7.837700
[INFO] 2021-07-12 19:25:09,343 [run_pretraining.py:  512]:	********exe.run_2609******* 
[INFO] 2021-07-12 19:25:10,282 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:10,282 [run_pretraining.py:  534]:	loss/total_loss, 6.96816349029541, 2610
[INFO] 2021-07-12 19:25:10,282 [run_pretraining.py:  535]:	loss/mlm_loss, 6.96816349029541, 2610
[INFO] 2021-07-12 19:25:10,282 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6089997845701873e-05, 2610
[INFO] 2021-07-12 19:25:10,282 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2610
[INFO] 2021-07-12 19:25:10,282 [run_pretraining.py:  558]:	worker_index: 3, step: 2610, cost: 6.968163, mlm loss: 6.968163, speed: 1.064974 steps/s, speed: 8.519789 samples/s, speed: 4362.132135 tokens/s, learning rate: 2.609e-05, loss_scalings: 2814.750488, pp_loss: 7.309700
[INFO] 2021-07-12 19:25:10,282 [run_pretraining.py:  512]:	********exe.run_2610******* 
[INFO] 2021-07-12 19:25:11,189 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:11,190 [run_pretraining.py:  534]:	loss/total_loss, 7.405586242675781, 2611
[INFO] 2021-07-12 19:25:11,190 [run_pretraining.py:  535]:	loss/mlm_loss, 7.405586242675781, 2611
[INFO] 2021-07-12 19:25:11,190 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6100000468431972e-05, 2611
[INFO] 2021-07-12 19:25:11,190 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2611
[INFO] 2021-07-12 19:25:11,190 [run_pretraining.py:  558]:	worker_index: 3, step: 2611, cost: 7.405586, mlm loss: 7.405586, speed: 1.102318 steps/s, speed: 8.818543 samples/s, speed: 4515.093928 tokens/s, learning rate: 2.610e-05, loss_scalings: 2814.750488, pp_loss: 7.385262
[INFO] 2021-07-12 19:25:11,190 [run_pretraining.py:  512]:	********exe.run_2611******* 
[INFO] 2021-07-12 19:25:12,100 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:12,101 [run_pretraining.py:  534]:	loss/total_loss, 7.780967712402344, 2612
[INFO] 2021-07-12 19:25:12,101 [run_pretraining.py:  535]:	loss/mlm_loss, 7.780967712402344, 2612
[INFO] 2021-07-12 19:25:12,101 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6109999453183264e-05, 2612
[INFO] 2021-07-12 19:25:12,101 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2612
[INFO] 2021-07-12 19:25:12,101 [run_pretraining.py:  558]:	worker_index: 3, step: 2612, cost: 7.780968, mlm loss: 7.780968, speed: 1.098386 steps/s, speed: 8.787085 samples/s, speed: 4498.987376 tokens/s, learning rate: 2.611e-05, loss_scalings: 2814.750488, pp_loss: 6.998743
[INFO] 2021-07-12 19:25:12,101 [run_pretraining.py:  512]:	********exe.run_2612******* 
[INFO] 2021-07-12 19:25:13,007 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:13,008 [run_pretraining.py:  534]:	loss/total_loss, 7.048891067504883, 2613
[INFO] 2021-07-12 19:25:13,008 [run_pretraining.py:  535]:	loss/mlm_loss, 7.048891067504883, 2613
[INFO] 2021-07-12 19:25:13,008 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.612000025692396e-05, 2613
[INFO] 2021-07-12 19:25:13,008 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2613
[INFO] 2021-07-12 19:25:13,008 [run_pretraining.py:  558]:	worker_index: 3, step: 2613, cost: 7.048891, mlm loss: 7.048891, speed: 1.103404 steps/s, speed: 8.827229 samples/s, speed: 4519.541030 tokens/s, learning rate: 2.612e-05, loss_scalings: 2814.750488, pp_loss: 6.420687
[INFO] 2021-07-12 19:25:13,008 [run_pretraining.py:  512]:	********exe.run_2613******* 
[INFO] 2021-07-12 19:25:13,924 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:13,925 [run_pretraining.py:  534]:	loss/total_loss, 7.248548984527588, 2614
[INFO] 2021-07-12 19:25:13,925 [run_pretraining.py:  535]:	loss/mlm_loss, 7.248548984527588, 2614
[INFO] 2021-07-12 19:25:13,925 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.612999924167525e-05, 2614
[INFO] 2021-07-12 19:25:13,925 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2614
[INFO] 2021-07-12 19:25:13,925 [run_pretraining.py:  558]:	worker_index: 3, step: 2614, cost: 7.248549, mlm loss: 7.248549, speed: 1.091586 steps/s, speed: 8.732687 samples/s, speed: 4471.135629 tokens/s, learning rate: 2.613e-05, loss_scalings: 2814.750488, pp_loss: 7.435475
[INFO] 2021-07-12 19:25:13,925 [run_pretraining.py:  512]:	********exe.run_2614******* 
[INFO] 2021-07-12 19:25:14,838 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:14,839 [run_pretraining.py:  534]:	loss/total_loss, 7.367793560028076, 2615
[INFO] 2021-07-12 19:25:14,839 [run_pretraining.py:  535]:	loss/mlm_loss, 7.367793560028076, 2615
[INFO] 2021-07-12 19:25:14,839 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6140000045415945e-05, 2615
[INFO] 2021-07-12 19:25:14,839 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2615
[INFO] 2021-07-12 19:25:14,839 [run_pretraining.py:  558]:	worker_index: 3, step: 2615, cost: 7.367794, mlm loss: 7.367794, speed: 1.094718 steps/s, speed: 8.757745 samples/s, speed: 4483.965313 tokens/s, learning rate: 2.614e-05, loss_scalings: 2814.750488, pp_loss: 7.108850
[INFO] 2021-07-12 19:25:14,839 [run_pretraining.py:  512]:	********exe.run_2615******* 
[INFO] 2021-07-12 19:25:15,745 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:15,746 [run_pretraining.py:  534]:	loss/total_loss, 7.293811321258545, 2616
[INFO] 2021-07-12 19:25:15,746 [run_pretraining.py:  535]:	loss/mlm_loss, 7.293811321258545, 2616
[INFO] 2021-07-12 19:25:15,746 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6149999030167237e-05, 2616
[INFO] 2021-07-12 19:25:15,746 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2616
[INFO] 2021-07-12 19:25:15,746 [run_pretraining.py:  558]:	worker_index: 3, step: 2616, cost: 7.293811, mlm loss: 7.293811, speed: 1.102884 steps/s, speed: 8.823074 samples/s, speed: 4517.413786 tokens/s, learning rate: 2.615e-05, loss_scalings: 2814.750488, pp_loss: 7.129974
[INFO] 2021-07-12 19:25:15,746 [run_pretraining.py:  512]:	********exe.run_2616******* 
[INFO] 2021-07-12 19:25:16,653 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:16,653 [run_pretraining.py:  534]:	loss/total_loss, 7.772755146026611, 2617
[INFO] 2021-07-12 19:25:16,653 [run_pretraining.py:  535]:	loss/mlm_loss, 7.772755146026611, 2617
[INFO] 2021-07-12 19:25:16,653 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.615999801491853e-05, 2617
[INFO] 2021-07-12 19:25:16,654 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2617
[INFO] 2021-07-12 19:25:16,654 [run_pretraining.py:  558]:	worker_index: 3, step: 2617, cost: 7.772755, mlm loss: 7.772755, speed: 1.102976 steps/s, speed: 8.823809 samples/s, speed: 4517.790364 tokens/s, learning rate: 2.616e-05, loss_scalings: 2814.750488, pp_loss: 7.670491
[INFO] 2021-07-12 19:25:16,654 [run_pretraining.py:  512]:	********exe.run_2617******* 
[INFO] 2021-07-12 19:25:17,562 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:17,562 [run_pretraining.py:  534]:	loss/total_loss, 7.001027584075928, 2618
[INFO] 2021-07-12 19:25:17,562 [run_pretraining.py:  535]:	loss/mlm_loss, 7.001027584075928, 2618
[INFO] 2021-07-12 19:25:17,563 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6170000637648627e-05, 2618
[INFO] 2021-07-12 19:25:17,563 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2618
[INFO] 2021-07-12 19:25:17,563 [run_pretraining.py:  558]:	worker_index: 3, step: 2618, cost: 7.001028, mlm loss: 7.001028, speed: 1.100830 steps/s, speed: 8.806644 samples/s, speed: 4509.001717 tokens/s, learning rate: 2.617e-05, loss_scalings: 2814.750488, pp_loss: 7.020911
[INFO] 2021-07-12 19:25:17,563 [run_pretraining.py:  512]:	********exe.run_2618******* 
[INFO] 2021-07-12 19:25:18,475 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:18,475 [run_pretraining.py:  534]:	loss/total_loss, 7.1438093185424805, 2619
[INFO] 2021-07-12 19:25:18,475 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1438093185424805, 2619
[INFO] 2021-07-12 19:25:18,475 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6179997803410515e-05, 2619
[INFO] 2021-07-12 19:25:18,475 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2619
[INFO] 2021-07-12 19:25:18,476 [run_pretraining.py:  558]:	worker_index: 3, step: 2619, cost: 7.143809, mlm loss: 7.143809, speed: 1.096311 steps/s, speed: 8.770486 samples/s, speed: 4490.488791 tokens/s, learning rate: 2.618e-05, loss_scalings: 2814.750488, pp_loss: 7.386685
[INFO] 2021-07-12 19:25:18,476 [run_pretraining.py:  512]:	********exe.run_2619******* 
[INFO] 2021-07-12 19:25:19,388 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:19,388 [run_pretraining.py:  534]:	loss/total_loss, 6.905218124389648, 2620
[INFO] 2021-07-12 19:25:19,388 [run_pretraining.py:  535]:	loss/mlm_loss, 6.905218124389648, 2620
[INFO] 2021-07-12 19:25:19,388 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6190000426140614e-05, 2620
[INFO] 2021-07-12 19:25:19,389 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2620
[INFO] 2021-07-12 19:25:19,389 [run_pretraining.py:  558]:	worker_index: 3, step: 2620, cost: 6.905218, mlm loss: 6.905218, speed: 1.095925 steps/s, speed: 8.767399 samples/s, speed: 4488.908336 tokens/s, learning rate: 2.619e-05, loss_scalings: 2814.750488, pp_loss: 7.176557
[INFO] 2021-07-12 19:25:19,389 [run_pretraining.py:  512]:	********exe.run_2620******* 
[INFO] 2021-07-12 19:25:20,314 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:20,315 [run_pretraining.py:  534]:	loss/total_loss, 6.9495744705200195, 2621
[INFO] 2021-07-12 19:25:20,315 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9495744705200195, 2621
[INFO] 2021-07-12 19:25:20,315 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6199999410891905e-05, 2621
[INFO] 2021-07-12 19:25:20,315 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2621
[INFO] 2021-07-12 19:25:20,315 [run_pretraining.py:  558]:	worker_index: 3, step: 2621, cost: 6.949574, mlm loss: 6.949574, speed: 1.080323 steps/s, speed: 8.642583 samples/s, speed: 4425.002636 tokens/s, learning rate: 2.620e-05, loss_scalings: 2814.750488, pp_loss: 6.042933
[INFO] 2021-07-12 19:25:20,315 [run_pretraining.py:  512]:	********exe.run_2621******* 
[INFO] 2021-07-12 19:25:21,231 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:21,231 [run_pretraining.py:  534]:	loss/total_loss, 8.247251510620117, 2622
[INFO] 2021-07-12 19:25:21,232 [run_pretraining.py:  535]:	loss/mlm_loss, 8.247251510620117, 2622
[INFO] 2021-07-12 19:25:21,232 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.62100002146326e-05, 2622
[INFO] 2021-07-12 19:25:21,232 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2622
[INFO] 2021-07-12 19:25:21,232 [run_pretraining.py:  558]:	worker_index: 3, step: 2622, cost: 8.247252, mlm loss: 8.247252, speed: 1.091437 steps/s, speed: 8.731494 samples/s, speed: 4470.524805 tokens/s, learning rate: 2.621e-05, loss_scalings: 2814.750488, pp_loss: 7.095459
[INFO] 2021-07-12 19:25:21,232 [run_pretraining.py:  512]:	********exe.run_2622******* 
[INFO] 2021-07-12 19:25:22,145 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:22,146 [run_pretraining.py:  534]:	loss/total_loss, 7.258022308349609, 2623
[INFO] 2021-07-12 19:25:22,146 [run_pretraining.py:  535]:	loss/mlm_loss, 7.258022308349609, 2623
[INFO] 2021-07-12 19:25:22,146 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6219999199383892e-05, 2623
[INFO] 2021-07-12 19:25:22,146 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2623
[INFO] 2021-07-12 19:25:22,146 [run_pretraining.py:  558]:	worker_index: 3, step: 2623, cost: 7.258022, mlm loss: 7.258022, speed: 1.094275 steps/s, speed: 8.754201 samples/s, speed: 4482.150881 tokens/s, learning rate: 2.622e-05, loss_scalings: 2814.750488, pp_loss: 7.452866
[INFO] 2021-07-12 19:25:22,146 [run_pretraining.py:  512]:	********exe.run_2623******* 
[INFO] 2021-07-12 19:25:23,062 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:23,063 [run_pretraining.py:  534]:	loss/total_loss, 6.9294586181640625, 2624
[INFO] 2021-07-12 19:25:23,063 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9294586181640625, 2624
[INFO] 2021-07-12 19:25:23,063 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6230000003124587e-05, 2624
[INFO] 2021-07-12 19:25:23,063 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2624
[INFO] 2021-07-12 19:25:23,063 [run_pretraining.py:  558]:	worker_index: 3, step: 2624, cost: 6.929459, mlm loss: 6.929459, speed: 1.091128 steps/s, speed: 8.729027 samples/s, speed: 4469.261802 tokens/s, learning rate: 2.623e-05, loss_scalings: 2814.750488, pp_loss: 7.198609
[INFO] 2021-07-12 19:25:23,063 [run_pretraining.py:  512]:	********exe.run_2624******* 
[INFO] 2021-07-12 19:25:23,996 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:23,997 [run_pretraining.py:  534]:	loss/total_loss, 7.258082389831543, 2625
[INFO] 2021-07-12 19:25:23,997 [run_pretraining.py:  535]:	loss/mlm_loss, 7.258082389831543, 2625
[INFO] 2021-07-12 19:25:23,997 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.623999898787588e-05, 2625
[INFO] 2021-07-12 19:25:23,997 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2625
[INFO] 2021-07-12 19:25:23,997 [run_pretraining.py:  558]:	worker_index: 3, step: 2625, cost: 7.258082, mlm loss: 7.258082, speed: 1.071791 steps/s, speed: 8.574326 samples/s, speed: 4390.054785 tokens/s, learning rate: 2.624e-05, loss_scalings: 2814.750488, pp_loss: 7.542318
[INFO] 2021-07-12 19:25:23,997 [run_pretraining.py:  512]:	********exe.run_2625******* 
[INFO] 2021-07-12 19:25:24,910 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:24,911 [run_pretraining.py:  534]:	loss/total_loss, 7.247654914855957, 2626
[INFO] 2021-07-12 19:25:24,911 [run_pretraining.py:  535]:	loss/mlm_loss, 7.247654914855957, 2626
[INFO] 2021-07-12 19:25:24,911 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.624999797262717e-05, 2626
[INFO] 2021-07-12 19:25:24,911 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2626
[INFO] 2021-07-12 19:25:24,911 [run_pretraining.py:  558]:	worker_index: 3, step: 2626, cost: 7.247655, mlm loss: 7.247655, speed: 1.094854 steps/s, speed: 8.758828 samples/s, speed: 4484.520113 tokens/s, learning rate: 2.625e-05, loss_scalings: 2814.750488, pp_loss: 6.710709
[INFO] 2021-07-12 19:25:24,911 [run_pretraining.py:  512]:	********exe.run_2626******* 
[INFO] 2021-07-12 19:25:25,825 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:25,825 [run_pretraining.py:  534]:	loss/total_loss, 7.446441173553467, 2627
[INFO] 2021-07-12 19:25:25,826 [run_pretraining.py:  535]:	loss/mlm_loss, 7.446441173553467, 2627
[INFO] 2021-07-12 19:25:25,826 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.626000059535727e-05, 2627
[INFO] 2021-07-12 19:25:25,826 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2627
[INFO] 2021-07-12 19:25:25,826 [run_pretraining.py:  558]:	worker_index: 3, step: 2627, cost: 7.446441, mlm loss: 7.446441, speed: 1.093920 steps/s, speed: 8.751361 samples/s, speed: 4480.696653 tokens/s, learning rate: 2.626e-05, loss_scalings: 2814.750488, pp_loss: 6.833891
[INFO] 2021-07-12 19:25:25,826 [run_pretraining.py:  512]:	********exe.run_2627******* 
[INFO] 2021-07-12 19:25:26,752 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:26,753 [run_pretraining.py:  534]:	loss/total_loss, 7.157437324523926, 2628
[INFO] 2021-07-12 19:25:26,753 [run_pretraining.py:  535]:	loss/mlm_loss, 7.157437324523926, 2628
[INFO] 2021-07-12 19:25:26,753 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6269997761119157e-05, 2628
[INFO] 2021-07-12 19:25:26,753 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2628
[INFO] 2021-07-12 19:25:26,753 [run_pretraining.py:  558]:	worker_index: 3, step: 2628, cost: 7.157437, mlm loss: 7.157437, speed: 1.078975 steps/s, speed: 8.631803 samples/s, speed: 4419.482912 tokens/s, learning rate: 2.627e-05, loss_scalings: 2814.750488, pp_loss: 7.267710
[INFO] 2021-07-12 19:25:26,753 [run_pretraining.py:  512]:	********exe.run_2628******* 
[INFO] 2021-07-12 19:25:27,681 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:27,682 [run_pretraining.py:  534]:	loss/total_loss, 7.152386665344238, 2629
[INFO] 2021-07-12 19:25:27,682 [run_pretraining.py:  535]:	loss/mlm_loss, 7.152386665344238, 2629
[INFO] 2021-07-12 19:25:27,682 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6280000383849256e-05, 2629
[INFO] 2021-07-12 19:25:27,682 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2629
[INFO] 2021-07-12 19:25:27,682 [run_pretraining.py:  558]:	worker_index: 3, step: 2629, cost: 7.152387, mlm loss: 7.152387, speed: 1.077175 steps/s, speed: 8.617402 samples/s, speed: 4412.109917 tokens/s, learning rate: 2.628e-05, loss_scalings: 2814.750488, pp_loss: 7.131317
[INFO] 2021-07-12 19:25:27,682 [run_pretraining.py:  512]:	********exe.run_2629******* 
[INFO] 2021-07-12 19:25:28,597 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:28,597 [run_pretraining.py:  534]:	loss/total_loss, 7.2311930656433105, 2630
[INFO] 2021-07-12 19:25:28,598 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2311930656433105, 2630
[INFO] 2021-07-12 19:25:28,598 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6289999368600547e-05, 2630
[INFO] 2021-07-12 19:25:28,598 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2630
[INFO] 2021-07-12 19:25:28,598 [run_pretraining.py:  558]:	worker_index: 3, step: 2630, cost: 7.231193, mlm loss: 7.231193, speed: 1.093055 steps/s, speed: 8.744441 samples/s, speed: 4477.153880 tokens/s, learning rate: 2.629e-05, loss_scalings: 2814.750488, pp_loss: 7.253471
[INFO] 2021-07-12 19:25:28,598 [run_pretraining.py:  512]:	********exe.run_2630******* 
[INFO] 2021-07-12 19:25:29,519 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:29,519 [run_pretraining.py:  534]:	loss/total_loss, 6.832147121429443, 2631
[INFO] 2021-07-12 19:25:29,519 [run_pretraining.py:  535]:	loss/mlm_loss, 6.832147121429443, 2631
[INFO] 2021-07-12 19:25:29,519 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6300000172341242e-05, 2631
[INFO] 2021-07-12 19:25:29,520 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2631
[INFO] 2021-07-12 19:25:29,520 [run_pretraining.py:  558]:	worker_index: 3, step: 2631, cost: 6.832147, mlm loss: 6.832147, speed: 1.085452 steps/s, speed: 8.683619 samples/s, speed: 4446.012800 tokens/s, learning rate: 2.630e-05, loss_scalings: 2814.750488, pp_loss: 7.244133
[INFO] 2021-07-12 19:25:29,520 [run_pretraining.py:  512]:	********exe.run_2631******* 
[INFO] 2021-07-12 19:25:30,439 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:30,440 [run_pretraining.py:  534]:	loss/total_loss, 7.348351955413818, 2632
[INFO] 2021-07-12 19:25:30,440 [run_pretraining.py:  535]:	loss/mlm_loss, 7.348351955413818, 2632
[INFO] 2021-07-12 19:25:30,440 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6309999157092534e-05, 2632
[INFO] 2021-07-12 19:25:30,440 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2632
[INFO] 2021-07-12 19:25:30,440 [run_pretraining.py:  558]:	worker_index: 3, step: 2632, cost: 7.348352, mlm loss: 7.348352, speed: 1.087167 steps/s, speed: 8.697337 samples/s, speed: 4453.036741 tokens/s, learning rate: 2.631e-05, loss_scalings: 2814.750488, pp_loss: 7.411194
[INFO] 2021-07-12 19:25:30,440 [run_pretraining.py:  512]:	********exe.run_2632******* 
[INFO] 2021-07-12 19:25:31,355 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:31,356 [run_pretraining.py:  534]:	loss/total_loss, 7.0736236572265625, 2633
[INFO] 2021-07-12 19:25:31,356 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0736236572265625, 2633
[INFO] 2021-07-12 19:25:31,356 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.631999996083323e-05, 2633
[INFO] 2021-07-12 19:25:31,356 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2633
[INFO] 2021-07-12 19:25:31,356 [run_pretraining.py:  558]:	worker_index: 3, step: 2633, cost: 7.073624, mlm loss: 7.073624, speed: 1.092182 steps/s, speed: 8.737453 samples/s, speed: 4473.575934 tokens/s, learning rate: 2.632e-05, loss_scalings: 2814.750488, pp_loss: 7.188266
[INFO] 2021-07-12 19:25:31,356 [run_pretraining.py:  512]:	********exe.run_2633******* 
[INFO] 2021-07-12 19:25:32,270 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:32,270 [run_pretraining.py:  534]:	loss/total_loss, 6.982604026794434, 2634
[INFO] 2021-07-12 19:25:32,271 [run_pretraining.py:  535]:	loss/mlm_loss, 6.982604026794434, 2634
[INFO] 2021-07-12 19:25:32,271 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.632999894558452e-05, 2634
[INFO] 2021-07-12 19:25:32,271 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2634
[INFO] 2021-07-12 19:25:32,271 [run_pretraining.py:  558]:	worker_index: 3, step: 2634, cost: 6.982604, mlm loss: 6.982604, speed: 1.094343 steps/s, speed: 8.754745 samples/s, speed: 4482.429209 tokens/s, learning rate: 2.633e-05, loss_scalings: 2814.750488, pp_loss: 7.292554
[INFO] 2021-07-12 19:25:32,271 [run_pretraining.py:  512]:	********exe.run_2634******* 
[INFO] 2021-07-12 19:25:33,190 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:33,191 [run_pretraining.py:  534]:	loss/total_loss, 6.63319206237793, 2635
[INFO] 2021-07-12 19:25:33,191 [run_pretraining.py:  535]:	loss/mlm_loss, 6.63319206237793, 2635
[INFO] 2021-07-12 19:25:33,191 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6339997930335812e-05, 2635
[INFO] 2021-07-12 19:25:33,191 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2635
[INFO] 2021-07-12 19:25:33,191 [run_pretraining.py:  558]:	worker_index: 3, step: 2635, cost: 6.633192, mlm loss: 6.633192, speed: 1.087390 steps/s, speed: 8.699116 samples/s, speed: 4453.947616 tokens/s, learning rate: 2.634e-05, loss_scalings: 2814.750488, pp_loss: 7.263382
[INFO] 2021-07-12 19:25:33,191 [run_pretraining.py:  512]:	********exe.run_2635******* 
[INFO] 2021-07-12 19:25:34,112 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:34,113 [run_pretraining.py:  534]:	loss/total_loss, 7.0818376541137695, 2636
[INFO] 2021-07-12 19:25:34,114 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0818376541137695, 2636
[INFO] 2021-07-12 19:25:34,115 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.635000055306591e-05, 2636
[INFO] 2021-07-12 19:25:34,116 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2636
[INFO] 2021-07-12 19:25:34,116 [run_pretraining.py:  558]:	worker_index: 3, step: 2636, cost: 7.081838, mlm loss: 7.081838, speed: 1.084924 steps/s, speed: 8.679389 samples/s, speed: 4443.847290 tokens/s, learning rate: 2.635e-05, loss_scalings: 2814.750488, pp_loss: 6.720324
[INFO] 2021-07-12 19:25:34,119 [run_pretraining.py:  512]:	********exe.run_2636******* 
[INFO] 2021-07-12 19:25:35,033 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:35,033 [run_pretraining.py:  534]:	loss/total_loss, 7.668839454650879, 2637
[INFO] 2021-07-12 19:25:35,033 [run_pretraining.py:  535]:	loss/mlm_loss, 7.668839454650879, 2637
[INFO] 2021-07-12 19:25:35,034 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.63599977188278e-05, 2637
[INFO] 2021-07-12 19:25:35,034 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2637
[INFO] 2021-07-12 19:25:35,034 [run_pretraining.py:  558]:	worker_index: 3, step: 2637, cost: 7.668839, mlm loss: 7.668839, speed: 1.094034 steps/s, speed: 8.752269 samples/s, speed: 4481.161810 tokens/s, learning rate: 2.636e-05, loss_scalings: 2814.750488, pp_loss: 7.759286
[INFO] 2021-07-12 19:25:35,034 [run_pretraining.py:  512]:	********exe.run_2637******* 
[INFO] 2021-07-12 19:25:35,957 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:35,958 [run_pretraining.py:  534]:	loss/total_loss, 7.428141117095947, 2638
[INFO] 2021-07-12 19:25:35,958 [run_pretraining.py:  535]:	loss/mlm_loss, 7.428141117095947, 2638
[INFO] 2021-07-12 19:25:35,958 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6370000341557898e-05, 2638
[INFO] 2021-07-12 19:25:35,958 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2638
[INFO] 2021-07-12 19:25:35,958 [run_pretraining.py:  558]:	worker_index: 3, step: 2638, cost: 7.428141, mlm loss: 7.428141, speed: 1.082714 steps/s, speed: 8.661714 samples/s, speed: 4434.797572 tokens/s, learning rate: 2.637e-05, loss_scalings: 2814.750488, pp_loss: 7.230774
[INFO] 2021-07-12 19:25:35,958 [run_pretraining.py:  512]:	********exe.run_2638******* 
[INFO] 2021-07-12 19:25:36,869 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:36,869 [run_pretraining.py:  534]:	loss/total_loss, 7.926738262176514, 2639
[INFO] 2021-07-12 19:25:36,870 [run_pretraining.py:  535]:	loss/mlm_loss, 7.926738262176514, 2639
[INFO] 2021-07-12 19:25:36,870 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.637999932630919e-05, 2639
[INFO] 2021-07-12 19:25:36,870 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2639
[INFO] 2021-07-12 19:25:36,870 [run_pretraining.py:  558]:	worker_index: 3, step: 2639, cost: 7.926738, mlm loss: 7.926738, speed: 1.097458 steps/s, speed: 8.779665 samples/s, speed: 4495.188616 tokens/s, learning rate: 2.638e-05, loss_scalings: 2814.750488, pp_loss: 7.246109
[INFO] 2021-07-12 19:25:36,870 [run_pretraining.py:  512]:	********exe.run_2639******* 
[INFO] 2021-07-12 19:25:37,787 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:37,788 [run_pretraining.py:  534]:	loss/total_loss, 7.226441383361816, 2640
[INFO] 2021-07-12 19:25:37,788 [run_pretraining.py:  535]:	loss/mlm_loss, 7.226441383361816, 2640
[INFO] 2021-07-12 19:25:37,788 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6390000130049884e-05, 2640
[INFO] 2021-07-12 19:25:37,788 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2640
[INFO] 2021-07-12 19:25:37,788 [run_pretraining.py:  558]:	worker_index: 3, step: 2640, cost: 7.226441, mlm loss: 7.226441, speed: 1.090065 steps/s, speed: 8.720520 samples/s, speed: 4464.906087 tokens/s, learning rate: 2.639e-05, loss_scalings: 2814.750488, pp_loss: 6.955030
[INFO] 2021-07-12 19:25:37,788 [run_pretraining.py:  512]:	********exe.run_2640******* 
[INFO] 2021-07-12 19:26:03,414 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:03,415 [run_pretraining.py:  534]:	loss/total_loss, 7.202230453491211, 2641
[INFO] 2021-07-12 19:26:03,415 [run_pretraining.py:  535]:	loss/mlm_loss, 7.202230453491211, 2641
[INFO] 2021-07-12 19:26:03,415 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6399999114801176e-05, 2641
[INFO] 2021-07-12 19:26:03,415 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2641
[INFO] 2021-07-12 19:26:03,415 [run_pretraining.py:  558]:	worker_index: 3, step: 2641, cost: 7.202230, mlm loss: 7.202230, speed: 0.039022 steps/s, speed: 0.312178 samples/s, speed: 159.835311 tokens/s, learning rate: 2.640e-05, loss_scalings: 2814.750488, pp_loss: 7.383164
[INFO] 2021-07-12 19:26:03,415 [run_pretraining.py:  512]:	********exe.run_2641******* 
[INFO] 2021-07-12 19:26:04,330 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:04,331 [run_pretraining.py:  534]:	loss/total_loss, 7.05657434463501, 2642
[INFO] 2021-07-12 19:26:04,331 [run_pretraining.py:  535]:	loss/mlm_loss, 7.05657434463501, 2642
[INFO] 2021-07-12 19:26:04,331 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6409998099552467e-05, 2642
[INFO] 2021-07-12 19:26:04,331 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2642
[INFO] 2021-07-12 19:26:04,331 [run_pretraining.py:  558]:	worker_index: 3, step: 2642, cost: 7.056574, mlm loss: 7.056574, speed: 1.092211 steps/s, speed: 8.737690 samples/s, speed: 4473.697087 tokens/s, learning rate: 2.641e-05, loss_scalings: 2814.750488, pp_loss: 7.041837
[INFO] 2021-07-12 19:26:04,331 [run_pretraining.py:  512]:	********exe.run_2642******* 
[INFO] 2021-07-12 19:26:05,244 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:05,244 [run_pretraining.py:  534]:	loss/total_loss, 6.539228439331055, 2643
[INFO] 2021-07-12 19:26:05,244 [run_pretraining.py:  535]:	loss/mlm_loss, 6.539228439331055, 2643
[INFO] 2021-07-12 19:26:05,244 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6419998903293163e-05, 2643
[INFO] 2021-07-12 19:26:05,244 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2643
[INFO] 2021-07-12 19:26:05,244 [run_pretraining.py:  558]:	worker_index: 3, step: 2643, cost: 6.539228, mlm loss: 6.539228, speed: 1.095715 steps/s, speed: 8.765718 samples/s, speed: 4488.047591 tokens/s, learning rate: 2.642e-05, loss_scalings: 2814.750488, pp_loss: 7.384056
[INFO] 2021-07-12 19:26:05,245 [run_pretraining.py:  512]:	********exe.run_2643******* 
[INFO] 2021-07-12 19:26:06,161 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:06,161 [run_pretraining.py:  534]:	loss/total_loss, 8.052323341369629, 2644
[INFO] 2021-07-12 19:26:06,161 [run_pretraining.py:  535]:	loss/mlm_loss, 8.052323341369629, 2644
[INFO] 2021-07-12 19:26:06,161 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6429997888044454e-05, 2644
[INFO] 2021-07-12 19:26:06,161 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2644
[INFO] 2021-07-12 19:26:06,161 [run_pretraining.py:  558]:	worker_index: 3, step: 2644, cost: 8.052323, mlm loss: 8.052323, speed: 1.091248 steps/s, speed: 8.729988 samples/s, speed: 4469.753661 tokens/s, learning rate: 2.643e-05, loss_scalings: 2814.750488, pp_loss: 7.448051
[INFO] 2021-07-12 19:26:06,162 [run_pretraining.py:  512]:	********exe.run_2644******* 
[INFO] 2021-07-12 19:26:07,076 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:07,077 [run_pretraining.py:  534]:	loss/total_loss, 7.3938517570495605, 2645
[INFO] 2021-07-12 19:26:07,077 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3938517570495605, 2645
[INFO] 2021-07-12 19:26:07,077 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6440000510774553e-05, 2645
[INFO] 2021-07-12 19:26:07,077 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2645
[INFO] 2021-07-12 19:26:07,077 [run_pretraining.py:  558]:	worker_index: 3, step: 2645, cost: 7.393852, mlm loss: 7.393852, speed: 1.093034 steps/s, speed: 8.744275 samples/s, speed: 4477.068708 tokens/s, learning rate: 2.644e-05, loss_scalings: 2814.750488, pp_loss: 7.151293
[INFO] 2021-07-12 19:26:07,077 [run_pretraining.py:  512]:	********exe.run_2645******* 
[INFO] 2021-07-12 19:26:07,994 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:07,994 [run_pretraining.py:  534]:	loss/total_loss, 6.765974998474121, 2646
[INFO] 2021-07-12 19:26:07,994 [run_pretraining.py:  535]:	loss/mlm_loss, 6.765974998474121, 2646
[INFO] 2021-07-12 19:26:07,994 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.644999767653644e-05, 2646
[INFO] 2021-07-12 19:26:07,994 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2646
[INFO] 2021-07-12 19:26:07,995 [run_pretraining.py:  558]:	worker_index: 3, step: 2646, cost: 6.765975, mlm loss: 6.765975, speed: 1.090586 steps/s, speed: 8.724685 samples/s, speed: 4467.038745 tokens/s, learning rate: 2.645e-05, loss_scalings: 2814.750488, pp_loss: 7.275497
[INFO] 2021-07-12 19:26:07,995 [run_pretraining.py:  512]:	********exe.run_2646******* 
[INFO] 2021-07-12 19:26:08,908 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:08,908 [run_pretraining.py:  534]:	loss/total_loss, 8.109624862670898, 2647
[INFO] 2021-07-12 19:26:08,908 [run_pretraining.py:  535]:	loss/mlm_loss, 8.109624862670898, 2647
[INFO] 2021-07-12 19:26:08,908 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.646000029926654e-05, 2647
[INFO] 2021-07-12 19:26:08,909 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2647
[INFO] 2021-07-12 19:26:08,909 [run_pretraining.py:  558]:	worker_index: 3, step: 2647, cost: 8.109625, mlm loss: 8.109625, speed: 1.094755 steps/s, speed: 8.758042 samples/s, speed: 4484.117460 tokens/s, learning rate: 2.646e-05, loss_scalings: 2814.750488, pp_loss: 7.474425
[INFO] 2021-07-12 19:26:08,909 [run_pretraining.py:  512]:	********exe.run_2647******* 
[INFO] 2021-07-12 19:26:09,826 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:09,826 [run_pretraining.py:  534]:	loss/total_loss, 7.195836067199707, 2648
[INFO] 2021-07-12 19:26:09,827 [run_pretraining.py:  535]:	loss/mlm_loss, 7.195836067199707, 2648
[INFO] 2021-07-12 19:26:09,827 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.646999928401783e-05, 2648
[INFO] 2021-07-12 19:26:09,827 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2648
[INFO] 2021-07-12 19:26:09,827 [run_pretraining.py:  558]:	worker_index: 3, step: 2648, cost: 7.195836, mlm loss: 7.195836, speed: 1.089871 steps/s, speed: 8.718967 samples/s, speed: 4464.111359 tokens/s, learning rate: 2.647e-05, loss_scalings: 2814.750488, pp_loss: 7.034854
[INFO] 2021-07-12 19:26:09,827 [run_pretraining.py:  512]:	********exe.run_2648******* 
[INFO] 2021-07-12 19:26:10,739 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:10,740 [run_pretraining.py:  534]:	loss/total_loss, 6.802491188049316, 2649
[INFO] 2021-07-12 19:26:10,740 [run_pretraining.py:  535]:	loss/mlm_loss, 6.802491188049316, 2649
[INFO] 2021-07-12 19:26:10,740 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6480000087758526e-05, 2649
[INFO] 2021-07-12 19:26:10,740 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2649
[INFO] 2021-07-12 19:26:10,740 [run_pretraining.py:  558]:	worker_index: 3, step: 2649, cost: 6.802491, mlm loss: 6.802491, speed: 1.095684 steps/s, speed: 8.765475 samples/s, speed: 4487.923315 tokens/s, learning rate: 2.648e-05, loss_scalings: 2814.750488, pp_loss: 6.865396
[INFO] 2021-07-12 19:26:10,740 [run_pretraining.py:  512]:	********exe.run_2649******* 
[INFO] 2021-07-12 19:26:11,658 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:11,658 [run_pretraining.py:  534]:	loss/total_loss, 6.630190849304199, 2650
[INFO] 2021-07-12 19:26:11,658 [run_pretraining.py:  535]:	loss/mlm_loss, 6.630190849304199, 2650
[INFO] 2021-07-12 19:26:11,659 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6489999072509818e-05, 2650
[INFO] 2021-07-12 19:26:11,659 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2650
[INFO] 2021-07-12 19:26:11,659 [run_pretraining.py:  558]:	worker_index: 3, step: 2650, cost: 6.630191, mlm loss: 6.630191, speed: 1.089271 steps/s, speed: 8.714172 samples/s, speed: 4461.655875 tokens/s, learning rate: 2.649e-05, loss_scalings: 2814.750488, pp_loss: 6.981119
[INFO] 2021-07-12 19:26:11,659 [run_pretraining.py:  512]:	********exe.run_2650******* 
[INFO] 2021-07-12 19:26:12,567 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:12,567 [run_pretraining.py:  534]:	loss/total_loss, 6.612765312194824, 2651
[INFO] 2021-07-12 19:26:12,568 [run_pretraining.py:  535]:	loss/mlm_loss, 6.612765312194824, 2651
[INFO] 2021-07-12 19:26:12,568 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.649999805726111e-05, 2651
[INFO] 2021-07-12 19:26:12,568 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2651
[INFO] 2021-07-12 19:26:12,568 [run_pretraining.py:  558]:	worker_index: 3, step: 2651, cost: 6.612765, mlm loss: 6.612765, speed: 1.100827 steps/s, speed: 8.806614 samples/s, speed: 4508.986332 tokens/s, learning rate: 2.650e-05, loss_scalings: 2814.750488, pp_loss: 6.871796
[INFO] 2021-07-12 19:26:12,568 [run_pretraining.py:  512]:	********exe.run_2651******* 
[INFO] 2021-07-12 19:26:13,481 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:13,481 [run_pretraining.py:  534]:	loss/total_loss, 7.021161079406738, 2652
[INFO] 2021-07-12 19:26:13,481 [run_pretraining.py:  535]:	loss/mlm_loss, 7.021161079406738, 2652
[INFO] 2021-07-12 19:26:13,482 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6509998861001804e-05, 2652
[INFO] 2021-07-12 19:26:13,482 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2652
[INFO] 2021-07-12 19:26:13,482 [run_pretraining.py:  558]:	worker_index: 3, step: 2652, cost: 7.021161, mlm loss: 7.021161, speed: 1.094986 steps/s, speed: 8.759889 samples/s, speed: 4485.063342 tokens/s, learning rate: 2.651e-05, loss_scalings: 2814.750488, pp_loss: 7.331795
[INFO] 2021-07-12 19:26:13,482 [run_pretraining.py:  512]:	********exe.run_2652******* 
[INFO] 2021-07-12 19:26:14,394 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:14,395 [run_pretraining.py:  534]:	loss/total_loss, 7.213498592376709, 2653
[INFO] 2021-07-12 19:26:14,395 [run_pretraining.py:  535]:	loss/mlm_loss, 7.213498592376709, 2653
[INFO] 2021-07-12 19:26:14,395 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6519997845753096e-05, 2653
[INFO] 2021-07-12 19:26:14,395 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2653
[INFO] 2021-07-12 19:26:14,395 [run_pretraining.py:  558]:	worker_index: 3, step: 2653, cost: 7.213499, mlm loss: 7.213499, speed: 1.095853 steps/s, speed: 8.766822 samples/s, speed: 4488.612784 tokens/s, learning rate: 2.652e-05, loss_scalings: 2814.750488, pp_loss: 7.122036
[INFO] 2021-07-12 19:26:14,395 [run_pretraining.py:  512]:	********exe.run_2653******* 
[INFO] 2021-07-12 19:26:15,315 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:15,315 [run_pretraining.py:  534]:	loss/total_loss, 7.260279178619385, 2654
[INFO] 2021-07-12 19:26:15,315 [run_pretraining.py:  535]:	loss/mlm_loss, 7.260279178619385, 2654
[INFO] 2021-07-12 19:26:15,316 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6530000468483195e-05, 2654
[INFO] 2021-07-12 19:26:15,316 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2654
[INFO] 2021-07-12 19:26:15,316 [run_pretraining.py:  558]:	worker_index: 3, step: 2654, cost: 7.260279, mlm loss: 7.260279, speed: 1.086733 steps/s, speed: 8.693863 samples/s, speed: 4451.257628 tokens/s, learning rate: 2.653e-05, loss_scalings: 2814.750488, pp_loss: 7.200584
[INFO] 2021-07-12 19:26:15,316 [run_pretraining.py:  512]:	********exe.run_2654******* 
[INFO] 2021-07-12 19:26:16,230 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:16,230 [run_pretraining.py:  534]:	loss/total_loss, 7.495988845825195, 2655
[INFO] 2021-07-12 19:26:16,231 [run_pretraining.py:  535]:	loss/mlm_loss, 7.495988845825195, 2655
[INFO] 2021-07-12 19:26:16,231 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6539999453234486e-05, 2655
[INFO] 2021-07-12 19:26:16,231 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2655
[INFO] 2021-07-12 19:26:16,231 [run_pretraining.py:  558]:	worker_index: 3, step: 2655, cost: 7.495989, mlm loss: 7.495989, speed: 1.093493 steps/s, speed: 8.747945 samples/s, speed: 4478.947920 tokens/s, learning rate: 2.654e-05, loss_scalings: 2814.750488, pp_loss: 7.229807
[INFO] 2021-07-12 19:26:16,231 [run_pretraining.py:  512]:	********exe.run_2655******* 
[INFO] 2021-07-12 19:26:17,145 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:17,145 [run_pretraining.py:  534]:	loss/total_loss, 7.171002388000488, 2656
[INFO] 2021-07-12 19:26:17,146 [run_pretraining.py:  535]:	loss/mlm_loss, 7.171002388000488, 2656
[INFO] 2021-07-12 19:26:17,146 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.655000025697518e-05, 2656
[INFO] 2021-07-12 19:26:17,146 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2656
[INFO] 2021-07-12 19:26:17,146 [run_pretraining.py:  558]:	worker_index: 3, step: 2656, cost: 7.171002, mlm loss: 7.171002, speed: 1.093628 steps/s, speed: 8.749026 samples/s, speed: 4479.501479 tokens/s, learning rate: 2.655e-05, loss_scalings: 2814.750488, pp_loss: 7.285689
[INFO] 2021-07-12 19:26:17,146 [run_pretraining.py:  512]:	********exe.run_2656******* 
[INFO] 2021-07-12 19:26:18,062 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:18,063 [run_pretraining.py:  534]:	loss/total_loss, 6.988358497619629, 2657
[INFO] 2021-07-12 19:26:18,063 [run_pretraining.py:  535]:	loss/mlm_loss, 6.988358497619629, 2657
[INFO] 2021-07-12 19:26:18,063 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6559999241726473e-05, 2657
[INFO] 2021-07-12 19:26:18,063 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2657
[INFO] 2021-07-12 19:26:18,063 [run_pretraining.py:  558]:	worker_index: 3, step: 2657, cost: 6.988358, mlm loss: 6.988358, speed: 1.090742 steps/s, speed: 8.725935 samples/s, speed: 4467.678824 tokens/s, learning rate: 2.656e-05, loss_scalings: 2814.750488, pp_loss: 7.190271
[INFO] 2021-07-12 19:26:18,063 [run_pretraining.py:  512]:	********exe.run_2657******* 
[INFO] 2021-07-12 19:26:18,975 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:18,976 [run_pretraining.py:  534]:	loss/total_loss, 7.211395740509033, 2658
[INFO] 2021-07-12 19:26:18,976 [run_pretraining.py:  535]:	loss/mlm_loss, 7.211395740509033, 2658
[INFO] 2021-07-12 19:26:18,976 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6570000045467168e-05, 2658
[INFO] 2021-07-12 19:26:18,976 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2658
[INFO] 2021-07-12 19:26:18,976 [run_pretraining.py:  558]:	worker_index: 3, step: 2658, cost: 7.211396, mlm loss: 7.211396, speed: 1.096494 steps/s, speed: 8.771949 samples/s, speed: 4491.237754 tokens/s, learning rate: 2.657e-05, loss_scalings: 2814.750488, pp_loss: 7.213525
[INFO] 2021-07-12 19:26:18,976 [run_pretraining.py:  512]:	********exe.run_2658******* 
[INFO] 2021-07-12 19:26:19,899 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:19,899 [run_pretraining.py:  534]:	loss/total_loss, 7.519364833831787, 2659
[INFO] 2021-07-12 19:26:19,899 [run_pretraining.py:  535]:	loss/mlm_loss, 7.519364833831787, 2659
[INFO] 2021-07-12 19:26:19,899 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.657999903021846e-05, 2659
[INFO] 2021-07-12 19:26:19,899 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2659
[INFO] 2021-07-12 19:26:19,900 [run_pretraining.py:  558]:	worker_index: 3, step: 2659, cost: 7.519365, mlm loss: 7.519365, speed: 1.083463 steps/s, speed: 8.667706 samples/s, speed: 4437.865454 tokens/s, learning rate: 2.658e-05, loss_scalings: 2814.750488, pp_loss: 7.389404
[INFO] 2021-07-12 19:26:19,900 [run_pretraining.py:  512]:	********exe.run_2659******* 
[INFO] 2021-07-12 19:26:20,823 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:20,823 [run_pretraining.py:  534]:	loss/total_loss, 6.8168044090271, 2660
[INFO] 2021-07-12 19:26:20,823 [run_pretraining.py:  535]:	loss/mlm_loss, 6.8168044090271, 2660
[INFO] 2021-07-12 19:26:20,824 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.658999801496975e-05, 2660
[INFO] 2021-07-12 19:26:20,824 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2660
[INFO] 2021-07-12 19:26:20,824 [run_pretraining.py:  558]:	worker_index: 3, step: 2660, cost: 6.816804, mlm loss: 6.816804, speed: 1.082775 steps/s, speed: 8.662204 samples/s, speed: 4435.048296 tokens/s, learning rate: 2.659e-05, loss_scalings: 2814.750488, pp_loss: 7.201125
[INFO] 2021-07-12 19:26:20,824 [run_pretraining.py:  512]:	********exe.run_2660******* 
[INFO] 2021-07-12 19:26:21,744 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:21,745 [run_pretraining.py:  534]:	loss/total_loss, 7.2668843269348145, 2661
[INFO] 2021-07-12 19:26:21,745 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2668843269348145, 2661
[INFO] 2021-07-12 19:26:21,745 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6599998818710446e-05, 2661
[INFO] 2021-07-12 19:26:21,745 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2661
[INFO] 2021-07-12 19:26:21,745 [run_pretraining.py:  558]:	worker_index: 3, step: 2661, cost: 7.266884, mlm loss: 7.266884, speed: 1.086115 steps/s, speed: 8.688921 samples/s, speed: 4448.727554 tokens/s, learning rate: 2.660e-05, loss_scalings: 2814.750488, pp_loss: 7.437239
[INFO] 2021-07-12 19:26:21,745 [run_pretraining.py:  512]:	********exe.run_2661******* 
[INFO] 2021-07-12 19:26:22,663 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:22,663 [run_pretraining.py:  534]:	loss/total_loss, 7.072050094604492, 2662
[INFO] 2021-07-12 19:26:22,663 [run_pretraining.py:  535]:	loss/mlm_loss, 7.072050094604492, 2662
[INFO] 2021-07-12 19:26:22,663 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6609997803461738e-05, 2662
[INFO] 2021-07-12 19:26:22,663 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2662
[INFO] 2021-07-12 19:26:22,664 [run_pretraining.py:  558]:	worker_index: 3, step: 2662, cost: 7.072050, mlm loss: 7.072050, speed: 1.089573 steps/s, speed: 8.716582 samples/s, speed: 4462.890235 tokens/s, learning rate: 2.661e-05, loss_scalings: 2814.750488, pp_loss: 6.685812
[INFO] 2021-07-12 19:26:22,664 [run_pretraining.py:  512]:	********exe.run_2662******* 
[INFO] 2021-07-12 19:26:23,574 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:23,574 [run_pretraining.py:  534]:	loss/total_loss, 7.5562052726745605, 2663
[INFO] 2021-07-12 19:26:23,575 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5562052726745605, 2663
[INFO] 2021-07-12 19:26:23,575 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6620000426191837e-05, 2663
[INFO] 2021-07-12 19:26:23,575 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2663
[INFO] 2021-07-12 19:26:23,575 [run_pretraining.py:  558]:	worker_index: 3, step: 2663, cost: 7.556205, mlm loss: 7.556205, speed: 1.098130 steps/s, speed: 8.785042 samples/s, speed: 4497.941400 tokens/s, learning rate: 2.662e-05, loss_scalings: 2814.750488, pp_loss: 7.106291
[INFO] 2021-07-12 19:26:23,575 [run_pretraining.py:  512]:	********exe.run_2663******* 
[INFO] 2021-07-12 19:26:24,486 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:24,486 [run_pretraining.py:  534]:	loss/total_loss, 6.6431660652160645, 2664
[INFO] 2021-07-12 19:26:24,486 [run_pretraining.py:  535]:	loss/mlm_loss, 6.6431660652160645, 2664
[INFO] 2021-07-12 19:26:24,486 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6629999410943128e-05, 2664
[INFO] 2021-07-12 19:26:24,486 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2664
[INFO] 2021-07-12 19:26:24,487 [run_pretraining.py:  558]:	worker_index: 3, step: 2664, cost: 6.643166, mlm loss: 6.643166, speed: 1.097626 steps/s, speed: 8.781005 samples/s, speed: 4495.874437 tokens/s, learning rate: 2.663e-05, loss_scalings: 2814.750488, pp_loss: 7.272875
[INFO] 2021-07-12 19:26:24,487 [run_pretraining.py:  512]:	********exe.run_2664******* 
[INFO] 2021-07-12 19:26:25,409 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:25,409 [run_pretraining.py:  534]:	loss/total_loss, 6.956884384155273, 2665
[INFO] 2021-07-12 19:26:25,410 [run_pretraining.py:  535]:	loss/mlm_loss, 6.956884384155273, 2665
[INFO] 2021-07-12 19:26:25,410 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6640000214683823e-05, 2665
[INFO] 2021-07-12 19:26:25,410 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2665
[INFO] 2021-07-12 19:26:25,410 [run_pretraining.py:  558]:	worker_index: 3, step: 2665, cost: 6.956884, mlm loss: 6.956884, speed: 1.083822 steps/s, speed: 8.670575 samples/s, speed: 4439.334452 tokens/s, learning rate: 2.664e-05, loss_scalings: 2814.750488, pp_loss: 7.108687
[INFO] 2021-07-12 19:26:25,410 [run_pretraining.py:  512]:	********exe.run_2665******* 
[INFO] 2021-07-12 19:26:26,327 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:26,327 [run_pretraining.py:  534]:	loss/total_loss, 7.277987480163574, 2666
[INFO] 2021-07-12 19:26:26,327 [run_pretraining.py:  535]:	loss/mlm_loss, 7.277987480163574, 2666
[INFO] 2021-07-12 19:26:26,327 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6649999199435115e-05, 2666
[INFO] 2021-07-12 19:26:26,327 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2666
[INFO] 2021-07-12 19:26:26,328 [run_pretraining.py:  558]:	worker_index: 3, step: 2666, cost: 7.277987, mlm loss: 7.277987, speed: 1.090456 steps/s, speed: 8.723646 samples/s, speed: 4466.506841 tokens/s, learning rate: 2.665e-05, loss_scalings: 2814.750488, pp_loss: 6.899538
[INFO] 2021-07-12 19:26:26,328 [run_pretraining.py:  512]:	********exe.run_2666******* 
[INFO] 2021-07-12 19:26:27,247 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:27,247 [run_pretraining.py:  534]:	loss/total_loss, 8.599592208862305, 2667
[INFO] 2021-07-12 19:26:27,247 [run_pretraining.py:  535]:	loss/mlm_loss, 8.599592208862305, 2667
[INFO] 2021-07-12 19:26:27,247 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.666000000317581e-05, 2667
[INFO] 2021-07-12 19:26:27,247 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2667
[INFO] 2021-07-12 19:26:27,247 [run_pretraining.py:  558]:	worker_index: 3, step: 2667, cost: 8.599592, mlm loss: 8.599592, speed: 1.087802 steps/s, speed: 8.702419 samples/s, speed: 4455.638743 tokens/s, learning rate: 2.666e-05, loss_scalings: 2814.750488, pp_loss: 7.684860
[INFO] 2021-07-12 19:26:27,248 [run_pretraining.py:  512]:	********exe.run_2667******* 
[INFO] 2021-07-12 19:26:28,170 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:28,171 [run_pretraining.py:  534]:	loss/total_loss, 7.211092948913574, 2668
[INFO] 2021-07-12 19:26:28,171 [run_pretraining.py:  535]:	loss/mlm_loss, 7.211092948913574, 2668
[INFO] 2021-07-12 19:26:28,171 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.66699989879271e-05, 2668
[INFO] 2021-07-12 19:26:28,171 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2668
[INFO] 2021-07-12 19:26:28,171 [run_pretraining.py:  558]:	worker_index: 3, step: 2668, cost: 7.211093, mlm loss: 7.211093, speed: 1.083466 steps/s, speed: 8.667731 samples/s, speed: 4437.878064 tokens/s, learning rate: 2.667e-05, loss_scalings: 2814.750488, pp_loss: 7.228875
[INFO] 2021-07-12 19:26:28,171 [run_pretraining.py:  512]:	********exe.run_2668******* 
[INFO] 2021-07-12 19:26:29,092 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:29,092 [run_pretraining.py:  534]:	loss/total_loss, 7.220577239990234, 2669
[INFO] 2021-07-12 19:26:29,092 [run_pretraining.py:  535]:	loss/mlm_loss, 7.220577239990234, 2669
[INFO] 2021-07-12 19:26:29,092 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6679997972678393e-05, 2669
[INFO] 2021-07-12 19:26:29,092 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2669
[INFO] 2021-07-12 19:26:29,093 [run_pretraining.py:  558]:	worker_index: 3, step: 2669, cost: 7.220577, mlm loss: 7.220577, speed: 1.085983 steps/s, speed: 8.687866 samples/s, speed: 4448.187333 tokens/s, learning rate: 2.668e-05, loss_scalings: 2814.750488, pp_loss: 7.170671
[INFO] 2021-07-12 19:26:29,093 [run_pretraining.py:  512]:	********exe.run_2669******* 
[INFO] 2021-07-12 19:26:30,006 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:30,006 [run_pretraining.py:  534]:	loss/total_loss, 7.383462429046631, 2670
[INFO] 2021-07-12 19:26:30,006 [run_pretraining.py:  535]:	loss/mlm_loss, 7.383462429046631, 2670
[INFO] 2021-07-12 19:26:30,006 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6689998776419088e-05, 2670
[INFO] 2021-07-12 19:26:30,007 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2670
[INFO] 2021-07-12 19:26:30,007 [run_pretraining.py:  558]:	worker_index: 3, step: 2670, cost: 7.383462, mlm loss: 7.383462, speed: 1.094722 steps/s, speed: 8.757777 samples/s, speed: 4483.981697 tokens/s, learning rate: 2.669e-05, loss_scalings: 2814.750488, pp_loss: 7.504149
[INFO] 2021-07-12 19:26:30,007 [run_pretraining.py:  512]:	********exe.run_2670******* 
[INFO] 2021-07-12 19:26:31,040 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:31,041 [run_pretraining.py:  534]:	loss/total_loss, 8.080227851867676, 2671
[INFO] 2021-07-12 19:26:31,041 [run_pretraining.py:  535]:	loss/mlm_loss, 8.080227851867676, 2671
[INFO] 2021-07-12 19:26:31,041 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.669999776117038e-05, 2671
[INFO] 2021-07-12 19:26:31,041 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2671
[INFO] 2021-07-12 19:26:31,041 [run_pretraining.py:  558]:	worker_index: 3, step: 2671, cost: 8.080228, mlm loss: 8.080228, speed: 0.967246 steps/s, speed: 7.737967 samples/s, speed: 3961.839032 tokens/s, learning rate: 2.670e-05, loss_scalings: 2814.750488, pp_loss: 7.389196
[INFO] 2021-07-12 19:26:31,041 [run_pretraining.py:  512]:	********exe.run_2671******* 
[INFO] 2021-07-12 19:26:32,138 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:32,138 [run_pretraining.py:  534]:	loss/total_loss, 7.1206536293029785, 2672
[INFO] 2021-07-12 19:26:32,138 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1206536293029785, 2672
[INFO] 2021-07-12 19:26:32,138 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.671000038390048e-05, 2672
[INFO] 2021-07-12 19:26:32,138 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2672
[INFO] 2021-07-12 19:26:32,138 [run_pretraining.py:  558]:	worker_index: 3, step: 2672, cost: 7.120654, mlm loss: 7.120654, speed: 0.911849 steps/s, speed: 7.294792 samples/s, speed: 3734.933610 tokens/s, learning rate: 2.671e-05, loss_scalings: 2814.750488, pp_loss: 7.384815
[INFO] 2021-07-12 19:26:32,138 [run_pretraining.py:  512]:	********exe.run_2672******* 
[INFO] 2021-07-12 19:26:33,239 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:33,239 [run_pretraining.py:  534]:	loss/total_loss, 7.38858699798584, 2673
[INFO] 2021-07-12 19:26:33,240 [run_pretraining.py:  535]:	loss/mlm_loss, 7.38858699798584, 2673
[INFO] 2021-07-12 19:26:33,240 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.671999936865177e-05, 2673
[INFO] 2021-07-12 19:26:33,240 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2673
[INFO] 2021-07-12 19:26:33,240 [run_pretraining.py:  558]:	worker_index: 3, step: 2673, cost: 7.388587, mlm loss: 7.388587, speed: 0.908460 steps/s, speed: 7.267682 samples/s, speed: 3721.053414 tokens/s, learning rate: 2.672e-05, loss_scalings: 2814.750488, pp_loss: 6.743464
[INFO] 2021-07-12 19:26:33,240 [run_pretraining.py:  512]:	********exe.run_2673******* 
[INFO] 2021-07-12 19:26:34,325 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:34,326 [run_pretraining.py:  534]:	loss/total_loss, 7.774571418762207, 2674
[INFO] 2021-07-12 19:26:34,326 [run_pretraining.py:  535]:	loss/mlm_loss, 7.774571418762207, 2674
[INFO] 2021-07-12 19:26:34,326 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6730000172392465e-05, 2674
[INFO] 2021-07-12 19:26:34,326 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2674
[INFO] 2021-07-12 19:26:34,326 [run_pretraining.py:  558]:	worker_index: 3, step: 2674, cost: 7.774571, mlm loss: 7.774571, speed: 0.921049 steps/s, speed: 7.368390 samples/s, speed: 3772.615649 tokens/s, learning rate: 2.673e-05, loss_scalings: 2814.750488, pp_loss: 7.666645
[INFO] 2021-07-12 19:26:34,326 [run_pretraining.py:  512]:	********exe.run_2674******* 
[INFO] 2021-07-12 19:26:35,423 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:35,423 [run_pretraining.py:  534]:	loss/total_loss, 7.375156402587891, 2675
[INFO] 2021-07-12 19:26:35,424 [run_pretraining.py:  535]:	loss/mlm_loss, 7.375156402587891, 2675
[INFO] 2021-07-12 19:26:35,424 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6739999157143757e-05, 2675
[INFO] 2021-07-12 19:26:35,424 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2675
[INFO] 2021-07-12 19:26:35,424 [run_pretraining.py:  558]:	worker_index: 3, step: 2675, cost: 7.375156, mlm loss: 7.375156, speed: 0.911586 steps/s, speed: 7.292691 samples/s, speed: 3733.858045 tokens/s, learning rate: 2.674e-05, loss_scalings: 2814.750488, pp_loss: 7.140732
[INFO] 2021-07-12 19:26:35,424 [run_pretraining.py:  512]:	********exe.run_2675******* 
[INFO] 2021-07-12 19:26:36,517 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:36,517 [run_pretraining.py:  534]:	loss/total_loss, 7.659145355224609, 2676
[INFO] 2021-07-12 19:26:36,517 [run_pretraining.py:  535]:	loss/mlm_loss, 7.659145355224609, 2676
[INFO] 2021-07-12 19:26:36,518 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6749999960884452e-05, 2676
[INFO] 2021-07-12 19:26:36,518 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2676
[INFO] 2021-07-12 19:26:36,518 [run_pretraining.py:  558]:	worker_index: 3, step: 2676, cost: 7.659145, mlm loss: 7.659145, speed: 0.914681 steps/s, speed: 7.317446 samples/s, speed: 3746.532127 tokens/s, learning rate: 2.675e-05, loss_scalings: 2814.750488, pp_loss: 7.411492
[INFO] 2021-07-12 19:26:36,518 [run_pretraining.py:  512]:	********exe.run_2676******* 
[INFO] 2021-07-12 19:26:37,611 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:37,611 [run_pretraining.py:  534]:	loss/total_loss, 7.447788238525391, 2677
[INFO] 2021-07-12 19:26:37,611 [run_pretraining.py:  535]:	loss/mlm_loss, 7.447788238525391, 2677
[INFO] 2021-07-12 19:26:37,611 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6759998945635743e-05, 2677
[INFO] 2021-07-12 19:26:37,611 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2677
[INFO] 2021-07-12 19:26:37,611 [run_pretraining.py:  558]:	worker_index: 3, step: 2677, cost: 7.447788, mlm loss: 7.447788, speed: 0.914797 steps/s, speed: 7.318373 samples/s, speed: 3747.006883 tokens/s, learning rate: 2.676e-05, loss_scalings: 2814.750488, pp_loss: 7.352543
[INFO] 2021-07-12 19:26:37,612 [run_pretraining.py:  512]:	********exe.run_2677******* 
[INFO] 2021-07-12 19:26:38,712 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:38,712 [run_pretraining.py:  534]:	loss/total_loss, 7.415841579437256, 2678
[INFO] 2021-07-12 19:26:38,713 [run_pretraining.py:  535]:	loss/mlm_loss, 7.415841579437256, 2678
[INFO] 2021-07-12 19:26:38,713 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6769997930387035e-05, 2678
[INFO] 2021-07-12 19:26:38,713 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2678
[INFO] 2021-07-12 19:26:38,713 [run_pretraining.py:  558]:	worker_index: 3, step: 2678, cost: 7.415842, mlm loss: 7.415842, speed: 0.908557 steps/s, speed: 7.268455 samples/s, speed: 3721.449181 tokens/s, learning rate: 2.677e-05, loss_scalings: 2814.750488, pp_loss: 6.796502
[INFO] 2021-07-12 19:26:38,713 [run_pretraining.py:  512]:	********exe.run_2678******* 
[INFO] 2021-07-12 19:26:39,811 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:39,812 [run_pretraining.py:  534]:	loss/total_loss, 4.787039756774902, 2679
[INFO] 2021-07-12 19:26:39,812 [run_pretraining.py:  535]:	loss/mlm_loss, 4.787039756774902, 2679
[INFO] 2021-07-12 19:26:39,812 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6780000553117134e-05, 2679
[INFO] 2021-07-12 19:26:39,812 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2679
[INFO] 2021-07-12 19:26:39,812 [run_pretraining.py:  558]:	worker_index: 3, step: 2679, cost: 4.787040, mlm loss: 4.787040, speed: 0.910042 steps/s, speed: 7.280335 samples/s, speed: 3727.531673 tokens/s, learning rate: 2.678e-05, loss_scalings: 2814.750488, pp_loss: 6.374588
[INFO] 2021-07-12 19:26:39,812 [run_pretraining.py:  512]:	********exe.run_2679******* 
[INFO] 2021-07-12 19:26:40,899 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:40,899 [run_pretraining.py:  534]:	loss/total_loss, 6.588557720184326, 2680
[INFO] 2021-07-12 19:26:40,899 [run_pretraining.py:  535]:	loss/mlm_loss, 6.588557720184326, 2680
[INFO] 2021-07-12 19:26:40,900 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6789997718879022e-05, 2680
[INFO] 2021-07-12 19:26:40,900 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2680
[INFO] 2021-07-12 19:26:40,900 [run_pretraining.py:  558]:	worker_index: 3, step: 2680, cost: 6.588558, mlm loss: 6.588558, speed: 0.920124 steps/s, speed: 7.360993 samples/s, speed: 3768.828476 tokens/s, learning rate: 2.679e-05, loss_scalings: 2814.750488, pp_loss: 6.908529
[INFO] 2021-07-12 19:26:40,900 [run_pretraining.py:  512]:	********exe.run_2680******* 
[INFO] 2021-07-12 19:26:41,984 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:41,985 [run_pretraining.py:  534]:	loss/total_loss, 6.461063861846924, 2681
[INFO] 2021-07-12 19:26:41,985 [run_pretraining.py:  535]:	loss/mlm_loss, 6.461063861846924, 2681
[INFO] 2021-07-12 19:26:41,985 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.680000034160912e-05, 2681
[INFO] 2021-07-12 19:26:41,985 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2681
[INFO] 2021-07-12 19:26:41,985 [run_pretraining.py:  558]:	worker_index: 3, step: 2681, cost: 6.461064, mlm loss: 6.461064, speed: 0.921746 steps/s, speed: 7.373970 samples/s, speed: 3775.472643 tokens/s, learning rate: 2.680e-05, loss_scalings: 2814.750488, pp_loss: 6.936409
[INFO] 2021-07-12 19:26:41,985 [run_pretraining.py:  512]:	********exe.run_2681******* 
[INFO] 2021-07-12 19:26:43,093 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:43,093 [run_pretraining.py:  534]:	loss/total_loss, 7.333619117736816, 2682
[INFO] 2021-07-12 19:26:43,093 [run_pretraining.py:  535]:	loss/mlm_loss, 7.333619117736816, 2682
[INFO] 2021-07-12 19:26:43,093 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6809999326360412e-05, 2682
[INFO] 2021-07-12 19:26:43,093 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2682
[INFO] 2021-07-12 19:26:43,093 [run_pretraining.py:  558]:	worker_index: 3, step: 2682, cost: 7.333619, mlm loss: 7.333619, speed: 0.902930 steps/s, speed: 7.223440 samples/s, speed: 3698.401298 tokens/s, learning rate: 2.681e-05, loss_scalings: 2814.750488, pp_loss: 7.376979
[INFO] 2021-07-12 19:26:43,093 [run_pretraining.py:  512]:	********exe.run_2682******* 
[INFO] 2021-07-12 19:26:44,181 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:44,182 [run_pretraining.py:  534]:	loss/total_loss, 6.613589763641357, 2683
[INFO] 2021-07-12 19:26:44,182 [run_pretraining.py:  535]:	loss/mlm_loss, 6.613589763641357, 2683
[INFO] 2021-07-12 19:26:44,182 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6820000130101107e-05, 2683
[INFO] 2021-07-12 19:26:44,182 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2683
[INFO] 2021-07-12 19:26:44,182 [run_pretraining.py:  558]:	worker_index: 3, step: 2683, cost: 6.613590, mlm loss: 6.613590, speed: 0.918942 steps/s, speed: 7.351533 samples/s, speed: 3763.984785 tokens/s, learning rate: 2.682e-05, loss_scalings: 2814.750488, pp_loss: 6.582918
[INFO] 2021-07-12 19:26:44,182 [run_pretraining.py:  512]:	********exe.run_2683******* 
[INFO] 2021-07-12 19:26:45,279 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:45,280 [run_pretraining.py:  534]:	loss/total_loss, 7.09385347366333, 2684
[INFO] 2021-07-12 19:26:45,280 [run_pretraining.py:  535]:	loss/mlm_loss, 7.09385347366333, 2684
[INFO] 2021-07-12 19:26:45,280 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.68299991148524e-05, 2684
[INFO] 2021-07-12 19:26:45,280 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2684
[INFO] 2021-07-12 19:26:45,280 [run_pretraining.py:  558]:	worker_index: 3, step: 2684, cost: 7.093853, mlm loss: 7.093853, speed: 0.911328 steps/s, speed: 7.290624 samples/s, speed: 3732.799320 tokens/s, learning rate: 2.683e-05, loss_scalings: 2814.750488, pp_loss: 7.648313
[INFO] 2021-07-12 19:26:45,280 [run_pretraining.py:  512]:	********exe.run_2684******* 
[INFO] 2021-07-12 19:26:46,406 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:46,407 [run_pretraining.py:  534]:	loss/total_loss, 7.482897758483887, 2685
[INFO] 2021-07-12 19:26:46,407 [run_pretraining.py:  535]:	loss/mlm_loss, 7.482897758483887, 2685
[INFO] 2021-07-12 19:26:46,407 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6839999918593094e-05, 2685
[INFO] 2021-07-12 19:26:46,407 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2685
[INFO] 2021-07-12 19:26:46,407 [run_pretraining.py:  558]:	worker_index: 3, step: 2685, cost: 7.482898, mlm loss: 7.482898, speed: 0.887845 steps/s, speed: 7.102760 samples/s, speed: 3636.613052 tokens/s, learning rate: 2.684e-05, loss_scalings: 2814.750488, pp_loss: 7.304889
[INFO] 2021-07-12 19:26:46,407 [run_pretraining.py:  512]:	********exe.run_2685******* 
[INFO] 2021-07-12 19:26:47,496 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:47,496 [run_pretraining.py:  534]:	loss/total_loss, 6.836323261260986, 2686
[INFO] 2021-07-12 19:26:47,496 [run_pretraining.py:  535]:	loss/mlm_loss, 6.836323261260986, 2686
[INFO] 2021-07-12 19:26:47,496 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6849998903344385e-05, 2686
[INFO] 2021-07-12 19:26:47,496 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2686
[INFO] 2021-07-12 19:26:47,497 [run_pretraining.py:  558]:	worker_index: 3, step: 2686, cost: 6.836323, mlm loss: 6.836323, speed: 0.918478 steps/s, speed: 7.347825 samples/s, speed: 3762.086547 tokens/s, learning rate: 2.685e-05, loss_scalings: 2814.750488, pp_loss: 7.214363
[INFO] 2021-07-12 19:26:47,497 [run_pretraining.py:  512]:	********exe.run_2686******* 
[INFO] 2021-07-12 19:26:48,592 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:48,593 [run_pretraining.py:  534]:	loss/total_loss, 7.233200550079346, 2687
[INFO] 2021-07-12 19:26:48,593 [run_pretraining.py:  535]:	loss/mlm_loss, 7.233200550079346, 2687
[INFO] 2021-07-12 19:26:48,593 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6859997888095677e-05, 2687
[INFO] 2021-07-12 19:26:48,593 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2687
[INFO] 2021-07-12 19:26:48,593 [run_pretraining.py:  558]:	worker_index: 3, step: 2687, cost: 7.233201, mlm loss: 7.233201, speed: 0.912394 steps/s, speed: 7.299154 samples/s, speed: 3737.167080 tokens/s, learning rate: 2.686e-05, loss_scalings: 2814.750488, pp_loss: 7.182690
[INFO] 2021-07-12 19:26:48,593 [run_pretraining.py:  512]:	********exe.run_2687******* 
[INFO] 2021-07-12 19:26:49,685 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:49,685 [run_pretraining.py:  534]:	loss/total_loss, 7.082804203033447, 2688
[INFO] 2021-07-12 19:26:49,686 [run_pretraining.py:  535]:	loss/mlm_loss, 7.082804203033447, 2688
[INFO] 2021-07-12 19:26:49,686 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6870000510825776e-05, 2688
[INFO] 2021-07-12 19:26:49,686 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2688
[INFO] 2021-07-12 19:26:49,686 [run_pretraining.py:  558]:	worker_index: 3, step: 2688, cost: 7.082804, mlm loss: 7.082804, speed: 0.915757 steps/s, speed: 7.326054 samples/s, speed: 3750.939474 tokens/s, learning rate: 2.687e-05, loss_scalings: 2814.750488, pp_loss: 6.855727
[INFO] 2021-07-12 19:26:49,686 [run_pretraining.py:  512]:	********exe.run_2688******* 
[INFO] 2021-07-12 19:26:50,776 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:50,777 [run_pretraining.py:  534]:	loss/total_loss, 7.142395973205566, 2689
[INFO] 2021-07-12 19:26:50,777 [run_pretraining.py:  535]:	loss/mlm_loss, 7.142395973205566, 2689
[INFO] 2021-07-12 19:26:50,777 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6879997676587664e-05, 2689
[INFO] 2021-07-12 19:26:50,777 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2689
[INFO] 2021-07-12 19:26:50,777 [run_pretraining.py:  558]:	worker_index: 3, step: 2689, cost: 7.142396, mlm loss: 7.142396, speed: 0.916788 steps/s, speed: 7.334305 samples/s, speed: 3755.164305 tokens/s, learning rate: 2.688e-05, loss_scalings: 2814.750488, pp_loss: 7.254034
[INFO] 2021-07-12 19:26:50,777 [run_pretraining.py:  512]:	********exe.run_2689******* 
[INFO] 2021-07-12 19:26:51,875 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:51,875 [run_pretraining.py:  534]:	loss/total_loss, 7.230378150939941, 2690
[INFO] 2021-07-12 19:26:51,875 [run_pretraining.py:  535]:	loss/mlm_loss, 7.230378150939941, 2690
[INFO] 2021-07-12 19:26:51,876 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6890000299317762e-05, 2690
[INFO] 2021-07-12 19:26:51,876 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2690
[INFO] 2021-07-12 19:26:51,876 [run_pretraining.py:  558]:	worker_index: 3, step: 2690, cost: 7.230378, mlm loss: 7.230378, speed: 0.910925 steps/s, speed: 7.287403 samples/s, speed: 3731.150366 tokens/s, learning rate: 2.689e-05, loss_scalings: 2814.750488, pp_loss: 7.217219
[INFO] 2021-07-12 19:26:51,876 [run_pretraining.py:  512]:	********exe.run_2690******* 
[INFO] 2021-07-12 19:26:52,967 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:52,968 [run_pretraining.py:  534]:	loss/total_loss, 8.030315399169922, 2691
[INFO] 2021-07-12 19:26:52,968 [run_pretraining.py:  535]:	loss/mlm_loss, 8.030315399169922, 2691
[INFO] 2021-07-12 19:26:52,968 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6899999284069054e-05, 2691
[INFO] 2021-07-12 19:26:52,968 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2691
[INFO] 2021-07-12 19:26:52,968 [run_pretraining.py:  558]:	worker_index: 3, step: 2691, cost: 8.030315, mlm loss: 8.030315, speed: 0.915784 steps/s, speed: 7.326271 samples/s, speed: 3751.050856 tokens/s, learning rate: 2.690e-05, loss_scalings: 2814.750488, pp_loss: 6.587584
[INFO] 2021-07-12 19:26:52,968 [run_pretraining.py:  512]:	********exe.run_2691******* 
[INFO] 2021-07-12 19:26:54,065 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:54,066 [run_pretraining.py:  534]:	loss/total_loss, 8.44104290008545, 2692
[INFO] 2021-07-12 19:26:54,066 [run_pretraining.py:  535]:	loss/mlm_loss, 8.44104290008545, 2692
[INFO] 2021-07-12 19:26:54,066 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.691000008780975e-05, 2692
[INFO] 2021-07-12 19:26:54,066 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2692
[INFO] 2021-07-12 19:26:54,066 [run_pretraining.py:  558]:	worker_index: 3, step: 2692, cost: 8.441043, mlm loss: 8.441043, speed: 0.911562 steps/s, speed: 7.292498 samples/s, speed: 3733.759042 tokens/s, learning rate: 2.691e-05, loss_scalings: 2814.750488, pp_loss: 7.619325
[INFO] 2021-07-12 19:26:54,066 [run_pretraining.py:  512]:	********exe.run_2692******* 
[INFO] 2021-07-12 19:26:55,163 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:55,164 [run_pretraining.py:  534]:	loss/total_loss, 6.769510269165039, 2693
[INFO] 2021-07-12 19:26:55,164 [run_pretraining.py:  535]:	loss/mlm_loss, 6.769510269165039, 2693
[INFO] 2021-07-12 19:26:55,164 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.691999907256104e-05, 2693
[INFO] 2021-07-12 19:26:55,164 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2693
[INFO] 2021-07-12 19:26:55,164 [run_pretraining.py:  558]:	worker_index: 3, step: 2693, cost: 6.769510, mlm loss: 6.769510, speed: 0.911129 steps/s, speed: 7.289030 samples/s, speed: 3731.983578 tokens/s, learning rate: 2.692e-05, loss_scalings: 2814.750488, pp_loss: 7.348742
[INFO] 2021-07-12 19:26:55,164 [run_pretraining.py:  512]:	********exe.run_2693******* 
[INFO] 2021-07-12 19:26:56,257 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:56,258 [run_pretraining.py:  534]:	loss/total_loss, 6.753910064697266, 2694
[INFO] 2021-07-12 19:26:56,258 [run_pretraining.py:  535]:	loss/mlm_loss, 6.753910064697266, 2694
[INFO] 2021-07-12 19:26:56,258 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6929999876301736e-05, 2694
[INFO] 2021-07-12 19:26:56,258 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2694
[INFO] 2021-07-12 19:26:56,258 [run_pretraining.py:  558]:	worker_index: 3, step: 2694, cost: 6.753910, mlm loss: 6.753910, speed: 0.914411 steps/s, speed: 7.315287 samples/s, speed: 3745.427009 tokens/s, learning rate: 2.693e-05, loss_scalings: 2814.750488, pp_loss: 5.927702
[INFO] 2021-07-12 19:26:56,258 [run_pretraining.py:  512]:	********exe.run_2694******* 
[INFO] 2021-07-12 19:26:57,354 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:57,354 [run_pretraining.py:  534]:	loss/total_loss, 6.897397041320801, 2695
[INFO] 2021-07-12 19:26:57,354 [run_pretraining.py:  535]:	loss/mlm_loss, 6.897397041320801, 2695
[INFO] 2021-07-12 19:26:57,355 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6939998861053027e-05, 2695
[INFO] 2021-07-12 19:26:57,355 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2695
[INFO] 2021-07-12 19:26:57,355 [run_pretraining.py:  558]:	worker_index: 3, step: 2695, cost: 6.897397, mlm loss: 6.897397, speed: 0.912562 steps/s, speed: 7.300496 samples/s, speed: 3737.854152 tokens/s, learning rate: 2.694e-05, loss_scalings: 2814.750488, pp_loss: 7.244179
[INFO] 2021-07-12 19:26:57,355 [run_pretraining.py:  512]:	********exe.run_2695******* 
[INFO] 2021-07-12 19:26:58,448 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:58,448 [run_pretraining.py:  534]:	loss/total_loss, 7.0959978103637695, 2696
[INFO] 2021-07-12 19:26:58,448 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0959978103637695, 2696
[INFO] 2021-07-12 19:26:58,448 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.694999784580432e-05, 2696
[INFO] 2021-07-12 19:26:58,448 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2696
[INFO] 2021-07-12 19:26:58,448 [run_pretraining.py:  558]:	worker_index: 3, step: 2696, cost: 7.095998, mlm loss: 7.095998, speed: 0.914795 steps/s, speed: 7.318358 samples/s, speed: 3746.999528 tokens/s, learning rate: 2.695e-05, loss_scalings: 2814.750488, pp_loss: 7.213349
[INFO] 2021-07-12 19:26:58,449 [run_pretraining.py:  512]:	********exe.run_2696******* 
[INFO] 2021-07-12 19:26:59,529 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:59,530 [run_pretraining.py:  534]:	loss/total_loss, 7.378170967102051, 2697
[INFO] 2021-07-12 19:26:59,530 [run_pretraining.py:  535]:	loss/mlm_loss, 7.378170967102051, 2697
[INFO] 2021-07-12 19:26:59,530 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6960000468534417e-05, 2697
[INFO] 2021-07-12 19:26:59,530 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2697
[INFO] 2021-07-12 19:26:59,530 [run_pretraining.py:  558]:	worker_index: 3, step: 2697, cost: 7.378171, mlm loss: 7.378171, speed: 0.925247 steps/s, speed: 7.401976 samples/s, speed: 3789.811899 tokens/s, learning rate: 2.696e-05, loss_scalings: 2814.750488, pp_loss: 7.165955
[INFO] 2021-07-12 19:26:59,530 [run_pretraining.py:  512]:	********exe.run_2697******* 
[INFO] 2021-07-12 19:27:00,630 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:00,631 [run_pretraining.py:  534]:	loss/total_loss, 6.7987823486328125, 2698
[INFO] 2021-07-12 19:27:00,631 [run_pretraining.py:  535]:	loss/mlm_loss, 6.7987823486328125, 2698
[INFO] 2021-07-12 19:27:00,631 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6969997634296305e-05, 2698
[INFO] 2021-07-12 19:27:00,631 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2698
[INFO] 2021-07-12 19:27:00,631 [run_pretraining.py:  558]:	worker_index: 3, step: 2698, cost: 6.798782, mlm loss: 6.798782, speed: 0.908508 steps/s, speed: 7.268067 samples/s, speed: 3721.250077 tokens/s, learning rate: 2.697e-05, loss_scalings: 2814.750488, pp_loss: 6.864726
[INFO] 2021-07-12 19:27:00,631 [run_pretraining.py:  512]:	********exe.run_2698******* 
[INFO] 2021-07-12 19:27:01,726 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:01,726 [run_pretraining.py:  534]:	loss/total_loss, 6.8001861572265625, 2699
[INFO] 2021-07-12 19:27:01,726 [run_pretraining.py:  535]:	loss/mlm_loss, 6.8001861572265625, 2699
[INFO] 2021-07-12 19:27:01,726 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6980000257026404e-05, 2699
[INFO] 2021-07-12 19:27:01,726 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2699
[INFO] 2021-07-12 19:27:01,726 [run_pretraining.py:  558]:	worker_index: 3, step: 2699, cost: 6.800186, mlm loss: 6.800186, speed: 0.913648 steps/s, speed: 7.309182 samples/s, speed: 3742.301416 tokens/s, learning rate: 2.698e-05, loss_scalings: 2814.750488, pp_loss: 7.287819
[INFO] 2021-07-12 19:27:01,726 [run_pretraining.py:  512]:	********exe.run_2699******* 
[INFO] 2021-07-12 19:27:02,830 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:02,830 [run_pretraining.py:  534]:	loss/total_loss, 7.540798664093018, 2700
[INFO] 2021-07-12 19:27:02,831 [run_pretraining.py:  535]:	loss/mlm_loss, 7.540798664093018, 2700
[INFO] 2021-07-12 19:27:02,831 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6989999241777696e-05, 2700
[INFO] 2021-07-12 19:27:02,831 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2700
[INFO] 2021-07-12 19:27:02,831 [run_pretraining.py:  558]:	worker_index: 3, step: 2700, cost: 7.540799, mlm loss: 7.540799, speed: 0.905979 steps/s, speed: 7.247832 samples/s, speed: 3710.889921 tokens/s, learning rate: 2.699e-05, loss_scalings: 2814.750488, pp_loss: 7.344043
[INFO] 2021-07-12 19:27:02,831 [run_pretraining.py:  512]:	********exe.run_2700******* 
[INFO] 2021-07-12 19:27:03,937 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:03,937 [run_pretraining.py:  534]:	loss/total_loss, 7.5781049728393555, 2701
[INFO] 2021-07-12 19:27:03,937 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5781049728393555, 2701
[INFO] 2021-07-12 19:27:03,937 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.700000004551839e-05, 2701
[INFO] 2021-07-12 19:27:03,937 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2701
[INFO] 2021-07-12 19:27:03,938 [run_pretraining.py:  558]:	worker_index: 3, step: 2701, cost: 7.578105, mlm loss: 7.578105, speed: 0.904093 steps/s, speed: 7.232742 samples/s, speed: 3703.163768 tokens/s, learning rate: 2.700e-05, loss_scalings: 2814.750488, pp_loss: 7.118128
[INFO] 2021-07-12 19:27:03,938 [run_pretraining.py:  512]:	********exe.run_2701******* 
[INFO] 2021-07-12 19:27:05,027 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:05,027 [run_pretraining.py:  534]:	loss/total_loss, 6.961732387542725, 2702
[INFO] 2021-07-12 19:27:05,028 [run_pretraining.py:  535]:	loss/mlm_loss, 6.961732387542725, 2702
[INFO] 2021-07-12 19:27:05,028 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7009999030269682e-05, 2702
[INFO] 2021-07-12 19:27:05,028 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2702
[INFO] 2021-07-12 19:27:05,028 [run_pretraining.py:  558]:	worker_index: 3, step: 2702, cost: 6.961732, mlm loss: 6.961732, speed: 0.917755 steps/s, speed: 7.342042 samples/s, speed: 3759.125562 tokens/s, learning rate: 2.701e-05, loss_scalings: 2814.750488, pp_loss: 7.074740
[INFO] 2021-07-12 19:27:05,028 [run_pretraining.py:  512]:	********exe.run_2702******* 
[INFO] 2021-07-12 19:27:06,135 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:06,136 [run_pretraining.py:  534]:	loss/total_loss, 6.622408390045166, 2703
[INFO] 2021-07-12 19:27:06,136 [run_pretraining.py:  535]:	loss/mlm_loss, 6.622408390045166, 2703
[INFO] 2021-07-12 19:27:06,136 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7019999834010378e-05, 2703
[INFO] 2021-07-12 19:27:06,136 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2703
[INFO] 2021-07-12 19:27:06,136 [run_pretraining.py:  558]:	worker_index: 3, step: 2703, cost: 6.622408, mlm loss: 6.622408, speed: 0.902917 steps/s, speed: 7.223334 samples/s, speed: 3698.347159 tokens/s, learning rate: 2.702e-05, loss_scalings: 2814.750488, pp_loss: 7.397251
[INFO] 2021-07-12 19:27:06,136 [run_pretraining.py:  512]:	********exe.run_2703******* 
[INFO] 2021-07-12 19:27:07,232 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:07,232 [run_pretraining.py:  534]:	loss/total_loss, 7.502363681793213, 2704
[INFO] 2021-07-12 19:27:07,232 [run_pretraining.py:  535]:	loss/mlm_loss, 7.502363681793213, 2704
[INFO] 2021-07-12 19:27:07,232 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.702999881876167e-05, 2704
[INFO] 2021-07-12 19:27:07,232 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2704
[INFO] 2021-07-12 19:27:07,233 [run_pretraining.py:  558]:	worker_index: 3, step: 2704, cost: 7.502364, mlm loss: 7.502364, speed: 0.912426 steps/s, speed: 7.299405 samples/s, speed: 3737.295531 tokens/s, learning rate: 2.703e-05, loss_scalings: 2814.750488, pp_loss: 7.325059
[INFO] 2021-07-12 19:27:07,233 [run_pretraining.py:  512]:	********exe.run_2704******* 
[INFO] 2021-07-12 19:27:08,330 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:08,331 [run_pretraining.py:  534]:	loss/total_loss, 6.966192722320557, 2705
[INFO] 2021-07-12 19:27:08,331 [run_pretraining.py:  535]:	loss/mlm_loss, 6.966192722320557, 2705
[INFO] 2021-07-12 19:27:08,331 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.703999780351296e-05, 2705
[INFO] 2021-07-12 19:27:08,331 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2705
[INFO] 2021-07-12 19:27:08,331 [run_pretraining.py:  558]:	worker_index: 3, step: 2705, cost: 6.966193, mlm loss: 6.966193, speed: 0.910933 steps/s, speed: 7.287462 samples/s, speed: 3731.180349 tokens/s, learning rate: 2.704e-05, loss_scalings: 2814.750488, pp_loss: 7.286092
[INFO] 2021-07-12 19:27:08,331 [run_pretraining.py:  512]:	********exe.run_2705******* 
[INFO] 2021-07-12 19:27:09,434 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:09,434 [run_pretraining.py:  534]:	loss/total_loss, 7.810967922210693, 2706
[INFO] 2021-07-12 19:27:09,435 [run_pretraining.py:  535]:	loss/mlm_loss, 7.810967922210693, 2706
[INFO] 2021-07-12 19:27:09,435 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.705000042624306e-05, 2706
[INFO] 2021-07-12 19:27:09,435 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2706
[INFO] 2021-07-12 19:27:09,435 [run_pretraining.py:  558]:	worker_index: 3, step: 2706, cost: 7.810968, mlm loss: 7.810968, speed: 0.906463 steps/s, speed: 7.251707 samples/s, speed: 3712.874042 tokens/s, learning rate: 2.705e-05, loss_scalings: 2814.750488, pp_loss: 7.158472
[INFO] 2021-07-12 19:27:09,435 [run_pretraining.py:  512]:	********exe.run_2706******* 
[INFO] 2021-07-12 19:27:10,530 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:10,530 [run_pretraining.py:  534]:	loss/total_loss, 6.817005157470703, 2707
[INFO] 2021-07-12 19:27:10,531 [run_pretraining.py:  535]:	loss/mlm_loss, 6.817005157470703, 2707
[INFO] 2021-07-12 19:27:10,531 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7059997592004947e-05, 2707
[INFO] 2021-07-12 19:27:10,531 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2707
[INFO] 2021-07-12 19:27:10,531 [run_pretraining.py:  558]:	worker_index: 3, step: 2707, cost: 6.817005, mlm loss: 6.817005, speed: 0.912910 steps/s, speed: 7.303277 samples/s, speed: 3739.277884 tokens/s, learning rate: 2.706e-05, loss_scalings: 2814.750488, pp_loss: 6.968852
[INFO] 2021-07-12 19:27:10,531 [run_pretraining.py:  512]:	********exe.run_2707******* 
[INFO] 2021-07-12 19:27:11,618 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:11,618 [run_pretraining.py:  534]:	loss/total_loss, 7.569976806640625, 2708
[INFO] 2021-07-12 19:27:11,619 [run_pretraining.py:  535]:	loss/mlm_loss, 7.569976806640625, 2708
[INFO] 2021-07-12 19:27:11,619 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7070000214735046e-05, 2708
[INFO] 2021-07-12 19:27:11,619 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2708
[INFO] 2021-07-12 19:27:11,619 [run_pretraining.py:  558]:	worker_index: 3, step: 2708, cost: 7.569977, mlm loss: 7.569977, speed: 0.919651 steps/s, speed: 7.357207 samples/s, speed: 3766.889835 tokens/s, learning rate: 2.707e-05, loss_scalings: 2814.750488, pp_loss: 7.591889
[INFO] 2021-07-12 19:27:11,619 [run_pretraining.py:  512]:	********exe.run_2708******* 
[INFO] 2021-07-12 19:27:12,716 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:12,716 [run_pretraining.py:  534]:	loss/total_loss, 7.7934417724609375, 2709
[INFO] 2021-07-12 19:27:12,716 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7934417724609375, 2709
[INFO] 2021-07-12 19:27:12,716 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7079999199486338e-05, 2709
[INFO] 2021-07-12 19:27:12,716 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2709
[INFO] 2021-07-12 19:27:12,716 [run_pretraining.py:  558]:	worker_index: 3, step: 2709, cost: 7.793442, mlm loss: 7.793442, speed: 0.911625 steps/s, speed: 7.293004 samples/s, speed: 3734.017920 tokens/s, learning rate: 2.708e-05, loss_scalings: 2814.750488, pp_loss: 7.316710
[INFO] 2021-07-12 19:27:12,716 [run_pretraining.py:  512]:	********exe.run_2709******* 
[INFO] 2021-07-12 19:27:13,807 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:13,807 [run_pretraining.py:  534]:	loss/total_loss, 6.931549072265625, 2710
[INFO] 2021-07-12 19:27:13,807 [run_pretraining.py:  535]:	loss/mlm_loss, 6.931549072265625, 2710
[INFO] 2021-07-12 19:27:13,807 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7090000003227033e-05, 2710
[INFO] 2021-07-12 19:27:13,808 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2710
[INFO] 2021-07-12 19:27:13,808 [run_pretraining.py:  558]:	worker_index: 3, step: 2710, cost: 6.931549, mlm loss: 6.931549, speed: 0.916954 steps/s, speed: 7.335633 samples/s, speed: 3755.844051 tokens/s, learning rate: 2.709e-05, loss_scalings: 2814.750488, pp_loss: 7.200943
[INFO] 2021-07-12 19:27:13,808 [run_pretraining.py:  512]:	********exe.run_2710******* 
[INFO] 2021-07-12 19:27:14,777 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:14,778 [run_pretraining.py:  534]:	loss/total_loss, 7.362499713897705, 2711
[INFO] 2021-07-12 19:27:14,778 [run_pretraining.py:  535]:	loss/mlm_loss, 7.362499713897705, 2711
[INFO] 2021-07-12 19:27:14,778 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7099998987978324e-05, 2711
[INFO] 2021-07-12 19:27:14,778 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2711
[INFO] 2021-07-12 19:27:14,778 [run_pretraining.py:  558]:	worker_index: 3, step: 2711, cost: 7.362500, mlm loss: 7.362500, speed: 1.030877 steps/s, speed: 8.247019 samples/s, speed: 4222.473755 tokens/s, learning rate: 2.710e-05, loss_scalings: 2814.750488, pp_loss: 7.443851
[INFO] 2021-07-12 19:27:14,778 [run_pretraining.py:  512]:	********exe.run_2711******* 
[INFO] 2021-07-12 19:27:15,703 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:15,704 [run_pretraining.py:  534]:	loss/total_loss, 7.429912090301514, 2712
[INFO] 2021-07-12 19:27:15,704 [run_pretraining.py:  535]:	loss/mlm_loss, 7.429912090301514, 2712
[INFO] 2021-07-12 19:27:15,704 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7110001610708423e-05, 2712
[INFO] 2021-07-12 19:27:15,704 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2712
[INFO] 2021-07-12 19:27:15,704 [run_pretraining.py:  558]:	worker_index: 3, step: 2712, cost: 7.429912, mlm loss: 7.429912, speed: 1.080859 steps/s, speed: 8.646868 samples/s, speed: 4427.196590 tokens/s, learning rate: 2.711e-05, loss_scalings: 2814.750488, pp_loss: 7.455099
[INFO] 2021-07-12 19:27:15,704 [run_pretraining.py:  512]:	********exe.run_2712******* 
[INFO] 2021-07-12 19:27:16,620 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:16,621 [run_pretraining.py:  534]:	loss/total_loss, 7.458662509918213, 2713
[INFO] 2021-07-12 19:27:16,621 [run_pretraining.py:  535]:	loss/mlm_loss, 7.458662509918213, 2713
[INFO] 2021-07-12 19:27:16,621 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.711999877647031e-05, 2713
[INFO] 2021-07-12 19:27:16,621 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2713
[INFO] 2021-07-12 19:27:16,621 [run_pretraining.py:  558]:	worker_index: 3, step: 2713, cost: 7.458663, mlm loss: 7.458663, speed: 1.091474 steps/s, speed: 8.731796 samples/s, speed: 4470.679531 tokens/s, learning rate: 2.712e-05, loss_scalings: 2814.750488, pp_loss: 7.185154
[INFO] 2021-07-12 19:27:16,621 [run_pretraining.py:  512]:	********exe.run_2713******* 
[INFO] 2021-07-12 19:27:17,545 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:17,545 [run_pretraining.py:  534]:	loss/total_loss, 7.038813591003418, 2714
[INFO] 2021-07-12 19:27:17,546 [run_pretraining.py:  535]:	loss/mlm_loss, 7.038813591003418, 2714
[INFO] 2021-07-12 19:27:17,546 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7129997761221603e-05, 2714
[INFO] 2021-07-12 19:27:17,546 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2714
[INFO] 2021-07-12 19:27:17,546 [run_pretraining.py:  558]:	worker_index: 3, step: 2714, cost: 7.038814, mlm loss: 7.038814, speed: 1.082015 steps/s, speed: 8.656119 samples/s, speed: 4431.932857 tokens/s, learning rate: 2.713e-05, loss_scalings: 2814.750488, pp_loss: 6.746511
[INFO] 2021-07-12 19:27:17,546 [run_pretraining.py:  512]:	********exe.run_2714******* 
[INFO] 2021-07-12 19:27:18,462 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:18,463 [run_pretraining.py:  534]:	loss/total_loss, 7.63924503326416, 2715
[INFO] 2021-07-12 19:27:18,463 [run_pretraining.py:  535]:	loss/mlm_loss, 7.63924503326416, 2715
[INFO] 2021-07-12 19:27:18,463 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.71400003839517e-05, 2715
[INFO] 2021-07-12 19:27:18,463 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2715
[INFO] 2021-07-12 19:27:18,463 [run_pretraining.py:  558]:	worker_index: 3, step: 2715, cost: 7.639245, mlm loss: 7.639245, speed: 1.091035 steps/s, speed: 8.728278 samples/s, speed: 4468.878158 tokens/s, learning rate: 2.714e-05, loss_scalings: 2814.750488, pp_loss: 7.504352
[INFO] 2021-07-12 19:27:18,463 [run_pretraining.py:  512]:	********exe.run_2715******* 
[INFO] 2021-07-12 19:27:19,383 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:19,383 [run_pretraining.py:  534]:	loss/total_loss, 6.8712921142578125, 2716
[INFO] 2021-07-12 19:27:19,383 [run_pretraining.py:  535]:	loss/mlm_loss, 6.8712921142578125, 2716
[INFO] 2021-07-12 19:27:19,383 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.714999754971359e-05, 2716
[INFO] 2021-07-12 19:27:19,384 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2716
[INFO] 2021-07-12 19:27:19,384 [run_pretraining.py:  558]:	worker_index: 3, step: 2716, cost: 6.871292, mlm loss: 6.871292, speed: 1.086981 steps/s, speed: 8.695848 samples/s, speed: 4452.273925 tokens/s, learning rate: 2.715e-05, loss_scalings: 2814.750488, pp_loss: 6.482534
[INFO] 2021-07-12 19:27:19,384 [run_pretraining.py:  512]:	********exe.run_2716******* 
[INFO] 2021-07-12 19:27:20,318 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:20,319 [run_pretraining.py:  534]:	loss/total_loss, 6.829022407531738, 2717
[INFO] 2021-07-12 19:27:20,321 [run_pretraining.py:  535]:	loss/mlm_loss, 6.829022407531738, 2717
[INFO] 2021-07-12 19:27:20,322 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7160000172443688e-05, 2717
[INFO] 2021-07-12 19:27:20,322 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2717
[INFO] 2021-07-12 19:27:20,324 [run_pretraining.py:  558]:	worker_index: 3, step: 2717, cost: 6.829022, mlm loss: 6.829022, speed: 1.069389 steps/s, speed: 8.555112 samples/s, speed: 4380.217275 tokens/s, learning rate: 2.716e-05, loss_scalings: 2814.750488, pp_loss: 7.000502
[INFO] 2021-07-12 19:27:20,324 [run_pretraining.py:  512]:	********exe.run_2717******* 
[INFO] 2021-07-12 19:27:21,247 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:21,248 [run_pretraining.py:  534]:	loss/total_loss, 7.4462080001831055, 2718
[INFO] 2021-07-12 19:27:21,248 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4462080001831055, 2718
[INFO] 2021-07-12 19:27:21,248 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.716999915719498e-05, 2718
[INFO] 2021-07-12 19:27:21,248 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2718
[INFO] 2021-07-12 19:27:21,248 [run_pretraining.py:  558]:	worker_index: 3, step: 2718, cost: 7.446208, mlm loss: 7.446208, speed: 1.083508 steps/s, speed: 8.668062 samples/s, speed: 4438.047736 tokens/s, learning rate: 2.717e-05, loss_scalings: 2814.750488, pp_loss: 6.914945
[INFO] 2021-07-12 19:27:21,248 [run_pretraining.py:  512]:	********exe.run_2718******* 
[INFO] 2021-07-12 19:27:22,171 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:22,172 [run_pretraining.py:  534]:	loss/total_loss, 7.328101634979248, 2719
[INFO] 2021-07-12 19:27:22,172 [run_pretraining.py:  535]:	loss/mlm_loss, 7.328101634979248, 2719
[INFO] 2021-07-12 19:27:22,172 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7179999960935675e-05, 2719
[INFO] 2021-07-12 19:27:22,172 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2719
[INFO] 2021-07-12 19:27:22,172 [run_pretraining.py:  558]:	worker_index: 3, step: 2719, cost: 7.328102, mlm loss: 7.328102, speed: 1.082507 steps/s, speed: 8.660055 samples/s, speed: 4433.948297 tokens/s, learning rate: 2.718e-05, loss_scalings: 2814.750488, pp_loss: 7.270349
[INFO] 2021-07-12 19:27:22,172 [run_pretraining.py:  512]:	********exe.run_2719******* 
[INFO] 2021-07-12 19:27:23,097 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:23,098 [run_pretraining.py:  534]:	loss/total_loss, 7.308030605316162, 2720
[INFO] 2021-07-12 19:27:23,098 [run_pretraining.py:  535]:	loss/mlm_loss, 7.308030605316162, 2720
[INFO] 2021-07-12 19:27:23,098 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7189998945686966e-05, 2720
[INFO] 2021-07-12 19:27:23,098 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2720
[INFO] 2021-07-12 19:27:23,098 [run_pretraining.py:  558]:	worker_index: 3, step: 2720, cost: 7.308031, mlm loss: 7.308031, speed: 1.081190 steps/s, speed: 8.649521 samples/s, speed: 4428.554647 tokens/s, learning rate: 2.719e-05, loss_scalings: 2814.750488, pp_loss: 7.270854
[INFO] 2021-07-12 19:27:23,098 [run_pretraining.py:  512]:	********exe.run_2720******* 
[INFO] 2021-07-12 19:27:24,020 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:24,021 [run_pretraining.py:  534]:	loss/total_loss, 5.066709041595459, 2721
[INFO] 2021-07-12 19:27:24,021 [run_pretraining.py:  535]:	loss/mlm_loss, 5.066709041595459, 2721
[INFO] 2021-07-12 19:27:24,021 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7200001568417065e-05, 2721
[INFO] 2021-07-12 19:27:24,021 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2721
[INFO] 2021-07-12 19:27:24,021 [run_pretraining.py:  558]:	worker_index: 3, step: 2721, cost: 5.066709, mlm loss: 5.066709, speed: 1.084171 steps/s, speed: 8.673370 samples/s, speed: 4440.765395 tokens/s, learning rate: 2.720e-05, loss_scalings: 2814.750488, pp_loss: 6.577474
[INFO] 2021-07-12 19:27:24,021 [run_pretraining.py:  512]:	********exe.run_2721******* 
[INFO] 2021-07-12 19:27:24,944 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:24,945 [run_pretraining.py:  534]:	loss/total_loss, 7.602686882019043, 2722
[INFO] 2021-07-12 19:27:24,945 [run_pretraining.py:  535]:	loss/mlm_loss, 7.602686882019043, 2722
[INFO] 2021-07-12 19:27:24,945 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7209998734178953e-05, 2722
[INFO] 2021-07-12 19:27:24,945 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2722
[INFO] 2021-07-12 19:27:24,945 [run_pretraining.py:  558]:	worker_index: 3, step: 2722, cost: 7.602687, mlm loss: 7.602687, speed: 1.082374 steps/s, speed: 8.658996 samples/s, speed: 4433.405938 tokens/s, learning rate: 2.721e-05, loss_scalings: 2814.750488, pp_loss: 7.084927
[INFO] 2021-07-12 19:27:24,945 [run_pretraining.py:  512]:	********exe.run_2722******* 
[INFO] 2021-07-12 19:27:25,871 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:25,871 [run_pretraining.py:  534]:	loss/total_loss, 7.137617111206055, 2723
[INFO] 2021-07-12 19:27:25,871 [run_pretraining.py:  535]:	loss/mlm_loss, 7.137617111206055, 2723
[INFO] 2021-07-12 19:27:25,871 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7219997718930244e-05, 2723
[INFO] 2021-07-12 19:27:25,871 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2723
[INFO] 2021-07-12 19:27:25,871 [run_pretraining.py:  558]:	worker_index: 3, step: 2723, cost: 7.137617, mlm loss: 7.137617, speed: 1.080546 steps/s, speed: 8.644369 samples/s, speed: 4425.916899 tokens/s, learning rate: 2.722e-05, loss_scalings: 2814.750488, pp_loss: 7.249239
[INFO] 2021-07-12 19:27:25,872 [run_pretraining.py:  512]:	********exe.run_2723******* 
[INFO] 2021-07-12 19:27:26,800 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:26,800 [run_pretraining.py:  534]:	loss/total_loss, 6.82744836807251, 2724
[INFO] 2021-07-12 19:27:26,800 [run_pretraining.py:  535]:	loss/mlm_loss, 6.82744836807251, 2724
[INFO] 2021-07-12 19:27:26,800 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7230000341660343e-05, 2724
[INFO] 2021-07-12 19:27:26,800 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2724
[INFO] 2021-07-12 19:27:26,800 [run_pretraining.py:  558]:	worker_index: 3, step: 2724, cost: 6.827448, mlm loss: 6.827448, speed: 1.077202 steps/s, speed: 8.617615 samples/s, speed: 4412.218699 tokens/s, learning rate: 2.723e-05, loss_scalings: 2814.750488, pp_loss: 7.036930
[INFO] 2021-07-12 19:27:26,801 [run_pretraining.py:  512]:	********exe.run_2724******* 
[INFO] 2021-07-12 19:27:27,722 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:27,723 [run_pretraining.py:  534]:	loss/total_loss, 7.455557823181152, 2725
[INFO] 2021-07-12 19:27:27,723 [run_pretraining.py:  535]:	loss/mlm_loss, 7.455557823181152, 2725
[INFO] 2021-07-12 19:27:27,723 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7239999326411635e-05, 2725
[INFO] 2021-07-12 19:27:27,723 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2725
[INFO] 2021-07-12 19:27:27,723 [run_pretraining.py:  558]:	worker_index: 3, step: 2725, cost: 7.455558, mlm loss: 7.455558, speed: 1.084435 steps/s, speed: 8.675478 samples/s, speed: 4441.844663 tokens/s, learning rate: 2.724e-05, loss_scalings: 2814.750488, pp_loss: 7.518417
[INFO] 2021-07-12 19:27:27,723 [run_pretraining.py:  512]:	********exe.run_2725******* 
[INFO] 2021-07-12 19:27:28,663 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:28,664 [run_pretraining.py:  534]:	loss/total_loss, 7.448949337005615, 2726
[INFO] 2021-07-12 19:27:28,664 [run_pretraining.py:  535]:	loss/mlm_loss, 7.448949337005615, 2726
[INFO] 2021-07-12 19:27:28,664 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.725000013015233e-05, 2726
[INFO] 2021-07-12 19:27:28,664 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2726
[INFO] 2021-07-12 19:27:28,664 [run_pretraining.py:  558]:	worker_index: 3, step: 2726, cost: 7.448949, mlm loss: 7.448949, speed: 1.063796 steps/s, speed: 8.510368 samples/s, speed: 4357.308397 tokens/s, learning rate: 2.725e-05, loss_scalings: 2814.750488, pp_loss: 6.284635
[INFO] 2021-07-12 19:27:28,664 [run_pretraining.py:  512]:	********exe.run_2726******* 
[INFO] 2021-07-12 19:27:29,586 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:29,587 [run_pretraining.py:  534]:	loss/total_loss, 7.865614414215088, 2727
[INFO] 2021-07-12 19:27:29,587 [run_pretraining.py:  535]:	loss/mlm_loss, 7.865614414215088, 2727
[INFO] 2021-07-12 19:27:29,587 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.725999911490362e-05, 2727
[INFO] 2021-07-12 19:27:29,587 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2727
[INFO] 2021-07-12 19:27:29,587 [run_pretraining.py:  558]:	worker_index: 3, step: 2727, cost: 7.865614, mlm loss: 7.865614, speed: 1.084212 steps/s, speed: 8.673695 samples/s, speed: 4440.931844 tokens/s, learning rate: 2.726e-05, loss_scalings: 2814.750488, pp_loss: 7.177161
[INFO] 2021-07-12 19:27:29,587 [run_pretraining.py:  512]:	********exe.run_2727******* 
[INFO] 2021-07-12 19:27:30,519 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:30,519 [run_pretraining.py:  534]:	loss/total_loss, 7.186399459838867, 2728
[INFO] 2021-07-12 19:27:30,519 [run_pretraining.py:  535]:	loss/mlm_loss, 7.186399459838867, 2728
[INFO] 2021-07-12 19:27:30,519 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7269999918644316e-05, 2728
[INFO] 2021-07-12 19:27:30,519 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2728
[INFO] 2021-07-12 19:27:30,519 [run_pretraining.py:  558]:	worker_index: 3, step: 2728, cost: 7.186399, mlm loss: 7.186399, speed: 1.072944 steps/s, speed: 8.583553 samples/s, speed: 4394.779327 tokens/s, learning rate: 2.727e-05, loss_scalings: 2814.750488, pp_loss: 7.522049
[INFO] 2021-07-12 19:27:30,520 [run_pretraining.py:  512]:	********exe.run_2728******* 
[INFO] 2021-07-12 19:27:31,457 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:31,458 [run_pretraining.py:  534]:	loss/total_loss, 7.056995391845703, 2729
[INFO] 2021-07-12 19:27:31,458 [run_pretraining.py:  535]:	loss/mlm_loss, 7.056995391845703, 2729
[INFO] 2021-07-12 19:27:31,458 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7279998903395608e-05, 2729
[INFO] 2021-07-12 19:27:31,458 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2729
[INFO] 2021-07-12 19:27:31,458 [run_pretraining.py:  558]:	worker_index: 3, step: 2729, cost: 7.056995, mlm loss: 7.056995, speed: 1.066438 steps/s, speed: 8.531506 samples/s, speed: 4368.131311 tokens/s, learning rate: 2.728e-05, loss_scalings: 2814.750488, pp_loss: 7.133287
[INFO] 2021-07-12 19:27:31,458 [run_pretraining.py:  512]:	********exe.run_2729******* 
[INFO] 2021-07-12 19:27:32,397 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:32,398 [run_pretraining.py:  534]:	loss/total_loss, 7.500054359436035, 2730
[INFO] 2021-07-12 19:27:32,398 [run_pretraining.py:  535]:	loss/mlm_loss, 7.500054359436035, 2730
[INFO] 2021-07-12 19:27:32,398 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.72899978881469e-05, 2730
[INFO] 2021-07-12 19:27:32,398 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2730
[INFO] 2021-07-12 19:27:32,398 [run_pretraining.py:  558]:	worker_index: 3, step: 2730, cost: 7.500054, mlm loss: 7.500054, speed: 1.064552 steps/s, speed: 8.516418 samples/s, speed: 4360.406090 tokens/s, learning rate: 2.729e-05, loss_scalings: 2814.750488, pp_loss: 7.664778
[INFO] 2021-07-12 19:27:32,398 [run_pretraining.py:  512]:	********exe.run_2730******* 
[INFO] 2021-07-12 19:27:33,345 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:33,345 [run_pretraining.py:  534]:	loss/total_loss, 7.176616191864014, 2731
[INFO] 2021-07-12 19:27:33,346 [run_pretraining.py:  535]:	loss/mlm_loss, 7.176616191864014, 2731
[INFO] 2021-07-12 19:27:33,346 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7299998691887595e-05, 2731
[INFO] 2021-07-12 19:27:33,346 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2731
[INFO] 2021-07-12 19:27:33,346 [run_pretraining.py:  558]:	worker_index: 3, step: 2731, cost: 7.176616, mlm loss: 7.176616, speed: 1.055571 steps/s, speed: 8.444568 samples/s, speed: 4323.618837 tokens/s, learning rate: 2.730e-05, loss_scalings: 2814.750488, pp_loss: 6.438453
[INFO] 2021-07-12 19:27:33,346 [run_pretraining.py:  512]:	********exe.run_2731******* 
[INFO] 2021-07-12 19:27:34,274 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:34,275 [run_pretraining.py:  534]:	loss/total_loss, 8.143680572509766, 2732
[INFO] 2021-07-12 19:27:34,275 [run_pretraining.py:  535]:	loss/mlm_loss, 8.143680572509766, 2732
[INFO] 2021-07-12 19:27:34,275 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7309997676638886e-05, 2732
[INFO] 2021-07-12 19:27:34,275 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2732
[INFO] 2021-07-12 19:27:34,275 [run_pretraining.py:  558]:	worker_index: 3, step: 2732, cost: 8.143681, mlm loss: 8.143681, speed: 1.077078 steps/s, speed: 8.616628 samples/s, speed: 4411.713364 tokens/s, learning rate: 2.731e-05, loss_scalings: 2814.750488, pp_loss: 7.781208
[INFO] 2021-07-12 19:27:34,275 [run_pretraining.py:  512]:	********exe.run_2732******* 
[INFO] 2021-07-12 19:27:35,212 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:35,213 [run_pretraining.py:  534]:	loss/total_loss, 6.8506388664245605, 2733
[INFO] 2021-07-12 19:27:35,213 [run_pretraining.py:  535]:	loss/mlm_loss, 6.8506388664245605, 2733
[INFO] 2021-07-12 19:27:35,213 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7320000299368985e-05, 2733
[INFO] 2021-07-12 19:27:35,213 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2733
[INFO] 2021-07-12 19:27:35,213 [run_pretraining.py:  558]:	worker_index: 3, step: 2733, cost: 6.850639, mlm loss: 6.850639, speed: 1.066392 steps/s, speed: 8.531140 samples/s, speed: 4367.943622 tokens/s, learning rate: 2.732e-05, loss_scalings: 2814.750488, pp_loss: 7.080250
[INFO] 2021-07-12 19:27:35,213 [run_pretraining.py:  512]:	********exe.run_2733******* 
[INFO] 2021-07-12 19:27:36,141 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:36,142 [run_pretraining.py:  534]:	loss/total_loss, 7.114675045013428, 2734
[INFO] 2021-07-12 19:27:36,142 [run_pretraining.py:  535]:	loss/mlm_loss, 7.114675045013428, 2734
[INFO] 2021-07-12 19:27:36,142 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7329999284120277e-05, 2734
[INFO] 2021-07-12 19:27:36,142 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2734
[INFO] 2021-07-12 19:27:36,142 [run_pretraining.py:  558]:	worker_index: 3, step: 2734, cost: 7.114675, mlm loss: 7.114675, speed: 1.077374 steps/s, speed: 8.618996 samples/s, speed: 4412.925909 tokens/s, learning rate: 2.733e-05, loss_scalings: 2814.750488, pp_loss: 7.460385
[INFO] 2021-07-12 19:27:36,142 [run_pretraining.py:  512]:	********exe.run_2734******* 
[INFO] 2021-07-12 19:27:37,071 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:37,071 [run_pretraining.py:  534]:	loss/total_loss, 7.187262058258057, 2735
[INFO] 2021-07-12 19:27:37,071 [run_pretraining.py:  535]:	loss/mlm_loss, 7.187262058258057, 2735
[INFO] 2021-07-12 19:27:37,071 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.734000008786097e-05, 2735
[INFO] 2021-07-12 19:27:37,071 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2735
[INFO] 2021-07-12 19:27:37,071 [run_pretraining.py:  558]:	worker_index: 3, step: 2735, cost: 7.187262, mlm loss: 7.187262, speed: 1.076733 steps/s, speed: 8.613867 samples/s, speed: 4410.299947 tokens/s, learning rate: 2.734e-05, loss_scalings: 2814.750488, pp_loss: 6.978672
[INFO] 2021-07-12 19:27:37,072 [run_pretraining.py:  512]:	********exe.run_2735******* 
[INFO] 2021-07-12 19:27:37,988 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:37,989 [run_pretraining.py:  534]:	loss/total_loss, 6.649174690246582, 2736
[INFO] 2021-07-12 19:27:37,989 [run_pretraining.py:  535]:	loss/mlm_loss, 6.649174690246582, 2736
[INFO] 2021-07-12 19:27:37,989 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7349999072612263e-05, 2736
[INFO] 2021-07-12 19:27:37,989 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2736
[INFO] 2021-07-12 19:27:37,989 [run_pretraining.py:  558]:	worker_index: 3, step: 2736, cost: 6.649175, mlm loss: 6.649175, speed: 1.090456 steps/s, speed: 8.723651 samples/s, speed: 4466.509164 tokens/s, learning rate: 2.735e-05, loss_scalings: 2814.750488, pp_loss: 7.121730
[INFO] 2021-07-12 19:27:37,989 [run_pretraining.py:  512]:	********exe.run_2736******* 
[INFO] 2021-07-12 19:27:38,914 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:38,915 [run_pretraining.py:  534]:	loss/total_loss, 7.225713729858398, 2737
[INFO] 2021-07-12 19:27:38,915 [run_pretraining.py:  535]:	loss/mlm_loss, 7.225713729858398, 2737
[INFO] 2021-07-12 19:27:38,915 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.735999987635296e-05, 2737
[INFO] 2021-07-12 19:27:38,915 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2737
[INFO] 2021-07-12 19:27:38,915 [run_pretraining.py:  558]:	worker_index: 3, step: 2737, cost: 7.225714, mlm loss: 7.225714, speed: 1.080695 steps/s, speed: 8.645556 samples/s, speed: 4426.524717 tokens/s, learning rate: 2.736e-05, loss_scalings: 2814.750488, pp_loss: 7.191058
[INFO] 2021-07-12 19:27:38,915 [run_pretraining.py:  512]:	********exe.run_2737******* 
[INFO] 2021-07-12 19:27:39,836 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:39,836 [run_pretraining.py:  534]:	loss/total_loss, 7.343259334564209, 2738
[INFO] 2021-07-12 19:27:39,837 [run_pretraining.py:  535]:	loss/mlm_loss, 7.343259334564209, 2738
[INFO] 2021-07-12 19:27:39,837 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.736999886110425e-05, 2738
[INFO] 2021-07-12 19:27:39,837 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2738
[INFO] 2021-07-12 19:27:39,837 [run_pretraining.py:  558]:	worker_index: 3, step: 2738, cost: 7.343259, mlm loss: 7.343259, speed: 1.085654 steps/s, speed: 8.685233 samples/s, speed: 4446.839079 tokens/s, learning rate: 2.737e-05, loss_scalings: 2814.750488, pp_loss: 7.420755
[INFO] 2021-07-12 19:27:39,837 [run_pretraining.py:  512]:	********exe.run_2738******* 
[INFO] 2021-07-12 19:27:40,763 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:40,763 [run_pretraining.py:  534]:	loss/total_loss, 7.5103020668029785, 2739
[INFO] 2021-07-12 19:27:40,763 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5103020668029785, 2739
[INFO] 2021-07-12 19:27:40,763 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.737999784585554e-05, 2739
[INFO] 2021-07-12 19:27:40,764 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2739
[INFO] 2021-07-12 19:27:40,764 [run_pretraining.py:  558]:	worker_index: 3, step: 2739, cost: 7.510302, mlm loss: 7.510302, speed: 1.079778 steps/s, speed: 8.638225 samples/s, speed: 4422.771004 tokens/s, learning rate: 2.738e-05, loss_scalings: 2814.750488, pp_loss: 6.232075
[INFO] 2021-07-12 19:27:40,764 [run_pretraining.py:  512]:	********exe.run_2739******* 
[INFO] 2021-07-12 19:27:41,688 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:41,688 [run_pretraining.py:  534]:	loss/total_loss, 7.128161907196045, 2740
[INFO] 2021-07-12 19:27:41,688 [run_pretraining.py:  535]:	loss/mlm_loss, 7.128161907196045, 2740
[INFO] 2021-07-12 19:27:41,688 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7389998649596237e-05, 2740
[INFO] 2021-07-12 19:27:41,688 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2740
[INFO] 2021-07-12 19:27:41,688 [run_pretraining.py:  558]:	worker_index: 3, step: 2740, cost: 7.128162, mlm loss: 7.128162, speed: 1.082013 steps/s, speed: 8.656105 samples/s, speed: 4431.925997 tokens/s, learning rate: 2.739e-05, loss_scalings: 2814.750488, pp_loss: 7.112957
[INFO] 2021-07-12 19:27:41,689 [run_pretraining.py:  512]:	********exe.run_2740******* 
[INFO] 2021-07-12 19:27:42,608 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:42,609 [run_pretraining.py:  534]:	loss/total_loss, 7.059505939483643, 2741
[INFO] 2021-07-12 19:27:42,609 [run_pretraining.py:  535]:	loss/mlm_loss, 7.059505939483643, 2741
[INFO] 2021-07-12 19:27:42,609 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7399997634347528e-05, 2741
[INFO] 2021-07-12 19:27:42,609 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2741
[INFO] 2021-07-12 19:27:42,609 [run_pretraining.py:  558]:	worker_index: 3, step: 2741, cost: 7.059506, mlm loss: 7.059506, speed: 1.086731 steps/s, speed: 8.693851 samples/s, speed: 4451.251862 tokens/s, learning rate: 2.740e-05, loss_scalings: 2814.750488, pp_loss: 7.612758
[INFO] 2021-07-12 19:27:42,609 [run_pretraining.py:  512]:	********exe.run_2741******* 
[INFO] 2021-07-12 19:27:43,534 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:43,534 [run_pretraining.py:  534]:	loss/total_loss, 7.209897518157959, 2742
[INFO] 2021-07-12 19:27:43,534 [run_pretraining.py:  535]:	loss/mlm_loss, 7.209897518157959, 2742
[INFO] 2021-07-12 19:27:43,534 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7410000257077627e-05, 2742
[INFO] 2021-07-12 19:27:43,534 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2742
[INFO] 2021-07-12 19:27:43,534 [run_pretraining.py:  558]:	worker_index: 3, step: 2742, cost: 7.209898, mlm loss: 7.209898, speed: 1.081591 steps/s, speed: 8.652730 samples/s, speed: 4430.197982 tokens/s, learning rate: 2.741e-05, loss_scalings: 2814.750488, pp_loss: 7.100102
[INFO] 2021-07-12 19:27:43,535 [run_pretraining.py:  512]:	********exe.run_2742******* 
[INFO] 2021-07-12 19:27:44,458 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:44,459 [run_pretraining.py:  534]:	loss/total_loss, 7.433925151824951, 2743
[INFO] 2021-07-12 19:27:44,459 [run_pretraining.py:  535]:	loss/mlm_loss, 7.433925151824951, 2743
[INFO] 2021-07-12 19:27:44,459 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.741999924182892e-05, 2743
[INFO] 2021-07-12 19:27:44,459 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2743
[INFO] 2021-07-12 19:27:44,459 [run_pretraining.py:  558]:	worker_index: 3, step: 2743, cost: 7.433925, mlm loss: 7.433925, speed: 1.081957 steps/s, speed: 8.655652 samples/s, speed: 4431.693917 tokens/s, learning rate: 2.742e-05, loss_scalings: 2814.750488, pp_loss: 7.512558
[INFO] 2021-07-12 19:27:44,459 [run_pretraining.py:  512]:	********exe.run_2743******* 
[INFO] 2021-07-12 19:27:45,382 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:45,382 [run_pretraining.py:  534]:	loss/total_loss, 7.622021675109863, 2744
[INFO] 2021-07-12 19:27:45,382 [run_pretraining.py:  535]:	loss/mlm_loss, 7.622021675109863, 2744
[INFO] 2021-07-12 19:27:45,382 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7430000045569614e-05, 2744
[INFO] 2021-07-12 19:27:45,382 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2744
[INFO] 2021-07-12 19:27:45,382 [run_pretraining.py:  558]:	worker_index: 3, step: 2744, cost: 7.622022, mlm loss: 7.622022, speed: 1.084101 steps/s, speed: 8.672807 samples/s, speed: 4440.477297 tokens/s, learning rate: 2.743e-05, loss_scalings: 2814.750488, pp_loss: 7.516950
[INFO] 2021-07-12 19:27:45,382 [run_pretraining.py:  512]:	********exe.run_2744******* 
[INFO] 2021-07-12 19:27:46,303 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:46,304 [run_pretraining.py:  534]:	loss/total_loss, 8.084651947021484, 2745
[INFO] 2021-07-12 19:27:46,304 [run_pretraining.py:  535]:	loss/mlm_loss, 8.084651947021484, 2745
[INFO] 2021-07-12 19:27:46,304 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7439999030320905e-05, 2745
[INFO] 2021-07-12 19:27:46,304 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2745
[INFO] 2021-07-12 19:27:46,304 [run_pretraining.py:  558]:	worker_index: 3, step: 2745, cost: 8.084652, mlm loss: 8.084652, speed: 1.085550 steps/s, speed: 8.684401 samples/s, speed: 4446.413243 tokens/s, learning rate: 2.744e-05, loss_scalings: 2814.750488, pp_loss: 7.533800
[INFO] 2021-07-12 19:27:46,304 [run_pretraining.py:  512]:	********exe.run_2745******* 
[INFO] 2021-07-12 19:27:47,226 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:47,226 [run_pretraining.py:  534]:	loss/total_loss, 7.86110782623291, 2746
[INFO] 2021-07-12 19:27:47,226 [run_pretraining.py:  535]:	loss/mlm_loss, 7.86110782623291, 2746
[INFO] 2021-07-12 19:27:47,226 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.74499998340616e-05, 2746
[INFO] 2021-07-12 19:27:47,226 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2746
[INFO] 2021-07-12 19:27:47,226 [run_pretraining.py:  558]:	worker_index: 3, step: 2746, cost: 7.861108, mlm loss: 7.861108, speed: 1.085112 steps/s, speed: 8.680896 samples/s, speed: 4444.618719 tokens/s, learning rate: 2.745e-05, loss_scalings: 2814.750488, pp_loss: 7.565189
[INFO] 2021-07-12 19:27:47,226 [run_pretraining.py:  512]:	********exe.run_2746******* 
[INFO] 2021-07-12 19:27:48,148 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:48,149 [run_pretraining.py:  534]:	loss/total_loss, 8.697591781616211, 2747
[INFO] 2021-07-12 19:27:48,149 [run_pretraining.py:  535]:	loss/mlm_loss, 8.697591781616211, 2747
[INFO] 2021-07-12 19:27:48,149 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7459998818812892e-05, 2747
[INFO] 2021-07-12 19:27:48,149 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2747
[INFO] 2021-07-12 19:27:48,149 [run_pretraining.py:  558]:	worker_index: 3, step: 2747, cost: 8.697592, mlm loss: 8.697592, speed: 1.084501 steps/s, speed: 8.676009 samples/s, speed: 4442.116859 tokens/s, learning rate: 2.746e-05, loss_scalings: 2814.750488, pp_loss: 7.784303
[INFO] 2021-07-12 19:27:48,149 [run_pretraining.py:  512]:	********exe.run_2747******* 
[INFO] 2021-07-12 19:27:49,083 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:49,084 [run_pretraining.py:  534]:	loss/total_loss, 9.216009140014648, 2748
[INFO] 2021-07-12 19:27:49,084 [run_pretraining.py:  535]:	loss/mlm_loss, 9.216009140014648, 2748
[INFO] 2021-07-12 19:27:49,084 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7469997803564183e-05, 2748
[INFO] 2021-07-12 19:27:49,084 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2748
[INFO] 2021-07-12 19:27:49,084 [run_pretraining.py:  558]:	worker_index: 3, step: 2748, cost: 9.216009, mlm loss: 9.216009, speed: 1.070260 steps/s, speed: 8.562082 samples/s, speed: 4383.786090 tokens/s, learning rate: 2.747e-05, loss_scalings: 2814.750488, pp_loss: 7.342393
[INFO] 2021-07-12 19:27:49,084 [run_pretraining.py:  512]:	********exe.run_2748******* 
[INFO] 2021-07-12 19:27:49,999 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:50,000 [run_pretraining.py:  534]:	loss/total_loss, 7.789517402648926, 2749
[INFO] 2021-07-12 19:27:50,000 [run_pretraining.py:  535]:	loss/mlm_loss, 7.789517402648926, 2749
[INFO] 2021-07-12 19:27:50,000 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7480000426294282e-05, 2749
[INFO] 2021-07-12 19:27:50,000 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2749
[INFO] 2021-07-12 19:27:50,000 [run_pretraining.py:  558]:	worker_index: 3, step: 2749, cost: 7.789517, mlm loss: 7.789517, speed: 1.092528 steps/s, speed: 8.740223 samples/s, speed: 4474.994070 tokens/s, learning rate: 2.748e-05, loss_scalings: 2814.750488, pp_loss: 7.282824
[INFO] 2021-07-12 19:27:50,000 [run_pretraining.py:  512]:	********exe.run_2749******* 
[INFO] 2021-07-12 19:27:50,929 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:50,929 [run_pretraining.py:  534]:	loss/total_loss, 7.3611297607421875, 2750
[INFO] 2021-07-12 19:27:50,930 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3611297607421875, 2750
[INFO] 2021-07-12 19:27:50,930 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.748999759205617e-05, 2750
[INFO] 2021-07-12 19:27:50,930 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2750
[INFO] 2021-07-12 19:27:50,930 [run_pretraining.py:  558]:	worker_index: 3, step: 2750, cost: 7.361130, mlm loss: 7.361130, speed: 1.076325 steps/s, speed: 8.610602 samples/s, speed: 4408.628348 tokens/s, learning rate: 2.749e-05, loss_scalings: 2814.750488, pp_loss: 7.423960
[INFO] 2021-07-12 19:27:50,930 [run_pretraining.py:  512]:	********exe.run_2750******* 
[INFO] 2021-07-12 19:27:51,851 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:51,851 [run_pretraining.py:  534]:	loss/total_loss, 7.256046295166016, 2751
[INFO] 2021-07-12 19:27:51,851 [run_pretraining.py:  535]:	loss/mlm_loss, 7.256046295166016, 2751
[INFO] 2021-07-12 19:27:51,851 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.750000021478627e-05, 2751
[INFO] 2021-07-12 19:27:51,851 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2751
[INFO] 2021-07-12 19:27:51,851 [run_pretraining.py:  558]:	worker_index: 3, step: 2751, cost: 7.256046, mlm loss: 7.256046, speed: 1.085744 steps/s, speed: 8.685952 samples/s, speed: 4447.207436 tokens/s, learning rate: 2.750e-05, loss_scalings: 2814.750488, pp_loss: 7.008292
[INFO] 2021-07-12 19:27:51,851 [run_pretraining.py:  512]:	********exe.run_2751******* 
[INFO] 2021-07-12 19:27:52,773 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:52,774 [run_pretraining.py:  534]:	loss/total_loss, 7.284414768218994, 2752
[INFO] 2021-07-12 19:27:52,774 [run_pretraining.py:  535]:	loss/mlm_loss, 7.284414768218994, 2752
[INFO] 2021-07-12 19:27:52,774 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.750999919953756e-05, 2752
[INFO] 2021-07-12 19:27:52,774 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2752
[INFO] 2021-07-12 19:27:52,774 [run_pretraining.py:  558]:	worker_index: 3, step: 2752, cost: 7.284415, mlm loss: 7.284415, speed: 1.084540 steps/s, speed: 8.676324 samples/s, speed: 4442.277666 tokens/s, learning rate: 2.751e-05, loss_scalings: 2814.750488, pp_loss: 7.384416
[INFO] 2021-07-12 19:27:52,774 [run_pretraining.py:  512]:	********exe.run_2752******* 
[INFO] 2021-07-12 19:27:53,693 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:53,694 [run_pretraining.py:  534]:	loss/total_loss, 7.417695045471191, 2753
[INFO] 2021-07-12 19:27:53,694 [run_pretraining.py:  535]:	loss/mlm_loss, 7.417695045471191, 2753
[INFO] 2021-07-12 19:27:53,694 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7520000003278255e-05, 2753
[INFO] 2021-07-12 19:27:53,694 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2753
[INFO] 2021-07-12 19:27:53,694 [run_pretraining.py:  558]:	worker_index: 3, step: 2753, cost: 7.417695, mlm loss: 7.417695, speed: 1.087495 steps/s, speed: 8.699962 samples/s, speed: 4454.380671 tokens/s, learning rate: 2.752e-05, loss_scalings: 2814.750488, pp_loss: 7.352056
[INFO] 2021-07-12 19:27:53,694 [run_pretraining.py:  512]:	********exe.run_2753******* 
[INFO] 2021-07-12 19:27:54,614 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:54,615 [run_pretraining.py:  534]:	loss/total_loss, 6.874349117279053, 2754
[INFO] 2021-07-12 19:27:54,615 [run_pretraining.py:  535]:	loss/mlm_loss, 6.874349117279053, 2754
[INFO] 2021-07-12 19:27:54,615 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7529998988029547e-05, 2754
[INFO] 2021-07-12 19:27:54,615 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2754
[INFO] 2021-07-12 19:27:54,615 [run_pretraining.py:  558]:	worker_index: 3, step: 2754, cost: 6.874349, mlm loss: 6.874349, speed: 1.086528 steps/s, speed: 8.692225 samples/s, speed: 4450.419331 tokens/s, learning rate: 2.753e-05, loss_scalings: 2814.750488, pp_loss: 7.308183
[INFO] 2021-07-12 19:27:54,615 [run_pretraining.py:  512]:	********exe.run_2754******* 
[INFO] 2021-07-12 19:27:55,538 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:55,539 [run_pretraining.py:  534]:	loss/total_loss, 6.669116020202637, 2755
[INFO] 2021-07-12 19:27:55,539 [run_pretraining.py:  535]:	loss/mlm_loss, 6.669116020202637, 2755
[INFO] 2021-07-12 19:27:55,539 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7539999791770242e-05, 2755
[INFO] 2021-07-12 19:27:55,539 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2755
[INFO] 2021-07-12 19:27:55,539 [run_pretraining.py:  558]:	worker_index: 3, step: 2755, cost: 6.669116, mlm loss: 6.669116, speed: 1.083081 steps/s, speed: 8.664649 samples/s, speed: 4436.300052 tokens/s, learning rate: 2.754e-05, loss_scalings: 2814.750488, pp_loss: 6.859005
[INFO] 2021-07-12 19:27:55,539 [run_pretraining.py:  512]:	********exe.run_2755******* 
[INFO] 2021-07-12 19:27:56,466 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:56,466 [run_pretraining.py:  534]:	loss/total_loss, 7.438436031341553, 2756
[INFO] 2021-07-12 19:27:56,466 [run_pretraining.py:  535]:	loss/mlm_loss, 7.438436031341553, 2756
[INFO] 2021-07-12 19:27:56,466 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7549998776521534e-05, 2756
[INFO] 2021-07-12 19:27:56,466 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2756
[INFO] 2021-07-12 19:27:56,467 [run_pretraining.py:  558]:	worker_index: 3, step: 2756, cost: 7.438436, mlm loss: 7.438436, speed: 1.079025 steps/s, speed: 8.632198 samples/s, speed: 4419.685290 tokens/s, learning rate: 2.755e-05, loss_scalings: 2814.750488, pp_loss: 7.362836
[INFO] 2021-07-12 19:27:56,467 [run_pretraining.py:  512]:	********exe.run_2756******* 
[INFO] 2021-07-12 19:27:57,392 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:57,392 [run_pretraining.py:  534]:	loss/total_loss, 6.798599720001221, 2757
[INFO] 2021-07-12 19:27:57,393 [run_pretraining.py:  535]:	loss/mlm_loss, 6.798599720001221, 2757
[INFO] 2021-07-12 19:27:57,393 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7559997761272825e-05, 2757
[INFO] 2021-07-12 19:27:57,393 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2757
[INFO] 2021-07-12 19:27:57,393 [run_pretraining.py:  558]:	worker_index: 3, step: 2757, cost: 6.798600, mlm loss: 6.798600, speed: 1.080427 steps/s, speed: 8.643414 samples/s, speed: 4425.427801 tokens/s, learning rate: 2.756e-05, loss_scalings: 2814.750488, pp_loss: 6.870193
[INFO] 2021-07-12 19:27:57,393 [run_pretraining.py:  512]:	********exe.run_2757******* 
[INFO] 2021-07-12 19:27:58,401 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:58,401 [run_pretraining.py:  534]:	loss/total_loss, 7.234216690063477, 2758
[INFO] 2021-07-12 19:27:58,401 [run_pretraining.py:  535]:	loss/mlm_loss, 7.234216690063477, 2758
[INFO] 2021-07-12 19:27:58,401 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7570000384002924e-05, 2758
[INFO] 2021-07-12 19:27:58,402 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2758
[INFO] 2021-07-12 19:27:58,402 [run_pretraining.py:  558]:	worker_index: 3, step: 2758, cost: 7.234217, mlm loss: 7.234217, speed: 0.991858 steps/s, speed: 7.934867 samples/s, speed: 4062.651670 tokens/s, learning rate: 2.757e-05, loss_scalings: 2814.750488, pp_loss: 7.547669
[INFO] 2021-07-12 19:27:58,402 [run_pretraining.py:  512]:	********exe.run_2758******* 
[INFO] 2021-07-12 19:27:59,473 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:59,474 [run_pretraining.py:  534]:	loss/total_loss, 7.34575080871582, 2759
[INFO] 2021-07-12 19:27:59,474 [run_pretraining.py:  535]:	loss/mlm_loss, 7.34575080871582, 2759
[INFO] 2021-07-12 19:27:59,474 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7579997549764812e-05, 2759
[INFO] 2021-07-12 19:27:59,474 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2759
[INFO] 2021-07-12 19:27:59,474 [run_pretraining.py:  558]:	worker_index: 3, step: 2759, cost: 7.345751, mlm loss: 7.345751, speed: 0.933154 steps/s, speed: 7.465228 samples/s, speed: 3822.196895 tokens/s, learning rate: 2.758e-05, loss_scalings: 2814.750488, pp_loss: 6.996270
[INFO] 2021-07-12 19:27:59,474 [run_pretraining.py:  512]:	********exe.run_2759******* 
[INFO] 2021-07-12 19:28:00,540 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:00,541 [run_pretraining.py:  534]:	loss/total_loss, 6.90630578994751, 2760
[INFO] 2021-07-12 19:28:00,541 [run_pretraining.py:  535]:	loss/mlm_loss, 6.90630578994751, 2760
[INFO] 2021-07-12 19:28:00,541 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.759000017249491e-05, 2760
[INFO] 2021-07-12 19:28:00,541 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2760
[INFO] 2021-07-12 19:28:00,541 [run_pretraining.py:  558]:	worker_index: 3, step: 2760, cost: 6.906306, mlm loss: 6.906306, speed: 0.937692 steps/s, speed: 7.501535 samples/s, speed: 3840.785740 tokens/s, learning rate: 2.759e-05, loss_scalings: 2814.750488, pp_loss: 7.142832
[INFO] 2021-07-12 19:28:00,541 [run_pretraining.py:  512]:	********exe.run_2760******* 
[INFO] 2021-07-12 19:28:01,603 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:01,604 [run_pretraining.py:  534]:	loss/total_loss, 6.918546199798584, 2761
[INFO] 2021-07-12 19:28:01,604 [run_pretraining.py:  535]:	loss/mlm_loss, 6.918546199798584, 2761
[INFO] 2021-07-12 19:28:01,604 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7599999157246202e-05, 2761
[INFO] 2021-07-12 19:28:01,604 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2761
[INFO] 2021-07-12 19:28:01,604 [run_pretraining.py:  558]:	worker_index: 3, step: 2761, cost: 6.918546, mlm loss: 6.918546, speed: 0.940986 steps/s, speed: 7.527888 samples/s, speed: 3854.278705 tokens/s, learning rate: 2.760e-05, loss_scalings: 2814.750488, pp_loss: 7.052619
[INFO] 2021-07-12 19:28:01,604 [run_pretraining.py:  512]:	********exe.run_2761******* 
[INFO] 2021-07-12 19:28:02,704 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:02,705 [run_pretraining.py:  534]:	loss/total_loss, 7.075273036956787, 2762
[INFO] 2021-07-12 19:28:02,705 [run_pretraining.py:  535]:	loss/mlm_loss, 7.075273036956787, 2762
[INFO] 2021-07-12 19:28:02,705 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7609999960986897e-05, 2762
[INFO] 2021-07-12 19:28:02,705 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2762
[INFO] 2021-07-12 19:28:02,705 [run_pretraining.py:  558]:	worker_index: 3, step: 2762, cost: 7.075273, mlm loss: 7.075273, speed: 0.909006 steps/s, speed: 7.272045 samples/s, speed: 3723.287255 tokens/s, learning rate: 2.761e-05, loss_scalings: 2814.750488, pp_loss: 7.255874
[INFO] 2021-07-12 19:28:02,705 [run_pretraining.py:  512]:	********exe.run_2762******* 
[INFO] 2021-07-12 19:28:03,771 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:03,772 [run_pretraining.py:  534]:	loss/total_loss, 7.13332462310791, 2763
[INFO] 2021-07-12 19:28:03,772 [run_pretraining.py:  535]:	loss/mlm_loss, 7.13332462310791, 2763
[INFO] 2021-07-12 19:28:03,772 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.761999894573819e-05, 2763
[INFO] 2021-07-12 19:28:03,772 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2763
[INFO] 2021-07-12 19:28:03,772 [run_pretraining.py:  558]:	worker_index: 3, step: 2763, cost: 7.133325, mlm loss: 7.133325, speed: 0.937693 steps/s, speed: 7.501541 samples/s, speed: 3840.789175 tokens/s, learning rate: 2.762e-05, loss_scalings: 2814.750488, pp_loss: 7.182262
[INFO] 2021-07-12 19:28:03,772 [run_pretraining.py:  512]:	********exe.run_2763******* 
[INFO] 2021-07-12 19:28:04,850 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:04,851 [run_pretraining.py:  534]:	loss/total_loss, 7.31538200378418, 2764
[INFO] 2021-07-12 19:28:04,851 [run_pretraining.py:  535]:	loss/mlm_loss, 7.31538200378418, 2764
[INFO] 2021-07-12 19:28:04,851 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7629999749478884e-05, 2764
[INFO] 2021-07-12 19:28:04,851 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2764
[INFO] 2021-07-12 19:28:04,851 [run_pretraining.py:  558]:	worker_index: 3, step: 2764, cost: 7.315382, mlm loss: 7.315382, speed: 0.927495 steps/s, speed: 7.419962 samples/s, speed: 3799.020381 tokens/s, learning rate: 2.763e-05, loss_scalings: 2814.750488, pp_loss: 7.457504
[INFO] 2021-07-12 19:28:04,851 [run_pretraining.py:  512]:	********exe.run_2764******* 
[INFO] 2021-07-12 19:28:05,913 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:05,914 [run_pretraining.py:  534]:	loss/total_loss, 7.16911506652832, 2765
[INFO] 2021-07-12 19:28:05,914 [run_pretraining.py:  535]:	loss/mlm_loss, 7.16911506652832, 2765
[INFO] 2021-07-12 19:28:05,914 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7639998734230176e-05, 2765
[INFO] 2021-07-12 19:28:05,914 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2765
[INFO] 2021-07-12 19:28:05,914 [run_pretraining.py:  558]:	worker_index: 3, step: 2765, cost: 7.169115, mlm loss: 7.169115, speed: 0.941005 steps/s, speed: 7.528043 samples/s, speed: 3854.358259 tokens/s, learning rate: 2.764e-05, loss_scalings: 2814.750488, pp_loss: 6.691942
[INFO] 2021-07-12 19:28:05,914 [run_pretraining.py:  512]:	********exe.run_2765******* 
[INFO] 2021-07-12 19:28:06,974 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:06,975 [run_pretraining.py:  534]:	loss/total_loss, 7.281914234161377, 2766
[INFO] 2021-07-12 19:28:06,975 [run_pretraining.py:  535]:	loss/mlm_loss, 7.281914234161377, 2766
[INFO] 2021-07-12 19:28:06,975 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7649997718981467e-05, 2766
[INFO] 2021-07-12 19:28:06,975 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2766
[INFO] 2021-07-12 19:28:06,975 [run_pretraining.py:  558]:	worker_index: 3, step: 2766, cost: 7.281914, mlm loss: 7.281914, speed: 0.943225 steps/s, speed: 7.545802 samples/s, speed: 3863.450754 tokens/s, learning rate: 2.765e-05, loss_scalings: 2814.750488, pp_loss: 7.252312
[INFO] 2021-07-12 19:28:06,975 [run_pretraining.py:  512]:	********exe.run_2766******* 
[INFO] 2021-07-12 19:28:08,033 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:08,034 [run_pretraining.py:  534]:	loss/total_loss, 7.3859639167785645, 2767
[INFO] 2021-07-12 19:28:08,034 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3859639167785645, 2767
[INFO] 2021-07-12 19:28:08,034 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7660000341711566e-05, 2767
[INFO] 2021-07-12 19:28:08,034 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2767
[INFO] 2021-07-12 19:28:08,034 [run_pretraining.py:  558]:	worker_index: 3, step: 2767, cost: 7.385964, mlm loss: 7.385964, speed: 0.944826 steps/s, speed: 7.558607 samples/s, speed: 3870.006698 tokens/s, learning rate: 2.766e-05, loss_scalings: 2814.750488, pp_loss: 7.398513
[INFO] 2021-07-12 19:28:08,034 [run_pretraining.py:  512]:	********exe.run_2767******* 
[INFO] 2021-07-12 19:28:09,103 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:09,104 [run_pretraining.py:  534]:	loss/total_loss, 7.299057483673096, 2768
[INFO] 2021-07-12 19:28:09,104 [run_pretraining.py:  535]:	loss/mlm_loss, 7.299057483673096, 2768
[INFO] 2021-07-12 19:28:09,104 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7669997507473454e-05, 2768
[INFO] 2021-07-12 19:28:09,104 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2768
[INFO] 2021-07-12 19:28:09,104 [run_pretraining.py:  558]:	worker_index: 3, step: 2768, cost: 7.299057, mlm loss: 7.299057, speed: 0.935259 steps/s, speed: 7.482071 samples/s, speed: 3830.820318 tokens/s, learning rate: 2.767e-05, loss_scalings: 2814.750488, pp_loss: 7.141962
[INFO] 2021-07-12 19:28:09,104 [run_pretraining.py:  512]:	********exe.run_2768******* 
[INFO] 2021-07-12 19:28:10,177 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:10,177 [run_pretraining.py:  534]:	loss/total_loss, 7.11996603012085, 2769
[INFO] 2021-07-12 19:28:10,177 [run_pretraining.py:  535]:	loss/mlm_loss, 7.11996603012085, 2769
[INFO] 2021-07-12 19:28:10,178 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7680000130203553e-05, 2769
[INFO] 2021-07-12 19:28:10,178 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2769
[INFO] 2021-07-12 19:28:10,178 [run_pretraining.py:  558]:	worker_index: 3, step: 2769, cost: 7.119966, mlm loss: 7.119966, speed: 0.931839 steps/s, speed: 7.454708 samples/s, speed: 3816.810620 tokens/s, learning rate: 2.768e-05, loss_scalings: 2814.750488, pp_loss: 7.082831
[INFO] 2021-07-12 19:28:10,178 [run_pretraining.py:  512]:	********exe.run_2769******* 
[INFO] 2021-07-12 19:28:11,236 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:11,237 [run_pretraining.py:  534]:	loss/total_loss, 7.719401836395264, 2770
[INFO] 2021-07-12 19:28:11,237 [run_pretraining.py:  535]:	loss/mlm_loss, 7.719401836395264, 2770
[INFO] 2021-07-12 19:28:11,237 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7689999114954844e-05, 2770
[INFO] 2021-07-12 19:28:11,237 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2770
[INFO] 2021-07-12 19:28:11,237 [run_pretraining.py:  558]:	worker_index: 3, step: 2770, cost: 7.719402, mlm loss: 7.719402, speed: 0.944318 steps/s, speed: 7.554541 samples/s, speed: 3867.925152 tokens/s, learning rate: 2.769e-05, loss_scalings: 2814.750488, pp_loss: 7.679816
[INFO] 2021-07-12 19:28:11,237 [run_pretraining.py:  512]:	********exe.run_2770******* 
[INFO] 2021-07-12 19:28:12,304 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:12,304 [run_pretraining.py:  534]:	loss/total_loss, 7.0140509605407715, 2771
[INFO] 2021-07-12 19:28:12,304 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0140509605407715, 2771
[INFO] 2021-07-12 19:28:12,305 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.769999991869554e-05, 2771
[INFO] 2021-07-12 19:28:12,305 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2771
[INFO] 2021-07-12 19:28:12,305 [run_pretraining.py:  558]:	worker_index: 3, step: 2771, cost: 7.014051, mlm loss: 7.014051, speed: 0.937408 steps/s, speed: 7.499265 samples/s, speed: 3839.623469 tokens/s, learning rate: 2.770e-05, loss_scalings: 2814.750488, pp_loss: 7.187962
[INFO] 2021-07-12 19:28:12,305 [run_pretraining.py:  512]:	********exe.run_2771******* 
[INFO] 2021-07-12 19:28:13,375 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:13,376 [run_pretraining.py:  534]:	loss/total_loss, 6.951833724975586, 2772
[INFO] 2021-07-12 19:28:13,376 [run_pretraining.py:  535]:	loss/mlm_loss, 6.951833724975586, 2772
[INFO] 2021-07-12 19:28:13,377 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.770999890344683e-05, 2772
[INFO] 2021-07-12 19:28:13,377 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2772
[INFO] 2021-07-12 19:28:13,377 [run_pretraining.py:  558]:	worker_index: 3, step: 2772, cost: 6.951834, mlm loss: 6.951834, speed: 0.933374 steps/s, speed: 7.466996 samples/s, speed: 3823.101900 tokens/s, learning rate: 2.771e-05, loss_scalings: 2814.750488, pp_loss: 7.312347
[INFO] 2021-07-12 19:28:13,377 [run_pretraining.py:  512]:	********exe.run_2772******* 
[INFO] 2021-07-12 19:28:14,432 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:14,433 [run_pretraining.py:  534]:	loss/total_loss, 6.9692792892456055, 2773
[INFO] 2021-07-12 19:28:14,433 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9692792892456055, 2773
[INFO] 2021-07-12 19:28:14,433 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.772000152617693e-05, 2773
[INFO] 2021-07-12 19:28:14,433 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2773
[INFO] 2021-07-12 19:28:14,433 [run_pretraining.py:  558]:	worker_index: 3, step: 2773, cost: 6.969279, mlm loss: 6.969279, speed: 0.947082 steps/s, speed: 7.576657 samples/s, speed: 3879.248591 tokens/s, learning rate: 2.772e-05, loss_scalings: 2814.750488, pp_loss: 7.265479
[INFO] 2021-07-12 19:28:14,433 [run_pretraining.py:  512]:	********exe.run_2773******* 
[INFO] 2021-07-12 19:28:15,481 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:15,481 [run_pretraining.py:  534]:	loss/total_loss, 6.8006768226623535, 2774
[INFO] 2021-07-12 19:28:15,481 [run_pretraining.py:  535]:	loss/mlm_loss, 6.8006768226623535, 2774
[INFO] 2021-07-12 19:28:15,481 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7729998691938818e-05, 2774
[INFO] 2021-07-12 19:28:15,481 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2774
[INFO] 2021-07-12 19:28:15,482 [run_pretraining.py:  558]:	worker_index: 3, step: 2774, cost: 6.800677, mlm loss: 6.800677, speed: 0.954485 steps/s, speed: 7.635882 samples/s, speed: 3909.571510 tokens/s, learning rate: 2.773e-05, loss_scalings: 2814.750488, pp_loss: 7.138080
[INFO] 2021-07-12 19:28:15,482 [run_pretraining.py:  512]:	********exe.run_2774******* 
[INFO] 2021-07-12 19:28:16,428 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:16,429 [run_pretraining.py:  534]:	loss/total_loss, 7.675276756286621, 2775
[INFO] 2021-07-12 19:28:16,429 [run_pretraining.py:  535]:	loss/mlm_loss, 7.675276756286621, 2775
[INFO] 2021-07-12 19:28:16,429 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.773999767669011e-05, 2775
[INFO] 2021-07-12 19:28:16,429 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2775
[INFO] 2021-07-12 19:28:16,429 [run_pretraining.py:  558]:	worker_index: 3, step: 2775, cost: 7.675277, mlm loss: 7.675277, speed: 1.055911 steps/s, speed: 8.447287 samples/s, speed: 4325.010985 tokens/s, learning rate: 2.774e-05, loss_scalings: 2814.750488, pp_loss: 7.142327
[INFO] 2021-07-12 19:28:16,429 [run_pretraining.py:  512]:	********exe.run_2775******* 
[INFO] 2021-07-12 19:28:17,354 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:17,354 [run_pretraining.py:  534]:	loss/total_loss, 7.203311443328857, 2776
[INFO] 2021-07-12 19:28:17,354 [run_pretraining.py:  535]:	loss/mlm_loss, 7.203311443328857, 2776
[INFO] 2021-07-12 19:28:17,354 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7750000299420208e-05, 2776
[INFO] 2021-07-12 19:28:17,354 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2776
[INFO] 2021-07-12 19:28:17,355 [run_pretraining.py:  558]:	worker_index: 3, step: 2776, cost: 7.203311, mlm loss: 7.203311, speed: 1.081375 steps/s, speed: 8.650999 samples/s, speed: 4429.311640 tokens/s, learning rate: 2.775e-05, loss_scalings: 2814.750488, pp_loss: 6.843264
[INFO] 2021-07-12 19:28:17,355 [run_pretraining.py:  512]:	********exe.run_2776******* 
[INFO] 2021-07-12 19:28:18,277 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:18,277 [run_pretraining.py:  534]:	loss/total_loss, 7.608614444732666, 2777
[INFO] 2021-07-12 19:28:18,277 [run_pretraining.py:  535]:	loss/mlm_loss, 7.608614444732666, 2777
[INFO] 2021-07-12 19:28:18,277 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7759997465182096e-05, 2777
[INFO] 2021-07-12 19:28:18,277 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2777
[INFO] 2021-07-12 19:28:18,277 [run_pretraining.py:  558]:	worker_index: 3, step: 2777, cost: 7.608614, mlm loss: 7.608614, speed: 1.084394 steps/s, speed: 8.675155 samples/s, speed: 4441.679294 tokens/s, learning rate: 2.776e-05, loss_scalings: 2814.750488, pp_loss: 7.725173
[INFO] 2021-07-12 19:28:18,277 [run_pretraining.py:  512]:	********exe.run_2777******* 
[INFO] 2021-07-12 19:28:19,199 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:19,199 [run_pretraining.py:  534]:	loss/total_loss, 6.670253753662109, 2778
[INFO] 2021-07-12 19:28:19,199 [run_pretraining.py:  535]:	loss/mlm_loss, 6.670253753662109, 2778
[INFO] 2021-07-12 19:28:19,199 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7770000087912194e-05, 2778
[INFO] 2021-07-12 19:28:19,200 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2778
[INFO] 2021-07-12 19:28:19,200 [run_pretraining.py:  558]:	worker_index: 3, step: 2778, cost: 6.670254, mlm loss: 6.670254, speed: 1.085133 steps/s, speed: 8.681062 samples/s, speed: 4444.703812 tokens/s, learning rate: 2.777e-05, loss_scalings: 2814.750488, pp_loss: 6.990741
[INFO] 2021-07-12 19:28:19,200 [run_pretraining.py:  512]:	********exe.run_2778******* 
[INFO] 2021-07-12 19:28:20,125 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:20,126 [run_pretraining.py:  534]:	loss/total_loss, 7.131524085998535, 2779
[INFO] 2021-07-12 19:28:20,126 [run_pretraining.py:  535]:	loss/mlm_loss, 7.131524085998535, 2779
[INFO] 2021-07-12 19:28:20,126 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7779999072663486e-05, 2779
[INFO] 2021-07-12 19:28:20,126 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2779
[INFO] 2021-07-12 19:28:20,126 [run_pretraining.py:  558]:	worker_index: 3, step: 2779, cost: 7.131524, mlm loss: 7.131524, speed: 1.079885 steps/s, speed: 8.639083 samples/s, speed: 4423.210545 tokens/s, learning rate: 2.778e-05, loss_scalings: 2814.750488, pp_loss: 7.085621
[INFO] 2021-07-12 19:28:20,126 [run_pretraining.py:  512]:	********exe.run_2779******* 
[INFO] 2021-07-12 19:28:21,045 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:21,046 [run_pretraining.py:  534]:	loss/total_loss, 7.2366790771484375, 2780
[INFO] 2021-07-12 19:28:21,046 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2366790771484375, 2780
[INFO] 2021-07-12 19:28:21,046 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.778999987640418e-05, 2780
[INFO] 2021-07-12 19:28:21,046 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2780
[INFO] 2021-07-12 19:28:21,046 [run_pretraining.py:  558]:	worker_index: 3, step: 2780, cost: 7.236679, mlm loss: 7.236679, speed: 1.088079 steps/s, speed: 8.704630 samples/s, speed: 4456.770343 tokens/s, learning rate: 2.779e-05, loss_scalings: 2814.750488, pp_loss: 6.689210
[INFO] 2021-07-12 19:28:21,046 [run_pretraining.py:  512]:	********exe.run_2780******* 
[INFO] 2021-07-12 19:28:21,965 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:21,966 [run_pretraining.py:  534]:	loss/total_loss, 7.805628776550293, 2781
[INFO] 2021-07-12 19:28:21,966 [run_pretraining.py:  535]:	loss/mlm_loss, 7.805628776550293, 2781
[INFO] 2021-07-12 19:28:21,966 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7799998861155473e-05, 2781
[INFO] 2021-07-12 19:28:21,966 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2781
[INFO] 2021-07-12 19:28:21,966 [run_pretraining.py:  558]:	worker_index: 3, step: 2781, cost: 7.805629, mlm loss: 7.805629, speed: 1.087539 steps/s, speed: 8.700310 samples/s, speed: 4454.558537 tokens/s, learning rate: 2.780e-05, loss_scalings: 2814.750488, pp_loss: 7.343960
[INFO] 2021-07-12 19:28:21,966 [run_pretraining.py:  512]:	********exe.run_2781******* 
[INFO] 2021-07-12 19:28:22,886 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:22,887 [run_pretraining.py:  534]:	loss/total_loss, 7.240412712097168, 2782
[INFO] 2021-07-12 19:28:22,887 [run_pretraining.py:  535]:	loss/mlm_loss, 7.240412712097168, 2782
[INFO] 2021-07-12 19:28:22,887 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.781000148388557e-05, 2782
[INFO] 2021-07-12 19:28:22,887 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2782
[INFO] 2021-07-12 19:28:22,887 [run_pretraining.py:  558]:	worker_index: 3, step: 2782, cost: 7.240413, mlm loss: 7.240413, speed: 1.086545 steps/s, speed: 8.692360 samples/s, speed: 4450.488504 tokens/s, learning rate: 2.781e-05, loss_scalings: 2814.750488, pp_loss: 7.298347
[INFO] 2021-07-12 19:28:22,887 [run_pretraining.py:  512]:	********exe.run_2782******* 
[INFO] 2021-07-12 19:28:23,810 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:23,810 [run_pretraining.py:  534]:	loss/total_loss, 6.906947135925293, 2783
[INFO] 2021-07-12 19:28:23,810 [run_pretraining.py:  535]:	loss/mlm_loss, 6.906947135925293, 2783
[INFO] 2021-07-12 19:28:23,810 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.781999864964746e-05, 2783
[INFO] 2021-07-12 19:28:23,810 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2783
[INFO] 2021-07-12 19:28:23,811 [run_pretraining.py:  558]:	worker_index: 3, step: 2783, cost: 6.906947, mlm loss: 6.906947, speed: 1.083561 steps/s, speed: 8.668492 samples/s, speed: 4438.267870 tokens/s, learning rate: 2.782e-05, loss_scalings: 2814.750488, pp_loss: 7.476875
[INFO] 2021-07-12 19:28:23,811 [run_pretraining.py:  512]:	********exe.run_2783******* 
[INFO] 2021-07-12 19:28:24,729 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:24,730 [run_pretraining.py:  534]:	loss/total_loss, 6.994298934936523, 2784
[INFO] 2021-07-12 19:28:24,730 [run_pretraining.py:  535]:	loss/mlm_loss, 6.994298934936523, 2784
[INFO] 2021-07-12 19:28:24,730 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.782999763439875e-05, 2784
[INFO] 2021-07-12 19:28:24,730 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2784
[INFO] 2021-07-12 19:28:24,730 [run_pretraining.py:  558]:	worker_index: 3, step: 2784, cost: 6.994299, mlm loss: 6.994299, speed: 1.088175 steps/s, speed: 8.705397 samples/s, speed: 4457.163475 tokens/s, learning rate: 2.783e-05, loss_scalings: 2814.750488, pp_loss: 7.208931
[INFO] 2021-07-12 19:28:24,730 [run_pretraining.py:  512]:	********exe.run_2784******* 
[INFO] 2021-07-12 19:28:25,657 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:25,657 [run_pretraining.py:  534]:	loss/total_loss, 7.300940990447998, 2785
[INFO] 2021-07-12 19:28:25,657 [run_pretraining.py:  535]:	loss/mlm_loss, 7.300940990447998, 2785
[INFO] 2021-07-12 19:28:25,657 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.784000025712885e-05, 2785
[INFO] 2021-07-12 19:28:25,657 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2785
[INFO] 2021-07-12 19:28:25,657 [run_pretraining.py:  558]:	worker_index: 3, step: 2785, cost: 7.300941, mlm loss: 7.300941, speed: 1.079164 steps/s, speed: 8.633315 samples/s, speed: 4420.257278 tokens/s, learning rate: 2.784e-05, loss_scalings: 2814.750488, pp_loss: 7.218863
[INFO] 2021-07-12 19:28:25,657 [run_pretraining.py:  512]:	********exe.run_2785******* 
[INFO] 2021-07-12 19:28:26,568 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:26,569 [run_pretraining.py:  534]:	loss/total_loss, 6.739912033081055, 2786
[INFO] 2021-07-12 19:28:26,569 [run_pretraining.py:  535]:	loss/mlm_loss, 6.739912033081055, 2786
[INFO] 2021-07-12 19:28:26,569 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.784999924188014e-05, 2786
[INFO] 2021-07-12 19:28:26,569 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2786
[INFO] 2021-07-12 19:28:26,569 [run_pretraining.py:  558]:	worker_index: 3, step: 2786, cost: 6.739912, mlm loss: 6.739912, speed: 1.097614 steps/s, speed: 8.780908 samples/s, speed: 4495.825023 tokens/s, learning rate: 2.785e-05, loss_scalings: 2814.750488, pp_loss: 7.056932
[INFO] 2021-07-12 19:28:26,569 [run_pretraining.py:  512]:	********exe.run_2786******* 
[INFO] 2021-07-12 19:28:27,488 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:27,488 [run_pretraining.py:  534]:	loss/total_loss, 7.551514625549316, 2787
[INFO] 2021-07-12 19:28:27,488 [run_pretraining.py:  535]:	loss/mlm_loss, 7.551514625549316, 2787
[INFO] 2021-07-12 19:28:27,489 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7860000045620836e-05, 2787
[INFO] 2021-07-12 19:28:27,489 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2787
[INFO] 2021-07-12 19:28:27,489 [run_pretraining.py:  558]:	worker_index: 3, step: 2787, cost: 7.551515, mlm loss: 7.551515, speed: 1.088275 steps/s, speed: 8.706199 samples/s, speed: 4457.574024 tokens/s, learning rate: 2.786e-05, loss_scalings: 2814.750488, pp_loss: 6.377161
[INFO] 2021-07-12 19:28:27,489 [run_pretraining.py:  512]:	********exe.run_2787******* 
[INFO] 2021-07-12 19:28:28,401 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:28,402 [run_pretraining.py:  534]:	loss/total_loss, 7.801064491271973, 2788
[INFO] 2021-07-12 19:28:28,402 [run_pretraining.py:  535]:	loss/mlm_loss, 7.801064491271973, 2788
[INFO] 2021-07-12 19:28:28,402 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7869999030372128e-05, 2788
[INFO] 2021-07-12 19:28:28,402 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2788
[INFO] 2021-07-12 19:28:28,402 [run_pretraining.py:  558]:	worker_index: 3, step: 2788, cost: 7.801064, mlm loss: 7.801064, speed: 1.095495 steps/s, speed: 8.763957 samples/s, speed: 4487.146157 tokens/s, learning rate: 2.787e-05, loss_scalings: 2814.750488, pp_loss: 7.259848
[INFO] 2021-07-12 19:28:28,402 [run_pretraining.py:  512]:	********exe.run_2788******* 
[INFO] 2021-07-12 19:28:29,321 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:29,322 [run_pretraining.py:  534]:	loss/total_loss, 7.711680889129639, 2789
[INFO] 2021-07-12 19:28:29,322 [run_pretraining.py:  535]:	loss/mlm_loss, 7.711680889129639, 2789
[INFO] 2021-07-12 19:28:29,322 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7879999834112823e-05, 2789
[INFO] 2021-07-12 19:28:29,322 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2789
[INFO] 2021-07-12 19:28:29,322 [run_pretraining.py:  558]:	worker_index: 3, step: 2789, cost: 7.711681, mlm loss: 7.711681, speed: 1.087502 steps/s, speed: 8.700016 samples/s, speed: 4454.408390 tokens/s, learning rate: 2.788e-05, loss_scalings: 2814.750488, pp_loss: 7.701128
[INFO] 2021-07-12 19:28:29,322 [run_pretraining.py:  512]:	********exe.run_2789******* 
[INFO] 2021-07-12 19:28:30,227 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:30,228 [run_pretraining.py:  534]:	loss/total_loss, 7.401135444641113, 2790
[INFO] 2021-07-12 19:28:30,228 [run_pretraining.py:  535]:	loss/mlm_loss, 7.401135444641113, 2790
[INFO] 2021-07-12 19:28:30,228 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7889998818864115e-05, 2790
[INFO] 2021-07-12 19:28:30,228 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2790
[INFO] 2021-07-12 19:28:30,228 [run_pretraining.py:  558]:	worker_index: 3, step: 2790, cost: 7.401135, mlm loss: 7.401135, speed: 1.104577 steps/s, speed: 8.836613 samples/s, speed: 4524.345982 tokens/s, learning rate: 2.789e-05, loss_scalings: 2814.750488, pp_loss: 7.438917
[INFO] 2021-07-12 19:28:30,228 [run_pretraining.py:  512]:	********exe.run_2790******* 
[INFO] 2021-07-12 19:28:31,192 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:31,193 [run_pretraining.py:  534]:	loss/total_loss, 7.58855676651001, 2791
[INFO] 2021-07-12 19:28:31,193 [run_pretraining.py:  535]:	loss/mlm_loss, 7.58855676651001, 2791
[INFO] 2021-07-12 19:28:31,193 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7900001441594213e-05, 2791
[INFO] 2021-07-12 19:28:31,193 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2791
[INFO] 2021-07-12 19:28:31,193 [run_pretraining.py:  558]:	worker_index: 3, step: 2791, cost: 7.588557, mlm loss: 7.588557, speed: 1.037056 steps/s, speed: 8.296451 samples/s, speed: 4247.782923 tokens/s, learning rate: 2.790e-05, loss_scalings: 2814.750488, pp_loss: 7.387674
[INFO] 2021-07-12 19:28:31,193 [run_pretraining.py:  512]:	********exe.run_2791******* 
[INFO] 2021-07-12 19:28:32,149 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:32,150 [run_pretraining.py:  534]:	loss/total_loss, 8.128866195678711, 2792
[INFO] 2021-07-12 19:28:32,150 [run_pretraining.py:  535]:	loss/mlm_loss, 8.128866195678711, 2792
[INFO] 2021-07-12 19:28:32,150 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.79099986073561e-05, 2792
[INFO] 2021-07-12 19:28:32,150 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2792
[INFO] 2021-07-12 19:28:32,150 [run_pretraining.py:  558]:	worker_index: 3, step: 2792, cost: 8.128866, mlm loss: 8.128866, speed: 1.045800 steps/s, speed: 8.366404 samples/s, speed: 4283.598625 tokens/s, learning rate: 2.791e-05, loss_scalings: 2814.750488, pp_loss: 7.822888
[INFO] 2021-07-12 19:28:32,150 [run_pretraining.py:  512]:	********exe.run_2792******* 
[INFO] 2021-07-12 19:28:33,076 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:33,076 [run_pretraining.py:  534]:	loss/total_loss, 7.463884353637695, 2793
[INFO] 2021-07-12 19:28:33,076 [run_pretraining.py:  535]:	loss/mlm_loss, 7.463884353637695, 2793
[INFO] 2021-07-12 19:28:33,076 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7919997592107393e-05, 2793
[INFO] 2021-07-12 19:28:33,076 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2793
[INFO] 2021-07-12 19:28:33,076 [run_pretraining.py:  558]:	worker_index: 3, step: 2793, cost: 7.463884, mlm loss: 7.463884, speed: 1.080098 steps/s, speed: 8.640787 samples/s, speed: 4424.083054 tokens/s, learning rate: 2.792e-05, loss_scalings: 2814.750488, pp_loss: 7.433673
[INFO] 2021-07-12 19:28:33,077 [run_pretraining.py:  512]:	********exe.run_2793******* 
[INFO] 2021-07-12 19:28:33,994 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:33,995 [run_pretraining.py:  534]:	loss/total_loss, 8.439618110656738, 2794
[INFO] 2021-07-12 19:28:33,995 [run_pretraining.py:  535]:	loss/mlm_loss, 8.439618110656738, 2794
[INFO] 2021-07-12 19:28:33,995 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.793000021483749e-05, 2794
[INFO] 2021-07-12 19:28:33,995 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2794
[INFO] 2021-07-12 19:28:33,995 [run_pretraining.py:  558]:	worker_index: 3, step: 2794, cost: 8.439618, mlm loss: 8.439618, speed: 1.089547 steps/s, speed: 8.716376 samples/s, speed: 4462.784738 tokens/s, learning rate: 2.793e-05, loss_scalings: 2814.750488, pp_loss: 7.841593
[INFO] 2021-07-12 19:28:33,995 [run_pretraining.py:  512]:	********exe.run_2794******* 
[INFO] 2021-07-12 19:28:34,912 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:34,912 [run_pretraining.py:  534]:	loss/total_loss, 6.96851110458374, 2795
[INFO] 2021-07-12 19:28:34,912 [run_pretraining.py:  535]:	loss/mlm_loss, 6.96851110458374, 2795
[INFO] 2021-07-12 19:28:34,912 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7939999199588783e-05, 2795
[INFO] 2021-07-12 19:28:34,912 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2795
[INFO] 2021-07-12 19:28:34,912 [run_pretraining.py:  558]:	worker_index: 3, step: 2795, cost: 6.968511, mlm loss: 6.968511, speed: 1.090626 steps/s, speed: 8.725005 samples/s, speed: 4467.202523 tokens/s, learning rate: 2.794e-05, loss_scalings: 2814.750488, pp_loss: 7.391320
[INFO] 2021-07-12 19:28:34,913 [run_pretraining.py:  512]:	********exe.run_2795******* 
[INFO] 2021-07-12 19:28:35,838 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:35,838 [run_pretraining.py:  534]:	loss/total_loss, 7.798669338226318, 2796
[INFO] 2021-07-12 19:28:35,838 [run_pretraining.py:  535]:	loss/mlm_loss, 7.798669338226318, 2796
[INFO] 2021-07-12 19:28:35,839 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7950000003329478e-05, 2796
[INFO] 2021-07-12 19:28:35,839 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2796
[INFO] 2021-07-12 19:28:35,839 [run_pretraining.py:  558]:	worker_index: 3, step: 2796, cost: 7.798669, mlm loss: 7.798669, speed: 1.080302 steps/s, speed: 8.642419 samples/s, speed: 4424.918297 tokens/s, learning rate: 2.795e-05, loss_scalings: 2814.750488, pp_loss: 7.747588
[INFO] 2021-07-12 19:28:35,839 [run_pretraining.py:  512]:	********exe.run_2796******* 
[INFO] 2021-07-12 19:28:36,762 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:36,762 [run_pretraining.py:  534]:	loss/total_loss, 7.228129863739014, 2797
[INFO] 2021-07-12 19:28:36,762 [run_pretraining.py:  535]:	loss/mlm_loss, 7.228129863739014, 2797
[INFO] 2021-07-12 19:28:36,762 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.795999898808077e-05, 2797
[INFO] 2021-07-12 19:28:36,763 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2797
[INFO] 2021-07-12 19:28:36,763 [run_pretraining.py:  558]:	worker_index: 3, step: 2797, cost: 7.228130, mlm loss: 7.228130, speed: 1.083102 steps/s, speed: 8.664814 samples/s, speed: 4436.384826 tokens/s, learning rate: 2.796e-05, loss_scalings: 2814.750488, pp_loss: 7.277415
[INFO] 2021-07-12 19:28:36,763 [run_pretraining.py:  512]:	********exe.run_2797******* 
[INFO] 2021-07-12 19:28:37,688 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:37,688 [run_pretraining.py:  534]:	loss/total_loss, 7.016903400421143, 2798
[INFO] 2021-07-12 19:28:37,689 [run_pretraining.py:  535]:	loss/mlm_loss, 7.016903400421143, 2798
[INFO] 2021-07-12 19:28:37,689 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7969999791821465e-05, 2798
[INFO] 2021-07-12 19:28:37,689 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2798
[INFO] 2021-07-12 19:28:37,689 [run_pretraining.py:  558]:	worker_index: 3, step: 2798, cost: 7.016903, mlm loss: 7.016903, speed: 1.080447 steps/s, speed: 8.643574 samples/s, speed: 4425.509880 tokens/s, learning rate: 2.797e-05, loss_scalings: 2814.750488, pp_loss: 7.556667
[INFO] 2021-07-12 19:28:37,689 [run_pretraining.py:  512]:	********exe.run_2798******* 
[INFO] 2021-07-12 19:28:38,615 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:38,615 [run_pretraining.py:  534]:	loss/total_loss, 7.430082321166992, 2799
[INFO] 2021-07-12 19:28:38,615 [run_pretraining.py:  535]:	loss/mlm_loss, 7.430082321166992, 2799
[INFO] 2021-07-12 19:28:38,615 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7979998776572756e-05, 2799
[INFO] 2021-07-12 19:28:38,616 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2799
[INFO] 2021-07-12 19:28:38,616 [run_pretraining.py:  558]:	worker_index: 3, step: 2799, cost: 7.430082, mlm loss: 7.430082, speed: 1.079730 steps/s, speed: 8.637838 samples/s, speed: 4422.572897 tokens/s, learning rate: 2.798e-05, loss_scalings: 2814.750488, pp_loss: 7.453054
[INFO] 2021-07-12 19:28:38,616 [run_pretraining.py:  512]:	********exe.run_2799******* 
[INFO] 2021-07-12 19:28:39,538 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:39,538 [run_pretraining.py:  534]:	loss/total_loss, 6.909038543701172, 2800
[INFO] 2021-07-12 19:28:39,538 [run_pretraining.py:  535]:	loss/mlm_loss, 6.909038543701172, 2800
[INFO] 2021-07-12 19:28:39,539 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7990001399302855e-05, 2800
[INFO] 2021-07-12 19:28:39,539 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2800
[INFO] 2021-07-12 19:28:39,539 [run_pretraining.py:  558]:	worker_index: 3, step: 2800, cost: 6.909039, mlm loss: 6.909039, speed: 1.084037 steps/s, speed: 8.672296 samples/s, speed: 4440.215630 tokens/s, learning rate: 2.799e-05, loss_scalings: 2814.750488, pp_loss: 7.027672
[INFO] 2021-07-12 19:28:39,539 [run_pretraining.py:  512]:	********exe.run_2800******* 
[INFO] 2021-07-12 19:28:40,465 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:40,466 [run_pretraining.py:  534]:	loss/total_loss, 7.518603324890137, 2801
[INFO] 2021-07-12 19:28:40,466 [run_pretraining.py:  535]:	loss/mlm_loss, 7.518603324890137, 2801
[INFO] 2021-07-12 19:28:40,466 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7999998565064743e-05, 2801
[INFO] 2021-07-12 19:28:40,466 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2801
[INFO] 2021-07-12 19:28:40,466 [run_pretraining.py:  558]:	worker_index: 3, step: 2801, cost: 7.518603, mlm loss: 7.518603, speed: 1.078774 steps/s, speed: 8.630193 samples/s, speed: 4418.658812 tokens/s, learning rate: 2.800e-05, loss_scalings: 2814.750488, pp_loss: 7.564171
[INFO] 2021-07-12 19:28:40,466 [run_pretraining.py:  512]:	********exe.run_2801******* 
[INFO] 2021-07-12 19:28:41,389 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:41,390 [run_pretraining.py:  534]:	loss/total_loss, 7.093600273132324, 2802
[INFO] 2021-07-12 19:28:41,390 [run_pretraining.py:  535]:	loss/mlm_loss, 7.093600273132324, 2802
[INFO] 2021-07-12 19:28:41,390 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8009997549816035e-05, 2802
[INFO] 2021-07-12 19:28:41,390 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2802
[INFO] 2021-07-12 19:28:41,390 [run_pretraining.py:  558]:	worker_index: 3, step: 2802, cost: 7.093600, mlm loss: 7.093600, speed: 1.083022 steps/s, speed: 8.664174 samples/s, speed: 4436.057204 tokens/s, learning rate: 2.801e-05, loss_scalings: 2814.750488, pp_loss: 6.697715
[INFO] 2021-07-12 19:28:41,390 [run_pretraining.py:  512]:	********exe.run_2802******* 
[INFO] 2021-07-12 19:28:42,310 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:42,310 [run_pretraining.py:  534]:	loss/total_loss, 7.009300708770752, 2803
[INFO] 2021-07-12 19:28:42,310 [run_pretraining.py:  535]:	loss/mlm_loss, 7.009300708770752, 2803
[INFO] 2021-07-12 19:28:42,310 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8020000172546133e-05, 2803
[INFO] 2021-07-12 19:28:42,310 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2803
[INFO] 2021-07-12 19:28:42,310 [run_pretraining.py:  558]:	worker_index: 3, step: 2803, cost: 7.009301, mlm loss: 7.009301, speed: 1.087551 steps/s, speed: 8.700407 samples/s, speed: 4454.608204 tokens/s, learning rate: 2.802e-05, loss_scalings: 2814.750488, pp_loss: 6.537608
[INFO] 2021-07-12 19:28:42,311 [run_pretraining.py:  512]:	********exe.run_2803******* 
[INFO] 2021-07-12 19:28:43,236 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:43,237 [run_pretraining.py:  534]:	loss/total_loss, 8.073980331420898, 2804
[INFO] 2021-07-12 19:28:43,237 [run_pretraining.py:  535]:	loss/mlm_loss, 8.073980331420898, 2804
[INFO] 2021-07-12 19:28:43,237 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8029999157297425e-05, 2804
[INFO] 2021-07-12 19:28:43,237 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2804
[INFO] 2021-07-12 19:28:43,237 [run_pretraining.py:  558]:	worker_index: 3, step: 2804, cost: 8.073980, mlm loss: 8.073980, speed: 1.079838 steps/s, speed: 8.638701 samples/s, speed: 4423.014677 tokens/s, learning rate: 2.803e-05, loss_scalings: 2814.750488, pp_loss: 7.478384
[INFO] 2021-07-12 19:28:43,237 [run_pretraining.py:  512]:	********exe.run_2804******* 
[INFO] 2021-07-12 19:28:44,158 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:44,158 [run_pretraining.py:  534]:	loss/total_loss, 7.84863805770874, 2805
[INFO] 2021-07-12 19:28:44,158 [run_pretraining.py:  535]:	loss/mlm_loss, 7.84863805770874, 2805
[INFO] 2021-07-12 19:28:44,158 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.803999996103812e-05, 2805
[INFO] 2021-07-12 19:28:44,158 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2805
[INFO] 2021-07-12 19:28:44,158 [run_pretraining.py:  558]:	worker_index: 3, step: 2805, cost: 7.848638, mlm loss: 7.848638, speed: 1.086147 steps/s, speed: 8.689175 samples/s, speed: 4448.857734 tokens/s, learning rate: 2.804e-05, loss_scalings: 2814.750488, pp_loss: 7.283663
[INFO] 2021-07-12 19:28:44,159 [run_pretraining.py:  512]:	********exe.run_2805******* 
[INFO] 2021-07-12 19:28:45,079 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:45,079 [run_pretraining.py:  534]:	loss/total_loss, 6.893571376800537, 2806
[INFO] 2021-07-12 19:28:45,080 [run_pretraining.py:  535]:	loss/mlm_loss, 6.893571376800537, 2806
[INFO] 2021-07-12 19:28:45,080 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.804999894578941e-05, 2806
[INFO] 2021-07-12 19:28:45,080 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2806
[INFO] 2021-07-12 19:28:45,080 [run_pretraining.py:  558]:	worker_index: 3, step: 2806, cost: 6.893571, mlm loss: 6.893571, speed: 1.086129 steps/s, speed: 8.689029 samples/s, speed: 4448.782851 tokens/s, learning rate: 2.805e-05, loss_scalings: 2814.750488, pp_loss: 7.238069
[INFO] 2021-07-12 19:28:45,080 [run_pretraining.py:  512]:	********exe.run_2806******* 
[INFO] 2021-07-12 19:28:45,998 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:45,999 [run_pretraining.py:  534]:	loss/total_loss, 7.0538249015808105, 2807
[INFO] 2021-07-12 19:28:45,999 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0538249015808105, 2807
[INFO] 2021-07-12 19:28:45,999 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8059999749530107e-05, 2807
[INFO] 2021-07-12 19:28:45,999 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2807
[INFO] 2021-07-12 19:28:45,999 [run_pretraining.py:  558]:	worker_index: 3, step: 2807, cost: 7.053825, mlm loss: 7.053825, speed: 1.088551 steps/s, speed: 8.708411 samples/s, speed: 4458.706608 tokens/s, learning rate: 2.806e-05, loss_scalings: 2814.750488, pp_loss: 7.329664
[INFO] 2021-07-12 19:28:45,999 [run_pretraining.py:  512]:	********exe.run_2807******* 
[INFO] 2021-07-12 19:28:46,911 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:46,911 [run_pretraining.py:  534]:	loss/total_loss, 7.263861656188965, 2808
[INFO] 2021-07-12 19:28:46,911 [run_pretraining.py:  535]:	loss/mlm_loss, 7.263861656188965, 2808
[INFO] 2021-07-12 19:28:46,912 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.80699987342814e-05, 2808
[INFO] 2021-07-12 19:28:46,912 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2808
[INFO] 2021-07-12 19:28:46,912 [run_pretraining.py:  558]:	worker_index: 3, step: 2808, cost: 7.263862, mlm loss: 7.263862, speed: 1.096545 steps/s, speed: 8.772357 samples/s, speed: 4491.446757 tokens/s, learning rate: 2.807e-05, loss_scalings: 2814.750488, pp_loss: 6.420762
[INFO] 2021-07-12 19:28:46,912 [run_pretraining.py:  512]:	********exe.run_2808******* 
[INFO] 2021-07-12 19:28:47,821 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:47,821 [run_pretraining.py:  534]:	loss/total_loss, 7.515130043029785, 2809
[INFO] 2021-07-12 19:28:47,821 [run_pretraining.py:  535]:	loss/mlm_loss, 7.515130043029785, 2809
[INFO] 2021-07-12 19:28:47,822 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8080001357011497e-05, 2809
[INFO] 2021-07-12 19:28:47,822 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2809
[INFO] 2021-07-12 19:28:47,822 [run_pretraining.py:  558]:	worker_index: 3, step: 2809, cost: 7.515130, mlm loss: 7.515130, speed: 1.099699 steps/s, speed: 8.797590 samples/s, speed: 4504.366275 tokens/s, learning rate: 2.808e-05, loss_scalings: 2814.750488, pp_loss: 7.230228
[INFO] 2021-07-12 19:28:47,822 [run_pretraining.py:  512]:	********exe.run_2809******* 
[INFO] 2021-07-12 19:28:48,742 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:48,742 [run_pretraining.py:  534]:	loss/total_loss, 6.8264055252075195, 2810
[INFO] 2021-07-12 19:28:48,743 [run_pretraining.py:  535]:	loss/mlm_loss, 6.8264055252075195, 2810
[INFO] 2021-07-12 19:28:48,743 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.809000034176279e-05, 2810
[INFO] 2021-07-12 19:28:48,743 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2810
[INFO] 2021-07-12 19:28:48,743 [run_pretraining.py:  558]:	worker_index: 3, step: 2810, cost: 6.826406, mlm loss: 6.826406, speed: 1.086482 steps/s, speed: 8.691858 samples/s, speed: 4450.231420 tokens/s, learning rate: 2.809e-05, loss_scalings: 2814.750488, pp_loss: 7.229764
[INFO] 2021-07-12 19:28:48,743 [run_pretraining.py:  512]:	********exe.run_2810******* 
[INFO] 2021-07-12 19:28:49,675 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:49,675 [run_pretraining.py:  534]:	loss/total_loss, 7.3382182121276855, 2811
[INFO] 2021-07-12 19:28:49,675 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3382182121276855, 2811
[INFO] 2021-07-12 19:28:49,676 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8099997507524677e-05, 2811
[INFO] 2021-07-12 19:28:49,676 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2811
[INFO] 2021-07-12 19:28:49,676 [run_pretraining.py:  558]:	worker_index: 3, step: 2811, cost: 7.338218, mlm loss: 7.338218, speed: 1.072662 steps/s, speed: 8.581297 samples/s, speed: 4393.623924 tokens/s, learning rate: 2.810e-05, loss_scalings: 2814.750488, pp_loss: 7.369424
[INFO] 2021-07-12 19:28:49,676 [run_pretraining.py:  512]:	********exe.run_2811******* 
[INFO] 2021-07-12 19:28:50,592 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:50,592 [run_pretraining.py:  534]:	loss/total_loss, 7.78327751159668, 2812
[INFO] 2021-07-12 19:28:50,592 [run_pretraining.py:  535]:	loss/mlm_loss, 7.78327751159668, 2812
[INFO] 2021-07-12 19:28:50,593 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8110000130254775e-05, 2812
[INFO] 2021-07-12 19:28:50,593 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2812
[INFO] 2021-07-12 19:28:50,593 [run_pretraining.py:  558]:	worker_index: 3, step: 2812, cost: 7.783278, mlm loss: 7.783278, speed: 1.091196 steps/s, speed: 8.729570 samples/s, speed: 4469.539695 tokens/s, learning rate: 2.811e-05, loss_scalings: 2814.750488, pp_loss: 7.472817
[INFO] 2021-07-12 19:28:50,593 [run_pretraining.py:  512]:	********exe.run_2812******* 
[INFO] 2021-07-12 19:28:51,509 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:51,509 [run_pretraining.py:  534]:	loss/total_loss, 7.709822654724121, 2813
[INFO] 2021-07-12 19:28:51,509 [run_pretraining.py:  535]:	loss/mlm_loss, 7.709822654724121, 2813
[INFO] 2021-07-12 19:28:51,509 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8119999115006067e-05, 2813
[INFO] 2021-07-12 19:28:51,509 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2813
[INFO] 2021-07-12 19:28:51,509 [run_pretraining.py:  558]:	worker_index: 3, step: 2813, cost: 7.709823, mlm loss: 7.709823, speed: 1.091663 steps/s, speed: 8.733300 samples/s, speed: 4471.449832 tokens/s, learning rate: 2.812e-05, loss_scalings: 2814.750488, pp_loss: 7.596812
[INFO] 2021-07-12 19:28:51,509 [run_pretraining.py:  512]:	********exe.run_2813******* 
[INFO] 2021-07-12 19:28:52,432 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:52,433 [run_pretraining.py:  534]:	loss/total_loss, 6.291066646575928, 2814
[INFO] 2021-07-12 19:28:52,433 [run_pretraining.py:  535]:	loss/mlm_loss, 6.291066646575928, 2814
[INFO] 2021-07-12 19:28:52,433 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8129999918746762e-05, 2814
[INFO] 2021-07-12 19:28:52,433 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2814
[INFO] 2021-07-12 19:28:52,433 [run_pretraining.py:  558]:	worker_index: 3, step: 2814, cost: 6.291067, mlm loss: 6.291067, speed: 1.083024 steps/s, speed: 8.664192 samples/s, speed: 4436.066368 tokens/s, learning rate: 2.813e-05, loss_scalings: 2814.750488, pp_loss: 7.301675
[INFO] 2021-07-12 19:28:52,433 [run_pretraining.py:  512]:	********exe.run_2814******* 
[INFO] 2021-07-12 19:28:53,357 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:53,358 [run_pretraining.py:  534]:	loss/total_loss, 4.41712760925293, 2815
[INFO] 2021-07-12 19:28:53,358 [run_pretraining.py:  535]:	loss/mlm_loss, 4.41712760925293, 2815
[INFO] 2021-07-12 19:28:53,358 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8139998903498054e-05, 2815
[INFO] 2021-07-12 19:28:53,358 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2815
[INFO] 2021-07-12 19:28:53,358 [run_pretraining.py:  558]:	worker_index: 3, step: 2815, cost: 4.417128, mlm loss: 4.417128, speed: 1.081910 steps/s, speed: 8.655279 samples/s, speed: 4431.503012 tokens/s, learning rate: 2.814e-05, loss_scalings: 2814.750488, pp_loss: 6.630677
[INFO] 2021-07-12 19:28:53,358 [run_pretraining.py:  512]:	********exe.run_2815******* 
[INFO] 2021-07-12 19:28:54,276 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:54,277 [run_pretraining.py:  534]:	loss/total_loss, 7.180386543273926, 2816
[INFO] 2021-07-12 19:28:54,277 [run_pretraining.py:  535]:	loss/mlm_loss, 7.180386543273926, 2816
[INFO] 2021-07-12 19:28:54,277 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.814999970723875e-05, 2816
[INFO] 2021-07-12 19:28:54,277 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2816
[INFO] 2021-07-12 19:28:54,277 [run_pretraining.py:  558]:	worker_index: 3, step: 2816, cost: 7.180387, mlm loss: 7.180387, speed: 1.088911 steps/s, speed: 8.711285 samples/s, speed: 4460.177859 tokens/s, learning rate: 2.815e-05, loss_scalings: 2814.750488, pp_loss: 7.124813
[INFO] 2021-07-12 19:28:54,277 [run_pretraining.py:  512]:	********exe.run_2816******* 
[INFO] 2021-07-12 19:28:55,192 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:55,192 [run_pretraining.py:  534]:	loss/total_loss, 6.9172282218933105, 2817
[INFO] 2021-07-12 19:28:55,192 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9172282218933105, 2817
[INFO] 2021-07-12 19:28:55,193 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.815999869199004e-05, 2817
[INFO] 2021-07-12 19:28:55,193 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2817
[INFO] 2021-07-12 19:28:55,193 [run_pretraining.py:  558]:	worker_index: 3, step: 2817, cost: 6.917228, mlm loss: 6.917228, speed: 1.093128 steps/s, speed: 8.745027 samples/s, speed: 4477.453760 tokens/s, learning rate: 2.816e-05, loss_scalings: 2814.750488, pp_loss: 7.152316
[INFO] 2021-07-12 19:28:55,193 [run_pretraining.py:  512]:	********exe.run_2817******* 
[INFO] 2021-07-12 19:28:56,108 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:56,108 [run_pretraining.py:  534]:	loss/total_loss, 6.979828834533691, 2818
[INFO] 2021-07-12 19:28:56,108 [run_pretraining.py:  535]:	loss/mlm_loss, 6.979828834533691, 2818
[INFO] 2021-07-12 19:28:56,108 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8169997676741332e-05, 2818
[INFO] 2021-07-12 19:28:56,108 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2818
[INFO] 2021-07-12 19:28:56,108 [run_pretraining.py:  558]:	worker_index: 3, step: 2818, cost: 6.979829, mlm loss: 6.979829, speed: 1.092736 steps/s, speed: 8.741885 samples/s, speed: 4475.845150 tokens/s, learning rate: 2.817e-05, loss_scalings: 2814.750488, pp_loss: 6.925011
[INFO] 2021-07-12 19:28:56,109 [run_pretraining.py:  512]:	********exe.run_2818******* 
[INFO] 2021-07-12 19:28:57,018 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:57,018 [run_pretraining.py:  534]:	loss/total_loss, 6.980388641357422, 2819
[INFO] 2021-07-12 19:28:57,018 [run_pretraining.py:  535]:	loss/mlm_loss, 6.980388641357422, 2819
[INFO] 2021-07-12 19:28:57,018 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.818000029947143e-05, 2819
[INFO] 2021-07-12 19:28:57,018 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2819
[INFO] 2021-07-12 19:28:57,018 [run_pretraining.py:  558]:	worker_index: 3, step: 2819, cost: 6.980389, mlm loss: 6.980389, speed: 1.099687 steps/s, speed: 8.797496 samples/s, speed: 4504.317855 tokens/s, learning rate: 2.818e-05, loss_scalings: 2814.750488, pp_loss: 6.846756
[INFO] 2021-07-12 19:28:57,019 [run_pretraining.py:  512]:	********exe.run_2819******* 
[INFO] 2021-07-12 19:28:57,951 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:57,952 [run_pretraining.py:  534]:	loss/total_loss, 7.183648109436035, 2820
[INFO] 2021-07-12 19:28:57,952 [run_pretraining.py:  535]:	loss/mlm_loss, 7.183648109436035, 2820
[INFO] 2021-07-12 19:28:57,952 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.818999746523332e-05, 2820
[INFO] 2021-07-12 19:28:57,952 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2820
[INFO] 2021-07-12 19:28:57,952 [run_pretraining.py:  558]:	worker_index: 3, step: 2820, cost: 7.183648, mlm loss: 7.183648, speed: 1.071673 steps/s, speed: 8.573382 samples/s, speed: 4389.571337 tokens/s, learning rate: 2.819e-05, loss_scalings: 2814.750488, pp_loss: 7.270252
[INFO] 2021-07-12 19:28:57,952 [run_pretraining.py:  512]:	********exe.run_2820******* 
[INFO] 2021-07-12 19:28:58,864 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:58,865 [run_pretraining.py:  534]:	loss/total_loss, 7.158320903778076, 2821
[INFO] 2021-07-12 19:28:58,865 [run_pretraining.py:  535]:	loss/mlm_loss, 7.158320903778076, 2821
[INFO] 2021-07-12 19:28:58,865 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8200000087963417e-05, 2821
[INFO] 2021-07-12 19:28:58,865 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2821
[INFO] 2021-07-12 19:28:58,865 [run_pretraining.py:  558]:	worker_index: 3, step: 2821, cost: 7.158321, mlm loss: 7.158321, speed: 1.096092 steps/s, speed: 8.768737 samples/s, speed: 4489.593415 tokens/s, learning rate: 2.820e-05, loss_scalings: 2814.750488, pp_loss: 7.218095
[INFO] 2021-07-12 19:28:58,865 [run_pretraining.py:  512]:	********exe.run_2821******* 
[INFO] 2021-07-12 19:28:59,777 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:59,777 [run_pretraining.py:  534]:	loss/total_loss, 8.118653297424316, 2822
[INFO] 2021-07-12 19:28:59,777 [run_pretraining.py:  535]:	loss/mlm_loss, 8.118653297424316, 2822
[INFO] 2021-07-12 19:28:59,777 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.820999907271471e-05, 2822
[INFO] 2021-07-12 19:28:59,778 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2822
[INFO] 2021-07-12 19:28:59,778 [run_pretraining.py:  558]:	worker_index: 3, step: 2822, cost: 8.118653, mlm loss: 8.118653, speed: 1.096703 steps/s, speed: 8.773625 samples/s, speed: 4492.096200 tokens/s, learning rate: 2.821e-05, loss_scalings: 2814.750488, pp_loss: 7.527081
[INFO] 2021-07-12 19:28:59,778 [run_pretraining.py:  512]:	********exe.run_2822******* 
[INFO] 2021-07-12 19:29:00,689 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:00,689 [run_pretraining.py:  534]:	loss/total_loss, 8.057120323181152, 2823
[INFO] 2021-07-12 19:29:00,689 [run_pretraining.py:  535]:	loss/mlm_loss, 8.057120323181152, 2823
[INFO] 2021-07-12 19:29:00,689 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8219999876455404e-05, 2823
[INFO] 2021-07-12 19:29:00,689 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2823
[INFO] 2021-07-12 19:29:00,690 [run_pretraining.py:  558]:	worker_index: 3, step: 2823, cost: 8.057120, mlm loss: 8.057120, speed: 1.097331 steps/s, speed: 8.778648 samples/s, speed: 4494.667626 tokens/s, learning rate: 2.822e-05, loss_scalings: 2814.750488, pp_loss: 7.308371
[INFO] 2021-07-12 19:29:00,690 [run_pretraining.py:  512]:	********exe.run_2823******* 
[INFO] 2021-07-12 19:29:01,599 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:01,600 [run_pretraining.py:  534]:	loss/total_loss, 7.082491874694824, 2824
[INFO] 2021-07-12 19:29:01,600 [run_pretraining.py:  535]:	loss/mlm_loss, 7.082491874694824, 2824
[INFO] 2021-07-12 19:29:01,600 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8229998861206695e-05, 2824
[INFO] 2021-07-12 19:29:01,600 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2824
[INFO] 2021-07-12 19:29:01,600 [run_pretraining.py:  558]:	worker_index: 3, step: 2824, cost: 7.082492, mlm loss: 7.082492, speed: 1.099183 steps/s, speed: 8.793466 samples/s, speed: 4502.254468 tokens/s, learning rate: 2.823e-05, loss_scalings: 2814.750488, pp_loss: 6.928349
[INFO] 2021-07-12 19:29:01,600 [run_pretraining.py:  512]:	********exe.run_2824******* 
[INFO] 2021-07-12 19:29:02,517 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:02,517 [run_pretraining.py:  534]:	loss/total_loss, 7.478960990905762, 2825
[INFO] 2021-07-12 19:29:02,517 [run_pretraining.py:  535]:	loss/mlm_loss, 7.478960990905762, 2825
[INFO] 2021-07-12 19:29:02,517 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.823999966494739e-05, 2825
[INFO] 2021-07-12 19:29:02,517 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2825
[INFO] 2021-07-12 19:29:02,517 [run_pretraining.py:  558]:	worker_index: 3, step: 2825, cost: 7.478961, mlm loss: 7.478961, speed: 1.090671 steps/s, speed: 8.725366 samples/s, speed: 4467.387223 tokens/s, learning rate: 2.824e-05, loss_scalings: 2814.750488, pp_loss: 7.505158
[INFO] 2021-07-12 19:29:02,518 [run_pretraining.py:  512]:	********exe.run_2825******* 
[INFO] 2021-07-12 19:29:03,422 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:03,422 [run_pretraining.py:  534]:	loss/total_loss, 6.769190311431885, 2826
[INFO] 2021-07-12 19:29:03,422 [run_pretraining.py:  535]:	loss/mlm_loss, 6.769190311431885, 2826
[INFO] 2021-07-12 19:29:03,422 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8249998649698682e-05, 2826
[INFO] 2021-07-12 19:29:03,422 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2826
[INFO] 2021-07-12 19:29:03,422 [run_pretraining.py:  558]:	worker_index: 3, step: 2826, cost: 6.769190, mlm loss: 6.769190, speed: 1.105823 steps/s, speed: 8.846585 samples/s, speed: 4529.451330 tokens/s, learning rate: 2.825e-05, loss_scalings: 2814.750488, pp_loss: 6.629851
[INFO] 2021-07-12 19:29:03,422 [run_pretraining.py:  512]:	********exe.run_2826******* 
[INFO] 2021-07-12 19:29:04,333 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:04,333 [run_pretraining.py:  534]:	loss/total_loss, 4.166678428649902, 2827
[INFO] 2021-07-12 19:29:04,333 [run_pretraining.py:  535]:	loss/mlm_loss, 4.166678428649902, 2827
[INFO] 2021-07-12 19:29:04,334 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8259997634449974e-05, 2827
[INFO] 2021-07-12 19:29:04,334 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2827
[INFO] 2021-07-12 19:29:04,334 [run_pretraining.py:  558]:	worker_index: 3, step: 2827, cost: 4.166678, mlm loss: 4.166678, speed: 1.098051 steps/s, speed: 8.784407 samples/s, speed: 4497.616398 tokens/s, learning rate: 2.826e-05, loss_scalings: 2814.750488, pp_loss: 6.331657
[INFO] 2021-07-12 19:29:04,334 [run_pretraining.py:  512]:	********exe.run_2827******* 
[INFO] 2021-07-12 19:29:05,248 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:05,249 [run_pretraining.py:  534]:	loss/total_loss, 7.336341857910156, 2828
[INFO] 2021-07-12 19:29:05,249 [run_pretraining.py:  535]:	loss/mlm_loss, 7.336341857910156, 2828
[INFO] 2021-07-12 19:29:05,250 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8270000257180072e-05, 2828
[INFO] 2021-07-12 19:29:05,250 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2828
[INFO] 2021-07-12 19:29:05,250 [run_pretraining.py:  558]:	worker_index: 3, step: 2828, cost: 7.336342, mlm loss: 7.336342, speed: 1.092488 steps/s, speed: 8.739904 samples/s, speed: 4474.830886 tokens/s, learning rate: 2.827e-05, loss_scalings: 2814.750488, pp_loss: 7.172579
[INFO] 2021-07-12 19:29:05,250 [run_pretraining.py:  512]:	********exe.run_2828******* 
[INFO] 2021-07-12 19:29:06,170 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:06,170 [run_pretraining.py:  534]:	loss/total_loss, 7.284985065460205, 2829
[INFO] 2021-07-12 19:29:06,170 [run_pretraining.py:  535]:	loss/mlm_loss, 7.284985065460205, 2829
[INFO] 2021-07-12 19:29:06,170 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.827999742294196e-05, 2829
[INFO] 2021-07-12 19:29:06,171 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2829
[INFO] 2021-07-12 19:29:06,171 [run_pretraining.py:  558]:	worker_index: 3, step: 2829, cost: 7.284985, mlm loss: 7.284985, speed: 1.086706 steps/s, speed: 8.693644 samples/s, speed: 4451.145760 tokens/s, learning rate: 2.828e-05, loss_scalings: 2814.750488, pp_loss: 7.065175
[INFO] 2021-07-12 19:29:06,171 [run_pretraining.py:  512]:	********exe.run_2829******* 
[INFO] 2021-07-12 19:29:07,082 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:07,083 [run_pretraining.py:  534]:	loss/total_loss, 7.586782932281494, 2830
[INFO] 2021-07-12 19:29:07,083 [run_pretraining.py:  535]:	loss/mlm_loss, 7.586782932281494, 2830
[INFO] 2021-07-12 19:29:07,083 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.829000004567206e-05, 2830
[INFO] 2021-07-12 19:29:07,083 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2830
[INFO] 2021-07-12 19:29:07,083 [run_pretraining.py:  558]:	worker_index: 3, step: 2830, cost: 7.586783, mlm loss: 7.586783, speed: 1.096879 steps/s, speed: 8.775034 samples/s, speed: 4492.817500 tokens/s, learning rate: 2.829e-05, loss_scalings: 2814.750488, pp_loss: 7.276078
[INFO] 2021-07-12 19:29:07,083 [run_pretraining.py:  512]:	********exe.run_2830******* 
[INFO] 2021-07-12 19:29:08,026 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:08,027 [run_pretraining.py:  534]:	loss/total_loss, 7.824491500854492, 2831
[INFO] 2021-07-12 19:29:08,027 [run_pretraining.py:  535]:	loss/mlm_loss, 7.824491500854492, 2831
[INFO] 2021-07-12 19:29:08,027 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.829999903042335e-05, 2831
[INFO] 2021-07-12 19:29:08,027 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2831
[INFO] 2021-07-12 19:29:08,027 [run_pretraining.py:  558]:	worker_index: 3, step: 2831, cost: 7.824492, mlm loss: 7.824492, speed: 1.059623 steps/s, speed: 8.476983 samples/s, speed: 4340.215124 tokens/s, learning rate: 2.830e-05, loss_scalings: 2814.750488, pp_loss: 7.401324
[INFO] 2021-07-12 19:29:08,027 [run_pretraining.py:  512]:	********exe.run_2831******* 
[INFO] 2021-07-12 19:29:09,081 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:09,081 [run_pretraining.py:  534]:	loss/total_loss, 7.119400501251221, 2832
[INFO] 2021-07-12 19:29:09,082 [run_pretraining.py:  535]:	loss/mlm_loss, 7.119400501251221, 2832
[INFO] 2021-07-12 19:29:09,082 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8309999834164046e-05, 2832
[INFO] 2021-07-12 19:29:09,082 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2832
[INFO] 2021-07-12 19:29:09,082 [run_pretraining.py:  558]:	worker_index: 3, step: 2832, cost: 7.119401, mlm loss: 7.119401, speed: 0.948882 steps/s, speed: 7.591057 samples/s, speed: 3886.621366 tokens/s, learning rate: 2.831e-05, loss_scalings: 2814.750488, pp_loss: 7.121080
[INFO] 2021-07-12 19:29:09,082 [run_pretraining.py:  512]:	********exe.run_2832******* 
[INFO] 2021-07-12 19:29:10,148 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:10,149 [run_pretraining.py:  534]:	loss/total_loss, 7.065916061401367, 2833
[INFO] 2021-07-12 19:29:10,149 [run_pretraining.py:  535]:	loss/mlm_loss, 7.065916061401367, 2833
[INFO] 2021-07-12 19:29:10,149 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8319998818915337e-05, 2833
[INFO] 2021-07-12 19:29:10,149 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2833
[INFO] 2021-07-12 19:29:10,149 [run_pretraining.py:  558]:	worker_index: 3, step: 2833, cost: 7.065916, mlm loss: 7.065916, speed: 0.937297 steps/s, speed: 7.498373 samples/s, speed: 3839.166994 tokens/s, learning rate: 2.832e-05, loss_scalings: 2814.750488, pp_loss: 7.339584
[INFO] 2021-07-12 19:29:10,149 [run_pretraining.py:  512]:	********exe.run_2833******* 
[INFO] 2021-07-12 19:29:11,212 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:11,213 [run_pretraining.py:  534]:	loss/total_loss, 7.208336353302002, 2834
[INFO] 2021-07-12 19:29:11,213 [run_pretraining.py:  535]:	loss/mlm_loss, 7.208336353302002, 2834
[INFO] 2021-07-12 19:29:11,213 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8329999622656032e-05, 2834
[INFO] 2021-07-12 19:29:11,213 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2834
[INFO] 2021-07-12 19:29:11,213 [run_pretraining.py:  558]:	worker_index: 3, step: 2834, cost: 7.208336, mlm loss: 7.208336, speed: 0.940623 steps/s, speed: 7.524984 samples/s, speed: 3852.791991 tokens/s, learning rate: 2.833e-05, loss_scalings: 2814.750488, pp_loss: 7.126637
[INFO] 2021-07-12 19:29:11,213 [run_pretraining.py:  512]:	********exe.run_2834******* 
[INFO] 2021-07-12 19:29:12,274 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:12,274 [run_pretraining.py:  534]:	loss/total_loss, 7.001189231872559, 2835
[INFO] 2021-07-12 19:29:12,274 [run_pretraining.py:  535]:	loss/mlm_loss, 7.001189231872559, 2835
[INFO] 2021-07-12 19:29:12,274 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8339998607407324e-05, 2835
[INFO] 2021-07-12 19:29:12,274 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2835
[INFO] 2021-07-12 19:29:12,275 [run_pretraining.py:  558]:	worker_index: 3, step: 2835, cost: 7.001189, mlm loss: 7.001189, speed: 0.942678 steps/s, speed: 7.541423 samples/s, speed: 3861.208757 tokens/s, learning rate: 2.834e-05, loss_scalings: 2814.750488, pp_loss: 7.402470
[INFO] 2021-07-12 19:29:12,275 [run_pretraining.py:  512]:	********exe.run_2835******* 
[INFO] 2021-07-12 19:29:13,323 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:13,323 [run_pretraining.py:  534]:	loss/total_loss, 7.157618522644043, 2836
[INFO] 2021-07-12 19:29:13,323 [run_pretraining.py:  535]:	loss/mlm_loss, 7.157618522644043, 2836
[INFO] 2021-07-12 19:29:13,323 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8349997592158616e-05, 2836
[INFO] 2021-07-12 19:29:13,323 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2836
[INFO] 2021-07-12 19:29:13,323 [run_pretraining.py:  558]:	worker_index: 3, step: 2836, cost: 7.157619, mlm loss: 7.157619, speed: 0.954024 steps/s, speed: 7.632193 samples/s, speed: 3907.682723 tokens/s, learning rate: 2.835e-05, loss_scalings: 2814.750488, pp_loss: 6.959170
[INFO] 2021-07-12 19:29:13,323 [run_pretraining.py:  512]:	********exe.run_2836******* 
[INFO] 2021-07-12 19:29:14,379 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:14,380 [run_pretraining.py:  534]:	loss/total_loss, 7.527970314025879, 2837
[INFO] 2021-07-12 19:29:14,380 [run_pretraining.py:  535]:	loss/mlm_loss, 7.527970314025879, 2837
[INFO] 2021-07-12 19:29:14,380 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8360000214888714e-05, 2837
[INFO] 2021-07-12 19:29:14,380 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2837
[INFO] 2021-07-12 19:29:14,380 [run_pretraining.py:  558]:	worker_index: 3, step: 2837, cost: 7.527970, mlm loss: 7.527970, speed: 0.946844 steps/s, speed: 7.574750 samples/s, speed: 3878.272161 tokens/s, learning rate: 2.836e-05, loss_scalings: 2814.750488, pp_loss: 7.328456
[INFO] 2021-07-12 19:29:14,380 [run_pretraining.py:  512]:	********exe.run_2837******* 
[INFO] 2021-07-12 19:29:15,437 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:15,438 [run_pretraining.py:  534]:	loss/total_loss, 6.916444301605225, 2838
[INFO] 2021-07-12 19:29:15,438 [run_pretraining.py:  535]:	loss/mlm_loss, 6.916444301605225, 2838
[INFO] 2021-07-12 19:29:15,438 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8369997380650602e-05, 2838
[INFO] 2021-07-12 19:29:15,438 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2838
[INFO] 2021-07-12 19:29:15,438 [run_pretraining.py:  558]:	worker_index: 3, step: 2838, cost: 6.916444, mlm loss: 6.916444, speed: 0.945595 steps/s, speed: 7.564757 samples/s, speed: 3873.155488 tokens/s, learning rate: 2.837e-05, loss_scalings: 2814.750488, pp_loss: 7.131071
[INFO] 2021-07-12 19:29:15,438 [run_pretraining.py:  512]:	********exe.run_2838******* 
[INFO] 2021-07-12 19:29:16,512 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:16,513 [run_pretraining.py:  534]:	loss/total_loss, 8.12381362915039, 2839
[INFO] 2021-07-12 19:29:16,513 [run_pretraining.py:  535]:	loss/mlm_loss, 8.12381362915039, 2839
[INFO] 2021-07-12 19:29:16,513 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.83800000033807e-05, 2839
[INFO] 2021-07-12 19:29:16,513 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2839
[INFO] 2021-07-12 19:29:16,513 [run_pretraining.py:  558]:	worker_index: 3, step: 2839, cost: 8.123814, mlm loss: 8.123814, speed: 0.930897 steps/s, speed: 7.447177 samples/s, speed: 3812.954553 tokens/s, learning rate: 2.838e-05, loss_scalings: 2814.750488, pp_loss: 7.768534
[INFO] 2021-07-12 19:29:16,513 [run_pretraining.py:  512]:	********exe.run_2839******* 
[INFO] 2021-07-12 19:29:17,574 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:17,575 [run_pretraining.py:  534]:	loss/total_loss, 6.72097110748291, 2840
[INFO] 2021-07-12 19:29:17,575 [run_pretraining.py:  535]:	loss/mlm_loss, 6.72097110748291, 2840
[INFO] 2021-07-12 19:29:17,575 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8389998988131993e-05, 2840
[INFO] 2021-07-12 19:29:17,575 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2840
[INFO] 2021-07-12 19:29:17,575 [run_pretraining.py:  558]:	worker_index: 3, step: 2840, cost: 6.720971, mlm loss: 6.720971, speed: 0.942022 steps/s, speed: 7.536179 samples/s, speed: 3858.523873 tokens/s, learning rate: 2.839e-05, loss_scalings: 2814.750488, pp_loss: 7.249765
[INFO] 2021-07-12 19:29:17,575 [run_pretraining.py:  512]:	********exe.run_2840******* 
[INFO] 2021-07-12 19:29:18,641 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:18,642 [run_pretraining.py:  534]:	loss/total_loss, 7.711036682128906, 2841
[INFO] 2021-07-12 19:29:18,642 [run_pretraining.py:  535]:	loss/mlm_loss, 7.711036682128906, 2841
[INFO] 2021-07-12 19:29:18,642 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8399999791872688e-05, 2841
[INFO] 2021-07-12 19:29:18,642 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2841
[INFO] 2021-07-12 19:29:18,642 [run_pretraining.py:  558]:	worker_index: 3, step: 2841, cost: 7.711037, mlm loss: 7.711037, speed: 0.938139 steps/s, speed: 7.505115 samples/s, speed: 3842.618992 tokens/s, learning rate: 2.840e-05, loss_scalings: 2814.750488, pp_loss: 7.451720
[INFO] 2021-07-12 19:29:18,642 [run_pretraining.py:  512]:	********exe.run_2841******* 
[INFO] 2021-07-12 19:29:19,717 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:19,718 [run_pretraining.py:  534]:	loss/total_loss, 7.899767875671387, 2842
[INFO] 2021-07-12 19:29:19,718 [run_pretraining.py:  535]:	loss/mlm_loss, 7.899767875671387, 2842
[INFO] 2021-07-12 19:29:19,718 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.840999877662398e-05, 2842
[INFO] 2021-07-12 19:29:19,718 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2842
[INFO] 2021-07-12 19:29:19,718 [run_pretraining.py:  558]:	worker_index: 3, step: 2842, cost: 7.899768, mlm loss: 7.899768, speed: 0.929635 steps/s, speed: 7.437077 samples/s, speed: 3807.783316 tokens/s, learning rate: 2.841e-05, loss_scalings: 2814.750488, pp_loss: 7.719543
[INFO] 2021-07-12 19:29:19,718 [run_pretraining.py:  512]:	********exe.run_2842******* 
[INFO] 2021-07-12 19:29:20,639 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:20,639 [run_pretraining.py:  534]:	loss/total_loss, 7.078397750854492, 2843
[INFO] 2021-07-12 19:29:20,640 [run_pretraining.py:  535]:	loss/mlm_loss, 7.078397750854492, 2843
[INFO] 2021-07-12 19:29:20,640 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8420001399354078e-05, 2843
[INFO] 2021-07-12 19:29:20,640 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2843
[INFO] 2021-07-12 19:29:20,640 [run_pretraining.py:  558]:	worker_index: 3, step: 2843, cost: 7.078398, mlm loss: 7.078398, speed: 1.085950 steps/s, speed: 8.687603 samples/s, speed: 4448.052586 tokens/s, learning rate: 2.842e-05, loss_scalings: 2814.750488, pp_loss: 7.008552
[INFO] 2021-07-12 19:29:20,640 [run_pretraining.py:  512]:	********exe.run_2843******* 
[INFO] 2021-07-12 19:29:21,565 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:21,566 [run_pretraining.py:  534]:	loss/total_loss, 7.605953216552734, 2844
[INFO] 2021-07-12 19:29:21,566 [run_pretraining.py:  535]:	loss/mlm_loss, 7.605953216552734, 2844
[INFO] 2021-07-12 19:29:21,566 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8429998565115966e-05, 2844
[INFO] 2021-07-12 19:29:21,566 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2844
[INFO] 2021-07-12 19:29:21,566 [run_pretraining.py:  558]:	worker_index: 3, step: 2844, cost: 7.605953, mlm loss: 7.605953, speed: 1.080269 steps/s, speed: 8.642149 samples/s, speed: 4424.780397 tokens/s, learning rate: 2.843e-05, loss_scalings: 2814.750488, pp_loss: 6.519357
[INFO] 2021-07-12 19:29:21,566 [run_pretraining.py:  512]:	********exe.run_2844******* 
[INFO] 2021-07-12 19:29:22,485 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:22,486 [run_pretraining.py:  534]:	loss/total_loss, 7.420219898223877, 2845
[INFO] 2021-07-12 19:29:22,486 [run_pretraining.py:  535]:	loss/mlm_loss, 7.420219898223877, 2845
[INFO] 2021-07-12 19:29:22,486 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8439997549867257e-05, 2845
[INFO] 2021-07-12 19:29:22,486 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2845
[INFO] 2021-07-12 19:29:22,486 [run_pretraining.py:  558]:	worker_index: 3, step: 2845, cost: 7.420220, mlm loss: 7.420220, speed: 1.088080 steps/s, speed: 8.704641 samples/s, speed: 4456.776124 tokens/s, learning rate: 2.844e-05, loss_scalings: 2814.750488, pp_loss: 7.167727
[INFO] 2021-07-12 19:29:22,486 [run_pretraining.py:  512]:	********exe.run_2845******* 
[INFO] 2021-07-12 19:29:23,412 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:23,413 [run_pretraining.py:  534]:	loss/total_loss, 7.533566951751709, 2846
[INFO] 2021-07-12 19:29:23,413 [run_pretraining.py:  535]:	loss/mlm_loss, 7.533566951751709, 2846
[INFO] 2021-07-12 19:29:23,413 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8450000172597356e-05, 2846
[INFO] 2021-07-12 19:29:23,413 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2846
[INFO] 2021-07-12 19:29:23,413 [run_pretraining.py:  558]:	worker_index: 3, step: 2846, cost: 7.533567, mlm loss: 7.533567, speed: 1.079240 steps/s, speed: 8.633917 samples/s, speed: 4420.565508 tokens/s, learning rate: 2.845e-05, loss_scalings: 2814.750488, pp_loss: 7.500498
[INFO] 2021-07-12 19:29:23,413 [run_pretraining.py:  512]:	********exe.run_2846******* 
[INFO] 2021-07-12 19:29:24,441 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:24,446 [run_pretraining.py:  534]:	loss/total_loss, 7.248122215270996, 2847
[INFO] 2021-07-12 19:29:24,451 [run_pretraining.py:  535]:	loss/mlm_loss, 7.248122215270996, 2847
[INFO] 2021-07-12 19:29:24,457 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8459997338359244e-05, 2847
[INFO] 2021-07-12 19:29:24,467 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2847
[INFO] 2021-07-12 19:29:24,471 [run_pretraining.py:  558]:	worker_index: 3, step: 2847, cost: 7.248122, mlm loss: 7.248122, speed: 0.968138 steps/s, speed: 7.745104 samples/s, speed: 3965.493294 tokens/s, learning rate: 2.846e-05, loss_scalings: 2814.750488, pp_loss: 7.216492
[INFO] 2021-07-12 19:29:24,472 [run_pretraining.py:  512]:	********exe.run_2847******* 
[INFO] 2021-07-12 19:29:25,380 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:25,381 [run_pretraining.py:  534]:	loss/total_loss, 7.716920852661133, 2848
[INFO] 2021-07-12 19:29:25,381 [run_pretraining.py:  535]:	loss/mlm_loss, 7.716920852661133, 2848
[INFO] 2021-07-12 19:29:25,381 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8469999961089343e-05, 2848
[INFO] 2021-07-12 19:29:25,381 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2848
[INFO] 2021-07-12 19:29:25,381 [run_pretraining.py:  558]:	worker_index: 3, step: 2848, cost: 7.716921, mlm loss: 7.716921, speed: 1.100393 steps/s, speed: 8.803146 samples/s, speed: 4507.210722 tokens/s, learning rate: 2.847e-05, loss_scalings: 2814.750488, pp_loss: 7.508358
[INFO] 2021-07-12 19:29:25,381 [run_pretraining.py:  512]:	********exe.run_2848******* 
[INFO] 2021-07-12 19:29:26,298 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:26,298 [run_pretraining.py:  534]:	loss/total_loss, 7.241252899169922, 2849
[INFO] 2021-07-12 19:29:26,298 [run_pretraining.py:  535]:	loss/mlm_loss, 7.241252899169922, 2849
[INFO] 2021-07-12 19:29:26,299 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8479998945840634e-05, 2849
[INFO] 2021-07-12 19:29:26,299 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2849
[INFO] 2021-07-12 19:29:26,299 [run_pretraining.py:  558]:	worker_index: 3, step: 2849, cost: 7.241253, mlm loss: 7.241253, speed: 1.090556 steps/s, speed: 8.724445 samples/s, speed: 4466.915630 tokens/s, learning rate: 2.848e-05, loss_scalings: 2814.750488, pp_loss: 7.142497
[INFO] 2021-07-12 19:29:26,299 [run_pretraining.py:  512]:	********exe.run_2849******* 
[INFO] 2021-07-12 19:29:27,213 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:27,213 [run_pretraining.py:  534]:	loss/total_loss, 6.965360641479492, 2850
[INFO] 2021-07-12 19:29:27,214 [run_pretraining.py:  535]:	loss/mlm_loss, 6.965360641479492, 2850
[INFO] 2021-07-12 19:29:27,214 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.848999974958133e-05, 2850
[INFO] 2021-07-12 19:29:27,214 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2850
[INFO] 2021-07-12 19:29:27,214 [run_pretraining.py:  558]:	worker_index: 3, step: 2850, cost: 6.965361, mlm loss: 6.965361, speed: 1.093555 steps/s, speed: 8.748442 samples/s, speed: 4479.202494 tokens/s, learning rate: 2.849e-05, loss_scalings: 2814.750488, pp_loss: 7.114681
[INFO] 2021-07-12 19:29:27,214 [run_pretraining.py:  512]:	********exe.run_2850******* 
[INFO] 2021-07-12 19:29:28,135 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:28,136 [run_pretraining.py:  534]:	loss/total_loss, 6.648078918457031, 2851
[INFO] 2021-07-12 19:29:28,136 [run_pretraining.py:  535]:	loss/mlm_loss, 6.648078918457031, 2851
[INFO] 2021-07-12 19:29:28,136 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.849999873433262e-05, 2851
[INFO] 2021-07-12 19:29:28,136 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2851
[INFO] 2021-07-12 19:29:28,136 [run_pretraining.py:  558]:	worker_index: 3, step: 2851, cost: 6.648079, mlm loss: 6.648079, speed: 1.085312 steps/s, speed: 8.682495 samples/s, speed: 4445.437579 tokens/s, learning rate: 2.850e-05, loss_scalings: 2814.750488, pp_loss: 6.985377
[INFO] 2021-07-12 19:29:28,136 [run_pretraining.py:  512]:	********exe.run_2851******* 
[INFO] 2021-07-12 19:29:29,060 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:29,060 [run_pretraining.py:  534]:	loss/total_loss, 7.028735637664795, 2852
[INFO] 2021-07-12 19:29:29,060 [run_pretraining.py:  535]:	loss/mlm_loss, 7.028735637664795, 2852
[INFO] 2021-07-12 19:29:29,061 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.851000135706272e-05, 2852
[INFO] 2021-07-12 19:29:29,061 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2852
[INFO] 2021-07-12 19:29:29,061 [run_pretraining.py:  558]:	worker_index: 3, step: 2852, cost: 7.028736, mlm loss: 7.028736, speed: 1.081979 steps/s, speed: 8.655833 samples/s, speed: 4431.786517 tokens/s, learning rate: 2.851e-05, loss_scalings: 2814.750488, pp_loss: 6.325448
[INFO] 2021-07-12 19:29:29,061 [run_pretraining.py:  512]:	********exe.run_2852******* 
[INFO] 2021-07-12 19:29:30,086 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:30,087 [run_pretraining.py:  534]:	loss/total_loss, 7.003753662109375, 2853
[INFO] 2021-07-12 19:29:30,087 [run_pretraining.py:  535]:	loss/mlm_loss, 7.003753662109375, 2853
[INFO] 2021-07-12 19:29:30,087 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8519998522824608e-05, 2853
[INFO] 2021-07-12 19:29:30,087 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2853
[INFO] 2021-07-12 19:29:30,087 [run_pretraining.py:  558]:	worker_index: 3, step: 2853, cost: 7.003754, mlm loss: 7.003754, speed: 0.974698 steps/s, speed: 7.797588 samples/s, speed: 3992.364993 tokens/s, learning rate: 2.852e-05, loss_scalings: 2814.750488, pp_loss: 7.285460
[INFO] 2021-07-12 19:29:30,087 [run_pretraining.py:  512]:	********exe.run_2853******* 
[INFO] 2021-07-12 19:29:31,146 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:31,147 [run_pretraining.py:  534]:	loss/total_loss, 7.615707874298096, 2854
[INFO] 2021-07-12 19:29:31,147 [run_pretraining.py:  535]:	loss/mlm_loss, 7.615707874298096, 2854
[INFO] 2021-07-12 19:29:31,147 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.85299975075759e-05, 2854
[INFO] 2021-07-12 19:29:31,147 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2854
[INFO] 2021-07-12 19:29:31,147 [run_pretraining.py:  558]:	worker_index: 3, step: 2854, cost: 7.615708, mlm loss: 7.615708, speed: 0.944247 steps/s, speed: 7.553975 samples/s, speed: 3867.635185 tokens/s, learning rate: 2.853e-05, loss_scalings: 2814.750488, pp_loss: 7.607678
[INFO] 2021-07-12 19:29:31,147 [run_pretraining.py:  512]:	********exe.run_2854******* 
[INFO] 2021-07-12 19:29:32,200 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:32,201 [run_pretraining.py:  534]:	loss/total_loss, 7.567666053771973, 2855
[INFO] 2021-07-12 19:29:32,201 [run_pretraining.py:  535]:	loss/mlm_loss, 7.567666053771973, 2855
[INFO] 2021-07-12 19:29:32,201 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8540000130305998e-05, 2855
[INFO] 2021-07-12 19:29:32,201 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2855
[INFO] 2021-07-12 19:29:32,201 [run_pretraining.py:  558]:	worker_index: 3, step: 2855, cost: 7.567666, mlm loss: 7.567666, speed: 0.949212 steps/s, speed: 7.593696 samples/s, speed: 3887.972401 tokens/s, learning rate: 2.854e-05, loss_scalings: 2814.750488, pp_loss: 7.750376
[INFO] 2021-07-12 19:29:32,201 [run_pretraining.py:  512]:	********exe.run_2855******* 
[INFO] 2021-07-12 19:29:33,277 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:33,277 [run_pretraining.py:  534]:	loss/total_loss, 7.844085693359375, 2856
[INFO] 2021-07-12 19:29:33,277 [run_pretraining.py:  535]:	loss/mlm_loss, 7.844085693359375, 2856
[INFO] 2021-07-12 19:29:33,277 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.854999911505729e-05, 2856
[INFO] 2021-07-12 19:29:33,278 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2856
[INFO] 2021-07-12 19:29:33,278 [run_pretraining.py:  558]:	worker_index: 3, step: 2856, cost: 7.844086, mlm loss: 7.844086, speed: 0.929511 steps/s, speed: 7.436088 samples/s, speed: 3807.277004 tokens/s, learning rate: 2.855e-05, loss_scalings: 2814.750488, pp_loss: 7.569911
[INFO] 2021-07-12 19:29:33,278 [run_pretraining.py:  512]:	********exe.run_2856******* 
[INFO] 2021-07-12 19:29:34,351 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:34,352 [run_pretraining.py:  534]:	loss/total_loss, 7.118070125579834, 2857
[INFO] 2021-07-12 19:29:34,352 [run_pretraining.py:  535]:	loss/mlm_loss, 7.118070125579834, 2857
[INFO] 2021-07-12 19:29:34,352 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8559999918797985e-05, 2857
[INFO] 2021-07-12 19:29:34,352 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2857
[INFO] 2021-07-12 19:29:34,352 [run_pretraining.py:  558]:	worker_index: 3, step: 2857, cost: 7.118070, mlm loss: 7.118070, speed: 0.931435 steps/s, speed: 7.451477 samples/s, speed: 3815.156097 tokens/s, learning rate: 2.856e-05, loss_scalings: 2814.750488, pp_loss: 7.482316
[INFO] 2021-07-12 19:29:34,352 [run_pretraining.py:  512]:	********exe.run_2857******* 
[INFO] 2021-07-12 19:29:35,417 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:35,418 [run_pretraining.py:  534]:	loss/total_loss, 7.000959396362305, 2858
[INFO] 2021-07-12 19:29:35,418 [run_pretraining.py:  535]:	loss/mlm_loss, 7.000959396362305, 2858
[INFO] 2021-07-12 19:29:35,418 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8569998903549276e-05, 2858
[INFO] 2021-07-12 19:29:35,418 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2858
[INFO] 2021-07-12 19:29:35,418 [run_pretraining.py:  558]:	worker_index: 3, step: 2858, cost: 7.000959, mlm loss: 7.000959, speed: 0.938400 steps/s, speed: 7.507201 samples/s, speed: 3843.686760 tokens/s, learning rate: 2.857e-05, loss_scalings: 2814.750488, pp_loss: 7.412466
[INFO] 2021-07-12 19:29:35,418 [run_pretraining.py:  512]:	********exe.run_2858******* 
[INFO] 2021-07-12 19:29:36,484 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:36,484 [run_pretraining.py:  534]:	loss/total_loss, 6.915071964263916, 2859
[INFO] 2021-07-12 19:29:36,485 [run_pretraining.py:  535]:	loss/mlm_loss, 6.915071964263916, 2859
[INFO] 2021-07-12 19:29:36,485 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.857999970728997e-05, 2859
[INFO] 2021-07-12 19:29:36,485 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2859
[INFO] 2021-07-12 19:29:36,485 [run_pretraining.py:  558]:	worker_index: 3, step: 2859, cost: 6.915072, mlm loss: 6.915072, speed: 0.938100 steps/s, speed: 7.504798 samples/s, speed: 3842.456557 tokens/s, learning rate: 2.858e-05, loss_scalings: 2814.750488, pp_loss: 7.292836
[INFO] 2021-07-12 19:29:36,485 [run_pretraining.py:  512]:	********exe.run_2859******* 
[INFO] 2021-07-12 19:29:37,541 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:37,541 [run_pretraining.py:  534]:	loss/total_loss, 6.928557872772217, 2860
[INFO] 2021-07-12 19:29:37,541 [run_pretraining.py:  535]:	loss/mlm_loss, 6.928557872772217, 2860
[INFO] 2021-07-12 19:29:37,542 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8589998692041263e-05, 2860
[INFO] 2021-07-12 19:29:37,542 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2860
[INFO] 2021-07-12 19:29:37,542 [run_pretraining.py:  558]:	worker_index: 3, step: 2860, cost: 6.928558, mlm loss: 6.928558, speed: 0.946742 steps/s, speed: 7.573936 samples/s, speed: 3877.855467 tokens/s, learning rate: 2.859e-05, loss_scalings: 2814.750488, pp_loss: 7.194160
[INFO] 2021-07-12 19:29:37,542 [run_pretraining.py:  512]:	********exe.run_2860******* 
[INFO] 2021-07-12 19:29:38,596 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:38,596 [run_pretraining.py:  534]:	loss/total_loss, 7.023489475250244, 2861
[INFO] 2021-07-12 19:29:38,596 [run_pretraining.py:  535]:	loss/mlm_loss, 7.023489475250244, 2861
[INFO] 2021-07-12 19:29:38,596 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.860000131477136e-05, 2861
[INFO] 2021-07-12 19:29:38,597 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2861
[INFO] 2021-07-12 19:29:38,597 [run_pretraining.py:  558]:	worker_index: 3, step: 2861, cost: 7.023489, mlm loss: 7.023489, speed: 0.948470 steps/s, speed: 7.587758 samples/s, speed: 3884.932134 tokens/s, learning rate: 2.860e-05, loss_scalings: 2814.750488, pp_loss: 7.394471
[INFO] 2021-07-12 19:29:38,597 [run_pretraining.py:  512]:	********exe.run_2861******* 
[INFO] 2021-07-12 19:29:39,523 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:39,523 [run_pretraining.py:  534]:	loss/total_loss, 7.2820353507995605, 2862
[INFO] 2021-07-12 19:29:39,523 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2820353507995605, 2862
[INFO] 2021-07-12 19:29:39,523 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.860999848053325e-05, 2862
[INFO] 2021-07-12 19:29:39,523 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2862
[INFO] 2021-07-12 19:29:39,523 [run_pretraining.py:  558]:	worker_index: 3, step: 2862, cost: 7.282035, mlm loss: 7.282035, speed: 1.079714 steps/s, speed: 8.637715 samples/s, speed: 4422.510281 tokens/s, learning rate: 2.861e-05, loss_scalings: 2814.750488, pp_loss: 7.207042
[INFO] 2021-07-12 19:29:39,524 [run_pretraining.py:  512]:	********exe.run_2862******* 
[INFO] 2021-07-12 19:29:40,439 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:40,439 [run_pretraining.py:  534]:	loss/total_loss, 6.603472709655762, 2863
[INFO] 2021-07-12 19:29:40,439 [run_pretraining.py:  535]:	loss/mlm_loss, 6.603472709655762, 2863
[INFO] 2021-07-12 19:29:40,440 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.861999746528454e-05, 2863
[INFO] 2021-07-12 19:29:40,440 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2863
[INFO] 2021-07-12 19:29:40,440 [run_pretraining.py:  558]:	worker_index: 3, step: 2863, cost: 6.603473, mlm loss: 6.603473, speed: 1.092242 steps/s, speed: 8.737938 samples/s, speed: 4473.824072 tokens/s, learning rate: 2.862e-05, loss_scalings: 2814.750488, pp_loss: 7.286182
[INFO] 2021-07-12 19:29:40,440 [run_pretraining.py:  512]:	********exe.run_2863******* 
[INFO] 2021-07-12 19:29:41,353 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:41,354 [run_pretraining.py:  534]:	loss/total_loss, 7.9621968269348145, 2864
[INFO] 2021-07-12 19:29:41,354 [run_pretraining.py:  535]:	loss/mlm_loss, 7.9621968269348145, 2864
[INFO] 2021-07-12 19:29:41,354 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.863000008801464e-05, 2864
[INFO] 2021-07-12 19:29:41,354 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2864
[INFO] 2021-07-12 19:29:41,354 [run_pretraining.py:  558]:	worker_index: 3, step: 2864, cost: 7.962197, mlm loss: 7.962197, speed: 1.094378 steps/s, speed: 8.755026 samples/s, speed: 4482.573065 tokens/s, learning rate: 2.863e-05, loss_scalings: 2814.750488, pp_loss: 7.487877
[INFO] 2021-07-12 19:29:41,354 [run_pretraining.py:  512]:	********exe.run_2864******* 
[INFO] 2021-07-12 19:29:42,277 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:42,278 [run_pretraining.py:  534]:	loss/total_loss, 7.226203918457031, 2865
[INFO] 2021-07-12 19:29:42,278 [run_pretraining.py:  535]:	loss/mlm_loss, 7.226203918457031, 2865
[INFO] 2021-07-12 19:29:42,278 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.863999907276593e-05, 2865
[INFO] 2021-07-12 19:29:42,278 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2865
[INFO] 2021-07-12 19:29:42,278 [run_pretraining.py:  558]:	worker_index: 3, step: 2865, cost: 7.226204, mlm loss: 7.226204, speed: 1.083130 steps/s, speed: 8.665038 samples/s, speed: 4436.499390 tokens/s, learning rate: 2.864e-05, loss_scalings: 2814.750488, pp_loss: 7.275666
[INFO] 2021-07-12 19:29:42,278 [run_pretraining.py:  512]:	********exe.run_2865******* 
[INFO] 2021-07-12 19:29:43,186 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:43,187 [run_pretraining.py:  534]:	loss/total_loss, 7.691880702972412, 2866
[INFO] 2021-07-12 19:29:43,187 [run_pretraining.py:  535]:	loss/mlm_loss, 7.691880702972412, 2866
[INFO] 2021-07-12 19:29:43,187 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8649999876506627e-05, 2866
[INFO] 2021-07-12 19:29:43,187 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2866
[INFO] 2021-07-12 19:29:43,187 [run_pretraining.py:  558]:	worker_index: 3, step: 2866, cost: 7.691881, mlm loss: 7.691881, speed: 1.100565 steps/s, speed: 8.804520 samples/s, speed: 4507.914411 tokens/s, learning rate: 2.865e-05, loss_scalings: 2814.750488, pp_loss: 7.292119
[INFO] 2021-07-12 19:29:43,187 [run_pretraining.py:  512]:	********exe.run_2866******* 
[INFO] 2021-07-12 19:29:44,126 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:44,127 [run_pretraining.py:  534]:	loss/total_loss, 4.26383113861084, 2867
[INFO] 2021-07-12 19:29:44,127 [run_pretraining.py:  535]:	loss/mlm_loss, 4.26383113861084, 2867
[INFO] 2021-07-12 19:29:44,127 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8659998861257918e-05, 2867
[INFO] 2021-07-12 19:29:44,127 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2867
[INFO] 2021-07-12 19:29:44,127 [run_pretraining.py:  558]:	worker_index: 3, step: 2867, cost: 4.263831, mlm loss: 4.263831, speed: 1.064882 steps/s, speed: 8.519058 samples/s, speed: 4361.757803 tokens/s, learning rate: 2.866e-05, loss_scalings: 2814.750488, pp_loss: 6.294927
[INFO] 2021-07-12 19:29:44,127 [run_pretraining.py:  512]:	********exe.run_2867******* 
[INFO] 2021-07-12 19:29:45,036 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:45,037 [run_pretraining.py:  534]:	loss/total_loss, 7.0609259605407715, 2868
[INFO] 2021-07-12 19:29:45,037 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0609259605407715, 2868
[INFO] 2021-07-12 19:29:45,037 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8669999664998613e-05, 2868
[INFO] 2021-07-12 19:29:45,037 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2868
[INFO] 2021-07-12 19:29:45,037 [run_pretraining.py:  558]:	worker_index: 3, step: 2868, cost: 7.060926, mlm loss: 7.060926, speed: 1.099144 steps/s, speed: 8.793152 samples/s, speed: 4502.094010 tokens/s, learning rate: 2.867e-05, loss_scalings: 2814.750488, pp_loss: 7.159628
[INFO] 2021-07-12 19:29:45,037 [run_pretraining.py:  512]:	********exe.run_2868******* 
[INFO] 2021-07-12 19:29:45,951 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:45,952 [run_pretraining.py:  534]:	loss/total_loss, 7.855607509613037, 2869
[INFO] 2021-07-12 19:29:45,952 [run_pretraining.py:  535]:	loss/mlm_loss, 7.855607509613037, 2869
[INFO] 2021-07-12 19:29:45,952 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8679998649749905e-05, 2869
[INFO] 2021-07-12 19:29:45,952 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2869
[INFO] 2021-07-12 19:29:45,952 [run_pretraining.py:  558]:	worker_index: 3, step: 2869, cost: 7.855608, mlm loss: 7.855608, speed: 1.093792 steps/s, speed: 8.750336 samples/s, speed: 4480.172007 tokens/s, learning rate: 2.868e-05, loss_scalings: 2814.750488, pp_loss: 7.361442
[INFO] 2021-07-12 19:29:45,952 [run_pretraining.py:  512]:	********exe.run_2869******* 
[INFO] 2021-07-12 19:29:46,914 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:46,915 [run_pretraining.py:  534]:	loss/total_loss, 7.263444900512695, 2870
[INFO] 2021-07-12 19:29:46,915 [run_pretraining.py:  535]:	loss/mlm_loss, 7.263444900512695, 2870
[INFO] 2021-07-12 19:29:46,915 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8690001272480004e-05, 2870
[INFO] 2021-07-12 19:29:46,915 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2870
[INFO] 2021-07-12 19:29:46,915 [run_pretraining.py:  558]:	worker_index: 3, step: 2870, cost: 7.263445, mlm loss: 7.263445, speed: 1.039057 steps/s, speed: 8.312460 samples/s, speed: 4255.979333 tokens/s, learning rate: 2.869e-05, loss_scalings: 2814.750488, pp_loss: 7.453001
[INFO] 2021-07-12 19:29:46,915 [run_pretraining.py:  512]:	********exe.run_2870******* 
[INFO] 2021-07-12 19:29:47,928 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:47,928 [run_pretraining.py:  534]:	loss/total_loss, 7.464381217956543, 2871
[INFO] 2021-07-12 19:29:47,928 [run_pretraining.py:  535]:	loss/mlm_loss, 7.464381217956543, 2871
[INFO] 2021-07-12 19:29:47,928 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.869999843824189e-05, 2871
[INFO] 2021-07-12 19:29:47,928 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2871
[INFO] 2021-07-12 19:29:47,929 [run_pretraining.py:  558]:	worker_index: 3, step: 2871, cost: 7.464381, mlm loss: 7.464381, speed: 0.987500 steps/s, speed: 7.899999 samples/s, speed: 4044.799482 tokens/s, learning rate: 2.870e-05, loss_scalings: 2814.750488, pp_loss: 7.224065
[INFO] 2021-07-12 19:29:47,929 [run_pretraining.py:  512]:	********exe.run_2871******* 
[INFO] 2021-07-12 19:29:48,906 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:48,907 [run_pretraining.py:  534]:	loss/total_loss, 7.103751182556152, 2872
[INFO] 2021-07-12 19:29:48,907 [run_pretraining.py:  535]:	loss/mlm_loss, 7.103751182556152, 2872
[INFO] 2021-07-12 19:29:48,907 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8709997422993183e-05, 2872
[INFO] 2021-07-12 19:29:48,907 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2872
[INFO] 2021-07-12 19:29:48,907 [run_pretraining.py:  558]:	worker_index: 3, step: 2872, cost: 7.103751, mlm loss: 7.103751, speed: 1.022278 steps/s, speed: 8.178225 samples/s, speed: 4187.251303 tokens/s, learning rate: 2.871e-05, loss_scalings: 2814.750488, pp_loss: 7.262409
[INFO] 2021-07-12 19:29:48,907 [run_pretraining.py:  512]:	********exe.run_2872******* 
[INFO] 2021-07-12 19:29:49,893 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:49,893 [run_pretraining.py:  534]:	loss/total_loss, 7.3830108642578125, 2873
[INFO] 2021-07-12 19:29:49,894 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3830108642578125, 2873
[INFO] 2021-07-12 19:29:49,894 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8720000045723282e-05, 2873
[INFO] 2021-07-12 19:29:49,894 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2873
[INFO] 2021-07-12 19:29:49,894 [run_pretraining.py:  558]:	worker_index: 3, step: 2873, cost: 7.383011, mlm loss: 7.383011, speed: 1.014465 steps/s, speed: 8.115721 samples/s, speed: 4155.249122 tokens/s, learning rate: 2.872e-05, loss_scalings: 2814.750488, pp_loss: 7.132340
[INFO] 2021-07-12 19:29:49,894 [run_pretraining.py:  512]:	********exe.run_2873******* 
[INFO] 2021-07-12 19:29:50,864 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:50,865 [run_pretraining.py:  534]:	loss/total_loss, 7.265867710113525, 2874
[INFO] 2021-07-12 19:29:50,865 [run_pretraining.py:  535]:	loss/mlm_loss, 7.265867710113525, 2874
[INFO] 2021-07-12 19:29:50,865 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8729999030474573e-05, 2874
[INFO] 2021-07-12 19:29:50,865 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2874
[INFO] 2021-07-12 19:29:50,865 [run_pretraining.py:  558]:	worker_index: 3, step: 2874, cost: 7.265868, mlm loss: 7.265868, speed: 1.030394 steps/s, speed: 8.243151 samples/s, speed: 4220.493522 tokens/s, learning rate: 2.873e-05, loss_scalings: 2814.750488, pp_loss: 7.561518
[INFO] 2021-07-12 19:29:50,865 [run_pretraining.py:  512]:	********exe.run_2874******* 
[INFO] 2021-07-12 19:29:51,857 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:51,858 [run_pretraining.py:  534]:	loss/total_loss, 7.0983171463012695, 2875
[INFO] 2021-07-12 19:29:51,858 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0983171463012695, 2875
[INFO] 2021-07-12 19:29:51,858 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.873999983421527e-05, 2875
[INFO] 2021-07-12 19:29:51,858 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2875
[INFO] 2021-07-12 19:29:51,858 [run_pretraining.py:  558]:	worker_index: 3, step: 2875, cost: 7.098317, mlm loss: 7.098317, speed: 1.007362 steps/s, speed: 8.058893 samples/s, speed: 4126.152968 tokens/s, learning rate: 2.874e-05, loss_scalings: 2814.750488, pp_loss: 7.192101
[INFO] 2021-07-12 19:29:51,858 [run_pretraining.py:  512]:	********exe.run_2875******* 
[INFO] 2021-07-12 19:29:52,864 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:52,864 [run_pretraining.py:  534]:	loss/total_loss, 8.482978820800781, 2876
[INFO] 2021-07-12 19:29:52,864 [run_pretraining.py:  535]:	loss/mlm_loss, 8.482978820800781, 2876
[INFO] 2021-07-12 19:29:52,864 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.874999881896656e-05, 2876
[INFO] 2021-07-12 19:29:52,864 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2876
[INFO] 2021-07-12 19:29:52,865 [run_pretraining.py:  558]:	worker_index: 3, step: 2876, cost: 8.482979, mlm loss: 8.482979, speed: 0.994358 steps/s, speed: 7.954863 samples/s, speed: 4072.889919 tokens/s, learning rate: 2.875e-05, loss_scalings: 2814.750488, pp_loss: 7.373819
[INFO] 2021-07-12 19:29:52,865 [run_pretraining.py:  512]:	********exe.run_2876******* 
[INFO] 2021-07-12 19:29:53,858 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:53,859 [run_pretraining.py:  534]:	loss/total_loss, 6.5232391357421875, 2877
[INFO] 2021-07-12 19:29:53,859 [run_pretraining.py:  535]:	loss/mlm_loss, 6.5232391357421875, 2877
[INFO] 2021-07-12 19:29:53,859 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8759999622707255e-05, 2877
[INFO] 2021-07-12 19:29:53,859 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2877
[INFO] 2021-07-12 19:29:53,859 [run_pretraining.py:  558]:	worker_index: 3, step: 2877, cost: 6.523239, mlm loss: 6.523239, speed: 1.005973 steps/s, speed: 8.047780 samples/s, speed: 4120.463602 tokens/s, learning rate: 2.876e-05, loss_scalings: 2814.750488, pp_loss: 7.080097
[INFO] 2021-07-12 19:29:53,859 [run_pretraining.py:  512]:	********exe.run_2877******* 
[INFO] 2021-07-12 19:29:54,767 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:54,768 [run_pretraining.py:  534]:	loss/total_loss, 6.983499050140381, 2878
[INFO] 2021-07-12 19:29:54,768 [run_pretraining.py:  535]:	loss/mlm_loss, 6.983499050140381, 2878
[INFO] 2021-07-12 19:29:54,768 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8769998607458547e-05, 2878
[INFO] 2021-07-12 19:29:54,768 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2878
[INFO] 2021-07-12 19:29:54,768 [run_pretraining.py:  558]:	worker_index: 3, step: 2878, cost: 6.983499, mlm loss: 6.983499, speed: 1.101339 steps/s, speed: 8.810709 samples/s, speed: 4511.083139 tokens/s, learning rate: 2.877e-05, loss_scalings: 2814.750488, pp_loss: 7.057791
[INFO] 2021-07-12 19:29:54,768 [run_pretraining.py:  512]:	********exe.run_2878******* 
[INFO] 2021-07-12 19:29:55,686 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:55,686 [run_pretraining.py:  534]:	loss/total_loss, 7.544694900512695, 2879
[INFO] 2021-07-12 19:29:55,686 [run_pretraining.py:  535]:	loss/mlm_loss, 7.544694900512695, 2879
[INFO] 2021-07-12 19:29:55,686 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8780001230188645e-05, 2879
[INFO] 2021-07-12 19:29:55,686 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2879
[INFO] 2021-07-12 19:29:55,687 [run_pretraining.py:  558]:	worker_index: 3, step: 2879, cost: 7.544695, mlm loss: 7.544695, speed: 1.089342 steps/s, speed: 8.714733 samples/s, speed: 4461.943252 tokens/s, learning rate: 2.878e-05, loss_scalings: 2814.750488, pp_loss: 7.454064
[INFO] 2021-07-12 19:29:55,687 [run_pretraining.py:  512]:	********exe.run_2879******* 
[INFO] 2021-07-12 19:29:56,600 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:56,601 [run_pretraining.py:  534]:	loss/total_loss, 6.818848609924316, 2880
[INFO] 2021-07-12 19:29:56,601 [run_pretraining.py:  535]:	loss/mlm_loss, 6.818848609924316, 2880
[INFO] 2021-07-12 19:29:56,601 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8790000214939937e-05, 2880
[INFO] 2021-07-12 19:29:56,601 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2880
[INFO] 2021-07-12 19:29:56,601 [run_pretraining.py:  558]:	worker_index: 3, step: 2880, cost: 6.818849, mlm loss: 6.818849, speed: 1.094085 steps/s, speed: 8.752680 samples/s, speed: 4481.372214 tokens/s, learning rate: 2.879e-05, loss_scalings: 2814.750488, pp_loss: 7.168439
[INFO] 2021-07-12 19:29:56,601 [run_pretraining.py:  512]:	********exe.run_2880******* 
[INFO] 2021-07-12 19:29:57,515 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:57,515 [run_pretraining.py:  534]:	loss/total_loss, 7.517946243286133, 2881
[INFO] 2021-07-12 19:29:57,515 [run_pretraining.py:  535]:	loss/mlm_loss, 7.517946243286133, 2881
[INFO] 2021-07-12 19:29:57,515 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8799997380701825e-05, 2881
[INFO] 2021-07-12 19:29:57,516 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2881
[INFO] 2021-07-12 19:29:57,516 [run_pretraining.py:  558]:	worker_index: 3, step: 2881, cost: 7.517946, mlm loss: 7.517946, speed: 1.094260 steps/s, speed: 8.754080 samples/s, speed: 4482.088905 tokens/s, learning rate: 2.880e-05, loss_scalings: 2814.750488, pp_loss: 7.232217
[INFO] 2021-07-12 19:29:57,516 [run_pretraining.py:  512]:	********exe.run_2881******* 
[INFO] 2021-07-12 19:29:58,426 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:58,426 [run_pretraining.py:  534]:	loss/total_loss, 6.642823219299316, 2882
[INFO] 2021-07-12 19:29:58,426 [run_pretraining.py:  535]:	loss/mlm_loss, 6.642823219299316, 2882
[INFO] 2021-07-12 19:29:58,427 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8810000003431924e-05, 2882
[INFO] 2021-07-12 19:29:58,427 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2882
[INFO] 2021-07-12 19:29:58,427 [run_pretraining.py:  558]:	worker_index: 3, step: 2882, cost: 6.642823, mlm loss: 6.642823, speed: 1.098421 steps/s, speed: 8.787365 samples/s, speed: 4499.131117 tokens/s, learning rate: 2.881e-05, loss_scalings: 2814.750488, pp_loss: 7.528593
[INFO] 2021-07-12 19:29:58,427 [run_pretraining.py:  512]:	********exe.run_2882******* 
[INFO] 2021-07-12 19:29:59,342 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:59,342 [run_pretraining.py:  534]:	loss/total_loss, 7.207589626312256, 2883
[INFO] 2021-07-12 19:29:59,342 [run_pretraining.py:  535]:	loss/mlm_loss, 7.207589626312256, 2883
[INFO] 2021-07-12 19:29:59,342 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8819998988183215e-05, 2883
[INFO] 2021-07-12 19:29:59,343 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2883
[INFO] 2021-07-12 19:29:59,343 [run_pretraining.py:  558]:	worker_index: 3, step: 2883, cost: 7.207590, mlm loss: 7.207590, speed: 1.092610 steps/s, speed: 8.740876 samples/s, speed: 4475.328634 tokens/s, learning rate: 2.882e-05, loss_scalings: 2814.750488, pp_loss: 7.486437
[INFO] 2021-07-12 19:29:59,343 [run_pretraining.py:  512]:	********exe.run_2883******* 
[INFO] 2021-07-12 19:30:00,256 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:00,257 [run_pretraining.py:  534]:	loss/total_loss, 7.82190465927124, 2884
[INFO] 2021-07-12 19:30:00,257 [run_pretraining.py:  535]:	loss/mlm_loss, 7.82190465927124, 2884
[INFO] 2021-07-12 19:30:00,257 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.882999979192391e-05, 2884
[INFO] 2021-07-12 19:30:00,257 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2884
[INFO] 2021-07-12 19:30:00,257 [run_pretraining.py:  558]:	worker_index: 3, step: 2884, cost: 7.821905, mlm loss: 7.821905, speed: 1.094196 steps/s, speed: 8.753566 samples/s, speed: 4481.825819 tokens/s, learning rate: 2.883e-05, loss_scalings: 2814.750488, pp_loss: 7.502187
[INFO] 2021-07-12 19:30:00,257 [run_pretraining.py:  512]:	********exe.run_2884******* 
[INFO] 2021-07-12 19:30:01,188 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:01,188 [run_pretraining.py:  534]:	loss/total_loss, 7.027280807495117, 2885
[INFO] 2021-07-12 19:30:01,189 [run_pretraining.py:  535]:	loss/mlm_loss, 7.027280807495117, 2885
[INFO] 2021-07-12 19:30:01,189 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8839998776675202e-05, 2885
[INFO] 2021-07-12 19:30:01,189 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2885
[INFO] 2021-07-12 19:30:01,189 [run_pretraining.py:  558]:	worker_index: 3, step: 2885, cost: 7.027281, mlm loss: 7.027281, speed: 1.074082 steps/s, speed: 8.592656 samples/s, speed: 4399.439690 tokens/s, learning rate: 2.884e-05, loss_scalings: 2814.750488, pp_loss: 7.106723
[INFO] 2021-07-12 19:30:01,189 [run_pretraining.py:  512]:	********exe.run_2885******* 
[INFO] 2021-07-12 19:30:02,104 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:02,105 [run_pretraining.py:  534]:	loss/total_loss, 7.455746650695801, 2886
[INFO] 2021-07-12 19:30:02,105 [run_pretraining.py:  535]:	loss/mlm_loss, 7.455746650695801, 2886
[INFO] 2021-07-12 19:30:02,105 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8849999580415897e-05, 2886
[INFO] 2021-07-12 19:30:02,105 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2886
[INFO] 2021-07-12 19:30:02,105 [run_pretraining.py:  558]:	worker_index: 3, step: 2886, cost: 7.455747, mlm loss: 7.455747, speed: 1.091771 steps/s, speed: 8.734167 samples/s, speed: 4471.893282 tokens/s, learning rate: 2.885e-05, loss_scalings: 2814.750488, pp_loss: 7.222015
[INFO] 2021-07-12 19:30:02,105 [run_pretraining.py:  512]:	********exe.run_2886******* 
[INFO] 2021-07-12 19:30:03,021 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:03,022 [run_pretraining.py:  534]:	loss/total_loss, 6.738852024078369, 2887
[INFO] 2021-07-12 19:30:03,022 [run_pretraining.py:  535]:	loss/mlm_loss, 6.738852024078369, 2887
[INFO] 2021-07-12 19:30:03,022 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.885999856516719e-05, 2887
[INFO] 2021-07-12 19:30:03,022 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2887
[INFO] 2021-07-12 19:30:03,022 [run_pretraining.py:  558]:	worker_index: 3, step: 2887, cost: 6.738852, mlm loss: 6.738852, speed: 1.091775 steps/s, speed: 8.734201 samples/s, speed: 4471.910742 tokens/s, learning rate: 2.886e-05, loss_scalings: 2814.750488, pp_loss: 6.679749
[INFO] 2021-07-12 19:30:03,022 [run_pretraining.py:  512]:	********exe.run_2887******* 
[INFO] 2021-07-12 19:30:03,934 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:03,935 [run_pretraining.py:  534]:	loss/total_loss, 7.692374229431152, 2888
[INFO] 2021-07-12 19:30:03,935 [run_pretraining.py:  535]:	loss/mlm_loss, 7.692374229431152, 2888
[INFO] 2021-07-12 19:30:03,935 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8870001187897287e-05, 2888
[INFO] 2021-07-12 19:30:03,935 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2888
[INFO] 2021-07-12 19:30:03,935 [run_pretraining.py:  558]:	worker_index: 3, step: 2888, cost: 7.692374, mlm loss: 7.692374, speed: 1.095801 steps/s, speed: 8.766412 samples/s, speed: 4488.402872 tokens/s, learning rate: 2.887e-05, loss_scalings: 2814.750488, pp_loss: 7.376770
[INFO] 2021-07-12 19:30:03,935 [run_pretraining.py:  512]:	********exe.run_2888******* 
[INFO] 2021-07-12 19:30:04,844 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:04,844 [run_pretraining.py:  534]:	loss/total_loss, 7.252521991729736, 2889
[INFO] 2021-07-12 19:30:04,844 [run_pretraining.py:  535]:	loss/mlm_loss, 7.252521991729736, 2889
[INFO] 2021-07-12 19:30:04,844 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.888000017264858e-05, 2889
[INFO] 2021-07-12 19:30:04,845 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2889
[INFO] 2021-07-12 19:30:04,845 [run_pretraining.py:  558]:	worker_index: 3, step: 2889, cost: 7.252522, mlm loss: 7.252522, speed: 1.100283 steps/s, speed: 8.802266 samples/s, speed: 4506.760240 tokens/s, learning rate: 2.888e-05, loss_scalings: 2814.750488, pp_loss: 6.653996
[INFO] 2021-07-12 19:30:04,845 [run_pretraining.py:  512]:	********exe.run_2889******* 
[INFO] 2021-07-12 19:30:05,768 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:05,769 [run_pretraining.py:  534]:	loss/total_loss, 6.81056022644043, 2890
[INFO] 2021-07-12 19:30:05,769 [run_pretraining.py:  535]:	loss/mlm_loss, 6.81056022644043, 2890
[INFO] 2021-07-12 19:30:05,769 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8889997338410467e-05, 2890
[INFO] 2021-07-12 19:30:05,769 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2890
[INFO] 2021-07-12 19:30:05,769 [run_pretraining.py:  558]:	worker_index: 3, step: 2890, cost: 6.810560, mlm loss: 6.810560, speed: 1.082162 steps/s, speed: 8.657298 samples/s, speed: 4432.536610 tokens/s, learning rate: 2.889e-05, loss_scalings: 2814.750488, pp_loss: 7.087663
[INFO] 2021-07-12 19:30:05,769 [run_pretraining.py:  512]:	********exe.run_2890******* 
[INFO] 2021-07-12 19:30:06,680 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:06,681 [run_pretraining.py:  534]:	loss/total_loss, 7.789546489715576, 2891
[INFO] 2021-07-12 19:30:06,681 [run_pretraining.py:  535]:	loss/mlm_loss, 7.789546489715576, 2891
[INFO] 2021-07-12 19:30:06,681 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8899999961140566e-05, 2891
[INFO] 2021-07-12 19:30:06,681 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2891
[INFO] 2021-07-12 19:30:06,681 [run_pretraining.py:  558]:	worker_index: 3, step: 2891, cost: 7.789546, mlm loss: 7.789546, speed: 1.097377 steps/s, speed: 8.779013 samples/s, speed: 4494.854604 tokens/s, learning rate: 2.890e-05, loss_scalings: 2814.750488, pp_loss: 7.284505
[INFO] 2021-07-12 19:30:06,681 [run_pretraining.py:  512]:	********exe.run_2891******* 
[INFO] 2021-07-12 19:30:07,596 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:07,596 [run_pretraining.py:  534]:	loss/total_loss, 6.998165130615234, 2892
[INFO] 2021-07-12 19:30:07,597 [run_pretraining.py:  535]:	loss/mlm_loss, 6.998165130615234, 2892
[INFO] 2021-07-12 19:30:07,597 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8909998945891857e-05, 2892
[INFO] 2021-07-12 19:30:07,597 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2892
[INFO] 2021-07-12 19:30:07,597 [run_pretraining.py:  558]:	worker_index: 3, step: 2892, cost: 6.998165, mlm loss: 6.998165, speed: 1.092999 steps/s, speed: 8.743995 samples/s, speed: 4476.925206 tokens/s, learning rate: 2.891e-05, loss_scalings: 2814.750488, pp_loss: 7.143232
[INFO] 2021-07-12 19:30:07,597 [run_pretraining.py:  512]:	********exe.run_2892******* 
[INFO] 2021-07-12 19:30:08,514 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:08,515 [run_pretraining.py:  534]:	loss/total_loss, 7.133541107177734, 2893
[INFO] 2021-07-12 19:30:08,515 [run_pretraining.py:  535]:	loss/mlm_loss, 7.133541107177734, 2893
[INFO] 2021-07-12 19:30:08,515 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8919999749632552e-05, 2893
[INFO] 2021-07-12 19:30:08,515 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2893
[INFO] 2021-07-12 19:30:08,515 [run_pretraining.py:  558]:	worker_index: 3, step: 2893, cost: 7.133541, mlm loss: 7.133541, speed: 1.089692 steps/s, speed: 8.717536 samples/s, speed: 4463.378373 tokens/s, learning rate: 2.892e-05, loss_scalings: 2814.750488, pp_loss: 6.284926
[INFO] 2021-07-12 19:30:08,515 [run_pretraining.py:  512]:	********exe.run_2893******* 
[INFO] 2021-07-12 19:30:09,429 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:09,430 [run_pretraining.py:  534]:	loss/total_loss, 7.096336364746094, 2894
[INFO] 2021-07-12 19:30:09,430 [run_pretraining.py:  535]:	loss/mlm_loss, 7.096336364746094, 2894
[INFO] 2021-07-12 19:30:09,430 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8929998734383844e-05, 2894
[INFO] 2021-07-12 19:30:09,430 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2894
[INFO] 2021-07-12 19:30:09,430 [run_pretraining.py:  558]:	worker_index: 3, step: 2894, cost: 7.096336, mlm loss: 7.096336, speed: 1.093621 steps/s, speed: 8.748969 samples/s, speed: 4479.472280 tokens/s, learning rate: 2.893e-05, loss_scalings: 2814.750488, pp_loss: 7.173907
[INFO] 2021-07-12 19:30:09,430 [run_pretraining.py:  512]:	********exe.run_2894******* 
[INFO] 2021-07-12 19:30:10,356 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:10,357 [run_pretraining.py:  534]:	loss/total_loss, 7.211195945739746, 2895
[INFO] 2021-07-12 19:30:10,357 [run_pretraining.py:  535]:	loss/mlm_loss, 7.211195945739746, 2895
[INFO] 2021-07-12 19:30:10,357 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.893999953812454e-05, 2895
[INFO] 2021-07-12 19:30:10,357 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2895
[INFO] 2021-07-12 19:30:10,357 [run_pretraining.py:  558]:	worker_index: 3, step: 2895, cost: 7.211196, mlm loss: 7.211196, speed: 1.079307 steps/s, speed: 8.634459 samples/s, speed: 4420.843066 tokens/s, learning rate: 2.894e-05, loss_scalings: 2814.750488, pp_loss: 7.063006
[INFO] 2021-07-12 19:30:10,357 [run_pretraining.py:  512]:	********exe.run_2895******* 
[INFO] 2021-07-12 19:30:11,273 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:11,273 [run_pretraining.py:  534]:	loss/total_loss, 7.6877851486206055, 2896
[INFO] 2021-07-12 19:30:11,274 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6877851486206055, 2896
[INFO] 2021-07-12 19:30:11,274 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.894999852287583e-05, 2896
[INFO] 2021-07-12 19:30:11,274 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2896
[INFO] 2021-07-12 19:30:11,274 [run_pretraining.py:  558]:	worker_index: 3, step: 2896, cost: 7.687785, mlm loss: 7.687785, speed: 1.091883 steps/s, speed: 8.735062 samples/s, speed: 4472.351955 tokens/s, learning rate: 2.895e-05, loss_scalings: 2814.750488, pp_loss: 7.439131
[INFO] 2021-07-12 19:30:11,274 [run_pretraining.py:  512]:	********exe.run_2896******* 
[INFO] 2021-07-12 19:30:12,186 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:12,187 [run_pretraining.py:  534]:	loss/total_loss, 8.215068817138672, 2897
[INFO] 2021-07-12 19:30:12,187 [run_pretraining.py:  535]:	loss/mlm_loss, 8.215068817138672, 2897
[INFO] 2021-07-12 19:30:12,187 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.896000114560593e-05, 2897
[INFO] 2021-07-12 19:30:12,187 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2897
[INFO] 2021-07-12 19:30:12,187 [run_pretraining.py:  558]:	worker_index: 3, step: 2897, cost: 8.215069, mlm loss: 8.215069, speed: 1.095746 steps/s, speed: 8.765965 samples/s, speed: 4488.174220 tokens/s, learning rate: 2.896e-05, loss_scalings: 2814.750488, pp_loss: 7.554603
[INFO] 2021-07-12 19:30:12,187 [run_pretraining.py:  512]:	********exe.run_2897******* 
[INFO] 2021-07-12 19:30:13,097 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:13,098 [run_pretraining.py:  534]:	loss/total_loss, 7.755735874176025, 2898
[INFO] 2021-07-12 19:30:13,098 [run_pretraining.py:  535]:	loss/mlm_loss, 7.755735874176025, 2898
[INFO] 2021-07-12 19:30:13,098 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.897000013035722e-05, 2898
[INFO] 2021-07-12 19:30:13,098 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2898
[INFO] 2021-07-12 19:30:13,098 [run_pretraining.py:  558]:	worker_index: 3, step: 2898, cost: 7.755736, mlm loss: 7.755736, speed: 1.098480 steps/s, speed: 8.787842 samples/s, speed: 4499.375028 tokens/s, learning rate: 2.897e-05, loss_scalings: 2814.750488, pp_loss: 7.502161
[INFO] 2021-07-12 19:30:13,098 [run_pretraining.py:  512]:	********exe.run_2898******* 
[INFO] 2021-07-12 19:30:14,011 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:14,012 [run_pretraining.py:  534]:	loss/total_loss, 6.900686740875244, 2899
[INFO] 2021-07-12 19:30:14,012 [run_pretraining.py:  535]:	loss/mlm_loss, 6.900686740875244, 2899
[INFO] 2021-07-12 19:30:14,012 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.897999729611911e-05, 2899
[INFO] 2021-07-12 19:30:14,012 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2899
[INFO] 2021-07-12 19:30:14,012 [run_pretraining.py:  558]:	worker_index: 3, step: 2899, cost: 6.900687, mlm loss: 6.900687, speed: 1.094768 steps/s, speed: 8.758145 samples/s, speed: 4484.170128 tokens/s, learning rate: 2.898e-05, loss_scalings: 2814.750488, pp_loss: 6.646728
[INFO] 2021-07-12 19:30:14,012 [run_pretraining.py:  512]:	********exe.run_2899******* 
[INFO] 2021-07-12 19:30:14,934 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:14,935 [run_pretraining.py:  534]:	loss/total_loss, 7.27994441986084, 2900
[INFO] 2021-07-12 19:30:14,935 [run_pretraining.py:  535]:	loss/mlm_loss, 7.27994441986084, 2900
[INFO] 2021-07-12 19:30:14,935 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8989999918849207e-05, 2900
[INFO] 2021-07-12 19:30:14,935 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2900
[INFO] 2021-07-12 19:30:14,935 [run_pretraining.py:  558]:	worker_index: 3, step: 2900, cost: 7.279944, mlm loss: 7.279944, speed: 1.084482 steps/s, speed: 8.675857 samples/s, speed: 4442.038757 tokens/s, learning rate: 2.899e-05, loss_scalings: 2814.750488, pp_loss: 7.195184
[INFO] 2021-07-12 19:30:14,935 [run_pretraining.py:  512]:	********exe.run_2900******* 
[INFO] 2021-07-12 19:30:15,842 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:15,842 [run_pretraining.py:  534]:	loss/total_loss, 7.953248977661133, 2901
[INFO] 2021-07-12 19:30:15,842 [run_pretraining.py:  535]:	loss/mlm_loss, 7.953248977661133, 2901
[INFO] 2021-07-12 19:30:15,842 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.89999989036005e-05, 2901
[INFO] 2021-07-12 19:30:15,842 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2901
[INFO] 2021-07-12 19:30:15,842 [run_pretraining.py:  558]:	worker_index: 3, step: 2901, cost: 7.953249, mlm loss: 7.953249, speed: 1.102570 steps/s, speed: 8.820557 samples/s, speed: 4516.125341 tokens/s, learning rate: 2.900e-05, loss_scalings: 2814.750488, pp_loss: 7.378702
[INFO] 2021-07-12 19:30:15,843 [run_pretraining.py:  512]:	********exe.run_2901******* 
[INFO] 2021-07-12 19:30:16,758 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:16,759 [run_pretraining.py:  534]:	loss/total_loss, 8.028738021850586, 2902
[INFO] 2021-07-12 19:30:16,759 [run_pretraining.py:  535]:	loss/mlm_loss, 8.028738021850586, 2902
[INFO] 2021-07-12 19:30:16,759 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9009999707341194e-05, 2902
[INFO] 2021-07-12 19:30:16,759 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2902
[INFO] 2021-07-12 19:30:16,759 [run_pretraining.py:  558]:	worker_index: 3, step: 2902, cost: 8.028738, mlm loss: 8.028738, speed: 1.091675 steps/s, speed: 8.733398 samples/s, speed: 4471.499875 tokens/s, learning rate: 2.901e-05, loss_scalings: 2814.750488, pp_loss: 7.439536
[INFO] 2021-07-12 19:30:16,759 [run_pretraining.py:  512]:	********exe.run_2902******* 
[INFO] 2021-07-12 19:30:17,671 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:17,671 [run_pretraining.py:  534]:	loss/total_loss, 7.197431564331055, 2903
[INFO] 2021-07-12 19:30:17,671 [run_pretraining.py:  535]:	loss/mlm_loss, 7.197431564331055, 2903
[INFO] 2021-07-12 19:30:17,671 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9019998692092486e-05, 2903
[INFO] 2021-07-12 19:30:17,672 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2903
[INFO] 2021-07-12 19:30:17,672 [run_pretraining.py:  558]:	worker_index: 3, step: 2903, cost: 7.197432, mlm loss: 7.197432, speed: 1.096707 steps/s, speed: 8.773660 samples/s, speed: 4492.113818 tokens/s, learning rate: 2.902e-05, loss_scalings: 2814.750488, pp_loss: 7.111078
[INFO] 2021-07-12 19:30:17,672 [run_pretraining.py:  512]:	********exe.run_2903******* 
[INFO] 2021-07-12 19:30:18,615 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:18,616 [run_pretraining.py:  534]:	loss/total_loss, 7.674804210662842, 2904
[INFO] 2021-07-12 19:30:18,616 [run_pretraining.py:  535]:	loss/mlm_loss, 7.674804210662842, 2904
[INFO] 2021-07-12 19:30:18,616 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9030001314822584e-05, 2904
[INFO] 2021-07-12 19:30:18,616 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2904
[INFO] 2021-07-12 19:30:18,616 [run_pretraining.py:  558]:	worker_index: 3, step: 2904, cost: 7.674804, mlm loss: 7.674804, speed: 1.059645 steps/s, speed: 8.477156 samples/s, speed: 4340.303941 tokens/s, learning rate: 2.903e-05, loss_scalings: 2814.750488, pp_loss: 7.384940
[INFO] 2021-07-12 19:30:18,616 [run_pretraining.py:  512]:	********exe.run_2904******* 
[INFO] 2021-07-12 19:30:19,536 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:19,536 [run_pretraining.py:  534]:	loss/total_loss, 7.208615303039551, 2905
[INFO] 2021-07-12 19:30:19,536 [run_pretraining.py:  535]:	loss/mlm_loss, 7.208615303039551, 2905
[INFO] 2021-07-12 19:30:19,536 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9039998480584472e-05, 2905
[INFO] 2021-07-12 19:30:19,536 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2905
[INFO] 2021-07-12 19:30:19,536 [run_pretraining.py:  558]:	worker_index: 3, step: 2905, cost: 7.208615, mlm loss: 7.208615, speed: 1.087046 steps/s, speed: 8.696368 samples/s, speed: 4452.540477 tokens/s, learning rate: 2.904e-05, loss_scalings: 2814.750488, pp_loss: 7.346268
[INFO] 2021-07-12 19:30:19,537 [run_pretraining.py:  512]:	********exe.run_2905******* 
[INFO] 2021-07-12 19:30:20,473 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:20,474 [run_pretraining.py:  534]:	loss/total_loss, 7.203919410705566, 2906
[INFO] 2021-07-12 19:30:20,474 [run_pretraining.py:  535]:	loss/mlm_loss, 7.203919410705566, 2906
[INFO] 2021-07-12 19:30:20,474 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9049997465335764e-05, 2906
[INFO] 2021-07-12 19:30:20,474 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2906
[INFO] 2021-07-12 19:30:20,474 [run_pretraining.py:  558]:	worker_index: 3, step: 2906, cost: 7.203919, mlm loss: 7.203919, speed: 1.067335 steps/s, speed: 8.538682 samples/s, speed: 4371.805049 tokens/s, learning rate: 2.905e-05, loss_scalings: 2814.750488, pp_loss: 6.675870
[INFO] 2021-07-12 19:30:20,474 [run_pretraining.py:  512]:	********exe.run_2906******* 
[INFO] 2021-07-12 19:30:21,380 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:21,381 [run_pretraining.py:  534]:	loss/total_loss, 7.653805255889893, 2907
[INFO] 2021-07-12 19:30:21,381 [run_pretraining.py:  535]:	loss/mlm_loss, 7.653805255889893, 2907
[INFO] 2021-07-12 19:30:21,381 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9060000088065863e-05, 2907
[INFO] 2021-07-12 19:30:21,381 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2907
[INFO] 2021-07-12 19:30:21,381 [run_pretraining.py:  558]:	worker_index: 3, step: 2907, cost: 7.653805, mlm loss: 7.653805, speed: 1.103081 steps/s, speed: 8.824649 samples/s, speed: 4518.220477 tokens/s, learning rate: 2.906e-05, loss_scalings: 2814.750488, pp_loss: 7.455441
[INFO] 2021-07-12 19:30:21,381 [run_pretraining.py:  512]:	********exe.run_2907******* 
[INFO] 2021-07-12 19:30:22,282 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:22,283 [run_pretraining.py:  534]:	loss/total_loss, 7.520137310028076, 2908
[INFO] 2021-07-12 19:30:22,283 [run_pretraining.py:  535]:	loss/mlm_loss, 7.520137310028076, 2908
[INFO] 2021-07-12 19:30:22,283 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.906999725382775e-05, 2908
[INFO] 2021-07-12 19:30:22,283 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2908
[INFO] 2021-07-12 19:30:22,283 [run_pretraining.py:  558]:	worker_index: 3, step: 2908, cost: 7.520137, mlm loss: 7.520137, speed: 1.109654 steps/s, speed: 8.877228 samples/s, speed: 4545.140944 tokens/s, learning rate: 2.907e-05, loss_scalings: 2814.750488, pp_loss: 7.372813
[INFO] 2021-07-12 19:30:22,283 [run_pretraining.py:  512]:	********exe.run_2908******* 
[INFO] 2021-07-12 19:30:23,219 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:23,219 [run_pretraining.py:  534]:	loss/total_loss, 7.77895450592041, 2909
[INFO] 2021-07-12 19:30:23,219 [run_pretraining.py:  535]:	loss/mlm_loss, 7.77895450592041, 2909
[INFO] 2021-07-12 19:30:23,220 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.907999987655785e-05, 2909
[INFO] 2021-07-12 19:30:23,220 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2909
[INFO] 2021-07-12 19:30:23,220 [run_pretraining.py:  558]:	worker_index: 3, step: 2909, cost: 7.778955, mlm loss: 7.778955, speed: 1.068439 steps/s, speed: 8.547510 samples/s, speed: 4376.325373 tokens/s, learning rate: 2.908e-05, loss_scalings: 2814.750488, pp_loss: 7.065919
[INFO] 2021-07-12 19:30:23,220 [run_pretraining.py:  512]:	********exe.run_2909******* 
[INFO] 2021-07-12 19:30:24,130 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:24,131 [run_pretraining.py:  534]:	loss/total_loss, 7.1028923988342285, 2910
[INFO] 2021-07-12 19:30:24,131 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1028923988342285, 2910
[INFO] 2021-07-12 19:30:24,131 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.908999886130914e-05, 2910
[INFO] 2021-07-12 19:30:24,131 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2910
[INFO] 2021-07-12 19:30:24,131 [run_pretraining.py:  558]:	worker_index: 3, step: 2910, cost: 7.102892, mlm loss: 7.102892, speed: 1.097974 steps/s, speed: 8.783795 samples/s, speed: 4497.303216 tokens/s, learning rate: 2.909e-05, loss_scalings: 2814.750488, pp_loss: 6.376297
[INFO] 2021-07-12 19:30:24,131 [run_pretraining.py:  512]:	********exe.run_2910******* 
[INFO] 2021-07-12 19:30:25,038 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:25,039 [run_pretraining.py:  534]:	loss/total_loss, 4.617867946624756, 2911
[INFO] 2021-07-12 19:30:25,039 [run_pretraining.py:  535]:	loss/mlm_loss, 4.617867946624756, 2911
[INFO] 2021-07-12 19:30:25,039 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9099999665049836e-05, 2911
[INFO] 2021-07-12 19:30:25,039 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2911
[INFO] 2021-07-12 19:30:25,039 [run_pretraining.py:  558]:	worker_index: 3, step: 2911, cost: 4.617868, mlm loss: 4.617868, speed: 1.101903 steps/s, speed: 8.815228 samples/s, speed: 4513.396505 tokens/s, learning rate: 2.910e-05, loss_scalings: 2814.750488, pp_loss: 6.233654
[INFO] 2021-07-12 19:30:25,039 [run_pretraining.py:  512]:	********exe.run_2911******* 
[INFO] 2021-07-12 19:30:25,947 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:25,948 [run_pretraining.py:  534]:	loss/total_loss, 7.006431579589844, 2912
[INFO] 2021-07-12 19:30:25,948 [run_pretraining.py:  535]:	loss/mlm_loss, 7.006431579589844, 2912
[INFO] 2021-07-12 19:30:25,948 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9109998649801128e-05, 2912
[INFO] 2021-07-12 19:30:25,948 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2912
[INFO] 2021-07-12 19:30:25,948 [run_pretraining.py:  558]:	worker_index: 3, step: 2912, cost: 7.006432, mlm loss: 7.006432, speed: 1.101030 steps/s, speed: 8.808241 samples/s, speed: 4509.819612 tokens/s, learning rate: 2.911e-05, loss_scalings: 2814.750488, pp_loss: 7.028520
[INFO] 2021-07-12 19:30:25,948 [run_pretraining.py:  512]:	********exe.run_2912******* 
[INFO] 2021-07-12 19:30:26,853 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:26,853 [run_pretraining.py:  534]:	loss/total_loss, 7.049747943878174, 2913
[INFO] 2021-07-12 19:30:26,853 [run_pretraining.py:  535]:	loss/mlm_loss, 7.049747943878174, 2913
[INFO] 2021-07-12 19:30:26,853 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9120001272531226e-05, 2913
[INFO] 2021-07-12 19:30:26,854 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2913
[INFO] 2021-07-12 19:30:26,854 [run_pretraining.py:  558]:	worker_index: 3, step: 2913, cost: 7.049748, mlm loss: 7.049748, speed: 1.105131 steps/s, speed: 8.841049 samples/s, speed: 4526.616917 tokens/s, learning rate: 2.912e-05, loss_scalings: 2814.750488, pp_loss: 7.183271
[INFO] 2021-07-12 19:30:26,854 [run_pretraining.py:  512]:	********exe.run_2913******* 
[INFO] 2021-07-12 19:30:27,765 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:27,765 [run_pretraining.py:  534]:	loss/total_loss, 7.607278823852539, 2914
[INFO] 2021-07-12 19:30:27,765 [run_pretraining.py:  535]:	loss/mlm_loss, 7.607278823852539, 2914
[INFO] 2021-07-12 19:30:27,765 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9129998438293114e-05, 2914
[INFO] 2021-07-12 19:30:27,765 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2914
[INFO] 2021-07-12 19:30:27,765 [run_pretraining.py:  558]:	worker_index: 3, step: 2914, cost: 7.607279, mlm loss: 7.607279, speed: 1.097533 steps/s, speed: 8.780265 samples/s, speed: 4495.495621 tokens/s, learning rate: 2.913e-05, loss_scalings: 2814.750488, pp_loss: 7.445458
[INFO] 2021-07-12 19:30:27,765 [run_pretraining.py:  512]:	********exe.run_2914******* 
[INFO] 2021-07-12 19:30:28,671 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:28,671 [run_pretraining.py:  534]:	loss/total_loss, 6.245318412780762, 2915
[INFO] 2021-07-12 19:30:28,671 [run_pretraining.py:  535]:	loss/mlm_loss, 6.245318412780762, 2915
[INFO] 2021-07-12 19:30:28,671 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9139997423044406e-05, 2915
[INFO] 2021-07-12 19:30:28,672 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2915
[INFO] 2021-07-12 19:30:28,672 [run_pretraining.py:  558]:	worker_index: 3, step: 2915, cost: 6.245318, mlm loss: 6.245318, speed: 1.104214 steps/s, speed: 8.833715 samples/s, speed: 4522.861868 tokens/s, learning rate: 2.914e-05, loss_scalings: 2814.750488, pp_loss: 7.127812
[INFO] 2021-07-12 19:30:28,672 [run_pretraining.py:  512]:	********exe.run_2915******* 
[INFO] 2021-07-12 19:30:29,578 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:29,578 [run_pretraining.py:  534]:	loss/total_loss, 7.180325508117676, 2916
[INFO] 2021-07-12 19:30:29,578 [run_pretraining.py:  535]:	loss/mlm_loss, 7.180325508117676, 2916
[INFO] 2021-07-12 19:30:29,578 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9150000045774505e-05, 2916
[INFO] 2021-07-12 19:30:29,579 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2916
[INFO] 2021-07-12 19:30:29,579 [run_pretraining.py:  558]:	worker_index: 3, step: 2916, cost: 7.180326, mlm loss: 7.180326, speed: 1.103380 steps/s, speed: 8.827040 samples/s, speed: 4519.444726 tokens/s, learning rate: 2.915e-05, loss_scalings: 2814.750488, pp_loss: 6.352442
[INFO] 2021-07-12 19:30:29,579 [run_pretraining.py:  512]:	********exe.run_2916******* 
[INFO] 2021-07-12 19:30:30,486 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:30,486 [run_pretraining.py:  534]:	loss/total_loss, 6.837741851806641, 2917
[INFO] 2021-07-12 19:30:30,486 [run_pretraining.py:  535]:	loss/mlm_loss, 6.837741851806641, 2917
[INFO] 2021-07-12 19:30:30,487 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9159999030525796e-05, 2917
[INFO] 2021-07-12 19:30:30,487 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2917
[INFO] 2021-07-12 19:30:30,487 [run_pretraining.py:  558]:	worker_index: 3, step: 2917, cost: 6.837742, mlm loss: 6.837742, speed: 1.102032 steps/s, speed: 8.816258 samples/s, speed: 4513.924218 tokens/s, learning rate: 2.916e-05, loss_scalings: 2814.750488, pp_loss: 6.829210
[INFO] 2021-07-12 19:30:30,487 [run_pretraining.py:  512]:	********exe.run_2917******* 
[INFO] 2021-07-12 19:30:31,396 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:31,397 [run_pretraining.py:  534]:	loss/total_loss, 7.37122106552124, 2918
[INFO] 2021-07-12 19:30:31,397 [run_pretraining.py:  535]:	loss/mlm_loss, 7.37122106552124, 2918
[INFO] 2021-07-12 19:30:31,397 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.916999983426649e-05, 2918
[INFO] 2021-07-12 19:30:31,397 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2918
[INFO] 2021-07-12 19:30:31,397 [run_pretraining.py:  558]:	worker_index: 3, step: 2918, cost: 7.371221, mlm loss: 7.371221, speed: 1.099205 steps/s, speed: 8.793636 samples/s, speed: 4502.341782 tokens/s, learning rate: 2.917e-05, loss_scalings: 2814.750488, pp_loss: 7.108444
[INFO] 2021-07-12 19:30:31,397 [run_pretraining.py:  512]:	********exe.run_2918******* 
[INFO] 2021-07-12 19:30:32,298 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:32,299 [run_pretraining.py:  534]:	loss/total_loss, 6.281607151031494, 2919
[INFO] 2021-07-12 19:30:32,299 [run_pretraining.py:  535]:	loss/mlm_loss, 6.281607151031494, 2919
[INFO] 2021-07-12 19:30:32,299 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9179998819017783e-05, 2919
[INFO] 2021-07-12 19:30:32,299 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2919
[INFO] 2021-07-12 19:30:32,299 [run_pretraining.py:  558]:	worker_index: 3, step: 2919, cost: 6.281607, mlm loss: 6.281607, speed: 1.109613 steps/s, speed: 8.876907 samples/s, speed: 4544.976211 tokens/s, learning rate: 2.918e-05, loss_scalings: 2814.750488, pp_loss: 7.258331
[INFO] 2021-07-12 19:30:32,299 [run_pretraining.py:  512]:	********exe.run_2919******* 
[INFO] 2021-07-12 19:30:33,209 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:33,210 [run_pretraining.py:  534]:	loss/total_loss, 7.3701066970825195, 2920
[INFO] 2021-07-12 19:30:33,210 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3701066970825195, 2920
[INFO] 2021-07-12 19:30:33,210 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9189999622758478e-05, 2920
[INFO] 2021-07-12 19:30:33,210 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2920
[INFO] 2021-07-12 19:30:33,210 [run_pretraining.py:  558]:	worker_index: 3, step: 2920, cost: 7.370107, mlm loss: 7.370107, speed: 1.098168 steps/s, speed: 8.785345 samples/s, speed: 4498.096852 tokens/s, learning rate: 2.919e-05, loss_scalings: 2814.750488, pp_loss: 7.164564
[INFO] 2021-07-12 19:30:33,210 [run_pretraining.py:  512]:	********exe.run_2920******* 
[INFO] 2021-07-12 19:30:34,118 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:34,118 [run_pretraining.py:  534]:	loss/total_loss, 7.606612205505371, 2921
[INFO] 2021-07-12 19:30:34,119 [run_pretraining.py:  535]:	loss/mlm_loss, 7.606612205505371, 2921
[INFO] 2021-07-12 19:30:34,119 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.919999860750977e-05, 2921
[INFO] 2021-07-12 19:30:34,119 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2921
[INFO] 2021-07-12 19:30:34,119 [run_pretraining.py:  558]:	worker_index: 3, step: 2921, cost: 7.606612, mlm loss: 7.606612, speed: 1.101240 steps/s, speed: 8.809920 samples/s, speed: 4510.679255 tokens/s, learning rate: 2.920e-05, loss_scalings: 2814.750488, pp_loss: 7.441548
[INFO] 2021-07-12 19:30:34,119 [run_pretraining.py:  512]:	********exe.run_2921******* 
[INFO] 2021-07-12 19:30:35,026 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:35,026 [run_pretraining.py:  534]:	loss/total_loss, 7.371086597442627, 2922
[INFO] 2021-07-12 19:30:35,026 [run_pretraining.py:  535]:	loss/mlm_loss, 7.371086597442627, 2922
[INFO] 2021-07-12 19:30:35,026 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9210001230239868e-05, 2922
[INFO] 2021-07-12 19:30:35,027 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2922
[INFO] 2021-07-12 19:30:35,027 [run_pretraining.py:  558]:	worker_index: 3, step: 2922, cost: 7.371087, mlm loss: 7.371087, speed: 1.102379 steps/s, speed: 8.819032 samples/s, speed: 4515.344320 tokens/s, learning rate: 2.921e-05, loss_scalings: 2814.750488, pp_loss: 7.401599
[INFO] 2021-07-12 19:30:35,027 [run_pretraining.py:  512]:	********exe.run_2922******* 
[INFO] 2021-07-12 19:30:35,935 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:35,935 [run_pretraining.py:  534]:	loss/total_loss, 6.796934604644775, 2923
[INFO] 2021-07-12 19:30:35,935 [run_pretraining.py:  535]:	loss/mlm_loss, 6.796934604644775, 2923
[INFO] 2021-07-12 19:30:35,935 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9219998396001756e-05, 2923
[INFO] 2021-07-12 19:30:35,935 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2923
[INFO] 2021-07-12 19:30:35,936 [run_pretraining.py:  558]:	worker_index: 3, step: 2923, cost: 6.796935, mlm loss: 6.796935, speed: 1.101009 steps/s, speed: 8.808070 samples/s, speed: 4509.732009 tokens/s, learning rate: 2.922e-05, loss_scalings: 2814.750488, pp_loss: 7.106450
[INFO] 2021-07-12 19:30:35,936 [run_pretraining.py:  512]:	********exe.run_2923******* 
[INFO] 2021-07-12 19:30:36,885 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:36,885 [run_pretraining.py:  534]:	loss/total_loss, 6.999061107635498, 2924
[INFO] 2021-07-12 19:30:36,885 [run_pretraining.py:  535]:	loss/mlm_loss, 6.999061107635498, 2924
[INFO] 2021-07-12 19:30:36,886 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9229997380753048e-05, 2924
[INFO] 2021-07-12 19:30:36,886 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2924
[INFO] 2021-07-12 19:30:36,886 [run_pretraining.py:  558]:	worker_index: 3, step: 2924, cost: 6.999061, mlm loss: 6.999061, speed: 1.053165 steps/s, speed: 8.425317 samples/s, speed: 4313.762359 tokens/s, learning rate: 2.923e-05, loss_scalings: 2814.750488, pp_loss: 7.130456
[INFO] 2021-07-12 19:30:36,886 [run_pretraining.py:  512]:	********exe.run_2924******* 
[INFO] 2021-07-12 19:30:37,790 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:37,791 [run_pretraining.py:  534]:	loss/total_loss, 7.208799839019775, 2925
[INFO] 2021-07-12 19:30:37,791 [run_pretraining.py:  535]:	loss/mlm_loss, 7.208799839019775, 2925
[INFO] 2021-07-12 19:30:37,791 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9240000003483146e-05, 2925
[INFO] 2021-07-12 19:30:37,791 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2925
[INFO] 2021-07-12 19:30:37,791 [run_pretraining.py:  558]:	worker_index: 3, step: 2925, cost: 7.208800, mlm loss: 7.208800, speed: 1.105447 steps/s, speed: 8.843577 samples/s, speed: 4527.911356 tokens/s, learning rate: 2.924e-05, loss_scalings: 2814.750488, pp_loss: 6.867329
[INFO] 2021-07-12 19:30:37,791 [run_pretraining.py:  512]:	********exe.run_2925******* 
[INFO] 2021-07-12 19:30:38,701 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:38,701 [run_pretraining.py:  534]:	loss/total_loss, 6.899574279785156, 2926
[INFO] 2021-07-12 19:30:38,701 [run_pretraining.py:  535]:	loss/mlm_loss, 6.899574279785156, 2926
[INFO] 2021-07-12 19:30:38,702 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9249998988234438e-05, 2926
[INFO] 2021-07-12 19:30:38,702 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2926
[INFO] 2021-07-12 19:30:38,702 [run_pretraining.py:  558]:	worker_index: 3, step: 2926, cost: 6.899574, mlm loss: 6.899574, speed: 1.098787 steps/s, speed: 8.790294 samples/s, speed: 4500.630351 tokens/s, learning rate: 2.925e-05, loss_scalings: 2814.750488, pp_loss: 7.264680
[INFO] 2021-07-12 19:30:38,702 [run_pretraining.py:  512]:	********exe.run_2926******* 
[INFO] 2021-07-12 19:30:39,609 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:39,609 [run_pretraining.py:  534]:	loss/total_loss, 7.2022552490234375, 2927
[INFO] 2021-07-12 19:30:39,609 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2022552490234375, 2927
[INFO] 2021-07-12 19:30:39,610 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9259999791975133e-05, 2927
[INFO] 2021-07-12 19:30:39,610 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2927
[INFO] 2021-07-12 19:30:39,610 [run_pretraining.py:  558]:	worker_index: 3, step: 2927, cost: 7.202255, mlm loss: 7.202255, speed: 1.102075 steps/s, speed: 8.816603 samples/s, speed: 4514.100941 tokens/s, learning rate: 2.926e-05, loss_scalings: 2814.750488, pp_loss: 7.053876
[INFO] 2021-07-12 19:30:39,610 [run_pretraining.py:  512]:	********exe.run_2927******* 
[INFO] 2021-07-12 19:30:40,510 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:40,510 [run_pretraining.py:  534]:	loss/total_loss, 7.723655700683594, 2928
[INFO] 2021-07-12 19:30:40,510 [run_pretraining.py:  535]:	loss/mlm_loss, 7.723655700683594, 2928
[INFO] 2021-07-12 19:30:40,510 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9269998776726425e-05, 2928
[INFO] 2021-07-12 19:30:40,511 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2928
[INFO] 2021-07-12 19:30:40,511 [run_pretraining.py:  558]:	worker_index: 3, step: 2928, cost: 7.723656, mlm loss: 7.723656, speed: 1.110752 steps/s, speed: 8.886014 samples/s, speed: 4549.639028 tokens/s, learning rate: 2.927e-05, loss_scalings: 2814.750488, pp_loss: 7.262827
[INFO] 2021-07-12 19:30:40,511 [run_pretraining.py:  512]:	********exe.run_2928******* 
[INFO] 2021-07-12 19:30:41,421 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:41,422 [run_pretraining.py:  534]:	loss/total_loss, 7.302637100219727, 2929
[INFO] 2021-07-12 19:30:41,422 [run_pretraining.py:  535]:	loss/mlm_loss, 7.302637100219727, 2929
[INFO] 2021-07-12 19:30:41,422 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.927999958046712e-05, 2929
[INFO] 2021-07-12 19:30:41,422 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2929
[INFO] 2021-07-12 19:30:41,422 [run_pretraining.py:  558]:	worker_index: 3, step: 2929, cost: 7.302637, mlm loss: 7.302637, speed: 1.097965 steps/s, speed: 8.783722 samples/s, speed: 4497.265543 tokens/s, learning rate: 2.928e-05, loss_scalings: 2814.750488, pp_loss: 7.670105
[INFO] 2021-07-12 19:30:41,422 [run_pretraining.py:  512]:	********exe.run_2929******* 
[INFO] 2021-07-12 19:30:42,325 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:42,326 [run_pretraining.py:  534]:	loss/total_loss, 7.44829797744751, 2930
[INFO] 2021-07-12 19:30:42,326 [run_pretraining.py:  535]:	loss/mlm_loss, 7.44829797744751, 2930
[INFO] 2021-07-12 19:30:42,326 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.928999856521841e-05, 2930
[INFO] 2021-07-12 19:30:42,326 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2930
[INFO] 2021-07-12 19:30:42,326 [run_pretraining.py:  558]:	worker_index: 3, step: 2930, cost: 7.448298, mlm loss: 7.448298, speed: 1.106560 steps/s, speed: 8.852483 samples/s, speed: 4532.471045 tokens/s, learning rate: 2.929e-05, loss_scalings: 2814.750488, pp_loss: 7.237736
[INFO] 2021-07-12 19:30:42,326 [run_pretraining.py:  512]:	********exe.run_2930******* 
[INFO] 2021-07-12 19:30:43,246 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:43,247 [run_pretraining.py:  534]:	loss/total_loss, 6.864433765411377, 2931
[INFO] 2021-07-12 19:30:43,247 [run_pretraining.py:  535]:	loss/mlm_loss, 6.864433765411377, 2931
[INFO] 2021-07-12 19:30:43,247 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.930000118794851e-05, 2931
[INFO] 2021-07-12 19:30:43,247 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2931
[INFO] 2021-07-12 19:30:43,247 [run_pretraining.py:  558]:	worker_index: 3, step: 2931, cost: 6.864434, mlm loss: 6.864434, speed: 1.086555 steps/s, speed: 8.692437 samples/s, speed: 4450.527703 tokens/s, learning rate: 2.930e-05, loss_scalings: 2814.750488, pp_loss: 7.226362
[INFO] 2021-07-12 19:30:43,247 [run_pretraining.py:  512]:	********exe.run_2931******* 
[INFO] 2021-07-12 19:30:44,149 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:44,149 [run_pretraining.py:  534]:	loss/total_loss, 7.372406482696533, 2932
[INFO] 2021-07-12 19:30:44,149 [run_pretraining.py:  535]:	loss/mlm_loss, 7.372406482696533, 2932
[INFO] 2021-07-12 19:30:44,149 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9309998353710398e-05, 2932
[INFO] 2021-07-12 19:30:44,149 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2932
[INFO] 2021-07-12 19:30:44,150 [run_pretraining.py:  558]:	worker_index: 3, step: 2932, cost: 7.372406, mlm loss: 7.372406, speed: 1.109176 steps/s, speed: 8.873409 samples/s, speed: 4543.185364 tokens/s, learning rate: 2.931e-05, loss_scalings: 2814.750488, pp_loss: 7.126809
[INFO] 2021-07-12 19:30:44,150 [run_pretraining.py:  512]:	********exe.run_2932******* 
[INFO] 2021-07-12 19:30:45,054 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:45,055 [run_pretraining.py:  534]:	loss/total_loss, 7.3357133865356445, 2933
[INFO] 2021-07-12 19:30:45,055 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3357133865356445, 2933
[INFO] 2021-07-12 19:30:45,055 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.931999733846169e-05, 2933
[INFO] 2021-07-12 19:30:45,055 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2933
[INFO] 2021-07-12 19:30:45,055 [run_pretraining.py:  558]:	worker_index: 3, step: 2933, cost: 7.335713, mlm loss: 7.335713, speed: 1.105183 steps/s, speed: 8.841468 samples/s, speed: 4526.831611 tokens/s, learning rate: 2.932e-05, loss_scalings: 2814.750488, pp_loss: 6.863652
[INFO] 2021-07-12 19:30:45,055 [run_pretraining.py:  512]:	********exe.run_2933******* 
[INFO] 2021-07-12 19:30:45,960 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:45,961 [run_pretraining.py:  534]:	loss/total_loss, 7.5208587646484375, 2934
[INFO] 2021-07-12 19:30:45,961 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5208587646484375, 2934
[INFO] 2021-07-12 19:30:45,961 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.932999996119179e-05, 2934
[INFO] 2021-07-12 19:30:45,961 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2934
[INFO] 2021-07-12 19:30:45,961 [run_pretraining.py:  558]:	worker_index: 3, step: 2934, cost: 7.520859, mlm loss: 7.520859, speed: 1.104156 steps/s, speed: 8.833245 samples/s, speed: 4522.621357 tokens/s, learning rate: 2.933e-05, loss_scalings: 2814.750488, pp_loss: 7.413297
[INFO] 2021-07-12 19:30:45,961 [run_pretraining.py:  512]:	********exe.run_2934******* 
[INFO] 2021-07-12 19:30:46,858 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:46,859 [run_pretraining.py:  534]:	loss/total_loss, 7.128751754760742, 2935
[INFO] 2021-07-12 19:30:46,859 [run_pretraining.py:  535]:	loss/mlm_loss, 7.128751754760742, 2935
[INFO] 2021-07-12 19:30:46,859 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.933999894594308e-05, 2935
[INFO] 2021-07-12 19:30:46,859 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2935
[INFO] 2021-07-12 19:30:46,859 [run_pretraining.py:  558]:	worker_index: 3, step: 2935, cost: 7.128752, mlm loss: 7.128752, speed: 1.114861 steps/s, speed: 8.918892 samples/s, speed: 4566.472635 tokens/s, learning rate: 2.934e-05, loss_scalings: 2814.750488, pp_loss: 7.126342
[INFO] 2021-07-12 19:30:46,859 [run_pretraining.py:  512]:	********exe.run_2935******* 
[INFO] 2021-07-12 19:30:47,772 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:47,772 [run_pretraining.py:  534]:	loss/total_loss, 7.876775741577148, 2936
[INFO] 2021-07-12 19:30:47,772 [run_pretraining.py:  535]:	loss/mlm_loss, 7.876775741577148, 2936
[INFO] 2021-07-12 19:30:47,772 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9349999749683775e-05, 2936
[INFO] 2021-07-12 19:30:47,772 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2936
[INFO] 2021-07-12 19:30:47,772 [run_pretraining.py:  558]:	worker_index: 3, step: 2936, cost: 7.876776, mlm loss: 7.876776, speed: 1.095344 steps/s, speed: 8.762751 samples/s, speed: 4486.528608 tokens/s, learning rate: 2.935e-05, loss_scalings: 2814.750488, pp_loss: 7.487576
[INFO] 2021-07-12 19:30:47,773 [run_pretraining.py:  512]:	********exe.run_2936******* 
[INFO] 2021-07-12 19:30:48,676 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:48,676 [run_pretraining.py:  534]:	loss/total_loss, 7.231566429138184, 2937
[INFO] 2021-07-12 19:30:48,676 [run_pretraining.py:  535]:	loss/mlm_loss, 7.231566429138184, 2937
[INFO] 2021-07-12 19:30:48,677 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9359998734435067e-05, 2937
[INFO] 2021-07-12 19:30:48,677 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2937
[INFO] 2021-07-12 19:30:48,677 [run_pretraining.py:  558]:	worker_index: 3, step: 2937, cost: 7.231566, mlm loss: 7.231566, speed: 1.106697 steps/s, speed: 8.853578 samples/s, speed: 4533.031934 tokens/s, learning rate: 2.936e-05, loss_scalings: 2814.750488, pp_loss: 7.294031
[INFO] 2021-07-12 19:30:48,677 [run_pretraining.py:  512]:	********exe.run_2937******* 
[INFO] 2021-07-12 19:30:49,582 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:49,583 [run_pretraining.py:  534]:	loss/total_loss, 6.785022735595703, 2938
[INFO] 2021-07-12 19:30:49,583 [run_pretraining.py:  535]:	loss/mlm_loss, 6.785022735595703, 2938
[INFO] 2021-07-12 19:30:49,583 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9369999538175762e-05, 2938
[INFO] 2021-07-12 19:30:49,583 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2938
[INFO] 2021-07-12 19:30:49,583 [run_pretraining.py:  558]:	worker_index: 3, step: 2938, cost: 6.785023, mlm loss: 6.785023, speed: 1.103927 steps/s, speed: 8.831415 samples/s, speed: 4521.684560 tokens/s, learning rate: 2.937e-05, loss_scalings: 2814.750488, pp_loss: 6.861686
[INFO] 2021-07-12 19:30:49,583 [run_pretraining.py:  512]:	********exe.run_2938******* 
[INFO] 2021-07-12 19:30:50,478 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:50,479 [run_pretraining.py:  534]:	loss/total_loss, 6.708605766296387, 2939
[INFO] 2021-07-12 19:30:50,479 [run_pretraining.py:  535]:	loss/mlm_loss, 6.708605766296387, 2939
[INFO] 2021-07-12 19:30:50,479 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9379998522927053e-05, 2939
[INFO] 2021-07-12 19:30:50,479 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2939
[INFO] 2021-07-12 19:30:50,479 [run_pretraining.py:  558]:	worker_index: 3, step: 2939, cost: 6.708606, mlm loss: 6.708606, speed: 1.116955 steps/s, speed: 8.935641 samples/s, speed: 4575.048323 tokens/s, learning rate: 2.938e-05, loss_scalings: 2814.750488, pp_loss: 6.796919
[INFO] 2021-07-12 19:30:50,479 [run_pretraining.py:  512]:	********exe.run_2939******* 
[INFO] 2021-07-12 19:30:51,382 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:51,383 [run_pretraining.py:  534]:	loss/total_loss, 7.484407424926758, 2940
[INFO] 2021-07-12 19:30:51,383 [run_pretraining.py:  535]:	loss/mlm_loss, 7.484407424926758, 2940
[INFO] 2021-07-12 19:30:51,383 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9390001145657152e-05, 2940
[INFO] 2021-07-12 19:30:51,383 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2940
[INFO] 2021-07-12 19:30:51,383 [run_pretraining.py:  558]:	worker_index: 3, step: 2940, cost: 7.484407, mlm loss: 7.484407, speed: 1.107335 steps/s, speed: 8.858681 samples/s, speed: 4535.644466 tokens/s, learning rate: 2.939e-05, loss_scalings: 2814.750488, pp_loss: 7.193544
[INFO] 2021-07-12 19:30:51,383 [run_pretraining.py:  512]:	********exe.run_2940******* 
[INFO] 2021-07-12 19:30:52,290 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:52,290 [run_pretraining.py:  534]:	loss/total_loss, 8.123663902282715, 2941
[INFO] 2021-07-12 19:30:52,290 [run_pretraining.py:  535]:	loss/mlm_loss, 8.123663902282715, 2941
[INFO] 2021-07-12 19:30:52,291 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9400000130408444e-05, 2941
[INFO] 2021-07-12 19:30:52,291 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2941
[INFO] 2021-07-12 19:30:52,291 [run_pretraining.py:  558]:	worker_index: 3, step: 2941, cost: 8.123664, mlm loss: 8.123664, speed: 1.102259 steps/s, speed: 8.818072 samples/s, speed: 4514.853056 tokens/s, learning rate: 2.940e-05, loss_scalings: 2814.750488, pp_loss: 7.257107
[INFO] 2021-07-12 19:30:52,291 [run_pretraining.py:  512]:	********exe.run_2941******* 
[INFO] 2021-07-12 19:30:53,202 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:53,203 [run_pretraining.py:  534]:	loss/total_loss, 6.596622467041016, 2942
[INFO] 2021-07-12 19:30:53,203 [run_pretraining.py:  535]:	loss/mlm_loss, 6.596622467041016, 2942
[INFO] 2021-07-12 19:30:53,203 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.940999729617033e-05, 2942
[INFO] 2021-07-12 19:30:53,203 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2942
[INFO] 2021-07-12 19:30:53,203 [run_pretraining.py:  558]:	worker_index: 3, step: 2942, cost: 6.596622, mlm loss: 6.596622, speed: 1.096603 steps/s, speed: 8.772827 samples/s, speed: 4491.687487 tokens/s, learning rate: 2.941e-05, loss_scalings: 2814.750488, pp_loss: 7.255949
[INFO] 2021-07-12 19:30:53,203 [run_pretraining.py:  512]:	********exe.run_2942******* 
[INFO] 2021-07-12 19:30:54,109 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:54,110 [run_pretraining.py:  534]:	loss/total_loss, 6.177587985992432, 2943
[INFO] 2021-07-12 19:30:54,110 [run_pretraining.py:  535]:	loss/mlm_loss, 6.177587985992432, 2943
[INFO] 2021-07-12 19:30:54,110 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.941999991890043e-05, 2943
[INFO] 2021-07-12 19:30:54,110 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2943
[INFO] 2021-07-12 19:30:54,110 [run_pretraining.py:  558]:	worker_index: 3, step: 2943, cost: 6.177588, mlm loss: 6.177588, speed: 1.103189 steps/s, speed: 8.825515 samples/s, speed: 4518.663745 tokens/s, learning rate: 2.942e-05, loss_scalings: 2814.750488, pp_loss: 6.774170
[INFO] 2021-07-12 19:30:54,110 [run_pretraining.py:  512]:	********exe.run_2943******* 
[INFO] 2021-07-12 19:30:55,008 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:55,009 [run_pretraining.py:  534]:	loss/total_loss, 7.248953819274902, 2944
[INFO] 2021-07-12 19:30:55,009 [run_pretraining.py:  535]:	loss/mlm_loss, 7.248953819274902, 2944
[INFO] 2021-07-12 19:30:55,009 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9429998903651722e-05, 2944
[INFO] 2021-07-12 19:30:55,009 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2944
[INFO] 2021-07-12 19:30:55,009 [run_pretraining.py:  558]:	worker_index: 3, step: 2944, cost: 7.248954, mlm loss: 7.248954, speed: 1.113337 steps/s, speed: 8.906695 samples/s, speed: 4560.227765 tokens/s, learning rate: 2.943e-05, loss_scalings: 2814.750488, pp_loss: 7.375201
[INFO] 2021-07-12 19:30:55,009 [run_pretraining.py:  512]:	********exe.run_2944******* 
[INFO] 2021-07-12 19:30:55,916 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:55,916 [run_pretraining.py:  534]:	loss/total_loss, 8.04996395111084, 2945
[INFO] 2021-07-12 19:30:55,916 [run_pretraining.py:  535]:	loss/mlm_loss, 8.04996395111084, 2945
[INFO] 2021-07-12 19:30:55,916 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9439999707392417e-05, 2945
[INFO] 2021-07-12 19:30:55,916 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2945
[INFO] 2021-07-12 19:30:55,916 [run_pretraining.py:  558]:	worker_index: 3, step: 2945, cost: 8.049964, mlm loss: 8.049964, speed: 1.103064 steps/s, speed: 8.824515 samples/s, speed: 4518.151558 tokens/s, learning rate: 2.944e-05, loss_scalings: 2814.750488, pp_loss: 7.439806
[INFO] 2021-07-12 19:30:55,916 [run_pretraining.py:  512]:	********exe.run_2945******* 
[INFO] 2021-07-12 19:30:56,819 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:56,820 [run_pretraining.py:  534]:	loss/total_loss, 6.979725360870361, 2946
[INFO] 2021-07-12 19:30:56,820 [run_pretraining.py:  535]:	loss/mlm_loss, 6.979725360870361, 2946
[INFO] 2021-07-12 19:30:56,820 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.944999869214371e-05, 2946
[INFO] 2021-07-12 19:30:56,820 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2946
[INFO] 2021-07-12 19:30:56,820 [run_pretraining.py:  558]:	worker_index: 3, step: 2946, cost: 6.979725, mlm loss: 6.979725, speed: 1.107076 steps/s, speed: 8.856607 samples/s, speed: 4534.582575 tokens/s, learning rate: 2.945e-05, loss_scalings: 2814.750488, pp_loss: 7.023602
[INFO] 2021-07-12 19:30:56,820 [run_pretraining.py:  512]:	********exe.run_2946******* 
[INFO] 2021-07-12 19:30:57,719 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:57,720 [run_pretraining.py:  534]:	loss/total_loss, 6.851436614990234, 2947
[INFO] 2021-07-12 19:30:57,720 [run_pretraining.py:  535]:	loss/mlm_loss, 6.851436614990234, 2947
[INFO] 2021-07-12 19:30:57,720 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9459999495884404e-05, 2947
[INFO] 2021-07-12 19:30:57,720 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2947
[INFO] 2021-07-12 19:30:57,720 [run_pretraining.py:  558]:	worker_index: 3, step: 2947, cost: 6.851437, mlm loss: 6.851437, speed: 1.112495 steps/s, speed: 8.899957 samples/s, speed: 4556.778122 tokens/s, learning rate: 2.946e-05, loss_scalings: 2814.750488, pp_loss: 6.646172
[INFO] 2021-07-12 19:30:57,720 [run_pretraining.py:  512]:	********exe.run_2947******* 
[INFO] 2021-07-12 19:30:58,625 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:58,626 [run_pretraining.py:  534]:	loss/total_loss, 6.998373031616211, 2948
[INFO] 2021-07-12 19:30:58,626 [run_pretraining.py:  535]:	loss/mlm_loss, 6.998373031616211, 2948
[INFO] 2021-07-12 19:30:58,626 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9469998480635695e-05, 2948
[INFO] 2021-07-12 19:30:58,626 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2948
[INFO] 2021-07-12 19:30:58,626 [run_pretraining.py:  558]:	worker_index: 3, step: 2948, cost: 6.998373, mlm loss: 6.998373, speed: 1.104424 steps/s, speed: 8.835394 samples/s, speed: 4523.721725 tokens/s, learning rate: 2.947e-05, loss_scalings: 2814.750488, pp_loss: 7.221899
[INFO] 2021-07-12 19:30:58,626 [run_pretraining.py:  512]:	********exe.run_2948******* 
[INFO] 2021-07-12 19:30:59,527 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:59,528 [run_pretraining.py:  534]:	loss/total_loss, 6.770816802978516, 2949
[INFO] 2021-07-12 19:30:59,528 [run_pretraining.py:  535]:	loss/mlm_loss, 6.770816802978516, 2949
[INFO] 2021-07-12 19:30:59,528 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9480001103365794e-05, 2949
[INFO] 2021-07-12 19:30:59,528 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2949
[INFO] 2021-07-12 19:30:59,528 [run_pretraining.py:  558]:	worker_index: 3, step: 2949, cost: 6.770817, mlm loss: 6.770817, speed: 1.109264 steps/s, speed: 8.874111 samples/s, speed: 4543.544622 tokens/s, learning rate: 2.948e-05, loss_scalings: 2814.750488, pp_loss: 7.068728
[INFO] 2021-07-12 19:30:59,528 [run_pretraining.py:  512]:	********exe.run_2949******* 
[INFO] 2021-07-12 19:31:00,430 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:00,431 [run_pretraining.py:  534]:	loss/total_loss, 7.828926086425781, 2950
[INFO] 2021-07-12 19:31:00,431 [run_pretraining.py:  535]:	loss/mlm_loss, 7.828926086425781, 2950
[INFO] 2021-07-12 19:31:00,431 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9490000088117085e-05, 2950
[INFO] 2021-07-12 19:31:00,431 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2950
[INFO] 2021-07-12 19:31:00,431 [run_pretraining.py:  558]:	worker_index: 3, step: 2950, cost: 7.828926, mlm loss: 7.828926, speed: 1.108187 steps/s, speed: 8.865496 samples/s, speed: 4539.134130 tokens/s, learning rate: 2.949e-05, loss_scalings: 2814.750488, pp_loss: 7.090580
[INFO] 2021-07-12 19:31:00,431 [run_pretraining.py:  512]:	********exe.run_2950******* 
[INFO] 2021-07-12 19:31:01,379 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:01,379 [run_pretraining.py:  534]:	loss/total_loss, 7.185575008392334, 2951
[INFO] 2021-07-12 19:31:01,379 [run_pretraining.py:  535]:	loss/mlm_loss, 7.185575008392334, 2951
[INFO] 2021-07-12 19:31:01,379 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9499997253878973e-05, 2951
[INFO] 2021-07-12 19:31:01,379 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2951
[INFO] 2021-07-12 19:31:01,380 [run_pretraining.py:  558]:	worker_index: 3, step: 2951, cost: 7.185575, mlm loss: 7.185575, speed: 1.055095 steps/s, speed: 8.440759 samples/s, speed: 4321.668726 tokens/s, learning rate: 2.950e-05, loss_scalings: 2814.750488, pp_loss: 7.156519
[INFO] 2021-07-12 19:31:01,380 [run_pretraining.py:  512]:	********exe.run_2951******* 
[INFO] 2021-07-12 19:31:02,285 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:02,286 [run_pretraining.py:  534]:	loss/total_loss, 7.371761322021484, 2952
[INFO] 2021-07-12 19:31:02,286 [run_pretraining.py:  535]:	loss/mlm_loss, 7.371761322021484, 2952
[INFO] 2021-07-12 19:31:02,286 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9509999876609072e-05, 2952
[INFO] 2021-07-12 19:31:02,286 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2952
[INFO] 2021-07-12 19:31:02,286 [run_pretraining.py:  558]:	worker_index: 3, step: 2952, cost: 7.371761, mlm loss: 7.371761, speed: 1.104001 steps/s, speed: 8.832010 samples/s, speed: 4521.989244 tokens/s, learning rate: 2.951e-05, loss_scalings: 2814.750488, pp_loss: 7.349903
[INFO] 2021-07-12 19:31:02,286 [run_pretraining.py:  512]:	********exe.run_2952******* 
[INFO] 2021-07-12 19:31:03,186 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:03,187 [run_pretraining.py:  534]:	loss/total_loss, 7.021334648132324, 2953
[INFO] 2021-07-12 19:31:03,187 [run_pretraining.py:  535]:	loss/mlm_loss, 7.021334648132324, 2953
[INFO] 2021-07-12 19:31:03,187 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9519998861360364e-05, 2953
[INFO] 2021-07-12 19:31:03,187 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2953
[INFO] 2021-07-12 19:31:03,187 [run_pretraining.py:  558]:	worker_index: 3, step: 2953, cost: 7.021335, mlm loss: 7.021335, speed: 1.110295 steps/s, speed: 8.882361 samples/s, speed: 4547.768660 tokens/s, learning rate: 2.952e-05, loss_scalings: 2814.750488, pp_loss: 7.113173
[INFO] 2021-07-12 19:31:03,187 [run_pretraining.py:  512]:	********exe.run_2953******* 
[INFO] 2021-07-12 19:31:04,084 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:04,085 [run_pretraining.py:  534]:	loss/total_loss, 7.707090377807617, 2954
[INFO] 2021-07-12 19:31:04,085 [run_pretraining.py:  535]:	loss/mlm_loss, 7.707090377807617, 2954
[INFO] 2021-07-12 19:31:04,085 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.952999966510106e-05, 2954
[INFO] 2021-07-12 19:31:04,085 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2954
[INFO] 2021-07-12 19:31:04,085 [run_pretraining.py:  558]:	worker_index: 3, step: 2954, cost: 7.707090, mlm loss: 7.707090, speed: 1.114600 steps/s, speed: 8.916799 samples/s, speed: 4565.401114 tokens/s, learning rate: 2.953e-05, loss_scalings: 2814.750488, pp_loss: 7.260247
[INFO] 2021-07-12 19:31:04,085 [run_pretraining.py:  512]:	********exe.run_2954******* 
[INFO] 2021-07-12 19:31:04,988 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:04,988 [run_pretraining.py:  534]:	loss/total_loss, 7.527358055114746, 2955
[INFO] 2021-07-12 19:31:04,988 [run_pretraining.py:  535]:	loss/mlm_loss, 7.527358055114746, 2955
[INFO] 2021-07-12 19:31:04,989 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.953999864985235e-05, 2955
[INFO] 2021-07-12 19:31:04,989 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2955
[INFO] 2021-07-12 19:31:04,989 [run_pretraining.py:  558]:	worker_index: 3, step: 2955, cost: 7.527358, mlm loss: 7.527358, speed: 1.107382 steps/s, speed: 8.859059 samples/s, speed: 4535.838462 tokens/s, learning rate: 2.954e-05, loss_scalings: 2814.750488, pp_loss: 7.275375
[INFO] 2021-07-12 19:31:04,989 [run_pretraining.py:  512]:	********exe.run_2955******* 
[INFO] 2021-07-12 19:31:05,896 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:05,897 [run_pretraining.py:  534]:	loss/total_loss, 6.220329284667969, 2956
[INFO] 2021-07-12 19:31:05,897 [run_pretraining.py:  535]:	loss/mlm_loss, 6.220329284667969, 2956
[INFO] 2021-07-12 19:31:05,897 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9549999453593045e-05, 2956
[INFO] 2021-07-12 19:31:05,897 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2956
[INFO] 2021-07-12 19:31:05,897 [run_pretraining.py:  558]:	worker_index: 3, step: 2956, cost: 6.220329, mlm loss: 6.220329, speed: 1.101469 steps/s, speed: 8.811750 samples/s, speed: 4511.616236 tokens/s, learning rate: 2.955e-05, loss_scalings: 2814.750488, pp_loss: 6.707891
[INFO] 2021-07-12 19:31:05,897 [run_pretraining.py:  512]:	********exe.run_2956******* 
[INFO] 2021-07-12 19:31:06,804 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:06,805 [run_pretraining.py:  534]:	loss/total_loss, 7.40141487121582, 2957
[INFO] 2021-07-12 19:31:06,805 [run_pretraining.py:  535]:	loss/mlm_loss, 7.40141487121582, 2957
[INFO] 2021-07-12 19:31:06,805 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9559998438344337e-05, 2957
[INFO] 2021-07-12 19:31:06,805 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2957
[INFO] 2021-07-12 19:31:06,805 [run_pretraining.py:  558]:	worker_index: 3, step: 2957, cost: 7.401415, mlm loss: 7.401415, speed: 1.102013 steps/s, speed: 8.816103 samples/s, speed: 4513.844757 tokens/s, learning rate: 2.956e-05, loss_scalings: 2814.750488, pp_loss: 7.125882
[INFO] 2021-07-12 19:31:06,805 [run_pretraining.py:  512]:	********exe.run_2957******* 
[INFO] 2021-07-12 19:31:07,712 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:07,712 [run_pretraining.py:  534]:	loss/total_loss, 7.383012771606445, 2958
[INFO] 2021-07-12 19:31:07,712 [run_pretraining.py:  535]:	loss/mlm_loss, 7.383012771606445, 2958
[INFO] 2021-07-12 19:31:07,712 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9570001061074436e-05, 2958
[INFO] 2021-07-12 19:31:07,713 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2958
[INFO] 2021-07-12 19:31:07,713 [run_pretraining.py:  558]:	worker_index: 3, step: 2958, cost: 7.383013, mlm loss: 7.383013, speed: 1.102914 steps/s, speed: 8.823308 samples/s, speed: 4517.533761 tokens/s, learning rate: 2.957e-05, loss_scalings: 2814.750488, pp_loss: 7.063169
[INFO] 2021-07-12 19:31:07,713 [run_pretraining.py:  512]:	********exe.run_2958******* 
[INFO] 2021-07-12 19:31:08,622 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:08,622 [run_pretraining.py:  534]:	loss/total_loss, 7.162579536437988, 2959
[INFO] 2021-07-12 19:31:08,623 [run_pretraining.py:  535]:	loss/mlm_loss, 7.162579536437988, 2959
[INFO] 2021-07-12 19:31:08,623 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9580000045825727e-05, 2959
[INFO] 2021-07-12 19:31:08,623 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2959
[INFO] 2021-07-12 19:31:08,623 [run_pretraining.py:  558]:	worker_index: 3, step: 2959, cost: 7.162580, mlm loss: 7.162580, speed: 1.099458 steps/s, speed: 8.795660 samples/s, speed: 4503.378001 tokens/s, learning rate: 2.958e-05, loss_scalings: 2814.750488, pp_loss: 7.355451
[INFO] 2021-07-12 19:31:08,623 [run_pretraining.py:  512]:	********exe.run_2959******* 
[INFO] 2021-07-12 19:31:09,535 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:09,535 [run_pretraining.py:  534]:	loss/total_loss, 7.065736770629883, 2960
[INFO] 2021-07-12 19:31:09,535 [run_pretraining.py:  535]:	loss/mlm_loss, 7.065736770629883, 2960
[INFO] 2021-07-12 19:31:09,535 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9589997211587615e-05, 2960
[INFO] 2021-07-12 19:31:09,535 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2960
[INFO] 2021-07-12 19:31:09,536 [run_pretraining.py:  558]:	worker_index: 3, step: 2960, cost: 7.065737, mlm loss: 7.065737, speed: 1.096408 steps/s, speed: 8.771265 samples/s, speed: 4490.887894 tokens/s, learning rate: 2.959e-05, loss_scalings: 2814.750488, pp_loss: 7.374310
[INFO] 2021-07-12 19:31:09,536 [run_pretraining.py:  512]:	********exe.run_2960******* 
[INFO] 2021-07-12 19:31:10,444 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:10,445 [run_pretraining.py:  534]:	loss/total_loss, 7.3847808837890625, 2961
[INFO] 2021-07-12 19:31:10,445 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3847808837890625, 2961
[INFO] 2021-07-12 19:31:10,445 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9599999834317714e-05, 2961
[INFO] 2021-07-12 19:31:10,445 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2961
[INFO] 2021-07-12 19:31:10,445 [run_pretraining.py:  558]:	worker_index: 3, step: 2961, cost: 7.384781, mlm loss: 7.384781, speed: 1.100435 steps/s, speed: 8.803483 samples/s, speed: 4507.383372 tokens/s, learning rate: 2.960e-05, loss_scalings: 2814.750488, pp_loss: 6.937863
[INFO] 2021-07-12 19:31:10,445 [run_pretraining.py:  512]:	********exe.run_2961******* 
[INFO] 2021-07-12 19:31:11,357 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:11,358 [run_pretraining.py:  534]:	loss/total_loss, 7.0955657958984375, 2962
[INFO] 2021-07-12 19:31:11,358 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0955657958984375, 2962
[INFO] 2021-07-12 19:31:11,358 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9609998819069006e-05, 2962
[INFO] 2021-07-12 19:31:11,358 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2962
[INFO] 2021-07-12 19:31:11,358 [run_pretraining.py:  558]:	worker_index: 3, step: 2962, cost: 7.095566, mlm loss: 7.095566, speed: 1.095973 steps/s, speed: 8.767782 samples/s, speed: 4489.104219 tokens/s, learning rate: 2.961e-05, loss_scalings: 2814.750488, pp_loss: 6.938895
[INFO] 2021-07-12 19:31:11,358 [run_pretraining.py:  512]:	********exe.run_2962******* 
[INFO] 2021-07-12 19:31:12,261 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:12,262 [run_pretraining.py:  534]:	loss/total_loss, 7.411808013916016, 2963
[INFO] 2021-07-12 19:31:12,262 [run_pretraining.py:  535]:	loss/mlm_loss, 7.411808013916016, 2963
[INFO] 2021-07-12 19:31:12,262 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.96199996228097e-05, 2963
[INFO] 2021-07-12 19:31:12,262 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2963
[INFO] 2021-07-12 19:31:12,262 [run_pretraining.py:  558]:	worker_index: 3, step: 2963, cost: 7.411808, mlm loss: 7.411808, speed: 1.106882 steps/s, speed: 8.855057 samples/s, speed: 4533.789175 tokens/s, learning rate: 2.962e-05, loss_scalings: 2814.750488, pp_loss: 6.918520
[INFO] 2021-07-12 19:31:12,262 [run_pretraining.py:  512]:	********exe.run_2963******* 
[INFO] 2021-07-12 19:31:13,169 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:13,169 [run_pretraining.py:  534]:	loss/total_loss, 7.013839244842529, 2964
[INFO] 2021-07-12 19:31:13,169 [run_pretraining.py:  535]:	loss/mlm_loss, 7.013839244842529, 2964
[INFO] 2021-07-12 19:31:13,169 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9629998607560992e-05, 2964
[INFO] 2021-07-12 19:31:13,169 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2964
[INFO] 2021-07-12 19:31:13,169 [run_pretraining.py:  558]:	worker_index: 3, step: 2964, cost: 7.013839, mlm loss: 7.013839, speed: 1.102781 steps/s, speed: 8.822250 samples/s, speed: 4516.992140 tokens/s, learning rate: 2.963e-05, loss_scalings: 2814.750488, pp_loss: 7.421290
[INFO] 2021-07-12 19:31:13,170 [run_pretraining.py:  512]:	********exe.run_2964******* 
[INFO] 2021-07-12 19:31:14,074 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:14,074 [run_pretraining.py:  534]:	loss/total_loss, 7.011376857757568, 2965
[INFO] 2021-07-12 19:31:14,075 [run_pretraining.py:  535]:	loss/mlm_loss, 7.011376857757568, 2965
[INFO] 2021-07-12 19:31:14,075 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9639999411301687e-05, 2965
[INFO] 2021-07-12 19:31:14,075 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2965
[INFO] 2021-07-12 19:31:14,075 [run_pretraining.py:  558]:	worker_index: 3, step: 2965, cost: 7.011377, mlm loss: 7.011377, speed: 1.105373 steps/s, speed: 8.842980 samples/s, speed: 4527.605873 tokens/s, learning rate: 2.964e-05, loss_scalings: 2814.750488, pp_loss: 6.293993
[INFO] 2021-07-12 19:31:14,075 [run_pretraining.py:  512]:	********exe.run_2965******* 
[INFO] 2021-07-12 19:31:14,980 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:14,981 [run_pretraining.py:  534]:	loss/total_loss, 6.367905139923096, 2966
[INFO] 2021-07-12 19:31:14,981 [run_pretraining.py:  535]:	loss/mlm_loss, 6.367905139923096, 2966
[INFO] 2021-07-12 19:31:14,981 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.964999839605298e-05, 2966
[INFO] 2021-07-12 19:31:14,981 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2966
[INFO] 2021-07-12 19:31:14,981 [run_pretraining.py:  558]:	worker_index: 3, step: 2966, cost: 6.367905, mlm loss: 6.367905, speed: 1.103894 steps/s, speed: 8.831150 samples/s, speed: 4521.548893 tokens/s, learning rate: 2.965e-05, loss_scalings: 2814.750488, pp_loss: 7.207412
[INFO] 2021-07-12 19:31:14,981 [run_pretraining.py:  512]:	********exe.run_2966******* 
[INFO] 2021-07-12 19:31:15,896 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:15,897 [run_pretraining.py:  534]:	loss/total_loss, 7.8915839195251465, 2967
[INFO] 2021-07-12 19:31:15,897 [run_pretraining.py:  535]:	loss/mlm_loss, 7.8915839195251465, 2967
[INFO] 2021-07-12 19:31:15,897 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9660001018783078e-05, 2967
[INFO] 2021-07-12 19:31:15,897 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2967
[INFO] 2021-07-12 19:31:15,897 [run_pretraining.py:  558]:	worker_index: 3, step: 2967, cost: 7.891584, mlm loss: 7.891584, speed: 1.092893 steps/s, speed: 8.743145 samples/s, speed: 4476.490088 tokens/s, learning rate: 2.966e-05, loss_scalings: 2814.750488, pp_loss: 7.297965
[INFO] 2021-07-12 19:31:15,897 [run_pretraining.py:  512]:	********exe.run_2967******* 
[INFO] 2021-07-12 19:31:16,820 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:16,820 [run_pretraining.py:  534]:	loss/total_loss, 8.349116325378418, 2968
[INFO] 2021-07-12 19:31:16,820 [run_pretraining.py:  535]:	loss/mlm_loss, 8.349116325378418, 2968
[INFO] 2021-07-12 19:31:16,820 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.967000000353437e-05, 2968
[INFO] 2021-07-12 19:31:16,820 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2968
[INFO] 2021-07-12 19:31:16,820 [run_pretraining.py:  558]:	worker_index: 3, step: 2968, cost: 8.349116, mlm loss: 8.349116, speed: 1.083603 steps/s, speed: 8.668823 samples/s, speed: 4438.437571 tokens/s, learning rate: 2.967e-05, loss_scalings: 2814.750488, pp_loss: 6.537968
[INFO] 2021-07-12 19:31:16,820 [run_pretraining.py:  512]:	********exe.run_2968******* 
[INFO] 2021-07-12 19:31:17,876 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:17,877 [run_pretraining.py:  534]:	loss/total_loss, 7.130250930786133, 2969
[INFO] 2021-07-12 19:31:17,877 [run_pretraining.py:  535]:	loss/mlm_loss, 7.130250930786133, 2969
[INFO] 2021-07-12 19:31:17,877 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9679997169296257e-05, 2969
[INFO] 2021-07-12 19:31:17,877 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2969
[INFO] 2021-07-12 19:31:17,877 [run_pretraining.py:  558]:	worker_index: 3, step: 2969, cost: 7.130251, mlm loss: 7.130251, speed: 0.946723 steps/s, speed: 7.573786 samples/s, speed: 3877.778441 tokens/s, learning rate: 2.968e-05, loss_scalings: 2814.750488, pp_loss: 7.238344
[INFO] 2021-07-12 19:31:17,877 [run_pretraining.py:  512]:	********exe.run_2969******* 
[INFO] 2021-07-12 19:31:18,946 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:18,947 [run_pretraining.py:  534]:	loss/total_loss, 7.689517498016357, 2970
[INFO] 2021-07-12 19:31:18,947 [run_pretraining.py:  535]:	loss/mlm_loss, 7.689517498016357, 2970
[INFO] 2021-07-12 19:31:18,947 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9689999792026356e-05, 2970
[INFO] 2021-07-12 19:31:18,947 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2970
[INFO] 2021-07-12 19:31:18,947 [run_pretraining.py:  558]:	worker_index: 3, step: 2970, cost: 7.689517, mlm loss: 7.689517, speed: 0.935484 steps/s, speed: 7.483873 samples/s, speed: 3831.743085 tokens/s, learning rate: 2.969e-05, loss_scalings: 2814.750488, pp_loss: 6.944481
[INFO] 2021-07-12 19:31:18,947 [run_pretraining.py:  512]:	********exe.run_2970******* 
[INFO] 2021-07-12 19:31:20,003 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:20,003 [run_pretraining.py:  534]:	loss/total_loss, 7.126684188842773, 2971
[INFO] 2021-07-12 19:31:20,003 [run_pretraining.py:  535]:	loss/mlm_loss, 7.126684188842773, 2971
[INFO] 2021-07-12 19:31:20,003 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9699998776777647e-05, 2971
[INFO] 2021-07-12 19:31:20,004 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2971
[INFO] 2021-07-12 19:31:20,004 [run_pretraining.py:  558]:	worker_index: 3, step: 2971, cost: 7.126684, mlm loss: 7.126684, speed: 0.946933 steps/s, speed: 7.575465 samples/s, speed: 3878.638155 tokens/s, learning rate: 2.970e-05, loss_scalings: 2814.750488, pp_loss: 7.306892
[INFO] 2021-07-12 19:31:20,004 [run_pretraining.py:  512]:	********exe.run_2971******* 
[INFO] 2021-07-12 19:31:21,044 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:21,045 [run_pretraining.py:  534]:	loss/total_loss, 7.9867939949035645, 2972
[INFO] 2021-07-12 19:31:21,045 [run_pretraining.py:  535]:	loss/mlm_loss, 7.9867939949035645, 2972
[INFO] 2021-07-12 19:31:21,045 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9709999580518343e-05, 2972
[INFO] 2021-07-12 19:31:21,045 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2972
[INFO] 2021-07-12 19:31:21,045 [run_pretraining.py:  558]:	worker_index: 3, step: 2972, cost: 7.986794, mlm loss: 7.986794, speed: 0.960572 steps/s, speed: 7.684574 samples/s, speed: 3934.501994 tokens/s, learning rate: 2.971e-05, loss_scalings: 2814.750488, pp_loss: 7.377452
[INFO] 2021-07-12 19:31:21,045 [run_pretraining.py:  512]:	********exe.run_2972******* 
[INFO] 2021-07-12 19:31:22,098 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:22,098 [run_pretraining.py:  534]:	loss/total_loss, 7.132692813873291, 2973
[INFO] 2021-07-12 19:31:22,099 [run_pretraining.py:  535]:	loss/mlm_loss, 7.132692813873291, 2973
[INFO] 2021-07-12 19:31:22,099 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9719998565269634e-05, 2973
[INFO] 2021-07-12 19:31:22,099 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2973
[INFO] 2021-07-12 19:31:22,099 [run_pretraining.py:  558]:	worker_index: 3, step: 2973, cost: 7.132693, mlm loss: 7.132693, speed: 0.949803 steps/s, speed: 7.598423 samples/s, speed: 3890.392714 tokens/s, learning rate: 2.972e-05, loss_scalings: 2814.750488, pp_loss: 7.052825
[INFO] 2021-07-12 19:31:22,099 [run_pretraining.py:  512]:	********exe.run_2973******* 
[INFO] 2021-07-12 19:31:23,153 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:23,153 [run_pretraining.py:  534]:	loss/total_loss, 7.457469940185547, 2974
[INFO] 2021-07-12 19:31:23,154 [run_pretraining.py:  535]:	loss/mlm_loss, 7.457469940185547, 2974
[INFO] 2021-07-12 19:31:23,154 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9730001187999733e-05, 2974
[INFO] 2021-07-12 19:31:23,154 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2974
[INFO] 2021-07-12 19:31:23,154 [run_pretraining.py:  558]:	worker_index: 3, step: 2974, cost: 7.457470, mlm loss: 7.457470, speed: 0.948438 steps/s, speed: 7.587504 samples/s, speed: 3884.802119 tokens/s, learning rate: 2.973e-05, loss_scalings: 2814.750488, pp_loss: 6.656170
[INFO] 2021-07-12 19:31:23,154 [run_pretraining.py:  512]:	********exe.run_2974******* 
[INFO] 2021-07-12 19:31:24,207 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:24,207 [run_pretraining.py:  534]:	loss/total_loss, 8.046092987060547, 2975
[INFO] 2021-07-12 19:31:24,208 [run_pretraining.py:  535]:	loss/mlm_loss, 8.046092987060547, 2975
[INFO] 2021-07-12 19:31:24,208 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.973999835376162e-05, 2975
[INFO] 2021-07-12 19:31:24,208 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2975
[INFO] 2021-07-12 19:31:24,208 [run_pretraining.py:  558]:	worker_index: 3, step: 2975, cost: 8.046093, mlm loss: 8.046093, speed: 0.949381 steps/s, speed: 7.595047 samples/s, speed: 3888.664115 tokens/s, learning rate: 2.974e-05, loss_scalings: 2814.750488, pp_loss: 7.628665
[INFO] 2021-07-12 19:31:24,208 [run_pretraining.py:  512]:	********exe.run_2975******* 
[INFO] 2021-07-12 19:31:25,269 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:25,269 [run_pretraining.py:  534]:	loss/total_loss, 7.726428031921387, 2976
[INFO] 2021-07-12 19:31:25,269 [run_pretraining.py:  535]:	loss/mlm_loss, 7.726428031921387, 2976
[INFO] 2021-07-12 19:31:25,270 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.975000097649172e-05, 2976
[INFO] 2021-07-12 19:31:25,270 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2976
[INFO] 2021-07-12 19:31:25,270 [run_pretraining.py:  558]:	worker_index: 3, step: 2976, cost: 7.726428, mlm loss: 7.726428, speed: 0.942261 steps/s, speed: 7.538091 samples/s, speed: 3859.502521 tokens/s, learning rate: 2.975e-05, loss_scalings: 2814.750488, pp_loss: 7.286167
[INFO] 2021-07-12 19:31:25,270 [run_pretraining.py:  512]:	********exe.run_2976******* 
[INFO] 2021-07-12 19:31:26,327 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:26,328 [run_pretraining.py:  534]:	loss/total_loss, 7.605940818786621, 2977
[INFO] 2021-07-12 19:31:26,328 [run_pretraining.py:  535]:	loss/mlm_loss, 7.605940818786621, 2977
[INFO] 2021-07-12 19:31:26,328 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.975999996124301e-05, 2977
[INFO] 2021-07-12 19:31:26,328 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2977
[INFO] 2021-07-12 19:31:26,328 [run_pretraining.py:  558]:	worker_index: 3, step: 2977, cost: 7.605941, mlm loss: 7.605941, speed: 0.945203 steps/s, speed: 7.561625 samples/s, speed: 3871.552097 tokens/s, learning rate: 2.976e-05, loss_scalings: 2814.750488, pp_loss: 7.158399
[INFO] 2021-07-12 19:31:26,328 [run_pretraining.py:  512]:	********exe.run_2977******* 
[INFO] 2021-07-12 19:31:27,385 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:27,386 [run_pretraining.py:  534]:	loss/total_loss, 4.269702911376953, 2978
[INFO] 2021-07-12 19:31:27,386 [run_pretraining.py:  535]:	loss/mlm_loss, 4.269702911376953, 2978
[INFO] 2021-07-12 19:31:27,386 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9769998945994303e-05, 2978
[INFO] 2021-07-12 19:31:27,386 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2978
[INFO] 2021-07-12 19:31:27,386 [run_pretraining.py:  558]:	worker_index: 3, step: 2978, cost: 4.269703, mlm loss: 4.269703, speed: 0.946002 steps/s, speed: 7.568014 samples/s, speed: 3874.823130 tokens/s, learning rate: 2.977e-05, loss_scalings: 2814.750488, pp_loss: 6.592398
[INFO] 2021-07-12 19:31:27,386 [run_pretraining.py:  512]:	********exe.run_2978******* 
[INFO] 2021-07-12 19:31:28,422 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:28,422 [run_pretraining.py:  534]:	loss/total_loss, 6.7013444900512695, 2979
[INFO] 2021-07-12 19:31:28,423 [run_pretraining.py:  535]:	loss/mlm_loss, 6.7013444900512695, 2979
[INFO] 2021-07-12 19:31:28,423 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9779999749734998e-05, 2979
[INFO] 2021-07-12 19:31:28,423 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2979
[INFO] 2021-07-12 19:31:28,423 [run_pretraining.py:  558]:	worker_index: 3, step: 2979, cost: 6.701344, mlm loss: 6.701344, speed: 0.965157 steps/s, speed: 7.721258 samples/s, speed: 3953.283974 tokens/s, learning rate: 2.978e-05, loss_scalings: 2814.750488, pp_loss: 6.954618
[INFO] 2021-07-12 19:31:28,423 [run_pretraining.py:  512]:	********exe.run_2979******* 
[INFO] 2021-07-12 19:31:29,476 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:29,476 [run_pretraining.py:  534]:	loss/total_loss, 7.482989311218262, 2980
[INFO] 2021-07-12 19:31:29,476 [run_pretraining.py:  535]:	loss/mlm_loss, 7.482989311218262, 2980
[INFO] 2021-07-12 19:31:29,476 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.978999873448629e-05, 2980
[INFO] 2021-07-12 19:31:29,476 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2980
[INFO] 2021-07-12 19:31:29,476 [run_pretraining.py:  558]:	worker_index: 3, step: 2980, cost: 7.482989, mlm loss: 7.482989, speed: 0.949586 steps/s, speed: 7.596691 samples/s, speed: 3889.505767 tokens/s, learning rate: 2.979e-05, loss_scalings: 2814.750488, pp_loss: 7.135761
[INFO] 2021-07-12 19:31:29,477 [run_pretraining.py:  512]:	********exe.run_2980******* 
[INFO] 2021-07-12 19:31:30,538 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:30,539 [run_pretraining.py:  534]:	loss/total_loss, 6.935513496398926, 2981
[INFO] 2021-07-12 19:31:30,539 [run_pretraining.py:  535]:	loss/mlm_loss, 6.935513496398926, 2981
[INFO] 2021-07-12 19:31:30,539 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9799999538226984e-05, 2981
[INFO] 2021-07-12 19:31:30,539 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2981
[INFO] 2021-07-12 19:31:30,539 [run_pretraining.py:  558]:	worker_index: 3, step: 2981, cost: 6.935513, mlm loss: 6.935513, speed: 0.941595 steps/s, speed: 7.532757 samples/s, speed: 3856.771522 tokens/s, learning rate: 2.980e-05, loss_scalings: 2814.750488, pp_loss: 7.089230
[INFO] 2021-07-12 19:31:30,539 [run_pretraining.py:  512]:	********exe.run_2981******* 
[INFO] 2021-07-12 19:31:31,605 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:31,606 [run_pretraining.py:  534]:	loss/total_loss, 6.73674201965332, 2982
[INFO] 2021-07-12 19:31:31,606 [run_pretraining.py:  535]:	loss/mlm_loss, 6.73674201965332, 2982
[INFO] 2021-07-12 19:31:31,606 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9809998522978276e-05, 2982
[INFO] 2021-07-12 19:31:31,606 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2982
[INFO] 2021-07-12 19:31:31,606 [run_pretraining.py:  558]:	worker_index: 3, step: 2982, cost: 6.736742, mlm loss: 6.736742, speed: 0.937618 steps/s, speed: 7.500943 samples/s, speed: 3840.482658 tokens/s, learning rate: 2.981e-05, loss_scalings: 2814.750488, pp_loss: 7.204367
[INFO] 2021-07-12 19:31:31,606 [run_pretraining.py:  512]:	********exe.run_2982******* 
[INFO] 2021-07-12 19:31:32,656 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:32,657 [run_pretraining.py:  534]:	loss/total_loss, 7.803134441375732, 2983
[INFO] 2021-07-12 19:31:32,657 [run_pretraining.py:  535]:	loss/mlm_loss, 7.803134441375732, 2983
[INFO] 2021-07-12 19:31:32,657 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9820001145708375e-05, 2983
[INFO] 2021-07-12 19:31:32,657 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2983
[INFO] 2021-07-12 19:31:32,657 [run_pretraining.py:  558]:	worker_index: 3, step: 2983, cost: 7.803134, mlm loss: 7.803134, speed: 0.952200 steps/s, speed: 7.617604 samples/s, speed: 3900.213079 tokens/s, learning rate: 2.982e-05, loss_scalings: 2814.750488, pp_loss: 7.360060
[INFO] 2021-07-12 19:31:32,657 [run_pretraining.py:  512]:	********exe.run_2983******* 
[INFO] 2021-07-12 19:31:33,720 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:33,720 [run_pretraining.py:  534]:	loss/total_loss, 7.176438808441162, 2984
[INFO] 2021-07-12 19:31:33,720 [run_pretraining.py:  535]:	loss/mlm_loss, 7.176438808441162, 2984
[INFO] 2021-07-12 19:31:33,721 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9829998311470263e-05, 2984
[INFO] 2021-07-12 19:31:33,721 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2984
[INFO] 2021-07-12 19:31:33,721 [run_pretraining.py:  558]:	worker_index: 3, step: 2984, cost: 7.176439, mlm loss: 7.176439, speed: 0.940800 steps/s, speed: 7.526399 samples/s, speed: 3853.516188 tokens/s, learning rate: 2.983e-05, loss_scalings: 2814.750488, pp_loss: 7.284649
[INFO] 2021-07-12 19:31:33,721 [run_pretraining.py:  512]:	********exe.run_2984******* 
[INFO] 2021-07-12 19:31:34,775 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:34,776 [run_pretraining.py:  534]:	loss/total_loss, 6.703033924102783, 2985
[INFO] 2021-07-12 19:31:34,776 [run_pretraining.py:  535]:	loss/mlm_loss, 6.703033924102783, 2985
[INFO] 2021-07-12 19:31:34,776 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.984000093420036e-05, 2985
[INFO] 2021-07-12 19:31:34,776 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2985
[INFO] 2021-07-12 19:31:34,776 [run_pretraining.py:  558]:	worker_index: 3, step: 2985, cost: 6.703034, mlm loss: 6.703034, speed: 0.948146 steps/s, speed: 7.585170 samples/s, speed: 3883.606914 tokens/s, learning rate: 2.984e-05, loss_scalings: 2814.750488, pp_loss: 6.868836
[INFO] 2021-07-12 19:31:34,776 [run_pretraining.py:  512]:	********exe.run_2985******* 
[INFO] 2021-07-12 19:31:35,932 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:35,932 [run_pretraining.py:  534]:	loss/total_loss, 7.351178169250488, 2986
[INFO] 2021-07-12 19:31:35,932 [run_pretraining.py:  535]:	loss/mlm_loss, 7.351178169250488, 2986
[INFO] 2021-07-12 19:31:35,932 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9849999918951653e-05, 2986
[INFO] 2021-07-12 19:31:35,933 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2986
[INFO] 2021-07-12 19:31:35,933 [run_pretraining.py:  558]:	worker_index: 3, step: 2986, cost: 7.351178, mlm loss: 7.351178, speed: 0.865094 steps/s, speed: 6.920748 samples/s, speed: 3543.423184 tokens/s, learning rate: 2.985e-05, loss_scalings: 2814.750488, pp_loss: 7.209492
[INFO] 2021-07-12 19:31:35,933 [run_pretraining.py:  512]:	********exe.run_2986******* 
[INFO] 2021-07-12 19:31:37,051 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:37,052 [run_pretraining.py:  534]:	loss/total_loss, 6.922574520111084, 2987
[INFO] 2021-07-12 19:31:37,052 [run_pretraining.py:  535]:	loss/mlm_loss, 6.922574520111084, 2987
[INFO] 2021-07-12 19:31:37,052 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9859998903702945e-05, 2987
[INFO] 2021-07-12 19:31:37,052 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2987
[INFO] 2021-07-12 19:31:37,052 [run_pretraining.py:  558]:	worker_index: 3, step: 2987, cost: 6.922575, mlm loss: 6.922575, speed: 0.893605 steps/s, speed: 7.148843 samples/s, speed: 3660.207676 tokens/s, learning rate: 2.986e-05, loss_scalings: 2814.750488, pp_loss: 6.293770
[INFO] 2021-07-12 19:31:37,052 [run_pretraining.py:  512]:	********exe.run_2987******* 
[INFO] 2021-07-12 19:31:38,137 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:38,138 [run_pretraining.py:  534]:	loss/total_loss, 7.389916896820068, 2988
[INFO] 2021-07-12 19:31:38,138 [run_pretraining.py:  535]:	loss/mlm_loss, 7.389916896820068, 2988
[INFO] 2021-07-12 19:31:38,138 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.986999970744364e-05, 2988
[INFO] 2021-07-12 19:31:38,138 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2988
[INFO] 2021-07-12 19:31:38,138 [run_pretraining.py:  558]:	worker_index: 3, step: 2988, cost: 7.389917, mlm loss: 7.389917, speed: 0.921529 steps/s, speed: 7.372233 samples/s, speed: 3774.583410 tokens/s, learning rate: 2.987e-05, loss_scalings: 2814.750488, pp_loss: 6.561803
[INFO] 2021-07-12 19:31:38,138 [run_pretraining.py:  512]:	********exe.run_2988******* 
[INFO] 2021-07-12 19:31:39,176 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:39,177 [run_pretraining.py:  534]:	loss/total_loss, 5.186302185058594, 2989
[INFO] 2021-07-12 19:31:39,177 [run_pretraining.py:  535]:	loss/mlm_loss, 5.186302185058594, 2989
[INFO] 2021-07-12 19:31:39,177 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.987999869219493e-05, 2989
[INFO] 2021-07-12 19:31:39,177 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2989
[INFO] 2021-07-12 19:31:39,177 [run_pretraining.py:  558]:	worker_index: 3, step: 2989, cost: 5.186302, mlm loss: 5.186302, speed: 0.963270 steps/s, speed: 7.706157 samples/s, speed: 3945.552156 tokens/s, learning rate: 2.988e-05, loss_scalings: 2814.750488, pp_loss: 6.744365
[INFO] 2021-07-12 19:31:39,177 [run_pretraining.py:  512]:	********exe.run_2989******* 
[INFO] 2021-07-12 19:31:40,079 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:40,080 [run_pretraining.py:  534]:	loss/total_loss, 7.450071811676025, 2990
[INFO] 2021-07-12 19:31:40,080 [run_pretraining.py:  535]:	loss/mlm_loss, 7.450071811676025, 2990
[INFO] 2021-07-12 19:31:40,080 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9889999495935626e-05, 2990
[INFO] 2021-07-12 19:31:40,080 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2990
[INFO] 2021-07-12 19:31:40,080 [run_pretraining.py:  558]:	worker_index: 3, step: 2990, cost: 7.450072, mlm loss: 7.450072, speed: 1.107894 steps/s, speed: 8.863152 samples/s, speed: 4537.933952 tokens/s, learning rate: 2.989e-05, loss_scalings: 2814.750488, pp_loss: 7.228183
[INFO] 2021-07-12 19:31:40,080 [run_pretraining.py:  512]:	********exe.run_2990******* 
[INFO] 2021-07-12 19:31:40,982 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:40,983 [run_pretraining.py:  534]:	loss/total_loss, 6.940285682678223, 2991
[INFO] 2021-07-12 19:31:40,983 [run_pretraining.py:  535]:	loss/mlm_loss, 6.940285682678223, 2991
[INFO] 2021-07-12 19:31:40,983 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9899998480686918e-05, 2991
[INFO] 2021-07-12 19:31:40,983 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2991
[INFO] 2021-07-12 19:31:40,983 [run_pretraining.py:  558]:	worker_index: 3, step: 2991, cost: 6.940286, mlm loss: 6.940286, speed: 1.108156 steps/s, speed: 8.865246 samples/s, speed: 4539.005809 tokens/s, learning rate: 2.990e-05, loss_scalings: 2814.750488, pp_loss: 7.198419
[INFO] 2021-07-12 19:31:40,983 [run_pretraining.py:  512]:	********exe.run_2991******* 
[INFO] 2021-07-12 19:31:41,887 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:41,888 [run_pretraining.py:  534]:	loss/total_loss, 7.491101264953613, 2992
[INFO] 2021-07-12 19:31:41,888 [run_pretraining.py:  535]:	loss/mlm_loss, 7.491101264953613, 2992
[INFO] 2021-07-12 19:31:41,888 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9910001103417017e-05, 2992
[INFO] 2021-07-12 19:31:41,888 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2992
[INFO] 2021-07-12 19:31:41,888 [run_pretraining.py:  558]:	worker_index: 3, step: 2992, cost: 7.491101, mlm loss: 7.491101, speed: 1.105962 steps/s, speed: 8.847697 samples/s, speed: 4530.021027 tokens/s, learning rate: 2.991e-05, loss_scalings: 2814.750488, pp_loss: 6.397423
[INFO] 2021-07-12 19:31:41,888 [run_pretraining.py:  512]:	********exe.run_2992******* 
[INFO] 2021-07-12 19:31:42,792 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:42,793 [run_pretraining.py:  534]:	loss/total_loss, 7.490285873413086, 2993
[INFO] 2021-07-12 19:31:42,793 [run_pretraining.py:  535]:	loss/mlm_loss, 7.490285873413086, 2993
[INFO] 2021-07-12 19:31:42,793 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9919998269178905e-05, 2993
[INFO] 2021-07-12 19:31:42,793 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2993
[INFO] 2021-07-12 19:31:42,793 [run_pretraining.py:  558]:	worker_index: 3, step: 2993, cost: 7.490286, mlm loss: 7.490286, speed: 1.105343 steps/s, speed: 8.842740 samples/s, speed: 4527.482975 tokens/s, learning rate: 2.992e-05, loss_scalings: 2814.750488, pp_loss: 7.626069
[INFO] 2021-07-12 19:31:42,793 [run_pretraining.py:  512]:	********exe.run_2993******* 
[INFO] 2021-07-12 19:31:43,704 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:43,705 [run_pretraining.py:  534]:	loss/total_loss, 8.35786247253418, 2994
[INFO] 2021-07-12 19:31:43,705 [run_pretraining.py:  535]:	loss/mlm_loss, 8.35786247253418, 2994
[INFO] 2021-07-12 19:31:43,705 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9929997253930196e-05, 2994
[INFO] 2021-07-12 19:31:43,705 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2994
[INFO] 2021-07-12 19:31:43,705 [run_pretraining.py:  558]:	worker_index: 3, step: 2994, cost: 8.357862, mlm loss: 8.357862, speed: 1.097207 steps/s, speed: 8.777653 samples/s, speed: 4494.158513 tokens/s, learning rate: 2.993e-05, loss_scalings: 2814.750488, pp_loss: 6.779158
[INFO] 2021-07-12 19:31:43,705 [run_pretraining.py:  512]:	********exe.run_2994******* 
[INFO] 2021-07-12 19:31:44,611 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:44,611 [run_pretraining.py:  534]:	loss/total_loss, 7.125486373901367, 2995
[INFO] 2021-07-12 19:31:44,611 [run_pretraining.py:  535]:	loss/mlm_loss, 7.125486373901367, 2995
[INFO] 2021-07-12 19:31:44,611 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9939999876660295e-05, 2995
[INFO] 2021-07-12 19:31:44,611 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2995
[INFO] 2021-07-12 19:31:44,612 [run_pretraining.py:  558]:	worker_index: 3, step: 2995, cost: 7.125486, mlm loss: 7.125486, speed: 1.104320 steps/s, speed: 8.834557 samples/s, speed: 4523.292947 tokens/s, learning rate: 2.994e-05, loss_scalings: 2814.750488, pp_loss: 6.920798
[INFO] 2021-07-12 19:31:44,612 [run_pretraining.py:  512]:	********exe.run_2995******* 
[INFO] 2021-07-12 19:31:45,511 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:45,511 [run_pretraining.py:  534]:	loss/total_loss, 6.680499076843262, 2996
[INFO] 2021-07-12 19:31:45,511 [run_pretraining.py:  535]:	loss/mlm_loss, 6.680499076843262, 2996
[INFO] 2021-07-12 19:31:45,511 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9949998861411586e-05, 2996
[INFO] 2021-07-12 19:31:45,512 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2996
[INFO] 2021-07-12 19:31:45,512 [run_pretraining.py:  558]:	worker_index: 3, step: 2996, cost: 6.680499, mlm loss: 6.680499, speed: 1.111904 steps/s, speed: 8.895234 samples/s, speed: 4554.359715 tokens/s, learning rate: 2.995e-05, loss_scalings: 2814.750488, pp_loss: 7.374343
[INFO] 2021-07-12 19:31:45,512 [run_pretraining.py:  512]:	********exe.run_2996******* 
[INFO] 2021-07-12 19:31:46,413 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:46,413 [run_pretraining.py:  534]:	loss/total_loss, 6.860940933227539, 2997
[INFO] 2021-07-12 19:31:46,413 [run_pretraining.py:  535]:	loss/mlm_loss, 6.860940933227539, 2997
[INFO] 2021-07-12 19:31:46,413 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.995999966515228e-05, 2997
[INFO] 2021-07-12 19:31:46,414 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2997
[INFO] 2021-07-12 19:31:46,414 [run_pretraining.py:  558]:	worker_index: 3, step: 2997, cost: 6.860941, mlm loss: 6.860941, speed: 1.109407 steps/s, speed: 8.875254 samples/s, speed: 4544.129890 tokens/s, learning rate: 2.996e-05, loss_scalings: 2814.750488, pp_loss: 7.001611
[INFO] 2021-07-12 19:31:46,414 [run_pretraining.py:  512]:	********exe.run_2997******* 
[INFO] 2021-07-12 19:31:47,318 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:47,318 [run_pretraining.py:  534]:	loss/total_loss, 8.441786766052246, 2998
[INFO] 2021-07-12 19:31:47,318 [run_pretraining.py:  535]:	loss/mlm_loss, 8.441786766052246, 2998
[INFO] 2021-07-12 19:31:47,318 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9969998649903573e-05, 2998
[INFO] 2021-07-12 19:31:47,319 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2998
[INFO] 2021-07-12 19:31:47,319 [run_pretraining.py:  558]:	worker_index: 3, step: 2998, cost: 8.441787, mlm loss: 8.441787, speed: 1.105722 steps/s, speed: 8.845778 samples/s, speed: 4529.038179 tokens/s, learning rate: 2.997e-05, loss_scalings: 2814.750488, pp_loss: 7.431542
[INFO] 2021-07-12 19:31:47,319 [run_pretraining.py:  512]:	********exe.run_2998******* 
[INFO] 2021-07-12 19:31:48,224 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:48,225 [run_pretraining.py:  534]:	loss/total_loss, 7.7502217292785645, 2999
[INFO] 2021-07-12 19:31:48,225 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7502217292785645, 2999
[INFO] 2021-07-12 19:31:48,225 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9979999453644268e-05, 2999
[INFO] 2021-07-12 19:31:48,225 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2999
[INFO] 2021-07-12 19:31:48,225 [run_pretraining.py:  558]:	worker_index: 3, step: 2999, cost: 7.750222, mlm loss: 7.750222, speed: 1.103981 steps/s, speed: 8.831850 samples/s, speed: 4521.907118 tokens/s, learning rate: 2.998e-05, loss_scalings: 2814.750488, pp_loss: 7.304073
[INFO] 2021-07-12 19:31:48,225 [run_pretraining.py:  512]:	********exe.run_2999******* 
[INFO] 2021-07-12 19:31:49,143 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:49,144 [run_pretraining.py:  534]:	loss/total_loss, 7.411825180053711, 3000
[INFO] 2021-07-12 19:31:49,144 [run_pretraining.py:  535]:	loss/mlm_loss, 7.411825180053711, 3000
[INFO] 2021-07-12 19:31:49,144 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.998999843839556e-05, 3000
[INFO] 2021-07-12 19:31:49,144 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 3000
[INFO] 2021-07-12 19:31:49,144 [run_pretraining.py:  558]:	worker_index: 3, step: 3000, cost: 7.411825, mlm loss: 7.411825, speed: 1.088627 steps/s, speed: 8.709015 samples/s, speed: 4459.015594 tokens/s, learning rate: 2.999e-05, loss_scalings: 2814.750488, pp_loss: 7.365247
[DEBUG] 2021-07-12 19:31:50,242 [run_pretraining.py:  575]:	saving final models to output/step3000-3p-bs8-npu_3/final_step_3000
[DEBUG] 2021-07-12 19:31:50,243 [run_pretraining.py:  576]:	end of training, total steps: 3000
I0712 19:31:50.243188 48394 lod_tensor_blocking_queue.h:59] LoDTensorBlockingQueue close
I0712 19:31:50.243214 48394 blocking_queue.h:132] close queue
I0712 19:31:50.243692 51934 lod_tensor_blocking_queue.h:59] LoDTensorBlockingQueue close
I0712 19:31:50.243736 51934 blocking_queue.h:132] close queue
I0712 19:31:58.069372 48394 reader.h:164] ~ReaderHolder
I0712 19:31:58.069447 48394 buffered_reader.cc:22] ~BufferedReader
I0712 19:31:58.069454 48394 lod_tensor_blocking_queue.h:59] LoDTensorBlockingQueue close
I0712 19:31:58.069461 48394 blocking_queue.h:132] close queue
I0712 19:31:58.069628 48394 reader.cc:76] ~DecoratedReader
I0712 19:31:58.069638 48394 lod_tensor_blocking_queue.h:59] LoDTensorBlockingQueue close
I0712 19:31:58.069644 48394 blocking_queue.h:132] close queue
I0712 19:31:58.069671 48394 lod_tensor_blocking_queue.h:59] LoDTensorBlockingQueue close
I0712 19:31:58.069676 48394 blocking_queue.h:132] close queue
I0712 19:31:58.070744 48394 reader.h:164] ~ReaderHolder
